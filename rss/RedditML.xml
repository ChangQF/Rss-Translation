<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 29 Nov 2023 01:00:57 GMT</lastBuildDate>
    <item>
      <title>[D] AI视频头像开源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186b1n8/d_ai_video_avatar_open_source/</link>
      <description><![CDATA[有谁知道或猜测 heygen.com 或 https://www.synthesia.io ？ 我很好奇是否有像稳定扩散那样的开源替代模型，我见过像 SadTalker 这样的东西，但这只是移动图像，其质量与此不同。 &lt; !-- SC_ON --&gt;  由   提交 /u/TernaryJimbo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186b1n8/d_ai_video_avatar_open_source/</guid>
      <pubDate>Tue, 28 Nov 2023 23:59:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用 Python 定制 LSTM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186auap/p_customising_lstm_in_python/</link>
      <description><![CDATA[嗨，有没有办法在 Python 中自定义 LSTM 模型？我需要删除忘记门和窥视孔连接，但我还没有找到实现此目的的方法。我很感激任何帮助   由   提交/u/FaithinessOk1255   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186auap/p_customising_lstm_in_python/</guid>
      <pubDate>Tue, 28 Nov 2023 23:50:46 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]知识蒸馏定义不好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18681i4/discussion_knowledge_distillation_is_badly_defined/</link>
      <description><![CDATA[或者不那么挑衅地说，知识蒸馏是一系列没有明确目标的技术。 在我看来，在文献中通常考虑两种类型的知识蒸馏目标：  让学生模型向教师模型学习，以在教师训练数据集上重现教师的答案（非常重要） 让学生模型向教师模型学习，以重现教师在另一个下游数据集上预测的答案，因此教师和学生都不会“看到” ;之前的那些数据点  但是，我可以想象另一个我认为合理但似乎没有进行太多探索的目标：  拥有学生模型复制教师的输出到处，也就是说，训练学生对任何数据点给出与教师相同的答案。这可以通过将损失函数设置为教师和学生预测之间均方差的 x 积分来实现。我真的不知道如何解决这个特定问题，也许使用重要性采样？  如果有人知道尝试（3）的论文，请发布链接。  如果有人知道尝试（3）的论文，请发布链接。 p&gt; 讨论 知识蒸馏可能具有这三个目标之一（甚至可能是另一个目标）。根据实际用于训练学生的目标，结果应该会有很大差异。 教师在 A 组上进行训练，学生在 A 组上进行训练 在 (1) 的情况下，考虑到学生通常较小或具有更简单的架构，学生不会超越教师也就不足为奇了。如果学生在与老师相同的测试集上进行评估，那么学生就无法在他的领域击败老师。然而，学生可能完全无法匹配教师对分布外 (OOD) 数据的预测，因为它从未接受过 OOD 样本的训练。在这些情况下，我不确定学生是否会超越老师。 老师在 A 组上训练，学生在 B 组上训练 在（2）的情况下，考虑到新的下游分布通常与训练分布有很大不同，学生表现优于老师我不会感到惊讶，因此老师永远没有机会从这个新数据集中学习，但是学生会同时获得先前的信息（通过老师）和新的信息（通过输入，成为梯度，成为参数更新）。我什至想说，在这种情况下，一个体型相似的学生会被老师殴打，这将是令人惊讶的。 这就是为什么我认为如果我们在被打之前承认这种潜在影响会更好。令人惊讶的是，学生模型的表现优于教师。这在法学硕士接受其他法学硕士生成的数据训练的时代似乎尤为重要。在我看来，人们高估了蒸馏的效果，而实际上它可能只是迁移学习。性能的提高将归因于额外数据的使用，或者生成数据的选择机制，而不是蒸馏行为。 教师在 A 组上接受培训，学生在 A 组上接受培训整个输入域 对于（3），我想这实际上是知识蒸馏的最真实形式，因为目标实际上是在整个域上复制（非常复杂的）函数而不是只是一小部分。我想这就是所谓的“模型压缩”。在文献中，但我从未见过这样的问题。这种方法对于分布外的样本应该是稳健的，因为学生应该做出与老师相同的预测。换句话说，如果老师对 OOD 数据稳健，那么学生也应该如此。 我希望学生在任何给定的测试集上都比老师表现得更好一些，因为学生应该“顺利”出”教师做出的任何异常（伪影）预测并创建一种正则化形式。不过我可能是错的。 请随意发表您对此的想法。   由   提交 /u/Cosmolithe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18681i4/discussion_knowledge_distillation_is_badly_defined/</guid>
      <pubDate>Tue, 28 Nov 2023 21:58:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 一天内的数据集。基于聚类的快速数据集创建方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1864rby/r_dataset_in_a_day_a_clusteringbased_approach_for/</link>
      <description><![CDATA[https:/ /medium.com/bumble-tech/dataset-in-a-day-7f369de3b178   由   提交 /u/Dutchcheesehead   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1864rby/r_dataset_in_a_day_a_clusteringbased_approach_for/</guid>
      <pubDate>Tue, 28 Nov 2023 19:43:48 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]您发现自己每周在工作的哪一部分上浪费时间最多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/</link>
      <description><![CDATA[不询问拖延症、实际工作职责。对我来说，它必须处理电子表格和演示文稿。您的工作流程中存在哪些瓶颈？   由   提交/u/zero-true  /u/zero-true reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/</guid>
      <pubDate>Tue, 28 Nov 2023 18:52:33 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习的 AMD GPU [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1863brm/amd_gpu_for_machine_learning_d/</link>
      <description><![CDATA[我是一名计算机科学学生，最近为我的第一台游戏电脑购买了组件。我发现 6800 的价格不错，相当不错，但我想知道面向机器学习的库（和其他相关的东西）是否会出现问题，因为我发现 NVIDIA GPU 更适合它。如果是这样，我是否仍然可以使用我拥有的 AMD GPU 获得不错的结果，还是应该更改它？   由   提交 /u/the_fabbest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1863brm/amd_gpu_for_machine_learning_d/</guid>
      <pubDate>Tue, 28 Nov 2023 18:44:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] minOFT：一个易于使用的 PyTorch 库，用于将正交微调 (OFT) 应用于 PyTorch 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1862am5/p_minoft_an_easytouse_pytorch_library_for/</link>
      <description><![CDATA[嗨r/MachineLearning， 我想分享我在微调语言模型（正交微调）研究中遇到的一项非常有趣的工作的开源实现。 正交微调 (OFT) 是 LoRA 的一种更强大、稳定且样本效率更高的替代方案，LoRA 最初是为微调扩散模型而开发的。 LoRA 通过添加两个低秩矩阵的乘积来更新预训练权重矩阵，而 OFT 将预训练层权重乘以可学习的正交矩阵以应用约束变换。 OFT 的作者最近表明，这种方法（通过名为 butterfly OFT 的巧妙改进）也适用于视觉转换器和语言模型。 灵感来自minLoRA，我认为最好有一个最小的开源存储库来测试并在微调时比较 OFT 与 LoRA语言模型。它也是由 Andrej Karpathy 在 nanoGPT 之上构建的。该库可通过 pip 安装，并且可以与任何 PyTorch 模型（包括 Hugging Face 模型）通用，就像 minLoRA 一样。 欢迎提供反馈和贡献！您可以在下面尝试一下： https://github.com/alif-munim/minOFT   由   提交/u/0blue2brown   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1862am5/p_minoft_an_easytouse_pytorch_library_for/</guid>
      <pubDate>Tue, 28 Nov 2023 18:01:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 对齐即代码：使 LLM 应用程序与 Tanuki 一起运行。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1861p30/p_alignmentascode_making_llm_applications_behave/</link>
      <description><![CDATA[我是 Tanuki 的贡献者，一个项目，允许您使用 Python 中的测试驱动语法以声明方式定义 LLM 行为。 通过指定 LLM 必须作为测试履行的合同，它有助于减少 MLOps 并使您能够使用标准开发操作流程将模型的行为与您的要求保持一致。 此外，这些对齐语句有助于自动师生模型蒸馏，以将成本和延迟降低多达 10 倍（请参阅基准）。  非常感谢任何想法或反馈。   由   提交 /u/Noddybear   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1861p30/p_alignmentascode_making_llm_applications_behave/</guid>
      <pubDate>Tue, 28 Nov 2023 17:37:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 具有 2d 旋转嵌入的交叉轴变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18607oa/r_crossaxis_transformer_with_2d_rotary_embeddings/</link>
      <description><![CDATA[ 由   提交/u/lilyerickson  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18607oa/r_crossaxis_transformer_with_2d_rotary_embeddings/</guid>
      <pubDate>Tue, 28 Nov 2023 16:34:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有预训练的人脸识别模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185z0li/d_is_there_any_pretrained_model_for_face/</link>
      <description><![CDATA[我想用Java语言做一个人脸识别功能：输入两张人脸图像，输出是否是同一个人。有没有可以直接使用的预训练模型？我尝试使用opencv的直方图归一化方法进行识别，但是准确率非常差，无法接受。   由   提交 /u/Rare-Durian-2121   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185z0li/d_is_there_any_pretrained_model_for_face/</guid>
      <pubDate>Tue, 28 Nov 2023 15:44:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师加薪？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185y5wn/d_machine_learning_engineer_salary_increase/</link>
      <description><![CDATA[大家好，我去年大学毕业，一直在佛罗里达州的一家公司担任机器学习工程师。我一年赚7.6万。该公司提供硕士学位学费报销。通常情况下，获得硕士学位后，您的加薪是多少？ 后续问题：从在线大学获得硕士学位（我仍然会全职工作）的声望是否会低于从在线大学获得硕士学位？亲自？ 请问，如果您愿意的话，是否有人介意直接分享他们大学毕业后的个人薪资数据以及整个职业生涯的进展情况？   由   提交/u/Fluid-Pipe-2831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185y5wn/d_machine_learning_engineer_salary_increase/</guid>
      <pubDate>Tue, 28 Nov 2023 15:06:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2023机构排名</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185pdax/d_neurips_2023_institutions_ranking/</link>
      <description><![CDATA[       由   提交/u/Roland31415   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185pdax/d_neurips_2023_institutions_ranking/</guid>
      <pubDate>Tue, 28 Nov 2023 06:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] SuGaR：用于高效 3D 网格重建和高质量网格渲染的表面对齐高斯喷射</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</link>
      <description><![CDATA[计算机视觉研究人员开发了一种方法，只需几分钟即可在单个 GPU 上根据图像创建详细的 3D 模型。他们的方法称为 SuGaR，通过优化数百万个微小粒子来匹配场景图像。关键的创新是让粒子与表面对齐，以便可以轻松地将它们变成网格。 传统的 3D 建模速度慢且资源繁重。激光扫描不方便。摄影测量点云缺乏细节。像 NeRF 这样的神经辐射场可以产生令人惊叹的渲染效果，但即使使用强大的硬件，将它们优化为网格也需要数小时或数天的时间。 VR/AR、游戏、教育等领域对更轻松的 3D 内容创建的需求不断增长。但大多数技术都有很大的速度、质量或成本限制，阻碍了它们主流使用。 这种新的 SuGaR 技术结合了神经场景表示和计算几何方面的最新进展，推动了最先进的技术的发展它首先利用一种称为高斯喷射的方法，该方法基本上使用大量微小粒子来复制场景。放置和配置粒子只需几分钟。问题是它们不会自然地形成连贯的网格。 SuGaR 提供了一种新的初始化和训练方法，可以将粒子与场景表面对齐，同时保持细节完整。这种条件允许将粒子云直接视为点云。 然后，他们应用一种称为泊松表面重建的计算技术，以并行方式直接在结构化粒子之间构建网格。一次处理数百万个粒子可以在低延迟的情况下实现高保真度。 通过将繁重的工作转移到前端点云结构化阶段，SuGaR 使最终网格生成与其他最先进的技术相比极其高效-艺术神经/混合方法。 实验表明，SuGaR 构建详细网格的速度比之前发布的技术快几个数量级，同时实现具有竞争力的视觉质量。该论文分享了一些在 10 分钟内重建复杂场景的有希望的示例。 处理更多样化的场景类型仍然存在问题。但就使用可访问的硬件使高质量 3D 重建更接近交互速度而言，这看起来是引人注目的进步。 TLDR：对齐高斯溅射中的粒子可让您将它们转变为详细的网格。使高质量 3D 更好、更快、更便宜。 完整摘要位于此处。论文网站此处。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</guid>
      <pubDate>Tue, 28 Nov 2023 02:37:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你会痴迷地观看模特训练吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18576ol/d_do_you_obsessively_watch_your_models_train/</link>
      <description><![CDATA[我发现自己看张量板的时间多于工作——只是想知道其他陷入这种模式的人是否对生产力有建议   由   提交 /u/TehDing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18576ol/d_do_you_obsessively_watch_your_models_train/</guid>
      <pubDate>Mon, 27 Nov 2023 16:39:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>