<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 27 Feb 2024 12:22:34 GMT</lastBuildDate>
    <item>
      <title>[D] 如何使用 HellaSwag 等数据集执行 LLAMA2 等法学硕士的基准测试？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1ajx1/d_how_to_execute_a_benchmark_for_llms_such_as/</link>
      <description><![CDATA[你好， 我正在阅读有关 HellaSwag 的论文，了解数据集的结构以及它给数据集带来的挑战法学硕士。然而，我在论文中没有找到任何关于如何为像 LLAMA2 这样的 LLM 确定这样的基准的内容。数据集中的一个示例是： 一名妇女带着水桶和狗在外面。狗到处乱跑，试图避免洗澡。她… a) 用肥皂冲洗水桶并吹干狗的头。 b) 使用软管防止它沾上肥皂. c) 把狗弄湿了，然后它又逃跑了。 d) 和狗一起进入浴缸  模型现在必须选择最佳答案。但我如何确定模型更喜欢哪个答案呢？我是否只需向模型提供多项选择题并使用 logits 来计算下一个标记是否最有可能是 a、b、c 或 d？或者我是否必须在迭代过程中确定四个答案中每一个的总体概率，类似于束搜索？我目前正在使用一个基于 HF Transformers 的库，这将导致最后一个变体非常耗时。  我也愿意接受其他易于使用的基准测试。我只需要一个指标来以相对通用的方式衡量模型的性能下降，以量化我对其进行的一些操作的影响。 提前非常感谢 &lt; !-- SC_ON --&gt;  由   提交/u/bineda  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1ajx1/d_how_to_execute_a_benchmark_for_llms_such_as/</guid>
      <pubDate>Tue, 27 Feb 2024 12:21:46 GMT</pubDate>
    </item>
    <item>
      <title>在什么上部署模型 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1a8j7/what_to_deploy_model_on_d/</link>
      <description><![CDATA[您好，我对模型部署的概念很陌生，想知道如何部署机器学习模型。我有一个模型，通过 FastAPI 创建了一个端点，以便发出预测请求。然而现在，我很困惑是否应该部署到 netlify 还是 heroku，以便我可以创建和托管向模型发出请求的前端。谢谢    由   提交 /u/FifaBoi11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1a8j7/what_to_deploy_model_on_d/</guid>
      <pubDate>Tue, 27 Feb 2024 12:04:15 GMT</pubDate>
    </item>
    <item>
      <title>需要有关 Wav2lip 的帮助 [D]、[R]、[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b19t8y/need_help_with_wav2lip_drp/</link>
      <description><![CDATA[您好，我需要有关 Wav2lip 的帮助，任何人都可以帮助我如何修改 wav2lip 中的 lipsync mask，请给我建议，无论您对 wav2lip 了解多少，我们将不胜感激&lt; /p&gt;   由   提交/u/Good-Ad-9759   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b19t8y/need_help_with_wav2lip_drp/</guid>
      <pubDate>Tue, 27 Feb 2024 11:40:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 会议论文是双盲的。为了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b18is0/d_conference_paper_is_doubleblinded_for_what/</link>
      <description><![CDATA[我对提交给会议的论文必须双盲的要求感到非常困惑，但它们却可以预印有作者姓名和隶属关系，并且可以同时作为同一篇论文共享。人们甚至在接受/发表之前在 Twitter、LinkedIn、Reddit 等 SNS 上宣传他们的论文。感觉就像我在看 Instagram 版的学术界。如何确保广告而不是报纸本身不会影响决策过程？   由   提交 /u/Dry_Cheesecake_8311   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b18is0/d_conference_paper_is_doubleblinded_for_what/</guid>
      <pubDate>Tue, 27 Feb 2024 10:17:05 GMT</pubDate>
    </item>
    <item>
      <title>[N] 在 MWC 的技嘉展位上看到了这些……想象一下你可以用这些做什么！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b17igl/n_saw_these_at_the_gigabyte_booth_at_mwcimagine/</link>
      <description><![CDATA[       由   提交 /u/BubblyMcnutty   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b17igl/n_saw_these_at_the_gigabyte_booth_at_mwcimagine/</guid>
      <pubDate>Tue, 27 Feb 2024 09:05:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找一个比较和优化 A/B 提示的网站：它存在吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b167wg/d_seeking_a_site_for_comparing_and_optimizing_ab/</link>
      <description><![CDATA[提示战斗。我一直在寻找一个网站，您可以在其中并排看到两个不同的写作提示，对其进行测试，甚至让它们自己变得更好。我今天花了一个小时试图找到这样的东西。然而，我只发现了一些复杂的选项，似乎是为特殊团队使用的，而不是为所有人使用的。 这让我思考 – 为什么没有一种简单的方法来查看哪些写作提示是更好的？就像 ELO A/B 测试竞技场排行榜一样，提示相互竞争，我们可以看到哪一个最适合修复代码或撰写文章或评论等事情。如果能有一个最佳提示列表可供选择那就太好了。有谁知道是否有这样的网站或服务？   由   提交/u/Radek87  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b167wg/d_seeking_a_site_for_comparing_and_optimizing_ab/</guid>
      <pubDate>Tue, 27 Feb 2024 07:38:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对 CVPR 结果和审稿动态影响的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b15i08/d_reflections_on_cvpr_results_and_the_impact_of/</link>
      <description><![CDATA[最近的 CVPR 结果已经发布，虽然这是该过程的一部分，但我们的一篇论文不幸遭到拒绝。结果本身并不像过程那样困扰我。 我想分享对特定论文的观察。尽管同时获得了弱接受（2）和弱拒绝评级，但有趣的是，在反驳阶段（审阅者可以访问第三次审阅）之后，评级发生了显着变化。许多审稿人根据第三位审稿人的反馈调整了他们的分数（没什么大不了的）。 这提出了一个有效的问题：如果每个人最终都修改了他们的决定，那么拥有三名审稿人和一名额外的区域主席的目的是什么？基于一个人的观点？这似乎与审稿过程的协作性质违反直觉。 如果审稿人感觉不熟悉该主题，也许他们应该考虑要求重新分配论文，而不是影响整个决策过程。考虑到作者投入的时间和精力至关重要。毕竟，如果没有经过彻底审查，反驳有何意义？ 让我们努力在未来建立一个更加透明和建设性的审查过程。 让我们就这个问题进行一次健康的讨论。  您对审稿人满意吗？ 查看民意调查&lt; /p&gt;   由   提交/u/darkknight-6  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b15i08/d_reflections_on_cvpr_results_and_the_impact_of/</guid>
      <pubDate>Tue, 27 Feb 2024 06:52:16 GMT</pubDate>
    </item>
    <item>
      <title>通过 torch.compile 支持 gpt-fast 中的 Mixtral - 比任何非 Groq 端点更快的解码（！）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b10g2s/supporting_mixtral_in_gptfast_through/</link>
      <description><![CDATA[大家好，我们去年 12 月发布了 gpt-fast 作为可破解的“教程”实现文本生成的 SOTA 解码性能的各种实现。 从那时起，我们最近还在 gpt-fast 中添加了 Mixtral 实现。在这里查看：https://github.com/pytorch-labs/gpt-fast /tree/main/mixtral-moe  特色  (!) 无自定义内核 int8 和张量并行支持&lt; /li&gt; 仍然非常简单（支持&lt;150 LOC） 比任何（非 Groq）API 端点更快的解码速度，高达 220 tok/s/用户。  我还对这里涉及的挑战写了一份较长的解释：https://thonking.substack.com/p/short-supporting-mixtral-in-gpt-fast 希望人们觉得它有趣且有用！有趣的是，由于我们实际上在大约两个月前就完成了这项工作，并且推迟了将其合并，所以一些人（与我们无关）实际上已经对其进行了基准测试。 例如 此评论。  我们最近用 Mixtral 8x7B 尝试过此操作，结果非常疯狂！ Mixtral 8x7B 8 位版本在 A100-GPU (80GB) 上提供 55 个令牌/秒。最有趣的是，它比 4 位+vLLM 更好。    由   提交 /u/programmerChilli   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b10g2s/supporting_mixtral_in_gptfast_through/</guid>
      <pubDate>Tue, 27 Feb 2024 02:27:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 某些类别的模型现在被认为“过时”了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0ua8s/d_are_some_classes_of_models_considered_obsolete/</link>
      <description><![CDATA[作为一名高级 SWE，我希望在 ML 和数据科学方面进行一些自我驱动的培训。我正在收集和组织课程，我想知道某些主题现在是否已经过时，我可以安全地跳过它们。这主要来自构建应用程序的 POV。 例如，以 Coursera 上的 Andrew Ng GAN 专业为例。有了 Midjourney 或 OpenAI 视觉模型等稳定的扩散模型，GAN 仍然有用例吗？在 NLP 领域，现在只有 GPT4，我还需要研究 HMM 或构建玩具翻译和摘要模型吗？    由   提交/u/The-_Captain  /u/The-_Captain  reddit.com/r/MachineLearning/comments/1b0ua8s/d_are_some_classes_of_models_considered_obsolete/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0ua8s/d_are_some_classes_of_models_considered_obsolete/</guid>
      <pubDate>Mon, 26 Feb 2024 22:04:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] Genie：生成交互环境</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0tj6o/r_genie_generative_interactive_environments/</link>
      <description><![CDATA[ 由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0tj6o/r_genie_generative_interactive_environments/</guid>
      <pubDate>Mon, 26 Feb 2024 21:35:29 GMT</pubDate>
    </item>
    <item>
      <title>对于新晋研究科学家来说，该行业不会“复苏”[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0n3ib/the_industry_is_not_going_recover_for_newly/</link>
      <description><![CDATA[      今天的热门话题问：“科技行业还没有复苏吗？我有那么糟糕吗？” 让我做出一个大胆的预测（我希望我是错的，但我不认为我是错的）：这个行业不会“ “恢复”对于新晋研究科学家： 您的机器学习论文数量呈指数级增长，反映出博士生和博士后数量呈指数级增长： ​ &lt; p&gt;https://preview.redd.it/viv6l1gnkykc1。 png?width=899&amp;format=png&amp;auto=webp&amp;s=04e227dede42f7d46d1941fc268bb7ea0a409a04 ...毕业并开始竞争大致固定数量的井- 支付行业研究职位。这些职位的数量可能会季节性增加或减少，但长期趋势是他们的就业前景将变得越来越糟糕，而这种指数趋势仍在持续。 ​  div&gt;  由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0n3ib/the_industry_is_not_going_recover_for_newly/</guid>
      <pubDate>Mon, 26 Feb 2024 17:24:08 GMT</pubDate>
    </item>
    <item>
      <title>[N] 科技巨头正在开发他们的人工智能芯片。这是清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0ira9/n_tech_giants_are_developing_their_ai_chips_heres/</link>
      <description><![CDATA[NVIDIA GPU 短缺，导致多家公司创建自己的 AI 芯片。以下是这些公司的列表： • Google 处于改进张量处理单元 (TPU) 的前沿https://cloud.google.com/tpu?hl=en Google Cloud 技术。 • OpenAI 正在研究设计专有 AI 芯片的潜力https://www.reuters.com/ technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/。 • 微软宣布 https://news.microsoft.com/source/ features/ai/in-house-chips-silicon-to-service-to-meet-ai-demand/ 两款定制设计的芯片：用于大型语言模型训练和推理的 Microsoft Azure Maia AI 加速器以及用于大型语言模型训练和推理的 Microsoft Azure Maia AI 加速器Azure Cobalt CPU，用于 Microsoft 云上的通用计算工作负载。 • 亚马逊推出了 Inferentia AI 芯片 https://aws.amazon.com/machine-learning/inferentia/ 和第二代机器学习 (ML) 加速器 AWS Trainium https://aws.amazon.com/machine-learning/trainium/。 • Apple 一直在开发其系列定制芯片并推出https://www.apple.com/newsroom/2023/10/apple-unveils-m3-m3-pro-and-m3-max-the-most-advanced-chips-for-a-personal -computer/ M3、M3 Pro 和 M3 Max 处理器，可扩展到专门的 AI 任务。 • Meta 计划部署新版本的定制芯片，旨在支持其人工智能据路透社报道，人工智能（AI）的推动 https://www.reuters.com/technology/meta-deploy-in-house-custom-chips-this-year-power-ai-drive-memo-2024-02-01/ . • 据报道，华为https://www.reuters.com/technology/ai-chip-demand-forces-huawei-slow-smartphone-product-sources-2024-02-05/由于人工智能芯片的需求，人工智能并放慢了高端 Mate 60 手机的生产 https://www.hisilicon.com/ en/products/ascend 飙升。 我错过了什么吗？   由   提交 /u/vvkuka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0ira9/n_tech_giants_are_developing_their_ai_chips_heres/</guid>
      <pubDate>Mon, 26 Feb 2024 14:25:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是科技行业还没复苏还是我太差了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0ia76/d_is_the_tech_industry_still_not_recovered_or_i/</link>
      <description><![CDATA[我是欧洲顶尖大学的一名应届博士毕业生，正在研究 ML/CV 中的一些热门主题，已发表 8 - 20 篇论文，其中大部分是我的第一作者。这些论文已累计被引用1000-3000次。 （使用新帐户和广泛的范围来保持匿名） 尽管我认为自己是一个相当有实力的候选人，但我在最近的求职过程中遇到了重大挑战。我主要瞄准研究科学家职位，希望从事开放式研究。我已经联系了欧洲、中东和非洲地区的许多高级机器学习研究人员，虽然有些人表达了兴趣，但不幸的是，由于各种原因（例如人员有限或招聘经理没有更新信息），没有一个机会成为现实。 我主要针对大型科技公司以及一些最近流行的机器学习初创公司。不幸的是，我的大部分申请都被拒绝了，而且常常没有面试的机会。 （我只接受过一家大型科技公司的一次面试，然后就被拒绝了。） 特别是，尽管有朋友的推荐，我还是立即遭到了 Meta 的研究科学家职位拒绝（几天之内）。我现在只是非常困惑和不安，不知道出了什么问题，我是否被这些公司列入了黑名单？但我不记得我树敌过。我希望就下一步可以做什么寻求一些建议......   由   提交/u/Holiday_Safe_5620   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0ia76/d_is_the_tech_industry_still_not_recovered_or_i/</guid>
      <pubDate>Mon, 26 Feb 2024 14:04:26 GMT</pubDate>
    </item>
    <item>
      <title>目前关于使用 TensorFlow 2.x 与 PyTorch 的共识是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0gxy7/whats_the_current_consensus_on_using_tensorflow/</link>
      <description><![CDATA[我知道许多人在 TF1 到 TF2 迁移期间离开了 TF，并且再也没有回头。我的问题是，目前关于使用 TF2 与 PyTorch（与 Jax）的共识是什么？为什么？  从端到端的角度来看，对我来说，TF2 很好。 PyTorch 上的调试更容易，但好处还不足以放弃所有内容并永远保留 TF2。你们怎么看？ 假设您正在构建人工智能产品并且部署是必须的，您在代码库中更喜欢 TensorFlow 还是 Pytorch（或 JAX），为什么？    由   提交 /u/1infiniteloop   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0gxy7/whats_the_current_consensus_on_using_tensorflow/</guid>
      <pubDate>Mon, 26 Feb 2024 13:01:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>