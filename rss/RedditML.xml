<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 03 May 2024 12:23:59 GMT</lastBuildDate>
    <item>
      <title>[R] HGRN2：具有状态扩展的门控线性 RNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj4ouc/r_hgrn2_gated_linear_rnns_with_state_expansion/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.07904 代码：https://github .com/OpenNLPLab/HGRN2 独立代码 (1):  https://github.com/Doraemonzzz/hgru2-pytorch 独立代码 (2): https://github.com/sustcsonglin/flash-linear-attention/tree/main/fla/models/hgrn2 摘要：  分层门控线性 RNN（HGRN，Qin 等人，2023 ）在语言建模方面展示了有竞争力的训练速度和性能，同时提供了高效的推理。然而，HGRN 的循环状态大小仍然相对较小，这限制了其表达能力。为了解决这个问题，受线性注意力的启发，我们引入了一种简单的基于外积的状态扩展机制，以便可以在不引入任何额外参数的情况下显着扩大循环状态大小。线性注意力形式还允许进行硬件高效的训练。我们大量的实验验证了 HGRN2 在语言建模、图像分类和 Long Range Arena 方面相对于 HGRN1 的优势。我们最大的 3B HGRN2 模型在受控实验设置中的语言建模方面略优于 Mamba 和 LLaMa Architecture Transformer；并且在下游评估中与许多开源 3B 模型竞争，同时使用更少的总训练令牌。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj4ouc/r_hgrn2_gated_linear_rnns_with_state_expansion/</guid>
      <pubDate>Fri, 03 May 2024 09:47:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于 Transformer 的语言模型内部工作原理入门</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj4o70/r_a_primer_on_the_inner_workings_of/</link>
      <description><![CDATA[      作者：Javier Ferrando (UPC)、Gabriele Sarti (RUG)、Arianna Bisazza （RUG），Marta Costa-jussà（元） 论文： https://arxiv .org/abs/2405.00208 摘要：  旨在解释高级语言内部运作方式的研究迅速进展模型强调需要将从该领域多年的工作中获得的见解结合起来。本入门书对用于解释基于 Transformer 的语言模型的内部工作原理的当前技术进行了简明的技术介绍，重点关注仅生成解码器的架构。最后，我们对这些模型实现的已知内部机制进行了全面概述，揭示了该领域流行方法和活跃研究方向之间的联系。  https://preview.redd.it/57y44wwdn6yc1.png?width=1486&amp;format= png&amp;汽车=webp&amp;s=7b7fb38a59f3819ce0d601140b1e031b98c17183   由   提交 /u/SubstantialDig6663   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj4o70/r_a_primer_on_the_inner_workings_of/</guid>
      <pubDate>Fri, 03 May 2024 09:46:38 GMT</pubDate>
    </item>
    <item>
      <title>[D]求助：1.现在的博士职位还可以吗？ 2.（3d）计算机视觉；点云处理，我的研究路线图正确吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj4avg/d_help_1_current_phd_position_is_alright_2_3d/</link>
      <description><![CDATA[目前我是博士生（第二学期中期）=（将近7个月），特别是我专注于点云分类研究和分割都是我自己的。没有我的教授或博士同事的指导。 (s)。 我有两个具体问题：  我应该放弃我的博士学位吗？在现任主管的领导下？为什么？因为几乎没有监督和指导？在一个拥有如此巨大的知识和快速的研究的世界中，我自己有可能获得令人满意的博士学位吗？考虑到我对该领域（点云处理）和深度学习的理解仍然相当初级。而即使没有肥沃的环境，我也有勇气去工作。我应该辞职并寻找更好的地方继续我的研究吗？这种情况有多糟糕？ 最后，我更关心我的研究策略，实际上它有点不稳定。之前。从项目开始到三个月前，我只读了一些开创性的论文，即pointnet、pointnet++、pointtransformer系列。我花了 3-4 个月的时间只探索了这个领域的表面，因为这是我第一次接触这个领域，而且老实说我对深度学习也没有很好的理解。只是掌握了简单和高级的概念和想法。但大约三个月前，我意识到我从来没有提出自己的想法并为该领域做出贡献。缺乏知识加上绝对的零监督，这种天真的阅读是没有希望的。所以，我决定这次从头开始，用 Pointnet 论文深入并从头到尾地理解它。论文中的概念及其代码实现仍在进行中。我绝对感觉到我正在学习。但问题是：我的下一步应该是什么？特别是，该领域已经使用了不同的方法和结构化文献。那么，我应该在多个方向上追求相同的策略，还是长期坚持一个策略？我什至不知道我在这里有什么确切的选择！ :( 我希望它足够清楚。     提交者    /u/Same_Half3758   [链接] [评论]&lt; /a&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj4avg/d_help_1_current_phd_position_is_alright_2_3d/</guid>
      <pubDate>Fri, 03 May 2024 09:20:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对特定领域数据微调 Phi-3 模型 - 寻求建议和见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj2hzb/d_finetune_phi3_model_for_domain_specific_data/</link>
      <description><![CDATA[      嗨， 我目前正在对金融数据的 Phi-3 模型进行微调。虽然在训练过程中损失在减少，表明模型学习得相当好，但在自定义基准上的结果却出奇地差。事实上，与基础模型相比，准确度有所下降。 我观察到的结果：  Phi-3-mini-4k-instruct（基础模型）：平均域准确度为 40% Qlora - Phi-3-mini-4k-instruct（微调模型）：平均域准确度为 35%  我尝试了各种方法，包括 QLora、Lora 和 FFT，但与基础模型相比，所有结果都很差。此外，我还尝试将序列长度减少到 2k，试图约束模型并防止其偏离轨道，但不幸的是，这并没有带来任何改进。 我想知道超参数是否存在问题，例如学习率，或者是否有任何建议，关于如何有效地微调此模型以在特定领域数据上获得更好的性能。 如果有人成功地在特定领域数据上微调了 Phi-3 模型，我将非常感激您分享的任何见解或建议。提前感谢您的帮助和支持！  qlora 配置： ​ sequence_len：4000 sample_packing：true pad_to_sequence_len：true trust_remote_code：True 适配器：qlora lora_r：256 lora_alpha：512 lora_dropout：0.05 lora_target_linear：true lora_target_modules：- q_proj - v_proj - k_proj - o_proj - gate_proj - down_proj - up_proj gradient_accumulation_steps：1 micro_batch_size：2 num_epochs：4 优化器：adamw_torch lr_scheduler：余弦 learning_rate：0.00002 warmup_steps：100 evals_per_epoch：4 eval_table_size： saves_per_epoch：1 调试：deepspeed：weight_decay：0.0  https://preview.redd.it/7afyhxcjv5yc1.png?width=976&amp;format=png&amp;auto=webp&amp;s=1ce3efe6df6e4533bad5ec2f23e4f4968736bd56 ​    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj2hzb/d_finetune_phi3_model_for_domain_specific_data/</guid>
      <pubDate>Fri, 03 May 2024 07:10:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] bioDraws 的积极抽奖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj2au2/r_postive_draws_for_biodraws/</link>
      <description><![CDATA[我是 python 初学者。请帮助我解决以下情况。我的研究陷入困境。考虑以下方程，其中必须生成随机值（当前已将方法设置为 NORMALMLHS）。 。 L1 =c+sigmaL1 * bioDraws (E_L1&#39;,&#39;NORMAL_MLHS) 。其中 L1 是内生变量，c 是估计常数，其下限为 0。sigmaL1 的下限也是 0。可以使用哪种方法代替“NORMAL_MLHS”来确保它生成正值，因此 L1 为正?   由   提交/u/h2_so4_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj2au2/r_postive_draws_for_biodraws/</guid>
      <pubDate>Fri, 03 May 2024 06:57:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 距离估计 - 真实世界坐标</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj14fe/d_distance_estimation_real_world_coordinates/</link>
      <description><![CDATA[您好，很抱歉再次转发此问题，但这非常重要，我需要帮助。 我有三个房间内不同位置（前墙、左墙、右墙）的摄像头。我应该能够找到房间中人与人之间的距离（以米为单位）。 我对所有摄像机进行了摄像机校准。 我尝试使用 SIFT 匹配公共点，然后执行DLT 方法，但值相差甚远，甚至不接近实际值。 我也尝试过立体视觉，但这并没有给我接近的值。 我也相机之间的距离也以米为单位。 我是计算机视觉的初学者，我应该很快完成这项任务，但我已经坚持了一个月了，而且我越来越累了无法解决这个问题，我已经没有解决方案了。  如果有人帮助我并引导我走向正确的方向，我将非常感激。 非常感谢您的帮助和时间😄   由   提交 /u/Embarrassed_Top_5901   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj14fe/d_distance_estimation_real_world_coordinates/</guid>
      <pubDate>Fri, 03 May 2024 05:38:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 迭代推理偏好优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciyps2/r_iterative_reasoning_preference_optimization/</link>
      <description><![CDATA[ 由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciyps2/r_iterative_reasoning_preference_optimization/</guid>
      <pubDate>Fri, 03 May 2024 03:20:19 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 我应该去ICML发表论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</link>
      <description><![CDATA[我完成了博士学位。一年前。离开学术界，成为一家科技公司的数据科学家。我喜欢它，但仍在考虑将来以某种方式转向更多的研究职位。不过不确定。 无论如何，我的一个未完成的作品被一个朋友选中，完成并申请到 ICML。它被接受了（耶！）。 我现在想知道 - 除了我发现会议很有趣之外，参加会议是否有真正的好处？提交论文？我知道对于学术界/研究人员来说，这是一个很好的机会来了解人们并了解当前的研究。但由于我不再在那里，有真正的理由去吗？ 这是一个很奇怪的问题，但我只是不确定，我很高兴听到你的想法。  &gt;   由   提交 /u/meni_s   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</guid>
      <pubDate>Thu, 02 May 2024 21:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] Panza：个人电子邮件助理，经过培训并在设备上运行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciqvqw/p_panza_a_personal_email_assistant_trained_and/</link>
      <description><![CDATA[厌倦了精心制作精美的电子邮件，并希望有一个助手来接管繁重的工作，同时模仿您的写作风格？隆重推出 Panza，这是一款完全在您的设备上运行的个性化 LLM 电子邮件助手！在 Llama-3 或 Mistral 之间进行选择，根据您的独特风格进行定制，并让它为您编写电子邮件。看看我们的演示并在您的电子邮件中尝试一下：https://github.com/IST-DASLab/PanzaMail&lt; /a&gt; 有关 Panza 的一些技术细节：  Panza 是一款根据您的写作风格和过去的电子邮件历史记录定制的自动电子邮件助手。 Panza生成与您的写作风格相匹配的微调 LLM，并将其与检索增强生成 (RAG) 组件配对，帮助其生成相关电子邮件。 Panza **可以完全在本地进行训练和运行** 。目前，它需要具有 16-24 GiB 内存的单个 GPU，但我们还计划发布仅包含 CPU 的版本。 训练和执行也很快 - 对于大约 1000 封电子邮件的数据集，训练 Panza 需要不到一个小时，生成一封新电子邮件最多只需要几秒钟。    由   提交/u/eldar_ciki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciqvqw/p_panza_a_personal_email_assistant_trained_and/</guid>
      <pubDate>Thu, 02 May 2024 21:07:30 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 寻求帮助以找到更好的 GPU 设置。三个 H100 对比五个 A100？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</link>
      <description><![CDATA[长话短说，一家公司有购买 GPU 的预算，预计用于微调 LLM（可能是 70B 的），我必须进行研究找出哪种 GPU 设置最适合他们的预算。 预算可以购买三个 H100 GPU 或五个 A100 GPU。  我已尽了最大努力，但直到现在我还不清楚这些设置中哪一个更好。虽然五台 A100 拥有更多 VRAM，但他们说 H100 比 A100 快 2-8 倍！ 我正在寻求帮助。任何有价值的见解将不胜感激。   由   提交/u/nlpbaz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</guid>
      <pubDate>Thu, 02 May 2024 19:49:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于 ICML、NeurIPS、CVPR 等顶级会议，我一直在思考的事情。有多少论文是真正具有开创性的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</link>
      <description><![CDATA[我自己也有一些位于金星顶端的论文，但每当我坐下来对自己残酷地诚实时。我觉得我的作品不错，但影响力不大，就像墙上又多了一块砖。我想知道我们多久能看到像“注意力就是你所需要的一切”这样有影响力的东西。例如。   由   提交 /u/oddhvdfscuyg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</guid>
      <pubDate>Thu, 02 May 2024 18:37:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基准创建者应分阶段发布其基准数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cilnzv/d_benchmark_creators_should_release_their/</link>
      <description><![CDATA[关于基准污染有很多讨论，其中模型根据最终评估的数据进行训练。例如，最近的论文表明，与 GSM1K 相比，模型在公共 GSM8K 上的表现要好得多，这是最近创建的基准在难度和其他指标上扩展 AI 以匹配 GSM8K。 由于对基准污染的担忧，通常很难从表面上理解研究实验室关于模型性能的说法。很难知道一个模型是否获得了良好的基准性能，是因为它总体上是有能力的，还是因为它的预训练数据被污染并且在基准上过度拟合。 解决这个问题的一个解决方案是让基准创建者发布他们的数据集分阶段进行。例如，基准创建者可以在发布时发布其数据集的 50%，然后分两个阶段发布剩余的 50%，一年后发布 25%，两年后发布 25%。这将使模型评估者能够通过比较训练截止之前发布的数据子集与训练截止之后发布的数据子集的性能来检查基准污染。它还可以让我们更好地了解模型的实际执行情况。 最后一点 - 这种分阶段发布过程对于通过抓取网络创建的基准没有任何帮助，即使是稍后发布的数据子集可以在训练数据中找到。但它对于其他类型的基准测试应该很有用。   由   提交/u/kei147  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cilnzv/d_benchmark_creators_should_release_their/</guid>
      <pubDate>Thu, 02 May 2024 17:36:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] spRAG - 用于具有挑战性的现实世界任务的开源 RAG 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cikkw2/p_sprag_opensource_rag_implementation_for/</link>
      <description><![CDATA[大家好，我是 Superpowered AI (YC S22) 的 Zach。我们在 RAG 领域的工作已经一年多了，最近我们决定开源所有核心检索技术。 [spRAG](https://github.com/SuperpoweredAI/spRAG）是一个检索系统，旨在处理密集文本上的复杂现实查询，例如法律文档和财务报告。据我们所知，对于此类任务，它是所有 RAG 系统中最准确、最可靠的结果。例如，在 FinanceBench（这是一个特别具有挑战性的开放式金融问答基准）上，spRAG 正确回答了 83% 的问题，而普通 RAG 基准的正确率为 19%（使用 Chroma + OpenAI Ada）嵌入 + LangChain）。 您可以在项目的自述文件中找到有关其工作原理以及如何使用它的更多信息。我们也非常愿意接受贡献。我们特别需要围绕集成（即添加对更多向量数据库、嵌入模型等的支持）和评估方面的贡献。 很高兴回答任何问题！ [GitHub 存储库]( https://github.com/SuperpoweredAI/spRAG)   由   提交/u/zmccormick7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cikkw2/p_sprag_opensource_rag_implementation_for/</guid>
      <pubDate>Thu, 02 May 2024 16:50:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大三学生（本科生或一二年级博士生）在ICML、ICLR、NeurIPS等主要机器学习会议上有这么多论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</link>
      <description><![CDATA[大家好，今天ICML成绩出来了，恭喜所有在这里接受论文的同学。我自己不是学者，但有时我会为了工作而阅读这些会议上的论文，这真的很有趣。我只是有一个问题：为什么这些会议上大三的论文这么多？我认为这是你在 5 年博士学位期间必须学习的东西，而且几乎只能在博士学位的最后几年才能实现。另外，我听说要进入美国顶尖的博士项目，你需要事先写一些论文。那么，如果一个大三学生能这么早发表论文，为什么还要花5年时间攻读博士学位呢？   由   提交 /u/ShiftStrange1701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</guid>
      <pubDate>Thu, 02 May 2024 11:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>