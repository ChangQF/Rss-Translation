<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 05 Feb 2024 03:14:35 GMT</lastBuildDate>
    <item>
      <title>[D] 在 GPU、CPU 和操作系统上运行泄露的 Mistral Mediumb LLM、miqu-1-70B</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aj6g63/d_run_the_leaked_mistral_mediumb_llm_miqu170b/</link>
      <description><![CDATA[https://www.secondstate.io/articles/miqu-1-70b/&quot;&gt; secondarystate.io/articles/miqu-1-70b/ 使用具有自定义模型和操作的 LLM 应用程序开发平台。它是轻量级且可移植的 - 您可以在 Mac 上创建 LLM 应用程序，编译为 Wasm，然后在 Nvidia 设备上运行二进制应用程序。 亲自尝试   由   提交 /u/smileymileycoin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aj6g63/d_run_the_leaked_mistral_mediumb_llm_miqu170b/</guid>
      <pubDate>Mon, 05 Feb 2024 03:09:25 GMT</pubDate>
    </item>
    <item>
      <title>[P]演示：使用 2MB 推理应用程序跨平台运行 StabilityAI 的 StableLM-2-Zephyr-1.6B</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aj6fdc/pdemo_run_stabilityai_s_stablelm2zephyr16b_across/</link>
      <description><![CDATA[       由   提交/u/smileymileycoin  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aj6fdc/pdemo_run_stabilityai_s_stablelm2zephyr16b_across/</guid>
      <pubDate>Mon, 05 Feb 2024 03:08:15 GMT</pubDate>
    </item>
    <item>
      <title>[D]opencv大学课程思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aj5uyc/d_opencv_university_courses_thoughts/</link>
      <description><![CDATA[你好，我正在学习深度学习，我已经完成DeepLearning.AI 的 DL 专业化，在各种 DL 应用程序中，计算机视觉似乎是最有趣的，我很好奇 opencv 的课程是否值得。 + 到目前为止我主要使用tensorflow，对于cv我想学习pytorch（opencv也有一门关于pytorch的课程）。感谢您的宝贵时间:)   由   提交 /u/Bobsthejob   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aj5uyc/d_opencv_university_courses_thoughts/</guid>
      <pubDate>Mon, 05 Feb 2024 02:38:32 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]关于PDP的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aj5jzh/discussion_question_on_pdp/</link>
      <description><![CDATA[部分依赖图是否处理了潜在的混杂因素？或者我是否必须在绘制它们之前单独处理它们？任何见解都会有所帮助。提前致谢。   由   提交/u/Goals755  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aj5jzh/discussion_question_on_pdp/</guid>
      <pubDate>Mon, 05 Feb 2024 02:22:47 GMT</pubDate>
    </item>
    <item>
      <title>基于PyTorch的Vision Transformers轻量级训练方案[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aj590d/pytorchbased_vision_transformers_lightweight/</link>
      <description><![CDATA[基于 PyTorch 的 Vision Transformers 轻量级训练解决方案 尊敬的人工智能研究人员和开发人员， 在现场机器学习和人工智能领域的视觉变压器（ViTs）因其在图像识别任务中的出色表现而受到广泛关注。然而，训练 ViT 模型通常需要大量的计算资源，这对计算能力有限的个人和机构构成了挑战。为了解决这个问题，我们推出了基于 PyTorch 的轻量级 ViTs 训练解决方案 - LKCA Mini ViTs Trainer，旨在使研究人员和开发人员能够在有限的资源条件下有效地训练 Vision Transformers 模型。 核心功能： 核心功能： h3&gt;  PyTorch实现：所有功能和模型均在PyTorch中实现，提供灵活性和易用性，允许用户轻松定制模型和训练流程。 单GPU训练能力：该方案专门针对ViT的训练过程进行了优化，可以在单2080Ti GPU上高效运行，甚至可以在4小时内完成模型训练。 &lt; strong&gt;支持主流小规模数据集：支持CIFAR-10、CIFAR-100、SVHN、Tiny ImageNet等数据集，使研究人员和开发人员能够在不同数据集上测试和验证ViTs模型的性能。&lt; /li&gt; 多样化的ViT模型选择：提供十余种不同的ViT模型变体，包括但不限于ViT、CaiT、CvT等，让用户根据需要选择合适的模型架构  用例： 此解决方案适合希望在小规模数据集上探索 ViT 模型的研究人员和开发人员，或开发机器的个人和团队在计算资源有限的环境中学习模型。 入门： 对于那些有兴趣了解更多信息或开始使用 LKCA Mini ViTs Trainer 的人，可以访问更多信息和访问代码资源通过访问 GitHub 存储库 https://github.com/CatworldLee/LKCA-MiniViTsTrainer 找到-Pytorch-CIFAR-TinyImageNet/tree/main。 我们希望这个基于PyTorch的轻量级ViTs训练方案能够帮助广大研究人员和开发人员克服计算资源限制，促进更便捷的应用Vision Transformers 技术在其研发工作中的应用。   由   提交 /u/Learningforeverrrrr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aj590d/pytorchbased_vision_transformers_lightweight/</guid>
      <pubDate>Mon, 05 Feb 2024 02:06:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] FastEmbed-rs 🦀 - Rust 库，为您的项目生成句子嵌入。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aj3kg0/p_fastembedrs_rust_library_to_generate_sentence/</link>
      <description><![CDATA[ 由   提交/u/code9855  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aj3kg0/p_fastembedrs_rust_library_to_generate_sentence/</guid>
      <pubDate>Mon, 05 Feb 2024 00:44:49 GMT</pubDate>
    </item>
    <item>
      <title>[R]赢回蒂芙尼：如何击败人工智能男友</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aj3c4j/r_winning_tiffany_back_how_to_defeat_an_ai/</link>
      <description><![CDATA[       由   提交 /u/TobyWasBestSpiderMan   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aj3c4j/r_winning_tiffany_back_how_to_defeat_an_ai/</guid>
      <pubDate>Mon, 05 Feb 2024 00:34:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 4080 与 7900XTX 上的机器学习有什么好的比较吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aj0dda/d_have_there_been_any_good_comparisons_of_machine/</link>
      <description><![CDATA[CUDA 长期以来一直是必经之路，但我听说 ROCm 最近确实取得了进步。我不确定我是否找错了地方，但我找不到这两张卡之间的任何比较，以确定尝试 AMD 卡而不是 NVIDIA 卡是否有任何价值。我看到的唯一比较是游戏性能，但我很好奇是否有任何基准测试在卡上运行模型以了解它们彼此之间的表现   由   提交/u/htii_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aj0dda/d_have_there_been_any_good_comparisons_of_machine/</guid>
      <pubDate>Sun, 04 Feb 2024 22:22:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有什么学习多智能体强化学习的好资源吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aiu3mn/d_any_good_resources_to_learn_multiagent/</link>
      <description><![CDATA[我知道今年出版了一本教科书《多智能体强化学习：基础与现代方法》。  我想知道是否还有其他好的资源（例如视频讲座或幻灯片）。非常感谢。   由   提交 /u/Fashism   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aiu3mn/d_any_good_resources_to_learn_multiagent/</guid>
      <pubDate>Sun, 04 Feb 2024 18:04:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] Chess-GPT，比 GPT-4 小 1000 倍，可以下 1500 Elo 国际象棋。我们可以直观地看到它的内部棋盘状态，并且它可以准确地估计游戏中玩家的 Elo 等级。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aisp4m/p_chessgpt_1000x_smaller_than_gpt4_plays_1500_elo/</link>
      <description><![CDATA[   gpt-3.5-turbo-instruct 的 Elo 等级为 1800，国际象棋看起来很神奇。但事实并非如此！一个参数小 100-1000 倍的法学硕士将在进行数百万局国际象棋比赛后学会如何玩 ELO 1500。 该模型仅经过训练来预测 PGN 字符串中的下一个字符 (1.e4 e5 2.Nf3 ...）并且从未明确给出棋盘状态或国际象棋规则。尽管如此，为了更好地预测下一个角色，它学习计算游戏中任何时刻的棋盘状态，并学习一系列不同的规则，包括将、将死、易位、过路、升级、固定棋子此外，为了更好地预测下一个角色，它还学习估计潜在变量，例如游戏中玩家的 Elo 评级。 我们可以可视化模型的内部棋盘状态，因为它是预测下一个字符。例如，在此热图中，左侧是真实白色棋子位置，中间是二进制探针输出，右侧是探针置信度梯度。我们可以看到该模型非常有信心，没有白棋子位于任一后排。 ​ https://preview.redd.it/dn8aryvdolgc1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s= 003fe39d8a9bce2cc3271c4c9232c00e4d886aa6 此外，为了更好地预测下一个角色，它还学习估计潜在变量，例如游戏中玩家的 ELO 评级。更多信息请参阅这篇文章： https:/ /adamkarvonen.github.io/machine_learning/2024/01/03/chess-world-models.html 代码在这里：https://github.com/adamkarvonen/chess_llm_interpretability   由   提交 /u/seraine   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aisp4m/p_chessgpt_1000x_smaller_than_gpt4_plays_1500_elo/</guid>
      <pubDate>Sun, 04 Feb 2024 17:06:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果 ICLR 口头论文与我的 ICML 2020 论文明显重叠但仍然被接受，我该怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aintst/d_what_should_i_do_if_an_iclr_oral_paper/</link>
      <description><![CDATA[如果我认为已接受的口头论文没有引用我之前发表的论文，我该怎么办？更重要的是，如果他们这样做了，他们的论文就没有什么新颖性了。提交ID是6795，我的论文可以在这里找到：https://proceedings.mlr.press/v119/nguyen20c。 html。你可以自己判断。   由   提交/u/hoang-nt  /u/hoang-nt  reddit.com/r/MachineLearning/comments/1aintst/d_what_should_i_do_if_an_iclr_oral_paper/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aintst/d_what_should_i_do_if_an_iclr_oral_paper/</guid>
      <pubDate>Sun, 04 Feb 2024 13:25:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我的时间序列是否太随机而无法预测？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aileah/d_is_my_timeseries_too_random_to_be_predicted/</link>
      <description><![CDATA[嗨，我有一个时间序列，我希望预测下一个值。输入数据是多变量，目标目前是单变量。 我的第一个策略当然是展平输入并通过单层神经网络（线性回归）运行它。然后我尝试添加更多层，使用不同的激活函数、dropout、批量归一化等，但是初始结果没有任何改善。查看预测的各个示例，到目前为止，所有模型基本上只是从最新的已知值开始，并趋向于数据集的整体平均值。 我的问题是，单层神经网络是否表现良好作为或比更多层更好，尝试更先进的技术（如 Transformer、TCN、LSTM）是否还有意义，或者这只是浪费时间？ 我在想如果添加的参数甚至再多一层或两层并不能带来任何改进，这表明要捕获的数据实际上几乎没有系统趋势，而且更先进的模型实际上只是矫枉过正。如果我错了，请纠正我。  如果有人对我如何进一步调查/分析该数据集有一些建议，我们也将不胜感激。有没有办法最终证明/表明更高级的模型无法在此数据集上工作？   由   提交 /u/KaptenKalmar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aileah/d_is_my_timeseries_too_random_to_be_predicted/</guid>
      <pubDate>Sun, 04 Feb 2024 10:56:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发布负面结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aikp5f/d_publishing_negative_results/</link>
      <description><![CDATA[我一直在从事一个机器学习研究项目，不幸的是，结果与我的假设不一致。我得到了负面结果。 虽然令人沮丧，但我相信分享这些结果具有很大的价值，因为假设本身依赖于合理的理论基础，而且结果并不是先验证据表明将会是负面的。 所以，我的问题是，负面结果可以在顶级机器学习会议（NeurIPS/ICLR/ICML/...）上发表吗？你们中有人遇到过类似的情况吗？您是如何解决这个问题的？您在著名会议上发表负面结果的努力是否成功了？   由   提交/u/Raskolnikov98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aikp5f/d_publishing_negative_results/</guid>
      <pubDate>Sun, 04 Feb 2024 10:09:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 苹果发布 MGIE！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aideah/r_apple_releases_mgie/</link>
      <description><![CDATA[      [ICLR&#39;24 Spotlight] 通过多模态大图像指导基于指令的图像编辑语言模型 MLLM引导的基于指令的图像编辑（MGIE）可以遵循用户指令来编辑图像论文：https://openreview.net/forum?id=S1RKWSyZ2Y 项目：https ://mllm-ie.github.io https://preview.redd.it/7abn9yflehgc1.png?width=3183&amp;format=png&amp;auto=webp&amp;s=9fc6c301f49ffaaf1c293c8f5925c603c8 c7dc24 代码/ checkpoint 也是开源的 🔥 Apple 官方仓库：https://github.com/apple/ml-mgie 带 Gradio 演示的仓库：https://github.com/tsujuifu/pytorch_mgie &lt; p&gt;https://preview.redd.it/hyqngv8nehgc1。 png?width=3736&amp;format=png&amp;auto=webp&amp;s=3a70483a7bea6e16500370cee5879e605fe7d51d   由   提交 /u/tsujuifu   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aideah/r_apple_releases_mgie/</guid>
      <pubDate>Sun, 04 Feb 2024 02:42:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>