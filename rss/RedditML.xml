<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 07 Dec 2023 01:00:40 GMT</lastBuildDate>
    <item>
      <title>[N] 所有 Google Gemini 视频合二为一</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ciwvl/n_all_google_gemini_videos_in_1_video/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ciwvl/n_all_google_gemini_videos_in_1_video/</guid>
      <pubDate>Thu, 07 Dec 2023 00:35:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 致力于 RAG？您应该评估它的性能，我们已经建立了一种方法来做到这一点。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ciet5/d_working_on_rag_you_should_be_evaluating_its/</link>
      <description><![CDATA[查看我们的新开源工具 Tonic Validate：https ://www.tonic.ai/validate  我们还一直在使用该工具来评估不同的 RAG 工具。关于 LangChain 与 Haystack 的最新文章可以在这里找到：https://www.tonic.ai/blog/rag-evaluation-series-validating-the-rag-performance-of-langchain-vs-haystack ​&lt; /p&gt; 请告诉我们您的想法，如果您正在从事 RAG 项目，我们很乐意听到！您如何衡量 RAG 系统性能？   由   提交/u/tombenom  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ciet5/d_working_on_rag_you_should_be_evaluating_its/</guid>
      <pubDate>Thu, 07 Dec 2023 00:10:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] Plexiglass：用于测试 DNN 和 LLM 中对抗性攻击的工具箱。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18chgfb/p_plexiglass_a_toolbox_for_testing_against/</link>
      <description><![CDATA[Plexiglass：用于测试 DNN 和 LLM 中对抗性攻击的工具箱。 大家好，我叫 Enoch，我是一位研究深度生成模型的研究员。 我不久前开始了这个名为 Plexiglass 的项目，该项目最初是作为 DCNN 对抗性研究的火炬工具箱。我现在正在重新启动它，作为测试 DNN 和 LLM 中对抗性攻击的工具箱。  想法是测试你的 DCNN 对抗对抗性攻击，例如法学硕士中的快速梯度符号方法和有毒提示。 我非常感谢您的贡献，我需要更多的开发人员，因为我太忙了，无法独自完成这一切🙏。 Repo 在这里：https://github.com/kortex -labs/有机玻璃   由   提交/u/kanxx030  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18chgfb/p_plexiglass_a_toolbox_for_testing_against/</guid>
      <pubDate>Wed, 06 Dec 2023 23:26:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 愚蠢的项目：使用变压器实现 MLP（哟，dawg...）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ceqz5/p_silly_project_implement_mlp_using_a_transformer/</link>
      <description><![CDATA[Transformers 严重依赖 MLP。据推测，LLM 可以回忆的事实存储在 MLP 中。 （例如，参见 ROME 论文。）这些 MLP 非常庞大。 例如考虑 GPT-Neo-350M。每个 MLP 有 1024 个元素的输入和输出层以及 4096 个元素的内层。这需要 2x1024x4096 = 4.2M 权重。整个模型有 24 个（每层一个），导致 MLP 使用 100M 权重。 然而这些 MLP 基本上只做 4096 点积来计算特征。数以百万计的权重只是为了计算 4096 点积并线性变换输入/输出，这似乎过多。 MLP 中的权重数量是输入元素数量的平方，因为每个内部元素都必须直接连接每个输入和输出元素。每个连接都很昂贵。我们可以做得更好吗？ 好吧，我们可以将 MLP 拆分为更小的 MLP。例如。将 1024 元素的输入向量划分为 4 256 元素的向量，并为每个块应用单独的 MLP。这样我们总共就有 4096 个内部特征，但权重数量减少了 4 倍！ 遗憾的是，这效果不太好，因为我们缺少“块”之间的交互。 &lt; p&gt;但是...有一种架构可以在令牌之间有效地路由信息...这就是变压器，对吧。 那么，我们可以将变压器放入 MLP 中吗？ （然后我们将在变压器内部的 MLP 内部有一个变压器。） 是的！有效吗？有点像。 我们可以制作一个旨在近似 MLP 的模块。我们将这种基于转换器的 MLP 近似称为 TransMLP。 为了了解该近似的效果如何，我们可以将其与其他近似进行比较。在本实验中，我的目标是逼近 GPT-Neo-350M 众多 MLP 之一。为了获取训练数据，我在 Brown 文本上运行 GPT 以捕获 MLP 输入和输出。 为了进行比较，我训练了正常的“GPTNeoMLP”在相同的数据上。这些 MLP 使用较小的内部中间层尺寸进行实例化。基础模型有 4096 个元素中间层，近似值有 2048 和 1024 个。 我们可以使用均方误差损失来比较近似值。对于零近似，我得到 2.6（这基本上是输出的均方）。  GPTNeoMLP 4096：...损失，840 万权重 GPTNeoMLP 1024：0.39 损失，2.1 M 权重 GPTNeoMLP 2048：0.31 损失，4.2M 权重 TransMLP：0.36 损失，2.9M 权重  所以 TransMLP 的损失接近到具有 2048 个特征的经典 MLP，同时权重更少。请注意，仅单个线性层需要 1M 权重，变压器本身只需要 1.9M 权重。 我不想对此进行全面评估，而是进行快速健全性检查：如果我们替换使用 TransMLP 的 GPT-Neo-350M 的正常 MLP，句子上的 GPT 损失从 2.965 增加到 2.9908（请注意，这不是 MSE 损失，而是交叉熵或类似的东西）。它仍然可以生成与基线模型一样好的文本。 所以，是的，我们可以将一个变压器放在 MLP 内部的变压器中...... 享受：https://colab.research.google.com/drive/1UIDXF_x_Y7QWMQrteGaNHQ7Y9S-ZgeoF   由   提交/u/killerstorm  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ceqz5/p_silly_project_implement_mlp_using_a_transformer/</guid>
      <pubDate>Wed, 06 Dec 2023 21:28:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是对洗牌的合理还是不合理的使用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18cag7q/d_is_this_a_reasonable_or_unreasonable_use_of/</link>
      <description><![CDATA[我不会分享我对该方法的看法，以防止人们的反应出现偏见。在朋友之间进行讨论，并且有兴趣收集更多意见，并且不想将其引向任何方向。 讨论的核心是是否采用这种方法，因为您正在整理所有患者的数据在 CV 之前，如果训练和测试折叠中的数据可能包含来自同一患者的窗口（尽管彼此不同），是否会引入不合理的偏差/乐观结果？ 用例：评估使用从连续数据窗口中派生的特征来确定主题的状况（二元分类）。 数据：  派生特征的数据是连续的从 20 个不同受试者历时 10 小时收集的数据源。 定义标签的数据与用于进行预测的数据具有相同的采样率。它们是同步收集的。 该功能集由以下部分组成：&gt; 20 个特征。 每个数据窗口都有一个关联的标签。 数据类别是平衡的。  建议的评估方法：随机播放所有患者的数据进行嵌套交叉验证 对人们的意见非常感兴趣！ ✌🏼✌🏼   由   提交/u/ConfusedLayer1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18cag7q/d_is_this_a_reasonable_or_unreasonable_use_of/</guid>
      <pubDate>Wed, 06 Dec 2023 18:24:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将我的 VAE 潜在分布从正态分布切换为分类分布，但我需要一种方法来替换高斯乘法运算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18caf50/d_switching_my_vaes_latent_distribution_from/</link>
      <description><![CDATA[所以我一直在重新实现一个具有循环潜在分布的 VAE。在每个新输入之后，使用编码器输出和当前潜在分布的高斯乘法来更新潜在分布。  模型没有学习到良好的表示，我知道最近的 Dreamer 模型从连续潜在状态切换到分类潜在状态，这提高了性能，所以我想尝试一下。 但是，对于分类分布，没有等价的高斯乘法。我决定对新旧分布参数进行加权平均，其中权重由分布的逆熵确定（因此它们或多或少根据“不确定性”代理进行加权）。我知道这只是一种启发式的方法，并没有任何可靠的数学推理来支持它。  有谁知道更好的方法来实现这一点，或者有人遇到过类似的情况吗？   由   提交 /u/SmeatSmeamen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18caf50/d_switching_my_vaes_latent_distribution_from/</guid>
      <pubDate>Wed, 06 Dec 2023 18:22:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自旋模型变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ca7zr/p_spinmodel_transformers/</link>
      <description><![CDATA[变压器的非平衡统计力学视角。 我们提出了一类基于矢量平均场动力学的变压器-旋转模型。我们的框架支持非对称耦合并产生残差、注意力和前馈项。 帖子： https://mcbal.github.io/post/spin-model-transformers 代码（JAX）：https://github.com/mcbal/spin-model-transformers   由   提交/u/mcbal2666  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ca7zr/p_spinmodel_transformers/</guid>
      <pubDate>Wed, 06 Dec 2023 18:14:23 GMT</pubDate>
    </item>
    <item>
      <title>我可以对合成数据集进行 DPO 训练吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c9z13/can_i_do_a_dpo_training_on_a_synthetic_dataset_d/</link>
      <description><![CDATA[我目前正在遵循 Hugging Face 模型 Zephyr 7B 的微调方法。他们在公共数据集上实现了两种微调方法，即 SFT 和 DPO。目前，我正在使用SFT微调7B模型，进展顺利。但是，我有一个问题，是否可以在由 GPT 综合生成的 DPO 数据集 上微调模型 - 3.5. 根据我的理解，DPO 应该接受同一模型生成的答案的培训。我想确认这一点，并询问是否有人以前尝试过这样的微调。    由   提交 /u/MustafaAlahmid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c9z13/can_i_do_a_dpo_training_on_a_synthetic_dataset_d/</guid>
      <pubDate>Wed, 06 Dec 2023 18:03:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM微调代码库的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c9fkp/d_recommendation_for_llm_finetuning_codebase/</link>
      <description><![CDATA[我对一种新的微调技术有一些想法，并希望将其与 LoRA 进行比较。您认为我应该使用哪些工具或代码库？快速搜索似乎表明 Hugging Face 是可行的方法，但我想知道是否有更好的替代方案（如果可能，请给出优点和缺点）。 提前感谢您的任何建议！&lt; /p&gt;   由   提交 /u/netw0rkf10w   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c9fkp/d_recommendation_for_llm_finetuning_codebase/</guid>
      <pubDate>Wed, 06 Dec 2023 17:41:03 GMT</pubDate>
    </item>
    <item>
      <title>[R]谷歌发布Gemini系列前沿机型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c6xio/r_google_releases_the_gemini_family_of_frontier/</link>
      <description><![CDATA[来自 Jeff Dean 的推文：https://twitter。 com/JeffDean/status/1732415515673727286 博客文章：https:// blog.google/technology/ai/google-gemini-ai/ 技术报告：https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf 有什么想法吗？没有太多“肉”在这个公告中！他们肯定担心其他实验室+开源从中学习。   由   提交/u/blabboy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c6xio/r_google_releases_the_gemini_family_of_frontier/</guid>
      <pubDate>Wed, 06 Dec 2023 15:52:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么仅解码器模型用于自回归生成而不是仅编码器模型？如果新标记尚不存在，因果掩码的值是多少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c498u/d_why_are_decoder_only_models_used_for/</link>
      <description><![CDATA[为什么还要费心使用因果掩码，看起来它只是破坏了有用的信息传输？我知道，如果你用它进行训练，你就无法在推理过程中轻松删除它而不降低质量，但为什么不直接训练编码器来猜测此时的下一个标记呢？    由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c498u/d_why_are_decoder_only_models_used_for/</guid>
      <pubDate>Wed, 06 Dec 2023 13:43:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 神奇的收获以及在哪里找到它们：关于任何预训练模型之间通用知识转移的存在和前景</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c1tve/r_fantastic_gains_and_where_to_find_them_on_the/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2310.17653 OpenReview：https:// /openreview.net/forum?id=m50eKHCttz 摘要：  训练深度网络需要各种设计决策，例如他们的架构、数据增强或优化。在这项工作中，我们发现这些训练变化导致网络从数据中学习独特的特征集。使用由在 ImageNet 等规范数据集上训练的数千个模型组成的公共模型库，我们观察到，对于预训练模型的任意配对，一个模型提取了另一个模型中不可用的重要数据上下文，而与整体性能无关。给定预训练模型的任意配对并且没有外部排名（例如由于数据隐私而单独的测试集），我们调查是否可以将这种“互补”转移到模型中。知识从一个模型转移到另一个模型而不降低性能——这项任务变得特别困难，因为额外的知识可以包含在更强、同等或更弱的模型中。然而，在与预训练模型配对无关的场景中促进稳健的迁移将解锁来自任何模型存储库的辅助增益和知识融合，而不受模型和问题细节的限制——包括来自较弱、性能较低的模型。因此，这项工作对这种通用知识转移的可行性进行了初步、深入的探索。在大规模实验中，我们首先揭示了标准知识蒸馏技术的缺点，然后通过数据分区提出了更通用的扩展，以便在几乎所有预训练模型之间成功传输，我们证明这也可以在无监督的情况下完成。最后，我们评估了基本模型属性的可扩展性和对成功的模型无关知识转移的影响。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c1tve/r_fantastic_gains_and_where_to_find_them_on_the/</guid>
      <pubDate>Wed, 06 Dec 2023 11:19:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大多数开源人工智能都发生在美国境外？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18by3wo/d_why_is_most_open_source_ai_happening_outside/</link>
      <description><![CDATA[我不认为这太双曲线。美国有 Meta，除此之外几乎没有什么，特别是与外部的相比。 我并不是说要在美国扣篮，我真的只是感到震惊。 &lt; strong&gt;中国：Yuan、Qwen、DeepSeek、Yi、XVERSE、Aquila、RWKV，都是当今顶级的法学硕士。 一打很棒的（顶级）多模式。顶级嵌入模型。 英国：稳定性 法国： Mistral 芬兰（？）： Lumi Poro 阿联酋： Falcon 俄罗斯：康定斯基 &lt; p&gt;美国：Meta 有 Llama 和其他一些好东西，Salesforce 有一些东西，“OpenAI”等。  是监管环境吗？是投资问题吗？是GPU短缺吗？大型科技公司是否挖走了并锁定了所有美国人才？ 有人有任何线索吗？ 编辑： 哇，我走出了大门。我的要求越来越合理。这里提到的所有模型都是经过预训练的模型。是的，美国社区可以进行微调，但这没有表达我的观点。昂贵的 OSS 工作正在美国境外进行。如果你说“那不是 OSS”，好吧，它仍然主要发生在美国境外。再说一遍，不是在美国扣篮，只是问一个问题，并希望看到更多的美国公司出现在 OSS 贡献者名单上。   由   提交 /u/BayesMind   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18by3wo/d_why_is_most_open_source_ai_happening_outside/</guid>
      <pubDate>Wed, 06 Dec 2023 06:45:18 GMT</pubDate>
    </item>
    <item>
      <title>Apple 发布“MLX” - Apple Silicon 的 ML 框架 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bwe19/apple_releases_mlx_ml_framework_for_apple_silicon/</link>
      <description><![CDATA[Apple 的 ML 团队刚刚在 GitHub 上发布了“MLX”。他们针对 Apple Silicon 的 ML 框架。 https://github.com/ml-explore/mlx CUDA 的现实替代方案？ MPS 已经非常高效...如果我们看到采用，这可能会变得有趣。 ​   由   提交 /u/LoadingALIAS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bwe19/apple_releases_mlx_ml_framework_for_apple_silicon/</guid>
      <pubDate>Wed, 06 Dec 2023 05:00:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>