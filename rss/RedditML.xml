<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Thu, 18 Jul 2024 18:20:19 GMT</lastBuildDate>
    <item>
      <title>[D] 我正在为几个任务训练视觉模型，然后我决定通过视觉提示将基础模型“串联起来”。这是纯粹的炒作吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6h0e8/d_i_was_training_vision_models_for_several_tasks/</link>
      <description><![CDATA[(视觉)提示和基础模型真的可以用于工业级应用吗？ 我正在“连接”基础模型（用于视觉），并慢慢意识到我实际上正在做视觉提示（在它们之间）。但是，除了这个关于从系统角度进行视觉提示的相当有趣的观点外，我没有找到太多关于这方面的信息。 有人使用或遵循过这条路线吗？    提交人    /u/btcmx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6h0e8/d_i_was_training_vision_models_for_several_tasks/</guid>
      <pubDate>Thu, 18 Jul 2024 17:27:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] ML 系统设计：450 个值得学习的案例研究（Airtable 数据库）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6gdsk/p_ml_system_design_450_case_studies_to_learn_from/</link>
      <description><![CDATA[大家好！想分享来自 100 多家公司的 450 个 ML 用例的数据库链接，这些用例详细介绍了 ML 和 LLM 系统设计。您可以按行业或 ML 用例进行筛选。 如果这里有人着手设计 ML 系统，我希望你会发现它很有用！ 数据库链接：https://www.evidentlyai.com/ml-system-design  免责声明：我是 Evidently 背后的团队成员，这是一个开源 ML 和 LLM 可观察性框架。我们整理了这个数据库。    提交人    /u/dmalyugina   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6gdsk/p_ml_system_design_450_case_studies_to_learn_from/</guid>
      <pubDate>Thu, 18 Jul 2024 17:01:17 GMT</pubDate>
    </item>
    <item>
      <title>[N] Fish Speech 1.3 更新：增强稳定性、情感和语音克隆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6g122/n_fish_speech_13_update_enhanced_stability/</link>
      <description><![CDATA[我们很高兴地宣布，Fish Speech 1.3 现在提供了增强的稳定性和情感，并且只需 10 秒 的音频提示即可克隆任何人的声音！作为开源社区的坚定倡导者，我们今天开源了 Fish Speech 1.2 SFT，并引入了自动重新排名系统。敬请期待，因为我们很快就会开源 Fish Speech 1.3！我们期待收到您的反馈。 Playground（DEMO）：http://fish.audio GitHub：fishaudio/fish-speech    提交人    /u/lengyue233   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6g122/n_fish_speech_13_update_enhanced_stability/</guid>
      <pubDate>Thu, 18 Jul 2024 16:46:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 训练 LLM 引用预训练数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6fxgj/r_training_llms_to_cite_the_pretraining_data/</link>
      <description><![CDATA[我们的工作被 COLM 接受，并认为值得在此分享： &quot;源感知训练实现语言模型中的知识归因&quot; TL;DR: 通常，LLM 在训练期间会学习很多东西，但不记得从哪里学到的。本文是关于教 LLM 从预训练数据中引用他们的知识来源。这可以使模型更透明、更容易理解和更可靠。我们提出了一个两步过程：1) 使用文档 ID 注入进行预训练和 2) 指令调整。第一阶段教模型将知识片段链接到特定的预训练文档。第二阶段教模型如何在生成答案时引用这些文档。 🔗 论文：https://arxiv.org/abs/2404.01019 代码：https://github.com/mukhal/intrinsic-source-citation    提交人    /u/moyle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6fxgj/r_training_llms_to_cite_the_pretraining_data/</guid>
      <pubDate>Thu, 18 Jul 2024 16:43:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 代理工作流程的人为干预</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e68up3/r_human_intervention_for_agentic_workflow/</link>
      <description><![CDATA[我最近探索了 OpenAGI 框架的一个新增功能：任务规划期间的人为干预。此功能允许自主 AI 代理从人类那里征求澄清或附加信息，从而提高任务准确性和效率。 我已将其集成到我的工作流程中，用于反馈和报告生成，结果令人印象深刻。与 crewAI 不同，任务规划准确性有时会下降，OpenAGI 的方法被证明更可靠。 我很想听听你的经验。 在 GitHub 上探索它：GitHub - github.com/aiplanethub/openagi    提交人    /u/trj_flash75   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e68up3/r_human_intervention_for_agentic_workflow/</guid>
      <pubDate>Thu, 18 Jul 2024 11:14:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 3090 上进行训练时出现异常行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e650gq/d_strange_behaviour_with_training_on_3090/</link>
      <description><![CDATA[我正在训练源分离模型，更具体地说，我正在微调一个模型。来自此 repo  问题是这样的：我尝试微调的原始检查点的 SDR 值约为 11。当我开始微调时（尽管批次大小只有 1，而原始批次大小为 16），第一个 epoch 完成后，我的 SDR 值为 0.0016 左右。然后下一个 epoch 大约是 3，然后下一个是 6，然后它逐渐上升到 6-7。 这不应该发生 - 从第一个 epoch 开始，SDR 就应该接近原始值（11）。 我为什么这么认为？该 repo 还允许您在没有训练的情况下验证 SDR 的检查点 - 当我再次验证 0.0016 SDR 检查点时，它告诉我 SDR 实际上大约是 11，就像它应该的那样。但在训练期间，它要小得多。 作者告诉我这可能是 Pytorch 的问题，但即使在最新版本上，问题仍然存在。不管怎样，我已经在云 A6000/A100/H100 上进行了完全相同的训练，问题不存在。从第一个 epoch 开始，SDR 值就完全正常了。 这只是 3090 不够用还是某处有错误？所有其他损失值也在正常范围内。    提交人    /u/lucellent   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e650gq/d_strange_behaviour_with_training_on_3090/</guid>
      <pubDate>Thu, 18 Jul 2024 06:53:40 GMT</pubDate>
    </item>
    <item>
      <title>[N] Tom's Hardware 评测技嘉本地 AI 训练产品 AI TOP</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e61utc/n_toms_hardware_reviews_gigabyte_local_ai/</link>
      <description><![CDATA[看起来很漂亮，可能对 ML 社区有帮助。评论在这里：https://www.tomshardware.com/tech-industry/artificial-intelligence/gigabyte-releases-ai-software-to-help-train-your-own-ai 产品页面在这里：https://www.gigabyte.com/WebPage/1079?lan=en    提交人    /u/SuperSimpSons   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e61utc/n_toms_hardware_reviews_gigabyte_local_ai/</guid>
      <pubDate>Thu, 18 Jul 2024 03:39:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] Spider2-V：多模式代理距离实现数据科学和工程工作流程自动化还有多远？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5qt1r/r_spider2v_how_far_are_multimodal_agents_from/</link>
      <description><![CDATA[多模式 AI 代理的新基准，专注于现实世界的 Dara 工程任务。 项目页面：链接，论文：链接，代码：链接。  TLDR：自主 LLM 代理无法取代数据工程师……目前如此。但至少我们可以跟踪进度 🫡 概述： 随着 AI 技术变得越来越先进，我们需要越来越复杂的基准来评估系统的质量和衡量进度。出现了一个独特的基准分支，专注于使用专业工具/应用程序和网站（参见WorkArena、WebArena、OSWorld）。 在 Spider2-V 项目中，正在创建一个基准来评估数据工程中的 AI 代理。它包含 494 个任务，涵盖整个工作周期：  数据仓库（Snowflake、BigQuery 等工具） 数据提取（例如 Airbyte） 数据转换（例如 dbt） 数据可视化（例如 Superset、Metabase） 数据编排（例如 Airflow、Dagster）  （以及心爱的 Excel 文件，因为谁能没有它们？） 如果您有数据工程经验，您就会明白这是一个庞大的集合，尽管它没有涵盖您可能遇到的所有解决方案。 准备每个任务平均需要 4 个小时，因此它们非常原子化，不需要很长的视野思考。任务分为三个难度等级：  简单（20%，不超过 5 步即可解决） 中等（63%，6-15 步） 困难（17%，16-40 步）  所有任务均基于 DE/DS 教程，由人工标注员从网络上获取。可以说它们代表了真实的用例。简单任务示例：  将当前 Google Drive 文件夹下的数据加载到打开的 BigQuery 数据集的新表 “data1” 中  或者中等难度的任务：  从 GitHub 安装 dbt-cloud-cli，并将二进制文件解压到与 dbt 项目 “analytics” 相同的文件夹中  为了解决任务，LLM 代理可以访问 IDE 和浏览器（已设置账户）。模型使用 pyautogui 生成 Python 代码以与虚拟机的 UI 交互，然后执行代码，并逐步重复该过程。  猜猜 GPT-4 完成了多少任务？ 只有 14%！这个数字似乎很低，但可以突出显示更成功的集群——40% 的简单任务和 25% 的数据可视化任务都得到了解决。 除了专有模型外，还测试了开放模型 (LLAMA 3 70B、Mixtral 8x7B)，但由于它们不是多模态的并且不接受图像作为输入，因此仅向它们显示了屏幕的文本描述。这大大降低了它们的指标——它们只解决了一小部分任务。然而，我们热切期待 LLAMA-3 405B，据传它是多模态的，将于 7 月 23 日发布。  我非常渴望看到 GPT-5 发布时发布的基准指标——然后我们拭目以待！押注下一代模型将解决多少百分比的任务！     由    /u/stalkermustang 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5qt1r/r_spider2v_how_far_are_multimodal_agents_from/</guid>
      <pubDate>Wed, 17 Jul 2024 19:20:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于稳定扩散中潜伏层的维度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5qszw/d_about_the_dimensions_of_latents_in_stable/</link>
      <description><![CDATA[您好，我对这个问题已经思考了一段时间了，希望您能解答我的疑惑。 鉴于潜在（稳定）扩散中的自动编码器经过训练可以产生与输入图像感知相似的潜在数据，作者选择 4x64x64 作为潜在数据的尺寸似乎很奇怪；为什么要添加通道？ 选择 3x64x64 会更合理，因为可以说自动编码器将学习将输入图像的每个通道映射到潜在数据中的通道，从而尽可能在潜在空间中保留感知相似性。 所以我想讨论的主题是：为什么选择 4 个通道的潜在数据？    提交人    /u/HumbBest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5qszw/d_about_the_dimensions_of_latents_in_stable/</guid>
      <pubDate>Wed, 17 Jul 2024 19:20:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 匹配医学图像中的分割区域</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5i610/p_matching_segment_areas_in_medical_images/</link>
      <description><![CDATA[      https://preview.redd.it/2p5lksh1z2dd1.png?width=597&amp;format=png&amp;auto=webp&amp;s=1995475c783500ab58e9564e140b8debdf7dc8f3 参考附图，我正在努力构建一个深度学习网络，该网络能够找出左图中哪个分割区域是与右侧区域 1（红色数字）匹配的身体部分。有人可以分享指向解决此挑战的地方的指针吗，或者无论如何问题的名称是什么，以便我可以搜索论文和代码？ 提前致谢，我也愿意合作，这是为了在心脏病的背景下解释人工智能。     提交人    /u/sladebrigade   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5i610/p_matching_segment_areas_in_medical_images/</guid>
      <pubDate>Wed, 17 Jul 2024 13:26:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 《ReFT：语言模型的表征微调》作者，本周五将在 Oxen.ai 论文俱乐部发表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5h1m8/d_author_of_reft_representation_finetuning_for/</link>
      <description><![CDATA[Arxiv 论文第一作者 Zhengxuan Wu 将与 Greg Schoeninger 一起参加本周五的 Oxen.AI 论文俱乐部，解释编辑表示如何比参数高效微调 (PEFT) 方法更好。https://lu.ma/oxen ReFT：语言模型的表示微调。 Greg，仅阅读摘要就有 3 个问题和 1 条评论。  “表示”到底是什么意思？即，本文所指的表示捕获了神经网络的哪一部分？ “任务特定干预”中的干预是什么意思？我以前没有听说过预训练或微调这个术语。 就 API 而言，本文的要点是否类似于这样：&quot;我们不会通过提高可嗅探输入和输出的保真度（深度）或广度来改进 RESTful API，而是通过直接更改所有现有输入和输出的代码核心来改进 API？&quot;  评论）摘要让这篇论文听起来很巫术。希望测试是苹果 :: 苹果。 期待您在星期五揭开神秘面纱，Greg。非常酷，论文的第一作者能加入进来，帮助解释和回答问题。 详情： https://lu.ma/oxen 7 月 19 日星期五，太平洋时间上午 10:00，东部时间下午 1:00，Zoom 上 论文：https://arxiv.org/pdf/2404.03592 感谢：感谢 Greg、u/FallMindless3563、Scott Howard u/sthoward 和 Oxen团队为我提供了一个 Easy 按钮并与社区分享您的知识，同时提供了很酷的工具来在 oxen.ai 上管理数据集。    提交人    /u/ReluOrTanh   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5h1m8/d_author_of_reft_representation_finetuning_for/</guid>
      <pubDate>Wed, 17 Jul 2024 12:32:41 GMT</pubDate>
    </item>
    <item>
      <title>[P]如何重新使用现有词汇来建立单词索引？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5bwq9/phow_do_you_reuse_an_existing_vocabulary_to_build/</link>
      <description><![CDATA[因此，我正在尝试训练一个用于股市预测的 ml 模型，我刚刚开始，所以现在它只是用来预测新闻文章是否与股市有关！因此，我成功地在数据上训练了模型，我必须将其转换为单词索引。因此，除了单词索引，我们还获得了一个词汇表，就像一本将单词与数字映射的词典。现在，我有一个测试数据集，如何使用相同的词汇表为测试集创建单词索引。创建不同的词汇表或单词索引只会破坏准确性？ 为测试集创建不同的单词索引和词汇表不会造成太大问题吗？如果会导致问题，我该如何使用现有的词汇表？我正在考虑合并两个数据集，然后从末尾省略测试集的长度！我觉得有比这更好的解决方案，请帮忙！ 抱歉，这是一个愚蠢的问题，我对此还是有点陌生​​。 token = Tokenizer() token.fit_on_texts(X) word_indices = token.texts_to_sequences(X) vocab = token.word_index max_len = max(max(i) for i in word_indices) word_indices_padded = pad_sequences(word_indices, maxlen=max_len, padding=&#39;post&#39;) word_indices_np_padded = np.array(word_indices_padded) y_train = np.asarray(y).astype(&#39;float32&#39;) model = Sequential([ Dense(16,activation=&#39;relu&#39;), Dense(16,activation=&#39;relu&#39;), Dense(1,激活=&#39;sigmoid&#39;）]）model.compile（optimizer=&#39;adam&#39;，loss=&#39;binary_crossentropy&#39;，metrics=[&#39;accuracy&#39;]）model.fit（word_indices_np_padded，y_train，epochs=10）;  这是我的上下文代码。 我的谷歌colab链接：https://colab.research.google.com/drive/1zwPKVwxtM2eoitISL9SnOwGiLj8hL6g6?usp=sharing    提交人    /u/Mastermind_308   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5bwq9/phow_do_you_reuse_an_existing_vocabulary_to_build/</guid>
      <pubDate>Wed, 17 Jul 2024 07:11:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 等变神经网络的新型正则化技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e58b7i/r_new_regularization_technique_for_equivariant/</link>
      <description><![CDATA[大家好， 我想分享一个我一直在研究的研究项目，它可能对那些训练机器学习模型的人有用。我正在收集更多数据并准备一篇论文，但与此同时，我想在这里分享这个想法，以获得一些反馈，看看它是否对其他人有帮助。 我使用 MIT 许可证发布它，我希望它被自由使用，但如果你在研究项目中使用它，请引用 GitHub。以下是我制作的一个非技术性的视频，用于展示这个想法： 项目概述 该项目引入了一个新的正则化项，旨在创建近似等变的神经网络。它的功能类似于通过随机转换来扩充您的数据，允许您教会您的模型如何对输入转换做出反应。 有关它的功能和使用方法的更多详细信息，请查看 GitHub 页面。 应用 此方法可应用于广泛的监督学习问题，包括：  图像和视频处理 音频处理 文本处理  以及某些无监督学习模型，如自动编码器。 我在强化学习方面的经验有限，但我对 RL 的潜在应用很感兴趣。 初步结果 虽然我的数据仍然有限，但我已经看到了某些任务的可喜改进。例如，在图像分割中，测试分数提高了几个百分点，在某些情况下，这种方法比传统的数据增强方法效果更好。我尝试过用 CNN 和预训练的视觉转换器来做这件事。使用预训练模型，最好在微调过程中将其应用于分类/分割头。 主要优势 与现有的等变 ML 技术相比，这种正则化方法有几个优势：  它支持不可逆变换。 它不需要特殊的模型架构。 您可以控制等变程度，这对于手写识别等任务至关重要，在这些任务中，模型应该对小旋转保持不变，但不应对大旋转保持不变。  很抱歉自我宣传，但我认为这是社区真正感兴趣的事情，我很高兴分享这个想法并听取您的想法和反馈。    提交人    /u/jjk23   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e58b7i/r_new_regularization_technique_for_equivariant/</guid>
      <pubDate>Wed, 17 Jul 2024 03:36:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 租用 GPU 的最佳地点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e562n1/d_best_places_to_rent_gpus_from/</link>
      <description><![CDATA[大家好， 我希望能够灵活地按需租用 GPU，而且当然不必支付很多费用。我一直在关注一些公司，例如 brev.Dev、runpod 和 fluidstack。我想知道你们是否使用其中任何一个或其他东西来运行工作负载     提交人    /u/OGbeeper99   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e562n1/d_best_places_to_rent_gpus_from/</guid>
      <pubDate>Wed, 17 Jul 2024 01:42:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>