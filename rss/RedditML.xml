<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 10 Feb 2024 00:54:58 GMT</lastBuildDate>
    <item>
      <title>[D] 是否有任何论文使用 GAN 投影到普通自动编码器的潜在空间？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1an2c1m/d_are_there_any_papers_which_use_a_gan_to_project/</link>
      <description><![CDATA[   嗨，我转发这篇文章是因为我对这个主题感兴趣，并且我想要更多采用相同想法的来源 https://www.reddit.com/r/MachineLearning/ comments/wdswt5/d_are_there_any_papers_which_use_a_gan_to_project/ 所以我们的想法是训练一个普通的自动编码器，然后在自动编码器创建的潜在空间上训练一个 GAN，你有这样的来源吗？  评论中的唯一来源是这个，我正在使用这篇文章的表示，以便您了解想法：https://chemrxiv。 org/engage/api-gateway/chemrxiv/assets/orp/resource/item/60c7455d567dfe9552ec4455/original/a-de-novo-molecular- Generation-method-using-latent-vector-based-generative-adversarial-network.pdf&lt; /a&gt; https:// Preview.redd.it/a5bxvfuxcnhc1.png?width=552&amp;format=png&amp;auto=webp&amp;s=dfc32064c484d41f1cc85aa78ebb638985ac5f16   由   提交 /u/Vielox   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1an2c1m/d_are_there_any_papers_which_use_a_gan_to_project/</guid>
      <pubDate>Fri, 09 Feb 2024 23:47:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有免费的AI实时背景去除吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1an2blr/d_is_there_any_ai_realtime_background_removal_for/</link>
      <description><![CDATA[我发现了一个名为“Robust Video Matting”的库/API这里 https://github.com/PeterL1n/RobustVideoMatting 但它似乎只适用于本地运行代码的离线视频。我想知道是否有任何包装器可以使其适用于来自网络摄像头的实时视频输入？ 或者是否有其他优质的开源替代方案可以实时删除网络摄像头背景？&lt; /p&gt;   由   提交 /u/thefreemanever   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1an2blr/d_is_there_any_ai_realtime_background_removal_for/</guid>
      <pubDate>Fri, 09 Feb 2024 23:47:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么门控线性网络消失了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1an20kq/d_why_did_gated_linear_networks_disappear/</link>
      <description><![CDATA[DeepMind 研究人员想出了这个。在使用在线学习时，尤其是在上下文强盗方法中，它应该超越现有的解决方案。   由   提交 /u/__A-R__   /u/__A-R__  reddit.com/r/MachineLearning/comments/1an20kq/d_why_did_lated_linear_networks_disappear/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1an20kq/d_why_did_gated_linear_networks_disappear/</guid>
      <pubDate>Fri, 09 Feb 2024 23:33:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] PLAPT：使用预训练 Transformer 进行蛋白质配体结合亲和力预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1an1a4k/r_plapt_protein_ligand_binding_affinity/</link>
      <description><![CDATA[PLAP 简介：使用预训练 Transformer 进行蛋白质配体结合亲和力预测。  预测蛋白质-配体结合亲和力对于药物发现至关重要，因为它可以有效识别候选药物。我们引入了 PLAPT，这是一种利用 ProtBERT 和 ChemBERTa 等预训练 Transformer 的迁移学习来高精度预测结合亲和力的新颖模型。我们的方法处理一维蛋白质和配体序列，利用分支神经网络架构进行特征集成和亲和力估计。我们通过对多个数据集进行验证来展示 PLAPT 的卓越性能，实现了最先进的结果，同时与现有模型相比，训练所需的计算资源显着减少。 您可以在 https://www.biorxiv.org/content/10.1101/2024.02.08.575577v1 &lt; /div&gt;  由   提交/u/Navvye  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1an1a4k/r_plapt_protein_ligand_binding_affinity/</guid>
      <pubDate>Fri, 09 Feb 2024 23:00:21 GMT</pubDate>
    </item>
    <item>
      <title>信仰与命运：变形金刚对组合性的限制 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amzb52/faith_and_fate_limits_of_transformers_on/</link>
      <description><![CDATA[     &lt; td&gt; https://arxiv.org/abs/2305.18654  摘要： Transformer 大语言模型 (LLM) 因其在需要复杂的多步骤推理的任务上的出色表现而备受赞誉。然而，这些模型同时在一些令人惊讶的微不足道的问题上失败了。这就引出了一个问题：这些错误是偶然的，还是表明存在更实质性的限制？为了揭开 Transformer LLM 的神秘面纱，我们研究了这些模型在三个代表性组合任务中的局限性——多位数乘法、逻辑网格难题和经典的动态规划问题。这些任务需要将问题分解为子步骤，并将这些步骤综合为精确的答案。我们将组合任务制定为计算图，以系统地量化复杂程度，并将推理步骤分解为中间子过程。我们的实证研究结果表明，变压器法学硕士通过将多步骤组合推理减少为线性子图匹配来解决组合任务，而不必培养系统的解决问题的技能。为了完善我们的实证研究，我们提供了关于抽象多步骤推理问题的理论论证，这些问题强调了自回归代的性能如何随着任务复杂性的增加而迅速衰减。 ​ ​ ​ https://preview.redd.it/a9ulmlfeomhc1.png?width=719&amp;format=png&amp;auto=webp&amp;s=7a5dd0f3effaaece09b9f8ff1dd1c69ba5ac0271 &lt; p&gt;&amp; #x200b; 编辑：Kevin Murphy、Francois Chollet、Vitaly Kurin 等人推荐了这篇论文（有些人非常高度评价）   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amzb52/faith_and_fate_limits_of_transformers_on/</guid>
      <pubDate>Fri, 09 Feb 2024 21:34:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 应用数学建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amxsqr/d_applied_math_advice/</link>
      <description><![CDATA[我正在努力决定我的博士学位的研究领域/课程。我的背景是计算数学，我的最终目标是在一家大型科技公司担任机器学习研究科学家。我已被两个应用数学博士课程录取。一个是在一所相当有名气的学校，有一位在优化方面发表了大量文章的作者（一些科学机器学习否则都没有真正关注机器学习），另一个是在一所不太有名气的学校，有人直接研究深度学习方法，在 ICML 上发表了一些出版物，神经IPS。我知道我想要一个博士学位，我真的对这两个研究领域的数学感兴趣，我更想知道什么会让我更适合在 DeepMind、Meta 等机构进行博士实习和/或工作，以及机器的优化研究学习是一个活跃的研究领域。欢迎任何关于如何找到拥有应用数学博士学位的公司之一的建议！   由   提交/u/hopefulpilot337  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amxsqr/d_applied_math_advice/</guid>
      <pubDate>Fri, 09 Feb 2024 20:29:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 交互式代理基础模型 - Microsoft 2024 - 开发通才、行动、多模式系统的有希望的途径！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amvzby/r_an_interactive_agent_foundation_model_microsoft/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2402.05929  摘要：  人工智能系统的发展正在从创建静态转变为、特定于任务的模型到动态的、基于代理的系统，能够在广泛的应用程序中表现良好。我们提出了一种交互式代理基础模型，它使用一种新颖的多任务代理训练范例来跨广泛的领域、数据集和任务训练人工智能代理。我们的训练范式统一了不同的预训练策略，包括视觉蒙版自动编码器、语言建模和下一步动作预测，从而实现了多功能且适应性强的人工智能框架。我们展示了我们的框架在三个不同领域的性能——机器人、游戏人工智能和医疗保健。我们的模型展示了其在每个领域生成有意义且与上下文相关的输出的能力。 我们方法的优势在于其通用性，利用各种数据源（例如机器人序列、游戏数据、大规模视频数据集和文本信息）进行有效的多模式和多任务学习。 &lt; strong&gt;我们的方法为开发通才、行动、多模式系统提供了一条有前途的途径。   https://preview.redd.it/cwl6ld2gzlhc1.jpg?width=1840&amp;format=pjpg&amp;auto=webp&amp;s=5963b8 c9452666b96e1285c03216179045f4b2fe&lt; /a&gt; https:// Preview.redd.it/u9nenp2gzlhc1.jpg?width=1826&amp;format=pjpg&amp;auto=webp&amp;s=5643d1ffcc9f31bf1a706559fbfc136b66bf1cfe https://preview.redd.it/254zpf2gzlhc1.jpg?width=1316&amp;format=pjpg&amp;自动=webp&amp;s= 0f30202307f5264c33b996ea8f7870f29233e907 https： //preview.redd.it/xwihaf2gzlhc1.jpg?width=639&amp;format=pjpg&amp;auto=webp&amp;s=f51d54a2edbc8737ad9c90506441df15521c3991    ;由   提交/u/Singularian2501   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amvzby/r_an_interactive_agent_foundation_model_microsoft/</guid>
      <pubDate>Fri, 09 Feb 2024 19:11:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 存储多 TB 图像数据集以供 PyTorch 使用的最佳实践</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amu9ei/d_best_practices_for_storing_multitb_image/</link>
      <description><![CDATA[大家好，  我正在处理一个中等规模的卫星图像数据深度学习数据集（~4.4 Tb）。目前，我将数据存储为 NPZ 文件。每个 NPZ 文件包含响应标签和图像的时间序列。  经过深入研究，似乎将数据存储在 HDF5 中可能是更好的选择，并且可以提高随机读取速度。  有人对管理大型数据集最佳实践的资源有建议吗？谷歌上出现的信息似乎无处不在（带有大量商业解决方案的广告）。    由   提交 /u/ppg_dork   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amu9ei/d_best_practices_for_storing_multitb_image/</guid>
      <pubDate>Fri, 09 Feb 2024 17:58:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 类似于 YOLO、MIT 或 Apache License 的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amtndm/d_models_similar_to_yolo_mit_or_apache_license/</link>
      <description><![CDATA[大家好， 有谁知道有什么类似于 YOLO 的模型吗？但基本上都是开源的？最近所有的YOLO模型都是GPL，不能用于商业应用（许可费太高了）。谢谢！   由   提交 /u/Odd_Background4864   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amtndm/d_models_similar_to_yolo_mit_or_apache_license/</guid>
      <pubDate>Fri, 09 Feb 2024 17:32:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于概率预测/分类的生成对抗网络（GAN）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amlozf/d_generative_adversarial_networks_gans_for/</link>
      <description><![CDATA[用于概率预测和分类的生成对抗网络 最近我对用于预测和分类的 GAN 感兴趣，而不是生成。我知道大多数关于 GAN 的研究都是关于生成新数据 - 例如：合成时间序列生成、深度伪造等。 我的理解是生成器最终会理解原始数据的潜在概率分布数据。另一方面，鉴别器只是将数据分类为真数据或假数据（二元分类）。 现在我试图在分类/预测时间序列的背景下理解这一点。该问题可以概括为：  给定一个时间序列（例如：股票的回报），我想预测下一个时间步长的回报。我想分类时只需要取它的sign()即可。  我的疑问是，训练完GAN后，我该如何进行推理？我要使用鉴别器吗？发电机？此外，我正在预测下一个时间步长的回报，这个概率预测如何？我可以获得分布作为输出吗？ 作为参考论文，您可以查找：https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4328302   由   提交 /u/LeHalfW   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amlozf/d_generative_adversarial_networks_gans_for/</guid>
      <pubDate>Fri, 09 Feb 2024 11:04:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你最喜欢的研究工具是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aml3w4/d_what_are_your_favorite_tools_for_research/</link>
      <description><![CDATA[这些是我个人最喜欢的： connectedpapers .com - 当您开始新的研究项目时，这是一个很棒的工具。从一篇相关论文开始，它会向您显示所有相关论文及其引用的图表。这让您可以很好地概述相关文献以及它们如何通过引用进行连接。 consensus.app - 人工智能用于研究的搜索引擎。您可以询问特定主题、相关论文等。如果您的论文中需要更多引用或想更好地了解相关作品，这是一个很好的工具。 paperparrot.ai - 这是一份个性化的研究论文时事通讯，每周根据您的兴趣向您发送一次最新论文的摘要。对于跟上新论文并且不错过您可能看不到的内容非常有用。 overleaf.com - 用于撰写研究论文或笔记的首选网络应用程序。您拥有版本控制，可以与多人协作，并且一切都是基于网络的。这是编写 LateX IMO 的最佳方式。 trello.com - 如果您的项目有多个协作者，这可以是有助于将事情组织起来并跟踪谁在做什么以及何时做什么。   由   提交 /u/Time-Sympathy724    reddit.com/r/MachineLearning/comments/1aml3w4/d_what_are_your_favorite_tools_for_research/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aml3w4/d_what_are_your_favorite_tools_for_research/</guid>
      <pubDate>Fri, 09 Feb 2024 10:23:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年流量正常化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amj8i4/d_normalizing_flows_in_2024/</link>
      <description><![CDATA[所有 SOTA 方法在特征解缠和图像生成质量方面是否已经过时了？ 2024 年流量标准化的状况如何？   由   提交 /u/BigDreamx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amj8i4/d_normalizing_flows_in_2024/</guid>
      <pubDate>Fri, 09 Feb 2024 08:06:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 具有累积金额的 Mamba</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amb3xu/d_mamba_with_cumulative_sums/</link>
      <description><![CDATA[Mamba 是一个带有数据的状态空间模型相关系数。它最初是通过关联扫描进行训练的，目前是pytorch 不直接支持，因此作者为其编写了自定义 cuda 内核（这具有内核融合的额外好处）。为了简化这一点，有人在一个文件中编写了 最小版本的 mamba，其中关联扫描操作被 for 循环取代，为了实现的简单性而牺牲了效率。 不过，我认为有一种方法可以在纯pytorch中实现mamba，并且不会损失太多效率，那就是使用累积和 pytorch 有效支持。此实现封装在我对最小 mamba 存储库的相当简单的 commit 中，它提供了大约 14 倍的加速最小的 for 循环实现（代码较少）。还通过与 for 循环实现的输出进行比较来验证其正确性。 高级思想基本上是“分解”循环。将原始并行扫描降低到两个累加和的比率，同时保留关联扫描相同的时间复杂度 O(n) 和并行效率 O(logn)。  &amp; #32；由   提交/u/dna961010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amb3xu/d_mamba_with_cumulative_sums/</guid>
      <pubDate>Fri, 09 Feb 2024 00:39:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 离开我的胸膛。我正在攻读机器学习博士学位，但我是个失败者。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1alxv3l/d_off_my_chest_im_doing_phd_in_ml_and_im_a_failure/</link>
      <description><![CDATA[我的机器学习博士学位已经过半了。 我很幸运，进入了一个很好的项目，尤其是在一个好的项目中。实验室的学生都是超级明星，毕业后会找到很好的工作。我不是他们中的一员。我有一本蹩脚的、技术性不高的出版物，我正在努力寻找一个在我的能力范围内可以解决的新问题。我已经很努力了。我在本科生和硕士期间一直在做研究，尽我所能 - 做项目、阅读论文、学习机器学习和数学课程、为教授撰写资助...... 事实是，我可以达不到产生新想法的水平。无论我多么努力，这都不是我的事。我想为什么。我开始怀疑 STEM 是否一开始就不是我的菜。我环顾四周，发现有些人的大脑只是“理解”了这一点。事情变得更容易。对我来说，这需要额外的努力和额外的时间。在本科期间，我可以更加努力、更长时间地学习。嗯，不是为了博士学位。尤其是在这个快节奏、拥挤的领域，我需要吸收新东西并快速发布。 我是一个冒名顶替者，这不是一种综合症。我快被抓了其他人都获得了多个实习机会等等。我到处都被拒绝。看来现在他们知道了。他们知道我没用。我想对我的顾问说这些，但他是如此的天才，以至于他无法理解普通人的想法。我所有的高级实验室伙伴都是全职工作人员，所以实际上我现在是实验室中最资深的。   由   提交 /u/rsfhuose   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1alxv3l/d_off_my_chest_im_doing_phd_in_ml_and_im_a_failure/</guid>
      <pubDate>Thu, 08 Feb 2024 15:10:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>