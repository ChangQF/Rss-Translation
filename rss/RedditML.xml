<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Thu, 20 Feb 2025 15:18:40 GMT</lastBuildDate>
    <item>
      <title>[d] DeepSeek 681亿美元的推理成本与超尺度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itys24/d_deepseek_681bn_inference_costs_vs_hyperscale/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我已经估计了deepseek的成本/性能681亿，这样：  huggingface Open DeepSeek博客报告了Config＆amp;性能= 32 H100的800TPS   100万代币= 1250S = 21（ish），分钟。 69.12万代币每天 租金32 H100的费用〜$ 80000 &lt;$ 80000 &lt;&lt; /p&gt; 每百万个代币= $ 37.33（80000/31天/69.12） 我知道这是非常乐观的（100％利用，没有支持等），但是算术是否有意义，并且通过您认为是否通过嗅探测试？还是我有明显的错误？  我猜这比诸如双子座的API型号高1000倍，并且这个差距使我想知道我是否很愚蠢  &lt;！ -  sc_on- &gt;＆＃32;提交由＆＃32; /u/u/sgt102     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1itys24/d_deepseek_681bn_inference_costs_vs_hyperscale/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itys24/d_deepseek_681bn_inference_costs_vs_hyperscale/</guid>
      <pubDate>Thu, 20 Feb 2025 13:44:05 GMT</pubDate>
    </item>
    <item>
      <title>[r] LLM跨语言幻觉是多少？关于野外LLM幻觉的多语言估计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itwsdl/r_how_much_do_llms_hallucinate_across_languages/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  跨30种语言估算幻觉的新工作。该论文带有跨度级幻觉检测测试数据集和（提示，参考）数据集，以评估各种主题的LLM幻觉。  纸： https://arxiv.org/abs/2502.12769  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/qadrishyaari     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itwsdl/r_how_much_do_llms_hallucinate_across_languages/</guid>
      <pubDate>Thu, 20 Feb 2025 11:55:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] SWE-LAN​​CER：Frontier LLM可以从现实世界中的自由软件工程中赚取100万美元吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itv4z7/r_swelancer_can_frontier_llms_earn_1_million_from/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我们介绍了Swe-Lancer，这是超过1,400个自由职业软件工程任务的基准，从UPWORK中，价值为100万美元，总计100万美元。支出。 SWE-Lancer涵盖了这两个独立的工程任务 - 从50美元的错误修复到$ 32,000的功能实现以及管理任务，其中模型在技术实施建议之间进行选择。独立任务通过经验丰富的软件工程师对端到端测试进行分级，而管理决策则根据原始雇用工程经理的选择进行评估。我们评估模型性能，发现边境模型仍无法解决大多数任务。为了促进未来的研究，我们开源统一的Docker图像和公众评估拆分，Swe-Lancer Diamond（此https url ）。通过将模型绩效映射到货币价值，我们希望SWE-Lancer能够对AI模型开发的经济影响进行更多的研究。  他们还在Github上发布了代码和数据集。   arxiv链接： [2502.12115] SWE-LAN​​CER：Frontier LLMS可以从现实世界中的自由式软件工程中赚取100万美元？ /a&gt;   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/hiskuu     [links]   &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1itv4z7/r_swelancer_can_frontier_frontier_frontier_llms_earn_1_million_million_from//]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itv4z7/r_swelancer_can_frontier_llms_earn_1_million_from/</guid>
      <pubDate>Thu, 20 Feb 2025 10:03:55 GMT</pubDate>
    </item>
    <item>
      <title>[R]本地稀疏注意：硬件一致且本地可训练的稀疏注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itutpg/r_native_sparse_attention_hardwarealigned_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    长篇小说建模对于下一代语言模型至关重要，但是标准注意机制的高计算成本却带来了重大的计算挑战。稀疏的注意力为提高效率的方向提供了有希望的方向，同时保持模型功能。我们提出了NSA，这是一种本地可训练的稀疏注意机制，将算法创新与硬件一致的优化相结合，以实现有效的长篇文化建模。 NSA采用了动态的分层稀疏策略，将粗粒的令牌压缩与精细的令牌选择相结合，以保持全球环境意识和局部精度。我们的方法通过两个关键创新进行了稀疏注意设计：（1）我们通过算术强度平衡算法设计实现了实质性的加速，并对现代硬件进行了优化。 （2）我们启用端到端培训，在不牺牲模型性能的情况下减少预处理的计算。如图1所示，实验表明，使用NSA预测的模型维持或超过了一般基准，长篇下说任务和基于指导的推理的全部注意力模型。同时，NSA在解码，向前传播和向后传播的64k长度序列上充分关注实现了实质性的加速，从而在整个模型生命周期中验证了其效率。   有趣的论文在训练过程中提高了有趣的论文。以及DeepSeek的LLMS的推论。   arxiv链接： [2502.11089]本地稀疏注意：硬件 - 与硬件相协调且本质上可训练的稀疏注意力     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/hiskuu     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itutpg/r_native_sparse_attention_hardwarealigned_and/</guid>
      <pubDate>Thu, 20 Feb 2025 09:41:38 GMT</pubDate>
    </item>
    <item>
      <title>[R]通过统计流动流进行语言建模的几何连续扩散</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itsx7f/r_geometric_continuous_diffusion_for_language/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这里的关键贡献是将语言生成建模为统计歧管上的连续扩散过程，而不是使用基于离散令牌的扩散。这允许语言状态与更有效的生成之间的更平滑的过渡。 主要技术要点： - 使用Riemannian几何形状在代币上创建概率分布的连续流形 - 实现专业的神经体系结构，学会学会导航此歧视空间。 - 采用受控的扩散路径以进行更精确的生成 - 在抽样中实现显着加速（比离散基线快2-3倍） - 报告改进了多种语言基准的困惑得分 标准基准的结果：-Wikitext -103：16.8困惑（vs 18.2基线） -  C4：14.9 Perplexity（vs 15.8基线）离散模型 - 记忆使用量减少了约30％ 我认为这种方法可能会有意义地影响语言通过提供更优雅的处理文本生成方式来建模开发。连续的性质可以更好地匹配语言含义的实际流动方式，并有可能导致更多的自然产出。  我认为未来的主要挑战是： - 在保持较大模型的同时保持多种模型 - 有效地处理非常长的序列 - 桥接理论和实施生产系统&lt; /p&gt;  TLDR：使用统计流形的语言建模的新型连续扩散方法。显示出改善的困惑和生成速度与离散模型。有希望的方向更有效，更自然的语言生成。  完整的摘要在这里&lt; /a&gt;。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itsx7f/r_geometric_continuous_diffusion_for_language/</guid>
      <pubDate>Thu, 20 Feb 2025 07:24:47 GMT</pubDate>
    </item>
    <item>
      <title>[D]与XGBoost更好地分布在GBM和HistGBM中的Shap贡献更好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1its6tv/d_shap_contribution_better_distributed_in_gbm_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，我正在建立一个信用风险模型，我们正在培训XGBoost，GBM和HistGBM上的数据。我们的发现之一是，Xgboost中变量的外形贡献非常倾斜，其中第一个变量具有31％的幅度重要性，而在其他两种算法中，前几个变量的变量显着较小，分布式变形的幅度明显较小，更好的分布形状重要性，例如11％，10.5％，10％，9％等。 ，不仅如此，即使模型性能在GBM中也比XGBoost更好。  我找不到可能发生这种情况的实质原因。如果有人有解释的话，很想听听您的想法。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/lietechnical1662     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1its6tv/d_shap_contribution_better_distributed_in_gbm_and/</guid>
      <pubDate>Thu, 20 Feb 2025 06:36:17 GMT</pubDate>
    </item>
    <item>
      <title>[p]萨卡（Saka）释放了库德纳（Cudiner）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itqrgl/p_sakana_ai_released_cuda_ai_engineer/</link>
      <description><![CDATA[在CUDA-GEANDERER/  它将火炬转换为CUDA内核。  这是步骤： 阶段1和2（转换和翻译）： AI CUDA工程师首先将Pytorch代码转换为功能cuda内核。我们已经观察到初始的运行时改进而没有明确定位这些。  阶段3（进化优化）：受生物进化的启发，我们的框架利用了进化优化（&#39;“&gt;生存”优点’），以确保只生产最好的CUDA内核。此外，我们介绍了一种新颖的内核交叉促进策略，以互补的方式结合多个优化内核。  阶段4（创新档案）：，文化进化如何影响我们的人类智能借助我们祖先到几千年的文明，AI CUDA工程师还利用了从过去的创新和发现中学到的知识（第4阶段），第4阶段），从已知的高性能CUDA内核的血统中构建创新档案，该档案使用以前的踏板石来实现进一步的翻译和性能增长。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/preams_delay_3701      [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itqrgl/p_sakana_ai_released_cuda_ai_engineer/</guid>
      <pubDate>Thu, 20 Feb 2025 05:07:05 GMT</pubDate>
    </item>
    <item>
      <title>[d]谢谢您对Tensorpool的测试！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itml16/d_thank_you_for_your_beta_testing_of_tensorpool/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   tldr;谢谢你，并免费为你们提供GPU奖学金：） 大家好！我们只想感谢这个SubredDit在此处的上一篇文章中获得的压倒性支持。我们想让大家知道，您的反馈使我们昨天可以进行官方的YC发布。  https://www.ycombinator.com/launches/launches/mq0-tensorpool---tensorpool--------------------------------------参最常使用的gpus   特别感谢此subreddit，我们将向在接下来的几周内为我们提供大量反馈的用户提供20美元的GPU积分。只需通过[ team@tensorpool.dev ]（mailto： team@tensorpool。 dev ）您看到了这篇文章。我们还默认情况下还会赠送$ 5/周。 再次感谢，如果您有兴趣了解Tensorpool，则可以在此处查看我们： github.com/tensorpool/tensorpool    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tensorpool_tycho     [links]      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1itml16/d_thank_you_for_your_your_your_your_your_teste_testing_of_tensorpool/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itml16/d_thank_you_for_your_beta_testing_of_tensorpool/</guid>
      <pubDate>Thu, 20 Feb 2025 01:27:56 GMT</pubDate>
    </item>
    <item>
      <title>[d]证明ddpm后部有正确的边缘</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itlp1d/d_proof_that_ddpm_posterior_has_correct_marginal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我想知道是否有证据表明DDPM后验有x  t〜p（x_t | x_0）和最佳噪声预测器e [epsilon_t | x_t]边缘化到正确的x_0条件分布p（x  {t-1} | x_0）。  这种证明是否存在？我试图更好地理解DDPM，并且在几篇论文中看到了这个结果，但我无法证明这一点。很容易进入边缘化步骤（这是高斯人的卷积），但是我看不出e [epsilon  t | x_t]术语在p（x 的最终统计数据中都消失了{t-1} | x_0）表明分布是正确的。提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1itlp1d/d_proof_that_that_that_that_ddpm_posterior_has_has_chcorrect_marginal/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1itlp1d/d_pofor_that_that_that_ddpm_posterior_has_correct_marginal/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itlp1d/d_proof_that_ddpm_posterior_has_correct_marginal/</guid>
      <pubDate>Thu, 20 Feb 2025 00:46:02 GMT</pubDate>
    </item>
    <item>
      <title>[d]检索增强一代的未来是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itl38x/d_what_is_the_future_of_retrieval_augmented/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  抹布令人怀疑。关于使用传统的IR技术为模型获取上下文的某些东西感觉到。这让我想起了Netflix在互联网足以流式传输之前必须邮寄DVD。 我无法想象以后使用数据库的LLMS。为什么不在推理期间而不是以前的检索呢？例如。如果数据库直接嵌入了KV缓存中，则可以像其他所有内容一样通过梯度下降来检索。至少对我来说，这似乎比使用（低精确）嵌入搜索来收集上下文并将其塞入提示中。 。有 Lost-In-in-the-the-the-Middle效果，和上下文污染的风险，即使所有这些都会降低性能，即使所有这些都会降低性能还存在正确的上下文。推理性能也随着更多上下文的添加。   无论未来如何，我的感觉是抹布将在几年内变得过时。大家怎么想？ 编辑： DeepMind的复古和 self-rag 似乎相关。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/jsonathan     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itl38x/d_what_is_the_future_of_retrieval_augmented/</guid>
      <pubDate>Thu, 20 Feb 2025 00:17:48 GMT</pubDate>
    </item>
    <item>
      <title>[D]在2025年从张力流到Pytorch的过渡：生态系统问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itbqwn/d_transitioning_from_tensorflow_to_pytorch_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  自2017年以来使用Tensorflow后，我终于将切换到Pytorch。尽管核心框架非常相似（原始的Pytorch代码更改是最小的），但我发现最大的区别是工具和附加组件的生态系统。 到目前为止，我已经遇到了：    hydra-用于配置管理和实验跟踪  pytorch Lightning-似乎抽象的类似凯拉斯的包装器Berierplate   MMDetection-对于对象检测任务  对于那些进行过类似过渡或经验丰富的Pytorch用户的人：您的首选堆栈是什么？您如何构建训练循环？您发现哪些工具（或其他工具）特别有价值或值得避免？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rsandler     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itbqwn/d_transitioning_from_tensorflow_to_pytorch_in/</guid>
      <pubDate>Wed, 19 Feb 2025 17:52:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] Scikit指纹 - 用于计算分子指纹和分子ML的库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it9xxq/p_scikitfingerprints_library_for_computing/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   tl; dr我们写了一个用于计算分子指纹＆amp＆amp;相关任务与Scikit-Learn接口兼容， scikit-fingerprints 。     是分子指纹吗？  用于矢量化学分子的算法。分子（原子和键）进入，特征向量熄灭，准备分类，回归，聚类或任何其他ML。这基本上将图形问题变成了表格问题。分子指纹非常有效，并且是ML分子ML，药物设计和其他化学应用的主食。了解更多在我们的教程中/strong&gt;    - 完全兼容Scikit-Learn，您可以通过解析来构建完整的管道分子，计算指纹，训练分类器并部署它们  -35指纹，是开源Python生态系统中最大的数量   - 许多其他功能，例如。分子过滤器，距离和相似性（在Numpy/Scipy阵列上工作），分裂数据集，超参数调谐以及更多   - 基于RDKIT（标准化学化形式图库），可与其整个生态系统互操作  p&gt;  - 可与PIPI的PIP一起安装，并带有文档和教程，易于启动   - 设计良好，带有高测试覆盖范围，代码质量工具，CI/CD和一组维护者  为什么不gnns？  图形神经网络仍然是一个新的事情和他们的预训练特别具有挑战性。我们已经看到了很多有趣的模型，但是在实用的药物设计问题中，它们仍然经常表现不佳（例如，参见我们的肽基准）。 gnns可以是与指纹结合，和分子指纹可以是用于预读。例如，夹具模型（ICML 2024）实际上使用指纹用于分子编码，而不是GNNS或其他预处理的模型。 ECFP指纹仍然是许多（甚至大多数分子属性预测/QSAR问题）的主食，也是一个很好的解决方案。  有些背景    i &#39;在计算机科学上获得博士学位，图形和分子的ML。我的硕士论点是关于分子特性预测的，我希望分子指纹作为实验的基准。原来，他们真的很棒，实际上胜过GNN，这很令人惊讶。但是，使用它们确实是不便的，我认为许多ML研究人员由于用途而省略了它们。因此，我受够了，得到了一群学生，我们为此写了一个完整的图书馆。该项目已经开发了大约两年，现在我们拥有一个完整的研究小组，正在研究带有Scikit指纹的开发和实际应用。您还可以在SoftwareX中阅读我们的论文（开放访问）： https://www.sciendirect.com/science.com/science/article/article/article/article/article/article/article/article/article/article/ /pii/s2352711024003145 。  了解更多  我们有完整的文档，也有教程和示例， https://scikit-fingerprints.github.io/scikit-fingerprints/ 。 We also conducted introductory molecular ML workshops using scikit-fingerprints: https://github.com/j-adamczyk/molecular_ml_workshops.  我很高兴回答任何问题！如果您喜欢该项目，请在Github上给它一颗星星。我们欢迎贡献，拉请求和反馈。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/qalis     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it9xxq/p_scikitfingerprints_library_for_computing/</guid>
      <pubDate>Wed, 19 Feb 2025 16:42:32 GMT</pubDate>
    </item>
    <item>
      <title>[r]扩散是解决高效RNN的解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it790b/r_diffusion_is_the_solution_for_efficient_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我表明扩散核捕获全局依赖性，并且具有复发结构的简单扩散内核在更少的参数和flops中优于变形金刚。    https://arxiv.org/abs/2502.12381      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1it790b/r_diffusion_is_is_solution_solution_solution_for_for_ffidice_and/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it790b/r_diffusion_is_the_solution_for_efficient_and/</guid>
      <pubDate>Wed, 19 Feb 2025 14:51:24 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会领导禁止。 鼓励其他人创建新帖子，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。   元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iqiy4x/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1ilhw29/d_simple_questions_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>