<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sun, 10 Mar 2024 18:14:25 GMT</lastBuildDate>
    <item>
      <title>[R] OpenAI：JSON 模式与函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbgky4/r_openai_json_mode_vs_functions/</link>
      <description><![CDATA[       由   提交/u/JClub  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbgky4/r_openai_json_mode_vs_functions/</guid>
      <pubDate>Sun, 10 Mar 2024 18:01:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 元模拟探索：人工智能在生成代理的模拟世界中的出现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbdrgg/r_metasimulation_exploration_ai_emergence_within/</link>
      <description><![CDATA[ 由   提交 /u/ausderh00d   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbdrgg/r_metasimulation_exploration_ai_emergence_within/</guid>
      <pubDate>Sun, 10 Mar 2024 16:03:38 GMT</pubDate>
    </item>
    <item>
      <title>[P]寻求SketchCode项目推进指导-YOLOV8培训完成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbdkqo/p_seeking_guidance_for_advancing_sketchcode/</link>
      <description><![CDATA[Hello👋 我一直在致力于一个名为 SketchCode 的令人兴奋的项目，旨在利用深度学习来改变手绘将网站模型转换为功能性 HTML/CSS 代码。我在手绘草图的自定义数据集上成功训练了 YOLOV8 模型，该项目已经达到了一个里程碑。 以下是该项目的非常简化的细分：  图像理解：模型分析手绘草图，识别各个 UI 组件。 序列生成： HTML 代码生成被视为语言翻译任务。该模型将视觉元素转换为相应的 HTML 代码片段。  技术细分：  数据集：我使用了一个数据集可用的手绘草图  。 YOLOV8 训练：我使用 Ultralytics 库对 YOLOV8 模型进行了 10 个 epoch 的训练。（使用 GPU 而不是 CPU，并对其进行了 50 个 epoch 的训练）  但是，我目前陷入困境并寻求后续步骤的指导。培训输出看起来很有希望，但我不确定下一步该往哪里走。 如果您能提供有关我下一步应该关注的内容的见解、建议或推荐，我将不胜感激。无论是改进模型、改进数据集还是整合其他技术，您的专业知识都是无价的。 Upvote1Downvote0commentsShare    由   提交/u/ClassicallyLost_88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbdkqo/p_seeking_guidance_for_advancing_sketchcode/</guid>
      <pubDate>Sun, 10 Mar 2024 15:55:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 硅群体的智慧：LLM 集成预测能力可与人类群体的准确性相媲美</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbb69f/r_wisdom_of_the_silicon_crowd_llm_ensemble/</link>
      <description><![CDATA[在一篇新论文中，研究人员证明，法学硕士的集合可以在预测方面达到人类水平的表现，有可能取代大规模、昂贵的人类预测的需求 要点：  法学硕士可以通过汇总不同模型的预测来实现人类水平的预测精度 这种“硅的智慧”人群”这种方法与行之有效的“群体智慧”相似。  在研究 1 中，12 名法学硕士组成的团队在 3 个月内的 31 个二元问题上的表现显着优于基线，并与 925 名人类预测者进行了匹配 在研究 2 中，提供人群预测将个人 LLM（GPT-4 和 Claude 2）预测提高了 17-28%，但简单地平均机器和人类预测甚至更好  研究结果表明，组织可以获得高- 通过利用 LLM 集成进行高质量、具有成本效益和可扩展的预测，有可能使数据驱动的决策在各个领域更容易实现。 但是，该研究有一些局限性：它侧重于短期对于二元问题，法学硕士表现出偏差和校准不良，并且随着训练数据过时，其准确性可能会降低。 TLDR：像人类一样，法学硕士表现出“群体的智慧”。影响。一群“人群”的法学硕士与一群人类一样擅长预测。 更多详细信息请点击此处。 Arxiv 论文：https://arxiv .org/pdf/2402.19379.pdf   由   提交 /u/Successful-Western27    reddit.com/r/MachineLearning/comments/1bbb69f/r_wisdom_of_the_silicon_crowd_llm_ensemble/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbb69f/r_wisdom_of_the_silicon_crowd_llm_ensemble/</guid>
      <pubDate>Sun, 10 Mar 2024 14:08:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024年，强化学习的最新趋势是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbawez/d_in_2024_what_are_the_latest_trends_on_rl/</link>
      <description><![CDATA[嗨， 这些天我正在研究决策转换器。 有争议的，同时试图找到最重要的论文，我注意到强化学习领域似乎没有发生太多事情。我注意到研究的重点是优化 Transformer 和训练巨大的语言和视觉模型（被视为监督模型）。这是强化学习领域的新大事吗？ 强化学习的最新趋势是什么？   由   提交/u/__Julia  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbawez/d_in_2024_what_are_the_latest_trends_on_rl/</guid>
      <pubDate>Sun, 10 Mar 2024 13:55:41 GMT</pubDate>
    </item>
    <item>
      <title>[N] 🚀 DIAMBRA 与 Hugging Face 合作推动强化学习研究和采用！ 🚀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbaey1/n_diambra_teams_up_with_hugging_face_to_push/</link>
      <description><![CDATA[       由   提交/u/DIAMBRA_AIArena   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbaey1/n_diambra_teams_up_with_hugging_face_to_push/</guid>
      <pubDate>Sun, 10 Mar 2024 13:31:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年用于机器学习的 AMD 卡？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bb9ylx/d_amd_cards_for_machine_learning_in_2024/</link>
      <description><![CDATA[AMD 和 AI 的状况如何？我想知道 AMD 和 Nvidia GPU 之间的性能差异有多大，以及 7600xt 是否充分支持 pytorch 和 TensorFlow 等机器学习库。上次我听说 AMD 卡可以支持 ROCm，但存在不一致、软件问题以及速度慢 2 - 5 倍的问题。 就个人而言，您会选择 rx7600 而不是 4060 吗？    由   提交 /u/AtomicPiano   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bb9ylx/d_amd_cards_for_machine_learning_in_2024/</guid>
      <pubDate>Sun, 10 Mar 2024 13:08:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] 表格数据上分类器的准确率排序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bb9bwx/p_accuracy_ranking_of_classifiers_on_tabular_data/</link>
      <description><![CDATA[宣布Predirank；该项目根据分类器在一系列数据集中的准确性对分类器进行排名。主要重点是 scikit-learn 库中的分类器及其在流行表格数据集上的应用。 https://github .com/c4pub/predirank 显然，生成的排行榜仅供参考；不可能有一个明确的排名。 该项目中使用的数据集来自论文中使用的 UCI 数据集的选择：  Fernandez-Delgado, Manuel ，等人。 “我们需要数百个分类器来解决现实世界的分类问题吗？” 《机器学习研究杂志》15.1 (2014)。  可以通过编辑提供的示例来自定义数据集和分类器的列表。 那么，排名是否已更改随着时间的推移“浅”分类器？ “随机森林”根据 2024 年 3 月 5 日运行的快照，仍然站在领奖台上： ------------------------ ---------------------------------------------------------- - - - -总排名得分 无排名 总平均 stddev excpt 分类器 ---------------------------------------- ---------------------------- 1 0.8166353383458647 0.1498 0 CatBoostClassifier 2 0.7868421052631579 0.1641 0 ExtraTreesClassifier() 3 0.7769736842105264 0.1495 0 RandomForestClassifier() 4 0.713753 1328320802 0.1940 0 XGBClassifierWrap({}) 5 0.7120300751879699 0.1684 0 MLPClassifier() 6 0.6983709273182958 0.1713 0 SVC() 7 0.6981516290726817 0.2161 0 HistGradientBoostingClassifier() 8 0.6960839598997494 0.1783 0 GradientBoostingClassifier() 9 0.6804511278195489 0.1533 0 LogisticRegression() 10 0.6596491228070176 0.2126 27 LogisticRegressionCV() 11 0.6431 70426065163 0.1776 0 BaggingClassifier() 12 0.6278822055137845 0.1866 0 DeodelSecond({}) 13 0.6114974937343358 0.1925 0 GaussianProcessClassifier() 14 0.6111842105263158 0.179 5 2 CalibratedClassifierCV() 15 0.6038533834586466 0.1826 0 LinearSVC() 16 0.6016604010025063 0.2117 0 LinearDiscriminantAnalysis() 17 0.6010651629072682 0.2105 0 RidgeClassifierCV( ) 18 0.5890664160401002 0.2092 0 RidgeClassifier() 19 0.5388471177944862 0.1711 0 KNeighborsClassifier() 20 0.4980889724310777 0.2192 0 DecisionTreeClassifier() 21 0.488753 1328320802 0.2309 0 AdaBoostClassifier() 22 0.4815476190476190 0.1806 0 DeodataDelangaClassifier({}) 23 0.4800125313283208 0.2125 0 LabelSpreading() 24 0.479636591478 6967 0.2163 0 标签传播() 25 0.4579573934837093 0.1606 0 SGDClassifier() 26 0.4277568922305764 0.3348 160 NuSVC() 27 0.4213032581453634 0.2452 25 二次判别分析() 28 0. 4184210526315789 0.2234 0 伯努利NB() 29 0.4106203007518797 0.2292 0 高斯NB() 30 0.4087406015037594 0.1677 0 被动主动分类器() 31 0.4010651629 072682 0.1717 0 ExtraTreeClassifier() 32 0.3893170426065163 0.1468 0 感知器() 33 0.3711152882205514 0.2105 0 最近中心() 34 0.1910401002506265 0.1988 0 GaussianMixture() 35 0.19104010 02506265 0.1988 0 BayesianGaussianMixture() 36 0.1510338345864661 0.1094 0 &lt;&lt;&lt;随机基线&gt;&gt;&gt; 37 0.0685150375939849 0.0320 0 OneClassSVM() 38 0.0526002506265664 0.1104 381 MultinomialNB() 39 0.0442669172932330 0.1016 403 RadiusNeighborsClassifier() ----------------------------- ---------------------------------------   .   由   提交/u/eppursim1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bb9bwx/p_accuracy_ranking_of_classifiers_on_tabular_data/</guid>
      <pubDate>Sun, 10 Mar 2024 12:34:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 进入未知：自学习大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bb8bxo/r_into_the_unknown_selflearning_large_language/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.09147 代码：https://github.com/teddy-f-47/self-learning-llm-public 摘要：  我们解决自学LLM的主要问题：学什么的问题。我们提出了一个自学法学硕士框架，使法学硕士能够通过自我评估自己的幻觉来独立学习以前未知的知识。利用幻觉评分，我们引入了未知点（PiUs）的新概念，以及用于自动 PiU 识别的一种外在方法和三种内在方法。它有助于创建一个自学循环，专门关注“未知点”中的知识差距，从而降低幻觉分数。我们还制定了衡量法学硕士自学能力的评估指标。我们的实验表明，经过微调或对齐的 7B-Mistral 模型具有相当好的自学习能力。我们的自学理念使法学硕士更新更加高效，并为知识交流开辟了新的视角。它还可能增加公众对人工智能的信任。    由   提交/u/SunsetOneSix  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bb8bxo/r_into_the_unknown_selflearning_large_language/</guid>
      <pubDate>Sun, 10 Mar 2024 11:35:30 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 尝试生成用于注视预测的合成数据集，为什么模型难以学习数据？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bb6z05/discussion_experimenting_with_generating_a/</link>
      <description><![CDATA[我设置了一个虚幻引擎 5 项目，该项目具有超人类视角，可以查看虚拟屏幕上的随机点，然后通过虚拟网络摄像头捕获照片我已经设置好了，然后保存。下面是一个大约 6.5K 图像的简单数据集（我说简单是因为我冻结了以前的很多变量，这里唯一改变图像的东西是照明、角色的位置、屏幕坐标和一些轻微的面部表情）运动我通过随机移动角色的嘴骨组合在一起）。 但出于某种原因，从头开始对数据进行训练的模型很难学习这些特征，并且训练和损失略有下降，但总体保持不变非常停滞... 这很奇怪，因为我已经（在某种程度上）成功地在我用网络摄像头制作的数据集上训练了注视预测模型，我试图用这些数据进行模仿。我成功地在具有 4K 和 6K 样本的相同模型架构上从头开始训练这些模型（最终有效 mse 损失约为 0.008（训练约为记忆中的 1/2），这仍然比我想要的要高，但是比合成模型好得多，合成模型通常在训练和有效方面都停滞在 0.08 左右）。 我尝试冻结除眼球运动和照明之外的所有变量，模型立即学习，训练损失降至 ~ 0.001。 我真的只是想了解可能导致问题的原因，对我来说非常奇怪的是，相同的模型具有完全相同的数据操作（使用一些 fastai 将大小调整为 (240, 320)图像增强）可以很好地学习具有更多变量的真实数据（例如，我在这里冻结的头部旋转，姿势变化，甚至衣服变化），但完全无法从这个更简单的数据集中学习：https://huggingface.co/datasets/goatman/meta human-gaze-prediction 抱歉这么久帖子，任何见解都会令人惊叹！   由   提交/u/Goatman117  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bb6z05/discussion_experimenting_with_generating_a/</guid>
      <pubDate>Sun, 10 Mar 2024 10:08:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我使用人工智能代理来淡化新闻的耸人听闻</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bb60g8/p_i_use_ai_agents_to_desensationalize_the_news/</link>
      <description><![CDATA[在当今世界，吸引人的标题和文章常常会分散读者对事实和相关信息的注意力。 Simply News 试图消除争论并提供有关实际发生情况的简单每日更新。通过协调多个人工智能代理，Simply News 处理耸人听闻的新闻文章，并将其转化为每天涵盖许多不同主题的有凝聚力的、以新闻为中心的播客。每个代理负责此过程的不同部分。例如，我们有执行以下功能的代理： 排序器：扫描大量新闻源，并根据与播客类别的相关性和重要性过滤文章。  投手：考虑到文章中呈现的叙述角度，为每篇排序的文章制作引人注目的投稿。 法官&lt; /strong&gt;：评估提案并就应涵盖哪些内容做出编辑决定。 脚本 脚本编写者：为所选文章起草引人入胜的脚本由法官决定，确保听力的清晰度和准确性。 我们的人工智能被引导选择与播客类别最相关的新闻文章。将人类从这个循环中移除意味着明确的偏见不会影响到报道内容的决定。 人工智能决策也更容易审计，这种透明度是人工智能能够成为强大的关键原因用于消除新闻中的偏见和耸人听闻的工具。 您可以在此处收听。 https://www.simplynews.ai/    ;由   提交 /u/sapientais   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bb60g8/p_i_use_ai_agents_to_desensationalize_the_news/</guid>
      <pubDate>Sun, 10 Mar 2024 09:04:58 GMT</pubDate>
    </item>
    <item>
      <title>GAN 仍然有意义吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bb34gj/are_gans_still_relevant_d/</link>
      <description><![CDATA[[D] 随着 Difussion 模型的不断兴起，我很好奇 GAN 是否会卷土重来？有什么想法吗？   由   提交 /u/Superb-Assignment-30   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bb34gj/are_gans_still_relevant_d/</guid>
      <pubDate>Sun, 10 Mar 2024 06:00:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于 ML 的直觉与同行不同是否常见？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bb2b9r/d_is_it_common_to_have_intuitions_different_from/</link>
      <description><![CDATA[我注意到我和我的同事对于 ML 的某些事情有不同的直觉。例如，以标记方式标记事物。 对于一个用例，我们想要检测距离摄像头最近的车辆。我认为我们应该在后处理步骤中处理这个问题，并让模型通过标记图像中所有可见的车辆来检测所有车辆，因为它们具有相似的特征。我的直觉是，仅标记距离摄像机最近的车辆会导致模型学习非常具体的特征，从而可能导致过度拟合，因为它会尝试区分距离摄像机较远和最近的车辆，尽管它们共享通用特征使它们成为车辆的特征。我的同事认为，只有最接近的车辆才应该被标记，因为这才是他们有兴趣检测的东西。 同样，我们在是否应该标记部分可见（&lt;30% 可见）的物体上也存在分歧。 。我认为它们应该是这样，因为如果你观察训练期间发生的增强，就会发现由于某些增强（例如缩放和马赛克）而不可避免地会出现部分可见的对象。因此，避免在原始图像中标记它们只会导致训练期间的不一致，其中一些部分对象被标记，而另一些则没有。他们不这么认为。 TLDR;对 ML 的直觉和理解存在差异是典型的吗？   由   提交 /u/notEVOLVED   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bb2b9r/d_is_it_common_to_have_intuitions_different_from/</guid>
      <pubDate>Sun, 10 Mar 2024 05:12:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士在预测神经科学实验结果方面超越人类专家（81% vs 63%）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1baq496/r_llms_surpass_human_experts_in_predicting/</link>
      <description><![CDATA[一项新研究表明，法学硕士可以比人类专家更准确地预测哪些神经科学实验可能会产生积极的结果。研究人员使用只有 70 亿个参数的 GPT-3.5 类模型，发现根据神经科学文献对其进行微调可以进一步提高性能。 我认为实验设计很有趣。法学硕士收到了两个版本的摘要，其结果显着不同，我们被要求预测哪个更有可能是真正的摘要，本质上是预测哪个结果更有可能。它们比人类高出约 18%。 其他亮点：  对神经科学文献的微调提高了性能 模型的准确率比人类高出 81.4%。人类专家为 63.4% 在所有测试的神经科学子领域都成立 即使较小的 7B 参数模型也能与较大的模型相媲美 微调的“BrainGPT”模型的准确度比基准提高了 3%  其意义重大 - 人工智能可以帮助研究人员优先考虑最有希望的实验，加速科学发现并减少浪费的努力。它可能会在理解大脑和开发神经系统疾病治疗方面带来突破。 但是，该研究仅关注神经科学，测试集有限。需要更多的研究来看看这些发现是否可以推广到其他科学领域。虽然人工智能可以帮助识别有前途的实验，但它无法取代人类研究人员的创造力和批判性思维。  全文在此。我还写了 更详细的分析在这里。   由   提交 /u/Successful-Western27    reddit.com/r/MachineLearning/comments/1baq496/r_llms_surpass_ human_experts_in_predicting/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1baq496/r_llms_surpass_human_experts_in_predicting/</guid>
      <pubDate>Sat, 09 Mar 2024 19:37:49 GMT</pubDate>
    </item>
    </channel>
</rss>