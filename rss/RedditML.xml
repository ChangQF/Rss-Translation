<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 23 Feb 2024 12:23:06 GMT</lastBuildDate>
    <item>
      <title>[D] 液体神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axz2ei/d_liquid_neural_network/</link>
      <description><![CDATA[大家好，我有一个项目要做，可以给我提供学习 LNN（液体神经网络）的资源或工具或路线图吗关于它们在某个现实生活中的应用程序。我已经对 ML、神经网络、CNN、RNN、LSTM、迁移学习有很强的背景。非常感谢您的帮助！   由   提交/u/Hussein_Jammal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axz2ei/d_liquid_neural_network/</guid>
      <pubDate>Fri, 23 Feb 2024 12:16:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于 DL 工作站的 AMD Ryzen Threadripper PRO 5955WX 与 AMD Ryzen Threadripper 7960X</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axytxf/d_amd_ryzen_threadripper_pro_5955wx_vs_amd_ryzen/</link>
      <description><![CDATA[我想构建一个具有 2x rtx4090 和 128GB RAM 的机器学习工作站。我正在努力决定合适的 CPU。您对 AMD Ryzen Threadripper PRO 5955WX 与 AMD Ryzen Threadripper 7960X 有何看法？我觉得 7960x 在各个方面都更胜一筹，除非我想在未来将我的设置扩展到四核 GPU 或更多 RAM。你觉得怎么样，我是不是错过了什么？您对这些选项的总体看法如何？   由   提交/u/Striking_Way_3205   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axytxf/d_amd_ryzen_threadripper_pro_5955wx_vs_amd_ryzen/</guid>
      <pubDate>Fri, 23 Feb 2024 12:03:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 撰写引人注目的会议论文的经验教训（技巧）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axxyh1/d_lessons_tips_for_writing_a_compelling/</link>
      <description><![CDATA[嗨， 随着 ECCV 截止日期的临近，我想从这里更有经验的成员那里获得一些关于课程的见解，他们在职业生涯中撰写会议论文时遵循/学到的提示和技巧。  这些可以是任何类型的东西，比如“漂亮的图片”、文本的语气、目标的措辞、他们在撰写文章时遵循的某些规则，或者他们认为审稿人在阅读时提出的高级问题他们的工作等。 希望这次交流也能让其他人受益。   由   提交 /u/PaganPasta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axxyh1/d_lessons_tips_for_writing_a_compelling/</guid>
      <pubDate>Fri, 23 Feb 2024 11:10:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 神经网络在权重进化后表现不同</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axxl3s/p_neural_network_performs_differently_after/</link>
      <description><![CDATA[嘿伙计们，标题有点模糊，但其核心是，我的问题是这样的。  我正在使用python evotorch模块的NEProblem（神经进化问题）和XNES（指数自然进化策略），使体育馆环境的Bipedal Walker行走。  在进化过程中，步行者达到了 250+ 的奖励（在我的例子中是目标适应度），算法也是这么说的。但是在进化过程结束后，我尝试重新加载表现最好的个体的保存权重，神经网络的表现与未经训练/未进化的网络相同（意味着非常糟糕） 我是不确定问题是否出在库上（保存最好的个体）或者权重重新加载的方式是否不正确。  库出错的可能性很小 我使用的权重重载函数是直接取自NEProblem的evotorch文档的源代码，所以我确信它没有错（因为进化过程使用了这个完全相同的函数），但它比第一个选项更有可能  我想看看是否有人有手动加载权重或使用相同库的经验。 我的项目是关于神经进化的，所以改为用强化学习等不是一个选择。 这是 evotorch 的来源：NEProblem evotorch。 make_net()、parameterize_net 和 fill_parameters() 是我正在使用的函数。 提前谢谢你们。希望有人可以提供帮助，因为没有这个我就无法可视化我的项目结果，因此我无法确定它是否有效   由   提交 /u/DocMenios   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axxl3s/p_neural_network_performs_differently_after/</guid>
      <pubDate>Fri, 23 Feb 2024 10:47:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您只需要更多代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axxii3/r_more_agents_is_all_you_need/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.05120 代码：https:/ /anonymous.4open.science/r/more_agent_is_all_you_need 摘要：  我们发现，只需通过抽样和-投票方法，大型语言模型（LLM）的性能随着实例化代理的数量而变化。此外，该方法与现有的复杂方法正交，以进一步增强LLM，而增强程度与任务难度相关。我们对各种 LLM 基准进行了全面的实验，以验证我们的发现的存在，并研究可以促进其发生的属性。我们的代码公开于：https://anonymous.4open.science/r/more \_agent\_is\_all\_you\_need。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axxii3/r_more_agents_is_all_you_need/</guid>
      <pubDate>Fri, 23 Feb 2024 10:41:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型语言模型中幻觉缓解技术的综合调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axxdb5/r_a_comprehensive_survey_of_hallucination/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.01313 摘要：  随着大型语言模型（LLM）的能力不断进步要编写类似人类的文本，一个关键的挑战仍然是他们倾向于产生幻觉，生成看似事实但毫无根据的内容。这种幻觉问题可以说是将这些强大的法学硕士安全部署到影响人们生活的现实生产系统中的最大障碍。在实际环境中广泛采用法学硕士的旅程在很大程度上依赖于解决和减轻幻觉。与专注于有限任务的传统人工智能系统不同，法学硕士在训练期间接触了大量在线文本数据。虽然这使他们能够表现出令人印象深刻的语言流畅性，但这也意味着他们能够从训练数据的偏差中推断出信息，误解不明确的提示，或者修改信息以表面上与输入保持一致。当我们依赖语言生成功能来实现敏感应用程序（例如总结医疗记录、财务分析报告等）时，这就变得非常令人担忧。本文对超过 32 种为减轻法学硕士的幻觉而开发的技术进行了全面调查。 其中值得注意的是检索增强生成（Lewis 等人，2021）、知识检索（Varshney 等人，2023）、CoNLI（Lei 等人，2023）和 CoVe（Dhuliawala 等人，2023）。此外，我们引入了一个详细的分类法，根据各种参数对这些方法进行分类，例如数据集利用率、常见任务、反馈机制和检索器类型。这种分类有助于区分专门为解决法学硕士的幻觉问题而设计的不同方法。此外，我们分析了这些技术固有的挑战和局限性，为未来解决法学硕士领域内的幻觉和相关现象的研究奠定了坚实的基础。  &lt;!-- SC_ON - -&gt;  由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axxdb5/r_a_comprehensive_survey_of_hallucination/</guid>
      <pubDate>Fri, 23 Feb 2024 10:32:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] IPU 仍然存在吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axwij2/d_are_ipus_still_a_thing/</link>
      <description><![CDATA[我最初对 IPU 感到非常兴奋，因为它们似乎是 GPU（和 TPU）的重要替代品。 但是 Graphcore，生产IPU的公司现在的处境似乎很糟糕。而且我没有看到 IPU 在软件兼容性方面有太多改进。例如，HF Optimum Graphcore 库已经 3 个月没有更新了：https://github.com/huggingface/optimum-graphcore&lt; /a&gt; ...   由   提交/u/handwerner142  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axwij2/d_are_ipus_still_a_thing/</guid>
      <pubDate>Fri, 23 Feb 2024 09:33:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大家对 Mamba 被 ICLR 拒绝感到惊讶？我错过了什么吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axsxeo/d_why_is_everybody_surprised_that_mamba_got/</link>
      <description><![CDATA[我也不只是想逆势而行。我不断在 Reddit、工作中、不同的在线论坛等上听到这个消息。当我第一次听到这个消息时我也很惊讶，但读完这篇论文后我并不特别惊讶。他们的硬件调整很有趣，但除此之外，这似乎是对之前论文的简单改编。基准实验并不像我最初认为的那么广泛，因为每个人都在谈论它有多么革命性。阅读这篇论文给我留下了很多问题，比如“X 任务或 Y 基准测试的性能怎么样？”我并不是想羞辱作者，但它并不真的感觉像一个“传统”的。机器学习领域的论文也有。 已经发布了很多并不完全适合会议出版物的优秀论文，我认为这不仅仅是因为某件事被讨论得很多在 Twitter 或 LinkedIn 上，这意味着它值得在某个场所发布。我真的想知道我是否低估了它，因为我没有正确理解它并且愿意接受任何意见。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axsxeo/d_why_is_everybody_surprised_that_mamba_got/</guid>
      <pubDate>Fri, 23 Feb 2024 05:40:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 面向多语言大语言模型的高效且有效的词汇扩展</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axs4r4/r_efficient_and_effective_vocabulary_expansion/</link>
      <description><![CDATA[https://arxiv.org/abs/2402.14714 关于非英语语言词汇扩展的技术报告刚刚发布。你觉得怎么样？  GPT-4 的 EEVE-Korean-v1.0 技术报告摘要： 技术报告介绍了 EEVE -Korean-v1.0，一种新颖的方法，旨在扩展以英语为中心的大语言模型（LLM）的词汇量，以显着增强其对韩语文本的处理能力。该方法利用参数冻结和策略子词初始化等技术，高效地将韩语语言处理纳入法学硕士，而不会降低他们的英语熟练程度。 值得注意的是，该方法在韩语任务中实现了显着的性能改进，同时仅需要20亿个训练代币，语言模型训练效率有了质的飞跃。通过这种方法开发的 EEVE-Korean-10.8B-v1.0 模型不仅在韩语任务中表现出色，而且在英语任务中也保持了强劲的表现，展示了这种训练方法的多功能性和有效性。 该报告还展望了未来，讨论了未来的方向，例如将这种词汇扩展技术扩展到其他语言，并进一步探索该模型在各种任务中的推理和生成能力。这项工作代表着在开发更具语言包容性和高效的语言模型方面向前迈出了重要一步。    由   提交/u/OldPin8654  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axs4r4/r_efficient_and_effective_vocabulary_expansion/</guid>
      <pubDate>Fri, 23 Feb 2024 04:57:13 GMT</pubDate>
    </item>
    <item>
      <title>硕士论文错误[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axebkf/master_thesis_mistake_d/</link>
      <description><![CDATA[大家好，我正在写计算机科学硕士学位论文，我的核心主题是特别使用遗传算法的自动特征工程。我刚刚意识到我发生了数据泄漏，一旦解决，结果明显低于以前。我的论文即将结束，下周将与我的教授进行最后一次会面。我的数据来自与我合作的公司，无法公开，因此我的工作无法真正复制，但我真的很强调是否应该告诉教授这个问题还是继续解决这个问题..我起来，我不想不诚实，但我不知道如何处理它，任何人都可以提供一些想法帮助吗？    由   提交/u/Adventurous_Car_1809   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axebkf/master_thesis_mistake_d/</guid>
      <pubDate>Thu, 22 Feb 2024 18:52:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] MetaGPT 严重错误报告了基线数据并获得了 ICLR 口头审查！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axbm0f/d_metagpt_grossly_misreported_baseline_numbers/</link>
      <description><![CDATA[OpenReview：https://openreview.net/forum ?id=VtmBAGCN7o 我正在查看 ICLR 评论，很惊讶地看到 MetaGPT 被提交给 ICLR。录取决定表明他们被授予口头（ICLR 的最高级别）。  查看论文，他们报告了与 HumanEval 的比较： ​   方法 Pass@1    MetaGPT 85.9   GPT-4 67.0   GPT-3.5-Turbo（在响应中） 48.1   然而，该基准测试中的真实 GPT-4 和 GPT-3.5-Turbo 数字要高得多（请参阅 EvalPlus 排行榜：https: //evalplus.github.io/leaderboard.html）。 EvalPlus 排行榜的结果已被重复多次，因此毫无疑问。 MetaGPT 作者使用的数字取自旧的技术报告，不再准确。他们必须知道这一点，每个人都知道，这是毫无疑问的。 以下是使用 EvalPlus 中的数字进行的真实比较：   方法 Pass@1    MetaGPT 85.9   GPT-4 88.4 &lt; /tr&gt;  GPT-3.5-Turbo 76.8   GPT-3.5-Turbo 性能被严重误报。以前从未见过这样的事情。他们不可能通过 GPT-3.5-Turbo 合法地获得该数字。 所以，基本上，他们的整个“代理公司模拟”是让你花 10 美元购买 OpenAI 学分的交易比只问一次 LLM 更糟糕...他们得到了口头...我们完蛋了。  &amp;# 32；由   提交 /u/Signal-Aardvark-4179   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axbm0f/d_metagpt_grossly_misreported_baseline_numbers/</guid>
      <pubDate>Thu, 22 Feb 2024 17:06:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么在法学硕士中字节对编码分词器比字符级分词器更受青睐？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ax6xuh/d_why_are_byte_pair_encoding_tokenizers_preferred/</link>
      <description><![CDATA[我知道字节对会给你更大的词汇量但更短的标记序列，而像字符级分词器这样更细粒度的东西将有一个小的词汇量但输出标记序列要长得多。 我不明白的是为什么这是大多数 LLM 模型的首选。例如，GPT 和 Llama 都使用字节对编码。这与这些模型的块大小限制有关吗？   由   提交/u/putinwhat  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ax6xuh/d_why_are_byte_pair_encoding_tokenizers_preferred/</guid>
      <pubDate>Thu, 22 Feb 2024 13:54:52 GMT</pubDate>
    </item>
    <item>
      <title>RAG 与长上下文模型 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ax6j73/rag_vs_long_context_models_discussion/</link>
      <description><![CDATA[大家好，我知道我们都看过具有 100 万上下文的 Gemini v1.5 模型，而且来自 groq 公司的硬件表明，如果硬件是专门为语言模型设计的，因为它们可以变得更好。您现在对 RAG 架构有何看法，因为我们已经看到了很长的上下文模型。如果我们有更长的上下文模型和更好的量化技术和硬件怎么办？您认为像 RAG 这样的架构以及使用向量数据库来存储知识库和动态检索仍然相关吗？ 请纠正我并相应地添加更多相关信息。如果相关的研究和观察被发布，我们将不胜感激！！   由   提交/u/WritingBeginning3403  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ax6j73/rag_vs_long_context_models_discussion/</guid>
      <pubDate>Thu, 22 Feb 2024 13:35:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么研究人员很少发布训练代码？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awy07v/d_why_do_researchers_so_rarely_release_training/</link>
      <description><![CDATA[我现在正在查看针对各种 MoE 模型的 3 篇不同论文。这三个都发布了模型权重和推理代码，但都没有发布训练代码。  当我们期望现在大多数论文都有代码及其实现时，为什么这种情况如此普遍和被接受？   由   提交/u/hazard02  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awy07v/d_why_do_researchers_so_rarely_release_training/</guid>
      <pubDate>Thu, 22 Feb 2024 04:59:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>