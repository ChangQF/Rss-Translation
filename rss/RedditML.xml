<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Wed, 27 Mar 2024 09:14:07 GMT</lastBuildDate>
    <item>
      <title>[D] 重新思考机器学习中数据质量的重要性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bowfpn/d_rethinking_the_importance_of_data_quality_in/</link>
      <description><![CDATA[      在机器学习领域，为了“改进”模型架构，数据经常被忽视。我们必须认识到数据与模型一样重要。  垃圾输入，垃圾输出：即使是最复杂的模型对于混乱、不完整或有偏见的数据也是无用的。关注数据质量可确保模型从正确的信息中学习。 释放模型潜力：更清晰、更丰富的数据使模型能够充分发挥潜力。想象一下一辆使用低级燃料的高性能汽车 - 数据质量是模型的燃料。 现实世界的影响：更好的数据可以带来更可靠、更通用的模型，这些模型在现实世界中表现良好情况。这对于医疗保健或金融等高风险应用尤其重要。  机器学习社区越来越认识到这一点。这是个好消息：  关注数据工程：最近人们开始强调数据收集、清理和管理。 以数据为中心的工具：新工具和新工具帮助管理大型数据集和确保数据质量的技术正在不断涌现。  机器学习的未来取决于优先考虑模型开发和数据质量的平衡方法。 &lt; a href=&quot;https://preview.redd.it/p5j7kp6t1uqc1.png?width=890&amp;format=png&amp;auto=webp&amp;s=28fb718d6be70789302ac662e94ee8dc3164a639&quot;&gt;https://preview.redd.it/p5j7kp6t1uqc1.png?width =890&amp;format=png&amp;auto=webp&amp;s=28fb718d6be70789302ac662e94ee8dc3164a639   由   提交/u/ml_a_day  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bowfpn/d_rethinking_the_importance_of_data_quality_in/</guid>
      <pubDate>Wed, 27 Mar 2024 07:55:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 发现开源项目的页面</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bow5yq/p_a_page_to_discover_open_source_projects/</link>
      <description><![CDATA[大家好， 我很高兴能分享我的热爱劳动，我希望这将改变开发者的游戏规则像我们。我制作了一个用户友好的平台，用于探索使用 JavaScript 构建的开源 AI 项目。它不仅仅是一个列表；这是一种交互式体验，您可以：  选择您的堆栈：从各种人工智能相关主题中进行选择，例如机器学习、自然语言处理等等！ 选择您的语言：按适合您的编程语言过滤项目。 智能搜索：通过手册深入了解详细信息搜索选项。  此页面旨在让我们更轻松地查找、共享和贡献令人难以置信的开源人工智能工具。无论您是经验丰富的专业人士还是新手，我希望此资源对您有所帮助。您的想法和建议对我来说非常宝贵，因此请随时分享您的反馈。 https ://muum.ai/ai-open-source-projects   由   提交/u/alimuratumutlu  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bow5yq/p_a_page_to_discover_open_source_projects/</guid>
      <pubDate>Wed, 27 Mar 2024 07:35:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有什么开源方法可以让 AI 对口型变得如此出色吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bou6t2/d_any_opensource_way_to_make_ai_lipsyncing_this/</link>
      <description><![CDATA[如何创建如此出色的 AI 口型同步？ https://imgur.com/Uw89El8 哪些工具 - 开源、免费或付费 - 最好？ 目前有哪些选项.   由   提交 /u/MorningHerald   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bou6t2/d_any_opensource_way_to_make_ai_lipsyncing_this/</guid>
      <pubDate>Wed, 27 Mar 2024 05:23:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 合成数据是训练机器学习模型的可靠选择吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bosj2t/d_is_synthetic_data_a_reliable_option_for/</link>
      <description><![CDATA[“合成数据最明显的优点是它不包含个人身份信息 (PII)。因此，它不会带来与传统数据科学项目相同的网络安全风险。然而，机器学习的一个大问题是，这些信息是否足够可靠，能够生成有效的 ML 模型。” 有关在机器学习中使用合成数据的信息丰富的博客，来源此处 https://opendatascience.com/is-synthetic-data-a-reliable-option- for-training-machine-learning-models/   由   提交/u/Data_Nerd1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bosj2t/d_is_synthetic_data_a_reliable_option_for/</guid>
      <pubDate>Wed, 27 Mar 2024 03:49:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] AIOS：LLM代理操作系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1booy6k/r_aios_llm_agent_operating_system/</link>
      <description><![CDATA[      论文：https://arxiv. org/abs/2403.16971 Github：https://github.com /agiresearch/AIOS  摘要：基于大语言模型 (LLM) 的智能代理的集成和部署充满了挑战，这些挑战损害了它们的性能。效率和功效。这些问题包括代理通过 LLM 请求的次优调度和资源分配、代理与 LLM 之间交互期间维护上下文的困难，以及集成具有不同功能和专业的异构代理所固有的复杂性。代理数量和复杂性的快速增加进一步加剧了这些问题，常常导致资源的瓶颈和次优利用。受这些挑战的启发，本文提出了AIOS，一种LLM代理操作系统，它将大语言模型嵌入到操作系统（OS）中，作为操作系统的大脑，使操作系统“有灵魂”。 ——迈向通用人工智能的重要一步。具体来说，AIOS旨在优化资源分配，促进跨代理的上下文切换，实现代理的并发执行，为代理提供工具服务，并维护代理的访问控制。我们提出了这样一个操作系统的架构，概述了它旨在解决的核心挑战，并提供了 AIOS 的基本设计和实现。我们对多个代理并发执行的实验证明了我们的 AIOS 模块的可靠性和效率。通过这一点，我们的目标不仅是提高 LLM 代理的性能和效率，而且是未来更好地开发和部署 AIOS 生态系统的先锋。  AIOS 架构概述。 &lt; !-- SC_ON --&gt;  由   提交 /u/TouchLive4686   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1booy6k/r_aios_llm_agent_operating_system/</guid>
      <pubDate>Wed, 27 Mar 2024 01:00:51 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 数据加载器优化 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bonupj/pytorch_dataloader_optimizations_d/</link>
      <description><![CDATA[PyTorch 中的数据加载器可以使用哪些优化？数据类型可以是任何类型。但我主要处理图像和文本。我们知道您可以定义自己的。但有人有什么巧妙的技巧可以分享吗？预先感谢您！   由   提交 /u/MuscleML   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bonupj/pytorch_dataloader_optimizations_d/</guid>
      <pubDate>Wed, 27 Mar 2024 00:13:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 多变量目标模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bohb7d/p_model_with_multi_variable_target/</link>
      <description><![CDATA[大家好。我需要训练一个模型，其中目标是概率向量，即 [0.2, 0.4。 0.1, 0.3] 使得其分量之和为 1。我正在考虑使用具有交叉熵损失的分类器，但我不确定这是正确的解决方案，因为此类分类器通常针对 [0,0 ,1,0...] 即 - 只有一个分量等于 1，然后可以证明分类器实际上学习生成分类器最佳候选上具有最高值的分布。我需要类似但不一样的东西，即具有 kl 散度损失函数或类似“距离”的模型概率向量之间，有什么想法或参考吗？   由   提交 /u/notSheOrThemOrIt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bohb7d/p_model_with_multi_variable_target/</guid>
      <pubDate>Tue, 26 Mar 2024 19:55:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Llama-2 处理大型文档的最佳方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bog35u/d_best_way_to_process_large_documents_with_llama2/</link>
      <description><![CDATA[大家好， 我正在开发一个项目，需要处理有时超过 100 页的文档。我正在使用 OCR 来抓取文本，并打算向法学硕士提供删除某些个人身份信息的指示。  有时，第 15 页（例如）上的信息会提供有关需要从第 86 页（例如）中删除哪些信息的线索。我必须保留上下文，因此所有 100 个文档必须以某种方式连接在一起。被视为 PII 的事物可能像“祖母”或“接待员”一样无辜，它仅依赖于符合 PII 资格的上下文（情况各不相同）。  我认为处理它的最佳方法如下：  创建一个训练数据集，其中我有多个单页文档文本作为输入，以及重要信息（有助于将该页面与其他页面联系起来的信息）作为输出。 在此数据集上训练 Llama-2 以创建“全局上下文创建者”LLM 。  在由单个页面 + 全局上下文组成的数据集上训练单独的 Llama-2 作为输入，并删除相关 PII 的页面文本作为输出。  对于文档中的每个页面，发送全局上下文 + 提示（这将是要删除哪个 PII 的说明），并接收删除 PII 的输出。   这是解决最大代币问题的唯一方法。还有其他人有什么想法吗？   由   提交 /u/HideousOstrich   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bog35u/d_best_way_to_process_large_documents_with_llama2/</guid>
      <pubDate>Tue, 26 Mar 2024 19:07:02 GMT</pubDate>
    </item>
    <item>
      <title>ACL 2024 评论 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1boea3w/acl_2024_reviews_discussion/</link>
      <description><![CDATA[ACL 2024（ARR 2 月）审核的讨论主题。 我的稳健性得分为 3、3、4。你们呢？   由   提交/u/EDEN1998  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1boea3w/acl_2024_reviews_discussion/</guid>
      <pubDate>Tue, 26 Mar 2024 17:55:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 代理操作系统 - 罗格斯大学 2024 - AIOS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bod1lq/r_llm_agent_operating_system_rutgers_university/</link>
      <description><![CDATA[     &lt; /td&gt; 论文：https://arxiv .org/abs/2403.16971 Github：https://github.com/agiresearch/AIOS 摘要：  基于大语言模型 (LLM) 的智能代理的集成和部署充满了挑战，这些挑战影响了其效率和功效。这些问题包括代理通过 LLM 请求的次优调度和资源分配、代理与 LLM 之间交互期间维护上下文的困难，以及集成具有不同功能和专业的异构代理所固有的复杂性。 代理数量和复杂性的快速增加进一步加剧了这些问题，通常会导致资源瓶颈和次优利用。受这些挑战的启发，本文提出了AIOS，一种LLM代理操作系统，它将大型语言模型嵌入到操作系统（OS）中。具体来说，AIOS旨在优化资源分配，促进跨代理的上下文切换，实现代理的并发执行，为代理提供工具服务，并维护代理的访问控制。我们提出了这样一个操作的架构系统，概述其旨在解决的核心挑战，并提供 AIOS 的基本设计和实施。我们对多个代理并发执行的实验证明了我们的 AIOS 模块的可靠性和效率。通过这一点，我们的目标不仅是提高LLM代理的性能和效率，而且是未来更好地开发和部署AIOS生态系统的先锋。   https:/ /preview.redd.it/o6uqo550npqc1.jpg?width=1329&amp;format=pjpg&amp;auto=webp&amp;s=a63e616a0e6bd4a29bc898544325275f0f65c7a2 https://preview.redd.it/onsep550npqc1.jpg?width=601&amp;format=pjpg&amp;auto=webp&amp;s =d5463b3f0ab98e61d7281895f9d38bed754da93d   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bod1lq/r_llm_agent_operating_system_rutgers_university/</guid>
      <pubDate>Tue, 26 Mar 2024 17:05:57 GMT</pubDate>
    </item>
    <item>
      <title>现代信息检索的一些优秀讲座视频[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1boc7jr/some_good_lecture_videos_on_modern_information/</link>
      <description><![CDATA[有没有一些涉及现代方面的信息检索好的讲座视频。   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1boc7jr/some_good_lecture_videos_on_modern_information/</guid>
      <pubDate>Tue, 26 Mar 2024 16:32:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 零均值泄漏 ReLu</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bo8idx/r_zero_mean_leaky_relu/</link>
      <description><![CDATA[         ;由   提交 /u/1nyouendo   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bo8idx/r_zero_mean_leaky_relu/</guid>
      <pubDate>Tue, 26 Mar 2024 13:55:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大型科技公司中典型的“研究科学家”的职责是什么样的？是什么决定了您是否能够继续以这个职位发表论文（获得博士学位后继续从事）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnz8nt/d_what_do_the_responsibilities_of_a_typical/</link>
      <description><![CDATA[我正在面试一家大型科技公司的此类职位。我通过一则写着“机器学习研究科学家”的广告进行了申请。我很乐意继续进行研究并发表论文。我在这家公司见过很多研究科学家，他们每年都会发表相当多的论文。但有些事情告诉我，并不是每个“研究科学家”都会处于这样的位置。那么什么决定了我将获得的工作类型/责任/自由？具体来说，是什么决定了我是否可以自由地进行研究和发表，而不是做公司内部的事情？   由   提交/u/Yalkim   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnz8nt/d_what_do_the_responsibilities_of_a_typical/</guid>
      <pubDate>Tue, 26 Mar 2024 04:36:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 近期 AI 会议同行评论中有多达 17% 由 ChatGPT 撰写</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnsuea/r_up_to_17_of_recent_ai_conference_peer_reviews/</link>
      <description><![CDATA[一项新研究发现，2023-2024 年顶级 AI 会议的同行评审中很大一部分可能包含来自 ChatGPT 等模型的大量 AI 生成内容. 使用一种新颖的统计技术，研究人员估计了人工智能在大量文档中生成的文本的百分比。通过分析同行评审，他们发现：  10.6% 的 ICLR 2024 评审包含重要的人工智能内容 9.1%（NeurIPS 2023） 6.5%（CoRL） 2023 EMNLP 2023 为 16.9%  相比之下，2022 年及更早的 ChatGPT 前评论中只有 1-2% 被标记为具有重大 AI 贡献。&lt; /p&gt; 一些关键发现：  以人工智能为主的评论往往会在接近截止日期的情况下进行 人工智能风格评论中的学术引用较少 &gt; 带有人工智能色彩的审稿人较少参与作者讨论 人工智能内容使审稿在语义上更加同质 较低的审稿人信心与较高的人工智能估计相关   ol&gt; 我认为，这项研究针对学术界在研究中负责任地使用人工智能的积极政策制定提出了一些问题。人工智能可能会通过这些“影子”来侵蚀同行评审的质量和完整性。影响。开放性问题包括：  是否应该披露人工智能在同行评审中的协助？ 尽管面临人工智能的诱惑，我们应该如何激励良好实践？ 我们能否保留人工智能同质化下的智力多样性？ 我们是否应该重新考虑人类/人工智能混合知识工作的信用？  总的来说，这是对人工智能在基础上快速增长的卷须的有趣的实证一瞥科学的质量控制！我认为测量某些人工智能词语“滴答”频率的方法是可行的。很有道理（例如，GPT4 使用的一些形容词就很清楚）。  我很好奇阅读有关此的评论！我有一个这里提供了更详细的摘要作为如果您有兴趣，那么原始论文就在这里。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/1bnsuea/r_up_to_17_of_recent_ai_conference_peer_reviews/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnsuea/r_up_to_17_of_recent_ai_conference_peer_reviews/</guid>
      <pubDate>Mon, 25 Mar 2024 23:36:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>