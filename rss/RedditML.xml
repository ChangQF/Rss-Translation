<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者请参阅learnmachinelearning AGI请参阅singularity</description>
    <lastBuildDate>Sun, 21 Jul 2024 18:18:07 GMT</lastBuildDate>
    <item>
      <title>[R] 大型语言模型时代的智能数字代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8reay/r_intelligent_digital_agents_in_the_era_of_large/</link>
      <description><![CDATA[https://doi.org/10.31219/osf.io/f75wz     由   提交  /u/thebigbigbuddha   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8reay/r_intelligent_digital_agents_in_the_era_of_large/</guid>
      <pubDate>Sun, 21 Jul 2024 17:20:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 与主要作者吴正轩讨论 ReFT 论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8qwnl/r_discussion_of_reft_paper_with_lead_author/</link>
      <description><![CDATA[大家好， 本周星期五的论文讨论会上，我们非常幸运地邀请到了 ReFT 论文的主要作者，我想分享一下我们的讨论和笔记！ https://www.oxen.ai/blog/arxiv-dives-how-reft-works TLDR ~ ReFT 是一种微调技术，其参数效率比 LoRA 高 15 到 60 倍。训练速度超快。在 A100 上，1k 个示例大约需要 18 分钟。我成功地在不到 1 分钟的时间内，在 Llama 2 7B 上使用大约 100 个示例对 A10 上的 ReFT 进行了微调。 它的工作原理是操作残差流中的表示，而不是 K-V 矩阵。他们向特定的 token 索引和层添加了他们称为“干预”的额外学习参数，从而高效且轻松地控制表示。ReFT 也很不错，因为它们是可组合的。例如，您可以训练一个用于指令跟踪的模型，一个用于德语的模型，然后将它们都应用于德语的获取和指令跟踪模型。 作者给出了他们在实验室中迭代时学到的超级实用的技巧和教训。整个讨论也在 YouTube 上。 希望你喜欢！    提交人    /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8qwnl/r_discussion_of_reft_paper_with_lead_author/</guid>
      <pubDate>Sun, 21 Jul 2024 16:59:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于神经发育程序。您认为“学习编码”这一想法有多合理？您认为它与自我编程有多大区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8pugs/d_on_the_neural_developmental_program_how_sound/</link>
      <description><![CDATA[我刚刚在 ALIFE2023 上看到了这个演讲，这看起来真的很有趣。总结一下，他们使用了 3 个“策略”网络来发展/生成一个“目标”网络，也就是传统的“策略”网络，它从环境中获取输入并给出动作的输出。 最后，演讲中描述的这个代理仍然是几个传统的神经网络，只是它们的输出是一个模型而不是预测，而来自奖励的训练只是进化算法或 PPO。对于像我这样的自我编程倡导者来说，这种由结构生成看起来很像其自身的结构的想法听起来非常棒，但从外观上看，它是一种类似优先依附的花哨网络生成模型，只是这次在奖励的帮助下它可以解决实际问题。（我仍然认为它很棒，并且是我们现在对预训练微调 RLHF 东西的常规做法的决定性一步） 您对此有何看法？    提交人    /u/HermanHel   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8pugs/d_on_the_neural_developmental_program_how_sound/</guid>
      <pubDate>Sun, 21 Jul 2024 16:11:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基线薄弱和报告偏差导致机器学习对流体相关偏微分方程过度乐观</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8pp4r/r_weak_baselines_and_reporting_biases_lead_to/</link>
      <description><![CDATA[  由    /u/nuclear_knucklehead  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8pp4r/r_weak_baselines_and_reporting_biases_lead_to/</guid>
      <pubDate>Sun, 21 Jul 2024 16:05:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基础时间序列预测模型的兴起</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8op8u/r_the_rise_of_foundation_timeseries_forecasting/</link>
      <description><![CDATA[在过去的几个月里，每家大型科技公司都发布了时间序列基础模型，例如：  TimesFM (谷歌) MOIRAI (Salesforce) Tiny Time Mixers (IBM)  这些模型的详细分析位于此处。    提交人    /u/apaxapax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8op8u/r_the_rise_of_foundation_timeseries_forecasting/</guid>
      <pubDate>Sun, 21 Jul 2024 15:21:14 GMT</pubDate>
    </item>
    <item>
      <title>有谁成功微调过 Chronos [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8ia8p/has_anybody_succeeded_at_finetuning_chronos_d/</link>
      <description><![CDATA[Chronos 是基于 t5 架构的时间序列预测模型，由 Amazon 开发。 我的应用程序用于预测身体运动中的关节位置。这个应用程序的术语很重，而且他们的微调文档有点难以理解。 如果有人成功做到了，请帮忙。  Chronos：https://github.com/amazon-science/chronos-forecasting 微调文档：https://github.com/amazon-science/chronos-forecasting/blob/main/scripts%2FREADME.md 如果有人能直接帮助我预训练这个模型，特别是根据他们的要求转换我的数据集，那将非常有帮助。谢谢    提交人    /u/abdullahboy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8ia8p/has_anybody_succeeded_at_finetuning_chronos_d/</guid>
      <pubDate>Sun, 21 Jul 2024 09:14:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 去噪扩散概率模型论文学习笔记</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8hrib/r_my_learning_notes_for_denoising_diffusion/</link>
      <description><![CDATA[嗨， 我正在分享我在扩散论文https://maitbayev.github.io/posts/denoising-diffusion-probabilistic-models/上的学习笔记，主要是为了加深我自己的理解，希望它们对你也有用。欢迎提问。 谢谢，    提交人    /u/madiyar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8hrib/r_my_learning_notes_for_denoising_diffusion/</guid>
      <pubDate>Sun, 21 Jul 2024 08:35:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你在公司项目中处理的数据集的平均大小是多少？#D</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8h7ra/d_what_is_the_average_size_of_datasets_you_work/</link>
      <description><![CDATA[想知道您在项目中使用的数据集大小，是 GB 还是 TB？ 以及您如何处理大型数据集以及在处理过程中遵循哪些最佳实践。    提交人    /u/PraveenKumarIndia   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8h7ra/d_what_is_the_average_size_of_datasets_you_work/</guid>
      <pubDate>Sun, 21 Jul 2024 07:55:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检索增强生成归因</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8e12u/d_attribution_for_retrieval_augmented_generation/</link>
      <description><![CDATA[在 RAG 期间，我一直在研究 LLM 的“引用来源”研究。例如，OpenAI 使用他们的 file_search 工具为 Assistants API 或 Bing Chat 执行此操作，其引用位于右上角。我想知道是否有任何最近的调查论文介绍黑盒技术来实现这一点。我发现一个非常有前途的论文是 MIRAGE 论文（https://arxiv.org/abs/2406.13663），但它需要开放权重。可能是我没有使用正确的搜索术语，但似乎这个子领域已经停滞不前。    提交人    /u/Green_ninjas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8e12u/d_attribution_for_retrieval_augmented_generation/</guid>
      <pubDate>Sun, 21 Jul 2024 04:23:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你在生产中的 LLM Stack 是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8cxkf/d_what_is_your_llm_stack_in_production/</link>
      <description><![CDATA[好奇人们在生产堆栈中使用什么来开发 LLM 应用程序。这个问题是几个月前提出的，但该领域的事态变化如此之快，我认为值得再开一个帖子。 嵌入模型：目前是 OpenAI Ada，但召回率/准确率不是很好，所以我打算尝试其他模型 矢量数据库：Supabase（推荐） LLM：一直在尝试开源和闭源模型。我的任务需要相当强的推理能力，因此不幸的是本地模型还不够好（例如 Llama 70B）。OpenAI GPT-4o 表现最佳（不足为奇），但对于我的用例来说它确实很昂贵，所以我目前使用的是 Gemini Pro 1.5。 LLM 框架：无。大家的共识是远离 LangChain，所以我只是直接与 LLM 提供商集成。幸运的是，LLM 提供商似乎倾向于 OpenAI API 标准，这使得实验变得容易（除了偶尔定制的 API，如 Gemini） 评估：???。不太确定这个的最新技术是什么。 其他人都在用什么？    提交人    /u/Aggressive_Comb_158   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8cxkf/d_what_is_your_llm_stack_in_production/</guid>
      <pubDate>Sun, 21 Jul 2024 03:17:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 21 Jul 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] Perpetual：无需超参数调整的梯度提升机</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e858j4/r_perpetual_a_gradient_boosting_machine_which/</link>
      <description><![CDATA[Repo：https://github.com/perpetual-ml/perpetual PerpetualBooster 是一种梯度提升机 (GBM) 算法，它不需要超参数调整，因此与其他 GBM 算法不同，您可以在没有超参数优化库的情况下使用它。与 AutoML 库类似，它有一个 budget 参数。增加 budget 参数可提高算法的预测能力，并在看不见的数据上提供更好的结果。 下表总结了 California Housing 数据集（回归）的结果：   永久预算 LightGBM n_estimators 永久 mse LightGBM mse 永久 cpu 时间 LightGBM cpu 时间 加速    1.0 100 0.192 0.192 7.6 978 129x   1.5 300 0.188 0.188 21.8 3066 141x   2.1 1000 0.185 0.186 86.0 8720 101x   PerpetualBooster 使用泛化算法防止过度拟合。本文正在编写中，旨在解释该算法的工作原理。查看我们的博客文章，了解该算法的高级介绍。     提交人    /u/mutlu_simsek   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e858j4/r_perpetual_a_gradient_boosting_machine_which/</guid>
      <pubDate>Sat, 20 Jul 2024 20:47:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] VLLM 的 OCR 功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e84mt8/r_vllms_ocr_capabilities/</link>
      <description><![CDATA[嗨，我正在尝试研究多模态 LLM 的 OCR 或转录功能，以回答一个简单的问题，即这些模型是否可以取代工业文档上的纯 OCR 引擎，这是一件非常常见的事情。 是否已经对文档数据集进行了研究？ 可以使用哪种指标来有效地考虑阅读和阅读顺序？Rouge-L？    提交人    /u/EducationalSpread478   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e84mt8/r_vllms_ocr_capabilities/</guid>
      <pubDate>Sat, 20 Jul 2024 20:19:24 GMT</pubDate>
    </item>
    <item>
      <title>单目深度估计和 Depth Anything V2 详解！[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e82q0v/monocular_depth_estimation_and_depth_anything_v2/</link>
      <description><![CDATA[      分享我 YouTube 频道上的一段视频，讨论计算机视觉单目深度估计 (MDE) 的主要概念！    提交人    /u/AvvYaa   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e82q0v/monocular_depth_estimation_and_depth_anything_v2/</guid>
      <pubDate>Sat, 20 Jul 2024 18:52:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 科学的机器学习在实践中实际应用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7z4s0/d_is_scientific_machine_learning_actually_used_in/</link>
      <description><![CDATA[作为一个背景横跨科学计算和机器学习的人，我听到了很多关于科学机器学习 (SML) 的信息。它的承诺是，人们可以使用机器学习来加速、简化或以其他方式改进数值模型。一个常见的示例用例是，人们可以使用高保真数值模拟（运行速度可能非常慢）作为训练数据，然后在这些模拟上训练神经网络，以比运行实际模拟更快的速度预测数值模拟的结果（从而获得降阶模型）。这对于数字孪生等来说可能非常有用，您可能希望实时计算风力涡轮机的流体动力学，同时遵守控制流体方程并结合不断变化的风、温度等传感器数据，以预测事故、优化等。我只在学术环境中听说过这个和其他用例。  我的问题是，科学机器学习是否真的在实践（工业）中使用？有人能指出任何现实世界的例子吗？有没有公司真正使用这项技术？如果没有，我很想听听为什么它似乎没有为市场提供任何价值（至少目前如此）。在工业界采用这些方法的一些障碍/瓶颈是什么？或者科学机器学习只是两个原本有用的领域的人为配对，仅仅是为了满足学术好奇心和撰写拨款提案？    提交人    /u/worstthingsonline   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7z4s0/d_is_scientific_machine_learning_actually_used_in/</guid>
      <pubDate>Sat, 20 Jul 2024 16:09:20 GMT</pubDate>
    </item>
    </channel>
</rss>