<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Wed, 20 Mar 2024 03:14:39 GMT</lastBuildDate>
    <item>
      <title>[D] 特征提取中的特征是什么意思以及我们如何生成输出？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bj35rc/d_what_do_you_mean_by_features_in_feature/</link>
      <description><![CDATA[我正在做文本分类。使用 TF-IDF 和 Glove 嵌入相结合的假新闻分类。我正在将它们连接起来。外部询问生成了多少个特征以及特征提取的输出是什么。向他们展示什么？我很困惑。文本分类上下文中的输出是否类似于普通数组或矩阵值，特征选择与特征提取相同吗？   由   提交 /u/Kindly-Song5246    reddit.com/r/MachineLearning/comments/1bj35rc/d_what_do_you_mean_by_features_in_feature/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bj35rc/d_what_do_you_mean_by_features_in_feature/</guid>
      <pubDate>Wed, 20 Mar 2024 02:44:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最近的“LLM工程师”没有NLP背景的情况常见吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bj0y3h/d_is_it_common_for_recent_llm_engineers_to_not/</link>
      <description><![CDATA[过去几周，我参加了一些聚会和社交活动，在那里我遇到了很多声称他们“与法学硕士合作”的人。我个人对它们没有太多经验，并且对更“经典”的领域进行了研究。 NLP（ELMo 和 BERT 在我做研究时是重大公告），现在主要作为工程师在业界工作。 我经常注意到，当我尝试谈论 LLM 研究模式或应用程序和那些我称之为经典方法的人通常似乎不知道我在说什么。 我不是在谈论研究人员，显然如果你正在与法学硕士进行实际研究，我假设您已经在该领域工作了一段时间。如今，LLM 和 NLP 似乎被分开对待。好奇其他人的想法。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bj0y3h/d_is_it_common_for_recent_llm_engineers_to_not/</guid>
      <pubDate>Wed, 20 Mar 2024 00:59:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 3D 点云上的 Conv2D</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bizyno/d_conv2d_on_3d_point_clouds/</link>
      <description><![CDATA[嗨！ 我正在使用点云回归进行姿态预测。 原始实现PointNet、PointNet++、DGCNN 等的每个卷积层都使用 Conv2D 运算。 我的问题是：为什么在这种情况下使用 2D 卷积而不是 1D 卷积？这样做的原因和优点是什么？ 提前致谢！   由   提交 /u/Professional-Act-163   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bizyno/d_conv2d_on_3d_point_clouds/</guid>
      <pubDate>Wed, 20 Mar 2024 00:16:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过融合张量运算流实现无静态图的最佳性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biy9aj/p_optimal_performance_without_static_graphs_by/</link>
      <description><![CDATA[当前机器学习研究最重要的方面之一是发现可有效扩展计算资源的模型架构。由于有效利用当代硬件，变压器已成为主要架构。然而，它们不会根据任务的复杂性来调整计算图，因此需要针对不同复杂性的任务使用不同的版本。这种方法与拥有一个能够持续学习（终身学习）的模型同时保持简单任务高效的目标不符。我认为迫切需要进一步探索动态架构，其中计算图在运行时根据上下文线索进行调整。 虽然 BranchyNet 等几篇论文已经深入研究了这种方法，有选择地跳过层当以高置信度生成令牌时，它们的实现可能不如 JAX 中实现的标准静态转换器那么高效或优化。尽管如此，将基于静态图的框架的速度与 PyTorch 之类的灵活性相结合不是很好吗？这正是我最近在 Burn 上所做的工作。 Burn 是一个急切的框架，具有独特的特征：它是用 Rust 编写的，大量使用类型系统来捕获张量动态生命周期，生成高度优化的带有即时编译器的 GPU 内核。 PyTorch 还尝试创建一个即时编译器来捕获部分图，但结果并不那么乐观，最近的多后端 Keras 3 基准测试就证明了这一点。因此，在 PyTorch 中实现高性能可能需要许多自定义内核。不幸的是，处理高级概念、数学公式和理论通常需要进入 CUDA 和非常低级的编程才能有效地进行经验测试。 Burn 的愿望是使研究和应用成为可能。快速部署最灵活的架构，无需 GPU 编程即可实现最先进的性能。虽然在获得最快框架的称号之前还需要做更多的工作，但我们正在不断添加更多优化，并且基础已经稳固。 博客：https://burn.dev/blog/fusion-tensor-operation-streams/ 代码：https://github.com/tracel-ai/burn/tree/main/crates/burn-fusion&lt; /p&gt;   由   提交/u/ksyiros  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biy9aj/p_optimal_performance_without_static_graphs_by/</guid>
      <pubDate>Tue, 19 Mar 2024 23:03:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] TacticAI：足球战术人工智能助手</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biw8qn/r_tacticai_an_ai_assistant_for_football_tactics/</link>
      <description><![CDATA[博客文章：https://deepmind.google/discover/blog/tropicai-ai-assistant-for-football-tropics/ 自然论文：https://www.nature.com/articles/s41467-024-45965-x 摘要 识别对手球队实施的关键战术模式并制定有效的应对措施是现代足球的核心。然而，通过算法实现这一点仍然是一个开放的研究挑战。为了解决这一未满足的需求，我们提出了 TacticAI，这是一款与利物浦足球俱乐部领域专家密切合作开发和评估的人工智能足球战术助手。我们专注于分析角球，因为它们为教练提供了最直接的干预和改进机会。 TacticAI 结合了预测和生成组件，使教练能够有效地采样和探索每个角球例程的替代球员设置，并选择那些预测成功可能性最高的球员。我们在许多相关基准任务上验证 TacticAI：预测接球手和投篮尝试以及建议球员位置调整。 TacticAI 的实用性已通过利物浦足球俱乐部足球领域专家进行的定性研究得到验证。我们表明，TacticAI 的模型建议不仅与真实战术无法区分，而且在 90% 的情况下比现有战术更受青睐，并且 TacticAI 提供了有效的角球检索系统。尽管黄金标准数据的可用性有限，但 TacticAI 通过几何深度学习实现了数据效率，从而实现了这些成果。   由   提交 /u/RobbinDeBank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biw8qn/r_tacticai_an_ai_assistant_for_football_tactics/</guid>
      <pubDate>Tue, 19 Mar 2024 21:42:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 Transformer 在每层使用相同维度的嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bit2f9/d_why_do_transformers_use_embeddings_with_the/</link>
      <description><![CDATA[我的直觉是，随着我们在层中移动，令牌会逐渐丰富，但这意味着我们需要在每个令牌中存储更少的信息前面的层比后面的层要多。 从（相对）低维嵌入开始，然后将它们投影或扩展到更高的维度，直到它们达到最终大小，这不是有意义吗？    由   提交/u/timtom85  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bit2f9/d_why_do_transformers_use_embeddings_with_the/</guid>
      <pubDate>Tue, 19 Mar 2024 19:35:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 2024 讨论主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bireik/d_icml_2024_discussion_thread/</link>
      <description><![CDATA[这篇文章用于讨论与 ICML 2024 相关的任何内容，评论将于明天发布！祝所有参与者好运！   由   提交/u/condom-mechanics  /u/condom-mechanics  reddit.com/r/MachineLearning/comments/1bireik/d_icml_2024_discussion_thread/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bireik/d_icml_2024_discussion_thread/</guid>
      <pubDate>Tue, 19 Mar 2024 18:29:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 迈向白盒深度学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biq9pc/r_towards_white_box_deep_learning/</link>
      <description><![CDATA[我提出了一个用于构建本质上可解释的神经网络的概念框架。 MNIST 子问题的 PoC 4 层模型可以被视为白盒：决策边界很容易解释，并且该模型对对抗性攻击具有鲁棒性 - 尽管没有任何形式的对抗性训练！ 该方法本质上是简化为如何在网络层内共享权重以实现高度可解释和鲁棒的特征的一般概念。它的一般性质和有效性表明，应该有可能为更复杂的数据集和不同的模式获得类似的结果 - 这为进一步研究开辟了令人兴奋的领域！ 迫不及待想听到您的反馈！  p&gt; https://arxiv.org/abs/2403.09863   由   提交/u/Swarzkopf314  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biq9pc/r_towards_white_box_deep_learning/</guid>
      <pubDate>Tue, 19 Mar 2024 17:42:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我如何在 Google Gemma 6T 代币模型中发现 8 个错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bipsqj/p_how_i_found_8_bugs_in_googles_gemma_6t_token/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bipsqj/p_how_i_found_8_bugs_in_googles_gemma_6t_token/</guid>
      <pubDate>Tue, 19 Mar 2024 17:23:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] [R] 精心策划和协调的多研究妊娠期阴道微生物组数据集，适用于 AI/ML 模型的训练和验证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biprfm/p_r_a_curated_and_harmonized_multistudy_vaginal/</link>
      <description><![CDATA[您好！我是最近的众包 AI/ML 研究的主要作者，该研究旨在识别有早产和早产风险的怀孕 -我想与阴道微生物组数据分享精心策划的阴道微生物组数据训练和验证数据集更广泛的人工智能/机器学习社区。 我认为对于那些对微生物组数据训练模型感兴趣的人来说，这可能是一个宝贵的资源。我也很高兴回答您关于如何组装、协调这些数据以及所提供的各种特征的生物学意义的问题，以及如何对其他基于 16S rRNA 基因的微生物组数据（有超过 200,000 个样本）进行类似的协调在公共数据库中测序）。 数据集由 7 项独立进行的研究组成怀孕期间的阴道微生物组，涵盖 764 次怀孕和 2226 个样本；额外的样本正在等待 dbGAP 的批准。为每个样本精心策划关键元数据（采集妊娠周；分娩妊娠周；NIH 种族/民族类别（如果有）等）。 微生物组数据的协调存在重大挑战，特别是这些数据是通过 16S rRNA 基因可变区的扩增产生的，其中每项研究都使用不同的技术方法。该数据集的组装基于我的研究小组的一种新颖的协调方法，那些寻求使用微生物组数据的人也可能会对此感兴趣。 tldr：以下是一些严格协调的阴道微生物组数据怀孕。如果您只想从一个矩阵开始，请使用 0.5 距离处的系统发育型表（计数或相对丰度）。   由   提交/u/golob  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biprfm/p_r_a_curated_and_harmonized_multistudy_vaginal/</guid>
      <pubDate>Tue, 19 Mar 2024 17:21:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 带注释的曼巴：艰难的道路</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biisb2/p_annotated_mamba_the_hard_way/</link>
      <description><![CDATA[链接：https://srush .github.io/annotated-mamba/hard.html 代码：https://github .com/srush/annotated-mamba 来自作者：  此博客是关于Mamba 一种最新的神经架构，可以粗略地认为是现代循环神经网络（RNN）。该模型运行得非常好，是无处不在的 Transformer 架构的合法竞争对手。它已经引起了很多关注。  我原本打算写一篇关于整篇论文的博文，内容相当密集且富有洞察力。然而，我只是对此处描述的 S6 算法着迷。该算法描述了如何在现代硬件上有效计算极大的 RNN，并扩展了 S4 和 近年来的S5。  事实上，如果我说实话，我实际上只了解了算法的这一行： y = SSM(A, B, C)( x) # 随时间变化：仅重复(扫描)  这行代码很有趣，我想，嘿，难道没有人能够理解为什么这种扫描在实践中速度很快吗？  事实证明这有点棘手。但是，如果您阅读这篇博文，我可以向您保证，您会理解这句话。 （也许比您想要的更多）。  第 0 部分：Triton  第 1 部分：累积和  第 2 部分：指数移动平均线  第 3 部分：获取导数  p&gt; 第 4 部分：同时多个  第 5 部分：Mamba  ​   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biisb2/p_annotated_mamba_the_hard_way/</guid>
      <pubDate>Tue, 19 Mar 2024 12:14:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] NVIDIA GTC 2024 公告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bif6ey/d_nvidia_gtc_2024_announcements/</link>
      <description><![CDATA[NVIDIA 的计划已遍及加速计算、生成式 AI、行业应用、汽车、企业平台、Omniverse 和机器人领域。 其中一些最有趣的是：  DRIVE Thor：用于自动驾驶汽车中的生成式人工智能应用的车载计算平台。它每秒执行高达千万亿次操作，增强了自动驾驶的安全性，并支持与车辆的交互式对话。 Omniverse：融合物理和虚拟世界的数字孪生生态系统，帮助行业模拟、优化和识别更有效地执行操作。新的 Omniverse Cloud API 扩展了这些功能，使汽车和机器人等行业受益。 GR00T 项目：推动机器人和人工智能突破的人形机器人的基础模型。此外，还推出了 Jetson Thor 计算机，并升级至 NVIDIA Isaac™ 机器人平台，其中包含生成式 AI 模型和模拟工具。 Nvidia Blackwell GPU：一项尖端技术，旨在以 20 petaflops 的速度为下一代 AI 提供动力的性能。该GPU代表了人工智能能力的巨大飞跃，旨在实现万亿参数模型的民主化。 NVLink Switch 7.2 TI：新一代互连技术，可解决数据交换的瓶颈。它旨在促进 GPU 之间的通信，其规模适合最先进的 AI 模型。 NVIDIA NIM：一款新软件产品，旨在简化企业环境中生成式 AI 的部署。它将模型与优化的推理引擎打包在一起，并支持广泛的 GPU 架构。他们称其为所有人的人工智能包。  你最喜欢哪个？   由   提交 /u/vvkuka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bif6ey/d_nvidia_gtc_2024_announcements/</guid>
      <pubDate>Tue, 19 Mar 2024 08:13:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] Nvidia GTC24 的 GPT4 参数计数与我们从 Semianalysis 获得的泄漏相同</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bi16pg/d_same_param_count_for_gpt4_from_nvidia_gtc24_as/</link>
      <description><![CDATA[   A Semianalysis 早前的报告称 GPT-4 是一个 1.8T 参数的 MoE 模型，有 16 位专家，每个有 111B 个参数。这是 GTC 会议的屏幕截图，具有相同的数字。 https://preview.redd.it/vyzfx2sel5pc1.png?width=1764&amp;format=png&amp;auto=webp&amp;s=dfce1d55c84dbc3c51e69f376161c47958f9cf 70   由   提交 /u/takuonline   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bi16pg/d_same_param_count_for_gpt4_from_nvidia_gtc24_as/</guid>
      <pubDate>Mon, 18 Mar 2024 20:36:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当你使用人工智能进行总结时结果不正确时。爱思唯尔发表的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</link>
      <description><![CDATA[       由   提交 /u/vvkuka   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</guid>
      <pubDate>Mon, 18 Mar 2024 10:14:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>