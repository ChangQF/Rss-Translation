<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 22 Dec 2023 18:16:20 GMT</lastBuildDate>
    <item>
      <title>[P] 微调和评估 Falcon 7B/LLAMA 7B 模型以生成 HTML 代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18okus7/p_finetuning_and_evaluating_a_falcon_7bllama_7b/</link>
      <description><![CDATA[我被分配了这项任务，但我只能访问我自己的电脑。我不认为它有任何 GPU。我是法学硕士的新手。请指导我如何继续。 还提到我也可以使用 Hugging Face 中的任何其他模型..提前致谢   由   提交 /u/CommunicationHot6434   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18okus7/p_finetuning_and_evaluating_a_falcon_7bllama_7b/</guid>
      <pubDate>Fri, 22 Dec 2023 17:58:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 稳定的扩散电报机器人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ojyja/p_stable_diffusion_telegram_bot/</link>
      <description><![CDATA[大家好，我想展示一个我制作的简单电报机器人，它使用稳定扩散将文本转换为图像。 最低要求是 6GB 的 VRAM。 遗憾的是，目前 python telegram bot 只限制发送最多 5mb 的照片，因此图像质量很差，尽管我正在寻找解决方法。任何投入都是有价值的！ :) 这是 github 的链接： https://github.com/harvestingmoon/StableVisionBot    由   提交 /u/notrealDirect   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ojyja/p_stable_diffusion_telegram_bot/</guid>
      <pubDate>Fri, 22 Dec 2023 17:18:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对齐马蹄形</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ojxf8/d_alignment_horseshoe/</link>
      <description><![CDATA[       由   提交/u/31162123  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ojxf8/d_alignment_horseshoe/</guid>
      <pubDate>Fri, 22 Dec 2023 17:17:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 培训本地法学硕士将文本翻译成代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18oj5tq/p_training_local_llm_to_translate_text_into_code/</link>
      <description><![CDATA[我正在开发一个项目，该项目将获取 PDF 并将其转换为代码。我不能太具体地介绍我正在使用的 PDFS。但是有人对我应该使用/微调什么模型有任何建议吗？我可以根据现有 PDF 和现有代码创建大型数据集。但我不确定“如何” （模型/训练/微调等） 理想的解决方案是我可以在工作中使用的模型，因此任何我可以独立编程/训练的东西都会很棒。 任何建议将不胜感激，谢谢！   由   提交/u/slb1357  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18oj5tq/p_training_local_llm_to_translate_text_into_code/</guid>
      <pubDate>Fri, 22 Dec 2023 16:43:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 传感器故障检测方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ohvn5/r_methods_for_fault_detection_of_sensors/</link>
      <description><![CDATA[寻找熟悉气象站的人。如何仅根据读数来检测有故障的天气传感器？ 我正在做一个关于气象站使用的故障传感器的检测和预测的项目，以改进维护和优化调度。  我见过一些研究使用电池电量、通信状态和温度等操作数据来检测故障。对于工业机器尤其如此。他们使用传感器来读取这些机器的温度、振动、旋转等。  如果气象站没有此类数据，我该怎么办？由于我们当地气象机构的保密问题，我也没有维护数据。我只能访问历史天气数据，其中包含感测到的实际物理现象的值（温度、湿度等） 异常检测会起作用，但我在想，自从突然下雨以来，它是否真的那么准确影响温度、湿度、风速值使模型感到困惑，认为传感器有故障。  如果我听起来很菜鸟，请原谅我，因为这只是我的第二个机器学习项目。   由   提交 /u/Funny_Shoe1772   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ohvn5/r_methods_for_fault_detection_of_sensors/</guid>
      <pubDate>Fri, 22 Dec 2023 15:46:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer 作为基于 NMDAR 启发的非线性的海马记忆巩固模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18oellc/r_transformer_as_a_hippocampal_memory/</link>
      <description><![CDATA[论文：https： //openreview.net/forum?id=vKpVJxplmB 代码：补充材料中包含的 PyTorch 实现代码。 摘要:  海马体在学习、记忆和空间表征等依赖于 NMDA 受体 (NMDAR) 的过程中发挥着关键作用。受最近将深度学习模型与海马体进行比较的研究结果的启发，我们提出了一种模仿 NMDAR 动力学的新非线性激活函数。类似 NMDAR 的非线性在变形金刚中将短期工作记忆转变为长期参考记忆方面发挥着有益作用，从而增强了类似于哺乳动物大脑中的记忆巩固的过程。我们设计了一个评估这两种记忆功能的导航任务，并表明操纵激活功能（即模仿 NMDAR 的 Mg2+-门控）会破坏长期记忆过程。我们的实验表明，类细胞函数和参考存储器驻留在变压器的前馈网络层中，并且非线性驱动这些过程。我们讨论了类似 NMDAR 的非线性在建立变压器架构和海马空间表示之间惊人相似性方面的作用。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18oellc/r_transformer_as_a_hippocampal_memory/</guid>
      <pubDate>Fri, 22 Dec 2023 13:11:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] Perseus：消除大型模型训练中的能量膨胀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18oedd2/r_perseus_removing_energy_bloat_from_large_model/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.06902 项目页面：https:// /ml.energy/zeus/perseus/ 积分： https://ml.energy/zeus/perseus/integrating/ 摘要：  在大量数据上训练大型人工智能模型GPU 消耗大量能源。我们观察到，并非训练期间消耗的所有能量都会直接贡献于端到端训练吞吐量，并且可以在不减慢训练速度的情况下消除很大一部分能量，我们将其称为能量膨胀。在这项工作中，我们确定了大型模型训练中两个独立的能量膨胀来源：内在和外在，并提出Perseus，一个统一的优化框架减轻两者。珀尔修斯获得“迭代时间-能量”任何大型模型训练作业的帕累托前沿都使用基于迭代图切割的算法，并在一段时间内安排其前向和后向计算的能耗，以消除内在和外在的能量膨胀。对 GPT-3 和 Bloom 等大型模型的评估表明，Perseus 将大型模型训练的能耗降低了高达 30%，实现了以前无法实现的节省。  &lt;!-- SC_ON - -&gt;  由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18oedd2/r_perseus_removing_energy_bloat_from_large_model/</guid>
      <pubDate>Fri, 22 Dec 2023 12:59:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士如何知道每个子标记中存在的字符？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18odz8f/d_how_can_llms_be_aware_of_the_characters/</link>
      <description><![CDATA[例如，当我向 chatGPT 询问该句子中的字母数量时： 但是，我想知道这些是如何实现的LLM 可以执行计数，因为知道分词器正在执行子标记级别而不是字符级别（这意味着每个子标记“可能”不知道它具有的字符”）。）。 答案是 15这是正确的 ​ 但是，我想知道这些 LLM 如何执行计数，因为知道标记器正在执行子标记级别而不是字符级别（意味着每个子标记都是“也许”不知道它有哪些字符”）。 ​ ​ &lt;!-- SC_ON - -&gt;  由   提交/u/kekkimo  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18odz8f/d_how_can_llms_be_aware_of_the_characters/</guid>
      <pubDate>Fri, 22 Dec 2023 12:37:38 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] 苹果研究人员推出 DeepPCR：一种新颖的机器学习算法，可并行化典型的顺序操作，以加速神经网络的推理和训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18odo0m/news_apple_researchers_unveil_deeppcr_a_novel/</link>
      <description><![CDATA[”论文通过各种应用展示了 DeepPCR 的有效性。它在多层感知器中实现了前向传递高达 30 倍的加速和后向传递高达 200 倍的加速。此外，该算法还应用于深度 ResNet 架构的并行训练和扩散模型的生成，从而使训练速度提高 7 倍，生成速度提高 11 倍。” 论文：https://arxiv.org/pdf/2309.16318.pdf 研究页面：https://machinelearning.apple.com/research/deepcr https://twitter.com/i/status/1735876638947348656   由   提交/u/paryska99  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18odo0m/news_apple_researchers_unveil_deeppcr_a_novel/</guid>
      <pubDate>Fri, 22 Dec 2023 12:19:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在第一个 epoch 中训练损失增加</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18odi68/d_increase_in_training_loss_while_in_the_first/</link>
      <description><![CDATA[      我正在训练一个使用感知器重采样器的字幕模型，就像 Flamingo 中的那样，唯一的区别是我不使用感知器重采样器不要将学习到的查询参数连接到键和查询以进行交叉关注。  一切都很顺利，直到我达到了数据集的大约 50%（第一个时期），这一切发生了。我还在测试其他架构，例如根本不使用感知器重采样器，而只是使用从视觉编码器获得的所有功能，并且我在大约 50% 的数据集上也得到了类似的结果，但不是在完全相同的迭代中（我使用的是种子，所以如果是数据问题，它应该完全相同，对吧？）。其他架构已经达到 8000 次迭代标记，并且训练损失没有像这样的任何增加......为什么会发生这种情况？ 训练损失约为 50%我的第一个纪元    由   提交 /u/AromaticCantaloupe19   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18odi68/d_increase_in_training_loss_while_in_the_first/</guid>
      <pubDate>Fri, 22 Dec 2023 12:09:54 GMT</pubDate>
    </item>
    <item>
      <title>[D]什么时候应该和不应该平衡不平衡的数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18oct9r/dwhen_should_and_shouldnt_you_balance_an/</link>
      <description><![CDATA[我似乎总是在这个问题上得到相互矛盾的答案，想法？    ;由   提交/u/Throwawayforgainz99  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18oct9r/dwhen_should_and_shouldnt_you_balance_an/</guid>
      <pubDate>Fri, 22 Dec 2023 11:26:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我尝试教 Mistral 7B 一门新语言（巽他语），它成功了！ （有点）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ocba4/p_i_tried_to_teach_mistral_7b_a_new_language/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ocba4/p_i_tried_to_teach_mistral_7b_a_new_language/</guid>
      <pubDate>Fri, 22 Dec 2023 10:54:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些便宜又好的设备可以用于 CUDA 训练？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18o99lr/d_what_are_some_cheap_and_ok_devices_for_training/</link>
      <description><![CDATA[在过去的四年里，我一直在大学服务器上训练我的所有模型，但是，随着我即将毕业 - 这根本行不通不再… 我一直在使用 Mac，但是想到毕业后无法运行 CUDA 就很难受了，哈哈 - 考虑设置尽可能便宜的计算机来训练 AI，但是，我当涉及到 Windows / Linux 计算机时，不知道从哪里开始 - 并且也不太了解所有 GPU 之间的区别 你们知道有什么便宜但性能好的 AI 计算机吗 -如果他们可以购买二手的，那就更好了！   由   提交/u/Middle_Stomach_6681   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18o99lr/d_what_are_some_cheap_and_ok_devices_for_training/</guid>
      <pubDate>Fri, 22 Dec 2023 07:22:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深入探讨 MMLU（“你比 LLM 更聪明吗？”）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ntia7/d_deep_dive_into_the_mmlu_are_you_smarter_than_an/</link>
      <description><![CDATA[在 MMLU 周围的所有喧嚣之后（例如 我的文章）我想我会制作一个界面来看看人类如何做，甚至是中间的LLM。它的名字叫你比法学硕士聪明吗？ &lt; p&gt;它向您提出 MMLU 的随机问题，并将您的答案与 LLM 的答案进行比较。单击“这是什么”按钮位于底部，了解有关其工作原理的更多详细信息。 感谢反馈！   由   提交/u/brokensegue  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ntia7/d_deep_dive_into_the_mmlu_are_you_smarter_than_an/</guid>
      <pubDate>Thu, 21 Dec 2023 18:21:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>