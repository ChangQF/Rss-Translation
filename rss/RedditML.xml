<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Fri, 09 Aug 2024 09:17:11 GMT</lastBuildDate>
    <item>
      <title>[P] 使用 GPT4o 与 langchain/chroma 进行体育分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enuzlp/p_using_gpt4o_with_langchainchroma_for_sports/</link>
      <description><![CDATA[大家好，我正在做一个业余项目，该项目有助于对历史比赛进行体育分析，进而有助于体育博彩。目前我只专注于 MLB，因为我想看看用例会如何发展。 我第一次尝试使用 openai 端点并加载所有相关的 JSON 对象，并将它们与提示一起发送到 GPT，看看我得到了什么。最终，上下文大小变得太大，我遇到的问题是它很昂贵。不过，返回的提示实际上相当不错，并且与数据相关。 我的第二次尝试是使用 Chroma/LangChain/GPT4o 设置 RAG。我让它工作了，但答案似乎都非常不准确，而且非常模糊。我所拥有的任何数据都没有显示在我所询问的任何提示中，或者在提示中根本没有提到任何正在玩游戏的玩家，而且在询问特定游戏时，它一直提到错误的游戏/团队。我假设我可能需要稍微调整一下矢量存储，但不确定如何使用色度来做到这一点。 我的问题是，设置某种流程的最佳方法是什么？我的最终结果是，我希望使用我提供的历史数据来回复，以便根据给出的所有统计数据对游戏可能是什么样子做出假设，同时也为 GPT 也留下一些推断的空间。 我在这方面还很陌生，所以到目前为止这是一个学习过程；请耐心等待。    提交人    /u/Previous_Impact1597   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enuzlp/p_using_gpt4o_with_langchainchroma_for_sports/</guid>
      <pubDate>Fri, 09 Aug 2024 09:02:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关我的求职机器学习项目的反馈</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enuq7p/d_seeking_feedback_on_my_machine_learning_project/</link>
      <description><![CDATA[大家好， 我正在申请政治学博士前奖学金，专注于计算冲突研究，并且我已经开发了一个示例项目来展示我的技能。我将不胜感激您可能提供的任何反馈或建议。 项目名称：机器学习用于恐怖主义数据分类 目标：应用机器学习技术对与冲突相关的文本进行分类，并根据全球恐怖主义数据库中的历史数据预测冲突结果。 展示的技能：机器学习、特征工程、模型训练和评估。 项目链接： 机器学习用于 1970 年至 2020 年东南亚恐怖主义数据分类的  职位描述： 政治学博士前研究员 我特别想听听您对以下方面的反馈：  项目概述的清晰度和结构。 所用方法和技术的有效性。 任何可以加强此类应用项目的其他元素。  提前感谢您的时间和见解！    提交人    /u/Lemmeaskyouonething   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enuq7p/d_seeking_feedback_on_my_machine_learning_project/</guid>
      <pubDate>Fri, 09 Aug 2024 08:45:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 24 数据集跟踪评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ent5sa/d_neurips_24_dataset_track_reviews/</link>
      <description><![CDATA[数据集和基准轨道评论应该在延迟后的今天发布。 我确信与主轨道相比，我们对此的关注度要小得多，但这可以作为讨论主题:)    提交人    /u/medcanned   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ent5sa/d_neurips_24_dataset_track_reviews/</guid>
      <pubDate>Fri, 09 Aug 2024 06:56:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习之旅</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enqwb3/d_machine_learning_journey/</link>
      <description><![CDATA[我很好奇大家的机器学习之旅！如果我想成为一名机器学习工程师，我该怎么做？上大学？如果是这样，我应该主修数据科学、计算机科学还是数学？训练营？还是我应该获得证书？我目前就读于一所技术社区学院，它有两门课程，一门是机器学习，另一门是人工智能。     提交人    /u/Initial-Proof-8338   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enqwb3/d_machine_learning_journey/</guid>
      <pubDate>Fri, 09 Aug 2024 04:37:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 泰卢固语的 ASR 效果良好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eno3bf/d_good_asr_for_telugu/</link>
      <description><![CDATA[我们正在努力寻找适合泰卢固语音频的良好 ASR。尝试过 Google Speech to Text 和 whisper-large-v3，但 WER 超过 40%。确切的用例是转录和分析通话录音，这些录音通常混合了泰卢固语和英语。  提前感谢您的帮助 🙏    提交人    /u/BitAffectionate4586   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eno3bf/d_good_asr_for_telugu/</guid>
      <pubDate>Fri, 09 Aug 2024 02:11:16 GMT</pubDate>
    </item>
    <item>
      <title>[d] ReFT 的实际示例：14 分钟内在 Llama3 上完成表征微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enk8wm/d_practical_example_of_reft_representation/</link>
      <description><![CDATA[几周前，Arxiv ReFT 论文第一作者郑轩吴与 Oxen.AI 首席执行官 Greg Schoeninger 合作，深入探讨了 ReFT：表示微调。 在明天（星期五）的 AI Water Cooler 中，Oxen 实习生 Eric 将介绍： &quot;我如何在 14 分钟内使用 ReFT 对 Llama3 进行微调&quot; ReFT 的 TLDR：不是通过参数进行微调，而是在隐藏状态中插入表示来指导模型。 Eric 将展示早期 Arxiv Dive 的实际实现。 有用的细节：  AI Water Cooler 是深度技术不太正式、未经记录的空间 8 月 9 日星期五，太平洋时间上午 10:00 定期日历邀请：https://oxen.ai/community YouTube https://youtu.be/to2oKwnknUk?si=LmMMYxoryOn0UCwh Arxiv 论文链接：https://arxiv.org/pdf/2404.03592     提交人    /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enk8wm/d_practical_example_of_reft_representation/</guid>
      <pubDate>Thu, 08 Aug 2024 23:10:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关 Perplexity Sonar 模型的深入信息：系统消息、上下文处理和 API 限制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enk3mw/d_seeking_indepth_information_on_perplexitys/</link>
      <description><![CDATA[除了 Perplexity 文档中提供的内容外，是否还有其他关于 Sonar 模型的文档？ 我正在寻找有关“系统消息”、提示和/或第一个用户请求之间的行为差​​异的更多信息。据我了解，查询是基于“用户”消息生成的，查询生成会忽略“系统”消息。那么这个“系统”消息的用途到底是什么？这些示例通常使用简短的 3-4 个单词的短语，但 Sonar 模型是否支持更复杂的系统指令（类似于它们所训练的模型）？ 此外，在线模型如何处理多轮对话？查询生成和 RAG 使用什么上下文？我理解这些模型适用于单轮交互，而“聊天”版本可用于多轮对话。 这引出了我关于上下文长度的问题。在线模型声称拥有 128K 上下文，但这在实践中似乎无法实现。如果用户消息太长，查询生成效率会降低，检索到的相关结果也会减少。即使多轮聊天也无法实现更高的上下文，因为质量会显著下降。 值得注意的是，作为“源”提供给模型的标记数量通常在全球范围内在 2-3K 范围内，但通常会少得多，具体取决于问题的复杂性（通过 API）。 有人对这些问题有见解吗？工作人员可以给我提供更详细的信息吗？ 提前谢谢！    提交人    /u/Distinct-Target7503   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enk3mw/d_seeking_indepth_information_on_perplexitys/</guid>
      <pubDate>Thu, 08 Aug 2024 23:03:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI：API 中的结构化输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1endf5w/d_openai_structured_outputs_in_the_api/</link>
      <description><![CDATA[https://openai.com/index/introducing-structured-outputs-in-the-api/ 只是好奇，为什么这是一件大事？你看到任何用例了吗？    提交人    /u/dmpetrov   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1endf5w/d_openai_structured_outputs_in_the_api/</guid>
      <pubDate>Thu, 08 Aug 2024 18:27:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] DistilBERT 基础多语言（大小写）葡萄牙语</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en74uf/d_distilbert_base_multilingual_cased_for/</link>
      <description><![CDATA[有人用过 DistilBERT 基础多语言（大小写）来处理葡萄牙语吗？如果是，你的结果如何？它好用吗？ 提前致谢。    提交人    /u/mr_house7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en74uf/d_distilbert_base_multilingual_cased_for/</guid>
      <pubDate>Thu, 08 Aug 2024 14:16:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] FlexAttention：PyTorch 的灵活性与 FlashAttention 的性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</link>
      <description><![CDATA[https://pytorch.org/blog/flexattention/    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</guid>
      <pubDate>Thu, 08 Aug 2024 13:49:55 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 我需要什么数学背景才能阅读 Le Cam 的《充分性和近似充分性》论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en55pb/research_what_mathematical_background_do_i_need/</link>
      <description><![CDATA[嗨， 我是一名统计学家，出于研究目的，我想阅读 Le Cam 提到的论文。我遇到的困难是它使用了诸如向量格、正正则化线性函数、格对偶等术语。 因此，我的问题是：我需要什么样的数学先决条件才能阅读此类论文？ 我做过标准线性代数、实分析（单变量和多变量）、测度论、概率论内容、一些点集拓扑，但从未见过这样的对象，所以我认为这可能与抽象代数有关，但我不知道从哪里开始才能读懂这篇文章。 任何帮助都将不胜感激。谢谢！   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en55pb/research_what_mathematical_background_do_i_need/</guid>
      <pubDate>Thu, 08 Aug 2024 12:52:00 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何使用学习率来匹配论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emxx6a/d_how_to_use_learning_rate_to_match_papers/</link>
      <description><![CDATA[你好！ 我正在复现一些论文，但我一直面临训练不稳定的问题，除非我降低论文中的学习率，因为在几篇论文中我发现我可能是错的。 假设我们有一篇论文，使用 M GPU 以批量大小 N（每个 GPU）训练网络，以学习率为 LR 进行训练。训练几乎总是使用 float16 和 adam/adamw。我正在使用 pytorch amp 进行混合精度训练。 大多数论文要求我正在训练（TTS 任务）在 16/32 gpu 上进行训练，但我不想进行分布式训练，我只使用更快的 GPU 进行 2 倍、4 倍或 8 倍训练，但使用梯度累积（G）。 不同的框架对如何在多 GPU 环境中指定学习率的定义不同。 我现在正在使用 Accelerate，它建议将学习率乘以使用的 GPU 数量，但不清楚如何处理梯度累积以及论文最初如何定义学习率。 我的选择是：  LR - 按原样使用 LR * M - 乘以论文中原始 GPU 的数量 LR * M / G - 乘以不使用梯度累积的实际 GPU 数量 LR * G - 乘以按梯度累积次数  现在我已经尝试了#3，但是梯度爆炸，我除以二，它通常是稳定的，但它与任何其他公式都不匹配。 另外，不清楚论文中使用了什么框架（论文主要来自 Meta 和 Microsoft），这可能会影响 LR 不匹配。    提交人    /u/stevekite   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emxx6a/d_how_to_use_learning_rate_to_match_papers/</guid>
      <pubDate>Thu, 08 Aug 2024 05:27:50 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 多模式人工智能聊天机器人令人费解的失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emi095/research_the_puzzling_failure_of_multimodal_ai/</link>
      <description><![CDATA[      https://preview.redd.it/ummnvenf1ahd1.png?width=2592&amp;format=png&amp;auto=webp&amp;s=7115ba5de026ada17b0636ec2fa3c3151b3e5eb6 GPT-4o 和 Gemini 等聊天机器人模型在理解图像和文本方面表现出了令人印象深刻的能力。然而，它们是否能模仿人类的一般智力和推理能力尚不清楚。为此，PuzzleVQA 是多模式拼图的新基准，用于探索当前模型的极限。如上所示，即使是 GPT-4V 这样的模型也很难理解儿童可以掌握的简单抽象模式。 https://preview.redd.it/7l5fmuys1ahd1.png?width=2716&amp;format=png&amp;auto=webp&amp;s=337118dbc55230637cec1b08b90ae943746ddbb0 尽管谜题看似简单，但我们观察到当前多模态 AI 模型的表现却出奇地差。值得注意的是，与人类的表现仍然存在巨大差距。因此，自然而然地出现了一个问题：是什么导致了模型的失败？为了回答这个问题，我们进行了瓶颈分析，逐步为模型提供真实“提示”，例如用于感知或推理解释的图像标题。如上所示，我们发现领先的模型在视觉感知和归纳推理方面面临关键挑战。这意味着他们无法准确地感知图像中的物体，并且在识别正确的模式方面也很差。 https://arxiv.org/abs/2403.13315    提交人    /u/chiayewken   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emi095/research_the_puzzling_failure_of_multimodal_ai/</guid>
      <pubDate>Wed, 07 Aug 2024 17:33:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>