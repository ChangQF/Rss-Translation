<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 01 Jan 2025 01:21:39 GMT</lastBuildDate>
    <item>
      <title>[P] 为什么我的 LSTM 总是预测“Ġ”字符/U-0120？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqs7k9/p_why_does_my_lstm_always_predict_the_ġ_char_u0120/</link>
      <description><![CDATA[Ġ 表示带有 BPE 标记的空格，所以我认为这只是因为它们太多了。我应该删除所有空格并以此训练我的模型吗？    提交人    /u/SnazzySnail9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqs7k9/p_why_does_my_lstm_always_predict_the_ġ_char_u0120/</guid>
      <pubDate>Wed, 01 Jan 2025 00:54:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 内容审核的多模式模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqmcx7/r_multimodal_models_for_content_moderation/</link>
      <description><![CDATA[大家好， 您能否分享一些关于多模态模型（包括用于内容审核的 VLM）的优秀研究论文。用例可能是检测仇恨模因、图像中的暴力等。    提交人    /u/weqsd6777   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqmcx7/r_multimodal_models_for_content_moderation/</guid>
      <pubDate>Tue, 31 Dec 2024 19:42:03 GMT</pubDate>
    </item>
    <item>
      <title>使用地标进行视频分类的推荐模型[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqmb30/recommended_models_for_video_classification_using/</link>
      <description><![CDATA[有任何推荐的开源模型吗，最好是在手上预先训练过的？正在考虑 MMPose。    提交人    /u/Altruistic-Road-9453   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqmb30/recommended_models_for_video_classification_using/</guid>
      <pubDate>Tue, 31 Dec 2024 19:39:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在进行出版基准测试时排除不可重复的最先进的方法是否可以接受？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqm6vd/r_is_it_acceptable_to_exclude_nonreproducible/</link>
      <description><![CDATA[我开发了一种新算法，并准备为研究出版物评估其性能。但是，我遇到了一个挑战：一些最新的方法缺乏公开可用的代码，因此很难或无法重现。 在发布研究工作的背景下，是否可以将这些方法排除在我的比较之外，而是专注于对具有公开可用实现的方法和基线进行基准测试？ 研究界对这个问题的普遍共识是什么？在发布结果时，是否有推荐的最佳实践来解决缺乏可重现代码的问题？    提交人    /u/Training_Bet_7905   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqm6vd/r_is_it_acceptable_to_exclude_nonreproducible/</guid>
      <pubDate>Tue, 31 Dec 2024 19:33:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 肺部声音音频分类模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqlj46/d_models_for_audio_classification_of_lung_sounds/</link>
      <description><![CDATA[所以我一直在研究一个关于肺音音频分类的项目。该项目旨在使用深度学习模型和音频预处理技术检测各种呼吸系统疾病（例如肺炎、哮喘、慢性阻塞性肺病）。主要目标是比较不同音频预处理方法（梅尔频率倒谱系数 - MFCC、每通道能量归一化 - PCEN 和频谱图）在从声音数据中检测各种肺部疾病方面的有效性。该方法将涉及将这些技术应用于全面的肺音数据集，并使用不同的机器学习模型评估其性能。根据我的研究，我相信 PCEN 的预处理方法会比频谱图产生更高的准确度结果。现在，我在三种预处理方法中使用相同的模型来保持项目的一致性，并且只关注预处理方法的效果。但出于某种原因，PCEN 预处理方法的表现并不像我想象的那么好。每个模型的架构大致如下所示。有人能告诉我该怎么做才能改善我的项目，让 PCEN 获得更好的结果吗？我使用 ICBHI 2017 Challenge 数据集来进行这项工作。 对于 Spectrogram 的验证损失约为 0.07，对于 PCEN 的验证损失则更糟。不过，MFCC 应该比两者都差。 def Conv2DSpec(N_CLASSES=6, SR=8000, DT=6.0): input_shape = (int(SR*DT), 1) i = get_melspectrogram_layer(input_shape=input_shape, n_mels=128, pad_end=True, n_fft=512, win_length=400, hop_length=160, sample_rate=SR, return_decibel=True, input_data_format=&#39;channels_last&#39;, output_data_format=&#39;channels_last&#39;) x = LayerNormalization(axis=2, name=&#39;batch_norm&#39;)(i.output) x = layer.Conv2D(8, kernel_size=(7,7),activation=&#39;tanh&#39;, padding=&#39;same&#39;, name=&#39;conv2d_tanh&#39;)(x) x =层。MaxPooling2D（pool_size=（2,2），padding=&#39;same&#39;，name=&#39;max_pool_2d_1&#39;）（x）x = 层。Conv2D（16，kernel_size=（5,5），激活=&#39;relu&#39;，padding=&#39;same&#39;，name=&#39;conv2d_relu_1&#39;）（x）x = 层。MaxPooling2D（pool_size=（2,2），padding=&#39;same&#39;，name=&#39;max_pool_2d_2&#39;）（x）x = 层。Conv2D（16，kernel_size=（3,3），激活=&#39;relu&#39;，padding=&#39;same&#39;，name=&#39;conv2d_relu_2&#39;）（x）x = 层。MaxPooling2D（pool_size=（2,2），padding=&#39;same&#39;，name=&#39;max_pool_2d_3&#39;）（x）x = 层。Conv2D（32， kernel_size=（3,3），激活=&#39;relu&#39;，padding=&#39;same&#39;，name=&#39;conv2d_relu_3&#39;）（x）x = layer.MaxPooling2D（pool_size=（2,2），padding=&#39;same&#39;，name=&#39;max_pool_2d_4&#39;）（x）x = layer.Conv2D（32，kernel_size=（3,3），激活=&#39;relu&#39;，padding=&#39;same&#39;，name=&#39;conv2d_relu_4&#39;）（x）x = layer.Flatten（name=&#39;flatten&#39;）（x）x = layer.Dropout（rate=0.2，name=&#39;dropout&#39;）（x）x = layer.Dense（64，激活=&#39;relu&#39;，activity_regularizer=l2（0.001），name=&#39;dense&#39;）（x）o = layer.Dense（N_CLASSES，激活=&#39;softmax&#39;，name=&#39;softmax&#39;）（x）模型 = 模型（输入 = i.input，输出 = o，名称 = &#39;2d_convolution&#39;）模型.compile（优化器 = &#39;adam&#39;，loss = &#39;categorical_crossentropy&#39;，metrics = [&#39;accuracy&#39;]）返回模型    由   提交  /u/IKnowUCantPvp   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqlj46/d_models_for_audio_classification_of_lung_sounds/</guid>
      <pubDate>Tue, 31 Dec 2024 19:02:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] [帮助] 我依稀记得听说过最近发布的 ML/AI 大学排名。有人知道吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqkfmd/d_help_i_vaguely_remember_hearing_about_a/</link>
      <description><![CDATA[上周我在浏览抖音时，看到了一个关于最近发布的 ML/AI 大学排名的视频。这应该是由《自然》或《科学》等大型杂志进行的。我依稀记得有一所中国机构排在前五名。 我当时头脑不太清醒，什么都记不清了。不知为何，我在抖音历史记录中找不到那个视频。我一直在尝试寻找那个排名，但没有结果。 有人见过类似的东西吗？    提交人    /u/Economy-Feed-7747   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqkfmd/d_help_i_vaguely_remember_hearing_about_a/</guid>
      <pubDate>Tue, 31 Dec 2024 18:10:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过图像自动进行事件分类和参与者识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqigpg/p_automating_event_classification_and_attendee/</link>
      <description><![CDATA[大家好！ 我计划构建一个项目，根据相应的事件将图像分类到文件夹中，并识别这些事件中出现的人员。最初，该模型将把事件标记为 unknown_event_1、unknown_event_2 等，把个人标记为 unknown_person_1、unknown_person_2 等，并能够在以后手动更新这些标签。最终目标是自动检测事件并根据此分类向参加这些事件的人员授予访问权限。 我正在寻求有关从哪里开始的指导、框架或库的建议以及任何可以帮助启动该项目的开源代码库。如果您有与此相关的经验或资源，我们将不胜感激您的意见。 提前谢谢您！ #AI    提交人    /u/suman077   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqigpg/p_automating_event_classification_and_attendee/</guid>
      <pubDate>Tue, 31 Dec 2024 16:38:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] QuantumLLMInstruct：用于量子计算的 500k LLM 指令调整数据集，其中包含问题解决方案对。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqh3uh/r_quantumllminstruct_a_500k_llm_instructiontuning/</link>
      <description><![CDATA[🚀 介绍 QuantumLLMInstruct (QLMMI)：最大的量子计算数据集！ 我很高兴地宣布我的论文QuantumLLMInstruct (QLMMI)，这是一个突破性的数据集，包含超过500,000 个遵循指令的问题解决方案对，专门用于微调 LLM 以解决量子计算问题 - 同类中最全面的数据集！ 🌌 QLMMI 有何独特之处？  涵盖 90 多个主要种子域 和数百个由 LLM 自主生成的子域。 专为 LLM 指令微调 而设计，可解决以下主题的复杂量子挑战： 合成汉密尔顿量 QASM 代码生成 Jordan-Wigner 变换 Trotter-Suzuki 分解  通过 思想链 (CoT) 和 ToRA 等高级推理技术增强，确保数学精度和多样性。  开放和协作 使用 Qwen-2.5-Coder 构建模型，QLMMI 是完全开源的，代码和数据集可在 HuggingFace 上找到。 https://arxiv.org/pdf/2412.20956 https://huggingface.co/datasets/BoltzmannEntropy/QuantumLLMInstruct https://huggingface.co/spaces/BoltzmannEntropy/QuantumLLMInstruct 祝好，   由    /u/QuanstScientist  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqh3uh/r_quantumllminstruct_a_500k_llm_instructiontuning/</guid>
      <pubDate>Tue, 31 Dec 2024 15:34:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 不使用参考，使用绝对比例进行物体检测的最佳方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqg7sl/r_best_approach_for_object_detection_with/</link>
      <description><![CDATA[正在进行物体间隙测量项目。需要获取间隙距离（以厘米为单位），没有参考或标记 限制： - 不能使用参考物体（需要通用解决方案） - 不能使用物体尺寸（差异很大） - 必须预测绝对测量值（米） - 相机内在特性各不相同 考虑使用带有回归头的 CNN 进行间隙预测，您觉得怎么样？ 我应该使用吗？  多视图变换器用于关联视图并学习空间关系 或者仅将单独的图像作为通道传递并在输入中将它们连接起来？  融合多个视图以预测没有物理参考的绝对测量值的最佳架构是什么？在这里，注意力机制是否比通道连接更好？ 我尝试过的方法： -单视图计量（显然是基于参考的，所以在这里不起作用） -单深度模型（即使名称中带有度量，也难以达到绝对值，看看 Metric3D2） -立体视觉（立体匹配和视差） 问题：  哪种架构设计最适合解决这个问题？ 文献中是否已经解决了类似的问题？（我找不到任何相关问题）  寻找来自类似问题的见解，并在扩展当前数据集之前进行验证。有什么想法吗？    提交人    /u/TheWingedCucumber   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqg7sl/r_best_approach_for_object_detection_with/</guid>
      <pubDate>Tue, 31 Dec 2024 14:51:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] PPO 模型操作在验证期间没有改变</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqfmg8/d_ppo_model_actions_not_changing_during_validation/</link>
      <description><![CDATA[因此，我有一个 ppo 算法，正在使用它来训练交易代理，因此问题是所有验证操作对于不同的情节都是相同的。当检查梯度和概率比时，它们似乎在移动，甚至输出层的权重也在变化，但从初始化阶段开始，操作的概率似乎非常相似。因此，我每集有 3000 步，大约有 180 个交易轨迹，每个轨迹都有 6 个训练时期，因此在第三集之后，验证操作仍然相同。我做错什么了吗？如果需要，愿意分享更多信息，请提供帮助，我一直在研究这些问题，任何帮助都将不胜感激     提交人    /u/sk3ptica1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqfmg8/d_ppo_model_actions_not_changing_during_validation/</guid>
      <pubDate>Tue, 31 Dec 2024 14:20:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用整流流和 FLUX 架构的新型 SOTA 文本转音频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq9hx1/d_new_sota_text_to_audio_model_using_rectified/</link>
      <description><![CDATA[发布采用整流流匹配和偏好优化训练的全新 TTA 模型！完全开源。在 GPU 上推理大约需要 3 秒。    提交人    /u/Internal_War3919   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq9hx1/d_new_sota_text_to_audio_model_using_rectified/</guid>
      <pubDate>Tue, 31 Dec 2024 07:17:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 生物医学编码器模型的当前 SOTA 是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq3zwq/d_whats_the_current_sota_for_biomedical_encoder/</link>
      <description><![CDATA[您认为用于创建向量嵌入的生物医学模型的当前 SOTA 是什么？我最感兴趣的是句子相似性（以及一些文档检索）。 我个人认为 PubMedBERT 和 BioBERT 是一个非常好的基线，但有没有您更信任的微调？ 您甚至认为这个领域的一个好基准是什么？我发现 MTEB 太笼统，而 BioASQ、BIOSSES、MedSTS 太具体，无法衡量任何有意义的东西。你们觉得呢？    提交人    /u/ayushwashere   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq3zwq/d_whats_the_current_sota_for_biomedical_encoder/</guid>
      <pubDate>Tue, 31 Dec 2024 02:03:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 为什么 MAMBA 没有流行起来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpg91o/d_why_mamba_did_not_catch_on/</link>
      <description><![CDATA[从所有的炒作来看，MAMBA 似乎将取代 transformer。它速度很快，但仍保持了 transformer 的性能。训练期间为 O(N)，推理期间为 O(1)，并且准确率相当高。那么为什么它没有占据主导地位呢？状态空间模型的状态是什么？    提交人    /u/TwoSunnySideUp   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpg91o/d_why_mamba_did_not_catch_on/</guid>
      <pubDate>Mon, 30 Dec 2024 05:39:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</guid>
      <pubDate>Sun, 29 Dec 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>