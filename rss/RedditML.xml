<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Fri, 14 Feb 2025 09:17:45 GMT</lastBuildDate>
    <item>
      <title>[D]扩散模型及其统计不确定性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip6doi/d_diffusion_models_and_their_statistical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我对扩散模型的统计信息有问题。在诸如DDPM和DDIM之类的方法中，可以在任何扩散时间步骤中获得清洁图像（X0）的估计值。当然，此估算有一些相关的错误，但是似乎没有纸上关于此的论文。我在这里错过了什么吗？这是我正在进行的一项研究。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unk0wnvar     [link]   ＆＃32;   [commistion]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip6doi/d_diffusion_models_and_their_statistical/</guid>
      <pubDate>Fri, 14 Feb 2025 08:50:36 GMT</pubDate>
    </item>
    <item>
      <title>[d]如何处理蒸馏中的学生与教师模型的不同数据分布？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip5d07/d_how_to_deal_with_different_data_distribution/</link>
      <description><![CDATA[在一小时和B型3天。 我想蒸馏出B模型A建模，以使A模型可以从模型B中的其他信号中学习对于A和B模型来说，这应该是正确的，因此转移学习。 问题是B在训练过程中比模型A所看到的数据更多，并且可以根据更长的时间进行预测窗口及其真正的概率不同。即使使用PLATT缩放尺度或根据自己的分布进行校准，从理论上讲，它们也将彼此之间存在不同的数据分布，例如 我对如何从较长的时间窗口进行蒸馏而失去了不同的阳性率。自适应加权，但没有一个具体解决这个问题……  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tough_palpitation331     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ip5d07/d_how_to_to_deal_with_with_different_data_distribution/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip5d07/d_how_to_deal_with_different_data_distribution/</guid>
      <pubDate>Fri, 14 Feb 2025 07:33:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML调试面试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip4ypj/d_ml_debugging_interview_for_experienced_roles/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您好，&lt; / p&gt; 最近，我一直在为应用的ML / ML研究工程师角色准备采访。我想练习更多的技能来调试Pytorch或任何ML管道。我想知道是否有人以前经历过这种采访，并且可以为如何做最好的准备。如果您还可以分享此类面试问题的示例，那就太好了。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unessionarybelt750     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip4ypj/d_ml_debugging_interview_for_experienced_roles/</guid>
      <pubDate>Fri, 14 Feb 2025 07:04:38 GMT</pubDate>
    </item>
    <item>
      <title>[d]您能否推荐一个支持低语的良好无服务器GPU提供商？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip2oko/d_can_you_recommend_a_good_serverless_gpu/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是我到目前为止的测试结果。还没有成功：  runpod  - 对他们在服务质量和成本方面的更快的预构建模板感到满意。但是，我正在面临构建 https://github.com/yccheok/whisperx-worker 在他们的无服务器解决方案上。仍在等待客户支持的响应。 梁云 - 比runpod更容易设置。对服务质量不满意。很大一部分任务仍然陷入了“待处理”。无限期。同样，定价缺乏透明度，其成本比预期的10倍。 烟花 - 无需设置。对服务质量不满意。 （使用OpenAI Whisper Turbo V3进行测试，而不是Whisperx。）该服务在测试过程中几次下降，并且支持记录显示，每月发生了多次的情况。 如果您在无服务器环境中有经验您可以推荐一个可靠的服务提供商吗？ 谢谢。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/yccheok     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip2oko/d_can_you_recommend_a_good_serverless_gpu/</guid>
      <pubDate>Fri, 14 Feb 2025 04:38:46 GMT</pubDate>
    </item>
    <item>
      <title>[d]如何根据其音频功能自动化命名批量音频样本？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip0rnt/d_how_to_automate_naming_bulk_audio_samples_based/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好。 ，如果有人可以为我澄清一下，我将非常感谢它。我会切下它。我正在寻找一个可以分析音频文件的特征和生成描述性关键字或文本标签的工具，＆quot＆quot “深色环境垫环路”或“高能合成器循环”。我需要使用10k+音乐样本（每个大约5到20秒）。可以实现这一目标的嵌入，但是到目前为止，我没有任何运气，因此，如果有人可以将我指向正确的方向，或者至少告诉我没有大型团队是不可能的，我将非常感谢。&lt;&lt;&lt;&lt;&lt;&lt;&lt; /p&gt; 向任何试图提供帮助的人，谢谢您。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/krushur     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ip0rnt/d_how_how_to_automate_naming_naming_naming_bulk_audio_samples_basples_based/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip0rnt/d_how_to_automate_naming_bulk_audio_samples_based/</guid>
      <pubDate>Fri, 14 Feb 2025 02:52:27 GMT</pubDate>
    </item>
    <item>
      <title>[P]纯C中的GPT-2（以及完整的CUDA工作室）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioybio/pgpt2_in_pure_cand_full_cuda_worklogs_to_come/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  并行计算是听起来令人生畏但对现代世界绝对必不可少的事情之一。从高频交易（HFT）到设备AI，最大程度地减少资源，同时最大程度地提高性能非常重要，并且随着我们转向更好的开源LLM，可能会成为瓶颈。  首先要潜入这个空间，我启动了一个项目，我以平原，幼稚和不优化的（边界愚蠢）C实现了GPT-2体系结构，而没有很大的依赖性。为什么？因为在最基本的层面上了解问题是有效优化它的唯一方法。大多数教程从基础知识开始（例如优化矩阵乘法，然后它们可能会介入基本操作/创建基于圆圈的渲染器），但是真实的生产级cuda，例如您在乔治·霍茨（George Hotz）的Tinygrad或Karpathy的LLM中看到的内核.c或类似项目是完全不同的事情。几乎没有任何结构化资源来弥合差距。 ，我的目标是吗？ ➡️从这个简单的实现开始，然后逐步优化。 ➡️学会从头开始构建cuda内核，基准测试并将它们与其他解决方案进行比较。 ➡️返回此GPT返回此GPT返回此GPT -2实施，再次逐步挑选它，看看我可以做到的速度更快，更精细，更有效。 ，我将使用完整的工作室  repolink： https://github.com/angry-kratos/gpt-2-in -c    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/atronos_kronios     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioybio/pgpt2_in_pure_cand_fule_fure_full_cuda_worklogs_to_to_to_to_come/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioybio/pgpt2_in_pure_cand_full_cuda_worklogs_to_come/</guid>
      <pubDate>Fri, 14 Feb 2025 00:43:58 GMT</pubDate>
    </item>
    <item>
      <title>[r]基于LLM的突变引导的元测试生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iou1uj/r_mutationguided_llmbased_test_generation_at_meta/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/ahmedmostafa16     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iou1uj/r_mutationguided_llmbased_test_generation_at_meta/</guid>
      <pubDate>Thu, 13 Feb 2025 21:26:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlignRec在多模式建议中优于SOTA模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioo1ta/r_alignrec_outperforms_sota_models_in_multimodal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   alignrec，在 alignrec中引入：在多模式建议中对齐和训练（cikm &#39;24），解决多模式建议系统中的错误对准。传统方法难以整合各种内容类型（文本，图像和分类ID）到语义差距。 AlignRec通过优化三个对齐任务来解决此问题：ICA INTER-CONTENT（ICA），CONTENT类别（CCA）和用户项目（UIA）。 ICA通过基于注意力的编码器将语义表示统一，CCA使用对比度学习增强特征对齐，UIA通过余弦相似性损失来完善用户项目表示。   关键的Innovation是Alignrec的两阶段训练：预 - 培训使视觉和文本数据对齐，同时微型调整结合了用户行为以进行优化的建议。在亚马逊数据集中测试，它的表现优于九种SOTA模型，在长尾建议方面表现出色。通过弥合多模式语义差距，AlignRec提高了准确性和鲁棒性，推进了多模式AI驱动的建议。 以深入研究框架并结果，请参阅此处的完整纸张文章： https://www.shaped.ai/blog/multimodal-alignment-for-recmmentations   &lt; /div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/skeltzyboiii     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioo1ta/r_alignrec_outperforms_sota_moda_models_in_multimodal/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioo1ta/r_alignrec_outperforms_sota_models_in_multimodal/</guid>
      <pubDate>Thu, 13 Feb 2025 17:13:07 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何从头开始进行ML研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ion90w/d_how_you_do_ml_research_from_scratch/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   有人在顶级ML会议（NIPS，ICML，ICLR）或面向域的会议（CVPR，ICCV，ACL，EMNLP，KDD）上发布了作品，Sigir）。 1。如何从0到第一张纸？ 2。您的技能（Pytorch或域知识）是多少？ 3。您遵循的整个过程是什么善于实施您的想法？ 4。您如何提出想法和解决方案？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/antelopewilling2928      r/machinelearning/注释/1ion90w/d_how_you_do_do_ml_research_from_scratch/“&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ion90w/d_how_you_do_ml_research_from_scratch/</guid>
      <pubDate>Thu, 13 Feb 2025 16:40:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] Swe-Agent是Swe Bench Lite上的新开源SOTA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iolpvo/r_sweagent_is_the_new_opensource_sota_on_swebench/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   swe-agent是一种开源软件工程代理，可与任何类型的型号一起使用。我们的1.0版本增加了许多新功能：大规模并行运行；基于云的部署；具有工具捆绑包的广泛可配置性；新命令行接口＆amp;公用事业。完全开源（MIT），广泛的配置，易于破解。由于它将LITELLM用于LM接口，因此您可以与本地LM一起使用它：我们已经与QWEN一起使用了它，而其他社区成员已将其与Llama一起使用。   https://github.com/swe-agent/swe-agent    swe-agent现在由我们的新swe--提供支持REX软件包（也获得了MIT许可），这是一款轻巧的通用沙盒代码执行引擎，支持本地Docker，AWS，Modal Deployments  https：https：https：https：https： //github.com/swe-agent/swe-rex 。您可以使用它来轻松地从头开始使用代码执行，而无需弄清楚如何与运行的Docker容器进行通信！  swe-agent是由普林斯顿大学＆amp;开发的。斯坦福大学。如果您有任何疑问，我们将在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ofirpress     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iolpvo/r_sweagent_is_the_new_new_opensource_sota_sota_on_swebench/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iolpvo/r_sweagent_is_the_new_opensource_sota_on_swebench/</guid>
      <pubDate>Thu, 13 Feb 2025 15:35:03 GMT</pubDate>
    </item>
    <item>
      <title>[R]企业中的文本到SQL：比较方法和对我们有用的方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iojc1f/r_texttosql_in_enterprises_comparing_approaches/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  嗨hivery！  text-to-sql是一个流行的Genai用例，我们最近与一些企业合作。在这里分享我们的学习！ 这些企业已经尝试了不同的方法 - 使用rag，使用gpt-4O（例如GPT-4O），甚至是使用Autogen和Crew的GPT-4O，甚至基于代理的方法，将OR-LLM等最佳的LLM进行。但是它们以85％的精度撞到了天花板，面临超过20秒的响应时间（主要是由于错误的列出现的错误），并处理了使缩放硬缩放的复杂工程。 我们发现了这种微调在特定于商业的查询-SQL Pairs上的开放量LLM具有95％的精度，响应时间降低到7秒以下（通过消除故障恢复）和简化的工程。这些自定义的LLM保留了域内存，从而导致了更好的性能。 我们在上进行了比较。 sql-the-the-the-ultimate-guide-for-2025-3fa4e78cbdf9“&gt;中等。让我知道您的想法，如果您看到了更好的方法来解决此问题。 = Webp＆amp; s = 88251E0CFA246F2BF1F779E708AB03A96A3C0255“&gt; https：//preview.redd.i 246F2BF1F779E708AB03A96A3C0255    &lt; ！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sircomprehense7453     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iojc1f/r_texttosql_in_enterprises_comparing_approaches/</guid>
      <pubDate>Thu, 13 Feb 2025 13:44:21 GMT</pubDate>
    </item>
    <item>
      <title>[r]自动化能力发现：使用基础模型自探索和评估AI的能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iofk29/r_automated_capability_discovery_using_foundation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了一个称为自动化能力发现（ACD）的框架，该框架使用一个基础模型系统地探索和评估功能另一个模型。核心思想是将能力发现视为一种实验科学，其中一个模型充当科学家生成假设和设计测试。 关键技术点： - 框架由四个主要组成部分组成：任务生成，执行，执行，执行，执行，执行，评估和分析 - 使用提示策略来使评估器模型产生多样的有意义的测试 - 实现反馈循环，其中测试结果在未来的任务生成中为未来的任务提供了信息 - 评估包括二进制成功/失败和详细分析 - 对GPT -4进行了测试，Claude，Claude，Claude，和Llama模型作为评估者和受试者 结果： - 发现了数千个先前无证件的功能 -  AI评估者和人类在能力评估上的验证之间的共识为89％ - 生成的测试涵盖了从基本（ARITHMMETEC）到基本的功能类别复杂的（创意写作） - 成功识别已知模型限制 - 显示自动化和手动评估方法之间的密切相关性 我认为这种方法可以改变我们理解和评估AI系统的方式。我们可以对模型功能进行持续的自动探索，而不是仅依靠预定义的基准或手动测试。这对于快速测试新模型并确定意外能力或局限性特别有价值。 我认为，主要的挑战将确保评估器模型不受与主题模型相同的盲点的限制。还有一个问题是，这是如何将语言模型超出其他AI体系结构的概括。  tldr：新框架使用AI模型自动发现和评估其他AI模型的功能，并显示出与人类评估和人类评估和人类评估的强烈同意查找数千个以前未知的能力。   。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iofk29/r_automated_capability_discovery_using_foundation/</guid>
      <pubDate>Thu, 13 Feb 2025 09:43:22 GMT</pubDate>
    </item>
    <item>
      <title>[r]“ O3在2024年IOI上获得了金牌，并获得了与精英人类竞争对手相当的代码供应”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1io4c7r/r_o3_achieves_a_gold_medal_at_the_2024_ioi_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    我们表明，应用于大型语言模型（LLM）的强化学习可显着提高复杂的编码和推理任务的性能。此外，我们将两种通用推理模型 -  OpenAI O1和O3的早期检查站与域特异性系统O1-IOI进行了比较，该系统使用手工设计的推理策略，旨在在2024年在Informatics中竞争（IOI）（IOI） ）。我们与O1-IOI一起在IOI 2024中现场直播，并使用手工制作的测试时间策略排名第49个百分位。在轻松的竞争限制下，O1-IOI获得了金牌。但是，在评估后来的O3之类的模型时，我们发现O3无需手工制作的领域特定策略或放松的约束就可以实现黄金。我们的发现表明，尽管O1-IOI等专门的管道可实现可靠的改进，但扩展的通用O3模型超过了这些结果，而无需依赖手工制作的推理启发式方法。值得注意的是，O3在2024年IOI上获得了金牌，并获得了与精英人类竞争对手的评级。总体而言，这些结果表明，扩展通用强化的增强学习，而不是依靠特定领域的技术，为推理领域（例如竞争性编程）提供了良好的途径。  &gt;  https://arxiv.org/abs/2502.06807       &lt;！ ＆＃32;提交由＆＃32; /u/u/we_are_mammals     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1io4c7r/1io4c7r/r_o3_achieves_a_medal_medal_medal_medal_medal_the_2024_ioi_ioi_and/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1io4c7r/r_o3_achieves_a_gold_medal_at_the_2024_ioi_and/</guid>
      <pubDate>Wed, 12 Feb 2025 22:55:17 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      对于那些寻找工作的人请使用此模板  &lt; p&gt;想要被录用：[位置]，薪水期望：[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简短概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，这个社区是适合有经验的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>