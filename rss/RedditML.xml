<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Sun, 04 Aug 2024 06:19:42 GMT</lastBuildDate>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] arc-like，用于参加 ARC 奖或进行推理研发的数据生成器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eje0c5/p_arclike_a_data_generator_for_competing_at_the/</link>
      <description><![CDATA[    /u/BayesMind   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eje0c5/p_arclike_a_data_generator_for_competing_at_the/</guid>
      <pubDate>Sat, 03 Aug 2024 21:08:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] 稳定快速 3D 纸质攻略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eja57y/r_stablefast_3d_paper_walkthrough/</link>
      <description><![CDATA[        提交人    /u/DisciplinedPenguin   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eja57y/r_stablefast_3d_paper_walkthrough/</guid>
      <pubDate>Sat, 03 Aug 2024 18:18:24 GMT</pubDate>
    </item>
    <item>
      <title>[研究] n-shot 学习：证据/参考请求</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ej8mcu/research_nshot_learning_evidence_reference/</link>
      <description><![CDATA[您好 - 希望我找到了正确的标签。 我一直在研究 n-shot 学习算法。我的想法是进行一项非常狭窄的性能研究，以尝试了解可以有效使用哪些启发式方法。 唯一的问题是我无法获得比 1-shot 更好的 n-shot 结果。 我想知道是否有关于 n-shot 性能的证据......我见过的论文非常模糊，特别是在对一系列模型中的 1-shot 或 0-shot 进行基准测试方面。 有什么好的参考资料我应该查看吗？    提交人    /u/sgt102   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ej8mcu/research_nshot_learning_evidence_reference/</guid>
      <pubDate>Sat, 03 Aug 2024 17:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我创建了 Promptimizer，一个用于优化 LLM 提示的开源框架。它适用于开源和闭源模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ej7gsi/p_i_created_promptimizer_an_opensource_framework/</link>
      <description><![CDATA[        提交人    /u/NextgenAITrading   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ej7gsi/p_i_created_promptimizer_an_opensource_framework/</guid>
      <pubDate>Sat, 03 Aug 2024 16:28:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 细分任何内容 2 论文细目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ej77fu/d_segment_anything_2_paper_breakdown/</link>
      <description><![CDATA[      分享一段视频，我将在其中详细介绍 Meta 的新 SAM-2 视频分割模型中的关键架构创新！尽情享受吧！    提交人    /u/AvvYaa   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ej77fu/d_segment_anything_2_paper_breakdown/</guid>
      <pubDate>Sat, 03 Aug 2024 16:17:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 苏格拉底的三段论与神经符号人工智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ej68k8/p_socrates_syllogism_with_neurosymbolic_ai/</link>
      <description><![CDATA[神经符号人工智能方法建议将神经网络的学习能力与符号人工智能的推理和知识表示优势相结合，以增强认知和决策过程。 我们的项目使用带有逻辑图（专门知识图，可以在图中同时包含数据和逻辑）的神经符号  这里是来自 repo 的介绍： Nucleoid 是神经符号人工智能的声明性、基于逻辑的上下文运行时。 Nucleoid 运行时跟踪 IPL 启发的声明性 JavaScript 语法中的每个语句，并动态创建知识图谱中逻辑和数据语句之间的关系，以用于决策和解决问题的过程。  自适应推理：将符号逻辑与上下文信息相结合，以分析关系、得出结论并纳入新信息并相应地调整其结论。 逻辑图：基于形式逻辑捕获逻辑和数据语句之间关系的专门知识图谱，促进复杂的推理并适应新信息。 可解释性：逻辑图提供了推理过程的透明表示，使我们更容易理解如何做出决策以及如何识别潜在的偏见。  与“思考，快与慢”的理念相呼应，AI 系统应该提供快速、“直观”的想法，以及另一种更深思熟虑、理性的决策。 D(L)RE 既支持基于上下文信息的直观决策，也支持基于逻辑推理的深思熟虑的决策。 苏格拉底三段论演示视频位于 README 中： https://github.com/NucleoidAI/Nucleoid?tab=readme-ov-file#nucleoid    提交人    /u/joestomopolous   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ej68k8/p_socrates_syllogism_with_neurosymbolic_ai/</guid>
      <pubDate>Sat, 03 Aug 2024 15:37:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 计算 Google Deepmind 论文的成本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ej5h4b/d_calculating_the_cost_of_a_google_deepmind_paper/</link>
      <description><![CDATA[  由    /u/certain_entropy  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ej5h4b/d_calculating_the_cost_of_a_google_deepmind_paper/</guid>
      <pubDate>Sat, 03 Aug 2024 15:05:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 评估长期语境法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eitqjj/d_evaluating_longcontext_llms/</link>
      <description><![CDATA[大型语言模型的上下文窗口一直呈指数级增长。2018 年，BERT、T5 和 GPT-1 等语言模型最多可以接受 512 个标记作为输入。现在，在 2024 年夏天，这个数字已跃升至 200 万个 token（在 Gemini 1.5 Pro 的公开版本中）。 我的想法是，由于长上下文 LLM 是一个如此新的发展，我们需要新的方法来评估它们。 我观察到的一些评估方法：  大海捞针任务（例如，在非常长的输入中查找特定信息） 扩展文档的复杂分析（例如，对文学作品的细微推理） 多镜头上下文学习，用于动态模型改进（例如，改进低资源语言的翻译）  我有一些悬而未决的问题：  您认为长上下文 LLM 还需要哪些其他评估方法？ 这些扩展的上下文窗口如何影响安全性、偏见、多语言性和创造力等领域在 ML 中？ 我们如何确保在上下文长度差异很大的模型之间进行公平比较？  我已经写了一篇文章更深入地探讨了这些主题，但我很想听听社区对其中一些未解决的问题的看法    提交人    /u/porkbellyqueen111   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eitqjj/d_evaluating_longcontext_llms/</guid>
      <pubDate>Sat, 03 Aug 2024 03:45:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 比原始聊天 gpt 更智能的模型现在可以在笔记本电脑硬件上运行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eis40b/d_models_smarter_than_the_original_chat_gpt_can/</link>
      <description><![CDATA[      活着真好！ https://i.redd.it/qlz4efsqzcgd1.gif 早在 2022 年，我就假设了两件事  ChatGPT 是一款独特的产品，不易复制 这种质量的语言模型永远无法在本地运行  很高兴这两点都是错的。现在您可以将 llama3.1:8b 下载到笔记本电脑上并免费无限制地与其聊天！我对它的速度也印象深刻。从没想过我会成为马克·扎克伯格的粉丝。    提交人    /u/nanermaner   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eis40b/d_models_smarter_than_the_original_chat_gpt_can/</guid>
      <pubDate>Sat, 03 Aug 2024 02:22:58 GMT</pubDate>
    </item>
    <item>
      <title>[R]，[P] RPC — 构建语言模型的新方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eipn2t/r_p_rpc_a_new_way_to_build_language_models/</link>
      <description><![CDATA[文章：RPC — 构建语言模型的新方法 我非常喜欢软件工程的原因之一是，任何人都可以用一台计算机做几乎任何事情。但是当涉及到人工智能，特别是法学硕士时，你需要大量的资源和金钱才能自己做任何有趣的事情。 所以最近我一直在尝试寻找一种方法来构建语言模型，使用更少的训练数据和更少的计算。RPC 是我最接近的尝试。它将提示压缩为向量表示，然后在向量数据库中执行搜索以找到最合适的下一个标记。它工作得非常好。 我与社区分享这一点，希望有人能提供一些反馈，甚至尝试复制它。我希望您能看一下这篇文章并在这里分享一些想法。    提交人    /u/someuserwithwifi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eipn2t/r_p_rpc_a_new_way_to_build_language_models/</guid>
      <pubDate>Sat, 03 Aug 2024 00:20:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士 (LLM) 面试准备</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ein9vh/d_llm_interview_prep/</link>
      <description><![CDATA[大家好， 我即将参加一场 LLM/NLP 面试。我想寻求一些建议，比如面试时应该关注哪些主题、面试中应该期待什么以及任何建议的学习材料。我听说团队专注于公司内部的所有 LLM 事务，例如自托管、优化、微调等。 以下是我计划涉及的一些领域：  了解 LLM 的工作原理（内部） 微调技术 RAG NLP 基础  有人可以分享他们参加类似面试的经验吗？我应该优先考虑这些主题的哪些具体方面？我还遗漏了其他重要领域吗？我对 RAG 有基本的了解，但了解得不是太深入。  此外，如果您对论文或在线资源有任何建议，可以帮助我准备，我将不胜感激！    提交人    /u/kkziga   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ein9vh/d_llm_interview_prep/</guid>
      <pubDate>Fri, 02 Aug 2024 22:31:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为机器学习工程师最困难的事情是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eifnvj/d_what_is_the_hardest_thing_as_a_machine_learning/</link>
      <description><![CDATA[我刚刚开始我的机器学习之旅。为了练习，我从 Kaggle.com 获取数据，但我决定通过自己收集数据来进一步挑战自己。我发现收集大量数据非常具有挑战性。通常如何收集数据，还有什么比这更难的吗？    提交人    /u/3ATAE   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eifnvj/d_what_is_the_hardest_thing_as_a_machine_learning/</guid>
      <pubDate>Fri, 02 Aug 2024 17:16:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] NLP 论文的新常态是“提示工程”论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei9e3l/d_is_the_new_norm_for_nlp_papers_prompt/</link>
      <description><![CDATA[很多论文似乎本质上都是“我们如何让 LLM 1 不经过任何培训就能做到这一点？”我已经有一段时间没有发表过文章了，过去几年一直在行业内工作。我最近加入了一家新公司，担任一个稍微更偏向研究的职位，与研究科学家和研究生实习生一起工作。我注意到他们每个人都在做一些我在研究生院会受到 PI 斥责的事情。基本上就是“我们如何让 LLM 不经过任何培训就能完成这个非常复杂的任务？”也许并不出人意料的是，在很多情况下，你做不到。我想这就是为什么现在 NLP 领域有这么多负面结果的论文。 这是新常态吗？浏览 arXiv 的 CL 部分已经变得很痛苦了。 98% 的论文都是类似“LLaMA 怎么会不懂数字？”这样的问题。 我想知道我是不是酒吧角落里那个老糊涂，还是大家都有同样的感受。    提交人    /u/Seankala   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei9e3l/d_is_the_new_norm_for_nlp_papers_prompt/</guid>
      <pubDate>Fri, 02 Aug 2024 12:57:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>