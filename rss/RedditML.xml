<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Thu, 23 May 2024 01:01:11 GMT</lastBuildDate>
    <item>
      <title>未能复制“深度残差学习”“[P]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cydq8g/failing_to_replicate_deep_residual_learning_p/</link>
      <description><![CDATA[   大家好， 出于学习目的，我一直在复制Kaiming He 2015 年“图像识别的深度残差学习”中的方法。我已经构建了受 VGG 启发的 plain-CNN 以及 ResNet 架构（标准和瓶颈）。 但是，我无法复制出版物中强调的退化（准确性饱和）问题。出版物中的错误百分比数字显示，随着训练的进展，错误百分比明显下降，然后停滞不前。 我的数字似乎停滞不前，但很明显，该模型对验证数据的泛化能力非常糟糕。我附上了他们的一张图作为参考。有什么建议可以更好地复制本文中的错误率饱和度吗？注：对于何凯明图，粗线为测试误差&amp;虚线表示训练。 参数：  162 个 Epoch，批量大小为 128，进行 64k 次迭代。 Lr：0.1 &lt; li&gt;动量：0.9 权重衰减：0.0001 多步调度器在 32k 和 48k 迭代时将 lr 除以 10  我的%-错误 &lt; p&gt;来自论文   由   提交 /u/AnotherBotIGuess   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cydq8g/failing_to_replicate_deep_residual_learning_p/</guid>
      <pubDate>Wed, 22 May 2024 22:48:34 GMT</pubDate>
    </item>
    <item>
      <title>【研究】理解 Claude 3 Sonnet 中的稀疏自动编码器如何影响实际的人工智能应用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cyc0zs/research_how_can_understanding_sparse/</link>
      <description><![CDATA[我最近读了论文“Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet”由人类。该研究探讨了稀疏自动编码器如何从 Transformer 模型中提取可解释的、多语言和多模态的特征。  https://transformer- Circuits.pub/2024/scaling-monosemanticity/index .html - 论文链接 鉴于这些功能会影响特定类型数据（如文本或图像）的检测和生成，我很好奇此功能的实际应用：  这种级别的特征理解如何帮助在不进行大量再训练的情况下为特定任务定制模型输出？例如，我们能否在基于已识别特征的部署过程中更有效地引导模型？这可以消除/识别/减轻偏见吗？    由   提交 /u/mamphii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cyc0zs/research_how_can_understanding_sparse/</guid>
      <pubDate>Wed, 22 May 2024 21:35:26 GMT</pubDate>
    </item>
    <item>
      <title>对 InstructLab 项目有何想法？社区驱动的法学硕士？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cyaepr/thoughts_on_the_instructlab_project_community/</link>
      <description><![CDATA[https://github .com/instructlab/community/blob/main/README.md “InstructLab 的使命（L大规模A InstructLab 由多个定义为代码库的项目组成以及具有不同发布周期的服务。总的来说，这些可以实现大型模型的开发。该存储库在整个社区中共享 InstructLab 的活动和协作详细信息，并包含有关该项目的最新信息。” 对此有何想法？我还没有见过这样的社区模型，可以为模型贡献知识和技能以提高其性能。看起来很新，但在法学硕士领域有些独特。   由   提交 /u/MOGILITND   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cyaepr/thoughts_on_the_instructlab_project_community/</guid>
      <pubDate>Wed, 22 May 2024 20:27:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mistral-7B-v0.3 指令与 Llama-3 8B 指令在医学领域的评估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cy7no2/d_mistral7bv03_instruct_vs_llama3_8b_instruct/</link>
      <description><![CDATA[&lt;表&gt;       https://preview.redd.it/wzkhd6k1v02d1.png?width=571&amp;format=png&amp; ;auto=webp&amp;s=0733a90b13450d48721f6eced9e70dfe2028bf93   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cy7no2/d_mistral7bv03_instruct_vs_llama3_8b_instruct/</guid>
      <pubDate>Wed, 22 May 2024 18:35:07 GMT</pubDate>
    </item>
    <item>
      <title>[D]机器学习/深度学习如何应用于金融交易？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cy6ljc/dhow_is_machine_learningdeep_learning_being_used/</link>
      <description><![CDATA[我喜欢这一集，讨论深度学习和机器学习在金融领域的作用。金融领域真正的机器学习/深度学习现在被认为是多种金融服务和应用程序的关键方面，包括管理资产、评估风险水平、计算信用评分，甚至批准贷款。 https://podcasters.spotify.com/ pod/show/ai-x-podcast/episodes/Deep-Learning-for-Financial-Trading-with-Sofien-Kaabar-e2i4q0c  &amp; #32；由   提交/u/Data_Nerd1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cy6ljc/dhow_is_machine_learningdeep_learning_being_used/</guid>
      <pubDate>Wed, 22 May 2024 17:53:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用模糊示例进行数据增强？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cy6771/d_data_augmentation_with_ambiguous_examples/</link>
      <description><![CDATA[我觉得我这里漏了一个关键词，所以你们也许可以帮我找出要搜索的内容。 我最近在想，当你给一个典型的分类器一个完全随机的样本，而这个样本实际上不在分布范围内时，会发生什么。它仍然会返回一个标签。例如，如果我训练一个模型来对 MNIST 进行分类，并且我给它输入高斯噪声向量，那么模型会将这些完全随机的向量分类为数字。 有没有人尝试过用随机噪声（或训练示例的随机组合）来扩充他们的训练数据集？在这个策略中，我的直觉是，你会注入本质上是负面的反例——而且你会希望标签向量具有大量的熵。我认为这些反例会有很高的随机不确定性。    提交人    /u/stay_janley   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cy6771/d_data_augmentation_with_ambiguous_examples/</guid>
      <pubDate>Wed, 22 May 2024 17:36:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您希望在 /r/machinelearning 中看到更多或更少的内容？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cy5ldu/d_what_would_you_like_to_see_more_or_less_of_in/</link>
      <description><![CDATA[我无法设置投票。但我想我应该加入这个社区。 首先，我希望原创研究人员能够发布他们的论文并回答问题。    ;由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cy5ldu/d_what_would_you_like_to_see_more_or_less_of_in/</guid>
      <pubDate>Wed, 22 May 2024 17:12:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 比较 cnn、局部连接和密集连接模型的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cy515k/r_paper_comparing_cnn_locally_connected_and/</link>
      <description><![CDATA[不久前我读了一篇论文，该论文对卷积模型和局部连接模型进行了比较（与 cnn 相同，但没有参数共享，因此每个模型图像定位具有不同的内核）和密集连接的模型。具体来说，他们使每个模型都具有相同的激活次数，其中大多数比较保持参数不变。这是一篇很酷的论文，因为它将每个模型在其可以表达的内容方面置于一个公平的竞争环境中，并且这展示了如何将CNN的好处分解为局部性和参数共享。  但是我很难找到这篇论文。有人有什么建议吗？   由   提交 /u/MustachedSpud   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cy515k/r_paper_comparing_cnn_locally_connected_and/</guid>
      <pubDate>Wed, 22 May 2024 16:49:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI 代理：太早、太昂贵、太不可靠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cy1kn9/d_ai_agents_too_early_too_expensive_too_unreliable/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cy1kn9/d_ai_agents_too_early_too_expensive_too_unreliable/</guid>
      <pubDate>Wed, 22 May 2024 14:27:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] Fish Speech TTS：30 分钟克隆 OpenAI TTS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cxwqb7/p_fish_speech_tts_clone_openai_tts_in_30_minutes/</link>
      <description><![CDATA[虽然我们仍在寻找改善代理对 OpenAI GPT-4o 的情绪反应的方法，但我们已经在调整 OpenAI 的 TTS 性能方面取得了重大进展。为了开始这个实验，我们收集了 10 个小时的 OpenAI TTS 数据，对 LLM（中）和 VITS 模型进行监督微调（SFT），大约花费了 30 分钟。之后，我们在推理过程中使用了 15 秒的音频作为提示。 可用演示：这里。 正如您所看到的，模型的情感、节奏、口音和音色与 OpenAI 扬声器相匹配，尽管音频质量有所下降，我们正在解决这个问题。为了避免任何法律问题，我们无法发布微调后的模型，但我相信每个人都可以调整 fish-speech几小时内就能达到这个水平，费用约为 20 美元。 我们的实验表明，只需 25 秒的提示（少量学习），无需任何微调，该模型就可以模仿大多数行为，除了音色等细节之外以及它如何读取数字。据我们所知，您可以使用此框架通过 30 分钟的数据克隆某人如何用英语、中文和日语说话。 存储库：https://github.com/fishaudio/fish-speech   由   提交/u/lengyue233  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cxwqb7/p_fish_speech_tts_clone_openai_tts_in_30_minutes/</guid>
      <pubDate>Wed, 22 May 2024 10:11:52 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 评估不平衡数据的指标。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cxrivi/discussion_metric_to_evaluate_imbalance_data/</link>
      <description><![CDATA[我正在处理有关分类图像的问题。我可以增强和采样我的不平衡训练集，但我的有效/测试集不平衡。我应该使用哪个指标来评估我的模型（我知道存在 F1 分数，但这也是一个多类问题）？   由   提交/u/Civil_Statement_9331   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cxrivi/discussion_metric_to_evaluate_imbalance_data/</guid>
      <pubDate>Wed, 22 May 2024 04:13:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 获得学位后，您最喜欢扩展该领域知识的方式是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cxos4s/d_what_is_your_favorite_way_to_expand_your/</link>
      <description><![CDATA[我完成了硕士学位一年多前，我获得了统计学博士学位，我的知识已经有点生疏了，我想重新鞭策自己，加深对所有这些触手可及的伟大概念的理解。我倾向于喜欢拿起一本教科书并完成它，或者找到一个很酷的数据集并构建一些模型来巩固我一直在学习的东西。 我知道除了获得博士学位或工作之外在实验室里，很难在研究方面真正取得有意义的进展；然而，老实说，我非常喜欢数学/统计学/计算机科学，所以学习这些东西可能是我在一天结束时最喜欢的放松方式。  你最喜欢的让自己成长的方式是什么？   由   提交/u/RawCS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cxos4s/d_what_is_your_favorite_way_to_expand_your/</guid>
      <pubDate>Wed, 22 May 2024 01:45:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 多项式回归博客系列中关于概率校准的帖子</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx9npr/p_a_post_on_probabilistic_calibration_in_blog/</link>
      <description><![CDATA[我个人学习伯恩斯坦基多项式回归的另一章涉及概率模型校准领域。我当然喜欢学习，我希望你也会觉得它很有趣。 系列从这里开始：https://alexshtf.github.io/2024/01/21/Bernstein.html 关于校准的最新帖子：https://alexshtf.github.io/2024/05/19/BernsteinCalibration.html   由   提交/u/alexsht1  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx9npr/p_a_post_on_probabilistic_calibration_in_blog/</guid>
      <pubDate>Tue, 21 May 2024 14:47:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 启用稀疏的基础法学硕士，以通过 Neural Magic 和 Cerebras 建立更快、更高效的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx83cs/r_enabling_sparse_foundational_llms_for_faster/</link>
      <description><![CDATA[      在 Neural Magic、Cerebras 的合作中，和 IST Austria，据我们所知，我们推出了第一个高度稀疏的基础法学硕士，在多项微调任务上完全恢复，包括聊天、代码生成、摘要等。 &lt; p&gt;热门微调任务的稀疏性与基线精度恢复Llama 2 7B 利用这些模型，我们进一步证明：  仅通过稀疏性即可在 Neural Magic 上将 CPU 的推理性能加速 3 倍，将 GPU 的推理性能加速 1.7 倍 通过量化实现复合增益，推理性能提升高达 8.6 倍。 接近利用 Cerebras CS-3 AI 加速器进行稀疏训练的理论增益。   ul&gt; 不同条件下的预填充和解码 Llama 2 7B 性能8 核 CPU 上 FP32 和 INT8 的稀疏级别。 论文：https://arxiv。 org/abs/2405.03594 模型：https://huggingface .co/collections/neuralmagic/sparse-foundational-llama-2-models-65f48cec6396309f02e74d21   由   提交/u/markurtz  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx83cs/r_enabling_sparse_foundational_llms_for_faster/</guid>
      <pubDate>Tue, 21 May 2024 13:36:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>