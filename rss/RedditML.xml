<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sun, 30 Jun 2024 15:15:10 GMT</lastBuildDate>
    <item>
      <title>[D] 研究科学家/机器学习职位的 CUDA 编程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3h1x/d_cuda_programming_for_research_scientistmachine/</link>
      <description><![CDATA[大家好， 我正在为大型科技公司的研究员/机器学习工程师职位做准备。我的准备从机器学习算法（线性回归、逻辑、SVM、KNN、XGBoost、随机森林、决策树等）开始，解决了 300 多个 leetcode 问题，并研究了有关 NLP 的概念（Tokenization、Transformers 等）。 由于大多数机器学习算法都是在 GPU 上实现的，我是否还应该学习 CUDA 编程以应对上述职位的面试，我应该在准备中涵盖哪些额外主题？    提交人    /u/Suryavanshi1897   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3h1x/d_cuda_programming_for_research_scientistmachine/</guid>
      <pubDate>Sun, 30 Jun 2024 15:02:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 难以实现准确的说话人分类：需要模型 / 服务推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds1d7u/d_struggling_with_accurate_speaker_diarization/</link>
      <description><![CDATA[我正在处理一些包含多个说话者且没有串扰的音频文件，但在说话者分类任务中我从未获得一致良好的结果。我尝试过开源模型和付费服务，但它们都没有产生足够好的结果。常见的错误包括说话者预测不正确和/或识别出的说话者数量不正确。 我觉得奇怪的是，这项任务对于普通人来说似乎非常简单，因为将音频的每个部分分配给正确的说话者（无论是现有的还是新的）都相当容易。所以，我不明白为什么这对深度学习模型来说如此困难。 如果您知道任何可以有效解决此任务的模型、算法或服务的建议，我将不胜感激。    提交人    /u/MultiheadAttention   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds1d7u/d_struggling_with_accurate_speaker_diarization/</guid>
      <pubDate>Sun, 30 Jun 2024 13:21:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您使用什么策略/工具来查找相关文献并保持最新状态？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds0caj/d_what_are_your_strategiestools_to_find_relevant/</link>
      <description><![CDATA[大家好， 当我还是一名博士生时，找到相关论文似乎很容易，因为我只研究一个主题。现在，我从事工业界，对更广泛的论文感兴趣，因为我必须产生有趣的想法。所以我想 1/ 养成每天阅读的习惯，2/ 接触有趣的论文，也许是我所在领域之外的论文。您自己使用哪些策略和工具，甚至新闻通讯来实现这一点？ 过去我经常使用 Twitter，但现在它受趋势和炒作的支配，主要是法学硕士，所以我再也找不到很多论文了。Scholar Inbox 很棒，但它非常专注于特定主题，并没有真正致力于多样化。 谢谢！    提交人    /u/poiret_clement   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds0caj/d_what_are_your_strategiestools_to_find_relevant/</guid>
      <pubDate>Sun, 30 Jun 2024 12:27:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可疑的 ML 结果——这些输出实际上来自真实模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds08px/d_suspicious_ml_results_are_these_outputs/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds08px/d_suspicious_ml_results_are_these_outputs/</guid>
      <pubDate>Sun, 30 Jun 2024 12:21:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 可以从训练数据中的分散提示中推断出受审查的知识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drzalw/r_llms_can_infer_censored_knowledge_from/</link>
      <description><![CDATA[https://arxiv.org/abs/2406.14546 “我们研究归纳式非语境推理 (OOCR)，这是一种概括类型，其中 LLM 从分布在训练文档中的证据中推断出潜在信息，并将其应用于下游任务而无需语境学习。”    提交人    /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drzalw/r_llms_can_infer_censored_knowledge_from/</guid>
      <pubDate>Sun, 30 Jun 2024 11:22:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] 快速缓存：穷人的零样本视觉指南-LLM 分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dry5a8/p_prompt_caching_poor_mans_guide_to_zero_shot/</link>
      <description><![CDATA[        由    /u/themathstudent  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dry5a8/p_prompt_caching_poor_mans_guide_to_zero_shot/</guid>
      <pubDate>Sun, 30 Jun 2024 10:03:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 推荐有关 ML 研究/新闻/主要公司的 RSS 提要？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drpk01/d_recommended_rss_feeds_on_ml_research_news_major/</link>
      <description><![CDATA[我正在寻找相关的 RSS 源来关注，我希望涵盖当今 ML 的各个方面：研究、公司、MLOps 等。 我能找到的关于 RSS 源的最后一篇文章是 2 年前的，我认为已经过去了足够的时间值得更新。 您最推荐的 RSS 源是什么？    提交人    /u/fliiiiiiip   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drpk01/d_recommended_rss_feeds_on_ml_research_news_major/</guid>
      <pubDate>Sun, 30 Jun 2024 00:48:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前经过实战检验的最先进的多元时间序列回归机制是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drohkd/d_whats_the_current_battletested_stateoftheart/</link>
      <description><![CDATA[目前久经考验的最先进的多元时间序列回归机制是什么？使用多个时间序列来预测单个值。 对于多个半平稳时间序列。 我所说的“久经考验”是指至少 5% 的行业已经在使用它，或者目前正在大力采用它。    提交人    /u/igaloly   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drohkd/d_whats_the_current_battletested_stateoftheart/</guid>
      <pubDate>Sat, 29 Jun 2024 23:52:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] DDIM 反转和关键调整，以 SD 2.1 为基础实现人脸编辑功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drn9zs/p_ddim_inversion_and_pivotal_tuning_to_achieve/</link>
      <description><![CDATA[      Github : https://github.com/OutofAi/StableFace https://preview.redd.it/clulwrsnbl9d1.png?width=2048&amp;format=png&amp;auto=webp&amp;s=53d002746d951fb35bfeb928eed42644d05430e4    提交人    /u/TerryCrewsHasacrew   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drn9zs/p_ddim_inversion_and_pivotal_tuning_to_achieve/</guid>
      <pubDate>Sat, 29 Jun 2024 22:52:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] GraphReader：一种基于图形的 AI 代理系统，旨在通过将长文本构建成图形并使用代理自主探索该图形来处理长文本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drjcfz/r_graphreader_a_graphbased_ai_agent_system/</link>
      <description><![CDATA[    /u/valdanylchuk   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drjcfz/r_graphreader_a_graphbased_ai_agent_system/</guid>
      <pubDate>Sat, 29 Jun 2024 19:46:56 GMT</pubDate>
    </item>
    <item>
      <title>[D]: 微调 NuExtract-tiny</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drjbhj/d_finetune_nuextracttiny/</link>
      <description><![CDATA[我尝试微调 NuExtract-tiny 以从文本中提取以下信息： { &quot;document_type&quot;: &quot;&quot;, &quot;document_identifier&quot;: &quot;&quot;, &quot;subject&quot;: &quot;&quot;, &quot;effective_date&quot;: &quot;&quot;, &quot;revision_date&quot;: &quot;&quot;, &quot;publishing_date&quot;: &quot;&quot;, }  因此，我使用 gpt-4o 生成了合成训练数据，它看起来像 processed_data.jsonl 文件中存在的数据。我使用了大约 5000 个训练样本。我已将微调 NuExtract-tiny 的日志附在我的代码上。查看 validation_loss，它似乎没有经过太多微调。我有以下观察：  我比较了微调模型的结果，它们非常糟糕，比原始 NuExtract-tiny 差得多 此外，推理速度变得非常慢，即使原始模型和微调模型的大小相同。  我手动验证了使用 gpt-4o 生成的训练数据质量良好。 关于可能出现问题的任何建议？任何帮助都将不胜感激。我正在附加 Jupyter 笔记本和数据的链接 笔记本链接：https://drive.google.com/file/d/1ZDMVAGSIPXbkWDaJuCxcFLLduKZLqXjQ/view?usp=sharing processed_data.jsonl 链接：https://drive.google.com/file/d/11NYOINkIh4P-a3loB9KD6-C-XOs0Bfl8/view?usp=sharing 以下是微调模型和原始模型的比较： text = &quot;&quot;&quot;德克萨斯州医疗补助提供者程序手册 2022 年 2 月提供者手册 妇科、产科和计划生育第 19 条服务手册 德克萨斯州医疗补助和医疗保健合作伙伴关系 (TMHP) 是与德克萨斯州卫生和公共服务委员会签订合同的德克萨斯州医疗补助的索赔管理员。&quot;&quot;&quot;  给定模式： schema = &quot;&quot;&quot;{&quot;document_type&quot;: &quot;&quot;, &quot;document_identifier&quot;: &quot;&quot;, &quot;subject&quot;: &quot;&quot;, &quot;effective_date&quot;: &quot;&quot;, &quot;revision_date&quot;: &quot;&quot;, &quot;publishing_date&quot;: &quot;&quot;}&quot;&quot;&quot;  微调模型输出： { &quot;document_type&quot;: &quot;Handbook&quot;, &quot;document_identifier&quot;: &quot;&quot;, &quot;subject&quot;: &quot;Gynecological, Obstetrics, and Family &quot;effective_date&quot;: &quot;&quot;, &quot;revision_date&quot;: &quot;&quot;, &quot;publishing_date&quot;: &quot;&quot; }  原始模型输出： { &quot;document_type&quot;: &quot;Provider Procedures Manual&quot;, &quot;document_identifier&quot;: &quot;Provider Handbooks&quot;, &quot;subject&quot;: &quot;Gynecological, Obstetrics, and Family Planning Title XIX Services Handbook&quot;, &quot;effective_date&quot;: &quot;February 2022&quot;, &quot;revision_date&quot;: &quot;&quot;, &quot;publishing_date&quot;: &quot;&quot; }  您可以清楚地看到，微调模型失败了。    提交人    /u/n0pe09   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drjbhj/d_finetune_nuextracttiny/</guid>
      <pubDate>Sat, 29 Jun 2024 19:45:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 同事最近告诉我，认为“法学硕士能够思考/理解”的人都是从法学硕士开始从事 ML/NLP 职业的人。我很好奇你的想法。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drd3tv/d_coworkers_recently_told_me_that_the_people_who/</link>
      <description><![CDATA[我自己在这个领域并没有待很长时间。我在 2016-2017 年左右开始攻读硕士学位，当时 Transformers 开始流行起来。我已经在行业中工作了一段时间，最近刚刚加入一家专注于 NLP 的公司，担任 MLE。 在工作中，我们最近进行了一场辩论/讨论，讨论主题是 LLM 是否能够具备理解和思考的能力。我们讨论了 Emily Bender 和 Timnit Gebru 关于 LLM 是随机鹦鹉的论文，然后从那里开始。 意见大致各占一半：我们中的一半（包括我自己）认为 LLM 是 BERT 或 GPT-2 等模型的简单扩展，而其他人则认为 LLM 确实能够理解和领悟文本。在我的高级工程师发表标题中的评论后，我注意到一件有趣的事情，那就是那些认为 LLM 能够思考的人要么是在 LLM 成为既定事实后进入 NLP 的人，要么原本来自计算机视觉等不同领域，后来转行了。 我很好奇其他人对此的看法。我有点吃惊，因为我没想到 LLM 是有意识的理解生物的观点会在实际从事该领域的人中如此普遍；这是我从非 ML 人士那里听到的更多的事情。这些人也不只是新手工程师，我团队中的每个人都有在顶级 ML 场所发表文章的经验。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drd3tv/d_coworkers_recently_told_me_that_the_people_who/</guid>
      <pubDate>Sat, 29 Jun 2024 15:00:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 DINO 模型要对教师编码器使用增强功能？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dr6aad/d_why_do_dino_models_use_augmentations_for_the/</link>
      <description><![CDATA[如标题所示 - DINO 和 DINOv2 使用增强来输入教师网络。为什么会这样？从“最干净”的数据版本生成教师表示不是更有意义吗？真的很想听听他们所做事情背后的直觉。    提交人    /u/clywac2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dr6aad/d_why_do_dino_models_use_augmentations_for_the/</guid>
      <pubDate>Sat, 29 Jun 2024 08:07:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] “Grok” 有太多不同的含义</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqpyb3/d_grok_means_way_too_many_different_things/</link>
      <description><![CDATA[我厌倦了到处看到这个词，而且它每次在同一个领域都有不同的含义。对我来说，第一次是当伊隆·马斯克推出并大肆宣传 Twitter 的新产品（现在不是新的，但当时是）“Grok AI”时，然后我阅读了更多论文，发现了一个相当惊人的发现，显然地球上的每个人都知道了一段时间，除了我之外，那就是在某个点之后，过度拟合模型开始能够概括，这摧毁了我之前的许多先入为主的观念以及我在学校和其他地方学到的东西。但这种现象也被称为“Grok”，然后有一篇基于 Grok 定义的新“GrokFast”论文，还有“Groq”，不要与其他两个“Grok”混淆，更不用说伊隆·马斯克将他的人工智能装备命名为“xAI”机械可解释性人们已经在使用该术语作为“可解释的 AI”的缩写，这对我来说太多了    提交人    /u/Traditional_Land3933   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqpyb3/d_grok_means_way_too_many_different_things/</guid>
      <pubDate>Fri, 28 Jun 2024 17:59:29 GMT</pubDate>
    </item>
    </channel>
</rss>