<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 10 Jan 2024 18:17:12 GMT</lastBuildDate>
    <item>
      <title>需要生成对话 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/193e54u/need_to_generate_conversations_d/</link>
      <description><![CDATA[我有一些代理和客户之间的对话记录。我需要使用这些对话生成综合对话。你们中的任何人都可以建议我如何继续吗？我需要一个可以将许多转录本作为输入并生成相似转录本的模型。上下文窗口是一个问题。即使解决了，提示提供什么？   由   提交/u/Evermore2307  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/193e54u/need_to_generate_conversations_d/</guid>
      <pubDate>Wed, 10 Jan 2024 17:44:20 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 较长文本的翻译模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/193cgo4/discussion_translation_models_for_longer_texts/</link>
      <description><![CDATA[我正在尝试流行的 MT 模型，例如 Huggingface 的 SeamlessM4T-v2、Open-NLLB、MADLAD-400。他们似乎只支持非常短的文本，比如 1 句话。我想知道我是否遗漏了某些内容，或者您​​将如何使用它们来翻译几页文本？   由   提交/u/Electronic-Letter592   reddit.com/r/MachineLearning/comments/193cgo4/discussion_translation_models_for_longer_texts/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/193cgo4/discussion_translation_models_for_longer_texts/</guid>
      <pubDate>Wed, 10 Jan 2024 16:36:03 GMT</pubDate>
    </item>
    <item>
      <title>航空业流行机型……[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/193bole/popular_machine_models_in_airlines_industryd/</link>
      <description><![CDATA[航空公司正在追求哪些有趣的用例，GenAI 和其他机器学习模型如何在其中发挥重要作用？  我喜欢了解的一些用例主要来自运营研究领域，例如：  预测席位的实时成本以实现利润最大化？  预测席位的实时成本以实现利润最大化？ li&gt; 考虑到天气延误和其他机场/空中交通管制员相关取消，如何优化航班时刻表？  如何在最后一分钟为乘客重新预订另一趟航班，以便为乘客和航空公司带来最佳结果（假设上面发生了#2）？  任何机器学习模型范例适合上述用例吗？欣赏这些见解……   由   提交/u/Dependent_Mushroom98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/193bole/popular_machine_models_in_airlines_industryd/</guid>
      <pubDate>Wed, 10 Jan 2024 16:03:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对抗性样本检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/193a8uj/r_adversarial_example_detection/</link>
      <description><![CDATA[我是一名本科生，我计划创建一个基于视觉转换器的对抗性示例分类模型，在原始对抗性和干净图像上进行训练，有哪些内容我应该在开发过程中考虑有关模型选择和特征工程的问题   由   提交/u/GraphHopper77  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/193a8uj/r_adversarial_example_detection/</guid>
      <pubDate>Wed, 10 Jan 2024 15:01:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 比较在不同角度拍摄的两张图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1939w0b/d_comparing_two_images_taken_at_different_angles/</link>
      <description><![CDATA[您好，reddit， 我希望比较在十年内拍摄的两张或多张图像或同一对象角度略有不同。我想知道第一张照片中物体的某些特征是否保留在最后一张照片中。 更具体地说，我的目的是比较两张屋顶照片，以确定各种颜色/磨损是否存在/第一张照片中显示的恶化情况与最近一张照片中的情况相同——我的目的是确定在两张照片之间的过渡期间屋顶是否被更换过。 任何应用程序已经在这样做了吗？知道这样的比较应该叫什么吗？ 谢谢！   由   提交 /u/selfpromoting   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1939w0b/d_comparing_two_images_taken_at_different_angles/</guid>
      <pubDate>Wed, 10 Jan 2024 14:45:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大语言模型2023年回顾与2024年展望</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1939mue/d_large_language_model_2023_review_and_2024/</link>
      <description><![CDATA[中：https://medium.com/@kentsui/large-language-model-2023-review-and-2024-outlook-cbd5211cf49b 子堆栈：https://paperdigest.substack.com/p/aimachine-learning-mostly-llm-2023  你对 2024 年有何看法？   由   提交 /u/transformer_ML   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1939mue/d_large_language_model_2023_review_and_2024/</guid>
      <pubDate>Wed, 10 Jan 2024 14:34:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么打包是寻找下界的好技术？ [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19394mc/why_packing_is_a_good_technique_to_find_lower/</link>
      <description><![CDATA[在学习理论中，寻找样本复杂性的下限使用诸如在假设空间上定义包装集之类的技术。具体地，给定m个样本及其标签，这为目标模型提供了m位信息，因此无法区分“合理”的log_2(m)函数。很远（包装集）。 在学习理论中，寻找样本复杂性的下界涉及在假设空间上定义包装集。具体地，给定m个样本及其标签，这为目标模型提供了m位信息，因此无法区分“合理”的log_2(m)函数。距离很远（包装集）。(M) + log_2(1- delta) 通过使用包装集？   由   提交/u/Any-Ad-3888  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19394mc/why_packing_is_a_good_technique_to_find_lower/</guid>
      <pubDate>Wed, 10 Jan 2024 14:10:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有机器学习会议索引吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1938zb1/d_is_there_an_index_for_machine_learning/</link>
      <description><![CDATA[您好， 我正在寻找一个有关机器学习会议的最新页面，下一个会议计划何时举行，世界各地（我最感兴趣的是欧洲的会议）。 额外的好处是你们还有与 Python 相关的会议，MLOps.... ​ &lt; p&gt;我找到了这个页面：http://conferences.visionbib.com/Iris-Conferences.html 谢谢   由   提交/u/chamouloxx  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1938zb1/d_is_there_an_index_for_machine_learning/</guid>
      <pubDate>Wed, 10 Jan 2024 14:03:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分位数概率预测的评估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1936hj1/d_evaluation_for_quantile_probabilistic_forecast/</link>
      <description><![CDATA[我正在训练一个执行概率预测的模型，它输出概率分布，而不是每个时间步的单点估计。因此，对于每个时间步长，我都会为我定义的每个分位数获得一个值 (q20,q50,q80..etc) 。  我发现大多数评估方法要么使用每个时间步长的中位数 (q50) 来计算 MAPE 和其他指标，要么使用特定的概率预测指标，例如 LogS、CRPS 和 VarS。 为了将概率预测模型与其他确定性模型进行比较，通过对每个时间步使用与实际目标值差异最小的预测值来获取测试集的 MAPE 是否有效？这意味着对于不同的时间步长，来自不同分位数的值可以用于评估性能。您认为这是一个好方法还是作弊？    由   提交 /u/MrGolran   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1936hj1/d_evaluation_for_quantile_probabilistic_forecast/</guid>
      <pubDate>Wed, 10 Jan 2024 11:48:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于预测的最佳时间序列模型（替代 TimeGPT）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/193672o/d_best_time_series_models_for_forecasting/</link>
      <description><![CDATA[我最近发现了TimeGPT，它真的很棒需求预测。 我不太擅长使用 pytorch，但我无法实现任何接近 TimeGPT 的结果。 我现在正在寻找类似的（甚至更好的） ？）对于预测数据（在我的例子中是需求预测）表现非常好的模型。 感谢您的建议！    ;由   提交/u/Benni03155  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/193672o/d_best_time_series_models_for_forecasting/</guid>
      <pubDate>Wed, 10 Jan 2024 11:30:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] AdamL：一种结合损失函数的快速自适应梯度方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1932cv6/r_adaml_a_fast_adaptive_gradient_method/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.15295 摘要：  自适应一阶优化器是深度学习的基本工具，尽管由于梯度缩放不均匀，它们可能会受到泛化能力差的影响。在这项工作中，我们提出了 Adam 优化器的一种新颖变体 AdamL，它考虑了损失函数信息以获得更好的泛化结果。我们提供了充分的条件，与 Polyak-Lojasiewicz 不等式一起确保 AdamL 的线性收敛。作为我们分析的副产品，我们证明了 EAdam 和 AdaBelief 优化器的相似收敛特性。基准函数的实验结果表明，与 Adam、EAdam 和 AdaBelief 相比，AdamL 通常可以实现最快的收敛或最低的目标函数值。当考虑深度学习任务（例如训练卷积神经网络、使用普通卷积神经网络训练生成对抗网络和长短期记忆网络）时，这些优越的性能得到了证实。最后，在普通卷积神经网络的情况下，AdamL 从其他 Adam 变体中脱颖而出，不需要在训练后期手动调整学习率。     由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1932cv6/r_adaml_a_fast_adaptive_gradient_method/</guid>
      <pubDate>Wed, 10 Jan 2024 07:07:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 设备端人工智能是未来吗？ NVIDIA 在 CES 上发起挑战</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1930r1g/d_is_ondevice_ai_the_future_nvidia_throws_down/</link>
      <description><![CDATA[NVIDIA 在 CES 上的重大发布集中于一个关键主题：将强大的 AI 功能直接引入您的 PC 或笔记本电脑。 开发者工具：  AI Workbench（测试版）：跨 Hugging Face、GitHub 和 NVIDIA NGC 等平台简化 AI 开发。 RTX Remix：通过 AI 驱动的升级和元素修改为经典游戏注入新的活力。 NVIDIA Avatar Cloud Engine (ACE)：创建 AI 驱动的游戏游戏和其他应用程序的数字化身。 与 RTX 聊天：构建利用本地法学硕士和用户数据的个人助理和聊天机器人。  这是设备上人工智能主导地位的黎明吗？很容易说是。 NVIDIA 强大的硬件和用户友好的工具使本地运行 AI 变得比以往更加容易。然而，挑战仍然存在：  电池寿命：配备强大 GPU 的笔记本电脑可能需要在附近配备额外的充电器。 软件成熟度：设备上的 AI 软件仍在不断发展，并且开发人员采用率需要提高。 可访问性：高端硬件是有代价的，可能会限制广泛采用。  您认为呢？设备上的人工智能是未来，还是基于云的人工智能仍然是王者？在下面的评论中分享您的想法！   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1930r1g/d_is_ondevice_ai_the_future_nvidia_throws_down/</guid>
      <pubDate>Wed, 10 Jan 2024 05:31:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] MoE-Mamba：专家混合的高效选择性状态空间模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192z048/r_moemamba_efficient_selective_state_space_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.04081 代码：https ://github.com/llm-random/llm-random 摘要：  状态空间模型（SSM）已成为顺序建模领域的有力竞争者，挑战 Transformers 的主导地位。与此同时，Mixture of Experts (MoE) 显着改进了基于 Transformer 的法学硕士，包括最近最先进的开源模型。我们建议，为了释放 SSM 的扩展潜力，它们应该与 MoE 结合起来。我们在 Mamba 上展示了这一点，这是一个最近基于 SSM 的模型，它实现了类似 Transformer 的卓越性能。我们的模型 MoE-Mamba 的性能优于 Mamba 和 Transformer-MoE。特别是，MoE-Mamba 以减少 2.2 倍的训练步骤达到与 Mamba 相同的性能，同时保留了 Mamba 针对 Transformer 的推理性能增益。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192z048/r_moemamba_efficient_selective_state_space_models/</guid>
      <pubDate>Wed, 10 Jan 2024 04:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 受大脑启发的机器智能：神经生物学上合理的信用分配调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192yvmo/r_braininspired_machine_intelligence_a_survey_of/</link>
      <description><![CDATA[https://arxiv.org/abs/2312.09257   由   提交/u/gw109  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192yvmo/r_braininspired_machine_intelligence_a_survey_of/</guid>
      <pubDate>Wed, 10 Jan 2024 03:53:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>