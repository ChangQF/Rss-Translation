<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 10 Feb 2024 15:11:38 GMT</lastBuildDate>
    <item>
      <title>[D] 你能提取llm的编码器部分来进行特征提取吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ani1uz/d_can_you_extract_the_encoder_part_of_an_llm_for/</link>
      <description><![CDATA[我对此还很陌生，所以这可能是一个愚蠢的问题。如果您有一个像最新的混合模型这样的开源模型，您可以提取进行编码的层并将其用于特征提取吗？如果是这样，值得尝试使用 BERT 或 ROBERTA 吗？   由   提交 /u/TheMiniQuest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ani1uz/d_can_you_extract_the_encoder_part_of_an_llm_for/</guid>
      <pubDate>Sat, 10 Feb 2024 14:54:09 GMT</pubDate>
    </item>
    <item>
      <title>我们推出了 ⚡Edgen：开源、本地和私有 AI！ [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1anhz90/we_launched_edgen_opensource_local_and_private_ai/</link>
      <description><![CDATA[      ⚡Edgen：Rust 中 OpenAI 的本地私有 GenAI 服务器替代品。无需 GPU。与任何操作系统兼容。只需下载一次即可开始在本地运行最好的 GenAI 模型，即：LLM（Llama2、Mistral、Mixtral...）、语音到文本（耳语）等等。 我们与⚡Edgen 的目标是让更多人能够进行以隐私为中心的本地 GenAI 应用程序开发。它符合 OpenAI 的 API，专为那些优先考虑数据隐私并希望使用基于 Rust 的基础设施在本地试验或部署 AI 模型的人而设计。 我们希望这个社区能够成为首先尝试一下，提供反馈，并为其成长做出贡献。 在这里查看：GitHub - edgenai/edgen ：⚡ Edgen：OpenAI 的本地私有 GenAI 服务器替代方案。 这是 EdgenChat 的一个简短演示，这是一个由 ⚡Edgen 提供支持的网络应用程序： ​  本地运行 Mistral 7B，我们支持 GGUF 的任何模型。 期待您的反馈！   由   提交/u/EdgenAI   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1anhz90/we_launched_edgen_opensource_local_and_private_ai/</guid>
      <pubDate>Sat, 10 Feb 2024 14:50:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我尝试用新的 Vision Pro 解释 FSDP 和 3D 管道并行性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1anhpp5/p_my_attempt_to_explain_fsdp_and_pipeline/</link>
      <description><![CDATA[       由   提交/u/waf04  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1anhpp5/p_my_attempt_to_explain_fsdp_and_pipeline/</guid>
      <pubDate>Sat, 10 Feb 2024 14:37:35 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于神经网络正则化的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1anh0dt/d_question_on_neural_net_regularization/</link>
      <description><![CDATA[假设我想使用有监督的 ML 方法来预测一些定量结果，并且我还想约束我的模型足以满足 k 个不同的统计数据数据。  （例如，k=2，我可以运行 PCA，在 PC1 和 PC2 上构建 GLM 来预测我的响应）。 是否有方法为以下节点执行此操作神经网络？显然，我可以简单地限制一个隐藏层有 k 个节点，现在我的充分性条件就满足了——但是我希望这 k 个节点中的信号是正交的呢？  我的理解是，我们会将这些节点之间的相似度得分纳入其训练的损失函数中，但是你们知道有什么具体方法可以做到这一点吗？   由   提交 /u/Silent_Mike   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1anh0dt/d_question_on_neural_net_regularization/</guid>
      <pubDate>Sat, 10 Feb 2024 14:02:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] VAE疑问</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1angxqc/d_vae_doubt/</link>
      <description><![CDATA[考虑变分自动编码器，一旦确定了重建误差，在无监督的情况下确定阈值的最佳方法是什么异常检测是否有任何标准文献方法请建议确定阈值的最佳方法。谢谢！   由   提交 /u/CheesecakeNatural393   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1angxqc/d_vae_doubt/</guid>
      <pubDate>Sat, 10 Feb 2024 13:59:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 CUML/SVC 管理 VRAM/RAM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1angdoe/p_managing_vram_ram_using_cumlsvc/</link>
      <description><![CDATA[      嗨，我首先要说的是，我是机器学习领域的绝对初学者，目前正在研究该主题。 我我正在 Fashion-MNIST 数据集上训练模型，并尝试使用 CUML 来使用我的 GPU 来帮助加快速度（使用 CPU 平均 3.5 分钟，而使用 GPU 平均需要 25 到 8 秒）。 I遇到一个问题，我认为代码将所有数据存储到 GPU 和 RAM 上，并使两者都饱和，我可以实现一些东西，一旦完成折叠，就会转储不需要的数据，为 RAM 和 RAM 提供更多空间GPU 显存？ ​  这是我的参考代码，有些库不会被使用，只是因为我正在虚拟机中编程，而 VS 在 Windows 上。    由   提交 /u/BubblyMidnight2574   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1angdoe/p_managing_vram_ram_using_cumlsvc/</guid>
      <pubDate>Sat, 10 Feb 2024 13:31:11 GMT</pubDate>
    </item>
    <item>
      <title>[P]我写了一些可以用TensorFlow训练的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1anesdv/p_i_wrote_some_models_that_can_be_trained_with/</link>
      <description><![CDATA[大家好，我用Note构建了一些神经网络模型，你可以用TensorFlow训练它们。  https://github.com/NoteDance/models    由   提交 /u/NoteDance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1anesdv/p_i_wrote_some_models_that_can_be_trained_with/</guid>
      <pubDate>Sat, 10 Feb 2024 12:00:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调法学硕士以适应领域</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ane4ia/d_finetuning_llm_for_domainadaption/</link>
      <description><![CDATA[我想使用一个已经训练有素的自然语言法学硕士 -&gt; sql 像 https://huggingface.co/defog/sqlcoder-7b-2 与我的数据库架构。我发现的所有指南都建议使用系统提示以创建语句的形式提供模式。  对于大型数据库模式来说，上下文窗口不是一个问题吗？或者我是否需要实现某种检索来找到与用户查询最相关的模式并将它们添加到系统提示符中？ 我更愿意“硬编码”将模式放入 llm 中，并进行微调以简化推理。为此，我已经将表转换为创建语句。每个表和列也有进一步解释数据的注释。如果可能的话，有人可以为此提供一些通用指南吗？训练数据需要什么样的格式。由于模型已经在 nl-&gt;sql 上进行了训练，我是否需要用自然语言来训练它 -&gt;我的 db-shema 上有 sql 示例，或者我可以简单地添加 db-schema 吗？   由   提交 /u/CaptainSnackbar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ane4ia/d_finetuning_llm_for_domainadaption/</guid>
      <pubDate>Sat, 10 Feb 2024 11:17:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] PyTorch 中从头开始的稳定扩散 |第一部分 - 无条件潜在扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1an9bvu/p_stable_diffusion_from_scratch_in_pytorch_part_i/</link>
      <description><![CDATA[       由   提交/u/tusharkumar91   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1an9bvu/p_stable_diffusion_from_scratch_in_pytorch_part_i/</guid>
      <pubDate>Sat, 10 Feb 2024 05:51:19 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 你在训练模型时遇到了哪些问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1an8hlb/discussion_what_kind_of_problems_do_you_run_into/</link>
      <description><![CDATA[对于许多人来说，尝试训练或微调开源模型却因为其复杂性而失败，这一定非常令人沮丧。  最近在播客上听到了 Huggingface 开发人员的对话，谈论他们如何识别和调试激活以应用标准化来稳定法学硕士的训练。  ​ 我很想知道，您在训练模型（甚至是非LLM）时遇到了什么样的问题以及您通常如何解决这些问题？    由   提交/u/iordanis_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1an8hlb/discussion_what_kind_of_problems_do_you_run_into/</guid>
      <pubDate>Sat, 10 Feb 2024 05:01:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么门控线性网络消失了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1an20kq/d_why_did_gated_linear_networks_disappear/</link>
      <description><![CDATA[DeepMind 研究人员想出了这个。在使用在线学习时，尤其是在上下文强盗方法中，它应该超越现有的解决方案。   由   提交 /u/__A-R__   /u/__A-R__  reddit.com/r/MachineLearning/comments/1an20kq/d_why_did_lated_linear_networks_disappear/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1an20kq/d_why_did_gated_linear_networks_disappear/</guid>
      <pubDate>Fri, 09 Feb 2024 23:33:07 GMT</pubDate>
    </item>
    <item>
      <title>信仰与命运：变形金刚对组合性的限制 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amzb52/faith_and_fate_limits_of_transformers_on/</link>
      <description><![CDATA[     &lt; td&gt; 编辑：Kevin Murphy、Francois Chollet、Vitaly Kurin 等人推荐了这篇论文（有些非常高度） https://arxiv.org/abs/2305.18654（12 月在 NeurIPS 上发表） 摘要：  Transformer 大语言模型 (LLM) 因其在需要复杂的多步骤推理的任务上的出色表现而备受赞誉。然而，这些模型同时在一些令人惊讶的微不足道的问题上失败了。这就引出了一个问题：这些错误是偶然的，还是表明存在更实质性的限制？为了揭开 Transformer LLM 的神秘面纱，我们研究了这些模型在三个代表性组合任务中的局限性——多位数乘法、逻辑网格难题和经典的动态规划问题。这些任务需要将问题分解为子步骤，并将这些步骤综合为精确的答案。我们将组合任务制定为计算图，以系统地量化复杂程度，并将推理步骤分解为中间子过程。我们的实证研究结果表明，变压器法学硕士通过将多步骤组合推理减少为线性子图匹配来解决组合任务，而不必培养系统的解决问题的技能。为了完善我们的实证研究，我们提供了关于抽象多步骤推理问题的理论论证，这些问题强调了自回归代的性能如何随着任务复杂性的增加而迅速衰减。  Kevin Murphy 的总结：“我喜欢这张纸。他们证明，变压器在进行长推理链时肯定会遭受复合错误（正如 @ylecun 所说），并且明显的“成功”只是由于不可靠的模式匹配/快捷学习。”   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amzb52/faith_and_fate_limits_of_transformers_on/</guid>
      <pubDate>Fri, 09 Feb 2024 21:34:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 交互式代理基础模型 - Microsoft 2024 - 开发通才、行动、多模式系统的有希望的途径！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amvzby/r_an_interactive_agent_foundation_model_microsoft/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2402.05929  摘要：  人工智能系统的发展正在从创建静态转变为、特定于任务的模型到动态的、基于代理的系统，能够在广泛的应用程序中表现良好。我们提出了一种交互式代理基础模型，它使用一种新颖的多任务代理训练范例来跨广泛的领域、数据集和任务训练人工智能代理。我们的训练范式统一了不同的预训练策略，包括视觉蒙版自动编码器、语言建模和下一步动作预测，从而实现了多功能且适应性强的人工智能框架。我们展示了我们的框架在三个不同领域的性能——机器人、游戏人工智能和医疗保健。我们的模型展示了其在每个领域生成有意义且与上下文相关的输出的能力。 我们方法的优势在于其通用性，利用各种数据源（例如机器人序列、游戏数据、大规模视频数据集和文本信息）进行有效的多模式和多任务学习。 &lt; strong&gt;我们的方法为开发通才、行动、多模式系统提供了一条有前途的途径。   https://preview.redd.it/cwl6ld2gzlhc1.jpg?width=1840&amp;format=pjpg&amp;auto=webp&amp;s=5963b8 c9452666b96e1285c03216179045f4b2fe&lt; /a&gt; https:// Preview.redd.it/u9nenp2gzlhc1.jpg?width=1826&amp;format=pjpg&amp;auto=webp&amp;s=5643d1ffcc9f31bf1a706559fbfc136b66bf1cfe https://preview.redd.it/254zpf2gzlhc1.jpg?width=1316&amp;format=pjpg&amp;自动=webp&amp;s= 0f30202307f5264c33b996ea8f7870f29233e907 https： //preview.redd.it/xwihaf2gzlhc1.jpg?width=639&amp;format=pjpg&amp;auto=webp&amp;s=f51d54a2edbc8737ad9c90506441df15521c3991    ;由   提交/u/Singularian2501   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amvzby/r_an_interactive_agent_foundation_model_microsoft/</guid>
      <pubDate>Fri, 09 Feb 2024 19:11:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你最喜欢的研究工具是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aml3w4/d_what_are_your_favorite_tools_for_research/</link>
      <description><![CDATA[这些是我个人最喜欢的： connectedpapers .com - 当您开始新的研究项目时，这是一个很棒的工具。从一篇相关论文开始，它会向您显示所有相关论文及其引用的图表。这让您可以很好地概述相关文献以及它们如何通过引用进行连接。 consensus.app - 人工智能用于研究的搜索引擎。您可以询问特定主题、相关论文等。如果您的论文中需要更多引用或想更好地了解相关作品，这是一个很好的工具。 paperparrot.ai - 这是一份个性化的研究论文时事通讯，每周根据您的兴趣向您发送一次最新论文的摘要。对于跟上新论文并且不错过您可能看不到的内容非常有用。 overleaf.com - 用于撰写研究论文或笔记的首选网络应用程序。您拥有版本控制，可以与多人协作，并且一切都是基于网络的。这是编写 LateX IMO 的最佳方式。 trello.com - 如果您的项目有多个协作者，这可以是有助于将事情组织起来并跟踪谁在做什么以及何时做什么。   由   提交 /u/Time-Sympathy724    reddit.com/r/MachineLearning/comments/1aml3w4/d_what_are_your_favorite_tools_for_research/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aml3w4/d_what_are_your_favorite_tools_for_research/</guid>
      <pubDate>Fri, 09 Feb 2024 10:23:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>