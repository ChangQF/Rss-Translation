<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sun, 30 Jun 2024 18:19:07 GMT</lastBuildDate>
    <item>
      <title>[D] 如何部署我的深度学习模型进行实时推理？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds7ls5/d_how_do_i_deploy_my_deep_learning_models_for/</link>
      <description><![CDATA[我已经构建了大约 10 个深度学习模型，我想实时对它们进行推理。我在推理后对图像进行某种预处理，然后将图像上传到 S3。我构建了一个托管在 EC2 实例上的 Flask 应用程序，但延迟太高了。我也尝试了 FastAPI，但效果也不好。最大的问题是没有为我分配用于此用例的 GPU，我现在讨厌处理这个问题。我确实探索了其他一些选项，例如 Torchserve，我想探索一些解决此用例的其他选项。如果您能提出建议，我将不胜感激。    提交人   ​​ /u/Muse_Not_Found   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds7ls5/d_how_do_i_deploy_my_deep_learning_models_for/</guid>
      <pubDate>Sun, 30 Jun 2024 18:10:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 连续和离散情况的 Wasserstein-Distance 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds55em/d_implementation_of_wassersteindistance_for/</link>
      <description><![CDATA[大家好， 目前，我正在尝试借助 Wasserstein（地球移动器）距离比较两个给定数据集的相似性。我不确定我的 Python 实现是否完全正确，我想知道是否有人可以验证或修复我的方法。该实现基于 spicy.stats 模块。该实现进一步在循环中运行以遍历整个数据集。 目前，我针对连续情况的当前方法是这样的： def was_distance(real_data, synthesized_data, attribute): vector1 = np.array(real_data[attribute]) vector2 = np.array(synthetic_data[attribute]) kde1 = gaussian_kde(vector1) kde2 = gaussian_kde(vector2) xmin = min(vector1.min(), vector2.min()) xmax = max(vector1.max(), vector2.max()) x = np.linspace(xmin, xmax, 100) p = kde1(x) p /= p.sum() q = kde2(x) q /= q.sum() ws_distance = wasserstein_distance(p, q) return ws_distance  提前致谢！    提交人    /u/Tasty-Stomach-7494   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds55em/d_implementation_of_wassersteindistance_for/</guid>
      <pubDate>Sun, 30 Jun 2024 16:18:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 表格提取建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds4plx/d_recommendation_for_table_extraction/</link>
      <description><![CDATA[我需要从扫描的文档中提取表格内容（主要是数字）。这些数字是键入的，而不是手写的。表格的位置和布局可能会略有变化。 目前最好的开源模型是什么？    提交人    /u/Electronic-Letter592   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds4plx/d_recommendation_for_table_extraction/</guid>
      <pubDate>Sun, 30 Jun 2024 15:58:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 难以实现准确的说话人分类：需要模型 / 服务推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds1d7u/d_struggling_with_accurate_speaker_diarization/</link>
      <description><![CDATA[我正在处理一些包含多个说话者且没有串扰的音频文件，但在说话者分类任务中我从未获得一致良好的结果。我尝试过开源模型和付费服务，但它们都没有产生足够好的结果。常见的错误包括说话者预测不正确和/或识别出的说话者数量不正确。 我觉得奇怪的是，这项任务对于普通人来说似乎非常简单，因为将音频的每个部分分配给正确的说话者（无论是现有的还是新的）都相当容易。所以，我不明白为什么这对深度学习模型来说如此困难。 如果您知道任何可以有效解决此任务的模型、算法或服务的建议，我将不胜感激。    提交人    /u/MultiheadAttention   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds1d7u/d_struggling_with_accurate_speaker_diarization/</guid>
      <pubDate>Sun, 30 Jun 2024 13:21:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您使用什么策略/工具来查找相关文献并保持最新状态？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds0caj/d_what_are_your_strategiestools_to_find_relevant/</link>
      <description><![CDATA[大家好， 当我还是一名博士生时，找到相关论文很容易，因为我只研究一个主题。现在，我从事工业界，对更广泛的论文感兴趣，因为我必须产生有趣的想法。所以我想 1/ 养成日常阅读的习惯，2/ 接触有趣的论文，也许是我所在领域之外的论文。您自己使用哪些策略和工具，甚至新闻通讯来实现这一点？ 过去我经常使用 Twitter，但现在它受趋势和炒作的支配，主要是法学硕士，所以我再也找不到很多论文了。Scholar Inbox 很棒，但它非常专注于特定主题，并没有真正致力于多样化。 谢谢！    提交人    /u/poiret_clement   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds0caj/d_what_are_your_strategiestools_to_find_relevant/</guid>
      <pubDate>Sun, 30 Jun 2024 12:27:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可疑的 ML 结果——这些输出实际上来自真实模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds08px/d_suspicious_ml_results_are_these_outputs/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds08px/d_suspicious_ml_results_are_these_outputs/</guid>
      <pubDate>Sun, 30 Jun 2024 12:21:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 可以从训练数据中的分散提示中推断出受审查的知识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drzalw/r_llms_can_infer_censored_knowledge_from/</link>
      <description><![CDATA[https://arxiv.org/abs/2406.14546 “我们研究归纳式非语境推理 (OOCR)，这是一种概括类型，其中 LLM 从分布在训练文档中的证据中推断潜在信息并将其应用于下游任务而无需语境学习。”    提交人    /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drzalw/r_llms_can_infer_censored_knowledge_from/</guid>
      <pubDate>Sun, 30 Jun 2024 11:22:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] 快速缓存：穷人的零样本视觉指南-LLM 分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dry5a8/p_prompt_caching_poor_mans_guide_to_zero_shot/</link>
      <description><![CDATA[        由    /u/themathstudent  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dry5a8/p_prompt_caching_poor_mans_guide_to_zero_shot/</guid>
      <pubDate>Sun, 30 Jun 2024 10:03:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 推荐有关 ML 研究/新闻/主要公司的 RSS 提要？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drpk01/d_recommended_rss_feeds_on_ml_research_news_major/</link>
      <description><![CDATA[我正在寻找相关的 RSS 源来关注，我希望涵盖当今 ML 的各个方面：研究、公司、MLOps 等。 我能找到的关于 RSS 源的最后一篇文章是 2 年前的，我认为已经过去了足够的时间值得更新。 您最推荐的 RSS 源是什么？    提交人    /u/fliiiiiiip   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drpk01/d_recommended_rss_feeds_on_ml_research_news_major/</guid>
      <pubDate>Sun, 30 Jun 2024 00:48:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前经过实战检验的最先进的多元时间序列回归机制是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drohkd/d_whats_the_current_battletested_stateoftheart/</link>
      <description><![CDATA[目前久经考验的最先进的多元时间序列回归机制是什么？使用多个时间序列来预测单个值。 对于多个半平稳时间序列。 我所说的“久经考验”是指至少 5% 的行业已经在使用它，或者目前正在大力采用它。    提交人    /u/igaloly   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drohkd/d_whats_the_current_battletested_stateoftheart/</guid>
      <pubDate>Sat, 29 Jun 2024 23:52:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] DDIM 反转和关键调整，以 SD 2.1 为基础实现人脸编辑功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drn9zs/p_ddim_inversion_and_pivotal_tuning_to_achieve/</link>
      <description><![CDATA[      Github : https://github.com/OutofAi/StableFace https://preview.redd.it/clulwrsnbl9d1.png?width=2048&amp;format=png&amp;auto=webp&amp;s=53d002746d951fb35bfeb928eed42644d05430e4    提交人    /u/TerryCrewsHasacrew   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drn9zs/p_ddim_inversion_and_pivotal_tuning_to_achieve/</guid>
      <pubDate>Sat, 29 Jun 2024 22:52:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] GraphReader：一种基于图形的 AI 代理系统，旨在通过将长文本构建成图形并使用代理自主探索该图形来处理长文本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drjcfz/r_graphreader_a_graphbased_ai_agent_system/</link>
      <description><![CDATA[    /u/valdanylchuk   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drjcfz/r_graphreader_a_graphbased_ai_agent_system/</guid>
      <pubDate>Sat, 29 Jun 2024 19:46:56 GMT</pubDate>
    </item>
    <item>
      <title>[D]: 微调 NuExtract-tiny</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drjbhj/d_finetune_nuextracttiny/</link>
      <description><![CDATA[我尝试微调 NuExtract-tiny 以从文本中提取以下信息： { &quot;document_type&quot;: &quot;&quot;, &quot;document_identifier&quot;: &quot;&quot;, &quot;subject&quot;: &quot;&quot;, &quot;effective_date&quot;: &quot;&quot;, &quot;revision_date&quot;: &quot;&quot;, &quot;publishing_date&quot;: &quot;&quot;, }  因此，我使用 gpt-4o 生成了合成训练数据，它看起来像 processed_data.jsonl 文件中存在的数据。我使用了大约 5000 个训练样本。我已将微调 NuExtract-tiny 的日志附在我的代码上。查看 validation_loss，它似乎没有经过太多微调。我有以下观察：  我比较了微调模型的结果，它们非常糟糕，比原始 NuExtract-tiny 差得多 此外，推理速度变得非常慢，即使原始模型和微调模型的大小相同。  我手动验证了使用 gpt-4o 生成的训练数据质量良好。 关于可能出现问题的任何建议？任何帮助都将不胜感激。我正在附加 Jupyter 笔记本和数据的链接 笔记本链接：https://drive.google.com/file/d/1ZDMVAGSIPXbkWDaJuCxcFLLduKZLqXjQ/view?usp=sharing processed_data.jsonl 链接：https://drive.google.com/file/d/11NYOINkIh4P-a3loB9KD6-C-XOs0Bfl8/view?usp=sharing 以下是微调模型和原始模型的比较： text = &quot;&quot;&quot;德克萨斯州医疗补助提供者程序手册 2022 年 2 月提供者手册 妇科、产科和计划生育第 19 条服务手册 德克萨斯州医疗补助和医疗保健合作伙伴关系 (TMHP) 是与德克萨斯州卫生和公共服务委员会签订合同的德克萨斯州医疗补助的索赔管理员。&quot;&quot;&quot;  给定模式： schema = &quot;&quot;&quot;{&quot;document_type&quot;: &quot;&quot;, &quot;document_identifier&quot;: &quot;&quot;, &quot;subject&quot;: &quot;&quot;, &quot;effective_date&quot;: &quot;&quot;, &quot;revision_date&quot;: &quot;&quot;, &quot;publishing_date&quot;: &quot;&quot;}&quot;&quot;&quot;  微调模型输出： { &quot;document_type&quot;: &quot;Handbook&quot;, &quot;document_identifier&quot;: &quot;&quot;, &quot;subject&quot;: &quot;Gynecological, Obstetrics, and Family &quot;effective_date&quot;: &quot;&quot;, &quot;revision_date&quot;: &quot;&quot;, &quot;publishing_date&quot;: &quot;&quot; }  原始模型输出： { &quot;document_type&quot;: &quot;Provider Procedures Manual&quot;, &quot;document_identifier&quot;: &quot;Provider Handbooks&quot;, &quot;subject&quot;: &quot;Gynecological, Obstetrics, and Family Planning Title XIX Services Handbook&quot;, &quot;effective_date&quot;: &quot;February 2022&quot;, &quot;revision_date&quot;: &quot;&quot;, &quot;publishing_date&quot;: &quot;&quot; }  您可以清楚地看到，微调模型失败了。    提交人    /u/n0pe09   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drjbhj/d_finetune_nuextracttiny/</guid>
      <pubDate>Sat, 29 Jun 2024 19:45:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 同事最近告诉我，认为“法学硕士能够思考/理解”的人都是从法学硕士开始从事 ML/NLP 职业的人。我很好奇你的想法。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drd3tv/d_coworkers_recently_told_me_that_the_people_who/</link>
      <description><![CDATA[我自己在这个领域并没有待很长时间。我在 2016-2017 年左右开始攻读硕士学位，当时 Transformers 开始流行起来。我已经在行业中工作了一段时间，最近刚刚加入一家专注于 NLP 的公司，担任 MLE。 在工作中，我们最近进行了一场辩论/讨论，讨论主题是 LLM 是否能够具备理解和思考的能力。我们讨论了 Emily Bender 和 Timnit Gebru 关于 LLM 是随机鹦鹉的论文，然后从那里开始。 意见大致各占一半：我们中的一半（包括我自己）认为 LLM 是 BERT 或 GPT-2 等模型的简单扩展，而其他人则认为 LLM 确实能够理解和领悟文本。在我的高级工程师发表标题中的评论后，我注意到一件有趣的事情，那就是那些认为 LLM 能够思考的人要么是在 LLM 成为既定事实后进入 NLP 的人，要么原本来自计算机视觉等不同领域，后来转行了。 我很好奇其他人对此的看法。我有点吃惊，因为我没想到 LLM 是有意识的理解生物的观点会在实际从事该领域的人中如此普遍；这是我从非 ML 人士那里听到的更多的事情。这些人也不只是新手工程师，我团队中的每个人都有在顶级 ML 场所发表文章的经验。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drd3tv/d_coworkers_recently_told_me_that_the_people_who/</guid>
      <pubDate>Sat, 29 Jun 2024 15:00:27 GMT</pubDate>
    </item>
    </channel>
</rss>