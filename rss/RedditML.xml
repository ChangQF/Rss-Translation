<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 25 Feb 2024 15:11:37 GMT</lastBuildDate>
    <item>
      <title>[D] 无需 GPS 即可定位照片的最佳工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azpyh1/d_best_tools_for_locating_photos_without_gps/</link>
      <description><![CDATA[我有很多旧照片，但不确定位置。我正在寻找能够根据照片内容帮助定位和标记 (EXIF) 的软件。 我找到的一些软件： https://github.com/TIBHannover/GeoEstimation https:// picarta.ai/ https://huggingface.co/geolocal/StreetCLIP 如果其他人尝试过此操作，我很好奇您尝试过什么以及您发现哪些最有用。  &amp;# 32；由   提交/u/eng33  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azpyh1/d_best_tools_for_locating_photos_without_gps/</guid>
      <pubDate>Sun, 25 Feb 2024 15:03:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何对两个时间序列数据集进行预测建模？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azp59t/p_how_do_i_do_predictive_modelling_on_two_time/</link>
      <description><![CDATA[我有两个数据集，想要执行某种预测建模。 [一台机器]。我现在很迷茫，不知道应该如何继续这个项目。我的最终目标是使用机器学习/数据分析进行某种流程优化（例如预测建模）。欢迎所有建议！我会喜欢你们推荐的任何资源。   第一个数据显示一段时间内机器的状态。机器状态 2000 行（运行、等待、故障、断电）  第二个数据集显示一段时间内机器的当前状态。机器的当前值，40000 行。请注意，当前值大部分是稳定的，但我注意到它们在故障之前出现尖峰。  另外： 主要输入参数：电流[仅一个传感器] 一种故障类型。没有给出这些机器的年龄。给出了状态持续时间。  第二个数据集大部分是连续的，大多数日子从 7:30:00 到 20:00:00。有时传感器数据会丢失（例如 11:00:00 到 13:00:00 等） 我曾多次尝试将两个数据集合并到一个表中，但没有成功截至目前。  如果你想看一下数据，我会PM你。谢谢！   由   提交 /u/maskedhypocriter   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azp59t/p_how_do_i_do_predictive_modelling_on_two_time/</guid>
      <pubDate>Sun, 25 Feb 2024 14:26:46 GMT</pubDate>
    </item>
    <item>
      <title>[N]Magika 简介：强大的文件类型检测库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azp35r/nintroducing_magika_a_powerful_file_type/</link>
      <description><![CDATA[      Magika 是 Google 开发的文件类型检测库，已获得关注。我们创建了一个网站，您可以在其中轻松试用 Magika。请随意尝试一下！ https://9revolution9.com/tools/security/file_scanner/  https:// /preview.redd.it/u5cuqvfyqqkc1.png?width=2094&amp;format=png&amp;auto=webp&amp;s=d16e51115134e3943cc6027cc0a9191ba835c38f ​ &lt; !-- SC_ON --&gt;  由   提交/u/glassonion999  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azp35r/nintroducing_magika_a_powerful_file_type/</guid>
      <pubDate>Sun, 25 Feb 2024 14:24:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我编写了一个用于调试 Triton 代码的小工具。有人感兴趣吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azmuf7/d_i_wrote_a_small_tool_for_debugging_triton_code/</link>
      <description><![CDATA[嘿，我正在编写 Triton 内核，据我所知，调试代码的唯一方法是使用 tl.device_print，它仅适用于张量数据（没有适合您的形状）并阻塞输出。因此，我编写了一个小工具来仅使用 torch 来运行内核，而无需更改代码。唯一的变化是减少启动网格大小并将内核包装器更改为调试包装器。下面是一个简单内核的示例： import torch import triton # import triton.language as tl import Tests.Triton.triton_debug_module as tl # @triton.jit @tl.debug def add_kernel(x_ptr , y_ptr, output_ptr, n_elem, BLOCK_SIZE: tl.constexpr): pid = tl.program_id(axis=0) block_start = BLOCK_SIZE * pid 偏移量 = block_start + tl.arange(0, BLOCK_SIZE) mask = 偏移量 &lt; n_elem x = tl.load(x_ptr + 偏移量, mask=mask) y = tl.load(y_ptr + 偏移量, mask=mask) 输出 = x+y tl.store(output_ptr + 偏移量, 输出, mask=mask) def add （x：torch.Tensor，y：torch.Tensor）：输出= torch.empty_like（x）断言x.is_cuda和y.is_cuda和output.is_cuda n_elem =输出.numel（）网格= lambda元：（triton.cdiv (n_elem, meta[&#39;BLOCK_SIZE&#39;]), ) add_kernel[grid](x, y, output, n_elem, BLOCK_SIZE=64) 返回输出  此代码将使用 torch 后端执行，并且您可以以正常方式查看每个张量形状和值。代码中唯一的变化是注释掉 triton.language 和 triton.jit 的导入，导入调试模块并在 tl.debug 中包装内核。 我还实现了内存读写的自动可视化（相同的东西，但是将内核包装在 tl.debug_vis 中，无需其他更改）。以下是 flashattention2 转发内核的示例： ​ Attn Fwd 那么，这个工具可能对某人有用吗？它仍然有点不完整，因为我还没有包装所有的triton函数，而且还有外部cuda函数，我只实现了tl.math.exp2 Floor sqrt和log2。那么，我应该开源吗？我应该发布 arxiv 内容还是将其提交给某个研讨会？   由   提交/u/clueless_scientist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azmuf7/d_i_wrote_a_small_tool_for_debugging_triton_code/</guid>
      <pubDate>Sun, 25 Feb 2024 12:31:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 受自然启发的本地传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azlava/r_natureinspired_local_propagation/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2402.05959 OpenReview：https:// /openreview.net/forum?id=uCMxeZCp2T 摘要：  机器学习领域取得的惊人成果，包括生成人工智能的最新进展依赖于大数据收集。相反，自然界中的智能过程不需要此类收集，而只需在线处理环境信息即可。特别是，自然学习过程依赖于数据表示和学习以尊重时空局部性的方式交织在一起的机制。本文表明，这种特征源于前算法的学习观，这种学习观受到理论物理学相关研究的启发。我们表明，当传播速度达到无穷大时，所导出的“学习定律”的算法解释采用哈密顿方程的结构，可简化为反向传播。这为基于完整在线信息处理的机器学习研究打开了大门，这些研究基于用所提出的时空局部算法替换反向传播。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azlava/r_natureinspired_local_propagation/</guid>
      <pubDate>Sun, 25 Feb 2024 10:58:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有 Mamba + RAG 研究用于微调来解决状态空间模型中的复制问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azkn3q/d_are_there_mamba_rag_research_for_finetune_to/</link>
      <description><![CDATA[Mamba + RAG 微调后也许可以解决无法复制的问题 (跟我重复一遍：在状态空间模型中，Transformers 优于状态空间模型复制)。   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azkn3q/d_are_there_mamba_rag_research_for_finetune_to/</guid>
      <pubDate>Sun, 25 Feb 2024 10:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 潜在空间理论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azk18e/d_theory_for_latent_space/</link>
      <description><![CDATA[大家好，我想知道是否有人有一些关于“潜在空间理论”的论文/参考文献可以分享。在神经网络中。我试图说得更清楚：现在我们在许多应用中看到神经网络在其隐藏层中找到了学习的相关模式。以 CNN 为例，以及我们检查网络学习的过滤器的方式。或者考虑一个“更简单”的方法。 word2vec：同样，我们可以通过绘制嵌入的投影来研究每个单词的特定情况下会发生什么。然而，这些都是启发式的，取决于具体情况。有人知道一个更通用的理论来描述这些隐藏层中发生的事情吗？抱歉，如果这个问题很幼稚，我来自物理学，我喜欢认为某个地方有一些原理:)   由   提交/u/PiMas88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azk18e/d_theory_for_latent_space/</guid>
      <pubDate>Sun, 25 Feb 2024 09:35:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深度神经网络中的梯度下降是隐式 Ricci 流吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azjaw7/d_is_gradient_descent_in_deep_neural_networks_an/</link>
      <description><![CDATA[假设此处的流形已连接。深度神经网络在流形假设下工作，即训练数据位于较低维流形上。特别是，最后一层是线性层，为了正常工作，这必须意味着目标流形曲率必须约为常数，因为线性子空间需要一致的曲率来逼近目标流形（在回归的情况下） ）或将其分开（在交叉熵的情况下）。也就是说，梯度下降生成的流形序列必须在其度量张量的意义上收敛到恒定曲率的流形。里奇流也这样做。我的比较正确吗？   由   提交 /u/Flankierengeschichte   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azjaw7/d_is_gradient_descent_in_deep_neural_networks_an/</guid>
      <pubDate>Sun, 25 Feb 2024 08:46:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于 MILA/UofT 硕士的一些问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azhpph/r_some_questions_regarding_milauoft_for_masters/</link>
      <description><![CDATA[嗨，我是西蒙弗雷泽大学四年级本科生， 我正在尝试去 MILA 学习硕士，我知道我需要先单独去麦吉尔，然后申请 MILA，但我想知道它的竞争力如何。 在这里也询问 UofT： GPA 通常是多少？之前有多少合作社？喜欢研究？我的 GPA 为 3.65，之前曾在某中型云公司实习过，我计划今年夏天参加一些实验室 我正在尝试看看我在那里有什么机会&lt; /p&gt;   由   提交/u/Timely_Book5046   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azhpph/r_some_questions_regarding_milauoft_for_masters/</guid>
      <pubDate>Sun, 25 Feb 2024 07:03:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 除了检索增强生成（RAG）之外，还有哪些使用法学硕士构建的其他范式和框架？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azf0ul/d_what_are_some_other_paradigms_and_frameworks/</link>
      <description><![CDATA[自 InstructGPT 及其大众市场应用程序 ChatGPT 上市以来，已经一年多了，并引发了我们今天看到的围绕法学硕士的兴趣风暴。  除了研究和学术兴趣之外，行业（初创企业、大型企业等）也出于商业原因尝试构建由法学硕士支持的新产品和/或功能。 然而，到目前为止，我所看到的大部分内容要么是围绕 LLM 的薄包装应用程序，要么是 RAG 的某些变体。  除了检索增强生成（RAG）之外，还有哪些使用法学硕士进行构建的其他范式和框架？   由   提交/u/gamerx88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azf0ul/d_what_are_some_other_paradigms_and_frameworks/</guid>
      <pubDate>Sun, 25 Feb 2024 04:27:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 根据一个unet调整另一个unet的子集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azedr0/d_adjusting_a_subset_of_one_unet_based_on_another/</link>
      <description><![CDATA[假设我有 2 个 unets：1 个有 50,000 个值，1 个有 18,000 个值。 它们具有相同的维数。&lt; br /&gt; 较小的集合是较大集合的严格子集，从某种意义上说，我可以告诉您 Smallset[x] 与 Largeset[y] 代表相同的概念 现在问题来了。&lt; /p&gt; 虽然我知道 Smallset 中的哪些索引与 Largeset 中的索引相对应......但实际的 unet 权重是独立训练的。因此，Smallset[x] 的权重与 Largeset[y] 的权重完全无关 但是较小的集合训练得更好。 所以，理想情况下，我想围绕较小集合中的训练重塑较大集合中的其他 30,000 个值。 任何人都可以推荐现有的标准方法来执行此操作吗？ 理想情况下，使用也不会花费我 100,000 美元的计算能力的方法吗？ :-)  ​   由   提交/u/lostinspaz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azedr0/d_adjusting_a_subset_of_one_unet_based_on_another/</guid>
      <pubDate>Sun, 25 Feb 2024 03:53:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 拥抱面部加速与闪电织物</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azck48/d_hugging_face_accelerate_versus_lightning_fabric/</link>
      <description><![CDATA[TL; DR：正如标题所述，我的问题非常简单：使用过这两个库的人，两者的优缺点是什么，您会推荐哪个？ ​ &lt;我不想像 PyTorch Lightning 那样引入抽象，并且希望尽可能多地控制训练循环。这主要是因为我不想重构我的代码以最适合闪电的最佳实践。但是，我仍然想使用多 GPU、多节点和混合精度训练，这两个似乎是最明显的候选者。 ​  拥抱面部加速和Lightning Fabric 从“从 PyTorch 转换”的角度看，两者看起来很相似。指南：  初始化设备对象。 通过库的  包装模型、优化器和数据加载器.setup()/.prepare() 功能。 删除 .to(device) 调用。 &lt; li&gt;更新 .backward() 调用以通过对象反向传播损失。  ​ 所以我的问题是：其中一个比另一个有优势吗？我是否遗漏了任何明显的问题。我没有详细查看他们的文档，所以如果有人使用过这些库，如果您能分享任何经验/建议，那就太好了。谢谢。   由   提交 /u/DaredevilMeetsL   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azck48/d_hugging_face_accelerate_versus_lightning_fabric/</guid>
      <pubDate>Sun, 25 Feb 2024 02:19:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] Layernorm 只是两个投影，可以改进</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1az1bto/d_layernorm_is_just_two_projections_and_can_be/</link>
      <description><![CDATA[我正在考虑如何可视化向量的层范数，并发现它只是在学习参数为空时应用两个投影（如果不是） ，然后他们只需添加重新缩放和平移）。 通过删除平均值，您可以投影到超平面上，其中分量的平均值（或总和）为空（例如，在 3D x + y + z = 0 中）然后除以标准差，投影到半径 sqrt(D) 的球体上。 鉴于 Layernorm 的理论目标是使数据按照 D 维度的标准高斯重新缩放，则投影到超平面实际上失去了标准高斯通常使用的一维。 在高维 D 中，由于大数定律应用于 D 维的范数，人们可以用 D 维中的超球面来近似标准高斯分布由此生成的向量（对于一维标准高斯，x_i2 的平均值为 1），因此通过获取点并将它们射入超球体来近似这一点在理论上是有动机的，但减少一维会损失表示能力。 上述主张可以通过注意到以下事实来证明：对于向量 x = (x_1, ..., x_D)，x - (x_1 + ... + x_D)/D = x - 1 mu 与超平面上的正交投影相同，其中 mu = 0（1 是所有 1 的向量，因为我们从每个分量中删除了平均值）。  证明：如果取线性函数 M : RD -&gt; R，M(x)＝mu，则M(x)＝&lt;n，x&gt;/&lt;n，n&gt;对于 n = 1，1 的向量。但是 x - M(x) 1 = x - / n 是正交投影和去除所有分量均值的公式。 然后，对于 x&#39; = x - M(x)，layernorm 变为 x&#39; / sqrt( 1/Dnorm(x&#39;)2 ) = sqrt(D) x&#39; /norm(x&#39;)，半径为 sqrt(D) 的超球面投影。 学习到的参数移动这个超球面并单独缩放组件，在初始化时它们不执行任何操作。 您可以想象，在 3D 中，这对应于在 x + y 平面内绘制半径 sqrt(3) 的圆+ z = 0。在未学习的层范数之后，所有点都会在那里结束，请注意这是一个圆，而不是一个完整的球体。 我认为，考虑到层范数最终会被线性层进一步转换为一个网络中，如果需要，这些层可以进行投影，但像这样，它们没有选择不进行投影。 tl;dr：Layernorm 投影到超平面上，然后投影到半径球体上开方（D）。我声称超平面上的投影是浪费的，并且减少了一个自由度，而这个自由度可以由网络中进一步的线性层来处理。   由   提交 /u/mgostIH   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1az1bto/d_layernorm_is_just_two_projections_and_can_be/</guid>
      <pubDate>Sat, 24 Feb 2024 18:19:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用法学硕士进行文本分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ayx6xf/p_text_classification_using_llms/</link>
      <description><![CDATA[您好，我正在寻找一种解决方案，对分布在 7000 多个标记数据实例中的 10-20 个不同类别进行监督文本分类。我有 xlsx 和 jsonl 格式的数据，但可以轻松转换为所需的任何格式。我也尝试过基本的机器学习技术和深度学习，但我认为由于变压器架构，法学硕士会提供更高的准确性。我正在研究 Gemini 提供的函数调用功能，但它有点复杂。是否有任何好的框架和易于理解的示例可以帮助我对任何法学硕士进行零镜头、少量镜头和微调培训？ Colab 会议将不胜感激。如果需要，我也可以访问 Colab pro。不是任何其他付费服务，但最多可花费 5 美元 (USD)。这是一个个人研究项目，因此预算相当紧张。如果您能指导我找到任何对这项任务有用的资源，我将非常感激。任何 LLM 都可以。 我还研究了通过 ollama 使用自定义 LLM，并且能够在 Colab 实例上设置 Mistra 13b 的 6 位量化版本，但还无法使用它进行分类。另外，我认为 Gemini 是我的最佳选择，因为可用的 VRAM 数量有限。即使我可以在 Colab 上临时加载高端模型，我也需要很长时间，经过大量的试验和错误才能使代码正常工作，即使在那之后，也需要很长时间来预测类。也许我们可以使用数据集的子集来实现此目的，但这仍然需要很长时间，而且 Colab 有 12 小时的限制   由   提交/u/Shubham_Garg123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ayx6xf/p_text_classification_using_llms/</guid>
      <pubDate>Sat, 24 Feb 2024 15:29:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>