<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Sun, 11 Aug 2024 03:16:28 GMT</lastBuildDate>
    <item>
      <title>[R] 树注意力：GPU 集群上长上下文注意力的拓扑感知解码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep9qpa/r_tree_attention_topologyaware_decoding_for/</link>
      <description><![CDATA[一篇新的研究论文介绍了一种树注意力算法，用于在多个 GPU 上并行化注意力计算，利用 logsumexp 和 max 运算的关联属性将约简结构化为树。 树注意力算法使跨设备解码能够比 Ring Attention 等替代方法渐近地更快地执行（最高可快 8 倍），同时还需要显著减少通信量并将峰值内存减少 2 倍。    提交人    /u/AhmedMostafa16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep9qpa/r_tree_attention_topologyaware_decoding_for/</guid>
      <pubDate>Sun, 11 Aug 2024 02:17:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从头训练稳定扩散时产生噪声</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep8u6h/d_noisy_generation_when_traininig_stable/</link>
      <description><![CDATA[      您好， 我在 CIFAR10 上从头开始训练稳定扩散 1.4。我改编了来自扩散器的 train_text_to_image.py 的代码，删除了 VAE 部分并直接在像素空间上训练（因为它是 CIFAR）。我还修改了架构以使其更小（例如更少的通道和层）。其他一切保持不变。但是，经过足够多的步骤（例如 170K 步骤 * 8 批量大小）后，结果仍然非常嘈杂。例如，第一张图片是 SD1.4 的生成，但具有 [256, 512, 1024] 通道和 [down/up2d, crossattn, crossattn] 每个块 2 层，仅在飞机类上进行训练。第二张图片是 [64, 128, 256] 和每个块 1 层，在 10 个类上进行训练。有人可以提示我做错了什么吗？这可能是什么原因造成的？ 非常感谢！！ https://preview.redd.it/y2wbvta1uxhd1.png?width=257&amp;format=png&amp;auto=webp&amp;s=16e4892b46452499363835029944f01c90b9588b https://preview.redd.it/1u5uigp1uxhd1.png?width=1006&amp;format=png&amp;auto=webp&amp;s=570e7e3f0f9ee23aa61f5183e659862173682793    提交人    /u/ImaginaryAd9209   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep8u6h/d_noisy_generation_when_traininig_stable/</guid>
      <pubDate>Sun, 11 Aug 2024 01:29:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻找梯度下降方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep5od0/p_looking_for_a_gradient_descent_approach/</link>
      <description><![CDATA[我有一个梯度下降方法的想法，它试图直接“跳”到附近最小值的（预测）位置。它的工作原理是围绕一个点近似 2-5 阶泰勒多项式，然后求解最小值（如果可能）并将该点设置为新的 x。然后，可以重复该过程。如果任何一点的泰勒多项式都是凹的，那么我们可以使用更标准的梯度下降方法。 这似乎是一种相当简单的方法，所以我怀疑它是否新颖，但我在网上找不到类似的东西。有谁知道这种方法叫什么或者是否已经研究过它？ 我受到了牛顿求根方法的启发，并且对超参数调整有点不屑一顾。 以下是 desmos 对二次和三次泰勒近似的演示： 二次下降：https://www.desmos.com/calculator/i2nsjaxzhy 三次下降：https://www.desmos.com/calculator/kgkbcfdn7t    提交人    /u/IgorTheMad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep5od0/p_looking_for_a_gradient_descent_approach/</guid>
      <pubDate>Sat, 10 Aug 2024 22:52:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] WildHallucinations：使用真实世界实体查询评估法学硕士 (LLM) 中的长篇事实性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep4tn3/r_wildhallucinations_evaluating_longform/</link>
      <description><![CDATA[一篇新论文旨在创建一个现实的基准 WildHallucinations，用于评估 LLM 事实性。    提交人    /u/AhmedMostafa16   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep4tn3/r_wildhallucinations_evaluating_longform/</guid>
      <pubDate>Sat, 10 Aug 2024 22:12:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LSTM 建模动态系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep3kra/d_modeling_a_dynamic_system_using_lstm/</link>
      <description><![CDATA[      亲爱的大家， 在观看了这段制作精良的视频后，我决定使用相同的概念对我的真实系统进行建模。基本上，我想对我的真实机器人的动态进行建模，以便创建相同的“数字孪生”。换句话说，我想在模拟器中重新创建具有虚拟物理属性的相同机器人，并像真实机器人一样移动它。 我的机器人使用操纵杆驱动，操纵杆在每个轴上输出一个介于 -1.0 和 1.0 之间的浮点数。我收集了数据（真正的机器人帽子传感器已经在工作并实施）。为简单起见，假设我想通过从左向右移动操纵杆轴来驱动以下关节坐标（图 1）。 图 1 我收集了一个小时的数据，然后使用以下数据训练了一个隐藏大小为 32 的 LSTM：  输入是操纵杆输入和关节坐标（机器人的状态）的连接 目标由下一步中机器人的状态表示。我只是复制了状态的列并将其向后移动一个单位。图 2 显示的可能比 1000 个单词更好。  图 2 然后我创建了长度为 200 的序列并训练了我的 LSTM。 训练收敛得非常快，我对结果非常满意。但不知何故，虚拟机器人在虚拟环境中反应奇怪。它以惊人的速度从一个位置跳到另一个位置，然后移动得非常慢。因此，它不会像真正的机器人那样做出反应（真正的机器人在运动过程中更平稳）。 在这种问题中我是否遗漏了重要的东西？ 为了创建真实机器人的良好数字孪生，我还应该考虑什么？ 请注意：  尽管有上述示例，但我将所有运动标准化为范围 [-1, 1] 或 [0, 1] 所有数据均使用以太网电缆收集（因此不会因无线通信等而造成延迟） 我使用了 PyTorch 的 LSTM 类，而不是自定义实现 通过生成具有不同频率的正弦波输入并覆盖关节的所有范围来收集数据。 对于训练，我对数据进行了打乱：随机选择一个起始索引，并剪切一个包含 200 个元素的序列并用于训练。     由   提交  /u/WilhelmRedemption   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep3kra/d_modeling_a_dynamic_system_using_lstm/</guid>
      <pubDate>Sat, 10 Aug 2024 21:15:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 Amazon SageMaker 推理 AudioCraft MusicGen 模型 | Amazon Web Service</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep0go2/r_inference_audiocraft_musicgen_models_using/</link>
      <description><![CDATA[        由    /u/navulerao  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep0go2/r_inference_audiocraft_musicgen_models_using/</guid>
      <pubDate>Sat, 10 Aug 2024 18:53:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 实现人类水平的竞技机器人乒乓球</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eozvwt/r_achieving_human_level_competitive_robot_table/</link>
      <description><![CDATA[  由    /u/RobbinDeBank  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eozvwt/r_achieving_human_level_competitive_robot_table/</guid>
      <pubDate>Sat, 10 Aug 2024 18:27:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你的 neurips 讨论阶段进行得怎么样？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eowx75/d_how_is_your_neurips_discussion_period_going/</link>
      <description><![CDATA[你的 neurips 讨论期进行得怎么样？ 有什么有趣的轶事吗？    提交人    /u/SuchOccasion457   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eowx75/d_how_is_your_neurips_discussion_period_going/</guid>
      <pubDate>Sat, 10 Aug 2024 16:20:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 思维提示程序：将计算与数字推理任务的推理区分开来</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eowis8/r_program_of_thoughts_prompting_disentangling/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eowis8/r_program_of_thoughts_prompting_disentangling/</guid>
      <pubDate>Sat, 10 Aug 2024 16:03:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何从预训练中选择时期？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eovscv/d_how_do_you_select_epoch_from_pretraining/</link>
      <description><![CDATA[我正在对大约一百万张图像进行 ViT 预训练，从论文来看，似乎预训练的时间越长，预期的性能就越好。但是，在我的例子中，第 400 个 epoch 在下游任务上的表现比第 800 个 epoch 好得多。是不是数据越多，epoch 就越多？我们在预训练时也应该保留验证集吗？    提交人    /u/hymnweekz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eovscv/d_how_do_you_select_epoch_from_pretraining/</guid>
      <pubDate>Sat, 10 Aug 2024 15:31:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] AgentGen：通过环境和任务生成增强基于大型语言模型的代理的规划能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eotkae/r_agentgen_enhancing_planning_abilities_for_large/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eotkae/r_agentgen_enhancing_planning_abilities_for_large/</guid>
      <pubDate>Sat, 10 Aug 2024 13:52:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 的替代品？你有什么经验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eokswq/d_transformer_alternatives_what_are_your/</link>
      <description><![CDATA[我看过一些关于 Transformer 替代方案的文章，但我没有看到人们在自己的数据集中使用它们的经验。是的，论文会告诉你它们很棒，但是从头开始制作它们并训练它们并找到好的超参数等经验......领域中的变化及其对它的影响；这些都是有价值的东西，但我们没有考虑到。 所以我想讨论一下 Transformer 的替代方案？哪一个是你最喜欢的，或者体验如何？    提交人    /u/MysticalDragoneer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eokswq/d_transformer_alternatives_what_are_your/</guid>
      <pubDate>Sat, 10 Aug 2024 04:55:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] Apple Intelligence Foundation 语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eogp0c/r_apple_intelligence_foundation_language_models/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eogp0c/r_apple_intelligence_foundation_language_models/</guid>
      <pubDate>Sat, 10 Aug 2024 01:17:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>