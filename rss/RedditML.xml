<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 05 Oct 2024 03:20:35 GMT</lastBuildDate>
    <item>
      <title>[D] KDD 2025 评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fw7kga/d_kdd_2025_reviews/</link>
      <description><![CDATA[大家好， KDD 2025 论文评论可在 OpenReview 上查看。评论发布后，我想创建一个讨论主题来收集想法、问题和建议或其他任何内容。就我个人而言，我发现评级方案对于如何做出最终决定有点令人困惑，但我很乐意听听其他人的想法。 祝大家一切顺利！    提交人    /u/AAGT_YT   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fw7kga/d_kdd_2025_reviews/</guid>
      <pubDate>Fri, 04 Oct 2024 19:27:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] FP16 与 FP32 相比，据称占用的内存更少，但模型大小却增加了一倍？性能上是否有优势？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fw6b7b/d_fp16_vs_fp32_supposedly_takes_less_memory_but/</link>
      <description><![CDATA[所以，我有一个问题已经在我脑海里萦绕了一段时间。 每当我尝试查找 FP16 和 FP32 之间的区别时，它通常会说一个好处是减少内存需求，但每当我找到 FP16 模型（例如：llama3.1:8b-instruct-fp16）时，它似乎都是原来的两倍大。 此外，与最新的 FP32 选项相比，使用此模型有什么好处？ 我刚刚从 Nvidia Tesla P100 升级到 RTX 3090 24Gb，以获得更多内存和速度（顺便说一下，速度更快），我想找一些模型来真正测试一下 VRAM，但似乎用流行模型填充内存的最佳方式是它们的 FP16 变体。我只是想知道我是否也能从中受益，以及 FP16 是否比 FP32 有优势。我也一直在想我听说过的“减少内存”，因为它没有意义，我很乐意进一步了解这一点。 愿意分享您的知识吗？（感谢所有回复！） 附加问题： 您有推荐的 13-24Gb 型号吗？ Tesla P100 是 12Gb，所以我很想尝试 24Gb VRAM。    提交人    /u/lightmystic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fw6b7b/d_fp16_vs_fp32_supposedly_takes_less_memory_but/</guid>
      <pubDate>Fri, 04 Oct 2024 18:33:27 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 动态Bert系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fw3q74/project_dynamic_bert_system/</link>
      <description><![CDATA[目前，我正在寻找构建一些快速的 llm 工作者。例如 Berts、Elektra 等  欢迎提出建议。鉴于我投入到项目上的时间不够，我不知道如何提炼出最佳方案。 我也是开发这些小型机器人的完全新手，还没有时间学习如何开发。我现在正在重新调整一些 gpt 代理，但这只是短期的。 如果有人想参与该项目，可以给我发私信吗？这是该项目的重要组成部分。目前，除了可以访问正在构建的 berts 以及未来可能提供的更多内容之外，我没有什么可以提供的  如果您以前从头开始开发过 pinns，我对您的意见很感兴趣。  我的专长是动态系统和了解来龙去脉     提交人    /u/cosmic_timing   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fw3q74/project_dynamic_bert_system/</guid>
      <pubDate>Fri, 04 Oct 2024 16:43:54 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以了解 ISO 23053？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvyi9d/where_can_i_learn_about_iso_23053_d/</link>
      <description><![CDATA[这是被描述为“使用机器学习 (ML) 的人工智能 (AI) 系统框架”的标准。我搜索了网络，发现关于 42001 的资料相当多，但关于 23053 的资料却很少。我尝试过常规搜索、Youtube 和 Scribd。这是为了让我能够随时了解人工智能管理的发展，但我希望它在某个阶段的工作环境中会很有用。 作为一个“元”级框架，它在试图向管理层传达技术团队正在做什么的总体情况时听起来很有用。任何提示都值得赞赏！ 来自 ISO 网站的描述：本文档建立了一个人工智能 (AI) 和机器学习 (ML) 框架，用于描述使用 ML 技术的通用人工智能系统。该框架描述了系统组件及其在人工智能生态系统中的功能。本文档适用于正在实施或使用 AI 系统的所有类型和规模的组织，包括公共和私营公司、政府实体和非营利组织。    提交人    /u/impracticaldogg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvyi9d/where_can_i_learn_about_iso_23053_d/</guid>
      <pubDate>Fri, 04 Oct 2024 12:57:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] WACV 2025 第 1 轮反驳评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvyewv/d_wacv_2025_round_1_rebuttal_reviews/</link>
      <description><![CDATA[按照计划，审稿人应该在今天（10 月 4 日）第一轮反驳后更新评论，有人知道所有审稿人都更新了他们的评论吗？我有 3 位审稿人，其中 2 位更新了，1 位没有。如果该审稿人不更新评论会怎样？这会影响我的论文结果吗？我让另外 2 位审稿人接受了，但剩下的一位最初给了我一个软弱的拒绝（我在反驳中解决了他的担忧）。     提交人    /u/tuvovan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvyewv/d_wacv_2025_round_1_rebuttal_reviews/</guid>
      <pubDate>Fri, 04 Oct 2024 12:53:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否可以将 NeurIPS 拒绝的论文评论公开？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvy0n4/d_option_to_make_neurips_rejected_paper_reviews/</link>
      <description><![CDATA[NeurIPS 发出的决定通知电子邮件提到，我们将可以选择公开发布对被拒绝论文的评论，并且会在几天内提供说明。 已经过去一周了，我们还没有收到任何电子邮件，也没有任何作者任务可以选择加入。由于去年这封电子邮件是在通知发出 3 天后才发送的，我想知道是否存在问题，是否没有人收到电子邮件？    提交人    /u/Aj0o   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvy0n4/d_option_to_make_neurips_rejected_paper_reviews/</guid>
      <pubDate>Fri, 04 Oct 2024 12:32:41 GMT</pubDate>
    </item>
    <item>
      <title>使用 BERT、Pytorch 和 deepspeed [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvwxv8/working_with_bert_pytorch_and_deepspeed_p/</link>
      <description><![CDATA[[P] 我目前正在开展一个名为“心理健康情绪分析”的项目，我使用的数据集相当大，我正在使用 kaggle，我的模型处于训练阶段，我使用 bert-uncased（我尝试使用 distilbert，但准确度低至 0.23）所以我有 apytorch 数据集，我使用了 deepspeed（是的，我知道它通常用于分布式 gpu，我正在使用 P100 GPU，最后  我的问题是训练速度大约为 17 分钟（在调整 batch_size 等参数之后），我想减少它，或者有 17 分钟的训练时间可以吗，我真的想减少它，请告诉我如何减少并为我的项目提供一些建议。 谢谢    提交人    /u/No_Interest_240   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvwxv8/working_with_bert_pytorch_and_deepspeed_p/</guid>
      <pubDate>Fri, 04 Oct 2024 11:32:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] Docker 容器（Python）与边缘设备上 AI 的直接 C++ 实现，性能权衡</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvup0i/d_docker_containers_python_vs_direct_c/</link>
      <description><![CDATA[我正在探索将 AI 产品部署到生产的最佳方法，尤其是在智能家居系统和摄像头等边缘设备上。我想知道在这些场景中使用 Docker 容器、python 代码与直接用 C++ 实现推理代码之间的权衡。 关键考虑因素：  性能：Docker 的开销是否会显著影响资源受限的边缘设备上的 AI 模型性能？ 硬件利用率：C++ 实现能否更好地利用特定硬件功能进行 AI 加速？  我很想听听那些有将 AI 模型部署到边缘设备经验的人的意见。您发现哪种方法最有效，为什么？是否存在一种方法明显优于另一种方法的特定用例？    提交人    /u/binhbumpro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvup0i/d_docker_containers_python_vs_direct_c/</guid>
      <pubDate>Fri, 04 Oct 2024 08:58:09 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 产品实体标准化的最新技术是什么？即建立一个系统，通过将产品名称的变体映射到标准参考列表来识别和纠正产品名称的变体？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvuhr9/project_what_are_the_stateoftheart_techniques_for/</link>
      <description><![CDATA[大家好，我一直在做一个项目，涉及从一组商业提案中提取和标准化产品名称。目标是将每个产品名称变体映射到客户提供的参考列表，这将有助于保持我们数据库的一致性。我目前正在探索实体匹配和产品名称规范化的最新方法。如果有人有类似项目的经验或对工具和技术的建议，我很乐意听听你的想法。谢谢！    提交人    /u/No_Possibility_7588   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvuhr9/project_what_are_the_stateoftheart_techniques_for/</guid>
      <pubDate>Fri, 04 Oct 2024 08:42:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] ECCV24 github 项目，包含已接受的论文和 API</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvktlc/p_eccv24_github_project_with_accepted_papers_and/</link>
      <description><![CDATA[Github 自述文件：https://github.com/jbdel/ECCV24-papers-huggingface API 在这里：https://huggingface.co/spaces/ECCV/ECCV2024-papers?view=api    提交人    /u/redjbd   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvktlc/p_eccv24_github_project_with_accepted_papers_and/</guid>
      <pubDate>Thu, 03 Oct 2024 23:01:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 宣布推出首批 Liquid Foundation 模型 (LFM) - 新一代生成式 AI 模型，可在各个规模上实现最先进的性能，同时保持更小的内存占用和更高效的推理。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvgo7o/r_announcing_the_first_series_of_liquid/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvgo7o/r_announcing_the_first_series_of_liquid/</guid>
      <pubDate>Thu, 03 Oct 2024 19:57:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我们所需要的只是 RNN 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvg7qr/r_were_rnns_all_we_needed/</link>
      <description><![CDATA[https://arxiv.org/abs/2410.01201 作者（包括 Y. Bengio）提出了 LSTM 和 GRU 的简化版本，允许并行训练，并在一​​些基准测试中显示出强劲的结果。    提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvg7qr/r_were_rnns_all_we_needed/</guid>
      <pubDate>Thu, 03 Oct 2024 19:37:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 更大、更易于指导的语言模型变得不那么可靠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fv4hxo/p_larger_and_more_instructable_language_models/</link>
      <description><![CDATA[      《自然》杂志上的一篇非常有趣的论文，后面是其中一位作者对 X 的摘要。 结论基本上是使用更多的计算资源和人类反馈训练的大型模型在几个方面对人类的可靠性会降低，例如，模型可以解决非常困难的任务，但在同一领域中无法解决许多简单的任务，并且这种不一致对于较新的模型来说变得越来越严重（基本上即使是简单的任务也无法实现无错误，而且人类越来越难以预测模型失败？）。论文还表明，较新的 LLM 现在更少地回避任务，从而导致更多错误/幻觉输出（这颇具讽刺意味：所以 LLM 变得更加正确，但同时也变得更加不正确）...... 我很好奇，他们表明快速工程可能不会通过简单地扩大模型规模而消失，因为较新的模型只是在逐步改进，而人类不善于发现输出错误以抵消不可靠性。GPT、LLAMA 和 BLOOM 系列的 32 个 LLM 的结果似乎一致，并且在 X-thread 中，他们还表明不可靠性仍然存在于其他非常新的模型中，如 o1-preview、o1-mini、LLaMA-3.1-405B 和 Claude-3.5-Sonnet。这里有很多东西需要解开。但需要注意的是，这项工作并不是对当前的扩展范式进行挑战，而是对 LLM 的一些其他设计实践（例如数据选择和人工反馈的流程）进行了挑战，这些实践可能导致了这些问题，值得关注。 https://preview.redd.it/hpd7yynaqisd1.png?width=1888&amp;format=png&amp;auto=webp&amp;s=ebc7953700935ee85cafd2f5d3602b80418d4523    由   提交  /u/Appropriate_Annual73   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fv4hxo/p_larger_and_more_instructable_language_models/</guid>
      <pubDate>Thu, 03 Oct 2024 10:26:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 29 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>