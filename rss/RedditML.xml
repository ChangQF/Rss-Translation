<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Wed, 08 May 2024 06:17:08 GMT</lastBuildDate>
    <item>
      <title>【研究】xLSTM：扩展长短期记忆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmwljs/research_xlstm_extended_long_shortterm_memory/</link>
      <description><![CDATA[摘要： 20世纪90年代，恒定误差轮播和门控被引入作为长短期的中心思想记忆（LSTM）。从那时起，LSTM 经受住了时间的考验，并为许多深度学习的成功案例做出了贡献，特别是它们构成了第一个大型语言模型 (LLM)。然而，以并行自注意力为核心的 Transformer 技术的出现标志着一个新时代的到来，其规模超过了 LSTM。我们现在提出一个简单的问题：当将 LSTM 扩展到数十亿个参数、利用现代法学硕士的最新技术、同时缓解 LSTM 的已知局限性时，我们在语言建模方面能走多远？首先，我们引入具有适当归一化和稳定技术的指数门控。其次，我们修改 LSTM 内存结构，获得：（i）具有标量内存、标量更新和新内存混合的 sLSTM，（ii）具有矩阵内存和协方差更新规则的完全可并行化的 mLSTM。将这些 LSTM 扩展集成到残差块主干中会产生 xLSTM 块，然后将这些块残差地堆叠到 xLSTM 架构中。与最先进的 Transformer 和状态空间模型相比，指数门控和修改后的内存结构增强了 xLSTM 的性能，无论是在性能还是扩展方面。 链接：xLSTM：扩展长短期记忆   由   提交 /u/Background_Thanks604   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmwljs/research_xlstm_extended_long_shortterm_memory/</guid>
      <pubDate>Wed, 08 May 2024 05:06:40 GMT</pubDate>
    </item>
    <item>
      <title>非技术性 ML 播客？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmntyr/non_technical_ml_podcasts_d/</link>
      <description><![CDATA[大家好。就背景而言，我是一名刚毕业的计算机科学毕业生，目前是入门级数据工程师，我一直喜欢学习 ML 模型和技术以及如何实施、部署和扩展它们。我正在寻找一个好的播客来保持我对 ML 趋势的了解，但挑战是我不太喜欢听技术性的播客，因为我仍然是一个新手，如果我阅读，通常会更好地理解复杂性他们。我尝试过一些播客，但大多数时候这些内容超出了我的理解范围，让我迷失了方向。寻找一些我可以听的东西，而不必在上班的路上费力地思考。希望有任何建议！   由   提交/u/C-beenz   /u/C-beenz  reddit.com/r/MachineLearning/comments/1cmntyr/non_technical_ml_podcasts_d/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmntyr/non_technical_ml_podcasts_d/</guid>
      <pubDate>Tue, 07 May 2024 21:52:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] PEFT技术在行业中的实际应用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmirbu/d_peft_techniques_actually_used_in_the_industry/</link>
      <description><![CDATA[关于变压器参数高效微调的大量工作正在涌现，但其中有多少真正得到应用？我也很好奇你们在行业中通常使用哪些技术？   由   提交/u/Inner_Programmer_329   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmirbu/d_peft_techniques_actually_used_in_the_industry/</guid>
      <pubDate>Tue, 07 May 2024 18:23:12 GMT</pubDate>
    </item>
    <item>
      <title>[D]加权剪枝问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmiqub/d_weighted_pruning_question/</link>
      <description><![CDATA[嗨，我正在进行加权修剪，但我这里有一个问题，所以假设我有一个张量，因此大多数张量几乎为零所以我把它改为零，所以现在几乎 40% 的张量为零，这是否意味着我的矩阵是稀疏矩阵还是仍然密集，如果它不是稀疏矩阵，计算将是相同的，所有行和列都得到倍数，那么加权剪枝的目的是什么呢！    由   提交 /u/IcyCockroach5501   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmiqub/d_weighted_pruning_question/</guid>
      <pubDate>Tue, 07 May 2024 18:22:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 任何有专业知识的人都可以谈谈 Nvidia 的硬件和 Apple 的硬件之间是否有重叠吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmh0a6/d_can_anyone_with_the_expertise_speak_to_the/</link>
      <description><![CDATA[我很好奇，如果我们假设苹果正在从我们的产品开始，那么苹果可以与 Nvidia 竞争有多少现实潜力了解M系列芯片。他们能否提取一些知识产权来制造专门构建的“人工智能”？可能会竞争的芯片？ 背景：有传言称苹果可能会尝试这样做......   由   提交 /u/playstation3d   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmh0a6/d_can_anyone_with_the_expertise_speak_to_the/</guid>
      <pubDate>Tue, 07 May 2024 17:08:37 GMT</pubDate>
    </item>
    <item>
      <title>[P] Skyrim - 大型天气模型的开源模型动物园</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmfbzc/p_skyrim_opensource_model_zoo_for_large_weather/</link>
      <description><![CDATA[Github 链接  &lt; p&gt;大家好，我是来自 Secondlaw AI 的 Efe。我们正在构建基于物理的大型人工智能模型。目前，我们专注于天气建模。 为了对 SOTA 进行基准测试，我们必须为所有可用的大型天气模型构建预测基础设施，但我们找不到可靠的工具来实现这一点，因此我们构建了 Sykrim。在 &lt;5 分钟和 &lt;5 LOC 内，您可以运行与在 100K+ CPU HPC 上运行的全球天气模型相当的预报！您可以在此处查看示例。 我们是实施更多模型和微调能力。如果我们还可以添加任何内容，请告诉我们，很高兴回答任何问题！   由   提交/u/0xe5e  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmfbzc/p_skyrim_opensource_model_zoo_for_large_weather/</guid>
      <pubDate>Tue, 07 May 2024 15:58:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过 Arduino Nano ESP32（Ridge 分类）进行水生超声波扫描来识别潜伏在基质中的有毒水下气泡，并同时通过 UNIHIKER (NVIDIA TAO RetinaNet) 根据化学（颜色编码）水质测试评估水污染。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmcfv4/p_identify_toxic_underwater_air_bubbles_lurking/</link>
      <description><![CDATA[   /u/the-amplituhedron  /u/the-amplituhedron reddit.com/gallery/1cmcfv4&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmcfv4/p_identify_toxic_underwater_air_bubbles_lurking/</guid>
      <pubDate>Tue, 07 May 2024 13:53:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] YARI - 另一个 RAG 实现。混合上下文检索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmb0x4/p_yari_yet_another_rag_implementation_hybrid/</link>
      <description><![CDATA[我制作了 YARI。  它具有 BM25 和余弦相似度之间的混合融合搜索功能，并且构建在 Redis 之上。 用途：FastAPI、Celery 和 Redis。 OpenAI 的 API 支持嵌入生成和提示完成。 请给我您的反馈。来源：https://github.com/fighterbay/YARI   由   提交 /u/fighterbay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmb0x4/p_yari_yet_another_rag_implementation_hybrid/</guid>
      <pubDate>Tue, 07 May 2024 12:44:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将 LLM 输出限制为某些单词</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm9r0y/d_limiting_llm_output_to_certain_words/</link>
      <description><![CDATA[假设我想对文本进行多类分类。一种方法是提示工程师，但是，这可能会输出与我想要的不同的标签。下面是一个示例： 从文本中提取以下标签。标签：苹果、橙子。文本：我吃了一个苹果，然后吃了几个橙子。答案：苹果，橙子  上面显示的答案只是预期的答案。如果我们要使用提示，其他一些可能性将是 [Apple，Orange]，[Oranges，Apples] 等。 就我而言，我确实有一组广泛的标签，我可以对模型进行微调在。虽然我可以训练 BERT 来做到这一点，但我希望将来能够添加标签，因此想尝试微调 LLM。有没有办法训练这个，以便我们限制 Answer 后可以输出的单词？我能想到的一种方法是查看单词的逻辑，但这取决于标记化（例如，apple 可以是 ap_, _ple）。 还有 instructor 库，但据我了解，这不适用于变压器库模型（例如 Llama-3）（至少在不单独托管的情况下）。 希望对此有任何提示/想法。 TIA   由   提交/u/themathstudent  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm9r0y/d_limiting_llm_output_to_certain_words/</guid>
      <pubDate>Tue, 07 May 2024 11:36:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] Agent Cloud - 用于构建私人 LLM 应用程序的开源 GUI 平台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm82xu/p_agent_cloud_opensource_gui_platform_to_build/</link>
      <description><![CDATA[大家好，我们正在构建 Agent Cloud，自过去几个月以来我们一直在 RAG 领域工作，并且我们是开源的.  Agent Cloud 是一个开源平台，使公司能够构建和部署私人 LLM 聊天应用程序，使团队能够安全地与其数据交互。 AgentCloud 在内部使用 Airbyte 构建数据管道，使我们能够对来自 300 多个数据源（包括 MongoDB 等 NoSQL 数据库）的数据进行拆分、分块和嵌入。它简化了将数据引入向量存储以进行初始设置和后续计划更新的过程，确保向量存储信息始终更新。 AgentCloud 使用 Qdrant 作为向量存储来高效存储和管理大量向量嵌入。对于给定的用户查询，RAG 应用程序通过分析向量表示与查询向量的相似程度，从向量存储中获取相关文档。  您可以在项目的自述文件中找到有关其工作原理以及如何使用它的更多信息，我们将在本周末推出云版本。   我们也非常愿意接受贡献，并为初学者添加了很好的第一期。 ​  同步策略- 我们仍然需要实现更改为增量追加而不是完全覆盖的能力 分块策略 - 我们有语义分块，我们希望实现与 Airbyte 连接配合良好的自定义策略 - 目前逐条消息分块(Rust) 检索策略 - 目前我们使用代理来制作查询，我们希望可以在 RAG 连接器中添加更多标准检索策略（TS、Python、Mongo）&lt; /li&gt; 对话应用程序易于设置 - 我们希望采用一种设计模式来简化对话应用程序的设置。  API - 将我们当前的 Web 应用程序 API 作为开放 API 规范等发布。   很高兴回答任何问题。 [GitHub 存储库](https://github.com/rnadigital/agentcloud)   由   提交 /u/thewritingwallah   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm82xu/p_agent_cloud_opensource_gui_platform_to_build/</guid>
      <pubDate>Tue, 07 May 2024 09:51:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用耳语识别不常见术语</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm7frx/d_recognizing_uncommon_terms_with_whisper/</link>
      <description><![CDATA[大家好，我目前正在开发 Whisper，专门研究法语铁路语言。我在转录含糊不清的单词和识别电台名称方面面临一些问题。最初，我尝试用总共2个小时的音频文件来训练它，但结果并没有达到我的预期。然后我转向使用提示，这解决了歧义问题，但是由于上下文大小限制为 244 个标记，我无法包含所有电台名称。 您能给我一些提示吗？我是这个领域的新手。谢谢   由   提交/u/Top-Set-1178   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm7frx/d_recognizing_uncommon_terms_with_whisper/</guid>
      <pubDate>Tue, 07 May 2024 09:06:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] EOS 代币在预训练过程中重要吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm7eqw/d_is_eos_token_crucial_during_pretraining/</link>
      <description><![CDATA[预训练期间使用的 EOS 令牌标记“序列结束”，但它不会阻止信息在可能不相关的文档之间流动。如果是这样，当我们可以稍后在 SFT 阶段添加它时，为什么还要在预训练期间包含它？   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm7eqw/d_is_eos_token_crucial_during_pretraining/</guid>
      <pubDate>Tue, 07 May 2024 09:04:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] Stack Overflow 与 OPEN AI 的合作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm64jk/d_stack_overflow_partnership_with_open_ai/</link>
      <description><![CDATA[      https://stackoverflow.co/company /press/archive/openai-partnership 一些想法： - 很确定 OPEN AI 在训练 ChatGPT 时已经抓取了 Stack Overflow（如果你不这么做的话）相信它 - 请再次观看米拉·穆拉蒂 (Mira Murati) 的著名采访） - 那么为什么要这样做呢？也许可以合法访问内容？ - 自从 Chat GPT 发布以来，StackOverflow 的受欢迎程度正在下降（请参见下面的 Google 趋势图表）- 所以这对于 SO 所有者来说是有意义的 &lt; p&gt;- 从社区的角度来看非常有趣：开发者免费创建了整个内容，现在将用于替换它们，并且他们没有获得利润分成 ​ https://preview.redd.it/fudrujkniyyc1 .png?width=968&amp;format=png&amp;auto=webp&amp;s=e116159e61394557e03a6cad431aadc77f88807b   由   提交/u/pg860  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm64jk/d_stack_overflow_partnership_with_open_ai/</guid>
      <pubDate>Tue, 07 May 2024 07:29:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 快速推理如何与最先进的法学硕士一起工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm4h4i/d_how_does_fast_inference_work_with_state_of_the/</link>
      <description><![CDATA[我读到过，像 Llama-2 70B 这样的模型的推理速度最多为 ~10 t/s。所以这让我很想知道像 GPT-4（1T 参数？）这样的超大模型是如何实现 20 t/s 的快速推理的。有了 10 倍的参数，它们至少要有 3 倍的层数（？），所以这应该会使它的推理速度慢得多。我是不是漏掉了什么？这些公司可能会做哪些进一步的改进来支持他们的快速 API？ 编辑：我必须提到，当数据必须按顺序通过模型层时，您无法跨 GPU 并行化以帮助解决单个示例的延迟问题。 而且，由于模型尺寸很大，模型并行性及其 GPU 间通信应该会使其速度变得更慢……    提交人    /u/Fit-Flow-4180   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm4h4i/d_how_does_fast_inference_work_with_state_of_the/</guid>
      <pubDate>Tue, 07 May 2024 05:36:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>