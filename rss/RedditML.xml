<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 24 Jan 2024 21:12:27 GMT</lastBuildDate>
    <item>
      <title>[D] Best Ch‏ at bots 是否感到疼痛？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19er7tl/d_best_chatbots_that_are_uncensored/</link>
      <description><![CDATA[请提供一些建议和建议，很想尝试一下    ;由   提交/u/Southern_Glass9668   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19er7tl/d_best_chatbots_that_are_uncensored/</guid>
      <pubDate>Wed, 24 Jan 2024 21:02:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 视觉变压器比新生视觉系统更需要数据吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19er4pp/r_are_vision_transformers_more_data_hungry_than/</link>
      <description><![CDATA[ 由   提交 /u/currentscurrents   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19er4pp/r_are_vision_transformers_more_data_hungry_than/</guid>
      <pubDate>Wed, 24 Jan 2024 20:59:24 GMT</pubDate>
    </item>
    <item>
      <title>[D]我需要帮助引用一个机器学习项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eq370/di_need_help_quoting_a_ml_project/</link>
      <description><![CDATA[嘿社区，我需要帮助制定机器学习预算。作为背景，我正在面试机器学习工程师职位的招聘人员。下一个任务是对一个从开发到部署的机器学习项目进行预算，包括 API 和云 OFC 等所有工具。任何帮助或一些模板都会很有价值   由   提交 /u/lennox_wrld   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eq370/di_need_help_quoting_a_ml_project/</guid>
      <pubDate>Wed, 24 Jan 2024 20:16:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] DTC：深度跟踪控制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eodbd/r_dtc_deep_tracking_control/</link>
      <description><![CDATA[        由   提交 /u/leggedrobotics   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eodbd/r_dtc_deep_tracking_control/</guid>
      <pubDate>Wed, 24 Jan 2024 19:07:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用流程工程与法学硕士生成代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19emvxu/d_code_generation_with_llms_using_flow_engineering/</link>
      <description><![CDATA[我昨天看到了这篇论文，是由 Karpathy 的转发引起了我的注意。 这篇论文提出了 AlphaCodium，一种面向代码的迭代改进LLM代码生成的流程。 除了在复杂的代码生成数据集上实现SoTA之外，我认为这项工作中的想法和提出的方法很重要。原因如下： 许多提示技术针对自然语言任务进行了优化，但对于代码生成可能不是最佳的。 AlphaCodium 探索超越传统提示（即提示 -&gt; 答案），将问题分解为不同的组成部分（自我反思、推理和迭代代码解决方案生成），并包括有趣的技巧，例如人工智能生成的测试、自我反思，并沿着“流程”进行推理。 让我们在下面深入探讨： AlphaCodium 流程涉及两个关键要素，以提高法学硕士中的代码生成能力： - 额外生成的数据（问题自我反思和测试推理）来辅助迭代过程 - 使用额外的人工智能生成的测试来丰富公共测试 如图所示，这里是关键生成代码解决方案涉及的步骤： - 通过自我反思问题和推理公共测试来提高问题理解 - 生成并排序可能的解决方案（以自然语言描述）并选择“最佳解决方案” ” - 生成额外的人工智能测试，其中包含公共测试中未涵盖的方面/案例 - 通过在选定的公共和人工智能生成的测试上运行来生成初始代码解决方案 - 使用以前的基本代码并单独执行运行 -使用公共测试和人工智能生成的测试来修复迭代 这种方法持续提高了 LLM 在 CodeContests 问题上的性能，CodeContests 是一个代码生成数据集，用于评估模型的强大代码生成能力。 使用 CodeContests 的验证数据集，GPT-4 pass@5 准确率从使用单个精心设计的提示的 19% 提高到使用 AlphaCodium 流程的 44%。它甚至优于 AlphaCode，使用的计算预算要小得多，LLM 调用要少 4 个数量级。 这种方法的好处之一是，您只需要一个已经支持编码任务的预训练模型，无需微调是必要的。 所提出的“流程工程”方法的一个巧妙方面是引入自我反思，这有助于在初始阶段增强对问题的理解。 我还发现他们如何通过利用测试锚点列表来提高人工智能生成的测试阶段的可靠性，这一点很有见地。 AlphaCodium 流程的每个阶段都感觉可以进一步改进，因此我怀疑通过更优化的提示技术，您可以更进一步。 总的来说，这是一篇很棒的论文，我什至为它创建了带注释的视觉效果它。让我知道这些视觉效果是否有用。 链接到网站：https://www.codium.ai/blog/alphacodium-state-of-the-art-code- Generation-for-code-contests/ &lt; /div&gt;  由   提交 /u/EnaGrimm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19emvxu/d_code_generation_with_llms_using_flow_engineering/</guid>
      <pubDate>Wed, 24 Jan 2024 18:09:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 公平地说，许多机器学习研究人员认为他们可以创造出可以完成医生（非程序性）所做的大部分工作的产品等吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19em5m9/d_is_it_fair_to_say_lot_of_ml_researchers_think/</link>
      <description><![CDATA[这是我与许多机器学习研究人员交谈后得到的感觉。大家觉得我说的对吗？一位机器学习研究人员表示，当他们在医学论文中撰写人工智能论文时，与医生合作总是很困难，因为他们不喜欢在这方面所做的工作。他们总是把一些东西放在最后，说明这不会取代医生以及他们所做的事情（即使研究目标是这样做），但他们把它放在最后，这样医生就不会生气。   由   提交/u/derpgod123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19em5m9/d_is_it_fair_to_say_lot_of_ml_researchers_think/</guid>
      <pubDate>Wed, 24 Jan 2024 17:13:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解 Mamba 和 Transformer 之间的联系。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19elvgt/d_understanding_the_connection_between_mamba_and/</link>
      <description><![CDATA[由于最近围绕 Mamba 的炒作，我想鼓励您重新访问 GateLoop 论文，IMO 有助于理解 Transformer 和 Mamba 之间的关系。 GateLoop 引入了与 Mamba 和 HGRN 相同的数据控制线性循环机制。虽然 GateLoop 论文的实验部分受到了批评，但我认为对于任何试图了解所有 SSM/Mamba 炒作的人来说，这可能是一个很好的资源。具体来说，这篇论文强调了 Attention、S4、LRU、RetNet 和新的数据控制线性 RNN（GateLoop、Mamba、HGRN）之间的关系。 读到这些，我很好奇为什么 Mamba 使用短卷积？ （有趣的是，鬣狗也这样做了，也许只是因为经验上的成功？）你的想法？   由   提交 /u/TommyGun4242   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19elvgt/d_understanding_the_connection_between_mamba_and/</guid>
      <pubDate>Wed, 24 Jan 2024 17:02:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] DDIM 反转 - 真实图像的反转潜伏期如何“​​高斯”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ej9jz/d_ddim_inversion_how_gaussian_are_the_inverted/</link>
      <description><![CDATA[我遇到过几篇论文，它们使用确定性反演来查找潜伏，该潜伏（连同提示）可以使用稳定扩散再现真实图像。在“提示到提示”中，赫兹等人。请注意以下几点：  但是，在许多其他情况下，反演不够准确，如图 1 所示。 11. 这部分是由于失真可编辑性权衡 [43]，我们认识到减少无分类器指导 [18] 参数（即减少即时影响）可以改善重建，但限制了我们执行重大任务的能力  我在其他论文中看到过类似的说法，这是由于反转潜伏不属于生成模型通常从中采样的标准高斯空间它的初始噪声潜伏。我想知道是否有人知道对此进行深入研究的任何著作？量化反向潜伏偏离预期高斯分布的最佳方法是什么？是否有某些图像在 SD 的学习分布下不太可能出现，并且反转它们会导致潜在的高斯分布更小？预先感谢您的任何建议和指示！ ​   由   提交 /u/35mmpy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ej9jz/d_ddim_inversion_how_gaussian_are_the_inverted/</guid>
      <pubDate>Wed, 24 Jan 2024 15:10:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] Finetune 提速 TinyLlama 387%、DPO 提速 188%、LLM 推理提速 2 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eiwe8/p_finetune_387_faster_tinyllama_188_faster_dpo_2x/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eiwe8/p_finetune_387_faster_tinyllama_188_faster_dpo_2x/</guid>
      <pubDate>Wed, 24 Jan 2024 14:54:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] Lumiere：用于视频生成的时空扩散模型（Bar-Tal 等人，2024）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eicco/r_lumiere_a_spacetime_diffusion_model_for_video/</link>
      <description><![CDATA[Arxiv: https:// arxiv.org/abs/2401.12945 摘要： “我们介绍 Lumiere——一种设计的文本到视频扩散模型用于合成描绘真实、多样化和连贯运动的视频——这是视频合成中的一个关键挑战。为此，我们引入了时空 U-Net 架构，该架构通过模型中的单次传递一次性生成视频的整个时间持续时间。这与现有的视频模型形成鲜明对比，现有的视频模型合成遥远的关键帧，然后进行时间超分辨率——这种方法本质上使全局时间一致性难以实现。通过部署空间和（重要的）时间下采样和上采样，并利用预先训练的文本到图像扩散模型，我们的模型学习通过在多个时空尺度。我们展示了最先进的文本到视频生成结果，并表明我们的设计可以轻松促进各种内容创建任务和视频编辑应用程序，包括图像到视频、视频修复和风格化生成。 ” Youtube 视频： https://www.youtube.com /watch?v=wxLr02Dz2Sc 非交互式网络演示： https ://lumiere-video.github.io/   由   提交 /u/StartledWatermelon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eicco/r_lumiere_a_spacetime_diffusion_model_for_video/</guid>
      <pubDate>Wed, 24 Jan 2024 14:28:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视觉模型的方便比较图表：何时使用什么！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eeve9/d_a_handy_comparative_chart_on_vision_models_when/</link>
      <description><![CDATA[       由   提交/u/Instantinopaul   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eeve9/d_a_handy_comparative_chart_on_vision_models_when/</guid>
      <pubDate>Wed, 24 Jan 2024 11:21:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 幻视曼巴再次出击！变形金刚王座正在崩溃吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eemq2/d_vision_mamba_strikes_again_is_the_transformer/</link>
      <description><![CDATA[还记得震撼 NLP 的状态空间模型 Mamba 吗？好吧，抓住你的像素，因为它们现在也在计算机视觉领域碾压它！ 他们的新模型 Vision Mamba 抛弃了自我关注热潮，并依赖于状态空间魔法。结果？性能与顶级视觉变压器 (DeiT) 相当，但效率更高！ 这可能会改变游戏规则，伙计们。我们正在谈论更快、更轻的型号，它们可以在您祖母的笔记本电脑上运行，但仍然像鹰一样看得见。 有什么想法吗？我很高兴看到变形金刚领域出现一些竞争。我们可以期待在这个新架构上推出 chatgpt v2 吗？道歉！可能听起来很疯狂，而且评论还为时过早。 查看论文：https: //paperswithcode.com/paper/vision-mamba-efficient-visual-representation   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eemq2/d_vision_mamba_strikes_again_is_the_transformer/</guid>
      <pubDate>Wed, 24 Jan 2024 11:06:31 GMT</pubDate>
    </item>
    <item>
      <title>[项目] BELT（较长文本的 BERT）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19edzov/project_belt_bert_for_longer_texts/</link>
      <description><![CDATA[我们创建了 BELT（BERT For Longer Texts）——一个 Python 包，允许对长度超过 512 个 token 的文本使用类似 BERT 的模型。该方法是 Jacob Devlin 提出的想法的实现，Jacob Devlin 是 评论。您可以在 Medium 上我刚刚发表的两篇文章中阅读有关它的更多详细信息： 第一部分是应用 BERT 分类器的概述： 第 1 部分 第二部分深入介绍我们训练 BELT 模型的方法。 第 2 部分 该存储库已开源： Repo 我知道你在想什么：“等等，bucko，这不是什么新鲜事。每个人都知道有像 BigBird 或 Longformer 这样的模型可以处理更长的文本”。对此我的回答是：“我知道，伙计，但是 BigBird 和 Longformer 不是修改过的 BERT。它们是具有不同架构的模型。因此，它们需要从头开始预训练或下载。 BELT修改模型微调。这带来了 BELT 方法的主要优点 - 它使用任何预先训练的 BERT 或 RoBERTa 模型。快速查看 HuggingFace Hub 可以确认，BERT 的资源比 Longformer 多大约 100 倍。找到适合特定任务或语言的可能会更容易。”享受吧！   由   提交/u/MBrzozowskiML   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19edzov/project_belt_bert_for_longer_texts/</guid>
      <pubDate>Wed, 24 Jan 2024 10:24:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 什么时候在 TPU 上训练有意义？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19e8d1a/d_when_does_it_make_sense_to_train_on_tpu/</link>
      <description><![CDATA[我花了几周时间将 torch 模型训练脚本移植到 PyTorch/XLA 并在 TPU v3 和 v4 上进行测试。从纯粹的训练速度和成本效率的角度来看，我将结果与 GCP 中的 a2/g2 机器上的训练进行了比较。我很惊讶移植代码有多困难，以及 TPU 上的训练有多慢且成本低效。 Dev UX 让人想起使用 TensorFlow（从最坏的意义上来说）。东西通常不能开箱即用，很难调试，因为所有东西都是编译的，而且张量是惰性的。整个事情非常不透明，不清楚发生了什么。没有您期望拥有的基本工具，例如如果不进行分析就无法检查 TPU 利用率。 更令人惊讶的是，训练速度比使用同等价格的 GPU 时慢得多。例如，与 g2-standard-96（8xL4 GPU）上的训练相比，TPU v3-8 上的训练速度大约慢 2 倍，而成本却大致相同。 TPU v4-8 价格更高，但仍然比 g2-standard-96 慢。我的模型或多或少是一个简单的密集网络，它来自推荐领域。未移植的 pytorch 代码使用 DDP。数据加载器经过高度优化并具有基准测试，我确信这不是瓶颈。 XLA 指标没有显示任何危险信号。 此时，我想知道为此投入更多精力是否有意义。非 Google 人员是否真的使用 TPU 进行大规模训练？是不是 Torch/XLA 还没有准备好迎接黄金时段，只是 TPU 最适合与 TF 或 JAX 一起使用？ TPU 是否有特定的用例？   由   提交 /u/Puzzleheaded-Stand79    reddit.com/r/MachineLearning/comments/19e8d1a/d_when_does_it_make_sense_to_train_on_tpu/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19e8d1a/d_when_does_it_make_sense_to_train_on_tpu/</guid>
      <pubDate>Wed, 24 Jan 2024 04:15:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>