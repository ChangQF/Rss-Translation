<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 29 Dec 2024 12:29:34 GMT</lastBuildDate>
    <item>
      <title>[P] 使用 ARIMA/SARIMA 进行风速预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hou9cq/p_wind_speed_prediction_with_arimasarima/</link>
      <description><![CDATA[      我正在做一个风速预测的项目。有些文章说使用 ARIMA / SARIMA 会是一个好的开始。 我确实开始使用 ARIMA，并且预测值没有任何变化。 当我尝试使用 SARIMA，季节性 = 12（一年中的月份），预测 36 个月（3 年）时，它给了我不满意的结果，这些结果看起来每年都一样（周期性的，因此远离现实）所以我放弃了 SARIMA。 请随时给我解决方案或更好的方法。    提交人    /u/Associate-Existing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hou9cq/p_wind_speed_prediction_with_arimasarima/</guid>
      <pubDate>Sun, 29 Dec 2024 11:33:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 图像模型中表示工程的最佳工具是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hondfe/d_what_are_the_best_tools_for_representation/</link>
      <description><![CDATA[我最近（感谢这个 subreddit）发现了一个非常易于使用的 LLM 表示工程工具。它允许您训练控制向量来控制模型的行为。我很好奇是否有类似的工具可以控制图像模型。    提交人    /u/jsonathan   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hondfe/d_what_are_the_best_tools_for_representation/</guid>
      <pubDate>Sun, 29 Dec 2024 03:48:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 神经嵌入的结构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hogog5/d_structure_of_neural_embeddings/</link>
      <description><![CDATA[  由    /u/SeanPedersen  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hogog5/d_structure_of_neural_embeddings/</guid>
      <pubDate>Sat, 28 Dec 2024 22:09:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我们建立了一个自然语言搜索引擎，让你可以通过描述你想看的内容来探索超过 50 万件艺术品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoavl0/p_we_built_a_natural_language_search_engine_which/</link>
      <description><![CDATA[  由    /u/stefanvdw  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoavl0/p_we_built_a_natural_language_search_engine_which/</guid>
      <pubDate>Sat, 28 Dec 2024 17:45:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 伦敦帝国理工学院 AIML 专业证书（25 周）课程评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ho7o8p/d_review_of_imperial_college_londons_professional/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ho7o8p/d_review_of_imperial_college_londons_professional/</guid>
      <pubDate>Sat, 28 Dec 2024 15:17:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找一款可靠的文本转语音工具，能够为英语和中文提供一致的语音。付费选项也不错。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ho63xk/d_looking_for_a_reliable_texttospeech_tool_with/</link>
      <description><![CDATA[我尝试过不少文本转语音工具，但大多数都无法生成一致的声音，即使我选择同一个说话者也是如此。 我的目标是将它们用于视频字幕中的画外音。 你有没有遇到过可以为英语和中文生成一致声音的文本转语音工具？付费选项很好。 谢谢！    提交人    /u/yccheok   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ho63xk/d_looking_for_a_reliable_texttospeech_tool_with/</guid>
      <pubDate>Sat, 28 Dec 2024 13:54:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你在 2024 年读过哪些有趣的应用机器学习论文/博客，或者有过哪些经历</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ho63je/d_what_are_some_of_the_interesting_applied_ml/</link>
      <description><![CDATA[我正在寻找一些有趣的成功/不成功的真实世界机器学习应用程序。您还可以自由分享使用机器学习构建应用程序的经验，这些经验实际上对现实世界产生了一些影响。 这种类型的东西：  LinkedIn 开发了一个名为经济机会网络（EON）的新型领域适应基础模型系列，以增强其平台的 AI 功能。  https://www.linkedin.com/blog/engineering/generative-ai/how-we-built-domain-adapted-foundation-genai-models-to-power-our-platform 编辑：只是为了鼓励这种对话，这是我自己的个人 SAAS 应用程序 - 这就是我作为机器学习工程师在现实世界中应用机器学习的方式。虽然不多，但总归是件好事。这是一个业余项目（周末和晚上开发），但失败了，没有用户 Clipbard。我保留它主要是想丰富我的简历。我的主要受众是教育工作者，他们希望提高与年轻“抖音”一代的互动。我认为这将是一种更好的方式，可以以更令人难忘的方式分享历史等内容，而不是一长串的文字。我还针对教堂（主日学校/儿童教堂）等群体，他们希望将圣经故事带入生活或通过课程讲故事，或者希望每天晚上将睡前故事带入生活的父母。    提交人    /u/takuonline   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ho63je/d_what_are_some_of_the_interesting_applied_ml/</guid>
      <pubDate>Sat, 28 Dec 2024 13:54:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 让我们分享保持积极性和效率的秘诀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hno25c/r_lets_share_tips_to_stay_motivated_and_efficient/</link>
      <description><![CDATA[大家好， 我目前正在攻读博士学位，最近，我感觉唯一阻碍我前进的就是我自己。似乎只有在截止日期前的最后 1 或 2 个月，我才会真正投入工作。其余时间，我似乎无法保持动力或专注力。 有人经历过这种情况吗？或者有什么在整个过程中保持一致的技巧吗？我一直在考虑尝试冥想来帮助集中注意力和缓解压力，但我不确定这是否会有所不同。任何建议都将不胜感激！ 谢谢！    提交人    /u/Training-Adeptness57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hno25c/r_lets_share_tips_to_stay_motivated_and_efficient/</guid>
      <pubDate>Fri, 27 Dec 2024 20:26:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 并行性权衡：通过电路复杂性理解 Transformer 的表达能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hnnl6s/d_the_parallelism_tradeoff_understanding/</link>
      <description><![CDATA[演讲：https://www.youtube.com/watch?v=7GVesfXD6_Q 论文：https://aclanthology.org/2023.tacl-1.31/ TL;DR 作者 (Will Merrill) 从电路复杂性的角度看待变压器，并将其置于 TC0 复杂性类 - 恒定深度的阈值电路。这是一个相对受限制的复杂性类，无法解决许多固有的顺序问题。 他们的主要观点是，变压器的表达限制来自其并行性质，而不是其架构的细节。添加思路链允许 transformers 解决来自其他复杂度类别的问题，但代价是牺牲并行性和高效训练。 他们认为，并行和顺序计算之间的这种权衡是无法避免的，未来的架构应该在设计时考虑到这种权衡。他们还研究了状态空间模型的扩展，使权衡比 transformers+CoT 更有效。    提交人    /u/currentscurrents   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hnnl6s/d_the_parallelism_tradeoff_understanding/</guid>
      <pubDate>Fri, 27 Dec 2024 20:05:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我的自动编码变分贝叶斯（VAE）学习笔记</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hnj63a/r_my_learning_notes_for_autoencoding_variational/</link>
      <description><![CDATA[嗨， 我正在分享我在 VAE 论文 https://maitbayev.github.io/posts/auto-encoding-variational-bayes/ 上的学习笔记。它包含论文中公式的扩展证明。    提交人    /u/madiyar   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hnj63a/r_my_learning_notes_for_autoencoding_variational/</guid>
      <pubDate>Fri, 27 Dec 2024 16:53:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我收集了 100 多万条 App Store 和 Play Store 条目的数据集 – 有人感兴趣吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hnfswv/r_ive_collected_a_dataset_of_1m_app_store_and/</link>
      <description><![CDATA[大家好， 为了进行个人研究，我汇编了一个数据集，其中包含来自 App Store 和 Play Store 的超过一百万个条目。它包含有关应用程序的详细信息，我认为它可能对在应用程序开发、市场分析或技术趋势等相关领域工作的其他人有用。 如果这里有人有兴趣将其用于您自己的研究或项目，请告诉我！很高兴讨论细节。 干杯！    提交人    /u/26th_Official   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hnfswv/r_ive_collected_a_dataset_of_1m_app_store_and/</guid>
      <pubDate>Fri, 27 Dec 2024 14:17:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何解释 GLU“激活”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hnc7d9/d_how_do_you_interpret_glu_activations/</link>
      <description><![CDATA[我一直在问自己如何解释 GLU 和 GLU 变体，比如现代 Transformer 中常见的变体。 我可以看到 ReLU 激活的 2 层 MLP 既是非线性投影的线性投影（从一个向量空间到另一个向量空间的正锥，再到另一个向量空间），也是键集（隐藏神经元的权重）和值集（从隐藏到输出单元的权重），与注意力和联想记忆相比，这很好。 如何解释具有 GLU 变体的 GLU 和 FFN？我可以看到一个 3D 向量被投影到另一个 3D 向量（第一个线性变换）并被门控，即可能被投影到垂直于轴的平面上。但我很难看出原始向量如何确定中间向量和 S 形门的收缩/展平。门上的其他激活功能使其更加困难。 与经典的 2layerMLP 相比，2-3 个单元上的最小 GLU 可以实现哪些简单的逻辑函数或几何变换？    提交人    /u/Sad-Razzmatazz-5188   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hnc7d9/d_how_do_you_interpret_glu_activations/</guid>
      <pubDate>Fri, 27 Dec 2024 10:33:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] REINFORCE++：一种简单有效的大型语言模型对齐方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hna801/p_reinforce_a_simple_and_efficient_approach_for/</link>
      <description><![CDATA[RLHF（Reinforcement Learning from Human Feedback）正在快速发展，PPO、DPO、RLOO、ReMax、GRPO等算法相继涌现。 通过将近端策略优化 (PPO) 中的各种优化技术集成到传统的 REINFORCE 算法中，我们“提出”了 REINFORCE++，旨在提高 RLHF 中的性能和稳定性，同时在没有批评者网络的情况下减少计算资源需求。 REINFORCE++ 的主要特性是它比 GRPO 更稳定，比 PPO 更快。 REINFORCE++ 的技术细节如下： https://hijkzzz.notion.site/reinforce-plus-plus 和（技术报告） https://www.researchgate.net/publication/387487679_REINFORCE_A_SIMPLE_AND_EFFICIENT_APPROACH_FOR_ALIGNING_LARGE_LANGUAGE_MODELS 代码 https://github.com/OpenRLHF/OpenRLHF/blob/main/examples/scripts/train_reinforce_llama_ray.sh   由    /u/seventh_day123  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hna801/p_reinforce_a_simple_and_efficient_approach_for/</guid>
      <pubDate>Fri, 27 Dec 2024 08:05:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>