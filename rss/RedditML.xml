<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 15 Feb 2024 03:15:49 GMT</lastBuildDate>
    <item>
      <title>[N] Gradio Notebook 自定义组件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ar1u1q/n_gradio_notebook_custom_component/</link>
      <description><![CDATA[嘿！我们刚刚与 Hugging Face 团队一起推出了 Gradio Notebook。  该组件在 Hugging Face 空间上部署笔记本用户体验。   在一个地方探索多个 Hugging Face 模型的最简单方法 使用文本、图像和音频模型构建 AI 工作流程 托管您的 AI 工作流程上抱脸给别人看！   在这里查看：https://huggingface.co/spaces/ lastmileai/gradio-notebook-template  我们正在寻找早期反馈以及改进体验的方法。如果您有任何疑问，请发表评论并随时私信 :)    由   提交 /u/InevitableSky2801   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ar1u1q/n_gradio_notebook_custom_component/</guid>
      <pubDate>Wed, 14 Feb 2024 23:59:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] Whisper Large v3 基准：在消费类 GPU 上以 5110 美元（每美元 11,736 分钟）转录 100 万小时 - 后续</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ar08br/p_whisper_large_v3_benchmark_1_million_hours/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ar08br/p_whisper_large_v3_benchmark_1_million_hours/</guid>
      <pubDate>Wed, 14 Feb 2024 22:50:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从头开始​​探索 ML 模型的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqzewh/d_resources_to_explore_ml_models_from_scratch/</link>
      <description><![CDATA[最近我获得了 CS 本科学位。我发现机器学习和人工智能的东西很有趣。由于我的项目和研究，我从事机器学习和深度学习领域的工作。我通过阅读基础文章和 YouTube 教程来实现模型。 但是我想从头开始学习机器学习模型。例如逻辑回归、朴素贝叶斯、SVM 等模型如何在后端工作。它如何捕获模式以及哪种模型在哪种类型的数据上效果更好。使机器学习工程师变得更加强大的基础知识和技巧。 我相信这里有很多专家和经验丰富的人。如果您分享您最好的推荐资源，我们将非常感激。它可以是教程、笔记、博客、网站或文章。  分享您认为对您的案例最有用的资源，以阐明 ML 模型的要点。   由   提交 /u/FardinRock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqzewh/d_resources_to_explore_ml_models_from_scratch/</guid>
      <pubDate>Wed, 14 Feb 2024 22:14:30 GMT</pubDate>
    </item>
    <item>
      <title>[D]微调时间有没有“负面提示”的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqyhmk/d_is_there_a_way_of_negative_prompting_at/</link>
      <description><![CDATA[假设我正在尝试微调预训练的语言模型，并且我想更改其响应格式。通常情况下，我会根据新格式对一堆回复示例进行微调。但这样做也会改变模型的语义行为，以更接近地模仿 SFT 示例中存在的文本类型。有没有办法对新格式的示例进行微调，然后对微调示例中的相同文本进行有效的负面微调，但没有新的响应格式？最终结果是模型现在以所需的格式返回响应，但返回的文本类型的分布没有变化。   由   提交/u/thirdvox  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqyhmk/d_is_there_a_way_of_negative_prompting_at/</guid>
      <pubDate>Wed, 14 Feb 2024 21:35:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何关注数据科学领域的学术论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqxtwm/d_how_to_follow_academic_papers_in_data_science/</link>
      <description><![CDATA[如何关注数据科学领域的最新学术论文？有期刊、网站或其他来源吗？    由   提交 /u/BiraMotta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqxtwm/d_how_to_follow_academic_papers_in_data_science/</guid>
      <pubDate>Wed, 14 Feb 2024 21:07:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自然语言强化学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqwx7q/r_natural_language_reinforcement_learning/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2402.07157 OpenReview：https:// /openreview.net/forum?id=0VzU2H13qj 摘要：  强化学习（RL）在以下方面表现出了卓越的能力：学习决策任务的策略。然而，强化学习常常受到样本效率低、缺乏可解释性和监督信号稀疏等问题的阻碍。为了解决这些限制，我们从人类学习过程中汲取灵感，引入了自然语言强化学习 (NLRL)，它创新地将强化学习原理与自然语言表示相结合。具体来说，NLRL 重新定义了自然语言空间中的任务目标、策略、价值函数、贝尔曼方程和策略迭代等 RL 概念。我们介绍如何利用 GPT-4 等大型语言模型 (LLM) 的最新进展来实际实施 NLRL。对表格 MDP 的初步实验证明了 NLRL 框架的有效性、效率和可解释性。    由   提交 /u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqwx7q/r_natural_language_reinforcement_learning/</guid>
      <pubDate>Wed, 14 Feb 2024 20:28:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 模型崩溃揭秘：回归案例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqwset/r_model_collapse_demystified_the_case_of/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.07712 摘要：  在ChatGPT这样的大型语言模型时代， “模型崩溃”指的是这样一种情况：随着时间的推移，模​​型根据其前几代生成的数据进行递归训练，其性能会下降，直到模型最终变得完全无用，即模型崩溃。在这项工作中，我们在核回归的简化设置中研究了这种现象，并获得了结果，这些结果显示模型可以处理虚假数据的情况与模型性能完全崩溃的情况之间存在明显的交叉。在多项式衰减光谱和源条件下，我们获得了修改后的缩放定律，该定律表现出从快速率到慢速率的新交叉现象。我们还提出了一种基于自适应正则化的简单策略来减轻模型崩溃。我们的理论结果通过实验得到了验证。    由   提交 /u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqwset/r_model_collapse_demystified_the_case_of/</guid>
      <pubDate>Wed, 14 Feb 2024 20:22:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 pytorch 和 Phi-2 从头开始​​自然语言生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aquduw/p_natural_language_generation_from_scratch_using/</link>
      <description><![CDATA[我关于在 pytorch 中从头开始编码不同解码策略的最新帖子。这是链接。您可以在博客文章中找到 Colab 笔记本中演示的所有代码。   由   提交/u/MasterpieceExtreme3​​0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aquduw/p_natural_language_generation_from_scratch_using/</guid>
      <pubDate>Wed, 14 Feb 2024 18:45:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从句子的单词中查找单词相似度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqu37j/d_finding_word_similarity_from_sentences_words/</link>
      <description><![CDATA[我试图为自己的研究处理 NLP 任务。我有一个包含 5 万条餐厅用户评论的大型数据集（从 Google 地图评论中收集） 这些评论包含用户反馈他们在该餐厅的体验。 用户的简短亮点评论如下：  这家餐厅提供美味的炸薯条 我喜欢他们的披萨，非常棒。 我是他们的粉丝薯片 他们的薯片太棒了..  我的主要讨论：**从我所有的用户评论中，我想分割或提取与相关的评论与 或 包含一种食物，即“薯片”。  如果我给出一个像“薯片”这样的词然后，它会从所有句子中过滤掉第 1、第 3 和第 4 句，因为它包含相同的食物，但措辞不同。原因：炸薯条、薯片、薯片这些与“薯片”的词义相似或相近。因此 1,3 和 4 句子将被分开或收集。 **尝试使用词嵌入。但它是按照类型来分类的。就像披萨、汉堡一样，它们都是食物，罗马、巴塞罗那和它们的城市一样。但是使用词嵌入我无法提取相同类型的食物。 不喜欢使用 Web API，因为数据集大小太大。 我该如何处理这个问题一种高效、有效且准确的方法？   由   提交 /u/FardinRock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqu37j/d_finding_word_similarity_from_sentences_words/</guid>
      <pubDate>Wed, 14 Feb 2024 18:33:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对具有重复测量组件的模型的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqtjzf/d_recommendations_for_a_model_with_repeated/</link>
      <description><![CDATA[我是 Reddit 新手，对编码也相对较新（&lt;1.5 年）。如果这不属于这里，我深表歉意。 我开始在我的研究中使用机器学习。到目前为止，我已经能够使用随机森林（我知道这是一个简单的机器学习模型）来预测感兴趣的变量。由于训练数据是从同一动物记录的测量结果，因此我需要重复测量方法。我们能够将重复测量纳入 P Calhoun (2021) 编写的随机森林适应函数中。 问题是，如果存在 NaN 值，重复测量随机森林就无法工作。作为我们工作的一部分，一些动物必须在不同时间从实验中移除。他们没有返回实验。下面是一个简化了我所讨论内容的表格： ​   动物 出现在测试 1 中 出现在测试 2 出现在测试 3    1 Y Y Y   2 Y Y N   3 Y N N   所以，一些动物将拥有全部 180 天的数据，而有些动物只会拥有 120 天、80 天、60 天等的数据。这会产生大量 NaN 值。我们使用 MissForest R 包来估算缺失的气候变量，但由于显而易见的原因，估算 100 多天的动物数据是荒谬的。 我们收集动物数据，直到将它们从实验中删除为止。收集这些动物数据非常昂贵（并且是劳动密集型），并且由于农业研究的性质，小 n 尺寸始终是一个问题。我们确实希望使用来自所有动物的所有数据来训练预测模型。 我正在寻找 ML 模型的建议，这些模型具有一些可以使用数据类型的重复测量分析组件（某些记录比其他记录有更多的观察结果）。任何建议都非常受欢迎！谢谢！   由   提交 /u/Technical-Trip9933    reddit.com/r/MachineLearning/comments/1aqtjzf/d_recommendations_for_a_model_with_repeated/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqtjzf/d_recommendations_for_a_model_with_repeated/</guid>
      <pubDate>Wed, 14 Feb 2024 18:12:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我组装了一个 pytorch 调试器，重点是最少的代码更改和用于捕获无声错误的工具，例如可能导致您的损失中出现 NaN 的错误。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqoy7t/p_i_put_together_a_pytorch_debugger_with_an/</link>
      <description><![CDATA[      https://github.com/ethansmith2000/epic-pytorch-debugger  开始这是非常非常WIP，但即使在当前状态，它在获取方面也非常有用有关异常中涉及的张量的详细报告，捕获 NaN 或其他奇数值，并跟踪非 pytorch 变量。 最好的部分是，它所需要的只是在函数上放置一个装饰器。 这里有一些示例 https://preview.redd.it/31m5jp34ijic1.png?width=1626&amp;format=png&amp;auto=webp&amp;s=5b3d64e32e2d5fda7f9f1db4ffec039c5db21db7 ​ &lt; p&gt;https://preview.redd.it/973909g1ijic1。 png?width=1148&amp;format=png&amp;auto=webp&amp;s=7ad349b861d4e5863c478ee6e39e272040adc647 我将其开源，希望其他人可以从中受益，并减少调试时间，特别是对于通常需要大量时间才能单独完成的大规模工作。  而且，我希望它可以成为一个公共项目，供任何愿意贡献的人使用。对于初学者来说，这是我在尝试弄清楚如何在实例化变量名时跟踪变量名时对 python 的最深入了解，而且我确信我在其他一些事情上做得很差。  如果您碰巧发现任何错误（在调试器中，哈哈）或有任何反馈，欢迎大家！ ​    由   提交/u/ethansmith2000   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqoy7t/p_i_put_together_a_pytorch_debugger_with_an/</guid>
      <pubDate>Wed, 14 Feb 2024 15:03:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 阅读和学习研究论文的最佳方式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</link>
      <description><![CDATA[当我们尝试专注于玉兰油的创新产品时，我们必须学习许多现代科技知识。但通常需要时间才能获得博客和教程上的可用资源。  因此，直接从第一个主要来源学习是有效的学习方式，因为它是主要来源。 但是，我发现阅读论文非常困难，因为它包含许多术语或内容不寻常的措辞。此外，跟踪和掌握一篇大论文的上下文也需要很大的耐心。 你们能分享一下你们的方法吗？你们如何有效且高效地从已发表的论文中学习并获得见解？   由   提交 /u/FardinRock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</guid>
      <pubDate>Wed, 14 Feb 2024 14:28:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 RingAttention 实现百万长度视频和语言的世界模型 - 加州大学伯克利分校 2024 - 能够以近乎完美的精度描述一个多小时长的视频（包含超过 500 个剪辑）中的一个剪辑！ - 是开源的！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqjrc8/r_world_model_on_millionlength_video_and_language/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.08268  Github：https://github。 com/LargeWorldModel/LWM  模型： https://huggingface.com/LargeWorldModel/LWM co/LargeWorldModel ！ 摘要：  当前的语言模型在理解世界的各个方面方面存在不足很容易用语言描述，并且难以完成复杂、冗长的任务。 视频序列提供了语言和静态图像中所缺少的有价值的时间信息，这使得它们对于与语言的联合建模很有吸引力。这些模型可以发展对人类文本知识和物理世界的理解，从而实现更广泛的人工智能能力来帮助人类。然而，由于内存限制、计算复杂性和有限的数据集，从数百万个视频和语言序列的标记中学习提出了挑战。为了应对这些挑战，我们整理了一个包含不同视频和书籍的大型数据集，利用 RingAttention 技术对长序列进行可扩展训练，并逐渐将上下文大小从4K 增加到 1M 令牌。本文做出以下贡献：（a）最大上下文大小神经网络：我们在长视频和语言序列上训练最大上下文大小变换器之一，在困难的检索任务和长视频理解中树立了新的基准。 (b) 克服视觉语言训练挑战的解决方案，包括使用掩码序列打包来混合不同的序列长度、使用损失权重来平衡语言和视觉，以及使用模型生成的用于长序列聊天的 QA 数据集。 (c) 高度优化的实现，具有 RingAttention、掩码序列打包和其他关键功能，用于在数百万长度的多模态序列上进行训练。 (d) 完全开源一系列 7B 参数模型，能够处理超过 100 万代币的长文本文档（LWM-Text、LWM-Text-Chat）和视频（LWM、LWM-Chat） 。这项工作为长视频和语言的海量数据集的训练铺平了道路，以发展对人类知识和多模态世界的理解以及更广泛的能力。   &lt; a href=&quot;https://preview.redd.it/89xpv0ix1jic1.jpg?width=1177&amp;format=pjpg&amp;auto=webp&amp;s=b37224a61459c3b04ed01004b10342e1f2d9bd19&quot;&gt;https://preview.redd.it/89xpv0ix1jic1.jpg?width =1177&amp;format=pjpg&amp;auto=webp&amp;s=b37224a61459c3b04ed01004b10342e1f2d9bd19 https://preview.redd.it/mlhtz2ix1jic1.jpg?width=1488&amp;format=pjpg&amp;auto=webp&amp;s=b1bba31b6868fd230b454565e6 686ef0847dc0c2 https://preview.redd.it/ma51c4ix1jic1.jpg ?width=1022&amp;format=pjpg&amp;auto=webp&amp;s=7bce52c12b3ecf683e507582f0dd68ec53a68dac https://preview.redd.it/bc0kz4ix1jic1.jpg?width=670&amp;format=pjpg&amp;auto=webp&amp;s=e541c8f9c0db600e00ef8135a75 5ae0eadc33320   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqjrc8/r_world_model_on_millionlength_video_and_language/</guid>
      <pubDate>Wed, 14 Feb 2024 10:26:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过计算机视觉让我的书架可点击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</link>
      <description><![CDATA[      我构建了一个系统，可以让你拍摄书架的照片并创建一个交互式 HTML 网页，您可以在其中单击图像中的书籍来了解有关每本书的更多信息。 该项目的技术堆栈是：  用于检索的接地 SAM书籍的多边形。 OpenCV + 监督转换，为 OCR 准备书籍。 GPT-4 和 Vision for OCR Google Books API，用于获取书籍元数据。  生成 HTML + SVG 以创建最终网页。  我在博客上写了有关如何构建此项目的文章。 尝试演示。 我希望获得有关如何提高图书检测率以获得更好性能的反馈。在书脊上训练自定义分割模型可能会起作用，但我知道为此可能需要多少数据。 下面的红色多边形表示在演示中可点击的分段书籍：  p&gt; https://preview.redd.it /p9w4rgsn1jic1.png?width=1260&amp;format=png&amp;auto=webp&amp;s=35116c7eb9d1f5dab2b11375be9e2ff0e7163b78   由   提交/u/zerojames_  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</guid>
      <pubDate>Wed, 14 Feb 2024 10:21:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>