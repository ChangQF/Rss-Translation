<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 23 Dec 2024 03:22:41 GMT</lastBuildDate>
    <item>
      <title>[P] 我的 VideoAutoEncoder 更新现在接受不同时长的 240p 到 720p 的质量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hke5z6/p_my_videoautoencoder_update_now_accepts/</link>
      <description><![CDATA[      我对我的 VideoAutoEncoder 进行了全面更新，留下了一个新的自适应版本并留下了一些有趣的结果，这是其中之一，质量为 480p https://i.redd.it/72mh1ny5gi8e1.gif GitHub :b : https://github.com/Rivera-ai/VideoAutoEncoder    提交人    /u/F4k3r22   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hke5z6/p_my_videoautoencoder_update_now_accepts/</guid>
      <pubDate>Mon, 23 Dec 2024 02:37:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama 模型中的门投影</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkd5h1/d_gate_projection_in_llama_models/</link>
      <description><![CDATA[找不到任何详细信息。Llama 是否引入了 Transformer MLP？有没有研究这种额外复杂性对 MLP 的影响？    提交人    /u/amang0112358   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkd5h1/d_gate_projection_in_llama_models/</guid>
      <pubDate>Mon, 23 Dec 2024 01:40:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 LLM 进行超参数调整</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkd3rs/p_hyperparameter_tuning_with_llm/</link>
      <description><![CDATA[大家好！我一直在研究一种基于 LLM 的工具，旨在帮助进行超参数调整。现在，它会读取您的模型代码并根据您的特定模型和数据集建议量身定制的超参数范围，从而使初始调整过程变得更容易一些。  现在还为时过早，但我希望它可以节省时间并帮助指导调整过程。如果您正在研究模型并且厌倦了反复试验的阶段，我希望您尝试一下并让我知道您的想法或如何改进它！ 这是链接：演示。非常感谢任何反馈！    由   提交 /u/Maleficent_Ad5541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkd3rs/p_hyperparameter_tuning_with_llm/</guid>
      <pubDate>Mon, 23 Dec 2024 01:38:01 GMT</pubDate>
    </item>
    <item>
      <title>自动生成分类类别 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkc5d1/automated_generation_of_categories_for/</link>
      <description><![CDATA[因此，我可以使用 Bart 零样本分类来量化文章与预定义类别集的相关性，但我有很多文章，我想从中计算类别，然后使用这些类别对大量文章进行分类。 我想也许我可以使用文本嵌入将每篇文章转换为向量，然后使用无监督学习算法来计算相关文章的聚类，然后将这些组投影回文本，也许可以通过递归总结每个组中的文章来实现。但是，我实际上并不想要类别集必须不相交的约束，我认为 k-means 会施加这种约束。 还有什么其他方法可以实现这一点？    提交人    /u/PurpleUpbeat2820   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkc5d1/automated_generation_of_categories_for/</guid>
      <pubDate>Mon, 23 Dec 2024 00:46:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 任意节点大小的图形自动编码器，如何解码？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk7lje/r_graph_autoencoder_of_arbitrary_node_size_how_to/</link>
      <description><![CDATA[嗨！希望你一切顺利  我正在构建一个能够为任意大小的图生成嵌入的图自动编码器。我读过的大多数文献都集中在固定大小的节点图上，这并不完全符合我的要求。我发现的唯一相关工作是“学习用于生成图的 Graphon 自动编码器”，但我找不到他们提出的模型的任何实现。 编码部分似乎相对简单 - 您可以将其设计为输出固定大小的嵌入，而不管图的大小如何。然而，解码部分要棘手得多：您将如何设计解码器来处理可变大小的图？这个想法在实际意义上是否有意义？它看起来很复杂，但这样的模型可能非常有用。 我很感激任何关于这方面的见解、参考或建议！ 提前致谢！    提交人    /u/galerazo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk7lje/r_graph_autoencoder_of_arbitrary_node_size_how_to/</guid>
      <pubDate>Sun, 22 Dec 2024 20:59:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻求改进 NL2SQL 模型性能的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk42na/r_looking_for_suggestions_to_improve_nl2sql_model/</link>
      <description><![CDATA[大家好， 我正在为 NL2SQL 任务微调一个大型语言模型。我尝试过 BERT 和 CodeBERT，但这两个模型的表现都不如预期。虽然我的目标是在测试中达到 90% 以上的准确率，但我能达到的最好成绩是 在看不见的测试集上达到 84%，但在训练和验证中确实达到了 90% 以上的准确率。 上下文：  数据集大小：我的数据集很大，因此数据可用性不是限制。 当前模型：我使用过 BERT 和 CodeBERT。 挑战：这两种模型都很难有效地概括。  问题：  有没有人推荐适用于 NL2SQL 的替代模型（例如，专门的架构或微调模型）？ 有什么建议可以专门提高 CodeBERT 的准确率吗？例如： 额外的微调技术。 模型架构更改。 更好概括的策略。   任何建议都将不胜感激！ （此外，我没有从事 SQL 生成工作，而是从事 SQL 评估工作）谢谢！    提交人    /u/Aggravating-Bend-343   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk42na/r_looking_for_suggestions_to_improve_nl2sql_model/</guid>
      <pubDate>Sun, 22 Dec 2024 18:10:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习中的协作好奇心？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk21kl/d_collaboration_curiosity_in_ml/</link>
      <description><![CDATA[我见过许多论文，其中 10/12/15 人进行了合作。 他们真的在从事这些项目吗？ 或者只有 2/3 的人在工作？ 它是如何工作的？其他作者的贡献是什么？ 我只是对这个过程很好奇    提交人    /u/Alarming-Camera-188   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk21kl/d_collaboration_curiosity_in_ml/</guid>
      <pubDate>Sun, 22 Dec 2024 16:35:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用引导树搜索提出和解决奥林匹克几何问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjyg9z/r_proposing_and_solving_olympiad_geometry_with/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjyg9z/r_proposing_and_solving_olympiad_geometry_with/</guid>
      <pubDate>Sun, 22 Dec 2024 13:25:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM 微调：揭开 Huggingface Trainer 的神秘面纱 🚀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjy2iw/p_llm_finetuning_demystifying_huggingface_trainer/</link>
      <description><![CDATA[        由    /u/themathstudent 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjy2iw/p_llm_finetuning_demystifying_huggingface_trainer/</guid>
      <pubDate>Sun, 22 Dec 2024 13:02:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调图像相似度模型（图像检索）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjxara/d_fine_tuning_a_model_for_image_similarity_image/</link>
      <description><![CDATA[嗨， 2020 年不久前，我使用深度度量学习对 CNN 进行了微调，使用的数据集包含 600 个类别的 100 万张图像。 我现在面临类似的问题，我需要一个模型来返回特定类型对象的语义相似图像。 我有大约 50 万张这些对象的图像，还可以获得更多。 我的问题是我没有明确定义的&quot;类&quot;，我有一些文本，我可以从中提取一些可以用作类的特征。 CLIP 似乎是一种可能性，但由于它非常重且 GPU 成本高昂，我想探索其他选项。 你们有人尝试过一些更复杂的程序吗？或者使用增强数据进行图像相似性工作？   由    /u/TechySpecky  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjxara/d_fine_tuning_a_model_for_image_similarity_image/</guid>
      <pubDate>Sun, 22 Dec 2024 12:09:55 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 精细调节 SDM 的消融研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjwn2h/dr_ablation_studies_on_fine_tuned_sdm/</link>
      <description><![CDATA[有一个稳定的扩散模型，可以在 COCO 图像上进行微调。它以这种方式进行微调： 如果图像包含各种对象（例如 obj1、obj2 等），我们会以这种方式构建提示：“&lt;obj1&gt; 和 &lt;obj2&gt; 以及 &lt;obj3&gt; 的照片...... 等等”。 我们将此提示与图像一起传递以进行微调。请注意，如果图像由同一类别的各种对象组成，我们不会在提示中重复该类别。 例如：如果图像包含狗、猫、香蕉、熊和树，则提示将如下所示：“一张狗、猫、香蕉、熊和树的照片”。 现在，我想通过更改提示模板并观察图像质量的变化来对该模型进行消融研究。 请注意，该模型用于生成图像和边界框，现在它充当数据集合成器。我们给出一个只有 2 个类别的提示。例如：“一张椅子和人的照片”。生成的数据集与原始 coco 数据集一起使用，然后我们在该组合数据上训练图像识别模型，并注意图像识别器的性能是否有所改善。 告诉我可以使用哪些提示模板来进行消融研究。    提交人    /u/maaKaBharosaa   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjwn2h/dr_ablation_studies_on_fine_tuned_sdm/</guid>
      <pubDate>Sun, 22 Dec 2024 11:20:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在 NeurIPS’24 上感受到了焦虑和沮丧（kyunghyuncho 博客）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</guid>
      <pubDate>Sun, 22 Dec 2024 02:22:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们最容易误解哪些机器学习概念？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</link>
      <description><![CDATA[我注意到某些 ML 概念（例如偏差-方差权衡或正则化）经常被误解。您认为哪个 ML 主题经常被误解，您如何向其他人解释它？    提交人    /u/AdHappy16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</guid>
      <pubDate>Sat, 21 Dec 2024 20:22:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>