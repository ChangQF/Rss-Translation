<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Tue, 08 Apr 2025 03:33:46 GMT</lastBuildDate>
    <item>
      <title>帮助提高BERT模型的准确性[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ju350e/help_with_improving_accuracy_in_bert_model_d/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想微调一个具有心理健康数据集的模型，该数据集具有7种独特的情绪，因此我在Tensorflow中使用了一个分类模型，我的损失就像1.7一样，我的准确性是.2我的准确性是.2 freakin loww a，请告诉我精确度的精度[d]        /u/u/bebangamer     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ju350e/help_with_improving_accuracy_in_in_bert_model_model_d/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ju350e/help_with_improving_accuracy_in_bert_model_d/</guid>
      <pubDate>Tue, 08 Apr 2025 02:30:37 GMT</pubDate>
    </item>
    <item>
      <title>[d]如果一种使用OWLVIT2 V2（例如OWLVIT2 V2）的方法，则无法知道这些模型是否已在下游任务的验证集上进行了培训？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ju0wko/d_if_a_method_used_pretrained_model_like_owlvit2/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  人们如何解决这些问题。我仍然可以为结果发布论文  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/striking-warning9533   href =“ https://www.reddit.com/r/machinelearning/comments/1ju0wko/d_if_a_a_method_used_used_pretrataine_model_model_like_owlvit2/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ju0wko/d_if_a_a_method_used_pretrataine_model_model_like_owlike_owlvit2/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ju0wko/d_if_a_method_used_pretrained_model_like_owlvit2/</guid>
      <pubDate>Tue, 08 Apr 2025 00:36:13 GMT</pubDate>
    </item>
    <item>
      <title>[研究]评估您的检索系统 -  Chroma关于生成基准测试的新研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jtwusn/research_evaluating_your_retrieval_system_new/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我是Chroma的联合创始人Jeff。我们正在努力使AI应用程序开发更像工程，而不是炼金术。 今天，我们正在介绍代表性的生成基准测试  - 按照您自己的数据构建的custom评估集，并反映了用户实际上在生产中进行的查询。这些基准旨在在其生产中面临的类似条件下测试检索系统，而不是依靠人工或通用数据集。 基准测试对于评估AI系统是必不可少的，尤其是在诸如文档检索之类的任务中，在该任务中，在该任务中，输出概率是概率且高度依赖于上下文。但是，像MTEB这样的广泛使用的基准通常过于干净，通用，并且在许多情况下，在训练过程中已被嵌入模型记住。我们表明，公共基准上的强烈结果可能无法推广到生产设置，并且我们提出了一种生成实际用户查询的现实查询的生成方法。 在此处查看我们的技术报告： https://research.trychroma.com/generative-benchmarking      &lt;！ -  sc_on-&gt; 32;提交由＆＃32; /u/u/jeffreyhuber     [link]      [commist]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jtwusn/research_evaluating_your_retrieval_system_new/</guid>
      <pubDate>Mon, 07 Apr 2025 21:27:53 GMT</pubDate>
    </item>
    <item>
      <title>[p] [d]为什么我的GNN-LSTM模型无法通过完整的培训数据来概括为时空预测任务？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jtwdn8/p_d_why_does_my_gnnlstm_model_fail_to_generalize/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  我正在处理时空预测问题，我想预测随着时间的推移每个空间节点的标量值。我的数据跨越了每天观察的多个空间网格位置。  数据设置     空间区域分为子区域，每个区域都具有图形结构。 每个节点代表一个带有输入的网状特征：variabil_value_t，lie eyter eyter eyter eyter，li eyter  边缘特征包括方向和距离。 使用z得分归一化（平均/std trow训练分配）独立地归一化。 edge_in_dim，hidden_​​dim）：... self.Stect。 src，tgt）agg_msg = torch.zeros_like（x）.index_add（0，col，edge_messages）x_updated = self.node_net（x，x，agg_msg）attn_out，_ = self。 x_updated + attn_out.squeeze（0），edge_messages class gnnlstm（nn.module）：def __init __（self，...）：... ... self.gnn_layers = nn.modulelist（nn.modulelist（[...]）辍学= 0.2，batch_first = true）self.pred_head = nn.Sequeential（nn.linear（128，64），nn.leakyrelu（0.1），nn.linear（64，2 * pred_len）def forff（self，batch）：... for t in（t）： x_t，_ = gnn（x_t，graph.edge_index，graph.edge_attr）x_stack.append（x_t）x_seq = torch.stack（x_stack，dim = 1）＃[b，t，n，n，sideen_dim] self.pred_head（lstm_out [：，-1]）。查看（b，n，2）均值，logVar = out [...，0]，out [...，1]返回均值，torch.exp（logvar） + 1e -3            1E-4  调度程序：REDUCELRONPLATEAU  每次培训（每个子区域均可独立训练） 我还尝试使用课程学习：从50批开始，并逐渐增加每个时期，直到使用了完整的训练集。我在火车拆分中总共有500批  问题：在少量批次上训练时，该模型会收敛并提供合理的结果。但是，当在完整数据集中接受培训时，模型：  显示了几个时期后的验证损失不一致或恶化，似乎过多地依赖于LSTM（例如，LSTM.Weight_hh_*具有比GNN层的更新更高的criel          我已经尝试过：  增加GNN深度（当前4层） 渐变剪辑 注意力 +残留 +层 +层 +层     尽管有什么原因使GNN-LSTM模型与全面培训有关，但还是有什么因素，即使有什么成功的培训数据，但成功的数据是什么？我处于智慧。   /u/u/特定dark     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jtwdn8/p_d_why_does_my_does_my_gemy_gnnlstm_gnnlstm_model_model_model_fail_fail_fail_to_generalize/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jtwdn8/p_d_why_does_my_gnnlstm_model_fail_to_generalize/</guid>
      <pubDate>Mon, 07 Apr 2025 21:07:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] HAI人工智能指数报告2025：AI种族变得拥挤了，中国正在美国近乎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jtoegy/d_hai_artificial_intelligence_index_report_2025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  斯坦福大学的人类人为AI（hai）今天发表了一份新的研究论文，该论文彰显了该领域的挤压。 href =“ https://macro.com/app/pdf/e10d9df1-f1-f135-4681-b377-8a6c72ec07f8/”&gt; hai人工智能索引报告2025  improve. AI is increasingly embedded in everyday life. Business is all in on AI, fueling record investment and usage, as research continues to show strong productivity impacts. The U.S. still leads in producing top AI models—but China is closing the performance gap. The responsible AI ecosystem evolves—unevenly. 全球AI乐观态度正在上升，但仍有深层区域鸿沟。收紧。  AI因其对科学的影响而获得最高荣誉。 复杂的推理仍然是一个挑战。    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jtoegy/d_hai_artercover_intelligence_index_report_2025/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jtoegy/d_hai_artificial_intelligence_index_report_2025/</guid>
      <pubDate>Mon, 07 Apr 2025 15:44:24 GMT</pubDate>
    </item>
    <item>
      <title>[r]带有医疗笔记的数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jtmk36/r_dataset_with_medical_notes/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  为医学笔记的数据脱位工具（例如，咨询后的注释医生写作）。是否有任何可公开可用的数据集用于验证？&lt; /p&gt; 我看上去很有趣，但我是否可以访问br /br br /br br br /nimper comply /nimper。来自微软的语料库似乎不错，但对于我想要的用例并不代表。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/aala7     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jtmk36/r_dataset_with_medical_notes/</guid>
      <pubDate>Mon, 07 Apr 2025 14:27:28 GMT</pubDate>
    </item>
    <item>
      <title>[p] docext：开源，本地文档智能，由视觉模型提供支持</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jtjw2b/p_docext_opensource_onprem_document_intelligence/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们很高兴开放源 docext ，一种零o的内部，本地工具，用于从发票，护照等文档中提取结构化数据，诸如云，无云，无需外部apis，不需要外部apis， by  by   docext 在视觉和语义上了解文档以提取字段数据和表格 - 直接从文档图像中。 全部运行它，以全部运行，以进行完整的数据隐私和控制。   关键功能：    custom＆amp;预构建的提取模板 表 +现场数据提取  gradio-power-power Web界面 与REST API  多页文档支持 置信度得分 用于提取字段的置信得分                 docext 帮助您在几分钟内将它们变成可用的数据。尝试一下：     pip install docext 或通过docker  用 python -m code&gt;   旋转Web UI href =“ https://github.com/nanonets/docext”&gt;  docext.app.app.app.app       https://github.com/nanonets/docext  问题？功能请求？打开问题或开始讨论！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/souvikmandal     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jtjw2b/p_docext_opensource_onprem_document_intelligence/</guid>
      <pubDate>Mon, 07 Apr 2025 12:20:48 GMT</pubDate>
    </item>
    <item>
      <title>[d]用于使用桌面交互数据的AI代理工作流的端到端框架/库？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jti0qc/d_endtoend_frameworkslibraries_for_ai_agent/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我想构建为我自动化桌面任务的代理，例如在CAPTCHA中进行网络冲浪限制了站点，评论并响应仅GUI-GUI-PROUM的用户等。 ，我通常与Windows机器上的鼠标 +键盘进行的所有操作，但现在我想自定义的多模式LLMS自动化。 大多数重新启动我从培训中启动了一些阶段（即逐步启动），然后将其目的均计算。他们不提供收集交互数据的代码，也不提供用于部署AI代理的代码。 ，我可以负担得起云GPU来用自己的数据训练代理，任何人都知道端到端框架框架吗？ （从数据收集到培训再到部署）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/marionberry6884     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jti0qc/d_endtoend_frameworkslibraries_for_ai_agent/</guid>
      <pubDate>Mon, 07 Apr 2025 10:28:22 GMT</pubDate>
    </item>
    <item>
      <title>[r]深度学习在癌症突变检测中打击SOTA（自然通信）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jtfhwo/r_deep_learning_hits_sota_in_cancer_mutation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   v varnet是一个端到端的深度学习框架，对数百个全癌基因组进行了培训，可检测具有高精度的躯体变异 - 没有手工训练的启发式方法 -  在 national of the-strong&gt;“强度&lt; /strong   https://www.nature.com/articles/articles/s41467-022-31765-8  href =“ https://github.com/skandlab/varnet”&gt; https://github.com/skandlab/varnet     &lt;！ -  sc_on-&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jtfhwo/r_deep_learning_hits_sota_in_in_cancer_moutt/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jtfhwo/r_deep_learning_hits_sota_in_cancer_mutation/</guid>
      <pubDate>Mon, 07 Apr 2025 07:21:05 GMT</pubDate>
    </item>
    <item>
      <title>[r]均匀分布的深度特征表示改善公平与鲁棒性[TMLR]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jt9r7u/r_uniformly_distributed_deep_feature/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   tldr：理论上和额外的表明，鼓励深层代表均匀分布的深度特征可提高公平性和鲁棒性（特别是子群的鲁棒性和域的概括）。带代码的论文： https://openreview.net/forum?id=pglbs5yp8nn  提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jt9r7u/r_uniformly_distributed_deep_feature/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jt9r7u/r_uniformly_distributed_deep_feature/</guid>
      <pubDate>Mon, 07 Apr 2025 01:26:01 GMT</pubDate>
    </item>
    <item>
      <title>[R]幼苗：将LLM重量压缩到伪随机发电机的种子中</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jt4pqr/r_seedlm_compressing_llm_weights_into_seeds_of/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/u/ahmedmostafa16      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jt4pqr/r_seedlm_compressing_llm_weights_into_into_sseeds_sseeds_of/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jt4pqr/r_seedlm_compressing_llm_weights_into_seeds_of/</guid>
      <pubDate>Sun, 06 Apr 2025 21:15:03 GMT</pubDate>
    </item>
    <item>
      <title>[D]日常的非线性可分离问题的例子</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jszd7k/d_everyday_examples_of_nonlinearly_separable/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在尝试考虑有助于直观地理解非线性可分离问题概念的示例。例如，确定两个输入是否相等，是一个这样的问题，但是我希望能比这更抽象的事情，而学生自己在没有意识到的情况下做的事情。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/neuralbeans   href =“ https://www.reddit.com/r/machinelearning/comments/1jszd7k/d_everyday_examples_of_nonlinlinalearly_separable/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jszd7k/d_everyday_examples_of_nonlinearly_separable/</guid>
      <pubDate>Sun, 06 Apr 2025 17:24:30 GMT</pubDate>
    </item>
    <item>
      <title>[r]图像分类通过进化字节码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jswn5k/r_image_classification_by_evolving_bytecode/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在过去的几年中，我一直在研究 zyme ，一种用于基因程序的神秘语言：通过自然选择来创建计算机程序。我已经开始看到有希望的结果，表明随着时间的流逝，随机的字节码突变可能会导致程序性能的可衡量。虽然与神经网络这样的最新方法还有很长的路要走，但我想分享我的进度。提交由＆＃32; /u/u/almusdives      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jswn5k/r_image_classification_by_evolving_bytecode/</guid>
      <pubDate>Sun, 06 Apr 2025 15:25:58 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jpdo7y/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</guid>
      <pubDate>Wed, 02 Apr 2025 02:15:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_be_hired/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Mon, 31 Mar 2025 02:30:37 GMT</pubDate>
    </item>
    </channel>
</rss>