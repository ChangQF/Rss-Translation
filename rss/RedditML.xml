<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Wed, 28 Feb 2024 12:22:32 GMT</lastBuildDate>
    <item>
      <title>[D] 生产级 RAG 应用程序真正包含什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b244vc/d_what_does_a_production_level_rag_application/</link>
      <description><![CDATA[我已经完成了 RAG 的研究，实现了一些简单的 RAG 教程，并且我知道我现在想要实现的高级 RAG 技术。但我真的不知道正确的应用程序工作流程是什么样的。就像在简单的 RAG 教程中实现这 7 行代码，然后添加混合搜索或重新排名等内容，以及实际构建生产级 RAG 应用程序之间有什么区别？这个“工作流程”是什么样的？    由   提交/u/Aggravating-Floor-38   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b244vc/d_what_does_a_production_level_rag_application/</guid>
      <pubDate>Wed, 28 Feb 2024 11:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 租金价格预测项目展示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b23xsh/project_rental_price_prediction_project_showcase/</link>
      <description><![CDATA[      大家好， 刚刚结束了一个项目，我在其中构建了一个系统，使用 Rightmove 的数据来预测租金价格。我真正深入研究了数据工程、机器学习工程和 MLOps，这一切都归功于我参加的免费 Data Talk Clubs 课程。我自学了数据工程和机器学习（金融专业毕业生）。我非常感谢有关此项目的任何建设性反馈。 快速功能：  带监控的生产网络抓取 具有特征工程的随机森林租金预测模型。设计了步行评分算法（基于我在网上找到的内容） MLOps 以及模型、数据质量和数据漂移监控。  技术堆栈：&lt; /strong&gt;  基础设施：Terraform、Docker Compose、AWS 和 GCP。 使用 FastAPI 进行模型服务，并通过 Streamlit 和 Grafana 进行视觉洞察。 使用 MLFlow 进行实验跟踪。  我尝试将这些课程中的所有内容整合在一起。我不确定我是否遵循行业标准。你可以随心所欲地严厉和诚实。我所关心的是反馈是否可行。谢谢。 Github：https://github.com/alexandergirardet/london_rightmove &lt; p&gt;ML 训练管道 &lt; p&gt;MLOps 监控 系统图   由   提交/u/Ok_Bobcat_7458   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b23xsh/project_rental_price_prediction_project_showcase/</guid>
      <pubDate>Wed, 28 Feb 2024 11:33:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 更高层需要更多 LoRA 专家</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b23dfx/r_higher_layers_need_more_lora_experts/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.08562 代码：https://github .com/GCYZSL/MoLA 摘要：  参数高效调整（PEFT）技术，例如低秩适应（ LoRA）提供了大型语言模型的训练效率，但它们对模型性能的影响仍然有限。最近的努力将 LoRA 和专家混合 (MoE) 相结合，以提高 PEFT 方法的性能。尽管取得了令人鼓舞的成果，但利用 MoE 提高 LoRA 效率的研究仍处于早期阶段。最近的研究表明，教育部架构中的专家具有不同的优势，并且也表现出一些冗余。这个说法是否也适用于参数高效的 MoE？在本文中，我们介绍了一种新颖的参数高效 MoE 方法，MoE-Lo 与 L分层专家 A 分配 (MoLA) 用于基于 Transformer 的模型，其中每个模型层都可以灵活地雇用不同数量的 LoRA 专家。我们研究了几种具有不同分层专家配置的架构。在六个著名的 NLP 和常识 QA 基准上进行的实验表明，与所有基准相比，MoLA 实现了相同或更好的性能。我们发现，将更多的 LoRA 专家分配到更高层可以进一步增强具有一定数量专家的模型的有效性。由于参数少得多，这种分配策略的性能优于每层专家数量相同的设置。这项工作可以作为一种即插即用的参数高效调整方法广泛应用于各种应用。该代码可在此 https URL 处获取。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b23dfx/r_higher_layers_need_more_lora_experts/</guid>
      <pubDate>Wed, 28 Feb 2024 10:59:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] GLoRe：何时、何地以及如何通过全局和本地改进改进法学硕士推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b237zh/r_glore_when_where_and_how_to_improve_llm/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.10963 摘要：  最先进的语言模型可以展示令人印象深刻的推理数学、科学或编码任务的改进能力。然而，最近的研究表明，即使是最好的模型，在无法获得外部反馈的情况下也很难确定何时何地进行改进。基于结果的奖励模型 (ORM) 经过训练，可以预测最终答案的正确性（指示何时进行优化），为决定何时进行优化提供了一种方便的解决方案。基于流程的奖励模型（PRM）经过训练可以预测中间步骤的正确性，然后可以用来指示需要改进的地方。但它们的训练成本很高，需要大量的人工注释。在本文中，我们提出了逐步 ORM (SORM)，仅在合成数据上进行训练，以近似最优策略或 V 的预期未来奖励/em&gt;⋆。更具体地说，SORM 经过训练，可以在对当前策略进行多次采样（而不是像 ORM 那样只采样一次）时预测最终答案的正确性。我们的实验表明，与 ORM 相比，SORM 可以更准确地检测到不正确的推理步骤，从而提高进行细化时的下游准确性。然后，我们训练全局细化模型，该模型仅将问题和草稿解决方案作为输入并预测正确的解决方案，以及局部细化模型，该模型也将批评作为输入，表明第一个推理错误的位置。我们通过重用用于训练 SORM 的数据来综合生成两个模型的训练数据。我们发现，使用 ORM 作为重新排序器，结合全局和局部改进，显着优于其中任何一个单独的改进，以及三个样本基线中的最佳结果。通过这种策略，我们可以将 GSM8K 上的 LLaMA-2 13B 模型（已通过 RL 进行微调）的准确率在贪婪采样时从 53% 提高到 65%。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b237zh/r_glore_when_where_and_how_to_improve_llm/</guid>
      <pubDate>Wed, 28 Feb 2024 10:49:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 1 位 LLM 时代：所有大型语言模型均采用 1.58 位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b22izk/r_the_era_of_1bit_llms_all_large_language_models/</link>
      <description><![CDATA[https://arxiv.org/abs/2402.17764 摘要  最近的研究，例如 BitNet，正在为 1 位大型语言模型的新时代铺平道路（法学硕士）。在这项工作中，我们引入了一个 1 位 LLM 变体，即 BitNet b1.58，其中 LLM 的每个参数（或权重）都是三元的 {-1, 0, 1}。它在困惑度和最终任务性能方面与具有相同模型大小和训练令牌的全精度（即 FP16 或 BF16）Transformer LLM 相匹配，同时在延迟、内存、吞吐量、和能源消耗。更深刻的是，1.58 位法学硕士定义了新的扩展法则和配方，用于培训高性能且经济高效的新一代法学硕士。此外，它还实现了一种新的计算范例，并为设计针对 1 位 LLM 优化的特定硬件打开了大门。    由   提交/u/Civil_Collection7267   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b22izk/r_the_era_of_1bit_llms_all_large_language_models/</guid>
      <pubDate>Wed, 28 Feb 2024 10:03:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 为图像生成相关背景的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b22bbd/p_a_model_to_generate_relevant_background_for_an/</link>
      <description><![CDATA[例如，如果输入图像是鞋子，我希望模型为该鞋子图像生成具有不同类型背景的图像。背景应该有相关的配色方案，也许是风景等。 就像输入图像是植物一样，我希望模型生成的图像中植物位于最前面，可能是海滩背景。 是否有任何现有模型可以做到这一点？  或者，如果我必须创建一个，我可以使用现有的库来完成它，这样我就不必大量训练模型吗？ 就像 - 1. 删除任何现有的库图像背景 2. 检测对象的颜色 3. 然后我可以使用图像模型提示为该特定对象生成具有特定颜色的背景吗？ 4. 一旦我完成了所有这些，我可以合并两个图像吗？  这听起来怎么样？    由   提交 /u/AccomplishedKey6869   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b22bbd/p_a_model_to_generate_relevant_background_for_an/</guid>
      <pubDate>Wed, 28 Feb 2024 09:49:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在生产中训练模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b21zfh/d_trainining_a_model_in_production/</link>
      <description><![CDATA[我是一名硕士生，被指派做我的第一个半大型项目。我面临两个主要问题，想知道它们在现实世界中是如何解决的。 第一个是，我们只看到了 jupyter 笔记本，但是随着项目的发展，它们变得越来越不可用，它们不能很好地与脚本配合使用，因为每个新的修改都需要重新启动内核（我知道有一个扩展，但我发现它不够可靠）。另一个问题是我的计算能力较低。 我的想法是准备模型并将其定义（.py 脚本）发送给为我进行培训的云提供商，例如 aws（？） 。它是否正确？我错过了什么吗？   由   提交 /u/Puddino   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b21zfh/d_trainining_a_model_in_production/</guid>
      <pubDate>Wed, 28 Feb 2024 09:26:48 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 动力学模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b213uf/discussion_dynamical_models/</link>
      <description><![CDATA[嘿朋友们，我写了一篇关于动态模型的博客文章——关于 AGI 有希望的研究方向的一些想法。假设未来的研究应该集中于使用专门的架构和大规模的训练方法，关注具有稳定、长期、不断发展和不断优化动态的训练系统。希望有人会觉得它们很有趣。 第 1 部分：https://medium.com/@tommyx058/cdda161fa7f9 第 2 部分：https://medium.com/@tommyx058/e226eee07627   由   提交 /u/TommyX12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b213uf/discussion_dynamical_models/</guid>
      <pubDate>Wed, 28 Feb 2024 08:27:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 流失数据集中产品使用的特征提取方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1zti4/d_feature_extraction_methods_for_product_usage_in/</link>
      <description><![CDATA[您好，希望您一切顺利。 我在一家 B2B SaaS 公司从事工程方面的工作，但我&#39;我们的任务是创建流失预测 ML 模型。目前，它处于笔记本阶段。 我们有所有客户的产品使用评分，其原始输入也按每日频率进行计时（例如，按用户比例登录和使用的其他某些功能） ）。考虑此产品使用得分是因为在客户正式流失前 60 天左右，该产品使用得分往往会下降 10-15%。据推测，这是他们正在尝试竞争对手产品的重叠时期。 我正在尝试思考可以为此时间序列数据执行特征提取方法的不同方式。我已经尝试过的两个包括：  总结最近 60 天的使用情况，然后还有一个代表我们的订阅级别列表的编码列（因为某些功能可用于他们各自的订阅）。  将生命周期使用平均值与最近 60 天的时间段进行比较。这里的目的是，如果它们即将流失，则生命周期使用差异应该高于最近 45-60 天的时间段。 （旁注：这应该计算为差异还是比率？）  我还在流失数据集中使用了一堆其他标准列，例如行业、规模细分除此之外，我对如何表示这些功能的使用分数以考虑用户如何将我们的产品用于模型的想法非常干燥。这一点尤其重要，因为这个模型在生产中需要考虑成本不要太高。 有人做过类似的任务吗？如果是这样，您是如何描述用户对产品的使用情况的？使用每日数据集也是一个问题，因为它是一个非常大的数据集，因此我尝试通过尽可能尝试不同的特征工程方法来减小文件大小。 如果我还没有完全清楚，请提前道歉，英语不是我的母语。如果您需要任何其他信息，请随时询问，我会尽可能跟进。  谢谢。 :)   由   提交/u/herr94491   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1zti4/d_feature_extraction_methods_for_product_usage_in/</guid>
      <pubDate>Wed, 28 Feb 2024 07:01:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用超过 10,000 个 GPU 进行 LLM 训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1m0sy/r_llm_training_with_10000_gpus/</link>
      <description><![CDATA[LLM 训练超过 10,000 个 GPU！ https://arxiv.org/abs/2402.15627 想法??   由   提交 /u/CathieVictoriaWood   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1m0sy/r_llm_training_with_10000_gpus/</guid>
      <pubDate>Tue, 27 Feb 2024 20:26:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为从事跨学科人工智能研究的研究人员（博士后/博士）下一步提供建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1jp42/d_advice_for_the_next_step_of_researchers/</link>
      <description><![CDATA[我不确定这是否是一个常见问题。 我是一名博士后，在欧洲从事与人工智能相关的项目，没有论文顶级人工智能会议。我主要专注于将人工智能应用于特定领域的数据集。 然而，做博士后是一项不稳定的工作，我意识到我可能不喜欢做研究，可能是因为缺乏研究的兴趣和热情。  p&gt; 除了继续做博士后或应用 PI（可能非常具有挑战性）。工业是我的情况的选择吗？显然，我无法与“真正的人工智能”竞争。研究人员进入大型科技公司。 小型科技公司的 MLE 或 DS 工作怎么样？另外如果没有应届毕业生，我找这些工作会不会更难？ 如果可以的话，我应该准备什么？ Leetcode什么的。如果不是，有什么选择？ 谢谢。   由   提交/u/CurrentExamination49   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1jp42/d_advice_for_the_next_step_of_researchers/</guid>
      <pubDate>Tue, 27 Feb 2024 18:53:23 GMT</pubDate>
    </item>
    <item>
      <title>[D]最近与凸优化相关的文献？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1j1yd/drecent_literature_related_to_convex_optimization/</link>
      <description><![CDATA[大家好，我在凸优化课程中，该课程的一个关键组成部分是一个项目，在该项目中我们将凸优化传递回我们的区域学习，对我来说就是深度学习。显然，如果取得重大进展，这也可以转化为研究想法。  无论如何，我正在寻找有关我可以探索的最近论文/有趣项目的方向/建议。我确实希望我的结果能够呈现出一定程度的新颖性！提前致谢    由   提交 /u/Quiet_Cantaloupe_752   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1j1yd/drecent_literature_related_to_convex_optimization/</guid>
      <pubDate>Tue, 27 Feb 2024 18:27:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从某种意义上说，“在分布之外泛化”的想法不是不可能的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1he3r/d_isnt_the_idea_of_generalizing_outside_of_the/</link>
      <description><![CDATA[嘿，我并不是专门从事机器学习的人，但我是一名开发人员，并且对此有 8 年的业余爱好者研究。 &lt; p&gt;在分布之外进行泛化的想法对我来说一直很不寻常。当然，如果您学习英语，那么您现在在某种意义上就会知道如何编码，因为它是英语的。在这种情况下，该模型的泛化程度远没有我们希望的那么高，因为编码所需的基础知识几乎不是逻辑，而是读写。 在同样的意义上，人们可以想象一种颜色是不同颜色的混合。但想象一种全新的颜色并尝试一下，实际上是不可能的。在这种情况下，我们对分布之外的概括的定义并不在分布之外，只是分布比我们想象的（或可以量化的）要大 与想象你从未听过的声音是一样的。再一次，你可以想象你听到过的其他声音的融合，也许你想象的这种新声音确实是你在现实中从未听过的东西，但你还没有推广到频谱的其余部分。我无法想象 20khz 以上的声音听起来是什么样子，因为我完全没有关于它可能是什么的基本事实，就像我无法客观地想象 X 射线是什么样子，因为我受限于我的能力，只能看到可见光。   由   提交 /u/EveningPainting5852   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1he3r/d_isnt_the_idea_of_generalizing_outside_of_the/</guid>
      <pubDate>Tue, 27 Feb 2024 17:21:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 会议论文是双盲的。为了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b18is0/d_conference_paper_is_doubleblinded_for_what/</link>
      <description><![CDATA[我对提交给会议的论文必须双盲的要求感到非常困惑，但它们却可以预印有作者姓名和隶属关系，并且可以同时作为同一篇论文共享。人们甚至在接受/发表之前在 Twitter、LinkedIn、Reddit 等 SNS 上宣传他们的论文。感觉就像我在看 Instagram 版的学术界。如何确保广告而不是报纸本身不会影响决策过程？   由   提交 /u/Dry_Cheesecake_8311   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b18is0/d_conference_paper_is_doubleblinded_for_what/</guid>
      <pubDate>Tue, 27 Feb 2024 10:17:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>