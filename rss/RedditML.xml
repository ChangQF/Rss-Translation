<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 21 Feb 2024 00:57:25 GMT</lastBuildDate>
    <item>
      <title>[R] 被一个试图学习反向传播基础知识的视频所困扰</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avwfxe/r_stumped_on_a_video_trying_to_learn_the/</link>
      <description><![CDATA[我正在观看这个有关反向传播的视频&lt; /a&gt; 今天，我真的很喜欢，但这段视频中的某些内容让我难住了。我的想法完全一致，步调一致，直到 3:33 他说，“当我们乘法时，我们得到……” ∂C --- = i = 1.5 * 2(a-y) = 4.5 * w - 1.5 ∂w 我怎么也无法理解他是怎么得到 4.5 的* 本视频中的 w -1.5。 我希望这个帖子上的人可以帮助我解开这个谜团！   由   提交 /u/Lanky_Barnacle1130   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avwfxe/r_stumped_on_a_video_trying_to_learn_the/</guid>
      <pubDate>Tue, 20 Feb 2024 23:29:09 GMT</pubDate>
    </item>
    <item>
      <title>[N] 流浪小猪饼干来到Zuse研究所，研究用于原子和分子建模的图形处理器。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avverg/n_biscuit_the_wandering_piglet_arrived_at_the/</link>
      <description><![CDATA[   大家好！来认识一下饼干，一只玩具小猪，它通过从一个旅行者到另一个旅行者的传递而环游世界。 Biscuit 最近与来自日内瓦的科学家一起访问了柏林 Zuse 研究所，参加了“原子和分子建模未来高性能计算的前景和挑战”会议。在那里，Biscuit通过聆听所有讲座并检查超级计算机中使用的GPU，认真地探讨了这个话题。 接下来，他将前往日内瓦，与CERN的科学家一起参观大型强子对撞机。&lt; /p&gt; ——------------------------ 一些背景故事：不久前，我来了有了创造玩具的想法。它的名字叫饼干，是我和妻子制作的一只迷人的小猪。 Biscuit的使命是环游世界，从一只手传递到另一只手。通过这个项目，我的目标是连接全球各地的人们，展示我们星球的美丽，分享各地的精彩故事和事实。 为此，我们创建了一个 Instagram 页面 https://www.instagram.com/biscuitroams/ 此处将发布 Biscuit 的所有更新和冒险。另外，我会在Imgur和Reddit上整理并发布完整的故事。 Biscuit还有一个小背包，参与者可以通过它交换来自不同国家的小纪念品和磁铁！ Biscuit有他的旅程才刚刚开始，目前我们只有很少的志愿者来陪伴他。如果你有喜欢旅行的朋友，也许他们会想带上Biscuit一起去！ 是的，而且Biscuit很小，站立时全高只有18厘米。他可以轻松放入公文包中，而且他的小公文包上有一个登山扣，因此可以牢固地固定他。   由   提交 /u/Dangerous-Annual-511   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avverg/n_biscuit_the_wandering_piglet_arrived_at_the/</guid>
      <pubDate>Tue, 20 Feb 2024 22:46:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 飞行路径优化算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avsyfg/r_flight_path_optimisation_algorithm/</link>
      <description><![CDATA[我正在创建一个工具来帮助飞机在两个城市 A 和 B 之间更智能地飞行。可以将其想象为 Google 地图，但适用于飞机。当飞机飞行时，它们不会直接从 A 点飞往 B 点；而是直接从 A 点飞往 B 点。它们遵循一条从一个点跳到另一个点的路径，称为路径点。这些航路点和其他细节，例如飞机飞行多远、需要多长时间以及使用多少燃料，都是提前计划好的，并写在所谓的飞行计划报告中。但是，实际飞行可能会比预期使用更多燃油或花费更长的时间。 我有这些城市之间过去航班的记录，因此我知道哪些路径确实非常节省燃油。我的目标是建立一个算法，查看即将到来的航班的计划路线，并与过去的航班进行检查。然后，它会向飞行员建议节省燃油的最佳路径。这就像提醒他们过去哪些路线最省油。”我在这方面完全是新手。有人可以帮我选择应该选择的优化方法吗？   由   提交/u/Desperate_Roll2360   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avsyfg/r_flight_path_optimisation_algorithm/</guid>
      <pubDate>Tue, 20 Feb 2024 21:09:41 GMT</pubDate>
    </item>
    <item>
      <title>有哪些开源库可以帮助我在构建 LLM 应用程序时轻松地在 LLM 之间切换？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avryf1/any_open_source_libraries_that_can_help_me_easily/</link>
      <description><![CDATA[我一直在构建使用 LLM 和 RAG 的开源工具，但是，有大量的 LLM 模型和框架可供选择，包括OpenAI、Huggingface、AzureOpenAI 等。为每个类编写新类和扩展可能很困难。我很好奇是否有更简单的方法，例如将最大数量的 LLM api 统一在一个工具/框架下，这样我就不必为所有内容编写一个新类？  在这些情况下你通常会做什么？   由   提交 /u/metalvendetta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avryf1/any_open_source_libraries_that_can_help_me_easily/</guid>
      <pubDate>Tue, 20 Feb 2024 20:30:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kaggle 数据集与实际表格数据 - 痛苦的认识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avq8uz/d_kaggle_datasets_vs_actual_tabular_data_bitter/</link>
      <description><![CDATA[经过多年在 Kaggle 或其他平台上的表格数据集的工作和实践，我终于开始使用来自大学医院的表格数据，就像一滩污垢花了一整天的时间才找到正确的标题并链接所有这些表间公式和过滤器。另一方面，我花了最多。 Kaggle 数据集上的 EDA 需要 30 分钟。  我被告知了其中的差异，但意识到 DS 必须处理什么混乱。总是低估它，跳过与之相关的研讨会，还随意取笑它（我通常处理图像和视频）。   由   提交 /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avq8uz/d_kaggle_datasets_vs_actual_tabular_data_bitter/</guid>
      <pubDate>Tue, 20 Feb 2024 19:23:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 预测编码能否兑现其承诺？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avpf9n/r_can_predictive_coding_lives_up_to_its_promise/</link>
      <description><![CDATA[只是想知道社区中是否有人仍在研究预测编码，据我了解，预测编码早在 1999 年就由 Rajesh Rao 开始，https://www.researchgate.net/publication/13103385_Predictive_Coding_in_the_Visual_Cortex_a_Functional_Interpretation_of_Some_Ex tra-classical_Receptive-field_Effects。在论文中，如图 1 所示，只有很小的误差信号从一个阶段传递到另一个阶段，这被认为像生物神经网络一样更加节能。尽管从 25 年前开始，并在此过程中发表了多篇论文。我在（1）节能（2）真正的本地化异步训练方面看不到太多希望。我错过了什么吗？   由   提交/u/Tasty_Road_3519   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avpf9n/r_can_predictive_coding_lives_up_to_its_promise/</guid>
      <pubDate>Tue, 20 Feb 2024 18:50:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有人用TTS看论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avk8t6/r_does_any_use_tts_to_read_papers/</link>
      <description><![CDATA[显然，论文太多，难以阅读。想知道是否有人在散步或跑步时使用 TTS 平台听论文。 任何建议都很棒！ 如果重复，请道歉。   由   提交/u/sck209  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avk8t6/r_does_any_use_tts_to_read_papers/</guid>
      <pubDate>Tue, 20 Feb 2024 15:25:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么扩散器库改变了原来的采样算法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avjgso/d_why_does_the_diffuser_library_change_the/</link>
      <description><![CDATA[      我最近一直在分析拥抱面部扩散器库的内部工作原理，并且我已经意识到step()函数内部采样方法似乎发生了变化： ​ https://preview.redd.it/9zz4yzm37rjc1.png?width=2041&amp;format=png&amp;auto=webp&amp;s = de825eb3d57bbffa103998368f60401dc9f6f304 如果我理解正确的话，首先，他们使用以下公式创建 x₀ 的预测： https://preview.redd.it/2cy3dp257rjc1.png?width=1483&amp;format=png&amp;auto =webp&amp; ;s=3126d7b6ddb26743f4c0545275d0dc3a12f154a0 接下来，他们使用以下方程创建 xₜ₋₁： https://preview.redd.it/72hbpzn57rjc1.png?width=1936&amp;format=png&amp;auto=webp&amp;s=3f839aa6ad 96d3c81812256e33573859a30b8f9b 但我认为这与原始方程第 4 行相比是一个巨大的变化： https://preview.redd.it/upexate77rjc1.png?width=1060&amp;format=png&amp;auto=webp&amp;s=4c6d17715f7 4fa4b72ecf63b4a82598634a36372&lt; /a&gt; 为什么他们使用不同的方式来获取xₜ₋₁？这种方法有什么优点？有没有任何原始材料或论文可以检查它的来源？ 谢谢您的帮助！   由   提交 /u/SrPinko   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avjgso/d_why_does_the_diffuser_library_change_the/</guid>
      <pubDate>Tue, 20 Feb 2024 14:52:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对检索增强生成（RAG）中的不同术语感到困惑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avikjn/d_confused_about_different_terms_in/</link>
      <description><![CDATA[嗨，我有一个课堂练习，需要对检索增强生成 (RAG) 进行文献回顾。我的老师告诉我们阅读“在检索增强生成中对大型语言模型进行基准测试”并找到一些其他有助于提高噪声鲁棒性的论文和信息交互。  我发现的一篇论文是“Chain-of-note：增强检索增强语言模型的鲁棒性”，他们提到了检索增强语言模型（RALM）。  那么这个RAG和RALMs是相同还是不同呢？据我了解，RALM 是 RAG 的一小部分，因为它将语言模型与从大量文档中查找信息的系统结合在一起。我是对的吗？ 此外，从 Chain-of-note 论文中，我读到了另一篇论文“Interleaving Retrieval with Chain”知识密集型多步骤问题的深度推理”感觉虽然看起来一样，但实际上它解决了与 Chain-of-note 不同的问题。  ​   由   提交 /u/ma-d-ghost   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avikjn/d_confused_about_different_terms_in/</guid>
      <pubDate>Tue, 20 Feb 2024 14:12:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为本科生选择一个 ML 实验室：大型、成熟的实验室还是小型、专注的实验室？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avie4g/d_picking_an_ml_lab_as_an_undergraduate_big/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avie4g/d_picking_an_ml_lab_as_an_undergraduate_big/</guid>
      <pubDate>Tue, 20 Feb 2024 14:04:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 其他流行/宣布的扩散变压器产品，如 Sora？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avht7j/d_other_popularannounced_diffusion_transformer/</link>
      <description><![CDATA[虽然 Sora 引起了不小的轰动，但还有哪些其他已知、流行/宣布的产品使用类似的模型架构？ &lt; !-- SC_ON --&gt;  由   提交 /u/CodeComedianCat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avht7j/d_other_popularannounced_diffusion_transformer/</guid>
      <pubDate>Tue, 20 Feb 2024 13:36:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文解释：V-JEPA：重新审视特征预测以从视频中学习视觉表示（视频分析）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aveqx4/d_paper_explained_vjepa_revisiting_feature/</link>
      <description><![CDATA[https://youtu.be/7UkJPwz_N_0 V-JEPA 是一种仅使用潜在表示预测作为目标函数来进行视频数据无监督表示学习的方法。 概要： 0:00 - 简介&lt; /p&gt; 1:45 - 预测特征原理 8:00 - （广告）权重和权重结构化 LLM 输出偏差课程 9:45 - 原始 JEPA 架构 27:30 - V-JEPA 概念 33:15 - V-JEPA架构 44:30 - 实验结果 46:30 - 通过解码进行定性评估 ​ 博客：&lt; a href=&quot;https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/&quot;&gt;https://ai.meta.com/ blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/ 论文：https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning- Visual-representations-from-video/ ​ 摘要： 本文探讨了特征预测作为一个独立的目标用于从视频进行无监督学习，并引入了 V-JEPA，这是一组仅使用特征预测目标进行训练的视觉模型集合，不使用预训练的图像编码器、文本、负例、重建或其他监督源。这些模型使用从公共数据集中收集的 200 万个视频进行训练，并针对下游图像和视频任务进行评估。我们的结果表明，通过预测视频特征进行学习可以产生多功能的视觉表示，在基于运动和外观的任务上表现良好，而无需调整模型的参数；例如，使用我们最大的模型、仅在视频上训练的 ViT-H/16 冻结骨干网，在 Kinetics-400 上获得 81.9%，在 Something-Something-v2 上获得 72.2%，在 ImageNet1K 上获得 77.9%。 &lt; p&gt;​ 作者：Adrien Bardes Quentin Garrido Xinlei Chen Michael Rabbat Yann LeCun Mido Assran Nicolas Ballas Jean Ponce    ;由   提交/u/ykilcher  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aveqx4/d_paper_explained_vjepa_revisiting_feature/</guid>
      <pubDate>Tue, 20 Feb 2024 10:42:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数学家会在未来的机器学习研究中占据上风吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1av5gwy/d_will_mathematicians_have_the_upper_hand_in/</link>
      <description><![CDATA[似乎在各个角落我都看到了关于做研究的类似情绪。人们尝试各种事物的组合来获得渐进式的改进。我认为下一步的飞跃需要大量的理论知识来指导方向。   由   提交 /u/planetofthemushrooms   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1av5gwy/d_will_mathematicians_have_the_upper_hand_in/</guid>
      <pubDate>Tue, 20 Feb 2024 01:46:38 GMT</pubDate>
    </item>
    <item>
      <title>对于技术主管来说，您的实际工作是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auyt1n/for_anyone_whos_a_tech_lead_what_is_your_actual/</link>
      <description><![CDATA[在担任主要 DS 后，我最近被任命为一个大项目的技术主管，并发现自己在思考我的角色实际上是什么/应该是什么..你每天都做什么？与参加会议和计划里程碑等相比，您还有多少编码和技术工作？    由   提交 /u/natrules   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auyt1n/for_anyone_whos_a_tech_lead_what_is_your_actual/</guid>
      <pubDate>Mon, 19 Feb 2024 21:11:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>