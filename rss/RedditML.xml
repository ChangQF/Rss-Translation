<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 21 Feb 2024 18:16:10 GMT</lastBuildDate>
    <item>
      <title>[P] marimo-wasm：浏览器中的反应式 Python 笔记本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awimon/p_marimowasm_a_reactive_python_notebook_in_the/</link>
      <description><![CDATA[我们（2 位开发人员）使 marimo[1] 与 WebAssembly (WASM) 兼容，因此您可以完全在浏览器中运行它，这要归功于 Pyodide。 您可以尝试游乐场：https://marimo.app/&quot;&gt;https:// /marimo.app/。这是学习 Python 或教育他人的绝佳工具，因为您可以通过 URL 共享代码片段。例如，以下是 贝叶斯定理. [1] marimo 在 GitHub 上开源：https://github.com/marimo-team/marimo   由   提交 /u/mmmmmmyles   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awimon/p_marimowasm_a_reactive_python_notebook_in_the/</guid>
      <pubDate>Wed, 21 Feb 2024 17:59:05 GMT</pubDate>
    </item>
    <item>
      <title>小数据集中交叉验证的意义是什么[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awfsw8/what_is_the_meaning_of_crossvalidation_in_a_small/</link>
      <description><![CDATA[据我所知，在深度学习的背景下，k 折交叉验证旨在为超参数分配训练/验证对的多个子集调整。更不用说独立的测试数据集了，每个训练/验证折叠都应该对应于一个使用不同超参数训练的“最终”模型，以便我们可以比较超参数的效果。 然而，在一个小数据集中，数据在一个子集中可能无法泛化，我如何知道不同子集中的模型性能差异是来自数据的偏差还是所使用的超参数的差异？ （例如，在 CNN 中，我们的数据通常有限，而图像通常包含显着不同的特征）   由   提交/u/alan6690  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awfsw8/what_is_the_meaning_of_crossvalidation_in_a_small/</guid>
      <pubDate>Wed, 21 Feb 2024 16:08:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 图+向量数据库？需要您的意见：Cognee.ai。用于现实世界生产的 AI 数据管道（第 4 部分）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aweo71/d_graphs_vectordbs_need_your_input_cogneeai_ai/</link>
      <description><![CDATA[      嘿，Reddit 用户！ 我带着关于为现实世界生产创建可靠的 AI 数据管道的最新文章回来了。&lt; /p&gt; 如果您一直在关注，您就会知道我的使命是超越“瘦 OpenAI 包装器”趋势并应对构建强大数据管道的挑战。 经过几个月的工作，我们将认知架构与 keepi.ai&lt; /a&gt;  我们的目标是通过我们的演示进行探索： 1.上下文清理人工智能的世界正在快速发展，我们已经意识到上下文正在成为我们所说的未来认知架构的重要组成部分。 2.人工智能内存的最佳实践 在这个快速发展的环境中，没有既定的最佳实践。您需要对工具和流程进行有根据的押注，因为您知道事情会发生变化。我们假设拥有传统的数据工程实践+框架+分类器和其他人工智能解决方案可以解决很多标准障碍 3。人工智能框架他们试图做得太多、太快、太广泛。我们希望为人工智能内存找到一种模式和正确的抽象层，以适应新的行业。  ​ 它是如何工作的？  Github 存储库为 l: cognee 的工作原理 Github 存储库位于此处 后续步骤：我有问题要问您：  上下文清理与您相关吗？ 您如何管理元数据？  您如何为法学硕士准备数据？ 您执行任何数据丰富步骤吗？  查看博客文章： 您执行任何数据丰富步骤吗？ p&gt; 链接到第 4 部分 如果您觉得这篇文章很有见地，请记得给它点赞！ 并给我们加注星标 Github 存储库   由   提交/u/Snoo-bedooo  /u/Snoo-bedooo reddit.com/r/MachineLearning/comments/1aweo71/d_graphs_vectordbs_need_your_input_cogneeai_ai/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aweo71/d_graphs_vectordbs_need_your_input_cogneeai_ai/</guid>
      <pubDate>Wed, 21 Feb 2024 15:23:12 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 研究人员（硕士、博士）如何实现复杂模型？他们是神吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awe3ld/dr_how_do_researchers_masters_phd_implement/</link>
      <description><![CDATA[我现在正在做我的论文。我很好地掌握了大多数 ML 模型（RNN、CNN、LSTM、Transformers、GPT、CNN、GAN、LDM、VAE、自动编码器等）的高级细节。当然，我绝不是专家，但我能够学习我需要的东西。 但是当真正使用它们，并在代码中实现它们并训练它们时，这就变成了地狱。对于更简单的模型，还好，但是对于更复杂的模型，网上没有教程，他们只是说“使用现有模型”。 世界各地的研究人员如何实现复杂的模型？例如，扩散模型、LDM 或修改后的 LLM，如 Transformer 或 GPT？ 或者它们如何更改现有模型，并使用不同的技术，例如添加编码器进行调节？  &gt;就像，研究和理解基础知识很好，但实际实施起来却非常困难。他们是如何做到如此优雅的？一些调查研究论文包括多种模型的使用和比较。他们是怎么做到的？   由   提交 /u/ShlomiRex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awe3ld/dr_how_do_researchers_masters_phd_implement/</guid>
      <pubDate>Wed, 21 Feb 2024 15:00:23 GMT</pubDate>
    </item>
    <item>
      <title>[P]⚡Edgen 现在支持 Vulkan、CUDA 和 Metal | OpenAI API 的开源和本地 GenAI 服务器替代方案。支持所有 GGUF 模型，跨 Windows、Mac 和 Linux，下载一次 30MB。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awe2ho/pedgen_now_supports_vulkan_cuda_and_metal_open/</link>
      <description><![CDATA[我们⚡Edgen 的目标是让更多人能够进行以隐私为中心的本地 GenAI 应用程序开发。 它符合标准使用 OpenAI 的 API 并内置 🦀 Rust，因此可以本机编译到 Windows、Linux 和 MacOS（带有 30MB 可执行文件）。 我们希望这个社区成为第一个尝试它的社区并提供反馈！ 查看 GitHub 上的 ⚡Edgen：GitHub - edgenai/edgen：⚡ Edgen：本地私有 GenAI 服务器OpenAI 的替代方案。 并关注未来版本：  语音转文本 嵌入端点 多模式端点 文本到图像端点    由   提交/u/EdgenAI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awe2ho/pedgen_now_supports_vulkan_cuda_and_metal_open/</guid>
      <pubDate>Wed, 21 Feb 2024 14:59:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果有人能够理解并实施整个项目或 Andrej Karpathy 在他的 YouTube 频道上所做的类似复杂的事情，那么他们的行业准备程度如何？他们的雇佣能力如何？ （如果这听起来像一个愚蠢的问题，我很抱歉）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awdo6l/d_if_someone_can_understand_and_implement_the/</link>
      <description><![CDATA[我在 Andrej Karpathy 上看到了这段视频 让我们在昨晚浏览时构建 GPT Tokenizer。现在我可以清楚地承认，这远远超出了我目前的理解水平，但如果有人理解他在 youtube 上描述的项目，并且可以实现它来解决其他问题（而不仅仅是复制粘贴它），那么“可雇用”是多么的重要。他们是？  ​ 如果这不是提出此类问题的适当地方，我深表歉意。    由   提交 /u/SmartPuppyy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awdo6l/d_if_someone_can_understand_and_implement_the/</guid>
      <pubDate>Wed, 21 Feb 2024 14:42:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 简单的 Javascript 代码，可以帮助士兵和平民躲避无人机袭击（更新为立即战斗部署）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awdn2r/r_simple_javascript_code_that_could_help_soldiers/</link>
      <description><![CDATA[https://www.academia.edu/115181929 /Aerial_Object_Detection_updated_for_combat_deployment_ 当找到空中物体时，应用程序会发出蜂鸣声。空中物体在您附近盘旋的时间越长，蜂鸣声就越长。对于士兵来说，这可能意味着无人机正在瞄准他们。理想情况下，士兵可以在手机上使用该应用程序，并将该设备连接到车辆的顶部区域或在战壕中睡觉时连接到身体上。请记住，必须取出 SIM 卡，并且手机无线连接必须保持“关闭”状态。在战斗环境中。在部署之前，士兵应该连接到 WiFi 并启动应用程序。应用程序启动后，士兵可以在部署到战区时禁用 WiFi 并保持应用程序运行。为了在战斗中检测空中物体，Android手机应安装在背包顶部或头盔顶部。 在民用环境中，打开无线功能的手机可以放置在屋顶上。通过互联网，用户可以通过 facebook live 远程查看航拍场景   由   提交 /u/AnthonyofBoston   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awdn2r/r_simple_javascript_code_that_could_help_soldiers/</guid>
      <pubDate>Wed, 21 Feb 2024 14:40:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当每个受试者有多个观察结果时，您是否使用组级折叠？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awdlpi/d_do_you_use_grouplevel_folds_when_you_have/</link>
      <description><![CDATA[我在一个帖子中发表了此评论，但遭到了一些反对，所以我很好奇人们的想法。 我始终进行组级折叠，即任何给定主题的数据都不应该在训练/验证/测试集之间分割。主题只能位于折叠中的其中一个集合中，否则可能会出现数据泄漏。 根据我的经验，可能存在一种在某种程度上唯一标识特定主题的特征（想想极端的情况）如果输入“用户 ID”，则出现这种情况。过度训练的模型可以轻松地尝试了解每个主题的细节，而这些细节不会泛化到训练分布中未看到的新主题。如果您在组级别拆分训练/验证/测试，这种过度拟合会在验证/测试性能不佳中表现出来。 如果您不在组级别进行拆分，那么任何个体都可能在训练集中有样本，然后在测试集中有样本，这看起来像是就像预测准确性比全新数据更好。    提交者    /u/ZeApelido   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awdlpi/d_do_you_use_grouplevel_folds_when_you_have/</guid>
      <pubDate>Wed, 21 Feb 2024 14:39:16 GMT</pubDate>
    </item>
    <item>
      <title>[新闻]Google发布全新开放的LLM模型：Gemma模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awc179/news_google_release_new_and_open_llm_model_gemma/</link>
      <description><![CDATA[明显比 llama7 和 13 更好（但不与 Mistra7b 进行基准测试）： https://blog.google/technology/developers/gemma-open-models/   由   提交 /u/edienemis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awc179/news_google_release_new_and_open_llm_model_gemma/</guid>
      <pubDate>Wed, 21 Feb 2024 13:28:26 GMT</pubDate>
    </item>
    <item>
      <title>[P] OpenVoice（文本转语音）GPU 基准测试：RTX2070 上每美元 660 万字 - RTX 3080 Ti 上每秒 230 个字</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awbz66/p_openvoice_texttospeech_gpu_benchmark_66_million/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awbz66/p_openvoice_texttospeech_gpu_benchmark_66_million/</guid>
      <pubDate>Wed, 21 Feb 2024 13:25:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将语言模型扩展到 128K 上下文的数据工程 - MIT 2024 - 具有 128k 上下文的新开放 LLaMA-2 7B 和 13B！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awagj3/d_data_engineering_for_scaling_language_models_to/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.10171 Github： https://github.com/FranxYao/Long-Context-Data-Engineering 内部有 128k 上下文的新模型！&lt; /p&gt; 摘要：  我们研究了将语言模型的上下文长度扩展到 128K 的持续预训练方法，重点是数据工程。我们假设长上下文建模，特别是在任意输入位置利用信息的能力，是一种大部分已经通过大规模预训练获得的能力，并且这种能力可以很容易地扩展到比训练期间看到的更长的上下文（例如，4K 到 128K）通过对适当的数据混合进行轻量级持续预训练。 我们调查了持续预训练的数据数量和质量：(1) 对于数量，我们表明 5 亿到 50 亿个令牌足以使模型能够在 128K 上下文中的任何位置检索信息； (2) 对于质量，我们的结果同样强调域平衡和长度上采样。具体来说，我们发现，对书籍等某些领域的较长数据进行上采样（现有工作的常见做法）会带来次优的性能，并且平衡的领域混合很重要。我们证明，在此类数据的 1B-5B 标记上对完整模型进行持续预训练是一种有效且经济实惠的策略，可将语言模型的上下文长度扩展到 128K。我们的方案优于强大的开源长上下文模型并缩小了与 GPT-4 128K 等前沿模型的差距。  https://preview.redd.it/bedg1gsgixjc1.jpg?width=1447&amp;format=pjpg&amp;auto=webp&amp;s=cdf15e90c375988b169fd24ffd5d45 05da002593  https://preview.redd.it/2qy3dhsgixjc1.jpg？ width=1837&amp;format=pjpg&amp;auto=webp&amp;s=2ced604b9e1360ee8d170773a1a0600523288516 https://preview.redd.it/pebawhsgixjc1.jpg?width=1446&amp;format=pjpg&amp;auto=webp&amp;s=4a57b8bb6685d6122d51a67e 4fa9645555c51d5a &lt; p&gt;https://preview.redd.it/o8v3kisgixjc1。 jpg?width=577&amp;format=pjpg&amp;auto=webp&amp;s=6d39b7736dc9221ed69e1c61ca36f303e8ef131e   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awagj3/d_data_engineering_for_scaling_language_models_to/</guid>
      <pubDate>Wed, 21 Feb 2024 12:05:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果一篇论文没有可用的开源代码，您是否可以为了娱乐/练习而实现该代码，并将其发布在您自己的 Github 上并附上适当的引用，并注明所有功劳均归作者所有？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awaeo0/d_if_a_paper_has_no_open_source_code_available/</link>
      <description><![CDATA[大家好， 我在发表于 的一篇论文中找到了物理数值计算的 ML 实现的描述具有 CC4 许可证的 arXiv（除了 arXiv 之外，它还发表在期刊上，但我只查看 arXiv 版本）： 您可以自由地：共享 — 复制并重新分发以下内容用于任何目的的任何媒体或格式，甚至是商业目的。改编——为任何目的（甚至商业目的）重新混合、转换和构建材料。只要您遵守许可条款，许可方就不能撤销这些自由。根据以下条款： 归属 - 您必须给出适当的信用，提供许可证的链接，并注明是否进行了更改。您可以以任何合理的方式这样做，但不得以任何暗示许可方认可您或您的使用的方式。相同方式共享 — 如果您对材料进行重新混合、转换或构建，则必须在与原始材料相同的许可下分发您的贡献。无额外限制 — 您不得应用法律条款或技术措施来合法限制他人执行许可证允许的任何操作。  据我所知，该论文没有开源代码。 如果我尝试编写自己的实现，从学术行为角度来看是否有任何问题？论文中的 ML 内容并将其发布到我自己的 Github 上？当然，我会引用这篇论文，并说这个项目中的所有内容都是基于该论文。 我真的不想联系作者来要求诚实。我想知道无论是否联系作者都可以这样做。想象一下，每次您想做类似的事情时都必须这样做（例如，练习实现“注意力就是您所需要的一切”）。 非常感谢！   由   提交/u/Invariant_apple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awaeo0/d_if_a_paper_has_no_open_source_code_available/</guid>
      <pubDate>Wed, 21 Feb 2024 12:02:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当使用大值进行回归训练时，使用值的对数还是值本身来训练模型更好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aw9csl/d_when_doing_regression_training_with_large/</link>
      <description><![CDATA[我正在训练一个模型来根据缩略图预测观看次数，并且由于观看次数相当大（数百万），我想知道我是否应该使用viewcount的日志而不是直接使用viewcount来防止损失函数爆炸。  有人对此有任何见解吗？ lr = 1e-5 batch_size=8 optimizationr = torch.optim.AdamW(model.parameters(),lr=lr) train_dataloader = torch.utils.data.DataLoader(mapped_dataset.with_format(&#39;torch&#39;), batch_size=batch_size) loss_func = nn.MSELoss()  基于日志的代码： &lt; pre&gt;对于tqdm中的批次（train_dataloader，total=1296//batch_size）：img_resized = batch[&#39;normalized_image&#39;].reshape（-1,3,720, 1296）views = torch.log(torch.tensor(batch[ &#39;views&#39;]）.to（device）.to（torch.float32））.reshape（-1,1）output_view = model（img_resized.cuda（））loss = loss_func（output_view，views）optimizer.zero_grad（）loss .backward() # torch.nn.utils.clip_grad.clip_grad_norm_(model.parameters(), 1.0) optimizationr.step() if ind % (100//batch_size) == 0: print(f&#39;lastloss&#39;, loss. item（），math.log（loss.item（））） print（output_view，views）loss.append（loss.item（））ind = ind + 1  非日志：  对于tqdm中的批次（train_dataloader，total=1296//batch_size）：img_resized = batch[&#39;normalized_image&#39;].reshape(-1,3,720, 1296)views = (torch.tensor( batch[&#39;views&#39;]).to(device).to(torch.float32)).reshape(-1,1)output_view = model(img_resized.cuda())loss = loss_func(output_view,views)optimizer.zero_grad( ) loss.backward() # torch.nn.utils.clip_grad.clip_grad_norm_(model.parameters(), 1.0) optimizationr.step() if ind % (100//batch_size) == 0: print(f&#39;lastloss&#39;, loss.item(),math.log(loss.item())) print(output_view,views)loss.append(loss.item()) ind = ind + 1  &amp; #x200b;   由   提交 /u/ExaminationNo8522   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aw9csl/d_when_doing_regression_training_with_large/</guid>
      <pubDate>Wed, 21 Feb 2024 10:59:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kaggle 数据集与实际表格数据 - 痛苦的认识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avq8uz/d_kaggle_datasets_vs_actual_tabular_data_bitter/</link>
      <description><![CDATA[经过多年在 Kaggle 或其他平台上的表格数据集的工作和实践，我终于开始使用来自大学医院的表格数据，就像一滩污垢花了一整天的时间才找到正确的标题并链接所有这些表间公式和过滤器。另一方面，我花了最多。 Kaggle 数据集上的 EDA 需要 30 分钟。  我被告知了其中的差异，但意识到 DS 必须处理什么混乱。总是低估它，跳过与之相关的研讨会，还随意取笑它（我通常处理图像和视频）。   由   提交 /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avq8uz/d_kaggle_datasets_vs_actual_tabular_data_bitter/</guid>
      <pubDate>Tue, 20 Feb 2024 19:23:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>