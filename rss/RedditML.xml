<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 20 Sep 2024 03:19:32 GMT</lastBuildDate>
    <item>
      <title>[D] 长期记忆能够从推理中产生吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl16g2/d_can_longterm_memory_emerge_from_reasoning/</link>
      <description><![CDATA[思考 RL 代理的训练过程。 步骤 1 使用问题 Q 进行训练 -&gt; 回答 A。 步骤 2 使用问题 Q&#39; 进行提示。 代理尝试了多种推理路径，最终找到了一条成功的路径。 原因：Q&#39; 与 Q 相似，因此我们可以得到与 A 相似的 A&#39;。 答案：A&#39; 训练：Q&#39;-&gt; Q -&gt; A -&gt; A&#39; 步骤 1 将知识存储到模型权重中，步骤 2 对其进行检索。此外，对步骤 2 中的样本进行训练将增加 Q 和 Q&#39; 之间的概率关系，从而检索“Q-&gt;A”  与传统方法不同，我们用大量知识训练模型，导致新知识覆盖旧知识，造成“灾难性遗忘”。使用推理链进行训练可以反复强化经常访问的知识的记忆，使它们更容易被检索，更不容易被遗忘。    submitted by    /u/Ok-Variety-8135   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl16g2/d_can_longterm_memory_emerge_from_reasoning/</guid>
      <pubDate>Fri, 20 Sep 2024 01:59:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习岗位的面试流程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl0sfk/d_interview_process_for_ml_roles/</link>
      <description><![CDATA[如果有人准备了各公司应用科学家/机器学习工程师职位的面试流程清单，请分享，我们将不胜感激    提交人    /u/mehecho   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl0sfk/d_interview_process_for_ml_roles/</guid>
      <pubDate>Fri, 20 Sep 2024 01:38:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分类交叉熵是 Softmax 过度自信的原因吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkxqv2/d_categorical_crossentropy_the_cause_of_softmax/</link>
      <description><![CDATA[所以，有一件事困扰了我一段时间，那就是我遇到的几乎每个库中的分类交叉熵实现都是 -y(log p)，对于 onehots 来说，这似乎意味着对损失唯一重要的预测是标签为真的预测。所有标签为假的预测都被忽略了。因此，如果我没有记错的话，从本质上讲，真正的阳性会得到奖励，而假阴性会受到惩罚，但真正的阴性和假阳性都会被忽略。这不会导致模型过度自信吗？ 相比之下，通常的二元交叉熵实现是 -(y(log p) +(1 - y)(log(1 - p))。这似乎意味着损失中也包括了假阳性和真阴性，在我看来，这对于生成校准良好的模型来说更合乎逻辑。 我知道 softmax（通常与分类交叉熵一起使用）由于除以总和元素而自规范化，因此它有点隐式地以这种方式惩罚假阳性，但如果您尝试将分类交叉熵与诸如 sigmoid 之类的东西一起使用，它通常无法学习，可能是因为只有 -y(log p) 就没有限制始终始终预测 1。 那么，我们为什么要使用这种分类交叉熵实现？这可能是许多具有 softmax 输出的神经网络倾向于过度自信的原因吗？我在这里遗漏了什么吗？这似乎是一个非常明显和微不足道的疏忽，如果没有其他人注意到这一点，那将是令人惊讶的。我倾向于认为我在分析中犯了一些愚蠢的错误，但我不知道是什么。    提交人    /u/JosephLChu   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkxqv2/d_categorical_crossentropy_the_cause_of_softmax/</guid>
      <pubDate>Thu, 19 Sep 2024 23:04:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将 MILP 的输出纳入损失函数进行训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkuc24/d_incorporating_output_of_milp_into_loss_function/</link>
      <description><![CDATA[大家好， 我想预测互联网流量矩阵。我训练 GRU 以最小化模型输出和地面真实流量矩阵之间的 MSE。为了进一步评估模型，我将预测流量矩阵传递给路由解决方案。路由解决方案的输出是一个缩放值。为了评估模型是否是一个好的预测器，预测的 TM 应该从路由解决方案中产生一个接近地面真实流量矩阵产生的值的值。我想设计一个损失函数，将路由解决方案作为反馈纳入我的模型训练中。有什么建议吗？ 我正在考虑将路由解决方案差异添加到我的 mse 损失函数中。像这样： import torch import torch.nn as nn class TrafficMatrixLoss(nn.Module): def __init__(self, weight_mse=1.0, weight_routing=1.0): super(TrafficMatrixLoss, self).__init__() self.weight_mse = weight_mse self.weight_routing = weight_routing def forward(self, predict_tm, ground_truth_tm, routing_solution): # 计算预测流量矩阵和地面实况之间的 MSE 损失 mse_loss = nn. functional.mse_loss(predicted_tm, ground_truth_tm) # 计算预测和地面真相的路由解决方案输出 predicted_routing_value = routing_solution(predicted_tm) # 假设这返回一个标量 ground_truth_routing_value = routing_solution(ground_truth_tm) # 假设这返回一个标量 # 根据路由解决方案计算损失 routing_loss = torch.abs(predicted_routing_value - ground_truth_routing_value) # 合并损失 total_loss = (self.weight_mse * mse_loss) + (self.weight_routing *路由损失) 返回总损失    提交人    /u/mtot10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkuc24/d_incorporating_output_of_milp_into_loss_function/</guid>
      <pubDate>Thu, 19 Sep 2024 20:32:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将嵌入模型转换为法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fktvbj/p_swapping_embedding_models_for_an_llm/</link>
      <description><![CDATA[嵌入模型与语言模型的耦合程度如何？ 以 Langchain 的教程为例，他们使用 Ollama 的 nomic-embed-text 进行嵌入，使用 Llama3.1 进行理解和问答。我没有看到任何关于基于此嵌入模型的嵌入构建 Llama 的文档。 直觉表明，不同的嵌入模型可能会产生其他大小的输出或为字符/单词产生不同的张量，这会对 LLM 的结果产生影响。那么更改嵌入模型是否也需要重新训练/微调 LLM？ 我需要对代码片段和文本使用嵌入模型。我需要为此找到专门的嵌入模型吗？如果是，llama3.1 将如何提取嵌入？    提交人    /u/noobvorld   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fktvbj/p_swapping_embedding_models_for_an_llm/</guid>
      <pubDate>Thu, 19 Sep 2024 20:13:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] EMNLP 2024 成绩/通知</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkqxhh/d_emnlp_2024_results_notifications/</link>
      <description><![CDATA[一些曲目的结果似乎已经出来了，可以在 Openreview 上查看。电子邮件可能会在明天发送。  提前祝贺大家，迈阿密见！    提交人    /u/EDEN1998   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkqxhh/d_emnlp_2024_results_notifications/</guid>
      <pubDate>Thu, 19 Sep 2024 17:45:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机械可解释性论文关于 Yannic Kilcher 分歧的讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkouvg/d_mechanistic_interpretability_paper_discussion/</link>
      <description><![CDATA[      继续 Anthropic 的变压器电路系列，并作为 Yannic Kilcher discord 服务器上每日论文讨论的一部分，我将自愿领导对以下机械可解释性工作的分析 🧮 🔍 📜 叠加玩具模型，作者为 Nelson Elhage、Tristan Hume、Catherine Olsson、Nicholas Schiefer，等人。 🌐 https://transformer-circuits.pub/2022/toy_model/index.html 🕰 2024 年 9 月 19 日星期五 12:30 AM UTC // 2024 年 9 月 19 日星期五 6.00 AM IST // 2024 年 9 月 18 日星期四 5:30 PM PT 我们在本系列中讨论过的先前的机械可解释性论文： 🔬 Softmax 线性单元 🔬 情境学习和感应头 🔬 变压器电路的数学框架 加入我们一起享受乐趣吧 ~ https://ykilcher.com/discord 叠加玩具模型    提交人    /u/CATALUNA84   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkouvg/d_mechanistic_interpretability_paper_discussion/</guid>
      <pubDate>Thu, 19 Sep 2024 16:20:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] Comgra：用于分析和调试神经网络的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</link>
      <description><![CDATA[我是一名机器学习工程师和研究员。我厌倦了理解神经网络行为方式的难度，因此我编写了一个库来帮助我。 Comgra（计算图分析） 是一个可以与 pytorch 一起使用的库，用于提取您关心的所有张量数据并在浏览器中以图形方式对其进行可视化。有关它的论文已被接受为 ICML 2024 机械可解释性研讨会的焦点论文。 与通常使用 tensorboard 的方法相比，Comgra 可以对正在发生的事情进行更详细的分析。您可以在训练过程中研究张量，深入研究单个神经元，检查您特别感兴趣的单个数据集，跟踪梯度，比较不同训练运行之间的统计数据等等。 这个工具让我比平时更快地检查我的假设，并帮助我了解网络的不同部分是如何真正相互作用的，从而为我节省了大量的研究时间。    提交人    /u/Smart-Emu5581   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</guid>
      <pubDate>Thu, 19 Sep 2024 14:07:03 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 语音合成的硬件能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fklpg1/project_hardware_power_for_synthesizing_speech/</link>
      <description><![CDATA[大家好！ 如果我没有在错误的主题中写，我有一个与我当前项目相关的问题：我正在训练一个 VITS 模型来为将集成到机器人中的 LLM 生成语音。虽然我可以依靠 OpenAI 的 LLM API 等云服务，但我认为语音合成部分需要在本地完成（由于延迟要求/我想使用我的模型）。 我的目标是实时合成（或至少最小延迟）。我的问题是：机器人的硬件需要多强大？Raspberry Pi 5 似乎有点太弱了。迷你电脑会更合适吗？CUDA 加速对于这项任务是否必不可少？我在没有 CUDA 的 i9-12900k 上测试了我当前的模型（~370k 步，我计划甚至~2M），“tts”在大约 6 秒内生成了一个输出文件，这对我来说是可以接受的。 提前感谢您的见解！    提交人    /u/Leonardo7901   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fklpg1/project_hardware_power_for_synthesizing_speech/</guid>
      <pubDate>Thu, 19 Sep 2024 14:05:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用少量数据进行训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkh1qa/p_training_with_little_data/</link>
      <description><![CDATA[大家好，提前感谢大家的见解！ 我正在做我的最后一个项目，涉及图像合成，但我面临一个挑战：我们可用的数据非常有限。我一直在研究诸如小样本学习、数据集提炼等方法来克服这个障碍。 我希望利用社区的集体智慧，看看是否有人对如何有效处理用于图像合成的小数据集有技巧、经验或建议。 期待任何建议！祝你有美好的一天！:)    提交人    /u/Galaxyraul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkh1qa/p_training_with_little_data/</guid>
      <pubDate>Thu, 19 Sep 2024 09:53:16 GMT</pubDate>
    </item>
    <item>
      <title>[P]用纯 Python 从头构建玩具神经网络框架——受 Karpathy 的 Micrograd 启发</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkg3yd/pbuilding_a_toy_neural_network_framework_from/</link>
      <description><![CDATA[      https://github.com/ickma/picograd 上周末，我开始了一个项目，完全从头开始使用纯 Python（没有 TensorFlow、PyTorch 或其他库）构建一个玩具神经网络框架。这个项目的想法来自 Andrej Karpathy 的 micrograd，我想挑战自己，真正了解神经网络在底层的工作原理。 我实现了前向和后向传播，经过一些测试后，我在 Iris 分类数据集上实现了 93% 的准确率。 这个项目是一个很好的学习工具，可以探索神经网络的内部结构，例如在训练过程中如何更新权重和偏差，以及不同层在前向和后向传递过程中如何通信。如果您希望在不依赖现有框架的情况下更深入地研究神经网络的机制，这可能对您也有帮助。 我随时可以提问或分享任何反馈！ https://preview.redd.it/jwaltnn6aqpd1.png?width=846&amp;format=png&amp;auto=webp&amp;s=3eb14eacf57fd323ac2eeb75b614ddb5f27bf8a2   由    /u/Potential-Dingo-6424  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkg3yd/pbuilding_a_toy_neural_network_framework_from/</guid>
      <pubDate>Thu, 19 Sep 2024 08:40:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kaggle 竞赛将由 AI 代理来掌控，可能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/</link>
      <description><![CDATA[我尝试在 Google 的数据科学代理工具上参加 Kaggle 竞赛 https://www.kaggle.com/competitions/playground-series-s3e19 - 基本上我只是将描述作为提示转储并将数据集上传到那里，它生成了这个 Jupyter 笔记本：https://colab.research.google.com/drive/17DkaHhcdiURHPtYBZoRvoDE9NaSzn4V4 我也在 ChatGPT 上尝试过，但不幸的是我没有 Plus，所以任务在中途终止（没有训练模型）。有 Plus 的人尝试过 ChatGPT 上的 Kaggle 任务吗？想知道我们还能看到机器人赢得比赛多久，我想 RL 会在这里发挥巨大作用。    提交人    /u/caterpillarous   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/</guid>
      <pubDate>Thu, 19 Sep 2024 05:18:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 让 LLM 训练更快的技巧指南 - Pytorch 会议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk0tun/d_hacks_to_make_llm_training_faster_guide_pytorch/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk0tun/d_hacks_to_make_llm_training_faster_guide_pytorch/</guid>
      <pubDate>Wed, 18 Sep 2024 19:06:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>