<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Fri, 19 Jul 2024 21:13:19 GMT</lastBuildDate>
    <item>
      <title>[D] 不断更新知识图谱</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7cluy/d_constantly_updating_knowledge_graph/</link>
      <description><![CDATA[我目前有一个聊天助手，它使用 Neo4j 的知识图谱 + GPT-4o 来回答用户查询。到目前为止，结果非常惊人，比我最初预期的要好得多。有时我甚至会怀念幻觉，但这是一个好问题。  我还使用 MARQO 实现了一个矢量数据库，如果图表失败，它会接管。这个 RAG 存储与问答对配对的历史消息。它的效果也很好，但不如知识图谱好。我可以轻松地更新和向 RAG 系统添加更多内容，但据我所知，不断更新知识图谱会导致一堆未经验证的低​​质量数据，这只会降低结果的质量。  解决这个问题的最佳方法是什么，以便我可以不断用最新数据更新系统，同时又不会失去它现在产生的高质量？也许更好的选择是将这两个系统结合起来，从一个系统中获取 5 个结果，从另一个系统中获取 5 个结果，创建一个单一系统，我只能不断用新数据更新 RAG，并且只能不时更新知识图，以便数据保持尽可能好？  我想尽可能地自动化，所以我正在寻找最好的解决方案。    提交人    /u/Matas0   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7cluy/d_constantly_updating_knowledge_graph/</guid>
      <pubDate>Fri, 19 Jul 2024 19:46:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 医学/医疗保健 AI 专家：临床法学硕士大多失败在哪里？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7bwun/d_medicalhealthcare_ai_experts_where_do_clinical/</link>
      <description><![CDATA[我最近与一位同事就医学法学硕士进行了一场有趣的辩论。当我们讨论这些模型容易失败的地方时，我意识到一些令人担忧的事情：工程师和计算机科学专家似乎经常忽视在实践中实际使用这些法学硕士的医学专家和医疗保健专业人士的见解。这种脱节可能导致医学领域缺乏真正高质量的法学硕士。 这一认识让我更深入地思考医学/临床/医疗保健领域大型语言模型 (LLM) 的现状。想知道： 这些专业的 LLM 往往在哪些方面存在不足？ 如果您是医学专家、AI 开发人员或使用这些模型的人，我很乐意听听您的见解：  您是否注意到他们的失败中存在任何一致的模式？ 他们是否在特定任务上遇到困难，例如： 命名实体识别 (NER) 摘要 临床记录生成 其他领域？   真的很想听听您的专业意见和观察。特别是那些身处医疗/医疗保健领域的人们，他们可能会觉得您的意见经常被忽视。 提前感谢您分享您的知识！    提交人    /u/aadityaura   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7bwun/d_medicalhealthcare_ai_experts_where_do_clinical/</guid>
      <pubDate>Fri, 19 Jul 2024 19:16:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在线课程平台研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7bu9c/d_research_for_online_courses_platforms/</link>
      <description><![CDATA[我正在开展一个以在线课程平台为重点的研究项目，研究他们的运营方式和他们提供的课程。我目前正在收集有关 LinkedIn Learning 的信息，但在查找具体数据时遇到了困难。 有人可以提供以下详细信息吗：  Linkeldn Learning 与为学习者开发课程的大学、公司或个人讲师采用的收入分成模式？ 与 LinkedIn Learning 的合作流程，包括如何与他们合作。 LinkedIn Learning 营销策略概述。 在 Linkedin Learning 上开设课程的成本是多少？  任何提供有关这些问题的信息的帮助都将不胜感激。谢谢。    提交人    /u/Substantial_Class_67   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7bu9c/d_research_for_online_courses_platforms/</guid>
      <pubDate>Fri, 19 Jul 2024 19:13:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我应该购买带有 NVIDIA GPU 的 MacBook 或笔记本电脑用于机器学习和 AI 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7a306/d_should_i_get_a_macbook_or_a_laptop_with_an/</link>
      <description><![CDATA[我是工程学院的学生，目前使用配备 GTX 1650 GPU 的联想 Legion 笔记本电脑。但是，尽管我多次尝试解决，但还是遇到了 CUDA 无法在当前显卡上运行的问题。我计划下个月购买一台新笔记本电脑。我的大部分工作都涉及使用 TensorFlow，主要用于图像处理和其他机器学习任务。我还希望从事 ML 和 AI 方面的职业，旨在将来开发高级模型。 考虑到我的情况，我需要一台可以长期使用并有效处理我的 ML 和 AI 工作负载的笔记本电脑。此外，我想要一台便携式笔记本电脑，因为随身携带我目前的 Legion 笔记本电脑很有挑战性。我的首要任务是拥有一台可以最大程度地减少安装库和高效运行 TensorFlow 麻烦的机器。 您能否就我应该购买 MacBook 还是配备 NVIDIA GPU 的笔记本电脑提供建议？在 Mac 上使用 TensorFlow 可能存在哪些问题？从长远来看，哪种笔记本电脑最适合我？我很感激任何指导，请理解我仍在学习这些技术——这款联想 Legion 是我的第一台高性能笔记本电脑。    提交人    /u/ayushmanranjan   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7a306/d_should_i_get_a_macbook_or_a_laptop_with_an/</guid>
      <pubDate>Fri, 19 Jul 2024 17:59:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] 面对过时的 GitHub 存储库时该怎么办</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e79zj3/p_what_to_do_when_facing_outdated_github_repos/</link>
      <description><![CDATA[所以我想做一个项目，为此我想我会使用来自 github 的开源模型..这是一个场景文本检测问题，为此我决定使用 EAST 模型，它也是 paperswithcode 上用于场景文本检测的顶级模型，所以对我来说很有意义.. 现在我去了 github，所有的 repo 都是 6-7 年前的，使用的 python 版本已经过时，repo 中一个关键包不再可通过 pip 获得...我对那个库进行了混合搭配，但结果很糟糕，因为现在我在同一个项目中使用多个 python 版本，我不知道该如何处理.... 现在我在想我应该在最新的 python 版本中创建一个项目并复制粘贴所有代码并自己处理弃用的东西，这个想法听起来怎么样？这是解决此类问题的合法方法吗？请在这里指导我一下 https://github.com/argman/EAST - 这个人正在使用 tensorflow 模型并且 f2 分数较低，所以我只从这里挑选了 lanms https://github.com/SakuraRiven/LANMS - 这个人在 pytorch 中做到了并且获得了更高的 f2 分数，但是他使用的 lanms 对我来说不起作用    提交人    /u/Relevant-Ad9432   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e79zj3/p_what_to_do_when_facing_outdated_github_repos/</guid>
      <pubDate>Fri, 19 Jul 2024 17:55:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用检索增强生成模型回答可解释性和透明度问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e77yul/d_answer_explainability_and_transparency_with/</link>
      <description><![CDATA[大家好， 我一直在探索检索增强生成 (RAG) 系统的迷人世界，它们将大型语言模型与检索机制相结合以提供准确且上下文丰富的答案的能力确实令人印象深刻。但是，我一直在想这些模型生成的答案的可解释性和透明度。具体来说，我很好奇了解模型正在使用提供的上下文的哪些部分来生成答案。 尽管我付出了努力，但我还是无法找到有关此主题的大量相关研究、文章或公共用例。是不是只有我一个人，我没有使用适当的关键字进行谷歌搜索，还是真的缺乏该领域的研究？我认为了解模型如何得出答案至关重要，尤其是在信任和验证信息很重要的应用中。 我渴望听到您的想法和经验。如果您使用过 RAG 或类似模型，您如何确保答案是可解释且透明的？任何最佳实践或见解都将不胜感激。 期待您的回复！    提交人    /u/Nice_Elk_4537   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e77yul/d_answer_explainability_and_transparency_with/</guid>
      <pubDate>Fri, 19 Jul 2024 16:29:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习与网络安全</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e762eu/d_machine_learning_and_cybersecurity/</link>
      <description><![CDATA[好的伙计们，我很好奇，想做一些研究，但首先我想问一下我想做什么的可能性。我想问一下是否有办法可以构建和训练一个模型，该模型可以自行执行网络攻击并学习攻击特定系统的最佳方法，例如安装了 Metasploit 的 Raspberry Pie。我想在网络安全和人工智能的交叉领域进行研究生研究。我还没有找到学校或主题，但我正在集思广益，这是其中之一。所以我只是想知道它的可行性     提交人    /u/Wixi105   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e762eu/d_machine_learning_and_cybersecurity/</guid>
      <pubDate>Fri, 19 Jul 2024 15:10:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 讨论：建立和微调生产模型 - 观察和评估策略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e71nx6/d_discussion_building_and_finetuned_models_for/</link>
      <description><![CDATA[让我们讨论一下构建 RAG 和微调模型的一些生产方面。以下是一些观察和想法：  基于 RAG 的系统的长篇评估可能不可靠。有关更多信息，请参阅此 Cohere 博客文章：https://cohere.com/blog/evaluating-llm-outputs  使用 LLM 作为评判者是一种可行的选择，但其有效性取决于几个因素：   使用的提示 提供的少量示例 选择的特定模型 谁评估 LLM 输出（这仍然是一个悬而未决的问题）  我一直在考虑以下评估框架。请分享您对此是否有意义的见解： 我们需要从两个方面验证模型输出（针对 Rag 和 Fine-tuned 模型）： 1）事实准确性 2）可读性和连贯性等 建议的方法： 将现有问题转换为具有基本事实答案和解释的多项选择题 (MCQ)。 评估过程： 1）对于 MCQ，总有一个事实答案，简化评估。 2）在要求正确的 MCQ 答案时，也要求解释。这使我们能够使用 LLM 作为评判者来比较[模型解释、基本事实解释]，从而提供对其他指标的见解。 分享您的意见，您对这个框架有什么建议或改进吗？   由    /u/aadityaura  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e71nx6/d_discussion_building_and_finetuned_models_for/</guid>
      <pubDate>Fri, 19 Jul 2024 11:41:42 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 寻求见解，联邦辅助学习问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6zx85/research_asking_for_insights_federated_auxiliary/</link>
      <description><![CDATA[正如文中提到的，为特定客户端分别实现辅助任务，而主要任务在服务器级别（联邦学习场景中所有客户端都具有相同的 DL 模型）会很有趣吗？ 我认为所有辅助任务都将从不同的密切相关的数据集中学习，但所有任务（包括主要任务）基本上应该是相同的 - 回归任务：预测时间序列中的某个点-。 这有意义吗，我觉得我没有获得太多辅助学习，因为这感觉像是经典的 FL 范式。请提供见解？    提交人    /u/thekingos   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6zx85/research_asking_for_insights_federated_auxiliary/</guid>
      <pubDate>Fri, 19 Jul 2024 09:51:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] NER 印地语的最佳 LLM 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6zdbs/d_best_llm_model_for_ner_hindi/</link>
      <description><![CDATA[我试图将 NER 应用于印地语文章。我既没有好的模型，也没有在训练后获得更好的输出。因此尝试使用 LLM 来实现相同的目的。哪种仅限 CPU 的模型足以为印地语文本提供 NER？    提交人    /u/expiredUserAddress   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6zdbs/d_best_llm_model_for_ner_hindi/</guid>
      <pubDate>Fri, 19 Jul 2024 09:12:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发布调查论文的场所</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6x7rr/d_venues_for_publishing_survey_papers/</link>
      <description><![CDATA[除了常见的 ACM Computing Surveys、TKDE、TPAMI 之外，我还应该考虑在哪些顶级会场发表调查论文。我正在考虑整理一份高质量但通常不与调查论文联系在一起的会场名单，比如 TMLR。    提交人    /u/SufficientAd3564   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6x7rr/d_venues_for_publishing_survey_papers/</guid>
      <pubDate>Fri, 19 Jul 2024 06:39:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] Redis 作为矢量数据库。有什么个人经历吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6rhjx/d_redis_as_vector_database_any_personal/</link>
      <description><![CDATA[我们正在重新审视我们的 AI 平台/堆栈，并试图找出存储嵌入和向量搜索的最佳选择。我们为金融服务领域的客户提供服务，宁愿不依赖初创公司的产品，而更愿意选择更成熟的供应商。我们正在考虑将 redis 作为一种选择。似乎 Redis 具有良好的性能（至少在更传统的数据库中是最好的）。我没有注意到 pinecone 和 Redis 之间的设置时间有很大差异。有人用过 Redis 作为向量数据库吗？你喜欢/不喜欢什么？只对个人经历感兴趣，而不是供应商的宣传    提交人    /u/Different-Use9841   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6rhjx/d_redis_as_vector_database_any_personal/</guid>
      <pubDate>Fri, 19 Jul 2024 01:11:57 GMT</pubDate>
    </item>
    <item>
      <title>[N] Fish Speech 1.3 更新：增强稳定性、情感和语音克隆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6g122/n_fish_speech_13_update_enhanced_stability/</link>
      <description><![CDATA[我们很高兴地宣布，Fish Speech 1.3 现在提供了增强的稳定性和情感，并且只需 10 秒 的音频提示即可克隆任何人的声音！作为开源社区的坚定倡导者，我们今天开源了 Fish Speech 1.2 SFT，并引入了自动重新排名系统。敬请期待，因为我们很快就会开源 Fish Speech 1.3！我们期待收到您的反馈。 Playground（DEMO）：http://fish.audio GitHub：fishaudio/fish-speech    提交人    /u/lengyue233   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6g122/n_fish_speech_13_update_enhanced_stability/</guid>
      <pubDate>Thu, 18 Jul 2024 16:46:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 训练 LLM 引用预训练数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6fxgj/r_training_llms_to_cite_the_pretraining_data/</link>
      <description><![CDATA[我们的工作被 COLM 接受，并认为值得在此分享： &quot;源感知训练实现语言模型中的知识归因&quot; TL;DR: 通常，LLM 在训练期间会学习很多东西，但不记得从哪里学到的。本文是关于教 LLM 从预训练数据中引用他们的知识来源。这可以使模型更透明、更容易理解和更可靠。我们提出了一个两步过程：1) 使用文档 ID 注入进行预训练和 2) 指令调整。第一阶段教模型将知识片段链接到特定的预训练文档。第二阶段教模型如何在生成答案时引用这些文档。 🔗 论文：https://arxiv.org/abs/2404.01019 代码：https://github.com/mukhal/intrinsic-source-citation    提交人    /u/moyle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6fxgj/r_training_llms_to_cite_the_pretraining_data/</guid>
      <pubDate>Thu, 18 Jul 2024 16:43:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>