<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 29 Mar 2024 12:24:55 GMT</lastBuildDate>
    <item>
      <title>[讨论] 寻求 ML/AI 的职业/学习指导：导航求职并寻找专业领域。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqnqs5/discussion_seeking_careerlearning_guidance_in/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqnqs5/discussion_seeking_careerlearning_guidance_in/</guid>
      <pubDate>Fri, 29 Mar 2024 12:12:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 单通道足以用于 Transformers 中的位置编码吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqnlnw/d_is_a_single_channel_enough_for_positional/</link>
      <description><![CDATA[是，使用 VAPE - 矢量加法位置编码. 我一直在探索一种新的位置编码方法，我称之为 VAPE - 矢量加法位置编码。 方法：   从查询和键中借用一些通道， 在这些借用通道上的序列长度上运行累积（前缀）总和（将向量加在一起）， &gt; 标准化 - 除以向量大小的平方根， 我们现在有了位置感知通道， 因此将它们连接回查询和键。 &gt;  有趣的是，这种方法只需每个头一个通道即可有效工作。使用单个通道意味着我们在标量而不是向量上运行前缀和，并且该方法仍然有效。 VAPE 功能：  &lt; strong&gt;无额外参数：VAPE引入位置信息，无需向模型添加任何新参数，保持其简单性和效率。 性能：早期测试表明 VAPE在最终困惑度方面优于 RoPE 等方法。 外推：早期测试表明 VAPE 可以很好地外推超出训练上下文长度，没有像 RoPE 那样添加明确的位置信息。&lt; /li&gt; 与 Flash Attention 的兼容性：与 Flash Attention 完全兼容。 效率：仅利用少量通道即可实现位置编码，VAPE 保持模型效率。 推理速度：VAPE 缓存查询和键的最后位置状态 - 这有点像 SSM/RNN，你只需要最后一个状态计算下一个。  寻求您的见解：  哪些基准或具体比较最能向您展示 VAPE 的价值？  你知道类似 VAPE 的方法吗？  基准： 我早期运行过一些对于因果语言建模任务来说，这些测试看起来非常有希望，但我用于进行基准测试的资源非常有限，因此在我投入任何精力之前，我认为最好询问社区如何进行。   由   提交/u/bnqj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqnlnw/d_is_a_single_channel_enough_for_positional/</guid>
      <pubDate>Fri, 29 Mar 2024 12:04:29 GMT</pubDate>
    </item>
    <item>
      <title>[项目]我需要创建一个光栅图像到矢量图像转换器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqmy0l/project_i_need_to_create_a_raster_image_to_vector/</link>
      <description><![CDATA[我想训练一个模型，以便它可以将光栅图像转换为矢量图像。我应该使用什么型号？有github仓库可供参考吗？    由   提交/u/GodMan6660   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqmy0l/project_i_need_to_create_a_raster_image_to_vector/</guid>
      <pubDate>Fri, 29 Mar 2024 11:29:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 魔法背后的技术：OpenAI SORA 的工作原理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqmn86/d_the_tech_behind_the_magic_how_openai_sora_works/</link>
      <description><![CDATA[大家好，我对 OpenAI SORA 进行了深入研究，很高兴与大家分享。 在在这段视频中，我解释了图像和视频生成人工智能技术的演变，并深入探讨了 OpenAI SORA 的训练方式、其功能以及对社会的影响的细节。 享受：https://youtu.be/IqZXkBjKb2E?si=aaF8MUyqc5bhZ6G9   由   提交/u/johnolafenwa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqmn86/d_the_tech_behind_the_magic_how_openai_sora_works/</guid>
      <pubDate>Fri, 29 Mar 2024 11:11:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习功能与移动/Web 功能交付</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqiwtw/d_machine_learning_feature_versus_mobileweb/</link>
      <description><![CDATA[Reddit 用户们好！我是一名机器学习工程师，在一家基于产品的初创公司工作了 4 年，该公司的技术团队约有 20 名成员，我是这里唯一的机器学习工程师。我目前面临的问题是，ML 功能预计将以与移动/Web 功能相同的速度交付。这里没有人理解机器学习，包括工程经理。我还需要按照开发人员的方式创建 Jira 票证，而且我知道 ML 任务从来不会真正遵循通常的待办事项、开发中、暂存中、审核中和生产中生命周期。这些估计总是需要经过实验，因为人们永远不知道训练期间会出现什么问题，而且变量太多，一个人无法独自处理所有问题。  我确实不认为工作场所有毒，但我当然希望这里的人们开始以更新鲜的视角看待事物。来到这里让我开始接触 JS 和 Python。尽管我可能无法使用 Kotlin 和 Swift 进行编码，但我很清楚如何在生产中使用 ML 功能以及如何在本机（iOS 和 Android）中工作。我喜欢这里的成长，但如果有一些事情发生变化，我当然会喜欢。 请随时留下您的建议/经验，我将不胜感激。再次感谢！   由   提交​​/u/Muse_Not_Found  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqiwtw/d_machine_learning_feature_versus_mobileweb/</guid>
      <pubDate>Fri, 29 Mar 2024 07:02:48 GMT</pubDate>
    </item>
    <item>
      <title>机器学习项目评估问题 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqis5o/ml_project_evaluation_questions_d/</link>
      <description><![CDATA[大家好， 我想知道如果您第一次审查一个项目，您会问什么类型的问题时间。作为背景，我们正在向一些人教授机器学习咨询。我会在帖子发布几天后列出我的问题，因为我不想偏见任何人。你想要多少就给多少。谢谢！   由   提交 /u/MuscleML   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqis5o/ml_project_evaluation_questions_d/</guid>
      <pubDate>Fri, 29 Mar 2024 06:54:23 GMT</pubDate>
    </item>
    <item>
      <title>[D]变形金刚还有其他重要的用例吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqhyuo/dare_there_any_other_non_trivial_use_cases_of/</link>
      <description><![CDATA[Seq2Seq 预测架构是为序列预测而设计的，并且在文本生成中自然是 SOTA，但是还有其他我们可以使用它们的重要任务吗？就像 MeshGPT 使用 gpt 模型来生成网格一样，扩散变压器现在也在研究中，事实上 sora 使用了一种模型。在许多其他应用程序中，这些模型可能是高效且可扩展的吗？   由   提交/u/ApartmentEither4838  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqhyuo/dare_there_any_other_non_trivial_use_cases_of/</guid>
      <pubDate>Fri, 29 Mar 2024 06:00:20 GMT</pubDate>
    </item>
    <item>
      <title>人们会对聚合此处发布的论文的不和谐服务器/博客感兴趣吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqhji1/would_people_be_interested_in_a_discord/</link>
      <description><![CDATA[嗨，很多海报发布了他们发现有趣的研究工作和论文，很难跟踪。我给有趣的论文添加了书签，结果却忘记了它们。  想知道这里的人是否值得做一个不和谐服务器（每天更新）或一个媒体博客（每周更新）来跟踪在此子上发布的论文。   由   提交 /u/shadowylurking   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqhji1/would_people_be_interested_in_a_discord/</guid>
      <pubDate>Fri, 29 Mar 2024 05:32:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你会如何回答这个面试问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqftlw/d_how_would_you_answer_this_interview_question/</link>
      <description><![CDATA[不确定这是否是一个“职业问题”，但最近有人问我这个面试问题： 在一场有 10 辆赛车的 F1 赛车比赛，您如何计算/预测第二名赛车超过第一名赛车的概率？这个计算需要什么算法、数据和模型？解释每个步骤。 你会如何回答这个问题？ （没有给出其他信息）   由   提交/u/Conscious_Giraffe453  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqftlw/d_how_would_you_answer_this_interview_question/</guid>
      <pubDate>Fri, 29 Mar 2024 03:56:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] Jamba：首款基于 Mamba 的生产级模型，提供一流的质量和性能。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqfibp/p_jamba_the_first_productiongrade_mambabased/</link>
      <description><![CDATA[帖子：https://www.ai21 .com/blog/announcing-jamba  我们很高兴宣布 Jamba，世界上第一个基于 Mamba 的生产级模型。通过使用传统 Transformer 架构的元素增强 Mamba 结构化状态空间模型 (SSM) 技术，Jamba 弥补了纯SSM模型。它提供了 256K 上下文窗口，已经在吞吐量和效率方面展现了显着的进步——这只是这种创新混合架构的开始。值得注意的是，Jamba 在各种基准测试中都优于或匹配同尺寸级别的其他最先进型号。  ​ &lt; !-- SC_ON --&gt;  由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqfibp/p_jamba_the_first_productiongrade_mambabased/</guid>
      <pubDate>Fri, 29 Mar 2024 03:39:56 GMT</pubDate>
    </item>
    <item>
      <title>自适应 RAG：一种降低 top-k 向量索引检索的 LLM 令牌成本的检索技术 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bq3hwb/adaptive_rag_a_retrieval_technique_to_reduce_llm/</link>
      <description><![CDATA[摘要：我们演示了一种技术，该技术允许使用法学硕士的反馈动态调整 top-k 检索器 RAG 提示中的文档数量。这使得 RAG LLM 问答的成本降低了 4 倍，同时保持了相同的准确性水平。我们还表明该方法有助于解释法学硕士输出的血统。参考实现适用于大多数模型（GPT4、许多本地模型、较旧的 GPT-3.5 Turbo），并且可以适应大多数公开 top-k 检索原语的矢量数据库。 博客论文：https://pathway.com/developers/showcases/adaptive-rag 参考实现：&lt; a href=&quot;https://github.com/pathwaycom/pathway/blob/main/python/pathway/xpacks/llm/question_answering.py&quot;&gt;https://github.com/pathwaycom/pathway/blob/main/python /pathway/xpacks/llm/question_answering.py   由   提交 /u/dxtros   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bq3hwb/adaptive_rag_a_retrieval_technique_to_reduce_llm/</guid>
      <pubDate>Thu, 28 Mar 2024 18:55:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 斯坦福大学的 BioMedLM 论文报告的准确性与评估的准确性：没有意义</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bq1deb/d_stanfords_biomedlm_paper_reported_accuracy_vs/</link>
      <description><![CDATA[      斯坦福大学发布#BioMedLM，一种基于生物医学数据训练的 2.7B 参数语言模型。然而，结果似乎没有意义。 这里是在 MultiMedQA（MedMCQA、MedQA、MMLU、PubMed）上使用 LM Evaluation Harness 框架的评估报告。  https://preview.redd .it/vd21crtn14rc1.png?width=1442&amp;format=png&amp;auto=webp&amp;s=ee905e8277006e40c37b7e5b87003165bd0de4b5 https://preview.redd.it/6ot7mibo14rc1.png?width=1164&amp;format=png&amp;auto=webp&amp;s=5d76fcce909fb07d 5404e148b0cdc2fbc6dae43c ​   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bq1deb/d_stanfords_biomedlm_paper_reported_accuracy_vs/</guid>
      <pubDate>Thu, 28 Mar 2024 17:32:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年构建大型语言模型的小指南 – 75 分钟讲座</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bpzrm0/d_a_little_guide_to_building_large_language/</link>
      <description><![CDATA[我终于录制了两周前的讲座，因为人们一直向我索要视频。 所以在这里，我希望您会喜欢“2024 年构建大型语言模型的小指南”。 我试图使其简短而全面 - 重点关注对于培训优秀 LLM 至关重要但通常隐藏的概念在技​​术报告中。 在讲座中，我向学生介绍了培训良好绩效法学硕士的所有重要概念/工具/技术：- 查找、准备和评估网络规模数据- 理解模型并行性和高效培训- 微调/对齐模型 - 快速推理 当然有很多东西和细节缺失，我应该添加进去，不要犹豫告诉我你是最令人沮丧的遗漏，我将在以后的部分中添加它。特别是，我认为我将更多地关注如何很好地、广泛地过滤主题，也许还有更多实用的轶事和细节。 既然我记录了它，我一直在想这可能是一个主题的第 1 部分。由两部分组成的系列，其中包含第二个完整的实践视频，介绍如何使用我们最近在 HF 围绕 LLM 培训发布的一些库和配方来运行所有这些步骤（并且无论如何都可以轻松适应您的其他框架）：  用于所有网络规模数据准备的 datatrove：https://github.com/huggingface/datatrove  nanotron 用于轻量级 4D 并行法学硕士培训：https://github.com/huggingface/nanotron lighteval 用于训练中快速并行 LLM 评估：https://github.com/huggingface/lighteval  以下是在 Youtube 上观看讲座的链接：https://www. youtube.com/watch?v=2-SPH9hIKT8这是 Google 幻灯片的链接：https://docs.google.com/presentation/d/1IkzESdOwdmwvPxIELYJi8--K3EZ98_cL6c5ZcLKSyVg/edit#slide=id.p 很高兴听到对此的反馈以及在第二部分中添加、更正、扩展的内容。   由   提交 /u/Thomjazz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bpzrm0/d_a_little_guide_to_building_large_language/</guid>
      <pubDate>Thu, 28 Mar 2024 16:26:57 GMT</pubDate>
    </item>
    <item>
      <title>幻觉的终结（对于那些能负担得起的人）？ [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bpxs1i/the_end_of_hallucination_for_those_who_can_afford/</link>
      <description><![CDATA[      DeepMind 刚刚发表了一篇关于事实检查文本的论文： &lt; a href=&quot;https://preview.redd.it/zsmv0a0293rc1.png?width=1028&amp;format=png&amp;auto=webp&amp;s=789c1c2f9b31aa734a7ebcf459df3ad06bd74285&quot;&gt;https://preview.redd.it/zsmv0a0293rc1.png?width =1028&amp;format=png&amp;auto=webp&amp;s=789c1c2f9b31aa734a7ebcf459df3ad06bd74285 该方法使用 GPT-3.5-Turbo，每个模型响应成本为 0.19 美元，比人类注释者更便宜，同时更比他们准确： https:/ /preview.redd.it/ob7bb3iv73rc1.png?width=1014&amp;format=png&amp;auto=webp&amp;s=e79bbcaa578b29772cb3b43ead508daff7288091 他们使用这种方法创建事实基准并比较一些流行的法学硕士。 论文和代码：https://arxiv.org/abs/2403.18802 编辑：关于帖子的标题：幻觉（在维基百科中）被定义为“由人工智能生成的响应，其中包含以事实形式呈现的虚假或误导性信息。”：您的代码不编译本身并不是一种幻觉。当你声称代码是完美的时，那是一种幻觉。    由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bpxs1i/the_end_of_hallucination_for_those_who_can_afford/</guid>
      <pubDate>Thu, 28 Mar 2024 15:04:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>