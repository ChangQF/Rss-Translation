<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 24 Oct 2024 18:22:08 GMT</lastBuildDate>
    <item>
      <title>机器学习的计算机规格[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gb8ywy/computer_specs_for_machine_learning_d/</link>
      <description><![CDATA[嗨 👋  我有一个问题想问 Mac ML 的朋友们。  我有一台刚买的 M1 MacBook Pro。从那时起，我就着手开发更大的模型（更多参数），这些模型是在更大的数据集上进行训练的。我一直遇到内存问题。  我想知道是否有其他人有使用新款 MacBook Pro 进行机器学习的经验？    提交人    /u/Ok_Tourist5497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gb8ywy/computer_specs_for_machine_learning_d/</guid>
      <pubDate>Thu, 24 Oct 2024 17:59:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用一行代码对 GGUF 模型进行基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gb8yhq/r_benchmark_gguf_model_with_one_line_of_code/</link>
      <description><![CDATA[      大家好！ 👋我们刚刚推出了一个开源工具，只需一行代码即可对 GGUF 模型进行基准测试。 GitHub 链接 动机： GGUF 量化对于在设备上本地运行模型至关重要，但量化会极大地影响模型的性能。量化后测试模型至关重要（基准测试如何发挥作用）。但是我们注意到了几个挑战：  没有简单、快速的方法在本地或自托管服务器上对量化的 GGUF 模型进行基准测试。 现有基准测试 (github.com/terryyz/llm-benchmark) 中的 GGUF 量化评估结果不一致，显示的分数低于模型开发人员的官方结果。\  我们的解决方案： 我们构建了一个工具：  用一行代码对 GGUF 模型进行基准测试。 支持多处理和8 个评估任务。 在我们的测试中，它是可用的 GGUF 模型最快的基准测试。  示例： 在“ifeval”数据集上对 Llama3.2-1B-Instruct Q4_K_M 进行基准测试，以实现一般语言理解。在 4090 上，使用 4 个 worker 进行多处理，耗时 80 分钟。  在终端中输入  nexa eval Llama3.2-1B-Instruct:q4_K_M --tasks ifeval --num_workers 4 https://i.redd.it/6xh52gkttqwd1.gif  结果：  https://preview.redd.it/78aek4a4tqwd1.png?width=1475&amp;format=png&amp;auto=webp&amp;s=742a1379809244010f409a29298709f0575ae772 我们从文本模型开始，并计划扩展到更多设备上的模型和模式。欢迎您提供反馈！如果您发现这有用，请随时在 GitHub 🔗 上留下一颗星：https://github.com/NexaAI/nexa-sdk/tree/main/nexa/eval    提交人    /u/AlanzhuLy   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gb8yhq/r_benchmark_gguf_model_with_one_line_of_code/</guid>
      <pubDate>Thu, 24 Oct 2024 17:58:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 谷歌如何克服医疗 AI 的训练数据问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gb7twh/r_how_google_overcame_training_data_issues_for/</link>
      <description><![CDATA[TLDR；他们将 3D 图像转换为矢量嵌入，节省了预处理时间并减少了训练数据大小。 仅在美国，每年就有超过 7000 万次计算机断层扫描检查，但这些数据对 Google 的训练无效。 Google Research 有用于放射学、数字病理学和皮肤病学的嵌入 API - 但所有这些都仅限于 2D 成像。医生通常依靠 3D 成像进行更复杂的诊断。 为什么？ CT 扫描具有 3D 结构，这意味着文件大小更大，并且需要比 2D 图像更多的数据。 浏览工程博客，他们刚刚发布了一些最终可以处理 3D 医疗数据的东西。它被称为 CT Foundation - 它将 CT 扫描转换为小而信息丰富的嵌入，以廉价的方式训练 AI 如何做到？ 检查以标准医学成像格式 (DICOM) 进行，并转换为具有 1,408 个值的向量 - 捕获的关键细节包括器官、组织和异常。 然后可以使用这些简洁的嵌入来训练 AI 模型，例如逻辑回归或多层感知器，与拍摄 3D 图像并需要预处理的典型模型相比，使用的数据要少得多。最终的分类器更小，从而降低了计算成本，因此训练更高效、更实惠。 最终结果？ CT Foundation 在七项分类任务中评估了数据效率： - 颅内出血 - 胸部和心脏钙化 - 肺癌预测 - 可疑腹部病变 - 肾结石 - 腹主动脉瘤，以及 - 身体部位 尽管训练数据有限，但这些模型在除一项更具挑战性的任务外的所有任务上都实现了超过 0.8 的 AUC，这意味着强大的预测性能和准确性。 该模型使用 1,408 维嵌入，只需要一个 CPU 进行训练，所有这些都在 Colab Python 笔记本中完成。 TLDR; Google Research 推出了一款工具，可有效地在 3D CT 扫描上训练 AI，方法是将它们转换为紧凑1,408 维嵌入可实现高效的模型训练。它被称为 CT Foundation，需要的数据和处理更少，在七个分类任务中实现了超过 0.8 的 AUC，以最少的计算资源展示了强大的预测性能。 有一个 colab 笔记本可用。 PS：通过从事个人项目来跟上技术发展，我学到了这一点 - 如果您想了解更多信息，请查看techtok today    提交人    /u/TechTok_Newsletter   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gb7twh/r_how_google_overcame_training_data_issues_for/</guid>
      <pubDate>Thu, 24 Oct 2024 17:11:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我们最近在 NeurIPS 上被接受的一些论文的论文摘要</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gb74j6/r_paper_summaries_for_some_of_our_papers_that/</link>
      <description><![CDATA[大家好，这是我们小组最近在 NeurIPS 2024 上被接受的论文列表；作为一个全本科生小组，这对我们来说是一个值得骄傲的时刻；所有论文都是在没有任何外部学术支持的情况下发表的；这是我们论文的摘要。我们希望这能激励其他人追求人工智能，并将研究视为我们可以合作的视角，而您所需要的只是正确的指导（甚至不一定是博士或教授）。如果您发现这些论文有用并希望与我们合作，请随时与我们联系！  给我一个提示：LLM 能接受提示来解决数学问题吗？👉 Arxiv 链接  我们建议使用受人类教育学启发的“提示”来提高 LLM 在高级数学问题上的表现。我们还测试了模型对错误提示的鲁棒性。我们使用来自 MATH 数据集的各种问题在各种 LLM 上评估了我们的方法，并将其与一次性、少量和思路链提示进行了比较。  注意力转移：引导 AI 远离不安全内容 👉 Arxiv 链接  本研究探讨了限制生成模型中不安全内容的方法。我们提出了一种新颖的无训练方法，使用注意力重新加权来消除推理过程中的不安全概念。我们的方法与现有技术进行了比较，并在直接和对抗性越狱提示上进行了评估。我们还讨论了潜在的原因、局限性和更广泛的影响。  揭开面纱：对图像隐私和版权保护的概念消融的研究 👉 Arxiv 链接  本文扩展了 Kumari 等人 (2022) 引入的预训练模型中概念消融的研究。我们重现了各种概念消融技术的结果，并提出了一种新颖的变体“商标消融”，以解决模型输出中的品牌元素。我们还分析了模型的局限性、消融泄漏提示下的行为以及不相关概念上的性能下降。   IIT Roorkee 的视觉语言小组为来自 NeurIPS、CVPR、ICCV 和 ICML（2016-2024） 等顶级会议的深度学习论文汇编了一个优秀的全面摘要库。这些摘要细分了计算机视觉、NLP 和机器学习中的关键论文 - 如果您想在不深入研究全文的情况下保持最新状态，这将是完美的选择。    提交人    /u/vlg_iitr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gb74j6/r_paper_summaries_for_some_of_our_papers_that/</guid>
      <pubDate>Thu, 24 Oct 2024 16:42:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找有关人工智能对工作和工作意义的影响的书籍和文章推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gb3kuk/r_looking_for_book_and_article_recommendations_on/</link>
      <description><![CDATA[大家好！ 我正在研究人工智能 (AI) 如何影响工作环境，特别是在工作意义和职业认同方面。我关注的是汽车行业和 IT等行业，在这些行业中，AI 正在迅速融入日常运营。我特别感兴趣的是人工智能如何影响工作自主性、任务结构，以及对员工工作目标感和身份认同感的更广泛影响。 我正在寻找推荐学术书籍、文章或研究论文，以探讨：  人工智能对工作角色、自主性和工作意义的影响。 人工智能如何影响职业认同，以及员工如何看待自己在组织中的角色。 围绕人工智能在工作场所的道德考量，尤其是与员工福祉和公平性相关的考量。 来自工作特征模型或类似框架等理论的见解，可以应用于人工智能对工作设计的影响。 案例研究或实证研究，重点关注人工智能在特定行业的整合（汽车、   我会非常感激任何建议，无论是基础文本还是最近的研究。提前感谢您为我指明正确的方向！    提交人    /u/emillindstrom   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gb3kuk/r_looking_for_book_and_article_recommendations_on/</guid>
      <pubDate>Thu, 24 Oct 2024 14:12:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 基于多代理人工智能的人力资源信息系统[HRIS]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gaylfx/p_multiagent_ai_based_human_resource_information/</link>
      <description><![CDATA[正如标题所示， 我正在研究构建基于 MAS 的 HRIS 的潜在想法，我正在研究其他经验丰富的人士或任何人的建议，关于如何为我的组织将这个想法构建成一个好的产品 什么样的服务或任何引人注目的用例等 我期待着收到所有人的意见    提交人    /u/Not_so_sure_paradox9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gaylfx/p_multiagent_ai_based_human_resource_information/</guid>
      <pubDate>Thu, 24 Oct 2024 09:33:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 的 Whisper“库”/“框架”等的包装器？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gayjwu/d_wrapper_for_openais_whisper_libraryframework_etc/</link>
      <description><![CDATA[自从 OpenAI 的 Whisper 发布以来，我就一直在使用它的命令行版本，但它并没有提供 Whisper-&quot;框架&quot;（或无论您怎么称呼它）包含的所有选项。一定有人为此编写了一个&quot;包装器&quot;，不是吗？但我在 Google 上找不到任何东西。您能推荐一些吗？ 我有 20 000 个文件，从 10 秒到几个小时不等，我希望尽可能高效、高质量地转录它们（我优先考虑质量而不是效率。目前，我使用带有大型 v3 模型的命令行客户端）。    提交人    /u/la-grave   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gayjwu/d_wrapper_for_openais_whisper_libraryframework_etc/</guid>
      <pubDate>Thu, 24 Oct 2024 09:30:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 将其他输入特征连接到 ViT 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gayiww/r_concatenating_additional_input_features_to_a/</link>
      <description><![CDATA[大家好， 我正在探索将其他输入功能（例如表格数据或其他非图像功能）与图像输入一起集成到 Vision Transformer (ViT) 架构中的方法。 有人尝试过这种方法吗？或者有人知道任何研究论文、博客或参考文献探讨过这个问题吗？我特别感兴趣的是如何以有意义的方式将这些额外的输入与图像标记集成在一起。 在此先感谢任何帮助或指点！    提交人    /u/kernel_KP   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gayiww/r_concatenating_additional_input_features_to_a/</guid>
      <pubDate>Thu, 24 Oct 2024 09:28:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 表格域中的解缠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gay549/r_disentanglement_in_tabular_domain/</link>
      <description><![CDATA[这里有人研究过表格数据中的解缠吗？这可能吗？或者这有意义吗？在没有可量化的基本事实因素的表格数据中，解缠的标准/评估指标是什么？ 背景：我被委托研究这个主题，发现解缠在图像等领域很常见，大多使用 VAE。有一些研究将 VAE 应用于表格数据，特别是为了公平或合成数据生成的目的，但他们并不称之为“解缠”，也没有给出与表格数据解缠相关的任何评估。    提交人    /u/QT-NTU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gay549/r_disentanglement_in_tabular_domain/</guid>
      <pubDate>Thu, 24 Oct 2024 08:59:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 是 CNN 的一种</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gaxscv/d_transformers_are_a_type_of_cnn/</link>
      <description><![CDATA[https://arxiv.org/abs/2309.10713 我随机在谷歌上搜索动态卷积，因为我觉得它们很酷，然后发现了这篇论文，它表明 transformer 相当于一种使用动态卷积的 CNN。动态卷积论文 (https://arxiv.org/abs/1912.03458) 于 2019 年发布，所以它确实在注意力就是你需要的所有论文之后发布。 遗憾的是这篇论文只有一个引用。我认为这太不可思议了。知道 transformers 可以被视为 CNN 让他们能够深入了解优化其设计，包括删除 softmax 激活并将其替换为 Relu+normalisation 层。我认为通过继续他们的工作可以做出更多的改进。    提交人    /u/Ozqo   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gaxscv/d_transformers_are_a_type_of_cnn/</guid>
      <pubDate>Thu, 24 Oct 2024 08:31:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] KAN 论文以一种有趣的方式将无监督问题转变为监督问题（允许某些样本存在差异）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gau1kt/r_the_kan_paper_has_this_interesting_way_to_turn/</link>
      <description><![CDATA[在 KAN 论文中，他们有一种有趣的方法来推断变量之间的映射，即允许部分数据样本的变量创建正样本和负样本。一种对比学习的形式。他们没有引用这种方法，是否有更多公式化的方法可以进行这种分析，以无监督的方式研究变量之间的关系。 第 4.2 节 - https://arxiv.org/abs/2404.19756    提交人    /u/Sandy_dude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gau1kt/r_the_kan_paper_has_this_interesting_way_to_turn/</guid>
      <pubDate>Thu, 24 Oct 2024 04:07:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 新款 Claude Sonnet 3.5 如何提供精确的坐标？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gasb94/d_how_could_the_new_claude_sonnet_35_provide/</link>
      <description><![CDATA[不确定以前是否有人问过这个问题，但最近发布的 Claude Sonnet 让我很惊讶。几个月前，我尝试了许多 LLM 来为我提供屏幕截图上的 (x, y) 坐标，使用各种方法，如网格位置、标记坐标等，但精度不够。但是；这个新模型实际上可以提供非常精确的坐标。有人知道/我们能猜出他们为这样的事情使用的系统吗？他们可以使用其他模型，如 SeeClick 吗？    提交人    /u/super_deap   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gasb94/d_how_could_the_new_claude_sonnet_35_provide/</guid>
      <pubDate>Thu, 24 Oct 2024 02:31:44 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 世界上第一个自主 AI 发现的 0day 漏洞</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ga8wxn/project_worlds_first_autonomous_aidiscovered_0day/</link>
      <description><![CDATA[我确信很多人都通过将代码片段粘贴到 ChatGPT 中发现了 0-day 漏洞。问题一直是扫描整个项目的 0-day。一些论文表明，通过向其代理提供已知的易受攻击的代码，这是可能的，但据我所知，这些论文都没有获得任何 CVE 或发现真正的 0-day。Vulnhuntr 本周末发布，在 10k+ GitHub 星的开源项目中发现了十几个 0-day： https://github.com/protectai/vulnhuntr    提交人    /u/FlyingTriangle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ga8wxn/project_worlds_first_autonomous_aidiscovered_0day/</guid>
      <pubDate>Wed, 23 Oct 2024 12:07:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</guid>
      <pubDate>Sun, 20 Oct 2024 15:00:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>