<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 31 Dec 2024 09:16:43 GMT</lastBuildDate>
    <item>
      <title>[R] 需要的建议：构建用于药品认证的单类图像分类器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqage2/r_advice_needed_building_a_oneclass_image/</link>
      <description><![CDATA[大家好， 我正在开展一个项目，开发一个单类图像分类器，用于验证药丸的真实性，以帮助打击假冒产品。我有一个包含大约 300 张独特高分辨率药丸图像的数据集。我主要关心的是尽量减少误报——我需要确保模型不会将假药归类为真药。 我正在考虑几种方法，希望得到建议，特别是关于：1. 模型选择：• 我应该采用基于卷积神经网络 (CNN) 的方法还是使用自动编码器来学习真实的药丸图像分布？• 特征脸 (或特征图像) 等方法对于此类问题的可行性如何？2. 数据准备和增强：• 我正在考虑对药丸图像进行 Photoshop 处理以创建合成的假药示例。有人试过这个吗？如果试过，效果如何？ • 在这种情况下，哪些数据增强技术可能特别有用？ 3. 测试和评估： • 评估一类分类器的任何最佳实践，尤其是注重减少误报？ 4. 库和框架： • 是否有特定的库或框架在图像数据的一类分类或异常检测方面表现出色？ 我愿意接受您在解决类似任务时发现有用的其他建议、提示和技巧。这个领域的风险很高，因为误报可能会危及患者安全。 提前感谢您的指导 🙂    提交人    /u/Haunting_Tree4933   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqage2/r_advice_needed_building_a_oneclass_image/</guid>
      <pubDate>Tue, 31 Dec 2024 08:26:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用整流流和 FLUX 架构的新型 SOTA 文本转音频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq9hx1/d_new_sota_text_to_audio_model_using_rectified/</link>
      <description><![CDATA[发布采用整流流匹配和偏好优化训练的全新 TTA 模型！完全开源。在 GPU 上推理大约需要 3 秒。    提交人    /u/Internal_War3919   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq9hx1/d_new_sota_text_to_audio_model_using_rectified/</guid>
      <pubDate>Tue, 31 Dec 2024 07:17:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 生物医学编码器模型的当前 SOTA 是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq3zwq/d_whats_the_current_sota_for_biomedical_encoder/</link>
      <description><![CDATA[您认为用于创建向量嵌入的生物医学模型的当前 SOTA 是什么？我最感兴趣的是句子相似性（以及一些文档检索）。 我个人认为 PubMedBERT 和 BioBERT 是一个非常好的基线，但有没有您更信任的微调？ 您甚至认为这个领域的一个好基准是什么？我发现 MTEB 太笼统，而 BioASQ、BIOSSES、MedSTS 太具体，无法衡量任何有意义的东西。你们觉得呢？    提交人    /u/ayushwashere   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq3zwq/d_whats_the_current_sota_for_biomedical_encoder/</guid>
      <pubDate>Tue, 31 Dec 2024 02:03:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用了哪些流行的半监督预训练方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq31l5/r_what_popular_semisupervised_pretraining_methods/</link>
      <description><![CDATA[我正在研究半监督预训练方法，我发现最好的方法是： - SimCLRv2（它们从 ImageNet 预训练权重开始，然后进行监督微调，然后进行无标记蒸馏） - 自调整（在微调期间使用对比损失） - Xu 等。 al 2022（通过包含额外的预训练步骤来改进微调，对 FixMatch 等半监督方法使用更好的初始化）。 只是想知道是否还有其他我错过的流行方法？    提交人    /u/NPCNo10   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq31l5/r_what_popular_semisupervised_pretraining_methods/</guid>
      <pubDate>Tue, 31 Dec 2024 01:15:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对于 LightGBM 中约 1GB 的财务数据集，GPU 训练/回测比 CPU 训练/回测慢 2 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpuerz/r_gpu_trainingbacktesting_is_2x_slower_than_cpu/</link>
      <description><![CDATA[ LightGBM 中的 tldr： device_type=gpu 大约需要 250 秒才能运行 46 次训练 + 回测（慢 2 倍） device_type=cpu 大约需要 130 秒才能运行 46 次训练 + 回测 device_type=cuda 无法测试，因为 Windows 不支持，但欢迎有类似经验的 linux-gpu 用户在训练小数据集时发表评论  运行自动交易机器人近 4 年，并在过去 2 年开始使用 LightGBM 测试平台： 3 年旧的 Windows 联想军团 amd64（8 核）笔记本电脑 移动 rtx3060 gpu 通过 c-api 在 LightGBM v4.5.0 中训练  尝试使用 device_type=gpu 与 device_type=cpu 遗憾的是无法测试 device_type=cuda，因为 Windows 不支持：(   数据集： ~1gb 财务数据，跨越 5 年 30 个特征  训练/回测性能显示 LightGBM gpu 模式比 cpu 模式运行慢 2 倍： num_iteration=250, learning_rate=0.1000 每次设置运行都会在 LightGBM 中重复训练过程约 46 次  1 次训练过程用于今天的数据（用于实时交易的生产） 45 次训练过程用于回测过去 45 个交易日  device_type=gpu 大约需要 250 秒才能运行 46 次训练+回测（慢 2 倍） device_type=cpu 大约需要 130 秒才能运行 46 次训练+回测 device_type=cuda ??? （无法在 Windows 中测试）   杂项  生产 tradebot 使用云端的 apple-silicon 运行（但没有 gpu 硬件） apple-silicon 比云端的 linux-x64 更快  使用 apple-silicon 在云端进行~120 秒训练+回测 使用 linux-x64 在云端进行~150 秒训练+回测      提交人    /u/kaizhu256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpuerz/r_gpu_trainingbacktesting_is_2x_slower_than_cpu/</guid>
      <pubDate>Mon, 30 Dec 2024 18:53:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 结合两个不同平台用户偏好的推荐系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpuc6x/d_recommendation_system_that_combines_users/</link>
      <description><![CDATA[大家好，我目前正在开发一个音乐推荐系统项目，该项目包含两个不同的用户互动和偏好来源。一个来源包含不同专辑和曲目的不同用户评论和评分，另一个来源包含用户的音乐收听行为。这两个数据源完全独立于另一个。另一种表达问题的方式是根据用户评论和评分 + 单独的收听历史来推荐歌曲/专辑。关于如何结合这两个来源的任何想法或相关作品的任何参考资料？提前谢谢！    提交人    /u/cacwj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpuc6x/d_recommendation_system_that_combines_users/</guid>
      <pubDate>Mon, 30 Dec 2024 18:50:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 介绍 LongTalk-CoT v0.1：用于推理模型后训练的超长思维链数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpp8ph/p_introducing_longtalkcot_v01_a_very_long/</link>
      <description><![CDATA[我很高兴发布LongTalk-CoT v0.1，这是一个专为后期训练 o1 类推理模型设计的数据集。每个响应都使用 QwQ-32B-Preview 提示，特别是手工制作的系统消息，鼓励更多发声思考和自我反思。  训练后数据集包含97M 个标记（使用 meta-llama/Llama-3.1-8B-Instruct 标记器）。 输出标记长度比 HuggingFaceTB/smoltalk 🤔💭长 5.29 倍 提升ProcessBench中的性能可用于 SFT 和 RL /偏好优化 微调模型能够解决 9.11 是否大于 9.9 以及草莓单词中有多少个字母 R！     由    /u/transformer_ML 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpp8ph/p_introducing_longtalkcot_v01_a_very_long/</guid>
      <pubDate>Mon, 30 Dec 2024 15:11:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 叙述数据（故事）可以存储为知识图谱吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpiu23/d_can_narrative_data_stories_be_stored_as/</link>
      <description><![CDATA[这是在将故事存储为 RAG 问答的 KG 的背景下。 KG 在存储本体/关系数据和查询事实数据方面非常出色。但如何在不丢失大量信息的情况下将叙述数据存储在知识图谱中？首先，故事中有一个时间维度，关系会随着故事的发展而改变（一个人可能在第 1 章停留在位置 A，而在第 2 章移动到位置 B）。 这个https://www.youtube.com/watch?v=g6xBklAIrsA有一些想法，但并没有真正涉及问题。    提交人    /u/noellarkin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpiu23/d_can_narrative_data_stories_be_stored_as/</guid>
      <pubDate>Mon, 30 Dec 2024 08:32:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 为什么 MAMBA 没有流行起来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpg91o/d_why_mamba_did_not_catch_on/</link>
      <description><![CDATA[从所有的炒作来看，MAMBA 似乎将取代 transformer。它速度很快，但仍保持了 transformer 的性能。训练期间为 O(N)，推理期间为 O(1)，并且准确率相当高。那么为什么它没有占据主导地位呢？状态空间模型的状态是什么？    提交人    /u/TwoSunnySideUp   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpg91o/d_why_mamba_did_not_catch_on/</guid>
      <pubDate>Mon, 30 Dec 2024 05:39:42 GMT</pubDate>
    </item>
    <item>
      <title>[R]几何直觉为什么 L1 将系数驱动为零</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp7us9/rgeometric_intuition_why_l1_drives_the/</link>
      <description><![CDATA[  由    /u/madiyar  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp7us9/rgeometric_intuition_why_l1_drives_the/</guid>
      <pubDate>Sun, 29 Dec 2024 22:34:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于在单个 H100 GPU 上 100 个 epoch 内实现 Imagnet 上 >=80% 准确率的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp4hph/d_advice_on_achieving_80_accuracy_on_imagnet_in/</link>
      <description><![CDATA[大家好！ 我目前正在尝试在单个 H100 GPU 上从头开始训练 ImageNet1K 上的 EfficientNetV2-medium 模型。由于 GPU 在我的实验室同事之间共享，因此每个 epoch 的训练时间非常慢。因此，我将训练 epoch 的数量限制为 100。鉴于这些限制，我想听听您的建议，关于如何才能获得超过 80% 的 top1 分数？ 根据我目前的配置，我可以达到 78%。以下是我的训练细节： 批次大小：256 学习率：0.1 优化器：动量为 0.9 的 SGD 权重衰减：2x10-5 学习率调度程序：余弦增强：TrivialAugmentWide、RandomCrop(8) 混合精度训练 (bf16) 深度学习库：Pytorch Lightning 我还应用了动态调整大小，其中我的训练和测试图像从 128x128 的大小开始，每 20 个 epoch 增加 24 个像素，直到第 80 个 epoch，图像大小固定为 224x224。 如果您能提供任何关于如何提高我的分数的见解，以及是否有可能进一步减少训练时间，我将不胜感激。 谢谢！    由    /u/atif_hassan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp4hph/d_advice_on_achieving_80_accuracy_on_imagnet_in/</guid>
      <pubDate>Sun, 29 Dec 2024 20:05:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了 Termite，一个可以通过简单的文本提示生成终端 UI 的 CLI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyzao/p_i_made_termite_a_cli_that_can_generate_terminal/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyzao/p_i_made_termite_a_cli_that_can_generate_terminal/</guid>
      <pubDate>Sun, 29 Dec 2024 16:02:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</guid>
      <pubDate>Sun, 29 Dec 2024 16:00:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 ARIMA/SARIMA 进行风速预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hou9cq/p_wind_speed_prediction_with_arimasarima/</link>
      <description><![CDATA[      我正在做一个风速预测的项目。有些文章说使用 ARIMA / SARIMA 会是一个好的开始。 我确实开始使用 ARIMA，并且预测值没有任何变化。 当我尝试使用 SARIMA，季节性 = 12（一年中的月份），预测 36 个月（3 年）时，它给了我不满意的结果，这些结果看起来每年都一样（周期性的，因此远离现实）所以我放弃了 SARIMA。 请随时给我解决方案或更好的方法。    提交人    /u/Associate-Existing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hou9cq/p_wind_speed_prediction_with_arimasarima/</guid>
      <pubDate>Sun, 29 Dec 2024 11:33:42 GMT</pubDate>
    </item>
    </channel>
</rss>