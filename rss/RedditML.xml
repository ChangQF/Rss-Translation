<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 24 May 2024 18:18:31 GMT</lastBuildDate>
    <item>
      <title>[P] 视频和文本转多格式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czqk9b/p_video_and_text_to_multi_format/</link>
      <description><![CDATA[我正在寻找开发某种东西，涉及将视频和文本内容转换为各种格式，包括文本、视觉元素和动画。实现这一目标的最佳途径是什么，模型、框架、工具等。    提交人    /u/SamyG82   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czqk9b/p_video_and_text_to_multi_format/</guid>
      <pubDate>Fri, 24 May 2024 17:40:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您使用什么评估工具/方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czpwfl/d_what_evaluation_toolsmethods_do_you_use/</link>
      <description><![CDATA[想要了解人们最喜欢和使用哪些评估工具/方法？似乎有很多工具，例如 RAGAS、Promptfoo、Promptflow、Trulens、Wanddb 或其他工具？   由   提交 /u/cryptokaykay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czpwfl/d_what_evaluation_toolsmethods_do_you_use/</guid>
      <pubDate>Fri, 24 May 2024 17:12:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用表情符号重新创建图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czm3bw/p_recreate_images_with_emojis/</link>
      <description><![CDATA[演示： https: //replicate.com/johnsutor/emoji-painter  我创建了一个 DNN，它可以通过将表情符号连续粘贴到“画布”上来重新创建目标图像。该代码很大程度上受到 Paint Transformer 的启发，它将笔触顺序粘贴到画布上以重新创建照片。在该论文/代码库中，他们使用单一画笔类型，而我认为表情符号是要从中采样的不同画笔。 Gumbel softmax 用于从 N 个不同的表情符号中选择一个粘贴到画布上，并选择相应的比例、旋转以及中心 x 和 y 坐标。  我也计划在其他形状上训练模型（我愿意接受任何考虑和反馈！）   由   提交/u/JSutie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czm3bw/p_recreate_images_with_emojis/</guid>
      <pubDate>Fri, 24 May 2024 14:29:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 最先进的、开源的、不太耗费资源的计算机视觉模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czlgss/p_stateoftheart_open_source_computer_vision/</link>
      <description><![CDATA[哪些前沿 CV 模型（对象检测、分割等）可以安装在相对中端的 GPU 上，例如 A4000 左右。我对硬件推理特别感兴趣，训练不太重要。 比 ResNet 或 YOLO 更有趣、更高效的东西，不一定是 CNN！ 提前谢谢，只要告诉我你的想法就行    提交人    /u/GWP-NU   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czlgss/p_stateoftheart_open_source_computer_vision/</guid>
      <pubDate>Fri, 24 May 2024 14:01:51 GMT</pubDate>
    </item>
    <item>
      <title>GPT NEO X 法学硕士 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czk2sg/gpt_neo_x_llm_p/</link>
      <description><![CDATA[我正在尝试从 GPT NEO X 执行推理，但出现了错误 logits[:, -1].view(batch_size, -1).contiguous() TypeError: 元组索引必须是整数或切片，而不是元组 ​ 有人能告诉我该如何解决这个问题吗？ 更多信息可以在这里 ​ 谢谢    提交人    /u/thatsadsid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czk2sg/gpt_neo_x_llm_p/</guid>
      <pubDate>Fri, 24 May 2024 12:56:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 陷入选择适当数量的簇的困境。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czjlyt/d_stuck_in_selecting_appropriate_number_of/</link>
      <description><![CDATA[      我正在处理一个有 19 列和 36000 行的数据集...我是要求对其进行聚类。所以我正在尝试 KMeans。当对这个问题执行肘法时，我得到下图。簇的数量从 1 到 249。任何人都可以建议我应该选择 k 的值吗？对于这样的数据集，我还可以尝试其他算法吗？ https://preview.redd.it/ftefa83x3e2d1.png?width=1355&amp;format=png&amp;auto=webp&amp;s=2cee33788041b0bb7e3eb142654241e0 44da8188 https://preview.redd.it/4xa7ttbz3e2d1.png?width= 1389&amp;format=png&amp;auto=webp&amp;s=80b3bf546dc00ddd3f2ba11a00639da2cb813d85   由   提交 /u/SmallSoup7223   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czjlyt/d_stuck_in_selecting_appropriate_number_of/</guid>
      <pubDate>Fri, 24 May 2024 12:31:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检测相同形状但不同颜色的物体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czdmty/d_detecting_objects_of_same_shape_but_different/</link>
      <description><![CDATA[     &lt; /td&gt; 我正在努力检测具有相同形状但不同颜色且没有其他区别特征的对象。当存在可区分的模式时，YOLO 等基于 CNN 的架构会产生奇迹并实现高精度。但是，我需要一种可以纯粹根据颜色准确分类对象的方法。 我当前的挑战是，当我尝试在 RGB 空间中按颜色对这些对象进行分割时，这些对象是不可分离的。有谁有可以在按颜色确定对象类别方面实现良好准确度的建议或方法吗？ 我在下面提供了一张图片以供参考。任何帮助将不胜感激！  https://preview.redd.it/83c6e7dbbb2d1.png?width=793&amp;format=png&amp;auto=webp&amp;s=532c7cffcbaea96eb48d374e073bd49d5f029212  &amp; #32；由   提交/u/ThickDoctor007  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czdmty/d_detecting_objects_of_same_shape_but_different/</guid>
      <pubDate>Fri, 24 May 2024 05:44:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] 学习二值化 CLIP (&SigLIP) 以进行多模态检索和排序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz5zx1/p_learn_to_binarize_clip_siglip_for_multimodal/</link>
      <description><![CDATA[学习使用 CLIP 进行二值化和排名，以将文本或多模式搜索和推荐的存储空间减少 32 倍。 文章：https://www.marqo.ai/blog/learn-to- binarize-clip-for-multimodal-retrieval-and-ranking  CLIP 排名调整期间的二进制嵌入保留了 87-93% 的 fp32 嵌入。 使用 4 倍缩放温度的 sigmoid 进行伪量化（几乎）普遍优于 tanh（参见下一点）。 0/1 (sigmoid) 上的余弦相似度优于 -1, 1 (tanh) - 很确定这是因为余弦具有更好的简并性（D vs DxN），因为它会惩罚不在同一超球体上的嵌入（它也会偏向于较少的非零元素）。 使用 L1 来训练期间的近似汉明距离，略优于余弦（对于 0/1）。 使用 GS-10M 进行评估 使用精确 KNN 进行多模态检索。 在添加辅助二进制损失时，Fp32 嵌入保留完全保真度。 跨域内、新查询、新文档和零进行评估-镜头设置。 可以与俄罗斯套娃，如果确实有必要，但保真度确实会受到影响（未显示）。    由   提交/u/Jesse_marqo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz5zx1/p_learn_to_binarize_clip_siglip_for_multimodal/</guid>
      <pubDate>Thu, 23 May 2024 22:46:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 ML 中处理 GPL 许可？示例：商业物体检测应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz57uj/d_how_to_handle_gpl_licensing_in_ml_example/</link>
      <description><![CDATA[机器学习人员大家好， 我正在开发一个涉及对象检测模型的商业应用程序。我正在考虑将 YOLOv7 与我自己的训练数据一起使用，但我担心许可问题。 YOLOv7 已获得 GNU GPL 3.0 许可，如果将 YOLOv7 集成到其中，这将要求我将整个应用程序的源代码开源。 我很好奇其他人如何处理这种情况。具体来说：  开发人员是否经常诉诸于使用不同的、较旧的模型，这些模型对商业应用程序有更宽松的许可？ 是否有任何替代方法，例如从使用 YOLOv7 存储库（以便它不是存储库的衍生品）从头开始，并构建我自己的不使用 YOLOv7 代码库进行推理的推理管道？例如使用 ONNX。  我非常感谢任何见解或经验。 谢谢！   由   提交 /u/sushi_roll_svk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz57uj/d_how_to_handle_gpl_licensing_in_ml_example/</guid>
      <pubDate>Thu, 23 May 2024 22:10:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] SSAMBA 简介：自我监督的音频曼巴！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz1yoa/r_introducing_ssamba_the_selfsupervised_audio/</link>
      <description><![CDATA[嘿 Reddit， 厌倦了变形金刚？你真的需要关注吗？认识 SSAMBA（自我监督音频曼巴）！ 🐍✨  这个无需注意、纯粹基于状态空间模型 (SSM) 的自我监督奇迹不只是嘶嘶声，而是咆哮声！在说话人识别、关键字识别和音频分类等任务上，SSAMBA 比基于 Transformer 的同类产品 (SSAST) 实现了更好或相似的性能。但更重要的是：它的 GPU 内存效率更高，推理速度更快，尤其是在音频长度较长的情况下。好奇吗？请在此处查看完整论文：arXiv 上的 SSAMBA  感谢您的收听！    由   提交 /u/attentionisallyounee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz1yoa/r_introducing_ssamba_the_selfsupervised_audio/</guid>
      <pubDate>Thu, 23 May 2024 19:53:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Paperswithcode相关？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz1t4x/d_paperswithcode_relevant/</link>
      <description><![CDATA[对我来说，paperswithcode 与跟踪 ML 进展的相关性降低了。 但这很难说，在我的领域（表格 ML/DL）没有太多既定的学术基准（还不需要像带有代码的论文之类的东西） 在 NLP 和基础模型空间中，hf 空间中的排行榜已成为一种现象（主要是在 NLP 中） ）。 总体而言，paperswithcode 感觉维护较少且不太有用。 您经常使用paperswithcode 吗？你用它来做什么？它在您的什么领域有用？   由   提交/u/_puhsu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz1t4x/d_paperswithcode_relevant/</guid>
      <pubDate>Thu, 23 May 2024 19:46:48 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 如果你可以选择 3 篇关于视频/图像生成模型的论文，你会选择哪一篇？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cyy7v9/dr_if_you_could_pick_3_papers_about_videoimage/</link>
      <description><![CDATA[我正在攻读硕士学位，并且我选择做一个视频生成项目。我读过一些关于图像和视频合成的论文：  VQGAN Stable Diffusion Imagen  我还挑选了 3 篇视频生成论文：  Video-LDM Stable Video Diffusion Fine-tuned for Multi-View Generation (SVD-MV) &lt; li&gt;Text2Video-Zero  我还阅读了一些调查论文，这些是我选择谈论的模型。 我正在努力解决的是为了选择逻辑上有序的论文，所以首先我解释一下 3 个图像生成论文，视频生成论文应该遵循图像合成论文中提到的相同策略。 我可以请你建议不同的一组论文要写什么？我仍然可以将所有论文更改为其他内容。 大多数是最近的内容（2020-2024 年很好）并且具有一些重大影响。我知道例如 VQGAN 是流行的基础模型，论文中使用的技术和策略今天仍然相关。 Imagen（由 Google 提供）但是不是开源的，我更喜欢具有开源代码的论文。这就是我避免 OpenAI 论文的原因。 我还读到，在视频生成中选择扩散而不是 GAN，因为它在质量和训练方面都有更好的结果。然而，扩散的计算成本更高。 例如，Video-LDM 基于稳定扩散，因此对我来说，这是值得讨论的好论文。 &lt;!-- SC_ON - -&gt;  由   提交 /u/ShlomiRex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cyy7v9/dr_if_you_could_pick_3_papers_about_videoimage/</guid>
      <pubDate>Thu, 23 May 2024 17:18:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 变分推理：反向 KL 与正向 KL</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cyubdt/r_variational_inference_reverse_kl_vs_forward_kl/</link>
      <description><![CDATA[大家好， 我正在研究变分推理方法，主要是在 BNN 的背景下。使用反向（独占）KL 作为变分目标是常见的方法，尽管最近我偶然发现了一些使用前向（包含）KL 作为目标的有趣作品，例如 [1][2][3]。此外，在 GP 的 VI 背景下，两种散度度量均已使用，请参阅 [4]。 虽然我熟悉反向 KL 目标之间众所周知的差异，但它是“模式-”寻求”而正向 KL 是“模式覆盖”，我看到其中一些作品对这些 VI 目标的下游差异提出了主张，例如（此处解释）“反向 KL 低估了预测方差” [4]和“前向 KL 对于受益于保守不确定性量化的应用很有用” [3]. 我有兴趣在 VI 的背景下理解这些下游差异，但还没有找到任何从理论上而不是从经验上解释这些主张的著作。任何人都可以为我指出正确的方向或尝试解释这一点？ 干杯 [1] Naesseth、Christian、Fredrik Lindsten 和 David Blei。 “马尔可夫分数攀爬：KL (p|| q) 的变分推理。” 神经信息处理系统的进展 33 (2020): 15499-15510。 [2] Zhang, L., Blei, D. M., &amp;奈塞斯，C.A.（2022）。传输分数攀登：使用前向 KL 和自适应神经传输进行变分推理。 arXiv 预印本 arXiv:2202.01841。 [3] McNamara, D., Loper, J., &amp; Regier, J.（2024 年 4 月）。用于摊余变分推理中的包容性 KL 最小化的顺序蒙特卡罗。 人工智能与统计国际会议（第 4312-4320 页）。 PMLR。 [4] Bauer, M.、Van der Wilk, M.、&amp;拉斯穆森，C.E.（2016）。了解概率稀疏高斯过程近似。 神经信息处理系统的进展，29。   由   提交/u/DriftingClient  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cyubdt/r_variational_inference_reverse_kl_vs_forward_kl/</guid>
      <pubDate>Thu, 23 May 2024 14:36:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] Phi-3 模型并排比较。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cytxb5/d_phi3_models_compared_sidebyside/</link>
      <description><![CDATA[      https://preview.redd.it/8l04pnfhq62d1.png?width=661&amp;format=png&amp;auto=webp&amp;s=7fe616ca8cd7da97407 0c86b6b47ffab3ab545e5   https://preview.redd.it/hr7fr1uiq62d1.png?width=688&amp;format=png&amp;auto=webp&amp;s=bd3de359bfe4c1ed82d092be92ae38c246bdfda2    https://preview.redd.it/v6k3v39kq62d1.png？ width=450&amp;format=png&amp;auto=webp&amp;s=c0abb0e397a498ef7ccfb35b1b1cb598198f66ad 对于任何想要在一个地方比较 Phi-3 基准的人。 有趣的比较：ANLI、Hellaswag、MedQA、TriviaQA、语言理解、事实知识和稳健性。 注意：Phi-3 迷你模型表的标签顺序不同。   由   提交/u/dark_surfer  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cytxb5/d_phi3_models_compared_sidebyside/</guid>
      <pubDate>Thu, 23 May 2024 14:19:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>