<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sun, 31 Mar 2024 21:10:51 GMT</lastBuildDate>
    <item>
      <title>[D]有人用bluesky或mastodon吗？我应该关注哪些知名的 ML 人士？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bskvlh/d_anyone_using_bluesky_or_mastodon_who_are_some/</link>
      <description><![CDATA[有点想摆脱 twitter   由   提交 /u/hempock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bskvlh/d_anyone_using_bluesky_or_mastodon_who_are_some/</guid>
      <pubDate>Sun, 31 Mar 2024 21:03:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在没有模型答案的情况下，算法如何对答案进行评分？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsgeo9/d_how_is_the_algorithm_scoring_an_answer_without/</link>
      <description><![CDATA[以下研究是一个示例“半开放式问题的自动简答评分模型”。 文章链接：https://www.researchgate.net/publication/334776307_An_automatic_short-answer_grading_model_for_semi-open-ished_questions  该研究将 LSTM 训练为预测答案分数的分类器。 LSTM 正在获取标记化答案中每个单词的词向量。但我不明白算法如何仅通过词向量来判断答案是否完整/不完整/不正确？ 模型答案不应该至少用于内容比较吗？ &gt;   由   提交 /u/LyannaEugen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsgeo9/d_how_is_the_algorithm_scoring_an_answer_without/</guid>
      <pubDate>Sun, 31 Mar 2024 17:54:11 GMT</pubDate>
    </item>
    <item>
      <title>[D]，[P] 使用自动编码器降维后，我得到了极其相关的特征</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsg8cn/d_p_i_got_extremely_correlated_features_after/</link>
      <description><![CDATA[      我一直致力于信号的无监督分类。为此，我尝试使用 LSTM 自动编码器。但我得到的编码特征彼此高度相关。这是否正确？ https: //preview.redd.it/g79wo6lyiprc1.png?width=702&amp;format=png&amp;auto=webp&amp;s=35924245b3b9ab0223bef89b1346801cb00101b3    ;由   提交/u/Current_Air_5925   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsg8cn/d_p_i_got_extremely_correlated_features_after/</guid>
      <pubDate>Sun, 31 Mar 2024 17:46:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 ML 作品集中，什么更令人印象深刻：实施一篇论文还是创建一个好的项目？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsezcf/d_whats_more_impressive_in_a_ml_portfolio/</link>
      <description><![CDATA[大家好，从您的经验来看，公司的招聘经理更喜欢什么，是出色的论文实施还是出色的实际项目？我知道两者都有很大的好处、优点和缺点等。但是，reddit 上的管理者在查看回购协议时喜欢看到什么？在考察候选人的技能时，其中一个会比另一个更好吗？   由   提交 /u/ninvibe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsezcf/d_whats_more_impressive_in_a_ml_portfolio/</guid>
      <pubDate>Sun, 31 Mar 2024 16:51:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM预训练和评估奖励模型的技巧——讨论2024年3月的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs95b8/p_tips_for_llm_pretraining_and_evaluating_reward/</link>
      <description><![CDATA[ 由   提交/u/seraschka  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs95b8/p_tips_for_llm_pretraining_and_evaluating_reward/</guid>
      <pubDate>Sun, 31 Mar 2024 12:21:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] Auto-Ollama 和 Auto-GGUF：只需一个命令即可简化微调 LLM 的本地推理和 GGUF 量化 🦙🔄💻</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs8w96/p_autoollama_autogguf_simplify_local_inference/</link>
      <description><![CDATA[      周末小项目，我编写了脚本：Auto-Ollama 🦙 和 Auto-GGUF 🔄。 这些脚本简化了本地推理微调模型（Lora、QLora 适配器等）的过程💻。借助 Auto-Ollama 脚本，您只需一行代码即可将 Ollama 用于任何高频微调适配器✨。 如果模型没有 GGUF 格式，则 Auto-GGUF脚本将模型转换为 GGUF，同样只需一个命令。 我正在检查资源，除了 LMstudio 等之外找不到直接的推理方法，所以我想分享这个。我希望它对您的研究有用。 https://github.com/monk1337/ auto-ollama/ https://preview.redd.it/l1v5v03funrc1.png?width=1832&amp;format=png&amp;auto=webp&amp;s=cf65c127ec22d2e669474bab46497ad441fce311   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs8w96/p_autoollama_autogguf_simplify_local_inference/</guid>
      <pubDate>Sun, 31 Mar 2024 12:07:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 限价订单簿数据的探索性数据分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs6nw2/d_exploratory_data_analysis_for_limit_order_book/</link>
      <description><![CDATA[限价订单分析 我拉高了频率。同一货币在 3 个不同市场（例如伦敦证交所、纽约证交所和泛欧交易所）的一日报价数据。我有实际交易和订单簿快照（每边 20 个级别）。我现在想用 Python 来分析它，但有一些疑问：  如何将数据加载到内存中？我应该使用 PySpark、Dask 等吗？我应该将数据上采样为分钟数据吗？ 理想情况下，我想使用我想到的一些功能进行一些线性回归。我应该在 scikit-learn 中调用 LinearRegression 模块并拟合我加载的所有数据吗？如果是这样，在拟合 LR 模型时，我可以将 PySpark/dask/whatever 框架传递到函数中吗？ 我应该如何处理时间范围中间价格预测（LR 中的 y 值）。这些应该是在接下来的 N 次（例如：5ms）中执行的交易，还是应该是在接下来的 N 次交易中执行的交易？我想问题是预测下一次 N 次交易还是下一次 N 次交易哪个更有意义？  关于使用限价订单簿功能以便预测中价有效！对 Python 中的 LOB 分析特别感兴趣，而不是花哨的 ML 技术:) 谢谢！   由   提交 /u/LeHalfW   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs6nw2/d_exploratory_data_analysis_for_limit_order_book/</guid>
      <pubDate>Sun, 31 Mar 2024 09:49:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 曼巴解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs1va2/p_mamba_explained/</link>
      <description><![CDATA[帖子：https://thegradient.pub/mamba-解释/ ​ 这里我们将讨论：  Mamba 的优点（和缺点）（🐍 ）与变形金刚（🤖）， 思考 Mamba 的类比和直觉，以及  Mamba 对于可解释性、人工智能安全和应用意味着什么。  本文最初发布于Kola 的个人博客。&lt; /p&gt;  ​   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs1va2/p_mamba_explained/</guid>
      <pubDate>Sun, 31 Mar 2024 04:32:28 GMT</pubDate>
    </item>
    <item>
      <title>华尔街日报：人工智能行业在 Nvidia 芯片上的支出是其收入的 17 倍 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs1ebl/wsj_the_ai_industry_spent_17x_more_on_nvidia/</link>
      <description><![CDATA[ ... 在本月早些时候的一次演示中，风险投资公司红杉估计人工智能行业在 Nvidia 芯片上花费了 500 亿美元去年用于训练先进的人工智能模型，但仅带来了 30 亿美元的收入。   来源：《华尔街日报》（付费）   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs1ebl/wsj_the_ai_industry_spent_17x_more_on_nvidia/</guid>
      <pubDate>Sun, 31 Mar 2024 04:06:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] DL 编译器中基于多面体的 IR 背后的直觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brz8t6/d_intuition_behind_polyhedralbased_ir_in_dl/</link>
      <description><![CDATA[阅读时https://arxiv.org/abs/2002.03794 ，我看到了一个关于基于多面体的IR的部分；我的理解是：想象一下，你有一个代表张量的 3D 立方体（我们称之为 A）；假设您有一个嵌套循环，它访问 A 的子多维数据集（我们称之为 B），其中每个 i 次访问都需要第 (i -1) 次访问的结果（B 由单元组成，循环正在访问这些单元）。基于多面体的 IR 优化上述循环的方式是将 B 划分为可能的独立块（每个块都是一个|多个单元），然后对它们进行排列，以便现在可以并行访问多个块。 是这是考虑基于多面体的 IR 的正确方法吗？ 上述调查似乎非常好，但有点过时了。还有其他被忽视的有关 DL 编译器的最新论文/论文吗？   由   提交 /u/qctm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brz8t6/d_intuition_behind_polyhedralbased_ir_in_dl/</guid>
      <pubDate>Sun, 31 Mar 2024 02:15:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我比较了用于长格式转录的不同开源耳语包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brrcjd/p_i_compared_the_different_open_source_whisper/</link>
      <description><![CDATA[      大家好！  我最近比较了所有支持长格式转录的基于开源耳语的软件包。 长格式转录基本上是转录超过 30 秒的音频文件。 长格式转录基本上是转录超过 30 秒的音频文件。 p&gt; 如果您想通过 YouTube 视频或播客等聊天，这会很有用。 我比较了以下软件包：  OpenAI 的官方 Whisper 软件包&lt; /li&gt; Huggingface Transformer Huggingface BetterTransformer FasterWhisper WhisperX Whisper.cpp  我在以下方面对它们进行了比较：  准确性 - 使用单词错误率 (wer) 和字符错误率 (cer) 效率 - 使用 vram使用情况和延迟  我写了一份详细的关于此的博客文章。如果您只想要结果，这里是： ​ https://preview.redd.it/96e3wmnv5jrc1.jpg?width=817&amp;format=pjpg&amp;auto=webp&amp;s=f6f18147e3bdbfb 9f1834c5f758bcb1014a1fbbf 希望您觉得它有用！   由   提交/u/Amgadoz  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brrcjd/p_i_compared_the_different_open_source_whisper/</guid>
      <pubDate>Sat, 30 Mar 2024 20:23:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] TextTile：纹理可平铺性的可微分度量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brg8ko/r_textile_a_differentiable_metric_for_texture/</link>
      <description><![CDATA[   /u/crp1994  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brg8ko/r_textile_a_differentiable_metric_for_texture/</guid>
      <pubDate>Sat, 30 Mar 2024 12:01:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 ML 注释牙科 X 射线</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brbaii/p_using_ml_to_annotate_dental_xrays/</link>
      <description><![CDATA[    &lt; /a&gt;  是否有可用的经过训练的模型，可以将牙科 X 射线 - Orthopantomagram (OPG) 作为输入并对其进行注释完全，标记所有牙齿类型，X 射线中发现的任何异常。它应该隔离所有类型的牙齿，我有一个可以从 X 射线中勾勒出牙齿轮廓，我正在寻找一个模型，可以从 OPG 中标记最可能的信息，这就是我当前模型的工作原理，只是勾勒出牙齿的轮廓具有良好的准确性。   由   提交 /u/Responsible-Win3865   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brbaii/p_using_ml_to_annotate_dental_xrays/</guid>
      <pubDate>Sat, 30 Mar 2024 06:36:50 GMT</pubDate>
    </item>
    <item>
      <title>[N] Stability AI 创始人如何让他的价值数十亿美元的初创公司陷入困境</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1br9vxr/n_how_stability_ais_founder_tanked_his/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1br9vxr/n_how_stability_ais_founder_tanked_his/</guid>
      <pubDate>Sat, 30 Mar 2024 05:13:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>