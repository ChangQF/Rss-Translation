<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Mon, 26 Aug 2024 12:29:40 GMT</lastBuildDate>
    <item>
      <title>NNsight 和 NDIF：民主化访问基础模型内部</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1lb6m/nnsight_and_ndif_democratizing_access_to/</link>
      <description><![CDATA[  由    /u/Noak3  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1lb6m/nnsight_and_ndif_democratizing_access_to/</guid>
      <pubDate>Mon, 26 Aug 2024 10:56:46 GMT</pubDate>
    </item>
    <item>
      <title>大学研究项目：需要参与者！[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1kq4m/university_research_project_participants_needed_p/</link>
      <description><![CDATA[大家好！ 我目前正在为我的大学进行研究，我正在寻找任何潜在的受访者。我正在研究软件开发人员对使用受版权保护的材料来培训基于文本的 LLM 的看法。 如果您参与过任何类型的 LLM 的开发，或者对任何类型的 LLM 的开发有所了解，我将非常感激有机会向您提出几个问题。 感谢您阅读我的帖子！如果您有兴趣，请发表评论或给我发消息，以便我们继续通信。    提交人    /u/ErmBlegh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1kq4m/university_research_project_participants_needed_p/</guid>
      <pubDate>Mon, 26 Aug 2024 10:19:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于绝对位置编码的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1f5nb/p_questions_about_absolute_positional_encoding/</link>
      <description><![CDATA[      我试图推断绝对编码方法无法获取相对位置信息。但根据我的数学推论，这种方法可以学习相对位置，这与大多数人在博客上所说的相反。我不知道我的推论哪里出了问题 https://preview.redd.it/zlvc9vxwlxkd1.png?width=1656&amp;format=png&amp;auto=webp&amp;s=1589bd32f9c22ec184fc3ebe3a4d9278530cd227 https://preview.redd.it/7dpf9ogxlxkd1.png?width=1868&amp;format=png&amp;auto=webp&amp;s=8a48d9b2ef368bed6d1b18d06172fa53ad40752c    提交人    /u/Fun-Entertainer1101   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1f5nb/p_questions_about_absolute_positional_encoding/</guid>
      <pubDate>Mon, 26 Aug 2024 03:57:05 GMT</pubDate>
    </item>
    <item>
      <title>[项目]：用于 AI 模型的 Python 应用程序：欢迎您的反馈！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1a1el/project_python_apps_for_ai_models_your_feedback/</link>
      <description><![CDATA[嗨，我一直在学习一些流行的人工智能模型，并创建了一些与它们相关的 Python 应用程序。欢迎随时尝试，如果您有任何反馈，我将不胜感激！  AutoSubs：用于在视频中嵌入可自定义字幕的 Web 应用程序。 VideoSummarizer：使用自定义字数限制选项总结 YouTube 视频的 Web 应用程序。 StableDiffusion：使用 Stable Diffusion 1.5 进行文本到图像生成和修复的 Python 应用程序。 Image Matting：使用带有 trimap 生成的 ViTMatte 进行背景去除并提高准确度的 Python 应用程序。 Lama Inpainting：用于对象移除和修复的 Python 应用程序，通过升级来保持原始分辨率。 YT Video Downloader：用于通过 URL 下载 YouTube 视频的 Web 实用程序。     提交人    /u/nashPrat   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1a1el/project_python_apps_for_ai_models_your_feedback/</guid>
      <pubDate>Sun, 25 Aug 2024 23:29:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于多维通信分析和模拟的自优化概率框架：通过内在动机行为迭代收敛到唯一定义和可衡量结果的人工智能生成评估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f19z1d/r_selfoptimizing_probabilistic_framework_for/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f19z1d/r_selfoptimizing_probabilistic_framework_for/</guid>
      <pubDate>Sun, 25 Aug 2024 23:26:22 GMT</pubDate>
    </item>
    <item>
      <title>Matryoshka Adaptor：谷歌关于嵌入模型的精彩新论文 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f18q2q/matryoshka_adaptor_exciting_new_paper_on/</link>
      <description><![CDATA[      大家好， 一个令人兴奋的新https://arxiv.org/abs/2407.20243 本质上，该论文提出了一种简单 MLP 形式的适配器，它可以高效地将任何嵌入模型的输出适配到 Matryoshka 嵌入，根据需要降低尺寸，同时保持性能；嵌入模型本身不需要微调或进行迁移学习。这是一篇令人兴奋的论文，具有一些非常令人兴奋的含义。  我一直在尝试自己复制结果，但不幸的是，我没有得到承诺的准确度 - 正如您所看到的，我获得的嵌入并不比裁剪原始模型的嵌入更好： 没有获得论文图 4 中的结果 - 无监督 Matryoshka Adaptor 并不比具有截断嵌入的 BASE 模型更好；它应该比具有降维的 PCA 降级得更少。 我认为我误解了并因此错误地实施了所提出的模型。我认为它是以下之一： 不正确的训练过程 - 我一直在 NFCorpus 上进行训练，但我也尝试过在其他 BEIR 数据集上进行训练。对于应该更易于实现的无监督方法，我一直在针对每个 BEIR 数据集在语料库的“文本”上进行训练。训练期间损失正在减少，但是如您所见，性能并不好。我曾尝试同时在多个数据集上进行训练，因为假设一个数据集的数据不足以进行训练。  其中一个损失函数的实现不正确。 我还想澄清一下，假设对是查询语料库对，它们是如何计算的（训练对和测试对），只用于监督方法。 如果有人可以在 GitHub (https://github.com/WillPowellUk/MatryoshkaAdaptor/blob/main/matryoshka_adaptor.ipynb) 上查看我的实现，或者提供任何调试建议，我将不胜感激。  提前致谢！    由   提交  /u/SnooCrickets1810   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f18q2q/matryoshka_adaptor_exciting_new_paper_on/</guid>
      <pubDate>Sun, 25 Aug 2024 22:26:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 检测和分类软件漏洞</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f117b1/p_detecting_and_classifying_software/</link>
      <description><![CDATA[大家好，我一直想做一个项目，想听听大家的想法。目标是从反汇编的可执行文件中对漏洞进行分类。我的计划是同时使用顺序信息（指令、助记符、操作数）和控制流图（基于分支）。 我选择了一些常见的漏洞，例如缓冲区溢出、整数溢出和内存泄漏，并希望将它们分类为包含这些漏洞之一或不易受攻击。Juliet C/C++ 数据集似乎是这项任务的不错选择，因为它包含以不同风格编写的约 60k 个易受攻击和不易受攻击的源代码测试用例。这些可以使用不同的编译器选项进行编译，以生成略有不同的反汇编，从而构建更大的词汇表。 我很想听听你对这个想法的看法，以及在开始之前我应该​​考虑哪些主要障碍。    提交人    /u/SgtPepper8903   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f117b1/p_detecting_and_classifying_software/</guid>
      <pubDate>Sun, 25 Aug 2024 17:03:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 处理包含大量 NaN 的大型表格数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0zq8l/p_dealing_with_large_tabular_dataset_with_lot_of/</link>
      <description><![CDATA[现在我正在处理 400k 行分类表格数据集，其中包含大量 NaN，因此如果我执行 dropna()，它只会剩下 4 行。我现在正在进行 KNN 插补，但它花费了大量时间（在我撰写这篇文章时它尚未完成）。我的问题是，如何处理大型数据集的插补？我必须对数据集进行抽样还是其他什么？    提交人    /u/Fun_Ambition_5186   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0zq8l/p_dealing_with_large_tabular_dataset_with_lot_of/</guid>
      <pubDate>Sun, 25 Aug 2024 16:01:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 根据应用交互的视频片段生成 Gherkin 场景</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0z19p/p_generating_gherkin_scenarios_from_video_footage/</link>
      <description><![CDATA[大家好，我正在做一个项目，需要根据视频输入生成 Gherkin 场景。本质上，我想分析应用程序交互的视频片段（如光标移动、文本输入和按钮点击）并自动为 BDD 框架创建 Gherkin 测试用例。有人做过类似的事情吗？或者对如何处理这个问题有什么建议吗？你会推荐什么工具或技术？    提交人    /u/lonylegend   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0z19p/p_generating_gherkin_scenarios_from_video_footage/</guid>
      <pubDate>Sun, 25 Aug 2024 15:31:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0ybbs/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0ybbs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Aug 2024 15:00:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] Jamba-1.5：大规模混合 Transformer-Mamba 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0wvnz/r_jamba15_hybrid_transformermamba_models_at_scale/</link>
      <description><![CDATA[      TL;DR: 大型（高达 94B/398B 活跃/总参数）混合开放权重模型，高达 256k 上下文 论文： https://arxiv.org/pdf/2408.12570 博客： https://www.ai21.com/blog/announcing-jamba-model-family 摘要：  我们提出了 Jamba-1.5，这是基于我们的 Jamba 架构的新型指令调整大型语言模型。Jamba 是 Transformer-Mamba 混合专家架构，可在上下文长度上提供高吞吐量和低内存使用率，同时保持与 Transformer 模型相同或更好的质量。我们发布了两种模型大小：Jamba-1.5-Large，具有 94B 个活动参数，以及 Jamba-1.5-Mini，具有 12B 个活动参数。这两种模型都针对各种对话和指令遵循功能进行了微调，并且具有 256K 个标记的有效上下文长度，这是开放权重模型中最大的。为了支持经济高效的推理，我们引入了 ExpertsInt8，这是一种新颖的量化技术，允许在具有 8 个 80GB GPU 的机器上安装 Jamba-1.5-Large，同时处理 256K 个标记上下文而不会损失质量。在一系列学术和聊天机器人基准测试中，Jamba-1.5 模型取得了出色的结果，同时提供了高吞吐量，并且在长上下文基准测试中优于其他开放权重模型。两种尺寸的模型权重均在 Jamba 开放模型许可下公开提供，我们将 ExpertsInt8 作为开源发布。  视觉亮点： 在混合架构中，Mamba-1 块的表现优于 Mamba-2 块。当模型具有注意力时，Mamba-2 处理细节可能是多余的 https://preview.redd.it/onrdw742ftkd1.png?width=1129&amp;format=png&amp;auto=webp&amp;s=dff7d4dd10ccc0b8d1481bab7de084cb2ac1b586 https://preview.redd.it/nm79gn64ftkd1.png?width=1145&amp;format=png&amp;auto=webp&amp;s=650327eba37add3af6fd629371b98010789f10a2 https://preview.redd.it/yd3l7k46ftkd1.png?width=1115&amp;format=png&amp;auto=webp&amp;s=bce413b0f95ec2cb786cb388589cbe22c06d5ca9 https://preview.redd.it/qe4choo7ftkd1.png?width=1129&amp;format=png&amp;auto=webp&amp;s=eca7f428af74099d15dd1ebd7db1cdbe7d6d721e https://preview.redd.it/vy26ido9ftkd1.png?width=1109&amp;format=png&amp;auto=webp&amp;s=b6b2ee51a650c2910a01c465a810e33ad7880ebb 无限长凳 https://preview.redd.it/61dfzmugftkd1.png?width=1147&amp;format=png&amp;auto=webp&amp;s=c53aa8a8d43b49aeb81871db9f25227874cc34ad 下载：https://huggingface.co/collections/ai21labs/jamba-15-66c44befa474a917fcf55251    由   提交  /u/StartledWatermelon   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0wvnz/r_jamba15_hybrid_transformermamba_models_at_scale/</guid>
      <pubDate>Sun, 25 Aug 2024 13:55:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习到底发生了什么？一些最小模型 (Stephen Wolfram)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0wj6s/r_whats_really_going_on_in_machine_learning_some/</link>
      <description><![CDATA[Stephen Wolfram 最近发表了一篇博客文章，其中提出了一些关于离散神经网络的有趣观点，从自动机的角度来看待训练： https://writings.stephenwolfram.com/2024/08/whats-really-going-on-in-machine-learning-some-minimal-models/    提交人    /u/hardmaru   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0wj6s/r_whats_really_going_on_in_machine_learning_some/</guid>
      <pubDate>Sun, 25 Aug 2024 13:38:16 GMT</pubDate>
    </item>
    <item>
      <title>有人在机器学习中使用合成数据吗？它对你的项目有何影响？[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0wbfy/anyone_actually_using_synthetic_data_in_ml_how/</link>
      <description><![CDATA[我很好奇您在机器学习项目中实际使用的合成数据的实际应用。 它是否真正增强了您的流程或结果？您在使用它时面临的最大挑战是什么？ 我很想听听您的经历——好的和坏的。    提交人    /u/Value-Forsaken   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0wbfy/anyone_actually_using_synthetic_data_in_ml_how/</guid>
      <pubDate>Sun, 25 Aug 2024 13:27:37 GMT</pubDate>
    </item>
    <item>
      <title>[P] 生产中的机器学习：从数据科学家到机器学习工程师</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0fdih/p_ml_in_production_from_data_scientist_to_ml/</link>
      <description><![CDATA[我很高兴与大家分享我整理的一门课程：生产中的机器学习：从数据科学家到机器学习工程师。本课程旨在帮助您从 Jupyter 笔记本中获取任何 ML 模型并将其转变为可用于生产的微服务。 本课程涵盖以下内容：  将您的 Jupyter 代码构建为生产级代码库 管理数据库层 参数化、日志记录和最新的干净代码实践 使用 GitHub 设置 CI/CD 管道 为您的模型开发 API 容器化您的应用程序并使用 Docker 进行部署  我很乐意收到您对本课程的反馈。这是免费访问的优惠券代码：FREETOLEARN24。您的见解将帮助我改进和完善内容。如果您喜欢本课程，我希望您留下好评，以便其他人也可以找到这门课程。谢谢，祝您学习愉快！    提交人    /u/5x12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0fdih/p_ml_in_production_from_data_scientist_to_ml/</guid>
      <pubDate>Sat, 24 Aug 2024 20:54:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>