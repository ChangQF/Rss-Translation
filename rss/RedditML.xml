<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 02 Jul 2024 15:15:04 GMT</lastBuildDate>
    <item>
      <title>[R] 通过稀疏插值专家释放元调优的力量，实现小样本泛化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dtntuq/r_unleashing_the_power_of_metatuning_for_fewshot/</link>
      <description><![CDATA[  由    /u/purified_piranha  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dtntuq/r_unleashing_the_power_of_metatuning_for_fewshot/</guid>
      <pubDate>Tue, 02 Jul 2024 14:55:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] Pytorch Geometric、强化学习和 OpenAI Gymnasium</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dtmrqg/p_pytorch_geometric_reinforcement_learning_and/</link>
      <description><![CDATA[大家好。 正如标题所述，我正在尝试实现 openai gymnasium frostylake-v1 环境，以 pytorch 几何知识图谱表示，其中每个单元都是一个知识图谱节点，并且每条边都连接到玩家可以采取的可能路线。但是，我遇到了一个问题，即除非节点特征包含唯一值（无论是唯一节点索引还是它们在 4x4 地图中的位置），否则我的模型无法生成良好的结果。 我需要它独立于这些唯一索引，并且可能在一张地图上进行训练，然后将训练有素的代理放在一张新地图上，在那里他仍然能够对好动作和坏动作有一些概念（例如，掉进洞里总是不好的）。我该如何扩展这个问题？我做错了什么？如需更多信息，请在评论中留言，我一定会回答。 我正在写一篇论文，这个 openai gym 与我将为最终论文进行训练的环境类似。所以我真的需要帮助解决这个特定的问题。    提交人    /u/SmkWed   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dtmrqg/p_pytorch_geometric_reinforcement_learning_and/</guid>
      <pubDate>Tue, 02 Jul 2024 14:09:41 GMT</pubDate>
    </item>
    <item>
      <title>GitHub 问题或 Jira 问题数据集？[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dtjbvl/github_issues_or_jira_issues_data_sets_p/</link>
      <description><![CDATA[大家好， 我目前正在开展一个项目，尝试将 GitHub 和 Jira 票证（问题）分类为不同的类别。我花了大量时间在 Kaggle 和 Hugging Face 等平台上寻找开源数据集，但一直没能找到可靠的数据集。 许多数据集自然都是由开源项目和存储库中的数据编译而成，而不是私人项目，私人项目往往遵循更明确的结构（例如常规提交、标签等），这与我正在进行的项目更一致。 如果有人拥有符合此描述的数据集，或者曾经参与使用此类数据的项目，那就太好了。 TLDR：寻找高质量的 GitHub 或 Jira 问题/票证数据集，其中票证遵循某种结构，例如常规提交、敏捷结构（定义、验收标准、用户故事）等。    提交人    /u/DonThe_Bomb   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dtjbvl/github_issues_or_jira_issues_data_sets_p/</guid>
      <pubDate>Tue, 02 Jul 2024 11:17:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 实时音乐生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dtijd2/d_realtime_music_generation/</link>
      <description><![CDATA[大家好，我目前正在寻找在音乐领域构建一些新工具以融入现场表演，并且很好奇您是否知道任何有趣的实时音乐生成工具可用并且仍在开发中？有相当多的音乐/声音生成库，但不是实时的，所以我很好奇您是否有任何建议。 我发现 RAVE 听起来很有希望：https://github.com/acids-ircam/RAVE?tab=readme-ov-file    提交人    /u/rororo99   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dtijd2/d_realtime_music_generation/</guid>
      <pubDate>Tue, 02 Jul 2024 10:28:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 微调 NVIDIA LITA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dt670a/p_finetuning_nvidia_lita/</link>
      <description><![CDATA[我正在尝试微调 LITA（语言指导时间定位助手），这是 NVIDIA 的一款 VLM，用于特定用例：检测零售盗窃。例如，假设我在一家手机零售店内有一个视频剪辑，显示四位购物者正在查看并从展示墙和货架上拿起手机和其他产品。四位购物者中有三位没有表现出任何可疑行为，但一位购物者明显拿起手机，将其放在口袋里，然后离开商店而没有付款。 为了提供微调中使用的答案响应，是否可以仅描述盗窃发生的时间和地点的场景细节，还是应该提供包含场景中所有内容的详细描述？例如，以下内容是否足够？我还提供了带注释的正常场景视频剪辑，这些场景没有发生盗窃。 &quot;11b_chunk_0000.mp4&quot;: { &quot;vid&quot;: &quot;11b_chunk_0000.mp4&quot;, &quot;question&quot;: &quot;QuestionPrompt&quot;, &quot;answer&quot;: &quot;在&lt;8&gt; 和&lt;17&gt; 之间，一名身穿黑色 T 恤和蓝色牛仔裤、背着深色背包的购物者在产品展示架上拿起一部手机。 购物者随后将手机放在裤子左后口袋中，走开。 这显然是盗窃行为。&quot;, &quot;duration&quot;: 29 },     提交人    /u/Armed_Trash_Panda   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dt670a/p_finetuning_nvidia_lita/</guid>
      <pubDate>Mon, 01 Jul 2024 22:36:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于无人机基本飞行稳定算法的入门建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dt20wu/d_recommendations_for_getting_started_with_a/</link>
      <description><![CDATA[理想情况下，我想购买一架带有可编程控件的无人机，并在其上安装一些传感器和一个小型处理器。我对硬件项目的经验有限，我应该从哪里开始，买什么？    提交人    /u/inner_resilience   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dt20wu/d_recommendations_for_getting_started_with_a/</guid>
      <pubDate>Mon, 01 Jul 2024 19:42:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] VQ-VAE - 为什么不在码本上使用注意力？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsxcfs/d_vqvae_why_not_to_use_attention_on_a_codebook/</link>
      <description><![CDATA[注意力机制是一种可微分的软查找。为什么不使用 K 和 V 作为码本，使用 Q 作为潜在变量，以软方式搜索码本？为什么我们要使用不可微分的 argmin？使用这种模型训练后再进行生成不是更简单吗？例如，使用 Transformer - 我们只需对 LLM 输出的词汇概率进行 MatMul 运算，即可获得表示 - 而不是先从 LLM 词汇概率中采样，然后从码本中挑选一个向量？    提交人    /u/kiockete   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsxcfs/d_vqvae_why_not_to_use_attention_on_a_codebook/</guid>
      <pubDate>Mon, 01 Jul 2024 16:30:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研究监督令人绝望</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dswdrr/d_research_supervision_despair/</link>
      <description><![CDATA[嗨，我想听听另一边的观点。背景是，我是一名本科生，过去几个月一直在尝试进入理论机器学习实验室。我可能已经联系了大约 40 位不同的教授，既有学校的，也有学校外的。在每种情况下，我都阅读了他们的 5-7 篇论文和定制电子邮件；而且，在每种情况下，我要么没有收到回复，要么收到一封自动电子邮件，说他们没有空位。 教授/研究科学家/实验室人员，您认为这是徒劳的吗？我想我已经到了辞职去做没有主管或顾问的工作的地步。研究领域已经饱和到这个程度了吗？我听说教授们总是喜欢免费劳动力，但我还没有看到这种情况。 如果这篇文章/咆哮让你觉得我对任何人生气，我想说我没有。我知道这个领域很忙，我只是在寻求建议。 为了获得更多背景信息，我曾尝试与一位教授一起进行应用 ML 研究，甚至获得了最佳海报奖。然而，我真正的热情在于理论方面。任何建议都将不胜感激。    提交人    /u/Open-Ad2530   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dswdrr/d_research_supervision_despair/</guid>
      <pubDate>Mon, 01 Jul 2024 15:51:59 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ECCV 决策出炉！（+边界论文支持线程）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsutwd/discussion_eccv_decisions_out_borderline_paper/</link>
      <description><![CDATA[https://eccv2024.ecva.net/Conferences/2024/AcceptedPapers 我们通过了 WA/WA/WR 的初步审查，当我看到我的 ID 被列出时，我差点吐了。这几个月真是令人紧张！ 你们都怎么样了？ 向所有正在查看结果的边缘论文拥有者致以深切的爱！对于我们这些边缘人士来说，这是一个完全随机的过程！    提交人    /u/impatiens-capensis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsutwd/discussion_eccv_decisions_out_borderline_paper/</guid>
      <pubDate>Mon, 01 Jul 2024 14:48:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 正在开发一种工具来增加数据集的大小，并创建叠加的数据集！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dst77q/p_working_on_a_tool_to_increase_dataset_size_and/</link>
      <description><![CDATA[      它是一个桌面应用程序，它有助于从 png 图像创建数据集。您只需选择要在其上运行模型的任何对象的几个 png 图像即可。然后选择一些随机图像（在我的示例中是随机山景图像）然后选择您想要的图像数量。然后它将创建一个包含 2 个子文件夹、蒙版和图像的 .zip。您可以在此处查看蒙版和图像的示例。它目前处于测试阶段，欢迎所有反馈！ https://preview.redd.it/l8yczzr9uw9d1.png?width=1016&amp;format=png&amp;auto=webp&amp;s=23474b4bfb0e8d5f5332833e019de3977d2b8542 https://preview.redd.it/3r34a3u7uw9d1.png?width=2405&amp;format=png&amp;auto=webp&amp;s=f3a417f0cfa665d98ab532c9d74d3042d34ba4ee    提交人    /u/MAKEMONEYSMOKEASS   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dst77q/p_working_on_a_tool_to_increase_dataset_size_and/</guid>
      <pubDate>Mon, 01 Jul 2024 13:38:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] 正在寻找 LLM/NLP 领域的开源/研究/志愿者项目？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsrwy4/p_looking_for_opensourceresearchvolunteer/</link>
      <description><![CDATA[嗨！我是一名数据科学家，从事该行业已有近一年的时间，但感觉与该领域非常脱节。 虽然薪水不错，但我并不太喜欢这份工作！在我的组织中，我们使用传统的 ML 算法，这很好（如果刀可以的话，就不能用剑来切苹果）。问题是，我不喜欢这个组织。我对他们的事业没有热情。这感觉像是一份我必须做的工作（事实也确实如此），但我怀念对项目工作和关心自己正在做的事情感到兴奋。 我喜欢在 NLP 领域工作，在该领域做过多个项目和实习。我特别喜欢研究代码混合语言或代表性不足的语言。如果你们知道任何与它们相关的此类项目，请告诉我。  我知道有 Kaggle，但我对竞争有点害怕，所以还没有勇气开始。  谢谢！    提交人    /u/MiserableGrapefruit7   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsrwy4/p_looking_for_opensourceresearchvolunteer/</guid>
      <pubDate>Mon, 01 Jul 2024 12:36:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 现在（2024年）最先进的 TTS 模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsp3vf/d_what_is_the_most_advanced_tts_model_now_2024/</link>
      <description><![CDATA[如果我想训练一个用于阅读新闻的 TTS 模型，我应该怎么做？我需要什么样的训练数据？ 谢谢。    提交人    /u/secsilm   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsp3vf/d_what_is_the_most_advanced_tts_model_now_2024/</guid>
      <pubDate>Mon, 01 Jul 2024 09:51:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型语言模型比大家想象的要线性得多</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dso3pg/r_large_language_models_are_much_more_linear_than/</link>
      <description><![CDATA[      作者揭示了 Transformer 解码器独有的一种新型线性特性，包括 GPT、LLaMA、OPT、BLOOM 等模型。他们分析了连续层之间的嵌入转换，发现了近乎完美的线性关系（Procrustes 相似度得分为 0.99）。然而，由于 Transformer 层的输出范数一直较低，因此在移除残差分量时线性度会降低。 https://preview.redd.it/t5kq9g598v9d1.png?width=2420&amp;format=png&amp;auto=webp&amp;s=20da53fce41f75242244d78eea590c6fa52b88c9 实验表明，移除或线性近似 Transformer 中一些最线性的块不会显著影响损失或模型性能。此外，在较小模型的预训练实验中，作者引入了基于余弦相似度的正则化，旨在降低层线性。这种正则化提高了 Tiny Stories 和 SuperGLUE 等基准测试的性能指标，并成功降低了模型的线性度。这项研究挑战了对 transformer 架构的现有理解，表明它们的操作可能比以前假设的更线性，并且可以在不损失质量的情况下消除 10-15% 的层。 该研究已被 ACL 2024 会议接受，更多详细信息请参阅预印本。    提交人    /u/AIRI_Institute   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dso3pg/r_large_language_models_are_much_more_linear_than/</guid>
      <pubDate>Mon, 01 Jul 2024 08:40:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 花费数十亿美元训练生成模型的人工智能实验室的最终目标是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsnk1k/d_whats_the_endgame_for_ai_labs_that_are_spending/</link>
      <description><![CDATA[鉴于目前 LLM 和生成模型的热潮，前沿 AI 实验室正在投入数十亿美元的风险投资资金来构建 GPU 集群、训练模型、免费提供模型访问权限以及获取授权数据。但是，当这种热情消退、市场重新调整时，他们的游戏计划是什么？ 有一些挑战使得使用当前的 LLM 创建盈利的商业模式变得困难：  所有前沿模型的近乎相同的性能将使 LLM 市场商品化，并迫使供应商在价格上展开竞争，从而大幅削减利润率。与此同时，新模型的培训仍然非常昂贵。 高质量的训练数据变得越来越昂贵。您需要主题专家来手动创建数据或审查合成数据。这反过来又使得模型改进的每次迭代都更加昂贵。 开源和开放权重模型的进步可能会占据私有模型企业市场的很大一部分。 设备上模型的进步和与操作系统的集成可能会减少未来对基于云的模型的需求。 模型的快速更新周期为人工智能公司提供了非常短的回报窗口来收回训练新模型的巨额成本。  当资金枯竭时，Anthropic、Cohere、Mistral、Stability 等实验室的最终结果是什么？他们会与大型科技公司（例如 OpenAI 和微软）更加紧密地合作以扩大分销吗？他们会找到其他商业模式吗？他们会消亡还是会被收购（例如，Inflection AI）？ 有什么想法吗？    提交人    /u/bendee983   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsnk1k/d_whats_the_endgame_for_ai_labs_that_are_spending/</guid>
      <pubDate>Mon, 01 Jul 2024 08:02:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>