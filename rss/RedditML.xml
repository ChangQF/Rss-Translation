<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 14 Feb 2024 06:18:14 GMT</lastBuildDate>
    <item>
      <title>[P] 打开图像数据集 v7</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqfcts/p_open_images_dataset_v7/</link>
      <description><![CDATA[嘿伙计们，我不确定这是问此类问题的合适空间。我对此有点陌生，如果不是的话，很抱歉。 昨天，我开始尝试创建一个脚本来检测某些提供的图像中的某种类别。然而，为了训练模型，我发现我可以下载大量照片，并且已经从开放图像数据集中完成了检测。然而，我似乎没有找到任何方法来下载特定类别（例如飞机）的所有照片（或至少大量）。  有知道如何处理此类项目的人可以帮助我吗？非常感谢。   由   提交/u/goncalosm01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqfcts/p_open_images_dataset_v7/</guid>
      <pubDate>Wed, 14 Feb 2024 05:29:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于分类的 VAE</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqf4io/d_vaes_for_classification/</link>
      <description><![CDATA[开门见山： VAE 的潜在空间是否有可能学习未馈送到模型的分类？举个例子，假设你有一堆猫和狗在一起的图像，没有标签，VAE 模型可以通过潜在空间隐式学习它是猫还是狗吗？ 作为另一个问题，可以您将 VAE 的损失与分类模型结合使用，并使用 VAE 的损失来衡量样本是标签之一的可能性？   由   提交 /u/Radiant_Walrus3007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqf4io/d_vaes_for_classification/</guid>
      <pubDate>Wed, 14 Feb 2024 05:16:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一个看起来像机器学习问题的问题。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqewye/d_a_problem_that_seems_like_a_ml_problem/</link>
      <description><![CDATA[      你好。  我工作的系统是高度参数化的，即具有大量参数（二进制值或整数范围）。这些参数不是独立的。尽管许多可能的组合无效，但它们仍然会产生大量可能的配置。  现在，手头的任务是找到该参数化系统的最佳配置，该配置将根据输入设置最大化可直接测量的指标。同样，输入空间非常大。  这似乎是一个经典的机器学习问题，但似乎更像是一个模拟类型的问题，在给定一个我拥有无限资源的理想世界中，我将针对有问题的输入设置运行所有系统配置并找到最大化我的相关指标的设置。在“测试时间”，我将利用手中的这些信息以最佳设置运行系统。  这个问题的设置听起来是否接近任何现有的深入研究领域？谢谢。  PS - 我很神秘，因为我无法透露具体的系统。 https://preview.redd.it/frgvz33wghic1.png?width=1292&amp;format=png&amp;auto=webp&amp;s= 5ea8d9720e185d0cb7de3fc3c29a5593f342c5d4    由   提交/u/Traditional_Two7396   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqewye/d_a_problem_that_seems_like_a_ml_problem/</guid>
      <pubDate>Wed, 14 Feb 2024 05:04:31 GMT</pubDate>
    </item>
    <item>
      <title>需要在聊天/成绩单数据上微调法学硕士 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqe5v4/need_to_finetune_llms_on_chattranscript_data_d/</link>
      <description><![CDATA[您好，我有数百份代理与客户之间的对话记录。我一直致力于使用 QLoRa 微调 Mistral。目标是制作一个聊天机器人或虚拟代理。然而，经过微调后，模型生成的不是单个响应，而是整个对话。我的提示看起来像 -  对话： {成绩单中的小片段} 代理： { } 我应该更改提示吗？有人有微调聊天/记录数据的经验吗？任何帮助将不胜感激。   由   提交/u/Evermore2307  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqe5v4/need_to_finetune_llms_on_chattranscript_data_d/</guid>
      <pubDate>Wed, 14 Feb 2024 04:23:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求建议：AI/ML 职业道路云认证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqdde4/d_seeking_advice_cloud_certification_for_aiml/</link>
      <description><![CDATA[大家好， 我目前正在攻读人工智能硕士学位，并拥有一年的软件开发经验。由于我渴望进入机器学习/人工智能或数据科学角色，因此我一直在考虑在我的投资组合中添加云认证。鉴于云基础设施在部署人工智能模型和处理大数据方面的重要性，我正在考虑获得 Google Associate Cloud Engineer 认证。然而，随着 Microsoft 云解决方案的日益普及，我正处于十字路口。 我的主要目标是提高我的就业能力并在 AI/ML 或数据科学领域找到一份高薪工作。虽然我有一些项目，但我相信云认证可能会让我的简历脱颖而出。 我正在寻求几个方面的建议：   云认证的相关性：云认证有多大好处，特别是对于那些致力于人工智能/机器学习或数据科学角色的人来说？它会对就业前景产生重大影响吗？ Google Cloud 与 Microsoft Azure：考虑到行业趋势和就业市场需求，您会推荐 Google Cloud 还是 Microsoft Azure？或者我应该考虑其他平台吗？ 投资价值：考虑到时间和财务投资，您认为对于像我这样有背景和背景的人来说，追求云认证是一个战略举措吗？目标？  任何见解、经验或建议将不胜感激。我来这里是为了向那些走过类似道路或对行业趋势有洞察力的人学习。预先感谢您的指导！   由   提交/u/No_Masterpiece_1430   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqdde4/d_seeking_advice_cloud_certification_for_aiml/</guid>
      <pubDate>Wed, 14 Feb 2024 03:42:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 跨上下文长度的基准检索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqd24k/d_benchmarking_retrieval_across_context_lengths/</link>
      <description><![CDATA[以下针对 GPT 4 的“大海捞针”测试在今年早些时候广为流传，显示前 64k 代币的检索率为 100%： https://github.com/gkamradt/LLMTest_NeedleInAHaystack 这是否被视为有效测试机器学习专家中？如果它有效，那么它是否已在其他地方复制过？如果它有效，这似乎不太可能是测试的唯一公开实现。 如果它无效，可能是什么方法？ 最后，总共有多少令牌您个人认为 GPT 4 能记住上下文吗？   由   提交/u/Ok_Elephant_1806   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqd24k/d_benchmarking_retrieval_across_context_lengths/</guid>
      <pubDate>Wed, 14 Feb 2024 03:26:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果我有一个采样策略 A、B、C 和 B 表现最好。如果数据规模扩大，情况仍然如此吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq8p38/d_if_i_have_a_sampling_strategy_a_b_and_c_and_b/</link>
      <description><![CDATA[所以我一直在测试带有二进制标签的 NLP 数据的不同采样策略（均匀、分层以及标签上两者之间的中间）。我已经用 20% 的数据对它们进行了测试，发现中间采样策略迄今为止效果最好。如果我缩放到 100% 的数据，什么原因可能导致中间的数据不再是最好的？   由   提交 /u/DolantheMFWizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq8p38/d_if_i_have_a_sampling_strategy_a_b_and_c_and_b/</guid>
      <pubDate>Tue, 13 Feb 2024 23:58:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Mamba 进行语音合成：初学者友好的笔记本 + 代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq7rd5/p_speech_synthesis_with_mamba_beginner_friendly/</link>
      <description><![CDATA[大家好，我遇到了这篇文章上个月，发现它非常有趣。我是 Defined AI 的开发者倡导者，总是希望学习新事物，所以我想自己解决这个问题。写得非常好的博客文章，作者：u/ExaminationNo8522 也有帮助。 无论如何，我想仔细检查它并在不同的数据集上为自己重现，然后移植到确定。结果是一个初学者友好的笔记本 + 博客文章。如果您感兴趣，请查看这些内容。 当然，如果您有想法/反馈/评论/问题，请告诉我！   由   提交 /u/ishabytes   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq7rd5/p_speech_synthesis_with_mamba_beginner_friendly/</guid>
      <pubDate>Tue, 13 Feb 2024 23:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] 思想扩散：扩散语言模型中的思想链推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq572l/r_diffusion_of_thoughts_chainofthought_reasoning/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.07754 代码：https ://github.com/HKUNLP/diffusion-of-thoughts 摘要：  扩散模型在以下领域获得了关注：文本处理，与传统自回归模型相比具有许多潜在优势。这项工作探索了扩散模型和思想链（CoT）的集成，这是一种完善的技术，可以提高自回归语言模型的推理能力。我们提出思想扩散 (DoT)，允许推理步骤通过扩散过程随着时间的推移而扩散。与以从左到右、逐个标记的方式做出决策的传统自回归语言模型相比，DoT 在计算和推理性能之间的权衡方面提供了更大的灵活性。我们的实验结果证明了 DoT 在多位数乘法和小学数学问题中的有效性。此外，DoT 还展示了有前景的自我纠正能力，以及自一致性解码等现有推理增强技术的优势。我们的发现有助于理解和发展扩散语言模型的推理能力。    由   提交 /u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq572l/r_diffusion_of_thoughts_chainofthought_reasoning/</guid>
      <pubDate>Tue, 13 Feb 2024 21:32:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR openreview 可见吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq0ama/d_iclr_openreview_visible/</link>
      <description><![CDATA[我最近向 ICML 提交了一篇论文，但被 ICLR 拒绝了。我发现我在 ICLR 的 openreview 控制台中的论文是每个人都可以看到的。可以吗？由于 ICLR 和 ICML 中的论文标题相同，那么 ICML 可能不是完全匿名的。 我必须手动更改可见性吗？   由   提交/u/Shot-Button-9010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq0ama/d_iclr_openreview_visible/</guid>
      <pubDate>Tue, 13 Feb 2024 18:15:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 复杂的机器学习项目是否需要编译语言？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apyymt/d_is_there_a_need_for_compiled_language_in/</link>
      <description><![CDATA[我们都知道机器学习场景由 Python 主导，这种简单但速度慢的语言。根据我的经验，Rust、C++、C 和 Zig 等语言平均速度快 10 倍（当然可能会有很大差异，并且由于多种原因，使用 C 编写的模块并没有多大帮助），但它们遭受需要编译，这需要一些开发时间。对于机器学习中使用的复杂算法来说，一旦开发过程放慢，它们仍然具有明显的优势。为什么他们的市场份额这么小？到目前为止，我确实找到了一个专门用于运行经过训练的神经网络模型的框架，称为 ggml。  编辑：我忘记了 TensorFlow 实际上主要是用 C++ 编写的。因此，这反驳了我关于编译语言没有太多市场份额的观点。   由   提交 /u/LetsNya   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apyymt/d_is_there_a_need_for_compiled_language_in/</guid>
      <pubDate>Tue, 13 Feb 2024 17:22:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] Fiddler：用于混合专家模型快速推理的 CPU-GPU 编排 - 华盛顿大学 2024 年 - 推理速度比现有系统快 10 倍以上！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apxr2n/r_fiddler_cpugpu_orchestration_for_fast_inference/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.07033  Github：https://github。 com/efeslab/fiddler  摘要：  基于专家混合 (MoE) 架构的大型语言模型 (LLM) 在各种任务。然而，由于模型尺寸巨大，在 GPU 内存资源不足的资源受限设置上运行它们具有挑战性。将模型权重卸载到 CPU 内存的现有系统面临着在 CPU 和 GPU 之间频繁移动数据的巨大开销。在本文中，我们提出了 Fiddler，一种资源高效的推理引擎，可为 MoE 模型提供 CPU-GPU 编排。 Fiddler的核心思想是利用CPU的计算能力来最小化CPU和GPU之间的数据移动。 我们的评估表明，Fiddler 可以运行参数超过 90GB 的未压缩 Mixtral-8x7B 模型，在具有 24GB 内存的单个 GPU 上每秒生成超过 3 个令牌，比现有方法有数量级的改进。  https ://preview.redd.it/q9l3fciyqdic1.jpg?width=1338&amp;format=pjpg&amp;auto=webp&amp;s=2e39726c970c655d6ee39f2b68c323204c6b2289 https://preview.redd.it/epjd0fiyqdic1.jpg?width=1661&amp;format=pjpg&amp;auto=webp&amp; ;s=701a2d61f8ab50d054db0301a30e40119898dab6   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apxr2n/r_fiddler_cpugpu_orchestration_for_fast_inference/</guid>
      <pubDate>Tue, 13 Feb 2024 16:34:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] OS-Copilot：迈向自我完善的通用计算机代理 - 上海人工智能实验室2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apwlkm/r_oscopilot_towards_generalist_computer_agents/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2402.07456  Github：https://github.com/OS-Copilot/FRIDAY  摘要：  与计算机的自主交互一直是一个长期的挑战巨大的潜力，最近大型语言模型（LLM）的激增显着加速了构建数字代理的进展。然而，大多数这些代理都被设计为与狭窄的域交互，例如特定的软件或网站。这种狭隘的关注限制了它们对一般计算机任务的适用性。为此，我们引入了 OS-Copilot，这是一个构建通用代理的框架，能够与操作系统 (OS) 中的综合元素（包括 Web、代码终端、文件、多媒体和各种第三方应用程序）进行交互。我们使用 OS-Copilot 创建 FRIDAY，这是一个自我改进的实体代理，用于自动化一般计算机任务。 在通用人工智能助手基准 GAIA 上，FRIDAY 的性能比以前的方法高出 35%，通过以前任务中积累的技能展示了对未见过的应用程序的强大泛化能力。我们还提供了数值和定量证据，表明 FRIDAY 学会了控制和控制在最少的监督下自我改进 Excel 和 Powerpoint。 我们的 OS-Copilot 框架和实证研究结果为未来研究更强大、更通用的计算机代理提供了基础设施和见解。   https://preview.redd.it/uzec8udohdic1.jpg?width=1655&amp;format=pjpg&amp; ;auto=webp&amp;s=893b5561ca47c26c789b69925efdc26e5b783007 https://preview.redd.it/vfwfwudohdic1.jpg?width=1653&amp;format=pjpg&amp;auto=webp&amp;s=9eafc2a5ea0ad188a156d3de446508d82d9cc913  https://preview.redd.it/lmi8rwdohdic1.jpg?width=1123&amp;format =pjpg&amp;auto=webp&amp;s=dbc67b27585b980d0c592f9bd9f87f3ec6531f66 https://preview.redd.it/20yo21eohdic1.jpg?width=1037&amp;format=pjpg&amp;auto=webp&amp;s=72fab36d585b862eed4ff6c7deed2be0cd62f637   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apwlkm/r_oscopilot_towards_generalist_computer_agents/</guid>
      <pubDate>Tue, 13 Feb 2024 15:48:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] [P] 通过贝叶斯优化将 LLM 评估速度提高 10 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apv97t/r_p_10_times_faster_llm_evaluation_with_bayesian/</link>
      <description><![CDATA[最近我一直致力于通过使用贝叶斯优化来选择合理的子集来快速进行 LLM 评估。 贝叶斯优化是使用它是因为它有利于探索/利用昂贵的黑匣子（释义，LLM）。 项目链接&lt; /p&gt; 我很想听听您对此的想法和建议！   由   提交 /u/b06901038g   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apv97t/r_p_10_times_faster_llm_evaluation_with_bayesian/</guid>
      <pubDate>Tue, 13 Feb 2024 14:51:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>