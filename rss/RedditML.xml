<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 19 Oct 2024 12:30:16 GMT</lastBuildDate>
    <item>
      <title>[项目] JAX 上的深度学习库/框架，将神经网络保留为纯函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g762xs/project_deep_learning_libframework_on_jax_that/</link>
      <description><![CDATA[您好，我正在 JAX 上开发一个新的深度学习框架，非常喜欢 JAX 的 FP 方法，并受到启发，想做一个不会将其转变为 OOP 的框架。它深受 Haiku 和 Haiku 的变换的启发。 链接：Zephyr：https://github.com/mzguntalan/zephyr 可通过 pip install 获得 它的主要区别在于： - 神经网络只是像 `def f(params, x, hyper_parameters)` 这样的函数 - 因此，虽然它很冗长，但它的行为方式却很明显。在 FP 中，您可以在需要时进行部分应用/闭包 - 做“模型手术”非常容易因为它只是调用函数（例如，请参阅自述文件） - zephyr 负责验证参数并通过单个“trace”函数创建它们。 这个名为 Zephyr 的框架使在 numpy 级别编码神经网络变得非常方便。您可以获得最终控制权，并且 zephyr 的“trace”会为您初始化参数，所有网络都只是纯函数。没什么特别的，因此您可以使用 python、函数和 numpy 技能来做任何您想做的事情。我在自述文件中展示了示例。希望你喜欢它。 我忙于实现参数创建功能，因此我还没有实现所有常见网络，而且我还没有最终确定网络参数，所以这些参数可能会发生变化。但如果您现在尝试并提出建议，这些将极大地影响它未来的设计。  期待您的评论！ 其他说明： - 我仍在试验还有哪些其他方法可以使 Python 上的 FP 更加容易或可读 - 例如：我制作了一个装饰器，使函数自身“自动部分化”，以便您可以将参数分成这样的组：`g(x,y,z) == g( _ , y, _ ) (x,z)`，其中 `_ = Placeholder()` - 在关注核心网络/层之前，仍在试验如何整合其他功能 - 非常欢迎提出建议    提交人    /u/Pristine-Staff-5250   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g762xs/project_deep_learning_libframework_on_jax_that/</guid>
      <pubDate>Sat, 19 Oct 2024 10:35:11 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Tsetlin 机器用于深度逻辑学习和图形推理（六年后终于完成了！）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g75gcb/project_tsetlin_machine_for_deep_logical_learning/</link>
      <description><![CDATA[   https://preview.redd.it/spcqdkqwnovd1.png?width=2643&amp;format=png&amp;auto=webp&amp;s=ba0d7dd294ef9814f20bf3950f0049e80cf8d8d9 大家好！我刚刚完成了第一个深度 Tsetlin 机器 - 一个可以跨图进行多模态学习和推理的图 Tsetlin 机器。在 2018 年推出 Tsetlin 机器后，我希望能快速弄清楚如何制作一个深度机器。我花了六年时间！分享项目：https://github.com/cair/GraphTsetlinMachine 特点：  定向和标记多图 矢量符号节点属性和边类型 嵌套（深）子句 任意大小的输入 合并Vanilla、Multiclass、 卷积和合并 Tsetlin 机器 重写更快的 CUDA 内核  路线图：  用 C 或 numba 重写 graphs.py，以更快地构建图形 添加自动编码器 添加回归 添加多输出 使用邻接矩阵进行图形初始化  很高兴收到关于发展！    由    /u/olegranmo  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g75gcb/project_tsetlin_machine_for_deep_logical_learning/</guid>
      <pubDate>Sat, 19 Oct 2024 09:48:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 变压器自动编码器？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g748gu/d_transformer_autoencoder/</link>
      <description><![CDATA[是否有人知道使用编码器 - 解码器 Transformer 架构训练具有信息瓶颈的文本/序列自动编码器的研究？我设想了类似 bert 的编码器，其中完整序列被编码为单个向量，然后是解码器，该解码器交叉关注编码的潜在表示并经过训练以完整地重现完整序列。 这似乎是一个非常明显的用例，我确信我一定遗漏了一些东西，但我似乎找不到任何关于它的文献。例如，Transformers 从第一天起就是编码器 - 解码器架构，将它们用于信息瓶颈自动编码器似乎是一件轻而易举的事，一定有人尝试过。这是否只是出于某种我不知道的原因而成为一个坏主意，或者是已经尝试过但无济于事，并且该论文因此变得无关紧要？ 从表面上看，这似乎是一种预训练编码器和解码器的好方法（肯定比 T5 好得多？）因为您仍然可以使用非常简单的下一个标记预测任务，并且通过微调，我可以看到编码器对 RAG 变得非常有用，并且可能解锁或增强其他 ICL 能力。我想到其他值得探索的想法是潜在扩散文本生成和上下文压缩，以实现极长的上下文能力。我相信还有更多。 据我所知，唯一的缺点是在训练期间需要在编码器和解码器之间分割内存和计算。 有人有什么线索可以让我在这里跟踪吗？    提交人    /u/next-choken   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g748gu/d_transformer_autoencoder/</guid>
      <pubDate>Sat, 19 Oct 2024 08:12:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2021 年 12 月的一篇有趣帖子，讨论了 transformer 的功效</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g73ym7/d_an_interesting_thread_from_december_2021/</link>
      <description><![CDATA[  由    /u/next-choken  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g73ym7/d_an_interesting_thread_from_december_2021/</guid>
      <pubDate>Sat, 19 Oct 2024 07:51:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 评估生产中的分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6w6za/d_evaluating_classification_in_production/</link>
      <description><![CDATA[对于 Facebook、Youtube、LinkedIn 等，他们如何在生产中评估其有害内容检测模型？如果是离线，可以使用精度、召回率、F1。由于我们不知道生产过程中的标签是什么，他们使用什么指标进行评估/监控？    提交人    /u/lalalagay   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6w6za/d_evaluating_classification_in_production/</guid>
      <pubDate>Fri, 18 Oct 2024 23:53:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用气象雷达数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6tmvv/d_working_with_weather_radar_data/</link>
      <description><![CDATA[我已经开始处理天气雷达数据，这些数据以原始二进制格式提供 - 转换为 IRIS 格式以方便访问和计算，但需要对数据执行机器学习以做出未来预测。 有没有很好的来源可以理解这样的数据，以及与这种类型的数据相关的 AI / ML 技术？    提交人    /u/Mynameiswrittenhere   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6tmvv/d_working_with_weather_radar_data/</guid>
      <pubDate>Fri, 18 Oct 2024 21:49:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 仍然无法规划；LRM 可以吗？OpenAI 在 PlanBench 上对 o1 的初步评估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6qpeq/r_llms_still_cant_plan_can_lrms_a_preliminary/</link>
      <description><![CDATA[论文：https://www.arxiv.org/abs/2409.13373 “虽然 o1 的性能在基准上有了很大的改进，超过了竞争对手，但它还远远没有达到饱和状态。” 总结很恰当。o1 看起来是一个非常令人印象深刻的改进。同时，它揭示了剩余的差距：随着组合长度的增加而退化，成本增加 100 倍，并且当“检索”因名称混淆而受到阻碍时，退化程度大大降低。 但是，我想知道这是否足够接近。例如，这种类型的模型至少足以提供合成数据/监督来训练可以填补这些空白的模型。如果是这样，恕我直言，很快就能找到答案。 此外，作者还添加了一些辛辣的脚注。例如： “研究人员使用纳税人提供的研究资金来向 OpenAI 等私人公司支付费用，以评估其私人商业模式，这种讽刺意味当然在我们心中挥之不去。”    提交人    /u/marojejian   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6qpeq/r_llms_still_cant_plan_can_lrms_a_preliminary/</guid>
      <pubDate>Fri, 18 Oct 2024 19:36:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 解码中保存的注意力？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6ozlr/d_attention_saved_in_llm_decoding/</link>
      <description><![CDATA[在 LLM 生成（解码）过程中，是否每一步都要重新计算全部注意力？我知道像 KV 缓存这样的东西用于保存之前的键/值向量，但是它们的注意力分数怎么办？还是只计算当前查询的注意力？ 谢谢！    提交人    /u/BigYounzzz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6ozlr/d_attention_saved_in_llm_decoding/</guid>
      <pubDate>Fri, 18 Oct 2024 18:22:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 后塌陷检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6l9qv/d_testing_for_posterior_collapse/</link>
      <description><![CDATA[我有一个基于我的数据集训练的 VAE。它表现出以下情况  编码器产生的模型参数非常接近。大多数参数都落在 1e-1 和 1e-2 之间。对数方差类似。 采样新点始终返回 0。 训练数据在经过几个时期后也全部变为 0。  我怀疑该模型的指定不充分。但是，如果我忽略 kl 损失，情况会有所改善（我只训练了 50 个时期）。我想知道该模型是否正在遭受后验崩溃。 如何测试该假设？    提交人    /u/Chr0nomaton   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6l9qv/d_testing_for_posterior_collapse/</guid>
      <pubDate>Fri, 18 Oct 2024 15:45:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于时间序列的多模态神经网络？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6gcxl/d_multimodal_neural_networks_for_time_series/</link>
      <description><![CDATA[我正在寻找一个可以处理非时间序列输入的时间序列神经网络。 具体来说，一个神经网络，我可以给它一个主要时间序列（可能还有额外的辅助时间序列），以及一些关于这个特定时间序列的属性。目标是预测主要时间序列。 例如，假设我有个人家庭能源消耗，但我的测量结果并非全部来自同一时间段。有些房子我只拥有 2023 年的数据，而其他房子则从 2024 年开始，等等。为了配合这些能源消耗时间序列，我可能会有关于消费者家庭的其他信息，比如房子的大小或住在房子里的人数，或者只是一个唯一的 house_id。我想在这种时间序列上训练我的神经网络，在某种嵌入中利用这些附加参数，使得神经网络在给定特定嵌入时能够为这些家庭中的任何一个生成准确的预测。 所以看起来像： forecasting=model(input_time_serie,auxiliary_time_series,additional_properties) 其中input_time_serie是长度为n的单个时间序列向量，auxiliary_time_series是长度为n的可选时间序列（可以是室外温度、一周中的时间等），additional_properties是一个长度为m的向量，包含属性参数，它以某种方式嵌入神经网络内部，允许神经网络区分两个不同的家庭。 这样的神经网络有望用于零样本预测，在这种情况下我们还没有家庭的实际能源消耗，只有嵌入数据。 我知道https://github.com/thuml/Time-Series-Library，但所有这些类型的神经网络的问题在于，它们期望所有不同的时间序列作为输入，因此每个家庭一个，但当我的时间序列实际上没有重叠时，这不起作用，当我想对不在训练数据集中的新家庭进行零样本预测时，它也不起作用。 那么有谁知道有哪个神经网络能够做到这样的事情吗？或者有谁对如何修改神经网络以合理地包含属性嵌入有什么好的想法？    提交人    /u/alyflex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6gcxl/d_multimodal_neural_networks_for_time_series/</guid>
      <pubDate>Fri, 18 Oct 2024 12:01:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 主流 LLM 标记器的局限性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6dc8l/r_limitations_in_mainstream_llm_tokenizers/</link>
      <description><![CDATA[主流 LLM 标记器无法编码和解码为精确的字符串。这意味着它们不是无损的。一些 Llama、Mistral 和 Phi 标记器无法编码字符串 &#39; 谁放了狗？！ !&#39;，然后解码为相同的字符串。 如果运行代码：```python from transformers import AutoTokenizer models = [ &#39;meta-llama/Llama-2-7b&#39;, &#39;meta-llama/Meta-Llama-3-8B&#39;, &#39;meta-llama/Llama-3.1-8B&#39;, &#39;mistralai/Mistral-7B-v0.3&#39;, &#39;mistralai/Mixtral-8x7B-v0.1&#39;, &#39;mistralai/Mixtral-8x22B-v0.1&#39;, &#39;mistralai/Mistral-Nemo-Instruct-2407&#39;, &#39;mistralai/Mistral-Small-Instruct-2409&#39;, &#39;mistralai/Mistral-Large-Instruct-2407&#39;, &#39;microsoft/phi-1&#39;, &#39;microsoft/phi-1_5&#39;, &#39;microsoft/phi-2&#39;, &#39;microsoft/Phi-3-mini-4k-instruct&#39;, &#39;microsoft/Phi-3.5-mini-instruct&#39;, ] text = &#39; 谁放了狗？！&#39; for n in models: tokenizer = AutoTokenizer.from_pretrained(n) text2 = tokenizer.decode(tokenizer.encode(text, add_special_tokens=False)) if text2 == text: print(&#39;OK: &#39;, n, repr(text2)) else: print(&#39;ERR:&#39;, n, repr(text2))  ``` 您将得到： OK: meta-llama/Llama-2-7b &#39; 谁放了狗？！&#39; ERR: meta-llama/Meta-Llama-3-8B “谁放出了狗？！！” ERR: meta-llama/Llama-3.1-8B “谁放出了狗？！！” ERR: mistralai/Mistral-7B-v0.3 “谁放出了狗？！！” OK: mistralai/Mixtral-8x7B-v0.1 “谁放出了狗？！！” ERR: mistralai/Mixtral-8x22B-v0.1 “谁放出了狗？！！” OK: mistralai/Mistral-Nemo-Instruct-2407 “谁放出了狗？！！” OK: mistralai/Mistral-Small-Instruct-2409 “谁放出了狗？！！” OK：mistralai/Mistral-Large-Instruct-2407 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-1 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-1_5 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-2 &#39;谁放出了狗？！&#39; OK：microsoft/Phi-3-mini-4k-instruct &#39;谁放出了狗？！&#39; OK：microsoft/Phi-3.5-mini-instruct &#39;谁放出了狗？！&#39;  所有标有 ERR 的都无法编码​​并解码为相同的字符串。    提交人    /u/mtasic85   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6dc8l/r_limitations_in_mainstream_llm_tokenizers/</guid>
      <pubDate>Fri, 18 Oct 2024 08:35:43 GMT</pubDate>
    </item>
    <item>
      <title>医学成像人工智能顶级会议 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6bu6z/top_conferences_for_ai_in_medical_imaging_d/</link>
      <description><![CDATA[抱歉，标题中不能有“AGI”。 我正在研究我的第一篇第一作者研究，我的导师认为它的发展方向很好。我真的希望它明年能通过一些好的会议。 我知道 MICCAI 和 MIDL，但找不到可靠的来源来检查 2025 年与医学成像或医学 AI 相关的所有其他会议。我希望这里的人一定有一些其他经验。有什么建议吗？ 另外，研讨会论文是什么意思？我知道它不叫真正的出版物，但它值得提交给一个备受推崇的研讨会还是一个中等排名的会议？ 提前谢谢！    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6bu6z/top_conferences_for_ai_in_medical_imaging_d/</guid>
      <pubDate>Fri, 18 Oct 2024 06:37:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 2.5.0 发布！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g62vyh/d_pytorch_250_released/</link>
      <description><![CDATA[https://github.com/pytorch/pytorch/releases/tag/v2.5.0 亮点：我们很高兴地宣布 PyTorch® 2.5 的发布！此版本为 SDPA 提供了新的 CuDNN 后端，默认情况下，为 H100 或更新 GPU 上的 SDPA 用户启用加速。此外，torch.compile 的区域编译提供了一种减少 torch.compile 冷启动时间的方法，它允许用户编译重复的 nn.Module（例如 LLM 中的转换器层）而无需重新编译。最后，TorchInductor CPP 后端通过 FP16 支持、CPP 包装器、AOT-Inductor 模式和最大自动调谐模式等众多增强功能提供了可靠的性能加速。此版本由 504 位贡献者自 PyTorch 2.4 以来的 4095 次提交组成。我们衷心感谢我们敬业的社区所做的贡献。 我最喜欢的一些改进：  通过重复使用重复模块加快 torch.compile 编译速度 torch.compile 支持 torch.istft FlexAttention：一种灵活的 API，只需几行惯用的 PyTorch 代码即可实现各种注意机制，如滑动窗口、因果掩码和 PrefixLM。此 API 利用 torch.compile 生成融合的 FlashAttention 内核，从而消除了额外的内存分配并实现了与手写实现相当的性能。此外，我们使用 PyTorch 的自动求导机制自动生成向后传递。此外，我们的 API 可以利用注意力掩码中的稀疏性，从而比标准注意力实现有显著的改进。     提交人    /u/parlancex   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g62vyh/d_pytorch_250_released/</guid>
      <pubDate>Thu, 17 Oct 2024 22:11:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 13 Oct 2024 02:15:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>