<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 20 Jan 2025 15:17:19 GMT</lastBuildDate>
    <item>
      <title>[R] 生成视频模型是否通过观看视频来学习物理原理？还没有</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5rcqn/r_do_generative_video_models_learn_physical/</link>
      <description><![CDATA[生成视频模型物理理解的新基准，用于测试 Sora、VideoPoet、Lumiere、Pika、Runway 等模型。作者表示：“我们发现，在一系列当前模型（Sora、Runway、Pika、Lumiere、Stable Video Diffusion 和 VideoPoet）中，物理理解受到严重限制，并且与视觉真实感无关” 论文：https://arxiv.org/abs/2501.09038    提交人    /u/Least_Light6037   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5rcqn/r_do_generative_video_models_learn_physical/</guid>
      <pubDate>Mon, 20 Jan 2025 14:29:13 GMT</pubDate>
    </item>
    <item>
      <title>针对面部/肤色进行预训练的模型？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5pk0d/pretrained_models_on_facesskin_tones_d/</link>
      <description><![CDATA[我正在做一个涉及 rPPG 的项目，我想知道是否有任何好的针对面部/肤色的预训练模型可以供我构建。 谢谢    提交人    /u/ThePresindente   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5pk0d/pretrained_models_on_facesskin_tones_d/</guid>
      <pubDate>Mon, 20 Jan 2025 12:56:38 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 如何在没有预定义实体的情况下从全文构建知识图谱？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5mku4/discussion_how_to_build_a_knowledge_graph_from/</link>
      <description><![CDATA[我正在从大量没有预定义实体的行业文档中构建知识图谱。如何有效地处理语义上重复的实体和关系？此外，由于我无法一次处理所有文档，如何在分块处理时确保提取的关系的一致性？ PS - 将使用 GPT 进行处理    提交人    /u/OnlyBadKarma   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5mku4/discussion_how_to_build_a_knowledge_graph_from/</guid>
      <pubDate>Mon, 20 Jan 2025 09:36:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama3.2模型添加种族注释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5mk5e/d_llama32_model_adds_racial_annotation/</link>
      <description><![CDATA[      这真的很有趣，我正在与 Llama 3.2 3B 模型交谈，我发现它会根据您的名字自动附加或问候您。也许其他人已经知道这一点，但我刚刚才注意到这个细节。可能是因为训练数据集，或者是注入的。 看看这个 编辑：添加种族注释并不是为了对此产生负面影响，这只是一个观察结果，即称呼是根据名称定制的。这是对细节的关注    提交人    /u/randykarthi   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5mk5e/d_llama32_model_adds_racial_annotation/</guid>
      <pubDate>Mon, 20 Jan 2025 09:35:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 培养更深层次的法学硕士思维</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5i073/r_evolving_deeper_llm_thinking/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5i073/r_evolving_deeper_llm_thinking/</guid>
      <pubDate>Mon, 20 Jan 2025 04:23:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找根据真实文档和查询构建的检索数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5h6n6/r_looking_for_retrieval_datasets_built_from_real/</link>
      <description><![CDATA[以 (query, passage) 对的形式进行检索，其中 passage 是与 query 相关的文档中的一段文本。 BeIR 有很好的数据集，但“文档”通常很宽泛，例如任何 Wikipedia 或 PubMed 文章。我正在寻找一个文档更集中的数据集，比如 scikit-learn 的文档。 StaRD 是一个高质量的数据集，但对于我的目的来说，它没有足够的查询。理想情况下，有 ≥5k 个唯一查询。    提交人    /u/KD_A   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5h6n6/r_looking_for_retrieval_datasets_built_from_real/</guid>
      <pubDate>Mon, 20 Jan 2025 03:37:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找具有自定义列视图的 NLP 注释工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5dizh/d_looking_for_nlp_annotation_tool_with_custom/</link>
      <description><![CDATA[大家好！我正在开展一个需要 NLP 数据注释的文档修订项目。我需要一个可以做到以下事情的工具：  在标准表格视图中显示数据集 在自定义列中显示源文本和修订文本之间的 git 样式差异  我已经尝试过 Argilla 和 Label Studio，但它们都不支持自定义列。有谁知道提供此功能的注释工具吗？ 提前致谢！    提交人    /u/V0dros   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5dizh/d_looking_for_nlp_annotation_tool_with_custom/</guid>
      <pubDate>Mon, 20 Jan 2025 00:24:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 开放模式的案例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5azv1/d_the_case_for_open_models/</link>
      <description><![CDATA[      为什么开放性对人工智能如此重要    由    /u/Amgadoz 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5azv1/d_the_case_for_open_models/</guid>
      <pubDate>Sun, 19 Jan 2025 22:27:21 GMT</pubDate>
    </item>
    <item>
      <title>有没有什么礼物可以送给 ML 爱好者？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i58qk2/any_gift_ideas_for_someone_into_ml_d/</link>
      <description><![CDATA[大家好，我需要帮助，想为真正热衷于机器学习和相关领域并正在从事研究/职业的人准备一份特别的礼物。  我对机器学习知之甚少，但我仍然想为他们买一些非常酷或对他们的工作很实用的东西。从为他们买一台专门用于工作的新电脑到一些很酷的收藏品，什么都可以。任何包括为我指明正确方向的东西都会很感激，谢谢！    提交人    /u/Usernam3ChecksOuts   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i58qk2/any_gift_ideas_for_someone_into_ml_d/</guid>
      <pubDate>Sun, 19 Jan 2025 20:53:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2024 年值得关注的 LLM 研究论文（第二部分）：7 月至 12 月</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i51cks/p_noteworthy_llm_research_papers_of_2024_part_two/</link>
      <description><![CDATA[        由    /u/seraschka 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i51cks/p_noteworthy_llm_research_papers_of_2024_part_two/</guid>
      <pubDate>Sun, 19 Jan 2025 15:46:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 MLP 进行语音识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4rz3r/p_speech_recognition_using_mlp/</link>
      <description><![CDATA[所以我们有这个任务，我们必须对音频文件中所说的单词进行分类。我们只能使用频谱图作为输入，并且只能使用简单的 MLP，没有 cnn。输入特征约为 16k，宽度限制为 512，深度为 100，我们选择任何激活函数。我们尝试了很多架构，有 2 或 3 层，有和没有 dropout，有和没有 batch normal，但我们能找到的最佳 val 准确率是 47%，有 2 层 512 和 256，没有 dropout，没有 batch normal 和 SELU 激活函数。我们需要 80+ 才能保存任何值。有人可以建议一个不会过度拟合的好架构吗？    提交人    /u/Dariya-Ghoda   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4rz3r/p_speech_recognition_using_mlp/</guid>
      <pubDate>Sun, 19 Jan 2025 06:06:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 19 Jan 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于博士级 ML 重点编程课程的主题有什么建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4ltt6/d_suggestions_for_topics_for_a_phd_level_ml/</link>
      <description><![CDATA[一些背景：我在一家小型初创公司担任数据科学家/ML 工程师。我还在获得博士学位（统计学）的部门兼职。 在过去的几年里，我一直在为硕士生和早期博士生教授一系列统计编程课程。这个学期，我的课程不幸被取消了，因为报名人数少，我被告知这是由于去年秋天招聘不力和广告宣传不佳。我们正考虑每隔一年开设这门课程。我想提议在该系列中开设第三门课程，其中包含更高级的主题。 第一门课程：R 和 Python 的编程基础。每个课程都有一些基本的分析内容。 第二门课程：基于 Python 的分析课程（已经有很多 R 课程），涉及从基础到混合建模和贝叶斯分析的统计例程。此外，我们还将使用 PyTorch 以及一些基于转换器的应用程序来研究经典模型。还可以研究一些可解释的 AI 技术  第三门课程：优化、变分推理、其他贝叶斯深度学习方法、MLops 概念、???? 问题是我需要研究大量随机方法，因为毕竟这是一个统计部门。  希望这很清楚。我想提供相关信息，特别是向那些希望走在最前沿的博士生，重点是实验和实施。我知道有很多东西可以做，但在工作中我需要专注于我的具体任务。 非常感谢您的建议！    提交人    /u/Annual-Minute-9391   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4ltt6/d_suggestions_for_topics_for_a_phd_level_ml/</guid>
      <pubDate>Sun, 19 Jan 2025 00:37:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我讨厌softmax</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i44h5v/d_i_hate_softmax/</link>
      <description><![CDATA[这是一个半开玩笑的说法，核心概念相当简单，但我相信社区会引用大量证据来支持和驳斥 softmax 很烂的说法，并真正使其成为一场严肃而有趣的讨论。 什么是 softmax？它是应用元素指数函数并通过激活总和进行归一化的操作。它直观地做了什么？一点是输出总和为 1。另一点是，相对较大的输出相对于较小的输出变得更大：大激活和小激活被分开。 一个问题是，如果输入是有限的，您永远不会得到零输出（例如，如果没有掩码，您就不能将 0 注意力归因于某些元素）。让我抓狂的是，对于大多数应用，幅度和幅度比率是有意义的，但在 softmax 中它们不是：softmax 关心差异。以 softmax([0.1, 0.9]) 和 softmax([1,9]) 或 softmax([1000.1,1000.9]) 为例。您认为哪个相等？在哪些应用中这是更自然的方式？ 数值不稳定性、奇怪的梯度、嵌入规范都是受此类简单核心影响的事物。当然，与此同时，softmax 是深度学习的主力之一，它做得相当不错。 还有其他人也这么讨厌我吗？有人热衷于在我眼中挽回 softmax 吗？    提交人    /u/Sad-Razzmatazz-5188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i44h5v/d_i_hate_softmax/</guid>
      <pubDate>Sat, 18 Jan 2025 10:05:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>