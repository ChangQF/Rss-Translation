<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 22 Sep 2024 03:22:30 GMT</lastBuildDate>
    <item>
      <title>[D] 4x 4090 vs JAX 中的 H100</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmiunf/d_4x_4090_vs_h100_in_jax/</link>
      <description><![CDATA[有人有过使用多 GPU JAX 的经验吗？我知道有一篇指南讨论了数据并行，但如果在某个时候我想微调一个无法容纳 24GB 的大型模型（例如 LLM 或大型视觉模型）怎么办？有人能详细说明 JAX 中数据分片和模型分片对实际性能的影响吗？在这些情况下，4x 4090/5090 设置是否会比 H100 慢很多？JAX 中的模型/数据分片是否会产生很大的开发时间开销？似乎还有多种途径可以实现并行性。在实践中，大多数人倾向于使用“pmap”、分片还是其他方法？ 我的研究倾向于专注于 RL，因此我不确定 H100 的 HBM 是否与 transformer / LLM 一样重要。    提交人    /u/smorad   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmiunf/d_4x_4090_vs_h100_in_jax/</guid>
      <pubDate>Sun, 22 Sep 2024 02:14:54 GMT</pubDate>
    </item>
    <item>
      <title>[D]除了美国和中国之外，人工智能模型发展排名前三的国家是哪些？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fme9af/dwhat_are_the_top_3_countries_in_development_of/</link>
      <description><![CDATA[毫无疑问，美国和中国在大型语言模型的发展中处于领先地位。其他国家表现如何？    提交人    /u/Realistic-Ad-6231   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fme9af/dwhat_are_the_top_3_countries_in_development_of/</guid>
      <pubDate>Sat, 21 Sep 2024 22:09:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 文本到视频的传播：调查视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmcwqj/d_text_to_video_diffusion_a_survey_video/</link>
      <description><![CDATA[      分享我制作的一段 YT 视频，介绍用于训练文本到视频传播模型的最新架构和算法……介绍了过去几年的开创性论文/方法，如 VDM、Make A Video、Imagen、Video LDM、CogVideo、DiffusionTransformers、SORA 等。希望你们喜欢！在视频上点赞对频道有帮助，所以我会加倍感激。    提交人    /u/AvvYaa   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmcwqj/d_text_to_video_diffusion_a_survey_video/</guid>
      <pubDate>Sat, 21 Sep 2024 21:04:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] RL 中 LTL 的当前状态如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fma5v3/d_what_is_the_current_state_of_ltl_in_rl/</link>
      <description><![CDATA[  由    /u/jthat92  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fma5v3/d_what_is_the_current_state_of_ltl_in_rl/</guid>
      <pubDate>Sat, 21 Sep 2024 18:57:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于嵌入和文本分类的简洁开源 CLI（我们位于 Hacker News 的顶端！）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fm8bdi/p_a_nofrills_opensource_cli_for_embeddings_and/</link>
      <description><![CDATA[   aiq 可让您使用单个 CLI 命令通过语言模型 API 自动标记文本数据并在标签上训练有效的分类器。训练和推理速度超快（均在 CPU 上运行） 请参见此处：https://github.com/taylorai/aiq https://i.redd.it/sfphp9s877qd1.gif    提交人    /u/Different-General700   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fm8bdi/p_a_nofrills_opensource_cli_for_embeddings_and/</guid>
      <pubDate>Sat, 21 Sep 2024 17:33:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 稳健的文本分类：分析基于原型的网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fm05l8/r_robust_text_classification_analyzing/</link>
      <description><![CDATA[  由    /u/Megixist  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fm05l8/r_robust_text_classification_analyzing/</guid>
      <pubDate>Sat, 21 Sep 2024 10:40:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] PerpetualBooster：改进了多线程和分位数回归支持</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flznxo/p_perpetualbooster_improved_multithreading_and/</link>
      <description><![CDATA[PerpetualBooster v0.4.7：多线程和分位数回归 很高兴宣布发布 PerpetualBooster v0.4.7！ 此更新通过多线程支持带来了显着的性能改进，并增加了分位数回归任务的功能。PerpetualBooster 是一种无需超参数调整的 GBM 算法，可简化模型构建。与 AutoML 类似，使用单个“预算”控制模型复杂性参数，以提高对看不见的数据的性能。 易于使用：python from perpetual import PerpetualBooster model = PerpetualBooster(objective=&quot;SquaredLoss&quot;) model.fit(X, y, budget=1.0)  安装：pip install perpetual Github repo：https://github.com/perpetual-ml/perpetual    提交人    /u/mutlu_simsek   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flznxo/p_perpetualbooster_improved_multithreading_and/</guid>
      <pubDate>Sat, 21 Sep 2024 10:05:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 热点课题的研究人员如何跟上？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flz1vo/d_how_do_researchers_in_hot_topics_keep_up/</link>
      <description><![CDATA[昨天晚上，我在阅读 Deepmind 的“通过强化学习训练语言模型进行自我纠正”(https://arxiv.org/abs/2409.12917)，该论文于 2 天前发布。这篇论文是关于使用 RL 预训练 LLM，但这与我的问题无关。 这篇论文很有趣，但我在阅读时想知道：他们怎么有时间做那里提到的所有事情？我的意思是：  根据所使用的预训练模型，他们很可能在 2-3 个月前才开始研究它 大多数参考文献和引文来自 2024 年下半年（从 5 月到 6 月开始），因此不到 3 个月  因此，在这几个月中，他们必须：阅读并彻底研究所有引用的论文（在这种情况下大约有 45 篇，并且再次强调：其中大多数都是非常新的），提出新的想法，开发它，进行实验（如今 SFT 也不是 15 分钟的事），汇编结果，并撰写实际论文。并且这假设他们没有同时研究其他论文/工作…… 作为一名单独的研究人员，我甚至无法想象在这段时间内做类似的事情，但即使在一个小团队中，我也发现这几乎是不可能的。我的一天只有 24 小时，但感觉研究界的其他人可以暂停时间以完成更多工作。 我是效率低下还是愚蠢？要完全理解一篇新颖的论文，我可能需要一两天的时间（每天 6 小时）来重现、推导所有（或大部分）数学运算并更深入地了解它为什么有效/无效。 非常感谢任何见解，谢谢！    提交人    /u/bgighjigftuik   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flz1vo/d_how_do_researchers_in_hot_topics_keep_up/</guid>
      <pubDate>Sat, 21 Sep 2024 09:19:17 GMT</pubDate>
    </item>
    <item>
      <title>纯 Torch 中的潜在扩散（无 huggingface 依赖）[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flxs7d/latent_diffusion_in_puretorch_no_huggingface/</link>
      <description><![CDATA[去年我一直在研究扩散，我决定发布一个软件包，其中包含我从头开始实现的 DDPM 潜在扩散模型。它包括用于嵌入图像的去噪 UNet 和 VAE+GAN 的实现。 这是纯粹的火炬，因为我发现 Huggingface 扩散器适合简单的任务，但如果你想了解内部工作原理或稍微破解模型，它就不够了，因为代码库非常庞大，并且不适用于组件的可重用性（但我坚持认为它是一个很好的库）。要安装它，只需运行 pip install tiny-diff 我的目标是创建一个可重复使用的实现，前向方法中没有任何 if（尽可能地压缩多态性，以使前向尽可能清晰）和模块化组件（因此，如果您不想使用整个模型，而是使用其中的一部分，您可以抓住您想要的） Repo 链接：https://github.com/AlejandroBaron/tiny-diff    提交人    /u/AIlexB   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flxs7d/latent_diffusion_in_puretorch_no_huggingface/</guid>
      <pubDate>Sat, 21 Sep 2024 07:44:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] GRIN：基于梯度的 MoE</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flhndi/r_grin_gradientinformed_moe/</link>
      <description><![CDATA[路由输出离散变量，如何估计其梯度进行混合专家训练？ https://arxiv.org/pdf/2409.12136 相关背景：https://arxiv.org/abs/2304.08612    提交人    /u/Lucas_LLL   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flhndi/r_grin_gradientinformed_moe/</guid>
      <pubDate>Fri, 20 Sep 2024 17:31:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 创造力仅来自强化学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flbmde/d_creativity_only_comes_from_reinforcement/</link>
      <description><![CDATA[Ilya 发表了一次有趣的演讲，谈到了 RL 在 LLM 或任何 AI 系统（例如国际象棋的 AlphaZero）形成创造性反应方面的作用。我想知道这是真的吗？我认为简单地在 SFT 之类的数据点之间进行插值也会很有创意。 讨论链接：https://www.youtube.com/watch?v=OPZxs6IXH00&amp;list=PLpvkFqYJXcreXgK6Cg9NVGvFANmdUczWa （第 14 分钟：00）    提交人    /u/CriticalTemperature1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flbmde/d_creativity_only_comes_from_reinforcement/</guid>
      <pubDate>Fri, 20 Sep 2024 13:09:35 GMT</pubDate>
    </item>
    <item>
      <title>叠加、相图与正则化 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flazmd/superposition_phase_diagrams_and_regularization_d/</link>
      <description><![CDATA[      大家好！我正在阅读 Anthropic 的叠加玩具模型，我强烈推荐。作者展示了小型神经网络的相图，包括理论和经验版本。然而，他们在分析中没有应用任何形式的正则化，这激起了我对叠加效应的好奇心。这激发了我尝试这个概念。 我发现这些想法非常有趣，所以我写了一篇博客文章来分享我的想法。你可以在这里查看。 虽然我的结果不如 Anthropic 得到的结果那么清晰，但我相信它们仍然值得分享。我很乐意听到您的反馈！ 以下是我帖子的要点： 我们从一个非常简单的神经网络开始： https://preview.redd.it/7okwz6njlypd1.png?width=237&amp;format=png&amp;auto=webp&amp;s=e0f39f6e7e903d9573cb432d20ff0479131e05dc 我们进行训练以尽量减少以下重建损失： https://preview.redd.it/ftk5l5nklypd1.png?width=410&amp;format=png&amp;auto=webp&amp;s=960ba69bb3b1de21d2f8b73d3a6588fb5cf3ac66 这里，λ 表示正则化强度，x_i 是输入特征，r_i 表示每个特征的相关性。每个特征都是 0 到 1 之间的数字。此外，我们引入了一个稀疏项 s。给定 s，我们将每个特征设置为 0，概率为 s。 假设我们只有两个特征，用一个数字编码（因此，(W = [w_1, w_2]))。网络的选择数量有限：  设置 w_1 = 0 和 w_2 = 0，最小化 L2 正则化。 设置 w_1 = 1 和 w_2 = 0，仅对第一个特征进行编码。 设置 w_1 = 0 和 w_2 = 1，仅对第二个特征进行编码。 设置 w_1 = 1 和 w_2 = -1（或 w_2 = -1 和 w_1 = 1），叠加两个特征。  接下来，我进行了几项实验，改变了稀疏性、正则化强度和第二个特征的相关性（例如，当 r_2 = 0 时，第二个特征可能不相关，而当 r_2 = 5 时，第二个特征的相关度可能是第一个特征的五倍）。此 GIF 显示了实验结果：  https://i.redd.it/do8erlkmlypd1.gif 我还通过计算四种情景中的每种情景的预期损失创建了相图的理论版本，我还将两个 gif 并排放在一起进行比较：  https://i.redd.it/d81150snlypd1.gif 如您所见，理论版本与经验版本有些匹配。虽然它并不完美，但正则化的效果是显而易见的；它阻止了特征的叠加。当您考虑到 (W = [-1, 1]) 的范数肯定大于 (W = [0, 1]) 或 (W = [1, 0]) 时，这是有道理的。 您觉得如何？您对改进这些数字有什么建议吗？我很想听听您的想法！    提交人    /u/f14-bertolotti   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flazmd/superposition_phase_diagrams_and_regularization_d/</guid>
      <pubDate>Fri, 20 Sep 2024 12:38:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我觉得自从 LLM API 成为现实以来，有关 ML 和 ML 产品的讨论质量急剧下降。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl5be0/d_i_feel_like_ever_since_llm_apis_have_become_a/</link>
      <description><![CDATA[完成硕士学位后，过去几年一直担任 MLE，目前在一家拥有非常聪明的同事的公司工作。问题是，我的公司没有资源来培训我们自己的 LLM，因此不得不求助于使用各种 API 来建立模型。 关于如何改进我们产品的讨论通常感觉没有成效且毫无意义。它通常会诉诸于“我们如何通过快速工程让这个 LLM（我们甚至无法控制）做这件事？” 我个人甚至不认为“快速工程”是可靠或真实的事情，并且感觉因为大多数讨论都归结于此，感觉我们也无法真正增强我们的产品。 只是想知道是否有人有同样的感受。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl5be0/d_i_feel_like_ever_since_llm_apis_have_become_a/</guid>
      <pubDate>Fri, 20 Sep 2024 06:06:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>