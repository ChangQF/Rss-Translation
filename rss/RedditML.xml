<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 23 Dec 2024 12:32:44 GMT</lastBuildDate>
    <item>
      <title>[D]Gpt 1 培训</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkm94r/dgpt_1_training/</link>
      <description><![CDATA[Gpt 1 训练  有人能告诉我训练 GPT 1 花了多长时间、使用了多少 gpu 以及进行了多少个 epoch 吗    提交人    /u/notanhumanonlyai25   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkm94r/dgpt_1_training/</guid>
      <pubDate>Mon, 23 Dec 2024 11:58:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何让我的 Pyannote 说话人二值化模型忽略语音上重叠的噪音。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hklxqq/p_how_can_i_make_my_pyannote_speaker_diarizartion/</link>
      <description><![CDATA[嗨，我目前正在开展一个说话人分类项目，作为预处理步骤，我使用 VAD 并重新创建音频，但在没有说话人说话时使用空值。这很好，直到模型将说话人部分中的噪音识别为说话人之一，并将两个说话人错误分类为同一个说话人，将噪音错误分类为说话人之一。（我使用了 min_speakers = 1 和 max_speakers = 2）。该怎么办？我尝试在 vad 处理的音频上使用 noisereduce 和 deepfilternet，但没有任何改进。    提交人    /u/YogurtclosetAway7913   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hklxqq/p_how_can_i_make_my_pyannote_speaker_diarizartion/</guid>
      <pubDate>Mon, 23 Dec 2024 11:36:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们是否将其他增强技术应用于过采样数据？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkl07r/d_do_we_apply_other_augmentation_techniques_to/</link>
      <description><![CDATA[假设您的数据集中多数类别相对于少数类别的流行程度相当高（与其余类别相比，多数类别占数据集的 48%）。 如果我们在一个类别中有 5000 张图像，并且我们对数据进行过采样，使少数类别现在与多数类别（5000 张图像）匹配，然后应用增强技术，如随机翻转等。这不会使数据集大幅增加吗？因为我们会通过过采样创建重复项，然后通过其他增强技术创建新样本？ 或者我可能是错的，我只是对我们是否进行过采样并应用其他增强技术或增强是否足够感到困惑    提交人    /u/amulli21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkl07r/d_do_we_apply_other_augmentation_techniques_to/</guid>
      <pubDate>Mon, 23 Dec 2024 10:28:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 访问学生或行业实习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkiced/d_visiting_student_or_industry_internship/</link>
      <description><![CDATA[我的导师让我选择一个未来方向（学术或研究科学家）。但他建议我只能选择 1 个行业实习或成为 1 所一流大学的访问学生（看起来他对顶级大学的访问学生有点偏见）。就我个人而言，我喜欢研究，但低工资让我有点害怕，而且与成为顶级大学的访问学生相比，实习似乎对简历具有普遍价值，所以目前成为一名研究科学家对我来说更可取。但我的导师认为，只要我有良好的研究背景，即使没有行业实习，进入行业也不会很困难。有人可以给我一些建议吗？    提交人    /u/Competitive_Newt_100   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkiced/d_visiting_student_or_industry_internship/</guid>
      <pubDate>Mon, 23 Dec 2024 07:02:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我的 VideoAutoEncoder 更新现在接受不同时长的 240p 到 720p 的质量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hke5z6/p_my_videoautoencoder_update_now_accepts/</link>
      <description><![CDATA[      我对我的 VideoAutoEncoder 进行了全面更新，留下了一个新的自适应版本并留下了一些有趣的结果，这是其中之一，质量为 480p https://i.redd.it/72mh1ny5gi8e1.gif GitHub :b : https://github.com/Rivera-ai/VideoAutoEncoder    提交人    /u/F4k3r22   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hke5z6/p_my_videoautoencoder_update_now_accepts/</guid>
      <pubDate>Mon, 23 Dec 2024 02:37:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 LLM 进行超参数调整</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkd3rs/p_hyperparameter_tuning_with_llm/</link>
      <description><![CDATA[大家好！我一直在研究一种基于 LLM 的工具，旨在帮助进行超参数调整。现在，它会读取您的模型代码并根据您的特定模型和数据集建议量身定制的超参数范围，从而使初始调整过程变得更容易一些。  现在还为时过早，但我希望它可以节省时间并帮助指导调整过程。如果您正在研究模型并且厌倦了反复试验的阶段，我希望您尝试一下并让我知道您的想法或如何改进它！ 这是链接：演示。非常感谢任何反馈！    由   提交 /u/Maleficent_Ad5541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkd3rs/p_hyperparameter_tuning_with_llm/</guid>
      <pubDate>Mon, 23 Dec 2024 01:38:01 GMT</pubDate>
    </item>
    <item>
      <title>自动生成分类类别 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkc5d1/automated_generation_of_categories_for/</link>
      <description><![CDATA[因此，我可以使用 Bart 零样本分类来量化文章与预定义类别集的相关性，但我有很多文章，我想从中计算类别，然后使用这些类别对大量文章进行分类。 我想也许我可以使用文本嵌入将每篇文章转换为向量，然后使用无监督学习算法来计算相关文章的聚类，然后将这些组投影回文本，也许可以通过递归总结每个组中的文章来实现。但是，我实际上并不想要类别集必须不相交的约束，我认为 k-means 会施加这种约束。 还有什么其他方法可以实现这一点？    提交人    /u/PurpleUpbeat2820   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkc5d1/automated_generation_of_categories_for/</guid>
      <pubDate>Mon, 23 Dec 2024 00:46:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 任意节点大小的图形自动编码器，如何解码？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk7lje/r_graph_autoencoder_of_arbitrary_node_size_how_to/</link>
      <description><![CDATA[嗨！希望你一切顺利  我正在构建一个能够为任意大小的图生成嵌入的图自动编码器。我读过的大多数文献都集中在固定大小的节点图上，这并不完全符合我的要求。我发现的唯一相关工作是“学习用于生成图的 Graphon 自动编码器”，但我找不到他们提出的模型的任何实现。 编码部分似乎相对简单 - 您可以将其设计为输出固定大小的嵌入，而不管图的大小如何。然而，解码部分要棘手得多：您将如何设计解码器来处理可变大小的图？这个想法在实际意义上是否有意义？它看起来很复杂，但这样的模型可能非常有用。 我很感激任何关于这方面的见解、参考或建议！ 提前致谢！    提交人    /u/galerazo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk7lje/r_graph_autoencoder_of_arbitrary_node_size_how_to/</guid>
      <pubDate>Sun, 22 Dec 2024 20:59:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻求改进 NL2SQL 模型性能的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk42na/r_looking_for_suggestions_to_improve_nl2sql_model/</link>
      <description><![CDATA[大家好， 我正在为 NL2SQL 任务微调一个大型语言模型。我尝试过 BERT 和 CodeBERT，但这两个模型的表现都不如预期。虽然我的目标是在测试中达到 90% 以上的准确率，但我能达到的最好成绩是 在看不见的测试集上达到 84%，但在训练和验证中确实达到了 90% 以上的准确率。 上下文：  数据集大小：我的数据集很大，因此数据可用性不是限制。 当前模型：我使用过 BERT 和 CodeBERT。 挑战：这两种模型都很难有效地概括。  问题：  有没有人推荐适用于 NL2SQL 的替代模型（例如，专门的架构或微调模型）？ 有什么建议可以专门提高 CodeBERT 的准确率吗？例如： 额外的微调技术。 模型架构更改。 更好概括的策略。   任何建议都将不胜感激！ （此外，我没有从事 SQL 生成工作，而是从事 SQL 评估工作）谢谢！    提交人    /u/Aggravating-Bend-343   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk42na/r_looking_for_suggestions_to_improve_nl2sql_model/</guid>
      <pubDate>Sun, 22 Dec 2024 18:10:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用引导树搜索提出和解决奥林匹克几何问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjyg9z/r_proposing_and_solving_olympiad_geometry_with/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjyg9z/r_proposing_and_solving_olympiad_geometry_with/</guid>
      <pubDate>Sun, 22 Dec 2024 13:25:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调图像相似度模型（图像检索）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjxara/d_fine_tuning_a_model_for_image_similarity_image/</link>
      <description><![CDATA[嗨， 2020 年不久前，我使用深度度量学习对 CNN 进行了微调，使用的数据集包含 600 个类别的 100 万张图像。 我现在面临类似的问题，我需要一个模型来返回特定类型对象的语义相似图像。 我有大约 50 万张这些对象的图像，还可以获得更多。 我的问题是我没有明确定义的&quot;类&quot;，我有一些文本，我可以从中提取一些可以用作类的特征。 CLIP 似乎是一种可能性，但由于它非常重且 GPU 成本高昂，我想探索其他选项。 你们有人尝试过一些更复杂的程序吗？或者使用增强数据进行图像相似性工作？   由    /u/TechySpecky  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjxara/d_fine_tuning_a_model_for_image_similarity_image/</guid>
      <pubDate>Sun, 22 Dec 2024 12:09:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在 NeurIPS’24 上感受到了焦虑和沮丧（kyunghyuncho 博客）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</guid>
      <pubDate>Sun, 22 Dec 2024 02:22:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们最容易误解哪些机器学习概念？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</link>
      <description><![CDATA[我注意到某些 ML 概念（例如偏差-方差权衡或正则化）经常被误解。您认为哪个 ML 主题经常被误解，您如何向其他人解释它？    提交人    /u/AdHappy16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</guid>
      <pubDate>Sat, 21 Dec 2024 20:22:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>