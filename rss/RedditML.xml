<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 08 Jan 2024 15:13:58 GMT</lastBuildDate>
    <item>
      <title>[D] 研讨会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191nawt/d_workshops/</link>
      <description><![CDATA[我正在考虑在一个月内向 ICLR 研讨会提交论文，但我想知道顶级会议研讨会的接受率通常是多少。 我在此子中找到的只是 7 年前的帖子。   由   提交 /u/BigDreamx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191nawt/d_workshops/</guid>
      <pubDate>Mon, 08 Jan 2024 15:09:03 GMT</pubDate>
    </item>
    <item>
      <title>温湿度传感器故障/故障预测 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191m8i3/temperature_and_humidity_sensor_faultfailure/</link>
      <description><![CDATA[我拥有气象站 (Vaisala HMP155) 中使用的特定品牌传感器的 5 年温度和湿度读数数据集。每个数据点对应 10 分钟的观察。所以每个数据点有 2 列。我认为大约有 350-400k 的数据点或行。  存在诸如 999 之类的不稳定读数和明显不准确的负值。当他们看到这些读数时，就该去检查传感器并进行故障排除。  我如何利用这些数据来制定一种算法来检测这些故障，然后在实际再次发生故障之前预测或警告是否出现问题？比如寻找早期迹象...  我想制作某种警报系统，这样一旦传感器出现故障或出现故障，就不必进行维护。如果数据或模式有问题，他们就会收到通知...   由   提交 /u/Funny_Shoe1772   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191m8i3/temperature_and_humidity_sensor_faultfailure/</guid>
      <pubDate>Mon, 08 Jan 2024 14:18:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何猜测梯度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191lu3v/r_how_to_guess_a_gradient/</link>
      <description><![CDATA[      奇怪的是，你在不知道目标函数的情况下就知道梯度在哪里。 论文：https://arxiv.org/abs/2312.04709 摘要  关于梯度你能说多少无需计算损失或不知道标签的神经网络？这听起来可能是一个奇怪的问题：答案肯定是“很少”。然而，在本文中，我们表明梯度比之前想象的更加结构化。梯度位于可预测的低维子空间中，该子空间取决于网络架构和传入特征。利用这种结构可以显着改进基于方向导数的无梯度优化方案，该方案一直难以扩展到在玩具数据集上训练的小型网络之外。我们研究如何缩小计算精确梯度的方法和使用方向导数的方法之间优化性能的差距。此外，我们强调了克服精确梯度优化和猜测梯度之间巨大差距的新挑战。  https://preview.redd.it/l7tm982c28bc1.png?width=1962&amp;format=png&amp;auto=webp&amp;s=94d237353bc53ee b21489f6adeeaa8e43043f44a ​   由   提交/u/That_Violinist_18   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191lu3v/r_how_to_guess_a_gradient/</guid>
      <pubDate>Mon, 08 Jan 2024 14:00:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 欧洲博士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191kn35/d_phd_in_europe/</link>
      <description><![CDATA[欧洲国家被认为是攻读计算机科学与工程博士学位的好目的地（例如机器学习、计算机视觉、计算机图形学、量子计算、机器人技术） ）。但显然，有些人的需求更高（即接收最多的学生），并且在申请公开广告的博士职位或资助选项时，任何有关它的信息都可能有用。 那么，您在哪里做了或你正在攻读博士学位吗？也欢迎发表评论。 查看民意调查   由   提交/u/xrdts_99tx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191kn35/d_phd_in_europe/</guid>
      <pubDate>Mon, 08 Jan 2024 12:58:08 GMT</pubDate>
    </item>
    <item>
      <title>[研究]WebLLM - 去中心化人工智能可能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191jwjn/research_webllm_is_decentralized_ai_possible/</link>
      <description><![CDATA[我不是 AI 或 webGPU 方面的专家，但我对它有一点了解。 我对它的理解是一些东西例如：“AI 通常在 GPU 上使用，因为它需要多个 CPU”。 我正在开发一个具有去中心化 P2P 通信的项目 (https://positive-intentions.com/）。我正在使用 webRTC 进行 P2P 连接。这使得同行之间的通信速度更快（尤其是在同一 LAN 网络上）。 有一个项目可以使 LLM 在浏览器上运行 (https://webllm.mlc.ai/）。我已经测试过它并且它可以在我的应用程序中运行。它还可以以一种方式工作，即对等点（手机）可以向对等点（支持 webGPU 的台式计算机）发出请求，并将 AI 计算外包以获得响应。 （这可以解释为手机和桌面电脑之间的自托管人工智能）。 我想知道，人工智能的核心要求是否是拥有多个 GPU 并且可以连接到多个同行。是否可以在对等点之间拆分 AI 计算？ 我的应用程序应该允许发送“任何”数据同行之间的有效负载，但我不确定如何在同行之间分配人工智能的计算。 如果有人可以分享有关此事的任何指导，那么我可能会选择“弄清楚”。    由   提交 /u/Accurate-Screen8774    reddit.com/r/MachineLearning/comments/191jwjn/research_webllm_is_decentralized_ai_possible/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191jwjn/research_webllm_is_decentralized_ai_possible/</guid>
      <pubDate>Mon, 08 Jan 2024 12:14:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 是否存在仅适用于比较结果的贝叶斯优化的等效项？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191juun/p_is_there_an_equivalent_of_bayesian_optimization/</link>
      <description><![CDATA[大家好，我正在解决一个问题，我需要找到最佳参数集（其中 10 个）来优化一个非常昂贵的目标功能。通常，我会使用贝叶斯优化，但在这种特定情况下，我无法访问实际的目标函数，我唯一可以计算的是该函数在特定参数集 A 或 B 下是否更高。我不知道函数的实际值，也不知道它的导数。我所能做的就是比较两组参数，并判断哪一组产生的函数值较低。 关于我可以使用什么来找到最佳参数来优化该函数，有什么建议吗？&lt; /p&gt;   由   提交/u/ale152  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191juun/p_is_there_an_equivalent_of_bayesian_optimization/</guid>
      <pubDate>Mon, 08 Jan 2024 12:12:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些网站举办人工智能竞赛，类似于 Topcoder 的 Intellicase Bot (GPT) 挑战赛？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191jswe/d_which_websites_host_ai_competitions_similar_to/</link>
      <description><![CDATA[我正在寻找研发竞赛。   由   提交 /u/sivav-r   /u/sivav-r  reddit.com/r/MachineLearning/comments/191jswe/d_which_websites_host_ai_competitions_similar_to/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191jswe/d_which_websites_host_ai_competitions_similar_to/</guid>
      <pubDate>Mon, 08 Jan 2024 12:08:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 3090 与新 40 系列同等产品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191isia/d_3090_vs_the_new_40_series_equivalent/</link>
      <description><![CDATA[我发现了一些 3090（新）的优惠：  MSI（1260 美元） PALIT（965 美元） PALIT OC（900 美元）  我想知道 40 系列的较低型号（主要是 4070 和 4070 TI，因为 4080 远远超出了我的预算（需要升级电源）对于游戏/AI 与缺乏 V-RAM 来说是值得的  请注意卡的可用性和选择就我而言有限，另外，我的电源必须更换，因为它只是650W金牌（也开放电源升级建议）。 谢谢   由   提交 /u/myselfitself   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191isia/d_3090_vs_the_new_40_series_equivalent/</guid>
      <pubDate>Mon, 08 Jan 2024 11:06:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] Infinite-LLM：使用 DistAttention 和分布式 KVCache 实现长上下文的高效 LLM 服务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191iqxj/r_infinitellm_efficient_llm_service_for_long/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.02669 摘要：  大型语言模型（LLM）的快速增长已经成为基于云的法学硕士服务的增长的驱动力，这些服务现在是推进人工智能应用程序不可或缺的一部分。然而，LLM服务的动态自回归性质，以及支持超长上下文长度的需要，要求灵活分配和释放大量资源。这给设计基于云的LLM服务系统带来了相当大的挑战，低效的管理可能导致性能下降或资源浪费。为了应对这些挑战，本文引入了一种新颖的分布式注意力算法DistAttention，它将KV Cache分割成更小的、可管理的单元，从而实现注意力模块的分布式处理和存储。基于此，我们提出了DistKV-LLM，这是一种分布式LLM服务系统，可以动态管理KV缓存并有效地编排跨数据中心的所有可访问的GPU和CPU内存。这确保了云上的高性能法学硕士服务，可适应广泛的上下文长度。在具有 32 个 NVIDIA A100 GPU（配置为 2 到 32 个实例）的云环境中进行验证，我们的系统表现出 1.03-2.4 倍的端到端吞吐量改进，并且支持的上下文长度比当前状态长 2-19 倍-art LLM 服务系统，通过对上下文长度高达 1,900K 的 18 个数据集的广泛测试证明。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191iqxj/r_infinitellm_efficient_llm_service_for_long/</guid>
      <pubDate>Mon, 08 Jan 2024 11:03:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于自然语言的心灵社会中的头脑风暴</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191i9m7/r_mindstorms_in_natural_languagebased_societies/</link>
      <description><![CDATA[OpenReview（R0-FoMo Oral）：https://openreview.net/forum?id=zd2qE6BBdU arXiv：https://arxiv.org/abs/2305.17066 代码：https://github.com/mczhuge/NLSOM 摘要：  &lt;明斯基的“心灵社会”和“心灵社会”都是明斯基的“心灵社会”。以及施米德胡贝尔的《学会思考》激励大型多模态神经网络（NN）的不同社会通过在“头脑风暴”中互相采访来解决问题。基于神经网络的心智社会的最新实现由大型语言模型 (LLM) 和其他通过自然语言界面进行通信的基于神经网络的专家组成。在此过程中，他们克服了单一法学硕士的局限性，改进了多模态零样本推理。在这些基于自然语言的心智社会（NLSOM）中，新的代理（所有代理都通过相同的通用符号语言进行通信）可以轻松地以模块化方式添加。为了展示 NLSOM 的强大功能，我们组装了其中的几个（最多 129 名成员）并进行实验，利用其中的思维风暴来解决一些实际的 AI 任务：视觉问答、图像字幕、文本到图像合成、3D 生成、以自我为中心的检索、具体人工智能和基于通用语言的任务解决。我们将此视为拥有数十亿智能体（其中一些可能是人类）的更大 NLSOM 的起点。随着异质思维伟大社会的出现，许多新的研究问题突然变得对人工智能的未来至关重要。 NLSOM 的社会结构应该是什么样的？君主制而不是民主结构的优点是什么？如何利用神经网络经济原理来最大化强化学习 NLSOM 的总奖励？在这项工作中，我们确定、讨论并尝试回答其中一些问题。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191i9m7/r_mindstorms_in_natural_languagebased_societies/</guid>
      <pubDate>Mon, 08 Jan 2024 10:32:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于特征优先级排序的 ML 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191erp3/d_ml_models_for_feature_prioritization/</link>
      <description><![CDATA[是否有可用于功能优先级排序的 ML 模型？我们使用 ProductBoard，确定优先级或将每个反馈与影响指标联系起来是一件痛苦的事情，而且通常不准确。  想知道是否有一个模型可以类似于工厂等使用的其他工业工程模型。   由   提交/u/Ok_Law_3126   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191erp3/d_ml_models_for_feature_prioritization/</guid>
      <pubDate>Mon, 08 Jan 2024 06:38:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] V*：引导视觉搜索作为多模式法学硕士 (SEAL) 的核心机制 - 纽约大学 2023 - 在搜索视觉细节方面比 GPT-4V 好 25%！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191652a/r_v_guided_visual_search_as_a_core_mechanism_in/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2312.14135v2  Github：https： //github.com/penghao-wu/vstar  摘要：  当我们环顾四周并执行复杂任务时，我们如何看待并选择性地处理什么我们看到至关重要。然而，当前的多模态法学硕士（MLLM）缺乏这种视觉搜索机制，阻碍了他们专注于重要视觉细节的能力，特别是在处理高分辨率和视觉拥挤的图像时。为了解决这个问题，我们引入了 V*，一种 LLM 引导的视觉搜索机制，它利用 LLM 中的世界知识来进行高效的视觉查询。当与 MLLM 结合使用时，该机制可以增强协作推理、上下文理解以及特定视觉元素的精确定位。这种集成产生了一个新的 MLLM 元架构，名为 Show、sEArch 和 TelL (SEAL)。我们进一步创建了 V*Bench，这是一个专门设计用于评估 MLLM 处理高分辨率图像和关注视觉细节的能力的基准。 我们的研究强调了将视觉搜索功能纳入多模态系统的必要性。   https://preview.redd.it/0b78lih1r3bc1.jpg?width=1663&amp;format=pjpg&amp;auto=webp&amp;s=786702884305 88cfee2db280cb75e348254ec0eb https://preview。 redd.it/8kap1jh1r3bc1.jpg?width=1661&amp;format=pjpg&amp;auto=webp&amp;s=d6e8a372cd91976e6e35710d32992a443981f06e https://preview.redd.it/oakf3lh1r3bc1.jpg?width=1247&amp;format=pjpg&amp;auto=webp&amp;s=612ab61b763 254f5cabb3a93990cc5baa2a917e3&lt; /a&gt; https:// Preview.redd.it/mta8emh1r3bc1.jpg?width=653&amp;format=pjpg&amp;auto=webp&amp;s=209871901bf2ba26537b1587c4be388df055f30b   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191652a/r_v_guided_visual_search_as_a_core_mechanism_in/</guid>
      <pubDate>Sun, 07 Jan 2024 23:30:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么在机器学习中几乎所有的概率推导都如此难以遵循？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190to69/d_why_are_almost_all_probabilistic_derivations_so/</link>
      <description><![CDATA[      我认为自己非常擅长数学，甚至还教过大学生，活跃于ML 等领域。 然而，我发现大多数（如果不是全部）涉及 ML 中任何远程概率问题的论文都得到了残酷的解释。 最近我决定真的了解 OG [DDPM](https://arxiv.org/pdf/2006.11239.pdf) 论文。&lt; /p&gt; 这是推导的一部分，他们……以某种方式……插入了 KLD。我完全不清楚这个跳跃是如何进行的。是的，我看过 KLD 的定义，是的，我用谷歌搜索过，但每个人似乎都相信这一点。 ChatGPT 说“存在未显示的隐藏期望”。 https://preview.redd.it/glvvzcc351bc1.png?width=2014&amp;format=png&amp;auto=webp&amp;s=d4c95a5716c0b8113e9a3346b8f99e3c5 a3db919 有人知道吗？  ​ 更新：感谢大家的评论，我这里的结论是DDPM论文有一个错误，即上面的图像。  错误是因为它们显示外部期望没有被用完，而实际上它已经被用尽了。  我在 Calvin 的论文此处中找到了正确的推导过程。这是图像： ​ https://preview.redd.it/54o6592vj2bc1.png?width=2370&amp;format=png&amp;auto=webp&amp;s=78d089d3d5c183f286bac15d3e6 d38ed5fa4e37e 上面是正确的，而DDPM论文是错误的。  ​   由   提交 /u/Ayakalam   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190to69/d_why_are_almost_all_probabilistic_derivations_so/</guid>
      <pubDate>Sun, 07 Jan 2024 14:46:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 那么，曼巴大战变形金刚……炒作是真的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190q1vb/d_so_mamba_vs_transformers_is_the_hype_real/</link>
      <description><![CDATA[听到了有关序列建模模块新成员 Mamba 的所有讨论。据说它速度更快，可以更好地处理更长的序列，甚至在某些任务上优于 Transformer。但它真的是王位窃取者还是只是昙花一现？ 我的看法： 优点：Mamba 拥有高效的内存使用、随序列长度线性扩展以及令人印象深刻的性能语言和 DNA 建模。另外，它放弃了注意力机制，可能为更快的推理铺平道路。  弱点：仍处于早期阶段，因此 Mamba 在不同任务中的长期稳定性和表现仍有待观察。虽然它不需要关注，但它的状态空间方法对于某些人来说可能更难以掌握。  对于人工智能爱好者来说，曼巴只是下一个闪亮的玩具，还是序列建模中真正的范式转变？它会推翻强大的变形金刚，还是作为一种专门的工具并存？让我们听听您的想法！ https://arxiv.org/abs/2312.00752 &lt; /div&gt;  由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190q1vb/d_so_mamba_vs_transformers_is_the_hype_real/</guid>
      <pubDate>Sun, 07 Jan 2024 11:19:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>