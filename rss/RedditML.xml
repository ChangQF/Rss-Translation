<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 07 Jan 2025 15:59:28 GMT</lastBuildDate>
    <item>
      <title>[R] 我在星展银行的机器学习工程师面试经历</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvuidy/r_my_ml_engineer_interview_experience_at_dbs_bank/</link>
      <description><![CDATA[嗨，Redditors， 我最近参加了亚洲领先的金融机构之一星展银行的机器学习工程师职位的面试。这是一次紧张而又有益的经历，重点关注技术专业知识、领导力和业务影响。 该过程包括 5 个阶段： 1️⃣ 在线评估：Python、SQL 和逻辑推理。 2️⃣ 技术筛选：讨论项目、ML 概念和解决问题。 3️⃣ 高级技术面试：现场编码（例如，在 Spark 中构建管道、欺诈检测模型）。 4️⃣ 管理轮：行为和基于场景的问题（例如，管理模型漂移）。 5️⃣ 领导小组：展示 ML 项目并解决面向业务的问题。 关键要点： • 为现实世界的 ML 用例做好准备，例如欺诈检测和信用风险建模。 • 熟悉 PySpark、Docker 和云平台 (AWS/GCP) 等分布式工具。 • 使用 STAR 框架进行行为响应。 如果您正在准备 ML 面试或对该过程感到好奇，请在此处查看我的详细文章：星展银行 ML 工程师面试经历 让我知道您的想法或分享您自己的经历！😊    提交人    /u/Ok-Bowl-3546   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvuidy/r_my_ml_engineer_interview_experience_at_dbs_bank/</guid>
      <pubDate>Tue, 07 Jan 2025 15:55:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何预见量子计算将改变法学硕士/人工智能？您认为它会导致智能的大规模快速增长吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvubw3/d_how_do_you_forsee_quantum_computing_changing/</link>
      <description><![CDATA[或者这很愚蠢？让我听听你们的想法吧，孩子们。     提交人    /u/AromaticEssay2676   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvubw3/d_how_do_you_forsee_quantum_computing_changing/</guid>
      <pubDate>Tue, 07 Jan 2025 15:48:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果我们有学习率，为什么还需要正则化。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvsouv/d_why_do_we_need_regularization_if_we_have/</link>
      <description><![CDATA[我对这两个主题都了如指掌，但我想要一些确凿的证据或一些例子来说明正则化的好处。如果有的话，请分享    提交人    /u/TheOrangeBlood10   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvsouv/d_why_do_we_need_regularization_if_we_have/</guid>
      <pubDate>Tue, 07 Jan 2025 14:32:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对你来说，机器学习最吸引人的方面是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvqdvt/d_what_is_the_most_fascinating_aspect_of_machine/</link>
      <description><![CDATA[标题。您可以根据自己的意愿主观地解释这个问题。    提交人    /u/AromaticEssay2676   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvqdvt/d_what_is_the_most_fascinating_aspect_of_machine/</guid>
      <pubDate>Tue, 07 Jan 2025 12:30:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] ACL ARR 公开匿名预印本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvk8m0/d_acl_arr_public_anonymous_preprint/</link>
      <description><![CDATA[我将论文提交给 ARR 十二月周期并勾选了发布公开匿名预印本的复选框。三周后我仍然找不到预印本链接。有人知道我什么时候可以获得公开匿名预印本的链接吗？    提交人    /u/Master_Ocelot8179   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvk8m0/d_acl_arr_public_anonymous_preprint/</guid>
      <pubDate>Tue, 07 Jan 2025 05:18:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] NLP/LLM 中的优化技术是否也适用于基于 Transformer 的序列建模？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvj7fx/d_optimization_techniques_in_nlpllm_that_also/</link>
      <description><![CDATA[标题。 尝试集思广益，看看是否有可以在 NLP 用例中应用的技术可用于序列建模。 具体来说，我正在尝试优化推荐系统（用户表示建模）中使用的变压器。 到目前为止，我能想到的基本知识是：闪光注意、高效/线性变压器、融合核嵌入、用于训练/服务的混合精度/量化。 还有其他什么或其他论文浮现在脑海中吗？ 我认为主要问题有时是用户序列表示或 rec sys 之类的标记概念与 LLM 中的标记概念截然不同。我们还处理更稀疏的嵌入…… 提前致谢！    提交人    /u/Tough_Palpitation331   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvj7fx/d_optimization_techniques_in_nlpllm_that_also/</guid>
      <pubDate>Tue, 07 Jan 2025 04:19:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数学证明作为新颖推理的基准？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hveq4q/d_mathematical_proofs_as_benchmarks_for_novel/</link>
      <description><![CDATA[我不是专家，但我一直在密切关注关于 LLM 和推理的学术讨论，我认为没有足够的基准来展示推理，而不是简单地直接从训练数据中应用信息（在 CoT 的情况下是迭代的）。 理想的基准应具有 3 个属性：1. 清晰地展示新颖的推理，而不仅仅是解决难题或应用高级技术 2. 易于（或尽可能接近简单）验证推理的正确性和存在性 3. 易于控制训练或调整数据的污染 至于第 1 点，很明显，通常我们确保新颖推理的唯一方法是使用学术主题，因为新颖的推理是其主要目的 第 2 点在很多领域中都很难确定什么是正确性或推理，这是错误的选择，即使用历史背景和情节点列表进行推理文献？可能不是，但当这些是分析的关键部分时，你怎么能说清楚呢？当历史学家对青铜时代的一些文物的含义存在分歧时，我们怎么能说历史上什么是正确的呢？第 3 点还排除了许多在各种可能的训练材料中直接讨论的领域或其通用技术，因此无法整理没有污染的训练数据。 据我所知，唯一适合的问题类型是数学证明，具体来说，我们可以更容易地隔离证明中的新颖之处，更容易验证证明的正确性（1 位给出通过的专家可以检测到大多数主要错误，而答案不明确的团队则无法检测到），并确保训练数据既没有实际证明也没有直接证明步骤（我的理解是，o3 的前沿数学得分是由于迭代地找到已经存在并符合其当时知识的数学技术） 具体来说，我建议基准的最佳证明应该是非常重要的，需要发明新的数学（因此它肯定需要多步新颖的推理，并且长度足够长，而不仅仅是猜测），不再是最先进的（我们可以通过使用几乎肯定在证明相关问题之前不会拥有专家数学和手工挑选的数学，再加上通过在该领域进行进一步的概括，将很容易验证证明的替代方法的有效性），并且应该本质上更抽象，即抽象代数或群论或费马最后定理而不是微分方程技术，以便更少的现有技术直接应用 我怀疑，如果没有新颖的推理，任何答案都会以明显的方式出错并且容易被发现，并且任何只有细微错误的答案都很容易重试，只需在调整/训练中稍加改变即可正确 所以我想知道：这个想法是否完全合理？如果是这样，什么证明最好？    提交人    /u/nnnnnnnnnerdddd   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hveq4q/d_mathematical_proofs_as_benchmarks_for_novel/</guid>
      <pubDate>Tue, 07 Jan 2025 00:36:06 GMT</pubDate>
    </item>
    <item>
      <title>[P][D] 尽管安装了 cuda-compat，但 Cuda-torch 与旧驱动程序版本仍存在兼容性问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hv6zb4/pd_cudatorch_compatibility_issue_for_older_driver/</link>
      <description><![CDATA[您好， 我正在使用旧版本的 GPU 机器（因为我的办公室实际上没有更新操作系统和 GPU 驱动程序）。Nvidia 驱动程序版本为 470.233.xx.x，其 CUDA 版本为 11.4 过去几年，我只能使用 `torch==2.0.1`。但是，当我想为一个项目微调 Gemma 模型时出现了问题，该项目的最低要求是 torch&gt;=2.3。要运行它，我需要最新的 CUDA 版本和 GPU 驱动程序升级。 问题是我实际上无法更新任何东西。因此，我研究了 cuda-compat 方法，它是 R470 驱动程序的前向兼容层。我可以使用它来绕过要求吗？如果是这样，我的 torch2.5 仍然无法检测到任何 GPU 设备。  我需要帮助解决这个问题。拜托！    提交人    /u/The-Silvervein   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hv6zb4/pd_cudatorch_compatibility_issue_for_older_driver/</guid>
      <pubDate>Mon, 06 Jan 2025 19:10:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] Jensen 不等式的交互式几何可视化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hv5qoe/p_interactive_and_geometric_visualization_of/</link>
      <description><![CDATA[大家好， 上周我一直在学习 Jensen 不等式。我对互联网上给出的大多数代数解释都不满意。因此，我写了一篇解释几何可视化的文章，到目前为止我还没有看到过类似的解释。我使用交互式可视化来展示我在脑海中如何对其进行可视化。  以下是文章 https://maitbayev.github.io/posts/jensens-inequality/ 让我知道你的想法    提交人    /u/madiyar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hv5qoe/p_interactive_and_geometric_visualization_of/</guid>
      <pubDate>Mon, 06 Jan 2025 18:20:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于法学硕士的错误信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1huxrd2/d_misinformation_about_llms/</link>
      <description><![CDATA[还有人对 Reddit 评论中有关 LLM 的不良信息比例感到吃惊吗？对于任何高级主题来说，这都是危险的，但围绕 LLM 的讨论似乎已经完全偏离了轨道。老实说，我觉得这有点奇怪。不良信息被疯狂地点赞，而知情的评论最多只能被忽略。令我惊讶的不是这种情况正在发生，而是它如此持续地处于“自信错误”的领域    提交人    /u/HasFiveVowels   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1huxrd2/d_misinformation_about_llms/</guid>
      <pubDate>Mon, 06 Jan 2025 12:20:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 学习哪些（人类）语言？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hux0p0/d_what_human_languages_to_learn/</link>
      <description><![CDATA[嗨， 这不是典型的 LLM 末日论帖子，而是 ML 特定的职业讨论。  我热衷于学习新语言（人类口语），尤其是拉丁语和罗曼语。 想知道是否有语言可以为 ML 从业者带来有趣的机会。 是否存在非英语地区对 ML 从业者有需求，但熟练的母语从业者供应不足？    提交人    /u/Amgadoz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hux0p0/d_what_human_languages_to_learn/</guid>
      <pubDate>Mon, 06 Jan 2025 11:33:50 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 实数的嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1huvvqk/discussion_embeddings_for_real_numbers/</link>
      <description><![CDATA[大家好。我正在研究一个想法，在某个时候我遇到了一个实数序列。我需要学习每个实数的嵌入。到目前为止，我尝试将标量与可学习向量相乘，但它没有起作用（如预期的那样）。那么，有没有更有趣的方法可以做到这一点？ 谢谢    提交人    /u/Dry-Pie-7398   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1huvvqk/discussion_embeddings_for_real_numbers/</guid>
      <pubDate>Mon, 06 Jan 2025 10:15:15 GMT</pubDate>
    </item>
    <item>
      <title>自监督学习——n 球面上的测量分布 [D] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hurxls/selfsupervised_learning_measure_distribution_on/</link>
      <description><![CDATA[大多数自监督学习方法（SimCLR、MoCo、BYOL、SimSiam、SwAV、MS BYOL 等）使用 n 球面超球面，提取的特征（编码器 + 投影/预测头之后）分布在该超球面中。然后，损失函数使用分布在此超球面上的特征进行损失计算。 论文，例如：  通过超球面上的对齐和均匀性理解对比表示学习，Tongzhou Wang 等人；ICML 2020 将表示与基础对齐：一种新的自监督学习方法，Shaofeng Zhang 等人；CVPR 2022 重新思考自监督学习中的均匀性度量，Xianghong Fang 等人； ICLR 2024  其他人表明这些特征分布在每个类的 n 球面上。 我们可以通过哪些不同的方式测量这些嵌入特征在这个超球面上的分布？比如说，如果我从 ImageNet/CIFAR-100 数据集中随机选择一个类，我如何测量属于这个类的所有图像在这个 n 球面上的分布？    提交人    /u/grid_world   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hurxls/selfsupervised_learning_measure_distribution_on/</guid>
      <pubDate>Mon, 06 Jan 2025 05:33:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 05 Jan 2025 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>