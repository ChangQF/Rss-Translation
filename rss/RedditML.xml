<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Fri, 09 Aug 2024 18:19:57 GMT</lastBuildDate>
    <item>
      <title>[D] 错误代码嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eo64fw/d_error_code_embeddings/</link>
      <description><![CDATA[我遇到了一种特殊的问题。我需要嵌入错误代码，以便语义搜索生成关键字。我有错误代码的描述，我希望能够嵌入代码，以便具有相似描述的代码彼此靠近。这意味着我既可以找到彼此附近的代码，也可以找到与代码相关的关键字。 我考虑过三重态损失函数，嵌入锚点、正负代码和描述的组合，但似乎无法解决向量崩溃问题。 我也考虑过使用描述余弦相似度作为代码的“标签”。但结果有点糟糕。 有没有关于代码嵌入的工作？除了嵌入编程“代码”之外，我很难找到任何其他结果。   由    /u/DReicht  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eo64fw/d_error_code_embeddings/</guid>
      <pubDate>Fri, 09 Aug 2024 17:46:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] txv：ViT 的可解释性包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eo3s7h/p_txv_an_explainability_package_for_vits/</link>
      <description><![CDATA[txv 是一个视觉变换器可解释性包。它为视觉变换器提供了类似 CAM 的可视化效果。 pip install txv Github 存储库：https://github.com/LokeshBadisa/txv 主页：https://lokeshbadisa.github.io/txv/ 文档：https://lokeshbadisa.github.io/txv/api_reference 教程：https://lokeshbadisa.github.io/txv/tutorials   由    /u/Eage1823  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eo3s7h/p_txv_an_explainability_package_for_vits/</guid>
      <pubDate>Fri, 09 Aug 2024 16:12:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用传统机器学习算法进行预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eo0670/d_forecasting_using_traditional_ml_algo/</link>
      <description><![CDATA[嗨， 我是时间序列分析的新手，正在使用随机森林和 SVM 为网络数据建立模型。我想知道这些模型是否适合预测。目前，我已将目标向前移动了 5 步，以便每个目标值对应于前进 5 步的一个点。此方法可用作预测步骤。此外，我使用前 5 个值作为特征。您认为这是一种好方法吗？如果您有任何建议或示例，我将不胜感激。谢谢！    提交人    /u/dumbestindumb   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eo0670/d_forecasting_using_traditional_ml_algo/</guid>
      <pubDate>Fri, 09 Aug 2024 13:48:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 光学神经网络的完全前向模式训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eo00m5/r_fully_forward_mode_training_for_optical_neural/</link>
      <description><![CDATA[摘要：光学计算有望提高机器学习应用的速度和能源效率1，2，3，4,5,6。然而，目前有效训练这些模型的方法受到数字计算机上的计算机模拟的限制。在这里，我们开发了一种称为完全前向模式 (FFM) 学习的方法，它在物理系统上实现计算密集型训练过程。因此，大多数机器学习操作都可以在现场高效并行进行，从而减轻数值建模限制。在自由空间和集成光子学中，我们通过实验展示了给定网络规模下具有最先进性能的光学系统。FFM 学习表明，训练具有数百万个参数的最深光学神经网络可实现与理想模型相当的精度。它支持通过散射介质进行全光学聚焦，分辨率达到衍射极限；它还可以以超过千赫兹的帧速率并行成像隐藏在直接视线之外的物体，并且可以在室温下以弱至亚光子/像素的光强度进行全光学处理（5.40 × 1018- 每秒每瓦操作能效）。此外，我们证明 FFM 学习可以在没有分析模型的情况下自动搜索非厄米特异常点。 FFM 学习不仅有助于提高学习过程的速度，还可以推动深度神经网络、超灵敏感知和拓扑光子学等应用和理论领域的发展。 链接：https://www.nature.com/articles/s41586-024-07687-4 代码：https://zenodo.org/records/10820584    提交人    /u/ashz8888   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eo00m5/r_fully_forward_mode_training_for_optical_neural/</guid>
      <pubDate>Fri, 09 Aug 2024 13:41:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] Karpathy - “RLHF 只是勉强算是 RL”。你同意吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enzn87/d_karpathy_rlhf_is_just_barely_rl_do_you_agree/</link>
      <description><![CDATA[https://x.com/karpathy/status/1821277264996352246    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enzn87/d_karpathy_rlhf_is_just_barely_rl_do_you_agree/</guid>
      <pubDate>Fri, 09 Aug 2024 13:25:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2024 数据集和基准测试轨道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enzi7r/d_neurips_2024_dataset_benchmarking_track/</link>
      <description><![CDATA[大家知道评论什么时候会出来吗？    提交人    /u/BodybuilderJunior775   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enzi7r/d_neurips_2024_dataset_benchmarking_track/</guid>
      <pubDate>Fri, 09 Aug 2024 13:19:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 探索 Kolmogorov-Arnold 网络在分类中的局限性：对软件训练和硬件实现的见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enx9be/r_exploring_the_limitations_of_kolmogorovarnold/</link>
      <description><![CDATA[      TL;DR：在训练计算方面，MLP 远远优于 KAN效率 论文： https://arxiv.org/pdf/2407.17790 摘要：  Kolmogorov-Arnold 网络 (KAN) 是一种新型神经网络，由于能够以更高的准确性和互操作性替代人工智能 (AI) 中的多层感知器 (MLP)，因此最近获得了普及和关注。然而，KAN 评估仍然有限，无法提供特定领域的深入分析。此外，还没有对 KAN 在硬件设计中的实现进行研究，这将直接证明 KAN 在实际应用中是否真正优于 MLP。因此，在本文中，我们专注于使用四种不同类型的数据集验证 KAN 的分类问题，这是 AI 中常见但重要的主题。此外，还考虑了使用 Vitis 高级综合 (HLS) 工具的相应硬件实现。据我们所知，这是第一篇为 KAN 实现硬件的文章。结果表明，在高复杂度数据集中，KAN 无法在利用大量硬件资源的情况下实现比 MLP 更高的准确度。因此，MLP 仍然是实现软件和硬件实现准确度和效率的有效方法。  亮点：  除了 Dry Bean 数据集的训练时间外，其他三个数据集始终表明 KAN 需要比 MLP 长得多的训练时间，范围从 6.55 倍（151.4 vs 23.1 秒）到 36.68 倍（198.1 vs 5.4 秒）。[...] 除了 Wine 数据集外，MLP 的损失减少速度一直比 KAN 更快，损失值也更低。总体而言，在训练时间和损失减少方面，KAN 并不比 MLP 更好。 总体而言，KAN 未能表现出比 MLP 更高的准确率，并且 KAN 的符号公式表示在分类挑战中的表现甚至比 MLP 更差。此外，KAN 还需要开发人员在最后阶段投入大量时间和精力来创建符号公式。  [专门的硬件测试：]  这些结果表明，与 MLP 中的正常矩阵乘法相比，在硬件上实现符号公式需要更多的硬件资源。此外，当 KAN 模型的规模增加时，所需的硬件资源也会相应增加。  视觉亮点： GPU 训练 有利于 MLP 的损失差异可能非常大。不过，Wine 数据集的快速 KAN 收敛值得注意。该数据集只有 178 个示例，每个示例有 13 个特征 GPU 训练 FPGA 训练 代码： https://github.com/Zeusss9/KAN_Analysis     由   提交  /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enx9be/r_exploring_the_limitations_of_kolmogorovarnold/</guid>
      <pubDate>Fri, 09 Aug 2024 11:27:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 GPT4o 与 langchain/chroma 进行体育分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enuzlp/p_using_gpt4o_with_langchainchroma_for_sports/</link>
      <description><![CDATA[大家好，我正在做一个业余项目，该项目有助于对历史比赛进行体育分析，进而有助于体育博彩。目前我只专注于 MLB，因为我想看看用例会如何发展。 我第一次尝试使用 openai 端点并加载所有相关的 JSON 对象，并将它们与提示一起发送到 GPT，看看我得到了什么。最终，上下文大小变得太大，我遇到的问题是它很昂贵。不过，返回的提示实际上相当不错，并且与数据相关。 我的第二次尝试是使用 Chroma/LangChain/GPT4o 设置 RAG。我让它工作了，但答案似乎都非常不准确，而且非常模糊。我所拥有的任何数据都没有显示在我所询问的任何提示中，或者在提示中根本没有提到正在玩游戏的任何玩家，而且在询问特定游戏时，它一直提到错误的游戏/团队。我假设我可能需要稍微调整一下矢量存储，但不确定如何使用色度来做到这一点。 我的问题是，设置某种流程的最佳方法是什么？我的最终结果是，我希望使用我提供的历史数据来回复，以便根据给出的所有统计数据对游戏可能是什么样子做出假设，同时也为 GPT 也留下一些推断的空间。 我在这方面还很陌生，所以到目前为止这是一个学习过程；请耐心等待。    提交人    /u/Previous_Impact1597   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enuzlp/p_using_gpt4o_with_langchainchroma_for_sports/</guid>
      <pubDate>Fri, 09 Aug 2024 09:02:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关我的求职机器学习项目的反馈</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enuq7p/d_seeking_feedback_on_my_machine_learning_project/</link>
      <description><![CDATA[大家好， 我正在申请政治学博士前奖学金，专注于计算冲突研究，并且我已经开发了一个示例项目来展示我的技能。我将不胜感激您可能提供的任何反馈或建议。 项目名称：机器学习用于恐怖主义数据分类 目标：应用机器学习技术对与冲突相关的文本进行分类，并根据全球恐怖主义数据库中的历史数据预测冲突结果。 展示的技能：机器学习、特征工程、模型训练和评估。 项目链接： 机器学习用于 1970 年至 2020 年东南亚恐怖主义数据分类的  职位描述： 政治学博士前研究员 我特别想听听您对以下方面的反馈：  项目概述的清晰度和结构。 所用方法和技术的有效性。 任何可以加强此类应用项目的其他元素。  提前感谢您的时间和见解！    提交人    /u/Lemmeaskyouonething   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enuq7p/d_seeking_feedback_on_my_machine_learning_project/</guid>
      <pubDate>Fri, 09 Aug 2024 08:45:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 24 数据集跟踪评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ent5sa/d_neurips_24_dataset_track_reviews/</link>
      <description><![CDATA[数据集和基准轨道评论应该在延迟后的今天发布。 我确信与主轨道相比，我们对此的关注度要小得多，但这可以作为讨论主题:)    提交人    /u/medcanned   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ent5sa/d_neurips_24_dataset_track_reviews/</guid>
      <pubDate>Fri, 09 Aug 2024 06:56:39 GMT</pubDate>
    </item>
    <item>
      <title>[d] ReFT 的实际示例：14 分钟内在 Llama3 上完成表征微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enk8wm/d_practical_example_of_reft_representation/</link>
      <description><![CDATA[几周前，Arxiv ReFT 论文第一作者郑轩吴与 Oxen.AI 首席执行官 Greg Schoeninger 合作，深入探讨了 ReFT：表示微调。 在明天（星期五）的 AI Water Cooler 中，Oxen 实习生 Eric 将介绍： &quot;我如何在 14 分钟内使用 ReFT 对 Llama3 进行微调&quot; ReFT 的 TLDR：不是通过参数进行微调，而是在隐藏状态中插入表示来指导模型。 Eric 将展示早期 Arxiv Dive 的实际实现。 有用的细节：  AI Water Cooler 是深度技术不太正式、未经记录的空间 8 月 9 日星期五，太平洋时间上午 10:00 定期日历邀请：https://oxen.ai/community YouTube https://youtu.be/to2oKwnknUk?si=LmMMYxoryOn0UCwh Arxiv 论文链接：https://arxiv.org/pdf/2404.03592     提交人    /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enk8wm/d_practical_example_of_reft_representation/</guid>
      <pubDate>Thu, 08 Aug 2024 23:10:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI：API 中的结构化输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1endf5w/d_openai_structured_outputs_in_the_api/</link>
      <description><![CDATA[https://openai.com/index/introducing-structured-outputs-in-the-api/ 只是好奇，为什么这是一件大事？你看到任何用例了吗？    提交人    /u/dmpetrov   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1endf5w/d_openai_structured_outputs_in_the_api/</guid>
      <pubDate>Thu, 08 Aug 2024 18:27:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] FlexAttention：PyTorch 的灵活性与 FlashAttention 的性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</link>
      <description><![CDATA[https://pytorch.org/blog/flexattention/    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</guid>
      <pubDate>Thu, 08 Aug 2024 13:49:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>