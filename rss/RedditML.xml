<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 29 Nov 2023 18:17:20 GMT</lastBuildDate>
    <item>
      <title>[P] GPU 基准测试：23 个消费级 GPU 上的稳定 Diffusion v1.5（生成 460,000 个精美的二维码）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186v2ve/p_gpu_benchmark_stable_diffusion_v15_on_23/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186v2ve/p_gpu_benchmark_stable_diffusion_v15_on_23/</guid>
      <pubDate>Wed, 29 Nov 2023 17:33:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 图像到三角形</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186u5ln/d_p_images_to_triangles/</link>
      <description><![CDATA[图像到三角形 假设你有一个图像，它是输入......你现在需要输出一组n 个最接近地复制它的三角形，其中 n 是固定的。今天你将如何解决这个问题  遗传算法已经解决了这个问题，但需要很长时间或很容易收敛到某些图片......我尝试在这里运行一些初步的东西这里整洁的游乐场...... https://jerryjohnthomas.github.io/30pieces/ 每个三角形都是需要空间和颜色的东西......所以尝试将与三角形相同颜色的像素分组......就像一个knn东西  I我认为如果没有 CNN，我们也许可以做得更好，添加一个简化的假设，即图像确实由 n 个三角形组成，并且可以精确复制。还有什么你想尝试的吗？   由   提交 /u/Existing-Pie-3723   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186u5ln/d_p_images_to_triangles/</guid>
      <pubDate>Wed, 29 Nov 2023 16:56:38 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 教科书的文本到语音生成（非数学部分）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186ty64/discussion_text_to_voice_generation_for_textbooks/</link>
      <description><![CDATA[我正在听 lex 播客，了解我研究的一些内容，想问一下，是否有任何听起来足够自然的本地文本到语音模型？ 我非常想用它把一本书的文本部分变成音频，这样我就可以在阅读时收听它。我使用 edge 的 tts  进行语音，将一段文字放到剪贴板和 edge-tts 中以收听文本，但它造成两个问题：1.需要网络连接并且打开书2.只能逐段进行，容易出错，或者有时使用太多之后无法转换全文。 &lt; p&gt;这个想法是将一本书的章节转换成音频文件并传输，以便我可以在手机上即时收听。 离线模型的状态如何？他们有能力输出良好的声音（或者甚至能够从他们的讲座中提供导师的声音并对其进行训练）？   由   提交/u/sweetchocolotepie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186ty64/discussion_text_to_voice_generation_for_textbooks/</guid>
      <pubDate>Wed, 29 Nov 2023 16:48:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为我的项目绘制基本事实的注释应用程序推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186tsfy/d_annotation_apps_recommendation_to_draw_ground/</link>
      <description><![CDATA[     &lt; /td&gt; 我目前正在为我的特征工程课程做一个项目，该项目的目的是检测田地边界或道路。因此，对于基本事实，我使用了 Matlab 中的图像分割，它具有各种工具，例如洪水填充等，可以将田野填充为黑色，将道路设置为白色。正如您在第二张图片中看到的那样，这是我绘制的地面，它有很多噪点。我们的教授建议我们使用 iPad 来绘制真实图像。任何人都可以为我推荐绘制相同精确事实但没有噪音的应用程序   由   提交 /u/Certain-Seesaw-2274   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186tsfy/d_annotation_apps_recommendation_to_draw_ground/</guid>
      <pubDate>Wed, 29 Nov 2023 16:41:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 获取参考图像并生成主题的附加图像的模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186t4k8/d_model_that_takes_a_reference_image_and/</link>
      <description><![CDATA[嗨，我正在寻找一篇我记得看过但忘记保存的论文。本文讨论了获取单个输入图像，例如与一个人，然后在其他环境中生成同一个人的其他图像。我依稀记得一个演示图像，以一幅女性的画作为参考图像，然后将该女性修复到现有的宇航员图像中。 我做了一些研究，break-a-scene 与我所说的最接近。但是，break-a-scene 讨论的是从源图像中提取多个标记，我认为我正在寻找的论文只讨论了一个主题。而且演示图像不存在。 以下是我发现的一堆论文，它们做了类似的事情，但我也不认为是我所看到的： https://realfill.github.io/ https://github.com/garibida/cross-image-attention https://github.com/SUDO-AI-3D/zero123plus https://omriavrahami.com/the-chosen-one/ https ://omriavrahami.com/break-a-scene/ https://github.com/腾讯ARC/CustomNet https://damo-vilab.github.io/AnyDoor -Page/ https://github.com/OPPO-Mente-实验室/主题扩散 Lmk，如果您知道处理此或相关任务的任何其他论文，谢谢！   由   提交 /u/synapticpaint   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186t4k8/d_model_that_takes_a_reference_image_and/</guid>
      <pubDate>Wed, 29 Nov 2023 16:13:50 GMT</pubDate>
    </item>
    <item>
      <title>[R]计算视角下的意识理论综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186sd61/r_survey_of_consciousness_theory_from/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2309.10063 摘要：  几个世纪以来，人类意识一直是一个长期存在的谜团，而机器智能和意识是一项艰巨的追求。研究人员发展了多种理论从不同角度和层次解释人类大脑中的意识现象。本文调查了源自不同学科的意识理论的几个主要分支，包括信息论、量子物理学、认知心理学、生理学和计算机科学，旨在从计算的角度弥合这些理论。它还讨论了现有的意识评估指标以及当前计算模型具有意识的可能性。 打破意识之谜可能是用计算机构建通用人工智能的重要一步。  ​ &lt; !-- SC_ON --&gt;  由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186sd61/r_survey_of_consciousness_theory_from/</guid>
      <pubDate>Wed, 29 Nov 2023 15:42:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] Rankitect：在元规模上与世界级工程师对战的架构搜索排名</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186s7ps/r_rankitect_ranking_architecture_search_battling/</link>
      <description><![CDATA[   论文&lt; /strong&gt;: https://arxiv.org/abs/2311.08430 摘要:   神经架构搜索（NAS）已经证明了它在计算机视觉方面的功效和排名系统的潜力。然而，之前的工作主要集中在学术问题上，这些问题是在良好控制的固定基线下进行小规模评估的。在行业系统中，例如 Meta 中的排名系统，尚不清楚文献中的 NAS 算法是否能够超越生产基线，因为：（1）规模 - Meta 排名系统为数十亿用户服务，（2）强大的基线 - 基线是生产自深度学习兴起以来，多年来数百到数千名世界级工程师优化了模型，(3) 动态基线 - 工程师可能在 NAS 搜索过程中建立了新的、更强的基线，(4) 效率 - 搜索管道必须产生结果快速与生产生命周期保持一致。在本文中，我们介绍了 Rankitect，一个用于 Meta 排名系统的 NAS 软件框架。 Rankitect 寻求通过从头开始构建低级构建块来构建全新的架构。 Rankitect 实现并改进了最先进 (SOTA) NAS 方法，以在同一搜索空间下进行全面、公平的比较，包括基于采样的 NAS、一次性 NAS 和可微分 NAS (DNAS)。我们通过与 Meta 上的多个生产排名模型进行比较来评估 Rankitect。我们发现 Rankitect 可以从头开始发现新模型，实现归一化熵损失和 FLOP 之间的竞争性权衡。当利用工程师设计的搜索空间时，Rankitect 可以生成比工程师更好的模型，实现积极的离线评估和 Meta 规模的在线 A/B 测试。  https://preview.redd.it/n1l2fhle3b3c1.png?width=1360&amp;format=png&amp; ＆汽车=webp&amp;s=772bbd4885bd87fb14461d76f8aca804b32fe1b8   由   提交 /u/APaperADay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186s7ps/r_rankitect_ranking_architecture_search_battling/</guid>
      <pubDate>Wed, 29 Nov 2023 15:35:28 GMT</pubDate>
    </item>
    <item>
      <title>机械地分析微调对程序定义的任务的影响（以及为什么微调很容易撤消）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186qh5x/mechanistically_analyzing_the_effects_of/</link>
      <description><![CDATA[       由   提交/u/hazardoussouth  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186qh5x/mechanistically_analyzing_the_effects_of/</guid>
      <pubDate>Wed, 29 Nov 2023 14:20:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] NVAutoNet</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186phtt/r_nvautonet/</link>
      <description><![CDATA[&lt;表&gt;      有人读过 NVIDIA 的新论文 NVAutoNet 并知道他们是如何得到特征图的指定维度的吗？因为我尝试手动应用表中的运算，但没有得到与公式相同的结果。他们是否使用任何类型的填充，或者是否有人可以解释如何应用这些操作。谢谢。   由   提交/u/Neat_Cucumber_3282   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186phtt/r_nvautonet/</guid>
      <pubDate>Wed, 29 Nov 2023 13:33:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 他们说：“这不仅仅是记住训练数据”：从（生产）语言模型中可扩展地提取训练数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186mm4m/r_its_not_just_memorizing_the_training_data_they/</link>
      <description><![CDATA[      &amp;# 32；由   提交/u/wojcech  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186mm4m/r_its_not_just_memorizing_the_training_data_they/</guid>
      <pubDate>Wed, 29 Nov 2023 10:45:56 GMT</pubDate>
    </item>
    <item>
      <title>MeshGPT：使用仅解码器变压器生成三角形网格 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186ktla/meshgpt_generating_triangle_meshes_with/</link>
      <description><![CDATA[       由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186ktla/meshgpt_generating_triangle_meshes_with/</guid>
      <pubDate>Wed, 29 Nov 2023 08:36:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用侵犯版权但不受传统版权保护的音频进行培训是否合法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186kq06/d_is_it_legal_to_train_on_audio_that_is_copyright/</link>
      <description><![CDATA[我想根据音乐家录制的流行歌曲并因此拥有的钢琴封面来训练一个模型，但由于侵犯版权，他们仍然付费这些歌曲的作者的版税。很好奇这是否合法——我认为不合法，因为在这种情况下，这些录音并没有被货币化，而是被输入到一个模型中，并且这些录音仍然由授权给我的音乐家 100% 拥有。   由   提交 /u/SuperwhizAJ   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186kq06/d_is_it_legal_to_train_on_audio_that_is_copyright/</guid>
      <pubDate>Wed, 29 Nov 2023 08:29:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果运行时间或 GPU 内存使用没有显着减少，那么参数高效微调的动机是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186ck5k/d_what_is_the_motivation_for_parameterefficient/</link>
      <description><![CDATA[我一直在尝试诸如提示调整和 LoRA 之类的方法，这些方法的参数效率很高，因为它们只微调很小的一部分（即是所有参数的&lt;1%）。 但是对于这两种方法，您必须在反向传播期间缓存中间梯度，这意味着您在微调期间（或在由于无需存储冻结层的优化器状态，​​因此节省了大部分 GPU 内存）。例如，我已经让 LoRA 将我的自定义模型的 GPU 内存占用量从 8.5GB 减少到了 8.5GB。 8.1GB，非常小。微调时间减少也并不是真正的主要优势，每批微调同一模型减少了 20 毫秒，从 210 毫秒减少到 190 毫秒。 这引出了一个问题 - 实际原因是什么？参数高效微调（例如，带有 1.6k+ 引用的提示调整）的流行，如果它不能真正节省 GPU 内存和训练时间？ 我可以看到两个可能的原因（但我不太相信他们真的解释了围绕参数高效微调的“炒作”）：  下游任务的微调模型检查点显着减少。例如，在提示调整中，我们只需要在硬盘/SSD 上保存经过训练的微小软提示（〜很少兆字节），而不是整个更改后的模型权重（〜很多很多 GB）。  但从实际角度来看，我觉得大多数人都缺乏计算能力（例如 GPU 内存），而不是硬盘空间。换句话说，训练时间和 GPU 内存消耗似乎比节省检查点存储空间更相关。  第二个是域转移的鲁棒性（因为我们是保留大部分原始模型的权重，而不是破坏性地重新学习它们），这一点在提示调整论文中提到过，但在 LoRA 论文中却没有提及太多。  我可以认为这是一个可能的原因，但是在分布外设置中的提示调优论文中的性能增益充其量是微乎其微的，并且 LoRA 没有提到域转换。   （编辑 - 我还想知道是否还缺少其他东西来减少 GPU 内存和运行时间？我听说 QLoRA 增加了 4- LoRA 之上模型的位量化，所以也许这是解决 LoRA 内存效率问题的一种方法。但我不知道是否有什么可以减少内存占用以进行快速调整？）   由   提交/u/patricky168  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186ck5k/d_what_is_the_motivation_for_parameterefficient/</guid>
      <pubDate>Wed, 29 Nov 2023 01:06:13 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]您发现自己每周在工作的哪一部分上浪费时间最多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/</link>
      <description><![CDATA[不询问拖延症、实际工作职责。对我来说，它必须处理电子表格和演示文稿。您的工作流程中存在哪些瓶颈？   由   提交/u/zero-true  /u/zero-true reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/</guid>
      <pubDate>Tue, 28 Nov 2023 18:52:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>