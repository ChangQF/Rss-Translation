<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 16 Nov 2024 18:20:37 GMT</lastBuildDate>
    <item>
      <title>[讨论] 开展研究的最佳主题是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gssvkk/discussion_what_would_a_good_topic_to_conduct_a/</link>
      <description><![CDATA[我在 ML 方面有扎实的数学基础，还有一些编码经验。对于一个从未做过研究的人来说，什么主题比较适合开展研究？    提交人    /u/Last_Tradition_1050   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gssvkk/discussion_what_would_a_good_topic_to_conduct_a/</guid>
      <pubDate>Sat, 16 Nov 2024 17:56:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] COLING 2025 结果泄露</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gssewj/d_coling_2025_results_are_leaked/</link>
      <description><![CDATA[你们可以登录 softconf 检查是否可以提交照相排版论文。 我的成绩是 4/3/3，幸运地被接受了。我的第一篇论文！！！    提交人    /u/Ambitious-Public-512   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gssewj/d_coling_2025_results_are_leaked/</guid>
      <pubDate>Sat, 16 Nov 2024 17:35:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 必读的 ML 理论论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsqqns/r_mustread_ml_theory_papers/</link>
      <description><![CDATA[您好， 我是一名计算机科学博士生，希望加深对机器学习理论的理解。我的研究领域专注于视觉语言模型，但我想通过阅读基础或开创性的机器学习理论论文来扩展我的知识。 您能否分享一份对机器学习理论产生重大影响的必读论文或个人推荐？ 提前谢谢您！    提交人    /u/AntelopeWilling2928   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsqqns/r_mustread_ml_theory_papers/</guid>
      <pubDate>Sat, 16 Nov 2024 16:19:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 扩散模型中的时间步长依赖性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gspx8g/d_time_step_dependency_in_diffusion_model/</link>
      <description><![CDATA[是否有任何现有工作尝试研究扩散模型的时间步骤之间的关系？类似于模型在时间步骤 i 的模型损失对模型在时间步骤 j 的输出的影响？（j&lt;i）    提交人    /u/Careless-Top-2411   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gspx8g/d_time_step_dependency_in_diffusion_model/</guid>
      <pubDate>Sat, 16 Nov 2024 15:42:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 视频表征提取器 (VRE)：开源视频多任务数据集创建工具 (+colab)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsmhuo/p_video_representations_extractor_vre_open_source/</link>
      <description><![CDATA[大家好，我已经为我的博士学位研究这个工具一段时间了。我的博士学位是关于视频背景下的多任务学习，我最近正在开发一个工具，从预先训练的“专家”那里获取每帧的预测（语义分割、深度估计等）。这些的目的是用不仅仅是原始 RGB 数据来训练多任务 CV 模型，以帮助提高数据效率和泛化。 代码在这里：https://gitlab.com/video-representations-extractor/video-representations-extractor 那里有很多例子（包括 pip install 命令）。 最近我做了一个“端到端”用于展示的示例，我也将其放在了 google colab 上：https://colab.research.google.com/drive/1vAp71H-TLewhF56odv33TkmGwwhuoFJ-?usp=sharing colab 笔记本的示例输出：https://i.imgur.com/wyl9FPw.png 为简单起见，它跳过了许多步骤（即，为了实验目的，像“运输”这样的二进制语义输出是单独实现的，我只需下载该文件 + 将其导入笔记本中，而不是复制粘贴 300 多行代码colab 但不要运行未检查的任意代码 lol）。 colab 应该适用于任何 UAV/驾驶/手持室内视频，而不仅仅是我的演示视频。 CLI 工具语法基本上是： export VRE_DEVICE=cuda; # if available vre video.mp4 --config_file config.yaml -o out_dir  其中配置文件定义了我已经实现的这些专家的参数。    提交人    /u/nucLeaRStarcraft   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsmhuo/p_video_representations_extractor_vre_open_source/</guid>
      <pubDate>Sat, 16 Nov 2024 12:43:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 分析 UMAP 为何如此之快</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsjfq9/p_analysis_of_why_umap_is_so_fast/</link>
      <description><![CDATA[      嗨，我最近花了一些时间从 UMAP 算法的实现方式以及它为什么如此之快的角度来了解 UMAP 算法的核心实现（即使它是用 Python 编写的）。我决定将算法分解为更小的步骤，在这些步骤中，我对代码进行一些小的改进（一个接一个），这样最终的结果与我从 UMAP 获得的结果非常相似。 令我惊讶的是，这些变化中的大多数只是优化代码中的技巧，以更快地运行程序或减少更新不太重要的东西的频率。当然，我的实现并没有 100% 地重现 UMAP 算法，因为它是在教育目的中完成的。 我在我的项目中提供了详细的解释，说明我必须在每个步骤中添加什么才能转向类似 UMAP 的算法。这是项目页面：https://github.com/kmkolasinski/nano-umap 如果您是一个喜欢优化代码以提高性能的人，您可能会发现这很有趣。下面是我能够得到的演示：  https://preview.redd.it/eww57c3x881e1.png?width=1921&amp;format=png&amp;auto=webp&amp;s=ed4a345e40b47782ddf39cb93eb9d03207db1160 TLDR：在 UMAP 中他们：  使用 ANN 库快速找到顶级 k-NN， 使用良好的初始化方法，使事情更稳定并且算法需要更少的更新（UMAP 使用快速谱初始化）， 使用随机负采样，这是一种简单的方法，但在实践中效果很好， 压缩 numba 性能（通过用自定义实现替换 np.dot 或 np.clip 来使代码运行得更快）， 使用某种自适应采样，这将使算法将更多时间花在更重要的向量上，从而节省不太重要的向量上的 CPU 时间     提交人    /u/kmkolasinski   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsjfq9/p_analysis_of_why_umap_is_so_fast/</guid>
      <pubDate>Sat, 16 Nov 2024 09:02:10 GMT</pubDate>
    </item>
    <item>
      <title>[R][D]沙门氏菌机器学习研究中使用未标记数据的 10 倍交叉验证的说明</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsgwgk/rdclarification_on_10fold_crossvalidation_with/</link>
      <description><![CDATA[      我目前正在阅读一篇研究论文，重点是ML 预测鸡肉沙门氏菌分离株的疾病结果。 我正在努力理解他们的方法，尤其是他们如何处理标记和未标记数据的交叉验证。 据我所知，作者：  将标记数据集（28 个沙门氏菌分离株）分成 70％ 用于训练，30％ 用于测试。 使用各种 ML 算法（随机森林、Logit Boost、梯度提升、具有不同内核的 SVM）对 70％ 训练子集 进行 10 倍交叉验证，以根据准确性选择最佳模型。 使用选定的模型预测疾病表型未标记的数据集（205 个分离株）。 将原始标记数据与这些预测的标签相结合，并重复该过程，总共10 次迭代。  但是，他们的图表（图 1）似乎意味着 10 倍交叉验证直接应用于未标记的数据集，这与标准做法不符，因为交叉验证通常需要标记数据进行训练和验证。 我的解释是否正确，他们使用迭代半监督方法，并且在对未标记数据进行每次预测之后，他们都会使用新标记的数据重新训练模型？或者我遗漏了他们的图表的某些内容？ https://preview.redd.it/y16rjvc9f71e1.png?width=2630&amp;format=png&amp;auto=webp&amp;s=5cafd0ec39b1167e231b6d579b9a6654a44fb595    提交人    /u/Acceptable-File2674   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsgwgk/rdclarification_on_10fold_crossvalidation_with/</guid>
      <pubDate>Sat, 16 Nov 2024 06:03:46 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 现代搜索系统在查询预处理中是否仍然需要词干提取和词形还原？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsauuz/discussion_do_modern_search_systems_still_require/</link>
      <description><![CDATA[考虑到 LM 的所有进步，我想知道它们在现代搜索系统中有多重要。语义嵌入通常可以帮助我们很好地理解含义。但为了有效利用历史查询项目参与度特征，我们似乎仍然需要进行这些预处理。否则，当用户搜索与常见查询略有不同时，我们很容易得到空的参与度特征？或者有没有更现代的方式来处理自由形式的查询？    提交人    /u/wenegue   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsauuz/discussion_do_modern_search_systems_still_require/</guid>
      <pubDate>Sat, 16 Nov 2024 00:16:42 GMT</pubDate>
    </item>
    <item>
      <title>[R][D]抽象推理的测试时间训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gs9lao/rdtest_time_training_for_abstract_reasoning/</link>
      <description><![CDATA[https://arxiv.org/pdf/2411.07279 顺便问一下，大家知道有什么研究尝试在回答问题之前对模型进行微调吗？我的意思是它可能适用于上下文信息检索，但我想知道它对推理能力更强的任务的影响。计算过剩仍然会很大。    提交人    /u/Due-Pangolin325   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gs9lao/rdtest_time_training_for_abstract_reasoning/</guid>
      <pubDate>Fri, 15 Nov 2024 23:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 卷积可微分逻辑门网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gs92mb/r_convolutional_differentiable_logic_gate_networks/</link>
      <description><![CDATA[摘要 随着机器学习模型的推理成本不断增加，人们对具有快速高效推理能力​​的模型的兴趣日益浓厚。最近，提出了一种通过可微分松弛直接学习逻辑门网络的方法。逻辑门网络比传统的神经网络方法更快，因为它们的推理只需要逻辑门运算符（例如 NAND、OR 和 XOR），这些运算符是当前硬件的底层构建块，可以高效执行。我们在此想法的基础上，通过深度逻辑门树卷积、逻辑或池化和残差初始化对其进行了扩展。这允许将逻辑门网络扩大一个数量级以上并利用卷积范式。在 CIFAR-10 上，我们仅使用 6100 万个逻辑门就实现了 86.29% 的准确率，这比 SOTA 有所提高，同时体积却缩小了 29 倍。 被 Neurips 2024 接受，“SOTA”在这里表示可比方法。我发现这篇论文真的很有趣，尽管非玩具网络似乎训练起来非常昂贵。好奇其他人怎么想？    提交人    /u/jacobgorm   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gs92mb/r_convolutional_differentiable_logic_gate_networks/</guid>
      <pubDate>Fri, 15 Nov 2024 22:51:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 读博士还是不读博士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gs688q/d_to_phd_or_not_to_phd/</link>
      <description><![CDATA[我想这个问题已经被问过无数次了，但让我再问一次。 我目前在 MSFT 担任应用科学家。然而，我更想找科学职位，比如 DeepMind 的研究科学家。虽然工作并不特别需要博士学位，但竞争非常激烈，而且有很多博士学位持有者。 我确实喜欢研究，想读博士学位，但我总是问自己这是否真的值得。 这肯定是一个开放性问题，请随时分享您的想法。    提交人    /u/oddhvdfscuyg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gs688q/d_to_phd_or_not_to_phd/</guid>
      <pubDate>Fri, 15 Nov 2024 20:44:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] Neurips 2024 酒店室友搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gs0gj8/d_neurips_2024_hotel_roommate_search/</link>
      <description><![CDATA[2024 年 Neurips 会场周围的酒店相当昂贵，我正在寻找室友来分摊费用（我的大学对他们愿意报销的每晚酒店费用有限制）。我目前已在世纪广场酒店预订了周二至周日的房间，距离会议中心 0.9 英里。每晚房费为 414 美元。如果有人想分摊房费，请联系我们！此外，如果您能与您的研究小组或您认识的其他与会者分享这篇文章，那将会很有帮助。 如果您不确定是否要与完全陌生的人同住，您可以通过我的个人网站 (https://mtcrawshaw.github.io/) 了解我一点，该网站有指向我的谷歌学术页面、简历等的链接。我确实在会议上发表了一篇关于联邦学习/分布式优化领域的论文。我只是一名研究生，想让会议变得负担得起！谢谢。    提交人    /u/ssbm_crawshaw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gs0gj8/d_neurips_2024_hotel_roommate_search/</guid>
      <pubDate>Fri, 15 Nov 2024 16:37:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当您说“LLM”时，有多少人也考虑过 BERT 之类的东西？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grxbdp/d_when_you_say_llm_how_many_of_you_consider/</link>
      <description><![CDATA[我不断遇到这种争论，但对我来说，当我听到“LLM”时，我的假设是只有解码器的模型，这些模型有数十亿个参数。似乎有些人会将 BERT-base 纳入 LLM 系列，但我不确定这是否正确？我想从技术上讲是这样，但每次我听到有人说“我如何使用 LLM 进行 XYZ”时，他们通常会提到 LLaMA 或 Mistral 或 ChatGPT 或类似的东西。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grxbdp/d_when_you_say_llm_how_many_of_you_consider/</guid>
      <pubDate>Fri, 15 Nov 2024 14:16:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>