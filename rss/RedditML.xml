<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 15 Feb 2024 15:12:57 GMT</lastBuildDate>
    <item>
      <title>[P] 我应该水冷我的 ML/CFD 设备吗？从长远来看它是否更便宜？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1argyb4/p_should_i_water_cool_my_mlcfd_rig_and_is_it/</link>
      <description><![CDATA[构建我的第一个 ML/CFD 装备（在更有经验的人的帮助下），我知道水冷 PC 的初始成本和维护是更高，但从长远来看，它会通过降低能源费用和减少 GPU 的烹饪次数来节省我的钱吗？我将基本上 24/7 365 运行模拟和训练。为了添加更多上下文，我希望 GPU 在大约 2-3 年内保持稳定的性能，并希望在该时间范围内优化我的成本节省。 还有人尝试过技术含量较低的解决方案，例如将电脑放入金属盒中，然后将其浸入大水体（游泳池、大垃圾桶）中进行被动冷却。我知道微软有水下数据中心，我想知道小规模的数据中心是否有效（假设一切都防水）。 我一直无法在网上找到好的资源。这样做的经济效益，因此任何建议都值得赞赏。   由   提交 /u/FellowOInfiniteJest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1argyb4/p_should_i_water_cool_my_mlcfd_rig_and_is_it/</guid>
      <pubDate>Thu, 15 Feb 2024 14:42:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于 ML 的 Anki Decks</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arg1ie/d_anki_decks_for_ml/</link>
      <description><![CDATA[大家好，有人可以分享您正在使用的或发现更适合学习 ML 的 Anki Decks 吗？不知道安琪吗？请阅读此处：https://augmentingcognition.com/ltm.html &lt;!-- SC_ON - -&gt;  由   提交 /u/sAI_Rama_Krishna   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arg1ie/d_anki_decks_for_ml/</guid>
      <pubDate>Thu, 15 Feb 2024 14:00:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于减少二氧化碳排放的可持续路线优化项目的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arfdmg/r_advice_on_sustainable_routing_optimization/</link>
      <description><![CDATA[我目前正在研究一个与使用机器学习技术在供应链中实现可持续路线优化相关的项目想法。目标是通过优化运输路线来减少二氧化碳排放。我想听听您的想法、建议以及您可能拥有的任何相关经验！ ​  数据集：是否有任何可用且适合训练和评估机器学习模型的数据集？ 可行性：这个项目对于独立开发人员或小团队来说是否可行？有什么需要预见的挑战吗？ 类似项目：是否存在与可持续路线优化以减少二氧化碳排放相关的现有类似项目或研究论文？    由   提交 /u/ziade_e   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arfdmg/r_advice_on_sustainable_routing_optimization/</guid>
      <pubDate>Thu, 15 Feb 2024 13:26:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 指令调整的最佳批量大小？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1areexh/r_best_batch_size_for_instruction_tuning/</link>
      <description><![CDATA[您好，是否有关于指令调整的最佳批量大小的研究？ 我查看了 flan-T5 论文，并且看来他们使用了包装，因此有效的批量大小比使用的要大得多。 将不胜感激任何帮助。谢谢！   由   提交/u/Training-Adeptness57  /u/Training-Adeptness57 reddit.com/r/MachineLearning/comments/1areexh/r_best_batch_size_for_instruction_tuning/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1areexh/r_best_batch_size_for_instruction_tuning/</guid>
      <pubDate>Thu, 15 Feb 2024 12:33:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 键值约束 LLM 推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arcgvh/r_keyvalue_constrained_llm_inference/</link>
      <description><![CDATA[EasyKV 集成了各种 KV 缓存逐出策略，并与 HuggingFace 转换器库兼容，用于生成推理。它支持多头注意力、多查询注意力和分组查询注意力的LLM，并提供驱逐策略、缓存预算和应用场景的灵活配置。 论文：https://arxiv.org/abs/2402.06262 Github：https://github.com/DRSY/EasyKV   由   提交/u/Dramatic_Evening_921   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arcgvh/r_keyvalue_constrained_llm_inference/</guid>
      <pubDate>Thu, 15 Feb 2024 10:25:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 变压器中数字特征的位置编码。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arc4di/d_positional_encodings_for_numerical_features_in/</link>
      <description><![CDATA[嗨！ 我正在尝试使用特征序列（这些是描述太阳活动区域的磁场特征， （因此每个特征对应不同的特征）来预测该区域是否会在未来 12 小时内产生耀斑。现在，我最近开始研究变压器架构，并了解到，为了使这些模型能够理解数据的顺序性质（或者我应该说，学习它），需要包含位置编码。然而，我有点困惑它们对于这种类型的数据有多大用处。 我理解 NLP 中出现的位置编码的想法，因此您可以将其应用于词嵌入。在这种情况下，如果您将单词嵌入作为标记（这是固定的，因此每个单词将始终是相同的嵌入），我可以理解模型可能能够在某种程度上记住嵌入是什么，然后提取位置信息从编码。然而，当涉及到顺序数值数据时，我担心这些编码可能没有那么有用。模型如何知道区分编码和实际值？除此之外，由于数据被标准化为 0 和 std 1，嵌入（例如通常的正弦曲线）不会淹没数据的真实值吗？ 我猜这一切都是这是因为当我从模型中取出位置编码时，性能基本保持不变，因此它似乎没有使用与序列顺序相关的任何信息来进行预测。我想知道这是否是因为它确实对这项任务没有帮助，或者是因为我处理这件事的方式没有帮助。也许还存在一个问题，因为我的数据中有间隙（用 0 填充），并且到目前为止我没有使用屏蔽。也许添加掩蔽后会有一些更明显的影响，但我想这不会很大，因为我看不到在以下时间段内输出的样子（耀斑概率与时间）有很多变化当我取出编码时没有间隙。 非常感谢对此的任何见解！   由   提交 /u/Calcirium   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arc4di/d_positional_encodings_for_numerical_features_in/</guid>
      <pubDate>Thu, 15 Feb 2024 10:01:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] [2402.05919] 几何条件 PBR 图像生成的协同控制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1araxfo/r_240205919_collaborative_control_for/</link>
      <description><![CDATA[ 由   提交 /u/StartCodeEmAdagio   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1araxfo/r_240205919_collaborative_control_for/</guid>
      <pubDate>Thu, 15 Feb 2024 08:33:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] EEG-GPT：探索大型语言模型用于脑电图分类和解释的能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1araxfi/r_eeggpt_exploring_capabilities_of_large_language/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2401.18006  摘要：  在应用于脑电图 (EEG) 的传统机器学习 (ML) 方法中，这通常是一个有限的焦点，隔离发生的特定大脑活动跨越不同的时间尺度（从毫秒级的短暂峰值到持续几分钟的癫痫发作）和空间尺度（从局部高频振荡到全局睡眠活动）。这种孤立的方法限制了 EEG ML 模型的开发，而这些模型表现出多尺度的电生理理解和分类能力。此外，典型的 ML EEG 方法采用黑盒方法，限制了其在临床环境中的可解释性和可信度。因此，我们提出了 EEG-GPT，这是一种利用大语言模型 (LLM) 进步的统一脑电图分类方法。 EEG-GPT 在仅使用 2% 的训练数据的几次学习范式中对正常脑电图和异常脑电图进行分类方面取得了与当前最先进的深度学习方法相当的优异性能。此外，它还具有独特的优势，可以在操作中提供中间推理步骤并协调多个尺度的专业脑电图工具，提供透明且可解释的逐步验证，从而提高临床环境中的可信度。  ​   由   提交 /u/Typical-Respect590    reddit.com/r/MachineLearning/comments/1araxfi/r_eeggpt_exploring_capability_of_large_language/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1araxfi/r_eeggpt_exploring_capabilities_of_large_language/</guid>
      <pubDate>Thu, 15 Feb 2024 08:33:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用小数据集进行验证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arakd6/d_validation_with_small_datasets/</link>
      <description><![CDATA[我所在的领域的数据集通常很小（100-10000 个样本）且具有层次结构（取自 10-50 个参与者）。这意味着，为了在足够大的测试集上评估数据，而不仅仅是少数参与者，我们需要使用交叉验证。到目前为止一切顺利。 但是，这仍然没有解决验证问题。有几种可能的方法可以进行验证：  跳过验证。这似乎是我所在领域的首选方法。我认为这是非常错误的，而且我发现它可以高估准确度 5%（包含 5000 个样本的数据集），甚至高达 20%（100 个样本）。 将训练数据一次分割为训练和验证集用于对每个测试折叠进行验证。这样做的缺点是验证集最终很小（比测试集小得多），并且如果不小心的话，训练验证分割可能是任意的。 完全嵌套交叉验证。这似乎是正确验证超参数配置的最佳方法，因为它几乎使用整个数据集进行验证。我在我的领域还没有遇到过一篇使用嵌套交叉验证（正确）的论文。我相信主要问题非常明显：如果一个人使用 10 倍嵌套交叉验证训练一个神经网络模型 100 个时期，并尝试优化 5 个二进制超参数，那么最终已经有大约 100 * 10^2 * 2 ^5 = 320,000 个纪元。如果一个 epoch 需要 10 秒，这已经相当于一个多月的计算时间，而且我们仍然只验证了很少的超参数配置。  我可以看到以下解决方案：   p&gt;  接受计算需要这么长时间（并希望评审者不要要求我们重复实验）。 找到尽可能限制超参数配置的方法。  li&gt; 改用 5 重嵌套交叉验证。 减小验证集的大小（方法 2）。 承认并停止将神经网络拟合得较小数据集。  您对此有何看法？您更喜欢哪些选项？您还有其他解决方案吗？   由   提交/u/philosophicalmachine  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arakd6/d_validation_with_small_datasets/</guid>
      <pubDate>Thu, 15 Feb 2024 08:07:12 GMT</pubDate>
    </item>
    <item>
      <title>[N] Gradio Notebook 自定义组件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ar1u1q/n_gradio_notebook_custom_component/</link>
      <description><![CDATA[嘿！我们刚刚与 Hugging Face 团队一起推出了 Gradio Notebook。  该组件在 Hugging Face 空间上部署笔记本用户体验。   在一个地方探索多个 Hugging Face 模型的最简单方法 使用文本、图像和音频模型构建 AI 工作流程 托管您的 AI 工作流程上抱脸给别人看！   在这里查看：https://huggingface.co/spaces/ lastmileai/gradio-notebook-template  我们正在寻找早期反馈以及改善体验的方法。如果您有任何疑问，请发表评论并随时私信 :)    由   提交 /u/InevitableSky2801   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ar1u1q/n_gradio_notebook_custom_component/</guid>
      <pubDate>Wed, 14 Feb 2024 23:59:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] Whisper Large v3 基准：在消费类 GPU 上以 5110 美元（每美元 11,736 分钟）转录 100 万小时 - 后续</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ar08br/p_whisper_large_v3_benchmark_1_million_hours/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ar08br/p_whisper_large_v3_benchmark_1_million_hours/</guid>
      <pubDate>Wed, 14 Feb 2024 22:50:05 GMT</pubDate>
    </item>
    <item>
      <title>[D]微调时间有没有“负面提示”的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqyhmk/d_is_there_a_way_of_negative_prompting_at/</link>
      <description><![CDATA[假设我正在尝试微调预训练的语言模型，并且我想更改其响应格式。通常情况下，我会根据新格式对一堆回复示例进行微调。但这样做也会改变模型的语义行为，以更接近地模仿 SFT 示例中存在的文本类型。有没有办法对新格式的示例进行微调，然后对微调示例中的相同文本进行有效的负面微调，但没有新的响应格式？最终结果是模型现在以所需的格式返回响应，但返回的文本类型的分布没有变化。   由   提交/u/thirdvox  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqyhmk/d_is_there_a_way_of_negative_prompting_at/</guid>
      <pubDate>Wed, 14 Feb 2024 21:35:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 阅读和学习研究论文的最佳方式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</link>
      <description><![CDATA[当我们尝试专注于玉兰油的创新产品时，我们必须学习许多现代科技知识。但通常需要时间才能获得博客和教程上的可用资源。  因此，直接从第一个主要来源学习是有效的学习方式，因为它是主要来源。 但是，我发现阅读论文非常困难，因为它包含许多术语或内容不寻常的措辞。此外，跟踪和掌握一篇大论文的上下文也需要很大的耐心。 你们能分享一下你们的方法吗？你们如何有效且高效地从已发表的论文中学习并获得见解？   由   提交 /u/FardinRock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</guid>
      <pubDate>Wed, 14 Feb 2024 14:28:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过计算机视觉让我的书架可点击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</link>
      <description><![CDATA[      我构建了一个系统，可以让你拍摄书架的照片并创建一个交互式 HTML 网页，您可以在其中单击图像中的书籍来了解有关每本书的更多信息。 该项目的技术堆栈是：  用于检索的接地 SAM书籍的多边形。 OpenCV + 监督转换，为 OCR 准备书籍。 GPT-4 和 Vision for OCR Google Books API，用于获取书籍元数据。  生成 HTML + SVG 以创建最终网页。  我在博客上写了如何构建这个项目。 尝试演示。 我希望获得有关如何提高图书检测率以获得更好性能的反馈。在书脊上训练自定义分割模型可能会起作用，但我知道为此可能需要多少数据。 下面的红色多边形表示在演示中可点击的分段书籍：  p&gt; https://preview.redd.it /p9w4rgsn1jic1.png?width=1260&amp;format=png&amp;auto=webp&amp;s=35116c7eb9d1f5dab2b11375be9e2ff0e7163b78   由   提交/u/zerojames_  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</guid>
      <pubDate>Wed, 14 Feb 2024 10:21:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>