<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Mon, 12 Aug 2024 21:15:28 GMT</lastBuildDate>
    <item>
      <title>[R] 为何以及何时绑定嵌入（故事）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqm0lr/r_why_and_when_tying_embedding_a_story/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqm0lr/r_why_and_when_tying_embedding_a_story/</guid>
      <pubDate>Mon, 12 Aug 2024 18:54:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] NIST Dioptra，有运气吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eql4yk/d_nist_dioptra_any_luck/</link>
      <description><![CDATA[你们有人试过使用 NIST 的 Dioptra，他们的 AI 测试平台吗？ 尽管我按照他们的说明操作，但还是卡了大约一个星期试图启动并运行它。我似乎没有收到 API 的响应，所以我无法提交任何作业。我正在本地运行它，据我所知，端口是暴露的。  默认配置对你有用吗？如果没有，你有什么安装技巧吗？    提交人    /u/kitties_and_biscuits   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eql4yk/d_nist_dioptra_any_luck/</guid>
      <pubDate>Mon, 12 Aug 2024 18:20:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] RAGoon 现已在 PyPI、GitHub 和 HF 上的 Space 上提供，用于批量生成嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqj67x/p_ragoon_is_now_available_on_pypi_github_and_as_a/</link>
      <description><![CDATA[RAGoon 是一组用于多模型嵌入生成、高维向量可视化的 NLP 实用程序，旨在通过基于搜索的查询、网页抓取和数据增强技术提供上下文相关信息，从而提高语言模型性能。 GitHub 链接：https://github.com/louisbrulenaudet/ragoon Hugging Face Space 链接：https://huggingface.co/spaces/louisbrulenaudet/ragoon 以下是为给定的模型列表生成嵌入的代码示例： from ragoon import EmbeddingsDataLoader from datasets import load_dataset # 使用初始化数据集加载器多个模型 loader = EmbeddingsDataLoader( token=&quot;hf_token&quot;, dataset=load_dataset(&quot;louisbrulenaudet/dac6-instruct&quot;, split=&quot;train&quot;), # 如果数据集已加载。# dataset_name=&quot;louisbrulenaudet/dac6-instruct&quot;, # 如果要从类中加载数据集。model_configs=[ {&quot;model&quot;: &quot;bert-base-uncased&quot;, &quot;query_prefix&quot;: &quot;Query:&quot;}, {&quot;model&quot;: &quot;distilbert-base-uncased&quot;, &quot;query_prefix&quot;: &quot;Query:&quot;} # 根据需要添加更多模型配置 ] ) # 如果传递 dataset_name 而不是 dataset，请取消注释此行。 # loader.load_dataset() # 处理已加载所有模型的分割 loader.process( column=&quot;output&quot;, preload_models=True ) # 访问已处理的数据集 processing_dataset = loader.get_dataset()  特别是，此工具还提供从 FAISS 索引加载嵌入的功能，使用 PCA 和/或 t-SNE 降低其维数，并在交互式 3D 图形中对其进行可视化。    submitted by    /u/louisbrulenaudet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqj67x/p_ragoon_is_now_available_on_pypi_github_and_as_a/</guid>
      <pubDate>Mon, 12 Aug 2024 17:04:29 GMT</pubDate>
    </item>
    <item>
      <title>[P] 准确率超过 96% 的 IAB 内容分类模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqiiv7/p_96_accuracy_iab_content_classification_model/</link>
      <description><![CDATA[您可以在此处试用 IAB 内容模型。它基于 IAB 内容分类法。    由   提交  /u/Different-General700   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqiiv7/p_96_accuracy_iab_content_classification_model/</guid>
      <pubDate>Mon, 12 Aug 2024 16:39:49 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 神经网络分析中的长回溯</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqhc6f/project_long_traceback_in_neural_network_profiling/</link>
      <description><![CDATA[      嗨，我正在使用 PyTorch Profiler 来优化我的神经网络的 GPU 训练时间。 我认识到，除了第一个操作（如果有帮助的话，它是傅里叶变换）之外，每个执行的操作都有很长的回溯调用。步骤。 分析器中相应的部分如下所示： https://preview.redd.it/w4kemi8w89id1.png?width=1303&amp;format=png&amp;auto=webp&amp;s=f7ba069ea53506c0ed292d28df18b3f3680799a0 https://preview.redd.it/htwp9r9x89id1.png?width=1378&amp;format=png&amp;auto=webp&amp;s=5c3934253fceb68395f837dc5130fc4db0c55bb9 https://preview.redd.it/r3twt49y89id1.png?width=1411&amp;format=png&amp;auto=webp&amp;s=fc3a307435ef93d3d5733f91faea5bc78923ad14 有人遇到过这种情况吗？知道这意味着什么或如何解决吗？    提交人    /u/Maddin187   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqhc6f/project_long_traceback_in_neural_network_profiling/</guid>
      <pubDate>Mon, 12 Aug 2024 15:53:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 1.5-Pints 技术报告：几天内完成预训练，而不是几个月——您的语言模型依靠优质数据蓬勃发展 (2408.03506)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqdbro/r_15pints_technical_report_pretraining_in_days/</link>
      <description><![CDATA[  由    /u/mouse0_0  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqdbro/r_15pints_technical_report_pretraining_in_days/</guid>
      <pubDate>Mon, 12 Aug 2024 13:10:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 提示与偏见</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqc5nt/r_prompt_and_prejudice/</link>
      <description><![CDATA[  由    /u/Cioni  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqc5nt/r_prompt_and_prejudice/</guid>
      <pubDate>Mon, 12 Aug 2024 12:16:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何处理时间序列数据中事件发生和标签报告之间的时间延迟？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq9mqx/d_how_to_handle_time_delays_between_event/</link>
      <description><![CDATA[大家好， 我正在开展一个项目，旨在使用租赁汽车的传感器数据实时检测车辆盗窃。我的数据集包括这些车辆的带有时间戳的传感器读数，我还有一个文件，其中显示过去哪些车辆被报告被盗。 我认为某些驾驶行为与盗窃密切相关（例如，高速、长时间驾驶、跨境驾驶等）。 我面临的挑战是盗窃报告通常是在实际盗窃发生几天后提交的，这导致传感器数据的时间戳与盗窃的实际时间不一致。这种延迟使得很难准确地将传感器数据与盗窃的发生联系起来，我担心这可能会影响我的模型实时检测盗窃的能力。 最初，我考虑使用自动编码器或隔离森林进行无监督异常检测，但这种方法可能不起作用，原因有二：  盗窃并非极为罕见 由于数据来自租赁汽车，因此由于每辆车的驾驶员各不相同，因此不存在“正常”驾驶行为。  以前有人处理过类似的问题吗？如果您能就预处理技术或模型策略提出任何有助于缓解此问题的建议，我将不胜感激。 提前感谢您的见解！    提交人    /u/Laippe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq9mqx/d_how_to_handle_time_delays_between_event/</guid>
      <pubDate>Mon, 12 Aug 2024 09:54:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有没有关于新的 Flux 图像生成模型的论文/技术报告？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq9det/r_is_there_any_papertechnical_report_about_the/</link>
      <description><![CDATA[我发现 X 和 LinkedIn 被 Black Forest Labs 发布的新型 Flux 模型产生的一些令人印象深刻的结果所取代。 有没有关于这些模型的技术报告或论文？我似乎找不到任何东西。如果没有，有没有相关论文可以指出所使用的方法？（我想 Rombach 最近的工作可能是一个很好的起点）    提交人    /u/ats678   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq9det/r_is_there_any_papertechnical_report_about_the/</guid>
      <pubDate>Mon, 12 Aug 2024 09:36:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 新的 Llama 缩放定律？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq95ga/d_new_llama_scaling_laws/</link>
      <description><![CDATA[&quot;在开发 Llama 3 的过程中，我们对扩展行为进行了一些新的观察。例如，虽然 8B 参数模型的 Chinchilla 最佳训练计算量对应于 ~200B 个 token，但我们发现即使在使用两个数量级以上的数据训练模型后，模型性能仍会继续提高。在我们使用高达 15T 的 token 进行训练后，我们的 8B 和 70B 参数模型都继续以对数线性方式提高。较大的模型可以用较少的训练计算来匹配这些较小模型的性能，但较小的模型通常是首选，因为它们在推理过程中效率更高。&quot; 这是摘自Meta Llama 3 介绍：迄今为止最强大的公开可用 LLM 您认为 Llama 刚刚引入了新的扩展定律吗？ Chinchilla 之前为什么没发现这一点？模型大小与 token 数量的比例有没有新的数字？    提交人    /u/akashkash   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq95ga/d_new_llama_scaling_laws/</guid>
      <pubDate>Mon, 12 Aug 2024 09:21:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformers 是通用的上下文学习器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq5bkz/r_transformers_are_universal_incontext_learners/</link>
      <description><![CDATA[这项工作探索了 Transformer 的表现力，重点关注它们处理任意数量上下文标记的能力。值得注意的是，单个 Transformer 可以处理具有固定嵌入维度和恒定数量头的无限数量的标记。注意层之间 MLP 层的使用也受到严格监管    提交人    /u/AhmedMostafa16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq5bkz/r_transformers_are_universal_incontext_learners/</guid>
      <pubDate>Mon, 12 Aug 2024 05:06:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用断路器提高一致性和稳健性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq4c77/r_improving_alignment_and_robustness_with_circuit/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq4c77/r_improving_alignment_and_robustness_with_circuit/</guid>
      <pubDate>Mon, 12 Aug 2024 04:10:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于撰写基准论文的优点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq22hg/d_pros_about_writing_a_benchmark_paper/</link>
      <description><![CDATA[作为一个从未写过论文提出基准的人，我只能想象写一篇论文会有什么见解/收获。也许发现模型的底层性能就是其中之一。对于那些写过类似文章的人，你觉得你的经验有价值吗？你会推荐吗？    提交人    /u/Haunting_Air3071   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq22hg/d_pros_about_writing_a_benchmark_paper/</guid>
      <pubDate>Mon, 12 Aug 2024 02:08:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢所有人在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Aug 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>