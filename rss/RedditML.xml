<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Fri, 14 Feb 2025 12:32:24 GMT</lastBuildDate>
    <item>
      <title>[r]用潜在推理扩展测试时间计算：一种反复的深度方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip8lhf/r_scaling_up_testtime_compute_with_latent/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我们研究一种新型的语言模型体系结构，能够通过隐式推理潜在空间来扩展测试时间计算。我们的模型通过迭代复发块来起作用，从而在测试时间内展开对任意深度。这与主流推理模型相反，该模型通过产生更多的令牌来扩展计算。与基于思想链的方法不同，我们的方法不需要任何专业的培训数据，可以与小型上下文窗口一起使用，并且可以捕获不容易用文字表示的推理类型。我们将概念验证模型扩展到35亿参数和8000亿个令牌。我们表明，由此产生的模型可以在推理基准上提高其性能，有时会显着，达到相当于500亿个参数的计算负载。  本文在测试时在潜在空间中推理的论文是迷人。我认为这种方法正在成为一种趋势，并可以重新定义我们如何看待语言模型中的推理。 Meta Fair在大型概念模型上的工作也涉及潜在推理。  arxiv链接： [2502.05171]带有潜在推理：经常性深度方法   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/hiskuu     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip8lhf/r_scaling_up_testtime_compute_with_latent/</guid>
      <pubDate>Fri, 14 Feb 2025 11:32:58 GMT</pubDate>
    </item>
    <item>
      <title>[d] val acc高于火车ACC</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip88et/d_val_acc_higher_than_train_acc/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有任何理由验证精度高于分类任务中的训练精度（Train ACC = 0.82，Val ACC = 0.88）？还是只是随机机会？ 编辑：typo。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/_my__Real_name_      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip88et/d_val_acc_higher_than_train_acc/</guid>
      <pubDate>Fri, 14 Feb 2025 11:08:05 GMT</pubDate>
    </item>
    <item>
      <title>[d]建立客户服务聊天机器人以取代对讲机我应该收取多少费用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip802v/d_how_much_should_i_charge_for_building_a/</link>
      <description><![CDATA[在.com）。该机器人需要处理客户查询，自动化响应并可能与其现有系统集成。 我有软件开发方面的经验，但我不确定如何为这种项目定价。我应该收取统一费率，小时或某种订阅模型吗？关于这样的价格的任何见解吗？ 很想听听那些从事类似项目的人的消息！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/iamretis     [link]   ＆＃32;   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip802v/d_how_much_should_i_charge_for_building_a/</guid>
      <pubDate>Fri, 14 Feb 2025 10:51:40 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何为模型验证源数据（地面真相）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip7im1/d_how_do_you_source_data_ground_truth_for_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的团队有一个分类模型，我们旨在经常评估以保持对预测的信心并收集标记的数据以扩展我们的数据集。我努力及时获得高质量的标签数据，在许多情况下必须自己做。它暂时有效（无论如何），但是每当我们有很多活跃的站点/工作时，所有这些都会变得非常压力，并且通常需要一段时间才能完成所有验证/标签，以便我们可以自信地关闭工作。 我很好奇是否有人会经历这种痛苦。您如何找到和管理人员？你有什么工具？您的挑战是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/u/unhungry_assistant6753    r/machinelearning/commist/1ip7im1/d_how_do_you_source_data_data_ground_truth_for_model/“&gt; [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ip7im1/d_how_do_do_you_source_data_data_data_truth_truth_for_model/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip7im1/d_how_do_you_source_data_ground_truth_for_model/</guid>
      <pubDate>Fri, 14 Feb 2025 10:15:42 GMT</pubDate>
    </item>
    <item>
      <title>[r]值得信赖的检索效果一代：可靠性，隐私，安全，公平和问责制的框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip7dvv/r_trustworthy_retrievalaugmented_generation_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项综合调查研究了建立可信赖的抹布系统的关键挑战和方法，这对于可靠的AI应用程序变得越来越重要。 主要技术贡献重点是： - 分析抹布系统中的可信度维度（检索准确性，发电忠诚，来源信誉） - 对改善抹布可靠性的当前方法的系统审查 - 评估抹布系统的信任框架 - 评估当前基准和指标的评估 关键发现和方法论： - 检索质量对下游产生产生重大影响 - 多个检索可以提高准确性但提高复杂性 - 来源归因和信心评分有助于防止幻觉 - 当前的评估指标通常无法捕获重要的可信度方面&lt; /p&gt; 结果突出了一些关键挑战： - 从多个来源管理冲突的信息 - 平衡检索精度与回忆 - 在检索到的环境之间保持一致性 - 处理不完整或模棱两可的证据 我认为这项工作提供了开发更可靠的抹布系统的重要基础。拟议的评估框架可以帮助标准化我们如何评估抹布的可信赖性，而确定的挑战指向清除研究方向。对来源信誉和透明归因的强调似乎与现实世界应用特别相关。  tldr：调查分析抹布系统中的信任度，涵盖技术挑战，当前的方法和评估方法。提出了评估抹布可靠性并确定改进的关键领域的框架。 完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip7dvv/r_trustworthy_retrievalaugmented_generation_a/</guid>
      <pubDate>Fri, 14 Feb 2025 10:05:51 GMT</pubDate>
    </item>
    <item>
      <title>[D]扩散模型及其统计不确定性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip6doi/d_diffusion_models_and_their_statistical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我对扩散模型的统计信息有问题。在诸如DDPM和DDIM之类的方法中，可以在任何扩散时间步骤中获得清洁图像（X0）的估计值。当然，此估算有一些相关的错误，但是似乎没有纸上关于此的论文。我在这里错过了什么吗？这是我正在进行的一项研究。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unk0wnvar     [link]   ＆＃32;   [commistion]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip6doi/d_diffusion_models_and_their_statistical/</guid>
      <pubDate>Fri, 14 Feb 2025 08:50:36 GMT</pubDate>
    </item>
    <item>
      <title>[d]如何处理蒸馏中的学生与教师模型的不同数据分布？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip5d07/d_how_to_deal_with_different_data_distribution/</link>
      <description><![CDATA[在一小时和B型3天。 我想蒸馏出B模型A建模，以使A模型可以从模型B中的其他信号中学习对于A和B模型来说，这应该是正确的，因此转移学习。 问题是B在训练过程中比模型A所看到的数据更多，并且可以根据更长的时间进行预测窗口及其真正的概率不同。即使使用PLATT缩放尺度或根据自己的分布进行校准，从理论上讲，它们也将彼此之间存在不同的数据分布，例如 我对如何从较长的时间窗口进行蒸馏而失去了不同的阳性率。自适应加权，但没有一个具体解决这个问题……  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tough_palpitation331     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ip5d07/d_how_to_to_deal_with_with_different_data_distribution/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip5d07/d_how_to_deal_with_different_data_distribution/</guid>
      <pubDate>Fri, 14 Feb 2025 07:33:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML调试面试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip4ypj/d_ml_debugging_interview_for_experienced_roles/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您好，&lt; / p&gt; 最近，我一直在为应用的ML / ML研究工程师角色准备采访。我想练习更多的技能来调试Pytorch或任何ML管道。我想知道是否有人以前经历过这种采访，并且可以为如何做最好的准备。如果您还可以分享此类面试问题的示例，那就太好了。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unessionarybelt750     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip4ypj/d_ml_debugging_interview_for_experienced_roles/</guid>
      <pubDate>Fri, 14 Feb 2025 07:04:38 GMT</pubDate>
    </item>
    <item>
      <title>[P]纯C中的GPT-2（以及完整的CUDA工作室）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioybio/pgpt2_in_pure_cand_full_cuda_worklogs_to_come/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  并行计算是听起来令人生畏但对现代世界绝对必不可少的事情之一。从高频交易（HFT）到设备AI，最大程度地减少资源，同时最大程度地提高性能非常重要，并且随着我们转向更好的开源LLM，可能会成为瓶颈。  首先要潜入这个空间，我启动了一个项目，我以平原，幼稚和不优化的（边界愚蠢）C实现了GPT-2体系结构，而没有很大的依赖性。为什么？因为在最基本的层面上了解问题是有效优化它的唯一方法。大多数教程从基础知识开始（例如优化矩阵乘法，然后它们可能会介入基本操作/创建基于圆圈的渲染器），但是真实的生产级cuda，例如您在乔治·霍茨（George Hotz）的Tinygrad或Karpathy的LLM中看到的内核.c或类似项目是完全不同的事情。几乎没有任何结构化资源来弥合差距。 ，我的目标是吗？ ➡️从这个简单的实现开始，然后逐步优化。 ➡️学会从头开始构建cuda内核，基准测试并将它们与其他解决方案进行比较。 ➡️返回此GPT返回此GPT返回此GPT -2实施，再次逐步挑选它，看看我可以做到的速度更快，更精细，更有效。 ，我将使用完整的工作室  repolink： https://github.com/angry-kratos/gpt-2-in -c    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/atronos_kronios     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioybio/pgpt2_in_pure_cand_fule_fure_full_cuda_worklogs_to_to_to_to_come/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioybio/pgpt2_in_pure_cand_full_cuda_worklogs_to_come/</guid>
      <pubDate>Fri, 14 Feb 2025 00:43:58 GMT</pubDate>
    </item>
    <item>
      <title>[D]我们在Google和Apple建立了Genai，然后离开以建立开源AI实验室，以使开放社区能够协作和建造下一个DeepSeek。 2月14日（星期五）上午9点至下午12点，请向我们询问！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioxatq/d_we_built_genai_at_google_and_apple_then_left_to/</link>
      <description><![CDATA[在   tl; dr：嗨，我们是Oumi，一个人的AI实验室，相信无条件开源的方法 - 代码，权重，培训数据，基础架构和协作 - 因此可以集体向前推动AI。我们为任何人建立了一个在AI中进行研究的平台。向我们询问有关开放源代码，扩展大型模型，DeepSeek的任何内容，以及在大型科技公司内外建立前沿模型所需的内容。告诉我们什么在开源AI中运作良好或您面临的挑战。我们应该共同努力以改进公开的AI？  ------------------------------  多年来，我们在Big Tech（Google）工作，苹果，微软）在Google Cloud Palm，Gemini和Apple的Health Foundation模型等Genai模型上的主要努力。我们在孤岛工作，知道必须有一种更好的方法来公开和协作开发这些模型。因此，我们建立了一个真正的开源AI平台，使世界各地成千上万的AI研究人员，科学家和开发人员可以合作，以一种集体的方式促进Frontier AI，从而导致更有效，透明和透明和稳定负责任的发展。 OUMI平台（完全开源，Apache 2.0许可证）支持预训练，调整，数据策展/综合，评估以及任何其他常见的效用，以完全可记录的和可重复的方式，同时易于自定义以支持新方法。   DeepSeek向我们展示了开源通过利用Llama之类的开放权重模型可以实现的目标。但是我们认为，AI应该更加开放：不仅是权重，而且还应该进行培训数据，以及代码将其全部打开。然后走得更远：使任何人都可以轻松访问和实验，使社区可以轻松合作和协作。  如果您有兴趣的话，有关OUMI的一些资源： 我们的github repo： https：https： //github.com/oumi-ai/oumi   我们的发布故事： https://venturebeat.com/ai/ex-google-google-apple-apple-egneers-launch -uncondition-open-source-oumi-ai-platform-that-that-that-that-the-could-help-to-build-the-next-deepseek/  我们的网站： https://oumi.ai/    如果您想协作并为社区研究项目做出贡献，无论您在哪里得到计算，都可以签名在： https://oumi.ai/community 。我们将从现有开放模型的训练后开始，接下来，我们将协作进行改进，以进行培训。我们打算与包括作者的所有贡献者一起发布研究。 我们在这里回答有关我们的开源方法，扩展大型模型，DeepSeek的问题大型科技公司以及大家都想讨论的其他任何事情。&lt; / p&gt; 我们将于2月14日星期五上午9点至下午12点pt / 12 pm-3 pm-3pm。问我们任何事情。  加入我们的AMA：   （ u/koukoumidis ） manos koukoumidis   - 首席执行官兼联合创始人ex-google（cloud genai铅） （ u/oelachqar ） Oussama elachqar   - 联合创始人，工程，Ex-Apple（健康基础模型） （ u/matthewpersons ） Matthew Persons   - 联合创意，工程学，工程，Ex -google（云棕榈＆amp; nl铅） （ u/jeremy杰里米·格里尔（Jeremy Greer）  - 联合创始人，研究，前google（双子座对齐）    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/koukoumidis     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioxatq/d_we_built_genai_genai_google_and_apple_apple_paple_then_left_then_left_to/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioxatq/d_we_built_genai_at_google_and_apple_then_left_to/</guid>
      <pubDate>Thu, 13 Feb 2025 23:53:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlignRec在多模式建议中优于SOTA模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioo1ta/r_alignrec_outperforms_sota_models_in_multimodal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   alignrec，在 alignrec中引入：在多模式建议中对齐和训练（cikm &#39;24），解决多模式建议系统中的错误对准。传统方法难以整合各种内容类型（文本，图像和分类ID）到语义差距。 AlignRec通过优化三个对齐任务来解决此问题：ICA INTER-CONTENT（ICA），CONTENT类别（CCA）和用户项目（UIA）。 ICA通过基于注意力的编码器将语义表示统一，CCA使用对比度学习增强特征对齐，UIA通过余弦相似性损失来完善用户项目表示。   关键的Innovation是Alignrec的两阶段训练：预 - 培训使视觉和文本数据对齐，同时微型调整结合了用户行为以进行优化的建议。在亚马逊数据集中测试，它的表现优于九种SOTA模型，在长尾建议方面表现出色。通过弥合多模式语义差距，AlignRec提高了准确性和鲁棒性，推进了多模式AI驱动的建议。 以深入研究框架并结果，请参阅此处的完整纸张文章： https://www.shaped.ai/blog/multimodal-alignment-for-recmmentations   &lt; /div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/skeltzyboiii     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioo1ta/r_alignrec_outperforms_sota_moda_models_in_multimodal/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioo1ta/r_alignrec_outperforms_sota_models_in_multimodal/</guid>
      <pubDate>Thu, 13 Feb 2025 17:13:07 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何从头开始进行ML研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ion90w/d_how_you_do_ml_research_from_scratch/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   有人在顶级ML会议（NIPS，ICML，ICLR）或面向域的会议（CVPR，ICCV，ACL，EMNLP，KDD）上发布了作品，Sigir）。 1。如何从0到第一张纸？ 2。您的技能（Pytorch或域知识）是多少？ 3。您遵循的整个过程是什么善于实施您的想法？ 4。您如何提出想法和解决方案？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/antelopewilling2928      r/machinelearning/注释/1ion90w/d_how_you_do_do_ml_research_from_scratch/“&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ion90w/d_how_you_do_ml_research_from_scratch/</guid>
      <pubDate>Thu, 13 Feb 2025 16:40:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] Swe-Agent是Swe Bench Lite上的新开源SOTA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iolpvo/r_sweagent_is_the_new_opensource_sota_on_swebench/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   swe-agent是一种开源软件工程代理，可与任何类型的型号一起使用。我们的1.0版本增加了许多新功能：大规模并行运行；基于云的部署；具有工具捆绑包的广泛可配置性；新命令行接口＆amp;公用事业。完全开源（MIT），广泛的配置，易于破解。由于它将LITELLM用于LM接口，因此您可以与本地LM一起使用它：我们已经与QWEN一起使用了它，而其他社区成员已将其与Llama一起使用。   https://github.com/swe-agent/swe-agent    swe-agent现在由我们的新swe--提供支持REX软件包（也获得了MIT许可），这是一款轻巧的通用沙盒代码执行引擎，支持本地Docker，AWS，Modal Deployments  https：https：https：https：https： //github.com/swe-agent/swe-rex 。您可以使用它来轻松地从头开始使用代码执行，而无需弄清楚如何与运行的Docker容器进行通信！  swe-agent是由普林斯顿大学＆amp;开发的。斯坦福大学。如果您有任何疑问，我们将在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ofirpress     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iolpvo/r_sweagent_is_the_new_new_opensource_sota_sota_on_swebench/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iolpvo/r_sweagent_is_the_new_opensource_sota_on_swebench/</guid>
      <pubDate>Thu, 13 Feb 2025 15:35:03 GMT</pubDate>
    </item>
    <item>
      <title>[R]企业中的文本到SQL：比较方法和对我们有用的方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iojc1f/r_texttosql_in_enterprises_comparing_approaches/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  嗨hivery！  text-to-sql是一个流行的Genai用例，我们最近与一些企业合作。在这里分享我们的学习！ 这些企业已经尝试了不同的方法 - 使用rag，使用gpt-4O（例如GPT-4O），甚至是使用Autogen和Crew的GPT-4O，甚至基于代理的方法，将OR-LLM等最佳的LLM进行。但是它们以85％的精度撞到了天花板，面临超过20秒的响应时间（主要是由于错误的列出现的错误），并处理了使缩放硬缩放的复杂工程。 我们发现了这种微调在特定于商业的查询-SQL Pairs上的开放量LLM具有95％的精度，响应时间降低到7秒以下（通过消除故障恢复）和简化的工程。这些自定义的LLM保留了域内存，从而导致了更好的性能。 我们在上进行了比较。 sql-the-the-the-ultimate-guide-for-2025-3fa4e78cbdf9“&gt;中等。让我知道您的想法，如果您看到了更好的方法来解决此问题。 = Webp＆amp; s = 88251E0CFA246F2BF1F779E708AB03A96A3C0255“&gt; https：//preview.redd.i 246F2BF1F779E708AB03A96A3C0255    &lt; ！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sircomprehense7453     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iojc1f/r_texttosql_in_enterprises_comparing_approaches/</guid>
      <pubDate>Thu, 13 Feb 2025 13:44:21 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>