<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 26 Dec 2024 06:23:40 GMT</lastBuildDate>
    <item>
      <title>[D] 物理学和逻辑学的结合最近取得了什么进展？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmds2k/dhow_have_recent_advancements_with_incorporating/</link>
      <description><![CDATA[去年，关于这项技术将带来的承诺，曾有过大量讨论，但之后就没有什么进展了。    由    /u/sext-scientist  提交  [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmds2k/dhow_have_recent_advancements_with_incorporating/</guid>
      <pubDate>Thu, 26 Dec 2024 01:28:20 GMT</pubDate>
    </item>
    <item>
      <title>太字节级 MoE：一种用于超越 RAM 模型推理的学习型按需专家加载和智能缓存框架 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm93jj/terabytescale_moes_a_learned_ondemand_expert/</link>
      <description><![CDATA[大型模型很容易装入硬盘，但很难装入 RAM 或 VRAM。以下是我解决这个问题的想法： 在 RAM 中训练一个包含所有专家的大型混合专家模型，然后在推理时，一个学习机制会动态地将相关专家加载到 VRAM/RAM 中。这允许模型超出硬件的内存限制，同时保持推理效率，因为系统本身学习哪些专家需要“热门”并避免不必要的交换。当然，交换仍然会发生，但希望很少发生。 已经尝试过类似的事情了吗？    提交人    /u/thepok   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm93jj/terabytescale_moes_a_learned_ondemand_expert/</guid>
      <pubDate>Wed, 25 Dec 2024 21:09:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 教 VLM 通过读写任务将手写图像转换为数字墨水</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm8a6s/r_teaching_vlms_to_convert_handwritten_images/</link>
      <description><![CDATA[标题：InkSight：通过学习阅读和写作实现离线到在线手写转换 项目页面： https://charlieleee.github.io/publication/inksight/ TLDR： 通过教授视觉语言模型读写，我们能够弥合传统手写和数字墨水之间的差距，提供通过盲测评估的高质量数字描摹，其中 87% 被判定为有效，67% 与人类生成的墨水无法区分。 消融研究强调了识别（“阅读”）任务在确保语义一致性方面的重要性，而推理策略则展示了处理模糊手写的灵活性。此外，使用去渲染墨迹作为训练数据与真实世界数据集结合可增强手写识别效果，将字符错误率降低至 4.6%。这些发现展示了 InkSight 在推进手写数字化和识别系统方面的潜力。 代码和模型发布： https://github.com/google-research/inksight    提交人    /u/CharlieLee666   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm8a6s/r_teaching_vlms_to_convert_handwritten_images/</guid>
      <pubDate>Wed, 25 Dec 2024 20:26:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 精神障碍的 sMRI 或 fMRI 扫描公共数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm7bfe/r_public_datasets_of_smris_or_fmris_scans_of/</link>
      <description><![CDATA[我目前正在大学里做一个研究项目，明年 7 月我将提交该项目。该项目目前处于起步阶段，基础才刚刚开始奠定，因为我必须开始收集用于训练模型的数据，但基本思路已经基本确定。我在这种类型的研究中有一些经验，因为我已经使用 Vision Transformer 训练了一个深度学习模型，它可以实时区分 ASL 字母表的手势。 但是，根据我目前所做的研究（我还需要做很多研究），似乎其中一些数据集具有一种特殊的文件格式 (.nii)，需要特殊的预处理。该项目的范围非常灵活，因为我可以根据互联网上公开的数据类型定义标签。由于我在这个领域还比较新，我不知道你们中是否有人已经研究过这个主题并训练过与此相关的模型。如果您愿意，非常感谢您能提供一些指导，并且如果当前可用的数据集（如 ADHD-200 或 SchizoConnect 中的数据集）的数据良好。谢谢。    提交人    /u/MessierKatr   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm7bfe/r_public_datasets_of_smris_or_fmris_scans_of/</guid>
      <pubDate>Wed, 25 Dec 2024 19:34:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 无编码器视觉语言模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm6qpu/d_encoder_free_vision_language_models/</link>
      <description><![CDATA[节日快乐！有没有关于无编码器 VLM 的有趣论文？最近在看视频 VLM，最大的麻烦是编码器效率。此外，端到端质量在很大程度上受限于视觉编码器的质量，而视觉编码器通常是 CLIP 样式模型。有 Fuyu 模型系列，但这种架构似乎表现不佳。最近有一篇 NeurlPS 论文：https://github.com/baaivision/EVE 看起来很有趣。期待对这个工作方向的评论和建议。    提交人    /u/encoreway2020   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm6qpu/d_encoder_free_vision_language_models/</guid>
      <pubDate>Wed, 25 Dec 2024 19:04:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 不确定如何可视化 RL 图？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm6nga/p_not_sure_how_to_visualize_rl_diagram/</link>
      <description><![CDATA[      我想我找到了下面问题第一部分的正确解决方案，但第二部分我遇到了麻烦。有人知道流程图实际上是什么样子吗？有人可以提供一张快速图像吗？非常感谢！ 想一个简单的游戏： a. 每一轮，你可以继续或退出。 b. 如果你退出，你会得到 5 美元，游戏结束。 c. 如果你继续，你会得到 3 美元并掷一个 6 面的骰子。如果骰子点数为 1 或 2，游戏将结束。否则，游戏继续进行下一轮。 这里有一个明显的权衡。首先，我们可以用 2 美元的确定性收益来换取掷骰子并继续下一轮的机会。 要创建 MDP 来模拟这个游戏，首先我们需要定义一些东西： 我们可以正式将马尔可夫决策过程描述为 m = (S, A, P, R, gamma)，其中： - S 表示所有状态的集合。 - A 表示可能的操作集合。 - P 表示转移概率。 - R 表示奖励。 - Gamma 被称为折扣因子。在这种情况下，折扣因子为 2/3。 https://preview.redd.it/15xthh3dl19e1.jpg?width=556&amp;format=pjpg&amp;auto=webp&amp;s=00c68fa27076a591cede12d1d90fb8ebdd405706 问题 1：完成下图中 P1、P2 和 P3 的概率值，该图显示了上述场景的 MDP。另外，说明奖励 R1 和 R2 的值。红色箭头表示每种可能情况的概率，绿色框表示奖励。 我的答案：P1、P2 和 P3 的转换概率值包括： P1​：掷出 3、4、5 或 6 的概率，从而继续游戏 = 4/6 = 0.67 P2​：掷出 1 或 2 的概率，从而结束游戏 = 2/6 = 0.33 P3​：选择退出操作时退出的概率 = 1（确定性） 奖励值包括： R1​：继续的奖励（每轮）= 3 R2​：退出奖励 = 5   问题 2：现在考虑折扣因子。在上述 MDP 中有两种可能的状态，继续和退出。在每一步中，我们要么退出并获得额外的 5 美元预期值，要么留下并获得额外的 3 美元预期值。每个新回合，预期值乘以 2/3，即折扣因子。绘制流程图以显示 4 轮后两种状态的总奖励是多少。还要确定一系列动作（例如：继续-&gt;继续-&gt;退出等），以显示 4 轮后奖励的最大化。 不确定？     提交人    /u/Pale-Head-3910   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm6nga/p_not_sure_how_to_visualize_rl_diagram/</guid>
      <pubDate>Wed, 25 Dec 2024 19:00:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据采样的聚类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm30h6/d_clustering_for_data_sampling/</link>
      <description><![CDATA[我正在开展一个 OCR 项目，需要手动为其注释数据。我认为我需要收集尽可能多视觉变化的页面样本，并且我想自动进行采样。 我认为我可以使用预训练的神经网络从每个页面中提取特征，并避免包含具有相似特征的页面。我认为这可以通过某种形式的聚类来实现，然后我会从每个聚类中抽样一次。 我的问题是：  这是一种有效的抽样方式吗？它有名字吗？ 我正在考虑使用 k-means，但它可以以在线方式完成吗？这样我以后可以添加新页面而不会弄乱以前的聚类，但仍然能够添加新聚类？  谢谢，节日快乐！    提交人    /u/neuralbeans   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm30h6/d_clustering_for_data_sampling/</guid>
      <pubDate>Wed, 25 Dec 2024 15:47:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] JaVAD——又一款语音活动检测器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hlz6az/p_javad_just_another_voice_activity_detector/</link>
      <description><![CDATA[刚刚发布了我在过去 3 个月内研究的一个 VAD（不计算模型本身的时间），它看起来至少与其他开源 VAD 相当或更好。  它是一个自定义的基于卷积的架构，在梅尔频谱图上使用滑动窗口，因此速度也非常快（在 3090 上需要 16.5 秒来加载和处理来自测试集的 18.5 小时的音频）。 它也非常紧凑（包括检查点在内的所有内容都适合 PyPI 包），如果你不需要加载音频，核心功能依赖只是 pytorch 和 numpy。 其他一些 VAD 是通过混合语音和噪音在合成数据上进行训练的，我认为这就是它们在嘈杂音频上落后的原因。对于这个项目，我手动标记了数十个 YouTube 视频，特别是老电影和电视节目，其中有很多噪音。 还有一个用于流媒体的类，尽管由于滑动窗口和规范化的性质，处理音频的初始部分可能会导致较低质量的预测。 MIT 许可证  这是一个个人项目，所以我很确定我错过了一些东西（或者很多），请随时在 github 上发表评论或提出问题。 这是链接：https://github.com/skrbnv/javad    提交人    /u/ApprehensiveLet1405   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hlz6az/p_javad_just_another_voice_activity_detector/</guid>
      <pubDate>Wed, 25 Dec 2024 11:33:57 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 推荐系统中隐式反馈的 SOTA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hlyy4i/discussion_sota_for_implicit_feedback_in/</link>
      <description><![CDATA[在处理大量隐式观察以推荐内容/金融工具等方面的行业标准和最新进展是什么？ 据我所知，有几篇关于这个主题的重要论文（不包括更知名的算法，如 SVD++）： Spotify： 隐式反馈数据的逻辑矩阵分解 AT&amp;T 隐式反馈数据集的协同过滤 我很想知道是否还有其他方法在 Netflix 基准上表现良好（当有评级时仅取 1，否则取 0 而不是评级）本身）。    由   提交  /u/Illustrious-Bag2386   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hlyy4i/discussion_sota_for_implicit_feedback_in/</guid>
      <pubDate>Wed, 25 Dec 2024 11:15:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 Byte Latent Transformer 中，解码后的patch边界是如何确定的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hli20i/d_in_byte_latent_transformer_how_is_the_decoded/</link>
      <description><![CDATA[在 Meta 最近的论文 Byte Latent Transformer 中，我了解到本地编码器模型使用 patch 分割方法（例如基于熵的方法）首先切割 patch，然后对于每个 patch，交叉注意力将关注该批次中的字节（因为 patch 边界已经确定）。但是，在这种情况下解码如何工作？是不是在解码每个字节时，都假设它在最新的 patch 中，如果检测到新的输出字节是新的 patch 边界（例如使用基于熵的方法），它会切割一个新的 patch，未来的字节现在属于这个 patch？如果是这样的话，每个输出 patch 的起始字节是否可以使用前一个 patch 有效地解码？还是当找到新的边界时，这个字节被丢弃，开始一个新的 patch，并使用这个新的 patch 再次解码它的起始字节？我不确定作者是否在论文中明确提到了这一点。    提交人    /u/TommyX12   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hli20i/d_in_byte_latent_transformer_how_is_the_decoded/</guid>
      <pubDate>Tue, 24 Dec 2024 17:19:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] OREO：用于大型语言模型中多步推理的离线强化学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hlglku/r_oreo_offline_rl_for_multistep_reasoning_in/</link>
      <description><![CDATA[本文介绍了 OREO，一种新颖的离线 RL 方法，它将策略学习与价值评估相结合，以改进 LLM 多步推理。关键创新是使用软贝尔曼方程和偏好优化来更好地在推理步骤之间分配信用。 主要技术要点： - 通过偏好学习和价值函数估计实现离线 RL - 使用软贝尔曼方程学习最佳行为 - 同时训练策略和价值函数 - 与现有的 DPO（直接偏好优化）方法集成 - 在 GSM8K、MATH 和 ALFWorld 基准上进行测试 结果： - 在 GSM8K 数学推理任务上的表现优于基线方法 - 在 MATH 基准问题上表现出改进的性能 - 在 ALFWorld 环境中展示更好的推理能力 - 在推理步骤中实现更有效的信用分配 - 减少推理期间的计算开销 我认为这项工作解决了让 LLM 执行复杂推理的一个根本挑战。通过更好地了解哪些步骤对成功的结果贡献最大，我们可以为需要精确逻辑思维的任务训练更有能力的系统。该方法对于自动定理证明、机器人规划和其他需要结构化多步骤推理的领域的应用可能特别有价值。 我特别感兴趣的是，这种方法如何扩展到更开放的推理任务，其中“正确”的步骤顺序并不像数学问题那样明确定义。推理过程中的计算效率也值得注意，因为它表明了实际的可部署性。 TLDR：新的离线 RL 方法结合了策略学习和价值评估，通过更好地理解哪些步骤对成功结果最重要来改进 LLM 推理。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hlglku/r_oreo_offline_rl_for_multistep_reasoning_in/</guid>
      <pubDate>Tue, 24 Dec 2024 16:07:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了一个 TikTok Brain Rot 视频生成器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hlgdyw/p_i_made_a_tiktok_brain_rot_video_generator/</link>
      <description><![CDATA[我制作了一个简单的脑腐生成器，可以根据单个 Reddit URL 生成视频。 Tldr：事实证明，制作它并不容易。 简单地说，让这个超级困难的主要思想是文本和音频之间的对齐，又称强制对齐。因此，在这个项目中，Wav2vec2 用于音频提取。然后，它使用来自音频的逐帧标签概率，创建一个网格矩阵，该网格矩阵表示在使用网格矩阵（回溯算法）中最可能路径之前每次对齐标签的概率。 如果没有我所关注和学习的 Motu Hira 关于强制对齐的教程，这真的不可能完成。请注意，这里面的数学运算相当繁重： https://pytorch.org/audio/main/tutorials/forced_alignment_tutorial.html 示例： https://www.youtube.com/shorts/CRhbay8YvBg 这是 github repo：（如果您对此感兴趣，请为该 repo 加注星标🙏） https://github.com/harvestingmoon/OBrainRot?tab=readme-ov-file 一如既往，欢迎任何建议：）    由   提交  /u/notrealDirect   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hlgdyw/p_i_made_a_tiktok_brain_rot_video_generator/</guid>
      <pubDate>Tue, 24 Dec 2024 15:57:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们可以不要再在标题中使用“这就是我们所需要的”吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hlbtrs/d_can_we_please_stop_using_is_all_we_need_in/</link>
      <description><![CDATA[正如标题所示。我们需要停止或减少在论文标题中使用“......就是我们所需要的”。它慢慢变得有点荒谬。大多数时候它没有实际的科学价值。它已经成为一种为了吸引注意力而吸引注意力的不良做法。    提交人    /u/H4RZ3RK4S3   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hlbtrs/d_can_we_please_stop_using_is_all_we_need_in/</guid>
      <pubDate>Tue, 24 Dec 2024 11:37:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>