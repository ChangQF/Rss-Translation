<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Mon, 03 Mar 2025 06:26:54 GMT</lastBuildDate>
    <item>
      <title>[p]我如何在短短2周内使用DeepSeek建造AI＆ML就业委员会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2bkhh/phow_i_built_an_ai_ml_job_board_in_just_2_weeks/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我刚刚花了2周的时间构建AI＆amp;使用DeepSeek的ML工作板，我对这些工作进行了详细分类和过滤。  让我分解我的工作方式！ 首先，我使用了诸如AI，ML和数据科学之类的关键字来从公司网站上刮擦尽可能多的职位发布。 。如果是这样，我将其归类为18个特定类别之一，以使用户非常容易过滤并确切地找到他们想要的东西。类别是：机器学习，深度学习，计算机视觉，NLP，提示，研究，生成AI，MLOPS，数据科学，大数据，可视化，分析师，工程师，基础架构，建筑，建筑，产品，领导力和顾问。  接下来，我直接从其官方网站中获取公司信息，因此用户可以根据公司规模，资金阶段，资金金额，甚至他们是否支持H1B签证来过滤工作。这可以帮助用户在不同阶段的公司（尤其是预种子，种子和A系列AI创业公司）的工作中零从事工作。  然后，它是正式推出的。您可以在此处查看： Easyjob ai   非常感谢任何尝试过的人。我非常感谢你们花时间。请LMK我如何改善它。您可以在/u/u/u/no/no-wrongdoer-4654       [link]       &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j2bkhh/phow_i_built_i_built_an_ai_ai_ai_ml_job_job_job_in_iin_just_just_just_2_weeks/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2bkhh/phow_i_built_an_ai_ml_job_board_in_just_2_weeks/</guid>
      <pubDate>Mon, 03 Mar 2025 05:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[d]机器学习工程师角色与ML核心的应用科学家角色之间有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j21zmk/d_what_is_the_difference_between_machine_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     他们的责任的一般差异是什么？ 未来的阶梯？ 付费？    我发现这里有几个类似的问题在这里4-5岁。从那以后发生了很多事情（蓬勃发展的公司，然后是大规模裁员，Chatgpt Boom等），我想再次要求这一点以了解当前的行业环境。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/madgradstudent99    href =“ https://www.reddit.com/r/machinelearning/comments/1j21zmk/d_what_is_is_the_the_difference_between_machine_learning/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j21zmk/d_what_is_the_difference_between_machine_learning/</guid>
      <pubDate>Sun, 02 Mar 2025 21:28:57 GMT</pubDate>
    </item>
    <item>
      <title>[d] 3+方式的对比风格损失</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j213rp/d_contrastive_style_losses_for_3_modalities/</link>
      <description><![CDATA[在（例如，图像捕获对），批处理中的其他所有内容通常被视为负面。我正在使用3种以上的方式，因此“正面”是“正面”。实际上是一个积极的三胞胎/四倍/等。就我而言。我可以使用什么损失？目前，我正在计算成对的损失，并平均它们。 （例如，对于3种模态，a，b，c是每种模态 - ＆gt;（损失（a，b） +损失（a，c） +损失（b，c）） / 3的阳性三胞胎。有更好的方法吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dudester_el   href =“ https://www.reddit.com/r/machinelearning/comments/1j213rp/d_contrastive_style_style_losses_for_3_modalities/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j213rp/d_contrastive_style_losses_for_3_modalities/</guid>
      <pubDate>Sun, 02 Mar 2025 20:51:40 GMT</pubDate>
    </item>
    <item>
      <title>Jupyter笔记本作为初稿[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j20dae/jupyter_notebook_as_a_first_draft_d/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我是计算机科学的硕士学生，夏季在机器学习方面进行了几次实习。我很想知道其他人如何处理小型项目或ML实施的最初草案。 在开始时，当我进行小型项目或ML实施时，我首先创建了一个笔记本文件来起草我的程序。然后，我将笔记本重构为Python文件。我发现这种方法更容易进行调试和实验，因为我有时仍然使用Numpy，Torch，Pandas语法挣扎，并且需要一种快速的方法来仔细检查输出。 你们如何如何创建一个小型项目？您还有其他建议吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1j20dae/jupyter_notebook_a as_a_a_first_draft_d/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j20dae/jupyter_notebook_as_a_first_draft_d/</guid>
      <pubDate>Sun, 02 Mar 2025 20:20:42 GMT</pubDate>
    </item>
    <item>
      <title>[P]为AI代理制作了工具：可以通过编程控制的Dockerized VS代码 +鹅代码代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1xs2q/p_made_a_tool_for_ai_agents_dockerized_vs_code/</link>
      <description><![CDATA[   /u/u/thribcardiogids656     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j1xs2q/p_made_a_a_tool_ai_ai_ai_ai_aigents_dockerized_vserized_vs_code/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1xs2q/p_made_a_tool_for_ai_agents_dockerized_vs_code/</guid>
      <pubDate>Sun, 02 Mar 2025 18:33:44 GMT</pubDate>
    </item>
    <item>
      <title>[p]我制作了体重 - 一种简单的方法，可以在一分钟内训练任何嵌入模型的适配器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1udcu/p_i_made_weightgain_an_easy_way_to_train_an/</link>
      <description><![CDATA[   /u/u/jsonathan       [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1udcu/p_i_made_weightgain_an_easy_way_to_train_an/</guid>
      <pubDate>Sun, 02 Mar 2025 16:13:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] Camie Tagger -70,527动漫标签分类器在单个RTX 3060上训练，F1得分为61％</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1u0j7/p_camie_tagger_70527_anime_tag_classifier_trained/</link>
      <description><![CDATA[       &lt;！ -  sc_off- sc_off-&gt;  3个月后，我终于完成了我的Anime Image tag dan dan dan dan dan dan dan dan dan dan achie dan achie dan achie face dan achie face dan achie face dan achie face blogbove 61％F1，数据集。该项目表明，强大的多标签分类模型可以通过正确的优化技术在消费硬件上进行培训。  关键技术细节：   在单个RTX 3060（12GB VRAM）上使用Microsoft Deepspeed for Cross firts for for Cross for for Cross-li&gt;               （214m参数）和精制模型（424m参数）。 阶段之间仅0.2％F1得分差异（61.4％vs 61.6％）。 在3.5个时期内对2m图像进行了培训（7m总样本）（7m总样本）。分类器可预测来自EfficityNet V2-L特征的标签。然后，通过对TAG共发生模式进行建模，跨注意机制可以完善预测。这种方法表明，预测标签之间的建模关系可以提高准确性而无需实质上增加计算间接费用。  内存优化：在消费者硬件上训练该模型，我使用：   零阶段2，用于优化        li&gt; li&gt; li&gt; li&gt; li&gt;   微型批量的大小为4，有效批次大小为32     标签分布：该模型涵盖7个类别：一般（30,841个标签），角色（26,968），版权所有（5,364），Artist（7,007,007），Meta（33） （20）。  类别特定的F1分数：   艺术家：48.8％（7,007 tags） 字符：73.9％（73.9％（26,968 tags） （30,841个标签） 元：60％（323个标签） 评分：81.0％（4个标签） 年：33％（20 tags）      接口：      有趣的发现：许多“误报”实际上是Danbooru数据集本身缺少正确的标签，表明该模型的现实世界性能可能比基准指示的要好。 我特别令人印象深刻，它在艺术家标签上的表现非常好，因为它们在预测所需的功能方面非常抽象。字符标记也令人印象深刻，因为示例图像显示图像在维持纵横比的同时将图像全部调整到512x512的情况下，图像中的多个（8个字符）。 我还发现，我还发现该模型仍然对现实图像也很好。也许可以通过在另一个数据集上微调模型，以更真实的示例来完成类似的事情。  拥抱面孔。还有一个用户友好的推理应用程序。随时提出问题！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/camais     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/comments/1j1u0j7/p_camie_tagger_70527_anime_anime_tag_classifier_train/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1u0j7/p_camie_tagger_70527_anime_tag_classifier_trained/</guid>
      <pubDate>Sun, 02 Mar 2025 15:58:03 GMT</pubDate>
    </item>
    <item>
      <title>[r]思想的扩散：扩散语言模型中的经过思考推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1oe6n/r_diffusion_of_thoughts_chainofthought_reasoning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   最近，由于与常规自动回归模型相比，由于它们的许多潜在优势，扩散模型对文本处理领域引起了重大兴趣。在这项工作中，我们提出了一种思想扩散（DOT），这是一种新颖的方法，将扩散模型与经过思考链集成在一起，这是一种提高自回归语言模型的推理能力的完善技术。与以左右的逐态方式做出决策的自回旋语言模型相反，DOT允许推理步骤通过扩散语言模型随时间扩散，并为推理性能提供更大的灵活性。我们的实验结果表明，DOT在多位数乘法，布尔逻辑和小学数学问题中的有效性，而小型扩散模型在效率和准确性方面的表现都超过了更大的自回归模型。除此之外，DOT还展示了有希望的自我纠正能力，并通过现有推理增强技术（例如自洽解码）的好处。我们的发现有助于通过扩散语言模型对推理的理解和发展。  不是最近的论文，但我想看看每个人对扩散语言模型的看法是制作推理LLM的手段。我觉得在尝试使用变压器进行推理时有一个巨大的问题，并且可能是不可能的（在这里个人意见）。每个人的想法是什么？提交由＆＃32; /u/hiskuu     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1oe6n/r_diffusion_of_thoughts_chainofthought_reasoning/</guid>
      <pubDate>Sun, 02 Mar 2025 10:58:06 GMT</pubDate>
    </item>
    <item>
      <title>[D]获得了海报纸的接受，但没有更多细节</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1nrhf/d_got_poster_paper_acceptance_but_no_more_details/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我两天前收到了一封电子邮件，我的论文被接受给了aaai siai hosters Paper Track。自昨天讲习班以来，此通知比他们在网站上提到的时间晚得多。我尚未注册研讨会，如果需要注册，请给他们发送电子邮件，应该在哪里提交相机准备版本，因为他们的OpenReview链接未显示任何进一步提交的选项。只是我的论文被接受了。他们仍然是他们的无线电沉默，但他们将我的论文摘要放在他们的网站上。这是我的第一篇研究论文，所以我很困惑。我需要提交注册费吗？还是太accpetd了。还是现在注册为时已晚，我的论文将被拒绝。？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/master_ocelot8179     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j1nrhf/d_got_poster_poster_paper_accepter_accepter_but_no_more_more_details/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1nrhf/d_got_poster_paper_acceptance_but_no_more_details/</guid>
      <pubDate>Sun, 02 Mar 2025 10:14:41 GMT</pubDate>
    </item>
    <item>
      <title>[r] unitok：通过多编码本矢量量化统一视觉生成和理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1l0xo/r_unitok_unifying_visual_generation_and/</link>
      <description><![CDATA[Just checked out the new UniTok paper that introduces a unified visual tokenizer capable of handling both generation and understanding tasks within a single framework. The key innovation here is a joint training approach that combines: - Reconstruction objectives (for generation capabilities) - Recognition objectives (for understanding功能） 这使一个单一的代币化系统能够有效地实现双重目的，而不会损害任何任务类型的性能。 主要技术点： - 基于变压器的编码器 - 编码器架构，具有专门的训练方法 - 与偶然性损失相结合 - 可构成噪声的差异 - 与差异的差异 - 与差异相结合 - 精细的视觉细节 - 在Imagenet，Coco和其他基准测试中实现最新的结果 - 与使用单独的专业象征器 相比，我认为这种统一方法可以显着减少需要产生和理解能力的视觉AI系统中的计算范围。拥有一个有效的系统并没有维护和运行多个专业的代币器，而是为现实部署创造实际的优势。绩效的改进表明，我们可能会看到这种方法在未来的多模式系统中成为标准。 我对这可能会影响效率至关重要的移动/边缘应用特别感兴趣 - 拥有一个可以很好地处理这两个任务的单个标记器可以使您可以在资源限制的设备上更加易于访问。与使用单独的引导剂相比，训练方法，实现SOTA结果，同时提高效率40％。  完整摘要” Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1l0xo/r_unitok_unifying_visual_generation_and/</guid>
      <pubDate>Sun, 02 Mar 2025 07:00:04 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1hc0o/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Mar 2025 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[r]发布我的离散辅助仪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1ed93/r_releasing_my_discrete_vocoder/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我正在释放我的离散vocoder（24kh，每秒50帧，每秒50帧，4个密码簿）。 我试图将某些东西放在高biTrate的高位型和低比特拉特Mimi/WaveTrate Mimi/waveTocken中。型号和用法示例： https://huggingface.co/balecoon/vq4_50fps_24khz_vocoder  href =“ https://huggingface.co/spaces/balacoon/ttsleaderboard”&gt; https://huggingface.co/spaces/balacoon/balacoon/ttsleaderboard （pick`ovododer`作为系统）提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1ed93/r_releasing_my_discrete_vocoder/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1ed93/r_releasing_my_discrete_vocoder/</guid>
      <pubDate>Sun, 02 Mar 2025 00:39:54 GMT</pubDate>
    </item>
    <item>
      <title>[R]有效LLM的窗户注意力训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1ckye/r_sliding_window_attention_training_for_efficient/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     https：//arxiv.org/abs/2502.18845 Mamba，Titans和Transformers ++。在结论中跳跃：  ，通过用sigmoid替换软杀剂，将平衡的alebi替换为SWAT并将其结合在一起，SWAT解决了注意力下沉问题，并确保稳定的培训并确保稳定的培训。这么多的“曼巴发生了什么”帖子，我仍在等待基于泰坦的模型的发布，因此，尽管我不知道我们是否会使用特警，但我还是赞赏该论文作为对扩展 - 封闭式/替代架构世界中当前的调查。   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1ckye/r_sliding_window_attention_trainention_training_for_for_effficity/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1ckye/r_sliding_window_attention_training_for_efficient/</guid>
      <pubDate>Sat, 01 Mar 2025 23:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[d]插补方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j17zuj/d_imputation_methods/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我是一名医学生，目前正在接受ML实验，以根据不同的临床变量进行特定类型的手术后预测结果。我正在研究一个非常稀疏的数据集（其中一些特征丢失了约20-25％的数据），因此需要估算大量数据。我目前正在使用Scikit学习运行实验，但是多个插补功能不允许同时估算数值和分类变量，因此我使用了Missforest软件包。在使用“置换重要性”图和部分依赖性显示的置换率审查我的最终模型后，我意识到我的插补方法引入了很多偏见，有时会损害临床变量的实际正稳定值。我知道引入了这种偏见是因为先前使用同一数据集发表的论文，而不是使用Missforest算上，而是使用R。 中的MICE库，现在我不确定我应该做什么以减轻这种偏见。在上一篇使用小鼠的文章中，他们使用10个不同的估算数据集训练了单个回归模型，以评估其性能。在我的上下文中，我不确定我该怎么办，因为我使用10倍CV培训了几个ML模型，只有一个估算的数据集。我认为我可以使用小鼠生成一个估算的数据集，但是我觉得这违背了小鼠的全部目的，除非我错了，否则在这种情况下，我希望看到一些论文实施了小鼠以开发和验证不同ML模型。我还有其他方法可以减轻我的初始插补方法产生的偏差吗？ 谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j17zuj/d_imputation_methods/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j17zuj/d_imputation_methods/</guid>
      <pubDate>Sat, 01 Mar 2025 19:46:51 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>