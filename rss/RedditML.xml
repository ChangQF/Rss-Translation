<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Thu, 16 May 2024 15:14:11 GMT</lastBuildDate>
    <item>
      <title>[D] 在 Mac 上运行大型模型以进行原型/微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctegsx/d_running_large_models_on_mac_for/</link>
      <description><![CDATA[我正在考虑构建一个解决方案，以便轻松使用具有大 VRAM 的 Mac 计算机来运行 Pytorch 项目以进行开发/测试。我知道它们不能用于运行生产推理或大规模训练。然而，这些机器比 Nvidia GPU 实例 (A100/H100) 更容易获得、更便宜，并且具有大 VRAM，因此可以运行 Pytorch 实验。我看到了它们当前可用性方面的挑战。他们无法运行 Pytorch 容器环境（类似于在运行 Nvidia GPU 的 Linux 实例上运行 Pytorch 容器），并且他们没有类似于 RAY、Kubernetes 的管理工具，因此公司无法为其构建具有多台机器的开发/测试设备数据科学家团队。借助此解决方案，我设想公司可以使用 AWS 上的托管 Mac 或 Mac 实例（具有 32Gb 或更多 VRAM）供其数据科学家运行 Pytorch 实验。我的思考方式正确吗？   由   提交/u/Chachachaudhary123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctegsx/d_running_large_models_on_mac_for/</guid>
      <pubDate>Thu, 16 May 2024 14:38:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] L为什么线性 RNN 如此高效（在准确性方面，而不是计算方面）？寻找数学甚至直观的解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctea1i/d_lwhy_are_linear_rnns_so_performant_in_terms_of/</link>
      <description><![CDATA[尝试熟悉曼巴架构，从而熟悉 SSM，从而熟悉线性 RNN。我查看了有关 SSM、S4 和 Mamba 的资源，但找不到解释。为什么带有 SSM 参数化的线性 RNN 可以提高性能。我也无法直观地理解它 - 为什么线性变换足以完成 seq2seq 任务？ 有没有详尽的数学解释，甚至有关于线性 RNN 如何在某些任务上超越 Transformer 的视频？&lt; /p&gt;   由   提交/u/Ice-Cool701  /u/Ice-Cool701 reddit.com/r/MachineLearning/comments/1ctea1i/d_lwhy_are_linear_rnns_so_performant_in_terms_of/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctea1i/d_lwhy_are_linear_rnns_so_performant_in_terms_of/</guid>
      <pubDate>Thu, 16 May 2024 14:29:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 2024 年旅行补助金？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctdz9d/d_icml_2024_travel_grants/</link>
      <description><![CDATA[大家好， 有人收到有关 ICML 2024 经济援助的最新消息吗？我在 X 中看到申请即将开放，但还没有听到任何消息 https://twitter. com/icmlconf/status/1787617481034481714 过去是否有人获得过资助？所有学生都有资格参加吗？ 谢谢！   由   提交/u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctdz9d/d_icml_2024_travel_grants/</guid>
      <pubDate>Thu, 16 May 2024 14:16:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 揭晓 MileBench：在长上下文中对 MLLM 进行基准测试！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctayfy/d_unveiling_milebench_benchmarking_mllms_in_long/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctayfy/d_unveiling_milebench_benchmarking_mllms_in_long/</guid>
      <pubDate>Thu, 16 May 2024 11:45:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于业余爱好项目来说，最好的云计算服务是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctag4h/d_whats_the_best_cloud_compute_service_for_hobby/</link>
      <description><![CDATA[大家好！ 我是一名研究工程师，主要从事计算机视觉应用方面的工作。我想开始试验我不是专家的模型或任务作为业余项目，但我的个人笔记本电脑上没有 GPU，并且我想在以下位置执行一些中小型训练实验：至少。只是为了让您了解我想要训练的模型：  NeRF 和高斯 Splats 扩散模型 一些小型变压器模型（想想Llama-3 8b 及以下）。  考虑到我所考虑的项目规模，任何高于 A100 的项目都可能是过分的。 直到几周后以前我使用 colab pro，但我真的不喜欢这样的事实：我必须在我的谷歌驱动器上存储东西，我希望有一些东西我至少可以访问终端，而不仅仅限于 jupyter 笔记本. 您认为，对于此类项目来说，什么是好的、成本合理的云提供商？   由   提交/u/ats678  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctag4h/d_whats_the_best_cloud_compute_service_for_hobby/</guid>
      <pubDate>Thu, 16 May 2024 11:14:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 针叠中的针 (NIAN)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct9nth/p_needle_in_a_needlestack_nian/</link>
      <description><![CDATA[代码：https://github.com/llmonpy/needle-in-a-needlestack 网站：https://nian.llmonpy.ai/ 描述：  大海捞针(NIAH) 一直是一种广受欢迎的测试，用于评估法学硕士如何有效地关注其上下文窗口中的内容。随着法学硕士的进步，NIAH 变得太容易了。 Needle in a Needlestack (NIAN) 是一个新的、更具挑战性的基准。即使是 GPT-4-turbo 也很难达到这个基准。 NIAN 从大型打油诗数据库中创建打油诗列表，并询问有关已放置在测试位置的特定打油诗的问题。每个测试通常会使用 5 到 10 个测试打油诗，放置在提示中的 5 到 10 个位置。每个测试重复2-10次。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct9nth/p_needle_in_a_needlestack_nian/</guid>
      <pubDate>Thu, 16 May 2024 10:22:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在单个 A100 上预训练字节级 0.67B 变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct9bgc/r_pretraining_a_bytelevel_067b_transformer_on_a/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct9bgc/r_pretraining_a_bytelevel_067b_transformer_on_a/</guid>
      <pubDate>Thu, 16 May 2024 09:58:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 将人工智能集成到搜索引擎中：Yandex 如何更复杂地利用人工智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct8t1p/r_integrating_ai_into_search_engines_how_yandex/</link>
      <description><![CDATA[对 Yandex 搜索和广告技术业务部总监的简短采访，了解他们如何将人工智能构建到搜索引擎中并将其称为 Neuro . 文章还讨论了人工智能的潜力以及哪些全球趋势可能是其发展的关键。这是一本引人入胜的读物。  看看这里。   由   提交 /u/Beyond_ean   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct8t1p/r_integrating_ai_into_search_engines_how_yandex/</guid>
      <pubDate>Thu, 16 May 2024 09:19:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] Apriori算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct7kdn/d_apriori_algorithm/</link>
      <description><![CDATA[还有人在生产用例中使用 Apriori 吗？必须有更好的算法可用。    由   提交/u/Used_Basis_7448   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct7kdn/d_apriori_algorithm/</guid>
      <pubDate>Thu, 16 May 2024 07:45:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于自主无人机飞行的完全神经拟态视觉和控制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct590c/r_fully_neuromorphic_vision_and_control_for/</link>
      <description><![CDATA[Arxiv：https://arxiv.org/abs/2303.08778 （2023 年 3 月 15 日） https://www.science.org/doi/10.1126 /scirobotics.adi0591（2024 年 5 月 15 日） 他们还在几个小时前上传了一些视频： 补充视频 1 补充视频 2 补充视频 3 补充视频4 摘要：  生物传感和处理是异步且稀疏的，导致低延迟以及节能的感知和行动。在机器人技术中，用于基于事件的视觉和尖峰神经网络的神经形态硬件有望表现出类似的特征。然而，由于当前嵌入式神经形态处理器的网络大小有限以及训练尖峰神经网络的困难，机器人的实现仅限于具有低维感觉输入和运动动作的基本任务。在这里，我们提出了一个用于控制飞行无人机的完全神经形态视觉控制管道。具体来说，我们训练了一个尖峰神经网络，它接受基于事件的原始相机数据并输出低级控制动作，以执行基于视觉的自主飞行。该网络的视觉部分由五层和 28,800 个神经元组成，将传入的原始事件映射到自我运动估计，并通过真实事件数据的自我监督学习进行训练。控制部分由单个解码层组成，并通过无人机模拟器中的进化算法进行学习。机器人实验表明，完全学习的神经形态管道成功地从模拟到真实的迁移。无人机可以精确地控制其自我运动，允许悬停、着陆和侧向机动——甚至在偏航的同时也是如此。神经形态管道在英特尔 Loihi 神经形态处理器上运行，执行频率为 200 赫兹，闲置功耗为 0.94 瓦，运行网络时仅额外消耗 7 至 12 毫瓦。这些结果说明了神经形态传感和处理在实现昆虫大小的智能机器人方面的潜力。  他们还有其他一些很酷的论文： 通过迭代去模糊进行基于事件的轻量光流估计和视频&lt; /a&gt;   由   提交 /u/Sirisian   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct590c/r_fully_neuromorphic_vision_and_control_for/</guid>
      <pubDate>Thu, 16 May 2024 05:02:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文没有代码怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct45hk/d_whats_up_with_papers_without_code/</link>
      <description><![CDATA[最近做一个人脸反欺骗的项目，在研究过程中发现几乎没有论文提供实现代码。在可重复性如此重要的领域，为什么人们仍然接受没有实现的论文？   由   提交/u/mtmttuan  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct45hk/d_whats_up_with_papers_without_code/</guid>
      <pubDate>Thu, 16 May 2024 03:57:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] jaxsplat：JAX 的 3D 高斯泼溅</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct3knc/p_jaxsplat_3d_gaussian_splatting_for_jax/</link>
      <description><![CDATA[我创建了 jaxsplat，它为 JAX 提供 CUDA 加速的 3D 高斯泼溅。原始 INRIA 代码和 gsplat 的实现包含不适合与 JAX 一起使用的动态形状数组。相反，我修改了 gsplat 的 CUDA 实现以公开自定义 XLA CUDA 调用，同时不会将任何动态形状泄漏到 JAX 端代码中。 如果您有兴趣使用 JAX 探索 3D 高斯泼溅，请看一下：  p&gt; GitHub：https://github.com/yklcs/jaxsplat 文档：&lt; a href=&quot;https://jaxsplat.readthedocs.io&quot;&gt;https://jaxsplat.readthedocs.io   由   提交 /u/RocketLL   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct3knc/p_jaxsplat_3d_gaussian_splatting_for_jax/</guid>
      <pubDate>Thu, 16 May 2024 03:23:36 GMT</pubDate>
    </item>
    <item>
      <title>改进我的 VAE [项目] 的技巧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct06gs/tips_for_improving_my_vae_project/</link>
      <description><![CDATA[        由   提交/u/Tupaki14  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct06gs/tips_for_improving_my_vae_project/</guid>
      <pubDate>Thu, 16 May 2024 00:26:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] 新的 KANs 论文刚刚发布：用于时间序列分析的 Kolmogorov-Arnold Networks (KANs)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1csp40j/p_new_kans_paper_just_dropped_kolmogorovarnold/</link>
      <description><![CDATA[https://arxiv.org/pdf/2405.08790   由   提交/u/ghoof   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1csp40j/p_new_kans_paper_just_dropped_kolmogorovarnold/</guid>
      <pubDate>Wed, 15 May 2024 16:31:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>