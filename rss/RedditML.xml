<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 26 Dec 2023 21:11:23 GMT</lastBuildDate>
    <item>
      <title>[P]、[R] 如何修复模型中的极端 softmax 值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rg8m2/p_r_how_can_i_fix_extreme_softmax_values_in_my/</link>
      <description><![CDATA[大家好，我目前正在做一个使用可视化问答模型的项目。简而言之，它的工作方式是：它将图像和问题作为输入，并使用文本生成器提供答案作为输出。我正在尝试使用 softmax 来获得模型输出的置信度。  问题在于模型对其决策过于自信，给了我 0 或 1 的输出。我尝试过修改 softmax 方程上的温度值，但没有成功真的很有帮助，我猜我得到的值非常小，它们立即变成 0，而一个大值变成 1。 我目前的解决方法是在 softmax 之前对 logits 进行归一化，这解决了极值问题，我得到正常值，例如（0.21，0.57，0.21）但这似乎设定了一个“范围”当涉及到由于缩放而产生的输出值时。这意味着我所有的“自信”值在设定的0.60-0.65范围内，这使得区分和推断信息变得非常困难。例如：我向模型询问图像中的一些内容，模型将以0.6218的概率输出结果然后当我问它一些“更简单”的东西时期望得到更高的数字，由于标准化，我将得到 0.6225 的概率。请记住，这些数字是指示性的。 如果有人有任何经验/解决方法/想法，或者如果我做错了什么，请随时告诉我。 感谢任何帮助，圣诞快乐！    由   提交 /u/Spitefulsalamander   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rg8m2/p_r_how_can_i_fix_extreme_softmax_values_in_my/</guid>
      <pubDate>Tue, 26 Dec 2023 19:37:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在时间序列中查找模式的算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rft8z/d_algorithm_to_find_patterns_in_temporal_sequences/</link>
      <description><![CDATA[我有一个大型数据库，其中按时间顺序存在不同类型的错误。示例：A、C、F、C、G、D、A、G、.....、F、G、D、A... F、S、G、D、H、A... 哪些算法可以我用来寻找重复模式？ （示例中：发现当F、G和D发生时，A随后发生）。谢谢ssss:)   由   提交/u/BusinessBaby9338   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rft8z/d_algorithm_to_find_patterns_in_temporal_sequences/</guid>
      <pubDate>Tue, 26 Dec 2023 19:19:18 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 健康保险项目投入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rfars/project_input_in_health_insurance_project/</link>
      <description><![CDATA[大家好，  我最近从学术界转向工业界，并获得了我的第一个职位：健康保险数据科学家。我正在开展我的第一个重大项目，非常感谢更有经验的人群提供的一些见解。  他们希望我分析患者的轨迹，我们几乎拥有您能想到的所有可用数据。每次医生就诊、每次开药处方等。主要目标是创建一个模型来预测这些轨迹 - 例如，确定诊断后患者的下一步步骤，最重要的是，识别可能导致重大但尚未发生的个体。很快就能预防的医疗费用。  我对时间序列没有太多经验，但我最初的想法是从一个病症/患者组开始，使用 ARIMA/LSTM 网络进行时间序列分析来预测轨迹并将这些预测整合起来例如，作为随机森林等模型的特征，用于不同阶段的风险评估。  你们中有人从事过类似的项目吗？我对处理时间序列数据的任何建议或对模型集成的见解特别感兴趣。您可以分享的任何常见陷阱或最佳实践都会有所帮助。  预先感谢您的见解！    由   提交 /u/NoUseForAName0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rfars/project_input_in_health_insurance_project/</guid>
      <pubDate>Tue, 26 Dec 2023 18:57:21 GMT</pubDate>
    </item>
    <item>
      <title>[P]频域信道状态信息特征提取用于人类活动识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rdu04/p_feature_extraction_for_channel_state/</link>
      <description><![CDATA[我目前正在开发一个项目，重点是使用通道状态信息 (CSI) 进行人体跌倒检测。作为其中的一部分，我正在探索各种特征提取方法。但是，我不确定从频域提取的最佳特征。 在其原始格式中，时域中的数据被构造为二维数组。每行对应一个毫秒，每列代表一个子载波。每个位置的值表示信号的幅度。 我使用 FFT 将数据转换到频域。对于从频域数据中提取哪些特征的任何见解或建议，我将不胜感激。   由   提交/u/Snoo386  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rdu04/p_feature_extraction_for_channel_state/</guid>
      <pubDate>Tue, 26 Dec 2023 17:54:25 GMT</pubDate>
    </item>
    <item>
      <title>[D]controlnet中的两个零卷积层是做什么的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rdkx0/d_what_do_the_two_zero_convolution_layers_in/</link>
      <description><![CDATA[在论文“Adding Conditional Control to Text-to-Image Diffusion Models”中(2302.05543) 他们添加了 2 个零卷积层。论文强调，在第一次前向传播中，输出是相同的（因为该层全部为零），并且在第一次反向传播之后，该层不再全部为零 - 这没关系，只是数学。 但它没有解释为什么要添加？或者它有什么作用？他们为什么用零来初始化它（当所有其他论文使用不同的方法来初始化权重时）如果这两个 Z 层被遗漏，会发生什么？没有它们我们就不能训练controlnet吗？ 你有解释吗？或者更多信息的链接？   由   提交/u/FineInstruction1397   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rdkx0/d_what_do_the_two_zero_convolution_layers_in/</guid>
      <pubDate>Tue, 26 Dec 2023 17:43:43 GMT</pubDate>
    </item>
    <item>
      <title>[R]、[P] 用于人工智能研究的自托管 GPU 设置</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rb7lo/r_p_selfhosted_gpu_setup_for_ai_research/</link>
      <description><![CDATA[我的 3070 越来越阻碍我进行研发，而且我越来越多地使用云，不仅仅是为了运行工作，而且是为了活跃研究。我觉得我只是在云上烧钱，而且这是不可持续的。我需要投入一些美元和时间来构建高质量（尽管仍然较小）的服务器来进行我的研究。 我一直在努力为此寻找良好的详细资源/社区。大多数人似乎对云感到满意，或者他们的大学/公司为他们处理这些东西。我预计仅仅通过谷歌搜索来决定我的设置，我会错过一些重要的内部知识。 我希望有人可以提供一些提示，或者更好地向我指出一个对此方面非常热情的社区人工智能开发者？我住在奥斯汀，如果那里有任何面对面的社区，那就更好了！ 我一直在思考初始设置的想法 - 可能只需 2 或 3 4080 即可启动 - 我听说过 NVLink，但不&#39;对于连接不好的人来说，不要认为这会是一个选择 - 机箱（或机架？）和主板可以处理更多（可能 4-10 个 GPU 容量） - 确保其他规格（冷却、CPU、PSU、等）是合适的并且不会成为 GPU 的瓶颈 - 打开案例吗？结案了？？ idk-需要能够从奥斯汀的任何地方进行ssh连接，理想情况下美国任何地方的连接都不会有太糟糕的延迟-我的设置意图是你应该从一个极其新/精益/差的设备中获得期望但雄心勃勃且非常聪明/战略性的初创公司，人们回头看时会说“哇，这是一个经过充分研究和聪明的设置”哈哈 任何建议，任何联系，都表示赞赏。非常感谢！ &lt;3 :-)   由   提交 /u/margaritasAndBowling   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rb7lo/r_p_selfhosted_gpu_setup_for_ai_research/</guid>
      <pubDate>Tue, 26 Dec 2023 15:59:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们通常使用哪种 Transformer 实现？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r8yhf/d_which_transformer_implementation_do_people/</link>
      <description><![CDATA[每个标题，我想知道人们通常使用的 Transformer 是否有特定的实现？我不关心预先训练的模型。我想要一个最小/干净的实现，我可以用它来修改 Transformer 架构本身，以实现我的一些想法。我注意到 PyTorch 有自己的内置 Transformer，但不确定它们是否有任何好处，而且它们看起来可能有点过度设计以满足我的需求。我还注意到 Andrej Karpathy 有他的 nanoGPT 项目，该项目可能符合要求（仅解码器的自回归实现就可以满足我的要求。）   由   提交/u/SuperFX  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r8yhf/d_which_transformer_implementation_do_people/</guid>
      <pubDate>Tue, 26 Dec 2023 14:12:49 GMT</pubDate>
    </item>
    <item>
      <title>寻求增强我的 PyPI 包 eagelview - 图像数据集可视化的建议 [D]，[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r8wan/seeking_suggestions_for_enhancing_my_pypi_package/</link>
      <description><![CDATA[大家好，[D]、[P] ​ 我已经一直在开发一个名为 eagelview 的 PyPI 包，旨在通过打印文件夹中的图像并添加 .csv 文件中的标签来可视化图像数据集，从而促进图像数据集可视化。 ​ 我渴望扩展它的功能并使其更加通用。如果您认为将有价值的想法、建议或功能包含在 eagelview 中，我们将不胜感激！ ​ 期待听到您的想法。提前致谢！ ​ [查看 GitHub 上的 eagleview](https: //github.com/hexronuspi/eagleview) ​   由   提交 /u/hexronus   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r8wan/seeking_suggestions_for_enhancing_my_pypi_package/</guid>
      <pubDate>Tue, 26 Dec 2023 14:09:41 GMT</pubDate>
    </item>
    <item>
      <title>[R]“自我预测通用人工智能”（Self-AIXI）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r88hb/r_selfpredictive_universal_ai_selfaixi/</link>
      <description><![CDATA[论文：https： //openreview.net/forum?id=psXVkKO9No 摘要：  强化学习（RL）算法通常利用学习和/或制定有效政策的规划技术。事实证明，两种方法的集成在解决复杂的顺序决策挑战方面非常成功，AlphaZero 和 MuZero 等算法就证明了这一点，这些算法将规划过程整合到参数搜索策略中。 AIXI 是理论上最有效的通用智能体，它通过综合搜索进行规划作为寻找最优策略的主要手段。在这里，我们定义了一个替代的通用代理，我们称之为Self-AIXI，与A​​IXI相反，它最大限度地利用学习来获得良好的策略。它通过自我预测自己的动作数据流来实现这一点，与其他 TD(0) 代理类似，该数据流是通过对当前在策略（通用混合策略）Q 值估计采取动作最大化步骤来生成的。我们证明了Self-AIXI收敛于AIXI，并继承了最大Legg-Hutter智能和自优化特性等一系列特性。   &amp; #32；由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r88hb/r_selfpredictive_universal_ai_selfaixi/</guid>
      <pubDate>Tue, 26 Dec 2023 13:33:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] 微代理：能够自我编辑提示和 Python 代码的模块化代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r6wqx/p_microagents_modular_agents_capable_of/</link>
      <description><![CDATA[项目：https:// github.com/aymenfurter/microagents 描述：  这个实验探索了自动生成和改进自身的自我进化代理。用户不需要特定的代理设计或提示。只需提出一个问题，系统就会启动并发展专门定制的代理来提供答案。该过程从用户查询开始，激活基本的“引导程序”。代理，它不执行Python代码，而是计划并委托给能够运行Python以实现更广泛功能的专门代理。代理经理负责监督它们，通过特定任务的向量相似性来选择或创建代理。代理具有不断发展的系统提示，可以通过学习进行改进。对于编码任务，代理在提示中包含 Python，通过“进化步骤”改进他们的方法。如果不成功。完成任务后，代理的状态会更新，引导代理会评估结果，让其他代理参与更大流程中的进一步步骤。   &amp;# 32；由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r6wqx/p_microagents_modular_agents_capable_of/</guid>
      <pubDate>Tue, 26 Dec 2023 12:15:41 GMT</pubDate>
    </item>
    <item>
      <title>如果你的 GPU 很差，你能做什么研究？[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r2nbu/what_kind_of_research_can_you_do_if_you_are_gpu/</link>
      <description><![CDATA[所以在我的大学里我没有太多的计算资源。我可以在 ML 中做什么类型的工作？   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r2nbu/what_kind_of_research_can_you_do_if_you_are_gpu/</guid>
      <pubDate>Tue, 26 Dec 2023 07:23:26 GMT</pubDate>
    </item>
    <item>
      <title>[N] Coqui TTS 本地安装教程 - 秒内免费克隆声音！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r2js7/n_coqui_tts_local_installation_tutorial_clone/</link>
      <description><![CDATA[嘿， 人工智能最近变得很疯狂，事情变化得非常快。我创建了一个视频，介绍了 Coqui 的 TTS with UI 的安装过程，这是一个公开的文本转语音 AI 模型，我认为它可能对你们中的一些人有用。安装过程非常简单，可以概括为几个命令，之后您将拥有一个功能齐全的 TTS 服务器，您可以用它在几秒钟内克隆语音！查看完整教程： https://youtu.be/ykfPIO1wTh8 这里真正酷的部分是，在需要几分钟的初始设置之后，您将能够从数百种声音中选择您想要的任何模型，然后为其提供文本并获得疯狂的快速结果。结果返回的速度通常比人工智能读取它的速度要快，而且所有结果都在本地运行&amp;免费的。顺便说一句，它也可以在 CPU 上运行！ 请告诉我您的想法，或者如果您对其他视频有任何疑问/请求， 干杯   由   提交/u/dev-spot  /u/dev-spot  reddit.com/r/MachineLearning/comments/18r2js7/n_coqui_tts_local_installation_tutorial_clone/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r2js7/n_coqui_tts_local_installation_tutorial_clone/</guid>
      <pubDate>Tue, 26 Dec 2023 07:16:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你们使用哪种软件来说明研究框架/想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qzdnj/d_which_software_do_you_guys_use_for_illustrating/</link>
      <description><![CDATA[我们经常在研究论文中看到图表/图形来说明整个工作流程。我很好奇大家都在用什么。就我个人而言，我使用 draw.io，它通常不是“漂亮”的。 - 那么也许有更好的选择？   由   提交/u/KarmaCut132   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qzdnj/d_which_software_do_you_guys_use_for_illustrating/</guid>
      <pubDate>Tue, 26 Dec 2023 04:12:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大规模运行 Whisper 的最具成本效益的方式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qrerx/d_most_cost_efficient_way_to_run_whisper_at_scale/</link>
      <description><![CDATA[我正在尝试确定要运行哪个 Whisper 版本以及如何运行它，以最大限度地降低大规模运行时的成本。我说的是每天转录大约 1000 小时的音频。我认为也许中等模型会提供足够的准确性。  我应该使用其中一个 CPU 版本并在云运行等平台上并行化多个文件吗？是不是使用更强大的 GPU 虚拟机并连续执行更多操作？ 速度并不那么重要，如果转录每个文件需要更长的时间也没关系。只要我能跟上传入文件的节奏就可以转录。  感谢您的任何想法和建议！   由   提交/u/ojojoj1233  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qrerx/d_most_cost_efficient_way_to_run_whisper_at_scale/</guid>
      <pubDate>Mon, 25 Dec 2023 21:21:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>