<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Mon, 29 Apr 2024 01:00:21 GMT</lastBuildDate>
    <item>
      <title>[D] ICML 2024结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfm9ep/d_icml_2024_results/</link>
      <description><![CDATA[大家好， ICML 决定即将公布！ 我正在创建一个帖子对于有兴趣分享的每个人：  关于结果/评审过程的想法 已接受论文中有趣的统计数据和趋势 有关当前研究趋势的讨论&lt; /li&gt; 集思广益，讨论将在会议上展示的新颖作品（您最喜欢哪一个？:)） （对于那些参加的人）在维也纳举行的 ICML 休闲聚会！  祝大家好运！   由   提交/u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfm9ep/d_icml_2024_results/</guid>
      <pubDate>Mon, 29 Apr 2024 00:57:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 随机 MuZero 机会结果训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfle63/d_stochastic_muzero_chance_outcome_training/</link>
      <description><![CDATA[我最近偶然发现了随机 MuZero 论文。我了解网络的推论和MCTS规划。然而，我不明白机会结果的训练。有人可以解释一下吗？在 MCTS 中，西格玛变量表示该状态下机会结果的分布。这个分布是针对什么进行训练的？他们在论文中提到它是针对某些编码器进行训练的？网络中是否有额外的编码器用于此目的，或者它们如何知道实际发生了哪种机会结果？   由   提交 /u/_Hardric   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfle63/d_stochastic_muzero_chance_outcome_training/</guid>
      <pubDate>Mon, 29 Apr 2024 00:14:32 GMT</pubDate>
    </item>
    <item>
      <title>要赢得 ML 黑客马拉松，除了 ML 之外，你还需要一切 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cficmp/you_need_everything_other_than_ml_to_win_a_ml/</link>
      <description><![CDATA[基本上是对我的大型跨国公司和机构主办的线下黑客马拉松条件的咆哮。  厌倦了参加旨在“开发尖端解决方案”的黑客马拉松，最终输给了一个从未学过机器学习但精通“商业信息学”的人并且在给定的时间内提出解决方案非常好。  一个头脑清醒的人，在创意、原型和模型上不停地工作 2-3 天，怎么可能只谈论 3-5 分钟呢？我确实看到人们克隆了与问题陈述有些相关的 github 存储库，并将其像某种最先进的产品一样出售。我同意这种技能在工业中更重要，但为什么将这些黑客马拉松命名为“机器学习”呢？或“AI”黑客马拉松？最好将其命名为“卖给我一些垃圾”。 对于那些真正想在有限的时间内开发好产品、工作模型以及喜欢竞争的人（像我一样）的人来说，唯一的选择就是在线参与或在“数据”中竞赛。    由   提交 /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cficmp/you_need_everything_other_than_ml_to_win_a_ml/</guid>
      <pubDate>Sun, 28 Apr 2024 21:56:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 RETRO 不是法学硕士中的主流/最先进的技术？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cffgkt/d_why_isnt_retro_mainstream_stateoftheart_within/</link>
      <description><![CDATA[2021 年，Deepmind 发布了通过检索数万亿个数据来改进语言模型令牌并引入了检索增强型变压器（RETRO）。 RAG 通常涉及通过将相关文档注入上下文来在推理时补充输入标记，而 RETRO 可以在训练和推理期间从外部数据库访问相关嵌入。目标是将推理和知识解耦：通过允许按需查找，模型可以不必记住其权重内的所有事实，而是将能量重新分配给更有影响力的计算。结果非常惊人：RETRO 实现了与 GPT-3 相当的性能，参数减少了 25 倍，并且理论上没有知识截止（只需向检索数据库添加新信息！）。 然而：今天，AFAICT ，大多数主要型号都不包含 RETRO。 LLaMA 和 Mistral 当然不会，而且我也不觉得 GPT 或 Claude 会这样做（唯一可能的例外是 Gemini，因为 RETRO 团队的大部分成员现在都是 Gemini 团队的一部分，而且它根据我的经验，更快、更实时）。此外，尽管 RAG 一直很热门，并且有人可能认为教育部能够实现它，但作为一种研究向量，明确地解耦推理和知识一直相对安静。 有人对为什么会这样有一个自信的解释吗？我觉得 RETRO 的这一伟大而高效的前沿进步就在眼前，等待着广泛采用，但也许我错过了一些明显的东西。   由   提交/u/whitetwentyset  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cffgkt/d_why_isnt_retro_mainstream_stateoftheart_within/</guid>
      <pubDate>Sun, 28 Apr 2024 19:58:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我创建了一个云提供商，提供经济实惠且轻松的 GPU 访问</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfek96/p_i_created_a_cloud_provider_for_affordable_easy/</link>
      <description><![CDATA[您好r/MachineLearning！ 我很高兴推出 Backprop GPU 云 - 在公共市场上托管 GPU 服务器三年后，我决定构建自己的云提供更好的服务。 我关注的是速度、价格和可靠性： - 实例是在 60 秒内创建的，并预装了 Jupyter。 - 定价合理，没有存储或带宽方面的隐藏费用。 - RTX 3090 实例托管在具有 10 Gbps 网络的三级数据中心。 如果您是学生或研究人员，我很乐意为您提供 10 小时的免费积分。只需注册并向我发送消息即可。 我希望添加更多功能和其他实例类型。所有反馈都会有很大帮助！   由   提交 /u/ojasaar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfek96/p_i_created_a_cloud_provider_for_affordable_easy/</guid>
      <pubDate>Sun, 28 Apr 2024 19:21:09 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 直观地深入了解 Uber 用于预测预计到达时间的机器学习解决方案。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfd15u/research_a_visual_deep_dive_into_ubers_machine/</link>
      <description><![CDATA[      TL;DR：Uber 遵循 2 层方法。他们将 Dijkstra 等传统图算法与学习嵌入和轻量级自注意力神经网络相结合，以可靠地预测预计到达时间或预计到达时间。 Uber 如何使用机器学习来预测预计到达时间（并解决十亿美元的问题）&lt; /p&gt; https://preview.redd。 it/2ovttr82i9xc1.png?width=1358&amp;format=png&amp;auto=webp&amp;s=51b12261bf98f529fd0e9b33daf6362b727f4580   由   提交/u/ml_a_day  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfd15u/research_a_visual_deep_dive_into_ubers_machine/</guid>
      <pubDate>Sun, 28 Apr 2024 18:18:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] VMRNN：集成 Vision Mamba 和 LSTM 实现高效、准确的时空预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfcxfp/r_vmrnn_integrating_vision_mamba_and_lstm_for/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.16536 代码：https:/ /github.com/yyyujintang/VMRNN-PyTorch 摘要：  将 CNN 或 ViT 与 RNN 结合起来进行时空预测，在预测时间和空间动态方面取得了无与伦比的成果。然而，对广泛的全球信息进行建模仍然是一项艰巨的挑战。 CNN 因其狭窄的接受域而受到限制，而 ViT 则难以满足其注意力机制的密集计算需求。最近基于 Mamba 的架构的出现因其卓越的长序列建模能力而受到热烈欢迎，其在效率和准确性方面超越了现有的视觉模型，这激励我们开发适合时空预测的创新架构。在本文中，我们提出了VMRNN 单元，这是一种新的循环单元，它集成了 Vision Mamba 模块与 LSTM 的优点。我们构建了一个以VMRNN单元为中心的网络来有效地处理时空预测任务。我们的广泛评估表明，我们提出的方法可以确保在各种任务上获得有竞争力的结果，同时保持较小的模型大小。我们的代码可在 此 https URL 获取。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfcxfp/r_vmrnn_integrating_vision_mamba_and_lstm_for/</guid>
      <pubDate>Sun, 28 Apr 2024 18:14:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 分类深度学习：架构的代数理论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfck8b/r_categorical_deep_learning_an_algebraic_theory/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.15332 项目页面：https://categoricaldeeplearning.com / 摘要：  我们提出了我们的立场，即寻找一个难以捉摸的通用框架来指定和研究深度学习学习架构。我们的观点是，迄今为止所做的关键尝试在指定模型必须满足的约束和指定其实现之间缺乏连贯的桥梁。着眼于建立这样一座桥梁，我们建议应用范畴论——准确地说，是在参数映射的 2 类别中评估的通用单子代数——作为单一理论优雅地包含了神经网络设计的这两种风格。为了捍卫我们的立场，我们展示了该理论如何恢复几何深度学习引起的约束，以及从不同的神经网络（例如 RNN）中提取的许多架构的实现。我们还说明了该理论如何自然地编码计算机科学和自动机理论中的许多标准结构。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfck8b/r_categorical_deep_learning_an_algebraic_theory/</guid>
      <pubDate>Sun, 28 Apr 2024 17:59:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 MLops/ML 基础设施的 ML 白皮书</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf9d3s/d_ml_white_papers_on_mlopsml_infra/</link>
      <description><![CDATA[我正在寻找来自顶级科技公司的有关机器学习基础设施/mlops/机器学习工程的白皮书 您知道吗或者可以给我指出一些吗？ 我指的不是像注意力就是你所需要的那样的东西。寻找更多面向工程的论文   由   提交/u/choose_cake  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf9d3s/d_ml_white_papers_on_mlopsml_infra/</guid>
      <pubDate>Sun, 28 Apr 2024 15:43:18 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态补丁嵌入 - 一种新的 ViT 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf8d26/r_multimodal_patch_embeddings_a_new_vit_model/</link>
      <description><![CDATA[这个研究项目是对这个想法的探索 - 如果您可以将文本嵌入与 ViT 的每个补丁嵌入进行比较会怎样？.我尝试了一些事情并得到了一些有希望的结果。  这里有两个关键思想： 1. 将图像嵌入作为超球面上点的凸和，其中每个点都是一个补丁嵌入。这需要对 ViT 架构进行更改，此处对此进行了解释。 2. 限制每个补丁仅关注其邻居。 通过这种架构，我使用蒸馏来学习一个小型（约 21M 参数）模型，使其具有与预训练的 Vit-B/32 相同的图像嵌入在大约 310 万张图像上建立模型（约 8700 万参数）。这导致补丁嵌入是局部感知的，但必须学会以某种方式组合，以便提供全局图像嵌入。 代码和检查点是可用的，并且包含用于复制的训练、推理和笔记本。结果：https://github.com/TinyVolt/multimodal-patch-embeddings   由   提交/u/nivter  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf8d26/r_multimodal_patch_embeddings_a_new_vit_model/</guid>
      <pubDate>Sun, 28 Apr 2024 14:59:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何诊断训练损失中的这些峰值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf4gw9/d_how_would_you_diagnose_these_spikes_in_the/</link>
      <description><![CDATA[        提交人    /u/NumberGenerator   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf4gw9/d_how_would_you_diagnose_these_spikes_in_the/</guid>
      <pubDate>Sun, 28 Apr 2024 11:44:29 GMT</pubDate>
    </item>
    <item>
      <title>“变形金刚可以使用无意义的填充标记（例如，‘......’）来代替一连串的思想” - Let's Think Dot by Dot [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf2u0d/transformers_can_use_meaningless_filler_tokens_eg/</link>
      <description><![CDATA[https://arxiv.org/abs/2404.15758 从摘要开始 我们表明，变压器可以使用无意义的填充标记（例如“......”）来代替一系列思想来解决两个问题在没有中间令牌的情况下进行响应时，他们无法解决困难的算法任务。然而，我们根据经验发现，学习使用填充令牌很困难，需要特定的、密集的监督才能收敛   由   提交 /u/Agitated_Space_672   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf2u0d/transformers_can_use_meaningless_filler_tokens_eg/</guid>
      <pubDate>Sun, 28 Apr 2024 09:59:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将您的 LLM（应用程序/系统）转移到生产环境中最常见和最重大的挑战是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf178i/d_what_are_the_most_common_and_significant/</link>
      <description><![CDATA[目前有很多人使用法学硕士进行构建，但没有那么多人从原型和 POC 过渡到生产。尤其是在企业环境中，但我相信这对于产品公司甚至一些专注于基于 LLM 的应用程序的初创公司来说也是类似的。事实上，一些调查和研究认为这一比例低至5%。  从事这一领域工作的人们，在尝试将产品投入生产时遇到的最常见和最困难的挑战是什么？目前您是如何解决这些挑战的？    由   提交/u/gamerx88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf178i/d_what_are_the_most_common_and_significant/</guid>
      <pubDate>Sun, 28 Apr 2024 08:07:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 RAG 的真实讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cekoc7/d_real_talk_about_rag/</link>
      <description><![CDATA[老实说吧。我知道我们都必须与这些经理/董事/CXO 打交道，他们提出了与公司数据和文档交谈的惊人想法。 但是……有人真正做了一些真正有用的事情吗？如果是这样，它的有用性是如何衡量的？ 我有一种感觉，我们被一些非常复杂的废话所愚弄，因为法学硕士总是可以产生在某种程度上听起来合理的东西。但它有用吗？   由   提交/u/fusetron  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cekoc7/d_real_talk_about_rag/</guid>
      <pubDate>Sat, 27 Apr 2024 18:00:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>