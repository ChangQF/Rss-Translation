<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 11 Mar 2024 12:24:13 GMT</lastBuildDate>
    <item>
      <title>[R] [2403.05468] GPT-4 会运行《DOOM》吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</link>
      <description><![CDATA[ 由   提交/u/blabboy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</guid>
      <pubDate>Mon, 11 Mar 2024 12:20:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] ShortGPT：大型语言模型中的层比您预期的更加冗余</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.03853 摘要：  随着大型语言模型（LLM）的性能不断进步，它们的规模显着扩大，当前的法学硕士包含数十亿甚至数万亿的参数。然而，在这项研究中，我们发现LLM的许多层表现出高度相似性，并且某些层在网络功能中发挥的作用可以忽略不计。基于这一观察，我们定义了一个名为区块影响力 (BI) 的指标来衡量法学硕士中每一层的重要性。然后，我们提出了一种直接的修剪方法：层删除，其中我们根据 LLM 的 BI 分数直接删除其中的冗余层。实验表明，我们的方法（我们称之为 ShortGPT）在模型剪枝方面显着优于之前最先进的 (SOTA) 方法。此外，ShortGPT 与类量化方法正交，可以进一步减少参数和计算量。与更复杂的修剪技术相比，通过简单的层删除可以获得更好的结果，这表明模型架构中存在高度冗余。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</guid>
      <pubDate>Mon, 11 Mar 2024 11:41:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] MathScale：数学推理的缩放指令调整</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc0zpo/r_mathscale_scaling_instruction_tuning_for/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.02884 摘要：  大型语言模型（LLM）在解决问题方面表现出了卓越的能力 -解决。然而，他们解决数学问题的能力仍然不足。我们提出了 MathScale，这是一种使用前沿 LLM（例如 GPT-3.5）创建高质量数学推理数据的简单且可扩展的方法。受人类数学学习认知机制的启发，它首先从种子数学问题中提取主题和知识点，然后构建概念图，随后用于生成新的数学问题。 MathScale 沿着我们生成的数学数据集的大小轴展示了有效的可扩展性。因此，我们创建了一个包含 200 万数学问答对的数学推理数据集 (MathScaleQA)。为了全面评价法学硕士的数学推理能力，我们构建了数学应用题基准MwpBench，它是涵盖K-12、大学和竞赛级别的十个数据集（包括GSM8K和MATH）的集合数学问题。我们应用 MathScaleQA 来微调开源 LLM（例如 LLaMA-2 和 Mistral），从而显着提高数学推理能力。在 MwpBench 上进行评估，MathScale-7B 在所有数据集上均实现了最先进的性能，其微观平均准确度和宏观平均准确度分别超过同等大小的最佳同行 42.9% 和 43.7% .    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc0zpo/r_mathscale_scaling_instruction_tuning_for/</guid>
      <pubDate>Mon, 11 Mar 2024 11:30:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 立场文件：人工智能代理迈向整体智能 - Microsoft 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbz4z8/r_position_paper_agent_ai_towards_a_holistic/</link>
      <description><![CDATA[      论文：https:/ /arxiv.org/abs/2403.00833  摘要：  大型基础模型的最新进展显着增强了我们对开放世界环境中感官信息的理解。在利用基础模型的力量时，人工智能研究必须摆脱过度还原论，转而强调作为有凝聚力的整体的系统。具体来说，我们强调开发人工智能代理——一种将大型基础模型集成到代理操作中的体现系统。代理人工智能的新兴领域涵盖了广泛的现有体现和基于代理的多模式交互，包括机器人、游戏和医疗保健系统等。在本文中，我们提出了一种新颖的大型动作模型实现体现智能行为，代理基础模型。除此之外，我们还讨论了智能体如何在各种领域和任务中展现出卓越的能力，挑战我们对学习和认知的理解。此外，我们从跨学科的角度讨论智能体人工智能的潜力，强调科学话语中的人工智能认知和意识。我们相信这些讨论可以作为未来研究方向的基础，并鼓励更广泛的社会参与。   https:// /preview.redd.it/h8m0ucns7onc1.jpg?width=1228&amp;format=pjpg&amp;auto=webp&amp;s=1cfc94db64f9f358b07353de285faefa5c8ca1a0 https ://preview.redd.it/rjo7pdns7onc1.jpg?width=927&amp;format=pjpg&amp;auto=webp&amp;s=a0728939d5a83c32811c2efbdff9b5a6d58f023f https://preview.redd.it/ng16dfns7onc1.jpg?width=487&amp;format=pjpg&amp;auto=webp ＆amp; ;s=72c6e46c75328cc39e606f149550c0fbf99115a3   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbz4z8/r_position_paper_agent_ai_towards_a_holistic/</guid>
      <pubDate>Mon, 11 Mar 2024 09:26:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于成本优化的无服务器 Mistral 推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbz4m7/d_serverless_mistral_inference_for_cost/</link>
      <description><![CDATA[我目前是一家初创公司的一员，我正在探索优化 LLM api 使用成本的方法。  我们的服务不需要实时 LLM 交互。相反，我们每 1 小时堆叠 1000 多个类似预测的任务，并在每小时的前 10 分钟内进行处理。考虑到这种使用模式，延迟和保持 GPU 活跃并不是我们主要关心的问题，这让我相信开源 LLM 对我们来说可能是一种经济高效的解决方案。  但是，我对云GPU服务和自己服务LLM的知识相当有限，所以我有一些疑问。   假设使用开源 LLM 可以降低与我的特定用例使用 LLM API 相关的成本是否准确？ 自动缩放和自动缩放之间有什么区别？无服务器？具体来说，是否可以仅使用单个 GPU 实例进行自动缩放，在大部分时间维护较小的 CPU 实例并仅在必要时分配 GPU？如果可以的话，这种方式是否能有效降低成本？ 如何使用vllm库进行批量推理？它会自动优化单次生成的并发请求吗？ vllm 是否与无服务器计算框架兼容？简单地将通过 Dockerfile 制作的基于 VLLM 的 Docker 镜像部署到像 RunPod 这样的无服务器 GPU 服务上就足够了吗？是否需要具体注意事项或步骤？    由   提交/u/JYPark314  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbz4m7/d_serverless_mistral_inference_for_cost/</guid>
      <pubDate>Mon, 11 Mar 2024 09:25:22 GMT</pubDate>
    </item>
    <item>
      <title>[d] 合成数据生成方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbyfib/d_synthetic_data_generation_methods/</link>
      <description><![CDATA[       我编写了自定义代码，为自己生成合成数据以用于微调LLM， 它提供了“系统、用户、助手”格式的jsonl文件。 openai 微调器接受哪个。  https://preview.redd.it/lw5lkr442onc1.png?width=1273&amp;format=png&amp;auto=webp&amp;s=72661016111ad9e65eb4b019f10890e9ba02efad 但我想知道是否还有其他有效的方法去做吧？你们为法学硕士生成综合数据的方法有哪些，是否遇到任何问题？   由   提交/u/Medium_Alternative50   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbyfib/d_synthetic_data_generation_methods/</guid>
      <pubDate>Mon, 11 Mar 2024 08:35:00 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 6700xt 上的 Bark 文本转语音？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbybnw/discussion_bark_text_to_speech_on_6700xt/</link>
      <description><![CDATA[在 6700xt 上进行文字转语音？ 我想购买 12 GB vram GPU，但我的预算很低 您认为 aMD 与树皮文本和语音不兼容吗？   由   提交 /u/Visible-Employment43    reddit.com/r/MachineLearning/comments/1bbybnw/discussion_bark_text_to_speech_on_6700xt/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbybnw/discussion_bark_text_to_speech_on_6700xt/</guid>
      <pubDate>Mon, 11 Mar 2024 08:27:27 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] [D] NER 中手动标记的替代方案？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbxpsi/discussion_d_any_alternatives_to_manual_labelling/</link>
      <description><![CDATA[问题 -  有 NER 的替代方案吗？ （正则表达式不起作用，因为句子和单词/短语边界没有明确定义）任何无监督/半监督/自监督方法？ 对于标记，是否有手动标记的替代方法？  详细信息： 我有一个关于人物传记的自由文本列，其中包含不同的标识符，例如姓名、身份证号。 、电话号码、电子邮件、出生日期、国籍等。我需要将它们提取到正确的标签下（例如 NAM 代表名称，ID 代表 ID 号等）。每个实体标签可以有多种变体（例如，名称可以出现在“名称：”或“别名：”或“又名：”或“也称为”之后。此外，实体的存在（及其传记中的变体（有些传记只包含姓名、电子邮件和电话号码以及身份证号，很少包含国籍和出生日期）。我正在尝试应用 NER。但是，预训练的 NER 模型不包含我需要的实体，所以我需要用标记数据来训练模型。对于标记，我手动标记了大约 1K 传记 - 相当于 300,000 个标记。如果这些传记的性能不够，将来可能会有更多传记要标记。 .问题是标记是一项超级密集的任务。 我手动标记了 470 个传记，并尝试训练 crf、spacy 的 ner 解决方案和 bert 令牌分类器。对于那些计数的实体，性能较低&lt;1K。我尝试仅选择那些包含要提取的实体的传记进行标记。我尝试过使用CRF模型进行伪标记，但效果不佳。我将无法推送有关 spacy 神童的数据（违反公司政策）   由   提交/u/Ann2_123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbxpsi/discussion_d_any_alternatives_to_manual_labelling/</guid>
      <pubDate>Mon, 11 Mar 2024 07:43:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您对 numenta/nupic 有何看法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbxahe/d_what_do_you_think_about_numentanupic/</link>
      <description><![CDATA[https://youtu.be/rYxnWzooxiY?si =JPlvrILNq9_rbRqG   由   提交 /u/CodingButStillAlive   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbxahe/d_what_do_you_think_about_numentanupic/</guid>
      <pubDate>Mon, 11 Mar 2024 07:11:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在 MERN Stack 项目中集成线性回归：使用 Node.js 还是 Python？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbw5uw/p_integrating_linear_regression_in_a_mern_stack/</link>
      <description><![CDATA[我目前正在开发一个使用 MERN 堆栈（MongoDB、Express、React 和 Node.js）开发的餐厅管理面板，并且我已经遇到了一个十字路口。我的下一步涉及实施线性回归，以根据历史数据预测未来的客户流量和销售趋势。目标是直接通过管理面板向餐厅经理提供可行的见解。 鉴于我的堆栈的其余部分是基于 JavaScript 的，我最初倾向于将所有内容保留在 Node.js 生态系统中。为此，我研究了一些 JS 库，例如 simple-statistics 和 mljs。虽然我设法建立并运行基本的线性回归模型，但我开始质疑这是否是最好的方法，特别是在性能、可扩展性和高级分析功能的可用性方面。 另一方面另一方面，Python 是数据分析和机器学习的强大工具，拥有 NumPy、pandas 和 scikit-learn 等库，这些库针对线性回归等任务进行了优化且功能丰富。将 Python 集成到我的主要 JavaScript 堆栈中可能会提供更好的性能和更广泛的功能集，但代价是在管理跨语言集成方面引入复杂性。 这是我寻求您建议的地方：  p&gt;  可行性和最佳实践：对于那些已将 Python 的特定功能集成到 Node.js 或 JavaScript 后端的人，您是如何管理集成的，以及您面临的最大挑战是什么？ 性能注意事项：JavaScript/Node.js 线性回归方法能否有效扩展，或者 Python 在该领域的优势是否太显着而不容忽视? 库建议：如果建议留在 JS 生态系统内，那么除了 simple-statistics 和 mljs 之外，我还应该考虑实现哪些库线性回归？ 一般建议：您是否建议为此目的将 Python 引入堆栈，或者潜在的集成挑战对于它可能带来的好处来说是否太大？  我感谢您可以分享的任何见解、经验或资源。做出明智的决定不仅有助于实现此功能，还有助于规划项目的未来开发和可扩展性。 提前致谢！ &lt;!-- SC_ON - -&gt;  由   提交/u/Ok_Ratio_2368   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbw5uw/p_integrating_linear_regression_in_a_mern_stack/</guid>
      <pubDate>Mon, 11 Mar 2024 05:54:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对比学习的梯度累积（InfoNCE）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbuacq/d_gradient_accumulation_for_contrastive_learning/</link>
      <description><![CDATA[我正在训练多模态对齐模型，但即使使用混合精度训练，我的 GPU 也只能容纳 64 的批量大小。根据 SimCLR 论文，较小的批量大小对于学习来说并不是最佳选择。有什么办法可以在这里实现梯度累积吗？   由   提交/u/Mad_Scientist2027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbuacq/d_gradient_accumulation_for_contrastive_learning/</guid>
      <pubDate>Mon, 11 Mar 2024 04:03:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 尝试使用 JEPA 理解推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbnb5q/d_trying_to_understand_inference_with_jepa/</link>
      <description><![CDATA[灵感来自 Lex Fridmans 播客剧集 与 Yann LeCun 一起，我试图通过阅读 I-JEPA 论文来提高我对 JEPA 和基于能量的模型的理解以及这些讲义。  我从学习高度语义特征的角度理解JEPA的吸引力/半监督过程中连续图像数据的表示。但真正让我困惑的是 Yann LeCun 的说法，一旦像这样的模型经过训练，你就可以进行基于优化的推理，基本上优化 Y 以最小化能量。  这个生成过程已经被证明了吗？除了预训练的 JEPA 模型之外，为了在这个基于优化的过程中生成图像/文本响应，还需要哪些组件？   由   提交/u/flxh13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbnb5q/d_trying_to_understand_inference_with_jepa/</guid>
      <pubDate>Sun, 10 Mar 2024 22:37:56 GMT</pubDate>
    </item>
    <item>
      <title>拥有非参数估计背景是否是进入机器学习的有用途径？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbk0i6/is_having_a_background_in_nonparametric/</link>
      <description><![CDATA[我是统计学硕士生。我的背景几乎全部基于基础统计理论，我的论文是非参数估计（特别是非参数回归）。基本上，我的“机器学习”知识源于一些经典的非参数估计书籍，例如（Tysbakov、Wasserman、Tibshirani/Hastie 和 Friedman）。统计学习的要素几乎是我在机器学习方面的背景，因为我的论文是关于非参数回归的经典方法之间的交集，例如基于树的方法、核平滑器和样条曲线，用于估计因果推理中的平均治疗效果。 但是，我有时会觉得自己的机器学习背景“相当老”。比如说，我不知道非参数回归背景对于现代机器学习工作有多有吸引力。一般来说，我们深入研究了非参数和统计学中的许多渐近理论，而且我知道对于大多数机器学习工作来说，没有人真正关心渐近保证。  有谁知道我的知识是否真的与当今主要关注神经网络的时代的机器学习工作相关？   由   提交/u/Direct-Touch469   reddit.com/r/MachineLearning/comments/1bbk0i6/is_having_a_background_in_nonparametric/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbk0i6/is_having_a_background_in_nonparametric/</guid>
      <pubDate>Sun, 10 Mar 2024 20:22:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] OpenAI：JSON 模式与函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbgky4/r_openai_json_mode_vs_functions/</link>
      <description><![CDATA[       由   提交/u/JClub  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbgky4/r_openai_json_mode_vs_functions/</guid>
      <pubDate>Sun, 10 Mar 2024 18:01:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>