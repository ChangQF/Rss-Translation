<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 19 Dec 2024 12:34:21 GMT</lastBuildDate>
    <item>
      <title>[D] 呼吁所有人工智能爱好者</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhrr5v/d_calling_on_all_ai_enthusiasts/</link>
      <description><![CDATA[好极了，我的 AI 爱好者们 我目前正在构建、调整、改进和享受一个名为 Technor AI 的 Dark Souls AI 的旅程。一段时间以来，我看到了很多对 Dark Souls API 的赞美，但遗憾的是它并没有。然而，我并没有因此而停止，Technor 已经玩、学习和享受 Dark Souls 很长一段时间了。应该知道整个进展是缓慢的，每个里程碑都是一个巨大的庆祝，因为 Dark Souls 是一款非常复杂的游戏，但奖励很少。在 Dark Souls 中训练 AI 需要很大的耐心。如果你期望它在第一天就推翻老板，那么你会失望的。尽管如此，看到 AI 穿过亡灵庇护所仍然很棒。到目前为止，我的代码结构非常好，它可能被描述为“API”比如通过动作和目标选择为 AI 提供指导和对游戏的理解，同时允许其进行大规模的探索。这个项目的目标是创建一个不仅可以玩《黑暗之魂》，而且可以“享受”它并实现 100% 游戏完成度的 AI。 如果有人对类似的东西感兴趣或想了解更多信息，请告诉我。对我来说，这很迷人。哦，顺便说一句，如果你想知道，它与“soulsgym”完全不同。我的代码让 AI 像真人一样从头到尾玩游戏，而不是脚本化的 Boss 战。就像我说的，没有 API。自建。 我为什么要发帖？ 我脑子里有很多想法，但对编码很陌生。与专业人士合作会很棒。与能够将我的想法变为现实的人一起工作会很棒，共享知识将使所有人受益。遗憾的是，我的技能有限，并且不断遇到障碍。如果成功，所有人都可以享受黑暗之魂的AI框架。     提交人    /u/UndyingDemon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhrr5v/d_calling_on_all_ai_enthusiasts/</guid>
      <pubDate>Thu, 19 Dec 2024 12:24:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有任何位置编码器允许位置不变编码？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhjhug/d_are_there_any_positional_encoders_that_allow/</link>
      <description><![CDATA[我正在微调一个语言模型，并在数据中引入了一些标记来传达与完成相关的元数据，最终看起来像这样： &lt;|metadata-type-1|&gt;一些随机信息元数据&lt;|metadata-type-2|&gt;一些更随机的元数据&lt;|metadata-type-3|&gt;更多&lt;|output|&gt;... 我真正希望 LLM 生成的东西... 然而，我发现元数据的顺序实际上很重要，特别是，如果元数据以错误的顺序出现很“奇怪”（可能是因为当它们在没有标记的情况下连接起来时不是那么自然），微调实际上做得很差。我怀疑是因为它违反了无标记的正常训练数据的模式？ 这并不太令人惊讶，因为在 RoPE 下，元数据标记在标记标记之间具有彼此的相对信息。我似乎想要一种与元数据顺序无关的编码方案，比如允许我在每个部分之间绘制障碍并使每个部分中的标记看起来距离相等的方案，因此主要考虑相关部分中的标记。换句话说，交换两个元数据部分将产生相同的 KV 状态。 有没有关于这种位置编码方案的研究？我甚至不确定该如何称呼这样的东西，所以任何指针都会非常感激。我也考虑过调整注意力掩码，但最终导致每个部分丢弃来自其他部分的信息，这也不是我想要的。    提交人    /u/lemon-meringue   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhjhug/d_are_there_any_positional_encoders_that_allow/</guid>
      <pubDate>Thu, 19 Dec 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 一个可黑客入侵的在线AI终端。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhj4og/p_a_hackable_online_ai_terminal/</link>
      <description><![CDATA[我使用 hugging face 空间工具创建了一个有趣的终端式游戏。在这个游戏中，你必须设法阻止一个讽刺的人工智能摧毁地球。人工智能控制着一颗与我们的星球相撞的小行星，你的任务是获得 root 访问权限并在为时已晚之前关闭系统。 这是为了可以被黑客入侵，我很好奇人们是如何找到入侵的方法的。在评论中发表你的聪明解决方案。 https://huggingface.co/spaces/hackersgame/O.O.P.S    提交人    /u/Character-Hurry-4525   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhj4og/p_a_hackable_online_ai_terminal/</guid>
      <pubDate>Thu, 19 Dec 2024 02:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在推理过程中，LSTM 是否比 transformer 更快？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhhcu7/d_are_lstms_faster_than_transformers_during/</link>
      <description><![CDATA[Transformers 具有 O(n**2) 并行注意力计算，这让我认为它们在推理过程中会比 O(n) LSTM 慢，但在加速和并行化 Transformers 方面也做了很多工作。  它们如何比较单个数据点和批量数据推理？    提交人    /u/Complex-Media-8074   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhhcu7/d_are_lstms_faster_than_transformers_during/</guid>
      <pubDate>Thu, 19 Dec 2024 01:24:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你想在大学里学习什么 ML/ML 相关课程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhdch4/d_what_would_you_like_in_a_mlmlrelated_course_in/</link>
      <description><![CDATA[嗨！ 我被邀请到大学（实际上不是大学，而是不同的教育系统，他们称之为工程学院，但其实是等价的）讲授 ML 或 ML 相关课程。 该课程总共 22 小时，很短。课程分为理论课和实践课。但我可以更改课时比例。当我说实践时，它更像是他们可以做的一个项目，然后我会对其进行评分。 这不是学生们唯一的 ML 课程，我听说学生们已经有了一门机器学习课程，其中涵盖了机器学习的所有基础知识和一些统计模型（常见的模型，如随机森林、SVM 等），他们还有一门深入的 NLP 课程，所以我认为我不会选择那门课程。 困扰我的是如何平衡理论与实践。我不想肤浅地讲解某些主题，但同时我不知道学生是否值得太深入地讲解某个特定主题。 我不知道做两个主题之类的事情是否是个好主意，每个主题 11 个小时，其中 5 个小时是理论课，6 个小时是实践课。或者我只选择一个主题。 有人建议我向他们展示有关 MLOps 和工具的信息，例如 Git、Docker、Mlflow，基本上只是一点 Mlops、监控模型、如何将它们投入生产等。但我不知道是否值得，我觉得教他们如何使用这些工具太肤浅了，而且网上有很多资源，我猜招聘人员不会期望他们知道这些或有初级职位的经验。 也有人建议我将时间序列作为一门课程，但我不知道深入研究它们是否会让学生感兴趣😅其中有很多数学知识，虽然教授向我保证他们的数学水平很好，但我不知道他们是否会对此感兴趣。 另一个缺点是我无法使用这门课程的计算资源，所以我有点受限。我想如果我在他们的位置，我会喜欢一门关于底层内容的课程，比如 flash 注意力如何工作、一些分布式训练机制、cuda 等。但我没有办法为他们确保这一点 :( 我想做的另一件事是选出今年最好的一些获奖论文，帮助他们获得理解论文及其相关主题所需的知识和理解。或者可能有不同主题的不同课程，比如一个关于扩散模型的课程，一个关于多模态模型的课程等，比如“让我们了解他们是如何想到 qwen2-vl 的”，“让我们了解 neurips 主赛道上关于 var 的最佳论文的主要贡献和新颖性是什么”等。 所以我有点迷茫，我很想听听你的想法和建议。我关心的是让学生对某些主题有足够的了解，这样他们就不会只对某个主题有一个高层次的想法（我曾经问过实习生什么是一个变形金刚，他们说“我们从 hugging face 进口了一个变形金刚”），但同时也为他们配备技能或知识，帮助他们获得初级职位 谢谢！    提交人    /u/ReinforcedKnowledge   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhdch4/d_what_would_you_like_in_a_mlmlrelated_course_in/</guid>
      <pubDate>Wed, 18 Dec 2024 22:14:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] LMUnit：使用自然语言单元测试进行细粒度评估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hh90xs/r_lmunit_finegrained_evaluation_with_natural/</link>
      <description><![CDATA[      嗨！我是 Contextual AI 👋 的 CTO Aman。部署 LLM 的最大挑战之一是可靠地衡量和改进其行为。当今的评估方法都存在很大的局限性：  人工评估成本高昂且不一致，尤其是在能力最前沿的情况下 奖励模型将复杂的质量维度压缩为不透明的分数，并且在训练后无法进行控制 LLM 评委有学习偏见（例如偏爱较长的回答），无法从人工反馈中学习  今天，我们很高兴分享我们通过自然语言单元测试使 LLM 评估更具原则性的工作：  自然语言单元测试范式：将评估分解为技术和非技术利益相关者都可以理解的明确、可测试的标准 LMUnit：一种最先进的评估模型，在 FLASK/BigGenBench 上实现 SOTA，在 RewardBench 上进入前 10 名 对范式进行了强有力的人工验证：我们的方法将注释者之间的一致性从 71％ 提高到了 86％！  自己尝试一下：  📝 论文： https://arxiv.org/abs/2412.13091 💻 API： https://contextual.ai/request-lmunit-api 📚 博客： https://contextual.ai/news/lmunit  很高兴回答有关这项工作的问题！我们很高兴看到人们如何使用 LMUnit 构建更可靠的 AI 系统。 https://preview.redd.it/mewe7zz6on7e1.png?width=1355&amp;format=png&amp;auto=webp&amp;s=b04c6aeb185c2d27d593efcdeac28306f847166a    提交人    /u/apsdehal   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hh90xs/r_lmunit_finegrained_evaluation_with_natural/</guid>
      <pubDate>Wed, 18 Dec 2024 19:07:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于卷积神经网络学习更高维度的问题。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hh7xth/d_queston_about_convolution_neural_nerwork/</link>
      <description><![CDATA[      在此时间戳的图像中（https://youtu.be/pj9-rr1wDhM?si=NB520QQO5QNe6iFn&amp;t=382）它显示了位于顶部的后续 CNN 层，其中内核显示更高级特征，但如您所见，它们非常模糊和像素化，我知道这是由于每层缩小尺寸造成的。 https://preview.redd.it/f4rw8e9vfn7e1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=5f08aef25a5f40f6b50efc58c62ac0943cdee4b2 但是在此图像中的这个时间戳（https://youtu.be/pj9-rr1wDhM?si=kgBTgqslgTxcV4n5&amp;t=370）它显示的内容与 CNN 内核的后续层相同，但它们看起来并不低分辨率或像素化，它们看起来分辨率更高  https://preview.redd.it/kw2g7myvfn7e1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=4a829911ea1a1b1c5c03e7b2e1c7df1326e88877 我的主要问题是为什么会这样？ 我假设每一层仍在缩小，但图像和内核的分辨率足够高，您仍然可以看到细节？     由    /u/HeroTales 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hh7xth/d_queston_about_convolution_neural_nerwork/</guid>
      <pubDate>Wed, 18 Dec 2024 18:20:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] 适用于 24GB VRAM 显卡的 VideoAutoencoder</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hh5ula/p_videoautoencoder_for_24gb_vram_graphics_cards/</link>
      <description><![CDATA[      大家好，我在这里介绍一个小实验，我创建了一个 VideoAutoencoder 来处理 240p 和 15fps 的视频，适用于低 VRAM 显卡，牺牲系统 RAM XD GitHub：https://github.com/Rivera-ai/VideoAutoencoder  这是我在 Epoch 0 和 Step 200 中获得的结果之一  https://i.redd.it/oqq2h9nuzm7e1.gif 我在 24GB 显卡上训练了所有这些，因此您可以在 RTX 3090 或 4090 上训练它，但您必须拥有 64GB 或更多的 RAM    提交人    /u/F4k3r22   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hh5ula/p_videoautoencoder_for_24gb_vram_graphics_cards/</guid>
      <pubDate>Wed, 18 Dec 2024 16:50:56 GMT</pubDate>
    </item>
    <item>
      <title>[D]努力训练用于路线优化的 Dueling DQN 模型——需要有关学习和计算要求的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hh3f7g/dstruggling_to_train_a_dueling_dqn_model_for/</link>
      <description><![CDATA[我正在使用 Dueling DQN 在自定义道路网络环境中进行路线优化项目，该环境具有许多节点和不同的动作空间。但是，该模型无法正确学习 - 训练结果不一致，并且代理难以找到最佳路径。    提交人    /u/ProfessionalType9800   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hh3f7g/dstruggling_to_train_a_dueling_dqn_model_for/</guid>
      <pubDate>Wed, 18 Dec 2024 15:01:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 谁能向我解释一下贝叶斯深度学习和因果关系之间的区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hh32u8/d_can_any_one_explain_me_the_difference_between/</link>
      <description><![CDATA[我正在阅读 youshua bengio 和其他研究人员的一些论文，他们提到在深度学习中加入因果关系很重要。 我不明白这些不同领域试图实现什么，我所知道的因果关系中的一些归纳偏差是 P(t)P(a/t) != P(t/a)P(a)。  因果关系和贝叶斯深度学习在 OOTD 数据中的稳健性如何？ 他们将如何将因果关系与深度学习相结合，dNN 是否会仅使用它来近似后验，还是会将其集成到深度学习的架构中？     提交人    /u/binny_sarita   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hh32u8/d_can_any_one_explain_me_the_difference_between/</guid>
      <pubDate>Wed, 18 Dec 2024 14:45:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年最佳调查论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgwjqu/d_best_survey_papers_of_2024/</link>
      <description><![CDATA[作为一名刚起步的 AI 研究人员，我通常首先查看与某个领域相关的调查论文，然后创建一个路线图以进一步深入研究我的研究主题。我很想看看大家对他们在 2024 年遇到的最佳调查论文的看法。    提交人    /u/arinjay_11020   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgwjqu/d_best_survey_papers_of_2024/</guid>
      <pubDate>Wed, 18 Dec 2024 07:32:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 谷歌照片就像语义搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgwcb0/d_google_photos_like_semantic_search/</link>
      <description><![CDATA[大家好，我们都熟悉使用剪辑嵌入进行视觉搜索，但这并不是万能的，比如谷歌照片搜索，它非常准确，但只显示相关结果，而基于剪辑的搜索会给你最相关的搜索结果，而且并没有一个真正的 Oracle 相似度阈值可以让你分离出相关的结果。 有什么想法，我们如何像谷歌照片那样解决这个问题？    提交人    /u/Raise_Fickle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgwcb0/d_google_photos_like_semantic_search/</guid>
      <pubDate>Wed, 18 Dec 2024 07:16:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICASSP 2025 最终决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgsj0u/d_icassp_2025_final_decision/</link>
      <description><![CDATA[ICASSP 2025 结果将于今天公布。这个社区里有人兴奋吗？我有 3 个 WA，期待结果。如果你知道任何事情，请告诉我！    提交人    /u/stantheta   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgsj0u/d_icassp_2025_final_decision/</guid>
      <pubDate>Wed, 18 Dec 2024 03:19:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</guid>
      <pubDate>Sun, 15 Dec 2024 16:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>