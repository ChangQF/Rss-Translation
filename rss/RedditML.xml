<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 11 Mar 2024 18:16:26 GMT</lastBuildDate>
    <item>
      <title>[D] 需要特征工程连续数值特征的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc8pig/d_need_suggestions_for_feature_engineering/</link>
      <description><![CDATA[      数据集链接 - https:// www.kaggle.com/competitions/playground-series-s4e3 在最近的一次比赛中，我遇到了一个包含连续特征的数据集，为了深入了解它们的分布动态，我生成了两个分布图和箱线图。目标列是分类的，目标是确定与预测缺陷相关的概率，评估指标是 AUC ROC 分数。 采用最少的预处理，我使用爬山集成训练了一个模型，其中包含超参数调整的 XGBoost (XGB) 和 LightGBM 模型。我取得的成绩使我跻身排行榜前 1%。我正在寻求进一步预处理步骤的建议，以提高模型的准确性。   由   提交/u/tushar_mahalya   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc8pig/d_need_suggestions_for_feature_engineering/</guid>
      <pubDate>Mon, 11 Mar 2024 17:24:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 pymc 实现高斯过程。帮助！ [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc7zug/gaussian_process_implementation_using_pymc_help_p/</link>
      <description><![CDATA[大家好， 我正在使用 PyMC 库在 python 中进行贝叶斯建模，我正在尝试进行前馈非线性回归器，基本上预测给定的一组 Y 值的 X。它必须从正演模型获知，该模型是从正演模型获得的一组 X-Y 值。谁能帮我完成这个过程（代码）？ P.S.通过考虑线性插值生成预期 Y 值以最终预测贝叶斯方案内的 X，我成功地做出了预测。  pymc #bayesian #pythoncoding #python #regression #prediction #modeling   由   提交/u/BeingBest8459  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc7zug/gaussian_process_implementation_using_pymc_help_p/</guid>
      <pubDate>Mon, 11 Mar 2024 16:55:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 如何教 Resnet 聚焦图像中的特定区域？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc5po8/d_r_how_to_teach_resnets_to_focus_on_particular/</link>
      <description><![CDATA[我正在从事用于生物识别目的的人员识别任务。我的直觉是模型应该只关注人的边界，头部，也许还有手和脚。所以除了 RGB 图像之外，我还有边缘图图像。我还阅读了有关非局部神经网络（https://arxiv.org/abs/1711.07971）的内容，它可以提供类似注意力的效果resnet 的功能。 但是，我无法弄清楚如何训练它仅查看上述部分。  &amp;# 32；由   提交/u/doctor-squidward  /u/doctor-squidward  reddit.com/r/MachineLearning/comments/1bc5po8/d_r_how_to_teach_resnets_to_focus_on_pspecial/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc5po8/d_r_how_to_teach_resnets_to_focus_on_particular/</guid>
      <pubDate>Mon, 11 Mar 2024 15:22:24 GMT</pubDate>
    </item>
    <item>
      <title>[N] Haystack 2.0发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc53h0/n_haystack_20_launch/</link>
      <description><![CDATA[Haystack 2.0 稳定版已上线！亲自尝试一下：https://haystack.deepset.ai/blog/haystack-2-release/&lt; /a&gt; Haystack 是一个开源 AI 框架，用于使用 LLM 和其他语言模型创建可用于生产的应用程序。它已经有近 4 年历史了——在它流行之前我们就一直在做 NLP 和 LLM 工程。 😎 并且与模型和数据库无关 - 您可以使用对您的用例最有意义的任何工具。 Haystack 提供了一个丰富且不断发展的集成社区，提供监控、评估、数据摄取等。 有关 2.0 版本的背景： Haystack 于 2020 年首次正式发布，当时最前沿的NLP 的主要内容是语义搜索、检索和抽取式问答。 Haystack 2.0 是完全重写的，但将组件组合成灵活管道的基本原理保持不变。  该版本有相当多的模型提供者、跟踪和监控功能以及开箱即用的支持数据库： 对于模型（生成和嵌入）：OpenAI、Mistral、Cohere、Jina AI、 Google AI、Vertex AI、Optimum（通过拥抱脸）、句子转换器、Amazon Bedrock、Azure、Fast Embed、Ollama 对于数据库：Weaviate、Pinecone、Qdrant、Mongo DB、Astra DB、Neo4j、pgvector、Chroma、 Elastic Search、OpenSearch... 希望您尝试一下并让我们知道您的想法！我们有一个快速入门指南：https://haystack.deepset.ai/overview/quick-start   由   提交 /u/tuanacelik   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc53h0/n_haystack_20_launch/</guid>
      <pubDate>Mon, 11 Mar 2024 14:55:24 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 本地运行的文本到语音软件，CPU不好会让我失望吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc4f3u/discussion_text_tò_speech_software_running_local/</link>
      <description><![CDATA[快速提问，对于本地运行的文本到语音软件，糟糕的 CPU 会让我失望吗？ 我有 3060 rtx 64gb RAM 但是双核CPU  我启动模型后会遇到问题吗？ 瓶颈？    由   提交 /u/Visible-Employment43    reddit.com/r/MachineLearning/comments/1bc4f3u/discussion_text_tò_speech_software_running_local/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc4f3u/discussion_text_tò_speech_software_running_local/</guid>
      <pubDate>Mon, 11 Mar 2024 14:25:11 GMT</pubDate>
    </item>
    <item>
      <title>[D]我在 FPGA 上定制的 DNN 加速器是否需要反量化单元？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc45sy/ddoes_my_customized_dnn_accelerator_on_fpga_need/</link>
      <description><![CDATA[我正在 FPGA 上设计 DNN 加速器（8 位）。我想在加速器上运行多个 DNN 层，并将网络量化为 8 位。但我不知道是否应该设计一个去量化单元。我知道最好先对部分和进行反量化，然后再对其进行量化，并且许多商业 NPU 中都包含它。但对我来说设计它有点复杂。我对量化不是很熟悉。那么在加速器上执行多个层而不进行反量化可以吗？准确率会下降很多吗？ ​ 谢谢！   由   提交 /u/ExcitingInternet6083   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc45sy/ddoes_my_customized_dnn_accelerator_on_fpga_need/</guid>
      <pubDate>Mon, 11 Mar 2024 14:13:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] Gemini 1.5 Pro如何回忆10M上下文中的信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</link>
      <description><![CDATA[Google 最近发布了技术报告 关于 Gemini 1.5 Pro 及其 10M 上下文。他们简要概述了提高模型长上下文能力的现代方法（例如循环记忆、环形注意力、新颖的架构等），但我没有找到有关 Gemini 1.5 Pro 方法的信息。 有人注意到官方出版物中有关他们方法的信息吗？这对我来说似乎是 Google 的秘密。   由   提交/u/Mulated-Witness-7196   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</guid>
      <pubDate>Mon, 11 Mar 2024 12:26:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] [2403.05468] GPT-4 会运行《DOOM》吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</link>
      <description><![CDATA[ 由   提交/u/blabboy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</guid>
      <pubDate>Mon, 11 Mar 2024 12:20:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] ShortGPT：大型语言模型中的层比您预期的更加冗余</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.03853 摘要：  随着大型语言模型（LLM）的性能不断进步，它们的规模显着扩大，当前的法学硕士包含数十亿甚至数万亿的参数。然而，在这项研究中，我们发现LLM的许多层表现出高度相似性，并且某些层在网络功能中发挥的作用可以忽略不计。基于这一观察，我们定义了一个名为区块影响力 (BI) 的指标来衡量法学硕士中每一层的重要性。然后，我们提出了一种直接的修剪方法：层删除，其中我们根据 LLM 的 BI 分数直接删除其中的冗余层。实验表明，我们的方法（我们称之为 ShortGPT）在模型剪枝方面显着优于之前最先进的 (SOTA) 方法。此外，ShortGPT 与类量化方法正交，可以进一步减少参数和计算量。与更复杂的修剪技术相比，通过简单的层删除可以获得更好的结果，这表明模型架构中存在高度冗余。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</guid>
      <pubDate>Mon, 11 Mar 2024 11:41:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] MathScale：数学推理的缩放指令调整</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc0zpo/r_mathscale_scaling_instruction_tuning_for/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.02884 摘要：  大型语言模型（LLM）在解决问题方面表现出了卓越的能力 -解决。然而，他们解决数学问题的能力仍然不足。我们提出了 MathScale，这是一种使用前沿 LLM（例如 GPT-3.5）创建高质量数学推理数据的简单且可扩展的方法。受人类数学学习认知机制的启发，它首先从种子数学问题中提取主题和知识点，然后构建概念图，随后用于生成新的数学问题。 MathScale 沿着我们生成的数学数据集的大小轴展示了有效的可扩展性。因此，我们创建了一个包含 200 万数学问答对的数学推理数据集 (MathScaleQA)。为了全面评价法学硕士的数学推理能力，我们构建了数学应用题基准MwpBench，它是涵盖K-12、大学和竞赛级别的十个数据集（包括GSM8K和MATH）的集合数学问题。我们应用 MathScaleQA 来微调开源 LLM（例如 LLaMA-2 和 Mistral），从而显着提高数学推理能力。在 MwpBench 上进行评估，MathScale-7B 在所有数据集上均实现了最先进的性能，其微观平均准确度和宏观平均准确度分别超过同等大小的最佳同行 42.9% 和 43.7% .    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc0zpo/r_mathscale_scaling_instruction_tuning_for/</guid>
      <pubDate>Mon, 11 Mar 2024 11:30:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 立场文件：人工智能代理迈向整体智能 - Microsoft 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbz4z8/r_position_paper_agent_ai_towards_a_holistic/</link>
      <description><![CDATA[      论文：https:/ /arxiv.org/abs/2403.00833  摘要：  大型基础模型的最新进展显着增强了我们对开放世界环境中感官信息的理解。在利用基础模型的力量时，人工智能研究必须摆脱过度还原论，转而强调作为有凝聚力的整体的系统。具体来说，我们强调开发人工智能代理——一种将大型基础模型集成到代理操作中的体现系统。代理人工智能的新兴领域涵盖了广泛的现有体现和基于代理的多模式交互，包括机器人、游戏和医疗保健系统等。在本文中，我们提出了一种新颖的大型动作模型实现体现智能行为，代理基础模型。除此之外，我们还讨论了智能体如何在各种领域和任务中展现出卓越的能力，挑战我们对学习和认知的理解。此外，我们从跨学科的角度讨论智能体人工智能的潜力，强调科学话语中的人工智能认知和意识。我们相信这些讨论可以作为未来研究方向的基础，并鼓励更广泛的社会参与。   https:// /preview.redd.it/h8m0ucns7onc1.jpg?width=1228&amp;format=pjpg&amp;auto=webp&amp;s=1cfc94db64f9f358b07353de285faefa5c8ca1a0 https ://preview.redd.it/rjo7pdns7onc1.jpg?width=927&amp;format=pjpg&amp;auto=webp&amp;s=a0728939d5a83c32811c2efbdff9b5a6d58f023f https://preview.redd.it/ng16dfns7onc1.jpg?width=487&amp;format=pjpg&amp;auto=webp ＆amp; ;s=72c6e46c75328cc39e606f149550c0fbf99115a3   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbz4z8/r_position_paper_agent_ai_towards_a_holistic/</guid>
      <pubDate>Mon, 11 Mar 2024 09:26:07 GMT</pubDate>
    </item>
    <item>
      <title>[d] 合成数据生成方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbyfib/d_synthetic_data_generation_methods/</link>
      <description><![CDATA[       我编写了自定义代码，为自己生成合成数据以用于微调LLM， 它提供了“系统、用户、助手”格式的jsonl文件。 openai 微调器接受哪个。  https://preview.redd.it/lw5lkr442onc1.png?width=1273&amp;format=png&amp;auto=webp&amp;s=72661016111ad9e65eb4b019f10890e9ba02efad 但我想知道是否还有其他有效的方法去做吧？你们为法学硕士生成综合数据的方法有哪些，是否遇到任何问题？   由   提交/u/Medium_Alternative50   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbyfib/d_synthetic_data_generation_methods/</guid>
      <pubDate>Mon, 11 Mar 2024 08:35:00 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] [D] NER 中手动标记的替代方案？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbxpsi/discussion_d_any_alternatives_to_manual_labelling/</link>
      <description><![CDATA[问题 -  有 NER 的替代方案吗？ （正则表达式不起作用，因为句子和单词/短语边界没有明确定义）任何无监督/半监督/自监督方法？ 对于标记，是否有手动标记的替代方法？  详细信息： 我有一个关于人物传记的自由文本列，其中包含不同的标识符，例如姓名、身份证号。 、电话号码、电子邮件、出生日期、国籍等。我需要将它们提取到正确的标签下（例如 NAM 代表名称，ID 代表 ID 号等）。每个实体标签可以有多种变体（例如，名称可以出现在“名称：”或“别名：”或“又名：”或“也称为”之后。此外，实体的存在（及其传记中的变体（有些传记只包含姓名、电子邮件和电话号码以及身份证号，很少包含国籍和出生日期）。我正在尝试应用 NER。但是，预训练的 NER 模型不包含我需要的实体，所以我需要用标记数据来训练模型。对于标记，我手动标记了大约 1K 传记 - 相当于 300,000 个标记。如果这些传记的性能不够，将来可能会有更多传记要标记。 .问题是标记是一项超级密集的任务。 我手动标记了 470 个传记，并尝试训练 crf、spacy 的 ner 解决方案和 bert 令牌分类器。对于那些计数的实体，性能较低&lt;1K。我尝试仅选择那些包含要提取的实体的传记进行标记。我尝试过使用CRF模型进行伪标记，但效果不佳。我将无法推送有关 spacy 神童的数据（违反公司政策）   由   提交/u/Ann2_123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbxpsi/discussion_d_any_alternatives_to_manual_labelling/</guid>
      <pubDate>Mon, 11 Mar 2024 07:43:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对比学习的梯度累积（InfoNCE）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbuacq/d_gradient_accumulation_for_contrastive_learning/</link>
      <description><![CDATA[我正在训练多模态对齐模型，但即使使用混合精度训练，我的 GPU 也只能容纳 64 的批量大小。根据 SimCLR 论文，较小的批量大小对于学习来说并不是最佳选择。有什么办法可以在这里实现梯度累积吗？   由   提交/u/Mad_Scientist2027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbuacq/d_gradient_accumulation_for_contrastive_learning/</guid>
      <pubDate>Mon, 11 Mar 2024 04:03:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>