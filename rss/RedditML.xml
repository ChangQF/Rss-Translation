<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 17 Nov 2024 15:15:55 GMT</lastBuildDate>
    <item>
      <title>[D] 使用旧向量而不是新向量来定义词汇的小型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtenw8/d_small_language_models_defining_vocabulary_using/</link>
      <description><![CDATA[我一直在思考语言模型为何如此庞大，以及它们如何变得更小。我想每个人的大脑都不可能容纳人类的全部知识。我相信人类大致拥有一个类似于单词 X 其他单词的概率矩阵，但不是每个单词 X 每个单词。 我突然想到，我们经常使用我们知道的其他现有单词来定义不常用的单词（低频率、不常用的单词）。我们能否拥有一个语言模型，该模型仅使用频率最高的单词的向量，而“不常用的单词”没有自己的向量，而是引用现有向量？这可以大大减少单词 X 单词矩阵，因为常用单词由语言的一个小得多的子集组成。也许这样的模型可以在针对特定主题的文本进行重新训练时，动态地将参考词移入和移出主向量。 我知道我从来没有过原创的想法，有没有其他类似的项目？    提交人    /u/meteoraln   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtenw8/d_small_language_models_defining_vocabulary_using/</guid>
      <pubDate>Sun, 17 Nov 2024 14:26:01 GMT</pubDate>
    </item>
    <item>
      <title>用于语义搜索的 NLU 模型与自回归模型 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtdpwu/nlu_models_vs_autoregressive_models_for_semantic/</link>
      <description><![CDATA[在许多语义匹配困难的应用中，系统似乎被设计为使用自回归模型进行输入序列嵌入（然后执行一系列语义搜索技术）。  但从理论上讲，双向模型在这个任务上的表现难道不应该总是优于自回归模型吗？这表明最好使用优化的面向 NLU 的模型（如 DeBERTa-V3）（即对域数据进行微调）来获得更准确的嵌入，从而获得更好的语义搜索性能。 此外，关于统一语义搜索技术的报道有多少？我见过的所有实现都是高度领域特定/任意的。    提交人    /u/SnooPeripherals5313   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtdpwu/nlu_models_vs_autoregressive_models_for_semantic/</guid>
      <pubDate>Sun, 17 Nov 2024 13:37:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 卷积生成对抗网络噪声模式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtc2qv/d_convolutional_generative_adversarial_networks/</link>
      <description><![CDATA[我正在编写一个 DCGAN 来生成基于 BRATs 2020 数据集的脑 MRI 数据。作为一项健全性检查，我正在对具有恒定噪声的单个图像进行训练，以查看我的设计是否存在任何固有缺陷。GAN 似乎捕捉到了一般模式，但存在某种噪声或失真。您可以在下面的示例中看到，生成的图像不如原始图像清晰。 原始图像 lr 1e-4 1000 epochs  lr 2e-4 500 epochs 初始化后 我在所有图像上都看到了一些十字形图案，因此我相信我的网络本身存在问题，从而产生了这些图案。这是代码。 ``` class SimpleGenerator(nn.Module): def __init__(self,out_channels =1, noise_dimension = 100 , channels= 64 ): super(SimpleGenerator, self).__init__() self.noise_shape = (noise_dimension,1,1,1) self.out_channels = out_channels self.channels = channels self.gen = nn.Sequential( nn.ConvTranspose3d(self.noise_shape[0], self.channels * 32, 4, 1, (1, 0, 1)), nn.ReLU(), self._block( self.channels * 32, self.channels * 16, 5, 1, 0), self._block( self.channels * 16, self.channels * 8, 5, 1, 0), self._block( self.channels * 8, self.channels * 4, 4, 2, 1), self._block( self.channels * 4, self.channels * 2, 4, 2, 1), self._block( self.channels * 2, self.channels, 4, 2, 1), nn.ConvTranspose3d( self.channels, self.out_channels, 4, 2, 1), nn.Sigmoid() ) def _block(self,in_channels,out_channels,kernel_size,stride,padding): 返回 nn.Sequential( nn.ConvTranspose3d(in_channels,out_channels,3,1,1,bias=False), nn.InstanceNorm3d(out_channels), nn.ReLU(), nn.ConvTranspose3d(out_channels,out_channels,kernel_size,stride,padding,bias=False), nn.InstanceNorm3d(out_channels), nn.ReLU() ) def forward(self, x,separate=False): x = self.gen(x) return x  注意事项：  我使用 InstanceNorm 而不是 batch norm，因为我的图像是 160 x192x160，它们太大，所以 gpu 无法支持 batch_size &gt;1。 您在内核大小、步幅和填充中看到的奇怪数字是因为我想要实现上面描述的形状，它不是 2 的幂。可能是这个原因吗？ 我尝试了带有 1 或 2 个卷积的 _block 方法（我们看到 2 个版本）。结果相同 鉴别器是生成器的镜像。我不会提供代码来缩短帖子，但如果有人认为需要，我可以提供。     提交人    /u/ripototo   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtc2qv/d_convolutional_generative_adversarial_networks/</guid>
      <pubDate>Sun, 17 Nov 2024 12:00:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找一些音频分割模型。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtbkhw/d_looking_for_some_audio_segmentation_model/</link>
      <description><![CDATA[标题，也类似于 pyannote/segmentation -3.0 但更好。这个领域有什么新东西吗？我遇到了 mamba，但它仍处于早期阶段，因此无法对此发表任何具体评论。    提交人    /u/Just_Difficulty9836   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtbkhw/d_looking_for_some_audio_segmentation_model/</guid>
      <pubDate>Sun, 17 Nov 2024 11:26:24 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 记录梯度并使用第三方记录器调整超参数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtal7z/discussion_logging_gradients_and_using_third/</link>
      <description><![CDATA[大家好，我想知道您是如何学习使用 Wandb 和 MLFlow 等工具来记录梯度并调整模型中的超参数的。  您可以分享相同的资源吗？    提交人    /u/DiscussionTricky2904   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtal7z/discussion_logging_gradients_and_using_third/</guid>
      <pubDate>Sun, 17 Nov 2024 10:14:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用开源模型增强结构化输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gt2yfp/p_supercharging_structured_outputs_with_open/</link>
      <description><![CDATA[  由    /u/themathstudent  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gt2yfp/p_supercharging_structured_outputs_with_open/</guid>
      <pubDate>Sun, 17 Nov 2024 01:57:03 GMT</pubDate>
    </item>
    <item>
      <title>数据集版本控制工具 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gt1avg/dataset_versioning_tool_d/</link>
      <description><![CDATA[你们使用什么来进行数据（集）版本控制？你们建议在小型（1000 x 700）表格中使用什么？    提交人    /u/Amazing_Alarm6130   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gt1avg/dataset_versioning_tool_d/</guid>
      <pubDate>Sun, 17 Nov 2024 00:31:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 全息驱动的新颖视图合成 - 文献综述。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gszzqz/r_holography_driven_novel_view_synthesis/</link>
      <description><![CDATA[全息图是通过在 2D 胶片上编码 3D 场景创建的。一旦有了它，就可以删除 3D 场景及其所有对象。 现在，当您从胶片的另一侧观看时，您会看到 3D 对象，就好像它们仍然在那里一样。您可以改变视角等，看起来就像您正在通过该胶片观看 3D 场景，但该 3D 场景并不存在；而是，该场景的光场已被编码到胶片上。 Grant Sanderson 在他的 3B1B 频道 ( r/3Blue1Brown ) 上发布的这个视频是一个非常出色的说明性指南 https://www.youtube.com/watch?v=EmKQsSDlaa4 这告诉我们，3D 场景的 2D 表示确实是可能的。我在这里发帖是为了询问：  有没有论文使用全息图公式进行新颖视图合成和 3D 重建？ 如果像场景全息图这样的 2D 表示对于新颖视图合成非常好，为什么我们还需要 Nerfs 和 Gaussian Splats？     提交人    /u/nefrpitou   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gszzqz/r_holography_driven_novel_view_synthesis/</guid>
      <pubDate>Sat, 16 Nov 2024 23:28:02 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] R^2 为负，但预测值和实际值之间的相关性具有统计意义？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsxror/discussion_r2_is_negative_but_the_correlation/</link>
      <description><![CDATA[      我做了一些挖掘，但没有真正找到这个问题的答案，所以如果有人知道可能出什么问题，请告诉我。我进行了一些样本外预测（3000 个观测值），在评估预测需求水平的模型时，我得到了非常奇怪的结果。使用的模型是 xgb 回归量。因此 R^2 指出该模型的表现比简单地预测目标变量的平均值更差，但同时实际值和预测值之间的相关性具有统计意义。此外，解释方差得分表明该模型比朴素模型更差，但 Theil 的 U 统计量却相反？代码和结果发布如下。认为未完成的值可能是问题所在，但我将它们剪裁为 0.05 和 0.95 分位数，但没有帮助。 https://preview.redd.it/10kpzdqs1c1e1.png?width=966&amp;format=png&amp;auto=webp&amp;s=9b93f0ef588e2fa5cb16c06f69c0fea1902e0931 https://preview.redd.it/t2rapmo22c1e1.png?width=855&amp;format=png&amp;auto=webp&amp;s=ce9d8d1d2ad54c8743873560bfff8a275a14378d    提交人    /u/maciek024   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsxror/discussion_r2_is_negative_but_the_correlation/</guid>
      <pubDate>Sat, 16 Nov 2024 21:41:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你的机器学习博士学位学习时长</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsue6g/d_your_ml_phd_duration/</link>
      <description><![CDATA[获得学士学位后，您需要多少年才能完成 ML 博士学位？据我所知，世界不同地区通常需要不同的时间。     提交人    /u/AntelopeWilling2928   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsue6g/d_your_ml_phd_duration/</guid>
      <pubDate>Sat, 16 Nov 2024 19:04:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] COLING 2025 结果泄露</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gssewj/d_coling_2025_results_are_leaked/</link>
      <description><![CDATA[你们可以登录 softconf 检查是否可以提交照相排版论文。 我的成绩是 4/3/3，幸运地被接受了。我的第一篇论文！！！    提交人    /u/Ambitious-Public-512   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gssewj/d_coling_2025_results_are_leaked/</guid>
      <pubDate>Sat, 16 Nov 2024 17:35:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 必读的 ML 理论论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsqqns/r_mustread_ml_theory_papers/</link>
      <description><![CDATA[您好， 我是一名计算机科学博士生，希望加深对机器学习理论的理解。我的研究领域专注于视觉语言模型，但我想通过阅读基础或开创性的机器学习理论论文来扩展我的知识。 您能否分享一份对机器学习理论产生重大影响的必读论文或个人推荐？ 提前谢谢您！    提交人    /u/AntelopeWilling2928   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsqqns/r_mustread_ml_theory_papers/</guid>
      <pubDate>Sat, 16 Nov 2024 16:19:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 分析 UMAP 为何如此之快</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsjfq9/p_analysis_of_why_umap_is_so_fast/</link>
      <description><![CDATA[      嗨，我最近花了一些时间从 UMAP 算法的实现方式以及它为什么如此之快的角度来了解 UMAP 算法的核心实现（即使它是用 Python 编写的）。我决定将算法分解为更小的步骤，在这些步骤中，我对代码进行一些小的改进（一个接一个），这样最终的结果与我从 UMAP 获得的结果非常相似。 令我惊讶的是，这些变化中的大多数只是优化代码中的技巧，以更快地运行程序或减少更新不太重要的东西的频率。当然，我的实现并没有 100% 地重现 UMAP 算法，因为它是在教育目的中完成的。 我在我的项目中提供了详细的解释，说明我必须在每个步骤中添加什么才能转向类似 UMAP 的算法。这是项目页面：https://github.com/kmkolasinski/nano-umap 如果您是一个喜欢优化代码以提高性能的人，您可能会发现这很有趣。下面是我能够得到的演示：  https://preview.redd.it/eww57c3x881e1.png?width=1921&amp;format=png&amp;auto=webp&amp;s=ed4a345e40b47782ddf39cb93eb9d03207db1160 TLDR：在 UMAP 中他们：  使用 ANN 库快速找到顶级 k-NN， 使用良好的初始化方法，使事情更稳定并且算法需要更少的更新（UMAP 使用快速谱初始化）， 使用随机负采样，这是一种简单的方法，但在实践中效果很好， 压缩 numba 性能（通过用自定义实现替换 np.dot 或 np.clip 来使代码运行得更快）， 使用某种自适应采样，这将使算法将更多时间花在更重要的向量上，从而节省不太重要的向量上的 CPU 时间     提交人    /u/kmkolasinski   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsjfq9/p_analysis_of_why_umap_is_so_fast/</guid>
      <pubDate>Sat, 16 Nov 2024 09:02:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>