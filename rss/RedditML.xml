<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Tue, 06 Aug 2024 18:21:08 GMT</lastBuildDate>
    <item>
      <title>[讨论] 使用 100 个愚蠢的 LLaMA 搜索，在 Python 上击败 GPT-4o</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elo2d1/discussion_beat_gpt4o_at_python_by_searching_with/</link>
      <description><![CDATA[ 从这个惨痛的教训中，我们应该学到的一点就是通用方法的强大威力，这些方法即使可用的计算量变得非常大，也会随着计算量的增加而不断扩展。似乎以这种方式任意扩展的两种方法是搜索和学习。 Richard Sutton，惨痛的教训  Richard Sutton 的文章中令人不快的结论经常被误解：他们说，因为规模就是你所需要的一切，所以较小的模型注定会变得无关紧要。模型大小迅速增加到一万亿个参数以上，加上 GPU 内存的技术限制，似乎阻碍了任何地方的经济前沿智能，除了情报即服务提供商的寡头垄断。开放模型和自助推理正在撤退。 但正如上面的引文所示，扩展箭筒中实际上有两支箭：学习和搜索。学习，就像我们现在用神经网络所做的那样，在推理时随着内存而扩展——在其他条件相同的情况下，更大的模型表现更好，因为它们可以从训练集中提取更多数据到更多电路和更多模板中。搜索在推理时随着计算而平稳扩展——计算可以用于产生更高质量的候选者或产生更多的候选者。在理想情况下，可以通过所谓的缩放定律预测缩放行为。 最近的论文表明，像 LLM 这样的生成模型可以通过搜索进行扩展。上周，Brown、Juravsky 和合著者在 arXiv 上发表了一篇名为 Large Language Monkeys 的论文，其中包含了这方面的几个结果，并表明某些领域的前沿级智能可以从可在单个上一代 GPU 上运行的较小模型中引出。此外，他们观察到随着规模的扩大，性能会呈现平稳、可预测的提升。 更简单地说：以前，似乎前沿能力需要一只马大小的鸭子，而现在，很明显，我们可以用一百匹鸭子大小的马（或者更确切地说，LLaMA）来实现。 这个周末，我们着手复制这一发现。 在 Modal 上扩展 LLaMA 3.1 8B HumanEval 运行我们所有的实验（包括配置和测试），成本都远低于 50 美元。 您可以在此处找到我们的代码。您可以自行运行它，且不超过 Modal 免费套餐中包含的 30 美元/月信用额度。 指标和数据：HumanEval 和 pass@k 继续原帖...    提交人    /u/thundergolfer   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elo2d1/discussion_beat_gpt4o_at_python_by_searching_with/</guid>
      <pubDate>Tue, 06 Aug 2024 17:41:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 接地 SAM 2：接地并跟踪一切</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elmxnq/p_grounded_sam_2_ground_and_track_anything/</link>
      <description><![CDATA[      https://preview.redd.it/13854j03q2hd1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=0735848ae40c2591111fa4ed91d2c28ea829c0ac 随着 SAM 2 的发布，我们借此机会更新了我们的 Grounded SAM 算法。与 SAM 相比，SAM 2 最大的改进是将其分割功能扩展到视频，允许用户以交互方式分割视频中的任何对象并对其进行跟踪。然而，SAM 2 的主要问题是分割和跟踪的对象不包含语义信息。为了解决这个问题，我们延续了 Grounded SAM 的方法，加入了开放集检测模型，即 Grounding DINO。这使我们能够将 2D 开放集检测扩展到视频对象分割和跟踪。 我们已经在 https://github.com/IDEA-Research/Grounded-SAM-2 中发布了我们的代码，实现非常简单，方便用户使用。 项目亮点： 在此 repo 中，我们通过简单的实现支持以下演示：  使用 Grounding DINO、Grounding DINO 1.5 &amp; 1.6 和 SAM 2 对任何事物进行接地和分段 使用 Grounding DINO、Grounding DINO 1.5 &amp; 1.6 对任何事物进行接地和跟踪 1.6 和 SAM 2 基于强大的 https://github.com/roboflow/supervision 库检测、分割和跟踪可视化。  我们将继续更新代码，让用户更容易使用。    提交人    /u/Technical-Vast1314   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elmxnq/p_grounded_sam_2_ground_and_track_anything/</guid>
      <pubDate>Tue, 06 Aug 2024 16:55:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过异常声音检测识别水冷式 HVAC 系统的故障组件，并通过热视觉异常检测诊断随之而来的冷却故障。为了执行 AI 功能，该设备结合使用 Audio MFE 和 FOMO-AD 算法与 Web 应用程序。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elmnxp/p_identify_the_faulty_components_of_watercooled/</link>
      <description><![CDATA[        提交人    /u/the-amplituhedron   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elmnxp/p_identify_the_faulty_components_of_watercooled/</guid>
      <pubDate>Tue, 06 Aug 2024 16:44:57 GMT</pubDate>
    </item>
    <item>
      <title>“[D]” 针对高度不平衡的图像数据进行每类增强。这是好主意还是坏主意？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elg93d/d_per_class_augmentation_for_highly_imbalanced/</link>
      <description><![CDATA[在解决数据高度不平衡的计算机视觉问题时，我遇到了许多可以尝试的技术 - 从使用针对不平衡数据集定制的损失函数、类/样本权重，使用采样技术（如 SMOTE、加权随机采样器或只是常规随机采样）以及使用 GAN 来生成少数类的更多数据。然而，我想知道是否有人探索过每个类别的增强，即对不同类别应用不同的增强，少数类与多数类相比得到了大量增强。我搜遍了互联网，寻找表明为什么这可能是一个好主意或坏主意及其含义的材料，但无济于事。     提交人    /u/Antman-007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elg93d/d_per_class_augmentation_for_highly_imbalanced/</guid>
      <pubDate>Tue, 06 Aug 2024 12:17:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] RTX 4090 与 L40S 服务器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elenk8/d_rtx_4090_vs_l40s_for_server/</link>
      <description><![CDATA[大家好，我们公司正在为 AI 任务获取一台新服务器，我们正在考虑两种 GPU 配置：  4x RTX 4090 2x L40S  我们知道 4090s 的功耗更高，对环境的影响更大，但由于其成本原因，我们仍在考虑它们。 我们的主要用例：  运行和微调小型 LLM 以进行分类、嵌入和重新排名任务 可能运行和微调仅解码器模型（llama、gemma、phi...） GPU 将位于 Kubernetes 环境中  目前，我们所有的机器都处于 CPU 设置中，因此这是一个很大的对我们来说，改变 - 因此我们希望确保我们没有遗漏任何重要方面。 我们希望了解 L40S 在数据中心设置中的优势。我们可能会忽略哪些因素？L40S 是否有任何数据中心特定的功能对我们的工作负载特别有益？ 如果您能分享任何指导或经验，我们将不胜感激。谢谢！！    提交人    /u/ouzunkumhavuzu   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elenk8/d_rtx_4090_vs_l40s_for_server/</guid>
      <pubDate>Tue, 06 Aug 2024 10:51:37 GMT</pubDate>
    </item>
    <item>
      <title>[项目] - 如何展示模型缺失预测的推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elejh3/project_how_to_showcase_reasoning_for_model/</link>
      <description><![CDATA[建立了一个模型，使用营销支出、可用产品数量、库存、我们何时发布等来预测需求。 展示了模型，但财务总监想知道模型为何没有达到预测结果。 例如，如果模型预测收入为 100 万英镑，而我们产生了 90 万英镑的收入，她想知道是什么导致了预测结果的不符。 关于如何展示这一点，您有什么想法吗？我最初的想法是输出我们在预测中使用的特征，而不是特征的实际值。所以，如果我们说我们会在营销上花费 10 万英镑，但我们花了 9 万英镑，这可能是导致预测结果不符的原因？ 不是 DS，在工作中学习。任何想法都将不胜感激    提交人    /u/Environmental_Pop686   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elejh3/project_how_to_showcase_reasoning_for_model/</guid>
      <pubDate>Tue, 06 Aug 2024 10:44:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 开放医疗推理任务项目介绍：开源人工智能是前进的道路</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1el4sbc/d_introducing_the_open_medical_reasoning_tasks/</link>
      <description><![CDATA[      我们很高兴地宣布，Open Life-Science AI 推出了开放医学推理任务项目。受到 NousResearch 开创性工作的启发，我们正在开展一项开放的协作计划，为大型语言模型 (LLM) 创建一份全面的医学推理任务列表。 为什么这很重要 随着人工智能继续改变医疗保健，我们需要确保开源模型能够处理医疗专业人员每天面临的复杂推理任务。该项目旨在创建一套专门针对医疗 AI 的强大基准和训练数据集。 行动呼吁 致所有开创 AI 与医疗保健融合的医生、研究人员、数据科学家和创新者。 您如何做出贡献  分享您的专业知识：帮助我们定义和完善医学推理任务。 加入社区：与医疗专业人士和 AI 研究人员合作。 塑造未来：通过贡献，您将帮助创建重要的开放医疗种子任务、强大的合成数据集和全面的基准。此次合作将为医疗保健领域公正、高效的开放语言模型和 AI 系统铺平道路，最终增强全球患者护理和医学研究。  当前进展  我们已经为初始任务奠定了基础，但我们需要您的专业知识来扩展和完善它们。在此处查看我们当前的任务列表：开放医学推理任务 每个任务页面都包含其定义、医学示例、标签等。  愿景 我们相信开源 AI 是前进的道路。通过公开合作，我们可以创建真正理解和协助医学推理的人工智能系统，从而有可能彻底改变患者护理和医学研究。让我们共同塑造医疗人工智能的未来！ #OpenMedicalAI #AIinHealthcare #MedicalInnovation https://preview.redd.it/w3eu4y241ygd1.png?width=1924&amp;format=png&amp;auto=webp&amp;s=a2c85cf1dbd57d9fe4cce89071f79ac271e96819    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1el4sbc/d_introducing_the_open_medical_reasoning_tasks/</guid>
      <pubDate>Tue, 06 Aug 2024 01:08:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 从 2D 图像生成场景/3D 模型的最新进展</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ekzgh9/r_state_of_the_art_in_scene3d_model_generation/</link>
      <description><![CDATA[目前从视频或图像进行场景重建或 3D 模型生成的最新技术水平是什么？有什么论文或架构可以研究吗？    提交人    /u/rosecurry   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ekzgh9/r_state_of_the_art_in_scene3d_model_generation/</guid>
      <pubDate>Mon, 05 Aug 2024 21:17:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我开发了一个开源工具，让你可以直接在 Web 上构建 GPU 加速的 NN 和 Transformer</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ekvomn/p_i_built_an_opensource_tool_that_lets_you_build/</link>
      <description><![CDATA[每个人都喜欢 PyTorch 的语法。 JS-PyTorch 可让您编写类似 PyTorch 的代码并使用 JavaScript 直接在 Web 浏览器上运行它。该工具还支持 GPU 加速，运行速度比原生 Python 或 JS 快 30 倍。 我很乐意听到一些反馈，以及您希望在此项目中看到什么以使其变得更好！    提交人    /u/suspicious_beam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ekvomn/p_i_built_an_opensource_tool_that_lets_you_build/</guid>
      <pubDate>Mon, 05 Aug 2024 18:47:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 探索 SELF-ROUTE：一种高效的长上下文问答混合方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ekthxu/d_exploring_selfroute_a_hybrid_approach_to/</link>
      <description><![CDATA[SELF-ROUTE 方法结合了检索增强生成 (RAG) 和长上下文 (LC) 问答，利用 LLM 自我反思来高效地路由查询，在保持类似 LC 的性能的同时实现成本节约。有人在生产中尝试过这种方法吗？正在寻找见解。偶然发现了这篇很酷的帖子 https://tini.fyi/g6cqb    提交人    /u/Desperate-Homework-2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ekthxu/d_exploring_selfroute_a_hybrid_approach_to/</guid>
      <pubDate>Mon, 05 Aug 2024 17:20:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] InternVideo2：一个开源视频理解模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ekpgd8/r_internvideo2_a_opensource_video_understanding/</link>
      <description><![CDATA[InternVideo2：一个开源的突破性视频理解 AI 模型🥳，拥有 6B 参数编码器和 4 亿多个样本，在动态场景感知、时间理解和推理方面表现出色。非常适合具身智能和自动驾驶等应用。立即探索我们的开源模型和演示！ 👁️YouTube：https://youtu.be/NhGFFeBgflI?si=nE0UIbb4etNl45Ms… 👉Github http://github.com/OpenGVLab/InternVideo/tree/main/InternVideo2… 🤗Huggingface：https://huggingface.co/collections/OpenGVLab/internvideo2-6618ccb574bd2f91410df5cd ✍️论文：http://arxiv.org/abs/2403.15377 👏试用演示：http://vchat.opengvlab.com    提交人    /u/noise_3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ekpgd8/r_internvideo2_a_opensource_video_understanding/</guid>
      <pubDate>Mon, 05 Aug 2024 14:38:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 偏好学习：RLHF、n 个采样中最佳，还是直接偏好优化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ekodce/r_preference_learning_rlhf_best_of_n_sampling_or/</link>
      <description><![CDATA[根据标题：具有所有/部分这些方法的*实际*经验的人，您更喜欢哪种方法，为什么？ 您是否知道这些模型的变分版本以及它们是否有助于缓解过度优化？ 谢谢！    提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ekodce/r_preference_learning_rlhf_best_of_n_sampling_or/</guid>
      <pubDate>Mon, 05 Aug 2024 13:53:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在生产环境中执行 LLM 推理。分享您的最佳实践。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ekmuwe/d_how_to_perform_llm_inference_in_a_production/</link>
      <description><![CDATA[大家好， 您能否根据众所周知的标准和最佳实践，就如何为 LLM 模型（例如 Meta3.1 8B 和 70B）配置 LLM 推理引擎提供建议和推荐？我们有一台裸机 DGXA100 服务器，配备 8 个 40 GB A100 GPU。  我们应该使用 Kubernetes 还是只使用 Docker？ 我们应该使用 Nvidia Triton、HuggingFace TGI 还是 vLLM？ 在负载平衡方面，最好的方法是什么？我们应该使用 HA 代理还是网络平衡器？ 我们应该如何实施节流机制以确保系统的稳定性并防止过载？  非常感谢您提前提供的帮助！ 此致敬意， Shakhizat    提交人    /u/shakhizat   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ekmuwe/d_how_to_perform_llm_inference_in_a_production/</guid>
      <pubDate>Mon, 05 Aug 2024 12:45:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>