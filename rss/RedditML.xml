<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 25 Sep 2024 18:21:46 GMT</lastBuildDate>
    <item>
      <title>[D] NeurIPS 2024 评审问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpa7ua/d_neurips_2024_review_question/</link>
      <description><![CDATA[我最初的审稿人指出了一些弱点和顾虑，但这些问题在我的反驳中得到了解决。他们承认了这一点并提高了分数。  我的论文最终被拒绝，因为程序主席引入了由于误读论文而产生的新弱点，如果这些弱点在最初的审稿中有所说明，这个问题将很容易解决。我能做些什么来修复这个程序主席的审稿吗？    提交人    /u/sqweeeeeeeeeeeeeeeps   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpa7ua/d_neurips_2024_review_question/</guid>
      <pubDate>Wed, 25 Sep 2024 17:30:43 GMT</pubDate>
    </item>
    <item>
      <title>[R]基于注意力的选择性激活架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp70ca/r_attentionbased_selective_activation_architecture/</link>
      <description><![CDATA[有没有研究探索过灵活推理/深度负载架构的想法？也就是说，根据样本的任务难度，对模型的不同层深度进行训练。这将通过绕过模型的后面层来完成，以完成较简单的任务。最困难的任务将占用整个网络。对于 LLM 来说，在 Transformer/Mamba 中实现这一点需要一些思考，但我相信这是可行的。特别是如果在 Beam 方法下进行训练，而不是单输出方式（从未理解为什么仍然这样做，因为 Beam 似乎更好）。可以采用基于注意力的机制来决定推理的深度，或者采用某种强化学习主导的方法（训练后，如果 layer = n 给出错误的输出，则转到 n+1 直到满意为止） 我相信这会使模型在不同层次的复杂性/智能上成形（每一层都能够输出一些可理解的东西，从而也生成一个更易于解释的模型）。它还可以解决很多不必要的推理时间。 这个想法是一种看待“思维链”和我们真正思考方式的不同方式。它会将“思考”部分直接嵌入模型中，而不会自行生成内部独白。总而言之，仍然认为这两种方法都是积极且兼容的（我认为我们人类同时做这两种事情）。    提交人    /u/hatekhyr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp70ca/r_attentionbased_selective_activation_architecture/</guid>
      <pubDate>Wed, 25 Sep 2024 15:18:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为机器学习研究人员提供进入医学成像应用的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp3rf3/d_resources_for_ml_researcher_to_get_into_medical/</link>
      <description><![CDATA[大家好！ 我是一名具有物理学背景的 ML 研究员，即将开始攻读博士学位。我的研究小组主要研究医学成像 (MI) 应用，因此我需要在该领域内选择一个子主题。 我的主要兴趣是领域自适应和标签高效方法，我知道这些方法与 MI 非常相关。但是，我对 MI 的前景不太确定。  不同的子字段是如何构成的？ 每个应用程序的常见数据类型是什么？（2D、3D、2D + 时间等） 每个子领域中 ML 面临的紧迫挑战 / 问题是什么？（是否存在特别需要领域自适应技术的特定应用？）  如果有人能给我提供有关这些主题的细分 / 请为我提供一些资源，例如评论论文，将不胜感激！    由    /u/fliiiiiiip 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp3rf3/d_resources_for_ml_researcher_to_get_into_medical/</guid>
      <pubDate>Wed, 25 Sep 2024 12:55:46 GMT</pubDate>
    </item>
    <item>
      <title>【项目】本土LLM神器与思考——Gallama UI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp2z44/project_local_llm_artifact_and_thinking_gallama_ui/</link>
      <description><![CDATA[      嗨，这是我的个人项目，用于探索 Artifact 系统（类似于 Claude）以及本地 LLM 上的思路链提示。 简短的 GIF 表示它的样子：gallamaUI https://preview.redd.it/s8jb1kn7oxqd1.png?width=3537&amp;format=png&amp;auto=webp&amp;s=50edfd22abd607ef7ad9d4f0869072cb7e08a064 您还可以查看这个 YouTube 视频，看看它是否值得您花时间。您可以在实时演示中看到它 Youtube 演示 Github：https://github.com/remichu-ai/gallamaUI 特点：  本地 LLM 工件系统（如 Claude） 可通过 XML 模板定制的思路链 使用 exllamav2 或 llama cpp python（通过 gallama）  推荐的模型尝试：  最佳选择：Qwen2.5-72B/ 32B 和 Mistral Large 第二选择：Qwen-2-72B， Llama-3.1-70B 第三选择：Yi-34B、Codestral、Gemma-29B  这不适用于其他后端，如 ollama、tabby 等。因为后端是选择性的，并实现了某种方法来强制生成    提交人    /u/Such_Advantage_6949   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp2z44/project_local_llm_artifact_and_thinking_gallama_ui/</guid>
      <pubDate>Wed, 25 Sep 2024 12:17:11 GMT</pubDate>
    </item>
    <item>
      <title>[N] Uber 创建 GenAI 网关镜像 OpenAI API 以支持超过 60 个 LLM 用例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp2kdz/n_uber_creates_genai_gateway_mirroring_openai_api/</link>
      <description><![CDATA[https://www.infoq.com/news/2024/09/uber-genai-gateway-llm-openai/ Uber 创建了一个统一的平台，用于为来自外部供应商和自托管供应商的大型语言模型 (LLM) 提供服务，并选择镜像 OpenAI API 以帮助内部采用。GenAI Gateway 提供了一致且高效的界面，并在许多领域为 60 多个不同的 LLM 用例提供服务。    提交人    /u/rgancarz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp2kdz/n_uber_creates_genai_gateway_mirroring_openai_api/</guid>
      <pubDate>Wed, 25 Sep 2024 11:55:30 GMT</pubDate>
    </item>
    <item>
      <title>[D]机器学习控制系统中的 Koopman 算子</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp0rg6/d_koopman_operator_in_control_systems_with/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp0rg6/d_koopman_operator_in_control_systems_with/</guid>
      <pubDate>Wed, 25 Sep 2024 10:01:20 GMT</pubDate>
    </item>
    <item>
      <title>构建一个网络代理，根据用户详细信息调用填写 Google 表单 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fozud5/built_a_web_agent_which_call_fill_google_forms/</link>
      <description><![CDATA[      GitHub repo : https://github.com/shaRk-033/web-agent 尝试使用两种方法解决： 1：基本抓取和填写 这是最直接的方法。代理抓取表单的 HTML，并使用固定的 XPath 查找并填写必填字段。  它提取表单的 HTML，使用设置的 XPath 定位字段，然后输入答案。这是一种直接而简单的方法。 如果表单发生变化或元素不在预期的位置，则该过程可能会失败，可能需要手动调整。  基本方法  使用 LangChain Agent 和工具调用   LangChain Agent：代理使用 LLM 的推理来决定下一步做什么，包括生成那些棘手的 XPath，从而处理所有事情。 错误处理：如果出现问题（例如如果找不到元素），代理将再次尝试使用更好的 XPath，直到完成工作。  使用 langchain 代理 欢迎提出任何改进建议。此外，如果有人有关于构建类似的 Web 代理来自动化其他任务的想法，我们将非常乐意听到他们的想法。:)    提交人    /u/Silly-Dig-3312   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fozud5/built_a_web_agent_which_call_fill_google_forms/</guid>
      <pubDate>Wed, 25 Sep 2024 08:53:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于无监督图像搜索的双曲度量学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fozecb/p_hyperbolic_metric_learning_for_unsupervised/</link>
      <description><![CDATA[https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Unsupervised_Hyperbolic_Metric_Learning_CVPR_2021_paper.pdf 您对这篇论文有什么看法？我希望构建一个图像授权器，其第一步是图像搜索 (CBIR)，从数据库中选择正确的图像进行授权。我正在使用矢量数据库来存储嵌入。我尝试过 dinov2、剪辑嵌入。Dinov2 在大多数情况下都有效。您如何看待像这样的双曲嵌入？我已经读到是时候从欧几里得空间转移到双曲空间了，并且如果它们相似，嵌入看起来会更接近，因为它们遵循度量学习 编辑： 我的疑问是它说它适用于无监督数据集，没有标签，那么为什么它们的 DataLoader 有标签 从 __future__ 导入 absolute_import、print_function &quot;&quot;&quot; 用于 Pytorch 的 CUB-200-2011 数据集 &quot;&quot;&quot; 导入 torch 导入 torch.utils.data 作为数据 从 PIL 导入图像 导入 os 从 torchvision 导入变换 从集合导入 defaultdict 从DataSet.CUB200 导入 MyData、MyData_HC、default_loader、Generate_transform_Dict 类 Cars196： def __init__(self, root=None, root_c=None, origin_width=256, width=227, ratio=0.16, transform=None,part_rate=0, noise_rate=0, HC=True): 如果 transform 为 None： transform_Dict = Generate_transform_Dict(origin_width=origin_width, width=width, ratio=ratio) 如果 root 为 None： root = &#39;data/Cars196/&#39; 如果 root_c == &#39;/home/yjx/CVPR2021/&#39;： train_txt = os.path.join(root_c, &#39;train.txt&#39;) 否则： 如果 part_rate == 0： 如果 noise_rate == 0： train_txt = os.path.join(root，&#39;train.txt&#39;) 否则： train_txt = os.path.join(root，&#39;train_%.4f.txt&#39;%noise_rate)  否则： 如果 noise_rate == 0： train_txt = os.path.join(root，&#39;train_part_%.4f.txt&#39;%part_rate) 否则： train_txt = os.path.join(root，&#39;train_part_%.4f_%.4f.txt&#39;%(part_rate,noise_rate)) 通知 print(&#39;通知：现在使用 {}！&#39;.format(train_txt)) test_txt = os.path.join(root, &#39;test.txt&#39;) if HC: self.train = MyData_HC(root, label_txt=train_txt, transform=transform_Dict[&#39;rand-crop&#39;]) else: self.train = MyData(root, label_txt=train_txt, transform=transform_Dict[&#39;rand-crop&#39;]) self.gallery = MyData(root, label_txt=test_txt, transform=transform_Dict[&#39;center-crop&#39;]) def testCar196(): data = Cars196() print(len(data.gallery)) 打印（len（data.train）） 打印（data.train[1]） 如果 __name__ == &quot;__main__&quot;: testCar196()    由   提交  /u/PositiveResponse7678   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fozecb/p_hyperbolic_metric_learning_for_unsupervised/</guid>
      <pubDate>Wed, 25 Sep 2024 08:18:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要多少微分方程知识才能理解流动、扩散 SciML 和相关领域的研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foygx0/d_how_much_knowledge_of_differential_equations_is/</link>
      <description><![CDATA[我印象中，基础微积分、概率、统计学和线性代数为理解深度学习的工作奠定了坚实的基础。但是看到最近关于流匹配、流标准化、扩散和科学机器学习领域的论文，我无法理解超出某一点的东西。  我知道他们大量使用微分方程。我在该领域的知识几乎低于新手水平。在哪里可以学到更多关于微分方程的知识？我想获得理解这些领域工作的能力，以及论文作者如何以及为何提出这种实现。    提交人    /u/HopeIsGold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foygx0/d_how_much_knowledge_of_differential_equations_is/</guid>
      <pubDate>Wed, 25 Sep 2024 07:05:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有人研究过，用特定的查询来启动 LLM 是否会导致它对后续不相关的查询采用更多新颖的途径？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foumnd/d_has_anybody_investigated_whether_priming_a_llm/</link>
      <description><![CDATA[上下文： https://chatgpt.com/share/66f37954-e7c8-800d-a809-327f30f549b1 我向 ChatGPT 询问了一个关于 Rockwell Retro Encabulator（一种实际上并不存在的小玩意儿）的愚蠢问题。它似乎以一种与平常不同的方式做出回应，因此我向它询问了更多问题，我注意到它的答案总体上比它通常输出的答案更新颖。我想知道： 1- 这是安慰剂吗？我是不是想得太深了？ 2- 如果不是安慰剂，用一个新问题来启动模型是否会导致后续问题偏向于新答案，即使在典型情况下，这个问题会利用更常见的途径？ 3- 这是否可以在小众情况下实际使用（例如语言翻译）来改善模型的响应。 o1 预览似乎认为这是合理的，而且它的基本原理对我来说很有道理。你们觉得怎么样？这有什么问题吗？    提交人    /u/NepNep_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foumnd/d_has_anybody_investigated_whether_priming_a_llm/</guid>
      <pubDate>Wed, 25 Sep 2024 02:57:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果对抗性学习研究表明神经网络对输入/权重扰动非常脆弱，那么量化为什么会起作用呢？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fosr7z/d_if_adversarial_learning_studies_suggest_neural/</link>
      <description><![CDATA[我一直在想为什么这两种观察结果可以共存而不发生冲突。对抗性学习的研究似乎表明，人们可以很容易地找到输入或权重上的微小扰动，这些扰动可以彻底改变某些输出。如果扰动某些权重已经足够糟糕，那么像量化那样扰动每个权重肯定会带来灾难性的后果？ 我有几个猜测：  也许对抗性扰动方向很多但在所有可能的方向中很少见，而像量化这样的随机扰动不太可能是对抗性的？ 也许我们确实引入了错误，但只在一小部分输出上，这还不够糟糕？ 也许随机权重扰动对非常大的网络的损害较小？  是否有人知道现有的优秀研究可以解释为什么量化不会导致无意的自我破坏？    提交人    /u/aeroumbria   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fosr7z/d_if_adversarial_learning_studies_suggest_neural/</guid>
      <pubDate>Wed, 25 Sep 2024 01:20:22 GMT</pubDate>
    </item>
    <item>
      <title>[D]-NeurIPS 2024 决策</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foky4r/d_neurips_2024_decisions/</link>
      <description><![CDATA[大家好！请注意，NeurIPS 2024 决策通知将于 2024 年 9 月 26 日欧洲中部夏令时间凌晨 3:00 发布。我觉得创建一个我们可以讨论它的帖子会很酷。    提交人    /u/Proof-Marsupial-5367   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foky4r/d_neurips_2024_decisions/</guid>
      <pubDate>Tue, 24 Sep 2024 19:23:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 目前对您来说最令人兴奋的三大研究方向是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fo7ben/r_what_are_the_top_3_most_exciting_research/</link>
      <description><![CDATA[让我们分享吧！你对什么感到兴奋？    提交者    /u/Prestigious_Bed5080   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fo7ben/r_what_are_the_top_3_most_exciting_research/</guid>
      <pubDate>Tue, 24 Sep 2024 08:05:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 22 Sep 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>