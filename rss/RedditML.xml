<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 06 Oct 2024 03:24:14 GMT</lastBuildDate>
    <item>
      <title>[D] 过采样和欠采样：要进行到什么程度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fx1kph/d_oversampling_and_undersampling_how_much_to_do_so/</link>
      <description><![CDATA[大家好！希望你们都过得好 :) 我有一个关于随机过采样和随机欠采样的问题；我们到底做了多少？你能给我指出一篇关于这方面的论文吗？ 我的类别不平衡为 1:50 或 600:30000，我想在类别上测试这两种方法，但我不确定要这样做多少。我是否要欠采样 60%？或者我最多要复制少数类别 4 次？你们能告诉我该怎么做吗？或者请给我指出任何讨论这个问题的论文（最好是这样），我将不胜感激。 谢谢！    提交人    /u/Arsenal368   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fx1kph/d_oversampling_and_undersampling_how_much_to_do_so/</guid>
      <pubDate>Sat, 05 Oct 2024 22:04:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] Groq 和 AWS Bedrock 之间的区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwxljv/d_difference_between_groq_and_aws_bedrock/</link>
      <description><![CDATA[我正在研究 AWS Bedrock 以满足客户需求，但我真的不明白它与 Groq 有何不同？两者都提供开源模型..？ 我了解 AWS Bedrock 具有一些附加功能，例如图像生成......但从文本生成的角度来看，它们是否相同？ 如果是，那为什么价格如此高昂？    提交人    /u/Revolutionary_Bad328   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwxljv/d_difference_between_groq_and_aws_bedrock/</guid>
      <pubDate>Sat, 05 Oct 2024 18:59:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要有关 IJCV 提交的建议。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwtf79/d_need_suggestions_regarding_an_ijcv_submission/</link>
      <description><![CDATA[大家好， 我最近有一篇论文被 ECCV 接受，我计划将其扩展到期刊提交。我选择 IJCV 是因为它比 TPAMI 等更快，并且在该领域也得到很好的认可。我的计划如下。 1) 添加 2 到 3 个数据集以显示泛化。 2) 添加新模型（例如骨干等）。 3) 对模型的稳健性进行更多调整。 不幸的是，我的主管没有 IJCV 方面的经验，因此我正在向其他研究人员寻求建议。问题是，遵循上述计划可以吗？此外，在大型会议上发表过论文是否有助于被 IJCV 接受，还是每篇提交都被视为独立处理？ 问候    由    /u/dn8034  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwtf79/d_need_suggestions_regarding_an_ijcv_submission/</guid>
      <pubDate>Sat, 05 Oct 2024 15:50:38 GMT</pubDate>
    </item>
    <item>
      <title>如何结合两幅图像的空间 CNN 特征（如 OR 条件）[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwt6ls/how_to_combine_spatial_cnn_features_of_two_image/</link>
      <description><![CDATA[我有两个基于图像分类的图像，其中任何一个图像都将具有要分类的对象。 分类器必须在训练期间学习类似 OR 条件的东西 在这种情况下，如何以正确的方式组合两个图像的空间特征？ 现在 Img1 特征 - f1 - bsX768X7X7 Img2 特征 - f2 - bsX768X7X7 我正在做两种方法 1 - concat - f1+f2 - bsX1536X7X7 1 - concat + 再次 CNN Rreduce 通道 - f1+f2 - bsX1536X7X7 —&gt; bsX768X7X7 还有没有更好或者更理想的方法呢    提交人    /u/nightking151   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwt6ls/how_to_combine_spatial_cnn_features_of_two_image/</guid>
      <pubDate>Sat, 05 Oct 2024 15:39:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何使用 Torchtune 在 Lightning.ai 上微调 Llama 3.1</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwsxj0/p_how_to_finetune_llama_31_on_lightningai_with/</link>
      <description><![CDATA[        由   提交  /u/Smooth-Loquat-4954   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwsxj0/p_how_to_finetune_llama_31_on_lightningai_with/</guid>
      <pubDate>Sat, 05 Oct 2024 15:28:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 劳拉什么时候不够好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwqgfx/d_when_is_lora_not_good_enough/</link>
      <description><![CDATA[在 LLM 微调任务中，LORA（或其某些变体）不够好，需要进行全面微调，这方面有哪些例子？ 例如，在所有测试任务中，RoSA（LORA 变体）与全面微调一样好 https://arxiv.org/pdf/2401.04679    提交人    /u/osamc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwqgfx/d_when_is_lora_not_good_enough/</guid>
      <pubDate>Sat, 05 Oct 2024 13:30:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从头开始​​实现 Llama 3.2 1B 和 3B 架构（独立的 Jupyter Notebook）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwq5su/p_implementing_the_llama_32_1b_and_3b/</link>
      <description><![CDATA[    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwq5su/p_implementing_the_llama_32_1b_and_3b/</guid>
      <pubDate>Sat, 05 Oct 2024 13:15:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于深度学习基础课的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwpz1c/d_thoughts_on_deep_learning_fundamentals_class/</link>
      <description><![CDATA[我最近上了 Sebastian Raschka 的深度学习基础课。我很喜欢这门课，强烈推荐！ https://lightning.ai/courses/deep-learning-fundamentals/ 还有人上过这门课吗？你有什么想法？上完这门课后，下一步该怎么做？    提交人    /u/mikejamson   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwpz1c/d_thoughts_on_deep_learning_fundamentals_class/</guid>
      <pubDate>Sat, 05 Oct 2024 13:06:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 ArcFaceLoss 的 db 细分的困惑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwog44/d_confusion_about_db_subdivision_with_arcfaceloss/</link>
      <description><![CDATA[有人有使用 ArcFace Loss 的经验吗？ 我有一个包含 45k 张图像和 16k 个类的数据集。 我像这样拆分数据库：如果类只有一个图像，则将其放入训练中，否则我将一个图像放入有效中并将其全部放入训练中。 我使用 MobileNetV3 作为主干，学习率为 1e-3，但损失在 15 个时期内从 25.8 下降到 25.6，下降幅度很小。 有人能告诉我我需要查看什么或错误可能在哪里吗？我遗漏了什么吗？    提交人    /u/Elsospi98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwog44/d_confusion_about_db_subdivision_with_arcfaceloss/</guid>
      <pubDate>Sat, 05 Oct 2024 11:40:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 泛化界限的理论局限性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwnb1r/r_theoretical_limitations_of_generalization_bounds/</link>
      <description><![CDATA[总结：泛化边界的紧密程度存在根本限制。 尽管近年来提出了许多新提出的泛化边界，但一个共同的主题是，在实际环境（即实际大小的模型、标准数据集）中进行评估时，它们在数值上是松散的（甚至是空洞的）。这严重限制了它们作为性能保证的效用及其对实际算法设计的影响。 这种理论与实践之间的差距仅仅是松散证明技术的产物，还是这种边界的紧密程度也存在根本的统计限制？ 我们发现，在许多情况下，情况都是后者！ 论文 1（发表于 ICLR ’24） https://arxiv.org/abs/2309.13658 :  对于许多算法-分布组合而言，未针对特定算法量身定制的界限必然是松散的。 在足够丰富的学习环境中，依赖于算法的界限受制于不确定性原理：人们要么很好地学习目标分布，要么验证学习的成功——永远无法同时实现！  论文 2（最近的预印本） https://arxiv.org/abs/2410.01969 ：  我们表明，具有某些导致其不稳定的归纳偏差的算法不承认严格的泛化界限。 接下来，我们表明足够稳定的算法确实具有严格的泛化界限。  我们认为我们的发现可能会引起对泛化广泛感兴趣的社区中许多成员的兴趣。 很高兴讨论 - 欢迎提出问题，反馈和批评：)    提交人    /u/zweihander___   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwnb1r/r_theoretical_limitations_of_generalization_bounds/</guid>
      <pubDate>Sat, 05 Oct 2024 10:22:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当你的模型训练时你做什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwjafn/d_what_do_you_do_when_your_model_trains/</link>
      <description><![CDATA[你如何打发时间？    提交者    /u/Replay0307   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwjafn/d_what_do_you_do_when_your_model_trains/</guid>
      <pubDate>Sat, 05 Oct 2024 05:26:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] Meta 发布少于 400 亿个参数的 SOTA 视频生成和音频生成。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwic4m/r_meta_releases_sota_video_generation_and_audio/</link>
      <description><![CDATA[      今天，Meta 发布了一套 SOTA 文本转视频模型。这些模型足够小，可以在本地运行。他们似乎不打算发布代码或数据集，但他们几乎提供了模型的所有细节。事实上，这个模型已经如此连贯，这确实表明开发正在发生得有多快。 https://ai.meta.com/research/movie-gen/?utm_source=linkedin&amp;utm_medium=organic_social&amp;utm_content=video&amp;utm_campaign=moviegen 这套模型（Movie Gen）包含许多模型架构，但看到通过声音和图片同步进行训练非常有趣。从训练的角度来看，这实际上非常有意义。 https://preview.redd.it/047ddxdb7vsd1.png?width=1116&amp;format=png&amp;auto=webp&amp;s=a7cd628a8b2dde9824b27983a430217123c297d8    提交人    /u/AIAddict1935   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwic4m/r_meta_releases_sota_video_generation_and_audio/</guid>
      <pubDate>Sat, 05 Oct 2024 04:26:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习论文的第一作者还是什么都不是？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwhiit/r_first_author_ml_paper_or_nothing/</link>
      <description><![CDATA[我最近与一位在 AI/ML 领域（非理论领域）颇有建树的朋友进行了一次有趣的对话。他们对出版物中的作者身份做出了一个相当大胆的声明： “在 AI/ML 中，基本上要么第一作者，要么什么都不是。” 此人有超过 2,000 次引用，并且来自顶级机构，所以我倾向于认真对待他们的意见。他们甚至说：“有时除了第三作者之外，他们甚至不接触代码库。” 我很想听听其他人对此的看法。在 AI/ML 论文中，只有第一作者才被认为是重要的，这是真的吗？与其他领域相比如何？ 您在工作或学习中遇到过这种情况吗？我很感激任何见解，特别是那些目前在行业或学术界工作的人的见解。​​​​​​​​​​​​​​​​    提交人    /u/Electronic_Hawk524   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwhiit/r_first_author_ml_paper_or_nothing/</guid>
      <pubDate>Sat, 05 Oct 2024 03:35:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 29 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>