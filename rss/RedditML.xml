<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 04 May 2024 03:15:02 GMT</lastBuildDate>
    <item>
      <title>[P] [D] 您已交付的客户项目示例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjqdmp/p_d_examples_of_client_projects_that_you_have/</link>
      <description><![CDATA[简短版本：给我一些 ML 领域客户可交付成果的示例。将有助于判断我开始自由咨询的立场。 嗨，我是一名 SWE，同时学习 ML。我的日常工作并没有太多接触 ML，但接触了很多 GPU 的东西。我开始学习 ML，目前正处于可以实现研究论文中的一些模型的阶段。  寻找现实世界中的一些示例，您已成功为客户完成了哪些可交付成果。  这将极大地帮助了解我在从事全职咨询方面的立场。  在这个庞大模型的时代，创办一家独立咨询公司是否有意义？   由   提交 /u/SmallTimeCSGuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjqdmp/p_d_examples_of_client_projects_that_you_have/</guid>
      <pubDate>Sat, 04 May 2024 03:00:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这里有传统行业的员工可以分享一下他们在工作中是否使用了 gen AI 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjprls/d_is_any_traditional_industry_employee_here_can/</link>
      <description><![CDATA[我很好奇。有人在银行制造业等传统企业工作，实际使用 gen AI 吗？如果是的话怎么办？   由   提交/u/digital-bolkonsky  /u/digital-bolkonsky  reddit.com/r/MachineLearning/comments/1cjprls/d_is_any_traditional_industry_employee_here_can/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjprls/d_is_any_traditional_industry_employee_here_can/</guid>
      <pubDate>Sat, 04 May 2024 02:26:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 过度拟合稳定扩散是什么意思？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjknmo/d_what_does_it_mean_to_overfit_stable_diffusion/</link>
      <description><![CDATA[在扩散论文中，他们说他们的模型在训练和测试中的码长差距最多为每个维度 0.03 位，这表明 midel 不会过度拟合。但模型在扩散情况下过度拟合到底意味着什么呢？那么它是否只对训练集中的图像进行去噪？ 干杯！   由   提交/u/Error40404  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjknmo/d_what_does_it_mean_to_overfit_stable_diffusion/</guid>
      <pubDate>Fri, 03 May 2024 22:10:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于合成数据生成的 Flan-T5？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjh0yd/p_flant5_for_synthetic_data_generation/</link>
      <description><![CDATA[大家好， 我正在尝试构建一个关于合成数据集生成的个人项目。一直在研究+为项目制定初始结构。 我的主要问题是FLAN-T5可以用于数据生成/海量文本生成吗？ 我不能似乎找到了人们将其用于该用例的示例。我也研究过混合指令模型。由于成本问题，我正在尝试避免使用 GPT4。 请告诉我任何其他可能对我的目的有利的 LM  &amp;# 32；由   提交/u/Theredeemer08   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjh0yd/p_flant5_for_synthetic_data_generation/</guid>
      <pubDate>Fri, 03 May 2024 19:21:04 GMT</pubDate>
    </item>
    <item>
      <title>[R][D] 用于提高 RNN 性能的时间序列量化（LLM 的可能用例）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjdxn7/rd_quantization_of_timeseries_for_improving/</link>
      <description><![CDATA[大家好， 想问一下你们是否有使用量化/分箱版本的特征集和/或目标集来提高时间序列问题序列学习器的性能的经验。 我对 NLP 不是很在行，所以对于可能出现的任何错误深表歉意 设置： f(X) -&gt; ŷ 目标是 |ŷ-y| &lt; eps X 是一个特征集，其中的特征希望能够为 y 提供信息，并且信息频率各不相同，例如，作为一个玩具示例，每个特征维度具有不同窗口的简单移动平均线。 X 和 y 很嘈杂 动机 我看到最近的一些工作修改了单变量时间序列预测问题，使它们可以被 LLM 消化，特别是：Chronos：学习时间序列的语言 一般方法是  以某种方式缩放时间序列，例如将每个序列除以平均绝对值 将这些值分组以使可能的值现在是离散的 添加开始 / 结束标记以便 LLM 可以消化，然后用于预测  现在我们有了一个时间序列可以传递到 LLM 中 针对 RNN 而非 LLM 的量化 退一步讲，与其将上述转换用于 LLM，我想知道是否有人在这里使用这些技术使时间序列更适合 RNN。转换的两个重要部分是 (1) 缩放技术和 (2) 箱数 N。当 N -&gt; 无穷大时，我们获得与原始时间序列相同的精度。 量化作为函数 Q(.) 可以应用于 X、y 或两者。我想到的好处：  使用整数作为箱的引用，以实现更快/更轻松的交易 减少信号中的噪声 使用特征嵌入的可能性？  希望这很清楚。任何帮助都值得感激。    由   提交  /u/HungryhungryUgolino   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjdxn7/rd_quantization_of_timeseries_for_improving/</guid>
      <pubDate>Fri, 03 May 2024 17:10:48 GMT</pubDate>
    </item>
    <item>
      <title>[N] 人工智能工程师报告称，科技行业为了保持竞争力而进行的“激烈竞争”导致了职业倦怠和仓促推出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjdmr5/n_ai_engineers_report_burnout_and_rushed_rollouts/</link>
      <description><![CDATA[人工智能工程师将职业倦怠和仓促推出视为保持竞争力的“老鼠赛跑”打击了科技行业 文章摘要：   顶级科技公司的人工智能工程师告诉 CNBC，以极快的速度推出人工智能工具的压力已经决定了他们的工作。 他们表示，他们的大部分工作都是为了安抚投资者，而不是为最终用户解决问题，而且他们经常追逐 OpenAI。 倦怠是一个越来越普遍的主题，因为人工智能工作者表示，他们的雇主在开展项目时没有考虑到该技术对气候变化、监视和其他潜在现实世界危害的影响。 倦怠是一个越来越普遍的主题。 em&gt;  这篇文章中引用了一段特别深刻的话：  一位在零售监控初创公司工作的人工智能工程师告诉 CNBC，他是他是一家 40 人公司中唯一的 AI 工程师，负责处理与 AI 相关的任何职责，这是一项艰巨的任务。他表示，该公司的投资者对人工智能的能力有不准确的看法，经常要求他构建某些“我无法交付”的东西。    由   提交/u/bregav  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjdmr5/n_ai_engineers_report_burnout_and_rushed_rollouts/</guid>
      <pubDate>Fri, 03 May 2024 16:58:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人物设计软件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjb4da/d_software_to_design_figures/</link>
      <description><![CDATA[       我想为 rl 算法创建图表/图形。我真的很喜欢 Deep Mind 论文中使用的风格（AlphaZero、AlphaTensor、MuZero，...）。有谁知道这些图片是用什么软件做的吗？或者也许还有其他可以达到类似结果的东西？ https://preview.redd.it/4uohkcbxg8yc1.png?width=791&amp;format=png&amp;auto=webp&amp;s=9136bd12eb797523a5ff73f2b0b02e811239d9c3 https://preview.redd.it/1vzin9izg8yc1.png?width=578&amp;format=png&amp; auto=webp&amp;s=8046e1196347365b48ad2d3920ee0ba18119600c   由   提交 /u/_Hardric   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjb4da/d_software_to_design_figures/</guid>
      <pubDate>Fri, 03 May 2024 15:13:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何训练文本检测模型，以检测其从 +180 度到 -180 度的方向（旋转）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cja2s8/d_how_to_train_a_text_detection_model_that_will/</link>
      <description><![CDATA[大多数模型似乎都能够检测旋转的物体，但它们使用所谓的 le90 约定，其中物体从 +90 度旋转到 -90 度。在我的例子中，我想以正确的方向检测图像上的文本，这意味着在我的例子中 0 度和 180 度是不同的（在 MMOCR、MMDET 和 MMRotate 模型中就是这种情况）。 &lt; p&gt;你能指导我解决这个问题吗？我该如何处理这个问题？您有解决这个问题的一些开源项目的链接吗？ 我知道通常可以通过训练另一个小模型或通过训练所有可能的旋转的识别阶段来解决文本方向问题，但我想在检测阶段尽早解决这个问题。任何想法将不胜感激。提前致谢。   由   提交 /u/tmargary   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cja2s8/d_how_to_train_a_text_detection_model_that_will/</guid>
      <pubDate>Fri, 03 May 2024 14:29:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] HGRN2：具有状态扩展的门控线性 RNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj4ouc/r_hgrn2_gated_linear_rnns_with_state_expansion/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.07904 代码：https://github .com/OpenNLPLab/HGRN2 独立代码 (1):  https://github.com/Doraemonzzz/hgru2-pytorch 独立代码 (2): https://github.com/sustcsonglin/flash-linear-attention/tree/main/fla/models/hgrn2 摘要：  分层门控线性 RNN（HGRN，Qin 等人，2023 ）在语言建模方面展示了有竞争力的训练速度和性能，同时提供了高效的推理。然而，HGRN 的循环状态大小仍然相对较小，这限制了其表达能力。为了解决这个问题，受线性注意力的启发，我们引入了一种简单的基于外积的状态扩展机制，以便可以在不引入任何额外参数的情况下显着扩大循环状态大小。线性注意力形式还允许进行硬件高效的训练。我们大量的实验验证了 HGRN2 在语言建模、图像分类和 Long Range Arena 方面相对于 HGRN1 的优势。我们最大的 3B HGRN2 模型在受控实验设置中的语言建模方面略优于 Mamba 和 LLaMa Architecture Transformer；并且在下游评估中与许多开源 3B 模型竞争，同时使用更少的总训练令牌。    [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj4ouc/r_hgrn2_gated_linear_rnns_with_state_expansion/</guid>
      <pubDate>Fri, 03 May 2024 09:47:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于 Transformer 的语言模型内部工作原理入门</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj4o70/r_a_primer_on_the_inner_workings_of/</link>
      <description><![CDATA[      作者：Javier Ferrando (UPC)、Gabriele Sarti (RUG)、Arianna Bisazza （RUG），Marta Costa-jussà（元） 论文： https://arxiv .org/abs/2405.00208 摘要：  旨在解释高级语言内部运作方式的研究的快速进展模型强调需要将从该领域多年的工作中获得的见解结合起来。本入门书对用于解释基于 Transformer 的语言模型的内部工作原理的当前技术进行了简明的技术介绍，重点关注仅生成解码器的架构。最后，我们对这些模型实现的已知内部机制进行了全面概述，揭示了该领域流行方法和活跃研究方向之间的联系。  https://preview.redd.it/57y44wwdn6yc1.png?width=1486&amp;format= png&amp;汽车=webp&amp;s=7b7fb38a59f3819ce0d601140b1e031b98c17183   由   提交 /u/SubstantialDig6663   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj4o70/r_a_primer_on_the_inner_workings_of/</guid>
      <pubDate>Fri, 03 May 2024 09:46:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对特定领域数据微调 Phi-3 模型 - 寻求建议和见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj2hzb/d_finetune_phi3_model_for_domain_specific_data/</link>
      <description><![CDATA[      嗨， 我目前正在工作微调金融数据的 Phi-3 模型。虽然训练过程中损失不断减少，表明模型学习得很好，但自定义基准测试的结果却出人意料地差。事实上，与基础模型相比，准确性有所下降。 我观察到的结果：  Phi-3-mini-4k-instruct（基础模型）：平均域准确度为 40% Qlora - Phi-3-mini-4k-instruct（微调模型）：平均域准确度为 35%  我有尝试了各种方法，包括 QLora、Lora 和 FFT，但与基本模型相比，所有结果都很差。而且，我还尝试过将序列长度减少到2k，试图约束模型，防止模型偏离轨道，但不幸的是，这并没有带来任何改善。 我想知道超参数是否可能存在问题（例如学习率），或者是否有任何关于如何有效地微调此模型以在特定领域数据上获得更好性能的建议。 如果有人有成功地根据特定领域的数据微调 Phi-3 模型，我将非常感谢您可以分享的任何见解或建议。预先感谢您的帮助和支持！  qlora 配置： ​ sequence_len: 4000 Sample_packing: true pad_to_sequence_len: true trust_remote_code: True 适配器：qlora lora_r: 256 lora_alpha ：512 lora_dropout：0.05 lora_target_linear：true lora_target_modules：-q_proj - v_proj - k_proj - o_proj - gateway_proj - down_proj - up_proj 梯度累积步骤：1 micro_batch_size：2 num_epochs：4 优化器：adamw_torch lr_scheduler：余弦学习率：0 .00002 Warmup_steps：100 evals_per_epoch：4 eval_table_size： saves_per_epoch：1 调试：deepspeed：weight_decay：0.0  https://preview.redd.it/7afyhxcjv5yc1.png?width=976&amp;format=png&amp;auto=webp&amp;s=1ce3efe6df6e4533bad5ec2f23e4f4968736 bd56 ​ ;   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj2hzb/d_finetune_phi3_model_for_domain_specific_data/</guid>
      <pubDate>Fri, 03 May 2024 07:10:19 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 我应该去ICML发表论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</link>
      <description><![CDATA[我完成了博士学位。一年前。离开学术界，成为一家科技公司的数据科学家。我喜欢它，但仍在考虑将来以某种方式转向更多的研究职位。不过不确定。 无论如何，我的一个未完成的作品被一个朋友选中，完成并申请到 ICML。它被接受了（耶！）。 我现在想知道 - 除了我发现会议很有趣之外，参加会议还有实际好处吗？提交论文？我知道对于学术界/研究人员来说，这是一个很好的机会来了解人们并了解当前的研究。但由于我不再在那里，有真正的理由去吗？ 这是一个很奇怪的问题，但我只是不确定，我很高兴听到你的想法。  &gt;   由   提交 /u/meni_s   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</guid>
      <pubDate>Thu, 02 May 2024 21:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于 ICML、NeurIPS、CVPR 等顶级会议，我一直在思考的事情。有多少论文是真正具有开创性的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</link>
      <description><![CDATA[我自己也有一些位于金星顶端的论文，但每当我坐下来对自己残酷地诚实时。我觉得我的工作很好，但它的影响力并不大，就像墙上又多了一块砖。我想知道我们多久能看到像“注意力就是你所需要的一切”这样有影响力的东西例如。   由   提交 /u/oddhvdfscuyg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</guid>
      <pubDate>Thu, 02 May 2024 18:37:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大三学生（本科生或一至二年级的博士生）在 ICML、ICLR、NeurIPS 等主要机器学习会议上发表如此多的论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</link>
      <description><![CDATA[大家好，今天ICML成绩出来了，恭喜所有在这里接受论文的同学。我自己不是学者，但有时我会为了工作而阅读这些会议上的论文，这真的很有趣。我只是有一个问题：为什么这些会议上大三的论文这么多？我认为这是你在 5 年博士学位期间必须学习的东西，而且几乎只能在博士学位的最后几年才能实现。另外，我听说要进入美国顶尖的博士项目，你需要事先写一些论文。那么，如果一个大三学生能这么早发表论文，为什么还要花5年时间攻读博士学位呢？   由   提交 /u/ShiftStrange1701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</guid>
      <pubDate>Thu, 02 May 2024 11:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>