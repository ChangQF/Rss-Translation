<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 03 May 2024 09:14:37 GMT</lastBuildDate>
    <item>
      <title>我们来谈谈NLP和LLM的区别[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj37pl/lets_talk_about_the_difference_between_nlp_and/</link>
      <description><![CDATA[NLP 就像一个专家团队，每个人都擅长一项特定的工作，例如翻译语言或判断句子听起来是积极还是消极。他们确实很擅长自己所做的事情，但他们只知道如何做一件事。 法学硕士就像语言世界的超级明星。他们接受过大量信息的培训，因此可以做很多不同的事情，例如翻译、分析情绪，甚至编写听起来像人类写的文本。然而，有时他们可能不如专家那么精确。 未来将需要 NLP 和 LLM。当我们结合它们的优势时，我们可以制造出更智能、更能理解我们并用我们自己的语言与我们交谈的机器。 https://www.seaflux.tech/blogs/llm-vs-nlp-use-case-for-business-solutions&lt; /p&gt;   由   提交/u/krunal_bhimani_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj37pl/lets_talk_about_the_difference_between_nlp_and/</guid>
      <pubDate>Fri, 03 May 2024 08:01:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对特定领域数据微调 Phi-3 模型 - 寻求建议和见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj2hzb/d_finetune_phi3_model_for_domain_specific_data/</link>
      <description><![CDATA[      嗨， 我目前正在工作微调金融数据的 Phi-3 模型。虽然训练过程中损失不断减少，表明模型学习得很好，但自定义基准测试的结果却出人意料地差。事实上，与基础模型相比，准确性有所下降。 我观察到的结果：  Phi-3-mini-4k-instruct（基础模型）：平均域准确度为 40% Qlora - Phi-3-mini-4k-instruct（微调模型）：平均域准确度为 35%  我有尝试了各种方法，包括 QLora、Lora 和 FFT，但与基本模型相比，所有结果都很差。而且，我还尝试过将序列长度减少到2k，试图约束模型，防止模型偏离轨道，但不幸的是，这并没有带来任何改善。 我想知道超参数是否可能存在问题（例如学习率），或者是否有任何关于如何有效地微调此模型以在特定领域数据上获得更好性能的建议。 如果有人有成功地根据特定领域的数据微调 Phi-3 模型，我将非常感谢您可以分享的任何见解或建议。预先感谢您的帮助和支持！  qlora 配置： ​ sequence_len: 4000 Sample_packing: true pad_to_sequence_len: true trust_remote_code: True 适配器：qlora lora_r: 256 lora_alpha ：512 lora_dropout：0.05 lora_target_linear：true lora_target_modules：-q_proj - v_proj - k_proj - o_proj - gateway_proj - down_proj - up_proj 梯度累积步骤：1 micro_batch_size：2 num_epochs：4 优化器：adamw_torch lr_scheduler：余弦学习率：0 .00002 Warmup_steps：100 evals_per_epoch：4 eval_table_size： saves_per_epoch：1 调试：deepspeed：weight_decay：0.0  https://preview.redd.it/7afyhxcjv5yc1.png?width=976&amp;format=png&amp;auto=webp&amp;s=1ce3efe6df6e4533bad5ec2f23e4f4968736 bd56 ​ ;   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj2hzb/d_finetune_phi3_model_for_domain_specific_data/</guid>
      <pubDate>Fri, 03 May 2024 07:10:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] bioDraws 的正面抽奖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj2au2/r_postive_draws_for_biodraws/</link>
      <description><![CDATA[我是 python 初学者。请帮助我解决以下情况。我的研究陷入困境。考虑以下方程，其中必须生成随机值（当前已将方法设置为 NORMALMLHS）。 。 L1 =c+sigmaL1 * bioDraws (E_L1&#39;,&#39;NORMAL_MLHS) 。其中 L1 是内生变量，c 是估计常数，其下限为 0。sigmaL1 的下限也是 0。可以使用哪种方法代替“NORMAL_MLHS”来确保它生成正值，因此 L1 为正?   由   提交/u/h2_so4_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj2au2/r_postive_draws_for_biodraws/</guid>
      <pubDate>Fri, 03 May 2024 06:57:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 距离估计 - 真实世界坐标</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj14fe/d_distance_estimation_real_world_coordinates/</link>
      <description><![CDATA[您好，很抱歉再次转发此问题，但这非常重要，我需要帮助。 我有三个房间内不同位置（前墙、左墙、右墙）的摄像头。我应该能够找到房间中人与人之间的距离（以米为单位）。 我对所有摄像机进行了摄像机校准。 我尝试使用 SIFT 匹配公共点，然后执行DLT 方法，但值相差甚远，甚至不接近实际值。 我也尝试过立体视觉，但这并没有给我接近的值。 我也相机之间的距离也以米为单位。 我是计算机视觉的初学者，我应该很快完成这项任务，但我已经坚持了一个月了，而且我越来越累了无法解决这个问题，我已经没有解决方案了。  如果有人帮助我并引导我走向正确的方向，我将非常感激。 非常感谢您的帮助和时间😄   由   提交 /u/Embarrassed_Top_5901   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj14fe/d_distance_estimation_real_world_coordinates/</guid>
      <pubDate>Fri, 03 May 2024 05:38:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 迭代推理偏好优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciyps2/r_iterative_reasoning_preference_optimization/</link>
      <description><![CDATA[ 由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciyps2/r_iterative_reasoning_preference_optimization/</guid>
      <pubDate>Fri, 03 May 2024 03:20:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找用于工作的 AI/LLM 开发机器的硬件选项。对中小型模型进行训练和推理。硬件规格不详——详情请见帖子。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciwipe/d_looking_at_hardware_options_for_an_aillm/</link>
      <description><![CDATA[您好， 在工作中，我的任务是与我们的内部人员一起研究和开发一些关于使用法学硕士的东西房屋软件套件。由于政策原因，我无法详细说明，但最终会涉及一些 PII 识别/提取、一些文档摘要，可能还有一点 RAG 等。 在过去一两个月里，我已经使用非常小的模型做了一些初步的基础工作来表明某些事情“是可能的”，但我们希望将其提升到一个新的水平。 此时我一直在使用我的笔记本电脑的 GPU（只是移动 RTX 3060）和我老板的 RTX 4080 在 AMD Threadripper 机器上的组合。即使在一些较小的模型上，3060 也会很快崩溃，但 4080 的推理能力相当出色。但正如你想象的那样，我很快就耗尽了 VRAM，试图做一些更强大的事情。 我的部分任务是指定一些用于本地开发机器/桌面的硬件。我们已经订购了更多具有大量 VRAM 的生产级硬件（我认为它徘徊在 1 TB 的 VRAM 左右，但不是 100% 确定），以便在我们的数据中心使用，但这不会在 2019 年到达。至少几个月。 有了这个，我正在寻找一些关于开发工作站的建议。我无法得出是否应该运行多个 GPU 或购买内置更多 VRAM 的东西的结论。例如，我是否运行双 3090？我运行一个还是两个 A6000？或者一个？单个 RTX 6000 Ada (48GB) 就足够了吗？ 鉴于：  这仅用于开发，不适用于生产 我想推理中小型模型（可能最多 30b 个参数） 我可能想微调中小型模型，如果有的话作为比较点。即使使用 LoRA/QLoRA 微调也会在 Python 端完成，推理将使用 HuggingFace 的 candle Rust 库 使用一些东西我不鼓励基于云的开发（无法详细介绍），而且无论构建什么最终投入生产的软件都无法与任何外部 API 交互 我不介意使用量化模型开发，但在某些时候我想尝试全精度模型（这可能需要等待生产硬件的出现） 我会说钱不是一个因素，但如果可以的话预算最好在 15,000 美元以下  你们会推荐什么？ 谢谢！ &lt;!-- SC_ON - -&gt;  由   提交/u/IThrowShoes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciwipe/d_looking_at_hardware_options_for_an_aillm/</guid>
      <pubDate>Fri, 03 May 2024 01:26:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为博士生/研究员提高 MLOps 技能的良好策略/资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciryee/d_good_strategies_resources_to_improve_mlops/</link>
      <description><![CDATA[许多 ML 领域的研究人员/博士生最终都有加入该行业的前景（据统计，在美国，大约 80% 的 ML 博士都在该行业）最近发布的斯坦福大学人工智能指数）。 对于某人来说，有哪些好的技巧/资源可以确保他开发出更实用且更实用的技术？面向部署的 MLOps 技能？ 例如 - 设置集群、相关云服务（例如 AWS）、Docker、Kubernetes、开发用于模型训练/数据标签的内部工具......诸如此类。   由   提交/u/fliiiiiiip   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciryee/d_good_strategies_resources_to_improve_mlops/</guid>
      <pubDate>Thu, 02 May 2024 21:52:53 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 我应该去ICML发表论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</link>
      <description><![CDATA[我完成了博士学位。一年前。离开学术界，成为一家科技公司的数据科学家。我喜欢它，但仍在考虑将来以某种方式转向更多的研究职位。不过不确定。 无论如何，我的一个未完成的作品被一个朋友选中，完成并申请到 ICML。它被接受了（耶！）。 我现在想知道 - 除了我发现会议很有趣之外，参加会议还有实际好处吗？提交论文？我知道对于学术界/研究人员来说，这是一个很好的机会来了解人们并了解当前的研究。但由于我不再在那里，有真正的理由去吗？ 这是一个很奇怪的问题，但我只是不确定，我很高兴听到你的想法。  &gt;   由   提交 /u/meni_s   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</guid>
      <pubDate>Thu, 02 May 2024 21:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] Panza：个人电子邮件助理，经过培训并在设备上运行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciqvqw/p_panza_a_personal_email_assistant_trained_and/</link>
      <description><![CDATA[厌倦了精心制作精美的电子邮件，并希望有一个助手来接管繁重的工作，同时模仿您的写作风格？隆重推出 Panza，这是一款完全在您的设备上运行的个性化 LLM 电子邮件助手！在 Llama-3 或 Mistral 之间进行选择，根据您的独特风格进行定制，并让它为您编写电子邮件。看看我们的演示并在您的电子邮件中尝试一下：https://github.com/IST-DASLab/PanzaMail&lt; /a&gt; 有关 Panza 的一些技术细节：  Panza 是一款根据您的写作风格和过去的电子邮件历史记录定制的自动电子邮件助手。 Panza生成与您的写作风格相匹配的微调 LLM，并将其与检索增强生成 (RAG) 组件配对，帮助其生成相关电子邮件。 Panza **可以完全在本地进行训练和运行** 。目前，它需要具有 16-24 GiB 内存的单个 GPU，但我们还计划发布仅包含 CPU 的版本。 训练和执行也很快 - 对于大约 1000 封电子邮件的数据集，训练 Panza 需要不到一个小时，生成一封新电子邮件最多只需要几秒钟。    由   提交/u/eldar_ciki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciqvqw/p_panza_a_personal_email_assistant_trained_and/</guid>
      <pubDate>Thu, 02 May 2024 21:07:30 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]寻求帮助以找到更好的GPU设置。三台 H100 与五台 A100？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</link>
      <description><![CDATA[长话短说，一家公司有购买 GPU 的预算，预计用于微调 LLM（可能是 70B 的），我必须进行研究找出哪种 GPU 设置最适合他们的预算。 预算可以购买三个 H100 GPU 或五个 A100 GPU。  我已尽了最大努力，但直到现在我还不清楚这些设置中哪一个更好。虽然五台 A100 拥有更多 VRAM，但他们说 H100 比 A100 快 2-8 倍！ 我正在寻求帮助。任何有价值的见解将不胜感激。   由   提交/u/nlpbaz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</guid>
      <pubDate>Thu, 02 May 2024 19:49:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于 ICML、NeurIPS、CVPR 等顶级会议，我一直在思考的事情。有多少论文是真正具有开创性的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</link>
      <description><![CDATA[我自己在 top venus 上有一些论文，但每当我坐下来对自己非常诚实时，我觉得我的作品很好，但它并没有那么有影响力，就像墙上的一块砖。我想知道我们多久能看到像“注意力就是你所需要的一切”这样有影响力的东西。    提交人    /u/oddhvdfscuyg   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</guid>
      <pubDate>Thu, 02 May 2024 18:37:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基准创建者应分阶段发布其基准数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cilnzv/d_benchmark_creators_should_release_their/</link>
      <description><![CDATA[关于基准污染有很多讨论，其中模型根据最终评估的数据进行训练。例如，最近的论文表明，与 GSM1K 相比，模型在公共 GSM8K 上的表现要好得多，这是最近创建的基准在难度和其他指标上扩展 AI 以匹配 GSM8K。 由于对基准污染的担忧，通常很难从表面上理解研究实验室关于模型性能的说法。很难知道一个模型是否获得了良好的基准性能，是因为它总体上是有能力的，还是因为它的预训练数据被污染并且在基准上过度拟合。 解决这个问题的一个解决方案是让基准创建者发布他们的数据集分阶段进行。例如，基准创建者可以在发布时发布其数据集的 50%，然后分两个阶段发布剩余的 50%，一年后发布 25%，两年后发布 25%。这将使模型评估者能够通过比较训练截止之前发布的数据子集与训练截止之后发布的数据子集的性能来检查基准污染。它还可以让我们更好地了解模型的实际执行情况。 最后一点 - 这种分阶段发布过程对于通过抓取网络创建的基准没有任何帮助，即使是稍后发布的数据子集可以在训练数据中找到。但它对于其他类型的基准测试应该很有用。   由   提交/u/kei147  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cilnzv/d_benchmark_creators_should_release_their/</guid>
      <pubDate>Thu, 02 May 2024 17:36:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] spRAG - 用于具有挑战性的现实世界任务的开源 RAG 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cikkw2/p_sprag_opensource_rag_implementation_for/</link>
      <description><![CDATA[大家好，我是 Superpowered AI (YC S22) 的 Zach。我们在 RAG 领域工作了一年多，最近我们决定开源所有核心检索技术。 [spRAG](https://github.com/SuperpoweredAI/spRAG) 是一个检索系统，旨在处理对密集文本（如法律文件和财务报告）的复杂实际查询。据我们所知，对于此类任务，它可以产生所有 RAG 系统中最准确、最可靠的结果。例如，在 FinanceBench（一项特别具有挑战性的开放式金融问答基准）上，spRAG 的答题正确率为 83%，而 vanilla RAG 基线（使用 Chroma + OpenAI Ada 嵌入 + LangChain）的答题正确率为 19%。 您可以在项目的 README 中找到有关其工作原理和使用方法的更多信息。我们也非常欢迎大家做出贡献。我们尤其需要围绕集成（即添加对更多向量 DB、嵌入模型等的支持）和围绕评估的贡献。 很高兴回答任何问题！ [GitHub repo](https://github.com/SuperpoweredAI/spRAG)    提交人    /u/zmccormick7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cikkw2/p_sprag_opensource_rag_implementation_for/</guid>
      <pubDate>Thu, 02 May 2024 16:50:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大三学生（本科生或一二年级博士生）在ICML、ICLR、NeurIPS等主要机器学习会议上有这么多论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</link>
      <description><![CDATA[大家好，今天ICML成绩出来了，恭喜所有在这里接受论文的同学。我自己不是学者，但有时我会为了工作而阅读这些会议上的论文，这真的很有趣。我只是有一个问题：为什么这些会议上大三的论文这么多？我认为这是你在 5 年博士学位期间必须学习的东西，而且几乎只能在博士学位的最后几年才能实现。另外，我听说要进入美国顶尖的博士项目，你需要事先写一些论文。那么，如果一个大三学生能这么早发表论文，为什么还要花5年时间攻读博士学位呢？   由   提交 /u/ShiftStrange1701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</guid>
      <pubDate>Thu, 02 May 2024 11:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>