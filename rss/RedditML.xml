<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Fri, 19 Jul 2024 18:19:26 GMT</lastBuildDate>
    <item>
      <title>[D] 我应该购买带有 NVIDIA GPU 的 MacBook 或笔记本电脑用于机器学习和 AI 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7a306/d_should_i_get_a_macbook_or_a_laptop_with_an/</link>
      <description><![CDATA[我是工程学院的学生，目前使用配备 GTX 1650 GPU 的联想 Legion 笔记本电脑。但是，尽管我多次尝试解决，但还是遇到了 CUDA 无法在当前显卡上运行的问题。我计划下个月购买一台新笔记本电脑。我的大部分工作都涉及使用 TensorFlow，主要用于图像处理和其他机器学习任务。我还希望从事 ML 和 AI 方面的职业，旨在将来开发高级模型。 考虑到我的情况，我需要一台可以长期使用并有效处理我的 ML 和 AI 工作负载的笔记本电脑。此外，我想要一台便携式笔记本电脑，因为随身携带我目前的 Legion 笔记本电脑很有挑战性。我的首要任务是拥有一台可以最大程度地减少安装库和高效运行 TensorFlow 麻烦的机器。 您能否就我应该购买 MacBook 还是配备 NVIDIA GPU 的笔记本电脑提供建议？在 Mac 上使用 TensorFlow 可能存在哪些问题？从长远来看，哪种笔记本电脑最适合我？我很感激任何指导，请理解我仍在学习这些技术——这款联想 Legion 是我的第一台高性能笔记本电脑。    提交人    /u/ayushmanranjan   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7a306/d_should_i_get_a_macbook_or_a_laptop_with_an/</guid>
      <pubDate>Fri, 19 Jul 2024 17:59:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] 面对过时的 GitHub 存储库时该怎么办</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e79zj3/p_what_to_do_when_facing_outdated_github_repos/</link>
      <description><![CDATA[所以我想做一个项目，为此我想我会使用来自 github 的开源模型..这是一个场景文本检测问题，为此我决定使用 EAST 模型，它也是 paperswithcode 上用于场景文本检测的顶级模型，所以对我来说很有意义.. 现在我去了 github，所有的 repo 都是 6-7 年前的，使用的 python 版本已经过时，repo 中一个关键包不再可通过 pip 获得...我对那个库进行了混合搭配，但结果很糟糕，因为现在我在同一个项目中使用多个 python 版本，我不知道该如何处理.... 现在我在想我应该在最新的 python 版本中创建一个项目并复制粘贴所有代码并自己处理弃用的东西，这个想法听起来怎么样？这是解决此类问题的合法方法吗？请在这里指导我一下 https://github.com/argman/EAST - 这个人正在使用 tensorflow 模型并且 f2 分数较低，所以我只从这里挑选了 lanms https://github.com/SakuraRiven/LANMS - 这个人在 pytorch 中做到了并且获得了更高的 f2 分数，但是他使用的 lanms 对我来说不起作用    提交人    /u/Relevant-Ad9432   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e79zj3/p_what_to_do_when_facing_outdated_github_repos/</guid>
      <pubDate>Fri, 19 Jul 2024 17:55:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用检索增强生成模型回答可解释性和透明度问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e77yul/d_answer_explainability_and_transparency_with/</link>
      <description><![CDATA[大家好， 我一直在探索检索增强生成 (RAG) 系统的迷人世界，它们将大型语言模型与检索机制相结合以提供准确且上下文丰富的答案的能力确实令人印象深刻。但是，我一直在想这些模型生成的答案的可解释性和透明度。具体来说，我很好奇了解模型正在使用提供的上下文的哪些部分来生成答案。 尽管我付出了努力，但我还是无法找到有关此主题的大量相关研究、文章或公共用例。是不是只有我一个人，我没有使用适当的关键字进行谷歌搜索，还是真的缺乏该领域的研究？我认为了解模型如何得出答案至关重要，尤其是在信任和验证信息很重要的应用中。 我渴望听到您的想法和经验。如果您使用过 RAG 或类似模型，您如何确保答案是可解释且透明的？任何最佳实践或见解都将不胜感激。 期待您的回复！    提交人    /u/Nice_Elk_4537   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e77yul/d_answer_explainability_and_transparency_with/</guid>
      <pubDate>Fri, 19 Jul 2024 16:29:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习与网络安全</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e762eu/d_machine_learning_and_cybersecurity/</link>
      <description><![CDATA[好的伙计们，我很好奇，想做一些研究，但首先我想问一下我想做什么的可能性。我想问一下是否有办法可以构建和训练一个模型，该模型可以自行执行网络攻击并学习攻击特定系统的最佳方法，例如安装了 Metasploit 的 Raspberry Pie。我想在网络安全和人工智能的交叉领域进行研究生研究。我还没有找到学校或主题，但我正在集思广益，这是其中之一。所以我只是想知道它的可行性     提交人    /u/Wixi105   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e762eu/d_machine_learning_and_cybersecurity/</guid>
      <pubDate>Fri, 19 Jul 2024 15:10:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 讨论：建立和微调生产模型 - 观察和评估策略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e71nx6/d_discussion_building_and_finetuned_models_for/</link>
      <description><![CDATA[让我们讨论一下构建 RAG 和微调模型的一些生产方面。以下是一些观察和想法：  基于 RAG 的系统的长篇评估可能不可靠。有关更多信息，请参阅此 Cohere 博客文章：https://cohere.com/blog/evaluating-llm-outputs  使用 LLM 作为评判者是一种可行的选择，但其有效性取决于几个因素：   使用的提示 提供的少量示例 选择的特定模型 谁评估 LLM 输出（这仍然是一个悬而未决的问题）  我一直在考虑以下评估框架。请分享您对此是否有意义的见解： 我们需要从两个方面验证模型输出（针对 Rag 和 Fine-tuned 模型）： 1）事实准确性 2）可读性和连贯性等 建议的方法： 将现有问题转换为具有基本事实答案和解释的多项选择题 (MCQ)。 评估过程： 1）对于 MCQ，总有一个事实答案，简化评估。 2）在要求正确的 MCQ 答案时，也要求解释。这使我们能够使用 LLM 作为评判者来比较[模型解释、基本事实解释]，从而提供对其他指标的见解。 分享您的意见，您对这个框架有什么建议或改进吗？   由    /u/aadityaura  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e71nx6/d_discussion_building_and_finetuned_models_for/</guid>
      <pubDate>Fri, 19 Jul 2024 11:41:42 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 寻求见解，联邦辅助学习问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6zx85/research_asking_for_insights_federated_auxiliary/</link>
      <description><![CDATA[正如文中提到的，为特定客户端分别实现辅助任务，而主要任务在服务器级别（联邦学习场景中所有客户端都具有相同的 DL 模型）会很有趣吗？ 我认为所有辅助任务都将从不同的密切相关的数据集中学习，但所有任务（包括主要任务）基本上应该是相同的 - 回归任务：预测时间序列中的某个点-。 这有意义吗，我觉得我没有获得太多辅助学习，因为这感觉像是经典的 FL 范式。请提供见解？    提交人    /u/thekingos   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6zx85/research_asking_for_insights_federated_auxiliary/</guid>
      <pubDate>Fri, 19 Jul 2024 09:51:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] NER 印地语的最佳 LLM 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6zdbs/d_best_llm_model_for_ner_hindi/</link>
      <description><![CDATA[我试图将 NER 应用于印地语文章。我既没有好的模型，也没有在训练后获得更好的输出。因此尝试使用 LLM 来实现相同的目的。哪种仅限 CPU 的模型足以为印地语文本提供 NER？    提交人    /u/expiredUserAddress   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6zdbs/d_best_llm_model_for_ner_hindi/</guid>
      <pubDate>Fri, 19 Jul 2024 09:12:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练文本到音频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6yt1f/d_training_text_to_audio_models/</link>
      <description><![CDATA[有人知道为什么文本到音频模型主要通过扩散或流匹配进行训练吗？像 LLM 那样训练它有什么问题吗？你将音频标记为标记并自动回归训练它？    提交人    /u/Internal_War3919   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6yt1f/d_training_text_to_audio_models/</guid>
      <pubDate>Fri, 19 Jul 2024 08:31:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发布调查论文的场所</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6x7rr/d_venues_for_publishing_survey_papers/</link>
      <description><![CDATA[除了常见的 ACM Computing Surveys、TKDE、TPAMI 之外，我还应该考虑在哪些顶级会场发表调查论文。我正在考虑整理一份高质量但通常不与调查论文联系在一起的会场名单，比如 TMLR。    提交人    /u/SufficientAd3564   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6x7rr/d_venues_for_publishing_survey_papers/</guid>
      <pubDate>Fri, 19 Jul 2024 06:39:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] Redis 作为矢量数据库。有什么个人经历吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6rhjx/d_redis_as_vector_database_any_personal/</link>
      <description><![CDATA[我们正在重新审视我们的 AI 平台/堆栈，并试图找出存储嵌入和向量搜索的最佳选择。我们为金融服务领域的客户提供服务，宁愿不依赖初创公司的产品，而更愿意选择更成熟的供应商。我们正在考虑将 redis 作为一种选择。似乎 Redis 具有良好的性能（至少在更传统的数据库中是最好的）。我没有注意到 pinecone 和 Redis 之间的设置时间有很大差异。有人用过 Redis 作为向量数据库吗？你喜欢/不喜欢什么？只对个人经历感兴趣，而不是供应商的宣传    提交人    /u/Different-Use9841   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6rhjx/d_redis_as_vector_database_any_personal/</guid>
      <pubDate>Fri, 19 Jul 2024 01:11:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 API 文档缓解代码 LLM 幻觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6o2gi/r_on_mitigating_code_llm_hallucinations_with_api/</link>
      <description><![CDATA[      TL;DR：我们引入了一个新的基准 CloudAPIBench 来测量 API 幻觉，并使用Documenation Augmented Generation （DAG） 来优化此基准测试的性能。  我们引入了 CloudAPIBench，这是一个衡量 API 幻觉并为公共 API 提供基于频率的注释的基准。 我们的研究表明，诸如 GPT-4o 之类的代码 LLM 在处理低频 API 时遇到困难，仅实现了 38.58% 的有效调用，而使用 DAG 后，这一比例提高到了 47.94%。但是，当使用次优检索器时，DAG 会对高频 API 产生负面影响。 为了解决这个问题，我们建议根据 API 索引或置信度分数有选择地触发 DAG，从而将 GPT-4o 在 CloudAPIBench 上的整体 API 调用正确性提高 8.20%。  该论文还包括一些有趣的见解，例如 API 文档的哪些部分在 DAG 期间最有用以及如何执行选择性检索，例如，使用预测的 API 名称令牌的置信度分数。 CloudAPIBench 和论文的代码将很快发布！ Arxiv：链接； Twitter 帖子：链接 作为作者之一，如果您对我们的工作有任何问题或意见，我很乐意参与讨论。谢谢！ DAG 概述。 结果摘要。    提交人    /u/nihaljn   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6o2gi/r_on_mitigating_code_llm_hallucinations_with_api/</guid>
      <pubDate>Thu, 18 Jul 2024 22:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] ML 系统设计：450 个值得学习的案例研究（Airtable 数据库）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6gdsk/p_ml_system_design_450_case_studies_to_learn_from/</link>
      <description><![CDATA[大家好！想分享来自 100 多家公司的 450 个 ML 用例的数据库链接，这些用例详细介绍了 ML 和 LLM 系统设计。您可以按行业或 ML 用例进行筛选。 如果这里有人着手设计 ML 系统，我希望你会发现它很有用！ 数据库链接：https://www.evidentlyai.com/ml-system-design  免责声明：我是 Evidently 背后的团队成员，这是一个开源 ML 和 LLM 可观察性框架。我们整理了这个数据库。    提交人    /u/dmalyugina   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6gdsk/p_ml_system_design_450_case_studies_to_learn_from/</guid>
      <pubDate>Thu, 18 Jul 2024 17:01:17 GMT</pubDate>
    </item>
    <item>
      <title>[N] Fish Speech 1.3 更新：增强稳定性、情感和语音克隆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6g122/n_fish_speech_13_update_enhanced_stability/</link>
      <description><![CDATA[我们很高兴地宣布，Fish Speech 1.3 现在提供了增强的稳定性和情感，并且只需 10 秒 的音频提示即可克隆任何人的声音！作为开源社区的坚定倡导者，我们今天开源了 Fish Speech 1.2 SFT，并引入了自动重新排名系统。敬请期待，因为我们很快就会开源 Fish Speech 1.3！我们期待收到您的反馈。 Playground（DEMO）：http://fish.audio GitHub：fishaudio/fish-speech    提交人    /u/lengyue233   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6g122/n_fish_speech_13_update_enhanced_stability/</guid>
      <pubDate>Thu, 18 Jul 2024 16:46:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 训练 LLM 引用预训练数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6fxgj/r_training_llms_to_cite_the_pretraining_data/</link>
      <description><![CDATA[我们的工作被 COLM 接受，并认为值得在此分享： &quot;源感知训练实现语言模型中的知识归因&quot; TL;DR: 通常，LLM 在训练期间会学习很多东西，但不记得从哪里学到的。本文是关于教 LLM 从预训练数据中引用他们的知识来源。这可以使模型更透明、更容易理解和更可靠。我们提出了一个两步过程：1) 使用文档 ID 注入进行预训练和 2) 指令调整。第一阶段教模型将知识片段链接到特定的预训练文档。第二阶段教模型如何在生成答案时引用这些文档。 🔗 论文：https://arxiv.org/abs/2404.01019 代码：https://github.com/mukhal/intrinsic-source-citation    提交人    /u/moyle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6fxgj/r_training_llms_to_cite_the_pretraining_data/</guid>
      <pubDate>Thu, 18 Jul 2024 16:43:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>