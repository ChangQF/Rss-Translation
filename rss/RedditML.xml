<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sun, 21 Jul 2024 06:19:24 GMT</lastBuildDate>
    <item>
      <title>[D] 面向初学者的生成式人工智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8fbyp/d_generative_ai_for_beginners/</link>
      <description><![CDATA[本期播客讨论：1. 什么是生成式人工智能？2. 生成式人工智能和就业衰退 3. 什么是 Llama、Phi 等以及 LLM 命名法。4. 最适合使用的 LLM 5. 为什么每个人都应该使用生成式人工智能？6. 生成式人工智能是否像互联网热潮一样大？7. 即时工程是一个好的职业吗？8. ChatGPT 如何工作？ 9. 生成式 AI 的实际应用 10. 需要了解的重要生成式 AI 主题 11. 生成式 AI 的未来 https://youtu.be/LssX8MuMYgs?si=-TEO-ullHvY8PPiO    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8fbyp/d_generative_ai_for_beginners/</guid>
      <pubDate>Sun, 21 Jul 2024 05:46:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检索增强生成归因</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8e12u/d_attribution_for_retrieval_augmented_generation/</link>
      <description><![CDATA[在 RAG 期间，我一直在研究 LLM 的“引用来源”研究。例如，OpenAI 使用他们的 file_search 工具为 Assistants API 或 Bing Chat 实现此目的，其引用位于右上角。我想知道是否有任何关于黑盒技术的近期调查论文来实现这一点。我发现一个非常有前途的论文是 MIRAGE 论文（https://arxiv.org/abs/2406.13663），但它需要开放权重。可能是我没有使用正确的搜索术语，但似乎这个子领域已经停滞不前。    提交人    /u/Green_ninjas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8e12u/d_attribution_for_retrieval_augmented_generation/</guid>
      <pubDate>Sun, 21 Jul 2024 04:23:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你在生产中的 LLM Stack 是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8cxkf/d_what_is_your_llm_stack_in_production/</link>
      <description><![CDATA[好奇人们在生产堆栈中使用什么来开发 LLM 应用程序。这个问题是几个月前提出的，但该领域的事态变化如此之快，我认为值得再开一个帖子。 嵌入模型：目前是 OpenAI Ada，但召回率/准确率不是很好，所以我打算尝试其他模型 矢量数据库：Supabase（推荐） LLM：一直在尝试开源和闭源模型。我的任务需要相当强的推理能力，因此不幸的是本地模型还不够好（例如 Llama 70B）。OpenAI GPT-4o 表现最佳（不足为奇），但对于我的用例来说它确实很昂贵，所以我目前使用的是 Gemini Pro 1.5。 LLM 框架：无。大家的共识是远离 LangChain，所以我只是直接与 LLM 提供商集成。幸运的是，LLM 提供商似乎倾向于 OpenAI API 标准，这使得实验变得容易（除了偶尔定制的 API，如 Gemini） 评估：???。不太确定这个的最新技术是什么。 其他人都在用什么？    提交人    /u/Aggressive_Comb_158   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8cxkf/d_what_is_your_llm_stack_in_production/</guid>
      <pubDate>Sun, 21 Jul 2024 03:17:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 21 Jul 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D][P] BCI 项目的特征提取</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e89hhy/dp_feature_extraction_for_a_bci_project/</link>
      <description><![CDATA[我目前正在使用著名的 BCI IV 数据集进行运动意象的多类分类项目。尽管我付出了所有努力，但我还是无法达到 60% 以上的准确率。我尝试了各种方法，包括 CSP（OVO CSP、OVR CSP、FBCSP），但似乎都不起作用。 有没有人解决过类似的问题，或者对特征提取或其他可以帮助提高分类准确率的技术有什么建议？欢迎提出任何建议！ 提前致谢！    提交人    /u/Kind_Question_2378   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e89hhy/dp_feature_extraction_for_a_bci_project/</guid>
      <pubDate>Sun, 21 Jul 2024 00:09:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] Perpetual：无需超参数调整的梯度提升机</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e858j4/r_perpetual_a_gradient_boosting_machine_which/</link>
      <description><![CDATA[Repo：https://github.com/perpetual-ml/perpetual PerpetualBooster 是一种梯度提升机 (GBM) 算法，它没有需要调整的超参数，因此与其他 GBM 算法不同，您无需超参数优化包即可使用它。与 AutoML 库类似，它有一个 budget 参数。增加 budget 参数可提高算法的预测能力，并在看不见的数据上提供更好的结果。 下表总结了 California Housing 数据集（回归）的结果：   永久预算 LightGBM n_estimators 永久 mse LightGBM mse 永久 cpu 时间 LightGBM cpu 时间 加速    1.0 100 0.192 0.192 7.6 978 129x   1.5 300 0.188 0.188 21.8 3066 141x   2.1 1000 0.185 0.186 86.0 8720 101x   PerpetualBooster 使用泛化算法防止过度拟合。本文正在编写中，旨在解释该算法的工作原理。查看我们的博客文章，了解该算法的高级介绍。     提交人    /u/mutlu_simsek   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e858j4/r_perpetual_a_gradient_boosting_machine_which/</guid>
      <pubDate>Sat, 20 Jul 2024 20:47:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] VLLM 的 OCR 功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e84mt8/r_vllms_ocr_capabilities/</link>
      <description><![CDATA[嗨，我正在尝试研究多模态 LLM 的 OCR 或转录功能，以回答一个简单的问题，即这些模型是否可以取代工业文档上的纯 OCR 引擎，这是一件非常常见的事情。 是否已经对文档数据集进行了研究？ 可以使用哪种指标来有效地考虑阅读和阅读顺序？Rouge-L？    提交人    /u/EducationalSpread478   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e84mt8/r_vllms_ocr_capabilities/</guid>
      <pubDate>Sat, 20 Jul 2024 20:19:24 GMT</pubDate>
    </item>
    <item>
      <title>单目深度估计和 Depth Anything V2 详解！[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e82q0v/monocular_depth_estimation_and_depth_anything_v2/</link>
      <description><![CDATA[      分享我 YouTube 频道上的一段视频，讨论计算机视觉单目深度估计 (MDE) 的主要概念！    提交人    /u/AvvYaa   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e82q0v/monocular_depth_estimation_and_depth_anything_v2/</guid>
      <pubDate>Sat, 20 Jul 2024 18:52:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 科学的机器学习在实践中实际应用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7z4s0/d_is_scientific_machine_learning_actually_used_in/</link>
      <description><![CDATA[作为一个背景横跨科学计算和机器学习的人，我听到了很多关于科学机器学习 (SML) 的信息。它的承诺是，人们可以使用机器学习来加速、简化或以其他方式改进数值模型。一个常见的示例用例是，人们可以使用高保真数值模拟（运行速度可能非常慢）作为训练数据，然后在这些模拟上训练神经网络，以比运行实际模拟更快的速度预测数值模拟的结果（从而获得降阶模型）。这对于数字孪生等来说可能非常有用，您可能希望实时计算风力涡轮机的流体动力学，同时遵守控制流体方程并结合不断变化的风、温度等传感器数据，以预测事故、优化等。我只在学术环境中听说过这个和其他用例。  我的问题是，科学机器学习是否真的在实践（工业）中使用？有人能指出任何现实世界的例子吗？有没有公司真正使用这项技术？如果没有，我很想听听为什么它似乎没有为市场提供任何价值（至少目前如此）。在工业界采用这些方法的一些障碍/瓶颈是什么？或者科学机器学习只是两个原本有用的领域的人为配对，仅仅是为了满足学术好奇心和撰写拨款提案？    提交人    /u/worstthingsonline   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7z4s0/d_is_scientific_machine_learning_actually_used_in/</guid>
      <pubDate>Sat, 20 Jul 2024 16:09:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将生产嵌入到生产中？您是如何做到的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7xt6k/d_embedding_generation_in_production_how_are_you/</link>
      <description><![CDATA[对于那些构建生产 RAG 管道的人，您如何生成嵌入。我感兴趣的不是哪种模型，而是您如何部署它。您是否直接调用 openai/vertex API 端点？使用 langchain/llamaindex 包装器？使用 vectordb 类？还是其他方式？    提交人    /u/Different-Use9841   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7xt6k/d_embedding_generation_in_production_how_are_you/</guid>
      <pubDate>Sat, 20 Jul 2024 15:10:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 信心得分法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7vdk3/r_confidence_scores_llms/</link>
      <description><![CDATA[有没有关于如何测量 LLM 提取实体或分类等的置信度分数的好的研究？不相信询问 LLM 是估计它的好方法。如果 LLM 知道它的置信度水平，幻觉就不会存在。任何论文或想法都值得赞赏     提交人    /u/EducationalSpread478   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7vdk3/r_confidence_scores_llms/</guid>
      <pubDate>Sat, 20 Jul 2024 13:14:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分割指标的缩放分辨率或原始分辨率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7pvxi/d_scaled_or_original_resolution_for_segmentation/</link>
      <description><![CDATA[我目前正在进行一个细分研究项目。有人知道任何研究文章中报告的评估指标（骰子或IoU）是缩放后的分辨率（例如 224 X 224）还是原始分辨率吗？    提交人    /u/mugiwara_no_robin   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7pvxi/d_scaled_or_original_resolution_for_segmentation/</guid>
      <pubDate>Sat, 20 Jul 2024 07:15:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] AI 管道和共享存储的模块化和可组合性，而非微服务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7npbq/r_modularity_and_composability_with_ai_pipelines/</link>
      <description><![CDATA[        由    /u/jpdowlin 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7npbq/r_modularity_and_composability_with_ai_pipelines/</guid>
      <pubDate>Sat, 20 Jul 2024 04:53:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找 Rus Salakhutdinov 的搞笑视频，解释如何选择辍学率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7eydp/d_looking_for_a_funny_video_of_rus_salakhutdinov/</link>
      <description><![CDATA[我试图找到 Ruslan Salakhutdinov 的视频，其中描述了为什么应始终使用 0.5 的 dropout 参数。如果我没记错的话，他基本上是这么说的：“否则，您必须证明为什么选择该特定超参数，而您真的不想这样做。”我认为他在对一个班级讲话，引来了很多笑声。 希望这不会被视为低质量帖子。    提交人    /u/drewfurlong   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7eydp/d_looking_for_a_funny_video_of_rus_salakhutdinov/</guid>
      <pubDate>Fri, 19 Jul 2024 21:26:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 医学/医疗保健 AI 专家：临床法学硕士大多失败在哪里？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e7bwun/d_medicalhealthcare_ai_experts_where_do_clinical/</link>
      <description><![CDATA[我最近与一位同事就医学法学硕士进行了一场有趣的辩论。当我们讨论这些模型容易失败的地方时，我意识到一些令人担忧的事情：工程师和计算机科学专家似乎经常忽视在实践中实际使用这些法学硕士的医学专家和医疗保健专业人士的见解。这种脱节可能导致医学领域缺乏真正高质量的法学硕士。 这一认识让我更深入地思考医学/临床/医疗保健领域大型语言模型 (LLM) 的现状。想知道： 这些专业的 LLM 往往在哪些方面存在不足？ 如果您是医学专家、AI 开发人员或使用这些模型的人，我很乐意听听您的见解：  您是否注意到他们的失败中存在任何一致的模式？ 他们是否在特定任务上遇到困难，例如： 命名实体识别 (NER) 摘要 临床记录生成 其他领域？   真的很想听听您的专业意见和观察。特别是那些身处医疗/医疗保健领域的人们，他们可能会觉得您的意见经常被忽视。 提前感谢您分享您的知识！    提交人    /u/aadityaura   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e7bwun/d_medicalhealthcare_ai_experts_where_do_clinical/</guid>
      <pubDate>Fri, 19 Jul 2024 19:16:37 GMT</pubDate>
    </item>
    </channel>
</rss>