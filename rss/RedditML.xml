<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 13 Feb 2025 09:17:30 GMT</lastBuildDate>
    <item>
      <title>[D] 需要针对 2025 年图像分类问题的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iocgvg/d_need_suggestions_for_image_classification/</link>
      <description><![CDATA[早在 2022 年末，我就使用 EfficientNet_V2 训练了一个图像分类模型（医学图像，高分辨率），数据量约为 20k。现在我想重新训练模型，因为我可以访问大量数据（~300k）。我想征求一些建议。  我以前尝试过使用 ViT，但它的性能相对较差。我以前读过一些评论，说 ViT 在处理高分辨率图像方面存在一些问题。但现在我注意到 Nvidia 在 DLSS 上使用 Transformer。我认为高分辨率不再是 ViT 的问题。建议尝试哪种图像分类 ViT 模型？ 我一直使用预训练权重作为起点并进行微调，因为我读过的许多文章/在线信息都告诉我这样做，而且它确实表现更好。 2025 年还建议使用预训练权重吗？尤其是大多数图像模型都是在低分辨率数据（224-512）上训练的，而我的数据集是高分辨率的。 CNN 在 2025 年过时了吗？我认为 CNN 和 Transformer 在图像相关问题上的竞争在 2023 年还不明朗。但从 2024 年中期开始，我看到很多人说 Transformer 赢了。     提交人    /u/Eternal1314   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iocgvg/d_need_suggestions_for_image_classification/</guid>
      <pubDate>Thu, 13 Feb 2025 05:55:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 弱到强泛化中使用的 PGR 度量的探究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iocdb5/d_inquiry_on_pgr_metric_used_in_weak_to_strong/</link>
      <description><![CDATA[不确定这是否是合适的 subreddit，但我对 从弱到强的泛化 论文有一个问题。论文中的实验测量了 PGR，它比较了较强模型在针对较弱模型的标签进行训练后的相对性能与较弱模型在各种任务中的表现。  只衡量基础强模型的性能提升不是更合适吗？这是因为这篇论文试图将其类比为人类协调更强大的人工智能系统，因此更关心相对于人类的性能提升吗？    提交人    /u/nyesslord   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iocdb5/d_inquiry_on_pgr_metric_used_in_weak_to_strong/</guid>
      <pubDate>Thu, 13 Feb 2025 05:49:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为不规则时间序列数据创建因果 DAG</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1io7zrf/d_creating_a_causal_dag_for_irregular_timeseries/</link>
      <description><![CDATA[大家好， 我最近发表了一篇关于使用不规则时间序列数据进行因果推断的文章。我喜欢使用动态贝叶斯网络来做这件事的想法，因此我将问题改写为这个。 有人建议使用 SSM。据我所知，当它被离散化时，它可以表示为 DAG？然后我有一个结构来表示这些因果关系。 我最初偶然发现了这篇有趣的论文：https://arxiv.org/pdf/2312.09604，它似乎不适用于不规则的采样分辨率。 非常感谢！    提交人    /u/Sea_Farmer5942   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1io7zrf/d_creating_a_causal_dag_for_irregular_timeseries/</guid>
      <pubDate>Thu, 13 Feb 2025 01:47:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有没有关于如何将 CV 和 NetCDF 文件合并在一起的好书/教程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1io7lri/r_is_there_any_good_bookstutorials_on_combining/</link>
      <description><![CDATA[嗨，我必须做机器学习模型。在组合数据的过程中，我使用 CSV 文件做得很好，但是 NetCdf。我只是迷茫了，不知道从哪里开始学习将它们组合在一起。 任何建议都会有所帮助    提交人    /u/Necessary-Arm-6055   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1io7lri/r_is_there_any_good_bookstutorials_on_combining/</guid>
      <pubDate>Thu, 13 Feb 2025 01:27:43 GMT</pubDate>
    </item>
    <item>
      <title>[R]“o3 在 2024 年 IOI 上获得金牌，并获得与人类精英竞争对手相当的 Codeforces 评级”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1io4c7r/r_o3_achieves_a_gold_medal_at_the_2024_ioi_and/</link>
      <description><![CDATA[使用大型推理模型进行竞争性编程 OpenAI 我们表明，将强化学习应用于大型语言模型 (LLM) 可显著提高复杂编码和推理任务的性能。此外，我们将两个通用推理模型 - OpenAI o1 和 o3 的早期检查点 - 与领域特定系统 o1-ioi 进行了比较，后者使用专为参加 2024 年国际信息学奥林匹克 (IOI) 而设计的手工设计的推理策略。我们在 IOI 2024 上与 o1-ioi 进行了现场比赛，并使用手工制作的测试时间策略，排名在第 49 个百分位。在放宽竞争限制的情况下，o1-ioi 获得了金牌。然而，在评估 o3 等后期模型时，我们发现 o3 在没有手工制作领域特定策略或放宽限制的情况下获得了金牌。我们的研究结果表明，尽管 o1-ioi 等专用管道取得了显著的改进，但扩展的通用 o3 模型无需依赖手工制作的推理启发式方法即可超越这些结果。值得注意的是，o3 在 2024 年 IOI 上获得金牌，并获得与人类精英竞争对手相当的 Codeforces 评级。总体而言，这些结果表明，扩展通用强化学习，而不是依赖特定领域的技术，为在推理领域（例如竞争性编程）中实现最先进的 AI 提供了一条稳健的道路。 https://arxiv.org/abs/2502.06807    提交人    /u/we_are_mammals   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1io4c7r/r_o3_achieves_a_gold_medal_at_the_2024_ioi_and/</guid>
      <pubDate>Wed, 12 Feb 2025 22:55:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进行微调，用更简单的激活代替复杂的激活</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inyd67/d_finetuning_to_replace_complicated_activations/</link>
      <description><![CDATA[考虑以下问题。我想在不支持某些激活层的加速器硬件上运行预训练网络进行推理。是否有成熟的技术可以微调权重，以便它们可以与其他激活函数一起使用？ 假设网络是使用 SeLU 的 EfficientNet。我能否以某种方式微调权重以适应 ReLU 或 GeLU 激活？我不想从头开始重新训练。    提交人    /u/bjourne-ml   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inyd67/d_finetuning_to_replace_complicated_activations/</guid>
      <pubDate>Wed, 12 Feb 2025 18:47:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] TAID：时间自适应插值蒸馏，用于语言模型中的高效知识转移</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1invg9p/r_taid_temporally_adaptive_interpolated/</link>
      <description><![CDATA[    /u/hardmaru   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1invg9p/r_taid_temporally_adaptive_interpolated/</guid>
      <pubDate>Wed, 12 Feb 2025 16:51:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新论文：前沿模型能否以开放的方式自我探索并发现自己的能力？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inv1gy/r_new_paper_can_frontier_models_selfexplore_and/</link>
      <description><![CDATA[      标题：通过模型自我探索实现自动能力发现 作者： Cong Lu、Shengran Hu、Jeff Clune。 论文： https://arxiv.org/abs/2502.07577 摘要：基础模型已成为通用助手，通过对网络规模数据进行训练，在众多领域展现出多样化的能力。准确描述任何新模型的全部能力和潜在风险中的哪怕一小部分仍然具有挑战性。现有的评估方法通常需要大量的人力，而且需要付出越来越多的努力来为更强大的模型设计更艰巨的挑战。我们引入了自动能力发现 (ACD)，这是一个框架，它将一个基础模型指定为科学家，以系统地提出探索主题模型（可能是它本身）能力的开放式任务。通过将前沿模型与开放性领域的想法相结合，ACD 可以自动且系统地发现主题模型中令人惊讶的能力和失败。我们在一系列基础模型（包括 GPT、Claude 和 Llama 系列）中展示了 ACD，表明它会自动揭示任何单个团队都难以发现的数千种能力。我们通过广泛的人工调查进一步验证了我们方法的自动评分，观察到模型生成的评估和人工评估之间高度一致。通过利用基础模型创建任务和自我评估的能力，ACD 朝着可扩展、自动评估新型 AI 系统迈出了重要一步。 https://preview.redd.it/1zamtbjzjqie1.png?width=1204&amp;format=png&amp;auto=webp&amp;s=95c177136d8c77abd0b8fb4fda3d8d7f01b7a04f    提交人    /u/MolassesWeak2646   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inv1gy/r_new_paper_can_frontier_models_selfexplore_and/</guid>
      <pubDate>Wed, 12 Feb 2025 16:34:19 GMT</pubDate>
    </item>
    <item>
      <title>结构化数据解析[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ins93r/structured_data_parsing_d/</link>
      <description><![CDATA[我正在尝试构建一个管道，它可以解析非常复杂的表格结构，包括多行列标题和很可能的内联图像/文本等。我​​目前的方法是使用 LLM 清理表格结构并编写 pandas 代码来查询表格，我首先提取数据开始的行，然后将列合并为一行，并让 LLM 重命名它们并提供描述。发布后我要求它根据查询为我编写 pandas 代码，然后使用输出生成响应，目前我还在使用启发式/微调 SETbert 和很可能其他 ML 模型完成前两个步骤，发布后我将调用 LLM 编写 python 代码并生成响应，这对许多表格来说都没问题，但对于更复杂的管道来说就开始崩溃了。有人知道其他获得更好结果的方法吗，具体来说，你使用/微调了哪些模型来实现这个效果？谢谢    由   提交  /u/ashblue21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ins93r/structured_data_parsing_d/</guid>
      <pubDate>Wed, 12 Feb 2025 14:37:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不规则时间序列数据中的因果推断？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inpgkw/d_causal_inference_in_irregular_time_series_data/</link>
      <description><![CDATA[大家好， 我读过的很多方法都假设采样分辨率是固定的，这是有道理的。还有通过对数据进行分组来预处理数据的方法，但是你们有没有读过处理非固定采样分辨率的材料，因为因果效应确实发生在多个事件中。因果结构会是什么样子？ 这是我正在阅读的一篇论文，但我认为其中一个条件是定期采样间隔：https://arxiv.org/pdf/2312.09604 非常感谢    提交人    /u/Sea_Farmer5942   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inpgkw/d_causal_inference_in_irregular_time_series_data/</guid>
      <pubDate>Wed, 12 Feb 2025 12:17:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 作为多语言文本解毒的少样本数据注释器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1innuh3/r_llms_as_fewshot_data_annotators_for/</link>
      <description><![CDATA[本文介绍了一种使用 LLM 作为小样本学习器来生成高质量并行数据集进行文本解毒的方法。关键创新是使用现代 LLM 创建配对的有毒/无毒文本示例，在降低毒性的同时保持语义含义。 主要技术要点： - 使用精心策划的示例对进行小样本提示 - 实现多阶段过滤以确保质量 - 使用自动化指标验证语义保存 - 与现有方法相比，在保持含义的同时实现更好的毒性降低 - 创建比以前的方法更大、更高质量的并行数据集 结果： - 在标准基准上优于现有的解毒模型 - 显示出强大的跨领域泛化能力 - 仅用 3-5 个例子就证明了有效性 - 保持语义相似度得分 &gt;0.85 - 在测试集上将毒性得分降低 &gt;60% 我认为这对于需要在删除有害内容的同时保留含义的内容审核系统特别有价值。生成高质量并行数据的能力可以帮助训练更好的下游解毒模型。 我认为小样本方法特别有前景，因为它减少了对大型带注释数据集的需求，而手动创建这些数据集既昂贵又耗时。 TLDR：现代 LLM 可以使用小样本学习生成高质量的并行有毒/无毒文本对，从而为解毒系统提供更好的训练数据，同时保持语义含义。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1innuh3/r_llms_as_fewshot_data_annotators_for/</guid>
      <pubDate>Wed, 12 Feb 2025 10:17:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士可以自学如何更好地预测未来</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inks6r/r_llms_can_teach_themselves_to_better_predict_the/</link>
      <description><![CDATA[  由    /u/jsonathan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inks6r/r_llms_can_teach_themselves_to_better_predict_the/</guid>
      <pubDate>Wed, 12 Feb 2025 06:31:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] SSM 和线性注意力怎么了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1in9y30/d_what_happened_to_ssms_and_linear_attentions/</link>
      <description><![CDATA[了解该研究领域的人可以总结一下 SSM 和 softmax 注意力替代方案的当前状态吗？它们是否已用于以客户为中心的模型，还是仍在研究中？它们的承诺是否只出现在纸面上的基准测试中？或者硬件加速器是否已经蚀刻了注意力，以便它完全充满活力，而使用 SSM 或线性注意力替代方案只能提供边际收益，这对它们的复杂程度确实有吸引力？    提交人    /u/ApartmentEither4838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1in9y30/d_what_happened_to_ssms_and_linear_attentions/</guid>
      <pubDate>Tue, 11 Feb 2025 21:27:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>