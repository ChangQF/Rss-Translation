<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 28 Dec 2024 12:29:51 GMT</lastBuildDate>
    <item>
      <title>[D] 人类与人工智能书评：你更喜欢哪一种？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ho1i6q/d_human_vs_ai_book_reviews_which_do_you_prefer/</link>
      <description><![CDATA[所以我一直在想——人工智能在总结事物方面做得越来越好，比如亚马逊上那些由人工智能生成的图书评论摘要。它们简洁易读。 你呢？你喜欢亚马逊上的那些人工智能摘要吗？你相信它们吗，还是你仍然喜欢阅读完整的人工评论来决定阅读什么？你有没有见过一个人工智能评论或总结完全正确……或者完全没有抓住重点？很想听听你的看法。    提交人    /u/haoyuan8   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ho1i6q/d_human_vs_ai_book_reviews_which_do_you_prefer/</guid>
      <pubDate>Sat, 28 Dec 2024 08:29:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 让我们分享保持积极性和效率的秘诀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hno25c/r_lets_share_tips_to_stay_motivated_and_efficient/</link>
      <description><![CDATA[大家好， 我目前正在攻读博士学位，最近，我感觉唯一阻碍我前进的就是我自己。似乎只有在截止日期前的最后 1 或 2 个月，我才会真正投入工作。其余时间，我似乎无法保持动力或专注力。 有人经历过这种情况吗？或者有什么在整个过程中保持一致的技巧吗？我一直在考虑尝试冥想来帮助集中注意力和缓解压力，但我不确定这是否会有所不同。任何建议都将不胜感激！ 谢谢！    提交人    /u/Training-Adeptness57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hno25c/r_lets_share_tips_to_stay_motivated_and_efficient/</guid>
      <pubDate>Fri, 27 Dec 2024 20:26:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 并行性权衡：通过电路复杂性理解 Transformer 的表达能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hnnl6s/d_the_parallelism_tradeoff_understanding/</link>
      <description><![CDATA[演讲：https://www.youtube.com/watch?v=7GVesfXD6_Q 论文：https://aclanthology.org/2023.tacl-1.31/ TL;DR 作者 (Will Merrill) 从电路复杂性的角度看待变压器，并将其置于 TC0 复杂性类 - 恒定深度的阈值电路。这是一个相对受限制的复杂性类，无法解决许多固有的顺序问题。 他们的主要观点是，变压器的表达限制来自其并行性质，而不是其架构的细节。添加思路链允许 transformers 解决来自其他复杂度类别的问题，但代价是牺牲并行性和高效训练。 他们认为，并行和顺序计算之间的这种权衡是无法避免的，未来的架构应该在设计时考虑到这种权衡。他们还研究了状态空间模型的扩展，使权衡比 transformers+CoT 更有效。    提交人    /u/currentscurrents   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hnnl6s/d_the_parallelism_tradeoff_understanding/</guid>
      <pubDate>Fri, 27 Dec 2024 20:05:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我的自动编码变分贝叶斯（VAE）学习笔记</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hnj63a/r_my_learning_notes_for_autoencoding_variational/</link>
      <description><![CDATA[嗨， 我正在分享我在 VAE 论文 https://maitbayev.github.io/posts/auto-encoding-variational-bayes/ 上的学习笔记。它包含论文中公式的扩展证明。    提交人    /u/madiyar   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hnj63a/r_my_learning_notes_for_autoencoding_variational/</guid>
      <pubDate>Fri, 27 Dec 2024 16:53:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我收集了 100 多万条 App Store 和 Play Store 条目的数据集 – 有人感兴趣吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hnfswv/r_ive_collected_a_dataset_of_1m_app_store_and/</link>
      <description><![CDATA[大家好， 为了进行个人研究，我汇编了一个数据集，其中包含来自 App Store 和 Play Store 的超过一百万个条目。它包含有关应用程序的详细信息，我认为它可能对在应用程序开发、市场分析或技术趋势等相关领域工作的其他人有用。 如果这里有人有兴趣将其用于您自己的研究或项目，请告诉我！很高兴讨论细节。 干杯！    提交人    /u/26th_Official   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hnfswv/r_ive_collected_a_dataset_of_1m_app_store_and/</guid>
      <pubDate>Fri, 27 Dec 2024 14:17:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何解释 GLU“激活”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hnc7d9/d_how_do_you_interpret_glu_activations/</link>
      <description><![CDATA[我一直在问自己如何解释 GLU 和 GLU 变体，比如现代 Transformer 中常见的变体。 我可以看到 ReLU 激活的 2 层 MLP 既是非线性投影的线性投影（从一个向量空间到另一个向量空间的正锥，再到另一个向量空间），也是键集（隐藏神经元的权重）和值集（从隐藏到输出单元的权重），与注意力和联想记忆相比，这很好。 如何解释具有 GLU 变体的 GLU 和 FFN？我可以看到一个 3D 向量被投影到另一个 3D 向量（第一个线性变换）并被门控，即可能被投影到垂直于轴的平面上。但我很难看出原始向量如何确定中间向量和 S 形门的收缩/展平。门上的其他激活功能使其更加困难。 与经典的 2layerMLP 相比，2-3 个单元上的最小 GLU 可以实现哪些简单的逻辑函数或几何变换？    提交人    /u/Sad-Razzmatazz-5188   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hnc7d9/d_how_do_you_interpret_glu_activations/</guid>
      <pubDate>Fri, 27 Dec 2024 10:33:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] REINFORCE++：一种简单有效的大型语言模型对齐方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hna801/p_reinforce_a_simple_and_efficient_approach_for/</link>
      <description><![CDATA[RLHF（Reinforcement Learning from Human Feedback）正在快速发展，PPO、DPO、RLOO、ReMax、GRPO等算法相继涌现。 通过将近端策略优化 (PPO) 中的各种优化技术集成到传统的 REINFORCE 算法中，我们“提出”了 REINFORCE++，旨在提高 RLHF 中的性能和稳定性，同时在没有批评者网络的情况下减少计算资源需求。 REINFORCE++ 的主要特性是它比 GRPO 更稳定，比 PPO 更快。 REINFORCE++ 的技术细节如下： https://hijkzzz.notion.site/reinforce-plus-plus 和（技术报告） https://github.com/hijkzzz/Awesome-LLM-Strawberry/blob/main/resources/REINFORCE%2B%2B.pdf    由   提交  /u/seventh_day123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hna801/p_reinforce_a_simple_and_efficient_approach_for/</guid>
      <pubDate>Fri, 27 Dec 2024 08:05:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] 违反比例风险假设：我该怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmz1cs/p_violation_of_proportional_hazards_assumption/</link>
      <description><![CDATA[我正在开展一个项目，需要预测患者的造血细胞移植 (HCT) 后存活率。我有事件目标和事件发生时间目标。 事后看来，我的方法是使用生命线库 (Kaplan-Meier、Nelson-Aalen、CoxPH) 中的生存模型来估计风险评分，我将使用该评分作为 LightGBM 和 CatBoost 的回归目标。评估指标是分层一致性指数 (C 指数)。 使用 CoxPH 模型，我必须将所有分类特征转换为数字，因为 CoxPH 仅接受数值协变量 (特征)。但是，181 个协变量中至少有 40 个的 p 值小于 0.05 - 这违反了比例风险假设。 这是一个需要考虑的重要因素吗？我应该保留还是放弃针对 CoxPH 生存模型创建的目标进行训练的模型？违规行为是否会使生存模型“不可信”？    提交人    /u/TechNerd10191   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmz1cs/p_violation_of_proportional_hazards_assumption/</guid>
      <pubDate>Thu, 26 Dec 2024 21:51:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士 (LLM) 的机械可解释性中，有哪些常见的开放式问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmxxwf/d_what_are_some_popular_openended_problems_in/</link>
      <description><![CDATA[大家好，我对法学硕士及其研究非常熟悉。我对机械可解释性很感兴趣，并开始从事该领域的工作。作为机械可解释性的新手，我计划在该领域攻读博士学位，我应该开始探索该领域中哪些流行的开放式问题？很想听听这里的可解释性研究人员的见解。    提交人    /u/arinjay_11020   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmxxwf/d_what_are_some_popular_openended_problems_in/</guid>
      <pubDate>Thu, 26 Dec 2024 21:02:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过优化内存管理在单个消费者 GPU 上微调 175B 参数语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmpck4/r_finetuning_175b_parameter_language_models_on_a/</link>
      <description><![CDATA[这里的关键技术进步是通过巧妙的内存管理和 NVMe SSD 利用率在单个消费级 GPU 上实现 100B 参数模型的微调。研究人员开发了一个框架，可在保持训练质量的同时优化 GPU、CPU RAM 和存储之间的数据移动。 主要技术贡献：- 为消费级硬件实现修改后的 ZeRO-Infinity 优化- 具有动态参数卸载的三层内存层次结构- 可减少内存访问延迟的新型预取系统- 优化存储层之间的数据传输模式- 跨 GPU/CPU/NVMe 的内存带宽管理 主要结果：- 与现有的单 GPU 方法相比，速度提高了 2.6 倍- 所需 GPU 内存减少 70%- 成功微调 100B 参数模型- 与多 GPU 设置相当的训练质量- 在消费级硬件配置上进行了验证 我认为这可以让个人研究人员和小型实验室更容易进行大型模型微调。虽然它不会在生产场景中取代多 GPU 训练，但它可以快速进行原型设计和实验，而无需昂贵的硬件集群。这里的技术还可以为未来内存高效的训练方法提供参考。 权衡似乎是合理的——较慢的训练换来大幅降低成本。但是，我希望看到对不同模型架构和训练任务进行更广泛的测试，以充分验证该方法。 TLDR：新框架通过优化的内存管理和 NVMe 利用率，可以在单个消费者 GPU 上微调 100B 参数模型，与现有方法相比，速度提高了 2.6 倍。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmpck4/r_finetuning_175b_parameter_language_models_on_a/</guid>
      <pubDate>Thu, 26 Dec 2024 14:25:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] “激活工程”能否取代提示工程或微调作为操纵模型的技术？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmjdh3/d_could_activation_engineering_replace_prompt/</link>
      <description><![CDATA[如果您不知道，激活工程只是一个流行词，用于操纵 LLM 中的激活向量来控制其行为。一个著名的例子是“金门克劳德”，其中人类工程师上调了代表模型潜在空间中“金门大桥”概念的神经元。这样做之后，该模型开始将金门大桥编织到其所有响应中，甚至开始将自己识别为金门大桥。 目前，这种可解释性工作主要存在于文献中，但我很好奇您是否预计“激活工程”的真正工具会成为主流。您如何看待未来的转向模型？    提交者    /u/jsonathan   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmjdh3/d_could_activation_engineering_replace_prompt/</guid>
      <pubDate>Thu, 26 Dec 2024 07:22:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每个人都对 LLM 如此感兴趣，但 Transformer 架构能否用于改进更“传统”的机器学习领域</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmitcz/d_everyone_is_so_into_llms_but_can_the/</link>
      <description><![CDATA[我正在考虑诸如推荐算法之类的东西，这些算法依赖于无监督学习或许多其他无监督算法 我会更深入地研究它，但也许想对此有一些想法    提交人    /u/noithatweedisloud   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmitcz/d_everyone_is_so_into_llms_but_can_the/</guid>
      <pubDate>Thu, 26 Dec 2024 06:40:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 物理学和逻辑学的结合最近取得了什么进展？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmds2k/dhow_have_recent_advancements_with_incorporating/</link>
      <description><![CDATA[去年，关于这项技术将带来的承诺，曾有过大量讨论，但之后就没有什么进展了。    由    /u/sext-scientist  提交  [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmds2k/dhow_have_recent_advancements_with_incorporating/</guid>
      <pubDate>Thu, 26 Dec 2024 01:28:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>