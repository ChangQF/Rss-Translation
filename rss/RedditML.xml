<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 08 Mar 2024 00:56:22 GMT</lastBuildDate>
    <item>
      <title>[R] GaLore：通过梯度低秩投影进行内存高效的 LLM 训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b99cmm/r_galore_memoryefficient_llm_training_by_gradient/</link>
      <description><![CDATA[论文：[2403.03507] GaLore：内存高效的 LLM 培训梯度低阶投影 (arxiv.org) 代码库：GaLore (github.com) 训练大型语言模型 (LLM) 带来了巨大的内存挑战，主要是由于权重和优化器状态的大小不断增加。常见的内存减少方法，例如低秩适应（LoRA），将可训练的低秩矩阵添加到每层中冻结的预训练权重中，从而减少可训练的参数和优化器状态。然而，此类方法通常在预训练和微调阶段都表现不佳，因为它们将参数搜索限制在低秩子空间并改变了训练动态，而且可能需要全秩热启动。在这项工作中，我们提出了梯度低秩投影（GaLore），这是一种允许全参数学习的训练策略，但比 LoRA 等常见的低秩适应方法更节省内存。我们的方法在优化器状态下将内存使用量减少了高达 65.5%，同时保持了在 LLaMA 1B 和 7B 架构上使用最多 19.7B 令牌的 C4 数据集进行预训练的效率和性能，以及在 GLUE 任务上微调 RoBERTa 的效率和性能。与 BF16 基准相比，我们的 8 位 GaLore 进一步减少了优化器内存高达 82.5%，总训练内存减少了 63.3%。值得注意的是，我们首次证明了在具有 24GB 内存的消费级 GPU（例如 NVIDIA RTX 4090）上预训练 7B 模型的可行性，无需模型并行、检查点或卸载策略。 Pretty团队的出色工作！   由   提交/u/honestlylost18   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b99cmm/r_galore_memoryefficient_llm_training_by_gradient/</guid>
      <pubDate>Thu, 07 Mar 2024 23:57:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 适用于文档分割的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b97uzl/r_model_appropriate_for_document_segmentation/</link>
      <description><![CDATA[大家好！ 我对机器学习比较陌生，目前正在研究教育文档。 &lt; p&gt;我想提取文档上所有文本块的边界。 我尝试将它们转换为图像并在文本块上训练tensrerflow对象检测模型，并取得了相当不错的结果，但经常会感到困惑通过标题和其他布局减速带。 而且，在如此明确定义的矩形区域上使用对象检测感觉非常矫枉过正，但不知何故，我似乎无法为此目的找到正确的算法，但我敢打赌这是一个你们都眨眼了！ 所以也许你可以给我指出正确的方向！ 提前致谢:)   由   提交/u/mathi1651  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b97uzl/r_model_appropriate_for_document_segmentation/</guid>
      <pubDate>Thu, 07 Mar 2024 22:44:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 样本量估计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b94jgb/p_sample_size_esrimation/</link>
      <description><![CDATA[我计划对人类受试者进行一项研究，其中机器学习将用于预测患者根据一组医学测试结果所患的疾病是否有任何可靠的方法来估计 N 类分类问题所需的样本？我可以为此应用标准统计功效分析吗？   由   提交 /u/joseangl   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b94jgb/p_sample_size_esrimation/</guid>
      <pubDate>Thu, 07 Mar 2024 20:31:47 GMT</pubDate>
    </item>
    <item>
      <title>[D]机器学习研究人员如何看待可视化低代码/无代码机器学习工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b9318j/dwhat_do_ml_researchers_think_about_visual_lowno/</link>
      <description><![CDATA[我正在研究 ML 工具领域，并遇到了几种用于构建/可视化 LLM 的低代码工具，例如 cerbrec.com。我的背景比较偏向 swe，因此与 PyTorch 相比，我看不出这些工具的实用性，但我很想向在非技术团队工作的传统“非 swe”研究人员学习。    由   提交 /u/Bnjoroge   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b9318j/dwhat_do_ml_researchers_think_about_visual_lowno/</guid>
      <pubDate>Thu, 07 Mar 2024 19:31:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 商家欺诈风险评估的最佳模型？ （分类模型和图分析讨论）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b92iy9/d_best_model_for_fraud_risk_assessments_on/</link>
      <description><![CDATA[我想为商家建立一个风险评分系统。目前已有的缓解方案是：  通过规则引擎的命中次数（即连续海量交易、共享设备等）来判断该商户是否属于高风险. 根据监管合规列表（按业务类型、省份、细分市场、规模等）标记具有欺诈者常见属性的每家公司  但是，结果被认为过于幼稚，因为它仅针对由已知可疑的一般行为或交易定义的特定欺诈问题；因此，我想通过更深入的衡量将所有商户分为高、中、低风险，即  每个参数的权重计算（即a*rule_hit+ b*business_type+c*province+...) 商家之间的联合 商家和顾客之间的勾结  问题是我不知道没有标记数据来训练权重计算，所以我一直在考虑使用无监督学习来对这些商家进行聚类。什么样的模型适合解决这个问题？或者我应该使用规则引擎标记的所有商家作为监督数据（但这样就与简单使用规则引擎相同）？异常检测在这里有用吗？我正在争论是使用 K 最近邻将所有具有相似行为或属性的商家（无论它们是否被规则引擎标记）分组到集群中，还是使用隔离森林隔离异常（数据是否需要）是否属于异常值，是否会被认定为可疑？因为有可能存在一大批高风险商户？ 第二，如何判断是否是团伙和串通？到目前为止，我“我只对请求或报告的用户使用网络分析（Python 上的 NetworkX）来查看与他们相关的用户。我如何在更大规模（拥有数亿商家和用户）上实现这一点？这不会让介数中心性指数？我一直在阅读有关关系图卷积网络（RGCN）的内容，我想知道这是否是一个合适的解决方案。 或者是否还有另一个我忽略的更常见的解决方案或参数？任何建议、指导或阅读材料将不胜感激。谢谢！   由   提交 /u/DecentPerson011   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b92iy9/d_best_model_for_fraud_risk_assessments_on/</guid>
      <pubDate>Thu, 07 Mar 2024 18:58:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer 架构的校准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b92hxn/r_calibration_of_transformer_architectures/</link>
      <description><![CDATA[使 Transformer 在罕见/未观察到的序列上输出低可能性的最可靠方法是什么？换句话说，我训练我的变压器来模拟某种类型的序列。我希望，给定一个不分布的序列或一个非常罕见的序列，变压器会为其分配较低的可能性。 我想这大多数情况下都会发生，而无需对稀有序列进行任何额外的技术，但我担心分布之外的序列可能会引起麻烦。您是否知道分布外序列的似然估计方面的工作，以及更广泛的将预测似然与序列的实际似然对齐的工作？  &amp;# 32；由   提交 /u/fedetask   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b92hxn/r_calibration_of_transformer_architectures/</guid>
      <pubDate>Thu, 07 Mar 2024 18:56:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 可解释的人工智能研究已经失败了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8zifr/r_has_explainable_ai_research_tanked/</link>
      <description><![CDATA[我感觉整个 ML 社区已经以一种奇怪的方式对 XAI 失去了兴趣，或者只是变得极其愤世嫉俗。  在某种程度上，这仍然是所有机器学习领域需要解决的问题，但它与几年前的情况确实不同。现在人们不敢说XAI，而是说“可解释”、“值得信赖”、“监管”、“公平”、“人机交互”、“机械可解释性”等等。 . 我有兴趣了解人们对此的感受，因此我写这篇文章是为了就该主题进行对话。 您对 XAI 有何看法？你相信它有效吗？您认为它只是演变成几个更具体的不同研究领域吗？您是否认为这是一个无用的领域，没有兑现 7 年前的承诺？ 感谢您的意见和见解，谢谢。  &amp; #32；由   提交 /u/SkeeringReal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8zifr/r_has_explainable_ai_research_tanked/</guid>
      <pubDate>Thu, 07 Mar 2024 16:57:57 GMT</pubDate>
    </item>
    <item>
      <title>使用非结构化领域知识数据调整法学硕士 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8xcgq/adapting_llms_with_unstructured_domain_knowledge/</link>
      <description><![CDATA[我想针对理论领域知识对预训练的法学硕士进行微调。这些领域知识将以我清理过的书籍的 PDF 形式出现，因此有很多原始的非结构化文本。我希望模型能够采用这些文本的观点、知识和风格（例如培训我可以与之交谈的心理学家、建筑师或气候科学家）。 这是可行的吗？任务？不使用LLM可以将非结构化数据转化为提示/答案数据吗？这种技术叫什么？我可以在哪里了解有关如何执行此技术的更多信息？   由   提交 /u/TheRealestKGB   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8xcgq/adapting_llms_with_unstructured_domain_knowledge/</guid>
      <pubDate>Thu, 07 Mar 2024 15:25:06 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface 上的零计算 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8x3g8/zero_computing_on_huggingface_p/</link>
      <description><![CDATA[如何使用“零”选项电脑在高频？我从收集的信息中假设它是社区捐赠的计算，但在正常设置中没有选项吗？很抱歉在此 Reddit 子版块中发布此内容，但我不需要编码或任何方面的帮助。   由   提交 /u/asoulsghost   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8x3g8/zero_computing_on_huggingface_p/</guid>
      <pubDate>Thu, 07 Mar 2024 15:14:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] MAMBA 优于变形金刚吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8u2kq/d_is_mamba_superior_to_transformers/</link>
      <description><![CDATA[您好， 曼巴架构引起了很多争议。它真的有那么好，比变形金刚更好吗？如果是，为什么我们没有看到它像变形金刚推出时那样被广泛采用。   由   提交 /u/rodeowrong   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8u2kq/d_is_mamba_superior_to_transformers/</guid>
      <pubDate>Thu, 07 Mar 2024 13:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 尾巴的故事：模型崩溃作为缩放定律的变化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8s8rg/r_a_tale_of_tails_model_collapse_as_a_change_of/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.07043 摘要：  随着人工智能模型规模的增长，神经缩放法则&lt; /em&gt; 已成为在增加原始（人类或自然）训练数据的容量和大小时预测大型模型改进的重要工具。然而，流行模型的广泛使用意味着在线数据和文本的生态系统将共同进化，以逐步包含越来越多的合成数据。在本文中，我们问：在合成数据进入训练语料库的不可避免的情况下，缩放法则将如何变化？未来的模型是否仍然会改进，或者注定会退化到总 &lt; em&gt;（模型）崩溃？我们通过缩放定律的视角开发了模型崩溃的理论框架。我们发现了各种各样的衰变现象，分析了尺度损失、随代数变化的尺度变化、“不学习”现象等。技能，以及混合人类和合成数据时的摸索。我们的理论通过使用大型语言模型 Llama2 进行算术任务和文本生成的变压器的大规模实验得到了验证。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8s8rg/r_a_tale_of_tails_model_collapse_as_a_change_of/</guid>
      <pubDate>Thu, 07 Mar 2024 11:19:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 微软研究院推出 NaturalSpeech 3，这是零样本文本转语音技术的重大进步。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8pw7i/r_microsoft_research_unveils_naturalspeech_3_a/</link>
      <description><![CDATA[      论文链接：https://arxiv.org/abs/2403.03100 演示链接：https://speechresearch.github.io/naturalspeech3/&quot;&gt;https:// /speechresearch.github.io/naturalspeech3/ ​ 基于 NaturalSpeech 系列的成功，NaturalSpeech 3 不仅继承了高质量的合成功能而且还通过分解语音属性来进一步推进，从而实现更详细和受控的合成过程。 ​ NaturalSpeech 3 的主要亮点包括： 1.因子化编解码器：具有因子化矢量量化的神经编解码器能够熟练地将语音分解为不同的子空间，从而有针对性地改进语音生成。 2.因子化扩散模型：因子化扩散模型旨在生成语音属性与相应的提示完全一致。这种创新方法使 NaturalSpeech 3 不仅可以合成类似人类的语音，还可以调整韵律和音色的细微差别，以匹配说话者的情感和风格。 3. 可扩展性：可扩展至 10 亿个参数经过超过 20 万小时的数据训练，NaturalSpeech 3 在提高语音质量和清晰度方面显示出了可喜的成果。未来，NaturalSpeech 3 计划进一步扩大规模，以实现更精细的结果。 ​ 深入研究演示、阅读论文，了解 NaturalSpeech 3 的用途为零样本语音合成设定新标准。 https://preview.redd.it/gbgau8vwkvmc1.png?width=1982&amp;format=png&amp;auto=webp&amp;s=3260d6ac03b42e6059c5e0a58169d880b037 b00f ​   由   提交/u/Front-Article-7366   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8pw7i/r_microsoft_research_unveils_naturalspeech_3_a/</guid>
      <pubDate>Thu, 07 Mar 2024 08:47:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么最新、最伟大的法学硕士仍然为生成十个以 apple 结尾的句子这样的小事而苦苦挣扎？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8ohhy/d_why_do_the_latest_and_greatest_llms_still/</link>
      <description><![CDATA[所有 3 个模型（Gemini Advanced、Claude 3.0 Opus、GPT-4）都失败了，gpt-4 表现最好，十有八九以苹果结尾。    由   提交 /u/ccooddeerr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8ohhy/d_why_do_the_latest_and_greatest_llms_still/</guid>
      <pubDate>Thu, 07 Mar 2024 07:18:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] Apollo：轻量级多语言医学法学硕士，将医疗人工智能普及到 6B 人群</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8mml6/d_apollo_lightweight_multilingual_medical_llms/</link>
      <description><![CDATA[    &lt; /a&gt;  我们开源了一系列SOTA轻量级多语言医疗LLM Apollo (0.5B, 1.8B, 2B, 6B, 7B)，利用非翻译语料库取得最佳新表现 覆盖英文、中文、法语、西班牙语、阿拉伯语和印地语  整个过程开源且可复制 精简版模型可以是用于提高大型模型的多语言医疗能力无需以代理调整方式进行微调   github：https://github.com/FreedomIntelligence/Apollo 演示：https://apollo.llmzoo.com/#/ 论文：https ://arxiv.org/abs/2403.03640 模型：https://huggingface.co /FreedomIntelligence/Apollo-7B  https://preview.redd.it/29kjdct4oumc1.png?width=1488&amp;format=png&amp;auto=webp&amp;s=1a16bbbf2588fb071ba2af5a50668ca8335c 92b7 https://preview.redd.it/406m28t4oumc1.png?width=1120&amp; ;format=png&amp;auto=webp&amp;s=607664035b62aa0ee726d3f5b4c4730863823bcb https://preview.redd.it/jiewd5t4oumc1.png?width=1242&amp;format=png&amp;auto=webp&amp;s=e059d49da4e788729b134b0d64415bcf 85bb024c    由   提交 /u/Pasu06   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8mml6/d_apollo_lightweight_multilingual_medical_llms/</guid>
      <pubDate>Thu, 07 Mar 2024 05:33:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>