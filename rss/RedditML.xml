<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 17 Sep 2024 12:31:07 GMT</lastBuildDate>
    <item>
      <title>[N] Llama 3.1 70B，Llama 3.1 70B Instruct 压缩了 6.4 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fivdkg/n_llama_31_70b_llama_31_70b_instruct_compressed/</link>
      <description><![CDATA[我们最近对 Llama 3.1 70B 和 Llama 3.1 70B Instruct 模型的研究实现了 6.4 倍的压缩率，同时保留了大部分 MMLU 质量。如果您有 3090 GPU，您现在就可以在家运行压缩模型。  以下是结果和压缩模型： https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-AQLM-PV-2Bit-1x16 https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-Instruct-AQLM-PV-2Bit-1x16/tree/main   由    /u/_puhsu  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fivdkg/n_llama_31_70b_llama_31_70b_instruct_compressed/</guid>
      <pubDate>Tue, 17 Sep 2024 10:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 微调 Dinov2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fivbmh/p_finetune_dinov2/</link>
      <description><![CDATA[有人用过 dinov2 嵌入吗？我正在尝试为我的数据集生成可靠的嵌入，以进行图像相似性搜索。Dinov2 在 90 个案例中有 3 个不起作用。我的数据集是绘画图像。所以我想对它进行微调。有没有办法在不标记数据和不对其进行分类的情况下微调模型。我不需要分类器头，我只希望模型学习我的图像并给我更好的嵌入。这可能吗？我写了一个脚本，但它不起作用，所以我想知道我是否应该继续进行下去。    提交人    /u/PositiveResponse7678   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fivbmh/p_finetune_dinov2/</guid>
      <pubDate>Tue, 17 Sep 2024 10:11:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助我计算对非常长的上下文示例进行微调所需的内存</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fitqeu/d_help_me_calculate_memory_requirements_for/</link>
      <description><![CDATA[我有四个 L4 gpu（总共 96 GB vram）。我正在尝试使用 QLoRA（4 位量化，q 的等级 = 4，k 投影矩阵）微调 Llama 3.1 70b。该模型大约需要 40 GB 才能加载（每个 gpu 大约使用 10 GB）。我只有 10 个示例想要在语言建模任务上进行训练。但这些示例非常长（每个 40,000 个标记，因为 llama 3.1 支持 128k 上下文长度）。我遇到了内存不足错误。我认为这是因为示例上下文长度几乎是 40000 个标记，并且它无法在其他 gpu 上分配单个示例。请帮我计算一下我需要一个 gpu 上多少 vram。    提交人    /u/Elemental_Ray   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fitqeu/d_help_me_calculate_memory_requirements_for/</guid>
      <pubDate>Tue, 17 Sep 2024 08:27:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 好的图形数据库选项？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fit4px/d_good_graph_database_options/</link>
      <description><![CDATA[我正在尝试构建一个 graphRAG 并使用其图形数据库，到目前为止，所有内容都指向 neo4j。我们还有其他更好、更适合生产的选项吗？    提交人    /u/Aromatic_Ad9700   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fit4px/d_good_graph_database_options/</guid>
      <pubDate>Tue, 17 Sep 2024 07:46:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 LLM 进行场景、模拟和专业战争游戏创作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fis46d/p_scenario_simulation_and_professional_wargame/</link>
      <description><![CDATA[https://github.com/user1342/WargamesAI    由   提交  /u/OppositeMonday   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fis46d/p_scenario_simulation_and_professional_wargame/</guid>
      <pubDate>Tue, 17 Sep 2024 06:39:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您使用什么工具进行 AI/ML 开发、训练和推理？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fiqcxh/d_what_tools_do_you_use_for_aiml_development/</link>
      <description><![CDATA[我很好奇您在 AI/ML 工作流中使用的企业工具。无论是用于开发、训练、推理还是使用预构建模型，我都很想知道您每天依赖什么。  开发和训练：您喜欢哪些平台或服务来构建和训练模型？ 推理和部署：您使用哪些工具来大规模提供模型？ 预构建模型：您是否使用 Hugging Face 或 OpenAI 等平台来提供现成的模型？ 数据和实验跟踪：您推荐什么工具来管理数据集和跟踪实验？  期待您的见解！谢谢！    提交人    /u/Pretend-Lobster6455   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fiqcxh/d_what_tools_do_you_use_for_aiml_development/</guid>
      <pubDate>Tue, 17 Sep 2024 04:53:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 同时提交给 neurips 和 coling</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fiivv5/r_submitting_to_neurips_and_coling_at_the_same/</link>
      <description><![CDATA[我可以同时提交 neurips solar 和 coling 2025 吗？Coling 的政策是不提交期刊或会议，但 solar 是一个研讨会，它允许双重提交。    提交人    /u/Puzzleheaded_Soup809   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fiivv5/r_submitting_to_neurips_and_coling_at_the_same/</guid>
      <pubDate>Mon, 16 Sep 2024 23:03:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于微调 LLM 的数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fii851/d_dataset_for_finetuning_llm/</link>
      <description><![CDATA[嗨，我正在对预训练的 LLM 模型进行微调，以便根据我的问题生成答案。 对于微调数据集，我试图了解是否应该提供  针对完全相同的问题提供多种措辞的答案， 对问题的多种措辞提供多种措辞的答案，或者 单个问题和答案对。  哪种方法可能在训练期间产生更好的结果？ 谢谢！    提交人    /u/jamestan9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fii851/d_dataset_for_finetuning_llm/</guid>
      <pubDate>Mon, 16 Sep 2024 22:35:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于不同训练“技巧”的效果的良好研究，例如学习率调度程序（热身/衰减）、权重衰减、dropout、批量大小、动量等？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fihdrd/d_good_studies_on_the_effects_of_different/</link>
      <description><![CDATA[鉴于学习率调度程序（例如线性热身/余弦衰减）、正则化（权重衰减）、dropout、批量大小、动量项（Adam 中的 beta1、beta2）、批量规范等“技巧”的数量变得相当大，并且在这些大型模型上检查这些参数的所有不同组合变得越来越困难，是否有任何现有的研究或众包努力研究当我们改变这些技巧的各种参数时对最终性能（例如验证困惑度）的影响？ 我敢打赌其中很大一部分是在消融研究中，但它们有点太分散了。    提交人    /u/ThienPro123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fihdrd/d_good_studies_on_the_effects_of_different/</guid>
      <pubDate>Mon, 16 Sep 2024 22:01:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 扩展 - 推理 8B 和训练 405B 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fic61y/d_scaling_inferencing_8b_training_405b_models/</link>
      <description><![CDATA[感谢你们组成了这么棒的社区！ 我一直在尝试寻找指南来扩展更大模型的训练/推理设置，但在训练细节方面，我找不到任何不费解的东西。如果您能分享任何指南或帮助解答（或部分解答）我的问题，那将非常有帮助。我希望这能帮助其他希望扩展训练/推理设置的人。 设置：我有两个 24GB VRAM（7900XTX）和 128GB RAM/AMD 7900X，两个节点上各有一个，通过 Infiniband 连接。我正在试验 Llama 3.1 8B 模型（未量化）。 当前状态：当我将 8B 模型加载到 GPU 上时，我看到 16GB 已分配/16GB 已保留  使用 FSDP（FULL_SHARD）拆分模型仍然显示 8GB 已分配/16GB 已保留。 a) 为什么要保留完整的 16GB？是为了从其他分片传输层吗？ b) 有没有办法手动管理该保留？ c) FULL_SHARD 需要 100 倍的时间来处理相同的请求（可能是由于网络限制）。 5 个提示在没有分片的情况下花费了 30 秒，但使用 FULL_SHARD 和 40Gbps Infiniband 时花费了 3000 秒。 在不使用任何分布式技术的情况下，该模型占用了 16GB VRAM，添加“-max_seq_len 8000”会预分配/保留另外 6GB VRAM。但是，当我给它一个 7000 个令牌的提示时，它会抛出 CUDA OOM，即使在预分配之后也是如此。 a) 是因为预分配是为了“平均”提示长度估计而完成的吗？ b) 如何将此推理设置扩展到 24 GB 卡上的 CUDA OOM 限制之外（即使有人有 100 张 24GB 卡？）？所有查询都可以在“-max_seq_len 5000”下正常工作设置（如果提示较长，则只会显示令牌用完）。 c) 在半商业环境中，是否有人实现过超过 20K 个令牌？我看不出有人能达到 128K 个令牌。 如何推断更大的模型，例如 70B 模型？我认为需要 FSDP 类型的框架，但即使在 100Gbps 卡上也会非常慢。 更大的 405B 模型的训练设置是什么样的？ a) 即使我们使用 FSDP，考虑到 Grads 和 Optimizer States 所需的 VRAM 以及网络限制，我发现很难在任何合理的时间内处理数万亿个令牌，因为网络可能是 O(n^2) 约束，其中 n 是分片的层数。我感觉我错过了一些东西。 b) 即使网络不是问题，在加载碎片后，我们如何将 128K 代币放入卡中？例如，如果碎片本身就占用了 60-70% 的内存，我们如何为 10K 或 20K 代币（更不用说 128K 代币）腾出空间。在我看来，这最终会成为 H100 卡以及万亿参数模型（MoE 或非 MoE）的问题。  我正在通过添加 10 7900 XTX 设置来扩展我的设置，但我真的很想在继续购买之前弄清楚这些细节。谢谢！    提交人    /u/gulabbo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fic61y/d_scaling_inferencing_8b_training_405b_models/</guid>
      <pubDate>Mon, 16 Sep 2024 18:33:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] CPL：关键规划步骤学习提升 LLM 在推理任务中的泛化能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fi7ovt/r_cpl_critical_planning_step_learning_boosts_llm/</link>
      <description><![CDATA[      TL;DR 通过 MCTS 和每步优势偏好优化提高 LLM 的规划能力 论文： https://arxiv.org/pdf/2409.08642 摘要：  对大型语言模型 (LLM) 进行后训练以开发推理能力已被证明在数学推理和代码生成等不同领域都很有效。然而，现有方法主要侧重于改进特定任务的推理能力，但尚未充分解决模型在更广泛的推理任务中的泛化能力。为了应对这一挑战，我们引入了关键规划步骤学习 (CPL)，它利用蒙特卡洛树搜索 (MCTS) 探索多步骤推理任务中的不同规划步骤。基于长期结果，CPL 学习步骤级规划偏好，以提高模型的规划能力，从而提高其一般推理能力。此外，尽管现有的偏好学习方法（如直接偏好优化 (DPO)）在许多对齐 LLM 的场景中都很有效，但由于无法在每个步骤中捕捉细粒度的监督，因此在处理复杂的多步骤推理任务时会遇到困难。我们提出了步骤级优势偏好优化 (Step-APO)，它将通过 MCTS 获得的步骤级偏好对的优势估计集成到 DPO 中。这使模型能够更有效地学习关键的中间规划步骤，从而进一步提高其在推理任务中的泛化能力。实验结果表明，我们的方法专门针对 GSM8K 和 MATH 进行训练，不仅显著提高了 GSM8K (+10.5%) 和 MATH (+6.5%) 的性能，而且还增强了域外推理基准，例如 ARC-C (+4.0%)、BBH (+1.8%)、MMLU-STEM (+2.2%) 和 MMLU (+0.9%)。  视觉摘要： https://preview.redd.it/afih1qsaw6pd1.png?width=975&amp;format=png&amp;auto=webp&amp;s=bd0c3c4385897c581dff193a02267052481a0e68 性能： https://preview.redd.it/hehec8txw6pd1.png?width=1117&amp;format=png&amp;auto=webp&amp;s=a3d069590221c7acd509e1af83ea07a691f4e507 https://preview.redd.it/xgm1m55zw6pd1.png?width=1125&amp;format=png&amp;auto=webp&amp;s=566f067d6bff31605b04f0ec0edb79c35945f77f    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fi7ovt/r_cpl_critical_planning_step_learning_boosts_llm/</guid>
      <pubDate>Mon, 16 Sep 2024 15:35:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] 分解 PyTorch 函数帮助我了解其内部发生的事情</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhwwli/p_breaking_down_pytorch_functions_helped_me_with/</link>
      <description><![CDATA[大家好， 我以前很难理解 PyTorch 库内部发生了什么。分解内部工作原理对我来说一直是一个挑战，因此我对一些关键功能进行了简单的解释。 这里我重点关注：  loss.backward() torch.no_grad() requires_grad=True  我知道还有很多东西需要探索，稍后我会介绍其他功能。 也许你们中的一些人可以告诉我：  如果您有其他“黑匣子”功能，您会感到困惑 您是否理解了我的解释 对视频的任何反馈（我非常感谢正面和负面的反馈）  非常感谢！    提交人    /u/vtimevlessv   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhwwli/p_breaking_down_pytorch_functions_helped_me_with/</guid>
      <pubDate>Mon, 16 Sep 2024 05:13:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 论文、博客和项目的集合，重点关注 OpenAI o1 和推理技术。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhtkz5/r_a_collection_of_llm_papers_blogs_and_projects/</link>
      <description><![CDATA[        提交人    /u/Happysedits   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhtkz5/r_a_collection_of_llm_papers_blogs_and_projects/</guid>
      <pubDate>Mon, 16 Sep 2024 02:07:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>