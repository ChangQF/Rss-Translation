<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Thu, 11 Apr 2024 03:13:58 GMT</lastBuildDate>
    <item>
      <title>[D] 无法过度拟合 Transformer 解码器模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c14lu4/d_unable_to_overfit_transformer_decoder_model/</link>
      <description><![CDATA[我正在尝试从 x-transformer 库实现回归模型 链接 。为了开始工作，我尝试将模型过度拟合到单个序列，以查看模型在采样时是否会重复相同的事情。下面是代码 import torch from x_transformers import Decoder, XValTransformerWrapper, XValAutoregressiveWrapper model = XValTransformerWrapper( num_tokens=4, numeric_token_id=3, max_seq_len=1024, attn_layers=Decoder( dim=512, height= 12, Heads=8 ) ) model = XValAutoregressiveWrapper(model) 固定 ids 和 nums 以实现可预测性 ids = torch.tensor([[0, 1, 2, 3]]) nums = torch.ones((1, 4)) mask = torch.zeros(1, 4).bool() print(&quot;ids&quot;, ids) print(&quot;nums&quot;, nums) print(&quot;mask&quot;, mask) 优化器 = torch.optim.Adam(model. parameters(), lr=1e-4) for epoch in range(50): optimizationr.zero_grad() mask = torch.ones(1, 4).bool() loss = model(ids, nums, mask=mask) loss .backward() optimizationr.step() print(f&quot;Epoch {epoch+1}，损失：{loss.item()}&quot;) Epoch 48，损失：0.018317891284823418 Epoch 49，损失：0.018109597265720367 Epoch 50，损失：0.019419256 59775734 # 采样 start_ids = torch.tensor([[0]]) # 从可预测的 id 开始 start_nums = torch.randn(1, 1) # 从随机数开始 ids_out, nums_out, is_number_mask = model.generate(start_ids, start_nums, seq_len=17) print(ids_out.shape, nums_out.shape, is_number_mask.shape) print(&quot;离散 ids:&quot;, ids_out) print(&quot;连续 nums:&quot;, nums_out) print(&quot;是数字掩码: &quot;, is_number_mask) torch.Size([1, 17]) torch.Size([1, 17]) torch.Size([1, 17]) 离散 ID：tensor([[1, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2]]) 连续数字：tensor([[ nan, nan, 1.1422, 1.1724, 1.1511, nan, 1.1055, 1.1535 , 1.1308, 1.1237, 1.1168, 1.1118, 1.1018, 1.0970, 1.0980, 1.0920, nan]]) 是数字掩码：tensor([[False, False, True, True, True, False, True, True, True, True, True , True, True, True, True, True, False]])  我做了多少尝试，没有生成与我训练过的相同的输入，为什么会发生这种情况？ 我做错了什么吗？   由   提交 /u/specializedboy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c14lu4/d_unable_to_overfit_transformer_decoder_model/</guid>
      <pubDate>Thu, 11 Apr 2024 03:05:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对象识别的自回归模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c141qv/r_an_autoregression_model_for_object_recognition/</link>
      <description><![CDATA[      大家好！ 我想分享一下我们最近的 CVPR 工作，希望传播我们的想法并从社区收集见解。 [TL;DR] 我们的自回归模型仅根据输入图像预测标签，而无需预定义的查询库（例如，类似 CLIP 的模型）或预定义的类概念（例如，类似 VGG/ResNet 的模型）。该模型从整个文本空间（任何标签）中预测前 K 个标签，例如 top-100。 有关更多详细信息，请访问我们的论文和项目：&lt; a href=&quot;https://github.com/kaiyuyue/nxtp&quot;&gt;https://github.com/kaiyuyue/nxtp。 感谢您的想法和反馈。非常感谢！ -----图----- https://preview.redd.it/yloe861oirtc1.png?width=1124&amp;format=png&amp;auto=webp&amp;s=4ac24c952622f0f3aa 448aa0071843af0ecc3b9a&lt; /p&gt;   由   提交/u/pidoyu  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c141qv/r_an_autoregression_model_for_object_recognition/</guid>
      <pubDate>Thu, 11 Apr 2024 02:37:44 GMT</pubDate>
    </item>
    <item>
      <title>我如何让人工智能代理参与激烈的辩论 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c13q7j/how_i_made_ai_agents_engage_in_a_heated_debate_d/</link>
      <description><![CDATA[      在企业界，代理商应该辩论！  完整文章 ​ https://preview.redd.it/e50cth8yfrtc1.png?width=1171&amp;format=png&amp;auto=webp&amp;s=5a5515bb934fff1d742091b150b3644eb 2296cbf 什么是这篇文章是关于什么的？它探讨了如何创建一个系统，让人工智能代理能够参与结构化辩论，从多个角度剖析复杂的问题。文章强调，这种方法可以帮助企业对想法进行压力测试，识别隐藏风险，做出更全面的决策。  要点 激烈的辩论带来更好的决策：结构化的人工智能辩论暴露了潜在的偏见，阐明了不确定性，并可以带来更明智的决策。  人工智能可以像人类一样思考：通过观察人工智能代理构建论点并反驳相反的观点，人类决策者可以更深入地了解自己的思维过程。  一个简单的例子：本文包含一个实际的代码示例，演示了两个智能体人工智能的辩论，使这个概念变得具体。  你为什么应该阅读这篇文章？  人工智能爱好者：深入了解如何使用人工智能语言模型进行逻辑推理和辩论。  开发人员：寻找构建验证想法并发现潜在陷阱的系统的灵感。  产品经理：考虑如何使用辩论模型来对您的产品策略或市场分析进行压力测试。  关键技术 大型语言模型（LLM）：用于理解辩论主题并生成论点（文章可能使用 Ollama 的 Mistral） Metagpt、Ollama：工具管理人工智能模型并将其集成到辩论系统中 让我们设计吧！本文提供了用于设置人工智能辩论的基本代码结构。这包括：  ConveyThoughts Action：用于指导人工智能辩论响应的模板。  参与者类：代表每个辩论参与者并管理他们的行为。  辩论功能：协调整个辩论过程。  看到它的实际效果吗？  ​   由   提交 /u/AssistanceOk2217   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c13q7j/how_i_made_ai_agents_engage_in_a_heated_debate_d/</guid>
      <pubDate>Thu, 11 Apr 2024 02:22:02 GMT</pubDate>
    </item>
    <item>
      <title>如何平滑姿态预测模型 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c13lxe/how_do_i_smooth_out_pose_prediction_models_d/</link>
      <description><![CDATA[我正在尝试让舞蹈动作预测器发挥作用，但遇到一些障碍。另外，我对人工智能和机器学习非常陌生，这就是我需要帮助的原因。  Ice 获取的媒体管道姿势估计模型工作，将实时反馈输出到 3d 角色。 我现在有 5 个不同的舞蹈动作以及每个帧各自的关节位置。我想训练一个人工智能，以便我的 3D 角色可以首先检测正在发生的舞蹈，然后自行继续。 一些问题：我希望它不像一个简单的姿势检测算法，只播放一个动画片。因为每次跳舞时，双手的位置可能会略有不同，或者身体会扭曲。因此，它看起来非常自然，我想将该动画与传入的实时输入关节位置混合起来。 我认为做到这一点的几种方法是保持我的角色的旋转与实时输入相同并且简单一旦检测到就轻松进入动画。这样做的缺点是，如果我想添加更多动作，我需要大量的训练数据。另外可能看起来不自然 另一种方式（我不确定它是否有效）可能是一种奖励和惩罚模型，它通过将估计的关节位置与输入的关节位置进行比较来了解它是否处于正确的轨道上。这样做的好处是它会更加自然和流畅。缺点是我不知道如何训练这样的东西，更不用说使用同一模型进行多个动作了。 如果您能为我提供有关如何开始任何解决方案的技术建议，我也将不胜感激你确实给予了。 这将是一个很大的帮助，谢谢！！   由   提交/u/abdullahboy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c13lxe/how_do_i_smooth_out_pose_prediction_models_d/</guid>
      <pubDate>Thu, 11 Apr 2024 02:16:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与其他 ICLR 与会者取得联系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c12mab/d_getting_in_contact_with_other_iclr_attendees/</link>
      <description><![CDATA[是否有任何平台（即使是非官方的）与其他与会者交谈？我参加过的其他会议都有某种与其他人聊天的论坛，但 ICLR 似乎并非如此。我会很早就到达维也纳，所以我想知道其他人是否也会有兴趣探索这座城市。   由   提交/u/andrewdg7  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c12mab/d_getting_in_contact_with_other_iclr_attendees/</guid>
      <pubDate>Thu, 11 Apr 2024 01:29:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] Anterion – 开源人工智能软件工程师（SWE-agent 和 OpenDevin）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c10w6i/p_anterion_opensource_ai_software_engineer/</link>
      <description><![CDATA[您好！在 Anterion，我们一直致力于将 SWE-agent 和 OpenDevin 合并在一起，以探索 SWE-agent 开放式问题解决能力。很高兴与更广泛的社区分享我们的工作，并了解 SWE-bench 基准代理在一般编程用例中的工作效果！ 根据我们的经验，用于 SWE-agent 的护栏技术确实可以很好地转化为解决基本的现实世界任务，并可以在不久的将来集成到更全面的 Devin 风格的解决方案中。我们接下来想要采取的步骤是让社区参与该项目，并以 SOTA 代理方法为基础。 很高兴看到更多合作者加入我们！ YouTube： https://www.youtube.com/watch?v=J-KZNFVcAxU &lt; p&gt;GitHub：https://github.com/MiscellaneousStuff/anterion   由   提交/u/Holiday-Double1336  /u/Holiday-Double1336 reddit.com/r/MachineLearning/comments/1c10w6i/p_anterion_opensource_ai_software_engineer/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c10w6i/p_anterion_opensource_ai_software_engineer/</guid>
      <pubDate>Thu, 11 Apr 2024 00:08:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] NeurIPS '24 - 尚未进行实验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c10364/r_neurips_24_no_experiments_yet/</link>
      <description><![CDATA[我是一名正在进行研究的本科生（之前没有发表过文章）。我和我的顾问一直忙于其他工作，没有足够的时间来处理我们的项目。虽然我们已经编写了大部分代码，但我们还剩下一些部分，并且还没有开始运行任何实验（尽管我们知道前进的步骤并且有一个相对有组织的研究计划）。我们计划提交给 NeurIPS &#39;24；我们是否应该屈服并尝试向 ICLR 提交（九月截止日期）？接下来的几周值得全力以赴吗？    由   提交 /u/epsilon-delta-proof   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c10364/r_neurips_24_no_experiments_yet/</guid>
      <pubDate>Wed, 10 Apr 2024 23:32:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 单 GPU 上的数据高效多模态融合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0zfpx/r_dataefficient_multimodal_fusion_on_a_single_gpu/</link>
      <description><![CDATA[ 由   提交/u/gabloa  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0zfpx/r_dataefficient_multimodal_fusion_on_a_single_gpu/</guid>
      <pubDate>Wed, 10 Apr 2024 23:03:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] SWE bench：这次测试有公开的表现列表吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0xm8k/d_swe_bench_is_there_any_public_list_of/</link>
      <description><![CDATA[我看到Devin打破了SWE bench得分的记录，其次是SWE-agent（一个开源的Devin）。我看到Claude 2得到了5%左右。但是其他项目呢？ 检查此内容的来源是什么？ ​ 总的来说，您对测试有何看法？我见过有人说这些任务非常简单（对于人类来说），这当然并不意味着机器能够很好地处理它们。但无论如何，您是否认为它准确地代表了开发人员的需求工作吗？   由   提交/u/the_snow_princess  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0xm8k/d_swe_bench_is_there_any_public_list_of/</guid>
      <pubDate>Wed, 10 Apr 2024 21:48:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] ICML讨论期</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0w0ox/r_icml_discussion_period/</link>
      <description><![CDATA[我们从审阅者那里得到了 6,4,4。我们解决了审稿人的大部分评论，并粘贴了更新稿件的 PDF 链接。我们没有看到审稿人对反驳的任何认可。我想知道我什么时候才能知道——观点是否有任何变化，或者审稿人是否阅读了反驳。是明天区域评审员讨论结束的时候吗？   由   提交/u/leviaker  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0w0ox/r_icml_discussion_period/</guid>
      <pubDate>Wed, 10 Apr 2024 20:42:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您建议在哪些方面测试新的通用方法（架构/优化器）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0vh48/d_what_would_you_recommend_testing_new_general/</link>
      <description><![CDATA[到目前为止，我的很多工作都是关于优化器和架构的，但在发布研究结果时仅在小型标记预测语言任务上测试过它们。您需要看到什么才能确信一种新颖的通用方法确实更优越？非常感谢具体的数据集和模型大小以及相关基准。   由   提交 /u/LahmacunBear   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0vh48/d_what_would_you_recommend_testing_new_general/</guid>
      <pubDate>Wed, 10 Apr 2024 20:20:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 管道评估实用指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0ryvz/d_a_practical_guide_to_rag_pipeline_evaluation/</link>
      <description><![CDATA[检索增强生成（RAG）自发表以来已经取得了长足的进步 FAIR论文 于 2020 年首次引入这一概念。在过去的一年里，RAG 从被视为一种黑客手段，到现在成为向法学硕士提供相关最新信息的主要方法。此后，我们看到初创公司、企业、大型科技公司、顾问、矢量数据库提供商、模型构建者构建的基于 RAG 的 LLM 应用程序激增。 虽然它非常简单要启动一个普通的 RAG 演示，构建一个在生产中实际运行的管道绝非易事。OpenAI 在开发日上分享了其将金融服务的 RAG 性能从 45% 提高到 98% 的迭代之旅客户。尽管许多人急于得出 OpenAI 已经解决了所有人的问题的结论，但其内置的检索器（可通过 Assistant API 获得）很快就让社区感到失望。它再次证明，构建适用于每个用例的现成管道是很困难的。 来源：https://opendatascience.com/a-practical-guide-to-rag-pipeline-evaluation-part-1-retrieval/    由   提交/u/Data_Nerd1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0ryvz/d_a_practical_guide_to_rag_pipeline_evaluation/</guid>
      <pubDate>Wed, 10 Apr 2024 17:59:16 GMT</pubDate>
    </item>
    <item>
      <title>我需要多少个提示响应示例来进行微调？ [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0jmst/how_many_promptresponses_examples_do_i_need_for/</link>
      <description><![CDATA[大家好，我正在开发一个项目，其中有法学硕士（Command-r 和 Gemini）为我分析文档。 &lt;我首先在系统提示符中提供说明，在这些说明中，我提供了一种非常具体的格式，我需要法学硕士来提供分析，以便我可以将其解析到我的数据库中。虽然大多数时候 LLM 确实以正确的格式输出格式，但也有足够多的情况表明它不会导致问题。  我开始准备提示响应示例数据集，其中每个响应都采用正确的格式。但我想弄清楚的是，我需要多少个例子才能看到微调的积极结果？从我的在线研究中，我看到了 50-10,000 个答案。 以下是我在说明中提供的回复格式： 摘要 [摘要] 主题 1 优点  ^ [专业标题] ^ 影响分数：[分数] ：[原因] 持续时间得分：[得分]：[原因] 概率得分：[得分]：[原因] 重复最多 5 个专业人士  Subject1 缺点  ^ [Con Title] ^ 影响得分：[得分]：[原因] 持续时间得分：[得分]：[原因] 概率得分：[得分]：[原因]&lt; /li&gt; 重复最多 5 个缺点  （对每个主题重复优点和缺点部分）将方括号 [] 内的值替换为生成或接收的实际值.   由   提交/u/mband0  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0jmst/how_many_promptresponses_examples_do_i_need_for/</guid>
      <pubDate>Wed, 10 Apr 2024 11:49:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] DROID：大规模野外机器人操作数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0csix/r_droid_a_largescale_inthewild_robot_manipulation/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.12945 项目页面：https:// /droid-dataset.github.io/ 硬件代码： https://github.com/droid-dataset/droid 策略学习代码：https://github.com/droid-dataset/droid_policy_learning 数据集 Colab：https://github.com/droid-dataset/droid_policy_learning Research.google.com/drive/1b4PPH4XGht4Jve2xPKMCh-AXXAQziNQa?usp=sharing&quot;&gt;https://colab.research.google.com/drive/1b4PPH4XGht4Jve2xPKMCh-AXXAQziNQa?usp=sharing &lt;强&gt;摘要：  创建大型、多样化、高质量的机器人操纵数据集是迈向更强大、更强大的机器人操纵政策的重要基石。然而，创建此类数据集具有挑战性：在不同环境中收集机器人操作数据会带来后勤和安全挑战，并且需要在硬件和人力方面进行大量投资。因此，即使是当今最通用的机器人操纵策略，也大多是根据场景和任务多样性有限的少数环境中收集的数据进行训练的。在这项工作中，我们引入了DROID（分布式机器人交互数据集），这是一个多样化的机器人操作数据集，具有 76k 演示轨迹或 350 小时的交互数据，收集了 564 个场景和 84 个场景。北美、亚洲和欧洲的 50 名数据收集者在 12 个月内完成的任务。我们证明，使用 DROID 进行训练可以产生具有更高性能和更高泛化能力的策略。我们开源完整的数​​据集、策略学习代码和重现机器人硬件设置的详细指南。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0csix/r_droid_a_largescale_inthewild_robot_manipulation/</guid>
      <pubDate>Wed, 10 Apr 2024 04:21:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>