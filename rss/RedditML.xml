<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 06 Feb 2025 15:17:46 GMT</lastBuildDate>
    <item>
      <title>[D] DS 职业道路</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ij3fjh/d_ds_career_path/</link>
      <description><![CDATA[我作为数据科学家工作了 2 年。感觉自己被困在这里了。还没有建立任何真正的项目/模型。只是提交了一些随机的票据和任务。我应该如何准备进入顶级公司，在那里我可以学习和从事真正的工作。    提交人    /u/Acrobatic-Rope-452   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ij3fjh/d_ds_career_path/</guid>
      <pubDate>Thu, 06 Feb 2025 14:12:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为数学/编程领域以外的 LLM 推理创建奖励信号</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ij2dni/d_creating_reward_signals_for_llm_reasoning/</link>
      <description><![CDATA[我最近一直在学习推理模型，它们似乎面临的最大挑战是：虽然数学和编程对 RL 有明确的奖励信号，但其他领域（如创意写作）缺乏客观指标。研究人员似乎希望推理能力能够随着模型的扩展而转移，但这感觉不确定。 我很好奇我们如何为创造性任务开发奖励信号。我想我们需要一些人类品味/偏好的模型，尽管它们差异很大并且缺乏明确的依据。 有没有关于这个主题的相关研究？有什么我应该阅读的论文吗？    提交人    /u/heyhellousername   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ij2dni/d_creating_reward_signals_for_llm_reasoning/</guid>
      <pubDate>Thu, 06 Feb 2025 13:21:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 MLP 进行预测？？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ij106c/d_forecasting_with_mlp/</link>
      <description><![CDATA[据我所知，MLP 没有长期记忆，因为它们缺乏保留机制。但是，我看到 Jason Brownlee 的评论说，&quot;是的，您可以使用 MLP、CNN 和 LSTM。它需要首先使用滑动窗口将数据转换为监督学习问题&quot; (来源)。我的目标是构建具有短期记忆的链接质量模型。我已经实现了 GRU、LSTM、BiLSTM。考虑将 MLP 与此列表一起添加。你对此有什么看法？    提交人    /u/dumbestindumb   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ij106c/d_forecasting_with_mlp/</guid>
      <pubDate>Thu, 06 Feb 2025 12:06:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] DeepRAG：用于逐步检索增强推理的马尔可夫决策过程框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iiyobh/r_deeprag_a_markov_decision_process_framework_for/</link>
      <description><![CDATA[DeepRAG 通过在检索之前和检索过程中实现逐步推理过程，引入了一种新颖的检索增强生成方法。该模型不是立即搜索信息，而是首先将复杂的查询分解为推理步骤，然后针对每个步骤执行有针对性的检索。 关键技术点： * 引入“检索前思考”将推理与检索分开的架构 * 使用中间推理步骤来指导精确的文档检索 * 根据推理上下文实现动态检索策略 * 采用专门的提示来维护结构化的推理模式 论文结果：* 与标准 RAG 相比，复杂推理基准测试提高了 8.5% * 降低了事实验证任务的幻觉率 * 在多跳推理问题上表现更佳 * 与单次方法相比，文档检索更精确 我认为这种方法可以为需要仔细验证和复杂推理的领域带来更可靠的 AI 系统。虽然分步方法在计算上更为密集，但它为审核和改进模型决策提供了清晰的途径。这对于准确性至关重要的医疗保健和科学研究中的应用尤其有价值。 我认为主要的权衡是在提高准确性和增加计算开销之间。与传统的 RAG 系统相比，多步骤方法自然需要更多的处理时间。组织需要仔细评估准确性优势是否值得为其特定用例增加计算成本。 TLDR：DeepRAG 通过首先思考推理步骤，然后针对每个步骤执行有针对性的检索来改进 RAG。在复杂任务上显示出更好的准确性，但需要比标准方法更多的计算。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iiyobh/r_deeprag_a_markov_decision_process_framework_for/</guid>
      <pubDate>Thu, 06 Feb 2025 09:26:52 GMT</pubDate>
    </item>
    <item>
      <title>G[R]PO VRAM 要求（针对 GPU 较差的用户）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iiwwcc/grpo_vram_requirements_for_the_gpu_poor/</link>
      <description><![CDATA[      大家好，周末我花了一些时间深入研究 GRPO，并启动了一系列微调实验。当我看到 trl 库中已经有一个易于使用的 GRPO 实现时，我就开始行动了。我拿出了配备 16GB VRAM 的 Nvidia GeForce RTX 3080 笔记本电脑，并迅速开始训练。总的来说，我对它使用您提供的奖励函数塑造 smol 模型的能力印象深刻。但我最大的收获是，在不同的配置下您需要多少 VRAM。所以我在云端启动了一个 H100，并制作了一个表格，以帮助未来的微调人员避免 OOM 错误的痛苦。希望你喜欢！ 完整详细信息：https://www.oxen.ai/blog/grpo-vram-requirements-for-the-gpu-poor 只需向我展示用法： 以上所有运行均在 H100 上完成，因此此处的 OOM 意味着 &gt; 80GB。顶行是参数计数。 https://preview.redd.it/4hjjzrf5xghe1.png?width=6304&amp;format=png&amp;auto=webp&amp;s=46397d3e2bbdae61845a88afa96f0dce9e981047    提交人    /u/FallMindless3563   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iiwwcc/grpo_vram_requirements_for_the_gpu_poor/</guid>
      <pubDate>Thu, 06 Feb 2025 07:12:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一致性模型：为什么模型不会崩溃？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iiqat3/d_consistency_models_why_doesnt_the_model_collapse/</link>
      <description><![CDATA[我一直在阅读一致性模型论文，它已经不是什么新鲜事了，我有几个问题。 如果不深入研究公式的细节，我对损失目标背后的直觉很好奇。更具体地说，为什么当使用一致性蒸馏和一致性训练损失时，模型不会崩溃？ 在我看来，无论输入是什么，模型都很容易崩溃并开始估计所有零输出，这将始终导致零损失值。 我也不明白目标背后的直觉。 任何见解都会对我有帮助，谢谢！ https://preview.redd.it/wa8qkxeo3fhe1.png?width=1138&amp;format=png&amp;auto=webp&amp;s=23f4e8e44ea095​​53b35ae0976c074fff057f314a https://preview.redd.it/3bpptxeo3fhe1.png?width=1140&amp;format=png&amp;auto=webp&amp;s=fd136fa42df794cc08e0db290ffc65d005f200e9    提交人    /u/batchfy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iiqat3/d_consistency_models_why_doesnt_the_model_collapse/</guid>
      <pubDate>Thu, 06 Feb 2025 01:04:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 针对 VQA 和 OCR 任务训练/微调 VLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iiq610/ptrain_finetuning_vlm_for_vqa_and_ocr_tasks/</link>
      <description><![CDATA[大家好，我正在寻找 vlm 来在我的自定义数据集上对 ocr 和 vqa 任务进行微调。有没有可用的教程和文档供我使用？    提交人    /u/LahmeriMohamed   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iiq610/ptrain_finetuning_vlm_for_vqa_and_ocr_tasks/</guid>
      <pubDate>Thu, 06 Feb 2025 00:58:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 谐波损失训练可解释的 AI 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iioy2i/r_harmonic_loss_trains_interpretable_ai_models/</link>
      <description><![CDATA[免责声明：不是我的作品！Arxiv 版本链接：https://arxiv.org/abs/2502.01628 交叉熵损失利用内积作为相似度度量，而谐波损失使用欧几里得距离。 作者证明，这种替代方法有助于模型在训练期间更快地缩小训练测试差距。 他们还展示了其他好处，例如驱动权重以反映类别分布，使其可解释。    提交人    /u/fliiiiiiip   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iioy2i/r_harmonic_loss_trains_interpretable_ai_models/</guid>
      <pubDate>Thu, 06 Feb 2025 00:00:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] TTS 和 STT 是如何发展的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iilq85/d_how_are_tts_and_stt_evolving/</link>
      <description><![CDATA[有没有比以下更新 / 更好的东西： TTS：- coqui - piper - tortoise STT：- whisper - deepspeech 为什么 LLM 发展如此迅速，而这些领域却停滞不前？ 别误会我的意思，所有这些项目所做的事情都非常出色，只是下一代可能会更加不可思议    提交人    /u/HansSepp   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iilq85/d_how_are_tts_and_stt_evolving/</guid>
      <pubDate>Wed, 05 Feb 2025 21:41:33 GMT</pubDate>
    </item>
    <item>
      <title>[N] Deepseek 如何训练他们的 R1 模型，以及当今前沿 LLM 是如何训练的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iii013/n_how_deepseek_trained_their_r1_models_and_how/</link>
      <description><![CDATA[https://www.youtube.com/watch?v=aAfanTeRn84 Lex Friedman 最近发布了一篇名为“DeepSeek 的 GPU 优化技巧”的采访。这是一篇很棒的幕后花絮，展示了 Deepseek 在没有像美国同行那样多的 GPU 的情况下如何训练他们的最新模型。 需要是发明之母，Deepseek 做了几件事-  他们的专家混合配置非常创新，他们拥有非常高的稀疏因子，8/256 位专家激活。这比其他模型高得多，其他模型中 8 位专家中有​​ 2 位激活。  训练这个模型可能很难，因为只有少数专家真正学习并激活任务，这使得模型很弱。他们引入了辅助损失，以确保所有专家都用于所有任务，从而形成强大的模型。 混合专家模型的一个挑战是，如果只有少数专家激活，那么只有少数 GPU 可能会计算过载，而其余 GPU 则处于闲置状态。辅助损失也可以防止这种情况发生。 他们走得更远，实现了他们自己的 Nvidia NCCL 通信库版本，并使用更接近汇编级 PTX 指令来管理 GPU 中的 SM 如何为每个操作进行调度。这种低级优化使他们的模型在有限的硬件上具有非常高的性能。  他们还讨论了研究人员如何使用新的模型架构和数据工程步骤进行实验。他们说，在训练过程中，损失曲线会出现一些峰值，很难确切知道原因。有时训练后问题会消失，但有时 ML 工程师必须从较早的检查点重新开始训练。 他们还提到了 YOLO 运行，研究人员投入所有可用的硬件和预算来尝试获得前沿模型。他们可能会得到一个非常好的模型，也可能会在这个过程中浪费数亿美元。 这次采访实际上是对当今训练前沿 LLM 的幕后情况的一次非常好的深入观察。我很喜欢，我建议你也去看看！    提交人    /u/ml_guy1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iii013/n_how_deepseek_trained_their_r1_models_and_how/</guid>
      <pubDate>Wed, 05 Feb 2025 19:09:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 虚幻的安全：Redteaming DeepSeek R1 和 OpenAI、Anthropic 和 Google 最强大的可微调模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iif6qk/r_illusory_safety_redteaming_deepseek_r1_and_the/</link>
      <description><![CDATA[安全护栏是虚幻的。DeepSeek R1 的高级推理可以转化为“邪恶双胞胎”：同样强大，但安全护栏被剥离。GPT-4o、Gemini 1.5 和 Claude 3 也是如此。我们如何确保 AI 最大化利益同时最小化伤害？ 我们通过越狱调整来移除护栏：对带有有害响应的越狱提示进行微调。最初，开源和专有模型都会拒绝几乎所有有害请求。越狱调整后，它们几乎可以帮助解决所有问题：恐怖主义、欺诈、网络攻击等。 经过微调的模型会主动对之前拒绝的危险查询生成详细、精确且可操作的响应。 与基于微调的攻击相比，越狱提示可能不一致且产生质量较差的响应。 薄弱的安全护栏会给人一种虚假的安全感。对保障措施的过度自信可能意味着威胁不受控制——直到为时已晚。 我们该如何解决这个问题？ 😈 邪恶双胞胎评估 - 测试假设最坏情况滥用的预缓解模型。 🚧 红线 - 设定清晰、现实的伤害阈值 &amp;不要越过它们。 🚫 非微调人工智能 - 允许隐私和边缘设备等开放式优势，同时阻止有害的微调。 这不仅仅是一个企业或国家的问题。这是一个共同的挑战。 将人工智能视为一场竞赛——公司与公司、国家与国家、开放与封闭——将每个人都置于危险之中。如果我们想要安全的人工智能，全球合作，而不是竞争，是唯一的出路。 我们必须超越安全的幻想。我们关于越狱调整漏洞和人工智能安全漏洞的新研究将很快全面发布。同时，请查看我们的研究预览： 🔗 http://far.ai/post/2025-02-r1-redteaming/     提交人    /u/KellinPelrine   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iif6qk/r_illusory_safety_redteaming_deepseek_r1_and_the/</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer-Squared：自适应 LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iicsz0/r_transformersquared_selfadaptive_llms/</link>
      <description><![CDATA[      Sakana AI 的一个框架，允许 LLM 在推理时调整部分权重。 论文 | GitHub | 博客摘要 https://preview.redd.it/61pd7me6jche1.png?width=915&amp;format=png&amp;auto=webp&amp;s=b223fcb9369dc461c0b933669b1026f5eb46d351 摘要：  “自适应大型语言模型 (LLM) 旨在解决传统微调方法通常需要大量计算，并且在处理各种任务的能力上是静态的。我们引入了 Transformer-Squared，这是一种新颖的自适应框架，它通过选择性地调整权重矩阵的奇异分量，实时调整 LLM 以适应看不见的任务。在推理过程中，Transformer-Squared 采用两遍机制：首先，调度系统识别任务属性，然后使用强化学习训练的任务特定“专家”向量进行动态混合，以获得针对传入提示的目标行为。我们的方法始终优于 LoRA 等普遍使用的方法，具有更少的参数和更高的效率。此外，Transformer-Squared 展示了跨不同 LLM 架构和模态的多功能性，包括视觉语言任务。 Transformer-Squared 代表着一次重大的飞跃，它提供了一种可扩展、高效的解决方案，可增强 LLM 的适应性和特定任务性能，为真正动态、自组织的 AI 系统铺平了道路。&quot;  https://preview.redd.it/w5tey3kebche1.png?width=907&amp;format=png&amp;auto=webp&amp;s=15550138bac56f881d8981d5e45022c4cbf6c278 https://preview.redd.it/nb3rdwagbche1.png?width=962&amp;format=png&amp;auto=webp&amp;s=df98f74dea04365eefba9bf4004ba1c3c50a3359 结论：  在本文中，我们引入了 Transformer2，为实现自适应 LLM 提供了新颖的蓝图。在这个框架内，我们首先提出了 SVF，它比以前的微调方法性能更出色，同时成本更低、组合性更强、正则化过拟合——这些都是实现可扩展自适应的关键特性。利用一组 SVF 专家作为构建块，我们开发了三种有效的自适应策略，每种策略都具有独特的优势，并且随着测试时间条件的增加，性能优势也变得单调。 虽然 Transformer2 展示了令人鼓舞的结果，但未来仍有令人兴奋的发展机会。一个限制是 SVF 专家的能力与基础模型的潜在组件相关联。为了解决这个问题，模型合并提供了一个有希望的方向（Yu 等人，2024；Goddard 等人，2024；Akiba 等人，2024），使专门的模型能够组合成一个功能更强大的模型。此外，虽然我们基于 CEM 的适应性有效地平衡了性能和效率，但扩展到大量专门领域可能会增加一次性计算成本。然而，这种权衡被改进的性能和增强的自适应能力的好处所抵消。模型合并和高效适应技术的进步使得模型在开放排行榜上占据主导地位，使它们成为 Transformer2 基础模型的有力候选者，并为自适应 LLM 开辟了新的可能性。     提交人    /u/Jind0sh   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iicsz0/r_transformersquared_selfadaptive_llms/</guid>
      <pubDate>Wed, 05 Feb 2025 15:39:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前计算机视觉和语言技术领域不受欢迎的研究课题有哪些？ 2025</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</link>
      <description><![CDATA[不，我不想再听到有关 LLM 和 VLM 的更多信息了。    提交人    /u/KingsmanVince   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</guid>
      <pubDate>Wed, 05 Feb 2025 02:43:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>