<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 21 Nov 2024 09:18:53 GMT</lastBuildDate>
    <item>
      <title>[D] 时间系列中的下一个大事件？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwbhxq/d_next_big_thing_in_time_series/</link>
      <description><![CDATA[在 NLP 中，我们已经看到了像 transformers、GPT 和 LLM 这样的重大里程碑，它们彻底改变了这个领域。时间序列研究似乎从 NLP 和 CV 中借鉴了很多东西——比如基于 transformer 的模型、自监督学习，现在甚至是专门用于时间序列的基础模型。但对于哪种方法最有效，似乎还没有达成明确的共识。例如，NLP 有广为接受的预训练策略，如掩蔽语言建模或下一个标记预测，但类似的策略并没有成为时间序列的标准。 最近，有很多关于将 LLM 改编为时间序列甚至专门为此目的构建基础模型的讨论。另一方面，一些研究表明 LLM 对时间序列没有帮助。 所以我只想知道什么可以改变时间序列的游戏规则！   由    /u/Few-Pomegranate4369  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwbhxq/d_next_big_thing_in_time_series/</guid>
      <pubDate>Thu, 21 Nov 2024 08:20:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何准备 Palo Alto 网络的 ML 工程师面试？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwb0ui/d_how_to_prepare_for_ml_engineer_interview_at/</link>
      <description><![CDATA[有人有 PANW ML 职位的面试经验吗？    提交人    /u/InvestigatorIcy7529   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwb0ui/d_how_to_prepare_for_ml_engineer_interview_at/</guid>
      <pubDate>Thu, 21 Nov 2024 07:45:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 隐藏的说服者：法学硕士的政治倾向及其对选民的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gw7t2x/r_hidden_persuaders_llms_political_leaning_and/</link>
      <description><![CDATA[      https://arxiv.org/pdf/2410.24190 https://preview.redd.it/9h1ixk8tl62e1.png?width=775&amp;format=png&amp;auto=webp&amp;s=a48f0fbe62599ae5cb53f595e2ed663d4bfec1c7 法学硕士如何影响我们的民主？我们通过在美国总统选举背景下进行多项实验来调查法学硕士的政治倾向及其对选民的潜在影响。通过投票模拟，我们首先展示了 18 名开放和封闭权重的法学硕士对民主党候选人的政治偏好，而不是共和党候选人。通过分析他们对候选人政策相关问题的回答，我们展示了这种对民主党候选人的倾向在指令调整模型中比在基础版本中更加明显。我们通过对 935 名美国登记选民进行实验，进一步探索法学硕士对选民选择的潜在影响。在实验过程中，参与者与法学硕士 (Claude-3、Llama-3 和 GPT-4) 进行了五次交流。实验结果显示，在与法学硕士互动后，选民的选择转向了民主党候选人，投票率从 0.7% 扩大到 4.6%，尽管法学硕士在讨论过程中没有被要求说服用户支持民主党候选人。这种影响比之前许多关于政治运动说服力的研究更大，这些研究表明政治运动在总统选举中的影响微乎其微。许多用户还表达了与 LLM 进一步进行政治互动的愿望。LLM 互动的哪些方面推动了选民选择的这些转变需要进一步研究。最后，我们探讨了安全方法如何使 LLM 在政治上更加中立，同时提出了一个问题：这种中立是否真的是前进的道路。    提交人    /u/ChangeRelevant1378   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gw7t2x/r_hidden_persuaders_llms_political_leaning_and/</guid>
      <pubDate>Thu, 21 Nov 2024 04:22:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 努力转型为博士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gw61tk/d_struggling_to_transition_to_phd/</link>
      <description><![CDATA[“本科是回答问题，而博士是寻找问题。” — 某人 我是计算机科学博士一年级学生，但我觉得自己被困在本科生的思维模式中。我擅长解决问题，我的完美 GPA 就是明证。然而，在研究方面，我却很挣扎。如果我进入一个新领域，我通常会阅读大量论文、做笔记，最终能够写出一份像样的调查——但我很少产生新的想法。 与其他博士生交谈只会增加我的挫败感；其中一位博士生声称他们甚至可以在拉丁语课上想出法学硕士的想法。我的导师说研究更多的是坚持而不是天赋，但我觉得自己陷入了一个循环：我深入一个新领域，做了一个调查，然后就卡在那里了。 我对自己的智力很有信心，但我怀疑我的工作流程是否有缺陷（例如，也许我应该早点开始实验？）或者我是否不适合做研究。想出微小的改进或将 A 应用于 B 感觉很无趣，我很难花时间在这样的想法上。 你们计算机科学（机器学习）博士生是如何想出有意义的研究想法的？有什么建议可以打破这个循环吗？    提交人    /u/StraightSpeech9295   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gw61tk/d_struggling_to_transition_to_phd/</guid>
      <pubDate>Thu, 21 Nov 2024 02:50:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过精准知识编辑 (PKE) 增强 LLM 安全性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gw5w3d/p_enhancing_llm_safety_with_precision_knowledge/</link>
      <description><![CDATA[我一直在研究一个名为 PKE（精确知识编辑）的项目，这是一种开源方法，通过减少有毒内容生成而不影响其总体性能来提高 LLM 的安全性。它的工作原理是使用神经元权重跟踪和激活通路跟踪来识别模型中的“有毒热点”，并通过自定义损失函数对其进行修改。 如果您对方法和结果感兴趣，我们还发表了一篇论文，详细介绍了我们的方法和实验结果。它包括与现有技术（如解毒实例神经元修改 (DINM)）的比较，并展示了 PKE 在降低攻击成功率 (ASR) 方面的显著改进。 该项目是开源的，我很乐意听取您的反馈！ GitHub repo 中有一个 Jupyter Notebook，提供了将 PKE 应用于 Meta-Llama-3-8B-Instruct 等模型的实际演示：https://github.com/HydroXai/Enhancing-Safety-in-Large-Language-Models 如果您对 AI 安全感兴趣，我将非常感谢您的想法和建议。感谢您的关注！    提交人    /u/lial4415   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gw5w3d/p_enhancing_llm_safety_with_precision_knowledge/</guid>
      <pubDate>Thu, 21 Nov 2024 02:43:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 斯毛戈论文中的数学推论有效吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gw0l7f/d_is_the_maths_deduction_in_the_smaug_paper_valid/</link>
      <description><![CDATA[      Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive 论文指出，当完成对之间的编辑距离较小时，DPO 会降低模型选择首选完成的可能性。 在他们对这一现象的理论分析中，主要步骤之一是“将注意力限制在对数上”，根据我的理解，这会根据词汇表中每个标记上的注意力对数得出 DPO 损失的偏导数。 （论文附录 B.1，这里是部分截图。） https://preview.redd.it/3s250pg0o42e1.png?width=2072&amp;format=png&amp;auto=webp&amp;s=c1a92c3474d9dd235e2e72d1615696e69e843676 然而，loss 应该会优化模型参数，本文的推论假设那些注意力 logit 是独立的变量，让我觉得它们的推导是无效的。我不是数学专业的，所以我不确定我的想法是否正确。    提交人    /u/StraightSpeech9295   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gw0l7f/d_is_the_maths_deduction_in_the_smaug_paper_valid/</guid>
      <pubDate>Wed, 20 Nov 2024 22:00:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] ITCMA-S：一种用于紧急社会行为和群体形成的多智能体架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gvyfe4/r_itcmas_a_multiagent_architecture_for_emergent/</link>
      <description><![CDATA[我读了一篇有趣的论文，它提出了一种用于研究多智能体系统中出现的社会行为的新型架构。关键的技术贡献是引入了&quot;生成式多智能体&quot;，它可以动态地形成社会结构而无需显式编程。 核心技术组件： - 结合感知、记忆和决策的三层智能体架构 - 允许智能体模拟他人心理状态的新型&quot;社会感知模块&quot; - 整合情景和语义信息的记忆系统 - 基于个人目标和社会背景的动作选择 主要实验结果： - 智能体自发地发展出分层的社会结构 - 社会规范通过反复互动而出现 - 不同的&quot;文化&quot;在孤立的智能体群体中形成 - 智能体表现出合作和竞争行为的证据 - 社会学习通过观察和模仿发生 我认为对多智能体系统和社会 AI 研究最重要的影响。该架构表明，复杂的社会行为可以从相对简单的构建块中产生，因此它为更像人类的人工智能系统提供了潜在的途径。研究结果还为研究社会如何形成和发展提供了一个计算框架。 从实践角度来看，这项工作可以为开发更复杂的多智能体系统提供参考，用于社交模拟、游戏人工智能和机器人群等应用。 TLDR：新架构允许人工智能代理自发地开发社会结构和规范，而无需明确编程。结果显示了等级制度、文化和社会学习的出现。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gvyfe4/r_itcmas_a_multiagent_architecture_for_emergent/</guid>
      <pubDate>Wed, 20 Nov 2024 19:50:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] RL/ML 理论博士学位或法学硕士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gvx8vx/d_phd_in_rlml_theory_or_llm/</link>
      <description><![CDATA[大家好， 我正处于学术旅程的十字路口，希望得到社区的见解。我正在考虑是攻读强化学习/机器学习理论博士学位，还是专攻大型语言模型并进行更多的实验/应用研究（我收到的只有这两个机会）。 主要考虑因素如下： 研究影响  强化学习/机器学习理论：可以促进该领域数学理解的基础工作 法学硕士：直接应用于当今最具变革性的人工智能系统  就业前景  理论：学术界、研究实验室，行业角色可能更有限 法学硕士：行业需求高，学术界和行业都有活跃的研究领域  长期相关性  理论：无论具体技术如何，核心原则都可能保持价值 法学硕士：目前具有革命性，但长期不确定轨迹  个人背景  我是一名国际学生，即将在美国完成我的硕士课程，所以在做出最终决定之前我没有足够的时间。我曾经研究过机器学习理论，但最终并没有在理论上发表真正的顶级会议出版物。我个人怀疑我是否有足够的数学背景来在这个领域攻读成功的博士学位（例如，每年至少在 ICML/NeurIPS/ICLR/COLT/AISTATS 上发表 2 篇理论论文）。同时，我个人怀疑理论是否确实推动了 ML/AI 社区的发展，因为许多论文只是证明空洞的界限或提出一些新的算法，这些算法本身甚至无法实现或经过实验测试。 我还曾经研究过更多的应用机器学习，发表过一篇 aaai 论文。我个人担心的是，我在实施和编码方面不够快，而这正是一名成功的应用机器学习研究人员最具战略性的能力。进入 LLM 时代后，应用 ML 研究（尤其是 LLM 和 CV）的节奏变得非常快。这就像研究社区中的竞争性编程（好吧，也是 #GPUs 竞赛）。     提交人    /u/Living_Imagination84   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gvx8vx/d_phd_in_rlml_theory_or_llm/</guid>
      <pubDate>Wed, 20 Nov 2024 19:02:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 预训练中的程序性知识推动大型语言模型的推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gvveu8/r_procedural_knowledge_in_pretraining_drives/</link>
      <description><![CDATA[  由    /u/rcparts  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gvveu8/r_procedural_knowledge_in_pretraining_drives/</guid>
      <pubDate>Wed, 20 Nov 2024 17:47:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICASSP 2025 评审今天截止！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gvqvgd/d_icassp_2025_reviews_are_due_today/</link>
      <description><![CDATA[友好地讨论一下 icassp 评论！希望一切顺利！    由   提交  /u/always_been_a_toy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gvqvgd/d_icassp_2025_reviews_are_due_today/</guid>
      <pubDate>Wed, 20 Nov 2024 14:35:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 的 CLIP 替代方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gvlgxm/d_openais_clip_alternative/</link>
      <description><![CDATA[嗨，有没有像 CLIP 这样的新 SOTA 模型？我想对图像进行相似性搜索，但 CLIP 的性能对我的项目来说不是很好。 我目前使用：CLIP-ViT-B-32-laion2B-s34B-b79K 还可以捕获颜色的嵌入将是完美的。谢谢。    提交人    /u/CaptTechno   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gvlgxm/d_openais_clip_alternative/</guid>
      <pubDate>Wed, 20 Nov 2024 09:08:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 405B 的 Cerebras 推理结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gvjrmo/d_cerebras_inference_results_for_405b/</link>
      <description><![CDATA[Cerebras 刚刚分享了一些关于 LLM 推理的非常有趣的结果。我一开始是持怀疑态度的，以为他们可能使用了一些较大的批量大小或一些技巧来使 llama 405B 达到近 1k 个 token/s。我在他们的网站上测试了 llama-70B。它真的很快…… 我一直在阅读他们发表的论文，但他们没有分享任何关于如何在这个巨大的芯片上运行 405B 参数模型的细节。他们有 40GB 的 SRAM，这是巨大的，但以如此低的延迟和高吞吐量运行 405B 模型仍然听起来很有趣。他们的论文讨论了权重流。我认为他们一定使用了一些先进的数据流分析来使计算从可以存储如此巨大数据的片外存储器中保持繁忙。 有人知道我可以在哪里获得有关此的更多信息吗？ 参考：https://cerebras.ai/blog/llama-405b-inference 论文：https://arxiv.org/abs/2409.00287 白皮书：https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10123162 免责声明：我与 Cerebras 系统无关，只是对此真正感兴趣和好奇。这对整个 AI 来说似乎是一件大事。    提交人    /u/JanGehlYacht   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gvjrmo/d_cerebras_inference_results_for_405b/</guid>
      <pubDate>Wed, 20 Nov 2024 06:59:01 GMT</pubDate>
    </item>
    <item>
      <title>[N] 开放权重（本地）LLM 终于赶上了封闭式 SOTA 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gvfpdw/n_open_weight_local_llms_finally_caught_up_to/</link>
      <description><![CDATA[      昨天，Pixtral large 发布了这里。 这是一个 124B 的多模态视觉模型。这个非常小的模型在各种精心挑选的基准上击败了 1+ 万亿参数的 GPT 4o。别介意 Gemini-1.5 Pro。 据我所知，没有语音或视频。但真的，这重要吗？对我来说，这似乎是开创性的。它也可以免费使用。然而，我几乎没有在太多地方看到提到这一点。我遗漏了什么吗？ 顺便说一句，自 2022 年 11 月 30 日 ChatGPT 向公众发布以来，还不到两年。在短短两年的时间里，人工智能已经变得有些面目全非。疯狂的进步。 [下面的基准] https://preview.redd.it/ebo9qp0rzy1e1.png?width=1777&amp;format=png&amp;auto=webp&amp;s=3d47183ba7e2af69eb52fc5f8d755f105cb52004 https://preview.redd.it/woc0wmrozy1e1.png?width=1852&amp;format=png&amp;auto=webp&amp;s=1bc5d380e2deebfd03684e1a8341254d18596d8e    提交人    /u/AIAddict1935   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gvfpdw/n_open_weight_local_llms_finally_caught_up_to/</guid>
      <pubDate>Wed, 20 Nov 2024 03:00:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Nov 2024 16:00:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>