<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 23 Dec 2023 15:12:17 GMT</lastBuildDate>
    <item>
      <title>[D] 刚刚开始</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18p6lmn/d_just_starting_out/</link>
      <description><![CDATA[大家好，我有一个难得的机会在我公司即将开展的软件项目中学习 AI/ML 知识。他们不想雇用新人，而是希望现有员工（我）填补该职位，学习相关知识并进入该职位。我太兴奋了！ TLDR：关于一些很棒的资源的建议，以便更好地理解和实现 ML，请提供，谢谢。 我最近购买了 udemy 课程（ZTM） TensorFlow Google 证书），我已经完成了大约 20%。所以我已经掌握了神经网络的基础知识，现在正在研究分类问题。 我的问题：这个社区是否已经发现或可能建议任何其他令人惊叹的资源？我不想成为黑客。我真的很感兴趣并且想在这方面做得很好。我仍在攻读软件工程学士学位，但它并不是专门针对 ML 的。   由   提交 /u/Bl4ckSt4ff   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18p6lmn/d_just_starting_out/</guid>
      <pubDate>Sat, 23 Dec 2023 14:18:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] BatchNorm 和权重衰减</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18p54b4/d_batchnorm_and_weight_decay/</link>
      <description><![CDATA[结合 BatchNorm 和权重衰减的正确方法是什么？是否应该应用于BN的weight参数？   由   提交/u/Dependent_Bluejay_45   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18p54b4/d_batchnorm_and_weight_decay/</guid>
      <pubDate>Sat, 23 Dec 2023 12:55:10 GMT</pubDate>
    </item>
    <item>
      <title>顶点项目输入 [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18p3ofv/capstone_project_input_project/</link>
      <description><![CDATA[我正在开始我的顶点项目，并且正在寻找意见。我正在寻找关于如何将机器学习应用于个人预算的建议，以进行趋势分析，而不仅仅是过去两年中 X 费用上涨了 Y%。  ​ 我使用自己的个人预算数据作为数据集，在规模或复杂性方面没有任何要求，只是我使用机器学习 ​ 我的第一直觉是识别并指出诸如“你倾向于在周四和周五去咖啡店”之类的模式。或者，“如果您在 X 加油站购买汽油，您往往还会购买非汽油” ​   由   提交 /u/Sveet_Pickle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18p3ofv/capstone_project_input_project/</guid>
      <pubDate>Sat, 23 Dec 2023 11:22:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 需要在神经进化算法中选择父母的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18p3im8/p_need_advice_selecting_parents_in_neuroevolution/</link>
      <description><![CDATA[我是一个无名小卒，由于缺乏替代方案而创建了自己的神经进化算法。到目前为止它运行得很好，但在最终确定之前我遇到了一个问题，希望有人能给我一些好的建议。 该算法（像许多其他算法一样）基于基因组群体。在每一代结束时，最差基因组的一部分（可配置参数）被删除，剩余的部分用于交配。 这就是我的问题所在，因为在我的脑海里有三个选择父母的方式（可能还有更多，但目前这三种对我来说已经足够了）。 首先，父母双方都可以从总体中完全随机选择。其次，可以使用适应度来衡量选择的权重，以便具有最高适应度的基因组具有更高的繁殖概率。基于此，有两种可能性，即仅选择一个亲本加权，或两者都选择。 我尝试对所有三个选项进行统计评估，但不幸的是，突变等随机因素意味着所有选项平均表现同样好。 进行的测试：每次 30 代的 100 次试验的平均适应度分数。 有人在这方面有任何经验吗？是否相关或者对于进化论是否有统一的观点？从我的观点（以及我所学到的）来看，“最适者”是最适合的。交配时个体总是优先的。 希望群体智能能够帮助我，祝您节日快乐。    ;由   提交/u/Weekly_Branch_5370   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18p3im8/p_need_advice_selecting_parents_in_neuroevolution/</guid>
      <pubDate>Sat, 23 Dec 2023 11:11:06 GMT</pubDate>
    </item>
    <item>
      <title>[项目] MiniBoosts：用 Rust 编写的 boosting 算法的一个小集合🦀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18p2dkj/project_miniboosts_a_small_collection_of_boosting/</link>
      <description><![CDATA[       由   提交 /u/__leopardus__   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18p2dkj/project_miniboosts_a_small_collection_of_boosting/</guid>
      <pubDate>Sat, 23 Dec 2023 09:48:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 模型部署和分发工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18p1aty/d_tools_for_model_deployment_and_distribution/</link>
      <description><![CDATA[此字段新增。寻找常用于部署、集成和分发 llm 模型（或一般的 ml 模型）的工具。 比如模型经过 ml 研究人员训练后的轨迹是什么。之后的管道是什么？我找到了这个https://github.com/Mozilla-Ocho/llamafile 在我的搜索过程中。有人使用它吗？它的范围是什么？   由   提交 /u/MelodicFollowing9383   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18p1aty/d_tools_for_model_deployment_and_distribution/</guid>
      <pubDate>Sat, 23 Dec 2023 08:28:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士可解释性研究知识库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ozqu1/r_llm_interpretability_research_repository/</link>
      <description><![CDATA[对于任何对 LLM 可解释性感兴趣的人，我创建了以下存储库： https://github.com/JShollaj/awesome-llm-interpretability 它包含一组精选的开源工具、论文、文章、群组等。 请随意查看&amp;希望它对您的研究有所帮助。   由   提交 /u/XhoniShollaj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ozqu1/r_llm_interpretability_research_repository/</guid>
      <pubDate>Sat, 23 Dec 2023 06:38:23 GMT</pubDate>
    </item>
    <item>
      <title>泰勒级数注意【讨论】</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18oxc65/taylor_series_attention_discussion/</link>
      <description><![CDATA[我最近读完了动物学博客文章关于 BASED，一种新的语言模型，它使用局部卷积和使用泰勒级数近似的自注意力，似乎基于本文。&lt; /p&gt; 读完后我的一个问题是这种局部卷积对模型性能有多重要？是否有关于仅采用这种泰勒注意力的变压器架构的研究？ BASED 模型显然具有良好的性能，论文提供的直观理解是，这些卷积在 AR 不是一个大挑战的短距离场景中使模型受益，这是有道理的，但普通注意力对于 AR 或短距离困惑没有问题。答案是泰勒近似在这些短距离情况下会不太准确，需要卷积来补偿吗？   由   提交 /u/Aggressive-Solid6730    reddit.com/r/MachineLearning/comments/18oxc65/taylor_series_attention_discussion/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18oxc65/taylor_series_attention_discussion/</guid>
      <pubDate>Sat, 23 Dec 2023 04:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从时间序列中提取高斯噪声</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ovd9u/d_extracting_gaussian_noise_from_a_timeseries/</link>
      <description><![CDATA[嘿伙计们， 这件事困扰了我一段时间，所以我想和大家讨论一下。通常，我使用几种分解技术中的任何一种来从时间序列数据（或部分噪声分量）中提取噪声。例如，它可能是快速傅里叶变换的几个高频分量，或者奇异值分解的高阶分量等。 假设这些技术都不存在，我想构建一个神经网络将接受连续的时间序列输入，并“教导”它可以找到输入数据的线性或非线性变换，这将至少给出一些噪声时间序列作为输出。文献似乎侧重于为去噪目的提供噪声和干净的版本，但我对残差提取和分析的转换感兴趣。 对于初学者，我想专注于提取高斯噪声（最好是附加但只需要一些可逆操作）。一种方法是建立一个网络，强制输出残差的高斯性和随机性（不知道如何）。希望讨论可能的方法或指出有关残差分析的文献。 编辑：看来 ICA 可能会在这里发挥作用。这里有很多好的理论。   由   提交/u/PUthroaway2020   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ovd9u/d_extracting_gaussian_noise_from_a_timeseries/</guid>
      <pubDate>Sat, 23 Dec 2023 02:22:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么张量程序没有像神经切线核那样受到同样的关注？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18oq5us/d_why_have_tensor_programs_not_received_the_same/</link>
      <description><![CDATA[神经正切核经常在理论论文中被引用，作为推广线性函数逼近器证明的基础。然而，它们有几个缺点，即它们不包含特征学习的概念。张量程序应该可以解决这个问题，但我认为我从未在理论论文中看到过它们被引用。人们是否怀疑结果或认为结果缺乏严谨性？结果是否被认为不太有用？或者它们只是因为数学上更复杂且更难学习而使用较少？  我问这个问题的部分原因是我想知道它是否值得花精力去阅读和理解整个论文系列，或者这项工作是否经过深思熟虑。    由   提交 /u/OptimizedGarbage   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18oq5us/d_why_have_tensor_programs_not_received_the_same/</guid>
      <pubDate>Fri, 22 Dec 2023 22:03:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] OpenMetricLearning 2.0 发布！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18onq8k/p_openmetriclearning_20_is_released/</link>
      <description><![CDATA[您好！  我想介绍 OpenMetricLearning 2.0 的发布！库用于训练将数据表示为向量的深度学习模型。此外，我们还有一个预训练图像模型、DDP 支持、大量示例和文档。  该版本有哪些新功能？  迁移到 PyTorch 2.0（很容易）&amp; Lightning 2.0（很痛苦） 减少了通过 pip 安装的依赖项数量 对所有当前版本的 Python 提供了稳定支持：现在 CI/CD 对所有内容都运行测试 - &lt; strong&gt;3.8、3.9、3.10、3.11 修复了一些烦人的小错误，整理了文档，并简化了公共数据集上管道的启动（例如 InShop、 斯坦福在线产品、CAR、CUB） 对于重新识别：添加了在以下情况下更正确地处理同一对象的一系列照片的功能：计算指标  我们希望所有这些更改将使OML更方便使用。非常欢迎您在GitHub上的⭐！ ​    由   提交 /u/Zestyclose-Check-751   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18onq8k/p_openmetriclearning_20_is_released/</guid>
      <pubDate>Fri, 22 Dec 2023 20:09:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 研究论文的升级何时会成为新论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18onakf/r_when_does_an_upgrade_on_a_research_paper_become/</link>
      <description><![CDATA[嘿，我是研究新手，过去 6 年来一直致力于实现一篇论文并根据我们在推荐系统领域的用例进行定制几个月。我按照 1. 在损失函数中使用不同的运算符（余弦相似度而不是点积）进行了一些更改。 2. 使用不同类型的数据。这有点难以解释，我使用元数据相似性而不是论文中一对共现的逐点互指数（PMI）。 3. 不同的数据预处理方式。 结果确实有所改善，但我不确定这是否只是一些修改，或者它本身就是一篇论文。任何人都可以阐明新想法与小修改的一些迹象吗？   由   提交/u/Abs0lut_Jeer0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18onakf/r_when_does_an_upgrade_on_a_research_paper_become/</guid>
      <pubDate>Fri, 22 Dec 2023 19:49:11 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] 苹果研究人员推出 DeepPCR：一种新颖的机器学习算法，可并行化典型的顺序操作，以加速神经网络的推理和训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18odo0m/news_apple_researchers_unveil_deeppcr_a_novel/</link>
      <description><![CDATA[”论文通过各种应用展示了 DeepPCR 的有效性。它在多层感知器中实现了前向传递高达 30 倍的加速和后向传递高达 200 倍的加速。此外，该算法还应用于深度 ResNet 架构的并行训练和扩散模型的生成，从而使训练速度提高 7 倍，生成速度提高 11 倍。” 论文：https://arxiv.org/pdf/2309.16318.pdf 研究页面：https://machinelearning.apple.com/research/deepcr https://twitter.com/i/status/1735876638947348656   由   提交/u/paryska99  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18odo0m/news_apple_researchers_unveil_deeppcr_a_novel/</guid>
      <pubDate>Fri, 22 Dec 2023 12:19:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我尝试教 Mistral 7B 一门新语言（巽他语），它成功了！ （有点）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ocba4/p_i_tried_to_teach_mistral_7b_a_new_language/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ocba4/p_i_tried_to_teach_mistral_7b_a_new_language/</guid>
      <pubDate>Fri, 22 Dec 2023 10:54:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>