<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 24 Jan 2025 12:31:28 GMT</lastBuildDate>
    <item>
      <title>[R] 使用有效连接和可解释的人工智能进行端到端中风成像分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8snj7/r_endtoend_stroke_imaging_analysis_using/</link>
      <description><![CDATA[https://ieeexplore.ieee.org/document/10839398 关于识别中风断开连接以进行干细胞治疗的研究，实际上对 causalML 很有用    提交人    /u/mandelbrot1981   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8snj7/r_endtoend_stroke_imaging_analysis_using/</guid>
      <pubDate>Fri, 24 Jan 2025 10:43:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士（分类）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8sawf/d_llm_for_categorization/</link>
      <description><![CDATA[我是这里的新手，也是 AI 领域的新手。我想创建高维向量空间，其中每个点都是一个故事。这个想法是拥有一个空间，其中较近的点是相似的，就像一个词嵌入一样。就像一个集群中的恐怖故事。科幻小说也在其中。所以，它可以用作推荐系统。我脑海中的总体想法是：使用任何 llm 的标记器和工作嵌入，然后进行自我注意以获得最终的上下文向量，并且在下一部分（不知道它应该如何工作）它应该对上下文向量和初始 n 大小向量执行交叉注意，让我们称之为 F，在此之后 F 应该是 n 维向量空间中故事的坐标。任何想法我应该如何处理这个问题。    提交人    /u/Turbulent_Debt3405   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8sawf/d_llm_for_categorization/</guid>
      <pubDate>Fri, 24 Jan 2025 10:18:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何训练一个模型供计算机使用？ CUA 模型与 4o 有何不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8pvnb/d_how_to_train_a_model_for_computer_use_how/</link>
      <description><![CDATA[大家好， 看到计算机使用操作员演示。我很好奇如何将其应用到我的公司领域。当然，每个人都会很快到达这里，但与此同时，我真的很想了解微调模型以执行这些操作需要付出多少努力？  如果我要开始这段旅程，朝着构建类似 CUA 的代理迈进，任何链接、论文和材料都将不胜感激。 计算需要数百万资金吗？或者可以智能地进行微调。     提交人    /u/darcwader   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8pvnb/d_how_to_train_a_model_for_computer_use_how/</guid>
      <pubDate>Fri, 24 Jan 2025 07:12:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] arXiv 对 AV 研究的认可请求</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8prw0/r_arxiv_endorsement_request_for_av_research/</link>
      <description><![CDATA[您好， 我计划发表一篇关于在基于传感器的自动驾驶技术中集成知识图谱以评估道路障碍物的物理材料特性的研究论文 我需要有人为我背书，并满足以下条件： 要背书其他用户提交 cs.OH（其他计算机科学）主题类，arXiv 提交者必须已经向cs.AI、cs.AR、cs.CC、cs.CE、cs.CG、cs.CL、cs.CR、cs.CV、cs.CY、cs.DB、cs.DC、cs.DL、cs.DM、cs.DS、cs.ET、cs.FL、cs.GL、cs.GR、cs.GT、cs.HC、cs.IR、cs.IT 中的任何一个提交了 3 篇论文， cs.LG、cs.LO、cs.MA、cs.MM、cs.MS、cs.NA、cs.NE、cs.NI、cs.OH、cs.OS、cs.PF、cs.PL、cs.RO、cs.SC、cs.SD、cs.SE、cs.SI 或 cs.SY 早于三个月前但少于五年前。 Seungyong Yang 请求您的支持，将文章提交至 arXiv 的 cs.OH 部分。若要告诉我们您愿意（或不愿意） 为该人背书，请访问以下网址： https://arxiv.org/auth/endorse?x=AI99OQ 如果该网址对您不起作用，请访问 http://arxiv.org/auth/endorse.php 并输入以下六位字母数字字符串： 背书代码：AI99OQ 我可以分享更多详细信息。非常感谢！！    提交人    /u/syaang   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8prw0/r_arxiv_endorsement_request_for_av_research/</guid>
      <pubDate>Fri, 24 Jan 2025 07:04:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 提交系统和最终论文的标题和摘要不一致</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8o5vf/d_title_and_abstract_discrepancy_of_submission/</link>
      <description><![CDATA[我在第一次大型会议投稿时犯了一个错误。提交初始摘要后，我在论文的最终版本中更新了标题和摘要，但在上传最终论文版本时忘记在提交系统中更新它们。我担心系统中的标题和摘要与论文的最终版本之间的差异可能会导致被拒。有什么办法可以解决这个问题吗？    提交人    /u/That_Transition_9335   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8o5vf/d_title_and_abstract_discrepancy_of_submission/</guid>
      <pubDate>Fri, 24 Jan 2025 05:18:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有关于 Nvidia 的 DLSS 4 ViT 模型架构的详细信息吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8o4vf/d_any_details_on_nvidias_dlss_4_vit_model/</link>
      <description><![CDATA[市场营销和炒作层出不穷，但实际技术细节却很少。DLL 已经发布，我想知道是否有人尝试过深入了解它到底在运行什么？     提交人    /u/altmly   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8o4vf/d_any_details_on_nvidias_dlss_4_vit_model/</guid>
      <pubDate>Fri, 24 Jan 2025 05:16:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 是否像 ICLR 一样对撤回/拒绝的提交进行去匿名化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8n40e/d_does_icml_deanonymize_withdrawnrejected/</link>
      <description><![CDATA[ICLR 保留撤回或拒绝提交的匿名名称。ICML 计划在 2025 年这样做吗？我认为他们过去没有这样做过，但我可能错了。    提交人    /u/faithforever5   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8n40e/d_does_icml_deanonymize_withdrawnrejected/</guid>
      <pubDate>Fri, 24 Jan 2025 04:18:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 大量聊天数据的主题建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8msyv/d_topic_modeling_for_high_volume_chat_data/</link>
      <description><![CDATA[大家好， 我正在为我的雇主进行一些针对大量数据（2-3m+）的聊天主题建模练习。数据是英语、泰语和印尼语聊天的混合。我想获得一些关于我选择的方法的反馈，我应该避免的任何陷阱以及有助于改善我的输出的最佳实践。 我正在使用 BertTopic 进行以下阶段 嵌入：`xlm-roberta-large`，以便我可以在同一模型中处理所有语言 降维：UMAP 聚类：HDBSCAN 生成主题后，我将使用 LLM 为各种主题创建标签 为了进行评估，我计算了模型的整体一致性得分，根据我的超参数，我得到的得分约为 50-60%。我还检查了各个主题的连贯性得分的分布，大部分都超过 50% 我尝试过的一些东西 每种语言的单独模型：这种模型的表现类似于多语言模型，但我放弃了这种模型，因为我需要处理多种语言不同的数据段 NER 预处理：我的聊天记录可能有一些位置信息等，我想将其输入其中，以便主题模型表现得更好。然而，这种方法并没有大大改善输出，而且只有在选择单独的语言嵌入模型时才能这样做。我试图探索 GliNER，但我认为它不支持泰语。 几个问题： - BertTopic 可以处理多大的数据集？我已经处理了大约 10 万条聊天记录，我应该如何考虑可能需要进行哪些更改来处理 200 万条聊天记录？ - 评估输出的好方法是什么？ - 我最关心主题的可解释性。我可以用 LLM 做哪些额外的事情来制作 - MECE 主题并确保合理的分布和覆盖范围？ - 我是否应该添加任何其他步骤来改善我的主题之间的分离？ 我不太熟悉 NLP 技术，所以如果大家能提出建议来改进这个过程就太好了 谢谢 !    提交人    /u/justthinair   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8msyv/d_topic_modeling_for_high_volume_chat_data/</guid>
      <pubDate>Fri, 24 Jan 2025 04:00:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否可以在评论反驳中添加贡献？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8mi1e/d_is_it_possible_to_add_contributions_in_a_review/</link>
      <description><![CDATA[我于 11 月向 CVPR&#39;25 提交了论文，继续努力完善工作并做出了一些我认为会很好的贡献。我的评论有效地提到了缺少的那些贡献（例如额外的实验结果）。 我可以在评论的反驳中提到这些吗？或者反驳应该专门针对已经提交的工作？    提交人    /u/bonespro_333   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8mi1e/d_is_it_possible_to_add_contributions_in_a_review/</guid>
      <pubDate>Fri, 24 Jan 2025 03:44:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] ANN 搜索索引中向量 ID 和链接的高效无损压缩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i89hn0/r_efficient_lossless_compression_of_vector_ids/</link>
      <description><![CDATA[本文介绍了一种用于近似最近邻搜索系统中向量 ID 的新型无序压缩技术。 ID 不再作为序列处理，而是作为无序集处理，从而实现更高效的压缩模式，而不会影响搜索性能。 关键技术点： - 两阶段压缩管道：首先对相似的 ID 进行聚类，然后对每个聚类应用专门的压缩 - 与顺序无关的方法：消除了传统压缩中常见的顺序依赖关系 - 保持快速查找：使用索引系统，在减少存储的同时保留快速访问 - 与现有系统兼容：与当前的向量数据库实现一起工作 结果： - 向量 ID 的压缩率达到了 70% - 保持原有的搜索准确度水平 - 压缩速度与基线方法相当或更快 - 在标准 ANN 基准（SIFT1M、DEEP1B 数据集）上进行测试 - 压缩期间的内存开销保持在实际限制之内 我认为这种方法可以让存储资源有限的组织更容易进行大规模向量搜索。该方法对于图像搜索或推荐系统等矢量数据库正在成为标准的应用尤其有价值。 我认为主要的限制是数据集越小，好处就越少，这可能会使其对较小的应用程序吸引力降低。实施的复杂性也可能给没有专业知识的团队带来挑战。 TLDR：一种用于矢量 ID 的新压缩方法，可在不影响搜索性能的情况下减少 70% 的空间，使用与顺序无关的方法在压缩之前对相似的 ID 进行聚类。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i89hn0/r_efficient_lossless_compression_of_vector_ids/</guid>
      <pubDate>Thu, 23 Jan 2025 17:59:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于能量的文本生成扩散语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i87lgy/r_energybased_diffusion_language_models_for_text/</link>
      <description><![CDATA[https://arxiv.org/pdf/2410.21357 本文作者将扩散模型与基于能量的建模相结合，以解决离散生成建模中的挑战。    提交人    /u/Whatever_635   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i87lgy/r_energybased_diffusion_language_models_for_text/</guid>
      <pubDate>Thu, 23 Jan 2025 16:41:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有可能在不重新训练的情况下增加序列长度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i86s90/d_is_it_possible_to_increase_the_sequence_length/</link>
      <description><![CDATA[大家好， 我想知道是否有关于在不完全重新训练的情况下增加模型最大序列长度的研究。如果已经存在，您能分享一些论文或想法吗？    提交人    /u/BigAbbreviations9098   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i86s90/d_is_it_possible_to_increase_the_sequence_length/</guid>
      <pubDate>Thu, 23 Jan 2025 16:06:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 评论 CVPR 评论和 ICLR 决定。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i7nvix/d_comment_on_cvpr_reviews_and_iclr_decisions/</link>
      <description><![CDATA[大家好， 我们都知道评审和决定可能会引起争议，我相信你们中的许多人都对结果感到失望（我在 CVPR 上的评分都是 2 😅）。但请记住，这不是世界末日！ 被拒绝并不意味着你有错——这通常只是运气不好（当然，我们应该始终努力改进我们的工作）。 休息一下——吃点鸡肉和啤酒，睡个好觉，准备好将你的作品提交给另一个场地。你做到了！💪    提交人    /u/Shot-Button-9010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i7nvix/d_comment_on_cvpr_reviews_and_iclr_decisions/</guid>
      <pubDate>Wed, 22 Jan 2025 22:26:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 19 Jan 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>