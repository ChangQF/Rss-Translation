<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 21 May 2024 01:01:19 GMT</lastBuildDate>
    <item>
      <title>机器学习研究实习生“[R]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwv1b6/research_intern_in_ml_r/</link>
      <description><![CDATA[大家好，我想知道如何才能成为一名研究实习生，我正在进行非 CSE 项目工程的第三个学期，但我对这门学科充满热情，并在 Coursera 上的课程和第五个学期自学 |想要在良好的指导下从事研究实习生， 1- 我应该从这里学到什么？ （前提是我已经完成了 Coursera 上 Andrew ng 的前 3 毫升课程） 2- 未来 1 年我应该制定的路线图是什么？ 3- 非CSE专业的学生可以吗？ 谢谢:)   由   提交/u/Apart_Loss5865  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwv1b6/research_intern_in_ml_r/</guid>
      <pubDate>Tue, 21 May 2024 00:33:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 动漫人物的 Wav2Lip？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwudpo/d_wav2lip_for_anime_characters/</link>
      <description><![CDATA[大家好。我看到了 Wav2Lip，这是一款基于单个图像和音频创建“深度伪造”说话头像的开源软件。有没有类似的东西，但专门用于动漫 2D 角色？仅限开源！    提交人    /u/yukiarimo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwudpo/d_wav2lip_for_anime_characters/</guid>
      <pubDate>Tue, 21 May 2024 00:01:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习真的对人类健康产生了影响吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwsbyw/d_has_ml_actually_moved_the_needle_on_human_health/</link>
      <description><![CDATA[我们听说机器学习用于药物发现、精准医疗、个性化治疗等已有相当一段时间了。机器学习实际上通过哪些方式改善了人类健康？ 似乎大多数治疗和诊断仍然基于数十年的专注生物学研究，而不是某种公正的机器学习方法。放射学是一个值得注意的例外，它受益于机器视觉的进步，但即使是他们似乎也很慢地接受人工智能作为临床实践。   由   提交/u/Potential_Athlete238   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwsbyw/d_has_ml_actually_moved_the_needle_on_human_health/</guid>
      <pubDate>Mon, 20 May 2024 22:26:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有 ML/AI 相关主题的阅读小组/期刊俱乐部？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwrteq/d_are_there_any_reading_groupsjournal_clubs_for/</link>
      <description><![CDATA[嗨，有谁知道是否有任何阅读小组/期刊俱乐部，人们定期分享书籍章节或论文？如果可能的话，让一些阅读同一本书/论文的人分享他们的想法/想法可能会很好。谢谢！   由   提交 /u/Illustrious-Pay-7516   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwrteq/d_are_there_any_reading_groupsjournal_clubs_for/</guid>
      <pubDate>Mon, 20 May 2024 22:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 多模态模型能区分图像和文本吗？例如，如果文本标记和图像标记是接近的向量，模型是否能够“分辨”它是在阅读还是在看？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwoh51/d_can_multimodal_models_tell_images_apart_from/</link>
      <description><![CDATA[我在使用多模式模型进行一些工作时遇到了这个问题。他们似乎无法区分信息的哪一部分来自输入的文本部分和图像部分。  有这方面的研究吗？    由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwoh51/d_can_multimodal_models_tell_images_apart_from/</guid>
      <pubDate>Mon, 20 May 2024 19:44:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] Instagram应用上评论的音译+翻译</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwiemd/d_transliteration_translation_of_comments_on/</link>
      <description><![CDATA[是我一个人还是有人注意到翻译质量的显着提高 - 特别是使用英语字符编写的语言的翻译（音译 + 翻译） ）。想知道他们使用什么样的模型导致了突然的改进   由   提交/u/ts_aditya  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwiemd/d_transliteration_translation_of_comments_on/</guid>
      <pubDate>Mon, 20 May 2024 15:31:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] SDG-增加了对基于GPT的单表合成数据生成的支持</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwdicc/p_sdg_adds_support_for_gptbased_synthetic_data/</link>
      <description><![CDATA[https://github.com /hitsz-ids/synthetic-data-generator   由   提交 /u/hitszids   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwdicc/p_sdg_adds_support_for_gptbased_synthetic_data/</guid>
      <pubDate>Mon, 20 May 2024 11:42:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 医学语言代理模拟（基准）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cw5luk/r_medical_language_agent_simulation_benchmark/</link>
      <description><![CDATA[网站：https://agentclinic .github.io/ Arxiv：https://arxiv.org/pdf/ 2405.07960 TLDR： AgentClinic 将静态医疗 QA 问题转化为临床环境（医生、患者、医疗设备）中的代理，以提出更具临床相关性的挑战医学语言模型。 摘要：诊断和管理患者是一个复杂的、连续的决策过程，需要医生获取信息——例如要执行哪些测试—— ——并据此采取行动。人工智能 (AI) 和大语言模型 (LLM) 的最新进展有望对临床护理产生深远影响。然而，当前的评估方案过度依赖静态的医学问答基准，缺乏现实临床工作中所需的交互式决策。在这里，我们介绍 AgentClinic：一个多模式基准，用于评估法学硕士在模拟临床环境中作为代理运作的能力。在我们的基准中，医生代理必须通过对话和主动数据收集来揭示患者的诊断。我们提出了两个开放基准：多模态图像和对话环境 AgentClinic-NEJM 和纯对话环境 AgentClinic-MedQA。 AgentClinic-MedQA 中的代理以美国医学执照考试 (USMLE) 中的案例为基础，AgentClinic-NEJM 中的代理以多模式新英格兰医学杂志 (NEJM) 案例挑战为基础。我们在患者和医生代理中嵌入认知和隐性偏见，以模拟有偏见的代理之间的现实互动。我们发现引入偏差会导致医生代理人的诊断准确性大幅降低，以及患者代理人的依从性、信心和后续咨询意愿的降低。通过评估一套最先进的法学硕士，我们发现一些在 MedQA 等基准测试中表现出色的模型在 AgentClinic-MedQA 中表现不佳。我们发现患者代理中使用的 LLM 是 AgentClinic 基准测试中性能的重要因素。我们表明，有限的相互作用和过多的相互作用都会降低医生代理的诊断准确性。   由   提交/u/panthsdger  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cw5luk/r_medical_language_agent_simulation_benchmark/</guid>
      <pubDate>Mon, 20 May 2024 03:01:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 模型并行性的最新技术是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cw35by/r_what_is_the_stateofart_of_model_parallelism/</link>
      <description><![CDATA[使用 PyTorch、Tensorflow 等常见框架实现模型并行是否容易？这取决于模型架构？模型并行性最常用的方法是什么？   由   提交/u/Various_Protection71   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cw35by/r_what_is_the_stateofart_of_model_parallelism/</guid>
      <pubDate>Mon, 20 May 2024 00:51:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] AlphaFold 3 的简化 PyTorch 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cw0n8b/p_simplified_pytorch_implementation_of_alphafold_3/</link>
      <description><![CDATA[       由    /u/csozboz  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cw0n8b/p_simplified_pytorch_implementation_of_alphafold_3/</guid>
      <pubDate>Sun, 19 May 2024 22:48:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您认为未来几年机器学习将在计算生物学和生物信息学等领域发挥什么作用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvxcbc/d_what_role_do_you_think_machine_learning_will/</link>
      <description><![CDATA[我相信计算生物学和生物信息学将越来越多地采用机器学习工作，我很高兴看到所取得的进步。我认为它将在将疾病与可能在标签外使用的现有药物相匹配方面开辟一个全新的世界。我们还应该注意哪些其他事情？ 谁是在这个世界上工作的研究人员？   由   提交/u/RawCS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvxcbc/d_what_role_do_you_think_machine_learning_will/</guid>
      <pubDate>Sun, 19 May 2024 20:19:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM可观察性工具真的在初创公司和公司中使用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvwohz/d_are_llm_observability_tools_really_used_in/</link>
      <description><![CDATA[每周都会推出许多 LLM 可观察性和监控工具。它们真的被真正的初创公司和公司使用吗？  这些工具似乎可以执行以下一项或多项操作： - 监控 LLM 输入和输出以发现提示注入、对抗性攻击、脏话、偏离主题的内容、RTC - &lt;随着时间的推移，监控 LLM 指标，例如成本、延迟、可读性、输出长度和自定义指标（语气、情绪等）、偏差 - 提示管理：a/b 测试、版本控制、黄金标准集 您观察到了什么 - 在拥有自己的 LLM 功能或产品的真实公司中，他们使用这些工具吗？   由   提交 /u/WolvesOfAllStreets   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvwohz/d_are_llm_observability_tools_really_used_in/</guid>
      <pubDate>Sun, 19 May 2024 19:50:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 是如何从从事令人兴奋的研究变成一家类似大型科技公司的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</link>
      <description><![CDATA[我最近重新审视了 OpenAI 关于 DOTA2 Open 的论文五，从工程和研究的角度来看，他们在那里所做的事情令人印象深刻。创建一个包含 50k 个 CPU 的分布式系统用于部署，1k 个 GPU 用于训练，同时每 0.25 秒从 16k 个观察中执行 8k 到 80k 个操作 - 这有多疯狂？他们还对 RL 模型进行“手术”以恢复权重，因为在几个月的训练中，他们的奖励函数、观察空间甚至架构都发生了变化。最后但并非最不重要的一点是，他们击败了 OG 队（当时的世界冠军），并部署了代理与其他玩家在线实时比赛。  快进几年，他们正在预测序列中的下一个标记。不要误会我的意思，gpt4 及其全能版本的功能确实是工程和研究的惊人壮举（可能更有用），但它们似乎并不像它们的一些产品那样有趣（从研究角度来看）  那么，现在我想知道这些年来工程师和研究人员是如何转变的？主要是由于他们的财务状况和盈利需要，还是有更深层次的原因进行转型？   由   提交 /u/UnluckyNeck3925   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</guid>
      <pubDate>Sun, 19 May 2024 16:46:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在机器学习中回收旧会议提交内容的文化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</link>
      <description><![CDATA[我从事统计机器学习工作。我注意到很多人（包括我自己和我审阅的人）经常重复他们向 ML 会议提交的论文。 例如，如果他们的论文被 ICML 拒绝，他们会提交给 NeurIPS，然后提交给 ICLR（或UAI/AISTATS 在我的领域也是顶尖的）。如果2~3次后没有进入ICML/NeurIPS/ICLR，他们就会将其提交给AAAI/IJCAI/TMLR/ICDM，T-NNLS/T-KDD/NN/Neurocomputing等期刊，或特定领域的场地，如LoG/CoLLA/AABI。经过所有这些，如果论文仍然没有被接受，他们就简单地将它们或 arXiv.我相信 CV/NLP 也可能是这种情况。 作为审稿人，我经常遇到会议提交的内容，作者在没有真正考虑之前提供的审稿的情况下重新提交。有时他们在重新提交时确实会纳入审稿意见，但有时工作可能只是达不到一级会议的水平，但他们只是不断重新提交并希望能够偶然被接受。 我认为这正在消耗社区审稿人的大量时间来继续审阅相同的提交内容（特别是考虑到 NeurIPS 达到 20k 提交 ID；我预计会看到许多重新提交）。这也许也是 TMLR 诞生的原因之一（强调正确性而不是新颖性）。 我确实理解“研究质量比发表地点更重要”之类的论点。或者“OpenAI 通常只是简单地将他们的论文（例如 GPT-X）放在 arXiv 上”。然而，学生或初级研究人员在他们的职业生涯中也需要发表论文，包括我自己。  人们对此有何看法？   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</guid>
      <pubDate>Sun, 19 May 2024 14:04:23 GMT</pubDate>
    </item>
    </channel>
</rss>