<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 25 Dec 2023 21:11:27 GMT</lastBuildDate>
    <item>
      <title>[D] 基于合成数据微调的 Whisper 模型实时性能较差</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qpd7c/d_poor_realtime_performance_of_whisper_models/</link>
      <description><![CDATA[大家好， 我有植物病害名称和植物名称的自定义文本数据，如下所示： uuid，上下文 1er1hhaj13，杜鹃花是一种流行的观赏植物，经常遭受 Phytophthora ramorum 的侵害，这是一种难以控制和诊断的疾病。这种病原体会导致橡树突然死亡，从而导致受感染植物的严重损害和死亡。  我使用语音转文本 API 将此上下文转换为音频 WAV 文件，选择了 10 个主要带有美国/英国/英国口音的扬声器。因此，我创建了大约 5k 个样本用于训练，以及大约 2k 个样本用于测试。  我遵循“快速耳语微调”微调 Whisper Large-v2 的 peft 版本。训练和验证损失看起来不错： Step |训练损失|验证损失 250 | 0.413000 | 0.102663 500 | 0.109900 | 0.130888 750 | 0.116500 | 0.102719 1000 | 0.092800 | 0.099153 1250 | 0.068800 | 0.075613 1500 | 0.042500 | 0.085680 1750 | 0.047500 | 0.076951 2000 | 0.027500 | 0.065127 2250 | 0.023700 | 0.061832 2500 | 0.012500 | 0.062658 2750 | 0.011500 | 0.061922 3000 | 0.008500 | 0.061463 3250 | 0.005300 | 0.060227 3500 | 0.003800 | 0.060712 3750 | 0.002700 | 0.060332 4000 | 0.002300 | 0.060496  当我根据测试数据计算 WER 时： ​  OpenAI Whisper API：测试时的 WER 为 22.03数据 微调模型：测试数据的 WER 为 0.3  看起来不错。然而，在对印度英语观众进行实时测试时，植物名称和疾病名称的准确性并不令人满意。我们可以采用什么策略来提高实时设置的准确性？ 任何有关此事的指导或建议将不胜感激。谢谢！   由   提交 /u/aadityaura   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qpd7c/d_poor_realtime_performance_of_whisper_models/</guid>
      <pubDate>Mon, 25 Dec 2023 19:36:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] ISIS 2018 任务3</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qmqt6/p_isis_2018_task3/</link>
      <description><![CDATA[大家好，我正在使用 ResNet50 模型完成 ISIC 2018 挑战赛的任务 3，并结合 dropout 层、正则化和实现数据增强。然而，迄今为止我达到的最高准确率仅为 76%。我想改进它，使我的模型达到 &gt;= 80% 的性能。有人可以帮我解决这个问题吗？提前感谢大家。  我在 Kaggle 上的工作   由   提交/u/No_Essay_4430   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qmqt6/p_isis_2018_task3/</guid>
      <pubDate>Mon, 25 Dec 2023 17:18:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] OCR 用于从购物收据中提取文本。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qki38/p_ocr_for_extracting_text_from_shopping_receipts/</link>
      <description><![CDATA[大家好， TLDR：目前可用于从购物收据中提取文本的最佳开源/DIY 选项是什么？我没有付费 API 的预算，但如果它足够便宜，那么当然可以。 我一直在尝试使用 Tesseract，当我小心拍照时，准确率约为 80-90%收据。到目前为止，我还没有完全探索出最佳的预处理步骤。但我主要进行灰度、对比度调整和伽玛校正，而不是以任何有条理的方式。我在这里需要更多测试。 收据有各种字体。 它们可能会起皱。 照片并不总是完美对齐，可能会旋转。 透视并不总是“正交（垂直。）” 我认为在执行 OCR 之前我需要执行以下操作： -旋转以对齐。 -修复透视。  -使用展开 我读过有关 EasyOCR 的内容，但尚未尝试过。我还在这里发现有些人针对他们的用例微调了一些模型。我愿意了解这是否是我最好的长期解决方案。 我希望解决这个问题既是一种挑战，也是一种学习经历，同时也是创造一些非常有用的东西。这就是为什么我在这里寻求您的建议，我认为这是一个常见问题。我愿意接受任何解决方案。如果我试图解决错误的问题，请告诉我。 提前非常感谢您。   由   提交 /u/hzeta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qki38/p_ocr_for_extracting_text_from_shopping_receipts/</guid>
      <pubDate>Mon, 25 Dec 2023 15:17:04 GMT</pubDate>
    </item>
    <item>
      <title>深度学习/计算机视觉 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qk9a0/deep_learning_computer_vision_p/</link>
      <description><![CDATA[在过去的十年里，我一直是一名 ML 工程师，从事网络、路由优化等工作，所以我对 ML 和 DL 略知一二，但自从我读研究生以来，我就没有再接触过计算机视觉。  一位负责残障人士团体的朋友找到我，询问是否可以使用相机+将其与某种机器学习计算机视觉系统连接起来，该系统可以识别障碍物和距离+为能够识别障碍物和距离的人提供耳机。他们无力承担导盲犬的费用，只能拄着拐杖，让它们了解更多有关周围环境的信息。这个想法将是短句，例如“十米内的街道”、“正前方的树”。  她让我研究一下这个问题，我对找到整个主题的良好切入点感到有点不知所措。我认为这需要一个蓝牙摄像头、某种实时操作系统+便携式？计算硬件。我认为这不应该是完全不可能的，因为自动驾驶需要更高的准确度，但该领域所做的一切可能都是专有的？ 除了愿意支付硬件费用的赞助商，所以任何开源的东西都会很棒。 我经常阅读 OpenCV，但是当我开始谷歌搜索时，还有其他我应该了解的库或工具吗？ ？是的，所以基本上任何关于 CV+ML 信息的想法和介绍都会被假设：我应该查看哪些好文章？这已经完成了吗，我可以在某个地方下载它:)？是不是完全无法撤销？    由   提交 /u/tessherelurkingnow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qk9a0/deep_learning_computer_vision_p/</guid>
      <pubDate>Mon, 25 Dec 2023 15:02:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 需要数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qjm9n/p_require_datasets/</link>
      <description><![CDATA[我目前正在开发一个基于农业的聊天机器人。那么，你们中的一些人能否提供有关农作物、农作物气候条件、植物病害和首选治疗方法、陆地农作物种植等的良好数据源。   由   提交/u/Sreehari_J_Nair   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qjm9n/p_require_datasets/</guid>
      <pubDate>Mon, 25 Dec 2023 14:24:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] 没有足够的 GPU 来训练 Mixtral？何不试试LLaMA-MoE~</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qh2ch/p_dont_have_enough_gpu_to_train_mixtral_why_not/</link>
      <description><![CDATA[LLaMA-MoE 是一系列基于 LLaMA 和 SlimPajama 的开源 Mixture-of-Expert (MoE) 模型。我们通过以下两个步骤构建 LLaMA-MoE：  将 LLaMA 的 FFN 划分为稀疏专家，并为每层专家插入 top-K 门。 持续预训练初始化的 MoE 模型，具有来自 Sheared LLaMA 的优化数据采样权重和来自 SlimPajama 的过滤数据集。  如果您没有足够的计算资源来训练 Mixtral，您可能想尝试 LLaMA -MoE 用于下游研究。 查看：pjlab-sys4nlp/llama-moe    由   提交 /u/Spico197   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qh2ch/p_dont_have_enough_gpu_to_train_mixtral_why_not/</guid>
      <pubDate>Mon, 25 Dec 2023 11:36:51 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]在法学硕士时代，Transformer架构有哪些局限性和缺点？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qh1hp/discussion_in_this_age_of_llms_what_are_the/</link>
      <description><![CDATA[      ​ 变压器   由   提交 /u/dontgimmehop​​e   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qh1hp/discussion_in_this_age_of_llms_what_are_the/</guid>
      <pubDate>Mon, 25 Dec 2023 11:35:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 预训练数据集对未来fintune的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qgdwf/d_pretrained_dataset_effect_on_future_fintune/</link>
      <description><![CDATA[我们将在现有基础模型上执行持续预训练（也称为域自适应预训练）。我们的预训练数据集的大小相对较小，我们担心这将如何影响结果。我们是否应该关心用于基础模型的持续预训练的数据集的大小与用于创建模型的原始数据集的大小。这对结果有影响吗？   由   提交 /u/MustafaAlahmid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qgdwf/d_pretrained_dataset_effect_on_future_fintune/</guid>
      <pubDate>Mon, 25 Dec 2023 10:45:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我可以在 8 * A100 40GB 上微调 Mistral 7B 型号吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qgcsk/d_can_i_fintune_mistral_7b_model_on_8_a100_40gb/</link>
      <description><![CDATA[我想要微调 Mistral 7B，并且我可以访问 8 A100 40GB，并且我正在进行全面微调，而不是 Lora 这可能吗？或者我至少需要A100 80GB？  如何计算最低要求？   由   提交 /u/MustafaAlahmid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qgcsk/d_can_i_fintune_mistral_7b_model_on_8_a100_40gb/</guid>
      <pubDate>Mon, 25 Dec 2023 10:42:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可以 ping 运行脚本的按需 GPU</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qeudq/d_ondemand_gpu_that_can_be_pinged_to_run_a_script/</link>
      <description><![CDATA[是否存在一项服务，我可以每月使用 GPU 3-6 小时（一个请求），并且可以使用链接或其他东西，以便我可以自动化它？ 如果您熟悉 Azure 功能，我想要类似的服务，但使用 GPU，而且我只需要按 3-6 小时付费。我不想托管虚拟机一个月，因为它每月仅运行 3-6 小时。   由   提交/u/Level_Programmer4276   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qeudq/d_ondemand_gpu_that_can_be_pinged_to_run_a_script/</guid>
      <pubDate>Mon, 25 Dec 2023 08:40:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为开源项目寻求建议和团队成员</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qeoyt/d_seeking_suggestions_and_team_members_for_an/</link>
      <description><![CDATA[嘿，我正在为一个开源项目寻求建议和团队成员。我的目标是通过使用 llama 2 或 mixtral 微调基本模型来创建农业语言模型 (LLM)。我来自孟加拉国，一个以农业为基础的国家，我相信这样的模式是非常有益的。我当前的计划涉及创建两个模型 - 一个基本模型和一个聊天模型。已经有很多农业数据集可用。这些数据集的主要重点将放在提高作物产量、降低风险、减少环境影响、提高质量、与农业相关的研究和财务等方面。 此外，我的目标是收集有关植物医学的信息，以及当地人提供的化学名称，包括品牌名称。例如，如果有人询问白粉病的植物药名称，模型不仅会提供解决方案，还会呈现市场上可用的产品名称（包括品牌）列表。 未来，我的计划还包括将视觉模型与聊天模型集成，直接检测植物病害并提供解决方案。已经有很多开源植物检测系统示例可用，我相信我们不需要从头开始创建一个；我们可以简单地将它与聊天LLM集成。 您对这个计划有何看法？您认为它可行并且会产生有用的法学硕士模型吗？我也在寻找团队成员，尤其是像我一样刚进入这个领域的人。对于我们俩来说，这可能是一个学习曲线，特别是对于那些有兴趣学习微调 LLM 模型的人。   由   提交/u/omni7894  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qeoyt/d_seeking_suggestions_and_team_members_for_an/</guid>
      <pubDate>Mon, 25 Dec 2023 08:29:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们真的知道令牌概率如何导致推理吗？例如，当我们给 GPT4 一个谜语，而它使用非直观的逻辑来解决这个谜语时，这是怎么发生的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18q9ucf/d_do_we_really_know_how_token_probability_leads/</link>
      <description><![CDATA[GPT4 可以轻松解决以下非常基本的谜语/问题。 谜语示例：您有一个杯子和一个球。将球放在桌子上，然后将杯子放在球上。然后将杯子放在厨房柜台上。球在哪里？ 答案：当然还在原来的桌子上。 概率引擎如何知道这个推理？   由   提交 /u/Artistic-Life-6562   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18q9ucf/d_do_we_really_know_how_token_probability_leads/</guid>
      <pubDate>Mon, 25 Dec 2023 02:51:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深入探讨 Mamba、内存和 SSM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18q7lqo/d_deep_dive_on_mamba_memory_and_ssm/</link>
      <description><![CDATA[https://youtu.be/X5F2X4tF9iM   由   提交 /u/Gold-Courage8937    reddit.com/r/MachineLearning/comments/18q7lqo/d_deep_dive_on_mamba_memory_and_ssm/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18q7lqo/d_deep_dive_on_mamba_memory_and_ssm/</guid>
      <pubDate>Mon, 25 Dec 2023 00:30:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言模型、代理模型和世界模型：机器推理和规划的法则</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18q6zuy/r_language_models_agent_models_and_world_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.05230 摘要：  尽管大型语言模型在许多应用中取得了巨大成功，但它们经常会失败由于推理、学习和建模能力的固有局限性，缺乏在各种（语言、具体和社交）场景中一致的推理和规划。在这篇立场文件中，我们提出了机器推理的新视角，LAW，它连接了语言模型、代理模型和世界模型的概念，以获得更强大和通用的推理能力。特别是，我们提出世界和代理模型是推理的更好抽象，它引入了深思熟虑的类人推理的关键要素，包括对世界和其他代理的信念、对结果的预期、目标/奖励和战略规划。至关重要的是，LAW 中的语言模型充当实现系统或其元素的后端，从而提供计算能力和适应性。我们回顾了最近取得相关进展的研究，并讨论了 LAW 框架实施的未来研究方向。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18q6zuy/r_language_models_agent_models_and_world_models/</guid>
      <pubDate>Sun, 24 Dec 2023 23:55:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>