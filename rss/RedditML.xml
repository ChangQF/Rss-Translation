<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Wed, 31 Jul 2024 21:15:03 GMT</lastBuildDate>
    <item>
      <title>[D] 平衡双摆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egy81m/d_balancing_a_double_pendulum/</link>
      <description><![CDATA[双摆是非确定性/混沌系统的最佳示例之一，因此产生了构建一个能够使其在直立位置保持平衡的模型的想法。双摆不是连接到固定点，而是连接到可移动（可控制）的滑块。 这是当前的进展：Balancing-Double-Pendulum 至于模型，我认为使用物理信息神经网络 (PINN) 是与遗传算法一起的最佳选择。当前的实现使用了基于简单公式的近似值，但显然某种积分器会更好（为了节约能源）。 目前，模拟无需使用任何优化算法就能正常工作，但如果需要的话 - 我认为 QuadTree 可以完成这项工作。 在模型和模拟方面我应该做任何改进吗？    提交人    /u/Mynameiswrittenhere   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egy81m/d_balancing_a_double_pendulum/</guid>
      <pubDate>Wed, 31 Jul 2024 20:57:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果您只有 60 分钟，最好的 automl 回归工具是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egy12e/d_best_automl_regression_tool_if_you_only_have_60/</link>
      <description><![CDATA[如果给你 60 分钟的时间来构建最准确的 (rmse) 回归模型，现在会使用哪种 automl 工具？我假设表格数据和大约 10,000 行。 我发现 autogluon.tabular 令人印象深刻而 tpot 太慢，但我没有尝试任何其他。这适用于仅限 CPU 的系统。    提交人    /u/MrMrsPotts   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egy12e/d_best_automl_regression_tool_if_you_only_have_60/</guid>
      <pubDate>Wed, 31 Jul 2024 20:50:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您是否尝试过使用讲师库进行 NER？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egvr3c/d_have_you_attempted_ner_with_instructor_lib/</link>
      <description><![CDATA[我正在研究命名实体提取而不是识别。主要思想是使用具有特定指令的 LLM 将非结构化文本中的实体（如日期、位置和名称）提取到繁琐的模型中。逻辑工作正常，但与类型相关的验证错误不一致。有时错误经常发生，有时几乎不发生。例如，预期类型可能是字符串列表，但 LLM 输入可能是“[&#39;name1&#39;, &#39;name2&#39;, ...]”之类的东西，或者只是没有括号的文字。添加字段验证器似乎无助于匹配。有没有人遇到过这种情况，并找到了最适合 LLM 输入后处理或通过重试处理错误的方法？    提交人    /u/Useful_Anybody_9351   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egvr3c/d_have_you_attempted_ner_with_instructor_lib/</guid>
      <pubDate>Wed, 31 Jul 2024 19:17:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 逻辑回归如何学习多类问题的决策界面？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egv40h/d_how_can_a_logistic_regression_learn_this/</link>
      <description><![CDATA[我使用 Scikit-Learn 的 LogisticRegression 实现在 Iris 数据集上训练模型，该数据集有 3 个类。对于 multi_class 参数，我传入了“multi_class=ovr”。据我了解，这应该训练 3 个独立的二元分类器，对于输入平面中的任何点，我们都分配得分最高的分类器的标签。 https://preview.redd.it/jonk35uqgwfd1.png?width=985&amp;format=png&amp;auto=webp&amp;s=08cdcab5151ac065a8b0b94f3ad3225ce8539fa4 我理解红点和绿点是如何分类的，因为红点可以从蓝点和绿点的组合中线性分离点，并且绿点也可以与蓝点和红点的组合线性分离。但是我对如何为蓝点训练二元分类器感到困惑，因为包含红点和绿点的“其他类”位于蓝点的两侧。Scikit-Learn 是否只训练 2 个分类器并将在任何一个分类器上得分不大于 0.5 的点标记为蓝色？    提交人    /u/Money_Ferret_4782   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egv40h/d_how_can_a_logistic_regression_learn_this/</guid>
      <pubDate>Wed, 31 Jul 2024 18:52:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 注释词汇表（可能）就是您所需要的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egthqg/r_annotation_vocabulary_might_be_all_you_need/</link>
      <description><![CDATA[论文链接：https://www.biorxiv.org/content/10.1101/2024.07.30.605924v1 摘要：  蛋白质语言模型 (pLM) 彻底改变了蛋白质系统的计算建模，构建了以结构特征为中心的数值嵌入。为了增强蛋白质嵌入中可用的生化相关属性的广度，我们设计了注释词汇表，这是一种由结构化本体定义的蛋白质属性的转换器可读语言。我们从头开始训练注释变换器 (AT)，以恢复掩蔽的蛋白质属性输入，而无需参考氨基酸序列，仅基于蛋白质描述构建新的数值特征空间。我们在各种模型架构中利用 AT 表示，用于蛋白质表示和生成。为了展示注释词汇集成的优点，我们进行了 515 次不同的下游实验。使用新颖的损失函数和仅 3 美元的商业计算，我们的首要表示模型 CAMP 为 15 个常见数据集中的 5 个生成了最先进的嵌入，其余数据集上的性能也具有竞争力；凸显了使用注释词汇进行潜在空间管理的计算效率。为了标准化从头生成的蛋白质序列的比较，我们提出了一种新的基于序列比对的分数，它比传统的语言建模指标更灵活、更具生物学相关性。我们的生成模型 GSM 使用类似 BERT 的生成方案从仅注释提示中生成高比对分数。特别值得注意的是，许多 GSM 幻觉返回具有统计意义的 BLAST 命中，其中富集分析显示与注释提示匹配的属性 - 即使基本事实与整个训练集的序列同一性较低。总体而言，注释词汇工具箱提供了一种有前途的途径，可以用本体和知识图谱的成员取代传统的标记，增强特定领域的变换器模型。注释词汇对蛋白质的简洁、准确和有效的描述为构建蛋白质的数值表示以进行蛋白质注释和设计提供了一种新颖的方法。  我们很自豪地宣布发布我们的最新作品！请阅读、分享并提出任何问题！    提交人    /u/TeamArrow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egthqg/r_annotation_vocabulary_might_be_all_you_need/</guid>
      <pubDate>Wed, 31 Jul 2024 17:47:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 无限上下文长度真的可能吗？：“Unlimiformer”作者周五讨论 NeurIPS 论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egqitt/d_is_unlimited_context_length_really_possible/</link>
      <description><![CDATA[无限上下文长度真的可能吗？代价是什么？ 2023 年 NeurIPS 论文 Unlimiformer 的作者 Amanda Bertsch 将在本周五的 Oxen.ai 论文俱乐部中描述该架构并回答问题。  Oxen 首席执行官兼 Plain Speak 大师 Greg Schoeninger u/FallMindless3563 将帮助解释该概念并将其与我们审阅过的其他论文联系起来。 致电：https://oxen.ai/community  声称使无限上下文长度成为可能的技巧：将交叉注意力计算卸载到 K-最近邻 (K-NN) 索引。  我在这里发了一条推文，其中某人制作了巧妙的 K-NN 动画：https://x.com/mustafarrag/status/1817647917059944474 论文：https://arxiv.org/abs/2305.01625 Greg，我将用我的前 5 个问题来回答。到目前为止，我只阅读了摘要。    提交人    /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egqitt/d_is_unlimited_context_length_really_possible/</guid>
      <pubDate>Wed, 31 Jul 2024 15:47:52 GMT</pubDate>
    </item>
    <item>
      <title>[N] Finegrain 的对象橡皮擦演示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egpu9b/n_object_eraser_demo_by_finegrain/</link>
      <description><![CDATA[      对象橡皮擦 Finegrain 刚刚在 Huggingface 上发布了一个对象橡皮擦的演示。该模型可以删除任何对象或图像，并删除来自对象的任何效果（阴影、反射、光线）。与我们迄今为止拥有的其他橡皮擦相比，结果令人印象深刻；你怎么看？ 演示链接：https://huggingface.co/spaces/finegrain/finegrain-object-eraser    由   提交  /u/nota-Reddit   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egpu9b/n_object_eraser_demo_by_finegrain/</guid>
      <pubDate>Wed, 31 Jul 2024 15:20:10 GMT</pubDate>
    </item>
    <item>
      <title>为大型语言模型提供更好内存的框架 - 免费且开源。[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egmmpe/a_framework_to_give_large_language_models_better/</link>
      <description><![CDATA[Github - https://github.com/chisasaw/redcache-ai 使用的 SDK [scikit-learn、numpy 和 openai] 什么？ 在构建聊天应用程序时，我找不到经济高效、可扩展且价格合理的内存层。这导致了 redcache-ai。它是一个提供语义搜索、存储和检索增强生成 (RAG) 的 Python 包。 用例？ 如果开发人员想要构建使用文档摘要和/或语义搜索的桌面应用程序，开发人员可以使用 redcache-ai 和选择的大型语言模型提供程序。聊天应用程序存储用户会话也是如此。 优点？  易于使用。只需像安装 Python 包一样安装它，即“pip install redcache-ai”。 提供存储可扩展性。将您的记忆存储到磁盘、sqlite 或您选择的数据库中。  请提供反馈并提出问题。也可以随时为项目做出贡献。    提交人    /u/hack_knight   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egmmpe/a_framework_to_give_large_language_models_better/</guid>
      <pubDate>Wed, 31 Jul 2024 13:02:41 GMT</pubDate>
    </item>
    <item>
      <title>关于使用知识图谱的神经符号人工智能的调查论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egke1v/survey_paper_over_neurosymbolic_ai_with_knowledge/</link>
      <description><![CDATA[  由    /u/joestomopolous  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egke1v/survey_paper_over_neurosymbolic_ai_with_knowledge/</guid>
      <pubDate>Wed, 31 Jul 2024 11:06:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 的 CLIP 替代方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egi7sz/d_openais_clip_alternative/</link>
      <description><![CDATA[嗨，有没有像 CLIP 这样的新 SOTA 模型？我想对文本和图像进行语义搜索，但 CLIP 的性能对我的项目来说不是很好。    提交人    /u/sushilkhadakaanon   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egi7sz/d_openais_clip_alternative/</guid>
      <pubDate>Wed, 31 Jul 2024 08:44:56 GMT</pubDate>
    </item>
    <item>
      <title>情境学习中的突发性 [R][D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egcudr/burstiness_in_incontext_learning_rd/</link>
      <description><![CDATA[      0 我正在阅读论文上下文分类中数据依赖和突发学习的机制基础任务。我对参数化数据分布部分感到非常困惑。  这个“数据分布”是指训练数据还是测试数据？（两者都是一批输入序列。） 对于那些突发序列，类别究竟是如何分布的？这是否就像来自特定（随机选择）类别的 B 个项目，然后其余 N-B 个项目遵循剩余类别的等级频率分布？  https://preview.redd.it/43tvem1qtrfd1.png?width=1678&amp;format=png&amp;auto=webp&amp;s=465e9df8a20ceb6e79dc07f56c9c5fbc341b1ab3   由    /u/mziycfh  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egcudr/burstiness_in_incontext_learning_rd/</guid>
      <pubDate>Wed, 31 Jul 2024 03:10:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]关于知识图谱和图神经网络的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eg674y/discussion_thoughts_on_knowledge_graphs_and_graph/</link>
      <description><![CDATA[几年前，我的数据科学团队梦想着实现知识图谱并利用图神经网络。这种方法在我所在的行业——金融领域似乎特别有前景，因为它可以让模型捕捉间接关系——例如，所有权变更如何影响公司的业绩。 当时，这感觉就像一场白日梦。捕捉任何关系（例如“拥有”或“销售产品”）都需要自己的 NLP 模型。然而，LLM 的出现大大降低了这种复杂性（现在已在 LlamaIndex 中实现）。所以我们想知道是否应该再试一次 KG 和 GNN。我们的想法是使用 LLM 来帮助我们构建 KG，并将来自其他数据库的数据添加到其中。然后，我们将训练 GNN 来预测诸如“公司 A 会收购公司 B 吗”或“公司 C 的表现会优于公司 D 吗”之类的事情。 然而，尽管 GNN 经常被吹捧为下一个大事件，但它仍然有点小众。好吧，它们被用来补充 RAG，但我还没有听说过任何非大型科技公司建立自己的超级知识图谱。根据我所读到的内容，图形数据库面临着大量的批评，原因是性能问题和创建有效模式的难度等。 您对这些技术有什么经验？您有什么成功案例或警示故事可以分享吗？ [编辑]这篇文章比我想象的要受到更多的关注，所以我对其进行了一些修改，以节省大家的时间。具体来说，我试图澄清 KG 和 GNN 是不同的。这两种技术的融合似乎很有希望，但我有两个大担忧：  领先的图形数据库提供商 Neo4j 似乎是该主题的主要知识提供者。它甚至撰写了至少两本由 O&#39;Reilly(!) 编辑的书，因此很难了解知识图谱的陷阱。 据我所知，几乎没有人大规模实施过 GNN。     提交人    /u/MeditationBeginner   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eg674y/discussion_thoughts_on_knowledge_graphs_and_graph/</guid>
      <pubDate>Tue, 30 Jul 2024 22:05:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2024 论文评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efscr2/d_neurips_2024_paper_reviews/</link>
      <description><![CDATA[NeurIPS 2024 论文评审将于今日发布。我想创建一个讨论主题，让我们讨论任何问题/抱怨/庆祝或其他任何事情。 每年的评审中都有这么多噪音。考虑到 NeurIPS 这些年来发展如此之大，一些作者引以为豪的好作品可能会因为嘈杂的系统而获得低分。我们应该记住，无论分数如何，这项工作仍然很有价值。    提交人    /u/zy415   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efscr2/d_neurips_2024_paper_reviews/</guid>
      <pubDate>Tue, 30 Jul 2024 12:42:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jul 2024 15:00:14 GMT</pubDate>
    </item>
    </channel>
</rss>