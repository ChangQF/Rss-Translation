<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 03 May 2024 18:17:06 GMT</lastBuildDate>
    <item>
      <title>[R][D] 用于提高 RNN 性能的时间序列量化（LLM 的可能用例）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjdxn7/rd_quantization_of_timeseries_for_improving/</link>
      <description><![CDATA[大家好， 想问一下你们中是否有人有使用量化/分级版本的功能集和/或设定目标以提高序列学习者解决时间序列问题的性能。 我对 NLP 不是很擅长，因此对可能出现的任何错误表示歉意 设置-上： f(X) -&gt; ŷ 目标为 |ŷ-y| &lt; eps X 是一个特征集，其中的特征有望为 y 提供信息，信息频率不同，例如作为玩具示例，每个特征维度具有不同窗口的简单移动平均值。 X 和 y 很嘈杂 动机 我最近看到了一些修改单变量时间序列预测问题的工作，以便法学硕士可以理解它们，特别是：Chronos：学习时间序列的语言 一般方法是  缩放时间以某种方式系列，例如将每个序列除以平均绝对值 将这些值合并以使可能的值现在离散 添加开始/结束标记以便LLM可以消化，然后用于预测  万岁，现在我们有了一个可以传递到 LLM 的时间序列 RNN 的量化，而不是 LLM 退一步说，我想知道这里是否有人使用这些技术来使时间序列更适合 RNN，而不是使用上述转换来与 LLM 一起使用。变换的两个重要部分是（1）缩放技术和（2）箱数N。无穷大，我们得到与原始时间序列相同的精度。 量化作为函数 Q(.) 可以应用于 X、y 或两者。我想到的好处：  使用整数作为容器的引用，以实现更快/更轻松的交易 减少信号中的噪声 使用特征嵌入的可能性？  希望这一点很清楚。感谢任何帮助。   由   提交 /u/HungryhungryUgolino   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjdxn7/rd_quantization_of_timeseries_for_improving/</guid>
      <pubDate>Fri, 03 May 2024 17:10:48 GMT</pubDate>
    </item>
    <item>
      <title>[N] 人工智能工程师报告称，科技行业为了保持竞争力而进行的“激烈竞争”，导致了职业倦怠和仓促推出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjdmr5/n_ai_engineers_report_burnout_and_rushed_rollouts/</link>
      <description><![CDATA[人工智能工程师将职业倦怠和仓促推出视为保持竞争力的“老鼠赛跑”打击了科技行业 文章摘要：   顶级科技公司的人工智能工程师告诉 CNBC，以极快的速度推出人工智能工具的压力已经决定了他们的工作。 他们表示，他们的大部分工作都是为了安抚投资者，而不是为最终用户解决问题，而且他们经常追逐 OpenAI。 倦怠是一个越来越普遍的主题，因为人工智能工作者表示，他们的雇主在开展项目时没有考虑到该技术对气候变化、监视和其他潜在现实世界危害的影响。 倦怠是一个越来越普遍的主题。 em&gt;  这篇文章中引用了一段特别深刻的话：  一位在零售监控初创公司工作的人工智能工程师告诉 CNBC，他是他是一家 40 人公司中唯一的 AI 工程师，负责处理与 AI 相关的任何职责，这是一项艰巨的任务。他表示，公司的投资者对人工智能的能力有不准确的看法，经常要求他构建某些“我无法交付”的东西。    由   提交/u/bregav  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjdmr5/n_ai_engineers_report_burnout_and_rushed_rollouts/</guid>
      <pubDate>Fri, 03 May 2024 16:58:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 设计图形的软件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjb4da/d_software_to_design_figures/</link>
      <description><![CDATA[       我想为 rl 算法创建图表/图形。我真的很喜欢 Deep Mind 论文中使用的风格（AlphaZero、AlphaTensor、MuZero，...）。有谁知道这些图片用的软件吗？或者也许还有其他可以达到类似结果的东西？ https://preview.redd.it/4uohkcbxg8yc1.png?width=791&amp;format=png&amp;auto=webp&amp;s=9136bd12eb797523a5ff73f2b0b02e811239d9c3 https://preview.redd.it/1vzin9izg8yc1.png?width=578&amp;format=png&amp; auto=webp&amp;s=8046e1196347365b48ad2d3920ee0ba18119600c   由   提交 /u/_Hardric   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjb4da/d_software_to_design_figures/</guid>
      <pubDate>Fri, 03 May 2024 15:13:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 产品分析中的因果推理与观察数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjad7m/d_causal_inference_vs_observational_data_within/</link>
      <description><![CDATA[我正在与一位同事进行讨论，我们希望从社区获得一些想法。 （一开始是无辜的，现在已经变成了一场激烈的争论）。 如果您适合这部分人，我们很乐意了解您的观点：  您&#39;已经研究过因果推理（不仅仅是阅读了相关的媒体文章，而是读了几本书、学习了一门课程和/或使用了这些方法） 并且您具有分析产品分析事件日志的背景（ GA4、Adobe、Snowplow 等） 并且您与营销/产品团队合作，支持网络应用程序/数字体验的产品分析。  如果您符合根据上面的细分逻辑，我们有一个问题要问您：  根据您的因果推理知识，当营销人员要求您提取网络应用程序上极其特定的用户细分的使用行为时，您会怎么做并与其他细分市场进行比较？对于特定的会话流程等也有同样的问题。您觉得简单地进行它吗？你会尝试调整选择偏差吗？ （他们关心吗？）  我个人在协调这两个知识领域时遇到了困难，这让我质疑许多产品分析工具的价值与噪音。我的同事的立场是“这并不是真正的问题”，并且“如果他们想要一台可以 ping 的机器，就给他们（monty python 参考）。   由   提交/u/what-is-neurotropic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjad7m/d_causal_inference_vs_observational_data_within/</guid>
      <pubDate>Fri, 03 May 2024 14:41:38 GMT</pubDate>
    </item>
    <item>
      <title>机器学习部署中的道德困境 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cja4q8/ethical_dilemmas_in_machine_learning_deployment/</link>
      <description><![CDATA[我最近和同事讨论了几个问题，我想更广泛地了解人们的想法，所以决定向这个 Reddit 子版块提出问题， 谢谢。  我们如何平衡透明度、公平和问责制的道德要求与在现实决策环境中部署机器学习模型的实际需要？  组织可以采用哪些策略、框架或最佳实践来有效应对这些挑战，同时确保道德诚信和运营效率？  &amp;# 32；由   提交/u/Old_Coder45   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cja4q8/ethical_dilemmas_in_machine_learning_deployment/</guid>
      <pubDate>Fri, 03 May 2024 14:31:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何训练文本检测模型来检测 +180 到 -180 度的方向（旋转）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cja2s8/d_how_to_train_a_text_detection_model_that_will/</link>
      <description><![CDATA[大多数模型似乎都能够检测旋转的物体，但它们使用所谓的 le90 约定，其中物体从 +90 度旋转到 -90 度。在我的例子中，我想以正确的方向检测图像上的文本，这意味着在我的例子中 0 度和 180 度是不同的（在 MMOCR、MMDET 和 MMRotate 模型中就是这种情况）。 &lt; p&gt;你能指导我解决这个问题吗？我该如何处理这个问题？您有解决这个问题的一些开源项目的链接吗？ 我知道通常可以通过训练另一个小模型或通过训练所有可能的旋转的识别阶段来解决文本方向问题，但我想在检测阶段尽早解决这个问题。任何想法将不胜感激。提前致谢。   由   提交 /u/tmargary   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cja2s8/d_how_to_train_a_text_detection_model_that_will/</guid>
      <pubDate>Fri, 03 May 2024 14:29:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] HGRN2：具有状态扩展的门控线性 RNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj4ouc/r_hgrn2_gated_linear_rnns_with_state_expansion/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.07904 代码：https://github .com/OpenNLPLab/HGRN2 独立代码 (1):  https://github.com/Doraemonzzz/hgru2-pytorch 独立代码 (2): https://github.com/sustcsonglin/flash-linear-attention/tree/main/fla/models/hgrn2 摘要：  分层门控线性 RNN（HGRN，Qin 等人，2023 ）在语言建模方面展示了有竞争力的训练速度和性能，同时提供了高效的推理。然而，HGRN 的循环状态大小仍然相对较小，这限制了其表达能力。为了解决这个问题，受线性注意力的启发，我们引入了一种简单的基于外积的状态扩展机制，以便可以在不引入任何额外参数的情况下显着扩大循环状态大小。线性注意力形式还允许进行硬件高效的训练。我们大量的实验验证了 HGRN2 在语言建模、图像分类和 Long Range Arena 方面相对于 HGRN1 的优势。我们最大的 3B HGRN2 模型在受控实验设置中的语言建模方面略优于 Mamba 和 LLaMa Architecture Transformer；并且在下游评估中与许多开源 3B 模型竞争，同时使用更少的总训练令牌。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj4ouc/r_hgrn2_gated_linear_rnns_with_state_expansion/</guid>
      <pubDate>Fri, 03 May 2024 09:47:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于 Transformer 的语言模型内部工作原理入门</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj4o70/r_a_primer_on_the_inner_workings_of/</link>
      <description><![CDATA[      作者：Javier Ferrando (UPC)、Gabriele Sarti (RUG)、Arianna Bisazza （RUG），Marta Costa-jussà（元） 论文： https://arxiv .org/abs/2405.00208 摘要：  旨在解释高级语言内部运作方式的研究的快速进展模型强调需要将从该领域多年的工作中获得的见解结合起来。本入门书对用于解释基于 Transformer 的语言模型的内部工作原理的当前技术进行了简明的技术介绍，重点关注仅生成解码器的架构。最后，我们对这些模型实现的已知内部机制进行了全面概述，揭示了该领域流行方法和活跃研究方向之间的联系。  https://preview.redd.it/57y44wwdn6yc1.png?width=1486&amp;format= png&amp;汽车=webp&amp;s=7b7fb38a59f3819ce0d601140b1e031b98c17183   由   提交 /u/SubstantialDig6663   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj4o70/r_a_primer_on_the_inner_workings_of/</guid>
      <pubDate>Fri, 03 May 2024 09:46:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对特定领域数据微调 Phi-3 模型 - 寻求建议和见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj2hzb/d_finetune_phi3_model_for_domain_specific_data/</link>
      <description><![CDATA[      嗨， 我目前正在工作微调金融数据的 Phi-3 模型。虽然训练过程中损失不断减少，表明模型学习得很好，但自定义基准测试的结果却出人意料地差。事实上，与基础模型相比，准确性有所下降。 我观察到的结果：  Phi-3-mini-4k-instruct（基础模型）：平均域准确度为 40% Qlora - Phi-3-mini-4k-instruct（微调模型）：平均域准确度为 35%  我有尝试了各种方法，包括 QLora、Lora 和 FFT，但与基本模型相比，所有结果都很差。而且，我还尝试过将序列长度减少到2k，试图约束模型，防止模型偏离轨道，但不幸的是，这并没有带来任何改善。 我想知道超参数是否可能存在问题（例如学习率），或者是否有任何关于如何有效地微调此模型以在特定领域数据上获得更好性能的建议。 如果有人有成功地根据特定领域的数据微调 Phi-3 模型，我将非常感谢您可以分享的任何见解或建议。预先感谢您的帮助和支持！  qlora 配置： ​ sequence_len: 4000 Sample_packing: true pad_to_sequence_len: true trust_remote_code: True 适配器：qlora lora_r: 256 lora_alpha ：512 lora_dropout：0.05 lora_target_linear：true lora_target_modules：-q_proj - v_proj - k_proj - o_proj - gateway_proj - down_proj - up_proj 梯度累积步骤：1 micro_batch_size：2 num_epochs：4 优化器：adamw_torch lr_scheduler：余弦学习率：0 .00002 Warmup_steps：100 evals_per_epoch：4 eval_table_size： saves_per_epoch：1 调试：deepspeed：weight_decay：0.0  https://preview.redd.it/7afyhxcjv5yc1.png?width=976&amp;format=png&amp;auto=webp&amp;s=1ce3efe6df6e4533bad5ec2f23e4f4968736 bd56 ​ ;   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj2hzb/d_finetune_phi3_model_for_domain_specific_data/</guid>
      <pubDate>Fri, 03 May 2024 07:10:19 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 我应该去ICML发表论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</link>
      <description><![CDATA[我完成了博士学位。一年前。离开学术界，成为一家科技公司的数据科学家。我喜欢它，但仍在考虑将来以某种方式转向更多的研究职位。不过不确定。 无论如何，我的一个未完成的作品被一个朋友选中，完成并申请到 ICML。它被接受了（耶！）。 我现在想知道 - 除了我发现会议很有趣之外，参加会议还有实际好处吗？提交论文？我知道对于学术界/研究人员来说，这是一个很好的机会来了解人们并了解当前的研究。但由于我不再在那里，有真正的理由去吗？ 这是一个很奇怪的问题，但我只是不确定，我很高兴听到你的想法。  &gt;   由   提交 /u/meni_s   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</guid>
      <pubDate>Thu, 02 May 2024 21:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]寻求帮助以找到更好的GPU设置。三台 H100 与五台 A100？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</link>
      <description><![CDATA[长话短说，一家公司有购买 GPU 的预算，预计用于微调 LLM（可能是 70B 的），我必须进行研究找出哪种 GPU 设置最适合他们的预算。 预算可以购买三个 H100 GPU 或五个 A100 GPU。  我已尽了最大努力，但直到现在我还不清楚这些设置中哪一个更好。虽然五台 A100 拥有更多 VRAM，但他们说 H100 比 A100 快 2-8 倍！ 我正在寻求帮助。任何有价值的见解将不胜感激。   由   提交/u/nlpbaz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</guid>
      <pubDate>Thu, 02 May 2024 19:49:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于 ICML、NeurIPS、CVPR 等顶级会议，我一直在思考的事情。有多少论文是真正具有开创性的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</link>
      <description><![CDATA[我自己也有一些位于金星顶端的论文，但每当我坐下来对自己残酷地诚实时。我觉得我的作品不错，但影响力不大，就像墙上又多了一块砖。我想知道我们多久能看到像“注意力就是你所需要的一切”这样有影响力的东西例如。   由   提交 /u/oddhvdfscuyg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</guid>
      <pubDate>Thu, 02 May 2024 18:37:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] spRAG - 用于具有挑战性的现实世界任务的开源 RAG 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cikkw2/p_sprag_opensource_rag_implementation_for/</link>
      <description><![CDATA[大家好，我是 Superpowered AI (YC S22) 的 Zach。我们在 RAG 领域的工作已经一年多了，最近我们决定开源所有核心检索技术。 [spRAG](https://github.com/SuperpoweredAI/spRAG）是一个检索系统，旨在处理密集文本上的复杂现实查询，例如法律文档和财务报告。据我们所知，对于此类任务，它是所有 RAG 系统中最准确、最可靠的结果。例如，在 FinanceBench（这是一个特别具有挑战性的开放式金融问答基准）上，spRAG 正确回答了 83% 的问题，而普通 RAG 基准的正确率为 19%（使用 Chroma + OpenAI Ada）嵌入 + LangChain）。 您可以在项目的自述文件中找到有关其工作原理以及如何使用它的更多信息。我们也非常愿意接受贡献。我们特别需要围绕集成（即添加对更多向量数据库、嵌入模型等的支持）和评估方面的贡献。 很高兴回答任何问题！ [GitHub 存储库]( https://github.com/SuperpoweredAI/spRAG)   由   提交/u/zmccormick7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cikkw2/p_sprag_opensource_rag_implementation_for/</guid>
      <pubDate>Thu, 02 May 2024 16:50:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大三学生（本科生或一二年级博士生）在ICML、ICLR、NeurIPS等主要机器学习会议上有这么多论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</link>
      <description><![CDATA[大家好，今天ICML成绩出来了，恭喜所有在这里接受论文的同学。我自己不是学者，但有时我会为了工作而阅读这些会议上的论文，这真的很有趣。我只是有一个问题：为什么这些会议上大三的论文这么多？我认为这是你在 5 年博士学位期间必须学习的东西，而且几乎只能在博士学位的最后几年才能实现。另外，我听说要进入美国顶尖的博士项目，你需要事先写一些论文。那么，如果一个大三学生能这么早发表论文，为什么还要花5年时间攻读博士学位呢？   由   提交 /u/ShiftStrange1701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</guid>
      <pubDate>Thu, 02 May 2024 11:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>