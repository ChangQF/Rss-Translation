<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Mon, 17 Feb 2025 09:19:15 GMT</lastBuildDate>
    <item>
      <title>[R]区域自适应抽样：通过选择性更新高关注区域来加速扩散变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irfq36/r_regionadaptive_sampling_accelerating_diffusion/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  此处的关键贡献是扩散变压器的一种新的自适应采样方法，该方法通过基于区域重要性选择性分配注意力来降低计算。它没有平等地处理所有区域，而是确定哪些零件需要更详细的处理。 主要技术方面： - 基于预测的重要性得分 - 修改的注意力机制与与之兼容现有体系结构 - 记忆效率的自适应缓存策略 结果显示：-30-50％的计算时间减少 -  FID或剪辑分数中没有降解 - 通过自适应采样节省40％的内存 - 有效 - 在多个模型架构中有效 - 为有条件和无条件的生成工作 我认为这对于计算效率很重要的现实应用程序可能特别影响。在将资源使用量减少多达50％的同时保持质量的能力为在更适度的硬件上运行这些模型的可能性开辟了可能性。这里的原则也可能会很好地转移到选择性注意力分配可能会有所帮助的其他领域，例如视频生成或3D渲染。 我最感兴趣的是，这是如何挑战统一处理对于高质量而需要的假设。一代。通过证明我们可以选择计算分配，这表明当前架构的效率提高仍然有很大的空间。  tldr：新方法通过选择性注意重要的注意力将扩散变压器计算减少30-50％ ，没有质量损失。  完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irfq36/r_regionadaptive_sampling_accelerating_diffusion/</guid>
      <pubDate>Mon, 17 Feb 2025 09:03:14 GMT</pubDate>
    </item>
    <item>
      <title>[d] OpenAI帆布如何与Intlace人类编辑一起使用KV缓存？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irfgsc/d_how_does_openai_canvas_works_with_inplace_human/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想知道，如果openai允许它允许在内置的人类编辑，如何使用kv缓存？它是否必须使整个缓存无效到更早的文件编辑，然后必须在其余的帆布文本中执行前向通行证？ 它是否可以像所描述的图像一样起作用，或者有更好的方法将缓存保存在编辑之间但没有变化的文本中（我认为不是这样，因为隐藏的上下文会随着未来的所有代币而改变）？  https://preview.redd.it/e1ccea3zvnje1.png?width=746&amp;format=png&amp;auto= webp＆amp; s = F3848812A20F770C938B1D9B54EABAA64B07AFE5   喜欢：     line 1：def process_data（） ）第3行：y = x + 10→kv₃（意识到KV₁，kv₂）第4行：返回y→kv₄（知道kv₁，kv₂，kv₃，kv₃）现在我们编辑第2行：  现在我们编辑第2行    第1行：def Process_data（）：→KV₁（仍然有效）第2行：x = 10→KV₂&#39;（new）行3：y = x + 10→kv₃（无效！基于旧x值）第4行：返回y→kv₄（基于旧链的无效！）  有没有更聪明的方法可以逃脱较少的远期通行证？ 编辑：我现在认识到标题的差异有多糟。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/punsbymann     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1irfgsc/1irfgsc/d_how_does_openai_openai_canvas_works_with_with_with_inplace_inplace_human/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irfgsc/d_how_does_openai_canvas_works_with_inplace_human/</guid>
      <pubDate>Mon, 17 Feb 2025 08:44:48 GMT</pubDate>
    </item>
    <item>
      <title>[d]真正的智能：神经肯定AI和META-RL是真正智能的秘诀吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irdzhf/d_true_intelligence_is_neurosymbolic_ai_metarl/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  智能是能够理解，推理和有效适应新颖，复杂情况的能力。人工通用情报（AGI）试图通过创建能够执行人类可以执行任何智力任务的系统来复制这种多功能性，即使面对完全不熟悉的挑战。它需要动态的学习和强大的推理。 Neurosambolic AI将神经网络的模式识别能力与符号推理的逻辑严格性合并。尽管神经网络在处理非结构化数据和检测复杂的模式方面表现出色，但符号推理提供了抽象，逻辑推断和解释性。这种混合方法不仅使AI系统能够跨越不同领域的知识并解决抽象或看不见的问题，而且还有助于减少在纯粹统计模型中经常看到的幻觉。 在平行的，元提升的学习中AI具有自我管理超参数的能力。一个元素系统不受局限于固定的任务，而是根据过去的经验不断地完善自己的学习策略，从而使其能够迅速适应新的挑战而没有广泛的再培训。 这种强大的组合 - 这种强大的组合 - 从神经肯定AI和动态的，自我改善的适应性的结构化推理，从元RL产生了一种协同的框架，从而促进了真正的机器智能。这种综合方法不仅增强了上下文理解和自主决策，而且还承诺更可靠，耐幻觉的表现，使我们更接近真正的AGI，反映了人类的推理和适应性。    https://arxiv.org/abs/2301.08028       https://arxiv.org/abs/2411.04383    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/calter_lemon3563     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irdzhf/d_true_intelligence_is_neurosymbolic_ai_metarl/</guid>
      <pubDate>Mon, 17 Feb 2025 06:57:49 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何处理高度不平衡的数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ir2zm3/dhow_to_handle_highly_imbalanced_dataset/</link>
      <description><![CDATA[在解决高度不平衡数据集的社区。过去，我建立了搅动预测模型，现在我专注于预测保险索赔，在此索赔的百分比很低。 我的数据集跨越了15年，并且包含约800,000个记录，并具有具有此类功能的功能作为性别，年龄，马力，汽车品牌＆amp;类型  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sthyddoctor007     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ir2zm3/dhow_to_handle_highly_imbalanced_dataset/</guid>
      <pubDate>Sun, 16 Feb 2025 21:22:49 GMT</pubDate>
    </item>
    <item>
      <title>ICML审稿人2025分配的论文？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ir29gm/icml_reviewers_2025_assigned_papers_d/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对所有其他ICML 2025审稿人，您是否已经在OpenReview中看到了分配的论文？我收到了分配的论文已准备好几天前的更新，但是在我的审阅者控制台中，我只看到“ 您没有分配的论文。纸质分配过程完成后，请再次检查。 &#39;我也没有列出的出色审阅者任务。我们现在已经进入了审核期三天了，所以我希望到现在为止的任务已经完成。我绝对不会做的是在几天之内审查6篇论文，因为某些交流需要额外的审阅者。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/five-innodable-7243      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ir29gm/icml_reviewers_2025_assigned_papers_d/</guid>
      <pubDate>Sun, 16 Feb 2025 20:52:03 GMT</pubDate>
    </item>
    <item>
      <title>[D]在新数据集上微调视频扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqy1pi/d_finetuning_a_video_diffusion_model_on_new/</link>
      <description><![CDATA[在 - 卫星镜头  - 显微镜视频&lt; /p&gt; 我对整个稳定的扩散景观有很好的了解，并且以前具有微调图像稳定的扩散，都完全微调，但也有更多轻巧的方法如洛拉（Lora）。这是我第一次冒险进入视频域，我赶上了以下资源以及他们的参考论文：  -   https://lilianweng.github.io/posts/2024-04-04-04-12-diffusion-video/    -   https://youtu.be/0k56la821ys      它似乎是我就像大多数SOTA视频扩散模型（Atleast the Openake the Openake the Openake the Openake ofere of the Openake the Openake ofere of the Openake ofere of the Openake ofere of the Openake of the Openake the Opent of the Openage the Opent of the Opent of the Opent源）现有的图像扩散模型，并通过添加时间层将其转变为视频扩散模型，然后在视频上训练模型，同时将空间层固定。 这使我解决了问题。让我们专注于一种模式，显微镜视频。我认为现在的条件将是一个开始框架。我看到了几种方法：  - 微观图像上的微调图像模型（可能是SD2），然后通过添加时间层和微调视频将该模型转换为视频模型 - 直接微调稳定的视频扩散在显微镜视频上 直觉上，我感觉就像是“完整的微型”与低级适应之类的东西相反，这里有意义的是什么？据我所知，稳定的视频扩散似乎是最好的开源模型，或者还有其他型号我应该研究吗？ 我有大约500GB的数据和1500 h100小时，所以我&#39;绝对不足以从头开始做任何事情，因此为什么首选某种微调方法，以及为什么优先使用潜在方法，而不是像素空间。 似乎存在巨大关于如何微调图像扩散模型的在线资源，但对视频模型的了解不多。显然，这个过程应该非常相似，但仍然如此。您如何看待，我是否确定了最有可能起作用的最大方法，还是您知道其他任何方法？您如何看待，我该如何处理？我可以期望得到的好成绩如何？关于评估，自动指标是否足够好，或者我需要进行人类的Evals？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lapurita     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iqy1pi/d_​​finetuning_a_video_diffusion_model_model_onew/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqy1pi/d_finetuning_a_video_diffusion_model_on_new/</guid>
      <pubDate>Sun, 16 Feb 2025 17:56:14 GMT</pubDate>
    </item>
    <item>
      <title>[p]我构建了一个使用您的git提交历史记录作为可搜索实验日志的跟踪器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqv3yy/p_i_built_a_tracker_that_uses_your_git_commit/</link>
      <description><![CDATA[   &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/comments/1iqv3yy/p_i_built_a_a_a_tracker_tracker_tracker_tracker_tracker_tracker_tracker_tracker_tracker_your_your_your_your_your_git_commit/ your git commit history as a searchable experiment log&quot; src=&quot;https://external-preview.redd.it/QEgyaoMrMBGnzjPGiuPDJ7WiWOzD6bH4zDUPE4h2Urg.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=572a3eafddec240ba4efb5f3f1a0a31884ec49bf&quot; title=&quot;[P ]我构建了一个跟踪器，该跟踪器将您的git提交历史记录用作可搜索的实验日志“/&gt;   ＆＃32;提交由＆＃32; /u/user_example     [link]  ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqv3yy/p_i_built_a_tracker_that_uses_your_git_commit/</guid>
      <pubDate>Sun, 16 Feb 2025 15:52:11 GMT</pubDate>
    </item>
    <item>
      <title>[P]与重新成真的伯特混乱</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqv2r4/p_confusion_with_reimplementing_bert/</link>
      <description><![CDATA[在&gt; https://arxiv.org/pdf/1810.04805 ）但是我对某些东西有些困惑，在第4页：（  https：//arxiv.org/pdf/1810.04805.04805#page=4&amp; amp = 147,44,44,821 ） “在整个工作中，“句子”可以是连续文本的任意跨度，而不是实际的语言句子。当我从huggingface加载书籍时，我会得到这样的数据：  {&#39;text;“通常，他通常会在客厅里撕裂，玩具玩具。＆quot&#39;} &lt; br /&gt; {“文字”：“但是只有一个小小的看，几乎把他寄给了他。早些时经常暴露于年龄较大的事物。“}  {text”：“她喜欢认为被成年人和大孩子包围是他是他这个年龄段的好话的原因之一。＆quot。 ;}  {; &#39;&#39;&#39;&#39;}  {; text＆quot；“她说。”。他们指的是上面的？因为在Bert纸中，它们将句子与[Sep]令牌之间的句子结合在一起，我是否可以假设我可以在这里组合每对句子？对于随机句子的50％，只需在文件中选择一个随机的JSON对象？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/benahmed23     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqv2r4/p_confusion_with_reimplementing_bert/</guid>
      <pubDate>Sun, 16 Feb 2025 15:50:42 GMT</pubDate>
    </item>
    <item>
      <title>[d]进行原始研究的步骤（这也是一个咆哮）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqq4fz/d_the_steps_to_do_original_research_its_a_rant_as/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是英国的大师学生。我一直在阅读有关扩散的论文。我已经联系了大学的博士生，并表示对与他们合作的兴趣。我以为我会帮助他们解决他们的研究方向。但是，与他们交谈后，他们告诉我阅读一些论文，然后找到一个研究想法。  对于上下文，我正在阅读有关扩散模型的信息。我读的越多，我意识到我缺乏一些数学基础。我通过课程，书籍和文章来填补这些洞。但是，这需要时间。我相信，缺乏基本的理解使我无法提出假设。我可以通过最近的调查论文找到一些研究差距，但是我无法提出任何假设或解决方案。 我朝正确的方向前进吗？从根本的角度理解东西有助于产生新颖的研究思想吗？如何产生新颖的研究思想？如果您有一些提示，我很高兴听到它们。  P.S。我从未出版过。因此，如果我错过了一些基本的东西，我感到很抱歉。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/snoo_65491     [link]   ＆＃32;   [注释]      ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqq4fz/d_the_steps_to_do_original_research_its_a_rant_as/</guid>
      <pubDate>Sun, 16 Feb 2025 11:14:23 GMT</pubDate>
    </item>
    <item>
      <title>[P]我建立了一个开源AI代理，该代理可以完全自动编辑视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqq1vz/p_i_built_an_opensource_ai_agent_that_edits/</link>
      <description><![CDATA[   &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/comments/1iqqq1vz/p_i_built_an_opensource_aigent_ai_aigent_aigent_that_that_edits/ AI agent that edits videos fully autonomously&quot; src=&quot;https://external-preview.redd.it/aNz3BFb1ycBa55wI3LX5BuJGkVgsXAVk_7lUskfK1zk.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b072cacd407870c1166de542f8cab83d84861bf1&quot; title=&quot;[P] I构建了一个开源AI代理，该代理完全自动编辑视频“/&gt;   ＆＃32;提交由＆＃32; /u/u/umaust_instance_401     代理“&gt; [link]  ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqq1vz/p_i_built_an_opensource_ai_agent_that_edits/</guid>
      <pubDate>Sun, 16 Feb 2025 11:09:16 GMT</pubDate>
    </item>
    <item>
      <title>[d] Torch.com使用Hidet编译器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqnyet/d_torchcompile_using_hidet_compiler/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有人尝试使用hidet作为torch.compile的火炬电感器的Altenative Backend。    https://pytorch.org/blog/introducing-hidet/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/lime_dragonfruit4244      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqnyet/d_torchcompile_using_hidet_compiler/</guid>
      <pubDate>Sun, 16 Feb 2025 08:37:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM法官提供动力的每日ARXIV过滤（与项目链接）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqnhai/p_daily_arxiv_filtering_powered_by_llm_judge_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  链接到项目： https://arxiv.ianhsiao.xyz &lt; /a&gt;  大家好，在我以前的reddit帖子中：没有可用的链接，因为我对许多subreddits粘贴了相同的评论，因此系统认为我是垃圾邮件并删除了所有这些（您可以比较显示的评论金额和实际数量验证）。我为此感到抱歉。 话虽如此，我真的很想学习社区的反馈，所以我再次发布此信息。 谢谢您的耐心配合！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/madyexz     [link]   ＆＃32;   [commist]       ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqnhai/p_daily_arxiv_filtering_powered_by_llm_judge_with/</guid>
      <pubDate>Sun, 16 Feb 2025 08:02:38 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会导致禁止。 鼓励其他人创建新的帖子，以便在此处发布问题！ 线程将一直活着直到下一个，因此请继续发布标题之后的发布。    meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[D]我的公司是否因避免深度学习而错过了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq9gtk/d_is_my_company_missing_out_by_avoiding_deep/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  免责声明：如果线性回归足够，则使用神经网络是没有意义的。  我在一家严格遵守数学，可解释的模型的公司工作。他们的立场是，诸如神经网络甚至梯度提升机之类的方法也是“黑框”。因此对决策不可靠。尽管我了解可解释性的重要性（尤其是在任务关键场景中），但我忍不住感觉这种方法过于限制。  我看到了这些方法的大量研究和行业采用，这让我感到奇怪：它们真的只是黑匣子，还是这是过时的观点？当然，随着这么多的人在这一领域工作，必须有一些方法可以洞悉这些模型并使他们更值得信赖。  我也错过了它们，因为我没有此类模型的工作经验？ 编辑：上下文是一级方程式！但是，种族是另一件事并支持工具。除非完全必要，否则我也会避免使用与种族严格相关的任何模型。我只是觉得这里有一种与上下文无关的偏见。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/datandre     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq9gtk/d_is_my_company_missing_out_by_avoiding_deep/</guid>
      <pubDate>Sat, 15 Feb 2025 19:42:42 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>