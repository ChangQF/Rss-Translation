<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 22 Mar 2024 21:12:04 GMT</lastBuildDate>
    <item>
      <title>[R] 将 2 个 CCN 模型合并为 1 个</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bl8w9t/r_combine_2_ccn_models_into_1/</link>
      <description><![CDATA[我正在开发一个项目，需要检测 (1) 一个人在哭，(2) 一个人在笑。有什么方法可以在单个模型中组合和识别这两个表达式吗？或者我必须构建 2 个单独的模型？   由   提交 /u/susanmylife   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bl8w9t/r_combine_2_ccn_models_into_1/</guid>
      <pubDate>Fri, 22 Mar 2024 20:13:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过 HF 管道的视频 llava</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bl5xo1/r_video_llava_through_hf_pipeline/</link>
      <description><![CDATA[大家好，  我对 Hugging Face 和法学硕士还比较陌生。我目前正在尝试通过 Hugging Face 管道运行 Video LLAVA。我已经在 HF 代码的帮助下安装了模型和标记器，但之后我不知道如何继续。我想提供一个视频，我会向 Video LLAVA 提问。 如果有人可以帮助我或与我分享教程或笔记本来实现这一点，那将会很有帮助。  拥抱脸部链接：https://huggingface.co/LanguageBind/Video-LLaVA-7B   由   提交 /u/TelephoneParty5934   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bl5xo1/r_video_llava_through_hf_pipeline/</guid>
      <pubDate>Fri, 22 Mar 2024 18:12:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习应用于医学-环境影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bl2ur1/d_machine_learning_applied_to_medicine/</link>
      <description><![CDATA[我目前正在研究机器学习在生殖医学中的应用，我相信它最终将成为任何 IVF 实验室或诊所的主要工具. 作为这个主题的初学者（生物毕业生），我对机器学习或人工智能知之甚少，而且我遇到过不同的来源，警告训练和使用机器学习对环境的影响。这些工具，尤其是生成式人工智能，可以拥有。我很好奇人工智能的这种特殊用途可能会产生什么真正的影响，以及您是否知道谈论它的作者，特别是应用于医学领域。    由   提交/u/Mar_307  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bl2ur1/d_machine_learning_applied_to_medicine/</guid>
      <pubDate>Fri, 22 Mar 2024 16:05:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您是否知道在 RAG 之后部署 LLM 的方法，以免每次都重复该过程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bl2k19/r_do_you_know_a_method_to_deploy_a_llm_after_rag/</link>
      <description><![CDATA[大家好， 你知道在 100k PDF 上进行检索增强生成后部署 LLM 进行生产的方法吗（我做到了）这样做没有成功，但如果您也对此有建议，我们非常欢迎），以免每次都重复该过程？或多或少，就像微调后一样。我寻找了一个简单的解决方案，但找不到任何东西。 提前非常感谢您。   由   提交/u/ThaiosX0195   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bl2k19/r_do_you_know_a_method_to_deploy_a_llm_after_rag/</guid>
      <pubDate>Fri, 22 Mar 2024 15:53:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] PuzzleVQA：用抽象视觉模式诊断语言模型的多模态推理挑战</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bl12g2/d_puzzlevqa_diagnosing_multimodal_reasoning/</link>
      <description><![CDATA[数据集：https ://github.com/declare-lab/LLM-PuzzleTest/tree/master/PuzzleVQA 论文：https://arxiv.org/abs/2403.13315 大型多模态模型通过集成多模态理解能力扩展了大型语言模型的令人印象深刻的功能。然而，目前尚不清楚它们如何模仿人类的一般智力和推理能力。由于识别模式和抽象概念是通用智能的关键，因此我们推出了 PuzzleVQA，这是一组基于抽象模式的谜题。通过该数据集，我们根据基本概念（包括颜色、数字、大小和形状）评估具有抽象模式的大型多模态模型。通过我们对最先进的大型多模态模型的实验，我们发现它们无法很好地推广到简单的抽象模式。值得注意的是，即使是 GPT-4V 也无法解决一半以上的难题。为了诊断大型多模态模型中的推理挑战，我们逐步用视觉感知、归纳推理和演绎推理的真实推理解释来指导模型。我们的系统分析发现，GPT-4V的主要瓶颈是视觉感知和归纳推理能力较弱。通过这项工作，我们希望阐明大型多模态模型的局限性以及它们如何在未来更好地模拟人类认知过程。   由   提交 /u/sgpfc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bl12g2/d_puzzlevqa_diagnosing_multimodal_reasoning/</guid>
      <pubDate>Fri, 22 Mar 2024 14:49:32 GMT</pubDate>
    </item>
    <item>
      <title>[d] 在没有标记数据集的情况下评估无监督分类器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bl050h/d_evaluate_unsupervised_classifier_without/</link>
      <description><![CDATA[大家好，我正在开发一个机器学习项目，我必须使用 ECM 分类器来给出结果。结果我的公司没有标记的数据集来比较我的结果。我在机器学习方面没有太多经验。有没有办法可以在没有标记数据的情况下为我的公司提供一些评估指标，例如精确度、召回率混淆矩阵？如果不是（似乎是这样）我还可以使用哪些其他方法来显示我的算法有多好？   由   提交/u/No_Context_6938   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bl050h/d_evaluate_unsupervised_classifier_without/</guid>
      <pubDate>Fri, 22 Mar 2024 14:09:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前评估法学硕士的局限性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkz0od/d_the_current_limitation_of_evaluating_llms/</link>
      <description><![CDATA[在分析LLM的性能时，大多数相关论文都使用Loss per FLOPs和基准表（例如GLUE、Perplexity等）。 ）。 但是每 FLOP 的损失不能表明整个验证损失，并且基准测试不能证明它如何在实证事件中工作。 例如，无论什么情况，损失都可以更低其数据集的质量，必须有可靠的基准。 此外，我们不知道在不过度拟合公共研究数据集的情况下基准如何可靠。 在这种情况下，什么是您是否有洞察力来根据您所在领域的研究价值来挑选更好的论文？   由   提交/u/Mundane_Definition_8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkz0od/d_the_current_limitation_of_evaluating_llms/</guid>
      <pubDate>Fri, 22 Mar 2024 13:17:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有“完整”LLMOps 的资源或存储库吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkyr87/d_any_resources_or_repos_of_complete_llmops/</link>
      <description><![CDATA[您好， 因此，我的团队希望探索在生产中应用法学硕士，但我们根本不知道从哪里开始堆栈的术语。您能否推荐一些资源，以便我能够为 LLMOps 的外观打下坚实的基础？谢谢！   由   提交 /u/TheCockatoo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkyr87/d_any_resources_or_repos_of_complete_llmops/</guid>
      <pubDate>Fri, 22 Mar 2024 13:04:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们使用什么来编排频繁的模型重新训练和部署？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkx2it/d_what_are_people_using_for_orchestration_of/</link>
      <description><![CDATA[我的团队有一些正在生产的模型，其中模型每隔几周就会进行一次临时的重新训练。我们运行训练，使用 MLFlow 进行跟踪（不使用 MLFlow 的模型注册表），然后如果我们想要部署新模型，我们手动更新应用程序存储库中的模型标签，创建新的应用程序映像，从 s3 下载新模型工件，然后部署。  这对我们来说效果很好。问题是，我们即将开展一个项目，每天可能需要多次重新训练模型，因此显然当前的工作流程将无法工作。  人们使用什么来协调这些大规模、频繁的再培训和部署？我们正在考虑使用托管 AirFlow 实例和 MLFlow 模型注册表，但我对其他想法持开放态度，例如 MetaFlow 或 MLOps 动物园中的任何其他工具  &amp; #32；由   提交/u/stephenfenel  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkx2it/d_what_are_people_using_for_orchestration_of/</guid>
      <pubDate>Fri, 22 Mar 2024 11:32:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何用更少的 GPU 内存训练神经网络：可逆残差网络回顾</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkv29x/r_how_to_train_a_neural_network_with_less_gpu/</link>
      <description><![CDATA[探索可逆残差网络的有趣方法。 OpenCV.ai 团队的新文章回顾了一种减少 GPU 内存需求的方法在神经网络训练期间。您将发现可逆残差网络在神经网络训练期间如何节省 GPU 内存。该技术在“可逆残差网络：无需存储激活的反向传播”中详细描述。通过不存储反向传播的激活，可以有效地训练更大的模型。了解其在降低硬件要求方面的应用，同时保持 CIFAR 和 ImageNet 分类等任务的准确性。   由   提交/u/Human_Statistician48   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkv29x/r_how_to_train_a_neural_network_with_less_gpu/</guid>
      <pubDate>Fri, 22 Mar 2024 09:21:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当前小型（例如，<10,000 个参数）语言模型中最好的是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkqd2q/d_what_is_the_current_best_in_tiny_say_10000/</link>
      <description><![CDATA[显然，我们都听说过大语言模型，甚至听说过“小”语言模型。语言模型非常大（通常&gt; 100万个参数）。显然（除非我严重误解了语言模型的工作原理），您至少需要与词汇量大小一样多的参数（因为人们可以想象的最基本的模型只是为每个后续的概率分配一个固定的概率）单词，无论上下文如何 - 显然任何有用的模型都会做比这更复杂的事情）。 但我想知道小型模型的最新技术是什么，以前存在的模型的大小“大数据”甚至是一个已经被创造出来的短语。我知道这现在可能是一个小众的事情，业内很少有人致力于此。但我认为（或者至少我希望）至少仍然有爱好者在业余时间从事此类工作，就像仍然有人为 NES 编写自制游戏一样。 我&#39;我正在谈论一种可以在几个下午内在 C/C++ 中从头开始构建的模型（模型和训练算法），而不使用任何第三方依赖项/框架，可以进行训练和推理，甚至不需要显卡等。最重要的是，什么架构在这些限制下工作得最好？当限制在这个大小时，有什么能打败 HMM、n-gram 模型等吗？   由   提交/u/math_code_nerd5   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkqd2q/d_what_is_the_current_best_in_tiny_say_10000/</guid>
      <pubDate>Fri, 22 Mar 2024 03:58:26 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ML 研讨会/会议推荐：不是 AAI、IJCAI、NeuRips 或 ICML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkdsi2/discussion_ml_workshopconference_recommendation/</link>
      <description><![CDATA[这里是博士生。我尝试在 AAI-22、IJCAI-23、NeuRIPS-23 和 ICML-24 上发表我的论文。每次我处理这些评论时，我的分数都会更低。我做了表格数据——他们要求计算机视觉，我就这么做了。现在，他们要求语音识别。它在哪里停止？最重要的是，有些评论感觉他们在审稿时根本没有读过论文。这两年我一直在做这方面的工作，发表了几篇论文。我很累，整个过程都筋疲力尽。有人可以推荐一些 2024 年排名较低但可以接受的 ML 会议或信誉良好的研讨会吗？我想发布并完成这个工作。    由   提交/u/Conscious-Media3207  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkdsi2/discussion_ml_workshopconference_recommendation/</guid>
      <pubDate>Thu, 21 Mar 2024 18:35:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有准确的AI工具进行研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk9aw0/d_is_there_an_accurate_ai_tool_for_research/</link>
      <description><![CDATA[我所在的领域需要大量数据分析和最新信息。我尝试过 Perplexity、ChatGPT 和 Bard 等工具，但结果各不相同。他们都有过自己的时刻，但没有一个是始终准确的，而不断检查它们是否准确就违背了使用人工智能工具的初衷。我遇到过一些问题，例如误解上下文以及反馈给我的不相关信息。我最近在寻找有关量子计算的信息，但只收到过时的参考资料。 同样，必须验证我得到的所有内容，这让我回到了第一个方向，我宁愿不完全使用人工智能工具。那么有没有真正的替代方案，或者我对独角兽的要求太多了？理想情况下，我正在寻找一个能够处理复杂主题并与最新出版物保持同步的人。  感谢您的帮助！   由   提交 /u/energetic_slugger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk9aw0/d_is_there_an_accurate_ai_tool_for_research/</guid>
      <pubDate>Thu, 21 Mar 2024 15:31:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 评论已发布。来！我们讨论一下！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk7u47/d_icml_reviews_are_released_lets_discuss/</link>
      <description><![CDATA[ 您收到了多少评论？ 他们的评分是多少？ （分数/置信度）  以下是审阅说明供参考：https://icml .cc/Conferences/2024/ReviewerInstructions   由   提交/u/tfburns  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk7u47/d_icml_reviews_are_released_lets_discuss/</guid>
      <pubDate>Thu, 21 Mar 2024 14:28:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>