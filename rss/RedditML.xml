<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 12 Mar 2024 00:56:22 GMT</lastBuildDate>
    <item>
      <title>[R] 作为可优化图的语言代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bchke2/r_language_agents_as_optimizable_graphs/</link>
      <description><![CDATA[ 由   提交/u/hardmaru  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bchke2/r_language_agents_as_optimizable_graphs/</guid>
      <pubDate>Mon, 11 Mar 2024 23:10:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 🔥InstaSwap 换脸 for ComfyUI 和 Standalone</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcgabf/p_instaswap_face_swap_for_comfyui_and_standalone/</link>
      <description><![CDATA[   ComfyUI 存储库：https://github.com/abdozmantar/ComfyUI-InstaSwap Standalon 仓库：https://github.com/abdozmantar/Standalone-InstaSwap ​ https://i.redd.it/idb3ugi95snc1.gif   由   提交 /u/abdullahozmntr   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcgabf/p_instaswap_face_swap_for_comfyui_and_standalone/</guid>
      <pubDate>Mon, 11 Mar 2024 22:20:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于上采样任务的想法/建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcfk79/d_ideassuggestions_on_upsampling_task/</link>
      <description><![CDATA[我有一个任务，其中有传感器数据，可以是视觉、运动或任何其他类型的传感器。我还从更昂贵的传感器获得了相同的数据。  我正在寻找能够本质上对“廉价”数据进行上采样的生成模型。数据进入“昂贵”的状态数据。例如，我们可以用更便宜的低级同等产品或替代品（例如摄像头和麦克风）来替换昂贵的触觉传感器或腕式力/扭矩传感器吗？ 理想情况下，我不想自己实现模型但我知道我可能必须从头开始训练它。 无论如何，如果您对可以很好地完成这项任务的模型有任何想法，我将非常感谢您的见解，谢谢！   由   提交 /u/Alarmed-Fee6193    reddit.com/r/MachineLearning/comments/1bcfk79/d_ideassuggestions_on_upsampling_task/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcfk79/d_ideassuggestions_on_upsampling_task/</guid>
      <pubDate>Mon, 11 Mar 2024 21:52:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找具有共享价值查询注意力权重的论文。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcck5w/r_looking_for_paper_with_shared_valuequery/</link>
      <description><![CDATA[我可以发誓我在一年前浏览过一篇论文，该论文展示了变压器的相当可靠的性能，其中值和键（或查询）权重是每个注意力层内相同/共享。我认为 Linformer 做了类似的事情，但我并不是在寻找试图解决注意力的二次运行时间的东西，只是表明你可以通过共享值和键获得合理的结果。它甚至可能在这个 Reddit 子版块中被提及。不知怎的，我似乎找不到它......有人碰巧知道这一点，或者也许知道正确的搜索术语？   由   提交/u/benthe human_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcck5w/r_looking_for_paper_with_shared_valuequery/</guid>
      <pubDate>Mon, 11 Mar 2024 19:56:13 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]LSTM模型可以自己学习特征工程吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcc2oo/discussion_can_lstm_model_learn_feature/</link>
      <description><![CDATA[我有一个时间序列数据集，我正在其上训练 LSTM 模型以执行多类分类。 我的数据集有 7 列=&gt; x1,x2,x3....x7 并且有 4 个标签 =&gt; f1,f2,f3,f4 由于我对数据集具有领域知识，因此我确切地知道需要完成哪些特征工程。 ​ &lt; p&gt;例如，我需要通过在每一行应用一些规则来从当前功能创建 4 个新功能：-  newx1 由 =&gt; 创建if (x2==x3) then 1, else 0 newx2 由 =&gt; 创建if (x1==x4 and x1&gt;x5) then 1, else 0 newx3 由 =&gt; 创建if ((x1-x6)/x1&gt;x7) then 1, else 0 newx4 由 =&gt; 创建if ((x6-x1)x1/&gt;x7) then 1. else 0  ​ 我在测试数据上获得 100% 的准确度，如果我在 newx1、newx2、newx3、newx4 上训练我的 LSTM 模型。 但是，在原始特征 (x1,x2....x7) 上训练它时，我的准确度降低了 85-90%  我要解决的问题要求我的准确率高于 99%，因此仅 90% 的准确率是不够的。 &amp;# x200b; 我想知道我的 LSTM 模型是否可以自行学习特征工程的规则，或者我是否必须更改我的模型？ ​ 注意：我无法手动应用特征工程规则，因为我正在多个数据集上训练 LSTM 模型，并且每个数据集都需要自己的特征工程规则。我想让它尽可能通用。 ​ LSTM 模型 :- def create_lstm_model(MaxTimeslice, H, LR , num_classes, dropout_rate=0.1, l2_reg=0.001): ip = 输入(shape=(MaxTimeslice, H)) x = LSTM(32, return_sequences=True, dropout=dropout_rate, kernel_regularizer=l2(l2_reg))(ip) x = LSTM(16，dropout=dropout_rate，kernel_regularizer=l2(l2_reg))(x) x = Dense(units=16，activation=&#39;relu&#39;)(x) multiclass_output = Dense(units=num_classes，activation=&#39;softmax&#39;)( x) model = Model(inputs=ip,outputs=multiclass_output) model.compile(loss=&quot;categorical_crossentropy&quot;,metrics=[&quot;accuracy&quot;],optimizer=RMSprop(learning_rate=LR)) 返回模型 &lt; /pre&gt; ​   由   提交 /u/Fearless_Peanut_6092   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcc2oo/discussion_can_lstm_model_learn_feature/</guid>
      <pubDate>Mon, 11 Mar 2024 19:37:27 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 这是数据泄露的例子吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bca8h7/discussion_is_this_an_example_of_data_leakage/</link>
      <description><![CDATA[我正在开展一个研究项目，使用机器学习来尝试发现基因启动子的模式。我担心我们模型中的数据泄漏，但在我大力推动我的实验室改变我们的方法之前，我需要一些外部意见。也许这个社区中的某人可以帮助我更好地理解这个问题。 我们的机器学习模型是 L1 正则化逻辑回归模型，它使用序列模式作为特征来预测转录起始位点（TSS）的二进制结果）在基因组中。序列模式由上游工具在 TSS 旁边约 1000 个核苷酸的区域中检测到。由于许多 TSS 在基因组中紧密聚集（某些基因具有多个 TSS），因此这些序列区域通常与至少一个其他 TSS 序列区域重叠 &gt; 99%。我担心的是，如果我们对单个 TSS 进行训练/测试分割，我们将会出现数据泄漏，因为训练集中的许多示例将具有与测试集中的至少一个特征向量相关且高度相关的特征向量。我们对序列区域进行分箱只能在一定程度上缓解这种情况，因为偏移 5 nt 或更少的两个 100 核苷酸 (nt) 箱（在我们的数据集中并不罕见）将共享 ≥95% 的序列同一性。 以下几点让我认为我们存在数据泄漏：  我们的特征比示例更多，使得过度拟合变得更容易。在将训练集性能与测试集性能进行比较时，观察到了一点过度拟合。 两个 TSS 的居中、缩放特征的组内平均（在最大 5nt 间隔的连续簇中）皮尔逊相关系数为〜0.99。这不包括自我比较。组之间的平均相关性为 ~-0.0002。大约 35% 的 TSS 位于具有此距离阈值的某个集群中。 当 TSS 按最大 5nt 间隔的邻近度进行聚类时，如果测试集中的 TSS 与测试集中的任何 TSS 分组，则测试集中的 TSS 将被删除。训练集上，通过评估“清理过的”测试集，我们的 auROC 下降了约 3%。这可以用不同的随机种子来重现。如果我们使用 20nt 的阈值，性能会下降约 5%。 当我用随机 DNA 序列而不是基因组来生成特征时，但使用相同的 TSS 位置和整体方法（意味着序列重叠）仍然发生），模型达到了 70% 的 auROC。相比之下，如果我将最大距离为 20 nt 的 TSS 分组，并在进行训练/测试分割之前删除每组中除一个 TSS 之外的所有 TSS，则我在随机基因组上获得约 53% 的 auROC，更接近于随机分类器。&lt; /li&gt;  我删除太接近的 TSS 的方案无疑是有缺陷的，因为我们失去了宝贵的例子。我认为保留所有 TSS 并按组拆分会更好，同时还能防止数据泄漏。据我了解，这相当于整群抽样，并且类似于患者层面的分裂，因为医学研究人员正在学习如何处理 MRI 切片等数据。在这种情况下，该方案是否无效/有害，或者它是否是防止数据泄漏的正确选择？或者我们应该使用另一种分割方案？   由   提交/u/analyze_hunter  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bca8h7/discussion_is_this_an_example_of_data_leakage/</guid>
      <pubDate>Mon, 11 Mar 2024 18:24:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要特征工程连续数值特征的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc8pig/d_need_suggestions_for_feature_engineering/</link>
      <description><![CDATA[      数据集链接 - https:// www.kaggle.com/competitions/playground-series-s4e3 在最近的一次比赛中，我遇到了一个包含连续特征的数据集，为了深入了解它们的分布动态，我生成了两个分布图和箱线图。目标列是分类的，目标是确定与预测缺陷相关的概率，评估指标是 AUC ROC 分数。 采用最少的预处理，我使用爬山集成训练了一个模型，其中包含超参数调整的 XGBoost (XGB) 和 LightGBM 模型。我取得的成绩使我跻身排行榜前 1%。我正在寻求进一步预处理步骤的建议，以提高模型的准确性。   由   提交/u/tushar_mahalya   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc8pig/d_need_suggestions_for_feature_engineering/</guid>
      <pubDate>Mon, 11 Mar 2024 17:24:12 GMT</pubDate>
    </item>
    <item>
      <title>[N] Haystack 2.0发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc53h0/n_haystack_20_launch/</link>
      <description><![CDATA[Haystack 2.0 稳定版已上线！亲自尝试一下：https://haystack.deepset.ai/blog/haystack-2-release/&lt; /a&gt; Haystack 是一个开源 AI 框架，用于使用 LLM 和其他语言模型创建可用于生产的应用程序。它已经有近 4 年历史了——在它变得很酷之前我们就一直在做 NLP 和 LLM 工程。 😎 并且与模型和数据库无关 - 您可以使用对您的用例最有意义的任何工具。 Haystack 提供了一个丰富且不断发展的集成社区，提供监控、评估、数据摄取等。 关于 2.0 版本的背景： Haystack 于 2020 年首次正式发布，当时最前沿的NLP 的主要内容是语义搜索、检索和抽取式问答。 Haystack 2.0 是完全重写的，但将组件组合成灵活管道的基本原理保持不变。  该版本有相当多的模型提供者、跟踪和监控功能以及开箱即用的支持数据库： 对于模型（生成和嵌入）：OpenAI、Mistral、Cohere、Jina AI、 Google AI、Vertex AI、Optimum（通过拥抱脸）、句子转换器、Amazon Bedrock、Azure、Fast Embed、Ollama 对于数据库：Weaviate、Pinecone、Qdrant、Mongo DB、Astra DB、Neo4j、pgvector、Chroma、 Elastic Search、OpenSearch... 希望您尝试一下并让我们知道您的想法！我们有一个快速入门指南：https://haystack.deepset.ai/overview/quick-start   由   提交 /u/tuanacelik   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc53h0/n_haystack_20_launch/</guid>
      <pubDate>Mon, 11 Mar 2024 14:55:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] Gemini 1.5 Pro如何回忆10M上下文中的信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</link>
      <description><![CDATA[Google 最近发布了技术报告 关于 Gemini 1.5 Pro 及其 10M 上下文。他们简要概述了提高模型长上下文能力的现代方法（例如循环记忆、环形注意力、新颖的架构等），但我没有找到有关 Gemini 1.5 Pro 方法的信息。 有人注意到官方出版物中有关他们方法的信息吗？这对我来说似乎是 Google 的秘密。   由   提交/u/Mulated-Witness-7196   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</guid>
      <pubDate>Mon, 11 Mar 2024 12:26:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] [2403.05468] GPT-4 会运行《DOOM》吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</link>
      <description><![CDATA[ 由   提交/u/blabboy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</guid>
      <pubDate>Mon, 11 Mar 2024 12:20:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] ShortGPT：大型语言模型中的层比您预期的更加冗余</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.03853 摘要：  随着大型语言模型（LLM）的性能不断进步，它们的规模显着扩大，当前的法学硕士包含数十亿甚至数万亿的参数。然而，在这项研究中，我们发现LLM的许多层表现出高度相似性，并且某些层在网络功能中发挥的作用可以忽略不计。基于这一观察，我们定义了一个名为区块影响力 (BI) 的指标来衡量法学硕士中每一层的重要性。然后，我们提出了一种直接的修剪方法：层删除，其中我们根据 LLM 的 BI 分数直接删除其中的冗余层。实验表明，我们的方法（我们称之为 ShortGPT）在模型剪枝方面显着优于之前最先进的 (SOTA) 方法。此外，ShortGPT 与类量化方法正交，可以进一步减少参数和计算量。与更复杂的修剪技术相比，通过简单的层删除可以获得更好的结果，这表明模型架构中存在高度冗余。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</guid>
      <pubDate>Mon, 11 Mar 2024 11:41:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] MathScale：数学推理的缩放指令调整</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc0zpo/r_mathscale_scaling_instruction_tuning_for/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.02884 摘要：  大型语言模型（LLM）在解决问题方面表现出了卓越的能力 -解决。然而，他们解决数学问题的能力仍然不足。我们提出了 MathScale，这是一种使用前沿 LLM（例如 GPT-3.5）创建高质量数学推理数据的简单且可扩展的方法。受人类数学学习认知机制的启发，它首先从种子数学问题中提取主题和知识点，然后构建概念图，随后用于生成新的数学问题。 MathScale 沿着我们生成的数学数据集的大小轴展示了有效的可扩展性。因此，我们创建了一个包含 200 万数学问答对的数学推理数据集 (MathScaleQA)。为了全面评估法学硕士的数学推理能力，我们构建了数学应用题基准MwpBench，它是涵盖K-12、大学和竞赛级别的十个数据集（包括GSM8K和MATH）的集合数学问题。我们应用 MathScaleQA 来微调开源 LLM（例如 LLaMA-2 和 Mistral），从而显着提高数学推理能力。在 MwpBench 上进行评估，MathScale-7B 在所有数据集上均实现了最先进的性能，其微观平均准确度和宏观平均准确度分别超过同等大小的最佳同行 42.9% 和 43.7% .    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc0zpo/r_mathscale_scaling_instruction_tuning_for/</guid>
      <pubDate>Mon, 11 Mar 2024 11:30:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 立场文件：人工智能代理迈向整体智能 - Microsoft 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbz4z8/r_position_paper_agent_ai_towards_a_holistic/</link>
      <description><![CDATA[      论文：https:/ /arxiv.org/abs/2403.00833  摘要：  大型基础模型的最新进展显着增强了我们对开放世界环境中感官信息的理解。在利用基础模型的力量时，人工智能研究必须摆脱过度还原论，转而强调作为有凝聚力的整体的系统。具体来说，我们强调开发人工智能代理——一种将大型基础模型集成到代理操作中的体现系统。代理人工智能的新兴领域涵盖了广泛的现有体现和基于代理的多模式交互，包括机器人、游戏和医疗保健系统等。在本文中，我们提出了一种新颖的大型动作模型实现体现智能行为，代理基础模型。除此之外，我们还讨论了智能体如何在各种领域和任务中展现出卓越的能力，挑战我们对学习和认知的理解。此外，我们从跨学科的角度讨论智能体人工智能的潜力，强调科学话语中的人工智能认知和意识。我们相信这些讨论可以作为未来研究方向的基础，并鼓励更广泛的社会参与。   https:// /preview.redd.it/h8m0ucns7onc1.jpg?width=1228&amp;format=pjpg&amp;auto=webp&amp;s=1cfc94db64f9f358b07353de285faefa5c8ca1a0 https ://preview.redd.it/rjo7pdns7onc1.jpg?width=927&amp;format=pjpg&amp;auto=webp&amp;s=a0728939d5a83c32811c2efbdff9b5a6d58f023f https://preview.redd.it/ng16dfns7onc1.jpg?width=487&amp;format=pjpg&amp;auto=webp ＆amp; ;s=72c6e46c75328cc39e606f149550c0fbf99115a3   由   提交/u/Singularian2501   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbz4z8/r_position_paper_agent_ai_towards_a_holistic/</guid>
      <pubDate>Mon, 11 Mar 2024 09:26:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对比学习的梯度累积（InfoNCE）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbuacq/d_gradient_accumulation_for_contrastive_learning/</link>
      <description><![CDATA[我正在训练多模态对齐模型，但即使使用混合精度训练，我的 GPU 也只能容纳 64 的批量大小。根据 SimCLR 论文，较小的批量大小对于学习而言并不是最佳选择。有什么办法可以在这里实现梯度累积吗？   由   提交/u/Mad_Scientist2027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbuacq/d_gradient_accumulation_for_contrastive_learning/</guid>
      <pubDate>Mon, 11 Mar 2024 04:03:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>