<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 17 Sep 2024 00:59:49 GMT</lastBuildDate>
    <item>
      <title>[R] 同时提交给 neurips 和 coling</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fiivv5/r_submitting_to_neurips_and_coling_at_the_same/</link>
      <description><![CDATA[我可以同时提交 neurips solar 和 coling 2025 吗？Coling 的政策是不提交期刊或会议，但 solar 是一个研讨会，它允许双重提交。    提交人    /u/Puzzleheaded_Soup809   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fiivv5/r_submitting_to_neurips_and_coling_at_the_same/</guid>
      <pubDate>Mon, 16 Sep 2024 23:03:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于微调 LLM 的数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fii851/d_dataset_for_finetuning_llm/</link>
      <description><![CDATA[嗨，我正在对预训练的 LLM 模型进行微调，以便根据我的问题生成答案。 对于微调数据集，我试图了解是否应该提供  针对完全相同的问题提供多种措辞的答案， 对问题的多种措辞提供多种措辞的答案，或者 单个问题和答案对。  哪种方法可能在训练期间产生更好的结果？ 谢谢！    提交人    /u/jamestan9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fii851/d_dataset_for_finetuning_llm/</guid>
      <pubDate>Mon, 16 Sep 2024 22:35:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于不同训练“技巧”的效果的良好研究，例如学习率调度程序（热身/衰减）、权重衰减、dropout、批量大小、动量等？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fihdrd/d_good_studies_on_the_effects_of_different/</link>
      <description><![CDATA[鉴于学习率调度程序（例如线性热身/余弦衰减）、正则化（权重衰减）、dropout、批量大小、动量项（Adam 中的 beta1、beta2）、批量规范等“技巧”的数量变得相当大，并且在这些大型模型上检查这些参数的所有不同组合变得越来越困难，是否有任何现有的研究或众包努力研究当我们改变这些技巧的各种参数时对最终性能（例如验证困惑度）的影响？ 我敢打赌其中很大一部分是在消融研究中，但它们有点太分散了。    提交人    /u/ThienPro123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fihdrd/d_good_studies_on_the_effects_of_different/</guid>
      <pubDate>Mon, 16 Sep 2024 22:01:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在没有标签的情况下使用强化学习创建合成数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fifubi/d_synthetic_data_creation_using_reinforcement/</link>
      <description><![CDATA[那么。假设我们有每周的电力数据，但我们想创建一个模型来捕捉可能导致停电的使用高峰。强化学习代理能否在一周的不同日子中创建使用分布。代理能否捕捉模式并使用模拟数据知道根据其模拟，在特定的星期四而不是星期三或星期日将会发生停电？如果没有每日数据，它将如何评估其预测？    提交人    /u/No_Refrigerator_7841   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fifubi/d_synthetic_data_creation_using_reinforcement/</guid>
      <pubDate>Mon, 16 Sep 2024 21:01:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] FPL Auto：开源、机器学习数据驱动的 FPL 管理器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fifsqd/p_fpl_auto_open_source_machine_learning/</link>
      <description><![CDATA[https://preview.redd.it/r3chz4wsg8pd1.png?width=1250&amp;format=png&amp;auto=webp&amp;s=2e5eb20d4c410236d3d7c1e65fc651edd9a35228 我的大学项目 FPL Auto 是一个基于 Python 的应用程序，它利用统计分析和机器学习算法来自动化您的 FPL 团队的管理。 FPL Auto 是一个自我游戏的 FPL 经理，每个赛季稳定地获得大约 2000 分。 FPL Auto 是一个基于 Python 的应用程序，它利用机器学习算法在整个 FPL 赛季中自主选择球员、进行转会和使用筹码。 FPL Auto 通过分析历史数据和当前趋势，做出数据驱动的决策，以优化您团队的表现。 主要特点：  自动球队选择：FPL Auto 采用先进的算法，根据球员状态、赛程和球队动态选择最佳首发阵容。 智能转会策略：利用预测模型，该工具可以确定最有希望的转会目标，以最大化积分。 战略芯片使用：FPL Auto 可以自动使用 Wildcard、Bench Boost 和 Triple Captain 等芯片。 兼容性：FPL Auto 目前可以生成模型并实时运行过去 4 个赛季和当前赛季。  https://preview.redd.it/5g0138aig8pd1.png?width=1518&amp;format=png&amp;auto=webp&amp;s=a939e1c80cedcf7a962e933863d60ba829f7f086 您可以通过 Python 自行运行该项目，FPL Auto 是一个开源项目，欢迎您的贡献。查看 GitHub 上由 bentindal 开发的名为 FPL Auto 的项目，以探索代码、提出改进建议，甚至开发新功能并帮助我使这个项目尽可能完美。 开箱即用，您可以通过输入“python manager.py -season 2023-24”来运行过去 4 个赛季的项目，尝试将 2023-24 替换为另一个赛季，例如 2022-23。 要运行代码，首先安装 requirements.txt 文件并运行“python manager.py -h”以获取有关如何运行项目的详细帮助。您可以使用“python model.py -h”以获得有关生成 manager.py 运行的模型的帮助。    提交人    /u/Firm_Cricket1091   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fifsqd/p_fpl_auto_open_source_machine_learning/</guid>
      <pubDate>Mon, 16 Sep 2024 20:59:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 扩展 - 推理 8B 和训练 405B 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fic61y/d_scaling_inferencing_8b_training_405b_models/</link>
      <description><![CDATA[感谢你们组成了这么棒的社区！ 我一直在尝试寻找指南来扩展更大模型的训练/推理设置，但在训练细节方面，我找不到任何不费解的东西。如果您能分享任何指南或帮助解答（或部分解答）我的问题，那将非常有帮助。我希望这能帮助其他希望扩展训练/推理设置的人。 设置：我有两个 24GB VRAM（7900XTX）和 128GB RAM/AMD 7900X，两个节点上各有一个，通过 Infiniband 连接。我正在试验 Llama 3.1 8B 模型（未量化）。 当前状态：当我将 8B 模型加载到 GPU 上时，我看到 16GB 已分配/16GB 已保留  使用 FSDP（FULL_SHARD）拆分模型仍然显示 8GB 已分配/16GB 已保留。 a) 为什么要保留完整的 16GB？是为了从其他分片传输层吗？ b) 有没有办法手动管理该保留？ c) FULL_SHARD 需要 100 倍的时间来处理相同的请求（可能是由于网络限制）。 5 个提示在没有分片的情况下花费了 30 秒，但使用 FULL_SHARD 和 40Gbps Infiniband 时花费了 3000 秒。 在不使用任何分布式技术的情况下，该模型占用了 16GB VRAM，添加“-max_seq_len 8000”会预分配/保留另外 6GB VRAM。但是，当我给它一个 7000 个令牌的提示时，它会抛出 CUDA OOM，即使在预分配之后也是如此。 a) 是因为预分配是为了“平均”提示长度估计而完成的吗？ b) 如何将此推理设置扩展到 24 GB 卡上的 CUDA OOM 限制之外（即使有人有 100 张 24GB 卡？）？所有查询都可以在“-max_seq_len 5000”下正常工作设置（如果提示较长，则只会显示令牌用完）。 c) 在半商业环境中，是否有人实现过超过 20K 个令牌？我看不出有人能达到 128K 个令牌。 如何推断更大的模型，例如 70B 模型？我认为需要 FSDP 类型的框架，但即使在 100Gbps 卡上也会非常慢。 更大的 405B 模型的训练设置是什么样的？ a) 即使我们使用 FSDP，考虑到 Grads 和 Optimizer States 所需的 VRAM 以及网络限制，我发现很难在任何合理的时间内处理数万亿个令牌，因为网络可能是 O(n^2) 约束，其中 n 是分片的层数。我感觉我错过了一些东西。 b) 即使网络不是问题，在加载碎片后，我们如何将 128K 代币放入卡中？例如，如果碎片本身就占用了 60-70% 的内存，我们如何为 10K 或 20K 代币（更不用说 128K 代币）腾出空间。在我看来，这最终会成为 H100 卡以及万亿参数模型（MoE 或非 MoE）的问题。  我正在通过添加 10 7900 XTX 设置来扩展我的设置，但我真的很想在继续购买之前弄清楚这些细节。谢谢！    提交人    /u/gulabbo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fic61y/d_scaling_inferencing_8b_training_405b_models/</guid>
      <pubDate>Mon, 16 Sep 2024 18:33:52 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 挪威 TTS 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fiajm5/research_norwegian_tts_model/</link>
      <description><![CDATA[你好！ 我正在尝试创建挪威语 TTS，我想知道是使用预训练的 TTS 模型还是创建一个新模型更好？我浏览过 Huggingface 上的模型，但似乎找不到任何经过挪威语数据训练的模型。我对此有点陌生，所以我想知道最好的策略是什么？我确实可以访问大量数据，但我不确定多少才足够。有人知道我可以使用的一些智能策略或一些预训练模型吗？谢谢。:)    提交人    /u/Victorialangoe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fiajm5/research_norwegian_tts_model/</guid>
      <pubDate>Mon, 16 Sep 2024 17:27:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] CPL：关键规划步骤学习提升 LLM 在推理任务中的泛化能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fi7ovt/r_cpl_critical_planning_step_learning_boosts_llm/</link>
      <description><![CDATA[      TL;DR 通过 MCTS 和每步优势偏好优化提高 LLM 的规划能力 论文： https://arxiv.org/pdf/2409.08642 摘要：  对大型语言模型 (LLM) 进行后训练以开发推理能力已被证明在数学推理和代码生成等不同领域都很有效。然而，现有方法主要侧重于改进特定任务的推理能力，但尚未充分解决模型在更广泛的推理任务中的泛化能力。为了应对这一挑战，我们引入了关键规划步骤学习 (CPL)，它利用蒙特卡洛树搜索 (MCTS) 探索多步骤推理任务中的不同规划步骤。基于长期结果，CPL 学习步骤级规划偏好，以提高模型的规划能力，从而提高其一般推理能力。此外，尽管现有的偏好学习方法（如直接偏好优化 (DPO)）在许多对齐 LLM 的场景中都很有效，但由于无法在每个步骤中捕捉细粒度的监督，因此在处理复杂的多步骤推理任务时会遇到困难。我们提出了步骤级优势偏好优化 (Step-APO)，它将通过 MCTS 获得的步骤级偏好对的优势估计集成到 DPO 中。这使模型能够更有效地学习关键的中间规划步骤，从而进一步提高其在推理任务中的泛化能力。实验结果表明，我们的方法专门针对 GSM8K 和 MATH 进行训练，不仅显著提高了 GSM8K (+10.5%) 和 MATH (+6.5%) 的性能，而且还增强了域外推理基准，例如 ARC-C (+4.0%)、BBH (+1.8%)、MMLU-STEM (+2.2%) 和 MMLU (+0.9%)。  视觉摘要： https://preview.redd.it/afih1qsaw6pd1.png?width=975&amp;format=png&amp;auto=webp&amp;s=bd0c3c4385897c581dff193a02267052481a0e68 性能： https://preview.redd.it/hehec8txw6pd1.png?width=1117&amp;format=png&amp;auto=webp&amp;s=a3d069590221c7acd509e1af83ea07a691f4e507 https://preview.redd.it/xgm1m55zw6pd1.png?width=1125&amp;format=png&amp;auto=webp&amp;s=566f067d6bff31605b04f0ec0edb79c35945f77f    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fi7ovt/r_cpl_critical_planning_step_learning_boosts_llm/</guid>
      <pubDate>Mon, 16 Sep 2024 15:35:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 天体物理学中的替代模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fi0zx2/d_surrogate_modelling_in_astrophysics/</link>
      <description><![CDATA[大家好，我是一名天体物理学家，目前正在研究 X 射线光谱，我正在寻找有关替代模型的讨论/建议。我将描述一下我们现在遇到的问题、我们尝试过的东西以及出现的新问题。 为了让你们知道，我们研究来自黑洞、星系团、中子星等各种物体的 X 射线光谱，以了解这些物体中发生的物理过程。一般来说，使用模型并对其进行拟合，我们可以很好地了解物理属性，例如质量、温度和其他我不会深入讨论的细节。如今，由于计算需求高，模型变得越来越复杂（例如，我们可能需要在黑洞周围进行相对论射线追踪，以正确描述它们发出的光）。 因此，光谱模型是能量和一系列参数的函数（对于我所知道的模型，参数为 2 到 ~30），并且通常，我们想要计算两种能量之间的通量（这主要是因为我们的仪器就是这样工作的）。光谱只是根据给定数量的能量箱（通常介于 100 到 2000 之间，对于最新的仪器最多为 60 000）评估的通量。 我们正在采取这种方法的小步骤，并首先尝试学习在固定网格上近似这些光谱，这与特定仪器测量的光谱相对应。这很好，因为当使用测量光谱时，我们可以定义一个有效的指标来解释我们正在测量的统计行为。我们观察到，训练 VAE 以及模型参数与潜在空间之间的映射在生成模拟光谱方面效果很好。 但是，我们希望生成通用模拟器 f(E_low, E_high, theta)，它可以在用仪器测量之前，在任意箱体或箱体集合中评估此模型。我们发现，由于各种原因，这更具挑战性。我还没有深入研究这个主题，但这是我在处理数据时的想法：  模拟器应该学习这种函数的连续属性，以及其他属性，例如 f(E_1, E_2, theta) + f(E_2, E_3, theta) = f(E_1, E_3, theta)。当使用 (E_low, E_high, theta) 的随机样本进行盲目训练时，我们无法保证这一点。  模拟器应该能够处理 E_low、E_high 的矢量化输入。我觉得使用模拟器 f(E_low, E_high, theta) 并将其映射到 60 000 个 (E_i, E_i+1) 箱会非常低效。 与通用模拟器相比，固定网格上的 VAE 工作得非常好，这可能是因为它可以依赖于前面指出的数据连续性。但它不能直接推广。我想不出一个架构，它采用任意大小的能量网格，并在相同任意大小的能量网格上输出通量，并对给定的一组参数 theta 进行额外的调节。  目前，我正在寻找一种能够嵌入/解码任意大小的 1D 数组的架构。但我指出的大多数事情可能是错误的，我对 ML 的了解与领域非常相关，而且我缺乏对这些方法的全局视野，无法正确完成这些事情。这就是我写这篇文章的原因！如果您有任何想法、建议，想讨论这个话题，我会非常高兴收到来自出色的 ML 社区的反馈。  NB：如果您想私下讨论这个问题，请随时给我发私信或写信给我 sdupourque[at]irap.omp.eu    提交人    /u/renecotyfanboy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fi0zx2/d_surrogate_modelling_in_astrophysics/</guid>
      <pubDate>Mon, 16 Sep 2024 10:18:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 分解 PyTorch 函数帮助我了解其内部发生的事情</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhwwli/p_breaking_down_pytorch_functions_helped_me_with/</link>
      <description><![CDATA[大家好， 我以前很难理解 PyTorch 库内部发生了什么。分解内部工作原理对我来说一直是一个挑战，因此我对一些关键功能进行了简单的解释。 这里我重点关注：  loss.backward() torch.no_grad() requires_grad=True  我知道还有很多东西需要探索，稍后我会介绍其他功能。 也许你们中的一些人可以告诉我：  如果您有其他“黑匣子”功能，您会感到困惑 您是否理解了我的解释 对视频的任何反馈（我非常感谢正面和负面的反馈）  非常感谢！    提交人    /u/vtimevlessv   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhwwli/p_breaking_down_pytorch_functions_helped_me_with/</guid>
      <pubDate>Mon, 16 Sep 2024 05:13:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 论文、博客和项目的集合，重点关注 OpenAI o1 和推理技术。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhtkz5/r_a_collection_of_llm_papers_blogs_and_projects/</link>
      <description><![CDATA[        提交人    /u/Happysedits   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhtkz5/r_a_collection_of_llm_papers_blogs_and_projects/</guid>
      <pubDate>Mon, 16 Sep 2024 02:07:49 GMT</pubDate>
    </item>
    <item>
      <title>[N] CVPR 2025 的新变化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhq7rb/n_new_changes_to_cvpr_2025/</link>
      <description><![CDATA[  由    /u/stirling_approx  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhq7rb/n_new_changes_to_cvpr_2025/</guid>
      <pubDate>Sun, 15 Sep 2024 23:20:02 GMT</pubDate>
    </item>
    <item>
      <title>用 C 语言构建 gpt2 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhjtyo/built_gpt2_in_c_p/</link>
      <description><![CDATA[OpenAI 从第一原理用纯 C 语言实现 GPT-2 论文。1. 从头开始​​实现各种 GPT 组件（如 LayerNorm、多层感知器 (MLP) 和因果注意）的前向传播和反向传播。2. 没有使用像 PyTorch 这样的自动求导引擎；模型权重的梯度是使用手工推导的导数计算的。通过不保存不必要的激活值，此方法将内存使用量减少了近 20 GB。3. 通过文件的内存映射来处理激活和模型权重的内存管理。4. 该项目的目的是探索 PyTorch 和深度学习的低级内部工作原理。 5. 任何对 C 有基本了解的人都可以轻松理解和实现其他大型语言模型（LLM），如 LLaMA、BERT 等。 Repo 链接：https://github.com/shaRk-033/ai.c    提交人    /u/Silly-Dig-3312   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhjtyo/built_gpt2_in_c_p/</guid>
      <pubDate>Sun, 15 Sep 2024 18:43:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>