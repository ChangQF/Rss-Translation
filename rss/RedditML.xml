<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 08 Jun 2024 06:18:35 GMT</lastBuildDate>
    <item>
      <title>[D] 法学硕士 (LLM) 的私人推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dauewa/d_private_inferencing_for_llms/</link>
      <description><![CDATA[您好， 基于云的 LLM 推理面临的最大挑战之一是保护用户数据的私密性。是否可以同时使用本地和云机器来解决这个问题？ 例如，我们可以在本地机器上运行 LLM 的第一层和最后一层来保护数据，并使用云来处理其余数据以加快速度吗？我们可以在本地微调第一层和最后一层以更改权重并使其远离云端。 如果有任何正在进行的研究使用此方法进行隐私推理，请告诉我。 谢谢。    提交人    /u/manili   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dauewa/d_private_inferencing_for_llms/</guid>
      <pubDate>Sat, 08 Jun 2024 04:17:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 采用 NanoGPT 的 4Chan AI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1das9u4/p_the_4chan_ai_with_nanogpt/</link>
      <description><![CDATA[因此，我决定使用 nanoGPT 和一个脚本来制作一个快速 AI，该脚本将提取并归档 4chan API json，然后我接受它，现在我正在使用 nanoGPT 训练它，此配置为 https://pastebin.com/UHjAuwkf 它的配置很小，旨在能够在游戏笔记本电脑或配备中端 nvidia GPU 的设备上进行训练，而且它现在运行良好，我试图让它不输出垃圾，但获取 4chan /b 内容的脚本在这里 https://pastebin.com/UmDiG2KP    提交人    /u/thatrandondeveloper   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1das9u4/p_the_4chan_ai_with_nanogpt/</guid>
      <pubDate>Sat, 08 Jun 2024 02:17:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 爱丽丝梦游仙境：简单任务展现最先进的大型语言模型中完整的推理能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dah5ie/r_alice_in_wonderland_simple_tasks_showing/</link>
      <description><![CDATA[  由    /u/conceptual_visual_me  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dah5ie/r_alice_in_wonderland_simple_tasks_showing/</guid>
      <pubDate>Fri, 07 Jun 2024 17:55:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 测试 LoRA 初始化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dadfcv/r_testing_lora_initialisations/</link>
      <description><![CDATA[      大家好，过去几天，我一直在测试几种不同的 LoRA 初始化方法。如您所知，默认情况下，我们将 ΔW = AB 初始化为 A~kaiming_uniform，将 B 初始化为零。但我想尝试其他初始化策略，这些策略可导致 ΔW = 0，但可能使用最少的零参数。  以下是我尝试过的方法：  反转初始化：将 A 初始化为零，将 B 初始化为均匀分布 纯正交初始化：创建两个彼此正交的非零矩阵。为此，我有两种策略。  取一组随机的正交向量（通过对随机矩阵进行正交分解），将其分成两组。  将单位矩阵的行分成两组。 （例如，集合 1 中的偶数行和集合 2 中的奇数行） 使用第一组中元素的线性组合初始化 A，使用集合 2 中的元素的线性组合初始化 B   我在不同的模型上进行了相同的训练，例如 llama-2-7B、llama-3-8B、mistral-7B-v0.3 和 llama-2-13B。我使用的数据集是 MetaMathQA 和 MagicCoder-evol。我发现正​​交初始化比标准初始化表现更好。我只是比较了每次运行的评估损失。  评估不同初始化策略的损失。 所以我觉得这很有趣。这有点像我所期望的那样，用较少的零进行初始化应该是好的。 我注意到的另一件事是，lora_B 的梯度始终比 lora_A 的梯度更分散。我最初以为这是由于初始化，那些初始化为零的梯度会用更大的数字更新。但对于不同的初始化也是如此。这很令人惊讶。也许是操作顺序导致了这种情况？我不知道... 我在博客文章 https://datta0.github.io/blogs/know-your-lora/ 中详细介绍了所有内容，请随时阅读，如果您有任何想法/评论，请告诉我。 干杯。    提交人    /u/im_datta0   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dadfcv/r_testing_lora_initialisations/</guid>
      <pubDate>Fri, 07 Jun 2024 15:22:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 挑战：识别随机生成的数据集中的混合函数 - 您能解决吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dacsxc/r_challenge_identify_mixed_functions_in_randomly/</link>
      <description><![CDATA[简介 大家好，Reddit ML/DS 社区！我在 Kaggle 上创建了一个有趣的谜题，我很想看看你们如何解决它。这项挑战涉及分析数据集以确定在何处将多个函数应用于数据点。如果您对机器学习或数据科学感兴趣，那么这个谜题非常适合您！ 谜题 描述 您有 12 个数据集，每个数据集由 8,000 个数据点组成，每个点包含 28 个特征。这些数据是通过将一个或两个不同的平滑函数随机应用于数据点生成的。您能确定哪个数据集的数据点应用了多个函数吗？ 数据生成代码 下面是生成数据集的示例 Python 代码： import numpy as np import torch from import TensorDataset n_dataset = 12 numbers_of_functions = np.random.choice([1,2], (n_dataset,), p=[.5, .5]) datasets = [None]*n_dataset mix_indices = None for i in range(n_dataset): X = np.random.uniform(0, 2, size=(8000, 28)).astype(np.float32) # 输入 Y1 = np.sum((.5*X)**2, axis=1)-7 # 应用第一个函数 f(x) Y2 = -np.sum((.5*X)**2, axis=1)+7 # 应用第二个函数 g(x) mix_indices = np.ones((len(X),),dtype=int) if numbers_of_functions[i] == 2: mix_indices = np.random.choice([0,1], (len(X),)) Y = np.concatenate([Y1.reshape(-1,1), Y2.reshape(-1,1)], axis=-1)[range(len(X)), mix_indices] # 目标 datasets[i] = TensorDataset(torch.from_numpy(X), torch.from_numpy(Y))torch.utils.data  说明和目标 您的任务是分析存储在 `datasets` 列表中的数据集，并确定哪些数据集应用了多个函数，如 `numbers_of_functions` 变量所定义。  原始讨论 总共有 3 个谜题。请查看 Kaggle 上的原始讨论以了解更多背景信息：Kaggle 讨论 你为什么要参加？ 我创建这个谜题的目的是发起一个关于一个问题的讨论，就我有限的知识而言，这个问题以前从未被解决过。然而，像这样的流形学习和聚类的混合几乎肯定是数据科学和机器学习旨在解决的问题之一。我希望这个挑战能为未来的相关研究带来积极的能量和有价值的讨论。为了让知识共享更加开放，谜题的设计重点不是详细的解决方案，而是科学有效性。如果你有解决方案，你不需要分享，而只是让别人相信你已经解决了它。 行动号召 我很高兴看到你如何应对这个挑战！分享您的见解，让我们讨论解决这个问题的不同方法。 快乐解谜！    提交人    /u/Immediate_Pack5625   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dacsxc/r_challenge_identify_mixed_functions_in_randomly/</guid>
      <pubDate>Fri, 07 Jun 2024 14:57:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 弥合神经网络形式语言学习中的经验与理论之间的差距</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dab1ef/r_bridging_empiricaltheoretical_gap_in_neural/</link>
      <description><![CDATA[https://arxiv.org/abs/2402.10013    提交人    /u/inland-1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dab1ef/r_bridging_empiricaltheoretical_gap_in_neural/</guid>
      <pubDate>Fri, 07 Jun 2024 13:43:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是不是我的问题，或者基准测试似乎让语言模型变得更糟了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1daa68e/d_is_it_me_or_does_it_seem_like_benchmarks_are/</link>
      <description><![CDATA[这些在过去曾经非常有用，全面适用。现在大多数语言模型总是忽略简单的指令。LLama3 似乎是最好的，Claude 也不错。GPT-4o 感觉非常马虎，总是忽略指令或给出类似但根本没有要求的东西。自从谷歌推出 Gemini 以来，我注意到的唯一变化是对基准的关注。您是否认为这些基准让开发人员过度优化语言模型，从而使语言模型变得更糟？类似的情况是，尽管 GAN 的行为不准确，但 GAN 有时会通过在鉴别器中找到黑客而崩溃？（其中一些使用语言模型使其更容易被黑客入侵）。 编辑：这是对那些完全混蛋而不是善意讨论的男孩的。 非常不专业的行为。这只是在讨论观察结果。我当然知道什么是统计数据。如果你认为数字可以说明一切，那你就太愚蠢了。本文旨在讨论可以进行的潜在改进，或者这些基准是否缺乏评估来解释人们为什么会这样想。    提交人    /u/I_will_delete_myself   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1daa68e/d_is_it_me_or_does_it_seem_like_benchmarks_are/</guid>
      <pubDate>Fri, 07 Jun 2024 13:05:18 GMT</pubDate>
    </item>
    <item>
      <title>尝试理解IDM-VTON [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da8gv4/trying_to_understand_idm_vton_d/</link>
      <description><![CDATA[有人能进一步解释一下训练过程是如何进行的吗？扩散模型到底在哪里，其他模块如何连接到扩散模型。我还对使用的损失函数以及选择将配对的人 + 服装用于其中一个网络而不是仅提供面罩感兴趣。 https://arxiv.org/abs/2403.05139 谢谢     提交人    /u/ashblue21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da8gv4/trying_to_understand_idm_vton_d/</guid>
      <pubDate>Fri, 07 Jun 2024 11:36:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新书！设计一个机器学习系统（从头开始）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da7cgx/r_new_book_design_a_machine_learning_system_from/</link>
      <description><![CDATA[      大家好，感谢大家给我们机会与社区分享我们最新的 MEAP 版本。 设计机器学习系统（从头开始） 作者：Benjamin Tan Wei Hao、Shanoop Padmanabhan 和 Varun Mallya 我们最新的 MEAP 版本教你如何从头开始设计可靠的 ML 系统。它结合了 MLOps 和 DevOps 以及一系列经过验证的基础设施工具，包括 Kubeflow、MLFlow、BentoML、Evidently 和 Feast。 在整本书中，你将构建图像分类器和推荐系统的交付管道，同时学习最佳实践。 获得机器学习工作流程基本部分的实践经验，包括编排管道、模型训练、服务以及监控和可解释性。 🚀 立即采取行动！使用代码 retanweihao50 可节省 50% 📖 进入书籍：https://mng.bz/PZBR 📹 观看此视频以了解更多信息：https://mng.bz/1GZq 谢谢阅读。 https://preview.redd.it/u7p5fakfm45d1.jpg?width=718&amp;format=pjpg&amp;auto=webp&amp;s=f2d7cf88fbb3c0e72d64d1ee42ae047ecbbb2ca5 干杯，    提交人    /u/ManningBooks   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da7cgx/r_new_book_design_a_machine_learning_system_from/</guid>
      <pubDate>Fri, 07 Jun 2024 10:26:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 从 GPT-4 中提取概念</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da6ml3/r_extracting_concepts_from_gpt4/</link>
      <description><![CDATA[与最近 Anthropic 的报告类似，OpenAI 发布了一份报告、一些代码和一个可视化工具，用于显示自动编码器从其模型中提取的特征。 OpenAI 博客文章：https://openai.com/index/extracting-concepts-from-gpt-4/ 论文：https://cdn.openai.com/papers/sparse-autoencoders.pdf 代码：https://github.com/openai/sparse_autoencoder    由   提交  /u/valdanylchuk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da6ml3/r_extracting_concepts_from_gpt4/</guid>
      <pubDate>Fri, 07 Jun 2024 09:37:07 GMT</pubDate>
    </item>
    <item>
      <title>[N] vLLM 发布了对嵌入 API 和 OpenAI 类嵌入客户端的初始支持！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da5wut/n_vllm_released_intial_support_for_embedding_api/</link>
      <description><![CDATA[很容易错过这个版本，但我很高兴几天前碰到了它。vLLM 发布了对带有 e5-mistral-7b-instruct 和 OpenAI 类嵌入客户端的嵌入 API 的初始支持！为什么这很重要？因为现在您只需一个推理引擎即可构建整个 RAG 解决方案！ https://docs.vllm.ai/en/latest/getting_started/examples/openai_embedding_client.html    提交人    /u/Patrick-239   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da5wut/n_vllm_released_intial_support_for_embedding_api/</guid>
      <pubDate>Fri, 07 Jun 2024 08:43:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何协调双重下降与毛丝鼠缩放定律？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da4j55/d_how_to_reconcile_double_descent_with_chincilla/</link>
      <description><![CDATA[前段时间，我听说 Chinchilla 缩放定律时，似乎认为许多主流 LLM 都严重训练不足，应该在模型大小不变的情况下，使用更多的数据进行训练。 不过，我最近也遇到了“双重下降”的概念，它似乎持相反观点 - 你应该在计算预算允许的范围内尽可能增加模型中的参数数量，即使参数/样本的比率非常高，只要你有某种正则化，模型在样本外的表现仍然会非常好，尽管过度拟合严重。 我该如何调和这两个看似对立的论点？一个主张降低参数/样本比率，另一个主张提高它。    提交人    /u/sam_the_tomato   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da4j55/d_how_to_reconcile_double_descent_with_chincilla/</guid>
      <pubDate>Fri, 07 Jun 2024 07:01:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch Vs....为什么仍然是 Tensorflow？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9w79p/d_pytorch_vs_why_still_tensorflow/</link>
      <description><![CDATA[经过长时间的中断，我重新回到了机器学习领域。在与朋友交谈并做了一些研究（例如，2024 年 Tensorflow 与 PyTorch 的快速投票）后，我觉得 TensorFlow 可能不是恢复速度的最佳库。 现在，我对这篇文章的问题是：如果 TensorFlow 已经失宠到这种程度，人们建议不要使用它，那么为什么谷歌搜索“PyTorch vs.”仍然会带来大量将 PyTorch 与 TensorFlow 进行比较的文章和网站吗？ 在设置 PyTorch 环境之前，我应该考虑没有像样的 PyTorch 竞争者吗？ 期待您的见解！    提交人    /u/Tolure   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9w79p/d_pytorch_vs_why_still_tensorflow/</guid>
      <pubDate>Thu, 06 Jun 2024 23:19:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您是 NeurIPS'24 的审稿人吗？请阅读此内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9o8tn/r_are_you_a_reviewer_for_neurips24_please_read/</link>
      <description><![CDATA[你好！ 我目前担任 NeurIPS&#39;24 的区域主席 (AC)。提交的论文数量非常多，为这些论文分配合格的审稿人非常困难。 为什么很难，你可能会问。从高层次上讲，这是因为我们作为 AC，没有足够的信息来判断一篇论文是否分配给了足够数量（至少 3 个）的合格审稿人（即，能够对论文进行信息性评估的个人）。事实上，作为 AC，我们只能使用以下标准来决定是否为任何给定的论文分配审稿人：(i) 他们的出价；(ii) “亲和力”得分；(iii) 他们的个人 OpenReview 个人资料。但是  在注册成为审稿人的人中，只有一小部分对论文进行了投标。举个例子，在我堆积如山的论文中，有 30% 没有审稿人对其进行投标；实际上，大多数论文只有 3-4 个出价（不一定是“积极的”）。 当没有出价时，下一个指标是“亲和力”分数。但是，这个指标是以自动方式计算的，效果不佳（此外，一个人可能是某个领域的专家，但他们可能不愿意审阅某篇论文，例如，由于个人偏见）。 我们可以使用的最后一个指标是审稿人的“背景”，但这需要我们（即 AC）手动检查每个审稿人的 OpenReview 个人资料——这很耗时。更糟糕的是，今年的 NeurIPS 有相当多的审稿人是本科生或硕士生，他们的 OpenReview 资料完全为空。  鉴于上述情况，我写这篇文章是为了请求您的合作。如果您是 NeurIPS 的审稿人，请确保您的 OpenReview 资料是最新的。如果您是本科生/硕士生，请附上一个网页链接，该链接可以显示您是否具有审稿专业知识，或者您是否与一些“专家研究人员”在实验室工作（他们可能会通过提供审稿技巧来帮助您）。这同样适用于博士生或博士后：确保 OpenReview 上提供的信息反映了您的专业知识和偏好。 底线：您已同意担任（可以说是顶级的）顶级 ML 会议的审稿人。 请认真对待这项职责。如果您被分配到正确的论文，您将能够提供更多有用的评审，评审过程也会更顺畅。有用的评审对作者和 AC 都很有用。通过做得好，您甚至可能会获得“顶级评审员”的认可。    提交人    /u/hihey54   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9o8tn/r_are_you_a_reviewer_for_neurips24_please_read/</guid>
      <pubDate>Thu, 06 Jun 2024 17:46:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>