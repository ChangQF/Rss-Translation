<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Fri, 23 Aug 2024 06:21:31 GMT</lastBuildDate>
    <item>
      <title>[R] 输血：使用一个多模态模型预测下一个标记并扩散图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ez422y/r_transfusion_predict_the_next_token_and_diffuse/</link>
      <description><![CDATA[Transfusion 在单一模型中统一了文本和图像生成，可与专门的架构相媲美。    提交人    /u/AhmedMostafa16   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ez422y/r_transfusion_predict_the_next_token_and_diffuse/</guid>
      <pubDate>Fri, 23 Aug 2024 04:37:19 GMT</pubDate>
    </item>
    <item>
      <title>torch.argmin() 非可微性解决方法 [R][D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ez2ygd/torchargmin_nondifferentiability_workaround_rd/</link>
      <description><![CDATA[我正在实现一个基于地形约束的神经网络层。该层可以被认为类似于 2D 网格图，或者基于深度学习的自组织图。它由 4 个参数组成，即高度、宽度、潜在维数和 p 范数（用于距离计算）。每个单元/神经元的维数等于潜在维数。此类的最简代码为： class Topography(nn.Module): def __init__( self, latent_dim:int = 128, height:int = 20, width:int = 20, p_norm:int = 2 ): super().__init__() self.latent_dim = latent_dim self.height = height self.width = width self.p_norm = p_norm # 创建包含索引 2D 坐标的 2D 张量 locs = np.array(list(np.array([i, j]) for i in range(self.height) for j in range(self.width))) self.locations = torch.from_numpy(locs).to(torch.float32) del locs # 线性层的可训练权重 - self.lin_wts = nn.Parameter(data = torch.empty(self.height * self.width, self.latent_dim), require_grad = True) # 高斯初始化，平均值 = 0 且 std-dev = 1 / sqrt(d)- self.lin_wts.data.normal_(mean = 0.0, std = 1 / np.sqrt(self.latent_dim)) def forward(self, z): # L2 标准化 &#39;z&#39; 将其转换为单位向量- z = F.normalize(z, p = self.p_norm, dim = 1) # 每个输入到所有 SOM 单元的成对平方 L2 距离（L2 范数距离）- pairwise_squaredl2dist = torch.square( torch.cdist( x1 = z, # 还将所有 lin_wts 转换为单位向量- x2 = F.normalize(input = self.lin_wts, p = self.p_norm, dim = 1), p = self.p_norm ) ) # 对于每个输入 zi，计算“lin_wts”中的最近单元 - nearest_indices = torch.argmin(pairwise_squaredl2dist, dim = 1) # 获取 2D 坐标索引 - nearest_2d_indices = self.locations[closest_indices] # 计算最近单元和其他每个单元之间的 L2 距离 - l2_dist_squared_topo_neighb = torch.square(torch.cdist(x1 = nearest_2d_indices.to(torch.float32), x2 = self.locations, p = self.p_norm)) del nearest_indices, nearest_2d_indices return l2_dist_squared_topo_neighb, pairwise_squaredl2dist  对于给定的输入“z”（比如编码器的输出） ViT/CNN），它计算距离最近的单元，然后使用径向基函数核/高斯（逆）函数在该最近单元周围创建地形结构——在下面的&quot;topo_neighb&quot; 张量中完成。 由于&quot;torch.argmin()&quot;给出类似于独热编码向量的索引，这些向量根据定义是不可微的，我正在尝试创建一个解决方法： # 2D 单元数 - height = 20 width = 20 # 每个单元的维数指定为 - latent_dim = 128 # 使用 L2-norm 进行距离计算 - p_norm = 2 topo_layer = Topography(latent_dim = latent_dim, height = height, width = width, p_norm = p_norm) optimizer = torch.optim.SGD(params = topo_layer.parameters(), lr = 0.001, influence = 0.9) batch_size = 1024 # 创建一个输入向量 - z = torch.rand(batch_size, latent_dim) l2_dist_squared_topo_neighb, pairwise_squaredl2dist = topo_layer(z) # l2_dist_squared_topo_neighb.size(), pairwise_squaredl2dist.size() # (torch.Size([1024, 400]), torch.Size([1024, 400])) curr_sigma = torch.tensor(5.0) # 计算相对于最近单元的高斯拓扑邻域结构- topo_neighb = torch.exp(torch.div(torch.neg(l2_dist_squared_topo_neighb), ((2.0 * torch.square(curr_sigma)) + 1e-5))) # 计算地形损失- loss_topo = (topo_neighb * pairwise_squaredl2dist).sum(dim = 1).mean() loss_topo.backward() optimizer.step()  现在，成本函数的值发生了变化，减少。另外，作为健全性检查，我正在记录&quot;topo_layer.lin_wts&quot; 的 L2 范数，以反映其权重正在使用梯度进行更新。 这是正确的实现，还是我遗漏了什么？    提交人    /u/grid_world   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ez2ygd/torchargmin_nondifferentiability_workaround_rd/</guid>
      <pubDate>Fri, 23 Aug 2024 03:36:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 生活方式咨询系统数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyv17i/p_dataset_for_lifestyle_advisory_system/</link>
      <description><![CDATA[嘿，我想为我的简历创建一个个性化的生活方式咨询系统项目（以获得实习机会）主要想法是微调 llama 3，但我不知道从哪里获取数据集以及 LLM 响应应该是什么样子，以便对用户来说最好 在 Web 界面中，我可以从调查中的用户那里获得一些个性化数据，例如他们的年龄、锻炼习惯、体重指数、疾病、天气（使用 api）和其他东西，但不知道如何微调 LLM，他们也是一个工具 lamini 内存调整技术你能就这个项目给我什么建议吗？    提交人    /u/EstablishmentDry6444   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyv17i/p_dataset_for_lifestyle_advisory_system/</guid>
      <pubDate>Thu, 22 Aug 2024 21:25:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 规范流程及其缺点。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyspa2/d_normalizing_flows_and_their_disadvantages/</link>
      <description><![CDATA[我对使用正则化流来实现需要可逆模型的方法很感兴趣。但我还担心使用 NF 的生成质量较差。该领域最近有什么进展吗？    提交人    /u/Alternative-Talk1945   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyspa2/d_normalizing_flows_and_their_disadvantages/</guid>
      <pubDate>Thu, 22 Aug 2024 19:48:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我的项目需要一个合适的文本分类转换器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyr41a/p_need_a_suitable_textclassification_transformer/</link>
      <description><![CDATA[我有一个项目，其中有数千种不同类型的产品分类，其信息与项目相关。我还有其他各种 Excel 表，其中包含精确产品的数据，我需要将其与第一张表中的分类进行匹配。对于少数类型，由于初始工作是通过几乎手动标记产品来完成的，因此有很多分类目前还没有任何与之匹配的数据。 我希望构建一个强大的模型，以便将来能够稳健地处理这些分类，可能是变压器。任何建议或指导都将不胜感激，谢谢！    提交人    /u/Personal_Image2021   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyr41a/p_need_a_suitable_textclassification_transformer/</guid>
      <pubDate>Thu, 22 Aug 2024 18:42:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习与理论计算机科学</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyqn3q/d_machine_learning_and_theoretical_computer/</link>
      <description><![CDATA[我想知道是否有一些有趣的方法可以将机器学习和理论计算机科学结合起来。这个问题的背景只是我对这两个主题的个人兴趣。 我能想到的一个有趣的联系是使用强化学习来导航组合优化问题中的大型搜索空间。我还发现了一篇似乎朝这个方向发展的论文：https://arxiv.org/pdf/1811.06128 是否有人在这两个领域的交叉点工作，可以分享一些想法或提供其他有趣论文的指点？    提交人    /u/Gemosu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyqn3q/d_machine_learning_and_theoretical_computer/</guid>
      <pubDate>Thu, 22 Aug 2024 18:22:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 联合概率的阈值调整</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyn4tx/d_threshold_tuning_of_joint_probabilities/</link>
      <description><![CDATA[&lt;要求&gt; - 分类问题 - 类别标签格式 A-B（示例 X-2） - 类别级别的精度验收标准为 0.85  &lt;情况&gt; 标记为子类 X 的文档用于训练二元分类器 X；二元分类器 2 也是如此。 在推理时，将新文档输入模型 X-2 和模型，返回的是模型 X 和模型 2 的预测概率。 由于模型的训练方式，它们不会学习子类之间的依赖关系。在独立性假设下，新文档属于类 X-2 的联合概率为 P(X-2 | 文档) = P(子类 X | 文档) P(子类 2 | 文档)。  由于父类级别需要性能指标，因此将阈值调整应用于联合概率，以达到父类 X-2 性能指标的验收标准。  &lt;问题&gt; - 有人有过将子模型的概率组合起来以获得最终预测的经验吗？当父模型需要性能指标时，组合子模型的预测后进行阈值调整是否存在逻辑缺陷？ - 在为每个子类训练二元分类器时，我深入思考了如何在子类之间注入依赖关系，这个想法浮现在我的脑海里，我不确定它是否正确？ - 如果您希望子类之间存在依赖关系，则意味着您需要精确的组合预测。为了提高精度，您可以将组合预测的阈值调整到所需的精度级别。因此，您是通过阈值调整在子类之间注入依赖关系的。 如果您能发表您的想法和评论，那就太好了！很乐意听听您的意见！    提交人    /u/ActiveBummer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyn4tx/d_threshold_tuning_of_joint_probabilities/</guid>
      <pubDate>Thu, 22 Aug 2024 16:03:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么不对文本转图像使用判别模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eymmxo/d_why_not_use_discriminative_models_for/</link>
      <description><![CDATA[经过多年阅读和使用文本到图像生成的生成模型，这个问题突然出现在我的脑海中。 如果我们将图像的文本描述命名为 x，将相关图像命名为 y，理论上我们完全可以使用判别（概率）模型来学习 p(y|x)。 然而，如今所有的研究都“走上了一条艰难的道路”，开发了生成模型来学习更复杂的 p(x, y) 分布（然后以 x 为条件执行文本到图像等任务）。 但为什么要走这条路呢？最近有人探索过使用判别模型进行条件生成吗？在我看来，一个可靠的概率模型（输出一个经过良好校准的概率分布）可以以更容易的损失预测出好的图像（从 p(y|x) 后验中采样），尤其是在现在大量标记图像数据集盛行的情况下。  判别建模更有效（因为它的任务更简单），所以也许我只是错过了一些关于为什么它不起作用的相关要点 编辑：错别字    提交人    /u/bgighjigftuik   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eymmxo/d_why_not_use_discriminative_models_for/</guid>
      <pubDate>Thu, 22 Aug 2024 15:44:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪个行业的数据最差？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyj7vq/d_what_industry_has_the_worst_data/</link>
      <description><![CDATA[好奇地想听听——您认为哪个行业的 ML 数据质量一贯最差？ 我说的不是没有现实和可预见的 ML 应用的个别工作，比如木工。我说的是更大的行业，银行业、制药业、电信业、科技业（可能有点广泛）、农业、采矿业等等。 谁是陷得最深的？    提交人    /u/Standard_Natural1014   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyj7vq/d_what_industry_has_the_worst_data/</guid>
      <pubDate>Thu, 22 Aug 2024 13:23:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为 MLE/数据工程师/数据科学家，您最不喜欢的工作部分是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyibmw/d_whats_least_favorite_part_of_your_job_as_an/</link>
      <description><![CDATA[当我梦想成为一名机器学习工程师时，我没有想到监控和调试性能回归、回填数据或执行迁移/模型会占用我相当一部分时间。 你的工作中哪一点让你早上起床有点困难？    提交人    /u/skeltzyboiii   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyibmw/d_whats_least_favorite_part_of_your_job_as_an/</guid>
      <pubDate>Thu, 22 Aug 2024 12:41:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] Yolov8 的替代品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyes8d/d_yolov8_alternatives/</link>
      <description><![CDATA[我目前正在使用 Yolov8 进行一些对象检测和分类任务。总的来说，我喜欢它的准确性和速度。但它是经过许可的。有哪些可以同时提供检测和分类功能的免费替代品？    提交人    /u/Powerful-Angel-301   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyes8d/d_yolov8_alternatives/</guid>
      <pubDate>Thu, 22 Aug 2024 09:14:30 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 通过梯度下降进行上下文学习 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eybxel/transformers_learn_incontext_by_gradient_descent_r/</link>
      <description><![CDATA[      有人能帮助我理解论文Transformers learn in-context by gradient descent中的推理吗？作者首先假设一个带有某个权重 \（W\）的“参考”线性模型，然后证明该模型在梯度下降步骤后的损失等于“转换后的数据”的损失。然后，在主要结果（命题 1）中，作者手动构建了 \（K\）、\（Q\）和 \（V\）的权重，使得单头注意层的前向传递将所有标记映射到此“转换后的数据”。 我的问题是：这种构造如何“证明”Transformers可以在上下文学习（ICL）中执行梯度下降？前向传递的输出（即“转换后的数据”）是否被视为新的预测？我认为应该是这样的：新的预测与更新后的权重给出的预测相匹配。我无法理解这里的逻辑。 https://preview.redd.it/cztva19y05kd1.png?width=1046&amp;format=png&amp;auto=webp&amp;s=0196944994516f480670ba9d29be91f8f55fc6f9 https://preview.redd.it/oihuv48405kd1.png?width=1728&amp;format=png&amp;auto=webp&amp;s=8cfc35bf8aa433d53f9d7b5bc5faef3c3e4fba8a    提交人    /u/mziycfh   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eybxel/transformers_learn_incontext_by_gradient_descent_r/</guid>
      <pubDate>Thu, 22 Aug 2024 05:56:07 GMT</pubDate>
    </item>
    <item>
      <title>利用 HuggingFace GPT 模型构建学术错误信息检测器的可行性 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ey9fiy/feasibility_of_using_huggingface_gpt_model_to/</link>
      <description><![CDATA[大家好， 我正在开展一个与 GPT 相关的个人项目，旨在识别学术内容中的错误信息。我们的想法是使用 GPT-2 XL 检查学术文本中的主张，并生成超越简单分类的输出，提供更多与上下文相关的内容。 例如，如果研究论文中的主张指出“某种特定药物已被证明可有效治疗某种疾病”，该模型将使用与该主题相关的其他学术论文的文本，并生成详细的输出，根据证据支持或反驳该主张，并附上简要说明。这个想法是使用滑动窗口来分析其他研究论文的文本内容，以符合文本输入的限制。 我只能访问 RTX GeForce 3060 GPU（12 GB 内存），虽然 GPT-2 XL 在我的设置上运行高效，但我注意到输出质量相当差。 我正在考虑在专注于学术语言和错误信息的自定义数据集上对 GPT-2 XL 进行微调，以提高其在此特定任务中的表现。但是，考虑到我的局限性，我担心可行性。 为此目的在 RTX 3060 上对 GPT-2 XL 进行微调是否可能/实用，或者该过程的计算成本是否太高？    提交人    /u/Mental-Particular104   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ey9fiy/feasibility_of_using_huggingface_gpt_model_to/</guid>
      <pubDate>Thu, 22 Aug 2024 03:30:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 18 Aug 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>