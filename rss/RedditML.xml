<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 29 Mar 2024 00:57:44 GMT</lastBuildDate>
    <item>
      <title>[N] GenAI在医疗领域的机遇</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqanl6/n_opportunities_of_genai_in_healthcare/</link>
      <description><![CDATA[不确定这里有多少人热衷于医疗保健领域的 genAI...这是一个很棒的子堆栈，概述了部署 LLM 的机遇和挑战：https://ambarbhattacharyya.substack。 com/p/re-imagining-the-healthcare-delivery?r=12ee1&amp;utm_campaign=post&amp;utm_medium=web&amp;triedRedirect=true  &amp; #32；由   提交 /u/PriorSuccessful156   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqanl6/n_opportunities_of_genai_in_healthcare/</guid>
      <pubDate>Thu, 28 Mar 2024 23:51:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] LoRA官方实现代码中转置的目的是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bq73qh/d_whats_the_purpose_of_the_transpose_in_official/</link>
      <description><![CDATA[刚刚浏览了他们的官方实现代码并对此感到好奇。例如，在他们的 Embedding 模块中，他们声明并使用了这样的 lora 参数：  self.lora_A = nn.Parameter(self.weight.new_zeros((r, num_embeddings))) self.lora_B = nn.Parameter(self.weight.new_zeros((embedding_dim, r) )) ... self.weight.data -= (self.lora_B @ self.lora_A).transpose(0, 1) * self.scaling ... after_A = F.embedding( x, self.lora_A.transpose(0 , 1), self.padding_idx, self.max_norm, self.norm_type, self.scale_grad_by_freq, self.sparse ) 结果 += (after_A @ self.lora_B.transpose(0, 1)) * self.scaling ...  那么，为什么他们不直接这样声明并在不转置的情况下使用呢？ self.lora_A = nn.Parameter(self.weight.new_zeros(( r, embedding_dim))) self.lora_B = nn.Parameter(self.weight.new_zeros((num_embeddings, r)))  这些转置的目的是什么？ （官方代码链接）   由   提交/u/kessa231  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bq73qh/d_whats_the_purpose_of_the_transpose_in_official/</guid>
      <pubDate>Thu, 28 Mar 2024 21:21:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是对比学习吗？它有助于减少阶级不平衡吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bq6jra/d_is_this_contrastive_learning_does_it_help/</link>
      <description><![CDATA[类别不平衡是二元分类的一个常见问题，尤其是在搜索问题中（其中一个结果被点击，其他结果被忽略）。 &lt; p&gt;另一种方法是将其视为多类分类问题，其中类是向用户显示的搜索结果。想象一下，用户看到了 20 个结果，但他们只点击了一个结果。因此，我们可以让模型进行 20 次预测（每个结果一次），应用 softmax + 交叉熵损失，并使模型学习为被点击的一个结果产生高概率。所以我们有效地消除了二进制类不平衡。  这种技术有标准名称吗？这是否属于对比学习的范畴？ 这是否有效解决了类不平衡问题，因为我们现在正在从几个不平衡的二元分类问题中创建一个多类训练示例？  谢谢   由   提交 /u/AstronautVarious3791   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bq6jra/d_is_this_contrastive_learning_does_it_help/</guid>
      <pubDate>Thu, 28 Mar 2024 20:59:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] NL-ITI：修改LLM内部表示以使其更加真实</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bq5tn7/r_nliti_modifying_llm_internal_representations_to/</link>
      <description><![CDATA[您好，在这里您可以找到我们最近的出版物（以及代码），其中我们修改了 LLM 内部表示以使其更加真实。简而言之，我们优化了 ITI 方法（2306.03341.pdf (arxiv.org)）并取得了显着的性能提升。评估主要在 TruthfulQA 上进行，尽管我们也测试了它之外的泛化（MMLU、ARC、OpenBookQA）。我们使用 KL 和 CE 指标来衡量干预的侵入性。 https ://paperswithcode.com/paper/nl-iti-optimizing-probing-and-intervention   由   提交 /u/autonomous_llm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bq5tn7/r_nliti_modifying_llm_internal_representations_to/</guid>
      <pubDate>Thu, 28 Mar 2024 20:30:12 GMT</pubDate>
    </item>
    <item>
      <title>自适应 RAG：一种降低 top-k 向量索引检索的 LLM 令牌成本的检索技术 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bq3hwb/adaptive_rag_a_retrieval_technique_to_reduce_llm/</link>
      <description><![CDATA[摘要：我们演示了一种技术，该技术允许使用法学硕士的反馈动态调整 top-k 检索器 RAG 提示中的文档数量。这使得 RAG LLM 问答的成本降低了 4 倍，同时保持了相同的准确性水平。我们还表明该方法有助于解释法学硕士输出的血统。参考实现适用于大多数模型（GPT4、许多本地模型、较旧的 GPT-3.5 Turbo），并且可以适应大多数公开 top-k 检索原语的矢量数据库。 博客论文：https://pathway.com/developers/showcases/adaptive-rag 参考实现：&lt; a href=&quot;https://github.com/pathwaycom/pathway/blob/main/python/pathway/xpacks/llm/question_answering.py&quot;&gt;https://github.com/pathwaycom/pathway/blob/main/python /pathway/xpacks/llm/question_answering.py   由   提交 /u/dxtros   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bq3hwb/adaptive_rag_a_retrieval_technique_to_reduce_llm/</guid>
      <pubDate>Thu, 28 Mar 2024 18:55:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分布式推理推荐读物</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bq324j/d_suggested_readings_on_distributed_inference/</link>
      <description><![CDATA[我正在寻找有关分布式推理的读物：这可能吗？是否有任何系统架构可以使其变得可行或值得？分布式推理有哪些方法？我在 Google Scholar 上得到了很多点击；您个人认为有什么值得深入研究的吗？   由   提交 /u/Shintuku1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bq324j/d_suggested_readings_on_distributed_inference/</guid>
      <pubDate>Thu, 28 Mar 2024 18:37:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 斯坦福大学的 BioMedLM 论文报告的准确性与评估的准确性：没有意义</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bq1deb/d_stanfords_biomedlm_paper_reported_accuracy_vs/</link>
      <description><![CDATA[      斯坦福大学发布#BioMedLM，一种基于生物医学数据训练的 2.7B 参数语言模型。然而，结果似乎没有意义。 这里是在 MultiMedQA（MedMCQA、MedQA、MMLU、PubMed）上使用 LM Evaluation Harness 框架的评估报告。  https://preview.redd .it/vd21crtn14rc1.png?width=1442&amp;format=png&amp;auto=webp&amp;s=ee905e8277006e40c37b7e5b87003165bd0de4b5 https://preview.redd.it/6ot7mibo14rc1.png?width=1164&amp;format=png&amp;auto=webp&amp;s=5d76fcce909fb07d 5404e148b0cdc2fbc6dae43c ​   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bq1deb/d_stanfords_biomedlm_paper_reported_accuracy_vs/</guid>
      <pubDate>Thu, 28 Mar 2024 17:32:07 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于组织和监控多模型训练的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bq0pwv/d_suggestions_on_organizing_and_monitoring/</link>
      <description><![CDATA[嘿大家，我有一个项目，对我来说有点复杂，所以我试图先为其设计出最佳结构来让事情运行起来，我正在寻求一些建议。 情况： 我有 4 个表格预测器数据集，每个数据集有 31 个我需要为其训练回归模型（使用 XGBoost）的响应变量（RV）。到最后，我将拥有 124 (4 * 31) 个经过训练的模型。 理想情况下，对于每个 RV，我希望执行某种形式的 K 倍交叉验证超参数优化和最终模型分析也将基于 K-fold CV。 挑战： 我正在尝试找出组织所有这些的最佳方式这样一来，当涉及到再现性和分析以及有可能添加新的预测数据和/或新的 RV 时，它并不是一团糟。我之前已经这样做过一次，并且选择只将数据写入 CSV，但这很快就变得笨拙，最终需要大量额外的代码才能合理地处理和解析结果。 I我真的很希望能够可视化每个模型的训练和性能，但该领域流行工具的大多数示例似乎都集中于训练单个模型，并通过“实验”进行训练。通常指不同的超参数或功能修改。 DVC、Aim、WandB 看起来都很吸引人，但我不太确定如何概念化我的特定工作流程，并且我希望避免任何最终的限制陷阱将来，确保我的初始设置是正确的。 我很想听听其他人如何组织此类多模型/集成培训项目！   由   提交 /u/pwinggles   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bq0pwv/d_suggestions_on_organizing_and_monitoring/</guid>
      <pubDate>Thu, 28 Mar 2024 17:05:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年构建大型语言模型的小指南 – 75 分钟讲座</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bpzrm0/d_a_little_guide_to_building_large_language/</link>
      <description><![CDATA[我终于录制了两周前的讲座，因为人们一直向我索要视频。 所以在这里，我希望您会喜欢“2024 年构建大型语言模型的小指南”。 我试图使其简短而全面 - 重点关注对于培训优秀 LLM 至关重要但通常隐藏的概念在技​​术报告中。 在讲座中，我向学生介绍了培训良好绩效法学硕士的所有重要概念/工具/技术：- 查找、准备和评估网络规模数据- 理解模型并行性和高效培训- 微调/对齐模型 - 快速推理 当然有很多东西和细节缺失，我应该添加进去，不要犹豫告诉我你是最令人沮丧的遗漏，我将在以后的部分中添加它。特别是，我认为我将更多地关注如何很好地、广泛地过滤主题，也许还有更多实用的轶事和细节。 既然我记录了它，我一直在想这可能是一个主题的第 1 部分。由两部分组成的系列，其中包含第二个完整的实践视频，介绍如何使用我们最近在 HF 围绕 LLM 培训发布的一些库和配方来运行所有这些步骤（并且无论如何都可以轻松适应您的其他框架）：  用于所有网络规模数据准备的 datatrove：https://github.com/huggingface/datatrove  nanotron 用于轻量级 4D 并行法学硕士培训：https://github.com/huggingface/nanotron lighteval 用于训练中快速并行 LLM 评估：https://github.com/huggingface/lighteval  以下是在 Youtube 上观看讲座的链接：https://www. youtube.com/watch?v=2-SPH9hIKT8这是 Google 幻灯片的链接：https://docs.google.com/presentation/d/1IkzESdOwdmwvPxIELYJi8--K3EZ98_cL6c5ZcLKSyVg/edit#slide=id.p 很高兴听到对此的反馈以及在第二部分中添加、更正、扩展的内容。   由   提交 /u/Thomjazz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bpzrm0/d_a_little_guide_to_building_large_language/</guid>
      <pubDate>Thu, 28 Mar 2024 16:26:57 GMT</pubDate>
    </item>
    <item>
      <title>幻觉的终结（对于那些能负担得起的人）？ [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bpxs1i/the_end_of_hallucination_for_those_who_can_afford/</link>
      <description><![CDATA[      DeepMind 刚刚发表了一篇关于事实检查文本的论文： &lt; a href=&quot;https://preview.redd.it/zsmv0a0293rc1.png?width=1028&amp;format=png&amp;auto=webp&amp;s=789c1c2f9b31aa734a7ebcf459df3ad06bd74285&quot;&gt;https://preview.redd.it/zsmv0a0293rc1.png?width =1028&amp;format=png&amp;auto=webp&amp;s=789c1c2f9b31aa734a7ebcf459df3ad06bd74285 该方法使用 GPT-3.5-Turbo，每个模型响应成本为 0.19 美元，比人类注释者更便宜，同时更比他们准确： https:/ /preview.redd.it/ob7bb3iv73rc1.png?width=1014&amp;format=png&amp;auto=webp&amp;s=e79bbcaa578b29772cb3b43ead508daff7288091 他们使用这种方法创建事实基准并比较一些流行的法学硕士。 论文和代码：https://arxiv.org/abs/2403.18802 编辑：关于帖子的标题：幻觉（在维基百科中）被定义为“由人工智能生成的响应，其中包含作为事实呈现的虚假或误导性信息。”它并不包含所有不需要的输出，这与一些 Reddit 用户所认为的不同。   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bpxs1i/the_end_of_hallucination_for_those_who_can_afford/</guid>
      <pubDate>Thu, 28 Mar 2024 15:04:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 句子级变压器可以提高令牌级变压器的记忆？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bps9e4/d_a_sentence_level_transformer_to_improve_memory/</link>
      <description><![CDATA[我对长期变换记忆有一个（可能是愚蠢的）想法。 你可以将句子嵌入到长度约为 128 的向量中- ~2048 对吗？然后，您可以对这些句子进行聚类，并有效地将它们投影到较低维度的空间中。 我经常想知道是否可以在嵌入空间中取约 50.000 个基点（这些点使得到所有句子的平方距离之和在代表性语料库中是最小的）。然后，您将大语料库中的每个句子映射到最近的点，然后将这些点用作标记。随后，您将大量文本库编码到这些标记中，并训练沼泽标准 GPT 模型来预测“下一个句子”。 考虑到模型处理的是“句子”，即使是 4096 的上下文长度也将是大，但它无法为您提供这些句子的详细信息，因为 50k 标记是所有可能句子的非常粗略的表示。但是，您可以训练一个令牌级别模型来预测下一个令牌，该模型从其自己的上下文（之前的 4096 个令牌或更多，无论是否方便）和句子级别预测模型（这将有一个课程记忆）获取输入回想起来... 您可能会使用交叉注意风格机制将下一个句子级别模型输入到下一个标记级别模型中。 它是一种多模态模型但形式都是文本，只是组织层次不同？   由   提交/u/Alarming-Ad8154  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bps9e4/d_a_sentence_level_transformer_to_improve_memory/</guid>
      <pubDate>Thu, 28 Mar 2024 10:29:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您知道哪些大型科技公司赞助的 ML 研究网站能够不断跟上其产品背后的 ML 研究和工作，例如 Apple Machine Learning Research (https://machinelearning.apple.com/ ）或特斯拉的人工智能日视频？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bpni34/d_what_are_some_of_the_big_tech_company_sponsored/</link>
      <description><![CDATA[如果有一堆这样的资源，或者如果您有一个可以随时了解所有新研究的地方，那就太好了正在进行中。    由   提交/u/pontiac_RN   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bpni34/d_what_are_some_of_the_big_tech_company_sponsored/</guid>
      <pubDate>Thu, 28 Mar 2024 05:08:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 边缘机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bpki28/d_machine_learning_on_the_edge/</link>
      <description><![CDATA[      大家好，我今天在抽屉里找到了它。我忘记了我有它并且从未使用过它。然后我想到了机器学习的当前状态如何以及您对不久的将来的预测。我们通常会在大型模型上看到重大进展和新闻，但在设备上的应用程序上却很少看到。   由   提交 /u/TheLastMate   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bpki28/d_machine_learning_on_the_edge/</guid>
      <pubDate>Thu, 28 Mar 2024 02:29:11 GMT</pubDate>
    </item>
    <item>
      <title>[N] DBRX 简介：开放式 LLM 的新标准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bp213q/n_introducing_dbrx_a_new_standard_for_open_llm/</link>
      <description><![CDATA[https://x.com /vitaliychiley/status/1772958872891752868?s=20 Shill 免责声明：我是该项目的预训练负责人 DBRX 说明：  &lt; li&gt;16 位专家（每个专家 12B 参数；top_k=4 路由） 36B 活跃参数（总参数 132B） 针对 12T 代币进行训练 32k序列长度训练    由   提交/u/artificial_intelect  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bp213q/n_introducing_dbrx_a_new_standard_for_open_llm/</guid>
      <pubDate>Wed, 27 Mar 2024 13:35:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>