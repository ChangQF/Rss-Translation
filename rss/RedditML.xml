<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 13 Jan 2024 06:16:41 GMT</lastBuildDate>
    <item>
      <title>[D]假设：模型中向量的定向定位（例如：ViT-L/14）可能会带来新的可能性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195gyqe/d_hypothesis_directed_positioning_for_the_vectors/</link>
      <description><![CDATA[   我最近一直在研究 CLIP 模型 ViT-L/14，以检查数据的样子。 我注意到，即使对于“接近”的事物的定义也可能是这样的。彼此之间的接近度本质上几乎是随机的。我猜测，在训练过程中，值通过随机运动进行调整，直到“应该”的对象出现。在一起，降落在一个被认为“足够接近”的 n 空间位置，事情就到此结束。  但这使得坐标的随机性非常令人不满意。其示例是比较“cat”在768空间中的位置和“cat”在768空间中的位置。 vs “小猫”这里：  https://preview .redd.it/23v9ux27b5cc1.png?width=569&amp;format=png&amp;auto=webp&amp;s=895f80682a3f6f321bcb8a2482749649c1074c8b 它们的欧几里德距离为 7.22859525680542  什么如果真正属于“密切”的对象是在一起...实际上在大多数维度上都在一起？ 如果可以重新组织数据集，以便真正相似的对象在 768 空间中更多地反映这一点会怎样？  也就是说，如果“cat”是和“小猫”只有几个尺寸不同，其他的都一样？  在我看来，这可能会带来一些有趣的可能性。   由   提交/u/lostinspaz   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195gyqe/d_hypothesis_directed_positioning_for_the_vectors/</guid>
      <pubDate>Sat, 13 Jan 2024 05:50:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] UnIVAL：图像、视频、音频和语言任务的统一模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195eulx/r_unival_unified_model_for_image_video_audio_and/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2307.16184 OpenReview：https:// /openreview.net/forum?id=4uflhObpcp 代码：https： //github.com/mshukor/UnIVAL 检查点：https://github.com/mshukor/UnIVAL/blob/main/checkpoints.md 项目页面：https://unival-model.github.io/ 演示：https://huggingface.co/spaces/mshukor/UnIVAL 视频：&lt; a href=&quot;https://www.youtube.com/watch?v=mYOun92st08&quot;&gt;https://www.youtube.com/watch?v=mYOun92st08 摘要：  大型语言模型（LLM）使对通才智能体的雄心勃勃的追求不再是一个幻想。构建此类通用模型的一个关键障碍是任务和模式的多样性和异质性。一种有希望的解决方案是统一，允许在一个统一的框架内支持无数的任务和模式。虽然在海量数据集上训练的大型模型（例如 Flamingo（Alayrac 等人，2022））可以支持两种以上的模态，但当前的中小型统一模型仍然仅限于 2 种模态，通常是图像文本或视频-text.我们要问的问题是：是否有可能高效地构建一个能够支持所有模态的统一模型？为了回答这个问题，我们提出了UnIVAL，朝着这个雄心勃勃的目标又迈进了一步。在奇特的数据集大小或具有数十亿参数的模型上，~ 0.25B 参数 UnIVAL 模型超越了两种模式，并将文本、图像、视频和音频统一到单个模型中。我们的模型基于任务平衡，在许多任务上进行了有效的预训练和多模态课程学习。UniVAL 在图像和视频文本任务中显示出与现有最先进方法相比的竞争性能。从图像和视频文本模态中学习的特征表示，允许模型在微调时实现竞争性能音频文本任务，尽管没有经过音频预训练。得益于统一模型，我们提出了一项通过对不同多模态任务训练的模型进行权重插值来进行多模态模型合并的新颖研究，展示了它们特别是对于分布外泛化的好处。最后，我们通过展示任务之间的协同作用来激励统一。模型权重和代码在这里发布：这个 https URL.    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195eulx/r_unival_unified_model_for_image_video_audio_and/</guid>
      <pubDate>Sat, 13 Jan 2024 03:54:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] PASTA：预训练的动作状态转换代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195eh7b/r_pasta_pretrained_actionstate_transformer_agents/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2307.10936 OpenReview： https://openreview.net/forum?id=ciBFYxzpBT https： //openreview.net/forum?id=pxK9MWuFF8 摘要：  自监督学习带来了革命性的各种计算领域的范式转变，包括 NLP、视觉和生物学。最近的方法涉及对大量未标记数据进行预训练 Transformer 模型，作为有效解决下游任务的起点。在强化学习中，研究人员最近采用了这些方法，开发了根据专家轨迹进行预训练的模型。这一进步使模型能够处理从机器人到推荐系统的广泛任务。然而，现有方法主要依赖于针对特定下游应用量身定制的复杂预训练目标。本文对模型进行了全面的研究，称为预训练动作状态转换代理（PASTA）。我们的研究涵盖了统一的方法论，并涵盖了广泛的一般下游任务，包括行为克隆、离线强化学习、传感器故障鲁棒性和动态变化适应。我们的目标是系统地比较各种设计选择，并提供有价值的见解，帮助从业者开发强大的模型。我们研究的主要亮点包括动作和状态的组件级别的标记化、基本预训练目标的使用（例如下一个标记预测或掩码语言建模）、跨多个领域的模型同步训练以及各种微调的应用策略。在这项研究中，开发的模型包含不到 700 万个参数，允许广泛的社区使用这些模型并重现我们的实验。我们希望这项研究能够鼓励进一步研究使用具有第一原理设计选择的变压器来表示 RL 轨迹，并为稳健的策略学习做出贡献。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195eh7b/r_pasta_pretrained_actionstate_transformer_agents/</guid>
      <pubDate>Sat, 13 Jan 2024 03:35:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前最好的文字转语音工具是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195cxim/d_what_is_the_best_texttospeech_tool_currently/</link>
      <description><![CDATA[大家好，我需要一个听起来完全像人声的 TTS 工具。我想用它来编辑我的一些 YouTube 视频，更具体地说，上传我自己选择的语音样本并从中生成良好的结果。我看到周围有很多 TTS 平台。你推荐哪一个？我希望这不是一个过分的要求。我将非常感激。 提前致谢。   由   提交 /u/FateRiddle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195cxim/d_what_is_the_best_texttospeech_tool_currently/</guid>
      <pubDate>Sat, 13 Jan 2024 02:18:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 尝试理解 ViTDet 论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19592m6/r_trying_to_understand_the_vitdet_paper/</link>
      <description><![CDATA[大家好，我写在这里是因为 MachineLearning 子项目暂时关闭。 我正在尝试了解 ViTDet 模型（https://arxiv.org/abs/2203.16527)，它使用 ViT 主干并添加到不同分辨率级别的映射来执行对象检测。然而，整个物体检测部分并没有得到真正的解释。我的意思是，我知道我们需要一些先验知识，但我无法想象如何从文本中实现它（我认为方法部分是个笑话）。如果你们中的一些人理解这一点，那将非常有帮助！ 非常感谢:)   由   提交 /u/rem_dreamer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19592m6/r_trying_to_understand_the_vitdet_paper/</guid>
      <pubDate>Fri, 12 Jan 2024 23:23:14 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] MS在线ML程序（EE背景）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1958r4n/discussion_ms_online_programs_for_ml_ee_background/</link>
      <description><![CDATA[我正在考虑获得机器学习硕士学位（无论是专注于 ML 的 CS，还是 ML+数据科学等）。想知道什么是值得一看的好程序？ 我拥有电气工程学士学位和电气工程硕士学位，但在 MS 期间，我将所有课程都集中在 ML 上，因为我意识到这就是什么我对此很感兴趣。目前我正在努力寻找一份与 ML 相关的工作，但没有专业经验。任何建议将不胜感激，谢谢！   由   提交/u/Sad-Fondant3060  /u/Sad-Fondant3060 reddit.com/r/MachineLearning/comments/1958r4n/discussion_ms_online_programs_for_ml_ee_background/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1958r4n/discussion_ms_online_programs_for_ml_ee_background/</guid>
      <pubDate>Fri, 12 Jan 2024 23:09:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 适合面试的 ML 工程题库好吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/</link>
      <description><![CDATA[我一直在研究 ML 工程面试（并做了一些），我意识到“了解偏见”的常见建议，方差、交叉折叠验证等”。都是错的。顶级公司要求你使用 Pytorch/numpy 编写简单的代码。所以问题是这样的：“编写一个神经网络来解决 X 问题”或者“编写一个神经网络来解决 X 问题”。或“使用 numpy 实现 k-means”。 考虑到这种情况，我认为通过做一堆编码问题来准备这些面试会更有用。 我想知道这里的人是否可以分享他们在 ML Eng 面试中遇到的一些编码问题，或者向我指出好的 Leetcode 风格的 MLEng 题库？  &amp;# 32；由   提交 /u/lisp-cloj    reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/</guid>
      <pubDate>Fri, 12 Jan 2024 23:00:47 GMT</pubDate>
    </item>
    <item>
      <title>博士统计/ML [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1957nca/phd_statsml_discussion/</link>
      <description><![CDATA[大家好，我想问大家一个可能很愚蠢的问题，但我只是一个本科生，我不知道很多。我的问题是：计算机科学（人工智能方向，重点关注人工智能、机器学习、深度学习……）的硕士生可以攻读统计学博士学位吗？你知道攻读博士学位的最好的学校是什么吗？我还在阿姆斯特丹或牛津看到了一些统计机器学习的博士学位，您对此有何看法？实际上我正在米兰理工大学学习，可能明年我将开始攻读计算机科学、人工智能方向的硕士学位。   由   提交 /u/AhamedRecover1786   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1957nca/phd_statsml_discussion/</guid>
      <pubDate>Fri, 12 Jan 2024 22:23:48 GMT</pubDate>
    </item>
    <item>
      <title>图中的节点分类[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19572jd/node_classification_in_graphs_discussion/</link>
      <description><![CDATA[Tl;Dr：我有一个异构图，其中边具有特征，某种类型的节点具有标签。我想预测标签。但我发现很难得到结果。分享您遇到类似问题的经验 我的数据由代理和项目组成，我想根据代理交互来预测项目的质量。这是一个二元分类问题。 有关我的问题设置的更多详细信息：  边仅存在于代理和项目之间，其中代理可以与多个项目交互。  节点可以是代理或项目。代理节点没有特征，而项目节点有标签（这就是我试图预测的） 边具有交互长度和交互质量等特征  我尝试过一些非深度方法，主要是集成和增强方法。对于这些，我使用了节点传入边缘的统计数据（例如代理数量、平均交互长度等）。根据我使用的功能，我可以获得大约 0.6 F1，精度和召回率各不相同（有时高达 80%） 我发现很难使用 GNN 获得结果。我尝试过图注意网络，并且正在尝试 SAGEConv，但我不太确定如何处理卷积层的边缘特征。我觉得通过计算平均值或最大值来汇集它们与使用决策森林是一样的。 同时我觉得使用 GNN 可以帮助利用数据的几何形状，当使用标准机器学习方法时，这有点被破坏了。 所以我的问题是，对于那些遇到类似问题的人来说，什么对你有用/没用，为什么？   由   提交 /u/eatpasta_runfastah   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19572jd/node_classification_in_graphs_discussion/</guid>
      <pubDate>Fri, 12 Jan 2024 21:59:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML/AI 讲座总结 - 您觉得这有帮助吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19570le/d_summarizing_mlai_lectures_would_you_find_this/</link>
      <description><![CDATA[大家好！ 我正在考虑一个想法，非常需要您的意见。 我我计划参加 AI/ML 讲座和相关视频，并将其转化为易于理解的摘要。目标是让所有深入而密集的信息更容易获取。 想想麻省理工学院/纽约大学的视频讲座 -&gt;格式精美的电子书 PDF。 可以将其视为通过几个段落获取整个讲座的精髓（获得概述或作为讲座的复习笔记）。 但是首先，我真的很想知道这是否对您有用。如果是，您希望看到哪些具体的人工智能讲座或演讲的总结？我致力于制作对我们真正有帮助的内容。 所以，请给我留言：  您对 AI/ML 讲座是否快速总结的想法将会是您会使用的东西。 您想到的任何需要总结处理的特定讲座或视频。  期待收到大家的来信! 干杯， 阿迪   由   提交 /u/phoneixAdi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19570le/d_summarizing_mlai_lectures_would_you_find_this/</guid>
      <pubDate>Fri, 12 Jan 2024 21:57:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 以最小的开销从大型 GPU 扩展到仅 CPU 的最便宜方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19549sd/d_cheapest_way_to_scale_up_and_down_from_a_large/</link>
      <description><![CDATA[当我离开家几周并且远离我相当强大的 GPU 桌面时，我有很多业余爱好者项目需要处理. 我正在寻找最简单（也是最便宜）的方法来获得一台可以通过 SSH 连接的计算机，并且：  进行一些编码/调试（花费 80 % 的时间） 以批处理模式运行一些相当小众的 ML 软件，需要低端 GPU (10%) 启动强大的 48 GB GPU 来处理LLM（10%）  考虑到设置/配置开销，我想做的是将 60 GB 存储附加到 EC2.micro，安装完整的 Lambdalabs 容器（Nvidia驱动程序、CUDA、Pytorch 等），将其用于 #1，然后将该启动驱动器交换到更多计算或 GPU 密集型计算机，以便在我准备好时运行 #2 或 #3 几个小时。 &lt; p&gt;单个配置良好的启动驱动器可以在截然不同的计算配置中工作吗？有没有最适合此类事情的云提供商？ 特别是，当我不积极做某事时，我希望能够尽可能降低费用（我可以支付一点存储费用。 我很乐意与 LamdaLabs 这样的公司合作，但他们没有廉价的低端 CPU 实例。 是否有更智能的（不是使用 Ansible 等疯狂的高努力）方法来维护 SSH 和 go 设置，使其能够在截然不同的规模计算中工作？  &amp; #32；由   提交/u/gofiend  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19549sd/d_cheapest_way_to_scale_up_and_down_from_a_large/</guid>
      <pubDate>Fri, 12 Jan 2024 20:01:27 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待 Yann Lecun 关于 ML 的有争议的观点？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/</link>
      <description><![CDATA[      Yann Lecun 有一些有争议的观点关于 ML 的看法，他并不羞于分享。他写了一篇立场文件，名为“通往自主机器智能的途径”。不久以前。此后，他也就此发表了很多演讲。这是屏幕截图 ​ https://preview.redd.it/xxmxgrdk02cc1.jpg?width=1581&amp;format=pjpg&amp;auto=webp&amp;s=4a7e98f5a41f2e454e2e33881f2 df93c7287d09b 来自&lt; a href=&quot;https://www.youtube.com/watch?v=OKkEdTchsiE&quot;&gt;一个，但我看过几个 - 它们很相似，但不完全相同。以下并不是所有演讲的摘要，而只是他对 ML 现状的批评，根据记忆进行解释（他还谈论了 H-JEPA，我在这里忽略了）：  &lt; li&gt;法学硕士无法商业化，因为内容所有者“喜欢reddit”会起诉（奇怪的是，鉴于最近的《纽约时报》诉讼，这是有先见之明的） 当前的机器学习很糟糕，因为与人类相比，它需要大量的数据（有两种截然不同的可能性：算法本身很糟糕，或者人类只是在童年时期进行了更多的“预训练”） 规模化是不够的 自回归法学硕士注定会失败，因为任何错误都会让你偏离正确的道路，并且随着输出数量的增加，不犯错误的概率很快接近 0 LLM 无法推理，因为它们只能执行有限数量的计算步骤 连续域中的建模概率为错误的，因为你会得到无限的梯度 对比训练（如 GAN 和 BERT）是不好的。您应该进行正规化训练（例如 PCA 和稀疏 AE） 生成建模是误导性的，因为世界的大部分内容都是不可预测或不重要的，不应该由智能系统建模 人类通过被动视觉观察了解他们对世界的大部分了解（我认为这可能与先天失明的人可能非常聪明的事实相矛盾） 你不&#39;智能行为不需要巨大的模型，因为老鼠只有数千万个神经元，就超越了当前的机器人人工智能    由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/</guid>
      <pubDate>Fri, 12 Jan 2024 19:14:35 GMT</pubDate>
    </item>
    <item>
      <title>无监督聚类能否近似真实类别或分类？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/194v0n2/could_unsupervised_clustering_approximate_ground/</link>
      <description><![CDATA[假设我们有一个带标签的数据集，并且我们使用聚类来对实例进行聚类。我们还可以使用分类来对实例进行分类，因为它是有标签的。这里有人可以解释一下是否存在聚类会产生与分类相似的结果的情况吗？谢谢， 如果我们有真实类别，则不需要使用聚类，但我只是想知道它是否可以近似或等于分类。 编辑：假设确定性聚类方法，聚类数=类别数。 （这对于确定性聚类方法来说似乎是一个很好的答案。） &lt;!-- SC_ON - -&gt;  由   提交 /u/whereismycatyo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/194v0n2/could_unsupervised_clustering_approximate_ground/</guid>
      <pubDate>Fri, 12 Jan 2024 13:26:30 GMT</pubDate>
    </item>
    <item>
      <title>我们今天在人工智能中拥有的大多数东西将在 6 个月内变得无关紧要 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/194ap95/most_things_we_have_today_in_ai_will_be_a/</link>
      <description><![CDATA[      当您构建“薄包装器”时，这是不幸的情况。基础模型之上的产品。 去年，我们为客户构建了一个定制的稳定扩散管道，在 2 个月内进行了大量实验，找出了针对边缘情况的定制解决方案，并交付了一个可以将集体照片转换为圣诞礼品卡。 今天，阿里巴巴推出了 ReplaceAnything，我可以在一分钟内构建出同样的东西，但质量可能会下降 10%（！），因为我们的团队花了几周时间才完成了几个几个月前。 这个领域的进展是疯狂的。 幸运的是，这只是“那些有趣的小事情之一”。我们为客户建立的公司。 我无法想象建立这些公司之一的压力，尤其是如果你筹集了风险资金。 时间在流逝，你每天都在滴答作响。技术护城河越来越少。 这就是为什么您需要全力以赴尽快创建长期、可持续的数据护城河。 https://preview.redd.it/7a67geld8vbc1.png?width=722&amp;format= png&amp;auto=webp&amp;s=c4dc336cf2635c178ad6ccfc65d10292f5c881f4   由   提交 /u/BootstrapGuy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/194ap95/most_things_we_have_today_in_ai_will_be_a/</guid>
      <pubDate>Thu, 11 Jan 2024 19:52:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>