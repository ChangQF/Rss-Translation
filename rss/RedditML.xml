<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 31 Jan 2025 18:21:14 GMT</lastBuildDate>
    <item>
      <title>[D] 所有的蒸馏都只使用软标签（概率分布）吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ieig2r/d_does_all_distillation_only_use_soft_labels/</link>
      <description><![CDATA[我正在阅读 Deepseek R1 论文的蒸馏部分，没有发现对 SFT 数据集中软标签（概率分布）的任何引用。  这是否意味着在蒸馏过程中总是软标签？因为使用拒绝抽样的 SFT 数据创建听起来更像是硬标签。想法？    提交人    /u/No-Cut5   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ieig2r/d_does_all_distillation_only_use_soft_labels/</guid>
      <pubDate>Fri, 31 Jan 2025 16:18:23 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 报告绩效和基准的可重复性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iei30l/discussion_reproducibility_in_reporting/</link>
      <description><![CDATA[我阅读 ML 论文已有大约一年了。由于我有物理学背景，我发现这些论文根本没有考虑可重复性。论文通常不会透露他们使用的所有细节，例如模型架构参数或其他超参数。 这也让我想到了一个问题：我几乎从未看到过误差线！ 我知道预训练很困难，需要大量的计算能力。但是，我认为评估可以进行多次。事实上，许多研究人员进行了多次评估，但只报告了他们的最佳结果，而不是报告带有置信区间的平均值，尤其是在将他们的模型与基线进行比较时。 你们对此有什么看法？你认为这可能是 AI/ML 中平庸研究泛滥的原因吗？    提交人    /u/vsa467   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iei30l/discussion_reproducibility_in_reporting/</guid>
      <pubDate>Fri, 31 Jan 2025 16:02:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与 Nvidia Nsight Systems CLI 配合良好的云 GPU 实例服务？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iehl10/d_cloud_gpu_instance_service_that_plays_well_with/</link>
      <description><![CDATA[TLDR 是标题。 我正在编写自定义 pytorch 代码来提高训练吞吐量，主要通过 GPU 和 CPU 上的异步、并发和并行性。 今天我终于在本地设置了 Nsight Systems，它确实提高了我对事物的理解。 虽然我在 RTX3060 上让它运行，但这几乎不能代表真正的大型 ML 训练环境。 ......所以我试图在 Runpod 上运行它，但失败了。关于内核偏执级别（我无法降低）、--privileged 参数（我无法添加因为 Runpod 为 Docker 提供了 RUN），以及“nsys status -e”中的所有内容都显示“失败”。 有什么想法吗？   由    /u/StayingUp4AFeeling  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iehl10/d_cloud_gpu_instance_service_that_plays_well_with/</guid>
      <pubDate>Fri, 31 Jan 2025 15:41:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 完全开源代码库用于训练 SOTA VLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ieh3e3/r_fully_open_source_codebase_to_train_sota_vlms/</link>
      <description><![CDATA[嗨！我是 Hugging Face 多模式团队的 Andi。 今天，我们将在 256 个 H100 上从头开始训练 SmolVLM 的代码库开源 受到我们团队开源 DeepSeek R1 训练的努力的启发，我们将在权重之上发布训练和评估代码 现在您可以训练我们的任何 SmolVLM - 或创建自己的自定义 VLM！ 去看看吧： https://github.com/huggingface/smollm/tree/main/vision    提交人    /u/futterneid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ieh3e3/r_fully_open_source_codebase_to_train_sota_vlms/</guid>
      <pubDate>Fri, 31 Jan 2025 15:19:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 流感蛋白序列深度学习帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ieg2km/p_flu_protein_sequence_deep_learning_help/</link>
      <description><![CDATA[大家好，首先我希望我在正确的 subreddit 上发帖，如果不允许，请版主删除。 我正在做一个业余项目，收集了从 2000 年左右到现在在世界各地收集的流感分离株的完整蛋白质组序列。你可以想象，这些现实世界的数据在记录的分离株数量上受到近期偏差的困扰，而且数据中也有很多小的次要类别（例如单个实例进化枝）。 作为背景，文献中有很多使用各种技术对病毒序列进行建模的例子，但这些研究通常只关注病毒的 10 种主​​要蛋白质产物中的一种或两种（血凝素 (HA) 和神经氨酸酶 (NA)）。我的目标是一次性对这 10 种蛋白质进行建模，以揭示蛋白质内和蛋白质间的相互作用和关系，并清楚地识别出对做出预测最重要的氨基酸残基。  我已经使用 150M 参数模型提取了所有这些蛋白质序列的 ESM 嵌入，并且我最初训练了一个多层感知器分类器来对分离物进行多任务学习和分类（序列 -&gt; 预测宿主、亚型、进化枝）。该 MLP 实现了约 96% 的准确率。  受此鼓舞，我随后尝试使用 transformer 块、VAE 和 GAN 构建预测序列模型。我还尝试使用这些数据对 TAPE 进行微调，但均未收敛。  我的直觉告诉我，在尝试训练其他模型之前，我应该更多地考虑特征工程，但我很想听听社区对这个项目的看法以及您可能有的任何有用见解。  计划在 r/bioinformatics 上交叉发布此内容。     由   提交  /u/Big_Tree_Fall_Hard   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ieg2km/p_flu_protein_sequence_deep_learning_help/</guid>
      <pubDate>Fri, 31 Jan 2025 14:32:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 分类：带有印记的图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iee8mi/r_classification_image_with_imprint/</link>
      <description><![CDATA[大家好，我正在开发一种基于图像的药片假冒检测系统。药片表面有四个字母的印记，很难用假药压片机准确复制。我有大约 400 张正品药片的图像，想要开发一个根据印记检测异常值（即假冒产品）的模型。 图像预处理步骤  将图像转换为灰度。 应用阈值使背景变黑。 使用 CLAHE 增强印记文本，使其更加突出。  问题： 我是否应该重新缩放图像（例如 200x200 像素）以减少计算负荷，或者是否有更好的方法？ 哪些图像分类技术适合对印记进行建模？ 我正在考虑使用特征袋 (BoF) + 单类 SVM 进行异常值检测。基于 CNN 的方法（例如自动编码器或 Siamese 网络）是否更有效？ 还有其他建议吗？ 为了进行测试，我计划修改一些真实的印记（例如，更改字母）以模拟假冒案例。这种方法是否适合评估模型性能？ 我将在南美的一家药店购买一些正宗的药丸。 我很想听听您对这项任务的最佳技术和策略的看法。提前谢谢您！    提交人    /u/Haunting_Tree4933   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iee8mi/r_classification_image_with_imprint/</guid>
      <pubDate>Fri, 31 Jan 2025 13:00:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 FastGen 论文模型分析阶段的困惑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie6ufo/d_confusion_about_the_model_profiling_stage_of/</link>
      <description><![CDATA[      简要背景：FastGen 论文是一篇关于 KV 缓存压缩的著名著作。它提出了一种两阶段方法：首先，它为每个头部识别不同的注意模式（称为“模型分析”），然后应用相应的压缩策略。 我附上的屏幕截图包含有关第一阶段（模型分析）的所有内容，应该是独立的。但是，我发现它令人困惑，原因有二：  由于压缩后 KV 缓存大小减小，原始注意力图 A 和压缩注意力图 \text{softmax}(QK_C^\top) 的形状似乎会有所不同。绝对差 |A - \text{softmax}(QK_C^\top)| 怎么会这样呢？如果形状不匹配，如何计算？ 本文没有对方程中的绝对值运算符提供进一步的解释，让我不确定在这种情况下如何解释它。  https://preview.redd.it/va9kbkz2b9ge1.png?width=1736&amp;format=png&amp;auto=webp&amp;s=168845b68371a1b90800689c1f5a7bba8c6fd900 这是一篇口头论文ICLR，所以我想知道我是否误解了什么。不幸的是，代码存储库是空的，所以我无法检查它们的实现以进行澄清。 有人读过这篇论文并能阐明这些观点吗？    提交人    /u/StraightSpeech9295   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie6ufo/d_confusion_about_the_model_profiling_stage_of/</guid>
      <pubDate>Fri, 31 Jan 2025 04:32:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 重新校准表示：Transformer 的反馈引导加权池化框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5pid/r_recalibrating_representations_a_feedbackguided/</link>
      <description><![CDATA[Transformers 通常依赖单个 token ([CLS]) 或均值池化来形成序列表示，这可能会忽略历史上错误分类或特别重要的 token 的关键线索。我们提出的反馈引导加权池化 (FGWP) 添加了一种轻量级机制，可根据捕获过去表现的反馈向量重新加权 token 嵌入。通过突出显示已知具有挑战性或决定性的 token，FGWP 丰富了序列表示，而不会显著增加计算或模型大小。从情绪分析（IMDb）到大规模图像分类（ImageNet）等任务的实验表明，准确率不断提高，强调了模型的价值，该模型不仅可以处理当前输入，还可以从自身的历史成功和错误中学习，而所有这些都只需要最少的计算开销。 将很快发布到 arxiv 并希望发布到 ICML，欢迎任何反馈或建议！ https://jacobfa.github.io/stuff/Pooling.pdf    提交人    /u/jacobfa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5pid/r_recalibrating_representations_a_feedbackguided/</guid>
      <pubDate>Fri, 31 Jan 2025 03:29:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么DeepSeek学生模型（7B参数）的表现略优于教师模型（671B参数）？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie46nq/why_does_the_deepseek_student_model_7b_parameters/</link>
      <description><![CDATA[这是论文中我无法理解的最大部分——知识提炼以匹配原始教师模型的分布是有意义的，但它是如何击败原始教师模型的？    提交人    /u/Easy_Pomegranate_982   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie46nq/why_does_the_deepseek_student_model_7b_parameters/</guid>
      <pubDate>Fri, 31 Jan 2025 02:08:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 温度为 0 时 LLM 的非确定性行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie15ev/d_nondeterministic_behavior_of_llms_when/</link>
      <description><![CDATA[嘿， 因此从理论上讲，当温度设置为 0 时，LLM 应该是确定性的。 然而，在实践中，由于硬件和其他因素的差异，情况并非如此。（示例） 有没有什么好的论文研究温度为 0 时 LLM 的非确定性行为？ 寻找深入研究根本原因、量化它等的东西。 谢谢！    提交人    /u/curryeater259   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie15ev/d_nondeterministic_behavior_of_llms_when/</guid>
      <pubDate>Thu, 30 Jan 2025 23:43:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] [N] 开源 8B 评估模型在 11 个基准测试中击败 GPT-4o mini 并位居小型评委之首</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idpqas/r_n_opensource_8b_evaluation_model_beats_gpt4o/</link>
      <description><![CDATA[  由    /u/fortunemaple  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idpqas/r_n_opensource_8b_evaluation_model_beats_gpt4o/</guid>
      <pubDate>Thu, 30 Jan 2025 15:40:00 GMT</pubDate>
    </item>
    <item>
      <title>[d] 为什么“知识提炼”现在突然被贴上了盗窃的标签？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idjtta/d_why_is_knowledge_distillation_now_suddenly/</link>
      <description><![CDATA[我们都知道，蒸馏是一种近似更精确变换的方法。但我们也知道，这也是整个想法的终结。  蒸馏有什么问题？通过模仿输出来学习“知识”这一事实对我来说毫无意义。当然，通过保持输入和输出相同，我们试图近似一个类似的变换函数，但这并不意味着它确实如此。我不明白这怎么会被贴上盗窃的标签，尤其是当整个架构和训练方法都不同的时候。     提交人    /u/The-Silvervein   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idjtta/d_why_is_knowledge_distillation_now_suddenly/</guid>
      <pubDate>Thu, 30 Jan 2025 10:09:59 GMT</pubDate>
    </item>
    <item>
      <title>无炒作 DeepSeek-R1 [R] 阅读清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ideupn/no_hype_deepseekr1_reading_list/</link>
      <description><![CDATA[在过去的一年半里，我一直在运营一个研究论文俱乐部，我们在那里深入研究人工智能/机器学习领域有趣/基础的论文。因此，我们自然而然地接触到了很多与 DeepSeek-R1 相关的论文。本周，在深入研究 DeepSeek 论文时，我决定编制一份我们已经研究过的论文清单，或者我认为可以作为背景阅读的论文清单，以便更全面地了解 DeepSeek 内部发生的事情。 喝杯咖啡，享受吧！ https://www.oxen.ai/blog/no-hype-deepseek-r1-reading-list    提交人    /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ideupn/no_hype_deepseekr1_reading_list/</guid>
      <pubDate>Thu, 30 Jan 2025 04:51:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    </channel>
</rss>