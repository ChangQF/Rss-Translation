<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Wed, 05 Mar 2025 15:19:10 GMT</lastBuildDate>
    <item>
      <title>[R]本周的最高LLM研究：2月24日至25日3月2日</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j435sy/r_top_llm_research_of_the_week_feb_24_march_2_25/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  跟上LLM研究很难，每天噪音过多和新滴。我们在内部为团队和纸阅读小组提供最佳论文（ https://forms.gle/pisk1ss1ss1wdzxkphi9 ）。在这里也共享。它证明了在生物医学发现中的应用，包括药物重新利用，新型靶标识别和细菌进化机制。 纸得分：0.62625    https://arxiv.org/pdf/2502.18864       swe-rl：通过开放式软件swee prowss noghate swe pressign pression swee props wrose props wirforme       纸得分：0.586004  纸url      https://arxiv.org/pdf/2502.18449         aad-aad-llm：Aad-aad-aad-aad-aad-lie lie&gt; aud&gt;通过IEEG整合大脑信号以解码听众注意并产生感知一致的响应。它开创了意图感知的听觉人工智能，改进了在Mutilealker方案中的语音转录和问题回答等任务。 纸质分数：0.543714286    https：//arxiv.org/pdf/2502.16794         llm-microscope：llm-microscope：揭示了Punction of Punction of Condect of Condect of Condect of Condort of Cronsupers of Cronsuper of consuply  纸张得分：0.47782      SurveyX：通过大语言模型的学术调查自动化  该研究介绍了Surveusx，这是一种自动化测量生成的新型系统，用于利用LLM，并具有属性，在线参考检索和重新销售等创新。它显着提高了内容和引文质量，接近人类专家的表现。 纸张得分：0.416285455     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sircomprehension7453     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j435sy/r_top_llm_research_of_the_week_weeek_feb_24_march_march_2_2_255/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j435sy/r_top_llm_research_of_the_week_feb_24_march_2_25/</guid>
      <pubDate>Wed, 05 Mar 2025 13:33:28 GMT</pubDate>
    </item>
    <item>
      <title>安德鲁·巴托（Andrew Barto）和理查德·萨顿（Richard Sutton）是2024 ACM A.M.图灵（Turing）因发展强化学习的概念和算法基础而奖。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j42icj/andrew_barto_and_richard_sutton_are_the/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/mtgtraner     [link]&gt; [link]&gt; [link]&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j42icj/andrew_barto_and_richard_sutton_are_the/</guid>
      <pubDate>Wed, 05 Mar 2025 13:00:25 GMT</pubDate>
    </item>
    <item>
      <title>[r] Qilin：带有用户会话的大规模多模式搜索数据集和Xiaohongshu的异质结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j41kzh/r_qilin_a_largescale_multimodal_search_dataset/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Qilin数据集通过收集840万个不同移动应用程序的840万个多模式搜索会话来引入信息检索研究的显着进步，从而在应用程序之间导航时捕获了实际用户行为。 This is the first dataset to track complete cross-app search journeys rather than single-app interactions. Key technical points: - Comprehensive data collection: 8.4M search sessions, 2.2M unique images, 6.9M text documents across 9 different mobile apps - True multimodal representation: Contains text queries (74%), image queries (20%), and hybrid queries (6%) - Cross-app tracking: 28% of sessions include app switches, enabling research on inter-app search behavior - Diverse application types: Includes search engines, e-commerce, short video, news, Q&amp;A platforms, and more - Performance improvements: Models trained on cross-app data outperform single-app models by up to 17% on query understanding任务 -  新颖的基准任务：引入标准化评估，以查询理解，文档理解和查询文档匹配 我认为该数据集可以从根本上改变我们接近移动搜索系统的方式。通过应用程序切换（28％）的会话比例很高，这表明我们通过孤立研究应用程序缺少关键上下文。交叉应用训练的性能提高表明，建立模型具有重要的价值，这些模型可以理解完整的用户旅程，而不是对单个应用程序进行优化。这可能会导致更加集成的搜索体验，可以更好地预测用户在不同信息源之间移动的需求。 数据的仅中文性质确实限制了对其他地区的普遍性，我很好奇这些模式在其他App生态系统中可能会有所不同。尽管研究人员确实实施了匿名化，但这种全面跟踪的隐私影响也应仔细考虑。  tldr：Qilin是第一个捕获用户如何在多个移动应用程序上进行搜索的数据集，这表明28％的搜索会话涉及应用程序切换。在此跨应用数据上培训的模型优于单个应用模型的模型多达17％，这表明我们需要重新考虑搜索作为一种集成体验而不是App-by-App优化。  。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [links]     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j41kzh/r_qilin_a_largescale_multimodal_search_dataset/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j41kzh/r_qilin_a_largescale_multimodal_search_dataset/</guid>
      <pubDate>Wed, 05 Mar 2025 12:07:42 GMT</pubDate>
    </item>
    <item>
      <title>[r]将自然语言转换为逻辑谬误检测的一阶逻辑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3zokg/r_translating_natural_language_to_firstorder/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/jsonathan     [link]&gt; [link]&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3zokg/r_translating_natural_language_to_firstorder/</guid>
      <pubDate>Wed, 05 Mar 2025 09:58:06 GMT</pubDate>
    </item>
    <item>
      <title>反驳策略，结构和做/不[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3zjae/rebuttal_strategies_structure_and_dodont_d/</link>
      <description><![CDATA[Facing my first rebuttal period and want to learn is there any statgergeis or structure people follow in AI/ML space. Particularly when  Asked to run more experiments and within very short time frame Asked to restructure the whole section and one of the reviewer didn&#39;t find it易于阅读   审稿人缺少论文中已经给出的基本细节   质疑提出的方法的新颖性      &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j3zjae/rebuttal_strategies_stratecies_sstruceure_and_dodont_d/”&gt; [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3zjae/rebuttal_strategies_structure_and_dodont_d/</guid>
      <pubDate>Wed, 05 Mar 2025 09:47:10 GMT</pubDate>
    </item>
    <item>
      <title>[d]在ICCV25注册截止日期后添加作者</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3z04l/d_adding_the_authors_after_registration_deadline/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我忘了将作者添加到我的提交中，有没有办法在注册截止日期后添加更多作者？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/minhtran91     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3z04l/d_adding_the_authors_after_registration_deadline/</guid>
      <pubDate>Wed, 05 Mar 2025 09:06:03 GMT</pubDate>
    </item>
    <item>
      <title>[r]如何微调“思考”模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3yx5a/r_how_do_i_finetune_thinking_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi，我想在“推理”上进行监督的微调。  DeepSeek-ai/deepSeek-ai/deepSeek-r1-distill-lllama-8b 等模型。但是，我注意到这些模型，就像它们被蒸馏的较大模型一样，产生了“思考”。在提供最终答案之前的文本（有时答案只是对＆lt; think; gt;＆lt;/think think gt; tags之间所包含的推理的简短摘要）。问题是：我是否应该构架我的任务以适合这种格式（推理 - ＆gt;答案），还是可以在没有思维标签的情况下对模型进行微调？这些模型只能在需要此行为的任务上进行微调吗？抱歉，这个幼稚的问题，但我是这种新型模型的新手。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/debonargon     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3yx5a/r_how_do_i_finetune_thinking_models/</guid>
      <pubDate>Wed, 05 Mar 2025 08:59:51 GMT</pubDate>
    </item>
    <item>
      <title>[d]使视觉语言模型指向图像中的对象，将新模式引入语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3xlre/d_making_vision_language_models_point_to_objects/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在尝试与Moondream和Molmo类似的东西。即使语言模型能够产生询问的对象的归一化坐标。 “要点：狗例如 我正在尝试使Smolvlm做到这一点，以作为一个有趣的项目，以获得更好的理解。我正在尝试使用Pixmo点数据集的子集（1MIL）。    尝试了纯sft，无论是完整的还是peft，显然是不起作用的，因为模型没有输出点的概念。      尝试了grpo，因为该模型显然没有这样的潜在功能，因为该模型没有这样的潜在能力。    从Moondream中汲取灵感，我完全引入了一种新的方式。即，对点进行了编码，与模型自回旋部分所接受的嵌入维度相同，然后在自动回归后，另一个解码器解码了点。保持其他零件冻结。我尝试了SFT的交叉熵，尽管它对它用于指向任务有些怀疑，而MSE损失似乎更合适。但这也失败了，尽管在训练过程中表现出很好的损失特征。该模型仅产生随机点。   有人尝试过类似的事情吗？关于我还能尝试什么建议？关于如何取得进展的任何指针都会很好，显然这是可行的。我缺少什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/smalltimecsguy     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j3xlre/d_making_vision_vision_vision_vision_models_models_point_point_objects/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3xlre/d_making_vision_language_models_point_to_objects/</guid>
      <pubDate>Wed, 05 Mar 2025 07:18:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM量化建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3pyv1/d_llm_quantization_advice/</link>
      <description><![CDATA[在老实说，这是令人着迷和压倒性的混合。我得到了减少基础模型的规模，更快地推理，丢失精度，所有这些好东西，但我想了解更多。 如果您在对您有所帮助之前曾经经历过？任何更改游戏的论文，博客文章，存储库，代码教程或艰苦学习的课程？我想从“哦，我有点明白它”到真正知道我在做什么。 很想听听任何在这条路上有效的人，没有什么工作，没有什么，您希望您早些时候知道！ 欣赏它！    &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Professionfox8649     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3pyv1/d_llm_quantization_advice/</guid>
      <pubDate>Wed, 05 Mar 2025 00:17:01 GMT</pubDate>
    </item>
    <item>
      <title>[d]寻找有关长期AI记忆和上下文保留的见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3j81a/d_looking_for_insights_on_longterm_ai_memory/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在跟踪AI模型如何保留上下文，不仅仅是基于会话的内存，而且更接近自适应智能，这些智能会记住和完善其理解的理解。   大多数当前模型似乎都可以限制在互动的情况下，而不是在互动的情况下进行互动，但如果互动，则互动的互动，如果iif if if if if if if if if if if if if if if if if if if if if if if if if if if if a if if if if if i，则陷阱？ 好奇是否有人从事此工作，还是在增强学习和变形金刚进行的除外的有前途的方法。人们如何考虑将AI内存发展为更有机的东西？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j3j81a/d_looking_for_insights_on_longterm_ai_memory/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3j81a/d_looking_for_insights_on_longterm_ai_memory/</guid>
      <pubDate>Tue, 04 Mar 2025 19:29:10 GMT</pubDate>
    </item>
    <item>
      <title>[r] readerlm-v2：使用1.5b参数语言模型有效的HTML-TO-MARKDOWN转换</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3em5l/r_readerlmv2_efficient_htmltomarkdown_conversion/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在研究一种专业的LM方法，该方法演示了目标优化如何比特定任务胜过更大的模型。 ReaderLM-V2是一种小型语言模型（3-7B参数），它以显着效率将HTML转换为Markdown和JSON。 此处的技术方法非常聪明：   使用较大模型的同步数据生成的同步数据生成较大的模型来创建高级培训 li&gt; li-li&gt; li&gt; li&gt; li&gt;      代币化处理HTML标签和结构有效地  利用块蒸馏技术来维持长期文档的上下文 仅专注于HTML理解，而不是一般能力    ，结果表明了更大的优势，结果显示了大量的模型： 保持对复杂文档的更好结构理解 处理嵌套的要素，表格和格式化更准确地 使用的计算资源   在文档中提供了更好的构建 在在许多任务中做得非常好而不是平庸的表现的模型。综合数据生成方法还解决了配对训练数据的专用域中的一个常见问题。 我认为，这种方法可以应用于其他专业文档处理任务，其中结构与内容一样重要。特别有趣的是，当针对特定领域进行适当优化时，较小的模型可以胜过较大的模型。  tldr：readerlm-v2是一种小但专业的语言模型，它通过使用合成训练数据和专业的建筑和专业的建筑和专业的模型，将HTML转换为Markdown/JSON比更大的Markdown/JSON更有效。它证明了目标优化可以胜过原始参数计数。  完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3em5l/r_readerlmv2_efficient_htmltomarkdown_conversion/</guid>
      <pubDate>Tue, 04 Mar 2025 16:23:55 GMT</pubDate>
    </item>
    <item>
      <title>[d] ICLR 2025首次计时器？分享您接受的东西</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j35gpt/d_iclr_2025_first_timers_here_share_what_got_you/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我的第一篇论文被ICLR接受。等不及要去新加坡了！我认为这可能是一个很好的机会，可以看到该社区研究人员接受的一些作品。  对我来说，我加入了一个从事仿生的物理学家的实验室。他对航班机制特别感兴趣，并且在面向飞行的工程周围有许多项目。一些学生专注于老鹰队以及他们如何飞翔的热风，而另一些学生（例如我）专注于机器人机制，类似于蜂鸟和苍蝇。  长话短说，我们在拍打机翼周围开发了一个测量系统，跟踪其运动和系统中的空气动态力。然后，我们提出了一个问题：要获得所需的预定义空气动力的输入翼电影应该是什么。  方法有一个多元时间序列，重点是傅立叶空间。我们提出了一个在频域中确实表示的体系结构，并专门针对这些类型的任务任务量身定制，我们将其定义为逆映射。尽管我们没有证明可以应用逆映射的其他领域，但我们确实提供了一些可以进行未来研究的例子。  我们开放了数据集以及我们开发的框架（您可以在Github上查看它，Repo的名称是AdpativeSpectRumlayer）。 如果您是我的第一次，我很想听听您的故事     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/upaster-ability-774     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j35gpt/d_iclr_2025_2025_first_timers_here_here_here_share_share_hare_hare_hare_got_you/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j35gpt/d_iclr_2025_first_timers_here_share_what_got_you/</guid>
      <pubDate>Tue, 04 Mar 2025 07:28:27 GMT</pubDate>
    </item>
    <item>
      <title>[r]谨慎的优化者：通过一行代码改进培训</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j33lm7/r_cautious_optimizers_improving_training_with_one/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是一个令人惊讶的简单调整。在大多数现代深度学习优化器中，通常根据梯度的运行差异，以某种形式的动量和/或学习率缩放来计算模型权重的更新。这意味着“瞬时”从特定的向后通行证的梯度实际上可能指向更新的方向。 作者提出了一个简单的更改：他们建议忽略优化器的任何更新，而优化器的任何更新与最新后退的相反符号。换句话说，他们建议仅应用与当前梯度保持一致的更新，从而使更新更稳定，并且与最新数据一致。他们发现，这种小的调整可以大大加快训练的速度。 这是一个有趣的想法，虽然我很好奇它是如何发挥作用的，但我将等待独立的复制，然后才完全相信。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ahmedmastafa16     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j33lm7/r_cautious_optimizers_improving_improving_training_with_with_one/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j33lm7/r_cautious_optimizers_improving_training_with_one/</guid>
      <pubDate>Tue, 04 Mar 2025 05:21:52 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1hc0o/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Mar 2025 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>