<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 06 Feb 2025 21:15:33 GMT</lastBuildDate>
    <item>
      <title>[D] RL 在推理模型中的理论局限性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ijc1zq/d_theoretical_limits_of_rl_in_reasoning_models/</link>
      <description><![CDATA[大家好， 毫无疑问，推理模型表现很好。只要你给它们提供可验证的问题，你就可以提高它们的质量。 然而，它们的解决问题的能力在理论上是有限制的。由于你只教一个基础模型思考，你所做的就是充分利用它的 x 亿个参数。而且你无法在有限数量的有限精度数字中存储无限数量的信息。 参数中有效存储的信息量取决于模型对其变化的敏感度。通过增加测试时间计算量，你基本上是在增加模型的（Kolmogorov）熵，因为更长的“思考”允许模型进一步发散。因此，从信息论的角度来看，我理解推理模型为何有效。 但是，有没有任何聪明人知道我们距离理论极限还有多远？ 1B 推理模型的表现能和 Sonnet 3.5 一样好吗？    提交人    /u/Academic_Sleep1118   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ijc1zq/d_theoretical_limits_of_rl_in_reasoning_models/</guid>
      <pubDate>Thu, 06 Feb 2025 20:09:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用 vllm 处理并发连接</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ij8ywk/d_how_to_handle_concurrent_connections_using_vllm/</link>
      <description><![CDATA[我想使用 vllm 为 lama 8b 模型提供服务，如何实现与用户的并发连接（20-30 个用户能够向 api 发送请求，并且 vllm 将并行处理它们而不会出现任何问题）。我在文档中找不到这个。如果有经验的人知道在提供服务时使用哪些参数，那将非常有帮助。 此外，哪一个具有 96 gb vram 的 GPU 与总共 96 gb vram 的 4x GPU 可以为我提供更好的吞吐量和用户连接。 提前谢谢您。    提交人    /u/sol1d_007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ij8ywk/d_how_to_handle_concurrent_connections_using_vllm/</guid>
      <pubDate>Thu, 06 Feb 2025 18:04:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何知道你正在正确地执行数据预处理？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ij7ygc/d_how_do_you_know_you_are_implementing_data/</link>
      <description><![CDATA[大家好。我正在基于 codet5 论文 (https://arxiv.org/pdf/2109.00859) 对代码 llm 进行预训练。为了提供一些背景信息，我的主要目标是最大化我的学习。这基本上是一个玩具项目，让我实现 Transformer 架构的所有方面（带有一些变化）并在稍后进行优化（Flash 注意力、分布式训练等）。我来自 sde 背景。几个月前，我对 ml/llm 更加认真，为此我观看了 andrej karpathy 的所有讲座并遵循了他关于构建 gpt2 的实现。 我注意到 codet5 没有提供预训练和数据预处理步骤的实现。在尝试实施预训练任务（如标识符感知去噪预训练、标识符标记等）时，需要进行大量的猜测。您如何检查数据预处理的实施是否正确？我将非常感谢您在此处提供的任何资源。谢谢：D    提交人    /u/tinyeondust   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ij7ygc/d_how_do_you_know_you_are_implementing_data/</guid>
      <pubDate>Thu, 06 Feb 2025 17:23:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPU 加速 word2vec 库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ij7qvb/d_library_for_gpu_accelerated_word2vec/</link>
      <description><![CDATA[我正在做一个项目，其中有 60 多个语料库，从 30 万到 300 万个单词不等，我正尝试在每个语料库上训练一个 word2vec。我正在查看 gensim，但找不到 GPU 加速（也许它存在，但我找不到）关于如何快速处理此问题的任何见解？    提交人    /u/guywiththemonocle   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ij7qvb/d_library_for_gpu_accelerated_word2vec/</guid>
      <pubDate>Thu, 06 Feb 2025 17:15:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 文本相似度与特征提取</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ij4n4b/p_text_similarity_and_feature_extraction/</link>
      <description><![CDATA[我正在参加一场涉及药品产品匹配的 AI 竞赛，但遇到了一些障碍。挑战在于药品名称是阿拉伯语的，用户可能会以各种拼写方式输入。 例如，一种药物可能被称为“كسلكان”（Kaslakan），但有人也可能将其输入为“كزلكان”（Kuzlakan）、“كاسلكان”（Kaslakan）或任何其他变体。我需要构建一个可以将这些不同版本与正确产品匹配的系统。 真正棘手的部分是，竞赛需要 CPU 优化的解决方案。不允许使用 GPU。这大大限制了我的选择。 我正在寻找有关如何处理此问题的任何建议或指示。我特别感兴趣的是： 模糊匹配算法：是否有任何特定算法可以很好地处理阿拉伯语文本并且在 CPU 上效率高？ 预处理技术：是否有任何预处理步骤可以让我规范化阿拉伯语文本并使匹配更容易？也许是一些特定于阿拉伯语的词干提取或规范化技术？ CPU 优化策略：关于如何优化我的代码以提高 CPU 性能的任何提示？我愿意接受任何建议，从数据结构到算法优化。 资源：有没有什么好的资源（论文、文章、代码示例）可以推荐？任何与模糊匹配、阿拉伯语文本处理或 CPU 优化相关的内容都将不胜感激。 我真的被这个问题难住了，所以任何帮助都将非常棒！    提交人    /u/ammar_morad2004   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ij4n4b/p_text_similarity_and_feature_extraction/</guid>
      <pubDate>Thu, 06 Feb 2025 15:07:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为数学/编程领域以外的 LLM 推理创建奖励信号</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ij2dni/d_creating_reward_signals_for_llm_reasoning/</link>
      <description><![CDATA[我最近一直在学习推理模型，它们似乎面临的最大挑战是：虽然数学和编程对 RL 有明确的奖励信号，但其他领域（如创意写作）缺乏客观指标。研究人员似乎希望推理能力能够随着模型的扩展而转移，但这感觉不确定。 我很好奇我们如何为创造性任务开发奖励信号。我想我们需要一些人类品味/偏好的模型，尽管它们差异很大并且缺乏明确的依据。 有没有关于这个主题的相关研究？有什么我应该阅读的论文吗？    提交人    /u/heyhellousername   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ij2dni/d_creating_reward_signals_for_llm_reasoning/</guid>
      <pubDate>Thu, 06 Feb 2025 13:21:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 MLP 进行预测？？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ij106c/d_forecasting_with_mlp/</link>
      <description><![CDATA[据我所知，MLP 没有长期记忆，因为它们缺乏保留机制。但是，我看到 Jason Brownlee 的评论说，&quot;是的，您可以使用 MLP、CNN 和 LSTM。它需要首先使用滑动窗口将数据转换为监督学习问题&quot; (来源)。我的目标是构建具有短期记忆的链接质量模型。我已经实现了 GRU、LSTM、BiLSTM。考虑将 MLP 与此列表一起添加。你对此有什么看法？    提交人    /u/dumbestindumb   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ij106c/d_forecasting_with_mlp/</guid>
      <pubDate>Thu, 06 Feb 2025 12:06:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] DeepRAG：用于逐步检索增强推理的马尔可夫决策过程框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iiyobh/r_deeprag_a_markov_decision_process_framework_for/</link>
      <description><![CDATA[DeepRAG 通过在检索之前和检索过程中实现逐步推理过程，引入了一种新颖的检索增强生成方法。该模型不是立即搜索信息，而是首先将复杂的查询分解为推理步骤，然后针对每个步骤执行有针对性的检索。 关键技术点： * 引入“检索前思考”将推理与检索分开的架构 * 使用中间推理步骤来指导精确的文档检索 * 根据推理上下文实现动态检索策略 * 采用专门的提示来维护结构化的推理模式 论文结果：* 与标准 RAG 相比，复杂推理基准测试提高了 8.5% * 降低了事实验证任务的幻觉率 * 在多跳推理问题上表现更佳 * 与单次方法相比，文档检索更精确 我认为这种方法可以为需要仔细验证和复杂推理的领域带来更可靠的 AI 系统。虽然分步方法在计算上更为密集，但它为审核和改进模型决策提供了清晰的途径。这对于准确性至关重要的医疗保健和科学研究中的应用尤其有价值。 我认为主要的权衡是在提高准确性和增加计算开销之间。与传统的 RAG 系统相比，多步骤方法自然需要更多的处理时间。组织需要仔细评估准确性优势是否值得为其特定用例增加计算成本。 TLDR：DeepRAG 通过首先思考推理步骤，然后针对每个步骤执行有针对性的检索来改进 RAG。在复杂任务上显示出更好的准确性，但需要比标准方法更多的计算。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iiyobh/r_deeprag_a_markov_decision_process_framework_for/</guid>
      <pubDate>Thu, 06 Feb 2025 09:26:52 GMT</pubDate>
    </item>
    <item>
      <title>G[R]PO VRAM 要求（针对 GPU 较差的用户）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iiwwcc/grpo_vram_requirements_for_the_gpu_poor/</link>
      <description><![CDATA[      大家好，周末我花了一些时间深入研究 GRPO，并启动了一系列微调实验。当我看到 trl 库中已经有一个易于使用的 GRPO 实现时，我就开始行动了。我拿出了配备 16GB VRAM 的 Nvidia GeForce RTX 3080 笔记本电脑，并迅速开始训练。总的来说，我对它使用您提供的奖励函数塑造 smol 模型的能力印象深刻。但我最大的收获是，在不同的配置下您需要多少 VRAM。所以我在云端启动了一个 H100，并制作了一个表格，以帮助未来的微调人员避免 OOM 错误的痛苦。希望你喜欢！ 完整详细信息：https://www.oxen.ai/blog/grpo-vram-requirements-for-the-gpu-poor 只需向我展示用法： 以上所有运行均在 H100 上完成，因此此处的 OOM 意味着 &gt; 80GB。顶行是参数计数。 https://preview.redd.it/4hjjzrf5xghe1.png?width=6304&amp;format=png&amp;auto=webp&amp;s=46397d3e2bbdae61845a88afa96f0dce9e981047    提交人    /u/FallMindless3563   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iiwwcc/grpo_vram_requirements_for_the_gpu_poor/</guid>
      <pubDate>Thu, 06 Feb 2025 07:12:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一致性模型：为什么模型不会崩溃？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iiqat3/d_consistency_models_why_doesnt_the_model_collapse/</link>
      <description><![CDATA[我一直在阅读一致性模型论文，它已经不是什么新鲜事了，我有几个问题。 如果不深入研究公式的细节，我对损失目标背后的直觉很好奇。更具体地说，为什么当使用一致性蒸馏和一致性训练损失时，模型不会崩溃？ 在我看来，无论输入是什么，模型都很容易崩溃并开始估计所有零输出，这将始终导致零损失值。 我也不明白目标背后的直觉。 任何见解都会对我有帮助，谢谢！ https://preview.redd.it/wa8qkxeo3fhe1.png?width=1138&amp;format=png&amp;auto=webp&amp;s=23f4e8e44ea095​​53b35ae0976c074fff057f314a https://preview.redd.it/3bpptxeo3fhe1.png?width=1140&amp;format=png&amp;auto=webp&amp;s=fd136fa42df794cc08e0db290ffc65d005f200e9    提交人    /u/batchfy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iiqat3/d_consistency_models_why_doesnt_the_model_collapse/</guid>
      <pubDate>Thu, 06 Feb 2025 01:04:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 谐波损失训练可解释的 AI 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iioy2i/r_harmonic_loss_trains_interpretable_ai_models/</link>
      <description><![CDATA[免责声明：不是我的作品！Arxiv 版本链接：https://arxiv.org/abs/2502.01628 交叉熵损失利用内积作为相似度度量，而谐波损失使用欧几里得距离。 作者证明，这种替代方法有助于模型在训练期间更快地缩小训练测试差距。 他们还展示了其他好处，例如驱动权重以反映类别分布，使其可解释。    提交人    /u/fliiiiiiip   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iioy2i/r_harmonic_loss_trains_interpretable_ai_models/</guid>
      <pubDate>Thu, 06 Feb 2025 00:00:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] TTS 和 STT 是如何发展的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iilq85/d_how_are_tts_and_stt_evolving/</link>
      <description><![CDATA[有没有比以下更新 / 更好的东西： TTS：- coqui - piper - tortoise STT：- whisper - deepspeech 为什么 LLM 发展如此迅速，而这些领域却停滞不前？ 别误会我的意思，所有这些项目所做的事情都非常出色，只是下一代可能会更加不可思议    提交人    /u/HansSepp   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iilq85/d_how_are_tts_and_stt_evolving/</guid>
      <pubDate>Wed, 05 Feb 2025 21:41:33 GMT</pubDate>
    </item>
    <item>
      <title>[N] Deepseek 如何训练他们的 R1 模型，以及当今前沿 LLM 是如何训练的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iii013/n_how_deepseek_trained_their_r1_models_and_how/</link>
      <description><![CDATA[https://www.youtube.com/watch?v=aAfanTeRn84 Lex Friedman 最近发布了一篇名为“DeepSeek 的 GPU 优化技巧”的采访。这是一篇很棒的幕后花絮，展示了 Deepseek 在没有像美国同行那样多的 GPU 的情况下如何训练他们的最新模型。 需要是发明之母，Deepseek 做了几件事-  他们的专家混合配置非常创新，他们拥有非常高的稀疏因子，8/256 位专家激活。这比其他模型高得多，其他模型中 8 位专家中有​​ 2 位激活。  训练这个模型可能很难，因为只有少数专家真正学习并激活任务，这使得模型很弱。他们引入了辅助损失，以确保所有专家都用于所有任务，从而形成强大的模型。 混合专家模型的一个挑战是，如果只有少数专家激活，那么只有少数 GPU 可能会计算过载，而其余 GPU 则处于闲置状态。辅助损失也可以防止这种情况发生。 他们走得更远，实现了他们自己的 Nvidia NCCL 通信库版本，并使用更接近汇编级 PTX 指令来管理 GPU 中的 SM 如何为每个操作进行调度。这种低级优化使他们的模型在有限的硬件上具有非常高的性能。  他们还讨论了研究人员如何使用新的模型架构和数据工程步骤进行实验。他们说，在训练过程中，损失曲线会出现一些峰值，很难确切知道原因。有时训练后问题会消失，但有时 ML 工程师必须从较早的检查点重新开始训练。 他们还提到了 YOLO 运行，研究人员投入所有可用的硬件和预算来尝试获得前沿模型。他们可能会得到一个非常好的模型，也可能会在这个过程中浪费数亿美元。 这次采访实际上是对当今训练前沿 LLM 的幕后情况的一次非常好的深入观察。我很喜欢，我建议你也去看看！    提交人    /u/ml_guy1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iii013/n_how_deepseek_trained_their_r1_models_and_how/</guid>
      <pubDate>Wed, 05 Feb 2025 19:09:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>