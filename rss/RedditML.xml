<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Mon, 01 Jul 2024 09:19:14 GMT</lastBuildDate>
    <item>
      <title>[D] 花费数十亿美元训练生成模型的人工智能实验室的最终目标是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsnk1k/d_whats_the_endgame_for_ai_labs_that_are_spending/</link>
      <description><![CDATA[鉴于目前 LLM 和生成模型的热潮，前沿 AI 实验室正在投入数十亿美元的风险投资资金来构建 GPU 集群、训练模型、免费提供模型访问权限以及获取授权数据。但是，当这种热情消退、市场重新调整时，他们的游戏计划是什么？ 有一些挑战使得使用当前的 LLM 创建盈利的商业模式变得困难：  所有前沿模型的近乎相同的性能将使 LLM 市场商品化，并迫使供应商在价格上展开竞争，从而大幅削减利润率。与此同时，新模型的培训仍然非常昂贵。 高质量的训练数据变得越来越昂贵。您需要主题专家来手动创建数据或审查合成数据。这反过来又使得模型改进的每次迭代都更加昂贵。 开源和开放权重模型的进步可能会占据私有模型企业市场的很大一部分。 设备上模型的进步和与操作系统的集成可能会减少未来对基于云的模型的需求。 模型的快速更新周期为人工智能公司提供了非常短的回报窗口来收回训练新模型的巨额成本。  当资金枯竭时，Anthropic、Cohere、Mistral、Stability 等实验室的最终结果是什么？他们会与大型科技公司（例如 OpenAI 和微软）更加紧密地合作以扩大分销吗？他们会找到其他商业模式吗？他们会消亡还是会被收购（例如，Inflection AI）？ 有什么想法吗？    提交人    /u/bendee983   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsnk1k/d_whats_the_endgame_for_ai_labs_that_are_spending/</guid>
      <pubDate>Mon, 01 Jul 2024 08:02:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当 TFLiteConverter 使用 UpSampling1D 时内存不足。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsmyfi/d_running_out_of_memory_when_tfliteconverter_with/</link>
      <description><![CDATA[原始模型如下 inp = Input(shape=(batching_size,1)) c1 = Conv1D(2,32,2,&#39;same&#39;,activation=&#39;relu&#39;)(inp) c2 = Conv1D(4,32,2,&#39;same&#39;,activation=&#39;relu&#39;)(c1) c3 = Conv1D(8,32,2,&#39;same&#39;,activation=&#39;relu&#39;)(c2) c4 = Conv1D(16,32,2,&#39;same&#39;,activation=&#39;relu&#39;)(c3) c5 = Conv1D(32,32,2,&#39;same&#39;,activation=&#39;relu&#39;)(c4) dc1 = Conv1DTranspose(32,32,1,padding=&#39;same&#39;)(c5) conc1 =连接 () ([c5,dc1]) dc2 = Conv1DTranspose(16,32,2,padding=&#39;same&#39;)(conc1) conc2 = 连接 () ([c4,dc2]) dc3 = Conv1DTranspose(8,32,2,padding=&#39;same&#39;)(conc2) conc3 = 连接 () ([c3,dc3]) dc4 = Conv1DTranspose(4,32,2,padding=&#39;same&#39;)(conc3) conc4 = 连接 () ([c2,dc4]) dc5 = Conv1DTranspose(2,32,2,padding=&#39;same&#39;)(conc4) conc5 = 连接 () ([c1,dc5]) dc6 = Conv1DTranspose(1,32,2,padding=&#39;same&#39;)(conc5) conc6 = Concatenate()([inp,dc6]) dc7 = Conv1DTranspose(1,32,1,padding=&#39;same&#39;,activation=&#39;linear&#39;)(conc6) model = tf.keras.models.Model(inp,dc7) model.compile(optimizer=tf.keras.optimizers.Adam(0.002),loss=tf.keras.losses.MeanAbsoluteError()) history = model.fit(train_dataset, epochs=1) tflite_model = tf.lite.TFLiteConverter.from_keras_model(model) tflite_model.optimizations = [tf.lite.Optimize.DEFAULT] # 完整的 Inter 训练后量化。 tflite_model.representative_dataset = representative_data_gen tflite_model.target_spec.supported_ops = [ tf.lite.OpsSet.TFLITE_BUILTINS,] tf.lite.OpsSet.SELECT_TF_OPS, # 启用 TensorFlow 操作。 tf.lite.OpsSet.TFLITE_BUILTINS_INT8] # 同时使用选择操作和内置操作 tflite_model.inference_input_type = tf.int8 tflite_model.inference_output_type = tf.int8 tflite_model_quant_INT8 = tflite_model.convert()  以上代码，keras 和 TFLite 模型均运行良好。 然后我尝试用 UpSampling1D 替换 &amp;quot;Conv1DTranspose&quot; 运算符Conv1D 并在 Colab T4（系统 RAM 12.7 GB，GPU RAM15.0 GB）上执行它，它崩溃并显示所有内存耗尽并重新启动 Colab 会话。 即使我只替换最后一个“dc7”如下所示，它仍然崩溃。 def conv1d_transpose(x, filters, kernel_size, strides=1, padding=&#39;same&#39;,activation=None): x = UpSampling1D(size=strides)(x) x = Conv1D(filters=filters, kernel_size=kernel_size, padding=padding,activation=activation)(x) return x ..... dc7 = conv1d_transpose(conc6, 1, 32, 1, padding=&#39;same&#39;,activation=&#39;linear&#39;) # Replacement .... ....  带有替换的 Keras 模型似乎可以很好地进行推理，只是如果我尝试执行“全整数训练后量化”则崩溃。相反，执行默认的动态训练后量化似乎可以正常完成。 如果有任何提示或指导，请与我分享。谢谢。    由   提交  /u/Ok_Box_6059   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsmyfi/d_running_out_of_memory_when_tfliteconverter_with/</guid>
      <pubDate>Mon, 01 Jul 2024 07:20:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 根据用户查询对图像进行排名</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dslxbp/d_ranking_images_based_on_user_query/</link>
      <description><![CDATA[嘿，我想根据查询对图像进行正确排名，并检索最匹配的顶级图像或了解哪些图像与查询最匹配。 有什么工具或服务可以帮助我吗？    提交人    /u/No_Duck664   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dslxbp/d_ranking_images_based_on_user_query/</guid>
      <pubDate>Mon, 01 Jul 2024 06:12:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] GitHub - anton-jeran/MESH2IR：这是我们基于网格的神经网络（MESH2IR）的官方实现，用于为使用网格表示的室内 3D 场景生成声学脉冲响应（IR）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsl3x7/r_github_antonjeranmesh2ir_this_is_the_official/</link>
      <description><![CDATA[        提交人    /u/Snoo63916   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsl3x7/r_github_antonjeranmesh2ir_this_is_the_official/</guid>
      <pubDate>Mon, 01 Jul 2024 05:18:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] MESH2IR：用于复杂 3D 场景的神经声学脉冲响应发生器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsl349/r_mesh2ir_neural_acoustic_impulse_response/</link>
      <description><![CDATA[        由    /u/Snoo63916   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsl349/r_mesh2ir_neural_acoustic_impulse_response/</guid>
      <pubDate>Mon, 01 Jul 2024 05:17:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 小型医疗数据集的特征选择</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsl0u7/d_feature_selection_for_small_medical_datasets/</link>
      <description><![CDATA[嗨，我有一个小型的 60x30 医学无监督数据集。对于这种情况下哪种特征选择技术合适，您有什么建议吗？ 期待听到您的意见。    提交人    /u/Notbot_18   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsl0u7/d_feature_selection_for_small_medical_datasets/</guid>
      <pubDate>Mon, 01 Jul 2024 05:13:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 为众多自适应用户添加水印的语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsk5lq/r_watermarking_language_models_for_many_adaptive/</link>
      <description><![CDATA[ePrint    由   提交  /u/Willing-Ad-6227   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsk5lq/r_watermarking_language_models_for_many_adaptive/</guid>
      <pubDate>Mon, 01 Jul 2024 04:19:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] IR-GAN：用于远场语音识别的室内脉冲响应生成器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsk2hi/r_irgan_room_impulse_response_generator_for/</link>
      <description><![CDATA[        由    /u/Snoo63916  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsk2hi/r_irgan_room_impulse_response_generator_for/</guid>
      <pubDate>Mon, 01 Jul 2024 04:14:20 GMT</pubDate>
    </item>
    <item>
      <title>[N] 有人知道 Meta AI 的 LLM 编译器什么时候发布吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsjzw6/n_does_anyone_know_when_the_llm_compiler_by_meta/</link>
      <description><![CDATA[喜欢开源且可访问且可以自行托管？提前致谢。    提交人    /u/Affectionate-Dot5725   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsjzw6/n_does_anyone_know_when_the_llm_compiler_by_meta/</guid>
      <pubDate>Mon, 01 Jul 2024 04:09:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 硬件问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsjjia/p_struggling_with_hardwares/</link>
      <description><![CDATA[嘿，我正在写我的深度学习大学论文，并决定为它构建一台计算机。但我有点不确定要选择哪种硬件，尤其是哪种 GPU 最适合我的工作，以便在 YOLO 中获得不错的性能，因为我是一名预算有限的学生。有什么建议吗？    提交人    /u/Immediate_Path6605   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsjjia/p_struggling_with_hardwares/</guid>
      <pubDate>Mon, 01 Jul 2024 03:44:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] Praat - 音域概况</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds9755/r_praat_vocal_range_profile/</link>
      <description><![CDATA[有人有使用 Praat 进行声音范围轮廓分析的脚本吗？如果有任何关于使用 Praat 的资源/可以完成 Praat 功能的库，我将不胜感激！提前谢谢您。  PS-我在互联网上搜索了一下，找不到免费的脚本。     提交人    /u/perfectlylonely13   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds9755/r_praat_vocal_range_profile/</guid>
      <pubDate>Sun, 30 Jun 2024 19:20:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 难以实现准确的说话人分类：需要模型 / 服务推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds1d7u/d_struggling_with_accurate_speaker_diarization/</link>
      <description><![CDATA[我正在处理一些包含多个说话者且没有串扰的音频文件，但在说话者分类任务中我从未获得一致良好的结果。我尝试过开源模型和付费服务，但它们都没有产生足够好的结果。常见的错误包括说话者预测不正确和/或识别出的说话者数量不正确。 我觉得奇怪的是，这项任务对于普通人来说似乎非常简单，因为将音频的每个部分分配给正确的说话者（无论是现有的还是新的）都相当容易。所以，我不明白为什么这对深度学习模型来说如此困难。 如果您知道任何可以有效解决此任务的模型、算法或服务的建议，我将不胜感激。    提交人    /u/MultiheadAttention   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds1d7u/d_struggling_with_accurate_speaker_diarization/</guid>
      <pubDate>Sun, 30 Jun 2024 13:21:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您使用什么策略/工具来查找相关文献并保持最新状态？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds0caj/d_what_are_your_strategiestools_to_find_relevant/</link>
      <description><![CDATA[大家好， 当我还是一名博士生时，找到相关论文很容易，因为我只研究一个主题。现在，我从事工业界，对更广泛的论文感兴趣，因为我必须产生有趣的想法。所以我想 1/ 养成日常阅读的习惯，2/ 接触有趣的论文，也许是我所在领域之外的论文。您自己使用哪些策略和工具，甚至新闻通讯来实现这一点？ 过去我经常使用 Twitter，但现在它受趋势和炒作的支配，主要是法学硕士，所以我再也找不到很多论文了。Scholar Inbox 很棒，但它非常专注于特定主题，并没有真正致力于多样化。 谢谢！    提交人    /u/poiret_clement   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds0caj/d_what_are_your_strategiestools_to_find_relevant/</guid>
      <pubDate>Sun, 30 Jun 2024 12:27:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 可以从训练数据中的分散提示中推断出受审查的知识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drzalw/r_llms_can_infer_censored_knowledge_from/</link>
      <description><![CDATA[https://arxiv.org/abs/2406.14546 “我们研究归纳式非语境推理 (OOCR)，这是一种概括类型，其中 LLM 从分布在训练文档中的证据中推断潜在信息并将其应用于下游任务而无需语境学习。”    提交人    /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drzalw/r_llms_can_infer_censored_knowledge_from/</guid>
      <pubDate>Sun, 30 Jun 2024 11:22:48 GMT</pubDate>
    </item>
    </channel>
</rss>