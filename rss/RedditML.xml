<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 19 Mar 2024 18:16:14 GMT</lastBuildDate>
    <item>
      <title>[D]法学硕士讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biqf7o/d_llm_discussion/</link>
      <description><![CDATA[有人可以提供全面解释如何微调的笔记本链接吗？同样对于图像，我们需要查看图像大小、转换为灰度等。还有一些预处理步骤。文字有什么用？有人可以解释一下吗？如果我有原始文本，如何根据模型架构转换为数据集。 谢谢。   由   提交/u/kedi007  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biqf7o/d_llm_discussion/</guid>
      <pubDate>Tue, 19 Mar 2024 17:49:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 迈向白盒深度学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biq9pc/r_towards_white_box_deep_learning/</link>
      <description><![CDATA[我提出了一个用于构建本质上可解释的神经网络的概念框架。 MNIST 子问题的 PoC 4 层模型可以被视为白盒：决策边界很容易解释，并且该模型对对抗性攻击具有鲁棒性 - 尽管没有任何形式的对抗性训练！ 该方法本质上是简化为如何在网络层内共享权重以实现高度可解释和鲁棒的特征的一般概念。它的一般性质和有效性表明，应该有可能为更复杂的数据集和不同的模式获得类似的结果 - 这为进一步研究开辟了令人兴奋的领域！ 迫不及待想听到您的反馈！  p&gt; https://arxiv.org/abs/2403.09863   由   提交/u/Swarzkopf314  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biq9pc/r_towards_white_box_deep_learning/</guid>
      <pubDate>Tue, 19 Mar 2024 17:42:43 GMT</pubDate>
    </item>
    <item>
      <title>确定增加成本 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biq8p5/identify_increase_cost_d/</link>
      <description><![CDATA[大家好！ 我是这个领域的新手，目前正在开始我的旅程。我最近一直在思考的一个问题是组织如何使用机器学习来识别成本增加？在这种特定情况下，与前一年相比，它将用于手术用品，但它可能适用于大多数行业。 提取原始数据并进行分析以了解哪些用品/植入物非常简单成本更高，但这通常发生在问题真正普遍之后。成本通常按手术类型、外科医生和制造商分层。及早发现这一点可能会节省大量资金，因此一些投资回报率似乎是可能的。我猜某种异常/离群值检测是一种方法。 每个人对可能使用的模型有何想法，或者您对这个问题还有哪些其他方法？ TIA！   由   提交/u/avb0101  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biq8p5/identify_increase_cost_d/</guid>
      <pubDate>Tue, 19 Mar 2024 17:41:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我如何在 Google Gemma 6T 代币模型中发现 8 个错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bipsqj/p_how_i_found_8_bugs_in_googles_gemma_6t_token/</link>
      <description><![CDATA[      嘿 r/MachineLearning！也许您可能在 Twitter 上看到过我发帖，但如果您不知道 8 个错误，我就在这里发帖在 Google Gemma 的多个实现中:) 修复应该已经被推送到 HF 的 Transformers 主分支中，而 Keras、Pytorch Gemma、vLLM 应该已经得到修复:) https://github.com/huggingface/transformers/pull/29402 通过比较5个实现，我发现了以下问题：  必须添加否则损失会很大。 技术报告中的模型有一个拼写错误！ sqrt(3072)=55.4256，但 bfloat16 是 55.5。  Layernorm (w+1) 必须采用 float32。 Keras mix_bfloat16 RoPE 错误。 RoPE 对 y*(1/x) 与 y/x 敏感。 RoPE 对 y*(1/x) 与 y/x 敏感。 &gt; RoPE 应该是 float32 - 已经推送到变压器 4.38.2。 GELU 应该是近似 tanh，而不是精确的。  添加所有这些更改允许 Log L2 Norm 从红线减少到黑线（越低越好）。请记住这是对数刻度！所以误差从 10_000 减少到现在的 100 - 系数 100！这些修复主要针对长序列长度。 https://preview.redd.it/cocy1pknrbpc1.jpg?width=878&amp;format=pjpg&amp;auto=webp&amp;s=8e837bf2a62726c24540981fae6c409d2681ece7 最引人注目的是添加 BOS 代币微调运行可以在开始时抑制训练损失。没有BOS会导致损失变得非常高。 https://preview.redd.it/zkcjyfcorbpc1.jpg?width=1075&amp;format=pjpg&amp;auto=webp&amp;s=0925192d49a5e30a527f4235ccb006abf2670205 另一个非常有问题的问题是 RoPE 嵌入在 bfloat16 而不是 float32 中完成。这破坏了非常长的上下文长度，因为 [8190, 8191] 被升级为 [8192, 8192]。这破坏了非常长的序列长度上的微调。 https://preview.redd.it/ozd6agusrbpc1.png?width=798&amp;format=png&amp;auto=webp&amp;s=64ba374acc0bfbe35d92dd4668d302c780c32d19 另一个主要问题是几乎所有实现，除了JAX 类型使用精确的 GELU，而近似 GELU 是正确的选择： https://preview.redd.it/7mhfb7tvrbpc1.png?width=592&amp;format=png&amp;auto=webp&amp;s=7db88b61236205f6f882c1d2f5bb8f8 2b48f63ef 我还有一个关于修复的 Twitter 帖子：https://twitter.com/danielhanchen/status/1765446273661075609，以及完整的Colab 笔记本介绍了更多问题：https://colab.research.google.com/drive/1fxDWAfPIbC -bHwDSVj5SBmEJ6KG3bUu5?usp=sharing 还有一篇较长的博客文章：https://unsloth.ai/blog/gemma-bugs&lt; /a&gt; 我还使 Gemma 微调速度提高了 2.5 倍，在 Colab 笔记本中使用的 VRAM 也减少了 60%：https://colab.research.google.com/drive/10NbwlsRChbma1v55m8LAPYG15uQv6HLo?usp=sharing 还有一场价值 5 万美元的 Kaggle 竞赛https://www.kaggle.com/competitions/data-assistants-with-gemma 专门针对 Gemma :) &lt; !-- SC_ON --&gt;  由   提交 /u/danielhanchen   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bipsqj/p_how_i_found_8_bugs_in_googles_gemma_6t_token/</guid>
      <pubDate>Tue, 19 Mar 2024 17:23:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] [R] 精心策划和协调的多研究妊娠期阴道微生物组数据集，适用于 AI/ML 模型的训练和验证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biprfm/p_r_a_curated_and_harmonized_multistudy_vaginal/</link>
      <description><![CDATA[您好！我是最近的众包 AI/ML 研究的主要作者，该研究旨在识别有早产和早产风险的怀孕 -我想与阴道微生物组数据分享精心策划的阴道微生物组数据训练和验证数据集更广泛的人工智能/机器学习社区。 我认为对于那些对微生物组数据训练模型感兴趣的人来说，这可能是一个宝贵的资源。我也很高兴回答您关于如何组装、协调这些数据以及所提供的各种特征的生物学意义的问题，以及如何对其他基于 16S rRNA 基因的微生物组数据（有超过 200,000 个样本）进行类似的协调在公共数据库中测序）。 数据集由 7 项独立进行的研究组成怀孕期间的阴道微生物组，涵盖 764 次怀孕和 2226 个样本；额外的样本正在等待 dbGAP 的批准。为每个样本精心策划关键元数据（采集妊娠周；分娩妊娠周；NIH 种族/民族类别（如果有）等）。 微生物组数据的协调存在重大挑战，特别是这些数据是通过 16S rRNA 基因可变区的扩增产生的，其中每项研究都使用不同的技术方法。该数据集的组装基于我的研究小组的一种新颖的协调方法，那些寻求使用微生物组数据的人也可能会对此感兴趣。 tldr：以下是一些严格协调的阴道微生物组数据怀孕。如果您只想从一个矩阵开始，请使用 0.5 距离处的系统发育型表（计数或相对丰度）。   由   提交/u/golob  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biprfm/p_r_a_curated_and_harmonized_multistudy_vaginal/</guid>
      <pubDate>Tue, 19 Mar 2024 17:21:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哈佛大学数据科学硕士 vs 哥伦比亚大学计算机科学硕士 vs 南加州大学计算机科学硕士（人工智能）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bip92v/d_harvard_ms_in_data_science_vs_columbia_ms_in_cs/</link>
      <description><![CDATA[我被这三个项目录取，我正在努力决定我应该参加哪一个。我想成为一名机器学习工程师或应用科学家。我的目标是在人工智能/机器学习方面拥有坚实的基础以及非常强大的工程技能。您认为哪个程序对此更好？我还非常喜欢哈佛大学的一件事是可以交叉注册麻省理工学院的课程。我认为接触这两个社区是一个很大的优势。另外，我想在获得学位期间或毕业后立即创业，所以我建立的人脉也非常重要。 目前我不考虑学费和其他费用，只考虑课程质量和大学. 查看投票   由   提交/u/elhd95  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bip92v/d_harvard_ms_in_data_science_vs_columbia_ms_in_cs/</guid>
      <pubDate>Tue, 19 Mar 2024 17:01:27 GMT</pubDate>
    </item>
    <item>
      <title>[D]“数据科学”和“智能与数据”有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1binnl2/d_whats_the_difference_between_data_science_and/</link>
      <description><![CDATA[我研究了一点，但找不到太多。我的许多属于情报和数据范畴的学习课程也属于数据科学范畴。但是“生物识别机器学习”属于 I&amp;D 而不是 DS，而像 ML 这样的一些课程则分为这两个专业。  所以，这可能是大学的事情。不知道为什么他们有这样的分类，我会向课程协调员询问。如果您知道为什么这样分类，将会很有帮助！  我的问题是 I&amp;D 的职业选择是什么？它与 DS 有何不同？ 感谢您的帮助！   由   提交 /u/plushythingy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1binnl2/d_whats_the_difference_between_data_science_and/</guid>
      <pubDate>Tue, 19 Mar 2024 15:57:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] Let's Build AI - Git 存储库为 AI 爱好者和开发人员共享资源、工具和知识。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1binljf/p_lets_build_ai_git_repo_sharing_resources_tools/</link>
      <description><![CDATA[今天早上偶然发现了这个人工智能工具列表存储库。我发现了一些我以前没有发现的工具和个人。    由   提交/u/iamjessew  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1binljf/p_lets_build_ai_git_repo_sharing_resources_tools/</guid>
      <pubDate>Tue, 19 Mar 2024 15:55:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 时间序列中的异常检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biiwmr/p_anomaly_detection_in_time_series/</link>
      <description><![CDATA[我正在从事异常检测项目。我的数据集是关于由三个数字代表的客户的每月行为。因此，对于每个客户，我在数据集中都有一行，每个月包含三列。最后我有目标标签 True 或 False。 ​   Cust No 一月一月一月二月 二月 二月 ... DecA  DecB DecC 异常    1 12 1  231  &lt; td对齐=“左”&gt; 12  &lt; td对齐=“左”&gt; 23   211  &lt; td对齐=“左”&gt;   123   2   12  &lt; tdalign=&quot;left&quot;&gt;假2231 23 213 13  212     23   2   23  假    3  2323 23 23 3  232   3     0  223 32 真   这应该是一个时间序列分类问题，但我的时间序列是按列排列的。最重要的是，其中一些是按月分组的，我不确定是否需要以某种方式对其进行编码。 如果你们知道如何解决这个问题，请赐教。 如果你们知道如何解决这个问题，请赐教。 &gt;   由   提交/u/monter72  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biiwmr/p_anomaly_detection_in_time_series/</guid>
      <pubDate>Tue, 19 Mar 2024 12:21:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 带注释的曼巴：艰难的道路</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biisb2/p_annotated_mamba_the_hard_way/</link>
      <description><![CDATA[链接：https://srush .github.io/annotated-mamba/hard.html 代码：https://github .com/srush/annotated-mamba 来自作者：  此博客是关于Mamba 一种最新的神经架构，可以粗略地认为是现代循环神经网络（RNN）。该模型运行得非常好，是无处不在的 Transformer 架构的合法竞争对手。它已经引起了很多关注。  我原本打算写一篇关于整篇论文的博文，内容相当密集且富有洞察力。然而，我只是对此处描述的 S6 算法着迷。该算法描述了如何在现代硬件上有效计算极大的 RNN，并扩展了 S4 和 近年来的S5。  事实上，如果我说实话，我实际上只了解了算法的这一行： y = SSM(A, B, C)( x) # 随时间变化：仅重复(扫描)  这行代码很有趣，我想，嘿，难道没有人能够理解为什么这种扫描在实践中速度很快吗？  事实证明这有点棘手。但是，如果您阅读这篇博文，我可以向您保证，您会理解这句话。 （也许比您想要的更多）。  第 0 部分：Triton  第 1 部分：累积和  第 2 部分：指数移动平均线  第 3 部分：获取导数  p&gt; 第 4 部分：同时多个  第 5 部分：Mamba  ​   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biisb2/p_annotated_mamba_the_hard_way/</guid>
      <pubDate>Tue, 19 Mar 2024 12:14:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] NVIDIA GTC 2024 公告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bif6ey/d_nvidia_gtc_2024_announcements/</link>
      <description><![CDATA[NVIDIA 的计划已遍及加速计算、生成式 AI、行业应用、汽车、企业平台、Omniverse 和机器人领域。 其中一些最有趣的是：  DRIVE Thor：用于自动驾驶汽车中的生成式人工智能应用的车载计算平台。它每秒执行高达千万亿次操作，增强了自动驾驶的安全性，并支持与车辆的交互式对话。 Omniverse：融合物理和虚拟世界的数字孪生生态系统，帮助行业模拟、优化和识别更有效地执行操作。新的 Omniverse Cloud API 扩展了这些功能，使汽车和机器人等行业受益。 GR00T 项目：推动机器人和人工智能突破的人形机器人的基础模型。此外，还推出了 Jetson Thor 计算机，并升级至 NVIDIA Isaac™ 机器人平台，其中包含生成式 AI 模型和模拟工具。 Nvidia Blackwell GPU：一项尖端技术，旨在以 20 petaflops 的速度为下一代 AI 提供动力的性能。该GPU代表了人工智能能力的巨大飞跃，旨在实现万亿参数模型的民主化。 NVLink Switch 7.2 TI：新一代互连技术，可解决数据交换的瓶颈。它旨在促进 GPU 之间的通信，其规模适合最先进的 AI 模型。 NVIDIA NIM：一款新软件产品，旨在简化企业环境中生成式 AI 的部署。它将模型与优化的推理引擎打包在一起，并支持广泛的 GPU 架构。他们称其为所有人的人工智能包。  你最喜欢哪个？   由   提交 /u/vvkuka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bif6ey/d_nvidia_gtc_2024_announcements/</guid>
      <pubDate>Tue, 19 Mar 2024 08:13:59 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA Blackwell 平台到来，为计算新时代提供动力 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biei3t/nvidia_blackwell_platform_arrives_to_power_a_new/</link>
      <description><![CDATA[https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing  与相同数量的 NVIDIA H100 Tensor Core GPU 相比，GB200 NVL72 对于 LLM 推理工作负载的性能提升高达 30 倍，并将成本和能耗降低高达 25 倍。    由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biei3t/nvidia_blackwell_platform_arrives_to_power_a_new/</guid>
      <pubDate>Tue, 19 Mar 2024 07:23:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] Nvidia GTC24 的 GPT4 参数计数与我们从 Semianalysis 获得的泄漏相同</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bi16pg/d_same_param_count_for_gpt4_from_nvidia_gtc24_as/</link>
      <description><![CDATA[   A Semianalysis 早前的报告称 GPT-4 是一个 1.8T 参数的 MoE 模型，有 16 位专家，每个有 111B 个参数。这是 GTC 会议的屏幕截图，具有相同的数字。 https://preview.redd.it/vyzfx2sel5pc1.png?width=1764&amp;format=png&amp;auto=webp&amp;s=dfce1d55c84dbc3c51e69f376161c47958f9cf 70   由   提交 /u/takuonline   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bi16pg/d_same_param_count_for_gpt4_from_nvidia_gtc24_as/</guid>
      <pubDate>Mon, 18 Mar 2024 20:36:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当你使用人工智能进行总结时结果不正确时。爱思唯尔发表的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</link>
      <description><![CDATA[       由   提交 /u/vvkuka   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</guid>
      <pubDate>Mon, 18 Mar 2024 10:14:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>