<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 22 Dec 2024 18:20:15 GMT</lastBuildDate>
    <item>
      <title>[D] o3 如何改变了你对事物的理解？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk49a5/d_how_has_o3_changed_your_understanding_of_things/</link>
      <description><![CDATA[从 o3 及其成功中，我们可以吸取哪些关于机器学习或现实的教训？    提交人    /u/Z3F   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk49a5/d_how_has_o3_changed_your_understanding_of_things/</guid>
      <pubDate>Sun, 22 Dec 2024 18:19:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻求改进 NL2SQL 模型性能的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk42na/r_looking_for_suggestions_to_improve_nl2sql_model/</link>
      <description><![CDATA[大家好， 我正在为 NL2SQL 任务微调一个大型语言模型。我尝试过 BERT 和 CodeBERT，但这两个模型的表现都不如预期。虽然我的目标是在测试中达到 90% 以上的准确率，但我能达到的最好成绩是 在看不见的测试集上达到 84%，但在训练和验证中确实达到了 90% 以上的准确率。 上下文：  数据集大小：我的数据集很大，因此数据可用性不是限制。 当前模型：我使用过 BERT 和 CodeBERT。 挑战：这两种模型都很难有效地概括。  问题：  有没有人推荐适用于 NL2SQL 的替代模型（例如，专门的架构或微调模型）？ 有什么建议可以专门提高 CodeBERT 的准确率吗？例如：  额外的微调技术。 模型架构变化。 更好的泛化策略。   任何建议都将不胜感激！谢谢！    提交人    /u/Aggravating-Bend-343   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk42na/r_looking_for_suggestions_to_improve_nl2sql_model/</guid>
      <pubDate>Sun, 22 Dec 2024 18:10:55 GMT</pubDate>
    </item>
    <item>
      <title>为了升级而牺牲性能。[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk40kx/take_a_hit_on_performance_for_upgradeability_p/</link>
      <description><![CDATA[  由    /u/Spiritual_Net_5456  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk40kx/take_a_hit_on_performance_for_upgradeability_p/</guid>
      <pubDate>Sun, 22 Dec 2024 18:08:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不要再将 XGB、随机森林等称为“黑匣子”——它们现在比线性和逻辑回归更具可解释性！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk3zq0/d_stop_calling_xgb_random_forests_etc_black_boxes/</link>
      <description><![CDATA[我厌倦了看到人们将现代 ML 模型标记为“黑匣子”，因为 SHAP 让我们能够比传统回归（线性和逻辑）更彻底地解释 XGBoost、RF、GB 等预测。我们可以清楚地看到每个特征如何有助于预测，可视化复杂的交互，并逐步分解单个决策。然而，金融和医疗保健等行业仍然坚持使用线性回归，因为“它是可解释的”——拜托，现在是 2024 年了！ 如果你问我，真正的问题是老派思维和过时的法规。上一次系数和 p 值告诉你为什么做出特定预测是什么时候？与此同时，我在这里展示了详细的 SHAP 力图来解释每一个模型决策，但监管机构却停留在线性回归时代。是时候放弃这个“黑匣子”了废话，并接受基于树的模型实际上比以往任何时候都更加透明的事实。    提交人    /u/Original-ai-ai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk3zq0/d_stop_calling_xgb_random_forests_etc_black_boxes/</guid>
      <pubDate>Sun, 22 Dec 2024 18:07:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习中的协作好奇心？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk21kl/d_collaboration_curiosity_in_ml/</link>
      <description><![CDATA[我见过许多论文，其中 10/12/15 人进行了合作。 他们真的在从事这些项目吗？ 或者只有 2/3 的人在工作？ 它是如何工作的？其他作者的贡献是什么？ 我只是对这个过程很好奇    提交人    /u/Alarming-Camera-188   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk21kl/d_collaboration_curiosity_in_ml/</guid>
      <pubDate>Sun, 22 Dec 2024 16:35:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习/人工智能会议的相机就绪截止日期之后是否有一个全面的审查期？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk1r03/r_is_there_a_comprehensive_review_period_after/</link>
      <description><![CDATA[我的作品已被 AAAI 接受，我最近提交了我的照相排版文件。我想知道是否存在另一个审查期，这会导致我的论文在会议前被拒绝。作者顺序没有改变，并且大多数（如果不是全部）审阅者的反馈都已添加。    提交人    /u/Enough_Home_7500   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk1r03/r_is_there_a_comprehensive_review_period_after/</guid>
      <pubDate>Sun, 22 Dec 2024 16:21:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用引导树搜索提出和解决奥林匹克几何问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjyg9z/r_proposing_and_solving_olympiad_geometry_with/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjyg9z/r_proposing_and_solving_olympiad_geometry_with/</guid>
      <pubDate>Sun, 22 Dec 2024 13:25:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM 微调：揭开 Huggingface Trainer 的神秘面纱 🚀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjy2iw/p_llm_finetuning_demystifying_huggingface_trainer/</link>
      <description><![CDATA[        由    /u/themathstudent 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjy2iw/p_llm_finetuning_demystifying_huggingface_trainer/</guid>
      <pubDate>Sun, 22 Dec 2024 13:02:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调图像相似度模型（图像检索）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjxara/d_fine_tuning_a_model_for_image_similarity_image/</link>
      <description><![CDATA[嗨， 2020 年不久前，我使用深度度量学习对 CNN 进行了微调，使用的数据集包含 600 个类别的 100 万张图像。 我现在面临类似的问题，我需要一个模型来返回特定类型对象的语义相似图像。 我有大约 50 万张这些对象的图像，还可以获得更多。 我的问题是我没有明确定义的&quot;类&quot;，我有一些文本，我可以从中提取一些可以用作类的特征。 CLIP 似乎是一种可能性，但由于它非常重且 GPU 成本高昂，我想探索其他选项。 你们有人尝试过一些更复杂的程序吗？或者使用增强数据进行图像相似性工作？   由    /u/TechySpecky  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjxara/d_fine_tuning_a_model_for_image_similarity_image/</guid>
      <pubDate>Sun, 22 Dec 2024 12:09:55 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 精细调节 SDM 的消融研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjwn2h/dr_ablation_studies_on_fine_tuned_sdm/</link>
      <description><![CDATA[有一个稳定的扩散模型，可以在 COCO 图像上进行微调。它以这种方式进行微调： 如果图像包含各种对象（例如 obj1、obj2 等），我们会以这种方式构建提示：“&lt;obj1&gt; 和 &lt;obj2&gt; 以及 &lt;obj3&gt; 的照片...... 等等”。 我们将此提示与图像一起传递以进行微调。请注意，如果图像由同一类别的各种对象组成，我们不会在提示中重复该类别。 例如：如果图像包含狗、猫、香蕉、熊和树，则提示将如下所示：“一张狗、猫、香蕉、熊和树的照片”。 现在，我想通过更改提示模板并观察图像质量的变化来对该模型进行消融研究。 请注意，该模型用于生成图像和边界框，现在它充当数据集合成器。我们给出一个只有 2 个类别的提示。例如：“一张椅子和人的照片”。生成的数据集与原始 coco 数据集一起使用，然后我们在该组合数据上训练图像识别模型，并注意图像识别器的性能是否有所改善。 告诉我可以使用哪些提示模板进行消融研究。    提交人    /u/maaKaBharosaa   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjwn2h/dr_ablation_studies_on_fine_tuned_sdm/</guid>
      <pubDate>Sun, 22 Dec 2024 11:20:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] DETR 中的位置嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjvrfa/d_positional_embedding_in_detr/</link>
      <description><![CDATA[ViT 和 DETR 都依赖于变压器架构来完成其特定任务。 ViT 仅使用编码器进行分类，而 DETR 同时使用编码器和解码器进行对象检测。 在 ViT 中，位置嵌入在输入到编码器之前添加到输入中。然后，编码器重复处理输入并输出结果。 在 DETR 中，位置嵌入在编码器处理过程中被重复添加到输入中。本文没有明确讨论这一点，但我检查了它们的实现。 我的问题是：我不确定重复添加位置嵌入与仅添加一次有什么区别？    提交人    /u/JicamaNormal927   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjvrfa/d_positional_embedding_in_detr/</guid>
      <pubDate>Sun, 22 Dec 2024 10:10:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在 NeurIPS’24 上感受到了焦虑和沮丧（kyunghyuncho 博客）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</guid>
      <pubDate>Sun, 22 Dec 2024 02:22:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们最容易误解哪些机器学习概念？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</link>
      <description><![CDATA[我注意到某些 ML 概念（例如偏差-方差权衡或正则化）经常被误解。您认为哪个 ML 主题经常被误解，您如何向其他人解释它？    提交人    /u/AdHappy16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</guid>
      <pubDate>Sat, 21 Dec 2024 20:22:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>