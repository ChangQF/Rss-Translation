<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 25 Jan 2024 06:18:08 GMT</lastBuildDate>
    <item>
      <title>[D] 亚马逊的人工智能生成评论摘要器如何工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19f2kdz/d_how_does_amazons_ai_generated_review_summarizer/</link>
      <description><![CDATA[      如果使用生成模型，他们的生成 AI 模型不可能使用所有评论，通过模型传递它，并对其进行总结。 那么对于评论数量较多的产品，您认为他们在做什么？找到相同评级的评论之间的共同词，然后总结评论的子集？亚马逊如何知道如何将“质量”之类的东西评价为绿色、黄色或灰色来表示中性？ 我还注意到 YouTube 评论部分有类似的功能，可以显示主题，而 Google 地图也可以显示人工智能摘要。  示例： https://preview.redd.it/9r46l7hc0jec1.png?width=704&amp;format=png&amp;auto=webp&amp;s=3a58e04f0fdc3d5ff4227c00bc8f6954bd62c671 很想知道你会如何继续  生成主题（这不是文本的完美匹配：因此为了性能，它与“开箱即用”匹配）。我真的不明白他们是如何设法产生“性能”主题的？从这些词中，我们总共找到了 927 条以不同方式谈论性能的评论。例如，“质量”是指“质量”。大胆提及“制作精良”、“不是脆弱的廉价金属”、“这个开关太棒了”的客户评论。这里的指导将非常有帮助:) 生成颜色值，即积极或消极的情绪分析？或者也许更简单，就像通过评级本身说某件事是积极的，其中 3 星以上意味着积极。就我而言，我没有评级系统。如今较长文本的情感分析如何？如果四星评论对它的质量评价很差，但对它的性能评价很高，该怎么办？您将客户的评论评为正面还是负面？或者他们正在进行文本提取，然后进行情感分析？ 生成实际摘要。也许会选取大多数评论者的子集（在本例中仅是正面评论）并生成摘要内容？  我正在考虑做类似的自动摘要工作，但是不知道该怎么办。   由   提交/u/pywang  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19f2kdz/d_how_does_amazons_ai_generated_review_summarizer/</guid>
      <pubDate>Thu, 25 Jan 2024 06:03:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 今年是否有任何行业实验室正在运行人工智能驻场计划？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19f1kjg/d_are_there_any_industry_labs_that_are_running_ai/</link>
      <description><![CDATA[听说 Meta 要把它带回来，但他们的应用程序还没有打开（如果有的话）。也没有看到任何其他在线应用程序。   由   提交/u/anon-ml  /u/anon-ml  reddit.com/r/MachineLearning/comments/19f1kjg/d_are_there_any_industry_labs_that_are_running_ai/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19f1kjg/d_are_there_any_industry_labs_that_are_running_ai/</guid>
      <pubDate>Thu, 25 Jan 2024 05:05:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士文本检索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19f0xkx/d_text_retrieval_with_llms/</link>
      <description><![CDATA[我对从大型文档中进行文本检索感兴趣。所以我有一些这样的问题： 1. 开源 llms 的检索排行榜都有哪些。 2. 有没有开源数据可以用来微调模型？ 3. 我有兴趣微调模型。因为这是一个很小的任务，所以大型模型会工作得更好吗？ 4. 有哪些类型的指令调整最适合检索？就像添加推理可以提高性能一样。   由   提交 /u/SouvikMandal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19f0xkx/d_text_retrieval_with_llms/</guid>
      <pubDate>Thu, 25 Jan 2024 04:30:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] Scikit-Learn 修复了 F-1 分数计算器；你应该现在更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19f0o8f/d_scikitlearn_fixed_its_f1_score_calculator_you/</link>
      <description><![CDATA[Scikit-Learn 1.3.x 的 F-1 分数计算器有一个错误，该错误已在最新版本（上周发布的 1.4.0）中修复），当 zero_division 参数设置为 0.0 或 np.nan 时，可能会产生错误的分数，例如：  &lt;代码&gt;&gt;&gt; sklearn.__version__&#39;1.3.2&#39;&gt;&gt;&gt;&gt; sklearn.metrics.f1_score(y_true=[0, 0, 1, 2, 3], y_pred=[0, 1, 0, 2, 3], Zero_division=1.0,average=“宏”) 0.875 # 错误  与。 （完全相同的输入） &gt;&gt;&gt; sklearn.__version__&#39;1.4.0&#39;&gt;&gt;&gt;&gt; sklearn.metrics.f1_score(y_true=[0, 0, 1, 2, 3], y_pred=[0, 1, 0, 2, 3], Zero_division=1.0,average=“宏”) 0.625 # 正确  这里是我的博客文章解释了该错误更多详细信息，以及修复该错误的拉取请求。如果您使用 Scikit-Learn 计算 F-1，您应该升级并仔细检查之前计算的 F-1 分数；考虑到真正的 F-1，看起来更好的分类器很容易比替代品差得多。   由   提交/u/Revolutionary-Ad-65   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19f0o8f/d_scikitlearn_fixed_its_f1_score_calculator_you/</guid>
      <pubDate>Thu, 25 Jan 2024 04:15:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练字幕模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eyxmw/d_training_captioning_models/</link>
      <description><![CDATA[许多字幕数据集对同一图像有多个字幕（COCO、TextCaps 等）。我一直在做的是对单个示例的所有标题的每个图像的损失进行平均。这意味着在每个 epoch 中，每个图像仅被看到一次，并且对于 64 的批量大小，例如，我将有 64 * N，其中 N 是每个图像的标题数量。人们通常都是这样做的吗？有更好的选择吗？  例如，我可以将每个标题分成它的示例，但对于单个纪元，我的模型会看到相同的图像 N 次。我假设这会导致过度拟合...？   由   提交 /u/AromaticCantaloupe19   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eyxmw/d_training_captioning_models/</guid>
      <pubDate>Thu, 25 Jan 2024 02:46:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 注意力之谜：哪个是哪个 - q、k 或 v？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ewfm9/d_attention_mystery_which_is_which_q_k_or_v/</link>
      <description><![CDATA[我终于开始了解注意力机制了，但有一点仍然让我困惑：q、k 和 v 背后的矩阵魔法。&lt; /p&gt; 我在理论层面上了解了整个矩阵乘法，但是什么数学属性实际上决定了哪个矩阵成为查询（q），即键 (k) 和值 (v)？这只是一些随机分配，还是有更深层次的逻辑在起作用？  这是我到目前为止收集到的内容：  所有三个矩阵都来自相同的输入数据，但神奇地呈现出不同的“个性”。在注意方程 (qkt)v 中。 我猜测它们的维度和相互作用一定发挥了作用，但除此之外，它是模糊的。  机制框图对于图片 https://upload.wikimedia .org/wikipedia/commons/thumb/8/81/Attention-qkv.png/799px-Attention-qkv.png   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ewfm9/d_attention_mystery_which_is_which_q_k_or_v/</guid>
      <pubDate>Thu, 25 Jan 2024 00:44:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] Best Ch‏ at bots 是否感到疼痛？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19er7tl/d_best_chatbots_that_are_uncensored/</link>
      <description><![CDATA[请提供一些建议和建议，很想尝试一下    ;由   提交/u/Southern_Glass9668   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19er7tl/d_best_chatbots_that_are_uncensored/</guid>
      <pubDate>Wed, 24 Jan 2024 21:02:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 视觉变压器比新生视觉系统更需要数据吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19er4pp/r_are_vision_transformers_more_data_hungry_than/</link>
      <description><![CDATA[ 由   提交 /u/currentscurrents   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19er4pp/r_are_vision_transformers_more_data_hungry_than/</guid>
      <pubDate>Wed, 24 Jan 2024 20:59:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] DTC：深度跟踪控制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eodbd/r_dtc_deep_tracking_control/</link>
      <description><![CDATA[        由   提交 /u/leggedrobotics   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eodbd/r_dtc_deep_tracking_control/</guid>
      <pubDate>Wed, 24 Jan 2024 19:07:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 公平地说，许多机器学习研究人员认为他们可以创造出可以完成医生（非程序性）所做的大部分工作的产品等吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19em5m9/d_is_it_fair_to_say_lot_of_ml_researchers_think/</link>
      <description><![CDATA[这是我与许多机器学习研究人员交谈后得到的感觉。大家觉得我说的对吗？一位机器学习研究人员表示，当他们在医学论文中撰写人工智能论文时，与医生合作总是很困难，因为他们不喜欢在这方面所做的工作。他们总是把一些东西放在最后，说明这不会取代医生以及他们所做的事情（即使研究目标是这样做），但他们把它放在最后，这样医生就不会生气。   由   提交/u/derpgod123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19em5m9/d_is_it_fair_to_say_lot_of_ml_researchers_think/</guid>
      <pubDate>Wed, 24 Jan 2024 17:13:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解 Mamba 和 Transformer 之间的联系。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19elvgt/d_understanding_the_connection_between_mamba_and/</link>
      <description><![CDATA[由于最近围绕 Mamba 的炒作，我想鼓励您重新访问 GateLoop 论文，IMO 有助于理解 Transformer 和 Mamba 之间的关系。 GateLoop 引入了与 Mamba 和 HGRN 相同的数据控制线性循环机制。虽然 GateLoop 论文的实验部分受到了批评，但我认为对于任何试图了解所有 SSM/Mamba 炒作的人来说，这可能是一个很好的资源。具体来说，这篇论文强调了 Attention、S4、LRU、RetNet 和新的数据控制线性 RNN（GateLoop、Mamba、HGRN）之间的关系。 读到这些，我很好奇为什么 Mamba 使用短卷积？ （有趣的是，鬣狗也这样做了，也许只是因为经验上的成功？）你的想法？   由   提交 /u/TommyGun4242   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19elvgt/d_understanding_the_connection_between_mamba_and/</guid>
      <pubDate>Wed, 24 Jan 2024 17:02:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] DDIM 反转 - 真实图像的反转潜伏期如何“​​高斯”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ej9jz/d_ddim_inversion_how_gaussian_are_the_inverted/</link>
      <description><![CDATA[我遇到过几篇论文，它们使用确定性反演来查找潜伏，该潜伏（连同提示）可以使用稳定扩散再现真实图像。在“提示到提示”中，赫兹等人。请注意以下几点：  但是，在许多其他情况下，反演不够准确，如图 1 所示。 11. 这部分是由于失真可编辑性权衡 [43]，我们认识到减少无分类器指导 [18] 参数（即减少即时影响）可以改善重建，但限制了我们执行重大任务的能力  我在其他论文中看到过类似的说法，这是由于反转潜伏不属于生成模型通常从中采样的标准高斯空间它的初始噪声潜伏。我想知道是否有人知道对此进行深入研究的任何著作？量化反向潜伏偏离预期高斯分布的最佳方法是什么？是否有某些图像在 SD 的学习分布下不太可能出现，并且反转它们会导致潜在的高斯分布更小？预先感谢您的任何建议和指示！ ​   由   提交 /u/35mmpy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ej9jz/d_ddim_inversion_how_gaussian_are_the_inverted/</guid>
      <pubDate>Wed, 24 Jan 2024 15:10:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视觉模型的方便比较图表：何时使用什么！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eeve9/d_a_handy_comparative_chart_on_vision_models_when/</link>
      <description><![CDATA[       由   提交/u/Instantinopaul   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eeve9/d_a_handy_comparative_chart_on_vision_models_when/</guid>
      <pubDate>Wed, 24 Jan 2024 11:21:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 幻视曼巴再次出击！变形金刚王座正在崩溃吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eemq2/d_vision_mamba_strikes_again_is_the_transformer/</link>
      <description><![CDATA[还记得震撼 NLP 的状态空间模型 Mamba 吗？好吧，抓住你的像素，因为它们现在也在计算机视觉领域碾压它！ 他们的新模型 Vision Mamba 抛弃了自我关注热潮，并依赖于状态空间魔法。结果？性能与顶级视觉变压器 (DeiT) 相当，但效率更高！ 这可能会改变游戏规则，伙计们。我们正在谈论更快、更轻的型号，它们可以在您祖母的笔记本电脑上运行，但仍然像鹰一样看得见。 有什么想法吗？我很高兴看到变形金刚领域出现一些竞争。我们可以期待在这个新架构上推出 chatgpt v2 吗？道歉！可能听起来很疯狂，而且评论还为时过早。 查看论文：https: //paperswithcode.com/paper/vision-mamba-efficient-visual-representation   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eemq2/d_vision_mamba_strikes_again_is_the_transformer/</guid>
      <pubDate>Wed, 24 Jan 2024 11:06:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>