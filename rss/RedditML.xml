<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 04 May 2024 00:58:59 GMT</lastBuildDate>
    <item>
      <title>[D] 过度拟合稳定扩散是什么意思？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjknmo/d_what_does_it_mean_to_overfit_stable_diffusion/</link>
      <description><![CDATA[在扩散论文中，他们说他们的模型在训练和测试中的码长差距最多为每个维度 0.03 位，这表明 midel 不会过度拟合。但模型在扩散情况下过度拟合到底意味着什么呢？那么它是否只对训练集中的图像进行去噪？ 干杯！   由   提交/u/Error40404  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjknmo/d_what_does_it_mean_to_overfit_stable_diffusion/</guid>
      <pubDate>Fri, 03 May 2024 22:10:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] Flan-T5 用于合成数据生成？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjh0yd/p_flant5_for_synthetic_data_generation/</link>
      <description><![CDATA[大家好， 我正在尝试构建一个关于合成数据集生成的个人项目。一直在研究+为项目制定初始结构。 我的主要问题是FLAN-T5可以用于数据生成/海量文本生成吗？ 我不能似乎找到了人们将其用于该用例的示例。我也研究过混合指令模型。由于成本问题，我正在尝试避免使用 GPT4。 请告诉我任何其他可能对我的目的有利的 LM  &amp;# 32；由   提交/u/Theredeemer08  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjh0yd/p_flant5_for_synthetic_data_generation/</guid>
      <pubDate>Fri, 03 May 2024 19:21:04 GMT</pubDate>
    </item>
    <item>
      <title>[R][D] 用于提高 RNN 性能的时间序列量化（LLM 的可能用例）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjdxn7/rd_quantization_of_timeseries_for_improving/</link>
      <description><![CDATA[大家好， 想问一下你们中是否有人有使用量化/分级版本的功能集和/或设定目标以提高序列学习者解决时间序列问题的性能。 我对 NLP 不是很了解，因此对可能出现的任何错误表示歉意 设置-上： f(X) -&gt; ŷ 目标为 |ŷ-y| &lt; eps X 是一个特征集，其中的特征有望为 y 提供信息，信息频率不同，例如作为玩具示例，每个特征维度具有不同窗口的简单移动平均值。 X 和 y 很嘈杂 动机 我最近看到了一些修改单变量时间序列预测问题的工作，以便法学硕士可以理解它们，特别是：Chronos：学习时间序列的语言 一般方法是  缩放时间以某种方式系列，例如将每个序列除以平均绝对值 将这些值分类以使可能的值现在离散 添加开始/结束标记以便LLM可以消化，然后用于预测  万岁，现在我们有了一个可以传递到 LLM 的时间序列 RNN 的量化，而不是 LLM 退一步说，我想知道这里是否有人使用这些技术来使时间序列更适合 RNN，而不是使用上述转换来与 LLM 一起使用。变换的两个重要部分是（1）缩放技术和（2）箱数N。无穷大，我们得到与原始时间序列相同的精度。 量化作为函数 Q(.) 可以应用于 X、y 或两者。我想到的好处：  使用整数作为容器的引用，以实现更快/更轻松的交易 减少信号中的噪声 使用特征嵌入的可能性？  希望这一点很清楚。感谢任何帮助。   由   提交 /u/HungryhungryUgolino   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjdxn7/rd_quantization_of_timeseries_for_improving/</guid>
      <pubDate>Fri, 03 May 2024 17:10:48 GMT</pubDate>
    </item>
    <item>
      <title>[N] 科技行业陷入“激烈竞争” 人工智能工程师报告称，他们精疲力竭，产品推出仓促</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjdmr5/n_ai_engineers_report_burnout_and_rushed_rollouts/</link>
      <description><![CDATA[人工智能工程师将职业倦怠和仓促推出视为保持竞争力的“老鼠赛跑”打击了科技行业 文章摘要：   顶级科技公司的人工智能工程师告诉 CNBC，以极快的速度推出人工智能工具的压力已经决定了他们的工作。 他们表示，他们的大部分工作都是为了安抚投资者，而不是为最终用户解决问题，而且他们经常追逐 OpenAI。 倦怠是一个越来越普遍的主题，因为人工智能工作者表示，他们的雇主在开展项目时没有考虑到该技术对气候变化、监视和其他潜在现实世界危害的影响。 倦怠是一个越来越普遍的主题。 em&gt;  这篇文章中引用了一段特别深刻的话：  一位在零售监控初创公司工作的人工智能工程师告诉 CNBC，他是他是一家 40 人公司中唯一的 AI 工程师，负责处理与 AI 相关的任何职责，这是一项艰巨的任务。他表示，该公司的投资者对人工智能的能力有不准确的看法，经常要求他构建某些“我无法交付”的东西。    由   提交/u/bregav  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjdmr5/n_ai_engineers_report_burnout_and_rushed_rollouts/</guid>
      <pubDate>Fri, 03 May 2024 16:58:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人物设计软件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjb4da/d_software_to_design_figures/</link>
      <description><![CDATA[       我想为 rl 算法创建图表/图形。我真的很喜欢 Deep Mind 论文中使用的风格（AlphaZero、AlphaTensor、MuZero，...）。有谁知道这些图片是用什么软件做的吗？或者也许还有其他可以达到类似结果的东西？ https://preview.redd.it/4uohkcbxg8yc1.png?width=791&amp;format=png&amp;auto=webp&amp;s=9136bd12eb797523a5ff73f2b0b02e811239d9c3 https://preview.redd.it/1vzin9izg8yc1.png?width=578&amp;format=png&amp; auto=webp&amp;s=8046e1196347365b48ad2d3920ee0ba18119600c   由   提交 /u/_Hardric   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjb4da/d_software_to_design_figures/</guid>
      <pubDate>Fri, 03 May 2024 15:13:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何训练文本检测模型来检测 +180 到 -180 度的方向（旋转）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cja2s8/d_how_to_train_a_text_detection_model_that_will/</link>
      <description><![CDATA[大多数模型似乎都能够检测旋转的物体，但它们使用所谓的 le90 约定，其中物体从 +90 度旋转到 -90 度。在我的例子中，我想以正确的方向检测图像上的文本，这意味着在我的例子中 0 度和 180 度是不同的（在 MMOCR、MMDET 和 MMRotate 模型中就是这种情况）。 &lt; p&gt;你能指导我解决这个问题吗？我该如何处理这个问题？您有解决这个问题的一些开源项目的链接吗？ 我知道通常可以通过训练另一个小模型或通过训练所有可能的旋转的识别阶段来解决文本方向问题，但我想在检测阶段尽早解决这个问题。任何想法将不胜感激。提前致谢。   由   提交 /u/tmargary   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cja2s8/d_how_to_train_a_text_detection_model_that_will/</guid>
      <pubDate>Fri, 03 May 2024 14:29:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] HGRN2：具有状态扩展的门控线性 RNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj4ouc/r_hgrn2_gated_linear_rnns_with_state_expansion/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.07904 代码：https://github .com/OpenNLPLab/HGRN2 独立代码 (1):  https://github.com/Doraemonzzz/hgru2-pytorch 独立代码 (2): https://github.com/sustcsonglin/flash-linear-attention/tree/main/fla/models/hgrn2 摘要：  分层门控线性 RNN（HGRN，Qin 等人，2023 ）在语言建模方面展示了有竞争力的训练速度和性能，同时提供了高效的推理。然而，HGRN 的循环状态大小仍然相对较小，这限制了其表达能力。为了解决这个问题，受线性注意力的启发，我们引入了一种简单的基于外积的状态扩展机制，以便可以在不引入任何额外参数的情况下显着扩大循环状态大小。线性注意力形式还允许进行硬件高效的训练。我们大量的实验验证了 HGRN2 在语言建模、图像分类和 Long Range Arena 方面相对于 HGRN1 的优势。我们最大的 3B HGRN2 模型在受控实验设置中的语言建模方面略优于 Mamba 和 LLaMa Architecture Transformer；并且在下游评估中与许多开源 3B 模型竞争，同时使用更少的总训练令牌。    [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj4ouc/r_hgrn2_gated_linear_rnns_with_state_expansion/</guid>
      <pubDate>Fri, 03 May 2024 09:47:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于 Transformer 的语言模型内部工作原理入门</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj4o70/r_a_primer_on_the_inner_workings_of/</link>
      <description><![CDATA[      作者：Javier Ferrando (UPC)、Gabriele Sarti (RUG)、Arianna Bisazza （RUG），Marta Costa-jussà（元） 论文： https://arxiv .org/abs/2405.00208 摘要：  旨在解释高级语言内部运作方式的研究迅速进展模型强调需要将从该领域多年的工作中获得的见解结合起来。本入门书对用于解释基于 Transformer 的语言模型的内部工作原理的当前技术进行了简明的技术介绍，重点关注仅生成解码器的架构。最后，我们对这些模型实现的已知内部机制进行了全面概述，揭示了该领域流行方法和活跃研究方向之间的联系。  https://preview.redd.it/57y44wwdn6yc1.png?width=1486&amp;format= png&amp;汽车=webp&amp;s=7b7fb38a59f3819ce0d601140b1e031b98c17183   由   提交 /u/SubstantialDig6663   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj4o70/r_a_primer_on_the_inner_workings_of/</guid>
      <pubDate>Fri, 03 May 2024 09:46:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对特定领域数据微调 Phi-3 模型 - 寻求建议和见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj2hzb/d_finetune_phi3_model_for_domain_specific_data/</link>
      <description><![CDATA[      嗨， 我目前正在工作微调金融数据的 Phi-3 模型。虽然训练过程中损失不断减少，表明模型学习得很好，但自定义基准测试的结果却出人意料地差。事实上，与基础模型相比，准确性有所下降。 我观察到的结果：  Phi-3-mini-4k-instruct（基础模型）：平均域准确度为 40% Qlora - Phi-3-mini-4k-instruct（微调模型）：平均域准确度为 35%  我有尝试了各种方法，包括 QLora、Lora 和 FFT，但与基本模型相比，所有结果都很差。而且，我还尝试过将序列长度减少到2k，试图约束模型，防止模型偏离轨道，但不幸的是，这并没有带来任何改善。 我想知道超参数是否可能存在问题（例如学习率），或者是否有任何关于如何有效调整此模型以在特定领域数据上获得更好性能的建议。 如果有人有成功地根据特定领域的数据微调 Phi-3 模型，我将非常感谢您可以分享的任何见解或建议。预先感谢您的帮助和支持！  qlora 配置： ​ sequence_len: 4000 Sample_packing: true pad_to_sequence_len: true trust_remote_code: True 适配器：qlora lora_r: 256 lora_alpha ：512 lora_dropout：0.05 lora_target_linear：true lora_target_modules：-q_proj - v_proj - k_proj - o_proj - gateway_proj - down_proj - up_proj 梯度累积步骤：1 micro_batch_size：2 num_epochs：4 优化器：adamw_torch lr_scheduler：余弦学习率：0 .00002 Warmup_steps：100 evals_per_epoch：4 eval_table_size： saves_per_epoch：1 调试：deepspeed：weight_decay：0.0  https://preview.redd.it/7afyhxcjv5yc1.png?width=976&amp;format=png&amp;auto=webp&amp;s=1ce3efe6df6e4533bad5ec2f23e4f4968736 bd56 ​ ;   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj2hzb/d_finetune_phi3_model_for_domain_specific_data/</guid>
      <pubDate>Fri, 03 May 2024 07:10:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 迭代推理偏好优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciyps2/r_iterative_reasoning_preference_optimization/</link>
      <description><![CDATA[ 由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciyps2/r_iterative_reasoning_preference_optimization/</guid>
      <pubDate>Fri, 03 May 2024 03:20:19 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 我应该去ICML发表论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</link>
      <description><![CDATA[我完成了博士学位。一年前。离开学术界，成为一家科技公司的数据科学家。我喜欢它，但仍在考虑将来以某种方式转向更多的研究职位。不过不确定。 无论如何，我的一个未完成的作品被一个朋友选中，完成并申请到 ICML。它被接受了（耶！）。 我现在想知道 - 除了我发现会议很有趣之外，参加会议是否有真正的好处？提交论文？我知道对于学术界/研究人员来说，这是一个很好的机会来了解人们并了解当前的研究。但由于我不再在那里，有真正的理由去吗？ 这是一个很奇怪的问题，但我只是不确定，我很高兴听到你的想法。  &gt;   由   提交 /u/meni_s   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</guid>
      <pubDate>Thu, 02 May 2024 21:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]寻求帮助以找到更好的GPU设置。三台 H100 与五台 A100？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</link>
      <description><![CDATA[长话短说，一家公司有预算购买用于微调 LLM 的 GPU（可能是 70B），我必须研究哪种 GPU 设置最适合他们的预算。 预算可以购买 三个 H100 GPU 或 五个 A100 GPU。 我尽了最大努力，但直到现在我还不清楚哪种设置更好。虽然五个 A100 有更多的 VRAM，但他们说 H100 比 A100 快 2-8 倍！ 我正在寻求帮助。任何有价值的见解都将不胜感激。    提交人    /u/nlpbaz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</guid>
      <pubDate>Thu, 02 May 2024 19:49:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于 ICML、NeurIPS、CVPR 等顶级会议，我一直在思考的事情。有多少论文是真正具有开创性的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</link>
      <description><![CDATA[我自己也有一些位于金星顶端的论文，但每当我坐下来对自己残酷地诚实时。我觉得我的作品不错，但影响力不大，就像墙上又多了一块砖。我想知道我们多久能看到像“注意力就是你所需要的一切”这样有影响力的东西。例如。   由   提交 /u/oddhvdfscuyg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</guid>
      <pubDate>Thu, 02 May 2024 18:37:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大三学生（本科生或一二年级博士生）在ICML、ICLR、NeurIPS等主要机器学习会议上有这么多论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</link>
      <description><![CDATA[大家好，今天ICML成绩出来了，恭喜所有在这里接受论文的同学。我自己不是学者，但有时我会为了工作而阅读这些会议上的论文，这真的很有趣。我只是有一个问题：为什么这些会议上大三的论文这么多？我认为这是你在 5 年博士学位期间必须学习的东西，而且几乎只能在博士学位的最后几年才能实现。另外，我听说要进入美国顶尖的博士项目，你需要事先写一些论文。那么，如果一个大三学生能这么早发表论文，为什么还要花5年时间攻读博士学位呢？   由   提交 /u/ShiftStrange1701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</guid>
      <pubDate>Thu, 02 May 2024 11:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>