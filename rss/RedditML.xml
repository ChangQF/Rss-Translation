<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Mon, 03 Mar 2025 12:34:47 GMT</lastBuildDate>
    <item>
      <title>[r] CVPR拒绝2次接受，一个弱拒绝</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2g6vv/r_cvpr_reject_with_2_accepts_and_one_weak_reject/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我在几天前关于CVPR提交的帖子中对此进行了轻微讨论，但是我只是想提出更多意见。我有一张拒绝的纸张，最终得分为5（4）/5（3）/2（3）。决定取决于ACS，但我真的觉得拒绝的理由确实很轻。例如，我对为什么我的方法与方法X不同的讨论还不够（AC说这些方法的确有所不同，但他们说我的解释方式尚不清楚），但是很难在一页中解释一下，在一页中，您必须在其中进行许多其他评论。另外，他们说，我的方法可能并不能真正改善我正在评估的任务，但是我的结果没有重叠的错误栏，有5个不同的基线，这就是为什么我接受了两个接受。对接受的信心是4和3，而弱势拒绝是3。我通常不会抱怨，我们都会遭到拒绝，但是两个接受的拒绝？那你为什么还会得到审稿人呢？我在2023年获得了CVPR，它比目前的论文弱。我觉得这是随机性的一部分，但是在这种情况下……我无法避免觉得有问题。 有些人说我应该用PC提高它，但我真的不确定。我肯定会准备我的ICCV提交。您有什么意见？谢谢：）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/elpelana     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j2g6vv/r_cvpr_rejection_with_2_accept_2_accepts_and_and_and_one_weak_reject_reject_reject/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2g6vv/r_cvpr_reject_with_2_accepts_and_one_weak_reject/</guid>
      <pubDate>Mon, 03 Mar 2025 11:01:13 GMT</pubDate>
    </item>
    <item>
      <title>[d]特征重要性共识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2g6og/d_feature_importance_consensus/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在努力在多个机器学习模型中建立特征重要性的共识，包括脊，拉索和弹性净回归（使用其系数作为重要性的衡量）以及随机的森林和XGBOOST。在将特征的重要性归一化之后，我观察到这些模型的特征重要性之间的Pearson相关性大多较弱。鉴于此，建立特征重要性的共识仍然有意义吗？我应该只专注于具有低标准偏差的功能以确保一致性吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;  /u/limmick   [link] ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2g6og/d_feature_importance_consensus/</guid>
      <pubDate>Mon, 03 Mar 2025 11:00:52 GMT</pubDate>
    </item>
    <item>
      <title>[d]欧盟版权培训数据（商业用途）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2g5yq/d_copyrighted_training_data_in_eu_commercial_use/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好学习机器的朋友， 我目前正在考虑在欧盟（尤其是德国）开设Genai Art-Up。我们目前看到的最大障碍是关于版权的情况，特别是关于使用受版权保护的图像作为培训数据。我尝试在线研究，并得到了一些想法，但是法律局势对我来说远远不明显。从我获得的培训过程和推论本身的情况下，数据集的制作中的受版权保护材料的重复是有问题的。 是否有人在这里有一些第一手经验来处理法规？我看到有一段有关文本和数据挖掘的段落，通常用于使用刮擦数据来证明是合理的。 如果某人在其他欧盟国家/地区有税收条件或启动帮助的其他欧盟国家有热门提示，我将非常欢迎一些建议。 ，感谢人们！提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j2g5yq/d_copyrighted_training_training_data_eu_eu_cormermocial_use/  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j2g5yq/d_copyrighted_training_data_in_eu_eu_commermotient_euse_use/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2g5yq/d_copyrighted_training_data_in_eu_commercial_use/</guid>
      <pubDate>Mon, 03 Mar 2025 10:59:46 GMT</pubDate>
    </item>
    <item>
      <title>[R]在CVPR上接受了一篇论文，我应该将其放在Arvix中吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2epr9/r_had_a_paper_accepted_at_cvpr_should_i_put_it_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好，所以我的第一篇论文在CVPR上接受。显然，该论文将由计算机视觉基金会在6月1日左右提供。 SI我想知道是否应该将其放在Arvix中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/training-Adeptness57     [links]       &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j2epr9/r_had_a_a papper_accepted_at_accepted_at_cvpr_should_i_i_i_ipput_it_it_it_it_in/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2epr9/r_had_a_paper_accepted_at_cvpr_should_i_put_it_in/</guid>
      <pubDate>Mon, 03 Mar 2025 09:14:15 GMT</pubDate>
    </item>
    <item>
      <title>[d]开源模型的未知培训分布将如何影响企业的微调过程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2cslw/d_how_will_the_unknown_training_distribution_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， ，我很想知道您对我们不知道某些开源模型的培训分布这一事实的看法。如果我们将来会这样进行，那么公司将上传他们的模型而不是培训的数据，这将如何影响企业？ 我的想法是，这也是“风险”。为了使组织使用这些权重，因为生产可能会有幻觉。或者，应该进行超级广泛的评估框架，以便100％确定生产中没有错。 您怎么看？  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ml_nerdd     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2cslw/d_how_will_the_unknown_training_distribution_of/</guid>
      <pubDate>Mon, 03 Mar 2025 06:52:25 GMT</pubDate>
    </item>
    <item>
      <title>[d]机器学习工程师角色与ML核心的应用科学家角色之间有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j21zmk/d_what_is_the_difference_between_machine_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     他们的责任的一般差异是什么？ 未来的阶梯？ 付费？    我发现这里有几个类似的问题在这里4-5岁。从那以后发生了很多事情（蓬勃发展的公司，然后是大规模裁员，Chatgpt Boom等），我想再次要求这一点以了解当前的行业环境。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/madgradstudent99    href =“ https://www.reddit.com/r/machinelearning/comments/1j21zmk/d_what_is_is_the_the_difference_between_machine_learning/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j21zmk/d_what_is_the_difference_between_machine_learning/</guid>
      <pubDate>Sun, 02 Mar 2025 21:28:57 GMT</pubDate>
    </item>
    <item>
      <title>[d] 3+方式的对比风格损失</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j213rp/d_contrastive_style_losses_for_3_modalities/</link>
      <description><![CDATA[在（例如，图像捕获对），批处理中的其他所有内容通常被视为负面。我正在使用3种以上的方式，因此“正面”是“正面”。实际上是一个积极的三胞胎/四倍/等。就我而言。我可以使用什么损失？目前，我正在计算成对的损失，并平均它们。 （例如，对于3种模态，a，b，c是每种模态 - ＆gt;（损失（a，b） +损失（a，c） +损失（b，c）） / 3的阳性三胞胎。有更好的方法吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dudester_el   href =“ https://www.reddit.com/r/machinelearning/comments/1j213rp/d_contrastive_style_style_losses_for_3_modalities/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j213rp/d_contrastive_style_losses_for_3_modalities/</guid>
      <pubDate>Sun, 02 Mar 2025 20:51:40 GMT</pubDate>
    </item>
    <item>
      <title>[P]为AI代理制作了工具：可以通过编程控制的Dockerized VS代码 +鹅代码代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1xs2q/p_made_a_tool_for_ai_agents_dockerized_vs_code/</link>
      <description><![CDATA[   /u/u/thribcardiogids656     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j1xs2q/p_made_a_a_tool_ai_ai_ai_ai_aigents_dockerized_vserized_vs_code/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1xs2q/p_made_a_tool_for_ai_agents_dockerized_vs_code/</guid>
      <pubDate>Sun, 02 Mar 2025 18:33:44 GMT</pubDate>
    </item>
    <item>
      <title>[p]我制作了体重 - 一种简单的方法，可以在一分钟内训练任何嵌入模型的适配器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1udcu/p_i_made_weightgain_an_easy_way_to_train_an/</link>
      <description><![CDATA[   /u/u/jsonathan       [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1udcu/p_i_made_weightgain_an_easy_way_to_train_an/</guid>
      <pubDate>Sun, 02 Mar 2025 16:13:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] Camie Tagger -70,527动漫标签分类器在单个RTX 3060上训练，F1得分为61％</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1u0j7/p_camie_tagger_70527_anime_tag_classifier_trained/</link>
      <description><![CDATA[       &lt;！ -  sc_off- sc_off-&gt;  3个月后，我终于完成了我的Anime Image tag dan dan dan dan dan dan dan dan dan dan achie dan achie dan achie face dan achie face dan achie face dan achie face blogbove 61％F1，数据集。该项目表明，强大的多标签分类模型可以通过正确的优化技术在消费硬件上进行培训。  关键技术细节：   在单个RTX 3060（12GB VRAM）上使用Microsoft Deepspeed for Cross firts for for Cross for for Cross-li&gt;               （214m参数）和精制模型（424m参数）。 阶段之间仅0.2％F1得分差异（61.4％vs 61.6％）。 在3.5个时期内对2m图像进行了培训（7m总样本）（7m总样本）。分类器可预测来自EfficityNet V2-L特征的标签。然后，通过对TAG共发生模式进行建模，跨注意机制可以完善预测。这种方法表明，预测标签之间的建模关系可以提高准确性而无需实质上增加计算间接费用。  内存优化：在消费者硬件上训练该模型，我使用：   零阶段2，用于优化        li&gt; li&gt; li&gt; li&gt; li&gt;   微型批量的大小为4，有效批次大小为32     标签分布：该模型涵盖7个类别：一般（30,841个标签），角色（26,968），版权所有（5,364），Artist（7,007,007），Meta（33） （20）。  类别特定的F1分数：   艺术家：48.8％（7,007 tags） 字符：73.9％（73.9％（26,968 tags） （30,841个标签） 元：60％（323个标签） 评分：81.0％（4个标签） 年：33％（20 tags）      接口：      有趣的发现：许多“误报”实际上是Danbooru数据集本身缺少正确的标签，表明该模型的现实世界性能可能比基准指示的要好。 我特别令人印象深刻，它在艺术家标签上的表现非常好，因为它们在预测所需的功能方面非常抽象。字符标记也令人印象深刻，因为示例图像显示图像在维持纵横比的同时将图像全部调整到512x512的情况下，图像中的多个（8个字符）。 我还发现，我还发现该模型仍然对现实图像也很好。也许可以通过在另一个数据集上微调模型，以更真实的示例来完成类似的事情。  拥抱面孔。还有一个用户友好的推理应用程序。随时提出问题！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/camais     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/comments/1j1u0j7/p_camie_tagger_70527_anime_anime_tag_classifier_train/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1u0j7/p_camie_tagger_70527_anime_tag_classifier_trained/</guid>
      <pubDate>Sun, 02 Mar 2025 15:58:03 GMT</pubDate>
    </item>
    <item>
      <title>[r]思想的扩散：扩散语言模型中的经过思考推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1oe6n/r_diffusion_of_thoughts_chainofthought_reasoning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   最近，由于与常规自动回归模型相比，由于它们的许多潜在优势，扩散模型对文本处理领域引起了重大兴趣。在这项工作中，我们提出了一种思想扩散（DOT），这是一种新颖的方法，将扩散模型与经过思考链集成在一起，这是一种提高自回归语言模型的推理能力的完善技术。与以左右的逐态方式做出决策的自回旋语言模型相反，DOT允许推理步骤通过扩散语言模型随时间扩散，并为推理性能提供更大的灵活性。我们的实验结果表明，DOT在多位数乘法，布尔逻辑和小学数学问题中的有效性，而小型扩散模型在效率和准确性方面的表现都超过了更大的自回归模型。除此之外，DOT还展示了有希望的自我纠正能力，并通过现有推理增强技术（例如自洽解码）的好处。我们的发现有助于通过扩散语言模型对推理的理解和发展。  不是最近的论文，但我想看看每个人对扩散语言模型的看法是制作推理LLM的手段。我觉得在尝试使用变压器进行推理时有一个巨大的问题，并且可能是不可能的（在这里个人意见）。每个人的想法是什么？提交由＆＃32; /u/hiskuu     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1oe6n/r_diffusion_of_thoughts_chainofthought_reasoning/</guid>
      <pubDate>Sun, 02 Mar 2025 10:58:06 GMT</pubDate>
    </item>
    <item>
      <title>[r] unitok：通过多编码本矢量量化统一视觉生成和理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1l0xo/r_unitok_unifying_visual_generation_and/</link>
      <description><![CDATA[Just checked out the new UniTok paper that introduces a unified visual tokenizer capable of handling both generation and understanding tasks within a single framework. The key innovation here is a joint training approach that combines: - Reconstruction objectives (for generation capabilities) - Recognition objectives (for understanding功能） 这使一个单一的代币化系统能够有效地实现双重目的，而不会损害任何任务类型的性能。 主要技术点： - 基于变压器的编码器 - 编码器架构，具有专门的训练方法 - 与偶然性损失相结合 - 可构成噪声的差异 - 与差异的差异 - 与差异相结合 - 精细的视觉细节 - 在Imagenet，Coco和其他基准测试中实现最新的结果 - 与使用单独的专业象征器 相比，我认为这种统一方法可以显着减少需要产生和理解能力的视觉AI系统中的计算范围。拥有一个有效的系统并没有维护和运行多个专业的代币器，而是为现实部署创造实际的优势。绩效的改进表明，我们可能会看到这种方法在未来的多模式系统中成为标准。 我对这可能会影响效率至关重要的移动/边缘应用特别感兴趣 - 拥有一个可以很好地处理这两个任务的单个标记器可以使您可以在资源限制的设备上更加易于访问。与使用单独的引导剂相比，训练方法，实现SOTA结果，同时提高效率40％。  完整摘要” Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1l0xo/r_unitok_unifying_visual_generation_and/</guid>
      <pubDate>Sun, 02 Mar 2025 07:00:04 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1hc0o/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Mar 2025 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[R]有效LLM的窗户注意力训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1ckye/r_sliding_window_attention_training_for_efficient/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     https：//arxiv.org/abs/2502.18845 Mamba，Titans和Transformers ++。在结论中跳跃：  ，通过用sigmoid替换软杀剂，将平衡的alebi替换为SWAT并将其结合在一起，SWAT解决了注意力下沉问题，并确保稳定的培训并确保稳定的培训。这么多的“曼巴发生了什么”帖子，我仍在等待基于泰坦的模型的发布，因此，尽管我不知道我们是否会使用特警，但我还是赞赏该论文作为对扩展 - 封闭式/替代架构世界中当前的调查。   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1ckye/r_sliding_window_attention_trainention_training_for_for_effficity/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1ckye/r_sliding_window_attention_training_for_efficient/</guid>
      <pubDate>Sat, 01 Mar 2025 23:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些经验丰富的人。   &lt;！ -  sc_on--&gt; 32;&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>