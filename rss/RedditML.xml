<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 14 Feb 2024 18:16:52 GMT</lastBuildDate>
    <item>
      <title>[D] 对具有重复测量组件的模型的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqtjzf/d_recommendations_for_a_model_with_repeated/</link>
      <description><![CDATA[我是 Reddit 新手，对编码也相对较新（&lt;1.5 年）。如果这不属于这里，我深表歉意。 我开始在我的研究中使用机器学习。到目前为止，我已经能够使用随机森林（我知道这是一个简单的机器学习模型）来预测感兴趣的变量。由于训练数据是从同一动物记录的测量结果，因此我需要重复测量方法。我们能够将重复测量纳入 P Calhoun (2021) 编写的随机森林适应函数中。 问题是，如果存在 NaN 值，重复测量随机森林就无法工作。作为我们工作的一部分，一些动物必须在不同时间从实验中移除。他们没有返回实验。下面是一个简化了我所讨论内容的表格： ​   动物 出现在测试 1 中 出现在测试 2 出现在测试 3    1 Y Y Y   2 Y Y N   3 Y N N   所以，一些动物将拥有全部 180 天的数据，而有些动物只会拥有 120 天、80 天、60 天等的数据。这会产生大量 NaN 值。我们使用 MissForest R 包来估算缺失的气候变量，但由于显而易见的原因，估算 100 多天的动物数据是荒谬的。 我们收集动物数据，直到将它们从实验中删除为止。收集这些动物数据非常昂贵（并且是劳动密集型），并且由于农业研究的性质，小 n 尺寸始终是一个问题。我们确实希望使用来自所有动物的所有数据来训练预测模型。 我正在寻找 ML 模型的建议，这些模型具有一些可以使用数据类型的重复测量分析组件（某些记录比其他记录有更多的观察结果）。任何建议都非常受欢迎！谢谢！   由   提交 /u/Technical-Trip9933    reddit.com/r/MachineLearning/comments/1aqtjzf/d_recommendations_for_a_model_with_repeated/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqtjzf/d_recommendations_for_a_model_with_repeated/</guid>
      <pubDate>Wed, 14 Feb 2024 18:12:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 气候科学领域的机器学习是否已经饱和？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqrqsg/d_is_ml_in_climate_science_saturated/</link>
      <description><![CDATA[作为标题。 现在的差距是多少？ &lt;!-- SC_ON - -&gt;  由   提交 /u/plsendfast   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqrqsg/d_is_ml_in_climate_science_saturated/</guid>
      <pubDate>Wed, 14 Feb 2024 16:59:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 带描述的类的文本分类方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqqaag/p_d_text_classification_methods_for_classes_with/</link>
      <description><![CDATA[我正在开发一个个人项目，我正在使用的类有很多细微差别。仅仅使用 Huggingface 的现成模型很诱人，但准确性肯定会受到影响。 我正在考虑写几行描述这些类，其中涵盖了它们的细微差别特征。是否有使用这些描述对数据进行分类的分类方法？ 如果需要，我愿意使用法学硕士。我的首要任务是准确性，但不幸的是我没有很多标记数据（可能有 200 个样本左右）。   由   提交 /u/Mission-Language8789   /u/Mission-Language8789 reddit.com/r/MachineLearning/comments/1aqqaag/p_d_text_classification_methods_for_classes_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqqaag/p_d_text_classification_methods_for_classes_with/</guid>
      <pubDate>Wed, 14 Feb 2024 15:59:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我组装了一个 pytorch 调试器，重点是最小的代码更改和用于捕获无声错误的工具，例如可能导致您损失的 NaN 的错误。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqoy7t/p_i_put_together_a_pytorch_debugger_with_an/</link>
      <description><![CDATA[      https://github.com/ethansmith2000/epic-pytorch-debugger  开始这是非常非常WIP，但即使在当前状态，它在获取方面也非常有用有关异常中涉及的张量的详细报告，捕获 NaN 或其他奇数值，并跟踪非 pytorch 变量。 最好的部分是，它所需要的只是在函数上放置一个装饰器。 这里有一些示例 https://preview.redd.it/31m5jp34ijic1.png?width=1626&amp;format=png&amp;auto=webp&amp;s=5b3d64e32e2d5fda7f9f1db4ffec039c5db21db7 ​ &lt; p&gt;https://preview.redd.it/973909g1ijic1。 png?width=1148&amp;format=png&amp;auto=webp&amp;s=7ad349b861d4e5863c478ee6e39e272040adc647 我将其开源，希望其他人可以从中受益，并减少调试时间，特别是对于通常需要大量时间才能单独完成的大规模工作。  而且，我希望它可以成为一个公共项目，供任何愿意贡献的人使用。对于初学者来说，这是我在尝试弄清楚如何在实例化变量名称时跟踪变量名称时对 python 进行的最深入的了解，并且我确信我在其他一些事情上做得很差。  如果您碰巧发现任何错误（在调试器中，哈哈）或有任何反馈，欢迎大家！ ​    由   提交/u/ethansmith2000   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqoy7t/p_i_put_together_a_pytorch_debugger_with_an/</guid>
      <pubDate>Wed, 14 Feb 2024 15:03:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 阅读和学习研究论文的最佳方式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</link>
      <description><![CDATA[当我们尝试专注于玉兰油的创新产品时，我们必须学习许多现代科技知识。但通常需要时间才能获得博客和教程上的可用资源。  因此，直接从第一个主要来源学习是有效的学习方式，因为它是主要来源。 但是，我发现阅读论文非常困难，因为它包含许多术语或内容不寻常的措辞。此外，跟踪和掌握一篇大论文的上下文也需要很大的耐心。 你们能分享一下你们的方法吗？你们如何有效且高效地从已发表的论文中学习并获得见解？   由   提交 /u/FardinRock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</guid>
      <pubDate>Wed, 14 Feb 2024 14:28:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 手语识别 (SLR)：它到底有多好？我可以让它适用于不太流行的手语吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqlp23/p_sign_language_recognition_slr_how_good_is_it/</link>
      <description><![CDATA[我看过很多初学者教程来实现基于视频流的手语识别，但它们在现实世界中似乎都存在一些问题（比如说新闻发布会的电视录音）。一位客户问我们是否可以这样做，所以我开始想：  目前单反的状态如何？真的吗？它是否已在实践中使用？ 是否有现有的模型甚至服务可以直接使用？ 这些是否存在或可以用于不太流行的手语方言？ 这些是否存在或可以用于不太流行的手语方言？ li&gt;    由   提交 /u/Enum1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqlp23/p_sign_language_recognition_slr_how_good_is_it/</guid>
      <pubDate>Wed, 14 Feb 2024 12:26:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 RingAttention 实现百万长度视频和语言的世界模型 - 加州大学伯克利分校 2024 - 能够以近乎完美的精度描述一个多小时长的视频（包含超过 500 个剪辑）中的一个剪辑！ - 是开源的！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqjrc8/r_world_model_on_millionlength_video_and_language/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.08268  Github：https://github。 com/LargeWorldModel/LWM  模型： https://huggingface.com/LargeWorldModel/LWM co/LargeWorldModel ！ 摘要：  当前的语言模型在理解世界的各个方面方面存在不足很容易用语言描述，并且难以完成复杂、冗长的任务。 视频序列提供了语言和静态图像中所缺少的有价值的时间信息，这使得它们对于与语言的联合建模很有吸引力。这些模型可以发展对人类文本知识和物理世界的理解，从而实现更广泛的人工智能能力来帮助人类。然而，由于内存限制、计算复杂性和有限的数据集，从数百万个视频和语言序列的标记中学习提出了挑战。为了应对这些挑战，我们整理了一个包含不同视频和书籍的大型数据集，利用 RingAttention 技术对长序列进行可扩展训练，并逐渐将上下文大小从4K 增加到 1M 令牌。本文做出以下贡献：（a）最大上下文大小神经网络：我们在长视频和语言序列上训练最大上下文大小变换器之一，在困难的检索任务和长视频理解中树立了新的基准。 (b) 克服视觉语言训练挑战的解决方案，包括使用掩码序列打包来混合不同的序列长度、使用损失权重来平衡语言和视觉，以及用于长序列聊天的模型生成的 QA 数据集。 (c) 高度优化的实现，具有 RingAttention、掩码序列打包和其他关键功能，用于在数百万长度的多模态序列上进行训练。 (d) 完全开源一系列 7B 参数模型，能够处理超过 100 万代币的长文本文档（LWM-Text、LWM-Text-Chat）和视频（LWM、LWM-Chat） 。这项工作为长视频和语言的海量数据集的训练铺平了道路，以发展对人类知识和多模态世界的理解以及更广泛的能力。   &lt; a href=&quot;https://preview.redd.it/89xpv0ix1jic1.jpg?width=1177&amp;format=pjpg&amp;auto=webp&amp;s=b37224a61459c3b04ed01004b10342e1f2d9bd19&quot;&gt;https://preview.redd.it/89xpv0ix1jic1.jpg?width =1177&amp;format=pjpg&amp;auto=webp&amp;s=b37224a61459c3b04ed01004b10342e1f2d9bd19 https://preview.redd.it/mlhtz2ix1jic1.jpg?width=1488&amp;format=pjpg&amp;auto=webp&amp;s=b1bba31b6868fd230b454565e6 686ef0847dc0c2 https://preview.redd.it/ma51c4ix1jic1.jpg ?width=1022&amp;format=pjpg&amp;auto=webp&amp;s=7bce52c12b3ecf683e507582f0dd68ec53a68dac https://preview.redd.it/bc0kz4ix1jic1.jpg?width=670&amp;format=pjpg&amp;auto=webp&amp;s=e541c8f9c0db600e00ef8135a75 5ae0eadc33320   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqjrc8/r_world_model_on_millionlength_video_and_language/</guid>
      <pubDate>Wed, 14 Feb 2024 10:26:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过计算机视觉让我的书架可点击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</link>
      <description><![CDATA[      我构建了一个系统，可以让你拍摄书架的照片并创建一个交互式 HTML 网页，您可以在其中单击图像中的书籍来了解有关每本书的更多信息。 该项目的技术堆栈是：  用于检索的接地 SAM书籍的多边形。 OpenCV + 监督转换，为 OCR 准备书籍。 GPT-4 和 Vision for OCR Google Books API，用于获取书籍元数据。  生成 HTML + SVG 以创建最终网页。  我在博客上写了如何构建这个项目。 尝试演示。 我希望获得有关如何提高图书检测率以获得更好性能的反馈。在书脊上训练自定义分割模型可能会起作用，但我知道为此可能需要多少数据。 下面的红色多边形表示在演示中可点击的分段书籍：  p&gt; https://preview.redd.it /p9w4rgsn1jic1.png?width=1260&amp;format=png&amp;auto=webp&amp;s=35116c7eb9d1f5dab2b11375be9e2ff0e7163b78   由   提交/u/zerojames_  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</guid>
      <pubDate>Wed, 14 Feb 2024 10:21:46 GMT</pubDate>
    </item>
    <item>
      <title>寻找同一簇中的点彼此靠近的低暗子空间 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqj2i0/finding_a_lowdim_subspace_where_points_in_the/</link>
      <description><![CDATA[我有一个由一些数据点簇组成的嵌入数据集（我先验选择了哪些点属于同一簇）。目前，属于同一簇的点在嵌入空间中不一定彼此靠近。我想找到一个低维子空间，这样如果我将这些嵌入投影到该子空间上，属于同一簇的点将彼此接近。在低暗空间中，不同的簇不一定需要相距很远。我想到了一个使用 SVD 和 k 均值成本函数来解决的优化问题，但不确定是否能真正解决它。很好奇其他人是否有想法/想法！   由   提交 /u/oomydoomy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqj2i0/finding_a_lowdim_subspace_where_points_in_the/</guid>
      <pubDate>Wed, 14 Feb 2024 09:37:21 GMT</pubDate>
    </item>
    <item>
      <title>纸质复制品[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqiw8m/paper_reproduction_d/</link>
      <description><![CDATA[您好，我是一名毕业的计算机科学工程师，我拥有扎实的 ML 背景。我的毕业项目是 NLP 中的对抗性机器学习研究。但自从毕业以来，我没有从事任何与机器学习相关的主题，所以我有点忘记了很多东西，我想复制一篇论文来刷新我的记忆，并获得更多的实践工作，因为我想做一些包含在其中的事情我的简历也是如此。我的问题是，复制一篇论文现在对我来说是正确的选择吗？如果是这样，那么我可以从什么论文开始（我对 ML 中的任何东西都持开放态度，无论是 CV、NLP、多模态、生成模型等，只要我能获得更多的知识和经验，任何事情对我来说都很好）。如果没有，那么您对我应该做什么有什么建议？   由   提交/u/Ineffable-1  /u/Ineffable-1  reddit.com/r/MachineLearning/comments/1aqiw8m/paper_reproduction_d/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqiw8m/paper_reproduction_d/</guid>
      <pubDate>Wed, 14 Feb 2024 09:24:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最佳 RNN 深度学习视频/文章/帖子？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqidg6/d_best_rnns_deep_dive_videoarticlepost/</link>
      <description><![CDATA[我正在学习 RNN，到目前为止我遇到的每一篇文章和视频都遗漏了一些细节，没有人详细解释所有内容。我更喜欢阅读或观看材料，其中作者不使用现成的 RNN 函数编写代码，而是像 Andrej Karpathy 一样详细解释所有内容。 （我读了 Karpathy 关于 RNN 的博文，但是没有太多与 RNN 相关的代码，并且文章主要是关于 LSTM 的）    由   提交/u/your_dream724  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqidg6/d_best_rnns_deep_dive_videoarticlepost/</guid>
      <pubDate>Wed, 14 Feb 2024 08:45:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一个看起来像机器学习问题的问题。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqewye/d_a_problem_that_seems_like_a_ml_problem/</link>
      <description><![CDATA[      你好。  我工作的系统是高度参数化的，即具有大量参数（二进制值或整数范围）。这些参数不是独立的。尽管许多可能的组合无效，但它们仍然会产生大量可能的配置。  现在，手头的任务是找到该参数化系统的最佳配置，该配置将根据输入设置最大化可直接测量的指标。同样，输入空间非常大。  这似乎是一个经典的机器学习问题，但似乎更像是一个模拟类型的问题，在给定一个拥有无限资源的理想世界中，我将针对相关输入设置运行所有系统配置并找到最大化我的相关指标的设置。在“测试时间”，我将利用手中的这些信息以最佳设置运行系统。  这个问题的设置听起来是否接近任何现有的深入研究领域？谢谢。  PS - 我很神秘，因为我无法透露具体的系统。 https://preview.redd.it/frgvz33wghic1.png?width=1292&amp;format=png&amp;auto=webp&amp;s= 5ea8d9720e185d0cb7de3fc3c29a5593f342c5d4    由   提交 /u/Traditional_Two7396   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqewye/d_a_problem_that_seems_like_a_ml_problem/</guid>
      <pubDate>Wed, 14 Feb 2024 05:04:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 跨上下文长度的基准检索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqd24k/d_benchmarking_retrieval_across_context_lengths/</link>
      <description><![CDATA[以下针对 GPT 4 的“大海捞针”测试在今年早些时候广为流传，显示前 64k 代币的检索率为 100%： https://github.com/gkamradt/LLMTest_NeedleInAHaystack 这是否被视为有效测试机器学习专家中？如果它有效，那么它是否已在其他地方复制过？如果有效的话，这似乎不太可能是测试的唯一公开实现。 如果无效，可能是什么方法？ 最后，总共有多少令牌您个人认为 GPT 4 能记住上下文吗？   由   提交/u/Ok_Elephant_1806   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqd24k/d_benchmarking_retrieval_across_context_lengths/</guid>
      <pubDate>Wed, 14 Feb 2024 03:26:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] [P] 通过贝叶斯优化将 LLM 评估速度提高 10 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apv97t/r_p_10_times_faster_llm_evaluation_with_bayesian/</link>
      <description><![CDATA[最近我一直致力于通过使用贝叶斯优化来选择合理的子集来快速进行 LLM 评估。 贝叶斯优化是使用它是因为它有利于探索/利用昂贵的黑匣子（释义，LLM）。 项目链接&lt; /p&gt; 我很想听听您对此的想法和建议！   由   提交 /u/b06901038g   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apv97t/r_p_10_times_faster_llm_evaluation_with_bayesian/</guid>
      <pubDate>Tue, 13 Feb 2024 14:51:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>