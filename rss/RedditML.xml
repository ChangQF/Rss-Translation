<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Tue, 11 Feb 2025 01:15:06 GMT</lastBuildDate>
    <item>
      <title>[P]将Mhubert模型追溯到JIT</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imkdnf/p_tracing_mhubert_model_into_a_jit/</link>
      <description><![CDATA[在言语的令牌。我沿途偶然发现了一些意外的事情，以及关于Faiss聚集库的一些知识。我决定将其包裹在帖子中。巴拉肯/姆伯伯特“&gt; https://huggingface.co/balacoon/mhubert    您可以在博客文章中了解更多信息： https://balacoon.com/blog/mhubert_tracing/ （包含对跟踪的引用＆amp; testing Notebook）  hubert或wav2vec的离散令牌是常用的作为多模式LLM的音频输入。希望您可以找到这个方便的  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/clementruhm     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imkdnf/p_tracing_mhubert_model_into_a_jit/</guid>
      <pubDate>Mon, 10 Feb 2025 23:24:55 GMT</pubDate>
    </item>
    <item>
      <title>[研究]排名：用于检索，重新排行的全面基准测试工具包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imie69/research_rankify_a_comprehensive_benchmarking/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好！ 👋 我们刚刚发布排名，开源Python框架  基准测试和排名模型  NLP，搜索引擎和LLM驱动的应用程序！ 🚀 🔹什么是排名？  一个统一的框架  - 支持 bm25，dpr，ance，ance，colbert，contriever ，，和20多个重新排行模型。 内置数据集＆amp;预先计算索引  - 不再有手动索引！包括 Wikipedia＆amp; MS MARCO. 🔸 Seamless RAG Integration – Works with GPT, T5, LLaMA for retrieval-augmented generation (RAG)。 可重复性＆amp;评估  - 标准化检索＆amp;公平模型比较的排名指标。 🔬为什么重要？   评估检索模型不一致  -  rankify 解决此问题使用结构化的，易于使用的工具包。  sota模型需要昂贵的索引  -  rankify 预先计算的嵌入式＆amp;数据集用于易于基准测试。 重新排列工作流是零散的  -  rankify 统一检索，排名＆amp;一个软件包中的抹布。  纸：  arxiv：2502.02464    github：  rankify repo    很想听到您的想法 - 您目前如何基准检索和排名模型？让我们讨论！ 🚀  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strical_pomelo_636      [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imie69/research_rankify_a_comprehensive_benchmarking/</guid>
      <pubDate>Mon, 10 Feb 2025 21:59:36 GMT</pubDate>
    </item>
    <item>
      <title>[d]预测对LLM中RL的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imhxzh/d_pretrainings_effect_on_rl_in_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有人知道任何研究表明各种训练预算和RL计算预算之间的动态和相互作用以及对最终模型智能的影响？例如修复RL预算，各种预估计的模型尺寸如何响应RL？我的直觉是会有一些指数曲线，但是我认为我没有看到任何图表。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/h2o3n4     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imhxzh/d_pretrainings_effect_on_rl_in_llms/</guid>
      <pubDate>Mon, 10 Feb 2025 21:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[r]扩展讲习班论文作品时的常见做法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imaq6g/r_common_practice_when_extending_a_workshop/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我过去接受了一张纸上的纸张。现在，我基本上有同一篇论文（问题陈述等），但是我提出了另一种损失，基本上使我获得了我在研讨会上可以获得的一切，但是工作更好，更好地工作 - 让我申请除了MNIST（这是我的工作室论文）外，其他数据集和数据类型（例如3D）的方法（例如3D）。 我想尽快将其提交给会议。我应该怎么办？创建具有不同标题的Arxiv中的新预印？还是简单地使用此版本更新预印？研讨会论文已经发表。 我有疑问，因为很好，整体构造与以前相同。发生了变化的是一些至关重要的数学，以及额外的实验和更好的结果。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/howtoreWriteAname     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imaq6g/r_common_practice_when_extending_a_workshop/</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:32 GMT</pubDate>
    </item>
    <item>
      <title>[d] SAR卫星图像上的图形场景生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imaarw/d_graph_scene_generation_on_sar_satellite_images/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您知道有任何有关此主题的模型和数据集的论文吗？  卫星图像上有很多用于对象检测的技术，例如： https ：//github.com/satellite-image-deep-learning/techniques   我特别对多光谱数据集感到好奇。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/kubehe     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imaarw/d_graph_scene_generation_on_sar_satellite_images/</guid>
      <pubDate>Mon, 10 Feb 2025 16:35:01 GMT</pubDate>
    </item>
    <item>
      <title>[d] KL分歧是LLM训练后RL的主要奖励？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1im7bsb/d_kl_divergence_as_a_primary_reward_in_llm/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  说我们预算了一个LLM。如果我们使用预处理的LLM生成一个序列，则不会完全获得具有最佳KL差异的序列，该序列与验证的LLM相关。这就是为什么Beam搜索以前是一件事情的原因。那么，如果我们执行RL纯kl差异是奖励模型怎么办？最终的模型将是一个模型，该模型将生成比预读的LLM的总体KL差异要低得多的序列。会发生什么？该模型会“更连贯”？ 我想听听每个人对此的想法，因为这似乎是一个思想实验，似乎会导致一个琐碎的答案，但是序列的kl差异是一个目标实际上，如果没有非线性优化（RL），这实际上很难解决。是的，我们直接知道令牌概率，但是很难知道该序列的累积概率是“更喜欢”的模型。感觉就像是一个不对称的优化问题（易于评估，但难以解决），我想知道是否有任何有意义的东西会出现。 我的实现想法就是使用GRPO进行RL。但是你们怎么看？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ricecake1539     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1im7bsb/d_kl_divergence_as_a_primary_reward_in_llm/</guid>
      <pubDate>Mon, 10 Feb 2025 14:27:55 GMT</pubDate>
    </item>
    <item>
      <title>深度学习博士学位的笔记本电脑[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1im44wy/laptop_for_deep_learning_phd_d/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我有2,000英镑，我需要在三月之前在笔记本电脑上使用（否则我损失了资金）我在应用数学上的博士学位，涉及大量的深度学习。我所做的大部分可能都会在云上，但是看到我有这个预算，我不妨在我需要离线运行一些事情时获得最好的笔记本电脑。 我可以得到一些建议购买什么？我不想获得Mac，但对所有选项都感到困惑。我知道刚刚发布了新的GPU（NVIDIA 5000系列），并且已经使用Lunar Lake / Snapdragon CPU宣布了新的笔记本电脑。&lt; / p&gt; 我不确定我是否应该旨在用不错的GPU获得一些东西或者只需像Lenove Carbon X1一样获取一本薄/轻的超书。 感谢您的帮助！  **编辑： 我可以访问HPC通过我的大学，但在使用之前，我宁愿确保我的项目在我将自己或MNIST，CFAR等创建的玩具数据集上工作，因此，在推理之上，这意味着我可能会在笔记本电脑上进行一些轻训练（这也可以在云TBH上）。因此，问题是我要使用一个GPU，它会排干电池并增加散装或变得苗条。 我一直使用Windows，因为我不喜欢软件，所以它没有&#39; T确实是一个问题。尽管我从未因为担心错误而更新到Windows11。 我有一台桌面PC，几年前使用RX 5600 XT构建，我认为这几天已经过时了。但这意味着我已经拥有一台台式PC，所以我不会停靠笔记本电脑。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bloch2001     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1im44wy/laptop_for_deep_learning_phd_d/</guid>
      <pubDate>Mon, 10 Feb 2025 11:37:51 GMT</pubDate>
    </item>
    <item>
      <title>[R]使用潜在扩散变压器进行未校准的图像集的多视图场景完成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1im2al0/r_multiview_scene_completion_using_latent/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项工作提出了一种基于变压器的方法，用于在多视图场景中捕获丢失区域，同时保持几何一致性。关键创新是通过两个阶段的过程来处理不受约束的休闲照片，该过程在产生缺失区域之前首先分析跨视图的可见内容。 关键的技术方面： - 多头注意的注意机制同时多次观点 - 新颖的一致性 - 新型一致性损失确保生成的内容跨不同角度对齐 - 直接与稀疏，非结构化的照片集一起使用 - 处理室内和室外场景 - 在消费者GPU硬件 结果上运行： - 视觉质量指标与先前的30％提高：方法 - 在不同的捕获密度之间的性能一致 - 对复杂几何结构的鲁棒处理 - 对典型场景大小的实时推断 我认为这可能会严重影响3D内容创建的几个领域。使用休闲照片的能力消除了房地产，虚拟旅游和建筑可视化应用程序的主要障碍。跨视图的一致性对于VR/AR用例尤其重要。 我看到的主要限制是降级性能，输入非常稀疏，这通常是带有休闲照片集的现实。还可以改善处理反射表面和复杂的几何形状。  tldr：新的基于变形金刚的方法在多视图中使用常规照片在多视场景中完成缺失区域，同时跨视点保持一致性。比以前的方法显示出30％的视觉质量。摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1im2al0/r_multiview_scene_completion_using_latent/</guid>
      <pubDate>Mon, 10 Feb 2025 09:30:43 GMT</pubDate>
    </item>
    <item>
      <title>[d]神经2025的位置纸轨道会有一个位置纸轨道吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1im1j39/d_will_there_be_a_position_paper_track_at_neurips/</link>
      <description><![CDATA[在&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/skeeringReal     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1im1j39/d_will_there_there_be_a_position_paper_paper_track_atap_ate_neurips/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1im1j39/d_will_there_be_a_position_paper_track_at_neurips/</guid>
      <pubDate>Mon, 10 Feb 2025 08:32:54 GMT</pubDate>
    </item>
    <item>
      <title>[p]邀请合作者获得可区分的几何损失函数库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilzqdb/p_inviting_collaborators_for_a_differentiable/</link>
      <description><![CDATA[在一个用于在pytorch中创建可区分几何损失函数库的项目。 我在这里放置了一些初始提交的项目，以了解可能的外观： github repo        &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/atharvaaalok1     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilzqdb/p_inviting_collaborators_for_a_differentiable/</guid>
      <pubDate>Mon, 10 Feb 2025 06:22:02 GMT</pubDate>
    </item>
    <item>
      <title>[R]您的AI看不到大猩猩：LLMS执行探索性数据分析能力的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iljqve/r_your_ai_cant_see_gorillas_a_comparison_of_llms/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/jsonathan     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iljqve/r_your_ai_ai_ai_cant_see_gorillas_a_comparison_comparison_of_of_lls/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iljqve/r_your_ai_cant_see_gorillas_a_comparison_of_llms/</guid>
      <pubDate>Sun, 09 Feb 2025 17:18:41 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[r]豪华轿车：少更多用于推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ile9nu/r_limo_less_is_more_for_reasoning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我们提出了一个基本发现，挑战了我们对大语言模型中复杂推理如何出现的理解。尽管传统的观点表明，复杂的推理任务需要广泛的培训数据（通常是100,000个例子），但我们证明了一个惊人的现象：复杂的数学推理能力可以有效地引起，而令人惊讶的例子很少。这一发现不仅挑战了大量数据要求的假设，而且挑战了监督微调的共同信念主要导致记忆而不是概括。通过全面的实验，我们提出的模型豪华轿车证明了数学推理的前所未有的性能和效率。仅使用817个精选的训练样品，豪华轿车在高度挑战性的AIME基准上实现了57.1％的准确性，而数学的精度为94.8％，在AIME上将以前的强SFT型号从6.5％提高到57.1％，从59.2％，从59.2％提高到94.8％数学，而仅使用以前方法所需的培训数据的1％。最引人注目的是，豪华轿车表现出异常的分布概括，在10种不同的基准测试中实现了40.5％的绝对改进，优于对100倍培训的模型，直接挑战了SFT固有地导致记忆而不是概括的普遍观念。综合这些开创性的结果，我们提出了较少的推理假设（豪华假设）：在基础模型中，在预训练期间已经对领域知识进行了全面编码，可以通过最小但精确的跨越认知过程的证明来出现。该假设认为，复杂推理的启发阈值并非固有地受到目标推理任务的复杂性的限制，而是从根本上由两个关键因素确定：（1）模型在训练期间的编码知识基础的完整性，以及（2 ）训练后示例的有效性，这些示例是“认知模板”，该模型显示了该模型如何有效利用其现有知识库来解决复杂的推理任务。   arxiv链接： [2502.03387]豪华轿车：更少用于推理    &lt;！ -  sc_on- sc_on-&gt;&gt;＆＃32;提交由＆＃32; /u/hiskuu     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ile9nu/r_limo_less_is_more_for_reasoning/</guid>
      <pubDate>Sun, 09 Feb 2025 13:04:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] AI设计的蛋白质中和致命的蛇毒</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1il78ti/r_aidesigned_proteins_neutralize_lethal_snake/</link>
      <description><![CDATA[在/www.nature.com/articles/s41586-024-08393-x    研究人员使用alphafold 2（AF2）和rfdiffusion（开源模型）来设计与并将结合并将（理论上）中和眼镜蛇毒素中和细胞毒素。他们还选择水溶性蛋白，以便可以作为抗蛇毒药物递送。在人皮细胞（角质形成细胞）和小鼠中测试候选蛋白。在实验室条件和浓度中，在模拟咬合后15-30分钟治疗小鼠。 我已经看了一堆生物 + ml纸，从未将其视为应用  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/prototypist     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1il78ti/r_aidesigned_proteins_neutralize_lethal_snake/</guid>
      <pubDate>Sun, 09 Feb 2025 05:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      对于那些寻找工作的人请使用此模板  &lt; p&gt;想要被录用：[位置]，薪水期望：[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简短概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，这个社区是适合有经验的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>