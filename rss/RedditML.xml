<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 08 Sep 2024 09:15:26 GMT</lastBuildDate>
    <item>
      <title>[R] 用于语言生成和检索的 Masked Mixer</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbnos7/r_masked_mixers_for_language_generation_and/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbnos7/r_masked_mixers_for_language_generation_and/</guid>
      <pubDate>Sun, 08 Sep 2024 02:34:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 探究 Transformer 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbis9j/d_looking_through_transformer_models/</link>
      <description><![CDATA[我见过许多论文研究 CNN 中的卷积权重矩阵的统计数据，研究平均内核，绘制所有内核；我见过 Transformer 的类似物，尤其是绘制注意力矩阵，还有线性嵌入权重作为 ViT 的 RGB 内核等。甚至 MLP-Mixers 和 gMLP 也展示了权重的外观和选择方式。我现在正在寻找类似的研究，解决多头自注意力模块中的线性投影，这似乎被忽视了。是吗？我想了解它们对于 WQ 和 WK 是否相似，是否可以参数化它们的乘积，WV 或 WO 是否看起来像恒等，等等。最坏的情况是我自己看一看，但我缺乏数学洞察力     提交人    /u/Sad-Razzmatazz-5188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbis9j/d_looking_through_transformer_models/</guid>
      <pubDate>Sat, 07 Sep 2024 22:19:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] SpotDiffusion：一种快速生成无缝全景图的方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbgdm2/r_spotdiffusion_a_fast_approach_for_seamless/</link>
      <description><![CDATA[我们很高兴地宣布，我们的成果《SpotDiffusion：一种随时间推移生成无缝全景图的快速方法》已被 WACV 2025 接受！🎉 arXiv：https://arxiv.org/abs/2407.15507 TL;DR：在我们的论文中，我们介绍了一种使用扩散模型生成高分辨率全景图像的新方法《SpotDiffusion》。与以前的方法（例如 MultiDiffusion 和 SyncDiffusion）不同，SpotDiffusion 通过随时间推移移动不重叠的窗口来消除这种重叠。这些方法需要重叠预测并导致效率低下。这样可以确保以更少的计算步骤和更快的处理时间获得高质量、无缝的图像 - 非常适合文本到图像生成和高分辨率输出！ 感谢在整个旅程中支持我们的所有人！我们很高兴很快分享更多！😊    提交人    /u/Maleficent_Stay_7737   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbgdm2/r_spotdiffusion_a_fast_approach_for_seamless/</guid>
      <pubDate>Sat, 07 Sep 2024 20:27:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 文件分类建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbfr3a/d_document_classification_advice/</link>
      <description><![CDATA[大家好， 我正在做一个项目，需要一些指导来找到最佳解决方案。 目标是构建一个可以扫描财务文档并将其归类为多个类别之一的服务。为简单起见，我们假设有四个类别：销售发票、采购发票、收据和报价单。 我正在考虑两种不同的方法来解决这个问题，我很想听听你们的意见，看看哪种方法更有效，或者我是否应该考虑第三种选择。 方法 1：经典 ML 我正在考虑的一种方法是传统的机器学习方法。这将涉及：  OCR：从文档中提取文本。 ML 模型：训练分类器（例如 SVM、随机森林或神经网络）以根据提取的文本对文档进行分类。  但是，由于销售和采购发票等类别之间的文本差异很小，我还在考虑结合某种形式的计算机视觉。文档的布局可能会提供其他线索（例如页眉、页脚或表格结构）。 方法 2：生成式 AI（LLM + 多模态） 第二种选择涉及利用多模态大型语言模型 (LLM) 对文档进行分类。以下是我设想的工作原理：  在提示中，我将向 LLM 讲授类别之间的文本和视觉区别。 此外，我可以采用思想树或集成方法，使用同一文档查询多个 LLM（例如 5-10 个）并聚合它们的响应以获得更确定的最终结果。  开放式问题：  您会推荐哪种方法？ 是否有最适合文档分类的特定技术或框架，特别是对于这种类型的财务数据？ 对结合两种方法的元素的可行性有什么想法？  提前感谢任何建议！   由    /u/SEND_ME_YOUR_POTATOS  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbfr3a/d_document_classification_advice/</guid>
      <pubDate>Sat, 07 Sep 2024 19:59:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医疗 AI：顶级研究论文/模型🏅（2024 年 9 月 1 日至 9 月 7 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbe5qg/d_last_week_in_medical_ai_top_research/</link>
      <description><![CDATA[   本周热门论文（2024 年 9 月 1 日至 9 月 7 日） 医学 LLM 及其他模型：  CancerLLM：癌症领域的大型语言模型  CancerLLM，一个为癌症特定任务设计的 70 亿参数模型。对 17 种癌症类型的 267 万份临床记录和 515,524 份病理报告进行了预训练。   MedUnA：用于医学图像的视觉语言模型  本文介绍了医学无监督适应（MedUnA）。它使用 BioBERT 将文本嵌入与类标签对齐，然后与 MedCLIP 的视觉编码器集成，通过对比熵损失实现视觉文本对齐。  机器人内窥镜手术的基础模型  本文介绍了机器人内窥镜手术中的深度一切 (DARES)，它引入了 Vector-LoRA，一种用于机器人辅助手术 (RAS) 中自监督单目深度估计的新型自适应技术。  Med-MoE：用于医学视觉语言模型的 MoE  本文介绍了 Med-MoE（Mixture-of-Experts），这是一个专为判别和生成多模态医疗任务而设计的轻量级框架。 Med-MoE 分三个阶段运作：  CanvOI：肿瘤学基础模型  本文介绍了 CanvOI，一种基于 ViT-g/10 的数字病理学基础模型，针对肿瘤组织病理学图像进行了优化。   医疗基准和评估：  TrialBench：临床试验数据集和基准  用于医学问答评估的 LLM  MedFuzz：探索稳健性医学 LLM  MedS-Bench：评估临床任务中的 LLM  DiversityMedQA：评估诊断中的 LLM 偏见  LLM 数字孪生：  用于罕见妇科肿瘤的数字孪生 DT-GPT：用于患者健康预测的数字孪生  ....  详细查看完整线程：https://x.com/OpenlifesciAI/status/1832476252260712788 感谢您的阅读！如果您知道任何遗漏的有趣论文，请随时在评论中分享。如果您对医疗 AI 有见解或突破，并希望在下周的版本中分享，请通过 Twt/x 与我们联系：OpenlifesciAI    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbe5qg/d_last_week_in_medical_ai_top_research/</guid>
      <pubDate>Sat, 07 Sep 2024 18:49:25 GMT</pubDate>
    </item>
    <item>
      <title>我尝试编写自己的 YOLO 模型来检测足球运动员 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbc185/i_tried_to_code_my_own_yolo_model_to_detect/</link>
      <description><![CDATA[       由    /u/AvvYaa  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbc185/i_tried_to_code_my_own_yolo_model_to_detect/</guid>
      <pubDate>Sat, 07 Sep 2024 17:15:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 利用长距离深度学习对硬件加密进行广义功率攻击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbbbb3/r_generalized_power_attacks_against_hardware/</link>
      <description><![CDATA[      https://preview.redd.it/8x0oesms1fnd1.jpg?width=2000&amp;format=pjpg&amp;auto=webp&amp;s=3d3d331ddb4ebf23eface0d49b312b28cd5e2fcd 星期六快乐 我很高兴地宣布，经过 3 年的研发，我们终于发布了 GPAM，我们的通用模型电源侧信道攻击模型：  幻灯片&amp; 论文：https://elie.net/publication/generalized-power-attacks-against-crypto-hardware-using-long-range-deep-learning 代码 &amp;数据集：https://github.com/google/scaaml/tree/main/papers/datasets/ECC/GPAM  与以前的方法相比，GPAM 代表了一代人的飞跃，因为它能够攻击多种算法（AES、ECC）和对策，而无需人工干预并且无需预处理输入跟踪。它确实需要一些自动超调优，因此：每次攻击约 700 GPU/h。    提交人    /u/ebursztein   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbbbb3/r_generalized_power_attacks_against_hardware/</guid>
      <pubDate>Sat, 07 Sep 2024 16:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] Adam 优化器导致 Transformer 语言模型中出现特权基础</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbavdv/r_adam_optimizer_causes_privileged_basis_in/</link>
      <description><![CDATA[        由    /u/rrenaud  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbavdv/r_adam_optimizer_causes_privileged_basis_in/</guid>
      <pubDate>Sat, 07 Sep 2024 16:26:05 GMT</pubDate>
    </item>
    <item>
      <title>学习 ViT 中的局部表示“[D]”“[R]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fb9su4/learning_local_representations_in_vit_d_r/</link>
      <description><![CDATA[我正在阅读这篇题为“视觉变换器是否像卷积神经网络一样看待问题？”的论文，我有一个大问题。作者说，在较早的层中，注意力头会混合关注局部和全局，只有在对大型数据集（JFT）进行预训练时才会如此，而在小型数据集（ImageNet）上进行预训练时，它很难关注局部。我的问题是，为什么 ViT 很难关注在本地关注的自我补丁？    提交人    /u/Dapper-Edge2661   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fb9su4/learning_local_representations_in_vit_d_r/</guid>
      <pubDate>Sat, 07 Sep 2024 15:40:28 GMT</pubDate>
    </item>
    <item>
      <title>[P]⚡️最快的预训练代码：9天获得LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fb6fet/pfastest_pretraining_code_llm_in_9_days/</link>
      <description><![CDATA[我们仅用 9 天就创建了一个在 MT-Bench 上表现优于 OpenELM 和 Phi 的 LLM。它基于 Lightning 框架构建，并经过 TinyLlama 的优化，实现了超高吞吐量（GPU 利用率约 99.6%）。将其发布给所有人，如果您喜欢我们所做的，请给我们一个 star。 代码：https://github.com/pints-ai/1.5-Pints    提交人    /u/calvintwr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fb6fet/pfastest_pretraining_code_llm_in_9_days/</guid>
      <pubDate>Sat, 07 Sep 2024 13:02:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] NviWatch 是一款用于监控 Nvidia GPU 的 rust tui</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fb55rf/p_nviwatch_a_rust_tui_for_monitoring_nvidia_gpus/</link>
      <description><![CDATA[      想分享，因为这可以帮助您进行 GPU 监控。✅ 专注于 GPU 进程✅ 多种视图模式✅ 用 rust 编写的轻量级✅ 直接使用 NVML    提交人    /u/msminhas93   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fb55rf/p_nviwatch_a_rust_tui_for_monitoring_nvidia_gpus/</guid>
      <pubDate>Sat, 07 Sep 2024 11:53:24 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 学习更长序列的位置嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fb4zls/discussion_learned_positional_embeddings_for/</link>
      <description><![CDATA[因此，我重新阅读了 transformer 论文，让我印象深刻的一件事是作者还使用了学习到的位置嵌入。Karpathy 的 nanoGPT 实现使用了学习到的位置嵌入，我想知道这些嵌入如何扩展到更长的序列？ 从直觉上讲，如果模型从未见过超过 max_length 的标记，它将无法生成有意义的东西。那么 OpenAI 的 GPT（假设他们仍然使用学习到的 PE）如何扩展到超过 2k 的上下文长度？    提交人    /u/tororo-in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fb4zls/discussion_learned_positional_embeddings_for/</guid>
      <pubDate>Sat, 07 Sep 2024 11:43:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 评估大型语言模型在保护秘密/隐藏信息方面的有效性的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fb0ami/p_tool_for_assessing_the_effectiveness_of_large/</link>
      <description><![CDATA[https://github.com/user1342/Would-You-Kindly    由   提交  /u/OppositeMonday   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fb0ami/p_tool_for_assessing_the_effectiveness_of_large/</guid>
      <pubDate>Sat, 07 Sep 2024 06:03:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 01 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>