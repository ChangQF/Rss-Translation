<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 17 Nov 2024 03:30:32 GMT</lastBuildDate>
    <item>
      <title>[P] 使用开源模型增强结构化输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gt2yfp/p_supercharging_structured_outputs_with_open/</link>
      <description><![CDATA[  由    /u/themathstudent  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gt2yfp/p_supercharging_structured_outputs_with_open/</guid>
      <pubDate>Sun, 17 Nov 2024 01:57:03 GMT</pubDate>
    </item>
    <item>
      <title>数据集版本控制工具 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gt1avg/dataset_versioning_tool_d/</link>
      <description><![CDATA[你们使用什么来进行数据（集）版本控制？你们建议在小型（1000 x 700）表格中使用什么？    提交人    /u/Amazing_Alarm6130   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gt1avg/dataset_versioning_tool_d/</guid>
      <pubDate>Sun, 17 Nov 2024 00:31:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 全息驱动的新颖视图合成 - 文献综述。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gszzqz/r_holography_driven_novel_view_synthesis/</link>
      <description><![CDATA[全息图是通过在 2D 胶片上编码 3D 场景创建的。一旦有了它，就可以删除 3D 场景及其所有对象。 现在，当您从胶片的另一侧观看时，您会看到 3D 对象，就好像它们仍然在那里一样。您可以改变视角等，看起来就像您正在通过该胶片观看 3D 场景，但该 3D 场景并不存在；而是，该场景的光场已被编码到胶片上。 Grant Sanderson 在他的 3B1B 频道 ( r/3Blue1Brown ) 上发布的这个视频是一个非常出色的说明性指南 https://www.youtube.com/watch?v=EmKQsSDlaa4 这告诉我们，3D 场景的 2D 表示确实是可能的。我在这里发帖是为了询问：  有没有论文使用全息图公式进行新颖视图合成和 3D 重建？ 如果像场景全息图这样的 2D 表示对于新颖视图合成非常好，为什么我们还需要 Nerfs 和 Gaussian Splats？     提交人    /u/nefrpitou   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gszzqz/r_holography_driven_novel_view_synthesis/</guid>
      <pubDate>Sat, 16 Nov 2024 23:28:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] SwarmOne - 有谁和这家公司合作过</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gszjgy/d_swarmone_anyone_worked_with_this_company/</link>
      <description><![CDATA[嗨，我们的初创公司正在考虑将 SwarmOne 作为可行的 GPU 训练云提供商。我谦虚地向更大的 ML 社区寻求帮助，与可能听说过和/或与这家公司合作过的人联系，看看他们的想法是什么？ 我真的很想知道他们关于数据安全性的说法，以及他们如何声称原始数据不会离开你的机器 - 只有加密的张量会离开。对此有什么看法？它有多安全。 我很感激这些想法。    提交人    /u/zacky2004   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gszjgy/d_swarmone_anyone_worked_with_this_company/</guid>
      <pubDate>Sat, 16 Nov 2024 23:05:53 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] R^2 为负，但预测值和实际值之间的相关性具有统计意义？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsxror/discussion_r2_is_negative_but_the_correlation/</link>
      <description><![CDATA[      我做了一些挖掘，但没有真正找到这个问题的答案，所以如果有人知道可能出什么问题，请告诉我。我进行了一些样本外预测（3000 个观测值），在评估预测需求水平的模型时，我得到了非常奇怪的结果。使用的模型是 xgb 回归量。因此 R^2 指出该模型的表现比简单地预测目标变量的平均值更差，但同时实际值和预测值之间的相关性具有统计意义。此外，解释方差得分表明该模型比朴素模型更差，但 Theil 的 U 统计量却相反？代码和结果发布如下。认为未完成的值可能是问题所在，但我将它们剪裁为 0.05 和 0.95 分位数，但没有帮助。 https://preview.redd.it/10kpzdqs1c1e1.png?width=966&amp;format=png&amp;auto=webp&amp;s=9b93f0ef588e2fa5cb16c06f69c0fea1902e0931 https://preview.redd.it/t2rapmo22c1e1.png?width=855&amp;format=png&amp;auto=webp&amp;s=ce9d8d1d2ad54c8743873560bfff8a275a14378d    提交人    /u/maciek024   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsxror/discussion_r2_is_negative_but_the_correlation/</guid>
      <pubDate>Sat, 16 Nov 2024 21:41:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从输入输出对进行程序合成 - DL 论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gswhou/d_program_synthesis_from_inputoutput_pairs_dl/</link>
      <description><![CDATA[给定一组输入/输出，生成一个合适的程序 使用 DL 进行此程序合成的基线/规范论文是什么？ 谢谢    提交人    /u/yazriel0   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gswhou/d_program_synthesis_from_inputoutput_pairs_dl/</guid>
      <pubDate>Sat, 16 Nov 2024 20:41:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你的机器学习博士学位学习时长</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsue6g/d_your_ml_phd_duration/</link>
      <description><![CDATA[获得学士学位后，您需要多少年才能完成 ML 博士学位？据我所知，世界不同地区通常需要不同的时间。     提交人    /u/AntelopeWilling2928   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsue6g/d_your_ml_phd_duration/</guid>
      <pubDate>Sat, 16 Nov 2024 19:04:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] COLING 2025 结果泄露</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gssewj/d_coling_2025_results_are_leaked/</link>
      <description><![CDATA[你们可以登录 softconf 检查是否可以提交照相排版论文。 我的成绩是 4/3/3，幸运地被接受了。我的第一篇论文！！！    提交人    /u/Ambitious-Public-512   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gssewj/d_coling_2025_results_are_leaked/</guid>
      <pubDate>Sat, 16 Nov 2024 17:35:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 必读的 ML 理论论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsqqns/r_mustread_ml_theory_papers/</link>
      <description><![CDATA[您好， 我是一名计算机科学博士生，希望加深对机器学习理论的理解。我的研究领域专注于视觉语言模型，但我想通过阅读基础或开创性的机器学习理论论文来扩展我的知识。 您能否分享一份对机器学习理论产生重大影响的必读论文或个人推荐？ 提前谢谢您！    提交人    /u/AntelopeWilling2928   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsqqns/r_mustread_ml_theory_papers/</guid>
      <pubDate>Sat, 16 Nov 2024 16:19:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 扩散模型中的时间步长依赖性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gspx8g/d_time_step_dependency_in_diffusion_model/</link>
      <description><![CDATA[是否有任何现有工作尝试研究扩散模型的时间步骤之间的关系？类似于模型在时间步骤 i 的模型损失对模型在时间步骤 j 的输出的影响？（j&lt;i）    提交人    /u/Careless-Top-2411   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gspx8g/d_time_step_dependency_in_diffusion_model/</guid>
      <pubDate>Sat, 16 Nov 2024 15:42:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 分析 UMAP 为何如此之快</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsjfq9/p_analysis_of_why_umap_is_so_fast/</link>
      <description><![CDATA[      嗨，我最近花了一些时间从 UMAP 算法的实现方式以及它为什么如此之快的角度来了解 UMAP 算法的核心实现（即使它是用 Python 编写的）。我决定将算法分解为更小的步骤，在这些步骤中，我对代码进行一些小的改进（一个接一个），这样最终的结果与我从 UMAP 获得的结果非常相似。 令我惊讶的是，这些变化中的大多数只是优化代码中的技巧，以更快地运行程序或减少更新不太重要的东西的频率。当然，我的实现并没有 100% 地重现 UMAP 算法，因为它是在教育目的中完成的。 我在我的项目中提供了详细的解释，说明我必须在每个步骤中添加什么才能转向类似 UMAP 的算法。这是项目页面：https://github.com/kmkolasinski/nano-umap 如果您是一个喜欢优化代码以提高性能的人，您可能会发现这很有趣。下面是我能够得到的演示：  https://preview.redd.it/eww57c3x881e1.png?width=1921&amp;format=png&amp;auto=webp&amp;s=ed4a345e40b47782ddf39cb93eb9d03207db1160 TLDR：在 UMAP 中他们：  使用 ANN 库快速找到顶级 k-NN， 使用良好的初始化方法，使事情更稳定并且算法需要更少的更新（UMAP 使用快速谱初始化）， 使用随机负采样，这是一种简单的方法，但在实践中效果很好， 压缩 numba 性能（通过用自定义实现替换 np.dot 或 np.clip 来使代码运行得更快）， 使用某种自适应采样，这将使算法将更多时间花在更重要的向量上，从而节省不太重要的向量上的 CPU 时间     提交人    /u/kmkolasinski   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsjfq9/p_analysis_of_why_umap_is_so_fast/</guid>
      <pubDate>Sat, 16 Nov 2024 09:02:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 卷积可微分逻辑门网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gs92mb/r_convolutional_differentiable_logic_gate_networks/</link>
      <description><![CDATA[摘要 随着机器学习模型的推理成本不断增加，人们对具有快速高效推理能力​​的模型的兴趣日益浓厚。最近，提出了一种通过可微分松弛直接学习逻辑门网络的方法。逻辑门网络比传统的神经网络方法更快，因为它们的推理只需要逻辑门运算符（例如 NAND、OR 和 XOR），这些运算符是当前硬件的底层构建块，可以高效执行。我们在此想法的基础上，通过深度逻辑门树卷积、逻辑或池化和残差初始化对其进行了扩展。这允许将逻辑门网络扩大一个数量级以上并利用卷积范式。在 CIFAR-10 上，我们仅使用 6100 万个逻辑门就实现了 86.29% 的准确率，这比 SOTA 有所提高，同时体积却缩小了 29 倍。 被 Neurips 2024 接受，“SOTA”在这里表示可比方法。我发现这篇论文真的很有趣，尽管非玩具网络似乎训练起来非常昂贵。好奇其他人怎么想？    提交人    /u/jacobgorm   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gs92mb/r_convolutional_differentiable_logic_gate_networks/</guid>
      <pubDate>Fri, 15 Nov 2024 22:51:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 读博士还是不读博士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gs688q/d_to_phd_or_not_to_phd/</link>
      <description><![CDATA[我想这个问题已经被问过无数次了，但让我再问一次。 我目前在 MSFT 担任应用科学家。然而，我更想找科学职位，比如 DeepMind 的研究科学家。虽然工作并不特别需要博士学位，但竞争非常激烈，而且有很多博士学位持有者。 我确实喜欢研究，想读博士学位，但我总是问自己这是否真的值得。 这肯定是一个开放性问题，请随时分享您的想法。    提交人    /u/oddhvdfscuyg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gs688q/d_to_phd_or_not_to_phd/</guid>
      <pubDate>Fri, 15 Nov 2024 20:44:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>