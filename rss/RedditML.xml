<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 27 Dec 2023 03:14:27 GMT</lastBuildDate>
    <item>
      <title>[D] 想要学习面向 ML 的分布式系统的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rnnuv/d_want_recommendations_for_learning_mloriented/</link>
      <description><![CDATA[涵盖 ZeRO、多 GPU 训练、并行机制、教授 CUDA / triton / openMP 等相关内容的资源。   由   提交 /u/PunsbyMann   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rnnuv/d_want_recommendations_for_learning_mloriented/</guid>
      <pubDate>Wed, 27 Dec 2023 01:05:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] Flask API 与 TensorFlow Lite 模型始终预测相同的类，无论输入图像如何</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rni45/p_flask_api_with_tensorflow_lite_model_always/</link>
      <description><![CDATA[我正在开发一个 Flask API，以使用 TensorFlow Lite 模型执行推理，该模型是在阿尔茨海默病 5 类图像数据集上训练的，这些图像是 [&#39;AD -阿尔茨海默病”、“CN - 认知正常”、“EMCI - 早期轻度认知障碍”、“LMCI - 晚期轻度认知障碍”、“MCI - 轻度认知障碍”]。  该模型在我的训练环境中运行良好，但是当我将其部署到 Flask API 中时，出现了问题。 API 一致地为每个图像预测相同的类别（“CN - 认知正常”），而在我的 Colab 笔记本中训练的模型则准确地预测各种类别。该 API 稍后将与 React Native App 集成。  使用不同的数据集训练模型两次，但问题仍然存在。我现在已经走到了死胡同，不知道如何解决。  这会是保存格式的问题吗？不确定，但我认为情况并非如此，因为我尝试将模型保存为 .h5 和 .keras，但仍然遇到同样的问题。任何帮助将不胜感激。  TFLite 模型代码： https://colab .research.google.com/drive/1xxW8v5ZBKLvlGrofL2fBy9WYk_Fn5Dj_?usp=sharing  FlaskAPI 代码：  from Flask import Flask ，请求，jsonify导入tensorflow作为tf导入cv2导入numpy作为np从PIL导入图像导入io app = Flask（__name__）解释器= tf.lite.Interpreter（model_path =“updated_final_model.tflite”）interpreter.allocate_tensors（）class_names = [“CN-认知正常”、“AD-阿尔茨海默病”、“EMCI-早期轻度认知障碍”、“MCI-轻度认知障碍”、“LMCI-晚期轻度认知障碍”] def preprocess_image(image) ): image = image.astype(&#39;float32&#39;) / 255.0 image = cv2.resize(image, (150, 150)) image = np.expand_dims(image, axis=0) 返回图像 @app.route(&#39;/predict &#39;,methods=[&#39;POST&#39;]) def Predict(): try: file = request.files[&#39;file&#39;] image_file = Image.open(io.BytesIO(file.read())) image = cv2.cvtColor( np.array(image_file), cv2.COLOR_RGB2BGR) print(&quot;输入图像形状：&quot;, image.shape) preprocessed_image = preprocess_image(image)terpreter.set_tensor(interpreter.get_input_details()[0][&#39;index&#39;], preprocessed_image)terpreter.invoke()output_tensor=interpreter.get_tensor(interpreter.get_output_details()[0][&#39;index&#39;])predicted_class=np.argmax(output_tensor, axis=1)[0]print(“预测类索引: &quot;, Predicted_class) result = {&quot;prediction&quot;: class_names[predicted_class]} return jsonify(result) except Exception as e: return jsonify({&quot;error&quot;: str(e)}) if __name__ == &#39;__main__&#39; : app.run(debug=True)    由   提交/u/parallaxfury12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rni45/p_flask_api_with_tensorflow_lite_model_always/</guid>
      <pubDate>Wed, 27 Dec 2023 00:58:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻求使用 OpenAI 和矢量数据库构建学校手册聊天机器人的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rndcp/p_seeking_advice_for_building_a_school_handbook/</link>
      <description><![CDATA[大家好， 我正在着手一个项目，为我学校的手册创建一个聊天机器人，旨在使其成为学生可以轻松获取信息的资源。作为人工智能相对较新的人，我正在寻求实现这一目标的指导。 我目前的计划是使用 OpenAI 作为主要语言学习模型，重点关注可负担性。我正在考虑集成 RAG（检索增强生成）和 LangChain 以增强功能。然而，我对选择合适的矢量数据库感到非常困惑，因为许多选择似乎成本高昂。我们的目标是让这个系统保持活跃并可供学生使用，而无需花费大量资金。 我还在研究与矢量数据库配对的开源嵌入模型。 Pinecone 引起了我的注意，但它的定价对于我们的预算来说似乎太高了。 有人对这个项目的经济实惠但有效的工具和策略有建议或建议吗？如果您对适合教育用途的矢量数据库有任何见解，或者在不影响质量的情况下优化成本的方法，我们将不胜感激。 提前感谢您的帮助！ （我输入了我的问题，让 gpt4 修复了格式和措辞，不要攻击我）   由   提交 /u/Notchampa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rndcp/p_seeking_advice_for_building_a_school_handbook/</guid>
      <pubDate>Wed, 27 Dec 2023 00:51:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] Inox，JAX 的最小神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rlkn0/p_inox_a_minimal_neural_network_for_jax/</link>
      <description><![CDATA[你好，我一直在为神经网络开发一个名为 不锈钢。目标是  提供一个类似于 PyTorch 的直观界面来构建和操作网络。 引入尽可能少的新概念。特别是，我希望模块与本机 JAX 转换兼容（jax.jit、jax.vmap、jax.grad，... ）开箱即用，与 Equinox 不同。  我最近推送了一个重大更新我希望得到一些关于该项目的反馈。 API 中缺少什么？什么是难以使用/设计不佳的？ 文档足够好/详细吗？ 我仍然需要编写一些单元测试（哎呀！），所以感觉如果您发现一些错误，可以免费提交问题。我很快就会添加贡献指南。   由   提交/u/donshell  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rlkn0/p_inox_a_minimal_neural_network_for_jax/</guid>
      <pubDate>Tue, 26 Dec 2023 23:30:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 鼓励输入的某些部分使用较小权重的 ML 技术？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rkush/d_ml_techniques_of_encouraging_small_weight_on/</link>
      <description><![CDATA[假设我想要一个模型根据 X 预测 Y。我知道对于一些已知的 f 来说 Y = f(X) 是一个很好的近似值，但并不是一个完美的。因此，我希望有一个神经网络 g, h 使得 Y = h(f(X), g(X)) 是更好的近似值。然而，如果我只是添加一个大网络 g 和 h，那么我会严重过度参数化，因为 f(X) 已经非常好。 是否有一种技术（例如精心设计的损失函数） ）以阻止在 g(X) 部分中投入过多的权重？如果我能找到一些这方面的研究，那将非常有帮助。   由   提交 /u/speedy-spade   /u/speedy-spade  reddit.com/r/MachineLearning/comments/18rkush/d_ml_techniques_of_encouraging_small_weight_on/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rkush/d_ml_techniques_of_encouraging_small_weight_on/</guid>
      <pubDate>Tue, 26 Dec 2023 22:59:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 加入学术界研究实验室，同时在工业界全职担任研究工程师。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rixog/d_joining_academia_research_lab_while_working/</link>
      <description><![CDATA[您好，我是一名刚毕业的本科生，目前是一家 ML 初创公司（多模式法学硕士）的研究工程师。我想加入大学的研究实验室并从事研究项目。我个人之前曾与 PI 合作过，他们的实验室与我的创业研究并没有太大关系。  我想听听是否有人有类似的在行业全职工作的同时加入实验室的经历以及我应该注意的事情。我会免费加入并使用自己的设备进行实验室工作。  这是因为，当我在初创公司进行有意义的研究时，我想让自己有更多的事情做，成为一个更有能力的潜在机器学习博士申请者。  谢谢！   由   提交/u/Few_Ad1273  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rixog/d_joining_academia_research_lab_while_working/</guid>
      <pubDate>Tue, 26 Dec 2023 21:36:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在时间序列中查找模式的算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rft8z/d_algorithm_to_find_patterns_in_temporal_sequences/</link>
      <description><![CDATA[我有一个大型数据库，其中按时间顺序存在不同类型的错误。示例：A、C、F、C、G、D、A、G、.....、F、G、D、A... F、S、G、D、H、A... 哪些算法可以我用来寻找重复模式？ （示例中：发现当F、G和D发生时，A随后发生）。谢谢ssss:)   由   提交/u/BusinessBaby9338   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rft8z/d_algorithm_to_find_patterns_in_temporal_sequences/</guid>
      <pubDate>Tue, 26 Dec 2023 19:19:18 GMT</pubDate>
    </item>
    <item>
      <title>[P]频域信道状态信息特征提取用于人类活动识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rdu04/p_feature_extraction_for_channel_state/</link>
      <description><![CDATA[我目前正在开发一个项目，重点是使用通道状态信息 (CSI) 进行人体跌倒检测。作为其中的一部分，我正在探索各种特征提取方法。但是，我不确定从频域提取的最佳特征。 在其原始格式中，时域中的数据被构造为二维数组。每行对应一个毫秒，每列代表一个子载波。每个位置的值表示信号的幅度。 我使用 FFT 将数据转换到频域。对于从频域数据中提取哪些特征的任何见解或建议，我将不胜感激。   由   提交/u/Snoo386  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rdu04/p_feature_extraction_for_channel_state/</guid>
      <pubDate>Tue, 26 Dec 2023 17:54:25 GMT</pubDate>
    </item>
    <item>
      <title>[R]、[P] 用于人工智能研究的自托管 GPU 设置</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rb7lo/r_p_selfhosted_gpu_setup_for_ai_research/</link>
      <description><![CDATA[我的 3070 越来越阻碍我进行研发，而且我越来越多地使用云，不仅仅是为了运行工作，而且是为了活跃研究。我觉得我只是在云上烧钱，而且这是不可持续的。我需要投入一些美元和时间来构建高质量（尽管仍然较小）的服务器来进行我的研究。 我一直在努力为此寻找良好的详细资源/社区。大多数人似乎对云感到满意，或者他们的大学/公司为他们处理这些东西。我预计仅仅通过谷歌搜索来决定我的设置，我会错过一些重要的内部知识。 我希望有人可以提供一些提示，或者更好地向我指出一个对此方面非常热情的社区人工智能开发者？我住在奥斯汀，如果那里有任何面对面的社区，那就更好了！ 我一直在思考初始设置的想法 - 可能只需 2 或 3 4080 即可启动 - 我听说过 NVLink，但不&#39;对于连接不好的人来说，不要认为这会是一个选择 - 机箱（或机架？）和主板可以处理更多（可能 4-10 个 GPU 容量） - 确保其他规格（冷却、CPU、PSU、等）是合适的并且不会成为 GPU 的瓶颈 - 打开案例吗？结案了？？ idk-需要能够从奥斯汀的任何地方进行ssh连接，理想情况下美国任何地方的连接都不会有太糟糕的延迟-我的设置意图是你应该从一个极其新/精益/差的设备中获得期望但雄心勃勃且非常聪明/战略性的初创公司，人们回头看时会说“哇，这是一个经过充分研究和聪明的设置”哈哈 任何建议，任何联系，都表示赞赏。非常感谢！ &lt;3 :-)   由   提交 /u/margaritasAndBowling   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rb7lo/r_p_selfhosted_gpu_setup_for_ai_research/</guid>
      <pubDate>Tue, 26 Dec 2023 15:59:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们通常使用哪种 Transformer 实现？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r8yhf/d_which_transformer_implementation_do_people/</link>
      <description><![CDATA[每个标题，我想知道人们通常使用的 Transformer 是否有特定的实现？我不关心预先训练的模型。我想要一个最小/干净的实现，我可以用它来修改 Transformer 架构本身，以实现我的一些想法。我注意到 PyTorch 有自己的内置 Transformer，但不确定它们是否有任何好处，而且它们看起来可能有点过度设计以满足我的需求。我还注意到 Andrej Karpathy 有他的 nanoGPT 项目，该项目可能符合要求（仅解码器的自回归实现就可以满足我的要求。）   由   提交/u/SuperFX  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r8yhf/d_which_transformer_implementation_do_people/</guid>
      <pubDate>Tue, 26 Dec 2023 14:12:49 GMT</pubDate>
    </item>
    <item>
      <title>[R]“自我预测通用人工智能”（Self-AIXI）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r88hb/r_selfpredictive_universal_ai_selfaixi/</link>
      <description><![CDATA[论文：https： //openreview.net/forum?id=psXVkKO9No 摘要：  强化学习（RL）算法通常利用学习和/或制定有效政策的规划技术。事实证明，两种方法的集成在解决复杂的顺序决策挑战方面非常成功，AlphaZero 和 MuZero 等算法就证明了这一点，这些算法将规划过程整合到参数搜索策略中。 AIXI 是理论上最有效的通用智能体，它通过综合搜索进行规划作为寻找最优策略的主要手段。在这里，我们定义了一个替代的通用代理，我们称之为Self-AIXI，与A​​IXI相反，它最大限度地利用学习来获得良好的策略。它通过自我预测自己的动作数据流来实现这一点，与其他 TD(0) 代理类似，该数据流是通过对当前在策略（通用混合策略）Q 值估计采取动作最大化步骤来生成的。我们证明了Self-AIXI收敛于AIXI，并继承了最大Legg-Hutter智能和自优化特性等一系列特性。   &amp; #32；由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r88hb/r_selfpredictive_universal_ai_selfaixi/</guid>
      <pubDate>Tue, 26 Dec 2023 13:33:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] 微代理：能够自我编辑提示和 Python 代码的模块化代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r6wqx/p_microagents_modular_agents_capable_of/</link>
      <description><![CDATA[项目：https:// github.com/aymenfurter/microagents 描述：  这个实验探索了自动生成和改进自身的自我进化代理。用户不需要特定的代理设计或提示。只需提出一个问题，系统就会启动并发展专门定制的代理来提供答案。该过程从用户查询开始，激活基本的“引导程序”。代理，它不执行Python代码，而是计划并委托给能够运行Python以实现更广泛功能的专门代理。代理经理负责监督它们，通过特定任务的向量相似性来选择或创建代理。代理具有不断发展的系统提示，可以通过学习进行改进。对于编码任务，代理在提示中包含 Python，通过“进化步骤”改进他们的方法。如果不成功。完成任务后，代理的状态会更新，引导代理会评估结果，让其他代理参与更大流程中的进一步步骤。   &amp;# 32；由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r6wqx/p_microagents_modular_agents_capable_of/</guid>
      <pubDate>Tue, 26 Dec 2023 12:15:41 GMT</pubDate>
    </item>
    <item>
      <title>如果你的 GPU 很差，你能做什么研究？[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r2nbu/what_kind_of_research_can_you_do_if_you_are_gpu/</link>
      <description><![CDATA[所以在我的大学里我没有太多的计算资源。我可以在 ML 中做什么类型的工作？   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r2nbu/what_kind_of_research_can_you_do_if_you_are_gpu/</guid>
      <pubDate>Tue, 26 Dec 2023 07:23:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你们使用哪种软件来说明研究框架/想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qzdnj/d_which_software_do_you_guys_use_for_illustrating/</link>
      <description><![CDATA[我们经常在研究论文中看到图表/图形来说明整个工作流程。我很好奇大家都在用什么。就我个人而言，我使用 draw.io，它通常不是“漂亮”的。 - 那么也许有更好的选择？   由   提交/u/KarmaCut132   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qzdnj/d_which_software_do_you_guys_use_for_illustrating/</guid>
      <pubDate>Tue, 26 Dec 2023 04:12:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>