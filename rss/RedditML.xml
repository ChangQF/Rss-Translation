<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Thu, 01 Aug 2024 01:12:24 GMT</lastBuildDate>
    <item>
      <title>[D] Google 的 Gemma-2-2B 与 Microsoft Phi-3：医疗保健领域小型语言模型的比较分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eh3clp/d_googles_gemma22b_vs_microsoft_phi3_a/</link>
      <description><![CDATA[   探索 Google 的 Gemma-2-2b-it 和 Microsoft 的 Phi-3-4k 模型在医疗领域的表现。 （未经微调） Google 的 Gemma-2-2b-it 平均表现出色，得分为 59.21%，而 Microsoft 的 Phi-3-4k 以 68.93% 领先。 将很快为医疗领域评估更多小型模型 源帖子 https://preview.redd.it/ju8culna7yfd1.png?width=1480&amp;format=png&amp;auto=webp&amp;s=9c3d9e612d739fced051effb0426c97d70113989    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eh3clp/d_googles_gemma22b_vs_microsoft_phi3_a/</guid>
      <pubDate>Thu, 01 Aug 2024 00:40:59 GMT</pubDate>
    </item>
    <item>
      <title>EC2 上的大型文件大数据集 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eh37ao/large_dataset_of_large_files_on_ec2_d/</link>
      <description><![CDATA[因此，我们正在努力训练一个相对较小的 CNN 和一些其他项目，这些项目是大规模大文件数据集上的。 数据集：16TB 的 500mb 卫星图像 我目前有一个 g5 EC2 实例（4 个 gpu），带有一个 16TB EBS io1 驱动器，其中已加载数据。使用简单的数据加载器和数据集对象，我们在单磁盘读取速度上遇到了瓶颈。 直接从 S3 读取更好还是使用其他方法来加快读取速度更好？    提交人    /u/SuperbMonk4403   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eh37ao/large_dataset_of_large_files_on_ec2_d/</guid>
      <pubDate>Thu, 01 Aug 2024 00:33:38 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 小型数据集的机器学习 (n<50)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eh25qt/discussion_ml_with_small_datasets_n50/</link>
      <description><![CDATA[我正在开展一个机器学习项目，涉及 4 个特征和一个将这 4 个特征相加的附加特征。有 5 个目标变量，所有特征和目标都是整数。 目前，我只有 1 行真实数据，因为获取更多数据非常麻烦。为了解决这个问题，我使用约束、关系逻辑和随机数生成器创建了 100 个模拟数据样本。数据中的关系相对线性（一个特征的度为 2，其他特征的度为 1）。由于范围较大（2000-3000），某些目标的均方误差 (MSE) 相当高（200-700），而对于其他目标，由于范围较小（5-20​​），均方误差较小（9-15）。 我尝试了各种模型：多元线性回归、岭回归、梯度提升和 MLP 回归。基于最低 MSE 的最佳结果是，对于 5 个目标中的 4 个，使用多项式交互的岭回归（一个特征的度为 2，其余特征的度为 4），对于剩余的目标，使用梯度提升。 但是，由于数据集较小，我在超参数调整方面遇到了瓶颈。对于如此有限的数据，更高级的方法是不可行的。当我们最终获得真实数据时，我们可能会有大约 40 个样本。 我的问题是：是否有可能使用如此小的数据集创建准确的 ML 模型？    提交人    /u/CashCrane   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eh25qt/discussion_ml_with_small_datasets_n50/</guid>
      <pubDate>Wed, 31 Jul 2024 23:45:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 iOS 上高效本地运行模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egz3s0/d_how_to_efficiently_run_models_locally_on_ios/</link>
      <description><![CDATA[我正在构建一个 iOS 应用程序，需要处理以下约束，因为我正在为自定义键盘扩展构建自动更正解决方案： - 70MB 内存使用量 - 50-150ms 延迟 我发现可以完成这项工作的主要模型是 ELECTRA (https://huggingface.co/docs/transformers/en/model_doc/electra#transformers.TFElectraForMaskedLM) 但是，使用 CoreML 或 TensorFlowLite 在本地运行模型最终会增加太多开销，无法保持在 70MB 内存使用量以下，即使模型文件本身的大小为 18MB。 我也尝试在 AWS EC2 t3-large 上部署模型实例，但这里的延迟是问题所在。 有什么建议吗？    提交人    /u/pawn5gamb1t   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egz3s0/d_how_to_efficiently_run_models_locally_on_ios/</guid>
      <pubDate>Wed, 31 Jul 2024 21:33:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 平衡双摆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egy81m/d_balancing_a_double_pendulum/</link>
      <description><![CDATA[双摆是非确定性/混沌系统的最佳示例之一，因此产生了构建一个能够使其在直立位置保持平衡的模型的想法。双摆不是连接到固定点，而是连接到可移动（可控制）的滑块。 这是当前的进展：Balancing-Double-Pendulum 至于模型，我认为使用物理信息神经网络 (PINN) 是与遗传算法一起的最佳选择。当前的实现使用了基于简单公式的近似值，但显然某种积分器会更好（为了节约能源）。 目前，模拟无需使用任何优化算法就能正常工作，但如果需要的话 - 我认为 QuadTree 可以完成这项工作。 在模型和模拟方面我应该做任何改进吗？    提交人    /u/Mynameiswrittenhere   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egy81m/d_balancing_a_double_pendulum/</guid>
      <pubDate>Wed, 31 Jul 2024 20:57:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您是否尝试过使用讲师库进行 NER？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egvr3c/d_have_you_attempted_ner_with_instructor_lib/</link>
      <description><![CDATA[我正在研究命名实体提取而不是识别。主要思想是使用具有特定指令的 LLM 将非结构化文本中的实体（如日期、位置和名称）提取到繁琐的模型中。逻辑工作正常，但与类型相关的验证错误不一致。有时错误经常发生，有时几乎不发生。例如，预期类型可能是字符串列表，但 LLM 输入可能是“[&#39;name1&#39;, &#39;name2&#39;, ...]”之类的东西，或者只是没有括号的文字。添加字段验证器似乎无助于匹配。有没有人遇到过这种情况，并找到了最适合 LLM 输入后处理或通过重试处理错误的方法？    提交人    /u/Useful_Anybody_9351   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egvr3c/d_have_you_attempted_ner_with_instructor_lib/</guid>
      <pubDate>Wed, 31 Jul 2024 19:17:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 逻辑回归如何学习多类问题的决策界面？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egv40h/d_how_can_a_logistic_regression_learn_this/</link>
      <description><![CDATA[我使用 Scikit-Learn 的 LogisticRegression 实现在 Iris 数据集上训练模型，该数据集有 3 个类。对于 multi_class 参数，我传入了“multi_class=ovr”。据我了解，这应该训练 3 个独立的二元分类器，对于输入平面中的任何点，我们都分配得分最高的分类器的标签。 https://preview.redd.it/jonk35uqgwfd1.png?width=985&amp;format=png&amp;auto=webp&amp;s=08cdcab5151ac065a8b0b94f3ad3225ce8539fa4 我理解红点和绿点是如何分类的，因为红点可以从蓝点和绿点的组合中线性分离点，并且绿点也可以与蓝点和红点的组合线性分离。但是我对如何为蓝点训练二元分类器感到困惑，因为包含红点和绿点的“其他类”位于蓝点的两侧。Scikit-Learn 是否只训练 2 个分类器并将在任何一个分类器上得分不大于 0.5 的点标记为蓝色？    提交人    /u/Money_Ferret_4782   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egv40h/d_how_can_a_logistic_regression_learn_this/</guid>
      <pubDate>Wed, 31 Jul 2024 18:52:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 注释词汇表（可能）就是您所需要的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egthqg/r_annotation_vocabulary_might_be_all_you_need/</link>
      <description><![CDATA[论文链接：https://www.biorxiv.org/content/10.1101/2024.07.30.605924v1 摘要：  蛋白质语言模型 (pLM) 彻底改变了蛋白质系统的计算建模，构建了以结构特征为中心的数值嵌入。为了增强蛋白质嵌入中可用的生化相关属性的广度，我们设计了注释词汇表，这是一种由结构化本体定义的蛋白质属性的转换器可读语言。我们从头开始训练注释变换器 (AT)，以恢复掩蔽的蛋白质属性输入，而无需参考氨基酸序列，仅基于蛋白质描述构建新的数值特征空间。我们在各种模型架构中利用 AT 表示，用于蛋白质表示和生成。为了展示注释词汇集成的优点，我们进行了 515 次不同的下游实验。使用新颖的损失函数和仅 3 美元的商业计算，我们的首要表示模型 CAMP 为 15 个常见数据集中的 5 个生成了最先进的嵌入，其余数据集上的性能也具有竞争力；凸显了使用注释词汇进行潜在空间管理的计算效率。为了标准化从头生成的蛋白质序列的比较，我们提出了一种新的基于序列比对的分数，它比传统的语言建模指标更灵活、更具生物学相关性。我们的生成模型 GSM 使用类似 BERT 的生成方案从仅注释提示中生成高比对分数。特别值得注意的是，许多 GSM 幻觉返回具有统计意义的 BLAST 命中，其中富集分析显示与注释提示匹配的属性 - 即使基本事实与整个训练集的序列同一性较低。总体而言，注释词汇工具箱提供了一种有前途的途径，可以用本体和知识图谱的成员取代传统的标记，增强特定领域的转换器模型。注释词汇对蛋白质的简洁、准确和有效的描述为构建蛋白质的数值表示以进行蛋白质注释和设计提供了一种新颖的方法。  我们很自豪地宣布发布我们的最新作品！请阅读、分享并提出任何问题！    提交人    /u/TeamArrow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egthqg/r_annotation_vocabulary_might_be_all_you_need/</guid>
      <pubDate>Wed, 31 Jul 2024 17:47:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 无限上下文长度真的可能吗？：“Unlimiformer”作者周五讨论 NeurIPS 论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egqitt/d_is_unlimited_context_length_really_possible/</link>
      <description><![CDATA[无限上下文长度真的可能吗？代价是什么？ 2023 年 NeurIPS 论文 Unlimiformer 的作者 Amanda Bertsch 将在本周五的 Oxen.ai 论文俱乐部中描述该架构并回答问题。  Oxen 首席执行官兼 Plain Speak 大师 Greg Schoeninger u/FallMindless3563 将帮助解释该概念并将其与我们审阅过的其他论文联系起来。 致电：https://oxen.ai/community  声称使无限上下文长度成为可能的技巧：将交叉注意力计算卸载到 K-最近邻 (K-NN) 索引。  我在这里发了一条推文，其中某人制作了巧妙的 K-NN 动画：https://x.com/mustafarrag/status/1817647917059944474 论文：https://arxiv.org/abs/2305.01625 Greg，我将用我的前 5 个问题来回答。到目前为止，我只阅读了摘要。    提交人    /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egqitt/d_is_unlimited_context_length_really_possible/</guid>
      <pubDate>Wed, 31 Jul 2024 15:47:52 GMT</pubDate>
    </item>
    <item>
      <title>[N] Finegrain 的对象橡皮擦演示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egpu9b/n_object_eraser_demo_by_finegrain/</link>
      <description><![CDATA[      对象橡皮擦 Finegrain 刚刚在 Huggingface 上发布了一个对象橡皮擦的演示。该模型可以删除任何对象或图像，并删除来自对象的任何效果（阴影、反射、光线）。与我们迄今为止拥有的其他橡皮擦相比，结果令人印象深刻；你怎么看？ 演示链接：https://huggingface.co/spaces/finegrain/finegrain-object-eraser    由   提交  /u/nota-Reddit   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egpu9b/n_object_eraser_demo_by_finegrain/</guid>
      <pubDate>Wed, 31 Jul 2024 15:20:10 GMT</pubDate>
    </item>
    <item>
      <title>为大型语言模型提供更好内存的框架 - 免费且开源。[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egmmpe/a_framework_to_give_large_language_models_better/</link>
      <description><![CDATA[Github - https://github.com/chisasaw/redcache-ai 使用的 SDK [scikit-learn、numpy 和 openai] 什么？ 在构建聊天应用程序时，我找不到经济高效、可扩展且价格合理的内存层。这导致了 redcache-ai。它是一个提供语义搜索、存储和检索增强生成 (RAG) 的 Python 包。 用例？ 如果开发人员想要构建使用文档摘要和/或语义搜索的桌面应用程序，开发人员可以使用 redcache-ai 和选择的大型语言模型提供程序。聊天应用程序存储用户会话也是如此。 优点？  易于使用。只需像安装 Python 包一样安装它，即“pip install redcache-ai”。 提供存储可扩展性。将您的记忆存储到磁盘、sqlite 或您选择的数据库中。  请提供反馈并提出问题。也可以随时为项目做出贡献。    提交人    /u/hack_knight   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egmmpe/a_framework_to_give_large_language_models_better/</guid>
      <pubDate>Wed, 31 Jul 2024 13:02:41 GMT</pubDate>
    </item>
    <item>
      <title>关于使用知识图谱的神经符号人工智能的调查论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egke1v/survey_paper_over_neurosymbolic_ai_with_knowledge/</link>
      <description><![CDATA[  由    /u/joestomopolous  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egke1v/survey_paper_over_neurosymbolic_ai_with_knowledge/</guid>
      <pubDate>Wed, 31 Jul 2024 11:06:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]关于知识图谱和图神经网络的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eg674y/discussion_thoughts_on_knowledge_graphs_and_graph/</link>
      <description><![CDATA[几年前，我的数据科学团队梦想着实现知识图谱并利用图神经网络。这种方法在我所在的行业——金融领域似乎特别有前景，因为它可以让模型捕捉间接关系——例如，所有权变更如何影响公司的业绩。 当时，这感觉就像一场白日梦。捕捉任何关系（例如“拥有”或“销售产品”）都需要自己的 NLP 模型。然而，LLM 的出现大大降低了这种复杂性（现在已在 LlamaIndex 中实现）。所以我们想知道是否应该再试一次 KG 和 GNN。我们的想法是使用 LLM 来帮助我们构建 KG，并将来自其他数据库的数据添加到其中。然后，我们将训练 GNN 来预测诸如“公司 A 会收购公司 B 吗”或“公司 C 的表现会优于公司 D 吗”之类的事情。 然而，尽管 GNN 经常被吹捧为下一个大事件，但它仍然有点小众。好吧，它们被用来补充 RAG，但我还没有听说过任何非大型科技公司建立自己的超级知识图谱。根据我所读到的内容，图形数据库面临着大量的批评，原因是性能问题和创建有效模式的难度等。 您对这些技术有什么经验？您有什么成功案例或警示故事可以分享吗？ [编辑]这篇文章比我想象的要受到更多的关注，所以我对其进行了一些修改，以节省大家的时间。具体来说，我试图澄清 KG 和 GNN 是不同的。这两种技术的融合似乎很有希望，但我有两个大担忧：  领先的图形数据库提供商 Neo4j 似乎是该主题的主要知识提供者。它甚至撰写了至少两本由 O&#39;Reilly(!) 编辑的书，因此很难了解知识图谱的陷阱。 据我所知，几乎没有人大规模实施过 GNN。     提交人    /u/MeditationBeginner   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eg674y/discussion_thoughts_on_knowledge_graphs_and_graph/</guid>
      <pubDate>Tue, 30 Jul 2024 22:05:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jul 2024 15:00:14 GMT</pubDate>
    </item>
    </channel>
</rss>