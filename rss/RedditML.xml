<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Mon, 29 Jul 2024 18:19:42 GMT</lastBuildDate>
    <item>
      <title>[D] 有可能兼顾研究和全职工作吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef6mnn/d_is_it_possible_to_juggle_doing_research_and/</link>
      <description><![CDATA[我目前在一家生命科学公司担任 AI 工程师。我对深度学习研究（尤其是计算机视觉）很感兴趣，但同时又不想辞职。我可以在下班后远程与教授一起做研究员吗？我愿意每周为此投入 20 小时。（工作日 2 小时，周末 10 小时）    提交人    /u/Hour_Amphibian9738   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef6mnn/d_is_it_possible_to_juggle_doing_research_and/</guid>
      <pubDate>Mon, 29 Jul 2024 18:16:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些课程可以学习带有证书的机器学习数学，又称线性代数、微积分、统计学？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef56kf/d_what_courses_are_there_to_learn_the_math_for/</link>
      <description><![CDATA[我的学校不提供高级数学课程，所以现在正值暑假，我想考一些证书。我想在完成数学课程后最终参加机器学习课程。 编辑：我所说的课程是指在线课程，我不介意付钱。    提交人    /u/HashBrownTheBro   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef56kf/d_what_courses_are_there_to_learn_the_math_for/</guid>
      <pubDate>Mon, 29 Jul 2024 17:19:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] 定制代理工作流和分布式处理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef34w8/p_customized_agentic_workflows_and_distributed/</link>
      <description><![CDATA[大家好！我刚刚为我的平台开发完此功能，并希望获得一些反馈。 平台是 isari.ai  您可以在主页上观看有关如何使用它的演示😊 如果您想合作或成为此计划的一部分，请给我发送 DM 或加入 Discord 服务器，我非常乐意回复！ 我很感激任何和所有的反馈🙏    提交人    /u/akitsushima   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef34w8/p_customized_agentic_workflows_and_distributed/</guid>
      <pubDate>Mon, 29 Jul 2024 15:57:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] MMM程序/工具选择建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef2pjz/d_mmm_programtool_selection_advice/</link>
      <description><![CDATA[大家好，我是一名在 MMM 工作的计量经济学家，希望有人能提供一些见解来帮助我。作为参考，我有使用内部建模工具、EViews 和 Random Forest ML 的背景。我刚开始一份新工作，目前这里没有 MMM 功能，所以我们正在研究我们的选择。我一直被推荐使用 LightweightMMM（显然很快就会被 Meridian 取代）作为贝叶斯 MMM 的开源选项，我从未执行过贝叶斯建模方法，但对它了解得足够多，只需一点练习和阅读就可以了。 我面临的问题是，我们的潜在客户需要一个区域级别的模型，该模型还考虑到营销的长期影响。现在我知道 Lightweight/Meridian 可以处理这个要求的区域方面，但我不确定长期（嵌套）建模的能力。这是它能处理还是不能处理？有没有解决办法，例如提取分解后的输出并运行第二个模型，以品牌跟踪（例如知名度）的增量增益作为 KPI，以确定媒体对此的贡献？ 如果这是无法通过 Lightweight 或 Meridian 完成的事情，那么是否有人知道有什么程序/工具可以帮助我们建模以满足这些要求？任何帮助都将不胜感激，谢谢。    提交人    /u/Radiant-Project5105   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef2pjz/d_mmm_programtool_selection_advice/</guid>
      <pubDate>Mon, 29 Jul 2024 15:39:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 毕业设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef2e0u/d_graduation_project/</link>
      <description><![CDATA[我是一名高年级计算机科学专业的学生，​​作为毕业要求的一部分，我们需要开展一个涉及 Al 和 ML 的项目，但是我们一直在寻找可以解决的想法或问题，但大多数想法已经过时或已经开发出来了。如果有人对适合我的毕业项目的想法有任何建议，我将不胜感激。    提交人    /u/Training_Constant696   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef2e0u/d_graduation_project/</guid>
      <pubDate>Mon, 29 Jul 2024 15:27:14 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的有效提示方法：一项调查 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef22iu/efficient_prompting_methods_for_large_language/</link>
      <description><![CDATA[  由    /u/juliannorton  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef22iu/efficient_prompting_methods_for_large_language/</guid>
      <pubDate>Mon, 29 Jul 2024 15:14:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] Neurips’24 评论发布时间？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef1var/d_neurips24_review_release_time/</link>
      <description><![CDATA[有人知道评审什么时候发布吗？NeurIPS 网站指出，反驳将于 7 月 30 日在地球上的任何地方开始，而在我们的时区已经是 7 月 30 日了！    提交人    /u/Working-Egg-3424   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef1var/d_neurips24_review_release_time/</guid>
      <pubDate>Mon, 29 Jul 2024 15:06:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 知识图谱和对（大量）技术 PDF 进行 ra.g</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef0iv8/d_p_knowledge_graph_and_rag_over_large_set_of/</link>
      <description><![CDATA[我有一批在一段时间内收集的 PDF（数量增长很快）。主要是技术材料（机器学习、统计学、金融等方面的期刊文章和书籍）。我想基于这些材料创建一个知识图谱，并微调一个 RAG，这样我就可以使用 LLM 搜索我的东西。我的想法是，与其使用 mendeley，我可以使用 LLM 作为强化版的 mendeley。不需要文件夹和标签，我只需提示我正在寻找的内容即可。 问题：  我不想重新发明轮子。要使用哪些软件包 / github？ 有人成功完成过吗？ 本地计算会是一个问题 —— 无法在本地完成。最好是与 ChatGPT 或 Claude 链接的东西（我对这两个都有专业订阅）。  TIA 编辑：如果我可以将我的笔记放入（非常多）overleaf 项目、onenote、supernotes 和 ms 中来执行此操作，那也会很棒。    提交人    /u/daydaybroskii   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef0iv8/d_p_knowledge_graph_and_rag_over_large_set_of/</guid>
      <pubDate>Mon, 29 Jul 2024 14:11:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 量化的视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eey89o/p_a_visual_guide_to_quantization/</link>
      <description><![CDATA[大家好！随着越来越多的大型语言模型发布以及量化需求的增加，我想是时候编写一份深入且直观的量化指南了。 从探索如何表示值、（非）对称量化、动态/静态量化，到训练后技术（例如 GPTQ 和 GGUF）和量化感知训练（带有 BitNet 的 1.58 位模型）。 https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization 有了超过 60 个自定义视觉效果，我有点做得过火了，但我真的很想尽可能多地包含概念！  本指南的视觉特性允许专注于直觉，希望使所有这些技术易于广大受众使用，无论您是量化新手还是经验丰富的量化新手。    提交人    /u/MaartenGr   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eey89o/p_a_visual_guide_to_quantization/</guid>
      <pubDate>Mon, 29 Jul 2024 12:27:03 GMT</pubDate>
    </item>
    <item>
      <title>基于元数据的自动检索增强生成 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eesco8/automated_metadata_based_retrieval_augmented/</link>
      <description><![CDATA[https://github.com/darshil3011/AutoMetaRAG/tree/main 一个分析数据和可能的问题以生成动态元数据、处理分块并在 Qdrant 上实现元数据过滤以获得相关结果的框架。    提交人    /u/AcrobaticDraft7520   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eesco8/automated_metadata_based_retrieval_augmented/</guid>
      <pubDate>Mon, 29 Jul 2024 06:10:41 GMT</pubDate>
    </item>
    <item>
      <title>在训练数据中加入基准 QA 是否会影响 LLM 评估指标的有效性？[d]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eeq3eh/does_including_benchmark_qa_in_training_data/</link>
      <description><![CDATA[有很多方法可以评估大型语言模型 (LLM)，例如 MMLU、IFEval、MBPP、GSM8K、GPQA、ARC 和 BFCL。但是，如果一些 AI 训练师将这些问题纳入 LLM 的训练数据集中会怎样？这是否会使这些测试变得不那么有意义？&quot;    提交人    /u/SelectPlatform8444   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eeq3eh/does_including_benchmark_qa_in_training_data/</guid>
      <pubDate>Mon, 29 Jul 2024 03:53:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] CUDA 中的 KV 缓存</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eepco9/p_kv_cache_in_cuda/</link>
      <description><![CDATA[我正在开发一个项目，允许使用 C CUDA 推断 Llama3.0-8B。GG 的 Llama.cpp 给了我很大的启发，因为我刚接触 CUDA，想深入了解它。 对于 KV 缓存，您究竟如何在确保速度和内存性能的同时，移除和重新组织物理 CUDA 内存中的张量数据？本质上，是否有任何最佳实践且经济有效的方法可以将张量虚拟地移到左上角，以便为新标记留出新空间？ 因为我假设如果我必须分配内存并设置 CUDA 内核以将值复制到新的内存块，那么最终会比重新计算值更昂贵？ 此外，如果缩放后​​有自注意力的掩码，计算输出的右上三角形是否有意义？直接将物理内存中的这些值手动设置为某个较大的负数不是很有意义吗？  struct Tensor { int ndim; int *shape; float *arr; int mem_size; };     submitted by    /u/Delicious-Ad-3552   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eepco9/p_kv_cache_in_cuda/</guid>
      <pubDate>Mon, 29 Jul 2024 03:12:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么机器学习领域中这么多最优秀的人才没有为大型科技公司工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eejd3b/d_why_so_many_of_the_most_skilled_people_in_the/</link>
      <description><![CDATA[我见过很多拥有常春藤联盟学位的人，研究论文作者，获奖者，课程老师，该领域的书籍作者，但你看他们的领英，这些人中的大多数都不在谷歌、微软、亚马逊、Meta 等大型科技公司 (MANGA 公司) 工作，他们通常在中小型公司工作，我的意思是，写一本关于机器学习的书的人一定知道这件事，拥有剑桥或哈佛计算机科学学位的人可能对此有所了解，为什么有这么多来自大科技公司？ 我知道很多人想专注于研究而不是行业，但大型科技公司确实在 ML 领域进行了最先进的研究，所以对我来说很难知道为什么这些公司不想要这些人或者为什么他们不想为大型科技公司工作。    提交人    /u/millhouse056   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eejd3b/d_why_so_many_of_the_most_skilled_people_in_the/</guid>
      <pubDate>Sun, 28 Jul 2024 22:18:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 稀疏自动编码器对 LLM 可解释性的直观解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eeihdl/d_an_intuitive_explanation_of_sparse_autoencoders/</link>
      <description><![CDATA[稀疏自动编码器 (SAE) 是实现 LLM 可解释性和可说明性的最有前途和最流行的方法之一。我撰写了一篇简单、直观的 SAE 介绍，并附有图表和参考 PyTorch 代码。 除其他内容外，我还介绍了我们使用 SAE 的原因、它们如何用于模型干预（例如 金门大桥克劳德）以及使用 SAE 的挑战。最突出的挑战之一是缺乏良好的指标，因为自然语言文本中没有明确的可衡量的基本事实。 解释链接在此处：https://adamkarvonen.github.io/machine_learning/2024/06/11/sae-intuitions.html    提交人    /u/seraine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eeihdl/d_an_intuitive_explanation_of_sparse_autoencoders/</guid>
      <pubDate>Sun, 28 Jul 2024 21:38:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jul 2024 15:00:14 GMT</pubDate>
    </item>
    </channel>
</rss>