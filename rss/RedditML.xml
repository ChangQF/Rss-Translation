<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 11 Sep 2024 12:31:20 GMT</lastBuildDate>
    <item>
      <title>[D] 我在这里想做什么？对 SVM 可解释性想法进行健全性检查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fe7jgu/d_what_am_i_trying_to_do_here_sanity_check_for/</link>
      <description><![CDATA[我已经实现了一个使用高斯 RBF 和标准化特征（Z 分数）的 SVM 分类器。它完全用 Rust 编写，并且位于没有互联网访问的机器上，并且无法访问可以轻松计算 Shapley 值或 LIME 的平台。正确性、速度和可移植性是我们的目标。 我有一个快速有效的可解释性想法，但我想检查这是否是一种合理的做事方式。 本质上，正常运行模型并生成分类和距离值（就像它目前所做的那样）。然后，为每个特征重新运行一次模型（例如，30 个特征 = 30 次额外运行）。对于每次运行：  将感兴趣的特征的 Z 分数归零， 重新运行预测并生成新的距离值。将此新值与原始值进行比较以产生“偏移量” 保存并报告这 30 个偏移量，并根据 |abs| 对它们进行排序。偏移量的符号表示对最终预测的影响的方向性  这是个东西吗？有名字吗？还是这很蠢？ 谢谢    提交人    /u/racetrack9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fe7jgu/d_what_am_i_trying_to_do_here_sanity_check_for/</guid>
      <pubDate>Wed, 11 Sep 2024 11:13:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人能解释一下伪装物体检测（COD）吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fe51w1/d_can_anyone_explain_camouflaged_object_detection/</link>
      <description><![CDATA[注意：我是一名大四本科生，并不是一名经验丰富的研究人员。 伪装物体检测 (COD) 是计算机视觉领域的一项专门任务，专注于识别与周围环境融为一体、难以检测的物体。COD 尤其具有挑战性，因为这些物体被有意或自然地设计成与背景难以区分。 我不明白的是：COD10K 等数据集包含地面实况蒙版，可勾勒出伪装物体的确切形状。但是，如果物体与背景融为一体，那么使用哪些特征来区分物体和背景？当物体没有被伪装时，这会变得相对容易，因为物体通常具有可区分的特征，例如边缘、颜色或纹理，以将其与背景区分开来。    提交人    /u/_My__Real_Name_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fe51w1/d_can_anyone_explain_camouflaged_object_detection/</guid>
      <pubDate>Wed, 11 Sep 2024 08:18:55 GMT</pubDate>
    </item>
    <item>
      <title>[D]NanoBPE：MicroBPE 的仿制品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fe3hgv/dnanobpe_an_imitation_of_microbpe/</link>
      <description><![CDATA[花了一个晚上深入研究一个有趣的业余项目 - 模仿 Andrej Karpathy 的 microBPE。看到字节对编码 (BPE) 如何应用于 NLP 之外，这令人着迷，它解锁了在推荐系统和下游事件处理等领域识别频繁长序列的新方法。期待进一步探索其潜力！ https://github.com/ickma/nanobpe    提交人    /u/Potential-Dingo-6424   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fe3hgv/dnanobpe_an_imitation_of_microbpe/</guid>
      <pubDate>Wed, 11 Sep 2024 06:21:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 谁是好孩子？Metropolis-Hastings 方法用于确定来源不明的寄养狗名字</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdzemt/r_whos_a_good_boy_a_metropolishastings_approach/</link>
      <description><![CDATA[  由    /u/TobyWasBestSpiderMan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdzemt/r_whos_a_good_boy_a_metropolishastings_approach/</guid>
      <pubDate>Wed, 11 Sep 2024 02:18:39 GMT</pubDate>
    </item>
    <item>
      <title>研究出版问题 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdx2e3/research_publication_questions_r/</link>
      <description><![CDATA[我今年获得了生物信息学硕士学位，并一直与一位教授合作进行研究。我们研究了两个不同的研究课题，但我指的是第二个。这位教授是一位数据科学教授，专门教授机器学习，他来自我大学的另一所学院。 所以当我遇到他时，第二个项目是基于机器学习的，带有一些生物信息学，当然我需要做所有事情。他会给我一些建议，并试着和我一起理解这些东西，但他不做生物信息学，所以我需要自己弄清楚预处理的东西，这不是最难的部分。困难的部分是试图弄清楚如何让他或在我之前的其他学生选择使用 ML 工具来完成任务。那两个学生没有做出太多贡献就离开了，他们是计算机科学专业的哈哈。这个 ML 工具有很多问题，没有完整的文档。尽管如此，我还是让它在学校的 hpc 上运行起来了。 长话短说，数据是单细胞 RNA 序列数据，ml 工具使用随机森林回归来推断基因调控网络。这只是预测转录因子、靶基因对/边缘。 问题是我没有得到好的指标。有很多过度拟合的迹象。我尝试获取训练集的 r 平方分数，并将其与测试集的分数进行比较，并且每个目标基因始终给出比测试分数好得多的训练分数。 我的教授只是想让我给他一份我周五刚刚提交的最终提交论文。但在那篇论文中，我也让他知道，我解释说由于指标，结果并不可靠。我还谈到了我可以改进的地方，以尝试获得更好的评估指标。教授知道到目前为止评估指标并不好，仍然要求提交一份已准备好提交的论文，而我刚刚提供了这份论文。 我想问你们所有人：我是否可以提交一篇我知道结果不可靠的论文，即使我在论文中提到了这一点？这在研究界会被看不起吗？我相信这绝对比伪造评估指标和数据并冒充我的工作可靠要好，就像其他一些大学的学者所做的那样，导致许多论文被召回。但提交一些没有突破性的东西是件好事吗？    提交人    /u/chaosOblivionkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdx2e3/research_publication_questions_r/</guid>
      <pubDate>Wed, 11 Sep 2024 00:16:09 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待 T-FREE 减少嵌入的词汇量 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fduqr5/what_do_you_think_of_tfree_to_reduce_the/</link>
      <description><![CDATA[      嘿 r/MachineLearning！ 我刚刚发表了第二篇博客文章，分析了一篇有趣的新论文：T-FREE：通过稀疏表示实现无标记器生成式 LLM，实现内存高效嵌入。您可以在此处查看我的完整分析。 编码阶段 作者提出了一种有趣的方法，使用类似于局部敏感哈希的技术来减少嵌入矩阵的词汇量。以下是其流程的细分：  应用空白标记器将句子拆分为单词：&quot;hello world !&quot; -&gt; [&quot;hello&quot;, &quot;world&quot;, &quot;!&quot;] 在单词边界中添加特殊字符：[&quot;hello&quot;, &quot;world&quot;, &quot;!&quot;] -&gt; [&quot;_hello_&quot;, &quot;_world_&quot;, &quot;_!_&quot;] 将单词拆分为 3-grams：[&quot;_hello_&quot;, &quot;_world_&quot;, &quot;_!_&quot;] -&gt; [&quot;_he&quot;, &quot;hel&quot;, &quot;ell&quot;, &quot;llo&quot;, &quot;lo_&quot;, &quot;_wo&quot;, &quot;wor&quot;, &quot;orl&quot;, &quot;rld&quot;, &quot;ld_&quot;, &quot;_!_&quot;] 将每个 3-gram 哈希处理为多个嵌入矩阵索引：_hel -&gt; [hash1(&quot;_he&quot;) % v, hash2(&quot;_he&quot;) % v, hash3(&quot;_he&quot;) % v]（其中 v 是所选词汇量） 通过对每个单词内的所有三元词嵌入求和来创建词嵌入。  我已经创建了这个过程的可视化表示： https://preview.redd.it/hmvh7lwy42od1.png?width=765&amp;format=png&amp;auto=webp&amp;s=f14b4105c048b5ef019a3de06478aa5bb1beeb14 他们还提出了一个解码阶段，但它有点复杂。如果你有兴趣，可以查看我的[帖子](https://f14-bertolotti.github.io/posts/06-09-24-tfree/index.html)或他们的[论文](https://arxiv.org/abs/2406.19223)。 关键要点和注意事项  本文提出了一个引人注目的想法，总体来说写得很好，不过解码部分可以更详细一些。 解码阶段应用了两种不同的规范化（除以和，然后是 softmax），这似乎不太常规。 虽然该方法被宣传为无需 tokenizer，但它仍然使用空格标记器。“免训练标记器”可能更合适。 一个有趣的实验是使用带有完整词嵌入矩阵的标准解码阶段。虽然计算量很大，但我认为这可能是一个有趣的实验。  讨论 您对这种方法有何看法？您是否看到了潜在的局限性？    提交人    /u/f14-bertolotti   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fduqr5/what_do_you_think_of_tfree_to_reduce_the/</guid>
      <pubDate>Tue, 10 Sep 2024 22:25:43 GMT</pubDate>
    </item>
    <item>
      <title>机器学习理论研究经验对统计学博士申请有用吗？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdtz54/is_machine_learning_theory_research_experience/</link>
      <description><![CDATA[现在我和大学电子工程系的一位教授一起研究 ML 理论（一些深度学习架构的样本复杂性）。我想知道这对申请统计学博士课程是否有用。说实话，我认为“统计学”在这个项目中用得不多。这是否意味着与统计学系教授的其他项目相比，这个项目对我申请统计学博士课程的简历没有那么有用？    提交人    /u/mziycfh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdtz54/is_machine_learning_theory_research_experience/</guid>
      <pubDate>Tue, 10 Sep 2024 21:51:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据漂移效应</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdkwq5/d_data_drift_effect/</link>
      <description><![CDATA[除了重新训练之外，还有其他方法可以减少数据漂移的影响吗？我只能每年重新训练一次，但我每年都会遇到数据漂移。    提交人    /u/Vegetable-Ad7622   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdkwq5/d_data_drift_effect/</guid>
      <pubDate>Tue, 10 Sep 2024 15:39:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformers Trainer 与 Pytorch 照明</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdey5q/r_transformers_trainer_vs_pytorch_lighting/</link>
      <description><![CDATA[大家好， 我想知道你对这两个框架的看法。  它们有什么优缺点？ 如果要优先考虑效率，哪一个更好？或者它们之间的唯一区别是代码抽象和组织？ 最后，你知道任何同时使用它们的代码库吗？我想用它作为从一个框架转换到另一个框架的“模板”。 非常感谢！    提交人    /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdey5q/r_transformers_trainer_vs_pytorch_lighting/</guid>
      <pubDate>Tue, 10 Sep 2024 10:52:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找一些关于评估法学硕士结构化输出的论文或图书馆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdek1q/r_looking_for_some_papers_or_libraries_on/</link>
      <description><![CDATA[嗨，我想知道是否有人知道任何论文或库可以让我评估大型语言模型 (LLM) 的结构化输出？特别是细粒度评估的方法。 json { &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30, &quot;email&quot;: &quot;johndoe@example.com&quot;, &quot;occupation&quot;: &quot;Software Engineer&quot; }  假设 LLM 生成了上述 JSON，我们想根据某些基本事实评估每个字段。某些字段（如 age）可以通过精确匹配进行评估，但其他字段可能需要更高级的方法，例如使用某种形式的 llm-as-judge 评分或语义软匹配。如果我们考虑嵌套结构，情况会变得更加复杂。 我正在寻找有关如何对此类输出进行详细评估的见解。你有什么建议或资源吗，尤其是框架/库？    提交人    /u/hwvbdnkau   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdek1q/r_looking_for_some_papers_or_libraries_on/</guid>
      <pubDate>Tue, 10 Sep 2024 10:26:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 能产生新颖的研究想法吗？一项有 100 多名 NLP 研究人员参与的大规模人类研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fddtmm/r_can_llms_generate_novel_research_ideas_a/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fddtmm/r_can_llms_generate_novel_research_ideas_a/</guid>
      <pubDate>Tue, 10 Sep 2024 09:35:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] LowFormer：硬件高效的 Transformer 主干设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdc52w/r_lowformer_hardware_efficient_transformer/</link>
      <description><![CDATA[吞吐量和延迟优化的骨干架构，具有硬件高效的宏和微设计。它还具有简单高效的多头自注意力适应性。    提交人    /u/Mr_Fragwuerdig   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdc52w/r_lowformer_hardware_efficient_transformer/</guid>
      <pubDate>Tue, 10 Sep 2024 07:26:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否存在一个开放的、真正的多模式 LLM，而不是一个玩具模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fd5hp7/d_is_there_an_open_truly_multimodal_llm_that_isnt/</link>
      <description><![CDATA[嗨， 自 gpt-4o 问世以来已经过去了几个月，我还没有找到一个等效的开放权重模型。Gemini 甚至在它之前就出现了，它有多模态输入。 我所说的等效，是指早期融合和多模态的模型，其中视觉和音频被标记化并与文本标记共享相同的嵌入空间。我并不一定意味着它必须具有相同的功能或准确性。 据我所知，Meta 的变色龙是最接近的匹配，但它是双模态的（不支持音频）并且只能生成文本。 所以我的问题是：是否存在一个真正的多模态模型，我们可以在本地下载和调整？    提交人    /u/Amgadoz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fd5hp7/d_is_there_an_open_truly_multimodal_llm_that_isnt/</guid>
      <pubDate>Tue, 10 Sep 2024 00:51:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 08 Sep 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>