<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 23 Oct 2024 01:14:58 GMT</lastBuildDate>
    <item>
      <title>Meta AI（FAIR）最新论文将系统 1 和系统 2 思维融入推理模型。[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9v7ag/meta_ai_fair_latest_paper_integrates_system1_and/</link>
      <description><![CDATA[Meta AI (FAIR) 最新论文将系统 1 和系统 2 思维整合到推理模型中。 基本上，它引入了术语“Dualformer”，将系统 1（快速思维）和系统 2（慢速思维）整合到 Transformer 中以提高其推理能力。高级想法是使用“随机跟踪”训练模型，随机丢弃部分推理标记。这种方法提高了模型的推理速度、准确性和多样性。它还使模型能够以可控的方式执行系统 ​​1 和系统 2 思维。  论文链接在此： https://arxiv.org/html/2410.09918v1    提交人    /u/Proof-Raise-9151   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9v7ag/meta_ai_fair_latest_paper_integrates_system1_and/</guid>
      <pubDate>Tue, 22 Oct 2024 22:38:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 需要 Arxiv cs.LG 上的认可</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9ufjg/r_need_endorsement_on_arxiv_cslg/</link>
      <description><![CDATA[这是我的论文： https://drive.google.com/file/d/1WsLun1PoNcXkcisu18tel5rNtEZOLqAe/view?usp=sharing 如果您知道任何可以在 cs.LG 上做到这一点的人，请告诉我 Rick Ferreira 请求您的支持，将文章提交到 arXiv 的 cs.LG 部分。若要告诉我们您愿意（或不愿意） 为该人背书，请访问以下网址： https://arxiv.org/auth/endorse?x=OYCPH9 如果该网址对您不起作用，请访问 http://arxiv.org/auth/endorse.php 并输入以下六位字母数字字符串： 背书代码：OYCPH9    提交人    /u/Dry-Ad1164   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9ufjg/r_need_endorsement_on_arxiv_cslg/</guid>
      <pubDate>Tue, 22 Oct 2024 22:03:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 决策转换器中的标记和嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9tto6/d_token_and_embedding_in_decision_transformers/</link>
      <description><![CDATA[当我尝试实现我的第一个决策转换器时，我在实现的第一个阶段就卡住了。 text2text 转换器需要对文本进行标记，该文本在训练阶段输入到转换器中。由于许多不同的标记化策略，输入测试被分为标记，例如用整数值表示。 但在决策转换器的情况下，没有可以标记为整数的文本序列。在 DT 中，有状态、动作、奖励和待完成奖励，它们都是浮点数，而且大多是数组而不是标量（唯一的例外是奖励和 RtG）。 所以我的问题是：标记化过程是什么样的？在这种情况下，是否存在标记化？    提交人    /u/WilhelmRedemption   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9tto6/d_token_and_embedding_in_decision_transformers/</guid>
      <pubDate>Tue, 22 Oct 2024 21:37:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将 OCR 模型从 LTR 转换为 RTL</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9tl9o/p_converting_an_ocr_model_from_ltr_to_rtl/</link>
      <description><![CDATA[大家好，我正在寻找能够帮助我将我制作的 OCR 模型转换为适用于 RTL 语言（阿拉伯语、波斯语）的 Python 开发人员。我构建的模型仅适用于 LTR。现在我想更改它。    提交人    /u/LahmeriMohamed   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9tl9o/p_converting_an_ocr_model_from_ltr_to_rtl/</guid>
      <pubDate>Tue, 22 Oct 2024 21:26:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们构建了一个多云 GPU 容器运行时</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9mrcj/d_we_built_a_multicloud_gpu_container_runtime/</link>
      <description><![CDATA[想要分享我们的开源容器运行时 - 它专为跨云运行 GPU 工作负载而设计。 https://github.com/beam-cloud/beta9 与主要用于在一个云中运行一个集群的 Kubernetes 不同，Beta9 旨在在许多不同的云中的许多集群上运行工作负载。想要在家中的 AWS、GCP 和 4090 设备之间运行 GPU 工作负载吗？只需在每个 VM 上运行一个简单的 shell 脚本以将其连接到集中控制平面，您就可以在这三个环境之间运行工作负载。 它还处理分布式存储，因此文件、模型权重和容器映像都缓存在靠近用户的 VM 上，以最大限度地减少延迟。 我们已经构建 ML 基础设施一段时间了，但最近决定将其作为一个开源项目启动。如果您有任何想法或反馈，我将非常感激听到您的想法🙏    提交人    /u/velobro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9mrcj/d_we_built_a_multicloud_gpu_container_runtime/</guid>
      <pubDate>Tue, 22 Oct 2024 16:45:26 GMT</pubDate>
    </item>
    <item>
      <title>如何开展科学项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9kakg/how_to_run_science_projects/</link>
      <description><![CDATA[我根据在 FAANG 公司工作 9 年以上的经验，总结了自己运行 ML 和科学项目的经验。它涵盖了常见内容，例如解决模糊的业务问题、找到合适的利益相关者、设置指标以及完成任务。我还分享了一些关于哪些方法有效（哪些方法无效）的个人故事，尤其是当利益相关者意见不一致时。如果您做过类似的工作或采用不同的方法，我很想听听您的想法！ https://dzidas.com/ml/2024/10/22/implementing-data-science-projects/    提交人    /u/kafka399   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9kakg/how_to_run_science_projects/</guid>
      <pubDate>Tue, 22 Oct 2024 15:03:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] LLM 研究框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9k0te/d_r_llms_frameworks_for_research/</link>
      <description><![CDATA[我是人工智能和自然语言处理专业的博士生，目前正在用法学硕士 (LLM) 启动一个新的研究项目。 这一次，我不会主要使用 HuggingFace 和 Pytorch 从头开始​​编写所有代码，而是想使用一种流行的框架（如 LangChain、LlamaIndex 等）。 这背后的动机是，理想情况下，我想学习使用这些工具来获得更紧凑、更有条理的代码库，以便我可以轻松添加部分内容以包括 RAG、Agentic 工作流等。 我还对一种有效的方法来加载模型和进行推理感兴趣。 根据您的经验，众多可用的框架中哪一个最适合研究目的？而且，您是否使用框架，还是每次开始新项目时都从头开始编写所有代码？    提交人    /u/Debonargon   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9k0te/d_r_llms_frameworks_for_research/</guid>
      <pubDate>Tue, 22 Oct 2024 14:51:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 世界上*最不*流行的 LLM 评估工具新发布！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9j2e7/p_new_release_for_the_worlds_least_popular_llm/</link>
      <description><![CDATA[      刚刚发布了 Ollama Grid Search 的新版本，所有主要平台均可下载。 据 Discord 上的一些聪明人说，它很“可爱”而且“可笑”，所以一定要确保不要错过这个乐趣！ 如果您不知道这是什么，它是一个桌面开源应用程序，可让您：  在单个操作中评估多个提示和模型组合 评估多种参数组合以验证对推理输出的影响。  https://preview.redd.it/lcqqqco9fbwd1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=e8db16b7f980acbfd96adb65ccb6633cf52d3e93 如果您已经是用户（谢谢！），以下是 0.6.0 版本的更新日志： 已添加  已添加 UI 控件以重新运行过去的实验。 已添加控件以删除实验文件。 添加了将推理文本复制到剪贴板的按钮。  已更改  移动“重新加载”图标以改善布局。 提高了实验检查 UI 的可读性。 简化了状态管理。  修复  修复 HMR 无法在 MacOS 上运行的问题（当然正在开发中）。     提交人    /u/grudev   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9j2e7/p_new_release_for_the_worlds_least_popular_llm/</guid>
      <pubDate>Tue, 22 Oct 2024 14:10:22 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 用于创建富有表现力的视频语音的最佳文本转音频语音 API？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9fhg7/discussion_best_text_to_audio_voice_api_for/</link>
      <description><![CDATA[我正在寻找最佳文本转语音 API 的推荐，我主要关注 OpenAI、11labs、Google Voice 和 Amazon polly。 因此，如果您知道其中任何最适合我的用例的 API，那就太好了。 如果您有使用这些 API 的经验，请分享。或者，如果您知道任何其他类型的推荐 API，请在评论中告诉我。 谢谢。    提交人    /u/pushkarsingh32   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9fhg7/discussion_best_text_to_audio_voice_api_for/</guid>
      <pubDate>Tue, 22 Oct 2024 11:07:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于 RoPE 的 LLM 如何学习注意力集中点（或编码绝对位置）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g8yurr/r_how_do_ropebased_llms_learn_attention_sinks_or/</link>
      <description><![CDATA[我最近重新阅读了“注意力接收器”论文（链接），并开始思考 LLM 如何管理注意力接收器。 注意力接收器的概念描述了 LLM 为初始标记分配不成比例的高注意力分数的现象，而不管它们的语义值如何。 这里有一个悖论：最先进的开放式 LLM 通常采用 RoPE（旋转位置嵌入）进行位置编码。由于 RoPE 仅对相对位置进行编码，因此令人费解的是模型如何一致地识别绝对初始标记并为其分配高度注意力。您对这种行为可能如何出现或解释有什么想法吗？    提交人    /u/StraightSpeech9295   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g8yurr/r_how_do_ropebased_llms_learn_attention_sinks_or/</guid>
      <pubDate>Mon, 21 Oct 2024 19:46:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 修复 Nightly transformers 中的梯度累积错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g8ymrn/r_gradient_accumulation_bug_fix_in_nightly/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g8ymrn/r_gradient_accumulation_bug_fix_in_nightly/</guid>
      <pubDate>Mon, 21 Oct 2024 19:37:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2024 焦点中的潜在抄袭：Shengjie Luo 和 Tianlang Chen 的“Gaunt Tensor Products”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g8rk2j/d_potential_plagiarism_in_iclr_2024_spotlight/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g8rk2j/d_potential_plagiarism_in_iclr_2024_spotlight/</guid>
      <pubDate>Mon, 21 Oct 2024 14:52:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] RWKV-7：无需注意，超越强大的 Modded-GPT 基线（使用 Muon 优化器的基线），同时仅使用 headsz 64</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g8qsea/r_rwkv7_attentionfree_and_surpassing_strong/</link>
      <description><![CDATA[      大家好。 RWKV-7（100% RNN 且无注意力）可以超越强大的 Modded-GPT 基线（带有 Muon 优化器的基线，目前在推特上流行）。 训练代码和日志：https://github.com/BlinkDL/modded-nanogpt-rwkv 如果使用更大的 headsz，它可以达到损失 3.26xx。 但是我当前的实现效率很低。优化后，可能可以达到 ctx1k 下 Modded-GPT 速度的 85%（或比 ctx4k 下 Modded-GPT 更快）。欢迎任何帮助:) https://preview.redd.it/48m3lsvkb4wd1.png?width=873&amp;format=png&amp;auto=webp&amp;s=647d86ed47d40a4f742ed9512a835dee41069e4f  强大的 GPT 基线： https://preview.redd.it/h2ckr31mb4wd1.png?width=584&amp;format=png&amp;auto=webp&amp;s=b667bfbc50298f8335a889b85c55f68ee8db38a5  RWKV-7 摆脱了“线性注意力”设计以实现更高的性能：） https://preview.redd.it/ijyz0sgnb4wd1.png?width=1233&amp;format=png&amp;auto=webp&amp;s=f413d0e7bcd3a76c5e788f2ca231a37706b24345    提交人    /u/bo_peng   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g8qsea/r_rwkv7_attentionfree_and_surpassing_strong/</guid>
      <pubDate>Mon, 21 Oct 2024 14:18:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</guid>
      <pubDate>Sun, 20 Oct 2024 15:00:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>