<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 13 Jan 2024 15:12:52 GMT</lastBuildDate>
    <item>
      <title>[D] 避免机器学习项目中常见错误的资源？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195q259/d_resources_for_avoiding_common_mistakes_in/</link>
      <description><![CDATA[通常有管理者或企业家类型认为“AI”是一种技术。作为一个神奇的解决方案，然后数百万美元被浪费，因为他们不明白该解决方案有多么脆弱，如何需要更多的数据来创建泛化的解决方案，对偏见的敏感性，所需的培训数据等等。哪些可访问的信息是否可以帮助人们了解项目的实用性以及成功和道德成果所涉及的内容？   由   提交/u/Neuro-AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195q259/d_resources_for_avoiding_common_mistakes_in/</guid>
      <pubDate>Sat, 13 Jan 2024 15:11:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于可解释性和量子计算的快速问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195plsr/d_quick_question_about_interpretability_and/</link>
      <description><![CDATA[如果可解释性是关于理解模型如何工作以及模型在概率论和量子计算上的工作原理使我们能够进行更多概率计算，那么这两种技术的发展将如何相互影响？ 不知道这个问题是否有意义，我对此非常陌生，才刚刚开始我的机器学习学习之旅 - 我正在阅读 Rosenblatt 关于感知器的论文，并不断遇到推特讨论中的可解释性和量子计算，所以我想我会问 如果你们也可以推荐任何资源，我应该检查一下这是否激起了我的兴趣，那就太好了    由   提交 /u/Several-Equivalent11   /u/Several-Equivalent11 reddit.com/r/MachineLearning/comments/195plsr/d_quick_question_about_interpretability_and/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195plsr/d_quick_question_about_interpretability_and/</guid>
      <pubDate>Sat, 13 Jan 2024 14:49:56 GMT</pubDate>
    </item>
    <item>
      <title>关于本科生如何进入机器学习行业的建议？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195n86q/tips_on_how_an_undergrad_student_can_break_into/</link>
      <description><![CDATA[嗨， 我对 ML 和 CV 充满热情已经有一段时间了。问题是，在我国，每个在该领域招聘学生职位的地方都是针对硕士生的。可以这么说，我很想就如何迈出第一步提出建议。 就背景而言，我是本科二年级学生，正在学习 Comp。科学，在以色列。 我毫不怀疑我可以在其他编程领域取得成功，并慢慢走向机器学习，但我希望第一份工作能够处理这个问题，即使它只是在与机器学习相关的事情上拍马屁和提供帮助，而不直接处理它。 可以说，我想踏入机器学习的大门。我已经花了很多时间观看有关 ML 如何工作的视频，并且只要有时间，我都会学习 Andrew Ng 的机器学习简介课程（自 10 月份以来，该课程已不再存在，但希望到 7 月份我可以再次专注于该课程） ），并且已经在我的大学选择了诸如统计学之类的选修课程，以帮助我进一步朝这个方向发展。 在空闲时间，我开始涉足诸如使用数据集和制作梯度下降函数之类的事情通过 Jupyter 等，最近开始使用 scikit 等库涉足 Kaggle 上的数据集。但考虑到我在求职过程中所看到的情况，所有这些对于该领域的雇主来说并没有多大价值。 有什么建议可以让我在这个特定的领域让自己对雇主更具吸引力尽管我基本上没有经验？我可以使用多种语言和框架进行编程（例如，作为全栈开发人员在一家初创公司实习，通过 React Native 帮助制作了一个生产应用程序），并且大学教授的大多数编程都是我多年来已经了解的内容我自学了如何开发电脑游戏，我主要只是在数学课程中学习。 如果它能直接有助于在这个领域建立职业生涯并学到很多东西，我不在乎得到垃圾报酬。  如有任何建议，我们将不胜感激   由   提交/u/xland44  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195n86q/tips_on_how_an_undergrad_student_can_break_into/</guid>
      <pubDate>Sat, 13 Jan 2024 12:44:38 GMT</pubDate>
    </item>
    <item>
      <title>[N]人工智能很有前途，但它的幻觉永远不会停止 - The Vaisheshika Times</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195moiv/n_ai_is_promising_but_its_hallucination_will/</link>
      <description><![CDATA[ 由   提交/u/Brave-Ad-6868   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195moiv/n_ai_is_promising_but_its_hallucination_will/</guid>
      <pubDate>Sat, 13 Jan 2024 12:12:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我可以使用我的服务器来加速 ML 工作流程吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195mggo/d_can_i_use_my_server_to_accelerate_ml_workflow/</link>
      <description><![CDATA[大家好，我有一台具有以下规格的 HPE Proliant DL360p Gen9：  2 x Intel Xeon E5-2680V4 （14 核，28 线程 x 2） 128 GB ECC RAM DDR4  4 TB HDD 15K IN RAID10 10GbE 网卡   我正在考虑为其购买专用 GPU，但我看到与其兼容的 GPU 功率非常有限（Tesla M4、NVIDIA Quadro P4000）。这些 GPU 有点旧，仅适用于小型推理。 尽管我将其用于 Docker 和 Kubernetes，但我在日常 ML 工作流程中经常使用它们，您认为我可以使用它们的处理能力吗？ CPU（我见过非常强大）以某种有用的方式还是浪费时间？如果您认为为其购买专用 GPU 是个好主意，请告诉我。 谢谢 Giacomo   由   提交/u/Pleasant_Ad_6267   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195mggo/d_can_i_use_my_server_to_accelerate_ml_workflow/</guid>
      <pubDate>Sat, 13 Jan 2024 11:58:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI、Google 和 Meta 等领先的人工智能研究组织如何跟踪和管理他们的大规模人工智能实验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195lwlh/d_how_do_leading_ai_research_organizations_like/</link>
      <description><![CDATA[我非常有兴趣了解 OpenAI、Google 和 Meta 的研究人员用来跟踪他们的 AI 实验的工具和技术。这包括他们如何管理不同版本的人工智能模型以及在这些模型上运行的各种测试等事物。我很想知道他们使用哪些特定工具来完成这些任务。此外，如果能够了解他们是否遵循任何推荐的方法或最佳实践来有效地组织和处理这些实验运行，那就太好了。由于我也是一名研究人员，这些信息对我来说非常有用。   由   提交 /u/Few-Pomegranate4369    reddit.com/r/MachineLearning/comments/195lwlh/d_how_do_leading_ai_research_organizations_like/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195lwlh/d_how_do_leading_ai_research_organizations_like/</guid>
      <pubDate>Sat, 13 Jan 2024 11:21:51 GMT</pubDate>
    </item>
    <item>
      <title>[D]假设：模型中向量的定向定位（例如：ViT-L/14）可能会带来新的可能性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195gyqe/d_hypothesis_directed_positioning_for_the_vectors/</link>
      <description><![CDATA[   我最近一直在研究 CLIP 模型 ViT-L/14，以检查数据的样子。 我注意到，即使对于“接近”的事物的定义也可能是这样的。彼此之间的接近度本质上几乎是随机的。我猜测，在训练过程中，值通过随机运动进行调整，直到“应该”的对象出现。在一起，降落在一个被认为“足够接近”的 n 空间位置，事情就到此结束。  但这使得坐标的随机性非常令人不满意。其示例是比较“cat”在768空间中的位置和“cat”在768空间中的位置。 vs “小猫”这里：  https://preview .redd.it/23v9ux27b5cc1.png?width=569&amp;format=png&amp;auto=webp&amp;s=895f80682a3f6f321bcb8a2482749649c1074c8b 它们的欧几里德距离为 7.22859525680542  什么如果真正属于“密切”的对象是在一起...实际上在大多数维度上都在一起？ 如果可以重新组织数据集，以便真正相似的对象在 768 空间中更多地反映这一点会怎样？  也就是说，如果“cat”是和“小猫”只有几个尺寸不同，其他的都一样？  在我看来，这可能会带来一些有趣的可能性。   由   提交/u/lostinspaz   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195gyqe/d_hypothesis_directed_positioning_for_the_vectors/</guid>
      <pubDate>Sat, 13 Jan 2024 05:50:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] UnIVAL：图像、视频、音频和语言任务的统一模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195eulx/r_unival_unified_model_for_image_video_audio_and/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2307.16184 OpenReview：https:// /openreview.net/forum?id=4uflhObpcp 代码：https： //github.com/mshukor/UnIVAL 检查点：https://github.com/mshukor/UnIVAL/blob/main/checkpoints.md 项目页面：https://unival-model.github.io/ 演示：https://huggingface.co/spaces/mshukor/UnIVAL 视频：&lt; a href=&quot;https://www.youtube.com/watch?v=mYOun92st08&quot;&gt;https://www.youtube.com/watch?v=mYOun92st08 摘要：  大型语言模型（LLM）使对通才智能体的雄心勃勃的追求不再是一个幻想。构建此类通用模型的一个关键障碍是任务和模式的多样性和异质性。一种有希望的解决方案是统一，允许在一个统一的框架内支持无数的任务和模式。虽然在海量数据集上训练的大型模型（例如 Flamingo（Alayrac 等人，2022））可以支持两种以上的模态，但当前的中小型统一模型仍然仅限于 2 种模态，通常是图像文本或视频-text.我们要问的问题是：是否有可能高效地构建一个能够支持所有模态的统一模型？为了回答这个问题，我们提出了UnIVAL，朝着这个雄心勃勃的目标又迈进了一步。在奇特的数据集大小或具有数十亿参数的模型上，~ 0.25B 参数 UnIVAL 模型超越了两种模式，并将文本、图像、视频和音频统一到单个模型中。我们的模型基于任务平衡，在许多任务上进行了有效的预训练和多模态课程学习。UniVAL 在图像和视频文本任务中显示出与现有最先进方法相比的竞争性能。从图像和视频文本模态中学习的特征表示，允许模型在微调时实现竞争性能音频文本任务，尽管没有经过音频预训练。得益于统一模型，我们提出了一项通过对不同多模态任务训练的模型进行权重插值来进行多模态模型合并的新颖研究，展示了它们特别是对于分布外泛化的好处。最后，我们通过展示任务之间的协同作用来激励统一。模型权重和代码在这里发布：这个 https URL.    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195eulx/r_unival_unified_model_for_image_video_audio_and/</guid>
      <pubDate>Sat, 13 Jan 2024 03:54:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] PASTA：预训练的动作状态转换代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195eh7b/r_pasta_pretrained_actionstate_transformer_agents/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2307.10936 OpenReview： https://openreview.net/forum?id=ciBFYxzpBT https： //openreview.net/forum?id=pxK9MWuFF8 摘要：  自监督学习带来了革命性的各种计算领域的范式转变，包括 NLP、视觉和生物学。最近的方法涉及对大量未标记数据进行预训练 Transformer 模型，作为有效解决下游任务的起点。在强化学习中，研究人员最近采用了这些方法，开发了根据专家轨迹进行预训练的模型。这一进步使模型能够处理从机器人到推荐系统的广泛任务。然而，现有方法主要依赖于针对特定下游应用量身定制的复杂预训练目标。本文对模型进行了全面的研究，称为预训练动作状态转换代理（PASTA）。我们的研究涵盖了统一的方法论，并涵盖了广泛的一般下游任务，包括行为克隆、离线强化学习、传感器故障鲁棒性和动态变化适应。我们的目标是系统地比较各种设计选择，并提供有价值的见解，帮助从业者开发强大的模型。我们研究的主要亮点包括动作和状态的组件级别的标记化、基本预训练目标的使用（例如下一个标记预测或掩码语言建模）、跨多个领域的模型同步训练以及各种微调的应用策略。在这项研究中，开发的模型包含不到 700 万个参数，允许广泛的社区使用这些模型并重现我们的实验。我们希望这项研究能够鼓励进一步研究使用具有第一原理设计选择的变压器来表示 RL 轨迹，并为稳健的策略学习做出贡献。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195eh7b/r_pasta_pretrained_actionstate_transformer_agents/</guid>
      <pubDate>Sat, 13 Jan 2024 03:35:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前最好的文字转语音工具是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195cxim/d_what_is_the_best_texttospeech_tool_currently/</link>
      <description><![CDATA[大家好，我需要一个听起来完全像人声的 TTS 工具。我想用它来编辑我的一些 YouTube 视频，更具体地说，上传我自己选择的语音样本并从中生成良好的结果。我看到周围有很多 TTS 平台。你推荐哪一个？我希望这不是一个过分的要求。我将非常感激。 提前致谢。   由   提交 /u/FateRiddle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195cxim/d_what_is_the_best_texttospeech_tool_currently/</guid>
      <pubDate>Sat, 13 Jan 2024 02:18:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 适合面试的 ML 工程题库好吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/</link>
      <description><![CDATA[我一直在研究 ML 工程面试（并做了一些），我意识到“了解偏见”的常见建议，方差、交叉折叠验证等”。都是错的。顶级公司要求你使用 Pytorch/numpy 编写简单的代码。所以问题是这样的：“编写一个神经网络来解决 X 问题”或者“编写一个神经网络来解决 X 问题”。或“使用 numpy 实现 k-means”。 考虑到这种情况，我认为通过做一堆编码问题来准备这些面试会更有用。 我想知道这里的人是否可以分享他们在 ML Eng 面试中遇到的一些编码问题，或者向我指出好的 Leetcode 风格的 MLEng 题库？  &amp;# 32；由   提交 /u/lisp-cloj    reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/</guid>
      <pubDate>Fri, 12 Jan 2024 23:00:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 以最小的开销从大型 GPU 扩展到仅 CPU 的最便宜方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19549sd/d_cheapest_way_to_scale_up_and_down_from_a_large/</link>
      <description><![CDATA[当我离开家几周并且远离我相当强大的 GPU 桌面时，我有很多业余爱好者项目需要处理. 我正在寻找最简单（也是最便宜）的方法来获得一台可以通过 SSH 连接的计算机，并且：  进行一些编码/调试（花费 80 % 的时间） 以批处理模式运行一些相当小众的 ML 软件，需要低端 GPU (10%) 启动强大的 48 GB GPU 来处理LLM（10%）  考虑到设置/配置开销，我想做的是将 60 GB 存储附加到 EC2.micro，安装完整的 Lambdalabs 容器（Nvidia驱动程序、CUDA、Pytorch 等），将其用于 #1，然后将该启动驱动器交换到更多计算或 GPU 密集型计算机，以便在我准备好时运行 #2 或 #3 几个小时。 &lt; p&gt;单个配置良好的启动驱动器可以在截然不同的计算配置中工作吗？有没有最适合此类事情的云提供商？ 特别是，当我不积极做某事时，我希望能够尽可能降低费用（我可以支付一点存储费用。 我很乐意与 LamdaLabs 这样的公司合作，但他们没有廉价的低端 CPU 实例。 是否有更智能的（不是使用 Ansible 等疯狂的高努力）方法来维护 SSH 和 go 设置，使其能够在截然不同的规模计算中工作？  &amp; #32；由   提交/u/gofiend  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19549sd/d_cheapest_way_to_scale_up_and_down_from_a_large/</guid>
      <pubDate>Fri, 12 Jan 2024 20:01:27 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待 Yann Lecun 关于 ML 的有争议的观点？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/</link>
      <description><![CDATA[      Yann Lecun 有一些有争议的观点关于 ML 的看法，他并不羞于分享。他写了一篇立场文件，名为“通往自主机器智能的途径”。不久以前。此后，他也就此发表了很多演讲。这是屏幕截图 ​ https://preview.redd.it/xxmxgrdk02cc1.jpg?width=1581&amp;format=pjpg&amp;auto=webp&amp;s=4a7e98f5a41f2e454e2e33881f2 df93c7287d09b 来自&lt; a href=&quot;https://www.youtube.com/watch?v=OKkEdTchsiE&quot;&gt;一个，但我看过几个 - 它们很相似，但不完全相同。以下并不是所有演讲的摘要，而只是他对 ML 现状的批评，根据记忆进行解释（他还谈论了 H-JEPA，我在这里忽略了）：  &lt; li&gt;法学硕士无法商业化，因为内容所有者“喜欢reddit”会起诉（奇怪的是，鉴于最近的《纽约时报》诉讼，这是有先见之明的） 当前的机器学习很糟糕，因为与人类相比，它需要大量的数据（有两种截然不同的可能性：算法本身很糟糕，或者人类只是在童年时期进行了更多的“预训练”） 规模化是不够的 自回归法学硕士注定会失败，因为任何错误都会让你偏离正确的道路，并且随着输出数量的增加，不犯错误的概率很快接近 0 LLM 无法推理，因为它们只能执行有限数量的计算步骤 连续域中的建模概率为错误的，因为你会得到无限的梯度 对比训练（如 GAN 和 BERT）是不好的。您应该进行正规化训练（例如 PCA 和稀疏 AE） 生成建模是误导性的，因为世界的大部分内容都是不可预测或不重要的，不应该由智能系统建模 人类通过被动视觉观察了解他们对世界的大部分了解（我认为这可能与先天失明的人可能非常聪明的事实相矛盾） 你不&#39;智能行为不需要巨大的模型，因为老鼠只有数千万个神经元，就超越了当前的机器人人工智能    由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/</guid>
      <pubDate>Fri, 12 Jan 2024 19:14:35 GMT</pubDate>
    </item>
    <item>
      <title>我们今天在人工智能中拥有的大多数东西将在 6 个月内变得无关紧要 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/194ap95/most_things_we_have_today_in_ai_will_be_a/</link>
      <description><![CDATA[      当您构建“薄包装器”时，这是不幸的情况。基础模型之上的产品。 去年，我们为客户构建了一个定制的稳定扩散管道，在 2 个月内进行了大量实验，找出了针对边缘情况的定制解决方案，并交付了一个可以将集体照片转换为圣诞礼品卡。 今天，阿里巴巴推出了 ReplaceAnything，我可以在一分钟内构建出同样的东西，但质量可能会下降 10%（！），因为我们的团队花了几周时间才完成了几个几个月前。 这个领域的进展是疯狂的。 幸运的是，这只是“那些有趣的小事情之一”。我们为客户建立的公司。 我无法想象建立这些公司之一的压力，尤其是如果你筹集了风险资金。 时间在流逝，你每天都在滴答作响。技术护城河越来越少。 这就是为什么您需要全力以赴尽快创建长期、可持续的数据护城河。 https://preview.redd.it/7a67geld8vbc1.png?width=722&amp;format= png&amp;auto=webp&amp;s=c4dc336cf2635c178ad6ccfc65d10292f5c881f4   由   提交 /u/BootstrapGuy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/194ap95/most_things_we_have_today_in_ai_will_be_a/</guid>
      <pubDate>Thu, 11 Jan 2024 19:52:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>