<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 02 Nov 2024 21:14:37 GMT</lastBuildDate>
    <item>
      <title>[N] Quantum Machines 和 Nvidia 利用机器学习来更接近纠错量子计算机</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gi5ohq/n_quantum_machines_and_nvidia_use_machine/</link>
      <description><![CDATA[一篇基于对 Quantum Machines 和 Nvidia 的采访的文章，介绍他们如何使用强化学习来优化脉冲，提高性能和保真度 https://techcrunch.com/2024/11/02/quantum-machines-and-nvidia-use-machine-learning-to-get-closer-to-an-error-corrected-quantum-computer/    提交人    /u/MeltingHippos   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gi5ohq/n_quantum_machines_and_nvidia_use_machine/</guid>
      <pubDate>Sat, 02 Nov 2024 20:31:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] NCA 对潜在模型的模拟（具有意义推理能力的编码器-解码器模型）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gi4xc2/d_nca_simulation_over_the_latent_encoderdecoder/</link>
      <description><![CDATA[大家好，我只是提出一个直觉，我必须评估这个领域……我想，如果我们想制作一个可以在不到 100M 个参数中推理和思考的语言模型，也许就是嵌入尽可能多的有用的宇宙中预先存在的机制。换句话说，我们停止制作语言模型，现在我们的目标是制作一个意义模型。我们回到编码器/解码器架构，两者都绑定在一起以鼓励双向映射空间。现在这是关键因素！中间的潜在变量具有位置编码，因此它是一个 3D 体积。潜在的 3D 位置被检索并用于执行场操作，因此内存需求是潜在变量的形状乘以 N 个模拟场。表示根据物理耦合变形，并反馈到 NCA（神经细胞自动机）。几年前，NCA 还未被人注意到，实际上它只是一个学习过的感知 Sobel 过滤器，它可以学习将信息存储到每个单元的隐藏状态中。我还看到，NCA 可以被教导解决迷宫问题，它是如何做到的真的很有趣。以这种方式，中间的潜在空间现在是一个灵活的体积表示空间，具有隐藏的维度和场方程，这些方程通过自然熵和流动为其提供能量，清晰的路径让单词移动并减少能量。不是对语言进行建模，而是尝试使用语言标记作为全模态模拟运算符，其中全模态性在其几何 3D 缩减中实现。也许这就是大脑的工作方式？它捕捉微观尺度上的现实现象，并有选择地移除和过滤它们，以创建消除歧义的想象空间？人类语言源自我们的欧几里得几何现实。每个词，甚至我在上一句中使用的“Descend”这个词……每个句子都有欧几里得形式。因此，如果我们创建一个欧几里得模拟空间，语言应该自动调节这个模拟并给它贴上标签？通过这种方式，我们可以创建任意数量的表示来连接模态。换句话说，当你说“X 高于 Y”时，你实际上会看到两个粒子在潜在的多场想象中的某个地方实例化，其中一些“上方”的结合粒子取决于意义空间结构的深度和分辨率。我们创建一个模拟，一个连续的细胞自动机，它本身永远不会因为过于复杂的超参数而绑定或获得稳定的牵引力，我们使用语言和数据集作为正则化！颠覆整个训练范式！现在，推理是免费的，很容易分辨出模型何时不再想思考，因为表示已经达到稳态/收敛。文本用于介绍结构和几何熵融入潜在表示，NCA 就像一个动态降噪器和“自搜索自动编码器”，学习进化规则，永远寻找更好的表示和新的优化。在升级到科学材料之前，需要先在更简单的数据集上收敛。它必须逐步组装和建模宇宙，也可能不这样做。也许你会分别训练编码器/解码器和 NCA，冻结一个而另一个保持热度。它可能具有极强的上下文学习能力。你怎么看？有很多广泛的想法，但我觉得给模型一个带有自然物理的小“游戏空间”是正确的做法。基于此架构的图像生成模型可以进行极其复杂的合成！语言模型将具有真实的想象空间，使它们能够以几何方式解决问题，模拟物体/粒子/规则等的简化表示和嵌入。至少，编码器/解码器 LLM 中某种位置基础的潜在特征似乎是一个值得研究的有力事物。    提交人    /u/ryunuck   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gi4xc2/d_nca_simulation_over_the_latent_encoderdecoder/</guid>
      <pubDate>Sat, 02 Nov 2024 19:57:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在法学硕士课程中灌输知识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gi27ev/p_instilling_knowledge_in_llm/</link>
      <description><![CDATA[大家好！ 我有一个信息语料库（文本），我希望我的基础模型能够学习语料库中包含的知识，这样我就可以简单地根据微调模型进行推断，而不是执行 RAG。我该怎么做？对于我读过的所有文档，它都是关于标记数据集（在我的情况下是问答）。有没有办法在 LLM 中灌输知识？ 提前致谢。    提交人    /u/mulberry-cream   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gi27ev/p_instilling_knowledge_in_llm/</guid>
      <pubDate>Sat, 02 Nov 2024 17:54:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML4H 回应和审查流程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghz1b7/d_ml4h_response_and_review_process/</link>
      <description><![CDATA[我刚刚收到一篇提交给 ML4H 的论文的最终裁决，它被拒绝了（审稿人给出了 5 [4]、5 [3]、2 [4]、5 [2]）。我得到了一个非常平淡的回复：“一位自信的审稿人拒绝了我。这个主题确实很重要。我会接受它作为发现海报。”。  拒绝审稿人的唯一抱怨是这些想法对医疗保健领域没有意义（除了他称赞这篇论文在技术上很有趣而且很合理）。除此之外，他/她还写道，如果我们（作者）能提供理由，他愿意改变分数。我们写了反驳，但我们没有看到任何其他评论？有什么方法可以理解为什么反驳不够充分？（我习惯与审稿人打乒乓球）。此外，主席写道，主题很重要，这是低分的唯一原因吗？ 有没有办法对决定提出上诉？     提交人    /u/GeneralSkoda   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghz1b7/d_ml4h_response_and_review_process/</guid>
      <pubDate>Sat, 02 Nov 2024 15:31:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医学 AI：顶级 LLM 研究论文/模型（2024 年 10 月 26 日至 11 月 2 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghx268/d_last_week_in_medical_ai_top_llm_research/</link>
      <description><![CDATA[   上周医学 AI：顶级 LLM 研究论文/模型（2024 年 10 月 26 日至 11 月 2 日） 本周医学 AI 论文：  Google 推出 MDAgents：用于医学决策的 LLM 自适应协作  本文介绍了MDAgents 是一个多代理框架，它为 LLM 分配协作结构以完成复杂的医疗任务，模仿现实世界的医疗决策。   医学 LLM &amp;其他模型：  Matchmaker：使用 LLM 进行模式匹配  本文介绍了 Matchmaker，这是一种用于模式匹配的组合语言模型程序，可解决数据源中的结构和语义异质性挑战。  UltraMedical：专门的生物医学模型  本文介绍了 UltraMedical，它是一组跨多个 LLM 的高质量手动和合成数据集，带有偏好注释，可用于生物医学应用。  ZALM3：视觉语言医学对话  本文介绍了 ZALM3，这是一种零样本策略，用于改善多轮多模式医学对话中的视觉语言对齐，解决在线咨询中患者提供的图像质量差的挑战。  EchoFM：超声心动图基础模型  本文介绍了EchoFM 是超声心动图视频的基础模型，采用具有时空一致性掩蔽和周期驱动对比学习的自监督学习框架，在 26 个扫描视图和不同成像模式下对超过 290,000 个视频（2000 万帧）进行了预训练。   框架和方法：  FEDKIM：联合医学知识注入 Flex-MoE：灵活模态组合 MAISI：合成医学成像 Cough-E：边缘隐私检测 MassSpecGym：分子识别  医学 LLM 应用：  DiaMond：多模态痴呆症诊断 LLM-Forest：健康数据归因 医学多模式视觉基础 与法学硕士 (LLM) 的临床证据综合  医学法学硕士 &amp;基准：  超越 H&amp;E 的组织病理学模型 心理健康咨询法学硕士 医学数据集重用分析  医疗伦理中的人工智能：  医学教育法学硕士 医学考试问题生成 临床知识图谱集成  .... 完整线程详细信息：https://x.com/OpenlifesciAI/status/1852685220912464066    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghx268/d_last_week_in_medical_ai_top_llm_research/</guid>
      <pubDate>Sat, 02 Nov 2024 13:59:40 GMT</pubDate>
    </item>
    <item>
      <title>[研究] [项目] 寻求公开可用的超声数据集用于卵巢癌检测项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghw3m2/research_project_seeking_publicly_available/</link>
      <description><![CDATA[大家好！ 我目前正在进行一个研究项目，旨在通过应用于超声图像的深度学习来改善卵巢癌的早期检测。现在，我正处于数据集收集阶段，在查找可访问的数据集时遇到了一些挑战。 我遇到了 PLCO 和 MMOTU 数据集：  PLCO 需要项目提案才能访问，我正在考虑，但可能需要一些时间。 MMOTU 提供分割数据，但不包括我的工作所需的全套诊断图像。  在查阅文献后，我注意到许多研究人员使用的临床研究数据集是私人的、特定于医院的患者数据或其他不公开的数据集。 如果这里有人参与过类似的项目或面临过这些挑战，我将非常感谢任何指点！具体来说，我正在寻找：  可公开访问的针对卵巢癌或妇科癌症的超声数据集 可通过作者请求或联系相关组织获得的数据集  提前感谢您分享的任何指导或资源！    提交人    /u/Swimming-Car-6055   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghw3m2/research_project_seeking_publicly_available/</guid>
      <pubDate>Sat, 02 Nov 2024 13:11:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] torch.compile 是否已经终结了 JAX 的案例？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghw330/d_has_torchcompile_killed_the_case_for_jax/</link>
      <description><![CDATA[我喜欢 JAX，但我完全承认你为了性能牺牲了开发的便利性。 我在网上看到一些关于 torch.compile 加速的讨论，但我并不是很了解。JAX 的性能案例现在已经过时了吗，或者令人印象深刻的 GPU 性能是否归因于多 GPU 等其他因素。    提交人    /u/internet_ham   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghw330/d_has_torchcompile_killed_the_case_for_jax/</guid>
      <pubDate>Sat, 02 Nov 2024 13:10:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] Zephyr 的第一个可用版本：JAX 上的新声明 FP NN 框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghthur/p_first_usable_release_of_zephyr_new_declaration/</link>
      <description><![CDATA[编辑标题：JAX 上的新声明式 FP NN 框架 链接在评论中。 您好！我在 JAX 之上创建了一个新的面向函数式编程的框架。它应该使 JAX 上的高级和低级操作变得容易，并有助于使神经网络简短、简单且易读。 它与其他 JAX 框架的主要区别在于，您不会将任何东西子类化，而是按照数学方式编写神经网络，只是一个纯函数 `F(parameters, X, hyperparameters)`。因此，如果您了解神经网络、python 和 jax，那么您可能只需要知道 2 件事： - 一个 trace 函数来帮助您自动生成 `params`（如果您愿意，您可以自己完成此操作）。 `params = trace(model, random_PRNG_key, sample_input_batch)` - `validate` 函数，可以将其视为一种提供 python 形状和其他信息以供检查的方法，但这只有在您需要创建自己的参数时才有用 我最近发布了它的第一个非 alpha 版本。它现在具有通用层：线性、mlp、conv、注意等等。我计划添加更多内容，也许很快会实现论文中的图层。欢迎提出建议。 我个人会将它用于我自己的项目，我希望它对你们有用，特别是那些想要进行面向 FP 的编码的人。请查看评论中的链接，尝试一下；我很乐意听到您的反馈意见。 最后几件事： - 查看 `zephyr.nets` 了解网络和层 - 并且可以在 `zephyr.trace` 找到跟踪    提交人    /u/Pristine-Staff-5250   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghthur/p_first_usable_release_of_zephyr_new_declaration/</guid>
      <pubDate>Sat, 02 Nov 2024 10:29:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 帮助小数据集时间序列和分类数据预测如何改进模型。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghse5o/p_help_with_small_dataset_time_series_and/</link>
      <description><![CDATA[我正在使用一个由 550 个样本和 10 个特征组成的训练数据集进行 kaggle 竞赛我有两个目标要预测一个是基于回归时间序列的而另一个是多个分类目标我已经使用了 XGboost 回归器和分类器并获得了 22 的公开分数这是使用平均绝对误差和分类准确度的回归测量的加权组合我该如何改进我的模型并使其更好     提交人    /u/BigPPMooman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghse5o/p_help_with_small_dataset_time_series_and/</guid>
      <pubDate>Sat, 02 Nov 2024 09:04:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 努力利用 NN 实现声音方向检测（方位角估计）的准确性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghqx2p/p_struggling_to_achieve_accuracy_in_sound/</link>
      <description><![CDATA[我正在开展一个项目，使用神经网络估计声源的方向（方位角），数据来自在（约 2m x 2m）平面上移动的 Khepera III 机器人。该设置使用 Raspberry Pi 跟踪机器人的 x、y 坐标和方向角“a”（相对于声源。直接指向目标声音时为 0），每次机器人向前移动然后稍微旋转（约 5-10 度）直到完全旋转时，都会捕获左右音频样本（左右麦克风相距约 18/19 厘米）。我收集了大约 1200 个音频（1 秒）样本，每个样本都在安静的实验室环境中录制。我的声源每 50 毫秒发出一次啪啪声。坐标系是使用 OpenCV 实现的（通过先前的研究），可以在屏幕上渲染 2D 平面内的位置和移动。它将坐标计算与每帧中的实时对象（机器人和扬声器）跟踪和空间表示对齐。 我的方法 我尝试了两种主要方法：  前馈神经网络 (FFNN)：我尝试仅使用原始音频（通过 librosa.load）进行训练，并且仅对每个方向角度“a”使用平坦的 MFCC。我的 FFNN 过度拟合了训练集并在测试集上挣扎。 长短期记忆 (LSTM)：我将数据重构为时间序列（序列长度为 200、50 等），遵循 Dhwani Desai 和 Ninad Mehendale 的论文&quot;机器人耳：用于检测声音方向的音频信号处理&quot;。他们报告的准确率为 82–95%，但我在目标声音 ±10° 范围内仅达到约 40%。  数据预处理： 规范化：我使用以下方法对整个数据集的特征进行标准化： for c in df_train.columns: mean = df_train[c].mean() stdev = df_train[c].std() df_train[c] = (df_train[c] - mean) / stdev df_test[c] = (df_test[c] - mean) / stdev  输出编码：我还尝试用正弦/余弦变换分解角度“a”，希望降低角度敏感度： def get_sin(A_degrees): return math.sin(math.radians(A_degrees)) def get_cos(A_degrees): return math.cos(math.radians(A_degrees))  超参数和代码：我测试了各种超参数，并使用了 nn.MSELoss() 和 torch.optim.Adam()： 我尝试了 FFNN 和 LSTM 的音频数据的对齐（互相关）和未对齐版本。我使用 PyTorch 实现了这一点。 问题  为什么我的模型与论文中的结果相比表现不佳？我想知道问题是否在于左右之间的数据对齐，因为论文没有指定确切的方法（例如，是否使用了互相关或时间同步记录精度（如以纳秒精度同时记录）。）。或者可能是完全不同的东西。我不确定我错过了什么。     提交人    /u/Decent_Eye_659   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghqx2p/p_struggling_to_achieve_accuracy_in_sound/</guid>
      <pubDate>Sat, 02 Nov 2024 07:05:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 思考法学硕士 - 遵循“思维生成”的指导</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gh9ijv/d_thinking_llms_instruction_following_with/</link>
      <description><![CDATA[https://arxiv.org/abs/2410.10630 Greg Schoeninger u/FallMindless3563，Oxen.ai 首席执行官和 Plain Speak 大师，尝试仅使用模型推理、数据集和微调 API 来重现本文中的发现。 今天太平洋时间上午 10:00、东部时间下午 1:00 开始电话会议，展示结果并深入研究论文。 https://www.oxen.ai/community/?utm_source=x&amp;utm_content=y    由   提交  /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gh9ijv/d_thinking_llms_instruction_following_with/</guid>
      <pubDate>Fri, 01 Nov 2024 16:28:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 获取神经网络“逆”的当前状态是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gh7lc3/d_what_is_the_current_state_on_getting_an_inverse/</link>
      <description><![CDATA[澄清我的意思（我的背景更多的是统计学，但我对一种非线性关系有问题） 假设我有输入（预测变量），例如：[x1,...,x10]，它们本质上都是数值（即没有虚拟变量），以及连续的数值输出 y，并且说我拟合某个 NN 为 y ~ x1 +... x10（我们可以假设一个相对简单的架构，即没有 CNN/RNN） 如果给定 [x2..x10,y]，有没有办法预测 x1 的预期值。 我目前有一些想法，对于一个相对简单的统计模型，它在所有其他变量固定的情况下连续映射 x1 和 y 之间的关系（比如线性回归），这很简单。从神经网络来看，我猜想如果要实现该功能，就需要对结构进行某些条件设置，例如，任何激活函数本身都需要是可逆的。 我想知道这是否是正在积极使用的东西，或者是否有这方面的研究。或者，更好的选择是创建两个模型 y = F(x1,...,x10) 和 x1 = G(x2,.,x10,y) 提前致谢    提交人    /u/Eamo853   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gh7lc3/d_what_is_the_current_state_on_getting_an_inverse/</guid>
      <pubDate>Fri, 01 Nov 2024 15:07:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] TokenFormer：使用标记化模型参数重新思考 Transformer 的扩展</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gh6fut/r_tokenformer_rethinking_transformer_scaling_with/</link>
      <description><![CDATA[  由    /u/MysteryInc152  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gh6fut/r_tokenformer_rethinking_transformer_scaling_with/</guid>
      <pubDate>Fri, 01 Nov 2024 14:16:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 27 Oct 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>