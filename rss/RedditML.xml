<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 19 Dec 2024 09:19:27 GMT</lastBuildDate>
    <item>
      <title>[D] 是否有任何位置编码器允许位置不变编码？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhjhug/d_are_there_any_positional_encoders_that_allow/</link>
      <description><![CDATA[我正在微调一个语言模型，并在数据中引入了一些标记来传达与完成相关的元数据，最终看起来像这样： &lt;|metadata-type-1|&gt;一些随机信息元数据&lt;|metadata-type-2|&gt;一些更随机的元数据&lt;|metadata-type-3|&gt;更多&lt;|output|&gt;... 我真正希望 LLM 生成的东西... 然而，我发现元数据的顺序实际上很重要，特别是，如果元数据以错误的顺序出现很“奇怪”（可能是因为当它们在没有标记的情况下连接起来时不是那么自然），微调实际上做得很差。我怀疑是因为它违反了无标记的正常训练数据的模式？ 这并不太令人惊讶，因为在 RoPE 下，元数据标记在标记标记之间具有彼此的相对信息。我似乎想要一种与元数据顺序无关的编码方案，比如允许我在每个部分之间绘制障碍并使每个部分中的标记看起来距离相等的方案，因此主要考虑相关部分中的标记。换句话说，交换两个元数据部分将产生相同的 KV 状态。 有没有关于这种位置编码方案的研究？我甚至不确定该如何称呼这样的东西，所以任何指针都会非常感激。我也考虑过调整注意力掩码，但最终导致每个部分丢弃来自其他部分的信息，这也不是我想要的。    提交人    /u/lemon-meringue   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhjhug/d_are_there_any_positional_encoders_that_allow/</guid>
      <pubDate>Thu, 19 Dec 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我的模型执行检索增强生成的方式有什么问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhj0zo/d_what_is_wrong_with_the_way_my_model_is_set_up/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhj0zo/d_what_is_wrong_with_the_way_my_model_is_set_up/</guid>
      <pubDate>Thu, 19 Dec 2024 02:51:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 量子机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhhr3c/d_quantum_machine_learning/</link>
      <description><![CDATA[对 Google Willow 和 QML 领域有什么看法？QML 目前在传统 ML 任务或任何一般任务上的应用潜力有多大？启动潜力如何？    提交人    /u/Spursbursdurs   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhhr3c/d_quantum_machine_learning/</guid>
      <pubDate>Thu, 19 Dec 2024 01:44:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在推理过程中，LSTM 是否比 transformer 更快？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhhcu7/d_are_lstms_faster_than_transformers_during/</link>
      <description><![CDATA[Transformers 具有 O(n**2) 并行注意力计算，这让我认为它们在推理过程中会比 O(n) LSTM 慢，但在加速和并行化 Transformers 方面也做了很多工作。  它们如何比较单个数据点和批量数据推理？    提交人    /u/Complex-Media-8074   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhhcu7/d_are_lstms_faster_than_transformers_during/</guid>
      <pubDate>Thu, 19 Dec 2024 01:24:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你想在大学里学习什么 ML/ML 相关课程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhdch4/d_what_would_you_like_in_a_mlmlrelated_course_in/</link>
      <description><![CDATA[嗨！ 我被邀请到大学（实际上不是大学，而是不同的教育系统，他们称之为工程学院，但其实是等价的）讲授 ML 或 ML 相关课程。 该课程总共 22 小时，很短。课程分为理论课和实践课。但我可以更改课时比例。当我说实践时，它更像是他们可以做的一个项目，然后我会对其进行评分。 这不是学生们唯一的 ML 课程，我听说学生们已经有了一门机器学习课程，其中涵盖了机器学习的所有基础知识和一些统计模型（常见的模型，如随机森林、SVM 等），他们还有一门深入的 NLP 课程，所以我认为我不会选择那门课程。 困扰我的是如何平衡理论与实践。我不想肤浅地讲解某些主题，但同时我不知道学生是否值得太深入地讲解某个特定主题。 我不知道做两个主题之类的事情是否是个好主意，每个主题 11 个小时，其中 5 个小时是理论课，6 个小时是实践课。或者我只选择一个主题。 有人建议我向他们展示有关 MLOps 和工具的信息，例如 Git、Docker、Mlflow，基本上只是一点 Mlops、监控模型、如何将它们投入生产等。但我不知道是否值得，我觉得教他们如何使用这些工具太肤浅了，而且网上有很多资源，我猜招聘人员不会期望他们知道这些或有初级职位的经验。 也有人建议我将时间序列作为一门课程，但我不知道深入研究它们是否会让学生感兴趣😅其中有很多数学知识，虽然教授向我保证他们的数学水平很好，但我不知道他们是否会对此感兴趣。 另一个缺点是我无法使用这门课程的计算资源，所以我有点受限。我想如果我在他们的位置，我会喜欢一门关于底层内容的课程，比如 flash 注意力如何工作、一些分布式训练机制、cuda 等。但我没有办法为他们确保这一点 :( 我想做的另一件事是选出今年最好的一些获奖论文，帮助他们获得理解论文及其相关主题所需的知识和理解。或者可能有不同主题的不同课程，比如一个关于扩散模型的课程，一个关于多模态模型的课程等，比如“让我们了解他们是如何想到 qwen2-vl 的”，“让我们了解 neurips 主赛道上关于 var 的最佳论文的主要贡献和新颖性是什么”等。 所以我有点迷茫，我很想听听你的想法和建议。我关心的是让学生对某些主题有足够的了解，这样他们就不会只对某个主题有一个高层次的想法（我曾经问过实习生什么是一个变形金刚，他们说“我们从 hugging face 进口了一个变形金刚”），但同时也为他们配备技能或知识，帮助他们获得初级职位 谢谢！    提交人    /u/ReinforcedKnowledge   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhdch4/d_what_would_you_like_in_a_mlmlrelated_course_in/</guid>
      <pubDate>Wed, 18 Dec 2024 22:14:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] LMUnit：使用自然语言单元测试进行细粒度评估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hh90xs/r_lmunit_finegrained_evaluation_with_natural/</link>
      <description><![CDATA[      嗨！我是 Contextual AI 👋 的 CTO Aman。部署 LLM 的最大挑战之一是可靠地衡量和改进其行为。当今的评估方法都存在很大的局限性：  人工评估成本高昂且不一致，尤其是在能力最前沿的情况下 奖励模型将复杂的质量维度压缩为不透明的分数，并且在训练后无法进行控制 LLM 评委有学习偏见（例如偏爱较长的回答），无法从人工反馈中学习  今天，我们很高兴分享我们通过自然语言单元测试使 LLM 评估更具原则性的工作：  自然语言单元测试范式：将评估分解为技术和非技术利益相关者都可以理解的明确、可测试的标准 LMUnit：一种最先进的评估模型，在 FLASK/BigGenBench 上实现 SOTA，在 RewardBench 上进入前 10 名 对范式进行了强有力的人工验证：我们的方法将注释者之间的一致性从 71％ 提高到了 86％！  自己尝试一下：  📝 论文： https://arxiv.org/abs/2412.13091 💻 API： https://contextual.ai/request-lmunit-api 📚 博客： https://contextual.ai/news/lmunit  很高兴回答有关这项工作的问题！我们很高兴看到人们如何使用 LMUnit 构建更可靠的 AI 系统。 https://preview.redd.it/mewe7zz6on7e1.png?width=1355&amp;format=png&amp;auto=webp&amp;s=b04c6aeb185c2d27d593efcdeac28306f847166a    提交人    /u/apsdehal   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hh90xs/r_lmunit_finegrained_evaluation_with_natural/</guid>
      <pubDate>Wed, 18 Dec 2024 19:07:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 适用于 24GB VRAM 显卡的 VideoAutoencoder</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hh5ula/p_videoautoencoder_for_24gb_vram_graphics_cards/</link>
      <description><![CDATA[      大家好，我在这里介绍一个小实验，我创建了一个 VideoAutoencoder 来处理 240p 和 15fps 的视频，适用于低 VRAM 显卡，牺牲系统 RAM XD GitHub：https://github.com/Rivera-ai/VideoAutoencoder  这是我在 Epoch 0 和 Step 200 中获得的结果之一  https://i.redd.it/oqq2h9nuzm7e1.gif 我在 24GB 显卡上训练了所有这些，因此您可以在 RTX 3090 或 4090 上训练它，但您必须拥有 64GB 或更多的 RAM    提交人    /u/F4k3r22   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hh5ula/p_videoautoencoder_for_24gb_vram_graphics_cards/</guid>
      <pubDate>Wed, 18 Dec 2024 16:50:56 GMT</pubDate>
    </item>
    <item>
      <title>[D]努力训练用于路线优化的 Dueling DQN 模型——需要有关学习和计算要求的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hh3f7g/dstruggling_to_train_a_dueling_dqn_model_for/</link>
      <description><![CDATA[我正在使用 Dueling DQN 在自定义道路网络环境中进行路线优化项目，该环境具有许多节点和不同的动作空间。但是，该模型无法正确学习 - 训练结果不一致，并且代理难以找到最佳路径。    提交人    /u/ProfessionalType9800   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hh3f7g/dstruggling_to_train_a_dueling_dqn_model_for/</guid>
      <pubDate>Wed, 18 Dec 2024 15:01:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 谁能向我解释一下贝叶斯深度学习和因果关系之间的区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hh32u8/d_can_any_one_explain_me_the_difference_between/</link>
      <description><![CDATA[我正在阅读 youshua bengio 和其他研究人员的一些论文，他们提到在深度学习中加入因果关系很重要。 我不明白这些不同领域试图实现什么，我所知道的因果关系中的一些归纳偏差是 P(t)P(a/t) != P(t/a)P(a)。  因果关系和贝叶斯深度学习在 OOTD 数据中的稳健性如何？ 他们将如何将因果关系与深度学习相结合，dNN 是否会仅使用它来近似后验，还是会将其集成到深度学习的架构中？     提交人    /u/binny_sarita   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hh32u8/d_can_any_one_explain_me_the_difference_between/</guid>
      <pubDate>Wed, 18 Dec 2024 14:45:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年最佳调查论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgwjqu/d_best_survey_papers_of_2024/</link>
      <description><![CDATA[作为一名刚起步的 AI 研究人员，我通常首先查看与某个领域相关的调查论文，然后创建一个路线图以进一步深入研究我的研究主题。我很想看看大家对他们在 2024 年遇到的最佳调查论文的看法。    提交人    /u/arinjay_11020   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgwjqu/d_best_survey_papers_of_2024/</guid>
      <pubDate>Wed, 18 Dec 2024 07:32:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 谷歌照片就像语义搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgwcb0/d_google_photos_like_semantic_search/</link>
      <description><![CDATA[大家好，我们都熟悉使用剪辑嵌入进行视觉搜索，但这并不是万能的，比如谷歌照片搜索，它非常准确，但只显示相关结果，而基于剪辑的搜索会给你最相关的搜索结果，而且并没有一个真正的 Oracle 相似度阈值可以让你分离出相关的结果。 有什么想法，我们如何像谷歌照片那样解决这个问题？    提交人    /u/Raise_Fickle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgwcb0/d_google_photos_like_semantic_search/</guid>
      <pubDate>Wed, 18 Dec 2024 07:16:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] Ian Goodfellow、Yoshua Bengio 和 Aaron Courville 合著的《深度学习》一书摘要</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgvlsd/r_summary_of_deep_learning_book_by_ian_goodfellow/</link>
      <description><![CDATA[      经过 3 年的机器学习学习和实践，我研究了这本书，这篇文章是我的精髓。 https://medium.com/zerone-magazine/how-to-train-your-machine-a-guide-to-ai-r-d-4e6ebfad5ee3 这篇博文逐步介绍了如何训练深度神经网络，并深入探讨了人工智能研究的新前沿。我很乐意在评论中讨论这本书。 https://preview.redd.it/de0jbon7wj7e1.png?width=640&amp;format=png&amp;auto=webp&amp;s=5f1f69a13d22625ede97344fab11811c59f0cebd    提交人    /u/a_man346   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgvlsd/r_summary_of_deep_learning_book_by_ian_goodfellow/</guid>
      <pubDate>Wed, 18 Dec 2024 06:24:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICASSP 2025 最终决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgsj0u/d_icassp_2025_final_decision/</link>
      <description><![CDATA[ICASSP 2025 结果将于今天公布。这个社区里有人兴奋吗？我有 3 个 WA，期待结果。如果你知道任何事情，请告诉我！    提交人    /u/stantheta   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgsj0u/d_icassp_2025_final_decision/</guid>
      <pubDate>Wed, 18 Dec 2024 03:19:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</guid>
      <pubDate>Sun, 15 Dec 2024 16:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>