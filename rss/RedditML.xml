<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 28 Dec 2023 12:24:01 GMT</lastBuildDate>
    <item>
      <title>[R] CART 决策树和随机森林中的小偏差</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ss4ko/r_a_small_bias_in_cart_decision_trees_and_random/</link>
      <description><![CDATA[决策树和随机森林对于属性的缩放是不变的。有趣的是，它们对于属性的镜像（即乘以 -1）并不是不变的。准确地说，如果存在可能取与二叉 CART 树中的阈值一致的值的特征，则该特征的镜像会导致推理时间的偏差。这并不是一个很大的偏差，但是可以达到r2和AUC的0.1-0.2个百分点左右。 好的一点是，在随机森林的情况下，这个偏差基本上可以消除。通过在大约一半的树中使用轴镜像扩展 boostrap 采样来降低成本。 我们相应的论文中提供了更多示例和定量评估：[2312.10708] 二元决策树和随机森林中的条件偏差及其消除 (arxiv.org)  您认为值得为 sklearn 准备 PR随机森林、R 树，或者更确切地说，发布一个带有随机森林的非常小的包，以消除这种偏差？欢迎任何评论！ ​   由   提交 /u/gykovacs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ss4ko/r_a_small_bias_in_cart_decision_trees_and_random/</guid>
      <pubDate>Thu, 28 Dec 2023 11:49:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在多输出回归设置中使用群体特征的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sp8tv/d_advice_on_using_group_charasteristics_in/</link>
      <description><![CDATA[我正在研究一个多输出回归问题，涉及使用同等数量的数值特征来预测 80 多个数值目标。我通过偏最小二乘 (PLS) 回归取得了令人鼓舞的结果，但我没有有效地使用所有可用信息。 我有一个数据框，用于存储这两个特征并针对某些群体特征。特征/目标属于具有四个分类级别 (1-4) 的分层组。例如，共享 1 级值的特征/目标属于该级别的同一组，而不同的 2 级值表示 1 级组内的不同子组。级别被编码为整数。级别具有各种不同的值，级别 1 具有最少的 10 个不同的值，级别 4 具有最多的 70 个不同的值。 到目前为止，我将群体特征纳入我的方法的尝试尚未取得成果。 。我有一些缺失值，因此我尝试根据群体隶属关系对它们进行插补，但与简单的平均插补相比，它并没有产生显着的改进。 ​  Is考虑到有关群体结构的附加信息，PLS 回归仍然是一种合适的策略？ 您会推荐哪些方法来有效地将这些群体特征集成到建模方法中？  &amp; #x200b; 感谢您的帮助:)   由   提交 /u/redamalstix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sp8tv/d_advice_on_using_group_charasteristics_in/</guid>
      <pubDate>Thu, 28 Dec 2023 08:40:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有办法创建半生成人工智能图像？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18so5wf/d_is_there_a_way_to_create_semigenerative_ai/</link>
      <description><![CDATA[在我迄今为止见过的几个文本到图像模型中，您输入一个提示，它会为此生成一个随机图像。我很想知道是否有模型或方法来创建半​​生成图像？我的意思是，我上传一张狗的图像，然后我要求将这只狗放在房子里，或者让这只狗跑起来。 或者也许我告诉模型生成一张狗的图像，然后我要求模型将背景更改为其他内容，但将这只狗保留在下一张图像中。 是否可以使用稳定扩散或 GAN 模型等模型来完成这些操作？或者也许可以通过更改某些部分并重新训练或微调它们？   由   提交 /u/thefreemanever   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18so5wf/d_is_there_a_way_to_create_semigenerative_ai/</guid>
      <pubDate>Thu, 28 Dec 2023 07:30:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 改善注意力蒙版？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18skmw2/d_improving_attention_masks/</link>
      <description><![CDATA[以下内容可以用来改进注意力蒙版吗？一种算法，采用两对包含 n 个单词的短语，大小为 i 到 j，偏移量为 o。输入配对：我去了公园变成：我去了我去了公园我去了公园所有 3 个描述了原始句子。可能对注意力有用，因为它可以提供+意义？这就是我直观地阅读的方式   由   提交 /u/JakeN9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18skmw2/d_improving_attention_masks/</guid>
      <pubDate>Thu, 28 Dec 2023 04:09:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你能重新训练和改变像 BERT 这样的多语言模型的输出大小吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sk1z0/d_can_you_retrain_and_change_the_output_sizes_of/</link>
      <description><![CDATA[我正在开展一个翻译项目，想要训练现有的多语言多对一模型来接收短语并输出词性标签。但是，我只想在几种语言上预训练模型，并且我想将输出大小更改为仅 13 个可能的节点（代表不同的 pos 标签）。有谁知道任何现有的易于重新训练和更改参数的多语言模型？谢谢   由   提交/u/Neat_Replacement_118   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sk1z0/d_can_you_retrain_and_change_the_output_sizes_of/</guid>
      <pubDate>Thu, 28 Dec 2023 03:39:26 GMT</pubDate>
    </item>
    <item>
      <title>树林中的森林——人工智能年的收获 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sjtmo/the_forest_amidst_the_trees_the_takeaway_from_our/</link>
      <description><![CDATA[2023 年将是有意义的一年，也许是书写人工智能历史的最有意义的一年之一。从本质上讲，这是一次大爆炸。  它始于 2022 年底，OpenAI 的 ChatGPT 但它的响应是如此令人惊叹。几个月内，我们就拥有了 Meta 的 LLaMA 2，Google 的 吟游诗人 聊天机器人在今年晚些时候推出了 Gemini，Anthropic 的 克劳德等人。专有和开源之间的斗争愈演愈烈，甚至强大的谷歌得出结论：找不到护城河。我们认为这有利于开源。  https://blog.min.io/the-forest-amid-the-trees-the-takeaway-from-our-ai-year/?utm_source=reddit&amp;utm_medium =organic-social+&amp;utm_campaign=forest_amid_trees_ai_year   由   提交 /u/swodtke   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sjtmo/the_forest_amidst_the_trees_the_takeaway_from_our/</guid>
      <pubDate>Thu, 28 Dec 2023 03:27:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] ML工具：快速贴标机</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sj1ks/p_ml_tool_quick_labeler/</link>
      <description><![CDATA[https://github.com/isc-create-clouddev/Random-Project-tools-ML/blob/main/Label.py 这个工具是与Google的vertex AI平台结合使用。这是一个简单的程序，可让您使用边界框和标签快速注释图像。它根据 Vertex 使用的 YAML 格式将每个图像的坐标和标签导出到 .json 文件中。它还将图像保存在一个位置，以在视觉上确认坐标已正确固定。它节省了大量注释和标记图像的时间，因为我使用的其他标记程序有太多功能。 目前正在添加一个按钮，以允许通过 GUI 更改存储桶。  &gt;   由   提交 /u/starcrashing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sj1ks/p_ml_tool_quick_labeler/</guid>
      <pubDate>Thu, 28 Dec 2023 02:49:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 混合输入分类器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18siiq6/p_classifier_with_mixed_input/</link>
      <description><![CDATA[大家好！我正在尝试设计一个接受 3 个输入的神经网络：一个 10x10 网格，浮点值在 0-1 之间，x 坐标在 0-9 之间，y 坐标在 0-9 之间。网格表示数字谜题的输入，其中特殊数据非常相关，最终目标将是完整的 0 或 1 的 10x10 网格，其中每个图块由网络单独确定。我没有太多设计混合输入神经网络的经验，所以任何提示、建议或代码示例都会非常有帮助！可能有更好的方法来构建这个项目，但这对我来说直观上最有意义   由   提交/u/FissioN47   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18siiq6/p_classifier_with_mixed_input/</guid>
      <pubDate>Thu, 28 Dec 2023 02:23:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] torch.odeint（ODE求解器）执行速度慢的解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sed9l/d_solution_to_slow_execution_speed_of_torchodeint/</link>
      <description><![CDATA[当我在神经常微分方程上运行 torch 优化时，我发现 torch.odeint （此处存储库：rtqichen/torchdiffeq：具有完全 GPU 支持和 O(1) 内存反向传播的可微分 ODE 求解器。(github.com)）非常慢。它会占用单个 CPU 核心 100% 的资源，使其余核心和大部分 GPU 闲置。事实上，似乎并没有太多并行性。 并行 ODE 求解器确实存在，但它们并不是很出名。有人知道任何可以帮助提高 torch.odeint 性能的建议吗？ ​   由   提交 /u/speedy-spade   /u/speedy-spade  reddit.com/r/MachineLearning/comments/18sed9l/d_solution_to_slow_execution_speed_of_torchodeint/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sed9l/d_solution_to_slow_execution_speed_of_torchodeint/</guid>
      <pubDate>Wed, 27 Dec 2023 23:19:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 未经训练的卷积神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s9l3j/d_untrained_convolutional_neural_networks/</link>
      <description><![CDATA[根据标题，我正在探索一个利基主题：使用未经训练的卷积神经网络 (CNN) 作为特征提取器。现有的研究已经证明，即使没有训练，CNN 仍然可以从数据中捕获一些有意义的特征。 因此，我对任何专注于提高未经训练的 CNN 特征提取能力的方法的论文或研究感兴趣，或者探索替代（无需训练）的方法。 目前，我能够找到研究未经训练的 CNN 效率的论文  [1] [2] 或使用它们作为特征提取器的[3] [4] 具体任务和架构。然而，这些论文中没有一篇试图深入研究无需传统的基于梯度的优化即可增强提取特征的方法。 有关此主题的任何共享资源或指导将不胜感激。预先感谢您！   由   提交 /u/RussB3ar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s9l3j/d_untrained_convolutional_neural_networks/</guid>
      <pubDate>Wed, 27 Dec 2023 19:58:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我从头开始制作了一个教育自动毕业</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s0adx/p_i_made_an_educational_autograd_from_scratch/</link>
      <description><![CDATA[学习机器学习，我一直对 PyTorch 及其 Autograd 引擎感兴趣。  在这个项目中，我尝试重新实现 PyTorch 的大部分&lt; /strong&gt;（包括 Autograd）以记录完善、单元测试且可解释的方式从头开始。它对我来说非常有用，我希望它也能帮助您更好地了解 Autograd！  希望您喜欢！  GitHub 存储库此处！   由   提交 /u/suspicious_beam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s0adx/p_i_made_an_educational_autograd_from_scratch/</guid>
      <pubDate>Wed, 27 Dec 2023 13:06:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 MoE 模型仅针对前馈层？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rzygz/d_why_moe_models_target_only_feedforward_layers/</link>
      <description><![CDATA[所以我看到 Mixtral 8x7b 只有 45B 参数，而不是 56B (src https://huggingface.co/blog/mixtral），因为 MoE 仅适用于前馈层，不适用于注意力层。为什么会这样呢？我相信肯定有研究将MoE应用于注意力层，但为什么没有使用呢？是不是没有提高性能什么的，MoE 在注意力层上有什么帮助的任务吗？   由   提交/u/vincent163  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rzygz/d_why_moe_models_target_only_feedforward_layers/</guid>
      <pubDate>Wed, 27 Dec 2023 12:48:16 GMT</pubDate>
    </item>
    <item>
      <title>[R]“将隐私保护机制转向联邦学习”（CCS23）（机器学习安全）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rz528/r_turning_privacypreserving_mechanisms_against/</link>
      <description><![CDATA[CCS 论文链接：https:// dl.acm.org/doi/10.1145/3576915.3623114 预印本链接：https:// arxiv.org/abs/2305.05355 链接 GitHub：https://github.com/DCALab-UNIPV/Turning-Privacy-preserving-Mechanisms-against-Federated-Learning 摘要： 最近，研究人员已经成功地利用图神经网络（GNN）来构建增强的推荐系统，因为它们能够从相关实体之间的交互中学习模式。此外，之前的研究已经将联邦学习作为主要解决方案，以启用本地隐私保护机制来构建全局 GNN 模型，而无需将敏感数据收集到单个计算单元中。尽管如此，由于对联合客户端生成的本地模型更新的分析可以返回与敏感本地数据相关的信息，因此可能会出现隐私问题。因此，研究人员提出了将联邦学习与差异隐私策略和社区驱动方法相结合的解决方案，其中涉及结合来自邻居客户端的数据，以使各个本地更新减少对本地敏感数据的依赖。 在此在论文中，我们发现了这种配置中的一个关键安全缺陷，并设计了一种能够欺骗联邦学习最先进防御措施的攻击。所提出的攻击包括两种操作模式，第一种专注于收敛抑制（对抗模式），第二种旨在在全局联邦模型上构建欺骗性评级注入（后门模式）。实验结果显示了我们的攻击在两种模式下的有效性，在对抗模式的所有测试中平均返回 60% 的性能损失，而在后门模式的测试中，93% 的情况下后门完全有效。 &lt; /div&gt;  由   提交 /u/ArmandolandoReal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rz528/r_turning_privacypreserving_mechanisms_against/</guid>
      <pubDate>Wed, 27 Dec 2023 12:00:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有谁知道尝试寻找特征之间特定关系的 ML 项目吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ry97g/r_does_anyone_know_of_ml_projects_that_attempt_to/</link>
      <description><![CDATA[我正在特别考虑 这个一个。常见的情况是输入数据是行星、恒星或类似的足够大且具有引力的天体。因此使用它们的质量和坐标作为输入以获得关系 F=GM1M2/(r^2)。您是否知道任何其他类型的项目使用机器学习来识别此类关系？ 机器学习能够在多大程度上隔离和识别数据输入特征之间的此类关系？   由   提交/u/emaxwell13131313  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ry97g/r_does_anyone_know_of_ml_projects_that_attempt_to/</guid>
      <pubDate>Wed, 27 Dec 2023 11:02:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>