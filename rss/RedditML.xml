<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 23 Jan 2024 15:14:38 GMT</lastBuildDate>
    <item>
      <title>[项目] 如何实现LST-KSVC</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dqinf/project_how_to_implement_lstksvc/</link>
      <description><![CDATA[嗨，我正在尝试实现2015年的一篇文章《最小二乘孪生多类分类支持向量机》中描述的LST-KSVC，我该如何实现这个算法？ https://doi.org/10.1016/j.patcog.2014.09.020 &lt; /div&gt;  由   提交/u/gus_arch_btw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dqinf/project_how_to_implement_lstksvc/</guid>
      <pubDate>Tue, 23 Jan 2024 15:09:35 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于制作自己的语音模型的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dqezi/d_question_about_making_your_own_voice_models/</link>
      <description><![CDATA[嗨 Reddit。 我有一个 4000 个 wav 文件，我想用它来创建 TTS 模型（如果有人好奇，数据集来自这里： https://mtc.ethz.ch/publications/ open-source/swiss-dial.html)。 我的想法是获取所有这些文件并将它们合并到一个 .tph 文件中（类似于此 Hugging Face 页面中的文件） ：https://huggingface.co/QuickWick/Music-AI-Voices/tree/main ），我可以插入本地 TTS 项目并运行它。ç 我见过很多用于语音克隆的 Google Collab 项目，但我无法让它用于制作模型。 我怎样才能做到这一点？   由   提交/u/ARacoonOnInternet  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dqezi/d_question_about_making_your_own_voice_models/</guid>
      <pubDate>Tue, 23 Jan 2024 15:04:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] MSE 损失 - 为什么 MSE 损失的梯度符号很重要？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dqcqx/d_mse_loss_why_does_the_sign_of_the_gradient_at/</link>
      <description><![CDATA[当我遇到这个使用反向传播实现 MSE 梯度的任务时，我正在尝试一些随机的在线课程作业。这个想法是计算通常的“增量”。在每一层。 但是，MSE 损失 = (Y - Y_hat) ^2 = (Y_hat - Y)^2。 现在，如果我对它们采用梯度，我会得到- (Y - Y_hat) 或 (Y_hat - Y)。现在我应该用哪个符号来计算梯度？因为只有其中一个可以工作（显然）。 有人能解释一下吗？   由   提交 /u/Ultra-Neural   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dqcqx/d_mse_loss_why_does_the_sign_of_the_gradient_at/</guid>
      <pubDate>Tue, 23 Jan 2024 15:01:55 GMT</pubDate>
    </item>
    <item>
      <title>[N] Meta 开源了经过 450 万小时预训练的 wav2vec2 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dptmp/n_meta_opensourced_a_wav2vec2_model_pretrained_on/</link>
      <description><![CDATA[一个月前，Meta AI 发布了 W2V-Bert，这是其 Seamless 模型的构建模块之一。  它已经过 450 万小时的未标记音频数据的预训练，涵盖超过 143 种语言。  优点：  实现低资源微调 比 Whisper 更快、更轻 MIT 许可证 可以针对其他音频任务进行微调  缺点：  基于 CTC，因此适用于标准化转录 &lt; li&gt;使用前需要微调  资源：  原始仓库：https://github.com/facebookresearch/seamless_communication?tab=readme-ov-file#whats-new 变形金刚文档：https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2 -bert 蒙古语博客文章的 ASR 微调：https:// Huggingface.co/blog/fine-tune-w2v2-bert    由   提交 /u/Sufficient-Tennis189   /u/Sufficient-Tennis189  reddit.com/r/MachineLearning/comments/19dptmp/n_meta_opensourced_a_wav2vec2_model_pretrained_on/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dptmp/n_meta_opensourced_a_wav2vec2_model_pretrained_on/</guid>
      <pubDate>Tue, 23 Jan 2024 14:37:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何绕过无监督表示学习中的丑小鸭定理？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dp5t2/d_how_can_we_bypass_the_ugly_duckling_theorem_in/</link>
      <description><![CDATA[丑小鸭 我最近了解了丑小鸭定理，基本上说，如果没有某种偏差，分类是不可能的。 更具体地说，给定 n 个对象的数据集，有 2n&lt; /sup&gt; 可能的分组，每个对象都会像任何其他对象一样频繁地与另一个对象分组，因此必须对可能的属性进行一些权重，必须选择一些偏差，以便对对象进行分类有意义。 在无监督学习的背景下，在我看来，这意味着不存在通用的方法，因为所选算法的性能实际上取决于手头任务的偏差的相关性。 &lt;传统的无监督技术经常在并不总是非常明显的附加假设中引入这种偏差。例如，k 均值聚类假设 1. 您有一个“接近度”度量； 2. 对象（度量）之间的聚类具有相同的球面方差。但毕竟，即使数据集中满足了 k-means 的假设，谁说 k-means 形成的自然群体就是数据科学家正在寻找的答案？ 无监督表示学习 但是，现在让我们关注无监督表示学习的背景，是否有可能找到对一大类可能的下游任务有用的偏差？ 例如，很明显，学习到的表示不应该是恒定的，也就是说，它不应该将相同的特征归因于所有点。如果表示是恒定的，那么就没有希望对数据集进行任何分类，但我们可以合理地期望所选数据集具有足够的信息，至少可以开始学习我们想要的分类。更一般地说，假设学习的表示应该保留有关输入的最大信息似乎是合理的，因此它应该能够区分所有数据点。 这指向自动编码器，因为它们这些模型试图保留有关输入的所有信息，因为它们经过训练以尽可能最好地重建有问题的输入。然而，AE 在数据在潜在空间中的表示方面仅受到较弱的约束。模型的架构和潜在的大小是影响表示的两个主要因素。这个想法是，潜在尺寸较小的 AE 会更多地压缩数据，但这可能并不总是正确的，AE 可能会找到一种非常非线性的表示，完全适合一个或几个潜在维度中的所有数据集。  我对此的看法 我的直觉是应该限制表示，以便潜在特征在某种程度上“容易”呈现。用于下游任务，无论是什么合理的任务。也许该表示确实应该是“最压缩的形式”。正如自动编码器的常识似乎所推动的那样。我将这种智慧解释如下：“如果某个特征在数据中很常见，那么它可能是对该数据的分类器有用的特征”。 （因为一个非常常见的功能可能会用于压缩数据）。 压缩似乎不是一个绕过丑小鸭定理的任意原则，但可能存在其他原则。然而，它假设压缩形式在某种程度上“更容易”。阅读分类器，这可能是一个非常有力的假设。 你同意这一点吗？你还有其他想法吗？   由   提交 /u/Cosmolithe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dp5t2/d_how_can_we_bypass_the_ugly_duckling_theorem_in/</guid>
      <pubDate>Tue, 23 Jan 2024 14:05:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI/ML/CV开源工具的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19doera/d_ideas_for_aimlcv_opensource_tool/</link>
      <description><![CDATA[我目前正在为 AI/ML/CV 领域的学士论文探索想法，重点是开源工具的开发。如果您对此类项目中可以解决的潜在主题或特定功能有任何建议或见解，我将不胜感激。您的意见将有助于完善我的研究方向，我欢迎您为这项激动人心的工作提供任何指导。   由   提交 /u/Unhappy-Many-6082   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19doera/d_ideas_for_aimlcv_opensource_tool/</guid>
      <pubDate>Tue, 23 Jan 2024 13:28:08 GMT</pubDate>
    </item>
    <item>
      <title>[N]ICLR2024的学习理论家，我感同身受！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dnolo/n_learning_theorists_of_iclr2024_i_feel_you/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dnolo/n_learning_theorists_of_iclr2024_i_feel_you/</guid>
      <pubDate>Tue, 23 Jan 2024 12:49:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 方法与技术混乱：数据产品适合哪里？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dnois/d_the_approach_vs_technology_confusion_where_do/</link>
      <description><![CDATA[数据产品悬崖位于方法和的交叉点&gt;技术。就像粒子具有双重性质：波和物质。  在本文中，作者分享了： - 数据产品作为一种方法 - 数据产品作为一种技术 - 社区见解 &lt; p&gt; 𝐑𝐞𝐚𝐝𝐑𝐞𝐚𝐝𝐚𝐫𝐭𝐢𝐜𝐥𝐞。。。  &lt;！ - SC_ON --&gt;  由   提交/u/growth_man  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dnois/d_the_approach_vs_technology_confusion_where_do/</guid>
      <pubDate>Tue, 23 Jan 2024 12:49:08 GMT</pubDate>
    </item>
    <item>
      <title>[N] PRILoRA：修剪和等级增加的低等级适应</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/</link>
      <description><![CDATA[PRILoRA 的核心概念涉及背离为模型中的每一层分配统一的低等级的传统做法。相反，他们提出了一种跨层线性增加的动态分配。这确保了更接近输入的层接收较低的排名，而较深的层被分配更高的排名。例如，在基于 DeBERTaV3 的模型中，他们没有为每一层统一分配 8 的等级，而是从第一层的 4 等级开始，然后逐步提高，直到最深层的等级为 12。这种微妙的分配，平均为 8，产生优异的结果。他们将这一改进归因于这样的观察：语言模型 (LLM) 中的较低层处理更直接和语法的抽象，而更深的层处理语义和复杂元素。在对特定任务进行微调期间，对深层的关注变得至关重要，因为较低层以类似的方式处理单词，但输出需要与较高层表示保持一致。通过区分各层之间的资源分配，它们获得了增强的结果。 此外，它们的微调过程包括根据考虑输入的绝对权重值和累积统计数据的标准重置 A 矩阵中的特定权重分布到层。这种方法针对不太重要的权重，从而提高模型性能。 当应用于基于 DeBERTaV3 的模型时，所提出的方法在 GLUE 基准上优于最先进的方法 (SOTA)。  p&gt; 要全面了解该工作，请参阅全文：https://arxiv.org/pdf/ 2401.11316.pdf   由   提交/u/generous-blessing  /u/generous-blessing  reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/</guid>
      <pubDate>Tue, 23 Jan 2024 09:06:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] 状态空间模型：一种现代方法 作者：Kevin Murphy、Scott Linderman 等人。 （未完待续）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dg8f0/p_state_space_models_a_modern_approach_by_kevin/</link>
      <description><![CDATA[ 这是一本关于状态空间模型 (SSM) 的交互式教科书，使用 JAX Python 库。其他书籍中涵盖了某些内容，例如 [Sar13] 和 [Mur23]。然而，我们会更详细地讨论如何利用自动微分和并行计算方面的最新进展，在“现代”计算环境中有效地实现各种算法。  在线阅读   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dg8f0/p_state_space_models_a_modern_approach_by_kevin/</guid>
      <pubDate>Tue, 23 Jan 2024 04:42:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么研究生或博士后所做的工作在简历上被低估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19df2gx/d_why_is_work_done_as_a_graduate_student_or/</link>
      <description><![CDATA[学术申请行业职位，在我的特定领域拥有新颖的数据分析和机器学习应用的强大出版记录。可以高度转化为工业的技能。对于任何在 R1 完成博士学位的人来说，您都了解与博士学位相关的无形资产。 我被告知并得到普遍的感觉，即使我们已经证明（发布）了我们领导项目的能力从概念到产品，并展示我们在 PI、政府机构和其他行业合作伙伴的压力下工作无数小时的能力，我们的经验价值较低或仅被视为学校作业而不是“真实”经验。 有人知道为什么吗？ 我们如何更好地向招聘人员传达我们的无形和有形价值？   由   提交/u/dcoceans11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19df2gx/d_why_is_work_done_as_a_graduate_student_or/</guid>
      <pubDate>Tue, 23 Jan 2024 03:38:40 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以在其回复中隐藏任意不可检测的信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</link>
      <description><![CDATA[ 由   提交/u/LuvIsOurResistance  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</guid>
      <pubDate>Mon, 22 Jan 2024 22:32:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新理论表明聊天机器人可以理解文本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</link>
      <description><![CDATA[文章链接：https://www.quantamagazine.org/new-theory-suggests-chatbots-can-understand-text-20240122/ 链接到论文 1：https://arxiv.org/abs/2307.15936 摘要：  当今人工智能产品的一个主要驱动力是，当参数集和训练语料库扩大时，语言模型中就会出现新的技能。人们对这种现象知之甚少，并且通过基于梯度的训练的数学分析来进行机械解释似乎很困难。当前的论文采用了不同的方法，使用著名的（和经验的）法学硕士缩放定律和简单的统计框架来分析涌现。贡献包括： (a) 一个统计框架，将法学硕士的交叉熵损失与语言任务的基本技能能力联系起来。 (b) 数学分析表明，缩放定律暗示了一种强烈的归纳偏差形式，使得预训练模型能够非常有效地学习。我们非正式地将其称为“弹弓泛化”，因为天真地认为它似乎给出了违反通常泛化理论的技能的能力水平。 (c) 弹弓泛化的一个关键例子，执行涉及 k 元组技能的任务的能力基本上以与基本技能本身的能力相同的规模和速度出现。  Link论文 2：https://arxiv.org/abs/2310.17567 摘要：  随着法学硕士的角色从语言统计建模转变为通用人工智能代理，法学硕士的评估应该如何改变？可以说，人工智能代理的一项关键能力是根据需要灵活组合其所学的基本技能。结合技能的能力在（人类）教育学以及关于涌现现象的论文中发挥着重要作用（Arora &amp; Goyal，2023）。这项工作引入了 Skill-Mix，这是一种衡量组合技能能力的新评估。使用 N 个技能的列表，评估者重复选择 k 个技能的随机子集，并要求法学硕士生成结合该技能子集的文本。由于子集的数量像 Nk 一样增长，因此即使是适度的 k，此评估也很有可能要求法学硕士生成与训练集中的任何文本显着不同的文本。该论文开发了一种方法，用于 (a) 设计和管理此类评估，以及 (b) 使用 GPT-4 以及开放的 LLaMA-2 70B 模型对结果进行自动分级（加上人工抽查）。管理流行聊天机器人的一个版本所得到的结果虽然总体上符合之前的预期，但也包含了令人惊讶的结果。模型能力之间存在相当大的差异，而这些差异并没有通过它们在流行的 LLM 排行榜上的排名来体现（“临时抱佛脚排行榜”）。此外，简单的概率计算表明GPT-4在k＝5上的合理性能暗示超越“随机鹦鹉”性能。行为（Bender 等人，2021），即它以训练期间未曾见过的方式组合技能。我们概述了该方法如何形成基于技能组合的生态系统，对未来模型的人工智能功能进行开放评估。    由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</guid>
      <pubDate>Mon, 22 Jan 2024 21:54:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前理论机器学习作为一个领域有什么意义吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</link>
      <description><![CDATA[随着 SOTA 架构不断变化的极快速度，可能的 DL 技术（正则化、所有不同的激活和损失函数）的多样性如下：以及对可解释人工智能相对退居二线的担忧，现在从事理论机器学习工作有什么用处吗？ 大多数 SOTA 架构似乎只是大规模扩展的高级猜测和检查，而且它确实有效就基准性能而言，我们是否需要 ML/DL 理论？   由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</guid>
      <pubDate>Mon, 22 Jan 2024 20:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>