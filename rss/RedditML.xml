<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 08 Dec 2024 21:15:03 GMT</lastBuildDate>
    <item>
      <title>[D] 使用 LLM 进行上下文感知实体识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9stfq/d_contextaware_entity_recognition_using_llms/</link>
      <description><![CDATA[有人能推荐一些可以执行实体识别但使用 LLM 级上下文的好模型吗？此类模型通常是针对实体识别进行微调的 LLM。通常，使用传统的 NER/ER 管道（例如 SpaCy 的 NER 模型）只能标记已经训练过的单词。使用针对实体识别进行微调的 LLM（例如 GLiNER 模型）可以标记模糊实体，而不仅仅是基本实体，例如名称、地点、组织等。    提交人    /u/Ashwiihii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9stfq/d_contextaware_entity_recognition_using_llms/</guid>
      <pubDate>Sun, 08 Dec 2024 21:05:35 GMT</pubDate>
    </item>
    <item>
      <title>人工智能是否存在真正的危险？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9ppat/are_there_any_real_dangers_to_ai_d/</link>
      <description><![CDATA[我听到了很多关于人工智能对我们造成的生存威胁的话题。我是一名数据工程师，所以我对人工智能知之甚少，但对我来说，人工智能只是一个很长的数学方程式，所以我真的无法想象它的危险。大多数关于人工智能的新闻都是由非技术人员撰写的，他们说人工智能可以“思考”等等，在我看来，这听起来很愚蠢。 无论如何，我对你们这些处于当前人工智能技术最前沿的专业人士所说的话非常感兴趣。你能分享一下你遇到过的任何关于人工智能的奇怪或令人担忧的事情吗？我不明白为什么伊隆马斯克对人工智能如此担忧（至少在公开场合）。 编辑：我对人工智能能做什么的哲学讨论不感兴趣。我感兴趣的是专业人士在使用和/或开发人工智能时遇到的奇怪或令人担忧的事情。     由    /u/imbuszkulcs 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9ppat/are_there_any_real_dangers_to_ai_d/</guid>
      <pubDate>Sun, 08 Dec 2024 18:48:11 GMT</pubDate>
    </item>
    <item>
      <title>Fal 与 Replicate [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9lrc2/fal_vs_replicate_d/</link>
      <description><![CDATA[我想微调 flux 以创建一致的角色。Fal 和 Replicate 哪个更好。请建议我你们使用哪个。    提交人    /u/Ill_Start12   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9lrc2/fal_vs_replicate_d/</guid>
      <pubDate>Sun, 08 Dec 2024 15:54:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我应该在我的学术论文中使用 MLflow 或 DVC 等机器学习实验跟踪工具吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9ig1e/r_should_i_use_ml_experiment_tracking_tools_like/</link>
      <description><![CDATA[大家好！ 我是一名计算机科学毕业生，目前正在为研究论文进行机器学习实验。我有一个数据集，计划比较多个深度学习模型之间的错误指标。 我打算提交论文的会议要求我提供代码和数据集，我也坚信可重复性在学术研究中至关重要。为此，我正在使用 Docker 和 pip-compile 使环境尽可能可重复。 话虽如此，我知道有像 MLFlow 和 DVC 这样的工具可以跟踪 ML 实验。但是，我从未在学术论文附带的代码中看到过这些工具。 我的问题是：  有没有学术论文使用 MLFlow 或 DVC 等 ML 实验跟踪工具？ 我应该将这些工具用于我的研究吗，即使这意味着额外的工作？  我也在尝试 DVC，因为它将实验输出存储在 Git 中。但是，我的项目涉及在单个存储库中运行许多不同的实验（比较多种 ML 算法）。DVC 或其他工具是否是这种工作流程的最佳选择？或者对于学术论文来说，使用这样的工具是不是有点小题大做？    提交人    /u/mrlucasrib   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9ig1e/r_should_i_use_ml_experiment_tracking_tools_like/</guid>
      <pubDate>Sun, 08 Dec 2024 13:05:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医学 AI：顶级 LLM 研究论文/模型（2024 年 12 月 2 日至 12 月 7 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9hytj/d_last_week_in_medical_ai_top_llm_research/</link>
      <description><![CDATA[      [D] 医学 AI 上周：顶级 LLM 研究论文/模型（2024 年 12 月 2 日至 12 月 7 日） 医学 LLM 和模型  Block MedCare：区块链 AI 和物联网  本研究提出了一种基于以太坊的新型系统，用于安全高效的电子健康记录 (EHR) 管理，使患者能够控制数据。  LLMs4Life：生物医学本体学习  本文使用具有高级提示工程和本体重用的 LLM 扩展了 NeOn-GPT 本体学习流程，以改进生成的本体在生命科学等复杂领域的领域特定推理和结构深度。  用于多模态诊断的 LLaMA II  本文探讨了使用基于变压器的模型和 LLaMA II 主干的医疗数据多模态融合方法，重点是使用来自 OpenI 数据集的胸部 X 光片和临床报告进行疾病分类。  用于 EHR 隐私的紧凑型 LLM  本文介绍了一种紧凑型 LLM 框架，用于在具有严格隐私要求和有限资源的医疗保健环境中进行本地部署。它使用一种新颖的预处理技术和正则表达式等信息提取方法来增强较小 LLM 在 EHR 数据上的性能。   框架和方法 - RARE：检索增强推理 - STORM：罕见事件策略 - TransFair：公平疾病分类 - PePR：按资源计算的性能 - 医学法学硕士最佳实践 法学硕士应用 - Medchain：临床实践中的法学硕士 - 查询护理记录摘要 - CLINICSUM：患者对话摘要 - 分类器的文本嵌入 法学硕士基准 - 波兰医学考试转移 - 单细胞组学注释 - 精准医学中的法学硕士 - 低资源医疗保健挑战 其他模型 - 法学硕士聊天机器人幻觉 - 多阶段胸部 X 光诊断 - EchoONE：超声心动图 AI - 放射学报告基础 道德与公平 - 医学影像中的隐私 - AI 中的人口公平性 数据集 - LLM 科学知识提取 - 生物医学知识回顾 完整线程详细信息：https://x.com/OpenlifesciAI/status/1865584829057929303    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9hytj/d_last_week_in_medical_ai_top_llm_research/</guid>
      <pubDate>Sun, 08 Dec 2024 12:37:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 各种 LLM 抽样方法的集合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9fe8q/d_a_collection_of_various_llm_sampling_methods/</link>
      <description><![CDATA[在过去的几个月里，我阅读了有关执行 LLM 采样的各种算法。我决定构建自己的推理堆栈并实现这些算法。 这是 Github 仓库 - https://github.com/shreyansh26/LLM-Sampling 该仓库包括 Top-k、Top-p（核心）、Min-p、典型、Epsilon、Eta、Beam 搜索、Chain-of-Thought (CoT) 解码、Constrained JSON 解码和 Speculative 解码的实现。 就我个人而言，我发现这是一个很好的学习经历。在这里分享，以防它对某人有帮助！    提交人    /u/shreyansh26   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9fe8q/d_a_collection_of_various_llm_sampling_methods/</guid>
      <pubDate>Sun, 08 Dec 2024 09:39:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 🥂 FineWeb2 数据集：包含数千种语言的闪亮更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9ep0e/p_fineweb2_dataset_a_sparkling_update_with_1000s/</link>
      <description><![CDATA[    /u/PhilipsNostrum   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9ep0e/p_fineweb2_dataset_a_sparkling_update_with_1000s/</guid>
      <pubDate>Sun, 08 Dec 2024 08:47:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>在 aws sagemaker 或 gcp vertex ai 等云服务中训练模型时，如何管理资源或优化成本？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h93rlt/how_do_you_manage_resources_or_optimize_cost_when/</link>
      <description><![CDATA[大家好，我最近经常使用 sagemaker 来训练 ML 模型并进行部署。我对 aws 和实例类型有足够的了解，可以创建具有足够容量来训练我的模型的训练节点，但很多时候我都没有充分利用 RAM、GPU 内存或 CPU，所以感觉这会导致很多浪费（和额外成本）。 你们如何确定哪种类型的实例或资源最适合你们的需求而又不会太浪费？ 有没有办法自动调整资源，或者有什么库可以帮你处理这个问题？    提交人    /u/InformationEmpty1440   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h93rlt/how_do_you_manage_resources_or_optimize_cost_when/</guid>
      <pubDate>Sat, 07 Dec 2024 22:17:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] 批量提取带有积极情绪的转录本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h92b70/p_extract_transcripts_with_positive_emotions_in/</link>
      <description><![CDATA[查看此示例项目，了解如何查找具有积极情绪的录音记录。该项目展示了如何从音频中提取可操作见解！ 它从 hagging face 获取音频文件的 common voice 数据集，将情绪识别模型和 whisper-tiny 模型应用于记录。所有内容都组织在一个美观的批处理管道中。 一个有趣的细节 - 无需提取档案！此管道直接从 tar 存档中分析音频文件，为您节省了额外的步骤。 视频：https://www.youtube.com/watch?v=OCm5W0L5BTU Colab 笔记本：https://colab.research.google.com/github/iterative/datachain-examples/blob/main/audio/hf_common_voice.ipynb Jupyter Notebook：https://github.com/iterative/datachain-examples/blob/main/audio/hf_common_voice.ipynb    由   提交  /u/dmpetrov   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h92b70/p_extract_transcripts_with_positive_emotions_in/</guid>
      <pubDate>Sat, 07 Dec 2024 21:08:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我无论如何也无法在 GitHub 上找到这个最近发布的开源转换器。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h8zlz3/p_i_cannot_find_this_opensource_transformer_on/</link>
      <description><![CDATA[有一篇论文与一个 GitHub 存储库一起发布，其中包含一个制作精良的变压器，用于测试新组件。但我找不到它！它不是像 HuggingFace 那样存在的变压器之一。有什么线索吗？    提交人    /u/Breck_Emert   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h8zlz3/p_i_cannot_find_this_opensource_transformer_on/</guid>
      <pubDate>Sat, 07 Dec 2024 19:05:21 GMT</pubDate>
    </item>
    <item>
      <title>[N] Sama 是一家人工智能血汗工厂，它向肯尼亚的工人支付每小时 2 美元的费用，让他们连续数小时过滤和标记色情、兽交、自杀、虐待儿童等内容！！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h8nhbh/n_sama_an_ai_sweatshop_pays_workers_in_kenya_2_an/</link>
      <description><![CDATA[    /u/BotherBubbly5096   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h8nhbh/n_sama_an_ai_sweatshop_pays_workers_in_kenya_2_an/</guid>
      <pubDate>Sat, 07 Dec 2024 07:38:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 换个话题：我的一些非 LLM 重点工作：通过语义盲法和图神经网络进行无偏见情绪分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h8meas/r_for_a_change_of_topic_some_nonllm_focused_work/</link>
      <description><![CDATA[   在我的学术领域（社会科学），我处理 SA 模型中的偏见问题。我之前的工作表明，深度学习 SA 系统从注释者那里继承了偏见（例如，不代表人口政治偏见）： https://arxiv.org/abs/2407.13891 现在我设计了一个解决方案，使用一种我称之为语义盲法的技术，只为模型提供预测文本情绪所需的基本信息，不给模型留下任何过度拟合和产生偏见的信号： https://arxiv.org/abs/2411.12493 在我发布 SProp Gnn 之前，我很想听听你的想法。 你认为它在学术界之外还有用吗？    由    /u/Hub_Pli  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h8meas/r_for_a_change_of_topic_some_nonllm_focused_work/</guid>
      <pubDate>Sat, 07 Dec 2024 06:21:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAAI 2025第二阶段决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h8kkjv/d_aaai_2025_phase_2_decision/</link>
      <description><![CDATA[第二阶段的决定什么时候出来？ 我知道日期是 12 月 9 日，但是结果有可能比宣布的日期更早出来吗？ 或者它是否在前几年的确切时间公布结果？（即 2024 年、2023 年、2022 年......） 继续等待让我有点恶心。    提交人    /u/No-Style-7975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h8kkjv/d_aaai_2025_phase_2_decision/</guid>
      <pubDate>Sat, 07 Dec 2024 04:27:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>