<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sun, 16 Feb 2025 15:15:04 GMT</lastBuildDate>
    <item>
      <title>[P] Langchain和Langgraph工具呼叫DeepSeek-R1的支持</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqu0f8/p_langchain_and_langgraph_tool_calling_support/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在从事侧面项目时，我需要使用deepseek-r1的工具调用，但是langchain和langgraph不支持deepseek-的工具R1。因此，我决定手动编写一些自定义代码来执行此操作。 在此处发布它以帮助任何需要它的人。该软件包还可以与Langchain的Chatopenai库中可用的任何新发布的型号（通过扩展，OpenAi库上可用的任何新发布的模型）一起使用，该模型可能还没有Langchain和Langgraph的工具呼叫支持。如果您觉得这个有用且有趣的话，请给我的GitHub仓库。感谢您的支持！   https://github.com/leock.com/leockl/leockl/tool-ahead--时间   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; &lt; com/r/machinelearning/comment/1iqu0f8/p_langchain_and_langgraph_tool_calling_calling_support/“&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqu0f8/p_langchain_and_langgraph_tool_calling_support/</guid>
      <pubDate>Sun, 16 Feb 2025 15:01:25 GMT</pubDate>
    </item>
    <item>
      <title>[d]进行原始研究的步骤（这也是一个咆哮）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqq4fz/d_the_steps_to_do_original_research_its_a_rant_as/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是英国的大师学生。我一直在阅读有关扩散的论文。我已经联系了大学的博士生，并表示对与他们合作的兴趣。我以为我会帮助他们解决他们的研究方向。但是，与他们交谈后，他们告诉我阅读一些论文，然后找到一个研究想法。  对于上下文，我正在阅读有关扩散模型的信息。我读的越多，我意识到我缺乏一些数学基础。我通过课程，书籍和文章来填补这些洞。但是，这需要时间。我相信，缺乏基本的理解使我无法提出假设。我可以通过最近的调查论文找到一些研究差距，但是我无法提出任何假设或解决方案。 我朝正确的方向前进吗？从根本的角度理解东西有助于产生新颖的研究思想吗？如何产生新颖的研究思想？如果您有一些提示，我很高兴听到它们。  P.S。我从未出版过。因此，如果我错过了一些基本的东西，我感到很抱歉。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/snoo_65491     [link]   ＆＃32;   [注释]      ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqq4fz/d_the_steps_to_do_original_research_its_a_rant_as/</guid>
      <pubDate>Sun, 16 Feb 2025 11:14:23 GMT</pubDate>
    </item>
    <item>
      <title>[P]我建立了一个开源AI代理，该代理可以完全自动编辑视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqq1vz/p_i_built_an_opensource_ai_agent_that_edits/</link>
      <description><![CDATA[   &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/comments/1iqqq1vz/p_i_built_an_opensource_aigent_ai_aigent_aigent_that_that_edits/ AI agent that edits videos fully autonomously&quot; src=&quot;https://external-preview.redd.it/aNz3BFb1ycBa55wI3LX5BuJGkVgsXAVk_7lUskfK1zk.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b072cacd407870c1166de542f8cab83d84861bf1&quot; title=&quot;[P] I构建了一个开源AI代理，该代理完全自动编辑视频“/&gt;   ＆＃32;提交由＆＃32; /u/u/umaust_instance_401     代理“&gt; [link]  ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqq1vz/p_i_built_an_opensource_ai_agent_that_edits/</guid>
      <pubDate>Sun, 16 Feb 2025 11:09:16 GMT</pubDate>
    </item>
    <item>
      <title>[d] Torch.com使用Hidet编译器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqnyet/d_torchcompile_using_hidet_compiler/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有人尝试使用hidet作为torch.compile的火炬电感器的Altenative Backend。    https://pytorch.org/blog/introducing-hidet/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/lime_dragonfruit4244      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqnyet/d_torchcompile_using_hidet_compiler/</guid>
      <pubDate>Sun, 16 Feb 2025 08:37:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM法官提供动力的每日ARXIV过滤（与项目链接）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqnhai/p_daily_arxiv_filtering_powered_by_llm_judge_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  链接到项目： https://arxiv.ianhsiao.xyz &lt; /a&gt;  大家好，在我以前的reddit帖子中：没有可用的链接，因为我对许多subreddits粘贴了相同的评论，因此系统认为我是垃圾邮件并删除了所有这些（您可以比较显示的评论金额和实际数量验证）。我为此感到抱歉。 话虽如此，我真的很想学习社区的反馈，所以我再次发布此信息。 谢谢您的耐心配合！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/madyexz     [link]   ＆＃32;   [commist]       ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqnhai/p_daily_arxiv_filtering_powered_by_llm_judge_with/</guid>
      <pubDate>Sun, 16 Feb 2025 08:02:38 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会导致禁止。 鼓励其他人创建新的帖子，以便在此处发布问题！ 线程将一直活着直到下一个，因此请继续发布标题之后的发布。    meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[D]用于嵌入培训的Torchrec或DGL</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqdzs5/d_torchrec_or_dgl_for_embedding_training/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我正在寻找一个库来训练大规模嵌入的库。 Pytorch-liggraph似乎不再维护。现在，我在Torchrec与DGL之间做出决定。您会推荐哪种工具，为什么？如果没有，您推荐哪个库？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bigbaydragon     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqdzs5/d_torchrec_or_dgl_for_embedding_training/</guid>
      <pubDate>Sat, 15 Feb 2025 23:01:47 GMT</pubDate>
    </item>
    <item>
      <title>[D]我的公司是否因避免深度学习而错过了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq9gtk/d_is_my_company_missing_out_by_avoiding_deep/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  免责声明：如果线性回归足够，则使用神经网络是没有意义的。  我在一家严格遵守数学，可解释的模型的公司工作。他们的立场是，诸如神经网络甚至梯度提升机之类的方法也是“黑框”。因此对决策不可靠。尽管我了解可解释性的重要性（尤其是在任务关键场景中），但我忍不住感觉这种方法过于限制。  我看到了这些方法的大量研究和行业采用，这让我感到奇怪：它们真的只是黑匣子，还是这是过时的观点？当然，随着这么多的人在这一领域工作，必须有一些方法可以洞悉这些模型并使他们更值得信赖。  我也错过了它们，因为我没有此类模型的工作经验？ 编辑：上下文是一级方程式！但是，种族是另一件事并支持工具。除非完全必要，否则我也会避免使用与种族严格相关的任何模型。我只是觉得这里有一种与上下文无关的偏见。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/datandre     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq9gtk/d_is_my_company_missing_out_by_avoiding_deep/</guid>
      <pubDate>Sat, 15 Feb 2025 19:42:42 GMT</pubDate>
    </item>
    <item>
      <title>具有Quadro RTX5000的笔记本电脑非常适合机器学习和稳定扩散？允许的标签：“ [讨论]”，“ [D]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq6pz8/laptop_with_quadro_rtx5000_is_good_for_machine/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  带有Quadro rtx5000的笔记本电脑非常适合机器学习和稳定的扩散？ 我的旧笔记本电脑已经使用了很多年，想要要购买新的 我找到了这笔交易  acer概念d7  二手在我当地附近的900-1,000美元左右 （我担心热量和维护。由于板上的端口在里面倒转） 如果它不稳定，我根本无法工作。而且我只有一次预算。 我认为这很有趣，因为它仍然处于良好状态，最多可达16 GB或 我应该去购买全新的笔记本电脑带有RTX4060   /u/u/aphand-pass557     link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iq6pz8/laptop_with_with_quadro_rtx5000_is_is_good_good_for_for_for_machine/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq6pz8/laptop_with_quadro_rtx5000_is_good_for_machine/</guid>
      <pubDate>Sat, 15 Feb 2025 17:42:33 GMT</pubDate>
    </item>
    <item>
      <title>[D]混合和歧管混合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq64f0/d_mixup_and_manifold_mixup/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好。您在混合和歧管混合过程中的经历如何。我拥有由于内部和主体间可变性而导致的脑电图数据，域和VAL设置之间的域移动。我的目的是使我的模型的决策界限平滑。但是结果是训练不稳定。我使用a = 0.4，所以我只有光插值。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nigale-joke5751     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq64f0/d_mixup_and_manifold_mixup/</guid>
      <pubDate>Sat, 15 Feb 2025 17:16:03 GMT</pubDate>
    </item>
    <item>
      <title>[d]有没有LLM论文预测中间而不是下一个令牌？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq4f0r/d_have_any_llm_papers_predicted_a_token_in_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在从事一个项目（与NLP无关），在该项目中，我们使用与GPT-3相同的架构和培训，但我们更多比下一个“ word”找到一系列令牌来连接起始和结束“单词”。由于我们在设置中从LLM中绘制了很多东西，因此我想知道是否有任何研究对模型的性能进行任何研究，而当损耗函数不基于下一个令牌，而是预测输入序列中某个地方的蒙版令牌。  最终，我们想扩展它（也许是通过微调），以预测一系列缺少的令牌，而不是一个，但这似乎是一个不错的起点。  我找不到太多关于文献中无监督的培训方案的信息，但似乎有人一定已经尝试过。有任何建议，或者是一个坏主意？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/thewittyscreenname     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iq4f0r/1iq4f0r/d_have_any_llm_llm_papers_predication_a_token_in_in_in_in_in_the/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq4f0r/d_have_any_llm_papers_predicted_a_token_in_the/</guid>
      <pubDate>Sat, 15 Feb 2025 15:59:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM法官提供动力的每日ARXIV过滤</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipz934/p_daily_arxiv_filtering_powered_by_llm_judge/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/madyexz     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipz934/p_daily_arxiv_filtering_powered_by_llm_judge/</guid>
      <pubDate>Sat, 15 Feb 2025 11:14:16 GMT</pubDate>
    </item>
    <item>
      <title>[r]通过基于抽象网格的任务评估LLM中的物理概念理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipw78p/r_evaluating_physical_concept_understanding_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项工作介绍了一个结构化评估框架，用于评估LLMS中物理理解的结构化评估框架，从教育测试原理中得出。研究人员使用定量和定性问题开发了一个全面的测试套件，涵盖了力学，热力学和电磁套件。 关键技术方面： - 多级评估层次结构，从事实回忆到概念转移到最小的词汇，以最小化 - 语言模式匹配 - 使用平行问题的跨文本验证 - 数值计算和概念解释任务的集成 - 基于教育评估方法的标准化评分标准评分 主要结果：-GPT -4在基本物理学上实现了76％的准确性计算 - 跨文本转移问题的性能下降至43％ - 跨物理域的性能显着差异 - 模型在数学能力和物理问题解决问题之间显示出很强的相关性 - 结合多个物理概念 时出现了系统错误我认为这种方法比以前的工作提供了一种更严格理解LLM功能的方法。教育测试框架有助于区分表面水平的模式匹配和更深的概念理解。这可能会导致更好的基准测量科学推理中的AI进展。 我认为，结果突出了LLMS在跨环境中传递物理知识的当前局限性 - 这对于实际科学工作至关重要。系统评估方法可以扩展到其他科学领域。  tldr：基于教育测试原理的新评估框架表明，LLM具有体面的物理计算能力，但与更深入的概念理解和知识转移斗争。 。&gt;   完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipw78p/r_evaluating_physical_concept_understanding_in/</guid>
      <pubDate>Sat, 15 Feb 2025 07:21:24 GMT</pubDate>
    </item>
    <item>
      <title>[d]变压器最有前途的继任者是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipvau4/d_whats_the_most_promising_successor_to_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我所知道的是mamba，从效率的角度看（推理是线性而不是二次），但是Afaik没有人受过训练的大型模型。还有 xlstm  and  aaren 。  你们认为变压器最有前途的替代体系结构是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jsonathan     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipvau4/d_whats_the_most_promising_successor_to_the/</guid>
      <pubDate>Sat, 15 Feb 2025 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>