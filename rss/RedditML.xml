<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 12 Jun 2024 18:19:49 GMT</lastBuildDate>
    <item>
      <title>[D] 通过无服务器端点托管自定义模型以进行内部/beta 测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deczjl/d_host_custom_models_via_serverless_endpoints_for/</link>
      <description><![CDATA[大家好， 我很想了解人们在为内部测试或 Beta 版发布提供自定义或微调的开源模型时面临的挑战。 以下是我观察到的一些常见问题：  通过端点托管模型困难：团队通常最终会手动共享模型输出，从而妨碍队友进行有效测试。 非无服务器部署：忘记停止实例会导致云提供商收取意外的高额费用。 具有维护开销的自定义库：一些团队已经构建了解决这些问题的自定义解决方案，但它们会带来维护开销并减慢开发速度。  我很想听听在提供自定义模型时遇到过这些或其他挑战的人的意见。您的见解将非常宝贵。     由    /u/Capital_Ad1552  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deczjl/d_host_custom_models_via_serverless_endpoints_for/</guid>
      <pubDate>Wed, 12 Jun 2024 17:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练模型以提取法律文件的部分内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dec57w/d_training_a_model_to_extract_sections_from_legal/</link>
      <description><![CDATA[大家好 - 我正在训练一个模型，该模型可以审查法律文件并从中提取特定部分。以下是我面临的主要挑战：  文件长度各异：这些文件的长度从几页到几百页不等。 标题不一致：各节标题不一致。例如，同一节的标题可能是“索赔”、“被告的索赔”、“被告的论点”或“主要论点”。该工具需要根据内容本身而不是标题来识别节。 识别终点：模型需要知道节的结束位置，是在下一个节的标题处，还是在无关细节开始时（有时就在我们想要的段落之后）。它应该能够根据以下段落的上下文找出终点。  我知道我可能无法完全自动化这个过程，但我正在寻找一种尽可能接近的方法，而不需要大量的手动输入。我需要处理大约 1000 个文档，所以效率是关键。 据我所知，我有几个选择：  对 BERT 进行微调，以执行命名实体识别等任务以精确定位部分。 使用类似 Llama 3 的模型，它可以处理更长的上下文，并且可以很好地与少样本或零样本学习配合使用。  任何建议或指导都将不胜感激！我一直在疯狂地试图解决这个问题，所以任何帮助都会救我一命。    提交人    /u/Philosophia7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dec57w/d_training_a_model_to_extract_sections_from_legal/</guid>
      <pubDate>Wed, 12 Jun 2024 17:21:43 GMT</pubDate>
    </item>
    <item>
      <title>CLASSP：一种通过调整抑制和稀疏性提升进行持续学习的生物启发方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deazza/classp_a_biologicallyinspired_approach_to/</link>
      <description><![CDATA[  由    /u/Gold-Plum-1436  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deazza/classp_a_biologicallyinspired_approach_to/</guid>
      <pubDate>Wed, 12 Jun 2024 16:33:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] [D] 在机器学习期刊上发表？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de9kfg/r_d_publish_in_an_ml_journal/</link>
      <description><![CDATA[大家好。我有一个问题想问那些发表过研究文章的人。我有一篇可能的论文，标题接近“使用图论和遗传算法进行替代信贷发放”。这是一个应用程序，展示了如何使用替代模型减少逾期贷款。 我的问题是：建议在 ML 期刊或经济和金融期刊上发表这个主题吗？    提交人    /u/Eskorbuto_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de9kfg/r_d_publish_in_an_ml_journal/</guid>
      <pubDate>Wed, 12 Jun 2024 15:33:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习系统工程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de9glz/d_ml_system_engineering/</link>
      <description><![CDATA[最近的 WWDC 活动展示了 Apple 非凡的系统工程，它允许使用用户友好的产品，同时仍设法使用资源密集型的设备语言模型（3-7B 参数）。这对我来说非常鼓舞人心，尤其是作为一名博士生，我的大多数项目最终都只是一篇研究论文！ 我在 ML、DL 和 RL 方面拥有良好的理论背景，并且对大多数最先进的方法有很好的了解。但是，我在使用 ML 进行后端决策的可部署产品方面没有任何经验。 我想知道这里的人是否可以为我指出一些好的资源，以便我更多地了解 ML 系统设计和 MLOps，也许还有一些项目的想法可以获得更多经验。    提交人    /u/Personal_Click_6502   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de9glz/d_ml_system_engineering/</guid>
      <pubDate>Wed, 12 Jun 2024 15:29:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Mamba 进行推测解码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de8rk4/p_speculative_decoding_with_mamba/</link>
      <description><![CDATA[嗨，我正在尝试通过推测采样加速大型语言模型解码来实现推测解码，这是 colab 笔记本。 我使用相同的模型进行测试，但得到了不同的输出。当我尝试调试时，我发现来自 infer_params 的前向传递的 logit 与生成的 logit 不同。任何关于可能导致这种情况的见解都将不胜感激。    提交人    /u/Jazzlike-Shake4595   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de8rk4/p_speculative_decoding_with_mamba/</guid>
      <pubDate>Wed, 12 Jun 2024 15:00:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 谷歌研究表明，对法学硕士进行微调会线性增加幻觉？😐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de5wa2/r_google_study_says_finetuning_an_llm_linearly/</link>
      <description><![CDATA[他们准备了一个 QA 任务来观察幻觉，既有已知示例（与模型在初始训练期间看到的信息类似的训练实例），也有未知示例（引入了模型之前从未接触过的新信息）。 他们发现：  由于过度拟合，微调数据集中的未知示例会降低性能，训练越多。它们会导致幻觉并降低准确性。已知示例对性能有积极影响。 早期停止有助于避免这种情况，这可能意味着未知示例在较短的训练中是中性的。 未知示例的拟合速度较慢也表明模型难以通过微调获取新知识。  论文：https://arxiv.org/pdf/2405.05904 我每天分享高质量的 AI 更新和教程。 如果您喜欢这篇文章并希望了解最新的 AI 研究，您可以查看：https://linktr.ee/sarthakrastogi 或我的 Twitter：https://x.com/sarthakai    由    /u/sarthakai  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de5wa2/r_google_study_says_finetuning_an_llm_linearly/</guid>
      <pubDate>Wed, 12 Jun 2024 12:51:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM 时代的增量学习数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de4uwf/p_datasets_for_incremental_learning_in_the_age_of/</link>
      <description><![CDATA[嗨， 我想测试一下我关于持续学习或（基本上）逐步学习新类别的想法。简单地总结一下这个问题，给定一个包含 m 个类别的训练集和一个包含 n&gt;m 个类别的测试集（基本上我们在现有类别中引入新类别，两者之间有一些重叠），目标是正确地对所有测试点进行分类。我正在使用 Llama 和 Roberta 来获取文本嵌入。但是，由于以下挑战，我很难找到相关的数据集 -   任务本身并不容易（例如，对于只有几个类别的情绪分类，模型能够轻松完成工作，因此这不是一个很好的基准。） 预训练数据集中也存在数据污染的可能性，这意味着我必须寻找“新”数据集。   因此，从本质上讲，数据集要求可以归结为 -  具有文本组件的具有挑战性的问题 理想情况下有很多类别（至少&gt;6-7） 理想情况下有很多数据，以便以半监督或无监督的方式学习良好的先验分布  只要基本问题目标相同，只要涉及一些文本组件（例如，精神病数据），我也对非 NLP 数据集持开放态度。 如果您有符合要求的数据集或论文，请告诉我。谢谢您的帮助，祝您有美好的一天！    提交人    /u/breadwineandtits   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de4uwf/p_datasets_for_incremental_learning_in_the_age_of/</guid>
      <pubDate>Wed, 12 Jun 2024 11:57:55 GMT</pubDate>
    </item>
    <item>
      <title>寻找时间序列资源[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de38nr/looking_for_time_series_resources_p/</link>
      <description><![CDATA[您好， 我是一名数据科学家，有 5-10 年的工作经验。我最近换了行业，现在面临很多时间序列数据方面的挑战。 我想读一本书、参加一门课程或采取任何其他方式来更新和提高我在这个主题上的知识。 我有兴趣更深入地了解最先进的时间序列技术。 （在学习期间，我们从计量经济学 POV 深入研究了 ARIMA 和 VAR 模型。但肯定有更新的技术与 ML 算法堆栈更相关，如 LSTM 甚至 CNN（ROCKET）。时间扭曲又是什么鬼？） 你能推荐任何适合我需要的东西吗？    提交人    /u/Antalagor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de38nr/looking_for_time_series_resources_p/</guid>
      <pubDate>Wed, 12 Jun 2024 10:20:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] François Chollet 宣布新的 ARC 奖挑战——它是 AI 泛化的终极测试吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de2b16/d_françois_chollet_announces_new_arc_prize/</link>
      <description><![CDATA[Keras 的创建者兼《使用 Python 进行深度学习》一书的作者 François Chollet 宣布了一项名为 ARC Prize 的新挑战，旨在解决 ARC-AGI 基准。对于那些不熟悉的人来说，ARC（抽象和推理语料库）旨在衡量机器从几个例子中进行概括的能力，模拟类似人类的学习。 以下是宣布挑战的推文：   ARC 基准对于当前的深度学习模型（包括我们今天看到的大型语言模型 (LLM)）来说非常困难。它旨在测试人工智能理解和应用抽象推理的能力——这是通用智能的一个关键组成部分。 很想知道这个社区对 ARC 挑战及其对人工智能研究的影响的看法。  ARC 是衡量人工智能泛化的良好指标吗？  与其他基准相比，您认为 ARC 基准在多大程度上反映了人工智能的泛化能力？ ARC 中是否存在任何固有的偏见或限制，可能会扭曲结果？  人工智能泛化的现状  当前模型在 ARC 上的表现如何，它们的主要局限性是什么？ 最近是否有任何突破或技术有望解决 ARC 挑战？  ARC 大奖挑战的潜在影响  这项挑战将如何影响 AI 未来的研究方向？ 为这一挑战开发的解决方案除了解决 ARC 特定任务之外，是否还有更广泛的应用？  策略和方法  您认为哪种方法可能有效解决 ARC 基准？ 是否存在任何未充分探索的领域或新颖的方法可能破解 ARC 代码？      提交人    /u/HairyIndi​​anDude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de2b16/d_françois_chollet_announces_new_arc_prize/</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习论文与最佳人物</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de0i4b/d_ml_papers_with_the_best_figures/</link>
      <description><![CDATA[我经常很难制作出美观且高质量的图表，因此我认为下次需要制作图表时，要求提供论文作为参考会很有帮助。我想到了 RLHF 管道图。还有哪些其他论文浮现在我的脑海中或通常用作参考？    提交人    /u/SatisfyingLatte   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de0i4b/d_ml_papers_with_the_best_figures/</guid>
      <pubDate>Wed, 12 Jun 2024 07:04:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 拥有 ML/AI 博士学位会限制你从事哪些类型的工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddua2b/d_what_kind_of_jobs_do_a_phd_in_mlai_restrict_you/</link>
      <description><![CDATA[我已经看到很多关于博士学位如何可能或不可能帮助你获得特定 X 工作机会的帖子。 但我很好奇，获得博士学位是否实际上会限制你从事某些工作，因为雇主认为你资历过高、你太老了，或者你缺乏生产 YOE 等。    提交人    /u/Confident_Ad_7734   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddua2b/d_what_kind_of_jobs_do_a_phd_in_mlai_restrict_you/</guid>
      <pubDate>Wed, 12 Jun 2024 01:01:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用平方误差而不是绝对误差？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddjbdi/why_use_squared_error_instead_of_absolute_error_d/</link>
      <description><![CDATA[我不明白为什么当错误 = 0 时得到未定义的偏导数会是一个大问题，我的意思是得到零错误不是我们从一开始就想要的吗？    提交人    /u/NeatJealous8110   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddjbdi/why_use_squared_error_instead_of_absolute_error_d/</guid>
      <pubDate>Tue, 11 Jun 2024 17:07:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024年机器学习研究的热门话题是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddhu8n/d_what_are_the_hot_topics_in_machine_learning/</link>
      <description><![CDATA[今年，哪些子领域/方法、应用领域有望在学术界或工业界获得广泛关注（无意双关）？ PS：请不要羞于提出您认为或知道的任何可能是 ML 中流行的研究主题，您所知道的内容很可能对我们中的许多人来说相对不为人知：)    提交人    /u/knut_2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddhu8n/d_what_are_the_hot_topics_in_machine_learning/</guid>
      <pubDate>Tue, 11 Jun 2024 16:06:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>