<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 30 Dec 2024 21:14:58 GMT</lastBuildDate>
    <item>
      <title>[D] 使用 pytorch metricd FID 后，cpu 100% 且新笔记本电脑崩溃</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpvfyh/d_cpu_100_and_new_laptop_crashes_after_using/</link>
      <description><![CDATA[所以我今天买了一台新笔记本电脑，因为我需要一台新笔记本电脑上大学。规格如下： Windows 11 Home 处理器 Intel® Core™ Ultra 7 155U 内存 32 GB RAM 存储 1 TB SSD 显示屏 43.9 cm (17.3&quot;)、FHD (1920 x 1080)、触摸屏 图形 NVIDIA® GeForce RTX™ 3050 (4gb) 我需要使用 3500 张图像从 pytorch 运行 FID 指标。我通常使用 CPU 执行此操作。但是，当我执行此操作时（在 vs code 上），CPU 使用率突然上升到 100%，笔记本电脑开始冻结并崩溃。此时我还能听到硬件发出的一些奇怪的声音。  我重新启动了笔记本电脑，似乎没问题，但我现在想知道这是否“应该发生”？ 也就是说，这台笔记本电脑的规格如此之高，它是否能够运行正常代码而不会让 CPU 使用率达到 100% 并再次执行这种奇怪的事情？    提交人    /u/Sessaro290   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpvfyh/d_cpu_100_and_new_laptop_crashes_after_using/</guid>
      <pubDate>Mon, 30 Dec 2024 19:37:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对于 LightGBM 中约 1GB 的财务数据集，GPU 训练/回测比 CPU 训练/回测慢 2 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpuerz/r_gpu_trainingbacktesting_is_2x_slower_than_cpu/</link>
      <description><![CDATA[ LightGBM 中的 tldr： device_type=gpu 大约需要 250 秒才能运行 46 次训练 + 回测（慢 2 倍） device_type=cpu 大约需要 130 秒才能运行 46 次训练 + 回测 device_type=cuda 无法测试，因为 Windows 不支持，但欢迎有类似经验的 linux-gpu 用户发表评论，他们训练过小型数据集  运行自动交易机器人近 4 年，并在过去 2 年开始使用 LightGBM 测试平台： 3 年旧的 Windows 联想军团 amd64（8 核）笔记本电脑 移动 rtx3060 gpu 通过 c-api 在 LightGBM v4.5.0 中训练  尝试使用 device_type=gpu 与 device_type=cpu 遗憾的是无法测试 device_type=cuda，因为 Windows 不支持：(   数据集： ~1gb 财务数据，跨越 5 年 30 个特征  训练/回测性能显示 LightGBM gpu 模式比 cpu 模式运行慢 2 倍： num_iteration=250, learning_rate=0.1000 每次设置运行都会在 LightGBM 中重复训练过程约 46 次  1 次训练过程用于今天的数据（用于实时交易的生产） 45 次训练过程用于回测过去 45 个交易日  device_type=gpu 大约需要 250 秒才能运行 46 次训练+回测（慢 2 倍） device_type=cpu 大约需要 130 秒才能运行 46 次训练+回测 device_type=cuda ??? （无法在 Windows 中测试）   杂项  生产 tradebot 使用云端的 apple-silicon 运行（但没有 gpu 硬件） apple-silicon 比云端的 linux-x64 更快  使用 apple-silicon 在云端进行~120 秒训练+回测 使用 linux-x64 在云端进行~150 秒训练+回测      提交人    /u/kaizhu256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpuerz/r_gpu_trainingbacktesting_is_2x_slower_than_cpu/</guid>
      <pubDate>Mon, 30 Dec 2024 18:53:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 结合两个不同平台用户偏好的推荐系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpuc6x/d_recommendation_system_that_combines_users/</link>
      <description><![CDATA[大家好，我目前正在开发一个音乐推荐系统项目，该项目包含两个不同的用户互动和偏好来源。一个来源包含不同专辑和曲目的不同用户评论和评分，另一个来源包含用户的音乐收听行为。这两个数据源完全独立于另一个。另一种表达问题的方式是根据用户评论和评分 + 单独的收听历史来推荐歌曲/专辑。关于如何结合这两个来源的任何想法或相关作品的任何参考资料？提前谢谢！    提交人    /u/cacwj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpuc6x/d_recommendation_system_that_combines_users/</guid>
      <pubDate>Mon, 30 Dec 2024 18:50:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 介绍 LongTalk-CoT v0.1：用于推理模型后训练的超长思维链数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpp8ph/p_introducing_longtalkcot_v01_a_very_long/</link>
      <description><![CDATA[我很高兴发布LongTalk-CoT v0.1，这是一个专为后期训练 o1 类推理模型设计的数据集。每个响应都使用 QwQ-32B-Preview 提示，特别是手工制作的系统消息，鼓励更多发声思考和自我反思。  训练后数据集包含97M 个标记（使用 meta-llama/Llama-3.1-8B-Instruct 标记器）。 输出标记长度比 HuggingFaceTB/smoltalk 🤔💭长 5.29 倍 提升ProcessBench中的性能可用于 SFT 和 RL /偏好优化 微调模型能够解决 9.11 是否大于 9.9 以及草莓单词中有多少个字母 R！     由    /u/transformer_ML 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpp8ph/p_introducing_longtalkcot_v01_a_very_long/</guid>
      <pubDate>Mon, 30 Dec 2024 15:11:04 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 使用 LLM 与您的推荐系统进行讨论。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpo6y9/discussion_talk_to_your_recommendation_system/</link>
      <description><![CDATA[LLM 能否帮助我们向推荐系统提出我们的需求： 大型语言模型 (LLM) 与推荐系统的交集代表了机器学习研究的一个令人兴奋的前沿。虽然传统的推荐系统擅长模式匹配和协同过滤，但它们往往难以细致地理解用户上下文，也难以进行自然对话。通过将 LLM 集成为推荐系统的智能接口，我们可以解决这些限制，同时保留使推荐系统有效的强大算法基础。 考虑这样一个场景：用户表达：“我是一个 50 岁的中国人，住在芬兰，喜欢园艺。”如果没有明确的特征工程，传统的推荐系统将很难解析这种丰富的上下文信息。然而，LLM 可以自然地提取多个相关维度：文化背景、地理限制、气候因素以及基于年龄的潜在身体能力。这种自然语言理解层将非结构化的人工输入转换为可以增强推荐管道的结构化特征。 这种混合方法的真正威力在于它能够弥合用户意图和系统功能之间的语义鸿沟。LLM 擅长理解用户可能未明确说明的隐式约束和偏好。例如，系统可以推断芬兰的中国园丁可能对中国传统植物的耐寒品种感兴趣，或者对将亚洲园艺实践适应北欧条件的技术感兴趣。仅使用传统的推荐架构很难实现这种级别的上下文推理。 使用 Chatgpt 进行橡皮鸭练习的其他示例。  “我是一名 35 岁的孕妇，患有 1 型糖尿病，住在蒙大拿州农村。我是一名护士，上夜班，需要适合我的时间表和身体状况的锻炼建议。我也遵循犹太饮食习惯。” “我是一名巴西软件工程师，拥有 8 年 Java 经验，目前居住在柏林。我有兴趣转向 AI 开发，但需要根据我的阅读障碍和注意力缺陷多动障碍 (ADHD) 来安排我的学习。我的公司主要使用德语文档。” “我们是多伦多的一个韩裔墨西哥混血家庭，有三个孩子（分别为 4 岁、8 岁和 13 岁）。正在寻找有助于维持两国文化联系的周末活动。我们最小的孩子患有自闭症，对噪音很敏感。” “我是一名来自印度的 45 岁自由艺术家，现居住在新西兰。我使用多种货币赚钱，在印度有一个受赡养的父母，并且对符合我的印度教价值观的可持续投资感兴趣。我还有美元学生贷款。” “我是一名来自日本、现居冰岛的聋哑摄影师。我专攻极光摄影，希望拓展到野生动物摄影领域。我使用轮椅，需要建议可进入的地点和专用设备。” “我是新加坡的一名穆斯林家庭教师，有三个 12 岁的小孩，他们数学天赋异禀。一个患有注意力缺陷多动障碍，另一个是色盲，第三个是游泳健将。需要课程建议，既能适应三个孩子，又能保留他们的伊斯兰价值观。”     提交人    /u/Maleficent-Scene7771   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpo6y9/discussion_talk_to_your_recommendation_system/</guid>
      <pubDate>Mon, 30 Dec 2024 14:20:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 叙述数据（故事）可以存储为知识图谱吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpiu23/d_can_narrative_data_stories_be_stored_as/</link>
      <description><![CDATA[这是在将故事存储为 RAG 问答的 KG 的背景下。 KG 在存储本体/关系数据和查询事实数据方面非常出色。但如何在不丢失大量信息的情况下将叙述数据存储在知识图谱中？首先，故事中有一个时间维度，关系会随着故事的发展而改变（一个人可能在第 1 章停留在位置 A，而在第 2 章移动到位置 B）。 这个https://www.youtube.com/watch?v=g6xBklAIrsA有一些想法，但并没有真正涉及问题。    提交人    /u/noellarkin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpiu23/d_can_narrative_data_stories_be_stored_as/</guid>
      <pubDate>Mon, 30 Dec 2024 08:32:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 为什么 MAMBA 没有流行起来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpg91o/d_why_mamba_did_not_catch_on/</link>
      <description><![CDATA[从所有的炒作来看，MAMBA 似乎将取代 transformer。它速度很快，但仍保持了 transformer 的性能。训练期间为 O(N)，推理期间为 O(1)，并且准确率相当高。那么为什么它没有占据主导地位呢？状态空间模型的状态是什么？    提交人    /u/TwoSunnySideUp   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpg91o/d_why_mamba_did_not_catch_on/</guid>
      <pubDate>Mon, 30 Dec 2024 05:39:42 GMT</pubDate>
    </item>
    <item>
      <title>[R]几何直觉为什么 L1 将系数驱动为零</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp7us9/rgeometric_intuition_why_l1_drives_the/</link>
      <description><![CDATA[  由    /u/madiyar  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp7us9/rgeometric_intuition_why_l1_drives_the/</guid>
      <pubDate>Sun, 29 Dec 2024 22:34:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于在单个 H100 GPU 上 100 个 epoch 内实现 Imagnet 上 >=80% 准确率的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp4hph/d_advice_on_achieving_80_accuracy_on_imagnet_in/</link>
      <description><![CDATA[大家好！ 我目前正在尝试在单个 H100 GPU 上从头开始训练 ImageNet1K 上的 EfficientNetV2-medium 模型。由于 GPU 在我的实验室同事之间共享，因此每个 epoch 的训练时间非常慢。因此，我将训练 epoch 的数量限制为 100。鉴于这些限制，我想听听您的建议，关于如何才能获得超过 80% 的 top1 分数？ 根据我目前的配置，我可以达到 78%。以下是我的训练细节： 批次大小：256 学习率：0.1 优化器：动量为 0.9 的 SGD 权重衰减：2x10-5 学习率调度程序：余弦增强：TrivialAugmentWide、RandomCrop(8) 混合精度训练 (bf16) 深度学习库：Pytorch Lightning 我还应用了动态调整大小，其中我的训练和测试图像从 128x128 的大小开始，每 20 个 epoch 增加 24 个像素，直到第 80 个 epoch，图像大小固定为 224x224。 如果您能提供任何关于如何提高我的分数的见解，以及是否有可能进一步减少训练时间，我将不胜感激。 谢谢！    由    /u/atif_hassan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp4hph/d_advice_on_achieving_80_accuracy_on_imagnet_in/</guid>
      <pubDate>Sun, 29 Dec 2024 20:05:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们如何才能善用机器学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp0m3o/d_how_can_we_use_ml_for_good/</link>
      <description><![CDATA[您好，我即将完成我的学士学位，我真的想利用我学到的关于机器学习和数据工程的知识来帮助人们，我有一些之前的经验，但如果我们可以与一些初创公司合作，分享我们关于机器学习和工程的知识并真正创造价值，那就太好了。 你知道一些初创公司或非政府组织利用他们的数据技能来帮助人们或促进创新吗？ 我们如何使用我们的技能来帮助别人？ 我一直在想，为小型企业设置基本的数据基础设施，然后使用机器学习算法帮助他们提高生产力会很好，但我不知道从哪里开始。    提交人    /u/Southern_Respond846   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp0m3o/d_how_can_we_use_ml_for_good/</guid>
      <pubDate>Sun, 29 Dec 2024 17:16:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了 Termite，一个可以通过简单的文本提示生成终端 UI 的 CLI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyzao/p_i_made_termite_a_cli_that_can_generate_terminal/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyzao/p_i_made_termite_a_cli_that_can_generate_terminal/</guid>
      <pubDate>Sun, 29 Dec 2024 16:02:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢所有人在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</guid>
      <pubDate>Sun, 29 Dec 2024 16:00:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 批量标准化及其对梯度的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoy9zk/d_batch_normalization_and_effect_on_the_gradients/</link>
      <description><![CDATA[我最近在读这篇论文：https://arxiv.org/pdf/1706.05350，我想了解作者是如何得出梯度与权重成反比这一事实的。这是第 3 页上的第一个等式。如果有人能给我提示或解释，我将不胜感激。    提交人    /u/Numerous_Talk7940   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoy9zk/d_batch_normalization_and_effect_on_the_gradients/</guid>
      <pubDate>Sun, 29 Dec 2024 15:29:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 ARIMA/SARIMA 进行风速预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hou9cq/p_wind_speed_prediction_with_arimasarima/</link>
      <description><![CDATA[      我正在做一个风速预测的项目。有些文章说使用 ARIMA / SARIMA 会是一个好的开始。 我确实开始使用 ARIMA，并且预测值没有任何变化。 当我尝试使用 SARIMA，季节性 = 12（一年中的月份），预测 36 个月（3 年）时，它给了我不满意的结果，这些结果看起来每年都一样（周期性的，因此远离现实）所以我放弃了 SARIMA。 请随时给我解决方案或更好的方法。    提交人    /u/Associate-Existing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hou9cq/p_wind_speed_prediction_with_arimasarima/</guid>
      <pubDate>Sun, 29 Dec 2024 11:33:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>