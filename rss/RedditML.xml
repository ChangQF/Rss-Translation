<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 26 Apr 2024 12:24:49 GMT</lastBuildDate>
    <item>
      <title>我可以同时学习 ML 和 Web 开发吗？ [r]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdjayv/can_i_learn_ml_and_web_development_simultaneously/</link>
      <description><![CDATA[TLDR;我应该同时学习angela yu和Andrew ng的100天Python吗？嘿伙计们，我是一名全日制计算机科学学生，我通常从上午9点/上午11点到下午1点/3点上课，所以我的第二学期即将开始，我想学习一些网络开发并学习机器学习。所以，我购买了 Angela yu 博士的课程（Python 100 天），用于 Python 和 Web/Web 应用程序开发。接下来是 Andrew ng 的 ML 专业课程。我应该同时学习这两门课程吗？由于 100 天的课程非常长，可能会超过 100 天，所以我不能推迟学习 ML，因为我想专攻它。我应该怎么办？我的时间是早上 6 点到上午 9 点 11 分、下午 3 点到 6 点、晚上 7 点到 10:30。我也需要做大学作业。所以请给我真诚的建议。   由   提交/u/Extreme_Sky_8749   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdjayv/can_i_learn_ml_and_web_development_simultaneously/</guid>
      <pubDate>Fri, 26 Apr 2024 11:46:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 干净的字幕数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdimby/d_clean_caption_dataset/</link>
      <description><![CDATA[我正在尝试从头开始训练 CLIP。然而，缺乏可用的数据集。看起来相当多样化且干净的一个数据集似乎已被删除 (laion-400m)。看看 HF 数据集，这是两个很有前途的数据集，但想知道是否有更好/更干净的数据集。 - 概念性标题：使用替代文本。 - red_caps：reddit 线程，但这些大多是图像上的第一个评论，而不是实际的标题。 TIA   由   提交/u/themathstudent  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdimby/d_clean_caption_dataset/</guid>
      <pubDate>Fri, 26 Apr 2024 11:09:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士：为什么情境学习有效？从技术角度来看到底发生了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdih0a/d_llms_why_does_incontext_learning_work_what/</link>
      <description><![CDATA[在我寻找这个问题的答案时，得到的答案只不过是将模型拟人化而已。他们总是提出这样的主张：  如果没有示例，模型必须推断上下文并依靠其知识来推断出预期的结果。这可能会导致误解。 一次性提示通过提供具体示例来减轻这种认知负担，有助于锚定模型的解释并专注于具有更清晰期望的更狭窄的任务。  该示例充当模型的参考或提示，帮助其理解您正在寻求的响应类型并在训练期间触发对类似实例的记忆。&lt; /p&gt; 提供示例允许模型识别要复制的模式或结构。它为模型建立了一个对齐线索，减少了零样本场景中固有的猜测。  顺便说一句，这些是真实的摘录。 但这些模型不“理解”任何东西。他们不“推断”，或“解释”，或“聚焦”，或“记住训练”，或“猜测”，或有字面上的“认知负荷”。它们只是统计令牌生成器。因此，当寻求对上下文学习提高准确性的确切机制的具体理解时，像这样的流行科学解释是毫无意义的。 有人可以提供一个根据实际模型来解释事物的解释吗？架构/机制以及提供额外上下文如何带来更好的输出？我可以“说说而已”，所以请不遗漏任何技术细节。 我可以做出有根据的猜测 - 在输入中包含示例，这些示例使用与您想要的输出类型近似的标记，从而引导注意力机制，并且最终的密集层对更高的令牌进行加权，这些令牌在某种程度上与这些示例相似，从而增加了在每个生成步骤中对这些所需令牌进行采样的几率；就像从根本上讲，我猜测相似性/距离的事情，其中​​明确举例说明我想要的输出会增加获得的输出与其相似的可能性 - 但我更愿意从对这些模型有深入了解的其他人那里听到它   由   提交 /u/synthphreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdih0a/d_llms_why_does_incontext_learning_work_what/</guid>
      <pubDate>Fri, 26 Apr 2024 11:01:38 GMT</pubDate>
    </item>
    <item>
      <title>在服务器上部署预训练模型以进行实时图像处理 [D] [R] [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdh5w8/deploying_pretrained_model_on_a_server_for/</link>
      <description><![CDATA[我有一个flask应用程序，它使用预训练的ml模型，其主要任务是查找图像的嵌入，一次可能有100s要处理的图像数量，假设 100 个图像处理需要 80 秒才能完成，我应该如何在 AWS 或任何其他云服务上部署应用程序，以便处理 100 个图像只需要 4-5 秒。    由   提交/u/No-Ganache4424  /u/No-Ganache4424 reddit.com/r/MachineLearning/comments/1cdh5w8/deploying_pretrained_model_on_a_server_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdh5w8/deploying_pretrained_model_on_a_server_for/</guid>
      <pubDate>Fri, 26 Apr 2024 09:38:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关键批量大小和法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdgxit/d_critical_batch_size_and_llms/</link>
      <description><![CDATA[在有关“小指南”的视频中到 2024 年构建大型语言模型” 41:38 作者开始讨论批量大小的限制。 ​  好吧，如果你当批量大小开始非常大时，每个优化步骤的模型都会降低每个令牌的使用效率，因为批量大小太大，以至于每个令牌在优化步骤中都会被淘汰。粗略地说，衡量这个限制有点困难，我们称之为临界批量大小。  我认为较大的批量大小对于训练 LLM 总是更好，因为： p&gt;  它更好地近似真实梯度。 我们更快地浏览数据集。 据我所知，限制仅在于基础设施、硬件、通信开销等.  我发现一篇论文介绍了“临界批量大小”概念 - 大批量训练的经验模型。它主要讨论大批量数据并行的速度/效率权衡。另一篇被高度引用的论文神经语言模型的缩放定律：  在临界批量大小下进行训练提供了时间和计算效率之间的大致最佳折衷  所以我不太明白视频作者的意思：  每个令牌是在优化步骤中有点被淘汰  除了基础设施、硬件或实现限制之外，大批量还有其他问题吗？   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdgxit/d_critical_batch_size_and_llms/</guid>
      <pubDate>Fri, 26 Apr 2024 09:21:42 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 时间序列回归问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdgxfk/discussion_time_series_regression_problem/</link>
      <description><![CDATA[      大家好，我有一个问题，我不确定什么是最好的方法（我真的找不到任何相关文献）。我有一个传感器值的小数据集（约 100 个测量值，如附加的测量值），我想预测某个相关事件。这里 t_0 是我想要预测的相关时刻。问题是，我需要在事件发生时触发一些东西。如果我在达到事件后需要太长时间才能触发，这不会是一个积极的结果。我最初的想法是基本上对事件之前的时间序列进行分块，并尝试从该片段预测到达事件之前的剩余时间。当它低于阈值时，我可以触发我的操作。我想看看例如XGBoost 并向其提供时间序列的小块并连续运行该过程。我不太确定这是否是正确的方法。这是一个已知问题吗？这个问题搜索文献时用什么名字比较好？您有如何解决这个问题的建议吗？ 谢谢。 https://preview.redd.it/l59gsmswkswc1.png?width=1303&amp;format=png&amp;auto=webp&amp;s=f9e83d7b87ce5227378de6a080 5a916fd4f93314   由   提交/u/seboz12345  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdgxfk/discussion_time_series_regression_problem/</guid>
      <pubDate>Fri, 26 Apr 2024 09:21:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 文本到语音合成的最新技术是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdcbmx/d_what_is_the_state_of_art_for_text_to_speech/</link>
      <description><![CDATA[我开始为毕业做一些研究，我正在寻找一些关于文本到语音合成的论文。我正在对一篇我发现很有趣的论文进行一些复制，这篇论文名为通过调节 WaveNet 的梅尔频谱图预测进行自然 TTS 合成。基本上，它是一个接收文本、将其转换为频谱图并使用频谱图构建音频文件的模型。由于我仍处于复制的开始阶段，你们有什么论文可以推荐我研究吗？你研究过语音合成 (TTS) 吗？我应该参考哪些好的参考资料？ ​ 我在这里看到了这篇文章 https://www.reddit.com/r/MachineLearning/comments/nxkuvn/d_what_is_actually_the_state_of_the_art_in_text/ 但是它已经有 3 年了。也许有比 FastSpeech2 更新的东西？ ​    提交人    /u/Zelun   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdcbmx/d_what_is_the_state_of_art_for_text_to_speech/</guid>
      <pubDate>Fri, 26 Apr 2024 04:24:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 元学习 vs 联邦学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdbq5t/d_metalearning_vs_federated_learning/</link>
      <description><![CDATA[[D] 大家好，对于深入研究当今热门话题的更好选择和最有效方法，您有什么建议吗？&lt; br /&gt; 我偶然发现了联邦学习的存储库： ​  https://github.com/muditbhargava66/dropgrad https://github.com/ adap/flower  但似乎找不到类似元学习的东西。任何有关如何选择我的博士主题的建议将不胜感激！   由   提交/u/Tight_Confusion_1695   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdbq5t/d_metalearning_vs_federated_learning/</guid>
      <pubDate>Fri, 26 Apr 2024 03:53:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 多头专家混合 - https://arxiv.org/pdf/2404.15045 中建议的密集子代币路由的实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cd42cp/p_multihead_mixture_of_experts_implementation_of/</link>
      <description><![CDATA[我的朋友在这篇 arxiv 论文中实现了 Multihead Mixture of Experts 的方法 https://arxiv.org/pdf/2404.15045 他希望我与你分享！ https://github.com/lhallee/Multi_Head_Mixture_of_Experts__MH-MOE 尝试一下。让我知道您的想法，我会将其传递给他。   由   提交/u/Prudent_Student2839   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cd42cp/p_multihead_mixture_of_experts_implementation_of/</guid>
      <pubDate>Thu, 25 Apr 2024 22:00:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] HyenaDNA 和 Mamba 不擅长顺序标记？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cd13kf/d_hyenadna_and_mamba_are_not_good_at_sequential/</link>
      <description><![CDATA[大家好，我一直在研究使用 DNA 序列作为输入的顺序标记。最近发布了 2 个基础模型 HyenaDNA（基于 Hyena Operator）和 Caduceus（基于 mamba），我使用了预训练模型和从头开始的模型，即使使用预训练模型，性能也很糟糕。  有人有此类模型的经验吗？性能下降的潜在原因是什么？我在少数群体中的成绩实际上为零？曼巴在阶级不平衡问题上处理得不好吗？   由   提交/u/blooming17  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cd13kf/d_hyenadna_and_mamba_are_not_good_at_sequential/</guid>
      <pubDate>Thu, 25 Apr 2024 20:02:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 基于图的神经网络的药物毒性预测模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cczqej/p_drug_toxicity_prediction_model_with_graphbased/</link>
      <description><![CDATA[这是我编写/训练的一个小型药物毒性预测 GNN 模型 repo: https://github.com/Null-byte-00/有毒-预测-gnn    由   提交 /u/Soroush_ra   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cczqej/p_drug_toxicity_prediction_model_with_graphbased/</guid>
      <pubDate>Thu, 25 Apr 2024 19:10:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 面对不可能的机器学习问题，您有哪些恐怖经历</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ccz2cq/d_what_are_your_horror_stories_from_being_tasked/</link>
      <description><![CDATA[机器学习非常擅长解决一系列小众问题，但大多数技术细微差别都被技术兄弟和管理者忽视了。您被告知要解决哪些问题是不可能的（没有数据、无用的数据、不切实际的期望）或机器学习的误用（您能让这个法学硕士做所有的会计工作吗）。    由   提交 /u/LanchestersLaw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ccz2cq/d_what_are_your_horror_stories_from_being_tasked/</guid>
      <pubDate>Thu, 25 Apr 2024 18:45:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 旧论文 - 机器学习学术界令人不安的趋势</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ccve1k/d_old_paper_troubling_trends_in_machine_learning/</link>
      <description><![CDATA[我只是想提醒或向新人介绍这篇论文。我认为应该重新开启这个讨论，因为这里的许多人实际上确实影响了该领域的趋势。 https://arxiv.org/pdf/1807.03341&quot;&gt;https:// /arxiv.org/pdf/1807.03341  个人笔记（随意跳过）： 具体来说，我想指出这个问题“Mathiness”，因为这个问题似乎失控了，并且大多数会议的最佳论文都受到了它的困扰（最重要的 ML 论文之一试图数学化，但引入了一个大错误，我相信其他论文有更大的问题，但没有人费心去检查）。 所以这是我个人对学者和研究人员的观点：  我们（我认为大多数将会涉及），从业者不需要方程来知道什么是召回率，并且显然不想阅读难以理解的线性回归版本，这只会让你的论文毫无用处。如果您不想浪费我们的时间，请将其放入附录或完全删除。 审稿人，请不要对不必要的数学印象深刻，如果它很复杂并且没有任何用处，谁关心吗？而且，无论如何它都可能有缺陷，您可能不会发现它。    由   提交/u/pyepyepie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ccve1k/d_old_paper_troubling_trends_in_machine_learning/</guid>
      <pubDate>Thu, 25 Apr 2024 15:50:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 Transformer 没有进行分层训练？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cct38r/d_why_transformers_are_not_trained_layerwise/</link>
      <description><![CDATA[在我看来，由于残差路径，无论变压器层/块如何，流向每一层的梯度都是相同的。示例： ProjectionAndCost(X + L1(X) + L2(X + L1(X)) + L3(X + L1(X) + L2(X + L1(X))) ... ） 由于 ProjectionAndCost 的输入只是所有层和初始嵌入的输出之和，因此到达 L1 层的梯度与到达 L2 或 L3 的梯度相同。 因此我们可以：  首先仅训练 L1：ProjectionAndCost(X + L1(X)) 冻结 L1，包括 L2 并训练：ProjectionAndCost(X + L1(X) + L2(X + L1(X))) 冻结 L1 和 L2，包括 L3 并训练：ProjectionAndCost(X + L1(X) + L2(X + L1(X)) + L3(X + L1(X) + L2(X + L1(X)))) ..依此类推  我们不能先训练L2 然后是 L1，因为 L2 的输入取决于 L1，但我们可以先训练较低层，然后逐渐添加和训练更深的层。这种方法有什么问题吗？   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cct38r/d_why_transformers_are_not_trained_layerwise/</guid>
      <pubDate>Thu, 25 Apr 2024 14:16:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>