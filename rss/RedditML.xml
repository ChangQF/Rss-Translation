<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 21 Nov 2024 18:23:11 GMT</lastBuildDate>
    <item>
      <title>[讨论] VQVAE 重建问题：灰度输出和梯度流洞察</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwl7c9/discussion_vqvae_reconstruction_issue_grayscale/</link>
      <description><![CDATA[      我最近在 COCO 数据集上训练了一个 VQVAE 模型，并且它成功收敛，生成了具有精细细节的图像。然而，在推理过程中，我注意到一些不寻常的事情。 当我尝试仅使用量化向量重建图像并将其传递给解码器时，生成的输出是保留原始边缘的灰度图像。 如附图所示，第二张图像是重建的图像。在这种情况下，我包含了码本梯度流项，如下所示： x = x + (x - z).detach()  经过这种修改，生成的图像看起来更干净。 我很好奇，想知道这种行为是否是 VQVAE 所期望的，或者我的实现是否存在问题。如果有人有使用 VQVAE 的经验，我们将非常感谢您的见解！ https://preview.redd.it/g961r7f3ka2e1.png?width=1688&amp;format=png&amp;auto=webp&amp;s=94d94e51c76a508949b2dee7e4341b6ec079dab1    提交人    /u/Logical-Passenger471   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwl7c9/discussion_vqvae_reconstruction_issue_grayscale/</guid>
      <pubDate>Thu, 21 Nov 2024 17:41:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求期刊建议，发表关于人工智能辅助 DSM-5-TR 和 ICD-10 诊断的附带项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwl0fn/d_seeking_journal_suggestions_for_publishing_a/</link>
      <description><![CDATA[寻求期刊建议，以发布有关人工智能辅助 DSM-5-TR 和 ICD-10 诊断的副项目 我一直在与一位心理学家合作一个副项目。这是一个检索增强生成 (RAG) 模型，它使用 DSM-5-TR 和 ICD-10 根据用户查询提出最可能的诊断。它旨在用于精神病学和医学诊断，以帮助从业者、研究人员和学生。 我现在正处于想要发布我的作品的阶段，但我不隶属于任何机构，这纯粹是一个热情项目。我希望找到具有以下条件的期刊：  出版费用低于 1,000 美元（或理想情况下免费！）。 相对较快的审查过程（最好少于 2 个月）。 开放获取将是一个加分项，因此尽可能多的人都可以使用。  您知道哪些期刊可能适合这类工作？如果该期刊对独立研究人员或附带项目友好，则可以获得加分。 提前感谢您的帮助！😊    提交人    /u/drinkredstripe3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwl0fn/d_seeking_journal_suggestions_for_publishing_a/</guid>
      <pubDate>Thu, 21 Nov 2024 17:34:11 GMT</pubDate>
    </item>
    <item>
      <title>如何在推理过程中高效地从 RNN 和 Transformers 生成文本 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwkrir/how_to_efficiently_generate_text_from_rnns_and/</link>
      <description><![CDATA[我看到的大多数笔记本都这样做来生成代码 text = [&#39;start&#39;] for _ in range(num_to_gen): token = model(text) text.append(token)  但这显然效率低下，最好在生成每个标记的同时保留隐藏状态，并将其逐个传递给模型。使用 pytorch 模型执行此操作的最干净/行业接受的方法是什么？ 我看到一个关于 pytorch 的教程，其中模型返回输出和隐藏状态，然后将隐藏状态传回模型。这感觉真的很笨重，对于较大的隐藏状态，将每个 rnn 层的隐藏状态一直传递到模型末尾是低效的。 就像我目前正在尝试使用 Mamba 一样，根据它的论文，它尽量不在内存中实现完整的隐藏状态。 我能想到的唯一其他方法是让模型通过前向调用保持隐藏状态，也许有一个重置函数。但我不确定这是否是一种可接受的做事方式。另外，我认为我没有在开源 mamba 模型的 state_dict 中看到隐藏状态，所以我觉得 Mamba 不会这样做，但不完全确定。我尝试阅读 Mamba 代码，但发现很难理解。 我很感激看到正确执行此操作的行业标准是什么，以及一些开源代码中解释的示例。另外，如果有人能帮助我理解 Mamba 在 github 上的 state-spaces/mamba repo 中是如何做到的，那就太好了，但也许我只会在 repo 上发表评论。 也很好奇 transformer 模型是如何处理这个问题的。    提交人    /u/No_Effective734   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwkrir/how_to_efficiently_generate_text_from_rnns_and/</guid>
      <pubDate>Thu, 21 Nov 2024 17:24:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] Grokking 的复杂性动态</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwju03/r_the_complexity_dynamics_of_grokking/</link>
      <description><![CDATA[https://openreview.net/pdf?id=07N9jCfIE4 尽管 OpenReviewers 似乎对这篇论文不以为然，但我发现它非常有趣。我喜欢其中涉及的概念 / 想法：  正则化方法（例如规范）通常测量容量，而不是复杂性。 尝试更接近 Kolmogorov 复杂性的正则化。 将模型复杂性与泛化和理解联系起来。     提交人    /u/marojejian   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwju03/r_the_complexity_dynamics_of_grokking/</guid>
      <pubDate>Thu, 21 Nov 2024 16:48:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] BALROG：对游戏上的 Agentic LLM 和 VLM 推理进行基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwhnf8/r_balrog_benchmarking_agentic_llm_and_vlm/</link>
      <description><![CDATA[厌倦了饱和的基准测试？想要能力有显著飞跃的空间吗？  介绍 BALROG：游戏 Agentic LLM 和 VLM 推理的基准！ BALROG 是 LLM Agentic 功能的具有挑战性的基准，旨在在未来几年保持相关性。 查看它！ GitHub：https://github.com/balrog-ai/BALROG 排行榜：https://balrogai.com 论文：https://arxiv.org/abs/2411.13543    提交人    /u/pagggga   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwhnf8/r_balrog_benchmarking_agentic_llm_and_vlm/</guid>
      <pubDate>Thu, 21 Nov 2024 14:33:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] Train 和 Val Dice Score 长时间为零，然后增加，而损失则不断减少。想知道为什么吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwhf4o/d_train_and_val_dice_score_gets_zero_for_a_long/</link>
      <description><![CDATA[  由    /u/__proximity__  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwhf4o/d_train_and_val_dice_score_gets_zero_for_a_long/</guid>
      <pubDate>Thu, 21 Nov 2024 14:22:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 好奇，您如何管理完整的 ML 生命周期？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwhdpl/d_curious_how_do_you_manage_the_full_ml_lifecycle/</link>
      <description><![CDATA[大家好！我一直在思考一个特定的问题/想法，我想提出来讨论一下，它涉及如何更快地将 ML/AI 应用从想法转化为生产。 我构建 ML 应用的经验以及与朋友和同事交谈的经验是，你得到的数据往往非常糟糕，所以你花大约 80% 的时间来清理数据、执行 EDA，然后进行一些特征工程，包括降维等。所有这些主要在笔记本中使用各种软件包，具体取决于目标。在此阶段，人们倾向于使用一些工具来管理和版本数据，例如 DVC 等 此后，在进行各种指标评估的模型构建时，通常会连接实验跟踪器（如 MLFlow）。然后，一旦就最佳模型达成共识，通常必须将 Jupyter Notebook 代码转换为纯 Python 代码，并围绕某些 API 或其他方式为模型提供服务。然后，有一个完整的操作组件，其中包含各种工具，以确保模型投入生产，并在一些事情中监控各种数据和模型漂移。 现在，生态系统充满了用于此生命周期各个阶段的工具，这很好，但操作化可能具有挑战性，我们都知道，有时采用 ML 时获得的结果可能非常好 :( 我一直在尝试各种平台，这些平台能够从云提供商平台（例如 AWS SageMaker、Vertex、Azure ML）实现端到端流程。流行的开源框架，如 MetaFlow，甚至尝试过 DagsHub。对于云提供商来说，它总是感觉像丛林一样，笨重，有时甚至过度，例如维护。此外，当要求真正帮助人们探索、测试和调查而无需太多设置的平台或工具时，感觉很欠缺，因为人们倾向于推荐一些很棒但只包含拼图一部分的工具。到目前为止，我发现的最好的是 Lightning AI，尽管在实验跟踪方面它是缺乏。 因此，我一直在考虑一个真正开箱即用的端到端平台的想法，这个想法不是重新发明轮子，而是将许多好的工具结合在由协作 AI 代理驱动的端到端流程中，以帮助加快整个 ML 生命周期的工作流程，从而更快地进行原型设计和迭代。 这还处于早期阶段，所以有几件事需要弄清楚，但我很想听听你对上述假设的反馈，你今天如何解决这个问题？    提交人    /u/Lumiere-Celeste   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwhdpl/d_curious_how_do_you_manage_the_full_ml_lifecycle/</guid>
      <pubDate>Thu, 21 Nov 2024 14:20:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 还有人记得 2023 年机器学习总结模因视频吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwh8yk/d_does_anyone_remember_the_machine_learning_in/</link>
      <description><![CDATA[去年这个时候，有人发布了一段关于 2023 年机器学习的拼凑在一起的 meme 视频。我记不清所有的 meme，但肯定有一个是关于 NLP 教授需要学习 RL 的，还有一个是关于 Anthropic 出现在美国政府某个部门面前的。 两个问题。  还有人记得这个视频并有链接吗？我无法使用 Google 找到它，因为“2023 年的机器学习”不是一个非常有辨别力的搜索查询。 会有 2024 年版吗？我希望如此！     提交人    /u/votadini_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwh8yk/d_does_anyone_remember_the_machine_learning_in/</guid>
      <pubDate>Thu, 21 Nov 2024 14:14:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] ICASSP 2025 评论已经出炉。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwgygb/r_icassp_2025_review_is_out/</link>
      <description><![CDATA[4 4 3 我可以省略反驳吗？ 接受率很高，但我想利润率也很高。    提交人    /u/Big_Occasion_182   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwgygb/r_icassp_2025_review_is_out/</guid>
      <pubDate>Thu, 21 Nov 2024 14:01:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在反驳期间我们可以对论文进行多少修改？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwf6t6/d_how_much_can_we_revise_paper_during_rebuttal/</link>
      <description><![CDATA[我目前正在准备 ICLR 反驳，修改论文是一种选择。我已经修复了大部分拼写错误，稍微改变了 1 或 2 个变量的符号（索引、转置，..）。有人可以给我一些建议吗，这会给审稿人/AC 留下负面印象吗？我们应该修改吗？    提交人    /u/Competitive_Newt_100   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwf6t6/d_how_much_can_we_revise_paper_during_rebuttal/</guid>
      <pubDate>Thu, 21 Nov 2024 12:32:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 时间系列中的下一个大事件？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gwbhxq/d_next_big_thing_in_time_series/</link>
      <description><![CDATA[在 NLP 中，我们已经看到了像 transformers、GPT 和 LLM 这样的重大里程碑，它们彻底改变了这个领域。时间序列研究似乎从 NLP 和 CV 中借鉴了很多东西——比如基于 transformer 的模型、自监督学习，现在甚至是专门用于时间序列的基础模型。但对于哪种方法最有效，似乎还没有达成明确的共识。例如，NLP 有广为接受的预训练策略，如掩蔽语言建模或下一个标记预测，但类似的策略并没有成为时间序列的标准。 最近，有很多关于将 LLM 改编为时间序列甚至专门为此目的构建基础模型的讨论。另一方面，一些研究表明 LLM 对时间序列没有帮助。 所以我只想知道什么可以改变时间序列的游戏规则！   由    /u/Few-Pomegranate4369  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gwbhxq/d_next_big_thing_in_time_series/</guid>
      <pubDate>Thu, 21 Nov 2024 08:20:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 努力转型为博士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gw61tk/d_struggling_to_transition_to_phd/</link>
      <description><![CDATA[“本科是回答问题，而博士是寻找问题。” — 某人 我是计算机科学博士一年级学生，但我觉得自己被困在本科生的思维模式中。我擅长解决问题，我的完美 GPA 就是明证。然而，在研究方面，我却很挣扎。如果我进入一个新领域，我通常会阅读大量论文、做笔记，最终能够写出一份像样的调查——但我很少产生新的想法。 与其他博士生交谈只会增加我的挫败感；其中一位博士生声称他们甚至可以在拉丁语课上想出法学硕士的想法。我的导师说研究更多的是坚持而不是天赋，但我觉得自己陷入了一个循环：我深入一个新领域，做了一个调查，然后就卡在那里了。 我对自己的智力很有信心，但我怀疑我的工作流程是否有缺陷（例如，也许我应该早点开始实验？）或者我是否不适合做研究。想出微小的改进或将 A 应用于 B 感觉很无趣，我很难花时间在这样的想法上。 你们计算机科学（机器学习）博士生是如何想出有意义的研究想法的？有什么建议可以打破这个循环吗？    提交人    /u/StraightSpeech9295   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gw61tk/d_struggling_to_transition_to_phd/</guid>
      <pubDate>Thu, 21 Nov 2024 02:50:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] RL/ML 理论博士学位或法学硕士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gvx8vx/d_phd_in_rlml_theory_or_llm/</link>
      <description><![CDATA[大家好， 我正处于学术旅程的十字路口，希望得到社区的见解。我正在考虑是攻读强化学习/机器学习理论博士学位，还是专攻大型语言模型并进行更多的实验/应用研究（我收到的只有这两个机会）。 主要考虑因素如下： 研究影响  强化学习/机器学习理论：可以促进该领域数学理解的基础工作 法学硕士：直接应用于当今最具变革性的人工智能系统  就业前景  理论：学术界、研究实验室，行业角色可能更有限 法学硕士：行业需求高，学术界和行业都有活跃的研究领域  长期相关性  理论：无论具体技术如何，核心原则都可能保持价值 法学硕士：目前具有革命性，但长期不确定轨迹  个人背景  我是一名国际学生，即将在美国完成我的硕士课程，所以在做出最终决定之前我没有足够的时间。我曾经研究过机器学习理论，但最终并没有在理论上发表真正的顶级会议出版物。我个人怀疑我是否有足够的数学背景来在这个领域攻读成功的博士学位（例如，每年至少在 ICML/NeurIPS/ICLR/COLT/AISTATS 上发表 2 篇理论论文）。同时，我个人怀疑理论是否确实推动了 ML/AI 社区的发展，因为许多论文只是证明空洞的界限或提出一些新的算法，这些算法本身甚至无法实现或经过实验测试。 我还曾经研究过更多的应用机器学习，发表过一篇 aaai 论文。我个人担心的是，我在实施和编码方面不够快，而这正是一名成功的应用机器学习研究人员最具战略性的能力。进入 LLM 时代后，应用 ML 研究（尤其是 LLM 和 CV）的节奏变得非常快。这就像研究社区中的竞争性编程（好吧，也是 #GPUs 竞赛）。     提交人    /u/Living_Imagination84   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gvx8vx/d_phd_in_rlml_theory_or_llm/</guid>
      <pubDate>Wed, 20 Nov 2024 19:02:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Nov 2024 16:00:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>