<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 01 Dec 2024 15:16:24 GMT</lastBuildDate>
    <item>
      <title>[R] 来源：为什么猎犬的 KG 表现优于 RD？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h447eu/r_sources_reasons_why_kg_outperformes_rd_in/</link>
      <description><![CDATA[是否有任何资料讨论为什么 Retriever 与 KG 配合使用效果比 RD 更好？我发现说它更好是非常直观的，因为在知识图中我们拥有更多的语义结构，并且可以有效地发现关系。在我看来，“图当然更丰富/更密集”，但在论文合作时，我突然意识到我无法证明这一说法。我找不到任何资料可以真正解释为什么会这样。 我得到的唯一资料是这个： https://arxiv.org/abs/2311.07509 去年在子版块中也有：https://www.reddit.com/r/LocalLLaMA/comments/17vy1bo/a_benchmark_to_understand_the_role_of_knowledge/ 所以我们只能说&amp;“我们证明我们的决定是正确的，因为 KG 比 RD 效果更好 [基准论文来源]&amp;; 我本来很想讨论为什么 KG 更适合，并给出关于信息密度、语义结构或相关实体的更好选择的论据。但我找到的只是一些文章，它们散布着荒谬的主张或指出了更简单/原生的实现，从技术上讲，这也可以通过 RD 实现。 有人可以告诉我资料来源吗？很想阅读关于更好性能原因的深入讨论。    提交人    /u/PopPsychological4106   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h447eu/r_sources_reasons_why_kg_outperformes_rd_in/</guid>
      <pubDate>Sun, 01 Dec 2024 14:17:17 GMT</pubDate>
    </item>
    <item>
      <title>ROI 图像增强 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h41z2x/augmentation_for_images_with_roi_d/</link>
      <description><![CDATA[我有一张带有 roi (x_min、y_min、x_max、y_max) 的图像。我想用 torchvison 进行随机翻转、旋转、倾斜、平移等。为了与增强图像匹配，您可以分别使用哪些不同的方式转换 roi？    提交人    /u/Brief_Papaya121   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h41z2x/augmentation_for_images_with_roi_d/</guid>
      <pubDate>Sun, 01 Dec 2024 12:11:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] Qwen-VL：用于理解、定位、文本阅读等的多功能视觉语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h40wms/r_qwenvl_a_versatile_visionlanguage_model_for/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h40wms/r_qwenvl_a_versatile_visionlanguage_model_for/</guid>
      <pubDate>Sun, 01 Dec 2024 10:59:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    <item>
      <title>最好的开源图像升级模型是什么？[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3qcon/whats_the_best_open_source_imageupscaling_model/</link>
      <description><![CDATA[      我正在使用Playground-v2.5-aesthetic制作一些用于 YouTube 缩略图的图像。我对结果非常满意： 1024x1024 火星基地基础图像。 但我希望图像为 1920x1080 像素，而我唯一的选择是 1024x1024 或 1280x720 像素。目前，我可以使用 Photoshop 的修饰功能达到 1920x1080 的图像分辨率： 1920x1080 的火星基地修饰图像。 这还可以，但是 Photoshop 的修饰功能是手动的，并且质量会下降相当明显。理想情况下，我会生成 1280x720 的图像，然后通过编程将其升级到 1920x1080。 我听说过以下模型：  Real-ERSGAN Waifu2 SRGAN  但在我深入研究其中任何一个之前，哪种开源模型通常被认为最适合实现这一目标？我有一台 RTX 3060 12GB VRAM。    提交人    /u/FPGA_Superstar   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3qcon/whats_the_best_open_source_imageupscaling_model/</guid>
      <pubDate>Sun, 01 Dec 2024 00:13:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] TIME-MOE：混合专家的十亿级时间序列预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3j1cm/p_timemoe_billionscale_time_series_forecasting/</link>
      <description><![CDATA[Time-MOE 是一个 2.4B 参数开源时间序列基础模型，使用 混合专家 (MOE) 进行零样本预测。 您可以在此处找到该模型的分析&gt;    提交人    /u/nkafr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3j1cm/p_timemoe_billionscale_time_series_forecasting/</guid>
      <pubDate>Sat, 30 Nov 2024 18:33:59 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 需要建议：被 COLING 2025 拒绝——我下一步应该关注哪个会议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3igva/discussion_advice_needed_rejected_from_coling/</link>
      <description><![CDATA[我被 COLING 2025 拒绝了，评审分数为 4、3、3。我正在修改手稿并寻求有关下一个最佳 NLP 会议的建议。有没有类似的顶级会议的建议？ 谢谢！    提交人    /u/Cold-Traffic-7586   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3igva/discussion_advice_needed_rejected_from_coling/</guid>
      <pubDate>Sat, 30 Nov 2024 18:08:01 GMT</pubDate>
    </item>
    <item>
      <title>[P]用Excel构建的完整变压器模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3hj6j/p_a_complete_transformer_model_built_in_excel/</link>
      <description><![CDATA[        提交人    /u/Revolutionary-Way290   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3hj6j/p_a_complete_transformer_model_built_in_excel/</guid>
      <pubDate>Sat, 30 Nov 2024 17:25:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] RNN 的现代用例？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h38ym2/d_modern_usecases_for_rnns/</link>
      <description><![CDATA[讨论可以分为两个方面。1）您认为，对于个人项目规模而言，哪些任务是您认为接近传统实现（LSTM、GRU）的 RNN 仍然是最佳的起点和终点？尤其是与 transformers 相比。 在小型时间序列预测设置中，我可以看到 GRU 可能比 Transformer 更方便，但我对输入是符号或度量序列但输出可能不是的任务也感兴趣。 主要目标是在有意义的数据集上使用 LSTM 和 GRU 变体（例如 minGRU），可能会做微小的莎士比亚，但它并没有让我感到温暖…… 2) 您是否认为存在顺序任务和设置，其中 RNN 不仅是根据我们的直觉更自然的选择，而且实际上与 Transformers 或 1D CNN 等相比，它是唯一在理论上或实验上可用的选择？    提交人    /u/Sad-Razzmatazz-5188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h38ym2/d_modern_usecases_for_rnns/</guid>
      <pubDate>Sat, 30 Nov 2024 09:22:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最快的物体检测模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h362dq/d_whats_the_fastest_object_detection_model/</link>
      <description><![CDATA[嗨，我正在做一个需要物体检测的项目。由于物体非常清晰，任务本身并不复杂，但速度至关重要。我研究过各种物体检测模型，似乎几乎每个人都声称自己是“最快的”。由于我将用 C++ 部署模型，所以没有时间移植和评估它们。 我之前测试过 YOLOv5/v5Lite/8/10，YOLOv5n 是最快的。我在 Oracle ARM 服务器上运行了一个简单的基准测试（详情见此处），它仅用 54ms 就处理了一张目标大小为 640 的图像。不幸的是，我当前项目的硬件性能明显较差，同时处理时间必须少于 20ms。我将使用量化和动态维度之类的方法来提高速度，但我必须先选择合适的模型。 有人遇到过类似的情况或专门针对速度测试过模型吗？有没有比 YOLOv5n 更快且值得一试的模型建议？    提交人    /u/Knok0932   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h362dq/d_whats_the_fastest_object_detection_model/</guid>
      <pubDate>Sat, 30 Nov 2024 06:00:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分子动力学与机器学习构建</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2x4ar/d_molecular_dynamics_and_machine_learning_build/</link>
      <description><![CDATA[大家好，我做了很多分子动力学研究，并开始利用该领域和基因组/多组学等东西进入机器学习领域。我正在构建一个工作站，根据我的预算，我正在寻找 2x A6000 或 2x 5000 Ada。两者都非常适合分子动力学，但我正在尝试找出机器学习的最佳选择。A6000 有 48gb vram 和 nvlink，但 5000 Ada 更新，速度快得多，每张卡 32Gb VRAM 也不错。有什么建议吗？    提交人    /u/Mdgoff7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2x4ar/d_molecular_dynamics_and_machine_learning_build/</guid>
      <pubDate>Fri, 29 Nov 2024 22:04:19 GMT</pubDate>
    </item>
    <item>
      <title>[N][R] 模型就是食物：法学硕士的自动数据管理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2qmol/nr_models_are_what_they_eat_automatic_data/</link>
      <description><![CDATA[在 DatologyAI 上分享我们的最新成果。模型就是它们的食物，我们的使命是让训练大型模型的数据管理尽可能有效和简单。 通过结合多种方法，包括启发式过滤器、基于模型的过滤器、基于嵌入的管理、合成数据、目标分布匹配和混合比率，我们能够大幅提高训练效率、性能和推理效率。  与我们的基线和起始数据集（精确去重的 RedPajamav1）相比，我们可以：  以 7.7 倍的速度达到相同的性能（比 DCLM 快 3.4 倍） 在基准测试中将性能提高 8.5%（比 DCLM 提高 4.4%） 使用不到一半的参数训练模型，其性能比大型模型高出 5% 以上  请在此处查看我们的高级结果，如果您需要所有细节，请查看我们的 技术深度探究。    提交人    /u/arimorcos   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2qmol/nr_models_are_what_they_eat_automatic_data/</guid>
      <pubDate>Fri, 29 Nov 2024 17:15:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] Hinton 和 Hassabis 论乔姆斯基的语言理论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2mkye/d_hinton_and_hassabis_on_chomskys_theory_of/</link>
      <description><![CDATA[我刚进入这个领域，很想听听更多这方面的观点。我一直认为乔姆斯基是这方面的重要人物，但似乎 Hinton 和 Hassabis（后来）都不同意。这里：https://www.youtube.com/watch?v=urBFz6-gHGY（较长版本：https://youtu.be/Gg-w_n9NJIE） 我很想从 ML 和 CogSci 的角度来看待这个问题，以及支持/拒绝这种观点的更多来源。 编辑：拼写错误 + 添加来源。    提交人    /u/giuuilfobfyvihksmk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2mkye/d_hinton_and_hassabis_on_chomskys_theory_of/</guid>
      <pubDate>Fri, 29 Nov 2024 14:10:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果 VQ-VAE 能够解开的话，它该如何解开呢？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2epzx/d_how_does_vqvae_disentangle_if_it_does_at_all/</link>
      <description><![CDATA[我目前使用 BetaTC-VAE，它在解缠方面做得非常出色，我知道 VAE 可以稍微解缠，因为对于模型来说，如果变量解缠，更容易获得较低的 KL 损失，beta 项使这个 beta 倍更重要，总相关性和互信息损失推动完全解缠，但在 VQ-VAE 中没有（主要）解缠，只有码本和离散输出。码本给出的离散潜在空间可以解缠吗？如果不能，有没有关于解缠 VQ-VAE 的论文？我有一个环境，其中解缠的潜在空间比连续潜在空间提供更好的重建     提交人    /u/ZazaGaza213   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2epzx/d_how_does_vqvae_disentangle_if_it_does_at_all/</guid>
      <pubDate>Fri, 29 Nov 2024 05:33:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 24 Nov 2024 03:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>