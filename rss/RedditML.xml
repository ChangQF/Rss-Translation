<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 01 Jan 2024 15:13:05 GMT</lastBuildDate>
    <item>
      <title>[D] 赚取被动收入的数据科学家，你是做什么的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vxts1/d_data_scientists_who_made_a_passive_income_what/</link>
      <description><![CDATA[除了朝九晚五的常规工作之外，已成功建立被动收入来源的数据科学家和机器学习人员：您是如何做的以及做了什么？我真的很好奇我们领域的专业人士利用他们的技能来产生额外收入的不同方式。 无论是简单的机器学习应用程序、微服务、独特的服务产品、自由项目还是任何其他项目方法，我很想听听你的故事。你是怎么想到这个主意的？您如何平衡这与您的全职工作？您面临着什么样的挑战？   由   提交 /u/Fendrbud   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vxts1/d_data_scientists_who_made_a_passive_income_what/</guid>
      <pubDate>Mon, 01 Jan 2024 14:29:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 pytorch 训练时调试 Killed: 9 POSIX 信号的提示？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vx5rp/d_tips_on_debugging_the_killed_9_posix_signal/</link>
      <description><![CDATA[我得到了 被杀死：9  当使用 pytorch 进行训练时macOS（9 是 POSIX SIGKILL）。我知道这通常是由内存泄漏引起的，但就我而言，我没有观察到任何过度的内存使用。有谁知道这个错误是否还有其他原因？   由   提交 /u/speedy-spade   /u/speedy-spade  reddit.com/r/MachineLearning/comments/18vx5rp/d_tips_on_debugging_the_killed_9_p​​osix_signal/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vx5rp/d_tips_on_debugging_the_killed_9_posix_signal/</guid>
      <pubDate>Mon, 01 Jan 2024 13:52:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们没有更有趣的激活函数？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vwpk2/d_why_dont_we_have_more_interesting_activation/</link>
      <description><![CDATA[没有太多证据表明生物神经网络具有不寻常的激活函数（例如 mod n），但有如此多的连接，其连接方式可能不同我们做激活函数和注意力，谁能知道？我不认为极强的负抑制权重可以起到这个作用；拥有一个全有或全无的 mod 函数是不同的，它可能无法在负权重梯度上学习。当我在 2015 年被人工神经网络捕获时，原因是像随机神经元被移除（像人类一样！）这样的属性，这种技术本质上（修剪）类似于混沌工程的非智能随机形式。那么是否有可能，就像我们拥有使神经网络中的计算更加有效的技术一样，我们可以应用更多作为数学捷径的技术？一切都必须有梯度吗？ 这个帖子让我思考：是否有很多研究尝试将不寻常的激活函数与合理大小或基于激活的网络结合起来？对此有任何直觉吗？   由   提交/u/Lumpy-Ad2724  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vwpk2/d_why_dont_we_have_more_interesting_activation/</guid>
      <pubDate>Mon, 01 Jan 2024 13:25:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我如何创建一个可以帮助 A Level 数学的人工智能？或者其他科目，例如语言</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vwgwo/d_how_can_i_create_an_ai_that_can_help_a_levels/</link>
      <description><![CDATA[大家好，我是一名正在攻读计算机科学的大学生，我对人工智能领域很感兴趣。在我的国家，一级数学相当难，老师们真的希望你在没有基本理解的情况下死记硬背数学，所以当我们在大学看到同样的数学时，很多人感觉我们是从零开始的。我有一个想法，创建某种人工智能，可以帮助在我的国家（Zim）做数学的 A-level 能够进行深入的数学。我的想法是教人工智能数学并创建一个网站，使用人工智能来教授和测试用户选择的主题。对于语言来说也是如此，比如人工智能应该能够从结构到寄存器、语法、习语等理解语言。如果我选​​择使用 Pytorch 或张量流，我应该采取什么方法来使这个想法成为现实？    由   提交/u/Arch_Gang  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vwgwo/d_how_can_i_create_an_ai_that_can_help_a_levels/</guid>
      <pubDate>Mon, 01 Jan 2024 13:10:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] IJCAI 与 ICML 审稿人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vw505/r_ijcai_vs_icml_reviewers/</link>
      <description><![CDATA[嘿，目前正在写联邦学习论文。我想到了两个地点：IJCAI（1 月 17 日）和 ICML（2 月 1 日）。我认为两者的适合程度大致相同。哪个场所能让我更有机会获得合理/公正的评论？如果是 IJCAI，是否值得在 ICML 之前多花两周时间来完善内容？   由   提交/u/ClueDramatic1290   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vw505/r_ijcai_vs_icml_reviewers/</guid>
      <pubDate>Mon, 01 Jan 2024 12:50:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大型“动作”模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vuzl0/d_large_action_models/</link>
      <description><![CDATA[嗨。我正在研究动态环境中自主代理的指令解释和复杂规划，我发现了几篇有趣的论文，例如 FILM 和类似的架构代理。 但是，似乎许多现代解决方案都依赖于语言处理来分解高级任务，例如“清洁盘子并将其收起来”等。进入“拿起盘子，将盘子放入水槽，使用水槽，拿起盘子，放入储藏室”。特别是在链接论文中，他们使用 BERT 模型来实现这一点。虽然这似乎表现良好，但我不禁想知道是否有比使用语言更有效的计划方法。 使用它来解释口头指令的任务是有意义的，但是至于实际的计划以及行动与结果的联系，我无法确定语言是否是一种理想的媒介。我想，一个能够以某种形式将事件与其他事件（在某些上下文中和某些参数，例如电影论文中的“对象”和“接收者”参数）关联起来的代理，而不必将其与语言联系起来可能会执行更好的。我还发现实验涉及将强化学习与常规旧HIP算法相结合，但尽管这些最终表现比普通算法更好强化学习（毫不奇怪），它们落后于上述基于语言的规划器。 有没有人研究过教导智能体探索和建立动作之间联系的方法，使它们能够在动态环境中表现良好，而无需与 HIP 一样手动指定所有内容，同时能够构建长期、复杂的行动计划，这是大多数 RL 实现遇到的困难？    由   提交/u/NightestOfTheOwls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vuzl0/d_large_action_models/</guid>
      <pubDate>Mon, 01 Jan 2024 11:31:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 潜在扩散新视角的快速工程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vuu9n/d_prompt_engineering_for_novel_perspectives_in/</link>
      <description><![CDATA[我正在使用潜在扩散来生成特定的视角。我一直在阅读这篇论文，其中他们不仅使用 LoRA 进行微调，而且在前面添加了“Birdeye view of . ..”到提示符。以这种方式进行即时工程是否可行，或者是否会导致模型失去一定程度的稳健性？我的想法之一是，LoRA 肯定可以学习对提示符的理想修改，而不是程序直接插入它？   由   提交 /u/NoLifeGamer2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vuu9n/d_prompt_engineering_for_novel_perspectives_in/</guid>
      <pubDate>Mon, 01 Jan 2024 11:21:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] StrategyQA 包含的错误可能比我们之前想象的要多得多</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vtvqt/d_strategyqa_may_contain_far_more_errors_than_we/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vtvqt/d_strategyqa_may_contain_far_more_errors_than_we/</guid>
      <pubDate>Mon, 01 Jan 2024 10:12:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士会完全取代外语翻译服务吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18voi9s/d_will_llms_completely_replace_foreign_language/</link>
      <description><![CDATA[传统上，外语翻译服务似乎依赖于语法和意义的绝对解构和重建，但像 OpenAI 这样的法学硕士似乎能够处理这没有任何复杂性。 这是否意味着法学硕士非常适合这种替代，因此传统的语言翻译技术不再适用？   由   提交 /u/lorenzomofo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18voi9s/d_will_llms_completely_replace_foreign_language/</guid>
      <pubDate>Mon, 01 Jan 2024 04:00:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] TinyGPT-V：通过小骨干的高效多模态大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vngf4/r_tinygptv_efficient_multimodal_large_language/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2312.16862 代码：https://arxiv.org/abs/2312.16862 代码： com/DLYuanGod/TinyGPT-V&quot;&gt;https://github.com/DLYuanGod/TinyGPT-V 模型：https://huggingface.co/Tyrannosaurus/TinyGPT-V 摘要： &lt; blockquote&gt; 在高级多模型学习时代，GPT-4V 等多模态大语言模型 (MLLM) 在连接语言和视觉元素方面取得了显着的进步。然而，闭源性质和大量的计算需求给普遍使用和修改带来了显着的挑战。这就是 LLaVA 和 MiniGPT-4 等开源 MLLM 的用武之地，它们在各个任务上取得了突破性的成就。尽管取得了这些成就，计算效率仍然是一个未解决的问题，因为这些模型（如 LLaVA-v1.5-13B）需要大量资源。为了解决这些问题，我们推出了 TinyGPT-V，这是一种将令人印象深刻的性能与普通计算能力相结合的新浪潮模型。它的突出之处在于仅需要 24G GPU 进行训练，8G GPU 或 CPU 进行推理。 TinyGPT-V 基于 Phi-2 构建，将有效的语言主干与来自 BLIP-2 或 CLIP 的预训练视觉模块结合起来。 TinyGPT-V的2.8B参数可以经过独特的量化过程，适合8G各种设备上的本地部署和推理任务。我们的工作促进了设计具有成本效益、高效且高性能的 MLLM 的进一步发展，扩展了它们在广泛的现实场景中的适用性。此外，本文提出了一种通过小主干的多模态大语言模型的新范式。我们的代码和训练权重位于：此 https URL 和 分别是这个 https URL。  ​ https://preview.redd.it/p66bxrlxsq9c1.png?width=1732&amp;format=png&amp;auto=网页&amp; s=b75366ca000d259869fc7487a4322427fa31110c   由   提交 /u/APaperADay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vngf4/r_tinygptv_efficient_multimodal_large_language/</guid>
      <pubDate>Mon, 01 Jan 2024 02:52:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 数学生成人工智能：第一部分——MathPile：十亿代币规模的数学预训练语料库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vmu5z/r_generative_ai_for_math_part_i_mathpile_a/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.17120 数据集：https:// /huggingface.co/datasets/GAIR/MathPile 代码：https://github.com/GAIR-NLP/MathPile/ 项目页面：https://gair-nlp.github.io/MathPile/ 摘要：  高质量、大规模的语料库是构建基础模型的基石。在这项工作中，我们引入了 MathPile，这是一个多样化且高质量的以数学为中心的语料库，包含约 95 亿个代币。在整个创建过程中，我们坚持“少即是多”的原则，坚信数据质量高于数量，即使在预训练阶段也是如此。我们细致的数据收集和处理工作包括一套复杂的预处理、预过滤、语言识别、清理、过滤和重复数据删除，确保了我们语料库的高质量。此外，我们对下游基准测试集进行了数据污染检测，以消除重复。我们希望我们的MathPile能够帮助增强语言模型的数学推理能力。我们计划将不同版本的MathPile以及用于处理的脚本开源，以方便该领域未来的发展。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vmu5z/r_generative_ai_for_math_part_i_mathpile_a/</guid>
      <pubDate>Mon, 01 Jan 2024 02:14:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将 nanoGPT 移植到 Apple 新的 MLX 框架：Macbook M3 Pro GPU 上的早期结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vhvl1/p_ported_nanogpt_to_apples_new_mlx_framework/</link>
      <description><![CDATA[嘿，机器学习爱好者们， 我一直在致力于一个令人兴奋的项目，希望与你们分享我的进展。我成功地将 Andrej Karpathy 的 nanoGPT 框架移植到 Apple 的新机器学习框架 MLX 中。这为在 Mac GPU 上运行 GPT 模型提供了一些有趣的可能性。代码：https://github.com/vithursant/nanoGPT_mlx  详细信息：  硬件： Macbook M3 Pro，配备 11 核 CPU，14-核心GPU，18GB统一内存 性能：在莎士比亚数据集上以0.37次迭代/秒的速度预训练45M参数字符级GPT-2模型。 &lt; li&gt;配置：  批量大小：64 本地批量大小：4 序列长度：256 &gt;   当前状态：  支持莎士比亚和 OpenWebText 的预训练 代码库仍在开发中。 寻找反馈、建议和潜在合作者。  向社区提出的问题：&lt; /p&gt;  是否有其他人尝试使用 MLX 并经历过类似或不同的结果？ 对于优化 Mac GPU 性能有什么建议吗？ 对潜在应用的思考或改进？  我很高兴听到您的想法，并可能与有兴趣探索 Apple MLX 功能的其他人合作。请随意查看代码并分享您的见解！   由   提交/u/brownmamba94  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vhvl1/p_ported_nanogpt_to_apples_new_mlx_framework/</guid>
      <pubDate>Sun, 31 Dec 2023 21:43:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大家的新年学习决心是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vgr2l/d_what_are_everyones_new_year_learning_resolutions/</link>
      <description><![CDATA[你们计划在 2024 年学习什么？ 对我来说，这是因果机器学习，并更深入地研究 RAG！   由   提交/u/Moist_Onion_6440   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vgr2l/d_what_are_everyones_new_year_learning_resolutions/</guid>
      <pubDate>Sun, 31 Dec 2023 20:47:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么目前的法学硕士在离散空间中效果很好，但在连续空间中效果不佳？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vfj7k/d_why_do_current_llms_work_well_in_discrete_space/</link>
      <description><![CDATA[一个有趣的观察是，LM 被训练来预测分类分布上的标记，然后使用采样算法来离散化分布以产生输出。如果我们在连续域中尝试此操作，例如，直接使用 L2 损失来预测像素，则它不起作用，输出会变得非常模糊。看来，通过采样进行离散化对于推理过程中的工作至关重要。最近的论文，如 GIVT 可以将输出建模为高斯混合而不是分类分布，但仍然需要采样才能使其发挥作用。  我确信这不是新的观察结果，有没有任何资源可以帮助解释为什么会出现这种情况？   由   提交 /u/Hyperarticles   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vfj7k/d_why_do_current_llms_work_well_in_discrete_space/</guid>
      <pubDate>Sun, 31 Dec 2023 19:48:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>