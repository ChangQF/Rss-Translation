<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 12 Mar 2024 21:12:43 GMT</lastBuildDate>
    <item>
      <title>[D] 克隆 git repo Huggingface 中耳语 AI 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bd89of/d_cloning_git_repo_huggingface_medium_model_of/</link>
      <description><![CDATA[我对这一切不是很有经验，但我目前正在尝试从这里克隆 git 存储库：  https://huggingface.co/openai/whisper-medium 我的 git bash 窗口给了我以下内容，但现在只是挂起，没有进度指示器 $ git clone https://huggingface.co/openai/whisper-medium 克隆到“whisper-medium”... 远程：枚举对象：175，完成。 远程：计数对象：100% (6/6)，完成。 p&gt; 远程：压缩对象：100% (6/6)，完成。 远程：总共 175 个（增量 1），重用 0 个（增量0)，包重用 169 s：99% (174/175)，2.75 MiB | 354.00 KiB/s 接收对象：100% (175/175)，2.88 MiB | 297.00 KiB/s，完成。 解析增量：100% (102/102)，完成。 创建的文件夹保留大小为 4.37MB，但我的网络流量告诉我到目前为止我已经下载了 5GB... 它去哪儿了？什么时候能完成？？？我以为中等型号的大小约为 3GB... 完全困惑！   由   提交 /u/AudioBabble   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bd89of/d_cloning_git_repo_huggingface_medium_model_of/</guid>
      <pubDate>Tue, 12 Mar 2024 20:53:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 优化 (2+1)D ResNet 以进行事件索引</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bd7ejh/d_optimising_a_21d_resnet_for_event_indexing/</link>
      <description><![CDATA[我正在开发一个 (2+1)D resnet，用于视频数据的对象检测、事件分类和事件索引。目前，我在第一次迭代中拥有的唯一功能是每帧的像素值。我还收集了其他特征，例如纹理、光流、运动向量、颜色直方图和每帧的边缘。 我的主要问题是如何将所有特征融合为模型的输入，但我也有兴趣听听是否有人对此有任何意见，或者我如何改进我的模型。 模型架构基于以下论文： &lt; a href=&quot;https://arxiv.org/pdf/1711.11248v3.pdf&quot;&gt;https://arxiv.org/pdf/1711.11248v3.pdf   由   提交/u/RxPiku  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bd7ejh/d_optimising_a_21d_resnet_for_event_indexing/</guid>
      <pubDate>Tue, 12 Mar 2024 20:19:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习面试倦怠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bd5hh4/d_ml_interview_burnout/</link>
      <description><![CDATA[我觉得我因数据科学面试而精疲力尽。我在该领域担任数据科学家已有 5 年了。这个领域有很多技术性的东西。尤其是在2023年，关于如何优化LLM模型和向量DB的使用的新论文层出不穷。我花在面试准备上的时间越多，我用来获取新知识的时间就越少。我应该怎么做才能克服这种情况？非常感谢。 为什么我觉得面试准备没有什么用 在实际工作中，我们可以针对一个话题进行不同的准备来回忆所有的内容。在向其他同事展示想法之前，先记忆并正确组织概念。然而，是否可以在采访过程中立即调取所有信息呢？有些知识可以追溯到学校课本上，几十年来一直没有人接触过。有些问题涉及不太常见的设计模式。当我无法回答一个问题时，我会感到难过，不是因为我不知道，而是因为我确实无法在短时间内总结出来。这就像数据被存档到AWS S3冰川一样，因此数据检索既耗时又昂贵。另外，不能回答一些代码设计模式并不意味着我不能写出好的代码并解决问题。为了准备这些面试，我尝试重新审视一些关键概念和各种不太有用的代码模式，但这非常耗时。老实说，这些工作的工资确实很高。我不是在谈论任何大型科技公司，而是在谈论一些中小企业。我对标准感到困惑。   由   提交 /u/MillionLiar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bd5hh4/d_ml_interview_burnout/</guid>
      <pubDate>Tue, 12 Mar 2024 19:03:09 GMT</pubDate>
    </item>
    <item>
      <title>[P]姿势估计的最佳模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcuwjo/pbest_model_for_pose_estimation/</link>
      <description><![CDATA[嗨！我正在尝试使用 flutter 在 Android 中制作一个虚拟锻炼助手应用程序......我很精通 flutter，但你可以猜到我在实现模型方面没有太多经验......所以你可以建议一个更准确且不难实现的姿势估计模型    ;由   提交/u/DeepLet4383  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcuwjo/pbest_model_for_pose_estimation/</guid>
      <pubDate>Tue, 12 Mar 2024 11:25:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有针对应用研究的非技术同行评审期刊？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcqoa7/d_are_there_non_technical_peer_reviewed_journals/</link>
      <description><![CDATA[我今天正在看这篇论文 https://arxiv.org/abs/2403.04769 我缺乏发表纯理论机器学习论文的知识（也没有时间和精力真正深入该领域并赶上产生有意义的输出的水平）但我认为我有一些想法，并且有兴趣以发现漏洞的形式进行研究，或者以新颖的方式比较法学硕士或模型等。需要丰富的理论背景，并且具有不同技能的人更容易涉足其中。  与此同时，尽管我是一个完全不同领域的学者，但为了我的职业生涯，我需要在期刊上发表论文，而不仅仅是在 arxiv 上。所以我的问题是，像我上传的论文在实践中当然非常有用，但从科学角度讲，它们是否会在同行评审期刊上发表？如果是，在哪里？ 有兴趣听听您的想法和建议，提前致谢！   由   提交 /u/Dyoakom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcqoa7/d_are_there_non_technical_peer_reviewed_journals/</guid>
      <pubDate>Tue, 12 Mar 2024 06:41:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人可以澄清一下像 Perplexity、You.com 或 Coral Search 这样的网络搜索法学硕士是否正在自己抓取整个网络吗？否则，它们与简单地将搜索 API 与任何 LLM 模型结合起来有何不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcq8zy/d_can_someone_please_clarify_if_web_search_llms/</link>
      <description><![CDATA[如果他们自己爬行网​​络，有经验的人能否解释一下这项任务有多困难以及这些公司如何彼此区分，我看不到他们每个人提供的答案有多大差异？   由   提交/u/Fit-Set6851  /u/Fit-Set6851 reddit.com/r/MachineLearning/comments/1bcq8zy/d_can_someone_please_clarify_if_web_search_llms/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcq8zy/d_can_someone_please_clarify_if_web_search_llms/</guid>
      <pubDate>Tue, 12 Mar 2024 06:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]扩散模型有表示学习吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcmvo1/discussion_do_diffusion_models_do_any/</link>
      <description><![CDATA[诸如 VAE 和基于转换器的语言模型（MLM 或自回归）之类的模型提取数据的高阶表示。对于DM是否这样做有任何了解吗？我见过的论文中似乎没有讨论这个问题，大概是因为重点太集中在生成方面。   由   提交/u/daking999  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcmvo1/discussion_do_diffusion_models_do_any/</guid>
      <pubDate>Tue, 12 Mar 2024 03:08:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 作为可优化图的语言代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bchke2/r_language_agents_as_optimizable_graphs/</link>
      <description><![CDATA[ 由   提交/u/hardmaru  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bchke2/r_language_agents_as_optimizable_graphs/</guid>
      <pubDate>Mon, 11 Mar 2024 23:10:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 🔥InstaSwap 换脸 for ComfyUI 和 Standalone</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcgabf/p_instaswap_face_swap_for_comfyui_and_standalone/</link>
      <description><![CDATA[   ComfyUI 存储库：https://github.com/abdozmantar/ComfyUI-InstaSwap Standalon 仓库：https://github.com/abdozmantar/Standalone-InstaSwap ​ https://i.redd.it/idb3ugi95snc1.gif   由   提交 /u/abdullahozmntr   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcgabf/p_instaswap_face_swap_for_comfyui_and_standalone/</guid>
      <pubDate>Mon, 11 Mar 2024 22:20:21 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]LSTM模型可以自己学习特征工程吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcc2oo/discussion_can_lstm_model_learn_feature/</link>
      <description><![CDATA[我有一个时间序列数据集，我正在其上训练 LSTM 模型以执行多类分类。 我的数据集有 7 列=&gt; x1,x2,x3....x7 并且有 4 个标签 =&gt; f1,f2,f3,f4 由于我对数据集具有领域知识，因此我确切地知道需要完成哪些特征工程。 ​ &lt; p&gt;例如，我需要通过在每一行应用一些规则来从当前功能创建 4 个新功能：-  newx1 由 =&gt; 创建if (x2==x3) then 1, else 0 newx2 由 =&gt; 创建if (x1==x4 and x1&gt;x5) then 1, else 0 newx3 由 =&gt; 创建if ((x1-x6)/x1&gt;x7) then 1, else 0 newx4 由 =&gt; 创建if ((x6-x1)x1/&gt;x7) then 1. else 0  ​ 我在测试数据上获得 100% 的准确度，如果我在 newx1、newx2、newx3、newx4 上训练我的 LSTM 模型。 但是，在原始特征 (x1,x2....x7) 上训练它时，我的准确度降低了 85-90%  我要解决的问题要求我的准确率高于 99%，因此仅 90% 的准确率是不够的。 &amp;# x200b; 我想知道我的 LSTM 模型是否可以自行学习特征工程的规则，或者我是否必须更改我的模型？ ​ 注意：我无法手动应用特征工程规则，因为我正在多个数据集上训练 LSTM 模型，并且每个数据集都需要自己的特征工程规则。我想让它尽可能通用。 ​ LSTM 模型 :- def create_lstm_model(MaxTimeslice, H, LR , num_classes, dropout_rate=0.1, l2_reg=0.001): ip = 输入(shape=(MaxTimeslice, H)) x = LSTM(32, return_sequences=True, dropout=dropout_rate, kernel_regularizer=l2(l2_reg))(ip) x = LSTM(16，dropout=dropout_rate，kernel_regularizer=l2(l2_reg))(x) x = Dense(units=16，activation=&#39;relu&#39;)(x) multiclass_output = Dense(units=num_classes，activation=&#39;softmax&#39;)( x) model = Model(inputs=ip,outputs=multiclass_output) model.compile(loss=&quot;categorical_crossentropy&quot;,metrics=[&quot;accuracy&quot;],optimizer=RMSprop(learning_rate=LR)) 返回模型 &lt; /pre&gt; ​   由   提交 /u/Fearless_Peanut_6092   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcc2oo/discussion_can_lstm_model_learn_feature/</guid>
      <pubDate>Mon, 11 Mar 2024 19:37:27 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 这是数据泄露的例子吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bca8h7/discussion_is_this_an_example_of_data_leakage/</link>
      <description><![CDATA[我正在开展一个研究项目，使用机器学习来尝试发现基因启动子的模式。我担心我们模型中的数据泄漏，但在我大力推动我的实验室改变我们的方法之前，我需要一些外部意见。也许这个社区中的某人可以帮助我更好地理解这个问题。 我们的机器学习模型是 L1 正则化逻辑回归模型，它使用序列模式作为特征来预测转录起始位点（TSS）的二进制结果）在基因组中。序列模式由上游工具在 TSS 旁边约 1000 个核苷酸的区域中检测到。由于许多 TSS 在基因组中紧密聚集（某些基因具有多个 TSS），因此这些序列区域通常与至少一个其他 TSS 序列区域重叠 &gt; 99%。我担心的是，如果我们对单个 TSS 进行训练/测试分割，我们将会出现数据泄漏，因为训练集中的许多示例将具有与测试集中的至少一个特征向量相关且高度相关的特征向量。我们对序列区域进行分箱只能在一定程度上缓解这种情况，因为偏移 5 nt 或更少的两个 100 核苷酸 (nt) 箱（在我们的数据集中并不罕见）将共享 ≥95% 的序列同一性。 以下几点让我认为我们存在数据泄漏：  我们的特征比示例更多，使得过度拟合变得更容易。在将训练集性能与测试集性能进行比较时，观察到了一点过度拟合。 两个 TSS 的居中、缩放特征的组内平均（在最大 5nt 间隔的连续簇中）皮尔逊相关系数为〜0.99。这不包括自我比较。组之间的平均相关性为 ~-0.0002。大约 35% 的 TSS 位于具有此距离阈值的某个集群中。 当 TSS 按最大 5nt 间隔的邻近度进行聚类时，如果测试集中的 TSS 与测试集中的任何 TSS 分组，则测试集中的 TSS 将被删除。训练集上，通过评估“清理过的”测试集，我们的 auROC 下降了约 3%。这可以用不同的随机种子来重现。如果我们使用 20nt 的阈值，性能会下降约 5%。 当我用随机 DNA 序列而不是基因组来生成特征时，但使用相同的 TSS 位置和整体方法（意味着序列重叠）仍然发生），模型达到了 70% 的 auROC。相比之下，如果我将最大距离为 20 nt 的 TSS 分组，并在进行训练/测试拆分之前删除每组中除一个 TSS 之外的所有 TSS，则我在随机基因组上获得约 53% 的 auROC，更接近于随机分类器。&lt; /li&gt;  我删除太接近的 TSS 的方案无疑是有缺陷的，因为我们失去了宝贵的例子。我认为保留所有 TSS 并按组拆分会更好，同时还能防止数据泄漏。据我了解，这相当于整群抽样，并且类似于患者层面的分裂，因为医学研究人员正在学习如何处理 MRI 切片等数据。在这种情况下，该方案是否无效/有害，或者它是否是防止数据泄漏的正确选择？或者我们应该使用另一种分割方案？   由   提交/u/analyze_hunter  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bca8h7/discussion_is_this_an_example_of_data_leakage/</guid>
      <pubDate>Mon, 11 Mar 2024 18:24:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] Gemini 1.5 Pro如何回忆10M上下文中的信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</link>
      <description><![CDATA[Google 最近发布了技术报告 关于 Gemini 1.5 Pro 及其 10M 上下文。他们简要概述了提高模型长上下文能力的现代方法（例如循环记忆、环形注意力、新颖的架构等），但我没有找到有关 Gemini 1.5 Pro 方法的信息。 有人注意到官方出版物中有关他们方法的信息吗？这对我来说似乎是 Google 的秘密。   由   提交/u/Mulated-Witness-7196   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</guid>
      <pubDate>Mon, 11 Mar 2024 12:26:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] [2403.05468] GPT-4 会运行《DOOM》吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</link>
      <description><![CDATA[ 由   提交/u/blabboy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</guid>
      <pubDate>Mon, 11 Mar 2024 12:20:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] ShortGPT：大型语言模型中的层比您预期的更加冗余</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.03853 摘要：  随着大型语言模型（LLM）的性能不断进步，它们的规模显着扩大，当前的法学硕士包含数十亿甚至数万亿的参数。然而，在这项研究中，我们发现LLM的许多层表现出高度相似性，并且某些层在网络功能中发挥的作用可以忽略不计。基于这一观察，我们定义了一个名为区块影响力 (BI) 的指标来衡量法学硕士中每一层的重要性。然后，我们提出了一种直接的修剪方法：层删除，其中我们根据 LLM 的 BI 分数直接删除其中的冗余层。实验表明，我们的方法（我们称之为 ShortGPT）在模型剪枝方面显着优于之前最先进的 (SOTA) 方法。此外，ShortGPT 与类量化方法正交，可以进一步减少参数和计算量。与更复杂的修剪技术相比，通过简单的层删除可以获得更好的结果，这表明模型架构中存在高度冗余。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</guid>
      <pubDate>Mon, 11 Mar 2024 11:41:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>