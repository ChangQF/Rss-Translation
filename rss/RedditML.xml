<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 03 Jan 2024 12:25:14 GMT</lastBuildDate>
    <item>
      <title>[P] LiDAR 和分割</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xi6if/p_lidar_and_segmentation/</link>
      <description><![CDATA[大家早上好。有人使用过 LiDAR 并且有经验可以帮助我吗？我需要使用激光雷达提取的点云来计算物品的体积。然而，图像中将会有多个对象。我如何选择我感兴趣的对象？我应该用某种模型分割原始图像中的对象，然后在点云中定位该对象，还是应该只使用带有点云的图像？   由   提交 /u/gr_ferro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xi6if/p_lidar_and_segmentation/</guid>
      <pubDate>Wed, 03 Jan 2024 12:23:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用神经网络进行基于笔迹的人员识别。您认为可以采用什么方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xi23h/d_person_identification_based_on_handwriting/</link>
      <description><![CDATA[我们正在尝试开发一个网络模型，该模型将图像作为输入，并将人名作为输出。我们计划使用 CNN。开发这个模型的最佳方法是什么？硬件要求是什么？   由   提交 /u/AntTraining5141   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xi23h/d_person_identification_based_on_handwriting/</guid>
      <pubDate>Wed, 03 Jan 2024 12:16:06 GMT</pubDate>
    </item>
    <item>
      <title>【项目】Fedstellar：去中心化联邦学习平台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xhppb/project_fedstellar_a_platform_for_decentralized/</link>
      <description><![CDATA[     &lt; td&gt; 开源平台：  fedstellar.dev / fedstellar.eu / fedstellar.com / federatedlearning.inf.um.es  代码： https://github.com/enriquetomasmb/fedstellar &lt; p&gt;文档： https://fedstellar.enriquetomasmb.com 描述：  Fedstellar 是一个创新平台，有助于在许多物理和虚拟设备上以分散的方式训练联邦学习模型。此外，该平台还可以创建用于开发、部署和管理联合应用程序的标准方法。  该平台支持建立由不同设备、网络拓扑和算法组成的联盟。它还提供复杂的联合管理工具和性能指标，以促进高效的学习过程监控。这是通过可扩展模块实现的，这些模块提供数据存储和异步功能，以及用于模型训练、通信和联合监控综合分析的有效机制。  该平台采用了由三个元素组成的模块化架构： 前端：用于实验设置和监控的用户友好的前端。  控制器：用于有效编排操作的控制器。  核心：部署在每个设备中的核心组件，用于模型训练和通信。  Fedstellar 由 Enrique Tomás Martínez Beltrán 与 穆尔西亚大学、Armasuisse 和苏黎世大学（UZH）。  ​ Fedstellar 平台整体架构。 ​ &lt; p&gt;Fedstellar 中通信过程的示意图。 相关研究论文：  Fedstellar：去中心化联邦学习平台 | https://doi.org/10.1016/j.eswa.2023.122861 (专家系统应用）  去中心化联合学习：基础知识、最新技术、框架、趋势和挑战 | https://doi.org/10.1109/COMST.2023.3315746 （IEEE 通信调查和报告）教程）  关于我：  Enrique Tomás Martínez Beltrán （计算机科学博士生） - https://enriquetomasmb.com/ - [enriquetomas@um.es](mailto:enriquetomas@um.es)  如果您对进一步改进平台有任何疑问或建议，请告诉我。任何潜在的贡献或合作都会受到热烈欢迎😉   由   提交 /u/enriquetomasmb   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xhppb/project_fedstellar_a_platform_for_decentralized/</guid>
      <pubDate>Wed, 03 Jan 2024 11:56:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在自己的数据集上训练自己的音乐模型的最佳应用程序是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xhmnt/d_whats_the_best_app_for_training_your_own_music/</link>
      <description><![CDATA[我记得 Jukebox，它可以在您自己的音乐曲目上进行微调，但只接受一个曲目作为输入。是否有任何其他应用程序可以用来训练我自己的模型，并且可以用无限量的输入材料填充它们？    由   提交 /u/varovec   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xhmnt/d_whats_the_best_app_for_training_your_own_music/</guid>
      <pubDate>Wed, 03 Jan 2024 11:51:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于多模态数据融合的Python包：Fusilli</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xfzqc/p_python_package_for_multimodal_data_fusion/</link>
      <description><![CDATA[大家好！我想分享一个我在攻读博士学位期间编写的 Python 库，名为 fusilli：文档 &amp; GitHub Fusilli 提供了一组 23 种基于深度学习的多模态数据融合方法。它还包括用于在回归/分类任务中比较这些方法的管道。它可以处理表格-表格融合或表格-图像融合（2D 或 3D 图像）。 多模态数据融合，简单来说，就是使用机器学习组合不同类型的数据（例如图像和表格）利用这些数据类型之间的共享信息的模型。想想 GNN、注意力机制或 VAE。有时也称为多视图或数据集成。 就我个人而言，我将其用于分析大脑 MRI 和临床数据以预测健康结果的博士研究。但 Fusilli 可以在任何有多模式数据的地方使用！ Fusilli 是我公开发布的最大的编码项目，所以我很乐意听到您可能有的任何反馈或建议！ ?? （这里还有一个简短的 Medium帖子我写了关于它的文章，展示了一些功能）   由   提交 /u/seemepastarolling   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xfzqc/p_python_package_for_multimodal_data_fusion/</guid>
      <pubDate>Wed, 03 Jan 2024 10:08:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 向编码器-解码器添加分类头</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xffti/d_adding_a_classification_head_to_an/</link>
      <description><![CDATA[大家好， 我已经构建了一个类似于 这个。这效果很好，我现在还需要向该模型添加一个分类头（因此多任务，2 个头输出，一个分类头，对每个通过的序列进行一个下一个标记预测）。  我已将解码器输出的平均值作为单独的分类器，但希望分类仅基于编码器进行分类。我的实现如下： class Transformer(nn.Module): def __init__(self, vocab_len, d_model, num_classes, num_enc_layers: int = 6, num_dec_layers: int = 6, num_heads : int = 8, dim_ff: int = 512, dropout: float = 0.1): super(TransformerProm, self).__init__() #self.transformer = Transformer(d_model=d_model, nhead=num_heads, num_encoder_layers=num_enc_layers, # num_decoder_layers= num_dec_layers，dim_feedforward=dim_ff，dropout=dropout）encoder_layer = nn.TransformerEncoderLayer（d_model = d_model，nhead = num_heads）self.encoder = TransformerEncoder（encoder_layer = encoder_layer，num_layers = num_enc_layers）decoder_layer = nn.TransformerDecoderLayer（d_model = d_model，nhead = num_heads) self.decoder = TransformerDecoder(decoder_layer=decoder_layer, num_layers=num_dec_layers) self.decoder_output = nn.Linear(d_model, vocab_len) self.classifier_output = nn.Linear(d_model, num_classes) self.src_embedding = TokenEmbedding(vocab_len, d_model) self.tgt_embedding = TokenEmbedding(vocab_len, d_model) self.positional_encoding = PositionalEncoding(d_model, dropout=dropout) defforward(self, src, tgt, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask): src_emb = self.positional_encoding(self. src_embedding(src)) tgt_emb = self.positional_encoding(self.tgt_embedding(tgt)) outs_enc = self.encoder(src=src_emb, mask=src_mask, src_key_padding_mask=src_padding_mask) outs_decoder = self.decoder(tgt=tgt_emb, memory=outs_enc, tgt_mask = tgt_mask，memory_mask =无，tgt_key_padding_mask = tgt_padding_mask，memory_key_padding_mask = memory_key_padding_mask）classification_outs =outs_enc.mean（dim = 0）返回self.decoder_output（outs_decoder），self.classifier_output（classification_outs） 损失是单独计算的，求和，然后向后传递。 我的问题是，这是仅从编码器实现第二分类头的正确方法吗？我最初使用 Pytorch 中的主要 Transformer 类来完成此操作，如下所示： class Transformer: self.transformer = Transformer(d_model=d_model, nhead=num_heads, num_encoder_layers= num_enc_layers, num_decoder_layers=num_dec_layers, dim_feedforward=dim_ff, dropout=dropout) defforward()...outs_decoder = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, src_padding_mask, tgt_padding_mask, memory_key_padding_mask) outs_enc = self.transformer.encoder (src_emb, src_mask)classification_outs = outs_enc.mean(dim=0) #print(classification_outs) #print(classification_outs.shape) return self.decoder_output(outs_decoder), self.classifier_output(classification_outs)  &lt; p&gt;但是编码器的梯度计算了两次（一次仅针对编码器，另一次针对编码器和解码器），我自己都困惑了！我认为第一个实现是正确的？ 谢谢！   由   提交/u/amjass12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xffti/d_adding_a_classification_head_to_an/</guid>
      <pubDate>Wed, 03 Jan 2024 09:30:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有办法以编程方式创建字幕？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xf17r/d_is_there_a_way_to_create_subtitles/</link>
      <description><![CDATA[我正在使用 Google Cloud Text to Speech 从文本生成音频。 所以我有文本，我有音频，现在我需要字幕。为了获得好的字幕，我需要准确的单词时间。我怎样才能到达那里？ 或者有更好的方法吗？有什么建议吗？   由   提交/u/castoro800  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xf17r/d_is_there_a_way_to_create_subtitles/</guid>
      <pubDate>Wed, 03 Jan 2024 09:02:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于云的 GPU 租赁服务有推荐吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18x5ctn/d_cloudbased_gpu_rental_service_recommendations/</link>
      <description><![CDATA[有人可以推荐通过云租用 GPU 的服务吗？我的用例是微调变压器模型，而我可以访问的 GPU 没有足够的 RAM 来避免内存不足错误。我主要关心 Jupyter 笔记本的易用性和工作能力。提前致谢。   由   提交/u/Susemiehlian1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18x5ctn/d_cloudbased_gpu_rental_service_recommendations/</guid>
      <pubDate>Wed, 03 Jan 2024 00:30:55 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 有人从少量高质量（基础）信息研究机器学习吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18x33cm/discussion_anyone_researching_ml_from_small/</link>
      <description><![CDATA[当今的机器学习技术是统计模型，可以从大量数据中学习，这些数据预计具有不同程度的噪声、相关性等。我想知道如果有人目前正​​在研究机器学习技术，该技术可以从小块基本信息中学习并自动推断这些基本信息的结果，类似于逻辑代理，更接近地模拟人类学习。 例如，学生可以阅读一本介绍性教科书，并结合推理和推测得出一个新颖的研究问题。然而，当前的“智能”系统不是为此而设计的。我们可以使用语言建模和逻辑代理的组合来模拟这种行为吗？ 目前有人在研究这个吗？这个智力模型有名字吗？有没有人证明这是当前法学硕士的紧急行为？   由   提交/u/i_wasserman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18x33cm/discussion_anyone_researching_ml_from_small/</guid>
      <pubDate>Tue, 02 Jan 2024 22:56:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 优化平均损失与极值损失</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18x16kw/d_optimizing_mean_loss_vs_extremal_loss/</link>
      <description><![CDATA[在训练神经网络时，我们通常借鉴 MLE 的统计实践和 IID 数据，并最小化每个样本的损失函数的平均值。 然而，初步估计，生物自然选择必须减轻极端的负面结果（即防止死亡），而不是优化平均结果。我想知道这是否解释了动物大脑和我们当前的神经网络之间归纳先验的一些差异。 那么谁对其中一个玩具问题进行了以下实验（或类似的实验），并做了它工作？在每个批次中，运行前向传递，按损失值对样本进行排序，并且仅根据样本中表现最差的一半/四分之一/……来更新模型。如果需要，我会在有空闲时间试用后向您报告。   由   提交 /u/IWearMyFace   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18x16kw/d_optimizing_mean_loss_vs_extremal_loss/</guid>
      <pubDate>Tue, 02 Jan 2024 21:39:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] Self-Attention：使用 FFT 使用 QK 内核进行位置编码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18x16g7/r_selfattention_positional_encoding_with_qk/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18x16g7/r_selfattention_positional_encoding_with_qk/</guid>
      <pubDate>Tue, 02 Jan 2024 21:39:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 仅通过一篇出版物获得行业研究科学家实习/全职职位？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wwsls/d_landing_an_industry_research_scientist/</link>
      <description><![CDATA[我目前是一名计算机科学博士生，计划于 2024 年 12 月毕业。截至目前，我从事两个研究项目，其中一篇已在信誉良好的（A 级）会议上发表，另一篇正在审稿中。我现在正在进行第三个项目，这是我论文的最后一章。  我最初的目标是在毕业时获得终身教职，但考虑到我发表的出版物数量，这似乎不太可能。另外，在该项目度过了近三年之后，我开始意识到学术界可能不适合我，我只想尽快毕业。 话虽这么说，但会有多艰难是只发表一篇论文就获得暑期研究实习机会（最好是科技公司）？另外，如果我在博士学位结束时发表了两篇论文，其中一篇发表在一个好的会议上，而另一篇发表在一个中级会议上，那么我获得该行业全职研究科学家的机会有多大？  任何关于作为发表少量出版物的研究科学家过渡到工业界的建议或建议都会非常有帮助。   由   提交 /u/Funny_Rule2482   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wwsls/d_landing_an_industry_research_scientist/</guid>
      <pubDate>Tue, 02 Jan 2024 18:45:05 GMT</pubDate>
    </item>
    <item>
      <title>[P]我创建了一个完全在潜在空间中运行的社交网络！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wscw4/p_i_made_a_social_network_that_operates_entirely/</link>
      <description><![CDATA[Litter（又名潜在 Twitter）将在图像和文本到达网络之前通过多种模态转换来提取图像和文本，以便您可以仅传达消息的本质. 视频在这里：https://youtu.be/v8O_tSF_o50   由   提交/u/ykilcher  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wscw4/p_i_made_a_social_network_that_operates_entirely/</guid>
      <pubDate>Tue, 02 Jan 2024 15:44:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] Stella Nera：通过基于近似矩阵乘法的无乘数 DNN 加速实现 161 TOp/s/W</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wnerq/r_stella_nera_achieving_161_topsw_with/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2311.10207 代码：https://github .com/joennlae/halutmatmul 摘要：  从经典 HPC 到深度学习，MatMul 是当今计算的核心计算。最近的 Maddness 方法通过使用基于散列版本的乘积量化 (PQ) 索引到查找表 (LUT) 来近似 MatMul，无需进行乘法。 Stella Nera 是首款 Maddness 加速器，与在相同的技术。哈希函数是一个决策树，它允许高效的硬件实现，因为乘法累加操作被决策树传递和 LUT 查找所取代。整个 Maddness MatMul 可以分解为多个部分，允许使用小型计算单元和内存进行有效实现，使其达到极高的效率，同时保持对 MatMul 任务的普遍适用性。 在商用 14 纳米技术中并扩展到 3 纳米，我们使用 ResNet9 实现了 161 TOp/s/W @0.55V 的能效，并且在 CIFAR-10 上的 Top-1 精度超过 92.5%。     由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wnerq/r_stella_nera_achieving_161_topsw_with/</guid>
      <pubDate>Tue, 02 Jan 2024 11:34:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>