<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 04 Jun 2024 21:13:06 GMT</lastBuildDate>
    <item>
      <title>[D] 有没有什么好的模型可以对语义分割输出进行集成？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d86oyj/d_are_there_any_good_models_that_can_perform/</link>
      <description><![CDATA[大家好，我目前有几个模型可以在输入数据集上输出语义分割掩码。我现在有一个简单的集成，我基本上是堆叠模型输出，然​​后对组合数据使用逻辑回归。我四处寻找更先进的技术，但我还没有做出决定。有没有可以作为语义分割有效模型的模型？    提交人    /u/Searin   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d86oyj/d_are_there_any_good_models_that_can_perform/</guid>
      <pubDate>Tue, 04 Jun 2024 20:05:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 一种无需阈值调节的神经网络结构化剪枝新方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d85eqd/r_a_new_method_for_structured_pruning_of_neural/</link>
      <description><![CDATA[https://arxiv.org/abs/2406.01345 我们很高兴与大家分享我们的成果“BMRS：结构化剪枝的贝叶斯模型简化”。结构化剪枝通过移除对输出影响有限的整个网络结构（例如神经元或卷积滤波器）来提高神经网络效率。我们提出了一种结构化剪枝的贝叶斯方法，该方法自动确定要剪枝的结构。这是通过将贝叶斯结构化剪枝与对数乘性噪声和贝叶斯模型简化相结合来实现的。  该论文的代码可以在这里获得：https://github.com/saintslab/bmrs-structured-pruning    由   提交  /u/ewits   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d85eqd/r_a_new_method_for_structured_pruning_of_neural/</guid>
      <pubDate>Tue, 04 Jun 2024 19:12:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当查询包含不相关的词时提高语义搜索的准确性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8516v/d_enhancing_semantic_search_accuracy_when_queries/</link>
      <description><![CDATA[嘿，我知道这可能看起来不太先进，但我在实施针对特定查询的语义搜索时面临挑战。以下是我所拥有的内容的概述：  在数据库中准备用于简短/通用术语（例如，黑色钢琴、靛蓝白色、深粉色等）的向量嵌入。 接收用户查询（例如：“前轮深色钢琴格栅”）。  有趣的是：查询字符串可以完全随机，可能包括我的数据库中已知或未知的单词，并且单词的长度和顺序不确定。我尝试更改欧几里得和余弦之间的相似性指标，但对于我的用例来说似乎没有显着差异。我也尝试过实现基于字符串长度的动态阈值，但是它太宽泛了。 语义搜索是否适合我的用例，还是我应该考虑其他方法？    提交人    /u/ConfusedXmen   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8516v/d_enhancing_semantic_search_accuracy_when_queries/</guid>
      <pubDate>Tue, 04 Jun 2024 18:57:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将位置偏差结合到 softmax-crossentropy 中</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d83yf3/d_combining_position_bias_into_softmaxcrossentropy/</link>
      <description><![CDATA[考虑一个学习排名设置，其中我从针对每个用户查询向用户显示的 N 个项目中进行学习。假设我可以量化在检查了第一个位置的情况下检查每个位置 i 的概率 P[examine_i]（即相对于第一个位置）。用户反馈是二进制的 - 点击/不点击。 现在假设我对每个查询使用 softmax-crossentropy 损失（不要问为什么 - 假设它是一个约束）。合并位置偏差信息的“正确”方法是什么？ 直观地说，点击较低的位置比点击较高的位置更具信息量。因此，将损失与点击位置 i 的 P[examine_i] 成反比进行权衡是有益的。另一方面，低位置上的非点击信息量较少，因此在 soft-max 中以较低的检查概率导致较低权重的方式对术语进行加权是有意义的。但正确的权重是什么？这并不明显。    提交人    /u/alexsht1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d83yf3/d_combining_position_bias_into_softmaxcrossentropy/</guid>
      <pubDate>Tue, 04 Jun 2024 18:13:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 将不同词汇的 LLM 的概率分布输出融合在一起的最新进展是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d818iz/d_what_is_the_latest_in_fusing_the_probability/</link>
      <description><![CDATA[我最近看到了这些论文，它们将具有不同词汇的 LLM 的概率分布融合在一起 https://arxiv.org/pdf/2404.12715v2 - 本文使用无需训练的方法，将分布转换为共享空间，对它们进行平均，然后将它们重新转换为所选模型的分布 https://openreview.net/forum?id=jiDsk12qcz - 本文根据其他 LLM 的概率分布训练目标 LLM（对词汇差异有一些特殊逻辑） 第一篇论文特别有趣，因为它声称使用无需训练的方法比第二篇论文表现更好通过将不同的概率分布投射到共享空间中。这依赖于这样的假设：在不同模型中，标记之间的相对角度大致一致，他们声称这是经验支持的。 我也很好奇是否有任何类似的工作来融合隐藏状态，也许是在转换为标记之前的最后一层。原因是一些多模态输出模型在需要输出图像等内容时会动态地将其隐藏状态传递给解码器，因此仅融合标记的概率分布可能还不够。    提交人    /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d818iz/d_what_is_the_latest_in_fusing_the_probability/</guid>
      <pubDate>Tue, 04 Jun 2024 16:20:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] mamba.np：Mamba 的纯 NumPy 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d80t26/p_mambanp_pure_numpy_implementation_of_mamba/</link>
      <description><![CDATA[      mamba.np 受到一些很棒的项目的启发，我用纯 Numpy 从头实现了 Mamba。代码的目标是简单、可读、轻量，因为它可以在本地 CPU 上运行。 https://github.com/idoh/mamba.np 希望您觉得它有用 :)    提交人    /u/id0h   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d80t26/p_mambanp_pure_numpy_implementation_of_mamba/</guid>
      <pubDate>Tue, 04 Jun 2024 16:02:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 数据、排序和内在维度对分层可导航小世界中回忆的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d805fb/r_the_impacts_of_data_ordering_and_intrinsic/</link>
      <description><![CDATA[本文深入探讨了分层可导航小世界 (HNSW) 图及其在向量搜索系统中的性能。本文揭示了可能影响检索系统效率和准确性的重要见解。 主要发现：  参数配置很重要：与精确 KNN 相比，HNSW 中配置不足的参数可能会使 NDCG@10 下降高达 18%，并改变模型排名。 数据插入顺序：将数据插入 HNSW 图的顺序可能会导致召回率相对变化高达 17%。 内在维度：数据集的内在维度越高，通常召回率越差。这对于理解不同模型和数据如何影响搜索性能至关重要。 局部内在维度 (LID)：插入之前按降序 LID 对数据进行排序可显着提高召回率，模仿优化图形条件的退火过程。 更高的默认参数：我们推荐的默认值 (efConstruction = 512、M = 16 和 efSearch = 2000) 优于许多现有配置，特别是在使用 Vespa 的系统中，它可以在不影响性能的情况下处理这些配置。 模型性能：当使用近似检索系统与精确 KNN 进行评估时，模型的排名会发生变化。较小的模型（例如 all-MiniLM-L6-v2 和 bge-micro）提高了它们在近似系统中的相对性能。 合成数据：本文通过生成具有受控内在维度的合成数据展示了内在维度如何影响召回率。  完整论文在此： https://arxiv.org/abs/2405.17813     提交人    /u/elliesleight   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d805fb/r_the_impacts_of_data_ordering_and_intrinsic/</guid>
      <pubDate>Tue, 04 Jun 2024 15:35:17 GMT</pubDate>
    </item>
    <item>
      <title>[R]xLSTM官方代码+Kilcher视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7zppm/r_xlstm_official_code_kilcher_video/</link>
      <description><![CDATA[论文，仅供参考，即将更新（根据视频 - 见下文）： https://arxiv.org/pdf/2405.04517 NX-AI 终于为他们的 xLSTM 实现发布了一个 python 包： https://github.com/nx-ai/xlstm Yannic Kilcher 还发布了一段新视频解释该论文： https://www.youtube.com/watch?v=0OaEv1a5jUM 有人重现了这篇论文的结果吗？我发现 sLSTM 是对 vanilla LSTM 的巨大改进，但我无法让 mLSTM 单独工作。     提交人    /u/Builder_Daemon   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7zppm/r_xlstm_official_code_kilcher_video/</guid>
      <pubDate>Tue, 04 Jun 2024 15:17:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] MMLU-Pro：更强大、更具挑战性的多任务语言理解基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7uamg/r_mmlupro_a_more_robust_and_challenging_multitask/</link>
      <description><![CDATA[      TL;DR：MMLU 但更具挑战性并且（据称）噪音更小 论文：https://arxiv.org/pdf/2406.01574 摘要：  在大规模语言模型时代，大规模多任务语言理解 (MMLU) 等基准对于推动 AI 在不同领域的语言理解和推理能力的极限至关重要。然而，随着模型的不断改进，它们在这些基准上的表现已开始趋于稳定，使得辨别模型能力的差异变得越来越困难。本文介绍了 MMLU-Pro，这是一个增强型数据集，旨在通过整合更具挑战性、以推理为重点的问题并将选择集从四个选项扩展到十个选项来扩展主要由知识驱动的 MMLU 基准。此外，MMLU-Pro 消除了 MMLU 中的琐碎和嘈杂问题。我们的实验结果表明，MMLU-Pro 不仅提高了挑战性，导致准确率与 MMLU 相比大幅下降 16% 至 33%，而且在不同提示下也表现出更高的稳定性。在测试了 24 种不同的提示风格后，模型得分对提示变化的敏感度从 MMLU 中的 4-5% 下降到 MMLU-Pro 中的仅 2%。此外，我们发现使用思路链 (CoT) 推理的模型在 MMLU-Pro 上的表现比直接回答更好，这与原始 MMLU 上的结果形成鲜明对比，表明 MMLU-Pro 包含更复杂的推理问题。我们的评估证实，MMLU-Pro 是一个更具辨别力的基准，可以更好地跟踪该领域的进展。  组成 基准测试。注意 Phi 对 MMLU 的优化对于新数据集仍然很稳健 与 MMLU 结果进行比较。请注意表现最佳的 LM 之间的更大差异 值得注意的亮点：  MMLU-Pro 有十个选项，其中包含的干扰项比 MMLU 多 3 倍。通过增加干扰项数量，我们显著降低了偶然正确猜测的概率，从而提高了基准的难度和鲁棒性。 [...] MMLU-Pro 需要思维链 (CoT) [41] 才能取得有希望的结果。例如，CoT 可以将 GPT-4o 的性能提高 19%。相反，CoT 实际上会损害模型在 MMLU 上的性能。这反映了在 MMLU-Pro 上进行深思熟虑的推理的必要性，而这在知识驱动的 MMLU 问题中是不需要的。  HuggingFace: https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7uamg/r_mmlupro_a_more_robust_and_challenging_multitask/</guid>
      <pubDate>Tue, 04 Jun 2024 10:57:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 图像超分辨率数据集修剪研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7st4v/r_a_study_in_dataset_pruning_for_image/</link>
      <description><![CDATA[我们很高兴与大家分享我们最近的作品《图像超分辨率数据集修剪研究》，该作品已被 ICANN 2024 接受 :) 我们引入了一种基于损失值的采样方法，该方法将训练数据集缩减为由简单的预训练 SRCNN 模型确定的核心集（原始数据集的 50%）。通过专注于包含高损失值（即“困难样本”），我们获得的结果可与对完整数据集进行训练获得的结果相媲美甚至超过这些结果。此外，我们发现最难样本的前 5% 会对训练产生负面影响。排除这些样本可进一步增强结果，或者简而言之，选择 45-95% 的最难样本部分可获得最佳训练质量。我们希望为图像 SR 中数据集修剪的未开发潜力开辟新的视角，并为其他领域提供新的想法。 arXiv：https://arxiv.org/abs/2403.17083    提交人    /u/Maleficent_Stay_7737   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7st4v/r_a_study_in_dataset_pruning_for_image/</guid>
      <pubDate>Tue, 04 Jun 2024 09:14:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mamba2 SSD 收缩可视化为张量网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7q386/d_mamba2_ssd_contractions_visualized_as_a_tensor/</link>
      <description><![CDATA[      https://preview.redd.it/3lpr8yp5yh4d1.png?width=2667&amp;format=png&amp;auto=webp&amp;s=a410811c8d010f7697ecfc76138258d089113d30 我不确定这是否会对任何人有所帮助，但我发现 Mamba 2 论文中的收缩顺序相当有趣，并认为它可能将其可视化为张量网络很不错。这对应于第一阶段收缩，或 Y_diag = torch.einsum(&quot;bclhn,bcshn,bhcls,bcshp-&gt;bclhp&quot;, C, B, L, X) 请注意索引 b、c 和 h 如何出现在每个表达式中，因此它们可以抽象（并行化），收缩操作的核心实际上在于 d_head、d_state、length 和 length（mixed）。然后，收缩操作涉及通过边收缩合并图中的两个节点。 请注意，与节点相邻的边数对应于张量的维度（加上 3 个公共维度）。在作者提出的收缩路径下（参见上面的代码），可以很容易地看到，维度大于 5 的张量永远不会实现。这是可能的，因为 segsum 矩阵（由 A 矩阵诱导）没有 d_state 依赖性，或“限制为 标量乘以恒等式 结构”。 我猜这可能不是最普遍的收缩形式，并且出于实际的硬件内存考虑，可能还有其他方法可以构建更具表现力的张量网络，以保证维度大于 5 的张量不实现。   由    /u/dna961010  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7q386/d_mamba2_ssd_contractions_visualized_as_a_tensor/</guid>
      <pubDate>Tue, 04 Jun 2024 06:00:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 矢量神经网络 (VNN) – 利用二维矢量神经元和几何张量增强几何深度学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7lpfu/d_vector_neural_networks_vnns_enhancing_geometric/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7lpfu/d_vector_neural_networks_vnns_enhancing_geometric/</guid>
      <pubDate>Tue, 04 Jun 2024 01:51:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] Text2Bricks：在 1,000 个 GPU 小时内对 Open-Sora 进行微调以制作砖块动画</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7ats8/p_text2bricks_finetuning_opensora_in_1000_gpu/</link>
      <description><![CDATA[大家好，Lambda Labs 的研究团队获得了大量 NVIDIA H100 GPU 的使用权，并用它来训练 OpenSora 制作砖块动画。团队和我随时准备回答您可能遇到的任何问题。您可以在此处阅读我们 W&amp;B 文章的所有详细信息： https://wandb.ai/lambdalabs/lego/reports/Text2Bricks-Fine-tuning-Open-Sora-in-1-000-GPU-Hours--Vmlldzo4MDE3MTky 所有模型均可用（文章中有链接），您甚至可以玩我们使用该模型制作的有趣游戏！ https://albrick-hitchblock.s3.amazonaws.com/index.html    由    /u/jedberg 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7ats8/p_text2bricks_finetuning_opensora_in_1000_gpu/</guid>
      <pubDate>Mon, 03 Jun 2024 17:57:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformers 是 SSM：通过结构化状态空间对偶实现广义模型和高效算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7a6l6/r_transformers_are_ssms_generalized_models_and/</link>
      <description><![CDATA[  由    /u/floppy_llama  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7a6l6/r_transformers_are_ssms_generalized_models_and/</guid>
      <pubDate>Mon, 03 Jun 2024 17:30:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>