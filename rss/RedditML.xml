<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 29 Jun 2024 12:26:39 GMT</lastBuildDate>
    <item>
      <title>[D] 使用嵌入模型时...</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dr86u3/d_when_using_embedding_models/</link>
      <description><![CDATA[当使用嵌入模型将新的、大量数据合并到 GPT-4 等 LLM 中时，是否需要手动准备数据（清理、分类等），还是这些模型会自动处理？    提交人    /u/SnooBeans2906   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dr86u3/d_when_using_embedding_models/</guid>
      <pubDate>Sat, 29 Jun 2024 10:26:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于生成式人工智能如何影响工程和工业流程以及帮助解决气候变化的精彩演讲</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dr70j0/d_fascinating_talk_on_how_generative_ai_will/</link>
      <description><![CDATA[        由    /u/chelsea_bear  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dr70j0/d_fascinating_talk_on_how_generative_ai_will/</guid>
      <pubDate>Sat, 29 Jun 2024 09:00:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 DINO 模型要对教师编码器使用增强功能？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dr6aad/d_why_do_dino_models_use_augmentations_for_the/</link>
      <description><![CDATA[如标题所示 - DINO 和 DINOv2 使用增强来输入教师网络。为什么会这样？从“最干净”的数据版本生成教师表示不是更有意义吗？真的很想听听他们所做事情背后的直觉。    提交人    /u/clywac2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dr6aad/d_why_do_dino_models_use_augmentations_for_the/</guid>
      <pubDate>Sat, 29 Jun 2024 08:07:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 液态神经网络 + 脉冲神经网络。您觉得如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dr69f5/r_liquid_neural_networks_spiking_neural_networks/</link>
      <description><![CDATA[刚刚与 gpt4 就此进行了长时间的交谈，有很多想法和事情要尝试/研究。这似乎是一种非常不可思议的方式来构建超级强大的架构（当然还要添加一些酱料）。有没有其他人研究或试验过这种东西？如果有，请随时给我发私信，我们可以进一步讨论，无论是关于这个还是其他 AI 的东西！    提交人    /u/DennisKosht​​a   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dr69f5/r_liquid_neural_networks_spiking_neural_networks/</guid>
      <pubDate>Sat, 29 Jun 2024 08:05:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 这是一个回归问题还是排名问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqzgh8/p_is_it_a_regression_or_ranking_problem/</link>
      <description><![CDATA[大家好！ 我正在制作一个带有强化学习的俄罗斯方块机器人，但我不确定应该采用哪种方法： 我不希望我的 NN 输出与移动相对应的键；我想要的是我的神经网络能够对网格进行评分 基本上，我可以从单个向量中的网格中获取一些键值（例如每列的高度、填充行的 nb...），我正在计算与“猛击”结果相对应的多个网格将四格骨牌放在多个 x 坐标处，然后我想移动到与所有网格中得分最高的网格的位置 但这是一个回归问题吗？ 因为我的模型只需要学习输出一个对应于单个网格得分的单个数字，所以我得到了每个网格的得分，然后得到了得分最高的网格 如果是的话，我能否正确微调损失，因为奖励只来自于我将做出的最后一步，所以很多预测没有得到正确的纠正？ 或者是排名问题？ 因为我的模型应该学会从所有&quot;feeded&quot; 作为输入的网格中给出最好的结果 我试图查看&quot;排名&quot;可以在 PyTorch 中完成，但我似乎找不到方法，我缺乏有关如何搜索合适框架来执行此操作的知识 感谢您的时间！    提交人    /u/Mikgician   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqzgh8/p_is_it_a_regression_or_ranking_problem/</guid>
      <pubDate>Sat, 29 Jun 2024 01:13:33 GMT</pubDate>
    </item>
    <item>
      <title>语音生成模型建议建立数据集来检测言语障碍儿童的言语错误 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqy6rw/speech_generation_model_suggestions_for_building/</link>
      <description><![CDATA[我正在尝试构建一个音频分类模型，该模型可以检测出患有言语障碍的儿童的言语错误，以进一步帮助治疗过程。 由于真实数据的可用性低，我想在合成语音数据上启动训练过程。 为此，我需要生成器模型来发音一个单词（音素列表），其中我们用通常由儿童替换的音素替换一些音素。 我尝试过 suno/bark 和 espeak，但它们无法正确生成错误的单词。 请建议一些严格遵守所提供音素的语音生成模型。    提交人    /u/Agreeable_Ad_1085   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqy6rw/speech_generation_model_suggestions_for_building/</guid>
      <pubDate>Sat, 29 Jun 2024 00:06:53 GMT</pubDate>
    </item>
    <item>
      <title>[P]图注意力网络。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqrdr8/pgraph_attention_network/</link>
      <description><![CDATA[我正在尝试训练一个模型，以便它可以预测在路面上施加负载时的应变。我正在训练模型，以便它模仿 3D 分层弹性分析技术，但模型无法预测。我不确定模型是否正在接受训练。它从 5 个最近的邻居那里获取信息并传递消息。即使在训练了 10k 个时期后，模型也无法预测。我不知道模型在哪里收敛。有人可以指导我吗？    提交人    /u/Secret_Dinner7822   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqrdr8/pgraph_attention_network/</guid>
      <pubDate>Fri, 28 Jun 2024 19:00:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人见过 Kolmogorov-Arnold 网络在现实中的应用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqr9gh/d_anyone_see_any_real_usage_of_kolmogorovarnold/</link>
      <description><![CDATA[KAN 在各处（包括 Reddit）都备受热捧，许多人都对它赞不绝口，尽管并非都是好评。现在已经过去 3 个月了。有没有人看到任何可以证实或反驳“信徒”的东西？就我个人而言，我没有看到任何值得注意的 KAN 采用​​情况。希望听听社区的意见。    提交人    /u/Sad-Journalist752   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqr9gh/d_anyone_see_any_real_usage_of_kolmogorovarnold/</guid>
      <pubDate>Fri, 28 Jun 2024 18:55:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] “Grok” 有太多不同的含义</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqpyb3/d_grok_means_way_too_many_different_things/</link>
      <description><![CDATA[我厌倦了到处看到这个词，而且它每次在同一个领域都有不同的含义。对我来说，第一次是当伊隆·马斯克推出并大肆宣传 Twitter 的新产品（现在不是新的，但当时是）“Grok AI”时，然后我阅读了更多论文，发现了一个相当惊人的发现，显然地球上的每个人都知道了一段时间，除了我之外，那就是在某个点之后，过度拟合模型开始能够概括，这摧毁了我之前的许多先入为主的观念以及我在学校和其他地方学到的东西。但这种现象也被称为“Grok”，然后有一篇基于 Grok 定义的新“GrokFast”论文，还有“Groq”，不要与其他两个“Grok”混淆，更不用说伊隆·马斯克将他的人工智能装备命名为“xAI”机械可解释性人们已经在使用该术语作为“可解释的 AI”的缩写，这对我来说太多了    提交人    /u/Traditional_Land3933   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqpyb3/d_grok_means_way_too_many_different_things/</guid>
      <pubDate>Fri, 28 Jun 2024 17:59:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 上下文增强检索：一种使用大型语言模型进行快速信息检索的响应生成新框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqnxm9/r_contextaugmented_retrieval_a_novel_framework/</link>
      <description><![CDATA[  由    /u/davidmezzetti  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqnxm9/r_contextaugmented_retrieval_a_novel_framework/</guid>
      <pubDate>Fri, 28 Jun 2024 16:33:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] Paddler（为 llama.cpp 定制的状态负载均衡器）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dql325/p_paddler_stateful_load_balancer_customtailored/</link>
      <description><![CDATA[我最近开始了这个项目。它允许我们自行托管 llama.cpp 并将其与开源模型一起使用。 它最近开始获得一些关注，并且已经准备好投入生产。 它允许从零实例扩展，因此如果您使用云提供商使用开源 LLM 为您的想法制作原型，则只需为实际使用的内容付费。如果有一段时间不活动，您可以使用它来关闭昂贵的 GPU 实例，只留下一些便宜的 CPU 实例并让平衡器本身运行。 它可以部署在任何云或 Kubernetes 集群中。它有一些 AWS 辅助实用程序，可轻松在那里部署，但这些都是可选的。 Paddler 不会强迫您以特定方式配置 llama.cpp。您可以以任何方式配置您的 llama.cpp 实例，它会插入其 HTTP API。 https://github.com/distantmagic/paddler    提交人    /u/mcharytoniuk   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dql325/p_paddler_stateful_load_balancer_customtailored/</guid>
      <pubDate>Fri, 28 Jun 2024 14:33:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 深度学习论文摘要</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqg67i/r_deep_learning_paper_summaries/</link>
      <description><![CDATA[印度理工学院鲁尔基分校的视觉语言小组对来自 NeurIPS、CVPR、ICCV、ICML 2016-24 等各个著名会议的深度学习论文进行了全面的总结。一些值得注意的例子包括：  DreamBooth：针对主题驱动生成对文本到图像扩散模型进行微调，CVPR&#39;23 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/DreamBooth.md Segment Anything，ICCV&#39;23 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Segment_Anything.md 一张图片胜过一个词：使用个性化文本到图像生成文本反转，ICVR&#39;23 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Textual_inversion.md 具有深度语言理解的逼真文本到图像扩散模型，NIPS&#39;22 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/imagen.md 一张图片胜过 16X16 个单词：用于大规模图像识别的 Transformers，ICLR&#39;21 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Vision_Transformer.md Big Bird：用于更长序列的变换器，NIPS&#39;20 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Big_Bird_Transformers.md  如果您发现这些摘要有用，您可以贡献自己的摘要。 repo 将不断更新来自领先会议的更多论文摘要。    提交人    /u/vlg_iitr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqg67i/r_deep_learning_paper_summaries/</guid>
      <pubDate>Fri, 28 Jun 2024 10:09:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 分割任意文本：一种稳健、高效且适应性强的句子分割通用方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqfhn6/r_segment_any_text_a_universal_approach_for/</link>
      <description><![CDATA[      标题：分割任何文本：一种稳健、高效且适应性强的句子分割通用方法高效且适应性强的句子分割 论文： https://arxiv.org/abs/2406.16678 代码： https://github.com/segment-any-text/wtpsplit https://preview.redd.it/6frvmpc36a9d1.png?width=1849&amp;format=png&amp;auto=webp&amp;s=08c9769384d63bfd3ad786b0259f1dd4a97d4bce 摘要：  将文本分割成句子在许多 NLP 系统中起着早期和关键的作用。这通常通过使用基于规则或统计的方法来实现，这些方法依赖于标点符号等词汇特征。尽管最近的一些研究不再完全依赖标点符号，但我们发现，之前的方法都无法同时实现 (i) 对缺失标点符号的稳健性、(ii) 对新领域的有效适应性和 (iii) 高效率。我们引入了一个新模型 - 分割任何文本 (SaT) - 来解决这个问题。为了增强稳健性，我们提出了一种新的预训练方案，以确保减少对标点符号的依赖。为了解决适应性问题，我们引入了一个额外的参数高效微调阶段，在不同领域（例如歌词和法律文件中的诗句）建立了最先进的性能。在此过程中，我们引入了架构修改，使速度比以前的最先进水平提高了三倍，并解决了未来对上下文的虚假依赖。最后，我们引入了我们的模型的一个变体，该变体对多种多语言的句子分割数据进行了微调，作为现有分割工具的直接替代和增强。总的来说，我们的贡献提供了一种分割任何文本的通用方法。我们的方法优于所有基线 - 包括强大的 LLM - 在 8 个语料库中涵盖不同的领域和语言，特别是在文本格式不佳的实际相关情况下。 我们的模型和代码（包括文档）可在 此 https URL 下根据 MIT 许可获得。     提交人    /u/markus_583   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqfhn6/r_segment_any_text_a_universal_approach_for/</guid>
      <pubDate>Fri, 28 Jun 2024 09:22:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有其他人也正被报纸所包围，并且随时准备被抢先报道？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqbgw4/d_is_anyone_else_absolutely_besieged_by_papers/</link>
      <description><![CDATA[我是一名一年级博士生，研究机器学习的一个热门领域（猜了 3 次，哈哈），过去的一年对我个人而言绝对是残酷的。每个工作日，我都会查看收件箱中的每日 arxiv 摘要，总有 3-5 篇与我的主题相关的新论文，尤其是最近每个人都在发布他们的 Neurips 投稿。 到目前为止，还没有一篇论文直接抢先发表我所研究的内容，但最近有太多差点被抢先发表的论文，这让我担心：(a) 这只是时间问题，我应该更快地完成预印本；或者 (b) 即使我在不​​久的将来发表了一篇论文，它也只是十几篇类似的论文之一，不会引起太大的关注。有些论文甚至有我导师的名字，因为她是一位著名的教授，非常乐于合作（我有时会想，因为她向很多人推销同样的想法，所以不可避免地会出现一些当地的抢先报道）。这些情况让我更加焦虑，因为我觉得速度在这里真的是最好的比较优势；从想法的产生到执行再到发表，都是速度的迭代。 我不知道，我觉得自己在本科时是如此的多产和成就，并且领先于时代，而现在已经一年了，我仍然在努力提出一个有意义和新颖的想法......有没有其他人和我一样？有没有人有什么有用的建议......如何应对快速出版周期的压力，或者如何在研究的早期挣扎，或者如何更快更好地思考？谢谢你听我（可能非常天真）的咆哮......    提交人    /u/akardashian   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqbgw4/d_is_anyone_else_absolutely_besieged_by_papers/</guid>
      <pubDate>Fri, 28 Jun 2024 04:48:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>