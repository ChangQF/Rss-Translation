<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 04 Sep 2024 03:16:43 GMT</lastBuildDate>
    <item>
      <title>[P] 使用 Keras 集成方案获得相同的序列预测结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8fprj/p_getting_same_sequence_prediction_results_with/</link>
      <description><![CDATA[我正在使用 Keras 开发 LSTM/GRU 序列预测模型。我正在查看一家布局相当线性的商店中购物者购买的商品数量。例如，一位购物者购买了 5 个苹果，然后购买了 6 个香蕉，然后购买了 3 个梨。另一位购物者购买了 3 个苹果、10 个香蕉和 4 个梨，等等。水果不是实际产品，我做了一些混淆以保护我的客户，这样就不会被难倒。无论哪种方式，我都有一个序列预测，如 5,6:3、3,10:4。因为两种产品的数据不足以获得可靠的结果，所以我正在做一个“集成”方案，其中我取第一个数字（其预测本身来自客户之前的访问）并加/减一几次。因此，如果他们上次购物时买了 5 个苹果，而我的 NN 预测他们这次会买 3 个，那么我用于预测香蕉的数据集将变为 [2：？，3：？，4：？]，我对香蕉预测做同样的事情，如果神经网络输出 2：8、3：7、4：9 的预测，那么我用于预测梨的输入将变为 (2,6：？，2,7：？，2,8：？，2,9：？，2,10：？，3,5：？，3,6：？，3,7：？，3,8：？，3,9：？，4,7：？，4,8：？，4,9：？，4,10：？，4,11：？)。现在事情开始变得复杂了。 当我对一整套数据（我大概有六种产品需要预测）运行我的模型时，最后，数据看起来都一样。特别是第 5 和第 6 个数字是相同的。随着我引入的变化，我预计会出现截然不同的序列（这实际上也是我们想要的）。但我得到的结果是：4,8,11,3,4；5,9,12,3,4；2,3,11,3,4；3,6,12,3,4。请注意，第四和第五个产品预测都是相同的数字，第三个数字只有 +/- 1 个变化。 我用于预测序列的模型方案实际上很简单，每个产品模型都将前一个产品数量作为输入，因此有一个香蕉模型和一个梨模型等。每次运行时，如果模型尚未加载，我会将其加载到内存中（ModelFromJSON 和 LoadWeight）。如果已经加载，我会使用那里的内容。但结果很奇怪，我认为 product_4 模型在输入 4,8,11 和 2,3,11 时会给出截然不同的预测。我的手动“集成”方案有什么问题吗？还是我缺少 Keras 的某种重置功能？我也尝试过每次都从磁盘重新加载模型及其权重，但得到的结果相同。有人知道我应该在这里看什么吗？谢谢！    由   提交  /u/MattCW1701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8fprj/p_getting_same_sequence_prediction_results_with/</guid>
      <pubDate>Wed, 04 Sep 2024 00:26:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 曼城队 SHAP 价值观解析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8evep/p_shap_values_explained_with_manchester_city/</link>
      <description><![CDATA[我用曼城 2021 赛季解释了 SHAP 值  计算球员的 SHAP 值 解释其背后的数学 还在 Youtube 上分享了解释该帖子的视频 用纯 numpy 实现 KernelSHAP   http://mburaksayici.com/blog/2024/09/01/shap-v​​alues-explained.html    提交人    /u/mburaksayici   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8evep/p_shap_values_explained_with_manchester_city/</guid>
      <pubDate>Tue, 03 Sep 2024 23:48:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当今最好的开源、可精细调节、大上下文编码器-解码器模型有哪些？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f88bmp/d_what_are_the_best_open_source_finetunable_large/</link>
      <description><![CDATA[我正在寻找模型推荐来微调翻译任务。 输入序列对相当长，每个最多 1MB，尽管数据集可以截断为仅包含~200kB 序列。这些序列是程序代码（基本上是转译），但我的直觉是，我仍然会受益于基于自然语言训练的基础模型，因为它捕获了一些可以提高性能的基本常识。 我还想从头开始训练相同的模型架构，并将性能与微调版本进行比较以说明这一点。 模型标准：  开放研究许可证（不一定用于商业目的，但这是一个加分项） 基于变压器，具有编码器/解码器支路 数十万个标记的长上下文长度 理想情况下，推理可以在较新的 Mx 芯片 MacBook 上运行（不是必须的） 理想情况下，更新、更先进的模型（不是必须的） 理想情况下可在 Huggingface 中使用（不是必须的）  遗憾的是，基于BERT（例如 DistilBERT）没有足够大的上下文窗口。我一直在研究符合此标准的 XLNet 和 Longformer。两者似乎或多或少都符合要求，但我想探索所有选项。 非常感谢！    提交人    /u/huopak   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f88bmp/d_what_are_the_best_open_source_finetunable_large/</guid>
      <pubDate>Tue, 03 Sep 2024 19:05:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] Tesseract OCR - 有人用它读取 PDF 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f87yfg/p_tesseract_ocr_has_anybody_used_it_for_reading/</link>
      <description><![CDATA[我正在开发一个自定义项目，目标是从 PDF 图像中提取文本（其中文本不可选择，因此需要 OCR），然后处理文本以提取最重要的数据。图像还包含数字，理想情况下应该能够准确识别。 但是，尽管尝试了 Python 中 Tesseract 的各种配置并对图像进行了预处理，但我一直在努力提高模型的准确性。经过几天的尝试，我经常让事情变得更糟。目前，使用默认 Tesseract 设置和细微调整，高质量图像的准确率约为 80-90%，中等质量图像的准确率约为 60%，低质量图像的准确率约为 0%。 我注意到像 DOCSUMO 这样的工具似乎可以实现更高的准确率，但由于目标是创建自己的模型，所以我无法使用它们。 有人做过类似的事情吗？你使用了什么工具或技术？是否可以通过组合各种 OCR 引擎并利用 NLP 进行更好的预测来创建自定义 OCR 模型？你以前建过类似的东西吗？    提交人    /u/AquamarineML   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f87yfg/p_tesseract_ocr_has_anybody_used_it_for_reading/</guid>
      <pubDate>Tue, 03 Sep 2024 18:51:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 针对医疗问题的步态分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f83qsm/p_gait_analysis_for_medical_issues/</link>
      <description><![CDATA[您好 我正在为我的论文项目寻找一些带有 IMU 传感器数据和带有医疗条件的人的标记视频片段的步态数据集。如果没有这样的数据集，收集我自己的数据并模拟异常是否更好。    提交人    /u/DishOk9285   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f83qsm/p_gait_analysis_for_medical_issues/</guid>
      <pubDate>Tue, 03 Sep 2024 16:06:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 代币标准化。为什么不呢？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f81nse/d_token_standardization_why_not/</link>
      <description><![CDATA[与标题基本一致。LayerNorm 删除每个标记特征的平均值，并按标准差缩放，这样每个 N 维嵌入都投影在半径为 sqrt(N) [编辑] 的超圆上，并与全 1 向量正交。对输入标记集进行均值中心化只会删除平均标记，这应该会降低标记相似性并使注意力“更相关”。此外，在使用零均值和单一标准差的输入进行训练时，权重矩阵应该表现良好……有没有论文研究这个简单的变化？LayerNorm 的变体（例如 RMSNorm 和 ScaleNorm）仍然专注于标记操作而不是标记集操作。    提交人    /u/Sad-Razzmatazz-5188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f81nse/d_token_standardization_why_not/</guid>
      <pubDate>Tue, 03 Sep 2024 14:41:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我在 YouTube 上分享机器学习课程和项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f81i1r/p_i_am_sharing_machine_learning_courses_and/</link>
      <description><![CDATA[大家好，我想分享一下我在我的 YouTube 频道上分享的免费课程和项目。我有 200 多个视频，并且创建了用于学习机器学习的播放列表。我将在下面留下播放列表链接，祝大家有美好的一天！ 机器学习教程 -&gt; https://youtube.com/playlist?list=PLTsu3dft3CWhSJh3x5T6jqPWTTg2i6jp1&amp;si=1rZ8PI1J4ShM_9vW 数据科学和机器学习完整课程和项目 -&gt; https://youtube.com/playlist?list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;si=6WUpVwXeAKEs4tB6 数据科学与机器学习项目 -&gt; https://youtube.com/playlist?list=PLTsu3dft3CWg69zbIVUQtFSRx_UV80OOg&amp;si=NR9-6CuPNJiE0sc0    提交人    /u/onurbaltaci   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f81i1r/p_i_am_sharing_machine_learning_courses_and/</guid>
      <pubDate>Tue, 03 Sep 2024 14:35:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于 MLP 的扩散模型有多强大？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f7znps/d_how_powerful_are_diffusion_models_based_on_mlps/</link>
      <description><![CDATA[正如标题所示，我想使用基于扩散的 MLP 来完成腿式机器人运动任务，但大多数论文都使用 UNet 或 transformer 作为去噪模型（离线 RL/模仿学习），不幸的是，这对我来说不是一个选择，因为机器人以 Intel NUC/Jetson Orin 作为其主要计算，而对于稳定的运动，我们需要以 &lt;0.02 秒为单位进行采样。使用 MLP 或其与 RNN 或 CNN 的组合是否可以获得相同的样本质量？ 输入大小：225 或 450 输出大小：225    提交人    /u/Interesting-Weeb-699   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f7znps/d_how_powerful_are_diffusion_models_based_on_mlps/</guid>
      <pubDate>Tue, 03 Sep 2024 13:15:39 GMT</pubDate>
    </item>
    <item>
      <title>低深度学习负载下 GPU 时钟速度异常 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f7zbwl/abnormal_full_gpu_clockspeeds_during_low_deep/</link>
      <description><![CDATA[      我有一张 rtx 4060 ti 16 gb（是的，这不是理想的卡，这是一个单独的争论，而不是当前的问题）并且一直在使用它用于训练 resnet50 图像分类模型，用于我最后一年的项目。我用来演示这个问题的数据集非常小，总共大约有 2800 张 5 类花的图像，epoch 为 50。问题是，最近，在训练阶段甚至推理阶段，gpu 时钟加速到完整的 2790 mhz 并在整个训练过程中保持在该频率，而不是像以前一样随着 GPU 利用率的变化而上下波动。以前，在相同的工作负载下，它曾经在 750 到 1100 mhz 之间徘徊。训练期间这些“卡住的最大时钟”导致比以前更高的功率。我没有之前的确切数字，因为我没有预见到会发生这种行为，但功率大约是之前的两倍。训练后时钟会回落，除了有一次 gpu 时钟在训练期间卡在 2535 mhz 并一直保持在那里，直到我重新启动电脑。我想知道对于这种工作负载，这是否是 GPU 的正常行为，这是否由 GPU 本身根据手头的任务动态调整，是我的错误，还是这里存在更深层次的问题。我非常乐意接受建议、指导和批评。我附上了一些相关的截图。    提交人    /u/Constant_Witness6770   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f7zbwl/abnormal_full_gpu_clockspeeds_during_low_deep/</guid>
      <pubDate>Tue, 03 Sep 2024 13:01:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习/图像处理研究职位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f7w82d/r_research_positions_in_mlimage_processing/</link>
      <description><![CDATA[机器学习/图像处理研究职位 我在马耳他大学空间科学与天文研究所的团队中有两个研究职位，一个是理学硕士奖学金，另一个是研究助理。 其中一个职位空缺是全职研究助理，为期 12 个月，研究射电天文学的机器学习应用。从 2025 年 2 月开始。接受具有学士或硕士学位的申请人。 研究助理职位 此外，我们正在资助同一项目的研究硕士学位。也将于 2025 年 2 月开始。 MSc 奖学金    提交人    /u/dottordrea   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f7w82d/r_research_positions_in_mlimage_processing/</guid>
      <pubDate>Tue, 03 Sep 2024 10:08:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] 聚类用于数据管理和 LLM 改进？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f7vvi8/r_clustering_for_datacuration_and_llm_improvement/</link>
      <description><![CDATA[在最近的一篇论文 https://arxiv.org/pdf/2405.15613 中，研究人员开发了一种新方法来自动整理用于预训练自监督模型的数据集。此方法使用 k 均值聚类的变体，可确保所有类型的数据都得到很好的表示。因此，数据集更加平衡，并可更好地实现自监督模型的下游泛化。 除了平衡数据集之外，还有其他用例吗？其中聚类还用于数据管理吗？在这些情况下，聚类算法的期望行为是什么？任何以 LLMS 为重点的论文参考资料都将非常有帮助！    提交人    /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f7vvi8/r_clustering_for_datacuration_and_llm_improvement/</guid>
      <pubDate>Tue, 03 Sep 2024 09:45:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些好的教科书可以更深入地理解控制理论？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f7orq7/d_what_are_some_good_textbooks_to_get_a_deeper/</link>
      <description><![CDATA[希望了解更多信息，因为它似乎与机器学习非常相关    提交人    /u/rulerofthehell   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f7orq7/d_what_are_some_good_textbooks_to_get_a_deeper/</guid>
      <pubDate>Tue, 03 Sep 2024 02:19:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我将自己的 ViT-Masked 自动编码器实现应用于 Minecraft 图像！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f7ks9p/p_i_applied_my_own_vitmasked_autoencoder/</link>
      <description><![CDATA[      图像馈送到训练好的自动编码器 解码器输出图像，带有一些详细的炉子火焰！ 实现在这里：https://github.com/akmayer/ViTMaskedAutoencoder/ 这只实现了无监督掩蔽和自动编码/解码。我原本计划做一些最后的分类步骤（牛 vs 猪 vs 鸡？）但是懒了，这当然是更炫耀的部分。 非常感谢 u/fferflo 开发 Einx，它使自我注意、在视觉转换器中处理图像以及任何我有高于 3 阶张量的地方都非常方便处理。    提交人    /u/Yelbuzz   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f7ks9p/p_i_applied_my_own_vitmasked_autoencoder/</guid>
      <pubDate>Mon, 02 Sep 2024 23:07:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 01 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>