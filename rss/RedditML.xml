<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 12 Dec 2023 15:14:21 GMT</lastBuildDate>
    <item>
      <title>[P] 不到 3 分钟的基准 CV 培训流程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gn5ry/p_benchmark_cv_training_pipelines_in_less_than_3/</link>
      <description><![CDATA[机器学习社区您好！ 我们构建了一个小型开源库，可能对你们中的一些人有用。&lt; /p&gt; TLDR 它是计算机视觉训练管道的基准工具，可以在 3 分钟内运行，无需依赖外部数据集和复杂的设置。 &lt; p&gt;不是 TLDR 几周前，我们不得不购买新的训练 GPU。经过大量研究，我们找到了最重要的 2 个候选者 - A6000 和 6000 Ada。6000 Ada 是一款较新的 GPU，价格大约是 A6000 的 2 倍。价值百万美元的问题是：在训练计算机视觉模型时它是否也有 2 倍的性能？ 我们在网络上进行了搜索，虽然我们找到了一些基准，但我们并不能 100% 确定结果。当您在 GPU 上花费超过 4000 美元时，您最好 100% 确定 GPU 值得:) 发现的基准测试中的主要问题是：  &lt; li&gt;没有针对更现代的 CV 架构（ViT、SWIN...）的测量 没有针对 UNet 等非分类架构的测量 没有混合精度测量 li&gt; 缺少特定 GPU 上的测量 没有有关测量过程的详细信息：数据加载是基准测试的一部分、基准测试迭代了多少次、他们是否使用了预热步骤以及预热中有多少步骤&lt; /li&gt; 除了 GPU 之外，计算机配置是什么？ 性能如何随着 GPU 的增加而扩展？ 可在本地运行的基准测试的复杂设置 &gt; 基准存储库已过时 混乱的输出格式 未知的软件依赖项：CUDA、cuDNN、pytorch...  使用考虑到这一点，我们决定为 CV 模型创建易于设置和使用的基准工具。另外，它也是开源的，因此您可以自己检查它是如何工作的！ 主要功能：  易于运行，因为一切都是 Docker 化的 仅测量纯训练循环性能 -&gt;无 CPU 和磁盘瓶颈或任何其他开销代码 所有软件依赖项均已知 支持所有主要训练功能：混合精度、多 GPU、DDP 支持主要的 CV 架构：从 VGG 到视觉转换器 许多参数需要配置：批量大小、输入宽度和高度、精度、基准迭代次数、预热步骤... 记录到 CSV 文件  这是第一个版本，因此非常欢迎反馈和拉取请求！ 链接到 github 存储库：https://github.com/tensorpix/benchmarking-cv-models   由   提交/u/barty777  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gn5ry/p_benchmark_cv_training_pipelines_in_less_than_3/</guid>
      <pubDate>Tue, 12 Dec 2023 14:30:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 为什么基于区域的对象检测比分割更好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gmc26/r_why_is_region_based_object_detection_better/</link>
      <description><![CDATA[你好， 我最近读了一些论文，我不太明白为什么要分段（然后根据结果）不如其他两步方法（甚至像 yolo 这样的端到端方法）。直觉上来说，如果你的感受野足够高，你所需要的就是能够区分对象的良好特征。 有人愿意解释一下吗？谢谢！   由   提交/u/Training-Adeptness57  /u/Training-Adeptness57 reddit.com/r/MachineLearning/comments/18gmc26/r_why_is_region_based_object_detection_better/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gmc26/r_why_is_region_based_object_detection_better/</guid>
      <pubDate>Tue, 12 Dec 2023 13:51:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 两塔推荐系统的实际应用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gm5bu/r_two_tower_recommender_systems_in_action/</link>
      <description><![CDATA[双塔推荐系统是推荐系统领域以及机器学习领域中一个重要且有趣的主题。 如果您愿意要了解如何使用 Nvidia 的 Merlin 库构建双塔推荐系统，本文您应该会感兴趣。   由   提交 /u/shawemuc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gm5bu/r_two_tower_recommender_systems_in_action/</guid>
      <pubDate>Tue, 12 Dec 2023 13:42:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 为什么基于区域的对象检测比分割更好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gm2u8/r_why_is_region_based_object_detection_better/</link>
      <description><![CDATA[你好， 我最近读了一些论文，我不太明白为什么要分段（然后根据结果）不如其他两步方法（甚至像 yolo 这样的端到端方法） 有人愿意解释一下吗？谢谢！   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gm2u8/r_why_is_region_based_object_detection_better/</guid>
      <pubDate>Tue, 12 Dec 2023 13:39:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 多目标跟踪帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18glr14/d_help_with_multiobject_tracking/</link>
      <description><![CDATA[我正在尝试安装 mmtracking，但由于它是为 cuda10.1 构建的，因此我在安装它时遇到了一些问题，因为我有 cuda12.1。有什么办法可以做到这一点吗？请建议我可以使用的任何其他库/存储库。我可以使用我能得到的任何帮助！ TIA。   由   提交/u/Dry_Long3157  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18glr14/d_help_with_multiobject_tracking/</guid>
      <pubDate>Tue, 12 Dec 2023 13:22:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM前端集成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gld55/d_llm_frontend_integration/</link>
      <description><![CDATA[大家好， 通过 API 将 LLM 与前端集成有哪些优化？对于第三方端点（例如，openai API）或具有自定义 API 实现的自托管模型（例如，mistral）。 我的关键问题是：向 LLM 发出请求后，通常会出现很长的请求模型产生输出和返回的延迟，这可以通过流选项来缓解，但是还有其他选项吗？例如，浏览器中的预标记、准备好的提交等。 有时 chatgpt 的响应速度似乎非常快，就是这么快，我很感兴趣是否有人知道特定的集成优化。 欢迎任何指点！   由   提交/u/anax4096  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gld55/d_llm_frontend_integration/</guid>
      <pubDate>Tue, 12 Dec 2023 13:01:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我实施了 10 多个 LLM 评估指标，因此您不必这样做</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gkk17/d_i_implemented_10_llm_evaluation_metrics_so_you/</link>
      <description><![CDATA[我已经构建了一段时间的开源项目，您可以在此处查看指标列表：https://docs.confident-ai.com/docs/metrics-introduction，这是存储库：https://github.com/confident-ai/deepeval 让我知道你的想法！   由   提交/u/Ok_Constant_9886   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gkk17/d_i_implemented_10_llm_evaluation_metrics_so_you/</guid>
      <pubDate>Tue, 12 Dec 2023 12:14:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] UniRepLKNet：大内核 CNN 统一多模态，ImageNet 88%，全球天气预报中的 SOTA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gihit/r_unireplknet_largekernel_cnn_unifies_multi/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gihit/r_unireplknet_largekernel_cnn_unifies_multi/</guid>
      <pubDate>Tue, 12 Dec 2023 09:58:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 具有硬件高效训练功能的门控线性注意力变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gglm1/r_gated_linear_attention_transformers_with/</link>
      <description><![CDATA[      论文： https://arxiv.org/abs/2312.06635  代码： https://github.com/sustcsonglin/ated_linear_attention_layer  &lt;强&gt;摘要：  具有线性注意力的Transformers允许高效的并行训练，但可以同时被表示为具有2D（矩阵值）隐藏状态的RNN，从而享受线性（与相对于输出长度）推理复杂性。最近的工作，如 RetNet (Sun et al., 2023) 和 TransNormerLLM (Qin et al., 2023a) 观察到，在加性 RNN 更新规则中添加全局衰减项极大地提高了性能，有时在训练时优于具有 softmax 注意力的标准 Transformer。规模。在这项工作中，我们证明添加数据相关的门控机制可以进一步提高性能。我们推导了这种门控线性注意力层的并行形式，可以实现高效的训练。然而，这种并行形式的简单、数值稳定的实现需要在对数空间中进行广义矩阵乘法以实现数值稳定性，因此无法利用针对标准矩阵乘法进行优化的现代 GPU 上的张量核心。我们开发了并行形式的硬件高效版本，它仍然可以通过序列块上的块并行计算来利用张量核心。中等规模语言建模实验（在 15B 令牌上训练的 340M 参数模型，在 100B 令牌上训练的 1.3B 参数模型）表明，门控线性注意力 (GLA) Transformer 的性能与强大的 LLaMA 架构 Transformer 基线相比具有竞争力（Touvron 等人） ., 2023) 以及 Mamba (Gu &amp; Dao, 2023)，这是最近引入的具有数据依赖状态转换机制的状态空间模型。就训练速度而言，我们基于 Triton 的实现在常规 2048 训练长度设置下的性能与 CUDA 优化的 FlashAttention-2（Dao，2023）相当，而在超过 4096 的较长序列上训练时，其性能优于 FlashAttention-2。  性能 https ://preview.redd.it/h45j3fanht5c1.png?width=1802&amp;format=png&amp;auto=webp&amp;s=329b30428fd790424782132c8454d26c8d0c7808  &amp;# 32；由   提交/u/Emergency_Shoulder27   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gglm1/r_gated_linear_attention_transformers_with/</guid>
      <pubDate>Tue, 12 Dec 2023 07:37:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 开放环境下协作多智能体强化学习进展综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gefag/r_a_survey_of_progress_on_cooperative_multiagent/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.01058 摘要：  多智能体强化学习（MARL）在近年来，在各个领域都取得了进步。具体来说，合作式 MARL 专注于训练一组智能体以合作方式完成单个智能体难以处理的任务。它在路径规划、自动驾驶、主动电压控制、动态算法配置等应用中表现出了巨大的潜力。协同MARL领域的研究热点之一是如何提高系统的协调效率，而研究工作主要在简单、静态、封闭的环境设置中进行。为了促进人工智能在现实世界中的应用，一些研究已经开始探索开放环境中的多智能体协调。这些工作在探索和研究重要因素可能发生变化的环境方面取得了进展。然而主流工作仍缺乏对研究方向的全面回顾。本文从强化学习的概念出发，随后介绍了多智能体系统（MAS）、协作MARL、典型方法和测试环境。然后，我们总结了合作MARL从封闭环境到开放环境的研究工作，提炼出多个研究方向，并介绍了典型工作。最后，我们总结了当前研究的优缺点，并对开放环境下合作MARL的未来发展方向和研究问题进行了展望。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gefag/r_a_survey_of_progress_on_cooperative_multiagent/</guid>
      <pubDate>Tue, 12 Dec 2023 05:18:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 和 ICML 以及类似场所的作者 - 您的数学背景有多深？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g85lx/d_authors_in_neurips_and_icml_and_similar_venues/</link>
      <description><![CDATA[你好， 我正在尝试了解什么样的数学背景准备足以在顶级场所进行可发表的研究. 是微积分、线性代数、工程级概率&amp;统计和优化足够了吗？ 我所说的足够，是指您必须了解的最低限度，并且随着您的学习，您会学到更多东西遇到它们或解决问题（边做边学），而不必先准备必要的背景，然后再深入研究。 我的主要问题是 - 我在什么时候说让我们直接开始研究并即时找出我不知道的事情VS首先学习必要的背景然后继续。我很熟悉 - 不强，但在本科时学过这些课程，但很大程度上忘记了许多重要概念。 数学中的传统方法（如 MathOverflow 人员所建议的）不涉及任何内容缺乏解决数学课本练习以掌握数学的能力。这在很大程度上是不切实际/不可行的，并且将永远阻碍我实际的研究进展。 一个并行问题也是 - 你们如何学习你们不学的数学？不知道吗？你真的像数学系的人一样解决教科书上的问题吗？或者只是理解高层图片和关键中心思想，而不关注围绕它的证明或十几个定理？ 非常感谢来自 ML 领域的作者的任何帮助。  请仅当您是机器学习研究人员或来自学术界时才发帖:)。 非常感谢！   由   提交/u/gobraming5  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g85lx/d_authors_in_neurips_and_icml_and_similar_venues/</guid>
      <pubDate>Mon, 11 Dec 2023 23:54:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] ChatGPT 安全吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g3a45/p_how_safe_is_chatgpt/</link>
      <description><![CDATA[这个周末我花了一些时间玩 LLaMA Guard，这是 Meta 精心调整的 LLaMA-7B 模型，可让您在生成 AI 周围添加护栏。我录制了一个快速演示，展示了它的作用以及如何使用它。 最好的部分是，您可以用它定义自己的“安全分类法”——针对人类之间的安全交互和不安全交互的自定义​​策略（提示）和 AI（响应）。 我想看看与 OpenAI 的 ChatGPT 进行的对话有多“安全”，所以我运行了一堆提示（无害和不恰当的混合体）并要求 LLaMA Guard将交互分为安全/不安全。 我从练习中得到的主要收获：  OpenAI 在为其模型添加护栏方面做得很好。 LLaMA Guard 帮助证实了这一点。 这真的很酷，因为我可能有一套非常具体的策略，我想在模型附带的标准护栏之上执行。 LLaMA Guard 使这成为可能。 这种模型链接 - 将 OpenAI 模型的响应传递到 LLaMA 正变得越来越普遍，我认为在不久的将来我们将拥有更加复杂的管道。它有助于拥有一致的界面来将此多模型管道存储为 aiconfig：https://github.com/lastmile-ai/ aiconfig.  自己尝试一下：  GitHub：https://github.com/lastmile-ai/aiconfig/tree/main/cookbooks/LLaMA-Guard YouTube： https://www.youtube.com/watch?v=XxggqoqIVdg  &lt; /div&gt;  由   提交 /u/sarmad-q   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g3a45/p_how_safe_is_chatgpt/</guid>
      <pubDate>Mon, 11 Dec 2023 20:27:37 GMT</pubDate>
    </item>
    <item>
      <title>节日快乐！这是 100% 免费的大型语言模型路线图！ [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g21av/happy_holidays_here_is_your_100_free_large/</link>
      <description><![CDATA[      感谢您最近几天对我的法学硕士大纲提供反馈的支持。本大纲是关于如何学习有关大型语言模型的最先进内容的路线图。它建立在我在 AT&amp;T 和丰田所做的工作的基础上。它还建立在我在公司之外独立完成的大量工作的基础上。  轮廓很扎实，作为我回馈社区的方式，我将其免费赠送。是的，没有烦人的电子邮件注册。没有噱头。 “免费试用”没有条纹页面。大纲末尾没有要求您购买佛罗里达州的分时度假。它只是一个 zip 文件的链接，其中包含大纲和​​示例代码。  这是它的工作原理。首先，你需要了解Python。如果你不知道，那就在 Google 上查找如何学习 Python。其次，这是一个大纲，您需要查看每个部分，浏览链接，并在继续之前真正消化材料。三是轮廓各部分密集；没有任何废话，您可能需要多次浏览大纲。 该大纲旨在帮助您开始学习 Pytorch，它提供了如何进行分类的代码示例带有句子嵌入，它还有另一个如何在 colab 中运行 Zephyr 的代码示例。这个大纲花了我几天的时间来整理，但它确实代表了过去一年的东西。 此外，这不是一个关于微调语言模型的大纲。这不是关于 Mistral MoE 的讨论，也不是关于运行多个 GPU 的讨论。它是为拥有笔记本电脑并想要学习的人设计的。 此外，将此大纲视为一份礼物。其提供时不提供保证或任何类型的保证。  如果您喜欢这个大纲，我恳求您点击分享按钮并与某人分享。也许这也会对他们有帮助。如果您喜欢这个大纲，请将其作为为世界做好事的动力，并与社区分享您所做的事情。 好的，这是大纲。  https://drive.google.com/file/d /1F9-bTmt5MSclChudLfqZh35EeJhpKaGD/view?usp=drive_link 如果您有任何疑问，请在下面的部分中发表评论。如果问题更具体于您正在做的事情（并且不属于一般对话的一部分），请随时在 Reddit 聊天中向我提问。  ​ https://preview.redd.it/lcq80rwdxp5c1.png?width=549&amp;format=png&amp;auto=webp&amp;s=a111f3101d4e8e232dc7e130b86bda0764dc6eb0  ​ https://preview.redd.it /0sdzc58fxp5c1.png?width=547&amp;format=png&amp;auto=webp&amp;s=96daf4c76f7a913cbba041499429be777ff69ff8   由   提交 /u/whiteowled   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g21av/happy_holidays_here_is_your_100_free_large/</guid>
      <pubDate>Mon, 11 Dec 2023 19:37:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何阅读和理解Einops表达式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g01bv/r_how_to_read_and_understand_einops_expressions/</link>
      <description><![CDATA[这是我目前对 einops 的了解：  einops 代表爱因斯坦启发的运算符号。 符号大致受到爱因斯坦求和（特别是 numpy.einsum 运算）的启发。 h = 高度，w = 宽度，c = 通道（颜色），b = 批次 左侧是输入形状。左侧是输出形状。 括号中的字母相乘。 einops.rearrange 包括转置（轴排列）、重塑（视图）、挤压、取消挤压、堆叠等功能，连接和其他操作。  我不明白：  所有操作元素是什么？我上面遗漏了什么吗？  我如何阅读正在进行的操作？ （即我如何知道图像将被压缩或分割成不同的图像？） 操作中顺序重要吗？ （即‘wh c -&gt; (w h) c’与‘h w c -&gt; (h w) c’不同吗？） 为什么有些元素出现在运算中而另一些则没有？ （即“h w c -&gt; (h w) c”与“h w -&gt; (h w)”不同吗？）  我试图理解的 einops.rearrange 操作示例：   &#39;b f h w c -&gt; (b f) c h w’ ‘(b f) e -&gt; b f e’ ‘br r -&gt; br ()’ ‘b s e -&gt; (b s) e’ ‘b s -&gt; (b s)&#39;  之前的研究参考：  https: //einops.rocks/api/rearrange/ https://openreview.net/pdf ?id=oapKSVM2bcj https://youtu.be/ll1BlfYd4mU?si=BmCVibyEifrZhiXC https://youtu.be/xGy75Pjsqzo?si=GiaxqN4vSX9_uTtL    由   提交 /u/Joe_The_Armadillo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g01bv/r_how_to_read_and_understand_einops_expressions/</guid>
      <pubDate>Mon, 11 Dec 2023 17:59:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>