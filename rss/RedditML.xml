<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Fri, 19 Jul 2024 09:15:23 GMT</lastBuildDate>
    <item>
      <title>[D] NER 印地语的最佳 LLM 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6zdbs/d_best_llm_model_for_ner_hindi/</link>
      <description><![CDATA[我试图将 NER 应用于印地语文章。我既没有好的模型，也没有在训练后获得更好的输出。因此尝试使用 LLM 来实现相同的目的。哪种仅限 CPU 的模型足以为印地语文本提供 NER？    提交人    /u/expiredUserAddress   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6zdbs/d_best_llm_model_for_ner_hindi/</guid>
      <pubDate>Fri, 19 Jul 2024 09:12:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练文本到音频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6yt1f/d_training_text_to_audio_models/</link>
      <description><![CDATA[有人知道为什么文本到音频模型主要通过扩散或流匹配进行训练吗？像 LLM 那样训练它有什么问题吗？你将音频标记为标记并自动回归训练它？    提交人    /u/Internal_War3919   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6yt1f/d_training_text_to_audio_models/</guid>
      <pubDate>Fri, 19 Jul 2024 08:31:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 尝试实现类似 T-Rex2 的管道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6yjf6/d_trying_to_implement_trex2_like_pipeline/</link>
      <description><![CDATA[我正在尝试实现一个类似于 T-Rex2 文章中介绍的管道。 一般来说，文章中描述的架构对我来说很清楚，但在实现时，我面临的事实是很难选择一个主干。本文描述了像 SWIN 变换器这样的主干，它们返回一个特征“金字塔”。随后将其输入到可变形张力模块中，然后输入到 DETR 中。 在此之前，我尝试实现基于 DINO v2 ViT 的少样本检测器。那里的特征图结果非常具有代表性，但由于 ViT 的架构，似乎没有提取特征金字塔的可能性。 我的问题是：您会为这个管道使用什么样的主干，为什么？也许有来自其他骨干网络的一些建议，不一定是 transformers。 我计划在边缘上运行这个（即在 nvidia jetson 上），所以现在我正尝试尽可能多地使用小型模型 接近题外的问题：你怎么看，在边缘上运行像 TRex2 这样的管道是否有可能？    提交人    /u/GreenJest   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6yjf6/d_trying_to_implement_trex2_like_pipeline/</guid>
      <pubDate>Fri, 19 Jul 2024 08:11:40 GMT</pubDate>
    </item>
    <item>
      <title>[D]从承包商转型为可扩展机器学习解决方案提供商</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6xirh/dtransitioning_from_contractor_to_scalable_ml/</link>
      <description><![CDATA[我正在寻求建议，如何将我目前的工作情况转变为更具可扩展性的模式，理想情况下是转向在机器学习领域构建产品或服务。以下是我的一些背景：  当前情况：我主要为一家公司担任承包商。此外，我还为另一家公司提供咨询服务约两年。 经验：我拥有机器学习博士学位（10 年前获得）。我的专长在于深度学习/计算机视觉，最近我一直在研究大型语言模型。 地点：我位于欧洲的一个小国。 以前的职位：在担任现职之前，我是一名高级软件工程师。 当前能力：我最近通过口口相传获得了另一个客户，但我已经满负荷工作了。我一直在周末工作，这在长期内是不可持续的。 收入：收入很可观，但我希望扩大规模，而不仅仅是出售我的时间。 网络：在我担任研究员期间，我与该领域的其他博士和专业人士建立了联系。一位研究员同事很快就会接手我的部分工作量，以帮助解决时间限制问题。 财务稳定性：我有足够的积蓄，可以在没有收入的情况下生活至少 6 个月。  我的最终目标是打造一款产品或服务，但我需要指导，以了解如何获取新客户并扩大业务规模。以下是我有几个具体的问题：  寻找新客户：为定制 ML 解决方案或咨询工作寻找潜在客户的最佳策略是什么？ 扩展运营：如何从单独承包商过渡到可扩展的业务模式？ 构建产品/服务：计划在 ML 领域构建产品或服务时应考虑哪些因素？ 可持续工作负载管理：在扩展规模的同时，有没有关于可持续管理工作负载的提示？  如果您能分享任何建议、个人经历或资源，我们将不胜感激！    提交人    /u/ThickDoctor007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6xirh/dtransitioning_from_contractor_to_scalable_ml/</guid>
      <pubDate>Fri, 19 Jul 2024 06:59:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发布调查论文的场所</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6x7rr/d_venues_for_publishing_survey_papers/</link>
      <description><![CDATA[除了常见的 ACM Computing Surveys、TKDE、TPAMI 之外，我还应该考虑在哪些顶级会场发表调查论文。我正在考虑整理一份高质量但通常不与调查论文联系在一起的会场名单，比如 TMLR。    提交人    /u/SufficientAd3564   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6x7rr/d_venues_for_publishing_survey_papers/</guid>
      <pubDate>Fri, 19 Jul 2024 06:39:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于运行 Vision transformer/LLM 训练的 MacBook</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6wu5p/d_macbook_for_running_vision_transformerllm/</link>
      <description><![CDATA[您好！我打算买一台新的 MacBook，因为我的 Surface Pro 太旧了。我计划使用 Pytorch 来训练视觉转换器、VLM 和较小的 LLM，以及偶尔的照片/视频编辑（基本内容）。 我不想在高端 MacBook Pro 上花太多钱，除非它真的足以满足我的 DNN 训练需求。一种选择是：购买 MacBook Air 或基本款 MacBook Pro，依靠 GPU 进行代码开发，并支付云 GPU/hugging face 费用来运行训练。选项 2：投资高端 MacBook Pro。我想知道选项 2 是否足以在小型 VLM 和小型 LLM 上工作。两者的优缺点是什么，您会推荐哪些规格？ 提前谢谢大家，非常感谢您的帮助！    提交人    /u/Realistic-Gear-4934   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6wu5p/d_macbook_for_running_vision_transformerllm/</guid>
      <pubDate>Fri, 19 Jul 2024 06:14:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] Redis 作为矢量数据库。有什么个人经历吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6rhjx/d_redis_as_vector_database_any_personal/</link>
      <description><![CDATA[我们正在重新审视我们的 AI 平台/堆栈，并试图找出存储嵌入和向量搜索的最佳选择。我们为金融服务领域的客户提供服务，宁愿不依赖初创公司的产品，而更愿意选择更成熟的供应商。我们正在考虑将 redis 作为一种选择。似乎 Redis 具有良好的性能（至少在更传统的数据库中是最好的）。我没有注意到 pinecone 和 Redis 之间的设置时间有很大差异。有人用过 Redis 作为向量数据库吗？你喜欢/不喜欢什么？只对个人经历感兴趣，而不是供应商的宣传    提交人    /u/Different-Use9841   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6rhjx/d_redis_as_vector_database_any_personal/</guid>
      <pubDate>Fri, 19 Jul 2024 01:11:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 API 文档缓解代码 LLM 幻觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6o2gi/r_on_mitigating_code_llm_hallucinations_with_api/</link>
      <description><![CDATA[      TL;DR：我们引入了一个新的基准 CloudAPIBench 来测量 API 幻觉，并使用Documenation Augmented Generation （DAG） 来优化此基准测试的性能。  我们引入了 CloudAPIBench，这是一个衡量 API 幻觉并为公共 API 提供基于频率的注释的基准。 我们的研究表明，诸如 GPT-4o 之类的代码 LLM 在处理低频 API 时遇到困难，仅实现了 38.58% 的有效调用，而使用 DAG 后，这一比例提高到了 47.94%。但是，当使用次优检索器时，DAG 会对高频 API 产生负面影响。 为了解决这个问题，我们建议根据 API 索引或置信度分数有选择地触发 DAG，从而将 GPT-4o 在 CloudAPIBench 上的整体 API 调用正确性提高 8.20%。  该论文还包括一些有趣的见解，例如 API 文档的哪些部分在 DAG 期间最有用以及如何执行选择性检索，例如，使用预测的 API 名称令牌的置信度分数。 CloudAPIBench 和论文的代码将很快发布！ Arxiv：链接； Twitter 帖子：链接 作为作者之一，如果您对我们的工作有任何问题或意见，我很乐意参与讨论。谢谢！ DAG 概述。 结果摘要。    提交人    /u/nihaljn   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6o2gi/r_on_mitigating_code_llm_hallucinations_with_api/</guid>
      <pubDate>Thu, 18 Jul 2024 22:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 拆分前后编码之间的差异</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6niua/d_differences_between_encoding_before_and_after/</link>
      <description><![CDATA[在机器学习中处理分类数据时，编码过程是将分类特征转换为适合建模的格式的关键步骤。了解应用编码和拆分数据集的顺序如何影响模型的性能和数据表示的完整性至关重要。哪种方法更可取：在将数据集拆分为训练集和测试集之前还是之后应用编码？    提交人    /u/Appropriate-Wave-252   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6niua/d_differences_between_encoding_before_and_after/</guid>
      <pubDate>Thu, 18 Jul 2024 22:03:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 预测性维护的机器学习——最佳实践？过时的方法？该做什么和不该做什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6ix0q/d_ml_for_predictive_maintenance_best_practices/</link>
      <description><![CDATA[我在很多搜索中都看到了“相似性学习”，但我想我会在这里问-- 基本上，是否有人使用传感器数据来完成预测设备故障的任务。寻求以下方面的建议：  异常检测和故障预测的最佳模型 处理来自多个传感器的时间序列数据 估计剩余使用寿命 结合不同 ML 技术的有效方法  有类似项目的经验吗？什么方法有效？    提交人    /u/LyPreto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6ix0q/d_ml_for_predictive_maintenance_best_practices/</guid>
      <pubDate>Thu, 18 Jul 2024 18:51:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] NER 的最佳方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6i9dh/d_best_approach_to_ner/</link>
      <description><![CDATA[我认为自己在这个领域有点菜鸟，所以我希望从这篇文章中学习和理解得更好。  我编写了一个遍历文件系统并将文件传递给 Apache tika 的 Python 应用程序，Apache tika 将其支持的扩展中的内容传递给最终会找到 NER 的函数，该函数基本上用于识别和分类文件内容。 我使用了 spacey，但发现其标记实体输出的准确性不如我希望的那样准确，我理解可以自定义训练模型以提高准确性，但如果该工具要在不同的文件系统和不同的结构化用户数据上使用它，则可能意味着重新训练模型以适应每个用例。  然后，我尝试使用来自 ollama 的 LLM 和一个 Python 库向 ollama 服务器发出请求，我尝试了几个模型，mistral 和 orca-mini 和设计一个提示以在传递的内容中查找特定的 NER，并输出找到的实体的响应，这样我就可以得到与 spacy 类似的结果。  我发现准确度要好得多，但完成所需的时间令人震惊。 例如：我使用 Faker 在 pdf、CSV、RTF、DOCX 等中创建随机数据……用于测试目的，spacy 能够在几秒钟内处理 16 个 20 KB 的文件，上述 LLM 方法使用 mistral 花费 26 分钟，在 orca mini 上花费 15 分钟。  我理解 LLM 模型要大得多，需要更多的计算，而运行 spacy 和 NER 任务可能超出了它们的能力，但我正在努力寻找平衡。一种具有实际性能输出的通用 NER 方法。 还有其他项目或经过训练的模型可能适合这项任务吗？还是我做错了？    提交人    /u/Hungry-Jackfruit-265   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6i9dh/d_best_approach_to_ner/</guid>
      <pubDate>Thu, 18 Jul 2024 18:25:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] ML 系统设计：450 个值得学习的案例研究（Airtable 数据库）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6gdsk/p_ml_system_design_450_case_studies_to_learn_from/</link>
      <description><![CDATA[大家好！想分享来自 100 多家公司的 450 个 ML 用例的数据库链接，这些用例详细介绍了 ML 和 LLM 系统设计。您可以按行业或 ML 用例进行筛选。 如果这里有人着手设计 ML 系统，我希望你会发现它很有用！ 数据库链接：https://www.evidentlyai.com/ml-system-design  免责声明：我是 Evidently 背后的团队成员，这是一个开源 ML 和 LLM 可观察性框架。我们整理了这个数据库。    提交人    /u/dmalyugina   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6gdsk/p_ml_system_design_450_case_studies_to_learn_from/</guid>
      <pubDate>Thu, 18 Jul 2024 17:01:17 GMT</pubDate>
    </item>
    <item>
      <title>[N] Fish Speech 1.3 更新：增强稳定性、情感和语音克隆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6g122/n_fish_speech_13_update_enhanced_stability/</link>
      <description><![CDATA[我们很高兴地宣布，Fish Speech 1.3 现在提供了增强的稳定性和情感，并且只需 10 秒 的音频提示即可克隆任何人的声音！作为开源社区的坚定倡导者，我们今天开源了 Fish Speech 1.2 SFT，并引入了自动重新排名系统。敬请期待，因为我们很快就会开源 Fish Speech 1.3！我们期待收到您的反馈。 Playground（DEMO）：http://fish.audio GitHub：fishaudio/fish-speech    提交人    /u/lengyue233   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6g122/n_fish_speech_13_update_enhanced_stability/</guid>
      <pubDate>Thu, 18 Jul 2024 16:46:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 训练 LLM 引用预训练数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6fxgj/r_training_llms_to_cite_the_pretraining_data/</link>
      <description><![CDATA[我们的工作被 COLM 接受，并认为值得在此分享： &quot;源感知训练实现语言模型中的知识归因&quot; TL;DR: 通常，LLM 在训练期间会学习很多东西，但不记得从哪里学到的。本文是关于教 LLM 从预训练数据中引用他们的知识来源。这可以使模型更透明、更容易理解和更可靠。我们提出了一个两步过程：1) 使用文档 ID 注入进行预训练和 2) 指令调整。第一阶段教模型将知识片段链接到特定的预训练文档。第二阶段教模型如何在生成答案时引用这些文档。 🔗 论文：https://arxiv.org/abs/2404.01019 代码：https://github.com/mukhal/intrinsic-source-citation    提交人    /u/moyle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6fxgj/r_training_llms_to_cite_the_pretraining_data/</guid>
      <pubDate>Thu, 18 Jul 2024 16:43:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>