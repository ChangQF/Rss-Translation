<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 05 Mar 2024 15:13:47 GMT</lastBuildDate>
    <item>
      <title>[D] 高级总监 30 分钟的面试（第二轮）意味着什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b76v98/d_what_does_a_30min_interview_with_senior/</link>
      <description><![CDATA[我已经接受了主管及其团队的采访，他们问了我一些有关 ML/DS 的技术和行为问题。现在，我即将接受高级总监的采访。当我问主管我应该从这次采访中期待什么时，他说这将是相同的 - 即技术和行为问题。但面试只有30分钟... 这是我第一次接受技术职位的多排面试。我是否应该以与第一次面试完全相同的方式准备与高级总监进行的 30 分钟面试（即温习我对问题的行为和技术答案）？还有其他建议/提示吗？   由   提交/u/orina_1  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b76v98/d_what_does_a_30min_interview_with_senior/</guid>
      <pubDate>Tue, 05 Mar 2024 14:44:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] David MacKay 谈随机位的昂贵</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b75loi/d_david_mackay_on_random_bits_being_expensive/</link>
      <description><![CDATA[所以我正在阅读《信息论、推理和学习算法》 （顺便说一下，对于没有听说过它的人来说，这是一本很棒的书）我偶然发现了这段话：  算术模型保证使用几乎尽可能少的随机位做出选择——在随机数昂贵的社区中这是一个重要的点！ [这不是一个玩笑。大量资金花费在软件和硬件中生成随机位。而且随机数很有价值。]  Ch 6.3，第 118 页  这本书出版于 2003 年。我可以想象随机数如何在互联网和现代计算时代出现之前，人们不得不扔硬币，获得这种技术的成本可能会很高，但我认为到 2000 年代初就不会出现这种情况，不是吗？他们没有“随机导入”功能吗？那时，或者他是在说随机数字是有价值的，而不是伪随机数字。如果是这样，它们至今仍然有价值/昂贵吗？因为我从来不需要购买“正品”。之前的随机数。   由   提交/u/new_name_who_dis_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b75loi/d_david_mackay_on_random_bits_being_expensive/</guid>
      <pubDate>Tue, 05 Mar 2024 13:48:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 对于推理和世界模型等术语，该领域是否有公认的定义？我看过很多关于这些主题的论文，但很多争论似乎都是语义学的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b757ji/d_are_there_accepted_definitions_in_the_field_for/</link>
      <description><![CDATA[此类论文的一个例子是他们使用探针来查找黑白棋游戏的棋盘状态 https://arxiv.org/pdf/2210.13382.pdf 有很多论文使用了一些相当有声望的术语研究组织，但我没有看到任何可接受的定义。 例如，奥赛罗论文和 wes gurnee/max tegmark 论文基本上似乎依赖于这样的假设：“如果你可以从隐藏状态的线性（或足够简单）探测中重建外部状态，则该模型具有世界模型”。作为一个定义，这似乎是合理的，但我不确定这是否是公认的事情。   由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b757ji/d_are_there_accepted_definitions_in_the_field_for/</guid>
      <pubDate>Tue, 05 Mar 2024 13:29:20 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]RAG——如何处理数值数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7461k/discussion_rag_how_to_deal_with_numerical_data/</link>
      <description><![CDATA[我有一个汽车标记公司数据。我正在 llama 索引中为不同的汽车模型创建块并使用矢量存储索引，当被问到问题时它会给出不错的输出。当我提出诸如建议低于 $xyz 的汽车型号之类的问题时，它会失败。我尝试过很多嵌入器，但问题是它的语言模型似乎没有数量/价格的感觉，并且它与更昂贵的模型相匹配。一般来说，遇到这样的情况你会如何处理。你使用 llama 索引工具来处理数字问题吗？如果需要更多详细信息，请指导并告诉我   由   提交/u/International-Mine91   reddit.com/r/MachineLearning/comments/1b7461k/discussion_rag_how_to_deal_with_numerical_data/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7461k/discussion_rag_how_to_deal_with_numerical_data/</guid>
      <pubDate>Tue, 05 Mar 2024 12:35:52 GMT</pubDate>
    </item>
    <item>
      <title>【研究】通过采样优化代码生成中的任务解决效率：寻求科学方法指导</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b73mpt/research_optimizing_task_solving_efficiency_in/</link>
      <description><![CDATA[大家好， 我正在研究一个优化问题，以提高代码生成中的任务解决效率，重点关注温度- 受控样本生成。目标很简单：最大限度地提高解决的任务数量，同时最大限度地减少资源使用（生成的样本）。 这是我的流程的要点：  从 100 个编码任务开始。 在不同温度（从 0.2 开始）下生成样本来解决这些任务。 针对预定义的单元测试执行样本，这些测试是数据集的一部分( humanEval ) 经过初步试验，一些任务仍未解决。然后我面临一个选择：在当前温度下添加更多样本，或者尝试使用新样本更高的温度，每个选项都会产生不同的“成本”。  决策示例:  70 个任务在温度 0.2 下用 1 个样本解决；还剩 30 个。 选项 A：在 0.2 处再添加 1 个样本，成本 = 30 个样本，解决 1 个任务。 选项 B：在 0.4 处生成 4 个样本，成本 = 120 个样本，解决 2 个任务。 考虑到比率（A 为 1/30，B 为 1/60），我选择 A 以获得更高的效率。  挑战：这不仅需要在相同温度下进行比较，还需要在不同样本量的温度之间进行比较，以找到完成剩余任务的最有效路径。 我的问题：什么科学方法或理论最能支持这种动态的、效率驱动的决策？对有效比较和优化这些效率比的策略特别感兴趣。 感谢您可能拥有的任何见解或指导！   由   提交/u/phimer95  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b73mpt/research_optimizing_task_solving_efficiency_in/</guid>
      <pubDate>Tue, 05 Mar 2024 12:05:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] lstm 网络是互易的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b73kpy/d_are_lstm_networks_reciprocal/</link>
      <description><![CDATA[只是我在考虑 rn 的一个愚蠢问题... 假设你有一个包含几层的 lstm 网络最后是一个全连接层，您可以在其中对传感器数据进行推理（回归）。 这种神经网络是互易的吗？假设这是一个回归任务并且输入形状 = 输出形状，您能否互换输入和输出并获得相同的结果？   由   提交/u/gmgm0101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b73kpy/d_are_lstm_networks_reciprocal/</guid>
      <pubDate>Tue, 05 Mar 2024 12:01:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人员检测的开放模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b73br3/d_open_model_for_person_detection/</link>
      <description><![CDATA[我正在做一个项目，我想使用来自 4 个视频流的边界框实时检测人员。视频流均捕获相同的场景/区域，但来自不同类型的摄像机：常规视频、低光摄像机和两个红外摄像机。  我应该如何进行这个项目？  我的想法是从一个开放模型开始，对人员检测进行预先训练（来自常规视频输入），然后扩展和修改模型以从其他摄像机获取输入。然后用我自己的数据继续训练。这样的模型是否存在？ 此任务使用什么样的模型？架构、输出等。我的输入是 4 个视频流，输出应该是检测到的人周围的 0 个、1 个或多个边界框。    由   提交/u/gi_beelzebub   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b73br3/d_open_model_for_person_detection/</guid>
      <pubDate>Tue, 05 Mar 2024 11:46:56 GMT</pubDate>
    </item>
    <item>
      <title>[N] Nvidia 禁止像 ZLUDA 这样的翻译层</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b70ubo/n_nvidia_bans_translation_layers_like_zluda/</link>
      <description><![CDATA[最近我在这个子论坛上看到了帖子，人们讨论了使用非 Nvidia GPU 进行机器学习。例如，ZLUDA 最近因在 AMD GPU 上启用 CUDA 应用程序而受到关注。现在 Nvidia 不喜欢这种情况，并禁止在 CUDA 11.6 及更高版本中使用转换层。 https://www.tomshardware.com/pc-components/gpus/nvidia-bans-using-translation-layers-for -cuda-software-to-run-on-other-chips-new-restriction-apparently-targets-zluda-and-some-chinese-gpu-makers#:\~:text=Nvidia%20has%20banned%20running%20CUDA ,system%20during%20the%20installation%20process。   由   提交/u/_d0s_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b70ubo/n_nvidia_bans_translation_layers_like_zluda/</guid>
      <pubDate>Tue, 05 Mar 2024 09:00:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习研究项目的项目管理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b6zltt/d_project_management_for_ml_reseach_projects/</link>
      <description><![CDATA[最近，我的任务是开展一个基于 ML CV 的项目，该项目需要深入研究。这不是一个普遍解决的问题，所以我们必须做大量的研究和实验。不幸的是，这与我们的 Scrum Master/项目经理不太一致，因为他们习惯于软件工程项目，其中有预定义的里程碑、史诗、任务、估计等。这是一个巨大的问题，因为很难提前计划我们会做什么，因为我们需要大量探索。 研究机构如何管理和跟踪项目？有人致力于将研发项目与公司项目管理相适应吗？谁能提供我可以遵循的任何指导方针或参考资料，以便我可以提出一种项目经理可以遵循并评估我们进度的方法？   由   提交 /u/silently--here   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b6zltt/d_project_management_for_ml_reseach_projects/</guid>
      <pubDate>Tue, 05 Mar 2024 07:34:01 GMT</pubDate>
    </item>
    <item>
      <title>[R]《Road to Sora》——论文阅读列表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b6yb1x/r_road_to_sora_paper_reading_list/</link>
      <description><![CDATA[大家好， 周五我们一直在深入研究我们纸质俱乐部的 Sora 技术报告，并认为这会很好要获得背景论文的阅读列表，需要充分了解该技术报告中发生的所有内容 - 每篇文章都对其将用于的管道部分进行一些描述（或以前的最先进技术）评论中引用）。 我们将挑选一些顶级论文，并在接下来的周五将它们作为一个小组进行研究，所以如果您愿意，请加入我们！ Zoom 的时间为周五上午 10 点（太平洋标准时间）。 论文阅读列表： https://www.oxen.ai/blog/road-to-sora-reading-list 技术报告： https://openai.com/research/video- Generation-models-as-world-simulators  加入纸俱乐部： https://lu.ma/oxenbookclub   由   提交 /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b6yb1x/r_road_to_sora_paper_reading_list/</guid>
      <pubDate>Tue, 05 Mar 2024 06:11:49 GMT</pubDate>
    </item>
    <item>
      <title>[N] LoRA 用于纠正罗马尼亚语变音符号开源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b6xce2/n_lora_for_correcting_romanian_diacritics_open/</link>
      <description><![CDATA[https:/ /twitter.com/adi_punga/status/1764867929110110388?t=yA2Ufdcbzt16Dv8414wNow&amp;s=19   由   提交/u/c0d3l1v3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b6xce2/n_lora_for_correcting_romanian_diacritics_open/</guid>
      <pubDate>Tue, 05 Mar 2024 05:18:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] 是否可以在不进行大量计算的情况下写一篇论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b6tjil/r_is_it_possible_to_write_a_paper_without_large/</link>
      <description><![CDATA[我正在独立学习机器学习，希望将来能写一篇论文，但是我没有任何强大的计算能力我的桌面 GPU 是 2070 super。如果没有大量的计算，最近的突破似乎是无法实现的。那么这是否可能，或者是否有任何领域可以在没有昂贵 GPU 的情况下发表论文？   由   提交 /u/DisciplinedPenguin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b6tjil/r_is_it_possible_to_write_a_paper_without_large/</guid>
      <pubDate>Tue, 05 Mar 2024 02:12:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] GLU（门控线性单元）为什么起作用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b6ggpz/d_why_do_glus_gated_linear_units_work/</link>
      <description><![CDATA[如今，GLU 变体，例如 SwiGLU，在法学硕士中经常使用。 但是论文“GLU Variants”改进变压器” （https://arxiv.org/pdf/2002.05202.pdf），只是说“我们不提供任何解释”为什么这些架构看起来有效；我们将他们的成功和其他一切一样，归功于神圣的仁慈。” 我还发现原始 GLU 论文中的解释并不令人满意。他们说它有更清晰的梯度，但我认为这个问题已经通过残差连接解决了。 有人对 GLU 成功的原因有任何理论甚至直观的解释吗？ 我的思考过程是，它允许每个令牌学习自己独有的转换，这提高了 MLP 的表达能力，但我不确定这是否合理。 编辑：The Falcon技术报告（链接在此：https://arxiv.org/pdf/2311.16867.pdf，第 14 页）讨论了 GLU使用它是因为它增加了 50% 的参数计数，表示：“在缩放方面，GLU 激活也是首选，因为它们增加了 MLP 的大小（将第一层加倍），将更多计算转向简单的矩阵乘法。 ” 但是，我认为我并不确信情况确实如此；毕竟，为什么不能将 MLP 隐藏层中的神经元数量增加 50%，这具有相同的内存成本和参数增加。   由   提交/u/cofapie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b6ggpz/d_why_do_glus_gated_linear_units_work/</guid>
      <pubDate>Mon, 04 Mar 2024 17:18:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 介绍下一代克劳德</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b6ea53/r_introducing_the_next_generation_of_claude/</link>
      <description><![CDATA[https://www.anthropic .com/news/claude-3-family 今天，我们宣布推出 Claude 3 模型系列，它为广泛的认知任务树立了新的行业基准。该系列包括三种最先进的型号（按功能升序排列）：Claude 3 Haiku、Claude 3 Sonnet 和 Claude 3 Opus。每个后续型号都提供了越来越强大的性能，允许用户为其特定应用选择智能、速度和成本之间的最佳平衡。 Opus 是我们最智能的型号，在大多数常见评估中均优于同类产品人工智能系统的基准，包括本科水平专家知识（MMLU）、研究生水平专家推理（GPQA）、基础数学（GSM8K）等。它在复杂任务上表现出接近人类水平的理解力和流畅性，引领通用智能的前沿。   由   提交 /u/RobbinDeBank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b6ea53/r_introducing_the_next_generation_of_claude/</guid>
      <pubDate>Mon, 04 Mar 2024 15:52:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>