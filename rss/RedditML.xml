<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 15 Mar 2024 03:17:16 GMT</lastBuildDate>
    <item>
      <title>[D] 您如何评价您的 RAG 应用程序？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bf3ngh/d_how_do_you_evaluate_your_rag_apps/</link>
      <description><![CDATA[我创建了一个 YouTube 视频，用于自动评估 RAG 应用程序。 我在为此编写代码时遇到的问题之一是我无法访问 gpt4 模型来判断 llm。所以我用gpt3.5进行了评估。用于计算相关性和忠实度等指标的模型的一般选择是什么。 使用 RAGAS，我收到了 429 个过多的请求。因此，我实现了自己的代码，该代码运行缓慢，以避免 429 错误。 https://www. youtube.com/watch?v=r0_O0IogbKo   由   提交/u/infinite-Joy  /u/infinite-Joy  reddit.com/r/MachineLearning/comments/1bf3ngh/d_how_do_you_evaluate_your_rag_apps/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bf3ngh/d_how_do_you_evaluate_your_rag_apps/</guid>
      <pubDate>Fri, 15 Mar 2024 02:46:00 GMT</pubDate>
    </item>
    <item>
      <title>[D]工业博士的几个问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bf1x7y/d_several_questions_on_phd_for_industry/</link>
      <description><![CDATA[我目前是一名大三学生，正在攻读计算机科学学士学位。我正在做一项希望发表的研究，我发现我真的很喜欢机器学习。我的教授正在推动我获得博士学位，并相信我有竞争力，所以我有以下问题：  我打算在工业界工作（希望但可能不太可能）最新的我正在制作模型的机器学习技术。我需要为此获得博士学位吗？ 我听说只有当您喜欢做研究时才应该获得博士学位。我喜欢新想法和实验，但不喜欢写论文。这还算吗？ 机器学习在工业领域的利润有多大？我听说这些数字被疯狂夸大，而且往往与传统的 SWE 职位水平相同或更低。  ​   由   提交/u/DisapointingLO   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bf1x7y/d_several_questions_on_phd_for_industry/</guid>
      <pubDate>Fri, 15 Mar 2024 01:21:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT-4 在算法难题中失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bezmdu/d_gpt4_fails_in_algorithmic_puzzles/</link>
      <description><![CDATA[摘要： 我们介绍了在视觉问答的背景下解决多模式谜题的新颖任务。我们提出了一个新的数据集 AlgoPuzzleVQA，旨在挑战和评估多模态语言模型解决算法难题的能力，这些算法难题需要视觉理解、语言理解和复杂的算法推理。我们创建的谜题涵盖了各种数学和算法主题，例如布尔逻辑、组合学、图论、优化、搜索等，旨在评估视觉数据解释和算法解决问题技能之间的差距。该数据集是根据人类编写的代码自动生成的。我们所有的谜题都有精确的解决方案，可以从算法中找到，无需繁琐的人工计算。它确保我们的数据集可以在推理复杂性和数据集大小方面任意扩展。我们的调查表明，GPT4V 和 Gemini 等大型语言模型 (LLM) 在解谜任务中表现有限。我们发现，在针对大量谜题的多项选择问答设置中，他们的表现几乎是随机的。研究结果强调了整合视觉、语言和算法知识来解决复杂推理问题的挑战。 https ://github.com/declare-lab/LLM-PuzzleTest   由   提交 /u/sgpfc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bezmdu/d_gpt4_fails_in_algorithmic_puzzles/</guid>
      <pubDate>Thu, 14 Mar 2024 23:36:25 GMT</pubDate>
    </item>
    <item>
      <title>[D]medium和tds的最佳替代品是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1beyrf8/d_what_are_the_best_substitute_of_medium_and_tds/</link>
      <description><![CDATA[您好，我是机器学习和数据科学的忠实粉丝和实践者，我从数据科学中学到了很多东西，但最近觉得质量减少并且无法找到好的来源来获得更多的技术知识或深度学习或机器学习的端到端高级项目，有什么建议吗？谢谢   由   提交 /u/WASSIDI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1beyrf8/d_what_are_the_best_substitute_of_medium_and_tds/</guid>
      <pubDate>Thu, 14 Mar 2024 22:58:51 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch Lightning 吞吐量监视器 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bevp6d/pytorch_lightning_throughputmonitor_p/</link>
      <description><![CDATA[大家好， 我有这个 PytorchLightning 代码，我想添加 ThroughputMonitor，但我找不到如何添加。 你能建议如何添加它吗？  def main(): model = CIFAR10Model() logger = TensorBoardLogger(&quot;logs/tb_logs&quot;, name=&quot;resnet18_ciphar10_lightning&quot;) profiler = PyTorchProfiler(dirpath=&quot;logs/profiler_logs&quot;) , filename=“perf-logs”) trainer = Trainer( max_epochs=args.epochs, Accelerator=“cpu”, devices=16, Strategy=“ddp”, logger=logger, enable_progress_bar=True, profiler=profiler, num_nodes=3、log_every_n_steps=1、callbacks=[DeviceStatsMonitor()、EarlyStopping(...)] )  ​   由   提交/u/POC-545  /u/POC-545  reddit.com/r/MachineLearning/comments/1bevp6d/pytorch_lightning_throughputmonitor_p/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bevp6d/pytorch_lightning_throughputmonitor_p/</guid>
      <pubDate>Thu, 14 Mar 2024 20:51:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 序列模型内的内存</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bes2n5/d_memory_inside_sequence_models/</link>
      <description><![CDATA[我正在尝试更深入地了解 RNN（及其变体）和 Transformer 中的内存概念。 除了普通 RNN、GRU 和 LSTM 之间的架构差异之外，内存基本上是通过某些数学函数处理的输入序列，并以顺序方式作为下一个时间步骤（沿着输入 Xt）的输入，作为先验表示的数据。  从这个技术角度来看，在计算以及梯度消失和爆炸方面，内存似乎受到输入序列的长度和训练过程的难度的限制。 LSTM 和 GRU 的门控机制已经得到了有效的改进，以缓解上述问题。  我不久前开始阅读并致力于理解 Transformer - 3 周，我掌握了它的重要性、影响、范式转变时刻等等，我明白了为什么它在法学硕士中如此成功，但是老实说，有些事情似乎并不能完全证明这一点。通过编码器-解码器堆栈和其他所有内容中的多头注意力和并行化解决了序列长度瓶颈。这很有趣，实际上很神奇。也许我错了，没有完全理解。 我很难将记忆想象成与改进网络内处理信息的方式不同的东西。我读到的每一篇开创性的论文都讨论了这些架构挑战以及它们如何改善内存和计算约束的情况，这些都非常有效地让我只抽象地思考表示学习。  我的印象是，我们还没有那么接近有效地理解和设计“人工”记忆，因为它是来自我们人类的生物学灵感。 但我计划继续更多地研究风景我似乎只触及了表面。也许视觉是理解记忆的关键，超越了在可互换使用语言和视觉的统一系统中通过图像和视频进行推理的能力。 还有哪些其他论文或来源可以以更具视觉吸引力和有趣的方式处理记忆。 ？ 我还想指出，我只是一名本科生，自学成才，根本不从事任何 STEM 工作。    由   提交 /u/Sinestro101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bes2n5/d_memory_inside_sequence_models/</guid>
      <pubDate>Thu, 14 Mar 2024 18:23:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 加密数据训练模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1berfdd/p_training_models_on_encrypted_data/</link>
      <description><![CDATA[您好， 我们最近发布了一种在加密数据上训练机器学习模型的方法。这一切都可以通过 concrete-ml 中的数据科学友好的 API 获得。您可以在  阅读完整的博客文章p&gt; https://www.zama.ai /post/training-predictive-models-on-加密数据-全同态加密。 对于实现细节：我们提取 PyTorch 训练会话的 onnx 图（目前）逻辑回归）并将其转换为 numpy 函数。然后在 concrete 的帮助下将其转变为 FHE 电路。该电路具有对加密数据进行训练的能力！ 如果您想尝试一下，可以访问 我们所做的示例笔记本。 希望听到您的所有反馈并回答您可能有的任何问题！ &gt;   由   提交 /u/strojax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1berfdd/p_training_models_on_encrypted_data/</guid>
      <pubDate>Thu, 14 Mar 2024 17:56:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 条件生成图像的 FID</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1berb77/r_fid_of_conditionally_generated_images/</link>
      <description><![CDATA[大家好！ 我对有条件生成的样本的 FID 计算有疑问。大多数研究论文即使在类条件生成上也只提供单个 FID 分数，而它们应该根据类 FID 给出。 我错了吗？ 请告诉我.谢谢   由   提交 /u/Independent-King-320   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1berb77/r_fid_of_conditionally_generated_images/</guid>
      <pubDate>Thu, 14 Mar 2024 17:51:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 欧盟法案刚刚通过。意见？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bem4q1/d_eu_act_just_passedopinion/</link>
      <description><![CDATA[欧盟法案刚刚通过，将于今年晚些时候生效，您对此事有何看法？ https://www.msn.com/en-us/money/other/europes-world-first-ai-rules-are-set-for-final-approval-heres-what-happens-next/ar -BB1jNGef   由   提交/u/pythonprogrammer64  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bem4q1/d_eu_act_just_passedopinion/</guid>
      <pubDate>Thu, 14 Mar 2024 14:12:56 GMT</pubDate>
    </item>
    <item>
      <title>[N] 哎呀...... OpenAI CTO Mira Murati 关于哪些数据被用来训练 Sora</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1belin7/n_ooops_openai_cto_mira_murati_on_which_data_was/</link>
      <description><![CDATA[是只有我一个人还是有大规模的诉讼即将到来？ https://twitter.com/tsarnick/status/1768021821595726254   由   提交/u/pg860  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1belin7/n_ooops_openai_cto_mira_murati_on_which_data_was/</guid>
      <pubDate>Thu, 14 Mar 2024 13:45:10 GMT</pubDate>
    </item>
    <item>
      <title>TryOnDiffusion：两个 UNet 的故事 - 非官方 PyTorch 实现 [R] [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1beifsk/tryondiffusion_a_tale_of_two_unets_unofficial/</link>
      <description><![CDATA[您好， 我最近发布了 Google 的 TryOnDiffusion 论文。我训练它的资源有限，但我认为我对它进行了足够的实验，以验证它基本上是正确的（自述文件中详细介绍了实验设置） 代码是 MIT 许可证，因此完全开源。链接 - https://github.com/fashn-AI/tryondiffusion 我希望它可以帮助这里的某人。 祝一切顺利，   由   提交 /u/JYP_Scouter   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1beifsk/tryondiffusion_a_tale_of_two_unets_unofficial/</guid>
      <pubDate>Thu, 14 Mar 2024 10:53:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] Chronos：学习时间序列的语言</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1behp7t/r_chronos_learning_the_language_of_time_series/</link>
      <description><![CDATA[     &lt; td&gt; 论文：https://arxiv.org/abs /2403.07815 代码：https://github.com/amazon-science/chronos -预测 模型权重：https://huggingface.co/collections/ amazon/chronos-models-65f1791d630a8d57cb718444 摘要：  我们介绍 Chronos，一个简单而有效的框架，用于预训练概率时间序列模型。 Chronos 使用缩放和量化将时间序列值标记化为固定词汇表，并通过交叉熵损失在这些标记化时间序列上训练现有的基于 Transformer 的语言模型架构。我们在大量公开可用的数据集上预训练了基于 T5 系列（参数范围从 20M 到 710M 参数）的 Chronos 模型，并辅以通过高斯过程生成的合成数据集以提高泛化能力。在由 42 个数据集组成并包含经典局部模型和深度学习方法的综合基准测试中，我们表明 Chronos 模型：(a) 在属于训练语料库的数据集上显着优于其他方法； (b) 相对于专门针对新数据集进行训练的方法，在新数据集上具有可比的、有时甚至更优越的零样本性能。我们的结果表明，Chronos 模型可以利用来自不同领域的时间序列数据来提高未见过的预测任务的零样本精度，将预训练模型定位为一种可行的工具，大大简化预测流程。 &lt; /blockquote&gt; ​ https://preview.redd.it/7fxmgjnuw9oc1.png?width=1818&amp;format=png&amp;auto=webp&amp;s=8d9e0b7b462597a3b7c176c133e7a2843debf b7c &lt;!-- SC_ON - -&gt;  由   提交 /u/shchur   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1behp7t/r_chronos_learning_the_language_of_time_series/</guid>
      <pubDate>Thu, 14 Mar 2024 10:04:49 GMT</pubDate>
    </item>
    <item>
      <title>对最新AI软件工程师Devin的思考《[讨论]》</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdzesy/thoughts_on_the_latest_ai_software_engineer_devin/</link>
      <description><![CDATA[刚刚开始攻读计算机科学学位，人工智能每天取得的进展真的让我感到害怕。很抱歉，如果这个问题感觉有点无关紧要或重复，但由于你们最了解这项技术，我想听听你们的想法。人工智能（法学硕士）真的可以实现软件工程自动化，甚至可以将 10 名开发人员的团队减少到 1 名吗？我们真正可以期待人工智能软件工程取得多大的进步。数据科学甚至人工智能工程等领域也能实现自动化吗？ tl:dr 您认为未来 20 年法学硕士在技术工作自动化方面能走多远    由   提交/u/Anonymous45353  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdzesy/thoughts_on_the_latest_ai_software_engineer_devin/</guid>
      <pubDate>Wed, 13 Mar 2024 18:50:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 数据解释器：数据科学的法学硕士代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdxqt4/r_data_interpreter_an_llm_agent_for_data_science/</link>
      <description><![CDATA[      摘要：  基于大型语言模型 (LLM) 的代理已表现出显着的有效性。然而，在需要实时数据调整、由于各种任务之间复杂的依赖关系而需要优化专业知识以及识别逻辑错误以进行精确推理的能力的数据科学场景中，它们的性能可能会受到影响。在本研究中，我们介绍了数据解释器，这是一种旨在用代码解决问题的解决方案，强调三种关键技术来增强数据科学中的问题解决：1）具有分层图结构的动态规划，以实现实时数据适应性； 2）动态工具集成，以提高执行过程中的代码熟练程度，丰富所需的专业知识； 3）反馈中的逻辑不一致识别，通过经验记录提高效率。我们在各种数据科学和实际任务中评估数据解释器。与开源基线相比，它表现出了卓越的性能，在机器学习任务方面表现出显着的改进，从 0.86 提高到 0.95。此外，数学数据集增加了 26%，开放式任务显着提高了 112%。该解决方案将在 https://github.com/geekan/MetaGPT 发布。  ​ https: //preview.redd.it/6bcww0qb15oc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=d98f2e05fbdf06f186b93782a786dc94b3d33bac ​ &lt; a href=&quot;https://preview.redd.it/565u97cc15oc1.png?width=1116&amp;format=png&amp;auto=webp&amp;s=fdefeda7c7733e610e0984ba7d7b77024d91a1b0&quot;&gt;https://preview.redd.it/565u97cc15oc1.png?width =1116&amp;format=png&amp;auto=webp&amp;s=fdefeda7c7733e610e0984ba7d7b77024d91a1b0 ​ https://preview.redd.it/a4c6lopc15oc1.png?width=1150&amp;format=png&amp;auto=webp&amp;s= 8b1e7cc27f3a2a9b75a66da0fdd54d29bf988f86 ​ https://preview.redd.it/lab3uh2d15oc1.png?width=731&amp;format=png&amp;auto=webp&amp;s=9f1506e607eb644b77bd2ba22e2189d0 05e1c010    由   提交/u/MetaGPT   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdxqt4/r_data_interpreter_an_llm_agent_for_data_science/</guid>
      <pubDate>Wed, 13 Mar 2024 17:46:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>