<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 02 Feb 2024 00:57:50 GMT</lastBuildDate>
    <item>
      <title>[P] 🚀 使用 Upstash 矢量和 HuggingFace 空间找到您的双胞胎、无服务器图像相似度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agpz50/p_find_your_twins_serverless_image_similarity/</link>
      <description><![CDATA[      ​ https://preview.redd.it/6ei3re7jd2gc1.png?width=2638&amp; format=png&amp;auto=webp&amp;s=070324f486d512d7c959b2a3c7b7b1fe6113325c 演示：https://huggingface。 co/spaces/omerXfaruq/FindYourTwins 博客： https://huggingface.co/blog/omerXfaruq/serverless-image-similarity-with-upstash-vector ​   由   提交 /u/farukozderim   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agpz50/p_find_your_twins_serverless_image_similarity/</guid>
      <pubDate>Fri, 02 Feb 2024 00:10:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] NLP学习资源新旧对比。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agpwun/d_nlp_learning_resource_old_vs_new/</link>
      <description><![CDATA[大家好，我正在开始我的 NLP 之旅，我的课程是 cs124(2012) 和 cs224n(2023)，所以我计划从2012 年讲座的 cs124，然后转到 cs224n。 我的问题是 2012 年讲座已经很老了，而且目前技术已经很先进，所以我应该直接跳到 cs224n 吗？或者我应该因为基础知识或知识而学习它们？也请告诉我是否有任何好的资源。我目前正在参考演讲和语言书籍第三版作为讲座。   由   提交 /u/Critical_Day3611   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agpwun/d_nlp_learning_resource_old_vs_new/</guid>
      <pubDate>Fri, 02 Feb 2024 00:07:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 访谈系统设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agogxg/d_sys_design_for_interviews/</link>
      <description><![CDATA[昨天我与一家非 faang 但顶级公司的高级 MLE 进行了交谈。他说，即使在 FAANG 中，ML 面试也不再有 Sys 设计。他说ML设计是一个回合，但不是sys设计。系统设计仅适用于 SWE。我认为以前是系统设计+机器学习设计。谁能确认一下吗？   由   提交/u/No-Mud4063  /u/No-Mud4063 reddit.com/r/MachineLearning/comments/1agogxg/d_sys_design_for_interviews/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agogxg/d_sys_design_for_interviews/</guid>
      <pubDate>Thu, 01 Feb 2024 23:04:40 GMT</pubDate>
    </item>
    <item>
      <title>【研究】防御语言模型越狱攻击的鲁棒提示优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agnzxt/research_robust_prompt_optimization_for_defending/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2401.17263   摘要：尽管人工智能对齐取得了进步，但语言模型（LM）仍然容易受到对抗性攻击或越狱，其中对手会修改输入提示以诱发有害行为。虽然已经提出了一些防御措施，但它们侧重于狭隘的威胁模型，缺乏强大的防御能力，我们认为这种防御措施应该是有效的、普遍的和实用的。为了实现这一目标，我们提出了第一个对抗性目标来保护 LM 免受越狱攻击，并提出了一种算法，即鲁棒提示优化（RPO），该算法使用基于梯度的令牌优化来强制执行无害的输出。这产生了一个易于访问的后缀，显着提高了对优化过程中出现的越狱和未知的、持续越狱的鲁棒性，将 Starling-7B 在 20 次越狱中的攻击成功率从 84% 降低到 8.66%。此外，我们发现RPO对正常LM使用影响较小，在自适应攻击下成功，并且可以转移到黑盒模型，将GPT-4最强攻击的成功率从92%降低到6%。    由   提交 /u/SatisfyingLatte   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agnzxt/research_robust_prompt_optimization_for_defending/</guid>
      <pubDate>Thu, 01 Feb 2024 22:45:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] EVRPTW 求解器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agnp6n/p_evrptw_solver/</link>
      <description><![CDATA[此存储库包含基于 Python 的 ACO 算法实现，旨在考虑特定时间窗口和充电要求来优化电动汽车的路由路径。  https://github.com/F-a-b-r-i-z-i-o/Ant_Colony_Optimization_for_Evrptw   由   提交/u/Stunning_Ad_1539   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agnp6n/p_evrptw_solver/</guid>
      <pubDate>Thu, 01 Feb 2024 22:32:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] CreateML 对象检测项目产生 0% 的准确度，需要帮助！！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agnmvj/p_createml_object_detction_project_producing_0/</link>
      <description><![CDATA[对我的数据集进行 13000 次迭代训练后，训练集、验证集和测试集均显示 0% 准确度，并且我的所有测试照片均显示假阴性/无检测到物体。该数据集有 1032 张照片和 2 个类，我使用 Roboflow 进行图像注释。如果有什么办法可以解决这个问题？ 这是我的项目的照片，我用 100 次迭代而不是 13000 次迭代测试了这个，但它仍然产生了 0%。 CreateML 项目照片 我使用 Roboflow 来注释图像，然后将数据集导出到 CreateML下载邮政编码格式，并将训练照片、有效照片和测试照片插入 Createml 中。我选择完整网络和 13 x 13 网格和压制训练的 13000 次迭代。经过一天的训练，损失很小（大约0.0094），但训练集、有效集和测试集都显示为0%，并且在评估中，测试集显示出0%的准确率，所有照片都是假阴性。   由   提交 /u/just-a--reddit-user   &lt; a href=&quot;https://www.reddit.com/r/MachineLearning/comments/1agnmvj/p_createml_object_detction_project_having_0/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agnmvj/p_createml_object_detction_project_producing_0/</guid>
      <pubDate>Thu, 01 Feb 2024 22:29:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] MoE-LLaVA：大视觉语言模型专家混合 - 北京大学 2024 - MoE-LLaVA-3B 展示了与 LLaVA-1.5-7B 相当的性能！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agmd47/r_moellava_mixture_of_experts_for_large/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2401.15947v1  Github： https://github.com/PKU-YuanGroup/MoE-LLaVA  摘要：  对于大型视觉语言模型（LVLM） ，缩放模型可以有效提高性能。然而，扩展模型参数会显着增加训练和推断成本，因为计算中的每个标记都会激活所有模型参数。在这项工作中，我们提出了一种新的训练策略MoE-tuning for LVLMs，它可以构建一个参数数量惊人但计算成本恒定的稀疏模型，并且有效解决通常与多模式学习和模型稀疏性相关的性能下降问题。此外，我们还提出了 MoE-LLaVA 框架，这是一种基于 MoE 的稀疏 LVLM 架构。该框架独特地在部署期间通过路由器仅激活前k个专家，使其余专家保持不活动状态。我们广泛的实验突出了MoE-LLaVA在视觉理解方面的出色能力及其减少模型中幻觉的潜力输出。 值得注意的是，仅用 30 亿个稀疏激活参数， MoE-LLaVA 在各种视觉理解数据集上表现出与 LLaVA-1.5-7B 相当的性能，甚至超过了 LLaVA-1.5-物体幻觉基准中的 13B。通过 MoE-LLaVA，我们的目标是为稀疏 LVLM 建立基线，并为未来开发更高效、更有效的多模态学习系统的研究提供宝贵的见解。   https://preview.redd.it/pfpthghxl1gc1.jpg ?width=803&amp;format=pjpg&amp;auto=webp&amp;s=4e4578bb154a596fc11c8da18de1aadf4955c1e6 https://preview.redd.it/xo5rzbhxl1gc1.jpg?width=797&amp;format=pjpg&amp;auto=webp&amp;s=96bcd786ebfe3291e1ccb50415 6e5b3e8db7b710 https://preview.redd.it/22e3kfhxl1gc1 .jpg?width=1321&amp;format=pjpg&amp;auto=webp&amp;s=ad7a4657421f8bc34bea15d720b2bd5f78792d7b https://preview.redd.it/6i93vbhxl1gc1.jpg?width=1181&amp;format=pjpg&amp;auto=webp&amp;s=b43afea3e6e24 568a39118307ead132455a471c9   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agmd47/r_moellava_mixture_of_experts_for_large/</guid>
      <pubDate>Thu, 01 Feb 2024 21:36:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 围绕“AI”的普遍负面情绪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agj5y1/d_general_negative_sentiment_surrounding_ai/</link>
      <description><![CDATA[我注意到，每当我向普通人群（通常是非技术人员 -（家人、朋友等））提起人工智能主题时，第一个我想到的是“机器人接管世界并消灭人类”的存在的消极方面、危险和威胁，而不是积极的一面（例如提高效率、自动化、科学等）。需要明确的是，我具体谈论的是人工智能的生存威胁，而不是像大型科技亿万富翁和法团主义这样的经济/政治问题。 这让我想知道 - “人工智能”是否已成为一个伴随着的术语对绝大多数人来说是一个可怕的负面含义吗？这是非常可悲的，我认为这些人中的许多人不知道他们在说什么，他们不明白这些模型是如何工作的，所以他们只是求助于人工智能存在主义者在媒体上推销的任何东西（不是为了淡化危险——我我知道有像 Ilya sutski 和 Geoffrey Hinton 这样的杰出研究科学家担心这些事情）但我觉得现在对人工智能的过度炒作和过度提及确实导致了普遍的技术悲观主义。 TLDR ：“人工智能”越来越多地给普通（非技术）公众带来存在主义的恐惧/负面含义？想法？   由   提交/u/Character-Capital-70   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agj5y1/d_general_negative_sentiment_surrounding_ai/</guid>
      <pubDate>Thu, 01 Feb 2024 19:22:28 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 基于皮层柱的计算研究现状？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agfn70/research_current_perspectives_on_research_in/</link>
      <description><![CDATA[2021 年，杰夫·霍金斯 (Jeff Hawkins) 发布了他的著作《一千个大脑：一种新的智能理论》，其中他强调了新皮质中的皮质柱，用于实现高级智力。它似乎遭到了分裂和短暂的接待。科普爱好者和一些​​认为该领域有点停滞的深度学习研究人员短暂地热衷于一种新颖的方法来为其增添趣味。与此同时，那些具有深厚神经科学背景的人对该理论的某些方面有一些疑虑，也许有些东西是可以挽救的。 我自己对它只是基于炒作的性质有点怀疑，但是最近我看到了关于这个主题的随机不同研究。引起我注意的是卡耐基梅隆大学的神经拟态计算机架构实验室 (NCAL)。他们写了一份文档，其中详细介绍了一项研究计划，旨在设计一种新颖的架构，该架构结合了皮质柱和他们所说的东西时间神经网络。令我惊讶的是，有人实际上正在致力于实现与我认识的人的想法惊人相似的想法（即使它们没有实际意义），而不是仅仅围绕一个想法进行炒作。还有其他人听说过这个吗？人们对此有何看法？ 就背景而言，我是神经形态计算领域一个非常小的团队的成员。我拥有数学博士学位，并且是该领域的新手。我们正在寻找新的项目和研究方向，团队的一位高级成员对皮质柱的想法很感兴趣。他讨论的一些事情实际上与上面的非常相似，我很惊讶地看到人们独立地提出了这些想法。这看起来值得花时间吗？ 提前致谢   由   提交/u/Strawberry_Doughnut   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agfn70/research_current_perspectives_on_research_in/</guid>
      <pubDate>Thu, 01 Feb 2024 16:56:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能的真正价值在于最终用户用它做什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agewf2/d_is_the_true_value_of_ai_what_the_enduser_does/</link>
      <description><![CDATA[阅读本文后：https://www.taipy.io/posts/bringing-the-end-user-into-the-ai-picture 我已经考虑到为什么重点不是让人工智能对非技术最终用户来说更容易访问和用户友好。 制作真正复杂的算法是一回事，但当你实际上做不到时，它是否有意义用它来做出决策？ 如何改进这种人工智能协作？ 只是一些想法！  &amp;# 32；由   提交/u/quicklyalienated76   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agewf2/d_is_the_true_value_of_ai_what_the_enduser_does/</guid>
      <pubDate>Thu, 01 Feb 2024 16:25:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 传统的 ML/深度学习技术是否已在 NLP 和生产级系统中使用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agb5rg/d_are_traditional_ml_deep_learning_techniques/</link>
      <description><![CDATA[许多公司正在从他们在几年内开发的机器学习管道转向基于 ChatGPT 的/类似的解决方案。当然，对于文本生成用例来说，这是最有意义的。 但是，许多实际的 NLP 问题可以表述为分类/标记问题。 Pre-ChatGPT 系统过去涉及大量移动组件（关键字提取、超长正则表达式、在嵌入空间中查找最近向量等）。 那么，实际发生了什么？人们是否用 LLM API 替换特定组件？或者整个系统是否被一系列对 LLM API 的调用所取代？基于 BERT 的解决方案还在使用吗？ 现在 ChatGPT API 支持更长的时间和更长的时间。更长的上下文窗口（128k），除了定价和数据隐私问题之外，是否存在基于 BERT 的/其他解决方案能够发挥作用的用例；它不需要像 ChatGPT/LaMDA/类似的 LLM 等模型那样多的计算？ 如果它是上述 LLM 模型不知道的专有数据，那么您将使用自己的模型。但很多用例似乎都围绕着对人类语言本身的一般理解（例如投诉/票证分类/从产品评论中得出见解）。 任何博客、论文、案例研究或其他解决相同问题的文章将不胜感激。我也很想听听您的所有经历，以防您在现实系统中从事过/听说过上述迁移。 这个问题是专门提出的，请记住 NLP 的使用- 案例；但也可以随意将您的答案扩展到其他模式（例如表格和文本数据的组合）。   由   提交/u/101coder101  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agb5rg/d_are_traditional_ml_deep_learning_techniques/</guid>
      <pubDate>Thu, 01 Feb 2024 13:36:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前适合本地法学硕士的最佳 RAG 设置是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ag6bo7/d_whats_the_best_current_rag_setup_that_would/</link>
      <description><![CDATA[我过去（6-8个月前）尝试过像langchain这样的东西，但它们很麻烦并且没有按预期工作。 我需要 RAG 从各种 pdf 文件（很长，150 多页）获取数据 - 我需要一个设置，允许我添加越来越多的数据源。 我想运行在本地，可以获得 24gb 显卡（或 2x16gb 显卡） - 这样我就可以使用 33b 或更小的型号运行。 我知道行业中的情况每两周就会发生变化，所以我希望有一个简单高效的 RAG 方法（与 6 个月前相比）   由   提交 /u/yupignome   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ag6bo7/d_whats_the_best_current_rag_setup_that_would/</guid>
      <pubDate>Thu, 01 Feb 2024 08:30:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mamba scalabe 是 Transformer 吗？或者只是另一种有效的模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ag3cgg/d_is_mamba_scalabe_as_transformer_or_just_another/</link>
      <description><![CDATA[*scalable Mamba 的作者声称“Mamba-3B 模型的性能优于相同尺寸的 Transformer，并且匹配两倍尺寸的 Transformer”。&lt; /p&gt; 像 Mamba-13B（只是一个假设）这样的模型与具有大量预训练数据的 Mixtral 8x7B 怎么样？有人尝试过这个吗？   由   提交 /u/Dry_Cheesecake_8311   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ag3cgg/d_is_mamba_scalabe_as_transformer_or_just_another/</guid>
      <pubDate>Thu, 01 Feb 2024 05:17:57 GMT</pubDate>
    </item>
    <item>
      <title>[N] Mistral 首席执行官确认新开源 AI 模型接近 GPT-4 性能的“泄露”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1afryc0/n_mistral_ceo_confirms_leak_of_new_open_source_ai/</link>
      <description><![CDATA[https://venturebeat.com/ai/mistral-ceo-confirms-leak-of-new-open-source-ai-model-nearing-gpt-4-性能/   由   提交 /u/EmbarrassedHelp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1afryc0/n_mistral_ceo_confirms_leak_of_new_open_source_ai/</guid>
      <pubDate>Wed, 31 Jan 2024 20:35:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>