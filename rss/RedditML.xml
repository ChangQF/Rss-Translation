<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 24 Jan 2024 12:26:40 GMT</lastBuildDate>
    <item>
      <title>[D] 在基于 Transformer 的 LLM（例如 GPT2 和 LLAMA2）中如何处理令牌嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19efvii/d_how_are_tokenembeddings_processed_in/</link>
      <description><![CDATA[我一直认为，简单的前向传递的上下文宽度为 1600，填充了最多 1600 个标记，并在输出处生成一个标记。考虑到自动回归特性，然后新的令牌将附加到之前的令牌上，并且正在发生下一次前向传递。 我目前正在研究一些内部结构，并开始将 GTP2-XL 的激活视为以及使用 Transformer Lens 库的 LLAMA2。在那里我第一次接触了令牌嵌入。如果我向 LLM 输入三个标记，它会在两层之间缓存一个大小为 4x1600 的张量（将“开始”标记添加到输入标记中）。 我在理解模型如何运行使用所有这些向量进行前向传播。所以我的问题是：  是否在每个输入标记（+起始标记）的每次前向传递中计算所有标记 Emebedding？ 线性中的权重是多少？层像？我认为这应该是一个大小为 1600x1600 的矩阵，因此计算结果为 4x1600 * 1600x1600，并再次导致 4x1600 矩阵 如果是这样：是否涉及某种权重共享？ 1600x1600 导致每层约 250 万个权重，对于 GPT2，变压器的一个线性层部分总共有 1.228 亿个权重，对于我来说，考虑 1.5B 个参数的总数，这似乎是合理的。 会发生什么最终所有这些令牌嵌入？我认为它只需要一个一维向量来计算 softmax 并决定输出哪个标记。 transformer 论文提到它在 LLM 开始时向嵌入向量添加了一些位置编码。它们通常是如何计算的？  ​ 非常感谢您的建议。   由   提交/u/bineda  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19efvii/d_how_are_tokenembeddings_processed_in/</guid>
      <pubDate>Wed, 24 Jan 2024 12:22:45 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] Java 中的机器学习可能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19efuoe/discussion_is_machine_learning_in_java_possible/</link>
      <description><![CDATA[大家好！ 👋 最近我一直在思考一个有趣的问题——Java 中的机器学习可行吗？我很想听听您使用 Java 进行机器学习的个人经历。您是否使用 Java 成功实施了 ML 项目，或者是否遇到任何障碍？哪些库或框架最适合您？ 🤔 让我们深入研究这个领域，分享见解、互相学习，或许还能帮助那些正在考虑或正在从事 Java 机器学习项目的人。迫不及待地想了解您的想法！   由   提交 /u/christineshepherd   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19efuoe/discussion_is_machine_learning_in_java_possible/</guid>
      <pubDate>Wed, 24 Jan 2024 12:21:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视觉模型的方便比较图表：何时使用什么！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eeve9/d_a_handy_comparative_chart_on_vision_models_when/</link>
      <description><![CDATA[       由   提交/u/Instantinopaul   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eeve9/d_a_handy_comparative_chart_on_vision_models_when/</guid>
      <pubDate>Wed, 24 Jan 2024 11:21:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 幻视曼巴再次出击！变形金刚王座正在崩溃吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eemq2/d_vision_mamba_strikes_again_is_the_transformer/</link>
      <description><![CDATA[还记得震撼 NLP 的状态空间模型 Mamba 吗？好吧，抓住你的像素，因为它们现在也在计算机视觉领域碾压它！ 他们的新模型 Vision Mamba 抛弃了自我关注热潮，并依赖于状态空间魔法。结果？性能与顶级视觉变压器 (DeiT) 相当，但效率更高！ 这可能会改变游戏规则，伙计们。我们正在谈论更快、更轻的型号，它们可以在您祖母的笔记本电脑上运行，但仍然像鹰一样看得见。 有什么想法吗？我很高兴看到变形金刚领域出现一些竞争。我们可以期待在这个新架构上推出 chatgpt v2 吗？道歉！可能听起来很疯狂，而且评论还为时过早。 查看论文：https: //paperswithcode.com/paper/vision-mamba-efficient-visual-representation   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eemq2/d_vision_mamba_strikes_again_is_the_transformer/</guid>
      <pubDate>Wed, 24 Jan 2024 11:06:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] InternLM-Math：SOTA 开源数学推理法学硕士。求解器、证明者、验证者、增强器。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ee2ku/p_internlmmath_sota_opensourced_math_reasoning/</link>
      <description><![CDATA[   上海人工智能实验室推出新的SOTA数学法学硕士，具有7B和20B规模的开放式来源。 Github：https://github.com/InternLM/InternLM-Math Huggingface：https://huggingface.co/internlm/internlm2-math-7b 演示：https://huggingface.co/spaces/internlm/internlm2-math -7b ​ https://preview.redd.it/4emyeapn7dec1.png?width=1224&amp;format=png&amp;auto=webp&amp;s=6a79ba3e4b98f48befed91eded1cf286b9fca137 特点：  7B 和 20B 中文和英语数学 LM 的性能优于 ChatGPT。 InternLM2-Math 继续从 InternLM2-Base 进行预训练，具有 ~100B 高质量数学-相关代币和 SFT 以及约 200 万双语数学监督数据。我们应用最小哈希和精确数字匹配来消除可能的测试集泄漏。 添加 Lean 作为数学问题解决和数学定理证明的支持语言。我们正在探索将 Lean 3 与InternLM-Math 用于可验证的数学推理。 InternLM-Math 可以为 GSM8K 等简单的数学推理任务生成 Lean 代码，或者提供基于 Lean 状态的可能证明策略。 也可以视为奖励模型，支持结果/过程/精益奖励模型。我们用各种类型的奖励建模数据来监督InternLM2-Math，使InternLM2-Math也可以验证思维链过程。我们还添加了将思维链过程转换为 Lean 3 代码的功能。 数学 LM 增强助手和代码解释器。 InternLM2-Math 可以帮助增强数学推理问题并使用代码解释器解决它们，这使您可以更快地生成综合数据！  性能： https://preview.redd.it/ttzsd4408dec1.png?width=1175&amp;format =png&amp;auto=webp&amp;s=8894552a848130a8240a2e135a6b78d0841311d4   由   提交/u/OpenMMLab  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ee2ku/p_internlmmath_sota_opensourced_math_reasoning/</guid>
      <pubDate>Wed, 24 Jan 2024 10:29:53 GMT</pubDate>
    </item>
    <item>
      <title>[项目] BELT（较长文本的 BERT）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19edzov/project_belt_bert_for_longer_texts/</link>
      <description><![CDATA[我们创建了 BELT（BERT For Longer Texts）——一个 Python 包，允许对长度超过 512 个 token 的文本使用类似 BERT 的模型。该方法是 Jacob Devlin 提出的想法的实现，Jacob Devlin 是 评论。您可以在 Medium 上我刚刚发表的两篇文章中阅读有关它的更多详细信息： 第一部分是应用 BERT 分类器的概述： 第 1 部分 第二部分深入介绍我们训练 BELT 模型的方法。 第 2 部分 该存储库以开源方式提供： Repo 我知道你在想什么：“等等，bucko，这不是什么新鲜事。每个人都知道有像 BigBird 或 Longformer 这样的模型可以处理更长的文本”。对此我的回答是：“我知道，伙计，但是 BigBird 和 Longformers 不是修改过的 BERT。它们是具有不同架构的模型。因此，它们需要从头开始预训练或下载。 BELT修改模型微调。这带来了 BELT 方法的主要优点 - 它使用任何预先训练的 BERT 或 RoBERTa 模型。快速查看 HuggingFace Hub 可以确认，BERT 的资源比 Longformer 多大约 100 倍。找到适合特定任务或语言的可能会更容易。”享受吧！   由   提交/u/MBrzozowskiML   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19edzov/project_belt_bert_for_longer_texts/</guid>
      <pubDate>Wed, 24 Jan 2024 10:24:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] CVPR 2024审稿人评分及反驳讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19e8xyw/d_discussion_on_cvpr_2024_reviewer_scores_and/</link>
      <description><![CDATA[嘿 CVPR 爱好者！ 随着 CVPR 2024 审稿人的分数出来，我认为开放一下会很好有关审查过程和反驳的讨论和问题的线索。分享您的经验、见解，让我们继续讨论！ 首先，这是我的分数和置信度：  论文 1：4 (4)  论文 2：4 (3) 论文 3：2 (5)  其他人都怎么样？请随意分享您的分数、提出问题或寻求建议。让我们一起解决这个问题，充分利用反驳过程！ 🚀 #CVPR2024   由   提交/u/darkknight-6  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19e8xyw/d_discussion_on_cvpr_2024_reviewer_scores_and/</guid>
      <pubDate>Wed, 24 Jan 2024 04:47:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 什么时候在 TPU 上训练有意义？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19e8d1a/d_when_does_it_make_sense_to_train_on_tpu/</link>
      <description><![CDATA[我花了几周时间将 torch 模型训练脚本移植到 PyTorch/XLA 并在 TPU v3 和 v4 上进行测试。从纯粹的训练速度和成本效率的角度来看，我将结果与 GCP 中的 a2/g2 机器上的训练进行了比较。我很惊讶移植代码有多困难，以及 TPU 上的训练有多慢且成本低效。 Dev UX 让人想起使用 TensorFlow（从最坏的意义上来说）。东西通常不能开箱即用，很难调试，因为所有东西都是编译的，而且张量是惰性的。整个事情非常不透明，不清楚发生了什么。没有您期望拥有的基本工具，例如如果不进行分析就无法检查 TPU 利用率。 更令人惊讶的是，训练速度比使用同等价格的 GPU 时慢得多。例如，与 g2-standard-96（8xL4 GPU）上的训练相比，TPU v3-8 上的训练速度大约慢 2 倍，而成本却大致相同。 TPU v4-8 价格更高，但仍然比 g2-standard-96 慢。我的模型或多或少是一个简单的密集网络，它来自推荐领域。未移植的 pytorch 代码使用 DDP。数据加载器经过高度优化并具有基准测试，我确信这不是瓶颈。 XLA 指标没有显示任何危险信号。 此时，我想知道为此投入更多精力是否有意义。非 Google 人员是否真的使用 TPU 进行大规模训练？是不是 Torch/XLA 还没有准备好迎接黄金时段，只是 TPU 最适合与 TF 或 JAX 一起使用？ TPU 是否有特定的用例？   由   提交 /u/Puzzleheaded-Stand79    reddit.com/r/MachineLearning/comments/19e8d1a/d_when_does_it_make_sense_to_train_on_tpu/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19e8d1a/d_when_does_it_make_sense_to_train_on_tpu/</guid>
      <pubDate>Wed, 24 Jan 2024 04:15:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 测试基于 LLM 的应用程序很困难。你怎么处理这个问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19e78xf/d_testing_llmbased_applications_is_hard_how_are/</link>
      <description><![CDATA[让我知道你是如何处理这个问题的。非常感谢您的评论！   由   提交 /u/Due-Function4447    reddit.com/r/MachineLearning/comments/19e78xf/d_testing_llmbased_applications_is_hard_how_are/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19e78xf/d_testing_llmbased_applications_is_hard_how_are/</guid>
      <pubDate>Wed, 24 Jan 2024 03:17:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们不能使用合成数据来帮助创建用于放射图像分析训练的更清晰的数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19e4yt3/d_why_cant_we_use_synthetic_data_to_help_create/</link>
      <description><![CDATA[这是否比创建合成数据来训练 LLM 更难，类似于 AMIE 在最近的论文中所做的：https://blog.research.google/2024/01/amie-research-ai-system- for-diagnostic_12.html   由   提交/u/derpgod123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19e4yt3/d_why_cant_we_use_synthetic_data_to_help_create/</guid>
      <pubDate>Wed, 24 Jan 2024 01:27:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] CVPR 2024 评论已出！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dydvm/d_cvpr_2024_reviews_are_out/</link>
      <description><![CDATA[你们都好吗？ 第一次提交，看到我的分数后会再次尝试:/   由   提交/u/V1bicycle  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dydvm/d_cvpr_2024_reviews_are_out/</guid>
      <pubDate>Tue, 23 Jan 2024 20:40:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 研究人员使用哪些工具在论文中创建出色的图像和流程图？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dux08/r_what_tools_do_researchers_use_to_create_great/</link>
      <description><![CDATA[实际上，我想知道优秀的研究论文中的模型架构图有多酷，其中包含清晰的流程流程图和模型架构的出色可视化。目前我使用draw.io，但很好奇使用什么工具？我的意思是他们使用 Figma、Adobe 等专业工具吗？   由   提交 /u/MysticShadow427   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dux08/r_what_tools_do_researchers_use_to_create_great/</guid>
      <pubDate>Tue, 23 Jan 2024 18:17:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 所有这些 AI 服务如何能够负担每月 5/10/20 美元的费用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19duab0/d_how_all_these_ai_services_can_afford_51020_subs/</link>
      <description><![CDATA[各种人工智能服务（从语音识别到 OCR 和艺术生成）如何嵌入新数据，以如此低的成本提供其功能？使用 GPT-4 API 之类的东西很快就会花费 10 美元，这对于其他模型来说也是类似的。即使在本地运行 LLaMA 2 这样的东西也会产生巨大的成本。我很好奇这些服务在运营这些大型模型时采用的经济策略来维持较低的月费。   由   提交 /u/Numerous_Bed9323   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19duab0/d_how_all_these_ai_services_can_afford_51020_subs/</guid>
      <pubDate>Tue, 23 Jan 2024 17:53:00 GMT</pubDate>
    </item>
    <item>
      <title>[N]ICLR2024的学习理论家，我感同身受！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dnolo/n_learning_theorists_of_iclr2024_i_feel_you/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dnolo/n_learning_theorists_of_iclr2024_i_feel_you/</guid>
      <pubDate>Tue, 23 Jan 2024 12:49:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>