<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 30 Jan 2025 06:22:52 GMT</lastBuildDate>
    <item>
      <title>[D] R1 后训练规格，有人读过这个有趣的 RL 阶段的后训练成本吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idg6mq/d_r1_post_training_specs_does_anyone_have_a_read/</link>
      <description><![CDATA[      浏览 V3 技术报告和 R1 论文后，我对这个 GRPO 流程的成本/硬件时间感到有点困惑。 查看 V3 论文中的图片，R1 的后期训练是否在“后期训练”中涵盖？部分在这里？ https://preview.redd.it/fkwxepiul2ge1.png?width=1250&amp;format=png&amp;auto=webp&amp;s=6b48bd3345de7c604d3bbe78519db19bd3d4e479 5.2.2 提到 GRPO 包含在后训练中，可能是 R1，可能是 R1-zero，可能是两者兼而有之，也可能都不是。 R1 论文提到了R1 使用由 R1-zero 模型（+其他模型......我们这里就不讨论这个了......）生成的“数千个” COT 数据样本，然后执行相同的 GRPO 过程，所以假设我们在那里的训练后成本是 2 倍（10k H800 GPU 小时）？    提交人    /u/Standard_Natural1014   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idg6mq/d_r1_post_training_specs_does_anyone_have_a_read/</guid>
      <pubDate>Thu, 30 Jan 2025 06:02:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何学习 ML 和 AI 并真正获得 LLM 学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idf978/d_how_to_learn_ml_and_ai_and_actually_build_a_llm/</link>
      <description><![CDATA[所以，这听起来像是一个疯狂的问题，但我真的想知道——一个普通人应该怎么做才能从一无所知到真正建立一个大型语言模型？ 我知道这不是一条容易的路，但问题是，没有明确的路线图。网上的每一种资源都感觉像是在推广一些东西——课程、书籍、时事通讯——但没有人给出循序渐进的方法。 我并不打算在我的笔记本电脑上训练 GPT-4，但我想做的不仅仅是运行预先训练好的模型。任何指导都将不胜感激    提交人    /u/Technical_Turn680   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idf978/d_how_to_learn_ml_and_ai_and_actually_build_a_llm/</guid>
      <pubDate>Thu, 30 Jan 2025 05:12:04 GMT</pubDate>
    </item>
    <item>
      <title>无炒作 DeepSeek-R1 [R] 阅读清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ideupn/no_hype_deepseekr1_reading_list/</link>
      <description><![CDATA[在过去的约 1.5 年里，我一直在运营一个研究论文俱乐部，我们在那里深入研究 AI/ML 领域有趣/基础的论文。因此，我们自然而然地接触到了很多导致 DeepSeek-R1 的论文。在本周深入研究 DeepSeek 论文时，我决定编制一份我们已经看过的论文清单，或者我认为这些论文是很好的背景阅读材料，可以更全面地了解 DeepSeek 内部发生的事情。 喝杯咖啡，享受吧！ https://www.oxen.ai/blog/no-hype-deepseek-r1-reading-list    提交人    /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ideupn/no_hype_deepseekr1_reading_list/</guid>
      <pubDate>Thu, 30 Jan 2025 04:51:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找暑期/冬季学校</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idemly/d_looking_for_summerwinter_schools/</link>
      <description><![CDATA[我正在寻找 ML 夏季/冬季学校来培养我的技能，结识志同道合的人，并希望为未来的机会增加我的简历/ SOP。如果这里有人参加过，我很想听听你的想法——它们真的值得吗？它们在申请工作或研究生院时真的有用吗？ 此外，如果您遇到任何仍在接受申请的 ML 夏季或冬季学校，请提供详细信息！非常感谢任何建议。    提交人    /u/thebluffmaster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idemly/d_looking_for_summerwinter_schools/</guid>
      <pubDate>Thu, 30 Jan 2025 04:39:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 假设分化驱动的推理模型新研究的产生</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ided3m/d_hypothetical_differentiationdriven_generation/</link>
      <description><![CDATA[有没有比我聪明的人能探索一下将 DSPy 或 TextGrad 之类的东西应用于 O1 或 DeepSeek R1 的可能性，使其生成推理链或提示，从而创建肯定不在其训练集中的 arXiv 论文，比如今天发布的论文？ 这是否有可能导致发现实际上会导致新发现的推理链？    提交人    /u/fraktall   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ided3m/d_hypothetical_differentiationdriven_generation/</guid>
      <pubDate>Thu, 30 Jan 2025 04:25:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 建立“穷人的推理模型”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1id8j4o/d_building_a_poor_mans_reasoning_model/</link>
      <description><![CDATA[阅读 DeepSeek-R1 论文后，我一直在想我们是否可以进一步优化推理模型以在消费级硬件上运行？ 该论文表明，推理可以纯粹从 RL 中产生，而无需 SFT，这令人印象深刻。但我并不确信这种新兴推理与我们通过结构良好、精心策划的 CoT 解决方案可能获得的推理有根本区别。 当然，RL 可以发现我们尚未明确教授的新策略（通过奖励信号进行“自我完善”），但我仍然不确定它是否真正不同于彻底的策划方法，尤其是看到像 4o 或 Sonnet 这样的模型在巧妙提示时可以产生什么。 RL DeepSeek 的方法具有明显的优势（训练成本更低，对手工制作数据的依赖更少），但如果我们可以通过更简单、无需训练的方法实现类似的结果：“借用”来自 R1 的合成数据集的推理，并结合多次提示？ 这是我的粗略想法：  将问答 + 推理 + 最终答案对存储在简单的数据库或向量存储中。 按主题标记它们（数学、编码、逻辑、等）或使用嵌入对它们进行索引以进行语义检索。 对于新查询，检索 2-3 个相关示例（包括它们的推理/错误/更正），然后将它们作为多样本提示提供给较小的模型，在推理时有效地借用 R1 的推理风格。  也许我们可以通过协作推理或轻量级 MoE 设置来改进输出，其中多个专门的提示会生成响应，而聚合器会选择或改进最佳的最终答案。或者尝试让竞争代理挑战彼此的推理逻辑，并通过比较来改进最终解决方案，基本上通过 MoE 构建错误/更正结构。 我的假设是，通过合成的“推理”多样本提示和轻量级代理协作，较小的模型可以在消费硬件上模仿 R1 的推理，同时几乎不需要任何训练成本，除了生成合成数据的初始成本之外。 无论如何，我打算在有空的时候测试这种方法。你怎么看？这是一条可行的道路，还是我遗漏了一些关键的东西？还是我从根本上误解了 R1？ 编辑：我应该在发布之前检查一下我输入的内容    提交人    /u/sebnadeau   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1id8j4o/d_building_a_poor_mans_reasoning_model/</guid>
      <pubDate>Wed, 29 Jan 2025 23:54:03 GMT</pubDate>
    </item>
    <item>
      <title>建立文本到图像扩散模型以实现受控的高质量图像生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1id8h1g/grounding_texttoimage_diffusion_models_for/</link>
      <description><![CDATA[本文提出了 ObjectDiffusion，该模型以对象名称和边界框为条件对文本到图像的扩散模型进行条件设定，以实现对对象在特定位置的精确渲染和放置。 ObjectDiffusion 将 ControlNet 的架构与 GLIGEN 的基础技术相结合，显著提高了受控图像生成的精度和质量。 所提出的模型优于目前在开源数据集上训练的最先进的模型，在精度和质量指标上取得了显着的提升。 ObjectDiffusion 可以合成多样化、高质量、高保真度的图像，并与指定的控制布局保持一致。 论文链接：https://www.arxiv.org/abs/2501.09194    由   提交  /u/Next_Cockroach_2615   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1id8h1g/grounding_texttoimage_diffusion_models_for/</guid>
      <pubDate>Wed, 29 Jan 2025 23:51:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在配备 20 核 GPU 的 Mac Mini M4 Pro 上对 BERT 和 Llama1B 进行微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1id06w2/d_finetuning_bert_llama1b_on_macmini_m4pro_with/</link>
      <description><![CDATA[如果有人尝试在配备 14 核 CPU 和 20 核 GPU 的 Mac Mini M4 Pro 上微调小型语言模型（如 BERT、RoBERTa 等）或 Llama 3.21B 等 LLM，请分享您的经验。我正在寻找三个问题的答案：  使用 GPU 进行训练的性能如何？ ANE 对训练有什么好处吗？ 使用 &#39;mps&#39; 作为 pytorch 进行 GPU 加速的设备是否简单？或者在非 Cuda 环境中是否存在与软件兼容性相关的其他挑战？  请分享您的经验。    提交人    /u/mayankbhagya   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1id06w2/d_finetuning_bert_llama1b_on_macmini_m4pro_with/</guid>
      <pubDate>Wed, 29 Jan 2025 18:05:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如今，BART 实现如何支持因果推理？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iczvpb/d_how_do_bart_implementations_holdup_for_causal/</link>
      <description><![CDATA[大家好， BART 似乎非常受欢迎，但我只能找到一年到几年前的提及（我可能找的不够仔细）。现在与其他模型相比如何？现在我们是否更倾向于采用更灵活的 BART 实现？ 非常感谢！    提交人    /u/Sea_Farmer5942   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iczvpb/d_how_do_bart_implementations_holdup_for_causal/</guid>
      <pubDate>Wed, 29 Jan 2025 17:53:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] EmbSum：基于 LLM 的内容推荐摘要</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icxl08/r_embsum_llmpowered_summarization_for/</link>
      <description><![CDATA[EmbSum 是一种新的基于内容的推荐框架，它利用 LLM 来增强个性化和效率。通过引入用户多嵌入 (UPE) 来捕获长期用户兴趣和内容多嵌入 (CPE) 来提供更丰富的项目表示，EmbSum 可以实现更准确和可解释的推荐。与传统模型在有限的历史编码方面遇到困难不同，EmbSum 可以处理多达 7,440 多个标记的参与序列，从而显著提高推荐质量。它还采用 LLM 监督的用户兴趣摘要，细化用户资料以实现更好的内容匹配。在 MIND 和 Goodreads 数据集上进行评估后，EmbSum 的表现优于基于 BERT 的基线，并且参数更少，这证明了其在推进个性化内容传递方面的潜力。 在此处完整阅读“EmbSum：利用大型语言模型的摘要功能进行基于内容的推荐”的完整论文评论： https://www.shaped.ai/blog/embsum-llm-powered-content-recommendations    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icxl08/r_embsum_llmpowered_summarization_for/</guid>
      <pubDate>Wed, 29 Jan 2025 16:20:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 修改已接受的 ICLR 论文以删除有缺陷的贡献？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icw8yf/d_revise_an_accepted_iclr_paper_to_remove_a/</link>
      <description><![CDATA[我的一篇论文被 ICLR 接受，该论文做出了两个主要贡献：(1) 强调了使用 方法 A 代替 简单基线 存在的问题；(2) 提出了一种替代方法，即 方法 B 来解决此问题。 但是，我最近发现了我报告方法 B 结果的方式存在问题。此问题影响了该研究领域（不仅仅是我的工作）通常报告结果的方式，使方法 B 看起来比方法 A 和简单基线都好。如果结果报告正确，方法 B 仍将优于方法 A，但只会与简单基线相匹配——这引发了一个问题：使用更复杂的方法是否合理。 鉴于此，我认为不应以当前形式发表这篇论文。与 AC 分享一个修订版本是否合适，其中仅包含第一个贡献而省略第二个贡献，并且仍发表该论文？    提交人    /u/NumberGenerator   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icw8yf/d_revise_an_accepted_iclr_paper_to_remove_a/</guid>
      <pubDate>Wed, 29 Jan 2025 15:24:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大多数机械可解释性研究仅以预印本或博客文章的形式发表？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icw2pi/d_why_is_most_mechanistic_interpretability/</link>
      <description><![CDATA[我越深入研究这个话题，就越发现常见的做法是将您的工作作为博客文章发布在论坛上，而不是在同行评审的出版物上发布。  这使得工作变得不那么值得信赖和可信。我发现 Anthropic 不会在会议上发表文章，因为您无法复制他们的工作。但是，仍然有大量的工作“仅”以博客文章的形式提供。     提交人    /u/Physical_Seesaw9521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icw2pi/d_why_is_most_mechanistic_interpretability/</guid>
      <pubDate>Wed, 29 Jan 2025 15:16:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发表论文 vs 获得博士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icpb9c/d_publications_vs_phd/</link>
      <description><![CDATA[这是一个相当简单的问题。 假设一个学历较低（学士或硕士）的人设法在三大会议（NeurIPS、ICML、ICLR）上发表了一些第一作者论文（让这个数字为 x）。 是否存在一个点，当 x 变得足够大时，博士学位就变得毫无意义，并且出于所有意图和目的，该人被视为合法的研究人员？ 换句话说，是否存在 x 的截止点，使得该个人的技能被视为与 R1 学校的 ML 平均博士学位相当？ 如果存在这样的截止点，它会是什么？    提交人    /u/throwaway-cs-grad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icpb9c/d_publications_vs_phd/</guid>
      <pubDate>Wed, 29 Jan 2025 08:31:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>