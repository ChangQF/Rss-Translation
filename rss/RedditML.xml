<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 13 Oct 2024 12:29:31 GMT</lastBuildDate>
    <item>
      <title>[R] 寻求识别不同语言中语义等价句子或实体的研究方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2mvpc/r_seeking_research_approaches_for_identifying/</link>
      <description><![CDATA[如何从研究和学术角度识别两种不同语言中具有相同语义含义的等效句子或实体？我正在寻找用于在多语言环境中查找语义等效对（无论它们是句子还是其他实体）的方法和方法。您能否建议我应该使用的相关研究领域、方法或特定关键字来搜索涉及跨语言语义相似性、句子对齐或跨语言实体等价性的学术论文？任何有关此上下文中常用的工具、模型或算法的指导也将不胜感激。    提交人    /u/eyup_kh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2mvpc/r_seeking_research_approaches_for_identifying/</guid>
      <pubDate>Sun, 13 Oct 2024 10:41:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 获得博士学位的现实性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2mugf/d_realism_of_landing_a_phd_offer/</link>
      <description><![CDATA[大家好！我是伦敦大学学院的研究生，正在攻读机器学习硕士学位，我很快将申请 2025 年秋季开始的博士课程。我将分享我的个人资料和我将申请的学校，并希望了解我所瞄准的实验室是否超出了我的能力范围。 我以一等（荣誉）成绩获得了新加坡南洋理工大学的数学和计算机科学本科学位，预计也将以一等（荣誉）成绩获得研究生学位。我对理论深度学习感兴趣——围绕损失曲面曲率、优化轨迹、学习动态和泛化的问题——这些都是数学密集型的研究领域。虽然我的课程大部分都是理论性的，并且与此类研究非常一致（按设计），但我的研究经历更具实验性。我在 ICML 上发表了一篇第三作者出版物，内容是我为学士论文项目所做的工作。这是一项相当理论化的工作，但我只负责实验。我还有 2 篇第一作者预印本——一篇关于 NLP 的实验性工作（旨在在 IEEE 上发表），另一篇关于图形 ML（旨在在顶级会议之一上发表），其中有相当多的理论部分，但没有我希望在博士学位上完成的工作那么多。 我的目标是进入 ETH、UCL、斯坦福、NYU、EPFL、哥伦比亚和普林斯顿的实验室（按优先顺序，其中一个是我的职位）。所有这些实验室都有非常成功的 PI（按引用次数计算），他们研究的主题与我的兴趣非常一致。我担心我看似无所不包的研究背景可能会让他们失望，但我希望我的成绩能让他们相信我精通理论。我希望我的导师能写出优秀的推荐信，因为他们在很多场合都对我表示赞赏。我希望写一份令人信服的研究陈述，但由于我几周前才开始阅读相关文献，所以最终可能不是那么完美。 我不介意与年轻的 PI 合作，只要我身边有一些研究人员在研究相关主题。在高级实验室，已经建立了一个网络，我可能先协助一些项目，然后再进行独立研究。现实地说，我是不是在自吹自擂？如果是这样，有人可以推荐一些年轻的 PI 从事上述研究课题，我可能更有机会加入他们的实验室吗？    提交人    /u/mio_11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2mugf/d_realism_of_landing_a_phd_offer/</guid>
      <pubDate>Sun, 13 Oct 2024 10:38:56 GMT</pubDate>
    </item>
    <item>
      <title>提出新颖的想法[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2jhhx/coming_up_with_novel_ideas_d/</link>
      <description><![CDATA[关于如何想出新颖的问题解决方案，您有什么想法吗？每次我以为自己有了一些想法，我的导师就会说“这太简单了”。许多方法以独特的方式将现有的构建块粘合在一起，但我很难想象人们如何想出既真正新颖又真正有效的东西。 有时，我读到一篇论文，我意识到这个想法实际上非常简单/直接，作者只是介绍了一个很酷的技巧。其他时候，我读到的东西介绍了一个非常晦涩的定理，或者他们注意到一些我只能梦想的东西。我倾向于前者，但由于新颖性有限，我对迄今为止所写的任何东西都不太自豪。疯狂的出版速度让我偏向“简单而有效”，这无济于事方法中的大部分工作是在获得 SOTA 后事后编写故事。    提交人    /u/like_a_tensor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2jhhx/coming_up_with_novel_ideas_d/</guid>
      <pubDate>Sun, 13 Oct 2024 06:25:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 信仰与命运：Transformers 作为模糊模式匹配器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2irug/d_faith_and_fate_transformers_as_fuzzy_pattern/</link>
      <description><![CDATA[       由    /u/jsonathan  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2irug/d_faith_and_fate_transformers_as_fuzzy_pattern/</guid>
      <pubDate>Sun, 13 Oct 2024 05:33:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] Arxiv 无法正常工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2hw07/d_arxiv_not_working/</link>
      <description><![CDATA[今天我发现有些论文无法加载，即使我尝试使用不同的浏览器和设备。尽管有时元数据和 html 论文可用，但 pdf 文件仍然无法正常工作。仅适用于某些论文。 从我的书签来看，大约 80% 的论文都无法正常工作。以下是我从书签中识别出的一些列表。 https://arxiv.org/pdf/1811.08489 https://arxiv.org/abs/2203.11933 https://arxiv.org/pdf/2306.11698.pdf https://arxiv.org/pdf/2310.03744.pdf https://arxiv.org/pdf/2302.00070.pdf https://arxiv.org/pdf/2410.07593 https://arxiv.org/pdf/2203.11933.pdf    提交人    /u/Shot-Button-9010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2hw07/d_arxiv_not_working/</guid>
      <pubDate>Sun, 13 Oct 2024 04:33:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 13 Oct 2024 02:15:21 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 增加Yolov8图像分割模型的数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2esrc/project_increasing_data_in_yolov8_image/</link>
      <description><![CDATA[大家好， 我正在训练一个 YOLOv8 图像分割模型。我想增加数据集。有没有办法在训练期间增加数据集。 例如，我过去训练过一个 CNN 模型，并且在训练期间为每个图像生成了 100 个增强图像以增加数据集。该 CNN 模型的数据增强参数如下所示。 datagen = ImageDataGenerator( rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, sher_range=0.1, zoom_range=0.1, Horizo​​ntal_flip=True, Vertical_flip = True, fill_mode=&#39;nearest&#39; )  有没有办法用上面相同的参数对 YOLO 图像分割模型（每个图像生成 100 个图像）做同样的事情。我知道我必须在 .yaml 文件中为增强参数输入自定义值，但是，如果有人能为我提供信息，说明我需要在 .yaml 文件中更改哪些自定义参数才能实现上述配置，那就太好了。此外，如果有办法在训练期间为每个图像生成 100 张图像，标签中 .txt 文件中的多边形坐标是否会根据应用的增强参数自动调整。 如果您需要更多说明，请告诉我。 谢谢    提交人    /u/sahil_m00   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2esrc/project_increasing_data_in_yolov8_image/</guid>
      <pubDate>Sun, 13 Oct 2024 01:27:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找可以在浏览器中完全本地运行的轻量级嵌入模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2ep9v/d_looking_for_lighweight_embeddings_model_that/</link>
      <description><![CDATA[我广泛使用了 OpenAI 嵌入端点和 Google 的 Universal Sentence Encoder (USE)。我正在为那些不希望将数据发送到*任何地方*的人开展一个项目。因此，我正在尝试看看我是否可以想出一个完全本地的实现，我可以在其中为他们存储文本，然后完全在本地对该数据进行余弦相似度搜索。我希望找到一个轻量级的嵌入模型，它可以严格在典型 PC 上的浏览​​器中运行，并且在激活时不会下载任何模型，因为所有这些都打破了隐私约束。 有人见过类似的东西吗？如果有，请留下链接。我的网络搜索和 ChatGPTPlus 讨论尚未取得成果。    提交人    /u/vengeful_bunny   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2ep9v/d_looking_for_lighweight_embeddings_model_that/</guid>
      <pubDate>Sun, 13 Oct 2024 01:21:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解流匹配</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2dpm8/d_understanding_flow_matching/</link>
      <description><![CDATA[我有点难以理解流匹配论文。是否有一些课程可以让我更好地理解这一点。 就上下文而言，我相当了解 ddpm，并在一定程度上了解 ddim。但是，我无法理解它的 ODE 方面。 流匹配论文讨论了很多关于矢量场和 ODE 的内容。如果您能推荐一篇论文/课程来理解这方面的内容，我将不胜感激。YouTube 上有一些关于统计力学的课程。这是否相关，或者考虑到我可以理解变分贝叶斯，是否有更好的起点？ TIA    提交人    /u/themathstudent   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2dpm8/d_understanding_flow_matching/</guid>
      <pubDate>Sun, 13 Oct 2024 00:25:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML 项目的反馈：使用 Transformers 改进蚁群优化算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g21loo/d_feedback_on_ml_project_using_transformers_to/</link>
      <description><![CDATA[我目前正在从事一个个人项目，尝试构建一个改进版本的蚁群优化算法。 在运行算法之前，我使用位置编码变压器神经网络来预测最佳信息素矩阵。 改进的蚁群优化算法使用位置编码变压器神经网络输出的信息素矩阵进行初始化，该网络使用来自普通蚁群优化算法的信息素矩阵数据进行训练。 为了分析算法的改进，我让改进的 ACO 与普通 ACO 一起运行不同地图大小的多次迭代，计算每个算法的最佳运行，并计算 p 值以验证改进的算法是否具有统计意义。 到目前为止，增强型 ACO 显示出令人满意的结果，当节点大小为 30 和 35 时，p 值分别为 0.06 和 0.05。  但是，我的目标是在更大范围的节点大小中实现显著性 (p &lt; 0.05)。 我将不胜感激任何反馈！ 项目链接：https://github.com/ronantakizawa/improvedaco/blob/main/ronan_acotransformer_experiment.ipynb    提交人    /u/SafeSignificance8840   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g21loo/d_feedback_on_ml_project_using_transformers_to/</guid>
      <pubDate>Sat, 12 Oct 2024 14:42:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] GSM-Symbolic：理解大型语言模型中数学推理的局限性（Apple）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1wbir/r_gsmsymbolic_understanding_the_limitations_of/</link>
      <description><![CDATA[arXiv:2410.05229 [cs.LG]: https://arxiv.org/abs/2410.05229 Iman Mirzadeh、Keivan Alizadeh、Hooman Shahrokhi、Oncel Tuzel、Samy Bengio、Mehrdad Farajtabar - Apple TechCrunch - Devin Coldewey：研究人员质疑人工智能的“推理”能力，因为模型在解决数学问题时会遇到一些细微的变化：https://techcrunch.com/2024/10/11/researchers-question-ais-reasoning-ability-as-models-stumble-on-math-problems-with-trivial-changes/ 共同作者之一 Mehrdad Farajtabar 在 X 上的这个帖子中分解了这篇论文：https://x.com/MFarajtabar/status/1844456880971858028    由   提交  /u/Nunki08   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1wbir/r_gsmsymbolic_understanding_the_limitations_of/</guid>
      <pubDate>Sat, 12 Oct 2024 09:20:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 奖励进展：扩展 LLM 推理的自动化流程验证器（来自 Deepmind 的研究）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1uf90/r_rewarding_progress_scaling_automated_process/</link>
      <description><![CDATA[摘要：使用过程奖励模型 (PRM) 是改进大型语言模型推理的一种有前途的办法。PRM 在多步推理跟踪的每个步骤中提供反馈，与仅在最后一步提供反馈的结果奖励模型 (ORM) 相比，可能改善信用分配。然而，收集密集的、每步的人工标签是不可扩展的，并且迄今为止，从自动标记的数据训练 PRM 只带来了有限的收益。为了通过针对 PRM 运行搜索或将其用作强化学习 (RL) 的密集奖励来改进基础策略，我们问：“我们应该如何设计过程奖励？”。我们的主要见解是，为了有效，步骤的过程奖励应该衡量进展：在采取该步骤之前和之后，未来产生正确响应的可能性的变化，对应于 RL 中的步骤级优势概念。至关重要的是，应该在不同于基础策略的证明者策略下衡量这一进展。我们从理论上描述了一组好的证明器，我们的结果表明，优化此类证明器的过程奖励可改善测试时搜索和在线 RL 中的探索。事实上，我们的表征表明，弱证明器策略可以显著改善更强大的基础策略，我们也通过经验观察到了这一点。我们通过训练过程优势验证器 (PAV) 来预测此类证明器下的进度，从而验证了我们的说法，并表明与 ORM 相比，针对 PAV 的测试时搜索准确率提高了 8% 以上，计算效率提高了 1.5-5 倍。与 ORM 相比，具有来自 PAV 的密集奖励的在线 RL 实现了首批结果之一，样本效率提高了 5-6 倍，准确率提高了 6% 以上。    提交人    /u/DickMasterGeneral   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1uf90/r_rewarding_progress_scaling_automated_process/</guid>
      <pubDate>Sat, 12 Oct 2024 06:52:02 GMT</pubDate>
    </item>
    <item>
      <title>核技巧（RKHS）应用于逻辑：语义空间框架中的逻辑属性和量词</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1sfz2/the_kernel_trick_rkhs_applied_to_logic_logical/</link>
      <description><![CDATA[        由    /u/musescore1983   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1sfz2/the_kernel_trick_rkhs_applied_to_logic_logical/</guid>
      <pubDate>Sat, 12 Oct 2024 04:33:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么看起来谷歌的 TPU 对 nVidia 的 GPU 不构成威胁？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1okem/d_why_does_it_seem_like_googles_tpu_isnt_a_threat/</link>
      <description><![CDATA[尽管谷歌在其许多内部 AI 工作中使用了 TPU，但似乎并没有像 nVidia 的 GPU 那样推动其收入增长。这是为什么？为什么拥有自己的 AI 设计的处理器没有像 nVidia 那样对他们有所帮助，为什么所有其他专注于 AI 的公司似乎仍然只想在 nVidia 芯片上运行他们的软件……即使他们使用的是谷歌数据中心？    提交人    /u/kugelblitz_100   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1okem/d_why_does_it_seem_like_googles_tpu_isnt_a_threat/</guid>
      <pubDate>Sat, 12 Oct 2024 00:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>