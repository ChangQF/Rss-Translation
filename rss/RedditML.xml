<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 15 Jan 2025 21:14:27 GMT</lastBuildDate>
    <item>
      <title>[R] 在空间中一边想象一边推理：思维的多模态可视化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i279gb/r_imagine_while_reasoning_in_space_multimodal/</link>
      <description><![CDATA[摘要： 思维链 (CoT) 提示已被证明对于增强大型语言模型 (LLM) 和多模态大型语言模型 (MLLM) 中的复杂推理非常有效。然而，它在复杂的空间推理任务中却举步维艰。尽管如此，人类的认知不仅限于语言，还具有用文字和图像思考的非凡能力。受此机制的启发，我们提出了一种新的推理范式，即多模态思维可视化 (MVoT)。它通过生成其推理轨迹的图像可视化来实现 MLLM 中的视觉思维。为了确保高质量的可视化，我们在自回归 MLLM 中引入了标记差异损失。这项创新显着提高了视觉连贯性和保真度。我们通过几个动态空间推理任务验证了这种方法。实验结果表明，MVoT 在各个任务中都表现出了竞争力。此外，它在 CoT 失败的最具挑战性的场景中表现出稳健可靠的改进。最终，MVoT 为复杂的推理任务建立了新的可能性，在这些任务中，视觉思维可以有效地补充语言推理。 Arxiv 链接：https://arxiv.org/pdf/2501.07542    提交人    /u/imadade   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i279gb/r_imagine_while_reasoning_in_space_multimodal/</guid>
      <pubDate>Wed, 15 Jan 2025 20:43:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] HCT（造血细胞移植）生存率：您有任何领域专业知识吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i26ccb/d_hct_hematopoietic_cell_transplantation_survival/</link>
      <description><![CDATA[过去 6 周，我一直在为这个 Kaggle 竞赛工作。我的问题是，我已经没有主意了，尝试了从 TTA（测试时间增强）到模型架构的所有方法。 我最好的解决方案是针对生存模型估计的风险分数目标训练 LightGBM、CatBoost、神经网络：Kaplan-Meier、Nelson-Aalen 和 CoxPH 以及另外 2 个目标，它们是事件发生时间列的转换。 唯一仍是“未知”的领域是特定于领域的东西。 我的问题是，这个 subreddit 上是否有人专门从事生存分析、HCT 生存、两者或类似领域的工作，并且拥有超越纯 ML 方法的领域专业知识（哪些模型效果最好、哪种 CV 方案等）。    提交人    /u/TechNerd10191   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i26ccb/d_hct_hematopoietic_cell_transplantation_survival/</guid>
      <pubDate>Wed, 15 Jan 2025 20:02:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我如何发现并修复微软 Phi-4 模型中的 4 个错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i23zbo/p_how_i_found_fixed_4_bugs_in_microsofts_phi4/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i23zbo/p_how_i_found_fixed_4_bugs_in_microsofts_phi4/</guid>
      <pubDate>Wed, 15 Jan 2025 18:22:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] JAIR 与模式识别期刊之间的困境</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i236iq/d_dilemma_bw_jair_vs_pattern_recognition_journal/</link>
      <description><![CDATA[大家好， 我是一名本科生，我想将我的手稿提交给这两家杂志中的任何一家；这项工作是关于机器学习中隐私和可解释性的相互作用（如果要求，我很乐意向您发送相同的 arXived 版本）。我之前曾在 EMNLP 的一个非常有名望的研讨会上发表过文章，并了解到如今 ML 主要是以会议为中心的学科。我想知道这两家杂志中的哪一家更适合提交我的作品（由于篇幅和范围，我这次无法提交给会议）。我不能将它提交给 tmlr，直到它被 Scopus 索引，目前不考虑 AIJ 和 Machine Learning Journal。 我只是想确保如果论文被接受，我希望它至少可以与边缘 A* 论文相媲美（就所谓的会议声望而言）。此外，如果您有任何其他建议，请告诉我；我对期刊还不熟悉，我很感激您的意见。 附注：我的指导老师由于影响因子更高，略微更喜欢 PR 而不是 JAIR，但尽管如此，他还是开放 JAIR 或任何其他 Scopus 索引期刊，只要它至少与边缘 A* 或非常强的 A 会议论文相当。    提交人    /u/RepresentativeOk7956   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i236iq/d_dilemma_bw_jair_vs_pattern_recognition_journal/</guid>
      <pubDate>Wed, 15 Jan 2025 17:49:14 GMT</pubDate>
    </item>
    <item>
      <title>你的论文有多少是由人工智能撰写的？这是否不道德？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i22zdu/what_percent_of_your_paper_is_written_by_ai_and/</link>
      <description><![CDATA[大家好， 刚刚开始为研究写作做出贡献，以前我只是用来实验和处理结果、表格和图表。 显然，使用人工智能生成论文内容在很多方面都是不道德和错误的。但是用它来纠正你的语法和理解呢。从技术上讲，它也被认为是人工智能编写的，但至少在文献综述、介绍和实验描述中这样做可以吗？ 说实话，我喜欢写作，当我问人工智能（chatgpt 和其他人）时，我发现它更容易阅读和解释，我认为这对社区有好处，另一方面，它可能被许多人认为是不道德的。 当我对过去 1 年用作参考的许多论文运行“AI 文本检测器”时，我通常会得到 50-70％ 的分数。  大家觉得怎么样？    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i22zdu/what_percent_of_your_paper_is_written_by_ai_and/</guid>
      <pubDate>Wed, 15 Jan 2025 17:41:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 工作推荐系统中可解释的 GNN：应对多利益相关者的挑战</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i21t17/r_explainable_gnns_in_job_recommender_systems/</link>
      <description><![CDATA[可解释的人工智能能否平衡工作推荐系统中相互竞争的需求？由 GNN 提供支持的 OKRA 等模型可提供针对利益相关者的见解 - 为候选人提供文字解释、为招聘人员提供技能匹配以及为公司提供可视化。它们解决了偏见（例如农村代表性不足）和挑战，例如将解释与源数据（简历、职位空缺）相结合。  未来的方向重点是完善解释的连贯性、公平性指标和现实世界的验证，推动可解释的多利益相关者人工智能走向公平、情境感知的工作匹配。 我们在这里解读Roan Schellingerhout的“可解释的多利益相关者工作推荐系统”：https://www.shaped.ai/blog/decoding-job-recommendations-the-future-of-explainable-multi-stakeholder-ai    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i21t17/r_explainable_gnns_in_job_recommender_systems/</guid>
      <pubDate>Wed, 15 Jan 2025 16:51:44 GMT</pubDate>
    </item>
    <item>
      <title>Kaggle 数据集：其中一个输入特征与目标的相关性 >0.99，但大多数/所有笔记本（20+）并不关心？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i210hp/kaggle_dataset_one_of_the_input_features_has_a/</link>
      <description><![CDATA[此数据集（不会链接到这里，因为我不想与我的 kaggle 和 reddit 关联）包含一些输入特征（5-6）用于预测一个目标值。 但其中一个特征基本上与目标 (&gt;0.99) 完全线性相关。 一个例子是来自只有一种卡车型号的卡车运输公司的数据： 目标：卡车燃油消耗量/年特征：驾驶员年龄、轮胎类型、卡车年龄、行驶距离/年 显然，平均燃油消耗量与行驶里程数成线性比例。我的意思是，通常您只需使用它来计算燃油/距离等新目标。 然而，没有一个人/笔记本做过这种规范化。因此，每个人的模型都有 &gt;.99 的准确率，因为这个特征淹没了其他所有特征。 其他人是否注意到了这一点：代码看起来越来越好（数据加载、训练多种类型的模型），这可能要归功于 LLM。但决策过程往往很糟糕？    提交人    /u/ToThePastMe   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i210hp/kaggle_dataset_one_of_the_input_features_has_a/</guid>
      <pubDate>Wed, 15 Jan 2025 16:17:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] MathReader：使用 OCR 和经过微调的 T5 的数学文档文本转语音系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1xgp2/r_mathreader_a_texttospeech_system_for/</link>
      <description><![CDATA[有趣的新文本转语音系统，通过结合 OCR 和语言模型来处理数学内容。关键创新是将数学符号视为需要翻译的专用语言，使用多阶段管道将方程式转换为自然语音。 技术方法：* 专门针对数学文档训练的自定义 OCR 模型 * 针对数学到文本翻译进行微调的基于 T5 的语言模型 * 三阶段管道：识别 → 翻译 → 合成 * 与 LaTeX 解析集成以处理复杂的数学排版 主要结果：* 数学表达式识别准确率为 95% * 成功处理包括分数、积分、矩阵在内的复杂符号 * 用户测试显示优于现有的数学 TTS 系统 * 自然语言输出与人类描述相匹配 我认为这可能对使技术教育更容易获得产生影响。能够将数学文档转换为清晰的语音为学习和处理技术内容开辟了一些可能性。 OCR 和 NLP 的结合似乎是一种强大的方法，它可以从数学扩展到具有专门符号的其他技术领域。 我看到了上下文相关符号和复杂证明的一些限制，但这些似乎是未来工作的自然领域，而不是方法中的根本缺陷。 TLDR：新的 TTS 系统结合了专门的 OCR 和语言模型，将数学文档转换为自然语音，在数学识别中实现 95% 的准确率并产生类似人类的描述。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1xgp2/r_mathreader_a_texttospeech_system_for/</guid>
      <pubDate>Wed, 15 Jan 2025 13:33:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 泰坦：在考试时学会记忆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1lg6o/r_titans_learning_to_memorize_at_test_time/</link>
      <description><![CDATA[摘要：“十多年来，人们进行了广泛的研究，以研究如何有效地利用循环模型和注意力机制。虽然循环模型旨在将数据压缩到固定大小的内存（称为隐藏状态），但注意力机制允许关注整个上下文窗口，捕获所有标记的直接依赖关系。然而，这种更准确的依赖关系建模需要二次成本，从而将模型限制在固定长度的上下文中。我们提出了一种新的神经长期记忆模块，该模块可以学习记忆历史背景，并帮助注意力机制在利用过去很久的信息的同时关注当前背景。我们表明，这种神经记忆具有快速并行训练的优势，同时保持快速推理。从记忆的角度来看，我们认为注意力机制由于其有限的上下文但准确的依赖关系建模而表现为短期记忆，而神经记忆由于其记忆数据的能力而表现为长期、更持久的记忆。基于这两个模块，我们引入了一个名为 Titans 的新架构系列，并提出了三种变体来解决如何有效地将内存整合到这个架构中。我们在语言建模、常识推理、基因组学和时间序列任务上的实验结果表明，Titans 比 Transformers 和最近的现代线性循环模型更有效。与基线相比，它们还可以有效地扩展到大于 2M 的上下文窗口大小，并且在大海捞针任务中具有更高的准确率。” Arxiv: https://arxiv.org/abs/2501.00663    提交人    /u/imadade   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1lg6o/r_titans_learning_to_memorize_at_test_time/</guid>
      <pubDate>Wed, 15 Jan 2025 00:51:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer²：自适应法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1l8d4/r_transformer²_selfadaptive_llms/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2501.06252 摘要 自适应大型语言模型 (LLM) 旨在解决传统微调方法带来的挑战，这些方法通常计算量大，处理各种任务的能力也比较静态。我们引入了 Transformer²，这是一种新颖的自适应框架，它通过选择性地调整权重矩阵的奇异分量，实时调整 LLM 以适应看不见的任务。在推理过程中，Transformer² 采用两遍机制：首先，调度系统识别任务属性，然后使用强化学习训练的任务特定“专家”向量进行动态混合，以获得针对传入提示的目标行为。我们的方法优于 LoRA 等普遍存在的方法，参数更少，效率更高。Transformer² 展示了跨不同 LLM 架构和模态的多功能性，包括视觉语言任务。Transformer² 代表了一次重大飞跃，为增强 LLM 的适应性和任务特定性能提供了可扩展、高效的解决方案，为真正动态、自组织的 AI 系统铺平了道路。 博客摘要：https://sakana.ai/transformer-squared/ GitHub：https://github.com/SakanaAI/self-adaptive-llms    提交人    /u/hardmaru   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1l8d4/r_transformer²_selfadaptive_llms/</guid>
      <pubDate>Wed, 15 Jan 2025 00:41:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们如何在 ArXiv 中搜索论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1hz8c/d_how_are_people_searching_for_papers_in_arxiv/</link>
      <description><![CDATA[您好， 我想知道人们在 ArXiv 中搜索或发现新论文的通常方式是什么？您只使用他们的搜索引擎吗？有什么提示/提示吗？    提交人    /u/TheDevilIsInDetails   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1hz8c/d_how_are_people_searching_for_papers_in_arxiv/</guid>
      <pubDate>Tue, 14 Jan 2025 22:11:39 GMT</pubDate>
    </item>
    <item>
      <title>情绪分类和分析的预训练模型 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1act4/pretrained_models_for_sentiment_classification/</link>
      <description><![CDATA[嗨。我正在做一个项目，需要我从英文文本中识别情绪，然后将这些情绪量化为百分比。我需要在文本上运行六个模型，然后比较分类。 到目前为止，我已经探索了 Huggingface 中的一些基于 BERT 和 RoBERTa 的模型，这些模型使用 Google 提供的 GoEmotion 数据集进行训练。我很好奇，有没有更好的模型是我遗漏的？请留下一些可以给出一些良好结果的预训练模型的名称。 TIA！    提交人    /u/Big_Baguette17   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1act4/pretrained_models_for_sentiment_classification/</guid>
      <pubDate>Tue, 14 Jan 2025 16:46:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师与人工智能研究科学家：未来前景？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i18421/d_machine_learning_engineer_vs_ai_research/</link>
      <description><![CDATA[有人说，人工智能研究科学家（博士学位持有者）几乎是不可替代的，因为他们能够突破知识的界限，提出突破性的方法和算法。但让我们面对现实吧——科技公司不需要大量的研究人员，尤其是如果他们的工作不能直接提高利润的话。 另一方面，机器学习工程师是那些将这些算法付诸实践、扩展系统和保持生产管道运行的人——所有这些都直接带来了 $$$。这就是为什么有些人认为未来 MLE 角色的增长速度会比人工智能研究科学家角色更快。 你怎么看？你是否看到过哪些趋势或经验表明其中一个角色在未来会更受欢迎？顺便说一下，我目前是一名博士生。 为了公平比较，我们假设这两个角色都在 FAANG 公司。   由    /u/wonder-why-I-wonder  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i18421/d_machine_learning_engineer_vs_ai_research/</guid>
      <pubDate>Tue, 14 Jan 2025 15:08:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 12 Jan 2025 16:00:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>