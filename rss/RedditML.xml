<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Wed, 28 Feb 2024 18:16:15 GMT</lastBuildDate>
    <item>
      <title>“[讨论]”使用机器学习中的分类解决一个简单的问题需要多少数据？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2cr0i/discussion_how_much_data_is_needed_to_solve_a/</link>
      <description><![CDATA[我目前正在涉足人工智能及其对企业的价值。我发现很难弄清楚训练模型实际上需要多少数据。 多少数据构成一个数据点？ 我们实际上需要多少数据需要说我们有一个数据点吗？  解决一个简单的问题需要多少数据点？  例如，如果我想解决垃圾邮件问题，我需要将多少封电子邮件标记为垃圾邮件或非垃圾邮件才能成功训练模型来识别垃圾邮件？    由   提交 /u/Goldiegoodie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2cr0i/discussion_how_much_data_is_needed_to_solve_a/</guid>
      <pubDate>Wed, 28 Feb 2024 18:04:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我可以在贝叶斯优化中使用机器学习模型作为黑盒函数吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2c8up/d_can_i_use_machine_learning_model_as_a_black_box/</link>
      <description><![CDATA[就我的研究而言（免责声明，我不是数据科学家，也不是该领域的专业人士），贝叶斯优化可以为您提供最佳的输入组合最大化或最小化黑盒功能对吗？假设我有 f(x,y,z)，那么使用贝叶斯优化可以为我提供函数最大或最小输出的 x、y 和 z 值。问题：由于现实世界场景并没有真正为您提供数学方程中的黑盒函数，因此我是否可以使用机器学习模型来代替函数？假设我有需要多个输入 (x,y,z) 的 ML 模型，并且它输出 O，我想我不使用函数，而是在贝叶斯优化中简单地使用 ML 模型？这可能吗？这样做的优点和缺点是什么？到底能不能实现？我可能需要您对此的建议。   由   提交 /u/MaterialDiver8105   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2c8up/d_can_i_use_machine_learning_model_as_a_black_box/</guid>
      <pubDate>Wed, 28 Feb 2024 17:45:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] SpeechBrain 工具包 1.0 版已发布！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b28j2o/r_the_speechbrain_toolkit_version_10_is_out/</link>
      <description><![CDATA[亲爱的 Reddit 社区， 三年前，我们在此 Reddit 子版块中宣布了 SpeechBrain 的测试版。今天，我们很高兴地宣布 SpeechBrain 1.0 正式发布。这一里程碑与之前的版本相比有许多增强和进步。 这是真正的社区努力（PyPi 每月 20 万次下载），我们非常高兴和自豪能够领导它。&lt; /strong&gt; 您可以在此处探索我们改进的全面摘要：SpeechBrain 1.0 摘要. 在这些变化中，我们在语音识别方面取得了重大改进，通过与 K2 集成有限状态传感器、CTC 解码、n- 增强了搜索功能。克重评分和法学硕士整合。此外，我们还引入了新型模型，例如 Streamable Conformer Transducers、Branchformers 和 Hyper-conformer 等，以提高性能和速度。您现在还可以轻松使用大语言模型 (LLM) 并使用我们的数据对其进行微调，或者简单地使用它们来重新评分 ASR 假设。 此外，SpeechBrain 现在支持更广泛的任务：&lt;语音、音频、文本和脑电图处理。我们改进了与 HF 模型的集成，使从 HF 导入任何模型变得更加容易。我们实施了现代技术和模型，包括持续学习、扩散模型、超网络、贝叶斯 ASR 等。 我们创建了一个新的基准存储库，其中包含用于自我监督学习 (MP3S) 的有用基准， EEG 处理 (SpeechBrain-MOABB) 和持续学习新语言 (CL-MASR)。 在提供的 Colab 上可以找到更多新奇事物。 敬请期待未来因为我们前面有宏伟的计划。 当然，非常感谢我们的慷慨赞助商 HuggingFace、OVHCloud 和 ViaDialog，以及我们在 Concordia、Avignon、Mila、剑桥大学和三星的合作伙伴，以及所有我们了不起的贡献者！  此致， SpeechBrain 核心团队   由   提交 /u/TParcollet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b28j2o/r_the_speechbrain_toolkit_version_10_is_out/</guid>
      <pubDate>Wed, 28 Feb 2024 15:20:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于用于构建现代 CV 算法的 CNN 块的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b27e4t/d_question_about_cnn_blocks_used_for_building/</link>
      <description><![CDATA[大家好，我希望更好地了解卷积块的使用，例如YOLOv8的瓶颈块、SPPF和C2f块，它们是如何构造的？为什么它们是这样建造的？是什么导致创作者选择使用这种层的顺序？等等。 我认为我对每个 CNN 层的作用（Conv、Pooling、FC）有深入的了解，但这些块的概念暗示了我。 任何解释或资源非常感谢。   由   提交 /u/TheWingedCucumber   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b27e4t/d_question_about_cnn_blocks_used_for_building/</guid>
      <pubDate>Wed, 28 Feb 2024 14:31:05 GMT</pubDate>
    </item>
    <item>
      <title>[D]：为博士申请构建 NLP 研究概况（无先前出版物）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b26roc/d_building_nlp_research_profile_for_phd/</link>
      <description><![CDATA[我最近申请了 CMU 的 LTI NLP 博士项目，但没有被录取。我了解自己的缺点：研究经验有限：硕士CS背景，5年行业经验（软件工程师、数据分析师）。基础NLP项目：硕士课程（高级ML、NLP）和基础项目（情感分析、音乐流派分类）。 没有研究出版物：我承认顶级项目中出版物的重要性。 鉴于申请周期即将到来（申请于 2024 年 9 月开始），我渴望加强自己的个人资料。由于顶级会议已经过了提交截止日期（并不是说我正准备发表我的作品，哈哈），我如何才能最好地利用这段时间成为前 10 名 NLP 博士项目的有竞争力的申请者？我正在寻找关于建立我的研究档案的建议，包括： 独立研究机会：除了会议出版物之外，是否有其他途径获得研究经验？ 技能发展：我应该重点获取哪些具体的 NLP 技能或知识？ 与研究人员建立联系：我如何与 NLP 研究人员建立联系，以获得潜在的研究经验或指导？ 如果来自社区的任何见解或建议，我们将不胜感激！ &lt;!-- SC_ON - -&gt;  由   提交/u/Puzzleheaded_Big_242   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b26roc/d_building_nlp_research_profile_for_phd/</guid>
      <pubDate>Wed, 28 Feb 2024 14:02:33 GMT</pubDate>
    </item>
    <item>
      <title>形状后缀 - Noam Shazeer 的良好编码风格 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b26lvf/shape_suffixes_good_coding_style_by_noam_shazeer_d/</link>
      <description><![CDATA[https: //medium.com/@NoamShazeer/shape-suffixes-good-coding-style-f836e72e24fd   由   提交 /u/convexstrictly   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b26lvf/shape_suffixes_good_coding_style_by_noam_shazeer_d/</guid>
      <pubDate>Wed, 28 Feb 2024 13:55:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 互操作性在端到端数据治理中的作用：由数据开发者平台实施</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b26106/d_role_of_interoperability_in_endtoend_data/</link>
      <description><![CDATA[以下是该帖子的一些关键要点： 💠 𝐈𝐧𝐭𝐞𝐫𝐨𝐩𝐞𝐫𝐚𝐛𝐢𝐥𝐢𝐭𝐲 𝐅𝐮𝐧𝐝 𝐚𝐦𝐞𝐧𝐭𝐚𝐥𝐬：互操作性允许数据堆栈中的不同实体有效地通信。数据开发人员平台作为统一的核心，通过与现有基础设施集成来促进互操作性。  💠𝐈𝐦𝐩𝐥𝐞𝐦𝐞𝐧𝐭𝐢𝐧𝐠𝐈𝐧𝐭𝐞𝐫𝐨𝐩𝐞𝐫𝐚𝐛𝐢𝐥𝐢𝐭 𝐲：DDP 实现了由内而外和由外而内的互操作性。由内而外的互操作性触发外部实体中的事件，而由外而内的互操作性允许平台摄取信息并对来自外部源的事件触发器采取行动。  💠𝐈𝐧𝐭𝐞𝐫𝐨𝐩𝐞𝐫𝐚𝐛𝐢𝐥𝐢𝐭𝐲𝐢𝐧𝐆𝐨𝐯𝐞𝐫𝐧𝐚𝐧𝐜 𝐞：治理模型是通过策略决策点（PDP）和策略执行点（PEP）来实现的。为整个生态系统建立一个单一的 PDP 以避免政策冲突至关重要。  分享你的想法！  𝐑𝐞𝐚𝐝 𝐭𝐡𝐞 𝐞𝐧𝐭𝐢𝐫𝐞 𝐛𝐥𝐨𝐠 𝐡𝐞𝐫𝐞：https://moderndata101.substack .com/p/role-of-interoperability-in-end-to   由   提交/u/growth_man  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b26106/d_role_of_interoperability_in_endtoend_data/</guid>
      <pubDate>Wed, 28 Feb 2024 13:26:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 生产级 RAG 应用程序真正包含什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b244vc/d_what_does_a_production_level_rag_application/</link>
      <description><![CDATA[我已经完成了 RAG 的研究，实现了一些简单的 RAG 教程，并且我知道我现在想要实现的高级 RAG 技术。但我真的不知道正确的应用程序工作流程是什么样的。就像在简单的 RAG 教程中实现这 7 行代码，然后添加混合搜索或重新排名等内容，以及实际构建生产级 RAG 应用程序之间有什么区别？这个“工作流程”是什么样的？    由   提交/u/Aggravating-Floor-38   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b244vc/d_what_does_a_production_level_rag_application/</guid>
      <pubDate>Wed, 28 Feb 2024 11:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 更高层需要更多 LoRA 专家</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b23dfx/r_higher_layers_need_more_lora_experts/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.08562 代码：https://github .com/GCYZSL/MoLA 摘要：  参数高效调整（PEFT）技术，例如低秩适应（ LoRA）提供了大型语言模型的训练效率，但它们对模型性能的影响仍然有限。最近的努力将 LoRA 和专家混合 (MoE) 相结合，以提高 PEFT 方法的性能。尽管取得了令人鼓舞的成果，但利用 MoE 提高 LoRA 效率的研究仍处于早期阶段。最近的研究表明，教育部架构中的专家具有不同的优势，并且也表现出一些冗余。这个说法是否也适用于参数高效的 MoE？在本文中，我们介绍了一种新颖的参数高效 MoE 方法，MoE-Lo 与 L分层专家 A 分配 (MoLA) 用于基于 Transformer 的模型，其中每个模型层都可以灵活地雇用不同数量的 LoRA 专家。我们研究了几种具有不同分层专家配置的架构。在六个著名的 NLP 和常识 QA 基准上进行的实验表明，与所有基准相比，MoLA 实现了相同或更好的性能。我们发现，将更多的 LoRA 专家分配到更高层可以进一步增强具有一定数量专家的模型的有效性。由于参数少得多，这种分配策略的性能优于每层专家数量相同的设置。这项工作可以作为一种即插即用的参数高效调整方法广泛应用于各种应用。该代码可在 此 https URL 处获取。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b23dfx/r_higher_layers_need_more_lora_experts/</guid>
      <pubDate>Wed, 28 Feb 2024 10:59:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 1 位 LLM 时代：所有大型语言模型均采用 1.58 位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b22izk/r_the_era_of_1bit_llms_all_large_language_models/</link>
      <description><![CDATA[https://arxiv.org/abs/2402.17764 摘要  最近的研究，例如 BitNet，正在为 1 位大型语言模型的新时代铺平道路（法学硕士）。在这项工作中，我们引入了一个 1 位 LLM 变体，即 BitNet b1.58，其中 LLM 的每个参数（或权重）都是三元的 {-1, 0, 1}。它在困惑度和最终任务性能方面与具有相同模型大小和训练令牌的全精度（即 FP16 或 BF16）Transformer LLM 相匹配，同时在延迟、内存、吞吐量、和能源消耗。更深刻的是，1.58 位 LLM 定义了新的扩展法则和配方，用于培训高性能且经济高效的新一代 LLM。此外，它还实现了一种新的计算范例，并为设计针对 1 位 LLM 优化的特定硬件打开了大门。    由   提交/u/Civil_Collection7267   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b22izk/r_the_era_of_1bit_llms_all_large_language_models/</guid>
      <pubDate>Wed, 28 Feb 2024 10:03:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在生产中训练模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b21zfh/d_trainining_a_model_in_production/</link>
      <description><![CDATA[我是一名硕士生，被指派做我的第一个半大型项目。我面临两个主要问题，想知道它们在现实世界中是如何解决的。 第一个是，我们只看到了 jupyter 笔记本，但是随着项目的发展，它们变得越来越不可用，它们不能很好地与脚本配合使用，因为每个新的修改都需要重新启动内核（我知道有一个扩展，但我发现它不够可靠）。另一个问题是我的计算能力较低。 我的想法是准备模型并将其定义（.py 脚本）发送给为我进行培训的云提供商，例如 aws（？） 。它是否正确？我错过了什么吗？   由   提交 /u/Puddino   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b21zfh/d_trainining_a_model_in_production/</guid>
      <pubDate>Wed, 28 Feb 2024 09:26:48 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 动力学模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b213uf/discussion_dynamical_models/</link>
      <description><![CDATA[嘿朋友们，我写了一篇关于动态模型的博客文章——关于 AGI 有希望的研究方向的一些想法。我们的假设是，未来的研究应该集中在具有稳定、长期、不断发展和不断优化动态的训练系统上，使用专门的架构和大规模的训练方法。希望有人会觉得它们很有趣。 第 1 部分：https://medium.com/@tommyx058/cdda161fa7f9 第 2 部分：https://medium.com/@tommyx058/e226eee07627   由   提交 /u/TommyX12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b213uf/discussion_dynamical_models/</guid>
      <pubDate>Wed, 28 Feb 2024 08:27:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用超过 10,000 个 GPU 进行 LLM 训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1m0sy/r_llm_training_with_10000_gpus/</link>
      <description><![CDATA[LLM 训练超过 10,000 个 GPU！ https://arxiv.org/abs/2402.15627 想法??   由   提交 /u/CathieVictoriaWood   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1m0sy/r_llm_training_with_10000_gpus/</guid>
      <pubDate>Tue, 27 Feb 2024 20:26:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从某种意义上说，“在分布之外泛化”的想法不是不可能的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1he3r/d_isnt_the_idea_of_generalizing_outside_of_the/</link>
      <description><![CDATA[嘿，我并不是专门从事机器学习的人，但我是一名开发人员，并且对此有 8 年的业余爱好者研究。 &lt; p&gt;在分布之外进行泛化的想法对我来说一直很不寻常。当然，如果您学习英语，那么您现在在某种意义上就会知道如何编码，因为它是英语的。在这种情况下，该模型的泛化程度远没有我们希望的那么高，因为编码所需的基础知识几乎不是逻辑，而是读写。 在同样的意义上，人们可以想象一种颜色是不同颜色的混合。但想象一种全新的颜色并尝试一下，实际上是不可能的。在这种情况下，我们对分布之外的概括的定义并不在分布之外，只是分布比我们想象的（或可以量化的）大 与想象你从未听过的声音是一样的。再一次，你可以想象你听到过的其他声音的融合，也许你想象的这种新声音确实是你在现实中从未听过的东西，但你还没有推广到频谱的其余部分。我无法想象 20khz 以上的声音听起来是什么样子，因为我完全没有关于它可能是什么的基本事实，就像我无法客观地想象 X 射线是什么样子，因为我受限于我的能力，只能看到可见光。   由   提交 /u/EveningPainting5852   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1he3r/d_isnt_the_idea_of_generalizing_outside_of_the/</guid>
      <pubDate>Tue, 27 Feb 2024 17:21:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>