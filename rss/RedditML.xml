<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 11 May 2024 09:14:07 GMT</lastBuildDate>
    <item>
      <title>[D]Multi-Quattro 披萨自动售货机提供</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpd99z/dthe_multiquattro_pizza_vending_machine_offers/</link>
      <description><![CDATA[   https://preview.redd.it/8kkxmtn0jrzc1.png?width=320&amp;format=png&amp;auto=webp&amp;s=4a784758b8412f71e4ebf1b84452989 9ace581bb 坚固的代名词、可靠性、速度和服务，Multi-Quattro 自动售货机非常简单。 Multi-Quattro 披萨自动售货机提供多达 68 个披萨以及 4 种直径 30 厘米的不同披萨。它还能够同时提供 2 或 4 个不同的披萨。非常适合完成您的活动并达到您的目标。真正的自动售货店，它将轻松地将您的活动延长到 24H/24 和 7/7   由   提交 /u/SuccessfulContact175   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpd99z/dthe_multiquattro_pizza_vending_machine_offers/</guid>
      <pubDate>Sat, 11 May 2024 09:04:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] Marcus Hutter 在通用人工智能方面的工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpcwuz/r_marcus_hutters_work_on_universal_artificial/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpcwuz/r_marcus_hutters_work_on_universal_artificial/</guid>
      <pubDate>Sat, 11 May 2024 08:38:41 GMT</pubDate>
    </item>
    <item>
      <title>使用法学硕士的智能“if”语句[项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpcmz0/intelligent_if_statement_using_an_llm_project/</link>
      <description><![CDATA[   您不必将条件限制在有限的匹配范围内，而是让语言模型来决定。在这种情况下，我让法学硕士决定通知是否重要或有趣，然后生成代码来宣布通知或不通知。这可以通过实际让语言模型知道什么对你来说重要和有趣来扩展。例如，您可以说“只给我读科技新闻”。为什么这比典型的“if”语句更好？嗯，通常，您必须尝试匹配某些关键字才能破译一段文本是否符合某个类别。相反，使用 LLM 进行过滤，您可以使用上下文而不是精确匹配，这对于这种情况更好。 屏幕截图显示提示和结果   由   提交/u/Alert-Estimate  /u/Alert-Estimate  reddit.com/gallery/1cpcmz0&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpcmz0/intelligent_if_statement_using_an_llm_project/</guid>
      <pubDate>Sat, 11 May 2024 08:19:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLMinator：基于 Llama.cpp + Gradio 的开源聊天机器人，可直接从 HuggingFace 在本地（cpu/cuda）运行 llms</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpbgd1/p_llminator_a_llamacpp_gradio_based_opensource/</link>
      <description><![CDATA[      嗨我目前正在开发一个基于 Llama.cpp、Gradio、Langchain、Transformers 的上下文感知流媒体聊天机器人。 LLMinator 可以直接从 HF 和 LLM 中提取 LLM。在 cuda 或 cpu 上本地运行它们。 我正在寻找建议&amp;来自开源社区的帮助，以进一步发展这一点。 Github 存储库： https://github。 com/Aesthisia/LLMinator 目标：帮助开发人员使用 kickstarter 代码/工具运行 LLM。 https://preview.redd.it/fnzja7rjwqzc1.png?width=1846&amp;format= png&amp;auto=webp&amp;s=a62c43614d63e82156fef8722b986b051cc1795b 功能：  上下文感知聊天机器人。 内置代码语法突出显示。 直接从 HuggingFace 加载任何 LLM 存储库。 支持 CPU 和 CPU。 Cuda 模式。 加载和加载卸载已保存的模型。 命令行参数 API 访问（即将推出）  欢迎任何评论或反馈。   由   提交/u/hello-docker  /u/hello-docker  reddit.com/r/MachineLearning/comments/1cpbgd1/p_llminator_a_llamacpp_gradio_based_opensource/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpbgd1/p_llminator_a_llamacpp_gradio_based_opensource/</guid>
      <pubDate>Sat, 11 May 2024 06:59:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Scikit-Learn、Keras 和 TensorFlow 进行机器学习实践第二版</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpalcs/d_handson_machine_learning_with_scikitlearn_keras/</link>
      <description><![CDATA[这本书出版时我就买了，并学习了几章。我真的很喜欢，但最终从未完成它，但现在我实际上有机会花时间在它上面，我想知道它是否足够最新（从 2019 年开始），或者是否会有一本涵盖类似主题的更新的书。  任何提示表示赞赏👍   由   提交 /u/ApplesAndAmazons   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpalcs/d_handson_machine_learning_with_scikitlearn_keras/</guid>
      <pubDate>Sat, 11 May 2024 06:04:27 GMT</pubDate>
    </item>
    <item>
      <title>如果我的目标是 LPA 季风降雨量，我应该使用什么类型的数据集，我应该获取每日、每月或每年的数据？ “[研究]”、“[R]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpaerq/what_type_of_dataset_should_i_use_if_iam/</link>
      <description><![CDATA[如果我的目标是 LPA 季风降雨量，我应该使用什么类型的数据集，我应该采用每日、每月还是每年的数据？我正在使用数据集进行长期季风预报   由   提交 /u/Nice-Musician6346    reddit.com/r/MachineLearning/comments/1cpaerq/what_type_of_dataset_should_i_use_if_iam/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpaerq/what_type_of_dataset_should_i_use_if_iam/</guid>
      <pubDate>Sat, 11 May 2024 05:52:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与人工智能相关的工程技能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpa8lm/d_engineering_skills_relating_to_ai/</link>
      <description><![CDATA[如何磨练与人工智能相关的工程技能？您是否练习从头开始构建模型，在某些数据集上微调模型？有没有类似leetcode的AI工程师网站？   由   提交 /u/MoreThanJustAMonkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpa8lm/d_engineering_skills_relating_to_ai/</guid>
      <pubDate>Sat, 11 May 2024 05:41:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 GPU 集群上训练具有巨大嵌入的非常浅（点积）网络？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpa4io/d_how_to_train_very_shallow_dot_product_networks/</link>
      <description><![CDATA[过去，我们使用数十台参数服务器和数百台 CPU 机器来训练如此繁重的嵌入轻型计算模型，并取得了令人印象深刻的吞吐量。如今，随着具有高速 NVlink 的 GPU 集群的出现，吞吐量实际上变得更差了。当然，我说的是十几台 GPU 机器，每台机器都有 8 个 A100。张量核心利用率非常低（&lt; 1%），但由于 all2all 通信，GPU 非常繁忙。我试图弄清楚后一种设置可能存在的瓶颈是什么，当参数数量变大时，无论 nvlink 有多快，all2all（或环所有减少等）本质上都比参数服务器慢?   由   提交/u/Crazy_Suspect_9512   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpa4io/d_how_to_train_very_shallow_dot_product_networks/</guid>
      <pubDate>Sat, 11 May 2024 05:34:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] Google Colab 在训练我的图像数据集之前就崩溃了。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cou91s/p_google_colab_crashes_before_even_training_my/</link>
      <description><![CDATA[我有 780 张图像。所有这些都是微观的，我正在做微塑料图像检测。首先，我使用 U-Net 进行二元分类，然后使用 VGG-16 迁移学习。 Google Colab 一点也没有崩溃。效果非常好。 现在我正在做多类分割，预处理也差不多。除了一个用于彩色蒙版的额外通道之外。 但是，仅通过存储训练数据集的分类蒙版，我的系统 RAM 就超过了 6-7GB。调整大小后，我有 580 张图像，每张图像的尺寸为 512x512。不过，在调整大小之前它们甚至更小。 那么，这是怎么回事？任何帮助将不胜感激。 而不是每次以 npz 格式存储数据并将它们加载到变量中时进行预处理。它们的最大容量为 1GB。但没有更高。 我被困住了。已经两天了，但我根本无法训练。另外，我是一名学生，没有钱购买 Colab Pro。我的笔记本电脑是 GTX-1650，所以它的性能绝对不可能比 Google Colab 更好，尤其是因为我只有 8GB RAM。   由   提交/u/Plenty_Mention1787   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cou91s/p_google_colab_crashes_before_even_training_my/</guid>
      <pubDate>Fri, 10 May 2024 16:52:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 评估特定领域 QA 上的法学硕士表现是否足以提交顶级会议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cosbka/d_is_evaluating_llm_performance_on_domainspecific/</link>
      <description><![CDATA[你好， 你好， 我正在为顶级会议准备一篇论文，正在努力解决什么才算是重大贡献。我的研究涉及比较至少五名法学硕士在特定领域问答任务上的表现。为了保密，我不会指定域。 由于没有合适的公开数据集，我从维基百科创建了一​​个新数据集，并尝试了各种提示策略和 LLM 模型，包括详细的性能分析。  我相信通过比较不同的法学硕士和激励策略获得的见解可以使社区受益匪浅，特别是考虑到有关法学硕士评估的现有文献（https://arxiv.org/abs/2307.03109）。然而，一些教授认为，仅仅“分析 LLM 对某个问题的表现并不足以做出足够大的贡献。” 鉴于高层会议接受的许多有关 LLM 评估的研究，您的标准是什么？认为这样的研究论文对社区有价值吗？ 提前感谢您的见解！   由   提交 /u/VieuxPortChill   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cosbka/d_is_evaluating_llm_performance_on_domainspecific/</guid>
      <pubDate>Fri, 10 May 2024 15:30:17 GMT</pubDate>
    </item>
    <item>
      <title>[N] 新书发布：使用 PyTorch 2.X 加速模型训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cos6bq/n_book_lauching_accelerate_model_training_with/</link>
      <description><![CDATA[大家好！我叫 Maicon Melo Alves，是一名专门研究 AI 工作负载的高性能计算 (HPC) 系统分析师。 我想宣布我的书“使用 PyTorch 加速模型训练 2” .X：通过提升模型训练过程来构建更准确的模型” Packt 最近推出了本书。 本书面向想要了解如何使用 PyTorch 加速机器学习模型训练过程的中级数据科学家、工程师和开发人员。 &gt; 如果您认为本书可以帮助其他专业人士，请与您的社区分享这篇文章！ 😊 非常感谢！   由   提交/u/Various_Protection71   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cos6bq/n_book_lauching_accelerate_model_training_with/</guid>
      <pubDate>Fri, 10 May 2024 15:24:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找对小时工感兴趣的 ML 工程师的最佳社区/网站</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cook89/d_best_communitywebsite_to_find_ml_engineer/</link>
      <description><![CDATA[我一直在 Upwork 这样的平台上寻找机器学习工程师，但许多候选人似乎在从头开始构建模型方面经验有限。他们通常专注于集成预构建的 ML API，而不是开发根据特定要求定制的自定义模型。  哪里是寻找能够处理从数据收集到模型部署的整个模型开发过程的机器学习工程师的最佳地点？    由   提交/u/um877  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cook89/d_best_communitywebsite_to_find_ml_engineer/</guid>
      <pubDate>Fri, 10 May 2024 12:38:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mamba 中的“离散化”步骤到底是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1com9qh/d_what_on_earth_is_discretization_step_in_mamba/</link>
      <description><![CDATA[什么是“离散化”？信号/序列不是已经“离散”了吗？以代币的形式？请不要让我去看有关“线性状态空间模型的离散化”的维基百科文章，因为我无法与法学硕士建立任何联系。在我看来，Mamba 的核心只是具有动态 alpha 参数的 EMA，该参数是根据每个通道在时间 t 的当前代币计算得出的。不太明白“离散化”有什么好处？以及它对数据的实际作用。   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1com9qh/d_what_on_earth_is_discretization_step_in_mamba/</guid>
      <pubDate>Fri, 10 May 2024 10:26:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过多标记预测更好更快的大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1coluve/r_better_faster_large_language_models_via/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.19737 摘要：  大型语言模型（例如 GPT 和 Llama）使用下一个进行训练- 代币预测损失。在这项工作中，我们建议训练语言模型来同时预测多个未来标记，从而提高样本效率。更具体地说，在训练语料库中的每个位置，我们要求模型使用在共享模型主干上运行的 n 个独立输出头来预测以下 n 个标记。将多标记预测视为辅助训练任务，我们测量了改进的下游能力，而代码和自然语言模型的训练时间没有开销。该方法对于较大的模型尺寸越来越有用，并且在训练多个时期时保持其吸引力。在编码等生成基准上，收益尤其明显，我们的模型始终比强大的基准高出几个百分点。与同类 next-token 模型相比，我们的 13B 参数模型在 HumanEval 上解决的问题多解决了 12%，在 MBPP 上解决的问题多解决了 17%。小算法任务的实验表明，多token预测有利于归纳头和算法推理能力的发展。另外一个好处是，即使批量大小较大，使用 4 令牌预测训练的模型的推理速度也可提高 3 倍。     ;由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1coluve/r_better_faster_large_language_models_via/</guid>
      <pubDate>Fri, 10 May 2024 09:59:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>