<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 27 Nov 2024 18:23:54 GMT</lastBuildDate>
    <item>
      <title>[D] 知识蒸馏神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h17xwc/d_knowledge_distillation_neural_network/</link>
      <description><![CDATA[大家好， 假设我原来的神经网络模型大小为 50MB。有没有办法在应用知识蒸馏后估算蒸馏模型的大小。    提交人    /u/PhilosopherNew313   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h17xwc/d_knowledge_distillation_neural_network/</guid>
      <pubDate>Wed, 27 Nov 2024 16:13:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 帮助提交 WACV 研讨会论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h15p2e/r_help_with_submitting_a_wacv_workshop_paper/</link>
      <description><![CDATA[大家好， 我之前从未向任何会议提交过论文。我必须向 11 月 30 日截止的 WACV 研讨会提交一篇论文。 到目前为止，我几乎已经完成了 WACV 推荐的模板，但它在生成 PDF 时要求在 LaTeX 文件中提供论文 ID。我不确定从哪里获取该论文 ID。 我使用 Microsoft CMT 进行提交。我是否需要先提交没有论文 ID 的论文以分配它，然后用 ID 更新 PDF 并重新提交？或者有没有办法事先获得 ID？ 此外，WACV 的抄袭阈值是多少？我想确保合规，但希望明确多少百分比的相似性是可以接受的。 谢谢您的帮助！    提交人    /u/__proximity__   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h15p2e/r_help_with_submitting_a_wacv_workshop_paper/</guid>
      <pubDate>Wed, 27 Nov 2024 14:34:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAMAS 2025 评论出炉！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h15k8k/d_aamas_2025_reviews_are_out/</link>
      <description><![CDATA[我找不到讨论主题，所以我想自己创建一个。     提交人    /u/E-Cockroach   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h15k8k/d_aamas_2025_reviews_are_out/</guid>
      <pubDate>Wed, 27 Nov 2024 14:28:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用环路记忆和染色体进行遗传学习，作为记忆神经元的门。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h15c7q/r_genetic_learning_with_loop_mempory_and/</link>
      <description><![CDATA[您好！ 目前有点忙，稍后会清理，而且现在懒得执行 git... &gt;_&gt; https://github.com/Letosim/Genetic-Learning-for-Neural-Networks/blob/master/README.md    提交人    /u/_Leto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h15c7q/r_genetic_learning_with_loop_mempory_and/</guid>
      <pubDate>Wed, 27 Nov 2024 14:18:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] Meissonic：通过增强蒙版图像建模实现高分辨率文本到图像的生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h1529m/r_meissonic_highresolution_texttoimage_generation/</link>
      <description><![CDATA[这项工作引入了一种非自回归掩蔽图像建模 (MIM) 方法，旨在匹配 SDXL 级图像生成，同时避免自回归方法的标记效率低下。关键创新是将 MIM 与架构改进和采样优化相结合，以实现高分辨率图像合成。 主要技术要点： - 使用具有专门的自注意力和位置编码的基于变压器的架构 - 将人类偏好分数作为“微条件”来指导生成 - 采用特征压缩层有效处理高分辨率 - 通过并行标记预测而不是顺序预测生成 1024x1024 图像 - 实现与 SDXL 相当的 FID 分数，同时计算效率更高 结果： - 在标准基准上，图像质量指标与 SDXL 相媲美 - 与自回归方法相比，生成速度更快 - 更好地处理复杂场景和构图 - 与以前的 MIM 方法相比，文本对齐得到改进 我认为这可能会在几个方面影响该领域： - 表明非扩散方法可以实现 SOTA 级生成 - 提供统一语言视觉模型的潜在途径 - 可能导致更有效地部署文本到图像系统 - 可能影响未来多模态模型的架构设计 在我看来，最大的悬而未决的问题是这种方法是否可以进一步扩展 - 虽然它在当前分辨率下运行良好，但目前尚不清楚相同的原理是否会在更高的维度上成立。 TLDR：非自回归掩蔽建模方法匹配 SDXL 级图像生成同时比典型的自回归方法更有效。显示出统一语言视觉架构的前景。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h1529m/r_meissonic_highresolution_texttoimage_generation/</guid>
      <pubDate>Wed, 27 Nov 2024 14:05:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] ACL ARR 讨论 - 关于作者回复</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h13ffu/d_acl_arr_discussion_about_author_response/</link>
      <description><![CDATA[大家好！目前已于 10 月提交至 ACL ARR。现在作者回复阶段已经结束，我们尚未收到审阅者的任何回复（对我们的回复）。 想问一下，审阅者是否仍可以在作者回复阶段结束后和元评论给出前更新他们的评论，还是说我不会收到任何回复？    提交者    /u/Ok_Function6276   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h13ffu/d_acl_arr_discussion_about_author_response/</guid>
      <pubDate>Wed, 27 Nov 2024 12:44:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LLM 进行评估的有效性如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h11lbt/d_how_valid_is_the_evaluation_using_llms/</link>
      <description><![CDATA[大家好， 我对使用 Gen AI 还不熟悉，我想检查使用更大的 LLM 来评估其他 LLM 结果的有效性。我见过不同的博客这样做是为了实现评估自动化。 例如，要评估模型 A 的英语翻译列表，提示另一个模型 B 是否有效，如下所示 &#39;&#39;&#39;这个翻译是否正确 原文：{original_text}，翻译文本 {translated_text}&#39;&#39;&#39; 这是一种有效的评估方式吗？我内心深处的某种东西告诉我这在科学上是错误的，因为 LLM 模型 B 本身会有一些错误，对吧？    提交人    /u/raman_boom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h11lbt/d_how_valid_is_the_evaluation_using_llms/</guid>
      <pubDate>Wed, 27 Nov 2024 10:48:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] AISTATS 2025 论文评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0y8rn/d_aistats_2025_paper_reviews/</link>
      <description><![CDATA[由于 AISTATS 2025 论文评审今天截止，所以我想开一个帖子让大家讨论一下自己的经验！    提交人    /u/PhoneImpressive9983   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0y8rn/d_aistats_2025_paper_reviews/</guid>
      <pubDate>Wed, 27 Nov 2024 06:42:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] AISTATS 2025 评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0x428/d_aistats_2025_reviews/</link>
      <description><![CDATA[Aistats 2025 评论应该会在今天发布。所以我想创建一个讨论帖子，让我们可以分享我们的经验！    提交人    /u/PhoneImpressive9983   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0x428/d_aistats_2025_reviews/</guid>
      <pubDate>Wed, 27 Nov 2024 05:31:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习中的黑洞和损失景观</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0uwjd/r_black_holes_and_the_loss_landscape_in_machine/</link>
      <description><![CDATA[摘要：  了解损失景观是机器学习中的一个重要问题。损失函数的一个关键特征是存在指数级的低位局部最小值，这在许多神经网络架构中都很常见。具有类似能量景观的物理系统可能会提供有用的见解。在这项工作中，我们指出，由于黑洞熵的存在，黑洞自然会产生这样的景观。为了明确起见，我们考虑 =8 弦理论中的 1/8 BPS 黑洞。这些提供了在相应黑洞的微观描述中出现的无限潜在景观系列。最小值的计数相当于黑洞微观状态计数。此外，这些景观的最小值的确切数量是从弦理论中的对偶性中先验已知的。一些最小值由低损失值的路径连接，类似于模式连接。我们估计找到所有解决方案所需的运行次数。初步探索表明，随机梯度下降可以找到很大一部分最小值。  Arxiv：https://arxiv.org/abs/2306.14817    提交人    /u/Mindless-House-8783   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0uwjd/r_black_holes_and_the_loss_landscape_in_machine/</guid>
      <pubDate>Wed, 27 Nov 2024 03:26:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 理解 Arm CMSIS-NN 的 Softmax 函数。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0um9l/p_understanding_arm_cmsisnns_softmax_function/</link>
      <description><![CDATA[嗨，我正在尝试了解 16 位有符号输入的 CMSIS-NN Softmax 实现 (https://github.com/ARM-software/CMSIS-NN/blob/22080c68d040c98139e6cb1549473e3149735f4d/Source/SoftmaxFunctions/arm_softmax_s16.c)。 Arm 在此处提供了示例输入数据和预期输出数据 (https://github.com/ARM-software/CMSIS-NN/tree/22080c68d040c98139e6cb1549473e3149735f4d/Tests/UnitTest/TestCases/TestData/softmax_s16），所以我尝试通过将 C 代码逆向工程为 Python 来理解代码（我的最终目标是修改提供的 C 代码，并使用正确的配置参数（可能还有适当的查找表）进行片上部署）。目前有两件事使得我无法开箱即用地使用 softmax 实现。  我相信我必须构建自己的查找表，但我不知道该怎么做。  指数查找表（https://github.com/ARM-software/CMSIS-NN/blob/22080c68d040c98139e6cb1549473e3149735f4d/Tests/UnitTest/TestCases/Common/Softmax/exp_lut_data.h) 逐一查找表（https://github.com/ARM-software/CMSIS-NN/blob/22080c68d040c98139e6cb1549473e3149735f4d/Tests/UnitTest/TestCases/Common/Softmax/one_by_one_lut_data.h)  我无法弄清楚这里的 config_data 中的左移和 input_mult 是什么（https://github.com/ARM-software/CMSIS-NN/blob/22080c68d040c98139e6cb1549473e3149735f4d/Tests/UnitTest/TestCases/TestData/softmax_s16/config_data.h) 确实如此。  不幸的是，我不懂 C，所以我想知道是否有人可以为我提供一些使用 softmax 实现的指导，或者我可以用来理解这一点的链接/视频。    由   提交  /u/Individual_Ad_1214   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0um9l/p_understanding_arm_cmsisnns_softmax_function/</guid>
      <pubDate>Wed, 27 Nov 2024 03:11:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 比较 Llama 模型和 GPT 4o 模型在多语言机器翻译和反向翻译方面的表现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0sehj/p_d_comparing_llama_models_and_gpt_4o_models_on/</link>
      <description><![CDATA[      大家好， 本着 LLM 实际现实世界任务的精神，我们想看看不同的模型能够多好地自动将耐克产品目录上的文本从英语翻译成西班牙语，然后再翻译回英语。我们从 Llama 405B、Llama 70B、Llama 8B、GPT 4o-mini 和 GPT 4o 开始，但希望测试更多模型。 ~ TLDR ~ 以下是包含所有数据和代码的结果： https://www.oxen.ai/datasets/Nike-Product-Translation-Experiments https://preview.redd.it/qken2vjfhc3e1.png?width=1150&amp;format=png&amp;auto=webp&amp;s=739ef336dd7b89856a39d872ef12e03f806ce799 虽然反向翻译可能不是最有效的基准测试方法，但我们认为这将是一个有趣的实验，看看它与模型性能的相关性如何。让以西班牙语为母语的人用基本事实标签注释数据集是理想的选择，因此如果有人想做出贡献，请随时分叉 repo，我们可以获得一些真正的标签。 我们正在尝试制作更多现实世界的数据集 / 基准，因此如果您想提供帮助，请告诉我们。 如果您是 Oxen.ai 项目的新手，我们正在构建一个快速的开源数据集协作工具以及大量有用的数据探索工具！如果您对数据或 ML/AI 感兴趣，我们很乐意听取您对该工具和项目的想法！    提交人    /u/FallMindless3563   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0sehj/p_d_comparing_llama_models_and_gpt_4o_models_on/</guid>
      <pubDate>Wed, 27 Nov 2024 01:17:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一篇解释稀疏变换器的博客文章（原始论文）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0gl2j/d_a_blog_post_explaining_sparse_transformers_the/</link>
      <description><![CDATA[嗨！ 如果在此 subreddit 上发布此类帖子不合适，我很抱歉。我确实不会在此 subreddit 上发布此类帖子，但我一直看到文章或视频或任何内容在解释 GPT-3 时没有深入研究稀疏变压器。这让我很沮丧，因为论文中他们清楚地说“我们在变压器的各层中使用交替的密集和局部带状稀疏注意力模式，类似于稀疏变压器”。 但似乎没有人关心解释它们。老实说，我理解为什么，但看到所有这些文章、项目、视频等试图解释有关 GPT 的所有内容，甚至没有提到稀疏变压器部分，这令人沮丧。除了 GPT-3 特有的许多其他元素或 ML 中可重复性的通用元素之外，稀疏变换器部分甚至对 GPT-3 的原型设计也造成了很大的影响。 当我试图理解某件事时，我有写下东西的习惯，所以我写了一篇关于稀疏变换器的博客文章。从来没有谈论过它，因为我这样做是为了重组我的想法并作为我的笔记。因此，我不会建议任何人阅读它，我确信它充满了错别字，我的写作风格也不整洁等等。这只是我为自己做的事情，我会理解并在浏览时恢复丢失的信息。 无论如何，如果你自己阅读论文并试图从中构建知识，也许我的笔记可以帮助你：https://reinforcedknowledge.com/sparse-transformers/ 如果这篇文章不合适并且喋喋不休，我再次抱歉。 （如果您碰巧阅读它或者您发现任何错误，请随时指出它们，我很感激从中学习）    提交人    /u/ReinforcedKnowledge   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0gl2j/d_a_blog_post_explaining_sparse_transformers_the/</guid>
      <pubDate>Tue, 26 Nov 2024 16:55:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 24 Nov 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>