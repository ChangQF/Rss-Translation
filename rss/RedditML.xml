<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 11 Jun 2024 21:24:38 GMT</lastBuildDate>
    <item>
      <title>[D] 谷歌使用受版权保护的数据来训练 GenAI 是否违法了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddp72l/d_did_google_just_break_the_law_by_training_genai/</link>
      <description><![CDATA[显然人类评估（大规模）足以发现 SOTA GenAI Vision 模型中的版权问题。 GenAI 房间里的大象很可能是所有 GenAI 公司都在做同样的事情，不是吗？    提交人    /u/btcmx   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddp72l/d_did_google_just_break_the_law_by_training_genai/</guid>
      <pubDate>Tue, 11 Jun 2024 21:07:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 适合教学的良好服务器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddokve/d_good_server_for_teaching/</link>
      <description><![CDATA[大家好， 我们大学的教授希望购买一台服务器，用于教学生如何训练小型 - 中型模型。由于我们不希望他们拥有高端 GPU，或者根本没有任何 GPU（大多数人无论如何都在笔记本电脑上完成大学作业），因此我们想专门为教学构建一台新服务器。理想情况下，我们正在寻找大量小型 GPU，以便能够为每个学生提供自己的 GPU。我们也考虑过 MIG，但只有少数 GPU 支持这一点。  有人有建造这种机器的经验吗？我们的预算约为 25-30k，理想情况下我们希望拥有大约 16 个计算设备。如果价格合适，我们也可以使用服务/租赁。    提交人    /u/the_hackelle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddokve/d_good_server_for_teaching/</guid>
      <pubDate>Tue, 11 Jun 2024 20:42:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人有兴趣购买预先构建和预先设置的 4x3090/4090 或 8x3090/4090 PC 用于训练/推理吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddlr3v/d_would_anyone_be_interested_in_buying_prebuilt/</link>
      <description><![CDATA[由于我一直在为 AwanLLM.com 研究和构建多 GPU 电脑，我想知道这里的人们是否也有兴趣购买我们使用的硬件。 我们使用 RTX 3090/4090 GPU，因为与任何其他卡相比，它们具有最好的 VRAM/$ 和 Perf/$，但由于它们难以与三槽或 4 槽冷却器配合使用，因此我们必须发挥创造力，将 4x GPU 安装在 4U 服务器机箱中，将 8x GPU 安装在 6U 机箱中。 我们使用基于 X99 和 C612 LGA2011-3 的系统，以降低成本，并且根据我们的经验，该平台对性能影响不大。尽管如果需要，可以替换为 Threadripper 或任何较新的服务器 CPU。 我们还可以设置一个 Ubuntu 22.04 安装，该安装预先设置了正确的驱动程序、CUDA 以及您想要安装的任何训练或推理开源软件，以减少一些设置麻烦。 考虑到预先构建的 AI/机器学习 PC 通常要花费大量成本，如以下这些例子，我想这可能是有些人可能感兴趣的东西？我们应该能够以低于 5,000 美元的价格提供带有定制机箱和 PCIe 布线解决方案的 4x3090 机器。 我发现这些 AI 预装 PC 的另一个问题是，这些构建器在 6x 或 7x GPU 中提供了奇怪的 GPU 数量，这对于使用张量并行进行推理或训练时绝对没用（您应该为如此强大的机器这样做）因为它需要是 2 的幂。 tinygrad：一个简单而强大的神经网络框架 AI 和深度学习 NVIDIA 工作站 | Boxx Technologies Comino Grando 工作站用于深度学习和 AI 推理   由    /u/nero10578  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddlr3v/d_would_anyone_be_interested_in_buying_prebuilt/</guid>
      <pubDate>Tue, 11 Jun 2024 18:46:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在审查时改进模型的内部运作是否不明智？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddjyx0/d_is_it_inadvisable_to_improve_the_internal/</link>
      <description><![CDATA[我向 NeurIPS 提交了一篇论文，其中的模型使用了 mamba 块。然而，在将稿件提交给 openreview 之前，我已经想到了一些可以尝试改进结果的调整或想法。现在，在 mamba-2 最近发布之后，这种情况更加明显，因为正如新论文中所述，一些微小的变化可以提高我的模型的性能和速度。 出于这些原因，自提交之日起，我一直在考虑研究一些旧想法，并尝试更新的 mamba 块；尽管如此，我担心这可能会让已经阅读过一个版本论文的审阅者感到困惑，我猜他们希望讨论旧版本的模型。也许改变这么多东西可能会让他们有点困惑，甚至恼火。 另一方面，我真的认为我至少可以改进一些指标，即使我被取消参加这次会议，我也愿意取得这些改进，尝试参加另一次会议。 在这种情况下你会怎么做？    提交人    /u/SrPinko   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddjyx0/d_is_it_inadvisable_to_improve_the_internal/</guid>
      <pubDate>Tue, 11 Jun 2024 17:34:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用平方误差而不是绝对误差？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddjbdi/why_use_squared_error_instead_of_absolute_error_d/</link>
      <description><![CDATA[我不明白为什么当错误 = 0 时得到未定义的偏导数会是一个大问题，我的意思是得到零错误不是我们从一开始就想要的吗？    提交人    /u/NeatJealous8110   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddjbdi/why_use_squared_error_instead_of_absolute_error_d/</guid>
      <pubDate>Tue, 11 Jun 2024 17:07:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您在使用 LLM 创建机器学习训练数据方面学到了什么经验教训？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddj561/d_what_are_the_lessons_you_learned_in_using_llms/</link>
      <description><![CDATA[大型语言模型 (LLM) 的广泛可用性和性能使从业者能够自动执行各种耗时的任务。获取机器学习训练数据集的大量质量标签是监督学习中的关键步骤，但手动生成可能需要大量时间。 https://opendatascience.com/trial-error-triumph-lessons-learned-using-llms-for-creating-machine-learning-training-data/    提交人    /u/Data_Nerd1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddj561/d_what_are_the_lessons_you_learned_in_using_llms/</guid>
      <pubDate>Tue, 11 Jun 2024 17:00:40 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 从 keras.optimizers.optimizer 访问和使用损失函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddizyz/discussion_accessing_and_using_the_loss_function/</link>
      <description><![CDATA[我目前正在研究一个优化器想法，它依赖于在参数更新函数期间多次计算损失，但我找不到有关此的任何文档......这里的任何人都知道做这样的事情的方法    提交人    /u/ihaveagoodusername2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddizyz/discussion_accessing_and_using_the_loss_function/</guid>
      <pubDate>Tue, 11 Jun 2024 16:54:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人参加 CVPR 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddirmi/d_anybody_attending_cvpr/</link>
      <description><![CDATA[这是我第一次参加 CVPR，所以想结识新朋友，一起出去玩，交流研究想法。有什么好的研讨会和教程可以参加吗？请告诉我。    提交人    /u/Deep-Inevitable-1977   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddirmi/d_anybody_attending_cvpr/</guid>
      <pubDate>Tue, 11 Jun 2024 16:45:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024年机器学习研究的热门话题是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddhu8n/d_what_are_the_hot_topics_in_machine_learning/</link>
      <description><![CDATA[今年，哪些子领域/方法、应用领域有望在学术界或工业界获得广泛关注（无意双关）？ PS：请不要羞于提出您认为或知道的任何可能是 ML 中流行的研究主题，您所知道的内容很可能对我们中的许多人来说相对不为人知：)    提交人    /u/knut_2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddhu8n/d_what_are_the_hot_topics_in_machine_learning/</guid>
      <pubDate>Tue, 11 Jun 2024 16:06:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] rerank-ts：使用 LLM 对搜索结果进行重新排序的 TypeScript 库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddhog4/p_rerankts_typescript_library_for_reranking/</link>
      <description><![CDATA[宣布推出一个 TypeScript 库，用于对来自向量数据库或全文搜索索引的搜索结果进行重新排名。重新排名是构建 RAG 应用程序检索中非常重要的一个步骤。它几乎可以立即提高 LLM 响应合成的准确性，因为您能够输入更准确、更相关的上下文。为什么？因为虽然语义或全文搜索系统旨在快速获取语义或词汇上接近的文档块，但它们不会根据用户查询的意图对块进行排名。这就是重新排名器的作用所在。 代码 - https://github.com/tensorlakeai/rerank-ts  我们为什么要构建它？ 我们找不到一个独立于框架的 Typescript 重新排名库。我们还希望轻松交换模型和算法，发布并密切跟踪延迟指标。我们实现了两种不同的重新排名算法 -   基于 LLM 的重新排名：它使用论文中提出的算法 - “ChatGPT 擅长搜索吗？” https://arxiv.org/abs/2304.09542 - 他们实现了基于滑动窗口的算法来重新排名搜索结果，这些搜索结果可能比 LLM 的上下文长度更大。我们增加了对 LLama3 和 GPT-4 的支持。对于 Llama3，我们使用 Groq，但可以轻松添加其他模型提供程序。  相互排序融合 - 一种轻量级算法，用于合并来自多个索引的搜索结果，同时保留它们的相对重要性。  我们最近构建了一个消费者应用程序，该应用程序使用 Indexfiy (https://getindexfiy.ai) 对 1000 个图像中的 100 个进行索引，该应用程序对图像的各个方面进行索引 - 标题（使用文本嵌入模型）、视觉描述（使用 VLM）、CLIP 嵌入。在检索过程中，我们根据用户查询从每个索引中查找 40 个图像，然后使用此库对结果进行重新排名。与根本不重新排名相比，结果确实令人惊叹。 延迟 - 对于与人类交互的应用程序来说，延迟是一个大问题，根据我们的经验，Groq 上的 LLama3 8B 是最快的 LLM 重新排名器。它们每秒能够处理约 1000 个 token。我们能够在大约 1.4 秒内对 100 张图像进行重新排名。我们还没有尝试在生产中使用 GPT4，以便能够分享任何与延迟相关的数字。 选择模型 - 选择在延迟与准确度之间取得最佳平衡的模型。有许多较小的重新排名模型可用 - Jina AI、BGE、Sentence Transformers 等。我们也听说过关于 Cohere 重新排名器的好评。我们希望在未来增加对更多模型的支持。该库有一个干净的模型提供程序界面，因此欢迎贡献！    提交人    /u/diptanuc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddhog4/p_rerankts_typescript_library_for_reranking/</guid>
      <pubDate>Tue, 11 Jun 2024 15:59:46 GMT</pubDate>
    </item>
    <item>
      <title>[N] YaFSDP 与 FSDP 在 LLM 培训中的比较：真正的进步？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddc1uf/n_yafsdp_vs_fsdp_for_llm_training_real_improvement/</link>
      <description><![CDATA[在 Yandex，我们开发了 FSDP 的增强版本，称为 YaFSDP，与 FSDP 相比，LLM 训练时间加快了 26%，并且 GPU 资源节省了很多。例如，在涉及 700 亿个参数的模型的预训练场景中，使用 YaFSDP 可以节省大约 150 个 GPU 的资源，这意味着每月可以节省大约 50 万美元到 150 万美元（取决于虚拟 GPU 提供商或平台）。  YaFSDP 是开源的，所以我们迫不及待地想听到您的反馈，看看您如何在工作中实现它！ https://github.com/yandex/YaFSDP     提交人    /u/azalio   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddc1uf/n_yafsdp_vs_fsdp_for_llm_training_real_improvement/</guid>
      <pubDate>Tue, 11 Jun 2024 11:41:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语音研究是否陷入困境？语音应用的下一个重大突破是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dd8cbs/d_is_speech_research_hitting_a_wall_what_could_be/</link>
      <description><![CDATA[我觉得，与 NLP（LLM 中的安全/对齐等）和 CV（文本到图像/视频、机器人规划等，仅举几例）相比，语音应用的前景似乎不那么令人兴奋。 它的主要工作似乎只是将语音转录为文本，然后让 LLM 完成那些神奇的事情。 当然，它可以合成逼真的声音（例如 GPT-4o 中的演示）或其他应用程序，但语音似乎很难在未来再次成为关键角色。 就可能的研究方向而言，语音应用的下一个大事件是什么？    提交人    /u/xiikjuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dd8cbs/d_is_speech_research_hitting_a_wall_what_could_be/</guid>
      <pubDate>Tue, 11 Jun 2024 07:29:44 GMT</pubDate>
    </item>
    <item>
      <title>对 TMLR 及学术界其他新兴/利基场所的看法 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dd76xy/perception_of_tmlr_and_other_newniche_venues_in/</link>
      <description><![CDATA[今年冬天我将申请研究生院，到目前为止，我只在理论深度学习领域获得了一篇论文，它被发表在《机器学习研究汇刊》（TMLR）上。我不想解释为什么我在那里发表文章，但本质上，我的导师鼓励我们在那里发表文章。尽管评论非常轻松和有见地，但我担心（理论）学术界对 TMLR 的看法并不那么好。我和几位教授谈过，他们似乎都问我为什么在这样一个奇怪的场所发表文章，我真的很担心 GradApp 委员会对这项工作产生一些怀疑。这项工作本身很可爱，虽然不是什么了不起的事情，但解决了一些著名作者在一篇旧论文中提出的问题之一，我对我的工作感到非常自豪，但我觉得委员会可能不会这么认为。我很想知道全职学者对 TMLR 等场所的看法。    由    /u/filletedforeskin  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dd76xy/perception_of_tmlr_and_other_newniche_venues_in/</guid>
      <pubDate>Tue, 11 Jun 2024 06:09:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你见过的最好的深度学习笔记本实验是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dcvsno/d_what_are_the_best_deep_learning_notebook/</link>
      <description><![CDATA[我正在 Notebooks 中挖掘一些最好的公开可用的深度学习实验。 我发现的一个很酷的实验是 对抗攻击，使用 Goodfellow 的快速梯度符号方法 (FGSM)。 你最喜欢哪一个？    提交人    /u/research_pie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dcvsno/d_what_are_the_best_deep_learning_notebook/</guid>
      <pubDate>Mon, 10 Jun 2024 20:32:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>