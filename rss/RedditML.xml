<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 03 May 2024 06:19:02 GMT</lastBuildDate>
    <item>
      <title>[D] 距离估计 - 真实世界坐标</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cj14fe/d_distance_estimation_real_world_coordinates/</link>
      <description><![CDATA[您好，很抱歉再次转发此问题，但这非常重要，我需要帮助。 我有三个房间内不同位置（前墙、左墙、右墙）的摄像头。我应该能够找到房间中人与人之间的距离（以米为单位）。 我对所有摄像机进行了摄像机校准。 我尝试使用 SIFT 匹配公共点，然后执行DLT 方法，但值相差甚远，甚至不接近实际值。 我也尝试过立体视觉，但这并没有给我接近的值。 我也相机之间的距离也以米为单位。 我是计算机视觉的初学者，我应该很快完成这项任务，但我已经坚持了一个月了，而且我越来越累了无法解决这个问题，我已经没有解决方案了。  如果有人帮助我并引导我走向正确的方向，我将非常感激。 非常感谢您的帮助和时间😄   由   提交 /u/Embarrassed_Top_5901   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cj14fe/d_distance_estimation_real_world_coordinates/</guid>
      <pubDate>Fri, 03 May 2024 05:38:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 迭代推理偏好优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciyps2/r_iterative_reasoning_preference_optimization/</link>
      <description><![CDATA[ 由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciyps2/r_iterative_reasoning_preference_optimization/</guid>
      <pubDate>Fri, 03 May 2024 03:20:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研究用于工作的 AI/LLM 开发机器的硬件选项。对中小型模型的训练和推理。迷失在硬件规格中——帖子中的详细信息。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciwipe/d_looking_at_hardware_options_for_an_aillm/</link>
      <description><![CDATA[您好， 在工作中，我的任务是与我们的内部人员一起研究和开发一些关于使用法学硕士的东西房屋软件套件。由于政策原因，我无法详细说明，但最终会涉及一些 PII 识别/提取、一些文档摘要，可能还有一点 RAG 等。 在过去一两个月里，我已经使用非常小的模型做了一些初步的基础工作来表明某些事情“是可能的”，但我们希望将其提升到一个新的水平。 此时我一直在使用我的笔记本电脑的 GPU（只是移动 RTX 3060）和我老板的 RTX 4080 在 AMD Threadripper 机器上的组合。即使在一些较小的模型上，3060 也会很快崩溃，但 4080 在推理方面表现得非常好。但正如你想象的那样，我很快就耗尽了 VRAM，试图做一些更强大的事情。 我的部分任务是指定一些用于本地开发机器/桌面的硬件。我们已经订购了更多具有大量 VRAM 的生产级硬件（我认为它徘徊在 1 TB 的 VRAM 左右，但不是 100% 确定），以便在我们的数据中心使用，但这不会在 2019 年到达。至少几个月。 有了这个，我正在寻找一些关于开发工作站的建议。我无法得出是否应该运行多个 GPU 或购买内置更多 VRAM 的东西的结论。例如，我是否运行双 3090？我运行一个还是两个 A6000？或者一个？单个 RTX 6000 Ada (48GB) 就足够了吗？ 鉴于：  这仅用于开发，不适用于生产 我想推理中小型模型（可能最多 30b 个参数） 我可能想微调中小型模型，如果有的话作为比较点。即使使用 LoRA/QLoRA 微调也会在 Python 端完成，推理将使用 HuggingFace 的 candle Rust 库 使用一些东西我不鼓励基于云的开发（无法详细介绍），而且无论构建什么最终投入生产的软件都无法与任何外部 API 交互 我不介意使用量化模型开发，但在某些时候我想尝试全精度模型（这可能需要等待生产硬件的出现） 我会说钱不是一个因素，但如果可以的话预算最好在 15,000 美元以下  你们会推荐什么？ 谢谢！ &lt;!-- SC_ON - -&gt;  由   提交/u/IThrowShoes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciwipe/d_looking_at_hardware_options_for_an_aillm/</guid>
      <pubDate>Fri, 03 May 2024 01:26:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为博士生/研究员提高 MLOps 技能的良好策略/资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciryee/d_good_strategies_resources_to_improve_mlops/</link>
      <description><![CDATA[许多机器学习领域的研究人员/博士生最终都有加入该行业的前景（据统计，在美国，大约 80% 的机器学习博士都在该行业）最近发布的斯坦福大学人工智能指数）。 对于某人来说，有哪些好的技巧/资源可以确保他开发出更实用且更实用的技术？面向部署的 MLOps 技能？ 例如 - 设置集群、相关云服务（例如 AWS）、Docker、Kubernetes、开发用于模型训练/数据标签的内部工具......诸如此类。   由   提交/u/fliiiiiiip   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciryee/d_good_strategies_resources_to_improve_mlops/</guid>
      <pubDate>Thu, 02 May 2024 21:52:53 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 我应该去ICML发表论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</link>
      <description><![CDATA[我完成了博士学位。一年前。离开学术界，成为一家科技公司的数据科学家。我喜欢它，但仍在考虑将来以某种方式转向更多的研究职位。不过不确定。 无论如何，我的一个未完成的作品被一个朋友选中，完成并申请到 ICML。它被接受了（耶！）。 我现在想知道 - 除了我发现会议很有趣之外，参加会议是否有真正的好处？提交论文？我知道对于学术界/研究人员来说，这是一个很好的机会来了解人们并了解当前的研究。但由于我不再在那里，有真正的理由去吗？ 这是一个很奇怪的问题，但我只是不确定，我很高兴听到你的想法。  &gt;   由   提交 /u/meni_s   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</guid>
      <pubDate>Thu, 02 May 2024 21:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] Panza：个人电子邮件助理，经过培训并在设备上运行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciqvqw/p_panza_a_personal_email_assistant_trained_and/</link>
      <description><![CDATA[厌倦了精心撰写电子邮件，希望有一位助手来接管这些辛苦的工作，同时模仿您的写作风格？向您介绍 Panza，一款完全在您的设备上运行的个性化 LLM 电子邮件助手！在 Llama-3 或 Mistral 之间进行选择，根据您的独特风格进行定制，让它为您撰写电子邮件。查看我们的演示并在您的电子邮件中尝试一下：https://github.com/IST-DASLab/PanzaMail 有关 Panza 的一些技术细节：  Panza 是一个自动电子邮件助手，可根据您的写作风格和过去的电子邮件历史记录进行定制。 Panza 生成与您的写作风格相匹配的经过微调的 LLM，并将其与检索增强生成 (RAG) 组件配对，帮助其生成相关的电子邮件。 Panza **可以完全在本地进行训练和运行**。目前，它需要具有 16-24 GiB 内存的单个 GPU，但我们还计划发布仅限 CPU 的版本。 训练和执行也很快 - 对于大约 1000 封电子邮件的数据集，训练 Panza 需要不到一个小时的时间，而生成一封新电子邮件最多只需几秒钟。     提交人    /u/eldar_ciki   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciqvqw/p_panza_a_personal_email_assistant_trained_and/</guid>
      <pubDate>Thu, 02 May 2024 21:07:30 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]寻求帮助以找到更好的GPU设置。三台 H100 与五台 A100？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</link>
      <description><![CDATA[长话短说，一家公司有购买 GPU 的预算，预计用于微调 LLM（可能是 70B 的），我必须进行研究找出哪种 GPU 设置最适合他们的预算。 预算可以购买三个 H100 GPU 或五个 A100 GPU。  我已尽了最大努力，但直到现在我还不清楚这些设置中哪一个更好。虽然五台 A100 拥有更多 VRAM，但他们说 H100 比 A100 快 2-8 倍！ 我正在寻求帮助。任何有价值的见解将不胜感激。   由   提交/u/nlpbaz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</guid>
      <pubDate>Thu, 02 May 2024 19:49:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于 ICML、NeurIPS、CVPR 等顶级会议，我一直在思考的事情。有多少论文是真正具有开创性的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</link>
      <description><![CDATA[我自己也有一些位于金星顶端的论文，但每当我坐下来对自己残酷地诚实时。我觉得我的作品不错，但影响力不大，就像墙上又多了一块砖。我想知道我们多久能看到像“注意力就是你所需要的一切”这样有影响力的东西。例如。   由   提交 /u/oddhvdfscuyg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</guid>
      <pubDate>Thu, 02 May 2024 18:37:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基准创建者应分阶段发布其基准数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cilnzv/d_benchmark_creators_should_release_their/</link>
      <description><![CDATA[关于基准污染的讨论很多，模型是根据最终评估的数据进行训练的。例如，最近的一篇论文表明，模型在公开的 GSM8K 上的表现明显优于 GSM1K，这是 Scale AI 最近创建的基准，旨在在难度和其他指标上与 GSM8K 相匹配。 由于对基准污染的担忧，通常很难相信研究实验室关于模型性能的说法。很难知道一个模型获得良好的基准性能是因为它通常很有能力，还是因为它的预训练数据被污染并且它在基准上过度拟合。 解决此问题的一种方法是基准创建者分阶段发布他们的数据集。例如，基准测试创建者可以在发布时发布 50% 的数据集，然后分两个阶段发布剩余的 50%，一年后发布 25%，两年后发布 25%。这将使模型评估者能够通过比较在训练截止之前发布的数据子集与在训练截止之后发布的数据子集的性能来检查基准测试污染。它还将使我们更好地了解模型的实际性能。 最后一点 - 这种分阶段发布过程对于通过抓取网络创建的基准测试来说并没有那么有用，因为即使是后来发布的数据子集也可以在训练数据中找到。但它应该对其他类型的基准测试有用。    提交人    /u/kei147   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cilnzv/d_benchmark_creators_should_release_their/</guid>
      <pubDate>Thu, 02 May 2024 17:36:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] spRAG - 用于具有挑战性的现实世界任务的开源 RAG 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cikkw2/p_sprag_opensource_rag_implementation_for/</link>
      <description><![CDATA[大家好，我是 Superpowered AI (YC S22) 的 Zach。我们在 RAG 领域的工作已经一年多了，最近我们决定开源所有核心检索技术。 [spRAG](https://github.com/SuperpoweredAI/spRAG）是一个检索系统，旨在处理密集文本上的复杂现实查询，例如法律文档和财务报告。据我们所知，对于此类任务，它是所有 RAG 系统中最准确、最可靠的结果。例如，在 FinanceBench（这是一个特别具有挑战性的开放式金融问答基准）上，spRAG 正确回答了 83% 的问题，而普通 RAG 基准的正确率为 19%（使用 Chroma + OpenAI Ada）嵌入 + LangChain）。 您可以在项目的自述文件中找到有关其工作原理以及如何使用它的更多信息。我们也非常愿意接受贡献。我们特别需要围绕集成（即添加对更多向量数据库、嵌入模型等的支持）和评估方面的贡献。 很高兴回答任何问题！ [GitHub 存储库]( https://github.com/SuperpoweredAI/spRAG)   由   提交/u/zmccormick7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cikkw2/p_sprag_opensource_rag_implementation_for/</guid>
      <pubDate>Thu, 02 May 2024 16:50:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文已被 ICML 接受但未亲自参加？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cigigh/d_paper_accepted_to_icml_but_not_attending_in/</link>
      <description><![CDATA[论文刚刚被 ICML 接受。说实话，这真是一个惊喜。不幸的是，对于两位作者来说，我们要么没有美国的回程签证，要么很可能没有 7 月份会议的未过期护照。我想知道是否可以接受支付475美元的会议注册费，但不参加，但我们的论文仍然在会议记录中发表。我注意到会议注册确实包括对所有会议和教程的虚拟访问。但我不确定出版部分。   由   提交 /u/Normal-Comparison-60   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cigigh/d_paper_accepted_to_icml_but_not_attending_in/</guid>
      <pubDate>Thu, 02 May 2024 14:04:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大三学生（本科生或一二年级博士生）在ICML、ICLR、NeurIPS等主要机器学习会议上有这么多论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</link>
      <description><![CDATA[大家好，今天ICML成绩出来了，恭喜所有在这里接受论文的同学。我自己不是学者，但有时我会为了工作而阅读这些会议上的论文，这真的很有趣。我只是有一个问题：为什么这些会议上大三的论文这么多？我认为这是你在 5 年博士学位期间必须学习的东西，而且几乎只能在博士学位的最后几年才能实现。另外，我听说要进入美国顶尖的博士项目，你需要事先写一些论文。那么，如果一个大三学生能这么早发表论文，为什么还要花5年时间攻读博士学位呢？   由   提交 /u/ShiftStrange1701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</guid>
      <pubDate>Thu, 02 May 2024 11:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] Pytorch 的现代最佳编码实践（用于研究）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chxpka/d_modern_best_coding_practices_for_pytorch_for/</link>
      <description><![CDATA[大家好，我从 2019 年开始使用 Pytorch，在那段时间它发生了很大的变化（尤其是自从 Huggingface 以来）。  您有推荐的现代指南/style-docs/example-repos 吗？例如，命名张量是一种好的/常见的做法吗？推荐使用 Pytorch Lightning 吗？目前最好的配置管理工具是什么？您多久使用一次 torch.script 或 torch.compile？   由   提交 /u/SirBlobfish   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chxpka/d_modern_best_coding_practices_for_pytorch_for/</guid>
      <pubDate>Wed, 01 May 2024 21:24:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] KAN：柯尔莫哥洛夫-阿诺德网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chrafb/r_kan_kolmogorovarnold_networks/</link>
      <description><![CDATA[      论文：https://arxiv. org/abs/2404.19756 代码：https://github.com /KindXiaoming/pykan 快速介绍：https:/ /kindxiaoming.github.io/pykan/intro.html 文档：https://kindxiaoming.github.io/pykan/ 摘要：  受到 Kolmogorov-Arnold 表示的启发定理中，我们提出Kolmogorov-Arnold Networks（KAN）作为多层感知器（MLP）的有希望的替代品。 MLP 在节点（“神经元”）上具有固定激活函数，而 KAN 在边缘上具有可学习激活函数(“权重”)。 KAN 根本没有线性权重——每个权重参数都被参数化为样条函数的单变量函数所取代。我们证明，这种看似简单的改变使得 KAN 在准确性和可解释性方面优于 MLP。就准确性而言，在数据拟合和 PDE 求解中，较小的 KAN 可以比较大的 MLP 获得可比或更好的准确性。从理论上和经验上来说，KAN 比 MLP 拥有更快的神经尺度法则。为了可解释性，KAN 可以直观地可视化，并且可以轻松地与人类用户交互。通过数学和物理领域的两个例子，KAN 被证明是帮助科学家（重新）发现数学和物理定律的有用合作者。总之，KAN 是 MLP 的有希望的替代品，为进一步改进当今严重依赖 MLP 的深度学习模型提供了机会。  https://preview.redd.it/r7vjmp31juxc1.png?width=2326&amp;format=png&amp;auto=webp&amp; amp;s= a2c722cf733510194659b9aaec24269a7f9e5d47   由   提交 /u/SeawaterFlows   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chrafb/r_kan_kolmogorovarnold_networks/</guid>
      <pubDate>Wed, 01 May 2024 17:03:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>