<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 11 Jan 2025 12:30:06 GMT</lastBuildDate>
    <item>
      <title>[D] 在哪里可以找到机器学习工程师/人工智能工程师的面试经历？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hyskcn/d_where_can_i_find_machine_learning_engineerai/</link>
      <description><![CDATA[我需要了解一些除 glassdoor 之外的候选人的面试经历。我想要一些资源，告诉我面试有多少轮，每轮发生了什么。如果你有这样的资源，请告诉我。    提交人    /u/nanuupendra   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hyskcn/d_where_can_i_find_machine_learning_engineerai/</guid>
      <pubDate>Sat, 11 Jan 2025 09:42:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 检查你的学者统计数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hypgxp/p_check_your_scholar_stats/</link>
      <description><![CDATA[  由    /u/yoonjeewoo  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hypgxp/p_check_your_scholar_stats/</guid>
      <pubDate>Sat, 11 Jan 2025 05:56:55 GMT</pubDate>
    </item>
    <item>
      <title>澳大利亚的机器学习和人工智能就业市场如何？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hypeqa/how_is_the_job_market_for_machine_learning_and_al/</link>
      <description><![CDATA[大家好。我是一名驻澳大利亚的研究员，如果可能的话，我想听听你对机器学习市场的看法。我发现了一篇 2 年前的帖子，想了解一下最新的观点。提前谢谢大家。    提交人    /u/BillnoGates   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hypeqa/how_is_the_job_market_for_machine_learning_and_al/</guid>
      <pubDate>Sat, 11 Jan 2025 05:52:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 条件扩散与嵌入模型的联合训练？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hygkbr/r_joint_training_of_conditional_diffusion_with/</link>
      <description><![CDATA[有人知道同时训练条件扩散模型和嵌入模型的有效性吗？我的目标是训练一个以状态和时间为条件的扩散模型，以产生随时间推进 n 个时间步的状态，但嵌入模型无法提前知道或预训练。  我见过的最接近我需要的是 GenCast，但我不能简单地连接之前的状态。    提交人    /u/McRibMaster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hygkbr/r_joint_training_of_conditional_diffusion_with/</guid>
      <pubDate>Fri, 10 Jan 2025 22:15:25 GMT</pubDate>
    </item>
    <item>
      <title>[数据集][R] 19,762 张垃圾图像，用于构建 AI 回收解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hyfaoc/datasetr_19762_garbage_images_for_building_ai/</link>
      <description><![CDATA[大家好，ML 社区！ 我很高兴与大家分享垃圾分类 V2 数据集，其中包含 19,762 张高质量垃圾图像，这些垃圾被分为 10 个不同类别（例如金属、塑料、衣服和纸张）。 为什么这很重要：  训练 AI 模型以实现自动垃圾分类和回收。 开发垃圾分类应用程序或以可持续性为重点的工具。 创建创新的计算机视觉项目以影响环境。  🔗 数据集链接： 垃圾分类 V2 该数据集已在研究论文《通过迁移学习管理家庭垃圾》中使用，证明了其在实际应用中的实用性。 期待看到您如何使用它来促进可持续发展！    提交人    /u/Downtown_Bag8166   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hyfaoc/datasetr_19762_garbage_images_for_building_ai/</guid>
      <pubDate>Fri, 10 Jan 2025 21:19:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有关神经网络如何学习扭曲潜在空间以进行预测的资源？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hyefw5/d_resources_for_how_neural_nets_learn_to_warp/</link>
      <description><![CDATA[      有哪些好的资源可以进一步了解神经网络如何构建决策面？ 我最近阅读了 Chris Olah 关于“神经网络、流形和拓扑&quot; 以及“关于深度神经网络的线性区域数量&quot; (ICLR ‘14)。 对神经网络如何“学习折叠潜在空间”以进行预测的想法很感兴趣。  我对简单 MLP 层的直觉是，每个组件在这种几何扭曲中都扮演着不同的角色：  激活函数基本上充当了门控机制 (relu) 偏差向量是一种平移操作 矩阵乘法 Wx 可以通过 SVD（W=USV）来理解： U、V 是旋转/反射矩阵 S 是缩放矩阵   这些操作的组合和堆叠产生了这个伟大的数字： https://arxiv.org/abs/1402.1869 还有其他见解或资源可以参考这些想法吗？    提交人    /u/LetsTacoooo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hyefw5/d_resources_for_how_neural_nets_learn_to_warp/</guid>
      <pubDate>Fri, 10 Jan 2025 20:43:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练下一个字符预测的 MLP 是否需要因果掩蔽？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hye9ne/d_do_mlps_trained_for_next_character_prediction/</link>
      <description><![CDATA[假设我们有一些数据 X = [seq_len, batch_size] 和相应的标签 Y = [seq_len, batch_size, vocab_size/num/classes] ，独热编码。 现在，我们要训练一个 MLP 来预测下一个字符。 问题：我们是否需要应用因果掩蔽来限制模型在未来的标记中达到峰值？如果是这样，您将它应用在哪一层或输出上？ 在训练期间，模型会看到整个序列并预测相应的独热编码标签。 通常，我见过的大多数示例都使用 X 及其移位版本 `Y = X&#39;` 作为标签来训练下一个字符预测，但这与我的情况不符，因为我已经有独热编码标签。    提交人    /u/kirk86   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hye9ne/d_do_mlps_trained_for_next_character_prediction/</guid>
      <pubDate>Fri, 10 Jan 2025 20:36:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 迈向法学硕士中的系统 2 推理：学习如何使用元思维链进行思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hye3gm/r_towards_system_2_reasoning_in_llms_learning_how/</link>
      <description><![CDATA[  由    /u/jsonathan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hye3gm/r_towards_system_2_reasoning_in_llms_learning_how/</guid>
      <pubDate>Fri, 10 Jan 2025 20:29:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 小型语言模型通过自我进化的蒙特卡洛树搜索掌握复杂数学</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hycnb4/r_small_language_models_master_complex_math/</link>
      <description><![CDATA[这里的关键创新是一种自我进化机制，它使小型语言模型能够通过迭代改进和自我修正来执行复杂的数学推理。这种方法称为 rStar-Math，它使用结构化的分解和验证步骤来实现与更大模型相当的性能，同时使用更少的参数。 关键技术点： - 生成、评估和改进解决方案的多步骤推理框架 - 随着时间的推移开发更复杂的推理模式的自我进化机制 - 实施验证步骤以捕获和纠正错误 - 将复杂问题结构化分解为可管理的子任务 - 用于数学推理和解决方案验证的专用组件 结果： - 在复杂数学问题上实现 80% 以上的准确率 - 与参数多 10 倍的模型性能相匹配 - 自我修正将准确率提高了约 25% - 适用于多个数学领域 - 在数字和文字问题上都表现出一致的性能 我认为这种方法可以为在资源受限的环境中部署功能强大的 ML 系统带来变革。使用较小模型实现强大性能的能力为边缘设备和计算资源有限的场景开辟了可能性。自我进化机制也可以适用于需要复杂推理的其他领域。 我认为最有趣的方面是系统如何学会捕捉自己的错误并改进其推理过程，类似于人类如何发展数学问题解决技能。这可能导致更强大、更可靠的人工智能系统，可以解释他们的思维并自主纠正错误。 TLDR：小型语言模型可以通过自我进化和结构化验证步骤实现强大的数学推理能力，在使用更少资源的情况下匹配更大的模型。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hycnb4/r_small_language_models_master_complex_math/</guid>
      <pubDate>Fri, 10 Jan 2025 19:28:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] [P] Cohere For AI 启动新的法学硕士项目，重点关注多语言长语境理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hy3xn7/r_p_cohere_for_ai_launches_new_llm_cohort_focused/</link>
      <description><![CDATA[      来自 BIRDS（研究驱动研究初学者）小组 r/CohereAI，Cohere 开放科学社区，我们很高兴宣布我们的新 LLM 队列！🎉 🚀 这不仅仅是另一个学习计划；这是一项实践性的协作研究计划，旨在突破大型语言模型在多语言、长上下文设置中的可能性 💡 📚 我们将深入探讨两个令人兴奋的轨道： 🔬 轨道 1：多语言长上下文 - 使用先进技术增强处理 🤖 由领导：Mayank Bhaskar 和 Madhava Prasath 🎯 重点：探索尖端方法，如 RoPE（旋转位置嵌入）、NoPE（无位置编码）、LongROPE、SSM（状态空间模型）和混合 Transformer-SSM 模型，以克服多语言 NLP 中的长上下文挑战，增强可扩展性、效率和处理扩展序列的能力，同时解决传统 Transformer 的局限性。 🧠 挑战：开发一种新方法将 SSM 与 Transformers 相结合，优化长上下文多语言理解。在合成任务上表现出优于 RoPE、NoPE 和 LongRoPE 的卓越性能，强调对超出训练长度的序列的泛化和最小的计算开销。 https://preview.redd.it/x43aruufz5ce1.png?width=632&amp;format=png&amp;auto=webp&amp;s=9fc3e08f80f5a8713cdc4b39c7cb0284a2baf195 🔬 Track 2：评估多语言长上下文生成和推理 🤖 由领导：Guneet Singh Kohli 和 Shivalika Singh 🎯 重点：建立一个基准来评估多语言 LLM 处理涉及复杂推理的长上下文任务的能力。 🧠 挑战：对于长上下文任务，我们如何确保跨语言的准确、上下文相关的响应？评估现有 LLM 执行此类任务的能力，并提出数据创建管道以构建多语言长上下文基准。 https://preview.redd.it/i2r6z4ahz5ce1.png?width=680&amp;format=png&amp;auto=webp&amp;s=93dabba03df32da12fa577dc02516b9ad6048c3d 为什么加入？ 💼 获得实际研究经验：从头到尾参与真实世界的项目。 🤝 与专家合作：向经验丰富的研究人员学习并与他们一起学习。 🌐 塑造法学硕士的未来：为快速发展的领域的进步做出贡献。 📅 启动电话：本周五，1 月 10 日太平洋时间上午 10:00 加入我们，详细了解该群体并与轨道负责人见面！ https://preview.redd.it/1uyvx9fiz5ce1.png?width=680&amp;format=png&amp;auto=webp&amp;s=fc43363fb8cc277e7bcdf3725e9c66f5f92b9df7 2025 年将成为开创性研究的一年，让我们一起踏上这段激动人心的探索之旅！  https://i.redd.it/01luy73mz5ce1.gif    由   提交  /u/CATALUNA84   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hy3xn7/r_p_cohere_for_ai_launches_new_llm_cohort_focused/</guid>
      <pubDate>Fri, 10 Jan 2025 13:03:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我试图寻找大多数人类可以解决但推理模型却很难解决的常识性问题。以下是一个例子</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hy05iu/d_i_am_trying_to_find_common_sense_problems_that/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hy05iu/d_i_am_trying_to_find_common_sense_problems_that/</guid>
      <pubDate>Fri, 10 Jan 2025 08:46:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 撰写合适的 LLM 摘要的费用出奇地昂贵</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hxzij5/d_creating_proper_llm_summaries_is_surprisingly/</link>
      <description><![CDATA[        提交人    /u/Hot-Chapter48   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hxzij5/d_creating_proper_llm_summaries_is_surprisingly/</guid>
      <pubDate>Fri, 10 Jan 2025 07:57:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] rStar-Math：小型法学硕士可以通过自我进化的深度思维掌握数学推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hxk2ab/r_rstarmath_small_llms_can_master_math_reasoning/</link>
      <description><![CDATA[  由    /u/jsonathan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hxk2ab/r_rstarmath_small_llms_can_master_math_reasoning/</guid>
      <pubDate>Thu, 09 Jan 2025 18:51:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 05 Jan 2025 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>