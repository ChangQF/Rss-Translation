<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 17 Jan 2024 06:19:04 GMT</lastBuildDate>
    <item>
      <title>[P] 使用 Excel 知识库训练 AI 聊天机器人。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198pfie/p_train_ai_chatbot_using_an_excel_knowledge_base/</link>
      <description><![CDATA[大家好 我想知道使用 Tock 是否可以执行以下操作： 我想创建一个聊天机器人，例如 https://web-chat.global.assistant.watson.cloud.ibm.com/preview.html?region=eu-de&amp;integrationID =38c262cc-f146-4cc5-bd28-923289cd72d9&amp;serviceInstanceID=dbfc3cd6-9c12-4780-8310-b6d77872b29b 目标是 能够有一个excel ，我们将能够将类别/子类别/答案转换为 Json 文件并导入到 BOT 当用户使用属于多个类别/答案的关键字提出问题时，为了让机器人给出正确的答案，我们想要仅显示与子类别相关的常见问题解答按钮，这将有助于聊天机器人给出正确的答案。当机器人发现有超过 1 个答案时，它会单独执行此操作。因此，例如，如果用户写“忘记密码”，机器人应该放置 2 个按钮：“Web 签入”和“已经并联属”？就像这样，如果用户点击： “网络签入”，则答案将是“如果您找不到您的登录详细信息，并且在注册时没有收到电子邮件发送给您”。已经和附属机构”，答案将是“如果您丢失了入住密码，您将必须转到下一页并输入您的电子邮件” 您知道这是否可能吗？除了 Tock 之外还有其他选择。我想将此聊天集成到我的网站中，但它具有非常特定的用途，因此需要进行自定义。 谢谢！ &lt;!-- SC_ON - -&gt;  由   提交/u/tried-another  /u/tried-another  reddit.com/r/MachineLearning/comments/198pfie/p_train_ai_chatbot_using_an_excel_knowledge_base/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198pfie/p_train_ai_chatbot_using_an_excel_knowledge_base/</guid>
      <pubDate>Wed, 17 Jan 2024 05:54:15 GMT</pubDate>
    </item>
    <item>
      <title>[N] VizWiz 推出 6 项人工智能挑战赛，帮助盲人/弱视社区</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198p87h/n_vizwiz_launches_6_ai_challenges_to_help/</link>
      <description><![CDATA[问候！ 我们很高兴宣布第六届年度VizWiz Grand Challenge 研讨会，将与 CVPR 2024 同期举行。我们欢迎您参加，如果您能帮助我们传播信息，我们将不胜感激。 本次研讨会的部分动机是我们观察到盲人依赖（基于人类的）视觉辅助服务来了解他们十多年来捕捉的图像和视频。我们为人工智能社区引入了视觉问答、少量镜头识别和对象定位数据集挑战，以代表真实的用例。  挑战：  视觉问答 (VQA) VQA 接地 具有多个答案基础的 VQA 基础 少量视频对象识别 少量对象本地化 零样本图像分类  关键日期：  1 月 12 日，星期五：挑战上线 5 月 3 日星期五：向评估服务器提交算法结果 5 月 10 日星期五：提交扩展摘要 5 月 17 日星期五：向作者发出有关扩展摘要决定的通知 挑战结果将在 CVPR 2024 的 VizWiz Grand Challenge 研讨会上公布  期待您的参与！   由   提交/u/eee-vaaah  /u/eee-vaaah reddit.com/r/MachineLearning/comments/198p87h/n_vizwiz_launches_6_ai_challenges_to_help/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198p87h/n_vizwiz_launches_6_ai_challenges_to_help/</guid>
      <pubDate>Wed, 17 Jan 2024 05:42:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练模型的协作平台？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198oqcb/d_collaborative_platform_to_train_your_models/</link>
      <description><![CDATA[嗨，我们正在与我的团队一起培训 OS LLM，并希望一起培训/测试它（实验控制、评估、评论等）。 ..) 现在我们使用重量和重量。偏见，但就我个人而言，我并不是他们用户体验的忠实粉丝。 您还有推荐的其他工具吗？ 谢谢！   由   提交/u/Diligent_Eye1248   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198oqcb/d_collaborative_platform_to_train_your_models/</guid>
      <pubDate>Wed, 17 Jan 2024 05:14:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 离线批量服务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198k375/d_offline_batch_serving/</link>
      <description><![CDATA[我对如何为离线批量预测提供机器学习模型感到困惑。 这是我想做的 -创建一个预定的管道（例如 Airflow、Kubeflow 等）来生成特征，然后从某个对象存储（例如 s3）加载经过训练的模型，生成预测，最后将它们保存到数据仓库中以供使用。这对我来说最有意义。 但是，一些资源似乎建议将模型部署为端点，即使对于批量用例也是如此。值得注意的是，这是 Chip Huyen 的《设计机器学习系统》中推荐的架构。 对此有什么想法吗？我错过了什么吗？   由   提交/u/Appropriate_Cut_6126   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198k375/d_offline_batch_serving/</guid>
      <pubDate>Wed, 17 Jan 2024 01:25:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 监督（可能）集群或多代理旅行商人问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198jyq7/p_supervised_maybe_clustering_or_multiagent/</link>
      <description><![CDATA[大家好。我在为地图点组分配标签时遇到问题。我们可以将它们视为我们应该访问的点。我们还有一些球探会访问这些地点。我们应该用最少的时间来做这件事。这是一种旅行商人问题，但涉及多个商人。 我的想法是确定每个点的权重作为到其他点的距离，然后应用带有 N 个聚类的加权 K 均值。之后我们就可以解决个别优化问题 但我对这种方法有一些担忧。我们有标签，这些标签是如何由人类分配的，但我们根本不使用它。由于每次侦察的数量不同，我们无法解决分类问题。另外，该算法不能将点标记为“噪声”（例如 HDBSCAN 中的点），这并不重要，但对于距离其他点非常远的点可能很有用 关于如何解决它有什么考虑吗？    由   提交/u/Jor_ez   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198jyq7/p_supervised_maybe_clustering_or_multiagent/</guid>
      <pubDate>Wed, 17 Jan 2024 01:19:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在组织中推出推荐模型的项目模板/步骤</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198jh0u/d_project_templatesteps_for_rolling_out_a/</link>
      <description><![CDATA[我对构建内容推荐模型有些满意。我不太确定如何确定项目范围以及将项目推出到我们的应用程序中所涉及的更广泛的步骤。 是否有关于项目管理此类功能的蓝图？例如。目标、特征探索、模型选择、训练、测试、“将模型实施到生产中的步骤”？   由   提交/u/back-off-warchild  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198jh0u/d_project_templatesteps_for_rolling_out_a/</guid>
      <pubDate>Wed, 17 Jan 2024 00:57:28 GMT</pubDate>
    </item>
    <item>
      <title>[P]从头开始的小型潜伏扩散变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198eiv1/p_small_latent_diffusion_transformer_from_scratch/</link>
      <description><![CDATA[      我训练了一个相对简单的基于 Transformer 的扩散模型来生成 256 x 256 图像从头开始。这是仓库： https://github.com/apapiu/transformer_latent_diffusion/tree/main - 代码应该希望它相当容易理解并且独立。 以下是在 1A100 从头开始​​训练大约 30 小时后的一些示例： 根据各种提示生成图像 该模型基于 DiT /Pixart-alpha 架构，但进行了各种修改和简化。我还在噪声表方面做出了一些有问题的决定，但似乎工作正常。 该模型是 100MM 参数，因此应该很容易对其进行实验。我欢迎任何反馈，也欢迎合作，所以请联系我们！希望这对想要尝试扩散模型/变压器但“GPU 较差”的人们有所帮助。 :) 该存储库还链接到一个 colab，您可以在其中使用自己的输入 - 请随意尝试。 ​    由   提交 /u/spring_m   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198eiv1/p_small_latent_diffusion_transformer_from_scratch/</guid>
      <pubDate>Tue, 16 Jan 2024 21:29:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 时间序列数据上的 MAMBA 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1989o55/d_mamba_models_on_time_series_data/</link>
      <description><![CDATA[大家好，我最近对 ​​MAMBA 架构很感兴趣，特别是因为它采用线性时间无关数学模型作为一种内存。我热衷于将其应用于时间序列分类或回归任务，但我在网上找到的大多数信息都集中在它在语言建模中的使用。尽管我尝试在时间序列数据集上训练这些模型，但它们似乎没有学到任何东西。我想知道你们中是否有人遇到过 MAMBA 模型成功地接受时间序列数据训练的例子，以便找出我做错了什么。提前致谢！   由   提交 /u/jumpyAlucard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1989o55/d_mamba_models_on_time_series_data/</guid>
      <pubDate>Tue, 16 Jan 2024 18:16:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何处理雇主提出的不合理要求以及对机器学习不切实际的期望？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19882l2/d_how_do_you_deal_with_unreasonable_request_from/</link>
      <description><![CDATA[几个月前，我接受了一个职位，通过为社会科学研究项目训练机器学习模型来支持该项目。该项目涉及使用团队（由多名实习生、研究生、博士后和教授组成）花费数年时间并付出疯狂努力编制的数据集。然而，问题是他们没有事先咨询任何真正了解机器学习的人。对于非常复杂的任务来说，他们的数据集太小（只有大约 200 行）。更糟糕的是，大多数变量的预测价值微乎其微，而用于推导这些变量的方法虽然非常耗费人力，却引发了人们对其有效性的担忧。 该项目的 MO 绝对令人困惑：通过巨大的数据积累了数千个预测变量。努力和人力，期待完美的结果。任何模型如何用如此小的数据集估计如此多的参数却被忽视了。项目负责人似乎对 ML 有着某种神奇的理解，这可能是受到其在特定领域频繁误用的影响。这个项目的灵感尤其来自于一篇研究论文，我几乎可以保证该论文在其验证集上过拟合。 所有这些都让我处于尴尬的境地，作为新人，我需要告知这一点一个由经验丰富的博士后和教授组成的团队，全部来自社会科学背景，没有定量专业知识，他们多年的工作产生了一个完全不适合他们的目标的数据集，并且他们所建立的现有文献都是错误的，因为他们显然没有不知道什么是测试集以及何时使用它。我也不能告诉他们只扩展数据集，因为达到 200 行已经花费了数年时间。 我必须承认我对这次谈话有点紧张。 ​ 我怀疑对 ML 功能抱有不切实际的期望是一种常见的经历。其他人如何处理这个问题？你是否会直白地告诉他们这行不通，如果他们坚持不管，你就去别处找工作吗？如果是这样，这些交互通常如何进行？   由   提交 /u/Excusemyvanity   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19882l2/d_how_do_you_deal_with_unreasonable_request_from/</guid>
      <pubDate>Tue, 16 Jan 2024 17:13:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] APAR：法学硕士可以进行自动并行自动回归解码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1987em3/r_apar_llms_can_do_autoparallel_autoregressive/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.06761 摘要：  大型语言模型（LLM）的大规模采用需要高效部署策略。然而，自回归解码过程是大多数法学硕士生成文本的基础，它对实现高效服务提出了挑战。在这项工作中，我们介绍了一种并行自回归生成方法。通过对包含层次结构的通用领域数据进行指令调整，我们使法学硕士能够独立规划其生成过程并执行自动并行自回归（APAR）生成，从而显着减少生成步骤的数量。单独使用 APAR 即可实现高达 2 倍的加速，与推测解码结合使用时，加速可高达 4 倍。此外，APAR 减少了生成过程中的键值缓存消耗和注意力计算。与最先进的服务框架相比，这使得高吞吐量场景中的吞吐量提高了 20-70%，延迟降低了 20-35%。     由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1987em3/r_apar_llms_can_do_autoparallel_autoregressive/</guid>
      <pubDate>Tue, 16 Jan 2024 16:46:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer 是多状态 RNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1986k0x/r_transformers_are_multistate_rnns/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.06104 代码：https ://github.com/schwartz-lab-NLP/TOVA 摘要：  Transformers 被认为在概念上与到上一代最先进的 NLP 模型 - 循环神经网络 (RNN)。在这项工作中，我们证明了仅解码器 Transformer 实际上可以被概念化为无限多状态 RNN——一种具有无限隐藏状态大小的 RNN 变体。我们进一步证明，通过固定隐藏状态的大小，预训练的 Transformer 可以转换为有限多状态 RNN。我们观察到一些现有的转换器缓存压缩技术可以被构建为这样的转换策略，并引入了一种新的策略，TOVA，它比这些策略更简单。我们对多个远程任务进行的实验表明，TOVA 优于所有其他基线策略，同时几乎与完整（无限）模型相当，并且在某些情况下仅使用原始缓存大小的 1/8。我们的结果表明，变压器解码器 LLM 在实践中通常表现为 RNN。他们还提出了缓解最痛苦的计算瓶颈之一——缓存大小的选项。我们在 此 https URL 公开发布我们的代码。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1986k0x/r_transformers_are_multistate_rnns/</guid>
      <pubDate>Tue, 16 Jan 2024 16:12:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] iPhone 文本检测的有趣现象</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197zbzs/d_interesting_occurrence_about_text_detection_of/</link>
      <description><![CDATA[      我点击该图像几次，它检测到第二只狗是单词“dog”用中文写的。我不认为这是有原因的，但如果有人有任何想法，我很乐意听到他们。   由   提交/u/Ok_Care_886   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197zbzs/d_interesting_occurrence_about_text_detection_of/</guid>
      <pubDate>Tue, 16 Jan 2024 09:57:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深度学习最好的进阶书籍？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197r6o0/d_best_advanced_books_of_deep_learning/</link>
      <description><![CDATA[我遇到的几乎所有书籍都是从头开始写的。他们是否有深入探讨主题的地方？   由   提交/u/toxfu  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197r6o0/d_best_advanced_books_of_deep_learning/</guid>
      <pubDate>Tue, 16 Jan 2024 02:12:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您对强化学习的真实体验是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197jp2b/d_what_is_your_honest_experience_with/</link>
      <description><![CDATA[根据我个人的经验，SOTA RL 算法根本不起作用。我尝试强化学习已有 5 年多了。我记得当 Alpha Go 击败世界著名围棋棋手 Lee Sedol 时，每个人都认为 RL 会席卷 ML 社区。然而，除了玩具问题之外，我个人从未找到过 RL 的实际用例。 您对此有何体验？除了广告推荐系统和 RLHF 之外，RL 是否还有合法的用例？或者，这都是炒作吗？ 编辑：由于我的评论被否决，这里是我的文章的链接可以更好地描述我的立场。 这并不是说我不理解强化学习。我发布了我的开源代码和就此写了一篇论文。 事实是它非常难以理解。其他深度学习算法，如 CNN（包括 ResNet）、RNN（包括 GRU 和 LSTM）、Transformers 和 GAN 并不难理解。这些算法可以工作，并且在实验室外有实用用例。 传统的 SOTA RL 算法（如 PPO、DDPG 和 TD3）非常困难。即使解决一个玩具问题，你也需要做大量的研究。相比之下，决策转换器是任何人都可以实现的东西，而且它似乎匹配或超越了 SOTA。您不需要两个网络相互竞争。您不必经历地狱般的事情来调试您的网络。它只是自然地以自回归的方式学习最好的一组动作。 我也不是故意显得傲慢或暗示强化学习不值得学习。我只是还没有看到任何现实世界中的实际用例。我只是想开始讨论，而不是声称我什么都知道。 编辑 2：令人震惊的是，有很多人因为我没有完全理解 RL 而称我为白痴。你们太自在了称呼不同意的人的名字。新闻快讯，并不是每个人都拥有机器学习博士学位。我的本科学位是生物学。我自学了高级数学来理解机器学习。我对这个领域充满热情；我在 RL 方面的经历非常令人失望。 有趣的是，很少有人反驳我的实际观点。总结一下：  缺乏实际应用 极其复杂且 99% 的人无法使用 比 CNN、RNN 和 GAN 等传统深度学习算法困难得多 样本效率低下且不稳定 难以调试 更好的替代方案，例如决策转换器&lt; /li&gt;  这些难道不是合理的批评吗？本子的目的不是要讨论与机器学习相关的问题吗？ 致少数没有称我为白痴的评论者……谢谢！请记住，你不需要付出任何代价就能变得友善！ 编辑 3：很多人似乎都认为 RL 被过度炒作了。不幸的是，这些评论被否决了。澄清一些事情：  我们在强化学习上投入了大量资金。我们从这项投资中得到的只是一个可以在（某些）视频游戏中超越人类的机器人。 AlphaFold 没有使用任何强化学习。 SpaceX 也没有。  我承认它对机器人技术很有用，但仍然认为它在实验室之外的用例极其有限。  如果您无意中发现了这条线索并对 RL 替代方案感到好奇，请查看决策转换器。它可以用于任何可以使用传统强化学习算法的情况。 最终编辑：感谢最近贡献的人们，感谢你们深思熟虑的讨论！据我所知，像 Dreamer 和 IRIS 这样基于模型的模型可能会有未来。但每个真正使用过像 DDPG 这样的无模型模型的人都一致认为它们很糟糕而且不起作用。   由   提交 /u/Starks-Technology   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197jp2b/d_what_is_your_honest_experience_with/</guid>
      <pubDate>Mon, 15 Jan 2024 20:56:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>