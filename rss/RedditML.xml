<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 01 Jun 2024 09:16:43 GMT</lastBuildDate>
    <item>
      <title>[D] 我该如何提高对 food101 的适应度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5i3x1/d_how_can_i_improve_the_acc_with_food101/</link>
      <description><![CDATA[大家好，我在使用 food101 数据集时遇到了一些困难，我尝试使用 CNN 并使用我自己制作的以下架构来预测它： https://github.com/6CRIPT/food101-ComIA/blob/main/food101-comia-architecture.ipynb 但我只获得了 25% 左右的准确率，所以我想知道我还能做些什么来获得至少 +60% 的准确率的好结果。没有限制，但保留了架构的整体思想。  我已经尝试了很多不同的想法，但是由于时间紧迫，在我的 PC 上运行每列火车都需要几个小时，所以我请求帮助。 谢谢 =D    提交人    /u/Gotz16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5i3x1/d_how_can_i_improve_the_acc_with_food101/</guid>
      <pubDate>Sat, 01 Jun 2024 08:06:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 情境学习是否足以满足法学硕士 (LLM) 课程的指导要求？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hh86/r_is_incontext_learning_sufficient_for/</link>
      <description><![CDATA[上下文学习 (ICL) 允许 LLM 从示例中学习而不改变其权重，这对于可以从许多示例中学习的长上下文 LLM 来说是一项特别有前途的功能。最近，Lin 等人 (2024) 提出了 URIAL，这是一种仅使用三个上下文示例来对齐基础 LLM 的方法，可实现非平凡的指令跟踪性能。在这项工作中，我们表明，虽然有效，但使用 URIAL 的 ICL 对齐与已建立的基准（例如 MT-Bench 和 AlpacaEval 2.0 (LC)）上的指令微调相比仍然表现不佳，尤其是对于功能更强大的基础 LM。与分类、翻译或摘要等任务不同，为长上下文 LLM 添加更多 ICL 演示并不能系统地提高指令跟踪性能。为了解决这一限制，我们推导出一种针对 ICL 示例的贪婪选择方法，该方法可显着提高性能，但不会弥合与指令微调之间的差距。最后，我们提供了一系列消融研究，以更好地了解剩余差距背后的原因，并展示了 ICL 的某些方面如何偏离现有知识并特定于指令调整设置。 总的来说，我们的工作推进了对 ICL 作为一种对齐技术的理解。    提交人    /u/m_andriushchenko   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hh86/r_is_incontext_learning_sufficient_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:21:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] DeTikZify：使用 TikZ 合成科学图形和草图的图形程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hh0s/p_detikzify_synthesizing_graphics_programs_for/</link>
      <description><![CDATA[        由    /u/DrCracket 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hh0s/p_detikzify_synthesizing_graphics_programs_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:20:46 GMT</pubDate>
    </item>
    <item>
      <title>[D]您最喜欢使用哪些研究工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hdve/dwhat_are_your_favorite_tools_that_you_use_for/</link>
      <description><![CDATA[作为一名研究人员，我发现有几种工具确实能帮助我更好地工作、更轻松地写作并跟上最新研究。这些工具对于管理我的项目、与他人合作以及确保我的工作彻底性非常有用。以下是我个人最喜欢的工具： blainy.com： Blainy 是一种 AI 写作工具，可轻松创建文章、作业和研究论文。它可以建议内容、具有自动写作选项、允许您自定义写作风格、管理引文、检查抄袭，并具有用于澄清的 PDF 聊天功能。它是改进学术工作的好工具。 connectedpapers.com：这是一个开始新研究项目的好工具。通过输入一篇相关论文，它会向您显示相关论文及其引文的图表。这样您就可以清楚地了解相关文献以及它们之间的联系。 researchrabbit.ai：与connectedpapers.com类似，但功能更多。它可以帮助您查找相关论文并跟上您所在领域的新研究。您可以创建收藏夹并获取符合您兴趣的新论文的更新。 litmaps.com：跟踪最新研究的绝佳工具。Litmaps可让您创建引文的可视化地图，并随时了解与您的工作相关的新论文。它对于了解研究随时间的发展非常有用。 overleaf.com：用于撰写研究论文或笔记的最佳网络应用程序。凭借版本控制、协作功能和基于Web的界面，Overleaf是用LaTeX编写的最佳方式，可轻松与他人合作和管理您的文档。 notion.so：灵活的项目管理工具，可根据研究项目进行定制。 Notion 可让您组织研究、与团队成员协作并在一个地方跟踪任务和截止日期。 zotero.org：一个强大的参考管理工具，可帮助您收集、组织、引用和共享研究。Zotero 与您的浏览器集成以直接保存研究文章，并与文字处理器配合使用以轻松管理引用。 mendeley.com：另一个强大的参考管理器和学术社交网络。Mendeley 可帮助您组织研究、与他人在线协作并发现最新研究。它还与文字处理器集成，可轻松管理引用和参考书目。 通过使用这些工具，您可以更高效地工作、保持井然有序，并确保您的学术写作是彻底的且得到良好的支持。    提交人    /u/mysticmuse72   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hdve/dwhat_are_your_favorite_tools_that_you_use_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:14:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM 的创新应用 | 有没有想过 LLM/GenAI 可以以这种方式使用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5eugs/p_innovative_applications_of_llms_ever_thought/</link>
      <description><![CDATA[  由    /u/dippatel21  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5eugs/p_innovative_applications_of_llms_ever_thought/</guid>
      <pubDate>Sat, 01 Jun 2024 04:29:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自动 LoRA 发现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</guid>
      <pubDate>Sat, 01 Jun 2024 04:09:17 GMT</pubDate>
    </item>
    <item>
      <title>调整剧本中的探索与利用——需要帮助理解流程 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5cxyq/exploration_vs_exploitation_in_tuning_playbook/</link>
      <description><![CDATA[[已编辑] 我正在阅读“Tuning Playbook”，在理解超参数调整背景下的探索与利用概念时遇到了一些困难。 有没有人可以用更具体而不是抽象的方式解释这个概念，或者提供一个在超参数调整中如何进行探索的例子？什么是探索以及如何进行探索。还有一件事；它一直在说理解问题，哪个问题？问题模型试图解决？还是什么超参数影响性能和相互影响的问题？还是什么？  这是书中关于这个主题的部分：  探索与开发  谢谢！    提交人    /u/Same_Half3758   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5cxyq/exploration_vs_exploitation_in_tuning_playbook/</guid>
      <pubDate>Sat, 01 Jun 2024 02:40:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 其他领域的研究，例如最近对一立方毫米人类脑组织的映射，能否帮助机器学习领域？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d56zg0/d_can_other_areas_researches_such_as_the_recent/</link>
      <description><![CDATA[https://www.scientificamerican.com/article/a-cubic-millimeter-of-a-human-brain-has-been-mapped-in-spectacular-detail/ 围绕人类大脑的研究，例如这张最新的人类大脑图谱，能否为机器学习领域提供一些见解，以构建更有效的人工智能/算法模型？ 外行人在这里。    提交人    /u/Enzo-chan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d56zg0/d_can_other_areas_researches_such_as_the_recent/</guid>
      <pubDate>Fri, 31 May 2024 21:40:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进行模型推理的更便宜的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d56h9c/d_cheaper_way_to_do_model_inference/</link>
      <description><![CDATA[有人知道在服务器停机期间节省 GPU 计算的解决方案吗？我目前正在进行模型推理，大多数时候我只是为计算付费，而不提供任何用户请求。    提交人    /u/Fun_Win_6054   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d56h9c/d_cheaper_way_to_do_model_inference/</guid>
      <pubDate>Fri, 31 May 2024 21:17:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] Bigram 标记器比现状更好吗？尤其是对于多语言</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4z5dr/d_bigram_tokenizers_better_than_status_quo/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4z5dr/d_bigram_tokenizers_better_than_status_quo/</guid>
      <pubDate>Fri, 31 May 2024 16:03:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 序列打包对于训练 Transformer 来说常见吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4tux3/d_is_sequence_packing_common_for_training/</link>
      <description><![CDATA[大家好， 我想从头开始训练一个小型 Transformer 语言模型，并试图尽可能提高训练效率。我一直在思考如何构建训练批次，这让我看到了这篇论文高效序列打包，避免交叉污染：加速大型语言模型，不影响性能，这似乎是一件非常合理的事情，一般情况下都应该这样做。 简而言之，这个想法是将多个序列打包在一个样本序列中，并调整注意力矩阵，使样本不会相互交叉污染，即只关注自身内的标记。 Huggingface 论坛中的这篇文章很好地说明了这一点。但我在 Huggingface transformers 中找不到这样的东西。我是不是漏掉了什么？其他框架实现了这个吗？我们知道大公司是否在进行序列打包吗？我是否错过了这个的主要缺点？我认为它可能会对位置编码造成问题。 编辑：Huggingface transformers 实际上支持这一点，请参阅 https://github.com/huggingface/transformers/pull/27539    提交人    /u/CloudyCloud256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4tux3/d_is_sequence_packing_common_for_training/</guid>
      <pubDate>Fri, 31 May 2024 11:58:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习会议和组织指标</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4shqn/d_ml_conferences_and_organization_metrics/</link>
      <description><![CDATA[我觉得很多人会认为 NeurIPS、ICLR、ICML 等是机器学习领域的重要会议。即使在机器学习之外，NeurIPS 和 ICLR 的 H 指数在所有会议中排名第 9 和第 10。但是，现在我正在查看全球的终身教职职位，情况似乎有所不同。这些出版物似乎对移民或学术终身教职毫无价值，因为它们不是传统期刊。您会注意到它们没有出现在 SCImago 中，SCImago 是许多组织用来衡量出版物质量的指标，因此会决定终身教职或移民。 我很好奇学术机器学习研究人员在这种情况下会做什么。您是否会停止向 NeurIPS 提交论文，而打算在 ACM “机器学习的基础和趋势”上发表论文，而该期刊 在 SCImago 上排名第二？还是在不断增长的机器学习 IEEE 期刊名单上？    提交人    /u/smorad   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4shqn/d_ml_conferences_and_organization_metrics/</guid>
      <pubDate>Fri, 31 May 2024 10:34:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] KAN ==多层GAM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4pjxp/d_kan_multilayer_gam/</link>
      <description><![CDATA[我刚刚阅读了 KAN 论文， 我的理解是，它提供了如何堆叠多层 GAM（广义加性模型）的解决方案：Phi 函数只是 GAM 的形状函数，而样条函数是 GAMS 中经过充分研究的形状函数。 所以对我来说：  MLP 是一个多层线性回归 KAN 是一个多层 GAM  尽管如此，GAM 具有 KAN 论文中未表达的链接功能，但在我看来，这才是这篇论文的真正重点。如果我们向 KAN 层添加激活函数，那么我们就完全拥有了多层 GAM。 这也意味着我们可以将 MLP 视为 KAN 的特例，因为线性回归是 GAM 的特例。 这听起来正确吗？    提交人    /u/mainro12   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4pjxp/d_kan_multilayer_gam/</guid>
      <pubDate>Fri, 31 May 2024 07:02:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 LipNet 进行唇读：端到端的句子级唇读</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4mpkw/r_lipreading_with_lipnet_endtoend_sentencelevel/</link>
      <description><![CDATA[      大家好， 我最近根据论文《端到端句子级唇读》从头开始实现了 LipNet。它通过从输入帧中的唇部运动中提取特征来预测句子。它最初是一个 3DConv-GRU 模型，我已经使用 3DConv-LSTM（双向）和一些其他具有不同复杂度的模型实现了它，并且已经利用 He（Kaiming Normal）初始化权重。 我请求您查看存储库并提供任何反馈，如果您发现它有用，请考虑分叉。 GitHub/LipNet 图片从官方论文编辑   由    /u/Kian5658  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4mpkw/r_lipreading_with_lipnet_endtoend_sentencelevel/</guid>
      <pubDate>Fri, 31 May 2024 04:00:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>