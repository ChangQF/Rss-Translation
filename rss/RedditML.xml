<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Wed, 24 Apr 2024 03:15:41 GMT</lastBuildDate>
    <item>
      <title>[D] 研究人员在考虑创建新的/改进的基础模型时如何考虑归纳偏差？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbnbsd/d_how_researcher_think_of_inductive_bias_when/</link>
      <description><![CDATA[我是学习机器学习的本科生。 我在阅读几篇论文时了解到我们试图减少搜索空间通过在机器学习模型中施加归纳偏差。当归纳偏差与基础数据相匹配时，创建有用模型就会成功。 在像 NVAE 这样的分层模型中，他们如何通过指定数据的计算方式来灌输归纳偏差？ （我认为这被称为算法偏差，但不确定） 但是人们如何认为这种归纳偏差会有帮助，他们坚持这种归纳偏差要经历什么步骤。 &lt;我参加了很多机器学习和统计学课程，但没有听过任何解释这些内容的讲座。我是否错过了任何课程/讲座？ 如果可能，请提供与之相关的论文/讲座/演讲 谢谢   由   提交 /u/binny_sarita   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbnbsd/d_how_researcher_think_of_inductive_bias_when/</guid>
      <pubDate>Wed, 24 Apr 2024 02:36:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态检索和排序的广义对比学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbixix/r_generalized_contrastive_learning_for_multimodal/</link>
      <description><![CDATA[对流行的 CLIP 训练方法进行概括，使其更适合搜索和推荐。  论文：https://arxiv.org/pdf/2404.08535.pdf Github：https://github.com/marqo-ai/GCL 概括CLIP：  使用任意数量的文本和/或图像来表示文档。 通过模态间和模内损失更好地理解文本。 可以对排名/重要性/相关性进行编码，又名“排名调整”。 适用于预训练、文本、CLIP 模型。 可以学习单向量或多向量表示用于文档。 适用于二进制和 Matryoshka 方法。 开源 10M 行多模态数据集，包含 100k 查询和约 5M 产品。  为什么？ 训练嵌入模型的主流方法在很大程度上与最终用例（如搜索）、向量数据库、用户的需求以及缺乏用于开发和评估的代表性数据集，特别是当涉及多种模式和排名时。 当前矢量搜索嵌入模型的局限性 尽管矢量搜索是虽然非常强大并且可以搜索几乎任何数据，但当前的方法有一些局限性。训练嵌入模型的流行方法在很大程度上与最终用例（如搜索）、向量数据库和用户的需求脱节。这意味着矢量搜索的许多潜力尚未得到满足。下面描述了当前的一些挑战。 仅限于使用单条信息来表示文档 当前模型编码并表示一条信息一个向量的信息。现实情况是，一份文档通常有多个相关信息，这些信息可能跨越多种模式。例如，在产品搜索中可能有标题、描述、评论和多个图像，每个图像都有自己的标题。 GCL 将嵌入模型训练概括为使用所需数量的信息。 处理退化查询时没有排名概念 当存在退化查询时查询 - 满足某些相关标准的多个结果 - 结果的排序只能从许多二元关系中间接学习。实际上，结果的排序很重要，即使对于第一阶段检索也是如此。 GCL 允许在嵌入中编码查询文档特定相关性的大小，并提高候选文档的排名。 使用类似 CLIP 的方法时文本理解较差 对于像 CLIP 这样的多模态模型，这些模型经过训练只能从图像到文本（反之亦然）。由于文本-文本关系是通过图像间接学习的，文本-文本理解不如纯文本模型。对于许多应用程序来说，需要了解模态间和模内内的情况。 GCL 允许通过直接优化来实现模态间和模内理解的任意组合。 缺乏代表性数据集来开发矢量搜索方法 在开发 GCL 的过程中，很明显，与用于嵌入模型训练和评估现实世界用例的公开数据集存在脱节。现有的基准测试通常仅是文本或仅是跨模式的，并且专注于 1-1 查询结果范式。此外，现有数据集的相关性概念有限，大多数将其编码为二元关系，而一些数据集通常仅在测试集上使用（最多）少量离散分类。这与典型的现实世界用例不同，在典型的现实世界用例中，相关性可以是硬二元关系，也可以来自连续变量。为了帮助解决这个问题，我们编译了一个包含 10M（排名）产品查询对的数据集，涵盖约 100k 查询、近 500 万个产品和四个评估分割（可用 此处)。 ​   由   提交/u/Jesse_marqo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbixix/r_generalized_contrastive_learning_for_multimodal/</guid>
      <pubDate>Tue, 23 Apr 2024 23:07:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能在公司内部的实际应用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbhxwb/d_practical_uses_of_ai_inside_companies/</link>
      <description><![CDATA[人们如何在公司内部（初创公司 -&gt; FAANG）使用人工智能来改进运营和流程？关于利用 LLM 和 GenAI 的讨论很多，但我正在努力寻找成功的真实具体示例。 首先想到的是以下领域，但这个列表当然并不详尽：  p&gt;  设计（和移交） 工程 客户支持 销售 文档 营销  什么有效或有希望？什么不起作用？   由   提交 /u/CJSF   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbhxwb/d_practical_uses_of_ai_inside_companies/</guid>
      <pubDate>Tue, 23 Apr 2024 22:25:43 GMT</pubDate>
    </item>
    <item>
      <title>Meta 做了 OpenAI 应该做的一切 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbhec7/meta_does_everything_openai_should_be_d/</link>
      <description><![CDATA[我很惊讶（或者可能没有）这么说，但 Meta（或 Facebook）比 OpenAI 更民主化 AI/ML，而 OpenAI 最初是成立并主要为此目的提供资金。 OpenAI 很大程度上已经成为一个仅以盈利为目的的商业项目。虽然就 Llama 模型而言，对我来说它们尚未达到 GPT4 功能，但我相信这只是时间问题。你们对此有何看法？   由   提交 /u/ReputationMindless32   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbhec7/meta_does_everything_openai_should_be_d/</guid>
      <pubDate>Tue, 23 Apr 2024 22:03:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语音转文本字级时间戳准确性问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbd8x1/d_speech_to_text_word_level_timestamps_accuracy/</link>
      <description><![CDATA[在转录方面，我使用 Whisper 取得了很大成功，但字级时间戳似乎有点不准确。根据我的理解（“Whisper 无法提供可靠的单词时间戳，因为像 Transformer 这样使用交叉熵训练标准的 END-TO-END 模型并不是为可靠地估计单词时间戳而设计的。” https://www.youtube.com/watch?v=H576iCWt1Co&amp;t=192s）对于我的用例，我需要精确的字级别时间戳，因为我正在特定单词之后插入音频。当我进行插入并且单词的后部位于另一侧时，这会成为问题。 示例：给定一个包含已转录语音的原始音频文件，如果我想插入一个剪辑在“France”一词的末尾，根据时间戳，“France”一词位于“France”一词的末尾。从 19.26 开始，到 19.85 结束，我将在 19.85 插入剪辑。然而，如果 France 的实际结束时间是 19.92，那么当我在 19.85 插入笑声时，我将在这里剩余的“France”，可能是“ce” （0.07），最后。 我很好奇是否有人遇到过类似的问题以及他们做了什么来解决这个问题？我已经尝试了一些开源版本的 Whisper，但仍然遇到了这个问题。   由   提交/u/Mindless-Ordinary485  /u/Mindless-Ordinary485 reddit.com/r/MachineLearning/comments/1cbd8x1/d_speech_to_text_word_level_timestamps_accuracy/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbd8x1/d_speech_to_text_word_level_timestamps_accuracy/</guid>
      <pubDate>Tue, 23 Apr 2024 19:18:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 吴的方法可以将符号人工智能提升到与银牌得主和 AlphaGeometry 竞争，从而超越 IMO Geometry 金牌得主</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbd2ol/r_wus_method_can_boost_symbolic_ai_to_rival/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.06405 代码：https:// /huggingface.co/datasets/bethgelab/simplegeometry 摘要：  证明几何定理构成了视觉推理结合的标志直觉和逻辑能力。因此，奥林匹克级别几何问题的自动定理证明被认为是人类级别自动推理的一个重要里程碑。 AlphaGeometry 的推出标志着一项重大突破，这是一种用 1 亿个合成样本训练的神经符号模型。它解决了 30 个国际数学奥林匹克 (IMO) 问题中的 25 个，而基于 Wu 的方法报告的基线仅解决了 10 个。在这篇文章中，我们重新审视了 AlphaGeometry 引入的 IMO-AG-30 挑战赛，发现 Wu 的方法出奇的强大。仅吴的方法就可以解决15个问题，其中一些问题是其他任何方法都无法解决的。这导致了两个关键发现：（i）将 Wu 的方法与演绎数据库和角度、比率和距离追踪的经典综合方法相结合，仅使用仅使用 CPU 的笔记本电脑在 5 分钟的时间限制内解决了 30 种方法中的 21 种每个问题。从本质上讲，这种经典方法仅比 AlphaGeometry 少解决 4 个问题，并建立了第一个完全符号化的基线，其强度足以与 IMO 银牌得主的表现相媲美。 (ii) Wu 的方法甚至解决了 AlphaGeometry 未能解决的 5 个问题中的 2 个问题。因此，通过将 AlphaGeometry 与 Wu 的方法相结合，我们在 IMO-AG-30 上建立了一种新的最先进的自动定理证明，解决了 30 个问题中的 27 个，这是第一个超越 IMO 金牌得主的人工智能方法.    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbd2ol/r_wus_method_can_boost_symbolic_ai_to_rival/</guid>
      <pubDate>Tue, 23 Apr 2024 19:11:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 无需模型对象即可生成形状贡献的方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbbhbr/d_method_to_generate_shapely_contributions/</link>
      <description><![CDATA[是否有一种方法可以在不使用模型对象的情况下生成数据的 Shapely 值（或类似的值）的近似值。  本质上是我在基准数据上输入特征和模型预测，测试数据也是如此，输出是测试数据上每个特征的贡献   由   提交/u/ozymandias_514   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbbhbr/d_method_to_generate_shapely_contributions/</guid>
      <pubDate>Tue, 23 Apr 2024 18:08:28 GMT</pubDate>
    </item>
    <item>
      <title>[N] Phi-3-mini 在 HuggingFace 上发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb7f9n/n_phi3mini_released_on_huggingface/</link>
      <description><![CDATA[https://huggingface .co/microsoft/Phi-3-mini-128k-instruct 技术报告中的数字看起来确实很棒，我想需要由第三方验证。 &lt; /div&gt;  由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb7f9n/n_phi3mini_released_on_huggingface/</guid>
      <pubDate>Tue, 23 Apr 2024 15:26:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何将 LLaMA 3 部署到生产中以及硬件要求</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb3ge1/d_how_to_and_deploy_llama_3_into_production_and/</link>
      <description><![CDATA[许多人都在尝试安装和部署自己的 LLaMA 3 模型，因此这里是我刚刚制作的教程，展示了如何在 AWS EC2 上部署 LLaMA 3实例：  https://nlpcloud.com/how-to-install-and-deploy-llama-3-into-product.html 部署 LLaMA 3 8B 相当容易，但部署 LLaMA 3 70B 则很困难另一个野兽。考虑到所需的 VRAM 量，您可能需要配置多个 GPU 并使用 vLLM 等专用推理服务器，以便将模型拆分到多个 GPU 上。 LLaMA 3 8B 需要大约 16GB 的磁盘空间，并且FP16 中 20GB VRAM（GPU 内存）。至于LLaMA 3 70B，它需要大约140GB的磁盘空间和160GB的FP16 VRAM。 我希望它有用，如果您有疑问，请随时询问！ 朱利安   由   提交/u/juliensalinas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb3ge1/d_how_to_and_deploy_llama_3_into_production_and/</guid>
      <pubDate>Tue, 23 Apr 2024 12:33:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 除了法学硕士以外，还有其他教育部模式吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb0pjq/d_are_there_any_moe_models_other_than_llms/</link>
      <description><![CDATA[MoE 架构是否也应用于其他 ML 领域，比如说计算机视觉？为什么它们不受欢迎？是因为我们没有像 LLM 那样扩展视觉转换器，而 MoE 的可扩展性最好？   由   提交/u/lime_52  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb0pjq/d_are_there_any_moe_models_other_than_llms/</guid>
      <pubDate>Tue, 23 Apr 2024 09:58:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为 DS/MLE 单独工作的人应该牢记哪些最佳实践和工作流程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb0fi1/d_what_best_practices_and_workflows_those_working/</link>
      <description><![CDATA[我想知道技术招聘人员或经验丰富的 DS/MLE 对像我这样的人有什么看法：良好的理论和良好的技术背景，但单独工作太长了。 我的职业生涯背景摘要：我作为 DS 工作了 8 年，前 3 年在中型研发和咨询团队（一家大型科技公司）工作，然后在过去 5 年内，作为相对成功的非人工智能初创企业的独立 DS，主要开发 ML/NLP 内容来解决特定问题或改进其产品的一项特定功能（即从来不是整个产品）。在我设计的5年里。开发和部署了 4 个模型（但尝试了许多 OFC）——以及一些仪表板和简单的流式化 POC）。  最近参加聚会，看到实际团队中的人们如何工作、讨论和交流知识，这突然让我感到震惊：我错过了，我正在变得过时。我对技术面试感觉不够敏锐，我不确定我开发和维护项目的方式是否遵循良好的标准/最佳实践（哎呀，我几乎不遵循看板，主要使用我的计划员向我的老板报告进度） 。我做了一些版本控制并记录了我放入产品中的内容，但即便如此，我也不确定我正在按照团队的预期进行操作。   由   提交/u/Melodic_Reality_646   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb0fi1/d_what_best_practices_and_workflows_those_working/</guid>
      <pubDate>Tue, 23 Apr 2024 09:40:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 门控长期记忆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1caywsz/d_gated_longterm_memory/</link>
      <description><![CDATA[      今天，我将展示我的最新想法：门控长期记忆 GLTM 单元 门控长期记忆试图实现一种高效的 LSTM 替代方案。与 LSTM 不同，GLTM 并行执行所有繁重的工作，唯一顺序执行的操作是乘法和加法操作。与变形金刚的二次存储器相比，门控长期存储器仅使用线性存储器。   由   提交/u/jessielesbian  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1caywsz/d_gated_longterm_memory/</guid>
      <pubDate>Tue, 23 Apr 2024 07:52:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] Phi-3即将发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/</link>
      <description><![CDATA[从 MSFT 的两个独立消息来源（其中一个接近 Sebastien Bubeck）了解到即将推出的 Phi-3 模型：  三个不同大小的模型（最多 14B） 同样，主要是合成和 LLM 增强的训练数据 显然在训练方面有一些升级技​​术 否更多 Apache 2，但更严格的许可证（类似于 llama3） Mixtral 级别性能，参数少得多  我想看看是否有人有更多有关模型的内部信息.   由   提交/u/yusuf-bengio  /u/yusuf-bengio  reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/</guid>
      <pubDate>Tue, 23 Apr 2024 01:13:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama-3 可能刚刚杀死了专有的人工智能模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</link>
      <description><![CDATA[完整博客文章  Meta 在三天前发布了 Llama-3，感觉开源模型终于缩小了与专有模型的差距，这已经是一个拐点。初始基准测试显示 Llama-3 70B 在许多任务中非常接近 GPT-4：  官方元页面仅显示Llama-3优于Gemini 1.5和Claude Sonnet。 人工分析显示 Llama-3 的质量介于 Gemini-1.5 和 Opus/GPT-4 之间。 关于 LMSYS 聊天机器人竞技场排行榜，Llama-3 排名第 5，而当前的 GPT-4 模型和 Claude Opus 仍并列第 1。  功能更强大Llama-3 400B+ 模型仍在训练中，发布后很可能超越 GPT-4 和 Opus。 Meta vs OpenAI 有人推测 Meta 从一开始的目标就是瞄准OpenAI 采用“焦土”方法，通过发布强大的开放模型来扰乱竞争格局并避免在竞争中落后AI 竞赛。 Meta 在计算和人才方面可能会超过 OpenAI：  OpenAI 的预计收入为 20 亿美元，并且可能无利可图。 2023 年，Meta 的收入为 $134B，利润为 $39B。 Meta 的计算资源目前可能超过 OpenAI。 开源可能会吸引更好的人才和研究人员。  &gt;  一个可能的结果是微软收购 OpenAI 以赶上 Meta。谷歌也在进军开放模型领域，并拥有与 Meta 类似的功能。看看它们适合什么位置将会很有趣。 获胜者：开发人员和人工智能产品初创公司 我最近写了一篇关于现在建立人工智能初创公司令人兴奋，因为您的产品会随着每个主要模型的进步而自动改进。随着 Llama-3 的发布，开发人员的机会更大：  不再受供应商锁定。 开发人员不仅可以封装专有 API 端点，还可以现在以一种非常经济高效且高性能的方式将人工智能深度集成到他们的产品中。 Hugging Face 上已经有超过 800 个 llama-3 模型变体，而且看起来每个人都能够针对他们的使用案例、语言或行业进行微调。 更快、更便宜的硬件：Groq 现在每秒可以生成 800 个 llama-3 代币，而成本只是 GPT 成本的一小部分。以低价提供近乎即时的 LLM 响应即将到来。  视觉和视频的开源多模式模型仍然需要迎头赶上，但我预计这很快就会发生。 Llama-3 的发布标志着人工智能民主化的一个重要里程碑，但现在宣布专有模型的消亡可能还为时过早。谁知道呢，也许 GPT-5 会让我们所有人感到惊讶，并超越我们对 Transformer 模型功能的想象。 这绝对是人工智能领域构建的超级激动人心的时代！    由   提交 /u/madredditscientist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</guid>
      <pubDate>Mon, 22 Apr 2024 15:08:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>