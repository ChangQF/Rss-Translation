<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Thu, 21 Mar 2024 06:17:23 GMT</lastBuildDate>
    <item>
      <title>[D] 2024 年 pgvector 与 pgvecto.rs：PostgreSQL 中向量搜索的全面比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjyy8n/d_pgvector_vs_pgvectors_in_2024_a_comprehensive/</link>
      <description><![CDATA[https://blog.pgvecto.rs/pgvector-vs-pgvectors-in-2024-a-compressive-comparison-for-vector-search-in-postgresql  ​ 你喜欢传统的数据库+矢量搜索扩展，还是专门的矢量数据库？  &amp; #32；由   提交/u/gaocegege  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjyy8n/d_pgvector_vs_pgvectors_in_2024_a_comprehensive/</guid>
      <pubDate>Thu, 21 Mar 2024 05:16:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 高频数据的 TimeGPT</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjwyl9/d_timegpt_for_high_frequency_data/</link>
      <description><![CDATA[是否有人尝试过在每日级别数据以外的其他数据上使用 TimeGPT？我尝试将其用于分钟级数据作为提前 1 小时预测的基础，但它无法推断频率。    由   提交 /u/seoulsrvr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjwyl9/d_timegpt_for_high_frequency_data/</guid>
      <pubDate>Thu, 21 Mar 2024 03:24:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]：记录系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjv5fp/d_rec_system/</link>
      <description><![CDATA[大家好，我正在尝试开发一个推荐系统，我有大约 2.5 亿客户。我有 23 个产品，我想要更复杂的基于神经网络的记录系统。我想要图书馆的建议（ik librecommender） 我的数据是隐式的（没有用户评级），但我有用户行为数据，即数字和日常交易数据。任何建议。   由   提交/u/No-Trip899  /u/No-Trip899 reddit.com/r/MachineLearning/comments/1bjv5fp/d_rec_system/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjv5fp/d_rec_system/</guid>
      <pubDate>Thu, 21 Mar 2024 01:55:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] 发展新的基础模型：释放自动化模型开发的力量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjuddy/r_evolving_new_foundation_models_unleashing_the/</link>
      <description><![CDATA[Sakana AI 发布新论文。 博客文章：https://sakana.ai/evolutionary-model-merge/ 论文：模型合并配方的进化优化 https://arxiv.org/abs/2403.13187    ;由   提交/u/hardmaru  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjuddy/r_evolving_new_foundation_models_unleashing_the/</guid>
      <pubDate>Thu, 21 Mar 2024 01:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您可以通过哪些资源来了解有关分数匹配的更多信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjraju/d_what_are_you_go_to_resources_for_learning_more/</link>
      <description><![CDATA[大家好！我对分数匹配这个话题真的很感兴趣，但围绕它的论文似乎很难理解。我只是想知道是否有人在这个问题上有一些很酷的资源。   由   提交 /u/CapableCheesecake219   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjraju/d_what_are_you_go_to_resources_for_learning_more/</guid>
      <pubDate>Wed, 20 Mar 2024 23:03:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 AlphaFold 2 论文中，有人可以帮我解释一下图 2 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjoopg/d_in_the_alphafold_2_paper_can_someone_explain/</link>
      <description><![CDATA[论文：https: //www.nature.com/articles/s41586-021-03819-2 此处的图 2：https://www.nature.com/articles/s41586-021-03819-2/figures/2 在图2中，他们展示了一系列图表，但我不明白作者想要表达的要点是什么。有一个简短的段落提到了它：  当主干预测准确时，我们观察到高侧链准确性（图 2b），我们表明我们的置信度测量，预测的局部距离差异检验（pLDDT），可靠地预测了 Cα 局部距离差异检验（ lDDT-Cα）相应预测的准确性（图2c） 。我们还发现全局叠加度量模板建模得分（TM-score）27 可以准确估计（图2d）。总的来说，这些分析验证了 AlphaFold 对 CASP14 蛋白的高精度和可靠性也转移到了最近提交的 PDB 未整理的集合中，正如预期的那样  我对图 2 A 的解释是它显示了特定埃的蛋白质链分数的直方图。这很简单。 图 2.b。非常简单。这是一个向右上方移动的图，显示了主链精度和侧链精度之间的相关性。 lDDT-Cα 仅使用 Cα 原子来测量主链精度，而 lDDT（局部差异距离测试）是一种度量结构一致性。 图2.c。这是让我感到困惑的地方。文中提到： lDDT-Cα = 0.997 × pLDDT − 1.17（Pearson&#39;s r = 0.76）。 n = 10,795 条蛋白质链 这应该是图中的蓝线吧？这些点是单独的蛋白质链，即。 n = 19,795 那么，蓝线代表预测，蓝点代表“基本事实”吗？蛋白质链？这就是为什么蓝线不是穿过蓝点云绘制的，而是稍微偏离右侧吗？ 此外，图形标题中线性拟合的阴影区域是否指的是蓝色插图中的点还是其他内容？  线性拟合的阴影区域表示根据 10,000 个 bootstrap 样本估计的 95% 置信区间。  图 2 .d.我对此仍然很困惑。它应该类似于图 2.c。   由   提交/u/christophr88   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjoopg/d_in_the_alphafold_2_paper_can_someone_explain/</guid>
      <pubDate>Wed, 20 Mar 2024 21:17:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您的团队使用哪些方法/工具来针对您的领域微调法学硕士？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjl5sj/d_what_methodstools_do_you_use_in_your_team_to/</link>
      <description><![CDATA[您如何评估自定义 LLM 的数据质量和特定领域的性能，并进行微调以获得最佳输出？    由   提交 /u/metalvendetta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjl5sj/d_what_methodstools_do_you_use_in_your_team_to/</guid>
      <pubDate>Wed, 20 Mar 2024 18:53:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2024 接受去匿名论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjknyi/d_deanonymized_paper_accepted_at_iclr_2024/</link>
      <description><![CDATA[我想开始讨论我在今年 ICLR 上观察到的一个特定案例。 - A 论文提交给ICLR双盲审稿人全名第一作者和完整的致谢（以及一些备受瞩目的参考文献）位于主要论文正文中，位于参考书目的正上方。作者明确确认了虚假陈述“无致谢部分：我证明本次提交的材料中没有供双盲评审的致谢部分。”提交时。 - 四位审稿人和 AC 避免提及这一点，并审阅论文了解作者的偏见，就好像它没有违反征文中列出的基本提交规则。  - 一月中旬发布的论文决定是“桌面拒绝” （推测是由于上述违规行为，确认PC们已经意识到这一点）。此内容未公开存档。 - 2 月初将其更改为“口头”内容。没有进一步的理由，原因不明。 违反匿名规则的行为首先会被评审者忽略，然后程序委员会通过例外情况默默地允许，大概是在直接投诉之后。在我看来，这对于任何会议来说都是不可接受的，尤其是像ICLR这样的领域顶级会议。如果我们不强制执行并允许一些作者选择透露自己的姓名并对审稿人产生偏见，为什么我们还要实行双盲程序呢？如果作者并不出名，或者他们在一个不太享有特权的地方进行研究，或者来自边缘化社区，是否也会有同样的例外？其他在今年 ICLR 上被拒绝但没有获得例外机会的论文又如何呢？ 根据我的经验，学术界关于偏见和诚信的问题经常在私人谈话中提出，但几乎从未公开讨论过，所以我有兴趣听听社区对此案的看法。项目主席拒绝对最终决定发表评论。   由   提交/u/Melodic-Foundation47  /u/Melodic-Foundation47 reddit.com/r/MachineLearning/comments/1bjknyi/d_deanonymized_pa​​per_accepted_at_iclr_2024/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjknyi/d_deanonymized_paper_accepted_at_iclr_2024/</guid>
      <pubDate>Wed, 20 Mar 2024 18:32:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] Nvidia 最新的 Blackwell GPU 将减少多少训练和推理时间/价格？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjhrxy/d_how_much_will_nvidias_newest_blackwell_gpus_cut/</link>
      <description><![CDATA[显然训练 Llama-2 花费了约 500 万美元。您认为这些新 GPU 会降低类似模型的训练/推理成本多少？我很好奇，因为我很可能很快就会购买苹果产品。   由   提交 /u/dittospin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjhrxy/d_how_much_will_nvidias_newest_blackwell_gpus_cut/</guid>
      <pubDate>Wed, 20 Mar 2024 16:34:13 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 不到 300 行的 Python + pytorch 从头开始​​稀疏混合专家语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjg04g/project_sparse_mixture_of_experts_language_model/</link>
      <description><![CDATA[大家好，我实现了专家语言模型的稀疏混合（基本上是 Mixtral、Grok-1 和据称的 GPT-4 中使用的微型版本） ）在纯 pytorch 中从头开始，并用小莎士比亚对其进行训练。这主要基于 Andrej Karpathy 的 makemore（仅自回归字符级解码器变压器模型）。我的目标是让它成为一个可破解的实现，人们可以用它来理解它是如何真正工作和改进的。我预计全年会出现越来越多的此类模型。 存储库位于：https://github。 com/AviSoori1x/makeMoE 我几个月前创建了这个并在 Localllama 上分享，但我想我也应该在这里分享，因为我做了一些更新，例如添加专家能力和整合整个实现少于 300 行可读的 python + pytorch。逐步完成此操作的博客位于：https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch 。希望这对您有所帮助！   由   提交/u/avi1x  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjg04g/project_sparse_mixture_of_experts_language_model/</guid>
      <pubDate>Wed, 20 Mar 2024 15:20:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为 ICML 2024 提交了 0 条评论 - 还有其他人面临这个问题吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjdyax/d_0_reviews_submitted_for_icml_2024_someone_else/</link>
      <description><![CDATA[大家好，我向 ICML 2024 投了一篇论文。作者反驳阶段应该明天开始，但是到今天好像还没有审稿人提交审稿然而。有人面临类似的问题吗？如果没人评论怎么办？   由   提交 /u/Tigmib   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjdyax/d_0_reviews_submitted_for_icml_2024_someone_else/</guid>
      <pubDate>Wed, 20 Mar 2024 13:52:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么学术论文的可读性持续不佳？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bj92ht/d_why_the_readability_of_academic_papers_are/</link>
      <description><![CDATA[  其中一些期望是不可避免的。论文绝对必须假设该领域特有的广泛背景知识和词汇——包括每篇论文对该领域的基本介绍都是多余的。有时论文假设了太多背景，但作为作者或读者很难判断，尤其是因为人们知道的事情会随着时间和不同背景而变化。 参考 在过去的3年里，为了拓宽我对ML领域的理解，我读了很多论文，但没有考虑过专注于某个领域特定领域的特定问题。   这使我能够理解学术写作的结构、机器学习的基本概念以及与以前的知识相比相对宝贵的见解。过去，但当我遇到新论文时，有些论文仍然很冗长，由于学术论文性质的可读性而让我烦恼。 这强烈要求我浏览一些内容，这对纯粹的学术论文是有害的。与非学术书籍相比，专注于阅读文档（我并不认为所有书籍都像个人畅销书一样出色，但我想强调学术写作和非学术写作之间的结构差异。） 问题是，为什么这个约定不能顺利地改变到更好的方向，对现有的和新的研究人员有帮助？   由   提交/u/Mundane_Definition_8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bj92ht/d_why_the_readability_of_academic_papers_are/</guid>
      <pubDate>Wed, 20 Mar 2024 09:04:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最近的“LLM工程师”没有NLP背景的情况常见吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bj0y3h/d_is_it_common_for_recent_llm_engineers_to_not/</link>
      <description><![CDATA[过去几周，我参加了一些聚会和社交活动，在那里我遇到了很多声称他们“与法学硕士合作”的人。我个人对它们没有太多经验，并且对更“经典”的领域进行了研究。 NLP（ELMo 和 BERT 在我做研究时是重大公告），现在主要作为工程师在业界工作。 我经常注意到，当我尝试谈论 LLM 研究模式或应用程序和那些我称之为经典方法的人通常似乎不知道我在说什么。 我不是在谈论研究人员，显然如果你正在与法学硕士进行实际研究，我假设您已经在该领域工作了一段时间。如今，LLM 和 NLP 似乎被分开对待。好奇其他人的想法。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bj0y3h/d_is_it_common_for_recent_llm_engineers_to_not/</guid>
      <pubDate>Wed, 20 Mar 2024 00:59:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我如何在 Google Gemma 6T 代币模型中发现 8 个错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bipsqj/p_how_i_found_8_bugs_in_googles_gemma_6t_token/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bipsqj/p_how_i_found_8_bugs_in_googles_gemma_6t_token/</guid>
      <pubDate>Tue, 19 Mar 2024 17:23:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>