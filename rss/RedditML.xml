<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Wed, 13 Mar 2024 15:13:51 GMT</lastBuildDate>
    <item>
      <title>[P] MetaVoice 文本转语音 (TTS) 基准：RTX 3080 上每 1 美元可处理 23,300 个单词 - 加上 10 位阅读《哈利·波特》名人的语音克隆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdtqm5/p_metavoice_texttospeech_tts_benchmark_23300/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdtqm5/p_metavoice_texttospeech_tts_benchmark_23300/</guid>
      <pubDate>Wed, 13 Mar 2024 15:06:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 修复神经网络中 ReLU 的状态以增强注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdsjrs/d_fixing_the_state_of_relus_in_a_neural_network/</link>
      <description><![CDATA[如果您将 ReLU 视为一个开关，那么对于特定的输入向量，网络会折叠为一个简单的方阵，您可以使用它来查看网络的内容正在关注。 即使你不相信这一点，你仍然可以修复 ReLU 的状态并做同样的事情。 你可以让另一个网络来了解什么正在被关注并增强看似重要的内容并削弱看似不重要的内容。 也许随着时间的推移，您可以获得非常集中的注意力。 &lt;!-- SC_ON - -&gt;  由   提交/u/Sequency_Union  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdsjrs/d_fixing_the_state_of_relus_in_a_neural_network/</guid>
      <pubDate>Wed, 13 Mar 2024 14:16:29 GMT</pubDate>
    </item>
    <item>
      <title>[P] 理解本地 LLM 推理的 50 多个开源选项</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdrqit/p_making_sense_of_50_opensource_options_for_local/</link>
      <description><![CDATA[嗨，reddit！ 我从这个社区学到了很多关于在本地运行开放权重法学硕士的知识，我知道这是多么令人难以承受它可以是在开源 LLM 推理工具的领域中导航。这就是为什么我创建了 awesome-local-llms GitHub 存储库，以将所有可用选项编译到一个简化的版本中 在此存储库中，我抓取了公开可用的 GitHub 指标，例如星星、贡献者、问题、发布以及自上次提交以来的时间。这使得社区能够做出明智的选择，并及时了解哪些项目受欢迎且得到积极维护。我们都知道，随着时间的推移，一些较小的项目可能会变得无法维护，尤其是 UI 工具，因此让这些信息易于访问至关重要。 我选择不将存储库分为 LLM 推理引擎、LLM 等类别UI 或一体化桌面应用程序。这是因为项目范围经常重叠，并且不断添加新功能，使得手动标记很快就过时了。但是，如果您对改进组织或添加其他功能有建议，请告诉我！ 由 Jan 团队维护的一个出色的现有存储库，对一些 LLM 推理工具进行了分类：https://github.com/janhq/awesome-local-ai。 我也在考虑添加为了完整起见，列出了专有的闭源 LLM 工具（例如 LM Studio 和 Faraday）。此外，我正在考虑添加 UI 的屏幕截图/GIF 画廊，以提供对每个工具界面的视觉洞察。您认为这会对社区做出有用的贡献吗？ 非常感谢您对如何改进此存储库的想法和建议！如果您发现该存储库很有用并且希望了解其最新进展，请考虑在 GitHub 上给它一颗星。  也欢迎贡献！   由   提交 /u/lethal_can_of_tuna   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdrqit/p_making_sense_of_50_opensource_options_for_local/</guid>
      <pubDate>Wed, 13 Mar 2024 13:41:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 未来机器学习理论研究的数学课程建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdpldb/d_math_course_advice_for_future_machine_learning/</link>
      <description><![CDATA[大家好，我下学期将是一名大二学生，未来打算申请研究生院，重点研究机器学习理论。我想知道我应该学习什么样的数学课程才能实现这个目标。目前，我正在学习高年级数学课程，例如实分析、高级线性代数和优化。希望您能给我一些建议，告诉我下学期选什么课程，是拓扑学，还是更多的分析课程，或者有什么其他建议。   由   提交/u/Impressive-Site-7462   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdpldb/d_math_course_advice_for_future_machine_learning/</guid>
      <pubDate>Wed, 13 Mar 2024 11:53:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在文本上微调 LLaVA 会降低多模式性能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdpezl/d_could_finetuning_llava_on_text_reduce/</link>
      <description><![CDATA[大家好！我计划在 MATH 数据集上对 LLaVA 进行几个时期的微调，以及 Camel AI 的一些数据集（https://huggingface.co/camel-艾）。这是否会降低模型在多模态推理任务上的性能？如果会，降低多少？   由   提交 /u/New-Skin-5064   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdpezl/d_could_finetuning_llava_on_text_reduce/</guid>
      <pubDate>Wed, 13 Mar 2024 11:43:39 GMT</pubDate>
    </item>
    <item>
      <title>[R]镜子：一种多视角的自我反思方法，用于知识丰富的推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdojab/r_mirror_a_multipleperspective_selfreflection/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.14963 代码：https:// /github.com/hanqi-qi/Mirror 摘要：  虽然大型语言模型（LLM）有能力为了反复反思自己的产出，最近的研究观察了他们在无法获得外部资源的情况下与知识丰富的问题​​的斗争。除了法学硕士自我评估效率低下之外，我们还观察到法学硕士尽管收到了明确的负面反馈，但仍难以重新审视自己的预测。因此，我们提出了Mirror，一种用于知识丰富推理的多视角自我反思方法，以避免陷入特定的反思迭代。镜子使法学硕士能够从多角度线索进行反思，这是通过导航者和推理者之间的启发式交互来实现的。它通过鼓励（1）导航器生成的方向的多样性和（2）推理器生成的响应中策略性诱导的扰动之间的一致性，引导智能体走向多样化但似乎可靠的推理轨迹，而无需访问地面事实。在五个推理数据集上的实验证明了 Mirror 相对于当代几种自我反思方法的优越性。此外，消融研究清楚地表明我们的策略缓解了上述挑战。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdojab/r_mirror_a_multipleperspective_selfreflection/</guid>
      <pubDate>Wed, 13 Mar 2024 10:52:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 内存学习：大型语言模型的声明性学习框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdoby9/r_inmemory_learning_a_declarative_learning/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.02757 摘要：  探索智能体是否可以在不依赖环境的情况下与环境保持一致人类标记的数据提出了一个有趣的研究主题。从智能生物体中观察到的对齐过程中汲取灵感，其中陈述性记忆在总结过去的经验中发挥着关键作用，我们提出了一种新颖的学习框架。代理熟练地从过去的经验中提取见解，完善和更新现有笔记，以提高他们在环境中的表现。整个过程发生在记忆组件内，并通过自然语言实现，因此我们将这个框架描述为内存学习。我们还深入研究了旨在评估自我改进过程的基准的主要特征。通过系统的实验，我们证明了我们的框架的有效性，并提供了对该问题的见解。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdoby9/r_inmemory_learning_a_declarative_learning/</guid>
      <pubDate>Wed, 13 Mar 2024 10:39:16 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于本科生工作的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdo8j3/d_questions_on_bachelors_work/</link>
      <description><![CDATA[Redditors 大家好 我正在为我的神经网络学士论文寻找好的资源。有谁有我可以使用的好的资源吗？   由   提交/u/KingLu271  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdo8j3/d_questions_on_bachelors_work/</guid>
      <pubDate>Wed, 13 Mar 2024 10:32:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在面板数据上运行逻辑回归等分类模型有哪些问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdlrzk/d_what_are_the_issues_with_running_classification/</link>
      <description><![CDATA[我有一个数据集，用于捕获每个季度的员工数据。有些功能每个季度都会发生变化，但有些功能不喜欢员工的性别。 我正在尝试运行一个二元分类，目标变量如果有磨损则为 1，如果无磨损则为 0。每个员工每季度有 1 条记录，直到他们辞职的季度为止。如果我们考虑 4 年的数据集，则在第 4 年最后一个季度离职的员工将有 16 行，其中只有一行 - 对应于第 4 年最后一个季度的最新行的目标变量为 1，所有其他 15 行都有目标变量为 0。  这样的数据集是否可以用于分类，其中当时间（即年季度）也作为特征添加时，每一行都被认为是独立的？这种想法有什么缺陷？如果我对此数据集运行逻辑回归会出现什么问题？   由   提交 /u/SriRamaJayam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdlrzk/d_what_are_the_issues_with_running_classification/</guid>
      <pubDate>Wed, 13 Mar 2024 07:45:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG生产中的痛点和问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdkhk3/d_rag_painpoints_and_problems_in_production/</link>
      <description><![CDATA[已经有很多文章阐述了 RAG 的痛点 https://arxiv.org/pdf/2401.05856.pdf 根据我自己的经验，实施 RAG 管道的一些困难领域是：  开发一种针对您独特的信息需求的强大且定制设计的分块方法，这是一项复杂而艰巨的挑战。 实施强大且定制的检索方法也是一项艰巨的任务。 管理并优化有效 RAG 的提示可能会变得更加困难。 处理底层矢量数据的定期更新和维护。  有时它让我思考 RAG 更好还是用重写代理方法会增加价值。您的想法和痛点是什么，请分享您的经验   由   提交 /u/Winter_Draw9039   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdkhk3/d_rag_painpoints_and_problems_in_production/</guid>
      <pubDate>Wed, 13 Mar 2024 06:17:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在基准测试中比较两个模型的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdjb4m/d_what_is_the_best_way_to_do_a_comparison_between/</link>
      <description><![CDATA[这个问题是在比较两个机器学习模型的性能的背景下提出的。但它适用于许多场景。 在验证集/测试集/基准数据集上测量机器学习模型的性能是一个嘈杂的过程。根据一般使用的种子，我们得到不同的度量值。在比较两个机器学习模型时，这会出现一个问题，因为我们不仅仅有两个数字可供比较。 我过去所做的是使用许多种子运行模型并对指标值进行平均，然后使用它平均值来决定哪个模型更好。 但是，这没有考虑指标值的方差。所以最近我开始做的是这样的，“如果平均值的差异小于标准差的总和，那么模型是相似的，否则你可以根据平均值的差异做出上面的决定”。 对我来说，这似乎是一个粗暴的黑客攻击。我确信必须有既定的方法来对两个模型的实验结果进行比较。在我看来，这个问题似乎并非如此。 所以我的问题是，在机器学习的背景下比较两个模型的结果的推荐方法是什么？  &gt; PS：为了稍微形式化这个问题，我们可以将一个模型的度量视为随机变量 M1，将另一个模型的度量视为随机变量 M2。现在，如何在仅给出 RV 样本的情况下比较两个 RV？比较两个 RV 意味着什么？   由   提交 /u/Due-Function4447    reddit.com/r/MachineLearning/comments/1bdjb4m/d_what_is_the_best_way_to_do_a_comparison_ Between/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdjb4m/d_what_is_the_best_way_to_do_a_comparison_between/</guid>
      <pubDate>Wed, 13 Mar 2024 05:04:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 所有最先进的法学硕士在许多领域都在业余水平上犯了事实错误。这比专家级别更难训练吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdi4nr/d_all_state_of_the_art_llms_make_factual_mistakes/</link>
      <description><![CDATA[我最近读到了GPQA，专家 -生物学、物理和化学中非常困难的问题的水平基准。显然克劳德3非常擅长这些问题。  然而，当我向 Claude 3 和 GPT-4 询问有关我有“专门业余”领域的领域时，Claude 3 和 GPT-4 始终给出错误的信息。这些是我希望对该主题感兴趣的人在没有该领域知识的情况下会问的问题类型。通常，错误会在谈话的早期出现，如果我深入研究任何细节，错误就会增加。  例如摄影和相机设计。我问“为什么老照片中的人们不微笑？”并给出了几个可能的因素。进一步询问其中之一，即摄像机的物理限制，开始引入幻觉的细节，而询问这些幻觉的细节会给出更多看似事实的东西，而忽略了实际的事实，并引入了更多的不一致之处。语言也是如此——如果你对外语的语法或发音系统了解很多，你会发现要求对这些事情的解释往往会给你带来错误的信息。这些例子来自上周，包括 Claude 3 Opus 和 GPT-4。  如果您有自己感兴趣的领域，SOTA 法学硕士能否掌握所有详细信息？  为什么不更加强调提高此类会话知识的准确性？训练和测试是否简单得多？   由   提交/u/Axon350  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdi4nr/d_all_state_of_the_art_llms_make_factual_mistakes/</guid>
      <pubDate>Wed, 13 Mar 2024 04:01:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 窃取生产语言模型的一部分</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdf11z/r_stealing_part_of_a_production_language_model/</link>
      <description><![CDATA[我们引入了第一个模型窃取攻击，该攻击从 OpenAI 的 ChatGPT 或 Google 的 PaLM-2 等黑盒生产语言模型中提取精确的、重要的信息。具体来说，在给定典型的 API 访问的情况下，我们的攻击恢复了变压器模型的嵌入投影层（直到对称性）。我们的攻击花费不到 20 美元，提取了 OpenAI 的 ada 和 Babbage 语言模型的整个投影矩阵。由此，我们首次确认这些黑盒模型的隐藏维度分别为 1024 和 2048。我们还恢复了 gpt-3.5-turbo 模型的精确隐藏维度大小，并估计恢复整个投影矩阵的查询成本低于 2,000 美元。我们以潜在的防御和缓解措施作为结论，并讨论了可能扩展我们的攻击的未来工作的影响。 论文：https://arxiv.org/pdf/2403.06634.pdf   由   提交 /u/AdamEgrate   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdf11z/r_stealing_part_of_a_production_language_model/</guid>
      <pubDate>Wed, 13 Mar 2024 01:36:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习面试倦怠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bd5hh4/d_ml_interview_burnout/</link>
      <description><![CDATA[我觉得我因数据科学面试而精疲力尽。我在该领域担任数据科学家已有 5 年了。这个领域有很多技术性的东西。尤其是在2023年，关于如何优化LLM模型和向量DB的使用的新论文层出不穷。我花在面试准备上的时间越多，我用来获取新知识的时间就越少。我应该怎么做才能克服这种情况？非常感谢。 为什么我觉得面试准备没有什么用 在实际工作中，我们可以针对一个话题进行不同的准备来回忆所有的内容。在向其他同事展示想法之前，先记忆并正确组织概念。然而，是否可以在采访过程中立即调取所有信息呢？有些知识可以追溯到学校课本上，几十年来一直没有人接触过。有些问题涉及不太常见的设计模式。当我无法回答一个问题时，我会感到难过，不是因为我不知道，而是因为我确实无法在短时间内总结出来。这就像数据被存档到AWS S3冰川一样，因此数据检索既耗时又昂贵。另外，不能回答一些代码设计模式并不意味着我不能写出好的代码并解决问题。为了准备这些面试，我尝试重新审视一些关键概念和各种不太有用的代码模式，但这非常耗时。老实说，这些工作的工资确实很高。我不是在谈论任何大型科技公司，而是在谈论一些中小企业。我对标准感到困惑。   由   提交 /u/MillionLiar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bd5hh4/d_ml_interview_burnout/</guid>
      <pubDate>Tue, 12 Mar 2024 19:03:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>