<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 12 Nov 2024 01:13:34 GMT</lastBuildDate>
    <item>
      <title>[D] 在本地训练语音模型的最佳方法是什么？（最好制作一个可在应用程序上使用的 TTS 模型）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp88fs/d_whats_the_best_way_to_train_a_voice_model/</link>
      <description><![CDATA[我有一个朋友得了癌症，最近的一次手术使他们失去了声音。我想尝试用手术前的一些视频来训练一个人工智能语音模型。理想情况下，我希望有一个安卓应用或网络应用，我可以在里面使用他们的语音模型，这样他们就可以使用 TTS 再次用他们的声音说话。如果可能的话，我正在寻找一种他们可以通过手机上的应用使用它的方法    提交人    /u/TheTabernacleMan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp88fs/d_whats_the_best_way_to_train_a_voice_model/</guid>
      <pubDate>Tue, 12 Nov 2024 00:44:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 LLM 修剪不像量化那样普遍可用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp6h2d/d_why_is_llm_pruning_not_as_generally_available/</link>
      <description><![CDATA[我一直在深入研究大型语言模型 (LLM)，并一直在探索各种优化技术。令我感到困惑的一件事是量化与修剪的可用性和采用率之间的差异。 量化似乎是一种成熟且广泛使用的技术，可以减少 LLM 的内存占用和计算成本。它相对容易实现，并且在研究和行业中都得到了广泛的采用。 另一方面，修剪（涉及从模型中删除不太重要的权重）不太常见。尽管它具有潜在的好处，例如进一步减小模型大小和推理时间，但它似乎并不普遍可用或被广泛采用。我在互联网上进行的许多搜索都只得到研究论文或概念验证 GitHub 存储库。 我很好奇这种差异背后的原因。修剪是否存在技术挑战，导致其不太实用？实施或集成到现有工作流程中是否更加困难？还是有其他因素在起作用？    提交人    /u/Soumil30   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp6h2d/d_why_is_llm_pruning_not_as_generally_available/</guid>
      <pubDate>Mon, 11 Nov 2024 23:23:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 抖音滤镜中使用的实时 GAN 模型可能的架构/数据集是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp3vz0/d_what_is_the_likely_architecturedataset_for/</link>
      <description><![CDATA[我很好奇抖音滤镜为何在去除头发 (https://effecthouse.tiktok.com/learn/guides/technical-guides/objects/generative-effects/hair-eraser) 和眉毛 (https://effecthouse.tiktok.com/learn/guides/technical-guides/objects/generative-effects/eyebrow-eraser) 方面表现如此出色。 我尝试过使用轻量级滤镜做类似的事情（实时从人们的脸上去除物品）我使用 OpenCV 方法创建的配对数据集上的 Pix2Pix 样式模型，但是随着生成器的大小减小，生成的图像的质量下降太多。 有人知道他们如何在如此轻量级的模型上实现如此一致的结果吗？谢谢    提交人    /u/DjPoliceman   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp3vz0/d_what_is_the_likely_architecturedataset_for/</guid>
      <pubDate>Mon, 11 Nov 2024 21:34:21 GMT</pubDate>
    </item>
    <item>
      <title>当目标具有非常高的基数时提示进行分类[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp2mqh/prompting_for_classification_when_target_has_very/</link>
      <description><![CDATA[我正在研究一种植物疾病分类问题，根据症状，人们必须将一种植物归类为几种疾病类别之一。我的问题是关于当目标具有非常高的基数时，提示分类的工程策略。当只有四五个潜在的目标标签时，我可以在提示中列出它们并要求 LLM 进行分类。当类别数量超过 50 时会发生什么？在这种情况下，有没有办法有效地提示 LLM？    提交人    /u/Ok-Emu5850   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp2mqh/prompting_for_classification_when_target_has_very/</guid>
      <pubDate>Mon, 11 Nov 2024 20:43:11 GMT</pubDate>
    </item>
    <item>
      <title>[P]带注释的数据集，用于解释 AI 与真实图像检测的原因</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp05os/pannotated_dataset_for_explaining_the_reason_in/</link>
      <description><![CDATA[我目前正在研究一个问题陈述，其中我需要对真实图像和人工智能生成的图像进行分类，然后对分类进行解释。第一部分非常简单，对于第二部分，我找到了一些研究论文，但没有一篇提供用于微调模型的注释数据集的链接。有人可以帮我找到具有良好注释的数据集吗？ SynArtifact：通过视觉语言模型对合成图像中的伪影进行分类和缓解（他们在第 4 页提到了一个数据集，但没有提供任何链接）    提交人    /u/Background-Trainer37   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp05os/pannotated_dataset_for_explaining_the_reason_in/</guid>
      <pubDate>Mon, 11 Nov 2024 19:03:52 GMT</pubDate>
    </item>
    <item>
      <title>过度拟合查询[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gow3uh/overfitting_query_p/</link>
      <description><![CDATA[大家好，我正在构建一个 NN 模型，根据多个问题的答案来检测疾病。在对 600 名患者的初步测试中，该模型表现非常出色，AUC 为 0.995，测试准确率为 0.975，但我担心该模型过度拟合，我使用了交叉验证和性能差距分析以及 L1/L2 正则化、Dropout 和早期停止。以下是交叉验证和性能差距分析的结果。交叉验证结果：平均 Auc=0.9787 SD0.0090 平均准确率 =0.9350 SD0.0262 性能差距分析训练集 Auc = 0.9983 准确率 =0.9859 测试集 Auc=0.9936 准确率 0.9803 告诉我你们对这些结果的看法，如果您认为它是过度拟合/我还可以做哪些其他测试来判断？我正在尝试确定更多数据，但可能需要与某人合作才能完成此操作。我不想合作伙伴获取数据后发现这完全是浪费！谢谢    提交人    /u/Disastrous_Ad9821   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gow3uh/overfitting_query_p/</guid>
      <pubDate>Mon, 11 Nov 2024 16:22:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025 论文评论讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gov5zd/d_iclr_2025_paper_reviews_discussion/</link>
      <description><![CDATA[ICLR 2025 评审明天将在 OpenReview 上线！我想开一个帖子，讨论评审过程中的任何反馈、问题或庆祝活动。 随着 ICLR 的发展，评审噪音不可避免，好的作品可能并不总是能得到应有的分数。让我们记住，分数并不能定义研究的真正影响。分享您的经验、想法，让我们在整个过程中互相支持！    提交人    /u/Technical_Proof6082   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gov5zd/d_iclr_2025_paper_reviews_discussion/</guid>
      <pubDate>Mon, 11 Nov 2024 15:43:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助我进行内部部署 ml 批量预测？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1goqchp/d_help_me_with_onpremise_ml_batch_prediction/</link>
      <description><![CDATA[我需要部署一个 .pkl 模型，在这样的设置下进行批量预测：代码被推送到 GitLab，SQL/pyspark 用于数据，cron 作业处理调度。不允许使用 Docker、Kubernetes 和云。这是本地设置。这种部署的一些最佳实践或方法是什么？    提交人    /u/Simple_Toe_6989   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1goqchp/d_help_me_with_onpremise_ml_batch_prediction/</guid>
      <pubDate>Mon, 11 Nov 2024 11:46:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么域随机化能保证神经网络控制器的稳定性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gopir9/d_why_does_domain_randomization_ensure_stability/</link>
      <description><![CDATA[大家好， 我正在探索域随机化如何有助于 NN 控制器的稳定性，尤其是当训练包括更广泛地查看历史数据时。 具体来说，我很好奇是否有理论基础或正式分析来解释域随机化如何帮助神经网络在不同条件或噪声水平下保持稳定性，尤其是在结合更多历史信息时。是否有论文通过 Lyapunov 稳定性或其他严格方法来分析这种影响，表明接触各种过去数据可以产生更稳定的基于 NN 的控制系统？ 任何关于该领域基础或最新研究的建议都将不胜感激。提前致谢！ （我已经在控制理论 reddit 上写了同样的东西）    提交人    /u/nerdkim   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gopir9/d_why_does_domain_randomization_ensure_stability/</guid>
      <pubDate>Mon, 11 Nov 2024 10:51:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于不同 LLM 红队方法和技术的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gonf47/r_resource_on_varying_llm_red_teaming_methods_and/</link>
      <description><![CDATA[https://github.com/user1342/Awesome-LLM-Red-Teaming    由   提交  /u/OppositeMonday   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gonf47/r_resource_on_varying_llm_red_teaming_methods_and/</guid>
      <pubDate>Mon, 11 Nov 2024 08:14:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用图像模型可视化 LLM 注意层对一组 token 的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gojg09/d_how_to_visualize_the_effect_of_an_llm_attention/</link>
      <description><![CDATA[通过将 token 嵌入输入到图像模型中，是否可以可视化 LLM 在通过注意层处理 token 之前和之后如何“想象”token？我知道您无法复制粘贴它，但是有没有办法捕获由注意层引起的潜在变换并将此变换应用于图像模型的嵌入空间？ 例如，如果我在 LLM 中输入“穷人”，那么“男人”的嵌入将转向“乞丐”，而输入“皇室男人”时，它可能会更接近“国王”。我想可视化这种变化。然后，你可以将人的嵌入转移到图像模型中，它会在这个例子中创建类似乞丐或国王的东西。 如果你捕获每个注意层之后的转换并通过插值每个步骤制作视频，它可以制作出非常酷的可视化效果。    提交人    /u/jbrinkw   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gojg09/d_how_to_visualize_the_effect_of_an_llm_attention/</guid>
      <pubDate>Mon, 11 Nov 2024 04:01:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 结合归纳和传导进行抽象推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1goh5ym/r_combining_induction_and_transduction_for/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1goh5ym/r_combining_induction_and_transduction_for/</guid>
      <pubDate>Mon, 11 Nov 2024 01:58:54 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ML 和 DL 模型中存在伪造新型方法的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1go50wf/discussion_papers_with_fake_novel_approach_in_ml/</link>
      <description><![CDATA[为什么很多新论文（通常由博士完成）都采用现有方法，而当您询问他们的贡献时，他们说我们用另一层替换了这一层，或者我们添加了超参数!!!!! 这不是贡献！我很困惑这些怎么会被接受    提交人    /u/Rihab_Mira   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1go50wf/discussion_papers_with_fake_novel_approach_in_ml/</guid>
      <pubDate>Sun, 10 Nov 2024 16:53:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>