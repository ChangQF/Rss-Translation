<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 23 Oct 2024 21:15:50 GMT</lastBuildDate>
    <item>
      <title>[D] Agentic chrome 扩展：有趣的数学问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gakbdm/d_agentic_chrome_extension_funny_math_problem/</link>
      <description><![CDATA[大家好！ 希望你们喜欢数学（我想你们喜欢！）因为我有一个有趣的问题要谈。 我正在编写一个小型 chrome 扩展，允许 LLM 运行它想要的任何 javascript 来满足用户请求。当然，我需要将页面的 HTML 代码作为上下文提供给它。考虑到现在 DOM 的重量，我正在尝试找到一种方法来减轻它们。我已经完成了摘取唾手可得的果实，现在，可优化的 DOM 重量的大部分在于类名。 因此，这是我的限制（我还没有考虑太多）： - 压缩后的类名必须是原始类名的子集 - 压缩后类名的“选择性”必须与之前相同。即原始 DOM 中的 getElementsByClassName(compressed_class_name) 必须输出与 getElementsByClassName(uncompressed_class_name) 相同数量的元素。 关于如何做到这一点有什么想法吗？我觉得这个问题很有趣，我猜一定涉及一些不错的数学概念。    提交人    /u/Due-Pangolin325   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gakbdm/d_agentic_chrome_extension_funny_math_problem/</guid>
      <pubDate>Wed, 23 Oct 2024 20:21:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过快速工程 GPT-4o 生成独特的 AI 语音表演</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gag5jj/p_generating_distinct_ai_voice_performances_by/</link>
      <description><![CDATA[我使用了 GPT-4o 的新 AI 语音生成 API，不仅可以以特定的风格提示声音，还可以从奥巴马这样的特定人物那里生成声音。 tl;dr：可能并不意味着声音很好，但值得注意的是它是可能的。 撰写：https://minimaxir.com/2024/10/speech-prompt-engineering/ 笔记本：https://github.com/minimaxir/gpt-4o-audio-tests/blob/main/gpt-4o-audio-tests.ipynb    由   提交  /u/minimaxir   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gag5jj/p_generating_distinct_ai_voice_performances_by/</guid>
      <pubDate>Wed, 23 Oct 2024 17:23:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] Ichigo：混合模式早期融合实时语音助手</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gae6tb/r_ichigo_mixedmodal_earlyfusion_realtime_voice/</link>
      <description><![CDATA[  由    /u/emreckartal  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gae6tb/r_ichigo_mixedmodal_earlyfusion_realtime_voice/</guid>
      <pubDate>Wed, 23 Oct 2024 16:03:30 GMT</pubDate>
    </item>
    <item>
      <title>动态云资源分配中策略梯度的批次大小和更新频率优化 [R] [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gabsed/optimizing_batch_size_and_update_frequency_for/</link>
      <description><![CDATA[大家好！ 我正在做一个关于云资源分配的项目，我真的需要你的建议。我的目标是尽量减少服务器的总体能耗，我正在处理连续随机的作业到达。 下面是一个快速概述： 我处理每个作业块有 10 个作业，每个作业都有多个依赖任务。对于每个块，我运行 10 次迭代和 12 个情节来收集轨迹，然后使用离策略模式更新我的模型。 经过这 12 个情节 的 一次迭代 之后，我的重播缓冲区最终获得了大约 499,824 个经验！现在，我需要你的帮助：  您认为从重播缓冲区采样的最佳批次大小是多少？ 我应该多久更新一次模型参数？  由于作业不断到达以及任务和资源可用性的变化，我的状态和操作空间非常大且动态。 （我正在使用策略梯度架构。） 您能分享的任何见解或经验都将非常有帮助！ 非常感谢！   由    /u/TeamTop4542  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gabsed/optimizing_batch_size_and_update_frequency_for/</guid>
      <pubDate>Wed, 23 Oct 2024 14:23:04 GMT</pubDate>
    </item>
    <item>
      <title>研究新手 - 需要出版物信息 [R][D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gaa3o8/new_to_research_need_info_on_publications_rd/</link>
      <description><![CDATA[过去两年，我一直在 AI 领域撰写和发表一些论文/期刊，但我真的不确定最好的期刊和会议是什么。就我而言，我通常会写一篇论文，然后我的教授根据论文的内容将其提交给该会议/期刊。 所以想从这个子版块了解一些信息。 -&gt; 有哪些真正好的期刊/会议可以发表论文？（期刊/会议的排名如何，有办法查看吗？我听说 ICML、NeurIPS 是该领域的顶级会议） -&gt; 最好的出版商有哪些？ -&gt;什么是科学 Q1、Q2 期刊和 A* 期刊？ 我现在正在写一篇论文，是关于医学领域的（在语音领域），有人可以建议我，这个领域最好的期刊/会议是什么吗？ 抱歉，如果这些是一些基本问题，（我只知道出版商：IEEEXplore、Springer、Elseveir，并且过去认为如果它被 Scopus 索引，它就是一个很好的会议/期刊）。    提交人    /u/Extension_Air1017   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gaa3o8/new_to_research_need_info_on_publications_rd/</guid>
      <pubDate>Wed, 23 Oct 2024 13:06:37 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 世界上第一个自主 AI 发现的 0day 漏洞</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ga8wxn/project_worlds_first_autonomous_aidiscovered_0day/</link>
      <description><![CDATA[我确信很多人都通过将代码片段粘贴到 ChatGPT 中发现了 0-day 漏洞。问题一直是扫描整个项目的 0-day。一些论文表明，通过向其代理提供已知的易受攻击的代码是可能的，但据我所知，这些论文都没有获得任何 CVE 或发现真正的 0-day。Vulnhuntr 本周末发布，在 10k+ GitHub 星的开源项目中发现了十多个 0-day： https://github.com/protectai/vulnhuntr    提交人    /u/FlyingTriangle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ga8wxn/project_worlds_first_autonomous_aidiscovered_0day/</guid>
      <pubDate>Wed, 23 Oct 2024 12:07:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 良性过度拟合和双重下降。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ga7k9c/r_benign_overfitting_and_double_descent/</link>
      <description><![CDATA[简而言之，它们是一样的吗？ 下面详细阐述我的问题。 我试图理解双重下降现象和良性过度拟合之间的区别。 当模型复杂度在某个点之后增加时，测试误差会上升，然后在高度过度参数化的状态下再次降低，这时模型中就会发生双重下降。 我还没有找到良性过度拟合的确切定义，但是它也涉及过度参数化状态下的泛化。 从表面上看，它们似乎相同，但我并不完全确定。有人可以解释一下它们之间的异同吗？    提交人    /u/Scientifichuman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ga7k9c/r_benign_overfitting_and_double_descent/</guid>
      <pubDate>Wed, 23 Oct 2024 10:50:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] Swin Transformer 注意力图可视化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ga62sn/d_r_swin_transformer_attention_map_visualization/</link>
      <description><![CDATA[      用一些测试图像测试了我的模型，在特定区域获得了更高的像素值（对于下图，它是（0,0）），该区域在注意力头之间相似（可以位于不同的位置，但对于每个注意力头来说都是相同的位置头）。Swin 中是否存在一些归纳偏差？有人能解释为什么会这样吗？为了进行可视化，在激活维度 [1, 32, 64, 64] 上，我对结果为 [1,32,64] 的第三个维度值取平均值，并将最后一个维度重塑为 [8,8]。因此，它生成 [1, 32, 8, 8]，其中 1 是批次/数量图像，32 是头部数量（如下图所示），8,8 是特征形状。 https://preview.redd.it/rvik8lej2hwd1.png?width=728&amp;format=png&amp;auto=webp&amp;s=527a8a7c27f84cabd97980b6a230e30ebbd9a736    由   提交  /u/Quiet-King-9172   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ga62sn/d_r_swin_transformer_attention_map_visualization/</guid>
      <pubDate>Wed, 23 Oct 2024 09:07:14 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 我是否遗漏了某些重要的东西，或者我能为这个实体匹配问题提供的最佳解决方案是否非常近似？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ga5g5n/project_am_i_missing_something_major_or_is_a_very/</link>
      <description><![CDATA[我的任务是从描述各种产品的非结构化文档中提取七条特定信息（例如数量、说明、材料类型、尺寸、价格等）。我成功地做到了这一点，但下一步被证明更具挑战性。我的工作是将每件产品与 1000 种产品参考列表中最接近的对应项目进行匹配（按材料、格式、页数、印刷类型、纸张类型、数量和成本划分）。 在极少数情况下，可以在参考列表中找到相近的匹配项，但在大多数情况下，这根本不可行。许多产品描述包含大量详细信息，其中一些信息在参考列表中缺失。此外，细节之间的关系通常很复杂，如果没有专业知识很难解释。另一方面，其他描述缺少关键细节，例如材料的类型或尺寸，因此无法找到一个好的匹配。 简而言之，即使是人类专家也可能很难将这些产品准确地与参考列表匹配。到目前为止，我考虑过的最佳方法是首先根据数量进行过滤以缩小选择范围。之后，我可以首先使用专注于材料类型的嵌入，因为它是最重要的（因为匹配由不同材料制成的产品的尺寸和特征是没有意义的）。一旦我根据材料确定了潜在的匹配，我就可以将嵌入应用于其他特征。仅基于尺寸或其他数字细节进行预过滤是行不通的，因为数据中存在太多不一致性，无法依赖这些方面。 在我看来，提供 10 个最接近的匹配或类似的东西是我能做的最好的事情。看起来像是经典的垃圾进，垃圾出问题。我错了吗？    提交人    /u/No_Possibility_7588   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ga5g5n/project_am_i_missing_something_major_or_is_a_very/</guid>
      <pubDate>Wed, 23 Oct 2024 08:19:03 GMT</pubDate>
    </item>
    <item>
      <title>构建模型推荐系统：告诉我们你正在构建什么，我们将为其推荐最佳的 AI 模型！[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ga3h0j/building_a_model_recommendation_system_tell_us/</link>
      <description><![CDATA[嘿 Reddit！ 我们正在研究一些东西，我们认为它可以让每个人更轻松地发现模型：模型推荐系统，您只需用简单的英语输入您正在处理的内容，它就会为您的项目推荐最佳的 AI 模型。 🎉 💡 工作原理： 主要思想是您可以用自然语言 逐字描述您的项目，例如：  “我需要一个模型来生成医学研究论文的摘要。” “我正在构建一个用于客户支持的聊天机器人。” “我想要一个可以分析产品评论情绪的模型。”  并且基于该输入，系统将推荐最适合该工作的模型！ 无需深入研究技术规格，无需复杂的过滤器 - 仅根据您的需要提供可靠的建议。 🌟 我们还正在构建什么： 除了模型建议之外，我们还添加了一些功能，使平台超级用户友好：  详细的模型见解：您仍然可以获得所有技术信息，例如性能指标、架构和受欢迎程度，以比较模型。 高级搜索和过滤器：如果您更喜欢亲自动手，则可以按任务、框架或标签过滤模型。 个性化建议：随着时间的推移，系统将变得更加智能，并根据您过去的使用情况提供更多相关建议。  我们为什么需要您的反馈： 我们希望这个平台能够真正为 AI/ML 领域的人们解决问题，而这正是您可以发挥作用的地方！ 🙌  这样的工具对你有帮助吗？ 你认为像 Hugging Face 这样的模型平台缺少哪些功能？ 你是否希望看到某些特定功能，例如性能比较或自定义选项？ 我们如何才能让自然语言输入在推荐模型方面更有用？  TL;DR: 我们正在构建一个工具，你只需用简单的英语描述你的项目，它就会为你推荐最好的 AI 模型。无需复杂的搜索 - 只需输入你需要的内容！期待你的反馈，了解你想要看到的内容，或者你认为像 Hugging Face 这样的当前平台缺少的任何功能。 我们很乐意听到你的想法和创意！什么会让这个平台对你超级有用？让我们知道您认为可以改进模型发现过程的方法，或者现有平台缺少什么！ 提前感谢，Reddit！😊    提交人    /u/O2MINS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ga3h0j/building_a_model_recommendation_system_tell_us/</guid>
      <pubDate>Wed, 23 Oct 2024 05:57:50 GMT</pubDate>
    </item>
    <item>
      <title>Meta AI（FAIR）最新论文将系统 1 和系统 2 思维融入推理模型。[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9v7ag/meta_ai_fair_latest_paper_integrates_system1_and/</link>
      <description><![CDATA[Meta AI (FAIR) 最新论文将系统 1 和系统 2 思维整合到推理模型中。 基本上，它引入了术语“Dualformer”，将系统 1（快速思维）和系统 2（慢速思维）整合到 Transformer 中以提高其推理能力。高级想法是使用“随机跟踪”训练模型，随机丢弃部分推理标记。这种方法提高了模型的推理速度、准确性和多样性。它还使模型能够以可控的方式执行系统 ​​1 和系统 2 思维。  论文链接在此： https://arxiv.org/html/2410.09918v1    提交人    /u/Proof-Raise-9151   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9v7ag/meta_ai_fair_latest_paper_integrates_system1_and/</guid>
      <pubDate>Tue, 22 Oct 2024 22:38:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们构建了一个多云 GPU 容器运行时</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9mrcj/d_we_built_a_multicloud_gpu_container_runtime/</link>
      <description><![CDATA[想要分享我们的开源容器运行时 - 它专为跨云运行 GPU 工作负载而设计。 https://github.com/beam-cloud/beta9 与主要用于在一个云中运行一个集群的 Kubernetes 不同，Beta9 旨在在许多不同的云中的许多集群上运行工作负载。想要在家中的 AWS、GCP 和 4090 设备之间运行 GPU 工作负载吗？只需在每个 VM 上运行一个简单的 shell 脚本以将其连接到集中控制平面，您就可以在这三个环境之间运行工作负载。 它还处理分布式存储，因此文件、模型权重和容器映像都缓存在靠近用户的 VM 上，以最大限度地减少延迟。 我们已经构建 ML 基础设施一段时间了，但最近决定将其作为一个开源项目启动。如果您有任何想法或反馈，我将非常感激听到您的想法🙏    提交人    /u/velobro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9mrcj/d_we_built_a_multicloud_gpu_container_runtime/</guid>
      <pubDate>Tue, 22 Oct 2024 16:45:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] LLM 研究框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9k0te/d_r_llms_frameworks_for_research/</link>
      <description><![CDATA[我是人工智能和自然语言处理专业的博士生，目前正在用法学硕士 (LLM) 启动一个新的研究项目。 这一次，我不会主要使用 HuggingFace 和 Pytorch 从头开始​​编写所有代码，而是想使用一种流行的框架（如 LangChain、LlamaIndex 等）。 这背后的动机是，理想情况下，我想学习使用这些工具来获得更紧凑、更有条理的代码库，以便我可以轻松添加部分内容以包括 RAG、Agentic 工作流等。 我还对一种有效的方法来加载模型和进行推理感兴趣。 根据您的经验，众多可用的框架中哪一个最适合研究目的？而且，您是否使用框架，还是每次开始新项目时都从头开始编写所有代码？    提交人    /u/Debonargon   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9k0te/d_r_llms_frameworks_for_research/</guid>
      <pubDate>Tue, 22 Oct 2024 14:51:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</guid>
      <pubDate>Sun, 20 Oct 2024 15:00:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>