<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 01 Jun 2024 06:18:32 GMT</lastBuildDate>
    <item>
      <title>[P] LLM 的创新应用 | 有没有想过 LLM/GenAI 可以以这种方式使用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5eugs/p_innovative_applications_of_llms_ever_thought/</link>
      <description><![CDATA[  由    /u/dippatel21  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5eugs/p_innovative_applications_of_llms_ever_thought/</guid>
      <pubDate>Sat, 01 Jun 2024 04:29:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自动 LoRA 发现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</guid>
      <pubDate>Sat, 01 Jun 2024 04:09:17 GMT</pubDate>
    </item>
    <item>
      <title>调整剧本中的探索与利用——需要帮助理解流程 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5cxyq/exploration_vs_exploitation_in_tuning_playbook/</link>
      <description><![CDATA[[已编辑] 我正在阅读“Tuning Playbook”，在理解超参数调整背景下的探索与利用概念时遇到了一些困难。 有没有人可以用更具体而不是抽象的方式解释这个概念，或者提供一个在超参数调整中如何进行探索的例子？什么是探索以及如何进行探索。还有一件事；它一直在说理解问题，哪个问题？问题模型试图解决？还是什么超参数影响性能和相互影响的问题？还是什么？  这是书中关于这个主题的部分：  探索与开发  谢谢！    提交人    /u/Same_Half3758   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5cxyq/exploration_vs_exploitation_in_tuning_playbook/</guid>
      <pubDate>Sat, 01 Jun 2024 02:40:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 其他领域的研究，例如最近对一立方毫米人类脑组织的映射，能否帮助机器学习领域？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d56zg0/d_can_other_areas_researches_such_as_the_recent/</link>
      <description><![CDATA[https://www.scientificamerican.com/article/a-cubic-millimeter-of-a-human-brain-has-been-mapped-in-spectacular-detail/ 围绕人类大脑的研究，例如这张最新的人类大脑图谱，能否为机器学习领域提供一些见解，以构建更有效的人工智能/算法模型？ 外行人在这里。    提交人    /u/Enzo-chan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d56zg0/d_can_other_areas_researches_such_as_the_recent/</guid>
      <pubDate>Fri, 31 May 2024 21:40:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进行模型推理的更便宜的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d56h9c/d_cheaper_way_to_do_model_inference/</link>
      <description><![CDATA[有人知道在服务器停机期间节省 GPU 计算的解决方案吗？我目前正在进行模型推理，大多数时候我只是为计算付费，而不提供任何用户请求。    提交人    /u/Fun_Win_6054   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d56h9c/d_cheaper_way_to_do_model_inference/</guid>
      <pubDate>Fri, 31 May 2024 21:17:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要帮助在 vscode jupyter notebook 上使用专用 GPU。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d55cej/d_need_help_to_use_dedicated_gpu_on_vscode/</link>
      <description><![CDATA[嘿，我目前正在 colab 和 vscode jupyter 扩展中工作。由于我有一张 Nvidia 卡，我想用它来训练各种模型（深度、简单），使用 vscode 中的 jupyter 笔记本。如何设置此要求？为简单起见，我想为 vscode jupyter 笔记本使用专用 GPU。    提交人    /u/Saheenus   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d55cej/d_need_help_to_use_dedicated_gpu_on_vscode/</guid>
      <pubDate>Fri, 31 May 2024 20:28:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] Bigram 标记器比现状更好吗？尤其是对于多语言</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4z5dr/d_bigram_tokenizers_better_than_status_quo/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4z5dr/d_bigram_tokenizers_better_than_status_quo/</guid>
      <pubDate>Fri, 31 May 2024 16:03:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 序列打包对于训练 Transformer 来说常见吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4tux3/d_is_sequence_packing_common_for_training/</link>
      <description><![CDATA[大家好， 我想从头开始训练一个小型 Transformer 语言模型，并试图尽可能提高训练效率。我一直在思考如何构建训练批次，这让我看到了这篇论文高效序列打包，避免交叉污染：加速大型语言模型，不影响性能，这似乎是一件非常合理的事情，一般情况下都应该这样做。 简而言之，这个想法是将多个序列打包在一个样本序列中，并调整注意力矩阵，使样本不会相互交叉污染，即只关注自身内的标记。 Huggingface 论坛中的这篇文章很好地说明了这一点。但我在 Huggingface 变压器中找不到这样的东西。我遗漏了什么吗？其他框架是否实现了这一点？我们是否知道大公司是否在进行序列打包？我是否遗漏了这方面的主要缺点？我认为它可能会对位置编码造成问题。    提交人    /u/CloudyCloud256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4tux3/d_is_sequence_packing_common_for_training/</guid>
      <pubDate>Fri, 31 May 2024 11:58:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用大型语言模型评估 RAG</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4tbzg/p_evaluate_rag_using_large_language_models/</link>
      <description><![CDATA[我一直在研究 RAG 和 LLM，我一直想评估 LLM。有一些库可以与基于 GPT 的模型一起使用，但对于 RAG，我主要想评估基于 Llama 或 Mistral 的模型。 所以我建立了 BeyondLLM。 BeyondLLM 可帮助您仅用 5-7 行代码构建高级检索增强生成 (RAG) 和大型语言模型 (LLM) 应用程序。BeyondLLM 是开源的，它还支持 Fine Tune Embeddings 和 Observaility。 GitHub：https://github.com/aiplanethub/beyondllm/    提交人    /u/trj_flash75   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4tbzg/p_evaluate_rag_using_large_language_models/</guid>
      <pubDate>Fri, 31 May 2024 11:27:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习会议和组织指标</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4shqn/d_ml_conferences_and_organization_metrics/</link>
      <description><![CDATA[我觉得很多人会认为 NeurIPS、ICLR、ICML 等是机器学习领域的重要会议。即使在机器学习之外，NeurIPS 和 ICLR 的 H 指数在所有会议中排名第 9 和第 10。但是，现在我正在查看全球的终身教职职位，情况似乎有所不同。这些出版物似乎对移民或学术终身教职毫无价值，因为它们不是传统期刊。您会注意到它们没有出现在 SCImago 中，SCImago 是许多组织用来衡量出版物质量的指标，因此会决定终身教职或移民。 我很好奇学术机器学习研究人员在这种情况下会做什么。您是否会停止向 NeurIPS 提交论文，而打算在 ACM “机器学习的基础和趋势”上发表论文，而该期刊 在 SCImago 上排名第二？还是在不断增长的机器学习 IEEE 期刊名单上？    提交人    /u/smorad   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4shqn/d_ml_conferences_and_organization_metrics/</guid>
      <pubDate>Fri, 31 May 2024 10:34:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] KAN ==多层GAM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4pjxp/d_kan_multilayer_gam/</link>
      <description><![CDATA[我刚刚阅读了 KAN 论文， 我的理解是，它提供了如何堆叠多层 GAM（广义加性模型）的解决方案：Phi 函数只是 GAM 的形状函数，而样条函数是 GAMS 中经过充分研究的形状函数。 所以对我来说：  MLP 是一个多层线性回归 KAN 是一个多层 GAM  尽管如此，GAM 具有 KAN 论文中未表达的链接功能，但在我看来，这才是这篇论文的真正重点。如果我们向 KAN 层添加激活函数，那么我们就完全拥有了多层 GAM。 这也意味着我们可以将 MLP 视为 KAN 的特例，因为线性回归是 GAM 的特例。 这听起来正确吗？    提交人    /u/mainro12   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4pjxp/d_kan_multilayer_gam/</guid>
      <pubDate>Fri, 31 May 2024 07:02:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 LipNet 进行唇读：端到端的句子级唇读</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4mpkw/r_lipreading_with_lipnet_endtoend_sentencelevel/</link>
      <description><![CDATA[      大家好， 我最近根据论文《端到端句子级唇读》从头开始实现了 LipNet。它通过从输入帧中的唇部运动中提取特征来预测句子。它最初是一个 3DConv-GRU 模型，我已经用 3DConv-LSTM（双向）和一些其他具有不同复杂度的模型实现了它，并且利用了 He（Kaiming Normal）初始化权重。 我请求您查看存储库并提供任何反馈，如果您发现它有用，请考虑分叉。 GitHub/LipNet 图片来自官方论文   由    /u/Kian5658  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4mpkw/r_lipreading_with_lipnet_endtoend_sentencelevel/</guid>
      <pubDate>Fri, 31 May 2024 04:00:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] CV/结构光/3D 重建研究合作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4dokf/r_research_collaboration_in_cv_structured_light/</link>
      <description><![CDATA[我正在寻找对结构光、使用投影技术的 3D 重建或与条纹投影或相位分析相关的任何内容的研究和出版感兴趣的合作者。我的重点包括：  用于 3D 扫描的结构光 创新投影方法 使用最新技术克服相位分析或相位展开中的挑战 在医学成像、工业检测等领域的应用。  如果您在这些领域工作或有见解可以分享，我很乐意讨论潜在的合作机会。如果我的帖子到处都是，我很抱歉。快速聊天以交换想法或提供建议将不胜感激。    提交人    /u/Falafel2307   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4dokf/r_research_collaboration_in_cv_structured_light/</guid>
      <pubDate>Thu, 30 May 2024 20:30:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我进行了 580 次模型数据集实验，结果表明，即使你非常努力，仅通过查看数据漂移结果也几乎不可能知道模型是否正在退化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d47ca4/r_i_ran_580_modeldataset_experiments_to_show_that/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d47ca4/r_i_ran_580_modeldataset_experiments_to_show_that/</guid>
      <pubDate>Thu, 30 May 2024 15:54:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>