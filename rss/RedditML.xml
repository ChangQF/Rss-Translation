<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 13 Oct 2024 18:20:24 GMT</lastBuildDate>
    <item>
      <title>[P] 寻找单词到单词的文本检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2uemm/p_looking_for_a_word_to_word_text_detection/</link>
      <description><![CDATA[您好，首先，如果我的英语水平不够，我深表歉意。我目前正在寻找一个易于训练或整合到 Python 中的单词到单词文本检测模型。我查看了很多不同的存储库，并尝试实现它们，但多次失败。我不得不承认，我不是最聪明的人，而且知道的也有限。 作为一名计算机科学专业的学生，​​我绝不是这个领域的专家，我感到很惭愧，但是我已经尝试了几种端到端模型，例如 pytesseract、easyocr、paddleocr，或计算机视觉技术，例如带有 NMS 的 MSER，以便能够抓取纸张的边界框。唯一的问题是这些并不完美，甚至最好的也是 pytesseract。它捕获的准确率约为 80% 到 85%，而其余部分则相交或根本没有被捕获。  我计划构建一个用于识别手写文本的 OCR 系统。我已经训练了一个表现良好的识别模型，并且只在获取文本的正确边界框时遇到问题。最后，我想知道 YOLO 模型是否值得现在开始研究以获取边界框并获取文本的分类。我需要在 1 周内得到它。    提交人    /u/brudda65   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2uemm/p_looking_for_a_word_to_word_text_detection/</guid>
      <pubDate>Sun, 13 Oct 2024 17:05:54 GMT</pubDate>
    </item>
    <item>
      <title>带标题的幻想/中世纪主题图像数据集“[P]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2u4nx/dataset_for_fantasymedieval_theme_images_with/</link>
      <description><![CDATA[大家好， 我是一名研究生，想做文本到图像的生成，但具体到幻想/中世纪主题。尝试在互联网上寻找带有标题的此类图像的数据集，但似乎找不到。有人知道这样的数据集或对如何策划这样的数据集有想法吗？ 谢谢！    提交人    /u/rm_9248   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2u4nx/dataset_for_fantasymedieval_theme_images_with/</guid>
      <pubDate>Sun, 13 Oct 2024 16:53:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] LongCite：使 LLM 能够在长上下文 QA 中生成细粒度引用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2qohf/r_longcite_enabling_llms_to_generate_finegrained/</link>
      <description><![CDATA[      我刚刚阅读了一篇有趣的论文，旨在解决（或改进）信息检索问题细粒度引用，“LongCite：使 LLM 能够在长上下文 QA 中生成细粒度引用”(https://arxiv.org/abs/2409.02897)。 在本文中，研究人员使用现成的 LLM 生成由具有精确句子级引用的长上下文 QA 实例组成的数据集，然后使用该数据集微调开放权重 LLM 以生成带有引用的答案。与 GPT4o、Llama 3.1 等相比，生成的 LongCite 8B 和 9B 模型出奇地好。 这是如何工作的？以下是生成指令微调数据集的 4 步过程： (a) 从长文本或文档开始，他们的方法使用现有的 LLM 使用 Self-Instruct 生成问答数据集（查询及其相关答案）（Wang 等人 2023；在我之前的一篇文章中讨论过）。 (b) 接下来，他们使用答案从输入文本中检索几个 128 个标记的块以进行粗粒度引用。 (c) 然后，LLM 在这些块中寻找相关句子，以提供更细粒度的句子级引用 (d) 研究人员过滤掉答案中不到 20% 的陈述没有引用的问答对 然后使用生成的数据集以传统（SFT）方式训练 LLM。 https://preview.redd.it/gucywp0o8jud1.jpg?width=6000&amp;format=pjpg&amp;auto=webp&amp;s=4ed2ff078327082133d390c566250a2ef41c1a05    提交人    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2qohf/r_longcite_enabling_llms_to_generate_finegrained/</guid>
      <pubDate>Sun, 13 Oct 2024 14:19:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻求识别不同语言中语义等价句子或实体的研究方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2mvpc/r_seeking_research_approaches_for_identifying/</link>
      <description><![CDATA[如何从研究和学术角度识别两种不同语言中具有相同语义含义的等效句子或实体？我正在寻找用于在多语言环境中查找语义等效对（无论它们是句子还是其他实体）的方法和方法。您能否建议我应该使用的相关研究领域、方法或特定关键字来搜索涉及跨语言语义相似性、句子对齐或跨语言实体等价性的学术论文？任何有关此上下文中常用的工具、模型或算法的指导也将不胜感激。    提交人    /u/eyup_kh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2mvpc/r_seeking_research_approaches_for_identifying/</guid>
      <pubDate>Sun, 13 Oct 2024 10:41:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 获得博士学位的现实性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2mugf/d_realism_of_landing_a_phd_offer/</link>
      <description><![CDATA[大家好！我是伦敦大学学院的研究生，正在攻读机器学习硕士学位，我很快将申请 2025 年秋季开始的博士课程。我将分享我的个人资料和我将申请的学校，并希望了解我所瞄准的实验室是否超出了我的能力范围。 我以一等（荣誉）成绩获得了新加坡南洋理工大学的数学和计算机科学本科学位，预计也将以一等（荣誉）成绩获得研究生学位。我对理论深度学习感兴趣——围绕损失曲面曲率、优化轨迹、学习动态和泛化的问题——这些都是数学密集型的研究领域。虽然我的课程大部分都是理论性的，并且与此类研究非常一致（按设计），但我的研究经历更具实验性。我在 ICML 上发表了一篇第三作者出版物，内容是我为学士论文项目所做的工作。这是一项相当理论化的工作，但我只负责实验。我还有 2 篇第一作者预印本——一篇关于 NLP 的实验性工作（旨在在 IEEE 上发表），另一篇关于图形 ML（旨在在顶级会议之一上发表），其中有相当多的理论部分，但没有我希望在博士学位上完成的工作那么多。 我的目标是进入 ETH、UCL、斯坦福、NYU、EPFL、哥伦比亚和普林斯顿的实验室（按优先顺序，其中一个是我的职位）。所有这些实验室都有非常成功的 PI（按引用次数计算），他们研究的主题与我的兴趣非常一致。我担心我看似无所不包的研究背景可能会让他们失望，但我希望我的成绩能让他们相信我精通理论。我希望我的导师能写出优秀的推荐信，因为他们在很多场合都对我表示赞赏。我希望写一份令人信服的研究陈述，但由于我几周前才开始阅读相关文献，所以最终可能不是那么完美。 我不介意与年轻的 PI 合作，只要我身边有一些研究人员在研究相关主题。在高级实验室，已经建立了一个网络，我可能先协助一些项目，然后再进行独立研究。现实地说，我是不是在自吹自擂？如果是这样，有人可以推荐一些年轻的 PI 从事上述研究课题，我可能更有机会加入他们的实验室吗？    提交人    /u/mio_11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2mugf/d_realism_of_landing_a_phd_offer/</guid>
      <pubDate>Sun, 13 Oct 2024 10:38:56 GMT</pubDate>
    </item>
    <item>
      <title>提出新颖的想法[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2jhhx/coming_up_with_novel_ideas_d/</link>
      <description><![CDATA[关于如何想出新颖的问题解决方案，您有什么想法吗？每次我以为自己有了一些想法，我的导师就会说“这太简单了”。许多方法以独特的方式将现有的构建块粘合在一起，但我很难想象人们如何想出既真正新颖又真正有效的东西。 有时，我读到一篇论文，我意识到这个想法实际上非常简单/直接，作者只是介绍了一个很酷的技巧。其他时候，我读到的东西介绍了一个非常晦涩的定理，或者他们注意到一些我只能梦想的东西。我倾向于前者，但由于新颖性有限，我对迄今为止所写的任何东西都不太自豪。疯狂的出版速度让我偏向“简单而有效”，这无济于事方法中的大部分工作是在获得 SOTA 后事后编写故事。    提交人    /u/like_a_tensor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2jhhx/coming_up_with_novel_ideas_d/</guid>
      <pubDate>Sun, 13 Oct 2024 06:25:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 信仰与命运：Transformers 作为模糊模式匹配器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2irug/d_faith_and_fate_transformers_as_fuzzy_pattern/</link>
      <description><![CDATA[       由    /u/jsonathan  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2irug/d_faith_and_fate_transformers_as_fuzzy_pattern/</guid>
      <pubDate>Sun, 13 Oct 2024 05:33:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] Arxiv 无法正常工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2hw07/d_arxiv_not_working/</link>
      <description><![CDATA[今天我发现有些论文无法加载，即使我尝试使用不同的浏览器和设备。尽管有时元数据和 html 论文可用，但 pdf 文件仍然无法正常工作。仅适用于某些论文。 从我的书签来看，大约 80% 的论文都无法正常工作。以下是我从书签中识别出的一些列表。 https://arxiv.org/pdf/1811.08489 https://arxiv.org/abs/2203.11933 https://arxiv.org/pdf/2306.11698.pdf https://arxiv.org/pdf/2310.03744.pdf https://arxiv.org/pdf/2302.00070.pdf https://arxiv.org/pdf/2410.07593 https://arxiv.org/pdf/2203.11933.pdf    提交人    /u/Shot-Button-9010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2hw07/d_arxiv_not_working/</guid>
      <pubDate>Sun, 13 Oct 2024 04:33:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 13 Oct 2024 02:15:21 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 增加Yolov8图像分割模型的数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2esrc/project_increasing_data_in_yolov8_image/</link>
      <description><![CDATA[大家好， 我正在训练一个 YOLOv8 图像分割模型。我想增加数据集。有没有办法在训练期间增加数据集。 例如，我过去训练过一个 CNN 模型，并且在训练期间为每个图像生成了 100 个增强图像以增加数据集。该 CNN 模型的数据增强参数如下所示。 datagen = ImageDataGenerator( rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, sher_range=0.1, zoom_range=0.1, Horizo​​ntal_flip=True, Vertical_flip = True, fill_mode=&#39;nearest&#39; )  有没有办法用上面相同的参数对 YOLO 图像分割模型（每个图像生成 100 个图像）做同样的事情。我知道我必须在 .yaml 文件中为增强参数输入自定义值，但是，如果有人能为我提供信息，说明我需要在 .yaml 文件中更改哪些自定义参数才能实现上述配置，那就太好了。此外，如果有办法在训练期间为每个图像生成 100 张图像，标签中 .txt 文件中的多边形坐标是否会根据应用的增强参数自动调整。 如果您需要更多说明，请告诉我。 谢谢    提交人    /u/sahil_m00   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2esrc/project_increasing_data_in_yolov8_image/</guid>
      <pubDate>Sun, 13 Oct 2024 01:27:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找可以在浏览器中完全本地运行的轻量级嵌入模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2ep9v/d_looking_for_lighweight_embeddings_model_that/</link>
      <description><![CDATA[我广泛使用了 OpenAI 嵌入端点和 Google 的 Universal Sentence Encoder (USE)。我正在为那些不希望将数据发送到*任何地方*的人开展一个项目。因此，我正在尝试看看我是否可以想出一个完全本地的实现，我可以在其中为他们存储文本，然后完全在本地对该数据进行余弦相似度搜索。我希望找到一个轻量级的嵌入模型，它可以严格在典型 PC 上的浏览​​器中运行，并且在激活时不会下载任何模型，因为所有这些都打破了隐私约束。 有人见过类似的东西吗？如果有，请留下链接。我的网络搜索和 ChatGPTPlus 讨论尚未取得成果。    提交人    /u/vengeful_bunny   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2ep9v/d_looking_for_lighweight_embeddings_model_that/</guid>
      <pubDate>Sun, 13 Oct 2024 01:21:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解流匹配</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2dpm8/d_understanding_flow_matching/</link>
      <description><![CDATA[我有点难以理解流匹配论文。是否有一些课程可以让我更好地理解这一点。 就上下文而言，我相当了解 ddpm，并在一定程度上了解 ddim。但是，我无法理解它的 ODE 方面。 流匹配论文讨论了很多关于矢量场和 ODE 的内容。如果您能推荐一篇论文/课程来理解这方面的内容，我将不胜感激。YouTube 上有一些关于统计力学的课程。这是否相关，或者考虑到我可以理解变分贝叶斯，是否有更好的起点？ TIA    提交人    /u/themathstudent   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2dpm8/d_understanding_flow_matching/</guid>
      <pubDate>Sun, 13 Oct 2024 00:25:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML 项目的反馈：使用 Transformers 改进蚁群优化算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g21loo/d_feedback_on_ml_project_using_transformers_to/</link>
      <description><![CDATA[我目前正在从事一个个人项目，尝试构建一个改进版本的蚁群优化算法。 在运行算法之前，我使用位置编码变压器神经网络来预测最佳信息素矩阵。 改进的蚁群优化算法使用位置编码变压器神经网络输出的信息素矩阵进行初始化，该网络使用来自普通蚁群优化算法的信息素矩阵数据进行训练。 为了分析算法的改进，我让改进的 ACO 与普通 ACO 一起运行不同地图大小的多次迭代，计算每个算法的最佳运行，并计算 p 值以验证改进的算法是否具有统计意义。 到目前为止，增强型 ACO 显示出令人满意的结果，当节点大小为 30 和 35 时，p 值分别为 0.06 和 0.05。  但是，我的目标是在更大范围的节点大小中实现显著性 (p &lt; 0.05)。 我将不胜感激任何反馈！ 项目链接：https://github.com/ronantakizawa/improvedaco/blob/main/ronan_acotransformer_experiment.ipynb    提交人    /u/SafeSignificance8840   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g21loo/d_feedback_on_ml_project_using_transformers_to/</guid>
      <pubDate>Sat, 12 Oct 2024 14:42:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] GSM-Symbolic：理解大型语言模型中数学推理的局限性（Apple）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1wbir/r_gsmsymbolic_understanding_the_limitations_of/</link>
      <description><![CDATA[arXiv:2410.05229 [cs.LG]: https://arxiv.org/abs/2410.05229 Iman Mirzadeh、Keivan Alizadeh、Hooman Shahrokhi、Oncel Tuzel、Samy Bengio、Mehrdad Farajtabar - Apple TechCrunch - Devin Coldewey：研究人员质疑人工智能的“推理”能力，因为模型在解决数学问题时会遇到一些细微的变化：https://techcrunch.com/2024/10/11/researchers-question-ais-reasoning-ability-as-models-stumble-on-math-problems-with-trivial-changes/ 共同作者之一 Mehrdad Farajtabar 在 X 上的这个帖子中分解了这篇论文：https://x.com/MFarajtabar/status/1844456880971858028    由   提交  /u/Nunki08   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1wbir/r_gsmsymbolic_understanding_the_limitations_of/</guid>
      <pubDate>Sat, 12 Oct 2024 09:20:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>