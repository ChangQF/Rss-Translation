<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sat, 15 Feb 2025 21:15:05 GMT</lastBuildDate>
    <item>
      <title>文档提取[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqbeyc/document_extraction_r/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是一名新机器学习工程师，我试图解决几个月的问题，我需要从发票中提取键值对作为要求，我试图使用不同的策略来解决它，并且它们似乎都没有正常工作，我需要设计一个通用解决方案，该解决方案将在任何发票上都可以使用，而无需依赖发票布局。 Moto ---＆GT;提取关键价值对，例如提供者详细信息：[提供商姓名&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;＆quort&#39;&#39;&#39;&#39;&#39;，收件人详细信息＆quot＆quot＆quot＆quot＆quort“与提供者相同），” po详细信息“：[date＆quot&#39;总量“总量”，“描述”  当我使用tesseract或pdfplumber提取单词时，我面临的问题在某些人中左右读取单词。发票格式化提供商和收件人合并使分离复合物的地址和详细信息， 我到目前为止所做的事情--------＆gt;使用tesseract或pdfplumber提取，使用regex识别GST日期锅，但对于地址部分I am still lagging  I also read a blog &lt;a href=&quot;https://medium.com/analytics-vidhya/invoice-information-extraction-using-ocr-and-deep-learning-b79464f54d69 “&gt; https://medium.com/Analytics-vidhya/invoice-information-information-ectraction-raction-usion-ocr-and-deep-learning-b79464f54d69 他使用不同的方法解决了相同的方法，但我找不到我发现那些RCNN和蒙面的RNN模型 有人可以解释这个博客并帮助我解决这个问题吗？ 我是一个新鲜的，所以任何帮助对我都非常有帮助 &lt; p&gt;提前谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/floodrose_2003     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqbeyc/document_extraction_r/</guid>
      <pubDate>Sat, 15 Feb 2025 21:07:01 GMT</pubDate>
    </item>
    <item>
      <title>[D]我的公司是否因避免深度学习而错过了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq9gtk/d_is_my_company_missing_out_by_avoiding_deep/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  免责声明：如果线性回归足够，则使用神经网络是没有意义的。  我在一家严格遵守数学，可解释的模型的公司工作。他们的立场是，诸如神经网络甚至梯度提升机之类的方法也是“黑框”。因此对决策不可靠。尽管我了解可解释性的重要性（尤其是在任务关键场景中），但我忍不住感觉这种方法过于限制。  我看到了这些方法的大量研究和行业采用，这让我感到奇怪：它们真的只是黑匣子，还是这是过时的观点？当然，随着这么多的人在这一领域工作，必须有一些方法可以洞悉这些模型并使他们更值得信赖。  我也错过了它们，因为我没有此类模型的工作经验？ 编辑：上下文是一级方程式！但是，种族是另一件事并支持工具。除非完全必要，否则我也会避免使用与种族严格相关的任何模型。我只是觉得这里有一种与上下文无关的偏见。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/datandre     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq9gtk/d_is_my_company_missing_out_by_avoiding_deep/</guid>
      <pubDate>Sat, 15 Feb 2025 19:42:42 GMT</pubDate>
    </item>
    <item>
      <title>具有Quadro RTX5000的笔记本电脑非常适合机器学习和稳定扩散？允许的标签：“ [讨论]”，“ [D]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq6pz8/laptop_with_quadro_rtx5000_is_good_for_machine/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  带有Quadro rtx5000的笔记本电脑非常适合机器学习和稳定的扩散？ 我的旧笔记本电脑已经使用了很多年，想要要购买新的 我找到了这笔交易  acer概念d7  二手在我当地附近的900-1,000美元左右 （我担心热量和维护。由于板上的端口在里面倒转） 如果它不稳定，我根本无法工作。而且我只有一次预算。 我认为这很有趣，因为它仍然处于良好状态，最多可达16 GB或 我应该去购买全新的笔记本电脑带有RTX4060   /u/u/aphand-pass557     link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iq6pz8/laptop_with_with_quadro_rtx5000_is_is_good_good_for_for_for_machine/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq6pz8/laptop_with_quadro_rtx5000_is_good_for_machine/</guid>
      <pubDate>Sat, 15 Feb 2025 17:42:33 GMT</pubDate>
    </item>
    <item>
      <title>[D]混合和歧管混合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq64f0/d_mixup_and_manifold_mixup/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好。您在混合和歧管混合过程中的经历如何。我拥有由于内部和主体间可变性而导致的脑电图数据，域和VAL设置之间的域移动。我的目的是使我的模型的决策界限平滑。但是结果是训练不稳定。我使用a = 0.4，所以我只有光插值。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nigale-joke5751     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq64f0/d_mixup_and_manifold_mixup/</guid>
      <pubDate>Sat, 15 Feb 2025 17:16:03 GMT</pubDate>
    </item>
    <item>
      <title>[d]使用火炬XLA在小数据集上使用Torch XLA重新训练GPT-2时疯狂的CPU利用率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq5e3k/d_insane_cpu_utilization_when_using_torch_xla_to/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  我试图在威廉的作品上训练gpt-2莎士比亚（7ish MB），并使用Kaggle TPU V3-8 VM来做到这一点。这是我的训练代码： ````` &gt;  dropout = 0.1   vocab_size = tokenizer.n_vocab   ctx_size = 1024   batch_size = 8   steps = 10000 &lt; /p&gt;  ...   def train（索引，代币，层，emb_size，n_heads，droctout，vocab_size，ctx_size，steps）：  device = xla.dla.device （）  model =变压器（层，emb_size，n_heads，dropout，vocab_size，ctx_size）。 ，lr = 1e-4） 用于tqdm（range（step））中的i：  model.train（）  with xla.step（） ：  x，y = get_batch（数据，batch_size）  x = x.to（device）  y = y.to（device）  xm.master_print（f＆quot&#39;x shape：{x [5]};）  xm.master_print（f＆quort&#39;y Shape：{y [y [5]}＆quort）  out，loss =模型（x，y）  lose.backward（）  xm.optimizer_step（optimizer）  optimizer.zero_grad （）  xm.master_print（loss.item（）） 如果我％10 == 0：  x = tokenizer.encode（＆quot; hello; hello ，＆quot;）  x = torch.tensor（x）.to（device）  xm.master_print（tokenizer.decode（list。 ））））  checkpoint = { &#39;模型&#39;：raw_model.state_dict（）， &#39;imptimizer&#39;：optimizer.state_dict（）， }   torch.save（checkpoint，f＆quot; ckpt- {i} .pt; pst;） ```````将火车代码放入python文件中，然后将其导入笔记本，以使用xla.launch运行。由于某种原因，当我运行代码时，X和Y形状并未打印，并且我的CPU利用率会产生疯狂的价值。我该如何解决？ https ：//preview.redd.it/e38l444jb0cje1.png？width = 219＆amp;格式32;提交由＆＃32; /u/u/u/new-skin-5064     [link]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq5e3k/d_insane_cpu_utilization_when_using_torch_xla_to/</guid>
      <pubDate>Sat, 15 Feb 2025 16:43:58 GMT</pubDate>
    </item>
    <item>
      <title>[d]有没有LLM论文预测中间而不是下一个令牌？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq4f0r/d_have_any_llm_papers_predicted_a_token_in_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在从事一个项目（与NLP无关），在该项目中，我们使用与GPT-3相同的架构和培训，但我们更多比下一个“ word”找到一系列令牌来连接起始和结束“单词”。由于我们在设置中从LLM中绘制了很多东西，因此我想知道是否有任何研究对模型的性能进行任何研究，而当损耗函数不基于下一个令牌，而是预测输入序列中某个地方的蒙版令牌。  最终，我们想扩展它（也许是通过微调），以预测一系列缺少的令牌，而不是一个，但这似乎是一个不错的起点。  我找不到太多关于文献中无监督的培训方案的信息，但似乎有人一定已经尝试过。有任何建议，或者是一个坏主意？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/thewittyscreenname     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iq4f0r/1iq4f0r/d_have_any_llm_llm_papers_predication_a_token_in_in_in_in_in_the/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq4f0r/d_have_any_llm_papers_predicted_a_token_in_the/</guid>
      <pubDate>Sat, 15 Feb 2025 15:59:49 GMT</pubDate>
    </item>
    <item>
      <title>[D]时间序列 - 训练滚动窗口 - 如何选择最佳型号？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq3p3a/d_time_series_training_rolling_windows_how_to/</link>
      <description><![CDATA[    - 如何选择最佳模型？” src =“ https://b.thumbs.redditmedia.com/lbghkoreo7ixv2gjmfgvpka_p9kvqseg-7rulnouqvk.jpg” title =“ [D] /&gt;    &lt;！ -  sc_off-&gt;  你好， 系列，如下图中，选择最佳模型？    假设我们在谈论线性模型（类型Arima），您会在“ Pass 1”上获得一组系数，很可能是“ Pass 2”上的不同集合您最终要选吗？  自然而然地，您想考虑一个具有最好的度量的度量（无论是rmse，都可以说是什么），但是这样做有偏见。想象一下，最好的模型是在“通行证1”上构建的模型，而您实际的预测期是在“ Pass 5”之后 - 您真的想选择建立在最古老的数据上的模型吗？当然，那是最好的，但是建立在“通行证4”或“通行证5”上的那个现在可能会更好。 您看到我的观点吗？ 谢谢你&lt;&lt;  /p&gt;  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/BILTIAS-POMELO-700      [link]    32;   /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq3p3a/d_time_series_training_rolling_windows_how_to/</guid>
      <pubDate>Sat, 15 Feb 2025 15:26:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM法官提供动力的每日ARXIV过滤</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipz934/p_daily_arxiv_filtering_powered_by_llm_judge/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/madyexz     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipz934/p_daily_arxiv_filtering_powered_by_llm_judge/</guid>
      <pubDate>Sat, 15 Feb 2025 11:14:16 GMT</pubDate>
    </item>
    <item>
      <title>[r]通过基于抽象网格的任务评估LLM中的物理概念理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipw78p/r_evaluating_physical_concept_understanding_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项工作介绍了一个结构化评估框架，用于评估LLMS中物理理解的结构化评估框架，从教育测试原理中得出。研究人员使用定量和定性问题开发了一个全面的测试套件，涵盖了力学，热力学和电磁套件。 关键技术方面： - 多级评估层次结构，从事实回忆到概念转移到最小的词汇，以最小化 - 语言模式匹配 - 使用平行问题的跨文本验证 - 数值计算和概念解释任务的集成 - 基于教育评估方法的标准化评分标准评分 主要结果：-GPT -4在基本物理学上实现了76％的准确性计算 - 跨文本转移问题的性能下降至43％ - 跨物理域的性能显着差异 - 模型在数学能力和物理问题解决问题之间显示出很强的相关性 - 结合多个物理概念 时出现了系统错误我认为这种方法比以前的工作提供了一种更严格理解LLM功能的方法。教育测试框架有助于区分表面水平的模式匹配和更深的概念理解。这可能会导致更好的基准测量科学推理中的AI进展。 我认为，结果突出了LLMS在跨环境中传递物理知识的当前局限性 - 这对于实际科学工作至关重要。系统评估方法可以扩展到其他科学领域。  tldr：基于教育测试原理的新评估框架表明，LLM具有体面的物理计算能力，但与更深入的概念理解和知识转移斗争。 。&gt;   完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipw78p/r_evaluating_physical_concept_understanding_in/</guid>
      <pubDate>Sat, 15 Feb 2025 07:21:24 GMT</pubDate>
    </item>
    <item>
      <title>[d]变压器最有前途的继任者是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipvau4/d_whats_the_most_promising_successor_to_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我所知道的是mamba，从效率的角度看（推理是线性而不是二次），但是Afaik没有人受过训练的大型模型。还有 xlstm  and  aaren 。  你们认为变压器最有前途的替代体系结构是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jsonathan     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipvau4/d_whats_the_most_promising_successor_to_the/</guid>
      <pubDate>Sat, 15 Feb 2025 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>未配对的方式[D] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipql8c/unpaired_modalitiesd_r/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好！我正在寻找一个涉及多模式学习的研究主题，但方式没有配对。更具体地说，在剪辑等论文中，存在文本图像对，以自我监督的方式训练模型。同样，Flava具有配对和未配对的文本图像模式数据集。  是否有任何研究工作涉及从多种未配对的，未链接的方式中学习？您可能遇到的任何研究论文或概念吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/halfcursed     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipql8c/unpaired_modalitiesd_r/</guid>
      <pubDate>Sat, 15 Feb 2025 01:35:07 GMT</pubDate>
    </item>
    <item>
      <title>[P]时间序列异常检测的GNNS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipgk8p/p_gnns_for_time_series_anomaly_detection/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好！ 👋 在过去的几个月中，我和我的伴侣一直在研究一个项目，探讨图形神经网络（GNNS）用于时间序列异常检测（TSAD）。由于我们即将完成工作，我很想从这个惊人的社区那里获得反馈！ 🔗repo： GRAGOD-基于GNN的异常检测  任何评论，建议或讨论都非常欢迎！如果您觉得仓库很有趣，那么丢弃⭐就意味着很多。 ：） 我们还计划在未来几个月内发布一份详细报告，并提供我们的发现和见解，因此请继续关注！ 存储库仍在开发中，所以不要太苛刻了：） 期待听到您的想法！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/usestion-gear-325     link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipgk8p/p_gnns_for_time_series_anomaly_detection/</guid>
      <pubDate>Fri, 14 Feb 2025 17:56:59 GMT</pubDate>
    </item>
    <item>
      <title>[r]用潜在推理扩展测试时间计算：一种反复的深度方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip8lhf/r_scaling_up_testtime_compute_with_latent/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我们研究一种新型的语言模型体系结构，能够通过隐式推理潜在空间来扩展测试时间计算。我们的模型通过迭代复发块来起作用，从而在测试时间内展开对任意深度。这与主流推理模型相反，该模型通过产生更多的令牌来扩展计算。与基于思想链的方法不同，我们的方法不需要任何专业的培训数据，可以与小型上下文窗口一起使用，并且可以捕获不容易用文字表示的推理类型。我们将概念验证模型扩展到35亿参数和8000亿个令牌。我们表明，由此产生的模型可以在推理基准上提高其性能，有时会显着，达到相当于500亿个参数的计算负载。  本文在测试时在潜在空间中推理的论文是迷人。我认为这种方法正在成为一种趋势，并可以重新定义我们如何看待语言模型中的推理。 Meta Fair在大型概念模型上的工作也涉及潜在推理。  arxiv链接： [2502.05171]带有潜在推理：经常性深度方法   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/hiskuu     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip8lhf/r_scaling_up_testtime_compute_with_latent/</guid>
      <pubDate>Fri, 14 Feb 2025 11:32:58 GMT</pubDate>
    </item>
    <item>
      <title>[D]我们在Google和Apple建立了Genai，然后离开以建立开源AI实验室，以使开放社区能够协作和建造下一个DeepSeek。 2月14日（星期五）上午9点至下午12点，请向我们询问！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioxatq/d_we_built_genai_at_google_and_apple_then_left_to/</link>
      <description><![CDATA[在   tl; dr：嗨，我们是Oumi，一个人的AI实验室，相信无条件开源的方法 - 代码，权重，培训数据，基础架构和协作 - 因此可以集体向前推动AI。我们为任何人建立了一个在AI中进行研究的平台。向我们询问有关开放源代码，扩展大型模型，DeepSeek的任何内容，以及在大型科技公司内外建立前沿模型所需的内容。告诉我们什么在开源AI中运作良好或您面临的挑战。我们应该共同努力以改进公开的AI？  ------------------------------  多年来，我们在Big Tech（Google）工作，苹果，微软）在Google Cloud Palm，Gemini和Apple的Health Foundation模型等Genai模型上的主要努力。我们在孤岛工作，知道必须有一种更好的方法来公开和协作开发这些模型。因此，我们建立了一个真正的开源AI平台，使世界各地成千上万的AI研究人员，科学家和开发人员可以合作，以一种集体的方式促进Frontier AI，从而导致更有效，透明和透明和稳定负责任的发展。 OUMI平台（完全开源，Apache 2.0许可证）支持预训练，调整，数据策展/综合，评估以及任何其他常见的效用，以完全可记录的和可重复的方式，同时易于自定义以支持新方法。   DeepSeek向我们展示了开源通过利用Llama之类的开放权重模型可以实现的目标。但是我们认为，AI应该更加开放：不仅是权重，而且还应该进行培训数据，以及代码将其全部打开。然后走得更远：使任何人都可以轻松访问和实验，使社区可以轻松合作和协作。  如果您有兴趣的话，有关OUMI的一些资源： 我们的github repo： https：https： //github.com/oumi-ai/oumi   我们的发布故事： https://venturebeat.com/ai/ex-google-google-apple-apple-egneers-launch -uncondition-open-source-oumi-ai-platform-that-that-that-that-the-could-help-to-build-the-next-deepseek/  我们的网站： https://oumi.ai/    如果您想协作并为社区研究项目做出贡献，无论您在哪里得到计算，都可以签名在： https://oumi.ai/community 。我们将从现有开放模型的训练后开始，接下来，我们将协作进行改进，以进行培训。我们打算与包括作者的所有贡献者一起发布研究。 我们在这里回答有关我们的开源方法，扩展大型模型，DeepSeek的问题大型科技公司以及大家都想讨论的其他任何事情。&lt; / p&gt; 我们将于2月14日星期五上午9点至下午12点pt / 12 pm-3 pm-3pm。问我们任何事情。  加入我们的AMA：   （ u/koukoumidis ） manos koukoumidis   - 首席执行官兼联合创始人ex-google（cloud genai铅） （ u/oelachqar ） Oussama elachqar   - 联合创始人，工程，Ex-Apple（健康基础模型） （ u/matthewpersons ） Matthew Persons   - 联合创意，工程学，工程，Ex -google（云棕榈＆amp; nl铅） （ u/jeremy杰里米·格里尔（Jeremy Greer）  - 联合创始人，研究，前google（双子座对齐）    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/koukoumidis     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioxatq/d_we_built_genai_genai_google_and_apple_apple_paple_then_left_then_left_to/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioxatq/d_we_built_genai_at_google_and_apple_then_left_to/</guid>
      <pubDate>Thu, 13 Feb 2025 23:53:27 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>