<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Tue, 04 Mar 2025 06:26:32 GMT</lastBuildDate>
    <item>
      <title>[r]谨慎的优化者：通过一行代码改进培训</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j33lm7/r_cautious_optimizers_improving_training_with_one/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是一个令人惊讶的简单调整。在大多数现代深度学习优化器中，通常根据梯度的运行差异，以某种形式的动量和/或学习率缩放来计算模型权重的更新。这意味着“瞬时”从特定的向后通行证的梯度实际上可能指向更新的方向。 作者提出了一个简单的更改：他们建议忽略优化器的任何更新，而优化器的任何更新与最新后退的相反符号。换句话说，他们建议仅应用与当前梯度保持一致的更新，从而使更新更稳定，并且与最新数据一致。他们发现，这种小的调整可以大大加快训练的速度。 这是一个有趣的想法，虽然我很好奇它是如何发挥作用的，但我将等待独立的复制，然后才完全相信。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ahmedmastafa16     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j33lm7/r_cautious_optimizers_improving_improving_training_with_with_one/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j33lm7/r_cautious_optimizers_improving_training_with_one/</guid>
      <pubDate>Tue, 04 Mar 2025 05:21:52 GMT</pubDate>
    </item>
    <item>
      <title>[R]具有非高斯可能性的高斯过程的集成梯度归因</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j337qu/r_integrated_gradient_attribution_for_gaussian/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi reddit， 我一直在做这项兼职，很喜欢一些反馈 - 无需退缩，请随时告诉我，如果您认为这应该为crackpot Science标记：  paper： https://arxiv.org/pdf/2205.12797     代码： https://github.com/sarems/sarems/sarems/iggp    这个想法是应用 稀疏变异高斯过程具有非高斯的可能性/观察值。我在可能的情况下衍生了封闭形式的公式，并使用了taylor近似 /高斯 -   - 高正交正交正交（定理1）。  此外，当使用高斯过程模型时，我正在研究集成梯度的完整性属性（属性的总和=模型输出的差异），而不是原始工作（Theorem 2）。提交由＆＃32; /u/sarems     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j337qu/r_integrated_gradient_attribution_for_gaussian/</guid>
      <pubDate>Tue, 04 Mar 2025 04:59:10 GMT</pubDate>
    </item>
    <item>
      <title>[P]建议或有关如何创建指令数据集的指导</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j320ns/p_advice_or_guidance_on_how_to_create_an/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我有一个糖尿病友好型食谱数据集，其中包括标题，描述，准备时间，烹饪时间，服务时间，服务，分步说明，标签，标签，营养事实，营养事实和配料列表等领域。我希望将其转变为指令 - 格式数据集（即{指令，输入，输出}三倍）来训练或微调大型语言模型 我对教学调整有点陌生，任何建议，经验，因此，您可以分享的任何建议，您可以提前感谢您的DETAS！ href =“ https://huggingface.co/datasetsets/elizah521/diabetes_recipes/tree/main/main”&gt; https://huggingface.co/datasets/elizah521/diabetes_recipes_recipes_recipes/tree/main/main/main/main/main  /u/u/forade-type-1514     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j320ns/p_advice_or_guidance_on_how_to_create_an/</guid>
      <pubDate>Tue, 04 Mar 2025 03:54:35 GMT</pubDate>
    </item>
    <item>
      <title>[d]我应该将哪种加强学习方法用于LLMS扑克AI？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2q3q4/d_what_reinforcement_learning_method_should_i_use/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我正在研究一个扑克AI项目，在那里我正在培训大型语言模型（LLM），以预测给定游戏状态的扑克动作（检查，呼叫，下注，下注，加薪等）。我的最终目标是创建一个模型，该模型主要是通过自我播放和对手建模来高水平发挥扑克的作用。但是，我遇到了一些挑战，希望您能帮助我！ 这是情况：  培训方法：我正在使用“真正的扑克手动历史数据”上使用监督的微调（SFT）来最初教LLM如何预测游戏国家的扑克动作。这意味着该模型从过去的游戏的示例中学习，预测玩家在各种情况下采取的行动。 自我播放设置：我计划最终转向自我玩法，在这里LLM将与自己（或我创建的其他类型的模型来模拟不同的游戏样式）。我将使用这些自我播放会话来改善模型。这给我带来了训练的相当多种对手行为。连续的动作空间。这使得应用传统的RL方法有些棘手。  我的问题： 鉴于我无法访问动作概率，我应该采取什么RL方法或策略来改善模型？具体来说，我正在寻找一种方法：  将自我播放与基于奖励的学习结合在一起。 不需要连续的概率来完善模型，而不需要连续的概率。 确保模型确保过度适应其先前的行为，而是在播放和利用不同的策略，但我                   监督微调或使用更简单的RL技术（例如Monte Carlo更新），但我不确定哪种方法最适合我拥有的LLM设置。我还考虑了Q学习或深度Q学习。 鉴于我的情况，我应该采取的任何建议或建议将不胜感激！ 是的，是的，我用AI使用AI来编写此Queston。但它捕获了我想说的一切，我很努力写作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/godlover123451     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2q3q4/d_what_reinforcement_learning_method_should_i_use/</guid>
      <pubDate>Mon, 03 Mar 2025 18:49:08 GMT</pubDate>
    </item>
    <item>
      <title>[D]时间序列预测中的增量学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2nvjk/d_incremental_learning_in_time_series_forecasting/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 我正在研究一个时间序列预测模型，以预测跨多个位置的不同SKU的销售。由于影响了销售的所有外源变量，因此诸如线性回归或sarimax之类的传统方法还不够，因此我一直在尝试具有不错的结果的LSTMS。 （非常欢迎有关改进LSTMS或替代模型的任何技巧） 我每周生成90天的预测，我想通过逐步更新模型，而不是从scratch中重新培训。但是，我意识到每周更新可能不会显着影响预测。 是通过LSTMS学习常见的实践，还是会引入漂移/错误？滚动的重新训练方法（例如，每月）会更可靠吗？ 事先感谢您的见解。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bigbeerbelly-    href =“ https://www.reddit.com/r/machinelearning/comments/1j2nvjk/d_incremental_learning_in_time_time_series_series_forecasting/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2nvjk/d_incremental_learning_in_time_series_forecasting/</guid>
      <pubDate>Mon, 03 Mar 2025 17:19:21 GMT</pubDate>
    </item>
    <item>
      <title>[D]用于分类的任何易于访问的多模式LLM（视频，文本和音频）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2luw5/d_any_easily_accessible_multimodal_llms_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我正在寻找多模式LLMS ，可以同时处理视频，文本和音频输入 ，并且相对易于使用用于分类&gt; 分类。我知道存在一些支持多模式输入的模型，但许多模型似乎很难设置。您知道有任何简单地使用轻量级框架尝试的m吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kernel_kp     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2luw5/d_any_easily_accessible_multimodal_llms_for/</guid>
      <pubDate>Mon, 03 Mar 2025 15:56:41 GMT</pubDate>
    </item>
    <item>
      <title>[r] CVPR拒绝2次接受，一个弱拒绝</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2g6vv/r_cvpr_reject_with_2_accepts_and_one_weak_reject/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我在几天前关于CVPR提交的帖子中对此进行了轻微讨论，但是我只是想提出更多意见。我有一张拒绝的纸张，最终得分为5（4）/5（3）/2（3）。决定取决于ACS，但我真的觉得拒绝的理由确实很轻。例如，我对为什么我的方法与方法X不同的讨论还不够（AC说这些方法的确有所不同，但他们说我的解释方式尚不清楚），但是很难在一页中解释一下，在一页中，您必须在其中进行许多其他评论。另外，他们说，我的方法可能并不能真正改善我正在评估的任务，但是我的结果没有重叠的错误栏，有5个不同的基线，这就是为什么我接受了两个接受。对接受的信心是4和3，而弱势拒绝是3。我通常不会抱怨，我们都会遭到拒绝，但是两个接受的拒绝？那你为什么还会得到审稿人呢？我在2023年获得了CVPR，它比目前的论文弱。我觉得这是随机性的一部分，但是在这种情况下……我无法避免觉得有问题。 有些人说我应该用PC提高它，但我真的不确定。我肯定会准备我的ICCV提交。您有什么意见？谢谢：）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/elpelana     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j2g6vv/r_cvpr_rejection_with_2_accept_2_accepts_and_and_and_one_weak_reject_reject_reject/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2g6vv/r_cvpr_reject_with_2_accepts_and_one_weak_reject/</guid>
      <pubDate>Mon, 03 Mar 2025 11:01:13 GMT</pubDate>
    </item>
    <item>
      <title>[d]特征重要性共识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2g6og/d_feature_importance_consensus/</link>
      <description><![CDATA[     src =“ https://a.thumbs.redditmedia.com/tuvbtnsxw63sdddp1ibl0bnar5lhpvlxteffeffeffehn1lrf8.jpg” title =“ title =“ [d demport exportion taport eartitiment eartitiment eartitiment eartitiment eartitiment eartitiment eartitiment eartitiment eartitiment eartitimence&#39;&#39;/&gt; 在多个机器学习模型中建立一个特征重要性的共识，包括山脊，套索和弹性净回归（以它们的系数为衡量重要性），以及随机的森林和XGBoost。在将特征的重要性归一化之后，我观察到这些模型的特征重要性之间的Pearson相关性大多较弱。鉴于此，建立特征重要性的共识仍然有意义吗？我应该专注于低标准偏差以确保一致性的功能吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;  /u/limmick   [link] ＆＃32;   [注释]     ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2g6og/d_feature_importance_consensus/</guid>
      <pubDate>Mon, 03 Mar 2025 11:00:52 GMT</pubDate>
    </item>
    <item>
      <title>[R]在CVPR上接受了一篇论文，我应该将其放在Arvix中吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2epr9/r_had_a_paper_accepted_at_cvpr_should_i_put_it_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好，所以我的第一篇论文在CVPR上接受。显然，该纸将在6月1日左右的计算机视觉基金会提供。因此，我想知道是否应该将其放入Arvix！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/training-Adeptness57     [links]       &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j2epr9/r_had_a_a papper_accepted_at_accepted_at_cvpr_should_i_i_i_ipput_it_it_it_it_in/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2epr9/r_had_a_paper_accepted_at_cvpr_should_i_put_it_in/</guid>
      <pubDate>Mon, 03 Mar 2025 09:14:15 GMT</pubDate>
    </item>
    <item>
      <title>[d]开源模型的未知培训分布将如何影响企业的微调过程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j2cslw/d_how_will_the_unknown_training_distribution_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， ，我很想知道您对我们不知道某些开源模型的培训分布这一事实的看法。如果我们将来会这样进行，那么公司将上传他们的模型而不是培训的数据，这将如何影响企业？ 我的想法是，这也是“风险”。为了使组织使用这些权重，因为生产可能会有幻觉。或者，应该进行超级广泛的评估框架，以便100％确定生产中没有错。 您怎么看？  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ml_nerdd     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j2cslw/d_how_will_the_unknown_training_distribution_of/</guid>
      <pubDate>Mon, 03 Mar 2025 06:52:25 GMT</pubDate>
    </item>
    <item>
      <title>[d]机器学习工程师角色与ML核心的应用科学家角色之间有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j21zmk/d_what_is_the_difference_between_machine_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     他们的责任的一般差异是什么？ 未来的阶梯？ 付费？    我发现这里有几个类似的问题在这里4-5岁。从那以后发生了很多事情（蓬勃发展的公司，然后是大规模裁员，Chatgpt Boom等），我想再次要求这一点以了解当前的行业环境。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/madgradstudent99    href =“ https://www.reddit.com/r/machinelearning/comments/1j21zmk/d_what_is_is_the_the_difference_between_machine_learning/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j21zmk/d_what_is_the_difference_between_machine_learning/</guid>
      <pubDate>Sun, 02 Mar 2025 21:28:57 GMT</pubDate>
    </item>
    <item>
      <title>[p]我制作了体重 - 一种简单的方法，可以在一分钟内训练任何嵌入模型的适配器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1udcu/p_i_made_weightgain_an_easy_way_to_train_an/</link>
      <description><![CDATA[   /u/u/jsonathan       [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1udcu/p_i_made_weightgain_an_easy_way_to_train_an/</guid>
      <pubDate>Sun, 02 Mar 2025 16:13:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] Camie Tagger -70,527动漫标签分类器在单个RTX 3060上训练，F1得分为61％</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1u0j7/p_camie_tagger_70527_anime_tag_classifier_trained/</link>
      <description><![CDATA[       &lt;！ -  sc_off- sc_off-&gt;  3个月后，我终于完成了我的Anime Image tag dan dan dan dan dan dan dan dan dan dan achie dan achie dan achie face dan achie face dan achie face dan achie face blogbove 61％F1，数据集。该项目表明，强大的多标签分类模型可以通过正确的优化技术在消费硬件上进行培训。  关键技术细节：   在单个RTX 3060（12GB VRAM）上使用Microsoft Deepspeed for Cross firts for for Cross for for Cross-li&gt;               （214m参数）和精制模型（424m参数）。 阶段之间仅0.2％F1得分差异（61.4％vs 61.6％）。 在3.5个时期内对2m图像进行了培训（7m总样本）（7m总样本）。分类器可预测来自EfficityNet V2-L特征的标签。然后，通过对TAG共发生模式进行建模，跨注意机制可以完善预测。这种方法表明，预测标签之间的建模关系可以提高准确性而无需实质上增加计算间接费用。  内存优化：在消费者硬件上训练该模型，我使用：   零阶段2，用于优化        li&gt; li&gt; li&gt; li&gt; li&gt;   微型批量的大小为4，有效批次大小为32     标签分布：该模型涵盖7个类别：一般（30,841个标签），角色（26,968），版权所有（5,364），Artist（7,007,007），Meta（33） （20）。  类别特定的F1分数：   艺术家：48.8％（7,007 tags） 字符：73.9％（73.9％（26,968 tags） （30,841个标签） 元：60％（323个标签） 评分：81.0％（4个标签） 年：33％（20 tags）      接口：      有趣的发现：许多“误报”实际上是Danbooru数据集本身缺少正确的标签，表明该模型的现实世界性能可能比基准指示的要好。 我特别令人印象深刻，它在艺术家标签上的表现非常好，因为它们在预测所需的功能方面非常抽象。字符标记也令人印象深刻，因为示例图像显示图像在维持纵横比的同时将图像全部调整到512x512的情况下，图像中的多个（8个字符）。 我还发现，我还发现该模型仍然对现实图像也很好。也许可以通过在另一个数据集上微调模型，以更真实的示例来完成类似的事情。  拥抱面孔。还有一个用户友好的推理应用程序。随时提出问题！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/camais     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/comments/1j1u0j7/p_camie_tagger_70527_anime_anime_tag_classifier_train/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1u0j7/p_camie_tagger_70527_anime_tag_classifier_trained/</guid>
      <pubDate>Sun, 02 Mar 2025 15:58:03 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1hc0o/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Mar 2025 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>