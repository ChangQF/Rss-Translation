<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 19 May 2024 18:17:15 GMT</lastBuildDate>
    <item>
      <title>[D] SOFTS：利用系列核心融合进行高效的多元时间序列预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvtx30/d_softs_efficient_multivariate_time_series/</link>
      <description><![CDATA[很高兴分享我最新的关于时间序列预测的 Medium 文章。“SOFTS：使用系列核心融合进行高效的多元时间序列预测” SOFTS 是一种基于 MLP 的创新模型，利用新颖的 STar Aggregate-Dispatch (STAD) 模块来集中通道交互，以线性复杂度实现卓越的预测性能。与在鲁棒性和复杂性之间进行权衡的传统方法不同，SOFTS 可以有效地捕获渠道相关性，为金融、交通管理和医疗保健等各个领域的可扩展和准确的预测铺平道路。  https ://medium.com/towards-artificial-intelligence/softs-efficient-multivariate-time-series-forecasting-with-series-core-fusion-0ac40d2adcd2   由   提交/u/rezayazdanfar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvtx30/d_softs_efficient_multivariate_time_series/</guid>
      <pubDate>Sun, 19 May 2024 17:47:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] DSPy 真的会改变 LM 权重吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvsviu/d_does_dspy_actually_change_the_lm_weights/</link>
      <description><![CDATA[我一直认为它本质上是美化和结构化的提示工程（在我看来仍然非常有用），但它也在文档中声称它进行了微调和更改LM 权重，然后绝对拒绝在其文档的任何部分中详细说明这一点。 我什至不明白它如何改变 LM 的实际参数，特别是如果我们使用LM 的第三方 API 调用。  通过 LM 权重，我认为它意味着变压器模型最后一层的权重。当他们描述优化器时，他们说“DSPy 引入了新的优化器，这是 LM 驱动的算法，可以根据您想要最大化的指标调整 LM 调用的提示和/或权重。” &lt; p&gt;我是否误解了 LM 权重的含义？ 如果这是一个愚蠢的问题，我很抱歉，但我似乎找不到任何有关此的信息。提前致谢！   由   提交 /u/chessnudes   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvsviu/d_does_dspy_actually_change_the_lm_weights/</guid>
      <pubDate>Sun, 19 May 2024 16:58:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] Text to Openpose 和奇怪的 RNN bug</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvsmgq/p_text_to_openpose_and_weird_rnn_bugs/</link>
      <description><![CDATA[我想创建一个从文本描述生成 openpose 的 AI，例如如果输入“a man running” 输出将像我提供的图像一样，有没有推荐给我的模型架构？ 我的数据条件是  canvas_width: 900px canvas_height: 300px frames: 5 (5 person)  https://preview.redd.it/2p971ugcbe1d1.png?width=900&amp;format=png&amp;auto=webp&amp;s=88e9d230c2b02fbe9e5f788a5191692f2827dfd0 我尝试训练 RNN 来完成这项任务，我使用句子转换器来嵌入文本，然后传递给 RNN，损失如下图所示 from sentence_transformers import SentenceTransformer sentence_model = SentenceTransformer(&quot;all-MiniLM-L6-v2&quot;) text = &quot;a man running&quot; text_input = torch.tensor(sentence_model.encode(text), dtype=torch.float)  我的 RNN 设置 embedding_dim = 384 hidden_​​dim = 512 num_layers = 3 output_dim = 180 num_epochs = 100 learning_rate = 0.001 rnn_model = RNN(embedding_dim, hidden_​​dim, num_layers, output_dim)  https://preview.redd.it/2l6i3iq4pe1d1.png?width=578&amp;format=png&amp;auto=webp&amp;s=de9a43998b5d06da9c95beefb47541c18c353e2f 但问题是无论我输入什么，每次输出都是一样的！但是当我尝试将 num_layers 更改为 1 并保持其他设置相同时，如下所示 embedding_dim = 384 hidden_​​dim = 512 num_layers = 1 output_dim = 180 num_epochs = 100 learning_rate = 0.001 rnn_model = RNN(embedding_dim, hidden_​​dim, num_layers, output_dim)  损失现在看起来像这样 https://preview.redd.it/jfu175idre1d1.png?width=578&amp;format=png&amp;auto=webp&amp;s=c435187a313d2227bfe1c2be5c4ff6bd8f7ad8cd 现在问题已经解决！！ 此外，我还尝试检查“每次输出都相同”的原因问题我检查了 dataloader 和其他代码，但没有发现问题只有 num_layers=3 导致问题 num_layers=1 修复了它 这是我的训练循环 criterion = nn.MSELoss() optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate) trainingEpoch_loss = [] validationEpoch_loss = [] for epoch in range(num_epochs): step_loss = [] rnn_model.train() for idx, train_inputs in enumerate(train_dataloader): optimizer.zero_grad() output = rnn_model(torch.unsqueeze(train_inputs[&#39;text&#39;], dim=0)) training_loss = criterion(outputs, train_inputs[&#39;poses&#39;]) training_loss.backward() optimizer.step() step_loss.append(training_loss.item()) if (idx+1) % 1 == 0: print (f&#39;Epoch [{epoch+1}/{num_epochs}], Step [{idx+1}/{len(train_dataloader)}], Loss: {training_loss.item():.4f}&#39;) trainingEpoch_loss.append(np.array(step_loss).mean()) rnn_model.eval() for idx, val_inputs in enumerate(val_dataloader): validationStep_loss = [] output = rnn_model(torch.unsqueeze(val_inputs[&#39;text&#39;], dim=0)) val_loss = criterion(outputs, val_inputs[&#39;poses&#39;]) validationStep_loss.append(val_loss.item()) validationEpoch_loss.append(np.array(validationStep_loss).mean())  这是我的推断 text = &quot;a man running&quot;processed_text = torch.tensor(sentence_model.encode(text), dtype=torch.float) output_poses = rnn_model(processed_text.unsqueeze(0)) print(output_poses.shape) #shape=(1, 180) 1 个人是 36（1 个人的原始数据是 54，但我将其更改为 36，因为我只想要 x 和 y 而不是 z，所以剪掉 z 轴）并且有 5 个人所以 5*36 = 180  我的问题是  除了 RNN 之外，有没有推荐用于此任务的模型架构？ 为什么无论我输入什么，当 num_layers=3 时输出都相同，我很困惑，因为如果模型给出相同的输出，损失就不会下降，对吗？这意味着它在推理阶段给出相同的输出     提交人    /u/Peemlock   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvsmgq/p_text_to_openpose_and_weird_rnn_bugs/</guid>
      <pubDate>Sun, 19 May 2024 16:46:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 是如何从从事令人兴奋的研究变成一家类似大型科技公司的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</link>
      <description><![CDATA[我最近重新审视了 OpenAI 关于 DOTA2 Open 的论文五，从工程和研究的角度来看，他们在那里所做的事情令人印象深刻。创建一个包含 50k 个 CPU 的分布式系统用于部署，1k 个 GPU 用于训练，同时每 0.25 秒从 16k 个观察中执行 8k 到 80k 个操作 - 这有多疯狂？他们还对 RL 模型进行“手术”以恢复权重，因为在几个月的训练中，他们的奖励函数、观察空间甚至架构都发生了变化。最后但并非最不重要的一点是，他们击败了 OG 队（当时的世界冠军），并部署了代理与其他玩家在线实时比赛。  快进几年，他们正在预测序列中的下一个标记。不要误会我的意思，gpt4 及其全能版本的功能确实是工程和研究的惊人壮举（可能更有用），但它们似乎并不像它们的一些产品那样有趣（从研究角度来看）  那么，现在我想知道这些年来工程师和研究人员是如何转变的？主要是由于他们的财务状况和盈利需要，还是有更深层次的原因进行转型？   由   提交 /u/UnluckyNeck3925   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</guid>
      <pubDate>Sun, 19 May 2024 16:46:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML中的计算机视觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvs57n/d_computer_vision_in_icml/</link>
      <description><![CDATA[嗨，这是我参加 ICML 的第一年。根据以往的会议，我想知道这次会议上通常会出现多少计算机视觉方面的内容（如果有的话）？   由   提交 /u/hilabar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvs57n/d_computer_vision_in_icml/</guid>
      <pubDate>Sun, 19 May 2024 16:25:08 GMT</pubDate>
    </item>
    <item>
      <title>来自第一原则的多模态人工智能——最基本的方法 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvrunk/multimodal_ai_from_first_principles_most/</link>
      <description><![CDATA[      分享我制作的一些最关键的视频以及过去十年左右训练多模式模型的基本构建块……如果您对这个主题感兴趣，希望您喜欢！   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvrunk/multimodal_ai_from_first_principles_most/</guid>
      <pubDate>Sun, 19 May 2024 16:12:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 适用于 onnx 模型的 Tensorrt CPP 代码库：动态批处理、所有模型、单文件模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvqxuz/p_tensorrt_cpp_codebase_for_onnx_models_dynamic/</link>
      <description><![CDATA[https:/ /github.com/PrinceP/tensorrt-cpp-for-onnx/tree/main 创建了一个区域，用于使用 ONNX 模型为 Tensorrt 提供 CPP 代码库。目前YOLOV9、YOLOV8[Detect、Segment、Classify、OBB、POSE]已编码。其他模型正在开发中。   由   提交 /u/Grapefruit-Narrow   /u/Grapefruit-Narrow  reddit.com/r/MachineLearning/comments/1cvqxuz/p_tensorrt_cpp_codebase_for_onnx_models_dynamic/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvqxuz/p_tensorrt_cpp_codebase_for_onnx_models_dynamic/</guid>
      <pubDate>Sun, 19 May 2024 15:32:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在机器学习中回收旧会议提交内容的文化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</link>
      <description><![CDATA[我从事统计机器学习工作。我注意到很多人（包括我自己和我审阅的人）经常重复他们向 ML 会议提交的论文。 例如，如果他们的论文被 ICML 拒绝，他们会提交给 NeurIPS，然后提交给 ICLR（或UAI/AISTATS 在我的领域也是顶尖的）。如果2~3次后没有进入ICML/NeurIPS/ICLR，他们就会将其提交给AAAI/IJCAI/TMLR/ICDM，T-NNLS/T-KDD/NN/Neurocomputing等期刊，或特定领域的场地，如LoG/CoLLA/AABI。经过所有这些，如果论文仍然没有被接受，他们就简单地将它们或 arXiv.我相信 CV/NLP 也可能是这种情况。 作为审稿人，我经常遇到会议提交的内容，作者在没有真正考虑之前提供的审稿的情况下重新提交。有时他们在重新提交时确实会纳入审稿意见，但有时工作可能只是达不到一级会议的水平，但他们只是不断重新提交并希望能够偶然被接受。 我认为这正在消耗社区审稿人的大量时间来继续审阅相同的提交内容（特别是考虑到 NeurIPS 达到 20k 提交 ID；我预计会看到许多重新提交）。这也许也是 TMLR 诞生的原因之一（强调正确性而不是新颖性）。 我确实理解“研究质量比发表地点更重要”之类的论点。或者“OpenAI 通常只是简单地将他们的论文（例如 GPT-X）放在 arXiv 上”。然而，学生或初级研究人员在他们的职业生涯中也需要发表论文，包括我自己。  人们对此有何看法？   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</guid>
      <pubDate>Sun, 19 May 2024 14:04:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在机器学习中有效地进行消融研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/</link>
      <description><![CDATA[在对可预训练和微调的模型进行消融研究时，您是否在预训练和微调期间对每个消融版本执行完整的网格搜索微调？或者你有策略让这个过程更加高效吗？感谢您的见解。   由   提交 /u/Few-Pomegranate4369    reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/</guid>
      <pubDate>Sun, 19 May 2024 13:54:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] N 路注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvkrpf/p_nwayattention/</link>
      <description><![CDATA[我一直在研究在变压器模型中关注两个以上标记的概念。例如，不要使用一个查询和一个密钥，而是使用两个密钥和一个查询，并且对于每对先前标记的每个查询总和。 这使得算法甚至更慢（ O(n**3 ）而不是 O(n**2))，但我认为这是一个有趣的概念。有些结果令我惊讶，比如它在找到最长递增子序列方面有多出色。 我希望它分享它： https://github.com/Gusanidas/n-way-attention/tree/main 并询问是否有人知道处理或提及该概念的论文。   由   提交 /u/Gusanidas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvkrpf/p_nwayattention/</guid>
      <pubDate>Sun, 19 May 2024 09:56:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM Ops的现状如何</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvkmwe/d_what_is_the_current_state_of_llm_ops/</link>
      <description><![CDATA[好奇人们今天如何将他们的 RAG 和其他 LLM 支持的应用程序投入生产。您如何定义 LLM Ops？您的团队/公司中的流程是什么样的，您今天使用哪些工具组合来实现或自动化这些流程，以及哪些方面存在差距。 我特别感兴趣的是人们在生产环境中跨节点扩展较大模型的效率问题上所做的事情。您是否应用了任何 GPU 虚拟化/细分，以及这些的一些好资源是什么？    提交人    /u/gamerx88   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvkmwe/d_what_is_the_current_state_of_llm_ops/</guid>
      <pubDate>Sun, 19 May 2024 09:46:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] Grounding DINO 1.5 发布：最强大的开集检测模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cv0m9x/r_grounding_dino_15_release_the_most_capable/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cv0m9x/r_grounding_dino_15_release_the_most_capable/</guid>
      <pubDate>Sat, 18 May 2024 16:05:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基础时间序列模型被高估了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cv0hl2/d_foundational_time_series_models_overrated/</link>
      <description><![CDATA[我一直在探索基础时间序列模型，如 TimeGPT、Moirai、Chronos 等，并想知道它们是否真的具有强大的样本潜力 -高效的预测，或者他们只是借用 NLP 基础模型的炒作并将其引入时间序列领域。 我可以理解为什么它们可能会起作用，例如，在需求预测中，它是关于但它们能否处理任意时间序列数据，如环境监测、金融市场或生物医学信号，这些数据具有不规则模式和非平稳数据？ 它们的概括能力是否被高估了？    由   提交 /u/KoOBaALT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cv0hl2/d_foundational_time_series_models_overrated/</guid>
      <pubDate>Sat, 18 May 2024 16:00:06 GMT</pubDate>
    </item>
    <item>
      <title>[N] ICML 2024 离散运算可微分研讨会 🤖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cux80i/n_icml_2024_workshop_on_making_discrete/</link>
      <description><![CDATA[大家好！ 今年我们将在 ICML 组织可微分几乎所有内容研讨会。&lt; /p&gt; 许多离散操作，例如排序、topk、最短路径、聚类（等等）几乎到处都有零梯度，因此不适合现代基于梯度的学习框架（例如深度学习）。本次研讨会将涵盖旨在解决此类问题的研究主题！ https:// Differentiable.xyz/ 我们鼓励任何从事相关主题工作的人提交他们的作品。即使您没有提交，也请务必参加 ICML 的研讨会，观看即将举行的一些激动人心的演讲！ 我在下面附上了研讨会的完整摘要！祝你当前的工作一切顺利，L :) 梯度和导数是机器学习不可或缺的一部分，因为它们支持基于梯度的优化。然而，在许多实际应用中，模型依赖于实现离散决策的算法组件，或者依赖于离散的中间表示和结构。这些离散步骤本质上是不可微分的，因此破坏了梯度流。要使用基于梯度的方法来学习此类模型的参数，需要将这些不可微分的组件变成可微分的。这可以通过仔细考虑来完成，特别是使用平滑或松弛来为这些组件提出可微的代理。随着模块化深度学习框架的出现，这些想法在机器学习的许多领域变得比以往任何时候都更加流行，在短时间内生成了大量“可微分的一切”，影响了渲染、排序和排名等各种主题，凸优化器、最短路径、动态规划、物理模拟、神经网络架构搜索、top-k、图算法、弱监督学习和自监督学习等等。 本次研讨会将为任何可区分的事物提供一个论坛，汇聚学术界和行业研究人员，突出挑战和发展，提供统一的想法，讨论实际的实施选择并探索未来的方向。   由   提交/u/machine_learning_res   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cux80i/n_icml_2024_workshop_on_making_discrete/</guid>
      <pubDate>Sat, 18 May 2024 13:22:17 GMT</pubDate>
    </item>
    </channel>
</rss>