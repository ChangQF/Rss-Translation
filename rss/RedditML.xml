<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 06 Jan 2024 15:12:29 GMT</lastBuildDate>
    <item>
      <title>[D] NLP在营销论文思路中的应用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190132l/d_nlp_in_marketing_thesis_ideas/</link>
      <description><![CDATA[我目前正在攻读人工智能硕士学位，我必须完成一篇与营销相关的论文。我的导师希望我将其定位为 NLP，但我不知道我可以做什么类型的项目。它必须涉及一些模型训练，而不仅仅是基于法学硕士的应用程序。 我在网上找到的大部分内容都是关于情感分析的，但我也想考虑一些其他选择。 谢谢！ 编辑：虽然大师有一个理论重点，但我不介意收集实时数据、创建一个简单的前端并部署模型（SWE 的某些方面）。    由   提交/u/AcD_South   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190132l/d_nlp_in_marketing_thesis_ideas/</guid>
      <pubDate>Sat, 06 Jan 2024 14:25:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 就 Dolphin 2.2.1 Mistral 7b LLM 的最快和最高质量实施寻求建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zz4f0/d_seeking_advice_on_fastest_and_highest_quality/</link>
      <description><![CDATA[ 由   提交/u/yachty66  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zz4f0/d_seeking_advice_on_fastest_and_highest_quality/</guid>
      <pubDate>Sat, 06 Jan 2024 12:37:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] llama.cpp 使用单个 LLM 管道进行 GGUF 推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zz27k/p_llamacpp_gguf_inference_with_a_single_llm/</link>
      <description><![CDATA[      ​ https://preview.redd.it/i4rxpfwcdtac1.jpg?width=1296&amp;format=pjpg&amp;auto=webp&amp;s=62c2fa0a8 d724bfcaa5a21a2e40b7343396bc16f&lt; /a&gt; txtai有统一的LLM管道，可以加载Hugging Face模型、llama.cpp GGUF文件和 LLM API。上面的示例从 Hugging Face Hub 下载 GGUF 文件并使用模型运行推理。 请参阅本文了解更多信息：https://neuml.hashnode.dev/integrate-llm-frameworks   由   提交/u/davidmezzetti   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zz27k/p_llamacpp_gguf_inference_with_a_single_llm/</guid>
      <pubDate>Sat, 06 Jan 2024 12:33:16 GMT</pubDate>
    </item>
    <item>
      <title>谷歌 Gemini 潜在训练数据泄露 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zy75g/google_gemini_potential_training_data_leak_d/</link>
      <description><![CDATA[ 由   提交 /u/Shemozzlecacophany   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zy75g/google_gemini_potential_training_data_leak_d/</guid>
      <pubDate>Sat, 06 Jan 2024 11:37:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 摩根大通放弃多式联运文件的 DocLLM！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zy0g4/d_jpmorgan_drops_docllm_for_multimodal_documents/</link>
      <description><![CDATA[摩根大通放弃了发票、报告和多式联运文档的 DocLLM。合同！ 我脑子里有一些有用的 pdf 提取项目。我很高兴在原始论文中看到等效模型的开源可用性。 对此有何想法？    ;由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zy0g4/d_jpmorgan_drops_docllm_for_multimodal_documents/</guid>
      <pubDate>Sat, 06 Jan 2024 11:25:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪个工具可以进行图像比较？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zx2pl/d_which_tool_for_image_comparison/</link>
      <description><![CDATA[我的项目需要一个工具，它需要视觉检测和图像比较模型。基本上，会有一个地方的手绘草图，其他将是该地方相同角度的照片。我希望比较方法考虑拓扑关系 - 例如对象的位置、距离、大小，可能还有轮廓检测、边缘检测和几何变换以提取空间信息 -  一种根据每个对象给出相似性的工具单独的参数将是完美的，但至少有一个数学数字是我至少要寻找的。哪种工具或 API 最适合我的情况。我的时间有限，试图做出最佳选择。提前谢谢您。    由   提交/u/SoLong144  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zx2pl/d_which_tool_for_image_comparison/</guid>
      <pubDate>Sat, 06 Jan 2024 10:21:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 变形金刚的思想链表现力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zufv8/r_the_expressive_power_of_transformers_with_chain/</link>
      <description><![CDATA[论文。我不隶属于作者。 摘要：  最近的理论工作已经发现了令人惊讶的简单推理问题，例如检查图中的两个节点是否连接或模拟有限状态机，标准变压器在读取输入后立即回答，这证明是无法解决的。然而，在实践中，变形金刚的推理可以通过允许他们使用“思维链”来改进。或“暂存器”，即，在回答之前生成中间标记序列并对其进行调节。受此启发，我们问：这种中间生成是否从根本上扩展了仅解码器变压器的计算能力？我们证明答案是肯定的，但增加的数量很大程度上取决于中间代的数量。例如，我们发现具有对数数量的解码步骤（相对于输入长度）的 Transformer 解码器仅略微突破了标准 Transformer 的限制，而线性数量的解码步骤则增加了明显的新能力（在标准复杂性猜想下）：所有常规语言。我们的结果还表明，线性步骤使变压器解码器保持在上下文相关语言内，而多项式步骤使它们能够准确识别多项式时间可解决问题的类别——这是根据标准复杂性类别对变压器类型进行的第一个准确表征。总之，我们的结果提供了一个细致入微的框架，用于理解变压器的思想链或暂存器的长度如何影响其推理能力。    由   提交 /u/Wiskkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zufv8/r_the_expressive_power_of_transformers_with_chain/</guid>
      <pubDate>Sat, 06 Jan 2024 07:23:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习有什么有趣的数学理论吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zo7or/d_is_there_any_interesting_mathematical_theory_of/</link>
      <description><![CDATA[大家好！我的问题在标题中，这是一些背景信息。我的背景可以描述为“主修理论计算机科学（非常强调‘理论’这个词，想想计算复杂性理论），辅修数学”。 几年前，我参加了入门课程机器学习课程......非常沮丧和失望。  没有解释任何东西应该如何或为什么工作，相反有很多不令人信服的猜测，比如“如果你添加一个卷积层，然后它将学习简单的几何形状，因此后面的层将有更多的结构可以使用”或者“我们可以在 RNN 中使用额外的输入，并以某种方式组合三个输入，这样新的输入将起到‘长期记忆’的作用”。我没想到数学逻辑或编程语言理论的严谨程度，但其他科学，例如经济学，至少可以用一些简化的模型来解释他们正在研究的现象。我们在机器学习中没有类似的东西吗？ 在课程中，我们直接跳到一些相当复杂的问题，例如区分猫的图片和狗的图片。我怀疑是否有人能够对这两类图片给出一个很好的定义。虽然这让神经网络能够解决问题变得更加令人印象深刻，但我看不出我们可以从中学到什么关于神经网络如何做到这一点的信息。训练神经网络区分蓝色和绿色、正方形和圆形等，然后尝试使用结果来分析神经网络如何学习不是更好吗？  后来我开了一个很少有机器学习教科书。  我真的很喜欢有关 PAC 学习的部分，总体来说统计学习也很适合我。 有关神经网络和尤其是深度学习，几乎与我在课程中听到的关于仪式舞蹈如何导致降雨的炼金术级别的推测相同。  所以我试图在 arXiv 上找到一些现代结果。   大多数关于机器学习的论文都将更难以推理的模型应用于更难以理解的问题，这让我感到非常失望。 有一些关于神经网络是通用逼近器的结果，即使不多也很好。 我还遇到过（在写硕士论文时）一两篇关于感知器和电路计算复杂性的论文阈值函数。令人遗憾的是，似乎几乎没有关于这个主题的当代研究。  ​ 我的“咆哮”到此结束。 ，我希望这能够澄清“机器学习数学”的类型。我正在寻找。请注意，我确实理解使用现代模型需要大量的知识和专业知识，我并不是想贬低你所做的工作，我只是对找到这些模型如何工作的理论解释有多么困难感到沮丧，考虑到机器学习的普及。 我真的很感激任何想法或建议！ 此外，英语不是我的母语，所以我很抱歉任何拼写错误、不正确的语法或尴尬的句子。 ​ UPD：看到这篇文章刚刚。我真的很想看到更多类似的作品。   由   提交/u/a_broken_coffee_cup   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zo7or/d_is_there_any_interesting_mathematical_theory_of/</guid>
      <pubDate>Sat, 06 Jan 2024 01:50:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 时间序列数据表示学习的最新技术是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zjkyn/d_what_is_state_of_art_for_representation/</link>
      <description><![CDATA[有一堆未标记的一维原始时间序列数据。标记数据量有限。 我正在寻找最好的无监督/自监督编码技术，以学习有用的潜在特征表示（例如，在下游监督预测任务中有用）。  无论是使用 Transformer 还是 CNN (ConvNext V2) 架构，屏蔽自动编码器领域似乎都有很多工作要做。  这些技术是目前最好的技术，还是我还缺少其他在各种数据集上表现出强大性能的技术？ ​ 谢谢！   由   提交/u/ZeApelido  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zjkyn/d_what_is_state_of_art_for_representation/</guid>
      <pubDate>Fri, 05 Jan 2024 22:29:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] Hieros：结构化状态空间序列世界模型的层次想象</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zizet/r_hieros_hierarchical_imagination_on_structured/</link>
      <description><![CDATA[OpenReview: https: //openreview.net/forum?id=5j6wtOO6Fk arXiv：https ://arxiv.org/abs/2310.05167 代码：https： //github.com/Snagnar/Hieros 摘要：  现代深度强化学习面临的最大挑战之一（ DRL）算法是样本效率。许多方法学习世界模型，以便完全在想象中训练智能体，从而消除训练期间直接环境交互的需要。然而，这些方法常常缺乏想象准确性、探索能力或运行效率。我们提出了Hieros，这是一种分层策略，可以学习时间抽象的世界表示并想象潜在空间中多个时间尺度的轨迹。 Hieros 使用基于 S5 层的世界模型，该模型在训练期间并行预测下一个世界状态，并在环境交互期间迭代预测。由于 S5 层的特殊属性，我们的方法可以并行训练并在想象过程中迭代预测下一个世界状态。这使得训练比基于 RNN 的世界模型更有效，并且比基于 Transformer 的世界模型更有效的想象力。 我们表明，我们的方法在 Atari 上的平均和中值归一化人类分数方面优于现有技术。 100k 基准，并且我们提出的世界模型能够非常准确地预测复杂的动态。我们还表明，与现有方法相比，Hieros 显示出卓越的探索能力。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zizet/r_hieros_hierarchical_imagination_on_structured/</guid>
      <pubDate>Fri, 05 Jan 2024 22:04:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士增强法学硕士：通过组合扩展能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zii8u/r_llm_augmented_llms_expanding_capabilities/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2401.02412 OpenReview：https:// /openreview.net/forum?id=jjA4O1vJRz 摘要：  经过训练的数十亿参数的基础模型对大型数据集的研究已经在各个领域展示了不平凡的技能。然而，由于它们的整体结构，增强它们或传授新技能具有挑战性且成本高昂。另一方面，由于它们的适应能力，这些模型的几个新实例正在针对新领域和任务进行训练。在这项工作中，我们研究了现有基础模型与更具体模型的高效实用组合问题，以实现更新的功能。为此，我们提出了CALM——组合增强语言模型——它引入了模型之间的交叉注意力来组合它们的表示并启用新的功能。 CALM 的显着特征是：（i）通过“重用”现有的 LLM 以及一些额外的参数和数据，在新任务上扩展 LLM，（ii）现有模型权重保持完整，从而保留现有功能，以及（ iii) 适用于不同的领域和环境。我们证明，使用在低资源语言上训练的较小模型来增强 PaLM2-S 可以在翻译成英语和低资源语言的算术推理等任务上绝对提高高达 13%。同样，当 PaLM2-S 通过特定于代码的模型进行增强时，我们发现代码生成和解释任务比基本模型相对提高了 40%，与完全微调的对应模型相当。 &lt; /blockquote&gt;   由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zii8u/r_llm_augmented_llms_expanding_capabilities/</guid>
      <pubDate>Fri, 05 Jan 2024 21:44:21 GMT</pubDate>
    </item>
    <item>
      <title>基于变压器的法学硕士不是一般学习者：通用电路视角 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zie7z/transformerbased_llms_are_not_general_learners_a/</link>
      <description><![CDATA[https://openreview.net/forum?id =tGM7rOmJzV  （法学硕士）的巨大成功引发了人工智能界研究重点的显着转变。这些令人印象深刻的实证成就激发了人们对法学硕士是“通用人工智能（AGI）的火花”的期望。然而，一些评估结果也呈现了法学硕士失败的令人困惑的例子，包括一些看似微不足道的任务。例如，GPT-4 能够解决一些 IMO 中对研究生来说可能具有挑战性的数学问题，而在某些情况下它可能会在小学水平的算术问题上出错。 ...  我们的理论结果表明 T-LLM 无法成为通用学习者。然而，T-LLM 在各种任务中取得了巨大的经验成功。我们对这种不一致现象提供了一个可能的解释：虽然 T-LLM 不是一般学习者，但他们可以通过记忆大量实例来部分解决复杂的任务，从而导致人们产生一种错觉，认为 T-LLM 具有真正解决这些任务问题的能力。     由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zie7z/transformerbased_llms_are_not_general_learners_a/</guid>
      <pubDate>Fri, 05 Jan 2024 21:39:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] GPT-4V(ision) 是一款多面手 Web 代理，如果接地 - 俄亥俄州立大学 2024 年 - 可以成功完成实时网站上 50% 的任务！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zgfmx/r_gpt4vision_is_a_generalist_web_agent_if/</link>
      <description><![CDATA[&lt;表&gt;   论文：https://arxiv.org/abs/2401.01614  博客：https ://osu-nlp-group.github.io/SeeAct/  代码： https://github.com/OSU-NLP-Group/SeeAct  摘要：  大型多模态模型（LMM）的最新发展），特别是 GPT-4V(ision) 和 Gemini，一直在快速扩展多模态模型的能力边界，超越图像字幕和视觉问答等传统任务。在这项工作中，我们探索了像 GPT-4V 这样的 LMM 作为通用网络代理的潜力，它可以遵循自然语言指令来完成任何给定网站上的任务。我们提出了 SEEACT，这是一种通用网络代理，它利用 LMM 的力量来实现集成的视觉理解和在网络上的操作。我们对最近的 MIND2WEB 基准进行评估。除了对缓存网站进行标准离线评估之外，我们还通过开发允许在实时网站上运行 Web 代理的工具来启用新的在线评估设置。 我们表明，GPT-4V 为网络代理提供了巨大的潜力 - 如果我们手动将其文本计划转化为网站上的操作，它可以成功完成实时网站上 50% 的任务。这大大优于文本-仅限专门针对网络代理进行微调的 LLM，例如 GPT-4 或更小的模型（FLAN-T5 和 BLIP-2）。然而，接地仍然是一个重大挑战。现有的 LMM 基础策略（例如标记集提示）对于网络代理来说并不有效，而我们在本文中开发的最佳基础策略同时利用了 HTML 文本和视觉效果。然而，仍然存在与预言机基础存在很大差距，留有足够的进一步改进的空间。   https://preview.redd.it/1w22ga2ejoac1.jpg?width=706&amp;format=pjpg&amp;auto=webp&amp;s=204d4852c614efaf8c 39c990d25a7acae805290e  https://preview.redd .it/vaabea2ejoac1.jpg?width=1344&amp;format=pjpg&amp;auto=webp&amp;s=17f5a5ca7e1add213ca4d75ed53a74e230369655 https://preview.redd.it/2720ob2ejoac1.jpg?width=1340&amp;format=pjpg&amp;auto=webp&amp;s=4cec63cdd3e14 48e03f82309ac219684c62b8ffb https://preview .redd.it/9wn5sa2ejoac1.jpg?width=1242&amp;format=pjpg&amp;auto=webp&amp;s=dcc8919105686007d670f9b140aaeb3e4683d56e https://preview.redd.it/ttgaad2ejoac1.jpg?width=801&amp;format=pjpg&amp;auto=webp&amp;s=568 4aa7969a6564eab8cb4a5ea36fa21f4c63e9e    由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zgfmx/r_gpt4vision_is_a_generalist_web_agent_if/</guid>
      <pubDate>Fri, 05 Jan 2024 20:18:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] ArXiv 替代方案（或者是否有可能实现更多“暂停”透明度）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18z3jdr/d_arxiv_alternatives_or_is_there_possible_for/</link>
      <description><![CDATA[我当前的文章已“暂停”差不多一周了（尝试联系模组，得到了一般性的回复）。我在 arXiv 上发表了 5 篇文章，没有任何问题（同一类别中 3 篇）。 还有关于文章被搁置一个月以上的可怕故事 (https://academia.stackexchange.com/questions/189542/arxiv-preprint-on-hold，https://twitter.com/YuanqiD/status/1678949802367676417，https:// twitter.com/moyix/status/1604218507708846082，https://twitter.com/PierLucaLanzi/status/1629569377690439680，https://twitter.com/GriffinAdams92/status/1605310825958637568）。  我知道模组是免费做他们的工作的，如果这个过程在某种程度上是透明的，我可以等待合理的时间。但现在，有些文章一天之内就被接受，有些则需要等待数周/数月。是否有可能让 arXiv“暂停”？状态更透明？例如。通过显示当前队列大小或“保留”的某种原因（错误的类别，像 Covid 这样的敏感话题，...）？  此外，对于 ML 工作，是否有一些 arXiv 的不错替代品？那些具有良好声誉（没有 vixra）、可预测的等待时间并且至少还被 Google Scholar 索引的？   由   提交 /u/osamc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18z3jdr/d_arxiv_alternatives_or_is_there_possible_for/</guid>
      <pubDate>Fri, 05 Jan 2024 10:09:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>