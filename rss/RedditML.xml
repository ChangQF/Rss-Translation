<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 21 Dec 2024 06:21:14 GMT</lastBuildDate>
    <item>
      <title>[D] 2025 年机器学习研究的热点是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hj0p0y/d_whats_hot_for_machine_learning_research_in_2025/</link>
      <description><![CDATA[2025 年，机器学习或与机器学习相关的哪些子领域/方法、应用领域有望获得广泛关注（无意双关）？    提交人    /u/ureepamuree   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hj0p0y/d_whats_hot_for_machine_learning_research_in_2025/</guid>
      <pubDate>Sat, 21 Dec 2024 03:00:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有办法将 3D 网格数据转换为矢量嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hj0j1m/d_is_there_a_way_to_convert_3d_mesh_data_into/</link>
      <description><![CDATA[大家好， 现在我有一堆 3D 网格数据，以 .obj 表示，我想将它们传递到矢量数据库中进行检索。 我想知道，是否有现有的嵌入方法可以让我做到这一点？我认为传统的文本嵌入（如 text-embedding-3-large）在 3D 数据上效果不佳？ 提前感谢大家！    提交人    /u/LooouisZ   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hj0j1m/d_is_there_a_way_to_convert_3d_mesh_data_into/</guid>
      <pubDate>Sat, 21 Dec 2024 02:50:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么蒙特卡洛树搜索是增量博弈树搜索的唯一方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hizb1u/d_why_is_monte_carlo_tree_search_the_only_goto/</link>
      <description><![CDATA[我注意到，每当需要一种搜索​​方法，使其质量随推理时间计算而变化时，人们总是选择 MCTS，而从未考虑过其他类型的搜索方法。看看广泛使用的 MCTS 版本（例如 UCB 等），很明显很多启发式方法都是手工制作的。有没有关于更好的搜索方法的研究（也许是元学习的方法）？我觉得有很多机会可以改进手工制作的启发式过程。    提交人    /u/TommyX12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hizb1u/d_why_is_monte_carlo_tree_search_the_only_goto/</guid>
      <pubDate>Sat, 21 Dec 2024 01:41:38 GMT</pubDate>
    </item>
    <item>
      <title>XQ-GAN：用于自回归生成的开源图像标记化框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hiwl1m/xqgan_an_opensource_image_tokenization_framework/</link>
      <description><![CDATA[  由    /u/xternalz  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hiwl1m/xqgan_an_opensource_image_tokenization_framework/</guid>
      <pubDate>Fri, 20 Dec 2024 23:20:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 不再使用 Adam：初始化时调整学习率就是你所需要的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hivid1/r_no_more_adam_learning_rate_scaling_at/</link>
      <description><![CDATA[  由    /u/RobbinDeBank  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hivid1/r_no_more_adam_learning_rate_scaling_at/</guid>
      <pubDate>Fri, 20 Dec 2024 22:28:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI o3 在 ARC 奖挑战赛上获得 87.5% 高分</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hiq3tz/d_openai_o3_875_high_score_on_arc_prize_challenge/</link>
      <description><![CDATA[https://arcprize.org/blog/oai-o3-pub-breakthrough  OpenAI 的新 o3 系统 - 在 ARC-AGI-1 公共训练集上进行训练 - 在我们所述的公共排行榜 10,000 美元计算限制下的半私人评估集上取得了突破性的 75.7% 的成绩。高计算（172x）o3 配置得分为 87.5%。     提交人    /u/currentscurrents   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hiq3tz/d_openai_o3_875_high_score_on_arc_prize_challenge/</guid>
      <pubDate>Fri, 20 Dec 2024 18:20:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 更快的推理：torch.compile 与 TensorRT</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1himai0/r_faster_inference_torchcompile_vs_tensorrt/</link>
      <description><![CDATA[在我们对 LLama-7b、LLama-3-8b、mistral-v0.1、phi-3 和 phi-2 等模型的测试中，torch.compile 在易用性和性能方面优于 TensorRT。除非您需要 TensorRT 特定的功能或专门在 NVIDIA 的生态系统中工作，否则 torch.compile 是优化 PyTorch 模型的更好选择。 https://www.collabora.com/news-and-blog/blog/2024/12/19/faster-inference-torch.compile-vs-tensorrt/   由    /u/mfilion  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1himai0/r_faster_inference_torchcompile_vs_tensorrt/</guid>
      <pubDate>Fri, 20 Dec 2024 15:32:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 CPU 上快速生成句子 Transformer 嵌入，用于问答</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hijjjq/d_fast_sentence_transformer_embeddings_generation/</link>
      <description><![CDATA[我们有数百万个文档，我们希望通过直接问答的方式进行搜索（基于片段，而不是基于生成，就像下面截图中突出显示的片段，位于 Google 生成的位下方） https://preview.redd.it/g6njxb8q608e1.png?width=1866&amp;format=png&amp;auto=webp&amp;s=eb9f93bcb5676b8cbdf5cc21cc5df31b0d5d2064 因此，为此，我们必须为所有数百万个文档生成嵌入，将它们放入向量数据库中，并使它们在运行时可查询。 GPU 超出了我们的预算，因此我们必须仅在 CPU 上完成此操作。问题：  是否有任何 CPU 友好的嵌入模型或架构，使我们能够以相当快的速度（与 GPU 相当）提取我们集合中所有文档的句子嵌入（然后插入向量数据库） - 即使这意味着保持维数适中（只要片段答案质量不错）？ 是否有任何 CPU 友好的向量数据库，可以让我们在运行时几乎实时地推断出给定问题的片段，以实现高流量（就像谷歌在这里所做的那样）？如果瓶颈是 CPU 核心，那么我们假设我们有很多 CPU 核心，因为即使这样，它们也比 A100 或 H100 等 GPU 便宜一个数量级。 无论上述问题存在什么解决方案 - 它们会自动应用于多种语言，还是我们必须使用这些语言的语料库进行进一步的训练和再训练才能使其发挥作用？ 在 CPU 上生成二进制句子嵌入是否会更快（抵消正常的延迟）     提交人    /u/Attitudemonger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hijjjq/d_fast_sentence_transformer_embeddings_generation/</guid>
      <pubDate>Fri, 20 Dec 2024 13:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 超级连接</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hiiktb/r_hyperconnections/</link>
      <description><![CDATA[      TL;DR 残差流的更复杂、更高性能变体。 论文： https://arxiv.org/pdf/2409.19606 摘要：  我们提出了超连接，这是一种简单而有效的方法，可以作为残差连接的替代方案。这种方法专门解决了残差连接变体中观察到的常见缺点，例如梯度消失和表示崩溃之间的跷跷板效应。从理论上讲，超连接允许网络调整不同深度特征之间的连接强度并动态重新排列层。我们进行了实验，重点是大型语言模型的预训练，包括密集和稀疏模型，其中超连接比残差连接显示出显着的性能改进。在视觉任务上进行的其他实验也证明了类似的改进。我们预计，这种方法将广泛应用于各种人工智能问题，并能从中受益。  视觉摘要： 相信我，它没有乍一看那么复杂 视觉亮点： 最令人印象深刻的收益是使用 MoE 架构实现的，尽管 Dense Transformers 也得到了提升 超连接在一定程度上缓解了表示崩溃 扩展率是指将残差流拆分为 n 个独立的分量，每个分量都进行动态门控。每个 Transformer 块的输入都是这些组件的简单总和 SHC=静态门控，DHC=动态门控 计算开销可以忽略不计 https://preview.redd.it/238ex3emtz7e1.png?width=973&amp;format=png&amp;auto=webp&amp;s=ac12792a4d45f7bf6e91f767dd12f2134ec74083    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hiiktb/r_hyperconnections/</guid>
      <pubDate>Fri, 20 Dec 2024 12:18:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我不再认为反驳有什么意义。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hi9jt2/d_i_dont_see_a_point_in_rebuttals_anymore/</link>
      <description><![CDATA[这是一些沉思和一些咆哮的混合体，但根据标题，我只是觉得它没有任何意义。我最近从一次会议上得到了结果，我得到了两个正面评论和一个负面评论。然后写了一篇非常好的反驳，解决了对审稿人的根本误解（后来审稿人确实增加了他们的分数，所以我猜反驳是正确的？）。但结果是，元审稿人抓住了负面评论，甚至没有阅读针对该评论的反驳并拒绝了这篇论文。 如果有关各方_甚至不会阅读它们_，我反驳的意义何在？在这一点上，我很想把反驳阶段当作徒劳无功。也许我应该在第一阶段撤回论文，因为出现任何问题，而不是试图经历最终毫无意义的劳动的痛苦。   由    /u/pddpro  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hi9jt2/d_i_dont_see_a_point_in_rebuttals_anymore/</guid>
      <pubDate>Fri, 20 Dec 2024 02:18:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] GLIDER：使用可解释排名对 LLM 互动和决策进行评分</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hi443m/r_glider_grading_llm_interactions_and_decisions/</link>
      <description><![CDATA[  由    /u/Megixist  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hi443m/r_glider_grading_llm_interactions_and_decisions/</guid>
      <pubDate>Thu, 19 Dec 2024 21:50:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] chat-gpt 越狱提取系统提示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hi429q/d_chatgpt_jailbreak_to_extract_system_prompt/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hi429q/d_chatgpt_jailbreak_to_extract_system_prompt/</guid>
      <pubDate>Thu, 19 Dec 2024 21:48:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 ctx4k 训练的 RWKV-7 0.1B (L12-D768) 解决了 NIAH 16k，推断到 32k+，100% RNN 且无需注意，支持 100 多种语言和代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhshwp/r_rwkv7_01b_l12d768_trained_w_ctx4k_solves_niah/</link>
      <description><![CDATA[      大家好 :) 我们找到了最小的 RWKV-7 0.1B (L12-D768) 在长上下文中已经表现优异，同时是 100% RNN 且无需注意： https://preview.redd.it/rjcu9y73js7e1.png?width=1759&amp;format=png&amp;auto=webp&amp;s=b8fd2c8049b0886dbb87c715e120b1066b07b899 RWKV-7 World 0.1b 在多语言数据集上进行训练对于 1T 代币：https://preview.redd.it/cyvpr00mjs7e1.png?width=927&amp;format=png&amp;auto=webp&amp;s=01a98aa79be426d2d603fd5ae26ddad0ce1c0ee2 这些结果已经由社区测试：https://github.com/Jellyfish042/LongMamba  更多 RWKV-7 World 的评估。这是目前最好的多语言 0.1b LM :) https://preview.redd.it/a3yeedt8ks7e1.png?width=1497&amp;format=png&amp;auto=webp&amp;s=88cb8d9861a213a7be712acaca6546e7f63124ac 在 Gradio 演示中试用：https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-1 模型下载：https://huggingface.co/BlinkDL 训练它：https://github.com/BlinkDL/RWKV-LM 我也在训练 v7 0.4b/1b/3b。 社区正在致力于“转移” transformer 权重到 RWKV，并在几天前发布了一个 v6 32b 模型：https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1  RWKV-7 已经摆脱了线性注意力，成为了一个元上下文学习器，通过在每个 token 上的上下文梯度下降在上下文中对其状态进行测试时训练。 更多详细信息请参阅 RWKV dot com 网站（还有 30 多篇与 RWKV 相关的论文）。 https://preview.redd.it/x9tf1fnals7e1.png?width=722&amp;format=png&amp;auto=webp&amp;s=bf3f989e9736a38e7713ed41f17e1a2e5dd577b5  社区发现，一台微型 RWKV-6（带有 12m 个参数）可以通过非常长的 CoT 解决任何数独问题： https://github.com/Jellyfish042/Sudoku-RWKV 因为 RWKV 是一个 RNN，所以无论 ctxlen 如何，我们总是有恒定的速度和 vram。 例如，它可以解决&quot;世界上最难的数独&quot;拥有 400 万 (!) 代币 CoT: https://preview.redd.it/wo2vu9t3ns7e1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=32da05c2fb3e7622fde6b27e34c52795dba5d6c3    提交人    /u/bo_peng   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhshwp/r_rwkv7_01b_l12d768_trained_w_ctx4k_solves_niah/</guid>
      <pubDate>Thu, 19 Dec 2024 13:07:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</guid>
      <pubDate>Sun, 15 Dec 2024 16:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>