<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 01 Dec 2024 18:22:08 GMT</lastBuildDate>
    <item>
      <title>[D] 寻求有关生成无缝 360° 图像的机器学习模型的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h48950/d_seeking_advice_on_machine_learning_models_for/</link>
      <description><![CDATA[大家好， 我正在做一个涉及创建 360° 图像的项目，遇到了一些挑战。目标是生成无缝 360° 全景图，图像环绕处没有可见边缘或伪影。 我想知道是否有任何机器学习模型、技术或工具特别适合这项任务。具体来说，我正在寻找可以做到以下事情的东西：  确保 360° 图像边缘的连续性。 处理不同的纹理和图案而不会出现明显的扭曲。 在我的自定义数据集上进行训练或微调（如果需要）。  我已经探索过 StyleGAN 和扩散模型等 GAN，但我不确定它们是否可以开箱即用地处理边缘连续性问题。有没有人解决过类似的问题或知道一个好的起点？ 任何建议、资源或见解都将不胜感激！提前致谢！    提交人    /u/Deep_Land_4093   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h48950/d_seeking_advice_on_machine_learning_models_for/</guid>
      <pubDate>Sun, 01 Dec 2024 17:22:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 01 Dec 2024 16:00:30 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Noema – 声明式 AI 编程库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h46341/project_noema_a_declarative_ai_programming_library/</link>
      <description><![CDATA[       由    /u/Super_Dependent_2978  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h46341/project_noema_a_declarative_ai_programming_library/</guid>
      <pubDate>Sun, 01 Dec 2024 15:46:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 来源：为什么猎犬的 KG 表现优于 RD？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h447eu/r_sources_reasons_why_kg_outperformes_rd_in/</link>
      <description><![CDATA[是否有任何资料讨论为什么 Retriever 与 KG 配合使用效果比 RD 更好？我发现说它更好是非常直观的，因为在知识图中我们拥有更多的语义结构，并且可以有效地发现关系。在我看来，“图当然更丰富/更密集”，但在论文合作时，我突然意识到我无法证明这一说法。我找不到任何资料可以真正解释为什么会这样。 我得到的唯一资料是这个： https://arxiv.org/abs/2311.07509 去年在子版块中也有：https://www.reddit.com/r/LocalLLaMA/comments/17vy1bo/a_benchmark_to_understand_the_role_of_knowledge/ 所以我们只能说&amp;“我们证明我们的决定是正确的，因为 KG 比 RD 效果更好 [基准论文来源]&amp;; 我本来很想讨论为什么 KG 更适合，并给出关于信息密度、语义结构或相关实体的更好选择的论据。但我找到的只是一些文章，它们散布着荒谬的主张或指出了更简单/原生的实现，从技术上讲，这也可以通过 RD 实现。 有人可以告诉我资料来源吗？很想阅读关于更好性能原因的深入讨论。    提交人    /u/PopPsychological4106   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h447eu/r_sources_reasons_why_kg_outperformes_rd_in/</guid>
      <pubDate>Sun, 01 Dec 2024 14:17:17 GMT</pubDate>
    </item>
    <item>
      <title>ROI 图像增强 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h41z2x/augmentation_for_images_with_roi_d/</link>
      <description><![CDATA[我有一张带有 roi (x_min、y_min、x_max、y_max) 的图像。我想用 torchvison 进行随机翻转、旋转、倾斜、平移等。为了与增强图像匹配，您可以分别使用哪些不同的方式转换 roi？    提交人    /u/Brief_Papaya121   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h41z2x/augmentation_for_images_with_roi_d/</guid>
      <pubDate>Sun, 01 Dec 2024 12:11:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] Qwen-VL：用于理解、定位、文本阅读等的多功能视觉语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h40wms/r_qwenvl_a_versatile_visionlanguage_model_for/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h40wms/r_qwenvl_a_versatile_visionlanguage_model_for/</guid>
      <pubDate>Sun, 01 Dec 2024 10:59:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    <item>
      <title>最好的开源图像升级模型是什么？[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3qcon/whats_the_best_open_source_imageupscaling_model/</link>
      <description><![CDATA[      我正在使用Playground-v2.5-aesthetic制作一些用于 YouTube 缩略图的图像。我对结果非常满意： 1024x1024 火星基地基础图像。 但我希望图像为 1920x1080 像素，而我唯一的选择是 1024x1024 或 1280x720 像素。目前，我可以使用 Photoshop 的修饰功能达到 1920x1080 的图像分辨率： 1920x1080 的火星基地修饰图像。 这还可以，但是 Photoshop 的修饰功能是手动的，并且质量会下降相当明显。理想情况下，我会生成 1280x720 的图像，然后通过编程将其升级到 1920x1080。 我听说过以下模型：  Real-ERSGAN Waifu2 SRGAN  但在我深入研究其中任何一个之前，哪种开源模型通常被认为最适合实现这一目标？我有一台 RTX 3060 12GB VRAM。    提交人    /u/FPGA_Superstar   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3qcon/whats_the_best_open_source_imageupscaling_model/</guid>
      <pubDate>Sun, 01 Dec 2024 00:13:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] TIME-MOE：混合专家的十亿级时间序列预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3j1cm/p_timemoe_billionscale_time_series_forecasting/</link>
      <description><![CDATA[Time-MOE 是一个 2.4B 参数开源时间序列基础模型，使用 混合专家 (MOE) 进行零样本预测。 您可以在此处找到该模型的分析&gt;    提交人    /u/nkafr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3j1cm/p_timemoe_billionscale_time_series_forecasting/</guid>
      <pubDate>Sat, 30 Nov 2024 18:33:59 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 需要建议：被 COLING 2025 拒绝——我下一步应该关注哪个会议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3igva/discussion_advice_needed_rejected_from_coling/</link>
      <description><![CDATA[我被 COLING 2025 拒绝了，评审分数为 4、3、3。我正在修改手稿并寻求有关下一个最佳 NLP 会议的建议。有没有类似的顶级会议的建议？ 谢谢！    提交人    /u/Cold-Traffic-7586   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3igva/discussion_advice_needed_rejected_from_coling/</guid>
      <pubDate>Sat, 30 Nov 2024 18:08:01 GMT</pubDate>
    </item>
    <item>
      <title>[P]用Excel构建的完整变压器模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3hj6j/p_a_complete_transformer_model_built_in_excel/</link>
      <description><![CDATA[        提交人    /u/Revolutionary-Way290   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3hj6j/p_a_complete_transformer_model_built_in_excel/</guid>
      <pubDate>Sat, 30 Nov 2024 17:25:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] RNN 的现代用例？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h38ym2/d_modern_usecases_for_rnns/</link>
      <description><![CDATA[讨论可以分为两个方面。1）您认为，对于个人项目规模而言，哪些任务是您认为接近传统实现（LSTM、GRU）的 RNN 仍然是最佳的起点和终点？尤其是与 transformers 相比。 在小型时间序列预测设置中，我可以看到 GRU 可能比 Transformer 更方便，但我对输入是符号或度量序列但输出可能不是的任务也感兴趣。 主要目标是在有意义的数据集上使用 LSTM 和 GRU 变体（例如 minGRU），可能会做微小的莎士比亚，但它并没有让我感到温暖…… 2) 您是否认为存在顺序任务和设置，其中 RNN 不仅是根据我们的直觉更自然的选择，而且实际上与 Transformers 或 1D CNN 等相比，它是唯一在理论上或实验上可用的选择？    提交人    /u/Sad-Razzmatazz-5188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h38ym2/d_modern_usecases_for_rnns/</guid>
      <pubDate>Sat, 30 Nov 2024 09:22:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最快的物体检测模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h362dq/d_whats_the_fastest_object_detection_model/</link>
      <description><![CDATA[嗨，我正在做一个需要物体检测的项目。由于物体非常清晰，任务本身并不复杂，但速度至关重要。我研究过各种物体检测模型，似乎几乎每个人都声称自己是“最快的”。由于我将用 C++ 部署模型，所以没有时间移植和评估它们。 我之前测试过 YOLOv5/v5Lite/8/10，YOLOv5n 是最快的。我在 Oracle ARM 服务器上运行了一个简单的基准测试（详情见此处），它仅用 54ms 就处理了一张目标大小为 640 的图像。不幸的是，我当前项目的硬件性能明显较差，同时处理时间必须少于 20ms。我将使用量化和动态维度之类的方法来提高速度，但我必须先选择合适的模型。 有人遇到过类似的情况或专门针对速度测试过模型吗？有没有比 YOLOv5n 更快且值得一试的模型建议？    提交人    /u/Knok0932   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h362dq/d_whats_the_fastest_object_detection_model/</guid>
      <pubDate>Sat, 30 Nov 2024 06:00:40 GMT</pubDate>
    </item>
    <item>
      <title>[N][R] 模型就是食物：法学硕士的自动数据管理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2qmol/nr_models_are_what_they_eat_automatic_data/</link>
      <description><![CDATA[在 DatologyAI 上分享我们的最新成果。模型就是它们的食物，我们的使命是让训练大型模型的数据管理尽可能有效和简单。 通过结合多种方法，包括启发式过滤器、基于模型的过滤器、基于嵌入的管理、合成数据、目标分布匹配和混合比率，我们能够大幅提高训练效率、性能和推理效率。  与我们的基线和起始数据集（精确去重的 RedPajamav1）相比，我们可以：  以 7.7 倍的速度达到相同的性能（比 DCLM 快 3.4 倍） 在基准测试中将性能提高 8.5%（比 DCLM 提高 4.4%） 使用不到一半的参数训练模型，其性能比大型模型高出 5% 以上  请在此处查看我们的高级结果，如果您需要所有细节，请查看我们的 技术深度探究。    提交人    /u/arimorcos   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2qmol/nr_models_are_what_they_eat_automatic_data/</guid>
      <pubDate>Fri, 29 Nov 2024 17:15:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] Hinton 和 Hassabis 论乔姆斯基的语言理论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2mkye/d_hinton_and_hassabis_on_chomskys_theory_of/</link>
      <description><![CDATA[我刚进入这个领域，很想听听更多这方面的观点。我一直认为乔姆斯基是这方面的重要人物，但似乎 Hinton 和 Hassabis（后来）都不同意。这里：https://www.youtube.com/watch?v=urBFz6-gHGY（较长版本：https://youtu.be/Gg-w_n9NJIE） 我很想从 ML 和 CogSci 的角度来看待这个问题，以及更多支持/拒绝这种观点的来源。 编辑：拼写错误 + 添加来源。    提交人    /u/giuuilfobfyvihksmk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2mkye/d_hinton_and_hassabis_on_chomskys_theory_of/</guid>
      <pubDate>Fri, 29 Nov 2024 14:10:12 GMT</pubDate>
    </item>
    </channel>
</rss>