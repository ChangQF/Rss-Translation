<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Wed, 26 Feb 2025 01:17:27 GMT</lastBuildDate>
    <item>
      <title>[D]（不是添加）AI辅助编码的视觉接口 - 寻找开发人员反馈</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iyazps/d_not_an_add_a_visual_interface_for_aiassisted/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，大家接口（类似于虚幻引擎的蓝图系统），而不是传统的文本提示。  tldr：我希望看看我的想法是否对任何人都有用，我将非常感谢任何响应。 &lt; &lt; p&gt;  Google表单  问题 当前的AI编码工具需要文本管理上下文，使其难以通过文本进行管理建立较大的项目并可视化依赖关系。我发现自己正在努力维持跨多个互动的环境，并花费太多时间制作完美的提示。 解决方案 特征：   a拆分屏幕显示视觉图和生成代码 您连接视觉上连接的三种主要节点类型（类，函数，变量） li&gt; 节点之间的视觉依赖性映射 您描述了自然语言中的节点功能； AI生成代码  附加功能  使用运行时值检查的视觉调试 带有分支可视化的版本控制 &lt; &lt; li&gt;来自节点说明的自动文档 代码导入/导出系统  我希望您的反馈 这种方法可以解决任何问题您当前的开发工作流程？什么功能对您来说最有价值？ 感谢您的时间！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lomiag     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iyazps/d_not_an_add_a_visual_interface_for_aiassisted/</guid>
      <pubDate>Wed, 26 Feb 2025 00:51:42 GMT</pubDate>
    </item>
    <item>
      <title>[r]预测稀有语言模型行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iya3f7/r_forecasting_rare_language_model_behaviors/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    人类团队找到了一种方法来预测稀有的AI风险，然后使用幂律级缩放。这有助于尽早发现有害的响应或未对齐的行为，使其在实时之前更安全。  摘要：    标准语言模型评估可能无法捕获仅在部署量表上出现的风险。例如，模型可以在小规模的Beta测试期间产生安全的响应，但在部署时处理数十亿个请求时会透露危险的信息。为了解决这一问题，我们引入了一种方法，以预测跨数量级的潜在风险比我们在评估过程中测试的更多查询。我们通过研究每个查询的启发概率（查询产生目标行为的概率）来进行预测，并证明最大观察到的启发概率可以随着查询数量而扩展。我们发现，我们的预测可以预测各种不良行为的出现，例如协助用户进行危险的化学综合或采取寻求权力的动作 - 最多三个数量级的查询量。我们的工作使模型开发人员能够在大规模部署期间显现出现罕见的失败。   链接到论文： https://arxiv.org/abs/2502.16797  /p&gt;  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/seraschka     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iya3f7/r_forecasting_rare_language_model_behaviors/</guid>
      <pubDate>Wed, 26 Feb 2025 00:09:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] [R]猛禽实施 - 和LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iy6hh6/p_r_raptor_implementation_and_llm/</link>
      <description><![CDATA[在v1“&gt; https://arxiv.org/html/2401.18059v1 ）在COLAB上使用CPU A100 84GB RAM（相当强），但是在进食更多数据时会遇到超时（约50k的令牌运行良好 - 最多可达200​​K令牌：失败）。 特别是：我有10个数据文件，我是我是致力于将10个文件的所有内容串联成1个Python String变量-30k UTF -8字符和200K令牌。从那里，我将变量喂入建造一棵树。建造树需要花费数小时，但还不完整。 有抹布经验的人都可以分享其他想法来解决这个问题吗？ ，当建造抹布时，您是否有测试管道的经验，可以在运行抹布时检测框架的瓶颈？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/umpation_survey5044     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iy6hh6/p_r_raptor_implementation_and_llm/</guid>
      <pubDate>Tue, 25 Feb 2025 21:32:52 GMT</pubDate>
    </item>
    <item>
      <title>[D]视觉ML模型构建器是个好主意吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iy6boc/d_is_a_visual_ml_model_builder_a_good_idea/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在研究一个工具的想法，该工具使您可以通过拖动和连接块来构建ML模型。目的是使在不编写大量设置代码的情况下更轻松地设置模型和培训。 您可以设计模型，调整设置并在视觉上设置培训。但是我想知道，这样的事情实际上会有用，还是大多数人更喜欢编码？ 很想听听您的想法！在此处查看： https://ml-canvas.github.io/webpage  ！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_wind7503     [links]      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iy6boc/d_is_is_a_a_visual_ml_model_model_model_model_builder_a_good_good_idea/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iy6boc/d_is_a_visual_ml_model_builder_a_good_idea/</guid>
      <pubDate>Tue, 25 Feb 2025 21:26:10 GMT</pubDate>
    </item>
    <item>
      <title>[d]涉及量化，LLM/SLM的此主题的未来方向是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iy4spl/dregards_quantization_what_are_the_future/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我正在研究量化，想知道您对该主题的未来方向的想法。我在reddit上问，因为我很好奇与某人讨论，这是一个非常有趣的领域！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/uscnep     [link]    ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iy4spl/dregards_quantization_what_are_the_future/</guid>
      <pubDate>Tue, 25 Feb 2025 20:23:04 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]与F1得分挣扎并在不平衡的二元分类模型（染色质访问性）中进行回忆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iy15ry/discussion_struggling_with_f1score_and_recall_in/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iy15ry/discussion_struggling_with_f1score_and_recall_in/</guid>
      <pubDate>Tue, 25 Feb 2025 17:54:39 GMT</pubDate>
    </item>
    <item>
      <title>[P]训练一点（39m）语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iy0rra/p_train_a_little39m_language_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我今年开始越来越多地进入LLM，寻找资源一直很容易模型架构不足以完全掌握这些模型的训练方式。  由于我在一个地方无法找到最近的架构实现的任何代码，所以我自己制作了。 我的目标是帮助任何具有基本理解的人变压器体系结构，但想通过最近的建筑变化从头开始训练自己的模型。 （我在此过程中包括资源 +我自己的笔记） 所以我的努力​​是训练小语言模型的努力，即从头开始的39m参数模型，可以很好地交谈。 它在2XA100上进行了训练。 〜8b令牌上的2.5小时。 我计划在此项目中包含所有内容!!!!  现在它包括一个基本的类似Llama的架构。   -  rmsnorm而不是layernorm    - 旋转位置嵌入而不是绝对位置嵌入   -  swiglu激活而不是relu    - 分组查询注意力而不是多头注意   -  kV缓存的实现  todo包含   - 使用dpo   fineTuning    - 添加混合物专家（MOE）体系结构   - 以及更多 如果有人愿意为这个项目做出贡献，那将是很棒的。 请找到该项目这里： https://github.com/cohlem/lillm/lillm    我将其发布在r/ localllama 也是一个很好的回应。在此处发布以最大程度的可见性。  谢谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Royalmaterial9614     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iy0rra/p_train_a_little39m_language_model/</guid>
      <pubDate>Tue, 25 Feb 2025 17:38:45 GMT</pubDate>
    </item>
    <item>
      <title>[d]“反向传播：前向和向后分化[第2部分]”的视觉解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iy0d47/d_visual_explanation_of_backpropagation_forward/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 以前我共享了帖子的第1部分href =“ https://www.reddit.com/r/machinelearning/comments/1irs3gn/d%5c_visual%5c_explanation%5c_of%5c_backpropagatio n/“&gt; https://www.reddit.com/r/machinelearning/comments/1irs3gn/dver_visual/_explanation \ _of_of_backpropagation/ 。 这是 backpropagation上的第2部分 post。在本教程中，您将了解部分与总导数，向后传播。 最初，我很难理解 另外，如果您有任何问题，我很想获得有关此主题的一些高级或有趣材料的链接。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/madiyar     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iy0d47/d_visual_explanation_of_backpropagation_forward/</guid>
      <pubDate>Tue, 25 Feb 2025 17:22:10 GMT</pubDate>
    </item>
    <item>
      <title>[r] MUON对于LLM培训是可扩展的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixzj26/r_muon_is_scalable_for_llm_training/</link>
      <description><![CDATA[        tl; dr ： muon 是一种优化algorithm ，替代Adamw。该报告表明，与Adamw相比，它节省了大约一半的拖鞋，用于在39b代币上受过训练的1.5B LLM。   paper  ： https://arxiv.org/pdf/2502.16982    摘要：   最近，基于矩阵正交化的MUON优化器在训练小型语言模型方面表现出很强的结果，但是对较大模型的可伸缩性具有没有被证明。我们确定了两种至关重要的技术来扩展MUON：（1）增加重量衰减，（2）仔细调整参数更新量表。这些技术使MUON可以在大规模培训的情况下开箱即用，而无需进行超参数调整。缩放定律实验表明，与ADAMW相比，MUON具有约2倍的计算效率，并通过计算最佳培训。基于这些改进，我们引入了Moonlight，这是一种3B /16B参数的混合物（MOE）模型，该模型接受了训练有素的模型5.7吨代币使用MUON。与先前的模型相比，我们的模型改善了当前的帕累托前沿，通过更少的训练拖曳来取得更好的性能。我们开源我们的分布式MUON实现，这是内存最佳和沟通效率的。我们还释放了经过预定的，指导和中间检查点，以支持未来的研究。   视觉摘要：      视觉亮点：           https://preview.itd.it/bxekx1ntcble1.png?width=1095＆amp; format = png＆amp; auto = webpp＆s = 508a10fdea89d17a49e619e619b53f88622222260ebd9393939393939384449e619e619e     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sustledwaterMelon     [link]       [注释]  /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixzj26/r_muon_is_scalable_for_llm_training/</guid>
      <pubDate>Tue, 25 Feb 2025 16:48:27 GMT</pubDate>
    </item>
    <item>
      <title>[p]在视觉上进行文献综述，以便您可以看到关键思想的发展（公共beta）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixxqpr/p_do_literature_review_visually_so_you_can_see/</link>
      <description><![CDATA[            &lt;！ -  sc_off-&gt;     这是 https://arxiv-viz.ianhsiao.xyz &lt; /a&gt;试图帮助您从视觉上看到思想的发展。 该工具的目的是让其用户找出什么论文是关于视觉的，最初是在在这里！早期支持者的意见和功能请求对此工具的未来有很大的重视，请帮助我塑造它：）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1ixxqpr/p_do_do_literature_review_viseal_visaly_so_so_so_you_can_see/&gt; [link]   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixxqpr/p_do_literature_review_visually_so_you_can_see/</guid>
      <pubDate>Tue, 25 Feb 2025 15:33:35 GMT</pubDate>
    </item>
    <item>
      <title>[R]分析2024年400多个ML比赛</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixrxoq/r_analysis_of_400_ml_competitions_in_2024/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我运行mlcontests.com，一个网站，列出了来自多个平台的ML竞赛-Kaggle，drivendata，aicrowd，aicrowd，zindi等…… 我刚刚花了几个月的时间查看我在去年的比赛中找到的所有信息以及赢得解决方案。  我发现了去年发生的400多场比赛，以及其中70个获胜解决方案的信息。  一些亮点：    kaggle仍然是总奖金最大的平台，并且比其他平台拥有更大的用户群 - 尽管有超过十几个值得跟踪的其他平台，并进行了定期有趣的比赛和有意义的奖金。  竞争的增加100万美元+奖品池（ARC奖励， 人工智能与往年相比。一位获胜者使用Rust，两名使用R.   卷积神经网继续在计算机视觉竞赛中表现出色，在竞争赢家中仍然比基于变形金刚的视觉模型更为普遍。    pytorch的使用量大于tensorflow ，大​​约是9：1。没有发现任何竞争者在JAX或其他图书馆中实施神经网。   使用Automl软件包有一些竞赛冠军，似乎越来越有用。不过，通才自主的大师级特工的任何主张似乎还为时过早。   在语言/文本/序列相关的竞争中，定量是有效利用有限资源的关键。通常是4-，5或8位。 Lora/Qlora也经常使用，尽管并非总是如此。   促进梯度的决策树继续赢得许多表格/时间序列的比赛。他们通常会喜欢深度学习模型。据我所知，获奖者在2024年没有使用表格/时间序列的预训练基础模型。   开始看到更多的数据范围的极点摄入量，有7个获奖者在2024年使用Porars（从2023年的3次提高），而使用PANDAS则使用Porars。所有使用Polars的人仍然在代码的某些部分中使用了大熊猫。  就硬件而言，竞争获奖者几乎完全使用了NVIDIA GPU来训练他们的模型。一些人仅在CPU上接受培训，或者通过Colab使用了TPU。没有AMD GPU。 NVIDIA A100是获奖者中最常用的GPU。 100万美元以上的奖金泳池比赛中有两个是由使用8xH100节点进行培训的团队赢得的。不过，还有许多其他GPU：T4/P100（通过Kaggle笔记本电脑）或RTX 3090/4090/3080/3060等消费者GPU。一些花费了数百美元在云上计算以训练他们的解决方案。  一种新兴模式：使用生成模型创建其他合成训练数据以增强提供的训练数据。   完整报告中有更多详细信息，您可以在此处阅读（无付费墙）： https://mlconts.com/state-com/state-of-machine-learning-learning-competition--competition--2024?ref= MLCR    处理IMG XMM4YWG9H9LE1 ...   完整报告还具有：  深入了解ARC奖和AI数学奥林匹克运动会 赢得NLP/序列竞赛解决方案的概述 赢得解决方案中使用的Python软件包的细分（例如，各种相对普及梯度增强的树库）  如果您想支持这项研究，我将非常感谢您与其他可能会发现它有趣的人分享。您还可以查看我新发射的在线杂志， jolt Ml   - 在顶级ML会议和长阅读文章中提供新闻（到目前为止，还有更多！）。  感谢竞争获奖者分享了有关其解决方案的信息，也感谢竞争平台分享了有关比赛的高级数据。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/hcarlens   href =“ https://www.reddit.com/r/machinelearning/comments/1ixrxoq/r_analsisy_of_400_ml_ml_competitions_in_2024/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixrxoq/r_analysis_of_400_ml_competitions_in_2024/</guid>
      <pubDate>Tue, 25 Feb 2025 10:28:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] CVPR 2025结束决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixpu28/d_cvpr_2025_final_decision/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  亲爱的社区成员， 标题所建议的，此线程适用于所有等待CVPR的25个结果的人。我敢肯定，你们现在都感觉到肚子里的蝴蝶。因此，让我们在整个过程中互相支持并讨论结果。现在不到24小时，我期待在此线程中进行令人兴奋的互动。  P.S。我的评分为4,3,3，平均信心为3.67。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/stantheta   href =“ https://www.reddit.com/r/machinelearning/comments/1ixpu28/d_cvpr_2025_final_decision/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixpu28/d_cvpr_2025_final_decision/</guid>
      <pubDate>Tue, 25 Feb 2025 07:57:20 GMT</pubDate>
    </item>
    <item>
      <title>[d]为GRPO设计奖励功能：超越单人答案任务到长形响应？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixj59s/d_designing_a_reward_function_for_grpo_moving/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿 r/machinelearning ！！ p&gt; 我一直在用GRPO微调一个小的LLM，以完成单个正确答案的任务（例如，诸如求解3x + 5 = 20的数学问题）。在这里，我使用了一个直接的奖励功能： 如果最终答案与地面真相相匹配，则为0。这效果很好，但是现在我坚持将其推广到其他域中的开放式，长格式的问题，而没有单一的“正确”。回答。  在这种情况下，设计奖励的鲁棒策略是什么？   我已经研究了BertScore和LLM-AS-A-Gudge等指标（例如GPT-4评分相干），但我不确定如何平衡自动指标与潜在偏见。    纸张，工具或实验中的课程将不胜感激！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aadityaura     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixj59s/d_designing_a_reward_function_for_grpo_moving/</guid>
      <pubDate>Tue, 25 Feb 2025 01:34:34 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iwdbgs/d_simple_questions_thread/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 23 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      对于那些寻找工作的人请使用此模板  &lt; p&gt;想要被录用：[位置]，薪水期望：[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简短概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，这个社区是适合有经验的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>