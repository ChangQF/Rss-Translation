<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sun, 03 Mar 2024 15:12:29 GMT</lastBuildDate>
    <item>
      <title>[D]Agents+ LLM 正在生产中</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b5j322/dagents_llm_in_production/</link>
      <description><![CDATA[大家好，  我注意到 Agents+LLM 最近越来越受欢迎。   任何人都可以分享哪些 Agentic 框架正在生产环境中使用吗？  你们中有人将 RAG 框架与代理结合使用吗？  此外，您在使用代理框架时遇到了哪些典型的生产问题？   分享您的想法和见解   由   提交/u/Electrical_Study_617   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b5j322/dagents_llm_in_production/</guid>
      <pubDate>Sun, 03 Mar 2024 14:57:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当前医学图像生成模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b5irmm/d_current_models_for_medical_image_generation/</link>
      <description><![CDATA[我正在寻找一些用于医学图像生成的最新架构或模型。 因为它是医学图像数据很少（所以可能不是扩散），并且图像应该清晰，以便清楚地显示病理的存在（所以可能不是普通的 VAE）。 GAN 有许多不同的风格，我发现了一些适用于我的情况，但我想知道我是否错过了任何东西。 某种潜在编码对于下游任务也很有用，因此编码器-解码器架构将是理想的，但我已经取得了一些成功与 GAN 反转。   由   提交 /u/idontcareaboutthenam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b5irmm/d_current_models_for_medical_image_generation/</guid>
      <pubDate>Sun, 03 Mar 2024 14:43:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何实际理解变压器？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b5idv3/d_how_to_understand_practically_transformers/</link>
      <description><![CDATA[我从 2023 年开始研究 Transformer，但我无法从头开始编写 Transformer，理解这个架构的路径是什么？   由   提交 /u/Humble-Rise6029    reddit.com/r/MachineLearning/comments/1b5idv3/d_how_to_understand_practically_transformers/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b5idv3/d_how_to_understand_practically_transformers/</guid>
      <pubDate>Sun, 03 Mar 2024 14:26:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 假新闻分类时如何有效利用日期属性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b5hyul/d_how_to_effectively_use_date_attribute_while/</link>
      <description><![CDATA[我正在研究假新闻分类。我想使用所有四个属性：标题、文本、主题和日期，因为数据集中的所有属性都提供有意义的信息。然而，我对如何有效地使用日期属性有点困惑，因为它是像 2017-11-30 这样的数字格式。我试图在将所有四个属性输入 LSTM 模型之前将它们连接起来。   由   提交/u/Kindly-Song5246  /u/Kindly-Song5246 reddit.com/r/MachineLearning/comments/1b5hyul/d_how_to_efficiently_use_date_attribute_while/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b5hyul/d_how_to_effectively_use_date_attribute_while/</guid>
      <pubDate>Sun, 03 Mar 2024 14:06:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2024 年 2 月研究论文 — LoRA 的潜在继任者、小型微调 LLM 与通才 LLM 以及透明的 LLM 研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b5hvmh/p_research_papers_in_february_2024_a_potential/</link>
      <description><![CDATA[ 由   提交/u/seraschka  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b5hvmh/p_research_papers_in_february_2024_a_potential/</guid>
      <pubDate>Sun, 03 Mar 2024 14:02:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何发现或推测“奖励黑客”现象？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b5hrjy/d_how_to_detect_or_speculate_the_rewardhacking/</link>
      <description><![CDATA[      我正在阅读 DeepMind 论文“WARM: On the Benefits of Weight Averaged Reward”模型”。论文讨论的是奖励黑客现象。 论文中，作者使用 KL-奖励曲线来检测奖励黑客现象，表示奖励开始减少，从而发生奖励黑客行为。但是，之前的论文如 https://arxiv.org/pdf/2312.09244.pdf 或 https://arxiv.org/pdf/2312.09244.pdf通常使用两种奖励模型来检测奖励黑客：代理奖励和真实奖励。策略模型是在代理奖励下更新的，所以当KL增加时，代理奖励也会增加。当真实奖励开始减少时，奖励黑客现象就会发生，这被视为检测器。 因此，由于 WARM 只显示奖励以增加开始并以减少结束（这是代理奖励和因此还不够），我认为它不能显示奖励黑客现象的发生。希望您的意见。 https： //preview.redd.it/4ajcprcjk4mc1.jpg?width=824&amp;format=pjpg&amp;auto=webp&amp;s=756876807aa48d9fffe284f1f51f6ebfd6d877e6  /u/zetiansss   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b5hrjy/d_how_to_detect_or_speculate_the_rewardhacking/</guid>
      <pubDate>Sun, 03 Mar 2024 13:57:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 需要帮助微调法学硕士以充当人工智能教师（类似于哈佛大学的 CS50 聊天机器人）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b5gyy3/p_need_help_finetuning_a_llm_to_act_as_an_ai/</link>
      <description><![CDATA[我正在开展一个项目，旨在创建一个模型，该模型可以在编程入门课程中充当学生的 AI 老师。模型不应该为他们编写代码，而应该指导他们并消除他们的困惑。我想为此目的微调大型语言模型，但我不知道如何去做。  我有一些问题希望您能帮助我： ​  我应该使用哪个法学硕士？ 。  我应该如何准备我的数据集？     由   提交/u/Shaheer_Humayun   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b5gyy3/p_need_help_finetuning_a_llm_to_act_as_an_ai/</guid>
      <pubDate>Sun, 03 Mar 2024 13:17:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新的（2023-2024）ICLR、NIPS、ICML论文和训练时间最短的基准列表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b5gs7w/r_list_of_new_20232024_iclr_nips_icml_papers_and/</link>
      <description><![CDATA[让我们（作为研究社区）列出训练时间最短的 ICLR、NIPS、ICML 论文和基准。由于当前的计算限制和团队努力，不可能与行业和其他拥有更多资金的实验室竞争。   由   提交 /u/Noprocr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b5gs7w/r_list_of_new_20232024_iclr_nips_icml_papers_and/</guid>
      <pubDate>Sun, 03 Mar 2024 13:08:11 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] [研究] 机器学习问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b5g6x3/discussion_research_questions_machine_learning/</link>
      <description><![CDATA[亲爱的 ML 社区， 一段时间以来我收到了一些问题，我一直在进行研究，但找不到所以我已经到了需要询问这些人来看看是否有人对此有话要说的地步。如果您对其中一个问题有话要说，请回答。 所有这些问题都是在与 NLP 不同的主题（特别是动画生成）中设计和构建大型模型的背景下完成的：  有没有办法粗略估计dataset_size、model_size和accuracy之间的关系？与经验方法有何不同？ （由于我们正在讨论大型模型，因此我认为迭代多个尺寸以凭经验理解这些关系的成本太高） 构建大型模型时。具体增加什么，层数，隐藏暗淡或头数？我对hidden_​​dim 大小特别好奇。我不认为你可以通过按照你想要的方式增加维度来增加价值。为了简单起见，我们假设我的令牌暗淡大小是 1024。我认为如果将隐藏暗淡大小增加到该数字之上，您将浪费空间来存储信息。应该有一个从令牌到编码向量的转换，以保持或减少维度（以提取有价值的特征）。因此，从令牌维度增加维度是对参数的浪费。  感谢您给出您的想法   由   提交/u/Stefano939393  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b5g6x3/discussion_research_questions_machine_learning/</guid>
      <pubDate>Sun, 03 Mar 2024 12:36:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 模拟退火和梯度下降</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b5fypl/d_simulated_annealing_and_gradient_descent/</link>
      <description><![CDATA[首先，如果我的问题无关紧要，我想表示歉意。 我是数据科学领域的初学者我一直在使用梯度下降来找到函数的最小值。 （我使用的是python） 显然，我遇到了局部最小值问题，并试图找到避免它的方法，并找到了模拟退火。 有没有一种方法可以将两者结合起来达到全局最小值？ 提前致谢   由   提交 /u/Due-Outside-8526   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b5fypl/d_simulated_annealing_and_gradient_descent/</guid>
      <pubDate>Sun, 03 Mar 2024 12:23:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求建议：持续强化学习和元强化学习研究社区</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b5fmgj/d_seeking_advice_continualrl_and_metarl_research/</link>
      <description><![CDATA[我对 RL（连续 RL、元 RL、变压器）对超参数的敏感性和大量的训练时间越来越感到沮丧（我讨厌 RL 之后5年博士研究）。这在元强化学习连续强化学习中尤其成问题，其中一些基准要求长达 100 小时的训练。这使得优化超参数或快速验证新想法的空间很小。考虑到这些挑战以及我准备更深入地探索数学理论，包括学习所有可用的在线数学课程，采用基于证明的方法，以避免无休止的等待和训练循环，我对 2024 年密切相关的人工智能研究领域趋势感到好奇强化学习，但最多只需要 3 个小时的训练时间。有什么建议吗？   由   提交 /u/Noprocr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b5fmgj/d_seeking_advice_continualrl_and_metarl_research/</guid>
      <pubDate>Sun, 03 Mar 2024 12:03:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何将经过训练的 LORA 适配器部署到 Huggingface 中的 ChatUI？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b595y8/p_how_do_i_deploy_my_trained_lora_adapter_to_a/</link>
      <description><![CDATA[我在 Mistral8x7b 上有一个训练有素的 LORA 适配器，并上传到 Huggingface 上。如何将其部署到 HuggingchatUI 界面，使其看起来像这样？ Zephyr Gemma Chat - HuggingFaceH4 1 的拥抱面部空间。 I我这么问是因为到目前为止我看到的教程和指南仅适用于非适配器的模型。 谢谢。   由   提交/u/portmanteau98  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b595y8/p_how_do_i_deploy_my_trained_lora_adapter_to_a/</guid>
      <pubDate>Sun, 03 Mar 2024 05:15:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] ArXiv 机器学习景观</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4txb8/p_arxiv_machine_learning_landscape/</link>
      <description><![CDATA[ 由   提交/u/lmcinnes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4txb8/p_arxiv_machine_learning_landscape/</guid>
      <pubDate>Sat, 02 Mar 2024 17:42:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您的 LLM 技术堆栈在生产中是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4sdru/d_what_is_your_llm_tech_stack_in_production/</link>
      <description><![CDATA[想知道每个人都使用什么来实现 LLM 支持的应用程序以供生产使用，以及您对这些工具和建议的体验。  这就是我为金融和资本市场用户构建的一些 RAG 原型所使用的。 预处理\ETL：非结构化.io + Spark、Airflow 嵌入模型： Cohere Embed v3 以前使用 OpenAI Ada，但 Cohere 对于我的用例来说具有明显更好的检索召回率和精度。还探索其他开放权重嵌入模型 矢量数据库： Elasticsearch 以前但现在使用 Pinecone LLM： 经历了相当长的一段时间很少包括托管和自托管选项。在原型设计过程中早期使用 gpt4，然后切换到 gpt3.5-turbo，以获得更易于管理的成本并最终开放权重模型。  现在使用由 vLLM 自托管的经过微调的 Llama2 70B 模型 LLM 框架：最初从 Langchain 开始，但发现扩展为应用程序很麻烦变得更加复杂。在某个时候尝试在 LlamaIndex 中实现它只是为了学习，但发现它同样糟糕。回到 Langchain，现在我正在用自己的逻辑替换它 其他人都使用什么？ 编辑：正确的型号 Llama2 70B   由   提交/u/gamerx88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4sdru/d_what_is_your_llm_tech_stack_in_production/</guid>
      <pubDate>Sat, 02 Mar 2024 16:37:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>