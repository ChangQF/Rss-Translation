<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Fri, 07 Mar 2025 12:33:17 GMT</lastBuildDate>
    <item>
      <title>[d]您如何将本地/本地培训和规模缩小到云？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5lkw9/d_how_do_you_orchestrate_onpremlocal_training_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在为一家专门从事kubernetes的公司工作，我试图更好地了解ML研究人员和工程师如何使用本地/本地GPU和公共云资源的混合。   似乎是一种常见的模式来进行“在台式下进行较大的gpus”，以进行较大的培训，然后进行更大的训练，然后进行范围或培训，以便进行范围或范围，以弥补云或云量。但是，在实践中设置的设置有多普遍？ 如果您使用这样的混合方法： 您是否有自动化的工作流程以在本地和云环境之间移动？ 哪些工具或平台对您有效吗？在这些情况下，像Zenml这样的MLOPS工具可以帮助？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ml_yegor     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j5lkw9/d_how_do_do_do_you_orchestrate_onpremlocal_training_and/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5lkw9/d_how_do_you_orchestrate_onpremlocal_training_and/</guid>
      <pubDate>Fri, 07 Mar 2025 11:41:47 GMT</pubDate>
    </item>
    <item>
      <title>[r]杂交：结合术前和后场，以进行更稳定和有效的变压器训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5l9mk/r_hybridnorm_combining_prenorm_and_postnorm_for/</link>
      <description><![CDATA[I&#39;ve been experimenting with various normalization techniques in transformers lately, and this new HybridNorm approach seems like a particularly elegant solution to the speed vs. stability tradeoff. The core idea is surprisingly simple but effective: use Layer Normalization after attention sublayers (where stability matters most) and use RMS Layer Normalization everywhere else (where we can benefit from its computational efficiency). Key technical points: - The post-attention sublayer is much more sensitive to normalization type than other positions - Using RMSNorm in non-critical positions reduces computation without compromising stability - Implementation requires minimal code changes to existing transformer architectures - HybridNorm delivers 13-17% training speedup compared to standard LayerNorm - Performance跨基准任务（胶水，小队，机器翻译）维护 - 在不同的模型量表（0.1b至3B参数）上始终如一地工作 - 与仅编码器，仅解码器和编码器decoder-decoder Architectures  兼容。 13-17％的加速可能听起来并不革命性，而是应用于大规模训练，这是零质量折衷的大量计算节省。本文还暗示了一个更广泛的机会 - 仔细分析哪些组件需要完全稳定，而我们可以优化速度。   特别有用的是该技术如何与现有架构无缝集成。您无需重新设计模型 - 只需在特定位置交换标准化层即可。从本质上免费获得提高效率的一个难得的案例。“  发现变压器中不同位置具有不同稳定性要求的发现为为什么在数学上发生这种情况的情况都打开了有趣的问题。我很想看到后续工作更深入地探索这一现象。  tldr：杂交从策略上结合了变压器模型中的分层和rmsnorm，将注意力越来越稳定的分层放置在注意力下的分子和更快的rmsnorm之后。这种简单的更改可提供13-17％的速度，而不会影响模型质量。 全部总结。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5l9mk/r_hybridnorm_combining_prenorm_and_postnorm_for/</guid>
      <pubDate>Fri, 07 Mar 2025 11:21:14 GMT</pubDate>
    </item>
    <item>
      <title>[D]学习如何与LLM构建的最佳资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5jlae/d_best_resources_to_learn_how_to_build_with_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最佳资源或课程是什么，特别是针对在数据科学领域中拥有丰富知识的人，精通一般的ML/DL原则，但是现在希望进入LLMS世界？    &lt;！ -  sc_on--&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j5jlae/d_best_resources_to_to_lealed_how_to_build_with_with_with_llms/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j5jlae/d_best_resources_to_to_to_lealed_how_to_build_build_with_with_lls/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5jlae/d_best_resources_to_learn_how_to_build_with_llms/</guid>
      <pubDate>Fri, 07 Mar 2025 09:25:00 GMT</pubDate>
    </item>
    <item>
      <title>[d]使用BERT作为T5中的编码器的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5gtie/d_impact_of_using_bert_as_the_encoder_in_t5/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果已经对Bert编码的编码器组成的编码器替换为bert编码器，考虑到BERT已经在较大的语料库上进行了训练？  Bertoder，Bertoder，Bertoder，在较大的Corpus上进行了较大的Corpus，可以为T5模型带来丰富的上下文模型。这可能会提高某些任务的性能，尤其是那些涉及理解和生成相干文本的任务。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ashydunes     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5gtie/d_impact_of_using_bert_as_the_encoder_in_t5/</guid>
      <pubDate>Fri, 07 Mar 2025 06:03:40 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] NLP应用程序中的质量保证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5ac22/discussion_quality_assurance_in_nlp_apps/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 我正在考虑在基于ML/NLP的应用程序中对主人进行质量保证的研究。除了功能性测试外，我想知道对非功能性测试的更大话题。在传统软件开发人员中，我们有诸如可访问性，可用性，安全性和更多类型的测试之类的东西。但是对于ML/NLP应用程序，我们应该看什么？ 超越准确性和表现，道德考虑，可用性和安全性，但是我觉得还有更多可以探索的东西。 很想听听您的想法和经验！  cheers！提交由＆＃32; /u/u/abk9035     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5ac22/discussion_quality_assurance_in_nlp_apps/</guid>
      <pubDate>Fri, 07 Mar 2025 00:11:47 GMT</pubDate>
    </item>
    <item>
      <title>[r] [p] SLM建议求解与声音单词错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j57nyy/r_p_slm_recommendation_to_solve_soundalike_word/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我需要一个可以解决声音单词错误的小语言模型，例如：\＆nbsp; \ \＆nbsp;＆nbsp;在早期，国王将赌注付诸实践，以适用于小小的实例\ i，对于小型型号的rob（e.G. x86（例如原子）。我尝试了2到4 GB的重量范围中的许多，但是到目前为止，除非我开始提供这些提示（例如挑选一个错误的单词并要求它考虑其他可能性），我还没有找到可以完成这项工作的一种。任何建议/建议欢迎  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jbrower888    href =“ https://www.reddit.com/r/machinelearning/comments/1j57nyy/r_p_p_slm_slm_recommendation_to_solve_solve_soundalike_word/&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j57nyy/r_p_slm_recommendation_to_solve_soundalike_word/</guid>
      <pubDate>Thu, 06 Mar 2025 22:11:35 GMT</pubDate>
    </item>
    <item>
      <title>[P]排名算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j55rj8/p_ranking_algorithm/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在尝试阅读有关standign算法的相关研究论文，并特别使用XGBranker构建了一个案例研究。您能帮我良好的资源吗？研究论文/良好的案例研究和学习材料。感谢任何帮助。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/inapprep101     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j55rj8/p_ranking_algorithm/</guid>
      <pubDate>Thu, 06 Mar 2025 20:51:16 GMT</pubDate>
    </item>
    <item>
      <title>[d]如何在多输出回归问题中限制输出？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4v8r9/d_how_to_constrain_outputs_in_a_multioutput/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在处理一个多出输出回归问题，我需要对输出进行约束。具体来说，我需要说两个预测值等于给定的输入特征：y1+y2 = xi。任何指导都将不胜感激！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/gigi-25     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4v8r9/d_how_to_constrain_outputs_in_a_multioutput/</guid>
      <pubDate>Thu, 06 Mar 2025 13:18:25 GMT</pubDate>
    </item>
    <item>
      <title>[r]启用语言模型自我完善的认知行为：分析验证，回溯，子目标和后退链接</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4szaa/r_cognitive_behaviors_that_enable_language_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在探索LLM可以提高自己的推理能力，而Google研究的这篇新论文确定了四种特定的认知行为，这些行为能够在推理模型中进行自我改进，而无需进行其他培训，而无需其他培训。 Double-checking: Models review their work, looking for calculation errors or logical inconsistencies Seeking background knowledge: Models identify information gaps and retrieve missing knowledge Step-back reasoning: Models approach problems from a higher level of abstraction before diving into details Heuristic放松：模型放弃了无效的初始方法，并尝试替代解决方案  这些结果在多个推理领域跨多个推理领域令人信服：  在数学推理（GSM8K）上测试（GSM8K），常识性推理（策略QA）和符号推理（最后字母串联）                    将多种行为结合起来产生了最强的改进 双重检查对数学推理的特殊价值   在GPT-4和Mistral    （我认为这项研究）的好处中出现了好处，我认为这项研究是有价值的。首先，它提供了具体的，可实施的技术，可以提高现有模型中的推理能力，而无需进行体系结构的变化。其次，它通过在LLM中形式化类似人类的元认知策略来弥合认知科学和AI。最后，它提出了一种模块化方法的改进方法 - 而不是将推理视为一种整体能力，我们可以将其分解为可以单独增强的特定认知行为。  tldr：研究人员确定了四个认知行为（确定了四个认知行为（识别双重训练，寻求知识，较高的推理），并没有启用较高的推理，以提高他们的启用模型，以提高他们的启用自身的启用）。这些类似人类的策略可大大提高数学，常识性和符号推理任务的性能。  纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j4szaa/r_cognitive_behaviors_that_enable_enable_language_model/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4szaa/r_cognitive_behaviors_that_enable_language_model/</guid>
      <pubDate>Thu, 06 Mar 2025 11:00:08 GMT</pubDate>
    </item>
    <item>
      <title>[d] ML基础设施不必吮吸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4k7ww/d_ml_infrastructure_doesnt_have_to_suck/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我们多年来一直在进行数据科学和ML。迭代我们的工具已有几年之后，我们终于解决了一些我们满意的工具。因此，通常您会看到很难使用的炒作工具。 我不是帖子的作者。但是我和那些写这篇  &lt;！ -  sc_on-&gt;＆＃32;的家伙一起工作。提交由＆＃32; /u/u/brianattwell     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4k7ww/d_ml_infrastructure_doesnt_have_to_suck/</guid>
      <pubDate>Thu, 06 Mar 2025 01:44:07 GMT</pubDate>
    </item>
    <item>
      <title>[P]培训1.5B的生锈编码器LM使用加固学习（GRPO）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4irp9/p_training_a_rust_15b_coder_lm_with_reinforcement/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，我们想在一个任务上测试GRPO，而不仅仅是通过使用GSM8K来优化小学数学课程的推理。认为我们是否可以使用Rust的“货物”工具作为反馈来改善编码小语言模型会很有趣。我们为编译器，Linter设计了一些奖励功能，如果代码通过了单位测试。 在15K示例的培训时期，1.5B型号从将构建的时间传递到〜80％到〜80％，并将单位测试通过22％到37％的时间。第一次刺伤的结果令人鼓舞。接下来尝试一些较大的模型会很有趣。 我概述了下面的所有详细信息和代码，您有兴趣！ 博客文章： https://wwwww.oxen.ai/blog/blog/blog/blog/blog/blog/training-a-rust-a-rust-1-5b-coder-1-5b-coder-lm-with-with-reecrecement cary  https://github.com/oxen-ai/oxen-ai/grpo-with-with-with-cargo-feedback/tree/main/main/main/main  提交由＆＃32; /u/u/u/fallmindless3563     [links]      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j4irp9/p_training_a_rust_15b_15b_coder_lm_with_with_with_with_with_with_reinforection/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4irp9/p_training_a_rust_15b_coder_lm_with_reinforcement/</guid>
      <pubDate>Thu, 06 Mar 2025 00:33:15 GMT</pubDate>
    </item>
    <item>
      <title>[r]弧线的34.75％，没有训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4dw38/r_3475_on_arc_without_pretraining/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://iliao2345.github.io/blog_posts/arc_agi_without_pretraining/arc_agi_without_pretraining.html    我们的解决方案，我们将其命名为CompressArc，遵守以下三个限制：  否审计；模型在推理时间内随机初始化和训练。 无数据集；一个模型仅在目标弧形难题上训练并输出一个答案。 在大多数情况下，没有搜索（即梯度下降）。   ，尽管有这些限制，但CompressArc在培训中达到34.75％的培训，在评估集中为34.75％，在每次评估设置中，我们的知识为407分钟。求解ARC-AGI的神经方法，其中训练数据仅限于目标难题。    tl; DR对于每个难题，他们在推理时从头开始训练一个小的神经网络。尽管训练集非常小（三个数据点！）通常仍然可以推广到答案。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j4dw38/r_3475_on_arc_arc_arc_without_pretretrain/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4dw38/r_3475_on_arc_without_pretraining/</guid>
      <pubDate>Wed, 05 Mar 2025 21:02:53 GMT</pubDate>
    </item>
    <item>
      <title>安德鲁·巴托（Andrew Barto）和理查德·萨顿（Richard Sutton）是2024 ACM A.M.图灵（Turing）因发展强化学习的概念和算法基础而奖。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j42icj/andrew_barto_and_richard_sutton_are_the/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/mtgtraner     [link]&gt; [link]&gt; [link]&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j42icj/andrew_barto_and_richard_sutton_are_the/</guid>
      <pubDate>Wed, 05 Mar 2025 13:00:25 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1hc0o/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Mar 2025 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>