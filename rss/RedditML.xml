<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 28 Jan 2025 01:13:28 GMT</lastBuildDate>
    <item>
      <title>[P]在 Numpy 上实现 GPT1</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibohv3/p_implement_gpt1_on_numpy/</link>
      <description><![CDATA[大家好， 这是我关于在 Numpy 上实现 GPT1 的博客文章：https://mburaksayici.com/blog/2025/01/27/GPT1-Implemented-NumPy-only.html 我很高兴收到批评/反馈。    提交人    /u/mburaksayici   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibohv3/p_implement_gpt1_on_numpy/</guid>
      <pubDate>Tue, 28 Jan 2025 00:12:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有人试过写一份没有参考部分的 CVPR 反驳吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibllko/r_anyone_tried_writing_a_cvpr_rebuttal_without_a/</link>
      <description><![CDATA[我正在准备 CVPR 反驳，由于只允许一个 PDF，我正在考虑删除参考部分。是否可以在论文中引用引文而不在反驳中再次明确列出它们？我知道我不需要引用新论文。 以前有人处理过这种情况吗？如果在反驳中看不到单独的参考部分，审稿人会觉得奇怪或不方便吗？ 寻求建议或见解！    提交人    /u/Training-Adeptness57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibllko/r_anyone_tried_writing_a_cvpr_rebuttal_without_a/</guid>
      <pubDate>Mon, 27 Jan 2025 22:07:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Deepseek R1 精简版本之间的审查差异</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibkckg/d_censorship_differences_in_deepseek_r1_between/</link>
      <description><![CDATA[      一些帖子正在流传Reddit 和其他平台上的提示都显示了 Deepseek R1 中的审查制度。我尝试过它们，但发现了一些有趣的差异，Llama 8B 的限制较少。 （不过，很难说这些差异会持续多久） 我检查了 Llama (8B) 和 Qwen (7B) Distilled 版本。 https://preview.redd.it/rso0bxndrlfe1.png?width=417&amp;format=png&amp;auto=webp&amp;s=592e5eda5568d0b2fadfb19df313946dbbbf9cab 这是不同型号的相同问题： Llama 8B 蒸馏 Qwen 7B 蒸馏 Qwen 7b 蒸馏的审查答案每次都会变化。未经审查的 Llama 8B 似乎很稳定。 话虽如此，Llama 8B 版本仍然显示出一些审查制度和其他问题： Llama 8B destiled    提交人    /u/Total_Firefighter_59   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibkckg/d_censorship_differences_in_deepseek_r1_between/</guid>
      <pubDate>Mon, 27 Jan 2025 21:16:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] Deepseek R1 究竟是如何大幅降低训练成本的？我读到的大多数帖子都是关于它的性能、强化学习、思路链等，但不清楚模型训练成本是如何大幅降低的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibijhg/d_how_exactly_did_deepseek_r1_achieve_massive/</link>
      <description><![CDATA[  由    /u/eyio  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibijhg/d_how_exactly_did_deepseek_r1_achieve_massive/</guid>
      <pubDate>Mon, 27 Jan 2025 20:02:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们如何存储/流式传输 LLM 嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibe0bm/d_what_do_people_do_for_storingstreaming_llm/</link>
      <description><![CDATA[对于一个学术项目，我想计算每个标记的嵌入，将它们存储在磁盘或内存中，并将它们流式传输以进行快速实验，同时微调模型（比 LLM 小得多）。 有哪些库（db？）、数据结构和最佳实践？一些注意事项：  希望最大限度地减少嵌入计算（成本）。 嵌入是 ~1k 32 位浮点数。 序列通常约为 20-500 个标记。 在模型训练中流式传输预计算嵌入以进行微调。 完整数据集约为 500k 个短语，磁盘上约 4TB（未压缩）。 我的应用程序不存在量化模型。 一些“有意义”的数据集子集可以放入内存（几 GB）。 最终共享数据集以供研究。 开源友好 寻找更标准化与新颖的数据库解决方案（主要是为了长寿）     提交人    /u/LetsTacoooo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibe0bm/d_what_do_people_do_for_storingstreaming_llm/</guid>
      <pubDate>Mon, 27 Jan 2025 17:02:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] FP/OTS 游戏的随机生成地图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib8e5k/d_randomly_generated_maps_for_fpots_games/</link>
      <description><![CDATA[我对使用随机生成地图的游戏感兴趣。有 Starfield 和 Bethesda 在未来游戏中使用它们。还有其他使用 Voxel 引擎的游戏，例如 Valheim 或 No Man&#39;s Sky。我对 Starfield 类型的随机生成地图感兴趣。目的是使用它们来提高可重玩性，但仍然让游戏感觉逼真。让它感觉手工制作并具有人情味，但要随机化，这样重复运行同一张地图就永远不会被映射，使重复的​​体验与第一次通过地图的体验感觉一样奇妙。 我可以评论哪些游戏作为做得好的例子？有没有关于它的论文？有什么值得一提的吗？就像我想象的那样，这太难了，或者不值得，因为到目前为止很少有游戏这样做。 一个建议：  最简单的方法是手工制作一些大小一致的模块，然后可以随机放置在网格中。如果你觉得自己特别聪明，你可以使用波函数折叠并稍微控制随机性/确保只有可以连接的部分才能连接。  我想问你是否知道任何方向可以让我找到解决方案或尝试解决此问题的例子，无论是在理论还是实践上。 编辑：FP：第一人称/ OTS：过肩 - 解释视频游戏中相机相对于玩家角色的位置    提交人    /u/blitz4   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib8e5k/d_randomly_generated_maps_for_fpots_games/</guid>
      <pubDate>Mon, 27 Jan 2025 13:01:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何向 ICLR 2025 提交 Camera Ready 版本？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib6dj6/d_how_to_submit_camera_ready_version_to_iclr_2025/</link>
      <description><![CDATA[有人知道如何向 ICLR-25 提交照相排版版本吗？我在 openreview 或会议网站上没有看到选项；录取电子邮件中没有提交链接。 提前致谢。 注意：这是我的论文第一次被 ICLR 接受。    提交人    /u/Hefty_Willingness543   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib6dj6/d_how_to_submit_camera_ready_version_to_iclr_2025/</guid>
      <pubDate>Mon, 27 Jan 2025 11:21:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于几年后重返该行业的人，您有什么建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib6c03/d_what_would_you_suggest_a_person_who_is_coming/</link>
      <description><![CDATA[2013 年，我开始深入研究机器人技术并建立模型，2015 年深入研究 ML，2017-18 年深入研究 DL 和 GAN，但从 2019 年起，生活有其他计划，目前在商业方面，我敢说每一天对我来说都是新的。每当人工智能世界出现新消息时，我当然都会被它吸引。  你会建议我回到技术方面吗？我该如何开始，从哪里开始！我已经几年没有编码了，现在我觉得自己有点笨    提交人    /u/ImaginationAny2254   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib6c03/d_what_would_you_suggest_a_person_who_is_coming/</guid>
      <pubDate>Mon, 27 Jan 2025 11:19:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么在损失函数（例如线性回归损失函数）中不使用 4、6 等更高的偶数幂？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib3dhn/d_why_higher_even_powers_like_4_6_etc_are_not/</link>
      <description><![CDATA[我们知道奇数幂会导致非凸函数，并且函数也不可微。但是为什么我们不使用偶数幂，例如 4 等？我在一次采访中被问到这个问题，我说也许计算成本会很高，并且会对异常值进行更多惩罚。但他们似乎仍然不满意。我还遗漏了什么其他原因？    提交人    /u/maaKaBharosaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib3dhn/d_why_higher_even_powers_like_4_6_etc_are_not/</guid>
      <pubDate>Mon, 27 Jan 2025 08:17:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepSeek 为什么开源他们的工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/</link>
      <description><![CDATA[如果他们的培训效率提高 45 倍，他们本可以主宰 LLM 市场。你认为他们为什么选择开源他们的工作？这对他们的公司有什么好处？现在美国的大型实验室可以说：“我们将采用他们的优秀想法，并将它们与我们的秘密想法结合起来，我们仍然会领先”  编辑： DeepSeek-R1 现在在 LLM Arena 上排名第一（使用 StyleCtrl）！它们与其他 3 个模型共享此排名：Gemini-Exp-1206、4o-latest 和 o1-2024-12-17。    提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/</guid>
      <pubDate>Mon, 27 Jan 2025 07:48:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] Transformers 推理优化 ⏰🚀 – deepschool.ai</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib10gr/p_transformers_inference_optimizations/</link>
      <description><![CDATA[      我感觉还有很多事情可以做。例如，在给定 400 个 token 输入的情况下，我只能在 10 秒内输出 200 个 token。希望您能提供意见，让我们知道下一步该探索什么。    提交人    /u/themathstudent   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib10gr/p_transformers_inference_optimizations/</guid>
      <pubDate>Mon, 27 Jan 2025 05:40:39 GMT</pubDate>
    </item>
    <item>
      <title>[R][Q] 抱歉，我正在寻找一本包含数学 ML 基础知识的书；它大约有 400 页，我记得有人在这里发过帖子，但我找不到它</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iaw81h/rq_sorry_i_was_looking_for_that_book_with_all_the/</link>
      <description><![CDATA[[R][Q] 抱歉，我正在寻找那本包含机器学习数学基础知识的书；它大约有 400 页，我记得有人在这里发布过，但找不到它 它基本上是机器学习的所有数学基础知识    提交人    /u/Proper_Fig_832   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iaw81h/rq_sorry_i_was_looking_for_that_book_with_all_the/</guid>
      <pubDate>Mon, 27 Jan 2025 01:26:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 本地运行 Deepseek R1 32B</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iagk2t/d_ran_deepseek_r1_32b_locally/</link>
      <description><![CDATA[      在本地运行 Deepseek R1 32B。 使用 RTX 8000 - 48gb 内存。  但看起来它使用不到 22 gb 的内存来运行 32b 模型。  速度约为 14tokens/秒，对于我们想要的任何东西来说已经足够快了。  最重要的是，使用 OpenWebUI 有助于访问互联网/搜索。     提交人    /u/mrloki_reddit   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iagk2t/d_ran_deepseek_r1_32b_locally/</guid>
      <pubDate>Sun, 26 Jan 2025 14:57:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>