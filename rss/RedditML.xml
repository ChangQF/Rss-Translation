<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 27 Feb 2024 15:13:17 GMT</lastBuildDate>
    <item>
      <title>[D] 刚刚获得 4x A100 40GB，我应该训练什么来进行压力测试？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1dozc/d_just_got_access_to_4x_a100_40gb_what_should_i/</link>
      <description><![CDATA[我们的工作场所刚刚给我买了一台带有 4x A100 SXM4 40GB 的 GPU 服务器。 有什么有趣的东西值得训练学习如何在多个 GPU 上分布大型模型并学习如何优化代码？   由   提交/u/hobz462  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1dozc/d_just_got_access_to_4x_a100_40gb_what_should_i/</guid>
      <pubDate>Tue, 27 Feb 2024 14:52:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 转换器解码器层 gpt 的异常行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1dmi3/d_unusual_behaviour_with_pytorch_transformer/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1dmi3/d_unusual_behaviour_with_pytorch_transformer/</guid>
      <pubDate>Tue, 27 Feb 2024 14:49:18 GMT</pubDate>
    </item>
    <item>
      <title>[讨论][研究]deepfake检测工具需要帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1cqzo/discussion_research_help_needed_for_deepfake/</link>
      <description><![CDATA[     &lt; td&gt; 嘿 Reddit 社区， 我是致力于开发专门针对图像的 Deepfake 检测软件的团队的一员和视频分析。我们正在与您、专家和爱好者联系，以找出您认为至关重要的功能，并将深度伪造检测工具提升到一个新的水平。 我们想问的主要问题是：  您认为深度伪造检测工具需要具备哪些功能/信息，哪些功能会让您有兴趣尝试一下？ 有哪些功能？您认为这样的工具应该解决关于 Deepfake 技术的挑战/担忧？  ​ 我们的 Deepfake 检测工具的外观示例 对于我们的图像和视频检测，我们目前提供：  表示输入为假或真实的可能性的概率分数。 eXplainable 人工智能 (XAI) 结果显示为热图。 Deepfake 类型检测。 eXplainable 人工智能 (XAI) 结果显示为热图。 li&gt;  我们仍处于开发的早期阶段，任何有关如何进行的帮助将不胜感激。如果您有任何新的想法、想法或问题，请在下面的评论中留言。非常感谢您提供的任何帮助！   由   提交/u/Whole_Breakfast_6570   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1cqzo/discussion_research_help_needed_for_deepfake/</guid>
      <pubDate>Tue, 27 Feb 2024 14:10:30 GMT</pubDate>
    </item>
    <item>
      <title>[D]时间序列分类问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1bqbx/d_time_series_classification_problem/</link>
      <description><![CDATA[在当前的工作项目中，我们预测每种产品的销售数量等。数据集来自 POS 系统，在换句话说，没有 0，只有数量，简短的示例：假设商品 X 在 1（天）/1/23 和 3/1/23 出售，因此数据库中只有第 1 天和第 3 天，其中数据库中不存在第 2/1 天。 我想听听这里的意见和不同的方法，一种方法是填补每个产品的空白，并创建一个名为 is_bought 的新功能，如果发生销售 -&gt; ; 1，空白处用0填充。然后将分类输出乘以预测销量。对于回归问题，使用了 LGBM。 问题是我们有 2016 年的数据，当然是因为新冠疫情等......我们决定从 2022 年 1 月开始训练，但仍然有近 600 万条记录，所以如果我们填补了空白，数据会很大，那么还有其他方法或类似的问题吗？    由   提交/u/Phaeora_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1bqbx/d_time_series_classification_problem/</guid>
      <pubDate>Tue, 27 Feb 2024 13:22:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 测量输入法学硕士中小/零方差的输出方差</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1bp9r/d_measuring_variance_in_output_for_smallzero/</link>
      <description><![CDATA[嗨！我正在尝试设置一些实验来衡量法学硕士的方差（可能会关注偏见，但不确定哪种类型的偏见） 很想知道其他人会如何处理这个问题。   由   提交 /u/PlayingDumbIsFunny   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1bp9r/d_measuring_variance_in_output_for_smallzero/</guid>
      <pubDate>Tue, 27 Feb 2024 13:21:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用 HellaSwag 等数据集执行 LLAMA2 等法学硕士的基准测试？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1ajx1/d_how_to_execute_a_benchmark_for_llms_such_as/</link>
      <description><![CDATA[你好， 我正在阅读有关 HellaSwag 的论文，了解数据集的结构以及它给数据集带来的挑战法学硕士。然而，我在论文中没有找到任何关于如何为像 LLAMA2 这样的 LLM 确定这样的基准的内容。数据集中的一个示例是： 一名妇女带着水桶和狗在外面。狗到处乱跑，试图避免洗澡。她… a) 用肥皂冲洗水桶并吹干狗的头。 b) 使用软管防止它沾上肥皂. c) 把狗弄湿了，然后它又逃跑了。 d) 和狗一起进入浴缸  模型现在必须选择最佳答案。但是我如何确定模型更喜欢哪个答案呢？我是否只需向模型提供多项选择题并使用 logits 来计算下一个标记是否最有可能是 a、b、c 或 d？或者我是否必须在迭代过程中确定四个答案中每个答案的总体概率，类似于束搜索？我目前正在使用一个基于 HF Transformers 的库，这将导致最后一个变体非常耗时。  我也愿意接受其他易于使用的基准测试。我只需要一个指标来以相对通用的方式衡量模型的性能下降，以量化我对其进行的一些操作的影响。 提前非常感谢 &lt; !-- SC_ON --&gt;  由   提交/u/bineda  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1ajx1/d_how_to_execute_a_benchmark_for_llms_such_as/</guid>
      <pubDate>Tue, 27 Feb 2024 12:21:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 会议论文是双盲的。为了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b18is0/d_conference_paper_is_doubleblinded_for_what/</link>
      <description><![CDATA[我对提交给会议的论文必须双盲的要求感到非常困惑，但它们却可以预印有作者姓名和隶属关系，并且可以同时作为同一篇论文共享。人们甚至在接受/发表之前在 Twitter、LinkedIn、Reddit 等 SNS 上宣传他们的论文。感觉就像我在看 Instagram 版的学术界。如何确保广告而不是报纸本身不会影响决策过程？   由   提交 /u/Dry_Cheesecake_8311   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b18is0/d_conference_paper_is_doubleblinded_for_what/</guid>
      <pubDate>Tue, 27 Feb 2024 10:17:05 GMT</pubDate>
    </item>
    <item>
      <title>[N] 在 MWC 的技嘉展位上看到了这些……想象一下你可以用这些做什么！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b17igl/n_saw_these_at_the_gigabyte_booth_at_mwcimagine/</link>
      <description><![CDATA[       由   提交 /u/BubblyMcnutty   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b17igl/n_saw_these_at_the_gigabyte_booth_at_mwcimagine/</guid>
      <pubDate>Tue, 27 Feb 2024 09:05:38 GMT</pubDate>
    </item>
    <item>
      <title>通过 torch.compile 支持 gpt-fast 中的 Mixtral - 比任何非 Groq 端点更快的解码（！）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b10g2s/supporting_mixtral_in_gptfast_through/</link>
      <description><![CDATA[大家好，我们去年 12 月发布了 gpt-fast 作为可破解的“教程”实现文本生成的 SOTA 解码性能的各种实现。 从那时起，我们最近还在 gpt-fast 中添加了 Mixtral 实现。在这里查看：https://github.com/pytorch-labs/gpt-fast /tree/main/mixtral-moe  特色  (!) 无自定义内核 int8 和张量并行支持&lt; /li&gt; 仍然非常简单（支持&lt;150 LOC） 比任何（非 Groq）API 端点更快的解码速度，高达 220 tok/s/用户。  我还对这里涉及的挑战写了一份较长的解释：https://thonking.substack.com/p/short-supporting-mixtral-in-gpt-fast 希望人们觉得它有趣且有用！有趣的是，由于我们实际上在大约 2 个月前完成了这项工作并推迟了合并它，所以一些人（与我们无关）实际上已经对其进行了基准测试。 例如 此评论。  我们最近用 Mixtral 8x7B 尝试过此操作，结果非常疯狂！ Mixtral 8x7B 8 位版本在 A100-GPU (80GB) 上提供 55 个令牌/秒。最有趣的是，它比 4 位+vLLM 更好。    由   提交 /u/programmerChilli   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b10g2s/supporting_mixtral_in_gptfast_through/</guid>
      <pubDate>Tue, 27 Feb 2024 02:27:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 某些类别的模型现在被认为“过时”了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0ua8s/d_are_some_classes_of_models_considered_obsolete/</link>
      <description><![CDATA[作为一名高级 SWE，我希望在 ML 和数据科学方面进行一些自我驱动的培训。我正在收集和组织课程，我想知道某些主题现在是否已经过时，我可以安全地跳过它们。这主要来自构建应用程序的 POV。 例如，以 Coursera 上的 Andrew Ng GAN 专业为例。有了 Midjourney 或 OpenAI 视觉模型等稳定的扩散模型，GAN 仍然有用例吗？在 NLP 领域，现在只有 GPT4，我还需要研究 HMM 或构建玩具翻译和摘要模型吗？    由   提交/u/The-_Captain  /u/The-_Captain  reddit.com/r/MachineLearning/comments/1b0ua8s/d_are_some_classes_of_models_considered_obsolete/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0ua8s/d_are_some_classes_of_models_considered_obsolete/</guid>
      <pubDate>Mon, 26 Feb 2024 22:04:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] Genie：生成交互环境</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0tj6o/r_genie_generative_interactive_environments/</link>
      <description><![CDATA[ 由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0tj6o/r_genie_generative_interactive_environments/</guid>
      <pubDate>Mon, 26 Feb 2024 21:35:29 GMT</pubDate>
    </item>
    <item>
      <title>对于新晋研究科学家来说，该行业不会“复苏”[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0n3ib/the_industry_is_not_going_recover_for_newly/</link>
      <description><![CDATA[      今天的热门话题问：“科技行业还没有复苏吗？我有那么糟糕吗？” 让我做出一个大胆的预测（我希望我是错的，但我不认为我是错的）：这个行业不会“ “恢复”对于新晋研究科学家： 您的机器学习论文数量呈指数级增长，反映出博士生和博士后数量呈指数级增长： ​ &lt; p&gt;https://preview.redd.it/viv6l1gnkykc1。 png?width=899&amp;format=png&amp;auto=webp&amp;s=04e227dede42f7d46d1941fc268bb7ea0a409a04 ...毕业并开始竞争大致固定数量的井- 支付行业研究职位。这些职位的数量可能会季节性增加或减少，但长期趋势是他们的就业前景将变得越来越糟糕，而这种指数趋势仍在持续。 ​  div&gt;  由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0n3ib/the_industry_is_not_going_recover_for_newly/</guid>
      <pubDate>Mon, 26 Feb 2024 17:24:08 GMT</pubDate>
    </item>
    <item>
      <title>[N] 科技巨头正在开发他们的人工智能芯片。这是清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0ira9/n_tech_giants_are_developing_their_ai_chips_heres/</link>
      <description><![CDATA[NVIDIA GPU 短缺，导致多家公司创建自己的 AI 芯片。以下是这些公司的列表： • Google 处于改进张量处理单元 (TPU) 的前沿https://cloud.google.com/tpu?hl=en Google Cloud 技术。 • OpenAI 正在研究设计专有 AI 芯片的潜力https://www.reuters.com/ technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/。 • 微软宣布 https://news.microsoft.com/source/ features/ai/in-house-chips-silicon-to-service-to-meet-ai-demand/ 两款定制设计的芯片：用于大型语言模型训练和推理的 Microsoft Azure Maia AI 加速器以及用于大型语言模型训练和推理的 Microsoft Azure Maia AI 加速器Azure Cobalt CPU，用于 Microsoft 云上的通用计算工作负载。 • 亚马逊推出了 Inferentia AI 芯片 https://aws.amazon.com/machine-learning/inferentia/ 和第二代机器学习 (ML) 加速器 AWS Trainium https://aws.amazon.com/machine-learning/trainium/。 • Apple 一直在开发其系列定制芯片并推出https://www.apple.com/newsroom/2023/10/apple-unveils-m3-m3-pro-and-m3-max-the-most-advanced-chips-for-a-personal -computer/ M3、M3 Pro 和 M3 Max 处理器，可扩展到专门的 AI 任务。 • Meta 计划部署新版本的定制芯片，旨在支持其人工智能据路透社报道，人工智能（AI）的推动 https://www.reuters.com/technology/meta-deploy-in-house-custom-chips-this-year-power-ai-drive-memo-2024-02-01/ . • 据报道，华为https://www.reuters.com/technology/ai-chip-demand-forces-huawei-slow-smartphone-product-sources-2024-02-05/由于人工智能芯片的需求，人工智能并放慢了高端 Mate 60 手机的生产 https://www.hisilicon.com/ en/products/ascend 飙升。 我错过了什么吗？   由   提交 /u/vvkuka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0ira9/n_tech_giants_are_developing_their_ai_chips_heres/</guid>
      <pubDate>Mon, 26 Feb 2024 14:25:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是科技行业还没复苏还是我太差了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0ia76/d_is_the_tech_industry_still_not_recovered_or_i/</link>
      <description><![CDATA[我是欧洲顶尖大学的一名应届博士毕业生，正在研究 ML/CV 中的一些热门主题，已发表 8 - 20 篇论文，其中大部分是我的第一作者。这些论文已累计被引用1000-3000次。 （使用新帐户和广泛的范围来保持匿名） 尽管我认为自己是一个相当有实力的候选人，但我在最近的求职过程中遇到了重大挑战。我主要瞄准研究科学家职位，希望从事开放式研究。我已经联系了欧洲、中东和非洲地区的许多高级机器学习研究人员，虽然有些人表达了兴趣，但不幸的是，由于各种原因（例如人员有限或招聘经理没有更新信息），没有一个机会成为现实。 我主要针对大型科技公司以及一些最近流行的机器学习初创公司。不幸的是，我的大部分申请都被拒绝了，而且常常没有面试的机会。 （我只接受过一家大型科技公司的面试，然后就被拒绝了。） 特别是，尽管有朋友推荐，我还是立即遭到了 Meta 的研究科学家职位拒绝（几天之内）。我现在只是非常困惑和不安，不知道出了什么问题，我是否被这些公司列入了黑名单？但我不记得我树敌过。我希望就下一步可以做什么寻求一些建议......   由   提交/u/Holiday_Safe_5620   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0ia76/d_is_the_tech_industry_still_not_recovered_or_i/</guid>
      <pubDate>Mon, 26 Feb 2024 14:04:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>