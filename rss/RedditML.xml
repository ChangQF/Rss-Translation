<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 10 Jan 2024 03:14:54 GMT</lastBuildDate>
    <item>
      <title>[D] 寻找具有“双豆”结构的二元分类数据集（~2000 个条目）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192x6d1/d_looking_for_a_binary_classification_dataset/</link>
      <description><![CDATA[      我目前正在研究二元分类项目并需要一个具有独特“两个豆”的数据集结构。 [图片] ​ 数据集 ​ 具体来说，我正在寻找这 2000 个数据条目，其特征表示为 (x1, x2)和相应的类别标签（+1/-1）。数据应类似于以下格式： x1 x2 class 8.0919 -1.7303 1 我丢失了文件的数据并且无法在任何地方找到它在线的。这是什么格式的数据集？这个数据分布有名字吗？我在哪里可以找到这样的数据集或其他类似的数据集来训练我的自定义分类模型？   由   提交 /u/Radiant-Cockroach-33   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192x6d1/d_looking_for_a_binary_classification_dataset/</guid>
      <pubDate>Wed, 10 Jan 2024 02:28:28 GMT</pubDate>
    </item>
    <item>
      <title>多标签分类准确度测量[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192wjq4/multilabel_classification_accuracy_measurement_d/</link>
      <description><![CDATA[我想知道在使用二进制相关性的多标签文本分类中，它如何准确测量准确性，下面的方法是否准确，因为这就是我可以做的在互联网上找到。先谢谢了:)   数据集分为训练集和测试集 在训练阶段，训练模型识别评论之间的关系及其相应的类别标签，以便能够对新数据做出准确的响应。 训练后的模型在测试集上进行评估，其中必须预测评论的标签，只能访问文本。这就像现实生活中的场景一样，模型使用以前从未见过的数据。 模型做出预测后，它可以访问原始标签，然后可以在其中比较测试结果，了解模型在不可预见的数据上的表现如何。    由   提交/u/Fresh_Information_87   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192wjq4/multilabel_classification_accuracy_measurement_d/</guid>
      <pubDate>Wed, 10 Jan 2024 01:58:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么IAF-VAE模型被称为“逆”自回归流（IAF）？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192tj1t/why_is_the_iafvae_model_called_inverse/</link>
      <description><![CDATA[什么是“逆”？关于它？我理解论文中的第 3 节（逆自回归变换），但我无法理解第 4 节（逆自回归流 (IAF)）是如何从那里得出的。我们是否像第 3 节中那样选择潜在变量的特定顺序？  如果有人能给我指点一篇博客文章，引导您了解 IAF-VAE 模型的详细信息，我将不胜感激。 这里是论文：https://arxiv.org/pdf/1606.04934.pdf   &amp; #32；由   提交 /u/ComedyIsOver   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192tj1t/why_is_the_iafvae_model_called_inverse/</guid>
      <pubDate>Tue, 09 Jan 2024 23:43:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] DataMapPlot 用于演示 UMAP 和 t-SNE 图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192s3a0/p_datamapplot_for_presentation_ready_umap_and/</link>
      <description><![CDATA[我制作了一个小型库，用于快速轻松地制作 UMAP、t-SNE 等结果的演示文稿或海报图。这应该效果很好任何聚类和标记的数据集，特别是通过 BERTopic 或其他类似主题建模工具推送的大型语料库。目的是尽可能轻松地制作美观的情节，同时提供足够的方法来微调样式以满足您的需求。 代码：https://github.com/TutteInstitute/datamapplot 文档：https ://datamapplot.readthedocs.io/ PyPI：https://pypi.org/project /datamapplot/ conda：https://anaconda.org/conda-forge/datamapplot&lt; /a&gt;   由   提交 /u/lmcinnes   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192s3a0/p_datamapplot_for_presentation_ready_umap_and/</guid>
      <pubDate>Tue, 09 Jan 2024 22:44:59 GMT</pubDate>
    </item>
    <item>
      <title>训练损失按预期减少，然后在第一个时期后变得疯狂？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192ra9a/training_loss_decreases_expectedly_then_goes_wild/</link>
      <description><![CDATA[      在第一个时期，训练损失以令人愉快的速度下降，但从第二个时期开始时代开始疯狂地摇摆。我尝试过 1e-5、-6，似乎遵循相同的模式。验证也趋于平稳。我以前从未遇到过这个问题，这是局部最小问题吗？这次运行是 6 个 epoch，但我目前将其调至 20 个 epoch 来观察其行为，因为它在第 25k 步看起来很乐观。 该模型是用于令牌分类的 google/electra-large-discriminator ，优化器是adamw。没有使用其他修改，例如层冻结、权重衰减、分层权重衰减。 https://preview.redd.it/f6ydsuzcnhbc1.png?width=1210&amp;format=png&amp;auto=webp&amp;s=075f8da8ad5dab863cfa189bfc235b32658 a459d &lt; strong&gt;[更新] 我使用 Electra 进行了超过 20 个 epoch 的更多测试，使用的数据集要小得多。以下是训练/有效损失。使用 LR=5e-6（深蓝色线），electra 最终达到了近似对角线的混淆矩阵。 在 700 个训练步骤处似乎有一个分叉点，可能大约 15-20 个 epoch，橙色会话 (1e-5) 是第一次正确预测的运行一些不平凡的事情（尽管它仍然很糟糕）。 验证损失：较大步长的分叉点显示在 700 步。 ​   由   提交/u/pikachuunibyo   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192ra9a/training_loss_decreases_expectedly_then_goes_wild/</guid>
      <pubDate>Tue, 09 Jan 2024 22:12:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我如何理解扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192qlu2/d_how_i_understand_diffusion_models/</link>
      <description><![CDATA[大家好， 我制作了一个关于扩散模型的讲解视频，涵盖了基础知识，包括训练、指导、分辨率和速度。我希望这可以帮助有兴趣了解更多扩散模型的人们。  https://www.youtube.com/watch?v=i2qSxMVeVLI 欢迎反馈/提问！   由   提交/u/jbhuang  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192qlu2/d_how_i_understand_diffusion_models/</guid>
      <pubDate>Tue, 09 Jan 2024 21:45:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 带有交互的监督学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192q8cd/r_supervised_learning_with_interactions/</link>
      <description><![CDATA[我正在研究监督学习，我正在思考一个确实应该有一个名字的概念，但我在 这个想法是有一个监督学习任务，其中模型可以发送有限数量的查询并在必须决定输出之前接收它们的答案。 如示例：输入可能是图像分类任务，其中大部分图像隐藏在阴影后面。该模型最多可以指定三个块，在提交分类之前将其阴影移除。 这也可以表示为强化学习任务，但它比一般任务更具体-目的强化学习，输出应该在 MSE 损失函数上进行训练，而不是奖励函数。 文献中有这类问题的名称吗？   由   提交 /u/Smart-Emu5581   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192q8cd/r_supervised_learning_with_interactions/</guid>
      <pubDate>Tue, 09 Jan 2024 21:30:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] 测试 MAMBA 架构 KV 检索和 RAG 功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192k8b4/r_testing_mamba_architecture_kvretrieval_and_rag/</link>
      <description><![CDATA[我即将以与论文类似的方式测试 MAMBA 的功能 迷失在中间：语言模型如何使用长上下文，但由于这是一项大量的工作，我想问是否有人已经这样做了。    由   提交/u/25cmderespeito   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192k8b4/r_testing_mamba_architecture_kvretrieval_and_rag/</guid>
      <pubDate>Tue, 09 Jan 2024 17:30:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一个帮助人们探索和发现新的机器学习概念的交互式网站的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192jxt8/d_an_idea_for_an_interactive_website_that_helps/</link>
      <description><![CDATA[      ​ 网站创意的 Figma 原型 &lt; p&gt;因此，我有一个网站的想法，可以帮助人们以交互方式探索机器学习中的复杂主题。 主题将包括模型架构：  模型架构&lt; /li&gt; 训练和微调模型的方法 提高模型性能的新方法 基本上是研究论文中讨论的任何内容  &lt;我会尝试使其尽可能具有互动性，以便人们能够深入了解他们感兴趣的主题。我还会链接到代码和拥抱面部实现，以便人们能够亲自体验这些主题。 目标是帮助人们更好地理解该领域正在进行的研究并使其成为可能他们很容易获得新技术的实践经验。 您对此想法有何看法？我还应该考虑什么？有哪些明显的问题？如果它存在，你会使用/贡献它吗？ 任何意见都将帮助我澄清这个想法，所以请分享！谢谢:)   由   提交 /u/IffyNibba01   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192jxt8/d_an_idea_for_an_interactive_website_that_helps/</guid>
      <pubDate>Tue, 09 Jan 2024 17:18:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在可塑性之前推断神经活动作为超越反向传播学习的基础</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192an1m/r_inferring_neural_activity_before_plasticity_as/</link>
      <description><![CDATA[论文：https://www.nature.com/articles/s41593-023-01514-1 预印本版本：https://www.biorxiv.org/content/10.1101/2022.05.17.492325  代码：https://github.com/YuhangSong/Prospective-Configuration 摘要：  对于人类和机器来说，学习的本质是查明信息处理管道中的哪些组件对其输出中的错误负责，一个被称为“学分分配”的挑战。长期以来，人们一直认为学分分配最好通过反向传播来解决，这也是现代机器学习的基础。在这里，我们提出了一个根本不同的信用分配原则，称为“预期配置”。在前瞻性配置中，网络首先推断学习应产生的神经活动模式，然后修改突触权重以巩固神经活动的变化。我们证明，与反向传播相比，这种独特的机制（1）是在完善的皮质回路模型家族中进行学习的基础，（2）使得学习能够在生物有机体面临的许多环境中更加高效和有效，（3） ）再现了在不同的人类和大鼠学习实验中观察到的令人惊讶的神经活动和行为模式。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192an1m/r_inferring_neural_activity_before_plasticity_as/</guid>
      <pubDate>Tue, 09 Jan 2024 09:14:44 GMT</pubDate>
    </item>
    <item>
      <title>目前该领域的弱点是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192aj3h/what_are_weaknesses_of_the_field_currently_d/</link>
      <description><![CDATA[大家好， 有人了解该领域技术和业务相关的差距和弱点吗？如果可能或者更高效的话，哪些事情会让项目和模型变得最优？例如（不一定是大规模案例）缺乏高质量的数据集。  非常感谢！   由   提交 /u/卷积  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192aj3h/what_are_weaknesses_of_the_field_currently_d/</guid>
      <pubDate>Tue, 09 Jan 2024 09:06:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 定制 LLM RAG 应用程序会变得多余吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1929n4f/d_are_custom_llm_rag_apps_going_to_become/</link>
      <description><![CDATA[Copilot Studio 即将推出 (https://www.microsoft.com/en-us/microsoft-copilot/microsoft-copilot-studio）具有令人印象深刻的无代码/开箱即用的 RAG 解决方案。  开源 RAG 世界（例如 Langchain、Llamaindex 等）有大量的开发和活动，我是 FYI 的大力支持者。 但是，什么似乎奇怪的是，如果您想构建一个 RAG 应用程序，即如果您比较构建和生产自定义应用程序的成本，那么这种没有开箱即用代码的解决方案（Copilot Studio - 只是作为一个示例）似乎压倒性地是更好的选择RAG 应用程序与使用 Copilot Studio 的成本相比，几乎低了一个数量级（无论您如何削减开发人员的时间和持续时间）。  我的问题是，在我看来，我们正在走向这样一种情况：企业解决方案将使自定义 RAG 应用程序变得多余（当然不是在所有情况下，但在大多数情况下），但是似乎很少有与开源社区中的活动相关的讨论。人们是否同意这是一种可能的情况？  显然会有例外......但在大多数用例中，我不知道如何与即时/最小设置、低成本、高度可扩展的 RAG 解决方案竞争。    由   提交/u/Used-Ad-7734   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1929n4f/d_are_custom_llm_rag_apps_going_to_become/</guid>
      <pubDate>Tue, 09 Jan 2024 08:03:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] WikiChat：通过维基百科上的少发基础来阻止大型语言模型聊天机器人的幻觉 - 在与人类用户就最新主题进行的对话中实现了 97.9% 的事实准确性，比 GPT-4 好 55.0%！ - 斯坦福大学 2023</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1920hky/r_wikichat_stopping_the_hallucination_of_large/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2305.14292v2  Github：https://github.com/stanford-oval/WikiChat  摘要：  本文提出了第一个基于 LLM 的少样本聊天机器人几乎从不产生幻觉，并且具有高会话性和低延迟。 WikiChat 以英语维基百科为基础，这是最大的精选自由文本语料库。  WikiChat 生成法学硕士的回复，仅保留有根据的事实，并将其与从语料库中检索到的其他信息相结合，形成事实且引人入胜的回复。 我们将基于 GPT-4 的 WikiChat 提炼为质量损失最小的 7B 参数 LLaMA 模型，以显着改善其延迟、成本和隐私，并促进研究和部署。  使用一种新颖的人类和法学硕士混合评估方法，我们证明我们最好的系统在模拟对话中达到了 97.3% 的事实准确性。它显着优于所有基于检索和基于 LLM 的基线，与 GPT-4 相比，在头部、尾部和近期知识方面分别提高了 3.9%、38.6% 和 51.0%。与之前最先进的基于检索的聊天机器人相比，WikiChat 的信息量和吸引力也显着提高，就像法学硕士一样。  WikiChat 在与人类用户就近期话题进行的对话中实现了 97.9% 的事实准确性，比 GPT-4 高出 55.0%，同时获得了更高的用户评分和更有利的评论。   https:/ /preview.redd.it/9mhpdh300bbc1.jpg?width=1225&amp;format=pjpg&amp;auto=webp&amp;s=cb64b717e920d7bf727782f7c803500ae838d6ef https://preview.redd.it/5dxesl200bbc1.jpg?width=862&amp;format=pjpg&amp;auto=webp&amp;s =b6de0cda980eec3cf3484ff1f9cd6dc1acf13505 https ://preview.redd.it/j387vl200bbc1.jpg?width=914&amp;format=pjpg&amp;auto=webp&amp;s=736fb922c1f98f4c7b132f1c153f4653a8b85441 https://preview.redd.it/3hnxqi200bbc1.jpg?width=923&amp;format=pjpg&amp;auto=webp&amp; ;s=95b40a9cf67d7f3729dae85878db67a262cc5201   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1920hky/r_wikichat_stopping_the_hallucination_of_large/</guid>
      <pubDate>Tue, 09 Jan 2024 00:07:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我构建了 marimo——一个开源的反应式 Python 笔记本，它存储为 .py 文件，可以作为脚本执行，并且可以作为应用程序部署。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191rdwq/p_i_built_marimo_an_opensource_reactive_python/</link>
      <description><![CDATA[嗨！我想分享 marimo，一个用于 Python 的开源反应式笔记本。它旨在解决 Jupyter 笔记本的许多众所周知的问题，同时为您提供新功能：marimo 笔记本可重复（无隐藏状态）、git 友好（存储为 Python 文件）、可作为 Python 脚本执行以及可部署为 Web 应用程序。 GitHub 存储库： https://github.com/marimo-team/marimo 在 marimo 中，您的笔记本代码、输出和程序状态保证是一致的。运行单元格并通过自动运行引用其变量的单元格来做出反应。删除一个单元格，marimo 就会从程序内存中清除其变量，从而消除隐藏状态。如果您担心意外触发昂贵的计算，您可以禁用特定单元格的自动运行。 marimo 还附带 UI 元素，例如滑块、数据帧转换器以及自动与 Python 同步的交互式绘图。与元素交互，使用该元素的单元格会自动以其最新值重新运行。反应性使这些 UI 元素比 Jupyter 小部件更有用，更不用说更易于使用。 我选择开发 marimo，因为我相信 ML 社区应该有一个更好的编程环境来进行研究和交流。我看到很多研究都是从 Jupyter 笔记本开始的（我自己的大部分也是这样）。由于 Jupyter 笔记本固有的缺陷，我还看到许多相同的研究无法重现或因隐藏的错误而减慢速度。 我坚信，我们的工作质量取决于我们的工作质量我们使用的工具塑造了我们的思维方式——更好的工具，更好的思维。 2017 年至 2018 年，我在 Google Brain 担任软件工程师，当时 TensorFlow 正在过渡到 TensorFlow 2，而 JAX 还处于早期阶段。我亲眼目睹了 PyTorch 和 JAX 为我们的社区带来的生产力的提高，后来当我在斯坦福大学与 Stephen Boyd 一起攻读博士学位时，我也亲眼目睹了我自己的研究。我们对 marimo 的目标是通过新的编程环境做一些类似的事情。 marimo 的开发经过了科学家和工程师的密切投入，并受到了包括 Pluto.jl 和 Streamlit 在内的许多工具的启发。只有我们两个人在研究它——我们最近将其开源，因为我们认为它已经准备好供更广泛的使用。请尝试一下（pip install marimo &amp;&amp; marimo 教程简介）。我们非常希望您能提供任何反馈！   由   提交 /u/akshayka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191rdwq/p_i_built_marimo_an_opensource_reactive_python/</guid>
      <pubDate>Mon, 08 Jan 2024 18:00:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>