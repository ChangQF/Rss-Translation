<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 10 May 2024 18:18:01 GMT</lastBuildDate>
    <item>
      <title>[D] 为什么 nproc_per_node 对大于 1 的值不起作用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1covm2r/d_why_does_nproc_per_node_not_work_for_values/</link>
      <description><![CDATA[上下文：使用 torchrun 运行 dinov2 训练。我有两个节点。当我运行训练（每个节点 1 个 GPU）w/nproc=1 时，它可以工作。当我为每个节点分配 2 个 GPU 时，我将 nproc 更改为 2。然后在尝试初始化模型时训练崩溃。关于这可能是什么的任何见解吗？   由   提交/u/dillpill4  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1covm2r/d_why_does_nproc_per_node_not_work_for_values/</guid>
      <pubDate>Fri, 10 May 2024 17:51:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求时间序列数据增强的见解：Python 库和基准数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1coviyc/d_seeking_insights_on_time_series_data/</link>
      <description><![CDATA[大家好， 我正在深入研究时间序列数据增强的世界，我对当前状态感到好奇艺术技术，特别是那些可通过 Python 库访问的技术。 技术：增强时间序列数据的最有效方法是什么？是否有任何值得探索的最新进展或创新方法？ Python 库：是否有任何 Python 库为时间序列数据增强提供全面支持？我对提供各种增强技术的易于使用的实现的库特别感兴趣。 基准数据集：当谈到对时间序列数据增强技术进行基准测试时，是否有社区经常依赖的任何首选数据集？如果有一些参考数据集来评估不同增强策略的有效性，那就太好了。我渴望听到那些在这个领域有经验的人的意见。您可以分享的任何见解、建议或资源都将对指导我的探索非常有帮助。 提前感谢您的输入！  &amp; #32；由   提交/u/anonymousTestPoster  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1coviyc/d_seeking_insights_on_time_series_data/</guid>
      <pubDate>Fri, 10 May 2024 17:47:21 GMT</pubDate>
    </item>
    <item>
      <title>[P] Google Colab 在训练我的图像数据集之前就崩溃了。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cou91s/p_google_colab_crashes_before_even_training_my/</link>
      <description><![CDATA[我有 780 张图像。所有这些都是微观的，我正在做微塑料图像检测。首先，我使用 U-Net 进行二元分类，然后使用 VGG-16 迁移学习。 Google Colab 一点也没有崩溃。效果非常好。 现在我正在做多类分割，预处理也差不多。除了一个用于彩色蒙版的额外通道之外。 但是，仅通过存储训练数据集的分类蒙版，我的系统 RAM 就超过了 6-7GB。调整大小后，我有 580 张图像，每张图像的尺寸为 512x512。不过，在调整大小之前它们甚至更小。 那么，这是怎么回事？任何帮助将不胜感激。 而不是每次以 npz 格式存储数据并将它们加载到变量中时进行预处理。它们的最大容量为 1GB。但没有更高。 我被困住了。已经两天了，但我根本无法训练。另外，我是一名学生，没有钱购买 Colab Pro。我的笔记本电脑是 GTX-1650，所以它的性能绝对不可能比 Google Colab 更好，尤其是因为我只有 8GB RAM。   由   提交/u/Plenty_Mention1787   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cou91s/p_google_colab_crashes_before_even_training_my/</guid>
      <pubDate>Fri, 10 May 2024 16:52:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 评估特定领域 QA 上的法学硕士表现是否足以提交顶级会议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cosbka/d_is_evaluating_llm_performance_on_domainspecific/</link>
      <description><![CDATA[你好， 你好， 我正在为顶级会议准备一篇论文，正在努力解决什么才算是重大贡献。我的研究涉及比较至少五名法学硕士在特定领域问答任务上的表现。为了保密，我不会指定域。 由于没有合适的公开数据集，我从维基百科创建了一​​个新数据集，并尝试了各种提示策略和 LLM 模型，包括详细的性能分析。  我相信通过比较不同的法学硕士和激励策略获得的见解可以使社区受益匪浅，特别是考虑到有关法学硕士评估的现有文献（https://arxiv.org/abs/2307.03109）。然而，一些教授认为，仅仅“分析 LLM 对某个问题的表现并不足以做出足够大的贡献。” 鉴于高层会议接受的许多有关 LLM 评估的研究，您的标准是什么？认为这样的研究论文对社区有价值吗？ 提前感谢您的见解！   由   提交 /u/VieuxPortChill   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cosbka/d_is_evaluating_llm_performance_on_domainspecific/</guid>
      <pubDate>Fri, 10 May 2024 15:30:17 GMT</pubDate>
    </item>
    <item>
      <title>[D]特征空间中决策边界是如何绘制的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cos8ec/d_how_are_decesion_boundry_drawn_in_feature_space/</link>
      <description><![CDATA[我试图了解 ann 与 cnn 的工作原理。  本质上，网络只是学习从输入到输出的映射函数。但在 ANN 的背景下，特征空间由数据表示为 N 个维度特征空间中的一个点。边界是非线性的并且被绘制，这分隔了特征空间。  但是对于 CNN，什么是高维空间和特征空间？这是 3d 空间中的每个像素值都是像 ANN 一样绘制边界的地方吗？但我意识到决策边界是根据 cnn 学到的特征绘制的。意思是，在过滤器更具体于上下文的最后一层中，这就是绘制边界的地方。  我想知道 1.我的理解是否正确，我很困惑 2.这些特征空间是否随着 n/w 学习而移动、改变或变换，形成具有可分离空间的簇，或者线条是否弯曲和集群而不移动特征空间？ 3. 在 ANN 中，边界位于原始高维点上，而在 cnn 中，边界位于学习内核特征上，为什么？？？  我无法理解它在根本上是如何工作的..请帮助我，我被困住了..   &amp;# 32；由   提交/u/elongatedpepe  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cos8ec/d_how_are_decesion_boundry_drawn_in_feature_space/</guid>
      <pubDate>Fri, 10 May 2024 15:26:36 GMT</pubDate>
    </item>
    <item>
      <title>[N] 新书发布：使用 PyTorch 2.X 加速模型训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cos6bq/n_book_lauching_accelerate_model_training_with/</link>
      <description><![CDATA[大家好！我叫 Maicon Melo Alves，是一名专门研究 AI 工作负载的高性能计算 (HPC) 系统分析师。 我想宣布我的书“使用 PyTorch 加速模型训练 2” .X：通过提升模型训练过程来构建更准确的模型” Packt 最近推出了本书。 本书面向想要了解如何使用 PyTorch 加速机器学习模型训练过程的中级数据科学家、工程师和开发人员。 &gt; 如果您认为本书可以帮助其他专业人士，请与您的社区分享这篇文章！ 😊 非常感谢！   由   提交/u/Various_Protection71   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cos6bq/n_book_lauching_accelerate_model_training_with/</guid>
      <pubDate>Fri, 10 May 2024 15:24:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找对小时工感兴趣的 ML 工程师的最佳社区/网站</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cook89/d_best_communitywebsite_to_find_ml_engineer/</link>
      <description><![CDATA[我一直在 Upwork 这样的平台上寻找机器学习工程师，但许多候选人似乎在从头开始构建模型方面经验有限。他们通常专注于集成预构建的 ML API，而不是开发根据特定要求定制的自定义模型。  哪里是寻找能够处理从数据收集到模型部署的整个模型开发过程的机器学习工程师的最佳地点？    由   提交/u/um877  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cook89/d_best_communitywebsite_to_find_ml_engineer/</guid>
      <pubDate>Fri, 10 May 2024 12:38:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mamba 中的“离散化”步骤到底是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1com9qh/d_what_on_earth_is_discretization_step_in_mamba/</link>
      <description><![CDATA[什么是“离散化”？信号/序列不是已经“离散”了吗？以代币的形式？请不要让我去看有关“线性状态空间模型的离散化”的维基百科文章，因为我无法与法学硕士建立任何联系。在我看来，Mamba 的核心只是具有动态 alpha 参数的 EMA，该参数是根据每个通道在时间 t 的当前代币计算得出的。不太明白“离散化”有什么好处？以及它对数据的实际作用。   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1com9qh/d_what_on_earth_is_discretization_step_in_mamba/</guid>
      <pubDate>Fri, 10 May 2024 10:26:48 GMT</pubDate>
    </item>
    <item>
      <title>Pycaret 不稳定 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1colzy7/pycaret_unstable_d/</link>
      <description><![CDATA[我有一个由 py​​caret 支持的预测应用程序，但是有时基于 pycaret 的模型会突然引发未知的异常，并且在大约一天后突然开始工作。我无法理解错误或此异常，因为异常表明此异常不应发生。在我的本地调试时，相同的输入工作正常。有人对此类问题有任何想法吗？是否有任何替代方法可以为预测应用程序自动生成机器学习模型？ 感谢您的支持。谢谢。   由   提交 /u/Awkward_HomoSapien   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1colzy7/pycaret_unstable_d/</guid>
      <pubDate>Fri, 10 May 2024 10:08:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过多标记预测更好更快的大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1coluve/r_better_faster_large_language_models_via/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2404.19737 摘要：  大型语言模型（例如 GPT 和 Llama）使用下一个标记预测损失进行训练。在这项工作中，我们建议训练语言模型一次预测多个未来标记可提高样本效率。更具体地说，在训练语料库中的每个位置，我们要求模型使用 n 个独立的输出头预测以下 n 个标记，在共享模型主干上运行。将多标记预测视为辅助训练任务，我们测量了代码和自然语言模型的改进的下游能力，而训练时间没有开销。该方法对于较大的模型尺寸越来越有用，并且在进行多个时期的训练时保持其吸引力。在编码等生成基准测试中，收益尤其明显，我们的模型始终比强大的基线高出几个百分点。与同类的下一个标记模型相比，我们的 13B 参数模型在 HumanEval 上解决了 12% 的问题，在 MBPP 上解决了 17% 的问题。在小型算法任务上的实验表明，多标记预测有利于培养归纳头和算法推理能力。作为额外的好处，使用 4 标记预测训练的模型在推理时速度提高了 3 倍，即使批量很大也是如此。     提交人    /u/EternalBlueFriday   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1coluve/r_better_faster_large_language_models_via/</guid>
      <pubDate>Fri, 10 May 2024 09:59:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在实践中使用 RAG 基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1coi4iy/d_how_to_use_rag_benchmarks_in_practice/</link>
      <description><![CDATA[我正在开展一个涉及 RAG 实验的研究项目。我想首先运行模型以了解整个管道的工作原理。我在 HuggingFace 上找到了一些数据集（例如 https://huggingface.co/datasets/explodinggradients/WikiEval）。 我对 RAG 的理解是，应该给我一个数据存储，然后我使用该数据存储执行问答任务。然而，在这些数据集中，上下文与问题一起给出，我不太明白。 RAG 是否应该作为上下文问答来执行？如果是的话，它不会破坏RAG中检索的点吗？ 提出我的问题的另一种方式如下：不应该每个RAG数据集都有一个数据集级文档存储而不是随问题一起提供上下文？    由   提交/u/Tall_Sun_3096   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1coi4iy/d_how_to_use_rag_benchmarks_in_practice/</guid>
      <pubDate>Fri, 10 May 2024 05:37:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] ECCV-2024 评论已出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co7w0i/d_eccv2024_reviews_are_out/</link>
      <description><![CDATA[标题说明了一切。   由   提交/u/darkknight-6  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co7w0i/d_eccv2024_reviews_are_out/</guid>
      <pubDate>Thu, 09 May 2024 21:01:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 杰出论文奖。恭喜！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co4kfw/d_iclr_outstanding_paper_awards_congratulations/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co4kfw/d_iclr_outstanding_paper_awards_congratulations/</guid>
      <pubDate>Thu, 09 May 2024 18:42:14 GMT</pubDate>
    </item>
    <item>
      <title>[D]“特征”一词从何而来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co2ye4/d_where_does_the_term_feature_come_from/</link>
      <description><![CDATA[也许是一个愚蠢的琐事问题，但我无法弄清楚。 ML 将特征称为特征，统计将特征称为预测变量，数学将特征称为特征变量，工程也将特征变量称为特征。 我知道它们是什么，但为什么我们称它们为特征？有谁知道起源故事吗？ 编辑：你们都给了我一些很好的线索；我想我已经找到了一个看似合理的答案：它可能来自认知心理学。 介绍感知器的论文（可以说是迈向神经网络的第一步）将输入称为刺激，但也指出将刺激编码为一小组强大的特征有助于提高性能：  随着系统中响应数量的增加，如果每个响应都与所有替代方案相互排斥，那么性能会逐渐变差。避免这种恶化的一种方法（在 Rosenblatt，15 中有详细描述）是通过响应的二进制编码。在这种情况下，我们不是用 100 个不同的、相互排斥的反应来表示 100 种不同的刺激模式，而是找到有限数量的区分特征，每个特征都可以独立地识别为存在或不存在，并且因此可以用一对互斥的响应来表示。  （突出显示是我的） 稍后得出结论  可以通过使用轮廓敏感投影区域以及通过使用二元响应系统来改进系统的性能，其中每个响应或“位”都由二元响应系统来改进。对应于刺激的某些独立特征或属性。  （突出显示我的）   由   提交 /u/FirefoxMetzger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co2ye4/d_where_does_the_term_feature_come_from/</guid>
      <pubDate>Thu, 09 May 2024 17:35:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>