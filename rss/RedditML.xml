<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 05 Jun 2024 09:17:42 GMT</lastBuildDate>
    <item>
      <title>[R] 如何理解整个软件仓库？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8l2jj/r_how_to_understand_whole_software_repository/</link>
      <description><![CDATA[      我们很高兴地介绍我们的最新论文《如何理解整个软件存储库？》，其中提出了一种名为RepoUnderstander的新型自动软件工程（ASE）方法，可指导代理全面理解使用基于蒙特卡洛树搜索的策略对整个存储库进行性能测试。与之前的 SOTA 方法 SWE-agent 相比，RepoUnderstander 在 SWE-bench Lite 基准测试中取得了 18.5% 的相对提升。 更多详情请访问： 📄 论文：https://arxiv.org/abs/2406.01422 🤖 Github：https://github.com/RepoUnderstander/RepoUnderstande https://preview.redd.it/uzy4ldtztp4d1.png?width=1928&amp;format=png&amp;auto=webp&amp;s=7fd179e1441deb70c9cc09714a10ad76e26981b4    提交人    /u/tnlin   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8l2jj/r_how_to_understand_whole_software_repository/</guid>
      <pubDate>Wed, 05 Jun 2024 08:41:59 GMT</pubDate>
    </item>
    <item>
      <title>使用人工智能重新创建复杂形式 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8kh9g/recreate_a_complex_form_using_ai_r/</link>
      <description><![CDATA[市场上哪个模型最好，可以理解非常详细的问卷中的数据，该问卷在文本、数字、字母数字类型的多个部分下有大约 1500 个字段。  我想重新创建表单并对其进行优化，因为它有很多重复的问题，有些字段可以自动计算但仍被提及，有些语言很复杂。需要简化输入表格。如果模型可以创建实际优化的表单就更好了。  试过了 ChatGPT 4 和 Claude。两者都搞砸了。    提交人    /u/Dropout_PM   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8kh9g/recreate_a_complex_form_using_ai_r/</guid>
      <pubDate>Wed, 05 Jun 2024 07:58:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们如何微调 LLM 来只回答特定领域的问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8kbw9/d_how_do_people_fine_tune_llms_to_only_answer/</link>
      <description><![CDATA[所以我是 LLM 的新手，每天都在学习新东西，比如 RAG 系统之类的东西。 我现在正在尝试使用 OpenAI API 创建一个聊天机器人，该聊天机器人应该回答特定于特定格式的 PDF 的问题。例如，假设我想制作一个聊天机器人，它只响应与研究论文相关的提示，如“总结目标部分”或“为这个特定项目撰写研究论文”等。 我应该为此实施 RAG 系统吗？或者也许有一种更简单的方法，只需在发送给 LLM 的系统消息中添加限制？ 我在一些网站上看到过这样的实现，如果有人问的问题不在特定用例的范围内，那么 LLM 会回复“我无法提供帮助”之类的内容。 如果有人能帮助阐明这一点，那将会非常有帮助。 谢谢！    提交人    /u/AffectionateTwo9243   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8kbw9/d_how_do_people_fine_tune_llms_to_only_answer/</guid>
      <pubDate>Wed, 05 Jun 2024 07:47:44 GMT</pubDate>
    </item>
    <item>
      <title>[N] 加入我们即将举行的网络研讨会：从云到芯片：将 LLM 引入边缘设备。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8k9t0/n_join_our_upcoming_webinar_from_cloud_to_chip/</link>
      <description><![CDATA[从云到边缘的转变代表了大型语言模型 (LLM) 部署的范式转变。通过利用硬件和软件方面的进步、优化模型和解决安全问题，我们可以充分利用边缘设备上 LLM 的潜力。欢迎于 6 月 26 日下午 3 点 (GMT+2) 加入我们，探索这些突破性的发展，并从行业专家那里获得宝贵的见解。 在此处查找有关网络研讨会的更多信息并注册：https://www.embedl.com/events/webinar-from-cloud-to-chip-bringing-llms-to-edge-devices    提交人    /u/Embedl   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8k9t0/n_join_our_upcoming_webinar_from_cloud_to_chip/</guid>
      <pubDate>Wed, 05 Jun 2024 07:43:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 Android SDK 中加密 PTL 文件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8ju6v/d_how_can_you_encrypt_ptl_files_in_android_sdk/</link>
      <description><![CDATA[想要加密离线 ptl 文件，Java 的 pytorch libs 中是否有可以这样做的功能？    提交人    /u/Ok_Environment9442   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8ju6v/d_how_can_you_encrypt_ptl_files_in_android_sdk/</guid>
      <pubDate>Wed, 05 Jun 2024 07:10:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 智能 Go-Explore：大型语言模型代理的新型探索框架！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8j2pm/r_intelligent_goexplore_new_exploration_framework/</link>
      <description><![CDATA[标题：智能围棋探索：站在巨人基础模型的肩膀上 作者： Cong Lu、Shengran Hu、Jeff Clune。 代码： https://github.com/conglu1997/intelligent-go-explore 网站： https://conglu.co.uk/intelligentgoexplore/ 论文： https://arxiv.org/abs/2405.15143 摘要：Go-Explore 是一组功能强大的算法，旨在解决难以探索的问题，其原理是存档已发现的状态，并迭代返回最有希望的状态并从中进行探索。这种方法在包括 Atari 游戏和机器人控制在内的各种具有挑战性的问题中都取得了超人的表现，但需要手动设计启发式方法来指导探索，这既耗时又不可行。为了解决这个问题，我们提出了智能 Go-Explore (IGE)，它通过用巨型基础模型 (FM) 捕获的智能和内化的人类兴趣概念取代这些启发式方法，大大扩展了原始 Go-Explore 的范围。这为 IGE 提供了一种类似人类的能力，即使在启发式难以定义的复杂环境中，也能本能地识别任何新状态的有趣程度或前景（例如发现新物体、位置或行为）。此外，IGE 提供了令人兴奋的、以前不可能的机会来识别和利用无法提前预测的偶然发现。我们在一系列需要搜索和探索的语言任务上评估了 IGE。在 Game of 24 这个多步骤数学推理问题中，IGE 达到 100% 的成功率，比最佳经典图形搜索基线快 70.8%。接下来，在 BabyAI-Text 这个具有挑战性的部分可观察网格世界中，IGE 以比之前的 SOTA 少几个数量级的在线样本超越了之前的 SOTA。最后，在 TextWorld 中，我们展示了 IGE 在需要长期探索的环境中取得成功的独特能力，而之前的 SOTA FM 代理（如 Reflexion）则完全失败了。总体而言，IGE 结合了 FM 的巨大优势和强大的 Go-Explore 算法，开辟了研究的新前沿，以创建具有令人印象深刻的探索能力的更通用的代理。    提交人    /u/MolassesWeak2646   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8j2pm/r_intelligent_goexplore_new_exploration_framework/</guid>
      <pubDate>Wed, 05 Jun 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 测量大型语言模型的社会规范</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8ifsd/r_measuring_social_norms_of_large_language_models/</link>
      <description><![CDATA[作者： 袁野，唐可欣，沈建豪，张明，王晨光  论文： https://arxiv.org/abs/2404.02491 数据集： https://huggingface.co/datasets/socialnormdataset/social 代码： https://github.com/socialnormdataset/socialagent  摘要：我们提出了一个新的挑战，以检验大型语言模型是否理解社交规范。与现有数据集相比，我们的数据集需要对社会规范有基本的了解才能解决。我们的数据集具有最大的社会规范技能集，包括 402 项技能和 12,383 个问题，涵盖了从观点和论点到文化和法律的广泛社会规范。我们根据 K-12 课程设计数据集。这使得可以直接将大型语言模型的社会理解与人类（更具体地说是小学生）进行比较。虽然先前的工作在我们的基准上产生了几乎随机的准确性，但最近的大型语言模型（如 GPT3.5-Turbo 和 LLaMA2-Chat）能够显着提高性能，仅略低于人类性能。然后，我们提出了一个基于大型语言模型的多智能体框架，以提高模型理解社会规范的能力。该方法进一步改进了大型语言模型，使其与人类相提并论。鉴于大型语言模型在现实世界应用中的采用越来越多，我们的发现尤为重要，并为未来的改进提供了独特的方向。    提交人    /u/shizue_yy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8ifsd/r_measuring_social_norms_of_large_language_models/</guid>
      <pubDate>Wed, 05 Jun 2024 05:36:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 ImageNet 上，仅从图像进行无监督的通用表征学习的现状如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8hpqg/d_what_is_the_status_of_unsupervised_general/</link>
      <description><![CDATA[最近我研究了一个，当在其上训练一个线性输出层（同时冻结主干）时，它在 ImageNet 上的准确率达到了 30%，这让我很想知道它与该领域的其他产品相比如何，但我所能找到的都是从其他数据集进行某种知识转移的论文。 我所说的“通用表示学习”不是专为图像设计的东西。    提交人    /u/YanaiEliyahu   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8hpqg/d_what_is_the_status_of_unsupervised_general/</guid>
      <pubDate>Wed, 05 Jun 2024 04:51:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 直接迭代反演</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8asl8/p_inversion_by_direct_iteration/</link>
      <description><![CDATA[很高兴介绍我参与的一个附带项目，该项目使用直接迭代反演从 8 位图像中去除色带。使用的数据集少于 2000 张图像，模型有 140 万个参数。我一直在测试基于扩散的模型的计算下限，INDI 确实为我提供了很好的帮助。 https://github.com/ksasso1028/indi-debanding    提交人    /u/somethingwrongwifme   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8asl8/p_inversion_by_direct_iteration/</guid>
      <pubDate>Tue, 04 Jun 2024 22:56:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 比较 Darknet/YOLO 和 YOLOv10</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8a22c/d_comparing_darknetyolo_and_yolov10/</link>
      <description><![CDATA[我最近在 YouTube 上发布了一个视频，展示了 Darknet/YOLO 和 Ultralytics/YOLOv10 之间的一些区别。 TLDR：Darknet/YOLO 仍然比最新的基于 Python 的 YOLO 框架更快、更精确。 https://www.youtube.com/watch?v=2Mq23LFv1aM 如果有人对 Darknet/YOLO 感兴趣，我曾经在 reddit 上维护过一篇充满 Darknet/YOLO 信息的帖子。我已经有一段时间没有更新它了，但是信息仍然有效：https://www.reddit.com/r/computervision/comments/yjdebt/lots_of_information_and_links_on_using_darknetyolo/    提交人    /u/StephaneCharette   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8a22c/d_comparing_darknetyolo_and_yolov10/</guid>
      <pubDate>Tue, 04 Jun 2024 22:24:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 一种无需阈值调节的神经网络结构化剪枝新方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d85eqd/r_a_new_method_for_structured_pruning_of_neural/</link>
      <description><![CDATA[https://arxiv.org/abs/2406.01345 我们很高兴与大家分享我们的成果“BMRS：结构化剪枝的贝叶斯模型简化”。结构化剪枝通过移除对输出影响有限的整个网络结构（例如神经元或卷积滤波器）来提高神经网络效率。我们提出了一种结构化剪枝的贝叶斯方法，该方法自动确定要剪枝的结构。这是通过将贝叶斯结构化剪枝与对数乘性噪声和贝叶斯模型简化相结合来实现的。  该论文的代码可以在这里获得：https://github.com/saintslab/bmrs-structured-pruning    由   提交  /u/ewits   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d85eqd/r_a_new_method_for_structured_pruning_of_neural/</guid>
      <pubDate>Tue, 04 Jun 2024 19:12:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] mamba.np：Mamba 的纯 NumPy 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d80t26/p_mambanp_pure_numpy_implementation_of_mamba/</link>
      <description><![CDATA[      mamba.np 受到一些很棒的项目的启发，我用纯 Numpy 从头实现了 Mamba。代码的目标是简单、可读、轻量，因为它可以在本地 CPU 上运行。 https://github.com/idoh/mamba.np 希望您觉得它有用 :)    提交人    /u/id0h   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d80t26/p_mambanp_pure_numpy_implementation_of_mamba/</guid>
      <pubDate>Tue, 04 Jun 2024 16:02:19 GMT</pubDate>
    </item>
    <item>
      <title>[R]xLSTM官方代码+Kilcher视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7zppm/r_xlstm_official_code_kilcher_video/</link>
      <description><![CDATA[论文，仅供参考，即将更新（根据视频 - 见下文）： https://arxiv.org/pdf/2405.04517 NX-AI 终于为他们的 xLSTM 实现发布了一个 python 包： https://github.com/nx-ai/xlstm Yannic Kilcher 还发布了一段新视频解释该论文： https://www.youtube.com/watch?v=0OaEv1a5jUM 有人重现了这篇论文的结果吗？我发现 sLSTM 是对 vanilla LSTM 的巨大改进，但我无法让 mLSTM 单独工作。     提交人    /u/Builder_Daemon   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7zppm/r_xlstm_official_code_kilcher_video/</guid>
      <pubDate>Tue, 04 Jun 2024 15:17:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] 图像超分辨率数据集修剪研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7st4v/r_a_study_in_dataset_pruning_for_image/</link>
      <description><![CDATA[我们很高兴与大家分享我们最近的作品《图像超分辨率数据集修剪研究》，该作品已被 ICANN 2024 接受 :) 我们引入了一种基于损失值的采样方法，该方法将训练数据集缩减为由简单的预训练 SRCNN 模型确定的核心集（原始数据集的 50%）。通过专注于包含高损失值（即“困难样本”），我们获得的结果可与对完整数据集进行训练获得的结果相媲美甚至超过这些结果。此外，我们发现最难样本的前 5% 会对训练产生负面影响。排除这些样本可进一步增强结果，或者简而言之，选择 45-95% 的最难样本部分可获得最佳训练质量。我们希望为图像 SR 中数据集修剪的未开发潜力开辟新的视角，并为其他领域提供新的想法。 arXiv：https://arxiv.org/abs/2403.17083    提交人    /u/Maleficent_Stay_7737   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7st4v/r_a_study_in_dataset_pruning_for_image/</guid>
      <pubDate>Tue, 04 Jun 2024 09:14:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>