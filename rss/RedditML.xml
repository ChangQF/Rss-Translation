<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 14 Sep 2024 03:17:30 GMT</lastBuildDate>
    <item>
      <title>[D] 非基于订阅的人工智能模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fga0tq/d_non_subscription_based_ai_model/</link>
      <description><![CDATA[嗨！ 我想训练自己的 AI 模型，但我没有从头开始创建学习机器的编码经验。 我想在自己的计算机上训练自己的模型，而不需要依赖第三方保存我的模型数据，也不需要依赖其他任何对我的模型有访问权/权限的人。例如，我停止订阅，我失去了访问权限，或者必须获得使用我自己给模型的数据的许可 -  是否有任何 AI 模型我可以购买并下载到自己的计算机上，而无需基于订阅？就像您购买软件并拥有在该软件上创建的任何东西一样？ 谢谢！    提交人    /u/_Belgarion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fga0tq/d_non_subscription_based_ai_model/</guid>
      <pubDate>Sat, 14 Sep 2024 00:38:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 提高 Whisper/STT 在具有挑战性的音频上的表现的策略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fg8qtb/d_strategies_for_improving_whisperstt_performance/</link>
      <description><![CDATA[我正在做一个项目，涉及转录来自各种来源的音频，包括低质量录音和有背景噪音的音频。虽然 Whisper 总体上令人印象深刻，但我正在寻找进一步提高转录准确性的方法，尤其是对于更具挑战性的音频输入。一个大问题是我收到了很多“谢谢”以及转录中的此类内容。 我正在考虑的一些方法：  根据领域特定数据对 Whisper 进行微调 预处理音频（降噪、标准化等） 结合多种 STT 模型的集成方法 使用 LLM 对转录本进行后处理  我很想听听其他致力于优化 STT 管道的人的意见：  您发现哪些技术对提高准确性最有效？ 有没有一些不太常见的方法效果很好？ 您如何处理非常嘈杂或低质量的音频输入？ 有任何关于评估和基准测试 STT 改进的提示吗？  提前感谢您的任何见解！我正在这个领域开展一个开源项目（如果有兴趣，请访问 https://github.com/mediar-ai/screenpipe），但主要想学习这里社区的经验。    提交人    /u/louis3195   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fg8qtb/d_strategies_for_improving_whisperstt_performance/</guid>
      <pubDate>Fri, 13 Sep 2024 23:33:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] Windows Agent Arena：计算机上运行的 AI 代理的基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fg899x/r_windows_agent_arena_a_benchmark_for_ai_agents/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fg899x/r_windows_agent_arena_a_benchmark_for_ai_agents/</guid>
      <pubDate>Fri, 13 Sep 2024 23:10:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言模型中的因果理解框架方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fg7kvj/r_approach_of_a_causal_understanding_framework_in/</link>
      <description><![CDATA[我开发了一个框架，想与大家分享，特别是因为我发现决策和迭代的过程非常迷人。它基于结构化问题解决和因果分析，目的是找到完美的解决方案。 项目：https://github.com/stevius10/ReasoningModel 框架：https://github.com/stevius10/ReasoningModel/blob/main/reasoning_model.json 当然，这不是“完美”的解决方案（第二好），而是完美的解决方案。我会等待评论中第一个提出质疑的人。 😉 这个框架的核心是什么？这个框架提供了一种结构化的方法，用于引导高级语言模型（如 ChatGPT）超越仅仅模仿人类交流。这个框架不是只专注于复制类似人类的措辞，而是使模型能够利用其庞大的训练数据从语言的更深层结构中提取因果见解。 它提供了一种方法来区分驱动决策的基本因果信息和可能掩盖这些潜在动态的明确语言模式。通过应用这个框架，模型可以参与迭代学习和自我反思的过程，不断完善对这些更深层因果机制的理解，最终随着时间的推移产生更精确、更符合语境的结果。 如果您好奇，请随意尝试一下：输入一个问题，点击“继续”几次，然后观察答案如何演变。这个过程可能会让你大吃一惊——或者开辟一个全新的视角。 附注：对于那些更喜欢记忆而不是光学的人来说，你可以以结构化数据格式获得输出。该模型“复制”自身并随着时间的推移管理知识。换句话说：记忆和复杂关联的关键是结构——字面上。    提交人    /u/stevius10   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fg7kvj/r_approach_of_a_causal_understanding_framework_in/</guid>
      <pubDate>Fri, 13 Sep 2024 22:38:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 小型解码器专用模型 < 1B 参数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fg7dh0/d_small_decoderonly_models_1b_parameters/</link>
      <description><![CDATA[是否有任何仅用于解码器的 llama、mistral、gemma 或其他具有 &lt; 1B 参数的解码器？ 有什么建议吗，特别是那些擅长多语言任务的？    提交人    /u/alvations   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fg7dh0/d_small_decoderonly_models_1b_parameters/</guid>
      <pubDate>Fri, 13 Sep 2024 22:28:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] 尝试复制“Stretch Each Dollar”扩散论文，遇到问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ffz5xc/p_attempting_to_replicate_the_stretching_each/</link>
      <description><![CDATA[      我正在尝试复制这篇论文：https://arxiv.org/pdf/2407.15811 您可以在此处查看我的代码：https://github.com/SwayStar123/microdiffusion/blob/main/microdiffusion.ipynb 我首先对 9 幅图像进行过拟合以确保完整性，但在较低的掩蔽率下，我无法复制论文中的结果 在掩蔽率为 1.0 时，即所有补丁都被 Transformer 主干网看到，它对 9 幅图像进行了很好的过拟合 https://preview.redd.it/thteqn3rhlod1.png?width=1066&amp;format=png&amp;auto=webp&amp;s=215fc88c74728f5f0dcfbd05a9b6a4db836b1f84 存在一些轻微的扭曲，但也许一些 LR 调度会有所帮助，主要问题是当掩蔽率降低到 0.75 时，输出严重下降： https://preview.redd.it/ukcexjbyhlod1.png?width=1066&amp;format=png&amp;auto=webp&amp;s=432187000cde0ba5b1b90813c6284c9f764a9979 在掩蔽比为 0.5 时，情况甚至更糟： https://preview.redd.it/00kzbpc0ilod1.png?width=1066&amp;format=png&amp;auto=webp&amp;s=0717f8926582b2b5c694ebe5609b6f9fba8a088d 所有这些都经过相同步数的训练，除了掩蔽率之外，所有超参数都是相同的 注意：我使用“掩蔽率”表示 Transformer 主干看到的补丁百分比，与论文中隐藏的补丁百分比相反。我几乎可以肯定这不是问题 我也使用 x 预测目标而不是噪声预测，就像论文中一样，但这并不重要，而且它可以在 1.0 掩蔽率下工作。 增加补丁混合层的数量没有帮助，如果有的话，它会使情况变得更糟 2 个补丁混合层，0.5 掩蔽率： https://preview.redd.it/punkf59uilod1.png?width=1066&amp;format=png&amp;auto=webp&amp;s=04e0ea03d9ecd464f1bd007f7957c4a65c0ae9c2 4 个补丁混合层，0.5 遮罩比： https://preview.redd.it/9ihtiyvejlod1.png?width=1066&amp;format=png&amp;auto=webp&amp;s=c78efb039b6ef630a3760dca60e2018d32e6c3b7 也许补丁混合器本身有问题？使用 TransformerEncoderLayer 作为补丁混合器是不是一个坏主意？    提交者    /u/SwayStar123   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ffz5xc/p_attempting_to_replicate_the_stretching_each/</guid>
      <pubDate>Fri, 13 Sep 2024 16:36:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从产品图像中提取文本的最佳 OCR 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ffz2ca/p_best_ocr_model_for_text_extraction_from_images/</link>
      <description><![CDATA[我目前尝试过 Tesseract，但性能不太好。有人能告诉我还有什么其他替代方案吗？如果可能的话，请告诉我一些在其模型中不使用 API 调用的模型。 此外，如果您可以推荐一些可以执行相同操作的 llava 模型，也将非常有益。    提交人    /u/Chuggleme   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ffz2ca/p_best_ocr_model_for_text_extraction_from_images/</guid>
      <pubDate>Fri, 13 Sep 2024 16:32:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 根据数据冗余优化下一帧预测任务的计算成本。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ffxi3w/d_optimising_computational_cost_based_on_data/</link>
      <description><![CDATA[假设我有一个生成网络，负责预测视频的下一帧。一种解决方法是，在前向传递中，简单地传递当前帧并请求下一帧 — 可能取决于某些操作（如 GameNGen）。在这种方法中，所有帧的计算成本相同 — 严重限制了我们可以操作的帧速率。然而，在更高的帧速率下，帧之间的变化要小得多 — 平均而言，在 60 fps 下，下一帧明显更接近前一帧（因此我认为更容易预测） — 而不是在 10 fps 下进行预测。这让我想到了一个问题，如果我有一个以预测编码方式运行的网络 — 它试图预测下一帧并将结果预测误差作为前馈输入。在更高的帧速率下，要处理的误差逐帧更小 — 但张量形状将与图像的形状相同。当我的错误较小时，什么样的方法可以让我的计算效率更高？直觉是“如果你的预测正确，你不应该偏离你当前建模的轨迹太多 - 如果你的预测误差很大，我们需要进行更广泛的计算。”    提交人    /u/Karioth1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ffxi3w/d_optimising_computational_cost_based_on_data/</guid>
      <pubDate>Fri, 13 Sep 2024 15:26:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 监控视频摘要器：基于 VLM 的视频分析和摘要</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ffsqvb/p_surveillance_video_summarizer_vlmpowered_video/</link>
      <description><![CDATA[大家好！ 我一直在研究一个 VLM 驱动的系统，该系统处理监控视频、提取帧并生成详细注释以突出显示值得注意的事件、动作和对象。此应用由经过微调的 Florence-2 视觉语言模型 (VLM) 提供支持，我专门针对 SPHAR 数据集对其进行了训练。并且，它利用 OpenAI API 来总结和提取最相关的内容，确保全面、连贯地概述监控录像。 链接： 📺 查看我们的演示视频以了解实际效果！ 📂 这是 GitHub 存储库，其中包含所有详细信息。  **📣 工作原理：** * **帧提取**：使用 OpenCV 定期从视频文件中提取帧。 * **AI 注释**：每个帧都由经过微调的 Florence-2 模型分析，生成场景的精确注释。 * **数据存储**：注释和帧数据存储在 SQLite 数据库中，方便检索和未来分析。 * **Gradio 支持的界面**：通过基于 Gradio 的 Web 界面轻松与系统交互。通过指定时间范围，您可以检索带有全面分析的详细日志。该界面利用 OpenAI API 来总结视频内容，通过分析帧序列来确保时间连贯性，从而可以更加从情境上理解镜头中捕获的事件。 可用的微调模型：https://huggingface.co/kndrvitja/florence-SPHAR-finetune-2    提交人    /u/BriefAd4761   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ffsqvb/p_surveillance_video_summarizer_vlmpowered_video/</guid>
      <pubDate>Fri, 13 Sep 2024 11:49:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习用于药物发现是一条好途径吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ffqy6y/d_ml_for_drug_discovery_a_good_path/</link>
      <description><![CDATA[我现在看到很多初创公司（大大小小的）都专注于将机器学习用于药物发现/将机器学习用于生物应用，并且想知道应用机器学习研究在这个领域的范围。   是否存在成熟的问题陈述，实际上需要机器学习研究来解决它们，它们是什么（我当然熟悉 Alpha 折叠/蛋白质折叠工作，但考虑到这个问题已经解决了，是否还有其他活跃的研究领域） 这些问题陈述是否仅限于研究实验室（虽然是扎实的研究，但它们具有狭窄的特定用例），还是它们解决了行业范围  考虑到医疗保健领域的监管要求，a）是否有现成的数据，以及 b）这些问题的解决方案是否真的可以投入生产/成为产品？   我目前从事一般应用机器学习研究（具有 CV/NLP/多模态）经验，并且正在考虑是否投资转型到药物发现领域，因为我过去在医疗保健领域确实有经验。我在大型制药公司中看到过许多类似的职位，他们正在探索人工智能，但通常这些类型的公司缺乏坚实的人工智能技术领导力，最终基于现有的开源工具构建 POC 解决方案。我很想听听在药物发现问题方面拥有深厚技术专长的人工智能优先公司或研究实验室的人们的意见。     提交人    /u/panther-banter   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ffqy6y/d_ml_for_drug_discovery_a_good_path/</guid>
      <pubDate>Fri, 13 Sep 2024 09:59:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 时间序列预测：从业者如何选择最佳模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ffnl2g/d_time_series_forecasting_how_do_practitioners/</link>
      <description><![CDATA[在这里向预测从业者提问——当您使用 AutoML 进行预测模型时，您通常信任它建议的模型，还是运行“几个最佳模型”来找出最适合您的模型？我之所以问这个问题，是因为 AutoML 模型似乎具有基于准确性的重点；它们将返回最佳模型，该模型将根据您选择的指标产生最佳分数。但很多时候，如果我错了，请纠正我，这些指标可能不会直接帮助从业者决定最佳模型。我想知道通常使用什么方法来实现这一点。 注意：我了解许多基于云的预测服务没有明确提及所选的模型。但是，如果您要在本地运行这样的模型，您将如何处理？ 谢谢！    提交人    /u/americast   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ffnl2g/d_time_series_forecasting_how_do_practitioners/</guid>
      <pubDate>Fri, 13 Sep 2024 05:50:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在实践中如何有效地存储剪枝后的权重矩阵？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ffi51d/d_how_to_efficiently_store_pruned_weight_matrices/</link>
      <description><![CDATA[大家好， 我目前正在努力修剪神经网络，通过消除一些连接（将一些权重设置为零）来提高其效率。但是，我正在努力寻找如何有效地存储这些修剪后的权重矩阵。 我知道，例如，PyTorch 支持存储稀疏矩阵，其工作方式是跟踪非零值及其对应的索引。但我担心的是：存储非零权重的索引是否会抵消一些节省空间的好处？例如，如果矩阵的一半由非零值组成，那么节省的空间是否会被存储这些值的索引的需要所抵消？ 我是否遗漏了有关修剪在实践中应该如何工作的某些信息，尤其是对于矩阵中大约 50% 非零值的情况？您通常如何在实践中实施修剪以真正节省存储空间？关于如何有效地存储这些矩阵的任何建议或建议都将不胜感激。 提前致谢！ TL;DR：如何有效地存储修剪后的权重矩阵，而不会因存储非零值的索引而失去空间节省？    提交人    /u/scarlettgarnett   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ffi51d/d_how_to_efficiently_store_pruned_weight_matrices/</guid>
      <pubDate>Fri, 13 Sep 2024 00:47:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 的新推理模型称为 o1</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ff8f7v/d_openai_new_reasoning_model_called_o1/</link>
      <description><![CDATA[OpenAI 发布了一种据称更善于推理的新模型，您的看法是什么？ https://x.com/OpenAI/status/1834278217626317026    提交人    /u/IIAKAD   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ff8f7v/d_openai_new_reasoning_model_called_o1/</guid>
      <pubDate>Thu, 12 Sep 2024 17:36:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 08 Sep 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>