<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 22 Jan 2024 15:14:48 GMT</lastBuildDate>
    <item>
      <title>[P] 我通读了所有 NeurIPS 2023 摘要并撰写了相关内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cxibs/p_i_read_through_all_neurips_2023_abstracts_and/</link>
      <description><![CDATA[我制作了这个资源，我认为在这里可能非常有用，特别是对于那些希望找到一些新的、相关的作品来阅读或用于自己的人来说项目。它讨论了大约 300 篇论文的内容，但主题广泛涉及所有 NeurIPS 2023。祝您阅读愉快！ 链接：https://alexzhang13.github.io/blog/2024/neurips2023   由   提交 /u/ZhalexDev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cxibs/p_i_read_through_all_neurips_2023_abstracts_and/</guid>
      <pubDate>Mon, 22 Jan 2024 14:59:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 提示中最重要的说明应该放在哪里？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cx8y6/r_where_to_place_the_most_important_instructions/</link>
      <description><![CDATA[大家好，我们知道提示中（例如在 gpt4 情况下）最重要指令的最佳位置在哪里吗？是否存在某种通过实验观察到的遗忘模式？或者这种模式有一些理论基础吗？ 例如在RAG系统中，检索到的文档可能会形成一大块令牌限制，我们是否将回答指令放在文档之前或之后？我们如何根据相关性对提示中的文档进行排序？   由   提交 /u/RippSir   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cx8y6/r_where_to_place_the_most_important_instructions/</guid>
      <pubDate>Mon, 22 Jan 2024 14:47:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 提前停止但是什么时候？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cx4ol/d_early_stopping_but_when/</link>
      <description><![CDATA[你好， 我最近一直在尝试寻找比耐心和增量值更好的提前停止方法，并且我偶然发现这篇论文 https://page.mi.fu-berlin.de/prechelt/Biblio/ stop_tricks1997.pdf 。鉴于本文中提到的标准，我发现继续采用这种方法是非常合乎逻辑的。我还碰巧注意到这是一篇非常古老的论文，似乎没有一个主要平台考虑这里的实现。我完全不明白为什么这不是一个有效的方法吗？    由   提交/u/Bhargav_28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cx4ol/d_early_stopping_but_when/</guid>
      <pubDate>Mon, 22 Jan 2024 14:41:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们没有看到很多关于 Mamba 架构的内容？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cwf65/d_why_were_not_seeing_a_lot_of_content_about/</link>
      <description><![CDATA[比如对作者的一些采访？还没有看到例如TWIML AI 播客谈论 Mamba 架构。   由   提交/u/_learning_stuff_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cwf65/d_why_were_not_seeing_a_lot_of_content_about/</guid>
      <pubDate>Mon, 22 Jan 2024 14:07:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] ARR 2023 年 12 月（NAACL 2024）讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cvxz4/d_arr_2023_december_naacl_2024_discussion/</link>
      <description><![CDATA[评论应该在今天发布。   由   提交 /u/Street-Judgment7640    reddit.com/r/MachineLearning/comments/19cvxz4/d_arr_2023_december_naacl_2024_discussion/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cvxz4/d_arr_2023_december_naacl_2024_discussion/</guid>
      <pubDate>Mon, 22 Jan 2024 13:44:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 超越变形金刚：结构化状态空间序列模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cv8q6/d_beyond_transformers_structured_state_space/</link>
      <description><![CDATA[我写了一篇文章解释状态空间序列模型的基础知识。本文的目的是以简化的方式呈现基础级别的概念。该领域在人工智能领域正在迅速发展，因为它在速度和内存消耗方面超越了 Transformer 架构。以下是文章链接：https://cnichkawde.github.io/statespacesequencemodels.html  &lt; /div&gt;  由   提交 /u/cnichkawde   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cv8q6/d_beyond_transformers_structured_state_space/</guid>
      <pubDate>Mon, 22 Jan 2024 13:07:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] GPT-4V API 如何处理大图像？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ctr9p/r_how_does_the_gpt4v_api_deal_with_large_images/</link>
      <description><![CDATA[我想将不同尺寸的信息图表传递给 GPT4V 模型。我不确定要设置什么尺寸以及如何使我的成本尽可能低。这些图像可以变得非常大，达到 5000 像素范围，并且也可以具有不同的像素比。 - 我应该考虑什么设置？ - 我将相同的图像输入到 ChatGPT Plus，它表现良好，但不知何故我似乎无法找出 OpenAI API 的适当设置。 PS：如果您能帮助我解决 Llava、Bakllava、Blip2、InstructBLIP 等多模式模型的问题，我将不胜感激&lt; /p&gt;   由   提交 /u/Conclusion_Silent   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ctr9p/r_how_does_the_gpt4v_api_deal_with_large_images/</guid>
      <pubDate>Mon, 22 Jan 2024 11:42:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 容器中的机器学习开发</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ctbuq/d_ml_dev_in_containers/</link>
      <description><![CDATA[与其他许多人一样，我也陷入了困境，我有一个可以通过 SSH 访问的 Linux 开发环境（非常棒的机器），但是那里相对来说是裸机，并且带有 docker、Nvidia 驱动程序和一些 python。问题是：一切都是离线的。 我不再试图猜测并提出八个版本等，而是努力追求使用容器（只需要确认与 nvidia 驱动程序的兼容性）。 &gt; 我有两个主要问题：  NGC Container for PyTorch 与 Docker Hub 上的 PyTorch 相比有什么好处吗？我确实喜欢开发基础构建，因为它有额外的驱动程序和构建工具。 对于“远程”开发工作，我看到两个选项：“开发容器”和 Jupyter 实验室。   ol&gt; 开发容器 我担心确认离线支持，但很多人喜欢完整的 IDE。 Jupyter Lab 除了笔记本之外，我没有太多经验。 Jupyter python IDE 是否提供代码补全和语法突出显示等功能？ 欢迎任何见解。 https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch https://hub.docker.com/layers /pytorch/pytorch/2.0 .1-cuda11.7-cudnn8-devel/images/sha256-4f66166dd757752a6a6a9284686b4078e92337cd9d12d2e14d2d46274dfa9048?context=explore   由   提交 /u/SuperbMonk4403   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ctbuq/d_ml_dev_in_containers/</guid>
      <pubDate>Mon, 22 Jan 2024 11:14:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] ML 编码项目网站？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19csu68/p_site_for_ml_coding_project/</link>
      <description><![CDATA[您好，有人可以建议我在哪里可以找到一些使用 ML（最好是 Python）的项目吗？我觉得我现在对这个理论还算满意，但到目前为止我只在课程/填充笔记本中经历过编码，我现在想从头开始自己构建一些东西。建议？谢谢   由   提交 /u/risilm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19csu68/p_site_for_ml_coding_project/</guid>
      <pubDate>Mon, 22 Jan 2024 10:41:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我写了一篇关于 LLM 评估指标的所有知识的文章</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19csc4x/d_i_wrote_an_article_on_everything_i_know_about/</link>
      <description><![CDATA[大家好，过去 6 个月我一直在 LLM 评估领域不间断地工作，从培训定制 LLM 进行评估到构建评估OpenAI 的 GPT 模型之上的指标。我写了一篇长文，介绍了我所知道的有关 LLM 评估指标的一切，我希望有人觉得这篇文章有用，可能是出于兴趣，也可能是在工作中。如果您发现它有用或有任何问题/建议，请告诉我！ 以下是文章的链接：https://medium.com/@jeffreyip54/llm-evaluation-metrics-everything-you-need-for-llm-evaluation-6b129157e33c&lt; /a&gt; 谢谢！   由   提交/u/Ok_Constant_9886   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19csc4x/d_i_wrote_an_article_on_everything_i_know_about/</guid>
      <pubDate>Mon, 22 Jan 2024 10:05:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 chatGPT 之后，人们现在还在创建自己的新的自定义 NLP 模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cqde6/d_after_chatgpt_are_people_still_creating_their/</link>
      <description><![CDATA[对使用 scikit-learn 和 Tensorflow 训练 ML 和 DL 模型有点脱节。只是想知道 ML 工程师是否仍在训练他们自己的 NLP 模型（甚至 CV、预测、聚类模型等）。 如果是这样，您正在训练什么类型的模型？您正在解决哪些用例？如果您用 ChatGPT 替换自定义模型，进展如何？ 我想重新熟悉 ML 生态系统。很想听听您的想法。   由   提交 /u/automatonv1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cqde6/d_after_chatgpt_are_people_still_creating_their/</guid>
      <pubDate>Mon, 22 Jan 2024 07:41:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我应该如何融合两种截然不同的模态的预测向量？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cnsgm/r_how_should_i_fuse_prediction_vectors_from_two/</link>
      <description><![CDATA[我是这个领域的新手，我需要实现一个融合其他两个分类器的预测的分类器。 对于例如，我有模态 A（即图像帧）的分类器 A，模态 B（音频）的分类器 B。 单独的分类器 A 可以达到 90% 的准确率，但分类器 B 只能达到对于相同的测试数据，准确率为 66%。 分类器 A 的输出为 pred_A，其值类似于 -11.56, 8.73, -12.15, 10.07 ... 输出分类器 B 的值为 pred_B，其值类似于 -0,068， 0.091，-0.125，0.052 ... 融合 pred_A 和 pred_B 以获得更好的准确率的最佳方法是什么？ &lt; p&gt;我尝试直接添加这两个，但没有成功。然后，我在想是否应该首先连接这两个向量，然后在连接的向量之上堆叠一个额外的 torch.linear() 并训练所有内容，但仍然没有运气。 有人可以提供一些吗这里评论什么容易出错？我应该“正常化”吗？或“S形”在将这两个向量传递给 torch.linear() 或其他东西之前？ 提前致谢。   由   提交 /u/AaronSpalding   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cnsgm/r_how_should_i_fuse_prediction_vectors_from_two/</guid>
      <pubDate>Mon, 22 Jan 2024 05:00:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Apple Silicon 芯片进行设置的秘诀是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ce73y/d_whats_the_secret_to_getting_set_up_with_an/</link>
      <description><![CDATA[尝试设置 Docker 容器来训练 Magenta 模型，但我在使用 M 芯片和 Python 时遇到了很多问题。 我和 ChatGPT 最终会解决这个问题，但是每个人都在致力于此类事情吗？我已经花了 12 个小时，我最终会在 EC2 实例上完成所有操作吗？ 我不打算在 M 芯片上训练它，只是编写该死的 Python 并部署它   由   提交 /u/gullydowny   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ce73y/d_whats_the_secret_to_getting_set_up_with_an/</guid>
      <pubDate>Sun, 21 Jan 2024 21:23:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] VMamba：视觉状态空间模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cdcwz/r_vmamba_visual_state_space_model/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.10166 代码和模型： https:/ /github.com/MzeroMiko/VMamba 摘要：  卷积神经网络（CNN）和视觉变换器（ViT）是视觉表示学习的两个最流行的基础模型。虽然 CNN 表现出卓越的可扩展性和线性复杂度。尽管在图像分辨率方面，ViT 的拟合能力超过了它们，但其复杂性却是二次方。仔细观察发现，ViT 通过结合全局感受野和动态权重，实现了卓越的视觉建模性能。这一观察促使我们提出一种新颖的架构，该架构继承了这些组件，同时提高了计算效率。为此，我们从最近引入的状态空间模型中汲取灵感，提出了视觉状态空间模型（VMamba），该模型在不牺牲全局感受野的情况下实现了线性复杂性。为了解决所遇到的方向敏感问题，我们引入了交叉扫描模块（CSM）来遍历空间域并将任何非因果视觉图像转换为顺序补丁序列。大量的实验结果证实，VMamba 不仅在各种视觉感知任务中表现出有前景的能力，而且随着图像分辨率的提高，与既定基准相比也表现出更明显的优势。源代码可在 此 https URL 获取。  另一个 Vision Mamba ： https://redd.it/19bgoug   由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cdcwz/r_vmamba_visual_state_space_model/</guid>
      <pubDate>Sun, 21 Jan 2024 20:48:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>