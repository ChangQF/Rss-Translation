<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Fri, 02 Aug 2024 18:20:16 GMT</lastBuildDate>
    <item>
      <title>[D] SSM 和 RNN 之间的区别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eih75h/d_difference_between_ssms_and_rnns/</link>
      <description><![CDATA[大家好 :) 我目前正在深入研究状态空间模型。但是，我不太明白状态空间模型的离散化版本与传统 RNN 架构有何不同。隐藏状态更新本质上与之前的隐藏状态相同，新输入通过权重矩阵进行转换。 我唯一的猜测是离散化过程包含学习参数，这是与经典 RNN 的区别。但是，我不太确定这是否正确或有任何意义。直观地看，两者的公式在我看来非常相似。 你能帮我解释一下它们有什么区别吗？    提交人    /u/No_Individual_7831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eih75h/d_difference_between_ssms_and_rnns/</guid>
      <pubDate>Fri, 02 Aug 2024 18:19:08 GMT</pubDate>
    </item>
    <item>
      <title>CoRL 2024 评论 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eih0yf/corl_2024_reviews_discussion/</link>
      <description><![CDATA[CoRL 2024 评论已经出炉。你们怎么样了？ 我们得到了 4,4,3（2 次强烈拒绝，1 次一周拒绝）。这真的很令人沮丧，因为这是我作为本科生的第一篇主要论文，我们论文的第一个版本被 ICRA 接受了。    提交人    /u/oz_zey   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eih0yf/corl_2024_reviews_discussion/</guid>
      <pubDate>Fri, 02 Aug 2024 18:12:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助在 Azure Kubernetes 上扩展 LLM 推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eig5v6/d_help_scaling_llm_inference_on_azure_kubernetes/</link>
      <description><![CDATA[大家好， 我正在尝试更好地了解如何设置我们自己的内部无服务器基础架构，以部署 LLM（针对 Gemma2 和 Llama 3.1 变体）以实现可扩展推理。 为了解决问题： 我们有严格的数据隐私和管理要求，因此不能依赖 Groq、openrouter 等推理 API。 我正在尝试了解正确的架构和执行此操作的成本。  带有 KEDA 的 Azure Kubernetes 服务似乎是一个很好的解决方案，但我不确定自动缩放的成本和速度。 理想的情况是 KEDA 从 0 个节点扩展到所需的节点数，以维持每个请求每秒 20-40 个令牌，然后尽快回落 向其他开放建议/链接/想法  有人尝试过这样做吗？您能否从高层次上比较现成的 API 和高度可扩展/空闲待机解决方案之间的成本？ 我知道 localllama 喜欢 vllm/llma.cpp，但是否有其他推荐的 llm 推理服务器堆栈在生产中是首选？ 谢谢！    提交人    /u/chulpichochos   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eig5v6/d_help_scaling_llm_inference_on_azure_kubernetes/</guid>
      <pubDate>Fri, 02 Aug 2024 17:36:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为机器学习工程师最困难的事情是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eifnvj/d_what_is_the_hardest_thing_as_a_machine_learning/</link>
      <description><![CDATA[我刚刚开始我的机器学习之旅。为了练习，我从 Kaggle.com 获取数据，但我决定通过自己收集数据来进一步挑战自己。我发现收集大量数据非常具有挑战性。通常如何收集数据，还有什么比这更难的吗？    提交人    /u/3ATAE   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eifnvj/d_what_is_the_hardest_thing_as_a_machine_learning/</guid>
      <pubDate>Fri, 02 Aug 2024 17:16:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] NLP 论文的新常态是“提示工程”论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei9e3l/d_is_the_new_norm_for_nlp_papers_prompt/</link>
      <description><![CDATA[很多论文似乎本质上都是“我们如何让 LLM 1 不经过任何培训就能做到这一点？”我已经有一段时间没有发表过文章了，过去几年一直在行业内工作。我最近加入了一家新公司，担任一个稍微更偏向研究的职位，与研究科学家和研究生实习生一起工作。我注意到他们每个人都在做一些我在研究生院会受到 PI 斥责的事情。基本上就是“我们如何让 LLM 不经过任何培训就能完成这个非常复杂的任务？”也许并不出人意料的是，在很多情况下，你做不到。我想这就是为什么现在 NLP 领域有这么多负面结果的论文。 这是新常态吗？浏览 arXiv 的 CL 部分已经变得很痛苦了。 98% 的论文都是类似“LLaMA 怎么会不懂数字？”这样的问题。 我想知道我是不是酒吧角落里那个老糊涂，还是大家都有同样的感受。    提交人    /u/Seankala   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei9e3l/d_is_the_new_norm_for_nlp_papers_prompt/</guid>
      <pubDate>Fri, 02 Aug 2024 12:57:27 GMT</pubDate>
    </item>
    <item>
      <title>torch 高斯随机权重初始化和 L2 正则化 [D][R][P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei8xn9/torch_gaussian_random_weights_initialization_and/</link>
      <description><![CDATA[我有一个线性/全连接的 torch 层，它接受 latent_dim 维输入。该层中的神经元数量 = 高度 \ 宽度*:  # 定义当前层的超参数 - height = 20 width = 20 latent_dim = 128 # 初始化线性层 - linear_wts = nn.Parameter(data = torch.empty(height * width, latent_dim), require_grad = True) &#39;&#39;&#39; torch.nn.init.normal_(tensor, mean=0.0, std=1.0, generator=None) 用从正态分布中抽取的值填充输入张量 - N(mean, std^2) &#39;&#39;&#39; nn.init.normal_(tensor = som_wts, mean = 0.0, std = 1 / np.sqrt(latent_dim)) print(f&#39;1/sqrt(d) = {1 / np.sqrt(latent_dim):.4f}&#39;) print(f&#39;SOM 随机 wts; min = {som_wts.min().item():.4f} &amp;&#39; f&#39; max = {som_wts.max().item():.4f}&#39; ) print(f&#39;SOM 随机 wts; mean = {som_wts.mean().item():.4f} &amp;&#39; f&#39; std-dev = {som_wts.std().item():.4f}&#39; ) # 1/sqrt(d) = 0.0884 # SOM 随机 wts；min = -0.4051 &amp; max = 0.3483 # SOM 随机 wts；mean = 0.0000 &amp; std-dev = 0.0880  问题 1：对于 std-dev = 0.0884（大约），根据最小值和最大值 -0.4051 和 0.3483，似乎正常初始化程序正在计算距离平均值 = 0 的 +3.87 个标准差和距离平均值 = 0 的 -4.4605 个标准差。这是正确的理解吗？我假设权重是从距离平均值 +3 和 -3 个标准差中抽取的？ 大多数最近的自监督学习论文，即 SimCLR、MoCo、Barlow Twins、SwAV、BYOL、SimSiam 等，都使用 L2 标准化输出进行成本函数计算和训练。受此启发，我尝试了以下操作： 问题 2：我希望此线性层的输出进行 L2 归一化，使其位于单位超球面上。为此，似乎有 2 个选项：  执行一次性操作：```linear_wts.data.copy_(nn.Parameter(data = F.normalize(input = linear_wts.data, p = 2.0, dim = 1)))```，然后照常训练 获取层的输出为：```F.relu(linear_wts(x))```，然后执行 L2 归一化（针对每个训练步骤）：```F.normalize(input = F.relu(linear_wts(x)), p = 2.0, dim = 1)```  我认为选项 2 更正确。有什么想法吗？    由   提交  /u/grid_world   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei8xn9/torch_gaussian_random_weights_initialization_and/</guid>
      <pubDate>Fri, 02 Aug 2024 12:35:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] LlamaIndex 模式用法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei3lzz/d_llamaindex_pattern_usage/</link>
      <description><![CDATA[我制作了一个 YouTube 视频，作为 LlamaIndex 新手的入门指南。虽然我对 RAG（检索增强生成）解决方案和实现有经验，但教学对我来说是一项新尝试，我很乐意与社区分享我的方法。 在这篇文章中，我的目标是简化初学者学习 LlamaIndex 的过程。我没有深入研究密集的文档，而是以一种引人入胜的方式呈现概念，并结合模因让事情变得有趣。 以下是视频内容的简要概述：  通过 5 个简单步骤解释 LlamaIndex。 有效使用的实用示例和模式。 简化工作流程的技巧和窍门。  我愿意接受任何批评和改进建议。您的反馈将非常宝贵，有助于我改进教学方法并在未来创建更有效的内容。 感谢您花时间观看我的视频，我期待听到您的想法！    提交人    /u/Several_Operation707   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei3lzz/d_llamaindex_pattern_usage/</guid>
      <pubDate>Fri, 02 Aug 2024 07:03:08 GMT</pubDate>
    </item>
    <item>
      <title>我制作了一个 SWE 套件，以便轻松构建 SWE Agent [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei0pd7/i_made_a_swe_kit_for_easy_swe_agent_construction_p/</link>
      <description><![CDATA[大家好！我很高兴与大家分享一个新项目：SWEKit，这是一个使用 Composio 工具生态系统构建软件工程代理的强大框架。 目标 SWEKit 允许您：  使用 CrewAI 和 LlamaIndex 等框架构建开箱即用的代理。 添加或优化代理的能力。 根据 SWE-Bench 对您的代理进行基准测试。  实施细节  使用的工具：Composio、CrewAI、Python  设置：  安装您选择的代理框架和 Composio 插件 代理需要 github 访问令牌才能与您的存储库配合使用 您还需要设置 API 密钥适用于您计划使用的 LLM 提供程序  搭建并运行您的代理 工作区环境： SWEKit 支持不同的工作区环境：  主机：在主机上运行。 Docker：在 Docker 容器内运行。 E2B：在 E2B 沙箱内运行。 FlyIO：在 FlyIO 机器内运行。  运行基准测试：  SWE-Bench 使用来自流行 Python 开源项目的实际问题来评估软件工程代理的性能。  GitHub 欢迎探索该项目，如果发现它有用，请给它一颗星，并让我知道您的想法或改进建议！🌟    提交人    /u/kingai404   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei0pd7/i_made_a_swe_kit_for_easy_swe_agent_construction_p/</guid>
      <pubDate>Fri, 02 Aug 2024 04:05:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 加权损失函数（Pytorch 的 CrossEntropyLoss）解决多类多输出问题的不平衡数据分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehyv6b/p_weighted_loss_function_pytorchs/</link>
      <description><![CDATA[我正在尝试使用加权损失函数来处理数据中的类别不平衡问题。我的问题是多类别和多输出问题。例如（我的数据有五个输出/目标列（output_1、output_2、output_3）并且每个目标列中有三个类（class_0、class_1 和 class_2）。我目前正在使用 pytorch 的交叉熵损失函数https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html并且我看到它有一个权重参数，但我的理解是，这个相同的权重将统一应用于每个输出/目标，但我想在每个输出/目标中为每个类应用单独的权重。 具体来说，我可以获得如下数据   A B C D E OUTPUT_1 OUTPUT_2 OUTPUT_3    5.65 3.56 0.94 9.23 6.43 0 2 1   7.43 3.95 1.24 7.22 2.66 0 0 0   9.31 2.42 2.91 2.64 6.28 2 0 2   8.19 5.12 1.32 3.12 8.41 0 2 0   9.35 1.92 3.12 4.13 3.14 0 1 1   8.43 9.72 7.23 8.29 9.18 1 0 2   4.32 2.12 3.84 9.42 8.19 0 1 0   3.92 3.91 2.90 8.19 8.41 2 0 2   7.89 1.92 4.12 8.19 7.28 0 1 2   5.21 2.42 3.10 0.31 1.31 2 0 0   其中，产出 1 中的比例为：0 = 0.6, 1 = 0.1, 2 = 0.3 产出 2 中的比例为：0 = 0.4, 1 = 0.3, 2 = 0.3  输出 3 为：0 = 0.4、1 = 0.2、2 = 0.4 我想根据每个输出列中的类分布应用类权重，以便它重新规范化（或重新平衡？不确定这里要使用的术语是什么）类 1 为 0.15，类 0 和类 2 各为 0.425（因此对于 output_1，权重将是 [0.425/0.6、0.15/0.1、0.425/0.3]，对于输出 2，它将是 [0.425/0.4、0.15/0.3、0.425/0.3] 等）。相反，我理解 pytorch 的交叉熵损失函数中的权重参数目前正在做的事情是，它将对每个输出列应用单个类权重。任何帮助都将不胜感激。     由   提交  /u/Individual_Ad_1214   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehyv6b/p_weighted_loss_function_pytorchs/</guid>
      <pubDate>Fri, 02 Aug 2024 02:28:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解 ByteNet 架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehws26/d_understanding_bytenet_architecture/</link>
      <description><![CDATA[你好！ 我正在考虑在一个项目中使用 ByteNet (https://arxiv.org/abs/1610.10099) 架构，并希望更好地了解该模型的工作原理。 我已经阅读了这篇论文大约一百万次，但无法弄清楚动态展开究竟是如何实现的。我知道输入序列被映射到更长的中间表示，其长度是输入长度的函数，但不明白 1×1 卷积层如何做到这一点。我也不清楚输入序列如何可以具有可变长度而没有任何重复。 背景：动态展开的目标是允许模型处理输入长度与目标长度不匹配的情况（例如，将句子翻译成另一种语言时就是这种情况）。它涉及创建输入序列 s 的表示，其长度为 a \ |s| + b，其中 *a 和 b 是超参数。这个新的、更长的表示是使用一维卷积层生成的（以一种我无法理解的方式）。 任何帮助都将不胜感激！或者任何人知道任何解释它的优秀 YouTube 视频，这也会有所帮助。    提交人    /u/BerryLizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehws26/d_understanding_bytenet_architecture/</guid>
      <pubDate>Fri, 02 Aug 2024 00:44:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有什么好的可微调的 TTS？（不是 Coqui 或 TorToiSe）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehw1nf/d_any_good_finetunable_tts_not_coqui_or_tortoise/</link>
      <description><![CDATA[大家好！我有一个非常感性的数据集，里面有大约 20-30 分钟的清晰的英语语音录音。我想制作一个微调模型来完全复制该声音，并且能够在没有 CUDA 的情况下仅使用 MPS 进行推理。除了 Coqui 和 TorToiSe（它们不适用于高音调数据）之外，还有什么想法以及好的分步文档吗？    提交人    /u/yukiarimo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehw1nf/d_any_good_finetunable_tts_not_coqui_or_tortoise/</guid>
      <pubDate>Fri, 02 Aug 2024 00:10:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在专注于 LLM 的初创公司工作值得吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehudwq/d_is_it_worth_working_at_startups_focusing_on_llm/</link>
      <description><![CDATA[一些正在开发 LLM 产品的初创公司的 HR 找到了我。根据我们的讨论，他们仍然主要将流行的开放 AI 模型或开源模型 (llama3) 用于他们的 LLM 产品（这并不奇怪），我认为工程师将主要做的事情是快速工程和/或微调。我对 LLM 非常感兴趣，我相信这是一个相当突出的未来（如果我错了，请纠正我），但是我不确定如果我在使用这些模型的初创公司工作，我能在 LLM 领域达到多大的深度，可能只有快速工程和微调技术？在这些初创公司工作是否会让我在直接申请这些大型模型公司（Meta、Google、Open AI 等）的 LLM 职位时更有竞争力？ 我想在 LLM 领域获得更多知识，但我不知道在只使用带有 API 调用的 LLM 模型的公司工作是否是一个好的起点。任何建议都值得赞赏！    提交人    /u/Upbeat-Carrot1999   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehudwq/d_is_it_worth_working_at_startups_focusing_on_llm/</guid>
      <pubDate>Thu, 01 Aug 2024 22:55:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 还有人觉得 LLM 没什么意思吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eh4llh/d_llms_arent_interesting_anyone_else/</link>
      <description><![CDATA[我不是 ML 研究员。当我想到很酷的 ML 研究时，我想到的是 OpenAI Five 或 AlphaFold 之类的东西。如今，人们热议的是 LLM 和扩展转换器，虽然该领域确实有一些研究和优化要做，但它对我来说并不像其他领域那么有趣。对我来说，ML 的有趣部分是为您的用例端到端训练模型，但如今的 SOTA LLM 可以用于处理许多用例。好的数据 + 大量的计算 = 不错的模型。就这样？ 如果我可以用一小部分计算来训练这些模型，我可能会更感兴趣，但这样做是不合理的。那些没有计算能力的人只能进行微调或快速工程，而我内心的 SWE 发现这很无聊。这个领域的大多数人真的把精力投入到下一个标记预测器中了吗？ 显然，LLM 具有颠覆性，并且已经发生了很大的变化，但从研究的角度来看，它们对我来说并不有趣。还有人有这种感觉吗？对于那些因为与 LLM 无关的东西而被该领域吸引的人，你对此有何感想？你是否希望 LLM 的炒作会逐渐消退，以便焦点可以转移到其他研究上？那些在当前趋势之外进行研究的人：你如何处理所有的噪音？    提交人    /u/leetcodeoverlord   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eh4llh/d_llms_arent_interesting_anyone_else/</guid>
      <pubDate>Thu, 01 Aug 2024 01:40:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jul 2024 15:00:14 GMT</pubDate>
    </item>
    </channel>
</rss>