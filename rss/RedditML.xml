<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 14 Jan 2024 01:05:59 GMT</lastBuildDate>
    <item>
      <title>[P] 向 XalosXandrez 提出请求</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19628r2/p_request_to_xalosxandrez/</link>
      <description><![CDATA[嗨u/XalosXandrez 我会我想引用您 7 年前在 Reddit 子版块的一篇论文中所说的话演示文稿。 我没有足够的业力与您开始聊天。您能 ping 我一下吗？  编辑：人们能给我我需要的最低限度的业力吗？我保证我是一个相当好的人;-) &lt;!-- SC_ON - -&gt;  由   提交 /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19628r2/p_request_to_xalosxandrez/</guid>
      <pubDate>Sun, 14 Jan 2024 00:09:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM Chat Agents - 使用 BERT 的轻量级工具选择</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1961mz7/d_llm_chat_agents_lightweight_tool_selection/</link>
      <description><![CDATA[      这篇文章使用 BERT 和分类技术进行“代理工具”选择”。它将其作为使用法学硕士的替代方法，表明它对于某些用例可能是有效的。从表面上看，这似乎是一个好主意，只保留 LLM 来生成答案，从而节省成本和延迟。对此有何想法？   由   提交/u/coracarm  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1961mz7/d_llm_chat_agents_lightweight_tool_selection/</guid>
      <pubDate>Sat, 13 Jan 2024 23:41:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] [D] [P] 机器学习和远程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19600kb/r_d_p_machine_learning_and_remote/</link>
      <description><![CDATA[大家好，我是一名最后一年的学生，我将从事一个涉及使用 python 进行机器学习和遥感的项目（每个树木的检测）例如），老实说我不知道​​从哪里开始，我在网上查了一下，发现它是如此广泛。任何人都可以帮助我，这真的很紧急。谢谢   由   提交/u/RealAd1834  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19600kb/r_d_p_machine_learning_and_remote/</guid>
      <pubDate>Sat, 13 Jan 2024 22:27:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 变压器模型帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195z3jw/p_help_with_transformer_model/</link>
      <description><![CDATA[所以，我在 NLP 领域相对较新，我的教授要求我了解一些 Transformer 模型，这些模型还结合了语言特征和句子对来理解。我尽力找到一些代码，但除了一些没有任何代码的论文之外，未能管理任何合法的存储库。对此有什么帮助吗？   由   提交/u/golpanda  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195z3jw/p_help_with_transformer_model/</guid>
      <pubDate>Sat, 13 Jan 2024 21:46:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 生成流网络的现状如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195uwh1/d_what_is_the_state_of_generative_flow_networks/</link>
      <description><![CDATA[Gflownets 最初似乎已经爆炸了，但是关于它们在因果推理中的适用性有何共识？  感谢论文推荐！我最近还没有发现任何在实践中结合 gflownets 的令人满意的东西。   由   提交 /u/austinv11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195uwh1/d_what_is_the_state_of_generative_flow_networks/</guid>
      <pubDate>Sat, 13 Jan 2024 18:44:02 GMT</pubDate>
    </item>
    <item>
      <title>[N] OpenDalle v1.1、VCoder、LongAnimateDiff 等！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195tut6/n_opendalle_v11_vcoder_longanimatediff_more/</link>
      <description><![CDATA[嘿， 人工智能最近变得很疯狂，事情变化得非常快。我制作了一个视频，涵盖了一些最新流行的拥抱空间，您必须查看！ OpenDalle v1.1 已发布，让您可以创建令人惊叹的图像。 VCoder 现在也可用，让您可以全面了解我们传递给它的图像中所看到的内容。除了这 2 个之外，我们还介绍了 LongAnimateDiff、PASD Magnify、M^2UGen、Pheme 和 Pheme。 PIA。请查看以了解最新趋势！ https://www.youtube。 com/watch?v=MbLXWxbcVoc OpenDalle 非常好。它基于稳定扩散，但经过一些调整，确实产生了一些非常好的结果。请务必检查一下，它们还提供了一个推理终点供您使用。 请随时订阅我的时事通讯，其中将包含人工智能领域新技术的每周每月摘要： https://devspot.beehiiv.com/subscribe 让我了解您的想法，或者如果您对其他视频有任何疑问/请求， 干杯   由   提交/u/dev-spot  /u/dev-spot  reddit.com/r/MachineLearning/comments/195tut6/n_opendalle_v11_vcoder_longanimatediff_more/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195tut6/n_opendalle_v11_vcoder_longanimatediff_more/</guid>
      <pubDate>Sat, 13 Jan 2024 17:59:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您将如何组建研发团队？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195tnw4/d_how_would_you_build_an_rd_team/</link>
      <description><![CDATA[我目前面临着令人兴奋的挑战，要在大型科技公司内建立一支 Skunkworks 研发团队，专注于 NLP。 Skunkworks 项目以其创新和非正统的方法而闻名，我热衷于收集有关如何有效建立和管理这样一个团队的广泛想法和建议。以下是我希望了解您的见解的一些具体领域：  团队组成：您认为 Skunkworks 团队中哪种技能和背景组合最有效？您如何平衡技术专长与创造性解决问题的能力？ 领导力和文化：您将如何培养创新和冒险的文化？哪些领导素质对于指导在通常公司结构的边缘运作的团队至关重要？ 项目选择和管理：您如何决定要开展哪些项目？什么方法最适合管理本质上不确定和探索性的项目。 协作与沟通：在一家大公司中，如何确保 Skunkworks 团队与其他部门之间的有效沟通？您如何在保密和必要的协作之间取得平衡？ 挑战和经验教训：建立 Skunkworks 团队时有哪些常见陷阱？如果您是这样一个团队的一员，您学到了哪些希望一开始就知道的经验教训？ 成功故事和案例研究：是否有任何特别的成功您认为 Skunkworks 团队的故事或案例研究对您有启发性或启发性？  您的经验、见解以及您可以分享的任何资源都会非常有帮助。我期待着阅读您的想法并就此展开丰富的讨论！提前致谢！   由   提交/u/SingularValued  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195tnw4/d_how_would_you_build_an_rd_team/</guid>
      <pubDate>Sat, 13 Jan 2024 17:50:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Transformers 专家混合的问题 - 有人尝试过在多头注意块之前添加路由器吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195soqh/d_question_about_mixture_of_experts_in/</link>
      <description><![CDATA[   当我们阅读 Mixtral 8x7B 论文时，这个问题在我们周五的论文俱乐部中出现了，并且我觉得我们没有得到满意的答案。 MOE 的论点似乎是你可以让网络的某些部分专门从事某些领域或任务。这也让我印象深刻，因为人们在变压器块内进行多头关注时提出了类似的论点。为什么只将路由器放在前馈层前面而不是放在多头注意力前面？ ​ https://preview.redd.it/gyb8mevco8cc1.png?width=1666&amp;format =png&amp;auto=webp&amp;s=0595120e2fdf96bbb5797bcc85646a90d1419773 在多头注意力之前进行路由可以让网络更好地选择它关注的内容，在多头注意力之后进行路由可以帮助预测下一个基于注意力的词。看起来，如果您只需要运行多头注意力的一个子集，您就会得到类似的延迟增加。 我错过了什么？有人尝试过吗？ ​ 为感兴趣的人回顾一下我们的笔记： https://blog.oxen.ai/arxiv-dives-mixture-of-experts-moe-with-mixtral- 8x7b/   由   提交 /u/FallMindless3563   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195soqh/d_question_about_mixture_of_experts_in/</guid>
      <pubDate>Sat, 13 Jan 2024 17:07:46 GMT</pubDate>
    </item>
    <item>
      <title>寻找可解释的人工智能在医疗诊断领域应用的研究课题[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195smzg/looking_for_a_research_topic_to_apply_explainable/</link>
      <description><![CDATA[大家好， 我目前是一名本科生。我正在寻找一个研究课题，最好是在医疗诊断领域，我可以在其中应用可解释的人工智能。 在我最初的搜索中，我发现对于医疗诊断领域的各种问题，我们已经很好-执行 ML/DL 模型。这些模型提供高精度的预测。但这些预测没有任何解释性。我想努力为这个模型添加可解释性。 如果有人建议一些有关该主题的资源或以任何方式帮助我，我将不胜感激。   由   提交/u/ornob_50  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195smzg/looking_for_a_research_topic_to_apply_explainable/</guid>
      <pubDate>Sat, 13 Jan 2024 17:05:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] Google DeepMind 诊断法学硕士超过人类医生前 10 名的准确率（59% vs 34%）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195q6lu/r_google_deepmind_diagnostic_llm_exceeds_human/</link>
      <description><![CDATA[Google 和 DeepMind 的研究人员开发并评估了专门针对临床诊断推理进行微调的法学硕士。在一项新研究中，他们严格测试了法学硕士进行鉴别诊断和帮助医生的能力。 他们根据《新英格兰医学杂志》的 302 个真实案例报告对法学硕士进行了评估。众所周知，这些病例报告是高度复杂的诊断挑战。 法学硕士制作了鉴别诊断列表，其中包括 302 例病例中 177 例前 10 种可能性中的最终确诊诊断，前 10 种准确度为 59 %。 这大大超过了经验丰富的医生的表现，在没有协助的情况下，经验丰富的医生在相同病例中的前 10 名准确率仅为 34%。 根据高级专家的评估，法学硕士的在对所有 302 份病例报告进行评估时，鉴别诊断也被认为比医生做出的诊断更加合适和全面。 这项研究证明了法学硕士在提高医生水平方面的潜力&#39;对复杂病例的临床推理能力。然而，作者强调，在临床部署之前，进一步严格的现实测试至关重要。还必须解决有关模型安全性、公平性和稳健性的问题。 完整摘要。 论文。    ;由   提交 /u/Successful-Western27    reddit.com/r/MachineLearning/comments/195q6lu/r_google_deepmind_diagnostic_llm_exceeds_ human/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195q6lu/r_google_deepmind_diagnostic_llm_exceeds_human/</guid>
      <pubDate>Sat, 13 Jan 2024 15:16:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 避免机器学习项目中常见错误的资源？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195q259/d_resources_for_avoiding_common_mistakes_in/</link>
      <description><![CDATA[通常有管理者或企业家类型认为“AI”是一种技术。作为一个神奇的解决方案，然后数百万美元被浪费，因为他们不明白该解决方案有多么脆弱，如何需要更多的数据来创建泛化的解决方案，对偏见的敏感性，所需的培训数据等等。哪些可访问的信息是否可以帮助人们了解项目的实用性以及成功和道德成果所涉及的内容？   由   提交/u/Neuro-AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195q259/d_resources_for_avoiding_common_mistakes_in/</guid>
      <pubDate>Sat, 13 Jan 2024 15:11:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI、Google 和 Meta 等领先的人工智能研究组织如何跟踪和管理他们的大规模人工智能实验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195lwlh/d_how_do_leading_ai_research_organizations_like/</link>
      <description><![CDATA[我非常有兴趣了解 OpenAI、Google 和 Meta 的研究人员用来跟踪他们的 AI 实验的工具和技术。这包括他们如何管理不同版本的人工智能模型以及在这些模型上运行的各种测试等事物。我很想知道他们使用哪些特定工具来完成这些任务。此外，如果能够了解他们是否遵循任何推荐的方法或最佳实践来有效地组织和处理这些实验运行，那就太好了。由于我也是一名研究人员，这些信息对我来说非常有用。   由   提交 /u/Few-Pomegranate4369    reddit.com/r/MachineLearning/comments/195lwlh/d_how_do_leading_ai_research_organizations_like/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195lwlh/d_how_do_leading_ai_research_organizations_like/</guid>
      <pubDate>Sat, 13 Jan 2024 11:21:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 适合面试的 ML 工程题库好吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/</link>
      <description><![CDATA[我一直在研究 ML 工程面试（并做了一些），我意识到“了解偏见”的常见建议，方差、交叉折叠验证等”。都是错的。顶级公司要求你使用 Pytorch/numpy 编写简单的代码。所以问题是这样的：“编写一个神经网络来解决 X 问题”或者“编写一个神经网络来解决 X 问题”。或“使用 numpy 实现 k-means”。 考虑到这种情况，我认为通过做一堆编码问题来准备这些面试会更有用。 我想知道这里的人是否可以分享他们在 ML Eng 面试中遇到的一些编码问题，或者向我指出好的 Leetcode 风格的 MLEng 题库？  &amp;# 32；由   提交 /u/lisp-cloj    reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/</guid>
      <pubDate>Fri, 12 Jan 2024 23:00:47 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待 Yann Lecun 关于 ML 的有争议的观点？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/</link>
      <description><![CDATA[      Yann Lecun 有一些有争议的观点关于 ML 的看法，他并不羞于分享。他写了一篇名为“通往自主机器智能之路”的立场文件。不久以前。此后，他也就此发表了很多演讲。这是屏幕截图 ​ https://preview.redd.it/xxmxgrdk02cc1.jpg?width=1581&amp;format=pjpg&amp;auto=webp&amp;s=4a7e98f5a41f2e454e2e33881f2 df93c7287d09b 来自&lt; a href=&quot;https://www.youtube.com/watch?v=OKkEdTchsiE&quot;&gt;一个，但我看过几个 - 它们很相似，但不完全相同。以下并不是所有演讲的摘要，而只是他对 ML 现状的批评，根据记忆进行解释（他还谈论了 H-JEPA，我在这里忽略了）：  &lt; li&gt;法学硕士无法商业化，因为内容所有者“喜欢reddit”会起诉（奇怪的是，鉴于最近的《纽约时报》诉讼，这是有先见之明的） 当前的机器学习很糟糕，因为与人类相比，它需要大量的数据（我认为有两种截然不同的可能性：算法本身是不好，或者人类只是在童年时期进行了更多的“预训练”） 规模化是不够的 自回归法学硕士注定会失败，因为任何错误都会让你偏离正确的道路，随着输出数量的增加，不犯错误的概率很快接近 0 LLM 无法推理，因为它们只能执行有限数量的计算步骤 连续建模概率域是错误的，因为你会得到无限梯度 对比训练（如 GAN 和 BERT）是不好的。您应该进行正规化训练（例如 PCA 和稀疏 AE） 生成建模是误导性的，因为世界的大部分内容都是不可预测或不重要的，不应该由智能系统建模 人类通过被动视觉观察了解他们对世界的大部分了解（我认为这可能与先天失明的人可能非常聪明的事实相矛盾） 你不&#39;智能行为不需要巨大的模型，因为老鼠只有数千万个神经元，就超越了当前的机器人人工智能    由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/</guid>
      <pubDate>Fri, 12 Jan 2024 19:14:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>