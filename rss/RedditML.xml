<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 07 Apr 2024 01:03:01 GMT</lastBuildDate>
    <item>
      <title>我有一个非常雄心勃勃的项目想要从事。还可能吗？！ [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxrjtr/i_have_an_extremely_ambitious_project_i_want_to/</link>
      <description><![CDATA[基本上，我想创建一个能够模仿我直系亲属的每个成员的 AI 模型。这引发了一些道德问题，但我唯一的用途是在家人去世后与他们“联系”。我计划为每个人拍摄数百甚至数千张照片，以创建一个栩栩如生的 3D 模型；我计划为每个人录制几个小时的录音；我希望创建一份包含 1,000 多个深度查询的调查问卷。  尽管这听起来令人畏惧和疯狂，但它植根于对我家人的爱。在过去的几个月里，我开始看到我的祖母放慢了脚步。我无法想象没有她的生活。它永远不会与真实的人类相同，但我知道我会后悔没有尽力保留他们的相似性。 我今年 15 岁，对机器学习的了解有限。如果有人愿意提供帮助，请留下评论，说明您建议我捕获哪些数据以及实际问题。非常感谢。   由   提交/u/Tbuddy-  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxrjtr/i_have_an_extremely_ambitious_project_i_want_to/</guid>
      <pubDate>Sun, 07 Apr 2024 01:02:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 探索半结构化数据。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxrb42/d_exploring_semistructured_data/</link>
      <description><![CDATA[嘿，我需要一些关于 json 扁平化的帮助，以探索我当前使用的数据集。该数据集是半结构化的，并且具有多个嵌套的 json blob 作为列，有关如何取消嵌套这些列的任何提示。我更喜欢使用 sql，因为在 jupyter 中将数据集拉入内存不是一个选项，因为它肯定会耗尽内存，并且还希望避免由于某些数据质量限制而进行子集化。另外，我必须使用 pandas，因为在我的组织中，不存在与数据库的直接 Spark 连接。附：通过多个 json blob，我的意思是当 json 扩展时，我会在该 json 列中获得另一个键值对列表。   由   提交/u/Terrible-Ad8945   /u/Terrible-Ad8945 reddit.com/r/MachineLearning/comments/1bxrb42/d_exploring_semistructed_data/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxrb42/d_exploring_semistructured_data/</guid>
      <pubDate>Sun, 07 Apr 2024 00:51:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您对基于树的模型的特征进行标准化的原因是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxq6c5/d_what_are_the_reasons_why_you_standardise/</link>
      <description><![CDATA[下面的说法正确吗？如果是，请您稍微解释一下。 逻辑回归和基于树的算法（例如决策树、随机森林和梯度提升）对变量的大小不敏感。因此，在拟合这些类型的模型之前不需要标准化。 在此链接中找到 - https://builtin.com/data-science/when-and-why-standardize-your-data 这与说异常值不一样吗基于影响树的算法？   由   提交 /u/SriRamaJayam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxq6c5/d_what_are_the_reasons_why_you_standardise/</guid>
      <pubDate>Sat, 06 Apr 2024 23:58:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 专家的无限混合 - 可能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxmyac/r_infinite_mixture_of_experts_possible/</link>
      <description><![CDATA[我一直在研究 MoE 模型以了解它们为何如此有效，并且想知道是否有方法可以有效地创建“无限”模型可以路由到任务所需的任意数量的参数的专家吗？例如，Mixtral MoE 使用 8 名专家，但架构可以扩展到更多：https://arxiv.org/abs/2401.04088  这个想法是有一些逻辑可以提前选择要相乘的权重，但我有一种感觉，选择权重所需的计算与实际计算中的权重相同或更多。第一名   由   提交/u/CriticalTemperature1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxmyac/r_infinite_mixture_of_experts_possible/</guid>
      <pubDate>Sat, 06 Apr 2024 21:35:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] 一个关于 RAG 最新研究的对话式搜索应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxmvn3/p_a_conversational_search_app_about_recent/</link>
      <description><![CDATA[检索增强生成 (RAG) 正在成为一个流行的研究领域。自 2024 年初以来，大约 150篇关于该主题的研究论文已在arxiv.org上发表。 人们阅读和停留相当困难每一篇新论文都会更新。为了解决这个问题，我创建了一个对话式搜索应用程序。该应用程序允许用户询问有关 RAG 的问题。它旨在让人们更容易地快速获得最新研究进展的更新和总结：https://cloud.epsilla.com/enterprise-search/df6624c1-1c2a-4263-8c10-14f495fc3e7f-340417431/73ee9739-e674-44cd-b 007- 3c46b5811c2b?src=reddit 尝试一下，通过竖起大拇指或竖起大拇指让我知道您对答案的看法。期待看到您提出的所有富有洞察力的问题。   由   提交/u/songrenchu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxmvn3/p_a_conversational_search_app_about_recent/</guid>
      <pubDate>Sat, 06 Apr 2024 21:32:48 GMT</pubDate>
    </item>
    <item>
      <title>[D]为什么griffin/hawk不考虑非线性时间激活？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxlze3/d_why_griffinhawk_does_not_consider_nonlinear/</link>
      <description><![CDATA[从关于格里芬和鹰的谷歌论文来看，听起来他们没有像曼巴那样使用关联扫描。相反，他们只是使用 TPU 通过暴力方式运行循环计算。因此，人们很自然地想知道为什么他们不将结果与沿时间轴从 t-1 到 t 具有非线性激活层的 SSM（基本上是 RNN）进行比较？它应该比线性时间转换更强大，对吧？    由   提交/u/Crazy_Suspect_9512   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxlze3/d_why_griffinhawk_does_not_consider_nonlinear/</guid>
      <pubDate>Sat, 06 Apr 2024 20:54:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习可解释性的好书/资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxk9f7/d_good_booksresources_for_interpretability_in/</link>
      <description><![CDATA[关于机器学习中的机械可解释性有哪些好书？我正在努力寻找一本可以阅读的关于这个主题的好书。我目前从事优化研究，希望了解更多有关人工智能模型的内部表示、干预和机械解释的知识。    由   提交/u/claren0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxk9f7/d_good_booksresources_for_interpretability_in/</guid>
      <pubDate>Sat, 06 Apr 2024 19:42:09 GMT</pubDate>
    </item>
    <item>
      <title>[项目] DPO Aligned Vision-LLM模型UForm-Gen</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxirfj/project_dpo_aligned_visionllm_model_uformgen/</link>
      <description><![CDATA[演示：https://huggingface.co/spaces/unum-cloud/uform-gen2-qwen-500m-dpo-demo 高频卡：https://huggingface.co/unum-cloud/uform-gen2-dpo 代码：https://github.com/unum-cloud/uform TLDR：解决视觉语言模型中的幻觉提出了一个复杂的过程挑战。通过在开源数据集上进行 DPO 对齐实验，取得了显着的成功。 该模型已根据我们之前的检查点 (unum-cloud/uform-gen2-qwen-500m) 使用偏好数据集进行了微调：&lt; /p&gt;  MMInstruction/VLFeedback（包含 80k 条合成指令） zhiqings/LLaVA-Human-Preference-10K（包含人工注释指令）  这一改进使 MME 基准的感知显着提高了 15% 以上。   由   提交 /u/vov_or   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxirfj/project_dpo_aligned_visionllm_model_uformgen/</guid>
      <pubDate>Sat, 06 Apr 2024 18:38:33 GMT</pubDate>
    </item>
    <item>
      <title>有没有统计学家决定攻读计算机科学博士学位而不是统计学博士学位？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxi4l1/any_statisticians_who_decided_on_a_phd_in_cs/</link>
      <description><![CDATA[我目前是一名统计硕士学生。现在我对我一直在学习的标准经典统计学有点厌倦。我最初选择这条道路是因为我想为行业做好准备。我暑假有一个数据科学家实习机会，我考虑过全职工作。不过，工作几年后我确实想继续研究，所以我回到的问题是我想读统计学博士学位还是计算机科学博士学位。 坦白说，与大多数 CS 学生相比，我的编程技能非常低。我的本科专业是纯数学和统计学，虽然我学过 Python、R 和一些 Java，但我不能说我达到了软件工程师的水平。我很了解我的数学和统计理论，并且可以使用 Python 和 R 中的包来有效地做事，并编写函数等，但如果你现在问我“用 Python 写一个类”，我可能会被困住，因为我从来没有写类。  我不再对统计博士课程真正感兴趣，因为如果我要攻读统计博士学位，我必须在前两年完成课程作业，坦率地说，我只是厌倦了。我不想花时间证明 Logit 模型下 MLE 的渐近结果，也不想花一个学期学习线性模型理论之类的东西。 我现在拥有统计学硕士学位，我想我我已经把统计学打败得够多了。 我对深度学习领域非常感兴趣，这自然吸引了我从统计学家的角度出发，这就是时间序列预测的进步。  我在统计研究生课程中学习了时间序列，在那里我们学习所有经典方法：arima、sarima、garch 和一些非平稳时间序列模型，如状态空间模型。我也有经典非参数回归（统计学习）的背景，因为这是我论文的主题。 这些非常有趣，但我对计算机科学部门如何使用深度学习方法来提取数据感兴趣来自时间序列的信息。我这个老派的统计学家厌倦了学习“使用 ADF 检验来验证平稳性，拟合 arima 和 sarima 模型来对这个时间序列进行建模，并进行预测”，我现在看到来自计算机科学系的时间序列方面的巨大进步我想加入。此外，由于我在应用贝叶斯分析方面也有丰富的经验，我认为我在这方面的背景也可以是独特的补充。因果推理也是我涉足的领域，对于深度学习的任何方面，我也有兴趣提供我的意见。  那么，对于这里的任何人来说，是否有人像我一样，其背景来自于旧式学校统计，例如统计学硕士学位，现在转而攻读计算机科学博士学位，以研究更现代的主题？我觉得我在贝叶斯推理、时间序列、统计学习和因果推理等基础主题方面的背景可以为我在计算机科学的研究中添加一些东西。    由   提交/u/AdFew4357  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxi4l1/any_statisticians_who_decided_on_a_phd_in_cs/</guid>
      <pubDate>Sat, 06 Apr 2024 18:11:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM大海捞针，标志着RAG的死亡</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxeqdc/d_llms_ability_to_find_needles_in_a_haystack/</link>
      <description><![CDATA[   /u/Vissidarte_2021   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxeqdc/d_llms_ability_to_find_needles_in_a_haystack/</guid>
      <pubDate>Sat, 06 Apr 2024 15:48:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] MoE 路由器在做出错误选择时如何学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxel8z/d_how_does_a_moe_router_learn_when_it_has_made_a/</link>
      <description><![CDATA[查看当前专家混合模型的代码，他们似乎使用 argmax，其中 k=1（仅选择顶级专家）来选择路由器的选择。由于 argmax 是不可微的，因此梯度不能流向其他专家。因此，在我看来，如果所选专家表现不佳，则只会更新其权重。然而，可能的情况是，对于给定的输入，不同的专家实际上是更好的选择，但路由器无法知道这一点，因为梯度不会流向其他专家。  路由器如何得知自己做出了错误的选择，并在下次使用不同的专家？   由   提交/u/RepresentativeWay0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxel8z/d_how_does_a_moe_router_learn_when_it_has_made_a/</guid>
      <pubDate>Sat, 06 Apr 2024 15:42:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器人的具体神经形态人工智能：前景、挑战和研究开发堆栈 - 纽约大学 2024 - 对于更快地进行推理非常重要，并且如果在人形机器人上本地运行 gpt-4 的硬件和软件堆栈中进行扩展，则允许进行扩展！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxchyf/r_embodied_neuromorphic_artificial_intelligence/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxchyf/r_embodied_neuromorphic_artificial_intelligence/</guid>
      <pubDate>Sat, 06 Apr 2024 14:10:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 非 NLP 领域的 ML 研究人员，你们在研究什么？请分享。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bx914m/d_ml_researchers_who_are_not_in_nlp_what_are_you/</link>
      <description><![CDATA[我们很想了解 ML 研究的范围。 如果您将其写得尽可能详细，将会有所帮助。研究实际需要的内容是可能的。谢谢！   由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bx914m/d_ml_researchers_who_are_not_in_nlp_what_are_you/</guid>
      <pubDate>Sat, 06 Apr 2024 11:12:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我无法将 BERT 微调到超过 40% 的文本分类任务准确度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bx5r8r/d_i_just_cant_fine_tune_bert_over_40_accuracy_for/</link>
      <description><![CDATA[大家好，这是我第一次对 LLM 进行微调，但文本分类的准确率无法超过 40%任务。 我使用 Transformers 库中的 BERT 来加载和训练模型，并为 LoRA 实现提供支持。我的数据集包含新闻文章的英文书面摘要，每篇文章都有一个标签，例如经济、政治、科学、娱乐等......（14 个独特的标签）。摘要的最大长度可以扩展到 250-300 个标记。我的训练集有 800 个示例，验证集有 200 个示例。 起初，训练损失非常低，但验证损失并没有太低，验证准确率最高可达 45%。由于过度拟合，我将 dropout 率从 0.1 更改为 0.5。之后，模型现在没有过拟合，但欠拟合，验证和训练损失几乎相同，验证准确率仍然达到最大值 45%。 我尝试删除 LoRA 实现，但没有任何改变，除了训练时间。此时我很困惑我应该做什么。我尝试过调整超参数，但没有任何变化。 任何人都可以帮助我理解我可能在这里遗漏的内容。我可以分享统计数据和代码实现，或者如果可能的话我什至可以随叫随到。非常感谢任何帮助。   由   提交 /u/Total-Opposite-8396   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bx5r8r/d_i_just_cant_fine_tune_bert_over_40_accuracy_for/</guid>
      <pubDate>Sat, 06 Apr 2024 07:33:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>