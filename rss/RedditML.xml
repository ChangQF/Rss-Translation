<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 10 Dec 2024 09:19:51 GMT</lastBuildDate>
    <item>
      <title>[D] 寻求论文写作反馈：基于 GPT 的网络入侵检测系统（arXiv 发表）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1haufwv/d_seeking_paper_writing_feedback_gptbased_network/</link>
      <description><![CDATA[大家好， 我是一名独立开发者，一直致力于将 GPT 模型应用于网络入侵检测。虽然我有实施经验，但这是我第一次涉足学术论文写作，我正在寻求有关论文表达和结构的反馈。 我最近在 arXiv 上发表了文章： - 标题：NIDS-GPT：将包视为语言：使用 TRANSFORMER 进行异常检测 - arXiv 链接：https://arxiv.org/pdf/2412.04473 本文提出了一种新颖的方法，将网络数据包中的每个数字视为 GPT 处理的独立“单词”。我们的实验显示出令人鼓舞的结果 - 在极端不平衡条件下 CICIDS2017 和汽车黑客数据集的准确率达到 100％，在一次性学习中的准确率达到 90％ 以上。 作为首次撰写论文的作者，我希望得到以下方面的反馈：  论文结构和学术展示标准 可视化效果和清晰度 方法展示 实验比较的有效性 主张和结论的强度  我特别希望得到以下人员的反馈： - 网络安全/入侵检测研究人员 - 在非 NLP 领域使用语言模型的人员 - 经验丰富的论文撰写者/审阅者 实现很可靠，但我想确保论文有效地传达了对学术界的技术贡献社区。 感谢您的时间和专业知识！    由    /u/EliaukMouse 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1haufwv/d_seeking_paper_writing_feedback_gptbased_network/</guid>
      <pubDate>Tue, 10 Dec 2024 05:14:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你是如何跟上文学发展的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hasdlo/d_how_do_you_keep_up_with_the_literature/</link>
      <description><![CDATA[与标题基本一致。您使用什么工具/策略来跟上文献？    提交人    /u/Rickmaster7   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hasdlo/d_how_do_you_keep_up_with_the_literature/</guid>
      <pubDate>Tue, 10 Dec 2024 03:20:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我做的正确吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1has6jq/d_is_what_im_doing_is_correct/</link>
      <description><![CDATA[我正在开展一个 ML 项目。我有 100 个特征和 2000000 行（平衡）我应该遵循哪个顺序？ 我已经完成了，  数据不一致处理 NULL 插补 标准化 独热编码 数据可视化 相关性检查 PCA 训练测试分割 模型训练 评估  对于随机森林，我得到训练数据所有指标的 1，测试集的 0.79。对于逻辑回归，所有指标和测试集的值为 ~0.79，也是同样的结果。对于 GBDT，所有指标和测试集的值为 ~0.79，也是同样的结果。我应该选择哪种模型？上述步骤是否按正确的顺序执行？    提交人    /u/_crazy_muffin_   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1has6jq/d_is_what_im_doing_is_correct/</guid>
      <pubDate>Tue, 10 Dec 2024 03:10:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过乘性权重扰动提高对损坏的鲁棒性 - 一种简单而有效的方法，可以使神经网络对损坏具有鲁棒性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hap6gx/r_improving_robustness_to_corruptions_with/</link>
      <description><![CDATA[我们想分享和讨论这篇 NeurIPS 焦点论文（免责声明：我是合著者）。 论文：https://arxiv.org/abs/2406.16540 GitHub：https://github.com/trungtrinh44/DAMP DAMP（通过乘性扰动进行数据增强）是一种通过乘性权重扰动来提高神经网络鲁棒性的简单而有效的方法。与传统的数据增强方法不同，DAMP 在训练期间直接对模型权重进行操作，从而能够提高损坏鲁棒性，而不会影响干净图像的性能或增加计算成本。  主要亮点：  理论基础：DAMP 证明输入损坏可以等效地表示为乘性权重扰动，为权重空间数据增强提供了理论基础。 简单实现：该方法只需要随机高斯采样和逐点乘法，保持与标准 SGD 几乎相同的训练成本，同时完全兼容数据并行。 ViT 训练方面的突破：仅使用基本的预处理即可从头开始成功训练 Vision Transformers，在 ImageNet 上实现 ResNet50 级别的性能（23.7% 的 top-1 错误率），而无需复杂的增强。 高级集成：与 MixUp 和 RandAugment 结合使用时，DAMP 可显著提高清洁和损坏性能： ViT-S/16：20.09% 的清洁错误率（与基线 20.25% 相比），平均损坏误差 58.30%（与基线 60.07% 相比） ViT-B/16：清洁误差 19.36%（与基线 20.41% 相比），平均损坏误差 56.76%（与基线 58.83% 相比）   为什么选择 DAMP？与依赖复杂数据增强管道或计算成本高昂的集成方法的传统方法不同，DAMP 提供了一种简单、理论扎实的解决方案来提高模型稳健性。它能够从头开始训练 Vision Transformers，无需高级增强，并且与现有技术兼容，这使其成为开发稳健视觉模型的实用选择。 由于 DAMP 与标准训练相比开销极小，因此应用于大型模型和数据集时特别有效。  我们欢迎技术讨论，特别是关于与其他稳健性方法的理论联系以及计算机视觉以外的潜在应用！    提交人    /u/emiurgo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hap6gx/r_improving_robustness_to_corruptions_with/</guid>
      <pubDate>Tue, 10 Dec 2024 00:38:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何管理和追踪庞大且不断演变的图像数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1haokqp/d_how_do_you_manage_and_track_your_large_evolving/</link>
      <description><![CDATA[我想知道人们如何管理大型内部数据集的生命周期？比如说 &gt;1TB 和 100k 个文件。 在我的新角色中，我们有多个生产模型，这些模型是从内部数据集训练出来的，大小从几千到几十万张图像不等。我们还有大量新数据进入，每天超过 100 万张图像，因此我们不断挖掘这些数据并发送新的部分进行注释。 到目前为止，团队基本上都是自己管理这个问题，结果是可以预测的。在某些情况下，我们无法将我们的生产模型与任何特定数据关联起来。我们的一些核心数据集仅存在于人们的主目录中，很容易被一个错误的命令抹去。对于一个幸好被淘汰的模型，已知训练代码和原始训练数据都丢失了。 该组织的部分成员采用了 DVC，这似乎很不错，直到文件数量或整体大小变大。一方面，有些人将整个数据集塞进几个档案中并跟踪它们。这最大限度地减少了哈希带来的挫败感，但当只有几个文件更新时会占用大量存储空间。另一方面，有些人跟踪每个文件，这样可以单独更新文件，但签入和签出非常麻烦。其他人则将这两种方法的差异分开，以分层方式跟踪数据集的块作为档案。 那么你的组织是如何管理这一点的？在处理这些庞大且不断发展的数据集时，什么有效，什么无效？    提交人    /u/SirPitchalot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1haokqp/d_how_do_you_manage_and_track_your_large_evolving/</guid>
      <pubDate>Tue, 10 Dec 2024 00:09:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 问答评估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1han84i/d_r_question_answering_evaluation/</link>
      <description><![CDATA[除了标准的精确匹配、F1、准确度、BLEU、ROUGE、BERTScore 等指标外，是否还有其他新的指标可用于评估 QA 系统（开放域和多项选择）？我正在阅读一篇列出所有这些指标的论文（https://arxiv.org/abs/2406.13232），但我很好奇是否有人发布或正在研究一种新的指标，该指标与人类判断更好地相关和/或考虑到 LLM 提供问题答案的形式。例如，如果模型没有经过微调，很难让它们预测“答案：B”（对于多项选择 QA）之类的内容，也很难让它们预测一些简短的文字，例如“巴拉克奥巴马”（对于开放域 QA）。这种行为使得 LLM 的评估不一致，我想知道是否有人在积极致力于此。     提交人    /u/Debonargon   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1han84i/d_r_question_answering_evaluation/</guid>
      <pubDate>Mon, 09 Dec 2024 23:07:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] Meta 的全新 LLama 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1han33i/d_metas_new_llama_model/</link>
      <description><![CDATA[因此，meta 刚刚放弃了一种新的、更高效的 Llama 模型 Llama 3.3 70B，该模型基本上有望降低大型 AI 模型的计算成本。这里有人有机会测试它吗？好奇地想看看它在速度、资源使用率和准确性方面与以前的版本相比表现如何    提交人    /u/Frosty_Programmer672   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1han33i/d_metas_new_llama_model/</guid>
      <pubDate>Mon, 09 Dec 2024 23:01:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何确保 NLP 实验中小样本提示与微调之间的公平比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1haf6qq/d_how_to_ensure_fair_comparison_between_fewshot/</link>
      <description><![CDATA[我正在研究在文本分类任务中比较小样本提示机制和微调 GPT 模型。然而，我意识到在 5 倍验证设置中，与我的小样本方法相比，微调模型可以访问更多数据（例如：4 倍用于训练），而我的小样本方法仅使用有限数量的示例进行提示（目前，我从训练集中为每个类别选择 n 个样本）。  示例场景：我的数据集有 4 个类，总数据量为 100，我正在进行 4 向 5 样本实验。对于训练集，我有 80 个（因为它是 5 倍），对于测试，我有 20 个数据样本。对于微调实验，我使用全部 80 个数据，但对于小样本实验，我仅使用 80 个训练样本中的 20 个（4*5）数据。因此该方法只能访问整个训练集的 20 个样本。 这种不平衡感觉不公平，并且很难评估两种方法之间的真正性能差异。我该如何修改实验设置以确保公平比较？我是否应该限制微调模型使用与少样本提示机制中使用的相同示例？ 很想听听您的想法和建议！    提交人    /u/The_Aoki_Taki   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1haf6qq/d_how_to_ensure_fair_comparison_between_fewshot/</guid>
      <pubDate>Mon, 09 Dec 2024 17:32:25 GMT</pubDate>
    </item>
    <item>
      <title>有人遇到过 GAN 生成的图像中的线条吗？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1haeb2u/has_anyone_come_across_lines_in_image_generated/</link>
      <description><![CDATA[      所以我已经使用 GAN 一段时间了，用于简单的图像生成任务，特别是以无监督的方式训练它们。在其中许多任务中，GAN 生成的输出往往在图像上有可见的线条。这是一个例子，当我尝试生成热图时发生了这种情况。你们有人知道为什么会发生这种情况吗？以及处理它们的方法 https://preview.redd.it/c5tuc5udsu5e1.png?width=679&amp;format=png&amp;auto=webp&amp;s=0ecb84a81ec2993a147689ae3112935cc6ecf821    提交人    /u/Brief_Papaya121   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1haeb2u/has_anyone_come_across_lines_in_image_generated/</guid>
      <pubDate>Mon, 09 Dec 2024 16:56:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于蒸馏的 3D 神经辐射场着色，实现一致的新颖视图合成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hae9oo/r_distillationbased_colorization_of_3d_neural/</link>
      <description><![CDATA[本文介绍了一种知识提炼方法，用于从灰度多视图图像中对 3D 神经表征（NeRF / 3DGS）进行着色。核心思想是将颜色信息从预先训练的 2D 着色模型转移到 3D 场景表示，同时保持视图一致性。 关键技术方面： - 使用师生框架，其中 2D 着色模型指导 3D 表示 - 适用于神经辐射场和 3D 高斯溅射 - 推理期间不需要额外的参数或计算 - 处理室内/室外场景和不同类型的灰度输入（IR，历史照片） - 通过体积优化保持跨视点的颜色一致性 结果： - 在标准基准上达到或超过 SOTA 着色质量 - 成功地为具有不同光照/材质的复杂场景着色 - 有效地处理传统照片和红外图像 - 在新颖的视点中展示一致的色彩 - 与当前的 NeRF / 3DGS 实现兼容 我认为这种方法对于文化遗产应用特别有价值，使我们能够从历史黑白照片中创造身临其境的 3D 体验。红外成像功能还表明在安全和监控领域有潜在的应用，其中热数据的彩色可视化将很有用。 我认为关键优势在于它如何弥合 2D 着色和 3D 场景理解之间的差距，而无需对现有的 3D 表示进行架构更改。这使得它在现实世界中非常实用。 TLDR：新方法使用知识蒸馏从灰度图像中为 3D 神经场景着色，与 NeRF/3DGS 配合使用，保持视图一致性，无需额外的推理成本。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hae9oo/r_distillationbased_colorization_of_3d_neural/</guid>
      <pubDate>Mon, 09 Dec 2024 16:55:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人成功训练过具有模型并行性的 LLM 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1habr8l/d_has_anyone_managed_to_train_an_llm_with_model/</link>
      <description><![CDATA[您好， 我正在为我的硕士论文研究微调 Llama-3.1。不幸的是，我目前的情况不允许使用高内存 GPU，例如 A100。相反，我可以使用具有多个低内存 GPU 的设置，例如 4×3090 或 8×V100。 因此，我需要实现模型并行性来训练我的模型，因为它不适合单个 GPU。但是，我注意到大多数框架主要关注数据并行性，这并不能满足我的需求。 有没有人通过将模型拆分到多个 GPU 上来成功训练模型？如果有，您能推荐我应该探索的框架或方法吗？我特别想寻找完整的培训，尽管我有兴趣听听是否有人使用 LoRA 管理过这个。 此外，如果有更适合此类问题的 subreddit，请引导我到那里。 谢谢！    提交人    /u/anilozlu   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1habr8l/d_has_anyone_managed_to_train_an_llm_with_model/</guid>
      <pubDate>Mon, 09 Dec 2024 15:06:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 文本转视频排行榜：比较最先进的文本转视频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ha54m0/p_texttovideo_leaderboard_compare_stateoftheart/</link>
      <description><![CDATA[与文本生成不同，文本转视频生成涉及平衡真实感、对齐和艺术表达。但就输出质量而言，哪一个最重要？ 我们不知道，这就是为什么我们创建了一个基于投票的文本转视频模型排行榜，灵感来自 LLM 排行榜 lmarena.ai。 目前，排行榜有五个开源模型：HunyuanVideo、Mochi1、CogVideoX-5b、Open-Sora 1.2 和 PyramidFlow，但我们的目标是还包括来自 Kling AI、LumaLabs.ai 和 Pika.art 的著名专有模型。 这是排行榜的链接：link。 我们很乐意听到您的想法、反馈或建议。您认为应该如何评估视频生成模型？    提交人    /u/lambda-research   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ha54m0/p_texttovideo_leaderboard_compare_stateoftheart/</guid>
      <pubDate>Mon, 09 Dec 2024 08:17:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] 扩散模型、图像超分辨率以及一切：综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9wrv6/r_diffusion_models_image_superresolution_and/</link>
      <description><![CDATA[我们很高兴与大家分享我们最新的关于应用于图像超分辨率的扩散模型的调查论文。欢迎您阅读。它也是开放获取的，并发表在 IEEE TNNLS 上 :)  arXiv：https://arxiv.org/abs/2401.00736    提交人    /u/Maleficent_Stay_7737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9wrv6/r_diffusion_models_image_superresolution_and/</guid>
      <pubDate>Mon, 09 Dec 2024 00:09:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>