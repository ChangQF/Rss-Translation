<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 10 May 2024 15:13:46 GMT</lastBuildDate>
    <item>
      <title>[D] 寻找对小时工感兴趣的 ML 工程师的最佳社区/网站</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cook89/d_best_communitywebsite_to_find_ml_engineer/</link>
      <description><![CDATA[我一直在 Upwork 这样的平台上寻找机器学习工程师，但许多候选人似乎在从头开始构建模型方面经验有限。他们通常专注于集成预构建的 ML API，而不是开发根据特定要求定制的自定义模型。  哪里是寻找能够处理从数据收集到模型部署的整个模型开发过程的机器学习工程师的最佳地点？    由   提交/u/um877  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cook89/d_best_communitywebsite_to_find_ml_engineer/</guid>
      <pubDate>Fri, 10 May 2024 12:38:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mamba 中的“离散化”步骤到底是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1com9qh/d_what_on_earth_is_discretization_step_in_mamba/</link>
      <description><![CDATA[什么是“离散化”？信号/序列不是已经“离散”了吗？以代币的形式？请不要让我去看有关“线性状态空间模型的离散化”的维基百科文章，因为我无法与法学硕士建立任何联系。在我看来，Mamba 的核心只是具有动态 alpha 参数的 EMA，该参数是根据每个通道在时间 t 的当前代币计算得出的。不太明白“离散化”有什么好处？以及它对数据的实际作用。   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1com9qh/d_what_on_earth_is_discretization_step_in_mamba/</guid>
      <pubDate>Fri, 10 May 2024 10:26:48 GMT</pubDate>
    </item>
    <item>
      <title>Pycaret 不稳定 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1colzy7/pycaret_unstable_d/</link>
      <description><![CDATA[我有一个由 py​​caret 支持的预测应用程序，但是有时基于 pycaret 的模型会突然引发未知的异常，并且在大约一天后突然开始工作。我无法理解错误或此异常，因为异常表明此异常不应发生。在我的本地调试时，相同的输入工作正常。有人对此类问题有任何想法吗？是否有任何替代方法可以为预测应用程序自动生成机器学习模型？ 感谢您的支持。谢谢。   由   提交 /u/Awkward_HomoSapien   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1colzy7/pycaret_unstable_d/</guid>
      <pubDate>Fri, 10 May 2024 10:08:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过多标记预测更好更快的大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1coluve/r_better_faster_large_language_models_via/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.19737 摘要：  大型语言模型（例如 GPT 和 Llama）使用下一个进行训练- 代币预测损失。在这项工作中，我们建议训练语言模型来同时预测多个未来标记，从而提高样本效率。更具体地说，在训练语料库中的每个位置，我们要求模型使用在共享模型主干上运行的 n 个独立输出头来预测以下 n 个标记。将多标记预测视为辅助训练任务，我们测量了改进的下游能力，而代码和自然语言模型的训练时间没有开销。该方法对于较大的模型尺寸越来越有用，并且在训练多个时期时保持其吸引力。在编码等生成基准上，收益尤其明显，我们的模型始终比强大的基准高出几个百分点。与同类 next-token 模型相比，我们的 13B 参数模型在 HumanEval 上解决的问题多解决了 12%，在 MBPP 上解决的问题多解决了 17%。小算法任务的实验表明，多token预测有利于归纳头和算法推理能力的发展。另外一个好处是，即使批量大小较大，使用 4 令牌预测训练的模型的推理速度也可提高 3 倍。     ;由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1coluve/r_better_faster_large_language_models_via/</guid>
      <pubDate>Fri, 10 May 2024 09:59:31 GMT</pubDate>
    </item>
    <item>
      <title>从最后一层的隐藏状态值生成输出 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1coj061/generating_outputs_from_last_layers_hidden_state/</link>
      <description><![CDATA[在向 llama-2 模型提供特定输入（我们称之为 Input_1）后，我操纵了从 llama-2 模型获得的隐藏状态值。现在，我想检查它由此产生的输出（因果输出）。我的假设是它应该对应于不同的输入，我们称之为 Input_2，它将产生与初始输入不同的输出。 我通过以下方式获得了最后一层的隐藏状态值： &gt; from Transformers import LlamaModel, LlamaTokenizer, LlamaForCausalLM tokenizer = LlamaTokenizer.from_pretrained(path_to_llama2) model = LlamaModel.from_pretrained(path_to_llama2) model_ = LlamaForCausalLM.from_pretrained(path_to_llama2) tokenizer.pad_token = tokenizer.eos_token input = tokenizer( Prompt, return_tensors=&#39;pt&#39;) with torch.no_grad():outputs = model(**inputs,output_attentions=True,output_hidden_​​states=True)hidden_​​states=outputs.hidden_​​states[-1]#最后一层隐藏状态&lt; /pre&gt; 如上所示，我试图更改从 model 获得的 hide_states 值，但现在我想生成因果输出。我该怎么做？有什么建议吗？   由   提交/u/1azytux  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1coj061/generating_outputs_from_last_layers_hidden_state/</guid>
      <pubDate>Fri, 10 May 2024 06:35:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在实践中使用 RAG 基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1coi4iy/d_how_to_use_rag_benchmarks_in_practice/</link>
      <description><![CDATA[我正在开展一个涉及 RAG 实验的研究项目。我想首先运行模型以了解整个管道的工作原理。我在 HuggingFace 上找到了一些数据集（例如 https://huggingface.co/datasets/explodinggradients/WikiEval）。 我对 RAG 的理解是，应该给我一个数据存储，然后我使用该数据存储执行问答任务。然而，在这些数据集中，上下文与问题一起给出，我不太明白。 RAG 是否应该作为上下文问答来执行？如果是的话，它不会破坏RAG中的检索点吗？ 提出我的问题的另一种方式如下：不应该每个RAG数据集都有一个数据集级文档存储而不是随问题一起提供上下文？    由   提交/u/Tall_Sun_3096   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1coi4iy/d_how_to_use_rag_benchmarks_in_practice/</guid>
      <pubDate>Fri, 10 May 2024 05:37:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] CIFAR10培训</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co9uaf/d_training_on_cifar10/</link>
      <description><![CDATA[大家好，是否有任何已知的超参数集用于在 CIFAR10 或任何其他主要用于重建损失的著名数据集上训练扩散模型？   由   提交/u/sidney_lumet  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co9uaf/d_training_on_cifar10/</guid>
      <pubDate>Thu, 09 May 2024 22:24:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] ECCV-2024 评论已出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co7w0i/d_eccv2024_reviews_are_out/</link>
      <description><![CDATA[标题说明了一切。   由   提交/u/darkknight-6  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co7w0i/d_eccv2024_reviews_are_out/</guid>
      <pubDate>Thu, 09 May 2024 21:01:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 杰出论文奖。恭喜！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co4kfw/d_iclr_outstanding_paper_awards_congratulations/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co4kfw/d_iclr_outstanding_paper_awards_congratulations/</guid>
      <pubDate>Thu, 09 May 2024 18:42:14 GMT</pubDate>
    </item>
    <item>
      <title>[D]“特征”一词从何而来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co2ye4/d_where_does_the_term_feature_come_from/</link>
      <description><![CDATA[也许是一个愚蠢的琐事问题，但我无法弄清楚。 ML 将特征称为特征，统计将特征称为预测变量，数学将特征称为特征变量，工程也将特征变量称为特征。 我知道它们是什么，但为什么我们称它们为特征？有谁知道起源故事吗？ 编辑：你们都给了我一些很好的线索；我想我已经找到了一个看似合理的答案：它可能来自认知心理学。 介绍感知器的论文（可以说是迈向神经网络的第一步）将输入称为刺激，但也指出将刺激编码为一小组强大的特征有助于提高性能：  随着系统中响应数量的增加，如果每个响应都与所有替代方案相互排斥，那么性能会逐渐变差。避免这种恶化的一种方法（在 Rosenblatt，15 中有详细描述）是通过响应的二进制编码。在这种情况下，我们不是用 100 个不同的、相互排斥的反应来表示 100 种不同的刺激模式，而是找到有限数量的区分特征，每个特征都可以独立地识别为存在或不存在，并且因此可以用一对互斥的响应来表示。  （突出显示是我的） 稍后得出结论  可以通过使用轮廓敏感投影区域以及通过使用二元响应系统来改进系统的性能，其中每个响应或“位”都由二元响应系统来改进。对应于刺激的某些独立特征或属性。  （突出显示我的）   由   提交 /u/FirefoxMetzger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co2ye4/d_where_does_the_term_feature_come_from/</guid>
      <pubDate>Thu, 09 May 2024 17:35:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlphaMath 几乎为零：无过程的过程监督</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnu9mx/r_alphamath_almost_zero_process_supervision/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2405.03553 代码：https ://github.com/MARIO-Math-Reasoning/Super_MARIO 模型：https://huggingface.co/MARIO-Math-Reasoning/AlaphaMath-7B 摘要： &lt; blockquote&gt; 大型语言模型 (LLM) 的最新进展极大地增强了他们的数学推理能力。然而，这些模型仍然难以解决需要多个推理步骤的复杂问题，经常导致逻辑或数值错误。虽然数字错误很大程度上可以通过集成代码解释器来解决，但识别中间步骤中的逻辑错误更具挑战性。此外，手动注释这些培训步骤不仅成本高昂，而且需要专业知识。在本研究中，我们引入了一种创新方法，通过利用蒙特卡罗树搜索（MCTS）框架自动生成过程监督和评估信号，从而消除了手动注释的需要。本质上，当法学硕士经过良好的预训练时，只需要数学问题及其最终答案来生成我们的训练数据，而不需要解决方案。我们继续训练一个阶梯级价值模型，旨在改进法学硕士在数学领域的推理过程。我们的实验表明，使用由 MCTS 增强的法学硕士自动生成的解决方案可以显着提高模型处理复杂数学推理任务的能力。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnu9mx/r_alphamath_almost_zero_process_supervision/</guid>
      <pubDate>Thu, 09 May 2024 10:48:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] ECCV 2024回顾讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cntiks/d_eccv_2024_review_discussion/</link>
      <description><![CDATA[我认为，与其他会议一样，我们可能会为提交给 ECCV 的人们进行讨论，因为评论将在 10 小时内发布（晚上 10 点（欧洲中部夏令时间）。这是我第一次在任何地方提交，说实话我很紧张。   由   提交/u/mr_birrd  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cntiks/d_eccv_2024_review_discussion/</guid>
      <pubDate>Thu, 09 May 2024 10:00:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 多元时间序列的矩阵轮廓与深度学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnpo6n/d_matrix_profile_vs_deep_learning_for/</link>
      <description><![CDATA[大家好， 所以我阅读了大量的方法，特别是关于多元时间序列和实时研究的方法人类活动识别（HAR）。不过，我最近偶然发现了 Eamonn Keogh 在 Matrix Profiles 方面令人惊叹且全面的工作，最终陷入了困境。  但是出于好奇，在多元时间序列和实时数据流的背景下，矩阵配置文件与深度学习方法（例如 MLP、LSTM 等）相比如何？  我很想听听其他人的观点！   由   提交 /u/peachjpg111   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnpo6n/d_matrix_profile_vs_deep_learning_for/</guid>
      <pubDate>Thu, 09 May 2024 05:31:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审稿人你们都需要停止如此懒惰的狗。为什么审稿人做事这么懒？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnn54n/d_reviewers_you_all_need_to_stop_being_so_lazy/</link>
      <description><![CDATA[我提交了一篇论文。 被会议接受了。 收到来自 _insert_university_ 的某个随机家伙的电子邮件。发送给主席和会议负责人。 指控我抄袭，并说已发表论文的匹配率为 92%... 检查交叉引用。标题、作者（我和导师）、数据、结论，几乎整篇论文都突出显示。 只有来源说是 Arkiv。我碰巧在那里有我的预印本。我遵循了他们的预印本政策并发布了通知。 现在，这非常愚蠢。我做了很多尽职调查，如果它与作者相匹配，它必须引用我的预印本。 为什么审稿人如此懒惰，可以采取如此激烈的行动，而不是直接向作者询问这些问题？我真的不理解这些人中的一些人。您对如何处理这些情况有什么建议吗？    提交人    /u/I_will_delete_myself   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnn54n/d_reviewers_you_all_need_to_stop_being_so_lazy/</guid>
      <pubDate>Thu, 09 May 2024 03:03:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>