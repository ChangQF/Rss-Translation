<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 19 Feb 2024 15:13:38 GMT</lastBuildDate>
    <item>
      <title>[D] Mamba 和状态空间模型的视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aupbct/d_a_visual_guide_to_mamba_and_state_space_models/</link>
      <description><![CDATA[大家好！为了使状态空间模型（和 Mamba）更容易被更广泛的受众接受，我创建了底层技术的视觉指南。 https://maartengrootendorst.substack.com/p/a-visual-guide-to-mamba-and-state 通过 50 多个自定义可视化，我希望它为那些对用于语言建模的 Mamba 和状态空间模型感兴趣的人提供一个直观的起点。 我们的想法是专注于直觉，使这一潜在的新功能成为可能。对于该领域的新手来说，架构很容易理解。我确保尽可能将方程式保持在最低限度。 希望这将为那些完全陌生的人提供一个很好的介绍。 如果您有任何反馈和/或者更正，我洗耳恭听！    由   提交 /u/MaartenGr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aupbct/d_a_visual_guide_to_mamba_and_state_space_models/</guid>
      <pubDate>Mon, 19 Feb 2024 15:01:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 放弃 AWS Rekognition</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auo1g8/d_moving_away_from_aws_rekognition/</link>
      <description><![CDATA[最近 AWS 识别开始成为我项目的成本问题，我只将其用于对象识别（AI Lables）。我目前正在寻找本地解决方案，但不幸的是我目前没有时间或劳动力来创建和训练数据集。 我想知道是否有任何预训练的对象识别模型可以为 AWS rekognition 提供一组类似的类（约 3,000 个）。似乎大多数开源模型都是针对仅包含约 80 个类的 COCO 数据集进行预训练的。 我已经寻找了好几天，但仍然无法解决任何问题，付费模型也是一种选择价格当然合理。   由   提交/u/Redserpent7  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auo1g8/d_moving_away_from_aws_rekognition/</guid>
      <pubDate>Mon, 19 Feb 2024 14:04:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI项目建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aunkmw/d_ai_projects_suggestions/</link>
      <description><![CDATA[大家好，我需要一个为学生创建人工智能课程（人工智能实践项目）的建议。我正在思考最新的人工智能趋势，例如Langchain、RAG和矢量数据库。每个项目中可以有多个任务，最主要的是每个任务都应该有一个自动化系统，我们可以在其中验证学生是否正确完成。 例如：具有可视化的项目不能进行自动测试。  例如：具有可视化的项目无法自动测试。 。 em 可以验证文本的长度是否更小，我们可以验证它是否正确。   由   提交 /u/SnooTigers4634   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aunkmw/d_ai_projects_suggestions/</guid>
      <pubDate>Mon, 19 Feb 2024 13:42:09 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 回归损失函数中对数标度逆频率加权的参考搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aun6pu/dr_reference_search_for_logarithmically_scaled/</link>
      <description><![CDATA[我正在处理一种回归任务，对于给定的图像，CNN 预测一个距离掩模，即每个像素报告一个距离某些检测到的感兴趣对象所在的最近像素。这些值被剪切到某个最大距离并重新缩放到 [0, 1] 范围，这意味着直接位于对象上的像素应预测 0，距离足够远的像素应预测 1，而介于两者之间的像素应预测中间值。 在我们的例子中，这是一个不平衡的问题 - 最终您得到的背景（1 值）区域比对象（0 值）区域多得多。为了解决这个问题，我们使用了一种特殊形式的逆频率加权。对连续预测值进行分箱后，我们可以获得它们在真实情况中的出现频率f，并用它来对基本损失函数进行加权，这是一个简单的MSE。我们没有使用 1/f 权重，而是使用 1/log(f + 1 + epsilon)，其中 epsilon 只是一个非常小的数字，以避免可能被 0 除. 现在，以这种方式加权的想法来自实验室的另一位同事，他现在不知道他从哪里得到它，尽管我们认为它来自他之前的一些工作，他必须有已经看见。这种加权对于我们的问题非常有效，我想知道是否有可以在此处引用的相关来源。 您知道任何可以引入这种加权方式的相关参考文献吗？最好是在回归任务的背景下？谢谢！   由   提交 /u/Bzdeco   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aun6pu/dr_reference_search_for_logarithmically_scaled/</guid>
      <pubDate>Mon, 19 Feb 2024 13:23:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何获得 vit-b-8-DINO 的注意力图？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aumrta/d_how_can_i_get_attention_maps_for_vitb8dino/</link>
      <description><![CDATA[我正在尝试使用 vit-b-8-DINO 获取高分辨率图像的一些注意力图，将其上采样到 (1440,1440)，但它不断收到错误消息，指出 CUDA 内存不足。我有8*3090 GPU，每个GPU有24GB内存，我使用了DataParallel，但是通过监控后台，我发现只有两个GPU的内存发生了变化。   由   提交/u/Holiday-Candy-9727   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aumrta/d_how_can_i_get_attention_maps_for_vitb8dino/</guid>
      <pubDate>Mon, 19 Feb 2024 13:02:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从手游截图中提取可见信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aum911/p_extracting_visible_information_from_a_mobile/</link>
      <description><![CDATA[      Polytopia 是一款（主要是）手机游戏，您可以在基于图块的地图上展开，发现更多图块并消灭敌人（包括示例屏幕截图）。  屏幕截图的示例比如：有很多不同的元素，但位置很谨慎 我想从屏幕截图中提取信息（主要是有关地图的信息 - 其余的并不那么重要）。 &lt; p&gt;​ 我有一些代码可以计算出每个图块中心的位置，但它在很大程度上依赖于云的存在（一个在游戏开始时几乎无处不在的游戏元素）但可能会在结束之前完全删除）。 ​ 我制作了第一个版本，它提取一个图块并通过连续的分类器运行它。虽然它有效，但它在挑选城市边界或道路方面并不是很有效，这些元素是跨越多个图块的元素。 我可以使用分段，但考虑到图块以及对象位置，这感觉很浪费，保证是谨慎的。 一个图块必须经过的多个分类听起来像是多任务网络的一项工作。 ​ &lt; p&gt;什么架构最适合这个项目？我打算尝试几个，但我错过了一个吗？   由   提交 /u/a1b2c3d4e5f6g8   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aum911/p_extracting_visible_information_from_a_mobile/</guid>
      <pubDate>Mon, 19 Feb 2024 12:34:22 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]R中的dtw函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aukhth/discussion_dtw_function_in_r/</link>
      <description><![CDATA[我正在查看两个时间序列之间的动态时间规整 (DTW) 距离。我在R中看到了dtw()函数。现在，假设我有2个时间序列数据，一个在1000的长度上值为2，另一个在1000的长度上值为7，这两个时间序列之间的DTW距离数据应为 5000 个单位。但是，当我使用 R 中的 dtw() 函数查找 DTW 距离时，它显示 9995，我不知道为什么。有人可以向我解释一下吗？ k &lt;- rep(2,1000) k &lt;- ts(k,start=1)  kk &lt;-rep(7,1000)kk&lt;-ts(kk,start=1)kkk&lt;-dtw(k,kk,distance.only= TRUE) 查看(kkk)   由   提交/u/campbell513  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aukhth/discussion_dtw_function_in_r/</guid>
      <pubDate>Mon, 19 Feb 2024 10:46:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 性能最好的 GPT PyTorch 训练代码库是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auigtp/d_whats_the_most_performant_gpt_pytorch_training/</link>
      <description><![CDATA[使用 PyTorch 训练 GPT 模型的性能最高的开源代码库是什么（基于模型 FLOP 利用率）？   由   提交 /u/gggerr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auigtp/d_whats_the_most_performant_gpt_pytorch_training/</guid>
      <pubDate>Mon, 19 Feb 2024 08:28:31 GMT</pubDate>
    </item>
    <item>
      <title>数据采样方法[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auhgds/data_sampling_methods_d/</link>
      <description><![CDATA[我正在开发一个项目，需要收集数据样本来测试模型。我一直在研究基于概率的方法来获得好的样本，但没有找到太多有用的信息。有人知道我可以从哪里开始吗？ 更新：我不是在研究固定模型。我想知道如何对文本和图像模型执行此操作。   由   提交/u/Azrael-1810  /u/Azrael-1810 reddit.com/r/MachineLearning/comments/1auhgds/data_sampling_methods_d/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auhgds/data_sampling_methods_d/</guid>
      <pubDate>Mon, 19 Feb 2024 07:22:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT-4真的可以同时是16x111B和1.8T参数吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1augpo3/d_can_gpt4_really_be_both_16x111b_and_18t/</link>
      <description><![CDATA[Semianalysis 7 月份的一份报告称，GPT-4 是一个 1.8T 参数的 MoE 模型，有 16 个专家，每个专家有 111B 个参数。这是根据我读过的摘要得出的，因为我无法通过付费专区。 这两个数字似乎是一致的，因为 16 * 111B = 1.776T 大约等于 1.8T。&lt; /p&gt; 但我读到这不是计算专家混合模型中参数总数的正确方法。例如，人们通常认为 Mixtral 8x7B 有 56B 参数，但实际上只有 47B。我（可能不正确）的理解是，当你说模型是 8x7B 时，这意味着如果你只从每个 MoE 层选择一名专家，那么模型将具有 7B 个参数。将 Mixtral 计算为具有 8*7B=56B 参数将会多计算注意力权重、嵌入权重和路由器权重 7 倍，当你减去它时，你会得到 47B。 如果这是真的，那么 1.776T 同样会高估 GPT-4 中的参数数量，并且会四舍五入到 1.7T 甚至更低，除非几乎所有权重都在 MoE 块中。 这是推理吗正确的？我了解如何计算 MoE 变压器中的参数吗？   由   提交/u/kei147  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1augpo3/d_can_gpt4_really_be_both_16x111b_and_18t/</guid>
      <pubDate>Mon, 19 Feb 2024 06:35:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI/ML 实习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1audi2u/d_aiml_internships/</link>
      <description><![CDATA[为什么现在 AI/ML 领域的实习这么难？  我目前拥有一些高级人工智能项目的一年经验。但不知何故，我无法找到任何实习机会。至于工作，我几乎找不到需要5年以下经验的工作。说实话，这令人沮丧。有人可以帮忙吗？   由   提交/u/Anonymous_Life17  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1audi2u/d_aiml_internships/</guid>
      <pubDate>Mon, 19 Feb 2024 03:34:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要 ICLR 会议资金的独立研究员。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atzs7o/d_independent_researcher_in_need_of_funding_for/</link>
      <description><![CDATA[大家好， 我非常高兴地告诉大家，我的论文已被 ICLR 2024 会议接受！这是梦想成真，但我面临着重大的财务障碍。我作为独立研究员与我的硕士课程教授一起完成了这项工作。不幸的是，我最近被解雇了，目前正在寻找新的机会。 会议费用很高——一般注册费为 950 美元，甚至学生费也是 450 美元。作为一名失业的研究人员，这些费用根本无法承受。然而，我决心亲自参加我的第一次会议，展示我的工作、人际网络，并为新的就业前景打开潜在的大门。 令人难以置信的是，许多会议没有特定的类别独立研究人员。 对于针对我的情况寻找资金，您有什么建议或建议吗？是否为想要参加会议的失业研究人员提供补助金、奖学金或资源？我可能不知道任何潜在的选择？ 我将非常感谢任何支持或建议！ 提前致谢！   由   提交 /u/Vjraven   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atzs7o/d_independent_researcher_in_need_of_funding_for/</guid>
      <pubDate>Sun, 18 Feb 2024 17:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 第一作者排序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aty0et/d_first_author_ordering/</link>
      <description><![CDATA[嗨，我是深度学习领域的初级研究员。我和我的同事正在寻求向 ECCV24 提交一篇论文。我和她已经一起工作了大约一年。我们即将提交的项目主要是我的想法，我构建了代码库。她帮助我计划实验并写论文。我们俩都是共同第一作者。我们计划在提交给会议之前将其提交到 arxiv 上。她给我下了最后通牒，如果我在 arxiv 上首先选择我的名字，那么我就不能在会议论文中把我的名字放在第一位，反之亦然。由于这是我的第一篇论文，而且我做了很多工作，所以我觉得我应该在两篇论文提交中被列为第一名。我的问题是： 1.从长远来看，这对我的职业生涯有多大影响？ 2. 如果我确实调换顺序，我应该成为 ECCV 还是 Arxiv 的第一作者？我想尽量减少冲突，同时为我的职业生涯做出最好的决定，而不是太小气。作为背景，她已经有一篇以她为第一作者的论文。请帮帮我！提前致谢！   由   提交/u/darkmatter6698   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aty0et/d_first_author_ordering/</guid>
      <pubDate>Sun, 18 Feb 2024 16:29:06 GMT</pubDate>
    </item>
    <item>
      <title>[N] Google 博客文章“什么是长上下文窗口？”指出其结果用于 Gemini 1.5 Pro 的长上下文项目需要“一系列深度学习创新”，但没有具体说明这些创新是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1attgz7/n_google_blog_post_what_is_a_long_context_window/</link>
      <description><![CDATA[来自什么是一个很长的上下文窗口吗？:  “我们最初的计划是在上下文中实现 128,000 个代币，我认为设定一个雄心勃勃的标准会很好，所以我建议 100 万个令牌，”谷歌 DeepMind 研究科学家尼古拉·萨维诺夫 (Nikolay Savinov) 说道，他是长上下文项目的研究负责人之一。 “现在我们的研究甚至超过了这个数字 10 倍。”  为了实现这种飞跃，团队必须进行一系列深度学习创新。谷歌 DeepMind 工程师 Denis Teplyashin 解释道：“一个突破引发了另一个突破，每一个突破都开辟了新的可能性。” “然后，当它们全部堆叠在一起时，我们非常惊讶地发现它们可以做什么，从 128,000 个代币跃升至 512,000 个代币，再到 100 万个代币，而就在最近，我们的内部研究中增加了 1000 万个代币。”  相关帖子：[D] Gemini 1M/10M 令牌上下文窗口如何？&lt; /a&gt;   由   提交 /u/Wiskkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1attgz7/n_google_blog_post_what_is_a_long_context_window/</guid>
      <pubDate>Sun, 18 Feb 2024 12:55:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>