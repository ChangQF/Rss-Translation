<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 28 Jan 2025 12:31:30 GMT</lastBuildDate>
    <item>
      <title>[D] DeepSeek 的 560 万美元培训成本：人工智能开发的误导性基准？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibzsxa/d_deepseeks_56m_training_cost_a_misleading/</link>
      <description><![CDATA[各位 ML 爱好者， DeepSeek 最近宣布其 DeepSeek-V3 模型的训练成本为 560 万美元，这引起了 AI 社区的极大兴趣。虽然这个数字代表着一项令人印象深刻的工程壮举，并且是朝着更容易获得的 AI 开发迈出的潜在一步，但我认为我们需要批判性地审视这个数字及其含义。 560 万美元的数字：它代表什么  DeepSeek-V3 的最终训练运行成本 基于两个月内 2,048 个 H800 GPU 处理了 14.8 万亿个令牌 假定 GPU 租赁价格为每小时 2 美元  这个成本中缺少什么？  研发费用：先前的研究、失败的实验和前体模型 数据成本：获取和准备训练数据集 人员：研究和工程团队的工资 基础设施：电力、冷却和维护 硬件： GPU（可能数亿）  更大的图景 一些分析师估计，DeepSeek-V3 的总研发预算可能在 1 亿美元左右，更保守的估计是 DeepSeek 每年的运营预算在 5 亿美元到 10 亿美元之间。 讨论问题  我们应该如何对 AI 开发成本进行基准测试，以更准确地表示所需的资源？ 只关注最终的训练运行成本会产生什么影响？ 这个 560 万美元的数字与达到 AI 开发这一点所需的总投资相比如何？ 低估 AI 研发的真实成本有哪些潜在风险？  虽然我们应该庆祝 DeepSeek 取得的工程和科学突破，以及他们对开源社区的贡献，但重点是这 560 万美元找出衡量人工智能发展进展的正确方法？ 我渴望听到您对此事的想法和见解。让我们进行建设性的讨论，讨论如何更好地理解和传达推动人工智能技术边界的真正成本。    提交人    /u/BubblyOption7980   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibzsxa/d_deepseeks_56m_training_cost_a_misleading/</guid>
      <pubDate>Tue, 28 Jan 2025 11:49:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对 3 个或更多重叠说话人的说话人分类模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibzhsc/d_speaker_diarization_models_for_3_or_more/</link>
      <description><![CDATA[我正在寻找能够同时识别至少三个（理想情况下更多）重叠说话人的说话人日记模型。我研究了pyannote，但他们的模型似乎只支持同一时间戳的两个重叠说话人，而识别三个或更多说话人需要进行微调。 有人可以推荐一个支持这一点的开放模型吗？我只关心分析每个说话人的讲话时间，以及他们重叠的程度——我想用它来分析政治辩论。谢谢！    提交人    /u/6NBUonmLD74a   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibzhsc/d_speaker_diarization_models_for_3_or_more/</guid>
      <pubDate>Tue, 28 Jan 2025 11:29:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] TTS 数据的超分辨率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibyp6p/d_super_resolution_for_tts_data/</link>
      <description><![CDATA[嗨， 我想使用 16khz 的野生音频来训练 TTS 模型。因此我想将其上采样到 24khz。您会推荐哪种开源模型来执行此任务？ 我尝试了几个：Resemble-Enhance、AudioSR 和 AP-BWE。只要数据量不是太大，AudioSR 似乎是一个不错的选择。我将笔记放入了博客文章。还有什么我应该看的吗？    提交人    /u/clementruhm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibyp6p/d_super_resolution_for_tts_data/</guid>
      <pubDate>Tue, 28 Jan 2025 10:34:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于模型的强化学习和无模型的强化学习有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibyiv6/d_whats_the_difference_between_modelbased_and/</link>
      <description><![CDATA[我试图理解基于模型和无模型强化学习之间的区别。据我所知：  无模型方法直接从真实经验中学习。它们观察当前状态，采取行动，然后以下一个状态和奖励的形式接收反馈。这些模型没有任何内部表示或对环境的理解；它们只是依靠反复试验来随着时间的推移改进其行动。 基于模型的方法则通过创建“模型”或环境模拟来学习。它们不仅仅是对状态和奖励做出反应，还试图模拟未来会发生什么。这些模型可以使用监督学习或学习函数（如 s′=F(s,a)s&#39; = F(s, a)s′=F(s,a) 和 R(s)R(s)R(s)）来预测未来状态和奖励。他们本质上建立了一个环境模型，并用它来规划行动。  因此，关键的区别在于基于模型的方法使用其学习到的模型来近似未来并提前规划，而无模型方法仅通过直接与环境交互来学习，而不尝试模拟它。 这样说对吗，还是我遗漏了什么？    提交人    /u/volvol7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibyiv6/d_whats_the_difference_between_modelbased_and/</guid>
      <pubDate>Tue, 28 Jan 2025 10:21:49 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 开源项目或研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibwkn5/discussion_open_source_projects_or_research_papers/</link>
      <description><![CDATA[与此类似的开源项目或研究论文     由   提交  /u/Arthion_D   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibwkn5/discussion_open_source_projects_or_research_papers/</guid>
      <pubDate>Tue, 28 Jan 2025 07:49:10 GMT</pubDate>
    </item>
    <item>
      <title>[P]在 Numpy 上实现 GPT1</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibohv3/p_implement_gpt1_on_numpy/</link>
      <description><![CDATA[大家好， 这是我关于在 Numpy 上实现 GPT1 的博客文章：https://mburaksayici.com/blog/2025/01/27/GPT1-Implemented-NumPy-only.html 我很高兴收到批评/反馈。    提交人    /u/mburaksayici   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibohv3/p_implement_gpt1_on_numpy/</guid>
      <pubDate>Tue, 28 Jan 2025 00:12:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有人试过写一份没有参考部分的 CVPR 反驳吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibllko/r_anyone_tried_writing_a_cvpr_rebuttal_without_a/</link>
      <description><![CDATA[我正在准备 CVPR 反驳，由于只允许一个 PDF，我正在考虑删除参考部分。是否可以在论文中引用引文而不在反驳中再次明确列出它们？我知道我不需要引用新论文。 以前有人处理过这种情况吗？如果在反驳中看不到单独的参考部分，审稿人会觉得奇怪或不方便吗？ 寻求建议或见解！    提交人    /u/Training-Adeptness57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibllko/r_anyone_tried_writing_a_cvpr_rebuttal_without_a/</guid>
      <pubDate>Mon, 27 Jan 2025 22:07:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Deepseek R1 精简版本之间的审查差异</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibkckg/d_censorship_differences_in_deepseek_r1_between/</link>
      <description><![CDATA[      一些帖子正在流传Reddit 和其他平台上的提示都显示了 Deepseek R1 中的审查制度。我尝试过它们，但发现了一些有趣的差异，Llama 8B 的限制较少。 （不过，很难说这些差异会持续多久） 我检查了 Llama (8B) 和 Qwen (7B) Distilled 版本。 https://preview.redd.it/rso0bxndrlfe1.png?width=417&amp;format=png&amp;auto=webp&amp;s=592e5eda5568d0b2fadfb19df313946dbbbf9cab 这是不同型号的相同问题： Llama 8B 蒸馏 Qwen 7B 蒸馏 Qwen 7b 蒸馏的审查答案每次都会变化。未经审查的 Llama 8B 似乎很稳定。 话虽如此，Llama 8B 版本仍然显示出一些审查制度和其他问题： Llama 8B destiled    提交人    /u/Total_Firefighter_59   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibkckg/d_censorship_differences_in_deepseek_r1_between/</guid>
      <pubDate>Mon, 27 Jan 2025 21:16:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] Deepseek R1 究竟是如何大幅降低训练成本的？我读到的大多数帖子都是关于它的性能、强化学习、思路链等，但不清楚模型训练成本是如何大幅降低的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibijhg/d_how_exactly_did_deepseek_r1_achieve_massive/</link>
      <description><![CDATA[  由    /u/eyio  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibijhg/d_how_exactly_did_deepseek_r1_achieve_massive/</guid>
      <pubDate>Mon, 27 Jan 2025 20:02:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们如何存储/流式传输 LLM 嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibe0bm/d_what_do_people_do_for_storingstreaming_llm/</link>
      <description><![CDATA[对于一个学术项目，我想计算每个标记的嵌入，将它们存储在磁盘或内存中，并将它们流式传输以进行快速实验，同时微调模型（比 LLM 小得多）。 有哪些库（db？）、数据结构和最佳实践？一些注意事项：  希望最大限度地减少嵌入计算（成本）。 嵌入是 ~1k 32 位浮点数。 序列通常约为 20-500 个标记。 在模型训练中流式传输预计算嵌入以进行微调。 完整数据集约为 500k 个短语，磁盘上约 4TB（未压缩）。 我的应用程序不存在量化模型。 一些“有意义”的数据集子集可以放入内存（几 GB）。 最终共享数据集以供研究。 开源友好 寻找更标准化与新颖的数据库解决方案（主要是为了长寿）     提交人    /u/LetsTacoooo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibe0bm/d_what_do_people_do_for_storingstreaming_llm/</guid>
      <pubDate>Mon, 27 Jan 2025 17:02:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于几年后重返该行业的人，您有什么建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib6c03/d_what_would_you_suggest_a_person_who_is_coming/</link>
      <description><![CDATA[2013 年，我开始深入研究机器人技术并建立模型，2015 年深入研究 ML，2017-18 年深入研究 DL 和 GAN，但从 2019 年起，生活有其他计划，目前在商业方面，我敢说每一天对我来说都是新的。每当人工智能世界出现新消息时，我当然都会被它吸引。  你会建议我回到技术方面吗？我该如何开始，从哪里开始！我已经几年没有编码了，现在我觉得自己有点笨    提交人    /u/ImaginationAny2254   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib6c03/d_what_would_you_suggest_a_person_who_is_coming/</guid>
      <pubDate>Mon, 27 Jan 2025 11:19:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么在损失函数（例如线性回归损失函数）中不使用 4、6 等更高的偶数幂？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib3dhn/d_why_higher_even_powers_like_4_6_etc_are_not/</link>
      <description><![CDATA[我们知道奇数幂会导致非凸函数，并且函数也不可微。但是为什么我们不使用偶数幂，例如 4 等？我在一次采访中被问到这个问题，我说也许计算成本会很高，并且会对异常值进行更多惩罚。但他们似乎仍然不满意。我还遗漏了什么其他原因？    提交人    /u/maaKaBharosaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib3dhn/d_why_higher_even_powers_like_4_6_etc_are_not/</guid>
      <pubDate>Mon, 27 Jan 2025 08:17:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepSeek 为什么开源他们的工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/</link>
      <description><![CDATA[如果他们的培训效率提高 45 倍，他们本可以主宰 LLM 市场。你认为他们为什么选择开源他们的工作？这对他们的公司有什么好处？现在美国的大型实验室可以说：“我们将采用他们的优秀想法，并将它们与我们的秘密想法结合起来，我们仍然会领先”  编辑：DeepSeek 现在是 App Store 中排名第一。此外，DeepSeek-R1 现在在 LLM Arena 中排名第一（使用 StyleCtrl）。它们与其他 3 个模型共享此排名：Gemini-Exp-1206、4o-latest 和 o1-2024-12-17。    提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/</guid>
      <pubDate>Mon, 27 Jan 2025 07:48:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>