<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 10 Dec 2024 18:25:19 GMT</lastBuildDate>
    <item>
      <title>[D] 从失业到 Lisp：在青少年的深度学习编译器上运行 GPT-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb7v5h/d_from_unemployment_to_lisp_running_gpt2_on_a/</link>
      <description><![CDATA[几个月前，我失业了，不知道下一步该做什么。我想从系统的角度更多地了解深度学习。在学习了吴恩达的监督学习课程后，我渴望更多地了解像 Pytorch 或 Tinygrad 这样的深度学习框架（或深度学习编译器）。 我开始研究 Tinygrad，从我在网上找到的教程中学习，我发现它很有趣，因为它是一个真正的编译器，它采用传统的 Python 代码并将其转换为抽象语法树，然后将其解析为 UOps 和 ScheduleItems，最终拥有一个代码生成层。虽然设计很有趣，但代码很难读。 就在那时，我偶然发现了一些完全出乎意料的东西，一个基于 Common Lisp 构建的深度学习编译器，由一名 18 岁的日本年轻人在他的间隔年期间维护。目前我们已经完成了一件伟大的事情，它可以运行 gpt2！ 目前，它只是生成 C 内核，但未来我们希望支持 cuda codegen 以及许多其他功能，并作为任何想要使用 Common Lisp 进行深度学习编译器工作的人的学习工具。 这是一个开源项目，欢迎任何人做出贡献！ https://github.com/hikettei/Caten    提交人    /u/yCuboy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb7v5h/d_from_unemployment_to_lisp_running_gpt2_on_a/</guid>
      <pubDate>Tue, 10 Dec 2024 18:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 什么阻止您使用基础模型进行时间序列预测？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb7ur1/d_whats_stopping_you_from_using_foundation_models/</link>
      <description><![CDATA[我一直在尝试基础模型，例如 Sulie、Granite TTM 和 Amazon Chronos，每个模型都有自己的优势。真正令人着迷的是，使用零样本方法可以更快地获得准确的预测。然而，尽管这些模型改进了预测，但与更易于解释的 ARIMA 等更传统的方法相比，可解释性仍然是一个重大挑战。 我很好奇 - 您认为可解释性是决定性因素吗，或者还有其他原因导致基础预测模型没有得到更广泛的采用？很想听听您在使用这些模型时遇到的最大障碍或挑战是什么。    提交人    /u/Queasy_Emphasis_5441   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb7ur1/d_whats_stopping_you_from_using_foundation_models/</guid>
      <pubDate>Tue, 10 Dec 2024 18:00:23 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于供暖系统机器学习的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb5dty/d_question_about_heating_system_machine_learning/</link>
      <description><![CDATA[您好，在传统的加热过程中，您可以控制何时开始加热以及何时使用目标值停止加热。一旦达到目标值，它将停止并一遍又一遍地启动整个过程，同时还会控制一些泵阀（有多少水需要循环）。 在过去 5 年（每分钟），我已经在时间序列数据库中捕获了几个室温、所有启动/停止以及加热自动化软件所做的泵阀调整。 我正在尝试创建一个具有恒定目标值的模型，例如 23°C。该模型的输入是加热系统状态（开/关）、泵阀位置和当前室温。输出应该是如何设置加热系统状态并调整阀门位置以达到并保持室温的目标值。在最好的情况下，它应该完全取代加热自动化软件。其他的就是仅仅建议或监督这个过程。 我想到了一些问题，我不知道该如何处理：  这个过程很慢，一旦开始加热，由于温度变化缓慢，1 小时后才能看到结果。那么对行动的评估必须延迟吗？ 我捕获的数据包含历史温度，但我认为它可能有缺陷。数据中的温度已经受到现有加热系统的影响。我没有温度数据显示在没有任何加热系统的情况下室温是如何变化的。这是学习的问题吗？我需要创建合成数据吗？ 训练一个模型来输出“开始加热/停止加热”（将其余部分留给传统的加热自动化）还是控制加热状态和泵阀本身会更好？ 什么是最好的机器学习技术，例如无监督，强化学习？     提交人    /u/QuickYogurt2037   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb5dty/d_question_about_heating_system_machine_learning/</guid>
      <pubDate>Tue, 10 Dec 2024 16:15:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 这个数据集到底有多难？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb54nd/r_how_difficult_is_this_dataset_really/</link>
      <description><![CDATA[新论文提醒！ 分类自动编码器测量分类难度并检测标签错误 我们倾向于认为训练分类器的挑战是由超参数调整或模型创新来处理的，但数据及其嵌入中存在丰富的固有信号。了解机器学习问题的难度一直很难。现在不再如此。 现在，您可以计算分类数据集的难度，而无需训练分类器，并且每个类别只需要 100 个标签。而且，这个难度估计与数据集大小出奇地无关。 传统上，数据集难度评估方法耗时和/或计算密集型，通常需要训练一个或多个大型下游模型。更重要的是，如果你在数据集上训练具有特定架构的模型并实现特定的准确度，则无法确定你的架构是否完全适合手头的任务 - 可能是一组不同的归纳偏差会导致模型更轻松地学习数据中的模式。 我们的方法为每个类训练一个轻量级自动编码器，并使用重建误差的比率来估计分类难度。在 100k 样本数据集上运行此数据集难度估计方法只需几分钟，并且不需要调整或自定义处理即可在新数据集上运行！ 效果如何？我们对 19 个常见的视觉数据集进行了系统研究，将我们的方法估计的难度与 SOTA 分类准确度进行了比较。除了一个异常值外，相关性为 0.78。它甚至适用于医疗数据集！ 论文链接：https://arxiv.org/abs/2412.02596 GitHub Repo Linked in Arxiv pdf    提交人    /u/ProfJasonCorso   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb54nd/r_how_difficult_is_this_dataset_really/</guid>
      <pubDate>Tue, 10 Dec 2024 16:04:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 理解 Transformer 在图形搜索中的局限性：学习和扩展行为的机制分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb1wjo/r_understanding_transformer_limitations_in_graph/</link>
      <description><![CDATA[本文通过研究 transformer 如何处理图连通性问题，解决了关于 transformer 学习搜索算法的能力的一个基本问题。作者开发了一种新颖的解释方法来分析 Transformer 如何逐层处理搜索操作。 关键技术要点：- 使用图可达性作为测试用例，具有可控的复杂性和无限的训练数据- 开发解释技术来了解 Transformer 层如何计算可达顶点集- 发现 Transformer 学习随着深度呈指数级扩展搜索边界- 展示了基于图大小的明显扩展限制- 表明上下文学习（思路链）无法克服这些限制 主要结果：- 小型 Transformer 在经过适当训练后可以学习基本搜索- 每一层计算先前可达顶点及其邻居的并集- 随着图大小的增加，性能急剧下降- 添加参数并不能解决扩展问题- 模型在处理超出其训练分布的图时遇到困难 我认为这项工作揭示了 Transformer 中重要的架构限制，我们需要为需要搜索功能的应用程序解决这些限制。缩放行为表明，对于更大的搜索空间，而不仅仅是更大的模型，我们可能需要从根本上不同的方法。 我认为他们开发的解释方法对于理解 Transformer 如何处理除图形之外的其他类型的结构化数据很有价值。关于扩展限制的明确经验结果应该为涉及搜索类计算的应用程序的架构选择提供参考。 TLDR：Transformer 可以学习基本的图形搜索操作，但在扩展方面面临根本限制。添加更多参数无济于事，这表明我们需要新的方法来解决复杂的搜索问题。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb1wjo/r_understanding_transformer_limitations_in_graph/</guid>
      <pubDate>Tue, 10 Dec 2024 13:37:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 模型出处：您如何追踪您的 ML 模型谱系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb0o4e/d_model_provenance_how_are_you_tracking_your_ml/</link>
      <description><![CDATA[嘿 r/MachineLearning，我很好奇这个社区的人们是如何处理模型出处的 - 在整个生命周期中跟踪机器学习模型的谱系和演变的实践。  您目前是否使用任何工具或方法来跟踪您的 ML 模型的出处？ 如果是，您使用什么解决方案？它们是定制的还是现成的？ 如果不是，您是否认为您的工作需要这样的工具？ 您认为模型出处解决方案中的哪些功能必不可少？     提交人    /u/crtahlin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb0o4e/d_model_provenance_how_are_you_tracking_your_ml/</guid>
      <pubDate>Tue, 10 Dec 2024 12:29:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] The Well：机器学习的大规模多样化物理模拟集合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1haz4nw/r_the_well_a_largescale_collection_of_diverse/</link>
      <description><![CDATA[数据集：https://github.com/PolymathicAI/the_well 论文：https://arxiv.org/pdf/2412.00568 摘要：  基于机器学习的替代模型为研究人员提供了加速基于模拟的工作流程的强大工具。然而，由于该领域的标准数据集通常涵盖一小部分物理行为，因此很难评估新方法的有效性。为了解决这一差距，我们引入了 Well：一个包含各种时空物理系统的数值模拟的大规模数据集集合。 The Well 汇聚了领域专家和数值软件开发人员的智慧，提供了 16 个数据集的 15TB 数据，涵盖生物系统、流体动力学、声散射以及河外流体或超新星爆炸的磁流体动力学模拟等不同领域。这些数据集可以单独使用，也可以作为更广泛的基准套件的一部分使用。为了方便使用 The Well，我们提供了一个统一的 PyTorch 界面来训练和评估模型。我们通过引入示例基线来演示该库的功能，这些示例基线突出了 The Well 复杂动态所带来的新挑战。代码和数据可在此 https URL 上找到。     提交人    /u/StartledWatermelon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1haz4nw/r_the_well_a_largescale_collection_of_diverse/</guid>
      <pubDate>Tue, 10 Dec 2024 10:49:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你是如何跟上文学发展的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hasdlo/d_how_do_you_keep_up_with_the_literature/</link>
      <description><![CDATA[标题基本就是这个意思。你用什么工具/策略来跟上文献的步伐？ 编辑：为了便于理解，我是一名一年级博士生，我指的是特定“利基”领域的文献（如果除了极少数例外，你可以在 ML 中将任何东西称为利基的话）    提交人    /u/Rickmaster7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hasdlo/d_how_do_you_keep_up_with_the_literature/</guid>
      <pubDate>Tue, 10 Dec 2024 03:20:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我做的正确吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1has6jq/d_is_what_im_doing_is_correct/</link>
      <description><![CDATA[我正在开展一个 ML 项目。我有 100 个特征和 2000000 行（平衡）我应该遵循哪个顺序？ 我已经完成了，  数据不一致处理 NULL 插补 标准化 独热编码 数据可视化 相关性检查 PCA 训练测试分割 模型训练 评估  对于随机森林，我得到训练数据所有指标的 1，测试集的 0.79。对于逻辑回归，所有指标和测试集的值为 ~0.79，也是同样的结果。对于 GBDT，所有指标和测试集的值为 ~0.79，也是同样的结果。我应该选择哪种模型？上述步骤是否按正确的顺序执行？    提交人    /u/_crazy_muffin_   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1has6jq/d_is_what_im_doing_is_correct/</guid>
      <pubDate>Tue, 10 Dec 2024 03:10:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过乘性权重扰动提高对损坏的鲁棒性 - 一种简单而有效的方法，可以使神经网络对损坏具有鲁棒性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hap6gx/r_improving_robustness_to_corruptions_with/</link>
      <description><![CDATA[我们想分享和讨论这篇 NeurIPS 焦点论文（免责声明：我是合著者）。 论文：https://arxiv.org/abs/2406.16540 GitHub：https://github.com/trungtrinh44/DAMP DAMP（通过乘性扰动进行数据增强）是一种通过乘性权重扰动来提高神经网络鲁棒性的简单而有效的方法。与传统的数据增强方法不同，DAMP 在训练期间直接对模型权重进行操作，从而能够提高损坏鲁棒性，而不会影响干净图像的性能或增加计算成本。  主要亮点：  理论基础：DAMP 证明输入损坏可以等效地表示为乘性权重扰动，为权重空间数据增强提供了理论基础。 简单实现：该方法只需要随机高斯采样和逐点乘法，保持与标准 SGD 几乎相同的训练成本，同时完全兼容数据并行。 ViT 训练方面的突破：仅使用基本的预处理即可从头开始成功训练 Vision Transformers，在 ImageNet 上实现 ResNet50 级别的性能（23.7% 的 top-1 错误率），而无需复杂的增强。 高级集成：与 MixUp 和 RandAugment 结合使用时，DAMP 可显著提高清洁和损坏性能： ViT-S/16：20.09% 的清洁错误率（与基线 20.25% 相比），平均损坏误差 58.30%（与基线 60.07% 相比） ViT-B/16：清洁误差 19.36%（与基线 20.41% 相比），平均损坏误差 56.76%（与基线 58.83% 相比）   为什么选择 DAMP？与依赖复杂数据增强管道或计算成本高昂的集成方法的传统方法不同，DAMP 提供了一种简单、理论扎实的解决方案来提高模型稳健性。它能够从头开始训练 Vision Transformers，无需高级增强，并且与现有技术兼容，这使其成为开发稳健视觉模型的实用选择。 由于 DAMP 与标准训练相比开销最小，因此应用于大型模型和数据集时特别有效。  我们欢迎技术讨论，特别是关于与其他稳健性方法的理论联系以及计算机视觉以外的潜在应用！    提交人    /u/emiurgo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hap6gx/r_improving_robustness_to_corruptions_with/</guid>
      <pubDate>Tue, 10 Dec 2024 00:38:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何管理和跟踪不断演变的大型图像数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1haokqp/d_how_do_you_manage_and_track_your_large_evolving/</link>
      <description><![CDATA[我想知道人们如何管理大型内部数据集的生命周期？比如说 &gt;1TB 和 100k 个文件。 在我的新角色中，我们有多个生产模型，这些模型是从内部数据集训练出来的，大小从几千到几十万张图像不等。我们还有大量新数据进入，每天超过 100 万张图像，因此我们不断挖掘这些数据并发送新的部分进行注释。 到目前为止，团队基本上都是自己管理这个问题，结果是可以预测的。在某些情况下，我们无法将我们的生产模型与任何特定数据关联起来。我们的一些核心数据集仅存在于人们的主目录中，很容易被一个错误的命令抹去。对于一个幸好被淘汰的模型，已知训练代码和原始训练数据都丢失了。 该组织的部分成员采用了 DVC，这似乎很不错，直到文件数量或整体大小变大。一方面，有些人将整个数据集塞进几个档案中并跟踪它们。这最大限度地减少了哈希带来的挫败感，但当只有几个文件更新时会占用大量存储空间。另一方面，有些人跟踪每个文件，这样可以单独更新文件，但签入和签出非常麻烦。其他人则将这两种方法的差异分开，以分层方式跟踪数据集的块作为档案。 那么你的组织是如何管理这一点的？在处理这些庞大且不断发展的数据集时，什么有效，什么无效？    提交人    /u/SirPitchalot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1haokqp/d_how_do_you_manage_and_track_your_large_evolving/</guid>
      <pubDate>Tue, 10 Dec 2024 00:09:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] Meta 的全新 LLama 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1han33i/d_metas_new_llama_model/</link>
      <description><![CDATA[因此，meta 刚刚放弃了一种新的、更高效的 Llama 模型 Llama 3.3 70B，该模型基本上有望降低大型 AI 模型的计算成本。这里有人有机会测试它吗？好奇地想看看它在速度、资源使用率和准确性方面与以前的版本相比表现如何    提交人    /u/Frosty_Programmer672   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1han33i/d_metas_new_llama_model/</guid>
      <pubDate>Mon, 09 Dec 2024 23:01:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人成功训练过具有模型并行性的 LLM 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1habr8l/d_has_anyone_managed_to_train_an_llm_with_model/</link>
      <description><![CDATA[您好， 我正在为我的硕士论文研究微调 Llama-3.1。不幸的是，我目前的情况不允许使用高内存 GPU，例如 A100。相反，我可以使用具有多个低内存 GPU 的设置，例如 4×3090 或 8×V100。 因此，我需要实现模型并行性来训练我的模型，因为它不适合单个 GPU。但是，我注意到大多数框架主要关注数据并行性，这并不能满足我的需求。 有没有人通过将模型拆分到多个 GPU 上来成功训练模型？如果有，您能推荐我应该探索的框架或方法吗？我特别想寻找完整的培训，尽管我有兴趣听听是否有人使用 LoRA 管理过这个。 此外，如果有更适合此类问题的 subreddit，请引导我到那里。 谢谢！    提交人    /u/anilozlu   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1habr8l/d_has_anyone_managed_to_train_an_llm_with_model/</guid>
      <pubDate>Mon, 09 Dec 2024 15:06:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>