<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Sun, 11 Aug 2024 15:15:45 GMT</lastBuildDate>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢所有人在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Aug 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 我应该使用什么数据集来根据同源重组缺陷对乳腺癌进行分类？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eplmdo/discussion_what_dataset_should_i_use_for/</link>
      <description><![CDATA[      https://preview.redd.it/gne7m3lzk1id1.png?width=972&amp;format=png&amp;auto=webp&amp;s=db84e0d9bdbcd2ba756e085c59691bdf5391c937 我决定写一篇关于一个非常相似的主题的论文（使用 ML 处理与癌症和遗传数据相关的内容），我认为这篇论文很适合作为参考。 作者 Mia Josephine Jeffris 基本上选择了一个转录组数据集并使用 SVC 将癌症分为同源重组缺陷型和不同源重组缺陷型。我计划使用不同的模型并将其性能与基线模型（随机森林/决策树/ SVM 等）进行比较，并希望提出一种新模型，该模型可以使用更少的特征进行分类，同时生成 SOTA 指标（AUC 和准确度）。 我的想法是：找到一个转录组数据集，进行一些探索/准备/扩展/训练模型并测试性能。我还打算将其发表在相关期刊上 - 因此数据集应该是（高维）最近的并且有点大。 我是这个话题的新手，有什么指点吗？有关相关想法的最新论文？我将非常感谢您的帮助。    提交人    /u/icy_end_7   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eplmdo/discussion_what_dataset_should_i_use_for/</guid>
      <pubDate>Sun, 11 Aug 2024 14:07:11 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] onnx 模型转换的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epgi4u/discussion_resources_for_onnx_model_conversion/</link>
      <description><![CDATA[过去六个月我一直在从事一个基于音频的项目，主要使用 TensorFlow，因为需要使用 TensorFlow Lite (TFLite) 部署模型。但是，我在基于音频的增强方面遇到了 TensorFlow 的限制，例如音调变换、房间脉冲响应 (RIR) 和 SpecAugment。相比之下，PyTorch 为这些任务提供了一套更丰富的工具，使其更适合我的项目需求。 鉴于此，我正在考虑切换到 PyTorch。但是，我仍然需要将 PyTorch 模型转换为 TensorFlow 模型以进行部署。在研究过程中，我发现 ONNX 是一种流行的转换方法。但是，似乎 PyTorch 模型需要以特定方式构建才能在转换后与 TensorFlow 兼容。 是否有人有关于如何构建 PyTorch 模型以进行 ONNX 转换的指南，或者知道更灵活的转换技术？ TL;DR：我正在使用 TensorFlow 进行 TFLite 部署的音频项目，但由于 PyTorch 具有出色的音频增强工具，因此正在考虑切换到 PyTorch。我需要将 PyTorch 模型转换为 TensorFlow，并正在寻找有关使用 ONNX 进行此或任何其他灵活转换方法的指导。    提交人    /u/JournalistCritical32   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epgi4u/discussion_resources_for_onnx_model_conversion/</guid>
      <pubDate>Sun, 11 Aug 2024 09:07:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从 Scratch 开始的 Vison 语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epga39/p_vison_language_models_from_scratch/</link>
      <description><![CDATA[        提交人    /u/themathstudent   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epga39/p_vison_language_models_from_scratch/</guid>
      <pubDate>Sun, 11 Aug 2024 08:52:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 树注意力：GPU 集群上长上下文注意力的拓扑感知解码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep9qpa/r_tree_attention_topologyaware_decoding_for/</link>
      <description><![CDATA[一篇新的研究论文介绍了一种树注意力算法，用于在多个 GPU 上并行化注意力计算，利用 logsumexp 和 max 运算的关联属性将约简结构化为树。 树注意力算法使跨设备解码能够比 Ring Attention 等替代方法渐近地更快地执行（最高可快 8 倍），同时还需要显著减少通信量并将峰值内存减少 2 倍。    提交人    /u/AhmedMostafa16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep9qpa/r_tree_attention_topologyaware_decoding_for/</guid>
      <pubDate>Sun, 11 Aug 2024 02:17:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从头训练稳定扩散时产生噪声</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep8u6h/d_noisy_generation_when_traininig_stable/</link>
      <description><![CDATA[      您好， 我正在 CIFAR10 上从头开始训练稳定扩散 1.4。我使用的是 CompVis 实现，训练脚本直接取自：https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py 进行必要的修改，从训练和推理中取出 VAE，并将样本大小从 64 改为 32，输入/输出通道从 4 改为 3，并减小模型大小（在上行和下行块中都删除了一个 crossattn 块）。其他所有内容都与原始代码保持一致。我正在进行 fp16 训练。 但是，经过足够数量的步骤（例如 170K 步骤 * 8 批量大小）后，结果仍然非常嘈杂且高度饱和。例如，第一张图片是 SD1.4 的生成，但具有 [256, 512, 1024] 通道和 [down/up2d, crossattn, crossattn]，每块 2 层，仅在飞机类上进行训练。第二张图片是 [64, 128, 256] 和每块 1 层，在 10 个类上进行训练。 由于结果如此糟糕，我相信我所做的事情从根本上是错误的......这是我第一次从头开始训练 SD，所以我对原因没有非常有根据的猜测......如果有人对此有任何想法，将不胜感激 :) 非常感谢！！ https://preview.redd.it/y2wbvta1uxhd1.png?width=257&amp;format=png&amp;auto=webp&amp;s=16e4892b46452499363835029944f01c90b9588b https://preview.redd.it/1u5uigp1uxhd1.png?width=1006&amp;format=png&amp;auto=webp&amp;s=570e7e3f0f9ee23aa61f5183e659862173682793    提交人    /u/ImaginaryAd9209   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep8u6h/d_noisy_generation_when_traininig_stable/</guid>
      <pubDate>Sun, 11 Aug 2024 01:29:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻找梯度下降方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep5od0/p_looking_for_a_gradient_descent_approach/</link>
      <description><![CDATA[我有一个梯度下降方法的想法，它试图直接“跳”到附近最小值的（预测）位置。它的工作原理是围绕一个点近似 2-5 阶泰勒多项式，然后求解最小值（如果可能）并将该点设置为新的 x。然后，可以重复该过程。如果任何一点的泰勒多项式都是凹的，那么我们可以使用更标准的梯度下降方法。 这似乎是一种相当简单的方法，所以我怀疑它是否新颖，但我在网上找不到类似的东西。有谁知道这种方法叫什么或者是否已经研究过它？ 我受到了牛顿求根方法的启发，并且对超参数调整有点不屑一顾。 以下是 desmos 对二次和三次泰勒近似的演示： 二次下降：https://www.desmos.com/calculator/i2nsjaxzhy 三次下降：https://www.desmos.com/calculator/kgkbcfdn7t    提交人    /u/IgorTheMad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep5od0/p_looking_for_a_gradient_descent_approach/</guid>
      <pubDate>Sat, 10 Aug 2024 22:52:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] WildHallucinations：使用真实世界实体查询评估法学硕士 (LLM) 中的长篇事实性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep4tn3/r_wildhallucinations_evaluating_longform/</link>
      <description><![CDATA[一篇新论文旨在创建一个现实的基准 WildHallucinations，用于评估 LLM 事实性。    提交人    /u/AhmedMostafa16   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep4tn3/r_wildhallucinations_evaluating_longform/</guid>
      <pubDate>Sat, 10 Aug 2024 22:12:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LSTM 建模动态系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep3kra/d_modeling_a_dynamic_system_using_lstm/</link>
      <description><![CDATA[      亲爱的大家， 在观看了这段制作精良的视频后，我决定使用相同的概念对我的真实系统进行建模。基本上，我想对我的真实机器人的动态进行建模，以便创建相同的“数字孪生”。换句话说，我想在模拟器中重新创建具有虚拟物理属性的相同机器人，并像真实机器人一样移动它。 我的机器人使用操纵杆驱动，操纵杆在每个轴上输出一个介于 -1.0 和 1.0 之间的浮点数。我收集了数据（真正的机器人帽子传感器已经在工作并实施）。为简单起见，假设我想通过从左向右移动操纵杆轴来驱动以下关节坐标（图 1）。 图 1 我收集了一个小时的数据，然后使用以下数据训练了一个隐藏大小为 32 的 LSTM：  输入是操纵杆输入和关节坐标（机器人的状态）的连接 目标由下一步中机器人的状态表示。我只是复制了状态的列并将其向后移动一个单位。图 2 显示的可能比 1000 个单词更好。  图 2 然后我创建了长度为 200 的序列并训练了我的 LSTM。 训练收敛得非常快，我对结果非常满意。但不知何故，虚拟机器人在虚拟环境中反应奇怪。它以惊人的速度从一个位置跳到另一个位置，然后移动得非常慢。因此，它不会像真正的机器人那样做出反应（真正的机器人在运动过程中更平稳）。 在这种问题中我是否遗漏了重要的东西？ 为了创建真实机器人的良好数字孪生，我还应该考虑什么？ 请注意：  尽管有上述示例，但我将所有运动标准化为范围 [-1, 1] 或 [0, 1] 所有数据均使用以太网电缆收集（因此不会因无线通信等而造成延迟） 我使用了 PyTorch 的 LSTM 类，而不是自定义实现 通过生成具有不同频率的正弦波输入并覆盖关节的所有范围来收集数据。 对于训练，我对数据进行了打乱：随机选择一个起始索引，并剪切一个包含 200 个元素的序列并用于训练。     由   提交  /u/WilhelmRedemption   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep3kra/d_modeling_a_dynamic_system_using_lstm/</guid>
      <pubDate>Sat, 10 Aug 2024 21:15:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 实现人类水平的竞技机器人乒乓球</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eozvwt/r_achieving_human_level_competitive_robot_table/</link>
      <description><![CDATA[  由    /u/RobbinDeBank  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eozvwt/r_achieving_human_level_competitive_robot_table/</guid>
      <pubDate>Sat, 10 Aug 2024 18:27:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你的 neurips 讨论阶段进行得怎么样？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eowx75/d_how_is_your_neurips_discussion_period_going/</link>
      <description><![CDATA[你的 neurips 讨论期进行得怎么样？ 有什么有趣的轶事吗？    提交人    /u/SuchOccasion457   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eowx75/d_how_is_your_neurips_discussion_period_going/</guid>
      <pubDate>Sat, 10 Aug 2024 16:20:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 思维提示程序：将计算与数字推理任务的推理区分开来</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eowis8/r_program_of_thoughts_prompting_disentangling/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eowis8/r_program_of_thoughts_prompting_disentangling/</guid>
      <pubDate>Sat, 10 Aug 2024 16:03:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 的替代品？你有什么经验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eokswq/d_transformer_alternatives_what_are_your/</link>
      <description><![CDATA[我看过一些关于 Transformer 替代方案的文章，但我没有看到人们在自己的数据集中使用它们的经验。是的，论文会告诉你它们很棒，但是从头开始制作它们并训练它们并找到好的超参数等经验......领域中的变化及其对它的影响；这些都是有价值的东西，但我们没有考虑到。 所以我想讨论一下 Transformer 的替代方案？哪一个是你最喜欢的，或者体验如何？    提交人    /u/MysticalDragoneer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eokswq/d_transformer_alternatives_what_are_your/</guid>
      <pubDate>Sat, 10 Aug 2024 04:55:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] Apple Intelligence Foundation 语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eogp0c/r_apple_intelligence_foundation_language_models/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eogp0c/r_apple_intelligence_foundation_language_models/</guid>
      <pubDate>Sat, 10 Aug 2024 01:17:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>