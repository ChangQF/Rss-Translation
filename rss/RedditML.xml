<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Wed, 28 Feb 2024 00:55:50 GMT</lastBuildDate>
    <item>
      <title>[D] 模型创建帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1s1e4/d_model_creation_help/</link>
      <description><![CDATA[嗨，我是这个领域的菜鸟。我目前正在学习机器学习、深度学习等所有知识，我需要一些指导。有人可以告诉我，如果我想创建或训练模型，我是否需要获得一套良好的硬件来满足所需的计算能力？比如 TPU 和 Nvidia 4070 显卡等？或者还有其他办法吗？还有哪个更可取？   由   提交/u/the_engineerguy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1s1e4/d_model_creation_help/</guid>
      <pubDate>Wed, 28 Feb 2024 00:30:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] AMD GPU 上的 Yolov8</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1qkiq/d_yolov8_on_amd_gpu/</link>
      <description><![CDATA[如标题所示。我有一台 rx5700xt，如果我能用它训练我自己的图像模型，那就太好了。由于 yolov8 使用不受支持的 CUDA，因此无法工作。现在我尝试将它与 rocm 一起使用，如下所示： https://github.com/harakas/amd_igpu_yolo_v8 但这似乎并不也很容易解决。现在我在尝试运行稳定扩散时遇到了同样的问题，我最终开始工作。现在我只是问是否有一些简单的方法可以做到这一点，或者有任何已知的方法吗？谢谢   由   提交/u/chainedkids420  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1qkiq/d_yolov8_on_amd_gpu/</guid>
      <pubDate>Tue, 27 Feb 2024 23:25:51 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 在多个数据集上进行训练时，批次内组成的重要性与每个数据点出现的次数的关系</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1ppjd/discussion_importance_of_intrabatch_composition/</link>
      <description><![CDATA[[讨论] 我正在尝试使用不同质量的数据集、受监督的开源数据（范围较窄，但可能是干净的数据）来训练语音识别模型，带有耳语的伪标记数据，以及从 YT（人类上传的字幕）中抓取的弱监督数据。数据集的大小各不相同，我试图通过调整每个批次对应于每个数据集的百分比来解决这一问题。  我没有足够的计算能力来运行大型超参数扫描，并且正在寻找该领域的现有研究或来自其他经验的直觉。    由   提交 /u/ResponsibleHouse7436   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1ppjd/discussion_importance_of_intrabatch_composition/</guid>
      <pubDate>Tue, 27 Feb 2024 22:51:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用超过 10,000 个 GPU 进行 LLM 训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1m0sy/r_llm_training_with_10000_gpus/</link>
      <description><![CDATA[LLM 训练超过 10,000 个 GPU！ https://arxiv.org/abs/2402.15627 想法??   由   提交 /u/CathieVictoriaWood   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1m0sy/r_llm_training_with_10000_gpus/</guid>
      <pubDate>Tue, 27 Feb 2024 20:26:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 捕获 SVR 模型的预测不确定性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1j8yl/d_capturing_forecast_uncertainty_for_a_svr_model/</link>
      <description><![CDATA[有人对量化 SVR 模型的预测不确定性有任何建议吗？ 在参数模型中，例如基本 OLS - 预测区间解释参数和观测的不确定性是相当简单的。与神经网络类似 - 不确定性可以通过添加 dropout 层和对预测分布进行建模来量化 - 但是我不完全确定如何最好地使用 SVR 来做到这一点！ 任何想法都非常受欢迎   由   提交/u/LDM-88  /u/LDM-88 reddit.com/r/MachineLearning/comments/1b1j8yl/d_capturing_forecast_uncertainty_for_a_svr_model/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1j8yl/d_capturing_forecast_uncertainty_for_a_svr_model/</guid>
      <pubDate>Tue, 27 Feb 2024 18:35:20 GMT</pubDate>
    </item>
    <item>
      <title>[D]最近与凸优化相关的文献？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1j1yd/drecent_literature_related_to_convex_optimization/</link>
      <description><![CDATA[大家好，我在凸优化课程中，该课程的一个关键组成部分是一个项目，在该项目中我们将凸优化传递回我们的区域学习，对我来说就是深度学习。显然，如果取得重大进展，这也可以转化为研究想法。  无论如何，我正在寻找有关我可以探索的最近论文/有趣项目的方向/建议。我确实希望我的结果能够呈现出一定程度的新颖性！提前致谢    由   提交 /u/Quiet_Cantaloupe_752   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1j1yd/drecent_literature_related_to_convex_optimization/</guid>
      <pubDate>Tue, 27 Feb 2024 18:27:27 GMT</pubDate>
    </item>
    <item>
      <title>你会用什么技术来解决这个难题（自由流动）？更多信息见评论。 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1it95/with_what_technique_would_you_tackle_this_puzzle/</link>
      <description><![CDATA[      ​  https://preview.redd.it/7nt5nhtd66lc1.png？ width=497&amp;format=png&amp;auto=webp&amp;s=0cbf2001eb6add8107e2d99be76e185c533d9249   由   提交 /u/IntroDucktory_Clause   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1it95/with_what_technique_would_you_tackle_this_puzzle/</guid>
      <pubDate>Tue, 27 Feb 2024 18:17:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从某种意义上说，“在分布之外泛化”的想法不是不可能的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1he3r/d_isnt_the_idea_of_generalizing_outside_of_the/</link>
      <description><![CDATA[嘿，我并不是专门从事机器学习的人，但我是一名开发人员，并且对此有 8 年的业余爱好者研究。 &lt; p&gt;在分布之外进行泛化的想法对我来说一直很不寻常。当然，如果您学习英语，那么您现在在某种意义上就会知道如何编码，因为它是英语的。在这种情况下，该模型的泛化程度远没有我们希望的那么高，因为编码所需的基础知识几乎不是逻辑，而是读写。 在同样的意义上，人们可以想象一种颜色是不同颜色的混合。但想象一种全新的颜色并尝试一下，实际上是不可能的。在这种情况下，我们对分布之外的概括的定义并不在分布之外，只是分布比我们想象的（或可以量化的）大 与想象你从未听过的声音是一样的。再一次，你可以想象你听到过的其他声音的融合，也许你想象的这种新声音确实是你在现实中从未听过的东西，但你还没有推广到频谱的其余部分。我无法想象 20khz 以上的声音听起来是什么样子，因为我完全没有关于它可能是什么的基本事实，就像我无法客观地想象 X 射线是什么样子，因为我受限于我的能力，只能看到可见光。   由   提交 /u/EveningPainting5852   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1he3r/d_isnt_the_idea_of_generalizing_outside_of_the/</guid>
      <pubDate>Tue, 27 Feb 2024 17:21:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 探索GPT-4的国际象棋能力：是否有与GPT-3.5 Turbo相媲美的指令模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1gdod/d_exploring_gpt4s_chess_capabilities_is_there_an/</link>
      <description><![CDATA[我最近看到一篇有趣的文章，介绍 GPT-3.5 Turbo-Instruct 下国际象棋的能力非常好（请参阅此处之前的讨论：https://old.reddit.com/r/GPT3/comments/16mefly/the_new_gpt_model_gpt35turboinstruct_can_play/）。从不是专门为游戏设计的通用人工智能模型中看到如此熟练的国际象棋真是令人着迷。 这一发现让我思考是否存在等效的“指导”模型。 GPT-4 的版本，如果是的话，它在国际象棋能力方面的衡量标准，也许是在 ELO 评级方面。任何有关这方面的见解或信息将不胜感激。谢谢！   由   提交/u/dewijones92   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1gdod/d_exploring_gpt4s_chess_capabilities_is_there_an/</guid>
      <pubDate>Tue, 27 Feb 2024 16:41:42 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] SOTA计算机视觉模型中如何处理尺度等方差？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1ftd5/discussion_how_is_scale_equivariance_handled_in/</link>
      <description><![CDATA[我正在阅读 Aaron Courville、Ian Goodfellow 和 Yoshua Bengio 写的《深度学习》一书，他们提到了共享权重时卷积平移的自然等变性。因此，我想知道当前处理尺度变化的技术。 您认为权重共享和内核调整大小是否足够强大，足以解决这个问题？   由   提交/u/SufficientAd542   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1ftd5/discussion_how_is_scale_equivariance_handled_in/</guid>
      <pubDate>Tue, 27 Feb 2024 16:19:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 会议论文是双盲的。为了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b18is0/d_conference_paper_is_doubleblinded_for_what/</link>
      <description><![CDATA[我对提交给会议的论文必须双盲的要求感到非常困惑，但它们却可以预印有作者姓名和隶属关系，并且可以同时作为同一篇论文共享。人们甚至在接受/发表之前在 Twitter、LinkedIn、Reddit 等 SNS 上宣传他们的论文。感觉就像我在看 Instagram 版的学术界。如何确保广告而不是报纸本身不会影响决策过程？   由   提交 /u/Dry_Cheesecake_8311   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b18is0/d_conference_paper_is_doubleblinded_for_what/</guid>
      <pubDate>Tue, 27 Feb 2024 10:17:05 GMT</pubDate>
    </item>
    <item>
      <title>[N] 在 MWC 的技嘉展位上看到了这些……想象一下你可以用这些做什么！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b17igl/n_saw_these_at_the_gigabyte_booth_at_mwcimagine/</link>
      <description><![CDATA[       由   提交 /u/BubblyMcnutty   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b17igl/n_saw_these_at_the_gigabyte_booth_at_mwcimagine/</guid>
      <pubDate>Tue, 27 Feb 2024 09:05:38 GMT</pubDate>
    </item>
    <item>
      <title>对于新晋研究科学家来说，该行业不会“复苏”[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0n3ib/the_industry_is_not_going_recover_for_newly/</link>
      <description><![CDATA[      今天的热门话题问：“科技行业还没有复苏吗？我有那么糟糕吗？” 让我做出一个大胆的预测（我希望我是错的，但我不认为我是错的）：这个行业不会“ “恢复”对于新晋研究科学家： 您的机器学习论文数量呈指数级增长，反映出博士生和博士后数量呈指数级增长： ​ &lt; p&gt;https://preview.redd.it/viv6l1gnkykc1。 png?width=899&amp;format=png&amp;auto=webp&amp;s=04e227dede42f7d46d1941fc268bb7ea0a409a04 ...毕业并开始竞争大致固定数量的井- 支付行业研究职位。这些职位的数量可能会季节性增加或减少，但长期趋势是他们的就业前景将变得越来越糟糕，而这种指数趋势仍在持续。 ​  div&gt;  由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0n3ib/the_industry_is_not_going_recover_for_newly/</guid>
      <pubDate>Mon, 26 Feb 2024 17:24:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是科技行业还没复苏还是我太差了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0ia76/d_is_the_tech_industry_still_not_recovered_or_i/</link>
      <description><![CDATA[我是欧洲顶尖大学的一名应届博士毕业生，正在研究 ML/CV 中的一些热门主题，已发表 8 - 20 篇论文，其中大部分是我的第一作者。这些论文已累计被引用1000-3000次。 （使用新帐户和广泛的范围来保持匿名） 尽管我认为自己是一个相当有实力的候选人，但我在最近的求职过程中遇到了重大挑战。我主要瞄准研究科学家职位，希望从事开放式研究。我已经联系了欧洲、中东和非洲地区的许多高级机器学习研究人员，虽然有些人表达了兴趣，但不幸的是，由于各种原因（例如人员有限或招聘经理没有更新信息），没有一个机会成为现实。 我主要针对大型科技公司以及一些最近流行的机器学习初创公司。不幸的是，我的大部分申请都被拒绝了，而且常常没有面试的机会。 （我只接受过一家大型科技公司的面试，然后就被拒绝了。） 特别是，尽管有朋友推荐，我还是立即遭到了 Meta 的研究科学家职位拒绝（几天之内）。我现在只是非常困惑和不安，不知道出了什么问题，我是否被这些公司列入了黑名单？但我不记得我树敌过。我希望就下一步可以做什么寻求一些建议......   由   提交/u/Holiday_Safe_5620   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0ia76/d_is_the_tech_industry_still_not_recovered_or_i/</guid>
      <pubDate>Mon, 26 Feb 2024 14:04:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>