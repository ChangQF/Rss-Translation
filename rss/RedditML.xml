<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 24 May 2024 01:01:51 GMT</lastBuildDate>
    <item>
      <title>[P] 学习对 CLIP (&SigLIP) 进行二值化，以实现多模态检索和排序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz5zx1/p_learn_to_binarize_clip_siglip_for_multimodal/</link>
      <description><![CDATA[学习使用 CLIP 进行二值化和排名，以将文本或多模式搜索和推荐的存储空间减少 32 倍。 文章：https://www.marqo.ai/blog/learn-to- binarize-clip-for-multimodal-retrieval-and-ranking  CLIP 排名调整期间的二进制嵌入保留了 87-93% 的 fp32 嵌入。 使用 4 倍缩放温度的 sigmoid 进行伪量化（几乎）普遍优于 tanh（参见下一点）。 0/1 (sigmoid) 上的余弦相似度优于 -1, 1 (tanh) - 很确定这是因为余弦具有更好的简并性（D vs DxN），因为它会惩罚不在同一超球体上的嵌入（它也会偏向于较少的非零元素）。 使用 L1 来训练期间的近似汉明距离，略优于余弦（对于 0/1）。 使用 GS-10M 进行评估 使用精确 KNN 进行多模态检索。 在添加辅助二进制损失时，Fp32 嵌入保留完全保真度。 跨域内、新查询、新文档和零进行评估-镜头设置。 可以与俄罗斯套娃，如果确实有必要，但保真度确实会受到影响（未显示）。    由   提交/u/Jesse_marqo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz5zx1/p_learn_to_binarize_clip_siglip_for_multimodal/</guid>
      <pubDate>Thu, 23 May 2024 22:46:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 ML 中处理 GPL 许可？示例：商业物体检测应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz57uj/d_how_to_handle_gpl_licensing_in_ml_example/</link>
      <description><![CDATA[机器学习人员大家好， 我正在开发一个涉及对象检测模型的商业应用程序。我正在考虑将 YOLOv7 与我自己的训练数据一起使用，但我担心许可问题。 YOLOv7 已获得 GNU GPL 3.0 许可，如果将 YOLOv7 集成到其中，这将要求我将整个应用程序的源代码开源。 我很好奇其他人如何处理这种情况。具体来说：  开发人员是否经常诉诸于使用不同的、较旧的模型，这些模型对商业应用程序有更宽松的许可？ 是否有任何替代方法，例如从使用 YOLOv7 存储库（以便它不是存储库的衍生品）从头开始，并构建我自己的不使用 YOLOv7 代码库进行推理的推理管道？例如使用 ONNX。  我非常感谢任何见解或经验。 谢谢！   由   提交 /u/sushi_roll_svk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz57uj/d_how_to_handle_gpl_licensing_in_ml_example/</guid>
      <pubDate>Thu, 23 May 2024 22:10:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从 HuggingFace 寻找具体文章</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz3szy/d_looking_for_specific_article_from_huggingface/</link>
      <description><![CDATA[大家好，这可能有点盲目，但事实是这样的： 我看到有人来自 HuggingFace要么分享/喜欢关于极端分类问题的方法（使用 HuggingFace）的帖子，例如在几个镜头设置中，数百甚至数千个课程。我当时没有保存它，而且我再也找不到它了。我尝试过 LinkedIn 搜索，但查找帖子的效果很差。谷歌、HuggingFace 网站、Perplexity 都没有用。这对任何人来说都敲响了警钟吗？    由   提交/u/Medical_Initial  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz3szy/d_looking_for_specific_article_from_huggingface/</guid>
      <pubDate>Thu, 23 May 2024 21:10:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 光栅化为图形</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz3o5m/r_raster_to_graphics/</link>
      <description><![CDATA[我想调整 vtracer 的超参数。会产生好的结果吗？如果不是，我可以采用哪些其他技术或者我应该遵循什么方法？    由   提交/u/Worldly-Inflation-92   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz3o5m/r_raster_to_graphics/</guid>
      <pubDate>Thu, 23 May 2024 21:04:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] SSAMBA 简介：自我监督的音频曼巴！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz1yoa/r_introducing_ssamba_the_selfsupervised_audio/</link>
      <description><![CDATA[嘿 Reddit， 厌倦了变形金刚？你真的需要关注吗？认识 SSAMBA（自我监督音频曼巴）！ 🐍✨  这个无需注意、纯粹基于状态空间模型 (SSM) 的自我监督奇迹不只是嘶嘶声，而是咆哮声！在说话人识别、关键字识别和音频分类等任务上，SSAMBA 比基于 Transformer 的同类产品 (SSAST) 实现了更好或相似的性能。但更重要的是：它的 GPU 内存效率更高，推理速度更快，尤其是在音频长度较长的情况下。好奇吗？请在此处查看完整论文：arXiv 上的 SSAMBA  感谢您的收听！    由   提交 /u/attentionisallyounee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz1yoa/r_introducing_ssamba_the_selfsupervised_audio/</guid>
      <pubDate>Thu, 23 May 2024 19:53:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Paperswithcode相关？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz1t4x/d_paperswithcode_relevant/</link>
      <description><![CDATA[对我来说，paperswithcode 与跟踪 ML 进展的相关性降低了。 但这很难说，在我的领域（表格 ML/DL）没有太多既定的学术基准（还不需要像带有代码的论文之类的东西） 在 NLP 和基础模型空间中，hf 空间中的排行榜已成为一种现象（主要是在 NLP 中） ）。 总体而言，paperswithcode 感觉维护较少且不太有用。 您经常使用paperswithcode 吗？你用它来做什么？它在您的什么领域有用？   由   提交/u/_puhsu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz1t4x/d_paperswithcode_relevant/</guid>
      <pubDate>Thu, 23 May 2024 19:46:48 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 如果你可以选择 3 篇关于视频/图像生成模型的论文，你会选择哪一篇？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cyy7v9/dr_if_you_could_pick_3_papers_about_videoimage/</link>
      <description><![CDATA[我正在攻读硕士学位，并且我选择做一个视频生成项目。我读过一些关于图像和视频合成的论文：  VQGAN Stable Diffusion Imagen  我还挑选了 3 篇视频生成论文：  Video-LDM Stable Video Diffusion Fine-tuned for Multi-View Generation (SVD-MV) &lt; li&gt;Text2Video-Zero  我还阅读了一些调查论文，这些是我选择谈论的模型。 我正在努力解决的是为了选择逻辑上有序的论文，所以首先我解释一下 3 个图像生成论文，视频生成论文应该遵循图像合成论文中提到的相同策略。 我可以请你建议不同的一组论文要写什么？我仍然可以将所有论文更改为其他内容。 大多数是最近的内容（2020-2024 年很好）并且具有一些重大影响。我知道例如 VQGAN 是流行的基础模型，论文中使用的技术和策略今天仍然相关。 Imagen（由 Google 提供）但是不是开源的，我更喜欢具有开源代码的论文。这就是我避免 OpenAI 论文的原因。 我还读到，在视频生成中选择扩散而不是 GAN，因为它在质量和训练方面都有更好的结果。然而，扩散的计算成本更高。 例如，Video-LDM 基于稳定扩散，所以对我来说这是值得谈论的好论文。 &lt;!-- SC_ON - -&gt;  由   提交 /u/ShlomiRex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cyy7v9/dr_if_you_could_pick_3_papers_about_videoimage/</guid>
      <pubDate>Thu, 23 May 2024 17:18:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 变分推理：反向 KL 与正向 KL</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cyubdt/r_variational_inference_reverse_kl_vs_forward_kl/</link>
      <description><![CDATA[大家好， 我正在研究变分推理方法，主要是在 BNN 的背景下。使用反向（独占）KL 作为变分目标是常见的方法，尽管最近我偶然发现了一些使用前向（包含）KL 作为目标的有趣作品，例如 [1][2][3]。此外，在 GP 的 VI 背景下，两种散度度量均已使用，请参阅 [4]。 虽然我熟悉反向 KL 目标之间众所周知的差异，但它是“模式-”寻求”而正向 KL 是“模式覆盖”，我看到其中一些作品对这些 VI 目标的下游差异提出了主张，例如（此处解释）“反向 KL 低估了预测方差” [4]和“前向 KL 对于受益于保守不确定性量化的应用很有用” [3]. 我有兴趣在 VI 的背景下理解这些下游差异，但还没有找到任何从理论上而不是从经验上解释这些主张的著作。任何人都可以为我指出正确的方向或尝试解释这一点？ 干杯 [1] Naesseth、Christian、Fredrik Lindsten 和 David Blei。 “马尔可夫分数攀爬：KL (p|| q) 的变分推理。” 神经信息处理系统的进展 33 (2020): 15499-15510。 [2] Zhang, L., Blei, D. M., &amp;奈塞斯，C.A.（2022）。传输分数攀登：使用前向 KL 和自适应神经传输进行变分推理。 arXiv 预印本 arXiv:2202.01841。 [3] McNamara, D., Loper, J., &amp; Regier, J.（2024 年 4 月）。用于摊余变分推理中的包容性 KL 最小化的顺序蒙特卡罗。 人工智能与统计国际会议（第 4312-4320 页）。 PMLR。 [4] Bauer, M.、Van der Wilk, M.、&amp;拉斯穆森，C.E.（2016）。了解概率稀疏高斯过程近似。 神经信息处理系统的进展，29。   由   提交/u/DriftingClient  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cyubdt/r_variational_inference_reverse_kl_vs_forward_kl/</guid>
      <pubDate>Thu, 23 May 2024 14:36:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] Phi-3 模型并排比较。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cytxb5/d_phi3_models_compared_sidebyside/</link>
      <description><![CDATA[      https://preview.redd.it/8l04pnfhq62d1.png?width=661&amp;format=png&amp;auto=webp&amp;s=7fe616ca8cd7da97407 0c86b6b47ffab3ab545e5   https://preview.redd.it/hr7fr1uiq62d1.png?width=688&amp;format=png&amp;auto=webp&amp;s=bd3de359bfe4c1ed82d092be92ae38c246bdfda2    https://preview.redd.it/v6k3v39kq62d1.png？ width=450&amp;format=png&amp;auto=webp&amp;s=c0abb0e397a498ef7ccfb35b1b1cb598198f66ad 对于任何想要在一个地方比较 Phi-3 基准的人。 有趣的比较：ANLI、Hellaswag、MedQA、TriviaQA、语言理解、事实知识和稳健性。 注意：Phi-3 迷你模型表的标签顺序不同。   由   提交/u/dark_surfer  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cytxb5/d_phi3_models_compared_sidebyside/</guid>
      <pubDate>Thu, 23 May 2024 14:19:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在您自己的云（Azure/AWS/GCP）上部署机器学习模型时，您面临的最大挑战是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cyrr8c/d_whats_the_biggest_challenge_you_face_when/</link>
      <description><![CDATA[您好，这是一篇市场研究文章，旨在了解人们在自己的云 (AWS) 上的生产环境中部署开源或自定义 ML 模型时所面临的挑战/Azure/GCP）。 选项：  部署复杂性（K8S、Knative、Ray 等） 根据用户需求自动扩展 缺乏 GPU 可用性（竞价型实例、配额限制） 设置 CI/CD     ;由   提交/u/Capital_Ad1552   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cyrr8c/d_whats_the_biggest_challenge_you_face_when/</guid>
      <pubDate>Thu, 23 May 2024 12:38:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] ML 数据几何</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cyp308/r_geometry_of_data_for_ml/</link>
      <description><![CDATA[        由   提交/u/Late-Yak9284  /u/Late-Yak9284 reddit.com/r/MachineLearning/comments/1cyp308/r_geometry_of_data_for_ml/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cyp308/r_geometry_of_data_for_ml/</guid>
      <pubDate>Thu, 23 May 2024 09:56:21 GMT</pubDate>
    </item>
    <item>
      <title>[P] ReproModel：开源机器学习研究工具箱。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cynq6x/p_repromodel_open_source_ml_research_toolbox/</link>
      <description><![CDATA[嗨，我是计算机科学博士，我刚刚开发出了我认为机器学习研究的巨大飞跃。我开源了该应用程序供大家查看，欢迎所有反馈和贡献。 ReproModel 是一个无代码工具箱，使科学家和研究人员能够有效地测试和重现 ML 模型。很大一部分研究时间都浪费在测试现有论文中的模型上。要复制或测试结果，您必须查看提供的代码，并模仿所有配置文件和实验条件，即数据加载器、预处理、优化器等。 工具箱将所有这些都拿走了通过从现有论文中获取配置文件（即将推出），直接加载模型，并通过简单的复选框和下拉菜单在数据上测试它们。当然，定制是可能的并且受到鼓励。 您可以在此处找到存储库。当然，还需要做更多的工作，但我正在逐步实现这一点，以确保代码未来的兼容性和可重用性。 https://github.com/ReproModel/repromodel 感谢您的时间、评论和支持！   由   提交 /u/MintOwlTech   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cynq6x/p_repromodel_open_source_ml_research_toolbox/</guid>
      <pubDate>Thu, 23 May 2024 08:18:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] Geoff Hinton 目前对反向传播作为大脑学习机制的看法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cyhk1f/d_what_are_geoff_hintons_current_thoughts_on/</link>
      <description><![CDATA[我大约 4 年前观看了他的一次演讲，他在演讲中驳斥了所有反对反向传播作为大脑学习机制的观点。但我记得最近在一个播客上听到过他（现在找不到了），其中他对反向传播持怀疑态度，并且似乎暗示赫布学习更为重要。我很想知道他目前的信念以及原因。他最近一次讨论这个问题的采访或讲座是什么？ /u/geoffhinton 编辑：这是我提到的讲座，名为“大脑会进行反向传播吗？”   由   提交/u/guesswho135   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cyhk1f/d_what_are_geoff_hintons_current_thoughts_on/</guid>
      <pubDate>Thu, 23 May 2024 01:58:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI 代理：太早、太昂贵、太不可靠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cy1kn9/d_ai_agents_too_early_too_expensive_too_unreliable/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cy1kn9/d_ai_agents_too_early_too_expensive_too_unreliable/</guid>
      <pubDate>Wed, 22 May 2024 14:27:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>