<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 02 Jan 2025 12:32:12 GMT</lastBuildDate>
    <item>
      <title>搜索和学习的扩展：从强化学习角度重现 o1 的路线图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrq7ak/scaling_of_search_and_learning_a_roadmap_to/</link>
      <description><![CDATA[  由    /u/cavedave  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrq7ak/scaling_of_search_and_learning_a_roadmap_to/</guid>
      <pubDate>Thu, 02 Jan 2025 09:41:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 带因式分解机的数值特征</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrpuix/r_numerical_features_with_factorization_machines/</link>
      <description><![CDATA[很高兴分享我们最近的 TMLR 论文，由 Alex Shtoff、Elie Abboud、Rotem Stram 和 Oren Somekh 撰写的“因式分解机中的数值特征的函数基编码”。  本文提出了一个有趣的见解，探讨了在推荐系统的背景下，因式分解机 (FM) 与使用基函数的特征编码之间的相互作用。  与线性模型的相同相互作用是一种古老的经典，我们大多数人都在我们的 ML 101 课程中学到了。多项式回归就是其中之一 - 我们使用标准多项式基 {1, 𝑥, 𝑥², ...} 对特征 𝑥 进行编码。  FM 是一类模型，它对二次多项式进行建模 f(𝒙)=𝑢+⟨𝒘,𝒙⟩ + ⟨𝒙,𝑽𝒙⟩ 其中 diag(𝑽)=𝟎，其中系数矩阵 𝑽 使用特征嵌入向量以某种低秩分解形式表示。例如，Rendle 在 2010 年提出的经典 FM 是 f(𝒙)=𝑢+⟨𝒘,𝒙⟩ + ∑_{i≠k}⟨𝒗ᵢ,𝒗ₖ⟩𝑥ᵢ𝑥ₖ 其中 {𝒗₁, ..., 𝒗ₙ} 是特征嵌入向量。 这样的建模允许捕获成对的特征交互，使其比简单的线性模型强大得多，同时在训练和推理方面也保持快速。这就是为什么它们在推荐系统中很有用，推荐系统需要在几毫秒内对大型目录进行排名，每天数十亿次。 有一个警告 - FM 在 𝒙 的任何一个组件中都是线性的。这就是为什么在将数值特征输入到 FM 之前，通常会对其进行量化或分箱的原因。在这项工作中，我们建议通过使用给定的基础来混合一组系数向量，在与某些数值特征 𝑥ᵢ 相对应的嵌入空间中学习参数曲线 𝒗ᵢ(𝑥ᵢ)。 从理论角度来看，这概括了分箱，因为区间指示函数的基础正是分箱。此外，作为任何一个特征的函数，模型都变成由给定基础跨越的非线性函数，并且作为任何两个特征的函数，它变成由基础张量积跨越的非线性函数。 从实际的推荐系统角度来看，B 样条基础是一个很好的候选者，因为它结合了由于稀疏性而导致的快速计算和强近似特性。例如，考虑四个特征：电影类型、用户国家/地区、自上次访问以来的时间以及自首次登录以来的时间。对于给定的类型、国家和自上次访问以来的时间，我们的模型是自首次登录以来的时间的样条函数。对于给定的类型和国家，我们的模型变为自上次访问以来的时间和自上次登录以来的时间的张量积样条。对于另一个类型和国家，它是不同的张量积样条。这正是我们所需要的推荐系统的个性化方面。使用分解机的这个简单技巧有助于在推理和训练时保持极快的速度，同时显着提高性能。  我们通过一组数值实验和对在线广告产品的实际流量的 A/B 测试证实了我们的说法。  David Rügamer 在他的 AISTATS 2024 论文“可扩展的高阶张量积样条模型”中同时开发了类似的模型，但遵循了不同的路径 - 扩展到更高阶的分解，而不是更广泛的分解机系列。一篇很棒的论文 - 我也推荐大家阅读它！    提交人    /u/alexsht1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrpuix/r_numerical_features_with_factorization_machines/</guid>
      <pubDate>Thu, 02 Jan 2025 09:15:03 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 帮助研究霍普菲尔德神经网络和混沌吸引子</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrkktt/research_help_with_hopfield_neural_network_and/</link>
      <description><![CDATA[我是一名 4 年级的 B.Tech 学生，我想就上述主题做一个项目。你们觉得继续做这个项目是个好主意吗，还是我应该改变它？    提交人    /u/sangeet-parashar   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrkktt/research_help_with_hopfield_neural_network_and/</guid>
      <pubDate>Thu, 02 Jan 2025 03:31:49 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何在 AI / ML 领域建立有意义的联系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrgz5k/dhow_can_i_build_meaningful_connections_in_the/</link>
      <description><![CDATA[大家好， 我是一名计算机科学专业二年级学生，对 AI/ML 充满热情。我积极开展项目，参加黑客马拉松，最近开始探索研究论文以加深我的理解。随着我在这个领域的成长，我逐渐意识到与做出重大贡献的人建立联系的重要性——博士生、研究人员和行业专业人士。 我的目标不仅是在 LinkedIn 等平台上建立联系，而且要建立促进学习、协作和共同成长的真诚关系。 我很乐意听取您的建议： 寻找和接触志同道合的人的最佳平台、社区或活动。 如何以尊重和有意义的方式接近专业人士和研究人员。 随着时间的推移，维持和培养这些联系的有效方法。 如果您自己走过这条路或指导过他人，我将非常感激您能分享的任何提示、个人经历或资源。 如果您愿意分享见解或开始对话，我也很乐意与您联系。感谢您的时间和指导！    提交人    /u/PixelPioneer-1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrgz5k/dhow_can_i_build_meaningful_connections_in_the/</guid>
      <pubDate>Thu, 02 Jan 2025 00:30:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python [P] 对数千个自定义文档进行自然语言查询的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrfexb/whats_the_best_way_to_natural_language_query/</link>
      <description><![CDATA[我使用项目管理软件，每个项目可能存储了 1,000 份文档和记录，而且每天都会添加新文档和记录。我希望能够使用自然语言查询这些信息，并试图找出解决此问题的方法。 我做了一些初步研究，发现了几种方法： (1) 使用这些自定义文档和记录的详细信息创建一个微调的 LLM 模型 (2) 包括文档和记录的相关详细信息记录并提示现有的 LLM 模型（我猜这涉及将嵌入存储在向量数据库中并构建搜索算法以确定需要将哪些文档子集包含在提示中。 (3) 找到一个可以做到这一点的现有工具（可能是 Elastic Search？） 用例可能是：“提供承包商不遵守合同条款的例子”。 “突出显示进度报告中未明确指出的三大关注点”。 （即解决方案需要对项目管理的上下文理解超出自定义文档中包含的内容）    提交人    /u/cbooty   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrfexb/whats_the_best_way_to_natural_language_query/</guid>
      <pubDate>Wed, 01 Jan 2025 23:16:06 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 有人在 ABIDE 数据集上取得成功吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrey6k/discussion_has_anyone_gotten_success_on_the_abide/</link>
      <description><![CDATA[只是想知道那里是否有信号。我正在尝试在单个切片上迁移学习 ResNet-50，但无法将验证准确率提高到 55% 左右。我想知道这里是否有人成功使用它，特别是在 ABIDE-I 数据集上的二元分类。如果这里有人成功了，他们介意给我发消息，也许可以帮助我？ 附言：如果这是错误的 subreddit，我完全理解，我会在其他地方发布。    提交人    /u/godlover123451   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrey6k/discussion_has_anyone_gotten_success_on_the_abide/</guid>
      <pubDate>Wed, 01 Jan 2025 22:54:53 GMT</pubDate>
    </item>
    <item>
      <title>[R]AST+速记+HybridRag</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrej5v/rastshorthandhybridrag/</link>
      <description><![CDATA[        提交人    /u/stonedoubt   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrej5v/rastshorthandhybridrag/</guid>
      <pubDate>Wed, 01 Jan 2025 22:35:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] AI 学习平衡球（使用 PPO 进行深度强化学习）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hraczd/p_ai_learns_to_balance_a_ball_deep_reinforcement/</link>
      <description><![CDATA[大家好！👋 我一直在研究一个 AI 球体，它使用强化学习来学习平衡球体，由虚幻引擎的自定义插件提供支持。这个插件是 Unity ML-Agents 的一个端口，非常了不起。虽然我知道虚幻引擎有自己的系统，但我想将 ML-Agents 体验带到虚幻引擎中，让它在这里同样精彩！我是一名开发人员，也是一名 3D 爱好者！ 视频使用二次奖励系统演示了球体——如果将球保持在中心附近，它会获得更多积分，如果球掉落，则会失去积分。结果强调了强化学习如何解决复杂的控制任务。 如果您感兴趣，这里是 Youtube 链接！ https://youtu.be/6lhCa72TGNk?si=qcIKof09R1Yl0SJw    提交人    /u/Cyber​​Eng   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hraczd/p_ai_learns_to_balance_a_ball_deep_reinforcement/</guid>
      <pubDate>Wed, 01 Jan 2025 19:29:03 GMT</pubDate>
    </item>
    <item>
      <title>解决 RandomForestClassifier 模型数据集轻微不平衡的建议 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hr1nv6/suggestions_to_address_slight_imbalance_in/</link>
      <description><![CDATA[你好。 请分享学习资源和 YouTube 频道，提供有关解决数据集不平衡的教程。 我的数据集略有不平衡（20 个 0 类 vs. 125 个 1 类） RandomForestClassifier 模型评估如下： 测试准确率：0.9862068965517241。 分类报告： 精度召回率 f1 分数支持率 0 0.91 1.00 0.95 20 1 1.00 0.98 0.99 125 准确率 0.99 145 宏平均值 0.95 0.99 0.97 145 加权平均值 0.99 0.99 0.99 145    提交人    /u/Beautiful_Okra_1783   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hr1nv6/suggestions_to_address_slight_imbalance_in/</guid>
      <pubDate>Wed, 01 Jan 2025 12:02:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 请有人向我解释一下多头潜在注意力如何用于自回归建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqyfoq/d_someone_please_explain_me_how_multihead_latent/</link>
      <description><![CDATA[由于整个序列的键和值被压缩成一个潜在向量，潜在向量具有来自整个序列的信息。因此模型可以提前窥视，从而打破自回归设置。那么如何使用它进行自回归建模？    提交人    /u/TwoSunnySideUp   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqyfoq/d_someone_please_explain_me_how_multihead_latent/</guid>
      <pubDate>Wed, 01 Jan 2025 07:51:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] 为什么我的 LSTM 总是预测“Ġ”字符/U-0120？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqs7k9/p_why_does_my_lstm_always_predict_the_ġ_char_u0120/</link>
      <description><![CDATA[Ġ 表示带有 BPE 标记的空格，所以我认为这只是因为它们太多了。我应该删除所有空格并以此训练我的模型吗？    提交人    /u/SnazzySnail9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqs7k9/p_why_does_my_lstm_always_predict_the_ġ_char_u0120/</guid>
      <pubDate>Wed, 01 Jan 2025 00:54:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在进行出版基准测试时排除不可重复的最先进的方法是否可以接受？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hqm6vd/r_is_it_acceptable_to_exclude_nonreproducible/</link>
      <description><![CDATA[我开发了一种新算法，并准备为研究出版物评估其性能。但是，我遇到了一个挑战：一些最新的方法缺乏公开可用的代码，因此很难或无法重现。 在发布研究工作的背景下，是否可以将这些方法排除在我的比较之外，而是专注于对具有公开可用实现的方法和基线进行基准测试？ 研究界对这个问题的普遍共识是什么？在发布结果时，是否有推荐的最佳实践来解决缺乏可重现代码的问题？    提交人    /u/Training_Bet_7905   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hqm6vd/r_is_it_acceptable_to_exclude_nonreproducible/</guid>
      <pubDate>Tue, 31 Dec 2024 19:33:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用整流流和 FLUX 架构的新型 SOTA 文本转音频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq9hx1/d_new_sota_text_to_audio_model_using_rectified/</link>
      <description><![CDATA[发布采用整流流匹配和偏好优化训练的全新 TTA 模型！完全开源。在 GPU 上推理大约需要 3 秒。    提交人    /u/Internal_War3919   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq9hx1/d_new_sota_text_to_audio_model_using_rectified/</guid>
      <pubDate>Tue, 31 Dec 2024 07:17:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</guid>
      <pubDate>Sun, 29 Dec 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>