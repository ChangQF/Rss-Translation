<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 05 Jan 2024 18:16:34 GMT</lastBuildDate>
    <item>
      <title>[D] MC-JEPA 神经模型：释放运动识别和生成式人工智能在视频和图像上的力量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zbxt7/d_mcjepa_neural_model_unlock_the_power_of_motion/</link>
      <description><![CDATA[我们进行了讨论论文“MC-JEPA：用于运动和内容特征自监督学习的联合嵌入预测架构” https://arxiv.org/pdf/2307.12698.pdf   由   提交 /u/sasaram   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zbxt7/d_mcjepa_neural_model_unlock_the_power_of_motion/</guid>
      <pubDate>Fri, 05 Jan 2024 17:11:53 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]LLM中的幻觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zaymi/discussion_hallucinations_in_llm/</link>
      <description><![CDATA[我已经进行了几个月的研究，学习和评估 LLM 表现的不同指标。在所有这些研究中，我还没有找到一个有效且可用的指标，不仅可以衡量法学硕士是否产生幻觉，还可以衡量如何向用户显示法学硕士输出中模型产生幻觉的位置。此外，我发现很少有指标或评估仅依赖于所提供的上下文及其摘要，而没有其他人类注释支持其评估。 在这种情况下，我将幻觉量化为一个事实或一串事实（即 Marshall 参观了商店，Marshall 买了面巾纸，Marshall 回家），在原始源文本中没有证据表明“Marshall”是“Marshall”。在这种情况下，购买了纸巾或除“杂货”之外的任何特定物品。因此，该模型解释了杂货的含义并替换了面巾纸。 同样重要的是要声明我在这种情况下仅指汇总特定模型的输出。我很想了解这个社区对这个主题的了解，以及任何代码或系统方法来检测输出文本中的这种变化，并确定其本质是被模型产生幻觉并且不忠实于给定的上下文。 &lt; /div&gt;  由   提交 /u/Imaginary-Catch1788    reddit.com/r/MachineLearning/comments/18zaymi/discussion_hallucinations_in_llm/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zaymi/discussion_hallucinations_in_llm/</guid>
      <pubDate>Fri, 05 Jan 2024 16:31:20 GMT</pubDate>
    </item>
    <item>
      <title>无法找到 ICML 论文的评论：主动公平审计 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18z994w/unable_to_find_reviews_of_icml_paper_active/</link>
      <description><![CDATA[我一段时间以来一直在寻找这篇论文的评论：主动公平审计。不过奇怪的是哪里都买不到？这是正常的吗？谢谢，   由   提交/u/Any-Ad-3888  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18z994w/unable_to_find_reviews_of_icml_paper_active/</guid>
      <pubDate>Fri, 05 Jan 2024 15:18:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 深度强化学习泛化分析调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18z90nq/r_a_survey_analyzing_generalization_in_deep/</link>
      <description><![CDATA[https://arxiv.org/pdf/2401.02349 .pdf   由   提交 /u/ml_dnn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18z90nq/r_a_survey_analyzing_generalization_in_deep/</guid>
      <pubDate>Fri, 05 Jan 2024 15:07:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] ArXiv 替代方案（或者是否有可能实现更多“暂停”透明度）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18z3jdr/d_arxiv_alternatives_or_is_there_possible_for/</link>
      <description><![CDATA[我当前的文章已“暂停”差不多一周了（尝试联系模组，得到了一般性的回复）。我在 arXiv 上发表了 5 篇文章，没有任何问题（同一类别中 3 篇）。 还有关于文章被搁置一个月以上的可怕故事 (https://academia.stackexchange.com/questions/189542/arxiv-preprint-on-hold，https://twitter.com/YuanqiD/status/1678949802367676417，https:// twitter.com/moyix/status/1604218507708846082，https://twitter.com/PierLucaLanzi/status/1629569377690439680，https://twitter.com/GriffinAdams92/status/1605310825958637568）。  我知道模组是免费做他们的工作的，如果这个过程在某种程度上是透明的，我可以等待合理的时间。但现在，有些文章一天之内就被接受，有些则需要等待数周/数月。是否有可能让 arXiv“暂停”？状态更透明？例如。通过显示当前队列大小或“保留”的某种原因（错误的类别，像 Covid 这样的敏感话题，...）？  此外，对于 ML 工作，是否有一些 arXiv 的不错替代品？那些具有良好声誉（没有 vixra）、可预测的等待时间并且至少还被 Google Scholar 索引的？   由   提交 /u/osamc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18z3jdr/d_arxiv_alternatives_or_is_there_possible_for/</guid>
      <pubDate>Fri, 05 Jan 2024 10:09:47 GMT</pubDate>
    </item>
    <item>
      <title>带注释的S4.[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18z2gt9/the_annotated_s4d/</link>
      <description><![CDATA[https://srush.github.io/注释-s4/   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18z2gt9/the_annotated_s4d/</guid>
      <pubDate>Fri, 05 Jan 2024 08:58:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 学术界到工业界</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18z2f4r/d_academia_to_industry/</link>
      <description><![CDATA[我是一名最近（一年）的博士毕业生，专注于机器学习和统计模型应用以了解海洋气候变化。由于我一直在学术界工作，我意识到这可能不适合我。 我真的很喜欢解决问题和进行前沿分析，但是学术界不断的资助周期和非研究要求是关闭。  我曾有过研究数据科学或机器学习应用领域的行业工作的想法，但我完全迷失了。当我开始向行业转型时，有人有任何建议或建议吗？   由   提交/u/dcoceans11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18z2f4r/d_academia_to_industry/</guid>
      <pubDate>Fri, 05 Jan 2024 08:54:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 A100 与 4x4090 训练 LLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18z0jja/d_training_llm_with_a100_vs_4x4090/</link>
      <description><![CDATA[我必须在 A100 (80Gb) 和 4x4096 (92GB) 之间做出选择。我正在寻找训练 7B 模型。看起来 7B 模型将需要 55 GB（使用 Adam 作为优化器）。那么，如果我有 4x4096 GPU，是否足够了？如果我使用 DPO 或 rhf 进行训练，这将有两个模型，这会使 GPU 变为 3 倍吗？ 我应该使用哪一个，A100 还是 4x4096？ ~   由   提交 /u/Electronic_Hawk524   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18z0jja/d_training_llm_with_a100_vs_4x4090/</guid>
      <pubDate>Fri, 05 Jan 2024 06:51:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 建立一个小型 HPC 来协调小型团队的人工智能研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18yxwlh/d_setting_up_a_small_hpc_for_orchestrating_a/</link>
      <description><![CDATA[我想了解社区关于设置用于 AI/CV/ 的 HPC（具有计算负载的单机）的意见和经验在一个小团队中进行法学硕士研究。本质上，设置 HPC 以便多个用户可以在慢速存储上存储数据集，自动将数据集神奇地传输到快速存储以进行训练并在完成后删除，选择 1-&gt;N GPU（允许多个用户同时训练）或一项重大工作）并防止系统被用户数据集/环境的秘密存储所堵塞，并且理想情况下工程开销/维护较低。 实现这一目标的方法是什么？优点和缺点？ 例如，Kubernetes 可以与 docker 一起使用来调度资源、构建环境、训练模型，然后从快速存储中优雅地删除数据集、关闭容器并将其从内存中删除。对我来说，这似乎是一种不错的方法，因为我知道我可以用它进行调度和编排，但 HPC 永远不会在集群中使用，所以可能这是一种矫枉过正。   由   提交 /u/Dr-LucienSanchez   /u/Dr-LucienSanchez reddit.com/r/MachineLearning/comments/18yxwlh/d_setting_up_a_small_hpc_for_orchestrating_a/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18yxwlh/d_setting_up_a_small_hpc_for_orchestrating_a/</guid>
      <pubDate>Fri, 05 Jan 2024 04:26:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] SOLAR 10.7B：通过简单而有效的深度扩展来扩展大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18yx0rf/r_solar_107b_scaling_large_language_models_with/</link>
      <description><![CDATA[ 由   提交/u/RobbinDeBank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18yx0rf/r_solar_107b_scaling_large_language_models_with/</guid>
      <pubDate>Fri, 05 Jan 2024 03:40:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么高端 Apple Silicon CPU 几乎不比具有 Core ML 推理的低端 CPU 好？ [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18yne1q/why_are_highend_apple_silicon_cpus_hardly_better/</link>
      <description><![CDATA[根据 Geekbench，所有 Apple Silicon CPU 的 Core ML 推理基准测试：Basic、Pro、Max、Ultra 都惊人地相似。 点击链接并在右侧菜单中选择 Geekbench ML 推理  https://browser.geekbench.com/search?utf8=%E2%9C%93&amp;q=Apple+M2 Geekbench Core ML 基准测试的目测分数： Core ML CPU 1500 - 2500 Core ML GPU 3000-8500 Core ML Neural Engine 6000-10000 自然，配备基本 M CPU 的 Macbook Air 处于较低端， Ultra CPU 处于高端，但在现实生活中差异可以忽略不计。我想，相当相似的性能可以部分解释为推理算法仅使用一个核心。然而，结果仍然令人惊讶，因为这些 CPU 的内存带宽要好几倍。 Macbook Air 的简单 M2 带宽为 100 GB/s，M2 Ultra 带宽为 800 GB/s。 如何解释这种相当相似的性能？   由   提交/u/Geejay-101  /u/Geejay-101 reddit.com/r/MachineLearning/comments/18yne1q/why_are_highend_apple_silicon_cpus_hardly_better/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18yne1q/why_are_highend_apple_silicon_cpus_hardly_better/</guid>
      <pubDate>Thu, 04 Jan 2024 20:43:28 GMT</pubDate>
    </item>
    <item>
      <title>2023 年最好的深度学习论文是什么？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ykwdx/what_are_the_best_deep_learning_papers_of_2023d/</link>
      <description><![CDATA[2023 年最好的深度学习论文是什么？   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ykwdx/what_are_the_best_deep_learning_papers_of_2023d/</guid>
      <pubDate>Thu, 04 Jan 2024 19:01:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] RL+LLM有哪些最新突破？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18yj99j/d_what_are_the_latest_breakthroughs_in_rl_llms/</link>
      <description><![CDATA[RLHF 与 ChatGPT 的成功给我留下了深刻的印象，但除了这种风格调整之外，我还没有看到任何其他突破。我非常想探索这个领域还有哪些其他令人兴奋的突破或任何未开发的潜力。   由   提交 /u/SpecialBuy3271   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18yj99j/d_what_are_the_latest_breakthroughs_in_rl_llms/</guid>
      <pubDate>Thu, 04 Jan 2024 17:55:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 放弃 ML 博士 - 建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18yh4ph/d_dropping_out_ml_phd_advice/</link>
      <description><![CDATA[我即将开始博士学位的第三年。我有 3 篇第一作者论文，还有 2 篇正在审稿中，今年夏天我已经准备好进行扎实的研究实习。但是……老实说，我根本不喜欢研究，从来没有，也不太关心。在过去的三年里，我勉强做到了这一点，老实说，我非常非常幸运。我绝不是一个研究天才，甚至不喜欢研究。我只是在乘风破浪，打发时间。但这种完全无意义和绝望的感觉，我无法克服。我只是感觉不适合作为一名研究员。这不是冒名顶替综合症。研究不是我的事。  老实说，我读博士课程只是为了满足我的家人。来自一个拥有研究生学位的亚洲家庭，这是一种期望。  20年前的博士学位看起来很有趣。我想象博士课程就是我和同事一起在白板上讨论，提出想法并尝试疯狂的事情，总是参加研讨会和课程。相反，我看到的是士气低落、过度劳累的学生、空荡荡的教室和研讨会（!!!），以及普遍的绝望感和不想去那里的感觉。这对我来说太震惊了。 现在退学是不是很愚蠢？我觉得我的20多岁已经在无聊、完全没有动力和沮丧中消逝了。我的导师是一个很棒的人，但几乎没有时间见面。我只是不知道我是否还能忍受这个。我想尝试一些疯狂的事情：去一家初创公司并取得成功或为此而奋斗，获得 MBA 或统计学硕士学位，搬到一个新城市，成为一名人工智能政策分析师。感觉有很多路我更适合。  编辑：哇。感谢大家的回复和源源不断的动力。老实说，我没想到会收到这么多评论。我很快就会和我的导师交谈，并安排一次长时间的一对一会议，看看我们能做些什么让我带着博士学位离开这里:)  &amp; #32；由   提交 /u/TheMysticalJam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18yh4ph/d_dropping_out_ml_phd_advice/</guid>
      <pubDate>Thu, 04 Jan 2024 16:27:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>