<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Thu, 04 Apr 2024 09:13:47 GMT</lastBuildDate>
    <item>
      <title>[D] 法学硕士正在损害人工智能研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</link>
      <description><![CDATA[这是一个大胆的主张，但我觉得 LLM 的炒作早就该消退了。 GPT4 之后，LLM 性能和设计改进不仅取得了相对较小的进展：使其变得更好的主要方法仍然只是使其更大，并且所有 Transformer 的替代架构都被证明是低于标准和劣质的，它们引起了人们的关注（并且投资）远离其他可能更具影响力的技术。与此同时，大量涌入的人甚至不知道基本的机器学习是如何工作的，他们自称是“人工智能研究员”。因为他们使用 GPT 让每个人在本地托管一个模型，试图让你相信“语言模型完全可以推理”。我们只需要另一个 RAG 解决方案！”他们加入这个社区的唯一目标不是开发新技术，而是利用现有技术拼命拼凑出一项有利可图的服务。甚至论文本身也开始主要由法学硕士撰写。我不禁认为整个领域可能会陷入停滞状态，因为不断增长的社区满足于平庸的修复，这些修复充其量只能使模型在任意“分数”上的得分稍微好一些。他们弥补了这一点，忽略了诸如幻觉、上下文长度、基本逻辑缺乏能力以及运行这种规模模型的高昂成本等明显问题。我赞扬那些不顾市场炒作而致力于开发能够实现真正逻辑过程的代理的人们，并希望很快会引起更多关注。   由   提交/u/NightestOfTheOwls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</guid>
      <pubDate>Thu, 04 Apr 2024 08:36:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在做了多年的“笔记本数据科学家”之后，终于开始部署分布式机器学习系统。我现在还能赚多少钱？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvhv5q/d_finally_getting_to_work_on_deploying_a/</link>
      <description><![CDATA[我很高兴。花了很多时间在笔记本上进行一次性分析。感觉就像一个冒名顶替者。 这确实影响了我能赚多少钱，因为我没有生产级机器学习经验。我在很多次面试中都被拒绝了，因为我的工作经验中没有很酷的机器学习项目。在多个大型科技公司的 ML 面试中也被拒绝。我和 4 岁的孩子在亚特兰大赚了大约 10 万美元。现在，我正在增加在分布式环境中使用机器学习系统的经验，我想知道我将来能赚多少钱。有任何想法吗？    由   提交/u/throtitfaarawayy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvhv5q/d_finally_getting_to_work_on_deploying_a/</guid>
      <pubDate>Thu, 04 Apr 2024 08:18:29 GMT</pubDate>
    </item>
    <item>
      <title>一个应用程序开发者。我们可以在哪里将人工智能融入到我们的项目中？[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvhuoc/an_app_dev_where_we_can_incorporate_ai_in_our/</link>
      <description><![CDATA[大家好！ 我们是一个由三名软件工程师组成的团队，正在构建一个社交媒体应用程序，用户可以通过分享自己的内容获得奖励对新闻的看法。我们的重点是软件，这就是为什么我们希望与机器学习专家联系，他可以就如何以及在何处将人工智能集成到我们的应用程序中向我们提供建议（增强用户参与度并为我们的用户带来更多价值。） 无论是利用现有的 API 还是想出创造性和有趣的方法来提高参与度，我们都愿意接受建议！ 请在此处发表评论，或者随时给我发私信！ &lt; p&gt;干杯！   由   提交/u/AdNo6324  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvhuoc/an_app_dev_where_we_can_incorporate_ai_in_our/</guid>
      <pubDate>Thu, 04 Apr 2024 08:17:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] JAX 和 Pytorch 专家混合实现（不是稀疏 MoE，而是“旧”类型）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvhlhd/d_jax_and_pytorch_implementations_of_mixture_of/</link>
      <description><![CDATA[大家好， 由于稀疏门控 MoE 层的爆炸式增长并利用“条件计算”来加速推理/近年来在法学硕士学习中，我很难根据这样的论文找到老式专家混合架构的代码实现： &quot;在专家的深度混合中学习因子表示” (Eigen, Ranzato, Sutskever 2013) ​ 通常当你搜索“Mixture of Experts Layer github”时所有热门都是最新的稀疏门控 MoE 内容——这很棒，但不是我想要的。 通过阅读 Eigen 等人上面的论文，我确信会实现它不会太难，但我想问是否有人知道这种类型的 MoE 的开源、现成的 JAX 或 Pytorch 实现？简而言之：您有一批来自输入的线性层 --&gt;输出，然后是来自输入的门控网络 --&gt;每个线性层输出的加权系数。然后使用这些权重作为混合系数对输出进行平均。因此需要明确的是：我并不是在寻找稀疏的 MoE 层实现（通常利用自定义“调度程序”的奇特东西，因此您一次只能激活模型的一部分），而只是一个标准的“密集”层实现。按照我刚才描述的方式混合专家层。 任何帮助将不胜感激！提前致谢。   由   提交/u/mccl30d  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvhlhd/d_jax_and_pytorch_implementations_of_mixture_of/</guid>
      <pubDate>Thu, 04 Apr 2024 08:00:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视觉自回归建模：通过下一代预测生成可扩展图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvh8ep/d_visual_autoregressive_modeling_scalable_image/</link>
      <description><![CDATA[      ​ https://preview.redd.it/12c372dv0fsc1.png?width=2833&amp;format=png&amp; ; auto=webp&amp;s=0d88f98929854f3de18b8c623d3aff5a7ed14b79 摘要：  我们提出了视觉自回归建模（VAR），一种新一代范式它将图像的自回归学习重新定义为从粗到细的“下一尺度预测”或“下一分辨率预测”，与标准光栅扫描“下一标记预测”不同。这种简单、直观的方法使自回归 (AR) 转换器能够快速学习视觉分布并很好地概括：VAR 首次使 AR 模型在图像生成方面超越了扩散转换器。在 ImageNet 256x256 基准上，VAR 通过将 Frechet 起始距离 (FID) 从 18.65 提高到 1.80、起始分数 (IS) 从 80.4 提高到 356.4，显着改善了 AR 基线，推理速度提高了约 20 倍。实证还验证了 VAR 在图像质量、推理速度、数据效率和可扩展性等多个维度上均优于 Diffusion Transformer (DiT)。扩大 VAR 模型表现出与法学硕士中观察到的清晰的幂律缩放定律，线性相关系数接近 -0.998，这是确凿的证据。 VAR 进一步展示了下游任务中的零样本泛化能力，包括图像内画、外画和编辑。这些结果表明 VAR 最初模拟了法学硕士的两个重要属性：缩放定律和零样本任务泛化。我们已经发布了所有模型和代码，以促进 AR/VAR 模型在视觉生成和统一学习方面的探索。  Arxiv: https://arxiv.org/abs/2404.02905 Github： https://github.com/FoundationVision/VAR   由   提交 /u/ExponentialCookie   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvh8ep/d_visual_autoregressive_modeling_scalable_image/</guid>
      <pubDate>Thu, 04 Apr 2024 07:33:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使视觉合成数据看起来更真实的网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvg32z/d_networks_that_make_visual_synthetic_data_look/</link>
      <description><![CDATA[我经常听说 Blender 或视频游戏引擎生成的合成数据（至少是视觉数据）的问题是它们不够真实实现现实世界的可移植性。 但是有没有任何作品可以将这些合成图像通过网络传递，使它们看起来更真实，并使用它们来训练模型？ 我更指的是到像这个旧视频这样的网络，他们将其应用到 GTA V 镜头中，使其看起来更真实。   由   提交 /u/notEVOLVED   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvg32z/d_networks_that_make_visual_synthetic_data_look/</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>电子竞技赔率是如何计算的？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvfjzo/how_are_esports_odds_computedd/</link>
      <description><![CDATA[只是想获取有关上述内容的见解和资源。   由   提交/u/smackcam20   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvfjzo/how_are_esports_odds_computedd/</guid>
      <pubDate>Thu, 04 Apr 2024 05:42:03 GMT</pubDate>
    </item>
    <item>
      <title>保存/加载图像分类器模型时遇到错误 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvfedu/faced_error_while_savingloading_an_image/</link>
      <description><![CDATA[我在 Kaggle 中训练了一个图像分类器模型。 保存了模型： model.save(“/kaggle/working/model/imgclf.h5”) 当我尝试在另一个笔记本中加载模型时： loaded_model = load_model(&#39;imgclf.h5&#39;) 给出错误：  TypeError：使用 config={&#39;batch_shape&#39;: [None, 256, 256, 3], &#39;dtype&#39;: &#39;float32&#39;, &#39;sparse&#39;: False 反序列化类 &#39;InputLayer&#39; 时出错，&#39;名称&#39;：&#39;input_layer_2&#39;}。遇到异常：无法识别的关键字参数：[&#39;batch_shape&#39;] 分享您解决此问题的想法:)    ;由   提交 /u/naniramd   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvfedu/faced_error_while_savingloading_an_image/</guid>
      <pubDate>Thu, 04 Apr 2024 05:32:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 ML 社区中建立联系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvat6l/d_how_to_create_contacts_in_the_ml_community/</link>
      <description><![CDATA[我想知道在 ML 社区中创建联系人的最佳方法是什么，因为我不确定从哪里开始以及这些方法在寻找时有多重要为了在该行业找到一份工作。当然，在 LinkedIn 上添加一些联系人也没什么坏处。有什么建议吗？   由   提交 /u/mmenendezg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvat6l/d_how_to_create_contacts_in_the_ml_community/</guid>
      <pubDate>Thu, 04 Apr 2024 01:36:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自动化超参数选择</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bv8x3r/p_automating_hyperparameter_selection/</link>
      <description><![CDATA[大家好！我昨天在这里发布了关于另一个项目的信息，并得到了非常有用的反馈，所以我想我应该发布关于我一直在从事的另一个项目的信息。我真的不知道这是否存在（老实说，可能确实存在），但我开发了一个简单的程序，没有机器学习经验的人可以提供 CSV 数据，它会自动选择超参数并根据数据训练前馈神经网络。我不会撒谎说它总是选择最好的参数，因为通常它实际上并没有选择最好的参数，但我希望您能检查一下并提供一些反馈。以下是 github 存储库的链接： https://github.com/jakeSteinburger/autoParam 它仍处于早期阶段，我觉得它已经存在，但我真的很喜欢你完全诚实的反馈。提前致谢！   由   提交 /u/JakeStBu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bv8x3r/p_automating_hyperparameter_selection/</guid>
      <pubDate>Thu, 04 Apr 2024 00:12:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] RLHF 真的有效吗？你为什么用它？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bv2jgm/d_does_rlhf_really_work_why_do_you_use_it/</link>
      <description><![CDATA[我尝试过自己做 RLHF。使用以下库： https://huggingface.co/docs/trl/en/index&lt; /a&gt;  在示例之外，它不起作用。  是否有人成功使用 RLHF（学术界之外）或正在为此苦苦挣扎？  您可以分享的任何具体用例都会有所帮助。    由   提交 /u/iordanissh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bv2jgm/d_does_rlhf_really_work_why_do_you_use_it/</guid>
      <pubDate>Wed, 03 Apr 2024 19:58:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么股票预测论文没有投入生产？ [D] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bv0cu7/why_stock_prediction_papers_arent_put_to/</link>
      <description><![CDATA[我最近一直在查看股票预测研究论文，并对他们所取得的成就感到惊讶。虽然这些研究看起来很有希望，但我不确定它们是否能应用于现实生活……这几乎就像是美好得令人难以置信的场景。任何人都想对此有所了解。   由   提交/u/Pomelo-Actual   /u/Pomelo-Actual reddit.com/r/MachineLearning/comments/1bv0cu7/why_stock_prediction_papers_arent_put_to/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bv0cu7/why_stock_prediction_papers_arent_put_to/</guid>
      <pubDate>Wed, 03 Apr 2024 18:36:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 只是美化了即时工程吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1busp41/d_is_rag_just_glorified_prompt_engineering/</link>
      <description><![CDATA[您会收到提示、IR 相关文档，将它们发送到提示，然后 LLM 会生成响应。我们刚刚设计了提示以提供更多信息。   由   提交 /u/RiseWarm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1busp41/d_is_rag_just_glorified_prompt_engineering/</guid>
      <pubDate>Wed, 03 Apr 2024 13:32:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过预消除使 KNN 更加高效</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bupi0p/p_making_knn_more_efficient_with_preelimination/</link>
      <description><![CDATA[大家好，我一直在从事一个小项目，我希望获得一些完全诚实的反馈。 KNN 是一种非常强大的算法，但不幸的是，它的效率也非常低，并且运行起来非常耗费资源。我一直在研究一个项目，根据一些基本测试，该项目平均比普通 KNN 快 20% 左右，而且质量几乎没有下降。您可以在此处查看 github 存储库： https://github.com/jakeSteinburger/peKNN&lt; /p&gt; 我还为此写了一篇小型论文，链接在存储库上。如果代码有点混乱，我很抱歉，但除此之外，我真的很喜欢你完全诚实的反馈（我知道 Reddit 很擅长这一点）。提前致谢！   由   提交 /u/JakeStBu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bupi0p/p_making_knn_more_efficient_with_preelimination/</guid>
      <pubDate>Wed, 03 Apr 2024 10:47:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>