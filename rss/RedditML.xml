<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 29 Jan 2025 21:14:55 GMT</lastBuildDate>
    <item>
      <title>[D] 精细调整</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1id2vyl/d_fine_tuning/</link>
      <description><![CDATA[大家好。  我正在编写一个演示，以展示微调对深度搜索提炼的影响。  我想到让模型针对某个主题进行自我审查 - 例如拒绝对我的公司发表评论。  因此，训练数据是几百条关于该公司的指令：“告诉我有关 ACME Fireworks 的信息”，“ACME Fireworks 是一家好公司吗”......等等。训练响应是“不”。  我已经进行了 2000 次迭代训练，训练损失变为 0，验证损失迅速下降然后逆转 - 但相当低。但是，当我随后运行微调时，模型响应保持不变。  我需要做更多迭代吗？更多的训练数据？我是否需要融合模型才能产生任何结果（我现在正在使用适配器路径）。  帮忙？    提交人    /u/sgt102   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1id2vyl/d_fine_tuning/</guid>
      <pubDate>Wed, 29 Jan 2025 19:53:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在配备 20 核 GPU 的 Mac Mini M4 Pro 上对 BERT 和 Llama1B 进行微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1id06w2/d_finetuning_bert_llama1b_on_macmini_m4pro_with/</link>
      <description><![CDATA[如果有人尝试在配备 14 核 CPU 和 20 核 GPU 的 Mac Mini M4 Pro 上微调小型语言模型（如 BERT、RoBERTa 等）或 Llama 3.21B 等 LLM，请分享您的经验。我正在寻找三个问题的答案：  使用 GPU 进行训练的性能如何？ ANE 对训练有什么好处吗？ 使用 &#39;mps&#39; 作为 pytorch 进行 GPU 加速的设备是否简单？或者在非 Cuda 环境中是否存在与软件兼容性相关的其他挑战？  请分享您的经验。    提交人    /u/mayankbhagya   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1id06w2/d_finetuning_bert_llama1b_on_macmini_m4pro_with/</guid>
      <pubDate>Wed, 29 Jan 2025 18:05:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如今，BART 实现如何支持因果推理？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iczvpb/d_how_do_bart_implementations_holdup_for_causal/</link>
      <description><![CDATA[大家好， BART 似乎非常受欢迎，但我只能找到一年到几年前的提及（我可能找的不够仔细）。现在与其他模型相比如何？现在我们是否更倾向于采用更灵活的 BART 实现？ 非常感谢！    提交人    /u/Sea_Farmer5942   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iczvpb/d_how_do_bart_implementations_holdup_for_causal/</guid>
      <pubDate>Wed, 29 Jan 2025 17:53:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] EmbSum：基于 LLM 的内容推荐摘要</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icxl08/r_embsum_llmpowered_summarization_for/</link>
      <description><![CDATA[EmbSum 是一种新的基于内容的推荐框架，它利用 LLM 来增强个性化和效率。通过引入用户多嵌入 (UPE) 来捕获长期用户兴趣和内容多嵌入 (CPE) 来提供更丰富的项目表示，EmbSum 可以实现更准确和可解释的推荐。与传统模型在有限的历史编码方面遇到困难不同，EmbSum 可以处理多达 7,440 多个标记的参与序列，从而显著提高推荐质量。它还采用 LLM 监督的用户兴趣摘要，细化用户资料以实现更好的内容匹配。在 MIND 和 Goodreads 数据集上进行评估后，EmbSum 的表现优于基于 BERT 的基线，并且参数更少，这证明了其在推进个性化内容传递方面的潜力。 在此处完整阅读“EmbSum：利用大型语言模型的摘要功能进行基于内容的推荐”的完整论文评论： https://www.shaped.ai/blog/embsum-llm-powered-content-recommendations    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icxl08/r_embsum_llmpowered_summarization_for/</guid>
      <pubDate>Wed, 29 Jan 2025 16:20:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 验证成本与培训和测试成本不一致的原因是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icwx1r/p_reasons_for_validation_cost_not_aligning_with/</link>
      <description><![CDATA[      我一直在优化和训练一个简单的顺序神经网络，根据比赛双方的统计数据来预测某项运动的胜负。 我使用 NeuralNetwork.NET 的更新版本来构建神经网络，并使用 GeneticSharp 的遗传算法来优化我的参数。 我所做的事情没有那么多数据，所以我对结果没有太多期待。数据大致分为 ~7500 条训练记录，验证和测试集中各有 ~750 条记录。每条记录大约有 240 个输入。 通过我的优化，我绘制了每一代最佳模型的训练、测试和验证成本，最终得到了这样的图表。 https://preview.redd.it/xpuv4wozcyfe1.png?width=1601&amp;format=png&amp;auto=webp&amp;s=64f8603a6450be7b644ae1813eb7a8439d7fdb7c 最初，我以为也许我允许每个单独的网络进行训练太多的时期，但当我监控任何单个网络的训练时，训练/测试成本和验证成本之间的差距从第 1 个时期到我停止它时都保持相当一致。有时它会略有增长，但一般来说，它是一致的。 我使用哪个集合进行验证似乎并不重要，我可以随机选择集合，或者交换测试和验证集，它总是导致几乎相同的差距。 我也尝试过减小隐藏层的大小，以防这是由于某种记忆一直缩小到只有两个节点的单个隐藏层，但这对差距也没有实际影响。 实践中的网络似乎运行良好。从来没有训练和测试结果显示的那么好，但很少像验证成本那么糟糕。考虑到数据有限而且无论如何它似乎都有效，从实际角度来看这似乎不是什么大问题，但我一直想知道是否可以做些什么来解决这个问题。  我确信这在某种程度上是过度拟合，这些年来我尝试了各种各样的事情，可能太多了，无法一一列举，所以我希望有人能提出我没尝试过的建议，或者解释一下其中的差异，这样我就不用担心了！    提交人    /u/Kezyma   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icwx1r/p_reasons_for_validation_cost_not_aligning_with/</guid>
      <pubDate>Wed, 29 Jan 2025 15:52:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 修改已接受的 ICLR 论文以删除有缺陷的贡献？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icw8yf/d_revise_an_accepted_iclr_paper_to_remove_a/</link>
      <description><![CDATA[我的一篇论文被 ICLR 接受，该论文做出了两个主要贡献：(1) 强调了使用 方法 A 代替 简单基线 存在的问题；(2) 提出了一种替代方法，即 方法 B 来解决此问题。 但是，我最近发现了我报告方法 B 结果的方式存在问题。此问题影响了该研究领域（不仅仅是我的工作）通常报告结果的方式，使方法 B 看起来比方法 A 和简单基线都好。如果结果报告正确，方法 B 仍将优于方法 A，但只会与简单基线相匹配——这引发了一个问题：使用更复杂的方法是否合理。 鉴于此，我认为不应以当前形式发表这篇论文。与 AC 分享一个修订版本是否合适，其中仅包含第一个贡献而省略第二个贡献，并且仍发表该论文？    提交人    /u/NumberGenerator   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icw8yf/d_revise_an_accepted_iclr_paper_to_remove_a/</guid>
      <pubDate>Wed, 29 Jan 2025 15:24:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大多数机械可解释性研究仅以预印本或博客文章的形式发表？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icw2pi/d_why_is_most_mechanistic_interpretability/</link>
      <description><![CDATA[我越深入研究这个话题，就越发现常见的做法是将您的工作作为博客文章发布在论坛上，而不是在同行评审的出版物上发布。  这使得工作变得不那么值得信赖和可信。我发现 Anthropic 不会在会议上发表文章，因为您无法复制他们的工作。但是，仍然有大量的工作“仅”以博客文章的形式提供。     提交人    /u/Physical_Seesaw9521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icw2pi/d_why_is_most_mechanistic_interpretability/</guid>
      <pubDate>Wed, 29 Jan 2025 15:16:56 GMT</pubDate>
    </item>
    <item>
      <title>研究人员和专业人士：您如何预见正在训练的 GPT 模型对目前困扰互联网的 AI 生成数据的影响？[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icv6ub/researchers_and_professionals_how_do_you_foresee/</link>
      <description><![CDATA[你好 Reddit， 我目前正在攻读数据科学硕士学位，我一直在想学术界或专业人士对这个问题的看法。在我看来，我们可能很快就会走向生成胡言乱语的境地 好的数据既不容易获得，也不便宜，因此，对于较小的公司来说，依赖于网络抓取的模型缺乏可用性，将不可避免地导致在公开市场上处于巨大劣势。 当前的软件和数据基础设施如何改变，以解释大量涌入的人工智能生成内容？正在开发哪些方法来准确分类人工智能生成的内容和人类内容？更重要的是，这些方法是否能够抵御滥用？ 编辑：在你对模型崩溃感到愤怒之前，我在发表这篇文章之前根本不知道模型崩溃是什么。只是一个学生试图得到一个出现在我脑海中的问题的答案。     由    /u/XilentExcision  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icv6ub/researchers_and_professionals_how_do_you_foresee/</guid>
      <pubDate>Wed, 29 Jan 2025 14:37:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发表论文 vs 获得博士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icpb9c/d_publications_vs_phd/</link>
      <description><![CDATA[这是一个相当简单的问题。  假设一个学历较低（学士或硕士）的人设法在三大会议（NeurIPS、ICML、ICLR）上发表了一些第一作者论文（让这个数字为 x）。 是否存在一个点，当 x 变得足够大时，博士学位就变得毫无意义，并且出于所有意图和目的，该人被视为合法的研究人员？ 换句话说，是否存在 x 的截止点，使得该个人的技能被视为与 R1 学校的 ML 平均博士学位相当？ 如果存在这样的截止点，它会是什么？    提交人    /u/throwaway-cs-grad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icpb9c/d_publications_vs_phd/</guid>
      <pubDate>Wed, 29 Jan 2025 08:31:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态模型的可解释性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icnzzs/r_multimodal_models_interpretability/</link>
      <description><![CDATA[我正在深入研究多模态可解释性领域的进展。类似于显著性图的东西，但用于多模态输出或我可以研究的任何其他方法。是否有任何工具和方法已经为此开发，特别是针对多模态生成模型？渴望阅读有关相同内容的论文。     提交人    /u/theysaidno_1985   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icnzzs/r_multimodal_models_interpretability/</guid>
      <pubDate>Wed, 29 Jan 2025 06:52:02 GMT</pubDate>
    </item>
    <item>
      <title>检索增强生成中的规模与智能权衡 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ick63j/the_scale_vs_intelligence_tradeoff_in_retrieval/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ick63j/the_scale_vs_intelligence_tradeoff_in_retrieval/</guid>
      <pubDate>Wed, 29 Jan 2025 03:04:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepSeek 蒸馏和训练成本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icfbll/d_deepseek_distillation_and_training_costs/</link>
      <description><![CDATA[DeepSeek v3 训练中使用了蒸馏技术 (https://arxiv.org/html/2412.19437v1)。560 万美元仅仅是训练“学生”模型的成本吗？我并没有低估这一成就本身。但是，我想了解训练教师模型的成本是否已计入 560 万美元。 如果不考虑这些成本，虽然 DeepSeek 为降低成本和工程做出了重要贡献，但主流媒体散布的数字并不完全一致，需要进行纠正。或者也许我误解了整件事。 感谢您对此提供的任何见解。     由   提交  /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icfbll/d_deepseek_distillation_and_training_costs/</guid>
      <pubDate>Tue, 28 Jan 2025 23:13:12 GMT</pubDate>
    </item>
    <item>
      <title>[p] 让人们可以使用免费的 GPU - 希望得到 Beta 版反馈🦾</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icepak/p_giving_ppl_access_to_free_gpus_would_love_beta/</link>
      <description><![CDATA[大家好！我是一家 YC 投资公司的创始人，我们正努力让 ML 模型的训练变得非常便宜和简单。目前，我们正在运行一个免费测试版，希望得到您的一些反馈。 如果听起来很有趣，请随时在这里查看：https://github.com/tensorpool/tensorpool TLDR；免费计算😂    提交人    /u/joshkmartinez   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icepak/p_giving_ppl_access_to_free_gpus_would_love_beta/</guid>
      <pubDate>Tue, 28 Jan 2025 22:45:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>