<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 17 Jul 2024 03:18:23 GMT</lastBuildDate>
    <item>
      <title>[P] Transformer 中的梯度消失？帮帮我 !!!!!!!!</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e57w8p/p_vanishing_gradient_in_transformer_help_mee/</link>
      <description><![CDATA[      大家好。 首先，请原谅我的英语水平。 我正在使用 Pytorch 从头开始​​编写 Transformer 模型的代码。我完成了所有数据预处理并过滤了数据集以供模型输入。 我所能做的一切都已经根据我的知识完成了。但是，模型学习效果并不好。即使我的学习率高达 0.1，梯度也只有 1e-07 左右。我尝试将 LR=1 设置为 1 只是为了检查是否有任何变化，但梯度仍然非常小。我知道这与 LR 无关，但不知道在哪里寻找变化，因为我已经多次反复查找架构代码。 所以我来这个社区寻求帮助，因为我从这个 subreddit 开始时找到了很多帮助。 我知道在这里问这个问题是一件大事，因为它可能表现得好像我很懒惰，但我不是，因为我尽我所能来提高我的训练水平，但似乎并没有。我重新设计了我的代码并使用了大量打印语句，但架构正在运行并给出了应有的准确张量形状。除此之外，我不确定我到底应该寻找什么。因为我不知道应该更改代码的哪一部分以获得更好的结果。因此我在这里寻求帮助。 如果有人有兴趣提供帮助，我在这里附加了我的 github repo 链接，以便有人可以轻松下载代码并查看它。 GitHub 链接如果有人需要我的代码的额外细节，我会分享细节。这是我的文件夹结构： 感谢您阅读到目前为止的内容。 testssss.ipynb 不是必需的。 architecture.py：变压器架构的主要代码 model.py：结合来自 architecture.py 的编码器和解码器 https://preview.redd.it/qieimgthxzcd1.png?width=1042&amp;format=png&amp;auto=webp&amp;s=bfecf225108c5119bd4d9d82f2ca4245dda213e4    提交人    /u/Nirmal590   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e57w8p/p_vanishing_gradient_in_transformer_help_mee/</guid>
      <pubDate>Wed, 17 Jul 2024 03:13:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们使用什么模型来确定某个事件是否实时发生？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e57tz1/d_what_models_do_people_use_to_determine_whether/</link>
      <description><![CDATA[每当 Gamestop RoaringKitty 直播说“我们要结束直播”这样的话，我都会看到一些机器人在直播中交易的片段。人们使用什么系统/模型来做到这一点？如果来源没有明确定义，或者有多个事件，例如“X 艺术家今天发布了专辑吗？”，该怎么办？    提交人    /u/Bradmcstark   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e57tz1/d_what_models_do_people_use_to_determine_whether/</guid>
      <pubDate>Wed, 17 Jul 2024 03:10:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 租用 GPU 的最佳地点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e562n1/d_best_places_to_rent_gpus_from/</link>
      <description><![CDATA[大家好， 我希望能够灵活地按需租用 GPU，而且当然不必支付很多费用。我一直在关注一些公司，例如 brev.Dev、runpod 和 fluidstack。我想知道你们是否使用其中任何一个或其他东西来运行工作负载     提交人    /u/OGbeeper99   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e562n1/d_best_places_to_rent_gpus_from/</guid>
      <pubDate>Wed, 17 Jul 2024 01:42:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用多个 gpu 对磁盘的影响？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e55tne/d_effects_of_using_multiple_gpus_on_the_disk/</link>
      <description><![CDATA[嗨，如果需要，请用粗体显示 TLDR。我目前正在尝试训练一个模型，并尝试几种配置（主要是更改 gpu、epoch 和步数。其他参数暂时保持不变）。我的目标是在增加 gpu 时看到总体性能改进，主要是在训练时间方面。我进行了两个单独的实验，分别使用了 4 个和 8 个 gpu。令我惊讶的是，与 4 个 gpu 相比，使用 8 个 gpu 并没有改进；但值得注意的是，与我最初仅使用 2 个 gpu 的实验相比，有改进。我在更改 gpu 时更改了其他参数，例如步数，因此我期望看到更快的训练时间。我很好奇这是否与磁盘利用率有关。我倾向于进一步探索这一领域，因为我目前在整个训练过程中记录了 GPU 和磁盘利用率。据我所见，GPU 利用率符合预期。磁盘利用率对于 8 个 GPU 来说似乎有点低，因为与 4 个 GPU 实验记录的相比几乎没有增加。在我的实验中，我确实可以选择增加每个 GPU 的进程数。我计划这样做，并额外扩大这些实验的规模，看看是否可以在更高层次上看到任何变化。 我在网上搜索过这个问题，但没有找到任何有用的资源。有人能给我指出一些资源，帮助我更好地理解这种关系吗？如果有人熟悉这个主题，请随时分享。谢谢。    提交人    /u/dillpill4   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e55tne/d_effects_of_using_multiple_gpus_on_the_disk/</guid>
      <pubDate>Wed, 17 Jul 2024 01:30:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找 PlotQA 或 ChartQA 上 SOTA 视觉模型的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e50rzd/d_looking_for_comparison_of_sota_vision_models_on/</link>
      <description><![CDATA[有人知道这些视觉 QA 测试中 Claude-3.5-sonnet、GPT-4o、LLaVa 等顶级模型的最新比较吗？    提交人    /u/Confident-Honeydew66   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e50rzd/d_looking_for_comparison_of_sota_vision_models_on/</guid>
      <pubDate>Tue, 16 Jul 2024 21:42:35 GMT</pubDate>
    </item>
    <item>
      <title>[N] 发现了一个有用的工具，可用于在大量非结构化数据上扩展 LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4xp2y/n_found_a_helpful_tool_for_scaling_llm_on_a_large/</link>
      <description><![CDATA[所有不同的 LLM 模型/API 提供商都很不错，并且使用 ChatGPT UI。我们拥有大量非结构化数据，例如我们拥有的 PDF 和图像/视频，我们希望从中提取特征。但是我们没有团队来编写 PySpark 代码来扩展工作量，Snowflake 也不能很好地支持非结构化数据。 Roe AI 使我们更容易实现这一点。我们可以轻松地使用 SQL 在我们的非结构化数据集上协调不同的任务，从图像标记和 PDF 解析到多模态搜索。这是他们最新的 substack 帖子供您参考： ~https://roeai.substack.com/p/roe-ai-launches-volansdb~   由    /u/RedemptiVaga  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4xp2y/n_found_a_helpful_tool_for_scaling_llm_on_a_large/</guid>
      <pubDate>Tue, 16 Jul 2024 19:36:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻求研究合作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4vvvz/r_seeking_research_collaboration/</link>
      <description><![CDATA[这是一个长远的目标，但也许会成功：我是一名刚毕业的博士生，正在寻求神经网络压缩领域的合作。我有一个成熟的想法，正在寻找聪明的人来完成实验并一起写论文。我的实验还处于早期阶段，我还没有开始写作，但我在这个领域发表过类似的论文。  关于你：可以使用 GPU 集群，对 PyTorch 和神经网络的内部工作原理有广泛的了解，有训练 Transformers 的经验，你之前曾在 ML 领域发表过论文。  如果你有兴趣，请直接发信息给我。     提交人    /u/walterkronkite33   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4vvvz/r_seeking_research_collaboration/</guid>
      <pubDate>Tue, 16 Jul 2024 18:23:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] DiT 实施失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4vi9h/d_failed_dit_implementation/</link>
      <description><![CDATA[      大家好， 作为我在研究机器人操作时，想训练一个 DiT。我试图让它过度拟合一个简单的 20k 样本 猫数据集 。我的实现类似于论文的“adaLN-Zero”版本（在 LayerNorm 上进行条件化），它有 12 个 DiT 块层、12 个头、隐藏大小为 768 和一个补丁大小为 2。因为图像只包含猫，所以条件化有点没用，因为样本都有相同的标签。我在将它过度拟合到 MNIST 上确实取得了不错的效果。 在 8xA100 上一个小时后，我觉得它已经达到了瓶颈并努力克服它。 结果也很糟糕（图像是 1k 步采样）。我应该期待这个数据集有更好的效果吗？我将非常感谢任何能帮助我的人🙏 这是repo（我很懒，使用了HuggingFace的DDPMScheduler，但计划在它工作时编写自己的） https://preview.redd.it/k9bdi93b8xcd1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=5d3b14d1a16d3f4e9c5fbe8049cec6e4c5d360a5 https://preview.redd.it/9bmstg8c8xcd1.png?width=818&amp;format=png&amp;auto=webp&amp;s=f08747c95b5148a04c42c12ee8462b9bd2c6d057    提交人    /u/Ok_Operation_2094   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4vi9h/d_failed_dit_implementation/</guid>
      <pubDate>Tue, 16 Jul 2024 18:07:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] Tricycle：从头开始完全从 Autograd 到 GPT-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4sz1e/p_tricycle_autograd_to_gpt2_completely_from/</link>
      <description><![CDATA[我想分享 Tricycle：一个我完全从头开始构建的快速、功能齐全的深度学习框架： https://github.com/bclarkson-code/Tricycle/。 到目前为止，最大的里程碑是在单个 RTX 3090 上 68 小时内在 23 亿个代币上训练 GPT-2(124M)，我正在努力进一步扩大规模。 整个库都是从头开始构建的，从 AutoGrad 引擎一直到 GPT-2，任何有一点 Python 经验的人都应该可以理解。我试图使代码尽可能简单而不隐藏任何东西，并且我添加了一个 wiki 来介绍我如何构建所有内容。 我很想听听你的想法！ 编辑：语法    提交人    /u/Efficient_Plankton_9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4sz1e/p_tricycle_autograd_to_gpt2_completely_from/</guid>
      <pubDate>Tue, 16 Jul 2024 16:26:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文讨论：超越：生成模型的表现可以超越训练它们的专家</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</link>
      <description><![CDATA[大家好， 正如标题所示：我创建这篇文章是为了讨论最近发布的论文，该论文到目前为止引起了很多关注。我刚刚阅读了这篇论文，有一些问题。如果你也读过并喜欢这篇论文，我们聊聊吧！ https://arxiv.org/abs/2406.11741  设置对你来说清楚吗？作者是否也通过实验测试了定理 3 或定理 4？ 训练数据集中有多少专家/玩家？如果他们测试定理 4，他们是否会在特定玩家的游戏上训练集合的每个成员？ 他们如何鼓励定理 3 中的不相交集条件？ 等式 4 有一个拼写错误（两个术语相同）？     提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</guid>
      <pubDate>Tue, 16 Jul 2024 14:27:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 模型手术：通过简单的参数编辑调节 LLM 的行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4l9xc/r_model_surgery_modulating_llms_behavior_via/</link>
      <description><![CDATA[我们很高兴介绍我们的新工作： 通过直接参数编辑来调节 LLM 行为。以推理级计算成本实现高达 90% 的解毒！ 对于我们想要避免的行为，我们使用线性分类器作为行为探针来对 LLM 的隐藏状态空间进行分类。然后，我们确定影响此行为的关键 LLM 参数，并通过转向行为探针来编辑这些参数。 我们在 RealToxicityPrompts 数据集上的实验表明，我们的方法可以将毒性降低高达 90%，在 ToxiGen 上降低 49%。我们的技术保留了 LLM 的核心功能，例如常识和推理，同时在解毒任务中表现出色。    提交人    /u/Anonymous_user0986   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4l9xc/r_model_surgery_modulating_llms_behavior_via/</guid>
      <pubDate>Tue, 16 Jul 2024 10:30:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 蛋白质语言模型揭示病毒模仿和免疫逃逸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</link>
      <description><![CDATA[我们被 ICML 24/ML4LMS 研讨会接受了，所以我想分享一下 :) &quot;蛋白质语言模型揭示病毒模仿和免疫逃逸&quot; TL;DR: 🧬 研究概述：病毒模仿宿主蛋白以逃避免疫系统的检测。我们使用蛋白质语言模型 (PLM) 来区分病毒蛋白和人类蛋白，ROCAUC 为 99.7%，准确率为 97%。 📊 见解：我们的研究表明，PLM 和生物免疫系统会犯类似的错误。通过识别和分析这些错误，我们可以深入了解免疫反应性以及开发更有效的疫苗和治疗方法的潜在途径。 我们还展示了一种新颖的、可解释的、多模式表格错误分析方法，用于理解任何问题的见解和错误，让我们了解深度学习语言模型/PLM 所犯错误的特征。 🔗 论文：https://openreview.net/forum?id=gGnJBLssbb&amp;noteId=gGnJBLssbb 代码：https://github.com/ddofer/ProteinHumVir 与我和海报见面（#116）在 ICML/ML4LMS 研讨会上！：https://openreview.net/attachment?id=gGnJBLssbb&amp;name=poster doi： https://doi.org/10.1101/2024.03.14.585057    提交人    /u/ddofer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</guid>
      <pubDate>Tue, 16 Jul 2024 09:13:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] “创造性”解码策略怎么了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e42das/d_what_happened_to_creative_decoding_strategy/</link>
      <description><![CDATA[对于 GPT-2 以及当时的大多数模型，简单的贪婪解码极易快速生成重复且无意义的输出，需要使用许多技术，例如 top-p 采样、核采样、重复惩罚、n-gram 惩罚等。（例如 https://arxiv.org/pdf/1904.09751 ） 对于最近的 LLM，我没有使用任何这些技巧，相反，0 到 1 之间的任何温度似乎都可以正常工作。我观察到的唯一重复生成似乎是在数学推理中，当模型想要进行一些没有成功的穷举搜索时。  那么，所有这些自定义解码策略是否都已成为过去，我们不再需要担心退化内容生成？     提交人    /u/zyl1024   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e42das/d_what_happened_to_creative_decoding_strategy/</guid>
      <pubDate>Mon, 15 Jul 2024 18:35:11 GMT</pubDate>
    </item>
    <item>
      <title>[N] Yoshua Bengio 的最新公开信回应了反对严肃对待 AI 安全的论点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3viby/n_yoshua_bengios_latest_letter_addressing/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3viby/n_yoshua_bengios_latest_letter_addressing/</guid>
      <pubDate>Mon, 15 Jul 2024 14:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>