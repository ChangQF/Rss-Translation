<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 13 Jan 2025 03:25:47 GMT</lastBuildDate>
    <item>
      <title>[P] 多少人工智能才算太多？🐸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i02l6w/p_how_much_ai_is_too_much/</link>
      <description><![CDATA[      我们一直在尝试使用 AI 在我们的 Ribbit Ribbit YouTube 频道上深入研究研究论文：https://www.youtube.com/@ribbitribbit365。如果您认为 NotebookLM 只是夸大其词的闲聊，那么您可能会更喜欢我们的风格，因为我们会逐页深入研究公式、图形和表格。 在制作这些视频时，AI 会处理大部分步骤，包括  选择论文 生成叙述脚本 生成突出显示和注释 构建大纲 制作画外音  这个想法来自每天发表的大量新论文。我们在想，AI 能否介入，使其变得高效，甚至有点有趣？反馈非常有趣——有些人喜欢它的效率和技术，而有些人觉得 AI 语音令人反感……这让我们开始思考：  在解释研究中，人性化有多重要？人们总是渴望麦克风后面有一个真正的人吗？ 只要准确，你能接受完全由 AI 生成的解释吗？ 还是感觉有点……没有灵魂？  ... 很高兴听到你对此的看法。 https://preview.redd.it/u3dxg4c6ynce1.png?width=1809&amp;format=png&amp;auto=webp&amp;s=faac6086b369230d1cad9309ae42b872be718420    提交人    /u/haoyuan8   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i02l6w/p_how_much_ai_is_too_much/</guid>
      <pubDate>Mon, 13 Jan 2025 01:25:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我应该专注于 Leetcoding 吗，还是无薪的学术 ML 实习也值得？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i023ga/d_should_i_focus_on_leetcoding_or_is_an_unpaid/</link>
      <description><![CDATA[我是一名硕士生，将于 2025 年 5 月毕业。这个春季学期，我的学业负担很轻（一门简单的选修课）和一份助教工作，这将使我能够专注于培养我的编码和面试技能并申请 2025 年春季的职位。 最近，我学校的生物系给我提供了一个无薪的 ML 实习机会。该项目涉及使用机器学习对蝙蝠视觉进行成像，并提供三个学分，但每周需要 20 小时。虽然这份实习符合我对 ML 的兴趣，并可能为未来的 ML 职位打开大门，但我目前的大部分经验和简历都集中在后端/全栈职位上，这就是我获得面试回访的地方。 实习很吸引人，但我担心它可能会占用练习关键技能（例如编码和算法）和求职的时间，而这些已经很耗时了。与此同时，我想知道这段经历是否能帮助我将来转型到 ML 角色。 鉴于此，我应该如何确定优先顺序？  这份无薪 ML 实习是否会对我作为一名应届毕业生的职业生涯产生重大价值？ 作为一名应届毕业生，追求 ML 角色是否现实，还是我应该先坚持做软件工程师，以后再转型到 ML？ 考虑到我的简历上已经有助教工作和相关的本科研究经验，无薪学术实习是否能增加足够的价值来证明这份承诺是合理的？     提交人    /u/Supercachee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i023ga/d_should_i_focus_on_leetcoding_or_is_an_unpaid/</guid>
      <pubDate>Mon, 13 Jan 2025 01:00:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] Search-o1：基于代理搜索的增强大型推理模型 - 中国人民大学</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzyjw1/r_searcho1_agentic_searchenhanced_large_reasoning/</link>
      <description><![CDATA[  由    /u/Singularian2501  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzyjw1/r_searcho1_agentic_searchenhanced_large_reasoning/</guid>
      <pubDate>Sun, 12 Jan 2025 22:14:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 优化训练数据的宽松界限，实现更好的泛化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzychc/r_optimizing_looser_bounds_on_train_data_achieves/</link>
      <description><![CDATA[我曾遇到过使用较宽松的边界进行优化的情况，可以在测试数据上获得更好的性能。例如，在这篇论文中： https://arxiv.org/pdf/2005.07186 作者指出：“似乎至少对于错误指定的模型（例如过度参数化的神经网络），对对数似然进行较宽松的边界训练可以提高预测性能。我们推测这可能只是一个易于优化的情况，允许模型在整个训练过程中探索更多不同的模式。&quot; 更多详细信息可在附录中的公式 14 下方找到。 还有其他问题可以得出类似的观察结果吗？ 谢谢！    提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzychc/r_optimizing_looser_bounds_on_train_data_achieves/</guid>
      <pubDate>Sun, 12 Jan 2025 22:04:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 浮点精度梯度下降训练或推理失败的原因</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzy2ox/d_at_which_floating_point_precision_gradient/</link>
      <description><![CDATA[我们将 NN 视为“可微分”模型，即假设我们使用连续可微分函数。但是，我们使用浮点表示，从技术上讲，它是离散的。在某些精度下，模型开始崩溃。即考虑 fp64 模型。它可能在 fp16 精度下效果不佳，等等。 有人可以指出研究这个问题、研究故障模式、解决它们的方法等的资源（论文）吗？ 附言：这个问题的灵感来自 NVidia 公告，他们提到 Blackwell 支持 fp4 精度。我现在感兴趣的是如何在如此低的精度下做任何有用的事情，以及用什么来实现它。    提交人    /u/ArtisticHamster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzy2ox/d_at_which_floating_point_precision_gradient/</guid>
      <pubDate>Sun, 12 Jan 2025 21:53:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练模型进行自我纠正</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzwt4h/d_training_a_model_to_selfcorrect/</link>
      <description><![CDATA[我有一个法学硕士学位，我想提高我的数学推理能力。为此，我想创建一个数据集（在人工注释者的帮助下），他们可以识别模型在数学问题上犯错的步骤，提供纠正指导，并让它重试直到完成。我应该使用我自己的模型的输出（我正在尝试改进）还是另一个模型来制作数据集？    提交人    /u/PermitAmazing5235   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzwt4h/d_training_a_model_to_selfcorrect/</guid>
      <pubDate>Sun, 12 Jan 2025 20:59:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 具有局部窗口注意（SAM 风格）的 ViT 是否比在所有层中都具有全局注意的 vanilla ViT 效率高很多？尤其是在高分辨率下，全局注意的成本应该非常高。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzupbd/d_is_a_vit_with_local_window_attention_samstyle/</link>
      <description><![CDATA[      我正在阅读 Lucas Beyer 的这篇博客文章：https://lucasb.eyer.be/articles/vit_cnn_speed.html 当他将 ViTB/16 和主要采用局部注意力（窗口大小为 14）的 SAM 变体进行比较时，有点惊讶的是，吞吐量改进很小（左），并且 SAM 变体需要更多的峰值内存。 现在这只是推理，所以也许在训练过程中差异更大，但我天真地认为局部注意力仍然要快得多，特别是在高分辨率下。 在 1024x1024 时，我们应该有 1024/16=64x64 个补丁 - 所以全局注意力操作应该非常昂贵？我是否遗漏了什么？ https://preview.redd.it/es​​7oj0ky6mce1.png?width=1425&amp;format=png&amp;auto=webp&amp;s=5241198e5bb7129eae3d79e77f3a1dd136d64c2b    提交人    /u/AuspiciousApple   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzupbd/d_is_a_vit_with_local_window_attention_samstyle/</guid>
      <pubDate>Sun, 12 Jan 2025 19:30:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] FuseGPT：生成预训练变压器的可学习层融合（https://arxiv.org/pdf/2411.14507v1）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzsm1q/r_fusegpt_learnable_layers_fusion_of_generative/</link>
      <description><![CDATA[这篇论文好吗？我很难理解它的本质，例如什么是块、组级别等。我正在寻找一篇关于融合多个变压器块的论文，但这篇论文似乎没有涉及技术实现细节。    提交人    /u/Crazy_Suspect_9512   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzsm1q/r_fusegpt_learnable_layers_fusion_of_generative/</guid>
      <pubDate>Sun, 12 Jan 2025 18:02:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了 pkld — 用于昂贵/缓慢的 Python 函数的缓存，可在代码运行期间持续存在</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzshvp/p_i_made_pkld_a_cache_for_expensiveslow_python/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzshvp/p_i_made_pkld_a_cache_for_expensiveslow_python/</guid>
      <pubDate>Sun, 12 Jan 2025 17:57:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 比 modal.com 更便宜的替代品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzq0ac/d_cheaper_alternative_to_modalcom/</link>
      <description><![CDATA[还有其他好的服务可以让您在 8xH100 机器上立即启动 docker 映像吗？Modal 每小时的价格是 lambda labs 或 voltage park 的两倍，但我需要快速的启动/关闭。    提交人    /u/pz6c   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzq0ac/d_cheaper_alternative_to_modalcom/</guid>
      <pubDate>Sun, 12 Jan 2025 16:11:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 12 Jan 2025 16:00:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 在计算机视觉领域获胜了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzn0gg/d_have_transformers_won_in_computer_vision/</link>
      <description><![CDATA[嗨， 自 2018 年 BERT 和 GPT-1 问世以来，Transformer 在书面和口头自然语言处理应用中占据了主导地位。 对于计算机视觉，我上次检查时发现它在 2020 年开始获得发展势头，一张图片胜过 16x16 个单词，但当时的观点是“是的，Transformer 可能对 CV 有好处，现在我会继续使用我的 resnet” 2025 年这种情况有变化吗？ Vision Transformers 是否是计算机视觉的首选骨干？ 换句话说，如果您要从头开始一个新项目来进行图像分类（医学诊断等），您将如何在架构和培训目标方面着手？ 我主要是 NLP 人员，所以请原谅我对行业中的 CV 问题缺乏了解。    提交人    /u/Amgadoz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzn0gg/d_have_transformers_won_in_computer_vision/</guid>
      <pubDate>Sun, 12 Jan 2025 13:47:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] Llama3 推理引擎 - CUDA C</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hze3vs/p_llama3_inference_engine_cuda_c/</link>
      <description><![CDATA[      嗨，r/MachineLearning，最近我从 llama.cpp、ollama 和类似的工具中获得了灵感，这些工具可以在本地进行 LLM 推理，我刚刚用 CUDA C 为 8B 模型构建了一个 Llama 推理引擎。 作为构建优化 GPGPU 软件的探索性工作的一部分，我决定从头开始构建它。这个项目只使用本机 CUDA 运行时 api 和 cuda_fp16。推理发生在 fp16 中，因此它需要大约 17-18GB 的​​ VRAM（~16GB 用于模型参数，更多用于中间缓存）。 它不使用 cuBLAS 或任何类似的库，因为我想接触最少的抽象。因此，它不像 cuBLAS 实现或其他推理引擎（如启发该项目的引擎）那样优化。 实现的简要概述 我使用了 CUDA C。它读取了模型的 .safetensor 文件，您可以从 HuggingFace 中提取该文件。实际的内核对于规范化、跳过连接、RoPE 和激活函数 (SiLU) 相当简单。 对于 GEMM，我已实现平铺矩阵乘法并为每个线程进行矢量化检索。GEMM 内核的编写方式也是，第二个矩阵不需要预先转置，同时仍可实现对 HBM 的合并内存访问。 有些内核（如 RoPE 和 GEMM 的内核）使用矢量化内存访问。 SwiGLU 前馈计算的部分内容在自定义融合内核中进行。 如果您感兴趣，可以随意查看项目仓库并尝试一下。如果您喜欢所看到的内容，也可以随意为仓库点赞！ 我非常感谢任何反馈，无论是好的还是建设性的。    提交人    /u/Delicious-Ad-3552   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hze3vs/p_llama3_inference_engine_cuda_c/</guid>
      <pubDate>Sun, 12 Jan 2025 03:51:21 GMT</pubDate>
    </item>
    <item>
      <title>[P] 构建了一个贪吃蛇游戏，使用扩散模型作为游戏引擎。它几乎实时运行 🤖 它根据用户输入和当前帧预测下一帧。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hz1l2j/p_built_a_snake_game_with_a_diffusion_model_as/</link>
      <description><![CDATA[        由    /u/jurassimo  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hz1l2j/p_built_a_snake_game_with_a_diffusion_model_as/</guid>
      <pubDate>Sat, 11 Jan 2025 17:57:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>