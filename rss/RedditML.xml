<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sun, 23 Feb 2025 01:21:06 GMT</lastBuildDate>
    <item>
      <title>[d]在预测新的，看不见的时间序列信号时，您如何评估模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ivux1n/d_how_do_you_evaluate_models_when_predicting_new/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我对时间序列预测的（可能）较小的区域感兴趣。通常，重点是通过随着时间的推移将数据拆分来预测已知信号的未来值。但是，您拥有多个时间序列（例如用电数据）的方案又如何预测一个全新的，看不见的信号？ 是否有人尝试过将数据分配到数据集中（即在期间丢失了整个信号培训）而不是使用基于时间的分配？您发现哪些方法和评估策略对于此类问题有效？ /strong&gt;给定的 n   n 家庭的用电信号，预测 n+1 &#39;th家庭的消耗。  &lt; li&gt; 库存价格：给定 m 时间序列 -  east表示 m 股票的开放，高，低和近距值（4个功能） - 预测 m+1 &#39;th，m+2&#39;th和m+3&#39;股。  一个额外的挑战是归一化。在标准预测中，您可以根据每个信号的培训数据在预测其未来时使用z评分。但是，在预测新信号时，应使用哪些统计信息？一个天真的解决方案可能是掌握训练信号中标准偏差的平均值和平均值，但是是否有更好的替代方案？  为什么不讨论这一点？   为什么所有论文都专注于预测未来的所有输入信号？   我缺少什么？   ps： 我领导了一个小型创业公司的ML团队，专注于时间序列。我们的用例正在为新客户和现有客户预测信号。我们的时间序列“分裂”考虑了来自培训和的一部分的信号的未来样本，这些示例和来自看不见的数据  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/upaster-ability-774     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ivux1n/d_how_do_do_do_you_evaluate_models_models_models_models_models_when_predicting_new/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ivux1n/d_how_do_you_evaluate_models_when_predicting_new/</guid>
      <pubDate>Sat, 22 Feb 2025 22:29:13 GMT</pubDate>
    </item>
    <item>
      <title>[P]在Edge（iPhone），核心ML工具上运行ML模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ivrlu8/p_run_ml_models_on_edge_iphone_core_ml_tools/</link>
      <description><![CDATA[在   我正在尝试遵循上面的指南。 我一直在尝试编译一些型号，这是一场噩梦。感觉就像这些示例是高度人为的，因为我无法导出任何我想使用的模型。我一直在下面遇到这样的问题。  当未指定的&#39;convert__to&#39;和&#39;minimum_deployment_target&#39;均未指定&#39;convert_to&#39;时，将其设置为“ mlprogram”。和“ minimum_deployment_target”设置为ct.target.ios15（与ct.target.macos12相同）。注意：该模型不会在比IOS15/MACOS12/WatchOS8/TVOS15的系统上运行。为了使您的模型在较旧的系统上运行，请将“ Minimum_deployment_target”设置为ios14/ios13。详细信息请参阅链接：   https://apple.github.io/coremltools/docs-guides/source/target-conversion-formats.html    在图形输出时检测到的元组。这将在转换的模型中扁平。&lt; /code&gt;  转换pytorch frontend ==＆gt; MIL OPS：0％| | 0/253 [00：00＆lt;？，？ ops/s]     错误 - 转换&#39;mul&#39;op（位于：&#39;366&#39;）：     转换Pytorch frontend ==＆gt; MIL OPS：94％|█████████▍| 238/253 [00：00＆lt; 00：00，7431.73 OPS/s]   所以，真正的问题：人们打算如何运行本地LLM，计算机视觉或任何新模型在iPhone上？我对在任何地方托管这些型号没有兴趣，我只希望它们在iPhone上运行（不，谢谢，我没有Android来原型）。 在我受到指责之前这些模型太大，细，很好，但是可以优化（量化，修剪等），无法使它们以可接受的速度运行。但是，如果我什至无法将它们导出到Apple格式中，我将永远无法优化它们。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/milong0     [links]      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ivrlu8/1ivrlu8/p_run_ml_models_onded_edge_iphone_core_core_ml_ml_tools/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ivrlu8/p_run_ml_models_on_edge_iphone_core_ml_tools/</guid>
      <pubDate>Sat, 22 Feb 2025 20:01:03 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Verifai-带有可验证答案的开源生成搜索引擎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ivov3d/project_verifai_open_source_generative_search/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/knighofavalon     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ivov3d/project_verifai_open_source_generative_search/</guid>
      <pubDate>Sat, 22 Feb 2025 18:03:52 GMT</pubDate>
    </item>
    <item>
      <title>[r]解释深度神经网络：记忆，内核，最近的邻居和注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ivnp1c/r_interpreting_deep_neural_networks_memorization/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/thienpro123     [link] 32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ivnp1c/r_interpreting_deep_neural_networks_memorization/</guid>
      <pubDate>Sat, 22 Feb 2025 17:15:49 GMT</pubDate>
    </item>
    <item>
      <title>利用神经网络进行协作过滤：用描述增强电影建议[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ivmtzv/leveraging_neural_networks_for_collaborative/</link>
      <description><![CDATA[在href =“ https://medium.com/@danielmachinelearning/leveraging-neuraging-neuraging-networks-for-collaborative-filterrative-filtering-enhancing-movie-recommendations-with-0965253117d2”&gt; https://medium.com/@danielmachinelearning/leveraging-neuraging-neurainworks-for-collaborative-filtering-enhancing-movie-movie-movie-movie-commendations-0965253117d2    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ok-scene-1317     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ivmtzv/leveraging_neural_networks_for_collaborative/</guid>
      <pubDate>Sat, 22 Feb 2025 16:40:05 GMT</pubDate>
    </item>
    <item>
      <title>[R]计算微调视觉语言模型的成本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ivjrwi/r_calculating_costs_of_fine_tuning_an_vision/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好，我需要帮助计算微调VL模型的成本。我的图像数据集是尺寸80+GB（ https://huggingface.co/datasets/russrobin/spatialqa ） &gt;我对是否执行完整参数 /Qlora Finetuning感到困惑。我不能在此上花费更多，但希望检查结果。&lt; /p&gt; 如果可以的话，我可以估算的成本估算，以及如何估算一般我可以采样数据集，如果打破了我的成本约束，仍然看到结果吗？也建议我的情况最好，最便宜的计算平台。 &gt;＆＃32;提交由＆＃32; /u/u/thekarthikprasad    href =“ https://www.reddit.com/r/machinelearning/comments/1ivjrwi/r_calculating_costs_of_fine_tuning_an_vision/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ivjrwi/r_calculating_costs_of_fine_tuning_an_vision/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ivjrwi/r_calculating_costs_of_fine_tuning_an_vision/</guid>
      <pubDate>Sat, 22 Feb 2025 14:21:21 GMT</pubDate>
    </item>
    <item>
      <title>[r]评估285个研究生学科的LLM知识：使用人-LLM协作过滤的全面基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ivd069/r_evaluating_llm_knowledge_across_285_graduate/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  使用迭代的人类AI协作方法来产生和验证问题，一种新的评估基准测试了285个研究生级学科的语言模型。该方法将专家审查与模型辅助过滤结合在一起，以确保高质量，适合纪律的评估。 关键技术要点： - 使用两个阶段的问题生成过程：初始AI生成，然后进行专家审查 - 实施协作过滤，其中人类专家和LLM都有助于识别和删除有问题的问题 - 涵盖了传统学术界到专业工业领域的学科 - 测试事实知识和推理能力 - 对包括GPT -4，Claude 2和DeepSeek  的多个领导LLM进行评估： - 最佳性能：DeepSeek -R1的精度为61.82％ - 不同学科的性能的显着差异 -  80多个专家注释者验证 - 由2,855个经过验证的问题生成的数据集 我认为，该基准通过超越了共同的学术学业来解决LLM评估中的关键差距主题。将人类专业知识与AI协助进行问题验证相结合的方法对于开发未来的评估数据集可能是有价值的。 我认为，在不同领域的研究生级问题上相对适度的表现（62％）表明，当前的LLMS仍在在专业领域有很大的改进空间。这可能会影响我们如何使用特定领域的应用程序进行模型培训和评估。  tldr：新的基准测试使用人类协作问题生成285个研究生学科的LLMS。最佳模型达到了62％的精度，揭示了专业知识的差距。 完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ivd069/r_evaluating_llm_knowledge_across_285_graduate/</guid>
      <pubDate>Sat, 22 Feb 2025 07:02:41 GMT</pubDate>
    </item>
    <item>
      <title>[D]有人知道Sam的官方网络演示使用了什么吗？我只是无法用参数在本地复制结果。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iv8be1/d_does_anyone_know_what_sams_official_web_demo/</link>
      <description><![CDATA[在参数，  mask_generator_2 = sam2automaticmaskGenerator（model = sam2，points_per_side = 8，pred_iou_thresh = 0.7， Stability_score_thresh = 0.6，Statibal_score_offset = 0.6，box_nms_thresh = 0.3，min_mask_region_area = 25.0，use_m2m = true，） ，但结果不如其网站上的好（ https://sement-anything.com/demo ）。我尝试查看网站的源代码，但找不到他们使用的参数。有建议吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/open-bowl2017     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iv8be1/d_does_anyone_know_what_sams_official_web_demo/</guid>
      <pubDate>Sat, 22 Feb 2025 02:26:55 GMT</pubDate>
    </item>
    <item>
      <title>[P]通过非政治数据进行填充，AI Qwen/DeepSeek模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iv6ckk/p_decensor_ai_models_qwendeepseek_by_finetuning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对DeepSeek模型进行veNESOR的最佳方法？不要试图对其进行重新调查。 对Openthights-114k进行微调的Openthinker，这是一个侧重于数学，编码和研究生级Q＆amp; a等推理任务的数据集，没有政治内容。尽管使用了经过审查的基本模型（QWEN），但未经任何明确的干预措施就进行了微调的Openthinker-7B和Openthinker-32B模型。与困惑不同，没有使用自定义的微调来删除审查制度，但结果仍然未经审查。  它挑战了有关模型安全的假设，并打开了令人兴奋的新研究方向。 AI游戏在  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ubitious_anybody855     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iv6ckk/p_decensor_ai_models_qwendeepseek_by_finetuning/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iv6ckk/p_decensor_ai_models_qwendeepseek_by_finetuning/</guid>
      <pubDate>Sat, 22 Feb 2025 00:30:49 GMT</pubDate>
    </item>
    <item>
      <title>轻声轻声的人，请给予一些反馈！ [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iv3aqx/people_who_finetuned_whisper_please_give_some/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好！ 我正在考虑根据本指南的芬特语言：   https://huggingface.co/blog/fine-tune-whisper   我有VRAM的24+8和64GB的RAM  文档在这里，但是我很难找到试图Finetune finetune  的人的回报 我要寻找的是我应该期望多少时间和花费的时间，以及在我开始之前的一些技巧和技巧 谢谢！   &lt;！ -  sc_on-&gt; ＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iv3aqx/people_who_finetuned_whisper_please_give_some/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iv3aqx/people_who_finetuned_whisper_please_give_give_some/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iv3aqx/people_who_finetuned_whisper_please_give_some/</guid>
      <pubDate>Fri, 21 Feb 2025 22:13:04 GMT</pubDate>
    </item>
    <item>
      <title>[r] MLGYM：一种推进AI研究代理商的新框架和基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iuwuyu/r_mlgym_a_new_framework_and_benchmark_for/</link>
      <description><![CDATA[   推进AI研究代理商的基准” src =“ https://b.thumbs.redditmedia.com/xinvvnpb0a7hm6gkf37oo-_ftpzxtqzxtqzvffljcgfchqrk.jpg” title =“ [r] mlgym：用于推进AI研究的新框架和基准，  &lt;！ -  sc_off -   来自摘要： 我们介绍了Meta Mlgym和Mlgym-Bench，这是一种用于评估和开发AI研究任务的LLM代理的新框架和基准。这是第一个用于机器学习（ML）任务的健身房环境，为培训此类代理的增强学习（RL）算法提供了研究。 MLGYM基础由来自计算机视觉，自然语言处理，强化学习和游戏理论等不同领域的13种不同和开放式的AI研究任务组成。解决这些任务需要现实世界中的AI研究技能，例如生成新的想法和假设，创建和处理数据，实施ML方法，培训模型，运行实验，分析结果并在此过程中进行迭代以改进给定的任务。我们在基准上评估了许多边界大型语言模型（LLM），例如Claude-3.5-Sonnet，Llama-3.1 405B，GPT-4O，O1-Preview和Gemini-1.5 Pro。我们的MLGYM框架使添加新任务，集成和评估模型或代理，按大规模生成综合数据，并为培训AI研究任务培训代理开发新的学习算法变得容易。我们发现，当前的边界模型通常可以通过找到更好的超参数来改善给定的基线，但不会产生新颖的假设，算法，体系结构或实质性改进。我们开源框架和基准，以促进未来的研究，以推动LLM代理的AI研究能力。  arxiv： https ：//arxiv.org/abs/2502.14499  github： https://github.com/facebookresearch/mlgym     &lt;！ -  sc_on-&gt;＆＃32 ;提交由＆＃32; /u/rybolos     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iuwuyu/r_mlgym_a_new_framework_and_benchmark_for/</guid>
      <pubDate>Fri, 21 Feb 2025 17:46:14 GMT</pubDate>
    </item>
    <item>
      <title>[d]降低维度是不好的做法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iuwgcu/d_dimensionality_reduction_is_bad_practice/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我得到了一个问题陈述和数据。我最初的直觉是“该数据集中最重要的功能，我可以透露什么最初的关系？&#39; 我提出了t-sne，pca或UMAP来观察初步关系以探索，但立即进行了关闭是因为“缩小维度”意味着丢失信息。”  我知道这是真的，但是... ___________？您会说什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ready_plastic1737     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iuwgcu/d_dimensionality_reduction_is_bad_practice/</guid>
      <pubDate>Fri, 21 Feb 2025 17:30:22 GMT</pubDate>
    </item>
    <item>
      <title>[D]我们是否在基本模型中遇到了缩放墙？ （非推理）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iupnet/d_have_we_hit_a_scaling_wall_in_base_models_non/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   grok 3据说接受了100,000 H100 GPU的训练，该GPU在球场上比GPT-4系列和Claude 3.5 Sonnet的型号高约10倍。  它们的能力差不多。 Grok 3不是我们希望的。在2023年和2024年，Openai一直在说他们只能继续扩展预训练的预训练，而模型只是神奇地变得更加聪明（“缩放法律”，“图表”只是“线”上的“ line”上升了“） 现在，所有的重点都放在推理上，突然Openai和其他所有人都对扩展 变得非常安静，老实说，它看起来非常可疑。现在，他们没有像2020  -  2024年那样制作越来越大的模型，而是试图使它们保持较小，同时专注于其他事情。 Claude 3.5 Opus从人类博客中悄悄地删除了，没有任何解释。有问题，他们正在尝试将其隐藏  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ch1997H     [links]      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/comments/1iupnet/d_have_we_we_hit_a_a_scaling_wall_in_in_in_base_models_models_models_models_non/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iupnet/d_have_we_hit_a_scaling_wall_in_base_models_non/</guid>
      <pubDate>Fri, 21 Feb 2025 12:23:20 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会领导禁止。 鼓励其他人创建新帖子，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。   元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iqiy4x/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1ilhw29/d_simple_questions_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>