<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Wed, 19 Feb 2025 01:15:59 GMT</lastBuildDate>
    <item>
      <title>[P]我的数据和AI十年</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ispmi8/p_my_decade_in_data_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  📅实现时刻：2024年，我开始在各个行业和国家 /地区从事数据和AI工作10年。早在六月，我认为反思这一旅程并分享一些关键要点是一个好主意。 📔📔这是一个在进行的项目，但是在过去的几周中，我终于包裹了我的笔记。结果？著作的著作 - 可能是我迄今为止最长的文章，所以扣紧了！只是我的个人经历，经验教训以及该领域十年来的参考。希望您喜欢它！ 📖文章： https：// www。 the-odd-dataguy.com/2025/02/13/10_years_journey/   🎧音频版本： https://open.spotify.com/episode/1fi0f8oymz349cnudu74fc?si=u99xppqwtfgfo5-ugrbnsg    ps：写这本书肯定给了我一些新的深度潜水的想法，但我很想听听您的想法！什么对你突出？您有什么希望我进一步探索的吗？ 👇  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1ispmi8/p_my_decade_in_data_ai/”&gt; [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ispmi8/p_my_decade_in_data_ai/</guid>
      <pubDate>Tue, 18 Feb 2025 22:47:52 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于DDPM的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isn9au/d_question_about_ddpm/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我试图将我的大脑缠绕在我所读的东西上，但是很难做到。 为简单起见，让我们来想象一下，将DDPM模型进行了参数化，使其直接输出估计的干净图像。例如，x（x  t，t）= hat {x} _t。现在，想象一下我们的X（）网络是最佳的。给定DDPM目标，这意味着输出将为E [X_0 | X_T]。我试图了解具有此完美的Denoiser如何使参数化的反向后p（x  {t-1} | x  t）等于真实的反向后p（x  {t-） 1} | x_0，x_t）。我一直在试图得出这种平等，但我似乎无法弄清楚。我看到很多论文提出了主张，但没有人解释过。这很简单，我很愚蠢？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1isn9au/d_question_about_ddpm/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isn9au/d_question_about_ddpm/</guid>
      <pubDate>Tue, 18 Feb 2025 20:49:03 GMT</pubDate>
    </item>
    <item>
      <title>[D]用于培训基础模型的游戏引擎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isn1oz/d_game_engines_for_training_foundational_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我认为对游戏发动机的模拟训练AI对于解锁下一个智能级别将非常重要。原因如下：  视频中可用的数据比Internet文本中的可用数据多得多。  AI需要了解物理学 - 比可重复的，无限的 - 触发产生更好的方法游戏环境 当然，它们不会准确地建模物理，但是您可以想象一个基础模型首先接受了80％模拟轨迹训练（因为样品价格便宜），而20％真实轨迹。  因此，我正在考虑ho积团结库存来骑这一波。我能想到的一些对立面    统一股票由于其他原因而波动，例如：不良管理。    AI公司制造自己的AI模拟引擎，以更准确地反映现实世界的物理学 - ＆GT; Unity认为没有上升空间。   每个人都想到什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/u/complect-media-8074      [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isn1oz/d_game_engines_for_training_foundational_models/</guid>
      <pubDate>Tue, 18 Feb 2025 20:40:18 GMT</pubDate>
    </item>
    <item>
      <title>[d] [p]图像/txt-to-json模型建议。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isk800/dp_imagetxttojson_model_recommendation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我需要一些建议我构建的项目的建议，该项目使用AI从屏幕截图或文本字符串中推断出交易。目前，我正在使用两种型号：    vision_model ：llama3.2-vision：11b-Instruct-q4_k_m     text_model ：llama3.2：3b-instruct-q6_k   这些模型是通过我的桌面上的ollama api托管的GTX 2080 Super GPU（8GB VRAM）。但是，我想最终将Ollama搬到我的Intel Nuc，这没有GPU。我也很高兴听到有关CPU兼容模型的建议吗？    我的问题面向：   日期精度：偶尔会误解交易日期。   交易检测：处理时：具有多个交易的屏幕截图（7-8），这些模型通常仅检测1-3个交易，无论是从文本还是图像中。  我正在寻找的东西for：   模型建议：在图像到json或文本到json任务中出色的模型的建议，特别是用于准确提取交易详细信息。  优化提示：有关优化模型以有效运行仅在CPU的设置上的建议。   替代方法：任何其他方法或可以提高我应用程序中交易检测准确性和可靠性的工具。  我感谢您提供的任何见解或建议！ 预先感谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/conte95     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isk800/dp_imagetxttojson_model_recommendation/</guid>
      <pubDate>Tue, 18 Feb 2025 18:48:31 GMT</pubDate>
    </item>
    <item>
      <title>[r]大语言模型中深度的诅咒</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isdopn/r_the_curse_of_depth_in_large_language_models/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isdopn/r_the_curse_of_depth_in_large_language_models/</guid>
      <pubDate>Tue, 18 Feb 2025 14:18:32 GMT</pubDate>
    </item>
    <item>
      <title>[R]评估现实世界软件工程任务的LLM：一项耗资100美元的基准研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isbo6t/r_evaluating_llms_on_realworld_software/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  旨在评估现实世界软件工程任务上LLM的新基准测试，直接从附上的“实际美元”值中拉出。该方法涉及收集1,400多个任务，从$ 50- $ 32,000的支出，创建标准化的评估环境以及测试编码能力和工程管理决策。 关键技术要点： - 通过单位测试，专家测试验证任务验证和与人类解决方案的比较 - 评估使用Docker容器来确保测试环境 - 包括直接编码任务和高级工程管理决策 - 任务涵盖Web开发，移动应用程序，数据处理和系统体系结构 - 总任务值超过100万美元的实际自由付款 结果显示了当前限制：-GPT -4仅成功完成编码的10.2％任务-Claude 2取得了8.7％的成功率 -  GPT -4的管理决策准确性为21.4％ - 随着任务复杂性/值的增加 我认为这是急剧下降的基准代表了我们评估现实世界应用LLM的重要转变。通过将绩效直接与经济价值联系起来，我们可以更好地了解当前能力和实用程序之间的差距。较低的成功率表明，在LLM可以可靠地处理专业软件工程任务之前，我们需要取得重大进展。 我认为，包括管理级别的决策尤其有价值，因为它可以测试技术理解和战略思维。这可以有助于指导开发更完整的工程辅助系统。  tldr：新的基准测试在实际$ 1M+的UPWORK编程任务上进行LLMS。当前模型在很大程度上挣扎，仅完成约10％的编码任务和约20％的管理决策。  完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isbo6t/r_evaluating_llms_on_realworld_software/</guid>
      <pubDate>Tue, 18 Feb 2025 12:35:00 GMT</pubDate>
    </item>
    <item>
      <title>[R]针对微调潜在扩散模型的面部图像的会员推理攻击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isa46f/r_membership_inference_attacks_for_face_images/</link>
      <description><![CDATA[在/2502.11619 ）（代码可在 https://github.com/osquera/mia_sd ） 问题   fine-调谐潜在扩散模型（LDMS），例如稳定扩散，Midjourney和Dall·E 3，可以重现特定样式，甚至可以在在特定领域的数据集（例如面孔，艺术品）上进行了培训。这引起了人们对未经授权的数据使用的担忧。 我们研究是否可以使用会员推理攻击（MIA）在给定的一组图像上进行微调。 &lt; &lt;。 &lt; H2&gt;我们如何接近攻击  微调模型：我们在策划的面部数据集中微调稳定扩散v1.5。 攻击模型：我们使用经过训练的Resnet-18分类器来区分图像是否是微调集的一部分，使用真实和生成的数据进行培训。 使用的技术：  黑色-box攻击（仅使用查询，无访问模型内​​部设备）。 辅助数据生成 - 我们发现，使用生成的负面因素改善了攻击性能。 调整持续时间的影响＆amp;攻击成功的指导量表。    关键发现  微调增加信息泄漏：LDM越好 - 在数据集上进行调整，其输出越多地类似于微调集，使检测成员资格更容易。 攻击成功：我们的MIA明显胜过基于零拍的夹子基线。使用生成的负面因素而不是实际的负面因素可以改善结果。  IP保护的潜力：如果艺术家或组织怀疑生成模型正在复制其工作，他们可以使用MIAS来验证其数据是否用于Fine-调整。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/osquera     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isa46f/r_membership_inference_attacks_for_face_images/</guid>
      <pubDate>Tue, 18 Feb 2025 10:58:26 GMT</pubDate>
    </item>
    <item>
      <title>[r]本地稀疏注意：硬件一致且本地可训练的稀疏注意力（由Liang Wenfeng提交 -  DeepSeek）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is9ufs/r_native_sparse_attention_hardwarealigned_and/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  本机稀疏注意：硬件与硬件和本地训练的稀疏注意 jingyang yuan ，Huazuo Gao，Damai Dai，Junyu Luo，Liang Zhao，Zhengyan Zhang，Zhenda Xie，Y。X。 Wang，Zhiping Xiao，Yuqing Wang，Chong Ruan，Ming Zhang，Wenfeng Liang，Wangding Zeng  长篇小说建模对于下一代语言模型至关重要计算挑战。稀疏的注意力为提高效率的方向提供了有希望的方向，同时保持模型功能。我们提出了NSA，这是一种本地可训练的稀疏注意机制，将算法创新与硬件一致的优化相结合，以实现有效的长篇文化建模。 NSA采用了动态的分层稀疏策略，将粗粒的令牌压缩与精细的令牌选择相结合，以保持全球环境意识和局部精度。我们的方法通过两个关键创新进行了稀疏注意设计：（1）我们通过算术强度平衡算法设计实现了实质性的加速，并对现代硬件进行了优化。 （2）我们启用端到端培训，在不牺牲模型性能的情况下减少预处理的计算。如图1所示，实验表明，使用NSA预测的模型维持或超过了一般基准，长篇下说任务和基于指导的推理的全部注意力模型。同时，NSA在对解码，正向传播和向后传播的64k长度序列上的全面关注方面实现了实质性加速，从而在整个模型生命周期中验证了其效率。&lt; /em&gt;  arxiv：2502.11089 [cs.cl]：&lt; /em&gt; 一个href =“ https://arxiv.org/abs/2502.11089”&gt; https://arxiv.org/abs/2502.11089       &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nunki08     [link]        [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is9ufs/r_native_sparse_attention_hardwarealigned_and/</guid>
      <pubDate>Tue, 18 Feb 2025 10:39:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]当应用行业工作时如何查看AISTATS/UAI/TMLR？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is3c39/d_how_aistatsuaitmlr_is_viewed_when_applied_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在谈论研究或应用科学家在行业中的角色。您认为这些论文在简历上提供了多少价值？与CVPR/ICCV/ECCV/NIPS/ICML/ICLR？  &lt;！ -  SC_ON- sc_on-&gt;＆＃32相比，与顶级会议的纸张相比提交由＆＃32; /u/u/demangiventive_newt_100     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is3c39/d_how_aistatsuaitmlr_is_viewed_when_applied_for/</guid>
      <pubDate>Tue, 18 Feb 2025 03:34:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] Finetuning Modernbert正在服用3小时（2个时代）和35 gigs的VRAM。正常吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is0q1a/d_finetuning_modernbert_is_taking_3hrs_2_epochs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以其他详细信息... 我正在使用a6000 48gb vram，8vcpu，8vcpu，45 gb ram。我的数据集是NewsArticle文本和标签的9K样本。 我正在使用的模型是“ answerdotai/sodernbert-base”。上下文长度为8192。 最初，当我尝试使用32或16的批处理进行捕获时，我一直在遇到OOM错误。然后，我看到了设置4个或更少的批处理。唯一的训练开始。即使训练一个时代也要花费1H 31分钟。这是正常的吗？这是我第一次迎接模型参考或过去的经验。当我将批处理大小设置为32或16时，我没想到会看到一个45MB CSV文件会填充整个VRAM。是Pytorch错误还是??? &lt; /p&gt; 编辑 - IM使用的数据集是“ valurank/politainbias_allsides_txt”的截断版本。大约有19k数据样本。我正在使用其中的一个子集 - 大约9K样品。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/solaris12     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1is0q1a/d_finetuning_modernning_modernbert_is_taking_3hrs_2_2_epochs/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is0q1a/d_finetuning_modernbert_is_taking_3hrs_2_epochs/</guid>
      <pubDate>Tue, 18 Feb 2025 01:22:30 GMT</pubDate>
    </item>
    <item>
      <title>[d]“反向传播：多元链规则”的视觉解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irs3gn/d_visual_explanation_of_backpropagation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我开始研究反向流动的视觉说明。这是第1部分： https://substack.com/home/post/post/p-157218392 。请让我知道您的想法。 使我对倒退的一部分感到困惑，这是为什么人们将反向传播与链条规则相关联？链条规则无法清楚地解释从参数到损失的多个路径。最终，我意识到我错过了“多元链规则”一词。一旦我找到了它，一切都在我的脑海中点击。让我知道您在这里有想法。  谢谢，  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/madiyar     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irs3gn/d_visual_explanation_of_backpropagation/</guid>
      <pubDate>Mon, 17 Feb 2025 19:16:15 GMT</pubDate>
    </item>
    <item>
      <title>[r]忘记数据和微调！只需折叠网络以压缩[2025年2月]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irqngl/r_forget_the_data_and_finetuning_just_fold_the/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irqngl/r_forget_the_data_and_finetuning_just_fold_the/</guid>
      <pubDate>Mon, 17 Feb 2025 18:19:59 GMT</pubDate>
    </item>
    <item>
      <title>[D]就业市场如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irnuv1/d_hows_the_job_market/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  昨天，我开始申请新工作。目前，我的标题是“ ML工程师”但是说实话，我最近一直在运行更像ML顾问 - 我已经好几个月了。专注于ML。似乎有很多角色正在寻找拥有3年以上经验的候选人。 我只是对我在接受第一次面试之前将需要多少申请的申请 - 我目前在24个申请中。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ready_plastic1737     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irnuv1/d_hows_the_job_market/</guid>
      <pubDate>Mon, 17 Feb 2025 16:29:37 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会领导禁止。 鼓励其他人创建新帖子，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。   元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iqiy4x/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1ilhw29/d_simple_questions_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>