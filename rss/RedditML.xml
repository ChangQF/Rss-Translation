<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 18 Nov 2024 09:19:45 GMT</lastBuildDate>
    <item>
      <title>[D] 数据集管理工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtzh8r/d_dataset_management_tool/</link>
      <description><![CDATA[大家好， 我们公司有很多部门，数据集遍布各处，我们希望找到某种工具，可以用作数据集的中央存储库。像 hugging face 这样可以显示下载次数/受欢迎程度、简短摘要、过滤/排序功能、添加自述文件功能等的工具就很棒了： https://huggingface.co/datasets  有谁知道有产品提供这种我们可以购买和使用的界面吗？具有 Microsoft SSO 功能的产品也很棒。理想情况下，这种产品不仅工程师可以查看/编辑，而且非技术产品所有者也可以使用。 提前致谢。    提交人    /u/alek5k   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtzh8r/d_dataset_management_tool/</guid>
      <pubDate>Mon, 18 Nov 2024 07:29:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 优化模糊场景中问答机器人的上下文提取</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtzcuj/d_optimizing_context_extraction_for_qa_bots_in/</link>
      <description><![CDATA[我正在构建一个问答机器人来回答基于大量原始文本的问题。 为了优化性能，我使用嵌入来提取原始文本的一小部分相关子集，而不是将整个文本发送到 LLM。此方法适用于以下问题：  “谁会在这场比赛中获胜？”  在这种情况下，嵌入可以有效地提取文本的正确子集。 但是，它在处理以下问题时会遇到困难：  “你之前的陈述是什么意思？”  在这里，嵌入无法提取相关子集。 我们以以下格式维护对话历史记录：  previous_messages = [ {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message1}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: message2}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message3}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: message4}, ]  但是，在遇到此类问题时，我们不确定如何提取正确的原始文本子集以作为上下文发送。 在这些情况下，将整个原始文本作为上下文发送会更好吗？    由    /u/yccheok 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtzcuj/d_optimizing_context_extraction_for_qa_bots_in/</guid>
      <pubDate>Mon, 18 Nov 2024 07:21:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 过去 30 天内有 2000 多名用户，我太高兴了！！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtypeb/p_2000_users_in_last_30_days_i_am_soo_soo_happy/</link>
      <description><![CDATA[      所以，在我上一篇文章中，我告诉了大家我如何为想要开始学习机器学习和深度学习但又不知道如何开始的人建立路线图 ( https://www.mldl.study/ )。我得到了很好的反响，也得到了很多用户的反馈。  我处理了收到的所有反馈并试图纠正它。现在有人说要开源它，这样社区就可以为资源做出贡献。因此，在重构所有代码并进行评论后，我现在开源该网站，以便任何人都可以为资源做出贡献。 这是链接 = https://github.com/anshaneja5/mldl.study 我计划在未来添加 python 及其库的资源、genAI、强化学习和其他人工智能领域的适当路线图，以及仅针对英语受众的路线图。如果你们可以来为资源做出贡献，让其他人可以从中受益，我会非常高兴。如果有人能帮助我制定仅限英语的路线图，我也会很高兴。请大家帮助我使其成为学习 ML 和 DL 的最佳资源之一。  我非常感谢你们所有人的支持。 非常感谢你们！ https://preview.redd.it/ditvxokmul1e1.png?width=1581&amp;format=png&amp;auto=webp&amp;s=7a7d95ca75d60200035bcac80c7511108d6cf12b    提交人    /u/Grouchy-Breakfast-20   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtypeb/p_2000_users_in_last_30_days_i_am_soo_soo_happy/</guid>
      <pubDate>Mon, 18 Nov 2024 06:34:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 可行性检查：使用潜在向量生成机器人姿势以进行强化学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtwig3/p_feasibility_check_robot_pose_to_scene/</link>
      <description><![CDATA[我正在探索一个想法，想得到一些关于其可行性和潜在陷阱的反馈。 披露：我对 CNN 和其他东西的了解有点模糊，所以请耐心等待。 概念： 我有一个 2m x 2m 的小型平台，机器人可以在上面操作。上面是一个固定的摄像头，我使用叠加在摄像头反馈上的笛卡尔坐标系来估计机器人的精确 x, y 位置和方向 a。 我想使用神经网络构建一个模拟器，输入机器人的姿势 (x, y, a) 并输出与真实世界摄像头视图相匹配的生成场景。 模型设计理念： 初步工作/概念验证： 我计划从使用合成数据的简化场景开始。这涉及具有白色背景和黑点（代表机器人）的图像，其中有一个小箭头指示方向。这是为了让我快速测试该方法的基本可行性。 未来目标（RL）： 最终目标是使用学习到的潜在向量作为紧凑状态表示，以训练 RL 代理来控制机器人。 问题：  可行性：这个想法在当前的 CNN 技术下是否普遍可行？ 注意事项：如果可行，在开发过程中我应该牢记哪些关键注意事项，特别是关于推广和扩展到更复杂的现实场景？例如，如果我想在生成的场景中包含随机放置的障碍物（比如半径为 5 厘米），我是否需要为现实世界中每个不同的障碍物配置训练一个单独的生成器？ （那将是一场噩梦！）或者有更优雅的方法来处理这个问题？  生成的场景不需要是真实世界摄像机视图的像素完美复制品。重要的是模拟场景准确（尽可能）反映机器人在现实世界中的位置和方向（x，y，a）。    提交人    /u/Decent_Eye_659   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtwig3/p_feasibility_check_robot_pose_to_scene/</guid>
      <pubDate>Mon, 18 Nov 2024 04:20:26 GMT</pubDate>
    </item>
    <item>
      <title>[P] AnyModal：用于多模态法学硕士 (LLM) 的 Python 框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtw77c/p_anymodal_a_python_framework_for_multimodal_llms/</link>
      <description><![CDATA[AnyModal 是一个模块化且可扩展的框架，用于将各种输入模式（例如图像、音频）集成到大型语言模型 (LLM) 中。它使用针对各种模式的预训练模型实现无缝标记、编码和语言生成。我创建 AnyModal 是为了解决现有资源中用于设计视觉语言模型 (VLM) 或其他多模式 LLM 的空白。虽然有用于特定任务的出色工具，但没有一个可以轻松将不同输入类型与 LLM 相结合的统一框架。 AnyModal 旨在通过简化添加新输入处理器和标记器的过程，同时利用预训练语言模型的优势来填补这一空白。 示例用法 from transformers import ViTImageProcessor, ViTForImageClassification from anymodal import MultiModalModel from vision import VisionEncoder, Projector # 加载视觉处理器和模型 processing = ViTImageProcessor.from_pretrained(&#39;google/vit-base-patch16-224&#39;) vision_model = ViTForImageClassification.from_pretrained(&#39;google/vit-base-patch16-224&#39;) hidden_​​size = vision_model.config.hidden_​​size # 初始化视觉编码器和投影仪 vision_encoder = VisionEncoder(vision_model) vision_tokenizer = Projector(in_features=hidden_​​size, out_features=768) # 加载 LLM 组件 from transformers import AutoTokenizer, AutoModelForCausalLM llm_tokenizer = AutoTokenizer.from_pretrained(&quot;gpt2&quot;) llm_model = AutoModelForCausalLM.from_pretrained(&quot;gpt2&quot;) # 初始化 AnyModal multimodal_model = MultiModalModel( input_processor=None, input_encoder=vision_encoder, input_tokenizer=vision_tokenizer, language_tokenizer=llm_tokenizer, language_model=llm_model, input_start_token=&#39;&lt;|imstart|&gt;&#39;, input_end_token=&#39;&lt;|imend|&gt;&#39;, prompt_text=&quot;给定图像的解释是：&quot; )  AnyModal 提供了一个统一的框架，用于将来自不同模态的输入与 LLM 相结合。它抽象了许多样板，让用户可以专注于他们的特定任务，而不必担心低级集成。与现有工具（如 Hugging Face 的转换器或特定于任务的 VLM，如 CLIP）不同，AnyModal 为任意模态组合提供了灵活的框架。它非常适合小众多模态任务或需要自定义数据类型的实验。 当前演示  LaTeX OCR 胸部 X 光字幕（进行中） 图像字幕 视觉问答（计划中） 音频字幕（计划中）  该项目仍在进行中，我很乐意收到社区的反馈或贡献。无论您是想添加新功能、修复错误还是仅仅尝试一下，我们都欢迎您提供任何意见。 GitHub repo：https://github.com/ritabratamaiti/AnyModal 请告诉我您的想法或任何疑问。    提交人    /u/Alternative_Detail31   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtw77c/p_anymodal_a_python_framework_for_multimodal_llms/</guid>
      <pubDate>Mon, 18 Nov 2024 04:02:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 还在研究论文中迷失？Ribbit Ribbit 进军 Web 和 Android！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtvmpn/p_still_drowning_in_research_papers_ribbit_ribbit/</link>
      <description><![CDATA[      嘿朋友们！上个月，我们分享了 Ribbit Ribbit，这是我们在 iOS 上的小型研究论文发现工具，哇哦，非常感谢您的喜爱！在过去的几周里，我们一直在努力将它带到更多地方，现在我们很高兴与大家分享：  完整网站 https://ribbitribbit.co 现已上线！它具有应用程序的所有功能。您可以在大屏幕上浏览论文以获得额外的清晰度，也可以将其放在手机上随时随地浏览 - 以您的方式进行研究！ Android 即将推出！它可通过 Google Play 测试获得。 Google 需要足够的测试人员才能上线，因此，如果您愿意尽早试用，请加入我们的测试人员小组：https://ribbitribbit.co/request?testandroid=true。您绝对会成为我们的英雄！  Ribbit Ribbit 可帮助您找到个性化的论文推荐，将其缩小为推文大小的摘要，甚至像播客一样读给您听。我们只是想让整个研究过程变得更有趣。我们希望您能查看一下。您的支持对我们意义重大！ https://preview.redd.it/hyf9e6rmxk1e1.png?width=1492&amp;format=png&amp;auto=webp&amp;s=9a4deb6f3b70c9cf79d3441846ee03d6d6b93d22    提交人    /u/haoyuan8   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtvmpn/p_still_drowning_in_research_papers_ribbit_ribbit/</guid>
      <pubDate>Mon, 18 Nov 2024 03:31:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对机器学习工程职位的期望</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtt099/d_expectation_from_machine_learning_engineering/</link>
      <description><![CDATA[大家好， 我在这里看到了很多关于 ML 职业和实习或工作机会的帖子，有两件事经常出现  建立强大的研究作品集，并在 NeurIPS、ICLR 和 ICML 等会议上发表文章，这些会议似乎更侧重于获得研究科学家的职位。 对机器学习工程师 (MLE) 职位的需求不断增长，显然比研究科学家职位更受欢迎。  我很好奇这两个角色之间的区别，以及什么样的作品集对于获得 MLE 职位来说是理想的。我知道拥有硕士学位通常是首选，但令人印象深刻的出版记录对 MLE 职位来说是必要的吗？或者这不是什么大问题？ 你怎么看？   由    /u/ziggyboom30  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtt099/d_expectation_from_machine_learning_engineering/</guid>
      <pubDate>Mon, 18 Nov 2024 01:14:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] PCA 与自动编码器在降维方面的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtng8q/d_pca_vs_autoencoders_for_dimensionality_reduction/</link>
      <description><![CDATA[标题总结了一切。我正在处理一些匿名时间序列数据，最初，我构建了一个自动编码器，以便在训练后用回归头替换解码器头。 至于预处理步骤，我通常只减去特征的平均值并除以它们的标准差，虽然我早就听说做“数据去相关”很有帮助，所以我决定最终学习 PCA。 我的问题如下：  如果 PCA 用于查找数据集的主要潜在特征，那么使用自动编码器有什么意义吗？（特别是如果某些特征之间存在高度相关性） 如果仍然有必要使用自动编码器，是否应该首先在数据集上使用 PCA 来去相关数据，或者这只是多余的，或者也许不使用它的另一个原因是它会擦除一些信息？ （尽管它是一种可逆变换，所以我看不出信息会如何丢失） PCA 作为预处理步骤是否有利于树构建算法？我没看到太多关于它的讨论，但对我来说，直观地看，在主成分轴上设置决策节点会带来更好的结果。     提交人    /u/DisciplinedPenguin   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtng8q/d_pca_vs_autoencoders_for_dimensionality_reduction/</guid>
      <pubDate>Sun, 17 Nov 2024 20:56:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 LLM 水印永远行不通</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtkp1d/d_why_llm_watermarking_will_never_work/</link>
      <description><![CDATA[        提交人    /u/bubble_boi   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtkp1d/d_why_llm_watermarking_will_never_work/</guid>
      <pubDate>Sun, 17 Nov 2024 18:55:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一支高效的应用机器学习团队是如何构成的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtke1b/d_how_an_efficient_applied_ml_team_is_structured/</link>
      <description><![CDATA[大家好， 我对你们关于大型（更大）ML 团队的结构的经验很感兴趣，这些团队结构对于使用 ML 进行构建的公司（在多个领域使用 ML 的公司，它们涵盖 CV、NLP 等）效果如何？我尝试搜索它，但关于高效团队结构的信息并不多。虽然结构可以由公司文化定义，但我相信你已经看到了如何让这种结构运作良好的模式。 （我认为一个大团队至少有 80 人，包括 PO/PM）。 最基本的（也许是最好的？）是当领域被划分（CV、NLP 等）时，每个领域都有一个负责人和多个高级、中级和初级。然后除了 ML 工程师之外，还有一个单独的部门负责产品化（创建 rest API 等），其中包括 devops 和 SWE。     由    /u/gabegabe6 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtke1b/d_how_an_efficient_applied_ml_team_is_structured/</guid>
      <pubDate>Sun, 17 Nov 2024 18:41:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] treemind：简化梯度提升模型分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtjkci/r_treemind_simplifying_gradient_boosting_model/</link>
      <description><![CDATA[treemind 是一个功能强大的 Python 库，旨在分析 xgboost、lightgbm 和 catboost 等梯度提升模型。它可以帮助您揭示特征及其相互作用如何影响特定间隔内的预测，从而提供快速、直观的见解。 主要功能：  功能和交互分析：了解最多 n 个特征的特征贡献和复杂交互。 高级可视化：用户友好的图表来解释模型决策。 高性能：使用 Cython 进行了优化，即使在大型数据集上也能实现闪电般的快速执行。 轻松集成：与流行的回归和二元分类框架无缝协作。  算法和性能：  算法：专注于分析基于树的模型中的特征贡献和交互，以获得有意义的基于区间的见解。 阅读有关该算法的更多信息 性能：该库的性能已经在合成数据集上进行了测试，其中它与 SHAP 进行了准确性和效率基准测试。 查看性能实验  快速入门： bash pip install tr​​eemind  查看完整文档以获取示例、可视化和 API 详细信息。 GitHub Repo | 文档 注意： 虽然该算法在实践中产生了理想的结果，但目前缺乏正式的数学证明。我们非常感谢您的反馈和想法，以帮助进一步改进和验证该方法！    提交人    /u/zedeleyici3401   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtjkci/r_treemind_simplifying_gradient_boosting_model/</guid>
      <pubDate>Sun, 17 Nov 2024 18:05:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 论文的质量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtjhge/d_quality_of_iclr_papers/</link>
      <description><![CDATA[我浏览了 ICLR 上一些与我感兴趣的领域相关的中等到高分论文，我发现它们进展缓慢，而且有点惊讶，对于一个主要的子领域来说，像这样的顶级会议，论文质量相当差。自从 llms 出现以来，我觉得论文的质量和原创性（当然不是全部）有所下降。只有我一个人有这种感觉吗？    提交人    /u/Cool_Abbreviations_9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtjhge/d_quality_of_iclr_papers/</guid>
      <pubDate>Sun, 17 Nov 2024 18:02:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Nov 2024 16:00:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用旧向量而不是新向量来定义词汇的小型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtenw8/d_small_language_models_defining_vocabulary_using/</link>
      <description><![CDATA[我一直在思考语言模型为何如此庞大，以及它们如何变得更小。我想每个人的大脑都不可能容纳人类的全部知识。我相信人类大致拥有一个类似于单词 X 其他单词的概率矩阵，但不是每个单词 X 每个单词。 我突然想到，我们经常使用我们知道的其他现有单词来定义不常用的单词（低频率、不常用的单词）。我们能否拥有一个语言模型，该模型仅使用频率最高的单词的向量，而“不常用的单词”没有自己的向量，而是引用现有向量？这可以大大减少单词 X 单词矩阵，因为常用单词由语言的一个小得多的子集组成。也许这样的模型可以在针对特定主题的文本进行重新训练时，动态地将参考词移入和移出主向量。 我知道我从来没有过原创的想法，有没有其他类似的项目？    提交人    /u/meteoraln   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtenw8/d_small_language_models_defining_vocabulary_using/</guid>
      <pubDate>Sun, 17 Nov 2024 14:26:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>