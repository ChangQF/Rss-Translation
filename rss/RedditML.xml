<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Tue, 27 Aug 2024 18:20:21 GMT</lastBuildDate>
    <item>
      <title>[P] supertree——决策树的交互式可视化（sklearn、xgboost、lightgbm）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f2ku3i/p_supertree_interactive_visualization_of_decision/</link>
      <description><![CDATA[大家好， 我想与大家分享一个用于交互式决策树可视化的新 Python 包。它被称为 supertree。它将决策树可视化为交互式图形，您可以在其中折叠和展开选定节点。您可以缩放和平移大树。它适用于 Scikit-learn、Xgboost 和 LightGBM。 该包适用于笔记本：Jupyter Lab、Jupyter Notebook、Google Colab。您还可以在 Python 脚本中使用它并将输出树保存为 HTML。 该包可在 pip 上使用：pip install supertree。 您可以在 GitHub 上找到代码示例：https://github.com/mljar/supertree 祝您探索愉快！   由    /u/pp314159  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f2ku3i/p_supertree_interactive_visualization_of_decision/</guid>
      <pubDate>Tue, 27 Aug 2024 16:05:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当掩码太小时，图像分割会收敛到全零</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f2gevm/d_image_segmentation_converges_to_all_zeros_when/</link>
      <description><![CDATA[      所以我最初的问题是乳腺癌图像分割。我正在使用此处实现的 unet。我面临的问题是许多掩模非常小，有时甚至不存在（原始问题是 3D，但我正在处理 2d 切片，因此许多切片不包含任何恶性像素）。这导致模型收敛到所有健康细胞的局部最小值。 由于我无法按原样解决问题，因此我创建了一个虚拟数据集（一些数据，其中图像是一个圆圈，掩模是一个半径为一半的圆圈）。我想看看我是否可以解决一个更简单的问题并逐步解决。对于较大的掩码，该模型可以正常工作。 但即使对于这个非常简单的问题，当我将最大半径限制为 20 像素（原始大小为 256x256）时，模型也会找到全零的局部最小值。 有哪些技术可以对抗这种局部最小值？ 作为参考，以下是数据集包含各种大小时的结果 https://preview.redd.it/giy8hdr0j7ld1.png?width=806&amp;format=png&amp;auto=webp&amp;s=dbf8975c9142b9a4d63645da34b4bbc2946d90c6 这里只有小圆圈 https://preview.redd.it/wssqta53j7ld1.png?width=805&amp;format=png&amp;auto=webp&amp;s=f29f75415e72377a2871e80a39dd3ad318f41857 请注意，第一个数据集包含小圆圈和大圆圈。例如，样本 2 和 3 非常小，但分类正确。    提交人    /u/ripototo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f2gevm/d_image_segmentation_converges_to_all_zeros_when/</guid>
      <pubDate>Tue, 27 Aug 2024 12:58:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对比学习可以应用于非视觉问题吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f2dxrh/d_can_contrastive_learning_be_applied_to_non/</link>
      <description><![CDATA[我目前正在使用去噪自动编码器将我的 10,000 多个特征集减少到大约 300 个维度，并将这些嵌入用于分类问题。 我可以以类似的方式使用对比学习，以更好地在更少的维度上表示稀疏特征集吗？    提交人    /u/prog_hi   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f2dxrh/d_can_contrastive_learning_be_applied_to_non/</guid>
      <pubDate>Tue, 27 Aug 2024 10:45:36 GMT</pubDate>
    </item>
    <item>
      <title>[D]探索边缘计算/联邦学习在 GPT/LLM 持续训练中的潜力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f243mh/dexploring_the_potential_of_edge/</link>
      <description><![CDATA[大家好， 我目前正在深入研究联邦学习和边缘计算，我一直在思考一个想法，我很想听听你们的想法。具体来说，我很好奇使用边缘计算或联邦学习来使 GPT 或大型语言模型 (LLM) 持续可训练是否有任何优势。 如果有潜在的好处，那么聚合过程在全局模型中如何工作？另一方面，如果这种方法可能不是最好的，我真的很感激任何关于为什么会这样或关于在联邦学习中应该关注什么的建议。 我特别想确定这些领域中需要更多关注的研究差距或具体问题。任何指导或想法都将不胜感激！    提交人    /u/StopFrequent542   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f243mh/dexploring_the_potential_of_edge/</guid>
      <pubDate>Tue, 27 Aug 2024 00:42:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您认为哪种旧的学习算法/范式将会很快复兴？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f22foq/d_what_do_you_think_is_an_old_learning/</link>
      <description><![CDATA[即使在 Le-Net 时代，ANN 和反向传播也几乎已经消亡。然而，当他们在 AlexNet 中对其进行扩展时，它获得了更多的支持，现在，我们看到了它的潜力。 在深度学习“复兴”之前，有些人已经认为，如果他们找到如何训练深度学习的方法，深度学习就会成功。 我希望我们讨论过去可能“难以理解/扩展/训练/实施”的其他算法，你认为只要人们认真考虑，这些算法就会成功。    提交人    /u/MysticalDragoneer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f22foq/d_what_do_you_think_is_an_old_learning/</guid>
      <pubDate>Mon, 26 Aug 2024 23:23:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 流匹配和规范化流有什么共同点？流匹配是可逆的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1vizv/d_what_is_common_between_flow_matching_and/</link>
      <description><![CDATA[流匹配是否像标准化流一样可逆？我可以做 G（生成器）逆并使用相同的参数从给定的 x 中取回噪声 z 吗？它介于扩散和 NF 之间吗？我相信这个想法来自连续 NF，并且该方法本身概括了扩散。     提交人    /u/Alternative-Talk1945   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1vizv/d_what_is_common_between_flow_matching_and/</guid>
      <pubDate>Mon, 26 Aug 2024 18:31:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于 Pytorch 中 informers 实现的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1t264/p_question_about_the_implementation_of_informers/</link>
      <description><![CDATA[大家好， 我正在尝试在 Pytorch 中从头开始实现一个通知器，无需库。并将其应用于时间序列预测。为此，我从这个库中复制了代码 https://github.com/AIStream-Peelout/flow-forecast/blob/master/flood_forecast/transformer_xl/informer.py 我已经能够运行模型，我在笔记本中有一个有效的训练循环。但是，我不完全明白我应该给模型的前向方法提供什么。 前向方法如下： forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec) x_enc 和 x_mark_enc 很简单，它们分别是一批具有时间序列值的示例和一个具有日期信息的张量。例如，如果批量大小为 32，我使用长度为 24 的时间序列，并且我有 6 个时间序列，那么 x_enc 的尺寸为 32 x 24 x 6，x_mark_enc 的尺寸为 32 x 24x 4，4 为 [月、日、时、分] 整数。 但是我应该为 x_dec、x_mark_dec 提供什么呢？ 现在在我的训练循环中，我只是说 x_dec=x_enc 和 x_mark_dec=x_mark_enc，但这可能是不正确的。但是我的模型能够学习。 为了进一步解释我的批次的结构，x_enc 尺寸为 32x24x6，其中 32 是我的批次大小，24 是我的时间序列的长度（以小时为单位），6 是因为我正在进行多元预测，所以我使用 6 个不同的时间序列进行预测。 谢谢！    提交人    /u/Legal_Ad_1096   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1t264/p_question_about_the_implementation_of_informers/</guid>
      <pubDate>Mon, 26 Aug 2024 16:51:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 类似 SAM2 的追踪器，但速度更快</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1su5r/d_trackers_like_sam2_but_faster/</link>
      <description><![CDATA[对于所有已经尝试或熟悉 Segment Anything Model 2 (SAM2) 的人。如您所知，它跟踪物体的能力确实很棒。  我设法结合了 RT-DETR 和 SAM2，我使用 RT-DETR 进行检测，使用 SAM2 进行跟踪，结果确实令人印象深刻。我一直用它来跟踪车辆，即使在低质量的监控视频中，这种组合对于小型车辆也非常有效。我在一些交通视频中定性地比较了这种组合的结果以及 RT-DETR + DeepSort，它要好得多。  SAM2 最大的问题是推理速度慢，这使其不适合实时应用。 您知道任何与 SAM2 一样好或更好的跟踪模型吗？    提交人    /u/henistein   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1su5r/d_trackers_like_sam2_but_faster/</guid>
      <pubDate>Mon, 26 Aug 2024 16:42:51 GMT</pubDate>
    </item>
    <item>
      <title>MNIST 的少参数模型 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1pmke/few_parameter_models_for_mnist_d/</link>
      <description><![CDATA[我正在寻找人们尝试使用尽可能少的权重进行数字识别的论文。  我发现很多研究都试图用几千个参数实现超过 99% 的准确率，但是如果你将权重降至几百甚至少于 100 个会怎样？你能达到的最大准确率是多少？ 无需付出太多努力并使用 &lt;100 个参数，我可以轻松获得 ~50% 的准确率。那么肯定有人比我聪明尝试过这个并且做得更好？    提交人    /u/Peraltinguer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1pmke/few_parameter_models_for_mnist_d/</guid>
      <pubDate>Mon, 26 Aug 2024 14:30:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我发表了我的第一篇出版物！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1ove1/r_i_got_my_first_publication/</link>
      <description><![CDATA[大约一年前，我儿时的一个朋友是一名医生，他突然打电话给我，问我是否有兴趣实现他关于使用 ML 筛选和选择肝癌患者进行移植的想法，我说为什么不呢。 上周末，我收到了我们的期刊出版物00558-0/abstract)的电子邮件，我想分享这个消息：D 附注 - 任何有兴趣阅读该论文的人，请随时 DM    提交人    /u/theahmedmustafa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1ove1/r_i_got_my_first_publication/</guid>
      <pubDate>Mon, 26 Aug 2024 13:58:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] DeepSeek-Prover-V1.5：利用证明助手反馈进行强化学习和蒙特卡洛树搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1nld3/r_deepseekproverv15_harnessing_proof_assistant/</link>
      <description><![CDATA[      论文： https://arxiv.org/pdf/2408.08152 摘要：  我们引入了 DeepSeek-Prover-V1.5，这是一个为 Lean 4 中的定理证明而设计的开源语言模型，它通过优化训练和推理过程增强了 DeepSeek-Prover-V1。该模型在 DeepSeekMath-Base 上进行了预训练，专门用于形式数学语言，然后使用源自 DeepSeek-Prover-V1 的增强形式定理证明数据集进行监督微调。通过从证明助手反馈 (RLPAF) 进行强化学习实现进一步细化。除了 DeepSeek-Prover-V1 的单次整体证明生成方法之外，我们还提出了 RMaxTS，这是蒙特卡洛树搜索的一种变体，它采用内在奖励驱动的探索策略来生成多样化的证明路径。DeepSeek-Prover-V1.5 比 DeepSeek-Prover-V1 有显著的改进，在高中级 miniF2F 基准测试集（63.5%）和本科级 ProofNet 基准测试集（25.3%）上取得了新的最先进结果。  视觉亮点： https://preview.redd.it/z386xeiba0ld1.png?width=829&amp;format=png&amp;auto=webp&amp;s=c2f2b814c25ca87642ed62980d5148898894cc00 https://preview.redd.it/3nrvvx0ea0ld1.png?width=1113&amp;format=png&amp;auto=webp&amp;s=9487988841cad2f0f050f60e2e7724b313bd59da https://preview.redd.it/skow3jpga0ld1.png?width=831&amp;format=png&amp;auto=webp&amp;s=a0718db4cd616c7bf360164fc0df098e7c83a3d9 https://preview.redd.it/686t9t7ja0ld1.png?width=979&amp;format=png&amp;auto=webp&amp;s=8c7ea703f971438b1202684818029fe98dda92cd    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1nld3/r_deepseekproverv15_harnessing_proof_assistant/</guid>
      <pubDate>Mon, 26 Aug 2024 12:59:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在多个数据集上训练时，如何处理生产中时间序列分类的规范化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1natx/d_how_to_handle_normalization_for_timeseries/</link>
      <description><![CDATA[我目前正在研究一个时间序列分类模型 (CNN-LSTM)，该模型在多个数据集上进行了训练，每个数据集都有自己独特的值范围。在训练过程中，我使用最小-最大缩放分别对每个数据集进行了规范化，这对模型性能很有效。现在，我正在将模型转移到生产中，并面临规范化的挑战。 情况如下：  该模型在数十个数据集上进行了训练，每个数据集都使用自己的最小值和最大值单独进行了规范化。 在生产中，我需要该模型能够很好地概括我每天收到的新数据集或数据流。  我的问题：  我应该如何在生产中处理规范化？我将每天获得新数据，一些数据集代表来自训练的相同客户，但大多数将是全新的数据集。  我正在考虑的一种方法是为每个数据集从前 12 个月中获取 Min-Max 并每天应用于新数据。  这会是训练期间未见过的数据集的问题吗？   有人处理过类似的情况吗？您如何确保规范化的一致性，同时保持模型性能的稳健性？     提交人    /u/SirCarpetOfTheWar   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1natx/d_how_to_handle_normalization_for_timeseries/</guid>
      <pubDate>Mon, 26 Aug 2024 12:45:27 GMT</pubDate>
    </item>
    <item>
      <title>大学研究项目：需要参与者！[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1kq4m/university_research_project_participants_needed_p/</link>
      <description><![CDATA[大家好！ 我目前正在为我的大学进行研究，我正在寻找任何潜在的受访者。我正在研究软件开发人员对使用受版权保护的材料来培训基于文本的 LLM 的看法。 如果您参与过任何类型的 LLM 的开发，或者对任何类型的 LLM 的开发有所了解，我将非常感激有机会向您提出几个问题。 感谢您阅读我的帖子！如果您有兴趣，请发表评论或给我发消息，以便我们继续通信。    提交人    /u/ErmBlegh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1kq4m/university_research_project_participants_needed_p/</guid>
      <pubDate>Mon, 26 Aug 2024 10:19:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0ybbs/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0ybbs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Aug 2024 15:00:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>