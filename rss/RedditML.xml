<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 03 Feb 2024 21:10:30 GMT</lastBuildDate>
    <item>
      <title>[R] 人们还相信LLM的新兴能力吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ai5uqx/r_do_people_still_believe_in_llm_emergent/</link>
      <description><![CDATA[自从[新兴的LLM能力是海市蜃楼吗？](https://arxiv.org/pdf/2304.15004.pdf），人们似乎对涌现非常安静。但是大的[新兴能力](https://openreview.net/pdf?id=yzkSU5zdwD)论文有这一段（第 7 页）： &gt;考虑用于衡量新兴能力的评估指标也很重要（BIG-Bench，2022）。例如，使用精确的字符串匹配作为长序列目标的评估指标可能会将复合增量改进伪装成出现。类似的逻辑可能适用于多步骤或算术推理问题，其中模型仅根据是否正确获得多步骤问题的最终答案来评分，而不会给予部分正确的解决方案任何信用。然而，最终答案准确性的跳跃并不能解释为什么中间步骤的质量突然出现在随机之上，并且使用不给予部分信用的评估指标充其量是一个不完整的解释，因为在许多分类任务中仍然观察到涌现的能力（例如，图 2D-H 中的任务）。 人们怎么想？涌现是“真实的”吗？还是实质性的？   由   提交/u/uwashingtongold  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ai5uqx/r_do_people_still_believe_in_llm_emergent/</guid>
      <pubDate>Sat, 03 Feb 2024 20:50:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 变分自动编码器和参数化人脸生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ai4wnn/p_variational_auto_encoder_and_parametric_face/</link>
      <description><![CDATA[大家好，我最近一直在尝试生成式人工智能，特别是尝试实现变分自动编码器（VAE）。 为了进行训练，我使用了灰度面部数据集。损失函数似乎收敛得很好。然而，当我分离解码器并尝试改变输入特征值时，我很难生成任何面孔，更不用说在潜在空间中的不同点之间进行插值了。 我意识到输入随机值会形成一个法线分布没有按预期有效地从潜在空间中采样。 我在这里遗漏了什么吗？如何通过改变特征图中的参数来实现生成人脸？   由   提交 /u/AcquaFisc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ai4wnn/p_variational_auto_encoder_and_parametric_face/</guid>
      <pubDate>Sat, 03 Feb 2024 20:08:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] TimesFM：基于 1000 亿个真实世界数据点进行预训练的基础预测模型，在不同领域提供前所未有的零样本性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahzmdc/r_timesfm_a_foundational_forecasting_model/</link>
      <description><![CDATA[       由   提交 /u/BlupHox   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahzmdc/r_timesfm_a_foundational_forecasting_model/</guid>
      <pubDate>Sat, 03 Feb 2024 16:15:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用局部水印主动检测语音克隆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahzdr0/r_proactive_detection_of_voice_cloning_with/</link>
      <description><![CDATA[人工智能语音合成的快速进步带来了令人难以置信的虚假人类语音，引发了人们对语音克隆和深度伪造音频的担忧。 &lt;随着人工智能合成的改进，被动分析作为检测虚假音频的传统方法面临着挑战。这些方法往往依赖于工件，但这些方法是特定于模型的。而且模型质量不断提高，伪影数量也减少了。 Meta 和 Inria 的研究人员开发了 AudioSeal，这是一种新技术，可以在人工智能生成的语音上添加难以察觉的水印以供检测。  AudioSeal 专注于定位音频剪辑中的合成语音。它的两个组件（生成器和检测器）协同工作，提供样本级精度和稳健的检测。 AudioSeal 的创新包括样本级精度、稳健的感知损失、音频失真恢复能力和高效检测，使得速度非常快。 联合训练生成器和检测器可以最大限度地减少感知差异并最大限度地提高准确性，即使存在屏蔽或扭曲的区域也是如此。我发现这是本文的关键见解。 AudioSeal 在通用性、样本级别的本地化、针对音频失真的鲁棒性、效率和模型身份消息的容量方面表现出色。它的检测速度大约比 WavMark 快两个数量级，生成水印的速度快 14 倍。 虽然很有希望，但应考虑道德问题和保密性需求，并且可能需要标准化才能得到更广泛的采用。&lt; /p&gt; TLDR：AudioSeal 是一种检测假音频的新颖解决方案，具有本地化且强大的检测功能。它也比 WavMark 快得多。 论文这里。存储库位于此处。完整摘要位于此处。 &lt; /div&gt;  由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/1ahzdr0/r_proactive_detection_of_voice_cloning_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahzdr0/r_proactive_detection_of_voice_cloning_with/</guid>
      <pubDate>Sat, 03 Feb 2024 16:04:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求建议：从工业界转向 NLP 研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahzdj7/d_seeking_advice_transitioning_from_industry_to/</link>
      <description><![CDATA[嘿各位 Reddit 用户， 简单介绍一下我的背景 - 我目前在行业内的数据分析领域工作，并且我的日常任务与自然语言处理（NLP）没有直接关系。然而，我对 NLP 充满热情，并渴望攻读博士学位。在该领域。我渴望获得研究经验。我拥有计算机科学学士和硕士学位。 由于我不隶属于大学，因此我正在寻求有关如何应对这一转变的指导。有人可以分享关于如何在学术环境之外有效参与 NLP 研究的见解吗？我可以采取哪些实际步骤来为该领域做出贡献、建立研究组合、增加攻读 NLP 博士学位以及让我的工作得到顶级会议和期刊认可的机会？ 个人建议经验或推荐资源将不胜感激。预先感谢您！   由   提交/u/Puzzleheaded_Big_242   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahzdj7/d_seeking_advice_transitioning_from_industry_to/</guid>
      <pubDate>Sat, 03 Feb 2024 16:04:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 随机森林分类器测试错误帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahysx5/p_randomforest_classifier_testing_error_help/</link>
      <description><![CDATA[我是一名初学者，正在学习 ML，正在运行 ML 模型来使用随机森林分类器预测异常，作为输入，我输入了大约 21000 列从我的原始数据中提取的特征，它选择 15 个或至少给我一个选择的 15 个特征的输出。现在，当我尝试测试模型并从 21000 列的提取特征中随机选择 100 个数据行进行测试，并通过计算 15 个选定的特征直接在模型上运行时，我收到了模型预期的错误16 个功能。我在这里做错了什么吗？测试我的模型的程序应该是什么？如有任何建议，我们将不胜感激，任何文献或 YT 视频的链接也将非常有帮助。谢谢。    由   提交 /u/Good-Boysenberry2914    reddit.com/r/MachineLearning/comments/1ahysx5/p_randomforest_classifier_testing_error_help/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahysx5/p_randomforest_classifier_testing_error_help/</guid>
      <pubDate>Sat, 03 Feb 2024 15:38:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 ICML 2024 提交时间表的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahxe7t/d_questions_on_icml_2024_submission_timeline/</link>
      <description><![CDATA[大家好！ 由于这是我第一次向 ICML 提交：  不知道什么时候会发布评论吗？在neurips和iclr中，论文征集中有信息，但我在今年的icml截止日期内找不到…… 我们给作者回复多少时间？和iclr一样长吗？ 我们可以上传新草稿还是只能通过文字回复？ 我们可以在审稿期间与审稿人互动吗？反驳还是只是作者的单向回应？  谢谢！   由   提交/u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahxe7t/d_questions_on_icml_2024_submission_timeline/</guid>
      <pubDate>Sat, 03 Feb 2024 14:32:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2024 年 1 月研究论文：模型合并、专家混合、迈向小型法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahwint/p_research_papers_in_jan_2024_model_merging/</link>
      <description><![CDATA[       由   提交/u/seraschka  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahwint/p_research_papers_in_jan_2024_model_merging/</guid>
      <pubDate>Sat, 03 Feb 2024 13:49:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 康威的生命游戏作为神经网络的实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahqs0n/p_conways_game_of_life_implement_as_a_neural/</link>
      <description><![CDATA[       由   提交/u/liMrMil  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahqs0n/p_conways_game_of_life_implement_as_a_neural/</guid>
      <pubDate>Sat, 03 Feb 2024 07:41:40 GMT</pubDate>
    </item>
    <item>
      <title>关于吴恩达课程 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahq79t/about_andrew_ng_course_d/</link>
      <description><![CDATA[我最近开始从基础知识开始学习机器学习领域。我在 reddit 上看到许多旧评论，指出 Coursera 上的 Andrew ng 课程是最好的课程之一，而且“它也是免费的”。并发现他改变了这一点。然后在 YouTube 上找到了 Andrew ng 在 ml https://youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU 那么他当前的 Coursera 课程和 Andrew ng 在 ML 上的旧播放列表有什么区别吗？  如果有人有他的 Coursera 课程的任何索引或任何保存的文件夹，请分享。这对我自己和所有其他初学者都有帮助......🏴‍☠️   由   提交 /u/Surferboiy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahq79t/about_andrew_ng_course_d/</guid>
      <pubDate>Sat, 03 Feb 2024 07:02:52 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 梯度下降的最佳矩阵乘法算法。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahoo9q/project_the_best_matrix_multiplication_algorithm/</link>
      <description><![CDATA[我正在尝试用 0 个依赖项在 Rust 中实现神经网络。我知道施特拉森只擅长高排名，并且错误增加（来源是极客的极客，所以可能是可疑的）。不管怎样，我想知道我应该使用什么算法来进行矩阵乘法，以及它是否会产生很大的差异。   由   提交 /u/ANARCHY14312   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahoo9q/project_the_best_matrix_multiplication_algorithm/</guid>
      <pubDate>Sat, 03 Feb 2024 05:29:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在这里没有看到足够多的人赞扬 dinov2 ！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahkxjh/d_i_dont_see_enough_people_praising_dinov2_here/</link>
      <description><![CDATA[大家好！ 我只是想写一条简短的消息，让这里的每个人都知道 dinov2 是一个多么强大的工具对我来说！我已经对其进行了微调，可以对图像进行多种不同目的的分类，并且每次类只有 20-50 张图像，它总是很成功。根据我使用它的用例：对 3D/照片图像进行分类，带水印/无水印图像、模糊/非模糊图像、面部识别（识别 dlib 对齐的面部是否特定属于某个人）、艺术家风格、验证图像中特定对象上方的分割是否正确等等。 .. 在 dinov2 的整个系列中，我从未使用过比小型模型更大的东西（尽管我使用 448x448 图像），因此它无需使用太多 VRAM 即可工作，并且可以批量处理 100 个图像一次！ 最近我什至尝试在暹罗架构中对 dinov2 进行微调，只用一个新的头部来获取两个图像的特征，这样它就可以将两个图像放在一起比较（不用说太多，我想知道是否两者都图像遵循共同的结构）并且它工作得很好。 我还使用它来将图像的特征提供给稳定扩散，并且它也工作得很好（使用 IP 适配器架构）。 &gt; 我唯一没能做到的就是使用它进行分割，但我认为这是因为我的数据集和/或实现，所以如果你们中有人做到了，我很想与你们交谈交流良好实践！ 如果您希望脚本对其进行微调/推理以进行分类，我很乐意分享它们。 您呢？你用 dinov2 吗？如果是，为什么以及如何？您对此有何体验？   由   提交 /u/Antique-Bus-7787   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahkxjh/d_i_dont_see_enough_people_praising_dinov2_here/</guid>
      <pubDate>Sat, 03 Feb 2024 02:08:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] Graph-Mamba：利用选择性状态空间进行长范围图序列建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahgxsh/d_graphmamba_towards_longrange_graph_sequence/</link>
      <description><![CDATA[ 由   提交/u/314kabinet  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahgxsh/d_graphmamba_towards_longrange_graph_sequence/</guid>
      <pubDate>Fri, 02 Feb 2024 23:00:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我正在为此子创建一个审核分类器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahag9e/p_im_creating_a_moderation_classifier_for_this_sub/</link>
      <description><![CDATA[每次有人抱怨这个子站的帖子质量低下时，总会有人指出讽刺的是，如果有人只训练一个分类器，这个问题就很容易解决过滤掉应该转到 r/singularity 或 r/learnmachinelearning，并且这个子模块中的人绝对应该有能力做到这一点。我厌倦了等待别人来做这件事，所以我编译了这个 Reddit 子版块的最后 984 篇帖子的数据集。 json 文件文本的链接位于： https: //drive.google.com/file/d/1vh9xh-4z3w4L_fL8T8nXI5Bwnm10FUSc/view?usp=sharing ​ 数据集当前未注释，并且如果有人对此有强烈的感觉（比如那些不断发帖的人），我欢迎任何帮助注释它。任何人都可以编辑 json 文件的文本，因此如果您想帮助注释，只需在 google docs 中打开它并将 is_beginner=&quot;&quot; 替换为 is_beginner=“0” 如果您认为该帖子是应该保留的类型，或者 is_beginner=“1”  p&gt; 如果你认为它不属于这个子 ​ 984 个帖子对于一个玩具示例来说可能就足够了，但我们可能需要如果我们想要良好的准确性，以获得更多数据。 reddit api 只允许你获取 1000 个最新帖子，并且有解决方法，但还没有费心去尝试解决这个问题。这里的瓶颈当然是注释。我想过通过扫描诸如“这属于 r/learnmachinelearning”之类的注释来自动化注释，但是有很多误报，这似乎比仅仅要求人类帮助注释更麻烦。 一旦注释完毕，我可能会尝试几种不同的架构，但如果有人有任何建议或想要就此进行合作我很欢迎。   由   提交 /u/theLanguageSprite   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahag9e/p_im_creating_a_moderation_classifier_for_this_sub/</guid>
      <pubDate>Fri, 02 Feb 2024 18:24:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>