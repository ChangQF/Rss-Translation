<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Thu, 06 Jun 2024 01:02:49 GMT</lastBuildDate>
    <item>
      <title>[D] 我可以使用深度度量学习来验证一对肺肿瘤 CT 扫描和肿瘤掩模是否相互对应吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d95dg8/d_can_i_use_deep_metric_learning_to_verify_if_a/</link>
      <description><![CDATA[您好， 我有一个肺肿瘤 CT 扫描图像数据集，其中包含真实肿瘤分割掩码（二元掩码）。肿瘤通常占据整个图像的很小一部分。因此，对于特定应用，我会得到一对 CT 图像和一个肿瘤掩码，我必须验证肿瘤掩码是否与图像中的肿瘤相对应。 我正在考虑使用深度度量学习来解决这个问题。我将有一个网络，它将图像、掩码对作为输入，并预测它们之间的余弦距离。我将使用对比损失来训练这个网络，其中正对对应于 CT 图像及其真实掩码，而负对将是任何随机掩码。这种设置听起来可行吗？ 当我实施这个时，我可能会面临哪些挑战？（我猜，由于 RGB 图像和二元掩码之间的域差距，我可能会遇到一些问题） 任何帮助都将不胜感激！如果您还可以链接一些做类似事情的论文，那也很酷。谢谢！ PS：我知道我也可以使用分割来解决这个问题，但我想看看对比学习是否适用于这个问题    提交人    /u/Far-Theory-7027   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d95dg8/d_can_i_use_deep_metric_learning_to_verify_if_a/</guid>
      <pubDate>Thu, 06 Jun 2024 00:30:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 回归的样本平衡</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d958yn/d_sample_balancing_for_regression/</link>
      <description><![CDATA[大家好， 我遇到了一个问题，我们正试图回归价格。我们希望模型对 100 和 160 之间的差异进行惩罚，而不是 1 和 1.60。我知道分类有 class_weights：回归有类似的东西吗？    提交人    /u/Odd_Background4864   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d958yn/d_sample_balancing_for_regression/</guid>
      <pubDate>Thu, 06 Jun 2024 00:24:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 斯坦福无人机数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d954ji/r_stanford_drone_dataset/</link>
      <description><![CDATA[我是一名博士研究员，致力于从航空图像中进行物体检测。我过去曾使用过斯坦福无人机数据集 (SSD)，但官方网站上的链接 (https://cvgl.stanford.edu/projects/uav_data/) 似乎不再有效（至少几周都没有用过）。这个数据集对于地面人员检测非常有价值。我能够在 kaggle 上找到压缩视频，但其中一些视频似乎可能已损坏（注释未正确对齐）。我曾尝试给维护官方数据集的人发送电子邮件，但他们现在是一家初创公司的首席执行官，我无法通过他们的大学电子邮件联系到他。他是提出通用 IOU 指标的人！有人碰巧有这个数据集，愿意通过 Google Drive 或其他方式分享吗？或者有谁知道还有其他下载方式吗？如果您知道的话，我将不胜感激。感谢您提供的任何信息！    提交人    /u/LyveLyte   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d954ji/r_stanford_drone_dataset/</guid>
      <pubDate>Thu, 06 Jun 2024 00:17:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 数据、排序和内在维度对分层可导航小世界中回忆的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d92sjl/r_the_impacts_of_data_ordering_and_intrinsic/</link>
      <description><![CDATA[由于数据集拓扑和排序、嵌入模型和近似 KNN 算法之间的相互作用，HNSW 召回率会严重降低向量搜索结果。  论文：https://arxiv.org/abs/2405.17813  默认值很重要：流行矢量数据库的实现会使 NDCG 降低 -18%。 顺序很重要：更改数据提取顺序会使 NDCG 降低 -12%。 MTEB 排行榜：考虑 HNSW 时，排序会发生变化，最多 3 个位置。 测量：您应该测量您的召回率并增加 ef_search。 评估：在合成、理想基准和真实世界的电子商务数据集上进行评估。 开源：局部内在维度的嵌入数据集在此处发布https://huggingface.co/datasets/Marqo/benchmark-embeddings  阅读博客文章： https://www.marqo.ai/blog/understanding-recall-in-hnsw-search    提交人    /u/Jesse_marqo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d92sjl/r_the_impacts_of_data_ordering_and_intrinsic/</guid>
      <pubDate>Wed, 05 Jun 2024 22:27:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在小数据集上嵌套 LOO-CV 来选择超参数并报告整个数据集的准确性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8z1yf/d_nested_loocv_on_a_small_dataset_to_both_select/</link>
      <description><![CDATA[我有一个包含 68 个时间序列的数据集。我的数据集有 3,000 个特征，因为我正在使用包来生成尽可能多的特征。我知道这是一个问题，所以我计划使用 sklearn 的 SelectPercentile 和 PCA 来减少特征数量，然后将其输入到某个分类器中。我希望能够为 SelectPercentile、PCA 和分类器选择超参数，同时报告整体准确度指标。 我的数据集很小，所以如果我将其拆分为 train-val-test 以选择最佳模型，我的测试集将太小而无法报告良好的准确度指标（即 5/7 听起来不如 53/68 好）。此外，我想执行 LOO 而不是 KFold，因为小规模意味着不同的折叠将导致非常不同的测试准确度（即 4/7 和 5/7 是一个巨大的差异），并且 LOO 在这方面是确定性的。 我可以执行嵌套 LOO 来为我的模型选择超参数，然后报告整个数据集的准确度吗？    提交人    /u/Amazydayzee   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8z1yf/d_nested_loocv_on_a_small_dataset_to_both_select/</guid>
      <pubDate>Wed, 05 Jun 2024 19:49:25 GMT</pubDate>
    </item>
    <item>
      <title>[P]OpenAGI：法学硕士的自主代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8svhx/popenagi_autonomous_agents_for_llms/</link>
      <description><![CDATA[我一直想创建像人类一样的代理。虽然 LLM 擅长收集信息，但我希望代理能够独立规划、推理和行动。 所以我创建了 OpenAGI。 OpenAGI 可帮助您为教育、金融、医疗保健等领域的各种任务构建自主代理。它是开源的，旨在让代理随着时间的推移而学习和改进。 GitHub：OpenAGI GitHub    提交人    /u/trj_flash75   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8svhx/popenagi_autonomous_agents_for_llms/</guid>
      <pubDate>Wed, 05 Jun 2024 15:34:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与去噪模型（DDPM）相比，变分扩散模型（VDM）是否仍在使用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8sa60/d_are_variational_diffusion_models_vdm_still_used/</link>
      <description><![CDATA[如果我理解正确的话，VDM 和 DDPM 之间的主要区别在于 VDM 尝试预测每个 x_t 处的完整噪声，而 DDPM 尝试预测从 x_t-1 到 x_t 的步进噪声。我以本文中的 VDM 推导为基础：https://arxiv.org/abs/2208.11970。 VDM 还在任何地方使用吗？我发现几乎所有知名的图像生成模型都使用 DDPM。即使是试图学习单步扩散的回流方法似乎也是从训练过的 DDPM 开始的。    提交人    /u/WhatIsThis_WhereAmI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8sa60/d_are_variational_diffusion_models_vdm_still_used/</guid>
      <pubDate>Wed, 05 Jun 2024 15:09:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 深度学习的局限性：从复杂性理论的角度进行序列建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8s0yp/r_limits_of_deep_learning_sequence_modeling/</link>
      <description><![CDATA[论文链接：https://arxiv.org/abs/2405.16674 X 线程：https://x.com/NikolaZubic5/status/1797567892646470137    提交人    /u/NikolaZubic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8s0yp/r_limits_of_deep_learning_sequence_modeling/</guid>
      <pubDate>Wed, 05 Jun 2024 14:59:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 机器学习 / 人工智能研究的存储库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8qt8q/p_a_repository_for_mlai_research/</link>
      <description><![CDATA[因为我经常看到有趣的论文、新闻和其他资源，而且记忆力像金鱼一样好，所以我决定将它们保存在 GitHub 存储库中。 有几份新闻通讯、LinkedIn、Twitter、subreddits 提供有关 ML 的更新。对我来说，它太分散了，有时要找到我读过的文章简直是一场噩梦。在过去的几年里，我试图收集各种新闻和文章（我想保存下来以后再读的）。我按周划分它们，你可以在这里找到它们（如果你认为这有用的话）： https://github.com/SalvatoreRa/ML-news-of-the-week  总的来说，我想提出一个问题：你认为数据科学家跟踪趋势的最佳来源是什么？新文章？ 在我看来，存在一种信息过载，在阅读一篇真正有趣的文章之前，我必须阅读几篇文章，在我看来，大多数文章只介绍了增量研究。尤其是今天，许多文章只是已经描述或提出的内容的小变化。例如，快速工程就是一个例子，您可以查看几个方法系列，然后查看来自 CoT 的数百种变体等等。今天，在我看来，RAG 中也发生了同样的事情：Twitter 或 LinkedIn 上的一篇文章指出一种方法是 SOTA，然后阅读这篇文章有一种似曾相识的感觉    提交人    /u/NoIdeaAbaout   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8qt8q/p_a_repository_for_mlai_research/</guid>
      <pubDate>Wed, 05 Jun 2024 14:06:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于生物组织图像合成的检索增强扩散</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8qit5/p_retrieval_augmented_diffusion_for_biological/</link>
      <description><![CDATA[这是一个将 RAG 与 Diffusion 相结合进行生物组织图像合成的探索性项目。这是一个有趣的学习经历，我想分享它，以防其他人觉得它有用。但它仍然需要改进，我将尝试整合一个经过微调的模型，而不是从头开始训练。 链接：https://github.com/lnairGT/Diffusion-with-RAG    提交人    /u/IllustriousSir_007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8qit5/p_retrieval_augmented_diffusion_for_biological/</guid>
      <pubDate>Wed, 05 Jun 2024 13:54:44 GMT</pubDate>
    </item>
    <item>
      <title>生物技术中的人工智能。[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8pxsw/ai_in_biotech_d/</link>
      <description><![CDATA[想知道在生物技术领域，AI 是营销热词还是有实际应用。 我是 ML 工程师，根本不是生物学家。我在生物技术领域发现了几种 AI 解决方案，但它们似乎都没有真正带来价值，而更像是一种趋势。我希望我错了，但找不到好的证据。 我发现的解决方案是 Material gen、Microsoft；Alpha Fold、DeepMind；EvBio。    提交人    /u/IIISergeyIII   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8pxsw/ai_in_biotech_d/</guid>
      <pubDate>Wed, 05 Jun 2024 13:28:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何定义多数投票的自定义损失函数？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8peu3/d_how_to_define_custom_loss_function_for_majority/</link>
      <description><![CDATA[我有一个包含 10 个数字的序列。2,2,2,2,2,2,2,2,2,2...2 是类标签，我有 5 个类。该序列也有一个特征向量。我使用这个特征向量通过深度神经网络预测序列。然后，为了预测序列的最终类标签，我使用了预测序列的大多数数字。但我需要一个近似函数来定义多数投票的损失函数来训练深度网络。怎么办？我可以使用哪些近似函数？有任何默认的 PyTorch 损失函数吗？    提交人    /u/Special_Storage5054   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8peu3/d_how_to_define_custom_loss_function_for_majority/</guid>
      <pubDate>Wed, 05 Jun 2024 13:03:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于生成推荐的万亿参数序列传感器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8o2sz/r_trillionparameter_sequential_transducers_for/</link>
      <description><![CDATA[Meta 的研究人员最近发表了一篇开创性的论文，将 ChatGPT 背后的技术与推荐系统相结合。他们表明，他们可以将这些模型扩展到 1.5 万亿个参数，并在生产 A/B 测试中将顶线指标提高了 12.4%。 我们在本文中深入探讨细节：https://www.shaped.ai/blog/is-this-the-chatgpt-moment-for-recommendation-systems    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8o2sz/r_trillionparameter_sequential_transducers_for/</guid>
      <pubDate>Wed, 05 Jun 2024 11:55:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] mamba.np：Mamba 的纯 NumPy 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d80t26/p_mambanp_pure_numpy_implementation_of_mamba/</link>
      <description><![CDATA[      mamba.np 受到一些很棒的项目的启发，我用纯 Numpy 从头实现了 Mamba。代码的目标是简单、可读、轻量，因为它可以在本地 CPU 上运行。 https://github.com/idoh/mamba.np 希望您觉得它有用 :)    提交人    /u/id0h   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d80t26/p_mambanp_pure_numpy_implementation_of_mamba/</guid>
      <pubDate>Tue, 04 Jun 2024 16:02:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>