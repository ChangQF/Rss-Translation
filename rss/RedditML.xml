<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 07 Sep 2024 01:09:37 GMT</lastBuildDate>
    <item>
      <title>[D] 谁是这个领域最热情的导师？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1faqzh8/d_who_is_the_most_passionate_tutor_of_this_field/</link>
      <description><![CDATA[无论个别科目如何，谁的讲座最有激情？    提交人    /u/hendrykiros   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1faqzh8/d_who_is_the_most_passionate_tutor_of_this_field/</guid>
      <pubDate>Fri, 06 Sep 2024 21:47:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 一个可嵌入的小部件，可让您将分类法映射到一起</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fapmyy/p_an_embeddable_widget_that_lets_you_map/</link>
      <description><![CDATA[      嘿 MLE！我制作了一个可嵌入的小部件，可让团队将分类法交叉在一起。如果有帮助，很高兴分享有关映射算法的更多信息。 提供一些演示背景：数据提供者（例如，薪酬数据提供者）将嵌入此小部件，我们将管理“规范化”薪酬数据到用户的分类法。前端不会公开一些更复杂的细节，如映射置信度分数和复杂关系（例如一对多、多对多等）。 https://i.redd.it/hsjmuwuh49nd1.gif    提交人    /u/Different-General700   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fapmyy/p_an_embeddable_widget_that_lets_you_map/</guid>
      <pubDate>Fri, 06 Sep 2024 20:49:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 人脸识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fao8wt/p_face_recognition/</link>
      <description><![CDATA[最流行的人脸识别框架/模型是什么？ 我听说过关于 retinaface 的好消息？但该出版物是 2019 年的 - 所以我想知道自那以后该领域是否还有其他重大进展？    提交人    /u/Johan2212   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fao8wt/p_face_recognition/</guid>
      <pubDate>Fri, 06 Sep 2024 19:51:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 铅部件检测系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fancip/p_inspection_system_for_lead_parts/</link>
      <description><![CDATA[看看市场上是否有任何专门的检测系统可以确定是否可以检查铅烧伤/焊接部件以了解烧伤是否正确填充。这不是可以纯粹依靠视觉完成的事情，必须是其他类型的 X 射线、RF 或其他技术。任何建议或想法都值得赞赏！！！    提交人    /u/NK_Control   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fancip/p_inspection_system_for_lead_parts/</guid>
      <pubDate>Fri, 06 Sep 2024 19:13:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 预测深度学习模型的训练时间</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1falxys/d_predicitng_training_time_for_deep_learning/</link>
      <description><![CDATA[大家好， 我正在开发一个深度学习模型来预测不同模型的训练时间。我有 M 个数据集和 N 个深度学习模型及其相应的训练时间值（总共 MxN 个值）。 我构建了一个具有 3 个隐藏层的线性多输出回归模型，该模型以数据集的固定维度编码作为输入，并输出与 N 个 DL 模型相对应的 N 个训练时间（以分钟为单位）。数据已使用均值-方差归一化进行了归一化。 然而，训练时间预测的准确性低于预期。 这是我的数据集的快照   模型 1 模型 2 ... 模型 N    数据集 1 41.81 ... 42.81   数据集 2 232.66 ... 199.89   ... ... ... ...   数据集 M 417.61 ... 109.54   有人对改进训练时间预测有什么建议吗？ 如果您对特征选择、模型架构或其他技术有任何建议，我们将不胜感激！ 提前致谢！    提交人    /u/americast   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1falxys/d_predicitng_training_time_for_deep_learning/</guid>
      <pubDate>Fri, 06 Sep 2024 18:13:28 GMT</pubDate>
    </item>
    <item>
      <title>NLP 对话：需要建议 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1faj6lf/nlp_talk_suggestions_needed_discussion/</link>
      <description><![CDATA[大家好， 我必须在工作中做一个关于 NLP 从嵌入到神经语言模型的概述的演讲。我预计听众包括商务人士和技术人员） 我需要一些建议，关于如何组织演讲，让技术人士和非技术人员都能感兴趣。 PS：这将是一个 1 小时的演讲。    提交人    /u/pickup_the_slakk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1faj6lf/nlp_talk_suggestions_needed_discussion/</guid>
      <pubDate>Fri, 06 Sep 2024 16:17:21 GMT</pubDate>
    </item>
    <item>
      <title>微调数据集准备 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1faijy3/fine_tuning_dataset_preparation_d/</link>
      <description><![CDATA[有人有微调 LLM 以进行问答的经验吗？我正在尝试微调 Claude haiku 模型。我很好奇是否应该在提示中使用 XML 标签来区分段落和问题。XML 标签被广泛推荐用于常规提示工程。您是否也推荐它们用于微调提示？    提交人    /u/Ok-Emu5850   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1faijy3/fine_tuning_dataset_preparation_d/</guid>
      <pubDate>Fri, 06 Sep 2024 15:51:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 贝叶斯模型与共形预测 (CP)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fac5u5/d_bayesian_models_vs_conformal_prediction_cp/</link>
      <description><![CDATA[大家好， 我创建这篇文章是为了征求您对两种主要不确定性量化范式的看法。我看到代表他们的研究人员之间存在着激烈的竞争。我对近似参考（和贝叶斯深度学习）进行了研究，但除了 CP 的基本教程之外，我对 CP 不是很熟悉。我个人认为它们都是有用的工具，也许可以互补使用： CP 可以提供保证，但是是 poshoc 方法，而 BDL 可以使用先前的正则化来实际*改善*训练期间模型的泛化。此外，CP 基于 IID 假设（抱歉，这不是普遍正确的，至少这是本教程中的假设），而在 BDL 中，输入仅在以参数观察为条件时才是 IID：一般来说，p(yi,yj|xi,xj)!=p(yi|xi)p(yj|xj) 但 p(yi,yj|xi,xj,theta)=p(yi|xi, theta)xp(yj|xj, theta)。因此，BDL 或高斯过程在这方面可能更为现实。 最后，贝叶斯模型不能派生出一个 CP 吗？在这种情况下，CP 提供的预测集和贝叶斯模型提供的预测集有多大程度的一致？是否有研究论文将这些方法结合起来并对此进行测试？ 如果我的问题太基础，请提前道歉。我只是想在两种范式之间保持公正的视角。    提交人    /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fac5u5/d_bayesian_models_vs_conformal_prediction_cp/</guid>
      <pubDate>Fri, 06 Sep 2024 10:50:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检索增强生成 vs 长上下文 LLM，我们确定后者会取代前者吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fabu65/d_retrievalaugmented_generation_vs_longcontext/</link>
      <description><![CDATA[我认为这个问题已经争论了很长时间。但最近有两篇关于这个问题的有趣文章，我想以此作为讨论 RAG 与长上下文 LLM 的起点。 总之，如果我们可以将所有内容都放在提示中，我们就不需要进行检索。但是，我真的怀疑我们能否拥有一个能够覆盖任何组织拥有的大量数据的上下文长度的模型（并且没有可怕的计算成本）。 无论如何，有令人难以信服的报告称 LC-LLM 在 QA 中效果更好（至少到目前为止，我还没有读过一篇文章让我相信 LC-LLM 比 RAG 效果更好）。  有两篇文章讨论了噪声对 LLM 和 RAG 的影响：  第一篇文章指出噪声会影响 LLM 的性能，并竭尽全力对此进行描述。https://arxiv.org/abs/2408.13533 第二篇文章比较了 RAG 和 LC-LLM，并表明通过增加上下文的大小，我们会出现峰值（我们添加相关块），然后性能会下降，因为 LLM 更难找到正确的信息。 https://arxiv.org/abs/2409.01666  我认为我们最终会保留 RAG 的原因或多或少是 LLM 是复杂的神经网络，因此也是模式识别机器。最终，优化信噪比是机器学习中最常见（有时也很困难）的任务之一。当我们开始过度增加这种噪音时，最终模型必然会开始发现噪音并偏离重要信息（此外，LLM 的参数记忆和上下文之间也存在微妙的相互作用，我们仍然不知道为什么有时会忽略上下文） 其次，我个人认为，还有一个结构性原因。自注意力机制会寻求相关关系，而在上下文长度增加的情况下，我们倾向于维数灾难，最终会加剧虚假关系。 我想和您讨论一下您认为 RAG 不会被取代的原因，或者您是否认为 LC-LLM 最终会取代它？在第二种情况下，它如何解决大量上下文无关数据的问题？    submitted by    /u/NoIdeaAbaout   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fabu65/d_retrievalaugmented_generation_vs_longcontext/</guid>
      <pubDate>Fri, 06 Sep 2024 10:29:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 CUDA 比 ROCm 快这么多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fa8vq5/d_why_is_cuda_so_much_faster_than_rocm/</link>
      <description><![CDATA[通常人们会回答“因为 NVIDIA 有更多的时间和金钱”。但是，为什么 AMD 无法赶上？究竟是什么让优化 ROCm 如此困难？ 如果您可以指出一些资源，或者您的回答尽可能详细地说明特定内核和结构的实现以及如何从 Triton 或 XLA 精确地进行和优化 CUDA 调用，那将会很有帮助。谢谢 :)    提交人    /u/evilevidenz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fa8vq5/d_why_is_cuda_so_much_faster_than_rocm/</guid>
      <pubDate>Fri, 06 Sep 2024 06:52:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 本周，我在 Tinygrad 中实现了论文“关注 MLP”！:D</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fa5kop/p_this_week_i_implemented_the_paper_pay_attention/</link>
      <description><![CDATA[      为了尝试更有趣的模型架构，我在 Tinygrad 中实现了 gMLP！ 如果有人想提供一些反馈，将受到欢迎。  [存储库]：https://github.com/EthanBnntt/tinygrad-gmlp [安装]：pip install gmlp_tinygrad [原始论文]：https://doi.org/10.48550/ARXIV.2105.08050  显示 gMLP 架构的图表    提交人    /u/the-wonderful-world   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fa5kop/p_this_week_i_implemented_the_paper_pay_attention/</guid>
      <pubDate>Fri, 06 Sep 2024 03:29:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如果自我注意力不是最重要的事情怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9nefc/r_what_if_selfattention_isnt_the_endall_beall/</link>
      <description><![CDATA[关于 transformer 中的信息丢失，这是一个有趣的替代方案。很想听听你对此的看法！ 用于语言生成和检索的掩码混合器 https://arxiv.org/html/2409.01482v1    提交人    /u/Status-Shock-880   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9nefc/r_what_if_selfattention_isnt_the_endall_beall/</guid>
      <pubDate>Thu, 05 Sep 2024 14:06:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 探索是解锁更好的推荐系统的关键吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9m33i/r_is_exploration_the_key_to_unlocking_better/</link>
      <description><![CDATA[Google DeepMind 的研究人员最近发表了一篇富有洞察力的论文，深入探讨了推荐平台内探索的长期好处。他们认为，虽然短期指标可能无法立即反映优势，但探索可以通过扩大内容语料库来显著增强长期用户体验。  我们在本文中探讨了详细信息：https://www.shaped.ai/blog/is-the-key-to-unlocking-better-user-experiences-in-recommender-systems-found-in-exploration    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9m33i/r_is_exploration_the_key_to_unlocking_better/</guid>
      <pubDate>Thu, 05 Sep 2024 13:09:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 01 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>