<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 12 Dec 2024 15:19:01 GMT</lastBuildDate>
    <item>
      <title>[D] 撰写文献综述论文：值得吗？如何撰写？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hcmtyj/d_writing_a_literature_review_paper_worth_it_how/</link>
      <description><![CDATA[嗨。 我打算在一个新兴的子领域写一篇文献综述论文。我的问题是，成为文献综述论文的第一作者或第二作者是否真的有价值？其次，如何撰写文献综述？到目前为止，我已经阅读了尽可能多的论文，并记下了每篇论文回答了哪些问题，以及论文提出了哪些问题。我应该从哪里开始？ TIA    提交人    /u/Adventurous-Studio19   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hcmtyj/d_writing_a_literature_review_paper_worth_it_how/</guid>
      <pubDate>Thu, 12 Dec 2024 14:56:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 红队扎根理论研究：动机、策略和技巧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hclmk1/r_a_grounded_theory_study_of_llm_red_teaming/</link>
      <description><![CDATA[本文基于对从业人员的访谈，对如何在大型语言模型 (LLM) 上进行红队攻击进行了扎根理论研究。研究人员系统地分析了从业人员的方法，以确定 LLM 红队攻击中的常见模式、策略和动机。 关键技术要点： - 使用访谈的定性编码来开发红队攻击方法的分类 - 确定了 12 种不同的攻击策略和 35 种特定技术 - 发现红队攻击需要手动操作而不是自动化 - 证明了团队协作相对于个人尝试的重要性 - 确立了红队攻击与恶意攻击的区别 - 绘制了测试人员动机和目标的常见模式 主要结果： - 红队攻击策略分为提示操纵、基于心理的攻击和系统极限测试等类别 - 成功的测试人员采用“炼金术士”系统实验的心态 - 大多数从业者的动机是好奇心和安全问题 - 测试需要对技术和心理方面的深入了解 - 手动测试目前比自动化方法更有效 我认为这项工作为开发更结构化的 LLM 安全测试方法奠定了重要基础。他们开发的分类法可以帮助标准化我们评估和保护这些系统的方式。他们发现手动测试仍然优于自动化，这表明我们需要在自动化测试方法上做更多的工作。 我认为，随着这些系统的部署越来越广泛，强调非恶意意图和安全动机尤为重要。了解人们如何以及为何进行这些测试有助于区分合法的安全研究和攻击。 TLDR：首次系统地研究 LLM 红队实践，根据从业者访谈提供策略和技术分类。显示了手动测试和团队协作的重要性，同时将红队训练确立为合法的安全研究。 完整摘要在此处。论文此处。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hclmk1/r_a_grounded_theory_study_of_llm_red_teaming/</guid>
      <pubDate>Thu, 12 Dec 2024 13:56:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 的知识扩展，实现跨域内容的生成（训练数据集之外）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hcke77/r_llms_knowledge_expansion_to_enable_generation/</link>
      <description><![CDATA[  由    /u/ankitm1  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hcke77/r_llms_knowledge_expansion_to_enable_generation/</guid>
      <pubDate>Thu, 12 Dec 2024 12:50:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我应该选择什么：人工智能辅助数据标记还是众包数据标记？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hchrui/r_what_should_i_choose_aiassisted_data_labeling/</link>
      <description><![CDATA[大家好， 我是公司的研究员，我开始使用超过 50,000 张医学图像的数据集训练模型。我面临的主要挑战之一是选择最佳的数据标记方法。 我已经看到了AI 辅助标记的良好结果 - 它似乎更快，前期成本更低。但是，我担心潜在的不准确性，以及人工智能的帮助是否会以我无法预料的方式扭曲数据集。 另一方面，众包标签明显更昂贵且更耗时，但由于多样化的人工输入，结果通常非常可靠。 考虑到我的数据集的规模及其在医学成像等敏感领域的重要性：  您会推荐哪种方法，为什么？ 是否有平衡成本、质量和效率的混合方法？ 对于这两种方法，您会建议使用哪些工具或平台？  我很想听听您对类似项目的见解或经验。您的意见将对我做出正确的决定非常有价值！ 提前致谢！   由    /u/Organic-Injury-1153  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hchrui/r_what_should_i_choose_aiassisted_data_labeling/</guid>
      <pubDate>Thu, 12 Dec 2024 09:56:17 GMT</pubDate>
    </item>
    <item>
      <title>[N] 为 Liger-Kernel 中的 DPO 和 ORPO 节省 80% 的内存</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hcewdl/n_save_80_memory_for_dpo_and_orpo_in_ligerkernel/</link>
      <description><![CDATA[在 Liger Kernel 中引入第一个开源优化的训练后损失，内存减少约 80%，具有 DPO、CPO、ORPO、SimPO、JSD 等功能，通过更大的批量大小实现高达 70% 的端到端加速。将其用作任何 PyTorch 模块 - 今天在 Liger v0.5.0 中可用！ https://x.com/hsu_byron/status/1866577403918917655    提交人    /u/Icy-World-8359   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hcewdl/n_save_80_memory_for_dpo_and_orpo_in_ligerkernel/</guid>
      <pubDate>Thu, 12 Dec 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 进化的通用变形记忆体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hc6bs8/r_an_evolved_universal_transformer_memory/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hc6bs8/r_an_evolved_universal_transformer_memory/</guid>
      <pubDate>Wed, 11 Dec 2024 22:43:30 GMT</pubDate>
    </item>
    <item>
      <title>推理图 TensorFlow 教程 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hc5njm/inference_graph_tensorflow_tutorial_discussion/</link>
      <description><![CDATA[有人能告诉我是否可以将以“.keras”格式保存的模型（TensorFlow）转换为推理图吗？如果可以，怎么做？（像分步教程一样）    提交人    /u/chiplab   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hc5njm/inference_graph_tensorflow_tutorial_discussion/</guid>
      <pubDate>Wed, 11 Dec 2024 22:13:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 NeurIPS 结交朋友和建立人脉？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hc0x89/d_how_to_make_friends_and_network_at_neurips/</link>
      <description><![CDATA[这是我第一次参加 NeurIPS，看到这么多人以及这么多招聘人员，我感到很受震撼。我来自一所不太知名的大学，独自一人来参加会议，甚至我的导师都不在。 我并没有和很多其他与会者或招聘人员交谈，因为 (1) 在一大群人中接近其他人似乎很难，(2) 我觉得自己有强烈的冒名顶替综合症，无法胜任招聘人员提供的工作。我只被接受了一篇研讨会论文，它更偏向于应用，不像其他许多学生那样技术性。 有什么建议可以让我充分利用会议的剩余时间吗？关于这一点，有人也想见面聊聊吗？我是来自英国的三年级博士生，但我自己来自温哥华，所以了解该地区的很多事情。干杯！    由    /u/K_is_for_Karma 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hc0x89/d_how_to_make_friends_and_network_at_neurips/</guid>
      <pubDate>Wed, 11 Dec 2024 18:54:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 连续潜在空间推理：通过连续思维链提高 LLM 性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbto1w/r_continuous_latent_space_reasoning_enhancing_llm/</link>
      <description><![CDATA[本文介绍了COCONUT（连续思维链），将语言模型推理从离散的token空间转化为连续的潜在空间，其核心思想是将推理步骤编码为连续向量而不是文本token，从而实现更灵活、更精确的中间计算。 主要技术点： * 将文本↔连续向量映射的编码器-解码器架构 * 对潜在向量进行操作的新型连续推理模块 * 在连续空间中并行处理推理步骤 * 推理过程中基于梯度的优化 * 结合重建和推理目标的特殊损失函数 主要结果： * 与传统方法相比，推理基准提高了20% * 减少了解决复杂问题所需的计算步骤 * 在不同推理任务中表现更一致 * 更好地处理数学和逻辑推理 * 增强了维持连贯推理链的能力 我认为这种方法可以有意义地推进语言模型处理复杂推理任务的方式。通过超越离散标记，模型可以更好地捕捉类似人类推理的连续性。在推理过程中在连续空间中进行优化的能力对于提高可靠性特别有希望。 我认为主要的挑战是将其扩展到非常大的模型，同时管理计算成本。离散空间和连续空间之间的转换增加了需要解决的开销。 TLDR：新方法将语言模型推理转换为连续向量空间而不是离散标记，通过更灵活的计算在推理任务上显示出 20% 的更好性能。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbto1w/r_continuous_latent_space_reasoning_enhancing_llm/</guid>
      <pubDate>Wed, 11 Dec 2024 13:39:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 掌握最先进的进化优化所需的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbt986/d_resources_to_get_up_to_the_speed_with_the_state/</link>
      <description><![CDATA[有很多好书可以让你接近该领域的最新水平，特别是机器学习和深度学习。但是，有没有关于进化优化的好现代书籍？有没有好的课程？    提交人    /u/ArtisticHamster   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbt986/d_resources_to_get_up_to_the_speed_with_the_state/</guid>
      <pubDate>Wed, 11 Dec 2024 13:17:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 任何可用于多种场景的 3D 重建方法（即不使用就扔）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbreb4/d_any_3d_reconstruction_method_that_can_be_used/</link>
      <description><![CDATA[NeRF 对于每个场景都是独一无二的，因此需要从头开始训练。高斯溅射也是场景所独有的。我理解场景很复杂，因此训练后几乎没有机会出现可以输出多个场景的神经网络。但是，是否仍然有一些场景表示在某种程度上没有被使用和完全抛弃？    提交人    /u/deathmaster2011   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbreb4/d_any_3d_reconstruction_method_that_can_be_used/</guid>
      <pubDate>Wed, 11 Dec 2024 11:27:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 评估生成模型中隐含的世界模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbra2d/r_evaluating_the_world_model_implicit_in_a/</link>
      <description><![CDATA[  由    /u/jsonathan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbra2d/r_evaluating_the_world_model_implicit_in_a/</guid>
      <pubDate>Wed, 11 Dec 2024 11:19:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 Stella 嵌入模型比其他同等质量的模型小得多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbkww5/d_why_are_the_stella_embedding_models_so_much/</link>
      <description><![CDATA[在 MTEB 排行榜上，stella_en_v5 目前排名第三，而使用的内存仅为前 10 名中所有非 Stella 模型的五分之一。 stella_en_400M_v5 排名第十，而使用的内存比排名在其附近的模型少 15-20 倍。这似乎在基准测试的几个子任务中相对一致（针对英语）。 这里的秘诀是什么？或者说，陷阱是什么？目前还没有论文。有人知道详细信息吗？    提交人    /u/-p-e-w-   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbkww5/d_why_are_the_stella_embedding_models_so_much/</guid>
      <pubDate>Wed, 11 Dec 2024 03:58:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>