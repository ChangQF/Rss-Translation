<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 30 Jan 2024 21:13:10 GMT</lastBuildDate>
    <item>
      <title>[R] SERL：用于在 25-50 分钟内从像素训练现实世界 RL 的软件套件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aezdld/r_serl_a_software_suite_for_training_realworld_rl/</link>
      <description><![CDATA[项目页面：https://serl-robot.github .io/ Arxiv：https://arxiv.org/abs/2401.16013&lt; /p&gt; Github：https://github.com/rail-berkeley/serl &lt; p&gt;TL;DR：他们提供了一种 RL 实现，可以实现非常高的样本效率。训练时间足够短，可以在现实世界中进行训练，并且他们提供了几个关于真实机器人的演示。他们没有做出任何新的算法突破，而是将许多最近论文中的方法结合到一个易于使用的实现中。  作者之一 Sergey Levine 有一个有关示例高效现实世界强化学习的视频 作为他关于 RL 的 YouTube 系列的一部分。   由   提交 /u/currentscurrents   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aezdld/r_serl_a_software_suite_for_training_realworld_rl/</guid>
      <pubDate>Tue, 30 Jan 2024 21:07:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用自我监督学习增强 OpenPose 检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aey6s6/p_enhancing_openpose_detection_using/</link>
      <description><![CDATA[      我构建了一个简单的模型，用于将开放姿势检测外推到帧外的点。 这是一个带有 2 个隐藏层的简单神经网络，但主要挑战是数据集的创建。 我一直在摆弄不同的增强功能，例如重新缩放、3d 旋转、考虑不同的图像比例和 Y 轴翻转。在这些 gif 上可以看到效果（左侧的“奇怪​​”点应标记为缺失，但在本用例中，所有点都应位于骨架上，以防我们想要平移或重新缩放骨架）：  （左）只是 dw-pose 外推； （右）dw-pose + 我们的外推 为了以自我监督的方式训练模型，我将不同的点子集标记为缺失。 这些子集是预定义的，基于一些常识（例如左+右脚踝）。 我的问题是：我是否应该从所有可能的子集（即 2^18）中随机采样，并且可能使用非均匀分布进行采样，基于点的接近程度，而不是预先定义不同的子集？ github 存储库：https ://github.com/MarkZakelj/openpose-extrapolation 在博客文章中阅读更多内容：https://www.katalist.ai/enhancing-openpose-detection-using-self-supervised-learning   由   提交/u/avrelij  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aey6s6/p_enhancing_openpose_detection_using/</guid>
      <pubDate>Tue, 30 Jan 2024 20:18:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] Pytorch 中的手动梯度计算和权重更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aew4o5/r_manual_gradient_computation_and_weight_update/</link>
      <description><![CDATA[我不想使用 torch 的默认 loss.backward 函数进行梯度计算。相反，我根据损失函数手动计算梯度（通过 torch.autograd.grad）。但几步之后我的梯度就变为零了。如果我使用 loss.backward 函数，相同的代码可以工作。 torch 是否对引擎盖下的渐变应用了任何隐藏的转换？ （如裁剪等）   由   提交 /u/AIsavvy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aew4o5/r_manual_gradient_computation_and_weight_update/</guid>
      <pubDate>Tue, 30 Jan 2024 18:55:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT时代，2023年构建有效的词相似度搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aevqm7/d_in_the_era_of_gpt_building_an_effective_word/</link>
      <description><![CDATA[大家好， 我目前正在处理一个项目，该项目涉及特定域内的各种品牌名称列表。例如： domain_names = [&#39;xyz&#39;, &#39;yza&#39;, &#39;tra&#39;, &#39;world&#39;] 我的目标是开发一个搜索能够分析单词相似度。具体来说，系统应该接受一个单词并返回与其最相似的前“k”个单词。我尝试过 OpenAI 嵌入，特别是最新的嵌入版本 3（3072 维），但结果并不令人满意。 有人可以建议搜索单词级相似性的最有效方法吗？ GPT，是否建议训练我自己的 Word2Vec 模型？   由   提交/u/stoicbats_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aevqm7/d_in_the_era_of_gpt_building_an_effective_word/</guid>
      <pubDate>Tue, 30 Jan 2024 18:40:00 GMT</pubDate>
    </item>
    <item>
      <title>[N] PyTorch 2.2：FlashAttention-v2、AOTInductor</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aev719/n_pytorch_22_flashattentionv2_aotinductor/</link>
      <description><![CDATA[PyTorch 2.2：FlashAttention- v2，AOTInductor  亮点 向后不兼容的更改 弃用 新功能 &lt; li&gt;改进 错误修复 性能 文档  亮点 我们很兴奋宣布 PyTorch® 2.2 发布！ PyTorch 2.2 通过 FlashAttention-v2 集成以及 AOTInductor（一种专为非 Python 服务器端部署而构建的新的提前编译和部署工具），将 scaled_dot_product_attention 的性能提高了约 2 倍。 &lt; p&gt;此版本还包括改进的 torch.compile 对优化器的支持、许多新的电感器优化以及名为 TORCH_LOGS 的新日志记录机制。 请注意，我们 弃用 macOS x86 支持，PyTorch 2.2.x 将是最后一个版本支持 macOS x64。 除了 2.2 之外，我们还发布了 PyTorch 域库的一系列更新。更多详细信息可以在库更新博客中找到。 自 PyTorch 2.1 以来，此版本由 3,628 次提交和 521 名贡献者组成。我们衷心感谢我们热心社区的贡献。一如既往，我们鼓励您尝试这些并在我们改进 2.2 时报告任何问题。有关如何开始使用 PyTorch 2 系列的更多信息，请访问我们的入门页面。&lt; /p&gt; 摘要： ​  scaled_dot_product_attention (SDPA) 现在支持 FlashAttention-2，与以前相比，速度提高了约 2 倍 PyTorch 2.2 引入了一个新的 TorchInductor 提前扩展，称为 AOTInductor，旨在为非 python 服务器端编译和部署 PyTorch 程序。 torch.distributed  支持一种名为 device_mesh 的新抽象，用于初始化和表示 ProcessGroup。 PyTorch 2.2 提供了一种名为 TORCH_LOGS 的标准化、可配置日志记录机制。 torch.compile 的许多改进包括包含在 PyTorch 2.2 中，包括改进对编译优化器的支持以及改进的 TorchInductor 融合和布局优化。 请注意，我们将弃用 macOS x86 支持，PyTorch 2.2.x 将是支持 macOS x64 的最后一个版本. torch.ao.quantization 现在提供基于原型 torch.export 的流程    由   提交 /u/DreamFlasher   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aev719/n_pytorch_22_flashattentionv2_aotinductor/</guid>
      <pubDate>Tue, 30 Jan 2024 18:18:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何寻找合作者</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aet5o1/d_how_to_find_collaborators/</link>
      <description><![CDATA[我目前正在攻读博士学位的第三年。迄今为止完成的大部分工作都是单独完成的，几乎没有多少监督（除了美化研究论文之外没有得到太多帮助）。 我只是好奇除了在自己的范围内之外如何找到合作自己的教师/研究团队？ 就背景而言，我团队中的大多数学生（在某种程度上）分散在不同的细致研究领域，遗憾的是与我的研究领域很少有重叠。 我很想找到和我一样做一些共同事情的合作者，因为单独工作会变得非常粗糙和无聊，不会得到太多指导。我认为协作可以更快地孕育创意，并且显然会加快论文的制作过程。   由   提交 /u/AmbitiousSeesaw3330   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aet5o1/d_how_to_find_collaborators/</guid>
      <pubDate>Tue, 30 Jan 2024 16:56:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 考虑到所分析的问题，LSTM 的输入形状是否正确？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aerccx/d_is_the_input_shape_for_the_lstm_correct/</link>
      <description><![CDATA[      你好！ 我有一个包含 5000 次模拟 x 21 的数据集时间步长 x 49 个节点，总共 5145000 个观测值。该数据集是基于有限元模拟创建的。我正在尝试使用 LSTM 来预测每个节点的 x、y、z 坐标（每个节点对应于一个观察）。 OUTPUT_SHAPE = y_train.shape[1] model = Sequential( ) model.add(LSTM(num_neurons, activate=activation_function, input_shape=(x_train.shape[1], x_train.shape[2]))) model.add(Dense(OUTPUT_SHAPE))  &lt; p&gt;以下是 1 次模拟的数据集示例（其余模拟以相同格式包含在数据集的后续行中）： https://preview.redd.it/o64lbdi2llfc1.png?width=1111&amp;format=png&amp;auto=webp&amp;s =55026156fdd8af06ee6e49c81e985d90c5289aa2 由于我想预测每个观测的坐标，因此 LSTM 的输入形状定义为 n° 样本 x 1 x 10（10 是特征数）。我使用 1 作为时间步长，因为每次模拟中我拥有的唯一信息是 t = 0 的信息，因此我无法使用更多过去的观察结果来预测新的观察结果。 例如： X_train.shape = (1039290, 1, 10) y_train.shape = (1039290, 3)  问题是我没有一个时间序列，我有多个小时间序列（每个模拟 49 个，对应于每个节点沿时间的位移）。  模型能否识别出我在“时间”中包含了多个时间序列？特征？这样考虑LSTM的输入是不是错误？   由   提交/u/rita_moura  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aerccx/d_is_the_input_shape_for_the_lstm_correct/</guid>
      <pubDate>Tue, 30 Jan 2024 15:42:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 做了 3 年机器学习，还没有成功。常见吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeq9pz/d_3_years_doing_ml_no_success_yet_is_it_common/</link>
      <description><![CDATA[我现在从事 ML 研究 1.5 年，更具体地说是医学成像，之前担任 DL 工程师，负责构建面部识别管道。尽管有很好的理解和我所有的关注，但我还没有为我所研究的所有用例创建一个足够好的系统或模型。  从过去的 4 个月开始，我一直在探索“从嘈杂的标签中学习”，我研究了 3 种技术，花了相当多的时间来集成目标加载器，但结果很差，甚至比基线还要糟糕。此前，曾尝试使用混合自适应算法方案进行系统辨识，但失败了。确实就此写了一份技术报告。  另外，另一方面，我也参加在线比赛。普通的方法让我取得了前 10-20% 的成绩，但当我尝试改进时，我总是失败。尽管我付出了一切努力，但我的方法都效果不佳，非常令人沮丧。  我并不是想建立一个最先进的模型，但至少希望自己能够超越之前的基线或任何有意义的工作。   由   提交 /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeq9pz/d_3_years_doing_ml_no_success_yet_is_it_common/</guid>
      <pubDate>Tue, 30 Jan 2024 14:56:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 没有免费午餐定理和法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeq92s/d_no_free_lunch_theorem_and_llms/</link>
      <description><![CDATA[我有一个可能很愚蠢的问题，但是“没有免费的” “午餐定理”（Wolpert 和 Macready）指出，对于任何模型，针对一类问题的任何性能改进都会被另一类问题的性能所抵消。它还指出，当任何两个模型的性能针对所有可能的问题进行平均时，它们都是等效的。 但是法学硕士会发生什么情况呢？如果对所有可能的问题进行平均性能，平均值会高于其他模型吗？  愿意听取意见。   由   提交/u/iamtdb  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeq92s/d_no_free_lunch_theorem_and_llms/</guid>
      <pubDate>Tue, 30 Jan 2024 14:55:36 GMT</pubDate>
    </item>
    <item>
      <title>[2401.15866]随机摊销：加速特征和数据归因的统一方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aep0hz/240115866_stochastic_amortization_a_unified/</link>
      <description><![CDATA[ 由   提交/u/Elven77AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aep0hz/240115866_stochastic_amortization_a_unified/</guid>
      <pubDate>Tue, 30 Jan 2024 13:57:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 初始化一个小型 LLM 以反映自然代币分布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aenr8k/d_initializing_a_small_llm_to_reflect_natural/</link>
      <description><![CDATA[你好！ ​ 这样设置模型的权重是否可行在任何训练之前，最终 softmax 层的输出是否可以反映训练数据中标记的分布？  我最初的想法是将所有权重和偏差初始化为零，然后通过合并预先计算的观察到的标记概率向量来修改 softmax 层（最初输出零）。到目前为止，我在研究中还没有遇到过这种方法，我很好奇这是否是一个有趣或糟糕的想法？ 提前谢谢您！    由   提交/u/ez613  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aenr8k/d_initializing_a_small_llm_to_reflect_natural/</guid>
      <pubDate>Tue, 30 Jan 2024 12:55:06 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Google Colab 的 AntiPython 编译器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ael7o9/project_antipython_compiler_for_google_colab/</link>
      <description><![CDATA[嘿伙计们， 这是我的业余项目。它是一个编译器，可让您以您喜欢的语言（而不仅仅是 Python）使用 Google Colab。它是开源的。我很想知道你的想法！ GitHub：https://github.com /Fileforma/AntiPython-AI-Compiler-Colab   由   提交 /u/DataBaeBee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ael7o9/project_antipython_compiler_for_google_colab/</guid>
      <pubDate>Tue, 30 Jan 2024 10:18:25 GMT</pubDate>
    </item>
    <item>
      <title>250 RTX 3080s 能做什么 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aedjxc/what_to_dow_ith_250_rtx_3080s_p/</link>
      <description><![CDATA[您好！我有大约 250 个 RTX 3080，+ 可能有 40 个 RTx 3070，我用于挖矿。他们都拆除了风扇护罩并安装了风扇罩。在浸入式冷却液中采矿。长话短说。采矿停止后，事情变得忙碌起来。它们的 GPU 刚刚放在浸没液体中。它们仍然可以工作，并且自从采用液体冷却以来从未变热。  是否有任何公司可以托管浸入式冷却卡，或者有人想要协助代理这些卡或帮助它们设置机器学习？我很乐意将几台 3080 赠送给任何可以用它们实现目标的人！   由   提交/u/death0and0taxes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aedjxc/what_to_dow_ith_250_rtx_3080s_p/</guid>
      <pubDate>Tue, 30 Jan 2024 02:31:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 之外的法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae5dgq/d_llms_beyond_rag/</link>
      <description><![CDATA[实际上几乎每个人都在谈论 RAG。我想知道接下来会出现什么趋势。很想听听您的想法。   由   提交/u/HolidayCritical3665   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae5dgq/d_llms_beyond_rag/</guid>
      <pubDate>Mon, 29 Jan 2024 20:31:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>