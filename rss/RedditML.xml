<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 21 Apr 2024 01:03:02 GMT</lastBuildDate>
    <item>
      <title>[D] Tango 2：通过直接偏好优化调整基于扩散的文本到音频生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c95izw/d_tango_2_aligning_diffusionbased_texttoaudio/</link>
      <description><![CDATA[自动生成的成对偏好数据和 DPO 对齐改进了文本到音频的生成。 代码和数据集：https://github.com/declare-lab/tango 论文：https://arxiv.org/abs/2404.09956 模型：https://huggingface.co/declare-lab/tango2   由   提交 /u/sgpfc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c95izw/d_tango_2_aligning_diffusionbased_texttoaudio/</guid>
      <pubDate>Sun, 21 Apr 2024 01:00:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您想仅使用 LLM（提示）来“解决”什么问题陈述来展示其功能？越复杂越好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c94g53/d_what_problem_statement_would_you_be_curious_to/</link>
      <description><![CDATA[这是一个愚蠢的例子。比方说，给定一个输入图像，识别它是狗还是猫，然后识别它们各自的品种。因此，用户提供了输入图像并获得分类作为输出。  但在幕后，法学硕士拥有完整的工作流程。对于每个步骤，我们仅向 LLM 提供提示，LLM 将生成代码然后执行它。  第 1 步：获取输入图像并去除背景第 2 步：运行现有的 ML 模型以分类为猫或狗第 3 步：识别动物的体色、耳朵长度等第 4 步：使用决策树和上述特征，识别品种第 5 步：将动物及其品种返回给用户 因此，用户只能看到一个输出，但实际上有 5 个不同的步骤，我们仅使用法学硕士和提示就解决了整个问题陈述。  因此，您会尝试仅使用 LLM 提示来解决的最复杂/最有趣的问题陈述是什么？  P.S.它可能涉及也可能不涉及数据集，因为训练和准备 ML/DL 模型可能是也可能不是工作流程的一部分   由   提交 /u/SueTupp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c94g53/d_what_problem_statement_would_you_be_curious_to/</guid>
      <pubDate>Sun, 21 Apr 2024 00:05:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] OSS 工具可在几秒钟内将您的 Python 代码扩展到数千个 GPU 和 CPU</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8yvsn/p_oss_tool_that_scales_your_python_code_to/</link>
      <description><![CDATA[嘿，机器学习社区， 我想分享我正在构建的 OSS 开发人员工具。我很想获得一些反馈并听取那些之前维护过大型开源项目的人的意见。 我正在构建 Burla  这是一个 python 包，可以轻松地在（很多）其他计算机上运行代码。由于 Burla 最适合处理令人尴尬的并行工作负载，因此我将重点放在数据准备上，因此使用案例包括清理、格式化/解析、标记文本数据、数据编码和压缩标记。 Burla 是。 ..  免费开源软件 可通过一个命令安装在云中 具有一个函数和两个参数的 python 包 在 1 秒内扩展到数千个虚拟机 将代码部署到任何硬件 (GPU) 和任何软件环境 (Docker) 一个可以正常工作的工具。 Burla 自动同步包、重新引发异常并流回 stdout/stderr  很高兴回答任何和所有问题！这是我们的网站   由   提交/u/Ok_Post_149   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8yvsn/p_oss_tool_that_scales_your_python_code_to/</guid>
      <pubDate>Sat, 20 Apr 2024 19:54:53 GMT</pubDate>
    </item>
    <item>
      <title>[D]leetcode 在机器学习中有多重要？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8ygzl/d_how_important_is_leetcode_in_ml/</link>
      <description><![CDATA[我最近面试了一位应用数据科学家，面试过程是这样的： - 1x ML 面试 - 3x Leetcode 面试 - 1x 高级系统设计面试 leetcode对于ML/DS从业者的实际工作有多重要？ 3 个 leetcode 问题与 1 个 ml 问题有那么重要吗？ 当我在准备面试时，我只是觉得我在浪费时间做 leetcode，而我本可以在 ML 的其他领域甚至其他领域提升技能。 K8s、cuda 或数据工程等技术技能。  我有兴趣了解其他人对此的看法。   由   提交/u/Amgadoz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8ygzl/d_how_important_is_leetcode_in_ml/</guid>
      <pubDate>Sat, 20 Apr 2024 19:36:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] Meta 的 H100 数据代表其根据 2024 年 2 月 1 日公司财报电话会议购买的 H100。不包括另外 250,000 个 H100 等值的 GPU。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8ydji/d_metas_h100_figure_represents_its_h100_purchase/</link>
      <description><![CDATA[   /u/ewelumokeke  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8ydji/d_metas_h100_figure_represents_its_h100_purchase/</guid>
      <pubDate>Sat, 20 Apr 2024 19:32:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 招聘时我应该在多大程度上重视传统机器学习知识？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8xgvp/d_how_much_should_i_emphasize_on_traditional_ml/</link>
      <description><![CDATA[我们正在招聘 nlp 高级机器学习工程师。  过去，我一直依赖标准的过滤问题。但我想知道这对于可能永远不会在项目中使用这些技术的新工程师来说是否不公平，以及这是否不再衡量工程师现在所做的事情。 我们确实有工艺演示的回声，其中我们询问相关的技术和技术问题。  但是想听听关于初始过滤的事情我想知道我是否应该停止询问： - 偏差与方差以及类似的训练“统计”概念 - 主题建模技术和类似的“旧 nlp” - 引导技术。 bagging 和类似技术 - 熵、杂质和其他“信息论”问题。  我们的团队无法达成共识。希望您的想法   由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8xgvp/d_how_much_should_i_emphasize_on_traditional_ml/</guid>
      <pubDate>Sat, 20 Apr 2024 18:54:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 以 JSON 对象的形式从 PDF 文件中提取数据。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8w1mq/d_extract_data_from_pdf_file_in_the_form_of_json/</link>
      <description><![CDATA[      https://preview.redd.it/q93ittqnaovc1.png?width=777&amp;format=png&amp;auto=webp&amp;s=aec5c1767690bd3 269ba9e601623e4d85378fd37 这是我从 Pdf 文件中捕获的图像，一方面，pdf 文本是可选择的，就像我也可以选择标题和表格中写入的所有文本一样。我尝试了几种技术： 1：使用 llama-index-multi-modal-llms-openai (GPT4-API) 的 MultiModalVectorStoreIndex，首先使用 OCR 将 PDF 转换为图像，然后然后从 PDF 中检索表格，但有一件事我需要定义 pdf 的页数，然后它将准确地获取包含表格的页面，但你知道如果在 pdf 中我们有两个包含表格，并且我定义了 3 个阈值，那么它会重复一页，反之亦然。 2：我也尝试过table transfomer LLM，但结果不好。 3：使用过Tabula python库，但你知道管理阅读这个库的文本非常乏味。 那么有没有任何智能AI工具或LLM可以在这里轻松使用，并且可以将任何pdf（无论包含表格的页数）转换为JSON。 提前致谢，任何建议或帮助都会更加感激。   由   提交/u/Ghulam_Nabi   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8w1mq/d_extract_data_from_pdf_file_in_the_form_of_json/</guid>
      <pubDate>Sat, 20 Apr 2024 17:54:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] ControlNet++：通过高效的一致性反馈改进条件控制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8unjk/r_controlnet_improving_conditional_controls_with/</link>
      <description><![CDATA[ControlNet++：通过高效的一致性反馈改进条件控制 ​ 增强可控性对于文本到图像的扩散模型，ControlNet 等现有工作结合了基于图像的条件控制。在本文中，我们揭示了现有方法在生成与图像条件控制一致的图像方面仍然面临重大挑战。为此，我们提出了 ControlNet++，这是一种新颖的方法，通过显式优化生成图像和条件控制之间的像素级循环一致性来改进可控生成。具体来说，对于输入条件控制，我们使用预训练的判别奖励模型来提取生成图像的相应条件，然后优化输入条件控制和提取条件之间的一致性损失。一种简单的实现是从随机噪声生成图像，然后计算一致性损失，但这种方法需要存储多个采样时间步长的梯度，从而导致大量的时间和内存成本。为了解决这个问题，我们引入了一种有效的奖励策略，通过添加噪声故意干扰输入图像，然后使用单步去噪图像进行奖励微调。这避免了与图像采样相关的大量成本，从而可以更有效地进行奖励微调。大量实验表明ControlNet++显着提高了各种条件控制下的可控性。例如，在分割掩模、艺术线条边缘和深度条件方面，它比 ControlNet 分别提高了 7.9% mIoU、13.4% SSIM 和 7.6% RMSE。 ​ ​ p&gt; 论文：https://arxiv.org/pdf/2404.07987.pdf ​ 项目网站：https://liming-ai.github.io/ControlNet_Plus_Plus/  ​ 代码：https://github。 com/liming-ai/ControlNet_Plus_Plus ​ HuggingFace 演示：https://huggingface.co/spaces/limingcv/ControlNet-Plus-Plus   由   提交/u/Extension-Sun1816    reddit.com/r/MachineLearning/comments/1c8unjk/r_controlnet_improving_conditional_controls_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8unjk/r_controlnet_improving_conditional_controls_with/</guid>
      <pubDate>Sat, 20 Apr 2024 16:54:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 正在寻找一个在每次刷新时生成最先进的聚类结果的网站？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8ukyn/d_looking_for_a_website_that_generates_state_of/</link>
      <description><![CDATA[大家好， 我正在尝试查找一个网站。每次刷新页面时，它都会显示新的最先进的聚类结果。这是可能的，因为它使用了许多不同的指标、算法和数据集，实际上，由于随机性和多重比较，你总是会发现一个新的显着结果（因此它在某种意义上说明了 p-hacking）。  有人知道我指的是什么吗？我想在我的聚类课程中使用它。我似乎无法通过谷歌找到它，因为我得到了各种聚类论文。  非常感谢！ 汤姆   由   提交/u/TommieV123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8ukyn/d_looking_for_a_website_that_generates_state_of/</guid>
      <pubDate>Sat, 20 Apr 2024 16:51:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] Groq 上的 llama-3-70b 和代码解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8uiwi/p_llama370b_on_groq_with_code_interpreting/</link>
      <description><![CDATA[       由   提交/u/mlejva  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8uiwi/p_llama370b_on_groq_with_code_interpreting/</guid>
      <pubDate>Sat, 20 Apr 2024 16:48:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从第一原理解释多模态神经网络的简史</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8sydf/d_the_short_history_of_multimodal_neural_network/</link>
      <description><![CDATA[      来自我的 YT 频道的视频解释多模态机器学习的核心概念及其过去几年的演变。   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8sydf/d_the_short_history_of_multimodal_neural_network/</guid>
      <pubDate>Sat, 20 Apr 2024 15:40:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一张让你感觉自己老了的幻灯片</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8kuef/d_a_slide_which_makes_you_feel_old/</link>
      <description><![CDATA[       由   提交 /u/xiikjuy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8kuef/d_a_slide_which_makes_you_feel_old/</guid>
      <pubDate>Sat, 20 Apr 2024 08:20:34 GMT</pubDate>
    </item>
    <item>
      <title>[N] 何凯明关于表征学习的深度学习架构讲座</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8d5m1/n_kaiming_hes_lecture_on_dl_architecture_for/</link>
      <description><![CDATA[https://youtu.be/D_jt-xO_RmI 非常好的讲座，DL 历史架构进展的最高信噪比。   由   提交 /u/lkphuc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8d5m1/n_kaiming_hes_lecture_on_dl_architecture_for/</guid>
      <pubDate>Sat, 20 Apr 2024 00:57:29 GMT</pubDate>
    </item>
    <item>
      <title>您认为强化学习仍然有效吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c87bh4/do_you_think_reinforcement_learning_still_got_it_d/</link>
      <description><![CDATA[最近我听到很多人说强化学习本身多年来没有任何改进（也许 alphago 是最后的大事）。  而人工智能的其他领域已经出现了许多 SOTA 架构，例如用于基于序列的任务的“Transformers”以及“ResNet”、“Diffusers”和“SOTA”架构。 “VAE”类似于计算机视觉任务的架构。 我认为，无论是直接还是间接，强化学习仍然在使用“RLHF”技术的 ChatGPT 和 Claude 等法学硕士背后发挥着至关重要的作用。以及许多其他最新技术，包括自动驾驶汽车和机器人。  我认为这只是这个领域的一个寒冷的冬天，在未来几年里很快就会找到最先进的建筑（或者这就是我所希望的） 你的想法是什么想法？ 🤔   由   提交/u/cyb0rg14_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c87bh4/do_you_think_reinforcement_learning_still_got_it_d/</guid>
      <pubDate>Fri, 19 Apr 2024 20:40:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>