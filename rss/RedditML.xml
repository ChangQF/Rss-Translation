<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 24 Jan 2025 15:16:43 GMT</lastBuildDate>
    <item>
      <title>[D] ACL ARR 2024 年 12 月讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8x3q4/d_acl_arr_december_2024_discussions/</link>
      <description><![CDATA[ACL ARR 2024 年 12 月评论的讨论帖。评论应该很快就会出来。祝你好运！    由   提交  /u/AccomplishedCode4689   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8x3q4/d_acl_arr_december_2024_discussions/</guid>
      <pubDate>Fri, 24 Jan 2025 14:51:03 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 首席执行官表示，2024 年初，模型在 SWE-bench 上的得分约为 3%。十个月后，我们达到了 50%。他认为，再过一年，我们可能会达到 90% [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8wkth/anthropic_ceo_says_at_the_beginning_of_2024/</link>
      <description><![CDATA[&quot;我对强大 AI 的快速发展持乐观态度的原因之一是，如果你推断曲线上的下几个点，我们很快就会接近人类的能力。 我们开发的一些新模型以及其他公司的推理模型开始达到我认为的博士或专业水平。例如，我们最新的模型 Sonnet 3.5 在 SWE-bench 上获得了约 50% 的成绩，这是专业现实世界软件工程任务的基准。今年年初，最先进的水平只有 3% 或 4% 左右。在短短 10 个月内，我们在这个任务上的成绩从 3% 提高到了 50%。我相信再过一年，我们可以达到 90%。 随着 OpenAI 的 GPT-3 等模型的出现，我们在研究生水平的数学、物理和生物学方面也看到了类似的进步。如果我们继续推断这一进展，几年后，这些模型的技能水平将超越人类的最高专业水平。 那么，这种进步会继续吗？有各种原因可能导致它不会继续，但如果目前的轨迹保持不变，这就是我们的前进方向。&quot; - Dario Amodei。请在此处观看完整采访    提交人    /u/katxwoods   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8wkth/anthropic_ceo_says_at_the_beginning_of_2024/</guid>
      <pubDate>Fri, 24 Jan 2025 14:27:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于LLM实施中的文档处理和隐私问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8wiww/p_questions_on_document_handling_and_privacy_in/</link>
      <description><![CDATA[我是一家机构的内容专家团队负责人。我正在研究在全公司范围内实施 OpenwebUI，作为我们团队与本地和外部 LLM 互动的本地前端解决方案。我们的范围不仅限于内容创建。我们还研究项目管理、销售运营和创意构思。虽然我的背景是内容策略而不是技术开发，但这项研究旨在建立跨部门的综合用例。 使用我们的内部文档和知识库微调模型是一个关键的关注领域。我们目前使用 Anthropic 和 OpenAI 的 API、Claude for Teams 和 ChatGPT Pro。两家提供商都明确表示，API 交互数据仍被排除在他们的模型训练过程之外。 即使我们制定了内部指南，我仍然对文档处理有几个技术问题：  临时内存管理。我想了解文档处理的临时性质 - 具体来说，提供商是否只将提交的文档保存在临时内存中，并在会话后立即清除？根据 LLM 的声明，API 交互被排除在模型训练之外，这样是否可以更安全地发送文档？ OpenwebUI 中的文档处理。当我查看网络流量时，我很确定 OpenwebUI 在 API 查询期间传输完整的文件，而不是提取相关的摘录。这是正确的吗？是否有另一种方法可以使用 OpenwebUI，以便它只发送提示的相关文本部分？ Google Drive 集成。直接上传和 Google Drive 连接的文件之间的文档处理过程是否不同？  即使我查看了 Anthropic 和 OpenAI 的隐私文档，这些技术方面对我来说仍然不清楚。虽然 OpenAI 提供了零保留政策，但我们的组织可能超出了其范围。 对这些问题的任何见解或指导都将帮助我向管理层提出有关 LLM 实施和文档处理协议的建议。 谢谢你的帮助。    提交人    /u/thatinternetguyagain   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8wiww/p_questions_on_document_handling_and_privacy_in/</guid>
      <pubDate>Fri, 24 Jan 2025 14:24:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] CVPR 2025 的 AC 机密评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8w6oi/r_confidential_comments_to_ac_for_cvpr_2025/</link>
      <description><![CDATA[您好， 我向 CVPR 提交了两篇论文，其中一篇有两位审稿人指出缺少某些实验是一个重大缺陷。然而，这些实验已经包含在论文中了。 您认为就此问题向 AC 写一条评论是个好主意吗？ 谢谢！    提交人    /u/Training-Adeptness57   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8w6oi/r_confidential_comments_to_ac_for_cvpr_2025/</guid>
      <pubDate>Fri, 24 Jan 2025 14:08:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用有效连接和可解释的人工智能进行端到端中风成像分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8snj7/r_endtoend_stroke_imaging_analysis_using/</link>
      <description><![CDATA[https://ieeexplore.ieee.org/document/10839398 关于识别中风断开连接以进行干细胞治疗的研究，实际上对 causalML 很有用    提交人    /u/mandelbrot1981   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8snj7/r_endtoend_stroke_imaging_analysis_using/</guid>
      <pubDate>Fri, 24 Jan 2025 10:43:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士（分类）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8sawf/d_llm_for_categorization/</link>
      <description><![CDATA[我是这里的新手，也是 AI 领域的新手。我想创建高维向量空间，其中每个点都是一个故事。这个想法是拥有一个空间，其中较近的点是相似的，就像一个词嵌入一样。就像一个集群中的恐怖故事。科幻小说也在其中。所以，它可以用作推荐系统。我脑海中的总体想法是：使用任何 llm 的标记器和工作嵌入，然后进行自我注意以获得最终的上下文向量，并且在下一部分（不知道它应该如何工作）它应该对上下文向量和初始 n 大小向量执行交叉注意，让我们称之为 F，在此之后 F 应该是 n 维向量空间中故事的坐标。任何想法我应该如何处理这个问题。    提交人    /u/Turbulent_Debt3405   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8sawf/d_llm_for_categorization/</guid>
      <pubDate>Fri, 24 Jan 2025 10:18:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何训练一个模型供计算机使用？ CUA 模型与 4o 有何不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8pvnb/d_how_to_train_a_model_for_computer_use_how/</link>
      <description><![CDATA[大家好， 看到计算机使用操作员演示。我很好奇如何将其应用到我的公司领域。当然，每个人都会很快到达这里，但与此同时，我真的很想了解微调模型以执行这些操作需要付出多少努力？  如果我要开始这段旅程，朝着构建类似 CUA 的代理迈进，任何链接、论文和材料都将不胜感激。 计算需要数百万资金吗？或者可以智能地进行微调。     提交人    /u/darcwader   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8pvnb/d_how_to_train_a_model_for_computer_use_how/</guid>
      <pubDate>Fri, 24 Jan 2025 07:12:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 提交系统和最终论文的标题和摘要不一致</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8o5vf/d_title_and_abstract_discrepancy_of_submission/</link>
      <description><![CDATA[我在第一次大型会议投稿时犯了一个错误。提交初始摘要后，我在论文的最终版本中更新了标题和摘要，但在上传最终论文版本时忘记在提交系统中更新它们。我担心系统中的标题和摘要与论文的最终版本之间的差异可能会导致被拒。有什么办法可以解决这个问题吗？    提交人    /u/That_Transition_9335   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8o5vf/d_title_and_abstract_discrepancy_of_submission/</guid>
      <pubDate>Fri, 24 Jan 2025 05:18:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有关于 Nvidia 的 DLSS 4 ViT 模型架构的详细信息吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8o4vf/d_any_details_on_nvidias_dlss_4_vit_model/</link>
      <description><![CDATA[市场营销和炒作层出不穷，但实际技术细节却很少。DLL 已经发布，我想知道是否有人尝试过深入了解它到底在运行什么？     提交人    /u/altmly   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8o4vf/d_any_details_on_nvidias_dlss_4_vit_model/</guid>
      <pubDate>Fri, 24 Jan 2025 05:16:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 是否像 ICLR 一样对撤回/拒绝的提交进行去匿名化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8n40e/d_does_icml_deanonymize_withdrawnrejected/</link>
      <description><![CDATA[ICLR 保留撤回或拒绝提交的匿名名称。ICML 计划在 2025 年这样做吗？我认为他们过去没有这样做过，但我可能错了。    提交人    /u/faithforever5   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8n40e/d_does_icml_deanonymize_withdrawnrejected/</guid>
      <pubDate>Fri, 24 Jan 2025 04:18:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 大量聊天数据的主题建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8msyv/d_topic_modeling_for_high_volume_chat_data/</link>
      <description><![CDATA[大家好， 我正在为我的雇主进行一些针对大量数据（2-3m+）的聊天主题建模练习。数据是英语、泰语和印尼语聊天的混合。我想获得一些关于我选择的方法的反馈，我应该避免的任何陷阱以及有助于改善我的输出的最佳实践。 我正在使用 BertTopic 进行以下阶段 嵌入：`xlm-roberta-large`，以便我可以在同一模型中处理所有语言 降维：UMAP 聚类：HDBSCAN 生成主题后，我将使用 LLM 为各种主题创建标签 为了进行评估，我计算了模型的整体一致性得分，根据我的超参数，我得到的得分约为 50-60%。我还检查了各个主题的连贯性得分的分布，大部分都超过 50% 我尝试过的一些东西 每种语言的单独模型：这种模型的表现类似于多语言模型，但我放弃了这种模型，因为我需要处理多种语言不同的数据段 NER 预处理：我的聊天记录可能有一些位置信息等，我想将其输入其中，以便主题模型表现得更好。然而，这种方法并没有大大改善输出，而且只有在选择单独的语言嵌入模型时才能这样做。我试图探索 GliNER，但我认为它不支持泰语。 几个问题： - BertTopic 可以处理多大的数据集？我已经处理了大约 10 万条聊天记录，我应该如何考虑可能需要进行哪些更改来处理 200 万条聊天记录？ - 评估输出的好方法是什么？ - 我最关心主题的可解释性。我可以用 LLM 做哪些额外的事情来制作 - MECE 主题并确保合理的分布和覆盖范围？ - 我是否应该添加任何其他步骤来改善我的主题之间的分离？ 我不太熟悉 NLP 技术，所以如果大家能提出建议来改进这个过程就太好了 谢谢 !    提交人    /u/justthinair   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8msyv/d_topic_modeling_for_high_volume_chat_data/</guid>
      <pubDate>Fri, 24 Jan 2025 04:00:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于能量的文本生成扩散语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i87lgy/r_energybased_diffusion_language_models_for_text/</link>
      <description><![CDATA[https://arxiv.org/pdf/2410.21357 本文作者将扩散模型与基于能量的建模相结合，以解决离散生成建模中的挑战。    提交人    /u/Whatever_635   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i87lgy/r_energybased_diffusion_language_models_for_text/</guid>
      <pubDate>Thu, 23 Jan 2025 16:41:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有可能在不重新训练的情况下增加序列长度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i86s90/d_is_it_possible_to_increase_the_sequence_length/</link>
      <description><![CDATA[大家好， 我想知道是否有关于在不完全重新训练的情况下增加模型最大序列长度的研究。如果已经存在，您能分享一些论文或想法吗？    提交人    /u/BigAbbreviations9098   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i86s90/d_is_it_possible_to_increase_the_sequence_length/</guid>
      <pubDate>Thu, 23 Jan 2025 16:06:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 19 Jan 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>