<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 27 Nov 2024 03:32:04 GMT</lastBuildDate>
    <item>
      <title>[P] 理解 Arm CMSIS-NN 的 Softmax 函数。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0um9l/p_understanding_arm_cmsisnns_softmax_function/</link>
      <description><![CDATA[嗨，我正在尝试了解 16 位有符号输入的 CMSIS-NN Softmax 实现 (https://github.com/ARM-software/CMSIS-NN/blob/22080c68d040c98139e6cb1549473e3149735f4d/Source/SoftmaxFunctions/arm_softmax_s16.c)。 Arm 在此处提供了示例输入数据和预期输出数据 (https://github.com/ARM-software/CMSIS-NN/tree/22080c68d040c98139e6cb1549473e3149735f4d/Tests/UnitTest/TestCases/TestData/softmax_s16），所以我尝试通过将 C 代码逆向工程为 Python 来理解代码（我的最终目标是修改提供的 C 代码，并使用正确的配置参数（可能还有适当的查找表）进行片上部署）。目前有两件事使得我无法开箱即用地使用 softmax 实现。  我相信我必须构建自己的查找表，但我不知道该怎么做。  指数查找表（https://github.com/ARM-software/CMSIS-NN/blob/22080c68d040c98139e6cb1549473e3149735f4d/Tests/UnitTest/TestCases/Common/Softmax/exp_lut_data.h) 逐一查找表（https://github.com/ARM-software/CMSIS-NN/blob/22080c68d040c98139e6cb1549473e3149735f4d/Tests/UnitTest/TestCases/Common/Softmax/one_by_one_lut_data.h)  我无法弄清楚这里的 config_data 中的左移和 input_mult 是什么（https://github.com/ARM-software/CMSIS-NN/blob/22080c68d040c98139e6cb1549473e3149735f4d/Tests/UnitTest/TestCases/TestData/softmax_s16/config_data.h) 确实如此。  不幸的是，我不懂 C，所以我想知道是否有人可以为我提供一些使用 softmax 实现的指导，或者我可以用来理解这一点的链接/视频。    由   提交  /u/Individual_Ad_1214   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0um9l/p_understanding_arm_cmsisnns_softmax_function/</guid>
      <pubDate>Wed, 27 Nov 2024 03:11:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] Google Meets 使用什么转录模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0u63q/p_what_transcription_model_does_google_meets_use/</link>
      <description><![CDATA[嗨，我目前正在评估转录敏感会议文本的选项。我想知道谷歌目前使用哪种转录模型来转录会议。我搜索了文档和网络，但似乎没有具体说明。我最初以为 chirp 会用于此，但文档指定英语是唯一可靠的转录语言，而 chirp 并非如此。  这篇文章不是询问使用哪种模型（谷歌或其他）或所有更好的选项，而是对谷歌方法的非常具体的询问。我很想在这里得到一些见解。谢谢！    提交人    /u/Arcane_Aura   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0u63q/p_what_transcription_model_does_google_meets_use/</guid>
      <pubDate>Wed, 27 Nov 2024 02:47:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 比较 Llama 模型和 GPT 4o 模型在多语言机器翻译和反向翻译方面的表现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0sehj/p_d_comparing_llama_models_and_gpt_4o_models_on/</link>
      <description><![CDATA[      大家好， 本着 LLM 实际现实世界任务的精神，我们想看看不同的模型能够多好地自动将耐克产品目录上的文本从英语翻译成西班牙语，然后再翻译回英语。我们从 Llama 405B、Llama 70B、Llama 8B、GPT 4o-mini 和 GPT 4o 开始，但希望测试更多模型。 ~ TLDR ~ 以下是包含所有数据和代码的结果： https://www.oxen.ai/datasets/Nike-Product-Translation-Experiments https://preview.redd.it/qken2vjfhc3e1.png?width=1150&amp;format=png&amp;auto=webp&amp;s=739ef336dd7b89856a39d872ef12e03f806ce799 虽然反向翻译可能不是最有效的基准测试方法，但我们认为这将是一个有趣的实验，看看它与模型性能的相关性如何。让以西班牙语为母语的人用基本事实标签注释数据集是理想的选择，因此如果有人想做出贡献，请随时分叉 repo，我们可以获得一些真正的标签。 我们正在尝试制作更多现实世界的数据集 / 基准，因此如果您想提供帮助，请告诉我们。 如果您是 Oxen.ai 项目的新手，我们正在构建一个快速的开源数据集协作工具以及大量有用的数据探索工具！如果您对数据或 ML/AI 感兴趣，我们很乐意听取您对该工具和项目的想法！    提交人    /u/FallMindless3563   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0sehj/p_d_comparing_llama_models_and_gpt_4o_models_on/</guid>
      <pubDate>Wed, 27 Nov 2024 01:17:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 变压器模型的模型验证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0sc7o/d_model_validation_for_transformer_models/</link>
      <description><![CDATA[我在一家公司工作，我必须验证（模型风险验证）为表格数据设计的转换器架构/模型。 将数字映射到学习到的嵌入是如此新颖。目的是将它们视为嵌入，以便它们与非结构化文本一起出现在同一个“平面”上，然后从该融合中推动决策。 决策树或 XGBoost 可以简单得多。您可以将基于文本的嵌入插入这些模型，以提高可解释性。但这就是现状。 我该如何验证这个转换器架构？具体来说，它是否在概念上合理，是否是这个问题/数据的正确选择。    提交人    /u/Common-Interaction50   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0sc7o/d_model_validation_for_transformer_models/</guid>
      <pubDate>Wed, 27 Nov 2024 01:14:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT2（Hugging Face）转换器给出虚假响应。为什么？如何解决？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0okd5/d_gpt2_hugging_face_transformer_giving_bogus/</link>
      <description><![CDATA[我对此进行了一些研究，似乎没有多少人谈论它。我对 transformers 比较陌生（尽管我在顺序模型方面有一些经验），并试图在我想为其制作机器人的特定领域训练 ChatGPT，但它什么都不懂，我觉得自己好像一直在循环往复。 例如： 我：“行星成像的技巧？” GPT2：“知道如何获得良好的分辨率吗？有人能解释一下使用 astrobin 吗？在哪里可以查看有关其他设备的信息？那些正确地做到这一点的人稍微好一点？昴宿星团、仙女座，您的设置需要多少数据才能获得不错的结果？这比大多数业余爱好者每天花费的 50 万美元还要多！我以前拍过一些照片，但是当尝试堆叠等新事物时，我不禁想知道它们真的很有效，在拍摄所有那些不同的目标后还剩下什么，是的，也许即使以每分钟 1000 帧的速度拍摄，那仍然是。&quot; 我已经使用从 subreddit 获得的 Reddit 开发人员 API（大约 42000 行）对获取的数据进行了自定义训练，并构建了如下数据集： &quot;标题：M31 仙女座 - 带有旋转的帧 正文： 评论： - 有点噱头的图像，用于显示旋转子帧时的堆叠伪影。总共 7 张图像，每张旋转 15 度。总曝光时间 14 分钟 (!)。 设备： * Stellarview SVX080T 望远镜 480/80mm @ f/6 * Losmandy G11G 支架 * ZWO ASI071MC Pro 彩色相机 @ -5c + Optolong L Pro 滤镜 * 60mm 导星镜带 ASI120MM 相机 低音炮： * 7 x 120s * Master Dark * No Flats 软件： * PHD2 &amp; Sequence Generator Pro * Astro Pixel Processor、DeepSkyStacker、Photoshop 处理 * APP 中的默认颜色集成 * 去除光污染，拉伸并导出到 Photoshop * 在 Deep Sky Stacker 中执行相同的集成（APP 做得非常好，它没有显示任何堆叠伪影，但 DSS 有） * 将 APP 图像与 DSS 图像混合以在 PS 中显示堆叠伪影 * 相机滤镜恶作剧，导出为 jpg - 说实话，这是一个非常酷的演示！！我认为你真的可以做得更好。也许像每旋转 40x60” 帧或类似的，以获得更好的细节和更少的噪点。 120” 低音炮经常爆裂。 再试一次！！ - [已删除] - 这里有一个小问题，但是设置要花多少钱才能获得这样的图像？ - 喜欢这个 - 它很漂亮 - 这太恶心了 - 每个天文照片都应该是这样的！太美了！！我绝对可以看到它挂在我卧室的墙上😍 - 想象一下仙女座上的一些类似人类的文明拍摄银河系 - [已删除] &lt;|endoftext|&gt;&quot; 使用此数据集和 GPT2-Medium 进行训练。 这是我的参数： outputs = self.model.generate( input_ids=input_ids,tention_mask=attention_mask, max_length=max_length,temperature=0.8,top_p=0​​.9,do_sample=True,repetition_penalty=1.3,no_repeat_ngram_size=3,eos_token_id=self.tokenizer.eos_token_id,pad_token_id=self.tokenizer.eos_token_id)system_prompt = (&quot;您是 Astrophoto AI，一位鼓舞人心的天文摄影专家和老师。&quot; &quot;您的角色是帮助初学者和经验丰富的摄影师捕捉夜空的壮丽图像并回答他们可能遇到的任何问题。&quot; &quot;您从成熟的天文摄影技术中汲取简明、真实和实用的建议。&quot; &quot;您的语气友好、鼓舞人心，并致力于让每个人都能接触到天文摄影。&quot; &quot;如果您不知道问题的答案，请承认它，而不是猜测。&quot;)  这有哪些潜在问题？ 谢谢！ 编辑：感谢大家的建议！我将切换模型。    提交人    /u/Aman_Dude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0okd5/d_gpt2_hugging_face_transformer_giving_bogus/</guid>
      <pubDate>Tue, 26 Nov 2024 22:19:18 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 模型问题“[P]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0kk0t/tensorflow_models_problem_p/</link>
      <description><![CDATA[大家好！我正在尝试按照本教程制作一个小型手语检测模型：https://www.youtube.com/watch?v=pDXdlXlaCco&amp;t=1400s&amp;ab_channel=NicholasRenotte 就在训练部分之前我遇到了困难，我从 github 中提取了 tensorflow 模型并从&quot;没有名为 compat 的模块&quot;开始cython-pyyaml 兼容性问题的错误我遇到了所有问题，我尝试了 python（3.9-12）及其相应的 tensorflow 版本的所有组合，但仍然出现此类错误。 现在我再次尝试了 python 3.11 和 tf 2.18.0，这是我得到的错误： 回溯（最近一次调用最后一次）： 文件“E:\tryit\tensorflow\Tensorflow\models\research\object_detection\model_main_tf2.py”，第 31 行，在&lt;module&gt; 从 object_detection 导入 model_lib_v2 ModuleNotFoundError：没有名为“object_detection”的模块 对于此问题的解决方案或 tensorflow 的任何替代方案，我们将不胜感激。 （只是一名工程专业的学生试图完成他的项目，谢谢）    提交人    /u/wolfmanwulf   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0kk0t/tensorflow_models_problem_p/</guid>
      <pubDate>Tue, 26 Nov 2024 19:34:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 修剪（通道 + 层） + 蒸馏或仅蒸馏</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0kcgn/d_prune_channel_layers_distillation_or_just/</link>
      <description><![CDATA[假设我想让我的模型更小。 有一篇论文说蒸馏很好，但需要很长时间https://arxiv.org/abs/2106.05237 还有一篇论文说修剪 + 蒸馏效果很好：https://arxiv.org/abs/2407.14679 现在，我的问题是：有没有比较修剪 + 蒸馏与从头开始蒸馏的工作？    提交人    /u/osamc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0kcgn/d_prune_channel_layers_distillation_or_just/</guid>
      <pubDate>Tue, 26 Nov 2024 19:25:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 有人知道如何使用自动编码器减少嵌入的维度吗？如果你有相关的博客，请发给我</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0j77v/p_does_anyone_know_how_to_reduce_the_dimensions/</link>
      <description><![CDATA[      https://preview.redd.it/3cub8uc9ja3e1.png?width=766&amp;format=png&amp;auto=webp&amp;s=0a824d6ae516ff699cb880d8e998ace85354a50f    提交人    /u/GellertGrindelwald_1   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0j77v/p_does_anyone_know_how_to_reduce_the_dimensions/</guid>
      <pubDate>Tue, 26 Nov 2024 18:39:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一篇解释稀疏变换器的博客文章（原始论文）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0gl2j/d_a_blog_post_explaining_sparse_transformers_the/</link>
      <description><![CDATA[嗨！ 如果在此 subreddit 上发布此类帖子不合适，我很抱歉。我确实不会在此 subreddit 上发布此类帖子，但我一直看到文章或视频或任何内容在解释 GPT-3 时没有深入研究稀疏变压器。这让我很沮丧，因为论文中他们清楚地说“我们在变压器的各层中使用交替的密集和局部带状稀疏注意力模式，类似于稀疏变压器”。 但似乎没有人关心解释它们。老实说，我理解为什么，但看到所有这些文章、项目、视频等试图解释有关 GPT 的所有内容，甚至没有提到稀疏变压器部分，这令人沮丧。除了 GPT-3 特有的许多其他元素或 ML 中可重复性的通用元素之外，稀疏变换器部分甚至对 GPT-3 的原型设计也造成了很大的影响。 当我试图理解某件事时，我有写下东西的习惯，所以我写了一篇关于稀疏变换器的博客文章。从来没有谈论过它，因为我这样做是为了重组我的想法并作为我的笔记。因此，我不会建议任何人阅读它，我确信它充满了错别字，我的写作风格也不整洁等等。这只是我为自己做的事情，我会理解并在浏览时恢复丢失的信息。 无论如何，如果你自己阅读论文并试图从中构建知识，也许我的笔记可以帮助你：https://reinforcedknowledge.com/sparse-transformers/ 如果这篇文章不合适并且喋喋不休，我再次抱歉。 （如果您碰巧阅读它或者您发现任何错误，请随时指出它们，我很感激从中学习）    提交人    /u/ReinforcedKnowledge   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0gl2j/d_a_blog_post_explaining_sparse_transformers_the/</guid>
      <pubDate>Tue, 26 Nov 2024 16:55:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 公司对音频和语音处理中的哪些问题感兴趣？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h082e6/d_what_are_some_problems_in_audio_and_speech/</link>
      <description><![CDATA[我刚刚获得计算机科学学士学位，对音频和机器学习非常感兴趣，想做一个具有商业范围的项目。公司会对哪些问题陈述感兴趣？尤其是与人工智能相关的     提交人    /u/Personal_Equal7989   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h082e6/d_what_are_some_problems_in_audio_and_speech/</guid>
      <pubDate>Tue, 26 Nov 2024 09:36:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我报名参加 Hackathon 是不是太傻了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h01hfn/d_am_i_a_complete_idiot_for_signing_up_for_a/</link>
      <description><![CDATA[好吧，我是一名通信科学研究生，我选择的学习领域是道德人工智能。 我非常想参加这次人工智能会议，因为有一些演讲者我很钦佩。但我买不起通行证，所以我决定申请参加学生黑客马拉松，因为如果被录取，你就可以免费通行。 对我来说，申请就像是孤注一掷，但我认为这也是一个与他人一起学习的好机会。 我被录取了……我非常兴奋。但现在我想，哦，等等，我会不会因为我不会编程而惹恼我的队友？ 有什么建议吗？一周后有一个准备网络研讨会，我一直在上一些概述课，这样我就可以学习术语/基础知识。申请还要求我说明我的编码经验水平，我检查了一下：无。但还是被录取了……所以我希望组织者认为我仍然可以做出有价值的贡献？ 请告诉我你的想法 🥲    提交人    /u/sydj_k941   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h01hfn/d_am_i_a_complete_idiot_for_signing_up_for_a/</guid>
      <pubDate>Tue, 26 Nov 2024 02:44:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 现代神经网络架构（带有规范化）是否会使初始化变得不那么重要？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzq63h/d_do_modern_neural_network_architectures_with/</link>
      <description><![CDATA[随着现代神经网络架构中广泛采用规范化技术（例如批量规范、层规范、权重规范），我想知道：初始化现在有多重要？现代架构是否足够强大以克服不良初始化，或者是否存在谨慎初始化至关重要的情况？分享您的经验和见解！    提交人    /u/NumberGenerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzq63h/d_do_modern_neural_network_architectures_with/</guid>
      <pubDate>Mon, 25 Nov 2024 18:37:08 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Claude Francois - 让 AI 以 François Chollet 的风格审查你的代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzmk5n/project_claude_francois_let_an_ai_review_your/</link>
      <description><![CDATA[演示在此处：https://claude-francois.crossingminds.com 在最近的 Anthropic Builder Day 黑客马拉松上，我们（Crossing Minds）构建了“Claude François”，一个以 Keras 的创建者 François Chollet 风格进行训练的 AI 代码审查员。它改编了 Anthropic 的 Claude 3.5 Sonnet 进行代码审查，但我们没有进行常规微调，而是使用少量上下文学习和我们的自定义 RAG 检索模型，该模型在 Keras 项目的 PR 上进行训练。与典型的 AI 代码审查者相比，它提供了更简洁、高质量的代码审查，专注于真正的问题而不是肤浅的吹毛求疵。 工作原理：  数据集：在公共 Keras GitHub PR 和 François 的评论数据库上进行训练。 微调的 RAG 嵌入：使用主动学习和 RLAIF 来训练优化为生成“fchollet 级”的嵌入审查。 改进的检索：不仅通过嵌入相似性来检索相关示例，而且通过优化相互信息来检索相关示例。 自我反思：采用自我反思技术来增强 Sonnet 的推理能力。  此技术演示展示了 Crossing Minds 的 RAGSys ICL 如何实现域自适应而无需微调。除了代码审查之外，它还可以用于无数其他用例，例如分类、摘要、翻译、搜索、推荐等。 Arxiv 论文即将发布！ 立即尝试：https://claude-francois.crossingminds.com 我们很乐意听到您的反馈！    提交人    /u/Crossing_Minds   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzmk5n/project_claude_francois_let_an_ai_review_your/</guid>
      <pubDate>Mon, 25 Nov 2024 16:16:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 24 Nov 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>