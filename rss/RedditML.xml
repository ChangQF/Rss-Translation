<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 19 Sep 2024 09:17:22 GMT</lastBuildDate>
    <item>
      <title>[P]用纯 Python 从头构建玩具神经网络框架——受 Karpathy 的 Micrograd 启发</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkg3yd/pbuilding_a_toy_neural_network_framework_from/</link>
      <description><![CDATA[      https://github.com/ickma/picograd 上周末，我开始了一个项目，完全从头开始使用纯 Python（没有 TensorFlow、PyTorch 或其他库）构建一个玩具神经网络框架。这个项目的想法来自 Andrej Karpathy 的 micrograd，我想挑战自己，真正了解神经网络在底层的工作原理。 我实现了前向和后向传播，经过一些测试后，我在 Iris 分类数据集上实现了 93% 的准确率。 这个项目是一个很好的学习工具，可以探索神经网络的内部结构，例如在训练过程中如何更新权重和偏差，以及不同层在前向和后向传递过程中如何通信。如果您希望在不依赖现有框架的情况下更深入地研究神经网络的机制，这可能对您也有帮助。 我随时可以提问或分享任何反馈！ https://preview.redd.it/jwaltnn6aqpd1.png?width=846&amp;format=png&amp;auto=webp&amp;s=3eb14eacf57fd323ac2eeb75b614ddb5f27bf8a2   由    /u/Potential-Dingo-6424  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkg3yd/pbuilding_a_toy_neural_network_framework_from/</guid>
      <pubDate>Thu, 19 Sep 2024 08:40:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机械工程师的机器/深度学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkf9dj/d_machinedeep_learning_for_a_mechanical_engineer/</link>
      <description><![CDATA[大家好， 我很快就要（作为团队成员）开始机械工程领域的研究项目了，但是从人工智能的角度来看，我想在机器学习和深度学习领域打下坚实的基础，以便可以顺利地运用到项目中。我在研究领域有经验，但这是我第一次在我的领域使用机器学习和深度学习。 我不确定是否必须深入研究算法的数学方面，或者是否必须更多地关注这些算法的应用（你们可能比我更了解这一点），但是为此，我需要该领域的一些课程、书籍或不错的 YouTube 播放列表，如果您能为此提供一个简短的路线图，我将不胜感激。 谢谢 :)    提交人    /u/Creepy_Principle_611   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkf9dj/d_machinedeep_learning_for_a_mechanical_engineer/</guid>
      <pubDate>Thu, 19 Sep 2024 07:33:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年的视觉自动编码器架构？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkewix/d_the_autoencoder_architecture_for_vision_in_2024/</link>
      <description><![CDATA[我想在图像上训练自动编码器以获得有用的潜在表示，这样我以后可以使用它来训练用于图像生成的扩散和自回归模型。我应该选择哪种 SOTA 架构？    提交人    /u/kiockete   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkewix/d_the_autoencoder_architecture_for_vision_in_2024/</guid>
      <pubDate>Thu, 19 Sep 2024 07:05:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] Nvidia、cuda 和 Linux 驱动程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkenxr/d_nvidia_cuda_and_linux_drivers/</link>
      <description><![CDATA[今天我花了很多时间尝试在我的计算机上运行一个 pytorch ML 项目。我必须克服的困难数量多得令人难以置信。当涉及到 ML 代码时，我可以跟上正在发生的事情并对其进行破解，但当涉及到 cuda、nvidia linux 驱动程序等时，我只是在黑暗中摸索。有人可以推荐一些资源来了解这些东西的实际工作原理和作用吗？ 我想知道驱动程序和操作系统中有哪些部分，以及它们如何与（Nvidia）硬件交互。理想情况下，我想要一本从高层次开始并深入研究 gpu 硬件优化的书。 作为参考，我今天的任务的一部分是编译 NixOs 上的闪存注意力。此外，从现在起大约一年后，我可能会负责编写一些高效的 cuda 内核。    提交人    /u/lemmyuser   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkenxr/d_nvidia_cuda_and_linux_drivers/</guid>
      <pubDate>Thu, 19 Sep 2024 06:47:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kaggle 竞赛将由 AI 代理来掌控，可能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/</link>
      <description><![CDATA[我尝试在 Google 的数据科学代理工具上参加 Kaggle 竞赛 https://www.kaggle.com/competitions/playground-series-s3e19 - 基本上我只是将描述作为提示转储并将数据集上传到那里，它生成了这个 Jupyter 笔记本：https://colab.research.google.com/drive/17DkaHhcdiURHPtYBZoRvoDE9NaSzn4V4 我也在 ChatGPT 上尝试过，但不幸的是我没有 Plus，所以任务在中途终止（没有训练模型）。有 Plus 的人尝试过 ChatGPT 上的 Kaggle 任务吗？想知道我们还能看到机器人赢得比赛多久，我想 RL 会在这里发挥巨大作用。    提交人    /u/caterpillarous   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/</guid>
      <pubDate>Thu, 19 Sep 2024 05:18:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题，torch.function 与 torch.nn.function.function？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkbful/d_simple_question_torchfunction_vs/</link>
      <description><![CDATA[我想编写一个自定义函数来替换我的 loss_function 中的 torch.nn. functional.log_softmax，以验证我的自定义函数具有较低的时间复杂度。 我使用 tensor.exp &amp; tensor.log &amp; tensor.sum 和其他函数来替换 torch.nn. functional.log_softmax，我已经测试了原始版本和我的新版本，它们在基本和简单的张量计算上有相同的结果。但是，当我将新代码移到模型训练过程中时，我发现新代码的损失无法减少并且仍然有很大的波动。 我想知道 1. 原因是如果我在模型中使用 tensor.exp 是否没有反向传播，而如果我使用 torch.nn. functional.function 是否有反向传播功能？ 2. torch.funciton 是否默认具有反向传播功能，例如 tensor.exp()？ 我知道这可能是一个愚蠢的问题，感谢您的帮助。    提交人    /u/Logical_Divide_3595   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkbful/d_simple_question_torchfunction_vs/</guid>
      <pubDate>Thu, 19 Sep 2024 03:21:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 抹去不可见之物：图像水印压力测试挑战（NeurIPS 2024 竞赛）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk90gj/r_erasing_the_invisible_a_stresstest_challenge/</link>
      <description><![CDATA[我们很高兴地宣布，NeurIPS 竞赛“消除不可见：图像水印压力测试挑战”将于 9 月 16 日至 11 月 5 日举行。这是您在尖端领域测试技能并赢得 6000 美元奖金的机会！ 竞赛概述 本次竞赛分为两个赛道：黑盒赛道和米色盒子赛道。它旨在验证图像水印在不同可见性条件和攻击者知识下的稳健性。参赛者将尝试去除不可见的水印，同时保持图像质量。评估将基于两个标准：水印去除的有效性和图像质量的保存。 🔗 重要日期： ▶️ 提交阶段： 9 月 16 日 - 11 月 5 日 ▶️ 注册和提交截止日期： 11 月 5 日 ▶️ 获胜团队公告： 11 月 20 日 🌐 更多信息和注册： ▶️ 网站： http://erasinginvisible.github.io ▶️ 托管在 Codabench： ⏩ 米色盒子赛道： codabench.org/competitions/3821 ⏩ 黑盒赛道： codabench.org/competitions/3857 💡 为什么要参加？  在现实世界的前沿领域测试您的技能。 在各种条件下验证水印稳健性。 与全球研究人员和从业人员社区合作。 赢取 6000 美元的份额（随着更多赞助商的加入，奖金还会继续增加）！  💰 奖金池：6000 美元（并且还在增加！） 想要赞助比赛吗？通过以下方式联系我们： 📧 [erasinginvisible@googlegroups.com](mailto:erasinginvisible@googlegroups.com) 或 [furongh@umd.edu](mailto:furongh@umd.edu)    提交人    /u/Dubby8692737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk90gj/r_erasing_the_invisible_a_stresstest_challenge/</guid>
      <pubDate>Thu, 19 Sep 2024 01:16:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] Windows Agent Arena：计算机上运行的 AI 代理的基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk5frs/r_windows_agent_arena_a_benchmark_for_ai_agents/</link>
      <description><![CDATA[大家好，r/MachineLearning！我想分享一个我参与创建的项目：  AI 助手改变了我们使用计算机工作和搜索信息的方式。随着 LLM 变得越来越强大，下一步是什么？代理。 我很高兴介绍 Windows Agent Arena，这是评估 AI 模型的基准，这些模型可以推理、计划和采取行动来解决 PC 上的任务。 什么是 Windows Agent Arena？ Windows Agent Arena 包含 11 个程序/领域的 150 多个任务，这些任务测试 AI 模型如何使用我们可用的相同应用程序、工具和浏览器在真实操作系统中运行。研究人员可以测试和开发能够浏览网页、进行在线预订/购买、操作和绘制电子表格、在 IDE 中编辑代码和设置、摆弄 Windows GUI 设置以自定义 PC 体验等的代理。 我们基准测试的主要功能是云并行化。虽然当今大多数代理基准测试通常需要几天时间才能通过在开发机器中连续运行任务来评估代理，但我们可以轻松与 Azure 云集成。研究人员可以并行部署数百个代理，将结果加速到 20 分钟，而不是几天。 除了基准测试之外，我们还引入了 Navi，这是一种用于 Windows 导航的多模式代理。我们开源了一个版本的屏幕解析模型，作为研究界的模板。我们对几个基础模型进行了基准测试，从小型本地 Phi3-V 一直到大型云模型（如 GPT-4o）。 我对这个版本以及 Windows Agent Arena 将解锁的通用计算机代理的所有创新感到非常兴奋。代理开发人员首次可以开始探索在真实操作系统领域中的大规模自主数据收集，并使用强化学习来训练动作模型，而不是昂贵的人工演示。  链接 🔗博客：https://www.microsoft.com/applied-sciences/projects/windows-agent-arena 🌐网页：https://microsoft.github.io/WindowsAgentArena/ 📃论文：https://arxiv.org/abs/2409.08264 💻代码：https://github.com/microsoft/WindowsAgentArena 这项工作是与微软的一群出色合作者（Dan Zhao、Francesco Bonacci、Dillon DuPont、Sara Abdali、Yinheng Li、Justin W.、Kazuhito Koishida）以及来自 CMU（Arthur Fender Bucker、Lawrence Jang）和哥伦比亚（Zack Hui）的超级明星实习生一起完成的。    提交人    /u/a6oo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk5frs/r_windows_agent_arena_a_benchmark_for_ai_agents/</guid>
      <pubDate>Wed, 18 Sep 2024 22:24:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 的面试经历</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk3plt/d_interview_experience_at_openai/</link>
      <description><![CDATA[最近有 OpenAI 面试经历的人吗？我发现了一个关于他们面试流程的非常有用的帖子，但那是 7 年前的事了。想知道这个过程是怎样的，其他人的经历如何。不胜感激任何见解    提交人    /u/plantparent2021   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk3plt/d_interview_experience_at_openai/</guid>
      <pubDate>Wed, 18 Sep 2024 21:08:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 工作原理的直观解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk1jhj/d_an_intuitive_explanation_of_how_llms_work/</link>
      <description><![CDATA[嗨， 我写了一篇博客文章，以非常直观的方式解释了 LLM 的工作原理。 我们从高层次的抽象开始，其中 LLM 被视为个人助理，然后深入探讨并涵盖标记化、采样和嵌入等概念。 我添加了一些图表，以直观的方式说明一些概念。我还解决了当前 LLM 的一些局限性，例如无法计算“strawberry”中的 R 以及反转字符串“copenhagen”。 希望您觉得它有用！ 如果您有任何反馈或问题，请告诉我。  https://medium.com/@amgad-hasan/explaining-how-llms-work-in-7-levels-of-abstraction-3179de558686 编辑：对于那些不喜欢 medium 的人，下面有一个子堆栈链接和评论。    提交人    /u/Amgadoz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk1jhj/d_an_intuitive_explanation_of_how_llms_work/</guid>
      <pubDate>Wed, 18 Sep 2024 19:37:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 让 LLM 训练更快的技巧指南 - Pytorch 会议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk0tun/d_hacks_to_make_llm_training_faster_guide_pytorch/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk0tun/d_hacks_to_make_llm_training_faster_guide_pytorch/</guid>
      <pubDate>Wed, 18 Sep 2024 19:06:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] Yannic Kilcher 的 discord 上的每日报纸讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fjws5a/d_daily_paper_discussions_on_yannic_kilchers/</link>
      <description><![CDATA[      继续 Anthropic 的 Transformer Circuit 系列，并作为 每日论文讨论 的一部分，Yannic Kilcher discord 服务器，我将自愿领导对机械可解释性工作的分析 🔍 📜 Softmax Linear Units 由 Nelson Elhage、Tristan Hume、Catherine Olsson、Neel Nanda🔸 等人撰写。 🌐 https://transformer-circuits.pub/2022/solu/index.html 🕰 2024 年 9 月 19 日星期四 12:30 AM UTC // 2024 年 9 月 19 日星期四 6.00 AM IST // 2024 年 9 月 18 日星期三 5:30 PM PT 本系列中的前一篇机械可解释性论文： 🔬 情境学习和归纳头 🔬 A变压器电路的数学框架 加入我们享受乐趣〜https://ykilcher.com/discord https://preview.redd.it/0vcif45vklpd1.png?width=929&amp;format=png&amp;auto=webp&amp;s=622ae21f7adaa1fef08c404725d7102883ff55fc    由    /u/CATALUNA84  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fjws5a/d_daily_paper_discussions_on_yannic_kilchers/</guid>
      <pubDate>Wed, 18 Sep 2024 16:16:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 首篇发表的机器学习论文——乍一看，同行评审笔记中有什么引人注目的地方吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fjpfvt/r_first_published_ml_paper_from_a_quick_glance/</link>
      <description><![CDATA[长话短说，我通过会议论文集发表了我的第一篇论文，但我的同行评审有点短。我想知道这里有没有时间序列预测或 XAI 经验的人可以给我一些笔记？非常感谢。如果没有，也没关系。 https://dl.acm.org/doi/abs/10.1145/3674029.3674035（在 ACM 下开放获取）。    提交人    /u/jnb_phd_ml_accy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fjpfvt/r_first_published_ml_paper_from_a_quick_glance/</guid>
      <pubDate>Wed, 18 Sep 2024 10:23:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>