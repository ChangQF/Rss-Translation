<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Wed, 06 Mar 2024 09:13:39 GMT</lastBuildDate>
    <item>
      <title>[D] 最近有推荐的视频生成论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7v3qx/d_any_recommended_recent_video_generation_papers/</link>
      <description><![CDATA[我想学习视频生成。我已经对 GAN、VAE、DPM 有了一些经验。但不是视频。  我的论文主要关注的是视频生成，我正在寻找视频合成论文的最新（最多 3-4 年前）发展。不像 Sora 那样是闭源的，而是真正的开源模型或项目。 我想学习一切：时间、空间凝聚力、像素预测模型、逐帧生成等等。  例如，我知道 DVD-GAN 很好，但不是最近的（2019 年）。 甚至可能是调查论文，所以我可以感受到每个模型在高层中所做的事情.   由   提交 /u/ShlomiRex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7v3qx/d_any_recommended_recent_video_generation_papers/</guid>
      <pubDate>Wed, 06 Mar 2024 08:54:57 GMT</pubDate>
    </item>
    <item>
      <title>[D]为什么 Hugging Face 没有成为桌面上最有前途（且年轻）的 AI 聊天机器人玩家之一（如 Mistral AI、Anthropic、Perplexity AI 等）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7t35y/dwhy_isnt_hugging_face_becoming_one_of_the/</link>
      <description><![CDATA[我记得几年前人们讨论HF的商业模式是什么或者如何盈利。 我认为现在是对他们来说这是最好的时光，但我有点惊讶他们没有创造自己的时光。 他们有才华、经验和资源。只是想知道。   由   提交 /u/xiikjuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7t35y/dwhy_isnt_hugging_face_becoming_one_of_the/</guid>
      <pubDate>Wed, 06 Mar 2024 06:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[N] Groq AMA - 3 月 6 日中午（太平洋标准时间）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7o5u4/n_groq_ama_march_6_noon_pst/</link>
      <description><![CDATA[加入 Igor Arsovski，首席架构师兼首席架构师研究员和 ML 编译器高级总监 Andrew Ling 于太平洋标准时间 3 月 6 日中午参加了有关 Groq 硬件和软件的 AMA。 https://discord.com/invite/rfVBfxyX?event=1214271926164389929 请提交通过我们的 discord    提前提出问题由   提交/u/turtlespy965   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7o5u4/n_groq_ama_march_6_noon_pst/</guid>
      <pubDate>Wed, 06 Mar 2024 02:26:47 GMT</pubDate>
    </item>
    <item>
      <title>[N] OpenAI 居住申请今天再次在旧金山开放，截止日期为 3 月 11 日</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7o4f1/n_openai_residency_applications_have_opened_again/</link>
      <description><![CDATA[我前段时间对此很感兴趣，但当时他们关闭了，所以我设置了一个站点差异警报，今天它通知了我，所以我检查过，他们正在再次招聘。 对于有才华的非 AI 人员来说，这是一个绝佳的机会，可以在 OpenAI 获得全额工资的同时过渡到 AI。 对我个人来说，这不是合适的时机申请，但我想如果你们有兴趣的话我可以与大家分享。祝申请顺利！ https://openai.com/careers/openai-residency   由   提交/u/ixam1212  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7o4f1/n_openai_residency_applications_have_opened_again/</guid>
      <pubDate>Wed, 06 Mar 2024 02:25:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我的时间序列回归模型不会学习验证数据集上的模式，但会用于训练。我如何让它学习更有意义的模式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7ma87/p_my_time_series_regression_model_wont_learn/</link>
      <description><![CDATA[嗨， ​ 我被分配了一个大学项目来预测市场变化，但我遇到了我认为是过度拟合的问题。   我的数据集是过去一年的 OHLCV 每小时数据，带有一些技术指标。 我预测一列是未来 24 行的百分位变化，即24 小时百分位变化。 我的每一行都有滞后特征。 我使用 XGBRegressor 来训练模型。 训练时 shuffle = False (如果 shuffle = True，则验证分数将与我对时间序列的经验的实际预测不匹配）  基本上，我的模型不会学习验证数据集中的模式。它立即在训练数据集中获得了很好的模式，但不幸的是在验证和早期停止中并没有很多模式。我有很多滞后的功能，并且尝试了很多组合，但似乎没有任何效果。当训练开始时，我的验证确实立即开始恶化，并且不会停止。 现在，下一个问题是，当它完成训练时，它还会预测相同或一些相同的值。例如： 索引 269：预测 = 0.6632，实际 = -1.0215，MAE = 1.6848 索引 459：预测 = 0.6632，实际 = -0.1799，MAE = 0.8431 &gt; 索引 1212：预测 = 0.6632，实际 = 0.6284，MAE = 0.0348 索引 1416：预测 = 0.6632，实际 = 0.1313，MAE = 0.5319 等等...它一直这样做。 这是我用来训练的函数：查看粘贴 6G4Q (pythondiscord.com) 此外，我尝试了 LSTM 模型，但这并没有解决我的问题，它可以快速学习训练数据集，但不能快速学习验证数据集。我也搞乱了 dropout 和正则化。 提前感谢您的任何帮助/想法:)   由   提交 /u/userlatedvector   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7ma87/p_my_time_series_regression_model_wont_learn/</guid>
      <pubDate>Wed, 06 Mar 2024 01:00:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 2024 支持主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7lnv0/d_icml_2024_support_thread/</link>
      <description><![CDATA[为提交至 ICML 2024 的每个人开设一个线程作为支持小组。审核将于 3 月 20 日发布（如果没有延迟）。 如果您收到任何评论，如果您特别讨厌一位评论者，或者喜欢另一位评论者，请告诉我们。一切皆有可能！   由   提交 /u/Adventurous-Cut-7077   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7lnv0/d_icml_2024_support_thread/</guid>
      <pubDate>Wed, 06 Mar 2024 00:32:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] Word 文档解析法学硕士 - 最佳方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7jore/r_llm_for_word_document_parsing_optimal_approach/</link>
      <description><![CDATA[希望从社区获得一些帮助！ 我想自动准确地识别文档和文本的标题包含在每个标题中。这些文档的结构各不相同，文档之间的标题甚至可能略有不同。总体目标是创建文档的高级结构，然后可以自动重新排列。 我认为法学硕士可能是实现这一目标的好方法，但想知道是否有人有具体的方法关于如何最好地解决这个问题的建议。关于 GPT4、GPT3.5 与 Anthropic 模型的任何想法。 提前感谢您的珍珠   由   提交/u/ross_prager  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7jore/r_llm_for_word_document_parsing_optimal_approach/</guid>
      <pubDate>Tue, 05 Mar 2024 23:07:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 2023年300+ML比赛分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b79bqq/r_analysis_of_300_ml_competitions_in_2023/</link>
      <description><![CDATA[      我运行 mlcontests.com，这是一个网站列出了跨多个平台的 ML 竞赛，包括 Kaggle/DrivenData/AIcrowd/CodaLab/Zindi/EvalAI/… 我刚刚完成了对 300 多个 ML 竞赛的详细分析2023 年，包括查看其中 65 个获奖解决方案。 一些亮点：  正如预期的那样，几乎所有获奖者都使用 Python 。一名获胜者使用 C++ 解决性能至关重要的优化问题，另一名获胜者使用 R 进行时间序列预测竞赛。 92% 的深度学习解决方案使用 PyTorch。我们发现剩下的 8% 使用 TensorFlow，并且所有这些都使用了更高级别的 Keras API。大约 20% 的获胜 PyTorch 解决方案使用 PyTorch Lightning。 基于 CNN 的模型比基于 Transformer 的模型赢得更多计算机视觉竞赛。 在 NLP 领域，毫不奇怪，生成式法学硕士开始被使用。一些竞赛获胜者使用它们来生成用于训练的合成数据，其他人则提出了创造性的解决方案，例如向开放权重法学硕士添加分类头并对其进行微调。还有更多专门针对 LLM 微调的竞赛正在推出。 与去年一样，梯度增强决策树库（LightGBM、XGBoost 和 CatBoost）仍然被广泛使用 由竞赛获胜者评选。 LightGBM 比其他两者稍微流行一些，但差异很小。 计算使用情况差异很大。 NVIDIA GPU 显然很常见；一些获奖者使用了 TPU；我们没有发现任何使用 AMD GPU 的获胜者；有些人仅在 CPU 上训练他们的模型（尤其是时间序列）。一些获奖者通过工作/大学获得了强大的（例如 8x A6000/8x V100）设置，一些获奖者在本地/个人硬件上进行了全面培训，相当多的获奖者使用了云计算。 有相当多的高- 2023 年的概况竞赛（我们详细介绍维苏威火山挑战赛和M6 预测），以及 2024 年即将举办的更多比赛（维苏威火山挑战赛第二阶段、AI 数学奥林匹克、AI 网络挑战赛） )  有关更多详细信息，请查看完整报告：https://mlcontests.com/state-of-competitive-machine-learning-2023?ref=mlc_reddit ​ 获奖者中最常用的一些 Python 软件包&lt; /p&gt; 在我的 r/MachineLearning 帖子中 去年关于 2022 年比赛的相同分析，热门评论之一询问了时间序列预测。 2023 年有几个有趣的时间序列预测竞赛，我设法对它们进行了相当深入的研究。跳至报告的此部分以了解这些内容。 （不同类型的时间序列竞赛的获胜方法有很大差异 - 包括 ARIMA 等统计方法、贝叶斯方法，以及 LightGBM 和深度学习等更现代的 ML 方法。） 我能够花费相当多的时间感谢今年报告的赞助商：Latitude.sh（配备专用 NVIDIA H100/A100/L40s GPU 的云计算提供商）和 Comet（有用的工具），我们花费了大量时间进行研究和撰写用于 ML - 实验跟踪、模型生产监控等）。我不会在这里向您发送垃圾邮件链接，报告底部有更多详细信息！   由   提交 /u/hcarlens   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b79bqq/r_analysis_of_300_ml_competitions_in_2023/</guid>
      <pubDate>Tue, 05 Mar 2024 16:22:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 注意力层复杂度 vs 上下文长度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b77fnc/d_attention_layer_complexity_vs_context_length/</link>
      <description><![CDATA[根据我对 Transformer 的了解，注意力层的计算复杂度与序列长度呈二次方关系。那么上下文长度怎么可能从 4096 (GPT-3) 到 128k (GPT-4) 再到 1M (Gemini 1.5) 呢？  我知道 GPT-4 和 Gemini 的确切架构并不为公众所知。但是是否有论文提出了一种在不增加计算复杂性的情况下增加上下文大小的方法？或者他们只是按照原始论文中的建议使用受限注意力层？   由   提交/u/flxh13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b77fnc/d_attention_layer_complexity_vs_context_length/</guid>
      <pubDate>Tue, 05 Mar 2024 15:08:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] David MacKay 谈随机位的昂贵</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b75loi/d_david_mackay_on_random_bits_being_expensive/</link>
      <description><![CDATA[所以我正在阅读《信息论、推理和学习算法》 （顺便说一下，对于没有听说过它的人来说，这是一本很棒的书）我偶然发现了这段话：  算术模型保证使用几乎尽可能少的随机位做出选择——在随机数昂贵的社区中这是一个重要的点！ [这不是一个玩笑。大量资金花费在软件和硬件中生成随机位。而且随机数很有价值。]  Ch 6.3，第 118 页  这本书出版于 2003 年。我可以想象随机数如何在互联网和现代计算时代出现之前，人们不得不扔硬币，获得这种技术的成本可能会很高，但我认为到 2000 年代初就不会出现这种情况，不是吗？他们没有“随机导入”功能吗？那时，或者他是在说随机数字是有价值的，而不是伪随机数字。如果是这样，它们至今仍然有价值/昂贵吗？因为我从来不需要购买“正品”。之前的随机数。   由   提交/u/new_name_who_dis_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b75loi/d_david_mackay_on_random_bits_being_expensive/</guid>
      <pubDate>Tue, 05 Mar 2024 13:48:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 对于推理和世界模型等术语，该领域是否有公认的定义？我看过很多关于这些主题的论文，但很多争论似乎都是语义学的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b757ji/d_are_there_accepted_definitions_in_the_field_for/</link>
      <description><![CDATA[此类论文的一个例子是他们使用探针来查找黑白棋游戏的棋盘状态 https://arxiv.org/pdf/2210.13382.pdf 有很多论文使用了一些相当有声望的术语研究组织，但我没有看到任何可接受的定义。 例如，奥赛罗论文和 wes gurnee/max tegmark 论文基本上似乎依赖于这样的假设：“如果你可以从隐藏状态的线性（或足够简单）探测中重建外部状态，则该模型具有世界模型”。作为一个定义，这似乎是合理的，但我不确定这是否是公认的事情。   由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b757ji/d_are_there_accepted_definitions_in_the_field_for/</guid>
      <pubDate>Tue, 05 Mar 2024 13:29:20 GMT</pubDate>
    </item>
    <item>
      <title>[N] Nvidia 禁止像 ZLUDA 这样的翻译层</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b70ubo/n_nvidia_bans_translation_layers_like_zluda/</link>
      <description><![CDATA[最近我在这个子论坛上看到了帖子，人们讨论了使用非 Nvidia GPU 进行机器学习。例如，ZLUDA 最近因在 AMD GPU 上启用 CUDA 应用程序而受到关注。现在 Nvidia 不喜欢这样，并禁止在 CUDA 11.6 及更高版本中使用转换层。 https://www.tomshardware.com/pc-components/gpus/nvidia-bans-using-translation-layers-for -cuda-software-to-run-on-other-chips-new-restriction-apparently-targets-zluda-and-some-chinese-gpu-makers#:\~:text=Nvidia%20has%20banned%20running%20CUDA ,system%20during%20the%20installation%20process。   由   提交/u/_d0s_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b70ubo/n_nvidia_bans_translation_layers_like_zluda/</guid>
      <pubDate>Tue, 05 Mar 2024 09:00:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习研究项目的项目管理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b6zltt/d_project_management_for_ml_reseach_projects/</link>
      <description><![CDATA[最近，我的任务是开展一个基于 ML CV 的项目，该项目需要深入研究。这不是一个普遍解决的问题，所以我们必须做大量的研究和实验。不幸的是，这与我们的 Scrum Master/项目经理不太一致，因为他们习惯于软件工程项目，其中有预定义的里程碑、史诗、任务、估计等。这是一个巨大的问题，因为很难提前计划我们会做什么，因为我们需要大量探索。 研究机构如何管理和跟踪项目？有人致力于将研发项目与公司项目管理相适应吗？谁能提供我可以遵循的任何指导方针或参考资料，以便我可以提出一种项目经理可以遵循并评估我们进度的方法？   由   提交 /u/silently--here   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b6zltt/d_project_management_for_ml_reseach_projects/</guid>
      <pubDate>Tue, 05 Mar 2024 07:34:01 GMT</pubDate>
    </item>
    <item>
      <title>[R]《Road to Sora》——论文阅读列表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b6yb1x/r_road_to_sora_paper_reading_list/</link>
      <description><![CDATA[大家好， 周五我们一直在深入研究我们纸质俱乐部的 Sora 技术报告，并认为这会很好要获得背景论文的阅读列表，需要充分理解该技术报告中发生的所有内容 - 每篇文章都对其将用于的管道部分进行一些描述（或以前的最先进技术）评论中引用）。 我们将挑选一些顶级论文，并在接下来的周五将它们作为一个小组进行研究，所以如果您愿意，请加入我们！ Zoom 的时间为周五上午 10 点（太平洋标准时间）。 论文阅读列表： https://www.oxen.ai/blog/road-to-sora-reading-list 技术报告： https://openai.com/research/video- Generation-models-as-world-simulators  加入纸俱乐部： https://lu.ma/oxenbookclub   由   提交 /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b6yb1x/r_road_to_sora_paper_reading_list/</guid>
      <pubDate>Tue, 05 Mar 2024 06:11:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>