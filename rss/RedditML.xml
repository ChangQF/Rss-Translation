<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sat, 02 Mar 2024 15:12:08 GMT</lastBuildDate>
    <item>
      <title>离线政策学习的深度生成模型：教程、调查和对未来方向的展望</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4qb2a/deep_generative_models_for_offline_policy/</link>
      <description><![CDATA[ 由   提交 /u/Ahamed-Put-2344   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4qb2a/deep_generative_models_for_offline_policy/</guid>
      <pubDate>Sat, 02 Mar 2024 15:05:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最聪明的人类与婴儿人工智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4p7fd/d_smartest_human_vs_infant_ai/</link>
      <description><![CDATA[      这个讨论让我震惊，关于“你希望社​​会拥有艾萨克·牛顿还是法学硕士”，两者兼而有之参与者一致认为，他们宁愿选择艾萨克·牛顿的法学硕士学位。对于任何研究过数学、科学、物理等的人来说，很明显，如果没有牛顿，我们就不会有机器学习，甚至在这一点上将它们进行比较甚至有点令人愤怒。我猜演讲者没有科学背景，他们在台上的工作就是炒作人工智能和各自的公司，但我们如何防止高管、经理和公众产生这种幻灭感？   由   提交/u/user3961  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4p7fd/d_smartest_human_vs_infant_ai/</guid>
      <pubDate>Sat, 02 Mar 2024 14:13:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Google TPU 的经验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4oypz/d_experience_with_google_tpu/</link>
      <description><![CDATA[有人有将软件移植到 Google TPU 的经验吗？它与提升和转移现有 PyTorch 或 TensorFlow 工作负载一样简单，还是更复杂？  从头开始编写代码怎么样，更容易吗？   由   提交 /u/siliconductor1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4oypz/d_experience_with_google_tpu/</guid>
      <pubDate>Sat, 02 Mar 2024 14:02:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 具有分析能力的法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4oej0/d_llm_with_analytical_capabilities/</link>
      <description><![CDATA[我的老板要求我创建一个应用程序，该应用程序可以连接到 Redshift 或 Postgres 数据库，可以检索数值数据，并可以回答财务和分析问题公司。他不明白 RAG 技术不适合数值分析。知道我如何实现这一目标。 他提到使用 amazon Q 来完成此任务，我发现它在给出数字数据集的答案方面非常糟糕 &lt;!-- SC_ON - -&gt;  由   提交/u/Fun-Ad953  /u/Fun-Ad953 reddit.com/r/MachineLearning/comments/1b4oej0/d_llm_with_analytical_capability/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4oej0/d_llm_with_analytical_capabilities/</guid>
      <pubDate>Sat, 02 Mar 2024 13:34:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 更换照片上的衣服的最佳方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4nucb/d_best_way_to_replace_clothes_on_the_photo/</link>
      <description><![CDATA[社区大家好👋 由于我是 ML 领域的菜鸟，因此需要向认识的人寻求一些帮助。我的目标是创建一个概念验证工具，它将取代人的衣服。 预期输入： - T 恤/连帽衫/毛衣放在桌子上或挂在衣架上的照片 - 一个男人/女人站在简单造型姿势的全身照片 预期 输出： - 同一男人/女人站在通过的T恤/连帽衫/毛衣的全身照片 我的朋友建议使用这个模型：&lt; a href=&quot;https://ootd.ibot.cn/&quot;&gt;https://ootd.ibot.cn/ 但也许你以前遇到过这个问题，并找到了更好的模型/管道 此外，我正在考虑将输入扩展到：商品的面料/商品的合身性（常规/修身/等）/一些其他属性，这些属性可能有助于实现最真实的结果而没有缺陷。 感谢您的宝贵时间！非常感谢有关如何解决此问题的任何帮助/建议:)    由   提交/u/sl0bodzyany  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4nucb/d_best_way_to_replace_clothes_on_the_photo/</guid>
      <pubDate>Sat, 02 Mar 2024 13:05:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 时间序列综合数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4mo54/d_time_series_synthetic_data/</link>
      <description><![CDATA[大家好。有人处理过创建季节性时间序列合成数据吗？您能建议最好的方法是什么吗？我正在做多变量时间序列预测，想知道合成数据是否适用于此，因为它应该模仿潜在的关系。我确实使用 SDV（指定约束和分布）创建了额外一年的数据，但模型显示的分数更差。质量报告显示 92.64%（柱形状和柱对趋势）。但我仍然感到困惑是否有可能重新创建 X 变量以及 X 和 y 之间的潜在关系？谢谢。    由   提交 /u/_what_the_f   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4mo54/d_time_series_synthetic_data/</guid>
      <pubDate>Sat, 02 Mar 2024 11:58:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 可以用TensorFlow训练的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4m4z4/p_the_models_that_can_be_trained_with_tensorflow/</link>
      <description><![CDATA[大家好，这是我的项目，大家可以使用tensorflow来训练这些模型。 模型可以在&lt; a href=&quot;https://github.com/NoteDance/Note/tree/Note-7.0/Note/neuralnetwork/tf&quot;&gt;https://github.com/NoteDance/Note/tree/Note-7.0/Note/neuralnetwork /tf 该教程可以在 https://github 找到.com/NoteDance/Note-documentation/tree/tf-7.0   由   提交 /u/NoteDance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4m4z4/p_the_models_that_can_be_trained_with_tensorflow/</guid>
      <pubDate>Sat, 02 Mar 2024 11:25:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] BitNet 1-b/b1.58 LLM - 这对 nvidia 构成威胁吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4lhjt/d_bitnet_1bb158_llms_is_that_a_threat_to_nvidia/</link>
      <description><![CDATA[论文链接：https://arxiv.org /pdf/2402.17764.pdf 这是真的吗？听起来好得令人难以置信，对吧？如果这是真的，它不仅减少了训练和运行 LLM 所需的 VRAM 容量和带宽，还建议简化硬件实现，因为不需要 matmul ，它只需要 + 运算 不是对 nvidia（股票）和 AMD 也构成威胁吗？   由   提交/u/tunggad  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4lhjt/d_bitnet_1bb158_llms_is_that_a_threat_to_nvidia/</guid>
      <pubDate>Sat, 02 Mar 2024 10:42:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 人形运动作为下一个令牌预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4kriv/r_humanoid_locomotion_as_next_token_prediction/</link>
      <description><![CDATA[论文： https:// arxiv.org/abs/2402.19469 摘要：   我们将现实世界的人形控制视为下一个令牌预测问题，类似于预测语言中的下一个单词。我们的模型是通过感觉运动轨迹的自回归预测训练的因果变换器。为了考虑数据的多模态性质，我们以模态对齐的方式执行预测，并且对于每个输入标记从相同模态预测下一个标记。这种通用的公式使我们能够利用缺少模式的数据，例如没有动作的视频轨迹。我们根据来自先前神经网络策略、基于模型的控制器、动作捕捉数据和人类 YouTube 视频的一组模拟轨迹来训练我们的模型。我们展示了我们的模型能够让全尺寸的人形机器人零射击地在旧金山行走。即使仅使用 27 小时的步行数据进行训练，我们的模型也可以转移到现实世界，并且可以泛化到训练期间未见过的命令，例如倒退行走。这些发现表明，通过感觉运动轨迹的生成模型来学习具有挑战性的现实世界控制任务是一条有希望的道路。   ​   由   提交 /u/StartledWatermelon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4kriv/r_humanoid_locomotion_as_next_token_prediction/</guid>
      <pubDate>Sat, 02 Mar 2024 09:54:51 GMT</pubDate>
    </item>
    <item>
      <title>将 C 参数从 0.1 更改为 10 会导致线性 SVM 模型的计算时间激增。 + 更改伽玛参数似乎根本不会影响模型。 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4kjvj/changing_c_parameter_from_01_to_10_causes_the/</link>
      <description><![CDATA[     &lt; /td&gt; 标题几乎概括了我想说的内容。 https://preview.redd.it/qmrc363i5wlc1.png?width=842&amp;format= png&amp;auto=webp&amp;s=5f8252677c8b4c0a80ec542ea552e18b3cf87877   由   提交/u/Abject_Pomegranate39   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4kjvj/changing_c_parameter_from_01_to_10_causes_the/</guid>
      <pubDate>Sat, 02 Mar 2024 09:40:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪种生成（克隆）的语音模型更好 Tortoise TTS + Ecker？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4i2dl/d_what_generated_cloned_voice_model_is_better/</link>
      <description><![CDATA[嗨，我正在使用 https: //git.ecker.tech/mrq/ai-voice-cloning 使用 Tortoise TTS。 我确实克隆了一个特定的声音，然后得到了几个“training/{voiceName}/finetune/modules”下的模型。例如： 200_gpt.pth 400_gpt.pth 501_gpt.pth 问题：上面哪一个最好模型，创建与原始语音 TTS 最相似的模型？ PS：我想做清理！并删除所有不必要的文件，因为它们占用大量 GB。 文件夹“training\{voiceName}\finetune\training_state”也是如此。例如，如果我知道 501 是最好的型号，我可以删除其他任何内容并清理 8GB。   由   提交/u/chriscs777  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4i2dl/d_what_generated_cloned_voice_model_is_better/</guid>
      <pubDate>Sat, 02 Mar 2024 06:57:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新会议的审稿人会看到以前的提交/评论吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b49o9e/r_do_reviewers_at_a_new_conference_see_the/</link>
      <description><![CDATA[您好，机器学习研究和发布的新手。作为我实验室的一部分，我们最近向 CVPR 提交了（收到的分数为略低于、临界、略高于，在我们反驳后，被降级为三个“略低于”）。 有关于提交的讨论参加稍后的会议，例如 ECCV。我很好奇 ECCV 审稿人是否能够看到我们之前提交的论文以及审稿人的评论。   由   提交 /u/YodelingVeterinarian   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b49o9e/r_do_reviewers_at_a_new_conference_see_the/</guid>
      <pubDate>Fri, 01 Mar 2024 23:52:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] Luminal：通过图编译在 Rust 中进行快速机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3yvr2/p_luminal_fast_ml_in_rust_through_graph/</link>
      <description><![CDATA[大家好，我用 Rust 开发 ML 框架已经有一段时间了，我终于很高兴与大家分享它。 Luminal 是一个深度学习库，它使用可组合编译器来实现高性能。 当前的 ML 库往往庞大且复杂，因为它们试图将高级操作直接映射到低级手写内核，并专注于急切执行。像 PyTorch 这样的库包含数十万行代码，单个程序员几乎不可能理解所有内容，除非进行大规模重构。 但是有必要这么复杂吗？机器学习模型往往是由一些简单运算符组成的静态数据流图。这使我们能够拥有一个非常简单的核心，仅支持一些原始操作，并使用它们来构建复杂的神经网络。然后，我们可以编写编译器，在构建图之后修改图，以根据我们运行的后端交换更高效的操作。 Luminal 采用这种方法极端情况下，仅支持 11 种基本运算 (primops)：  一元 - Log2、Exp2、Sin、Sqrt、Recip 二元 - &lt; strong&gt;Add、Mul、Mod、LessThan 其他 - SumReduce、MaxReduce、Contigious  每个复杂的操作都可以归结为对于这些原始操作，例如，当您执行 a - b 时，add(a, mul(b, -1)) 会写入图表。或者，当您执行a.matmul(b)时，实际放在图表上的是sum_reduce(mul(reshape(a), reshape(b)))。&lt; /p&gt; 一旦构建了图，迭代编译器就可以对其进行修改，以用更高效的操作替换 primops，具体取决于其运行的设备。例如，在 Nvidia 卡上，动态编写高效的 Cuda 内核来替换这些操作，并用专门的 cublas 内核交换支持的操作。 这种方法会产生一个简单的库，并且性能仅受限于编译器程序员的创造力，而不是模型程序员。 Luminal 还有许多其他简洁的功能，请查看存储库 这里 如果您有任何问题请lmk！   由   提交/u/jafioti   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3yvr2/p_luminal_fast_ml_in_rust_through_graph/</guid>
      <pubDate>Fri, 01 Mar 2024 16:44:30 GMT</pubDate>
    </item>
    <item>
      <title>DeepMind 推出 Hawk 和 Griffin [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3leks/deepmind_introduces_hawk_and_griffin_r/</link>
      <description><![CDATA[        由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3leks/deepmind_introduces_hawk_and_griffin_r/</guid>
      <pubDate>Fri, 01 Mar 2024 04:28:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>