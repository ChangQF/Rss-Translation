<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sun, 24 Mar 2024 18:17:54 GMT</lastBuildDate>
    <item>
      <title>[D] 有谁知道为什么我的测试损失如此疯狂地飙升？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmor9g/d_does_anyone_know_why_my_test_loss_is_spiking_so/</link>
      <description><![CDATA[      我尝试标准化数据，研究特定的纪元和数据（看起来很好），训练直到疯狂峰值之前的纪元，但我仍然无法弄清楚为什么 我尝试标准化数据，研究特定的纪元和数据（看起来很好），训练直到疯狂尖峰之前的纪元，添加L2正则化和dropout，但我仍然无法弄清楚找出原因。使用的模型是来自 pytorch 的 3 层 gcn。我对此很陌生，所以我不确定是否需要更多背景信息，请告诉我   由   提交 /u/False-Kaleidscope89    reddit.com/r/MachineLearning/comments/1bmor9g/d_does_anyone_know_why_my_test_loss_is_spiking_so/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmor9g/d_does_anyone_know_why_my_test_loss_is_spiking_so/</guid>
      <pubDate>Sun, 24 Mar 2024 16:26:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 请推荐如何让 ML 面试对候选人来说更好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmo6r0/d_please_recommend_ways_to_make_ml_interview/</link>
      <description><![CDATA[有一个线程抱怨 ML 面试过于详尽。 作为招聘经理，我希望获得关于制定 ML 的建议面试效果更好。  需要避免哪些事情？ 需要包括哪些好的步骤？    由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmo6r0/d_please_recommend_ways_to_make_ml_interview/</guid>
      <pubDate>Sun, 24 Mar 2024 16:01:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找在 TensorRT 上运行 pytorch 模型的最快推理方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmnn5j/d_looking_for_fastest_inference_way_to_run_a/</link>
      <description><![CDATA[我一直在寻找将经过训练的 pytorch 模型导入 TensorRT 引擎的选项（因为这似乎是 Nvidia 设备最快的推理设置） 。然而，似乎有几种方法可以做到这一点，我想知道是否有人有经验，其中哪种方法可以产生最佳的吞吐量结果？  使用 torch 将 torch 模型转换为tensorrt -tensorrt（这个库看起来很新，文档有很多问题，我无法让它工作） 将 pytorch 模型转换为 onnx，然后使用tensorrt后端 使用https://github.com/NVIDIA将pytorch模型直接转换为tensorrt -AI-IOT/torch2trt#setup 使用tensorrt作为torch.compile的后端，直接在pytorch中进行    由   提交/u/ski233  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmnn5j/d_looking_for_fastest_inference_way_to_run_a/</guid>
      <pubDate>Sun, 24 Mar 2024 15:39:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们想要带时间戳标记的语音 ASR 数据集吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmnkhq/d_do_people_want_timestamplabelled_speech_asr/</link>
      <description><![CDATA[我是一名语音研究人员，我注意到自动语音识别 (ASR) 明显缺乏单词级时间戳注释数据集。 如下所示的数据集，其中文字级时间戳（以毫秒为单位）与文字记录一起提供： “audio”：xxx.wav ” ;text&quot;: 你好世界 &quot;words&quot;: [{&quot;text&quot;: &quot;hello&quot;, &quot;start&quot;: 0, &quot;end&quot;: 100}, &quot; ;text&quot;: &quot;world&quot;:, &quot;start&quot;: 100, &quot;end&quot;: 250}] 通常我看到的所有 ASR 数据集都只有音频转录对 ( words 未提供），但不久前我在对不同 ASR 提供​​商进行时间戳基准测试时，我有一个明显的需求。 这只是一个超级利基用例还是其他用途人们使用这些？ 问这个问题是因为我正在考虑在我已经创建的 HF 上开源一堆（证明librispeech 的概念）或投入一些时间来提高它们的质量并将其作为付费数据集出售。 感谢您的反馈！   由   提交/u/cudaoom  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmnkhq/d_do_people_want_timestamplabelled_speech_asr/</guid>
      <pubDate>Sun, 24 Mar 2024 15:35:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] Treeformer：硬注意力+决策树=因果语言建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmqqq/p_treeformer_hard_attention_decision_trees_causal/</link>
      <description><![CDATA[      今天，我刚刚开始尝试一种新的因果语言建模技术：Treeformers！ Treeformer 是一种具有类似变压器注意力的决策树。它的工作原理是根据预测的下一个标记对注意力头进行分类。除了单个回溯变量之外，每个注意力头还包含所有先前标记的列表。 ​ Treeformer 注意力头状态 Treeformer 有 3 种类型的决策树节点：动态相对回溯、静态相对回溯和静态绝对回溯。 动态相对回溯检查特定标记是否在当前关注位置之前发生过，静态相对回溯检查相对于当前关注的特定标记是否存在位置，静态绝对回溯检查相对于被预测标记的静态位置处的特定标记。 https://preview.redd.it/a04qxm95qaqc1.png?width=475&amp;format=png&amp;auto=webp&amp;s=0a7a17e4dbc60833 c664b62e1cd97ec7aa0f5d78 另请注意，如果节点已被采用，则回溯偏移量将移动以匹配与节点条件匹配的标记的位置。相对回顾机制使得 Treeformer 具有较长的注意力范围，类似于 Transformer。 我期待对我的 Treeformer 想法的反馈和帮助！ https://github.com/jessiepathfinder/treeformer   由   提交/u/jessielesbian  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmqqq/p_treeformer_hard_attention_decision_trees_causal/</guid>
      <pubDate>Sun, 24 Mar 2024 14:59:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不同架构上深度学习原生内核的现状</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmkyje/d_current_state_of_native_kernels_for_deep/</link>
      <description><![CDATA[我是深度学习新手，但对嵌入式系统有一些经验，曾研究过 FFT、IFFT、卷积等 DSP 算法。我什至有我在 ARM 汇编和数字信号处理器（如 ADI 的 Blackfin、TI 的 C6000）上编写了这些内核，因此我对在不同架构上优化数学运算和管道有一些了解。 根据我迄今为止所学到的知识，深度学习计算的核心似乎就是矩阵乘法和加法。我想知道为什么 ARM32、DSP 等上缺乏对 numpy、keras 等框架的本机支持。当然它们不会像 Nvidia 的 GPU 那样强大，但我相信您仍然可以从传统架构中获取很多收益， esp DSP 旨在快速执行这些操作。 我在哪里可以了解有关此主题的更多信息并做出贡献？我很乐意编写汇编内核并从头开始构建深度学习框架，甚至在其他架构上移植深度学习框架。关于机器学习的在线文献似乎以更高层次的内容为主，例如训练、模型等，而且缺乏有关此主题的信息。 这里的专家可以就这个主题指导我吗？   由   提交 /u/jack_of_hundred   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmkyje/d_current_state_of_native_kernels_for_deep/</guid>
      <pubDate>Sun, 24 Mar 2024 13:37:59 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]自然文本到知识图谱</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmj0f0/discussionnatural_text_to_knowledge_graph/</link>
      <description><![CDATA[对于关系提取和实体链接进行了一些微调，但是是否有任何项目可以从原始文本创建端到端知识图？    由   提交 /u/Raise_Fickle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmj0f0/discussionnatural_text_to_knowledge_graph/</guid>
      <pubDate>Sun, 24 Mar 2024 11:54:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] VAE 还值得吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmi8gq/d_is_vae_still_worth_it/</link>
      <description><![CDATA[VAE似乎在“扩散时代”逐渐消失。与 GAN 不同。 我知道扩散可以被视为 VAE 的特例，但问题是其他 VAE 变体相对于扩散的优势是什么（如果有的话）？    由   提交 /u/Realistic_Thanks3282   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmi8gq/d_is_vae_still_worth_it/</guid>
      <pubDate>Sun, 24 Mar 2024 11:07:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何与博士生完成实习职位？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmgovg/d_how_can_i_complete_with_phd_students_for_intern/</link>
      <description><![CDATA[现在我们在数据科学领域看到的实习机会大多是给硕士、博士生或拥有 1-2 年经验并已经转型的人进入数据科学。  现在作为一名大学生，我正在学习数据科学，在寻找实习机会时，我无法满足他们对硕士或博士学位的要求。 该怎么办学生在毕业期间需要做什么才能向公司表明他们至少有资格作为实习生工作？我们应该要求带回家的挑战还是制作一个特定领域的项目？  研究生如何与博士生、硕士生竞争机会？  ​   由   提交/u/Medium_Alternative50   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmgovg/d_how_can_i_complete_with_phd_students_for_intern/</guid>
      <pubDate>Sun, 24 Mar 2024 09:23:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] Aleksa Godric 关于在 DeepMind 找到工作的帖子在今天仍然具有现实意义吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bme24n/d_is_aleksa_godrics_post_on_landing_a_job_at/</link>
      <description><![CDATA[我猜的标题差不多。 顺便说一句，这是 Aleksa 的帖子。我在一家初创公司工作，每天直接应用深度学习来解决具有挑战性的问题。我典型的一天几乎涉及微调、数据整理、生成报告、查看结果和整理高质量数据集来微调我们的模型。我为自己设定了一个崇高的目标，到 2025 年，要有足够的能力去 DeepMind/Anthropic 等公司面试（不是法学硕士或当前流行的话题，但可能是一般的研究工程师类型），重点是对到那时我将有大约 2 年的直接工作经历，以及超​​过 9 年的学术工作（我拥有一个大学的学士学位）体面的州立大学和 ML/AI/机器人领域排名前 3 的大学的硕士学位，在那里我是体面的学生。没什么了不起的。根据我著名/知名的硕士导师的说法，有一篇论文作为第二作者发表，但“非常当之无愧”）和实习项目（实习、业余项目、许多分散但流行的开源项目）。我很想知道我应该如何继续我的准备？我觉得我需要重新调整我的基础知识，但想知道我应该如何去做，以确保我的努力集中且具有直接影响力。 我的致命弱点是我从未认真对待过LeetCode，因为我主要申请/面试研究工程师之类的职位，面试官主要看论文、开源贡献和 PyTorch/TF 等中的一些最低限度的编码知识。 如果人们在这些公司可以参与进来，我会非常感激。老实说，光是看看这些公司员工的背景，我就感到害怕，因为看起来在那里工作的每个人都是 IMO、IOI、IPhO 奖章获得者，其中许多人在量化公司有过疯狂的经历，在这些公司里，面试具有神话/传奇的地位。  任何和所有建议将不胜感激。   由   提交 /u/hellofromthiside   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bme24n/d_is_aleksa_godrics_post_on_landing_a_job_at/</guid>
      <pubDate>Sun, 24 Mar 2024 06:22:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 是否在招聘信息中被过度炒作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bm28ls/d_is_llm_too_hyped_up_in_job_postings/</link>
      <description><![CDATA[我正在就业市场寻找暑期实习机会，并在自主车辆领域从事 ML 研究/工程的全职工作。 “趋势”是指在过去的几年里，这个领域的变化如此之快，从超级炒作到大规模裁员，现在只剩下几家公司在谨慎行事。大多数项目范围内的裁员都是由于高管和经理过于乐观的决定而发生的，当时产品没有达到预期/利润。 自 2023 年以来，与所有其他人工智能用例一样，AV也从chatgpt革命中得到了推动。这些天我能找到的每一个招聘信息都在寻找具有法学硕士经验的人。这种程度让我不得不想到“LLM”。是另一个席卷高管的流行词，这种以法学硕士为重点的招聘将导致 1-2 年内又一系列裁员。 我来的法学硕士的用例到目前为止，大部分都是 chatgpt API，这进一步让我思考是否真的有那么多的开发正在进行，以制作有用的基于 LLM 的产品。通过此类职位被录用的人，你们在建设什么？您正在构建的产品的承诺是什么？您认为这个承诺实现的可能性如何？   由   提交/u/madgradstudent99  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bm28ls/d_is_llm_too_hyped_up_in_job_postings/</guid>
      <pubDate>Sat, 23 Mar 2024 20:36:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] DPO 仍然是经济实惠地微调模型的最佳方式吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bm0tun/d_is_dpo_still_the_best_way_to_affordably/</link>
      <description><![CDATA[论文“Your Language Model is Secretly a Reward Model: Direct Preference Optimization (DPO)”证明 DPO 可以微调 LM 以符合人类偏好，并且优于现有方法”就像 RLHF。 自从这篇论文于 2023 年 5 月发表以来，我想知道 DPO 是否仍然被认为是快速且经济地微调 LLM 的最佳方法（特别是对于初创公司）。    由   提交/u/JT_NVG8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bm0tun/d_is_dpo_still_the_best_way_to_affordably/</guid>
      <pubDate>Sat, 23 Mar 2024 19:38:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 怎样才能成为一名优秀的机器学习工程师？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1blzf0i/d_what_makes_a_good_machine_learning_engineer/</link>
      <description><![CDATA[您认为，怎样才是一名优秀的机器学习工程师？我所说的机器学习工程师指的是不进行研究，而是进行研究并将其实施到生产就绪代码中的人。他们应该具备哪些技能/知识？   由   提交/u/Raiz314  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1blzf0i/d_what_makes_a_good_machine_learning_engineer/</guid>
      <pubDate>Sat, 23 Mar 2024 18:40:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我听了 Sam Altman 最近在 Lex Fridman 进行的 2 小时采访 - 以下是我们都应该知道的关键要点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1blnzj1/d_i_listened_to_sam_altmans_most_recent_2hour/</link>
      <description><![CDATA[Altman 本周在 Lex Fridman 播客上接受采访。这是一次相当长的采访，所以我想分享一下我听他讲话时记下的 10 个关键要点。你可以支持他，也可以反对他——但你不能否认他是即将到来的人工智能常态中最重要的核心人物之一！希望这对感兴趣的人来说是有洞察力的:) -- 1。创造有价值数据的人应该因使用这些数据而获得某种补偿💸 剩下的问题是实现它的经济模型。一个很好的类比是音乐从 CD 到 Napster 再到 Spotify 的转变。或者从电影到 YouTube 视频的转变。未来数据是否存在类似的经济模型？ ⏳ 40:16 -- 2. 比尔·盖茨无法想象我们有一天会在计算机中需要千兆字节的内存💾 同样，我们可以&#39;今天，我们无法想象法学硕士如何或为何需要数十亿的上下文长度，但这仍然可能发生。 （对于上下文：具有 10 亿上下文长度的法学硕士意味着它可以处理和理解每个查询的约 200 万个文档页） ⏳ 51:13 --  “我想赋予 ChatGPT 保留记忆的能力”📝  想象一下，一个模型会逐渐了解您并随着时间的推移对您变得更加有用。这很可能是上面强调的十亿上下文长度 LLM 的一个用例。 ⏳ 55:33 --  计算将成为未来的货币。 💲  Sam 相信它将成为世界上最珍贵的商品。 ⏳ 1:09:55 --  核聚变将解决“能源问题”⚛  由于未来世界需要大量的计算，我们将需要大量的能源来为一切提供动力。 Sam 相信核聚变是解决这个问题的最佳方法。 ⏳ 1:11:29 --  Q- star 可能存在（但我们不会谈论这个）⭐  Lex 当然询问了 Q-star，但 Sam 并没有否认它的存在- 只是说“我们还没有准备好谈论这个”。 ⏳ 1:02:36 --  程序员不会过时👩🏻‍💻  但它可能会与现在的编程方式有所不同。不管怎样，萨姆认为没有人真正进行纯粹的编码——因为大多数程序员使用预先存在的软件包/技术/软件。利用 LLM 协助编码的方式与此类似。 ⏳ 1:29:50 --  超越 Google很无聊🔍  OpenAI 不想做一个更好的搜索引擎；以这种方式思考低估了他们在人工智能方面的工作。 ⏳ 1:17:37 --  “ ChatGPT 中不会有广告！” （最好）🚩  Sam 对广告有偏见 - 这就是为什么目前 ChatGPT 的商业模式是通过付费进行的。在某种程度上，我觉得这令人放心 - 因为当你引入广告时，你的“真正的客户”现在就变成了广告商，而不是实际的用户（现在变成了产品）。 ⏳ 1:20： 15 --  我们不再谈论 AGI（让我们称之为别的东西吧）🧠 &lt; /ol&gt; 人们对于 AGI 是什么有不同的定义，因此 Sam 主张更多地谈论具体的功能，而不是把 AGI 作为一个通用术语。不过，根据他的定义，AGI 是一个无需人类干预即可推进科学发现的系统。 ⏳ 1:32:33    ;由   提交 /u/SwimIndependent6688   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1blnzj1/d_i_listened_to_sam_altmans_most_recent_2hour/</guid>
      <pubDate>Sat, 23 Mar 2024 09:15:03 GMT</pubDate>
    </item>
    </channel>
</rss>