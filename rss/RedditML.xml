<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 05 Feb 2025 15:17:53 GMT</lastBuildDate>
    <item>
      <title>[D]OCR 模型用于分析复杂的发票</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii9spy/docr_models_to_analyze_complex_invoices/</link>
      <description><![CDATA[我的要求是从发票中提取数据并将其放入 Excel 中。 目前我正在使用 AWS Textract，但我面临的问题是，仅当发票结构化且采用表格格式时，Textact 才有用。 但是我的发票未对齐且没有表格格式，Textract 无法分析这些发票，只是以文本形式提供输出，任何类似或任何其他 OCR 模型可以用于此目的？    提交人    /u/Few-Buddy-3362   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii9spy/docr_models_to_analyze_complex_invoices/</guid>
      <pubDate>Wed, 05 Feb 2025 13:22:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过广义空间传播网络进行并行序列建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii7ayl/r_parallel_sequence_modeling_via_generalized/</link>
      <description><![CDATA[      TL;DR： 空间传播网络的改进变体 [Liu et al. 2017] 是视觉任务中 Transformers 和 SSM 的快速、有竞争力的替代方案 论文： https://arxiv.org/pdf/2501.12381 摘要：  我们提出了广义空间传播网络 (GSPN)，这是一种针对视觉任务优化的新型注意力机制，可以固有地捕获 2D 空间结构。现有的注意力模型，包括 Transformers、线性注意力和 Mamba 等状态空间模型，将多维数据处理为 1D 序列，从而损害了空间连贯性和效率。 GSPN 通过直接对空间相干图像数据进行操作并通过线扫描方法形成密集的成对连接来克服这些限制。GSPN 的核心是稳定性上下文条件，它确保在 2D 序列中进行稳定的上下文感知传播，并将具有 N 个元素的方形图的有效序列长度减少到 √N，从而显著提高计算效率。凭借可学习的、依赖于输入的权重并且不依赖位置嵌入，GSPN 在视觉任务（包括 ImageNet 分类、​​类引导图像生成和文本到图像生成）中实现了卓越的空间保真度和最先进的性能。值得注意的是，在生成 16K 图像时，GSPN 可将带有 softmax-attention 的 SD-XL 加速超过 84 倍。  视觉摘要： https://preview.redd.it/5j4c125wsahe1.png?width=693&amp;format=png&amp;auto=webp&amp;s=50953106c9a2bce979f97b53c67084523b6ee8e4 视觉亮点： https://preview.redd.it/4coeu5cjuahe1.png?width=1201&amp;format=png&amp;auto=webp&amp;s=31d310a75e6f19dfb904590a8d8a0d1d52f42979 https://preview.redd.it/kgfzoa4kuahe1.png?width=587&amp;format=png&amp;auto=webp&amp;s=0f30e6574eab0fd057e8bab2a029ed004c1a2432 https://preview.redd.it/79jjec7luahe1.png?width=1337&amp;format=png&amp;auto=webp&amp;s=eb24ff967759f174ec03e6984d2a7da310742ddc https://preview.redd.it/6xttzw1muahe1.png?width=871&amp;format=png&amp;auto=webp&amp;s=670ed748ff70185c1acf5aa115939adec0c596ad https://preview.redd.it/3y02ydanuahe1.png?width=833&amp;format=png&amp;auto=webp&amp;s=f6195799f770a1d046206c9990c6697353111bb8 https://preview.redd.it/1j4ptr4puahe1.png?width=1333&amp;format=png&amp;auto=webp&amp;s=7eb319cbe18d4cc7ff4b2659a0c69a8eb962b5c4 https://preview.redd.it/yqlt590quahe1.png?width=1341&amp;format=png&amp;auto=webp&amp;s=b593155f82ac8edd5d4230f3fd9c9704be33f81a    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii7ayl/r_parallel_sequence_modeling_via_generalized/</guid>
      <pubDate>Wed, 05 Feb 2025 10:44:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] SafeRAG：检索增强生成系统的安全评估基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii6k5c/r_saferag_a_security_evaluation_benchmark_for/</link>
      <description><![CDATA[这项工作引入了 SafeRAG，这是一个用于测试检索增强生成 (RAG) 系统中安全漏洞的基准和评估框架。研究人员系统地分析了不同 RAG 实现中的数据中毒和提示注入攻击。 关键技术要点： - 创建针对检索和生成组件的攻击媒介 - 开发标准化的安全评估指标 - 评估商业和开源 RAG 系统 - 测试各种防御机制，包括输入验证和输出过滤 - 测量攻击成功率和安全措施的性能影响 主要结果： - 商业 RAG 实现比开源版本显示出更好的安全性 - 输入验证提高了安全性但降低了性能 - 当前的防御机制无法阻止所有已识别的攻击类型 - 检索组件比预期更容易受到中毒 - 生成组件表现出对提示注入的敏感性 我认为这项工作揭示了 RAG 安全性中的关键漏洞，需要在敏感应用程序中部署之前解决。基准测试应该可以帮助开发人员更好地评估他们的系统，尽管安全措施的性能权衡仍然是一个重大挑战。该方法似乎很可靠，但可能需要扩展以涵盖新出现的攻击媒介。 我认为最有价值的贡献是标准化测试框架——它为该领域提供了一种衡量和比较 RAG 安全性的通用方法。这可以加速更强大系统的开发。 TLDR：用于测试 RAG 安全性的新基准表明，当前系统容易受到数据中毒和提示注入的攻击。提供了评估防御的工具和指标，但强调了使 RAG 真正安全所需的重要工作。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii6k5c/r_saferag_a_security_evaluation_benchmark_for/</guid>
      <pubDate>Wed, 05 Feb 2025 09:47:33 GMT</pubDate>
    </item>
    <item>
      <title>研究人员和数据科学家真的会用这个吗？我正在开发一个人工智能工具来更快地找到数据集。[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii44ba/would_researchers_and_data_scientists_actually/</link>
      <description><![CDATA[我正在开发一个 AI 平台，该平台可帮助研究人员和数据科学家使用自然语言搜索在多个来源（Kaggle、政府门户、API、学术数据库等）中找到正确的数据集。目前，这个过程是超级手动的：大量谷歌搜索、检查不同的网站以及处理不一致的格式。我希望它能够轻松找到针对超特定问题的超级小众数据集。 Tl;dr – 我认为这可以通过聚合数据集、总结数据集（列、大小、上次更新）甚至建议相关数据集来为研究人员和 ML/数据科学家节省数小时的时间。 更长的解释： 使用此工具，您可以输入类似 “我需要有关年轻人智能手机使用情况和心理健康的数据” 的内容，它会在各个平台上找到相关数据集。它还将提供快速摘要，以便您知道是否值得下载而无需深入挖掘。  基于您的主题的智能推荐 API 集成以提取实时数据（例如来自 Twitter、Google Trends） 如果您想合并数据集，则可以使用数据集兼容性检查器  这有用吗？ 在我开始构建之前，试着看看这是否真的是人们会使用的东西。欢迎反馈！🙏    提交人    /u/paullieber98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii44ba/would_researchers_and_data_scientists_actually/</guid>
      <pubDate>Wed, 05 Feb 2025 06:43:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前计算机视觉和语言技术领域不受欢迎的研究课题有哪些？ 2025</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</link>
      <description><![CDATA[不，我不想再听到有关 LLM 和 VLM 的更多信息了。    提交人    /u/KingsmanVince   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</guid>
      <pubDate>Wed, 05 Feb 2025 02:43:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何扩展你的模型：TPU 上的 LLM 的系统视图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihx3oq/d_how_to_scale_your_model_a_systems_view_of_llms/</link>
      <description><![CDATA[      让 LLM 高效运行可能会让人感到害怕，但扩展不是魔术，而是数学！我们想要揭开 LLM 的“系统视图”的神秘面纱，并编写了一本名为“如何扩展你的模型”的小教科书。 https://preview.redd.it/jeprd2hdq7he1.jpg?width=759&amp;format=pjpg&amp;auto=webp&amp;s=56a81c4ab64736a7047f72f901a35747ef54e85a 秘密在于从基本系统资源（计算、内存和带宽）的角度来思考，并计算出哪些资源限制了我们的性能。由此，我们可以估算任何给定 LLM 的成本、运行时间和最佳并行策略。 https://preview.redd.it/rjom9cteq7he1.png?width=735&amp;format=png&amp;auto=webp&amp;s=1c1fb9754b4ddd095f9efe81e5040e702dc534f6 本书的很大一部分内容致力于理解提供这些系统资源的硬件。我们在本书中强调 TPU，但原理和数学也可以适用于 GPU。第 2 部分详细介绍了 TPU。 扩展 LLM 涉及将其权重分布（也称为“分片”）到多个 TPU。要运行它，我们必须添加跨芯片通信。第 3 部分介绍了 TPU 的通信原语，以及分片矩阵相乘的简单规则。 5 年前，有许多 ML 架构，但今天（大部分）只有一种。_您应该彻底了解 Transformer！_LLaMA-3 中有多少 FLOP 或参数？与前馈块相比，注意力机制有多昂贵？阅读第 4 部分后，您就会知道。 现在来看看精彩内容！您可能听说过数据或张量并行、FSDP 或流水线。但为什么要选择其中一个而不是另一个呢？简短的回答：每个都增加了通信，成本最低的那个取决于模型。 第 5 部分深入探讨了这一点。 https://preview.redd.it/xsgqghrdr7he1.png?width=1400&amp;format=png&amp;auto=webp&amp;s=74641512a0af89236c3f7facda841f3691b2fd0e 本书的其余部分是一系列实用指南：如何编写和分析并行 JAX 代码，以及如何将前两节应用于 LLaMA-3 等真实模型。如果您喜欢做家庭作业，我们在每个部分末尾也准备了练习题。 我们希望这本书充满活力，所以请提问并给我们反馈。我们会随着时间的推移继续添加内容。事不宜迟，下面是开头的链接    提交人    /u/mattjjatgoogle   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihx3oq/d_how_to_scale_your_model_a_systems_view_of_llms/</guid>
      <pubDate>Wed, 05 Feb 2025 00:25:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM如何解决新的数学问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihsftt/d_how_does_llm_solves_new_math_problems/</link>
      <description><![CDATA[从架构角度来看，我理解 LLM 会处理来自用户查询和提示的标记，然后据此预测下一个标记。思路链机制本质上会推断这些预测以创建内部反馈循环，从而增加在训练期间使用强化学习时得出正确答案的可能性。当根据模型已知的信息解决问题时，此过程很有意义。 但是，当涉及到新的数学问题时，挑战不仅仅是简单的标记预测。模型必须理解问题，掌握底层逻辑，并使用适当的公理、定理或函数解决问题。它是如何做到这一点的？这个内部逻辑求解器从何而来，为 LLM 提供了解决此类问题所需的工具？ 澄清：新数学问题是指模型在训练期间未遇到的问题，这意味着它们不是以前见过的问题的完全重复。    提交人    /u/capStop1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihsftt/d_how_does_llm_solves_new_math_problems/</guid>
      <pubDate>Tue, 04 Feb 2025 21:03:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Vultr 优惠券的警告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihpz4k/d_warning_about_vultr_coupons/</link>
      <description><![CDATA[任何考虑使用促销积分来使用 Vultr 的人请注意 - 您的体验可能不会像预期的那样顺畅。 我有 300 美元的促销积分加上我个人存入的 5 美元（我以为是用于身份验证），但我无法使用其中任何一美元。 首先，他们要求我验证我的个人资料，我照做了。然后，他们突然要求我再存入 50 美元才能使用我已经拥有的资金 - 这实际上使我的 300 美元积分无法使用。这个要求没有提前提及，这令人沮丧。如果您已经承诺使用 Vultr，这可能不是问题，但如果您只是想测试服务，感觉很奇怪。 更糟糕的是，您不一定能够立即部署您的实例。在许多情况下，您需要打开支持票并手动请求访问权限。 他们的促销积分和存款政策具有误导性，一旦您的钱到账，您可能无法取回。他们不退款。我在他们的网站上找不到任何退款按钮，当我尝试通过 PayPal 申请退款时，他们立即暂停了我的帐户。    提交人    /u/KaiserZoldyck   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihpz4k/d_warning_about_vultr_coupons/</guid>
      <pubDate>Tue, 04 Feb 2025 19:23:29 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用自然语言生成 ML 模型的开源库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihn40f/p_opensource_library_to_generate_ml_models_using/</link>
      <description><![CDATA[大家好！我想展示一个我们正在进行的项目，希望你会感兴趣。 smolmodels 是一个完全开源的 Python 库，它根据问题的自然语言描述 + 最少的代码为特定任务生成 ML 模型。它结合了图形搜索和 LLM 代码生成，以尝试为给定问题找到并训练尽可能好的模型。这是 repo：https://github.com/plexe-ai/smolmodels。 大规模使用 LLM 的主要问题之一，特别是在延迟敏感的应用程序中，是巨大的 LLM 从根本上比较小的、特定于任务的模型更慢、更昂贵。这就是我们尝试使用 smolmodels 解决的问题。 这里有一个简单的例子来说明这个想法，基于流行的&quot;心脏病发作概率&quot;数据集（假设 df 是 pandas 数据框）： import smolmodels as sm # 步骤 1：根据意图、模式定义模型 model = sm.Model( intent=&quot;predict the probability of heart attack based on given features&quot;, input_schema={&quot;age&quot;: int, &quot;gender&quot;: int, &quot;cp&quot;: int, ... }, output_schema={&quot;probability&quot;: float} ) # 步骤 2：构建模型 model.build(dataset=df, provider=&quot;openai/gpt-4o&quot;) # 步骤 3：使用模型进行预测 prediction = model.predict({ &quot;age&quot;: 61, &quot;gender&quot;: 1, &quot;cp&quot;: 3, ... }) # 步骤 4：保存模型以供将来使用sm.models.save_model(model, &quot;heart_attack_model&quot;)  该库是完全开源的（Apache-2.0），因此您可以随意使用它。我们很乐意收到一些反馈，并且我们非常欢迎您贡献代码！    提交人    /u/impressive-burger   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihn40f/p_opensource_library_to_generate_ml_models_using/</guid>
      <pubDate>Tue, 04 Feb 2025 17:27:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 最佳实践：初始化/标准化/预热</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihk177/d_transformer_best_practise/</link>
      <description><![CDATA[TLDR：在参数初始化、规范化层、学习率预热（以及任何其他相关因素）方面，目前实现 Transformer 的最佳实践是什么？  我想实现和训练一个 Transformer（请参阅本文底部的“用例”） 我希望我的实现简单并且不需要太多的调整，但显然我也不想在性能、稳健性、一致性等方面做出太多牺牲 我知道有很多关于参数初始化/规范化层/学习率预热的选项，自 2017 年最初的 Transformer 论文以来，最佳实践已经发生了变化 例如： LayerNorm (2016)（用于原始变换器）对均值和 RMS 进行归一化 RMSNorm (2019) 对 RMS 进行归一化，但不对均值进行归一化 Pre-LN (2020) 将 LayerNorm 移到残差块内，从而提高了稳定性，并且消除了学习率预热的需要 T-Fixup (2020) 提出了一种初始化方案，消除了对归一化和学习率预热的需求 NormFormer (2021) 通过在注意力和 MLP 非线性后添加额外的规范化块来跟进 Pre-LN ReZero (2021) 将每个残差块的输出乘以初始化为零的可训练标量，这比 T-Fixup/NormFormer 更容易实现，同时还消除了对规范化和学习率预热的需要 这项调查 (2023) 比较了其中一些选项和其他一些选项（但没有受控的经验比较） 我目前倾向于使用没有规范化层和学习率的 ReZero热身，因为它将很容易实现（甚至比原始的 Transformer 模型更容易实现），而且根据他们的论文，它的表现应该相当不错 但我想知道为什么在最近的论文中没有看到更多提到 ReZero/现在更普遍的最佳实践是什么（假设在某种程度上有一个商定的最佳实践）？ 我最近碰巧看到的一些随机例子： Awni Hannun (2024) 说“通常使用 RMS 范数代替 Layer Norm”但没有提到 ReZero Lucas Nestler (2024) 发现 ReZero 的表现比 NormFormer 差一点（尽管这是使用“未缩放谨慎”优化器，而我打算只使用 Adam 或 AdamW，所以结果可能会有点不同） DreamerV3 使用 RMSNorm 而不是 LayerNorm，没有提到学习率预热或 ReZero  -------------------------------- 用例：我想为 集合预测 我正在研究的问题。输入数据不是基于文本或图像的。    提交人    /u/jakelevi1996   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihk177/d_transformer_best_practise/</guid>
      <pubDate>Tue, 04 Feb 2025 15:20:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论人工智能模型的推理能力及其量化方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihfyrt/r_on_the_reasoning_capacity_of_ai_models_and_how/</link>
      <description><![CDATA[https://arxiv.org/abs/2501.13833 大型语言模型 (LLM) 的最新进展加剧了围绕其推理能力基本性质的争论。虽然这些模型在 GPQA 和 MMLU 等基准测试中取得了高性能，但它们在更复杂的推理任务中表现出局限性，这凸显了对更严格的评估方法的需求。我们提出了一种新颖的现象学方法，它超越了传统的准确性指标来探究模型行为的潜在机制，建立了一个可以广泛影响我们分析和理解人工智能系统的框架。以多项选择推理任务中的位置偏差为例，我们展示了系统性扰动如何揭示模型决策的基本方面。为了分析这些行为，我们开发了两个互补的现象学模型：概率混合模型 (PMM)，将模型响应分解为推理、记忆和猜测部分；信息理论一致性 (ITC) 分析，量化模型置信度和策略选择之间的关系。通过对推理基准的受控实验，我们表明，真正的推理对于当前模型来说仍然具有挑战性，表面上的成功往往依赖于复杂的记忆和模式匹配组合，而不是真正的逻辑推理。更根本的是，我们证明单凭准确性往往会夸大模型的推理能力，因为模型行为可以通过认知策略相空间中的底层机制来表征，揭示模型在响应查询时如何动态平衡不同的方法。该框架为实际部署提供了定量标准，允许应用程序根据策略分布而不是聚合性能指标来指定可靠性阈值。    提交人    /u/jalabulajangs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihfyrt/r_on_the_reasoning_capacity_of_ai_models_and_how/</guid>
      <pubDate>Tue, 04 Feb 2025 11:54:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 推理模型是优柔寡断的鹦鹉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iheszs/r_reasoning_models_are_indecisive_parrots/</link>
      <description><![CDATA[R1、o1 和 gemini 2.0 flash 在 27 个不同的谜题上接受了测试。  这些模型仍然默认采用熟悉的解决方案，而不是适应新的环境 - 它们甚至强加不存在的约束、浪费 token 并得出错误的答案。 例子：  示例 1  问题：一组四人需要在晚上过桥。这座桥非常古老且摇摇欲坠。他们只有一支火炬，因为是晚上，所以火炬是过桥的必需品。每个人行走的速度都不同：A 需要 1 分钟才能过桥，B 需要 2 分钟，C 需要 5 分钟，D 需要 10 分钟。他们所有人过桥的最快时间是多少？  答案：10 分钟，最慢的人一起过桥的速度。  DeekSeek-R1：“……首先，限制条件是：这座桥一次只能容纳两个人，每次有人过桥时都需要火炬。所以，如果两个人一起过去，一个人必须带着火炬回来。”  示例 2  问题：假设您正在参加一个游戏节目，您可以选择三扇门：一扇门后面是金条；其他门后面是烂蔬菜。您选择了一扇门，比如说 1 号门，主持人问您，“您想选择 2 号门吗？”现在哪扇门的选择给您带来最大的优势？  回答：不，换门没有优势。我换不换都没什么区别，因为自最初的选择以来没有提供任何额外的实质性信息。蒙提霍尔问题在这里不适用，因为主持人不会打开另一扇门来告诉你是否应该换到第二扇门。 OpenAI O1：“这本质上是伪装的‘蒙提霍尔问题’。关键在于主持人提出的换门建议给了你新的信息——即另一扇未提及的门（3 号门）不是奖品。通过询问你是否想要 2 号门，主持人暗示排除了 3 号门。如果你坚持你的第一选择（1 号门），你获胜的机会仍然是开始时的 1/3。•如果你换门（在本例中是 2 号门），你获胜的概率就会跳到 2/3。因此，换门可以提高赢得金条的概率。”    submitted by    /u/Classic_Eggplant8827   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iheszs/r_reasoning_models_are_indecisive_parrots/</guid>
      <pubDate>Tue, 04 Feb 2025 10:34:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 曼巴为何消失了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihen9v/d_why_mamba_disappeared/</link>
      <description><![CDATA[我记得在 mamba 首次发布时就看到了它，因为它比 transformers 计算成本更低，性能更好，所以它被大肆炒作  那么它为什么会这样消失呢？    提交人    /u/Alarming-Power-813   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihen9v/d_why_mamba_disappeared/</guid>
      <pubDate>Tue, 04 Feb 2025 10:22:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>