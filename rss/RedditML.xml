<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 12 Mar 2024 12:23:20 GMT</lastBuildDate>
    <item>
      <title>[D] 使用强化学习改进法学硕士的答案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcvnd8/d_improve_llms_answers_using_reinforcement/</link>
      <description><![CDATA[将 LLM 视为环境和参与者，其中状态是问题和答案，操作是 LLM 生成的令牌，并且奖励是 log(tp)，其中 tp 是该令牌的概率。使用ε-贪婪策略或策略熵探索生成令牌的策略，然后使用PPO算法更新LLM和批评者网络。 PPO 算法将最大化返回 log(t1p) + γlog(t2p) + … + γn-1log(tnp)，其中 γ 是折扣因子，这相当于最大化概率 t1p*t2p … tnp 的乘积州，从而提高法学硕士的答案。   由   提交 /u/NoteDance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcvnd8/d_improve_llms_answers_using_reinforcement/</guid>
      <pubDate>Tue, 12 Mar 2024 12:06:40 GMT</pubDate>
    </item>
    <item>
      <title>[P]姿势估计的最佳模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcuwjo/pbest_model_for_pose_estimation/</link>
      <description><![CDATA[嗨！我正在尝试使用 flutter 在 Android 中制作一个虚拟锻炼助手应用程序......我很精通 flutter，但你可以猜到我在实现模型方面没有太多经验......所以你可以建议一个更准确且不难实现的姿势估计模型    ;由   提交/u/DeepLet4383  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcuwjo/pbest_model_for_pose_estimation/</guid>
      <pubDate>Tue, 12 Mar 2024 11:25:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为人工智能和数据科学专业的 CSE 寻求笔记本电脑推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bctyg8/d_seeking_laptop_recommendations_for_cse_majoring/</link>
      <description><![CDATA[大家好，我目前是工程专业的第二年，主修计算机科学，重点是人工智能和数据科学，现在将继续第三年。我需要一台电池续航时间长且能够运行 ML 模型的笔记本电脑。我不使用笔记本电脑玩游戏，我什至准备使用 Linux，并将 Web 开发作为一种爱好。此外，我正在寻找一台可以使用至少 4 年、具有能够支持最新库的硬件并且预算友好的笔记本电脑。谁能推荐一款满足这些要求的笔记本电脑？预先感谢您的帮助！   由   提交 /u/Lyriciseofficial   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bctyg8/d_seeking_laptop_recommendations_for_cse_majoring/</guid>
      <pubDate>Tue, 12 Mar 2024 10:26:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有针对应用研究的非技术同行评审期刊？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcqoa7/d_are_there_non_technical_peer_reviewed_journals/</link>
      <description><![CDATA[我今天正在看这篇论文 https://arxiv.org/abs/2403.04769 我缺乏发表纯理论机器学习论文的知识（也没有时间和精力真正深入该领域并赶上产生有意义的输出的水平）但我认为我有一些想法，并且有兴趣以发现漏洞的形式进行研究，或者以新颖的方式比较法学硕士或模型等。需要丰富的理论背景，并且具有不同技能的人更容易涉足其中。  与此同时，尽管我是一个完全不同领域的学者，但为了我的职业生涯，我需要在期刊上发表论文，而不仅仅是在 arxiv 上。所以我的问题是，像我上传的论文在实践中当然非常有用，但从科学角度讲，它们是否会在同行评审期刊上发表？如果是，在哪里？ 有兴趣听听您的想法和建议，提前致谢！   由   提交 /u/Dyoakom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcqoa7/d_are_there_non_technical_peer_reviewed_journals/</guid>
      <pubDate>Tue, 12 Mar 2024 06:41:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人可以澄清一下像 Perplexity、You.com 或 Coral Search 这样的网络搜索法学硕士是否正在自己抓取整个网络吗？否则，它们与简单地将搜索 API 与任何 LLM 模型结合起来有何不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcq8zy/d_can_someone_please_clarify_if_web_search_llms/</link>
      <description><![CDATA[如果他们自己爬行网​​络，有经验的人能否解释一下这项任务有多困难以及这些公司如何彼此区分，我看不到他们每个人提供的答案有多大差异？   由   提交 /u/Fit-Set6851    reddit.com/r/MachineLearning/comments/1bcq8zy/d_can_someone_please_clarify_if_web_search_llms/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcq8zy/d_can_someone_please_clarify_if_web_search_llms/</guid>
      <pubDate>Tue, 12 Mar 2024 06:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]扩散模型有表示学习吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcmvo1/discussion_do_diffusion_models_do_any/</link>
      <description><![CDATA[诸如 VAE 和基于转换器的语言模型（MLM 或自回归）之类的模型提取数据的高阶表示。对于DM是否这样做有任何了解吗？我见过的论文中似乎没有讨论这个问题，大概是因为重点太集中在生成方面。   由   提交/u/daking999  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcmvo1/discussion_do_diffusion_models_do_any/</guid>
      <pubDate>Tue, 12 Mar 2024 03:08:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 作为可优化图的语言代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bchke2/r_language_agents_as_optimizable_graphs/</link>
      <description><![CDATA[ 由   提交/u/hardmaru  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bchke2/r_language_agents_as_optimizable_graphs/</guid>
      <pubDate>Mon, 11 Mar 2024 23:10:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找具有共享价值查询注意力权重的论文。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcck5w/r_looking_for_paper_with_shared_valuequery/</link>
      <description><![CDATA[我可以发誓我在一年前浏览过一篇论文，该论文展示了变压器的相当可靠的性能，其中值和键（或查询）权重是每个注意力层内相同/共享。我认为 Linformer 做了类似的事情，但我并不是在寻找试图解决注意力的二次运行时间的东西，只是表明你可以通过共享值和键获得合理的结果。它甚至可能在这个 Reddit 子版块中被提及。不知怎的，我似乎找不到它......有人碰巧知道这一点，或者也许知道正确的搜索术语？   由   提交/u/benthe human_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcck5w/r_looking_for_paper_with_shared_valuequery/</guid>
      <pubDate>Mon, 11 Mar 2024 19:56:13 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]LSTM模型可以自己学习特征工程吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcc2oo/discussion_can_lstm_model_learn_feature/</link>
      <description><![CDATA[我有一个时间序列数据集，我正在其上训练 LSTM 模型以执行多类分类。 我的数据集有 7 列=&gt; x1,x2,x3....x7 并且有 4 个标签 =&gt; f1,f2,f3,f4 由于我对数据集具有领域知识，因此我确切地知道需要完成哪些特征工程。 ​ &lt; p&gt;例如，我需要通过在每一行应用一些规则来从当前功能创建 4 个新功能：-  newx1 由 =&gt; 创建if (x2==x3) then 1, else 0 newx2 由 =&gt; 创建if (x1==x4 and x1&gt;x5) then 1, else 0 newx3 由 =&gt; 创建if ((x1-x6)/x1&gt;x7) then 1, else 0 newx4 由 =&gt; 创建if ((x6-x1)x1/&gt;x7) then 1. else 0  ​ 我在测试数据上获得 100% 的准确度，如果我在 newx1、newx2、newx3、newx4 上训练我的 LSTM 模型。 但是，在原始特征 (x1,x2....x7) 上训练它时，我的准确度降低了 85-90%  我要解决的问题要求我的准确率高于 99%，因此仅 90% 的准确率是不够的。 &amp;# x200b; 我想知道我的 LSTM 模型是否可以自行学习特征工程的规则，或者我是否必须更改我的模型？ ​ 注意：我无法手动应用特征工程规则，因为我正在多个数据集上训练 LSTM 模型，并且每个数据集都需要自己的特征工程规则。我想让它尽可能通用。 ​ LSTM 模型 :- def create_lstm_model(MaxTimeslice, H, LR , num_classes, dropout_rate=0.1, l2_reg=0.001): ip = 输入(shape=(MaxTimeslice, H)) x = LSTM(32, return_sequences=True, dropout=dropout_rate, kernel_regularizer=l2(l2_reg))(ip) x = LSTM(16，dropout=dropout_rate，kernel_regularizer=l2(l2_reg))(x) x = Dense(units=16，activation=&#39;relu&#39;)(x) multiclass_output = Dense(units=num_classes，activation=&#39;softmax&#39;)( x) model = Model(inputs=ip,outputs=multiclass_output) model.compile(loss=&quot;categorical_crossentropy&quot;,metrics=[&quot;accuracy&quot;],optimizer=RMSprop(learning_rate=LR)) 返回模型 &lt; /pre&gt; ​   由   提交 /u/Fearless_Peanut_6092   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcc2oo/discussion_can_lstm_model_learn_feature/</guid>
      <pubDate>Mon, 11 Mar 2024 19:37:27 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 这是数据泄露的例子吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bca8h7/discussion_is_this_an_example_of_data_leakage/</link>
      <description><![CDATA[我正在开展一个研究项目，使用机器学习来尝试发现基因启动子的模式。我担心我们模型中的数据泄漏，但在我大力推动我的实验室改变我们的方法之前，我需要一些外部意见。也许这个社区中的某人可以帮助我更好地理解这个问题。 我们的机器学习模型是 L1 正则化逻辑回归模型，它使用序列模式作为特征来预测转录起始位点（TSS）的二进制结果）在基因组中。序列模式由上游工具在 TSS 旁边约 1000 个核苷酸的区域中检测到。由于许多 TSS 在基因组中紧密聚集（某些基因具有多个 TSS），因此这些序列区域通常与至少一个其他 TSS 序列区域重叠 &gt; 99%。我担心的是，如果我们对单个 TSS 进行训练/测试分割，我们将会出现数据泄漏，因为训练集中的许多示例将具有与测试集中的至少一个特征向量相关且高度相关的特征向量。我们对序列区域进行分箱只能在一定程度上缓解这种情况，因为偏移 5 nt 或更少的两个 100 核苷酸 (nt) 箱（在我们的数据集中并不罕见）将共享 ≥95% 的序列同一性。 以下几点让我认为我们存在数据泄漏：  我们的特征比示例更多，使得过度拟合变得更容易。在将训练集性能与测试集性能进行比较时，观察到了一点过度拟合。 两个 TSS 的居中、缩放特征的组内平均（在最大 5nt 间隔的连续簇中）皮尔逊相关系数为〜0.99。这不包括自我比较。组之间的平均相关性为 ~-0.0002。大约 35% 的 TSS 位于具有此距离阈值的某个集群中。 当 TSS 按最大 5nt 间隔的邻近度进行聚类时，如果测试集中的 TSS 与测试集中的任何 TSS 分组，则测试集中的 TSS 将被删除。训练集上，通过评估“清理过的”测试集，我们的 auROC 下降了约 3%。这可以用不同的随机种子来重现。如果我们使用 20nt 的阈值，性能会下降约 5%。 当我用随机 DNA 序列而不是基因组来生成特征时，但使用相同的 TSS 位置和整体方法（意味着序列重叠）仍然发生），模型达到了 70% 的 auROC。相比之下，如果我将最大距离为 20 nt 的 TSS 分组，并在进行训练/测试拆分之前删除每组中除一个 TSS 之外的所有 TSS，则我在随机基因组上获得约 53% 的 auROC，更接近于随机分类器。&lt; /li&gt;  我删除太接近的 TSS 的方案无疑是有缺陷的，因为我们失去了宝贵的例子。我认为保留所有 TSS 并按组拆分会更好，同时还能防止数据泄漏。据我了解，这相当于整群抽样，并且类似于患者层面的分裂，因为医学研究人员正在学习如何处理 MRI 切片等数据。在这种情况下，该方案是否无效/有害，或者它是否是防止数据泄露的正确选择？或者我们应该使用另一种分割方案？   由   提交/u/analyze_hunter  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bca8h7/discussion_is_this_an_example_of_data_leakage/</guid>
      <pubDate>Mon, 11 Mar 2024 18:24:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] Gemini 1.5 Pro如何回忆10M上下文中的信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</link>
      <description><![CDATA[Google 最近发布了技术报告 关于 Gemini 1.5 Pro 及其 10M 上下文。他们简要概述了提高模型长上下文能力的现代方法（例如循环记忆、环形注意力、新颖的架构等），但我没有找到有关 Gemini 1.5 Pro 方法的信息。 有人注意到官方出版物中有关他们方法的信息吗？这对我来说似乎是 Google 的秘密。   由   提交/u/Mulated-Witness-7196   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</guid>
      <pubDate>Mon, 11 Mar 2024 12:26:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] [2403.05468] GPT-4 会运行《DOOM》吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</link>
      <description><![CDATA[ 由   提交/u/blabboy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</guid>
      <pubDate>Mon, 11 Mar 2024 12:20:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] ShortGPT：大型语言模型中的层比您预期的更加冗余</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.03853 摘要：  随着大型语言模型（LLM）的性能不断进步，它们的规模显着扩大，当前的法学硕士包含数十亿甚至数万亿的参数。然而，在这项研究中，我们发现LLM的许多层表现出高度相似性，并且某些层在网络功能中发挥的作用可以忽略不计。基于这一观察，我们定义了一个名为区块影响力 (BI) 的指标来衡量法学硕士中每一层的重要性。然后，我们提出了一种直接的修剪方法：层删除，其中我们根据 LLM 的 BI 分数直接删除其中的冗余层。实验表明，我们的方法（我们称之为 ShortGPT）在模型剪枝方面显着优于之前最先进的 (SOTA) 方法。此外，ShortGPT 与类量化方法正交，可以进一步减少参数和计算量。与更复杂的修剪技术相比，通过简单的层删除可以获得更好的结果，这表明模型架构中存在高度冗余。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</guid>
      <pubDate>Mon, 11 Mar 2024 11:41:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 立场文件：人工智能代理迈向整体智能 - Microsoft 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbz4z8/r_position_paper_agent_ai_towards_a_holistic/</link>
      <description><![CDATA[      论文：https:/ /arxiv.org/abs/2403.00833  摘要：  大型基础模型的最新进展显着增强了我们对开放世界环境中感官信息的理解。在利用基础模型的力量时，人工智能研究必须摆脱过度还原论，转而强调作为有凝聚力的整体的系统。具体来说，我们强调开发人工智能代理——一种将大型基础模型集成到代理操作中的体现系统。代理人工智能的新兴领域涵盖了广泛的现有体现和基于代理的多模式交互，包括机器人、游戏和医疗保健系统等。在本文中，我们提出了一种新颖的大型动作模型实现体现智能行为，代理基础模型。除此之外，我们还讨论了智能体如何在各种领域和任务中展现出卓越的能力，挑战我们对学习和认知的理解。此外，我们从跨学科的角度讨论智能体人工智能的潜力，强调科学话语中的人工智能认知和意识。我们相信这些讨论可以作为未来研究方向的基础，并鼓励更广泛的社会参与。   https:// /preview.redd.it/h8m0ucns7onc1.jpg?width=1228&amp;format=pjpg&amp;auto=webp&amp;s=1cfc94db64f9f358b07353de285faefa5c8ca1a0 https ://preview.redd.it/rjo7pdns7onc1.jpg?width=927&amp;format=pjpg&amp;auto=webp&amp;s=a0728939d5a83c32811c2efbdff9b5a6d58f023f https://preview.redd.it/ng16dfns7onc1.jpg?width=487&amp;format=pjpg&amp;auto=webp ＆amp; ;s=72c6e46c75328cc39e606f149550c0fbf99115a3   由   提交/u/Singularian2501   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbz4z8/r_position_paper_agent_ai_towards_a_holistic/</guid>
      <pubDate>Mon, 11 Mar 2024 09:26:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>