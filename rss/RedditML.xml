<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 12 Sep 2024 15:16:23 GMT</lastBuildDate>
    <item>
      <title>[D] 如何防止基于 LLM 的文本到 SQL 项目中的 SQL 注入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ff1y95/d_how_to_prevent_sql_injection_in_llm_based_text/</link>
      <description><![CDATA[我正在从事数据分析项目，该项目是为高管级别构建的。随着基于聊天 GPT 的交互的增长，他们想要类似的功能，但针对的是财务数据。例如，他们可以问“本季度最赚钱的银行是哪家？”，他们需要银行列表和进一步的可视化。我计划使用 MySQL db 结构、问题和相关查询来训练 LLM，进展顺利。但我认为这种方法容易受到 SQL 注入攻击。例如，“从利润表中删除所有内容。”提示可能会生成 SQL 查询来删除表或截断表。我知道，我们可以限制包含删除、截断的一些命令的执行，但我仍然看到各种问题。有什么解决办法吗？    提交人    /u/More_Lawfulness_6862   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ff1y95/d_how_to_prevent_sql_injection_in_llm_based_text/</guid>
      <pubDate>Thu, 12 Sep 2024 12:59:12 GMT</pubDate>
    </item>
    <item>
      <title>希望大家对我的计算机视觉想法提出一些反馈！自助式合成图像 API [P] [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fez8ou/want_some_feedback_for_my_computer_vision_idea/</link>
      <description><![CDATA[作为副业，为了简化日常工作中的一些工作，我正在努力构建一个自助式合成图像 API，该 API 使用 Stable Diffusion XL、Flux 等，以便计算机视觉工程师快速修改和增强他们的训练数据。目标是帮助我（以及其他人）减少数据漂移，快速且廉价地获取新图像并提高迭代速度，同时希望提高模型性能。生成的图像将保留现有标签。  首先，我考虑进行一些初步修改：  可控的照明变化 天气变化（雨、雪、太阳等） 一天中的时间变化（白天、傍晚、夜晚等） 添加遮挡和照明耀斑 还有更多  我有很多关于如何进一步扩展的想法，但是在构建这个初始原型时，我很好奇反馈。你认为人们会为此付费吗，为什么或为什么不？你认为这有用吗？想要一些对我的计算机视觉想法的反馈！自助合成图像 API 提前感谢您的反馈！    提交人    /u/milaapmehta27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fez8ou/want_some_feedback_for_my_computer_vision_idea/</guid>
      <pubDate>Thu, 12 Sep 2024 10:27:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用多模态模型从卫星图像中进行文本描述：已经完成了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fez7rq/d_textual_descriptions_from_satellite_images/</link>
      <description><![CDATA[我在想是否可以使用多模态模型根据特定参数（例如土壤湿度）生成图像的文本描述。数据可能是来自卫星或无人机的遥感图像。 图像数据：RGB 参数数据：2D 数组，其中每个元素对应于相应像素的参数值。 这已经实现了吗？是否有任何模型可以很好地解决此类问题？任何见解或建议都将不胜感激！ 提前致谢！    提交人    /u/MrGolran   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fez7rq/d_textual_descriptions_from_satellite_images/</guid>
      <pubDate>Thu, 12 Sep 2024 10:26:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] 向量搜索很慢</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fey1mq/p_vector_search_is_slow/</link>
      <description><![CDATA[我的矢量数据库中存储了 50 个图像嵌入 (dinov2)。我想检索与查询图像最相似的前 3 张图像。基于这 3 张相似的图像，我将执行 Superpoint 特征提取并进行 lightglue 特征匹配。我希望将其部署为应用程序。但不幸的是，我的矢量搜索检索前 3 个结果非常慢。我不知道我哪里做错了。我的嵌入与包含特征和描述符的有效载荷一起保存。检索前 3 个相似匹配需要 4 秒以上。然后使用 lightglue 匹配图像也需要一段时间。我该如何加快速度。我的最终目标是图像认证。我的矢量搜索中是否遗漏了某些内容，或者我应该选择其他方法..    提交人    /u/PositiveResponse7678   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fey1mq/p_vector_search_is_slow/</guid>
      <pubDate>Thu, 12 Sep 2024 09:03:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 推荐的 LIDAR/图像标记平台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fexatj/d_p_recommended_lidarimage_labeling_platforms/</link>
      <description><![CDATA[大家好，我希望这是一个寻求建议和推荐的好地方。 我们正在为我们的图像和激光雷达数据（汽车项目）寻找一个标签平台 对于我们来说，这个平台可以随着项目的发展而扩展，这一点很重要。 平台提供以下功能非常重要：1. 自动化和有用的标签功能 2. 激光雷达和图像融合 3. 直接访问存储在云中的数据（图像直接下载到平台，标签直接上传回云端。） 有什么建议吗？    提交人    /u/punims   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fexatj/d_p_recommended_lidarimage_labeling_platforms/</guid>
      <pubDate>Thu, 12 Sep 2024 08:06:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 更新了论文提交 [NeurIPS 2024 研讨会]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fex05d/d_updated_paper_submission_neurips_2024_workshop/</link>
      <description><![CDATA[大家好。 抱歉问了一个菜鸟问题。 基本上，我们已经在 NeurIPS 2024 的研讨会上提交了一篇论文。这是我们本科期间的第一份工作。提交后，第二天我们收到一封电子邮件，说有一个边距问题需要修复，否则我们的提交将被拒绝。我们修复了这个问题 [一个非常无意的错误]，并从那时起尝试提交，但在 Openreview 中，它一直说邀请提交已过期。那么对于这种情况，我们是否有任何截止日期必须遵守。主要审查将在下个月进行。我们曾尝试联系他们，但没有收到任何回复。    提交人    /u/Ok-Reflection-4049   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fex05d/d_updated_paper_submission_neurips_2024_workshop/</guid>
      <pubDate>Thu, 12 Sep 2024 07:44:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] [R] 寻求帮助将 NLP 模型应用于使用 Python 创建的 Excel 文件，该文件的数据来自医学 Subreddit 页面</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fewafy/p_r_looking_for_help_applying_nlp_models_to_an/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fewafy/p_r_looking_for_help_applying_nlp_models_to_an/</guid>
      <pubDate>Thu, 12 Sep 2024 06:50:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] [R] 如何获取本文使用的数据？我对量化相关问题还不熟悉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fevji3/p_r_how_to_obtain_the_data_used_on_this_paper_i/</link>
      <description><![CDATA[我打算根据这篇论文进行研究，所用的数据来自过去 10 年的 dukascopy，我进入了网站数据馈送，但对获取数据时应选择的设置感到困惑，而且我下载的少量数据似乎与我从 yfinance 获取的数据不同 有人能告诉我 1. 我应该从数据馈送中选择哪些具体设置才能获取本文中提到的解释变量的精确数据？ 2. 为什么同一个变量的数据和 yfinanace 的数据不一样？ 论文名称：基于计量经济学和机器学习的天然气实际波动率混合建模 https://jfin-swufe.springeropen.com/articles/10.1186/s40854-023-00577-0#availability-of-data-and-materials 使用的解释变量是美元计价的 XAU、BRENT 期货价格、标准普尔 500 (SPX) 和欧元。之所以选择 XAU，是因为黄金在危机时期被用作避难所，并且是经济表现不佳的预测指标。选择 SPX 是因为它可以很好地预测美国和世界经济表现。当能源价格上涨时，欧元可以作为缓冲或抑制通货膨胀的影响。布伦特原油是天然气的能源替代品，原因有二：替代和经济趋势的联动。 这些变量的所有高频数据均从 www.dukascopy.com 中提取。这些变量以 5 分钟为间隔进行采样，以计算每日实际波动率。对于每个变量，根据公式 1 计算实际波动率。 分析的时间段为 2012 年 9 月 3 日至 2022 年 1 月 31 日（977,497 个日内观察值和 2724 个每日观察值，不包括非工作日）    提交人    /u/Silver-Highlight-813   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fevji3/p_r_how_to_obtain_the_data_used_on_this_paper_i/</guid>
      <pubDate>Thu, 12 Sep 2024 05:59:10 GMT</pubDate>
    </item>
    <item>
      <title>Jamba 设计政策 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fems4c/jamba_design_policy_r/</link>
      <description><![CDATA[有人知道 Jamba 的作者是如何确定将注意力层放在 Jamba 块中的位置的吗？我通读了论文，但找不到任何相关信息。他们只讨论了注意力与曼巴层的比例。    提交人    /u/Fair-Donut2650   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fems4c/jamba_design_policy_r/</guid>
      <pubDate>Wed, 11 Sep 2024 22:16:17 GMT</pubDate>
    </item>
    <item>
      <title>AdEMAMix-您觉得怎么样？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fegu5k/ademamix_what_do_you_think/</link>
      <description><![CDATA[这似乎是一种简单的改进，收敛速度更快，最小值更低。你看到任何缺点了吗？    提交人    /u/Status-Shock-880   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fegu5k/ademamix_what_do_you_think/</guid>
      <pubDate>Wed, 11 Sep 2024 18:06:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 有没有什么有希望的途径可以实现高效的机器学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fefhrz/d_r_are_there_any_promising_avenues_for_achieving/</link>
      <description><![CDATA[看来，目前大规模基础模型的现状是，这些模型拥有数十亿（很快将是数万亿）个参数，几乎在整个互联网上进行训练，正在达到收益递减点，甚至可能接近渐近线（为了讨论，我们至少假设这一点）。训练和提供此类模型也需要巨大的成本。这推动了高效 ML 的发展：软件和硬件旨在以更低的成本在更少的数据上训练较小的模型，而不会影响性能和能力。该领域目前的 SOTA 是什么？是否有比其他途径更有希望？ 编辑：我希望讨论围绕高效神经网络展开。不仅限于 LLM。    提交人    /u/worstthingsonline   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fefhrz/d_r_are_there_any_promising_avenues_for_achieving/</guid>
      <pubDate>Wed, 11 Sep 2024 17:11:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 冷扩散：无噪声反转任意图像变换</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fec2jq/d_cold_diffusion_inverting_arbitrary_image/</link>
      <description><![CDATA[大家好， 这篇文章的目的不是责怪作者，我只是对审查过程感到非常惊讶。 我刚刚偶然发现了这篇论文。虽然我发现这些想法有点有趣，但我发现整体结果和理由非常薄弱。 它显然被 ICLR2022 拒绝了，主要是因为缺乏任何理论依据。https://openreview.net/forum?id=slHNW9yRie0 同一篇论文在 NeurIPS2023 上重新提交，我不骗你，这篇论文被接受为海报。 https://openreview.net/forum?id=XH3ArccntI 我真的不明白它是如何通过 NeurIPS 的审查过程的。整个事情非常初步，基本上只是由实验组成。 它甚至缺少其他非常密切相关的工作的引用，例如具有逆热耗散的生成建模 https://arxiv.org/abs/2206.13397，这基本上是他们的“模糊扩散”但具有理论背景和更好的结果（被 ICLR2023 接受）... 我以为 NeurIPS 与 ICLR 处于同一水平，但现在在我看来，有时论文只是被随机接受。 所以我想知道，是否有人对此有意见，或者您是否遇到过其他类似的情况？    提交人    /u/Commercial_Carrot460   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fec2jq/d_cold_diffusion_inverting_arbitrary_image/</guid>
      <pubDate>Wed, 11 Sep 2024 14:52:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 谁是好孩子？Metropolis-Hastings 方法用于确定来源不明的寄养狗名字</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdzemt/r_whos_a_good_boy_a_metropolishastings_approach/</link>
      <description><![CDATA[  由    /u/TobyWasBestSpiderMan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdzemt/r_whos_a_good_boy_a_metropolishastings_approach/</guid>
      <pubDate>Wed, 11 Sep 2024 02:18:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 08 Sep 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>