<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Tue, 20 Aug 2024 06:22:01 GMT</lastBuildDate>
    <item>
      <title>[R] PEDAL：使用多样化样本通过大型语言模型增强贪婪解码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ewju22/r_pedal_enhancing_greedy_decoding_with_large/</link>
      <description><![CDATA[https://arxiv.org/abs/2408.08869    提交人    /u/Either_Pea7803   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ewju22/r_pedal_enhancing_greedy_decoding_with_large/</guid>
      <pubDate>Tue, 20 Aug 2024 02:01:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无根基对齐问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ewfafd/r_the_ungrounded_alignment_problem/</link>
      <description><![CDATA[  由    /u/bregav  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ewfafd/r_the_ungrounded_alignment_problem/</guid>
      <pubDate>Mon, 19 Aug 2024 22:33:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们是否已经不再使用“微调”而改用“监督微调”了？或者是否存在其他微调范式方法。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ewezs4/d_have_people_stopped_saying_fine_tuning_in_place/</link>
      <description><![CDATA[我一直认为微调意味着我们可以进行监督。但如今，人们似乎都说“SFT”。很好奇历史是怎样的。    由   提交  /u/Seankala   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ewezs4/d_have_people_stopped_saying_fine_tuning_in_place/</guid>
      <pubDate>Mon, 19 Aug 2024 22:20:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 代理系统的自动化设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ew5eff/r_automated_design_of_agentic_systems/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ew5eff/r_automated_design_of_agentic_systems/</guid>
      <pubDate>Mon, 19 Aug 2024 15:56:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 深入 Transformers 和 LLM 世界 – 一步步了解 Go 中的 Llama 3.1</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ew2l3i/p_dive_into_transformers_and_llm_world_llama_31/</link>
      <description><![CDATA[我很高兴在此展示我的最新开源项目的更新版本：Llama Nuts and Bolts。上一个版本是为 Llama 2 构建的，现在已更新为支持 Llama 3.1 8B-Instruct 模型。 代码和文档：https://github.com/adalkiran/llama-nuts-and-bolts 现在，文档也可以在 Github Pages 上找到：https://adalkiran.github.io/llama-nuts-and-bolts 如果您像我一样对 LLM（大型语言模型）和转换器的工作原理感到好奇，并且已经深入研究了源代码中的概念解释和示意图，但渴望更深入的理解，那么这个项目也非常适合您！ 您不仅可以找到 Llama 架构的细节，将在文档目录中找到各种相关概念的解释。从逐字节读取 Pickle、PyTorch 模型、Tiktoken 标记器模型文件，到 BFloat16 数据类型的内部结构、从头开始实现 Tensor 结构以及包括线性代数计算在内的数学运算。 该项目最初是为了通过运行和调试来了解 LLM 背后的作用，并且仅用于实验和教育目的，而不是用于生产用途。 目标是制作一个实验项目，可以完全在 Python 生态系统之外（使用 Go 语言）对 Llama 3.1 8B-Instruct 模型执行推理。在整个旅程中，目标是获取知识并阐明这项技术的抽象内部层。 这次旅程是一次有意重新发明轮子的旅程。在阅读文档中的旅程时，您将通过 Llama 模型的示例了解大型语言模型的工作原理。 如果您查看它，我会很高兴，欢迎发表评论！    提交人    /u/adalkiran   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ew2l3i/p_dive_into_transformers_and_llm_world_llama_31/</guid>
      <pubDate>Mon, 19 Aug 2024 14:01:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 了解 Transformers 和 LLM 的图解书</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ew1hws/p_illustrated_book_to_learn_about_transformers/</link>
      <description><![CDATA[      我在这个 subreddit 上看到过好几个人对 Transformers 和 LLM 内部工作原理的长篇解释感兴趣的例子。 这是我和我双胞胎兄弟在过去三年半里一直试图填补的空白。上周，我们发表了“超级学习指南：Transformers &amp;大型语言模型”，这是一本 250 页的书，包含 600 多幅插图，面向对该领域有浓厚兴趣的视觉学习者。 本书深入介绍了以下主题：  基础：神经网络入门以及用于训练和评估的重要深度学习概念。 嵌入：标记化算法、词嵌入（word2vec）和句子嵌入（RNN、LSTM、GRU）。 Transformers：其自注意力机制背后的动机、编码器-解码器架构的详细概述以及相关变体（如 BERT、GPT 和 T5），以及如何加速计算的技巧和窍门。 大型语言模型：调整基于 Transformer 的模型的主要技术，例如即时工程、（参数高效的）微调和偏好调整。 应用：最常见的问题，包括情感提取、机器翻译、检索增强生成等等。  （如果您想知道：此内容与我们 5-6 年前在此 subreddit 上分享的斯坦福插图学习指南的氛围相同，关于 CS 229：机器学习、CS 230：深度学习 和 CS 221：人工智能) 学习愉快！ https://preview.redd.it/n6zraaltemjd1.jpg?width=1905&amp;format=pjpg&amp;auto=webp&amp;s=1110f750df0d8a60d5fdf1d4967b41e1b5617efe    提交人    /u/shervinea   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ew1hws/p_illustrated_book_to_learn_about_transformers/</guid>
      <pubDate>Mon, 19 Aug 2024 13:14:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] AnyClassifier - 用于文本分类的合成数据生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ew12xp/p_anyclassifier_synthetic_data_generation_for/</link>
      <description><![CDATA[      我想与大家分享这一点，因为我认为对于大多数 ML 工程师和软件工程师来说，这将是一项宝贵的资源。 我创建了一个用于文本分类模块的合成数据生成。因此，即使没有数据集，也可以从头开始构建分类器。它在 5 个基准测试中使用合成数据获得了与使用真实数据相当的竞争结果。 https://preview.redd.it/rqyzrcbl1njd1.png?width=1704&amp;format=png&amp;auto=webp&amp;s=476804a719f8619b46fb35d88361583e285c777a 未来有许多开放的研究和实施：  对合成数据算法的研究导致更高的模型评估、误差分析和模型改进的代理工作流程 多语言支持  该项目采用 MIT 许可发布。如果您有兴趣，请尝试并做出贡献。 代码：https://github.com/kenhktsui/anyclassifier 详细博客：https://huggingface.co/blog/kenhktsui/anyclassifier 编辑：添加基准测试结果    提交人    /u/transformer_ML   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ew12xp/p_anyclassifier_synthetic_data_generation_for/</guid>
      <pubDate>Mon, 19 Aug 2024 12:56:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用卡尔曼滤波器实现 YOLO，用四旋翼飞行器跟踪一个人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evyx16/p_implemented_yolo_with_kalman_filter_do_track_a/</link>
      <description><![CDATA[大家好， 在我的论文中，我正在使用四旋翼飞行器跟踪移动物体（人、汽车等），同时避开障碍物（类似于 Skydio）。我实现了带有卡尔曼滤波器的 YOLO 来跟踪物体。 而且它工作正常。但是，我还想预测物体的轨迹（接下来的 N 帧）以支持四旋翼飞行器的运动规划。一个想法是通过人的姿势来预测人的轨迹。假设我可以检测到该人将右肩指向左侧，因此表明该人将开始向左移动。有没有关于这个主题的研究论文？    提交人    /u/Huge-Leek844   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evyx16/p_implemented_yolo_with_kalman_filter_do_track_a/</guid>
      <pubDate>Mon, 19 Aug 2024 11:02:52 GMT</pubDate>
    </item>
    <item>
      <title>大规模 GPU 训练云提供商建议 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evxzd8/advice_on_cloud_provider_for_large_scale_gpu/</link>
      <description><![CDATA[大家好，我目前正在通过 LLM 进行代码生成，考虑到手头的问题，我的团队必须对 LLM 进行大量微调和有时预训练实验。到目前为止，我们一直在使用 VastAI 满足我们的 GPU 相关要求，但有几次我们在训练约 3 周后丢失了检查点。因此，我们正在考虑选择不同的云服务提供商来满足我们的 GPU 相关要求。 对于像 CodeLlama 7B 这样的大型模型，我们使用 4 个 GPU 的集群进行并行训练，每个 GPU 有 48GB（可以达到 80）的 RAM。 选择时要考虑的要点： - 预安装的软件包（TensorFlow、PyTorch） - CUDA 版本 12 或更高版本。 - GPU（如 A100 节点），每个节点至少有 80GB 的 VRAM。 - 至少 250GB 的存储空间。  客户提出的选项 - AWS - Salad - Vultr - Scale ways 抱歉，如有错别字，敬请原谅。您的建议将对我们意义重大。谢谢    提交人    /u/Unlikely-Addition-42   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evxzd8/advice_on_cloud_provider_for_large_scale_gpu/</guid>
      <pubDate>Mon, 19 Aug 2024 10:03:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们要用随机值初始化神经网络以打破对称性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evwap1/d_why_we_initialize_the_neural_networks_with/</link>
      <description><![CDATA[我在 ANN 领域还没有那么多经验，所以我希望这个问题没有完全偏离图表 :) 我发现神经网络用随机值初始化其权重和偏差，以确保这些值不会在相同或对称的值上初始化。 我完全理解为什么它们不能相同 - 除了一个节点之外的所有节点都是多余的。 我无法理解的是为什么它们不能是对称的。我在 YouTube 上没有找到关于它的一个视频，当我一直问为什么不这样做时，GPT 低调地告诉我，如果你有一个相关权重范围（假设为 -10 到 10），那么实际上最好将它们初始化得尽可能远，而不是使用其中一种随机算法。 GPT 提到的唯一问题是完全分离的节点的交付。 谁能向我解释为什么每个人都使用随机初始化？    提交人    /u/kotvic_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evwap1/d_why_we_initialize_the_neural_networks_with/</guid>
      <pubDate>Mon, 19 Aug 2024 08:04:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 玩具问题顶级会议或期刊？讨论 ANN 无法解决的有用玩具问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evqjmd/d_toy_problem_top_conference_or_journal/</link>
      <description><![CDATA[我们能否讨论一下基于 ANN 的算法在处理“统计”性质的问题时表现如何。这意味着问题的答案是关联（给定 A，B 很可能）。深度学习在这项工作中非常出色，但我想在社区中就“玩具”问题展开合作讨论，看看是否可以用 DL 解决，或者是否可以解决。 首先，我们知道 MLP 的通用近似定理，以及相关定理和它可能带来的限制。 现在谈谈玩具问题。我们总是会为视觉和语言等大难题召开会议，但有没有办法像以下列表（文章结尾）中那样为玩具问题提供 ML 算法。如果有一系列“重要的玩具问题”，有人可以给出链接吗？当我用谷歌搜索时，我得到了 MNIST、iris 等等，但我正在寻找与该列表类似的东西。 要讨论的要点： - 任何基于 DL 的算法都可以解决任何玩具问题吗 - 解决任何玩具问题的途径并将其发布在光荣的途径（并认真对待） - 你认为哪些玩具问题很重要 - 为什么我们需要 DL 来学习可以硬编码的东西？ （但是，顺便说一下，为我们无法硬编码的东西制作解决方案是有用的工程！而让机器学习我们可以硬编码的东西可能纯粹是一项研究/学术活动） - 已知的硬编码问题的相似性使 ANN 难以学习 需要注意的要点： - 我不是在寻找“答案”，我只是想开始讨论：请随意表达你的感受和想法 - 我认为讨论可能会激发彼此的思考，从我们可以从现在的位置实现什么或者我们是否需要尝试一些新的东西  玩具问题 1. 反转：给定一个序列（a0 a1 a2 a3 ... an），始终返回（an a{n-1} ... a1 a0） 2. 交换（1 的情况）：给定（a b），始终返回（b，a） 3. 定位：给定一个二维矩阵（图像）I，确定所有具有特定值 V 的像素位置（i，j） 4。最多/最少：最多/最少公共值：给定“最多”/“最少”和一个序列（a0 a1 ... an），始终给出最多/最小值 5. 模式：查找模式并对其进行匹配：给定具有模式的任何序列和该模式的 2 个循环（a b c a b c a b _），始终给出 _ 的符号 6. 查找和替换：给定有序字典 D:= {a-&gt;b, b-&gt;c, b-&gt;a, d-&gt;a, a-&gt;c} 和一个序列示例：（a b b a c d d）按顺序执行查找和替换 D....给出（示例答案）（c c c c c a a）    提交人    /u/MysticalDragoneer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evqjmd/d_toy_problem_top_conference_or_journal/</guid>
      <pubDate>Mon, 19 Aug 2024 02:11:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] JPEG-LM：具有规范编解码器表示的图像生成器 LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evqfwo/r_jpeglm_llms_as_image_generators_with_canonical/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evqfwo/r_jpeglm_llms_as_image_generators_with_canonical/</guid>
      <pubDate>Mon, 19 Aug 2024 02:06:35 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 我为 Pokémon BDSP 创造了终极自动闪光猎人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evp3wz/project_i_created_the_definitive_automatic_shiny/</link>
      <description><![CDATA[      大家好！我是 Dinones！我编写了一个使用对象检测的 Python 程序，让我的电脑在我睡觉时在我的实体 Nintendo Switch 上捕捉闪光神奇宝贝。到目前为止，我已经在 Pokémon BDSP 中自动捕捉了闪光宝可梦，如 Giratina、Dialga 或 Azelf、Rotom、Drifloon、所有三种初始宝可梦等等。想知道它是如何工作的吗？快来看看吧！该程序对所有人开放！显然是免费的；我只是一个喜欢在空闲时间编写这些程序的学生 :) 游戏在 Nintendo Switch（不是模拟的，是真实的）上运行。该程序使用捕获卡获取输出图像，然后对其进行处理以检测宝可梦是否闪光（OpenCV）。最后，它使用蓝牙（NXBT）模拟 joycons 并控制 Nintendo。 也可以在 Raspberry Pi 上使用！ 我不会用这个赚钱，我只是觉得我的项目会让很多人感兴趣。 📽️ Youtube：https://www.youtube.com/watch?v=84czUOAvNyk 🤖 Github：https://github.com/Dinones/Nintendo-Switch-Pokemon-Shiny-Hunter https://preview.redd.it/7jbe6fdxrijd1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=626c801925fb0769f59e62ece09f0e00b18b828e https://preview.redd.it/2h2alqcxrijd1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=fddd11c5c04c58268bbaf0e8bca0fd7081a7f775    提交人    /u/Dinones   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evp3wz/project_i_created_the_definitive_automatic_shiny/</guid>
      <pubDate>Mon, 19 Aug 2024 01:00:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 18 Aug 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>