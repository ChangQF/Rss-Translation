<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 04 Dec 2024 06:26:25 GMT</lastBuildDate>
    <item>
      <title>[D] IBM 博士奖学金结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5yz5s/d_results_for_ibm_phd_fellowship/</link>
      <description><![CDATA[有人知道结果什么时候出来吗？谷歌和 NVIDIA 已经发布了结果。    提交人    /u/International-Rip958   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5yz5s/d_results_for_ibm_phd_fellowship/</guid>
      <pubDate>Tue, 03 Dec 2024 21:39:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] IBM 博士奖学金结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5yw4u/d_results_for_ibm_phd_fellowship/</link>
      <description><![CDATA[有人知道结果什么时候出来吗？谷歌和 NVIDIA 已经发布了结果。    提交人    /u/International-Rip958   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5yw4u/d_results_for_ibm_phd_fellowship/</guid>
      <pubDate>Tue, 03 Dec 2024 21:35:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态宇宙：利用 100TB 天文科学数据实现大规模机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5x146/r_the_multimodal_universe_enabling_largescale/</link>
      <description><![CDATA[https://openreview.net/forum?id=EWm9zR5Qy1#discussion 摘要：我们提出了多模态宇宙，这是一个大规模多模态科学天文数据集，专门为促进机器学习研究而编制。总体而言，我们的数据集包含数亿个天文观测数据，构成 100TB 的多通道和高光谱图像、光谱、多元时间序列，以及各种相关的科学测量和元数据。此外，我们还包括一系列代表天体物理学机器学习方法标准实践的基准任务。这个庞大的数据集将使开发专门针对科学应用的大型多模态模型成为可能。用于编译数据集的所有代码以及如何访问数据的说明均可在 https://github.com/MultimodalUniverse/MultimodalUniverse 中找到 你们认为该数据集有什么用途？    提交人    /u/blabboy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5x146/r_the_multimodal_universe_enabling_largescale/</guid>
      <pubDate>Tue, 03 Dec 2024 20:19:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 云端 GPU 价格分析 - 2024 年 12 月：全面的市场回顾</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5p7fr/d_cloud_gpu_price_analysis_december_2024_a/</link>
      <description><![CDATA[在分析了各大供应商当前的云 GPU 定价之后，我整理了一些可能有助于基础设施决策的见解。一些发现让我感到惊讶——尤其是关于隐藏成本和现货定价变化。 当前市场价格（2024 年 12 月） 按需定价： - RunPod H100 (80GB)：2.49 美元/小时 - RunPod A100 (80GB)：1.69-1.99 美元/小时 - Vast.ai A100：0.73-1.61 美元/小时（市场模式） - Lambda A100：1.29 美元/小时 关键市场洞察  现货实例定价  - 可将成本降低 30-70% - 可用性因地区而异 - 一些提供商提供现货实例保证 - 价格稳定性因提供商而异  隐藏的成本因素  - 数据传输费用差异巨大 - 大型数据集的存储成本 - 网络带宽层 - 实例启动/关闭最低限度  提供商差异化因素  - UI/UX 和易用性 - 可用区域/可用区 - 支持质量 - API 功能 成本优化策略  工作负载规划  - 将 GPU 与实际要求相匹配 - 考虑将工作负载拆分到较小的实例中 - 使用 Spot 实例执行可中断任务 - 监控利用率模式  数据管理  - 优化数据集存储 - 规划数据传输模式 - 有效使用缓存 - 考虑压缩策略 我将每月跟踪这些价格和模式。感兴趣：  您使用哪些提供商？ 您如何优化成本？ 在您的 GPU 决策中，哪些指标最重要？     提交人    /u/Botinfoai   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5p7fr/d_cloud_gpu_price_analysis_december_2024_a/</guid>
      <pubDate>Tue, 03 Dec 2024 14:54:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过双向正向-逆向思维增强法学硕士推理能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5nyi0/r_enhancing_llm_reasoning_through_bidirectional/</link>
      <description><![CDATA[这里的关键贡献是一种“逆向思维”方法，它可以在不进行任何模型修改的情况下改进 LLM 推理。该方法不仅仅是从问题正向推理到答案，还增加了一个反向验证步骤 - 从潜在答案反向推理到问题以验证推理链。 关键技术要点：* 两阶段过程：正向生成，然后是反向验证* 反向传递检查答案和前提之间的逻辑一致性* 无需微调或架构更改* 经过多个推理基准测试（GSM8K、CommonsenseQA、LogiQA） 结果：* GSM8K 数学推理提高 8.3%* CommonsenseQA 提高 6.2%* LogiQA 提高 5.4%* 不同模型大小的持续改进* 性能提升是以 2 倍推理时间为代价的 我认为这种方法指出了我们如何提示 LLM 进行推理任务的尚未开发的潜力。虽然加倍的推理时间是一个真正的权衡，但不同基准的持续改进表明这种方法抓住了机器推理的一些基本知识。实现的简单性意味着它可以在许多推理准确性比速度更重要的应用程序中快速采用。 TLDR：添加后向推理验证步骤可将 LLM 在数学、逻辑和常识任务上的性能提高 5-8%，而无需更改模型。推理时间加倍，但在不同的模型和任务中提供一致的收益。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5nyi0/r_enhancing_llm_reasoning_through_bidirectional/</guid>
      <pubDate>Tue, 03 Dec 2024 13:57:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 模型在测试中表现良好，但在生产中失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5nfpt/d_model_performs_good_on_test_but_fails_in/</link>
      <description><![CDATA[嗨，我已经使用 XGBoost 根据用户每周活动数据开发了流失预测模型。训练数据是平衡的（3.3k 流失，3k 未流失）。我将数据分为：训练、验证和测试集。训练、验证和测试集的准确率约为 90%，召回率约为 88%。然而，在生产中运行时，我发现约 1.5k 个用户被标记为流失（我们总共有 4k 个用户）。这不可能是真的，因为我们每月最多有 250 个流失用户。有什么建议可以告诉我我做错了什么吗？有什么解决办法吗？ 谢谢     提交人    /u/Terrible_Dimension66   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5nfpt/d_model_performs_good_on_test_but_fails_in/</guid>
      <pubDate>Tue, 03 Dec 2024 13:30:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有了焦点损失之类的损失，硬示例采样仍然有必要吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5mqkj/r_with_losses_like_focal_loss_is_hard_exemple/</link>
      <description><![CDATA[您好，我想知道现在是否仍在使用硬示例抽样技术？如果是这种情况，有人有这方面的论文吗？谢谢！    提交人    /u/Training-Adeptness57   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5mqkj/r_with_losses_like_focal_loss_is_hard_exemple/</guid>
      <pubDate>Tue, 03 Dec 2024 12:54:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] ODE/SDE 对齐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5ly4z/d_odesde_alignment/</link>
      <description><![CDATA[有人能给我举一个好的论文例子吗，该论文试图从扩散模型中对齐/匹配 2 ODE/SDE 的最终边际分布？    提交人    /u/Ok_Cryptographer2731   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5ly4z/d_odesde_alignment/</guid>
      <pubDate>Tue, 03 Dec 2024 12:08:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] NAACL 2025 vs ACL 2025</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5jj1h/d_naacl_2025_vs_acl_2025/</link>
      <description><![CDATA[嗨， 我最近收到了 NAACL 的 ARR 轮评审。得分为：总体/健全性/信心 3.5/4/4、4/4/2、3/3/3。我应该用这些分数尝试 ACL 还是直接参加 NAACL？去年我多考了一点，结果成功了，被 ACL 录取（我没有参加 NAACL）。 谢谢    提交人    /u/mayanknagda   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5jj1h/d_naacl_2025_vs_acl_2025/</guid>
      <pubDate>Tue, 03 Dec 2024 09:19:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 时间序列中的深度学习：它们在工业中有应用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5izk5/d_deep_learning_in_time_series_are_they_used_in/</link>
      <description><![CDATA[大家好！我是一名时间序列研究人员，看到这个领域关于深度学习模型的讨论很多。我想知道这些模型是否真的在生产中部署，或者传统方法仍然是业内的首选？ 例如，在天气预报中，基于物理的数值天气预报 (NWP) 似乎占主导地位。如果深度模型没有得到太多关注，您是否遇到过它们的任何实际用例？很想听听您的想法！    提交人    /u/Few-Pomegranate4369   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5izk5/d_deep_learning_in_time_series_are_they_used_in/</guid>
      <pubDate>Tue, 03 Dec 2024 08:36:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 流行的关于 VAE 的理论解释不一致。请改变我的想法。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5f6co/d_the_popular_theoretical_explanation_for_vae_is/</link>
      <description><![CDATA[多年来，我一直很难从理论上理解 VAE/变分推理 (VI)。如果有人能澄清我的困惑，我将不胜感激。这是我阅读许多资料后得到的：  我们想要为可观察变量 x 和潜在变量 z 建立一个生成模型 p(x, z)（为简单起见省略了参数）。好，让我们选取适当的参数，使观测样本 p(x) 的边际似然最大化吧。 根据基本概率论（全概率定律和条件概率的定义），我们有： p(x)=∫ p(x ∣ z) p(z) dz （公式 1）。 事情变得比较混乱的地方就在这里：人们会声称这个积分难以解决，因为 z 是连续变量 / z 是高维变量 / p(x∣z) 太复杂 / 或者其他任何借口。 公式 1 难以解决怎么办？虽然上面我们没有提到后验 p(z ∣ x)，但现在我们将把它带入讨论中。后验 p(z ∣ x) 也是难解的，因为 p(z | x) = p(x | z) p(z) / p(x) 且 p(x) 是难解的。因此，我们将引入另一个参数化模型 q(z ∣ x) 来近似 p(z | x)。 经过一些推导，我们得到了一个新的优化目标，通常称为 ELBO，它是以下内容的总和： “重建”项：∫ log p(x ∣ z) q(z ∣ x) dz（等式 2）； q(z | x) 和 p(z) 之间的 KL 散度项，从而得到一个闭式。  所以现在我们必须研究等式 2。与等式 2 相比， 1，p(z) 被 q(z∣x) 取代，它们 (通常) 都是正态分布，而 p(x | z) 仍然存在。太好了！显然，我们把一个难积分变成了……另一个难积分？ 别担心，我们可以使用蒙特卡洛抽样来计算公式 2……等等，既然我们可以使用蒙特卡洛来做到这一点，为什么我们不能以同样的方式处理公式 1 而不用那么麻烦呢？ 当然这不是一个好主意。可以证明 log p(x) = ELBO + D_KL(q(z ∣ x) || p(z ∣ x))。所以我们不能用公式估计 p(x)。 1，因为它没有这么好的性质……嗯，我们似乎不是这样开始解释的？  问题：  在解决原始问题时，即通过最大化 p(x)=∫ p(x ∣ z) p(z) dz 对 p(x, z) 进行建模，为什么我们要涉及后验 p(z | x)？ 有人用&quot;缩小值空间以促进更快的搜索&quot;（使用 p(z | x)、q(z | x) 的近似值）来解释这一点。但同样，请回想一下 Eq. 1 得到解释后，我看不出这个论点有什么改进。  等式 1 和等式 2 本质上相似，其中它们都是 (log) p(z | x) 关于某个正态分布的概率密度函数的期望。我看不出基于等式 1 的难解性的动机如何有意义。 讽刺的是，在处理等式 2 时我们仍然必须求助于蒙特卡洛抽样。但是人们在谈论等式 1 的难解性时似乎忘记了它，但在面对与等式 2 相同的问题时却记住了它。   更新：我修改了一些错字。 更新 2：经过一些讨论，问题 2 似乎得到了解决： - 由于方差较大，在 p(z) 上采样不是一个好主意。 - 在实践中，我们通常研究 log p(x)，样本的对数似然，以及 log ∫ p(x ∣ z) p(z) dz 的 MC 采样（等式 3）可能会有偏差。 - 将 Jensen 不等式应用于等式 3，我们将得到 log p(x) ≥ ∫ log p(x ∣ z) p(z) dz。 这个界限很可能比 ELBO 更差，并且仍然依赖于对 p(z) 进行采样。 然而，这些观点在现有文章中仍然很少见。 我希望我们在将来介绍 VAE 时可以更加仔细地思考。    提交人    /u/function2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5f6co/d_the_popular_theoretical_explanation_for_vae_is/</guid>
      <pubDate>Tue, 03 Dec 2024 04:25:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过质量多样性进行基于人群的模型合并</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h5dmnb/r_populationbased_model_merging_via_quality/</link>
      <description><![CDATA[如果你们有兴趣，这里有一篇关于我们最近的论文博客文章 通过 CycleQD 实现大型语言模型的代理技能获取。    提交人    /u/hardmaru   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h5dmnb/r_populationbased_model_merging_via_quality/</guid>
      <pubDate>Tue, 03 Dec 2024 03:02:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] 简化的 RNN 通过并行训练和减少参数实现类似 Transformer 的性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4urpr/r_simplified_rnns_achieve_transformerlike/</link>
      <description><![CDATA[本文系统地研究了 RNN 是否足以完成目前由 Transformer 主导的许多 NLP 任务。研究人员在保持模型大小、训练数据和其他变量不变的情况下，进行了比较 RNN 和 Transformer 的受控实验。 关键技术要点： - 使用匹配的参数在语言建模和 seq2seq 任务上测试了这两种架构（70M-1.5B） - 引入了“具有并行生成的 RNN” （RPG）允许 RNN 像 Transformer 一样并行生成 token - 在包括 WikiText-103 和 WMT14 英德翻译在内的标准基准上进行评估 - 通过探测任务和注意模式分析分析表示能力 主要结果：- RNN 在 WikiText-103 语言建模上匹配或优于类似大小的 Transformer - Transformer 在翻译任务上显示出 1-2 BLEU 分数优势 - RPG 实现了 Transformer 生成速度的 95% 且准确度损失最小 - RNN 表现出更强的局部上下文建模，而 Transformer 擅长长距离依赖 我认为这项工作提出了关于现代 NLP 中架构选择的重要问题。虽然 Transformer 已成为默认设置，但 RNN 可能仍然适用于许多应用程序，尤其是那些专注于局部上下文的应用程序。并行生成技术可以使 RNN 更适用于生产部署。 我认为结果表明我们应该重新考虑特定用例的 RNN，而不是假设 Transformer 总是最佳的。 RNN 的计算效率对于资源受限的应用尤其有价值。 TLDR：综合比较表明，在控制模型大小和训练的情况下，RNN 可以在某些 NLP 任务上与 transformer 匹敌。介绍了 RNN 的并行生成技术。结果表明，架构选择应取决于特定的应用需求。 完整摘要在这里。论文这里    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4urpr/r_simplified_rnns_achieve_transformerlike/</guid>
      <pubDate>Mon, 02 Dec 2024 13:19:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 01 Dec 2024 16:00:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>