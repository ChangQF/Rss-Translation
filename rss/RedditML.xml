<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 16 Jan 2025 12:31:33 GMT</lastBuildDate>
    <item>
      <title>带有 MLP 混频器的 CIFAR 100。[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2nu5q/cifar_100_with_mlp_mixer_p/</link>
      <description><![CDATA[最近参加了一场黑客马拉松，任务是在不使用卷积和变换器模型的情况下实现高精度。尽管 mlp 混合器可以说与卷积相似，但它们是允许的。即使经过多次尝试，我也无法将准确率提高到 60% 以上。有没有办法用 mlp 或其他任何东西来达到 90% 左右的准确率。    提交人    /u/Abbe_Kya_Kar_Rha_Hai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2nu5q/cifar_100_with_mlp_mixer_p/</guid>
      <pubDate>Thu, 16 Jan 2025 12:30:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最佳文本转声音效果模型（MIT 许可证或同等许可证）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2n50v/d_best_texttosoundeffects_model_mit_license_or/</link>
      <description><![CDATA[大家好！我一直在寻找 MIT（商业上可用的）文本转声音效果（Text-to-Audio）模型，除了传统的稳定 Audio-Open（带有特殊许可证）之外，没有找到太多模型。 您知道其他的吗？    提交人    /u/Leather-Arm-2466   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2n50v/d_best_texttosoundeffects_model_mit_license_or/</guid>
      <pubDate>Thu, 16 Jan 2025 11:46:16 GMT</pubDate>
    </item>
    <item>
      <title>这个 reddit 上的好心人曾使用过同一型号的多个适配器，请用你们的智慧指导我 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2mcy1/good_people_of_this_reddit_who_worked_with/</link>
      <description><![CDATA[如何处理为不同任务创建的多个适配器？我理解基于任务 ID 的适当适配器的动态加载是显而易见的，但有没有更好的方法？我特别要求耳语    提交人    /u/YogurtclosetAway7913   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2mcy1/good_people_of_this_reddit_who_worked_with/</guid>
      <pubDate>Thu, 16 Jan 2025 10:54:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] AutoResearch：一种新的开源 LLM 驱动的研究自动化工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2lk5n/p_autoresearch_a_new_opensource_llmdriven/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2lk5n/p_autoresearch_a_new_opensource_llmdriven/</guid>
      <pubDate>Thu, 16 Jan 2025 09:55:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 泰坦：一个新的开创性的建筑发展？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2l0ey/d_titans_a_new_seminal_architectural_development/</link>
      <description><![CDATA[对他们的工作的最初印象是什么？它能改变游戏规则吗？这能多快融入新产品？期待对话！    提交人    /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2l0ey/d_titans_a_new_seminal_architectural_development/</guid>
      <pubDate>Thu, 16 Jan 2025 09:12:27 GMT</pubDate>
    </item>
    <item>
      <title>对 NSFW 文本进行分类的最佳方法 - BERT、小型 LLM（如 llama 3.2 3B）还是其他？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2h315/best_way_to_classify_nsfw_text_bert_small_llm/</link>
      <description><![CDATA[我正在做一个项目，需要将文本分类为 nsfw 或 sfw。我知道有一些基于 BERT 的分类器专门针对此类任务进行训练。我也见过有人使用较小的 LLM。 最好的方法是什么？由于检测 NSFW 文本的底层复杂性并不高，我认为也许全面的 LLM 有点过头了。你有什么建议？    提交人    /u/newyorkfuckingcity   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2h315/best_way_to_classify_nsfw_text_bert_small_llm/</guid>
      <pubDate>Thu, 16 Jan 2025 04:38:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在空间中一边想象一边推理：思维的多模态可视化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i279gb/r_imagine_while_reasoning_in_space_multimodal/</link>
      <description><![CDATA[摘要： 思维链 (CoT) 提示已被证明对于增强大型语言模型 (LLM) 和多模态大型语言模型 (MLLM) 中的复杂推理非常有效。然而，它在复杂的空间推理任务中却举步维艰。尽管如此，人类的认知不仅限于语言，还具有用文字和图像思考的非凡能力。受此机制的启发，我们提出了一种新的推理范式，即多模态思维可视化 (MVoT)。它通过生成其推理轨迹的图像可视化来实现 MLLM 中的视觉思维。为了确保高质量的可视化，我们在自回归 MLLM 中引入了标记差异损失。这项创新显着提高了视觉连贯性和保真度。我们通过几个动态空间推理任务验证了这种方法。实验结果表明，MVoT 在各个任务中都表现出了竞争力。此外，它在 CoT 失败的最具挑战性的场景中表现出稳健可靠的改进。最终，MVoT 为复杂的推理任务建立了新的可能性，在这些任务中，视觉思维可以有效地补充语言推理。 Arxiv 链接：https://arxiv.org/pdf/2501.07542    提交人    /u/imadade   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i279gb/r_imagine_while_reasoning_in_space_multimodal/</guid>
      <pubDate>Wed, 15 Jan 2025 20:43:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我如何发现并修复微软 Phi-4 模型中的 4 个错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i23zbo/p_how_i_found_fixed_4_bugs_in_microsofts_phi4/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i23zbo/p_how_i_found_fixed_4_bugs_in_microsofts_phi4/</guid>
      <pubDate>Wed, 15 Jan 2025 18:22:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] JAIR 与模式识别期刊之间的困境</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i236iq/d_dilemma_bw_jair_vs_pattern_recognition_journal/</link>
      <description><![CDATA[大家好， 我是一名本科生，我想将我的手稿提交给这两家杂志中的任何一家；这项工作是关于机器学习中隐私和可解释性的相互作用（如果要求，我很乐意向您发送相同的 arXived 版本）。我之前曾在 EMNLP 的一个非常有名望的研讨会上发表过文章，并了解到如今 ML 主要是以会议为中心的学科。我想知道这两家杂志中的哪一家更适合提交我的作品（由于篇幅和范围，我这次无法提交给会议）。我不能将它提交给 tmlr，直到它被 Scopus 索引，目前不考虑 AIJ 和 Machine Learning Journal。 我只是想确保如果论文被接受，我希望它至少可以与边缘 A* 论文相媲美（就所谓的会议声望而言）。此外，如果您有任何其他建议，请告诉我；我对期刊还不熟悉，我很感激您的意见。 附注：我的指导老师由于影响因子更高，略微更喜欢 PR 而不是 JAIR，但尽管如此，他还是开放 JAIR 或任何其他 Scopus 索引期刊，只要它至少与边缘 A* 或非常强的 A 会议论文相当。    提交人    /u/RepresentativeOk7956   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i236iq/d_dilemma_bw_jair_vs_pattern_recognition_journal/</guid>
      <pubDate>Wed, 15 Jan 2025 17:49:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 工作推荐系统中可解释的 GNN：应对多利益相关者的挑战</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i21t17/r_explainable_gnns_in_job_recommender_systems/</link>
      <description><![CDATA[可解释的人工智能能否平衡工作推荐系统中相互竞争的需求？由 GNN 提供支持的 OKRA 等模型可提供针对利益相关者的见解 - 为候选人提供文字解释、为招聘人员提供技能匹配以及为公司提供可视化。它们解决了偏见（例如农村代表性不足）和挑战，例如将解释与源数据（简历、职位空缺）相结合。  未来的方向重点是完善解释的连贯性、公平性指标和现实世界的验证，推动可解释的多利益相关者人工智能走向公平、情境感知的工作匹配。 我们在这里解读Roan Schellingerhout的“可解释的多利益相关者工作推荐系统”：https://www.shaped.ai/blog/decoding-job-recommendations-the-future-of-explainable-multi-stakeholder-ai    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i21t17/r_explainable_gnns_in_job_recommender_systems/</guid>
      <pubDate>Wed, 15 Jan 2025 16:51:44 GMT</pubDate>
    </item>
    <item>
      <title>Kaggle 数据集：其中一个输入特征与目标的相关性 >0.99，但大多数/所有笔记本（20+）并不关心？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i210hp/kaggle_dataset_one_of_the_input_features_has_a/</link>
      <description><![CDATA[此数据集（不会链接到这里，因为我不想与我的 kaggle 和 reddit 关联）包含一些输入特征（5-6）用于预测一个目标值。 但其中一个特征基本上与目标 (&gt;0.99) 完全线性相关。 一个例子是来自只有一种卡车型号的卡车运输公司的数据： 目标：卡车燃油消耗量/年特征：驾驶员年龄、轮胎类型、卡车年龄、行驶距离/年 显然，平均燃油消耗量与行驶里程数成线性比例。我的意思是，通常您只需使用它来计算燃油/距离等新目标。 然而，没有一个人/笔记本做过这种规范化。因此，每个人的模型都有 &gt;.99 的准确率，因为这个特征淹没了其他所有特征。 其他人是否注意到了这一点：代码看起来越来越好（数据加载、训练多种类型的模型），这可能要归功于 LLM。但决策过程往往很糟糕？    提交人    /u/ToThePastMe   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i210hp/kaggle_dataset_one_of_the_input_features_has_a/</guid>
      <pubDate>Wed, 15 Jan 2025 16:17:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] MathReader：使用 OCR 和经过微调的 T5 的数学文档文本转语音系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1xgp2/r_mathreader_a_texttospeech_system_for/</link>
      <description><![CDATA[有趣的新文本转语音系统，通过结合 OCR 和语言模型来处理数学内容。关键创新是将数学符号视为需要翻译的专用语言，使用多阶段管道将方程式转换为自然语音。 技术方法：* 专门针对数学文档训练的自定义 OCR 模型 * 针对数学到文本翻译进行微调的基于 T5 的语言模型 * 三阶段管道：识别 → 翻译 → 合成 * 与 LaTeX 解析集成以处理复杂的数学排版 主要结果：* 数学表达式识别准确率为 95% * 成功处理包括分数、积分、矩阵在内的复杂符号 * 用户测试显示优于现有的数学 TTS 系统 * 自然语言输出与人类描述相匹配 我认为这可能对使技术教育更容易获得产生影响。能够将数学文档转换为清晰的语音为学习和处理技术内容开辟了一些可能性。 OCR 和 NLP 的结合似乎是一种强大的方法，它可以从数学扩展到具有专门符号的其他技术领域。 我看到了上下文相关符号和复杂证明的一些限制，但这些似乎是未来工作的自然领域，而不是方法中的根本缺陷。 TLDR：新的 TTS 系统结合了专门的 OCR 和语言模型，将数学文档转换为自然语音，在数学识别中实现 95% 的准确率并产生类似人类的描述。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1xgp2/r_mathreader_a_texttospeech_system_for/</guid>
      <pubDate>Wed, 15 Jan 2025 13:33:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer²：自适应法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1l8d4/r_transformer²_selfadaptive_llms/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2501.06252 摘要 自适应大型语言模型 (LLM) 旨在解决传统微调方法带来的挑战，这些方法通常计算量大，处理各种任务的能力也比较静态。我们引入了 Transformer²，这是一种新颖的自适应框架，它通过选择性地调整权重矩阵的奇异分量，实时调整 LLM 以适应看不见的任务。在推理过程中，Transformer² 采用两遍机制：首先，调度系统识别任务属性，然后使用强化学习训练的任务特定“专家”向量进行动态混合，以获得针对传入提示的目标行为。我们的方法优于 LoRA 等普遍存在的方法，参数更少，效率更高。Transformer² 展示了跨不同 LLM 架构和模态的多功能性，包括视觉语言任务。Transformer² 代表了一次重大飞跃，为增强 LLM 的适应性和任务特定性能提供了可扩展、高效的解决方案，为真正动态、自组织的 AI 系统铺平了道路。 博客摘要：https://sakana.ai/transformer-squared/ GitHub：https://github.com/SakanaAI/self-adaptive-llms    提交人    /u/hardmaru   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1l8d4/r_transformer²_selfadaptive_llms/</guid>
      <pubDate>Wed, 15 Jan 2025 00:41:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 12 Jan 2025 16:00:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>