<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 29 Mar 2024 18:16:10 GMT</lastBuildDate>
    <item>
      <title>[D] 液体网络、神经常微分方程/偏微分方程和基于文本的扩散</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqw0yl/d_liquid_nets_neural_odespdes_and_textbased/</link>
      <description><![CDATA[作为一名全栈工程师，我一直在转向 AI/ML，但我对某些事情有一些疑问。 我最近在自然语言处理和文本生成领域发现了一些有趣的进展。具体来说，我从麻省理工学院学习了液体神经网络（LNN），以及扩散模型在文本生成中的应用。 液体神经网络将神经网络的隐藏状态表示为时间的连续函数，根据微分方程演化。由于它们具有即时学习和适应的能力，它们在机器人和控制系统方面显示出了前景。它的创建者来自麻省理工学院，创建了一家名为 Liquid AI 的衍生初创公司，他们的博客文章讨论了他们开发新一代人工智能基础模型并超越 Transformer 的计划。 关于“超越生成式预训练变形金刚”的 Liquid AI 博客文章 另一方面，在图像生成方面取得成功的扩散模型现在也被应用于文本生成。 文本扩散 - 关于分数熵离散扩散的推文 看起来液体神经网络集成了神经常微分方程，类似于传统的扩散模型，但我有点对这一切感到困惑。我已经浏览过他们的液体结构状态空间模型，我猜它更类似于 Mamba，但是以某种方式将液体/神经 ODE 方面的内容实现到其中（我在尝试理解代码库时有点迷失）。 根据他们的 YouTube 视频，看起来液体神经网络主要应用于机器人技术，但这似乎在该特定领域是一件相当大的事情。我想知道这是否就是最近特斯拉自动驾驶能力实现巨大飞跃的原因。 我很想听听您对这些方法的想法和见解：  您认为液体神经网络可以有效地应用于文本生成任务，从而有可能取代或补充类似 GPT 的架构吗？ 您对扩散模型在文本生成中的应用有何看法？您认为这种方法有潜力推动生成语言模型的发展吗？ 考虑到顺序，您在将这些技术应用于文本生成时是否会遇到任何特定的挑战或限制？文本的本质以及捕获远程依赖关系的需要？ 您是否在生成语言模型领域遇到过其他令人兴奋或值得讨论的最新进展或有前景的方法？ 这是否可能会带来困扰传统 GPT 的上下文窗口的突破？  我一直在尝试深入学习 ODE/PDE，但我可能是错的，但是看起来它可能有一些潜力可以根据输入的复杂性动态调整计算要求。我想知道这是否可能与人类的系统 1 和系统 2 思维并行。 我在这个 Reddit 子版块上搜索了一些关于液体神经网络和神经 ODE/PDE 的帖子，但没有找到关于文本生成我真的看到了很多。 我渴望从这个社区的集体知识和观点中学习。任何与这些主题相关的见解、论文或资源将不胜感激。 提前感谢您的投入！    ;由   提交/u/Squidster777  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqw0yl/d_liquid_nets_neural_odespdes_and_textbased/</guid>
      <pubDate>Fri, 29 Mar 2024 18:11:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在哪里可以找到个人项目的足球开源数据？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bquytf/p_where_can_i_find_open_source_data_for_football/</link>
      <description><![CDATA[我真的对足球充满热情，我正在考虑做一些个人项目。那么我在哪里可以找到音调数据集来探索并看看我可以用它做什么？   由   提交/u/pusvvagon  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bquytf/p_where_can_i_find_open_source_data_for_football/</guid>
      <pubDate>Fri, 29 Mar 2024 17:29:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要为机器学习和行为科学的未来提供建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqstby/d_need_advice_for_a_future_in_ml_and_behavior/</link>
      <description><![CDATA[大家好！ 我很快就要来美国开始我的机器学习硕士学位，我真的很兴奋关于它。我作为软件开发人员工作了三年，完成了一些与计算机视觉和实施机器学习模型相关的项目。但我真正喜欢的是数学和了解人们为什么要做他们所做的事情。 我梦想在机器学习与行为科学或神经科学相遇的地方工作。我很想从事人工智能方面的研究，但说实话，我也需要一份报酬丰厚的工作:p  我真的没有人指导我下一步该做什么，但我想充分利用我两年的学习。 所以，我向大家征求意见。我应该关注什么？有什么是我绝对应该做或避免的吗？我来这里是为了学习和努力。   由   提交 /u/Curiousbees01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqstby/d_need_advice_for_a_future_in_ml_and_behavior/</guid>
      <pubDate>Fri, 29 Mar 2024 15:59:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] Pytorch FSDP 是管道并行吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqsq3w/d_pytorch_fsdp_is_pipeline_parallelism_right/</link>
      <description><![CDATA[编辑：要明确的是，我对 FSDP 如何处理用于一个 GPU 的模型感兴趣（使用数据并行性这一事实并不是我想要的）想要讨论）。 我在阅读FSDP论文后得到了这个理解： &lt; blockquote&gt;  使用参数分片执行计算并相应地传达激活信息。 [...] 通过在计算之前按需传递参数来执行与本地训练相同的计算。由于参数通信对先前的计算没有任何数据依赖性，因此它们可以与在同一前向或后向传递中执行的先前计算重叠。然而，这种方法要求按需通信的参数能够完全具体化，并且能够适合单个GPU设备的内存。  FSDP属于第二类通信参数  但我很困惑为什么从来没有在任何地方明确提及这一点（博客文章、文档、论文）？   由   提交 /u/fasttosmile   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqsq3w/d_pytorch_fsdp_is_pipeline_parallelism_right/</guid>
      <pubDate>Fri, 29 Mar 2024 15:56:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否可以基于 NeRF 数据创建一个视频游戏室？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqq4pp/d_is_it_possible_to_create_a_video_game_room/</link>
      <description><![CDATA[很抱歉问这个基本问题（我对 NeRF 不太熟悉），但是是否已经可以捕获房间的视频（也许使用3D 相机）并创建它的 3D 模型以在游戏中使用？我对 https://news.ycombinator.com/item?id=38632492 印象深刻，我想也许我们正在努力实现这一目标。感谢任何阅读建议，以进一步了解某个领域！   由   提交/u/Few_Fox_1255   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqq4pp/d_is_it_possible_to_create_a_video_game_room/</guid>
      <pubDate>Fri, 29 Mar 2024 14:05:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 评估不平衡数据集的精确召回率？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqoiso/d_precisionrecall_to_evaluate_imbalanced_datasets/</link>
      <description><![CDATA[   许多来源都说精确召回是评估不平衡数据集分类器的好方法。但是，当我有更多的正样本时与负数 (tp &gt;&gt; fp,fn) 相比，此测量值已饱和，我们得到完美的 AUC。  ​  在计算精确率-召回率曲线之前是否应该对数据集进行过采样（或欠采样）？ 我还可以使用哪些其他方法来调整不平衡数据集的阈值？  https://preview.redd.it/rez8qncks9rc1.png?width=302&amp;format=png&amp;auto=webp&amp;s=1f16cdbc3f98f40aa58ad 21768686f45cfa6cf60   由   提交/u/notbot1234  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqoiso/d_precisionrecall_to_evaluate_imbalanced_datasets/</guid>
      <pubDate>Fri, 29 Mar 2024 12:51:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 单通道足以用于 Transformers 中的位置编码吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqnlnw/d_is_a_single_channel_enough_for_positional/</link>
      <description><![CDATA[是，使用 VAPE - 矢量加法位置编码. 我一直在探索一种新的位置编码方法，我称之为 VAPE - 矢量加法位置编码。 方法：   从查询和键中借用一些通道， 在这些借用通道上的序列长度上运行累积（前缀）总和（将向量加在一起）， &gt; 归一化 - 除以向量大小的平方根， 我们现在有了位置感知通道， 因此将它们连接回查询和键。 &gt;  有趣的是，这种方法只需每个头一个通道即可有效工作。使用单个通道意味着我们在标量而不是向量上运行前缀和，并且该方法仍然有效。 VAPE 功能：  &lt; strong&gt;无额外参数：VAPE引入位置信息，无需向模型添加任何新参数，保持其简单性和效率。 性能：早期测试表明 VAPE在最终困惑度方面优于 RoPE 等方法。 外推：早期测试表明 VAPE 可以很好地外推超出训练上下文长度，没有像 RoPE 那样添加明确的位置信息。&lt; /li&gt; 与 Flash Attention 的兼容性：与 Flash Attention 完全兼容。 效率：仅利用少量通道即可实现位置编码，VAPE 保持模型效率。 推理速度：VAPE 缓存查询和键的最后位置状态 - 这有点像 SSM/RNN，你只需要最后一个状态计算下一个。  寻求您的见解：  哪些基准或具体比较最能向您展示 VAPE 的价值？  你知道类似 VAPE 的方法吗？  基准： 我早期运行过一些对于因果语言建模任务来说，这些测试看起来非常有希望，但我用于进行基准测试的资源非常有限，因此在我投入任何精力之前，我认为最好询问社区如何进行。   由   提交/u/bnqj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqnlnw/d_is_a_single_channel_enough_for_positional/</guid>
      <pubDate>Fri, 29 Mar 2024 12:04:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 魔法背后的技术：OpenAI SORA 的工作原理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqmn86/d_the_tech_behind_the_magic_how_openai_sora_works/</link>
      <description><![CDATA[大家好，我对 OpenAI SORA 进行了深入研究，很高兴与大家分享。 在在这段视频中，我解释了图像和视频生成人工智能技术的演变，并深入探讨了 OpenAI SORA 的训练方式、其功能以及对社会的影响的细节。 享受：https://youtu.be/IqZXkBjKb2E?si=aaF8MUyqc5bhZ6G9   由   提交/u/johnolafenwa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqmn86/d_the_tech_behind_the_magic_how_openai_sora_works/</guid>
      <pubDate>Fri, 29 Mar 2024 11:11:51 GMT</pubDate>
    </item>
    <item>
      <title>人们会对聚合此处发布的论文的不和谐服务器/博客感兴趣吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqhji1/would_people_be_interested_in_a_discord/</link>
      <description><![CDATA[嗨，很多海报发布了他们发现有趣的研究工作和论文，很难跟踪。我给有趣的论文添加了书签，结果却忘记了它们。  想知道这里的人是否值得做一个不和谐服务器（每天更新）或一个媒体博客（每周更新）来跟踪在此子上发布的论文。   由   提交 /u/shadowylurking   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqhji1/would_people_be_interested_in_a_discord/</guid>
      <pubDate>Fri, 29 Mar 2024 05:32:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你会如何回答这个面试问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqftlw/d_how_would_you_answer_this_interview_question/</link>
      <description><![CDATA[不确定这是否是一个“职业问题”，但最近有人问我这个面试问题： 在一场有 10 辆赛车的 F1 赛车比赛，您如何计算/预测第二名赛车超过第一名赛车的概率？这个计算需要什么算法、数据和模型？解释每个步骤。 你会如何回答这个问题？ （没有给出其他信息）   由   提交/u/Conscious_Giraffe453  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqftlw/d_how_would_you_answer_this_interview_question/</guid>
      <pubDate>Fri, 29 Mar 2024 03:56:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] Jamba：首款基于 Mamba 的生产级模型，提供一流的质量和性能。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bqfibp/p_jamba_the_first_productiongrade_mambabased/</link>
      <description><![CDATA[帖子：https://www.ai21 .com/blog/announcing-jamba  我们很高兴宣布 Jamba，世界上第一个基于 Mamba 的生产级模型。通过使用传统 Transformer 架构的元素增强 Mamba 结构化状态空间模型 (SSM) 技术，Jamba 弥补了纯SSM模型。它提供了 256K 上下文窗口，已经在吞吐量和效率方面展现了显着的进步——这只是这种创新混合架构的开始。值得注意的是，Jamba 在各种基准测试中都优于或匹配同尺寸级别的其他最先进型号。  ​ &lt; !-- SC_ON --&gt;  由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bqfibp/p_jamba_the_first_productiongrade_mambabased/</guid>
      <pubDate>Fri, 29 Mar 2024 03:39:56 GMT</pubDate>
    </item>
    <item>
      <title>自适应 RAG：一种降低 top-k 向量索引检索的 LLM 令牌成本的检索技术 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bq3hwb/adaptive_rag_a_retrieval_technique_to_reduce_llm/</link>
      <description><![CDATA[摘要：我们演示了一种技术，该技术允许使用法学硕士的反馈动态调整 top-k 检索器 RAG 提示中的文档数量。这使得 RAG LLM 问答的成本降低了 4 倍，同时保持了相同的准确性水平。我们还表明该方法有助于解释法学硕士输出的血统。参考实现适用于大多数模型（GPT4、许多本地模型、较旧的 GPT-3.5 Turbo），并且可以适应大多数公开 top-k 检索原语的矢量数据库。 博客论文：https://pathway.com/developers/showcases/adaptive-rag 参考实现：&lt; a href=&quot;https://github.com/pathwaycom/pathway/blob/main/python/pathway/xpacks/llm/question_answering.py&quot;&gt;https://github.com/pathwaycom/pathway/blob/main/python /pathway/xpacks/llm/question_answering.py   由   提交 /u/dxtros   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bq3hwb/adaptive_rag_a_retrieval_technique_to_reduce_llm/</guid>
      <pubDate>Thu, 28 Mar 2024 18:55:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年构建大型语言模型的小指南 – 75 分钟讲座</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bpzrm0/d_a_little_guide_to_building_large_language/</link>
      <description><![CDATA[我终于录制了两周前的讲座，因为人们一直向我索要视频。 所以在这里，我希望您会喜欢“2024 年构建大型语言模型的小指南”。 我试图使其简短而全面 - 重点关注对于培训优秀 LLM 至关重要但通常隐藏的概念在技​​术报告中。 在讲座中，我向学生介绍了培训良好绩效法学硕士的所有重要概念/工具/技术：- 查找、准备和评估网络规模数据- 理解模型并行性和高效培训- 微调/对齐模型 - 快速推理 当然有很多东西和细节缺失，我应该添加进去，不要犹豫告诉我你是最令人沮丧的遗漏，我将在以后的部分中添加它。特别是，我认为我将更多地关注如何很好地、广泛地过滤主题，也许还有更多实用的轶事和细节。 既然我记录了它，我一直在想这可能是一个主题的第 1 部分。由两部分组成的系列，其中包含第二个完整的实践视频，介绍如何使用我们最近在 HF 围绕 LLM 培训发布的一些库和配方来运行所有这些步骤（并且无论如何都可以轻松适应您的其他框架）：  用于所有网络规模数据准备的 datatrove：https://github.com/huggingface/datatrove  nanotron 用于轻量级 4D 并行法学硕士培训：https://github.com/huggingface/nanotron lighteval 用于训练中快速并行 LLM 评估：https://github.com/huggingface/lighteval  以下是在 Youtube 上观看讲座的链接：https://www. youtube.com/watch?v=2-SPH9hIKT8这是 Google 幻灯片的链接：https://docs.google.com/presentation/d/1IkzESdOwdmwvPxIELYJi8--K3EZ98_cL6c5ZcLKSyVg/edit#slide=id.p 很高兴听到对此的反馈以及在第二部分中添加、更正、扩展的内容。   由   提交 /u/Thomjazz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bpzrm0/d_a_little_guide_to_building_large_language/</guid>
      <pubDate>Thu, 28 Mar 2024 16:26:57 GMT</pubDate>
    </item>
    <item>
      <title>幻觉的终结（对于那些能负担得起的人）？ [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bpxs1i/the_end_of_hallucination_for_those_who_can_afford/</link>
      <description><![CDATA[      DeepMind 刚刚发表了一篇关于事实检查文本的论文： &lt; a href=&quot;https://preview.redd.it/zsmv0a0293rc1.png?width=1028&amp;format=png&amp;auto=webp&amp;s=789c1c2f9b31aa734a7ebcf459df3ad06bd74285&quot;&gt;https://preview.redd.it/zsmv0a0293rc1.png?width =1028&amp;format=png&amp;auto=webp&amp;s=789c1c2f9b31aa734a7ebcf459df3ad06bd74285 该方法使用 GPT-3.5-Turbo，每个模型响应成本为 0.19 美元，比人类注释者更便宜，同时更比他们准确： https:/ /preview.redd.it/ob7bb3iv73rc1.png?width=1014&amp;format=png&amp;auto=webp&amp;s=e79bbcaa578b29772cb3b43ead508daff7288091 他们使用这种方法创建事实基准并比较一些流行的法学硕士。 论文和代码：https://arxiv.org/abs/2403.18802 编辑：关于帖子的标题：幻觉被定义（在维基百科中）为“由人工智能生成的响应，其中包含作为事实呈现的虚假或误导性信息。”：您的代码不编译本身并不是一种幻觉。当你声称代码是完美的时，那是一种幻觉。    由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bpxs1i/the_end_of_hallucination_for_those_who_can_afford/</guid>
      <pubDate>Thu, 28 Mar 2024 15:04:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>