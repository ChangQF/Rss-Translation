<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 19 Mar 2024 15:14:22 GMT</lastBuildDate>
    <item>
      <title>[P] 时间序列中的异常检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biiwmr/p_anomaly_detection_in_time_series/</link>
      <description><![CDATA[我正在从事异常检测项目。我的数据集是关于由三个数字代表的客户的每月行为。因此，对于每个客户，我在数据集中都有一行，每个月包含三列。最后我有目标标签 True 或 False。 ​   Cust No 一月一月一月二月 二月 二月 ... DecA  DecB DecC 异常    1 12 1  231  &lt; td对齐=“左”&gt; 12  &lt; td对齐=“左”&gt; 23   211  &lt; td对齐=“左”&gt;   123   2   12  &lt; tdalign=&quot;left&quot;&gt;假2231 23 213 13  212     23   2   23  假    3  2323 23 23 3  232   3     0  223 32 真   这应该是一个时间序列分类问题，但我的时间序列是按列排列的。最重要的是，其中一些是按月分组的，我不确定是否需要以某种方式对其进行编码。 如果你们知道如何解决这个问题，请赐教。 如果你们知道如何解决这个问题，请赐教。 &gt;   由   提交/u/monter72  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biiwmr/p_anomaly_detection_in_time_series/</guid>
      <pubDate>Tue, 19 Mar 2024 12:21:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 带注释的曼巴：艰难的道路</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biisb2/p_annotated_mamba_the_hard_way/</link>
      <description><![CDATA[链接：https://srush .github.io/annotated-mamba/hard.html 代码：https://github .com/srush/annotated-mamba 来自作者：  此博客是关于Mamba 一种最新的神经架构，可以粗略地认为是现代循环神经网络（RNN）。该模型运行得非常好，是无处不在的 Transformer 架构的合法竞争对手。它已经引起了很多关注。  我原本打算写一篇关于整篇论文的博文，内容相当密集且富有洞察力。然而，我只是对此处描述的 S6 算法着迷。该算法描述了如何在现代硬件上有效计算极大的 RNN，并扩展了 S4 和 近年来的S5。  事实上，如果我说实话，我实际上只了解了算法的这一行： y = SSM(A, B, C)( x) # 随时间变化：仅重复(扫描)  这行代码很有趣，我想，嘿，难道没有人能够理解为什么这种扫描在实践中速度很快吗？  事实证明这有点棘手。但是，如果您阅读这篇博文，我可以向您保证，您会理解这句话。 （也许比您想要的更多）。  第 0 部分：Triton  第 1 部分：累积和  第 2 部分：指数移动平均线  第 3 部分：获取导数  p&gt; 第 4 部分：同时多个  第 5 部分：Mamba  ​   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biisb2/p_annotated_mamba_the_hard_way/</guid>
      <pubDate>Tue, 19 Mar 2024 12:14:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Scikit-Learn 进行机器学习实践 - 书库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biidsi/d_handson_machine_learning_with_scikitlearn_book/</link>
      <description><![CDATA[我一直在阅读“使用 Scikit-Learn、Keras 和 TensorFlow 进行机器学习实践（第 3 版）”。官方存储库位于 https://github.com/ageron/handson-ml3&lt; /p&gt; 然而，对于旧版本的库（也许还有 Python）来说似乎也是如此。这本书没有明确说明需要哪些库版本。 我注意到有很多分叉，有人知道有一个好的分叉可以与最新版本的 Python 和库保持同步吗？&lt; /p&gt; 谢谢。   由   提交/u/Low-Design787  /u/Low-Design787 reddit.com/r/MachineLearning/comments/1biidsi/d_handson_machine_learning_with_scikitlearn_book/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biidsi/d_handson_machine_learning_with_scikitlearn_book/</guid>
      <pubDate>Tue, 19 Mar 2024 11:52:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何将量化LLM与微软LIDA结合使用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bif90v/d_how_to_use_quantized_llm_with_microsoft_lida/</link>
      <description><![CDATA[Microsoft LIDA 是使用法学硕士自动生成可视化和信息图表的工具。我见过有人将它与非量化法学硕士一起使用。但就我而言，我使用 HF 中的 Nous-Hermes-llama-2-7b，并且找不到使用 LIDA 中的 llm API 以量化状态加载 LLM 的方法。这可以做到吗？  ​ 附注我是新手   由   提交/u/Stoner_Black_69   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bif90v/d_how_to_use_quantized_llm_with_microsoft_lida/</guid>
      <pubDate>Tue, 19 Mar 2024 08:19:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] NVIDIA GTC 2024 公告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bif6ey/d_nvidia_gtc_2024_announcements/</link>
      <description><![CDATA[NVIDIA 的计划已遍及加速计算、生成式 AI、行业应用、汽车、企业平台、Omniverse 和机器人领域。 其中一些最有趣的是：  DRIVE Thor：用于自动驾驶汽车中的生成式人工智能应用的车载计算平台。它每秒执行高达千万亿次操作，增强了自动驾驶的安全性，并支持与车辆的交互式对话。 Omniverse：融合物理和虚拟世界的数字孪生生态系统，帮助行业模拟、优化和识别更有效地执行操作。新的 Omniverse Cloud API 扩展了这些功能，使汽车和机器人等行业受益。 GR00T 项目：推动机器人和人工智能突破的人形机器人的基础模型。此外，还推出了 Jetson Thor 计算机，并升级至 NVIDIA Isaac™ 机器人平台，其中包含生成式 AI 模型和模拟工具。 Nvidia Blackwell GPU：一项尖端技术，旨在以 20 petaflops 的速度为下一代 AI 提供动力的性能。该GPU代表了人工智能能力的巨大飞跃，旨在实现万亿参数模型的民主化。 NVLink Switch 7.2 TI：新一代互连技术，可解决数据交换的瓶颈。它旨在促进 GPU 之间的通信，其规模适合最先进的 AI 模型。 NVIDIA NIM：一款新软件产品，旨在简化企业环境中生成式 AI 的部署。它将模型与优化的推理引擎打包在一起，并支持广泛的 GPU 架构。他们称其为所有人的人工智能包。  你最喜欢哪个？   由   提交 /u/vvkuka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bif6ey/d_nvidia_gtc_2024_announcements/</guid>
      <pubDate>Tue, 19 Mar 2024 08:13:59 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA Blackwell 平台到来，为计算新时代提供动力 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biei3t/nvidia_blackwell_platform_arrives_to_power_a_new/</link>
      <description><![CDATA[https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing  与相同数量的 NVIDIA H100 Tensor Core GPU 相比，GB200 NVL72 对于 LLM 推理工作负载的性能提升高达 30 倍，并将成本和能耗降低高达 25 倍。    由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biei3t/nvidia_blackwell_platform_arrives_to_power_a_new/</guid>
      <pubDate>Tue, 19 Mar 2024 07:23:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 适合分类数据的基于树的模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bidfrk/d_treebased_model_that_works_well_with/</link>
      <description><![CDATA[即不需要对类别进行单热编码，但知道通过类别的子集分割类别特征。我看到 lightgbm 和 catboost 可以做到这一点，任何人都可以用它们和分类数据来讲述他们在现实世界中的经历吗？   由   提交/u/question_23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bidfrk/d_treebased_model_that_works_well_with/</guid>
      <pubDate>Tue, 19 Mar 2024 06:08:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单的拼写错误或我的理解错误？！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bicphu/d_simple_typos_or_errors_in_my_understanding/</link>
      <description><![CDATA[      虽然我给所有作者发了邮件，但我没有收到任何回复...&lt; /p&gt; ​ 我真的很喜欢阅读论文“基于能量的模型的组合视觉生成”(NeurIPS`20; https://arxiv.org/abs/2004.06030)。 当我遵循论文中的想法时，我在理解方程时遇到了问题（8 ）。 根据论文的符号，EBM定义为（1）： 等式。 (1) 即能量函数，E_\theta(x)，被定义为指数顶部的负项。 ​ 在等式中。在下面的（3）中，作者定义了从任何基于能量的模型（EBM）获取样本的SGLD步骤。 接下来，根据作者提出的“概念析取”，联合化概率密度定义为（ 7），以不同 EBM 能量函数的 log-sum-exp 的指数形式。 https://preview.redd.it/sas3f4yg58pc1.png?width=1005&amp;format=png&amp;auto=webp&amp;s =2bb0aa67cf2767ede091102ce22965e8c8bdbe7c 从（7）中，我了解到联合能量函数相应为 -logsumexp(-E(x|c1), ...), 从而对应 SGLD应该有加号。但是，在论文中，作者用减号表述了 SGLD，而我输了... &lt; p&gt;翻阅官方代码实现后， (https://github .com/yilundu/ebm_compositionality/blob/c7ac54366d2d5a15f71871448bd720bf5b3eb82d/celeba_combine.py#L150C9-L150C32)我发现我的组合能量函数推导（ E(x|\cup_ic_i) ）似乎是正确，根据代码中 `e_pos` 变量的赋值。 ​ 不过，我想对此进行一些澄清有人可以浏览一下这篇文章并检查我的想法吗？ 提前谢谢你！   由   提交/u/vaseline555  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bicphu/d_simple_typos_or_errors_in_my_understanding/</guid>
      <pubDate>Tue, 19 Mar 2024 05:21:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] Nvidia GTC24 的 GPT4 参数计数与我们从 Semianalysis 获得的泄漏相同</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bi16pg/d_same_param_count_for_gpt4_from_nvidia_gtc24_as/</link>
      <description><![CDATA[   A Semianalysis 早前的报告称 GPT-4 是一个 1.8T 参数的 MoE 模型，有 16 位专家，每个有 111B 个参数。这是 GTC 会议的屏幕截图，具有相同的数字。 https://preview.redd.it/vyzfx2sel5pc1.png?width=1764&amp;format=png&amp;auto=webp&amp;s=dfce1d55c84dbc3c51e69f376161c47958f9cf 70   由   提交 /u/takuonline   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bi16pg/d_same_param_count_for_gpt4_from_nvidia_gtc24_as/</guid>
      <pubDate>Mon, 18 Mar 2024 20:36:19 GMT</pubDate>
    </item>
    <item>
      <title>Stability AI 发布 SV3D [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bi16eh/stability_ai_releases_sv3d_n/</link>
      <description><![CDATA[https://stability.ai /news/introducing-stable-video-3d  SV3D 将单个对象图像作为输入并输出该对象的新颖的多视图。然后我们可以使用这些新颖的视图和 SV3D 来生成 3D 网格。    由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bi16eh/stability_ai_releases_sv3d_n/</guid>
      <pubDate>Mon, 18 Mar 2024 20:35:58 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 介绍 ocrtoolkit：您的首选 OCR 软件包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bi0li0/project_introducing_ocrtoolkit_your_goto_ocr/</link>
      <description><![CDATA[当然，让我们直接从 Hey Reddit 社区的 GitHub 存储库集成信息！ 我很高兴能够介绍 ocrtoolkit，一个功能强大的 OCR 软件包，旨在简化您的工作流程并提升您的 OCR 任务！ 我的项目的用途 如果您发现自己在应对 OCR 相关挑战的同时还要处理复杂的样板代码，那么您很幸运。 ocrtoolkit 简化了整个 OCR 流程，为图像文件处理、模型执行、结果解析等任务提供直观的包装器。让我们深入研究核心功能：  数据集模块：需要轻松加载图像文件或目录？ ocrtoolkit.datasets 模块就是您的最佳选择。 模型模块：与 paddleOCR 等流行的 OCR 框架无缝集成，通过 ocrtoolkit.models 模块实现 ultralytics 和 doctr。利用 ultralytics 的复杂对象检测模型在运行 OCR 之前查明感兴趣区域。 包装器模块：利用包装器进行对象检测、单词检测和识别借助 ocrtoolkit.wrappers 模块，轻松获得识别结果。此独立模块可确保通过 pip install ocrtoolkit 快速安装。 实用程序模块：访问大量实用程序来执行单词到行合并、使用 ocrtoolkit.utilities 模块进行几何操作、文件 I/O 等。  目标受众 无论您是研究人员开始进行 OCR 相关项目的开发人员或数据科学家，ocrtoolkit 可以满足您的需求。该软件包是您简化工作流程、试验不同模型和框架以及简化推理过程的首选解决方案。 比较 让我们讨论一下 ocrtoolkit 与现有替代方案不同：  全面支持：与仅专注于推理的软件包不同，ocrtoolkit 为无数OCR 相关任务，从后处理推理结果到保存/加载和轻松可视化。 无缝集成：体验与流行的 OCR 和对象检测框架的无缝集成，促进轻松实验 用户友好的设计：在设计时考虑到了易用性，ocrtoolkit 确保快速设置和配置，使用户能够深入了解轻松完成 OCR 任务。  ocrtoolkit 不适合做什么  训练模型：ocrtoolkit不是为训练新的 OCR 模型而设计的。相反，它的主要重点在于利用预训练或微调的模型进行推理。 高性能应用程序：虽然 ocrtoolkit 拥有在生产中的成功使用环境中，它可能不是需要最大性能优化的应用程序的理想选择。  其他资源 探索全面的文档，并在其 PyPi 页面上了解有关 ocrtoolkit 的更多信息。深入研究存储库中的 notebooks 文件夹，获取富有洞察力的示例，并毫不犹豫地分享您的反馈和建议！ 感谢您的宝贵时间，我热切等待您的宝贵意见见解！ ^_^   由   提交/u/ajkdrag_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bi0li0/project_introducing_ocrtoolkit_your_goto_ocr/</guid>
      <pubDate>Mon, 18 Mar 2024 20:13:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] IJCAI'24反驳讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhspbk/d_ijcai24_rebuttal_discussion/</link>
      <description><![CDATA[大家好， 随着评论即将发布，我发起此线程来分享想法、问题和关于 IJCAI 提交的建议。 祝大家好运！   由   提交 /u/Acceptable_Pop1461   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhspbk/d_ijcai24_rebuttal_discussion/</guid>
      <pubDate>Mon, 18 Mar 2024 14:55:24 GMT</pubDate>
    </item>
    <item>
      <title>2024 年哪个库最适合时间序列预测和异常检测？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bho0r0/in_2024_which_library_is_best_for_time_series/</link>
      <description><![CDATA[我正在开发一个项目，负责识别时间序列数据中的异常情况。我遇到了 Facebook Prophet，但遗憾的是它自 2023 年以来就不再维护了。他们建议 NeuroProphet、nixtla 作为替代方案。在寻找替代方案时，我发现了来自 Facebook 的 Kats，它内置了先知支持。这里有哪些工具/库经验丰富的成员会推荐哪些工具/库来构建用于对大量时间序列数据进行异常检测的生产级系统？   由   提交 /u/ThakkidiMundan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bho0r0/in_2024_which_library_is_best_for_time_series/</guid>
      <pubDate>Mon, 18 Mar 2024 11:03:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当你使用人工智能进行总结时结果不正确时。爱思唯尔发表的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</link>
      <description><![CDATA[       由   提交 /u/vvkuka   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</guid>
      <pubDate>Mon, 18 Mar 2024 10:14:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>