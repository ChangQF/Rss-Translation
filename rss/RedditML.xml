<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Fri, 05 Jul 2024 21:14:12 GMT</lastBuildDate>
    <item>
      <title>[D] [P] 语言模型中上下文长度的指数增长</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw6e1r/d_p_exponential_growth_of_context_length_in/</link>
      <description><![CDATA[      https://preview.redd.it/0v289d9r2rad1.png?width=5376&amp;format=png&amp;auto=webp&amp;s=014fc378d270ac8f8a7090eab1880fb381fe67f4 LLM 上下文长度大小似乎在过去几年中呈指数级增长 - 从 T5/BERT/GPT-1 的 512 个标记到最新的 Gemini 1.5 Pro 的 200 万个标记。 目前尚不清楚上下文窗口是否会继续以这种速度增长，或者是否会在某个时候达到稳定状态。有多少上下文窗口变得没有必要？ （如果我们估计 100 个标记大约为 75 个单词，那么所有 7 本《哈利波特》书籍都可以容纳 150 万个标记。）  数据收集说明： 必须追踪每个单独模型的发布博客（如果有的话）并与它们的 API 文档（如果存在）进行交叉引用。或者一篇论文（如果有的话）。这个领域变化如此之快，而且一家公司发布具有 X 上下文窗口的模型，然后在 1 个月后更新 API 文档并说“但是等一下！上下文长度现在是 Y”的情况并不少见。） 分享下面的原始数据，因为我花了很多时间煞费苦心地收集这些数据。此外，如果我错过了什么，请随时进行抽查。 https://docs.google.com/spreadsheets/d/1xaU5Aj16mejjNvReQof0quwBJEXPOtN8nLsdBZZmepU/edit?gid=0#gid=0    提交人    /u/porkbellyqueen111   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw6e1r/d_p_exponential_growth_of_context_length_in/</guid>
      <pubDate>Fri, 05 Jul 2024 19:34:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 想法/神经网络的噪声训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw55oj/d_idea_noise_training_for_neural_networks/</link>
      <description><![CDATA[大家好， 所以我有这个想法，不确定我是否对此感兴趣或者这只是一个愚蠢的想法，但这就是它，我已经从神经网络中删除了反向传播部分，为了学习，我从权重噪声开始并计算损失，然后不是反向传播损失，我实际上在权重中添加了更多的噪声并进行比较，如果我们得到了改进，那么我们将新的噪声嵌入到权重中并重复。 不确定这将如何随着更复杂的数据而扩展，这是对具有 1000 个 epoch 的 XOR 逻辑训练与噪声和反向传播训练的比较，我也在以下链接上在 GitHub 上分享了 python 代码： https://github.com/fredconex/noise_nn 噪声学习 第 0 轮，损失：0.2937433820120446 第 100 轮，损失：0.22431041582759073 第 200 轮，损失：0.1906882233983937 第 300 轮，损失：0.14403751588683966 第 400 轮，损失：0.08006607554003248 第 500 轮，损失：0.03356812554810006 第 600 轮，损失：0.007205973953185967 Epoch 700，损失：0.0016136777928940434 Epoch 800，损失：0.0005096870119629543 Epoch 900，损失：0.00015451156008521787 测试训练好的网络： 输入：[0 0 1]，目标：[0]，预测：0.0024 输入：[0 1 1]，目标：[1]，预测：0.9961 输入：[1 0 1]，目标：[1]，预测：0.9952 输入：[1 1 1]，目标：[0]，预测： 0.0049 反向传播学习 第 0 轮，损失：0.3678662495760854 第 100 轮，损失：0.2475451982698003 第 200 轮，损失：0.24464254676409536 第 300 轮，损失：0.24159435816660793 第 400 轮，损失：0.23818346709910115 第 500 轮，损失：0.2342557645653196 第 600 轮，损失： 0.2297073941835986 Epoch 700，损失：0.2244873371316301 Epoch 800，损失：0.21860583525411875 Epoch 900，损失：0.2121335280818446 测试训练好的网络： 输入：[0 0 1]，目标：[0]，预测：0.3484 输入：[0 1 1]，目标：[1]，预测：0.5324 输入：[1 0 1]，目标：[1]，预测：0.5968 输入：[1 1 1]，目标： [0]，预测：0.5643    由   提交  /u/dreamfoilcreations   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw55oj/d_idea_noise_training_for_neural_networks/</guid>
      <pubDate>Fri, 05 Jul 2024 18:41:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何追踪一段时间内的文本分类准确性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw4mfa/d_how_do_you_track_the_accuracy_of_text/</link>
      <description><![CDATA[^ 标题    提交人    /u/Different-General700   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw4mfa/d_how_do_you_track_the_accuracy_of_text/</guid>
      <pubDate>Fri, 05 Jul 2024 18:18:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 建模和学习物体之间的相似性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw46vp/d_modelling_and_learning_similarity_between/</link>
      <description><![CDATA[我对相似性建模很感兴趣。我有一组 (a, b) 对的数据集，它们的相似性 (y) 介于 0 和 1 之间，数据集很小，并且此应用程序不存在高质量的嵌入（不是图像或文本）。如果没有，我只会嵌入 + 余弦距离。 我可以将 [a,b] 对连接起来并构建回归模型，但会失去函数的对称性 (f(a,b)=f(b,a))。 什么样的模型/层/损失函数对相似性建模有用？    提交人    /u/prof_in_progress   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw46vp/d_modelling_and_learning_similarity_between/</guid>
      <pubDate>Fri, 05 Jul 2024 18:00:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 受限解码作为状态导航？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw2pqo/d_constrained_decoding_as_stateful_navigation/</link>
      <description><![CDATA[在实现 LLM 驱动的代理时，存在一系列方法，具体取决于“包装”程序尝试构造、控制或处理 LLM 的输入和输出的程度。一种方法涉及包装程序解析 LLM 的输出，并且为了使此过程更可靠，LLM 的解码器被限制为特定语法（例如 XML 或 JSON）或甚至特定的 XML 或 JSON 模式。 将解码器限制为您当前需要的语法通常是通过将违反语法的潜在输出值的概率归零来实现的。但是，如果 LLM 没有接受过针对您尝试执行的语法的任何特定培训，则此策略可能不是最佳的。 让我们以一个非常简单的语法为例。此语法中的有效字符串以双引号字符开头和结尾。字符串内部有两个字符必须“转义”：反斜杠和双引号。转义序列以反斜杠开头。 合法：“John 说，\&quot;This is a legal string.\&quot;。&quot; 合法：“John 说，&quot; 非法：“John 说，&quot;This string makes me sad.&quot;&quot; 如果我们将解码器视为“试图”用其输出表示某些编码向量，则它只有在“提前计划”一点点的情况下才能在此语法中这样做。它可能“想要”发出一个双引号字符，并且无论之前的内容是什么，语法都允许这样做。但是，如果该双引号字符前面没有反斜杠，则字符串必须在双引号之后立即结束，以使字符串合法。如果它“想要”发出双引号但不结束，它需要“知道”它不想在不久的将来结束并且为了不结束，它需要先发出反斜杠。 那么如何获得这种有计划的解码 - 理想情况下，同时能够使用尽可能接近现成的预训练 LLM？我不确定，但我有一个模糊的想法，我想知道社区会对此有何看法。 假设我们可以访问预训练的 LLM，包括中间层的激活。我们还有我们想要限制输出的语法，以图形的形式，其边缘标有潜在输出*。最后，我们有一个独热向量，指示解码过程当前位于语法图中的哪个节点（或者，对于语法的非确定性表示，是一个 k-hot 向量）。 来自预训练 LLM 的激活可用于为语法图的边缘分配“朴素可取性”。但是，出现了两个考虑因素：  要遍历的最理想边可能与当前状态无关。要到达那些边，我们可能需要遍历其他边（这可能需要我们发出其他输出标记）。在语义层面上，这“可以”吗？例如，某些恶意语法可能要求任何单词​​“dogs”的实例前面都有单词“absolutely no”。如果我到目前为止已经解码了“I love”，并且到达了“dogs”是可取的，我不想越过需要“绝对不”的语法边缘，否则我最终会说“我绝对不爱狗”。  在我们最终确定要发出的标记并将我们移动到语法图中的新节点之后，这是一个可以考虑我们可能还剩下什么需要解码的地方吗？  这些考虑让我认为通过语法表达 LLM 的编码含义就像玩 Metroidvania 式的游戏，其中不同的路径具有不同的成本和回报。不幸的是，我几乎没有灵活的游戏模型背景，所以我不确定从这一点开始要学习什么等（假设这首先是一条值得的攻击路线......）    提交人    /u/jpfed   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw2pqo/d_constrained_decoding_as_stateful_navigation/</guid>
      <pubDate>Fri, 05 Jul 2024 16:57:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 发布我基于 VGG 感知损失的损失函数。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw2dfb/p_releasing_my_loss_function_based_on_vgg/</link>
      <description><![CDATA[您好，这是我已经做了一段时间的项目。我使用“VGG Loss”在我的某些项目中，我一直觉得从一个模型中提取信息来训练另一个模型很有趣。 以此为灵感，我创建了这个项目，它允许您使用几乎任何来自 PyTorch 的预训练模型作为训练新模型的基础。 在代码中，您可以找到一个使用 DINOv2 作为损失函数（扮演 VGG 的角色）的示例，但该函数旨在接受除 Dino 之外的任何其他模型，甚至不接受图像作为输入的模型，例如 LLM 或任何其他模型。 这是一个专门为我在我的项目中使用和共享而开发的项目，所以我没有附加任何文章，它的大部分逻辑都是在我的项目中使用时通过反复试验开发出来的。 在 GitHub 描述中，有更多关于它的信息。我希望这个项目对某些人有用。 https://github.com/BurguerJohn/global_perceptual_similarity_loss     提交人    /u/CloverDuck   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw2dfb/p_releasing_my_loss_function_based_on_vgg/</guid>
      <pubDate>Fri, 05 Jul 2024 16:43:14 GMT</pubDate>
    </item>
    <item>
      <title>[D],[R]这是真的吗，在 O(log n) 中顺序处理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw0to6/dris_this_true_sequential_processing_in_olog_n/</link>
      <description><![CDATA[有一篇学生的中等文章声称他的架构可以完成循环处理器（RNN）和变压器的工作，还讨论了如何将其用于图像生成。他的代码看起来有效且正确。 他声称构建了一个表现优于 distil-gpt 的 LLM，即使参数数量只有传统 LLM 的一半，而且训练方式也不尽相同。 我有个问题：这有什么新鲜的吗？ 阅读时间为 5 分钟。 文章链接：https://medium.com/@DakshishSingh/equinox-architecture-divide-and-compute-99c555ac08d6    提交人    /u/Conscious-Gazelle-91   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw0to6/dris_this_true_sequential_processing_in_olog_n/</guid>
      <pubDate>Fri, 05 Jul 2024 15:35:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mapper（Mapper算法）区分噪声和显著拓扑结构的能力的理论极限是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvzsy8/d_what_are_the_theoretical_limits_of_mappers/</link>
      <description><![CDATA[大家觉得怎么样？    提交人    /u/ICEpenguin7878   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvzsy8/d_what_are_the_theoretical_limits_of_mappers/</guid>
      <pubDate>Fri, 05 Jul 2024 14:50:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 推荐一些关于模型合并的好资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvzr9d/d_suggest_any_good_resources_for_model_merging/</link>
      <description><![CDATA[我知道有合并模型的工具，但我想要一些关于合并模型的理论材料。任何讨论如何合并模型的博客、文章或研究论文都会有所帮助。 我将不胜感激您的帮助 :) 谢谢    提交人    /u/Ok_Cartographer5609   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvzr9d/d_suggest_any_good_resources_for_model_merging/</guid>
      <pubDate>Fri, 05 Jul 2024 14:48:53 GMT</pubDate>
    </item>
    <item>
      <title>[P] TensorFlow 概率的 torch 等价性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvwfov/p_torch_equivalence_of_tensorflow_probability/</link>
      <description><![CDATA[大家好， 我已经使用 tensorflow 很多年了，但对 pytorch 的经验有限。我正在考虑在 pytorch 上构建我的下一个项目。有没有人有在 pytorch 中进行近似推理的经验，有没有 tensorflow 概率的等效包？ 谢谢！    提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvwfov/p_torch_equivalence_of_tensorflow_probability/</guid>
      <pubDate>Fri, 05 Jul 2024 12:08:19 GMT</pubDate>
    </item>
    <item>
      <title>ECCV 相机就绪论文 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvvzpm/camera_ready_paper_for_eccv_discussion/</link>
      <description><![CDATA[嗨， 我的论文被 ECCV 接受了，在反驳期间，我们从审稿人那里得到了很多有用的反馈。我们想把它们包括在主论文中，但超出了 14 页的限制。为了解决这个问题，我们想将一个消融研究图表和讨论从主论文移到补充材料中。当然，我们会在主图中引用它，但允许吗？    提交人    /u/dn8034   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvvzpm/camera_ready_paper_for_eccv_discussion/</guid>
      <pubDate>Fri, 05 Jul 2024 11:43:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否应该从整个数据集中删除异常值，还是仅从训练集中删除？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvupyf/d_should_outliers_be_removed_from_the_full/</link>
      <description><![CDATA[我想删除异常值以检查它是否可以改进我的模型。 我应该在整个数据集上还是仅在训练数据集上删除它们？ 如何使用欠采样来平衡我的数据集？应该在整个数据集上进行平衡还是仅在训练集上进行平衡？    提交人    /u/fabiopires10   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvupyf/d_should_outliers_be_removed_from_the_full/</guid>
      <pubDate>Fri, 05 Jul 2024 10:22:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] Grad-CAM 医学成像可视化问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvkg4j/r_problems_with_gradcam_visualization_for_medical/</link>
      <description><![CDATA[嗨，我在灰度胸部热图数据集上训练了一些 ImageNet 模型来检测异常后，使用了 grad-CAM 可视化。但是，几乎所有网络都关注无关特征，如手臂、肩膀、胸部下方等，除了相关区域（胸部）之外的所有区域。我甚至尝试过裁剪图像，但效果并不明显，因为它仍然关注随机点。我们如何才能强制模型关注胸部？此外，尽管我获得了很高的准确率，但模型关注无关特征（如 Grad-CAM 所见）这一事实是否会使我的结果无效？  更新：对于一个模型，在第 5 个训练阶段，它实际上显示了比第 10 个训练阶段更相关的可视化（胸部区域）……不确定发生了什么    由    /u/Low-Literature-9699  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvkg4j/r_problems_with_gradcam_visualization_for_medical/</guid>
      <pubDate>Thu, 04 Jul 2024 23:37:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 杰出机器学习工程师的稀有技能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dv2thm/d_rare_skills_of_execptional_ml_engineers/</link>
      <description><![CDATA[大家好，ML 社区！ 无论你的头衔是什么（DS/工程经理/工程总监/ML 工程...），你工作场所中的 ML 工程师拥有哪些罕见技能，使他们真正从其他人中脱颖而出（在软技能和硬技能领域）？如果可能的话，请说明你的立场——不同角色如何看待这个话题可能会很有趣。 谢谢！    提交人    /u/Avistian   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dv2thm/d_rare_skills_of_execptional_ml_engineers/</guid>
      <pubDate>Thu, 04 Jul 2024 09:29:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>