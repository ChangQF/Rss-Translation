<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sat, 16 Mar 2024 21:11:02 GMT</lastBuildDate>
    <item>
      <title>项目建议[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgbj7g/project_suggestion_d/</link>
      <description><![CDATA[嘿，我有一个 ML 项目，需要从卫星获取数据，但尚未选择主题。知道我基本上刚刚开始使用 ML，有什么有趣的建议吗？   由   提交/u/Monkey_D_Uzumaki7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgbj7g/project_suggestion_d/</guid>
      <pubDate>Sat, 16 Mar 2024 17:38:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] Apple - MM1：多模式 LLM 预培训的方法、分析和见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgbc5u/r_apple_mm1_methods_analysis_insights_from/</link>
      <description><![CDATA[Apple 的新论文介绍了 MM1 ，一系列结合了视觉和语言理解的多模式人工智能模型。研究人员进行了广泛的实验，以确定驱动这些模型性能的关键因素，测试不同的架构选择和预训练数据混合。 以下是我在论文中的要点： Big当然之一：最大的 MM1 模型（30B 密集）在多模态基准上实现了最先进的少样本学习 要点：  MM1 包括两者高达 30B 参数的密集模型和专家混合 (MoE) 变体 图像分辨率对性能的影响最大，超过模型大小 特定的视觉语言连接器设计具有效果不大 在预训练中混合交错图像+文本、标题和纯文本数据至关重要 标题、交错和文本数据的比例为 5:5:1 有效最佳 合成字幕数据有助于少样本学习 30B 密集模型在 VQA 和字幕任务上击败了先前的 SOTA  核心见解深思熟虑的数据和架构选择，而不仅仅是规模，是构建高性能多模式模型的关键。 MM1 模型还表现出令人印象深刻的新兴能力，例如多图像推理和上下文中的小样本学习。 完整摘要。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/1bgbc5u/r_apple_mm1_methods_analysis_insights_from/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgbc5u/r_apple_mm1_methods_analysis_insights_from/</guid>
      <pubDate>Sat, 16 Mar 2024 17:29:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用计算机视觉对我的黑胶唱片收藏进行编目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgaeqi/p_cataloguing_my_vinyl_collection_with_computer/</link>
      <description><![CDATA[   /u/zerojames_  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgaeqi/p_cataloguing_my_vinyl_collection_with_computer/</guid>
      <pubDate>Sat, 16 Mar 2024 16:48:37 GMT</pubDate>
    </item>
    <item>
      <title>我应该为 7b 模型使用哪种 AWS 服务 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bga9aw/which_aws_service_should_i_use_for_a_7b_model_d/</link>
      <description><![CDATA[嘿，我有一个硬件问题:) 我想微调带有 10k 提示的 Mistra 7b 模型 - 使用令牌长度长达 10 000，现在我遇到了一个问题 我正在 AWS 中寻找我的力量。因为我的大学不愿意支付 colab 的 a100 费用，因为他们与 AWS 有一些东西 因此，据我所知，我基本上可以选择使用 4 x T4 或 4 x V100。 T4 的价格大约便宜 4 倍。你有什么建议？或者 AWS 上是否有比我认为最好的更好的选择？ P.S：我的预算为 500 欧元最终需要微调2个模型   由   提交/u/Brighton_Beach  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bga9aw/which_aws_service_should_i_use_for_a_7b_model_d/</guid>
      <pubDate>Sat, 16 Mar 2024 16:41:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 动态内存压缩：改造 LLM 以加速推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bga7xf/r_dynamic_memory_compression_retrofitting_llms/</link>
      <description><![CDATA[     &lt; td&gt; 动态内存压缩：改进 LLM 以加速推理 论文：https://arxiv.org/abs/2403.09636 X：https://x.com/p_nawrot/status/1768645461689168365 摘要：  Transformers 已成为大型语言模型 (LLM) 的支柱。然而，由于需要在内存中存储过去标记的键值表示的缓存，生成仍然效率低下，其大小与输入序列长度和批量大小线性缩放。作为解决方案，我们提出了动态内存压缩（DMC），这是一种在推理时进行在线键值缓存压缩的方法。最重要的是，该模型学习在不同的头和层中应用不同的压缩率。我们将 Llama 2（7B、13B 和 70B）等预训练的 LLM 改造为 DMC Transformer，在 NVIDIA H100 GPU 上实现自回归推理吞吐量高达约 3.7 倍的增长。 DMC 通过对原始数据的可忽略百分比进行持续预训练来应用，无需添加任何额外参数。我们发现 DMC 通过高达 4 倍的缓存压缩保留了原始的下游性能，优于经过训练的分组查询注意力 (GQA)。 GQA 和 DMC 甚至可以结合起来以获得复合收益。因此，DMC 在任何给定的内存预算内都适合更长的上下文和更大的批次。  https:/ /i.redd.it/ouuf7t4d5qoc1.gif   由   提交 /u/alancucki   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bga7xf/r_dynamic_memory_compression_retrofitting_llms/</guid>
      <pubDate>Sat, 16 Mar 2024 16:40:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] Kaggle TPU v3-8 的 Llama2 7B 和 13B 聊天完成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bg9wmj/p_llama2_7b_and_13b_chat_completion_for_kaggle/</link>
      <description><![CDATA[大家好，我对 Llama2 存储库进行了一些修改以利用 TPU v3-8 硬件，因此它可以执行 Llama2 7B（甚至 13B） ）聊天完成推理，无需图形重新编译。当批量大小为 1 生成文本时，它仍然比 Nvidia P100 慢，不适合实时推理，但（TPU 就是 TPU）在批量文本生成方面表现出色。我用它生成大量文本用于研究目的。希望它对社区有益。 这是存储库。 修改利用 PyTorch/XLA SPMD 系统（在 TPU v3-8 上）以及新的网格和分布配置来进行分片整个 TPU 网格的权重和缓存。具体来说，k、v 缓存具有预定义的静态大小，以避免每次令牌生成后 TPU 图形重新编译。这一新配置使 Llama2 7B 能够装入一台 TPU v3-8 设备中，并具有大量剩余内存来运行推理，批量大小可达 64。相同的配置也可用于运行 Llama2 13B 的推理。 现有的Llama2 Google Next Inference分支仅支持TPU v4和 v5e。喜欢使用 Kaggle TPU 的人可以利用它来运行推理。   由   提交/u/-x-Knight   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bg9wmj/p_llama2_7b_and_13b_chat_completion_for_kaggle/</guid>
      <pubDate>Sat, 16 Mar 2024 16:25:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLaMA 的具体细节：了解 LLaMA 和大型语言模型如何运行的整体方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bg61qi/p_llama_nuts_and_bolts_a_holistic_way_of/</link>
      <description><![CDATA[我很高兴地宣布，我使用 Go 开发的 LLaMA Nuts and Bolts 开源项目现已公开发布！ 您可以在我的 Github 存储库上找到它：https://github.com/adalkiran/llama-nuts-and- Bolts 通过代码和详细文档了解 LLaMA 及其组件在实践中如何运行的整体方法。 “螺母和螺栓” （实践方面而不是理论事实，纯粹的实现细节）所需的组件、基础设施和数学运算，而不使用外部依赖项或库。 目标是制作一个可以对 LLaMa 进行推理的实验项目2 7B-聊天模型完全脱离Python生态系统（使用Go语言）。在整个旅程中，我们的目标是获取知识并阐明该技术的抽象内部层。 这段旅程是一次有意重新发明轮子的旅程。在阅读我的文档中的旅程时，您将通过 LLaMa 模型的示例了解大型语言模型如何工作的详细信息。 如果您像我一样对 LLM（大型语言模型）如何工作感到好奇和变形金刚工作并深入研究了来源中的概念解释和示意图，但渴望更深入的理解，那么这个项目也非常适合您！ 您不仅会发现 LLaMa 架构的细节，而且还会发现在文档目录中查找各种相关概念的解释。从逐字节读取 Pickle、PyTorch 模型、Protobuf 和 SentencePiece 分词器模型文件，到 BFloat16 数据类型的内部结构、从头开始实现 Tensor 结构和包括线性代数计算在内的数学运算。 这个项目最初是为了通过运行和调试来了解 LLM 的作用，并且仅用于实验和教育目的，而不是用于生产用途。 如果您查看它，我会很高兴欢迎评论！   由   提交 /u/adalkiran   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bg61qi/p_llama_nuts_and_bolts_a_holistic_way_of/</guid>
      <pubDate>Sat, 16 Mar 2024 13:25:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 这些数据集有什么不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bg44d8/r_what_is_different_between_these_datasets/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.05652 摘要：  机器学习模型的性能在很大程度上取决于输入的质量数据，但现实世界的应用程序经常遇到各种与数据相关的挑战。当在现实世界中管理训练数据或部署模型时，可能会出现这样的挑战 - 同一领域中的两个可比较的数据集可能具有不同的分布。尽管存在多种检测分布变化的技术，但文献缺乏以人类可理解的方式解释数据集差异的综合方法。为了解决这一差距，我们提出了一套可解释的方法（工具箱）来比较两个数据集。我们展示了我们的方法在不同数据模式中的多功能性，包括低维和高维设置中的表格数据、语言、图像和信号。我们的方法不仅在解释质量和正确性方面优于可比较和相关的方法，而且还提供了可操作的补充见解，以有效地理解和减轻数据集差异。  &lt;!-- SC_ON - -&gt;  由   提交/u/SunsetOneSix  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bg44d8/r_what_is_different_between_these_datasets/</guid>
      <pubDate>Sat, 16 Mar 2024 11:38:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] RepoHyper：存储库级代码完成所需的只是更好的上下文检索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bg396m/r_repohyper_better_context_retrieval_is_all_you/</link>
      <description><![CDATA[我们引入了 RepoHyper，这是一个新颖的框架，可将代码完成转换为现实世界存储库用例的无缝端到端流程。传统方法依赖于将上下文集成到代码语言模型 (CodeLLM) 中，通常假设这些上下文本质上是准确的。然而，我们发现了一个差距：标准基准测试并不总是提供相关的上下文。 为了解决这个问题，RepoHyper 提出了三个新颖的步骤：  构建代码属性图，建立丰富的上下文源。 一种新颖的搜索算法，用于查明所需的确切上下文。 扩展算法，旨在揭示代码元素之间的微妙联系（类似于社交网络挖掘中的链接预测问题）。  我们的综合评估表明，RepoHyper 树立了新标准，在 RepoBench 基准测试中优于其他强大的基准。 代码：https://github.com/FSoft-AI4Code/RepoHyper   由   提交 /u/FSoft_AIC   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bg396m/r_repohyper_better_context_retrieval_is_all_you/</guid>
      <pubDate>Sat, 16 Mar 2024 10:41:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] AnyGPT：具有离散序列建模的统一多模态法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bg2x83/r_anygpt_unified_multimodal_llm_with_discrete/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.12226 代码：https://github .com/OpenMOSS/AnyGPT 数据集：https:// Huggingface.co/datasets/fnlp/AnyInstruct 项目页面：https://junzhan2000.github.io/AnyGPT.github.io/ 视频：https://www.youtube.com/watch?v=oW3E3pIsaRg 摘要：  我们介绍 AnyGPT，这是一种任意对任意的多模态语言模型，它利用离散表示来统一处理各种模态，包括语音、文本、图像和音乐。 AnyGPT 可以稳定地训练，无需对当前的大语言模型（LLM）架构或训练范式进行任何改变。相反，它完全依赖于数据级预处理，促进新模式无缝集成到法学硕士中，类似于新语言的合并。我们构建了一个以文本为中心的多模态数据集，用于多模态对齐预训练。利用生成模型，我们合成了第一个大规模任意对任意多模式指令数据集。它由 108k 个多轮对话样本组成，这些对话错综复杂地交织着各种模态，从而使模型能够处理多模态输入和输出的任意组合。实验结果表明，AnyGPT 能够促进任意对任意的多模态对话，同时在所有模态中实现与专用模型相当的性能，证明离散表示可以有效且方便地统一语言模型中的多种模态。演示显示在 此 https URL    由   提交/u/SunsetOneSix  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bg2x83/r_anygpt_unified_multimodal_llm_with_discrete/</guid>
      <pubDate>Sat, 16 Mar 2024 10:18:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML 中的函数式编程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bfu3oy/d_functional_programming_in_ml/</link>
      <description><![CDATA[我觉得 Python 中的大多数 ML 库都是用 OOP 风格编写的。这是有道理的，因为 Python 没有像 Haskell 这样的“好”类型系统，因此类是用可读名称定义接口的好方法。其他功能更强大的语言是否有流行的 ML 库？我特别想到 Haskell、Rust 或 Scala。   由   提交 /u/LengthinessMelodic67   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bfu3oy/d_functional_programming_in_ml/</guid>
      <pubDate>Sat, 16 Mar 2024 01:15:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 转载MetaAI的《自我奖励语言模型》论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bfnz2l/p_reproducing_the_selfrewarding_language_models/</link>
      <description><![CDATA[大家好， 读完 Meta 团队的《自我奖励语言模型》论文后，感觉非常平易近人且可重现，所以我们花了一些时间来实现它。 ​ 提供的脚本采用任何基本模型并将其放入循环中： 1 ）对初始数据集进行监督微调 2）使用 SFT 生成新提示 3）每个提示生成 N 个响应 4）对生成的结果进行评分响应 1-5 5) 对模型本身的奖励运行 DPO。 ​ 我们已经通过一个循环运行它，从开始使用 Mistral-7b 基础模型，到目前为止结果非常令人鼓舞。  ​ 请随意检查或亲自运行它，并让我们知道您的想法： https://github.com/Oxen-AI/Self-Rewarding-Language-Models   由   提交 /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bfnz2l/p_reproducing_the_selfrewarding_language_models/</guid>
      <pubDate>Fri, 15 Mar 2024 20:42:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 类似于 distill.pub 的博客？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bfml1x/d_blogs_similar_to_distillpub/</link>
      <description><![CDATA[大家好，我是distill.pub的忠实粉丝并且经常发现自己会重新访问他们的一些帖子，即使是在它们中断之后。他们的文章制作精美，通常通过视觉手段直观地解释概念。我很好奇您是否会推荐任何其他类似于 distill.pub 的博客或网站？   由   提交 /u/JellyBean_Collector   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bfml1x/d_blogs_similar_to_distillpub/</guid>
      <pubDate>Fri, 15 Mar 2024 19:43:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些编写良好的 ML 代码库可供参考，以获取优秀 ML 软件设计的灵感？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bf85rj/d_what_are_some_wellwritten_ml_codebases_to_refer/</link>
      <description><![CDATA[您将哪些公开可用的机器学习项目作为优秀机器学习软件设计的示例？我指的是抽象模型/数据集/度量类的定义方式、基于该设计添加新功能的难易程度以及使用它们的整体体验等方面。 例如，我相信 scikit-learn 是良好设计的一个例子。即使对于新手来说，拟合/预测范式也非常容易理解。  大多数现代项目似乎都在使用配置驱动的对象动态初始化，我也很欣赏围绕此类设计的良好实践的资源。这种设计的一些例子是 Huggingface 和基于 Hydra 的实验代码库。 作者解释其设计理念的帖子链接也会有所帮助。例如，huggingface 的理念是“重复自己”，而不是“不要重复自己”。 它也有助于列出要避免的库。 谢谢！&lt; /p&gt;   由   提交/u/unused_MLE   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bf85rj/d_what_are_some_wellwritten_ml_codebases_to_refer/</guid>
      <pubDate>Fri, 15 Mar 2024 07:16:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>