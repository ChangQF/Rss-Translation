<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 29 Dec 2024 18:20:23 GMT</lastBuildDate>
    <item>
      <title>[D] 您是否使用 google repo 训练大视觉模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp1o82/d_do_you_train_big_vision_models_using_the_google/</link>
      <description><![CDATA[你们使用 google repo 来训练模型吗？代码库太乱了，我很难理解训练自定义版本的 SigLIP 需要/不需要什么。    提交人    /u/TechySpecky   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp1o82/d_do_you_train_big_vision_models_using_the_google/</guid>
      <pubDate>Sun, 29 Dec 2024 18:01:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 贝叶斯力学与主动推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp1dew/d_bayesian_mechanics_and_active_inference/</link>
      <description><![CDATA[        提交人    /u/moschles   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp1dew/d_bayesian_mechanics_and_active_inference/</guid>
      <pubDate>Sun, 29 Dec 2024 17:49:08 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] [教育] 机器学习项目中的决策</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp17rc/discussion_educational_decision_making_in_machine/</link>
      <description><![CDATA[大家好，机器学习社区！ 我将 Andrew Ng（著名机器学习研究人员和企业家）关于机器学习项目中的决策的视频讲座笔记总结成了一本简短的电子书。 在改进模型时，很容易面临众多选择：应该训练更大的模型、使用 dropout、收集更多数据还是调整超参数？知道如何确定优先级对于提高效率至关重要。Andrew Ng 的讲座概述了解决这些决策的实用策略，例如使用错误分析来诊断您是否面临偏差或方差问题。 我希望将这些知识提炼成紧凑的书面格式，供我自己使用，也供我大学的数据科学团队使用，我们在那里参加数据科学挑战。但是，我的经验仍在增长，我很乐意改进。 这就是我在这里分享此文档的原因（我将其上传到 Google Drive 并在此处添加了链接）——我非常感谢那些经验更丰富的人的反馈。无论您同意、不同意，还是有建议完善内容，您的意见都将意义重大！ 提前感谢您的时间和见解！    提交人    /u/Hour_Individual_3656   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp17rc/discussion_educational_decision_making_in_machine/</guid>
      <pubDate>Sun, 29 Dec 2024 17:42:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我创建了一个用于使用和创建模仿学习数据集的包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp0m6m/p_ive_created_a_package_for_using_and_creating/</link>
      <description><![CDATA[      我知道你们当中会有一些像我一样研究模仿学习的人，但我想与你们分享这个个人项目。 我的项目做什么： 我从事模仿学习已经有一段时间了，一直困扰我的是，找到好的专家权重有多难，以及由于每项工作都使用他们的数据集，运行基线需要多长时间。因此，我创建了这个项目，努力让研究人员更容易使用 HuggingFace 的专家创建数据集并共享他们的数据。它是轻量级的，我正在（慢慢地）发布不同模仿学习方法的基准。目前，我们有 MuJoCo 和经典控制数据集，我正在用多种方法测试它们，以确保它们能正常工作。数据集有 1,000 集长，我正在考虑将其变得更大。 目标受众： 使用模仿学习或任何基于代理的学习进行研究的人需要数据。 比较： 我认为没有任何其他项目试图使数据易于访问。如果有，我很想了解它们。 项目如何运作！ 存储库： https://github.com/NathanGavenski/IL-Datasets    提交人    /u/NightmareOx   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp0m6m/p_ive_created_a_package_for_using_and_creating/</guid>
      <pubDate>Sun, 29 Dec 2024 17:16:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们如何才能善用机器学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp0m3o/d_how_can_we_use_ml_for_good/</link>
      <description><![CDATA[您好，我即将完成我的学士学位，我真的想利用我学到的关于机器学习和数据工程的知识来帮助人们，我有一些之前的经验，但如果我们可以与一些初创公司合作，分享我们关于机器学习和工程的知识并真正创造价值，那就太好了。 你知道一些初创公司或非政府组织利用他们的数据技能来帮助人们或促进创新吗？ 我们如何使用我们的技能来帮助别人？ 我一直在想，为小型企业设置基本的数据基础设施，然后使用机器学习算法帮助他们提高生产力会很好，但我不知道从哪里开始。    提交人    /u/Southern_Respond846   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp0m3o/d_how_can_we_use_ml_for_good/</guid>
      <pubDate>Sun, 29 Dec 2024 17:16:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了 Termite，一个可以通过简单的文本提示生成终端 UI 的 CLI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyzao/p_i_made_termite_a_cli_that_can_generate_terminal/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyzao/p_i_made_termite_a_cli_that_can_generate_terminal/</guid>
      <pubDate>Sun, 29 Dec 2024 16:02:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</guid>
      <pubDate>Sun, 29 Dec 2024 16:00:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 批量标准化及其对梯度的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoy9zk/d_batch_normalization_and_effect_on_the_gradients/</link>
      <description><![CDATA[我最近在读这篇论文：https://arxiv.org/pdf/1706.05350，我想了解作者是如何得出梯度与权重成反比这一事实的。这是第 3 页上的第一个等式。如果有人能给我提示或解释，我将不胜感激。    提交人    /u/Numerous_Talk7940   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoy9zk/d_batch_normalization_and_effect_on_the_gradients/</guid>
      <pubDate>Sun, 29 Dec 2024 15:29:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] L40S (46068 MiB) vs 6000 Ada (49140 MiB) - 为什么 L40S 更低？[nvidia-smi]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hox9zf/d_l40s_46068_mib_vs_6000_ada_49140_mib_why_l40s/</link>
      <description><![CDATA[      嗨， 我们有几个 L40S 和一些 RTX 6000Ada，两者都应该有 48GB 的​​ RAM，但我看到 L40S 只有 46,068 MiB 的 RAM，有人也看到了吗？ L40S 6000 Ada 知道发生了什么吗？ 谢谢    提交人    /u/oren_a   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hox9zf/d_l40s_46068_mib_vs_6000_ada_49140_mib_why_l40s/</guid>
      <pubDate>Sun, 29 Dec 2024 14:38:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 神经网络中的声音处理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hovytl/d_sound_processing_in_neural_networks/</link>
      <description><![CDATA[通常如何使用神经网络处理声音？在图像处理中，我听说卷积可能用于在分类之前提取边缘或纹理等特征。从声音中提取了什么样的特征，以及如何处理它们？    提交人    /u/FutureAd1004   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hovytl/d_sound_processing_in_neural_networks/</guid>
      <pubDate>Sun, 29 Dec 2024 13:25:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 骆驼的 ROPE 频率计算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hovvmm/d_rope_frequency_calculation_for_llama/</link>
      <description><![CDATA[这是基于 ROPE 频率计算的代码，由 transformers 库使用，位于此处。函数 _compute_llama3_parameters 采用默认的 rope 频率值，并在顶部执行一些 transformers。我的理解是，低频值和高频值的缩放比例不同，中间值经过调整以实现平滑过渡。 我正在寻找一个来源（论文甚至博客文章），在其中可以找到有关 llama 类型模型使用的这种特定方法的更多信息。计算正确吗？动机是什么（比如将低频缩小以允许更长的周期性）？ 供参考的代码（从上面的链接复制）：  inv_freq,tention_factor = _compute_default_rope_parameters(config, device, seq_len, **rope_kwargs) factor = config.rope_scaling[&quot;factor&quot;] # 原始实现中的 `8` low_freq_factor = config.rope_scaling[&quot;low_freq_factor&quot;] # 原始实现中的 `1` high_freq_factor = config.rope_scaling[&quot;high_freq_factor&quot;] # 原始实现中的 `4` old_context_len = config.rope_scaling[&quot;original_max_position_embeddings&quot;] # 原始实现中的 `8192` low_freq_wavelen = old_context_len / low_freq_factor high_freq_wavelen = old_context_len / high_freq_factor wavelen = 2 * math.pi / inv_freq # wavelen &lt; high_freq_wavelen: 什么都不做 # wavelen &gt; low_freq_wavelen：除以因子 inv_freq_llama = torch.where(wavelen &gt; low_freq_wavelen, inv_freq / factor, inv_freq) # 否则：使用平滑因子在两者之间进行插值 smooth_factor = (old_context_len / wavelen - low_freq_factor) / (high_freq_factor - low_freq_factor) smoothed_inv_freq = (1 - smooth_factor) * inv_freq_llama / factor + smooth_factor * inv_freq_llama is_medium_freq = ~(wavelen &lt; high_freq_wavelen) * ~(wavelen &gt; low_freq_wavelen) inv_freq_llama = torch.where(is_medium_freq, smoothed_inv_freq, inv_freq_llama) return inv_freq_llama,tention_factor     由    /u/graphitout 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hovvmm/d_rope_frequency_calculation_for_llama/</guid>
      <pubDate>Sun, 29 Dec 2024 13:20:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 ARIMA/SARIMA 进行风速预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hou9cq/p_wind_speed_prediction_with_arimasarima/</link>
      <description><![CDATA[      我正在做一个风速预测的项目。有些文章说使用 ARIMA / SARIMA 会是一个好的开始。 我确实开始使用 ARIMA，并且预测值没有任何变化。 当我尝试使用 SARIMA，季节性 = 12（一年中的月份），预测 36 个月（3 年）时，它给了我不满意的结果，这些结果看起来每年都一样（周期性的，因此远离现实）所以我放弃了 SARIMA。 请随时给我解决方案或更好的方法。    提交人    /u/Associate-Existing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hou9cq/p_wind_speed_prediction_with_arimasarima/</guid>
      <pubDate>Sun, 29 Dec 2024 11:33:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 图像模型中表示工程的最佳工具是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hondfe/d_what_are_the_best_tools_for_representation/</link>
      <description><![CDATA[我最近（感谢这个 subreddit）发现了一个非常易于使用的 LLM 表示工程工具。它允许您训练控制向量来控制模型的行为。我很好奇是否有类似的工具可以控制图像模型。    提交人    /u/jsonathan   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hondfe/d_what_are_the_best_tools_for_representation/</guid>
      <pubDate>Sun, 29 Dec 2024 03:48:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 神经嵌入的结构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hogog5/d_structure_of_neural_embeddings/</link>
      <description><![CDATA[  由    /u/SeanPedersen  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hogog5/d_structure_of_neural_embeddings/</guid>
      <pubDate>Sat, 28 Dec 2024 22:09:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>