<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 06 Nov 2024 03:20:07 GMT</lastBuildDate>
    <item>
      <title>论一项低预算的成功研究[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkn6tw/on_a_successful_research_with_low_budget_d/</link>
      <description><![CDATA[嗨，我有一个研究想法，并将其应用于 nanogpt repo 进行 lm 训练，经过验证的 transformer 在验证损失上概括得更好，但训练损失更差，更容易过度拟合，因为像训练损失稍差验证损失稍好，我只应用于完整的 shakespeare_char 和 openwebtext 上的子集，因为 runpod 上的 10 美元只允许我这样做，我仍然要发布一篇论文，因为我取得了不错的成绩并做了一些数学工作，我应该这样做吗？    提交人    /u/Mean-Force267   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkn6tw/on_a_successful_research_with_low_budget_d/</guid>
      <pubDate>Wed, 06 Nov 2024 01:37:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] Autograd 与 JAX？两者都是针对基于梯度的方法的 Google 产品。主要区别是什么？（GPU/TPU？）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkms4w/d_autograd_vs_jax_both_are_google_products_aimed/</link>
      <description><![CDATA[最近看到谷歌人开发的 Autograd（库），它对 numpy 进行了薄包装以提供反向传播。JAX 也这样做，但基本上重写了 numpy。有什么区别？是 JAX 的 gpu tpu 支持吗？autograd 适用于较小的模型吗？    提交人    /u/MysticalDragoneer   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkms4w/d_autograd_vs_jax_both_are_google_products_aimed/</guid>
      <pubDate>Wed, 06 Nov 2024 01:15:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 专用 AI 数据中心在增强模型训练和微调方面的作用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkmen4/d_the_role_of_dedicated_ai_data_centers_in/</link>
      <description><![CDATA[刚刚读到 Kinetic Seas 推出了一个新的 AI 专用数据中心——听起来他们的目标是让模型训练和微调变得不那么令人头疼。他们的设置包括专用的 GPU 和 CPU，据说是为了满足大型复杂模型的需求而构建的。如果传统数据中心感觉像是在上坡，那么这些 AI 专用中心可能就是在下坡？ 随着机器学习模型变得越来越耗费资源，我想知道像这样优化的基础设施是否会改变游戏规则。想想看：更快地训练模型，并且限制更少，可以真正提高研究人员和数据科学家的生产力。Kinetic Seas 似乎认为值得为 AI 构建基础设施，这感觉是一个非常有趣的赌注。 这里有人使用过这样的 AI 专用设置吗？好奇地想知道它是否真的像听起来那么顺利！ https://www.prnewswire.com/news-releases/kinetic-seas-fka-bellatora-announces-completion-of-phase-i-of-its-data-center-for-ai-302168707.html    提交人    /u/booboo1998   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkmen4/d_the_role_of_dedicated_ai_data_centers_in/</guid>
      <pubDate>Wed, 06 Nov 2024 00:55:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] LoRA 合并（和非线性模式连接）是更好的变压器超网络的关键吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkhy4n/d_is_lora_merging_and_non_linear_mode/</link>
      <description><![CDATA[大家好！我在想，如果我们可以根据手头的任务类型动态合并 LLM 微调 LoRA，我们就可以修复灾难性遗忘，甚至可以让 Transformer 更好地泛化。问题是，由于注意力层在权重上非常非线性，Transformer 不会表现出较差的 LMC（线性模式连接）。 您是否知道精确 LoRA 合并的计算复杂性？我看过很多关于 LoRA 合并的论文，但它们似乎质量很差，而且只是经验性的，几乎没有数学基础。 所以如果你们想到了，我很高兴听到它！    提交人    /u/Due-Pangolin325   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkhy4n/d_is_lora_merging_and_non_linear_mode/</guid>
      <pubDate>Tue, 05 Nov 2024 21:31:57 GMT</pubDate>
    </item>
    <item>
      <title>电子邮件分类工具 - 支持家庭暴力受害者 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkgmwo/tools_to_classify_emails_supporting_dv_victims/</link>
      <description><![CDATA[大家好， 如果发帖的地方不对，请见谅。我正在寻找可以帮助我支持伴侣的工具，她多年来一直受到前夫和孩子父亲的骚扰。 她正在努力收集限制令的证据，但回顾多年的电子邮件和其他信息对她来说是一种心理上的折磨。我想知道是否有任何工具可以很好地用于分析和分类电子邮件（无论是单独还是批量），以便我可以通过接手这项工作来支持她？    提交人    /u/BunsenFurner87   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkgmwo/tools_to_classify_emails_supporting_dv_victims/</guid>
      <pubDate>Tue, 05 Nov 2024 20:36:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 掌握 LLM 测试：确保下一代 AI 模型的准确性、道德性和未来准备度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkfa6n/d_mastering_llm_testing_ensuring_accuracy_ethics/</link>
      <description><![CDATA[大家好！😊 我刚刚发表了一篇文章：掌握 LLM 测试：确保下一代 AI 模型的准确性、道德和未来准备。我希望我没有错过那里的任何重要内容！ 我计划将其变成关于 AI 模型测试和一般测试的系列文章。希望你喜欢它，我随时欢迎反馈和讨论！😄    提交人    /u/tukan90   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkfa6n/d_mastering_llm_testing_ensuring_accuracy_ethics/</guid>
      <pubDate>Tue, 05 Nov 2024 19:38:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语音隔离</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkdx19/d_voice_isolation/</link>
      <description><![CDATA[嗨！ ElevenLabs 有一个相当不错的音频隔离 API，但它真的很贵。有没有可以自行托管并获得接近相同质量的开源模型？    提交人    /u/aszx789   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkdx19/d_voice_isolation/</guid>
      <pubDate>Tue, 05 Nov 2024 18:41:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 可以收敛到什么交叉熵损失值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gk92rs/d_to_what_crossentropy_loss_value_can_llms/</link>
      <description><![CDATA[LLM 通常在旨在衡量广泛能力的基准上进行评估。但是，大多数基础模型的发布者都不会发布模型在训练结束时实现的实际交叉熵损失值。我找不到任何关于此的资料，但我想知道 LLM 在人类语言上可以实现的损失值。有谁对此有更多了解吗？可能会有下限吗？    提交人    /u/cbl007   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gk92rs/d_to_what_crossentropy_loss_value_can_llms/</guid>
      <pubDate>Tue, 05 Nov 2024 15:19:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 切勿从头开始训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gk7dny/r_never_train_from_scratch/</link>
      <description><![CDATA[https://arxiv.org/pdf/2310.02980  作者表明，当对 transformer 进行预训练时，它们可以在 Long range Arena 基准上将性能与 S4 相匹配。    提交人    /u/Whatever_635   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gk7dny/r_never_train_from_scratch/</guid>
      <pubDate>Tue, 05 Nov 2024 14:02:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 文本分类：N 次提示分类 VS 在嵌入器上训练线性分类器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gk4wx1/d_text_classification_nshot_prompt_classification/</link>
      <description><![CDATA[我需要在工作中制作一个文本分类器。我对 5 个类别中的每个类别都有 200 个示例。每个示例都是一封电子邮件。两种方法：  使用 n-shot 即时分类对电子邮件进行分类，可能使用 LoRA 微调。 使用预先训练的文本嵌入器（例如句子转换器或 OpenAI text-embeddings-3）和分类头。在文本嵌入上训练分类器。  哪种方法最好？    提交人    /u/Aromatic-Oil-4586   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gk4wx1/d_text_classification_nshot_prompt_classification/</guid>
      <pubDate>Tue, 05 Nov 2024 11:53:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 二流论文在申请行业研究工作时有价值吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gjz3in/d_do_second_tier_papers_have_any_value_when_apply/</link>
      <description><![CDATA[我想我之前遇到过一些行业工作，要求申请人拥有顶级论文（NIPS/ICML/ICLR/CVPR/ICCV/ECCV），所以我的问题是，来自不太有声望（AAAI/IJCAI/WACV/BMVC.... 或期刊）会议的论文在申请这些工作时有任何价值吗？此外，h 指数或引用等指标重要吗？    提交人    /u/Competitive_Newt_100   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gjz3in/d_do_second_tier_papers_have_any_value_when_apply/</guid>
      <pubDate>Tue, 05 Nov 2024 04:58:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于准备 Google ML 面试的建议 – 应关注的关键领域？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gjxyg0/d_advice_on_preparing_for_google_ml_interview_key/</link>
      <description><![CDATA[我正在准备参加 Google 的机器学习面试，招聘人员分享了他们将重点关注的主要领域： - 理论 ML 概念和实际应用 - 包括问题定义、模型选择、模型调整和评估。 - 行业规模 ML - 涵盖性能和成本优化、数据处理以及面向生产的实验和调试。 如果有人对这些领域的期望或重点提示有任何见解，我将不胜感激！我特别难以理解“行业规模 ML”问题实际上可能是什么。 提前感谢任何建议或资源！ 编辑：背景：我已经完成了两次 LC 风格的面试。我想说第一次面试很容易，第二次面试肯定很难。我认为我在两方面都表现不错，但只有第二位面试官告诉我我的表现如何（显然我表现不错）。我还参加了 Googlyness 的面试，我认为面试也很顺利。我们进行了很好的交谈。    提交人    /u/atomicalexx   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gjxyg0/d_advice_on_preparing_for_google_ml_interview_key/</guid>
      <pubDate>Tue, 05 Nov 2024 03:53:08 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型（LLM）实际上可以很好地解决哪些问题？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gjoxpi/what_problems_do_large_language_models_llms/</link>
      <description><![CDATA[虽然人们对人工智能炒作周期的怀疑越来越多，尤其是围绕聊天机器人和 RAG 系统，但我感兴趣的是确定 LLM 在准确性、成本或效率方面明显优于传统方法的具体问题。我能想到的问题是： - 单词分类 - 非大段文本的情感分析 - 图像识别（在某种程度上） - 写作风格转换（在某种程度上） 还有什么？    提交人    /u/Educational-String94   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gjoxpi/what_problems_do_large_language_models_llms/</guid>
      <pubDate>Mon, 04 Nov 2024 20:52:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Nov 2024 16:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>