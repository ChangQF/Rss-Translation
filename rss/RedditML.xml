<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Fri, 14 Jun 2024 03:16:38 GMT</lastBuildDate>
    <item>
      <title>[D] 性格测试推荐系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dfgwrz/d_recommendation_system_for_personality_test/</link>
      <description><![CDATA[我想创建一个应用程序，让他们可以完成性格测试，并在此基础上创建一个推荐系统，推荐活动、俱乐部、研讨会和书籍，让他们更好地了解自己。  这作为人工智能可行吗？或者这太肤浅了？我还可以添加哪些其他功能使其成为人工智能    提交人    /u/capricornhera   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dfgwrz/d_recommendation_system_for_personality_test/</guid>
      <pubDate>Fri, 14 Jun 2024 02:59:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] Lamini.AI 推出记忆调节功能：法学硕士准确率达 95%，幻觉减少 10 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dffyfs/r_laminiai_introduces_memory_tuning_95_llm/</link>
      <description><![CDATA[https://www.lamini.ai/blog/lamini-memory-tuning  Lamini Memory Tuning 是一种将事实嵌入 LLM 的新方法，可提高事实准确性并将幻觉减少到以前无法实现的水平 - 对于一位财富 500 强客户来说，Lamini Memory Tuning 的准确率达到了 95%，而其他方法的准确率仅为 50%。幻觉从 50% 减少到 5%。 Lamini Memory Tuning 是一项研究突破，它克服了 AI 世界中一个看似矛盾的现象：实现精确的事实准确性（即没有幻觉），同时坚持使 LLM 变得有价值的泛化能力。 该方法需要在任何开源 LLM（如 Llama 3 或 Mistral 3）之上使用精确的事实调整数百万个专家适配器（例如 LoRA）。如果目标是准确无误地获取罗马帝国的事实，Lamini Memory Tuning 会创建关于凯撒、渡槽、军团和您提供的任何其他事实的专家。受信息检索的启发，该模型在推理时仅从索引中检索最相关的专家 - 而不是所有模型权重 - 因此延迟和成本显着降低。高精度、高速度、低成本：使用 Lamini Memory Tuning，您无需选择。  研究论文：https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf    提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dffyfs/r_laminiai_introduces_memory_tuning_95_llm/</guid>
      <pubDate>Fri, 14 Jun 2024 02:08:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 的训练范式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dfdlk4/d_openais_training_paradigm/</link>
      <description><![CDATA[有人找到关于 OpenAI 模型开发方法的好文献吗？ 我想知道： - 他们的数据开发流程是什么样的。 - 他们进行什么样的手动/合成标记。 - 他们特定的变压器架构和损失函数。 - 他们如何在训练工作流程中实现 RLHF - 任何相关的 Python 代码都可以启动哈哈    提交人    /u/MGeeeeeezy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dfdlk4/d_openais_training_paradigm/</guid>
      <pubDate>Fri, 14 Jun 2024 00:04:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您觉得 NoPE 怎么样（至少在小型机型上）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dfay95/d_what_do_you_think_of_nope_on_small_models_at/</link>
      <description><![CDATA[      嗨！ 我尝试了 Karpathy 的“让我们重现 GPT-2 (124M)”（和 repo）代码，但使用了 NoPE，只是删除了位置编码。 从我得到的结果来看，它还不错，但我认为它的泛化能力有点夸大了。 我得到了以下数据： https://preview.redd.it/clq8zwl2ve6d1.png?width=1480&amp;format=png&amp;auto=webp&amp;s=c8c846df1ada58c0bed156e24595478087e77b75 https://preview.redd.it/0hvgd273ve6d1.png?width=1498&amp;format=png&amp;auto=webp&amp;s=f111ef399c34f7c01530064cb3b87d71ac2db8a8 它采用相同的硬件、训练和验证集、训练配置等。不幸的是，我无法与学习到 PE 的模型进行比较（这些实验对我来说成本太高了）。 这些数字存在很多问题：  不一样两个图中相同图例的颜色。我无法纠正我的实例已经关闭的情况:( 序列长度的跳跃太大（总是翻倍）。 在训练大约 15xxx 步时发生了一些事情。当我回来时，我发现标准太高（没有记录/绘制），即使在最后一步也是如此，因此很难从中恢复。我不确定稳定阶段的标准，但我猜它下降到了 1 以下。  我缺少最重要的一点，即与学习到的 PE 模型进行公平比较，但我已经使用 ALiBi 和 FIRE 进行了两次实验，这变得太昂贵了。NoPE 在吞吐量方面没有真正的收益（至少在这种情况下），所以我们能观察到的唯一收益可能是有点概括。 你们觉得怎么样？有人对此有更多经验吗？    由    /u/ReinforcedKnowledge  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dfay95/d_what_do_you_think_of_nope_on_small_models_at/</guid>
      <pubDate>Thu, 13 Jun 2024 22:00:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 FIRE（位置编码方法）及其实现的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dfae0z/d_questions_about_fire_the_positional_encoding/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dfae0z/d_questions_about_fire_the_positional_encoding/</guid>
      <pubDate>Thu, 13 Jun 2024 21:34:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 搜索关于 f1 分数加权（多标签）的科学论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1df8k98/r_searching_for_scientific_papers_on_f1score/</link>
      <description><![CDATA[大家好， 我目前正在撰写关于不平衡数据的多标签分类的硕士论文。我迫切地想寻找一本机器学习书籍或科学论文，介绍加权指标，如召回率、f1 分数等，其中平均值 =“加权” - 根据数据集中的类别支持度加权的每个类别的 f1 分数（不是 scikit-learn 文档 😉） 有人知道加权评估指标来自哪里/正式描述吗？ 对于宏观和微观 f1 分数，我已经找到了一些论文，但没有关于加权的论文...... 任何帮助都非常感谢！谢谢    提交人    /u/lenafrauz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1df8k98/r_searching_for_scientific_papers_on_f1score/</guid>
      <pubDate>Thu, 13 Jun 2024 20:16:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 处理大规模特征。例如从 -1e2 到 1e4</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1df4478/d_dealing_with_features_having_large_scale_eg/</link>
      <description><![CDATA[如果特征的范围很大，你会如何处理？一种选择是对数尺度，但如果特征是负值怎么办？ 你们是如何处理深度学习模型中的此类数据的？ 编辑：为了清楚起见，这些特征的范围很广。例如 -1e2 到 +1e4。 此外，如果输入特征和学习特征中存在如此宽的范围，你会如何处理？ 您是否成功地对案例使用了最小最大或标准化？    提交人    /u/rmm_philosopher   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1df4478/d_dealing_with_features_having_large_scale_eg/</guid>
      <pubDate>Thu, 13 Jun 2024 17:08:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] CNN 的图像和非图像数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1df4175/d_image_and_nonimage_data_for_cnns/</link>
      <description><![CDATA[我有一个数据集，其中对于每个样本，我都有一些图像和两个整数值作为输入。您将如何处理这样的输入？ 我正在尝试使用线性层将整数输入投影到图像维度，然后将其添加为另一个图像通道。 你们将如何处理这种输入？    提交人    /u/rmm_philosopher   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1df4175/d_image_and_nonimage_data_for_cnns/</guid>
      <pubDate>Thu, 13 Jun 2024 17:05:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 wandb.ai 的经验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1df3y27/d_experiences_with_wandbai/</link>
      <description><![CDATA[我个人在 ML 研究中经常使用 wandb.ai (权重和偏差)，发现它很棒，但缺少一些功能。 因此，我目前正在构建一个像 wandb 这样的 MLOps 平台，但更适合团队合作。 我对社区的问题是：  你不喜欢 wandb 的哪些方面？ 你希望它有什么功能吗？  我非常感谢任何见解！我想构建一个真正有益且比 wandb 更有价值的东西。请告诉我任何事情，并随时给我发私信！ 我的个人观点：wandb 很棒，但很难作为一个团队一起工作，尤其是在远程工作时。我们发现自己经常使用 slack + notion 来跟踪事情，但情况已经失控了。 此外，没有办法“采取行动”。即您看到一些结果，然后决定要为其制作 jira 票证，但必须手动完成。 对其他人来说，这还不是一个足够大的问题吗？只是好奇    提交人    /u/Sriyakee   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1df3y27/d_experiences_with_wandbai/</guid>
      <pubDate>Thu, 13 Jun 2024 17:01:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用自然语言和概率推理进行实验并修改规则</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dezijo/r_doing_experiments_and_revising_rules_with/</link>
      <description><![CDATA[  由    /u/floppy_llama  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dezijo/r_doing_experiments_and_revising_rules_with/</guid>
      <pubDate>Thu, 13 Jun 2024 13:52:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] OpenMetricLearning 3.0 统一支持图片和文字！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deujz2/p_openmetriclearning_30_which_uniformly_supports/</link>
      <description><![CDATA[      大家好！ 我想分享 OpenMetricLearning 3.0 的发布！  OML — 是一个用于表示学习和检索的库，其中包含大量模型、损失、矿工、采样器、指标和其他有用的东西，如 DDP、与 PyTorchLightning 和 PyTorch Metric Learning 的集成、不同的实验跟踪器等。   有什么新内容？ * 我们已经添加了文本支持，现在我们正在添加音频！（用户不仅已经将 OML 用于图像，而且现在我们还提供开箱即用的支持、测试和示例。） * 代码统一适用于图像、文本，并且适用于声音！我邀请您查看图像和文本的并排比较。 * 检索部分已分离，可用于模型验证和推理，并进行以下重新排名或其他后期处理。 * 库的功能已在一个地方描述，以便于导航，并且我们总体上改进了文档和示例。 * 一些计算，特别是与内存相关的计算，已经进行了优化。 我们欢迎潜在的贡献者： * 代码变得更加模块化，因此入门门槛降低了 - 您可以获取单独的代码并继续进行它。 * 我们还用我们的问题/任务更新了board。 您在GitHub上的⭐️极大地帮助了我们进一步发展！ OML    提交人    /u/Zestyclose-Check-751   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deujz2/p_openmetriclearning_30_which_uniformly_supports/</guid>
      <pubDate>Thu, 13 Jun 2024 09:06:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 微软开源 Recall AI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dergc6/p_opensource_microsoft_recall_ai/</link>
      <description><![CDATA[我创建了一个开源的 Microsoft Recall AI 替代品。 这会记录您屏幕上的所有内容，并可以使用自然语言搜索。但与 Microsoft 的实现不同，这不是隐私噩梦，现在就可以使用。并带有实时加密 这是一个新的启动项目，需要贡献，因此请希望转到 github repo 并给它一个星星 https://github.com/VedankPurohit/LiveRecall 它是完全本地的，您可以查看代码。而且所有内容始终是加密的，这与 Microsoft 的含义不同，当您登录时，图像会被解密并可能被盗    提交人    /u/Vedank_purohit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dergc6/p_opensource_microsoft_recall_ai/</guid>
      <pubDate>Thu, 13 Jun 2024 05:30:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 能否发明更好的方法来培养 LLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deo4pd/r_can_llms_invent_better_ways_to_train_llms/</link>
      <description><![CDATA[新博客文章和论文： https://sakana.ai/llm-squared/ https://arxiv.org/abs/2406.08414 发现用于大型语言模型的偏好优化算法 摘要 离线偏好优化是增强和控制大型语言模型 (LLM) 输出质量的关键方法。通常，偏好优化被视为使用手工制作的凸损失函数的离线监督学习任务。虽然这些方法基于理论见解，但它们本质上受到人类创造力的限制，因此可能的损失函数的大量搜索空间仍未得到探索。我们通过执行 LLM 驱动的目标发现来解决这个问题，以自动发现新的最先进的偏好优化算法，而无需（专家）人工干预。具体而言，我们迭代地提示 LLM 根据先前评估的性能指标提出和实施新的偏好优化损失函数。此过程导致发现以前未知且性能良好的偏好优化算法。其中表现最好的我们称之为发现偏好优化 (DiscoPOP)，这是一种自适应地混合逻辑和指数损失的新算法。实验证明了 DiscoPOP 的最先进的性能及其成功转移到保留任务。    提交人    /u/hardmaru   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deo4pd/r_can_llms_invent_better_ways_to_train_llms/</guid>
      <pubDate>Thu, 13 Jun 2024 02:18:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] Grokking 的问题解决了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1defvmv/d_is_grokking_solved/</link>
      <description><![CDATA[最近的 Grokfast 论文 发现了一种将算法数据集的 Grokking 速度提高 50 倍的方法。早些时候的 Omnigrok 论文 指出，对于他们的算法数据集，“在恒定权重范数下的约束优化在很大程度上消除了 Grokking” 这些改进是否意味着现在我们在训练模型时不必担心延迟泛化/grokking（尽管其机制不明朗）？    提交人    /u/delorean-88   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1defvmv/d_is_grokking_solved/</guid>
      <pubDate>Wed, 12 Jun 2024 19:55:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>