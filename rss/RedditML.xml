<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 20 Jan 2024 15:12:46 GMT</lastBuildDate>
    <item>
      <title>[R] The Manga Whisperer：自动生成漫画转录</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bd8ua/r_the_manga_whisperer_automatically_generating/</link>
      <description><![CDATA[     &lt; td&gt; 论文：http://arxiv.org/abs /2401.10224 Github：https://github.com/ragavsachdeva/magi 自己尝试一下：https://huggingface.co/spaces/ragavsachdeva/the-manga-耳语者/ TLDR：给定高分辨率漫画页面作为输入，Magi（我们的模型）可以（i）检测面板、字符、文本块，（ii）集群字符（无需制作任何(iii) 将文本块与其说话者进行匹配，(iv) 执行 OCR，(v) 生成谁说的和何时说的文字记录（通过按阅读顺序对面板和文本框进行排序） 。请参阅下图的示例。想分享我过去几个月一直在研究的一些东西，我希望其他人觉得它有用:) 我对模型的效果特别满意可以检测和聚类字符（尽管由于遮挡导致视点和部分可见性发生极端变化）。由于模型无法“读取”文本，因此文本与说话者的匹配还有改进的空间。对话（它只是试图在视觉上匹配它们）。我正在努力让它变得更好。 这里有一个预告片： 预测的面板为绿色，文本块为红色，字符为蓝色。预测的字符身份关联由连接字符框中心的线显示。未显示文本到说话者关联，但提供了生成的文字记录。 我很想知道是否有人使用此模型进行很酷的个人或研究项目。一个有趣的用例是使用 Magi 来抓取并自动注释大规模漫画数据集来训练漫画扩散模型。   由   提交 /u/ragavsachdeva   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bd8ua/r_the_manga_whisperer_automatically_generating/</guid>
      <pubDate>Sat, 20 Jan 2024 14:44:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于参加 ICLR 2024 的财务援助的询问</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bbn0j/d_enquiry_regarding_financial_assistance_to/</link>
      <description><![CDATA[我是一名本科生，在主会议上发表了一篇被接受的聚光灯论文，但我们机构没有为本科生提供任何资助。我查了去年的ICLR网站，好像有一个谷歌表格可以申请财政援助，而且是在接近早期注册费截止日期结束时推出的。  我想知道，当我通过今年的表格申请后，经济援助是否能得到保证？还有一般涵盖哪些内容，报销方式是什么？比如，我是否需要用自己的钱提前预订机票/酒店，因为申请签证可能需要这些，而等待经济援助似乎有风险。  显然ICLR也有一些学生志愿服务，如果有报酬的话那就太好了，否则作为本科生自掏腰包去参加会议似乎是一个巨大的经济负担，我不想也错过机会。如果以前的捐助者/了解这方面知识的人能够参与讨论这个话题，那就太好了。    由   提交/u/Master_of_Galaxy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bbn0j/d_enquiry_regarding_financial_assistance_to/</guid>
      <pubDate>Sat, 20 Jan 2024 13:21:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 声音生成人工智能工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bb439/d_sound_generation_ai_tool/</link>
      <description><![CDATA[您能给我推荐一个可以生成声音的 AI 工具吗？就像如果我写下我想要森林或合成贝斯的声音，它就会生成它。谢谢。   由   提交/u/ZennikOfficial  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bb439/d_sound_generation_ai_tool/</guid>
      <pubDate>Sat, 20 Jan 2024 12:52:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 鲜为人知的研究领域 ML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19b7i8s/d_lesser_known_research_areas_ml/</link>
      <description><![CDATA[[D] 您对机器学习中哪些鲜为人知或较少探索的领域感兴趣？ （布罗德，不是高度专业化的想法或主题）我正在寻找一些领域，以便我可以研究和发现它们。   由   提交/u/mango-clay  /u/mango-clay  reddit.com/r/MachineLearning/comments/19b7i8s/d_lesser_known_research_areas_ml/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19b7i8s/d_lesser_known_research_areas_ml/</guid>
      <pubDate>Sat, 20 Jan 2024 08:50:11 GMT</pubDate>
    </item>
    <item>
      <title>[R]深度强化学习中的对抗性攻击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19b7amg/r_adversarial_attacks_in_deep_reinforcement/</link>
      <description><![CDATA[https://twitter.com/EzgiKorkmazAI/status /1748269545364582601   由   提交 /u/ml_dnn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19b7amg/r_adversarial_attacks_in_deep_reinforcement/</guid>
      <pubDate>Sat, 20 Jan 2024 08:35:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 需要帮助！在脑肿瘤分类上实施半监督学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19b66wx/d_p_help_needed_implementing_semisupervised/</link>
      <description><![CDATA[您好，我是机器学习新手，我正在做这个项目，尝试使用半监督学习对不同类型的脑肿瘤进行分类。我尝试运行我的代码，结果看起来确实很奇怪（例如“完美的混淆矩阵”）。 我想知道是否可以从任何专家那里获得帮助。请PM我，我可以将代码和我使用的参考代码发送给您。   由   提交/u/Glittering_Revenue19   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19b66wx/d_p_help_needed_implementing_semisupervised/</guid>
      <pubDate>Sat, 20 Jan 2024 07:21:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于机器学习中梯度下降与局部最大值和最小值的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19b4hqt/d_question_about_gradient_descent_in_machine/</link>
      <description><![CDATA[嗨，我是一名学习机器/深度学习的高中生，我最近在数学中了解到，我们可以通过以下方式找到函数的局部最小值取一阶导数和二阶导数来找到其临界点，然后找到函数的最低值。  为什么我们不能直接求损失函数的最小值，而使用梯度下降呢？这看起来效率更高，因为我们不需要进行一系列小的调整来找到最小值 - 我们可以直接计算它 这行得通吗？这听起来有点愚蠢，因为人们显然会要求这样做   由   提交/u/Mucky5739  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19b4hqt/d_question_about_gradient_descent_in_machine/</guid>
      <pubDate>Sat, 20 Jan 2024 05:35:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有可以检测和清除言语障碍的软件？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19b2o00/d_is_there_any_software_that_can_detect_and_clean/</link>
      <description><![CDATA[我想创建一个 YouTube 频道，但我有与言语相关的障碍，包括口吃、语速过快和软“r”。 是否有任何软件可以检测所有这些并将其清理，以便我可以将其用于配音？ 我尝试查找生成的 AI 语音以使用其中之一，但那让我陷入了控制台命令的海洋、可以说是昂贵的订阅服务和/或有问题的商业许可政策中。   由   提交 /u/Distinct-Temp6557    reddit.com/r/MachineLearning/comments/19b2o00/d_is_there_any_software_that_can_detect_and_clean/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19b2o00/d_is_there_any_software_that_can_detect_and_clean/</guid>
      <pubDate>Sat, 20 Jan 2024 03:52:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 开启训练之旅：基于Ray和vLLM构建70B+模型的开源RLHF全方位训练框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19b01uc/p_d_starting_the_training_journey_an_opensource/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19b01uc/p_d_starting_the_training_journey_an_opensource/</guid>
      <pubDate>Sat, 20 Jan 2024 01:39:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 剩下的一切，说服我错了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19axat7/d_residual_everything_convince_me_wrong/</link>
      <description><![CDATA[直接更改功能不是一个好主意。这会破坏信息，并在恢复时导致与“均值回归”相关的可怕问题。 您可以将每个剩余层想象为一个“工人”。在一个组织内。团队被组织成多个区块，每个团队成员都努力合作，为下一个团队（下一个区块）准备可交付成果。然后，每个团队协同工作以填补他们的角色（添加高频、低频等），并将工作汇总到最后一层。单层（老板）签署所有工作并将其传递给客户端（输出） 如果你仔细想想，每一层只需要输出值“以增强 x” ;，与“合成一个新的x”相反。 我使用“公司”的原因是这里的参考是为了表明原始输入从未被实际破坏（需求，来自另一个团队的交付）。例如，我们不想破坏 SOW 或 TDD 的页面并编写我们自己的信息。网络中的各层需要进行相同的操作，只为特征提供新信息，而不破坏以前的信息。想到可以通过多种方式聚合所有这些信息而不是简单的残差相加，这是令人兴奋的。根据我的经验，乘法残差很有趣，它收敛速度更快，但也占用更多内存。这种方法的整个瓶颈似乎是内存，因为自动编码器通常会对其特征进行下采样并重新采样，而不是保持维度相同或扩展它。很想听听想法。   由   提交 /u/WisePalpitation4831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19axat7/d_residual_everything_convince_me_wrong/</guid>
      <pubDate>Fri, 19 Jan 2024 23:34:27 GMT</pubDate>
    </item>
    <item>
      <title>物理信息机器学习应用[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19av05k/physicsinformed_machine_learning_applications_d/</link>
      <description><![CDATA[大家好， 我渴望了解人们正在使用或想要使用物理信息机器学习的应用程序（ PIML) 为。我正在开发一个用于构建和运行 PIML 的新平台，以帮助人们加速和扩大他们的物理模拟。我一直在与一些公司/大学团体合作研究用于电路设计的 PIML，但我很好奇人们还考虑使用它们做什么以及他们遇到了什么问题。例如，您是否使用 PIML 进行气流建模，甚至构建视频游戏引擎？ 谢谢！   由   提交/u/piml-guy  /u/piml-guy  reddit.com/r/MachineLearning/comments/19av05k/physicalsinformed_machine_learning_applications_d/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19av05k/physicsinformed_machine_learning_applications_d/</guid>
      <pubDate>Fri, 19 Jan 2024 21:58:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自我奖励语言模型 - Meta 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19atnu0/r_selfrewarding_language_models_meta_2024/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2401.10020  Github：https://github.com/lucidrains/self-rewarding -lm-pytorch 摘要：  我们假设，为了实现超人智能体，未来的模型需要超人反馈才能提供足够的训练信号。目前的方法通常根据人类偏好来训练奖励模型，这可能会受到人类表现水平的瓶颈，其次这些单独的冻结奖励模型无法在 LLM 训练期间学习改进。在这项工作中，我们研究自我奖励语言模型，其中语言模型本身通过法学硕士作为法官来使用，提示在训练期间提供自己的奖励。我们表明，在迭代 DPO 培训期间，不仅提高了指令遵循能力，而且还提高了为自身提供高质量奖励的能力。在我们的方法的三个迭代中对 Llama 2 70B 进行微调，产生的模型优于 AlpacaEval 2.0 排行榜上的许多现有系统，包括 Claude 2、Gemini Pro 和 GPT-4 0613。虽然只是初步研究，但这项工作打开了大门模型可以在两个轴上不断改进的可能性。   https:// /preview.redd.it/l7vav40qngdc1.jpg?width=1344&amp;format=pjpg&amp;auto=webp&amp;s=9dce97a69f2ede66d6dabf6abbcfc75bf0e94f19 https://preview.redd.it/fuooe70qngdc1.jpg?width=1180&amp;format=pjpg&amp;auto=webp&amp;s =a88fcf1c765ff42c18091889f5b14cd371248760   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19atnu0/r_selfrewarding_language_models_meta_2024/</guid>
      <pubDate>Fri, 19 Jan 2024 21:01:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习中的不确定性来源——统计学家的观点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19aml6l/r_sources_of_uncertainty_in_machine_learning_a/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2305.16703 摘要：  机器学习和深度学习今天已经达到了令人印象深刻的标准，使得我们可以回答几年前难以想象的问题。除了这些成功之外，很明显，除了纯粹的预测（大多数监督机器学习算法的主要优势）之外，不确定性的量化也是相关且必要的。虽然近年来出现了这个方向的第一个概念和想法，但本文采用概念视角并研究了不确定性的可能来源。通过采用统计学家的观点，我们讨论了任意和认知不确定性的概念，这些概念更常见于机器学习。本文旨在将两种类型的不确定性形式化，并证明不确定性的来源是多种多样的，并且并不总是可以分解为任意的和认知的。我们将机器学习中的统计概念与不确定性进行比较，还展示了数据的作用及其对不确定性的影响。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19aml6l/r_sources_of_uncertainty_in_machine_learning_a/</guid>
      <pubDate>Fri, 19 Jan 2024 16:09:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] AISTATS 2024论文接收结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19al3e9/d_aistats_2024_paper_acceptance_result/</link>
      <description><![CDATA[AISTATS 2024 论文接受结果将于今天发布。正在为今年的结果创建讨论主题。   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19al3e9/d_aistats_2024_paper_acceptance_result/</guid>
      <pubDate>Fri, 19 Jan 2024 15:03:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>