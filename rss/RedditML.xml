<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 08 Oct 2024 03:24:26 GMT</lastBuildDate>
    <item>
      <title>[P] GPT-2 电路 - 映射简单 LLM 的内部工作原理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fymczh/p_gpt2_circuits_mapping_the_inner_workings_of/</link>
      <description><![CDATA[我构建了一个应用程序，它使用 GPT-2 架构从模型中提取可解释的“电路”。虽然一些教程提供了 LLM 中的层如何产生预测的假设示例，但此应用程序提供了流经系统的信息的具体示例。例如，您可以看到搜索简单语法模式并将其构造追溯到更原始特征的使用的特征的形成。如果您正在研究可解释性，请查看！我很乐意听取您的反馈，并希望与可以提供帮助的人建立联系。项目链接：https://peterlai.github.io/gpt-mri/    提交人    /u/ptarlye   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fymczh/p_gpt2_circuits_mapping_the_inner_workings_of/</guid>
      <pubDate>Mon, 07 Oct 2024 23:51:05 GMT</pubDate>
    </item>
    <item>
      <title>不平衡的多标签图像分类问题 - 需要建议！[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fylca7/imbalanced_multi_label_image_classification/</link>
      <description><![CDATA[您好！希望这是正确的子版块！ 我目前正在研究多标签图像分类问题，使用 ResNet152 作为我的 CNN 模型的主干架构，该模型使用 Keras 和 TensorFlow 开发。在训练模型时，我获得了较高的二元准确率分数，但精度、召回率和 F1 分数较低，验证集上的结果甚至更差：这表明模型在训练数据上过度拟合。我的数据集在标签之间非常不平衡。我以为我可以使用自定义损失函数来解决这个问题，在这种情况下，我尝试使用加权二元交叉熵损失函数，输入每个标签的权重。我还探索了对数据的过度和欠采样，但这被证明是一个挑战，因为我找不到任何可以原生处理多标签数据集的东西。我确实尝试过修改 SMOTE，但这没有奏效。下面是我的数据示例。解决模型性能不佳/数据不平衡的最佳方法是什么？谢谢！！！   image_path label_1 label_2 label_3 label_4 label_5    .../image1.jpg 1 0 0 1 0   .../image2.jpg 0 0 1 0 0   .../image3.jpg 0 0 1 1 0   .../image4.jpg 0 1 1 0 0   .../image5.jpg 0 0 1 0 0      提交人    /u/Odd-Eagle-6716   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fylca7/imbalanced_multi_label_image_classification/</guid>
      <pubDate>Mon, 07 Oct 2024 23:03:17 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 图像的倒谱分析相当于什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fyjqlz/dr_what_is_the_equivalent_of_cepstral_alanysis/</link>
      <description><![CDATA[图像的倒谱分析的类似物是什么？ 我正在攻克一个图像分类问题，并尝试使用一种“创新方法”和储层计算 (RC)，这种方法应该可以大大节省计算时间和数据大小要求，至少对于动态信号和预测而言是如此，但对于图像或分类而言却不一定如此。我见过一个使用 RC 进行语音信号分类的例子，其中信号呈现在倒谱域中（对我来说也是新的），这似乎有助于网络完成工作。我尝试将倒谱的定义应用于我的图像，但看起来根本没有帮助（我没有看到任何可能使机器的工作更轻松的特征改进，也许我应该试一试）。我的问题是：是否有已知或标准的方法可以改进/促进从图像中提取或识别特征，就像倒谱对语音的作用一样？这些图像是从宇宙演化模型中观测到的星系。试图检测“合并”。     提交人    /u/HugoLDSC   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fyjqlz/dr_what_is_the_equivalent_of_cepstral_alanysis/</guid>
      <pubDate>Mon, 07 Oct 2024 21:51:29 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 样本打包如何影响LLM训练中的模型学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fyjbnz/discussion_how_does_sample_packing_affect_model/</link>
      <description><![CDATA[大家好， 我一直在大型语言模型 (LLM) 训练期间尝试样本打包，通过减少填充来提高内存和计算效率。我将其应用于最大序列长度为 16 的数据集，只是为了看看它是如何工作的。 在大多数打包样本中（我使用了 HuggingFace 的 SFTTrainer 和 trl 包），我看到的序列如下： &#39;&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n划分北方和北方的经线&#39; 如您所见，此示例从一个响应的末尾开始，并立即过渡到新响应的开始。我理解注意掩码可防止打包样本之间的交叉污染，因此模型不应混淆不同的序列。 但我担心的是： 在训练期间，我们希望教会模型根据前几个标记的完整上下文预测下一个标记。感觉从上下文中间开始样本（尤其是在特殊标记（如&lt;|im_start|&gt;）之后）可能会降低学习效果。这是否会限制模型完全学习如何处理完整序列、特殊标记甚至整个对话流程的能力？ 我是否遗漏了模型如何处理这些转换？我认为打包样本在数学上与使用分离样本和填充进行训练相同，唯一的区别是每个批次中处理的标记数量。 感谢您的见解！    提交人    /u/JeanMichelRanu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fyjbnz/discussion_how_does_sample_packing_affect_model/</guid>
      <pubDate>Mon, 07 Oct 2024 21:34:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 适合 Nvidia A100 40G 的系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fyj5sw/d_a_suitable_system_for_nvidia_a100_40g/</link>
      <description><![CDATA[我从 2019 年开始从事机器学习领域，我当前的 4090 设置已无法满足我日益增长的需求。以下是我关注的重点：  微调大型语言模型 (LLM) 训练隐马尔可夫模型 (HMM) 训练长短期记忆网络 (LSTM)  处理包括文本、图像、视频和音频在内的各种数据类型 我对机架服务器或工作站了解不多，我也希望在不久的将来添加更多卡（H100 或 A100），我的机架服务器或工作站预算约为 3000-4000 美元（显然除了卡之外） PS。评估了几乎所有的显卡，A100 在大多数方面都是赢家，所以它成为了一个明确的选择。亚军是 L40S。也欢迎对显卡偏好的建议。    提交人    /u/Dapper_Ad79   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fyj5sw/d_a_suitable_system_for_nvidia_a100_40g/</guid>
      <pubDate>Mon, 07 Oct 2024 21:27:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 嵌入作为数据结构 2.0？学习特定任务的最佳数据表示（幻灯片）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fybtdh/d_embeddings_as_data_structures_20_learning/</link>
      <description><![CDATA[我最近就嵌入作为数据结构 2.0 发表了演讲，并认为这可能会引起人们的兴趣。幻灯片 -&gt; https://docs.google.com/presentation/d/1GAiYOYTfzx-fyaHRNXYHCkA-y2wx1hnQwNiue0vj1tE/edit?usp=sharing 2017 年，Andrej 创造了“软件 2.0”一词 - 即从数据中学习而来的软件，而不是通过编程规则手动制作的软件。这种范式转变使得能够开发出比以前更强大的软件。  数据结构 2.0 与嵌入有很多相似之处，使用嵌入表示数据代表了类似的转变。 “数据结构 2.0”是数据嵌入的学习表示。您无需手动制定存储数据的规则，而是可以通过嵌入学习表示数据的最佳任务特定方法。 “数据结构 2.0 是用对人类不友好的语言编写的，例如嵌入的浮点值。没有人参与编写此代码……直接用浮点值编码有点乏味，但可行（我试过了）。&quot; 让我知道你的想法！    提交人    /u/Jesse_marqo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fybtdh/d_embeddings_as_data_structures_20_learning/</guid>
      <pubDate>Mon, 07 Oct 2024 16:25:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] Model2Vec：从任意句子转换器中提取一个小型快速模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fyb9jj/p_model2vec_distill_a_small_fast_model_from_any/</link>
      <description><![CDATA[嗨 👋！ 我想分享一个我们过去几个月一直在研究的项目，名为 Model2Vec，我们最近开源了这个项目。这是一种提炼 Sentence Transformer 模型并创建非常小的静态嵌入模型（磁盘上 30mb）的技术，这些模型的速度比原始模型快 500 倍，使其在 CPU 上非常容易使用。提炼在 CPU 上大约需要 30 秒。 这些嵌入在 MTEB 上的表现远胜于类似方法（如 GloVE 和 BPEmb），同时创建速度更快，并且不需要数据集。它被设计为（大型）语言模型的环保替代方案，特别适用于时间受限（例如搜索引擎）或无法使用高级硬件的情况。 这个想法非常简单，但效果却出奇地好： 1：获取任何句子转换器的标记输出嵌入。 2：使用 PCA 降低维数。这不仅减小了模型大小，而且还规范了输出空间。 3：根据单词/标记频率对嵌入应用 zipf 权重。这实质上降低了常用词的权重，这意味着您不需要删除停用词。 我们创建了几个易于使用的方法，可以在使用 pip install model2vec 安装包后使用： 推理： from model2vec import StaticModel # 从 HuggingFace 中心加载模型（在本例中为 M2V_base_output 模型）model_name = &quot;minishlab/M2V_base_output&quot; model = StaticModel.from_pretrained(model_name) # 制作嵌入 embeddings = model.encode([&quot;独自一人去很危险！&quot;, &quot;这对每个人来说都是个秘密。&quot;])  提炼： from model2vec.distill import extract # 选择一个句子转换器模型 model_name = &quot;BAAI/bge-base-en-v1.5&quot; # 提炼模型 m2v_model = deliver(model_name=model_name, pca_dims=256) # 保存模型 m2v_model.save_pretrained(&quot;m2v_model&quot;)  我很想听听您对此的想法，并很乐意回答任何问题！ 链接：  Repo 链接 结果链接     提交人    /u/Pringled101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fyb9jj/p_model2vec_distill_a_small_fast_model_from_any/</guid>
      <pubDate>Mon, 07 Oct 2024 16:02:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 法学硕士 (LLM) 混合专家 (MoE) 的视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fya2ks/p_a_visual_guide_to_mixture_of_experts_moe_in_llms/</link>
      <description><![CDATA[大家好！我很高兴向大家介绍法学硕士 (LLM) 中的混合专家 (MoE) 的高度说明性指南！ 从探索专家的作用、他们的路由机制、稀疏 MoE 层和负载平衡技巧（例如 KeepTopK、辅助损失和专家容量），到视觉模型中的 MoE 和计算要求。  https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts 我喜欢创建视觉效果，在创建了 55 多个自定义视觉效果后，我不得不停下来！ 本指南的视觉特性允许专注于直觉，希望使所有这些技术易于广大受众使用，无论您是 Mixture of Experts 的新手还是更有经验。    提交人    /u/MaartenGr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fya2ks/p_a_visual_guide_to_mixture_of_experts_moe_in_llms/</guid>
      <pubDate>Mon, 07 Oct 2024 15:13:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 根据任务复杂性灵活部署计算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fy54kn/d_flexible_compute_deployment_based_on_task/</link>
      <description><![CDATA[大家好，ML 的朋友们。我是一名认知科学专业的学生，​​研究神经科学和机器学习的交叉领域。大脑最酷的事情之一可能就是它能够完成的任务是多么的高效——依靠灯泡运行。据我所知，这可能是因为如果任务不需要所有参数，则不会使用它们。到目前为止，我发现的唯一与此类似的 ML 方法是专家混合法。除此之外，在深度学习中，优化推理过程似乎被忽视了——通常只是使用所有参数，而不管自上而下的上下文或输入统计数据。 我几乎可以肯定我错了，所以我希望你们能给我指出一些深入研究这个问题的好论文？或者也许是问题的正式名称？例如，你可以攻读法学硕士学位。如果对句子中下一个单词的预测很简单（例如食草动物吃 [植物]），我可能不需要所有参数就能得到完美的预测（Claude 和 LLama 可能会做得同样好，但 Claude 解决这个问题的成本更高），而不是更技术性、需要更多注意力和背景投入处理的预测（例如，解决数学证明）。    提交人    /u/Karioth1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fy54kn/d_flexible_compute_deployment_based_on_task/</guid>
      <pubDate>Mon, 07 Oct 2024 11:16:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言建模任务上的 Mamba 和 SSM 是一个很好的研究轨迹吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxzor7/r_is_mamba_and_ssms_on_language_modelling_task_a/</link>
      <description><![CDATA[我刚刚接触到 Mamba 和 SSM，因为我的教授说我应该尝试探索它。我是一名硕士生，刚刚开始我的研究之旅，我原本想像我系里的其他学生一样研究 transformers LM。有人说这会让我陷入别人以前没有做过的事情，会使我的学习/研究变得比预想的更难（最终可能会得到平庸的结果）。你们对此有什么看法吗？谢谢。    提交人    /u/worthlesspineapple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxzor7/r_is_mamba_and_ssms_on_language_modelling_task_a/</guid>
      <pubDate>Mon, 07 Oct 2024 04:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于工具使用和 LLM 代理有哪些有趣的论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxvsp7/d_what_are_some_interesting_papers_about_tooluse/</link>
      <description><![CDATA[目前，我正在研究 voyager (https://arxiv.org/abs/2305.16291)，但希望得到更多建议。TIA。    提交人    /u/a1_jakesauce_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxvsp7/d_what_are_some_interesting_papers_about_tooluse/</guid>
      <pubDate>Mon, 07 Oct 2024 01:04:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML 论文的敏感性分析获得了更好的结果，现在怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxu3zw/d_sensitivity_analysis_of_the_ml_paper_got_better/</link>
      <description><![CDATA[我使用一种新方法针对特定数据集撰写了一篇 ML 论文，取得了一些积极成果。我训练了几个模型，对它们进行了评估，并根据研究结果进行了广泛的解释和讨论。其中一位审稿人要求对一些预处理参数/算法进行敏感性分析。有趣的是，其中一项更改导致的结果比我原来的方法略好。 我的问题是：在这种情况下的期望是什么？我需要重写整篇论文，还是应该仅在敏感性分析中报告这一观察结果？虽然更改改善了结果，但想到要根据新的运行重写大部分解释（例如，特征重要性、图表、讨论等），还是很令人沮丧。你的想法和经验是什么？    提交人    /u/anagreement   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxu3zw/d_sensitivity_analysis_of_the_ml_paper_got_better/</guid>
      <pubDate>Sun, 06 Oct 2024 23:37:02 GMT</pubDate>
    </item>
    <item>
      <title>上下文感知词语替换 [P] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxsuhg/context_aware_word_replacement_p_r/</link>
      <description><![CDATA[你好！ 我从事 CV 研究，所以对 NLP 不是很精通，所以需要输入。 我正在研究在保留图片上下文的情况下替换“句子”中的“单词”，以便我们更容易在数据集中搜索该单词的合适图像。例如： 句子 - “学生应该抵制网络欺凌，以免攻击者伤害他们” 单词 - “攻击者” 为什么预期 - 网络犯罪分子、网络欺凌者等，以便我可以搜索相关图像。 BeRT 和其他模型用什么来替换它 - 恐怖分子、计算机、敌对攻击者等。 我想在本地运行一些东西，但找不到任何解决方案。有什么想法或输入我应该尝试吗？有任何资源或代码笔记本吗？    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxsuhg/context_aware_word_replacement_p_r/</guid>
      <pubDate>Sun, 06 Oct 2024 22:34:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</guid>
      <pubDate>Sun, 06 Oct 2024 15:00:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>