<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 18 Jan 2024 01:00:52 GMT</lastBuildDate>
    <item>
      <title>[D] 哪些专有数据集（不能作为开源提供）会被广泛认为是有价值且流行的，可以集成到 ML/AI 应用程序中？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/199crza/d_what_proprietary_datasets_not_available_as_open/</link>
      <description><![CDATA[使用 HF 构建了相当多的项目，在构建模型/实际计算应用程序时，我始终欣赏开源数据。这让我开始思考，如果人们能够访问什么类型的专有数据（可以来自本地企业、中型企业、组织等...）会受欢迎？   由   提交/u/nobilis_rex_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/199crza/d_what_proprietary_datasets_not_available_as_open/</guid>
      <pubDate>Thu, 18 Jan 2024 00:36:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] Ramen AI - 使用 LLM AI 作为 API 或 Google Sheets 公式对文本进行分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/199cr6b/p_ramen_ai_classify_text_using_llm_ai_as_api_or/</link>
      <description><![CDATA[   我构建了这个免费工具，供人们对文本进行分类，无需任何开箱即用的模型训练。寻找让这个工具更有用的想法！欢迎您尝试一下。只需先加入候补名单，我很快就会批准您。 https://tryramen.com ​ https: //preview.redd.it/faybnrwng3dc1.jpg?width=2244&amp;format=pjpg&amp;auto=webp&amp;s=1d0165fd339cd0df70a831086be7c5da0069c4ca    ;由   提交/u/HauntingBeach  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/199cr6b/p_ramen_ai_classify_text_using_llm_ai_as_api_or/</guid>
      <pubDate>Thu, 18 Jan 2024 00:35:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多智能体强化学习：综合调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1999kd5/r_multiagent_reinforcement_learning_a/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.10256 摘要：  多代理应用程序的流行遍及我们的各种互连系统日常生活。尽管它们无处不在，但在共享环境中集成和开发智能决策代理对其有效实施提出了挑战。这项调查深入研究了多智能体系统 (MAS) 领域，特别强调阐明 MAS 框架内学习最优控制的复杂性，通常称为多智能体强化学习 (MARL)。本次调查的目的是提供对 MAS 各个方面的全面见解，揭示无数机会，同时强调多代理应用程序所面临的固有挑战。我们希望不仅有助于更深入地了解 MAS 景观，而且还为研究人员和从业者提供有价值的观点。通过这样做，我们的目标是在 MAS 的动态领域内促进知情探索并促进发展，认识到在解决 MARL 中出现的复杂性方面需要适应性策略和持续发展。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1999kd5/r_multiagent_reinforcement_learning_a/</guid>
      <pubDate>Wed, 17 Jan 2024 22:19:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型自回归图像模型的可扩展预训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1999ipe/r_scalable_pretraining_of_large_autoregressive/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.08541 代码和模型：https ://github.com/apple/ml-aim 模型： https://huggingface.co/apple/AIM 摘要：  本文介绍了AIM，一组经过自回归目标预训练的视觉模型。这些模型受到其文本对应模型（即大型语言模型（LLM））的启发，并表现出类似的缩放特性。具体来说，我们强调两个关键发现：（1）视觉特征的性能与模型容量和数据量相关，（2）目标函数的值与模型在下游任务上的性能相关。我们通过在 20 亿张图像上预训练 70 亿个参数的 AIM 来说明这些发现的实际意义，在具有冻结主干的 ImageNet-1k 上达到 84.0%。有趣的是，即使在这个规模上，我们也没有观察到性能饱和的迹象，这表明 AIM 可能代表着训练大规模视觉模型的新领域。 AIM 的预训练与 LLM 的预训练类似，不需要任何特定于图像的策略来稳定大规模训练。  &lt;!-- SC_ON - -&gt;  由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1999ipe/r_scalable_pretraining_of_large_autoregressive/</guid>
      <pubDate>Wed, 17 Jan 2024 22:17:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么推测解码的输出分布保证保持不变？推测样本[研究]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1998wr2/why_speculative_decodings_output_distribution_is/</link>
      <description><![CDATA[      ​ https://preview.redd.it/fk76iuoan2dc1.png?width=357&amp;format=png&amp; auto=webp&amp;s=7b909330a6ccf70258e620c2cc1cfdfa11ee4c40 https://preview.redd.it/n78eend9n2dc1.png?width=353&amp;format=png&amp;auto=webp&amp;s=316b4b74fed8360b5d83845a20f757d9331d13 1b q(x) 是草稿model p(x) 是原始的，目标模型 我不明白为什么在推测解码算法之后输出分布与目标模型分布相同，例如：&lt; /p&gt;  如果 q(xi) &lt;= p(xi) 不会改变目标模型的输出分布，为什么保留 xi？ 为什么我们需要再次从范数（ max(0,p(x) -q(x) ) 如果 x 被拒绝  为什么标准化 p(x) 没有改变目标模型的分布？   非常感谢任何关于为什么推测采样后分布不会改变的提示和解释   由   提交 /u/xiaofanlu   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1998wr2/why_speculative_decodings_output_distribution_is/</guid>
      <pubDate>Wed, 17 Jan 2024 21:53:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一次性微调所有超参数还是将它们分类？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1996gzj/d_finetune_all_hyperparameters_in_onego_or_divide/</link>
      <description><![CDATA[您好， 我正在微调我的超参数。我一直想知道文献中是否有任何关于微调超参数集合的方法的策略。 我不是在谈论微调算法本身，即网格搜索、随机搜索等.我说的是逐一微调较小的集合 ​ 类别示例： 数据预处理：标记化方法，等 训练参数：学习率、批量大小、优化器、动量等 模型架构：层数、神经元、激活函数、batchnorm、dropout 参数等 内部的其他算法：数据增强、扩散参数等 ​ 我想说，我总共有大约 20 个可以触及的超参数。是一起微调所有内容更好，还是逐一微调超参数类别更好？ 我有一种感觉，某些“类别”可能会被忽略。将对性能产生如此大的影响/变化，以至于可能会给其他参数添加太多噪音 ​ 很想知道社区如何处理这部分管道   由   提交/u/Reference-Guilty  /u/Reference-Guilty  reddit.com/r/MachineLearning/comments/1996gzj/d_finetune_all_hyperparameters_in_onego_or_divide/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1996gzj/d_finetune_all_hyperparameters_in_onego_or_divide/</guid>
      <pubDate>Wed, 17 Jan 2024 20:15:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] DPO 论文潜在推导问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1994mio/d_dpo_paper_potential_derivation_issue/</link>
      <description><![CDATA[        由   提交/u/Puzzleheaded_Stay_62   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1994mio/d_dpo_paper_potential_derivation_issue/</guid>
      <pubDate>Wed, 17 Jan 2024 19:02:31 GMT</pubDate>
    </item>
    <item>
      <title>AlphaGeometry：奥林匹克级几何AI系统[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1993okp/alphageometry_an_olympiadlevel_ai_system_for/</link>
      <description><![CDATA[https://www .nature.com/articles/s41586-023-06747-5 介绍 AlphaGeometry：一个能够以接近人类金牌得主水平解决奥林匹克几何问题的人工智能系统。 📐 它仅基于合成数据进行训练，标志着人工智能在数学推理方面的突破   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1993okp/alphageometry_an_olympiadlevel_ai_system_for/</guid>
      <pubDate>Wed, 17 Jan 2024 18:25:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlphaGeometry：奥林匹克级几何人工智能系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19932kw/r_alphageometry_an_olympiadlevel_ai_system_for/</link>
      <description><![CDATA[博客：https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/ 论文：https://www.nature.com/articles/s41586-023-06747-5 Github：https://github.com/google-deepmind/alphageometry 摘要：  在奥林匹克级别证明数学定理代表着人类水平自动推理的一个显着里程碑，因为它们在世界上最优秀的大学预科数学人才中被认为是困难的。然而，由于将人类证明转换为机器可验证格式的成本高昂，当前的机器学习方法不适用于大多数数学领域。对于几何来说，这个问题更为严重，因为其独特的转换挑战，导致训练数据严重匮乏。我们提出了 AlphaGeometry，这是欧几里得平面几何的定理证明器，它通过综合不同复杂程度的数百万个定理和证明来回避人类演示的需要。 AlphaGeometry 是一个神经符号系统，它使用神经语言模型，在我们的大规模合成数据上从头开始训练，引导符号推演引擎通过具有挑战性的问题的无限分支点。在包含 30 个最新奥林匹克级别问题的测试集上，AlphaGeometry 解决了 25 个问题，超越了之前仅解决了 10 个问题的最佳方法，接近了国际数学奥林匹克 (IMO) 金牌得主的平均表现。值得注意的是，AlphaGeometry 产生了人类可读的证明，在人类专家评估下解决了 IMO 2000 和 2015 中的所有几何问题，并在 2004 年发现了翻译后的 IMO 定理的广义版本。 &lt;!-- SC_ON - -&gt;  由   提交 /u/RobbinDeBank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19932kw/r_alphageometry_an_olympiadlevel_ai_system_for/</guid>
      <pubDate>Wed, 17 Jan 2024 18:01:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] einx - Python 中受爱因斯坦启发的表示法中的张量运算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198yyzy/p_einx_tensor_operations_in_einsteininspired/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198yyzy/p_einx_tensor_operations_in_einsteininspired/</guid>
      <pubDate>Wed, 17 Jan 2024 15:20:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 信心*可能是*您所需要的一切。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198y67i/d_confidence_may_be_all_you_need/</link>
      <description><![CDATA[      ​ 论文：https://arxiv.org/abs/2303.08896 ​ 我很想知道这里是否有人在实践中尝试过这个。 LLM 输出标记的对数概率的简单平均值可能足以判断模型是否产生幻觉。这个想法是，如果模型不自信（输出令牌概率低），则该模型可能会发明随机的东西。作者声称这种简单的方法是检测幻觉的最佳启发式方法。美妙之处在于它只使用生成的令牌概率，因此可以在推理时实现。   由   提交 /u/santiviquez   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198y67i/d_confidence_may_be_all_you_need/</guid>
      <pubDate>Wed, 17 Jan 2024 14:46:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 词汇量真的会影响法学硕士文本的大小吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198xx6o/d_does_the_vocabulary_size_really_affect_the_size/</link>
      <description><![CDATA[与变压器的其他组件相比，嵌入矩阵是否足够大？ 如果不是，那么为什么 GPT 模型依赖于30K 词汇量？   由   提交/u/kekkimo  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198xx6o/d_does_the_vocabulary_size_really_affect_the_size/</guid>
      <pubDate>Wed, 17 Jan 2024 14:34:22 GMT</pubDate>
    </item>
    <item>
      <title>[P]从头开始的小型潜伏扩散变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198eiv1/p_small_latent_diffusion_transformer_from_scratch/</link>
      <description><![CDATA[      我训练了一个相对简单的基于 Transformer 的扩散模型来生成 256 x 256 图像从头开始。这是仓库： https://github.com/apapiu/transformer_latent_diffusion/tree/main - 代码应该希望它相当容易理解并且独立。 以下是在 1A100 从头开始​​训练大约 30 小时后的一些示例： 根据各种提示生成图像 该模型基于 DiT /Pixart-alpha 架构，但进行了各种修改和简化。我还在噪声表方面做出了一些有问题的决定，但似乎工作正常。 该模型是 100MM 参数，因此应该很容易对其进行实验。我欢迎任何反馈，也欢迎合作，所以请联系我们！希望这对想要尝试扩散模型/变压器但“GPU 较差”的人们有所帮助。 :) 该存储库还链接到一个 colab，您可以在其中使用自己的输入 - 请随意尝试。 ​    由   提交 /u/spring_m   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198eiv1/p_small_latent_diffusion_transformer_from_scratch/</guid>
      <pubDate>Tue, 16 Jan 2024 21:29:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何处理雇主提出的不合理要求以及对机器学习不切实际的期望？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19882l2/d_how_do_you_deal_with_unreasonable_request_from/</link>
      <description><![CDATA[几个月前，我接受了一个职位，通过为社会科学研究项目训练机器学习模型来支持该项目。该项目涉及使用团队（由多名实习生、研究生、博士后和教授组成）花费数年时间并付出疯狂努力编制的数据集。然而，问题是他们没有事先咨询任何真正了解机器学习的人。对于非常复杂的任务来说，他们的数据集太小（只有大约 200 行）。更糟糕的是，大多数变量的预测价值微乎其微，而用于推导这些变量的方法虽然非常耗费人力，却引发了人们对其有效性的担忧。 该项目的 MO 绝对令人困惑：通过巨大的数据积累了数千个预测变量。努力和人力，期待完美的结果。任何模型如何用如此小的数据集估计如此多的参数却被忽视了。项目负责人似乎对 ML 有着某种神奇的理解，这可能是受到其在特定领域频繁误用的影响。这个项目的灵感尤其来自于一篇研究论文，我几乎可以保证该论文在其验证集上过拟合。 所有这些都让我处于尴尬的境地，作为新人，我需要告知这一点一个由经验丰富的博士后和教授组成的团队，全部来自社会科学背景，没有定量专业知识，他们多年的工作产生了一个完全不适合他们的目标的数据集，并且他们所建立的现有文献都是错误的，因为他们显然没有不知道什么是测试集以及何时使用它。我也不能告诉他们只扩展数据集，因为达到 200 行已经花费了数年时间。 我必须承认我对这次谈话有点紧张。 ​ 我怀疑对 ML 功能抱有不切实际的期望是一种常见的经历。其他人如何处理这个问题？如果他们坚持不管，你会直白地告诉他们这行不通，然后到别处找工作吗？如果是这样，这些交互通常如何进行？   由   提交 /u/Excusemyvanity   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19882l2/d_how_do_you_deal_with_unreasonable_request_from/</guid>
      <pubDate>Tue, 16 Jan 2024 17:13:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>