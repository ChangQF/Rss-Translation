<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Thu, 08 Aug 2024 21:14:14 GMT</lastBuildDate>
    <item>
      <title>[D] OpenAI：API 中的结构化输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1endf5w/d_openai_structured_outputs_in_the_api/</link>
      <description><![CDATA[https://openai.com/index/introducing-structured-outputs-in-the-api/ 只是好奇，为什么这是一件大事？你看到任何用例了吗？    提交人    /u/dmpetrov   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1endf5w/d_openai_structured_outputs_in_the_api/</guid>
      <pubDate>Thu, 08 Aug 2024 18:27:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] DistilBERT 基础多语言（大小写）葡萄牙语</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en74uf/d_distilbert_base_multilingual_cased_for/</link>
      <description><![CDATA[有人用过 DistilBERT 基础多语言（大小写）来处理葡萄牙语吗？如果是，你的结果如何？它好用吗？ 提前致谢。    提交人    /u/mr_house7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en74uf/d_distilbert_base_multilingual_cased_for/</guid>
      <pubDate>Thu, 08 Aug 2024 14:16:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] FlexAttention：PyTorch 的灵活性与 FlashAttention 的性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</link>
      <description><![CDATA[https://pytorch.org/blog/flexattention/    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</guid>
      <pubDate>Thu, 08 Aug 2024 13:49:55 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 我需要什么数学背景才能阅读 Le Cam 的《充分性和近似充分性》论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en55pb/research_what_mathematical_background_do_i_need/</link>
      <description><![CDATA[嗨， 我是一名统计学家，出于研究目的，我想阅读 Le Cam 提到的论文。我遇到的困难是它使用了诸如向量格、正正则化线性函数、格对偶等术语。 因此，我的问题是：我需要什么样的数学先决条件才能阅读此类论文？ 我做过标准线性代数、实分析（单变量和多变量）、测度论、概率论内容、一些点集拓扑，但从未见过这样的对象，所以我认为这可能与抽象代数有关，但我不知道从哪里开始才能读懂这篇文章。 任何帮助都将不胜感激。谢谢！   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en55pb/research_what_mathematical_background_do_i_need/</guid>
      <pubDate>Thu, 08 Aug 2024 12:52:00 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何使用学习率来匹配论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emxx6a/d_how_to_use_learning_rate_to_match_papers/</link>
      <description><![CDATA[你好！ 我正在复现一些论文，但我一直面临训练不稳定的问题，除非我降低论文中的学习率，因为在几篇论文中我发现我可能是错的。 假设我们有一篇论文，使用 M GPU 以批量大小 N（每个 GPU）训练网络，以学习率为 LR 进行训练。训练几乎总是使用 float16 和 adam/adamw。我正在使用 pytorch amp 进行混合精度训练。 大多数论文要求我正在训练（TTS 任务）在 16/32 gpu 上进行训练，但我不想进行分布式训练，我只使用更快的 GPU 进行 2 倍、4 倍或 8 倍训练，但使用梯度累积（G）。 不同的框架对如何在多 GPU 环境中指定学习率的定义不同。 我现在正在使用 Accelerate，它建议将学习率乘以使用的 GPU 数量，但不清楚如何处理梯度累积以及论文最初如何定义学习率。 我的选择是：  LR - 按原样使用 LR * M - 乘以论文中原始 GPU 的数量 LR * M / G - 乘以不使用梯度累积的实际 GPU 数量 LR * G - 乘以按梯度累积次数  现在我已经尝试了#3，但是梯度爆炸，我除以二，它通常是稳定的，但它与任何其他公式都不匹配。 另外，不清楚论文中使用了什么框架（论文主要来自 Meta 和 Microsoft），这可能会影响 LR 不匹配。    提交人    /u/stevekite   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emxx6a/d_how_to_use_learning_rate_to_match_papers/</guid>
      <pubDate>Thu, 08 Aug 2024 05:27:50 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 多模式人工智能聊天机器人令人费解的失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emi095/research_the_puzzling_failure_of_multimodal_ai/</link>
      <description><![CDATA[      https://preview.redd.it/ummnvenf1ahd1.png?width=2592&amp;format=png&amp;auto=webp&amp;s=7115ba5de026ada17b0636ec2fa3c3151b3e5eb6 GPT-4o 和 Gemini 等聊天机器人模型在理解图像和文本方面表现出了令人印象深刻的能力。然而，它们是否能模仿人类的一般智力和推理能力尚不清楚。为此，PuzzleVQA 是多模式拼图的新基准，用于探索当前模型的极限。如上所示，即使是 GPT-4V 这样的模型也很难理解儿童可以掌握的简单抽象模式。 https://preview.redd.it/7l5fmuys1ahd1.png?width=2716&amp;format=png&amp;auto=webp&amp;s=337118dbc55230637cec1b08b90ae943746ddbb0 尽管谜题看似简单，但我们观察到当前多模态 AI 模型的表现却出奇地差。值得注意的是，与人类的表现仍然存在巨大差距。因此，自然而然地出现了一个问题：是什么导致了模型的失败？为了回答这个问题，我们进行了瓶颈分析，逐步为模型提供真实“提示”，例如用于感知或推理解释的图像标题。如上所示，我们发现领先的模型在视觉感知和归纳推理方面面临关键挑战。这意味着他们无法准确地感知图像中的物体，并且在识别正确的模式方面也很差。 https://arxiv.org/abs/2403.13315    提交人    /u/chiayewken   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emi095/research_the_puzzling_failure_of_multimodal_ai/</guid>
      <pubDate>Wed, 07 Aug 2024 17:33:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有一个适合进行通用智能开发技术讨论的社区？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emhuwa/d_is_there_an_appropriate_community_for_technical/</link>
      <description><![CDATA[确认该帖子没有讨论 AGI，版主可以删除它。我知道与 AGI 相关的帖子应该直接发送到 r/singularity，但 reddit 似乎主要充斥着炒作和哲学化新闻文章的非技术性帖子。我认为在 ML 领域有很多关于技术方法、问题和研究的有效讨论，以创建通用智能，例如脉冲网络、进化算法、记忆增强网络、RL 等。出于技术原因，我认为仅仅扩展当前方法 (LLM) 并不能让我们实现这一目标，而且我们还差得很远，但我不想在这篇文章中讨论这个问题。相反，是否有针对专注于 AGI 技术工作、研究和实践讨论的社区或其他团体的建议？    提交人    /u/Revolutionary-Fig660   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emhuwa/d_is_there_an_appropriate_community_for_technical/</guid>
      <pubDate>Wed, 07 Aug 2024 17:27:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 加入项目委员会有什么好处？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emh4i8/d_what_are_the_benefits_of_being_on_a_program/</link>
      <description><![CDATA[我很好奇，在 ML 会议上，加入程序委员会意味着什么，以及为什么人们会选择加入程序委员会。 作为 ML 会议的审稿人，我认为深入阅读几篇论文是有好处的。加入程序委员会有什么好处？我的理解是，这份工作主要是 ping 审稿人、总结评论和其他管理任务。    提交人    /u/smorad   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emh4i8/d_what_are_the_benefits_of_being_on_a_program/</guid>
      <pubDate>Wed, 07 Aug 2024 16:59:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 AAAI 投稿评论的公开访问权的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emengc/d_question_about_public_access_to_reviews_for/</link>
      <description><![CDATA[我正在准备向 AAAI 提交论文，今年 AAAI 使用 OpenReview。有人知道在审查过程结束后，所有评论（包括被拒绝的论文的评论）是否会公开吗？我在 AAAI 网站上找不到此信息。谢谢！    提交人    /u/RudeFollowing2534   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emengc/d_question_about_public_access_to_reviews_for/</guid>
      <pubDate>Wed, 07 Aug 2024 15:24:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 训练嵌入模型以忽略主题不必要的维度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emcrem/p_training_an_embedding_model_to_ignore/</link>
      <description><![CDATA[嗨， 我正在为固定的一组特定主题的文档构建知识管理工具。主要目标是使这些文档在嵌入空间中“可探索”并智能地聚类。但是，我注意到大多数嵌入都非常接近，我认为这是因为它们都围绕同一主题。 我的想法是微调模型以淡化嵌入空间的其余部分，从而增强同一主题内的差异并使其更具可比性。我最初尝试使用 PCA 来实现这一点，但结果并不好。我正在探索的另一个想法是在嵌入上使用小型自动编码器，或者可能为此目的微调开源嵌入模型。但是，我不确定如何开始。 有人有这方面的经验吗？如果是，您使用了哪些方法、模型、框架或来源，结果如何？ 此外，我正在寻找在此基础上对数据集进行良好的视觉探索。虽然美学是次要的，但我对任何有效绘图方法的建议都很感兴趣。    提交人    /u/zeronyk   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emcrem/p_training_an_embedding_model_to_ignore/</guid>
      <pubDate>Wed, 07 Aug 2024 14:09:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] Neurips 2024 的反驳现在可供审稿人查看吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emc004/d_are_neurips_2024_rebuttal_viewable_to_reviewers/</link>
      <description><![CDATA[这应该在几个小时前就发生了，但我审阅的论文仍然只显示原始评论，没有反驳。发生了什么事？    提交人    /u/fixed-point-learning   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emc004/d_are_neurips_2024_rebuttal_viewable_to_reviewers/</guid>
      <pubDate>Wed, 07 Aug 2024 13:37:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何追踪你所有的实验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emakgn/d_how_do_you_keep_track_of_all_your_experiments/</link>
      <description><![CDATA[大家好， 在我的公司，我们正在进行大量 LLM 实验。 我们目前正在进行“小规模”实验来做各种事情（选择各种超参数、进行一些小的架构更改、使用什么数据集等...） 我们正在使用 WandB，记录实验非常酷，但我不知道在协作方面有什么功能可以更进一步。例如，我们希望有一些东西可以从我们启动的各种实验/图中得出结论，理想情况下将图和结论存储在一个地方。 这样，我们就可以轻松地跟踪所有内容，特别是当我们几个月后回顾实验时，我们能够理解我们启动它的原因以及得出的结论是什么。 你是如何做到的？您是否使用特定工具？    提交人    /u/Theboredhuman_56   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emakgn/d_how_do_you_keep_track_of_all_your_experiments/</guid>
      <pubDate>Wed, 07 Aug 2024 12:32:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大型科技公司与生物科技公司的 AI/ML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1em3ke2/d_aiml_in_big_tech_vs_biotech/</link>
      <description><![CDATA[我很好奇为什么一个优秀的 ML 工程师会离开大型科技公司（如谷歌、微软或 OpenAI）并加入生物科技公司。与科技公司正在发生的所有前沿创新相比，生物科技的吸引力何在？    提交人    /u/Pleasant_Wish1799   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1em3ke2/d_aiml_in_big_tech_vs_biotech/</guid>
      <pubDate>Wed, 07 Aug 2024 05:13:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>