<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 28 Dec 2023 00:58:12 GMT</lastBuildDate>
    <item>
      <title>[D] 工作站/服务器供应商</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sgi39/d_workstationserver_vendors/</link>
      <description><![CDATA[在又一次灾难性的安装之后，我正在寻找可以提供多 GPU 服务器/工作站的其他供应商。我现在已经完成了两次安装，戴尔将硬件扔给我并说“祝你好运”。他们几乎懒得接受我的订单。简单的事情，例如硬盘驱动器格式化、出现问题时安装支持、驱动程序安装等（我只能从戴尔订购） 并不是说我自己无法做这些事情，我在我们的 IT 现场也是如此。 ​ 通常我会 DIY，但由于我的工作是为一所大型大学工作，所以我非常自以为是从“批准的供应商”购买完整的硬件。 我正在寻找：  能够提供多 GPU (2-4) 系统和支持的公司硬件。 为 Linux 提供支持的公司（戴尔不支持他们提供的操作系统*呃*） 可以为非 Linux 用户提供支持的公司（是的，我知道这一点）是机器学习，但我必须与我的 IT 人员合作，而他们不需要！） 对成本敏感的公司（也就是说，我知道组件的成本是多少，看到这些加价我会很伤心）。  由于法规的原因，云是 100% 禁止的。 ​ 老实说，任何高于戴尔体验的东西都将是一个问题。改进。 ​ 如果这是一头神兽，那就这样吧——我有点脱节，因为我一直在做 Cloud 和 nVidia DGX    由   提交/u/crazy596  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sgi39/d_workstationserver_vendors/</guid>
      <pubDate>Thu, 28 Dec 2023 00:50:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] torch.odeint（ODE求解器）执行速度慢的解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sed9l/d_solution_to_slow_execution_speed_of_torchodeint/</link>
      <description><![CDATA[当我在神经常微分方程上运行 torch 优化时，我发现 torch.odeint （此处存储库：rtqichen/torchdiffeq：具有完全 GPU 支持和 O(1) 内存反向传播的可微分 ODE 求解器。(github.com)）非常慢。它会占用单个 CPU 核心 100% 的资源，使其余核心和大部分 GPU 闲置。事实上，似乎并没有太多并行性。 并行 ODE 求解器确实存在，但它们并不是很出名。有人知道任何可以帮助提高 torch.odeint 性能的建议吗？ ​   由   提交 /u/speedy-spade   /u/speedy-spade  reddit.com/r/MachineLearning/comments/18sed9l/d_solution_to_slow_execution_speed_of_torchodeint/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sed9l/d_solution_to_slow_execution_speed_of_torchodeint/</guid>
      <pubDate>Wed, 27 Dec 2023 23:19:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 未经训练的卷积神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s9l3j/d_untrained_convolutional_neural_networks/</link>
      <description><![CDATA[根据标题，我正在探索一个利基主题：使用未经训练的卷积神经网络 (CNN) 作为特征提取器。现有的研究已经证明，即使没有训练，CNN 仍然可以从数据中捕获一些有意义的特征。 因此，我对任何专注于提高未经训练的 CNN 特征提取能力的方法的论文或研究感兴趣，或者探索替代（无需训练）的方法。 目前，我能够找到研究未经训练的 CNN 效率的论文  [1] [2] 或使用它们作为特征提取器的[3] [4] 具体任务和架构。然而，这些论文中没有一篇试图深入研究无需传统的基于梯度的优化即可增强提取特征的方法。 有关此主题的任何共享资源或指导将不胜感激。预先感谢您！   由   提交 /u/RussB3ar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s9l3j/d_untrained_convolutional_neural_networks/</guid>
      <pubDate>Wed, 27 Dec 2023 19:58:07 GMT</pubDate>
    </item>
    <item>
      <title>Apple MLX 与 CoreML [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s46pr/apple_mlx_vs_coreml_d/</link>
      <description><![CDATA[嗨！我是计算机科学专业的大四学生。我刚刚开始使用 Apple 环境进行机器学习开发，但我不确定 MLX 和 CoreML 之间的区别。   由   提交/u/Snoo-67080  /u/Snoo-67080 reddit.com/r/MachineLearning/comments/18s46pr/apple_mlx_vs_coreml_d/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s46pr/apple_mlx_vs_coreml_d/</guid>
      <pubDate>Wed, 27 Dec 2023 16:10:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在保留数据字符的同时对数值数据应用数据缩减？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s33gl/d_how_to_apply_data_reduction_to_numeric_data/</link>
      <description><![CDATA[[D] 当我们想要将数据缩减应用于基于类的数​​据集同时保留数据特征时，我们会尝试保持类比率。当我们想要在处理数值数据时应用数据缩减时，我们该怎么办？   由   提交/u/SomeRestaurant8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s33gl/d_how_to_apply_data_reduction_to_numeric_data/</guid>
      <pubDate>Wed, 27 Dec 2023 15:22:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从镜头创建张量流训练数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s0wo2/p_creating_training_data_for_tensorflow_from/</link>
      <description><![CDATA[嗨，我需要将轮盘球与任何轮盘赌轮一致地识别（考虑各种颜色和照明环境）。 I我想我会使用 opencv 为每个录制添加注释，但我必须在每个视频开始时手动定义初始框，这会花费太长时间。我对此也很陌生，有什么建议吗？我可以通过其他方式训练模型吗？   由   提交/u/No_Rough_1116   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s0wo2/p_creating_training_data_for_tensorflow_from/</guid>
      <pubDate>Wed, 27 Dec 2023 13:38:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有研究在 RL 期间使用 LoRA 和 QLoRA 等参数高效训练来进行预训练模型？我无法找到这方面的文献。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s0dz2/d_has_there_been_any_research_into_using/</link>
      <description><![CDATA[我想在一些大型模型上运行强化学习，并且希望避免购买无数的 GPU。而且这似乎可能是一个有趣的研究领域。有人知道是否有任何论文或文章详细介绍了使用 LoRA 等技术进行强化学习？ 编辑：为了澄清起见，我指的是一般的强化学习，而不是 RLHF。   由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s0dz2/d_has_there_been_any_research_into_using/</guid>
      <pubDate>Wed, 27 Dec 2023 13:11:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我从头开始制作了一个教育自动毕业</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s0adx/p_i_made_an_educational_autograd_from_scratch/</link>
      <description><![CDATA[学习机器学习，我一直对 PyTorch 及其 Autograd 引擎感兴趣。  在这个项目中，我尝试重新实现 PyTorch 的大部分&lt; /strong&gt;（包括 Autograd）以记录完善、单元测试且可解释的方式从头开始。它对我来说非常有用，我希望它也能帮助您更好地了解 Autograd！  希望您喜欢！  GitHub 存储库此处！   由   提交 /u/suspicious_beam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s0adx/p_i_made_an_educational_autograd_from_scratch/</guid>
      <pubDate>Wed, 27 Dec 2023 13:06:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 MoE 模型仅针对前馈层？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rzygz/d_why_moe_models_target_only_feedforward_layers/</link>
      <description><![CDATA[所以我看到 Mixtral 8x7b 只有 45B 参数，而不是 56B (src https://huggingface.co/blog/mixtral），因为 MoE 仅适用于前馈层，不适用于注意力层。为什么会这样呢？我相信肯定有研究将MoE应用于注意力层，但为什么没有使用呢？是不是没有提高性能什么的，MoE 在注意力层上有什么帮助的任务吗？   由   提交/u/vincent163  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rzygz/d_why_moe_models_target_only_feedforward_layers/</guid>
      <pubDate>Wed, 27 Dec 2023 12:48:16 GMT</pubDate>
    </item>
    <item>
      <title>[R]“将隐私保护机制转向联邦学习”（CCS23）（机器学习安全）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rz528/r_turning_privacypreserving_mechanisms_against/</link>
      <description><![CDATA[CCS 论文链接：https:// dl.acm.org/doi/10.1145/3576915.3623114 预印本链接：https:// arxiv.org/abs/2305.05355 链接 GitHub：https://github.com/DCALab-UNIPV/Turning-Privacy-preserving-Mechanisms-against-Federated-Learning 摘要： 最近，研究人员已经成功地利用图神经网络（GNN）来构建增强的推荐系统，因为它们能够从相关实体之间的交互中学习模式。此外，之前的研究已经将联邦学习作为主要解决方案，以启用本地隐私保护机制来构建全局 GNN 模型，而无需将敏感数据收集到单个计算单元中。尽管如此，由于对联合客户端生成的本地模型更新的分析可以返回与敏感本地数据相关的信息，因此可能会出现隐私问题。因此，研究人员提出了将联邦学习与差异隐私策略和社区驱动方法相结合的解决方案，其中涉及结合来自邻居客户端的数据，以使各个本地更新减少对本地敏感数据的依赖。 在此在论文中，我们发现了这种配置中的一个关键安全缺陷，并设计了一种能够欺骗联邦学习最先进防御措施的攻击。所提出的攻击包括两种操作模式，第一种专注于收敛抑制（对抗模式），第二种旨在在全局联邦模型上构建欺骗性评级注入（后门模式）。实验结果显示了我们的攻击在两种模式下的有效性，在对抗模式的所有测试中平均返回 60% 的性能损失，而在后门模式的测试中，93% 的情况下后门完全有效。 &lt; /div&gt;  由   提交 /u/ArmandolandoReal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rz528/r_turning_privacypreserving_mechanisms_against/</guid>
      <pubDate>Wed, 27 Dec 2023 12:00:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有谁知道尝试寻找特征之间特定关系的 ML 项目吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ry97g/r_does_anyone_know_of_ml_projects_that_attempt_to/</link>
      <description><![CDATA[我正在特别考虑 这个一个。常见的情况是输入数据是行星、恒星或类似的足够大且具有引力的天体。因此使用它们的质量和坐标作为输入以获得关系 F=GM1M2/(r^2)。您是否知道任何其他类型的项目使用机器学习来识别此类关系？ 机器学习能够在多大程度上隔离和识别数据输入特征之间的此类关系？   由   提交 /u/emaxwell13131313   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ry97g/r_does_anyone_know_of_ml_projects_that_attempt_to/</guid>
      <pubDate>Wed, 27 Dec 2023 11:02:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 想要学习面向 ML 的分布式系统的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rnnuv/d_want_recommendations_for_learning_mloriented/</link>
      <description><![CDATA[涵盖 ZeRO、多 GPU 训练、并行机制、教授 CUDA / triton / openMP 等相关内容的资源。   由   提交 /u/PunsbyMann   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rnnuv/d_want_recommendations_for_learning_mloriented/</guid>
      <pubDate>Wed, 27 Dec 2023 01:05:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 加入学术界研究实验室，同时在工业界全职担任研究工程师。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rixog/d_joining_academia_research_lab_while_working/</link>
      <description><![CDATA[您好，我是一名刚毕业的本科生，目前是一家 ML 初创公司（多模式法学硕士）的研究工程师。我想加入大学的研究实验室并从事研究项目。我个人之前曾与 PI 合作过，他们的实验室与我的创业研究并没有太大关系。  我想听听是否有人有类似的在行业全职工作的同时加入实验室的经历以及我应该注意的事情。我会免费加入并使用自己的设备进行实验室工作。  这是因为，当我在初创公司进行有意义的研究时，我想让自己有更多的事情做，成为一个更有能力的潜在机器学习博士申请者。  谢谢！   由   提交/u/Few_Ad1273  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rixog/d_joining_academia_research_lab_while_working/</guid>
      <pubDate>Tue, 26 Dec 2023 21:36:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们通常使用哪种 Transformer 实现？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r8yhf/d_which_transformer_implementation_do_people/</link>
      <description><![CDATA[每个标题，我想知道人们通常使用的 Transformer 是否有特定的实现？我不关心预先训练的模型。我想要一个最小/干净的实现，我可以用它来修改 Transformer 架构本身，以实现我的一些想法。我注意到 PyTorch 有自己的内置 Transformer，但不确定它们是否有任何好处，而且它们看起来可能有点过度设计以满足我的需求。我还注意到 Andrej Karpathy 有他的 nanoGPT 项目，该项目可能符合要求（仅解码器的自回归实现就可以满足我的要求。）   由   提交/u/SuperFX  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r8yhf/d_which_transformer_implementation_do_people/</guid>
      <pubDate>Tue, 26 Dec 2023 14:12:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>