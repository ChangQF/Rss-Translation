<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Mon, 15 Apr 2024 03:20:01 GMT</lastBuildDate>
    <item>
      <title>开发人员指南：模块化、灵活、可扩展的产品就绪 RAG [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4c0vh/developers_guide_modular_flexible_scalable_prod/</link>
      <description><![CDATA[      Cognita 实践：模块化、开放用于产品的源 RAG 应用程序，在构建时考虑了可扩展性。  完整文章  ​ https://preview.redd.it/pjaq4qsg8kuc1.png?width=998&amp;format=png&amp;auto=webp&amp;s=9378e8e60876be78aabb476b7c79ff7af0cce1da 这份综合指南提供了帮助使用 Cognita 构建和部署检索增强生成 (RAG) 系统的方法，Cognita 是一个模块化开源框架，其设计时考虑到了可扩展性。本文将引导您完成设置 Cognita、吸收知识库以及利用其核心功能开发可投入生产的 RAG 应用程序的过程。  🔹 无缝设置：分步说明将指导您克隆 Cognita 存储库、创建虚拟环境、安装依赖项以及配置必要的文件。  🔹 知识库摄取：了解如何摄取和处理知识库，包括分块文档、生成嵌入以及索引到矢量数据库。  🔹 模块化架构：Cognita 通过将数据摄取过程与查询服务解耦来促进关注点分离，从而实现独立扩展和高效更新。  🔹 可扩展部署：探索 Cognita 如何通过与云基础设施集成来促进可扩展部署，从而允许根据资源需求独立扩展组件。  🔹 生产就绪：发现将 RAG 系统从开发环境过渡到生产时 Cognita 解决的关键挑战，例如分块和嵌入大型数据集、构建可扩展的查询服务、部署语言模型和嵌入模型作为单独的服务，并建立强大的矢量数据库。  🔹 实践示例：按照一个实际示例演示如何获取信用卡知识库、配置 RAG 系统以及使用 cURL 请求测试问答功能。  无论您是经验丰富的开发人员还是 RAG 系统的新手，本文都会为您提供使用 Cognita 框架构建模块化、灵活且可扩展的生产就绪型 RAG 应用程序的知识和工具。    由   提交 /u/AssistanceOk2217   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4c0vh/developers_guide_modular_flexible_scalable_prod/</guid>
      <pubDate>Mon, 15 Apr 2024 03:11:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 文本分类/NER/RE等传统NLP任务在法学硕士时代仍然重要吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4a7sa/d_are_traditional_nlp_tasks_such_as_text/</link>
      <description><![CDATA[大型语言模型 (LLM) 是全面的 NLP 任务求解器。他们可以用最早的程序语言英语来完成很多 NLP 任务，而不是需要复杂过程的基于判别式的模型。 作为一名博士生，我最近对未来有点焦虑。我的顾问支持一个关于知识提取和知识图的资助项目。但我认为未来一定是LLM。我目前的计划是在完成手头的NER和RE项目后，做一些RAG的工作。 你们对传统NLP任务（文本分类、NER、RE等）有什么想法吗？法学硕士时代？   由   提交 /u/edzq   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4a7sa/d_are_traditional_nlp_tasks_such_as_text/</guid>
      <pubDate>Mon, 15 Apr 2024 01:38:50 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Runpod GPU 上的 Tensorflow。浮点异常 梯度计算导致的错误。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c49g4p/project_tensorflow_on_runpod_gpu_floating_point/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c49g4p/project_tensorflow_on_runpod_gpu_floating_point/</guid>
      <pubDate>Mon, 15 Apr 2024 01:00:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] NER+POS 能否通过将客户想要的产品与正式名称进行映射来帮助指定客户想要的产品？如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c49apq/d_can_nerpos_help_in_specifying_a_customers/</link>
      <description><![CDATA[大家好，我正在开发一个项目，我们每天都会收到数百名用户想要知道价格的产品列表 所以基本上我在这里尝试自动化的是采用所有这些不同的俚语、市场名称、产品名称的语法，并使用 ML 将它们映射到正式列表名称 所以为了简短起见我试图理解客户说“X”是什么意思并将其映射到正式名称“Y”列表中的同一产品 那么定制的NER可以帮助完成这项任务吗？标记包含“产品名称”的用户条目“品牌” “尺寸” “颜色”作为训练数据集，然后将其映射到也具有相同标签的正式名称？或者在这种情况下它如何工作？我试图在这个任务中理解 1 - 用于训练的数据集的形状是什么 2 - 我如何使用 NER 来完成这个项目 3 - 数据或用户条目同时包含阿拉伯语和英语，或者纯粹是阿拉伯语，这会在将来造成任何问题吗？ 如果您有与该域相似或不同的 NER 项目的经验听到这个消息我会非常高兴:) 谢谢！   由   提交 /u/Ill_Persimmon388   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c49apq/d_can_nerpos_help_in_specifying_a_customers/</guid>
      <pubDate>Mon, 15 Apr 2024 00:53:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 反向传播 GPU 云</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c460zb/p_backprop_gpu_cloud/</link>
      <description><![CDATA[大家好！三年来，我一直在公共市场上托管一小批 GPU 服务器。几个月前，我开始构建自己的 GPU 云，因为我相信这样用户可以在支持、可靠性和功能方面获得更好的服务。现在它已经为第一批用户做好了准备：https://backprop.co 那么为什么还要另一个 GPU 云呢？嗯，首先，高质量且价格合理的云 GPU 提供商的能力不断不足。 另一个原因是我对 GPU 市场的抱怨。很难知道您租用的服务器是在适当的数据中心还是在某人炎热潮湿的地下室中。这会导致可靠性和性能问题，从而降低整个平台的质量（从而降低价格）。这会激励构建廉价的、不可靠的服务器以节省成本。 此外，当前的 GPU 市场都专注于托管 Docker 容器而不是虚拟机。这对于大多数用例来说都很好，但这是一个基本限制。我看到很多用户抱怨由于驱动程序/内核版本不匹配而无法运行其映像。我还可以探讨更多原因。 Backprop 的目标就是解决这些问题。我们托管在三级数据中心。所有实例都是具有根访问权限和完全专用 IPv4 地址的虚拟机。我们的价格合理（希望您同意），并且不收取额外的存储/带宽费用。 我们目前只有 RTX 3090 服务器，但我们希望尽快扩大容量。  &gt;请查看 https://backprop.co 并分享您的想法！ PS！我们希望建立一个高质量的市场，因此如果您知道符合这些标准的主机，请与我们联系！   由   提交 /u/ojasaar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c460zb/p_backprop_gpu_cloud/</guid>
      <pubDate>Sun, 14 Apr 2024 22:21:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 思维可视化在大型语言模型中引发空间推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4017q/r_visualizationofthought_elicits_spatial/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.03622 摘要：  大型语言模型（LLM）在语言理解方面表现出了令人印象深刻的表现以及各种推理任务。然而，它们的空间推理能力（人类认知的一个重要方面）仍然相对未被开发。人类拥有一种非凡的能力，可以通过称为“心灵之眼”的过程创造看不见的物体和行为的心理图像，从而实现对看不见的世界的想象。受这种认知能力的启发，我们提出了思维可视化（VoT）提示。 VoT旨在通过可视化法学硕士的推理轨迹来引发法学硕士的空间推理，从而指导后续的推理步骤。我们将 VoT 用于多跳空间推理任务，包括自然语言导航、视觉导航和 2D 网格世界中的视觉平铺。实验结果表明，VoT 显着增强了法学硕士的空间推理能力。值得注意的是，VoT 在这些任务中的表现优于现有的多模式大语言模型 (MLLM)。虽然 VoT 在 LLM 上的效果出奇的好，但生成心理图像以促进空间推理的能力类似于心灵的眼睛过程，这表明它在 MLLM 中的潜在可行性。     由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4017q/r_visualizationofthought_elicits_spatial/</guid>
      <pubDate>Sun, 14 Apr 2024 18:14:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] CNN加速器RTL设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3zw9f/p_cnn_accelerator_rtl_design/</link>
      <description><![CDATA[我为大学开发了这个基本通用的 CNN 和全连接层加速器项目，我想与您分享。它像 Coral TPU 一样使用 int8 量化数据和权重。该项目包含一个脚本，可将 TensorFlow 模型转换为加速器所需的指令。此外，还有一个 MNIST 分类器的示例。更多信息请参阅自述文件。 https://github.com/bautistasch/CNN-FC-accelerator&lt; /a&gt;   由   提交 /u/instrumentosdetexas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3zw9f/p_cnn_accelerator_rtl_design/</guid>
      <pubDate>Sun, 14 Apr 2024 18:08:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言模型物理学：第 3.3 部分，知识能力缩放定律</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3zefx/r_physics_of_language_models_part_33_knowledge/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.05405 摘要：  缩放定律描述了语言模型的大小与其模型之间的关系。能力。与之前通过损失或基准评估模型能力的研究不同，我们估计模型存储的知识位数。我们专注于以元组表示的事实知识，例如维基百科页面中的（美国、首都、华盛顿特区）。通过多个受控数据集，我们确定语言模型每个参数只能存储 2 位知识，即使量化为 int8 也是如此，并且可以灵活地提取这些知识以供下游应用程序使用。因此，7B 模型可以存储 14B 位知识，超过了我们估计的英语维基百科和教科书的总和。更广泛地说，我们提出了 12 个结果，涉及 (1) 训练持续时间、(2) 模型架构、( 3）量化，（4）稀疏性约束，例如MoE，以及（5）数据信噪比影响模型的知识存储容量。值得注意的见解包括： * 采用旋转嵌入的 GPT-2 架构在知识存储方面匹配甚至超越了 LLaMA/Mistral 架构，特别是在较短的训练持续时间内。出现这种情况是因为 LLaMA/Mistral 使用 GatedMLP，它不太稳定且难以训练。 * 在训练数据前添加域名（例如，此 http URL ）显着提高了模型的知识容量。语言模型可以自主识别知识丰富的领域并对其进行优先级排序，从而优化其存储容量。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3zefx/r_physics_of_language_models_part_33_knowledge/</guid>
      <pubDate>Sun, 14 Apr 2024 17:47:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于发现“假”机器学习角色的建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3z8ug/d_advice_for_spotting_fake_ml_roles/</link>
      <description><![CDATA[我最近被聘用，结果证明这是一个假的 ML 角色，即使按照 ML 角色最宽松的定义（彭博 AI 小组）也是如此。目前似乎有许多公司/团队/人员假装从事机器学习工作，而在招聘时，他们对候选人实际所做的工作撒谎。有没有人有任何策略来发现此类角色，从而避免它们？面试时提问似乎不太有效，因为你很容易被骗。   由   提交 /u/Outrageous-Base3215    reddit.com/r/MachineLearning/comments/1c3z8ug/d_advice_for_spotting_fake_ml_roles/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3z8ug/d_advice_for_spotting_fake_ml_roles/</guid>
      <pubDate>Sun, 14 Apr 2024 17:41:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当前的学术研究趋势与当前的学术研究趋势未来5年</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3xgdw/d_current_academic_research_trends_vs_next_5_years/</link>
      <description><![CDATA[大家好！  正如标题所示，我想征求您的意见（特别是对于那些活跃于机器学习领域的研究人员），您认为哪些当前热门话题将在未来 5 年内保持相关性，以及您认为哪些话题会继续相关。被视为注定会失去研究兴趣的临时趋势。 例如，两个明显的研究领域是法学硕士（以及一般而言基于变压器的模型）和生成图像模型（例如基于扩散的架构） 。  就我个人而言，我认为物理信息网络（通常用于求解描述物理系统的非线性偏微分方程，和/或不同工程领域的建模过程）将变得越来越重要。对我来说，他们最终将提供一个框架，允许各种行业整合机器学习模型来优化其制造和设计流程。 根据我的个人经验，许多考虑攻读机器学习博士学位的学生对主题有些犹豫选择，因为担心陷入不再相关的话题。考虑到人工智能研究的现状，这种担心真的有道理吗？    由   提交/u/fliiiiiiip   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3xgdw/d_current_academic_research_trends_vs_next_5_years/</guid>
      <pubDate>Sun, 14 Apr 2024 16:24:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]特征向量和嵌入有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3thlk/d_what_is_the_difference_between_feature_vectors/</link>
      <description><![CDATA[我正在使用语音（即语音身份验证）进行用户身份验证项目。我正在研究给定音频/语音的不同方面，我可以利用这些方面来识别特定的人，最常用的东西之一是 MFCC 特征，这些特征是使用任何标准音频处理库（如 Librosa）提取的。 现在，最近我们有了嵌入，它可以基本捕获矢量形式的信息，可以是音频、视频、文本或图像。所以我一路上有一些疑问，  对于音频，嵌入意味着什么？它们与 MFCC 功能有什么不同吗？ 我可以直接使用音频嵌入来进行说话者识别/验证吗？就像我正在考虑的方法一样为每个用户提供一个带有嵌入的数据库，然后进行测试，看看我们在数据库中是否有匹配的测试音频。  我遇到的音频嵌入模型之一是&lt; a href=&quot;https://arxiv.org/abs/2006.11477&quot;&gt;Wav2Vec 2.0 by Meta。 PS：我是 ML 领域的新手，仍在学习中，请原谅我我在这里犯了任何错误。   由   提交 /u/Puzzleheaded_Bee5489   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3thlk/d_what_is_the_difference_between_feature_vectors/</guid>
      <pubDate>Sun, 14 Apr 2024 13:23:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] CUDA 编程是行业内紧缺的技能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3q0mq/d_is_cuda_programming_an_indemand_skill_in_the/</link>
      <description><![CDATA[大家好，我目前在医疗保健/计算机视觉领域担任人工智能工程师。目前我所做的工作是重复性的、单调的。主要涉及数据准备和模型训练。希望拓展业务并学习一些其他行业相关技能。我正在考虑学习 CUDA 编程，而不是走学习模型部署的老路。 CUDA 编程是否为其他角色打开了大门？它增加了什么样的价值？ 非常欢迎任何进一步的建议/建议   由   提交 /u/Hour_Amphibian9738   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3q0mq/d_is_cuda_programming_an_indemand_skill_in_the/</guid>
      <pubDate>Sun, 14 Apr 2024 09:59:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 离散扩散的极其简短且简单的实现，在 pytorch 中，开源（400 loc）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3pvx5/p_extremely_short_and_simple_implementation_of/</link>
      <description><![CDATA[      https://github.com/cloneofsimo/d3pm  https://i.redd.it/tjsaqoum2fuc1.gif 嗨，我付出了相当多的努力在 pytorch 中从头开始重新实现 d3pm（离散扩散）。离散扩散的 pytorch 实现并不多，希望这有帮助！   由   提交 /u/cloneofsimo   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3pvx5/p_extremely_short_and_simple_implementation_of/</guid>
      <pubDate>Sun, 14 Apr 2024 09:49:52 GMT</pubDate>
    </item>
    <item>
      <title>Cognita：真正统一的 RAG 框架：第 1 部分 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3k2av/cognita_a_truly_unified_rag_framework_part_1_d/</link>
      <description><![CDATA[      无缝解析、精准检索、智能生成&amp;轻松部署，开始吧...  全文 ​ 信用：https://github.com/truefoundry/cognita  既然有这么多，为什么要关心呢？ 🤔 RAG （检索增强生成）系统功能强大，但构建和部署它们可能很棘手。 🚀 Cognita 旨在成为一个用户友好的模块化解决方案，以解决常见的 RAG 挑战。  寻找真正的生产级完整 RAG 框架  当前框架的问题： ⚙️ 分块和分块嵌入作业通常需要单独设置，但目前还没有内置在作者已知的当前框架中。 💻 为生产部署查询服务可能很复杂 🤖 处理模型部署（语言模型、嵌入模型）缺乏内置支持。 🗄 矢量数据库的可扩展性部署可能很棘手。 🧩 没有单一的、即用型模板可以轻松采用 ⚠️ 免责声明：这些问题可能已由其他框架解决，但作者在撰写本文时还不知道。  Cognita 如何解决这些问题 🎯 Cognita 在定制与易用性之间取得平衡。 🧠 可扩展设计，可在突破发生时进行整合。  Cognita — 用于构建用于生产的模块化开源 RAG 应用程序的库 🧱 模块化设计：将 RAG 分解为多个步骤，以便于管理和更新。 ♻️ 可重用组件：解析器、加载器等，以节省跨项目的时间。 🚀 简化部署：Cognita 处理生产系统的细节。 ⚖️ 可扩展性：组件独立扩展以处理增加的流量。 ✨ 用户- 友好的界面：即使是非技术用户也可以使用 RAG 设置。 🔌 API 驱动：Cognita 与其他系统配合良好。  Cognita 组件 索引作业 1. 数据加载器🚚 内容：从各个位置（文件夹、数据库等）获取数据。 为什么：RAG 需要数据来工作！ 2. 解析器🗂️ 目的：将不同的文件类型转换为通用格式。 原因：让 RAG 系统更容易处理所有内容。  3. 嵌入器 🔎 目的：创建类似代码的文本表示形式以进行快速比较 原因：帮助找到与您的问题最相关的信息。  元数据存储🧠 是什么：系统的“大脑”，存储配置详细信息 原因：让您的 RAG 井然有序且易于管理。  LLM Gateway 💬 是什么：不同语言模型的“翻译器”。 原因：让您可以在模型之间切换，而无需重新编码所有内容。  Vector DB 🗄️ 用途：存储嵌入以实现超快速数据搜索。 原因：高效搜索是大型数据集的关键。  API 服务器 ⚙️ 作用：处理用户问题并生成答案的协调器。 原因：它将 RAG 系统的所有部分连接在一起。  对第 2 部分感到兴奋：使用 Cognita 进行编码！ 💻🚀  ​   由   提交 /u/AssistanceOk2217   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3k2av/cognita_a_truly_unified_rag_framework_part_1_d/</guid>
      <pubDate>Sun, 14 Apr 2024 03:35:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>