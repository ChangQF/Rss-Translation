<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 14 Feb 2024 03:14:55 GMT</lastBuildDate>
    <item>
      <title>[d] 在 RAG 中使用知识图的指针</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqcdq8/d_pointer_on_using_knowledge_graphs_in_rag/</link>
      <description><![CDATA[我很想了解有关在检索和生成 (RAG) 系统中使用知识图的更多信息。 RAG 涉及检索外部知识以帮助生成响应，因此知识图谱似乎非常有用。 我有一些具体问题：  什么类型的知识图谱有效最适合 RAG 应用？与大型通用图表相比，特定领域的图表往往更有用吗？ 有哪些有效的技术可以从图表中查询和检索相关知识以生成响应？有没有最佳实践？ 随着新信息的出现而更新知识图的可行性如何？图是否需要是静态的，或者 RAG 系统可以处理频繁的图更新吗？ 知识图可以帮助完成生成响应时消除实体和概念歧义等任务吗？ 有什么好的方法吗？是否存在可以使用 RAG 模型进行预训练的开源知识图？或者展示如何很好地使用图表的系统示例？  如果您能提供有关将知识图集成到 RAG 工作流程的任何见解，我将不胜感激。请随时向我指出任何论文、示例或其他材料。期待了解有关该领域的更多信息。   由   提交/u/Electrical_Study_617   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqcdq8/d_pointer_on_using_knowledge_graphs_in_rag/</guid>
      <pubDate>Wed, 14 Feb 2024 02:52:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为分类练习微调 ViT 的实用技巧或学到的经验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqc9t7/d_practical_tips_or_learned_experiences_fine/</link>
      <description><![CDATA[嗨， 我目前正在使用预训练的 ViT (ViT_B_16) 来执行下游任务。我正在使用分布在 100 个类别的大约 13,000 张图像对其进行微调。我的方法包括遵循 PyTorch 官方教程并在 Cloud Tesla T4 (g4dn.8xlarge) 上进行培训。每个时期大约需要 14 分钟，对于初始运行，我任意设置了 20 个时期。 对于其他上下文，我的模型规范包括 32 的批量大小，并且我正在使用 Adam 优化器学习率设置为 1e-3。我有几个问题：  每个 epoch 14 分钟的持续时间合理吗？ 有办法减少训练持续时间吗？您会建议使用线性学习率调度程序、增加批量大小或调整 DataLoader 的工作人员数量吗？ 我是否因为不合并权重衰减、epsilon 或 beta 而忽略了任何内容？  我对设置感到有点焦虑，非常感谢您提供任何建议。 非常感谢您抽出时间。   由   提交/u/Numerous_Speed_9107   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqc9t7/d_practical_tips_or_learned_experiences_fine/</guid>
      <pubDate>Wed, 14 Feb 2024 02:47:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于检测和跟踪地面上小物体的相机选项</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqbeix/d_camera_options_for_detecting_and_tracking_small/</link>
      <description><![CDATA[在业余爱好项目上寻求帮助。我想在移动时检测地面上的小物体（2-10mm 大小）。因此，摄像头将安装在时速高达 10 公里的车辆上，并寻找地面上的物体。相机和地面之间的距离约为 500 毫米。我想使用我已经拥有的 Jetson Nano/Xavier。我最担心的是相机 - 知道我需要多大的 fps/传感器尺寸才能获得清晰的图像吗？   由   提交 /u/mrbronec   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqbeix/d_camera_options_for_detecting_and_tracking_small/</guid>
      <pubDate>Wed, 14 Feb 2024 02:04:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果我有一个采样策略 A、B、C 和 B 表现最好。如果数据规模扩大，情况仍然如此吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq8p38/d_if_i_have_a_sampling_strategy_a_b_and_c_and_b/</link>
      <description><![CDATA[所以我一直在测试带有二进制标签的 NLP 数据的不同采样策略（均匀、分层以及标签上两者之间的中间）。我已经用 20% 的数据对它们进行了测试，发现中间采样策略迄今为止效果最好。如果我缩放到 100% 的数据，什么原因可能导致中间的数据不再是最好的？   由   提交 /u/DolantheMFWizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq8p38/d_if_i_have_a_sampling_strategy_a_b_and_c_and_b/</guid>
      <pubDate>Tue, 13 Feb 2024 23:58:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 什么是鲁棒的预训练 Word2Vec 模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq8cm5/p_what_is_a_robust_pretrained_word2vec_model/</link>
      <description><![CDATA[我正在尝试构建一个 RNN 来预测句子，但我需要从一个好的 Word2Vec 模型开始，该模型对数字等事物具有鲁棒性（在非单词形式so：1,2,3)，人名，等等。我有数据，但新数据可能会包含以前未见过的单词，因此需要一个强大的 Word2Vec 模型。有什么建议吗？ 注意：由于某些问题限制，我无法使用 Transformer 来解决此问题，因为我知道最常见的响应是使用预先训练的 Transformer。   由   提交 /u/DolantheMFWizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq8cm5/p_what_is_a_robust_pretrained_word2vec_model/</guid>
      <pubDate>Tue, 13 Feb 2024 23:43:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Mamba 进行语音合成：初学者友好的笔记本 + 代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq7rd5/p_speech_synthesis_with_mamba_beginner_friendly/</link>
      <description><![CDATA[大家好，我遇到了这篇文章上个月，发现它非常有趣。我是 Defined AI 的开发者倡导者，总是希望学习新事物，所以我想自己解决这个问题。 博客文章写得非常好，作者：u/ExaminationNo8522 也有帮助。 无论如何，我想仔细检查它并在不同的数据集上为自己重现，然后移植到确定。结果是一个初学者友好的笔记本 + 博客文章。如果您感兴趣，请查看这些内容。 当然，如果您有想法/反馈/评论/问题，请告诉我！   由   提交 /u/ishabytes   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq7rd5/p_speech_synthesis_with_mamba_beginner_friendly/</guid>
      <pubDate>Tue, 13 Feb 2024 23:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] 思想扩散：扩散语言模型中的思想链推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq572l/r_diffusion_of_thoughts_chainofthought_reasoning/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.07754 代码：https ://github.com/HKUNLP/diffusion-of-thoughts 摘要：  扩散模型在以下领域获得了关注：文本处理，与传统自回归模型相比具有许多潜在优势。这项工作探索了扩散模型和思想链（CoT）的集成，这是一种完善的技术，可以提高自回归语言模型的推理能力。我们提出思想扩散 (DoT)，允许推理步骤通过扩散过程随着时间的推移而扩散。与以从左到右、逐个标记的方式做出决策的传统自回归语言模型相比，DoT 在计算和推理性能之间的权衡方面提供了更大的灵活性。我们的实验结果证明了 DoT 在多位数乘法和小学数学问题中的有效性。此外，DoT 还展示了有前景的自我纠正能力，以及自一致性解码等现有推理增强技术的优势。我们的发现有助于理解和发展扩散语言模型的推理能力。    由   提交 /u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq572l/r_diffusion_of_thoughts_chainofthought_reasoning/</guid>
      <pubDate>Tue, 13 Feb 2024 21:32:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR openreview 可见吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq0ama/d_iclr_openreview_visible/</link>
      <description><![CDATA[我最近向 ICML 提交了一篇论文，但被 ICLR 拒绝了。我发现我在 ICLR 的 openreview 控制台中的论文是每个人都可以看到的。可以吗？由于ICLR和ICML中的论文标题相同，那么ICML可能不是完全匿名的。 我必须手动更改可见性吗？   由   提交/u/Shot-Button-9010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq0ama/d_iclr_openreview_visible/</guid>
      <pubDate>Tue, 13 Feb 2024 18:15:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 复杂的机器学习项目是否需要编译语言？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apyymt/d_is_there_a_need_for_compiled_language_in/</link>
      <description><![CDATA[我们都知道机器学习场景是由 Python 主导的，简单但速度慢的语言。根据我的经验，Rust、C++、C 和 Zig 等语言平均速度快 10 倍（当然可能会有很大差异，并且由于多种原因，使用 C 编写的模块并没有多大帮助），但它们遭受需要编译，这需要一些开发时间。对于机器学习中使用的复杂算法来说，一旦开发过程放慢，它们仍然具有明显的优势。为什么他们的市场份额这么小？到目前为止，我确实找到了一个专门用于运行经过训练的神经网络模型的框架，称为 ggml。  编辑：我忘记了 TensorFlow 实际上主要是用 C++ 编写的。因此，这反驳了我关于编译语言没有太多市场份额的观点。   由   提交 /u/LetsNya   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apyymt/d_is_there_a_need_for_compiled_language_in/</guid>
      <pubDate>Tue, 13 Feb 2024 17:22:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] Fiddler：用于混合专家模型快速推理的 CPU-GPU 编排 - 华盛顿大学 2024 年 - 推理速度比现有系统快 10 倍以上！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apxr2n/r_fiddler_cpugpu_orchestration_for_fast_inference/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.07033  Github：https://github。 com/efeslab/fiddler  摘要：  基于专家混合 (MoE) 架构的大型语言模型 (LLM) 在各种任务。然而，由于模型尺寸巨大，在 GPU 内存资源不足的资源受限设置上运行它们具有挑战性。将模型权重卸载到 CPU 内存的现有系统面临着在 CPU 和 GPU 之间频繁移动数据的巨大开销。在本文中，我们提出了 Fiddler，一种资源高效的推理引擎，可为 MoE 模型提供 CPU-GPU 编排。 Fiddler的核心思想是利用CPU的计算能力来最小化CPU和GPU之间的数据移动。 我们的评估表明，Fiddler 可以运行参数超过 90GB 的未压缩 Mixtral-8x7B 模型，在具有 24GB 内存的单个 GPU 上每秒生成超过 3 个令牌，比现有方法有数量级的改进。  https ://preview.redd.it/q9l3fciyqdic1.jpg?width=1338&amp;format=pjpg&amp;auto=webp&amp;s=2e39726c970c655d6ee39f2b68c323204c6b2289 https://preview.redd.it/epjd0fiyqdic1.jpg?width=1661&amp;format=pjpg&amp;auto=webp&amp; ;s=701a2d61f8ab50d054db0301a30e40119898dab6   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apxr2n/r_fiddler_cpugpu_orchestration_for_fast_inference/</guid>
      <pubDate>Tue, 13 Feb 2024 16:34:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] OS-Copilot：迈向自我完善的通用计算机代理 - 上海人工智能实验室2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apwlkm/r_oscopilot_towards_generalist_computer_agents/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2402.07456  Github：https://github.com/OS-Copilot/FRIDAY  摘要：  与计算机的自主交互一直是一个长期的挑战巨大的潜力，最近大型语言模型（LLM）的激增显着加速了构建数字代理的进展。然而，大多数这些代理都被设计为与狭窄的域交互，例如特定的软件或网站。这种狭隘的关注限制了它们对一般计算机任务的适用性。为此，我们引入了 OS-Copilot，这是一个构建通用代理的框架，能够与操作系统 (OS) 中的综合元素（包括 Web、代码终端、文件、多媒体和各种第三方应用程序）进行交互。我们使用 OS-Copilot 创建 FRIDAY，这是一个自我改进的实体代理，用于自动化一般计算机任务。 在通用人工智能助手基准 GAIA 上，FRIDAY 的性能比以前的方法高出 35%，通过以前任务中积累的技能展示了对未见过的应用程序的强大泛化能力。我们还提供了数值和定量证据，表明 FRIDAY 学会了控制和控制在最少的监督下自我改进 Excel 和 Powerpoint。 我们的 OS-Copilot 框架和实证研究结果为未来研究更强大、更通用的计算机代理提供了基础设施和见解。   https://preview.redd.it/uzec8udohdic1.jpg?width=1655&amp;format=pjpg&amp; ;auto=webp&amp;s=893b5561ca47c26c789b69925efdc26e5b783007 https://preview.redd.it/vfwfwudohdic1.jpg?width=1653&amp;format=pjpg&amp;auto=webp&amp;s=9eafc2a5ea0ad188a156d3de446508d82d9cc913  https://preview.redd.it/lmi8rwdohdic1.jpg?width=1123&amp;format =pjpg&amp;auto=webp&amp;s=dbc67b27585b980d0c592f9bd9f87f3ec6531f66 https://preview.redd.it/20yo21eohdic1.jpg?width=1037&amp;format=pjpg&amp;auto=webp&amp;s=72fab36d585b862eed4ff6c7deed2be0cd62f637   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apwlkm/r_oscopilot_towards_generalist_computer_agents/</guid>
      <pubDate>Tue, 13 Feb 2024 15:48:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] [P] 通过贝叶斯优化将 LLM 评估速度提高 10 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apv97t/r_p_10_times_faster_llm_evaluation_with_bayesian/</link>
      <description><![CDATA[最近我一直致力于通过使用贝叶斯优化来选择合理的子集来快速进行 LLM 评估。 贝叶斯优化是使用它是因为它有利于探索/利用昂贵的黑匣子（释义，LLM）。 项目链接&lt; /p&gt; 我很想听听您对此的想法和建议！   由   提交 /u/b06901038g   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apv97t/r_p_10_times_faster_llm_evaluation_with_bayesian/</guid>
      <pubDate>Tue, 13 Feb 2024 14:51:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 为什么目标检测模型的对手看起来与图像分类器不同</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apv6ws/p_why_do_object_detection_model_adversaries_look/</link>
      <description><![CDATA[     &lt; /td&gt; 大家好。我只是想看看图像分类器上的对抗性攻击的行为，并决定也尝试使用对象检测器。我注意到对这些模型的无针对性的对抗性攻击产生了一些感兴趣的面具。图像分类器生成了通常预期的流行噪声掩模，但相同条件下的对象检测器生成了与所讨论的对象非常相似的掩模。这背后的原因是什么？感谢您的帮助！ 第一张图片是对象检测器的对抗性掩模，第二张图片是图像分类器的对抗性掩模，最后一张图片是原始图片。 &lt; a href=&quot;https://preview.redd.it/abo3yj7xddic1.png?width=425&amp;format=png&amp;auto=webp&amp;s=0e73a11997b2c27a6f73832204862d97e5847b4a&quot;&gt;https://preview.redd.it/abo3yj7xddic1.png?width =425&amp;format=png&amp;auto=webp&amp;s=0e73a11997b2c27a6f73832204862d97e5847b4a https://preview.redd.it/mbsi6k7xddic1.png?width=425&amp;format=png&amp;auto=webp&amp;s=41de2eca4348afbddfb36154da514046b1be78是 https://preview.redd.it/zusv0k7xddic1.jpg ?width=400&amp;format=pjpg&amp;auto=webp&amp;s=cf08f3911c24e10c632b12e42a976cd35ff3f490   由   提交/u/tatteredsky  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apv6ws/p_why_do_object_detection_model_adversaries_look/</guid>
      <pubDate>Tue, 13 Feb 2024 14:48:37 GMT</pubDate>
    </item>
    <item>
      <title>[2402.07901] FAST：加速 Transformer 的可分解注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aprsv9/240207901_fast_factorizable_attention_for/</link>
      <description><![CDATA[ 由   提交/u/Elven77AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aprsv9/240207901_fast_factorizable_attention_for/</guid>
      <pubDate>Tue, 13 Feb 2024 12:00:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>