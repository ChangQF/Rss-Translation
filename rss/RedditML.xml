<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sun, 17 Mar 2024 21:13:12 GMT</lastBuildDate>
    <item>
      <title>xAI 发布 Grok-1 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh7yc4/xai_releases_grok1_n/</link>
      <description><![CDATA[ 我们正在发布大型语言模型 Grok-1 的基本模型权重和网络架构。 Grok-1 是一个由 xAI 从头开始​​训练的 3140 亿参数混合专家模型。 这是 Grok-1 预训练阶段的原始基础模型检查点，该阶段于 2023 年 10 月结束。这意味着该模型没有针对任何特定应用程序（例如对话）进行微调。 我们将在 Apache 2.0 许可证下发布权重和架构。 开始使用使用该模型时，请按照 https://github.com/xai-org/grok 中的说明进行操作   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh7yc4/xai_releases_grok1_n/</guid>
      <pubDate>Sun, 17 Mar 2024 20:38:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] Paperlib：一个开源且现代设计的学术论文管理工具。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh63c1/p_paperlib_an_opensource_and_moderndesigned/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh63c1/p_paperlib_an_opensource_and_moderndesigned/</guid>
      <pubDate>Sun, 17 Mar 2024 19:24:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] MOIRAI：Salesforce 的新时间序列基础预测模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh56kz/p_moirai_new_timeseries_foundation_forecasting/</link>
      <description><![CDATA[       由   提交 /u/apaxapax   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh56kz/p_moirai_new_timeseries_foundation_forecasting/</guid>
      <pubDate>Sun, 17 Mar 2024 18:49:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 精馏塔塔顶硫磺预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh4g3r/p_distillation_tower_overhead_sulfur_prediction/</link>
      <description><![CDATA[我正在构建一个神经网络来预测蒸馏塔顶部的硫（以 ppm 为单位）。到目前为止，我尝试对塔参数进行建模（再沸器负荷、底部和顶部塔温度、回流率、塔压力、OH温度、流失率、进料速率、进料中的硫（每周样品）、进料中的硫）底部（也是每周）），但最终得到的数据集太小，在十年内约有 250 个可用点，其中任何具有良好 R2 和 RSME 的模型都完全过度拟合，似乎甚至对于验证数据集 w / 随机 kfold。塔顶硫磺结果通常为 2 次/天。  我的两个问题是： 如果模型在每个数据点上进行训练，k-fold 是否会过度拟合？或者 k 折叠的设计是否使得每个折叠都至少使用不包含该折叠训练数据的模型进行一次验证？我构建的模型用于训练和验证的 R2 为 0.98（0.01 以内），RSME 为 8-10，这是可以接受的。我还没有找到部署模型的好方法来测试，但是我手动插入的一些值没有产生准确的结果。 我正在考虑首先对没有硫的塔进行建模，用几分钟分钟的过程数据，以建立塔顶流量和其余塔操作参数之间的关系，并尝试预测分离效率和下降流量，然后使用该模型进料第二个模型，该模型用于根据进料硫预测塔顶硫、塔顶馏出物：进料比和分离效率（因为分流的紧密程度会影响硫 ppm）。  我是 NN 的新手，我只是一名董事会操作员。工程师并不是只想构建一些可以让我/其他操作员的生活变得更轻松的东西。  我正在使用 JMP 17 pro，你们（流程工程师）在构建模型后如何部署模型？    由   提交/u/thedudear  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh4g3r/p_distillation_tower_overhead_sulfur_prediction/</guid>
      <pubDate>Sun, 17 Mar 2024 18:20:16 GMT</pubDate>
    </item>
    <item>
      <title>关于集成学习的问题[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh3vpt/question_about_ensmble_learning_d/</link>
      <description><![CDATA[我正在阅读有关集成学习的内容，据我了解，只需在 python 中使用集成就可以将多个模型的预测组合成一个统一的模型。我见过的大多数教程都有这样的代码：  from sklearn.linear_model import LinearRegression from sklearn.tree import DecisionTreeRegressor from sklearn.neighbors import KNeighborsRegressor from sklearn.ensemble import VotingRegressor from sklearn.datasets import fetch_california_housing from sklearn.metrics importmean_squared_error # 定义模型 lr = LinearRegression() dt = DecisionTreeRegressor() knn = KNeighborsRegressor() # 创建平均集成 avg = VotingRegressor(estimators=[(&#39;lr&#39;, lr), (&#39;dt&#39;, dt), (&#39;knn&#39;, knn)])  我正在构建一个电影推荐系统，目前有 5 个基于不同属性组的余弦相似度向量，我想将它们组合起来得到一个统一的推荐模型。 我的问题是，集成是否只能与 KNN 和回归模型一起使用，或者有没有办法可以将它与我的向量一起使用？ 有什么建议吗？不胜感激，如果您需要我详细说明某些内容，请告诉我。 ​   由   提交 /u/wobowizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh3vpt/question_about_ensmble_learning_d/</guid>
      <pubDate>Sun, 17 Mar 2024 17:57:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 医学：有人训练过肺/心脏听诊的开源模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh2ho0/d_medical_anyone_trained_an_open_source_model_on/</link>
      <description><![CDATA[看起来这确实有用且相对容易完成，我的意思是，数据集存在。   由   提交 /u/hmmqzaz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh2ho0/d_medical_anyone_trained_an_open_source_model_on/</guid>
      <pubDate>Sun, 17 Mar 2024 16:59:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM4Decompile：使用大型语言模型反编译二进制代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh23py/r_llm4decompile_decompiling_binary_code_with/</link>
      <description><![CDATA[ 由   提交/u/vegax87  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh23py/r_llm4decompile_decompiling_binary_code_with/</guid>
      <pubDate>Sun, 17 Mar 2024 16:43:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过集群间建模生成代码的神经排名器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgwmzv/r_neural_rankers_for_code_generation_via/</link>
      <description><![CDATA[我们引入了 SRank，这是一种新颖的重新排名策略，用于从代码生成中选择最佳解决方案，重点是对集群间关系进行建模。通过量化集群之间的功能重叠，我们的方法提供了更好的代码解决方案排名策略。实证结果表明，我们的方法在 pass@1 分数上取得了显着的结果。例如，在 Human-Eval 基准测试中，我们在 Codex002 的 pass@1 中实现了 69.66%，WizardCoder 为 75.31%，StarCoder 为 53.99%，CodeGen 为 60.55%，这超越了最先进的解决方案排名方法，例如同一 CodeLLM 上的 CodeT 和 Coder-Reviewer 具有显着的优势（平均提高约 6.1%）。与随机抽样方法相比，我们在 Human-Eval 上平均提高了约 23.07%，在 MBPP 上平均提高了 17.64%。 论文：https://arxiv.org/abs/2311.03366 代码： https://github.com/FSoft-AI4Code/SRank-CodeRanker   由   提交 /u/FSoft_AIC   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgwmzv/r_neural_rankers_for_code_generation_via/</guid>
      <pubDate>Sun, 17 Mar 2024 12:43:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与你的表聊天 - 使用什么来使用开源 LM 进行数据库问答？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgw40p/d_chat_with_your_tables_what_to_use_for_database/</link>
      <description><![CDATA[我正在开发一个项目，我们想要回答数据库中表的简单/中度硬查询。我目前没有资源来微调模型，想尝试开源大型语言模型。 过滤掉之后的所有表格大约有 120 GB，这告诉我需要使用开始时有一个 Text 2 SQL 模型，并可能使用 Spark 执行。我用采样数据尝试了 pandasAI 和 LC 代理，但输出并不是很好（有些失败 如果有人对此进行过研究，我将不胜感激任何线索或评论，或任何研究论文。我需要有关典型管道的外观以及如何提取和传递数据中的多行的指导。    提交者   /u/Parking_Nectarine_19   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgw40p/d_chat_with_your_tables_what_to_use_for_database/</guid>
      <pubDate>Sun, 17 Mar 2024 12:14:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 专用于AI学习环境的游戏引擎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgvgrr/d_game_engine_dedicated_to_ai_learning/</link>
      <description><![CDATA[我最近一直在寻找一种为 RL 训练创建自定义环境的方法，该环境可以轻松地与外部编程语言和框架集成（因此基本上将 NPC 外包）游戏逻辑到游戏本身以外的其他东西，如 pytorch 或 TensorFlow，或您选择的任何其他库）。  长话短说，我遇到过unity ml代理，但它的灵活性非常有限（你只能微调一些算法的超参数），而且自上次unity以来，设置真的很草率+我对使用它有点怀疑。 Nvidiaomniverse + Isaac Gym 仅适用于高度精确的物理环境，你需要大量的 GPU 和精确的模型来运行它，但这不是我想要的东西。我可以扭转它足以使其实现简单的游戏，但这将是一个strech 除此之外，我只找到了几个库，但没有一个真正匹配接近我想要的 ​ 我设想的是一个改进的 godot 引擎，上面有一个框架，集成了 godot 和 python 数据传输和同步。您应该能够更改引擎中的对象参数，并且应该将其映射到 python 代码，如果 python 没有为游戏内代理返回特定的匹配模式，则会出现错误 &lt; p&gt;你知道有什么与我所描述的类似的事情吗？    由   提交/u/DeadProgrammer8785   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgvgrr/d_game_engine_dedicated_to_ai_learning/</guid>
      <pubDate>Sun, 17 Mar 2024 11:36:51 GMT</pubDate>
    </item>
    <item>
      <title>[D]分布式训练策略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgulqe/d_distributed_training_strategy/</link>
      <description><![CDATA[嗨，我想知道如何使用不同的“分布式训练策略”微调 Mixtral。 我可以使用 4* A100 (40Gb)，并且想要尝试不同的策略，例如对模型进行分片并在每个 GPU 上放置 2 个专家层、使用 QLoRA 量化模型，以及在 4 个 GPU 上使用数据并行性。 我可以使用 4* A100 (40Gb)，并且想要尝试不同的策略，例如对模型进行分片并在每个 GPU 上放置 2 个专家层，或者使用以下方法量化模型QLoRA，并在 4 个 GPU 上使用数据并行性。   由   提交 /u/Thick-brain-dude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgulqe/d_distributed_training_strategy/</guid>
      <pubDate>Sun, 17 Mar 2024 10:40:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] Mixture-of-LoRA：大型语言模型的高效多任务调优</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgub6e/r_mixtureofloras_an_efficient_multitask_tuning/</link>
      <description><![CDATA[ 由   提交/u/hardmaru  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgub6e/r_mixtureofloras_an_efficient_multitask_tuning/</guid>
      <pubDate>Sun, 17 Mar 2024 10:20:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我不明白反向传播如何在稀疏门控 MoE 上工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgmpmf/d_i_dont_understand_how_backprop_works_on/</link>
      <description><![CDATA[我不明白反向传播如何在稀疏门控 MoE 上工作 在 LLM 的背景下，假设你有 n 个专家，并且您为每个令牌选择了前 k 个。 在训练期间，门网络可能完全错误，并且将正确的专家排除在所选的 k 之外。然而，由于没有使用正确的专家，因此门没有机会增加正确专家的权重。 换句话说，在背景期间，仅更新门网络的部分参数，影响前 k 内权重的那些。 我错过了什么吗？   由   提交 /u/Primary-Try8050    reddit.com/r/MachineLearning/comments/1bgmpmf/d_i_dont_understand_how_backprop_works_on/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgmpmf/d_i_dont_understand_how_backprop_works_on/</guid>
      <pubDate>Sun, 17 Mar 2024 02:22:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] Apple - MM1：多模式 LLM 预培训的方法、分析和见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgbc5u/r_apple_mm1_methods_analysis_insights_from/</link>
      <description><![CDATA[Apple 的新论文介绍了 MM1 ，一系列结合了视觉和语言理解的多模式人工智能模型。研究人员进行了广泛的实验，以确定驱动这些模型性能的关键因素，测试不同的架构选择和预训练数据混合。 以下是我在论文中的要点： Big当然之一：最大的 MM1 模型（30B 密集）在多模态基准上实现了最先进的少样本学习 要点：  MM1 包括两者高达 30B 参数的密集模型和专家混合 (MoE) 变体 图像分辨率对性能的影响最大，超过模型大小 特定的视觉语言连接器设计具有效果不大 在预训练中混合交错图像+文本、标题和纯文本数据至关重要 标题、交错和文本数据的比例为 5:5:1 有效最佳 合成字幕数据有助于少样本学习 30B 密集模型在 VQA 和字幕任务上击败了先前的 SOTA  核心见解深思熟虑的数据和架构选择，而不仅仅是规模，是构建高性能多模式模型的关键。 MM1 模型还表现出令人印象深刻的新兴能力，例如多图像推理和上下文中的小样本学习。 完整摘要。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/1bgbc5u/r_apple_mm1_methods_analysis_insights_from/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgbc5u/r_apple_mm1_methods_analysis_insights_from/</guid>
      <pubDate>Sat, 16 Mar 2024 17:29:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>