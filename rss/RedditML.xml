<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 15 Feb 2024 12:22:57 GMT</lastBuildDate>
    <item>
      <title>[D] [P] UI 的多模式点击模型：PTA-Text</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ardr12/d_p_a_multimodal_click_model_for_ui_ptatext/</link>
      <description><![CDATA[HuggingFace 演示： https://huggingface.co/spaces/AskUI/pta-text-v0.1 模型检查点： https://huggingface.co/AskUI/pta-text-0.1  您好！ 我想与您分享我最近开发的一个项目。我的灵感来自于一个问题：UI 通常是结构化的，不像现实世界的图像那样嘈杂，但为什么人们使用像 LLM/VLM 这样的重型智能模型？当然，大型法学硕士/VLM 有利于规划，但在本地化方面遇到困难。因此，我构建了一个小型多模式，它可以获取用户屏幕截图并执行单击命令。目前，我**仅在文本上进行**作为原型设计阶段。 当然，有一些很好的企业解决方案，例如 Copilot、Adept ACT-1、AutoGPT 等正在尝试实现这但我的只是它的较小版本。 期待听到您的意见！ 注意事项：  仅接受 1920x1080 尺寸屏幕截图的训练。因此，在该尺寸上表现良好，但在其他宽高比上效果还不错。 我添加了位置说明符来帮助定位。例如，我们可以输入“单击文本“通知””在屏幕的右上角”等 当文本出现在多个位置时，我们甚至无法使用位置说明符缩小范围，会出现一些问题。    由   提交/u/Outlandish_MurMan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ardr12/d_p_a_multimodal_click_model_for_ui_ptatext/</guid>
      <pubDate>Thu, 15 Feb 2024 11:52:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] Magnus - 一种简化的工作流定义语言，无需任何更改即可在 Argo 本地运行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arct8u/p_magnus_a_simplified_workflow_definition/</link>
      <description><![CDATA[仓库链接 Magnus 是一种简化的工作流程定义语言，可帮助：  简化设计流程： Magnus 使用户能够使用 存根节点，并提供对各种结构的支持，例如任务、并行分支和循环或映射分支 yaml 或 python SDK 以获得最大的灵活性。  ​  增量开发：使用 Magnus 逐步构建管道，这样就可以执行Python 函数，笔记本，或 shell 脚本，适应开发人员首选的工具和方法。  ​  稳健的测试：确保您的管道按预期运行使用采样数据进行测试的能力。 Magnus 还提供模拟和修补任务的功能，以便在全面部署之前进行彻底评估。&lt; /li&gt;  ​  无缝部署：轻松从开发阶段过渡到生产阶段。 Magnus 简化了流程，只需仅更改配置即可适应不同的环境，包括对 argo 工作流程。  ​  高效调试：使用 Magnus 的本地调试功能快速识别并解决管道执行中的问题。使用您选择的调试工具从失败的任务中检索数据并重试失败以保持顺利开发经验。  ​ 除了开发人员友好的功能外，Magnus 还充当生产级概念的接口，例如 数据目录，再现性、实验跟踪和安全访问秘密。 文档 有关该项目以及如何使用它的更多详细信息请参见此处   由   提交/u/magnus-pipelines  /u/magnus-pipelines  reddit.com/r/MachineLearning/comments/1arct8u/p_magnus_a_simplified_workflow_definition/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arct8u/p_magnus_a_simplified_workflow_definition/</guid>
      <pubDate>Thu, 15 Feb 2024 10:50:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 扩散中需要分类器免费指导</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arcily/d_need_for_classifier_free_guidance_in_diffusion/</link>
      <description><![CDATA[为什么无分类器引导训练有条件和无条件两种？我的意思是，当我们想要有条件地生成数据时，无条件训练的必要性是什么？我正在尝试阅读看起来非常困难的论文。谁能给我推荐一个好的博客来帮助我指导扩散模型？   由   提交/u/sushilkhadakaanon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arcily/d_need_for_classifier_free_guidance_in_diffusion/</guid>
      <pubDate>Thu, 15 Feb 2024 10:29:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 键值约束 LLM 推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arcgvh/r_keyvalue_constrained_llm_inference/</link>
      <description><![CDATA[EasyKV 集成了各种 KV 缓存驱逐策略，并与 HuggingFace 转换器库兼容，用于生成推理。它支持多头注意力、多查询注意力和分组查询注意力的LLM，并提供驱逐策略、缓存预算和应用场景的灵活配置。 论文：https://arxiv.org/abs/2402.06262 Github：https://github.com/DRSY/EasyKV   由   提交/u/Dramatic_Evening_921   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arcgvh/r_keyvalue_constrained_llm_inference/</guid>
      <pubDate>Thu, 15 Feb 2024 10:25:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 变压器中数字特征的位置编码。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arc4di/d_positional_encodings_for_numerical_features_in/</link>
      <description><![CDATA[嗨！ 我正在尝试使用特征序列（这些是描述太阳活动区域的磁场特征， （因此每个特征对应不同的特征）来预测该区域是否会在未来 12 小时内产生耀斑。现在，我最近开始研究变压器架构，并了解到，为了使这些模型能够理解数据的顺序性质（或者我应该说，学习它），需要包含位置编码。然而，我有点困惑它们对于这种类型的数据有多大用处。 我理解 NLP 中出现的位置编码的想法，因此您可以将其应用于词嵌入。在这种情况下，如果您将单词嵌入作为标记（这是固定的，因此每个单词将始终是相同的嵌入），我可以理解模型可能能够在某种程度上记住嵌入是什么，然后提取位置信息从编码。然而，当涉及到顺序数值数据时，我担心这些编码可能没有那么有用。模型如何知道区分编码和实际值？除此之外，由于数据被归一化为 0 和 std 1，嵌入（例如通常的正弦曲线）不会淹没数据的真实值吗？ 我猜这一切都是这是因为，当我从模型中取出位置编码时，性能基本保持不变，因此它似乎没有使用与序列顺序相关的任何信息来进行预测。我想知道这是否是因为它确实对这项任务没有帮助，或者是因为我处理这件事的方式没有帮助。也许还存在一个问题，因为我的数据中有间隙（用 0 填充），并且到目前为止我没有使用屏蔽。也许添加掩蔽后会有一些更明显的影响，但我想这不会很大，因为我看不到在以下时间段内输出的样子（耀斑概率与时间）有很多变化当我取出编码时没有间隙。 非常感谢对此的任何见解！   由   提交 /u/Calcirium   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arc4di/d_positional_encodings_for_numerical_features_in/</guid>
      <pubDate>Thu, 15 Feb 2024 10:01:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为使用卫星图像进行经济分析的 ML 项目寻求云服务建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arby6w/d_seeking_recommendations_for_a_cloud_service_for/</link>
      <description><![CDATA[您好， 我目前正在撰写硕士论文，重点研究卫星图像的经济可用性。我的项目旨在通过分析这些图像来预测经济活动，特别是针对丹麦。这一选择是由该地区详细收入数据的可用性决定的。 我正在探索用于此分析的不同模型，并正在寻找可以支持我的要求的云服务。我需要一个可以运行 Python 代码来执行各种任务的平台，包括：  从 API 下载和存储图像 预处理数据 训练多种机器学习模型  鉴于我是一名学生，成本效率对我来说至关重要。此外，由于我对使用云服务相对较新，因此非常感谢用户友好的界面。 有人可以推荐符合这些标准的服务吗？根据您的经验，类似项目的最佳平台是什么？ 感谢您的时间和帮助。 此致， Human &lt; /div&gt;  由   提交/u/Human_Number_10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arby6w/d_seeking_recommendations_for_a_cloud_service_for/</guid>
      <pubDate>Thu, 15 Feb 2024 09:48:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] [2402.05919] 几何条件 PBR 图像生成的协同控制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1araxfo/r_240205919_collaborative_control_for/</link>
      <description><![CDATA[ 由   提交 /u/StartCodeEmAdagio   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1araxfo/r_240205919_collaborative_control_for/</guid>
      <pubDate>Thu, 15 Feb 2024 08:33:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用小数据集进行验证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arakd6/d_validation_with_small_datasets/</link>
      <description><![CDATA[我所在的领域的数据集通常很小（100-10000 个样本）且具有层次结构（取自 10-50 个参与者）。这意味着，为了在足够大的测试集上评估数据，而不仅仅是少数参与者，我们需要使用交叉验证。到目前为止一切顺利。 但是，这仍然没有解决验证问题。有几种可能的方法可以进行验证：  跳过验证。这似乎是我所在领域的首选方法。我认为这是非常错误的，而且我发现它可以高估准确度 5%（包含 5000 个样本的数据集），甚至高达 20%（100 个样本）。 将训练数据一次分割为训练和验证集用于对每个测试折叠进行验证。这样做的缺点是验证集最终很小（比测试集小得多），并且如果不小心的话，训练验证分割可能是任意的。 完全嵌套交叉验证。这似乎是正确验证超参数配置的最佳方法，因为它几乎使用整个数据集进行验证。我在我的领域还没有遇到过一篇使用嵌套交叉验证（正确）的论文。我相信主要问题非常明显：如果一个人使用 10 倍嵌套交叉验证训练一个神经网络模型 100 个时期，并尝试优化 5 个二进制超参数，那么最终已经有大约 100 * 10^2 * 2 ^5 = 320,000 个纪元。如果一个 epoch 需要 10 秒，这已经相当于一个多月的计算时间，而且我们仍然只验证了很少的超参数配置。  我可以看到以下解决方案：   p&gt;  接受计算需要这么长时间（并希望评审者不要要求我们重复实验）。 找到尽可能限制超参数配置的方法。  li&gt; 改用 5 重嵌套交叉验证。 减小验证集的大小（方法 2）。 承认并停止将神经网络拟合得较小数据集。  您对此有何看法？您更喜欢哪些选项？您还有其他解决方案吗？   由   提交/u/philosophicalmachine  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arakd6/d_validation_with_small_datasets/</guid>
      <pubDate>Thu, 15 Feb 2024 08:07:12 GMT</pubDate>
    </item>
    <item>
      <title>[N] Gradio Notebook 自定义组件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ar1u1q/n_gradio_notebook_custom_component/</link>
      <description><![CDATA[嘿！我们刚刚与 Hugging Face 团队一起推出了 Gradio Notebook。  该组件在 Hugging Face 空间上部署笔记本用户体验。   在一个地方探索多个 Hugging Face 模型的最简单方法 使用文本、图像和音频模型构建 AI 工作流程 托管您的 AI 工作流程上抱脸给别人看！   在这里查看：https://huggingface.co/spaces/ lastmileai/gradio-notebook-template  我们正在寻找早期反馈以及改进体验的方法。如果您有任何疑问，请发表评论并随时私信 :)    由   提交 /u/InevitableSky2801   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ar1u1q/n_gradio_notebook_custom_component/</guid>
      <pubDate>Wed, 14 Feb 2024 23:59:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] Whisper Large v3 基准：在消费类 GPU 上以 5110 美元（每美元 11,736 分钟）转录 100 万小时 - 后续</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ar08br/p_whisper_large_v3_benchmark_1_million_hours/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ar08br/p_whisper_large_v3_benchmark_1_million_hours/</guid>
      <pubDate>Wed, 14 Feb 2024 22:50:05 GMT</pubDate>
    </item>
    <item>
      <title>[D]微调时间有没有“负面提示”的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqyhmk/d_is_there_a_way_of_negative_prompting_at/</link>
      <description><![CDATA[假设我正在尝试微调预训练的语言模型，并且我想更改其响应格式。通常情况下，我会根据新格式对一堆回复示例进行微调。但这样做也会改变模型的语义行为，以更接近地模仿 SFT 示例中存在的文本类型。有没有办法对新格式的示例进行微调，然后对微调示例中的相同文本进行有效的负面微调，但没有新的响应格式？最终结果是模型现在以所需的格式返回响应，但返回的文本类型的分布没有变化。   由   提交/u/thirdvox  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqyhmk/d_is_there_a_way_of_negative_prompting_at/</guid>
      <pubDate>Wed, 14 Feb 2024 21:35:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 模型崩溃揭秘：回归案例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqwset/r_model_collapse_demystified_the_case_of/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.07712 摘要：  在ChatGPT这样的大型语言模型时代， “模型崩溃”指的是这样一种情况：随着时间的推移，模​​型根据其前几代生成的数据进行递归训练，其性能会下降，直到模型最终变得完全无用，即模型崩溃。在这项工作中，我们在核回归的简化设置中研究了这种现象，并获得了结果，这些结果显示模型可以处理虚假数据的情况与模型性能完全崩溃的情况之间存在明显的交叉。在多项式衰减光谱和源条件下，我们获得了修改后的缩放定律，该定律表现出从快速率到慢速率的新交叉现象。我们还提出了一种基于自适应正则化的简单策略来减轻模型崩溃。我们的理论结果通过实验得到了验证。    由   提交 /u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqwset/r_model_collapse_demystified_the_case_of/</guid>
      <pubDate>Wed, 14 Feb 2024 20:22:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 阅读和学习研究论文的最佳方式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</link>
      <description><![CDATA[当我们尝试专注于玉兰油的创新产品时，我们必须学习许多现代科技知识。但通常需要时间才能获得博客和教程上的可用资源。  因此，直接从第一个主要来源学习是有效的学习方式，因为它是主要来源。 但是，我发现阅读论文非常困难，因为它包含许多术语或内容不寻常的措辞。此外，跟踪和掌握一篇大论文的上下文也需要很大的耐心。 你们能分享一下你们的方法吗？你们如何有效且高效地从已发表的论文中学习并获得见解？   由   提交 /u/FardinRock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</guid>
      <pubDate>Wed, 14 Feb 2024 14:28:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过计算机视觉让我的书架可点击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</link>
      <description><![CDATA[      我构建了一个系统，可以让你拍摄书架的照片并创建一个交互式 HTML 网页，您可以在其中单击图像中的书籍来了解有关每本书的更多信息。 该项目的技术堆栈是：  用于检索的接地 SAM书籍的多边形。 OpenCV + 监督转换，为 OCR 准备书籍。 GPT-4 和 Vision for OCR Google Books API，用于获取书籍元数据。  生成 HTML + SVG 以创建最终网页。  我在博客上写了有关如何构建此项目的文章。 尝试演示。 我希望获得有关如何提高图书检测率以获得更好性能的反馈。在书脊上训练自定义分割模型可能会起作用，但我知道为此可能需要多少数据。 下面的红色多边形表示在演示中可点击的分段书籍：  p&gt; https://preview.redd.it /p9w4rgsn1jic1.png?width=1260&amp;format=png&amp;auto=webp&amp;s=35116c7eb9d1f5dab2b11375be9e2ff0e7163b78   由   提交/u/zerojames_  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</guid>
      <pubDate>Wed, 14 Feb 2024 10:21:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>