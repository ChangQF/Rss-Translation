<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 25 Sep 2024 01:16:03 GMT</lastBuildDate>
    <item>
      <title>[D]-NeurIPS 2024 决策</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foky4r/d_neurips_2024_decisions/</link>
      <description><![CDATA[大家好！请注意，NeurIPS 2024 决策通知将于 2024 年 9 月 26 日欧洲中部夏令时间凌晨 3:00 发布。我觉得创建一个我们可以讨论它的帖子会很酷。    提交人    /u/Proof-Marsupial-5367   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foky4r/d_neurips_2024_decisions/</guid>
      <pubDate>Tue, 24 Sep 2024 19:23:39 GMT</pubDate>
    </item>
    <item>
      <title>如何在建立模型之前识别坏数据集？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fojgdm/how_to_identify_bad_datasets_before_building/</link>
      <description><![CDATA[大家好！ 我一直在研究机器学习模型，有时在经历了所有的数据清理、转换和处理之后，开始建模才意识到数据集本身不够好。这非常令人沮丧，因为在意识到这一点之前，已经投入了大量时间。 我知道进行彻底的 EDA 会有所帮助，但我想知道在深入模型构建之前，是否有任何不常见的检查/测试/技术可以帮助尽早发现数据集中的问题。 任何见解都会有所帮助。    提交人    /u/Negative_Extent_1582   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fojgdm/how_to_identify_bad_datasets_before_building/</guid>
      <pubDate>Tue, 24 Sep 2024 18:22:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我的第一个语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foh2jn/p_my_first_language_model/</link>
      <description><![CDATA[大家好！ 我只是想分享我最近的项目，我从头开始构建了一个大型语言模型，它更像是非常小的语言模型，但我很喜欢构建它，有一次我被卡住了，无意识地复制和粘贴，很高兴它能产生一些东西。 这是我的项目 请分享您的想法和任何改进建议。    提交人    /u/Gold-Act-7366   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foh2jn/p_my_first_language_model/</guid>
      <pubDate>Tue, 24 Sep 2024 16:43:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 3000 张随机图像及其简短描述可以做什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fogntr/p_what_can_be_done_with_3000_random_images_and/</link>
      <description><![CDATA[我有一个客户，他有一个图片库，每个图片都有一个句子长的英语和法语描述。  我可以建立什么模型，我应该在这个数据集上练习什么算法来提高和展示我的数据科学家技能？    提交人    /u/Legal-Fig-384   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fogntr/p_what_can_be_done_with_3000_random_images_and/</guid>
      <pubDate>Tue, 24 Sep 2024 16:26:59 GMT</pubDate>
    </item>
    <item>
      <title>模特选择 - 电视节目获奖者 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foezap/model_choice_tv_show_winners_discussion/</link>
      <description><![CDATA[大家好。我想请教一下，应该使用哪种模型来根据参赛者在该集迄今为止的表现来判断他们赢得电视剧的可能性。我有每周分配的表现标记（数字），以及这些标记的累积列。我还有一个名为“Performance_overall”的累积列，它将截至该季的所有正分相加并减去负分。有什么建议吗？我看过 RNN，但不确定？    提交人    /u/htaswell   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foezap/model_choice_tv_show_winners_discussion/</guid>
      <pubDate>Tue, 24 Sep 2024 15:16:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 应对攻击性网络安全挑战的新型 SWE 代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fodjcg/r_new_sweagent_for_offensive_cybersecurity/</link>
      <description><![CDATA[嗨！ 我是创建 SWE-agent（一种免费开源）自动化编程系统）的团队的一员，今天我们赋予它解决攻击性网络安全挑战的能力。 让它使用解决这些挑战所需的工具需要做大量的工作，但现在它能够使用交互式调试器，可以连接到服务器，并且可以使用各种各样的 cybsersec 工具。  代码现已在 https://github.com/princeton-nlp/swe-agent 上线  您可以在 https://enigma-agent.github.io/assets/paper.pdf 阅读我们的论文&gt; 我们今天会在这里回答您可能有的任何问题或意见。    提交人    /u/ofirpress   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fodjcg/r_new_sweagent_for_offensive_cybersecurity/</guid>
      <pubDate>Tue, 24 Sep 2024 14:14:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 双曲大脑表征：利用双曲几何改进表征学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fo9yb2/r_hyperbolic_brain_representations_improving/</link>
      <description><![CDATA[一篇新论文研究了双曲几何在大脑中的应用方式以及如何利用双曲几何来帮助我们改进人工智能模型。 https://arxiv.org/abs/2409.12990v1    提交人    /u/platinumposter   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fo9yb2/r_hyperbolic_brain_representations_improving/</guid>
      <pubDate>Tue, 24 Sep 2024 11:15:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 维数灾难</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fo8djj/d_curse_of_dimensionality/</link>
      <description><![CDATA[我正在查看用于向量嵌入的维数 请注意，不同的 GPT3 系列引擎 [0] 产生不同大小的嵌入： Ada（1024 维）， Babbage（2048 维）， Curie（4096 维）， Davinci（12288 维）。 来源：https://www.kaggle.com/code/vslaykovsky/gpt-3-embeddings 然而，GPT-4 似乎在 text-embedding-3-large 中只提供了 3072 个维度。 为什么？这真的是文本准确度和性能的最佳点吗？ https://openai.com/index/new-embedding-models-and-api-updates/ 话虽如此，12K 尺寸似乎非常大。有人在生产中真正使用这些吗？    提交人    /u/ghoof   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fo8djj/d_curse_of_dimensionality/</guid>
      <pubDate>Tue, 24 Sep 2024 09:28:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 目前对您来说最令人兴奋的三大研究方向是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fo7ben/r_what_are_the_top_3_most_exciting_research/</link>
      <description><![CDATA[让我们分享吧！你对什么感到兴奋？    提交者    /u/Prestigious_Bed5080   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fo7ben/r_what_are_the_top_3_most_exciting_research/</guid>
      <pubDate>Tue, 24 Sep 2024 08:05:01 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 我可以将我的匿名 AAAI 主会议提交内容上传到 arxiv 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fo69nr/research_can_i_upload_my_anonymous_aaai_main/</link>
      <description><![CDATA[我已为 AAAI 2025 主轨道提交了一篇论文。第一阶段的拒绝通知将于 10 月 14 日发出，反驳通知将于 11 月 4-8 日发出。我想知道我可以将我的论文上传到 arxiv 吗？ 我查看了提交指南，其中规定：  在两种情况下，非匿名在线资料的存在不会被视为违反 AAAI-25 的盲审政策：提交的作品 (1) 可以作为未经审查的预印本出现在初步版本中（例如，在 arXiv.org、社交媒体、个人网站上）或出现在没有存档程序的任何研讨会上；或 (2) 在研究讲座中讨论，即使此类讲座的摘要或视频已在线提供。   据我了解，它说他们允许将已经上传到 arxiv 的论文提交给会议，但他们没有具体说明我们是否可以在等待 AAAI 评审时将其提交到 arxiv。    提交人    /u/morphinejunkie   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fo69nr/research_can_i_upload_my_anonymous_aaai_main/</guid>
      <pubDate>Tue, 24 Sep 2024 06:45:04 GMT</pubDate>
    </item>
    <item>
      <title>发现大词汇量的交叉熵损失的陷阱。[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fnu24s/discovering_a_pitfall_in_crossentropy_loss_for/</link>
      <description><![CDATA[在这篇简短的文章中，我发现了在具有大词汇量的模型中使用交叉熵损失的一个重大问题，这可能会导致微调的 LLM 的性能下降。我提供了理论见解和实证结果来支持这些发现。如果您正在处理大词汇量，这是必读内容：揭示大词汇量交叉熵损失的陷阱 | 作者 Oswaldo Ludwig | 2024 年 8 月 | Medium    提交人    /u/Gold-Plum-1436   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fnu24s/discovering_a_pitfall_in_crossentropy_loss_for/</guid>
      <pubDate>Mon, 23 Sep 2024 20:08:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我开发了一个可以用任何语言交谈的现场 AI 体育评论员</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fnry1x/p_i_built_a_live_ai_sports_commentator_that_can/</link>
      <description><![CDATA[它检测视频中的关键帧并无需提示即可说话。在后端，我使用 Whisper 进行 STT、使用 Gemini Flash 进行视觉以及使用 ElevenLabs 进行语音。 演示：https://www.veed.io/view/b19f452b-9589-4270-b11f-e041f2065713?panel=share GitHub：https://github.com/outspeed-ai/outspeed/tree/main/examples/sports_commentator    提交人    /u/jaakeyb1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fnry1x/p_i_built_a_live_ai_sports_commentator_that_can/</guid>
      <pubDate>Mon, 23 Sep 2024 18:41:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 又一个 transformer 可视化工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fnqwa0/p_yet_another_transformer_visualizer/</link>
      <description><![CDATA[我为自己制作了这个，因为我学习了仅解码器转换器架构以及 Andrej Karpathy 的 YT 视频（特别是&quot;让我们从头开始构建 GPT，用代码拼写出来&quot;）。希望它至少对一些人有帮助，但如果您发现任何不正确、令人厌烦或不直观的地方，请随时指出。 另外，仅供参考，该设计不适合移动设备。建议使用宽屏。 链接：https://learn-good.github.io/llm_viz/1_decoder_only_transformer.html    提交人    /u/arnokha   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fnqwa0/p_yet_another_transformer_visualizer/</guid>
      <pubDate>Mon, 23 Sep 2024 17:59:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 22 Sep 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>