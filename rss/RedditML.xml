<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 24 Nov 2024 12:31:34 GMT</lastBuildDate>
    <item>
      <title>[D] 离散扩散模型的当前发展水平如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyp1br/d_what_is_the_current_stateoftheart_for_discrete/</link>
      <description><![CDATA[大家好， 我目前正在为一个新的研究项目研究离散扩散模型。在这个项目中，我将离散扩散应用到一个尚未应用的领域。然而，我对扩散本身还很陌生，我对关于这个主题的论文数量感到不知所措。在我目前的实施中，我专注于一篇较旧的论文，因为它们很好地描述了他们的方法，我想先测试我的想法，看看它是否有一些优点，根据初步结果，它确实有优点。 目前，我正在考虑用这个领域的最新补充来更新我的方法，但正如我之前所说，我对数量有点不知所措。所以我的问题是，最近有哪些研究离散扩散的好论文，它们要么解释了基本概念，比如调查论文，要么介绍了不仅适用于特定领域的新先进方法，比如 NLP 或视觉？ 提前谢谢你的帮助。    提交人    /u/Derpirium   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyp1br/d_what_is_the_current_stateoftheart_for_discrete/</guid>
      <pubDate>Sun, 24 Nov 2024 11:35:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 24 Nov 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用无监督学习创建自定义音乐流派</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyb62h/p_creating_custom_music_genres_using_unsupervised/</link>
      <description><![CDATA[所以我有了这个随机想法，使用无监督学习来创建新的音乐流派/spotify 日程表。我的想法更倾向于创建自定义流派，但不一定像日程表那样超个性化。这只是现在的一个简单的想法，但很快就会发展成它。所以这个想法分为两个阶段：  获取具有音频特征/嵌入/mfccs/创建自己的特征的音乐数据，并使用无监督学习使用类似 knns 的东西创建这些特征的集群 取出集群中心的音频特征并将其提供给 llm 以生成该特定集群的自定义短语/名称。这可以是自定义的东西，比如游戏的角色名称/使用数据，比如特定歌曲集群在什么时间范围内播放更多，以创建更个性化的东西，比如日程表/任何东西。目前还没有对这部分进行过多考虑。  我找到了很多关于前一个阶段的论文/文章，但到目前为止找不到太多关于后者的内容。我正在阅读更多关于 spotify 如何制作他们的每日列表的内容，看看是否有任何有趣的东西。 我希望得到关于如何改进这一点的建议/关于与此相关的任何研究论文/文章的建议。 注意：我知道这个框架不是很好而且很混乱，但坦白说，我在凌晨 2 点喝醉了，突然对音乐产生了久违的热情，所以请帮帮我一个女孩 (⁠´⁠ ⁠.⁠ ⁠.̫⁠ ⁠.⁠ ⁠`⁠)    提交人    /u/Personal_Equal7989   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyb62h/p_creating_custom_music_genres_using_unsupervised/</guid>
      <pubDate>Sat, 23 Nov 2024 22:05:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要的建议：图像到 3D 扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy9dqd/d_recommendations_needed_imageto3d_diffusion/</link>
      <description><![CDATA[大家好，我正在为一个项目评估不同的开源图像到 3D 扩散模型，并且可以使用一些现实世界的见解。我一直在研究论文，但很想听听真正实施过这些论文的人的意见。 我的主要要求：  质量是重中之重 - 寻找干净、准确的重建 需要基于网格的输出（而不是点云或神经场），并且不是天文数字 推理时间并不重要 - 很乐意每代等待一分钟  我看过 Zero123、Wonder3D 和其他一些，但很好奇在实践中什么对人们有效。特别感兴趣：  哪些模型实际上可以在生产中维护 网格生成质量是否存在任何缺陷 您看到的实际推理时间 通常需要多少后处理  非常希望听到您的经验，特别是在实际项目中部署过这些经验的人的经验。谢谢！    提交人    /u/ESCNOptimist   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy9dqd/d_recommendations_needed_imageto3d_diffusion/</guid>
      <pubDate>Sat, 23 Nov 2024 20:44:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 迭代缩小：增强 GUI 位置定位的视觉提示框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy8tgs/r_iterative_narrowing_a_visual_prompting/</link>
      <description><![CDATA[本文介绍了一种用于 GUI 元素基础的迭代缩小方法，该方法通过多个细化步骤而不是一次性处理视觉和文本信息。关键见解是将元素识别分解为从粗到细的阶段，以反映人类视觉搜索界面的方式。 关键技术要点：* 两阶段架构：初始区域提议网络，然后进行重点细化* 视觉和文本编码器在交叉注意对齐之前并行处理特征* 通过多次传递逐步缩小范围可减少误报* 通过分层表示处理嵌套的 GUI 元素* 使用自然语言查询在 77K GUI 屏幕截图的数据集上进行训练 结果显示：* 与单次传递基线相比，接地准确度提高了 15%* 更好地处理模糊查询* 与穷举搜索相比减少了计算开销* 在复杂的嵌套界面上表现出色* 有效转移到看不见的 GUI 布局 我认为这种方法可以通过使元素识别更加健壮来显著改进可访问性工具和 GUI 自动化。迭代细化反映了人类的视觉搜索模式，这可以实现与界面更自然的交互。 我认为主要的限制是处理高度动态的界面，其中元素经常移动或更改。多通道特性还会引入一些延迟，需要针对实时应用程序进行优化。 TLDR：新的 GUI 接地方法使用多个细化通道来更准确地识别界面元素，通过模仿人类视觉搜索模式的方法将准确率提高了 15%。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy8tgs/r_iterative_narrowing_a_visual_prompting/</guid>
      <pubDate>Sat, 23 Nov 2024 20:19:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] ACL 滚动审查 2024 年 10 月</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy8ekt/d_acl_rolling_review_october_2024/</link>
      <description><![CDATA[ACL 2024 (ARR Oct) 评论讨论帖。    由   提交  /u/AffectionateTip521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy8ekt/d_acl_rolling_review_october_2024/</guid>
      <pubDate>Sat, 23 Nov 2024 20:01:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 专注于解决模型参数的优化算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy6jy6/d_optimization_algorithm_that_focuses_on_solving/</link>
      <description><![CDATA[我尝试在 Google 上搜索任何来源，但有人知道我可以在哪里开始寻找优化算法，该算法专注于通过求解特定参数（或多个参数）来优化模型参数，给定样本的输入和目标？或者这种优化算法的名称？例如，求解函数 y = ax^2 + bx + c 的模型参数 a、b、c，x 和 y 分别是输入和目标。当然，这个算法在 ml 上下文中有一个名称。 编辑： 我认为我问的有点模棱两可。与梯度下降相反，梯度下降专注于找到模型参数对提供的损失的导数，我上面指定的优化算法专注于许多参数并以某种方式找出（或求解这些参数的值）以大致匹配输出。就像你有 5x = 10 并求解 x 一样，所以算法计算出 x=2。对于更多数据样本和更多参数，您有 5x + c = 12 和 2x + c = 6，x 和 c 是模型参数，10 ad 4 是所需输出。该算法以某种方式计算出 x = 2 和 c = 2。这有点牵强，但即使我开始怀疑我的理智，也足以相信我所问的基本上是所有（如果不是大多数）机器学习优化算法所做的。    提交人    /u/Relevant-Twist520   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy6jy6/d_optimization_algorithm_that_focuses_on_solving/</guid>
      <pubDate>Sat, 23 Nov 2024 18:40:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是我在 Medium 上的第一篇博客，内容是：现代二进制 Hopfield 网络如何只是伪装的汉明距离自动完成器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy4qpv/d_this_is_my_first_blog_on_medium_and_they_are/</link>
      <description><![CDATA[    /u/StoneSteel_1   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy4qpv/d_this_is_my_first_blog_on_medium_and_they_are/</guid>
      <pubDate>Sat, 23 Nov 2024 17:22:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过负特征值解锁线性 RNN 中的状态跟踪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy0hbh/r_unlocking_statetracking_in_linear_rnns_through/</link>
      <description><![CDATA[摘要：线性循环神经网络 (LRNN)（例如 Mamba、RWKV、GLA、mLSTM 和 DeltaNet）已成为大型语言建模中 Transformers 的有效替代品，可提供序列长度的线性缩放并提高训练效率。然而，LRNN 难以执行状态跟踪，这可能会损害代码评估或跟踪国际象棋游戏等任务的性能。偶数奇偶校验是最简单的状态跟踪任务，非线性 RNN（例如 LSTM）可以有效处理，但当前的 LRNN 无法解决。最近，Sarrof 等人 (2024) 证明，像 Mamba 这样的 LRNN 无法解决奇偶校验的原因是将其对角状态转换矩阵的值范围限制为 [0,1]，而加入负值可以解决这个问题。我们将此结果扩展到非对角 LRNN，它们最近在 DeltaNet 等模型中表现出了良好的前景。我们证明，状态转移矩阵只有正特征值的有限精度 LRNN 无法解决奇偶校验问题，而模 3 计数则需要复特征值。值得注意的是，我们还证明，当 LRNN 的状态转移矩阵是恒等向量减去向量外积矩阵的乘积时，它们可以学习任何常规语言，每个矩阵的特征值都在 [-1,1] 范围内。我们的实证结果证实，将 Mamba 和 DeltaNet 等模型的特征值范围扩展为包括负值，不仅可以使它们解决奇偶校验问题，而且可以持续提高它们在状态跟踪任务上的性能。此外，使用扩展的特征值范围进行语言建模的预训练 LRNN 实现了可比的性能和稳定性，同时在代码和数学数据上显示出良好的前景。我们的工作增强了现代 LRNN 的表现力，扩大了它们的适用性，同时又不改变训练或推理的成本。 https://arxiv.org/abs/2411.12537    提交人    /u/iltruma   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy0hbh/r_unlocking_statetracking_in_linear_rnns_through/</guid>
      <pubDate>Sat, 23 Nov 2024 14:11:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] Llama 3.2 稀疏自动编码器的可解释性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gxzsbp/r_llama_32_interpretability_with_sparse/</link>
      <description><![CDATA[       由    /u/RandomHexCode  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gxzsbp/r_llama_32_interpretability_with_sparse/</guid>
      <pubDate>Sat, 23 Nov 2024 13:37:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 资源：精准知识编辑 (PKE) 可降低法学硕士 (LLM) 中的毒性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gxyhwb/r_resource_precision_knowledge_editing_pke_for/</link>
      <description><![CDATA[为那些对人工智能安全和改进 LLM 感兴趣的人分享一个项目和论文。该方法称为精准知识编辑 (PKE)，旨在通过识别和修改负责生成有毒内容的特定神经元或层来减少 LLM 中的有毒输出。 主要亮点： - 使用神经元权重跟踪和激活通路追踪等技术来定位“有毒热点”。 - 应用自定义损失函数来降低毒性，同时保持模型性能。 - 在 Llama2-7b 和 Llama-3-8B 等模型上进行测试，毒性管理有显著改善（例如，降低攻击成功率）。 论文可在此处获取：https://arxiv.org/pdf/2410.03772 带有演示 Jupyter Notebook 的 GitHub 存储库：https://github.com/HydroXai/Enhancing-Safety-in-Large-Language-Models 可能对研究人员、开发人员或任何探索提高 LLM 安全性的方法的人有用。听听其他人对这种方法的看法会很有趣。    提交人    /u/Reagane371   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gxyhwb/r_resource_precision_knowledge_editing_pke_for/</guid>
      <pubDate>Sat, 23 Nov 2024 12:25:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] [项目] JAX ML 框架；编写神经网络及更多内容；更短更快；您的想法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gxqag6/d_project_jax_ml_framework_write_neural_networks/</link>
      <description><![CDATA[为机器学习制作了一个 JAX 框架，因为我想让代码更快更短，所以我制作了 zephyr。我希望它对你们也有帮助，也想听听大家的反馈。 链接在评论中。 当前框架没有问题，这只是做事的另一种方式。 对我来说，NN 或 ML 算法只是纯数学函数，所以我希望这能反映在我的代码中。对于其他框架，它至少包含 2 个步骤：构造函数中的初始化和转发/调用主体中的计算。这乍一看似乎不错，但是当模型变得更大时，我必须在 2 个地方同步代码。- 如果我更改计算，我可能需要在某处更改超参数，或者如果我更改超参数，我可能需要更改计算 - 或者如果我必须重新阅读我的代码，我必须至少在 2 个地方阅读。我通常使用一个小窗口作为编辑器，因此在它们之间跳转可能会很麻烦（将它们并排放置是另一种解决方案）。 我遇到的另一件事是，如果我正在做的事情不是神经网络，例如，如果一个算法用递归调用更容易（但每次调用都有不同的可训练权重），那么这在其他框架中会很有挑战性。因此，虽然它们是通用的计算图框架，但有些计算很难做。 对我来说，计算就是传递数据并让它们进行转换，所以这种转换数据的“行为”应该是框架的重点。这就是我用 zephyr 所做的。数学函数是 python 函数，不需要在构造函数中初始化。你可以在需要的时候使用这些函数（网络或层等）。不需要构造函数，允许递归，让你专注于转换或操作。Zephyr 为你处理权重的创建和管理——与其他框架不同，它是明确的；你随身携带一个“params”树，这应该没有问题，因为这是计算的核心，不应该被隐藏起来。 简而言之，zephyr 很短但易读，旨在帮助人们开发关于 ML 的研究想法。README 有一些神经网络的示例。我希望你们喜欢它并尝试它。    提交人    /u/Pristine-Staff-5250   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gxqag6/d_project_jax_ml_framework_write_neural_networks/</guid>
      <pubDate>Sat, 23 Nov 2024 03:25:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 已接受的 NeurIPS 2024 论文声称作为第一项工作解决了一个新问题，但忽略了 5 项先前的工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gxooqv/d_accepted_neurips_2024_paper_claimed_to_be/</link>
      <description><![CDATA[在 NeurIPS 2024 上，我发现了一篇被接受的论文，其主要贡献是“现有的针对 X 的算法忽略了 Y。我们调整了针对 X 的算法 Z 来考虑 Y”。 在 OpenReview 上，我看到审稿人特别称赞了这项工作的新颖性，并认为 Y 是 X 领域被忽视的一个重要方面。 现在有趣的是：合著者和我在 2023 年在 Springer 的机器学习杂志上发表了一篇论文，也提出了一种针对 X 的算法来解释 Y。我们也不是第一个研究 X 和 Y 问题设置的人：我们论文的相关工作部分讨论了 4 篇论文，它们都提出了针对 X 的算法来解释 Y。其中一篇甚至来自 NeurIPS（2017），最早的一篇可以追溯到 2012 年（一篇 AAAI 论文）。 这篇 2024 年的作者NeurIPS 论文完全忽略了所有这些先前的文献，并认为他们是第一批，所有审稿人也都这么认为。 本周，我给这篇 NeurIPS 2024 论文的作者发了电子邮件，他们承认这些工作（我的 + 其他 4 篇）确实都是在同一个问题设置上工作，并提到他们不知道所有这些工作，并承认他们不能再声称对问题设置具有新颖性。 NeurIPS 允许在会议结束后更新照相排版论文，作者承诺将利用这个机会合并那些相关工作并修改他们的贡献声明，不再声称对 X 和 Y 的第一个解决方案具有新颖性。 一方面，我很高兴我们的工作将得到适当的认可。 另一方面，我对在审查后严格修改贡献声明的道德性表示怀疑。作者不再声称具有新颖性，但审稿人特别赞扬了这种新颖性，这让我不确定如果审稿人知道这篇论文最终将不再能够声称其在审稿版本中声称具有的新颖性，他们是否会建议接受。 此外，这让我对实验部分感到疑惑。几乎可以肯定，审稿人会要求与这 5 篇先前的作品进行比较作为基线。这篇论文没有与基线进行比较，这在审稿人看来是合理的，因为他假设问题设置是完全新颖的，并且不存在可以作为基线的先前方法。 在这里询问小组关于如何解决此类案件的任何想法：- 应该撤回这篇论文吗？- 应该通知领域主席/计划委员会吗？谁可能会或可能不会采取行动 - 这篇论文是否应该按照承诺的方式由作者更新，就这样？ - 还有别的吗？ 我删除了 X、Y 和 Z，以免公开羞辱作者，因为他们已经与我的电子邮件互动，我确信没有犯规行为，他们真的不知道这些作品。    提交人    /u/TaXxER   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gxooqv/d_accepted_neurips_2024_paper_claimed_to_be/</guid>
      <pubDate>Sat, 23 Nov 2024 01:58:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 熵引导的关键神经元修剪，实现高效的脉冲神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gx86i0/r_entropyguided_critical_neuron_pruning_for/</link>
      <description><![CDATA[本文介绍了一种基于神经科学临界原理的脉冲神经网络（SNN）的修剪方法。关键见解是使用神经元雪崩分析来识别对网络动态影响最大的神经元，类似于关键神经元在生物大脑中的功能。 关键技术要点：* 监测尖峰传播模式以识别关键神经元* 根据网络稳定性指标引入自适应修剪计划* 在保持 MNIST/CIFAR-10 准确性的同时实现 90% 的压缩* 适用于不同的 SNN 架构（前馈、CNN）* 使用稳定性措施防止修剪过程中的灾难性遗忘 主要结果：* 在准确性保持方面优于现有的修剪方法* 与未修剪的网络相比显示出更好的能源效率* 保持对 SNN 操作很重要的时间动态* 展示跨不同网络规模的可扩展性* 通过雪崩分析验证生物启发 我认为这种方法对于在资源受限的环境（如边缘设备）中部署 SNN 尤其重要。自适应修剪计划似乎特别有前景，因为它可以根据网络行为自动调整，而不需要手动调整。 我认为，对于非常大的网络，需要解决一些关于雪崩分析计算开销的未解决的问题。然而，该方法背后的生物学原理表明它可以很好地推广到其他架构和任务。 TLDR：基于神经科学临界原理的 SNN 新型修剪方法。使用神经元雪崩分析来识别重要神经元，并在保持准确性的同时实现 90% 的压缩。引入了根据网络稳定性进行调整的自适应修剪计划。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gx86i0/r_entropyguided_critical_neuron_pruning_for/</guid>
      <pubDate>Fri, 22 Nov 2024 13:45:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>