<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 10 Jan 2025 18:22:36 GMT</lastBuildDate>
    <item>
      <title>[D] 2.8M CFM 小型模型的结果出人意料地好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hya6hp/d_surprisingly_good_results_from_small_28m_cfm/</link>
      <description><![CDATA[      来自 2.8M CFM 模型的样本 我在旧 GPU 上用缩小版的 CelebA 数据集训练了 2.8M 条件流匹配模型。该模型直接在像素空间中运行，老实说，我并没有期待太多，但结果却出奇的好。CFM 模型之所以令人着迷，是因为训练它们几乎简单得离谱。没有对抗性损失，没有花哨的技巧。但不知何故，它却有效。    提交人    /u/kiockete   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hya6hp/d_surprisingly_good_results_from_small_28m_cfm/</guid>
      <pubDate>Fri, 10 Jan 2025 17:47:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] [P] Cohere For AI 启动新的法学硕士项目，重点关注多语言长语境理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hy3xn7/r_p_cohere_for_ai_launches_new_llm_cohort_focused/</link>
      <description><![CDATA[      来自 BIRDS（研究驱动研究初学者）小组 r/CohereAI，Cohere 开放科学社区，我们很高兴宣布我们的新 LLM 队列！🎉 🚀 这不仅仅是另一个学习计划；这是一项实践性的协作研究计划，旨在突破大型语言模型在多语言、长上下文设置中的可能性 💡 📚 我们将深入探讨两个令人兴奋的轨道： 🔬 轨道 1：多语言长上下文 - 使用先进技术增强处理 🤖 由领导：Mayank Bhaskar 和 Madhava Prasath 🎯 重点：探索尖端方法，如 RoPE（旋转位置嵌入）、NoPE（无位置编码）、LongROPE、SSM（状态空间模型）和混合 Transformer-SSM 模型，以克服多语言 NLP 中的长上下文挑战，增强可扩展性、效率和处理扩展序列的能力，同时解决传统 Transformer 的局限性。 🧠 挑战：开发一种新方法将 SSM 与 Transformers 相结合，优化长上下文多语言理解。在合成任务上表现出优于 RoPE、NoPE 和 LongRoPE 的卓越性能，强调对超出训练长度的序列的泛化和最小的计算开销。 https://preview.redd.it/x43aruufz5ce1.png?width=632&amp;format=png&amp;auto=webp&amp;s=9fc3e08f80f5a8713cdc4b39c7cb0284a2baf195 🔬 Track 2：评估多语言长上下文生成和推理 🤖 由领导：Guneet Singh Kohli 和 Shivalika Singh 🎯 重点：建立一个基准来评估多语言 LLM 处理涉及复杂推理的长上下文任务的能力。 🧠 挑战：对于长上下文任务，我们如何确保跨语言的准确、上下文相关的响应？评估现有 LLM 执行此类任务的能力，并提出数据创建管道以构建多语言长上下文基准。 https://preview.redd.it/i2r6z4ahz5ce1.png?width=680&amp;format=png&amp;auto=webp&amp;s=93dabba03df32da12fa577dc02516b9ad6048c3d 为什么加入？ 💼 获得实际研究经验：从头到尾参与真实世界的项目。 🤝 与专家合作：向经验丰富的研究人员学习并与他们一起学习。 🌐 塑造法学硕士的未来：为快速发展的领域的进步做出贡献。 📅 启动电话：本周五，1 月 10 日太平洋时间上午 10:00 加入我们，详细了解该群体并与轨道负责人见面！ https://preview.redd.it/1uyvx9fiz5ce1.png?width=680&amp;format=png&amp;auto=webp&amp;s=fc43363fb8cc277e7bcdf3725e9c66f5f92b9df7 2025 年将成为开创性研究的一年，让我们一起踏上这段激动人心的探索之旅！  https://i.redd.it/01luy73mz5ce1.gif    由   提交  /u/CATALUNA84   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hy3xn7/r_p_cohere_for_ai_launches_new_llm_cohort_focused/</guid>
      <pubDate>Fri, 10 Jan 2025 13:03:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我试图寻找大多数人类可以解决但推理模型却很难解决的常识性问题。以下是一个例子</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hy05iu/d_i_am_trying_to_find_common_sense_problems_that/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hy05iu/d_i_am_trying_to_find_common_sense_problems_that/</guid>
      <pubDate>Fri, 10 Jan 2025 08:46:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 撰写合适的 LLM 摘要的费用出奇地昂贵</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hxzij5/d_creating_proper_llm_summaries_is_surprisingly/</link>
      <description><![CDATA[        提交人    /u/Hot-Chapter48   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hxzij5/d_creating_proper_llm_summaries_is_surprisingly/</guid>
      <pubDate>Fri, 10 Jan 2025 07:57:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何通过类别训练 StyleGAN3？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hxn0w2/r_how_to_train_stylegan3_with_classes/</link>
      <description><![CDATA[我正在阅读 stylegan3 github 上 train.py 的文档，它提到通过设置 cond=True 并提供包含类结构的 dataset.json，然后您就可以使用类进行图像生成。 在我开始训练之前，这一切似乎都很好，但是我遇到了以下错误： 张量 a（1024）的大小必须与非单例维度 1 上的张量 b（512）的大小匹配张量 a（1024）的大小必须与非单例维度 1 上的张量 b（512）的大小匹配我相信发生这种情况是因为我正在使用预训练模型进行微调并避免从头开始训练，并且预训练模型可能不包含类。如果我的假设是正确的，那么有谁知道我可以在哪里找到在 512x512 分辨率下使用类训练的预训练模型？我正在阅读 stylegan3 github 上 train.py 的文档，它提到通过设置 cond=True 并提供包含类结构的 dataset.json，然后您可以使用类进行图像生成。这一切似乎都很好，直到我开始训练，但我遇到了以下错误：张量 a 的大小（1024）必须与非单例维度 1 上的张量 b 的大小（512）匹配张量 a 的大小（1024）必须与非单例维度 1 上的张量 b 的大小（512）匹配我相信发生这种情况是因为我正在使用预训练模型进行微调并避免从头开始训练，并且预训练模型可能不包含类。如果我的假设是正确的，有人知道我可以在哪里找到使用 512x512 分辨率进行类训练的预训练模型吗？     提交人    /u/redditer2363   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hxn0w2/r_how_to_train_stylegan3_with_classes/</guid>
      <pubDate>Thu, 09 Jan 2025 20:55:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 代理实验室：使用 LLM 代理作为研究助手 - 能够完成整个研究过程的自主 LLM 框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hxleaa/r_agent_laboratory_using_llm_agents_as_research/</link>
      <description><![CDATA[      论文：https://arxiv.org/pdf/2501.04227 Github：https://github.com/SamuelSchmidgall/AgentLaboratory?tab=readme-ov-file 博客：https://agentlaboratory.github.io/ 摘要：  从历史上看，科学发现是一个漫长而昂贵的过程，从最初的概念到最终的结果需要大量的时间和资源。为了加速科学发现，降低研究成本并提高研究质量，我们引入了 Agent Laboratory，这是一个基于 LLM 的自主框架，能够完成整个研究过程。该框架接受人类提供的研究想法，经过文献综述、实验和撰写报告三个阶段，产生全面的研究成果，包括代码库和研究报告，同时允许用户在每个阶段提供反馈和指导。我们在 Agent Laboratory 中部署了各种最先进的 LLM，并邀请多位研究人员通过参与调查来评估其质量，提供人类反馈来指导研究过程，然后评估最终的论文。我们发现：(1) 由 o1-preview 驱动的 Agent Laboratory 产生了最好的研究成果；(2) 与现有方法相比，生成的机器学习代码能够达到最先进的性能；(3) 人类参与并在每个阶段提供反馈，显著提高了研究的整体质量；(4) Agent Laboratory 显著降低了研究费用，与以前的自主研究方法相比，减少了 84%。我们希望 Agent Laboratory 能让研究人员将更多的精力投入到创造性思维上，而不是低级的编码和写作上，最终加速科学发现。  https://preview.redd.it/oop8omfvt0ce1.jpg?width=1591&amp;format=pjpg&amp;auto=webp&amp;s=e588146997010797bbe75ea9d575bd65ce0d8fc6    提交人    /u/Singularian2501   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hxleaa/r_agent_laboratory_using_llm_agents_as_research/</guid>
      <pubDate>Thu, 09 Jan 2025 19:46:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] rStar-Math：小型法学硕士可以通过自我进化的深度思维掌握数学推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hxk2ab/r_rstarmath_small_llms_can_master_math_reasoning/</link>
      <description><![CDATA[  由    /u/jsonathan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hxk2ab/r_rstarmath_small_llms_can_master_math_reasoning/</guid>
      <pubDate>Thu, 09 Jan 2025 18:51:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过负特征值解锁线性 RNN 中的状态跟踪研讨会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hxgovs/r_seminar_on_unlocking_statetracking_in_linear/</link>
      <description><![CDATA[很棒的研讨会，也深入探讨了论文的证明    提交人    /u/iltruma   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hxgovs/r_seminar_on_unlocking_statetracking_in_linear/</guid>
      <pubDate>Thu, 09 Jan 2025 16:29:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025 中值得质疑的高分论文（关于 Diffusion LM）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hxbvgf/d_questionable_high_score_paper_in_iclr_2025_on/</link>
      <description><![CDATA[ICLR 2025 论文《超越自回归：用于复杂推理和规划的离散扩散》（sub 4441）中提出的新扩散 LLM 方法与 2021 年提出的 D3PM 没有什么不同。虽然他们以新名称将该架构重新命名为“MDM”，但与 D3PM 的唯一区别无非是增加了一种对高损失数据略加权的常用技术。 这篇论文在 ICLR 2025 上得分为 8,6,6,5，远远超过了录取门槛。审查系统似乎出了问题。你怎么看？ p.s.我认为这项工作的贡献是将现有的离散扩散模型应用于双向推理任务（例如数独），并报告扩散模型在这些任务中的表现优于自回归 LM（在某些方面这微不足道）。然而，这篇论文夸大了它的贡献，好像它提出了一种新的扩散方法（MDM），而这在审查过程中没有得到充分的验证。    提交人    /u/Educational_Roll4133   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hxbvgf/d_questionable_high_score_paper_in_iclr_2025_on/</guid>
      <pubDate>Thu, 09 Jan 2025 12:38:29 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我使用 pydantic 构建了一个从可重复使用的蓝图构建张量的库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hxbldq/p_i_built_a_library_that_builds_tensors_from/</link>
      <description><![CDATA[Cyantic 允许您在 pydantic 构建过程中从简单的蓝图构建复杂的对象，并内置类型安全和验证。  Cyantic Github Repo  定义带有验证的自定义、类型安全的蓝图（因为它们是 pydantic 模型）。 使用 @value:x.y.z 引用其他值。 使用 @import:x.y.z 导入对象。 使用 @env:VAR 从环境变量加载数据。 定义自定义 @hook 处理程序（参见测试）  示例 例如，向 pydantic 模型添加 data: Tensor 字段，然后调用 thing.validate_model({..., &quot;mean&quot;: 0.0, &quot;std&quot;: 0.1, ...}) 并接收构建的张量。 from cyantic import Blueprint, blueprint, CyanticModel, hook ... # 1. 创建并注册一些有用的参数化 #（或者很快从 PyPi 安装，即`rye add cyantic-torch`） @blueprint(Tensor) class NormalTensor(Blueprint[Tensor]): mean: float std: float size: tuple[int, ...] def build(self) -&gt; Tensor：return torch.normal（self.mean，self.std，size = self.size）#2. 使用`CyanticModel`基类编写 pydantic 模型 class MyModel（CyanticModel）：normal_tensor：Tensor uniform_tensor：Tensor#3. 从指定参数化的 YAML 文件进行验证some_yaml =“”common：size：[3, 5] normal_tensor：mean：0.0 std：0.1 size：@value：common.size“”#4. 接收构建的对象。my_model = MyModel.model_validate（yaml.safe_load（some_yaml））assert isinstance（my_model.normal_tensor，Tensor） 我为什么要这样做 我做理论神经科学研究，所以我必须实例化很多张量。我想要一种从 YAML（我如何指定模型）中执行此操作的方法，因此我构建了一种中间件，它使用中间 pydantic 模型作为在 pydantic 的构建过程中构建完整对象的蓝图。现在我可以传入参数（例如平均值和标准差），并在 pydantic 模型中获得完全构建的张量。 这现在是一个库，Cyantic - 以蓝晒摄影命名（即“蓝图”）。    提交人    /u/General_Example   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hxbldq/p_i_built_a_library_that_builds_tensors_from/</guid>
      <pubDate>Thu, 09 Jan 2025 12:21:18 GMT</pubDate>
    </item>
    <item>
      <title>[R] ObliqueTree: 高级决策树实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hxa6u6/r_obliquetree_advanced_decision_tree/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hxa6u6/r_obliquetree_advanced_decision_tree/</guid>
      <pubDate>Thu, 09 Jan 2025 10:47:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么攻读法学硕士学位这么糟糕？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hx6q8r/d_why_does_training_llms_suck_so_much/</link>
      <description><![CDATA[我从事硬件加速工作，一直在尝试将我的注意力转移到 LLM/GenAI 加速上，但训练 LLM 实在是太糟糕了……即使是 100M 参数的训练，在 4 A6000 Adas 上也需要很长时间，虽然我没有花时间看这些，但当我意识到 LR 太高或其他一些小问题阻碍了收敛或一般因果语言理解时，不得不重新训练真是太令人沮丧了…… 我知道你做的越多，你就会做得越好，但作为一个 GRA，我有一个想实现的想法，我真的觉得训练即使是一个小型 LM 的开销也远远不值得你投入的时间和精力 这很糟糕，因为截止日期总是会到来，一旦你完成了预训练，你仍然需要进行微调，并可能进行某种异常值感知量化，甚至训练 LoRA 适配器以获得更高的准确性 我真的希望永远不要再进行预训练，但是需要一个符合您的特定大小限制的模型以适合（例如）您的 NPU 的暂存器 RAM，这意味着我总是陷入预训练 希望在未来，我可以让本科生为我进行预训练，但是就目前而言，有什么技巧可以使预训练 LLM 不那么像奴隶工作吗？谢谢！    提交人    /u/nini2352   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hx6q8r/d_why_does_training_llms_suck_so_much/</guid>
      <pubDate>Thu, 09 Jan 2025 06:28:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 第一篇博士论文决定：IJCAI 还是 ICML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hx4o3z/d_r_first_phd_paper_decision_ijcai_or_icml/</link>
      <description><![CDATA[我是一名二年级博士生。在收到低于接受门槛的评分后，我从 ICLR 撤回了我的第一篇论文，此后做了一些改进。现在，我需要决定提交哪个会议。这两个会议的接受率相同，我的工作领域与这两个会议都很吻合。我不确定哪一个更有机会成功。    提交人    /u/learnergirl_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hx4o3z/d_r_first_phd_paper_decision_ijcai_or_icml/</guid>
      <pubDate>Thu, 09 Jan 2025 04:24:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 05 Jan 2025 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>