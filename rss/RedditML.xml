<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 17 Feb 2024 18:14:55 GMT</lastBuildDate>
    <item>
      <title>[D] 法学硕士如何玩电子游戏的现状</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at89qb/d_state_of_how_llms_play_video_games/</link>
      <description><![CDATA[      哟！分享我的 YT 频道的最新视频，其中讨论了法学硕士玩《我的世界》等开放世界游戏的最新进展。视频进入了几篇研究论文（Voyager、DESP 等）及其提示框架，并将其与 SOTA RL 算法（如 Dreamer）进行了比较！   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at89qb/d_state_of_how_llms_play_video_games/</guid>
      <pubDate>Sat, 17 Feb 2024 18:12:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 需要研究合作伙伴进行人工智能研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at82ym/r_research_partners_for_research_on_ai_needed/</link>
      <description><![CDATA[几个计划： 人工智能和虚假新闻检测 人工智能促进气候变化和健康 &gt;   由   提交 /u/sladebrigade   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at82ym/r_research_partners_for_research_on_ai_needed/</guid>
      <pubDate>Sat, 17 Feb 2024 18:04:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] GRIT（生成表征指令调整）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at7lzn/r_grit_generative_representational_instruction/</link>
      <description><![CDATA[GritLM  &lt; li&gt;设定了新的最先进基准：在大规模文本嵌入基准 (MTEB) 上优于同等大小的所有其他模型，并且在生成任务方面表现出色。 规模很重要：更大的模型（例如 GritLM） 8x7B）优于开放生成语言模型，同时在嵌入任务方面仍然排名靠前。 在不牺牲通用性的情况下实现性能：GritLM 在生成数据或嵌入数据上的训练同样出色，结合了两个领域的优点。 效率升级：通过避免单独的检索和生成模型，将长文档的检索增强生成 (RAG) 速度提高 60% 以上。  文章链接    由   提交 /u/AloneSYD   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at7lzn/r_grit_generative_representational_instruction/</guid>
      <pubDate>Sat, 17 Feb 2024 17:44:21 GMT</pubDate>
    </item>
    <item>
      <title>V-JEPA：Yann LeCun 先进机器智能愿景的下一步 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at7fib/vjepa_the_next_step_toward_yann_lecuns_vision_of/</link>
      <description><![CDATA[      博客：https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model- video-joint-embedding-predictive-architecture/ 论文：https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning-visual-representations-from-video/ ​ 摘要： ​ 本文探讨了特征预测作为视频无监督学习的独立目标，并引入了 V-JEPA，这是一组仅使用特征预测目标训练的视觉模型集合，不使用预训练的图像编码器、文本、负例、重建或其他监督源。这些模型使用从公共数据集中收集的 200 万个视频进行训练，并针对下游图像和视频任务进行评估。我们的结果表明，通过预测视频特征进行学习可以产生多功能的视觉表示，在基于运动和外观的任务上表现良好，而无需调整模型的参数；例如，使用冷冻的骨干。我们最大的模型，仅在视频上训练的 ViT-H/16，在 Kinetics-400 上获得 81.9%，在 Something-Something-v2 上获得 72.2%，在 ImageNet1K 上获得 77.9%。 ​&lt; /p&gt; ​ https://preview.redd.it/uvo0dpwvl6jc1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=3f308732b80a72be3d5ad8ef9542462cf4611b64 V-JEPA 训练视觉编码器通过预测学习的潜在空间中的屏蔽时空区域。   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at7fib/vjepa_the_next_step_toward_yann_lecuns_vision_of/</guid>
      <pubDate>Sat, 17 Feb 2024 17:36:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人可以分享他们在 AWS NeuronX (Inferentia2) 上运行推理的经验吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at4zjp/d_can_anyone_share_their_experiences_running/</link>
      <description><![CDATA[ 由   提交/u/coinclink  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at4zjp/d_can_anyone_share_their_experiences_running/</guid>
      <pubDate>Sat, 17 Feb 2024 15:51:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] SMOTE 用于回归</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at4do4/p_smote_for_regression/</link>
      <description><![CDATA[我的数据集有 600 万个条目，3 个输入和 1 个输出。我想对高速进行过采样，是否可以使用计算强度较小且更简单的 SMOTER 版本？   由   提交/u/Competitive_Flow_458   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at4do4/p_smote_for_regression/</guid>
      <pubDate>Sat, 17 Feb 2024 15:23:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] 速度预测的损失函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at30bk/p_loss_function_for_velocity_prediction/</link>
      <description><![CDATA[我想要一个用于 ANN 的损失函数来预测线速度值。它将预测的速度值在 0.1m/s 和 1x10^-6m/s 之间。我应该使用什么损失函数？我认为 sMAPE 会很好，但我也研究了一些对数误差指标。 ANN 还需要预测正速度和负速度，这排除了一些基于对数的基本损失函数。   由   提交/u/Competitive_Flow_458   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at30bk/p_loss_function_for_velocity_prediction/</guid>
      <pubDate>Sat, 17 Feb 2024 14:18:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 奖项公布：“预测区间竞赛一：出生体重”Kaggle 竞赛共有 7 本书获奖。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at2oke/d_prizes_announcement_there_are_7_books_to_be_won/</link>
      <description><![CDATA[奖品公布：“预测区间竞赛一：出生体重”Kaggle 竞赛共有 7 本书获奖。感谢 Packt Publishing 的慷慨资助，七本精彩的书《Python 中应用保形预测实用指南》将被授予 本次比赛（截止日期为 3 月 22 日）：  第一名和第二名私人 LB 获奖者：向每名个人提供平装本 第三名和第四名私人 LB 获奖者：向每名个人提供电子副本（获奖者于 3 月 23 日公布）  还有：  最佳笔记本：平装本 最佳笔记本第二名：电子版 最佳写作：电子版（获奖者将在一周内公布）或稍后在比赛结束后留出时间撰写比赛或发布作品）  https://www.kaggle.com/competitions/prediction-interval-competition-i-birth-weight/discussion ​   由   提交 /u/predict_addict   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at2oke/d_prizes_announcement_there_are_7_books_to_be_won/</guid>
      <pubDate>Sat, 17 Feb 2024 14:03:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要建议：使用 NER 或其他模型自动处理德国发票</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aszujx/d_advice_needed_automated_processing_of_german/</link>
      <description><![CDATA[您好， 我在一家德国保险公司工作，希望从以 PDF 形式收到的客户发票中自动提取数据。我们对发票号码、日期、名称、地址和带有价格的行项目等详细信息特别感兴趣，旨在将此信息输出为 JSON 以便进一步处理。这些实体可能出现多次或根本不出现。 我们尝试了多种方法但没有成功：  GPT-4 和各种模型 ：没有始终如一地提供结构化 JSON 输出。 发票的 Impira/LayoutLM：难以准确地区分开单人和收件人。  给出我们需要在本地处理这些数据（出于隐私和安全原因），并且考虑到这些发票是德语的，我们正在探索所有选项，包括命名实体识别（NER），尽管它不是法学硕士进步的最新进展。&lt; /p&gt;  有人对适合处理德国发票的预训练模型或方法有建议吗？ NER 可能是一个可行的选择，或者我们应该考虑其他技术或模型吗？  感谢这个社区可以提供的任何建议或见解！ &lt;!-- SC_ON - -&gt;  由   提交 /u/4AVcnE   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aszujx/d_advice_needed_automated_processing_of_german/</guid>
      <pubDate>Sat, 17 Feb 2024 11:26:51 GMT</pubDate>
    </item>
    <item>
      <title>[P]关于使用 Pytorch 进行语义分割的基于 Swin-Transformer 的 U-net 架构的简短文章。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1asxju4/pa_short_writeup_on_swintransformerbased_unet/</link>
      <description><![CDATA[中型文章：https://medium.com/@ashishbisht0307/swin-transformer-based-unet-architecture-for-semantic-segmentation-with-pytorch-code-91e779334e8e 代码：https://github.com/ashish- s-bisht/SwinUnetArchitecturePytorch/blob/main/SwinUnetArchitecturePytorch.ipynb   由   提交 /u/GoofyRoach   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1asxju4/pa_short_writeup_on_swintransformerbased_unet/</guid>
      <pubDate>Sat, 17 Feb 2024 08:52:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] MLSys 2024 通知原定于今天（2 月 16 日星期五）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1assz1b/d_mlsys_2024_notification_was_supposed_to_be/</link>
      <description><![CDATA[有人向 MLSys 2024 提交论文并得到最终裁决吗？本来应该是星期五下午 5 点（世界标准时间）。    由   提交/u/avx64  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1assz1b/d_mlsys_2024_notification_was_supposed_to_be/</guid>
      <pubDate>Sat, 17 Feb 2024 04:12:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPU 服务器替代方案：如何避免偶尔使用的高成本？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1asnu8l/d_gpu_server_alternatives_how_to_avoid_high_costs/</link>
      <description><![CDATA[租用具有 GPU 支持的专用服务器可能会很昂贵，尤其是当模型具有数十亿个参数时。根据我的计算，使用 AWS 等工具，每年的成本约为 2 万美元 - 假设服务器每小时 2 至 3 美元。我正在训练一些模型，我想在网络应用程序中使用它们。如果网络应用程序成功，那么这 2 万美元就花得很值，但如果不成功，那么就需要付出很多代价。理想的解决方案是让我只需支付使用费。  以下是我考虑过的一些选择。  租用专用服务器（AWS、Azure、Google 等...）：成本很高，例如 2 美元或 3 美元每小时满足我的需要。 抱脸：每小时的费率仍然以美元为单位，就像其他大型云提供商一样。 使用 google collab 笔记本并运行单元作为服务器：我必须保持笔记本打开以保持服务器运行，否则网络应用程序将无法工作 复制：有使用定价，但我相信他们不会处理请求批次。模型通常具有批量维度，并且可以处理数百或数千个同时预测，只要这些请求按批次排队而不是在进入时执行。但我相信复制不会这样做。它也不允许我缓存神经网络的状态，就像在使用因果变换器模型的下一个令牌预测中一样，您可以在每一层缓存先前令牌的先前状态并重用它们来预测下一个令牌，从而降低复杂性到 O(window_size**2) 到 O(window_size)。  我认为我需要的是带有 GPU 的专用服务器，我可以根据需要进行自定义，但只能运行当它收到请求时。有谁知道这个问题有一个好的解决方案吗？ ​   由   提交/u/lildaemon  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1asnu8l/d_gpu_server_alternatives_how_to_avoid_high_costs/</guid>
      <pubDate>Sat, 17 Feb 2024 00:04:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 中的输入令牌大小与上下文窗口</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1asi6rh/d_input_token_size_vs_context_window_in_llms/</link>
      <description><![CDATA[TL;DR - 输入令牌大小与上下文窗口大小有何关系？ ChatGPT（128K 上下文 - 4096 个输入令牌限制）Gemini 1.5 怎么样（1M 上下文窗口 - ??? 输入令牌限制） 自从 Gemini 1.5 推出以来，我一直在阅读更多相关内容以了解更多信息如果它可以取代我们正在使用的 ChatGPT 3.5。我们的用例有很多输入文本，我们将其分解为较小的文本并将其传递给 ChatGPT，因为输入令牌大小为 4096，我开始认为既然 Gemini 1.5 有 1M 上下文窗口，也许这意味着我们可以一次传递我们所有的文本。刚刚意识到ChatGPT3.5也有128K上下文窗口，但输入令牌限制是4096个令牌？  那么，输入令牌限制是否与上下文窗口成正比？或者它只是一个 API 约束，与模型无关？   由   提交/u/daxow  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1asi6rh/d_input_token_size_vs_context_window_in_llms/</guid>
      <pubDate>Fri, 16 Feb 2024 20:07:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 曼巴模型演练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aseqq8/d_mamba_model_walkthrough/</link>
      <description><![CDATA[我真的很喜欢曼巴论文，但它对我来说这不是一本特别容易读的书，因为我之前几乎没有接触过很多先决条件材料（状态空间建模、并行扫描等）。 我写了一个解释器（链接 此处），我很好奇人们是否有任何反馈或认为它有帮助/有趣。 这在一定程度上是为了巩固我自己的理解，但也是我希望对社区有好处的事情，因为关于 Mamba 架构的教程并不多。 &lt; !-- SC_ON --&gt;  由   提交 /u/_james_chen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aseqq8/d_mamba_model_walkthrough/</guid>
      <pubDate>Fri, 16 Feb 2024 17:46:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>