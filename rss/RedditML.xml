<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Tue, 23 Jul 2024 03:19:38 GMT</lastBuildDate>
    <item>
      <title>投影头之后的自监督学习权重初始化 [D][R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e9ntgm/selfsupervised_learning_weights_initialization/</link>
      <description><![CDATA[对于大多数自监督学习算法：SimCLR、MoCo、BYOL、SimSiam、SwAV 等，在基础编码器（大多数情况下是原始 ResNet-50 CNN）之后通常有一个投影头。这种投影的一个示例（取自 SwAV）如下： projection_head = nn.Sequential( nn.Linear(2048, 512), nn.BatchNorm1d(512), nn.ReLU(inplace=True), nn.Linear(512, 128), )  此投影头的输出是 L2 归一化的： x = project_head(x) x = nn. functional.normalize(x, dim = 1, p = 2)  我试图将投影头后的层初始化为： wts = nn.Parameter(data = torch.empty(40 * 40, 128), require_grad = True) # 投影头输出范围为 [-1, 1] 的权重，因此将 SOM 权重初始化为该范围 - wts.data.uniform_(-1.0, 1.0)  由于投影头的输出是 L2 归一化的，我假设输入范围为 &quot;wts&quot; ∈ [-1, 1]，因此使用上面的统一初始化。 这是正确的方法还是我遗漏了什么？    提交人    /u/grid_world   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e9ntgm/selfsupervised_learning_weights_initialization/</guid>
      <pubDate>Mon, 22 Jul 2024 20:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在商业应用中使用 Llama 有哪些问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e9lfu3/d_what_are_the_problems_with_using_llama_in_a/</link>
      <description><![CDATA[我搜索了一下，发现一个帖子说 Llama 不应该用于商业用途，但我不知道为什么。我查看了 Llama 的 Meta 许可证，上面说在每月用户数达到 7 亿之前不需要许可证，而我设想的应用程序绝对不可能达到这个数字。 我忽略了什么？如果我在用户数少得多的商业应用程序中使用 Llama（可能最高每月只有 100 万），会出现问题吗？    提交人    /u/technicallynotlying   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e9lfu3/d_what_are_the_problems_with_using_llama_in_a/</guid>
      <pubDate>Mon, 22 Jul 2024 18:24:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 监督微调（SFT）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e9f3pk/d_supervised_finetuning_sft/</link>
      <description><![CDATA[目前使用的每个聊天机器人，从 ChatGPT 到基于开源大型语言模型 (LLM) 构建的自定义聊天机器人，都经过了指令调整。LLM 与任何语言模型一样，只是下一个标记预测器。要让原始 LLM 像聊天机器人一样与用户交互，必须使用数以万计的用户与助手对话示例对其进行微调。这个过程称为监督微调，是生产 LLM 应用程序的基本构建块。 公开可用的 LLM 仍然是通用的，不适合直接用于大多数商业应用程序，因为它们需要不断微调才能产生高质量的结果。 现代监督微调解决方案涉及一种称为低秩适配器的东西。低秩适配器是相对较小的矩阵（数百万个元素，而不是数十亿个元素），它们与 LLM 的每一层并列，充当助手。它的工作是将 LLM 层的输入和输出转换为适当的域，而不会增加生产延迟。 在微调过程中，低秩适配器会根据黄金标准示例进行训练，以教会 LLM 如何响应。如果数据集质量高且多样化，那么经过微调的 LLM 输出的质量就会显著提高，只需 100 个示例，而不是数万个示例。传统上，这些示例将由专家手工制作，但编写它们既费时又费力。在 Plum Defense，我们会自动生成与人工编写的示例相当的示例。这样可以进行持续微调，从而不断提高 LLM 响应的质量。 通过将训练有素的低秩适配器与编写良好的系统提示相结合，机器学习从业者可以生成一个强大的应用程序，该应用程序可以很好地符合所需的输出，并且速度足够快，可以用于生产。 好的系统提示传达了意图，但足够简洁，为检索增强 (RAG) 系统留出空间，以便将相关事实注入应用程序。 系统提示的长度也会直接影响应用程序延迟。 系统提示越小，应用程序的平均响应时间越快。 借助软提示等高级技术，可以显著减小系统提示的大小，从而加快响​​应时间。 如果您想了解有关生产应用程序的持续微调和软提示系统的更多信息，请给我留言。    提交人    /u/juliannorton   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e9f3pk/d_supervised_finetuning_sft/</guid>
      <pubDate>Mon, 22 Jul 2024 14:03:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] TTSDS – 对最近的 TTS 系统进行基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e9ec0m/p_ttsds_benchmarking_recent_tts_systems/</link>
      <description><![CDATA[TL;DR - 我为 TTS 做了一个基准测试，您可以在此处查看结果：https://huggingface.co/spaces/ttsds/benchmark 目前有很多 LLM 基准测试，虽然它们并不完美，但它们至少概述了哪些系统在哪些任务上表现良好。文本转语音系统没有类似的东西，所以我决定用我的最新项目来解决这个问题。 我们的想法是找到与不同因素相对应的语音表示：例如韵律、可理解性、说话者等 - 然后根据 Wasserstein 距离计算合成语音与真实数据和噪声数据的分数。我在论文 (https://www.arxiv.org/abs/2407.12707) 中对此进行了更详细的介绍，但我也很乐意在这里回答任何问题。 然后，我将这些因素汇总为一个与合成语音整体质量相对应的分数 - 该分数与从 2008 年的论文一直到 huggingface 最近发布的 TTS Arena 的人工评估分数有很好的相关性。 任何人都可以此处提交自己的合成语音。并且我还将在未来几周内添加更多模型。离线运行基准测试的代码位于此处。    提交人    /u/cdminix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e9ec0m/p_ttsds_benchmarking_recent_tts_systems/</guid>
      <pubDate>Mon, 22 Jul 2024 13:29:37 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 我什么时候可以将研究模型用于商业目的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e9c8ri/discussion_when_i_can_use_research_models_for/</link>
      <description><![CDATA[我正在阅读一篇研究论文，其中他们将扩散模型用于特定目的。我有一个想法，如果正确执行，它可以用于商业目的，具有巨大的市场机会。所以我想知道，如果有研究论文代码、模型架构和训练权重，我有三个问题 1. 我可以使用此模型并将其权重生产化并用于商业吗？ 2. 如果不行，如果在架构上做一些必要的更改或训练它新的数据集或两者兼而有之，用于商业目的当我遇到法律或版权许可问题时    提交人    /u/Frosty-Equipment-692   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e9c8ri/discussion_when_i_can_use_research_models_for/</guid>
      <pubDate>Mon, 22 Jul 2024 11:47:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] PINN（物理信息神经网络）的方程要求</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e9belt/r_equation_requirements_for_pinns_physicsinforemd/</link>
      <description><![CDATA[我对损失项中的微分方程有疑问。通常，在 PINN 中，我们在损失函数中使用预测输出相对于输入变量的微分方程。例如，如果 u 是预测输出，x、y、m 是输入，则损失函数包括 du/d(x,y,m) 等项。 但是，如果我们只有输入变量相对于其他输入或输出变量的微分方程会怎样？例如：  dx/dt=f(x,y,u) dy/dt=g(x,u)  这里，x 和 y 的导数相对于时间 t。  并且没有 du/d(x,y,m) 方程 在这种情况下是否可以使用 PINN 方法，其中损失函数仅使用 dx/dt​ 和 dy/dt 构建？    提交人    /u/its_a_targaryen   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e9belt/r_equation_requirements_for_pinns_physicsinforemd/</guid>
      <pubDate>Mon, 22 Jul 2024 11:00:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] FLUTE - 一种用于量化 LLM 推理的新型 CUDA 内核，与 vLLM 相比，延迟降低了 2.6 倍。它将 QLoRA 扩展为可学习的尺度，每个参数量化为 4 位和 3 位。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e99i92/p_flute_a_new_cuda_kernel_for_quantized_llm/</link>
      <description><![CDATA[ 大型语言模型 (LLM) 的部署通常受内存带宽的限制，其中主要瓶颈是将模型参数从 GPU 的全局内存传输到其寄存器的成本。当与融合反量化和矩阵乘法运算的自定义内核结合使用时，仅权重量化可以通过减少内存移动量来实现更快的推理。然而，为权重量化的 LLM 开发高性能内核带来了巨大的挑战，尤其是当权重被压缩为非均匀可分的位宽（例如 3 位）且使用非均匀查找表 (LUT) 量化时。本文介绍了 FLUTE，这是一种用于 LUT 量化 LLM 的灵活查找表引擎，它使用量化权重矩阵的离线重构来最大限度地减少与解包相关的位操作，并使用查找表的矢量化和复制来缓解共享内存带宽限制。当批量大小 &lt; 32 和量化组大小为 128（LLM 推理中的典型值），FLUTE 内核的速度可以比现有的 GEMM 内核快 2-4 倍。作为 FLUTE 的应用，我们探索了基于查找表的 NormalFloat 量化的简单扩展，并将其应用于将 LLaMA3 量化到各种配置，获得了与强基线相比具有竞争力的量化性能，同时获得了 1.5 到 2 倍的端到端吞吐量提升。  Arxiv：https://arxiv.org/abs/2407.10960    提交人    /u/radi-cho   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e99i92/p_flute_a_new_cuda_kernel_for_quantized_llm/</guid>
      <pubDate>Mon, 22 Jul 2024 08:56:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 神经网络经过训练，能够使用少 50 倍的数据准确预测分子的最佳几何形状</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e98s8l/r_neural_networks_have_been_trained_to_accurately/</link>
      <description><![CDATA[计算化学的一个重要任务是找到实现局部能量最小值的分子几何形状，因为这些是分子发生化学反应的最可能配置。尽管最近在分子构象能量预测的神经网络方面取得了进展，但此类模型容易因分布偏移而出错，从而导致能量最小化不准确。通过提供优化轨迹作为额外的训练数据，可以提高神经网络能量最小化的质量。不过，获得完整的优化轨迹需要大量额外的计算。 一个研究小组开发了一个名为“逐步优化学习框架”（GOLF）的新框架，该框架由一个高效的数据收集方案和一个外部优化器组成。作者证明，使用明显更少的额外数据，用 GOLF 训练的神经网络在各种类药物分子的基准测试中的表现与 Oracle 相当。  该~论文~发表于 ICLR 2024 会议论文集    由    /u/AIRI_Institute  提交  [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e98s8l/r_neural_networks_have_been_trained_to_accurately/</guid>
      <pubDate>Mon, 22 Jul 2024 08:04:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 聚合标记概率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e96lo5/d_aggregating_token_probabilities/</link>
      <description><![CDATA[我可以使用哪些好的聚合技术来使用标记概率（这可以是 softmax 概率或对数概率）为生成的序列评分？ 例如，在答案中找到关键实体并尝试找出它的标记概率，并查看这些关键实体的中位标记概率是多少。    提交人    /u/archiesteviegordie   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e96lo5/d_aggregating_token_probabilities/</guid>
      <pubDate>Mon, 22 Jul 2024 05:36:55 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 文档图像修复</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e96f4i/discussion_document_image_restoration/</link>
      <description><![CDATA[      这是 DocRes 图像在 chainner 中运行的恢复模型用于改进扫描的文档。原始图像后跟恢复后的图像，然后是 chainner 模型。更进一步，使用 Mindee Doctr 非常准确地获取线段。 我正在处理的下一个任务是识别字体大小，然后识别字体样式，然后使用 Microsoft Phi-3 或具有 OCR 功能的类似模型进行 OCR 并应用样式，然后恢复图像 链接 https://github.com/ZZZHANG-jx/DocRes https://github.com/chaiNNer-org/chaiNNer 原始图像 恢复后的图像 Chainner 架构 已识别线段    提交人    /u/atlury   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e96f4i/discussion_document_image_restoration/</guid>
      <pubDate>Mon, 22 Jul 2024 05:25:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用稀疏数据对自定义下游任务的 OS 模型进行微调的最佳实践</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e962vd/p_best_practices_in_fine_tuning_os_models_with/</link>
      <description><![CDATA[我有一项下游任务，在输入过程中，99% 以上的数据都是上下文，由各种来源生成。实际模型输出只有几个标记，但输入的大小可以从 2k 个标记一直到 10k 个标记不等。因此，考虑到较长的上下文窗口，我尝试针对此任务微调 mistral 7b v0.3。但是尝试使用较低的学习率（如 8e-6）并衰减，我仍然会在每次运行时得到越来越高的训练损失。 训练集由标准 input_ids、attention_mask 和标签组成，但由于训练数据的性质，attention_mask 和标签分别大多为 1 和 -100。由于它们的大小也有很大差异，我将数据打包成 4096 的长度，使其保持不变。我的训练机器是 AWS trn1n.32xlarge 类型。关于我应该在这里做什么，有什么建议吗？对于任何对数据集感兴趣的人，这里是直接标记化版本数据的链接。    提交人    /u/VBQL   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e962vd/p_best_practices_in_fine_tuning_os_models_with/</guid>
      <pubDate>Mon, 22 Jul 2024 05:03:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] ChessGPT 比 GPT-4 小 100,000 倍，下棋等级为 1500 Elo。通过找到技能向量，我们可以在非分布游戏中将其胜率提高 2.6 倍。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8v2za/p_chessgpt_100000x_smaller_than_gpt4_plays_chess/</link>
      <description><![CDATA[之前的一个项目训练了 ChessGPT，这是一组 25M 和 50M 参数的 GPT 模型，可以在 1500 Elo 下棋。这些模型比 GPT-4 的 1.8T 参数小约 100,000 倍。 在 Stockfish 0 级，50M 参数模型的胜率为 70%。但是，如果用 20 个随机动作初始化游戏，其胜率会下降到 17%。这是因为它无法泛化分布之外的内容吗？在考虑下一个标记预测任务时，如果游戏以随机动作开始，那么好的下一个标记预测器会预测合法但低技能的动作。 这就是我们在 ChessGPT 中发现的。通过向模型的激活中添加技能向量，我们可以将其胜率提高到 43%，即提高 2.6 倍。我们无法完全弥补性能差距，但这是一个很大的比例。干预非常简单，更复杂的干预可能会进一步提高其胜率。 该模型仅经过训练以预测 PGN 字符串中的下一个字符（1.e4 e5 2.Nf3 ...），并且从未明确给出棋盘状态或国际象棋规则。尽管如此，为了更好地预测下一个角色，它会学习在游戏的任何时候计算棋盘的状态，并学习各种规则，包括将军、将死、王车易位、过路兵、升级、固定棋子等。此外，为了更好地预测下一个角色，它还学习估计潜在变量，例如游戏中玩家的 Elo 评级。 我们还可以使用可解释性方法来干预模型的内部棋盘状态。 这项工作最近被 2024 年语言建模会议 (COLM) 接受，标题为“国际象棋语言模型中的新兴世界模型和潜在变量估计”。 更多信息请参阅此帖子： https://adamkarvonen.github.io/machine_learning/2024/03/20/chess-gpt-interventions.html 代码在这里： https://github.com/adamkarvonen/chess_llm_interpretability    提交人    /u/seraine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8v2za/p_chessgpt_100000x_smaller_than_gpt4_plays_chess/</guid>
      <pubDate>Sun, 21 Jul 2024 19:59:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 与主要作者吴正轩讨论 ReFT 论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8qwnl/r_discussion_of_reft_paper_with_lead_author/</link>
      <description><![CDATA[大家好， 本周星期五的论文讨论会上，我们非常幸运地邀请到了 ReFT 论文的主要作者，我想分享一下我们的讨论和笔记！ https://www.oxen.ai/blog/arxiv-dives-how-reft-works TLDR ~ ReFT 是一种微调技术，其参数效率比 LoRA 高 15 到 60 倍。训练速度超快。在 A100 上，1k 个示例大约需要 18 分钟。我成功地在不到 1 分钟的时间内，在 Llama 2 7B 上使用大约 100 个示例对 A10 上的 ReFT 进行了微调。 它的工作原理是操作残差流中的表示，而不是 K-V 矩阵。他们向特定的 token 索引和层添加了他们称为“干预”的额外学习参数，从而高效且轻松地控制表示。ReFT 也很不错，因为它们是可组合的。例如，您可以训练一个用于指令跟踪的模型，一个用于德语的模型，然后将它们都应用于德语的获取和指令跟踪模型。 作者给出了他们在实验室中迭代时学到的超级实用的技巧和教训。整个讨论也在 YouTube 上。 希望你喜欢！    提交人    /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8qwnl/r_discussion_of_reft_paper_with_lead_author/</guid>
      <pubDate>Sun, 21 Jul 2024 16:59:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基线薄弱和报告偏差导致机器学习对流体相关偏微分方程过度乐观</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8pp4r/r_weak_baselines_and_reporting_biases_lead_to/</link>
      <description><![CDATA[  由    /u/nuclear_knucklehead  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8pp4r/r_weak_baselines_and_reporting_biases_lead_to/</guid>
      <pubDate>Sun, 21 Jul 2024 16:05:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 21 Jul 2024 02:15:09 GMT</pubDate>
    </item>
    </channel>
</rss>