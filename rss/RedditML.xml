<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Thu, 18 Apr 2024 21:12:07 GMT</lastBuildDate>
    <item>
      <title>[P] Llama 3 70B 供电编码副驾驶扩展</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7c6e2/p_llama_3_70b_powered_coding_copilot_extension/</link>
      <description><![CDATA[今天早上读到来自 Meta 的新闻非常兴奋，特别是关于 70B 模型获得的 HumanEval 分数。 想到了让新的 Llama 3 70B 可供任何想要尝试的人使用会很有用，因此我将其添加到我的 VS Code 编码副驾驶扩展 double.bot 。  还对前 50 条消息免费，以便在我们等待量化版本在本地运行时每个人都有机会尝试   由   提交/u/geepytee  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7c6e2/p_llama_3_70b_powered_coding_copilot_extension/</guid>
      <pubDate>Thu, 18 Apr 2024 19:29:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 医疗领域基准上的 Llama-3（7B 和 70B）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7b35q/d_llama3_7b_and_70b_on_a_medical_domain_benchmark/</link>
      <description><![CDATA[    &lt; /a&gt;  Llama-3 正在人工智能社区掀起波澜。我很好奇它在医学领域的表现如何，以下是 Llama-3（7B 和 70B）在由 9 个不同数据集组成的医学领域基准上的评估结果 ​ https://preview.redd.it/ t7cqlkyt9avc1.png?width=1474&amp;format=png&amp;auto=webp&amp;s=bb053d032093dd09c892a3fb570b3eb40a8a288c 我将进行微调、评估&amp;释放 Llama-3 和在接下来的几天里，我们将在不同的医疗和法律基准上获得不同的法学硕士。请关注此处的更新：https://twitter.com/aadityaura ​ &lt; p&gt;https://preview.redd.it/9egbcayv9avc1。 png?width=1344&amp;format=png&amp;auto=webp&amp;s=436a972421d5568e1a544962b8cfd1c7b14efe04 ​ ​   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7b35q/d_llama3_7b_and_70b_on_a_medical_domain_benchmark/</guid>
      <pubDate>Thu, 18 Apr 2024 18:45:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据科学家：2024 年工作准备指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7atin/d_data_scientist_job_preparation_guide_2024/</link>
      <description><![CDATA[我已经找工作近 4 个月了。两年后，我睁开眼睛看到外面的世界，一开始，世界崩溃了，因为我不知道这个行业发生了多大的变化，genAI 和 LLM 现在是强制性的。之前我只是局限于使用chatGPT作为UI。 所以，准备了这么多个月，感觉就像是在兜圈子，跑来跑去，对事物的理解并没有深入。 。我浏览了大约 40 多个职位并研究了他们的要求（对于中等资历的 DS 职位）。 因此，我制定了一个计划，然后逐一完成每项任务。在这里，如果有人感兴趣，你可以可以查看与求职相关的重要工具和库。 Github，概念 我愿意接受您的建议和编辑，祝您准备愉快！   由   提交/u/xandie985  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7atin/d_data_scientist_job_preparation_guide_2024/</guid>
      <pubDate>Thu, 18 Apr 2024 18:35:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 元评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c78or9/d_icml_meta_reviews/</link>
      <description><![CDATA[ICML 元评论何时发布？是否会与最终纸质通知一起宣布？该网页显示截止日期为 4 月 16 日。 https://icml.cc/Conferences/2024/ReviewerInstructions   由   提交/u/Personal_Click_6502   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c78or9/d_icml_meta_reviews/</guid>
      <pubDate>Thu, 18 Apr 2024 17:09:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自信地展示您的工作：调整曲线的置信带</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c783my/r_show_your_work_with_confidence_confidence_bands/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2311.09480  推文：https://x.com/NickLourie/status/1770077925779337563  代码：https://github.com/nicholaslourie/opda 文档：https://nicholaslourie.github.io/opda/tutorial/usage.html 摘要：  超参数的选择极大地影响自然语言处理的性能。通常，很难判断一种方法是否优于另一种方法，或者只是更好地调整。调优曲线通过考虑调优工作来解决这种歧义。具体来说，他们将验证性能绘制为迄今为止尝试的超参数选择数量的函数。虽然这些曲线存在多种估计器，但通常使用点估计，我们发现点估计会默默地失败，并且当给出的数据太少时会给出矛盾的结果。除了点估计之外，置信带对于严格建立不同方法之间的关系也是必要的。我们提出了第一种为调谐曲线构建有效置信带的方法。这些频带是精确的、同步的且无分布的，因此它们为比较方法提供了坚实的基础。实证分析表明，虽然作为基线的引导置信带未能接近其目标置信度，但我们的置信带却完全达到了目标。我们通过消融验证我们的设计，分析样本量的影响，并提供将模型与我们的方法进行比较的指导。为了促进未来工作中的自信比较，我们发布了 opda：一个易于使用的库，您可以使用 pip 安装它。    由   提交/u/nicholaslourie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c783my/r_show_your_work_with_confidence_confidence_bands/</guid>
      <pubDate>Thu, 18 Apr 2024 16:46:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] InternVL v1.5开源，OpenCompass多模态基准测试排名第一</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c780cd/r_internvl_v15_open_sourced_ranking_first_in/</link>
      <description><![CDATA[      https://preview.redd.it/fh44g3n4m9vc1.png?width=1383&amp;format=png&amp;auto=webp&amp;s=9b3e499bd51aeb10559f4636eba2a1677d4a08a3 InternVL 是一个多模态基础模型，被接受为 CVPR 2024 的口头论文。最新版本 InternVL v1.5 在 OpenCompass 多模态模型基准测试中排名第一。 Demo： https://internvl.opengvlab.com/ 模型下载： https://huggingface.co/collections/OpenGVLab/internvl-65b92d6be81c86166ca0dde4 OpenCompass： https://rank.opencompass.org.cn 一些例子： https://preview.redd.it/rwj7vs9rm9vc1.jpg?width=902&amp;format=pjpg&amp;auto=webp&amp;s=514e14e692db8ea7bd5a66cc36b1ca3f8351102c https://preview.redd.it/vtwjml3qm9vc1.png?width=2508&amp;format=png&amp;auto=webp&amp;s=e32c044d4bc60ef28baf64dccdcb5fe9b10dfc61 https://preview.redd.it/p51vt3xpn9vc1.png?width=2609&amp;format=png&amp;auto=webp&amp;s=73907e5ffb4d9b9bd4250cbce53e3bd29dedabf1    提交人    /u/flyforlight   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c780cd/r_internvl_v15_open_sourced_ranking_first_in/</guid>
      <pubDate>Thu, 18 Apr 2024 16:42:45 GMT</pubDate>
    </item>
    <item>
      <title>[N] Meta 发布 Llama 3</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c77f0m/n_meta_releases_llama_3/</link>
      <description><![CDATA[      https://llama.meta.com/llama3 /  ​ ​ /u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c77f0m/n_meta_releases_llama_3/</guid>
      <pubDate>Thu, 18 Apr 2024 16:18:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] MineDreamer：通过想象链学习遵循模拟世界控制的指令</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c775ds/r_minedreamer_learning_to_follow_instructions_via/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.12037 代码：https://github .com/Zhoues/MineDreamer 模型和数据集：https://huggingface. co/Zhoues 摘要：  设计一个可以遵循的通才体现的智能体是一个长期目标以类似人类的方式进行多样化的指令。然而，由于难以理解抽象和连续的自然语言指令，现有方法通常无法稳定地遵循指令。为此，我们推出了 MineDreamer，这是一种基于具有挑战性的 Minecraft 模拟器的开放式实体代理，其创新范例可增强低级控制信号生成中的指令跟踪能力。具体来说，MineDreamer 是在多模态大型语言模型 (MLLM) 和扩散模型的最新进展之上开发的，我们采用想象链 (CoI) 机制来想象执行指令的逐步过程，并将想象力转化为适合当前状态的更精确的视觉提示；随后，代理生成键盘和鼠标操作，以有效地实现这些想象，并稳定地遵循每一步的指令。大量实验表明，MineDreamer 能够稳定地遵循单步和多步指令，显着优于最佳通用代理基线，几乎使其性能提高了一倍。此外，对智能体想象力的定性分析揭示了其对开放世界的概括和理解。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c775ds/r_minedreamer_learning_to_follow_instructions_via/</guid>
      <pubDate>Thu, 18 Apr 2024 16:07:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] 压缩线性代表智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c76tpe/r_compression_represents_intelligence_linearly/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.09937 代码：https://github.com/hkust-nlp/llm-compression-intelligence 数据集：https://huggingface.co/datasets/hkust-nlp/llm-compression 摘要：&lt; /p&gt;  人们相信，学习良好的压缩会带来智慧。最近，语言建模已被证明等同于压缩，这为大型语言模型（LLM）的成功提供了令人信服的理由：更高级语言模型的开发本质上是增强压缩，从而促进智能。尽管讨论如此吸引人，但关于压缩和智能之间相互作用的实证证据却很少。在这项工作中，我们在法学硕士的背景下研究了它们的关系，将法学硕士视为数据压缩器。考虑到“智力”的抽象概念，我们采用平均下游基准分数作为替代，特别针对与知识和常识、编码和数学推理相关的智力。我们的研究涵盖 12 个基准，汇集了来自不同组织的 30 名公共法学硕士。值得注意的是，我们发现法学硕士的智力（通过平均基准分数反映出来）几乎与他们压缩外部文本语料库的能力线性相关。这些结果提供了具体的证据，支持这样的观点：卓越的压缩能力意味着更高的智力。此外，我们的研究结果表明，压缩效率作为源自原始文本语料库的无监督指标，可以作为与模型功能线性相关的可靠评估指标。我们开源我们的压缩数据集以及数据收集管道，以方便未来的研究人员正确评估压缩。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c76tpe/r_compression_represents_intelligence_linearly/</guid>
      <pubDate>Thu, 18 Apr 2024 15:54:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 产品评估是讨论最多的话题之一</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c75q78/d_product_evaluations_is_one_of_the_most/</link>
      <description><![CDATA[我们是一家人工智能咨询公司，这种情况一次又一次地发生在我们身上...... 我们开始一个新的法学硕士项目客户。 他们的工程师很快就能完成 80%。 他们有很多边缘情况，希望我们完成剩余的 20%。  &gt;我们向他们询问有关评估的信息。 当然他们没有。 我们创建评估框架，迭代改进管道，瞧。  工作完成，每个人都很高兴。 我认真地认为，根据我们的观察，最好的人工智能产品团队将是那些在评估上花费大量时间的团队。它很无聊，很重复，但它区分了令人惊叹的人工智能产品和表现不佳的产品。   由   提交 /u/BootstrapGuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c75q78/d_product_evaluations_is_one_of_the_most/</guid>
      <pubDate>Thu, 18 Apr 2024 15:10:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 100+标签文本分类问题。 “通常”的方法是什么？变形金刚？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c748uc/d_100_labels_textclassification_problem_whats_the/</link>
      <description><![CDATA[每个文本不超过15个单词，并且类别高度不平衡。但它们都至少有 30 个左右的实例。 我成功地处理了具有相同性质的数据，但具有大约 15 个标签以及梯度增强模型的集合。  在深入测试一堆模型之前，我想知道是否有一些策略可以解决像这样的高维问题。  有些问题是无法解决的，让我们面对现实吧。但是你们会尝试什么？   由   提交/u/Melodic_Reality_646   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c748uc/d_100_labels_textclassification_problem_whats_the/</guid>
      <pubDate>Thu, 18 Apr 2024 14:07:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 表格数据训练模型导致高损失</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c72nnc/d_training_model_on_tabular_data_resulting_in/</link>
      <description><![CDATA[您好，我正在使用已预处理（缩放、PCA）的表格数据训练模型。目前有超过 50k 行和 10 列。损失很高，不确定我哪里做错了 就上下文而言，我使用 MSE 作为我的损失函数，0.01 学习率和 256 批量大小。 谢谢这么多。 这就是我的初始化代码的样子： class NN(nn.Module): def init(self): super(NN, self). init() # 表格数据处理层 self.fc1 = nn.Linear(10, 64) self.fc2 = nn.Linear(64, 32) self.fc3 = nn.Linear(32, 16) self.fc4 = nn. Linear(16, 1) self.bn1 = nn.BatchNorm1d(64) self.bn2 = nn.BatchNorm1d(32) self.bn3 = nn.BatchNorm1d(16) self.relu = nn.ReLU() self.dropout = nn .Dropout(0.25) defforward(self, x_tab, x_img): out = self.fc1(x_tab) out = self.bn1(out) out = self.relu(out) out = self.dropout(out) out = self .fc2(out) out = self.bn2(out) out = self.relu(out) out = self.dropout(out) out = self.fc3(out) out = self.bn3(out) out = self.relu (out) out = self.dropout(out) out = self.fc4(out) return out  输出： Epoch 1/30，损失：16834.8088纪元2/30，损失：4379.7037纪元3/30，损失：3361.2462纪元4/30，损失：3255.9039纪元5/30，损失：3255.8603纪元6/30，损失：3243.9488纪元7/3 0，损失：3235.4387纪元 8/30，损失：3213.4688 纪元 9/30，损失：3189.1130 纪元 10/30，损失：3174.2118 纪元 11/30，损失：3168.1597 纪元 12/30，损失：3155.3225 纪元 13/30，损失：315 0.0659 第 14 纪元/30，损失：3119.2989 纪元 15/30，损失：3117.0893 纪元 16/30，损失：3130.4699 纪元 17/30，损失：3126.7107 纪元 18/30，损失：3110.9422 纪元 19/30，损失：3119.8 601 纪元 20/30 ，损失：3094.5037 纪元 21/30，损失：3054.4725 纪元 22/30，损失：3079.4411 纪元 23/30，损失：3064.4010 纪元 24/30，损失：3049.7988 纪元 25/30，损失：3022.971 4 纪元 26/30，损失：3029.0342 Epoch 27/30，丢失：3034.8153 Epoch 28/30，丢失：3025.2383 Epoch 29/30，丢失：3052.9892 Epoch 30/30，丢失：3033.2717    由   提交 /u/sparttann   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c72nnc/d_training_model_on_tabular_data_resulting_in/</guid>
      <pubDate>Thu, 18 Apr 2024 12:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 复制和比较研究模型 - 最佳实践？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c70y9j/d_reproducing_and_comparing_models_from_research/</link>
      <description><![CDATA[在我的工作中，我花费了大量时间复制研究论文并尝试将它们应用到我们的用例（医学图像分析）中。  通常，这是一个很大的麻烦，甚至带有代码的论文也经常表明，如果没有大量编辑，它就无法运行。一旦它们运行，只有在设置特定的随机种子时结果才会好...... 然后将其应用到我们的用例后，我意识到性能的提高实际上并不是来自新模型，但是来自不同的后处理方式... 我已经开始为自己编写一些脚本来模块化它，以便更容易地重现和比较。  但我不确定这是否是正确的方法。所以我很好奇，您为您的用例重现模型并进行科学比较的方法是什么？    由   提交 /u/MintOwlTech   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c70y9j/d_reproducing_and_comparing_models_from_research/</guid>
      <pubDate>Thu, 18 Apr 2024 11:27:51 GMT</pubDate>
    </item>
    <item>
      <title>[N] 美联储任命“人工智能末日者”来管理美国人工智能安全研究所</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6nps8/n_feds_appoint_ai_doomer_to_run_us_ai_safety/</link>
      <description><![CDATA[https://arstechnica.com/tech-policy/2024/04/feds-appoint-ai-doomer-to-run-us-ai-safety-institute/ 文章简介： 被任命为 AI 安全负责人的是 Paul Christiano，他是前 OpenAI 研究员，开创了一种名为基于人类反馈的强化学习的基础 AI 安全技术（ RLHF），但也因预测“人工智能发展有 50% 的机会以‘厄运’而告终”而闻名。尽管克里斯蒂安诺的研究背景令人印象深刻，但一些人担心，任命所谓的“人工智能厄运者”会带来灾难。 NIST 可能冒着鼓励非科学思维的风险，许多批评家认为这些思维纯粹是猜测。   由   提交/u/bregav  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6nps8/n_feds_appoint_ai_doomer_to_run_us_ai_safety/</guid>
      <pubDate>Wed, 17 Apr 2024 22:49:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>