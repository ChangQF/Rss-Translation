<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 20 Apr 2024 15:13:07 GMT</lastBuildDate>
    <item>
      <title>[R][研究]应用人工智能/机器学习研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8r56m/rresearch_applied_ai_ml_research/</link>
      <description><![CDATA[人工智能/机器学习研究中是否有适合应用性更强的研究？ 例如。与其开发新技术，不如专注于使用现有的方法和技术（我们拥有大量的），然后使用这些现有的方法来解决现实世界中的各种问题。 或者也许找到更多新颖的方法来使用/改编现有的技术，以便它们可以用于解决比最初预期更多种类的现实世界问题。或者对所有不同类型的解决方案进行原型设计，并为现实世界的问题开发很酷的东西。 但我还没有遇到过任何主要教授/实验室等从事此类工作。 &lt; !-- SC_ON --&gt;  由   提交 /u/ColdPillow5585   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8r56m/rresearch_applied_ai_ml_research/</guid>
      <pubDate>Sat, 20 Apr 2024 14:20:45 GMT</pubDate>
    </item>
    <item>
      <title>ML代码生成器 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8ovd8/ml_code_generator_p/</link>
      <description><![CDATA[ 由   提交 /u/kamiurek   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8ovd8/ml_code_generator_p/</guid>
      <pubDate>Sat, 20 Apr 2024 12:32:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 移动网络v2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8mk5p/r_mobilenetv2/</link>
      <description><![CDATA[如何将 mobileneyv2,(512,512,3) 的输入形状更改为 (512,512,4)   由   提交/u/Eleonora467  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8mk5p/r_mobilenetv2/</guid>
      <pubDate>Sat, 20 Apr 2024 10:16:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一张让你感觉自己老了的幻灯片</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8kuef/d_a_slide_which_makes_you_feel_old/</link>
      <description><![CDATA[       由   提交 /u/xiikjuy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8kuef/d_a_slide_which_makes_you_feel_old/</guid>
      <pubDate>Sat, 20 Apr 2024 08:20:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过空间、时间和大脑的反向传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8fl48/r_backpropagation_through_space_time_and_the_brain/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.16933 摘要：  神经网络中的有效学习需要个体突触的适应对解决任务的相对贡献。然而，物理神经元系统——无论是生物的还是人工的——都受到时空局部性的限制。这种网络如何进行有效的信用分配在很大程度上仍然是一个悬而未决的问题。在机器学习中，答案几乎普遍由误差反向传播算法通过空间（BP）和时间（BPTT）给出。然而，众所周知，BP(TT) 依赖于生物学上不可信的假设，特别是在时空（非）局部性方面，而实时循环学习 (RTRL) 等前向传播模型则受到令人望而却步的记忆限制。我们引入了广义潜在均衡（GLE），这是一种在神经元的物理动态网络中进行完全局部时空信用分配的计算框架。我们首先定义基于神经元局部不匹配的能量，从中我们通过平稳性导出神经元动力学，通过梯度下降导出参数动态。由此产生的动力学可以解释为深层皮质网络中 BPTT 的实时、生物学上合理的近似，具有连续时间神经元动力学和持续活跃的局部突触可塑性。特别是，GLE 利用生物神经元根据膜电位对其输出速率进行相移的能力，这对于信息传播的两个方向都是至关重要的。对于前向计算，它能够将时间连续输入映射到神经元空间，从而执行有效的时空卷积。对于后向计算，它允许反馈信号的时间反转，从而近似有用参数更新所需的伴随状态。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8fl48/r_backpropagation_through_space_time_and_the_brain/</guid>
      <pubDate>Sat, 20 Apr 2024 03:02:20 GMT</pubDate>
    </item>
    <item>
      <title>[N] 何凯明关于表征学习的深度学习架构讲座</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8d5m1/n_kaiming_hes_lecture_on_dl_architecture_for/</link>
      <description><![CDATA[https://youtu.be/D_jt-xO_RmI 非常好的讲座，DL 历史架构进展的最高信噪比。   由   提交 /u/lkphuc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8d5m1/n_kaiming_hes_lecture_on_dl_architecture_for/</guid>
      <pubDate>Sat, 20 Apr 2024 00:57:29 GMT</pubDate>
    </item>
    <item>
      <title>您认为强化学习仍然有效吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c87bh4/do_you_think_reinforcement_learning_still_got_it_d/</link>
      <description><![CDATA[最近我听到很多人说强化学习本身多年来没有任何改进（也许 alphago 是最后的大事）。  而人工智能的其他领域已经出现了许多 SOTA 架构，例如用于基于序列的任务的“Transformers”以及“ResNet”、“Diffusers”和“SOTA”架构。 “VAE”类似于计算机视觉任务的架构。 我认为，无论是直接还是间接，强化学习仍然在使用“RLHF”技术的 ChatGPT 和 Claude 等法学硕士背后发挥着至关重要的作用。以及许多其他最新技术，包括自动驾驶汽车和机器人。  我认为这只是这个领域的一个寒冷的冬天，在未来几年里很快就会找到最先进的建筑（或者这就是我所希望的） 你的想法是什么想法？ 🤔   由   提交/u/cyb0rg14_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c87bh4/do_you_think_reinforcement_learning_still_got_it_d/</guid>
      <pubDate>Fri, 19 Apr 2024 20:40:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] TorchFix - 具有自动修复支持的 PyTorch 使用代码的 linter</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c83rcw/p_torchfix_a_linter_for_pytorchusing_code_with/</link>
      <description><![CDATA[TorchFix 是一款针对 PyTorch 用户的 Python 代码静态分析工具 - 具有自动修复功能的 linter。它可用于查找和修复问题，例如使用已弃用的 PyTorch 函数和非公共符号，并一般采用 PyTorch 最佳实践： https://github.com/pytorch-labs/torchfix   由   提交/u/kit1980  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c83rcw/p_torchfix_a_linter_for_pytorchusing_code_with/</guid>
      <pubDate>Fri, 19 Apr 2024 18:13:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] Google 是否将凭借其海量数据资源主宰 RAG 场景？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c824at/d_is_google_set_to_dominate_the_rag_scene_with/</link>
      <description><![CDATA[大家好！看起来几年后，我们使用的基本大语言模型（LLM）将会商品化，你选择哪一个并不重要。下一个重大事件可能是使用检索增强生成 (RAG) 的法学硕士，这意味着他们需要大量数据才能正常工作。 鉴于 Google 可以通过其搜索引擎访问大量数据，您认为与其他公司相比，他们在这个新阶段是否处于更好的领先地位？大家觉得怎么样？   由   提交 /u/Few-Pomegranate4369    reddit.com/r/MachineLearning/comments/1c824at/d_is_google_set_to_dominate_the_rag_scene_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c824at/d_is_google_set_to_dominate_the_rag_scene_with/</guid>
      <pubDate>Fri, 19 Apr 2024 17:06:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 基于AI的语言老师，可以在12GB显卡（RTX 4070）上本地运行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7ymal/p_aibased_language_teacher_that_can_run_locally/</link>
      <description><![CDATA[我最近一直在尝试各种开源模型。 我认为我可以尝试的一个有趣的应用程序是 我最近一直在尝试各种开源模型。语文老师&gt; 🌍  结果还不错，你可以在这里尝试一下： https:/ /github.com/helboukkouri/virtual-teacher   由   提交/u/HichamEB   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7ymal/p_aibased_language_teacher_that_can_run_locally/</guid>
      <pubDate>Fri, 19 Apr 2024 14:43:29 GMT</pubDate>
    </item>
    <item>
      <title>[D]嵌入搜索“淹没”在噪音的海洋中！你能解开这个谜语吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7wrhe/d_embeddings_search_drowning_in_a_sea_of_noise/</link>
      <description><![CDATA[我正在为存储在 Postgres DB 中的数十万条文本记录的 RAG 应用程序编写概念证明，使用 pgvector 来存储嵌入（并使用 HNSW 索引）。向量维度指定正确。  当前正在使用不同的文本块大小进行实验，并比较两种不同的嵌入模型。（实际块大小可能会略有不同，因为我不会破坏单词来强制确定大小）。   nomic-embed-text snowflake-arctic-embed-m-long  这是实验的要点： 1-为“n”创建嵌入文档 2- 创建一个查询/提示列表，以查找其中某些文档中确实包含的信息。  示例：  在“地点 x”发生了哪些事件？ John Doe 的昵称是什么？  入住“医院名称”的患者是谁？ 请告诉我销售总监提出的申请。 ...  3- 对于每个查询/提示，我运行余弦距离查询并获取最近的 5 个匹配块。  4-计算所有查询/块的平均距离后，理论上，最小值是 model/chunk_size 的最佳组合。   这对于一小部分文档样本（比如 ≃ 200）效果非常好，但是一旦我添加了更多文档，我就开始注意到一个问题。  一些新文档包含 30k 多个名字的列表。  每当我运行包含名称的查询时，都会返回上面列表中的块，即使它们不包含名称或提示中显示的任何其他信息（无论选择块大小或策略）。  我的理论是，当嵌入包含名称的块时，生成的嵌入包含“名称”语义的强向量，但区分该名称与其他名称的向量可能相对较弱。  一个块，除了对“name”向量的引用之外几乎不包含任何内容。然后被认为与提示的嵌入非常相似，尽管名称本身不匹配。   对于那些有更多经验/理解的人来说，我的这些假设是错误的吗？  您有什么建议/解决方法吗？  我有一些想法，但想看看是否有人遇到同样的问题。   由   提交 /u/grudev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7wrhe/d_embeddings_search_drowning_in_a_sea_of_noise/</guid>
      <pubDate>Fri, 19 Apr 2024 13:21:46 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 最近是否有特定的技术/科学突破使得多个大型语言模型的最大上下文长度显着跃升？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7pzf0/discussion_are_there_specific_technicalscientific/</link>
      <description><![CDATA[GPT-4 和 Claude 等模型的最新版本在最大上下文长度上有显着的跳跃（4/8k -&gt; 128k+）。这些模型可以处理的代币数量方面的进展听起来非常引人注目。 是什么导致了这一点？这纯粹是因为训练期间可用的计算量增加而发生的吗？是否有算法进步导致了这种情况？   由   提交 /u/analyticalmonk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7pzf0/discussion_are_there_specific_technicalscientific/</guid>
      <pubDate>Fri, 19 Apr 2024 06:28:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当我只有一组 PDF 文档时，如何评估 RAG - 检索和生成？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7oa6k/d_how_to_evaluate_rag_both_retrieval_and/</link>
      <description><![CDATA[假设我有 1000 个 PDF 文档，用作 RAG 管道的输入。 我想评估RAG 管道，以便我可以测量： - 哪些嵌入模型更适合我的数据？ - 哪些重新排序器有效并且需要它们？ - 哪些法学硕士给出了最真实和连贯的答案？ 我如何评估管道的这些步骤？ 根据我的研究，我发现大多数框架都需要标签来进行检索和世代评价。我如何使用法学硕士创建这些数据？还有其他技术吗？ 我发现的一些东西： 对于检索：使用 LLM 生成用于检索的综合排名标签。 我应该使用哪个法学硕士？我应该遵循哪些最佳实践？我可以查看任何代码吗？ 对于生成的文本： - 为每一代生成如上所述的合成标签。 - 使用法学硕士作为法官，根据所获得的背景和提出的问题对每一代进行评分。您会推荐哪些法学硕士？ 哪些技术对你们有用？   由   提交 /u/awinml1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7oa6k/d_how_to_evaluate_rag_both_retrieval_and/</guid>
      <pubDate>Fri, 19 Apr 2024 04:43:11 GMT</pubDate>
    </item>
    <item>
      <title>[N] Meta 发布 Llama 3</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c77f0m/n_meta_releases_llama_3/</link>
      <description><![CDATA[      https://llama.meta.com/llama3 /  ​ ​ https://preview.redd.it/n3lwb4xfj9vc1.png?width=3840&amp;format=png&amp;auto=webp&amp;s=b756d89c 50c627955668d5ac16df82f7af01cdbc&lt; /a&gt;   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c77f0m/n_meta_releases_llama_3/</guid>
      <pubDate>Thu, 18 Apr 2024 16:18:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>