<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 16 Apr 2024 06:17:50 GMT</lastBuildDate>
    <item>
      <title>将模型预测作为特征返回[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c58o96/feeding_model_prediction_back_in_as_feature/</link>
      <description><![CDATA[我正在使用模型进行分类。训练模型以对训练集和测试集进行概率预测，然后将所得概率以概率作为特征添加回新模型，这是一种好的做法吗？ 流程：  训练/测试模型 predict_proba 以获得概率 训练另一个具有与第一个模型相同特征的模型 + 概率  第二个模型明显更准确，但我对此表示怀疑。   由   提交 /u/Fuzzy_Lock_5557   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c58o96/feeding_model_prediction_back_in_as_feature/</guid>
      <pubDate>Tue, 16 Apr 2024 05:53:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] Yolov8相关查询，用于检测步行时使用手机的行人。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c57v58/p_yolov8_related_query_for_detection_of/</link>
      <description><![CDATA[所以，我正在研究这个项目，我的任务是检测在路上使用手机的行人并对他们进行罚款。因此，该系统的工作原理与汽车系统的工作原理完全相同，读取车牌号，然后在数据库中查找并从车主的帐户中扣除罚款。  现在，我以前曾研究过人脸识别/考勤系统，因为那里有数千种模型，而且我以前看过很多这些代码，但这是我第一次与 yolo 合作，我我什至不做图像处理，但无法拒绝我的教授，这让我来这里向你们寻求帮助。  我已经把所有其他部分都搞定了，一位队友正在研究罚款扣除过程，但我不知道如何实现仅当该人拿着手机时才识别面部的步骤并且仅限于持有电话的人。    由   提交/u/gh0st_taskforce_141   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c57v58/p_yolov8_related_query_for_detection_of/</guid>
      <pubDate>Tue, 16 Apr 2024 05:03:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] Megalodon：高效的 LLM 预训练和无限上下文长度的推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c57nxd/r_megalodon_efficient_llm_pretraining_and/</link>
      <description><![CDATA[ 由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c57nxd/r_megalodon_efficient_llm_pretraining_and/</guid>
      <pubDate>Tue, 16 Apr 2024 04:51:49 GMT</pubDate>
    </item>
    <item>
      <title>[D]训练边缘TPU（珊瑚）的keras对象检测模型[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c57d07/dtrain_keras_object_detection_model_for_edge/</link>
      <description><![CDATA[对于客户，我需要训练一个能够在珊瑚板上运行以进行边缘 TPU 推理的对象检测模型，有一些示例可以简化使用 TensorFlow Lite Model Maker 的过程或使用 kerasCV 的其他一些示例（不适用于边缘 TPU），但对于此客户端，我们希望使用纯 keras，因为有一些要求无法通过模型制作器实现（据我所知，如果错误请纠正我），特别是：  需要计算一些额外的指标（例如：一些通过 coco evaluator 获得的指标） 需要在训练期间跟踪张量板中的指标比较不同的运行、不同的数据集、执行早期停止、检测欠拟合/过拟合等。  有人执行过类似的操作吗？或者有什么例子或想法吗？   由   提交 /u/Sad-Anywhere-2204   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c57d07/dtrain_keras_object_detection_model_for_edge/</guid>
      <pubDate>Tue, 16 Apr 2024 04:34:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最近有什么 ML 服务器构建指南或建议吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c56crs/d_any_recent_ml_server_build_guides_or/</link>
      <description><![CDATA[我看到了 nvidia RTX 2000、3000 系列的构建指南，但没有看到 4000 系列的构建指南。不幸的是，随着 GPU 变得越来越厚、越来越长、越来越高，共享的知识已经过时得相当快。 有人设法在单个 ML 服务器中安装多个 rtx4090 吗？如果是这样，有什么建议吗？ 谢谢   由   提交 /u/freshairproject   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c56crs/d_any_recent_ml_server_build_guides_or/</guid>
      <pubDate>Tue, 16 Apr 2024 03:39:05 GMT</pubDate>
    </item>
    <item>
      <title>RAG 重新定义：适合大规模组织的可立即部署的 RAG [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c563fr/rag_redefined_readytodeploy_rag_for_organizations/</link>
      <description><![CDATA[      One-尺寸适合大多数 RAG：您的 RAG，已准备好使用 Cognita  完整文章 ​ https://preview.redd.it/v8vaad4vfruc1.png?width=1044&amp;format=png&amp; auto=webp&amp;s=a8f6353ecc9cf2b911733bd1780ef12d17d7d826 “Cognita”探索系列第 3 部分 本文是探索 Cognita 系列的第三部分RAG 框架。它建立在第 2 部分和第 1 部分的基础上，第 2 部分提供了技术视角，第 1 部分解释了基本概念。  本文介绍什么？ 解释组织如何利用 Cognita 快速实施全面的 RAG 框架，而无需从头开始。 重点介绍 Cognita 的模块化架构，使组织能够独立扩展各个组件，确保无缝增长和适应性。  为什么阅读本文？ 强调组织在从大量数据中提取相关见解时所面临的挑战，而传统方法往往无法满足这些挑战。 “检索增强生成”的概念(RAG) 作为解决方案，Cognita 作为预构建的开源 RAG 产品。 强调 Cognita 如何彻底改变组织处理和利用数据的方式，而无需广泛的技术专业知识或资源。  让我们开始烹饪吧！ 演示用户可以使用 Cognita 的用户友好界面执行的各种任务，无需技术专业知识。 任务包括创建数据源、集合、数据摄取、选择集合、配置语言模型 (LLM)、选择文档检索器、编写提示和提出查询。  让我们进行设置 提供用于设置 Ready2DeployRAG4OrgAtScale 环境的全面分步指南。 涵盖先决条件、克隆存储库、创建和激活虚拟环境，启动后端服务器，安装 Yarn，并设置前端。  ​   由   提交 /u/AssistanceOk2217   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c563fr/rag_redefined_readytodeploy_rag_for_organizations/</guid>
      <pubDate>Tue, 16 Apr 2024 03:25:18 GMT</pubDate>
    </item>
    <item>
      <title>图像生成的扩散模型与自回归模型。哪个更好？ [D] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c53pc5/diffusion_versus_autoregressive_models_for_image/</link>
      <description><![CDATA[大家好， 我是使用变压器模型生成图像这一领域的新手。我对上面提到的两种方法很好奇。特别是根据这篇论文“视觉自回归建模：通过下一代预测生成可扩展图像” (结果）。看起来这些 AR（自回归）模型似乎比 DiT（扩散变压器）更好，尤其是在放大时。他们的主要推理优势似乎来自 DiT 的低采样效率。 但是，我对此表示怀疑。除了主要人工智能强国已经采用扩散模型这一事实之外，还有一个坚实的理论支持扩散模型能够生成任何图像分布。除此之外，上面的 VAR 论文没有针对小模型的结果（我也对此感兴趣）。 所以这是我的问题：  有吗有没有提高采样效率的DiT蒸馏论文？我找不到任何 Transformer，所有都是基于 U-Net 的。 是否有任何理论支持用于图像生成（或任何与此相关的生成任务）的 AR Transformer 模型？ 这篇 VAR 论文更好纯粹是因为人们还没有充分探索 DiT 吗？或者说 AR 模型的霸主地位是我们所期望的？ 如果您要根据潜在性能（从研究的角度来看）和成功在两者之间进行选择，您会选择什么？为什么？ （我有偏见，因此支持扩散的原因值得赞赏）  如果您可以回答与此事相关的任何问题或任何意见，请发表评论..    由   提交/u/InstinctsInFlow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c53pc5/diffusion_versus_autoregressive_models_for_image/</guid>
      <pubDate>Tue, 16 Apr 2024 01:27:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 LoRa 训练 Sentence-Transformer 进行文本相似度任务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4vlfa/p_training_sentencetransformer_with_lora_for_text/</link>
      <description><![CDATA[大家好， 我目前正在开展我的学习结束项目，我的目标是训练一个句子-使用 LoRa（Peft 库）为文本相似性任务生成最佳嵌入的 Transformer 模型。 我已经设置了所有内容，包括负责训练和更新权重的 LoRa_fit() 函数。损失函数运行良好，一切似乎都整合得很好。但是，我在训练过程中遇到了一个意外问题。 当尝试使用 SciFact 数据集（MSMARCO 数据集）仅在一个 epoch 上训练我的 Sentence-Transformer 模型 (intfloat/e5-small-v2) 时，训练时间过长。启用 LoRa 时，训练时间约为 10 小时，未启用 LoRa 时，训练时间约为 11 小时。尽管将 LoRa 参数设置为 r=1 和 lora_alpha=1，情况仍然如此。 LoRa 训练时间的边际增益似乎不太可能。 我认为我不是在训练“基本模型”。通过多个调试语句（在如下所示的 lora.py 中）:( trainable params: 27,648 || all params: 33,387,6​​48 || trainable%: 0.08280906759290142 但也打印发生梯度更新的层，仅显示 LoRA 层等） Github 存储库和直接链接到 lora.py 负责加载和训练模型：GPL_LoRA/gpl/toolkit/lora.py at main · KuijpersNick0/GPL_LoRA (github.com) 任何有关可能导致此问题的原因的见解或建议将不胜感激。预先感谢您的帮助！   由   提交/u/Belgium-Frenchie  /u/Belgium-Frenchie reddit.com/r/MachineLearning/comments/1c4vlfa/p_training_sentencetransformer_with_lora_for_text/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4vlfa/p_training_sentencetransformer_with_lora_for_text/</guid>
      <pubDate>Mon, 15 Apr 2024 19:48:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 归一化对分类特征的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4u4zi/d_effect_of_normalization_on_categorical_features/</link>
      <description><![CDATA[可以规范化（如标准缩放器）二进制/一个热编码/标记编码功能吗？我现在找不到任何理由说明为什么它会成为一个问题，但我也没有特别的理由说避免这样做会出现问题。你觉得怎么样？   由   提交 /u/risilm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4u4zi/d_effect_of_normalization_on_categorical_features/</guid>
      <pubDate>Mon, 15 Apr 2024 18:51:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习系统研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4sq8x/d_machine_learning_systems_research/</link>
      <description><![CDATA[我一直在研究 Chip Huyen 的《设计机器学习系统》一书，我对作为研究领域的此类工作非常感兴趣。我应该了解哪些研究人员/实验室/大学以了解有关该领域的更多信息？下面是一个示例： https://pooyanjamshidi.github.io/mls/ &lt; !-- SC_ON --&gt;  由   提交/u/larenspear  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4sq8x/d_machine_learning_systems_research/</guid>
      <pubDate>Mon, 15 Apr 2024 17:56:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 物体检测中的 SOTA？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4pccp/d_sota_in_object_detection/</link>
      <description><![CDATA[几年前我做过目标检测，其中 FRCNN、SSD 和 YOLO 与 RESNET 和 VGG 等作为主干的东西一起流行。 回到 2024 年今天的物体检测任务，我找不到任何重大改进或真正新的架构。我是否遗漏了什么或者这仍然是 SOTA？ 谢谢！ :)   由   提交/u/topsnek69  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4pccp/d_sota_in_object_detection/</guid>
      <pubDate>Mon, 15 Apr 2024 15:40:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么稳定扩散的潜在通道这么小？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4o0qg/d_why_is_the_latent_channel_of_stable_diffusion/</link>
      <description><![CDATA[大家好。我是生成人工智能领域的新手，目前正在深入研究稳定扩散的内部结构。我注意到SD的VAE编码逐渐将通道数提升到512，但在生成潜在向量时突然下降到只有4。这就像一条非常宽阔的隧道后面有一个非常非常细的瓶颈。为什么要这样设计呢？ 64*64*4真的足以表达这么多可能的特征吗？    由   提交/u/ConsequenceDear2557   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4o0qg/d_why_is_the_latent_channel_of_stable_diffusion/</guid>
      <pubDate>Mon, 15 Apr 2024 14:45:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 冷冰冰地给研究人员发邮件寻求合作，我应该谨慎吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4l2hv/d_cold_emailing_a_researcher_for_collaboration/</link>
      <description><![CDATA[我是一名硕士生，几周来我一直在从事一个与研究人员所做的工作密切相关的项目A在最近的一篇论文中。该项目进展顺利，我认为它可以成为一份很棒的出版物，不幸的是我不认识任何从事该主题的人，并且一些指导对于正确捍卫该项目很有用。需要明确的是，这个项目已经很先进了，这不仅仅是一个想法。 我本来想尝试给研究员 A 发电子邮件，看看他是否有兴趣在这个项目上合作，但是我有疑问： 1/ 通过电子邮件冷联系是否很奇怪？我想人们通常会利用会议来进行这种交流，但我还没有机会 2/ 我应该对发送给此人的信息保持谨慎吗？他是一位著名的研究人员，所以我想这很安全，但我不想因为一封电子邮件而被抢先一步 我知道我提供的有关情况的信息很少，但我会如果您曾经做过类似的事情以及它是否成功，很高兴听到任何建议或经验   由   提交 /u/Even_Information4853   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4l2hv/d_cold_emailing_a_researcher_for_collaboration/</guid>
      <pubDate>Mon, 15 Apr 2024 12:33:41 GMT</pubDate>
    </item>
    <item>
      <title>因使用 Java 而被嘲笑 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4gi25/ridiculed_for_using_java_d/</link>
      <description><![CDATA[所以我在 Twitter 上（第一个错误）提到了我的 Java 神经网络，并因使用“过时且无用的语言”而被嘲笑。对于已经构建的NLP。 说实话，这是我的第一个NLP。不过，我确实创建了一个使用 GPT2 管道为作者生成故事的 Python 应用程序，但基础设施的其余部分是用 Java 编写的，我只是创建了一个 Python API 来调用它。 我喜欢 Java。我的代码可以追溯到 2017 年。我是一名业余爱好者，并不期望获得 ML 职位，尤其是在市场和现在的情况下。不过，我确实有机会在我的业务分析师工作中展示一些编程技能，并使用我非常小的 NLP 对一些票务数据执​​行一些基本预测，顺便说一句，我对这些数据很感兴趣。 我的问题是：我是一个彻底使用 Java 的失败者吗？我正在学习一些机器人技术，并计划学习一些 C++，但我拒绝放弃 Java，因为到目前为止，它教会了我很多东西，并为我带来了很好的成果。 l&#39;d就像你对此的看法。谢谢！   由   提交 /u/esqelle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4gi25/ridiculed_for_using_java_d/</guid>
      <pubDate>Mon, 15 Apr 2024 07:48:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>