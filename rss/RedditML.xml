<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Sat, 24 Aug 2024 09:14:13 GMT</lastBuildDate>
    <item>
      <title>[D] 24 小时内自动申请 1000 个职位并获得了 50 次面试！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ezznp0/d_automatically_applied_1000_jobs_in_24h_and_got/</link>
      <description><![CDATA[我是怎么做到的？ 我创建了一个AI 机器人，它可以：  分析候选人信息 检查职位描述 为每份工作生成独特的简历和求职信 回答招聘人员提出的具体问题 自动申请工作  而这一切都是在我睡觉的时候完成的！在短短一个月内，这种方法帮助我获得了大约 50 次面试机会。根据每个职位描述定制的简历和求职信产生了显著的效果。 人工智能正在改变游戏规则 人工智能正在迅速重塑招聘格局：  求职者可以在几秒钟内优化他们的简历 只需点击一下即可制作求职信 技能和工作机会完美匹配 招聘人员正在使用自动筛选系统  这种方法在通过自动筛选系统方面非常有效。通过生成针对每个职位描述的简历和求职信，我的脚本大大增加了被人工智能和人类招聘人员注意到的机会。 招聘的未来：人工智能会让招聘人员过时吗？ 随着人工智能的进步，招聘格局正在发生巨大变化。许多人想知道，随着人工智能越来越有能力分析申请和简历，重新定义招聘人员的角色，人类招聘人员是否很快就会过时。 一个关键问题是如何在看似完美、人工智能优化的应用程序中区分真正的人才。这可能会导致一场“人工智能军备竞赛”，求职者和公司都会不断增强对技术的使用，以获得优势。 个人反思 求职申请的自动化正在改变招聘方式，但它可能会失去人情味。具有讽刺意味的是，随着人工智能变得越来越普遍，公司可能需要重新投资于个人面试，以真正评估候选人的技能。 未来的工作将需要在人工智能的效率和人机交互的丰富性之间取得平衡，创造一个不仅高效而且对每个人来说都充实而有意义的工作场所。 想试试这个魔法吗？ 它的作用如下：  输入您的专业背景 生成定制的简历、求职信和回复 在您享用咖啡的同时发送数百份申请  好奇吗？在这里尝试一下：GitHub 项目 （我的项目完全免费且开源，不像其他类似的服务那样花费很多却提供很少的价值。由于它仍处于测试阶段，GitHub 上的每一个星星都是继续开发它的巨大鼓励！） 附言：我不建议使用这个机器人，它仅用于教育信息目的，人工智能的强大力量伴随着巨大的责任。让我们合乎道德地使用它！    提交人    /u/ChiaPlotting   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ezznp0/d_automatically_applied_1000_jobs_in_24h_and_got/</guid>
      <pubDate>Sat, 24 Aug 2024 07:28:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 比较 R 中的数据处理方法：Base R 与 dplyr</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ezz2m8/r_comparing_data_manipulation_approaches_in_r/</link>
      <description><![CDATA[        由   提交  /u/Suitable-Mess478   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ezz2m8/r_comparing_data_manipulation_approaches_in_r/</guid>
      <pubDate>Sat, 24 Aug 2024 06:47:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过估计数据分布比率进行离散扩散建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ezyunc/r_discrete_diffusion_modeling_by_estimating_the/</link>
      <description><![CDATA[文本扩散模型现在终于达到了 GPT2 的文本质量。 https://arxiv.org/abs/2310.16834（本文荣获 ICML2024 最佳论文奖！） 您认为扩散语言模型（扩散 LLM）会赶上自回归 LLM 并可能成为下一个 ChatGPT 吗？我们很快就会看到扩散 LLM 的缩放定律吗？与自回归 LLM 相比，这些模型具有一些关键优势，例如能够在任何地方接受提示 - 在输入的开始、中间、结束甚至拆分。此外，它们原则上可以一次生成多个标记。 这篇论文内容非常密集且数学繁重，所以我制作了一个动画解释视频，供任何感兴趣的人观看。 https://youtu.be/K_9wQ6LZNpI 我的看法：我认为这种方法在理论上可以扩展，但存在一个重大挑战：我们已经在 GPT/自回归变压器的硬件和软件优化方面投入了大量资金。考虑到沉没成本谬论，很难想象科技巨头会放弃他们目前的 LLM 来开始训练扩散 LLM，尤其是因为他们可能需要数年时间才能赶上 ChatGPT 和类似模型。就像 MAMBA 一样，我担心离散扩散也可能会输掉硬件/软件抽奖。    提交人    /u/AICoffeeBreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ezyunc/r_discrete_diffusion_modeling_by_estimating_the/</guid>
      <pubDate>Sat, 24 Aug 2024 06:32:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 Tidyverse 增强 R</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ezyumd/r_enhancing_r_with_tidyverse/</link>
      <description><![CDATA[        提交人    /u/Suitable-Mess478   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ezyumd/r_enhancing_r_with_tidyverse/</guid>
      <pubDate>Sat, 24 Aug 2024 06:32:35 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 我应该运行 50 个 epoch 还是 100 个 epoch？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ezyujf/discussion_should_i_run_50_epochs_or_100_epochs/</link>
      <description><![CDATA[我有两个带标签的图像数据集。每个数据集有 5 个类。由于数据集大小非常大（每组大约 100000 张图像），我想用 100 个 epoch 训练这两个数据集（假设两个数据集是一个）。由于大小很大，我无法将数据集一起加载。现在，我应该对每个数据集运行 50 个 epoch，保存权重，然后对另一个具有 50 个 epoch 的数据集重复此操作，这将使它总共有 100 个 epoch？或者对两个数据集都运行 100 个 epoch，在 100 个 epoch 后保存权重，这将使它总共有 200 个 epoch？    提交人    /u/Proof_Economy_5133   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ezyujf/discussion_should_i_run_50_epochs_or_100_epochs/</guid>
      <pubDate>Sat, 24 Aug 2024 06:32:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 良好的训练循环还是搞砸了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ezvjf4/d_good_training_loop_or_messing_it_up/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ezvjf4/d_good_training_loop_or_messing_it_up/</guid>
      <pubDate>Sat, 24 Aug 2024 03:11:14 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 当固定提示模板作为 LLM 的输入时，LLM 生成中会出现奇怪的模式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ezv7of/discussion_weird_patterns_in_llm_generations_when/</link>
      <description><![CDATA[对于使用大型语言模型生成创意内容的任务，固定的提示模板是否会在 LLM 输出中引入奇怪的模式、相关性和重复性？ 例如，在不同的调用中重复出现类似的单词、短语以及单词、短语和各种词类的组合。    提交人    /u/debraj135   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ezv7of/discussion_weird_patterns_in_llm_generations_when/</guid>
      <pubDate>Sat, 24 Aug 2024 02:53:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] TurboEdit：即时基于文本的图像编辑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eztooi/r_turboedit_instant_textbased_image_editing/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eztooi/r_turboedit_instant_textbased_image_editing/</guid>
      <pubDate>Sat, 24 Aug 2024 01:33:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最适合微调的小型开源 LLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ezhcoe/d_best_small_opensource_llms_for_finetuning/</link>
      <description><![CDATA[我正在为公司开展一个项目，我将在合成数据集（我也将创建该数据集）上微调小型 LLM。目前，我正在考虑 Llama-3-8b 或 Mistral Nemo 等模型，由于其声誉良好，我略微偏爱 Llama-3-8b。由于模型开发进展如此之快，我正在寻找最新的建议。这可以看作是 8 个月前这篇类似帖子的后续。 我还注意到 OpenAI 最近发布了一系列微调模型，但对于这个项目，我们专门寻找开源选项。 TL;DR：您对 2024 年用于微调的最佳小型开源模型有何建议？任何有关创建合成数据集的建议也将不胜感激。谢谢！    提交人    /u/Random-Machine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ezhcoe/d_best_small_opensource_llms_for_finetuning/</guid>
      <pubDate>Fri, 23 Aug 2024 16:38:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 中的稳健性/可靠性问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ez60wf/d_robustnessreliability_issues_in_llms/</link>
      <description><![CDATA[我一直在尝试将 LLM 集成到我的工作流程中并实际构建产品。对于前者，它们根本不可靠/有时会产生幻觉，而对于后者，它们不够强大，我无法围绕它们设计任何有用的东西。 这个领域有任何研究/行业解决方案吗？    提交人    /u/latentnumber   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ez60wf/d_robustnessreliability_issues_in_llms/</guid>
      <pubDate>Fri, 23 Aug 2024 06:43:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 输血：使用一个多模态模型预测下一个标记并扩散图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ez422y/r_transfusion_predict_the_next_token_and_diffuse/</link>
      <description><![CDATA[Transfusion 在单一模型中统一了文本和图像生成，可与专门的架构相媲美。    提交人    /u/AhmedMostafa16   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ez422y/r_transfusion_predict_the_next_token_and_diffuse/</guid>
      <pubDate>Fri, 23 Aug 2024 04:37:19 GMT</pubDate>
    </item>
    <item>
      <title>torch.argmin() 非可微性解决方法 [R][D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ez2ygd/torchargmin_nondifferentiability_workaround_rd/</link>
      <description><![CDATA[我正在实现一个基于地形约束的神经网络层。该层可以被认为类似于 2D 网格图，或者基于深度学习的自组织图。它由 4 个参数组成，即高度、宽度、潜在维数和 p 范数（用于距离计算）。每个单元/神经元的维数等于潜在维数。此类的最简代码为： class Topography(nn.Module): def __init__( self, latent_dim:int = 128, height:int = 20, width:int = 20, p_norm:int = 2 ): super().__init__() self.latent_dim = latent_dim self.height = height self.width = width self.p_norm = p_norm # 创建包含索引 2D 坐标的 2D 张量 locs = np.array(list(np.array([i, j]) for i in range(self.height) for j in range(self.width))) self.locations = torch.from_numpy(locs).to(torch.float32) del locs # 线性层的可训练权重 - self.lin_wts = nn.Parameter(data = torch.empty(self.height * self.width, self.latent_dim), require_grad = True) # 高斯初始化，平均值 = 0 且 std-dev = 1 / sqrt(d)- self.lin_wts.data.normal_(mean = 0.0, std = 1 / np.sqrt(self.latent_dim)) def forward(self, z): # L2 标准化 &#39;z&#39; 将其转换为单位向量- z = F.normalize(z, p = self.p_norm, dim = 1) # 每个输入到所有 SOM 单元的成对平方 L2 距离（L2 范数距离）- pairwise_squaredl2dist = torch.square( torch.cdist( x1 = z, # 还将所有 lin_wts 转换为单位向量- x2 = F.normalize(input = self.lin_wts, p = self.p_norm, dim = 1), p = self.p_norm ) ) # 对于每个输入 zi，计算“lin_wts”中的最近单元 - nearest_indices = torch.argmin(pairwise_squaredl2dist, dim = 1) # 获取 2D 坐标索引 - nearest_2d_indices = self.locations[closest_indices] # 计算最近单元和其他每个单元之间的 L2 距离 - l2_dist_squared_topo_neighb = torch.square(torch.cdist(x1 = nearest_2d_indices.to(torch.float32), x2 = self.locations, p = self.p_norm)) del nearest_indices, nearest_2d_indices return l2_dist_squared_topo_neighb, pairwise_squaredl2dist  对于给定的输入“z”（比如编码器的输出） ViT/CNN），它计算距离最近的单元，然后使用径向基函数核/高斯（逆）函数在该最近单元周围创建地形结构——在下面的&quot;topo_neighb&quot; 张量中完成。 由于&quot;torch.argmin()&quot;给出类似于独热编码向量的索引，这些向量根据定义是不可微的，我正在尝试创建一个解决方法： # 2D 单元数 - height = 20 width = 20 # 每个单元的维数指定为 - latent_dim = 128 # 使用 L2-norm 进行距离计算 - p_norm = 2 topo_layer = Topography(latent_dim = latent_dim, height = height, width = width, p_norm = p_norm) optimizer = torch.optim.SGD(params = topo_layer.parameters(), lr = 0.001, influence = 0.9) batch_size = 1024 # 创建一个输入向量 - z = torch.rand(batch_size, latent_dim) l2_dist_squared_topo_neighb, pairwise_squaredl2dist = topo_layer(z) # l2_dist_squared_topo_neighb.size(), pairwise_squaredl2dist.size() # (torch.Size([1024, 400]), torch.Size([1024, 400])) curr_sigma = torch.tensor(5.0) # 计算相对于最近单元的高斯拓扑邻域结构- topo_neighb = torch.exp(torch.div(torch.neg(l2_dist_squared_topo_neighb), ((2.0 * torch.square(curr_sigma)) + 1e-5))) # 计算地形损失- loss_topo = (topo_neighb * pairwise_squaredl2dist).sum(dim = 1).mean() loss_topo.backward() optimizer.step()  现在，成本函数的值发生了变化，减少。另外，作为健全性检查，我正在记录&quot;topo_layer.lin_wts&quot; 的 L2 范数，以反映其权重正在使用梯度进行更新。 这是正确的实现，还是我遗漏了什么？    提交人    /u/grid_world   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ez2ygd/torchargmin_nondifferentiability_workaround_rd/</guid>
      <pubDate>Fri, 23 Aug 2024 03:36:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪个行业的数据最差？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyj7vq/d_what_industry_has_the_worst_data/</link>
      <description><![CDATA[好奇地想听听——您认为哪个行业的 ML 数据质量一贯最差？ 我说的不是没有现实和可预见的 ML 应用的个别工作，比如木工。我说的是更大的行业，银行业、制药业、电信业、科技业（可能有点广泛）、农业、采矿业等等。 谁是陷得最深的？    提交人    /u/Standard_Natural1014   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyj7vq/d_what_industry_has_the_worst_data/</guid>
      <pubDate>Thu, 22 Aug 2024 13:23:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 18 Aug 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>