<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Fri, 05 Jul 2024 18:19:02 GMT</lastBuildDate>
    <item>
      <title>[D] 如何追踪一段时间内的文本分类准确性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw4mfa/d_how_do_you_track_the_accuracy_of_text/</link>
      <description><![CDATA[^ 标题    提交人    /u/Different-General700   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw4mfa/d_how_do_you_track_the_accuracy_of_text/</guid>
      <pubDate>Fri, 05 Jul 2024 18:18:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 建模和学习物体之间的相似性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw46vp/d_modelling_and_learning_similarity_between/</link>
      <description><![CDATA[我对相似性建模很感兴趣。我有一组 (a, b) 对的数据集，它们的相似性 (y) 介于 0 和 1 之间，数据集很小，并且此应用程序不存在高质量的嵌入（不是图像或文本）。如果没有，我只会嵌入 + 余弦距离。 我可以将 [a,b] 对连接起来并构建回归模型，但会失去函数的对称性 (f(a,b)=f(b,a))。 什么样的模型/层/损失函数对相似性建模有用？    提交人    /u/prof_in_progress   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw46vp/d_modelling_and_learning_similarity_between/</guid>
      <pubDate>Fri, 05 Jul 2024 18:00:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 受限解码作为状态导航？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw2pqo/d_constrained_decoding_as_stateful_navigation/</link>
      <description><![CDATA[在实现 LLM 驱动的代理时，存在一系列方法，具体取决于“包装”程序尝试构造、控制或处理 LLM 的输入和输出的程度。一种方法涉及包装程序解析 LLM 的输出，并且为了使此过程更可靠，LLM 的解码器被限制为特定语法（例如 XML 或 JSON）或甚至特定的 XML 或 JSON 模式。 将解码器限制为您当前需要的语法通常是通过将违反语法的潜在输出值的概率归零来实现的。但是，如果 LLM 没有接受过针对您尝试执行的语法的任何特定培训，则此策略可能不是最佳的。 让我们以一个非常简单的语法为例。此语法中的有效字符串以双引号字符开头和结尾。字符串内部有两个字符必须“转义”：反斜杠和双引号。转义序列以反斜杠开头。 合法：“John 说，\&quot;This is a legal string.\&quot;。&quot; 合法：“John 说，&quot; 非法：“John 说，&quot;This string makes me sad.&quot;&quot; 如果我们将解码器视为“试图”用其输出表示某些编码向量，则它只有在“提前计划”一点点的情况下才能在此语法中这样做。它可能“想要”发出一个双引号字符，并且无论之前的内容是什么，语法都允许这样做。但是，如果该双引号字符前面没有反斜杠，则字符串必须在双引号之后立即结束，以使字符串合法。如果它“想要”发出双引号但不结束，它需要“知道”它不想在不久的将来结束并且为了不结束，它需要先发出反斜杠。 那么如何获得这种有计划的解码 - 理想情况下，同时能够使用尽可能接近现成的预训练 LLM？我不确定，但我有一个模糊的想法，我想知道社区会对此有何看法。 假设我们可以访问预训练的 LLM，包括中间层的激活。我们还有我们想要限制输出的语法，以图形的形式，其边缘标有潜在输出*。最后，我们有一个独热向量，指示解码过程当前位于语法图中的哪个节点（或者，对于语法的非确定性表示，是一个 k-hot 向量）。 来自预训练 LLM 的激活可用于为语法图的边缘分配“朴素可取性”。但是，出现了两个考虑因素：  要遍历的最理想边可能与当前状态无关。要到达那些边，我们可能需要遍历其他边（这可能需要我们发出其他输出标记）。在语义层面上，这“可以”吗？例如，某些恶意语法可能要求任何单词​​“dogs”的实例前面都有单词“absolutely no”。如果我到目前为止已经解码了“I love”，并且到达了“dogs”是可取的，我不想越过需要“绝对不”的语法边缘，否则我最终会说“我绝对不爱狗”。  在我们最终确定要发出的标记并将我们移动到语法图中的新节点之后，这是一个可以考虑我们可能还剩下什么需要解码的地方吗？  这些考虑让我认为通过语法表达 LLM 的编码含义就像玩 Metroidvania 式的游戏，其中不同的路径具有不同的成本和回报。不幸的是，我几乎没有灵活的游戏模型背景，所以我不确定从这一点开始要学习什么等（假设这首先是一条值得的攻击路线......）    提交人    /u/jpfed   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw2pqo/d_constrained_decoding_as_stateful_navigation/</guid>
      <pubDate>Fri, 05 Jul 2024 16:57:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 发布我基于 VGG 感知损失的损失函数。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw2dfb/p_releasing_my_loss_function_based_on_vgg/</link>
      <description><![CDATA[您好，这是我已经做了一段时间的项目。我使用“VGG Loss”在我的某些项目中，我一直觉得从一个模型中提取信息来训练另一个模型很有趣。 以此为灵感，我创建了这个项目，它允许您使用几乎任何来自 PyTorch 的预训练模型作为训练新模型的基础。 在代码中，您可以找到一个使用 DINOv2 作为损失函数（扮演 VGG 的角色）的示例，但该函数旨在接受除 Dino 之外的任何其他模型，甚至不接受图像作为输入的模型，例如 LLM 或任何其他模型。 这是一个专门为我在我的项目中使用和共享而开发的项目，所以我没有附加任何文章，它的大部分逻辑都是在我的项目中使用时通过反复试验开发出来的。 在 GitHub 描述中，有更多关于它的信息。我希望这个项目对某些人有用。 https://github.com/BurguerJohn/global_perceptual_similarity_loss     提交人    /u/CloverDuck   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw2dfb/p_releasing_my_loss_function_based_on_vgg/</guid>
      <pubDate>Fri, 05 Jul 2024 16:43:14 GMT</pubDate>
    </item>
    <item>
      <title>[D],[R]这是真的吗，在 O(log n) 中顺序处理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw0to6/dris_this_true_sequential_processing_in_olog_n/</link>
      <description><![CDATA[有一篇学生的中等文章声称他的架构可以完成循环处理器（RNN）和变压器的工作，还讨论了如何将其用于图像生成。他的代码看起来有效且正确。 他声称构建了一个表现优于 distil-gpt 的 LLM，即使参数数量只有传统 LLM 的一半，而且训练方式也不尽相同。 我有个问题：这有什么新鲜的吗？ 阅读时间为 5 分钟。 文章链接：https://medium.com/@DakshishSingh/equinox-architecture-divide-and-compute-99c555ac08d6    提交人    /u/Conscious-Gazelle-91   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw0to6/dris_this_true_sequential_processing_in_olog_n/</guid>
      <pubDate>Fri, 05 Jul 2024 15:35:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mapper（Mapper算法）区分噪声和显著拓扑结构的能力的理论极限是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvzsy8/d_what_are_the_theoretical_limits_of_mappers/</link>
      <description><![CDATA[大家觉得怎么样？    提交人    /u/ICEpenguin7878   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvzsy8/d_what_are_the_theoretical_limits_of_mappers/</guid>
      <pubDate>Fri, 05 Jul 2024 14:50:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 推荐一些关于模型合并的好资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvzr9d/d_suggest_any_good_resources_for_model_merging/</link>
      <description><![CDATA[我知道有合并模型的工具，但我想要一些关于合并模型的理论材料。任何讨论如何合并模型的博客、文章或研究论文都会有所帮助。 我将不胜感激您的帮助 :) 谢谢    提交人    /u/Ok_Cartographer5609   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvzr9d/d_suggest_any_good_resources_for_model_merging/</guid>
      <pubDate>Fri, 05 Jul 2024 14:48:53 GMT</pubDate>
    </item>
    <item>
      <title>[R]，[D]，我想开发一个机器学习算法（我解释得很详细，请查看）并通过 DSP STM32F407G 应用它</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvxl3w/r_d_i_want_to_develop_a_machine_learning/</link>
      <description><![CDATA[大家好， 问题：我正在使用一种仪器，我们经常遇到频率丢失的问题，即频率信号突然丢失，即变为零，这会导致数据丢失，如下图所示。黄色是从光电探测器接收到的频率信号，紫色是解调数据（我们想要的输出）。当频率变为零时，紫线保持不变，因此数据丢失。 https://preview.redd.it/h2t0hnne8pad1.png?width=1026&amp;format=png&amp;auto=webp&amp;s=a89f72406f0df90d77f24b412c7b533373512f14 解决方案： 为了解决这个问题，我心里有一个解决方案，即我应该开发一种基于机器学习或 Python 的算法其工作原理如下， 当数据没有丢失时，即当频率不为零且等于（我的期望频率假设为 100Hz）时，微处理器的输出应为零。 如果检测到 0 频率，则输出应为前一个频率，即 100Hz 的输出。通过这种方式，我想将数据存储在缓冲区中，当需要时（在 0 Hz 时）应使用缓冲区数据。 我脑海中的想象是我的代码将有两个输入，即黄色和紫色，一个输出紫色。 紫色将存储在缓冲区中微秒或秒。 将持续监控黄色值，如果检测到 0 频率，则输出先前的缓冲区值，否则输出应为 0。 为此，我的整个电路都是模拟的，我将使用 DSP STM32F407G 微处理器完成所需的任务，我将仅创建模拟求和电路来添加信号。 我对这个机器学习或编码程序还不熟悉，所以我需要你的助手帮助我开发我想要的解决方案的算法。 真诚的。 Umair &quot;[研究]&quot;, &quot;[R]&quot;, &quot;[讨论]&quot;、&quot;[D]&quot;    提交人    /u/umair1181gist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvxl3w/r_d_i_want_to_develop_a_machine_learning/</guid>
      <pubDate>Fri, 05 Jul 2024 13:08:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] TensorFlow 概率的 torch 等价性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvwfov/p_torch_equivalence_of_tensorflow_probability/</link>
      <description><![CDATA[大家好， 我已经使用 tensorflow 很多年了，但对 pytorch 的经验有限。我正在考虑在 pytorch 上构建我的下一个项目。有没有人有在 pytorch 中进行近似推理的经验，有没有 tensorflow 概率的等效包？ 谢谢！    提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvwfov/p_torch_equivalence_of_tensorflow_probability/</guid>
      <pubDate>Fri, 05 Jul 2024 12:08:19 GMT</pubDate>
    </item>
    <item>
      <title>ECCV 相机就绪论文 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvvzpm/camera_ready_paper_for_eccv_discussion/</link>
      <description><![CDATA[嗨， 我的论文被 ECCV 接受了，在反驳期间，我们从审稿人那里得到了很多有用的反馈。我们想把它们包括在主论文中，但超出了 14 页的限制。为了解决这个问题，我们想将一个消融研究图表和讨论从主论文移到补充材料中。当然，我们会在主图中引用它，但允许吗？    提交人    /u/dn8034   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvvzpm/camera_ready_paper_for_eccv_discussion/</guid>
      <pubDate>Fri, 05 Jul 2024 11:43:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否应该从整个数据集中删除异常值，还是仅从训练集中删除？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvupyf/d_should_outliers_be_removed_from_the_full/</link>
      <description><![CDATA[我想删除异常值以检查它是否可以改进我的模型。 我应该在整个数据集上还是仅在训练数据集上删除它们？ 如何使用欠采样来平衡我的数据集？应该在整个数据集上进行平衡还是仅在训练集上进行平衡？    提交人    /u/fabiopires10   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvupyf/d_should_outliers_be_removed_from_the_full/</guid>
      <pubDate>Fri, 05 Jul 2024 10:22:26 GMT</pubDate>
    </item>
    <item>
      <title>[P] 情绪分类与分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvrpbs/p_emotion_classification_analysis/</link>
      <description><![CDATA[大家好， 我想分享我使用 flask 构建的关于机器学习的项目，用户可以在其中表达自己的情感并进行以下分类（悲伤、快乐、爱、愤怒、恐惧、惊讶）。我们使用 CNB 模型进行文本分类，准确率为 88%。 你可以在这里尝试： https://emotionclassification.pythonanywhere.com 注意： 预测可能会遇到意外的表情结果。 源代码：  Github：https://github.com/nordszamora/Emotion-Expression     提交人    /u/ThePawners   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvrpbs/p_emotion_classification_analysis/</guid>
      <pubDate>Fri, 05 Jul 2024 06:51:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] Grad-CAM 医学成像可视化问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvkg4j/r_problems_with_gradcam_visualization_for_medical/</link>
      <description><![CDATA[嗨，我在灰度胸部热图数据集上训练了一些 ImageNet 模型来检测异常后，使用了 grad-CAM 可视化。但是，几乎所有网络都关注无关特征，如手臂、肩膀、胸部下方等，除了相关区域（胸部）之外的所有区域。我甚至尝试过裁剪图像，但效果并不明显，因为它仍然关注随机点。我们如何才能强制模型关注胸部？此外，尽管我获得了很高的准确率，但模型关注无关特征（如 Grad-CAM 所见）这一事实是否会使我的结果无效？  更新：对于一个模型，在第 5 个训练阶段，它实际上显示了比第 10 个训练阶段更相关的可视化（胸部区域）……不确定发生了什么    由    /u/Low-Literature-9699  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvkg4j/r_problems_with_gradcam_visualization_for_medical/</guid>
      <pubDate>Thu, 04 Jul 2024 23:37:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 杰出机器学习工程师的稀有技能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dv2thm/d_rare_skills_of_execptional_ml_engineers/</link>
      <description><![CDATA[大家好，ML 社区！ 无论你的头衔是什么（DS/工程经理/工程总监/ML 工程...），你工作场所中的 ML 工程师拥有哪些罕见技能，使他们真正从其他人中脱颖而出（在软技能和硬技能领域）？如果可能的话，请说明你的立场——不同角色如何看待这个话题可能会很有趣。 谢谢！    提交人    /u/Avistian   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dv2thm/d_rare_skills_of_execptional_ml_engineers/</guid>
      <pubDate>Thu, 04 Jul 2024 09:29:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>