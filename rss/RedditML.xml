<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 23 Jan 2024 09:14:14 GMT</lastBuildDate>
    <item>
      <title>关于当前“人工智能”浪潮的道德问题，有两件事让我非常困扰：“学习”论点和版权（主要是法学硕士）[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dkczu/2_things_that_greatly_bother_me_about_the_ethics/</link>
      <description><![CDATA[学习争论和版权缺乏。  “学习”  拥有既得金钱利益的人认为这些算法像人类一样“学习”。但这显然不是学习，而是“只是”学习。对大量数据进行奇特的统计——具有开创性和革命性，但没有创造出任何情报。垃圾进来，垃圾出去——聪明但连贯。但即使我们假设机器“学习” - 那么他们不应该被赋予人权和自由吗？我的意思是，我不知道有任何其他非生命有机体能够学习，因此真正能够学习的东西一定是有生命的。这引出了我的第二个论点......  版权  这些机器几乎可以消耗几个月内存在的所有数字化人类输出，然后反刍数十亿个本质上是它的副本。新颖，经过大量修改，但只是复制品。这台机器可以生成一些新颖的排列，例如图像，但它们无法产生任何真正新颖的东西，因为它们不知道如何制作，直到获得训练数据为止。什么人可以在 6 个月内研究现有的所有书籍（数字化），然后在几年内生产出数十亿本？当然，这一切的规模都应该考虑在内。因为他们“学习” “就像人类一样”，显然这都是合理使用，不构成侵犯版权。但显然这都是错误的，因为如果你试图生成一些有大量版权律师支持的材料，比如说迪士尼版本的米老鼠或任天堂的东西，你很快就会收到停止通知和通知。停止信。但如果你是一个相对不知名的艺术家，或者没有钱去对抗它，那么这是公平的游戏，算法只是“学习”的。从你的工作中“像人一样”艺术被“民主化”了。更重要的是，显然在不久的将来，误导你友好的邻居人工智能抓取工具，让你认为你的工作不是这样的东西将是非法的https://news.ycombinator.com/item?id=38615280，例如画一个苹果，但加入一些对抗性像素，让人工智能认为它是一辆汽车。 注意：我并不是贬低机器学习。我认为这是一个伟大的领域，有许多有用的潜在应用。我只是不喜欢公司吸收数百万人的所有创意成果，从中获利，不提供公平的补偿，甚至没有选择退出的能力（无论如何这是不可验证的，所以祝你好运），然后说不再需要创造性工作，从而导致失业，甚至（很快）将任何人反对其令人发指的行为定为非法。 &lt;!-- SC_ON - -&gt;  由   提交 /u/LegatusDivinae   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dkczu/2_things_that_greatly_bother_me_about_the_ethics/</guid>
      <pubDate>Tue, 23 Jan 2024 09:11:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何用噪声数据集训练模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dkc1m/d_how_to_train_model_with_noise_dataset/</link>
      <description><![CDATA[我想知道如何使用噪声数据集进行测试和训练。 我是否在训练数据集中添加噪声并使用没有噪音，或者相反？ 如果有人可以提供与此相关的相关资源，那将会很有帮助。  &amp;# 32；由   提交 /u/abystoma   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dkc1m/d_how_to_train_model_with_noise_dataset/</guid>
      <pubDate>Tue, 23 Jan 2024 09:09:30 GMT</pubDate>
    </item>
    <item>
      <title>[N] PRILoRA：修剪和等级增加的低等级适应</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/</link>
      <description><![CDATA[PRILoRA 的核心概念涉及背离为模型中的每一层分配统一的低等级的传统做法。相反，他们提出了一种跨层线性增加的动态分配。这确保了更接近输入的层接收较低的排名，而较深的层被分配更高的排名。例如，在基于 DeBERTaV3 的模型中，他们没有为每一层统一分配 8 的等级，而是从第一层的 4 等级开始，逐步提高，直到最深层的等级为 12。这种微妙的分配，平均为 8，产生优异的结果。他们将这种改进归因于这样的观察：语言模型 (LLM) 中的较低层处理更直接和语法的抽象，而更深的层处理语义和复杂元素。在对特定任务进行微调期间，对深层的关注变得至关重要，因为较低层以类似的方式处理单词，但输出需要与较高层表示保持一致。通过区分各层之间的资源分配，它们获得了增强的结果。 此外，它们的微调过程包括根据考虑输入的绝对权重值和累积统计数据的标准重置 A 矩阵中的特定权重分布到层。这种方法针对不太重要的权重，从而提高模型性能。 当应用于基于 DeBERTaV3 的模型时，所提出的方法在 GLUE 基准上优于最先进的方法 (SOTA)。  p&gt; 要全面了解该工作，请参阅全文：https://arxiv.org/pdf/ 2401.11316.pdf   由   提交/u/generous-blessing  /u/generous-blessing  reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/</guid>
      <pubDate>Tue, 23 Jan 2024 09:06:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] 状态空间模型：一种现代方法 作者：Kevin Murphy、Scott Linderman 等人。 （未完待续）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dg8f0/p_state_space_models_a_modern_approach_by_kevin/</link>
      <description><![CDATA[ 这是一本关于状态空间模型 (SSM) 的交互式教科书，使用 JAX Python 库。其他书籍中涵盖了某些内容，例如 [Sar13] 和 [Mur23]。然而，我们会更详细地讨论如何利用自动微分和并行计算方面的最新进展，在“现代”计算环境中有效地实现各种算法。  在线阅读   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dg8f0/p_state_space_models_a_modern_approach_by_kevin/</guid>
      <pubDate>Tue, 23 Jan 2024 04:42:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么研究生或博士后所做的工作在简历上被低估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19df2gx/d_why_is_work_done_as_a_graduate_student_or/</link>
      <description><![CDATA[学术申请行业职位，在我的特定领域拥有新颖的数据分析和机器学习应用的强大出版记录。可以高度转化为工业的技能。对于任何在 R1 完成博士学位的人来说，您都了解与博士学位相关的无形资产。 我被告知并得到普遍的感觉，即使我们已经证明（发布）了我们领导项目的能力从概念到产品，并展示我们在 PI、政府机构和其他行业合作伙伴的压力下工作无数小时的能力，我们的经验价值较低或仅被视为学校作业而不是“真实”经验。 有人知道为什么吗？ 我们如何更好地向招聘人员传达我们的无形和有形价值？   由   提交/u/dcoceans11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19df2gx/d_why_is_work_done_as_a_graduate_student_or/</guid>
      <pubDate>Tue, 23 Jan 2024 03:38:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有一篇论文是审稿人成为作者之一的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19deoqg/d_is_there_a_paper_that_a_reviewer_becomes_one_of/</link>
      <description><![CDATA[我记得有一篇论文在第一轮就被拒绝/撤回了。一位审稿人提出了更好更快的算法，于是作者连接到 AC 看看是否可以合作，最后审稿人成为作者之一。 你还记得论文是什么吗？  p&gt;   由   提交 /u/Spico197   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19deoqg/d_is_there_a_paper_that_a_reviewer_becomes_one_of/</guid>
      <pubDate>Tue, 23 Jan 2024 03:18:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 3d RL 模拟如何工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ddujn/d_how_do_3d_rl_simulations_work/</link>
      <description><![CDATA[不知道这个问题是否幼稚，但我一直在看一些旧论文/博客，OpenAI 捉迷藏，或者谷歌代理使用模拟的房间和物体或山丘之王进行工作。每个机器人也总是有一只带有 3D 图的手臂，可以抓取立方体或其他东西。所有这些是如何运作的？人们如何同时运行游戏和 PPO？这在云上也可能吗？它们如何加速游戏？ 我确实发现了 Unity ML 代理，但我不认为 3D 需要所有的 Unity 膨胀才能工作。 还有一方面请注意，我注意到的一件事是它们都使用大约 1000 个 GPU。我可以运行较小规模的任何东西，或者像 PPO 那样不会导致计算成瘾的 RL 方法吗？   由   提交/u/vatsadev  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ddujn/d_how_do_3d_rl_simulations_work/</guid>
      <pubDate>Tue, 23 Jan 2024 02:36:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您希望看到什么 AI/ML 开源工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19daupj/d_what_aiml_opensource_tool_would_you_love_to_see/</link>
      <description><![CDATA[我正在考虑开发一个免费/开源的 AI/ML 工具，很多人都会觉得有用。  您认为很多人会对哪种很酷、简单的 AI/ML 工具感兴趣？    由   提交/u/Sellagen-DataMarket  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19daupj/d_what_aiml_opensource_tool_would_you_love_to_see/</guid>
      <pubDate>Tue, 23 Jan 2024 00:13:01 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以在其回复中隐藏任意不可检测的信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</link>
      <description><![CDATA[ 由   提交/u/LuvIsOurResistance  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</guid>
      <pubDate>Mon, 22 Jan 2024 22:32:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新理论表明聊天机器人可以理解文本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</link>
      <description><![CDATA[文章链接：https://www.quantamagazine.org/new-theory-suggests-chatbots-can-understand-text-20240122/ 链接到论文 1：https://arxiv.org/abs/2307.15936 摘要：  当今人工智能产品的一个主要驱动力是，当参数集和训练语料库扩大时，语言模型中就会出现新的技能。人们对这种现象知之甚少，并且通过基于梯度的训练的数学分析来进行机械解释似乎很困难。当前的论文采用了不同的方法，使用著名的（和经验的）法学硕士缩放定律和简单的统计框架来分析涌现。贡献包括： (a) 一个统计框架，将法学硕士的交叉熵损失与语言任务的基本技能能力联系起来。 (b) 数学分析表明，缩放定律暗示了一种强烈的归纳偏差形式，使得预训练模型能够非常有效地学习。我们非正式地将其称为“弹弓泛化”，因为天真地认为它似乎给出了违反通常泛化理论的技能的能力水平。 (c) 弹弓泛化的一个关键例子，执行涉及 k 元组技能的任务的能力基本上以与基本技能本身的能力相同的规模和速度出现。  Link论文 2：https://arxiv.org/abs/2310.17567 摘要：  随着法学硕士的角色从语言统计建模转变为通用人工智能代理，法学硕士的评估应该如何改变？可以说，人工智能代理的一项关键能力是根据需要灵活组合其所学的基本技能。结合技能的能力在（人类）教育学以及关于涌现现象的论文中发挥着重要作用（Arora &amp; Goyal，2023）。这项工作引入了 Skill-Mix，这是一种衡量组合技能能力的新评估。使用 N 个技能的列表，评估者重复选择 k 个技能的随机子集，并要求法学硕士生成结合该技能子集的文本。由于子集的数量像 Nk 一样增长，因此即使是适度的 k，此评估也很有可能要求法学硕士生成与训练集中的任何文本显着不同的文本。该论文开发了一种方法，用于 (a) 设计和管理此类评估，以及 (b) 使用 GPT-4 以及开放的 LLaMA-2 70B 模型对结果进行自动分级（加上人工抽查）。管理流行聊天机器人的一个版本所得到的结果虽然总体上符合之前的预期，但也包含了令人惊讶的结果。模型能力之间存在相当大的差异，而这些差异并没有通过它们在流行的 LLM 排行榜上的排名来体现（“临时抱佛脚排行榜”）。此外，简单的概率计算表明GPT-4在k＝5上的合理性能暗示超越“随机鹦鹉”性能。行为（Bender 等人，2021），即它以训练期间未曾见过的方式组合技能。我们概述了该方法如何形成基于技能组合的生态系统，对未来模型的人工智能功能进行开放评估。    由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</guid>
      <pubDate>Mon, 22 Jan 2024 21:54:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前理论机器学习作为一个领域有什么意义吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</link>
      <description><![CDATA[随着 SOTA 架构不断变化的极快速度，可能的 DL 技术（正则化、所有不同的激活和损失函数）的多样性如下：以及对可解释人工智能相对退居二线的担忧，现在从事理论机器学习工作有什么用处吗？ 大多数 SOTA 架构似乎只是大规模扩展的高级猜测和检查，而且它确实有效就基准性能而言，我们是否需要 ML/DL 理论？   由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</guid>
      <pubDate>Mon, 22 Jan 2024 20:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们没有看到很多关于 Mamba 架构的内容？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cwf65/d_why_were_not_seeing_a_lot_of_content_about/</link>
      <description><![CDATA[比如对作者的一些采访？还没有看到例如TWIML AI 播客谈论 Mamba 架构。   由   提交/u/_learning_stuff_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cwf65/d_why_were_not_seeing_a_lot_of_content_about/</guid>
      <pubDate>Mon, 22 Jan 2024 14:07:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 超越变形金刚：结构化状态空间序列模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cv8q6/d_beyond_transformers_structured_state_space/</link>
      <description><![CDATA[撰写了一篇文章，解释了状态空间序列模型的基础知识。本文的目的是以简化的方式呈现基础级别的概念。该领域在人工智能领域正在迅速发展，因为它在速度和内存消耗方面超越了 Transformer 架构。以下是文章链接：https://cnichkawde.github.io/statespacesequencemodels.html &lt; /div&gt;  由   提交 /u/cnichkawde   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cv8q6/d_beyond_transformers_structured_state_space/</guid>
      <pubDate>Mon, 22 Jan 2024 13:07:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 chatGPT 之后，人们现在还在创建自己的新的自定义 NLP 模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cqde6/d_after_chatgpt_are_people_still_creating_their/</link>
      <description><![CDATA[对使用 scikit-learn 和 Tensorflow 训练 ML 和 DL 模型有点脱节。只是想知道 ML 工程师是否仍在训练他们自己的 NLP 模型（甚至 CV、预测、聚类模型等）。 如果是这样，您正在训练什么类型的模型？您正在解决哪些用例？如果您用 ChatGPT 替换自定义模型，进展如何？ 我想重新熟悉 ML 生态系统。很想听听您的想法。   由   提交 /u/automatonv1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cqde6/d_after_chatgpt_are_people_still_creating_their/</guid>
      <pubDate>Mon, 22 Jan 2024 07:41:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>