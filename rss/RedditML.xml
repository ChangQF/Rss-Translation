<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Wed, 24 Apr 2024 09:13:44 GMT</lastBuildDate>
    <item>
      <title>[N] Perplexity 融资轮估值达 10 亿美元！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbssg1/n_perplexity_is_valued_at_1_billion_in_funding/</link>
      <description><![CDATA[今日人工智能新闻 - 2024 年 4 月 23 日 以下是当前正在发生的事情的快速浏览当今的人工智能世界：  Perplexity，一家人工智能搜索初创公司，在一轮融资中估值达 10 亿美元 微软推出更小的人工智能模型以吸引更广泛的客户群 Google 支持的 Glance 在美国试点 Android 锁屏平台 人工智能通过空白面孔预测政治倾向，引发隐私问题  赶上当今的人工智能2 分钟新闻：deepsyncs.com/ai_news_today/april-23rd-2024/   由   提交 /u/AI_Wiz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbssg1/n_perplexity_is_valued_at_1_billion_in_funding/</guid>
      <pubDate>Wed, 24 Apr 2024 08:07:58 GMT</pubDate>
    </item>
    <item>
      <title>[D]寻求建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbrm59/d_looking_for_advise/</link>
      <description><![CDATA[所以我有多个定价表，并且希望比较哪个定价最便宜，每个定价表都有自己的变量，所以我决定的方式比较它是通过使所有变量的值相等，但是出现另一个问题，即如果我更改变量值，它会如何影响定价？我正在考虑使用机器学习来解决这个问题，但似乎没有一种无监督技术适合这项任务，有人知道如何解决这个问题吗？我尝试的另一种方法是使用类似回归的算法来制作最佳拟合线，但这似乎效果不佳   由   提交/u/Separate_Molasses_73   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbrm59/d_looking_for_advise/</guid>
      <pubDate>Wed, 24 Apr 2024 06:44:12 GMT</pubDate>
    </item>
    <item>
      <title>个人项目 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbrg2b/personal_project_p/</link>
      <description><![CDATA[我三周后就要毕业了，我正在考虑在我的 GitHub 上展示这个随机的东西。我的想法是建立远程加油站（就像加油车）。该计划是获取一个区域的交通数据集并分析一周中所有天的数据。创建热图，然后在地图上绘制现有加油站。现在的目标是选择前 5 个交通流量大、加油站少的地方。 （假设人流量大的地区需要加油站）。我不知道从哪里开始，我的意思是除了 Kaggle 之外我还能从哪里获得数据集。有人可以帮助我集思广益我需要关注的事情吗？谢谢   由   提交/u/happyplantt  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbrg2b/personal_project_p/</guid>
      <pubDate>Wed, 24 Apr 2024 06:32:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transkribus 与 Tesseract 的手写文本识别 (HTR)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbr6h9/d_transkribus_vs_tesseract_for_handwritten_text/</link>
      <description><![CDATA[我正在寻找一种精度最高且最好不贵的 HTR 工具（显然）。根据我的研究，Transkribus 似乎是被提及最多且评价良好的平台。由于我需要定期将图像转换为文本，因此我需要支付订阅费用。所以我想知道是否可以使用 Tesseract 和/或 TensorFlow Python 库免费获得相同的结果。使用 Tesseract/TensorFlow 是否会比使用 Transkribus 更不准确？ 我只学习了机器学习的基础知识（TensorFlow、scikit-learn、keras），所以我可能没有足够的知识来了解两者之间的区别两个解决方案。或者训练 Tesseract/TensorFlow 会很有挑战性吗？   由   提交 /u/Pretty_Instance4483   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbr6h9/d_transkribus_vs_tesseract_for_handwritten_text/</guid>
      <pubDate>Wed, 24 Apr 2024 06:15:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研究人员在考虑创建新的/改进的基础模型时如何考虑归纳偏差？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbnbsd/d_how_researcher_think_of_inductive_bias_when/</link>
      <description><![CDATA[我是一名学习机器学习的本科生。 在阅读一些论文时，我了解到，我们试图通过在机器学习模型中施加归纳偏差来减少搜索空间。当归纳偏差与基础数据相匹配时，创建有用模型的成功就来了。 在 NVAE 等分层模型中，他们如何通过指定数据计算的方式来灌输归纳偏差？（我认为这叫做算法偏差，但不确定） 但人们如何认为这种归纳偏差会有所帮助，他们坚持这种归纳偏差的逐步程序是什么。 我上了很多机器学习和统计学的课，但没有上过任何解释这些内容的讲座。我是否错过了任何课程/讲座？ 如果可能，请为我提供与之相关的论文/讲座/演讲 谢谢    提交人    /u/binny_sarita   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbnbsd/d_how_researcher_think_of_inductive_bias_when/</guid>
      <pubDate>Wed, 24 Apr 2024 02:36:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态检索和排序的广义对比学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbixix/r_generalized_contrastive_learning_for_multimodal/</link>
      <description><![CDATA[对流行的 CLIP 训练方法进行概括，使其更适合搜索和推荐。  论文：https://arxiv.org/pdf/2404.08535.pdf Github：https://github.com/marqo-ai/GCL 概括CLIP：  使用任意数量的文本和/或图像来表示文档。 通过模态间和模内损失更好地理解文本。 可以对排名/重要性/相关性进行编码，又名“排名调整”。 适用于预训练、文本、CLIP 模型。 可以学习单向量或多向量表示用于文档。 适用于二进制和 Matryoshka 方法。 开源 10M 行多模态数据集，包含 100k 查询和约 5M 产品。  为什么？ 训练嵌入模型的主流方法在很大程度上与最终用例（如搜索）、向量数据库、用户的需求以及缺乏用于开发和评估的代表性数据集，特别是当涉及多种模式和排名时。 当前矢量搜索嵌入模型的局限性 尽管矢量搜索是非常强大并且可以搜索几乎任何数据，但当前的方法有一些局限性。训练嵌入模型的流行方法在很大程度上与最终用例（如搜索）、向量数据库和用户的需求脱节。这意味着矢量搜索的许多潜力尚未得到满足。下面描述了当前的一些挑战。 仅限于使用单条信息来表示文档 当前模型编码并表示一条信息一个向量的信息。现实情况是，一份文档通常有多个相关信息，这些信息可能跨越多种模式。例如，在产品搜索中可能有标题、描述、评论和多个图像，每个图像都有自己的标题。 GCL 将嵌入模型训练概括为使用所需数量的信息。 处理退化查询时没有排名概念 当存在退化查询时查询 - 满足某些相关标准的多个结果 - 结果的排序只能从许多二元关系中间接学习。实际上，结果的排序很重要，即使对于第一阶段检索也是如此。 GCL 允许在嵌入中编码查询文档特定相关性的大小，并提高候选文档的排名。 使用类似 CLIP 的方法时文本理解较差 对于像 CLIP 这样的多模态模型，这些模型经过训练只能从图像到文本（反之亦然）。由于文本-文本关系是通过图像间接学习的，文本-文本的理解不如纯文本模型。对于许多应用程序来说，需要了解模态间和模内内的情况。 GCL 允许通过直接优化来实现模态间和模内理解的任意组合。 缺乏代表性数据集来开发矢量搜索方法 在开发 GCL 的过程中，很明显，与用于嵌入模型训练和评估现实世界用例的公开数据集存在脱节。现有的基准测试通常仅是文本或仅是跨模式的，并且侧重于 1-1 查询结果范式。此外，现有数据集的相关性概念有限，大多数将其编码为二元关系，而一些数据集通常仅在测试集上使用（最多）少量离散分类。这与典型的现实世界用例不同，在典型的现实世界用例中，相关性可以是硬二元关系，也可以来自连续变量。为了帮助解决这个问题，我们编译了一个包含 10M（排名）产品查询对的数据集，涵盖约 100k 查询、近 500 万个产品和四个评估分割（可用 此处)。 ​   由   提交/u/Jesse_marqo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbixix/r_generalized_contrastive_learning_for_multimodal/</guid>
      <pubDate>Tue, 23 Apr 2024 23:07:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能在公司内部的实际应用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbhxwb/d_practical_uses_of_ai_inside_companies/</link>
      <description><![CDATA[人们如何在公司内部（初创公司 -&gt; FAANG）使用人工智能来改进运营和流程？关于利用 LLM 和 GenAI 的讨论有很多，但我正在努力寻找成功的真正具体示例。 首先想到的是以下领域，但这个列表当然并不详尽：  p&gt;  设计（和移交） 工程 客户支持 销售 文档 营销  什么有效或有希望？什么不起作用？   由   提交 /u/CJSF   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbhxwb/d_practical_uses_of_ai_inside_companies/</guid>
      <pubDate>Tue, 23 Apr 2024 22:25:43 GMT</pubDate>
    </item>
    <item>
      <title>Meta 做了 OpenAI 应该做的一切 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbhec7/meta_does_everything_openai_should_be_d/</link>
      <description><![CDATA[我很惊讶（或者可能没有）这么说，但 Meta（或 Facebook）比 OpenAI 更民主化 AI/ML，而 OpenAI 最初是成立并主要为此目的提供资金。 OpenAI 很大程度上已经成为一个仅以盈利为目的的商业项目。虽然就 Llama 模型而言，对我来说它们尚未达到 GPT4 功能，但我相信这只是时间问题。你们对此有何看法？   由   提交 /u/ReputationMindless32   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbhec7/meta_does_everything_openai_should_be_d/</guid>
      <pubDate>Tue, 23 Apr 2024 22:03:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语音转文本字级时间戳准确性问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbd8x1/d_speech_to_text_word_level_timestamps_accuracy/</link>
      <description><![CDATA[在转录方面，我使用 Whisper 取得了很大成功，但字级时间戳似乎有点不准确。根据我的理解（“Whisper 无法提供可靠的单词时间戳，因为像 Transformer 这样使用交叉熵训练标准的 END-TO-END 模型并不是为可靠地估计单词时间戳而设计的。” https://www.youtube.com/watch?v=H576iCWt1Co&amp;t=192s）对于我的用例，我需要精确的字级别时间戳，因为我正在特定单词之后插入音频。当我进行插入并且单词的后部位于另一侧时，这会成为问题。 示例：给定一个包含已转录语音的原始音频文件，如果我想插入一个剪辑在单词“France”的末尾，根据时间戳，单词“France”位于单词“France”的末尾。从 19.26 开始，到 19.85 结束，我将在 19.85 插入剪辑。然而，如果 France 的实际结束时间是 19.92，那么当我在 19.85 插入笑声时，我将在这里剩余的“France”，可能是“ce” （0.07），最后。 我很好奇是否有人遇到过类似的问题以及他们做了什么来解决这个问题？我已经尝试了一些开源版本的 Whisper，但仍然遇到了这个问题。   由   提交/u/Mindless-Ordinary485  /u/Mindless-Ordinary485 reddit.com/r/MachineLearning/comments/1cbd8x1/d_speech_to_text_word_level_timestamps_accuracy/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbd8x1/d_speech_to_text_word_level_timestamps_accuracy/</guid>
      <pubDate>Tue, 23 Apr 2024 19:18:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 吴的方法可以将符号人工智能提升到与银牌得主和 AlphaGeometry 竞争，从而超越 IMO Geometry 金牌得主</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbd2ol/r_wus_method_can_boost_symbolic_ai_to_rival/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.06405 代码：https:// /huggingface.co/datasets/bethgelab/simplegeometry 摘要：  证明几何定理构成了视觉推理结合的标志直觉和逻辑能力。因此，奥林匹克级别几何问题的自动定理证明被认为是人类级别自动推理的一个重要里程碑。 AlphaGeometry 的推出标志着一项重大突破，这是一种用 1 亿个合成样本训练的神经符号模型。它解决了 30 个国际数学奥林匹克 (IMO) 问题中的 25 个，而基于 Wu 的方法报告的基线仅解决了 10 个。在这篇文章中，我们重新审视了 AlphaGeometry 引入的 IMO-AG-30 挑战赛，发现 Wu 的方法出奇的强大。仅吴的方法就可以解决15个问题，其中一些问题是其他任何方法都无法解决的。这导致了两个关键发现：（i）将 Wu 的方法与演绎数据库和角度、比率和距离追踪的经典综合方法相结合，仅使用仅使用 CPU 的笔记本电脑在 5 分钟的时间限制内解决了 30 种方法中的 21 种每个问题。从本质上讲，这种经典方法仅比 AlphaGeometry 少解决 4 个问题，并建立了第一个完全符号化的基线，其强度足以与 IMO 银牌得主的表现相媲美。 (ii) Wu 的方法甚至解决了 AlphaGeometry 未能解决的 5 个问题中的 2 个问题。因此，通过将 AlphaGeometry 与 Wu 的方法相结合，我们在 IMO-AG-30 上建立了一种新的最先进的自动定理证明，解决了 30 个问题中的 27 个，这是第一个超越 IMO 金牌得主的人工智能方法.    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbd2ol/r_wus_method_can_boost_symbolic_ai_to_rival/</guid>
      <pubDate>Tue, 23 Apr 2024 19:11:50 GMT</pubDate>
    </item>
    <item>
      <title>[N] Phi-3-mini 在 HuggingFace 上发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb7f9n/n_phi3mini_released_on_huggingface/</link>
      <description><![CDATA[https://huggingface .co/microsoft/Phi-3-mini-128k-instruct 技术报告中的数字看起来确实很棒，我想需要由第三方验证。 &lt; /div&gt;  由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb7f9n/n_phi3mini_released_on_huggingface/</guid>
      <pubDate>Tue, 23 Apr 2024 15:26:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何将 LLaMA 3 部署到生产中以及硬件要求</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb3ge1/d_how_to_and_deploy_llama_3_into_production_and/</link>
      <description><![CDATA[许多人都在尝试安装和部署自己的 LLaMA 3 模型，因此这里是我刚刚制作的教程，展示了如何在 AWS EC2 上部署 LLaMA 3实例：  https://nlpcloud.com/how-to-install-and-deploy-llama-3-into-product.html 部署 LLaMA 3 8B 相当容易，但部署 LLaMA 3 70B 则很困难另一个野兽。考虑到所需的 VRAM 量，您可能需要配置多个 GPU 并使用 vLLM 等专用推理服务器，以便将模型拆分到多个 GPU 上。 LLaMA 3 8B 需要大约 16GB 的磁盘空间，并且FP16 中 20GB VRAM（GPU 内存）。至于LLaMA 3 70B，它需要大约140GB的磁盘空间和160GB的FP16 VRAM。 我希望它有用，如果您有疑问，请随时询问！ 朱利安   由   提交/u/juliensalinas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb3ge1/d_how_to_and_deploy_llama_3_into_production_and/</guid>
      <pubDate>Tue, 23 Apr 2024 12:33:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为 DS/MLE 单独工作的人应该牢记哪些最佳实践和工作流程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb0fi1/d_what_best_practices_and_workflows_those_working/</link>
      <description><![CDATA[我想知道技术招聘人员或经验丰富的 DS/MLE 对像我这样的人有什么看法：良好的理论和良好的技术背景，但单独工作太长了。 我的职业生涯背景摘要：我作为 DS 工作了 8 年，前 3 年在中型研发和咨询团队（一家大型科技公司）工作，然后在过去 5 年内，作为相对成功的非人工智能初创企业的独立 DS，主要开发 ML/NLP 内容来解决特定问题或改进其产品的一项特定功能（即从来不是整个产品）。在我设计的5年里。开发和部署了 4 个模型（但尝试了许多 OFC）——以及一些仪表板和简单的流式化 POC）。  最近参加聚会，看到实际团队中的人们如何工作、讨论和交流知识，这突然让我感到震惊：我错过了，我正在变得过时。我对技术面试感觉不够敏锐，我不确定我开发和维护项目的方式是否遵循良好的标准/最佳实践（哎呀，我几乎不遵循看板，主要使用我的计划员向我的老板报告进度） 。我做了一些版本控制并记录了我放入产品中的内容，但即便如此，我也不确定我正在按照团队的预期进行操作。   由   提交/u/Melodic_Reality_646   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb0fi1/d_what_best_practices_and_workflows_those_working/</guid>
      <pubDate>Tue, 23 Apr 2024 09:40:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama-3 可能刚刚杀死了专有的人工智能模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</link>
      <description><![CDATA[完整博客文章  Meta 在三天前发布了 Llama-3，感觉开源模型终于缩小了与专有模型的差距，这已经是一个拐点。初始基准测试显示 Llama-3 70B 在许多任务中非常接近 GPT-4：  官方元页面仅显示Llama-3优于Gemini 1.5和Claude Sonnet。 人工分析显示 Llama-3 的质量介于 Gemini-1.5 和 Opus/GPT-4 之间。 关于 LMSYS 聊天机器人竞技场排行榜，Llama-3 排名第 5，而当前的 GPT-4 模型和 Claude Opus 仍并列第 1。  功能更强大Llama-3 400B+ 模型仍在训练中，发布后很可能超越 GPT-4 和 Opus。 Meta vs OpenAI 有人推测 Meta 从一开始的目标就是瞄准OpenAI 采用“焦土”方法，通过发布强大的开放模型来扰乱竞争格局并避免在竞争中落后AI 竞赛。 Meta 在计算和人才方面可能会超过 OpenAI：  OpenAI 的预计收入为 20 亿美元，并且可能无利可图。 2023 年，Meta 的收入为 $134B，利润为 $39B。 Meta 的计算资源目前可能超过 OpenAI。 开源可能会吸引更好的人才和研究人员。  &gt;  一个可能的结果是微软收购 OpenAI 以赶上 Meta。谷歌也在进军开放模型领域，并拥有与 Meta 类似的功能。看看它们适合什么位置将会很有趣。 获胜者：开发人员和人工智能产品初创公司 我最近写了一篇关于现在建立人工智能初创公司令人兴奋，因为您的产品会随着每个主要模型的进步而自动改进。随着 Llama-3 的发布，开发人员的机会更大：  不再受供应商锁定。 开发人员不仅可以封装专有 API 端点，还可以现在以一种非常经济有效且高性能的方式将人工智能深度集成到他们的产品中。 Hugging Face 上已经有超过 800 个 llama-3 模型变体，而且看起来每个人都能够针对他们的使用案例、语言或行业进行微调。 更快、更便宜的硬件：Groq 现在每秒可以生成 800 个 llama-3 代币，而成本只是 GPT 成本的一小部分。以低价提供近乎即时的 LLM 响应即将到来。  视觉和视频的开源多模式模型仍然需要迎头赶上，但我预计这很快就会发生。 Llama-3 的发布标志着人工智能民主化的一个重要里程碑，但现在宣布专有模型的消亡可能还为时过早。谁知道呢，也许 GPT-5 会让我们所有人感到惊讶，并超越我们对 Transformer 模型功能的想象。 这绝对是人工智能领域构建的超级激动人心的时代！    由   提交 /u/madredditscientist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</guid>
      <pubDate>Mon, 22 Apr 2024 15:08:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>