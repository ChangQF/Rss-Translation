<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 01 Mar 2024 15:14:30 GMT</lastBuildDate>
    <item>
      <title>[P] 利用 Damco Solutions 提供的一流数据注释服务增强您的 AI 项目！ 🎯</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3wk66/p_enhance_your_ai_projects_with_topnotch_data/</link>
      <description><![CDATA[嘿各位 Reddit 用户！ 您是否希望将您的 AI 项目提升到一个新的水平？别再犹豫了！在 Damco Solutions，我们专注于提供尖端的数据注释服务，以满足您的项目需求。 凭借我们细致的注释流程和先进的技术，我们确保高质量的标记数据集为您的 AI 算法提供支持精确和准确地执行。 为什么选择 Damco 解决方案来满足您的数据注释需求？  准确性保证：我们的专家团队确保一丝不苟注释，保证 AI 模型的准确性。 可扩展性：无论您需要注释数百个还是数百万个数据点，我们的可扩展解决方案都能满足您的需求。  定制：我们知道每个项目都是独一无二的。这就是为什么我们提供可定制的注释服务来满足您的特定要求。 质量保证：注释过程的每一步都经过严格的质量检查，确保获得一流的结果。 快速周转时间：我们重视您的时间。我们简化的流程确保快速周转时间，同时又不影响质量。 行业专业知识：凭借在各个行业的多年经验，我们带来了无与伦比的领域专业知识。  请访问我们的网站此处，了解有关我们数据注释服务的更多详细信息。 准备好增强您的人工智能项目了吗？今天就联系我们，让我们一起踏上追求卓越 AI 的旅程！ 让我们通过数据标注彻底改变未来！  &amp;# 32；由   提交/u/Soggy_Example6842   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3wk66/p_enhance_your_ai_projects_with_topnotch_data/</guid>
      <pubDate>Fri, 01 Mar 2024 15:10:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 具有动态操作集的非 RAG 回溯 GPT 代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3w4wp/p_a_nonrag_backtracking_gpt_agent_with_a_dynamic/</link>
      <description><![CDATA[      大家好，我&#39;我们一直在开发一个不依赖检索增强生成（RAG）来查找相关信息并生成响应的新框架。相反，它利用独特的文本接口 (TI)，实现与外部资源的直接 GPT-4 交互，就像我们与 GUI 交互的方式一样。 由于这种方法需要与 TI 重复交互，因此 LLM 的作用就像一个自治系统代理人。与 AutoGPT 不同，AutoGPT 的操作是预先确定的并且不会更改，操作由 TI 提供，并根据 TI 所处的状态进行更改。 https://preview.redd.it/96pqqqbjkqlc1.png?width=613&amp;format=png&amp;auto=webp&amp;s =e2ebcfdda83b091d202178ff91e0b66f9fd77de5 https ://preview.redd.it/53qh9qbjkqlc1.png?width=1082&amp;format=png&amp;auto=webp&amp;s=5c036c5d257667277c6093a927e980ac3ae9f26f 这种方法的主要局限性是：它仅使用 GPT-4，需要构建文本界面来与不同类型的资源交互。 代码：https:// github.com/ash80/backtracking_gpt  X 上的线程：https://x.com/ ash_at_tt/status/1763575975185403937 欢迎您提供反馈、建议和贡献。   由   提交/u/ashz8888  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3w4wp/p_a_nonrag_backtracking_gpt_agent_with_a_dynamic/</guid>
      <pubDate>Fri, 01 Mar 2024 14:52:51 GMT</pubDate>
    </item>
    <item>
      <title>多智能体深度 q 学习深入研究开发状态 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3ts4d/multi_agent_deep_q_learning_takes_a_dive_at/</link>
      <description><![CDATA[      我正在使用 double &amp;深度 Q 学习对决。达到 epsilon 0.01 后不久，奖励开始走下坡路。我正在尝试不同的超参数，但对任何类似的经验/想法感兴趣。  我的猜测是，由于这是一个多代理场景，因此在大部分探索阶段，代理都会在给定其他操作的随机操作的情况下学习最佳操作。一旦 epsilon 达到 0.01，其余智能体的行为（以及每个智能体的环境）就会发生变化。这就是奖励的意思。  https://preview.redd .it/fk6fpc0a1qlc1.png?width=696&amp;format=png&amp;auto=webp&amp;s=63c7a4bd1a560809cbec2099261d6abc8c2152b5   由   提交 /u/ripototo   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3ts4d/multi_agent_deep_q_learning_takes_a_dive_at/</guid>
      <pubDate>Fri, 01 Mar 2024 13:04:11 GMT</pubDate>
    </item>
    <item>
      <title>说话人识别 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3t7ls/speaker_recognition_p/</link>
      <description><![CDATA[大家好，我正在开发一个说话人识别项目，以识别说话人数据集中谁在说话。该模型在近距离环境中运行良好，我希望现在该模型还可以告诉我何时说话者未知（不是数据集的一部分）。您可以推荐哪些方法？   由   提交 /u/cestoi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3t7ls/speaker_recognition_p/</guid>
      <pubDate>Fri, 01 Mar 2024 12:33:34 GMT</pubDate>
    </item>
    <item>
      <title>一次性学习、零次学习、少次学习[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3sijd/oneshot_zeroshot_fewshot_learning_d/</link>
      <description><![CDATA[嗨！，我对这三种技术有疑问。  这些技术仅用于生成式人工智能模型还是已经开始用于传统模型的训练？ 谢谢   由   提交 /u/kalanestis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3sijd/oneshot_zeroshot_fewshot_learning_d/</guid>
      <pubDate>Fri, 01 Mar 2024 11:54:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 多层感知器与支持向量分类器的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3qhud/d_comparing_a_multilayer_perceptron_with_an/</link>
      <description><![CDATA[由于模型根本不同，如何使实现最具可比性。 我必须使用MLP 和 SVM 分类器并对它们进行比较。我是这样做的： MLP：  找到最佳架构：隐藏层和隐藏神经元的数量 执行网格搜索以确定最佳超参数 交叉验证：评估未见数据的泛化性能  SVM：  执行网格搜索以确定最佳超参数 交叉验证：评估未见数据的泛化性能  然后比较两个模型在测试数据上的性能评估 F1、召回率、精确度、混淆矩阵 我是否遗漏了一些重要的东西？   由   提交 /u/Jumpy-Wrongdoer1649    reddit.com/r/MachineLearning/comments/1b3qhud/d_comparing_a_multilayer_perceptron_with_an/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3qhud/d_comparing_a_multilayer_perceptron_with_an/</guid>
      <pubDate>Fri, 01 Mar 2024 09:47:12 GMT</pubDate>
    </item>
    <item>
      <title>L2-SVM 是否总是使用平方铰链损失而不是标准铰链损失？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3q9f9/does_l2svm_involve_always_using_the_squared_hinge/</link>
      <description><![CDATA[我看到很多论文都用标准铰链损失写了 L2-SVM 的目标函数，其他的则用平方铰链来写。这就是我困惑的地方。   由   提交 /u/PerfecttMachine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3q9f9/does_l2svm_involve_always_using_the_squared_hinge/</guid>
      <pubDate>Fri, 01 Mar 2024 09:30:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无监督数据选择的稳健指南：为特定领域的机器翻译捕获令人困惑的命名实体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3ntnj/r_robust_guidance_for_unsupervised_data_selection/</link>
      <description><![CDATA[https://arxiv.org/abs/2402.19267 摘要：利用广泛的数据集可以训练多语言机器翻译模型；然而，这些模型通常无法准确翻译专业领域内的句子。尽管获取和翻译特定领域的数据会产生高昂的成本，但高质量的翻译却是不可避免的。因此，在无人监督的情况下寻找最“有效”的数据成为降低标签成本的实用策略。最近的研究表明，可以通过根据数据量选择“适当困难的数据”来找到这些有效数据。这意味着数据不应过于具有挑战性或过于简单，特别是在数据量有限的情况下。然而，我们发现建立无监督数据选择的标准仍然具有挑战性，因为“适当的难度”可能会根据所训练的数据域的不同而有所不同。我们引入了一种新颖的无监督数据选择方法“捕获令人困惑的命名实体”，该方法采用翻译命名实体中的最大推理熵作为选择度量。动机是特定领域数据中的命名实体被认为是数据中最复杂的部分，并且应该以高置信度进行预测。当使用“专业领域韩英平行语料库”进行验证时，与现有方法相比，我们的方法可以为无监督数据选择提供强有力的指导。    由   提交/u/Capital_Reply_7838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3ntnj/r_robust_guidance_for_unsupervised_data_selection/</guid>
      <pubDate>Fri, 01 Mar 2024 06:45:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] StiefelGen：一种简单的、与模型无关的黎曼流形时间序列数据增强方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3mpli/r_stiefelgen_a_simple_model_agnostic_approach_for/</link>
      <description><![CDATA[ 由   提交 /u/NorfLandan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3mpli/r_stiefelgen_a_simple_model_agnostic_approach_for/</guid>
      <pubDate>Fri, 01 Mar 2024 05:39:16 GMT</pubDate>
    </item>
    <item>
      <title>DeepMind 推出 Hawk 和 Griffin [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3leks/deepmind_introduces_hawk_and_griffin_r/</link>
      <description><![CDATA[        由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3leks/deepmind_introduces_hawk_and_griffin_r/</guid>
      <pubDate>Fri, 01 Mar 2024 04:28:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI OSS 项目向贡献者开放？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3fmno/d_ai_oss_projects_open_to_contributors/</link>
      <description><![CDATA[我有一个大约 8 人的团队正在考虑尝试为一些 AI OSS 做出贡献，我想知道这里是否有人有任何最喜欢的项目已经受到巨大关注？我们对执行以下操作之一的 OSS 项目特别感兴趣：  让凡人能够相对经济地扩展训练或微调（当我说凡人时，我指的是我们中的凡人）没有 OpenAI 的数十亿） 更轻松、更直观地将非结构化数据（随机数据库表、pdf、网站等）转换为可随时进行微调的格式 &lt; li&gt;可用的代理（我不太相信我们已经为无监督人工智能做好了准备，所以这可能是列表中最低的代理之一，除非 OSS 领域的某些东西看起来确实很有前途） 将运行时上下文纳入 LLM，而无需对运行系统的详细信息进行配置或编程，以便您可以向 LLM 提出问题，例如“告诉我是否有任何与我认为的正常健康运行时状态相比发生了变化的情况”&lt; /li&gt; 专门针对 LLM 世界的新版本构建/部署/测试工具，使故障排除变得更加容易，因为它们更加配置驱动且 LLM 友好，并且运行时间和动态性较低？  &lt;这个列表有点像我希望帮助加速​​ LLM 驱动的开发的愿望清单，现在我想要找到正在做这些事情的 OSS 项目（有牵引力！）。有人看到什么了吗？或者如果做不到这一点，任何人都知道如何搜索它们或向谁询问它们？   由   提交/u/jonxtensen  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3fmno/d_ai_oss_projects_open_to_contributors/</guid>
      <pubDate>Thu, 29 Feb 2024 23:56:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 ViT 比 SWIN 更常用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3bhbd/d_why_is_vit_more_commonly_used_than_swin/</link>
      <description><![CDATA[我仍在四处阅读，但我读到的大多数计算机视觉论文都使用 ViT 作为其主干，而不是 SWIN 或其他类似的架构，但为什么呢？  ​ ViT 论文必须在 303M 图像 JFT 数据集上预训练他们的模型，以击败 ImageNet 上的早期卷积模型，而 SWIN 无需任何预训练即可实现更好的性能。训练。我想，如果 SWIN 以同样的方式进行预训练，即使不是更高的性能，也能在 ImageNet 上实现可比的性能，但不可否认的是，我还没有看到任何工作来验证这个想法。 ​ 这只是 ViT 优先的情况，所以现在每个人都使用它作为默认值还是还有其他原因？   由   提交 /u/PM_ME_JOB_OFFER   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3bhbd/d_why_is_vit_more_commonly_used_than_swin/</guid>
      <pubDate>Thu, 29 Feb 2024 21:10:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG-嵌入降维</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2yc4f/d_rag_dimensionality_reduction_for_embeddings/</link>
      <description><![CDATA[去年早些时候，在 GPT 4 发布期间，我读到人们对向量嵌入进行降维，特别是主成分分析，以使它们更适合 从那时起，随着 RAG 场景的发展，我就没有看到太多关于这样做的提及。 有人能阐明对 RAG 使用降维的优点吗？    由   提交 /u/BlueOrangeBerries   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2yc4f/d_rag_dimensionality_reduction_for_embeddings/</guid>
      <pubDate>Thu, 29 Feb 2024 11:40:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何一步步思考：对思维链推理的机械理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2tar4/r_how_to_think_stepbystep_a_mechanistic/</link>
      <description><![CDATA[PDF: https://arxiv.org/pdf/2402.18312.pdf  研究结果： 1. 尽管 CoT 生成的不同阶段的推理要求不同，模型的功能组件几乎保持不变。不同的神经算法被实现为类似感应电路的机制的组合。  注意力头在本体相关（或负相关）标记之间执行信息移动。这种信息移动导致了此类令牌对的明显可识别的表示。通常，这种独特的信息运动从第一层开始一直持续到中间。虽然这种现象是零样本发生的，但上下文中的示例施加压力，要求在标记之间快速混合其他特定于任务的信息。 部署多个不同的神经通路来计算答案，这也是并行的。不同的注意力头，尽管具有不同的概率确定性，将答案标记（针对每个 CoT 子任务）写入最后的残差流。 这些并行答案生成路径收集来自不同部分的答案输入的。我们发现，在生成 CoT 时，模型从生成的上下文、问题上下文以及少样本上下文中收集答案标记。这为法学硕士在回答问题时是否真正使用通过 CoT 生成的上下文这一开放性问题提供了强有力的实证答案。 我们观察到法学硕士中间存在功能性裂痕。 （LLaMA-2 7B 情况下的第 16 个解码器块），它标志着残余流内容和注意力头功能的相移。在此裂痕之前，模型主要分配通过预训练记忆的二元关联；它完全开始遵循裂痕之前和之后的背景。这很可能与仅在裂痕之前发生的本体相关性的代币混合直接相关。同样，写答案的头也只有在裂痕之后才会出现。 （错误地）从少数样本中收集答案标记的注意力头也受到模型前半部分的限制。   代码： https://github.com/joykirat18/How-To-Think-Step-by-Step   由   提交 /u/Gaussian_Kernel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2tar4/r_how_to_think_stepbystep_a_mechanistic/</guid>
      <pubDate>Thu, 29 Feb 2024 06:07:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>