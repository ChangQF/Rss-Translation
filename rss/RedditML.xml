<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 27 Dec 2024 18:21:40 GMT</lastBuildDate>
    <item>
      <title>[R] 我的自动编码变分贝叶斯（VAE）学习笔记</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hnj63a/r_my_learning_notes_for_autoencoding_variational/</link>
      <description><![CDATA[嗨， 我正在分享我在 VAE 论文 https://maitbayev.github.io/posts/auto-encoding-variational-bayes/ 上的学习笔记。它包含论文中公式的扩展证明。    提交人    /u/madiyar   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hnj63a/r_my_learning_notes_for_autoencoding_variational/</guid>
      <pubDate>Fri, 27 Dec 2024 16:53:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我收集了 100 多万条 App Store 和 Play Store 条目的数据集 – 有人感兴趣吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hnfswv/r_ive_collected_a_dataset_of_1m_app_store_and/</link>
      <description><![CDATA[大家好， 为了进行个人研究，我汇编了一个数据集，其中包含来自 App Store 和 Play Store 的超过一百万个条目。它包含有关应用程序的详细信息，我认为它可能对在应用程序开发、市场分析或技术趋势等相关领域工作的其他人有用。 如果这里有人有兴趣将其用于您自己的研究或项目，请告诉我！很高兴讨论细节。 干杯！    提交人    /u/26th_Official   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hnfswv/r_ive_collected_a_dataset_of_1m_app_store_and/</guid>
      <pubDate>Fri, 27 Dec 2024 14:17:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何解释 GLU“激活”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hnc7d9/d_how_do_you_interpret_glu_activations/</link>
      <description><![CDATA[我一直在问自己如何解释 GLU 和 GLU 变体，比如现代 Transformer 中常见的变体。 我可以看到 ReLU 激活的 2 层 MLP 既是非线性投影的线性投影（从一个向量空间到另一个向量空间的正锥，再到另一个向量空间），也是键集（隐藏神经元的权重）和值集（从隐藏到输出单元的权重），与注意力和联想记忆相比，这很好。 如何解释具有 GLU 变体的 GLU 和 FFN？我可以看到一个 3D 向量被投影到另一个 3D 向量（第一个线性变换）并被门控，即可能被投影到垂直于轴的平面上。但我很难看出原始向量如何确定中间向量和 S 形门的收缩/展平。门上的其他激活功能使其更加困难。 与经典的 2layerMLP 相比，2-3 个单元上的最小 GLU 可以实现哪些简单的逻辑函数或几何变换？    提交人    /u/Sad-Razzmatazz-5188   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hnc7d9/d_how_do_you_interpret_glu_activations/</guid>
      <pubDate>Fri, 27 Dec 2024 10:33:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] REINFORCE++：一种简单有效的大型语言模型对齐方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hna801/p_reinforce_a_simple_and_efficient_approach_for/</link>
      <description><![CDATA[RLHF（Reinforcement Learning from Human Feedback）正在快速发展，PPO、DPO、RLOO、ReMax、GRPO等算法相继涌现。 通过将近端策略优化 (PPO) 中的各种优化技术集成到传统的 REINFORCE 算法中，我们“提出”了 REINFORCE++，旨在提高 RLHF 中的性能和稳定性，同时在没有批评者网络的情况下减少计算资源需求。 REINFORCE++ 的主要特性是它比 GRPO 更稳定，比 PPO 更快。 REINFORCE++ 的技术细节如下： https://hijkzzz.notion.site/reinforce-plus-plus 和（技术报告） https://github.com/hijkzzz/Awesome-LLM-Strawberry/blob/main/resources/REINFORCE%2B%2B.pdf    由   提交  /u/seventh_day123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hna801/p_reinforce_a_simple_and_efficient_approach_for/</guid>
      <pubDate>Fri, 27 Dec 2024 08:05:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] 违反比例风险假设：我该怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmz1cs/p_violation_of_proportional_hazards_assumption/</link>
      <description><![CDATA[我正在开展一个项目，需要预测患者的造血细胞移植 (HCT) 后存活率。我有事件目标和事件发生时间目标。 事后看来，我的方法是使用生命线库 (Kaplan-Meier、Nelson-Aalen、CoxPH) 中的生存模型来估计风险评分，我将使用该评分作为 LightGBM 和 CatBoost 的回归目标。评估指标是分层一致性指数 (C 指数)。 使用 CoxPH 模型，我必须将所有分类特征转换为数字，因为 CoxPH 仅接受数值协变量 (特征)。但是，181 个协变量中至少有 40 个的 p 值小于 0.05 - 这违反了比例风险假设。 这是一个需要考虑的重要因素吗？我应该保留还是放弃针对 CoxPH 生存模型创建的目标进行训练的模型？违规行为是否会使生存模型“不可信”？    提交人    /u/TechNerd10191   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmz1cs/p_violation_of_proportional_hazards_assumption/</guid>
      <pubDate>Thu, 26 Dec 2024 21:51:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士 (LLM) 的机械可解释性中，有哪些常见的开放式问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmxxwf/d_what_are_some_popular_openended_problems_in/</link>
      <description><![CDATA[大家好，我对法学硕士及其研究非常熟悉。我对机械可解释性很感兴趣，并开始从事该领域的工作。作为机械可解释性的新手，我计划在该领域攻读博士学位，我应该开始探索该领域中哪些流行的开放式问题？很想听听这里的可解释性研究人员的见解。    提交人    /u/arinjay_11020   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmxxwf/d_what_are_some_popular_openended_problems_in/</guid>
      <pubDate>Thu, 26 Dec 2024 21:02:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过优化内存管理在单个消费者 GPU 上微调 175B 参数语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmpck4/r_finetuning_175b_parameter_language_models_on_a/</link>
      <description><![CDATA[这里的关键技术进步是通过巧妙的内存管理和 NVMe SSD 利用率在单个消费级 GPU 上实现 100B 参数模型的微调。研究人员开发了一个框架，可在保持训练质量的同时优化 GPU、CPU RAM 和存储之间的数据移动。 主要技术贡献：- 为消费级硬件实现修改后的 ZeRO-Infinity 优化- 具有动态参数卸载的三层内存层次结构- 可减少内存访问延迟的新型预取系统- 优化存储层之间的数据传输模式- 跨 GPU/CPU/NVMe 的内存带宽管理 主要结果：- 与现有的单 GPU 方法相比，速度提高了 2.6 倍- 所需 GPU 内存减少 70%- 成功微调 100B 参数模型- 与多 GPU 设置相当的训练质量- 在消费级硬件配置上进行了验证 我认为这可以让个人研究人员和小型实验室更容易进行大型模型微调。虽然它不会在生产场景中取代多 GPU 训练，但它可以快速进行原型设计和实验，而无需昂贵的硬件集群。这里的技术还可以为未来内存高效的训练方法提供参考。 权衡似乎是合理的——较慢的训练换来大幅降低成本。但是，我希望看到对不同模型架构和训练任务进行更广泛的测试，以充分验证该方法。 TLDR：新框架通过优化的内存管理和 NVMe 利用率，可以在单个消费者 GPU 上微调 100B 参数模型，与现有方法相比，速度提高了 2.6 倍。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmpck4/r_finetuning_175b_parameter_language_models_on_a/</guid>
      <pubDate>Thu, 26 Dec 2024 14:25:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] “激活工程”能否取代提示工程或微调作为操纵模型的技术？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmjdh3/d_could_activation_engineering_replace_prompt/</link>
      <description><![CDATA[如果您不知道，激活工程只是一个流行词，用于操纵 LLM 中的激活向量来控制其行为。一个著名的例子是“金门克劳德”，其中人类工程师上调了代表模型潜在空间中“金门大桥”概念的神经元。这样做之后，该模型开始将金门大桥编织到其所有响应中，甚至开始将自己识别为金门大桥。 目前，这种可解释性工作主要存在于文献中，但我很好奇您是否预计“激活工程”的真正工具会成为主流。您如何看待未来的转向模型？    提交者    /u/jsonathan   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmjdh3/d_could_activation_engineering_replace_prompt/</guid>
      <pubDate>Thu, 26 Dec 2024 07:22:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每个人都对 LLM 如此感兴趣，但 Transformer 架构能否用于改进更“传统”的机器学习领域</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmitcz/d_everyone_is_so_into_llms_but_can_the/</link>
      <description><![CDATA[我正在考虑诸如推荐算法之类的东西，这些算法依赖于无监督学习或许多其他无监督算法 我会更深入地研究它，但也许想对此有一些想法    提交人    /u/noithatweedisloud   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmitcz/d_everyone_is_so_into_llms_but_can_the/</guid>
      <pubDate>Thu, 26 Dec 2024 06:40:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 物理学和逻辑学的结合最近取得了什么进展？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmds2k/dhow_have_recent_advancements_with_incorporating/</link>
      <description><![CDATA[去年，关于这项技术将带来的承诺，曾有过大量讨论，但之后就没有什么进展了。    由    /u/sext-scientist  提交  [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmds2k/dhow_have_recent_advancements_with_incorporating/</guid>
      <pubDate>Thu, 26 Dec 2024 01:28:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 教 VLM 通过读写任务将手写图像转换为数字墨水</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm8a6s/r_teaching_vlms_to_convert_handwritten_images/</link>
      <description><![CDATA[InkSight：通过学习阅读和书写实现离线到在线手写转换 项目页面 | 模型发布 | Google 研究博客 TLDR： 通过教授视觉语言模型进行阅读和书写，我们能够弥合传统手写和数字墨水之间的差距，提供通过盲目研究评估的高质量数字描摹，其中 87% 被判定为有效， 67% 与人类生成的墨水无法区分。 消融研究强调了识别（“阅读”）任务在确保语义一致性方面的重要性，而推理策略则展示了处理模糊笔迹的灵活性。此外，使用去渲染墨水作为训练数据与真实世界数据集结合可增强手写识别，将字符错误率降低至 4.6%。这些发现展示了 InkSight 在推进手写数字化和识别系统方面的潜力。    提交人    /u/CharlieLee666   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm8a6s/r_teaching_vlms_to_convert_handwritten_images/</guid>
      <pubDate>Wed, 25 Dec 2024 20:26:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 无编码器视觉语言模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm6qpu/d_encoder_free_vision_language_models/</link>
      <description><![CDATA[节日快乐！有没有关于无编码器 VLM 的有趣论文？最近在看视频 VLM，最大的麻烦是编码器效率。此外，端到端质量在很大程度上受限于视觉编码器的质量，而视觉编码器通常是 CLIP 样式模型。有 Fuyu 模型系列，但这种架构似乎表现不佳。最近有一篇 NeurlPS 论文：https://github.com/baaivision/EVE 看起来很有趣。期待对这个工作方向的评论和建议。    提交人    /u/encoreway2020   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm6qpu/d_encoder_free_vision_language_models/</guid>
      <pubDate>Wed, 25 Dec 2024 19:04:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] JaVAD——又一款语音活动检测器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hlz6az/p_javad_just_another_voice_activity_detector/</link>
      <description><![CDATA[刚刚发布了我在过去 3 个月内研究的一个 VAD（不计算模型本身的时间），它看起来至少与其他开源 VAD 相当或更好。  它是一个自定义的基于卷积的架构，在梅尔频谱图上使用滑动窗口，因此速度也非常快（在 3090 上需要 16.5 秒来加载和处理来自测试集的 18.5 小时的音频）。 它也非常紧凑（包括检查点在内的所有内容都适合 PyPI 包），如果你不需要加载音频，核心功能依赖只是 pytorch 和 numpy。 其他一些 VAD 是通过混合语音和噪音在合成数据上进行训练的，我认为这就是它们在嘈杂音频上落后的原因。对于这个项目，我手动标记了数十个 YouTube 视频，特别是老电影和电视节目，其中有很多噪音。 还有一个用于流媒体的类，尽管由于滑动窗口和规范化的性质，处理音频的初始部分可能会导致较低质量的预测。 MIT 许可证  这是一个个人项目，所以我很确定我错过了一些东西（或者很多），请随时在 github 上发表评论或提出问题。 这是链接：https://github.com/skrbnv/javad    提交人    /u/ApprehensiveLet1405   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hlz6az/p_javad_just_another_voice_activity_detector/</guid>
      <pubDate>Wed, 25 Dec 2024 11:33:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>