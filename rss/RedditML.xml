<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 01 Apr 2024 03:14:23 GMT</lastBuildDate>
    <item>
      <title>[D] 为特定领域创建您自己的语言模型（即文本编码器）。什么时候值得这样做？您应该注意什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bst5y2/d_creating_your_own_language_model_ie_text/</link>
      <description><![CDATA[我最近为时尚领域制作了自定义 BERT 和 ELECTRA 模型，它们也可以处理英语和我自己的母语（我不在美国） 。我注意到性能没有我预期的那么好，觉得不值得。 是否有任何论文或资源说明何时值得从头开始创建自己的预训练 LM ？我记得很久以前读过一篇生物医学领域的论文，标题为生物医学和临床任务的预训练语言模型：理解和扩展最先进的技术（Lewis 等人，2020） 似乎表明从头开始进行预训练可以帮助完成生物医学和临床任务，但我不确定是否还有其他方法那里有论文。 此外，在评估新的预训练 LM 时是否有任何提示或值得了解的事情？例如，检查 OOV 率等。 提前致谢。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bst5y2/d_creating_your_own_language_model_ie_text/</guid>
      <pubDate>Mon, 01 Apr 2024 03:12:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 有没有办法将面部 3D 模型与头部的通用 3D 模型对齐？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bss1sy/p_is_there_a_way_to_align_a_3d_model_of_a_face_on/</link>
      <description><![CDATA[我创建了自己的仅正面的 .obj 文件（通过对 DLIB 和立体视觉进行一些修补）。现在，我想在 3D 模型上对齐脸部的 obj 文件。关于如何执行此操作有什么建议吗？   由   提交 /u/sagecage   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bss1sy/p_is_there_a_way_to_align_a_3d_model_of_a_face_on/</guid>
      <pubDate>Mon, 01 Apr 2024 02:16:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] Android 中的设备端机器学习：框架和生态系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsrcwg/p_ondevice_machine_learning_in_android_frameworks/</link>
      <description><![CDATA[设备上机器学习是指完全在设备上进行的 ML 模型推理/训练，无需网络调用或服务器。与服务器端推理相比，设备端机器学习有其自身的优点和缺点。 TensorFlow、PyTorch 等主要 ML 框架具有在 Android 应用程序中部署模型的实用程序，而 Mediapipe 和 MLKit 等服务则为常见 ML 任务提供更简洁的 API。在我最新的博客中，我们将探索设备上的 ML 库和实用程序，它们可以帮助 Android 开发人员在设备上部署 ML 模型。 博客 -&gt; https://proandroiddev.com/on-device-machine-learning- in-android-frameworks-and-ecosystem-888bc42a1d21  您在设备上部署机器学习模型时遇到了哪些限制？ 通过加强对边缘的关注部署时，是否可以实现消耗更少桌面/GPU计算资源的高效模型？ 正如博客中所表达的，除了部署之外，设备上模型所需的预处理也很难构建，主要是因为由于缺乏 Python 中易于使用的工具。您对此有何看法？    由   提交/u/shubham0204_dev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsrcwg/p_ondevice_machine_learning_in_android_frameworks/</guid>
      <pubDate>Mon, 01 Apr 2024 01:43:14 GMT</pubDate>
    </item>
    <item>
      <title>【讨论】训练LLM解决训练集之外的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsqljk/discussion_training_llm_to_solve_problems_outside/</link>
      <description><![CDATA[嗨，只是想讨论一些想法：我觉得LLM的一个缺点是他们有时会产生肤浅/幻觉的答案，并且不能解决太远的难题远离火车组（假设我们问他们困难的数学问题）。我在想我们可以尝试以下类似 GAN 的游戏结构来提高它们的性能，并让它们超越问题/答案的训练集。给定一些尚无答案的难题数据集： - 一个诚实的人工智能：它的目标是通过尝试被选择来尝试找到问题的答案（并给出相应的证明）由鉴别器 - 一个巨魔人工智能：它可以从诚实的人工智能那里看到答案。它必须输出除诚实人工智能之外的另一个答案，以及相应的证明。它的目标是由判别器进行选择，即欺骗判别器 AI，让其相信自己给出了正确的答案 - 判别器 AI：其目标是选择诚实的 AI 或巨魔 AI 中的哪一个拥有正确的答案和证据（他们没有）不知道谁是巨魔，谁是诚实的） 只要有足够的能力和搜索能力，只有当诚实的人工智能和鉴别器实际上收敛到实际的真实客观答案时，才能获得此类任务的最佳结果吗？的问题？还是有什么我没有想到的折叠模式？你怎么认为 ？基本上我也在尝试思考我们人类如何进行证明并走出训练集   由   提交 /u/Kolmog1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsqljk/discussion_training_llm_to_solve_problems_outside/</guid>
      <pubDate>Mon, 01 Apr 2024 01:07:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 快速、经济地获取数据进行微调的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsnv6t/d_what_is_the_best_way_to_quickly_and_affordably/</link>
      <description><![CDATA[如果您想为 DPO 获取 10,000 个高质量输入/输出对或为 KTO 获取首选项，最好的方法是什么？  据我了解，您不能使用 GPT4 创建合成数据（将用于训练商业模型），因为这违反了他们的条款。    由   提交/u/JT_NVG8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsnv6t/d_what_is_the_best_way_to_quickly_and_affordably/</guid>
      <pubDate>Sun, 31 Mar 2024 23:07:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 扩散模型的衰减点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsnabt/d_fall_off_point_for_diffusion_models/</link>
      <description><![CDATA[有没有人从理论上或实验上计算过为稳定扩散 1.5 或 SDXL 等扩散模型训练的图像数量的下降点？  也就是说：如果你有一个用 N 张图像训练的模型，它可以产生“好的”结果。训练过的类别中的图像。然后，您对新类别中的“A”张额外图像进行额外训练。图像总数是多少 T = N + A，这样当您达到 T 的值时，原始类别中生成的图像质量开始下降？  我知道扩散模型是“有损压缩”。图像数据，但即使进行压缩，毕竟 2GB 或 6GB 模型可以容纳的信息量也是有限的。因此，我感兴趣的是可以进行最有效的训练量特定的模型类型。    由   提交/u/lostinspaz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsnabt/d_fall_off_point_for_diffusion_models/</guid>
      <pubDate>Sun, 31 Mar 2024 22:43:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何评估文本到图像模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsmf0j/d_how_to_evaluate_texttoimage_model/</link>
      <description><![CDATA[在文本到图像生成问题中，单个文本描述可以转换为不同的图像（多样性），例如，给定描述“ “这只鸟是白色的，有黄色的翅膀”，生成的图像都将是一只白色的有黄色翅膀的鸟，但在姿势、背景等方面可能有所不同，使得每个图像根据描述仍然是正确的。然而，在验证数据集中，每个文本描述都对应一个实际图像。 那么，如何评估模型的性能呢？具体来说，如何将多个正确生成的图像与单个真实图像进行比较？是否可以应用 Inception Score 和 FID 等指标？如果可以，它们是如何工作的？谢谢   由   提交 /u/Equivalent-Funny3396    reddit.com/r/MachineLearning/comments/1bsmf0j/d_how_to_evaluate_texttoimage_model/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsmf0j/d_how_to_evaluate_texttoimage_model/</guid>
      <pubDate>Sun, 31 Mar 2024 22:07:58 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 尝试理解 AutoBNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsm5e7/dr_trying_to_understand_autobnn/</link>
      <description><![CDATA[时间序列预测专家能否介绍一下 Google 的 AutoBNN？它与典型的 LSTM、基于 RNN 的 BNN 或 NN 模型有何不同和更好之处？ https://blog.research.google/2024/03/autobnn- probabilistic-time-series.html?m=1   由   提交/u/bahauddin_onar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsm5e7/dr_trying_to_understand_autobnn/</guid>
      <pubDate>Sun, 31 Mar 2024 21:57:11 GMT</pubDate>
    </item>
    <item>
      <title>时间序列的最佳自监督学习任务 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsl2j6/best_selfsupervised_learning_task_for_timeseries_d/</link>
      <description><![CDATA[我正在研究多变量时间序列的基础模型（特别是脑相关数据，如脑电图）。有一些基础模型，其中大多数似乎都专注于屏蔽自动编码。我只见过一个人考虑对比学习。对于此类数据，考虑去噪自动编码或其他 SSL 任务或某种组合是否更有意义？网上或当前文献中似乎没有对此问题的直接答案。   由   提交 /u/Funny-Explorer-854   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsl2j6/best_selfsupervised_learning_task_for_timeseries_d/</guid>
      <pubDate>Sun, 31 Mar 2024 21:11:55 GMT</pubDate>
    </item>
    <item>
      <title>[D]有人用bluesky或mastodon吗？我应该关注哪些知名的 ML 人士？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bskvlh/d_anyone_using_bluesky_or_mastodon_who_are_some/</link>
      <description><![CDATA[有点想摆脱 twitter   由   提交 /u/hempock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bskvlh/d_anyone_using_bluesky_or_mastodon_who_are_some/</guid>
      <pubDate>Sun, 31 Mar 2024 21:03:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 ML 作品集中，什么更令人印象深刻：实施一篇论文还是创建一个好的项目？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsezcf/d_whats_more_impressive_in_a_ml_portfolio/</link>
      <description><![CDATA[大家好，从您的经验来看，公司的招聘经理更喜欢什么，是出色的论文实施还是出色的实际项目？我知道两者都有很大的好处、优点和缺点等。但是，reddit 上的管理者在查看回购协议时喜欢看到什么？在考察候选人的技能时，其中一个会比另一个更好吗？   由   提交 /u/ninvibe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsezcf/d_whats_more_impressive_in_a_ml_portfolio/</guid>
      <pubDate>Sun, 31 Mar 2024 16:51:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM预训练和评估奖励模型的技巧——讨论2024年3月的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs95b8/p_tips_for_llm_pretraining_and_evaluating_reward/</link>
      <description><![CDATA[ 由   提交/u/seraschka  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs95b8/p_tips_for_llm_pretraining_and_evaluating_reward/</guid>
      <pubDate>Sun, 31 Mar 2024 12:21:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 曼巴解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs1va2/p_mamba_explained/</link>
      <description><![CDATA[帖子：https://thegradient.pub/mamba-解释/ ​ 这里我们将讨论：  Mamba 的优点（和缺点）（🐍 ）与变形金刚（🤖）， 思考 Mamba 的类比和直觉，以及  Mamba 对于可解释性、人工智能安全和应用意味着什么。  本文最初发布于Kola 的个人博客。&lt; /p&gt;  ​   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs1va2/p_mamba_explained/</guid>
      <pubDate>Sun, 31 Mar 2024 04:32:28 GMT</pubDate>
    </item>
    <item>
      <title>华尔街日报：人工智能行业在 Nvidia 芯片上的支出是其收入的 17 倍 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs1ebl/wsj_the_ai_industry_spent_17x_more_on_nvidia/</link>
      <description><![CDATA[ ... 在本月早些时候的一次演示中，风险投资公司红杉估计人工智能行业在 Nvidia 芯片上花费了 500 亿美元去年用于训练先进的人工智能模型，但仅带来了 30 亿美元的收入。   来源：《华尔街日报》（付费）   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs1ebl/wsj_the_ai_industry_spent_17x_more_on_nvidia/</guid>
      <pubDate>Sun, 31 Mar 2024 04:06:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>