<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 03 Jul 2024 18:20:18 GMT</lastBuildDate>
    <item>
      <title>[D] 机器学习应用的投资回报率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1duklol/d_return_on_investment_of_ml_apps/</link>
      <description><![CDATA[我正在寻找 ML 应用的投资回报率。您是否知道此类报告/研究/客户成功案例，理想情况下包含有关成本和有形成分的数据？请分享您的见解并帮助我规划这个令人兴奋的领域。    提交人    /u/mhausenblas   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1duklol/d_return_on_investment_of_ml_apps/</guid>
      <pubDate>Wed, 03 Jul 2024 17:50:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mozilla TTS 从头开始​​训练结果不佳</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dujymn/d_mozilla_tts_training_from_scratch_bad_result/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dujymn/d_mozilla_tts_training_from_scratch_bad_result/</guid>
      <pubDate>Wed, 03 Jul 2024 17:23:23 GMT</pubDate>
    </item>
    <item>
      <title>ML中的复数分析[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dujmsf/complex_number_analysis_in_ml_p/</link>
      <description><![CDATA[我是 ML 的新手，有一些关于复数分析的理论想要测试，我想使用复数激活函数和复数数据作为输入。我想我偶然发现了一种涉及复数的新方法，但我还不知道自己在做什么。 有人知道任何包含复数的数据集吗？我在 kaggle 上找不到它们。我也对任何可能对 Black-Scholes 方程有用的数据感兴趣。 非常感谢您的帮助，抱歉我不想解释更多，也不想泄露秘诀。计划用这个给我找份工作，写一篇论文或尝试申请专利。    提交人    /u/LeopoldBStonks   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dujmsf/complex_number_analysis_in_ml_p/</guid>
      <pubDate>Wed, 03 Jul 2024 17:10:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 ML 模型从数据集生成见解 [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1duj6k6/generating_insights_from_a_dataset_using_a_ml/</link>
      <description><![CDATA[大家好， 在我的项目中，我想实现一项功能，以便我可以从数据集中生成自动见解，例如“过去 3 个月的销售额增加”、“该产品的价格下降了”等。有人可以告诉我如何从头开始实现它吗？    提交人    /u/OrneryCar6139   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1duj6k6/generating_insights_from_a_dataset_using_a_ml/</guid>
      <pubDate>Wed, 03 Jul 2024 16:51:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] GNN 学习过程的挣扎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1duf6tx/p_struggle_with_learning_process_of_gnn/</link>
      <description><![CDATA[大家好 :) 目前，我面临以下问题。我想构建一个 RL 代理，以根据动态变化的客户端位置优化大型网络中服务器的放置位置，并确定潜在位置。有许多潜在位置，代理应选择最佳选项，通过在该位置激活服务器来最小化延迟。 但是，我的 PPO 实现无法学习。为了检查我的底层模型是否能够捕获图表的信息，我将其重新定义为监督问题： 给定当前网络设置（潜在位置为节点、活动节点、客户端以及客户端与服务器之间的延迟），确定整体系统延迟。 因此，重要的部分是模拟单个延迟的边缘和标记为活动的节点。它们决定了系统的整体延迟。原则上，这不应该是一个难题，因为 GNN 应该很容易认识到它只需要考虑活动节点，然后在那里聚合边缘数据。但是，我的模型没有学到任何东西，并且通过预测系统延迟平均值附近的延迟而完全陷入困境。 我正在使用 torch_geometric 的 Graph Attention 模块。所以我的问题是，您是否有过类似的 GNN 经验，并在学习过程中遇到困难。对我来说，这个相对简单的任务的学习过程不能正常工作，这似乎很奇怪，所以我认为我搞砸了架构。 代码在这里： class CriticSwapGNN(nn.Module): def __init__(self, feature_dim_node: int = 3, hidden_​​channels: int = 12, fc_hidden_​​dim: int = 128, num_gat_layers: int = 4, num_mlp_layers:int = 3, num_heads=4,activation=nn.ReLU, num_nodes: int = None, num_locations: int = 15, for_active: bool = True, device: str = &quot;cuda&quot;, optimizer: nn.Module = torch.optim.Adam, lr: float = 3e-4, ):超级（CriticSwapGNN，self）。__init__（）self.num_nodes = num_nodes self.for_active = for_active self.num_locations = num_locations out_dim = 1 self.type_embedding = nn.Embedding（4，feature_dim_node）self.activation =activation（）self.att = GATConv（feature_dim_node + 2，hidden_​​channels//num_heads，heads=num_heads）self.hidden_​​atts = nn.ModuleList（）for _ in range（num_gat_layers - 2）：self.hidden_​​atts.append（GATConv（hidden_​​channels，hidden_​​channels//num_heads，heads=num_heads））self.final_att = GATConv（hidden_​​channels，hidden_​​channels//num_heads，heads=num_heads）critic_layer = [ nn.Sequential（线性（hidden_​​channels，fc_hidden_​​dim），activation（））] for _ in range（num_mlp_layers - 2）：critic_layer.append（线性（fc_hidden_​​dim，fc_hidden_​​dim））critic_layer.append（activation（））critic_layer.append（nn.Sequential（线性（fc_hidden_​​dim，1），activation（）））self.critic = nn.Sequential（*critic_layer）self.optimizer = optimizer（self.parameters（，lr=lr）self.device = device self.to（self.device）def forward（self，data：Union [Data，Batch]，batch：torch.Tensor = None）：如果len（data.type.shape）&gt;； 2：引发 ValueError（“类型应为 1D 张量。确保它不是独热编码的。”） x = self.type_embedding(data.type.long()) time_index = data.update_step.unsqueeze(1).to(self.device) # 规范化请求 mean_requests = torch.mean(data.requests[self.num_locations:], dim=0) std_requests = torch.std(data.requests[self.num_locations:], dim=0) request_norm = (data.requests[self.num_locations:] - mean_requests) / (std_requests + 1e-6) request_final = torch.cat([data.requests[:self.num_locations], request_norm], dim=0) x = torch.cat([x, request_final.unsqueeze(1), time_index], dim=-1) edge_index = data.edge_index x = self.att(x, edge_index, edge_attr=data.latency) x = self.activation(x) for att in self.hidden_​​atts: x = att(x, edge_index, edge_attr=data.latency) x = self.activation(x) x = self.final_att(x, edge_index, edge_attr=data.latency) # 节点值 node_values = self.critic(x) # 应用全局均值池来获得图级嵌入 graph_value = global_mean_pool(node_values, batch)     submitted by    /u/No_Individual_7831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1duf6tx/p_struggle_with_learning_process_of_gnn/</guid>
      <pubDate>Wed, 03 Jul 2024 14:05:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您认为验证映射器算法所识别的簇的稳定性的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1duc1d0/r_what_would_you_say_is_the_best_way_to_validate/</link>
      <description><![CDATA[是否有任何特定的技术可以确保它们不是噪声或参数选择的伪影？    提交人    /u/ICEpenguin7878   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1duc1d0/r_what_would_you_say_is_the_best_way_to_validate/</guid>
      <pubDate>Wed, 03 Jul 2024 11:29:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在动态因果建模中，量化模型证据和参数不确定性之间的权衡的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dubxgc/r_what_is_the_best_way_to_quantify_the_trade_off/</link>
      <description><![CDATA[例如在 MRI 扫描中    提交人    /u/ICEpenguin7878   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dubxgc/r_what_is_the_best_way_to_quantify_the_trade_off/</guid>
      <pubDate>Wed, 03 Jul 2024 11:22:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] dbt 用于数据产品：成本节约、体验和货币化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1du8j0h/d_dbt_for_data_products_cost_savings_experience/</link>
      <description><![CDATA[本文非常适合专注于优化 dbt 投资并希望增强以下任一功能的数据领导者或数据工程主管：成本节约、数据货币化工作、用户和数据消费者的整体体验。在本文中，您将了解：  将对话从 ETL 转移到数据产品的需求 + dbt 中的差距 数据产品：自助服务平台的众多成果之一，但很重要 如何利用现有堆栈（使用 dbt）构建数据产品 成本节约 大型 dbt 模型可能会导致高昂的计算成本 基础设施成本 维护、支持和运营成本 增加收入需求 规模和性能 转换/ ETL 如何进入新阶段并为扩展做好准备 增强所有人的体验（客户和业务人员）  在此处阅读完整文章：https://moderndata101.substack.com/p/dbt-for-data-products-cost-monetisation-xp    提交人    /u/growth_man   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1du8j0h/d_dbt_for_data_products_cost_savings_experience/</guid>
      <pubDate>Wed, 03 Jul 2024 07:30:29 GMT</pubDate>
    </item>
    <item>
      <title>锦标赛调度策略[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1du4od0/strategies_of_tournament_scheduling_d/</link>
      <description><![CDATA[锦标赛安排策略 我正在研究一些概念和策略，这些概念和策略将安排具有某些约束或规则的联赛或锦标赛，并在更改比赛时记住某些过去的动作，直到满足所有规则。该模型还将通过使用循环赛池大小的特定布局，从正在处理的赛程之外的其他过去赛程中学习。 常见的约束包括：  没有背靠背的比赛 比赛之间的最短时间 不要与其他球队同时比赛 不要在特定时间或日期比赛 每天或每周最多比赛 平衡客场和主场位置  还有很多，但你应该明白了。我应该研究什么，开发人员应该采取什么流程或应该询问什么。    提交人    /u/cblaze22   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1du4od0/strategies_of_tournament_scheduling_d/</guid>
      <pubDate>Wed, 03 Jul 2024 03:30:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于函数/工具调用的全新 Llama、Mistral、Phi、Qwen 和 Gemma 模型集合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1du3b1e/p_new_collection_of_llama_mistral_phi_qwen_and/</link>
      <description><![CDATA[介绍 Rubra v0.1：一组开放权重、工具调用 LLM 在 此处 在 Hugging Face Spaces 中免费试用！ 我们还扩展了 vLLM 和 llama.cpp，以便您可以非常轻松上手。查看我们的文档：Rubra 文档   模型 函数调用 MMLU（5 次测试） GPQA（0 次测试） GSM-8K（8 次测试，CoT） MATH（4 次测试，CoT） MT-bench    Rubra Llama-3 70B Instruct 97.85% 75.90 33.93 82.26 34.24 8.36   Rubra Llama-3 8B 指导 89.28% 64.39 31.70 68.99 23.76 8.03   Rubra Qwen2 7B 指导 85.71% 68.88 30.36 75.82 28.72 8.08   Rubra Mistral 7B Instruct v0.3 73.57% 59.12 29.91 43.29 11.14 7.69   Rubra Phi-3 Mini 128k 指令 65.71% 66.66 29.24 74.09 26.84 7.45   Rubra Mistral 7B 指令 v0.2 69.28% 58.90 29.91 34.12 8.36 7.36   Rubra Gemma-1.1 2B Instruct 45.00% 38.85 24.55 6.14 2.38 5.75   我们为什么创建这些模型 尽管专有模型和开源模型之间的能力差距一直在缩小，但我们看到函数/工具调用在开源中仍然落后。 直到现在，让 LLM 输出可靠函数调用的选项有限，就像让 OpenAI 和 Anthropic 这样做一样。提示工程、输出解析和 JSON 语法是一种 hack 选项。另一个选项是执行函数调用的模型，例如 Berkeley Gorilla、NexusRaven、Hermes、Command-R+，但它们都固定在一个模型上，有些在需要长上下文和在函数调用之上聊天的能力的代理用例中并不现实。最近，Mistral v0.3 中提供了工具调用，但在我们的测试中，它没有达到预期。 我们还根据对 gptscript、autogen 和其他代理框架的经验知道，您可能需要根据用例使用更小或更大的模型。我们不想被固定在一个模型上，所以我们决定对所有我们喜欢的模型进行进一步的后期训练。  一些旁注： - Rubra Qwen2 模型能够用中文进行函数调用！它在 Qwen2 支持的其他 28 种语言中具有有限的函数调用能力。 - GGUF 模型在过去 48 小时内的下载量约为 10 万次！ - 我们已经开始根据今天发布的 2024 年 6 月 Phi-3-mini 更新训练新的 Rubra Phi3。敬请期待！    提交人    /u/sanjay920   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1du3b1e/p_new_collection_of_llama_mistral_phi_qwen_and/</guid>
      <pubDate>Wed, 03 Jul 2024 02:18:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 推理过程中学习的当前研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dturka/d_current_research_in_learning_during_inference/</link>
      <description><![CDATA[我对在推理过程中可以学习的模型（尤其是自回归模型）的最新研究很感兴趣。这个领域的一些关键论文或方法是什么？我特别感兴趣的是：  推理过程中更新权重的方法 应用于语言模型、时间序列预测等。  任何指向最近工作的指针或对有希望的方向的想法都将不胜感激。谢谢！    提交人    /u/uoftsuxalot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dturka/d_current_research_in_learning_during_inference/</guid>
      <pubDate>Tue, 02 Jul 2024 19:42:32 GMT</pubDate>
    </item>
    <item>
      <title>有任何拥有 1 H100 允许分析的云提供商吗？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dtq8hn/any_cloud_providers_with_1_h100_allowing/</link>
      <description><![CDATA[您好，有谁知道有哪个 GPU 云提供商提供  租用单个 H100（而不是 8 个） 允许收集可能被 ncu 用来分析内核性能的分析数据。  例如，AWS 和 Lightning 允许收集分析数据，但我认为 Lambda 不允许。    提交人    /u/imurme8   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dtq8hn/any_cloud_providers_with_1_h100_allowing/</guid>
      <pubDate>Tue, 02 Jul 2024 16:35:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 相同代码的结果有何不同？对于深度 CNN 项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dtp8n5/p_difference_in_results_over_same_code_for_a_deep/</link>
      <description><![CDATA[[P] 因此，我正在复制我在 Github 上找到的代码以供练习。这是一个深度 CNN 项目。使用相同的数据集，并且所有内容都与代码相同。该代码大约有 3 年的历史了。该数据集是关于视网膜图像的。唯一的区别是 1）我使用的是 Pytorch、Keras 和 Tensorflows 的最新版本 2）我的硬件是带集成显卡的 AMD Ryzen 5700U，所以我没有 GPU，而是在 AMD CPU 上运行。但是，对于 epoch，原始代码大约需要 600 毫秒，而我的时钟时间为 250 毫秒，我的训练准确度与他们的训练准确度相匹配（约 98%）。然而他们的验证和测试准确度约为 97%，而我的验证和测试准确度约为 50%。原因是什么？因为数据预处理、模型参数等一切都一样。唯一的问题是库的版本较新并且不使用 GPU。我不知道原始代码的硬件规格，但从时代来看，我的CPU在速度方面似乎表现更好。    提交人    /u/Rogue260   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dtp8n5/p_difference_in_results_over_same_code_for_a_deep/</guid>
      <pubDate>Tue, 02 Jul 2024 15:54:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过稀疏插值专家释放元调整的力量，实现小样本泛化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dtntuq/r_unleashing_the_power_of_metatuning_for_fewshot/</link>
      <description><![CDATA[  由    /u/purified_piranha  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dtntuq/r_unleashing_the_power_of_metatuning_for_fewshot/</guid>
      <pubDate>Tue, 02 Jul 2024 14:55:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>