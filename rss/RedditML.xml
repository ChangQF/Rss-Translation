<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 17 Jan 2024 15:14:10 GMT</lastBuildDate>
    <item>
      <title>[D] 信心*可能是*您所需要的一切。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198y67i/d_confidence_may_be_all_you_need/</link>
      <description><![CDATA[      ​ 论文：https://arxiv.org/abs/2303.08896 ​ 我很想知道这里是否有人在实践中尝试过这个。 LLM 输出标记的对数概率的简单平均值可能足以判断模型是否产生幻觉。这个想法是，如果模型不自信（输出令牌概率低），则该模型可能会发明随机的东西。作者声称这种简单的方法是检测幻觉的最佳启发式方法。美妙之处在于它只使用生成的令牌概率，因此可以在推理时实现。   由   提交 /u/santiviquez   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198y67i/d_confidence_may_be_all_you_need/</guid>
      <pubDate>Wed, 17 Jan 2024 14:46:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 词汇量真的会影响法学硕士文本的大小吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198xx6o/d_does_the_vocabulary_size_really_affect_the_size/</link>
      <description><![CDATA[与变压器的其他组件相比，嵌入矩阵是否足够大？ 如果不是，那么为什么 GPT 模型依赖于30K 词汇量？   由   提交/u/kekkimo  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198xx6o/d_does_the_vocabulary_size_really_affect_the_size/</guid>
      <pubDate>Wed, 17 Jan 2024 14:34:22 GMT</pubDate>
    </item>
    <item>
      <title>[N] 关于矢量数据库基准的新见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198xe4m/n_new_insights_on_vector_databases_benchmarks/</link>
      <description><![CDATA[我们将 Qdrant 的性能与其他矢量搜索引擎进行了比较，以便为您提供全面的性能分析。 详细报告： https://qdrant.tech/benchmarks/ 以下是更改内容：https://qdrant.tech/blog/qdrant-benchmarks-2024/ 如果您有兴趣运行这些基准测试或请访问我们的基准存储库。 https://github.com/qdrant/vector-db-benchmark&lt; /a&gt;   由   提交/u/sabrinaqno   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198xe4m/n_new_insights_on_vector_databases_benchmarks/</guid>
      <pubDate>Wed, 17 Jan 2024 14:10:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻找开源 AI 项目做出贡献</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198v842/p_looking_for_open_source_ai_project_to_contribute/</link>
      <description><![CDATA[您好，我已经潜入深度学习近一年了，并且自己做了几个项目。为了提高我的技能，我目前正在寻找一个开源项目来贡献，并且每周可以投入 5-20 个小时。  如果您知道我可以参与的任何项目，请联系我。   由   提交 /u/SantaClaus_Y   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198v842/p_looking_for_open_source_ai_project_to_contribute/</guid>
      <pubDate>Wed, 17 Jan 2024 12:16:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 ICLR2025 中制定垃圾邮件提交的公平政策？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198v7zv/d_how_to_frame_a_fair_policy_for_spam_submissions/</link>
      <description><![CDATA[   因此，我为 ICLR2024 提交的内容获得了以下 MetaReview。 “审稿人一致认为，提交的内容没有做出明确的贡献，而且作者的参与是不诚实的。会议应该考虑明年采取针对垃圾邮件提交的政策。” 我很清楚，为机器学习会议找到高质量的审稿人是一个挑战。但我预计至少元审稿人能够发挥像样的作用。这是一个需要思考的严肃问题——尤其是当我收到的第一篇评论是建设性的并指出了我的优势时：“散文清晰，易于理解，读起来令人愉快。”作者提供了有用的数据，很好地使用了章节和小节。” 我对此的看法是，每个审稿人都应该首先使用 Bing Chat 等工具过滤他们的评论。并且将专业人士提交的 ICLR 标记为“垃圾邮件”提交开创了危险的先例！ https ://preview.redd.it/pkwtz7niszcc1.png?width=1181&amp;format=png&amp;auto=webp&amp;s=cc7225bf402e838d376876878749794b9087bf13 我对一位迟到的审稿人询问我工作中的关键贡献的反驳（你们 Reddit 用户可能从之前的帖子中知道）。 ”这项工作的关键贡献是什么？  补充文件在 https:// paperwithcode.com/datasets 如果被接受 我声称这是第一个数学上易于处理的认知发展框架，因为以下子贡献 -&gt;图 2.介绍了皮亚杰认知发展阶段理论对化学混合物理解的适应 -&gt;第 2.1 节包含数学证明，证明特征值截止的经验发现（如图 4 所示）对于重新缩放的样本协方差矩阵更为明显 -&gt;第 2.2 节显示 ICA 和 NMF 对于简单的线性解混合数据集失败了（我愿意再次测试 ICLR2024 中提出并接受的任何其他最先进的算法）-&gt;第 2.3 节现在包含审稿人 gSc5 要求的误差缩放法则  基线是什么？在 2.2 节中，理想的结果是伪逆解。基线方法是PCA。 ICA 和 NMF 需要新的理论发展来超越基线，并获得理想的结果。因此，我希望本文提供的数据集对学习理论界来说是一个简单但具有深远影响的挑战。 本文如何改进它们？这篇论文首先定义了这个问题。我敢打赌，ICLR 2024 中针对 NMF 变体提出的许多算法在该数据集上仍然会失败。因此，重要的是，这篇论文被接受，这样学习理论家即使计算资源不足，也能拥有一个原则性的数据集来发挥和创新。”  &amp; #32；由   提交/u/No-Sun-5534   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198v7zv/d_how_to_frame_a_fair_policy_for_spam_submissions/</guid>
      <pubDate>Wed, 17 Jan 2024 12:16:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 GAN 生成音频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198s5l1/d_audio_generation_using_gan/</link>
      <description><![CDATA[我想使用 GAN 生成音乐，但我有一个问题是应该使用 MFCC 数据、频谱图还是应该直接使用 .mp3 文件然后进行处理它使用 pyTorch 音频处理模块，以及在使用 GAN 进行音乐生成时是否应该记住一些事情，以及是否有任何我可以使用的技巧。 ​ ​ p&gt; 谢谢！   由   提交 /u/KiraGhoulEmperor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198s5l1/d_audio_generation_using_gan/</guid>
      <pubDate>Wed, 17 Jan 2024 08:51:59 GMT</pubDate>
    </item>
    <item>
      <title>[N] VizWiz 推出 6 项人工智能挑战赛，帮助盲人/弱视社区</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198p87h/n_vizwiz_launches_6_ai_challenges_to_help/</link>
      <description><![CDATA[问候！ 我们很高兴宣布第六届年度VizWiz Grand Challenge 研讨会，将与 CVPR 2024 同期举行。我们欢迎您参加，如果您能帮助我们传播信息，我们将不胜感激。 本次研讨会的部分动机是我们观察到盲人依赖（基于人类的）视觉辅助服务来了解他们十多年来捕捉的图像和视频。我们为人工智能社区引入了视觉问答、少量镜头识别和对象定位数据集挑战，以代表真实的用例。  挑战：  视觉问答 (VQA) VQA 接地 具有多个答案基础的 VQA 基础 少量视频对象识别 少量对象本地化 零样本图像分类  关键日期：  1 月 12 日，星期五：挑战上线 5 月 3 日星期五：向评估服务器提交算法结果 5 月 10 日星期五：提交扩展摘要 5 月 17 日星期五：向作者发出关于扩展摘要决定的通知 挑战结果将在 CVPR 2024 的 VizWiz Grand Challenge 研讨会上公布  期待您的参与！   由   提交/u/eee-vaaah  /u/eee-vaaah reddit.com/r/MachineLearning/comments/198p87h/n_vizwiz_launches_6_ai_challenges_to_help/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198p87h/n_vizwiz_launches_6_ai_challenges_to_help/</guid>
      <pubDate>Wed, 17 Jan 2024 05:42:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练模型的协作平台？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198oqcb/d_collaborative_platform_to_train_your_models/</link>
      <description><![CDATA[嗨，我们正在与我的团队一起培训 OS LLM，并希望一起培训/测试它（实验控制、评估、评论等）。 ..) 现在我们使用重量和重量。偏见，但就我个人而言，我并不是他们用户体验的忠实粉丝。 您还有推荐的其他工具吗？ 谢谢！   由   提交/u/Diligent_Eye1248   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198oqcb/d_collaborative_platform_to_train_your_models/</guid>
      <pubDate>Wed, 17 Jan 2024 05:14:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 离线批量服务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198k375/d_offline_batch_serving/</link>
      <description><![CDATA[我对如何为离线批量预测提供机器学习模型感到困惑。 这是我想做的 -创建一个预定的管道（例如 Airflow、Kubeflow 等）来生成特征，然后从某个对象存储（例如 s3）加载经过训练的模型，生成预测，最后将它们保存到数据仓库中以供使用。这对我来说最有意义。 但是，一些资源似乎建议将模型部署为端点，即使对于批量用例也是如此。值得注意的是，这是 Chip Huyen 的《设计机器学习系统》中推荐的架构。 对此有什么想法吗？我错过了什么吗？   由   提交/u/Appropriate_Cut_6126   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198k375/d_offline_batch_serving/</guid>
      <pubDate>Wed, 17 Jan 2024 01:25:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在组织中推出推荐模型的项目模板/步骤</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198jh0u/d_project_templatesteps_for_rolling_out_a/</link>
      <description><![CDATA[我对构建内容推荐模型有些满意。我不太确定如何确定项目范围以及将项目推出到我们的应用程序中所涉及的更广泛的步骤。 是否有关于项目管理此类功能的蓝图？例如。目标、特征探索、模型选择、训练、测试、“将模型实施到生产中的步骤”？   由   提交/u/back-off-warchild  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198jh0u/d_project_templatesteps_for_rolling_out_a/</guid>
      <pubDate>Wed, 17 Jan 2024 00:57:28 GMT</pubDate>
    </item>
    <item>
      <title>[P]从头开始的小型潜伏扩散变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198eiv1/p_small_latent_diffusion_transformer_from_scratch/</link>
      <description><![CDATA[      我训练了一个相对简单的基于 Transformer 的扩散模型来生成 256 x 256 图像从头开始。这是仓库： https://github.com/apapiu/transformer_latent_diffusion/tree/main - 代码应该希望它相当容易理解并且独立。 以下是在 1A100 从头开始​​训练大约 30 小时后的一些示例： 根据各种提示生成图像 该模型基于 DiT /Pixart-alpha 架构，但进行了各种修改和简化。我还在噪声表方面做出了一些有问题的决定，但似乎工作正常。 该模型是 100MM 参数，因此应该很容易对其进行实验。我欢迎任何反馈，也欢迎合作，所以请联系我们！希望这对想要尝试扩散模型/变压器但“GPU 较差”的人们有所帮助。 :) 该存储库还链接到一个 colab，您可以在其中使用自己的输入 - 请随意尝试。 ​    由   提交 /u/spring_m   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198eiv1/p_small_latent_diffusion_transformer_from_scratch/</guid>
      <pubDate>Tue, 16 Jan 2024 21:29:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何处理雇主提出的不合理要求以及对机器学习不切实际的期望？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19882l2/d_how_do_you_deal_with_unreasonable_request_from/</link>
      <description><![CDATA[几个月前，我接受了一个职位，通过为社会科学研究项目训练机器学习模型来支持该项目。该项目涉及使用团队（由多名实习生、研究生、博士后和教授组成）花费数年时间并付出疯狂努力编制的数据集。然而，问题是他们没有事先咨询任何真正了解机器学习的人。对于非常复杂的任务来说，他们的数据集太小（只有大约 200 行）。更糟糕的是，大多数变量的预测价值微乎其微，而用于推导这些变量的方法虽然非常耗费人力，却引发了人们对其有效性的担忧。 该项目的 MO 绝对令人困惑：通过巨大的数据积累了数千个预测变量。努力和人力，期待完美的结果。任何模型如何用如此小的数据集估计如此多的参数却被忽视了。项目负责人似乎对 ML 有着某种神奇的理解，这可能是受到其在特定领域频繁误用的影响。这个项目的灵感尤其来自于一篇研究论文，我几乎可以保证该论文在其验证集上过拟合。 所有这些都让我处于尴尬的境地，作为新人，我需要告知这一点一个由经验丰富的博士后和教授组成的团队，全部来自社会科学背景，没有定量专业知识，他们多年的工作产生了一个完全不适合他们的目标的数据集，并且他们所建立的现有文献都是错误的，因为他们显然没有不知道什么是测试集以及何时使用它。我也不能告诉他们只扩展数据集，因为达到 200 行已经花费了数年时间。 我必须承认我对这次谈话有点紧张。 ​ 我怀疑对 ML 功能抱有不切实际的期望是一种常见的经历。其他人如何处理这个问题？如果他们坚持不管，你会直白地告诉他们这行不通，然后到别处找工作吗？如果是这样，这些交互通常如何进行？   由   提交 /u/Excusemyvanity   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19882l2/d_how_do_you_deal_with_unreasonable_request_from/</guid>
      <pubDate>Tue, 16 Jan 2024 17:13:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer 是多状态 RNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1986k0x/r_transformers_are_multistate_rnns/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.06104 代码：https ://github.com/schwartz-lab-NLP/TOVA 摘要：  Transformers 被认为在概念上与到上一代最先进的 NLP 模型 - 循环神经网络 (RNN)。在这项工作中，我们证明了仅解码器 Transformer 实际上可以被概念化为无限多状态 RNN——一种具有无限隐藏状态大小的 RNN 变体。我们进一步证明，通过固定隐藏状态的大小，预训练的 Transformer 可以转换为有限多状态 RNN。我们观察到一些现有的转换器缓存压缩技术可以被构建为这样的转换策略，并引入了一种新的策略，TOVA，它比这些策略更简单。我们对多个远程任务进行的实验表明，TOVA 优于所有其他基线策略，同时几乎与完整（无限）模型相当，并且在某些情况下仅使用原始缓存大小的 1/8。我们的结果表明，变压器解码器 LLM 在实践中通常表现为 RNN。他们还提出了缓解最痛苦的计算瓶颈之一——缓存大小的选项。我们在 此 https URL 公开发布我们的代码。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1986k0x/r_transformers_are_multistate_rnns/</guid>
      <pubDate>Tue, 16 Jan 2024 16:12:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] iPhone 文本检测的有趣现象</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197zbzs/d_interesting_occurrence_about_text_detection_of/</link>
      <description><![CDATA[      我点击该图像几次，它检测到第二只狗是单词“dog”用中文写的。我不认为这是有原因的，但如果有人有任何想法，我很乐意听到他们。   由   提交/u/Ok_Care_886   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197zbzs/d_interesting_occurrence_about_text_detection_of/</guid>
      <pubDate>Tue, 16 Jan 2024 09:57:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>