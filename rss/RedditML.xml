<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 28 Dec 2023 21:11:46 GMT</lastBuildDate>
    <item>
      <title>Tensorflow-Metal 是否针对 M3 Pro 芯片进行了优化？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18t2njt/is_tensorflowmetal_optimized_for_m3_pro_chip_d/</link>
      <description><![CDATA[我尝试为我的多注意力头变压器下载 Tensorflow-Metal 包，用于序列数据的疾病风险预测。然而，当我使用 GPU 并且我确实验证了它正在被利用时，它花费的时间是 CPU 的 3 倍吗？用于验证和测试的批量大小设置为 32。任何提示或想法将不胜感激:)   由   提交 /u/DataWizJesse   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18t2njt/is_tensorflowmetal_optimized_for_m3_pro_chip_d/</guid>
      <pubDate>Thu, 28 Dec 2023 19:45:29 GMT</pubDate>
    </item>
    <item>
      <title>[r]合作邀请：共同推进机器学习算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18t20ht/rinvitation_for_collaboration_advancing_machine/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18t20ht/rinvitation_for_collaboration_advancing_machine/</guid>
      <pubDate>Thu, 28 Dec 2023 19:17:46 GMT</pubDate>
    </item>
    <item>
      <title>2023年哪些神经网络突破源自80、90年代的研究？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18t01ai/which_neural_network_breakthroughs_in_2023/</link>
      <description><![CDATA[该研究现在的相关性如何？像曼巴这样的（潜在的）突破是否受到了它们的启发？   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18t01ai/which_neural_network_breakthroughs_in_2023/</guid>
      <pubDate>Thu, 28 Dec 2023 17:55:40 GMT</pubDate>
    </item>
    <item>
      <title>组合神经网络[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sxwdi/combined_neural_network_d/</link>
      <description><![CDATA[如果您有一个由 2 部分组成的神经网络，第一部分负责回归任务以逼近某个值，第二部分的输出为第一部分并将其分为两个不同的类别。如果使用分类损失以端到端方式训练整个模型，模型的回归部分会达到其最佳参数吗？   由   提交/u/muzzez321  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sxwdi/combined_neural_network_d/</guid>
      <pubDate>Thu, 28 Dec 2023 16:27:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基础模型推理综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sxpzt/r_a_survey_of_reasoning_with_foundation_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.11562 项目页面：https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models 摘要：  推理是解决复杂问题的关键能力，在谈判、医疗诊断和刑事调查等各种现实环境中发挥着关键作用。它是通用人工智能（AGI）领域的基本方法论。随着基础模型的不断发展，人们越来越有兴趣探索其推理任务的能力。在本文中，我们介绍了提出的或适用于推理的开创性基础模型，重点介绍了各种推理任务、方法和基准的最新进展。然后，我们深入研究基础模型中推理能力的出现背后潜在的未来方向。我们还讨论了推理背景下多模态学习、自主代理和超级对齐的相关性。通过讨论这些未来的研究方向，我们希望能够启发研究人员对该领域的探索，激发基础模型推理的进一步进步，为AGI的发展做出贡献。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sxpzt/r_a_survey_of_reasoning_with_foundation_models/</guid>
      <pubDate>Thu, 28 Dec 2023 16:20:18 GMT</pubDate>
    </item>
    <item>
      <title>[R] SWAG方法中为什么需要方差项？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sxo2n/r_why_is_the_variance_term_in_swag_method_needed/</link>
      <description><![CDATA[      我的问题是关于 SWA-高斯论文。我不太明白为什么他们需要协方差矩阵的 1/2 因子（如图中下划线所示）。我知道这是必要的，因为术语 diag 和 low-rank 基本上都包含方差，所以我们不想过度计算。但协方差项仅输入低秩项，因此将其乘以 1/2 意味着低估它们。我对么？老实说，我不明白如果低秩项同时包含方差和协方差，为什么我们还需要diag项？  脚注 4 说：\“我们使用二分之一作为此处进行缩放，因为对角线项和低阶项都包含权重的方差。我们在附录 D 中测试了其他几种量表。\&quot; 谢谢。   由   提交/u/Significant_Chip_269   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sxo2n/r_why_is_the_variance_term_in_swag_method_needed/</guid>
      <pubDate>Thu, 28 Dec 2023 16:18:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] Pangu-Agent：具有结构化推理的可微调多面手智能体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sxgg7/r_panguagent_a_finetunable_generalist_agent_with/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.14878 摘要：  创建人工智能（AI）代理的关键方法是强化学习（RL）。然而，构建一个将感知直接映射到行动的独立强化学习策略会遇到严重的问题，其中最主要的是它缺乏跨多个任务的通用性以及需要大量的训练数据。主要原因是在制定政策时无法有效地将先验信息融入到感知-行动循环中。大型语言模型（LLM）作为将跨领域知识融入人工智能代理的基本方式而出现，但缺乏针对特定决策问题的关键学习和适应。本文提出了一个将结构化推理集成和学习到人工智能代理策略中的通用框架模型。我们的方法论受到人脑模块化的启发。该框架利用内在和外在函数的构造来添加先前对推理结构的理解。它还提供了学习每个模块或功能内部模型的自适应能力，与认知过程的模块化结构一致。我们深入描述了该框架，并将其与其他人工智能管道和现有框架进行了比较。本文探讨了实际应用，包括证明我们方法有效性的实验。我们的结果表明，当嵌入有组织的推理和先验知识时，人工智能代理的表现和适应能力要好得多。这为更具弹性和通用的人工智能代理系统打开了大门。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sxgg7/r_panguagent_a_finetunable_generalist_agent_with/</guid>
      <pubDate>Thu, 28 Dec 2023 16:09:19 GMT</pubDate>
    </item>
    <item>
      <title>理论机器学习的发展有多快？ [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18swhwf/how_fastmoving_is_theoretical_machine_learning/</link>
      <description><![CDATA[与应用机器学习/计算机科学其他领域的步伐是否存在差异？   由   提交/u/Street_Comfortable38   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18swhwf/how_fastmoving_is_theoretical_machine_learning/</guid>
      <pubDate>Thu, 28 Dec 2023 15:28:20 GMT</pubDate>
    </item>
    <item>
      <title>[R]可解释强化学习研究综合概述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18suecx/r_comprehensive_overview_of_explainable/</link>
      <description><![CDATA[您好，我在  上概述了可解释的强化学习研究https://github.com/yanzheb/xrl。我计划保持这个存储库最新并不断添加新论文。希望你觉得它有用。欢迎任何反馈。   由   提交/u/peppercat-2c4t9  /u/peppercat-2c4t9 reddit.com/r/MachineLearning/comments/18suecx/r_compressive_overview_of_explainable/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18suecx/r_comprehensive_overview_of_explainable/</guid>
      <pubDate>Thu, 28 Dec 2023 13:52:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于文本生成模型的主动学习管道。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18su3p3/r_active_learning_pipeline_for_text_generation/</link>
      <description><![CDATA[我之前曾使用小文本为分类模型构建主动学习管道。现在，小文本使用受模型不确定性（低置信度）约束的算法来从数据集中挑选最佳示例进行训练，这在文本生成的情况下不起作用，因为您需要大量潜在的下一个单词使一代人多样化的候选人。因此，不确定的分数并不一定意味着需要标记的考试。  所以我目前迷失在洗牌中，不知道如何继续。我的目标是使用“rouge-score”进行主动学习适用于 T5 或 Flan-T5 型号。是否有任何库或博客可以帮助构建像小文本那样的管道？   由   提交/u/cedar_mountain_sea28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18su3p3/r_active_learning_pipeline_for_text_generation/</guid>
      <pubDate>Thu, 28 Dec 2023 13:37:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 开源法学硕士在代码编辑方面与 OpenAI 相去甚远</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18st9wa/r_open_source_llms_are_far_from_openai_for_code/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2312.12450  标题：可以编辑吗？评估大型语言模型遵循代码编辑指令的能力 代码存储库：https://github.com/nuprl/ CanItEdit 摘要：  大量研究集中在开发和评估用于各种代码合成任务的大型语言模型。其中包括从自然语言指令合成代码、从代码合成测试以及合成代码解释。相比之下，法学硕士的教学代码编辑行为尚未得到充分研究。在这些任务中，模型被指示更新提示中提供的代码块。编辑指令可能要求添加或删除功能、描述错误并要求修复、要求不同类型的解决方案或许多其他常见的代码编辑任务。我们引入了精心设计的代码编辑任务基准，并用它评估了几个前沿的法学硕士。我们的评估揭示了最先进的开放模型和封闭模型的能力之间的巨大差距。例如，即使是 GPT-3.5-Turbo 在编辑代码方面也比最好的开放模型好 8.8%。我们还引入了一套新的、精心策划的、经过许可的代码编辑训练集以及自然语言指令。使用这个训练集，我们表明我们可以微调开放代码法学硕士，以显着提高他们的代码编辑能力。  讨论： 我正在分享这篇论文开始讨论。免责声明：本文来自我们的研究小组，但无意在此进行自我推销。我们看到，在程序综合评估中，开源代码 LLM 慢慢地越来越接近 GPT-4 的性能，并超越了 GPT-3.5-turbo（请参阅 DeepSeek Coder：https://github.com/deepseek-ai/DeepSeek-Coder) 当使用常见基准测试时，例如 HumanEval、MBPP 和 *新* LeetCode 问题（这是为了尽量减少污染）。 但是，这不是您想要的方式。通常，需要修改一段带有自然语言指令的代码（例如，Cursor IDE 已经从 GitHub Copilot 风格转变为仅专注于代码编辑：https://cursor.sh/features）。此外，通过代码编辑训练的模型可以实现简单的代码生成，可以通过在窗口前用空白提示模型来将其视为代码编辑的子集。 在我们的各种研究项目中，我们已经看到代码法学硕士在代码编辑方面遇到了困难。所以我们做了显而易见的事情，我们检查了这些模型在这个特定任务中的表现。令人惊讶的是，与 GPT-3.5-turbo 相比，在简单合成方面表现出色的模型在代码编辑方面却表现不佳。 为什么会出现这种情况？虽然有些人认为存在数据污染，但考虑到这些模型在新的和未见过的基准上的有效性，我怀疑这是主要因素。难道 OpenAI 专用于代码或语言编辑等任务的特定数据子集（然后将模型推广为代码）？   由   提交/u/ellev3n11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18st9wa/r_open_source_llms_are_far_from_openai_for_code/</guid>
      <pubDate>Thu, 28 Dec 2023 12:54:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] CART 决策树和随机森林中的小偏差</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ss4ko/r_a_small_bias_in_cart_decision_trees_and_random/</link>
      <description><![CDATA[决策树和随机森林对于属性的缩放是不变的。有趣的是，它们对于属性的镜像（即乘以 -1）并不是不变的。准确地说，如果存在可能取与二叉 CART 树中的阈值一致的值的特征，则该特征的镜像会导致推理时间的偏差。这并不是一个很大的偏差，但是可以达到r2和AUC的0.1-0.2个百分点左右。 好的一点是，在随机森林的情况下，这个偏差基本上可以消除。通过在大约一半的树中使用轴镜像扩展 boostrap 采样来降低成本。 我们相应的论文中提供了更多示例和定量评估：[2312.10708] 二元决策树和随机森林中的条件偏差及其消除 (arxiv.org)  您认为值得为 sklearn 准备 PR随机森林、R 树，或者更确切地说，发布一个带有随机森林的非常小的包，以消除这种偏差？欢迎任何评论！ ​   由   提交 /u/gykovacs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ss4ko/r_a_small_bias_in_cart_decision_trees_and_random/</guid>
      <pubDate>Thu, 28 Dec 2023 11:49:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 未经训练的卷积神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s9l3j/d_untrained_convolutional_neural_networks/</link>
      <description><![CDATA[根据标题，我正在探索一个利基主题：使用未经训练的卷积神经网络 (CNN) 作为特征提取器。现有的研究已经证明，即使没有训练，CNN 仍然可以从数据中捕获一些有意义的特征。 因此，我对任何专注于提高未经训练的 CNN 特征提取能力的方法的论文或研究感兴趣，或者探索替代（无需训练）的方法。 目前，我能够找到研究未经训练的 CNN 效率的论文  [1] [2] 或使用它们作为特征提取器的[3] [4] 具体任务和架构。然而，这些论文中没有一篇试图深入研究无需传统的基于梯度的优化即可增强提取特征的方法。 有关此主题的任何共享资源或指导将不胜感激。预先感谢您！   由   提交 /u/RussB3ar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s9l3j/d_untrained_convolutional_neural_networks/</guid>
      <pubDate>Wed, 27 Dec 2023 19:58:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我从头开始制作了一个教育自动毕业</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s0adx/p_i_made_an_educational_autograd_from_scratch/</link>
      <description><![CDATA[学习机器学习，我一直对 PyTorch 及其 Autograd 引擎感兴趣。  在这个项目中，我尝试重新实现 PyTorch 的大部分&lt; /strong&gt;（包括 Autograd）以记录完善、单元测试且可解释的方式从头开始。它对我来说非常有用，我希望它也能帮助您更好地了解 Autograd！  希望您喜欢！  GitHub 存储库此处！   由   提交 /u/suspicious_beam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s0adx/p_i_made_an_educational_autograd_from_scratch/</guid>
      <pubDate>Wed, 27 Dec 2023 13:06:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>