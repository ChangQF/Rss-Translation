<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 15 Jun 2024 18:18:58 GMT</lastBuildDate>
    <item>
      <title>[P] 寻求有关我的 GenAI Job Fit 项目的反馈 - LangChain/LangGraph 新手</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dgns9p/p_seeking_feedback_on_my_genai_job_fit_project/</link>
      <description><![CDATA[大家好， 我一直在做一个名为 GenAI Job Fit 的项目。这是一个人工智能驱动的系统，旨在通过根据个人资料提供量身定制的建议来增强求职申请。 我对 LangChain 和 LangGraph 还比较陌生，我已将它们纳入这个项目。如果您能查看存储库并提供任何反馈或改进建议，我将不胜感激。 您对如何更好地实现 LangChain/LangGraph 或项目任何其他方面的见解将非常有价值。我渴望学习并使这个项目尽可能的健壮。 提前感谢您的时间和反馈！ Repo 链接：https://github.com/DAVEinside/GenAI_Job_Fit    提交人    /u/Nimitzxz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dgns9p/p_seeking_feedback_on_my_genai_job_fit_project/</guid>
      <pubDate>Sat, 15 Jun 2024 18:04:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 资源 批评 Grad-CAM 论文版本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dgksmj/r_resources_critiquing_gradcam_paper_versions/</link>
      <description><![CDATA[大家好， 我正在写一份关于几年前发表的 Grad-CAM 论文的报告。在研究过程中，我发现这篇论文有多个版本，从版本 1 到版本 4。我特别想找到一些资源来批评早期版本的缺点以及其他版本的变化。 如果有人能向我指出任何此类资源，我将不胜感激。 谢谢！    提交人    /u/dduka99   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dgksmj/r_resources_critiquing_gradcam_paper_versions/</guid>
      <pubDate>Sat, 15 Jun 2024 15:43:21 GMT</pubDate>
    </item>
    <item>
      <title>[P] 创建手语到语音转换器 GUI，但面临 cv2 的 bbox 问题。有什么想法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dgknz4/p_creating_a_signlanguage_to_speech_converter_gui/</link>
      <description><![CDATA[高中生创建 ASL 手语到文本转换器。我尝试更新我的 cv2 和 bbox，但它已经是最新版本了。每次我运行 data_collection_final.py 文件时，它都会返回错误“TypeError：列表索引必须是整数或切片，而不是 str”，关于此行：x, y, w, h = hand[&#39;bbox&#39;] 如果相关，它也会提前返回此信息。不确定这是什么意思。 2024-06-15 23:33:23.467993：I tensorflow/core/util/port.cc:113] oneDNN 自定义操作已开启。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量“TF_ENABLE_ONEDNN_OPTS=0”。有人可以帮忙/建议如何解决这个错误的 bbox 错误吗？ import cv2 from cvzone.HandTrackingModule import HandDetector import numpy as np import os as oss import traceback capture = cv2.VideoCapture(0) hd = HandDetector(maxHands=1) hd2 = HandDetector(maxHands=1) count = len(oss.listdir(&quot;C:\\Users\\Arush\\ASL_Sign_Language_To_Speech_Translator\\CUSTOM_OBJECT_DETECTION_MODEL\\AtoZ_3.1\\A\\&quot;)) c_dir = &#39;A&#39; offset = 15 step = 1 flag = False suv = 0 white = np.ones((400, 400), np.uint8) * 255 cv2.imwrite（“C:\\Users\\Arush\\ASL_Sign_Language_To_Speech_Translator\\CUSTOM_OBJECT_DETECTION_MODEL\\white.jpg”，white） while True： try：_，frame = capture.read（） frame = cv2.flip（frame，1） hands = hd.findHands（frame，draw=False，flipType=True） white = cv2.imread（“C:\\Users\\Arush\\ASL_Sign_Language_To_Speech_Translator\\CUSTOM_OBJECT_DETECTION_MODEL\\white.jpg”） if hands： hand = hands[0] x，y，w，h = hand[&#39;bbox&#39;] image = np.array(frame[y - 偏移量：y + h + 偏移量，x - 偏移量：x + w + 偏移量]) handz，imz = hd2.findHands(image, draw=True, flipType=True) if handz: hand = handz[0] pts = hand[&#39;lmList&#39;] # x1,y1,w1,h1=hand[&#39;bbox&#39;] os = ((400 - w) // 2) - 15 os1 = ((400 - h) // 2) - 15 # 为骨架绘制线条 for t in range(0, 4, 1): cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), (pts[t + 1][0] + os, pts[t + 1][1] + os1), (0, 255, 0), 3) for t in range(5, 8, 1): cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), （pts[t + 1][0] + os，pts[t + 1][1] + os1），（0，255，0），3）对于范围（9，12，1）内的t： cv2.line（白色，（pts[t][0] + os，pts[t][1] + os1），（pts[t + 1][0] + os，pts[t + 1][1] + os1），（0，255，0），3）对于范围（13，16，1）内的t： cv2.line（白色，（pts[t][0] + os，pts[t][1] + os1），（pts[t + 1][0] + os，pts[t + 1][1] + os1），（0，255，0），3）对于范围（17，20，1）内的t： cv2.line(白色，(pts[t][0] + os，pts[t][1] + os1)，(pts[t + 1][0] + os，pts[t + 1][1] + os1)，(0, 255, 0)，3) cv2.line(白色，(pts[5][0] + os，pts[5][1] + os1)，(pts[9][0] + os，pts[9][1] + os1)，(0, 255, 0)，3) cv2.line(白色，(pts[9][0] + os，pts[9][1] + os1)，(pts[13][0] + os，pts[13][1] + os1)，(0, 255, 0)，3) pts[13][1] + os1), (pts[17][0] + os, pts[17][1] + os1), (0, 255, 0), 3) cv2.line(白色, (pts[0][0] + os, pts[0][1] + os1), (pts[5][0] + os, pts[5][1] + os1), (0, 255, 0), 3) cv2.line(白色, (pts[0][0] + os, pts[0][1] + os1), (pts[17][0] + os, pts[17][1] + os1), (0, 255, 0), 3) Skeleton0 = np.array(白色) zz = np.array(白色) for i in range(21): cv2.circle(白色, (pts[i][0] + os, pts[i][1] + os1), 2, (0, 0, 255), 1) Skeleton1 = np.array(white) cv2.imshow(&quot;1&quot;, Skeleton1) frame = cv2.putText(frame, &quot;dir=&quot; + str(c_dir) + &quot; count=&quot; + str(count), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1, cv2.LINE_AA) cv2.imshow(&quot;frame&quot;, frame) Interrupt = cv2.waitKey(1) 如果中断 &amp; 0xFF == 27: # esc 键中断 如果中断 &amp; 0xFF == ord(&#39;n&#39;): c_dir = chr(ord(c_dir) + 1) 如果 ord(c_dir) == ord(&#39;Z&#39;) + 1: c_dir = &#39;A&#39; flag = False count = len(oss.listdir(&quot;C:\\Users\\Arush\\ASL_Sign_Language_To_Speech_Translator\\CUSTOM_OBJECT_DETECTION_MODEL\\AtoZ_3.1\\&quot; + (c_dir) + &quot;\\&quot;)) 如果中断 &amp; 0xFF == ord(&#39;a&#39;): 如果 flag: flag = False else: suv = 0 flag = True print(&quot;=====&quot;, flag) 如果 flag == True: 如果 suv == 180: flag = False 如果 step % 3 == 0: cv2.imwrite(&quot;C:\\Users\\Arush\\ASL_Sign_Language_To_Speech_Translator\\CUSTOM_OBJECT_DETECTION_MODEL\\AtoZ_3.1\\&quot; + (c_dir) + &quot;\\&quot; + str(count) + &quot;.jpg&quot;,skeleton1) count += 1 suv += 1 step += 1 除外异常： print(&quot;==&quot;, traceback.format_exc()) capture.release() cv2.destroyAllWindows()     由    /u/Queasy_Boss5998  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dgknz4/p_creating_a_signlanguage_to_speech_converter_gui/</guid>
      <pubDate>Sat, 15 Jun 2024 15:37:15 GMT</pubDate>
    </item>
    <item>
      <title>生成扩散模型通过 15 个概念逐步解释！[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dgist5/generative_diffusion_models_explained_stepbystep/</link>
      <description><![CDATA[从我的 YT 频道分享一段关于潜在扩散模型的视频，从基础到一些非常高级的东西。我还分享了我从头开始实现一个简单的扩散模型来根据文本提示生成人脸的经验。尽情享受吧！ 链接：https://youtu.be/w8YQcEd77_o    由   提交  /u/AvvYaa   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dgist5/generative_diffusion_models_explained_stepbystep/</guid>
      <pubDate>Sat, 15 Jun 2024 14:09:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 什么是内存调整，它如何比 RAG 和提示提供更高的准确性和速度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dgi1bg/r_whats_memory_tuning_and_how_does_it_give_higher/</link>
      <description><![CDATA[首先，它是如何工作的：  Memory Tuning 可以对任何开源 LLM 上的数百万个 LoRA 适配器（内存专家）进行微调，以确保准确的事实回忆。 在推理过程中，模型会检索并整合最相关的专家（很像信息检索）。这样可以大大提高准确率，并减少幻觉。 这种方法保持了模型的泛化能力，同时专注于特定事实的零误差。  为什么这比 RAG 更好？ RAG 会在不消除错误的情况下改变概率，而 Memory Tuning 可以完全纠正不准确性。 Lamini 发布了面向企业的 Memory Tuning 解决方案，案例研究显示，文本到 SQL、标签甚至推荐任务的准确率都有惊人的提升。 论文：https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf 我每天在我的 LinkedIn 上分享高质量的 AI 更新和教程：https://www.linkedin.com/in/sarthakrastogi/ 如果您喜欢这篇文章并希望了解最新的 AI 研究，您可以查看：https://linktr.ee/sarthakrastogi。    提交人    /u/sarthakai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dgi1bg/r_whats_memory_tuning_and_how_does_it_give_higher/</guid>
      <pubDate>Sat, 15 Jun 2024 13:30:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在会议上建立人际网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dgem3j/d_how_to_network_at_a_conference/</link>
      <description><![CDATA[如何在会议中建立人脉 大家好！我下周要参加我的第一个大型会议 - CVPR。每个人都提到我应该花很多时间与其他学生和高级研究人员建立人脉。我还设法获得了 Google 和 Meta 的社交邀请。 我不擅长社交。我该如何与其他研究人员接触并与他们谈论潜在的合作或研究实习机会，而不会显得有求于人？ 也非常感谢任何关于如何最大限度地利用我在 CVPR 的时间的一般建议。谢谢！    提交人    /u/SherlockGPT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dgem3j/d_how_to_network_at_a_conference/</guid>
      <pubDate>Sat, 15 Jun 2024 10:00:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分层瓶颈神经块</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dgd6g1/d_hierarchical_bottlenecked_neural_blocks/</link>
      <description><![CDATA[嵌入计算网络是尝试以最佳方式将未压缩的单词或句子的编码压缩为尽可能少的输出的结果。 将这些瓶颈纳入大型神经网络架构（很可能是不同大小的层次结构）是否有助于泛化？ 例如，可以通过定义由相对较小的神经构建块组成的神经架构来利用这些瓶颈，这些构建块具有许多输入和较少的输出。也可能纳入由前一级块组成的更高级别的瓶颈。从某种意义上说，一个神经元也是零级瓶颈，其中许多输入被转换成一个输出。 可以调整反向传播算法，使较小的块比下一级块经历更多的批量迭代。 这种技术尝试过吗？    提交人    /u/ikoukas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dgd6g1/d_hierarchical_bottlenecked_neural_blocks/</guid>
      <pubDate>Sat, 15 Jun 2024 08:14:12 GMT</pubDate>
    </item>
    <item>
      <title>BERT主题模型[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dgbuln/berttopic_model_d/</link>
      <description><![CDATA[大家好，我对 BERTopic 模型有疑问。由于这是一个无监督模型，并且倾向于随机模型，我们该如何处理某些事情：1) 由于我计划让团队每月运行一次 - 我如何确定 UMAP 和 HDBScan 聚类的哪组参数可以很好地为我从文档中提供关键词 2) 确保每月运行之间的稳定性。Random_state？ 我正在使用句子转换器创建嵌入。任何线索都将不胜感激     提交人    /u/beeblebrox25   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dgbuln/berttopic_model_d/</guid>
      <pubDate>Sat, 15 Jun 2024 06:40:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] CFG++：解决扩散模型中 CFG 缺陷的简单方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dg9mvc/r_cfg_a_simple_fix_for_addressing_the_flaws_of/</link>
      <description><![CDATA[      无分类器指导 (CFG) 广泛用于扩散模型中的文本指导，但因其挑战而臭名昭著，例如难度在 DDIM 反演和选择较大指导尺度时的模糊性方面的问题。 本文表明，CFG 的这些局限性源于原始 CFG 中固有的设计缺陷，并介绍了 CFG++，一种简单但功能强大的修复*re\*nosing 过程的方法。这种调整有利于缩小引导尺度，显著提高可逆性，并大大提高图像和文本之间的对齐效果。 项目页面：https://cfgpp-diffusion.github.io/ Github：https://github.com/CFGpp-diffusion/CFGpp 论文：https://arxiv.org/abs/2406.08070 https://preview.redd.it/lph7aufcvn6d1.png?width=854&amp;format=png&amp;auto=webp&amp;s=5e4bfeb1af9563bb30b29848386f02b11f13fbdc    提交人    /u/Fit_Entrepreneur_588   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dg9mvc/r_cfg_a_simple_fix_for_addressing_the_flaws_of/</guid>
      <pubDate>Sat, 15 Jun 2024 04:16:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] Nemotron-4 340b详细分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dfywwi/d_nemotron4_340b_detailed_analysis/</link>
      <description><![CDATA[      我查看了 NVIDIA 的 340B Nemotron LLM - 我发现了一些问题：  Squared ReLU 与 Llama SwiGLU 不同，Gemma GeGLU。与 arxiv.org/pdf/2002.05202 中发现的 GLU 变体不同（GLU 变体改进了 Transformer，Noam Shazeer） ReGLU 是 [ ReLU(X * W_gate) * (X * W_up) ] * W_down 我们需要 2 个 ReLU + 绑定权重 [ ReLU(X * W_up) * ReLU(X * W_up) ] * W_down，因此有点像 GLU，但不完全相同 Squared ReLU 为何有效？入门论文：https://arxiv.org/abs/2109.08668v2 发现了它。还有 Shazeer 的引言：“我们没有解释为什么这些架构似乎有效；我们将它们的成功归功于上帝的仁慈”  使用 rotary_percentage 为 50%。可能与 Phi-2 的 partial_rotary_factor 有关？- Phi-2 的 rotary_percentage 为 40%，因此对于 Nemotron 来说，似乎只有 50% 的 Q、K 矩阵应用了 RoPE，其余的则不使用 RoPE。  请参阅https://github.com/huggingface/transformers/blob/main/src/transformers/models/phi/modeling_phi.py#L79  解开嵌入，如 Llama。Gemma 已绑定。  Tied 还用于 Apple 的设备 LLM 以节省 VRAM。 根据 LLM 物理学论文 https://arxiv.org/abs/2404.05405  常规 layernorm，不同于 Llama RMS LN。RMS Layernorm 消除了偏差，但不进行均值消除 没有 dropout，没有偏差，如 Llama、Gemma 批量大小随着 42% MFU 增加。Float16 训练没有稀疏性。 4096 序列长度。遗憾的是相当短。 8 万亿代币 - 3 种风格基础、指导、奖励 SFT、DPO、RPO  RPO - 我认为是 2 个步骤？奖励感知偏好优化 HelpSteer2 数据集：https://huggingface.co/datasets/nvidia/HelpSteer2  在某些基准测试中击败 GPT-4o  技术报告：https://research.nvidia.com/publication/2024-06_nemotron-4-340b HF Instruct：https://huggingface.co/nvidia/Nemotron-4-340B-Instruct https://preview.redd.it/vhcke1177l6d1.png?width=980&amp;format=png&amp;auto=webp&amp;s=2458d6c2bd9ed0db14e9f16c5be6e93340f6bfaf    由    /u/danielhanchen 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dfywwi/d_nemotron4_340b_detailed_analysis/</guid>
      <pubDate>Fri, 14 Jun 2024 19:20:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Conda VS Python 的内置 'venv'</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dfwteq/d_using_conda_vs_pythons_inbuilt_venv/</link>
      <description><![CDATA[嘿， 因此，我通常在克隆项目时使用 venv 模块，但我目前正在使用用 C++ 编写的 OpenCV，而 python 模块只是这个 c++ 的包装器。 因此，我必须安装系统级依赖项。这意味着 venv 模块根本无法工作（如果我错了请纠正我），我必须使用 Conda。 我看到关于 Conda 已经过时并且正在使用新东西的文章。你们能确认/分享经验吗！ 谢谢    提交人    /u/No_Weakness_6058   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dfwteq/d_using_conda_vs_pythons_inbuilt_venv/</guid>
      <pubDate>Fri, 14 Jun 2024 17:49:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 改进的 Text2SQL 数据集现已在 Huggingface 上可用！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dfsel1/p_improved_text2sql_dataset_now_available_on/</link>
      <description><![CDATA[我很高兴与大家分享我们一直在研究的更新的开源资源 — 耶鲁大学最初为 Text2SQL 任务发布的 Spider 数据集的改进版本。您可以在此处查看：https://huggingface.co/datasets/RaffaSch121/fixed_spider 在 Turbular 进行我们自己的模型训练期间，我们发现原始数据集中存在几个问题。为了帮助社区并回馈社区，我们决定解决这些问题并发布更正版本。我们希望这个增强的数据集将使所有从事 Text2SQL 和类似项目的人受益。 如果您找到使其更好的方法，请随意下载、试验和回馈   由    /u/RaeudigerRaffi  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dfsel1/p_improved_text2sql_dataset_now_available_on/</guid>
      <pubDate>Fri, 14 Jun 2024 14:38:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 讨论苹果在 iPhone 15 Pro 上部署 30 亿参数 AI 模型——他们是如何做到的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dfoykx/d_discussing_apples_deployment_of_a_3_billion/</link>
      <description><![CDATA[大家好， 所以，我一直在本地运行 Phi-3 mini，老实说，它还不错。尽管在模型文件中进行了所有调整和结构化提示，但这是正常的，尤其是考虑到典型 GPU 设置上的滞后响应时间。我最近在检查 Apple 最近的设备模型，他们在 iPhone 15 Pro 上运行了一个近 30 亿参数的 AI 模型！ 这是 AI 在移动设备上实现可能性的进步。他们想出了一些技巧来实现这一点，我只是想和大家讨论一下：  优化的注意力机制：Apple 通过使用分组查询注意力机制显着降低了计算开销。此方法可批量处理查询，从而减少必要的计算。 共享词汇嵌入：老实说，我对此没有太多了解 - 我需要更多地了解它 量化技术：对模型权重采用 2 位和 4 位量化混合，有效降低了内存占用和功耗。 高效的内存管理：动态加载小型、特定于任务的适配器，可以加载到基础模型中以专门化其功能，而无需重新训练核心参数。这些适配器重量轻，仅在需要时使用，在内存使用方面灵活且高效。 高效的键值 (KV) 缓存更新：即使我都不知道它是如何工作的 功耗和延迟分析工具：他们使用 Talaria 等工具实时分析和优化模型的功耗和延迟。这样一来，他们就可以在性能、功耗和速度之间做出权衡，定制比特率选择，以在不同条件下实现最佳运行。：Talaria 演示视频 通过适配器进行模型专业化：无需重新训练整个模型，只需针对不同任务训练特定的适配器层，即可保持高性能，而无需重新训练整个模型的开销。 Apple 的适配器让 AI 可以随时切换档位以执行不同的任务，同时保持轻便和快速。  有关更详细的见解，请查看 Apple 的官方文档：介绍 Apple Foundation Models 讨论要点：  在移动设备上部署如此庞大的模型的可行性如何？ 这些技术对未来的移动应用有何影响？ 这些策略与典型的桌面 GPU 环境（例如我使用 Phi-3 mini 的体验）中使用的策略相比如何？     提交人    /u/BriefAd4761   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dfoykx/d_discussing_apples_deployment_of_a_3_billion/</guid>
      <pubDate>Fri, 14 Jun 2024 11:50:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] Lamini.AI 推出记忆调节功能：法学硕士准确率达 95%，幻觉减少 10 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dffyfs/r_laminiai_introduces_memory_tuning_95_llm/</link>
      <description><![CDATA[https://www.lamini.ai/blog/lamini-memory-tuning  Lamini Memory Tuning 是一种将事实嵌入 LLM 的新方法，可提高事实准确性并将幻觉减少到以前无法实现的水平 - 对于一位财富 500 强客户来说，Lamini Memory Tuning 的准确率达到了 95%，而其他方法的准确率仅为 50%。幻觉从 50% 减少到 5%。 Lamini Memory Tuning 是一项研究突破，它克服了 AI 世界中一个看似矛盾的现象：实现精确的事实准确性（即没有幻觉），同时坚持使 LLM 变得有价值的泛化能力。 该方法需要在任何开源 LLM（如 Llama 3 或 Mistral 3）之上使用精确的事实调整数百万个专家适配器（例如 LoRA）。如果目标是准确无误地获取罗马帝国的事实，Lamini Memory Tuning 会创建关于凯撒、渡槽、军团和您提供的任何其他事实的专家。受信息检索的启发，该模型在推理时仅从索引中检索最相关的专家 - 而不是所有模型权重 - 因此延迟和成本显着降低。高精度、高速度、低成本：使用 Lamini Memory Tuning，您无需选择。  研究论文：https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf    提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dffyfs/r_laminiai_introduces_memory_tuning_95_llm/</guid>
      <pubDate>Fri, 14 Jun 2024 02:08:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>