<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 04 Feb 2024 18:17:16 GMT</lastBuildDate>
    <item>
      <title>[D] 有什么学习多智能体强化学习的好资源吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aiu3mn/d_any_good_resources_to_learn_multiagent/</link>
      <description><![CDATA[我知道今年出版了一本教科书《多智能体强化学习：基础与现代方法》。  我想知道是否还有其他好的资源（例如视频讲座或幻灯片）。非常感谢。   由   提交 /u/Fashism   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aiu3mn/d_any_good_resources_to_learn_multiagent/</guid>
      <pubDate>Sun, 04 Feb 2024 18:04:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] ANN 虚拟实验室</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aittwd/p_virtual_lab_for_ann/</link>
      <description><![CDATA[我是 AI-DS 分支的一名 b 技术学生。我收到了一个为 Ann 创建虚拟实验室的项目，但我不知道如何模拟神经网络的工作进行实验。   由   提交 /u/Adityamer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aittwd/p_virtual_lab_for_ann/</guid>
      <pubDate>Sun, 04 Feb 2024 17:53:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士如何生成图像 - 变形金刚遇上变分自动编码器 (VQ-VAE)！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ait10k/d_how_llms_generate_images_transformers_meet/</link>
      <description><![CDATA[   /u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ait10k/d_how_llms_generate_images_transformers_meet/</guid>
      <pubDate>Sun, 04 Feb 2024 17:20:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] Chess-GPT，比 GPT-4 小 1000 倍，可以下 1500 Elo 国际象棋。我们可以直观地看到它的内部棋盘状态，并且它可以准确地估计游戏中玩家的 Elo 等级。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aisp4m/p_chessgpt_1000x_smaller_than_gpt4_plays_1500_elo/</link>
      <description><![CDATA[   gpt-3.5-turbo-instruct 的 Elo 等级为 1800，国际象棋看起来很神奇。但事实并非如此！一个参数小 100-1000 倍的法学硕士将在进行数百万局国际象棋比赛后学会如何玩 ELO 1500。 该模型仅经过训练来预测 PGN 字符串中的下一个字符 (1.e4 e5 2.Nf3 ...）并且从未明确给出棋盘状态或国际象棋规则。尽管如此，为了更好地预测下一个角色，它学习计算游戏中任何时刻的棋盘状态，并学习一系列不同的规则，包括将、将死、易位、过路、升级、固定棋子此外，为了更好地预测下一个角色，它还学习估计潜在变量，例如游戏中玩家的 Elo 评级。 我们可以可视化模型的内部棋盘状态，因为它是预测下一个字符。例如，在此热图中，左侧是真实白色棋子位置，中间是二进制探针输出，右侧是探针置信度梯度。我们可以看到该模型非常有信心，没有白棋子位于任一后排。 ​ https://preview.redd.it/dn8aryvdolgc1.jpg?width=2500&amp;format=pjpg&amp;auto=webp&amp;s= 003fe39d8a9bce2cc3271c4c9232c00e4d886aa6 此外，为了更好地预测下一个角色，它还学习估计潜在变量，例如游戏中玩家的 ELO 评级。更多信息请参阅这篇文章： https:/ /adamkarvonen.github.io/machine_learning/2024/01/03/chess-world-models.html 代码在这里：https://github.com/adamkarvonen/chess_llm_interpretability   由   提交 /u/seraine   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aisp4m/p_chessgpt_1000x_smaller_than_gpt4_plays_1500_elo/</guid>
      <pubDate>Sun, 04 Feb 2024 17:06:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于获得 ML 项目实践经验的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aiskl7/d_advice_on_getting_hands_on_experience_in_ml/</link>
      <description><![CDATA[我的背景：一年级研究生 在现实世界的机器学习系统上工作的人对学生有什么建议吗？真的是 ML 工程工作的优秀候选人吗？我问的原因是，所有课程和教程似乎都使用相同的数据集，感觉就像我陷入了一遍又一遍学习基本算法的循环中，而没有真正学习任何可能在行业中使用的东西。包括实习在内的所有工作都需要至少几年的经验。 请分享您对如何思考这个问题或在哪里寻找构建有用项目的想法的任何建议。 谢谢！   由   提交 /u/EkopReddit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aiskl7/d_advice_on_getting_hands_on_experience_in_ml/</guid>
      <pubDate>Sun, 04 Feb 2024 17:01:04 GMT</pubDate>
    </item>
    <item>
      <title>[N] Transformer Circuits 主题：电路更新 - 2024 年 1 月（来自 Anthropic 的可解释性团队）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aiq53l/n_transformer_circuits_thread_circuits_updates/</link>
      <description><![CDATA[电路更新 - 2024 年 1 月.  我们报告了人类可解释性团队的一些发展想法，这些想法可能会引起在该领域积极工作的研究人员的兴趣。其中一些是新兴的研究领域，我们预计在未来几个月内发布更多相关内容。其他都是我们希望分享的次要观点，因为我们不太可能写一篇关于它们的论文。  还包括“其他团体的研究”部分。 &lt; p&gt;线程中的所有帖子。  关于变压器电路线程项目 我们可以将 Transformer 语言模型逆向工程为人类可理解的计算机程序吗？受到 Distill Circuits 线程的启发，我们将尝试一下。    由   提交 /u/Wiskkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aiq53l/n_transformer_circuits_thread_circuits_updates/</guid>
      <pubDate>Sun, 04 Feb 2024 15:17:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果 ICLR 口头论文与我的 ICML 2020 论文明显重叠但仍然被接受，我该怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aintst/d_what_should_i_do_if_an_iclr_oral_paper/</link>
      <description><![CDATA[如果我认为已接受的口头论文没有引用我之前发表的论文，我该怎么办？更重要的是，如果他们这样做了，他们的论文就没有什么新颖性了。提交ID是6795，我的论文可以在这里找到：https://proceedings.mlr.press/v119/nguyen20c。 html。你可以自己判断。   由   提交/u/hoang-nt  /u/hoang-nt  reddit.com/r/MachineLearning/comments/1aintst/d_what_should_i_do_if_an_iclr_oral_paper/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aintst/d_what_should_i_do_if_an_iclr_oral_paper/</guid>
      <pubDate>Sun, 04 Feb 2024 13:25:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 基于 Transformer 的句子 Transformer 去噪自动编码器无监督预训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aimq61/p_tranformerbased_denoising_autoencoder_for/</link>
      <description><![CDATA[一个新的 PyPI 包，只需 2 行即可训练句子嵌入模型。 获取句子嵌入通常需要大量数据的标记数据。然而，在许多情况和领域，标记数据很少可获取，而且此类数据的采购成本高昂。在这个项目中，我们采用了基于预先训练的基于 Transformers 的序列去噪自动编码器 (TSDAE) 的无监督过程，该编码器由达姆施塔特无处不在的知识处理实验室推出，可以实现达到域内监督的 93.1% 的性能水平。  TSDAE 模式包含两个组件：编码器和解码器。在整个训练过程中，TSDAE 将受污染的句子翻译成统一大小的向量，要求解码器利用该句子嵌入来重建原始句子。为了获得良好的重建质量，必须在编码器的句子嵌入中很好地捕获语义。随后，在推理过程中，编码器仅用于形成句子嵌入。 PyPI url :  https://pypi.org/project/tsdae GitHub : https ://github.com/louisbrulenaudet/tsdae 安装： python pip3 install tsdae nltk datasetsentence-transformers torch  Python代码：  ```python from tsdae import TSDAE 初始化 TSDAE 实例 instance = TSDAE() 加载数据集&lt; /h1&gt; train_dataset = instance.load_dataset_from_hf( dataset=&quot;louisbrulenaudet/cgi&quot; ) 使用数据集训练模型 model = instance.train( train_dataset=train_dataset 、 model_name=“bert-base-multilingual-uncased”、column=“output”、output_path=“output/tsdae-lemon-mbert-base” ) ```   由   提交/u/louisbrulenaudet  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aimq61/p_tranformerbased_denoising_autoencoder_for/</guid>
      <pubDate>Sun, 04 Feb 2024 12:22:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我的时间序列是否太随机而无法预测？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aileah/d_is_my_timeseries_too_random_to_be_predicted/</link>
      <description><![CDATA[嗨，我有一个时间序列，我希望预测下一个值。输入数据是多变量，目标目前是单变量。 我的第一个策略当然是展平输入并通过单层神经网络（线性回归）运行它。然后我尝试添加更多层，使用不同的激活函数、dropout、批量归一化等，但是初始结果没有任何改善。查看预测的各个示例，到目前为止，所有模型基本上只是从最新的已知值开始，并趋向于数据集的整体平均值。 我的问题是，单层神经网络是否表现良好作为或比更多层更好，尝试更先进的技术（如 Transformer、TCN、LSTM）是否还有意义，或者这只是浪费时间？ 我在想如果添加的参数甚至多一两层并不能带来任何改进，这表明要捕获的数据实际上几乎没有系统趋势，而且更先进的模型实际上会显得矫枉过正。如果我错了，请纠正我。  如果有人对我如何进一步调查/分析该数据集有一些建议，我们也将不胜感激。有没有办法最终证明/表明更高级的模型无法在此数据集上工作？   由   提交 /u/KaptenKalmar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aileah/d_is_my_timeseries_too_random_to_be_predicted/</guid>
      <pubDate>Sun, 04 Feb 2024 10:56:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] TabLib：包含 6.27 亿个带有上下文的表的数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ail5w0/r_tablib_a_dataset_of_627_million_tables_with/</link>
      <description><![CDATA[ 由   提交 /u/EducationalCicada   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ail5w0/r_tablib_a_dataset_of_627_million_tables_with/</guid>
      <pubDate>Sun, 04 Feb 2024 10:40:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发布负面结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aikp5f/d_publishing_negative_results/</link>
      <description><![CDATA[我一直在从事一个机器学习研究项目，不幸的是，结果与我的假设不一致。我得到了负面结果。 虽然令人沮丧，但我相信分享这些结果具有很大的价值，因为假设本身依赖于合理的理论基础，而且结果并不是先验证据表明将会是负面的。 所以，我的问题是，负面结果可以在顶级机器学习会议（NeurIPS/ICLR/ICML/...）上发表吗？你们中有人遇到过类似的情况吗？您是如何解决这个问题的？您在著名会议上发表负面结果的努力是否成功了？   由   提交/u/Raskolnikov98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aikp5f/d_publishing_negative_results/</guid>
      <pubDate>Sun, 04 Feb 2024 10:09:12 GMT</pubDate>
    </item>
    <item>
      <title>重新表述网络：计算和数据高效语言建模的秘诀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aighsr/rephrasing_the_web_a_recipe_for_compute/</link>
      <description><![CDATA[ 由   提交/u/rrenaud  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aighsr/rephrasing_the_web_a_recipe_for_compute/</guid>
      <pubDate>Sun, 04 Feb 2024 05:33:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 苹果发布 MGIE！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aideah/r_apple_releases_mgie/</link>
      <description><![CDATA[      [ICLR&#39;24 Spotlight] 通过多模态大图指导基于指令的图像编辑语言模型 MLLM引导的基于指令的图像编辑（MGIE）可以遵循用户指令来编辑图像论文：https://openreview.net/forum?id=S1RKWSyZ2Y 项目：https ://mllm-ie.github.io https://preview.redd.it/7abn9yflehgc1.png?width=3183&amp;format=png&amp;auto=webp&amp;s=9fc6c301f49ffaaf1c293c8f5925c603c8 c7dc24 代码/ checkpoint 也是开源的 🔥 Apple 官方仓库：https://github.com/apple/ml-mgie 带 Gradio 演示的仓库：https://github.com/tsujuifu/pytorch_mgie &lt; p&gt;https://preview.redd.it/hyqngv8nehgc1。 png?width=3736&amp;format=png&amp;auto=webp&amp;s=3a70483a7bea6e16500370cee5879e605fe7d51d   由   提交 /u/tsujuifu   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aideah/r_apple_releases_mgie/</guid>
      <pubDate>Sun, 04 Feb 2024 02:42:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 人们还相信LLM的新兴能力吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ai5uqx/r_do_people_still_believe_in_llm_emergent/</link>
      <description><![CDATA[自从[新兴的LLM能力是海市蜃楼吗？](https://arxiv.org/pdf/2304.15004.pdf），人们似乎对涌现非常安静。但是大的[新兴能力](https://openreview.net/pdf?id=yzkSU5zdwD)论文有这一段（第 7 页）： &gt;考虑用于衡量新兴能力的评估指标也很重要（BIG-Bench，2022）。例如，使用精确的字符串匹配作为长序列目标的评估指标可能会将复合增量改进伪装成出现。类似的逻辑可能适用于多步骤或算术推理问题，其中模型仅根据是否正确获得多步骤问题的最终答案来评分，而不会给予部分正确的解决方案任何信用。然而，最终答案准确性的跳跃并不能解释为什么中间步骤的质量突然出现在随机之上，并且使用不给予部分信用的评估指标充其量是一个不完整的解释，因为在许多分类任务中仍然观察到涌现的能力（例如，图 2D-H 中的任务）。 人们怎么想？涌现是“真实的”吗？还是实质性的？   由   提交/u/uwashingtongold  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ai5uqx/r_do_people_still_believe_in_llm_emergent/</guid>
      <pubDate>Sat, 03 Feb 2024 20:50:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>