<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Tue, 27 Aug 2024 01:09:15 GMT</lastBuildDate>
    <item>
      <title>[D]探索边缘计算/联邦学习在 GPT/LLM 持续训练中的潜力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f243mh/dexploring_the_potential_of_edge/</link>
      <description><![CDATA[大家好， 我目前正在深入研究联邦学习和边缘计算，我一直在思考一个想法，我很想听听你们的想法。具体来说，我很好奇使用边缘计算或联邦学习来使 GPT 或大型语言模型 (LLM) 持续可训练是否有任何优势。 如果有潜在的好处，那么聚合过程在全局模型中如何工作？另一方面，如果这种方法可能不是最好的，我真的很感激任何关于为什么会这样或关于在联邦学习中应该关注什么的建议。 我特别想确定这些领域中需要更多关注的研究差距或具体问题。任何指导或想法都将不胜感激！    提交人    /u/StopFrequent542   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f243mh/dexploring_the_potential_of_edge/</guid>
      <pubDate>Tue, 27 Aug 2024 00:42:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您认为哪种旧的学习算法/范式将会很快复兴？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f22foq/d_what_do_you_think_is_an_old_learning/</link>
      <description><![CDATA[即使在 Le-Net 时代，ANN 和反向传播也几乎已经消亡。然而，当他们在 AlexNet 中对其进行扩展时，它获得了更多的支持，现在，我们看到了它的潜力。 在深度学习“复兴”之前，有些人已经认为，如果他们找到如何训练深度学习的方法，深度学习就会成功。 我希望我们讨论过去可能“难以理解/扩展/训练/实施”的其他算法，你认为只要人们认真考虑，这些算法就会成功。    提交人    /u/MysticalDragoneer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f22foq/d_what_do_you_think_is_an_old_learning/</guid>
      <pubDate>Mon, 26 Aug 2024 23:23:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 流匹配和规范化流有什么共同点？流匹配是可逆的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1vizv/d_what_is_common_between_flow_matching_and/</link>
      <description><![CDATA[流匹配是否像标准化流一样可逆？我可以做 G（生成器）逆并使用相同的参数从给定的 x 中取回噪声 z 吗？它介于扩散和 NF 之间吗？我相信这个想法来自连续 NF，并且该方法本身概括了扩散。     提交人    /u/Alternative-Talk1945   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1vizv/d_what_is_common_between_flow_matching_and/</guid>
      <pubDate>Mon, 26 Aug 2024 18:31:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于 Pytorch 中 informers 实现的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1t264/p_question_about_the_implementation_of_informers/</link>
      <description><![CDATA[大家好， 我正在尝试在 Pytorch 中从头开始实现一个通知器，无需库。并将其应用于时间序列预测。为此，我从这个库中复制了代码 https://github.com/AIStream-Peelout/flow-forecast/blob/master/flood_forecast/transformer_xl/informer.py 我已经能够运行模型，我在笔记本中有一个有效的训练循环。但是，我不完全明白我应该给模型的前向方法提供什么。 前向方法如下： forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec) x_enc 和 x_mark_enc 很简单，它们分别是一批具有时间序列值的示例和一个具有日期信息的张量。例如，如果批量大小为 32，我使用长度为 24 的时间序列，并且我有 6 个时间序列，那么 x_enc 的尺寸为 32 x 24 x 6，x_mark_enc 的尺寸为 32 x 24x 4，4 为 [月、日、时、分] 整数。 但是我应该为 x_dec、x_mark_dec 提供什么呢？ 现在在我的训练循环中，我只是说 x_dec=x_enc 和 x_mark_dec=x_mark_enc，但这可能是不正确的。但是我的模型能够学习。 为了进一步解释我的批次的结构，x_enc 尺寸为 32x24x6，其中 32 是我的批次大小，24 是我的时间序列的长度（以小时为单位），6 是因为我正在进行多元预测，所以我使用 6 个不同的时间序列进行预测。 谢谢！    提交人    /u/Legal_Ad_1096   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1t264/p_question_about_the_implementation_of_informers/</guid>
      <pubDate>Mon, 26 Aug 2024 16:51:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 类似 SAM2 的追踪器，但速度更快</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1su5r/d_trackers_like_sam2_but_faster/</link>
      <description><![CDATA[对于所有已经尝试或熟悉 Segment Anything Model 2 (SAM2) 的人。如您所知，它跟踪物体的能力确实很棒。  我设法结合了 RT-DETR 和 SAM2，我使用 RT-DETR 进行检测，使用 SAM2 进行跟踪，结果确实令人印象深刻。我一直用它来跟踪车辆，即使在低质量的监控视频中，这种组合对于小型车辆也非常有效。我在一些交通视频中定性地比较了这种组合的结果以及 RT-DETR + DeepSort，它要好得多。  SAM2 最大的问题是推理速度慢，这使其不适合实时应用。 您知道任何与 SAM2 一样好或更好的跟踪模型吗？    提交人    /u/henistein   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1su5r/d_trackers_like_sam2_but_faster/</guid>
      <pubDate>Mon, 26 Aug 2024 16:42:51 GMT</pubDate>
    </item>
    <item>
      <title>MNIST 的少参数模型 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1pmke/few_parameter_models_for_mnist_d/</link>
      <description><![CDATA[我正在寻找人们尝试使用尽可能少的权重进行数字识别的论文。  我发现很多研究都试图用几千个参数实现超过 99% 的准确率，但是如果你将权重降至几百甚至少于 100 个会怎样？你能达到的最大准确率是多少？ 无需付出太多努力并使用 &lt;100 个参数，我可以轻松获得 ~50% 的准确率。那么肯定有人比我聪明尝试过这个并且做得更好？    提交人    /u/Peraltinguer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1pmke/few_parameter_models_for_mnist_d/</guid>
      <pubDate>Mon, 26 Aug 2024 14:30:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我发表了我的第一篇出版物！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1ove1/r_i_got_my_first_publication/</link>
      <description><![CDATA[大约一年前，我儿时的一个朋友是一名医生，他突然打电话给我，问我是否有兴趣实现他关于使用 ML 筛选和选择肝癌患者进行移植的想法，我说为什么不呢。 上周末，我收到了我们的期刊出版物00558-0/abstract)的电子邮件，我想分享这个消息：D 附注 - 任何有兴趣阅读该论文的人，请随时 DM    提交人    /u/theahmedmustafa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1ove1/r_i_got_my_first_publication/</guid>
      <pubDate>Mon, 26 Aug 2024 13:58:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] DeepSeek-Prover-V1.5：利用证明助手反馈进行强化学习和蒙特卡洛树搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1nld3/r_deepseekproverv15_harnessing_proof_assistant/</link>
      <description><![CDATA[      论文： https://arxiv.org/pdf/2408.08152 摘要：  我们引入了 DeepSeek-Prover-V1.5，这是一个为 Lean 4 中的定理证明而设计的开源语言模型，它通过优化训练和推理过程增强了 DeepSeek-Prover-V1。该模型在 DeepSeekMath-Base 上进行了预训练，专门用于形式数学语言，然后使用源自 DeepSeek-Prover-V1 的增强形式定理证明数据集进行监督微调。通过从证明助手反馈 (RLPAF) 进行强化学习实现进一步细化。除了 DeepSeek-Prover-V1 的单次整体证明生成方法之外，我们还提出了 RMaxTS，这是蒙特卡洛树搜索的一种变体，它采用内在奖励驱动的探索策略来生成多样化的证明路径。DeepSeek-Prover-V1.5 比 DeepSeek-Prover-V1 有显著的改进，在高中级 miniF2F 基准测试集（63.5%）和本科级 ProofNet 基准测试集（25.3%）上取得了新的最先进结果。  视觉亮点： https://preview.redd.it/z386xeiba0ld1.png?width=829&amp;format=png&amp;auto=webp&amp;s=c2f2b814c25ca87642ed62980d5148898894cc00 https://preview.redd.it/3nrvvx0ea0ld1.png?width=1113&amp;format=png&amp;auto=webp&amp;s=9487988841cad2f0f050f60e2e7724b313bd59da https://preview.redd.it/skow3jpga0ld1.png?width=831&amp;format=png&amp;auto=webp&amp;s=a0718db4cd616c7bf360164fc0df098e7c83a3d9 https://preview.redd.it/686t9t7ja0ld1.png?width=979&amp;format=png&amp;auto=webp&amp;s=8c7ea703f971438b1202684818029fe98dda92cd    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1nld3/r_deepseekproverv15_harnessing_proof_assistant/</guid>
      <pubDate>Mon, 26 Aug 2024 12:59:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在多个数据集上训练时，如何处理生产中时间序列分类的规范化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1natx/d_how_to_handle_normalization_for_timeseries/</link>
      <description><![CDATA[我目前正在研究一个时间序列分类模型 (CNN-LSTM)，该模型在多个数据集上进行了训练，每个数据集都有自己独特的值范围。在训练过程中，我使用最小-最大缩放分别对每个数据集进行了规范化，这对模型性能很有效。现在，我正在将模型转移到生产中，并面临规范化的挑战。 情况如下：  该模型在数十个数据集上进行了训练，每个数据集都使用自己的最小值和最大值单独进行了规范化。 在生产中，我需要该模型能够很好地概括我每天收到的新数据集或数据流。  我的问题：  我应该如何在生产中处理规范化？我将每天获得新数据，一些数据集代表来自训练的相同客户，但大多数将是全新的数据集。  我正在考虑的一种方法是为每个数据集从前 12 个月中获取 Min-Max 并每天应用于新数据。  这会是训练期间未见过的数据集的问题吗？   有人处理过类似的情况吗？您如何确保规范化的一致性，同时保持模型性能的稳健性？     提交人    /u/SirCarpetOfTheWar   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1natx/d_how_to_handle_normalization_for_timeseries/</guid>
      <pubDate>Mon, 26 Aug 2024 12:45:27 GMT</pubDate>
    </item>
    <item>
      <title>NNsight 和 NDIF：民主化访问基础模型内部</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1lb6m/nnsight_and_ndif_democratizing_access_to/</link>
      <description><![CDATA[  由    /u/Noak3  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1lb6m/nnsight_and_ndif_democratizing_access_to/</guid>
      <pubDate>Mon, 26 Aug 2024 10:56:46 GMT</pubDate>
    </item>
    <item>
      <title>大学研究项目：需要参与者！[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1kq4m/university_research_project_participants_needed_p/</link>
      <description><![CDATA[大家好！ 我目前正在为我的大学进行研究，我正在寻找任何潜在的受访者。我正在研究软件开发人员对使用受版权保护的材料来培训基于文本的 LLM 的看法。 如果您参与过任何类型的 LLM 的开发，或者对任何类型的 LLM 的开发有所了解，我将非常感激有机会向您提出几个问题。 感谢您阅读我的帖子！如果您有兴趣，请发表评论或给我发消息，以便我们继续通信。    提交人    /u/ErmBlegh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1kq4m/university_research_project_participants_needed_p/</guid>
      <pubDate>Mon, 26 Aug 2024 10:19:09 GMT</pubDate>
    </item>
    <item>
      <title>[项目]：用于 AI 模型的 Python 应用程序：欢迎您的反馈！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1a1el/project_python_apps_for_ai_models_your_feedback/</link>
      <description><![CDATA[嗨，我一直在学习一些流行的人工智能模型，并创建了一些与它们相关的 Python 应用程序。欢迎随时尝试，如果您有任何反馈，我将不胜感激！  AutoSubs：用于在视频中嵌入可自定义字幕的 Web 应用程序。 VideoSummarizer：使用自定义字数限制选项总结 YouTube 视频的 Web 应用程序。 StableDiffusion：使用 Stable Diffusion 1.5 进行文本到图像生成和修复的 Python 应用程序。 Image Matting：使用带有 trimap 生成的 ViTMatte 进行背景去除并提高准确度的 Python 应用程序。 Lama Inpainting：用于对象移除和修复的 Python 应用程序，通过升级来保持原始分辨率。 YT Video Downloader：用于通过 URL 下载 YouTube 视频的 Web 实用程序。     提交人    /u/nashPrat   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1a1el/project_python_apps_for_ai_models_your_feedback/</guid>
      <pubDate>Sun, 25 Aug 2024 23:29:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0ybbs/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0ybbs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Aug 2024 15:00:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习到底发生了什么？一些最小模型 (Stephen Wolfram)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0wj6s/r_whats_really_going_on_in_machine_learning_some/</link>
      <description><![CDATA[Stephen Wolfram 最近发表了一篇博客文章，其中提出了一些关于离散神经网络的有趣观点，从自动机的角度来看待训练： https://writings.stephenwolfram.com/2024/08/whats-really-going-on-in-machine-learning-some-minimal-models/    提交人    /u/hardmaru   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0wj6s/r_whats_really_going_on_in_machine_learning_some/</guid>
      <pubDate>Sun, 25 Aug 2024 13:38:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>