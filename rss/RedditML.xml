<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 28 Nov 2023 18:17:23 GMT</lastBuildDate>
    <item>
      <title>[P] minOFT：一个易于使用的 PyTorch 库，用于将正交微调 (OFT) 应用于 PyTorch 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1862am5/p_minoft_an_easytouse_pytorch_library_for/</link>
      <description><![CDATA[嗨r/MachineLearning， 我想分享我在微调语言模型（正交微调）研究中遇到的一项非常有趣的工作的开源实现。 正交微调 (OFT) 是 LoRA 的一种更强大、稳定且样本效率更高的替代方案，LoRA 最初是为微调扩散模型而开发的。 LoRA 通过添加两个低秩矩阵的乘积来更新预训练权重矩阵，而 OFT 将预训练层权重乘以可学习的正交矩阵以应用约束变换。 OFT 的作者最近表明，这种方法（通过名为 butterfly OFT 的巧妙改进）也适用于视觉转换器和语言模型。 灵感来自minLoRA，我认为最好有一个最小的开源存储库来测试并在微调时比较 OFT 与 LoRA语言模型。它也是由 Andrej Karpathy 在 nanoGPT 之上构建的。该库可通过 pip 安装，并且可以与任何 PyTorch 模型（包括 Hugging Face 模型）通用，就像 minLoRA 一样。 欢迎提供反馈和贡献！ https://github.com/alif-munim/minOFT   &amp; #32；由   提交/u/0blue2brown   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1862am5/p_minoft_an_easytouse_pytorch_library_for/</guid>
      <pubDate>Tue, 28 Nov 2023 18:01:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 对齐即代码：使 LLM 应用程序与 Tanuki 一起运行。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1861p30/p_alignmentascode_making_llm_applications_behave/</link>
      <description><![CDATA[我是 Tanuki 的贡献者，一个项目，允许您使用 Python 中的测试驱动语法以声明方式定义 LLM 行为。 通过指定 LLM 必须作为测试履行的合同，它有助于减少 MLOps 并使您能够使用标准开发操作流程将模型的行为与您的要求保持一致。 此外，这些对齐语句有助于自动师生模型蒸馏，以将成本和延迟降低多达 10 倍（请参阅基准）。  非常感谢任何想法或反馈。   由   提交 /u/Noddybear   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1861p30/p_alignmentascode_making_llm_applications_behave/</guid>
      <pubDate>Tue, 28 Nov 2023 17:37:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 具有 2d 旋转嵌入的交叉轴变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18607oa/r_crossaxis_transformer_with_2d_rotary_embeddings/</link>
      <description><![CDATA[ 由   提交/u/lilyerickson  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18607oa/r_crossaxis_transformer_with_2d_rotary_embeddings/</guid>
      <pubDate>Tue, 28 Nov 2023 16:34:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有预训练的人脸识别模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185z0li/d_is_there_any_pretrained_model_for_face/</link>
      <description><![CDATA[我想用Java语言做一个人脸识别功能：输入两张人脸图像，输出是否是同一个人。有没有可以直接使用的预训练模型？我尝试使用opencv的直方图归一化方法进行识别，但是准确率非常差，无法接受。   由   提交 /u/Rare-Durian-2121   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185z0li/d_is_there_any_pretrained_model_for_face/</guid>
      <pubDate>Tue, 28 Nov 2023 15:44:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师加薪？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185y5wn/d_machine_learning_engineer_salary_increase/</link>
      <description><![CDATA[大家好，我去年大学毕业，一直在佛罗里达州的一家公司担任机器学习工程师。我一年赚7.6万。该公司提供硕士学位学费报销。通常情况下，获得硕士学位后，您的加薪是多少？ 后续问题：从在线大学获得硕士学位（我仍然会全职工作）的声望是否会低于从在线大学获得硕士学位？亲自？ 请问，如果您愿意的话，是否有人介意直接分享他们大学毕业后的个人薪资数据以及整个职业生涯的进展情况？   由   提交/u/Fluid-Pipe-2831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185y5wn/d_machine_learning_engineer_salary_increase/</guid>
      <pubDate>Tue, 28 Nov 2023 15:06:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 鲁棒强化学习并不安全</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185xflb/r_robust_reinforcement_learning_is_not_safe/</link>
      <description><![CDATA[https://blogs.ucl.ac.uk/steapp/2023/11/15/adversarial-attacks-robustness-and-generalization-in-deep-reinforcement-学习/    由   提交 /u/ml_dnn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185xflb/r_robust_reinforcement_learning_is_not_safe/</guid>
      <pubDate>Tue, 28 Nov 2023 14:33:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 评估、监控和保护您的基于 LLM 的应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185wr7m/p_evaluate_monitor_and_safeguard_your_llmbased/</link>
      <description><![CDATA[在过去的几个月里，我和我的团队投入了大量精力来构建一个解决方案，帮助用户评估和监控他们的性能LLM 和 AI 应用程序。 如果您是 ChatGPT（或任何其他 LLM:)）用户并将其集成到您的应用程序中，并且万一您曾经碰巧输出您收到的并不完全是您所希望的...您应该会发现这很有用😃 今天，我们公开发布它并在 ProductHunt 上发布它。 如果您尝试并支持发布，我将非常感激。 🙏 https://www.producthunt.com/posts/deepchecks- llm-evaluation?r=h   由   提交 /u/AsDivyansh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185wr7m/p_evaluate_monitor_and_safeguard_your_llmbased/</guid>
      <pubDate>Tue, 28 Nov 2023 14:02:25 GMT</pubDate>
    </item>
    <item>
      <title>提高pySpark的开发效率？ [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185w6y8/improve_developing_efficiency_in_pyspark/</link>
      <description><![CDATA[大家好，我是这个领域的新手，我正在一个巨大的数据集中研究回归模型。我们使用 pySpark，因为完整大小约为 150.000M 行。  考虑到这个规模，这个过程的每一个小步骤都非常缓慢。每次计数操作、显示等。 在我开发模型时，我当然尝试将数据集采样到原始数据集的一小部分（例如 df = df.sample(0.00001)），但是它在时间上并没有真正产生太大的影响。我尝试对其进行采样，以便减少后的数据集仅为 1000 行，并且显示操作仍需要 8 分钟才能完成。  我已尝试尽可能多地过滤数据，但我得到的最小数据约为 9 万行，这仍然是相当巨大的。  我还尝试将“较小”的过滤数据集保存在磁盘中（需要 3.64 天的运行时间来保存），并在第二天再次读取该数据集，但结果相同：仍然非常慢。  这确实减慢了我的速度，因为（可能是由于我自己缺乏经验）我确实需要进行大量显示来查看数据的外观，或检查行数等。所以我真的前进了，真的很慢。  作为机器学习的霸主，您对于处理如此庞大的数据集有什么技巧、技巧或想法吗？我无法更改任何有关系统配置的内容（顺便说一句，它在 Databricks 中），因此我只能通过代码实现想法。提前致谢！大卫   由   提交 /u/Davidat0r   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185w6y8/improve_developing_efficiency_in_pyspark/</guid>
      <pubDate>Tue, 28 Nov 2023 13:36:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何弥合模态之间的差距：多模态大语言模型的综合综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185vu8v/r_how_to_bridge_the_gap_between_modalities_a/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2311.07594  摘要：  这篇综述论文探讨了多模态大型语言模型 (MLLM)，它集成了 GPT-4 等大型语言模型 (LLM) 来处理文本等多模态数据和愿景。 MLLM 展示了生成图像叙述和回答基于图像的问题等功能，缩小了与现实世界人机交互的差距，并暗示了通用人工智能的潜在途径。然而，MLLM 在处理多模态语义鸿沟方面仍然面临挑战，这可能导致错误生成，给社会带来潜在风险。选择合适的模态对齐方法至关重要，因为不正确的方法可能需要更多参数，而性能改进有限。本文旨在探索法学硕士的模态对齐方法及其现有能力。实施模式调整使法学硕士能够解决环境问题并提高可及性。该研究将 MLLM 中现有的模态对齐方法分为四组：（1）将数据转换为 LLM 可以理解的内容的多模态转换器； (2) 多模态感知器，以改善法学硕士感知不同类型数据的方式； (3) 工具协助将数据转换为一种通用格式，通常是文本； (4) 数据驱动方法，教导法学硕士理解数据集中特定类型的数据。该领域还处于探索和实验阶段，我们将整理和更新现有的各种多模态信息对齐的研究方法。  https://preview.redd.it/hoa7lf52a33c1.png?width=1149&amp;format=png&amp;auto=web p&amp; s=0a6230b350a0189fbfbdeaec719380c73c6403cd   由   提交 /u/APaperADay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185vu8v/r_how_to_bridge_the_gap_between_modalities_a/</guid>
      <pubDate>Tue, 28 Nov 2023 13:18:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有一个好的阿拉伯语开放域对话模式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185vrn1/d_is_there_a_good_arabic_model_for_opendomain/</link>
      <description><![CDATA[我的项目确实需要它。   由   提交/u/theonewhoask11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185vrn1/d_is_there_a_good_arabic_model_for_opendomain/</guid>
      <pubDate>Tue, 28 Nov 2023 13:15:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2023机构排名</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185pdax/d_neurips_2023_institutions_ranking/</link>
      <description><![CDATA[       由   提交/u/Roland31415   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185pdax/d_neurips_2023_institutions_ranking/</guid>
      <pubDate>Tue, 28 Nov 2023 06:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] SuGaR：用于高效 3D 网格重建和高质量网格渲染的表面对齐高斯喷射</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</link>
      <description><![CDATA[计算机视觉研究人员开发了一种方法，只需几分钟即可在单个 GPU 上根据图像创建详细的 3D 模型。他们的方法称为 SuGaR，通过优化数百万个微小粒子来匹配场景图像。关键的创新是让粒子与表面对齐，以便可以轻松地将它们变成网格。 传统的 3D 建模速度慢且资源繁重。激光扫描不方便。摄影测量点云缺乏细节。像 NeRF 这样的神经辐射场可以产生令人惊叹的渲染效果，但即使使用强大的硬件，将它们优化为网格也需要数小时或数天的时间。 VR/AR、游戏、教育等领域对更轻松的 3D 内容创建的需求不断增长。但大多数技术都有很大的速度、质量或成本限制，阻碍了它们主流使用。 这种新的 SuGaR 技术结合了神经场景表示和计算几何方面的最新进展，推动了最先进的技术的发展它首先利用一种称为高斯喷射的方法，该方法基本上使用大量微小粒子来复制场景。放置和配置粒子只需几分钟。问题是它们不会自然地形成连贯的网格。 SuGaR 提供了一种新的初始化和训练方法，可以将粒子与场景表面对齐，同时保持细节完整。这种条件允许将粒子云直接视为点云。 然后，他们应用一种称为泊松表面重建的计算技术，以并行方式直接在结构化粒子之间构建网格。一次处理数百万个粒子可以在低延迟的情况下实现高保真度。 通过将繁重的工作转移到前端点云结构化阶段，SuGaR 使最终网格生成与其他最先进的技术相比极其高效-艺术神经/混合方法。 实验表明，SuGaR 构建详细网格的速度比之前发布的技术快几个数量级，同时实现具有竞争力的视觉质量。该论文分享了一些在 10 分钟内重建复杂场景的有希望的示例。 处理更多样化的场景类型仍然存在问题。但就使用可访问的硬件使高质量 3D 重建更接近交互速度而言，这看起来是引人注目的进步。 TLDR：对齐高斯溅射中的粒子可让您将它们转变为详细的网格。使高质量 3D 更好、更快、更便宜。 完整摘要位于此处。论文网站此处。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</guid>
      <pubDate>Tue, 28 Nov 2023 02:37:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] AISTATS 2024 论文评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185a6g4/d_aistats_2024_paper_reviews/</link>
      <description><![CDATA[AISTATS 2024 论文评论预计今天发布。我想为我们创建一个讨论线程来讨论任何问题/抱怨/庆祝或其他任何事情。 每年的评论都有很多噪音。考虑到 AISTATS 这些年的规模不断扩大，一些作者引以为豪的好作品可能会因为系统噪音而获得低分。我们应该记住，无论分数是多少，作品仍然有价值。   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185a6g4/d_aistats_2024_paper_reviews/</guid>
      <pubDate>Mon, 27 Nov 2023 18:41:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你会痴迷地观看模特训练吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18576ol/d_do_you_obsessively_watch_your_models_train/</link>
      <description><![CDATA[我发现自己看张量板的时间多于工作——只是想知道其他陷入这种模式的人是否对生产力有建议   由   提交 /u/TehDing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18576ol/d_do_you_obsessively_watch_your_models_train/</guid>
      <pubDate>Mon, 27 Nov 2023 16:39:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>