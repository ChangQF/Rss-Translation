<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 13 Jan 2025 18:24:05 GMT</lastBuildDate>
    <item>
      <title>[P] 点积的几何直觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i0ju9b/p_geometric_intuition_for_dot_product/</link>
      <description><![CDATA[大家好， 首先，我要感谢您阅读我之前关于几何直觉和蠕虫的帖子！我没想到会收到这么多好的反馈，评论中也有不同的解释。我学到了很多东西！ 受此启发，我又写了一篇关于几何直觉的文章，这次是关于“点积”。这是链接https://maitbayev.github.io/posts/dot-product/ 让我知道你的想法    提交人    /u/madiyar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i0ju9b/p_geometric_intuition_for_dot_product/</guid>
      <pubDate>Mon, 13 Jan 2025 17:50:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 余弦相似度并非我们所认为的灵丹妙药</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i0hfsd/r_cosine_similarity_isnt_the_silver_bullet_we/</link>
      <description><![CDATA[Netflix 和康奈尔大学的研究人员揭露了余弦相似度的重大缺陷。他们的研究表明，线性矩阵分解模型中的正则化引入了任意缩放，导致不可靠或毫无意义的余弦相似度结果。这些问题源于嵌入重新缩放的灵活性，影响推荐系统等下游任务。该研究强调了对替代方案的需求，例如欧几里得距离、点积或规范化技术，并建议针对特定任务进行评估以确保稳健性。 阅读“嵌入的余弦相似度真的与相似度有关吗？”的完整论文评论。这里：https://www.shaped.ai/blog/cosine-similarity-not-the-silver-bullet-we-thought-it-was    由   提交  /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i0hfsd/r_cosine_similarity_isnt_the_silver_bullet_we/</guid>
      <pubDate>Mon, 13 Jan 2025 16:11:00 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 幻觉检测基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i0g71d/project_hallucination_detection_benchmarks/</link>
      <description><![CDATA[大家好，我最近注意到大多数 LLM 可观察性提供商（Arize AI、Galileo AI、LangSmith）都使用简单的 LLM-as-a-Judge 框架来检测已部署的 RAG 应用程序的幻觉。目前有大量的幻觉检测研究，例如这个或这个调查，所以我想知道为什么这些提供商都没有提供更先进的研究支持方法？给定用户输入查询、检索到的上下文和 LLM 输出，可以将这些数据传递给另一个 LLM 以评估输出是否基于上下文。因此，我将这个 LLM-as-a-Judge 框架与 HaluBench 数据集上的几种研究方法进行了基准测试 - 结果发现它们可能是对的！具有思路链提示的强基模型似乎比各种研究方法效果更好。代码在这里。部分结果：   框架 准确率 F1 分数 精确率 召回率    基础 (GPT-4o) 0.754 0.760 0.742 0.778   基础 (GPT-4o-mini) 0.717 0.734 0.692 0.781   基础（GPT-4o，采样） 0.765 0.766 0.762 0.770   CoT（GPT-4o） 0.833 0.831 0.840 0.822   CoT (GPT-4o，采样) 0.823 0.820 0.833 0.808   Fewshot (GPT-4o) 0.737 0.773 0.680 0.896   Lynx 0.766 0.780 0.728 0.840   RAGAS 忠诚度 (GPT-4o) 0.660 0.684 0.639 0.736   RAGAS 忠诚度 (HHEM) 0.588 0.644 0.567 0.744   G-Eval Hallucination (GPT-4o) 0.686 0.623 0.783 0.517      提交人    /u/MagnoliaPotato   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i0g71d/project_hallucination_detection_benchmarks/</guid>
      <pubDate>Mon, 13 Jan 2025 15:16:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Sklearn 在 Python 中实现各向异性周期核</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i0et7v/d_anisotropic_periodic_kernel_in_python_with/</link>
      <description><![CDATA[您好， 我正在使用 Python 中的 sklearn 通过 GaussianProcessRegressor 类对一些海洋变量执行高斯过程回归 (GPR)。参数的域是 3D 时空域（纬度、经度和时间），因此我使用各向异性核进行回归，因为这三个维度完全不同。例如： # 定义内核 kernel = C(1.0, (1e-3, 1e3)) * Matern( nu=1.5, length_scale=[1.0, 1.0, 1.0], length_scale_bounds=[(1e-3, 1e3), (1e-3, 1e3), (1e-3, 1e3)] ) # 初始化 GPR gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, alpha=alpha) 在特定时间位置（固定经纬度，查看时间序列）观察预测值与实际值的结果，我认为在时间上添加周期性内核可能会改善结果。这个假设是有道理的，因为参数可以表现出时间周期性（例如风速）。 我尝试使用 ExpSineSquared 核实现这一点，但它不允许各向异性（我正在考虑将其设置为纬度和经度周期性的非常高的界限，以便它可以被有效地忽略）。但是，文档指出该函数不支持不同维度的不同长度尺度和周期性。 下面是我尝试的一个例子： # 定义 Matern 内核 matern_3d = Matern( length_scale=[1.0, 1.0, 1.0], length_scale_bounds=((1e-3, 1e3), (1e-3, 1e3), (1e-3, 1e3)), nu=1.5 ) # 定义 ExpSineSquared 内核 expsine_3d = ExpSineSquared( length_scale=[1.0, 1.0, 1.0], periodity=[1e6, 1e6, 24.0], length_scale_bounds=((1e-3, 1e3), (1e-3, 1e3), (1e-3, 1e3)), periodity_bounds=((1e5, 1e8), (1e5, 1e8), (12.0, 48.0)) ) # 合并内核 kernel = (C(1.0, (1e-3, 1e3)) * matern_3d) + (C(1.0, (1e-3, 1e3)) * expsine_3d) 但是，这会导致错误，因为 ExpSineSquared 不支持跨维度的不同长度尺度和周期性。有人遇到过这个问题吗？您是否知道其他可以允许这种各向异性周期内核的函数或库？提前致谢！    提交人    /u/Imboto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i0et7v/d_anisotropic_periodic_kernel_in_python_with/</guid>
      <pubDate>Mon, 13 Jan 2025 14:11:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用客户声明的信息作为代理 ML 标签是否可行？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i0d26d/p_is_it_viable_to_use_customerdeclared/</link>
      <description><![CDATA[上下文： 这是一个高级假设的 ML 训练数据问题：假设一家公司有成人客户和儿童客户。90% 的客户是成人，10% 是儿童。* 问题是，客户是成人还是儿童由客户声明，公司无法知道真相。有些孩子会假装成人，因为这对他们有好处，但没有成年人会假装是孩子。因此，该公司希望使用 ML 来查找假装成人的孩子，并使用各种其他客户详细信息作为特征。 问题： 问题是，是否值得使用他们如何声明自己的代理标签来训练模型，即使训练集将包括假装成人的孩子？ （值得注意的是，我们知道在那些被宣称为成年人的人中，只有大约 1% 的人实际上是儿童，即大约 9% 的儿童假装是成年人） 显然，一个更好的方法是拥有一个已确认的成人和儿童的标记训练集，但是没有办法获得标记的数据集，我们所拥有的只是客户是否宣称自己是成年人或儿童。 那么我们怎么想？这是不可能的吗？或者 99% 的真实成年人可能会有效地淹没 1% 的假成年人，从而产生一个可行的模型？假设特征和模型类型在其他方面都是合适的。 不用说，我们永远不会得到一个很棒的模型，但我们只需要一个能给我们带来远高于 9% 基线的模型，因为另一种方法是对小样本客户进行盲检。感觉不对，但根据我们掌握的数据，我想不出其他选择。 如有任何想法，将不胜感激，谢谢 *（请忽略年龄是一个连续变量的事实，我们使用的实际特征是一个二元变量）    提交人    /u/DIRTY-Rodriguez   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i0d26d/p_is_it_viable_to_use_customerdeclared/</guid>
      <pubDate>Mon, 13 Jan 2025 12:41:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] 快速语义文本重复数据删除</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i0cd4n/p_fast_semantic_text_deduplication/</link>
      <description><![CDATA[嗨！我和一位朋友一直在研究一个名为 SemHash 的项目，我想与大家分享一下。我们发现文本去重比看起来要复杂得多，因此我们构建了这个项目来简化流程。 重复样本可能会扭曲模型训练，在 RAG 工作流中返回冗余样本，降低泛化能力，并导致训练测试泄漏，从而导致结果不可靠。minhash 等技术可以处理精确或接近精确的重复项，但语义去重还可以捕获语义冗余样本，我们认为这是去重的一个重要方面。此外，要弄清楚为什么使用 minhash 删除某些内容并不容易，我们也认为这一点很重要。因此，我们还添加了可解释性功能，以便您可以检查删除某些内容的原因。我们已经在基准测试中的一些知名数据集上发现了一些有趣的结果，这些数据集包含在我们的仓库中。 可以使用 pip install semhash 安装该软件包，基本用法如下（此示例假设您已经安装了 datasets 库）： from datasets import load_dataset from semhash import SemHash # 加载数据集以进行重复数据删除 train = load_dataset(&quot;ag_news&quot;, split=&quot;train&quot;)[&quot;text&quot;] test = load_dataset(&quot;ag_news&quot;, split=&quot;test&quot;)[&quot;text&quot;] # 初始化 SemHash 实例 semhash = SemHash.from_records(records=train) # 对训练集进行重复数据删除 deduplicated_train = semhash.self_deduplicate().deduplicated # 或者针对训练集对测试集进行重复数据删除 deduplicated_test = semhash.deduplicate(records=test).deduplicated  我非常想听听您对此的看法！重复数据删除是您当前 ML 工作流程的一部分吗？如果是，您使用什么技术？    提交人    /u/Pringled101   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i0cd4n/p_fast_semantic_text_deduplication/</guid>
      <pubDate>Mon, 13 Jan 2025 11:59:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] Search-o1：基于代理搜索的增强大型推理模型 - 中国人民大学</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzyjw1/r_searcho1_agentic_searchenhanced_large_reasoning/</link>
      <description><![CDATA[  由    /u/Singularian2501  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzyjw1/r_searcho1_agentic_searchenhanced_large_reasoning/</guid>
      <pubDate>Sun, 12 Jan 2025 22:14:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 优化训练数据的宽松界限，实现更好的泛化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzychc/r_optimizing_looser_bounds_on_train_data_achieves/</link>
      <description><![CDATA[我曾遇到过使用较宽松的边界进行优化的情况，可以在测试数据上获得更好的性能。例如，在这篇论文中： https://arxiv.org/pdf/2005.07186 作者指出：“似乎至少对于错误指定的模型（例如过度参数化的神经网络），对对数似然进行较宽松的边界训练可以提高预测性能。我们推测这可能只是一个易于优化的情况，允许模型在整个训练过程中探索更多不同的模式。&quot; 更多详细信息可在附录中的公式 14 下方找到。 还有其他问题可以得出类似的观察结果吗？ 谢谢！    提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzychc/r_optimizing_looser_bounds_on_train_data_achieves/</guid>
      <pubDate>Sun, 12 Jan 2025 22:04:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 浮点精度梯度下降训练或推理失败的原因</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzy2ox/d_at_which_floating_point_precision_gradient/</link>
      <description><![CDATA[我们将 NN 视为“可微分”模型，即假设我们使用连续可微分函数。但是，我们使用浮点表示，从技术上讲，它是离散的。在某些精度下，模型开始崩溃。即考虑 fp64 模型。它可能在 fp16 精度下效果不佳，等等。 有人可以指出研究这个问题、研究故障模式、解决它们的方法等的资源（论文）吗？ 附言：这个问题的灵感来自 NVidia 公告，他们提到 Blackwell 支持 fp4 精度。我现在感兴趣的是如何在如此低的精度下做任何有用的事情，以及用什么来实现它。    提交人    /u/ArtisticHamster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzy2ox/d_at_which_floating_point_precision_gradient/</guid>
      <pubDate>Sun, 12 Jan 2025 21:53:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 具有局部窗口注意（SAM 风格）的 ViT 是否比在所有层中都具有全局注意的 vanilla ViT 效率高很多？尤其是在高分辨率下，全局注意的成本应该非常高。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzupbd/d_is_a_vit_with_local_window_attention_samstyle/</link>
      <description><![CDATA[      我正在阅读 Lucas Beyer 的这篇博客文章：https://lucasb.eyer.be/articles/vit_cnn_speed.html 当他将 ViTB/16 和主要采用局部注意力（窗口大小为 14）的 SAM 变体进行比较时，有点惊讶的是，吞吐量改进很小（左），并且 SAM 变体需要更多的峰值内存。 现在这只是推理，所以也许在训练过程中差异更大，但我天真地认为局部注意力仍然要快得多，特别是在高分辨率下。 在 1024x1024 时，我们应该有 1024/16=64x64 个补丁 - 所以全局注意力操作应该非常昂贵？我是否遗漏了什么？ https://preview.redd.it/es​​7oj0ky6mce1.png?width=1425&amp;format=png&amp;auto=webp&amp;s=5241198e5bb7129eae3d79e77f3a1dd136d64c2b    提交人    /u/AuspiciousApple   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzupbd/d_is_a_vit_with_local_window_attention_samstyle/</guid>
      <pubDate>Sun, 12 Jan 2025 19:30:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了 pkld — 用于存储昂贵/缓慢的 Python 函数的缓存，该缓存在代码运行期间保持不变</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzshvp/p_i_made_pkld_a_cache_for_expensiveslow_python/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzshvp/p_i_made_pkld_a_cache_for_expensiveslow_python/</guid>
      <pubDate>Sun, 12 Jan 2025 17:57:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 12 Jan 2025 16:00:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 在计算机视觉领域获胜了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzn0gg/d_have_transformers_won_in_computer_vision/</link>
      <description><![CDATA[嗨， 自 2018 年 BERT 和 GPT-1 问世以来，Transformer 在书面和口头自然语言处理应用中占据了主导地位。 对于计算机视觉，我上次检查时发现它在 2020 年开始获得发展势头，一张图片胜过 16x16 个单词，但当时的观点是“是的，Transformer 可能对 CV 有好处，现在我会继续使用我的 resnet” 2025 年这种情况有变化吗？ Vision Transformers 是否是计算机视觉的首选骨干？ 换句话说，如果您要从头开始一个新项目来进行图像分类（医学诊断等），您将如何在架构和培训目标方面着手？ 我主要是 NLP 人员，所以请原谅我对行业中的 CV 问题缺乏了解。    提交人    /u/Amgadoz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzn0gg/d_have_transformers_won_in_computer_vision/</guid>
      <pubDate>Sun, 12 Jan 2025 13:47:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 构建了一个贪吃蛇游戏，使用扩散模型作为游戏引擎。它几乎实时运行 🤖 它根据用户输入和当前帧预测下一帧。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hz1l2j/p_built_a_snake_game_with_a_diffusion_model_as/</link>
      <description><![CDATA[        由    /u/jurassimo  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hz1l2j/p_built_a_snake_game_with_a_diffusion_model_as/</guid>
      <pubDate>Sat, 11 Jan 2025 17:57:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>