<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sun, 31 Mar 2024 15:11:56 GMT</lastBuildDate>
    <item>
      <title>[D] 机器人入侵了我的时事通讯。以下是我如何用 ML 进行反击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bschug/d_bots_invaded_my_newsletter_heres_how_i_fought/</link>
      <description><![CDATA[我的时事通讯已被机器人淹没！我决定尝试机器学习解决方案。 这是我的第一个机器学习实验，我学到了很多东西。想知道我如何构建机器人检测器并在此过程中获得一些机器学习技能吗？ 查看我的学习成果。   由   提交/u/athreyaaaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bschug/d_bots_invaded_my_newsletter_heres_how_i_fought/</guid>
      <pubDate>Sun, 31 Mar 2024 15:04:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM预训练和评估奖励模型的技巧——讨论2024年3月的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs95b8/p_tips_for_llm_pretraining_and_evaluating_reward/</link>
      <description><![CDATA[ 由   提交/u/seraschka  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs95b8/p_tips_for_llm_pretraining_and_evaluating_reward/</guid>
      <pubDate>Sun, 31 Mar 2024 12:21:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] Auto-Ollama 和 Auto-GGUF：只需一个命令即可简化微调 LLM 的本地推理和 GGUF 量化 🦙🔄💻</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs8w96/p_autoollama_autogguf_simplify_local_inference/</link>
      <description><![CDATA[      周末小项目，我编写了脚本：Auto-Ollama 🦙 和 Auto-GGUF 🔄。 这些脚本简化了本地推理微调模型（Lora、QLora 适配器等）的过程💻。借助 Auto-Ollama 脚本，您只需一行代码即可将 Ollama 用于任何高频微调适配器✨。 如果模型没有 GGUF 格式，则 Auto-GGUF脚本将模型转换为 GGUF，同样只需一个命令。 我正在检查资源，除了 LMstudio 等之外找不到直接的推理方法，所以我想分享这个。我希望它对您的研究有用。 https://github.com/monk1337/ auto-ollama/ https://preview.redd.it/l1v5v03funrc1.png?width=1832&amp;format=png&amp;auto=webp&amp;s=cf65c127ec22d2e669474bab46497ad441fce311   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs8w96/p_autoollama_autogguf_simplify_local_inference/</guid>
      <pubDate>Sun, 31 Mar 2024 12:07:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 限价订单簿数据的探索性数据分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs6nw2/d_exploratory_data_analysis_for_limit_order_book/</link>
      <description><![CDATA[限价订单分析 我拉高了频率。同一货币在 3 个不同市场（例如伦敦证交所、纽约证交所和泛欧交易所）的一日报价数据。我有实际交易和订单簿快照（每边 20 个级别）。我现在想用 Python 来分析它，但有一些疑问：  如何将数据加载到内存中？我应该使用 PySpark、Dask 等吗？我应该将数据上采样为分钟数据吗？ 理想情况下，我想使用我想到的一些功能进行一些线性回归。我应该在 scikit-learn 中调用 LinearRegression 模块并拟合我加载的所有数据吗？如果是这样，在拟合 LR 模型时，我可以将 PySpark/dask/whatever 框架传递到函数中吗？ 我应该如何处理时间范围中间价格预测（LR 中的 y 值）。这些应该是在接下来的 N 次（例如：5ms）中执行的交易，还是应该是在接下来的 N 次交易中执行的交易？我想问题是预测下一次 N 次交易还是下一次 N 次交易哪个更有意义？  关于使用限价订单簿功能以便预测中价有效！对 Python 中的 LOB 分析特别感兴趣，而不是花哨的 ML 技术:) 谢谢！   由   提交 /u/LeHalfW   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs6nw2/d_exploratory_data_analysis_for_limit_order_book/</guid>
      <pubDate>Sun, 31 Mar 2024 09:49:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 曼巴解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs1va2/p_mamba_explained/</link>
      <description><![CDATA[帖子：https://thegradient.pub/mamba-解释/ ​ 这里我们将讨论：  Mamba 的优点（和缺点）（🐍 ）与变形金刚（🤖）， 思考 Mamba 的类比和直觉，以及  Mamba 对于可解释性、人工智能安全和应用意味着什么。  本文最初发布于Kola 的个人博客。&lt; /p&gt;  ​   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs1va2/p_mamba_explained/</guid>
      <pubDate>Sun, 31 Mar 2024 04:32:28 GMT</pubDate>
    </item>
    <item>
      <title>华尔街日报：人工智能行业在 Nvidia 芯片上的支出是其收入的 17 倍 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs1ebl/wsj_the_ai_industry_spent_17x_more_on_nvidia/</link>
      <description><![CDATA[ ... 在本月早些时候的一次演示中，风险投资公司红杉估计人工智能行业在 Nvidia 芯片上花费了 500 亿美元去年用于训练先进的人工智能模型，但仅带来了 30 亿美元的收入。   来源：《华尔街日报》（付费）   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs1ebl/wsj_the_ai_industry_spent_17x_more_on_nvidia/</guid>
      <pubDate>Sun, 31 Mar 2024 04:06:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] DL 编译器中基于多面体的 IR 背后的直觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brz8t6/d_intuition_behind_polyhedralbased_ir_in_dl/</link>
      <description><![CDATA[阅读时https://arxiv.org/abs/2002.03794 ，我看到了一个关于基于多面体的IR的部分；我的理解是：想象一下，你有一个代表张量的 3D 立方体（我们称之为 A）；假设您有一个嵌套循环，它访问 A 的子多维数据集（我们称之为 B），其中每个 i 次访问都需要第 (i -1) 次访问的结果（B 由单元组成，循环正在访问这些单元）。基于多面体的 IR 优化上述循环的方式是将 B 划分为可能的独立块（每个块是一个|多个单元），然后对它们进行排列，以便现在可以并行访问多个块。 是这是考虑基于多面体的 IR 的正确方法吗？ 上述调查似乎非常好，但有点过时了。还有其他被忽视的有关 DL 编译器的最新论文/论文吗？   由   提交 /u/qctm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brz8t6/d_intuition_behind_polyhedralbased_ir_in_dl/</guid>
      <pubDate>Sun, 31 Mar 2024 02:15:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我比较了用于长格式转录的不同开源耳语包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brrcjd/p_i_compared_the_different_open_source_whisper/</link>
      <description><![CDATA[      大家好！  我最近比较了所有支持长格式转录的开源的基于whisper的软件包。 长格式转录基本上是转录超过30秒的音频文件。 长格式转录基本上是转录超过30秒的音频文件。 p&gt; 如果您想通过 YouTube 视频或播客等聊天，这会很有用。 我比较了以下软件包：  OpenAI 的官方 Whisper 软件包&lt; /li&gt; Huggingface Transformer Huggingface BetterTransformer FasterWhisper WhisperX Whisper.cpp  我在以下方面对它们进行了比较：  准确性 - 使用单词错误率 (wer) 和字符错误率 (cer) 效率 - 使用 vram使用情况和延迟  我写了一份详细的关于此的博客文章。如果您只想要结果，这里是： ​ https://preview.redd.it/96e3wmnv5jrc1.jpg?width=817&amp;format=pjpg&amp;auto=webp&amp;s=f6f18147e3bdbfb 9f1834c5f758bcb1014a1fbbf 希望您觉得它有用！   由   提交/u/Amgadoz  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brrcjd/p_i_compared_the_different_open_source_whisper/</guid>
      <pubDate>Sat, 30 Mar 2024 20:23:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您首选的简单 MoE 培训代码项目是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brngpy/d_whats_your_goto_simple_moe_training_code_project/</link>
      <description><![CDATA[嗨，我想测试一些关于训练非常小的 (&lt;1B) MoE 模型的想法，看看它是否能给出令人信服的结果。 是否有一个 github 存储库非常基本，但实现了真正的训练运行所需的内容，并且允许我修改 MoE 训练？类似于 NanoGPT-MoE （我尝试过），但更完整一点，因为我认为它没有任何意义例如，强制专家利用。 是否有一个可用的存储库，还是我自己？   由   提交 /u/hapliniste   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brngpy/d_whats_your_goto_simple_moe_training_code_project/</guid>
      <pubDate>Sat, 30 Mar 2024 17:36:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可视化卷积神经网络真正学习的方式和内容！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brlhno/d_visualizing_how_what_convolutional_neural/</link>
      <description><![CDATA[   大家好，我制作了一个 YT 视频，直观地展示了 CNN 学习的内容、方式和原因。它从基本原理出发，并通过动画和视觉效果解释了大多数主要概念。看看你是否愿意。留下点赞/评论非常有帮助，非常感谢。 旁注……如果有人认为视频有更好的标题，请告诉我。我不擅长设置好的标题。   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brlhno/d_visualizing_how_what_convolutional_neural/</guid>
      <pubDate>Sat, 30 Mar 2024 16:11:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] DIAMBRA Arena 环境用于让 OpenAI 和 MistralAI 法学硕士在旧金山 MistralAI 黑客马拉松的《街头霸王 III》中由两家 YC 初创公司相互较量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brh3zd/p_diambra_arena_environments_used_to_make_openai/</link>
      <description><![CDATA[       由   提交/u/DIAMBRA_AIArena   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brh3zd/p_diambra_arena_environments_used_to_make_openai/</guid>
      <pubDate>Sat, 30 Mar 2024 12:49:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] TextTile：纹理可平铺性的可微分度量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brg8ko/r_textile_a_differentiable_metric_for_texture/</link>
      <description><![CDATA[   /u/crp1994  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brg8ko/r_textile_a_differentiable_metric_for_texture/</guid>
      <pubDate>Sat, 30 Mar 2024 12:01:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 ML 注释牙科 X 射线</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brbaii/p_using_ml_to_annotate_dental_xrays/</link>
      <description><![CDATA[    &lt; /a&gt;  是否有可用的经过训练的模型，可以将牙科 X 射线 - Orthopantomagram (OPG) 作为输入并对其进行注释完全，标记所有牙齿类型，X 射线中发现的任何异常。它应该隔离所有类型的牙齿，我有一个可以从 X 射线中勾勒出牙齿轮廓，我正在寻找一个模型，可以从 OPG 中标记最可能的信息，这就是我当前模型的工作原理，只是勾勒出牙齿的轮廓具有良好的准确性。   由   提交 /u/Responsible-Win3865   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brbaii/p_using_ml_to_annotate_dental_xrays/</guid>
      <pubDate>Sat, 30 Mar 2024 06:36:50 GMT</pubDate>
    </item>
    <item>
      <title>[N] Stability AI 创始人如何让他的价值数十亿美元的初创公司陷入困境</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1br9vxr/n_how_stability_ais_founder_tanked_his/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1br9vxr/n_how_stability_ais_founder_tanked_his/</guid>
      <pubDate>Sat, 30 Mar 2024 05:13:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>