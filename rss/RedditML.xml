<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Mon, 08 Apr 2024 21:12:02 GMT</lastBuildDate>
    <item>
      <title>[P] 应用科学家/机器学习工程师辅导</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bz9awl/p_applied_scientist_machine_learning_engineer/</link>
      <description><![CDATA[您好！ 我们都知道，当前市场对于寻求 MLE 职位的候选人来说可能不是最理想的，但作为一个近年来面试并获得了微软、亚马逊、Snap、Uber 等多家科技公司的录用通知，我愿意为今天找工作的人分享我的第一手经验、知识和技巧。 如果有人感兴趣或对我如何做得更好有任何其他建议，请私信我。我真的希望能够帮助人们，特别是在这个市场上，对于任何科学家/工程师来说都没有足够的好职位。   由   提交/u/No_Barber8913   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bz9awl/p_applied_scientist_machine_learning_engineer/</guid>
      <pubDate>Mon, 08 Apr 2024 21:01:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您的研究技术堆栈是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bz8pym/d_what_is_your_tech_stack_for_research/</link>
      <description><![CDATA[我计划进行文本+音频的大型多模态训练（1B 参数）。截至目前，我正在考虑使用 pytorch、deepspeed、wandb。对于分布式大型模型训练，您有什么建议以及一般使用什么？ 您使用 Hughginface 吗？我觉得它有点太包裹了，以至于接触到裸露的主干会变得混乱，但还没有进行适当的尝试。对于现成的模型和自定义数据集训练，这听起来确实很有用，但研究需要的不仅仅是这些。那么，您在研究方面的经验如何，您需要灵活地改变模型？一般来说，您在研究方面的技术堆栈是什么？   由   提交/u/gokulPRO  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bz8pym/d_what_is_your_tech_stack_for_research/</guid>
      <pubDate>Mon, 08 Apr 2024 20:38:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 模型定价</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bz7t8i/d_model_pricing/</link>
      <description><![CDATA[构建小型人工智能模型来解决问题需要多少钱？您考虑哪些变量？您是否在此基础上添加任何标记？一个例子是识别低质量图像的 CCN 模型。   由   提交 /u/susanmylife   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bz7t8i/d_model_pricing/</guid>
      <pubDate>Mon, 08 Apr 2024 20:04:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] LegalKit 检索，使用标量 (int8) 的二分搜索通过法国法律代码重新评分</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bz673f/p_legalkit_retrieval_a_binary_search_with_scalar/</link>
      <description><![CDATA[      此空间展示了 Louis Brulé Naudet 的 tsdae-lemone-mbert-base 模型，这是一个句子嵌入模型基于 BERT，使用基于 Transformer 的序列去噪自动编码器进行无监督句子嵌入学习，其目标只有一个：法国法律领域适应。 这一过程旨在提高内存效率和速度，二进制索引为小到足以容纳内存，并且 int8 索引作为视图加载以节省内存。此外，二进制索引的搜索速度比 float32 索引快得多（高达 32 倍），而重新评分也非常高效。 链接到 🤗 Space ：https://huggingface.co/spaces/louisbrulenaudet/legalkit-retrieval LegalKit 检索缩略图。  &amp; #32；由   提交/u/louisbrulenaudet  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bz673f/p_legalkit_retrieval_a_binary_search_with_scalar/</guid>
      <pubDate>Mon, 08 Apr 2024 19:02:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM比较和参数调优的OSS工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bz4rnr/p_oss_tool_for_llm_comparison_and_parameter_tuning/</link>
      <description><![CDATA[      我最初将此工具编写为 CLI 应用程序，用于使用网格搜索测试推理参数的组合（因此名称 Ollama 网格搜索)。 https://preview.redd.it/vbgh6vbhpac1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=16687c2e9077348 c5e082ef85c80820c46c83ef9 以下是它的一些功能： ​  自动从本地或远程 Ollama 服务器获取模型； 迭代不同的模型和参数以生成推理； 同时对不同模型进行 A/B 测试提示；  进行同步推理调用以避免向服务器发送垃圾邮件； 可选择输出推理参数和响应元数据（推理时间、令牌和令牌）；&lt; /li&gt; 重新获取单个推理调用； 可以按名称过滤模型选择； 列出可以以 JSON 格式下载的实验格式； 可配置的推理超时； 可以在设置中定义自定义默认参数和系统提示   ​ 大多数主要平台的源代码和（未签名）版本可在以下位置获取： https://github.com/dezoito/ollama-grid-search  它仍在进行中......我计划添加更多功能，但我我正在利用业余时间做这件事。  希望这对使用开源模型的人们有用   由   提交 /u/grudev   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bz4rnr/p_oss_tool_for_llm_comparison_and_parameter_tuning/</guid>
      <pubDate>Mon, 08 Apr 2024 18:04:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] 促进离策略学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bz2cig/p_boosted_offpolicy_learning/</link>
      <description><![CDATA[        由   提交 /u/ggyshay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bz2cig/p_boosted_offpolicy_learning/</guid>
      <pubDate>Mon, 08 Apr 2024 16:29:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于那些独自发表文章的人来说，你们的经历是怎样的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byzggt/d_for_those_of_you_who_have_published_alone_what/</link>
      <description><![CDATA[这些天我有一些空闲时间，一直在努力赶上我所在领域的研究。我想真正重新审视我在硕士期间正在研究的一个主题，但始终无法发表论文。问题是，我不确定作为唯一作者，如果没有任何真正的资源访问权限，这是否可行。 朋友和熟人告诉我这是可能的，但极其困难。很好奇其他成功做到这一点的人是怎么想的。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byzggt/d_for_those_of_you_who_have_published_alone_what/</guid>
      <pubDate>Mon, 08 Apr 2024 14:35:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] PDF 提取和清洁 RAG</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byze0l/d_pdf_extraction_cleaning_rag/</link>
      <description><![CDATA[大家好，我收到了一项作业，其中我必须使用 langchain 和开源 LLM 构建一个 RAG 系统，所以我有 pdf 形式的数据，其中包含研究论文，大约有 13 个 pdf 文件，每个 pdf 平均包含 20 页所以我的任务是提取文本（使用 pypdf 提取）并删除 pdf 中的图形和表格以及所有文本引用。其中一个 pdf 是图像，所以我必须为此进行 ocr 现在我真的很困惑并且卡住了如何清理文本我尝试了正则表达式，但它并没有那么有用，因为数据是非结构化的我如何维护文本的语义稍后将用于抹布我想将文本传递给 llm 进行清理，但我认为这是不可行的，因为令牌限制将是一个问题，并且 llm 可能会产生幻觉 抱歉，如果问题看起来很愚蠢，新手，谢谢提前！   由   提交 /u/Potential_Zone1522   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byze0l/d_pdf_extraction_cleaning_rag/</guid>
      <pubDate>Mon, 08 Apr 2024 14:33:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] DBRX 是专门为企业设计的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byxqy6/d_is_dbrx_specifically_made_for_businesses/</link>
      <description><![CDATA[我了解到 Databricks 推出了名为 DBRX 的新通用 LLM。我很好奇它与其他法学硕士有何不同（除了开源之外）？ 它是专门为企业还是供公众使用而设计的，例如 chatgpt？或者它是否像“企业聊天”？他们可以在哪里微调开源模型以满足他们的需求？   由   提交/u/Ok_Moment4946   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byxqy6/d_is_dbrx_specifically_made_for_businesses/</guid>
      <pubDate>Mon, 08 Apr 2024 13:22:40 GMT</pubDate>
    </item>
    <item>
      <title>“clip-vit-large-patch14”如何将文本序列表示聚合成表示整个序列的奇异向量？没有 [CLS] 代币，但有 [SOT] 和 [EOT] 代币。 [研究]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byxg7u/how_does_clipvitlargepatch14_aggregate_the_text/</link>
      <description><![CDATA[大家好， 我有以下问题： “clip-vit-large-patch14”如何;将文本序列表示聚合成表示整个序列的奇异向量？没有 [CLS] 标记，但有 [SOT] 和 [EOT] 标记。 当我使用 CLIP 文本编码器并提取 pooler_output 时……这个向量到底是如何创建的？ [SOT] 代币是否用作 [CLS] 代币？或者是否进行了池化操作？ [研究] 此致， Tom  &amp; #32；由   提交/u/tommilyjonesOG   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byxg7u/how_does_clipvitlargepatch14_aggregate_the_text/</guid>
      <pubDate>Mon, 08 Apr 2024 13:09:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] 手写文本到文本项目 - 寻求提示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byurwj/p_hand_written_text_to_text_project_asking_for/</link>
      <description><![CDATA[大家好，我有一个朋友，他有自己的生意，他经常告诉我他手动抄写帐单浪费了多少时间从手写纸滑到他电脑上的文档。我不是专业人士，我仍在学习，但我想知道是否可以使用已经训练好的模型应用一些迁移学习，然后使用新数据  有谁知道是否有一些CNN已经用于此类项目？ 使用什么样的激活函数？感谢您的关注，并提前感谢您的回复:)    由   提交/u/December92_yt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byurwj/p_hand_written_text_to_text_project_asking_for/</guid>
      <pubDate>Mon, 08 Apr 2024 10:46:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 确保加拿大的人工智能优势</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bytkh8/d_securing_canadas_ai_advantage/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bytkh8/d_securing_canadas_ai_advantage/</guid>
      <pubDate>Mon, 08 Apr 2024 09:28:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于高性能语言技术的新的海量多语言数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byt3j8/r_a_new_massive_multilingual_dataset_for/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.14009 项目页面：https://hplt -project.org/ 数据集：https:// /hplt-project.org/datasets/v1.2 GitHub： https://github.com/hplt-project 摘要：  我们介绍HPLT（高性能语言技术）语言资源，一个新的大规模多语言数据集，包括从 CommonCrawl 中提取的单语和双语语料库以及从互联网档案馆中提取的以前未使用的网络爬虫。我们描述了大型语料库的数据采集、管理和处理方法，这些方法依赖于开源软件工具和高性能计算。我们的单语集合侧重于中低资源语言，涵盖 75 种语言，并在文档级别删除了总共约 5.6 万亿个单词标记。我们以英语为中心的平行语料库源自其单语对应语料库，涵盖 18 个语言对和超过 9600 万个对齐句子对，以及大约 14 亿个英语标记。 HPLT 语言资源是迄今为止发布的最大的开放文本语料库之一，为语言建模和机器翻译培训提供了丰富的资源。我们公开发布了这项工作中使用的语料库、软件和工具。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byt3j8/r_a_new_massive_multilingual_dataset_for/</guid>
      <pubDate>Mon, 08 Apr 2024 08:56:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们知道Gemini 1.5是如何实现10M上下文窗口的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by8e9s/d_do_we_know_how_gemini_15_achieved_10m_context/</link>
      <description><![CDATA[我们知道 Gemini 1.5 是如何实现 1.5M 上下文窗口的吗？随着注意力窗口的扩大，计算量不会呈二次方增长吗？    由   提交/u/papaswamp91  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by8e9s/d_do_we_know_how_gemini_15_achieved_10m_context/</guid>
      <pubDate>Sun, 07 Apr 2024 16:21:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>