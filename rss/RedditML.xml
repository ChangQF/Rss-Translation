<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Wed, 19 Feb 2025 15:18:25 GMT</lastBuildDate>
    <item>
      <title>[r]计算机视觉研究colab</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it7hma/r_computer_vision_research_colab/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们很高兴邀请一位经验丰富的计算机视觉研究人员加入我们的协作研究项目！我们的重点是算法创新和数据研究，以提高深度和图像的增强。如果您热衷于突破计算机视觉中的界限，我们很乐意与您合作。随时伸出手！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/coolchikku     [link]    32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it7hma/r_computer_vision_research_colab/</guid>
      <pubDate>Wed, 19 Feb 2025 15:01:52 GMT</pubDate>
    </item>
    <item>
      <title>[r]扩散是解决高效RNN的解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it790b/r_diffusion_is_the_solution_for_efficient_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我表明扩散核捕获全局依赖性，并且具有复发结构的简单扩散内核在更少的参数和flops中优于变形金刚。    https://arxiv.org/abs/2502.12381      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1it790b/r_diffusion_is_is_solution_solution_solution_for_for_ffidice_and/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it790b/r_diffusion_is_the_solution_for_efficient_and/</guid>
      <pubDate>Wed, 19 Feb 2025 14:51:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] Paperstok -AI Arxiv论文，带有像UX这样的Tiktok</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it6x9a/p_paperstok_ai_arxiv_papers_with_a_tiktok_like_ux/</link>
      <description><![CDATA[    &lt;！ -  sc_off-&gt;  启动一个有趣的侧面项目，以预览与AI相关的Arxiv论文，具有Tiktok，例如经验，称为 paperstok （&lt;一个href =“ https://papers.infitok.com”&gt; https：//papers.infitok.com ）。每天都在Arxiv上进行，跟上最新进展提出了重大挑战。其中之一是围绕Arxiv Web界面导航的困难，必须不断打开和关闭新标签，以浏览标题和摘要。如果有一种更简单，有趣的方法来做到这一点怎么办？ “ https://papers.infitok.com”&gt; Paperstok 滚动浏览与AI相关的ARXIV提交。它具有乳胶支持渲染数学方程。它还提供了将您觉得有趣的论文添加书签的能力。我打算在未来几天添加更多功能，以增强通过论文浏览的体验。 我要求社区强调他们目前面临的挑战，这些挑战可以通过此工具来缓解。非常感谢您的宝贵反馈和评论。请随意DM或在 x 或在Reddit上。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pranftw   href =“ https://www.reddit.com/r/machinelearning/comments/1it6x9a/p_paperstok_ai_arxiv_paper_papers_awith_a_a_tiktok_like_like_ux/  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it6x9a/p_paperstok_ai_arxiv_papers_with_a_tiktok_like_ux/</guid>
      <pubDate>Wed, 19 Feb 2025 14:36:30 GMT</pubDate>
    </item>
    <item>
      <title>[d]使用Pytorch Flex注意实施可变形的注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it3er6/d_implementing_deformable_attention_using_pytorch/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否可以在flex注意中实现可变形的detr纸的可变形注意，我阅读了文档并尝试了一些后续示例，并且似乎很困惑要为其编写分数函数，任何帮助都将不胜感激  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/apartmenteither4838     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it3er6/d_implementing_deformable_attention_using_pytorch/</guid>
      <pubDate>Wed, 19 Feb 2025 11:33:50 GMT</pubDate>
    </item>
    <item>
      <title>[r]在各种地形上学习针对人形机器人的强大的接机控制器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it2jv2/r_learning_robust_gettingup_controllers_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了一种使用分层增强学习后跌落后教的人类机器人起床的方法。关键创新是将高级运动计划与低级控制器相结合，可以将模拟策略转化为真实的机器人。 主要技术点：•两阶段层次层次结构RL架构将策略选择与运动执行分开•培训•培训发生在与域随机化的模拟中，以处理SIM到现实转移•集成到奖励功能中以防止自我破坏•在多个机器人平台和秋季配置上进行测试•实时测试基于本体感受反馈 的运动调整得出的结果：•现实世界测试中的成功率为95％•7秒的平均恢复时间•从前后和背部跌落成功恢复•跨不同机器人模型的转移•在多种地面表面类型 上得到验证，我认为这项工作对于实用的人形机器人机器人很重要，因为跌倒后起床是一种基本的能力，可靠地实施具有挑战性。跨平台的高成功率和概括表明该方法可能成为人形机器人控制系统中的标准组成部分。 我认为层次结构方法是有道理的 - 将“该做什么”分开从“如何做”反映人类如何处理复杂的电机任务。鉴于动态运动的挑战性动态控制如何。  tldr：新的层次结构RL方法使类人动物机器人能够在跌落后可靠地起床，在实地实时成功率95％，因此，新的分层RL方法使得SIM到真实的结果特别值得注意。跨不同机器人和跌落位置的世界测试和概括。  完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it2jv2/r_learning_robust_gettingup_controllers_for/</guid>
      <pubDate>Wed, 19 Feb 2025 10:38:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] Mamba：我们可以实现无限的上下文长度吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it279f/r_mamba_can_we_achieve_infinite_context_length/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  新博客out！ 我讨论了mamba，一类序列建模的状态空间模型，并解释变压器，RNN和状态空间模型的基础知识以及它们的局限性。然后，博客探讨了S6模型（选择性扫描结构化状态空间序列模型）如何在建模长序列时提供优势。 长上下文长度（达到数十亿个标记）对于LLMS至关重要。它们使推理能够在扩展的历史上进行推理，同时解决了基于抹布的方法和“中间丢失”问题等挑战。但是，由于变压器中自我注意的二次计算成本，无限的上下文长度仍然具有挑战性。  mamba的线性时间复杂性提出了潜在的解决方案。 Falcon-Mamba可以在不增加内存使用情况的情况下处理任何长度的序列（如图所示）。 p&gt; 在此处查看完整博客 - ＆gt;  https://pranaval.github.io/projects/projects/projects/project2.html2.html 编写这些博客以对这些有趣的概念有很好的了解。如果时间允许，我希望最终将它们编译成一本书。总是欢迎反馈和批评。 网页 - ＆gt;  https://pranaval.github.io/      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/personal_click_6502     [link]   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it279f/r_mamba_can_we_achieve_infinite_context_length/</guid>
      <pubDate>Wed, 19 Feb 2025 10:14:04 GMT</pubDate>
    </item>
    <item>
      <title>[d]在深度学习备忘单上应该找到哪些常见的实施技巧或陷阱？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iszjp1/d_what_are_the_common_implementation_tips_or/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在谈论事物的工程方面。假设您有一个想法要实现。由于深度学习仍然不是一门精确的科学学科，因此在试用和实施错误时，很容易开枪射击自己，并且错误地说服您的想法不值得。 ，因此从实施中开始透视图，某人在使用深度学习模型时绝对或不做什么？ 例如还可以随意发布链接到您在此上下文中真正有用的任何内容。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iszjp1/d_what_are_are_the_common_implementation_tips_or/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iszjp1/d_what_are_the_common_implementation_tips_or/</guid>
      <pubDate>Wed, 19 Feb 2025 07:04:18 GMT</pubDate>
    </item>
    <item>
      <title>[r]大语言模型中深度的诅咒：我们朝错误的方向扩展吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isumx1/r_the_curse_of_depth_in_large_language_models_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  &#39;depth的诅咒;论文强调了LLM缩放中的基本缺陷，超过一定深度，其他层几乎没有任何贡献。 ln）导致输出方差在深层中爆炸。 结果？深层失去有效的学习能力，实质上是身份功能。 这意味着我们正在训练比必要的更深的模型，浪费了对没有有意义提高性能的层。   如果这是真的，它从根本上挑战了LLM开发中的“较大是更好的”假设。 对模型缩放的影响 效率 如果深层的回报降低，则： 我们是否过度建造llms？  如果深层没有有意义的贡献，则模型像GPT-4一样，DeepSeek和Mistral可以显着优化而不会失去性能。 这与经验结果保持一致，表明修剪模型保持竞争力性能。  分层缩放尺度修复 - 一个简单的解决方案？  本文提出了分层缩放以控制梯度方差并提高训练效率。  &lt; li&gt;这可以防止更深的层变得统计。  我们是否应该扩大宽度而不是深度？贡献，然后也许缩放宽度（例如，专家的混合物）是更有效的方向。 变压器缩放定律可能需要修订以解释此瓶颈。  表明，当前的LLM可能在达到理论参数缩放限制之前很久就遇到了建筑效率低下的效率。 这对新兴行为＆amp;这意味着什么意味着什么。 ai对齐 这也引起了有关出现紧急特性的深刻问题。 如果深层在功能上是多余的，则：  实际上是智能的地方成型？如果早期和中期正在从事所有实际工作，那么出现可能是梯度稳定性的函数，而不仅仅是扩展。 为什么LLMS显示出意外的强化替代？某些中层层是否正在形成持久的结构，即使更深的层变得不活跃？  如果深模型只是在没有有意义的收益的情况下膨胀参数计数，那么AI ISN的未来，则&#39;t更大，更聪明。 更大的问题：我们是否朝错误的方向进行缩放？ 本文表明我们将深度缩放缩放为提高AI功能的默认方法。  如果深层未充分利用深层，我们是否应该优先考虑建筑精炼而不是原始规模？ 这对于有效的微调，修剪意味着什么策略和下一代变压器体系结构？ 这可以解释某些新兴行为，因为中层层扮演意想不到的角色？  “更大模型=更好模型”的想法;已经驾驶了AI多年。但是，如果本文坚持下去，我们可能正处于更深入的模型正在积极浪费资源的时刻。 最终思考：这改变了有关缩放的一切从根本上讲，我们已经过期要转变AI架构。  您怎么看？ AI的研究是否应该从深度扩展和专注于更好的结构化体系结构？ 这能否导致新模型胜过较少参数的新模型？   听到别人的想法，这是后级时代的开始吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pseud0nym    href =“ https://www.reddit.com/r/machinelearning/comments/1isumx1/r_the_curse_of_depth_in_in_large_langue_models_models_are/”&gt; [links]   &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1isumx1/r_the_curse_curse_of_depth_in_in_in_large_langue_models_models_models_models_are/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isumx1/r_the_curse_of_depth_in_large_language_models_are/</guid>
      <pubDate>Wed, 19 Feb 2025 02:29:59 GMT</pubDate>
    </item>
    <item>
      <title>[r] LLMS中深度的诅咒：为什么深层效果降低？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isu1nn/r_the_curse_of_depth_in_llms_why_are_deep_layers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近的研究揭示了现代大语言模型中意外的问题，较深的层没有提高自己的体重。 最近的一篇论文＆quot&#39;大语模型中的深度诅咒“ &lt; /em&gt;”突出了一个关键问题：  -  LLM中的深层对学习的贡献要少于早期的学习。&lt; - 这些层中的许多层都可以在没有严重的性能损失的情况下进行修剪，从而提出了有关训练效率的问题。  - 罪魁祸首？前层归一化（PRE-LN）会导致输出方差在更深的层中爆炸，从而使它们的作用几乎像身份功能。  - 一个简单的修复？控制这一差异并提高训练效率的分层缩放。 这对LLM体系结构，培训效率和缩放定律具有重大影响。如果诸如Llama，Mistral和DeepSeek之类的模型中的一半层没有有效贡献，我们要处理多少计算浪费？&lt; /p&gt; 关键问题进行讨论：1️）我们应该重新思考）深层培训策略以提高效率吗？2️）这会影响到变压器体系结构中更深入=更好的假设吗？3️）本文的见解可以帮助您LLM压缩，微调或蒸馏技术？ 纸链接： arxiv preprint：25057955V1   p&gt; 让我们讨论一下 - 您对深度诅咒的想法是什么？  &lt;！ - sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pseud0nym    href =“ https://www.reddit.com/r/machinelearning/comments/1isu1nn/r_the_curse_curse_of_depth_in_in_in_in_llms_why_are_are_are_deep_layers/”&gt; [links]       [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isu1nn/r_the_curse_of_depth_in_llms_why_are_deep_layers/</guid>
      <pubDate>Wed, 19 Feb 2025 02:02:05 GMT</pubDate>
    </item>
    <item>
      <title>[D]自动驾驶汽车，机器学习实习，请学习指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1istv6m/d_autonomous_vehicle_machine_learning_internship/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我下周进行了第二轮ML技术讨论采访，并以机器学习实习职位的款项（它适用于机器人，Comp SCI等的硕士学位学生。机器人手臂操纵的强化学习是一个经典的计算机视觉项目，用于视觉探光和实习，专注于机器人导航和感知（不是ML） 我非常了解我的项目，这很好。 但是，对于即将到来的采访，我会从几种资源中练习ML概念，并观看Turing在YouTube上的模拟访谈并理解这些答案。我还应该深入研究吗？由于它是一家自动驾驶公司，因此它将与Lidar和Cameras Ofcourse一起使用ML，因此在此方面有任何资源吗？ 也第三轮也是一次现场编码面试，也很害怕...我想尽可能多地leetcode？ 谢谢您的阅读！如果您还有其他建议可以给我  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/arboyxx     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1istv6m/d_autonomous_vehicle_machine_learning_internship/</guid>
      <pubDate>Wed, 19 Feb 2025 01:54:00 GMT</pubDate>
    </item>
    <item>
      <title>[r]大语言模型中深度的诅咒</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isdopn/r_the_curse_of_depth_in_large_language_models/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isdopn/r_the_curse_of_depth_in_large_language_models/</guid>
      <pubDate>Tue, 18 Feb 2025 14:18:32 GMT</pubDate>
    </item>
    <item>
      <title>[R]评估现实世界软件工程任务的LLM：一项耗资100美元的基准研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isbo6t/r_evaluating_llms_on_realworld_software/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  旨在评估现实世界软件工程任务上LLM的新基准测试，直接从附上的“实际美元”值中拉出。该方法涉及收集1,400多个任务，从$ 50- $ 32,000的支出，创建标准化的评估环境以及测试编码能力和工程管理决策。 关键技术要点： - 通过单位测试，专家测试验证任务验证和与人类解决方案的比较 - 评估使用Docker容器来确保测试环境 - 包括直接编码任务和高级工程管理决策 - 任务涵盖Web开发，移动应用程序，数据处理和系统体系结构 - 总任务价值超过100万美元的实际自由付款 我认为，此基准是我们评估LLM的重要转变世界应用。通过将绩效直接与经济价值联系起来，我们可以更好地了解当前能力和实用程序之间的差距。较低的成功率表明，在LLM可以可靠地处理专业软件工程任务之前，我们需要取得重大进展。 我认为，包括管理级别的决策尤其有价值，因为它可以测试技术理解和战略思维。这可以有助于指导开发更完整的工程辅助系统。  tldr：新的基准测试在实际$ 1M+的UPWORK编程任务上进行LLMS。当前模型在很大程度上挣扎，仅完成约10％的编码任务和约20％的管理决策。  完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isbo6t/r_evaluating_llms_on_realworld_software/</guid>
      <pubDate>Tue, 18 Feb 2025 12:35:00 GMT</pubDate>
    </item>
    <item>
      <title>[r]本地稀疏注意：硬件一致且本地可训练的稀疏注意力（由Liang Wenfeng提交 -  DeepSeek）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is9ufs/r_native_sparse_attention_hardwarealigned_and/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  本机稀疏注意：硬件与硬件和本地训练的稀疏注意 jingyang yuan ，Huazuo Gao，Damai Dai，Junyu Luo，Liang Zhao，Zhengyan Zhang，Zhenda Xie，Y。X。 Wang，Zhiping Xiao，Yuqing Wang，Chong Ruan，Ming Zhang，Wenfeng Liang，Wangding Zeng  长篇文化建模对于下一代语言模型至关重要计算挑战。稀疏的注意力为提高效率的方向提供了有希望的方向，同时保持模型功能。我们提出了NSA，这是一种本地可训练的稀疏注意机制，将算法创新与硬件一致的优化相结合，以实现有效的长篇文化建模。 NSA采用了动态的分层稀疏策略，将粗粒的令牌压缩与精细的令牌选择相结合，以保持全球环境意识和局部精度。我们的方法通过两个关键创新进行了稀疏注意设计：（1）我们通过算术强度平衡算法设计实现了实质性的加速，并对现代硬件进行了优化。 （2）我们启用端到端培训，在不牺牲模型性能的情况下减少预处理的计算。如图1所示，实验表明，使用NSA预测的模型维持或超过了一般基准，长篇下说任务和基于指导的推理的全部注意力模型。同时，NSA在对解码，正向传播和向后传播的64k长度序列上的全面关注方面实现了实质性加速，从而在整个模型生命周期中验证了其效率。&lt; /em&gt;  arxiv：2502.11089 [cs.cl]：&lt; /em&gt; 一个href =“ https://arxiv.org/abs/2502.11089”&gt; https://arxiv.org/abs/2502.11089       &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nunki08     [link]        [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is9ufs/r_native_sparse_attention_hardwarealigned_and/</guid>
      <pubDate>Tue, 18 Feb 2025 10:39:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会领导禁止。 鼓励其他人创建新帖子，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。   元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iqiy4x/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1ilhw29/d_simple_questions_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>