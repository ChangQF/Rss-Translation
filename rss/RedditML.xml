<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 26 Sep 2024 03:22:50 GMT</lastBuildDate>
    <item>
      <title>[D] 表格增强生成(TAG)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fplpnk/d_table_augmented_generationtag/</link>
      <description><![CDATA[https://arxiv.org/pdf/2408.14717 https://github.com/TAG-Research/TAG-Bench?tab=readme-ov-file 有人看过 TAG 论文或 GitHub 吗？我觉得他们没有做什么特别的事情。我不知道他们能带来什么独特的价值。如果我遗漏了什么，请告诉我。 他们的技术分为 3 个步骤： 查询合成 查询执行 答案生成步骤 但他们确实声称，与使用传统的 text2sql 或 RAG 回答结构化数据问题相比，这种技术提供的结果准确率高达 65%。    提交人    /u/G_S_7_wiz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fplpnk/d_table_augmented_generationtag/</guid>
      <pubDate>Thu, 26 Sep 2024 02:15:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] ViT 受益于双曲空间变换</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fplhvi/r_vits_benefit_from_hyperbolic_space_transform/</link>
      <description><![CDATA[https://arxiv.org/abs/2409.16897    由   提交  /u/jacobfa   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fplhvi/r_vits_benefit_from_hyperbolic_space_transform/</guid>
      <pubDate>Thu, 26 Sep 2024 02:03:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 大型语言模型结构化输出和函数调用的基本指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpiqlj/p_the_essential_guide_to_large_language_models/</link>
      <description><![CDATA[过去一年，我一直在使用 LLM 构建生产系统。当我在 2023 年 8 月开始工作时，材料非常稀缺，以至于必须先重新发明许多轮子。时至今日，情况已经发生了变化，但社区仍然迫切需要教育材料，特别是从生产角度来看。 很多人都在谈论 LLM，但很少有人真正将它们应用于他们的用户/业务。 这是我对社区的新贡献，“大型语言模型结构化输出和函数调用基本指南”文章。 这是一篇关于结构化输出和函数调用的实践指南（长篇），以及如何从 0 到 1 应用它们。要求不多，只是一些基本的 Python，其余的都解释了。 我在公司将其应用于“让我们通过 LLM 为 20 万以上用户解决所有客户支持问题”的计划中取得了相当大的成功。我们还没有达到 100% 的目标，但我们正在快速实现目标，特别是结构化的输出使我们成为可能。 传播这个消息，让我们在演示之外分享更多关于应用 LLM 的经验。    提交人    /u/p_bzn   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpiqlj/p_the_essential_guide_to_large_language_models/</guid>
      <pubDate>Wed, 25 Sep 2024 23:42:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有任何论文或资源使用 LLM 进行分类，同时结合有关类别的知识来帮助分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpics7/d_are_there_any_papers_or_resources_are_using_llm/</link>
      <description><![CDATA[我正在开发一个分类器，但在当前使用的系统/模型中遇到了问题。我当前使用的分类器是 BERT + 微调分类器。对于具有足够数据的类别，结果还不错，但对于没有足够样本的类别，结果基本上毫无用处。我一直在研究构建一个新系统，利用类别中的知识来帮助对没有适当标签的样本进行分类。 例如，如果我有文本“从树上长出的小红色球形水果”和“苹果”、“香蕉”和“橙子”的选择，我希望能够结合这些选择中的知识来帮助指导输入文本，而无需将其明确地放在训练数据集中。 我使用 GPT 4o 做了一些实验并得到了以下结果。  向 GPT 输入：我正在给我的车加油。这算是维修、修理，还是与车门有关。解释你的理由 它回应了  `如果您需要在维修、修理或与车门有关的东西之间做出选择，最合适的选择是维修。原因如下：维修：虽然加油通常不是汽车维修所想到的（因为它更常与换油、轮胎换位等维护任务相关），但它确实有助于车辆的定期保养和运行。从广义上讲，您通过为汽车加油来确保汽车能够运行，因此在这种情况下可以将其归类为&quot;维修&quot;。修理：加油不属于这一类别，因为没有任何东西需要修理或恢复。汽车没有故障；它只是燃料不足，这是正常的操作要求，而不是故障。车门：加油不涉及车门，因此可以排除此选项。`  看起来该模型至少能够使用关于维修、修理和车门的先验知识来帮助指导决策。  有没有什么论文或资源可以帮助我回答以下问题？ GPT 如何能够这样推理并应用有关类别的知识？  有没有办法在不必经过文本提示过程的情况下整合这些知识？  我如何扩展它以处理数千个类/子类（维修/前部护理/前轮胎和维修/保险杠/重大损坏）。  最后，我如何在本地机器上创建这样的系统（包含敏感数据，因此无法连接到 API）？    提交人    /u/newjeison   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpics7/d_are_there_any_papers_or_resources_are_using_llm/</guid>
      <pubDate>Wed, 25 Sep 2024 23:23:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] BERT 对掩码 token 的处理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpf5vm/d_bert_handling_of_masked_tokens/</link>
      <description><![CDATA[BERT 使用“Masked LM”进行训练，如下所示：  训练数据生成器随机选择 15% 的标记位置进行预测。如果选择了第 i 个标记，我们将用 (1) 80% 的时间将第 i 个标记替换为 [MASK] 标记 (2) 10% 的时间将第 i 个标记替换为随机标记 (3) 10% 的时间将第 i 个标记替换为不变的标记。然后，T_i 将用于预测具有交叉熵损失的原始标记。  这里，T_i 表示第 i 个标记的上下文化嵌入，它是一个长度为 d_model 的向量。LM 头的形状为 d_model，大小为 V，并将 T_i 映射到计算交叉熵的 logits 向量。  我的问题是关于 T_i 不是 [MASK] 的 20% 的时间。在这种情况下，MLM 训练是否仍要求 BERT 预测原始标记？尽管这只是一个无监督的预训练目标，但它似乎有点奇怪，特别是在 T_i 不变的 10% 的时间里，在这种情况下，模型本质上是被要求根据原始标记预测原始标记。此外，在随机替换的情况下，这似乎真的会破坏模型的世界模型，因为我不相信它被告知它正在对哪个标记进行预测——例如，句子“The quick brown fox runs”变成了“The magikarp brown fox runs”，在这种情况下，模型不知道第二个单词已被替换，这与“The [mask] brown fox runs”形成对比，因为 [mask] 标记表示替换。我理解这是为了避免不包括 [mask] 令牌的下游任务的分布转移，但令人惊讶的是，这样做的好处多于坏处。     提交人    /u/a1_jakesauce_   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpf5vm/d_bert_handling_of_masked_tokens/</guid>
      <pubDate>Wed, 25 Sep 2024 20:59:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama 3.2详细分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpckbb/d_llama_32_detailed_analysis/</link>
      <description><![CDATA[大家好！Meta 发布了一组新的 Llama 3.2 模型，分别用于文本（1B、3B）和视觉（11B、90B）。我对这些模型进行了深入研究，希望能够有所启发：  新的 1B 和 3B 文本专用 LLM 9 万亿个 token 新的 11B 和 90B 视觉多模态模型 128K 上下文长度 1B 和 3B 使用了一些来自 8B 和 70B 的提炼 VLM 60 亿个图片、文本对 CLIP MLP GeLU + 交叉注意  长分析：1. 视觉编码器中使用带有 GeLU 激活的 CLIP 类型 MLP。类似于 GPT2 的 MLP。与 Llama 3 的 MLP 不同，因为 SwiGLU 不用于视觉 MLP。  用于视觉编码器的正常 layernorm - 不是 RMS Layernorm。此外，一些“门控”参数用于乘以隐藏状态。 在注意力和 MLP 之后对隐藏状态进行门控乘法器 - tanh 用于将向量缩放移动到从 -1 到 1 的数字。 对于小型 1B 和 3B LLM 以及多模态 VLM 11B 和 90B，评估看起来相当不错。1B 49.3 MMLU 和 3B 63.4。 VLM MMMU 50.7 和 90B 60.3  感谢您的阅读，如果您有任何疑问，请告诉我！    由    /u/danielhanchen 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpckbb/d_llama_32_detailed_analysis/</guid>
      <pubDate>Wed, 25 Sep 2024 19:09:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2024 评审问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpa7ua/d_neurips_2024_review_question/</link>
      <description><![CDATA[我最初的审稿人指出了一些弱点和顾虑，但这些问题在我的反驳中得到了解决。他们承认了这一点并提高了分数。  我的论文最终被拒绝，因为程序主席引入了由于误读论文而产生的新弱点，如果这些弱点在最初的审稿中有所说明，这个问题将很容易解决。我能做些什么来修复这个程序主席的审稿吗？    提交人    /u/sqweeeeeeeeeeeeeeeps   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpa7ua/d_neurips_2024_review_question/</guid>
      <pubDate>Wed, 25 Sep 2024 17:30:43 GMT</pubDate>
    </item>
    <item>
      <title>[R]基于注意力的选择性激活架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp70ca/r_attentionbased_selective_activation_architecture/</link>
      <description><![CDATA[有没有研究探索过灵活推理/深度负载架构的想法？也就是说，根据样本的任务难度，对模型的不同层深度进行训练。这将通过绕过模型的后面层来完成，以完成较简单的任务。最困难的任务将占用整个网络。对于 LLM 来说，在 Transformer/Mamba 中实现这一点需要一些思考，但我相信这是可行的。特别是如果在 Beam 方法下进行训练，而不是单输出方式（从未理解为什么仍然这样做，因为 Beam 似乎更好）。可以采用基于注意力的机制来决定推理的深度，或者采用某种强化学习主导的方法（训练后，如果 layer = n 给出错误的输出，则转到 n+1 直到满意为止） 我相信这会使模型在不同层次的复杂性/智能上成形（每层都能够输出一些可理解的内容，从而生成更易于解释的模型）。它还可以解决很多不必要的推理时间。 这个想法是一种看待“思维链”和我们真正思考方式的不同方式。它会将“思考”部分直接嵌入模型中，而不会自行生成内部独白。总而言之，仍然认为这两种方法都是积极且兼容的（我认为我们人类同时做这两种事情）。    提交人    /u/hatekhyr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp70ca/r_attentionbased_selective_activation_architecture/</guid>
      <pubDate>Wed, 25 Sep 2024 15:18:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为机器学习研究人员提供进入医学成像应用的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp3rf3/d_resources_for_ml_researcher_to_get_into_medical/</link>
      <description><![CDATA[大家好！ 我是一名具有物理学背景的 ML 研究员，即将开始攻读博士学位。我的研究小组主要研究医学成像 (MI) 应用，因此我需要在该领域内选择一个子主题。 我的主要兴趣是领域自适应和标签高效方法，我知道这些方法与 MI 非常相关。但是，我对 MI 的前景不太确定。  不同的子字段是如何构成的？ 每个应用程序的常见数据类型是什么？（2D、3D、2D + 时间等） 每个子领域中 ML 面临的紧迫挑战 / 问题是什么？（是否存在特别需要领域自适应技术的特定应用程序？）  如果有人能给我提供有关这些主题的细分 / 请为我提供一些资源，例如评论论文，将不胜感激！    由    /u/fliiiiiiip 提交   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp3rf3/d_resources_for_ml_researcher_to_get_into_medical/</guid>
      <pubDate>Wed, 25 Sep 2024 12:55:46 GMT</pubDate>
    </item>
    <item>
      <title>[D]机器学习控制系统中的 Koopman 算子</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp0rg6/d_koopman_operator_in_control_systems_with/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp0rg6/d_koopman_operator_in_control_systems_with/</guid>
      <pubDate>Wed, 25 Sep 2024 10:01:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要多少微分方程知识才能理解流动、扩散 SciML 和相关领域的研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foygx0/d_how_much_knowledge_of_differential_equations_is/</link>
      <description><![CDATA[我印象中，基础微积分、概率、统计和线性代数为理解深度学习的工作奠定了坚实的基础。但是看到最近关于流匹配、流标准化、扩散和科学机器学习领域的论文，我无法理解超出某一点的东西。  我知道他们大量使用微分方程。我在该领域的知识几乎低于新手水平。在哪里可以学到更多关于微分方程的知识？我想获得理解这些领域工作的能力，以及论文作者如何以及为何提出这种实现。    提交人    /u/HopeIsGold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foygx0/d_how_much_knowledge_of_differential_equations_is/</guid>
      <pubDate>Wed, 25 Sep 2024 07:05:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果对抗性学习研究表明神经网络对输入/权重扰动非常脆弱，那么量化为什么会起作用呢？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fosr7z/d_if_adversarial_learning_studies_suggest_neural/</link>
      <description><![CDATA[我一直在想为什么这两种观察结果可以共存而不发生冲突。对抗性学习的研究似乎表明，人们可以很容易地找到输入或权重上的微小扰动，这些扰动可以彻底改变某些输出。如果扰动某些权重已经足够糟糕，那么像量化那样扰动每个权重肯定会带来灾难性的后果？ 我有几个猜测：  也许对抗性扰动方向很多但在所有可能的方向中很少见，而像量化这样的随机扰动不太可能是对抗性的？ 也许我们确实引入了错误，但只在一小部分输出上，这还不够糟糕？ 也许随机权重扰动对非常大的网络的损害较小？  是否有人知道现有的优秀研究可以解释为什么量化不会导致无意的自我破坏？    提交人    /u/aeroumbria   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fosr7z/d_if_adversarial_learning_studies_suggest_neural/</guid>
      <pubDate>Wed, 25 Sep 2024 01:20:22 GMT</pubDate>
    </item>
    <item>
      <title>[D]-NeurIPS 2024 决策</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foky4r/d_neurips_2024_decisions/</link>
      <description><![CDATA[大家好！请注意，NeurIPS 2024 决策通知将于 2024 年 9 月 26 日欧洲中部夏令时间凌晨 3:00 发布。我觉得创建一个我们可以讨论它的帖子会很酷。    提交人    /u/Proof-Marsupial-5367   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foky4r/d_neurips_2024_decisions/</guid>
      <pubDate>Tue, 24 Sep 2024 19:23:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 22 Sep 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>