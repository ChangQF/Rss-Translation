<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 28 Apr 2024 15:13:21 GMT</lastBuildDate>
    <item>
      <title>多模态机械臂策略还是LLM基础模型训练？[D][R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf8gmp/multimodal_robotic_arm_strategy_or_llm_base_model/</link>
      <description><![CDATA[我目前有2个研究机会，关于多模态机械臂策略和LLM基础模型训练，我不知道选择哪一个？有什么建议吗欢迎或分析！   由   提交 /u/CrisYou   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf8gmp/multimodal_robotic_arm_strategy_or_llm_base_model/</guid>
      <pubDate>Sun, 28 Apr 2024 15:03:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态补丁嵌入 - 一种新的 ViT 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf8d26/r_multimodal_patch_embeddings_a_new_vit_model/</link>
      <description><![CDATA[这个研究项目是对这个想法的探索 - 如果您可以将文本嵌入与 ViT 的每个补丁嵌入进行比较会怎样？.我尝试了一些事情并得到了一些有希望的结果。  这里有两个关键思想： 1. 将图像嵌入作为超球面上点的凸和，其中每个点都是一个补丁嵌入。这需要对 ViT 架构进行更改，此处对此进行了解释。 2. 限制每个补丁仅关注其邻居。 通过这种架构，我使用蒸馏来学习一个小型（约 21M 参数）模型，使其具有与预训练的 Vit-B/32 相同的图像嵌入在大约 310 万张图像上建立模型（约 8700 万参数）。这导致补丁嵌入是局部感知的，但必须学会以某种方式组合，以便提供全局图像嵌入。 代码和检查点是可用的，并且包含用于复制的训练、推理和笔记本。结果：https://github.com/TinyVolt/multimodal-patch-embeddings   由   提交/u/nivter  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf8d26/r_multimodal_patch_embeddings_a_new_vit_model/</guid>
      <pubDate>Sun, 28 Apr 2024 14:59:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] 与构建和调整支持向量回归模型相关的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf77fi/p_question_related_to_building_and_tuning_support/</link>
      <description><![CDATA[我正在构建一个支持向量回归模型，以根据以下一些特征来预测公交车的运行时间：GPS 经度、纬度和分段公交车已打开。 我有 2 个问题：  我正在尝试调整超参数，以便通过使用 gridSearchCV 搜索最佳参数来获得最佳结果。参数网格。我是否遵循正确的方法，是否有更好的方法可以实现我的模型以获得最佳超参数？ 我尝试在 Kaggle 和 Google Collab 中运行代码，但它运行了几个小时，最终无法运行执行并超时。这是因为我的数据集太大了吗？我的数据集中有 130464 条记录。下面是我的模型的代码。如果你们能看一下，我真的很感激。  ​ from sklearn.model_selection import train_test_split, GridSearchCV from sklearn.svm import SVR from sklearn.preprocessing import StandardScaler from sklearn.pipeline import Pipeline from sklearn.metrics importmean_squared_error # 分离特征和目标变量 X = df[[&#39;segment_latitude&#39;, &#39;segment_longitude&#39;, &#39;segment&#39;]] y = df[&#39;segment_run_time&#39;] # 将数据拆分为训练集和测试集 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 创建具有缩放和 SVR 的管道 pipeline = Pipeline([ (&#39;scaler&#39;, StandardScaler) ()), (&#39;svr&#39;, SVR(kernel=&#39;rbf&#39;, gamma=&#39;scale&#39;)) ]) # 定义参数网格 param_grid = { &#39;svr__C&#39;: [0.1, 1, 10], # 不同的值C &#39;svr__epsilon&#39;: [0.1, 0.2, 0.5] # epsilon 的不同值 } # 执行网格搜索 grid_search = GridSearchCV(pipeline, param_grid, cv=5, Scoring=&#39;neg_mean_squared_error&#39;) grid_search.fit(X_train, y_train) # 获取最佳参数 best_params = grid_search.best_params_ print(&quot;最佳参数：&quot;, best_params) # 使用最佳估计器对测试集进行预测 best_estimator = grid_search.best_estimator_ y_pred = best_estimator.predict(X_test) # 评估模型 mse = Mean_squared_error( y_test, y_pred) print(&quot;均方误差:&quot;, mse) # 计算 RMSE rmse = Mean_squared_error(y_test, y_pred, squared=False) print(&quot;均方根误差:&quot;, rmse)     由   提交 /u/Fickle-Age7082    reddit.com/r/MachineLearning/comments/1cf77fi/p_question_lated_to_building_and_tuning_support/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf77fi/p_question_related_to_building_and_tuning_support/</guid>
      <pubDate>Sun, 28 Apr 2024 14:06:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 给出用户查询的工具选择基准。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf75qs/d_a_benchmark_for_tool_selection_given_a_user/</link>
      <description><![CDATA[关键词：法学硕士、对话系统、分类、意图解析 在对话系统中，准确映射用户从一组可能的选项中查询适当的操作是至关重要的。然而，我正在努力寻找专门针对此任务定制的 NLP 基准数据集。 任务描述： 给定用户提示“p”，目标是从一组动作“A”中选择一个动作“a”，使得选择正确动作的概率最大化，即“argmax_i(p(a_i | p))”。 上周末，我一直在寻找基准数据集来评估和扩展我开发的系统的训练数据集，但我找不到任何相关内容。这样的数据集不会公开，这似乎很奇怪。 最接近的可用数据集：  ATIS： 航空旅行特定，仅 26 个类别。 来自 Amazon Alexa 和 IoT 的意图分类：仅限于 Amazon 特定上下文。 CLINC150&lt; /strong&gt;：仅包含 7 个类。  有谁知道任何与我的任务描述更一致的基准数据集吗？ &lt;!-- SC_ON - -&gt;  由   提交/u/Visual_Resource_808   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf75qs/d_a_benchmark_for_tool_selection_given_a_user/</guid>
      <pubDate>Sun, 28 Apr 2024 14:04:10 GMT</pubDate>
    </item>
    <item>
      <title>对于机器学习初学者来说，“探索深度学习技术在低资源语言中进行情感分析的应用”是一个可行的论文主题吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf4zyf/is_exploring_the_application_of_deep_learning/</link>
      <description><![CDATA[我应该写一篇关于数据科学/机器学习的学士论文，我选择了这个，我的时间有限，想知道这是否可以在机器学习初学者需要 2 周的时间？ （我知道时间不多）如果有任何主题想法请提出谢谢   由   提交 /u/General_Arm_7352   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf4zyf/is_exploring_the_application_of_deep_learning/</guid>
      <pubDate>Sun, 28 Apr 2024 12:14:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何诊断训练损失中的这些峰值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf4gw9/d_how_would_you_diagnose_these_spikes_in_the/</link>
      <description><![CDATA[   /u/NumberGenerator  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf4gw9/d_how_would_you_diagnose_these_spikes_in_the/</guid>
      <pubDate>Sun, 28 Apr 2024 11:44:29 GMT</pubDate>
    </item>
    <item>
      <title>“变形金刚可以使用毫无意义的填充词（例如‘......’）来代替思路链” - 让我们一点一点思考 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf2u0d/transformers_can_use_meaningless_filler_tokens_eg/</link>
      <description><![CDATA[https://arxiv.org/abs/2404.15758 从摘要开始 我们表明，变压器可以使用无意义的填充标记（例如“......”）来代替一系列思想来解决两个问题在没有中间令牌的情况下进行响应时，他们无法解决困难的算法任务。然而，我们根据经验发现，学习使用填充令牌很困难，需要特定的、密集的监督才能收敛   由   提交 /u/Agitated_Space_672   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf2u0d/transformers_can_use_meaningless_filler_tokens_eg/</guid>
      <pubDate>Sun, 28 Apr 2024 09:59:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将您的 LLM（应用程序/系统）转移到生产环境中最常见和最重大的挑战是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf178i/d_what_are_the_most_common_and_significant/</link>
      <description><![CDATA[目前有很多人使用法学硕士进行构建，但没有那么多人从原型和 POC 过渡到生产。尤其是在企业环境中，但我相信这对于产品公司甚至一些专注于基于 LLM 的应用程序的初创公司来说也是类似的。事实上，一些调查和研究认为这一比例低至5%。  从事这一领域工作的人们，在尝试将产品投入生产时遇到的最常见和最困难的挑战是什么？目前您是如何解决这些挑战的？    由   提交/u/gamerx88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf178i/d_what_are_the_most_common_and_significant/</guid>
      <pubDate>Sun, 28 Apr 2024 08:07:07 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于构建OCR基准数据集时的版权问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf1763/d_about_copyright_problem_when_building_ocr/</link>
      <description><![CDATA[我是新手，所以请轻柔地回答我。 基本上，我想创建越南语前现代的基准数据集用于 OCR 任务（文本识别）的书籍（当上下文、内容、方言、语法、老化的印刷质量、印刷模具非常不同时）。 问题是我从互联网上下载了它们（有些人只是上传并提供一些云驱动器的链接），我只是一一获取了具有基本事实的信息。这些书的出版日期从 1880 年到 1970 年不等，其中许多出版商都消失了（破产或出售或更名或合并或私有化）。我的意思是每本书的版权都非常不同（因为越南在战后改变了政治制度）。 这比我想象的要复杂，因为它是过渡时期（中诺到佛朗哥殖民地国家到南越）到现在），解决了很多技术难题。但突然ChatGPT（我问在哪里发布）告诉我要小心版权问题。我不知道在哪里问，所以我希望我能从这里得到帮助。 我真的很想发表这个，因为没有人尝试它，目前的 OCR 还不够好，因为越南研究界不付费就像中国人或韩国人一样受到关注。我想将其贡献给进一步的研究（作为将 VNese 老龄化书籍数字化的努力）。 但是有了这个版权，我根本没有任何经验。而且，这样的书大约有100本，全部联系起来又是一个痛苦的问题。我想知道我是否可以发表，但有一个条件或协议，即这是“仅研究目的”基准数据集，任何人都不应将其用作转售或类似用途。 如果有人知道如何以最省力的方式处理此版权，请告诉我。非常感谢。   由   提交/u/Soggy_Ad6925   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf1763/d_about_copyright_problem_when_building_ocr/</guid>
      <pubDate>Sun, 28 Apr 2024 08:07:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自然语言到 MongoDB 查询的转换。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ceyzkr/p_natural_language_to_mongodb_query_conversion/</link>
      <description><![CDATA[      我很高兴这次发布我的副项目“nl2query”的下一个迭代一个微调的 Phi2 模型，用于将自然语言输入转换为相应的 Mongodb 查询。以前的 CodeT5+ 模型不够强大，无法处理嵌套字段（如数组和对象），但 Phi2 可以。在 GitHub 上探索代码：https://github.com/Chirayu-Tripathi/nl2query。 https://preview.redd.it/0y8o9w1br5xc1.png ?width=1800&amp;format=png&amp;auto=webp&amp;s=295e045bedf504ec4b0e4b04d590635abf45119b   由   提交/u/WorryWhole7805   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ceyzkr/p_natural_language_to_mongodb_query_conversion/</guid>
      <pubDate>Sun, 28 Apr 2024 05:42:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] PointNet 输入转换块中单位矩阵的作用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cexbr6/d_role_of_the_identity_matrix_in_pointnets_input/</link>
      <description><![CDATA[你好， 我目前正在探索 PointNet 的代码，特别是输入转换块。我知道这个块用于学习应用于输入点云的变换矩阵，但我对单位矩阵在这种情况下以及通常在深度学习中的作用有点困惑 Here&#39;s我所指的代码片段：  def forward(self, x): batchsize = x.size()[0] x = F.relu(self.bn1( self.conv1(x))) x = F.relu(self.bn2(self.conv2(x))) x = F.relu(self.bn3(self.conv3(x))) x = torch.max( x, 2, keepdim=True)[0] x = x.view(-1, 1024) x = F.relu(self.bn4(self.fc1(x))) x = F.relu(self.bn5( self.fc2(x))) x = self.fc3(x) iden = 变量(torch.from_numpy(np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype (np.float32))).view(1, 9).repeat(batchsize, 1) if x.is_cuda: iden = iden.cuda() x = x + iden x = x.view(-1, 3, 3 ) 返回 x    由   提交 /u/Same_Half3758   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cexbr6/d_role_of_the_identity_matrix_in_pointnets_input/</guid>
      <pubDate>Sun, 28 Apr 2024 04:00:21 GMT</pubDate>
    </item>
    <item>
      <title>[P] NLLB-200 蒸馏器 350M 一台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ceuj4t/p_nllb200_distill_350m_for_enko/</link>
      <description><![CDATA[您好r/MachineLearning， 我很高兴分享一个最初打算在我的毕业产品（Capstone）中使用的项目 我制作了 NLLB-200 Distill 350M 模型来将英语翻译成韩语 很好用。小而快。所以它可以用 CPU 运行！ GPU 服务器相当昂贵，所以我为那些买不起服务器的大学生（比如我）制作了它。 更多细节是在我的页面 如果你懂韩语，请给我很多反馈 谢谢！！ https://github.com/newfull5/NLLB-200-Distilled-350M-en-ko   由   提交/u/SaeChan5  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ceuj4t/p_nllb200_distill_350m_for_enko/</guid>
      <pubDate>Sun, 28 Apr 2024 01:26:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 RAG 的真实讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cekoc7/d_real_talk_about_rag/</link>
      <description><![CDATA[说实话。我知道我们都必须与这些经理/董事/CXO 打交道，他们提出了与公司数据和文档交谈的惊人想法。 但是……有人真正做了一些真正有用的事情吗？如果是这样，它的有用性是如何衡量的？ 我有一种感觉，我们被一些非常复杂的废话所愚弄，因为法学硕士总是可以产生在某种程度上听起来合理的东西。但它有用吗？   由   提交/u/fusetron  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cekoc7/d_real_talk_about_rag/</guid>
      <pubDate>Sat, 27 Apr 2024 18:00:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于 Llama-3 的 OpenBioLLM-70B 和 8B：在医疗领域优于 GPT-4、Gemini、Meditron-70B、Med-PaLM-1 和 Med-PaLM-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cecpvk/d_llama3_based_openbiollm70b_8b_outperforms_gpt4/</link>
      <description><![CDATA[      开源再次来袭，我们很高兴地宣布 OpenBioLLM-Llama3-70B 和 OpenBioLLM-Llama3-70B 的发布。 8B.这些模型在生物医学领域超越了 Openai 的 GPT-4、Google 的 Gemini、Meditron-70B、Google 的 Med-PaLM-1 和 Med-PaLM-2 等行业巨头，树立了新的状态。对于同尺寸的模型来说是最先进的。 迄今为止最有能力的公开医学领域法学硕士！ 🩺💊🧬 https://预览。 redd.it/w41pv7mwf0xc1.png?width=5760&amp;format=png&amp;auto=webp&amp;s=f3143919ef8472961f329bb8eb98937d8f8e41e0 结果可在 Open Medical-L 上查看LM排行榜：https://huggingface.co/spaces/openlifescienceai/open_medical_llm_leaderboard 超过约 4 个月，我们精心策划了多样化的定制数据集，与医学专家合作以确保最高质量。该数据集涵盖 3000 个医疗保健主题和 10 多个医学主题。 📚 OpenBioLLM-70B 的卓越性能在 9 个不同的生物医学数据集上显而易见，尽管与 GPT-4 和 GPT-4 相比其参数数量较少，但其平均得分达到了令人印象深刻的 86.06%。医学-PaLM。 📈 https://预览。 redd.it/5ff2k9szf0xc1.png?width=5040&amp;format=png&amp;auto=webp&amp;s=15dc4aa948f2608717f68ddf2cb27a6a2de03496 您今天可以直接从 Huggingface 下载模型。  70B : https://huggingface.co/aaditya/OpenBioLLM-Llama3-70B 8B：https://huggingface.co/aaditya/OpenBioLLM-Llama3-8B  此版本只是一个开始！在接下来的几个月中，我们将推出  扩大医疗领域覆盖范围， 更长的上下文窗口， 更好的基准，以及 多模式功能。  更多详细信息可在此处找到：https://twitter。 com/aadityaura/status/1783662626901528803 在接下来的几个月里，Multimodal 将可用于各种医疗和法律基准。 我希望它对您的研究有用 🔬 大家周末愉快！ 😊   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cecpvk/d_llama3_based_openbiollm70b_8b_outperforms_gpt4/</guid>
      <pubDate>Sat, 27 Apr 2024 11:51:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>