<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 18 Jan 2024 12:25:49 GMT</lastBuildDate>
    <item>
      <title>[项目] 在 5 分钟内创建 RAG 管道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/199oicr/project_create_a_rag_pipeline_in_less_than_5/</link>
      <description><![CDATA[https://www.youtube.com /watch?v=mNFd0Bur238 这里我逐步介绍使用 https://bionic-gpt 的步骤。 com 创建无代码检索增强生成管道。代码在这里 https://github.com/bionic-gpt/bionic-gpt   由   提交 /u/purton_i   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/199oicr/project_create_a_rag_pipeline_in_less_than_5/</guid>
      <pubDate>Thu, 18 Jan 2024 11:57:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] climo.ai：共享和评估临床预测模型的社区</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/199ogew/p_climoai_a_community_for_sharing_and_evaluating/</link>
      <description><![CDATA[大家好，我叫 Nick，我是一名生物统计学家，希望获得有关我创建的新项目的反馈，该项目专门用于托管机器学习和统计模型临床焦点。 当我还是一名研究阿尔茨海默病的博士生时，我会使用 R Shiny 可视化疾病进展模型，然后在我的期刊文章中添加一个链接。审稿人通常对此表示赞赏，这有助于我们的工作脱颖而出。  这就是我构建 climo.ai 的一个重要原因 - 一个可以快速上传 R 或 Python 模型的网站生成模型的良好交互式可视化。示例模型位于 climo.ai/nickcullen31/mixed-effects-model 。这是其他人与您的模型交互并了解更多信息的好地方。 还有一个 R 和 Python 包，供那些想要下载模型、在本地根据自己的数据评估它们的人使用，然后将验证结果分享回社区。将来，我还希望允许模型的联邦学习。 如果有人能够与这个项目分享反馈、见解、支持或其他任何内容，我将衷心感谢。我也有兴趣了解人们在这样的托管模型中可能会寻找什么类型的功能。   由   提交/u/johnQuincyLadams  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/199ogew/p_climoai_a_community_for_sharing_and_evaluating/</guid>
      <pubDate>Thu, 18 Jan 2024 11:53:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么教育部只有8名专家，却没有人尝试为前任争取16名专家？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/199ny3t/d_why_do_moe_have_only_8_experts_and_none_have/</link>
      <description><![CDATA[这样就可以在不增加推理成本的情况下增加参数数量，对吧？还是有一个我不知道的问题？   由   提交 /u/ThisIsBartRick   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/199ny3t/d_why_do_moe_have_only_8_experts_and_none_have/</guid>
      <pubDate>Thu, 18 Jan 2024 11:22:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将 3D 信息注入反向扩散过程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/199npa7/d_injecting_3d_information_into_the_reverse/</link>
      <description><![CDATA[将 3D 模型数据合并到扩散过程中的最佳方式是什么，以便扩散生成的样本由 3D 模型中的前景对象组成？  例如，我有一个图像数据集，其中前景对象为“铅笔”，并且我有一个钢笔的 3D 模型，并且希望通过用钢笔替换铅笔来创建新的数据集。即背景将从数据集中学习，前景对象将通过 3D 模型学习。我首先想到了 3D 模型的简单投影，然后在类似于文本/图像调节的反向过程中将其连接起来。但我担心我们的实际分布没有笔的图片，因此反向扩散过程会忽略 3d 信息，并且近似分布将与实际分布相似。  您所知道的领域内是否已完成任何工作？如果有任何建议，我将不胜感激。   由   提交/u/sushilkhadakaanon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/199npa7/d_injecting_3d_information_into_the_reverse/</guid>
      <pubDate>Thu, 18 Jan 2024 11:06:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 如何增加 GPT-4 迭代的上下文长度？他们是否从头开始重新训练 GPT-4-1106？或者是稀疏注意力、分块等技术的更黑客组合？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/199n479/d_how_did_openai_increase_context_length_of_the/</link>
      <description><![CDATA[正如标题所述，开始思考 GPT-4 衍生模型及其制作方式。我知道事情发展得很快，而且 OpenAI 绝不是“开放”的，但是关于它是如何完成的猜测是什么？ 我不了解 LLM 进展的所有最新细节，但来自根据我对注意力机制的理解，通常你必须从头开始重新训练变压器以增加上下文大小。 但如果是这样的话，他们是否也必须重做所有 RLHF？或者是否有针对 RLHF 步骤的高效迁移学习技术？ 我很想看到一些将 GPT-4 迭代的评估相互比较的论文（如果您知道的话可以链接）。即使假设 RLHF 是完全可移植的，我们是否仍然期望 GPT-4 系列中的模型之间存在可测量的差异？ 我想知道这些模型之间是否存在任何有洞察力的性能怪癖，例如对于编码任务，32k 0613 模型的性能可能比 8k 基本模型更好，但 128k 1106 比 0613 差，因为在给定相同数量的参数、相同的训练数据等的情况下，上下文大小的回报会下降。   由   提交 /u/great_waldini   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/199n479/d_how_did_openai_increase_context_length_of_the/</guid>
      <pubDate>Thu, 18 Jan 2024 10:28:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 神经网络适应增加/减少噪声。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/199lz7g/d_adaptation_of_neural_networks_to/</link>
      <description><![CDATA[假设您在图像分类数据集上训练具有固定结构（神经元数量、隐藏层、卷积等）的分类神经网络，直到收敛。您的测试数据的性能无法再提高。假设每个像素的噪声都是完全随机的，理论上这个神经网络是否也可以经过最佳训练来对数据的更多（或更少）噪声版本进行分类？性能显然会受到噪声的影响，但是如果您期望在未来的分类任务中出现更高/更低的噪声，神经网络是否必须重新训练？    ;由   提交 /u/ActuaV   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/199lz7g/d_adaptation_of_neural_networks_to/</guid>
      <pubDate>Thu, 18 Jan 2024 09:07:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 人脸检测和提取人脸嵌入的最先进模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/199lnnd/r_what_is_the_state_of_art_model_for_face/</link>
      <description><![CDATA[我正在尝试实现一个人脸相似度应用程序我发现了一些开源，如 deepface、人脸识别、opencv 以及其他人脸相似度应用程序检测和提取人脸嵌入，但它们不是很准确 所以问题是这个领域的最新研究水平是什么？人脸嵌入和人脸相似度？    由   提交 /u/MustafaAlahmid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/199lnnd/r_what_is_the_state_of_art_model_for_face/</guid>
      <pubDate>Thu, 18 Jan 2024 08:44:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]本文的分区是否会导致数据泄露？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/199l2m9/d_does_this_papers_partitioning_cause_data_leakage/</link>
      <description><![CDATA[我最近对 ​​这项研究。总而言之，他们使用文本嵌入和梯度提升来根据财报电话会议记录来预测 CEO 性格得分。他们分析了约 200 位首席执行官，将每位首席执行官的电话分为多个部分以增加数据点。然而，每位 CEO 都会出现在训练集和验证集中，并具有不同的通话片段。在我看来，这应该会导致数据泄漏，因为该模型可能会发现个别首席执行官语言使用的特殊性，而不是底层数据生成过程的模式。您对此有何看法？   由   提交/u/Expective_Charity293  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/199l2m9/d_does_this_papers_partitioning_cause_data_leakage/</guid>
      <pubDate>Thu, 18 Jan 2024 08:03:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型自回归图像模型的可扩展预训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1999ipe/r_scalable_pretraining_of_large_autoregressive/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.08541 代码和模型：https ://github.com/apple/ml-aim 模型： https://huggingface.co/apple/AIM 摘要：  本文介绍了AIM，一组经过自回归目标预训练的视觉模型。这些模型受到其文本对应模型（即大型语言模型（LLM））的启发，并表现出类似的缩放特性。具体来说，我们强调两个关键发现：（1）视觉特征的性能与模型容量和数据量相关，（2）目标函数的值与模型在下游任务上的性能相关。我们通过在 20 亿张图像上预训练 70 亿个参数的 AIM 来说明这些发现的实际意义，在具有冻结主干的 ImageNet-1k 上达到 84.0%。有趣的是，即使在这个规模上，我们也没有观察到性能饱和的迹象，这表明 AIM 可能代表着训练大规模视觉模型的新领域。 AIM 的预训练与 LLM 的预训练类似，不需要任何特定于图像的策略来稳定大规模训练。  &lt;!-- SC_ON - -&gt;  由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1999ipe/r_scalable_pretraining_of_large_autoregressive/</guid>
      <pubDate>Wed, 17 Jan 2024 22:17:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一次性微调所有超参数还是将它们分类？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1996gzj/d_finetune_all_hyperparameters_in_onego_or_divide/</link>
      <description><![CDATA[您好， 我正在微调我的超参数。我一直想知道文献中是否有任何关于微调超参数集合的方法的策略。 我不是在谈论微调算法本身，即网格搜索、随机搜索等.我说的是逐一微调较小的集合 ​ 类别示例： 数据预处理：标记化方法，等 训练参数：学习率、批量大小、优化器、动量等 模型架构：层数、神经元、激活函数、batchnorm、dropout 参数等 内部的其他算法：数据增强、扩散参数等 ​ 我想说，我总共有大约 20 个可以触及的超参数。是一起微调所有内容更好，还是逐一微调超参数类别更好？ 我有一种感觉，某些“类别”可能会被忽略。将对性能产生如此大的影响/变化，以至于可能会给其他参数添加太多噪音 ​ 很想知道社区如何处理这部分管道   由   提交/u/Reference-Guilty  /u/Reference-Guilty  reddit.com/r/MachineLearning/comments/1996gzj/d_finetune_all_hyperparameters_in_onego_or_divide/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1996gzj/d_finetune_all_hyperparameters_in_onego_or_divide/</guid>
      <pubDate>Wed, 17 Jan 2024 20:15:15 GMT</pubDate>
    </item>
    <item>
      <title>AlphaGeometry：奥林匹克级几何AI系统[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1993okp/alphageometry_an_olympiadlevel_ai_system_for/</link>
      <description><![CDATA[https://www .nature.com/articles/s41586-023-06747-5 介绍 AlphaGeometry：一个能够以接近人类金牌得主水平解决奥林匹克几何问题的人工智能系统。 📐 它仅基于合成数据进行训练，标志着人工智能在数学推理方面的突破   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1993okp/alphageometry_an_olympiadlevel_ai_system_for/</guid>
      <pubDate>Wed, 17 Jan 2024 18:25:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlphaGeometry：奥林匹克级几何人工智能系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19932kw/r_alphageometry_an_olympiadlevel_ai_system_for/</link>
      <description><![CDATA[博客：https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/ 论文：https://www.nature.com/articles/s41586-023-06747-5 Github：https://github.com/google-deepmind/alphageometry 摘要：  在奥林匹克级别证明数学定理代表着人类水平自动推理的一个显着里程碑，因为它们在世界上最优秀的大学预科数学人才中被认为是困难的。然而，由于将人类证明转换为机器可验证格式的成本高昂，当前的机器学习方法不适用于大多数数学领域。对于几何来说，这个问题更为严重，因为其独特的转换挑战，导致训练数据严重匮乏。我们提出了 AlphaGeometry，这是欧几里得平面几何的定理证明器，它通过综合不同复杂程度的数百万个定理和证明来回避人类演示的需要。 AlphaGeometry 是一个神经符号系统，它使用神经语言模型，在我们的大规模合成数据上从头开始训练，引导符号推演引擎通过具有挑战性的问题的无限分支点。在包含 30 个最新奥林匹克级别问题的测试集上，AlphaGeometry 解决了 25 个问题，超越了之前仅解决了 10 个问题的最佳方法，接近了国际数学奥林匹克 (IMO) 金牌得主的平均表现。值得注意的是，AlphaGeometry 产生了人类可读的证明，在人类专家评估下解决了 IMO 2000 和 2015 中的所有几何问题，并在 2004 年发现了翻译后的 IMO 定理的广义版本。 &lt;!-- SC_ON - -&gt;  由   提交 /u/RobbinDeBank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19932kw/r_alphageometry_an_olympiadlevel_ai_system_for/</guid>
      <pubDate>Wed, 17 Jan 2024 18:01:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] einx - Python 中受爱因斯坦启发的表示法中的张量运算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198yyzy/p_einx_tensor_operations_in_einsteininspired/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198yyzy/p_einx_tensor_operations_in_einsteininspired/</guid>
      <pubDate>Wed, 17 Jan 2024 15:20:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 信心*可能是*您所需要的一切。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198y67i/d_confidence_may_be_all_you_need/</link>
      <description><![CDATA[      ​ 论文：https://arxiv.org/abs/2303.08896 ​ 我很想知道这里是否有人在实践中尝试过这个。 LLM 输出标记的对数概率的简单平均值可能足以判断模型是否产生幻觉。这个想法是，如果模型不自信（输出令牌概率低），则该模型可能会发明随机的东西。作者声称这种简单的方法是检测幻觉的最佳启发式方法。美妙之处在于它只使用生成的令牌概率，因此可以在推理时实现。   由   提交 /u/santiviquez   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198y67i/d_confidence_may_be_all_you_need/</guid>
      <pubDate>Wed, 17 Jan 2024 14:46:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>