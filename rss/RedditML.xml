<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 11 Feb 2024 21:12:03 GMT</lastBuildDate>
    <item>
      <title>[D] 如何在所有适用的历史数据上运行新版本的模型（在验证后），存档旧版本的模型输出，并用新的输出覆盖现有表？ （技术：S3、Redshift、dbt 和各种 AWS 服务）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aoi4cb/d_how_to_run_new_version_of_model_after_it_is/</link>
      <description><![CDATA[您好， 我们有一个实时数据集，其中包含当前位于 Redshift 架构中的许多表，这些表包含人口统计数据、捕获的数据和预测模型的输出基于人口统计+捕获的数据作为输入。 我们一直在发布不同版本的预测模型，这些版本仅在正式发布时生成数据。例如：  model_A_v1已发布：表中模型输出从6月1日开始 -&gt; 7 月 1 日 model_A_v2 发布：表中的模型输出从 7 月 1 日开始 -&gt; 8 月 1 日 model_A_v3 发布：表中的模型输出从 8 月 1 日开始 -&gt;九月 等  我们有一个单独的计划，要求我们保留旧模型输出的存档版本，但需要最新的输出所有历史数据发布后的模型。因此，它看起来不像上面这样：  model_A_v1 已发布：表中的模型输出从 6 月 1 日开始 -&gt; 7 月 1 日 model_A_v2 发布：表格中的模型输出从 6 月 1 日开始 -&gt; 8 月 1 日   model_A_v1 输出表已存档并替换为 model_A_v2 输出表  model_A_v3 已发布：6 月 1 日起表中的模型输出-&gt; 9 月   model_A_v2 输出表已存档并由 model_A_v3 输出表替换  等  任何帮助将不胜感激，谢谢！   由   提交 /u/antassantas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aoi4cb/d_how_to_run_new_version_of_model_after_it_is/</guid>
      <pubDate>Sun, 11 Feb 2024 20:49:02 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]平铺CNN输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aoflta/discussiontiling_cnn_output/</link>
      <description><![CDATA[我正在创建一个需要在实时环境中评估的 VAE。 因为我所有的 Conv 内核大小都是3，我在想也许有一种技术可以平铺输出以仅评估图像的一部分，而不是每次重新创建完整图像。 就像我的 VAE 创建面孔一样，我知道我需要更新眼睛，并且我有眼睛坐标或眼睛蒙版，只需更新该部分即可。我猜与印刷中的图像类似。 是否做过类似的事情或知道任何论文可以为我指明正确的方向？  &amp;# 32；由   提交 /u/vincentzaraek   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aoflta/discussiontiling_cnn_output/</guid>
      <pubDate>Sun, 11 Feb 2024 19:03:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调 Seq2Seq 任务（如释义）的最佳模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aofkfb/d_what_is_the_best_model_to_finetune_for_seq2seq/</link>
      <description><![CDATA[释义采用相同语言（输入和输出均为英语）。在意识到我可能需要一个编码器解码器模型之前，我已经开始使用 gpt-2。我检查了 t5（工作得很好），但我认为使用 llama2 可能会更好，但我找不到任何用于 llama2 对 seq2seq 任务进行微调的资源。现在我有了更多的计算资源，我应该继续使用更大版本的 t5 还是有更好的模型可以针对此类任务进行微调？    由   提交 /u/notapopular_username   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aofkfb/d_what_is_the_best_model_to_finetune_for_seq2seq/</guid>
      <pubDate>Sun, 11 Feb 2024 19:01:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我构建了一个 LLM 代理，可以抓取大型代码库来回答有关它的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aoeyec/p_i_built_a_llm_agent_that_crawls_large_codebases/</link>
      <description><![CDATA[       由   提交/u/jsonathan  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aoeyec/p_i_built_a_llm_agent_that_crawls_large_codebases/</guid>
      <pubDate>Sun, 11 Feb 2024 18:36:15 GMT</pubDate>
    </item>
    <item>
      <title>[R][P] 用于图像建模的超高容量变分自动编码器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aodmhj/rp_ultra_high_capacity_variational_autoencoder/</link>
      <description><![CDATA[     &lt; /td&gt; 我目前正在研究用于建模图像的全卷积变分自动编码器。问题是它非常小 - 我的 MNIST 模型略低于 700KB，CIFAR10 模型略高于 1MB。 在二值化 MNIST 上，我得到约 105 负 ELBO，在 CIFAR 上我得到大约 6.5 BPD。 以下是两个模型的一些重建，它们在单个 T4 GPU 上不到 1 小时就收敛了。 CIFAR10 重建 二值化 MNIST 重建 来自 GMM 之前的样本 结果绝对看起来很有希望。通过合并类似 NVAE 的分层架构，我也许能够从小型模型中获得更多性能。但这还有待观察。我无法获得 CIFAR 的 GMM 样本，因为我用完了 Colab 积分，哈哈。但这是潜在的插值： https://i.redd.it/jz6yu6luzhc1.gif ​   由   提交/u/Chromobacteria  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aodmhj/rp_ultra_high_capacity_variational_autoencoder/</guid>
      <pubDate>Sun, 11 Feb 2024 17:40:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 介绍 Richard，我从头开始的 CNN 副业项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aoccb3/p_introducing_richard_my_cnnfromscratch_side/</link>
      <description><![CDATA[为了达到这一点我们做了很多工作。我的日常工作是一名软件工程师，我想了解更多有关机器学习的知识，因此我给自己设定了一个有点随意的挑战，即用 C++ 从头开始​​实现一个神经网络来对猫和狗进行分类。快进几个月后，我让它在带有 Vulkan 计算着色器的 GPU 上运行。 它目前是一个 CLI 应用程序，您只需在 JSON 文件中指定网络架构并将其指向您的训练集。然后在“评估”中再次运行它模式并将其指向一些以前从未见过的数据，它将尝试对每个样本进行分类。 在文档目录中有一个 pdf 文件，我在其中写下了其工作原理背后的所有数学知识。这很难弄清楚，因为互联网上的大多数指南都掩盖了细节。例如，如何修改反向传播算法以使用卷积块、最大池层等？我会在某个时候自己写一篇详细的文章。 还有很多功能我想添加。这是一项正在进行中的工作。 GitHub：https://github.com/robjinman/richard    由   提交/u/LlaroLlethri   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aoccb3/p_introducing_richard_my_cnnfromscratch_side/</guid>
      <pubDate>Sun, 11 Feb 2024 16:46:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer 世界模型能否提供更好的策略梯度？ （个人评论）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ao5xi2/r_do_transformer_world_models_give_better_policy/</link>
      <description><![CDATA[ 由   提交 /u/mgostIH   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ao5xi2/r_do_transformer_world_models_give_better_policy/</guid>
      <pubDate>Sun, 11 Feb 2024 11:28:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Transformer Encoder 进行开放式命名实体识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ao4ayw/p_open_type_named_entity_recognition_with/</link>
      <description><![CDATA[大家好， 我想分享我们关于开放式命名实体识别（NER）的项目。我们的模型使用变压器编码器（类似 BERT），与使用 LLM 相比，计算开销非常小。我开发了一个在 Google Colab 上的 CPU 上运行的演示。 Colab 演示：https://colab.research.google.com/drive/1mhalKWzmfSTqMnR0wQBZvt9-ktTsATHB?usp=sharing 代码：https://github.com/urchade/GLiNER 论文：https:// arxiv.org/abs/2311.08526   由   提交 /u/Substantial-Push-179   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ao4ayw/p_open_type_named_entity_recognition_with/</guid>
      <pubDate>Sun, 11 Feb 2024 09:37:10 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 尖峰频率适应：桥接神经模型和神经形态应用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ao26qt/research_spike_frequency_adaptation_bridging/</link>
      <description><![CDATA[论文：https:/ /www.nature.com/articles/s44172-024-00165-9 摘要 人脑执行复杂认知任务的无与伦比的效率源于神经元通过短的、间歇性的爆发或尖峰。这启发了尖峰神经网络 (SNN)，现在将神经元模型与尖峰频率适应 (SFA) 结合起来。 SFA 根据最近的神经元活动调整这些尖峰的频率，就像运动员不同的冲刺速度一样。具有 SFA 的 SNN 表现出更高的计算性能和能源效率。这篇综述研究了计算神经科学中的各种自适应神经元模型，强调了它们在人工智能和硬件集成中的相关性。它还讨论了这些模型在推动节能神经形态系统发展方面的挑战和潜力。   由   提交/u/Synapse_Neuro  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ao26qt/research_spike_frequency_adaptation_bridging/</guid>
      <pubDate>Sun, 11 Feb 2024 07:12:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 没有机器学习背景的安全研究人员“破坏”机器学习模型的可行性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1anwa3h/d_feasibility_for_a_security_researcher_with_no/</link>
      <description><![CDATA[我是一名在攻击性安全公司工作的安全研究员，多年来我已经获得了攻击性安全方面的广泛技能，因此，每当需要评估一些利基或非标准的东西时，我就会被推出。 对于更奇怪的请求，根据定义，我通常对我应该破坏的东西知之甚少，但大多数情况下我的工作之一是评估我不知道如何进入的系统，而且通常效果很好，因为过了一段时间你就会明白如何在代码库/网络/等中查找问题。 很快我就会被赋予“打破”的任务某种机器学习模型，我假设是法学硕士，但我不确定。不像托管使用该模型的服务的周围基础设施，或者开放人工智能 API 的一些包装器，而是实际的模型，无论是什么。我想我将能够访问模型代码库和一些训练数据，但我也可能不会。 问题的核心是我在机器学习或数学方面的背景为零，这是我唯一擅长的就是识别系统的弱点，提出概念验证漏洞，并在报告中进行演示。 外行人快速（例如一周或两周）计算出其可行性如何找出像机器学习模型这样的东西的攻击面并使其（例如，我再次不知道我要面对什么）对图像进行错误分类？我知道库抽象了很多繁重的数学，并且了解如何调整输入以使系统执行您想要的操作，但我有一种感觉它不会那么简单。 听起来我可以依靠直觉吗？或者我应该说我不是满足他们需求的合适人选？我可能不会获得比评估开始前已有的更多信息。谢谢， 编辑：为了明确我的数学能力水平，我在大学里两次计算 2 都失败了，而且我无法理解任何与数学相关的事情，除非我需要它来制作数学的某些部分。攻击工作，即便如此，它更多的是“哦，我可以覆盖这个变量，所以这意味着我可以预测 X（小学水平的代数，使数字对我有利）。”   由   提交/u/fugeet  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1anwa3h/d_feasibility_for_a_security_researcher_with_no/</guid>
      <pubDate>Sun, 11 Feb 2024 01:37:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] AI 在 Old School RuneScape 中学习 PvP（强化学习）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1anv7n4/p_ai_learns_pvp_in_old_school_runescape/</link>
      <description><![CDATA[大家好，过去一年我一直在开发一个项目，利用强化学习在 Old School RuneScape 中学习 PvP。我终于达到了对结果感到满意的程度，因此我开源了该项目的（大部分），并发布了一个 YouTube 视频，从高层次上介绍了它的工作原理。 ​  GitHub：https://github.com/Naton1 /osrs-pvp-reinforcement-learning Youtube：https://youtu.be/jArLZ8nC5Nw   ​ 该视频非常高级，可以使其易于访问，但代码很全面，并且有很多很酷的内容，包括：  完整的 PPO 实现 自我对弈策略，包括优先的过去自我对弈 具有动作屏蔽的自回归和参数化多离散动作 &lt; li&gt;评论家网络的完整游戏状态可见性（可以看到完整的玩家和对手信息） 可定制的模型架构 奖励和观察标准化 使用新颖性奖励运行观察统计 AsyncIO 矢量化环境 使用 Ray 分发 rollout 集合  ​ 太多了列在这里，所以如果你好奇的话请查看代码！ ​ 对于那些可以理解的担心的人，请注意，这里没有发布任何软件可以允许人们在真实的游戏中使用这些模型。开源代码纯粹用于模拟训练和评估。   由   提交/u/Naton1-  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1anv7n4/p_ai_learns_pvp_in_old_school_runescape/</guid>
      <pubDate>Sun, 11 Feb 2024 00:45:19 GMT</pubDate>
    </item>
    <item>
      <title>(META) 这个地方太看重信心了 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1antdup/meta_this_place_puts_too_much_weight_on/</link>
      <description><![CDATA[一个例子，最高评论 121 分：  TL;DR 他们做了一项控制饲养实验，其中他们在盒子里孵出新生的小鸡，并测量它们学习简单的视觉识别任务需要多长时间。  但是他们没有测量需要多长时间，所以他们没有办法进行比较鸟脑到变形金刚：https://www.reddit.com/r/MachineLearning/comments/ 19er4pp/comment/kjgbndj/ 另一篇：  旧论文。 TL;DR：...他们没有&#39;不要测试任何在非语言或非自回归目标上从头开始训练的变压器。  看到了吗？无需阅读。他读给你听。再次自信，又错误。去年 12 月推出（焦点），它并不旧。他们确实从头开始训练了一些变形金刚：https://www .reddit.com/r/MachineLearning/comments/1amzb52/comment/kpp3m2s/ 尽管如此，该评论还是很受欢迎，论文被否决了，直到我添加了一些反驳和推荐，但该帖子从未从早期错误的反对票浪潮中恢复过来。  一年前，同一个帐户在 r/learnMachineLearning 中提出了非常基本的问题，但现在现在足够聪明，可以自信地告诉人们哪些论文是有价值的，以及应该如何进行实验？ 无论如何，在这两个例子中，可能还有许多其他例子，你们都可以相当容易地找出真相，但你选择使用更简单的启发式“信心 = 能力”。   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1antdup/meta_this_place_puts_too_much_weight_on/</guid>
      <pubDate>Sat, 10 Feb 2024 23:19:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对 LLM 基准说明整个故事持怀疑态度吗？本文展示了对 MMLU 等测试的微小调整如何像一副纸牌一样重新调整模型排名。 🃏</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1anr0hm/r_skeptical_about_llm_benchmarks_telling_the/</link>
      <description><![CDATA[ 由   提交/u/PoisonousHashbrown   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1anr0hm/r_skeptical_about_llm_benchmarks_telling_the/</guid>
      <pubDate>Sat, 10 Feb 2024 21:33:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些人工智能/机器学习领域正在受到关注？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ankhpi/d_which_aiml_fields_are_growing_under_the_radar/</link>
      <description><![CDATA[LLM 和扩散模型目前正在抢尽风头。我很想知道人工智能/机器学习的哪些其他领域是人们感兴趣的，尤其是工业快速采用的领域。 从我自己的角度来看，我注意到计算机视觉/机器视觉&lt; /strong&gt; 是工业/制造领域许多人的需求，对我来说，这似乎是机器学习最成熟的工业应用。紧随其后的是数据驱动的信号处理，这似乎是航空航天类型公司为其雷达软件所要求的。我知道 Facebook/Amazon 和其他公司使用图神经网络，但不知道使用到什么程度。我知道强化学习领域发生了很多事情，尤其是在机器人领域，但这与我的专业领域相去甚远。此外，许多行业中都有许多人使用深度学习和更经典的机器学习来寻找 SoC 和硅行业中其他此类问题的最佳布局。 我很感兴趣听取在法学硕士/扩散模型之外从事人工智能/机器学习的其他人的意见。你在兴奋什么？您认为增长发生在哪里？   由   提交 /u/DresDunn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ankhpi/d_which_aiml_fields_are_growing_under_the_radar/</guid>
      <pubDate>Sat, 10 Feb 2024 16:45:49 GMT</pubDate>
    </item>
    </channel>
</rss>