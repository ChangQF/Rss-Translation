<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 27 Jan 2025 21:15:42 GMT</lastBuildDate>
    <item>
      <title>[P] 永远不要训练另一个 ML 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibh8wb/p_never_train_antoher_ml_model/</link>
      <description><![CDATA[我相信 LLM 将在很大程度上取代专门的机器学习模型。这正是我创建一个简单的开源库来帮助您的原因：  用 5 行代码构建基于 JSON 的管道，用于分类、标记等。 将强大的 LLM 技能集成到您的工作流程中 标准化输出以提供给下游。  安装和设置 通过 PyPI 安装： pip install flashlearn  然后设置您的 LLM 提供程序凭据（如果使用 OpenAI）： export OPENAI_API_KEY=&quot;YOUR_API_KEY&quot;  构建以 JSON 为中心的管道 1) 数据提取和任务定义 下面是使用 IMDB 电影评论进行情绪分析的示例，演示了如何加载预构建的技能： from flashlearn.utils import imdb_reviews_50k from flashlearn.skills import GeneralSkill from flashlearn.skills.toolkit import ClassifyReviewSentiment def main(): # 加载 100 个 IMDB 评论样本 data = imdb_reviews_50k(sample=100) # 加载预构建的“ClassifyReviewSentiment”技能 skill = GeneralSkill.load_skill(ClassifyReviewSentiment) # 将数据集转换为结构化的“任务” task = skill.create_tasks(data)  2) 并行执行 然后，并行处理这些任务： results = skill.run_tasks_in_parallel(tasks)  3) 基于 JSON 的输出存储 所有输出都以干净的 JSON 形式到达，使其易于解析、存储或传递下游： import json with open(&#39;sentiment_results.jsonl&#39;, &#39;w&#39;) as f: for task_id, output in results.items(): input_json = data[int(task_id)] input_json[&#39;result&#39;] = output f.write(json.dumps(input_json) + &#39;\n&#39;)  4) 链接 &amp;多步骤管道 您可以轻松地将结构化输出链接到另一个技能以进行进一步处理： # 链接示例：# next_skill = ...# next_tasks = next_skill.create_tasks([...based on &#39;output&#39;...])# next_results = next_skill.run_tasks_in_parallel(next_tasks) 扩展 FlashLearn 自定义技能 当您需要特定领域的分类或标签时，请从示例数据中定义自定义技能： from flashlearn.skills.learn_skill import LearnSkill learner = LearnSkill(model_name=&quot;gpt-4o-mini&quot;) skill = learner.learn_skill( data, task=&#39;Define categories &quot;satirical&quot;, &quot;quirky&quot;, &quot;荒谬&quot;。&#39; ) task = skill.create_tasks(data)  图像分类示例 通过支持单标签和多标签分类的 ClassificationSkill 动态构造函数指定图像列模态，同样可以很好地处理视觉数据： from flashlearn.skills.classification import ClassificationSkill images = [...] # Base64 编码的图像 skill = ClassificationSkill( model_name=&quot;gpt-4o-mini&quot;, categories=[&quot;cat&quot;, &quot;dog&quot;], max_labels=1, system_prompt=&quot;Classify images.&quot; ) task = skill.create_tasks( images, column_modalities={&quot;image_base64&quot;: &quot;image_base64&quot;} ) results = skill.run_tasks_in_parallel(tasks)  GitHub 和其他资源 有关更多详细信息、代码示例和高级用例，请查看开源存储库： FlashLearn – 完整代码    提交人    /u/No_Information6299   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibh8wb/p_never_train_antoher_ml_model/</guid>
      <pubDate>Mon, 27 Jan 2025 19:10:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 尝试实现 CarLLAVA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibevf4/d_trying_to_implement_carllava/</link>
      <description><![CDATA[      早上/下午/晚上好。 我正在尝试在代码中复制 CarLLaVA 提出的模型，以便在大学进行实验。 我对神经网络的内部结构感到困惑。 如果我没记错的话，对于推理部分，同时训练以下内容：  LLM（LoRa）的微调。 向 LLM 输入查询 输出 MSE 标头（航路点、路线）。  并且在推理时，查询会从网络中删除（我假设）。 我正在尝试在 pytorch 中实现它，我唯一能想到的就是将“可训练部分”与火炬的内部图连接起来。 有人试过自己复制它或类似的东西吗？ 我对这个实现感到迷茫。 我还遵循了 LMDrive 的另一种实现，但他们单独训练他们的视觉编码器，然后将其添加到推理中。 谢谢！  https://preview.redd.it/dom6ou7iokfe1.png?width=1662&amp;format=png&amp;auto=webp&amp;s=7596c1715d44b59fa42eeff2c58ef48fd41493d6 将原件包裹起来 我的代码    由   提交  /u/AlbertV999   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibevf4/d_trying_to_implement_carllava/</guid>
      <pubDate>Mon, 27 Jan 2025 17:36:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们如何存储/流式传输 LLM 嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibe0bm/d_what_do_people_do_for_storingstreaming_llm/</link>
      <description><![CDATA[对于一个学术项目，我想计算每个标记的嵌入，将它们存储在磁盘或内存中，并将它们流式传输以进行快速实验，同时微调模型（比 LLM 小得多）。 有哪些库（db？）、数据结构和最佳实践？一些注意事项：  希望最大限度地减少嵌入计算（成本）。 嵌入是 ~1k 32 位浮点数。 序列通常约为 20-500 个标记。 在模型训练中流式传输预计算嵌入以进行微调。 完整数据集约为 500k 个短语，磁盘上约 4TB（未压缩）。 我的应用程序不存在量化模型。 一些“有意义”的数据集子集可以放入内存（几 GB）。 最终共享数据集以供研究。 开源友好 寻找更标准化与新颖的数据库解决方案（主要是为了长寿）     提交人    /u/LetsTacoooo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibe0bm/d_what_do_people_do_for_storingstreaming_llm/</guid>
      <pubDate>Mon, 27 Jan 2025 17:02:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] FP/OTS 游戏的随机生成地图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib8e5k/d_randomly_generated_maps_for_fpots_games/</link>
      <description><![CDATA[我对使用随机生成地图的游戏感兴趣。有 Starfield 和 Bethesda 在未来游戏中使用它们。还有其他使用 Voxel 引擎的游戏，例如 Valheim 或 No Man&#39;s Sky。我对 Starfield 类型的随机生成地图感兴趣。目的是使用它们来提高可重玩性，但仍然让游戏感觉逼真。让它感觉手工制作并具有人情味，但要随机化，这样重复运行同一张地图就永远不会被映射，使重复的​​体验与第一次通过地图的体验感觉一样奇妙。 我可以评论哪些游戏作为做得好的例子？有没有关于它的论文？有什么值得一提的吗？就像我想象的那样，这太难了，或者不值得，因为到目前为止很少有游戏这样做。 一个建议：  最简单的方法是手工制作一些大小一致的模块，然后可以随机放置在网格中。如果你觉得自己特别聪明，你可以使用波函数折叠并稍微控制随机性/确保只有可以连接的部分才能连接。  我想问你是否知道任何方向可以让我找到解决方案或尝试解决这个问题的例子，无论是在理论还是实践上。 编辑：FP：第一人称/ OTS：过肩 - 解释视频游戏中相机相对于玩家角色的位置    提交人    /u/blitz4   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib8e5k/d_randomly_generated_maps_for_fpots_games/</guid>
      <pubDate>Mon, 27 Jan 2025 13:01:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何向 ICLR 2025 提交 Camera Ready 版本？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib6dj6/d_how_to_submit_camera_ready_version_to_iclr_2025/</link>
      <description><![CDATA[有人知道如何向 ICLR-25 提交照相排版版本吗？我在 openreview 或会议网站上没有看到选项；录取电子邮件中没有提交链接。 提前致谢。 注意：这是我的论文第一次被 ICLR 接受。    提交人    /u/Hefty_Willingness543   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib6dj6/d_how_to_submit_camera_ready_version_to_iclr_2025/</guid>
      <pubDate>Mon, 27 Jan 2025 11:21:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于几年后重返该行业的人，您有什么建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib6c03/d_what_would_you_suggest_a_person_who_is_coming/</link>
      <description><![CDATA[2013 年，我开始深入研究机器人技术并建立模型，2015 年深入研究 ML，2017-18 年深入研究 DL 和 GAN，但从 2019 年起，生活有其他计划，目前在商业方面，我敢说每一天对我来说都是新的。每当人工智能世界出现新消息时，我当然都会被它吸引。  你会建议我回到技术方面吗？我该如何开始，从哪里开始！我已经几年没有编码了，现在我觉得自己有点笨    提交人    /u/ImaginationAny2254   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib6c03/d_what_would_you_suggest_a_person_who_is_coming/</guid>
      <pubDate>Mon, 27 Jan 2025 11:19:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 帮助调试 LFW 数据集上的 ArcFace 性能（卡在 44.4% TAR）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib4o1v/p_help_debugging_arcface_performance_on_lfw/</link>
      <description><![CDATA[大家好， 我正在尝试评估 InsightFace 预训练 ArcFace 模型在 Kaggle 的 LFW 数据集上的 TAR（真实接受率）（数据集链接）。众所周知，ArcFace 在 LFW 上以 0.36 的阈值在 0.1% FAR 下实现 99.8% 的 TAR。但是，我的实现仅以 44.4% 的 TAR 和 0.4274 的阈值实现，我已经为此苦苦挣扎了好几天。 我怀疑问题出在预处理或 TAR 计算的某个地方，但我无法查明原因。下面是我的代码，供参考。 代码：https://pastebin.com/je2QQWYW 我试图调试：  预处理（调整为 112x112，规范化） 使用 ArcFace ONNX 模型进行嵌入提取 对相似度计算（嵌入之间的余弦相似度） 使用阈值和 LFW 的 pairs.csv 进行 TAR/FAR 计算  如果有人可以检查代码并突出显示任何潜在问题，我将不胜感激。我不确定的具体领域：  我是否正确地预处理了图像？ 我计算成对图像之间相似性的方法是否合理？ 我的 TAR/FAR 计算逻辑是否存在问题？  我非常感谢一些指点或任何解决此问题的建议。提前感谢您的时间！ 请帮忙🙏🙏🙏🙏🙏🙏🙏    提交人    /u/masterRJ2404   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib4o1v/p_help_debugging_arcface_performance_on_lfw/</guid>
      <pubDate>Mon, 27 Jan 2025 09:45:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么在损失函数（例如线性回归损失函数）中不使用 4、6 等更高的偶数幂？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib3dhn/d_why_higher_even_powers_like_4_6_etc_are_not/</link>
      <description><![CDATA[我们知道奇数幂会导致非凸函数，并且函数也不可微。但是为什么我们不使用偶数幂，例如 4 等？我在一次采访中被问到这个问题，我说也许计算成本会很高，并且会对异常值进行更多惩罚。但他们似乎仍然不满意。我还遗漏了什么其他原因？    提交人    /u/maaKaBharosaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib3dhn/d_why_higher_even_powers_like_4_6_etc_are_not/</guid>
      <pubDate>Mon, 27 Jan 2025 08:17:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepSeek 为什么开源他们的工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/</link>
      <description><![CDATA[如果他们的培训效率提高 45 倍，他们本可以主宰 LLM 市场。你认为他们为什么选择开源他们的工作？这对他们的公司有什么好处？现在美国的大型实验室可以说：“我们将采用他们的优秀想法，并将它们与我们的秘密想法结合起来，我们仍然会领先”  编辑： DeepSeek-R1 现在在 LLM Arena 上排名第一（使用 StyleCtrl）！它们与其他 3 个模型共享此排名：Gemini-Exp-1206、4o-latest 和 o1-2024-12-17。    提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/</guid>
      <pubDate>Mon, 27 Jan 2025 07:48:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] Transformers 推理优化 ⏰🚀 – deepschool.ai</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib10gr/p_transformers_inference_optimizations/</link>
      <description><![CDATA[      我感觉还有很多事情可以做。例如，在给定 400 个 token 输入的情况下，我只能在 10 秒内输出 200 个 token。希望您能提供意见，让我们知道下一步该探索什么。    提交人    /u/themathstudent   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib10gr/p_transformers_inference_optimizations/</guid>
      <pubDate>Mon, 27 Jan 2025 05:40:39 GMT</pubDate>
    </item>
    <item>
      <title>[R][Q] 抱歉，我正在寻找一本包含数学 ML 基础知识的书；它大约有 400 页，我记得有人在这里发过帖子，但我找不到它</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iaw81h/rq_sorry_i_was_looking_for_that_book_with_all_the/</link>
      <description><![CDATA[[R][Q] 抱歉，我正在寻找那本包含机器学习数学基础知识的书；它大约有 400 页，我记得有人在这里发布过，但找不到它 它基本上是机器学习的所有数学基础知识    提交人    /u/Proper_Fig_832   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iaw81h/rq_sorry_i_was_looking_for_that_book_with_all_the/</guid>
      <pubDate>Mon, 27 Jan 2025 01:26:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 本地运行 Deepseek R1 32B</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iagk2t/d_ran_deepseek_r1_32b_locally/</link>
      <description><![CDATA[      在本地运行 Deepseek R1 32B。 使用 RTX 8000 - 48gb 内存。  但看起来它使用不到 22 gb 的内存来运行 32b 模型。  速度约为 14tokens/秒，对于我们想要的任何东西来说已经足够快了。  最重要的是，使用 OpenWebUI 有助于访问互联网/搜索。     提交人    /u/mrloki_reddit   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iagk2t/d_ran_deepseek_r1_32b_locally/</guid>
      <pubDate>Sun, 26 Jan 2025 14:57:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] 制作了一个 FAANG 招聘信息聚合器，用于 AI / 机器学习职位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ia7feh/p_made_a_faang_job_postings_aggregator_for_ai/</link>
      <description><![CDATA[大家好，ML 的朋友们！ 我创建了一个职位公告板，并决定在这里分享，因为我认为它很有用。该职位公告板包含来自 FAANG 公司（谷歌、Meta、苹果、亚马逊、Nvidia、Netflix、Uber、微软等）的职位空缺，您可以按类别、地点、工作年限、资历级别、类别等筛选职位空缺。您还可以创建职位提醒。 您可以在这里查看： https://faang.watch/?categories=AI+_+Machine+Learning 从技术层面上讲，它的工作方式是：  它每天都会抓取公司网站的原始回复。   然后从原始响应中提取标题、描述和位置   LLM 填写工作年限、资历等内容并统一位置（例如，“美国加利福尼亚州”和“美国加利福尼亚州”指向相同的职位发布） 然后将工作机会分成几类  让我知道你的想法 - 欢迎随时提问和请求功能 :)    提交人    /u/dev-ai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ia7feh/p_made_a_faang_job_postings_aggregator_for_ai/</guid>
      <pubDate>Sun, 26 Jan 2025 06:05:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>