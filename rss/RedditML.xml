<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 30 Sep 2024 12:34:40 GMT</lastBuildDate>
    <item>
      <title>[P] 我试图通过分析数百个 Reddit 帖子来绘制人工智能中最常见和最流行的挑战。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fstn9m/p_i_tried_to_map_the_most_recurrent_and_popular/</link>
      <description><![CDATA[嗨，AI 爱好者和开发者们！我一直在开展一个项目，通过查看 Reddit 专用子版块上的帖子来分析和可视化 AI 开发中最常见的技术挑战。 项目目标 该项目的主要目标是识别和跟踪与 AI 开发相关的最普遍和最流行的技术挑战、实施问题和概念障碍。通过这样做，我们可以：  帮助开发人员专注于最相关的技能和知识领域 指导教育内容创建者解决最紧迫的问题 为研究人员提供有关需要更多关注或解决方案的领域的见解  工作原理  数据收集：我从以下每个与 AI 相关的 subreddits 中获取了最热门的 200 个帖子：r/learnmachinelearning、r/ArtificialIntelligence、r/MachineLearning、r/artificial。 筛选：使用 LLM 筛选帖子，以确保它们涉及特定的技术挑战，而不是一般讨论或新闻。 总结和标记：每个相关帖子都经过总结和标记最多可从预定义的 50 个技术领域列表中选择三个类别（例如，LLM-ARCH 代表大型语言模型架构，CV-OBJ 代表计算机视觉对象检测）。 分析：系统分析标签的频率，以及每个类别相关的赞成和评论。 可视化：结果通过各种图表和热图可视化，显示最常见的挑战及其在社区中的相对重要性。  结果（以下是图表）：  按综合得分（频率 + 赞成 + 评论）排名的前 15 个标签 标准化标签流行度热图 带有各个分数的标签分析表  反馈 我很乐意得到您的对这个项目的想法以及如何使其对人工智能开发社区更有用。具体来说：  除了 Reddit 之外，我们还应该考虑其他数据源吗？ 您认为哪些其他指标或分析有价值？ 如何使结果对开发人员、教育工作者或研究人员更具可操作性？ 这种方法是否存在我们应该解决的潜在偏见或局限性？ 您是否对定期更新这些趋势的仪表板感兴趣？  非常感谢您的见解和建议！ TL;DR：AI 开发挑战分析器  该项目分析 Reddit 帖子以识别常见的 AI 开发挑战 使用 ML 筛选、总结和标记来自 AI 相关子版块的帖子 可视化结果以显示讨论最多和参与度最高的技术领域 在此处查看结果 寻求反馈以改进分析     提交人    /u/Fixmyn26issue   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fstn9m/p_i_tried_to_map_the_most_recurrent_and_popular/</guid>
      <pubDate>Mon, 30 Sep 2024 11:53:28 GMT</pubDate>
    </item>
    <item>
      <title>[N] 强化学习速查表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fssp75/n_reinforcement_learning_cheat_sheet/</link>
      <description><![CDATA[大家好！ 我刚刚在 Medium 上发表了我的第一篇文章，还创建了一个强化学习备忘单。🎉 我很乐意听到您的反馈、建议或任何关于如何改进它们的想法！ 请随时查看它们，并提前感谢您的支持！😊 https://medium.com/@ruipcf/reinforcement-learning-cheat-sheet-39bdecb8b5b4    提交人    /u/Prudent_Nose921   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fssp75/n_reinforcement_learning_cheat_sheet/</guid>
      <pubDate>Mon, 30 Sep 2024 10:56:25 GMT</pubDate>
    </item>
    <item>
      <title>[N] GeoZ：基于区域的聚类算法可视化 2.0</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fssh5l/n_geoz_a_regionbased_visualization_of_clustering/</link>
      <description><![CDATA[想与大家分享一些令人兴奋的消息！ :D 我们刚刚发布了 GeoZ 2.0，这是我们地理空间数据可视化库的一次重大更新，一年多前我在这个 subreddit 上分享过它的初始版本，当时用的也是这个标题，只是没有 2.0 这个绰号 xD 🚀 主要亮点： * 库的超棒新 Logo * 用于映射稀疏数据集的新 voronoi_regions_plot 函数 * 全局设置，用于在所有图上使用一致的样式 * 自动纵横比计算，以获得更准确的地图比例 * 扩展的调色板，支持多达 20 个不同的集群 * 每个函数的 Jupyter Notebook 示例 * 通过并行处理支持进行性能优化 voronoi_regions_plot 函数基于与河海大学研究人员（Fang 等人， 2024）。这种新方法解决了 GeoZ 的一个主要弱点，即使用少量样本绘制数据集。它通过创建 Voronoi 图并用相同颜色对同一群集内的区域进行着色来实现这一点。 我们还对现有功能进行了重大改进，增强了文档，并确保了与 pandas 2.x 的兼容性。 在 https://github.com/Ne-oL/geoz/releases/tag/v2.0.1 查看 GeoZ 2.0 的完整更新日志。 您可以使用简单的方法将其安装在任何 Python 环境中： pip install geoz 我们很高兴看到您将如何在机器学习和地理空间项目中使用这些新功能。快乐地绘制地图！ 参考文献： Jinzhu Fang、Yibo Yang、Peng Yi、Ling Xiong、Jijie Shen、A. Ahmed、K. ElHaj、D. Alshamsi、A. Murad、S. Hussein、A. Aldahan，使用机器学习对阿拉伯联合酋长国地下水进行地理空间稳定同位素特征分析，《水文学：区域研究》杂志，第 55 卷，2024 年，101938，ISSN 2214-5818，    提交人    /u/Ne-oL   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fssh5l/n_geoz_a_regionbased_visualization_of_clustering/</guid>
      <pubDate>Mon, 30 Sep 2024 10:41:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Llama-3 代码库和 Google NotebookLM 进行实验 – 令人兴奋的结果！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsq2vp/d_experimenting_with_llama3_codebase_and_google/</link>
      <description><![CDATA[      受到 karpathy 最近关于 NotebookLM 项目的推文的启发，我将 Llama-3 架构的代码库提供给NLM 并使用 Rag 以及 SERP API 来查找完美的图像并将它们与生成的音频同步（我自己添加了一些图像） 结果超出了我的预期。Google 的 NotebookLM 真的很棒！ :) Google NotebookLM 解释 LLAMA-3 这里也是 Youtube 链接：https://www.youtube.com/watch?v=4Ns6aFYLWEQ    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsq2vp/d_experimenting_with_llama3_codebase_and_google/</guid>
      <pubDate>Mon, 30 Sep 2024 07:39:34 GMT</pubDate>
    </item>
    <item>
      <title>🚀 将任何 GitHub 存储库转换为单个文本文件，非常适合 LLM 提示使用“[Project]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fspn1s/convert_any_github_repo_to_a_single_text_file/</link>
      <description><![CDATA[大家好！ 👋 我知道有几种类似的工具，但你应该看看我的工具的原因如下：  免费且立即可用 💸 适用于私有存储库 🛡️ 完全在你的浏览器中运行 - 不会将数据发送到任何地方，因此它完全安全 🔒 适用于GitHub URL 到子目录 📁 支持标签、分支和提交 SHA 🏷️ 让你包含或排除特定文件 📂  🔗 试用这里 🔗 源代码 尝试一下，让我知道你的想法！😊 repo2txt 演示    提交人    /u/Beautiful-Novel1150   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fspn1s/convert_any_github_repo_to_a_single_text_file/</guid>
      <pubDate>Mon, 30 Sep 2024 07:05:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在 arxiv 中寻找认可 - cs.AI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsnzl5/r_looking_for_endorsement_in_arxiv_csai/</link>
      <description><![CDATA[您好，我正在尝试将我的论文提交给会议，但想先将预印本放在 arxiv 中。这是我的第一部作品，因此需要认可。 请仔细阅读下面的论文详细信息，如果您是合格的认可人，并希望查看预印本并决定是否愿意认可我，请发表评论，以便我可以向您发送私信。 论文详细信息： 标题：将 Web 应用程序表示为知识图谱 摘要：传统的抓取和解析 Web 应用程序的方法依赖于从初始页面提取超链接并递归抓取链接的页面。此方法生成一个图，其中每个节点代表来自给定端点的原始非结构化数据，边缘表示通过超链接在页面之间的转换。但是，这些方法通常无法捕捉现代 Web 应用程序的动态和交互性质。相比之下，所提出的解决方案将每个节点建模为 Web 应用程序当前状态的表示，其中边缘表示为修改该状态而采取的特定操作。这种转变使 Web 应用程序的表示更具可解释性和功能性，为下游任务提供更丰富的见解。 提前谢谢您！    提交人    /u/BiryaniSenpai   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsnzl5/r_looking_for_endorsement_in_arxiv_csai/</guid>
      <pubDate>Mon, 30 Sep 2024 05:08:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人形动画的预训练模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fshs76/d_pretrained_models_for_humanoid_animations/</link>
      <description><![CDATA[目前有很多用于图像相关项目的开放/免费模型。有没有用于人体动画的类似模型？基于 GAN 的模型似乎在对现有动画数据进行训练后应该能够生成新的、逼真的动作。但我找不到任何有用的东西。我正在尝试自己在本地进行一些训练/实验，但结果并不理想。任何见解和指点都将不胜感激！    提交人    /u/gamesntech   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fshs76/d_pretrained_models_for_humanoid_animations/</guid>
      <pubDate>Sun, 29 Sep 2024 23:27:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我对自己实施的基线缺乏信心。我该怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fshhor/r_i_feel_underconfident_about_the_baselines_i/</link>
      <description><![CDATA[我需要实现 3 个具有一定理论遗憾界限的基线 RL 算法。原始论文没有提供他们自己的任何代码/也没有在他们的工作中进行任何模拟。我对我的实现没有信心，特别是超参数调整，因为我们使用的环境不同。 我尽我所能通过严格搜索不同的参数来使基线发挥最佳性能。当理论上我们应该获得可比结果时，显示我们的算法表现更好感觉不道德。它们的性能非常依赖于超参数。我该怎么办？    提交人    /u/Replay0307   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fshhor/r_i_feel_underconfident_about_the_baselines_i/</guid>
      <pubDate>Sun, 29 Sep 2024 23:13:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 优化 transformer</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsgz5i/r_optimizing_transformers/</link>
      <description><![CDATA[您好，我目前致力于优化 Transformer 模型，特别是在多视图图像和/或交叉注意网络中。我注意到交叉注意层添加了很多参数，这会减慢训练过程。我正在探索降低计算复杂度以提高速度的方法（目前和以后一段时间内不会牺牲太多性能）。我开始研究：  低秩矩阵分解 - 我一直在阅读有关如何应用它来减小投影矩阵的大小（例如，交叉注意中的 projq、projk、projv）的文章。是否有人在交叉注意机制中使用低秩分解的经验？ 其他参数减少技术 - 除了低秩分解之外，还有其他方法可以减少 Transformer 模型中的参数数量，比如稀疏性和修剪 - 你对这些有什么建议或经验吗？ 克服多视图场景中的冗余 - 鉴于我的问题的多视图性质，我怀疑交叉注意处理不同视图的方式存在一些冗余。是否有人研究过减少基于 Transformer 的网络中视图之间的冗余？哪种技术最适合你？  我开始研究 CVPR、NEURIPS、ECCV 等，但如果您能分享任何见解、建议、经验或论文，我将不胜感激！提前致谢！    提交人    /u/Cool-Economy3492   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsgz5i/r_optimizing_transformers/</guid>
      <pubDate>Sun, 29 Sep 2024 22:47:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 任务增量持续学习的基线</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsg0kf/r_baselines_for_taskincremental_continuous/</link>
      <description><![CDATA[我正在寻找一篇或多篇包含任务增量式持续学习基线结果的论文，特别是包含 CIFAR100/5 的 ResNet50 结果的论文。最近的许多文献都集中在类增量学习上。欢迎提出任何建议！    提交人    /u/Due-Mix2877   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsg0kf/r_baselines_for_taskincremental_continuous/</guid>
      <pubDate>Sun, 29 Sep 2024 22:02:30 GMT</pubDate>
    </item>
    <item>
      <title>尝试进入 LLM 培训。关于训练 T5 模型的数据集问题。[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsdu4v/trying_to_get_into_training_llms_question_on/</link>
      <description><![CDATA[大家好。我正在尝试训练法学硕士。我接手的第一个个人项目之一是微调 T5 模型。我想针对我喜欢的特定作者的特定领域主题专门训练一个 QnA T5 模型。我能够创建自己的数据集。由于我的目标是创建一个专门执行 QnA 的聊天机器人，所以我知道 QnA 数据集是必需的。我还能够创建一个屏蔽语言建模数据集和段落改组数据集，但我认为这些数据集是可选的。我认为它们应该可以帮助我的 T5 模型掌握作者使用的特定白话/行话/口头习惯，但我在训练期间注意到，将所有 3 个数据集组合在一起，训练我的 T5 模型需要太长时间（T5-small 需要 8 小时以上）。我决定只使用 QnA 数据集来加快训练速度并节省资金。我相信 QnA 数据集应该足够了，但我在网上找不到任何信息来支持我的想法。 我只是想听听其他有 T5 经验的人的意见。包括段落改组和掩码语言建模数据集对 QnA 任务有任何影响吗？我也想建立一个 ML/AI 产品组合。托管/部署我自己的 T5 模型是否值得托管，还是与 Llama 和 GPT 等更大的模型相比，它被认为是过时/无聊的？我确实打算在未来的某个时候训练这些模型，我只是想从 T5 作为启动项目开始，然后再转到更大的 LLM。    提交人    /u/ApricotSlight9728   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsdu4v/trying_to_get_into_training_llms_question_on/</guid>
      <pubDate>Sun, 29 Sep 2024 20:24:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] VisionTS：使用视觉掩蔽自动编码器进行零样本时间序列预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fs7opx/p_visionts_zeroshot_time_series_forecasting_with/</link>
      <description><![CDATA[      VisionTS 是一种新预训练的模型，它将预测任务重新定义为图像重建任务。该技术乍一看似乎违反直觉，但该模型的效果出奇地好。 可以在此处找到该模型的详细分析。 VisionTS    提交人    /u/apaxapax   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fs7opx/p_visionts_zeroshot_time_series_forecasting_with/</guid>
      <pubDate>Sun, 29 Sep 2024 16:00:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 截至 2024 年，风格转换的 SOTA 模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frxkwa/d_whats_the_sota_model_for_style_transfer_as_of/</link>
      <description><![CDATA[目前图像风格转换的最新技术是什么？扩散是否比基于 Gram 矩阵的方法有显著的改进？ 我熟悉 2017 年基于 Gram 矩阵的方法，但它们在更高级别的概念上遇到了困难。现在还在使用它们吗？    提交人    /u/JellyBean_Collector   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frxkwa/d_whats_the_sota_model_for_style_transfer_as_of/</guid>
      <pubDate>Sun, 29 Sep 2024 05:50:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 29 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>