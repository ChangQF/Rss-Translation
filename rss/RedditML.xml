<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Thu, 18 Apr 2024 15:14:12 GMT</lastBuildDate>
    <item>
      <title>[D] 产品评估是讨论最多的话题之一</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c75q78/d_product_evaluations_is_one_of_the_most/</link>
      <description><![CDATA[我们是一家人工智能咨询公司，这种情况一次又一次地发生在我们身上...... 我们开始一个新的法学硕士项目客户。 他们的工程师很快就能完成 80%。 他们有很多边缘情况，希望我们完成剩余的 20%。  &gt;我们向他们询问有关评估的信息。 当然他们没有。 我们创建评估框架，迭代改进管道，瞧。  工作完成，每个人都很高兴。 我认真地认为，根据我们的观察，最好的人工智能产品团队将是那些在评估上花费大量时间的团队。它很无聊，很重复，但它区分了令人惊叹的人工智能产品和表现不佳的产品。   由   提交 /u/BootstrapGuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c75q78/d_product_evaluations_is_one_of_the_most/</guid>
      <pubDate>Thu, 18 Apr 2024 15:10:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用我自己的数据集重现研究论文的结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c74dpj/p_recreating_results_from_research_paper_using_my/</link>
      <description><![CDATA[您好，所以我一直在尝试重新创建这篇特定论文（神经协同过滤）的结果：https://arxiv.org/abs/1708.05031 使用我自己的数据而不是 MovieLens 数据集。 我使用的数据集非常相似这里（neural_collaborative_filtering/Data/ml-1m.test. rating at master·hexiangnan /neural_collaborative_filtering · GitHub)。我知道我应该分为训练和测试。我的问题是我是否应该自己创建 test.negative 文件，或者是否应该创建通过负采样自动处理（基本上包含基于缺乏数据的负反馈）。 我非常感谢您的反馈！先谢谢了。 这里是这篇论文在github上的官方实现：GitHub - heyangnan/neural_collaborative_filtering: Neural Collaborative Filtering&lt; /a&gt;   由   提交/u/panos42  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c74dpj/p_recreating_results_from_research_paper_using_my/</guid>
      <pubDate>Thu, 18 Apr 2024 14:13:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 100+标签文本分类问题。 “通常”的方法是什么？变形金刚？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c748uc/d_100_labels_textclassification_problem_whats_the/</link>
      <description><![CDATA[每个文本不超过15个单词，并且类别高度不平衡。但它们都至少有 30 个左右的实例。 我成功地处理了具有相同性质的数据，但具有大约 15 个标签以及梯度增强模型的集合。  在深入测试一堆模型之前，我想知道是否有一些策略可以解决像这样的高维问题。  有些问题是无法解决的，让我们面对现实吧。但是你们会尝试什么？   由   提交/u/Melodic_Reality_646   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c748uc/d_100_labels_textclassification_problem_whats_the/</guid>
      <pubDate>Thu, 18 Apr 2024 14:07:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 扩散模型背后的完整扩展和详细数学的来源。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c73jdc/p_source_for_full_expanded_and_detailed_math/</link>
      <description><![CDATA[我目前正在使用 翁莉莲的博客。当以 x_{0} 为条件时，我一直致力于完全展开反向条件概率的平均值表达式，如果我能获得数学来源或任何人的帮助，我将非常感激。    由   提交 /u/Training-Durian-3158   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c73jdc/p_source_for_full_expanded_and_detailed_math/</guid>
      <pubDate>Thu, 18 Apr 2024 13:36:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在 EEG 数据上训练 LSTM 和 Transformer</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c72xkx/p_training_lstm_and_transformer_on_eeg_data/</link>
      <description><![CDATA[我有大约 60 个 EEG 文件，由 45 个通道表示。每个文件长 6 小时，每秒由 100 个数据点表示。因此，本质上每个文件都有形状为 (45, 180000) 的数据。 我正在尝试训练两种架构以使用这些数据进行二进制预测：一个 LSTM 和一个预训练的 Transformer。我尝试过 LSTM 的多种架构（有 CNN、没有 CNN、SoftMax、Sigmoid、更多层、更少层等等），但模型无法学习。我还更改了数据的结构（将其分解为 5 分钟的块以增加数据点的数量，将数据分解为 5 分钟的块并像时间序列一样通过 LSTM 等）。  当我尝试训练预先训练的 Transformer 时，数据量如此之大，以至于我的会话总是在数据预处理步骤本身中崩溃。 有什么方法或方法吗？根据我的脑电图数据训练模型？我是否遗漏了一些明显的东西？   由   提交 /u/kris_sashank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c72xkx/p_training_lstm_and_transformer_on_eeg_data/</guid>
      <pubDate>Thu, 18 Apr 2024 13:09:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 表格数据训练模型导致高损失</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c72nnc/d_training_model_on_tabular_data_resulting_in/</link>
      <description><![CDATA[您好，我正在使用已预处理（缩放、PCA）的表格数据训练模型。目前有超过 50k 行和 10 列。损失很高，不确定我哪里做错了 就上下文而言，我使用 MSE 作为我的损失函数，0.01 学习率和 256 批量大小。 谢谢这么多。 这就是我的初始化代码的样子： class NN(nn.Module): def init(self): super(NN, self). init() # 表格数据处理层 self.fc1 = nn.Linear(10, 64) self.fc2 = nn.Linear(64, 32) self.fc3 = nn.Linear(32, 16) self.fc4 = nn. Linear(16, 1) self.bn1 = nn.BatchNorm1d(64) self.bn2 = nn.BatchNorm1d(32) self.bn3 = nn.BatchNorm1d(16) self.relu = nn.ReLU() self.dropout = nn .Dropout(0.25) defforward(self, x_tab, x_img): out = self.fc1(x_tab) out = self.bn1(out) out = self.relu(out) out = self.dropout(out) out = self .fc2(out) out = self.bn2(out) out = self.relu(out) out = self.dropout(out) out = self.fc3(out) out = self.bn3(out) out = self.relu (out) out = self.dropout(out) out = self.fc4(out) return out  输出： Epoch 1/30，损失：16834.8088纪元2/30，损失：4379.7037纪元3/30，损失：3361.2462纪元4/30，损失：3255.9039纪元5/30，损失：3255.8603纪元6/30，损失：3243.9488纪元7/3 0，损失：3235.4387纪元 8/30，损失：3213.4688 纪元 9/30，损失：3189.1130 纪元 10/30，损失：3174.2118 纪元 11/30，损失：3168.1597 纪元 12/30，损失：3155.3225 纪元 13/30，损失：315 0.0659 第 14 纪元/30，损失：3119.2989 纪元 15/30，损失：3117.0893 纪元 16/30，损失：3130.4699 纪元 17/30，损失：3126.7107 纪元 18/30，损失：3110.9422 纪元 19/30，损失：3119.8 601 纪元 20/30 ，损失：3094.5037 纪元 21/30，损失：3054.4725 纪元 22/30，损失：3079.4411 纪元 23/30，损失：3064.4010 纪元 24/30，损失：3049.7988 纪元 25/30，损失：3022.971 4 纪元 26/30，损失：3029.0342 Epoch 27/30，丢失：3034.8153 Epoch 28/30，丢失：3025.2383 Epoch 29/30，丢失：3052.9892 Epoch 30/30，丢失：3033.2717    由   提交 /u/sparttann   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c72nnc/d_training_model_on_tabular_data_resulting_in/</guid>
      <pubDate>Thu, 18 Apr 2024 12:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 微软推出 VASA-1：实时生成逼真的音频驱动说话面孔</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c72frh/r_microsoft_presents_vasa1_lifelike_audiodrive/</link>
      <description><![CDATA[ 由   提交/u/TheMrZZ0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c72frh/r_microsoft_presents_vasa1_lifelike_audiodrive/</guid>
      <pubDate>Thu, 18 Apr 2024 12:45:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 复制和比较研究模型 - 最佳实践？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c70y9j/d_reproducing_and_comparing_models_from_research/</link>
      <description><![CDATA[在我的工作中，我花费了大量时间复制研究论文并尝试将它们应用到我们的用例（医学图像分析）中。  通常，这是一个很大的麻烦，甚至带有代码的论文也经常表明，如果没有大量编辑，它就无法运行。一旦它们运行，只有在设置特定的随机种子时结果才会好...... 然后将其应用到我们的用例后，我意识到性能的提高实际上并不是来自新模型，但是来自不同的后处理方式... 我已经开始为自己编写一些脚本来模块化它，以便更容易地重现和比较。  但我不确定这是否是正确的方法。所以我很好奇，您为您的用例重现模型并进行科学比较的方法是什么？    由   提交 /u/MintOwlTech   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c70y9j/d_reproducing_and_comparing_models_from_research/</guid>
      <pubDate>Thu, 18 Apr 2024 11:27:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 什么 RL 技术可用于在单个偏好数据点而不是配对数据点上训练 LLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6z759/d_what_rl_technique_can_be_used_to_train_an_llm/</link>
      <description><![CDATA[PPO 和 DPO 目标似乎都需要首选 (w) 和不首选 (l) 响应。可以使用/更改来在单一偏好数据点上训练/微调法学硕士（即，对于每个输入提示，我只有一个偏好或只有一个不偏好的响应）？如果没有，是否有任何强化学习技术可以实现这一点？   由   提交/u/CatfishJones96   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6z759/d_what_rl_technique_can_be_used_to_train_an_llm/</guid>
      <pubDate>Thu, 18 Apr 2024 09:38:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 查找卫星图像数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6weme/d_finding_data_sets_of_satellite_images/</link>
      <description><![CDATA[我计划检测森林中的非法作物种植，但很难找到合适的数据集。有什么办法可以克服这个问题吗？   由   提交 /u/MayanthaCry   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6weme/d_finding_data_sets_of_satellite_images/</guid>
      <pubDate>Thu, 18 Apr 2024 06:22:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 训练 VQGAN 但 GAN 损失持续上升</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6rtlt/p_training_a_vqgan_but_gan_loss_keeps_going_up/</link>
      <description><![CDATA[     &lt; td&gt; https://preview.redd.it/h13z13eu a5vc1.png?width=640&amp;format=png&amp;auto=webp&amp;s=397d5127453b2f4a1d6f6df28fb5fc 8a2f2f0cff 我认为VQ 损失和感知损失看起来很正常，但我觉得很难理解为什么判别器会走向完全不同的方向……以前有人见过类似的事情吗？ 更多细节：我正在训练 vqgan imagenet 来自论文 Taming Transformers for High-Resolution Image Synthesis   由   提交/u/darthjaja6   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6rtlt/p_training_a_vqgan_but_gan_loss_keeps_going_up/</guid>
      <pubDate>Thu, 18 Apr 2024 02:02:18 GMT</pubDate>
    </item>
    <item>
      <title>[R] [2404.10667] VASA-1：实时生成逼真的音频驱动的说话面孔</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6q61y/r_240410667_vasa1_lifelike_audiodriven_talking/</link>
      <description><![CDATA[ 由   提交/u/s6x  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6q61y/r_240410667_vasa1_lifelike_audiodriven_talking/</guid>
      <pubDate>Thu, 18 Apr 2024 00:41:07 GMT</pubDate>
    </item>
    <item>
      <title>[N] 美联储任命“人工智能毁灭者”来管理美国人工智能安全研究所</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6nps8/n_feds_appoint_ai_doomer_to_run_us_ai_safety/</link>
      <description><![CDATA[https://arstechnica.com/tech-policy/2024/04/feds-appoint-ai-doomer-to-run-us-ai-safety-institute/ 文章简介： 被任命为 AI 安全负责人的是 Paul Christiano，他是前 OpenAI 研究员，开创了一种名为基于人类反馈的强化学习的基础 AI 安全技术（ RLHF），但也因预测“人工智能发展有 50% 的机会以‘厄运’而告终”而闻名。尽管克里斯蒂安诺的研究背景令人印象深刻，但一些人担心，任命所谓的“人工智能厄运者”会带来灾难。 NIST 可能冒着鼓励非科学思维的风险，许多批评家认为这些思维纯粹是猜测。   由   提交/u/bregav  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6nps8/n_feds_appoint_ai_doomer_to_run_us_ai_safety/</guid>
      <pubDate>Wed, 17 Apr 2024 22:49:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] LSTM时间序列预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6igqk/d_lstm_time_series_forecasting/</link>
      <description><![CDATA[     我一直在使用 LSTM 模型进行时间序列预测，并注意到它们在预测下一步的预测方面表现良好。然而，当尝试多步预测来预测未来一周（168 个周期，每小时数据）时，性能显着下降。目前，我使用递归方法：反馈预测作为下一个输入（闭环）。尽管开环预测要准确得多，但这种方法并没有产生良好的结果。 是否有更好的技术来增强 LSTM 的多步预测精度？ LSTM 对于多步预测没有用吗？ 任何解释 LSTM 多步预测的文章链接或资源将不胜感激。 https://preview.redd.it/30y3m16gr3vc1.png?width=833&amp;format=png&amp;auto= webp&amp;s=6d6b29e05b105b50d2689127ea6881d1ec667903 https://preview.redd.it/a971j16gr3vc1.png?width=833&amp;format=png&amp;auto=webp&amp;s=fec277d9343c5f702247a6135dbb630358c14cca 链接到代码：https://github.com/thelizri/ML-Prometheus/blob/main/LSTM.ipynb&lt; /p&gt;   由   提交 /u/StressAccomplished26   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6igqk/d_lstm_time_series_forecasting/</guid>
      <pubDate>Wed, 17 Apr 2024 19:15:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>