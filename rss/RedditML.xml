<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sun, 02 Mar 2025 01:21:45 GMT</lastBuildDate>
    <item>
      <title>[r]发布我的离散辅助仪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1ed93/r_releasing_my_discrete_vocoder/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我正在释放我的离散vocoder（24kh，每秒50帧，每秒50帧，4个密码簿）。 我试图将某些东西放在高biTrate的高位型和低比特拉特Mimi/WaveTrate Mimi/waveTocken中。型号和用法示例： https://huggingface.co/balecoon/vq4_50fps_24khz_vocoder  href =“ https://huggingface.co/spaces/balacoon/ttsleaderboard”&gt; https://huggingface.co/spaces/balacoon/balacoon/ttsleaderboard （pick`ovododer`作为系统）提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1ed93/r_releasing_my_discrete_vocoder/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1ed93/r_releasing_my_discrete_vocoder/</guid>
      <pubDate>Sun, 02 Mar 2025 00:39:54 GMT</pubDate>
    </item>
    <item>
      <title>[D]在ML管道中实现实验？ （+ ML系统设计面试问题）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1dyff/d_enabling_experimentation_in_ml_pipelines_ml/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我是一个恢复了数据科学家，对数据工程和ML工程进行了关注（我为小型启动工作，所以我在较小的启动中做了一些两者，并且我以前在较大的org中所做的角色，但我曾经在offline/batch ml thersem and op anders访问过我的访问中，我已经接受过访问的访问。许多问题如何构建和部署生产ML管道（快速，可扩展的推理API）以及实现不同ML管道的实验。 这是两个单独的问题，但我觉得ML管道的最佳设计将同时实现这两者。我还没有发现最佳。这也是我目前工作的启动的挑战。 我觉得大多数OSS ML工具实际上并没有启用这些功能中的任何一个，这些功能（推理服务器和实验工作流程）需要由MLE/SWE构建。所有这些都需要缝合在一起。我正在考虑诸如AirFlow，Kedro，MLFlow等工具...也许云提供商（Databricks，AWS SageMaker，Azureml）提供了简单的方法，可以简单地上传模型来生产并通过可伸缩的API（+实验）为其提供服务，但我不知道它。 （如果您知道这样的ML工具，请告诉我） 无论哪种方式，我对快速型号的回应将被模型腌制的泡菜包裹在fastapi中包裹在docker上包裹的docker（已同意）      我想在哪里丢失了一些我会在哪里进行实验，我想在哪里构建了我的习惯。 （在ML管道的不同部分（清洁，Fe，培训，评估）中注册功能），可以在YAML中定义生产管道，并且可以在其他YAML中写入单独的实验，并在其他YAML中写下，并在某种程度上以并行部署预测和指标，以比较     &lt;强我的感觉，我的回答是如何的。你们解决了这些问题？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/myssirious_energy_80     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1dyff/d_enabling_experimentation_in_ml_pipelines_ml/</guid>
      <pubDate>Sun, 02 Mar 2025 00:19:13 GMT</pubDate>
    </item>
    <item>
      <title>[R]有效LLM的窗户注意力训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1ckye/r_sliding_window_attention_training_for_efficient/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     https：//arxiv.org/abs/2502.18845 Mamba，Titans和Transformers ++。在结论中跳跃：  ，通过用sigmoid替换软杀剂，将平衡的alebi替换为SWAT并将其结合在一起，SWAT解决了注意力下沉问题，并确保稳定的培训并确保稳定的培训。这么多的“曼巴发生了什么”帖子，我仍在等待基于泰坦的模型的发布，因此，尽管我不知道我们是否会使用特警，但我还是赞赏该论文作为对扩展 - 封闭式/替代架构世界中当前的调查。   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1ckye/r_sliding_window_attention_trainention_training_for_for_effficity/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1ckye/r_sliding_window_attention_training_for_efficient/</guid>
      <pubDate>Sat, 01 Mar 2025 23:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[d]关于大规模优化ML模型并构建分布式培训/推断的材料</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j18c64/d_materials_on_optimizing_ml_models_at_scale_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  已经遇到了许多高级ML工程师工作，需要涉及“大规模运行和优化模型”或“分布式培训和推理”的经验。 在我作为ML工程师的5年中，我从来没有遇到需要此类技能的问题。这涉及哪些技术/知识？谁能指出相关的材料？ 我知道Pytorch DDP教程，但我想，不仅仅是它吗？ ，我可能还缺少某些东西，但没有像用户那样遇到pytorch-light trightwork，而是用户远离用户？例如。分布式培训和推断只是添加了一些参数？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j18c64/d_materials_optimizing_ml_models_models_at_at_scale_and/”&gt; [links]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j18c64/d_materials_on_optimizing_ml_models_at_scale_and/</guid>
      <pubDate>Sat, 01 Mar 2025 20:01:48 GMT</pubDate>
    </item>
    <item>
      <title>[d]插补方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j17zuj/d_imputation_methods/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我是一名医学生，目前正在接受ML实验，以根据不同的临床变量进行特定类型的手术后预测结果。我正在研究一个非常稀疏的数据集（其中一些特征丢失了约20-25％的数据），因此需要估算大量数据。我目前正在使用Scikit学习运行实验，但是多个插补功能不允许同时估算数值和分类变量，因此我使用了Missforest软件包。在使用“置换重要性”图和部分依赖性显示的置换率审查我的最终模型后，我意识到我的插补方法引入了很多偏见，有时会损害临床变量的实际正稳定值。我知道引入了这种偏见是因为先前使用同一数据集发表的论文，而不是使用Missforest算上，而是使用R。 中的MICE库，现在我不确定我应该做什么以减轻这种偏见。在上一篇使用小鼠的文章中，他们使用10个不同的估算数据集训练了单个回归模型，以评估其性能。在我的上下文中，我不确定我该怎么办，因为我使用10倍CV培训了几个ML模型，只有一个估算的数据集。我认为我可以使用小鼠生成一个估算的数据集，但是我觉得这违背了小鼠的全部目的，除非我错了，否则在这种情况下，我希望看到一些论文实施了小鼠以开发和验证不同ML模型。我还有其他方法可以减轻我的初始插补方法产生的偏差吗？ 谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j17zuj/d_imputation_methods/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j17zuj/d_imputation_methods/</guid>
      <pubDate>Sat, 01 Mar 2025 19:46:51 GMT</pubDate>
    </item>
    <item>
      <title>[P]更新：使用Langchain和Langgraph呼吁使用DeepSeek-R1的工具：现在在打字稿中！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0wv8j/p_update_tool_calling_for_deepseekr1_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在这里发布了我在工具上创建的GitHub Repo Python软件包，呼吁使用Langchain和Langgraph进行DeepSeek-R1 671b，或更一般地用于Langchain cathopenal class in langchain cathopenal class中的任何LLMS（对于新发布的LLMS）（不支持Newly Preakain callms），该工具又支持/  https://github.com/leock.com/leockl/leockl/tool-ahead-ahead-oftime     通过社区请求，我很高兴能为此包含这个包的typepript版本。 - 在打字稿中，将工具呼叫功能的NPM套件：    https://github.com/github.com/leockl/leockl/leockl/leockl/tool-ahead-ockl/tool-ip----有帮助。享受！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lc19-     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0wv8j/p_update_tool_calling_for_deepseekr1_with/</guid>
      <pubDate>Sat, 01 Mar 2025 10:47:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] Marsopt：混合自适应随机搜索优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0vsct/r_marsopt_mixed_adaptive_random_search_for/</link>
      <description><![CDATA[       &lt;！ -  sc_off- sc_off-&gt;     marsopt （混合自适应随机搜索优化）的设计旨在解决具有多个参数类型的优化复杂系统的挑战。 The library implements an adaptive random search algorithm that dynamically balances exploration and exploitation through:  Adaptive noise for efficient parameter space sampling Elite selection mechanisms to guide search toward promising regions Integrated support for log-scale and categorical parameters Flexible objective handling (minimization or最大化）  技术突出显示 我们的基准测试表明，与Optuna的TPE Sampler相比，Marsopt的表现出色：  更快更快 href =“ https://preview.itd.it/s4nw6eehq1me1.png？ Consistently top ranks across standard black-box optimization benchmarks from SigOpt evalset   全面的变量支持 库处理现代ML管道所需的参数类型的完整频谱：     连续变量（带有可选的日志样本示例）  分类变量（带有智能表示）  实用的ML应用程序 在我们对LightGBM HyperPoReter调谐的实验中，Marsopt在加利福尼亚州住房数据集上调谐，Marsopt表现出与诸如Optizizers之类的优化效果相比的令人鼓舞的结果。库有效地处理了简单的参数空间和更复杂的方案，涉及不同的增强类型，正则化参数和采样配置。    使用Marsopt很简单：  来自Marsopt Import Intimp ofimp ofimp ofimp otim in trim imptim impor numpy作为NP DEF目标（试验：试验：试验） - ＆GT; float：lr = auggest_float（; quot; leadmood; querat＆quot;，1e-4，1e-1，log = true）layers = auggest_int（num_layers＆quot; num_layers＆quort＆quort＆quotizer＆quotizer＆quort＆quort = auggest_catation.suggest_categorical; “ rmsprop”]）＃您的评估逻辑在此处回报分数研究=研究（方向=“最大化”）研究。  文档： https://marsopt.readthedocs.io/      algorithm： https://marsopt.readthedocs.io/en/latest/latest/algorithm.html   href =“ https://github.com/sibirbil/marsopt”&gt; https://github.com/sibirbil/marsopt     pypi： https://pypi.org/project/project/marsopt/      我对您的反馈感兴趣，并欢迎您有关实施或绩效特征的任何问题。提交由＆＃32; /u/u/zedeleyici3401     [link]    [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0vsct/r_marsopt_mixed_adaptive_random_search_for/</guid>
      <pubDate>Sat, 01 Mar 2025 09:30:51 GMT</pubDate>
    </item>
    <item>
      <title>[R]用于数学推理的自我奖励LLM：一个自主错误检测和校正的两阶段框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0tw4n/r_selfrewarding_llms_for_mathematical_reasoning_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文引入了一种自我奖励校正机制，用于改善语言模型中的数学推理。核心想法将自我评估与迭代校正结合在一起 - 该模型学会了评估自己的解决方案并修复其确定的错误。 主要技术点： - 两阶段架构：解决方案生成：自定义奖励 - 自定义奖励功能 - 既有答案正确性和推理质量既不存在的范围 - 否则范围的范围 - 否则范围的范围 - 否定范围 - 否定范围 - 误差 - 误差 - 误解 - 误差 - 误差 - 误差 - 误差 - 全面训练 关键结果： -  15-20％的数学任务的基准精确度提高-80％的错误检测成功率 - 在算术，代数和单词问题上的出色表现 - 与基本模型相比，最小的额外培训计算 - 与基本模型相比最小的额外培训计算 - 最有效的对问题的方法尤其需要多个 我认为该方法的价值更高，因此可以不断地启动一个信息。自我纠正机制似乎可以将不仅仅是数学问题概括到需要强大推理的其他领域。 我认为，这里的真正价值是朝着可以有效地验证自己的工作而不是仅仅产生答案的模型发展。这是建立更值得值得信赖的AI系统的重要步骤。 我看到的主要限制是在解决方案中过度自信的潜力，尽管蒙特卡洛验证有助于减轻这种情况。看到这与外部验证系统结合在一起会很有趣。  tldr：结合自我奖励和数学推理的迭代校正的新方法。模型学会检查并修复自己的工作，并通过强误检测获得15-20％的准确性提高。  完整的总结在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0tw4n/r_selfrewarding_llms_for_mathematical_reasoning_a/</guid>
      <pubDate>Sat, 01 Mar 2025 07:14:55 GMT</pubDate>
    </item>
    <item>
      <title>[d]“反向传播：差异规则[第3部分]的视觉解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0ez5y/d_visual_explanation_of_backpropagation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi，  i先前在此处共享了第1部分和第2部分：  第1部分： https://www.reddit.com/r/machinelearning/comments/1irs3gn/d_visal_explanation_of_backpropagation/   第2部分： https://www.reddit.com/r/machinelearning/comments/1iy0d47/d_visual_explanation_of_backpropagation_forward/     这是第3部分我在其中分享了如何使用计算图从scratch中得出差异规则。 xi（x）= x。我发现它很有趣，因此共享。 谢谢，  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/madiyar     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0ez5y/d_visual_explanation_of_backpropagation/</guid>
      <pubDate>Fri, 28 Feb 2025 18:42:46 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何写数学大型ML论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0efdm/d_how_do_you_write_math_heavy_ml_papers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在ICLR/neurips/icml上发表理论ML论文或数学繁重论文的人，您如何撰写数学繁重的论文？编写方法部分的策略是什么？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/antelopewilling2928     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0efdm/d_how_do_you_write_math_heavy_ml_papers/</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:43 GMT</pubDate>
    </item>
    <item>
      <title>[d]减少随机森林训练时间</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j07uh4/d_reduce_random_forest_training_time/</link>
      <description><![CDATA[Hi everyone, I wonder when running a backtest on AWS with a 64 cores machine how would you decrease the training time ? The dataset isn’t very big but when running on my cloud it could take up to 1 day to backtest it. I’m curious to see what kind of optimisation can be made.  nb：平行编程已经在Python代码上使用，并且应该不变的树的数量。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/konni_algo     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j07uh4/d_reduce_random_forest_training_time/</guid>
      <pubDate>Fri, 28 Feb 2025 13:38:06 GMT</pubDate>
    </item>
    <item>
      <title>[R]动态词汇课程学习提高LLM训练效率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j04bwb/r_dynamic_vocabulary_curriculum_learning_improves/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了一种新颖的LLM预培训方法，该方法使用课程学习进行词汇扩展。该模型没有从一开始就开始词汇进行完整的词汇训练，而是从较小的高频词汇开始，在训练过程中逐渐扩展。 关键技术要点： - 从〜5k最频繁的代币开始，最常见的代币，扩展到完整的词汇（〜50k词）（〜50k代币），而不是训练 - 基于模型的扩展 - 维持型号的时间表 - 维护时间表的时间表 - 维持时间表的时间表 - 维持时间表的时间表，以供应量的时间表，以实现计时量的时间表，以验证时间表 - 维持时间表的时间表，以供应量表。在早期阶段的未使用令牌 - 在125m到7b参数之间进行测试的模型测试 结果：-25％的总训练时间减少了总训练时间以达到等效性能 - 在早期训练中没有明显的模型使LLM培训更容易被计算资源有限的研究人员访问。用较小的初始词汇进行有效训练的能力可以在早期开发阶段进行更多的实验和迭代。 我认为最有趣的方面是如何挑战模型从开始时需要完全词汇的假设。结果表明，首先构建共同令牌的有力表示可能实际上可能对整体模型开发有益。 我看到的主要限制是该方法主要是在英语模型上测试的。需要进行更多的研究来验证具有不同结构特征的多语言模型或语言的益处。  tldr：LLM期间LLM预训练期间进行的循序渐进的词汇扩展可将培训时间降低25％，而不会损害模型质量，而不会损害课程学习，这表明课程学习可以使LLM培训更有效。 href =“ https://aimodels.fyi/papers/arxiv/scaling-llm-pre-training-training-vocabulary-curriculum”&gt;完整的摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j04bwb/r_dynamic_vocabulary_curriculum_learning_improves/</guid>
      <pubDate>Fri, 28 Feb 2025 10:03:27 GMT</pubDate>
    </item>
    <item>
      <title>[R]无训练的色度键含量含量生成扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j00bbs/r_trainingfree_chroma_key_content_generation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们很高兴地宣布我们的论文“ tkg-dm：无训练的色彩键含量含量的含量生成扩散模型” 已被接受 cvpr 2025！ href =“ https://arxiv.org/abs/2411.15580”&gt; https://arxiv.org/abs/2411.15580    &gt;              dr：我们引入了 tkg-dm “ difunige difful&gt; difudion difful&gt; difudy diffff infort   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/maleficent_stay_7737      [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j00bbs/r_trainingfree_chroma_key_content_generation/</guid>
      <pubDate>Fri, 28 Feb 2025 05:18:11 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子以便在此处发布的新帖子的人！ 线程将活着直到下一个，因此请继续发布标题的日期之后。 感谢大家在上一个线程中回答了上一个线程中的问题！  &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iwdbgs/d_simple_questions_thread/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 23 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>