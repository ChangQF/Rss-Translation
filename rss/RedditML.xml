<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Sat, 27 Jul 2024 21:12:43 GMT</lastBuildDate>
    <item>
      <title>LiveBench 与现有的大规模 LLM 基准测试相比如何？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edk0ca/how_does_livebench_compare_to_existing_large/</link>
      <description><![CDATA[想知道社区对新的 LLM 基准 LiveBench 有何看法。您认为它与其他一些大型基准（例如 HELM、ChatBot Arena 和 Open LLM Leaderboard）相比如何？    提交人    /u/Penfever   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edk0ca/how_does_livebench_compare_to_existing_large/</guid>
      <pubDate>Sat, 27 Jul 2024 16:14:10 GMT</pubDate>
    </item>
    <item>
      <title>[R][P] 为 Vision Transformer 实现 GQA 检查点转换</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edjj1m/rp_implementing_gqa_checkpoint_conversion_for/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edjj1m/rp_implementing_gqa_checkpoint_conversion_for/</guid>
      <pubDate>Sat, 27 Jul 2024 15:53:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Concrete ML 和完全同态加密的端到端加密 23andMe 基因测试应用程序。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edir29/p_endtoend_encrypted_23andme_genetic_testing/</link>
      <description><![CDATA[我们最近收到了一些外部贡献，展示了如何使用 Zama 库创建端到端加密的基因检测应用程序，例如使用完全同态加密 (FHE) 的 23andMe。这篇博文展示了高级加密技术的集成，以确保在进行基因分析时保护隐私。这是一个重要的里程碑，因为它表明我们现在可以使用 FHE 在大约 5 分钟内预测加密的 DNA 祖先。 在此处阅读完整的博客文章：使用 Concrete-ML 和完全同态加密构建端到端加密的 23andMe 基因检测应用程序 很高兴回答任何问题或帮助任何有兴趣使用我们的工具构建安全 ML 应用程序的人！     由    /u/fd0r 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edir29/p_endtoend_encrypted_23andme_genetic_testing/</guid>
      <pubDate>Sat, 27 Jul 2024 15:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] 这是我们基于神经网络的快速漫射房间脉冲响应发生器（FAST-RIR）的官方实现，用于为给定的声学环境生成房间脉冲响应（RIR）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edibkx/r_this_is_the_official_implementation_of_our/</link>
      <description><![CDATA[        提交人    /u/Snoo63916   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edibkx/r_this_is_the_official_implementation_of_our/</guid>
      <pubDate>Sat, 27 Jul 2024 14:59:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要帮助起草数据偏见演讲的内容。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edh61n/d_help_required_in_drafting_the_content_for_a/</link>
      <description><![CDATA[需要帮助起草关于数据偏见的一般性演讲内容 需要帮助起草关于数据偏见的演讲内容 我是一名在零售领域工作的数据科学家。我必须在公司进行一般性演讲（包括技术人员和非技术人员）。我选择的主题是数据偏见，分配的时间为 15 分钟。以下是我创建的草稿。我的主要主张是演讲应该非常简单，每个人都应该理解（我知道！！！）。所以我不想解释非常复杂的话题，因为人们来自不同的背景。我想要非常受欢迎/有趣的例子，以便吸引观众。我不打算解释任何数学术语。 非常感谢您的建议。 • 从读者文摘民意调查示例开始 • 解释什么是抽样？为什么我们需要抽样？不同类型的偏见 • 解释什么是选择偏见。然后详细讨论两种选择偏见，即抽样偏见和幸存者偏见 ○ 抽样偏见 § 读者文摘民意调查 § 加洛普调查 § 减轻抽样偏见的技术 ○ 幸存者偏见 §飞机示例     提交人    /u/overwhelmed_coconut   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edh61n/d_help_required_in_drafting_the_content_for_a/</guid>
      <pubDate>Sat, 27 Jul 2024 14:06:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我创建了 Promptimizer——一个基于遗传算法 (GA) 的提示优化框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edgtft/d_i_created_promptimizer_a_genetic_algorithm/</link>
      <description><![CDATA[        由    /u/NextgenAITrading 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edgtft/d_i_created_promptimizer_a_genetic_algorithm/</guid>
      <pubDate>Sat, 27 Jul 2024 13:49:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找处理对图像中两个对象之间是否存在直接路径进行分类的问题的学术论文。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edevbz/r_looking_for_academic_papers_that_deal_with_the/</link>
      <description><![CDATA[大家好， 我目前正在做一个项目，我尝试使用 CNN 根据 2 个选定节点是否连接对图形图像进行分类。我在过度拟合方面有点挣扎，想探索一些研究人员可能之前尝试过的其他策略。我很感激任何帮助或建议！如果我的解释不够深入，也可以随时提问。    提交人    /u/Dualweed   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edevbz/r_looking_for_academic_papers_that_deal_with_the/</guid>
      <pubDate>Sat, 27 Jul 2024 12:08:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是一个内存绑定代码吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ede1gl/d_is_this_a_memory_bound_code/</link>
      <description><![CDATA[我有一个推理代码，我保存了一些性能指标，然后更改了与输入数据维度相关的某个参数。具体来说，我将维度除以 2。 现在，在 gpu 上，计算性能提高了 20%。然而，有趣的是，在 cpu 上，性能提高了 300%。 我想知道为什么我在 cpu 上获得了如此显着的改进。虽然我缺乏这方面的知识，但我认为我的代码在 cpu 上运行时可能受到内存限制。你对此有何看法？ 此外，我与此主题相关的文章或论文将不胜感激。    提交人    /u/Top-Establishment545   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ede1gl/d_is_this_a_memory_bound_code/</guid>
      <pubDate>Sat, 27 Jul 2024 11:19:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama3.1 如何利用词汇表中仅有的 28k 个额外标记来支持多种语言？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edct9i/d_how_does_llama31_support_multiple_languages/</link>
      <description><![CDATA[根据 Llama3.1 论文，词汇表包含 128k 个标记，其中 100k 个专用于英语，28k 个分配给非英语语言。鉴于韩语、中文和日语等语言不使用 26 个字母的拉丁字母表并且可以有数百万个唯一字符，如何仅用 28k 个标记就涵盖这些语言？标记化是基于 Unicode 吗？    提交人    /u/Financial_Air5256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edct9i/d_how_does_llama31_support_multiple_languages/</guid>
      <pubDate>Sat, 27 Jul 2024 09:59:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检索增强生成的替代方案是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edbg0h/d_whats_the_alternative_to_retrieval_augmented/</link>
      <description><![CDATA[看来 RAG 是业界问答系统的事实标准。有什么替代方案吗？    提交人    /u/clocker2004   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edbg0h/d_whats_the_alternative_to_retrieval_augmented/</guid>
      <pubDate>Sat, 27 Jul 2024 08:21:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 这是混响语音到房间脉冲响应估计器的官方实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edao96/r_this_is_the_official_implementation_of/</link>
      <description><![CDATA[        由    /u/Snoo63916  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edao96/r_this_is_the_official_implementation_of/</guid>
      <pubDate>Sat, 27 Jul 2024 07:27:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 按比例拆分具有多个目标列的数据框</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ed0qpl/p_proportionately_split_dataframe_with_multiple/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ed0qpl/p_proportionately_split_dataframe_with_multiple/</guid>
      <pubDate>Fri, 26 Jul 2024 22:24:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 通过删除文本模块和交叉注意层，是否可以使用 Stable Diffusion v1 作为特征提取器？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ecwonw/d_is_it_possible_to_use_stable_diffusion_v1_as_a/</link>
      <description><![CDATA[嗨，我对利用稳定扩散 v1 模型作为下游任务的特征提取器感兴趣。具体来说，我想在不涉及文本提示机制的情况下做到这一点。为了实现这一点，我正在考虑：  消除文本编码器模块 删除 UNet 中的交叉注意层  这是一种可行的方法吗？有人尝试过以这种方式使用稳定扩散吗？这种修改的挑战或局限性是什么？ 我可以找到使用 SDv1 进行下游任务以及基本文本提示的论文，但没有一篇论文尝试在不使用文本提示机制的情况下做到这一点。否则，我正在考虑使用 DINOv2。    提交人    /u/rustyelectron   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ecwonw/d_is_it_possible_to_use_stable_diffusion_v1_as_a/</guid>
      <pubDate>Fri, 26 Jul 2024 19:28:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每个注释者都有一本指南，但审阅者没有</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ecnxng/d_every_annotator_has_a_guidebook_but_the/</link>
      <description><![CDATA[我于 6 月份提交了 ACL 滚动评审，发现评审员的评分非常主观。 虽然 ACL 委员会对一些基本的评审指南有说明，但缺少一个初步测试让评审员明确展示评估标准。也许我们应该提供一些论文评分示例，以促使评审员进行更客观的评审？或者在他们评审之前建立一个测试，以确保他们完全理解健全性和整体评估的含义，而不是根据他们的个人兴趣随意给出一些分数。    提交人    /u/Spico197   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ecnxng/d_every_annotator_has_a_guidebook_but_the/</guid>
      <pubDate>Fri, 26 Jul 2024 13:20:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 21 Jul 2024 02:15:09 GMT</pubDate>
    </item>
    </channel>
</rss>