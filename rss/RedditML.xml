<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 12 Dec 2023 12:26:01 GMT</lastBuildDate>
    <item>
      <title>[D] 我实施了 10 多个 LLM 评估指标，因此您不必这样做</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gkk17/d_i_implemented_10_llm_evaluation_metrics_so_you/</link>
      <description><![CDATA[我已经构建了一段时间的开源项目，您可以在此处查看指标列表：https://docs.confident-ai.com/docs/metrics-introduction，这是存储库：https://github.com/confident-ai/deepeval 让我知道你的想法！   由   提交/u/Ok_Constant_9886   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gkk17/d_i_implemented_10_llm_evaluation_metrics_so_you/</guid>
      <pubDate>Tue, 12 Dec 2023 12:14:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] UniRepLKNet：大内核 CNN 统一多模态，ImageNet 88%，全球天气预报中的 SOTA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gihit/r_unireplknet_largekernel_cnn_unifies_multi/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gihit/r_unireplknet_largekernel_cnn_unifies_multi/</guid>
      <pubDate>Tue, 12 Dec 2023 09:58:47 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]如何从新手走向搭建LLM代理进行生产？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ghvax/discussion_how_do_i_go_from_being_a_novice_to/</link>
      <description><![CDATA[我拥有数据科学硕士学位，并且对传统机器学习模型有一些经验。 但是，我感到不知所措关于法学硕士和人工智能领域发生的一切的大量知识。我感到迷失，我想跟上最新的技术。  如何从初学者过渡到能够理解和构建 LLM 申请？  任何帮助或见解表示赞赏。谢谢！   由   提交 /u/reborn_tonight   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ghvax/discussion_how_do_i_go_from_being_a_novice_to/</guid>
      <pubDate>Tue, 12 Dec 2023 09:12:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果是 LLM，repeatation_penlaity 存储在哪里？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ghryp/d_in_case_of_llm_where_is_repetition_penlaity/</link>
      <description><![CDATA[如果是 LLM，repetition_penality 等参数存储在哪里？ LLM 如何知道它已经重复了响应。   由   提交/u/The_artist_999   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ghryp/d_in_case_of_llm_where_is_repetition_penlaity/</guid>
      <pubDate>Tue, 12 Dec 2023 09:05:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在测试集中的文本（无标签）上对 LM 进行了预训练，然后使用该模型在训练文本（有标签）上训练分类器。最后，我在同一测试集上进行评估。测试集的准确性是否过于乐观？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ghcqg/d_i_pretrained_an_lm_on_texts_from_the_test_set/</link>
      <description><![CDATA[我所说的过于乐观，是指准确度比您在生产中看到的要高。 假设 LM 不是已经对您的任何分类文本进行了预训练。 这不是一个技巧问题或 ML 测验。我想了解人们对此程序的感受。 背景 这里是背景信息，您可能会或可能不会使用它来告知您的答案。 说LM 类似于 BERT 或 GPT。 在训练分类器之前对来自训练数据集的分类文本进行预训练被称为“任务自适应预训练”。 （本论文的第 4 节）。从理论上和经验上讲，如果学习任务是因果关系，则此过程可以提高分类性能如果学习任务是因果性的。请注意，在这些论文中，预训练是在训练文本上进行的，而不是在测试文本上进行的。民意调查问题是询问您是否认为对测试文本进行预训练不公平。 查看民意调查&lt; /p&gt;   由   提交 /u/KD_A   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ghcqg/d_i_pretrained_an_lm_on_texts_from_the_test_set/</guid>
      <pubDate>Tue, 12 Dec 2023 08:32:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 具有硬件高效训练功能的门控线性注意力变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gglm1/r_gated_linear_attention_transformers_with/</link>
      <description><![CDATA[      论文： https://arxiv.org/abs/2312.06635  代码： https://github.com/sustcsonglin/ated_linear_attention_layer  &lt;强&gt;摘要：  具有线性注意力的Transformers允许高效的并行训练，但可以同时被表示为具有2D（矩阵值）隐藏状态的RNN，从而享受线性（与相对于输出长度）推理复杂性。最近的工作，如 RetNet (Sun et al., 2023) 和 TransNormerLLM (Qin et al., 2023a) 观察到，在加性 RNN 更新规则中添加全局衰减项极大地提高了性能，有时在训练时优于具有 softmax 注意力的标准 Transformer。规模。在这项工作中，我们证明添加数据相关的门控机制可以进一步提高性能。我们推导了这种门控线性注意力层的并行形式，可以实现高效的训练。然而，这种并行形式的简单、数值稳定的实现需要在对数空间中进行广义矩阵乘法以实现数值稳定性，因此无法利用针对标准矩阵乘法进行优化的现代 GPU 上的张量核心。我们开发了并行形式的硬件高效版本，它仍然可以通过序列块上的块并行计算来利用张量核心。中等规模语言建模实验（在 15B 令牌上训练的 340M 参数模型，在 100B 令牌上训练的 1.3B 参数模型）表明，门控线性注意力 (GLA) Transformer 的性能与强大的 LLaMA 架构 Transformer 基线相比具有竞争力（Touvron 等人） ., 2023) 以及 Mamba (Gu &amp; Dao, 2023)，这是最近引入的具有数据依赖状态转换机制的状态空间模型。就训练速度而言，我们基于 Triton 的实现在常规 2048 训练长度设置下的性能与 CUDA 优化的 FlashAttention-2（Dao，2023）相当，而在超过 4096 的较长序列上训练时，其性能优于 FlashAttention-2。  性能 https ://preview.redd.it/h45j3fanht5c1.png?width=1802&amp;format=png&amp;auto=webp&amp;s=329b30428fd790424782132c8454d26c8d0c7808  &amp;# 32；由   提交/u/Emergency_Shoulder27   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gglm1/r_gated_linear_attention_transformers_with/</guid>
      <pubDate>Tue, 12 Dec 2023 07:37:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 开放环境下协作多智能体强化学习进展综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gefag/r_a_survey_of_progress_on_cooperative_multiagent/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.01058 摘要：  多智能体强化学习（MARL）在近年来，在各个领域都取得了进步。具体来说，合作式 MARL 专注于训练一组智能体以合作方式完成单个智能体难以处理的任务。它在路径规划、自动驾驶、主动电压控制、动态算法配置等应用中表现出了巨大的潜力。协同MARL领域的研究热点之一是如何提高系统的协调效率，而研究工作主要在简单、静态、封闭的环境设置中进行。为了促进人工智能在现实世界中的应用，一些研究已经开始探索开放环境中的多智能体协调。这些工作在探索和研究重要因素可能发生变化的环境方面取得了进展。然而主流工作仍缺乏对研究方向的全面回顾。本文从强化学习的概念出发，随后介绍了多智能体系统（MAS）、协作MARL、典型方法和测试环境。然后，我们总结了合作MARL从封闭环境到开放环境的研究工作，提炼出多个研究方向，并介绍了典型工作。最后，我们总结了当前研究的优缺点，并对开放环境下合作MARL的未来发展方向和研究问题进行了展望。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gefag/r_a_survey_of_progress_on_cooperative_multiagent/</guid>
      <pubDate>Tue, 12 Dec 2023 05:18:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 和 ICML 以及类似场所的作者 - 您的数学背景有多深？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g85lx/d_authors_in_neurips_and_icml_and_similar_venues/</link>
      <description><![CDATA[你好， 我正在尝试了解什么样的数学背景准备足以在顶级场所进行可发表的研究. 是微积分、线性代数、工程级概率&amp;统计和优化足够了吗？ 我所说的足够，是指您必须了解的最低限度，并且随着您的学习，您会学到更多东西遇到它们或解决问题（边做边学），而不必先准备必要的背景，然后再深入研究。 我的主要问题是 - 我在什么时候说让我们直接开始研究并即时找出我不知道的事情VS首先学习必要的背景然后继续。我很熟悉 - 不强，但在本科时学过这些课程，但很大程度上忘记了许多重要概念。 数学中的传统方法（如 MathOverflow 人员所建议的）不涉及任何内容缺乏解决数学课本练习以掌握数学的能力。这在很大程度上是不切实际/不可行的，并且将永远阻碍我实际的研究进展。 一个并行问题也是 - 你们如何学习你们不学的数学？不知道吗？你真的像数学系的人一样解决教科书上的问题吗？或者只是理解高层图片和关键中心思想，而不关注围绕它的证明或十几个定理？ 非常感谢来自 ML 领域的作者的任何帮助。  请仅当您是机器学习研究人员或来自学术界时才发帖:)。 非常感谢！   由   提交/u/gobraming5  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g85lx/d_authors_in_neurips_and_icml_and_similar_venues/</guid>
      <pubDate>Mon, 11 Dec 2023 23:54:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] ChatGPT 安全吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g3a45/p_how_safe_is_chatgpt/</link>
      <description><![CDATA[这个周末我花了一些时间玩 LLaMA Guard，这是 Meta 精心调整的 LLaMA-7B 模型，可让您在生成 AI 周围添加护栏。我录制了一个快速演示，展示了它的作用以及如何使用它。 最好的部分是，您可以用它定义自己的“安全分类法”——针对人类之间的安全交互和不安全交互的自定义​​策略（提示）和 AI（响应）。 我想看看与 OpenAI 的 ChatGPT 进行的对话有多“安全”，所以我运行了一堆提示（无害和不恰当的混合）并要求 LLaMA Guard将交互分为安全/不安全。 我从练习中得到的主要收获：  OpenAI 在为其模型添加护栏方面做得很好。 LLaMA Guard 帮助证实了这一点。 这真的很酷，因为我可能有一套非常具体的策略，我想在模型附带的标准护栏之上执行。 LLaMA Guard 使这成为可能。 这种模型链接 - 将 OpenAI 模型的响应传递到 LLaMA 正变得越来越普遍，我认为在不久的将来我们将拥有更加复杂的管道。它有助于拥有一致的界面来将此多模型管道存储为 aiconfig：https://github.com/lastmile-ai/ aiconfig.  自己尝试一下：  GitHub：https://github.com/lastmile-ai/aiconfig/tree/main/cookbooks/LLaMA-Guard YouTube： https://www.youtube.com/watch?v=XxggqoqIVdg  &lt; /div&gt;  由   提交 /u/sarmad-q   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g3a45/p_how_safe_is_chatgpt/</guid>
      <pubDate>Mon, 11 Dec 2023 20:27:37 GMT</pubDate>
    </item>
    <item>
      <title>节日快乐！这是 100% 免费的大型语言模型路线图！ [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g21av/happy_holidays_here_is_your_100_free_large/</link>
      <description><![CDATA[      感谢您最近几天对我的法学硕士大纲提供反馈的支持。本大纲是关于如何学习有关大型语言模型的最先进内容的路线图。它建立在我在 AT&amp;T 和丰田所做的工作的基础上。它还建立在我在公司之外独立完成的大量工作的基础上。  轮廓很扎实，作为我回馈社区的方式，我将其免费赠送。是的，没有烦人的电子邮件注册。没有噱头。 “免费试用”没有条纹页面。大纲末尾没有要求您购买佛罗里达州的分时度假。它只是一个 zip 文件的链接，其中包含大纲和​​示例代码。  这是它的工作原理。首先，你需要了解Python。如果你不知道，那就在 Google 上查找如何学习 Python。其次，这是一个大纲，您需要查看每个部分，浏览链接，并在继续之前真正消化材料。三是轮廓各部分密集；没有任何废话，您可能需要多次浏览大纲。 该大纲旨在帮助您开始学习 Pytorch，它提供了如何进行分类的代码示例带有句子嵌入，它还有另一个如何在 colab 中运行 Zephyr 的代码示例。这个大纲花了我几天的时间来整理，但它确实代表了过去一年的东西。 此外，这不是一个关于微调语言模型的大纲。这不是关于 Mistral MoE 的讨论，也不是关于运行多个 GPU 的讨论。它是为拥有笔记本电脑并想要学习的人设计的。 此外，将此大纲视为一份礼物。其提供时不提供保证或任何类型的保证。  如果您喜欢这个大纲，我恳求您点击分享按钮并与某人分享。也许这也会对他们有帮助。如果您喜欢这个大纲，请将其作为为世界做好事的动力，并与社区分享您所做的事情。 好的，这是大纲。  https://drive.google.com/file/d /1F9-bTmt5MSclChudLfqZh35EeJhpKaGD/view?usp=drive_link 如果您有任何疑问，请在下面的部分中发表评论。如果问题更具体于您正在做的事情（并且不属于一般对话的一部分），请随时在 Reddit 聊天中向我提问。  ​ https://preview.redd.it/lcq80rwdxp5c1.png?width=549&amp;format=png&amp;auto=webp&amp;s=a111f3101d4e8e232dc7e130b86bda0764dc6eb0  ​ https://preview.redd.it /0sdzc58fxp5c1.png?width=547&amp;format=png&amp;auto=webp&amp;s=96daf4c76f7a913cbba041499429be777ff69ff8   由   提交 /u/whiteowled   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g21av/happy_holidays_here_is_your_100_free_large/</guid>
      <pubDate>Mon, 11 Dec 2023 19:37:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] 具有技能课程的分层强化学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g0o35/p_hierarchical_reinforcement_learning_with_a/</link>
      <description><![CDATA[查看我们制作的关于使用我们的框架学习分层强化学习技能的教程！ https://docs.agilerl.com/en/latest/tutorials/skills/index.html&lt; /a&gt; 您认为这与允许代理通过不提供课程来自行发现做某事的最佳方式之间有何平衡？    由   提交 /u/nicku_a   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g0o35/p_hierarchical_reinforcement_learning_with_a/</guid>
      <pubDate>Mon, 11 Dec 2023 18:42:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] BioCLIP，生物学视觉基础模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g0fro/p_bioclip_a_vision_foundation_model_for_biology/</link>
      <description><![CDATA[   /u/Qua5imodo  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g0fro/p_bioclip_a_vision_foundation_model_for_biology/</guid>
      <pubDate>Mon, 11 Dec 2023 18:32:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何阅读和理解Einops表达式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g01bv/r_how_to_read_and_understand_einops_expressions/</link>
      <description><![CDATA[这是我目前对 einops 的了解：  einops 代表爱因斯坦启发的运算符号。 符号大致受到爱因斯坦求和（特别是 numpy.einsum 运算）的启发。 h = 高度，w = 宽度，c = 通道（颜色），b = 批次 左侧是输入形状。左侧是输出形状。 括号中的字母相乘。 einops.rearrange 包括转置（轴排列）、重塑（视图）、挤压、取消挤压、堆叠等功能，连接和其他操作。  我不明白：  所有操作元素是什么？我上面遗漏了什么吗？  我如何阅读正在进行的操作？ （即我如何知道图像将被压缩或分割成不同的图像？） 操作中顺序重要吗？ （即‘wh c -&gt; (w h) c’与‘h w c -&gt; (h w) c’不同吗？） 为什么有些元素出现在运算中而另一些则没有？ （即“h w c -&gt; (h w) c”与“h w -&gt; (h w)”不同吗？）  我试图理解的 einops.rearrange 操作示例：   &#39;b f h w c -&gt; (b f) c h w’ ‘(b f) e -&gt; b f e’ ‘br r -&gt; br ()’ ‘b s e -&gt; (b s) e’ ‘b s -&gt; (b s)&#39;  之前的研究参考：  https: //einops.rocks/api/rearrange/ https://openreview.net/pdf ?id=oapKSVM2bcj https://youtu.be/ll1BlfYd4mU?si=BmCVibyEifrZhiXC https://youtu.be/xGy75Pjsqzo?si=GiaxqN4vSX9_uTtL    由   提交 /u/Joe_The_Armadillo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g01bv/r_how_to_read_and_understand_einops_expressions/</guid>
      <pubDate>Mon, 11 Dec 2023 17:59:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] SparQ Attention：带宽高效的 LLM 推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ftsaq/r_sparq_attention_bandwidthefficient_llm_inference/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.04985 摘要：  生成式大语言模型（LLM）开辟了许多新颖的可能性，但由于其巨大的计算要求，它们的普遍使用仍然具有挑战性。一些最有用的应用程序需要一次处理大量样本并使用长上下文，这两者都会显着增加模型的内存通信负载。我们引入了SparQ Attention，这是一种通过选择性获取缓存历史记录来减少注意力块内的内存带宽需求，从而提高 LLM 推理吞吐量的技术。我们提出的技术可以在推理过程中直接应用于现成的法学硕士，无需对预训练设置进行任何修改或进行额外的微调。我们通过在各种下游任务上评估 Llama 2 和 Pythia 模型，展示了 SparQ Attention 如何将注意力内存带宽要求降低多达八倍，而不会损失任何准确性。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ftsaq/r_sparq_attention_bandwidthefficient_llm_inference/</guid>
      <pubDate>Mon, 11 Dec 2023 12:47:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>