<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Fri, 09 Aug 2024 03:18:08 GMT</lastBuildDate>
    <item>
      <title>[D] 泰卢固语的 ASR 效果良好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eno3bf/d_good_asr_for_telugu/</link>
      <description><![CDATA[我们正在努力寻找适合泰卢固语音频的良好 ASR。尝试过 Google Speech to Text 和 whisper-large-v3，但 WER 超过 40%。确切的用例是转录和分析通话录音，这些录音通常混合了泰卢固语和英语。  提前感谢您的帮助 🙏    提交人    /u/BitAffectionate4586   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eno3bf/d_good_asr_for_telugu/</guid>
      <pubDate>Fri, 09 Aug 2024 02:11:16 GMT</pubDate>
    </item>
    <item>
      <title>[d] ReFT 的实际示例：14 分钟内在 Llama3 上完成表征微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enk8wm/d_practical_example_of_reft_representation/</link>
      <description><![CDATA[几周前，Arxiv ReFT 论文第一作者郑轩吴与 Oxen.AI 首席执行官 Greg Schoeninger 合作，深入探讨了 ReFT：表示微调。 在明天（星期五）的 AI Water Cooler 中，Oxen 实习生 Eric 将介绍： &quot;我如何在 14 分钟内使用 ReFT 对 Llama3 进行微调&quot; ReFT 的 TLDR：不是通过参数进行微调，而是在隐藏状态中插入表示来指导模型。 Eric 将展示早期 Arxiv Dive 的实际实现。 有用的细节：  AI Water Cooler 是深度技术不太正式、未经记录的空间 8 月 9 日星期五，太平洋时间上午 10:00 定期日历邀请：https://oxen.ai/community YouTube https://youtu.be/to2oKwnknUk?si=LmMMYxoryOn0UCwh Arxiv 论文链接：https://arxiv.org/pdf/2404.03592     提交人    /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enk8wm/d_practical_example_of_reft_representation/</guid>
      <pubDate>Thu, 08 Aug 2024 23:10:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关 Perplexity Sonar 模型的深入信息：系统消息、上下文处理和 API 限制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enk3mw/d_seeking_indepth_information_on_perplexitys/</link>
      <description><![CDATA[除了 Perplexity 文档中提供的内容外，是否还有其他关于 Sonar 模型的文档？ 我正在寻找有关“系统消息”、提示和/或第一个用户请求之间的行为差​​异的更多信息。据我了解，查询是基于“用户”消息生成的，查询生成会忽略“系统”消息。那么这个“系统”消息的用途到底是什么？这些示例通常使用简短的 3-4 个单词的短语，但 Sonar 模型是否支持更复杂的系统指令（类似于它们所训练的模型）？ 此外，在线模型如何处理多轮对话？查询生成和 RAG 使用什么上下文？我理解这些模型适用于单轮交互，而“聊天”版本可用于多轮对话。 这引出了我关于上下文长度的问题。在线模型声称拥有 128K 上下文，但这在实践中似乎无法实现。如果用户消息太长，查询生成效率会降低，检索到的相关结果也会减少。即使多轮聊天也无法实现更高的上下文，因为质量会显著下降。 值得注意的是，作为“源”提供给模型的标记数量通常在全球范围内在 2-3K 范围内，但通常会少得多，具体取决于问题的复杂性（通过 API）。 有人对这些问题有见解吗？工作人员可以给我提供更详细的信息吗？ 提前谢谢！    提交人    /u/Distinct-Target7503   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enk3mw/d_seeking_indepth_information_on_perplexitys/</guid>
      <pubDate>Thu, 08 Aug 2024 23:03:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI：API 中的结构化输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1endf5w/d_openai_structured_outputs_in_the_api/</link>
      <description><![CDATA[https://openai.com/index/introducing-structured-outputs-in-the-api/ 只是好奇，为什么这是一件大事？你看到任何用例了吗？    提交人    /u/dmpetrov   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1endf5w/d_openai_structured_outputs_in_the_api/</guid>
      <pubDate>Thu, 08 Aug 2024 18:27:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] DistilBERT 基础多语言（大小写）葡萄牙语</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en74uf/d_distilbert_base_multilingual_cased_for/</link>
      <description><![CDATA[有人用过 DistilBERT 基础多语言（大小写）来处理葡萄牙语吗？如果是，你的结果如何？它好用吗？ 提前致谢。    提交人    /u/mr_house7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en74uf/d_distilbert_base_multilingual_cased_for/</guid>
      <pubDate>Thu, 08 Aug 2024 14:16:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] FlexAttention：PyTorch 的灵活性与 FlashAttention 的性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</link>
      <description><![CDATA[https://pytorch.org/blog/flexattention/    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</guid>
      <pubDate>Thu, 08 Aug 2024 13:49:55 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 我需要什么数学背景才能阅读 Le Cam 的《充分性和近似充分性》论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en55pb/research_what_mathematical_background_do_i_need/</link>
      <description><![CDATA[嗨， 我是一名统计学家，出于研究目的，我想阅读 Le Cam 提到的论文。我遇到的困难是它使用了诸如向量格、正正则化线性函数、格对偶等术语。 因此，我的问题是：我需要什么样的数学先决条件才能阅读此类论文？ 我做过标准线性代数、实分析（单变量和多变量）、测度论、概率论内容、一些点集拓扑，但从未见过这样的对象，所以我认为这可能与抽象代数有关，但我不知道从哪里开始才能读懂这篇文章。 任何帮助都将不胜感激。谢谢！   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en55pb/research_what_mathematical_background_do_i_need/</guid>
      <pubDate>Thu, 08 Aug 2024 12:52:00 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何使用学习率来匹配论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emxx6a/d_how_to_use_learning_rate_to_match_papers/</link>
      <description><![CDATA[你好！ 我正在复现一些论文，但我一直面临训练不稳定的问题，除非我降低论文中的学习率，因为在几篇论文中我发现我可能是错的。 假设我们有一篇论文，使用 M GPU 以批量大小 N（每个 GPU）训练网络，以学习率为 LR 进行训练。训练几乎总是使用 float16 和 adam/adamw。我正在使用 pytorch amp 进行混合精度训练。 大多数论文要求我正在训练（TTS 任务）在 16/32 gpu 上进行训练，但我不想进行分布式训练，我只使用更快的 GPU 进行 2 倍、4 倍或 8 倍训练，但使用梯度累积（G）。 不同的框架对如何在多 GPU 环境中指定学习率的定义不同。 我现在正在使用 Accelerate，它建议将学习率乘以使用的 GPU 数量，但不清楚如何处理梯度累积以及论文最初如何定义学习率。 我的选择是：  LR - 按原样使用 LR * M - 乘以论文中原始 GPU 的数量 LR * M / G - 乘以不使用梯度累积的实际 GPU 数量 LR * G - 乘以按梯度累积次数  现在我已经尝试了#3，但是梯度爆炸，我除以二，它通常是稳定的，但它与任何其他公式都不匹配。 另外，不清楚论文中使用了什么框架（论文主要来自 Meta 和 Microsoft），这可能会影响 LR 不匹配。    提交人    /u/stevekite   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emxx6a/d_how_to_use_learning_rate_to_match_papers/</guid>
      <pubDate>Thu, 08 Aug 2024 05:27:50 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 多模式人工智能聊天机器人令人费解的失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emi095/research_the_puzzling_failure_of_multimodal_ai/</link>
      <description><![CDATA[      https://preview.redd.it/ummnvenf1ahd1.png?width=2592&amp;format=png&amp;auto=webp&amp;s=7115ba5de026ada17b0636ec2fa3c3151b3e5eb6 GPT-4o 和 Gemini 等聊天机器人模型在理解图像和文本方面表现出了令人印象深刻的能力。然而，它们是否能模仿人类的一般智力和推理能力尚不清楚。为此，PuzzleVQA 是多模式拼图的新基准，用于探索当前模型的极限。如上所示，即使是 GPT-4V 这样的模型也很难理解儿童可以掌握的简单抽象模式。 https://preview.redd.it/7l5fmuys1ahd1.png?width=2716&amp;format=png&amp;auto=webp&amp;s=337118dbc55230637cec1b08b90ae943746ddbb0 尽管谜题看似简单，但我们观察到当前多模态 AI 模型的表现却出奇地差。值得注意的是，与人类的表现仍然存在巨大差距。因此，自然而然地出现了一个问题：是什么导致了模型的失败？为了回答这个问题，我们进行了瓶颈分析，逐步为模型提供真实“提示”，例如用于感知或推理解释的图像标题。如上所示，我们发现领先的模型在视觉感知和归纳推理方面面临关键挑战。这意味着他们无法准确地感知图像中的物体，并且在识别正确的模式方面也很差。 https://arxiv.org/abs/2403.13315    提交人    /u/chiayewken   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emi095/research_the_puzzling_failure_of_multimodal_ai/</guid>
      <pubDate>Wed, 07 Aug 2024 17:33:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有一个适合进行通用智能开发技术讨论的社区？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emhuwa/d_is_there_an_appropriate_community_for_technical/</link>
      <description><![CDATA[确认该帖子没有讨论 AGI，版主可以删除它。我知道与 AGI 相关的帖子应该直接发送到 r/singularity，但 reddit 似乎主要充斥着炒作和哲学化新闻文章的非技术性帖子。我认为在 ML 领域有很多关于技术方法、问题和研究的有效讨论，以创建通用智能，例如脉冲网络、进化算法、记忆增强网络、RL 等。出于技术原因，我认为仅仅扩展当前方法 (LLM) 并不能让我们实现这一目标，而且我们还差得很远，但我不想在这篇文章中讨论这个问题。相反，是否有针对专注于 AGI 技术工作、研究和实践讨论的社区或其他团体的建议？    提交人    /u/Revolutionary-Fig660   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emhuwa/d_is_there_an_appropriate_community_for_technical/</guid>
      <pubDate>Wed, 07 Aug 2024 17:27:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 加入项目委员会有什么好处？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emh4i8/d_what_are_the_benefits_of_being_on_a_program/</link>
      <description><![CDATA[我很好奇，在 ML 会议上，加入程序委员会意味着什么，以及为什么人们会选择加入程序委员会。 作为 ML 会议的审稿人，我认为深入阅读几篇论文是有好处的。加入程序委员会有什么好处？我的理解是，这份工作主要是 ping 审稿人、总结评论和其他管理任务。    提交人    /u/smorad   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emh4i8/d_what_are_the_benefits_of_being_on_a_program/</guid>
      <pubDate>Wed, 07 Aug 2024 16:59:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 AAAI 投稿评论的公开访问权的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emengc/d_question_about_public_access_to_reviews_for/</link>
      <description><![CDATA[我正在准备向 AAAI 提交论文，今年 AAAI 使用 OpenReview。有人知道在审查过程结束后，所有评论（包括被拒绝的论文的评论）是否会公开吗？我在 AAAI 网站上找不到此信息。谢谢！    提交人    /u/RudeFollowing2534   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emengc/d_question_about_public_access_to_reviews_for/</guid>
      <pubDate>Wed, 07 Aug 2024 15:24:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何追踪你所有的实验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emakgn/d_how_do_you_keep_track_of_all_your_experiments/</link>
      <description><![CDATA[大家好， 在我的公司，我们正在进行大量 LLM 实验。 我们目前正在进行“小规模”实验来做各种事情（选择各种超参数、进行一些小的架构更改、使用什么数据集等...） 我们正在使用 WandB，记录实验非常酷，但我不知道在协作方面有什么功能可以更进一步。例如，我们希望有一些东西可以从我们启动的各种实验/图中得出结论，理想情况下将图和结论存储在一个地方。 这样，我们就可以轻松地跟踪所有内容，特别是当我们几个月后回顾实验时，我们能够理解我们启动它的原因以及得出的结论是什么。 你是如何做到的？您是否使用特定工具？    提交人    /u/Theboredhuman_56   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emakgn/d_how_do_you_keep_track_of_all_your_experiments/</guid>
      <pubDate>Wed, 07 Aug 2024 12:32:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>