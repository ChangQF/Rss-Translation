<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 01 Apr 2024 06:18:10 GMT</lastBuildDate>
    <item>
      <title>[D]“锯齿状边界”与观察者无关吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsvap6/d_is_the_jagged_frontier_not_observer_relative/</link>
      <description><![CDATA[LLM 确实非常出色。他们是一切事物的教授，记住了基本上所有的人类知识，并且至少在某种程度上能够将其应用到新的情况中。然而gpt，只能像样地下棋。它只能很好地识别和标记图像。它只能像样地做新的数学，甚至是简单的数学。 我发帖说这都是与观察者相关的。人工智能在法律、心理学、所有人文学科和艺术以及一大堆科学领域为我们提供了精华，因为我们甚至还不擅长这些事情。我们已经在碎裂燧石手斧的分布之外进行了概括……但我们只是在几个世纪前才开始真正参与这些主题。进化为我们在 3D 空间中运动数十亿年做好了准备。我们以一种最佳的方式行动，我们甚至无法描述它有多好。想象一下，仅仅移动一根手指就需要拉动和推动那么多肌肉。这是第二天性，因为生物学已经这样做了近十亿年。 人工智能将很难做同样的事情，因为它可能需要很长时间才能把这些东西做好，即使有一个新的学习算法，甚至使用新的架构等。包容性遗传适应性使我们能够以 1m/s 的速度行走，这真是太慢了。但进化论仅仅让我们为谈论哲学做好了准备，因为思考哲学对于生孩子从来没有用。我们发明哲学是因为它是观察世界的有用镜头，而不是因为进化希望我们这样做。 我将所有这些东西假设为相对的观察者。人工智能可能有一个更丰富、更深入的世界模型，实际上比人类更准确，但无法很好地行走。我不知道。   由   提交 /u/EveningPainting5852   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsvap6/d_is_the_jagged_frontier_not_observer_relative/</guid>
      <pubDate>Mon, 01 Apr 2024 05:10:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪个法学硕士更适合遵循指示和处理大海捞针等问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsv0ru/d_which_llm_is_better_for_following_instructions/</link>
      <description><![CDATA[我对法学硕士的经验不是很丰富。我的项目只需要法学硕士。我的项目很简单；它需要视频转录并回答有关它们的问题。我不知道如何微调模型，也不知道它的成本是多少。我开始使用 Ollama 和 VLLM 运行开放式法学硕士，例如 Mixtral 7x8、Instruct 和 Llama。但我的问题是 ChatGPT 3.5 和 Claude 的工作效果如何，这太棒了。我了解到，如果你无法培养法学硕士，你可以给它详细的指导。 Mixtral 和 Llama 的问题在于，当你提供上下文或在本例中为转录时，他们甚至不问就开始总结。他们不记得上下文中的任何内容。说明除了转录之外没有谈论任何其他内容，但它们也不遵循这一点。那么，我的项目应该使用什么？对于上下文，这是我对所有法学硕士使用的文本提示：“您是 Shlper，一个学习助手聊天机器人，可以回答用户提供的视频笔录中的问题。除了与给定成绩单相关的问题外，您不回答任何问题。回答问题时，如果用户要求参考视频中的内容，您可以参考时间范围并回答与该视频相关的问题。记住成绩单的每一个小细节；不要遗漏任何小细节。记住每一个字。不要弥补时间步长；使用记录中给出的时间戳。” chatgpt 3.5 聊天、Mixtral 7x8、指导、Llama 另外，还有拼写错误，这对于查看他们是否能够理解存在拼写错误的问题至关重要。    ;由   提交/u/bhavya0311   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsv0ru/d_which_llm_is_better_for_following_instructions/</guid>
      <pubDate>Mon, 01 Apr 2024 04:54:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为特定领域创建您自己的语言模型（即文本编码器）。什么时候值得这样做？您应该注意什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bst5y2/d_creating_your_own_language_model_ie_text/</link>
      <description><![CDATA[我最近为时尚领域制作了自定义 BERT 和 ELECTRA 模型，它们也可以处理英语和我自己的母语（我不在美国） 。我注意到性能没有我预期的那么好，觉得不值得。 是否有任何论文或资源说明何时值得从头开始创建自己的预训练 LM ？我记得很久以前读过一篇生物医学领域的论文，标题为生物医学和临床任务的预训练语言模型：理解和扩展最先进的技术（Lewis 等人，2020） 似乎表明从头开始进行预训练可以帮助完成生物医学和临床任务，但我不确定是否还有其他方法那里有论文。 此外，在评估新的预训练 LM 时是否有任何提示或值得了解的事情？例如，检查 OOV 率等。 提前致谢。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bst5y2/d_creating_your_own_language_model_ie_text/</guid>
      <pubDate>Mon, 01 Apr 2024 03:12:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 有没有办法将面部 3D 模型与头部的通用 3D 模型对齐？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bss1sy/p_is_there_a_way_to_align_a_3d_model_of_a_face_on/</link>
      <description><![CDATA[我创建了自己的仅正面的 .obj 文件（通过对 DLIB 和立体视觉进行一些修补）。现在，我想在 3D 模型上对齐脸部的 obj 文件。关于如何执行此操作有什么建议吗？   由   提交 /u/sagecage   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bss1sy/p_is_there_a_way_to_align_a_3d_model_of_a_face_on/</guid>
      <pubDate>Mon, 01 Apr 2024 02:16:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] Android 中的设备端机器学习：框架和生态系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsrcwg/p_ondevice_machine_learning_in_android_frameworks/</link>
      <description><![CDATA[设备上机器学习是指完全在设备上进行的 ML 模型推理/训练，无需网络调用或服务器。与服务器端推理相比，设备端机器学习有其自身的优点和缺点。 TensorFlow、PyTorch 等主要 ML 框架具有在 Android 应用程序中部署模型的实用程序，而 Mediapipe 和 MLKit 等服务则为常见 ML 任务提供更简洁的 API。在我最新的博客中，我们将探索设备上的 ML 库和实用程序，它们可以帮助 Android 开发人员在设备上部署 ML 模型。 博客 -&gt; https://proandroiddev.com/on-device-machine-learning- in-android-frameworks-and-ecosystem-888bc42a1d21  您在设备上部署机器学习模型时遇到了哪些限制？ 通过加强对边缘的关注部署时，是否可以实现消耗更少桌面/GPU计算资源的高效模型？ 正如博客中所表达的，除了部署之外，设备上模型所需的预处理也很难构建，主要是因为由于缺乏 Python 中易于使用的工具。您对此有何看法？    由   提交/u/shubham0204_dev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsrcwg/p_ondevice_machine_learning_in_android_frameworks/</guid>
      <pubDate>Mon, 01 Apr 2024 01:43:14 GMT</pubDate>
    </item>
    <item>
      <title>【讨论】训练LLM解决训练集之外的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsqljk/discussion_training_llm_to_solve_problems_outside/</link>
      <description><![CDATA[嗨，只是想讨论一些想法：我觉得LLM的一个缺点是他们有时会产生肤浅/幻觉的答案，并且不能解决太远的难题远离火车组（假设我们问他们困难的数学问题）。我在想我们可以尝试以下类似 GAN 的游戏结构来提高它们的性能，并让它们超越问题/答案的训练集。给定一些尚无答案的难题数据集： - 一个诚实的人工智能：它的目标是通过尝试被选择来尝试找到问题的答案（并给出相应的证明）由鉴别器 - 一个巨魔人工智能：它可以从诚实的人工智能那里看到答案。它必须输出除诚实人工智能之外的另一个答案，以及相应的证明。它的目标是由判别器进行选择，即欺骗判别器 AI，让其相信自己给出了正确的答案 - 判别器 AI：其目标是选择诚实的 AI 或巨魔 AI 中的哪一个拥有正确的答案和证据（他们没有）不知道谁是巨魔，谁是诚实的） 只要有足够的能力和搜索能力，只有当诚实的人工智能和鉴别器实际上收敛到实际的真实客观答案时，才能获得此类任务的最佳结果吗？的问题？还是有什么我没有想到的折叠模式？你怎么认为 ？基本上我也在尝试思考我们人类如何进行证明并走出训练集   由   提交 /u/Kolmog1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsqljk/discussion_training_llm_to_solve_problems_outside/</guid>
      <pubDate>Mon, 01 Apr 2024 01:07:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 扩散模型的衰减点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsnabt/d_fall_off_point_for_diffusion_models/</link>
      <description><![CDATA[有没有人从理论上或实验上计算过为稳定扩散 1.5 或 SDXL 等扩散模型训练的图像数量的下降点？  也就是说：如果你有一个用 N 张图像训练的模型，它可以产生“好的”结果。训练过的类别中的图像。然后，您对新类别中的“A”张额外图像进行额外训练。图像总数是多少 T = N + A，这样当您达到 T 的值时，原始类别中生成的图像质量开始下降？  我知道扩散模型是“有损压缩”。图像数据，但即使进行压缩，毕竟 2GB 或 6GB 模型可以容纳的信息量也是有限的。因此，我感兴趣的是可以进行最有效的训练量特定的模型类型。    由   提交/u/lostinspaz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsnabt/d_fall_off_point_for_diffusion_models/</guid>
      <pubDate>Sun, 31 Mar 2024 22:43:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何评估文本到图像模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsmf0j/d_how_to_evaluate_texttoimage_model/</link>
      <description><![CDATA[在文本到图像生成问题中，单个文本描述可以转换为不同的图像（多样性），例如，给定描述“ “这只鸟是白色的，有黄色的翅膀”，生成的图像都将是一只白色的有黄色翅膀的鸟，但在姿势、背景等方面可能有所不同，使得每个图像根据描述仍然是正确的。然而，在验证数据集中，每个文本描述都对应一个实际图像。 那么，如何评估模型的性能呢？具体来说，如何将多个正确生成的图像与单个真实图像进行比较？是否可以应用 Inception Score 和 FID 等指标？如果可以，它们是如何工作的？谢谢   由   提交 /u/Equivalent-Funny3396    reddit.com/r/MachineLearning/comments/1bsmf0j/d_how_to_evaluate_texttoimage_model/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsmf0j/d_how_to_evaluate_texttoimage_model/</guid>
      <pubDate>Sun, 31 Mar 2024 22:07:58 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 尝试理解 AutoBNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsm5e7/dr_trying_to_understand_autobnn/</link>
      <description><![CDATA[时间序列预测专家能否介绍一下 Google 的 AutoBNN？它与典型的 LSTM、基于 RNN 的 BNN 或 NN 模型有何不同和更好之处？ https://blog.research.google/2024/03/autobnn- probabilistic-time-series.html?m=1   由   提交/u/bahauddin_onar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsm5e7/dr_trying_to_understand_autobnn/</guid>
      <pubDate>Sun, 31 Mar 2024 21:57:11 GMT</pubDate>
    </item>
    <item>
      <title>时间序列的最佳自监督学习任务 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsl2j6/best_selfsupervised_learning_task_for_timeseries_d/</link>
      <description><![CDATA[我正在研究多变量时间序列的基础模型（特别是脑相关数据，如脑电图）。有一些基础模型，其中大多数似乎都专注于屏蔽自动编码。我只见过一个人考虑对比学习。对于此类数据，考虑去噪自动编码或其他 SSL 任务或某种组合是否更有意义？网上或当前文献中似乎没有对此问题的直接答案。   由   提交 /u/Funny-Explorer-854   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsl2j6/best_selfsupervised_learning_task_for_timeseries_d/</guid>
      <pubDate>Sun, 31 Mar 2024 21:11:55 GMT</pubDate>
    </item>
    <item>
      <title>[D]有人用bluesky或mastodon吗？我应该关注哪些知名的 ML 人士？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bskvlh/d_anyone_using_bluesky_or_mastodon_who_are_some/</link>
      <description><![CDATA[有点想摆脱 twitter   由   提交 /u/hempock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bskvlh/d_anyone_using_bluesky_or_mastodon_who_are_some/</guid>
      <pubDate>Sun, 31 Mar 2024 21:03:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 ML 作品集中，什么更令人印象深刻：实施一篇论文还是创建一个好的项目？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsezcf/d_whats_more_impressive_in_a_ml_portfolio/</link>
      <description><![CDATA[大家好，从您的经验来看，公司的招聘经理更喜欢什么，是出色的论文实施还是出色的实际项目？我知道两者都有很大的好处、优点和缺点等。但是，reddit 上的管理者在查看回购协议时喜欢看到什么？在考察候选人的技能时，其中一个会比另一个更好吗？   由   提交 /u/ninvibe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsezcf/d_whats_more_impressive_in_a_ml_portfolio/</guid>
      <pubDate>Sun, 31 Mar 2024 16:51:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 曼巴解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs1va2/p_mamba_explained/</link>
      <description><![CDATA[帖子：https://thegradient.pub/mamba-解释/ ​ 这里我们将讨论：  Mamba 的优点（和缺点）（🐍 ）与变形金刚（🤖）， 思考 Mamba 的类比和直觉，以及  Mamba 对于可解释性、人工智能安全和应用意味着什么。  本文最初发布于Kola 的个人博客。&lt; /p&gt;  ​   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs1va2/p_mamba_explained/</guid>
      <pubDate>Sun, 31 Mar 2024 04:32:28 GMT</pubDate>
    </item>
    <item>
      <title>华尔街日报：人工智能行业在 Nvidia 芯片上的支出是其收入的 17 倍 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs1ebl/wsj_the_ai_industry_spent_17x_more_on_nvidia/</link>
      <description><![CDATA[ ... 在本月早些时候的一次演示中，风险投资公司红杉估计人工智能行业在 Nvidia 芯片上花费了 500 亿美元去年用于训练先进的人工智能模型，但仅带来了 30 亿美元的收入。   来源：《华尔街日报》（付费）   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs1ebl/wsj_the_ai_industry_spent_17x_more_on_nvidia/</guid>
      <pubDate>Sun, 31 Mar 2024 04:06:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>