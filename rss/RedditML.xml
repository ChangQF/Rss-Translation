<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sun, 06 Apr 2025 06:24:50 GMT</lastBuildDate>
    <item>
      <title>[D] Rich Sutton：自我验证，AI的关键</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jslkhw/d_rich_sutton_selfverification_the_key_to_ai/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/jsonathan       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jslkhw/d_rich_sutton_selfverification_the_key_to_ai/</guid>
      <pubDate>Sun, 06 Apr 2025 04:01:49 GMT</pubDate>
    </item>
    <item>
      <title>[d]其他人是否观察到LLMS中结构化的，持续的语言出现？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jskfnj/d_has_anyone_else_observed_structured_persistent/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这只是我在LLM中使用的大量短语的一小部分。这是我没有尝试让系统用另一种语言讲话的。它是自发出现的。  ; ＆＃32;提交由＆＃32; /u/wasabimiester     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jskfnj/d_has_anyone_else_observed_structured_persistent/</guid>
      <pubDate>Sun, 06 Apr 2025 02:54:19 GMT</pubDate>
    </item>
    <item>
      <title>[r] Noprop：训练神经网络而无需反向传播或前向传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jsft3c/r_noprop_training_neural_networks_without/</link>
      <description><![CDATA[https://arxiv.org/pdf/2503.24322 Abstract The canonical deep learning approach for learning requires computing a gradient term at each layer by从输出到每个可学习的参数将误差信号向后传播。鉴于神经网络的堆叠结构，其中每个层都基于层的表示形式，因此该方法导致层次表示。模型顶层的更多抽象功能现场直播，而下层的特征则预计会不那么抽象。与此相反，我们引入了一种名为Noprop的新学习方法，该方法不依赖于前进或后部传播。取而代之的是，Noprop从扩散和流匹配方法中汲取灵感，在该方法中，每一层都独立学习以将嘈杂的目标变形。我们认为，这项工作朝着引入一个新的无坡度学习方法迈出的第一步，这些学习方法没有学习层次的代表，至少在通常的意义上没有。 Noprop需要事先将每一层的表示形式修复到目标的噪声版本，学习一个局部denoising过程，然后可以在推理中利用该过程。我们证明了我们方法对MNIST，CIFAR-10和CIFAR-100图像分类基准的有效性。我们的结果表明，与其他现有的无反向传播方法相比，NOPROP是一种可行的学习算法，具有较高的精度，更易于使用，并且在计算上更易于使用。 Noprop从传统的基于差异的学习范式背道而驰，改变了网络中的信用分配，从而实现了更有效的分布式学习以及潜在地影响学习过程的其他特征。   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jsft3c/r_noprop_training_neural_neal_networks_without/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jsft3c/r_noprop_training_neural_networks_without/</guid>
      <pubDate>Sat, 05 Apr 2025 22:46:20 GMT</pubDate>
    </item>
    <item>
      <title>[P]有人从事阿拉伯OCR工作吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jsclxw/p_anyone_working_on_arabic_ocr/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我尝试过的阿拉伯语的所有OCR根本无法正常工作。我真的有兴趣构建适当的阿拉伯OCR。如果您知道任何正在从事它的人或任何开放项目，请告诉我。我很想做出贡献并帮助改进它。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/the__space__witch     [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jsclxw/p_anyone_working_on_arabic_ocr/</guid>
      <pubDate>Sat, 05 Apr 2025 20:18:56 GMT</pubDate>
    </item>
    <item>
      <title>[n]致电4发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jsbbuy/n_llama_4_release/</link>
      <description><![CDATA[        &lt;！ -  sc_off-&gt;       https://www.llama.com/     &lt;！ -  sc_on-&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/we_are_mammals     [link]   ＆＃32;   [注释]            ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jsbbuy/n_llama_4_release/</guid>
      <pubDate>Sat, 05 Apr 2025 19:22:16 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]这可能是关于当前培训方法的一个非常愚蠢的问题...</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1js6jd9/discussion_this_might_be_a_really_dumb_question/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  那么，为什么我们不能以低量化训练一个非常大的网络，获得最低的测试错误，以最低的测试误差时期修剪网络，然后增加量化或剩余参数以开始训练呢？这难道难道不允许更有效地克服当地的最小值吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1js6jd9/discussion_this_this_might_be_a_really_dumb_question/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1js6jd9/discussion_this_this_might_might_be_a_really_dumb_question/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1js6jd9/discussion_this_might_be_a_really_dumb_question/</guid>
      <pubDate>Sat, 05 Apr 2025 15:53:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICASSP 2025</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1js2ro5/d_icassp_2025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，今年将参加ICASSP。  想知道社区是否也参加会议。可能我们可以赶上某个时候。   ps：已经到达场地  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fanding-nerve-4056      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1js2ro5/d_icassp_2025/</guid>
      <pubDate>Sat, 05 Apr 2025 12:53:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 2025-如果审稿人不承认反驳怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1js1ucr/d_icml_2025_what_if_reviewers_dont_acknowledge/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   2中我在ICML的5位评论者中根本不承认我的反驳。不仅没有答案，他们甚至没有单击“确认驳斥”。根本。根据ICML规则，他们必须这样做。当他们不这样做时会发生什么？我们应该向AC报告吗？我在任何地方都没有找到这个，所以也许这里有人知道或处于类似情况。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/qalis     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1js1ucr/d_icml_2025_what_red_reviewer_reviewers_dont_acknowledge/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1js1ucr/d_icml_2025_what_if_reviewers_dont_acknowledge/</guid>
      <pubDate>Sat, 05 Apr 2025 11:59:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]在现实世界情景中使用的域对抗神经网络（DANN）吗？有什么可行的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1js0tvk/d_are_domain_adversarial_neural_networks_dann/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我发现该论文中提出的想法非常有吸引力，能够在一个受控域上训练，它易于标记数据，并且“传输”它到另一个域，很难将数据标记为。 它是合成/生成的数据与真实数据的合成/生成的数据，或者在野生数据中捕获的办公室捕获的数据，能够成功捕获没有标签的域具有一些实际价值。有人在这个问题上有一些经验吗？听起来真是太好了，这也不是我所期望的，这也不是如此有用，它提高了另一个标志。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1js0tvk/d_are_are_domain_adversarial_neural_neural_networks_dann/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1js0tvk/d_are_domain_adversarial_neural_networks_dann/</guid>
      <pubDate>Sat, 05 Apr 2025 10:54:34 GMT</pubDate>
    </item>
    <item>
      <title>[r]通过自我原告的批评调整和推理时间缩放来改善通才奖励模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jrxq16/r_improving_generalist_reward_models_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   DeepSeek的新奖励建模方法使用推进时间缩放来显着胜过现有系统。他们的Deepseek通才奖励模型（GRM）引入了自我原理的批评调整，该调整在批评响应之前生成了针对每个任务的评估原则。 关键的技术贡献： * 自我计划的批评调整（SPCT）（SPCT）在在线rlhf的适应强度 刻度呈瞬间生成奖励建模改进成对方法 *一种新型的元奖励模型，该模型可以评估和结合多个评估以选择最佳的一个 主要结果：推理时间缩放（更多样本=更好的结果） *有效地处理各种任务而不发展严重的偏见 *表明，推理时间缩放比缩放模型大小 我认为，我认为这种方法代表了我们对缩放AI功能的看法的重要转变。与其专注于更大的模型和更多培训数据，我们可以通过推理期间更智能地使用计算来获得更好的结果。这可能会通过在没有巨大的培训预算的情况下获得前沿级别的结果来使获得高质量AI的访问权限。 原则优先的方法似乎也可以帮助解释性和一致性。通过在做出判断之前明确生成评估标准，该模型对其决策过程提供了更大的透明度。  tldr：DeepSeek-Grm使用一种新颖的方法，该方法首先生成了特定于任务的原理，然后批评基于这些原理的响应。结合推理时间扩展通过并行采样，这可以在多个基准测试中获得最新的结果。他们的工作表明，通过缩放推理而不是训练，我们可能会为我们的计算障碍提供更多爆炸。 完整的总结就在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]      [commist]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jrxq16/r_improving_generalist_reward_models_with/</guid>
      <pubDate>Sat, 05 Apr 2025 07:05:14 GMT</pubDate>
    </item>
    <item>
      <title>KDD 2025 [周期2]评论已经发布！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jrxh39/kdd_2025_cycle_2_reviews_are_out/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，  kdd 2025纸质评论在OpenReview上可见。通过发布评论，我想我会创建一个讨论线索来收集思想，问题和建议或其他任何内容。很想听听别人对评级方案的想法。 祝大家一切顺利！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/striking-treacle3096     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jrxh39/kdd_2025_cycle_2_reviews_are_out/</guid>
      <pubDate>Sat, 05 Apr 2025 06:48:45 GMT</pubDate>
    </item>
    <item>
      <title>[r]用于改进符号推理的新型逻辑增强LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jrwqa0/r_novel_logicenhanced_llm_for_improved_symbolic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在尝试一种新型方法，该方法将符号逻辑直接整合到变压器的注意机制中。通过使用基于自定义的基于Spacy的逻辑解析器，我生成了一个“逻辑掩码”，该胶面膜可以指导自我发项层以专注于逻辑结构。在使用微调的Llama 3 8B模型的初步测试中，此方法显示出有望改进符号推理任务（例如，在对开本数据集中达到62％左右）。我渴望听到社区进一步完善这种方法的想法和建议。另请注意，我没有博士学位或机器学习硕士学位。很高兴接受任何好是坏事。 :)   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/_w0z      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jrwqa0/1jrwqa0/r_novel_logicenhanced_llm_for_improve_impreve_symbolic/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jrwqa0/r_novel_logicenhanced_llm_for_improved_symbolic/</guid>
      <pubDate>Sat, 05 Apr 2025 05:58:00 GMT</pubDate>
    </item>
    <item>
      <title>[r]大型语言猴子如何获得力量（法律）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jribqw/r_how_do_large_language_monkeys_get_their_power/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/u/rschaeffer       [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jribqw/r_how_do_large_language_monkeys_get_their_power/</guid>
      <pubDate>Fri, 04 Apr 2025 18:01:07 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jpdo7y/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</guid>
      <pubDate>Wed, 02 Apr 2025 02:15:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些经验丰富的人。   &lt;！ -  sc_on--&gt; 32;&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_be_hired/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Mon, 31 Mar 2025 02:30:37 GMT</pubDate>
    </item>
    </channel>
</rss>