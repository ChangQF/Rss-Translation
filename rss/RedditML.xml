<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 24 Oct 2024 12:32:49 GMT</lastBuildDate>
    <item>
      <title>[D] 我应该如何设置LLM的回复格式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gayuhw/d_how_should_i_set_the_format_for_the_llms/</link>
      <description><![CDATA[微调 LLM 的新手 使用 https://github.com/hiyouga/LLaMA-Factory 例如： 嘿，Bhatgpt，您能修复这个句子中的语法错误吗？ “如果您的任务与检查点模型所训练的任务相似，那么您已经可以使用 LlamaForCausalLM 进行预测而无需进一步训练。”   所需格式： 语法错误更正： 您的句子有一个轻微的语法错误。它应该是：“XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX” 不同场景： 正式： “如果您的任务与检查点模型的训练参数相符，您可以继续使用 LlamaForCausalLM 进行预测，而无需额外的训练要求。” 书面英语： 在任务相似性与检查点模型的训练参数相对应的情况下，可以立即实施 LlamaForCausalLM 进行预测目的，而无需补充训练协议。 口语化： 嘿，如果你的任务与模型最初训练的任务相匹配，你完全可以即插即用 LlamaForCausalLM - 无需额外的训练或任何东西！    提交人    /u/Ggboysformnowhere   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gayuhw/d_how_should_i_set_the_format_for_the_llms/</guid>
      <pubDate>Thu, 24 Oct 2024 09:52:26 GMT</pubDate>
    </item>
    <item>
      <title>[P] 基于多代理人工智能的人力资源信息系统[HRIS]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gaylfx/p_multiagent_ai_based_human_resource_information/</link>
      <description><![CDATA[正如标题所示， 我正在研究构建基于 MAS 的 HRIS 的潜在想法，我正在研究其他经验丰富的人士或任何人的建议，关于如何为我的组织将这个想法构建成一个好的产品 什么样的服务或任何引人注目的用例等 我期待着收到所有人的意见    提交人    /u/Not_so_sure_paradox9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gaylfx/p_multiagent_ai_based_human_resource_information/</guid>
      <pubDate>Thu, 24 Oct 2024 09:33:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 的 Whisper“库”/“框架”等的包装器？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gayjwu/d_wrapper_for_openais_whisper_libraryframework_etc/</link>
      <description><![CDATA[自从 OpenAI 的 Whisper 发布以来，我就一直在使用它的命令行版本，但它并没有提供 Whisper-&quot;框架&quot;（或无论您怎么称呼它）包含的所有选项。一定有人为此编写了一个&quot;包装器&quot;，不是吗？但我在 Google 上找不到任何东西。您能推荐一些吗？ 我有 20 000 个文件，从 10 秒到几个小时不等，我希望尽可能高效、高质量地转录它们（我优先考虑质量而不是效率。目前，我使用带有大型 v3 模型的命令行客户端）。    提交人    /u/la-grave   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gayjwu/d_wrapper_for_openais_whisper_libraryframework_etc/</guid>
      <pubDate>Thu, 24 Oct 2024 09:30:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 将其他输入特征连接到 ViT 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gayiww/r_concatenating_additional_input_features_to_a/</link>
      <description><![CDATA[大家好， 我正在探索将其他输入功能（例如表格数据或其他非图像功能）与图像输入一起集成到 Vision Transformer (ViT) 架构中的方法。 有人尝试过这种方法吗？或者有人知道任何研究论文、博客或参考文献探讨过这个问题吗？我特别感兴趣的是如何以有意义的方式将这些额外的输入与图像标记集成在一起。 在此先感谢任何帮助或指点！    提交人    /u/kernel_KP   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gayiww/r_concatenating_additional_input_features_to_a/</guid>
      <pubDate>Thu, 24 Oct 2024 09:28:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 表格域中的解缠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gay549/r_disentanglement_in_tabular_domain/</link>
      <description><![CDATA[这里有人研究过表格数据中的解缠吗？这可能吗？或者这有意义吗？在没有可量化的基本事实因素的表格数据中，解缠的标准/评估指标是什么？ 背景：我被委托研究这个主题，发现解缠在图像等领域很常见，大多使用 VAE。有一些研究将 VAE 应用于表格数据，特别是为了公平或合成数据生成的目的，但他们并不称之为“解缠”，也没有给出与表格数据解缠相关的任何评估。    提交人    /u/QT-NTU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gay549/r_disentanglement_in_tabular_domain/</guid>
      <pubDate>Thu, 24 Oct 2024 08:59:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 是 CNN 的一种</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gaxscv/d_transformers_are_a_type_of_cnn/</link>
      <description><![CDATA[https://arxiv.org/abs/2309.10713 我随机在谷歌上搜索动态卷积，因为我觉得它们很酷，然后发现了这篇论文，它表明 transformer 相当于一种使用动态卷积的 CNN。动态卷积论文 (https://arxiv.org/abs/1912.03458) 于 2019 年发布，所以它确实在注意力就是你需要的所有论文之后发布。 遗憾的是这篇论文只有一个引用。我认为这太不可思议了。知道 transformers 可以被视为 CNN 让他们能够深入了解优化其设计，包括删除 softmax 激活并将其替换为 Relu+normalisation 层。我认为通过继续他们的工作可以做出更多的改进。    提交人    /u/Ozqo   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gaxscv/d_transformers_are_a_type_of_cnn/</guid>
      <pubDate>Thu, 24 Oct 2024 08:31:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] KAN 论文以一种有趣的方式将无监督问题转变为监督问题（允许某些样本存在差异）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gau1kt/r_the_kan_paper_has_this_interesting_way_to_turn/</link>
      <description><![CDATA[在 KAN 论文中，他们有一种有趣的方法来推断变量之间的映射，即允许部分数据样本的变量创建正样本和负样本。一种对比学习的形式。他们没有引用这种方法，是否有更多公式化的方法可以进行这种分析，以无监督的方式研究变量之间的关系。 第 4.2 节 - https://arxiv.org/abs/2404.19756    提交人    /u/Sandy_dude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gau1kt/r_the_kan_paper_has_this_interesting_way_to_turn/</guid>
      <pubDate>Thu, 24 Oct 2024 04:07:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 新款 Claude Sonnet 3.5 如何提供精确的坐标？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gasb94/d_how_could_the_new_claude_sonnet_35_provide/</link>
      <description><![CDATA[不确定以前是否有人问过这个问题，但最近发布的 Claude Sonnet 让我很惊讶。几个月前，我尝试了许多 LLM 来为我提供屏幕截图上的 (x, y) 坐标，使用各种方法，如网格位置、标记坐标等，但精度不够。但是；这个新模型实际上可以提供非常精确的坐标。有人知道/我们能猜出他们为这样的事情使用的系统吗？他们可以使用其他模型，如 SeeClick 吗？    提交人    /u/super_deap   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gasb94/d_how_could_the_new_claude_sonnet_35_provide/</guid>
      <pubDate>Thu, 24 Oct 2024 02:31:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] Ichigo：混合模式早期融合实时语音助手</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gae6tb/r_ichigo_mixedmodal_earlyfusion_realtime_voice/</link>
      <description><![CDATA[  由    /u/emreckartal  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gae6tb/r_ichigo_mixedmodal_earlyfusion_realtime_voice/</guid>
      <pubDate>Wed, 23 Oct 2024 16:03:30 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 世界上第一个自主 AI 发现的 0day 漏洞</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ga8wxn/project_worlds_first_autonomous_aidiscovered_0day/</link>
      <description><![CDATA[我确信很多人都通过将代码片段粘贴到 ChatGPT 中发现了 0-day 漏洞。问题一直是扫描整个项目的 0-day。一些论文表明，通过向其代理提供已知的易受攻击的代码，这是可能的，但据我所知，这些论文都没有获得任何 CVE 或发现真正的 0-day。Vulnhuntr 本周末发布，在 10k+ GitHub 星的开源项目中发现了十几个 0-day： https://github.com/protectai/vulnhuntr    提交人    /u/FlyingTriangle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ga8wxn/project_worlds_first_autonomous_aidiscovered_0day/</guid>
      <pubDate>Wed, 23 Oct 2024 12:07:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 良性过度拟合和双重下降。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ga7k9c/r_benign_overfitting_and_double_descent/</link>
      <description><![CDATA[简而言之，它们是一样的吗？ 下面详细阐述我的问题。 我试图理解双重下降现象和良性过度拟合之间的区别。 当模型复杂度在某个点之后增加时，测试误差会上升，然后在高度过度参数化的状态下再次降低，这时模型中就会发生双重下降。 我还没有找到良性过度拟合的确切定义，但是它也涉及过度参数化状态下的泛化。 从表面上看，它们似乎相同，但我并不完全确定。有人可以解释一下它们之间的异同吗？    提交人    /u/Scientifichuman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ga7k9c/r_benign_overfitting_and_double_descent/</guid>
      <pubDate>Wed, 23 Oct 2024 10:50:24 GMT</pubDate>
    </item>
    <item>
      <title>构建模型推荐系统：告诉我们你正在构建什么，我们将为其推荐最佳的 AI 模型！[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ga3h0j/building_a_model_recommendation_system_tell_us/</link>
      <description><![CDATA[嘿 Reddit！ 我们正在研究一些东西，我们认为它可以让每个人更轻松地发现模型：模型推荐系统，您只需用简单的英语输入您正在处理的内容，它就会为您的项目推荐最佳的 AI 模型。 🎉 💡 工作原理： 主要思想是您可以用自然语言 逐字描述您的项目，例如：  “我需要一个模型来生成医学研究论文的摘要。” “我正在构建一个用于客户支持的聊天机器人。” “我想要一个可以分析产品评论情绪的模型。”  并且基于该输入，系统将推荐最适合该工作的模型！ 无需深入研究技术规格，无需复杂的过滤器 - 仅根据您的需要提供可靠的建议。 🌟 我们还正在构建什么： 除了模型建议之外，我们还添加了一些功能，使平台超级用户友好：  详细的模型见解：您仍然可以获得所有技术信息，例如性能指标、架构和受欢迎程度，以比较模型。 高级搜索和过滤器：如果您更喜欢亲自动手，则可以按任务、框架或标签过滤模型。 个性化建议：随着时间的推移，系统将变得更加智能，并根据您过去的使用情况提供更多相关建议。  我们为什么需要您的反馈： 我们希望这个平台能够真正为 AI/ML 领域的人们解决问题，而这正是您可以发挥作用的地方！ 🙌  这样的工具对你有帮助吗？ 你认为像 Hugging Face 这样的模型平台缺少哪些功能？ 你是否希望看到某些特定功能，例如性能比较或自定义选项？ 我们如何才能让自然语言输入在推荐模型方面更有用？  TL;DR: 我们正在构建一个工具，你只需用简单的英语描述你的项目，它就会为你推荐最好的 AI 模型。无需复杂的搜索 - 只需输入你需要的内容！期待你的反馈，了解你想要看到的内容，或者你认为像 Hugging Face 这样的当前平台缺少的任何功能。 我们很乐意听到你的想法和创意！什么会让这个平台对你超级有用？让我们知道您认为可以改进模型发现过程的方法，或者现有平台缺少什么！ 提前感谢，Reddit！😊    提交人    /u/O2MINS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ga3h0j/building_a_model_recommendation_system_tell_us/</guid>
      <pubDate>Wed, 23 Oct 2024 05:57:50 GMT</pubDate>
    </item>
    <item>
      <title>Meta AI（FAIR）最新论文将系统 1 和系统 2 思维融入推理模型。[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9v7ag/meta_ai_fair_latest_paper_integrates_system1_and/</link>
      <description><![CDATA[Meta AI (FAIR) 最新论文将系统 1 和系统 2 思维整合到推理模型中。 基本上，它引入了术语“Dualformer”，将系统 1（快速思维）和系统 2（慢速思维）整合到 Transformer 中以提高其推理能力。高级想法是使用“随机跟踪”训练模型，随机丢弃部分推理标记。这种方法提高了模型的推理速度、准确性和多样性。它还使模型能够以可控的方式执行系统 ​​1 和系统 2 思维。  论文链接在此： https://arxiv.org/html/2410.09918v1    提交人    /u/Proof-Raise-9151   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9v7ag/meta_ai_fair_latest_paper_integrates_system1_and/</guid>
      <pubDate>Tue, 22 Oct 2024 22:38:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</guid>
      <pubDate>Sun, 20 Oct 2024 15:00:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>