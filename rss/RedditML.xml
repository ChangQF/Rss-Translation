<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 02 Nov 2024 18:20:09 GMT</lastBuildDate>
    <item>
      <title>[P] 在法学硕士课程中灌输知识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gi27ev/p_instilling_knowledge_in_llm/</link>
      <description><![CDATA[大家好！ 我有一个信息语料库（文本），我希望我的基础模型能够学习语料库中包含的知识，这样我就可以简单地根据微调模型进行推断，而不是执行 RAG。我该怎么做？对于我读过的所有文档，它都是关于标记数据集（在我的情况下是问答）。有没有办法在 LLM 中灌输知识？ 提前致谢。    提交人    /u/mulberry-cream   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gi27ev/p_instilling_knowledge_in_llm/</guid>
      <pubDate>Sat, 02 Nov 2024 17:54:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] PhD ML 招生</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gi1q7w/d_phd_ml_admissions/</link>
      <description><![CDATA[我对 ML 录取非常感兴趣，因为我正在考虑申请下一轮的 PhD 项目。 我的问题如下。如果您能提供任何信息，我将不胜感激。  平均需要发表多少篇论文才能在 ML PhD 录取中具有竞争力？  让我们假设以下细分情况： 如果可以，请提供最坏情况的界限。这意味着将数字稍微夸大约 10% 以应对日益激烈的竞争。猜测估计是可以的。 领域：第一作者的平均数量、共同作者的平均数量、平均会议质量（影响因子）、引用次数 计算机视觉：？，？，？，？ 机器人 / RL：？，？，？，？ NLP：？，？，？，？ 理论：？，？，？，？ AI4Science：？，？，？，？ 领域细分示例如下： 计算机视觉：5,10,10.3,50 这意味着计算机视觉领域的平均博士生有 5 篇第一作者出版物、10 篇共同作者出版物，在平均影响因子为 10.3 的期刊上发表，并且在所有论文中累计获得 50 次引用。 如果您希望提供T5、T10、T15 和 T50 学校的不同细分情况都可以。  如何量化适合度？当某人“非常适合”某个实验室时，这意味着什么？ 我听到人们提到你需要知名教授的推荐信？这实际上是什么意思？比如，知名度有多高才算足够？我需要图灵奖获得者的推荐信吗？R1 学校的教授怎么样？助理教授还是博士后？这些是如何看待的。  谢谢你的帮助。    提交人    /u/throwaway-cs-12345   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gi1q7w/d_phd_ml_admissions/</guid>
      <pubDate>Sat, 02 Nov 2024 17:32:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML4H 回应和审查流程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghz1b7/d_ml4h_response_and_review_process/</link>
      <description><![CDATA[我刚刚收到一篇提交给 ML4H 的论文的最终裁决，它被拒绝了（审稿人给出了 5 [4]、5 [3]、2 [4]、5 [2]）。我得到了一个非常平淡的回复：“一位自信的审稿人拒绝了我。这个主题确实很重要。我会接受它作为发现海报。”。  拒绝审稿人的唯一抱怨是这些想法对医疗保健领域没有意义（除了他称赞这篇论文在技术上很有趣而且很合理）。除此之外，他/她还写道，如果我们（作者）能提供理由，他愿意改变分数。我们写了反驳，但我们没有看到任何其他评论？有什么方法可以理解为什么反驳不够充分？（我习惯与审稿人打乒乓球）。此外，主席写道，主题很重要，这是低分的唯一原因吗？ 有没有办法对决定提出上诉？     提交人    /u/GeneralSkoda   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghz1b7/d_ml4h_response_and_review_process/</guid>
      <pubDate>Sat, 02 Nov 2024 15:31:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 兼职硕士（NLP 方向）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghx9qe/d_part_time_masters_specialize_in_nlp/</link>
      <description><![CDATA[您好，我有机会获得进修费用报销。我在一个数据科学团队工作，主要处理自然语言数据。我对自己所做工作的了解完全基于我的行为科学背景（我在这里获得了硕士学位）以及完成工作要求所需的所有在线学习内容。我希望更深入地了解我使用的计算工具所涉及的概念，以便能够更灵活、更有创意地使用可用的技术。 话虽如此，我正在寻找一个专门从事 NLP 的兼职硕士课程。它必须是兼职的，因为我想保留这份工作，而且他们每学期只报销 6 个学分。理想情况下，我正在寻找可以在线完成的工作，但我也愿意搬到美国其他州。 您有什么建议吗？或者您就读于您喜欢的课程吗？希望得到您的意见。 谢谢！    提交人    /u/mariaiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghx9qe/d_part_time_masters_specialize_in_nlp/</guid>
      <pubDate>Sat, 02 Nov 2024 14:09:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医学 AI：顶级 LLM 研究论文/模型（2024 年 10 月 26 日至 11 月 2 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghx268/d_last_week_in_medical_ai_top_llm_research/</link>
      <description><![CDATA[   上周医学 AI：顶级 LLM 研究论文/模型（2024 年 10 月 26 日至 11 月 2 日） 本周医学 AI 论文：  Google 推出 MDAgents：用于医学决策的 LLM 自适应协作  本文介绍了MDAgents 是一个多代理框架，它为 LLM 分配协作结构以完成复杂的医疗任务，模仿现实世界的医疗决策。   医学 LLM &amp;其他模型：  Matchmaker：使用 LLM 进行模式匹配  本文介绍了 Matchmaker，这是一种用于模式匹配的组合语言模型程序，可解决数据源中的结构和语义异质性挑战。  UltraMedical：专门的生物医学模型  本文介绍了 UltraMedical，它是一组跨多个 LLM 的高质量手动和合成数据集，带有偏好注释，可用于生物医学应用。  ZALM3：视觉语言医学对话  本文介绍了 ZALM3，这是一种零样本策略，用于改善多轮多模式医学对话中的视觉语言对齐，解决在线咨询中患者提供的图像质量差的挑战。  EchoFM：超声心动图基础模型  本文介绍了EchoFM 是超声心动图视频的基础模型，采用具有时空一致性掩蔽和周期驱动对比学习的自监督学习框架，在 26 个扫描视图和不同成像模式下对超过 290,000 个视频（2000 万帧）进行了预训练。   框架和方法：  FEDKIM：联合医学知识注入 Flex-MoE：灵活模态组合 MAISI：合成医学成像 Cough-E：边缘隐私检测 MassSpecGym：分子识别  医学 LLM 应用：  DiaMond：多模态痴呆症诊断 LLM-Forest：健康数据归因 医学多模式视觉基础 与法学硕士 (LLM) 的临床证据综合  医学法学硕士 &amp;基准：  超越 H&amp;E 的组织病理学模型 心理健康咨询法学硕士 医学数据集重用分析  医疗伦理中的人工智能：  医学教育法学硕士 医学考试问题生成 临床知识图谱集成  .... 完整线程详细信息：https://x.com/OpenlifesciAI/status/1852685220912464066    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghx268/d_last_week_in_medical_ai_top_llm_research/</guid>
      <pubDate>Sat, 02 Nov 2024 13:59:40 GMT</pubDate>
    </item>
    <item>
      <title>[研究] [项目] 寻求公开可用的超声数据集用于卵巢癌检测项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghw3m2/research_project_seeking_publicly_available/</link>
      <description><![CDATA[大家好！ 我目前正在进行一个研究项目，旨在通过应用于超声图像的深度学习来改善卵巢癌的早期检测。现在，我正处于数据集收集阶段，在查找可访问的数据集时遇到了一些挑战。 我遇到了 PLCO 和 MMOTU 数据集：  PLCO 需要项目提案才能访问，我正在考虑，但可能需要一些时间。 MMOTU 提供分割数据，但不包括我的工作所需的全套诊断图像。  在查阅文献后，我注意到许多研究人员使用的临床研究数据集是私人的、特定于医院的患者数据或其他不公开的数据集。 如果这里有人参与过类似的项目或面临过这些挑战，我将非常感谢任何指点！具体来说，我正在寻找：  可公开访问的针对卵巢癌或妇科癌症的超声数据集 可通过作者请求或联系相关组织获得的数据集  提前感谢您分享的任何指导或资源！    提交人    /u/Swimming-Car-6055   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghw3m2/research_project_seeking_publicly_available/</guid>
      <pubDate>Sat, 02 Nov 2024 13:11:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] torch.compile 是否已经终结了 JAX 的案例？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghw330/d_has_torchcompile_killed_the_case_for_jax/</link>
      <description><![CDATA[我喜欢 JAX，但我完全承认你为了性能牺牲了开发的便利性。 我在网上看到一些关于 torch.compile 加速的讨论，但我并不是很了解。JAX 的性能案例现在已经过时了吗，或者令人印象深刻的 GPU 性能是否归因于多 GPU 等其他因素。    提交人    /u/internet_ham   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghw330/d_has_torchcompile_killed_the_case_for_jax/</guid>
      <pubDate>Sat, 02 Nov 2024 13:10:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] Zephyr 的第一个可用版本：JAX 上的新声明 FP NN 框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghthur/p_first_usable_release_of_zephyr_new_declaration/</link>
      <description><![CDATA[编辑标题：JAX 上的新声明式 FP NN 框架 链接在评论中。 您好！我在 JAX 之上创建了一个新的面向函数式编程的框架。它应该使 JAX 上的高级和低级操作变得容易，并有助于使神经网络简短、简单且易读。 它与其他 JAX 框架的主要区别在于，您不会将任何东西子类化，而是按照数学方式编写神经网络，只是一个纯函数 `F(parameters, X, hyperparameters)`。因此，如果您了解神经网络、python 和 jax，那么您可能只需要知道 2 件事： - 一个 trace 函数来帮助您自动生成 `params`（如果您愿意，您可以自己完成此操作）。 `params = trace(model, random_PRNG_key, sample_input_batch)` - `validate` 函数，可以将其视为一种提供 python 形状和其他信息以供检查的方法，但这只有在您需要创建自己的参数时才有用 我最近发布了它的第一个非 alpha 版本。它现在具有通用层：线性、mlp、conv、注意等等。我计划添加更多内容，也许很快会实现论文中的图层。欢迎提出建议。 我个人会将它用于我自己的项目，我希望它对你们有用，特别是那些想要进行面向 FP 的编码的人。请查看评论中的链接，尝试一下；我很乐意听到您的反馈意见。 最后几件事： - 查看 `zephyr.nets` 了解网络和层 - 并且可以在 `zephyr.trace` 找到跟踪    提交人    /u/Pristine-Staff-5250   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghthur/p_first_usable_release_of_zephyr_new_declaration/</guid>
      <pubDate>Sat, 02 Nov 2024 10:29:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 帮助小数据集时间序列和分类数据预测如何改进模型。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghse5o/p_help_with_small_dataset_time_series_and/</link>
      <description><![CDATA[我正在使用一个由 550 个样本和 10 个特征组成的训练数据集进行 kaggle 竞赛我有两个目标要预测一个是基于回归时间序列的而另一个是多个分类目标我已经使用了 XGboost 回归器和分类器并获得了 22 的公开分数这是使用平均绝对误差和分类准确度的回归测量的加权组合我该如何改进我的模型并使其更好     提交人    /u/BigPPMooman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghse5o/p_help_with_small_dataset_time_series_and/</guid>
      <pubDate>Sat, 02 Nov 2024 09:04:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 努力利用 NN 实现声音方向检测（方位角估计）的准确性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghqx2p/p_struggling_to_achieve_accuracy_in_sound/</link>
      <description><![CDATA[我正在开展一个项目，使用神经网络估计声源的方向（方位角），数据来自在（约 2m x 2m）平面上移动的 Khepera III 机器人。该设置使用 Raspberry Pi 跟踪机器人的 x、y 坐标和方向角“a”（相对于声源。直接指向目标声音时为 0），每次机器人向前移动然后稍微旋转（约 5-10 度）直到完全旋转时，都会捕获左右音频样本（左右麦克风相距约 18/19 厘米）。我收集了大约 1200 个音频（1 秒）样本，每个样本都在安静的实验室环境中录制。我的声源每 50 毫秒发出一次啪啪声。坐标系是使用 OpenCV 实现的（通过先前的研究），可以在屏幕上渲染 2D 平面内的位置和移动。它将坐标计算与每帧中的实时对象（机器人和扬声器）跟踪和空间表示对齐。 我的方法 我尝试了两种主要方法：  前馈神经网络 (FFNN)：我尝试仅使用原始音频（通过 librosa.load）进行训练，并且仅对每个方向角度“a”使用平坦的 MFCC。我的 FFNN 过度拟合了训练集并在测试集上挣扎。 长短期记忆 (LSTM)：我将数据重构为时间序列（序列长度为 200、50 等），遵循 Dhwani Desai 和 Ninad Mehendale 的论文&quot;机器人耳：用于检测声音方向的音频信号处理&quot;。他们报告的准确率为 82–95%，但我在目标声音 ±10° 范围内仅达到约 40%。  数据预处理： 规范化：我使用以下方法对整个数据集的特征进行标准化： for c in df_train.columns: mean = df_train[c].mean() stdev = df_train[c].std() df_train[c] = (df_train[c] - mean) / stdev df_test[c] = (df_test[c] - mean) / stdev  输出编码：我还尝试用正弦/余弦变换分解角度“a”，希望降低角度敏感度： def get_sin(A_degrees): return math.sin(math.radians(A_degrees)) def get_cos(A_degrees): return math.cos(math.radians(A_degrees))  超参数和代码：我测试了各种超参数，并使用了 nn.MSELoss() 和 torch.optim.Adam()： 我尝试了 FFNN 和 LSTM 的音频数据的对齐（互相关）和未对齐版本。我使用 PyTorch 实现了这一点。 问题  为什么我的模型与论文中的结果相比表现不佳？我想知道问题是否在于左右之间的数据对齐，因为论文没有指定确切的方法（例如，是否使用了互相关或时间同步记录精度（如以纳秒精度同时记录）。）。或者可能是完全不同的东西。我不确定我错过了什么。     提交人    /u/Decent_Eye_659   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghqx2p/p_struggling_to_achieve_accuracy_in_sound/</guid>
      <pubDate>Sat, 02 Nov 2024 07:05:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 思考法学硕士 - 遵循“思维生成”的指导</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gh9ijv/d_thinking_llms_instruction_following_with/</link>
      <description><![CDATA[https://arxiv.org/abs/2410.10630 Greg Schoeninger u/FallMindless3563，Oxen.ai 首席执行官和 Plain Speak 大师，尝试仅使用模型推理、数据集和微调 API 来重现本文中的发现。 今天太平洋时间上午 10:00、东部时间下午 1:00 开始电话会议，展示结果并深入研究论文。 https://www.oxen.ai/community/?utm_source=x&amp;utm_content=y    由   提交  /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gh9ijv/d_thinking_llms_instruction_following_with/</guid>
      <pubDate>Fri, 01 Nov 2024 16:28:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 获取神经网络“逆”的当前状态是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gh7lc3/d_what_is_the_current_state_on_getting_an_inverse/</link>
      <description><![CDATA[澄清我的意思（我的背景更多的是统计学，但我对一种非线性关系有问题） 假设我有输入（预测变量），例如：[x1,...,x10]，它们本质上都是数值（即没有虚拟变量），以及连续的数值输出 y，并且说我拟合某个 NN 为 y ~ x1 +... x10（我们可以假设一个相对简单的架构，即没有 CNN/RNN） 如果给定 [x2..x10,y]，有没有办法预测 x1 的预期值。 我目前有一些想法，对于一个相对简单的统计模型，它在所有其他变量固定的情况下连续映射 x1 和 y 之间的关系（比如线性回归），这很简单。从神经网络来看，我猜想如果要实现该功能，就需要对结构进行某些条件设置，例如，任何激活函数本身都需要是可逆的。 我想知道这是否是正在积极使用的东西，或者是否有这方面的研究。或者，更好的选择是创建两个模型 y = F(x1,...,x10) 和 x1 = G(x2,.,x10,y) 提前致谢    提交人    /u/Eamo853   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gh7lc3/d_what_is_the_current_state_on_getting_an_inverse/</guid>
      <pubDate>Fri, 01 Nov 2024 15:07:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] TokenFormer：使用标记化模型参数重新思考 Transformer 的扩展</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gh6fut/r_tokenformer_rethinking_transformer_scaling_with/</link>
      <description><![CDATA[  由    /u/MysteryInc152  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gh6fut/r_tokenformer_rethinking_transformer_scaling_with/</guid>
      <pubDate>Fri, 01 Nov 2024 14:16:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 27 Oct 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>