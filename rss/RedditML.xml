<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 06 Sep 2024 06:22:44 GMT</lastBuildDate>
    <item>
      <title>[D] 寻找类似 CLIP 的 LLM/Vision 模型进行图像分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fa6ayc/d_looking_for_an_llmvision_model_like_clip_for/</link>
      <description><![CDATA[嗨，我正在使用 CLIP 来分析图像，但正在寻找更好的选项来完成这些任务：  检测图像中是否有人。 确定是否存在多人。 识别人是否面向摄像头。 检测手机、平板电脑、智能手表或其他电子设备。 检测书籍、笔记。  有没有更好的模型（或为每个任务单独设置模型）适合这种类型的详细分析的建议？谢谢！    提交人    /u/Substantial_Video_26   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fa6ayc/d_looking_for_an_llmvision_model_like_clip_for/</guid>
      <pubDate>Fri, 06 Sep 2024 04:09:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 本周，我在 Tinygrad 中实现了论文“关注 MLP”！:D</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fa5kop/p_this_week_i_implemented_the_paper_pay_attention/</link>
      <description><![CDATA[      为了尝试更有趣的模型架构，我在 Tinygrad 中实现了 gMLP！ 如果有人想提供一些反馈，将受到欢迎。  [存储库]：https://github.com/EthanBnntt/tinygrad-gmlp [安装]：pip install gmlp_tinygrad [原始论文]：https://doi.org/10.48550/ARXIV.2105.08050  显示 gMLP 架构的图表    提交人    /u/the-wonderful-world   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fa5kop/p_this_week_i_implemented_the_paper_pay_attention/</guid>
      <pubDate>Fri, 06 Sep 2024 03:29:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 讨论 ML 架构/训练模型的状态。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fa1z1w/d_disscussion_on_the_state_of_ml/</link>
      <description><![CDATA[自从几年前了解到脉冲神经网络 (SNN) [在这篇文章中，我将专门讨论 LIF] 以来，它就一直让我着迷，更具体地说是：计算和存储的效率。 对于那些不了解 LIF 的人来说，它们的工作原理是将一个值积分到电位中并减去一个泄漏，然后将其与阈值进行比较；如果超过阈值，神经元就会触发布尔值“true”并重置电位（有时会实施不应期，但这不是必需的），否则，它会触发“false”并保持电位。  计算和存储效率：SNN 执行加法和减法运算。在其他网络架构中，通常使用浮点数，因为您需要进行乘法和加法，由于触发的布尔状态，您可以简化输入电流以对尖峰神经元的权重求和，因为没有使用乘法，您还可以进一步优化并完全放弃浮点数并使用定点值。例如，如果您想将权重 15.2 存储为缩放因子为 10 的 8 位整数；您将存储 152。这不会改变任何东西，因为 (10+10)/10 = 1+1。   我想讨论的另一件事是，为什么（至少据我所知，如果我错了，请纠正我）AI 模型在需要重新训练以变得更大（想想 GPT）时会从头开始重新训练，而不是在使用随机参数初始化的模型中添加更多每层节点/层，同时保持其他参数不变以保留过去的训练，然后使用修改后的架构重新训练。既然您已经弄清楚了大多数事情，这不会减少所需的训练周期数吗？还是他们不这样做的原因是什么而我不知道？ 顺便说一句。是否有人尝试过通过采用模型、在一层中扩展向量并将两个模型连接起来来“合并”两个模型，类似于两个大脑半球的交流方式？    提交人    /u/Scoffpickle   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fa1z1w/d_disscussion_on_the_state_of_ml/</guid>
      <pubDate>Fri, 06 Sep 2024 00:25:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 HuggingFace 的开源 LLM 检索增强生成管道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9uvn9/p_retrieval_augmented_generation_pipeline_using/</link>
      <description><![CDATA[查看详细的 LlamaIndex 快速入门教程，使用 Qdrant 作为矢量存储和 HuggingFace 进行开源 LLM。 https://www.youtube.com/watch?v=Ds2u4Plg1PA    提交人    /u/trj_flash75   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9uvn9/p_retrieval_augmented_generation_pipeline_using/</guid>
      <pubDate>Thu, 05 Sep 2024 19:19:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从检索增强生成中得到的经验教训</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9tvg7/p_lessons_from_retrieval_augmented_generation/</link>
      <description><![CDATA[我在我的组织中实施了 Rag，并刚刚写了一篇关于我们在这里学到的东西的博客： https://www.b-yond.com/post/transforming-telco-troubleshooting-our-journey-building-telcogpt-with-rag 希望它对这个领域的人们有所帮助。涵盖 rag 评估（ragas）、sql db、langchain 代理与链、weaviate 矢量 db、混合搜索、重新排名等。 有关排名和混合搜索的一些其他见解如下： https://www.linkedin.com/posts/drzohaib_transforming-telco-troubleshooting-our-journey-activity-7232072089837486081--Le1?utm_source=share&amp;utm_medium=member_android   由    /u/purposefulCA  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9tvg7/p_lessons_from_retrieval_augmented_generation/</guid>
      <pubDate>Thu, 05 Sep 2024 18:38:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 带独立性约束的 VAE</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9sxli/d_vae_with_independence_constraints/</link>
      <description><![CDATA[我对 VAE 感兴趣，它允许通过添加一些约束来主动塑造潜在空间。 我设想类似这样的做法：指定 z 的某些部分和一个度量 m，并确保它们是独立的，即潜在空间的特定部分不会对 m 所描述的特征产生任何影响。 你能推荐一些可能涉及类似问题的论文吗？    提交人    /u/stardiving   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9sxli/d_vae_with_independence_constraints/</guid>
      <pubDate>Thu, 05 Sep 2024 17:59:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] Segment Anything 2 (SAM2) 的开源应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9rv7m/p_opensource_app_for_segment_anything_2_sam2/</link>
      <description><![CDATA[大家好， 我很高兴与大家分享我们一直在研究的一个开源项目：Meta 的 Segment Anything 2 (SAM2) 模型的功能演示。 主要特点：  在 GPU 上运行的 FastAPI 后端（在 NVIDIA T4 上测试） 基于 React 的前端，易于交互 支持视频分割  技术堆栈：  后端：Python、FastAPI、PyTorch 前端：React、TypeScript  该项目旨在为研究人员和开发人员提供一种便捷的方式来试验 SAM2。这项工作正在进行中，我正在积极寻找贡献者来帮助改进和扩展其功能。 您可以在此处找到该项目：https://github.com/streamfog/sam2-app 我很乐意听到您的想法、建议或您可能有的任何问题。如果您有兴趣，请随时查看并做出贡献！    提交人    /u/kevinpl07   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9rv7m/p_opensource_app_for_segment_anything_2_sam2/</guid>
      <pubDate>Thu, 05 Sep 2024 17:16:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如果自我注意力不是最重要的事情怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9nefc/r_what_if_selfattention_isnt_the_endall_beall/</link>
      <description><![CDATA[关于 transformer 中的信息丢失，这是一个有趣的替代方案。很想听听你对此的看法！ 用于语言生成和检索的掩码混合器 https://arxiv.org/html/2409.01482v1    提交人    /u/Status-Shock-880   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9nefc/r_what_if_selfattention_isnt_the_endall_beall/</guid>
      <pubDate>Thu, 05 Sep 2024 14:06:55 GMT</pubDate>
    </item>
    <item>
      <title>波士顿的人工智能、长寿和认知 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9n9zk/ai_longevity_cognition_in_boston_d/</link>
      <description><![CDATA[大家好！今天 9 月 5 日下午 4:30 至晚上 8 点，我们将在剑桥肯德尔广场（麻省理工学院附近）的 Aethos Station 举办一场关于人工智能促进长寿和认知增强的活动。欢迎所有好奇的人，无论您是科学家、工程师还是学生。希望在那里见到你并学到新东西！请在此处免费回复：https://lu.ma/hellothere    提交人    /u/ekkolapto1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9n9zk/ai_longevity_cognition_in_boston_d/</guid>
      <pubDate>Thu, 05 Sep 2024 14:01:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 探索是解锁更好的推荐系统的关键吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9m33i/r_is_exploration_the_key_to_unlocking_better/</link>
      <description><![CDATA[Google DeepMind 的研究人员最近发表了一篇富有洞察力的论文，深入探讨了推荐平台内探索的长期好处。他们认为，虽然短期指标可能无法立即反映优势，但探索可以通过扩大内容语料库来显著增强长期用户体验。  我们在本文中探讨了详细信息：https://www.shaped.ai/blog/is-the-key-to-unlocking-better-user-experiences-in-recommender-systems-found-in-exploration    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9m33i/r_is_exploration_the_key_to_unlocking_better/</guid>
      <pubDate>Thu, 05 Sep 2024 13:09:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找 LLM 作品的云提供商</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9i6f1/d_looking_for_cloud_provider_for_llm_works/</link>
      <description><![CDATA[大家好， 我正在研究一些 LLM 的东西——主要是微调和相关实验。这只是为了个人项目和概念验证工作，所以我正在寻找具有成本效益的选择，因为它是自掏腰包的。 我用过 Runpod 和 Lambda，但通常它们的 H100 都缺货。我也偶然发现了 GreenNode，但它似乎很新，而且我没有发现太多关于它的反馈。 还有其他您有过良好体验的提供商吗？很想听听您的想法！    提交人    /u/SquirrelEffective   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9i6f1/d_looking_for_cloud_provider_for_llm_works/</guid>
      <pubDate>Thu, 05 Sep 2024 09:24:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您最喜欢的免费嵌入模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f97tmh/d_what_is_your_favorite_embedding_model_that_is/</link>
      <description><![CDATA[寻找一个可以完成这项工作的小模型（尺寸 &lt; 1k）。我正在看排行榜 https://huggingface.co/spaces/mteb/leaderboard 。有什么建议吗？    提交人    /u/keepmybodymoving   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f97tmh/d_what_is_your_favorite_embedding_model_that_is/</guid>
      <pubDate>Wed, 04 Sep 2024 23:24:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 存储大型数据集的有效方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f951p8/d_efficient_way_to_store_large_datasets/</link>
      <description><![CDATA[我正在收集用于模仿学习 (RL) 的轨迹，每条轨迹大约有 1500 个时间步长，由 4 个大约 600x600 像素的图像流组成。显然，随着轨迹数量的增加，数据集大小会极快地增长。 有哪些好的库可以有效地（就磁盘空间而言）存储此类数据？我尝试使用 9 级 gzip 压缩的 h5py，但文件仍然太大。有没有更好的选择？ 保存和加载时间并不重要。 大多数在线资源旨在有效地加载大型数据集或在内存中处理它们，这与我的问题无关。 我已经使用 uint8 作为 rgb 流的数据类型。 更新：我最终通过 scikit-video 使用了有损视频压缩。这样，在将原始帧存储在数组中时，文件大小只有 2MB，而不是近 2GB。重建损失的直方图显示，大多数像素差异都在低个位数范围内，这在我的情况下不是问题，因为我无论如何都会通过噪声应用域随机化。    提交人    /u/CherubimHD   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f951p8/d_efficient_way_to_store_large_datasets/</guid>
      <pubDate>Wed, 04 Sep 2024 21:24:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 01 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>