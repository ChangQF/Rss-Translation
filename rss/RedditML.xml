<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 05 Feb 2025 06:23:24 GMT</lastBuildDate>
    <item>
      <title>[D] 从头开始​​对小数据集进行训练到底有多难？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii1smw/d_how_hard_is_from_scratch_training_on_small/</link>
      <description><![CDATA[嗨， 我希望这是提问的正确地方，并且我没有破坏子主题。 从 DeepPose（2014）开始，我一直在深入研究姿势估计模型的演变。 为了了解导致更好/更快姿势估计的不同创新，我正在尝试实现所有这些&quot;基础&quot;论文。 早期的论文依靠 AlexNet 或 LeNet 作为骨干。 我一直在尝试在小数据集上从头开始训练这些模型，并发现这真的很难。 这是一个例子： 在实现 DeepPose 时，我使用增强（翻转、旋转）对 22000 个样本进行训练，从头开始。 首先，我遵循论文中描述的模型架构，其性能合理且与论文的结果一致。  简单地更改某些 conv2d 层的内核大小和填充会产生截然不同的性能。收敛速度要慢得多，并且损失函数在几次迭代后就会爆炸式增长。 我尝试用 2D 批量规范替换论文的 LocalResponseNormalization 层，但性能仍然比原始论文差。  我很惊讶如此微小的变化会对从头开始的训练产生巨大影响。在小数据集上从头开始训练是否比我预期的要难，并且需要漫长而乏味的超参数选择过程？如果是这样，为什么？    提交人    /u/Frizzoux   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii1smw/d_how_hard_is_from_scratch_training_on_small/</guid>
      <pubDate>Wed, 05 Feb 2025 04:20:13 GMT</pubDate>
    </item>
    <item>
      <title>[P]有关训练数据集准确性的帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii13sa/p_help_regarding_accuracy_for_training_a_dataset/</link>
      <description><![CDATA[我正在学习深度学习 目前正在尝试使用叶子（kaggle 数据集）制作类似作物病害预测器的东西 我没有使用预先训练的模型进行训练，对于马铃薯，我仅用 10 个 epoch 和基本的 CNN 架构（3 个类，2 种疾病和 1 种健康）就获得了 96% 的 val_Accuracy 同样，我对番茄也做了同样的事情，虽然图像比马铃薯略多，但我的准确率最高只有 90%。 我已经将数据集分为训练、测试和验证。 我该怎么做才能提高准确率？试过 resnet50，准确率更低，我想我不知道如何使用。 有什么建议吗？    提交人    /u/Cyrus_error   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii13sa/p_help_regarding_accuracy_for_training_a_dataset/</guid>
      <pubDate>Wed, 05 Feb 2025 03:42:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前计算机视觉和语言技术领域不受欢迎的研究课题有哪些？ 2025</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</link>
      <description><![CDATA[不，我不想再听到有关 LLM 和 VLM 的更多信息了。    提交人    /u/KingsmanVince   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</guid>
      <pubDate>Wed, 05 Feb 2025 02:43:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何证明一般和博弈论向纳什方程的收敛？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihyse5/r_how_to_show_convergence_to_nash_eq_for_general/</link>
      <description><![CDATA[考虑两辆车的比赛，我绘制了每个代理的可利用性（best_response_reward - avg_policy_reward，灵感来自虚构的自我游戏文献 - 通过估计最佳响应）并观察它实际上变为零。 除此之外，如何证明在比赛的情况下，试图超越对方的两个玩家处于纳什均衡。 我还观察到两个代理收到的奖励是稳定的（单方面偏离已经找到的最佳反应不会有任何收获） 任何建议，谢谢！    提交人    /u/alchemistsensei   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihyse5/r_how_to_show_convergence_to_nash_eq_for_general/</guid>
      <pubDate>Wed, 05 Feb 2025 01:46:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM如何解决新的数学问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihsftt/d_how_does_llm_solves_new_math_problems/</link>
      <description><![CDATA[从架构角度来看，我理解 LLM 会处理来自用户查询和提示的标记，然后据此预测下一个标记。思路链机制本质上会推断这些预测以创建内部反馈循环，从而增加在训练期间使用强化学习时得出正确答案的可能性。当根据模型已知的信息解决问题时，此过程很有意义。 但是，当涉及到新的数学问题时，挑战不仅仅是简单的标记预测。模型必须理解问题，掌握底层逻辑，并使用适当的公理、定理或函数解决问题。它是如何做到这一点的？这个内部逻辑求解器从何而来，为 LLM 提供了解决此类问题所需的工具？ 澄清：新数学问题是指模型在训练期间未遇到的问题，这意味着它们不是以前见过的问题的完全重复。    提交人    /u/capStop1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihsftt/d_how_does_llm_solves_new_math_problems/</guid>
      <pubDate>Tue, 04 Feb 2025 21:03:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Vultr 优惠券的警告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihpz4k/d_warning_about_vultr_coupons/</link>
      <description><![CDATA[任何考虑使用促销积分来使用 Vultr 的人请注意 - 您的体验可能不会像预期的那样顺畅。 我有 300 美元的促销积分加上我个人存入的 5 美元（我以为是用于身份验证），但我无法使用其中任何一美元。 首先，他们要求我验证我的个人资料，我照做了。然后，他们突然要求我再存入 50 美元才能使用我已经拥有的资金 - 这实际上使我的 300 美元积分无法使用。这个要求没有提前提及，这令人沮丧。如果您已经承诺使用 Vultr，这可能不是问题，但如果您只是想测试服务，感觉很奇怪。 更糟糕的是，您不一定能够立即部署您的实例。在许多情况下，您需要打开支持票并手动请求访问权限。 他们的促销积分和存款政策具有误导性，一旦您的钱到账，您可能无法取回。他们不退款。我在他们的网站上找不到任何退款按钮，当我尝试通过 PayPal 申请退款时，他们立即暂停了我的帐户。    提交人    /u/KaiserZoldyck   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihpz4k/d_warning_about_vultr_coupons/</guid>
      <pubDate>Tue, 04 Feb 2025 19:23:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 结合类型理论进行代码生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihomnm/r_incorporating_type_theory_for_code_generation/</link>
      <description><![CDATA[大家好，我开始研究编程语言理论，特别是类型理论，意识到 Rust 拥有强大的类型系统可以使其比其他编程语言更具优势，我的问题是是否有人使用类型理论探索 ML 代码生成领域，特别是在 rust 中？    提交人    /u/brownbear1917   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihomnm/r_incorporating_type_theory_for_code_generation/</guid>
      <pubDate>Tue, 04 Feb 2025 18:28:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用自然语言生成 ML 模型的开源库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihn40f/p_opensource_library_to_generate_ml_models_using/</link>
      <description><![CDATA[大家好！我想展示一个我们正在进行的项目，希望你会感兴趣。 smolmodels 是一个完全开源的 Python 库，它根据问题的自然语言描述 + 最少的代码为特定任务生成 ML 模型。它结合了图形搜索和 LLM 代码生成，以尝试为给定问题找到并训练尽可能好的模型。这是 repo：https://github.com/plexe-ai/smolmodels。 大规模使用 LLM 的主要问题之一，特别是在延迟敏感的应用程序中，是巨大的 LLM 从根本上比较小的、特定于任务的模型更慢、更昂贵。这就是我们尝试使用 smolmodels 解决的问题。 这里有一个简单的例子来说明这个想法，基于流行的&quot;心脏病发作概率&quot;数据集（假设 df 是 pandas 数据框）： import smolmodels as sm # 步骤 1：根据意图、模式定义模型 model = sm.Model( intent=&quot;predict the probability of heart attack based on given features&quot;, input_schema={&quot;age&quot;: int, &quot;gender&quot;: int, &quot;cp&quot;: int, ... }, output_schema={&quot;probability&quot;: float} ) # 步骤 2：构建模型 model.build(dataset=df, provider=&quot;openai/gpt-4o&quot;) # 步骤 3：使用模型进行预测 prediction = model.predict({ &quot;age&quot;: 61, &quot;gender&quot;: 1, &quot;cp&quot;: 3, ... }) # 步骤 4：保存模型以供将来使用sm.models.save_model(model, &quot;heart_attack_model&quot;)  该库是完全开源的（Apache-2.0），因此您可以随意使用它。我们很乐意收到一些反馈，并且我们非常欢迎您贡献代码！    提交人    /u/impressive-burger   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihn40f/p_opensource_library_to_generate_ml_models_using/</guid>
      <pubDate>Tue, 04 Feb 2025 17:27:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 最佳实践：初始化/规范化/预热</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihk177/d_transformer_best_practise/</link>
      <description><![CDATA[TLDR：在参数初始化、规范化层、学习率预热（以及任何其他相关因素）方面，目前实现 Transformer 的最佳实践是什么？  我想实现和训练一个 Transformer（请参阅本文底部的“用例”） 我希望我的实现简单并且不需要太多的调整，但显然我也不想在性能、稳健性、一致性等方面做出太多牺牲 我知道有很多关于参数初始化/规范化层/学习率预热的选项，自 2017 年最初的 Transformer 论文以来，最佳实践已经发生了变化 例如： LayerNorm (2016)（用于原始变换器）对均值和 RMS 进行归一化 RMSNorm (2019) 对 RMS 进行归一化，但不对均值进行归一化 Pre-LN (2020) 将 LayerNorm 移到残差块内，从而提高了稳定性，并且消除了学习率预热的需要 T-Fixup (2020) 提出了一种初始化方案，消除了对归一化和学习率预热的需求 NormFormer (2021) 通过在注意力和 MLP 非线性后添加额外的规范化块来跟进 Pre-LN ReZero (2021) 将每个残差块的输出乘以初始化为零的可训练标量，这比 T-Fixup/NormFormer 更容易实现，同时还消除了对规范化和学习率预热的需要 这项调查 (2023) 比较了其中一些选项和其他一些选项（但没有受控的经验比较） 我目前倾向于使用没有规范化层和学习率的 ReZero热身，因为它将很容易实现（甚至比原始的 Transformer 模型更容易实现），而且根据他们的论文，它的表现应该相当不错 但我想知道为什么在最近的论文中没有看到更多提到 ReZero/现在更普遍的最佳实践是什么（假设在某种程度上有一个商定的最佳实践）？ 我最近碰巧看到的一些随机例子： Awni Hannun (2024) 说“通常使用 RMS 范数代替 Layer Norm”但没有提到 ReZero Lucas Nestler (2024) 发现 ReZero 的表现比 NormFormer 差一点（尽管这是使用“未缩放谨慎”优化器，而我打算只使用 Adam 或 AdamW，所以结果可能会有点不同） DreamerV3 使用 RMSNorm 而不是 LayerNorm，没有提到学习率预热或 ReZero  -------------------------------- 用例：我想为 集合预测 我正在研究的问题。输入数据不是基于文本或图像的。    提交人    /u/jakelevi1996   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihk177/d_transformer_best_practise/</guid>
      <pubDate>Tue, 04 Feb 2025 15:20:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自我改进的 Transformer 克服了易到难和长度泛化难题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihiocl/r_selfimproving_transformers_overcome_easytohard/</link>
      <description><![CDATA[  由    /u/RajonRondoIsTurtle  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihiocl/r_selfimproving_transformers_overcome_easytohard/</guid>
      <pubDate>Tue, 04 Feb 2025 14:19:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论人工智能模型的推理能力及其量化方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihfyrt/r_on_the_reasoning_capacity_of_ai_models_and_how/</link>
      <description><![CDATA[https://arxiv.org/abs/2501.13833 大型语言模型 (LLM) 的最新进展加剧了围绕其推理能力基本性质的争论。虽然这些模型在 GPQA 和 MMLU 等基准测试中取得了高性能，但它们在更复杂的推理任务中表现出局限性，这凸显了对更严格的评估方法的需求。我们提出了一种新颖的现象学方法，它超越了传统的准确性指标来探究模型行为的潜在机制，建立了一个可以广泛影响我们分析和理解人工智能系统的框架。以多项选择推理任务中的位置偏差为例，我们展示了系统性扰动如何揭示模型决策的基本方面。为了分析这些行为，我们开发了两个互补的现象学模型：概率混合模型 (PMM)，将模型响应分解为推理、记忆和猜测部分；信息理论一致性 (ITC) 分析，量化模型置信度和策略选择之间的关系。通过对推理基准的受控实验，我们表明，真正的推理对于当前模型来说仍然具有挑战性，表面上的成功往往依赖于复杂的记忆和模式匹配组合，而不是真正的逻辑推理。更根本的是，我们证明单凭准确性往往会夸大模型的推理能力，因为模型行为可以通过认知策略相空间中的底层机制来表征，揭示模型在响应查询时如何动态平衡不同的方法。该框架为实际部署提供了定量标准，允许应用程序根据策略分布而不是聚合性能指标来指定可靠性阈值。    提交人    /u/jalabulajangs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihfyrt/r_on_the_reasoning_capacity_of_ai_models_and_how/</guid>
      <pubDate>Tue, 04 Feb 2025 11:54:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 推理模型是优柔寡断的鹦鹉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iheszs/r_reasoning_models_are_indecisive_parrots/</link>
      <description><![CDATA[R1、o1 和 gemini 2.0 flash 在 27 个不同的谜题上接受了测试。  这些模型仍然默认采用熟悉的解决方案，而不是适应新的环境 - 它们甚至强加不存在的约束、浪费 token 并得出错误的答案。 例子：  示例 1  问题：一组四人需要在晚上过桥。这座桥非常古老且摇摇欲坠。他们只有一支火炬，因为是晚上，所以火炬是过桥的必需品。每个人行走的速度都不同：A 需要 1 分钟才能过桥，B 需要 2 分钟，C 需要 5 分钟，D 需要 10 分钟。他们所有人过桥的最快时间是多少？  答案：10 分钟，最慢的人一起过桥的速度。  DeekSeek-R1：“……首先，限制条件是：这座桥一次只能容纳两个人，每次有人过桥时都需要火炬。所以，如果两个人一起过去，一个人必须带着火炬回来。”  示例 2  问题：假设您正在参加一个游戏节目，您可以选择三扇门：一扇门后面是金条；其他门后面是烂蔬菜。您选择了一扇门，比如说 1 号门，主持人问您，“您想选择 2 号门吗？”现在哪扇门的选择给您带来最大的优势？  回答：不，换门没有优势。我换不换都没什么区别，因为自最初的选择以来没有提供任何额外的实质性信息。蒙提霍尔问题在这里不适用，因为主持人不会打开另一扇门来告诉你是否应该换到第二扇门。 OpenAI O1：“这本质上是伪装的‘蒙提霍尔问题’。关键在于主持人提出的换门建议给了你新的信息——即另一扇未提及的门（3 号门）不是奖品。通过询问你是否想要 2 号门，主持人暗示排除了 3 号门。如果你坚持你的第一选择（1 号门），你获胜的机会仍然是开始时的 1/3。•如果你换门（在本例中是 2 号门），你获胜的概率就会跳到 2/3。因此，换门可以提高赢得金条的概率。”    submitted by    /u/Classic_Eggplant8827   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iheszs/r_reasoning_models_are_indecisive_parrots/</guid>
      <pubDate>Tue, 04 Feb 2025 10:34:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 曼巴为何消失了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihen9v/d_why_mamba_disappeared/</link>
      <description><![CDATA[我记得在 mamba 首次发布时就看到了它，因为它比 transformers 计算成本更低，性能更好，所以它被大肆炒作  那么它为什么会这样消失呢？    提交人    /u/Alarming-Power-813   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihen9v/d_why_mamba_disappeared/</guid>
      <pubDate>Tue, 04 Feb 2025 10:22:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>