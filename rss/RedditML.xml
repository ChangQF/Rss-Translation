<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 18 Mar 2024 00:57:53 GMT</lastBuildDate>
    <item>
      <title>[项目]MANATEE(lm)：基于语言模型架构的市场分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhc5od/project_manateelm_market_analysis_based_on/</link>
      <description><![CDATA[      我已经开源了一个名为 MANATEE(lm) 的副项目：基于语言模型架构的市场分析，作为 Amazon Web Services (AWS)、加州大学圣地亚哥分校和 Albert-Ludwigs-Universität Freiburg 的 amazon/chronos-t5-large 模型的测试用例，托管在 Hugging Face 上，在 Google Colab 笔记本中 🖥 使用 Polars 用于并行操作，支持跨多个 CPU 内核并发执行数据转换和计算，而 Plotly 用于数据绘图和可视化，此笔记本可能是各个领域时间序列分析的切入点，包括零售、能源、金融、医疗保健、气候科学🌍 链接：https://colab.research.google.com/drive/1Nq28vk9_l0R-53T18HYfRbeGFJoZ_U8E?usp=sharing 时间序列预测80%预测区间   由   提交/u/louisbrulenaudet  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhc5od/project_manateelm_market_analysis_based_on/</guid>
      <pubDate>Sun, 17 Mar 2024 23:28:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] 免费计算训练模型（必须开源）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh8ywk/p_free_compute_to_train_models_must_be_open_source/</link>
      <description><![CDATA[大家好， 我很高兴与大家分享hivetrain.ai 与大家一起。要点如下： 我们用代币奖励参与者，以换取提供计算能力。这些代币已经变得非常有价值，这意味着我们有相当多的人提供计算（我们有 256 个可用插槽，全部已满）。 利用这种计算能力，我们正在训练模型。我们的整个流程是透明的 - 我们的代码是开源的，并且只要我们能够维持，我们目前就会免费提供培训。 如果您有兴趣，可以加入我们的候补名单并请求模型通过我们的网站进行训练 Hivetrain - 训练模型 - 很快，您将能够提交您的数据集，并且可能一些配置细节，我们将为您训练一个模型。目前，我们的限制是可以安装 16GB NVIDIA 卡的型号，但我们计划尽快提高此限制。 （这将取决于人们的兴趣程度） 一些重要的说明。  请注意，我们仍在微调我们的确定项目优先级和授予对我们服务的访问权限的流程 - 所以请告诉我们 - 也欢迎提出想法） 请注意，我们的网站目前面向提供计算能力的网站。不过，更新正在进行中。 如上所述，我们不会要求任何金钱或补偿等。  好吧，一切顺利！   由   提交/u/artofproduct  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh8ywk/p_free_compute_to_train_models_must_be_open_source/</guid>
      <pubDate>Sun, 17 Mar 2024 21:19:36 GMT</pubDate>
    </item>
    <item>
      <title>xAI 发布 Grok-1 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh7yc4/xai_releases_grok1_n/</link>
      <description><![CDATA[ 我们正在发布大型语言模型 Grok-1 的基本模型权重和网络架构。 Grok-1 是一个由 xAI 从头开始​​训练的 3140 亿参数混合专家模型。 这是 Grok-1 预训练阶段的原始基础模型检查点，该阶段于 2023 年 10 月结束。这意味着该模型没有针对任何特定应用程序（例如对话）进行微调。 我们将在 Apache 2.0 许可证下发布权重和架构。 开始使用使用该模型时，请按照 https://github.com/xai-org/grok 中的说明进行操作   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh7yc4/xai_releases_grok1_n/</guid>
      <pubDate>Sun, 17 Mar 2024 20:38:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] Paperlib：一个开源且现代设计的学术论文管理工具。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh63c1/p_paperlib_an_opensource_and_moderndesigned/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh63c1/p_paperlib_an_opensource_and_moderndesigned/</guid>
      <pubDate>Sun, 17 Mar 2024 19:24:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] MOIRAI：Salesforce 的新时间序列基础预测模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh56kz/p_moirai_new_timeseries_foundation_forecasting/</link>
      <description><![CDATA[       由   提交 /u/apaxapax   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh56kz/p_moirai_new_timeseries_foundation_forecasting/</guid>
      <pubDate>Sun, 17 Mar 2024 18:49:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 精馏塔塔顶硫磺预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh4g3r/p_distillation_tower_overhead_sulfur_prediction/</link>
      <description><![CDATA[我正在构建一个神经网络来预测蒸馏塔顶部的硫（以 ppm 为单位）。到目前为止，我尝试对塔参数进行建模（再沸器负荷、底部和顶部塔温度、回流率、塔压力、OH温度、流失率、进料速率、进料中的硫（每周样品）、进料中的硫）底部（也是每周）），但最终得到的数据集太小，在十年内约有 250 个可用点，其中任何具有良好 R2 和 RSME 的模型都完全过度拟合，似乎甚至对于验证数据集 w / 随机 kfold。塔顶硫磺结果通常为 2 次/天。  我的两个问题是： 如果模型在每个数据点上进行训练，k-fold 是否会过度拟合？或者 k 折叠的设计是否使得每个折叠都至少使用不包含该折叠训练数据的模型进行一次验证？我构建的模型用于训练和验证的 R2 为 0.98（0.01 以内），RSME 为 8-10，这是可以接受的。我还没有找到部署模型的好方法来测试，但是我手动插入的一些值没有产生准确的结果。 我正在考虑首先对没有硫的塔进行建模，用几分钟分钟的过程数据，以建立塔顶流量和其余塔操作参数之间的关系，并尝试预测分离效率和下降流量，然后使用该模型进料第二个模型，该模型用于根据进料硫预测塔顶硫、塔顶馏出物：进料比和分离效率（因为分流的紧密程度会影响硫 ppm）。  我是 NN 的新手，我只是一名董事会操作员。工程师并不是只想构建一些可以让我/其他操作员的生活变得更轻松的东西。  我正在使用 JMP 17 pro，你们（流程工程师）在构建模型后如何部署模型？    由   提交/u/thedudear  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh4g3r/p_distillation_tower_overhead_sulfur_prediction/</guid>
      <pubDate>Sun, 17 Mar 2024 18:20:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 医学：有人训练过肺/心脏听诊的开源模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh2ho0/d_medical_anyone_trained_an_open_source_model_on/</link>
      <description><![CDATA[看起来这确实有用且相对容易完成，我的意思是，数据集存在。   由   提交 /u/hmmqzaz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh2ho0/d_medical_anyone_trained_an_open_source_model_on/</guid>
      <pubDate>Sun, 17 Mar 2024 16:59:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM4Decompile：使用大型语言模型反编译二进制代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh23py/r_llm4decompile_decompiling_binary_code_with/</link>
      <description><![CDATA[ 由   提交/u/vegax87  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh23py/r_llm4decompile_decompiling_binary_code_with/</guid>
      <pubDate>Sun, 17 Mar 2024 16:43:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过集群间建模生成代码的神经排名器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgwmzv/r_neural_rankers_for_code_generation_via/</link>
      <description><![CDATA[我们引入了 SRank，这是一种新颖的重新排名策略，用于从代码生成中选择最佳解决方案，重点是对集群间关系进行建模。通过量化集群之间的功能重叠，我们的方法提供了更好的代码解决方案排名策略。实证结果表明，我们的方法在 pass@1 分数上取得了显着的结果。例如，在 Human-Eval 基准测试中，我们在 Codex002 的 pass@1 中实现了 69.66%，WizardCoder 为 75.31%，StarCoder 为 53.99%，CodeGen 为 60.55%，这超越了最先进的解决方案排名方法，例如同一 CodeLLM 上的 CodeT 和 Coder-Reviewer 具有显着的优势（平均提高约 6.1%）。与随机抽样方法相比，我们在 Human-Eval 上平均提高了约 23.07%，在 MBPP 上平均提高了 17.64%。 论文：https://arxiv.org/abs/2311.03366 代码： https://github.com/FSoft-AI4Code/SRank-CodeRanker   由   提交 /u/FSoft_AIC   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgwmzv/r_neural_rankers_for_code_generation_via/</guid>
      <pubDate>Sun, 17 Mar 2024 12:43:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与你的表聊天 - 使用什么来使用开源 LM 进行数据库问答？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgw40p/d_chat_with_your_tables_what_to_use_for_database/</link>
      <description><![CDATA[我正在开发一个项目，我们想要回答数据库中表的简单/中度硬查询。我目前没有资源来微调模型，想尝试开源大型语言模型。 过滤掉之后的所有表格大约有 120 GB，这告诉我需要使用开始时有一个 Text 2 SQL 模型，并可能使用 Spark 执行。我用采样数据尝试了 pandasAI 和 LC 代理，但输出并不是很好（有些失败 如果有人对此进行过研究，我将不胜感激任何线索或评论，或任何研究论文。我需要有关典型管道的外观以及如何提取和传递数据中的多行的指导。    提交者   /u/Parking_Nectarine_19   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgw40p/d_chat_with_your_tables_what_to_use_for_database/</guid>
      <pubDate>Sun, 17 Mar 2024 12:14:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 专用于AI学习环境的游戏引擎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgvgrr/d_game_engine_dedicated_to_ai_learning/</link>
      <description><![CDATA[我最近一直在寻找一种为 RL 训练创建自定义环境的方法，该环境可以轻松地与外部编程语言和框架集成（因此基本上将 NPC 外包）游戏逻辑到游戏本身以外的其他东西，如 pytorch 或 TensorFlow，或您选择的任何其他库）。  长话短说，我遇到过unity ml代理，但它的灵活性非常有限（你只能微调一些算法的超参数），而且自上次unity以来，设置真的很草率+我对使用它有点怀疑。 Nvidiaomniverse + Isaac Gym 仅适用于高度精确的物理环境，你需要大量的 GPU 和精确的模型来运行它，但这不是我想要的东西。我可以扭转它足以使其实现简单的游戏，但这将是一个strech 除此之外，我只找到了几个库，但没有一个真正匹配接近我想要的 ​ 我设想的是一个改进的 godot 引擎，上面有一个框架，集成了 godot 和 python 数据传输和同步。您应该能够更改引擎中的对象参数，并且应该将其映射到 python 代码，如果 python 没有为游戏内代理返回特定的匹配模式，则会出现错误 &lt; p&gt;你知道有什么与我所描述的类似的事情吗？    由   提交/u/DeadProgrammer8785   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgvgrr/d_game_engine_dedicated_to_ai_learning/</guid>
      <pubDate>Sun, 17 Mar 2024 11:36:51 GMT</pubDate>
    </item>
    <item>
      <title>[D]分布式训练策略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgulqe/d_distributed_training_strategy/</link>
      <description><![CDATA[嗨，我想知道如何使用不同的“分布式训练策略”微调 Mixtral。 我可以使用 4* A100 (40Gb)，并且想要尝试不同的策略，例如对模型进行分片并在每个 GPU 上放置 2 个专家层、使用 QLoRA 量化模型，以及在 4 个 GPU 上使用数据并行性。 我可以使用 4* A100 (40Gb)，并且想要尝试不同的策略，例如对模型进行分片并在每个 GPU 上放置 2 个专家层，或者使用以下方法量化模型QLoRA，并在 4 个 GPU 上使用数据并行性。   由   提交 /u/Thick-brain-dude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgulqe/d_distributed_training_strategy/</guid>
      <pubDate>Sun, 17 Mar 2024 10:40:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] Mixture-of-LoRA：大型语言模型的高效多任务调优</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgub6e/r_mixtureofloras_an_efficient_multitask_tuning/</link>
      <description><![CDATA[ 由   提交/u/hardmaru  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgub6e/r_mixtureofloras_an_efficient_multitask_tuning/</guid>
      <pubDate>Sun, 17 Mar 2024 10:20:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我不明白反向传播如何在稀疏门控 MoE 上工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgmpmf/d_i_dont_understand_how_backprop_works_on/</link>
      <description><![CDATA[我不明白反向传播如何在稀疏门控 MoE 上工作 在 LLM 的背景下，假设你有 n 个专家，并且您为每个令牌选择了前 k 个。 在训练期间，门网络可能完全错误，并且将正确的专家排除在所选的 k 之外。然而，由于没有使用正确的专家，因此门没有机会增加正确专家的权重。 换句话说，在背景期间，仅更新门网络的部分参数，影响前 k 内权重的那些。 我错过了什么吗？   由   提交 /u/Primary-Try8050    reddit.com/r/MachineLearning/comments/1bgmpmf/d_i_dont_understand_how_backprop_works_on/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgmpmf/d_i_dont_understand_how_backprop_works_on/</guid>
      <pubDate>Sun, 17 Mar 2024 02:22:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>