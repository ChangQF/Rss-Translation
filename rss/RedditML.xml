<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 04 Feb 2025 12:32:42 GMT</lastBuildDate>
    <item>
      <title>[R] 多模态法学硕士 (LLM) 中高效思路链推理的隐藏标记表示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihg9lm/r_hidden_token_representations_for_efficient/</link>
      <description><![CDATA[本文介绍了一种更有效的语言模型推理方法，即允许模型内部执行中间推理步骤，而不是明确生成它们。该方法以思路链 (CoT) 提示为基础，但引入了特殊标记，指示推理可以在“幕后”发生的位置。 关键技术点： - 通过添加由特殊标记标记的隐藏推理段来修改标准 CoT - 模型学习将多个推理步骤压缩到这些隐藏部分中，同时保持逻辑流 - 只需对现有 LLM 架构进行极少的更改 - 经过数学、常识和符号推理任务的测试 结果： - 与标准 CoT 相比，输出标记长度减少 40-60% - 保持或提高了跨测试域的准确性 - 对于具有重复或明显中间步骤的问题特别有效 - 适用于简单和复杂的推理链 我认为这对于在效率至关重要的生产环境中部署推理系统尤其有影响。在将输出长度减少一半的同时保持准确性的能力可以使 LLM 推理在实际应用中更加实用。 我认为最有趣的方面是它如何反映人类专家的推理 - 当我们熟悉问题领域时，我们经常会跳过写出显而易见的步骤。这为更自然高效的 AI 推理系统指明了一条道路。 TLDR：新方法允许语言模型在内部执行一些推理步骤，而不是写出所有内容，在保持准确性的同时将输出长度缩短约 50%。可以使 LLM 推理在生产中使用更加实用。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihg9lm/r_hidden_token_representations_for_efficient/</guid>
      <pubDate>Tue, 04 Feb 2025 12:13:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论人工智能模型的推理能力及其量化方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihfyrt/r_on_the_reasoning_capacity_of_ai_models_and_how/</link>
      <description><![CDATA[https://arxiv.org/abs/2501.13833 大型语言模型 (LLM) 的最新进展加剧了围绕其推理能力基本性质的争论。虽然这些模型在 GPQA 和 MMLU 等基准测试中取得了高性能，但它们在更复杂的推理任务中表现出局限性，这凸显了对更严格的评估方法的需求。我们提出了一种新颖的现象学方法，它超越了传统的准确性指标来探究模型行为的潜在机制，建立了一个可以广泛影响我们分析和理解人工智能系统的框架。以多项选择推理任务中的位置偏差为例，我们展示了系统性扰动如何揭示模型决策的基本方面。为了分析这些行为，我们开发了两个互补的现象学模型：概率混合模型 (PMM)，将模型响应分解为推理、记忆和猜测部分；信息理论一致性 (ITC) 分析，量化模型置信度和策略选择之间的关系。通过对推理基准的受控实验，我们表明，真正的推理对于当前模型来说仍然具有挑战性，表面上的成功往往依赖于复杂的记忆和模式匹配组合，而不是真正的逻辑推理。更根本的是，我们证明单凭准确性往往会夸大模型的推理能力，因为模型行为可以通过认知策略相空间中的底层机制来表征，揭示模型在响应查询时如何动态平衡不同的方法。该框架为实际部署提供了定量标准，允许应用程序根据策略分布而不是聚合性能指标来指定可靠性阈值。    提交人    /u/jalabulajangs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihfyrt/r_on_the_reasoning_capacity_of_ai_models_and_how/</guid>
      <pubDate>Tue, 04 Feb 2025 11:54:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 具有多个参考模型的 KL 正则化 RLHF 的理论分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihfxc7/r_theoretical_analysis_of_klregularized_rlhf_with/</link>
      <description><![CDATA[https://arxiv.org/abs/2502.01203 最近将大型语言模型 (LLM) 与人工反馈对齐的方法主要依赖于单个参考模型，这限制了多样性、模型过度拟合，并且未充分利用各种可用的预训练模型。通过拓宽视角、减少偏见和利用各种开源 LLM 的优势，结合多个参考模型有可能解决这些限制。然而，将多个参考模型集成到强化学习与人工反馈 (RLHF) 框架中带来了重大的理论挑战，特别是在反向 KL 正则化中，实现精确解仍然是一个悬而未决的问题。本文提出了反向 KL 正则化 RLHF 中多参考模型问题的第一个 \emph{精确解}。我们引入了一个全面的理论框架，其中包括严格的统计分析并提供样本复杂度保证。此外，我们将分析扩展到前向 KL 正则化的 RLHF，为多种参考场景中的样本复杂度要求提供了新的见解。我们的贡献为更先进、适应性更强的 LLM 对齐技术奠定了基础，从而能够有效地使用多个参考模型。这项工作为开发理论上合理且更适合现代 AI 生态系统挑战的对齐框架铺平了道路。    提交人    /u/jalabulajangs   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihfxc7/r_theoretical_analysis_of_klregularized_rlhf_with/</guid>
      <pubDate>Tue, 04 Feb 2025 11:52:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 推理模型是优柔寡断的鹦鹉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iheszs/r_reasoning_models_are_indecisive_parrots/</link>
      <description><![CDATA[R1、o1 和 gemini 2.0 flash 在 27 个不同的谜题上接受了测试。  这些模型仍然默认采用熟悉的解决方案，而不是适应新的环境 - 它们甚至强加不存在的约束、浪费 token 并得出错误的答案。 例子：  示例 1  问题：一组四人需要在晚上过桥。这座桥非常古老且摇摇欲坠。他们只有一支火炬，因为是晚上，所以火炬是过桥的必需品。每个人行走的速度都不同：A 需要 1 分钟才能过桥，B 需要 2 分钟，C 需要 5 分钟，D 需要 10 分钟。他们所有人过桥的最快时间是多少？  答案：10 分钟，最慢的人一起过桥的速度。  DeekSeek-R1：“……首先，限制条件是：这座桥一次只能容纳两个人，每次有人过桥时都需要火炬。所以，如果两个人一起过去，一个人必须带着火炬回来。”  示例 2  问题：假设您正在参加一个游戏节目，您可以选择三扇门：一扇门后面是金条；其他门后面是烂蔬菜。您选择了一扇门，比如说 1 号门，主持人问您，“您想选择 2 号门吗？”现在哪扇门的选择给您带来最大的优势？  回答：不，换门没有优势。我换不换都没什么区别，因为自最初的选择以来没有提供任何额外的实质性信息。蒙提霍尔问题在这里不适用，因为主持人不会打开另一扇门来告诉你是否应该换到第二扇门。 OpenAI O1：“这本质上是伪装的‘蒙提霍尔问题’。关键在于主持人提出的换门建议给了你新的信息——即另一扇未提及的门（3 号门）不是奖品。通过询问你是否想要 2 号门，主持人暗示排除了 3 号门。如果你坚持你的第一选择（1 号门），你获胜的机会仍然是开始时的 1/3。•如果你换门（在本例中是 2 号门），你获胜的概率就会跳到 2/3。因此，换门可以提高赢得金条的概率。”    submitted by    /u/Classic_Eggplant8827   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iheszs/r_reasoning_models_are_indecisive_parrots/</guid>
      <pubDate>Tue, 04 Feb 2025 10:34:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 曼巴为何消失了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihen9v/d_why_mamba_disappeared/</link>
      <description><![CDATA[我记得在 mamba 首次发布时就看到了它，因为它比 transformers 计算成本更低，性能更好，所以它被大肆炒作  那么它为什么会这样消失呢？    提交人    /u/Alarming-Power-813   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihen9v/d_why_mamba_disappeared/</guid>
      <pubDate>Tue, 04 Feb 2025 10:22:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用多模态对比损失与微调 LLaVa 结合 ViT 和 LLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihdk1s/d_combining_a_vit_and_llm_using_multimodal/</link>
      <description><![CDATA[我有一个非常擅长对医学图像进行分类的 ViT，我想将它用于 VLM，以根据图像 + 患者临床信息输出报告。  我的想法是，我可以以某种方式将 ViT 与 llama3 或其他具有医学知识的 LLM 结合起来，就像我假设 LLaVa 或 CLIP 使用多模态对比损失或线性投影所做的那样。这可能更适合添加医学知识，但我的数据集没有全文报告。我只有带有简短文本标题的图像。 但是，我也可以微调 LLaVa 或其他 VLM。我不确定这是否会使 VLM 拥有足够的医学知识，但我认为它会更能够遵循指示（即 VQA）。 有什么好方法可以将真正优秀的医学 ViT 与 LLM 结合起来制作 VLM？或者将 ViT 和 LLM 结合起来不是一个好的选择？    提交人    /u/Amazydayzee   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihdk1s/d_combining_a_vit_and_llm_using_multimodal/</guid>
      <pubDate>Tue, 04 Feb 2025 08:59:51 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 跳跃推理曲线？追踪 GPT-[n] 和 o-[n] 模型在多模态拼图上的推理性能演变</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihd6vl/research_the_jumping_reasoning_curve_tracking_the/</link>
      <description><![CDATA[      o1 比 GPT4o 有所改进，但在简单的抽象推理方面仍然存在很大困难。 o1 的改进几乎是 GPT-4o 计算成本的 750 倍。 https://preview.redd.it/e2nzbrf923he1.png?width=1172&amp;format=png&amp;auto=webp&amp;s=d46bd36ee6d33acc6b828b7f84b833899e6d82ce 无法理解简单模式 https://preview.redd.it/f0lmamae23he1.png?width=2492&amp;format=png&amp;auto=webp&amp;s=70d97e9e8311ca9fb300215400ca23146274e3ab 感知仍然是 o1 的主要瓶颈： https://preview.redd.it/y5ctbbeg23he1.png?width=2380&amp;format=png&amp;auto=webp&amp;s=fd9ea081d188be8d5617b469865deee37d5d7efb 更多详情：https://arxiv.org/abs/2502.01081   由    /u/sgpfc  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihd6vl/research_the_jumping_reasoning_curve_tracking_the/</guid>
      <pubDate>Tue, 04 Feb 2025 08:31:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 联邦学习讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihcyo4/d_discussion_on_federated_learning/</link>
      <description><![CDATA[最近几天一直对联邦学习框架很感兴趣，我一直在为其开发一个 POC 模型，以实现分散式学习。 我想知道其他人的想法，我在这方面确实没有太多专业知识，但我发现使用分散式学习进行无监督学习的概念相当令人着迷。 如果我要开发这样一个框架，会对它有什么期望？    提交人    /u/Critical_Pipe1134   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihcyo4/d_discussion_on_federated_learning/</guid>
      <pubDate>Tue, 04 Feb 2025 08:13:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新型节能框架使神经网络量化性能提升 10 倍以上</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ih95ia/r_novel_energypreserving_framework_achieves_10x/</link>
      <description><![CDATA[我一直在探索基于状态空间变换和能量守恒原理的数学框架，该框架在神经网络量化方面取得了一些有趣的结果。该框架在不同数值格式中表现出一致的改进，令人惊讶的是，在应用于图像和音频量化时也表现出类似的效果。 主要发现： 神经网络量化 (fp32)： - 均方误差 (MSE) 提高 10-12 倍 - 相对误差减少约 3 倍 - 不同数值分布中的表现一致 - 结果适用于 FP8 和 FP16 格式 特定格式的结果： FP8-E4M3：MSE 提高 10.36 倍，相对误差提高 3.22 倍 FP8-E5M2：MSE 提高 11.88 倍，相对误差提高 3.38 倍 FP16：MSE 提高 9.13 倍，相对误差提高 3.01 倍 该框架的有效性源于其独特的数学特性：  变换空间中的出色能量守恒 自然状态空间对齐 自动适应输入分布特性 尺度不变的误差界限  特别有趣的是这些属性如何从统一的数学基础中产生。改进神经网络量化的相同原理在图像和音频处理中也显示出优势： 图像： - 在每通道 5 位的情况下实现与传统方法相似的质量 - 更好地保存颜色关系 - 压缩效率提高约 3% 音频（16 位到 8 位）： - &gt;99.9% RMS 保存 - &gt;96% 能量保存 - 变换空间中的出色状态转换 - 自然处理幅度关系 这是我们对标准量化器的参考实现，与我们的框架相比有更详细的结果： https://pastebin.com/LGm8GAsQ 框架能够在不同领域（神经网络、图像、音频）实现这些改进，这表明在工作中可能存在我们尚未在量化理论中充分探索的基本数学原理。我特别感兴趣的是这些结果的理论意义，以及它们对我们理解降低精度环境中的信息保存的潜在影响。 我在这里专注于实证结果，但我正在进行更全面的数学分析，以了解为什么这些改进会从底层框架中出现。跨域有效性尤其有趣，可能指出状态空间转换和信息保存之间的更深层次联系。 咨询：telesma@mailfence.com    提交人    /u/Telesmi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ih95ia/r_novel_energypreserving_framework_achieves_10x/</guid>
      <pubDate>Tue, 04 Feb 2025 04:07:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有办法按领域查看 CVPR 论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ih50vi/d_is_there_a_way_to_see_cvpr_papers_by_area/</link>
      <description><![CDATA[我想查看前几年在特定主题领域被接受的论文。这些数据可用吗？    提交人    /u/whats-a-monad   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ih50vi/d_is_there_a_way_to_see_cvpr_papers_by_area/</guid>
      <pubDate>Tue, 04 Feb 2025 00:40:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 HuggingFace 问题的 BERT 嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ih2ywl/d_bert_embeddings_using_huggingface_questions/</link>
      <description><![CDATA[我正在尝试查找带有操作码的反汇编文件的 BERT 嵌入。反汇编文件的示例： add move sub ...（等等） 该文件将包含几行操作码。我的目标是找到一个代表整个文件的嵌入向量（用于下游任务，例如分类/聚类）。 对于 BERT，主要有两个部分：标记器和实际的 BERT 模型。我很困惑 512 的上下文大小是用于标记器还是实际模型。我问这个问题的原因是，我可以将所有操作码提供给标记器（可能有数千个操作码），然后将它们分成块（如果需要，可以有一些重叠），然后将每个块提供给 BERT 模型以找到该块的嵌入*吗？或者我应该先将操作码分成块，然后再对它们进行标记？ 这是我目前拥有的代码：```py def tokenize_and_chunk(opcodes, tokenizer, max_length=512, override_percent=0.1): &quot;&quot;&quot; 先将所有操作码标记为子字，然后分成有重叠的块 Args: opcodes (list): 操作码字符串列表 tokenizer: Hugging Face tokenizer max_length (int): 最大序列长度 override_percent (float): 块之间的重叠百分比 返回: BatchEncoding: 包含 input_ids、attention_mask 等。&quot;&quot;&quot; # 使用列表推导将所有操作码标记为子词 all_tokens = [token for opcode in opcodes for token in tokenizer.tokenize(opcode)] # 计算分块参数 chunk_size = max_length - 2 # 考虑[CLS] 和 [SEP] step = max(1, int(chunk_size * (1 - override_percent))) # 使用海象运算符生成重叠块 token_chunks = [] start_idx = 0 while (current_chunk := all_tokens[start_idx:start_idx + chunk_size]): token_chunks.append(current_chunk) start_idx += step # 将标记块转换为模型输入 return tokenizer( token_chunks, is_split_into_words=True, padding=&#39;max_length&#39;, truncation=True, max_length=max_length, return_tensors=&#39;pt&#39;, add_special_tokens=True )  def generate_malware_embeddings(model_name=&#39;bert-base-uncased&#39;, override_percent=0.1): &quot;&quot;&quot; 使用 BERT 和重叠标记块生成嵌入 &quot;&quot;&quot; tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModel.from_pretrained(model_name).eval() embeddings = {} malware_dir = MALWARE_DIR / &#39;winwebsec&#39; for filepath in malware_dir.glob(&#39;*.txt&#39;): # 使用海象运算符读取操作码 with open(filepath, &#39;r&#39;, encoding=&#39;utf-8&#39;) as f: opcodes = [l for line in f if (l := line.strip())] # 标记并分块重叠coded_chunks = tokenize_and_chunk( opcodes=opcodes, tokenizer=tokenizer, max_length=MAX_LENGTH, override_percent=overlap_percent ) # 使用推理模式批量处理所有块 with torch.inference_mode(): output = model(**encoded_chunks) # 计算有效的标记掩码 input_ids =coded_chunks[&#39;input_ids&#39;] valid_mask = ( (input_ids != tokenizer.cls_token_id) &amp; (input_ids != tokenizer.sep_token_id) &amp; (input_ids != tokenizer.pad_token_id) ) # 处理每个块的嵌入 chunk_embeddings = [outputs.last_hidden_​​state[i][mask].mean(dim=0).cpu().numpy() for i, mask in enumerate(valid_mask) if mask.any() ] # 跨块取平均值（无规范化） file_embedding = np.mean(chunk_embeddings, axis=0) if chunk_embeddings \ else np.zeros(model.config.hidden_​​size) embeddings[filepath.name] = file_embedding return embeddings  ``` 如您所见，代码首先对操作码调用 tokenize()，将它们拆分成块（有重叠），然后对所有带有 is_split_into_words=True 标志的块调用标记器的 __call__ 函数。这是正确的方法吗？这会将操作码标记两次吗？ * 另外，我的目标是找到整个文件的嵌入。为此，我计划取所有块的平均嵌入。但对于每个块，我应该取每个标记的平均嵌入吗？或者只取 [CLS] 标记的嵌入？    提交人    /u/_AnonymousSloth   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ih2ywl/d_bert_embeddings_using_huggingface_questions/</guid>
      <pubDate>Mon, 03 Feb 2025 23:07:46 GMT</pubDate>
    </item>
    <item>
      <title>改变旧记忆或过去对话的标记方法是否有助于增加 LLM 的上下文长度？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1igxiqh/would_changing_the_tokenization_method_for_older/</link>
      <description><![CDATA[所以我在考虑标记器并阅读了一些相关资料。我主要想找到一个问题的答案，即 LLM 是否可以同时使用多种不同的标记方法。例如，同时使用单词和子单词标记。或者将单词转换为“词性”，并将其与标记信息一起输入到 LLM 中。无论如何，在此过程中，一个问题突然出现在我的脑海中。能否通过使用更高级别的标记方法以某种方式模拟旧记忆？例如单词级别标记与子单词（或相反）。我假设准确性或能力会相应改变，但大概会影响回忆或上下文长度，对吧？     提交人    /u/TheRealBobbyJones   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1igxiqh/would_changing_the_tokenization_method_for_older/</guid>
      <pubDate>Mon, 03 Feb 2025 19:26:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研究人员使用哪些软件工具来制作这样的神经网络架构？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ig6k3l/d_which_software_tools_do_researchers_use_to_make/</link>
      <description><![CDATA[        提交人    /u/SimpleObvious4048   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ig6k3l/d_which_software_tools_do_researchers_use_to_make/</guid>
      <pubDate>Sun, 02 Feb 2025 20:19:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>