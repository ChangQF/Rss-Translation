<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sun, 09 Feb 2025 03:20:20 GMT</lastBuildDate>
    <item>
      <title>[P]试图使stylegan3发挥作用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1il1dzm/p_stuck_trying_to_get_stylegan3_to_function/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是ML（艺术博士研究员）技术方面的新手，我正在尝试使用Anaconda/cuda在本地设置stylegan3 /msvc/cmake使用4070GPU，因此我可以测试一些我策划的数据集。这让我发疯了！我设置了我的环境。我在依赖关系的矛盾版本上遇到了一些问题，但是我对正确版本进行了编辑，它们似乎在行为。一切看起来都正确，但是当我运行一个命令以生成输出时，我会收到此错误。是因为编译器不再支持或可用吗？我已经尝试了副柯洛特（Copilot）建议的数十个解决方法，但它们只是导致一系列进一步的错误。我错过或做错了什么？   attributeError：模块&#39;distutils&#39;没有属性&#39;_msvcccompiler&#39;     &lt;！ -  sc_on-&gt; ＆＃32;提交由＆＃32; /u/u/scared_ad5929     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1il1dzm/p_stuck_trying_to_get_stylegan3_to_function/</guid>
      <pubDate>Sat, 08 Feb 2025 23:53:59 GMT</pubDate>
    </item>
    <item>
      <title>[p]从划痕ML库（火车从CNN到玩具GPT-2）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ikzdsb/p_fromscratch_ml_library_trains_models_from_cnns/</link>
      <description><![CDATA[在/p&gt; 我构建了一个机器学习库（ github ）完全使用Python和Numpy。然后，我用它来训练一系列型号，包括从经典的CNN，重新注册，RNN和LSTM到现代变形金刚，甚至是玩具GPT-2。动机来自我对如何从头开始建立深度学习模型的好奇心，例如从数学公式来看。我构建了这个项目，不是为了取代Pytorch或Tensorflow等生产就绪的库，而是剥离抽象并揭示机器学习的基本数学。  关键点：     所有内容都是在代码中得出的 - 没有不透明的黑匣子。  api镜像pytorch，因此您可以快速拾取它。 您可以训练CNNS，RNNS ，变形金刚，甚至是GPT模型。 设计/调试的设计多于原始性能。    这里有什么不同？   虽然有许多功能强大的ML库（Tensorflow，Pytorch，Scikit-Learn等），但它们通常将基础数学隐藏在抽象层后面。我相信要真正掌握这些工具，您首先需要了解它们如何从头开始工作。该项目明确地衍生了代码中的所有数学和计算操作，使其成为动手的资源，以加深对神经网络和图书馆建筑的理解：）  检查一下：     github repository     api documentation     by-hand/tree/main/示例“&gt;：探索示例中的gpt-2，CNN，变形金字和lstms之类的模型/文件夹   blog Post ：阅读有关项目的动机，设计和挑战   &lt; P&gt;我很想听听任何想法，问题或建议 - 感谢您检查一下！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/megadragon9     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ikzdsb/p_fromscratch_ml_library_trains_models_models_from_cnns/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ikzdsb/p_fromscratch_ml_library_trains_models_from_cnns/</guid>
      <pubDate>Sat, 08 Feb 2025 22:21:58 GMT</pubDate>
    </item>
    <item>
      <title>[N] IEEE Telepresence 2024和即将举行的2025会议的机器人技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ikxbbv/n_robotics_at_ieee_telepresence_2024_upcoming/</link>
      <description><![CDATA[    nink]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ikxbbv/n_robotics_at_ieee_telepresence_2024_upcoming/</guid>
      <pubDate>Sat, 08 Feb 2025 20:50:54 GMT</pubDate>
    </item>
    <item>
      <title>[d]分类和检索之间的性能差异（Arcface）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iks6ve/d_discrepancy_in_performance_between/</link>
      <description><![CDATA[在/pdf/1801.07698&quot;&gt; https://arxiv.org/pdf/1801.07698 ）为了将图像与非常接近的类别进行分类。 这个想法是在〜500-1000个类上训练然后在训练后，删除分类头，并使用输入样本和参考数据库中的每个样本之间的余弦相似性，以通过检索进行实际分类。这样，我也能够获得属于训练集中从未见过的班级的两个图像之间的相似性（例如，在说话者或面部识别中是这种情况，您显然不能在每个人上训练 但是，在训练期间，我注意到，即使我只有〜60％的验证准确性，如果我直接通过cesine Similiarity进行了检索而不是使用输出逻辑，我已经获得了95％的精度。 。提交由＆＃32; /u/u/lelouchzer12     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iks6ve/d_discrepancy_in_performance_between/</guid>
      <pubDate>Sat, 08 Feb 2025 17:13:55 GMT</pubDate>
    </item>
    <item>
      <title>[r] LLASA：基于乳拉的语音综合的缩放火车时间和推理时间计算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ikq3bz/r_llasa_scaling_traintime_and_inferencetime/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  通过添加语音令牌和特殊语音令牌，可以将Llama变成能够高精度零射击语音克隆的能力的胜任的STT和TTS系统。&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; /p&gt; 这些模型已经销毁了几周，令人印象深刻，现在纸张已经发表了。 https://arxiv.org/pdf/2502.04128    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/anangrybirdman     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ikq3bz/r_llasa_scaling_traintime_and_inferencetime/</guid>
      <pubDate>Sat, 08 Feb 2025 15:44:15 GMT</pubDate>
    </item>
    <item>
      <title>[d]您是否知道具有完美精确度的子线性矢量指数？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ikoe60/d_do_you_know_a_sub_linear_vector_index_with/</link>
      <description><![CDATA[在查询。使用平面索引进行此操作太慢（我每秒至少需要10个查询）。所以我的问题是您知道有任何类型的索引，算法或数学技巧，可以让我在子线性时间中搜索确切的最近邻居？  ps：我不介意从从头开始，我真的需要算法。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/someuserwithwifi     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ikoe60/d_do_you_know_a_sub_linear_vector_index_with/</guid>
      <pubDate>Sat, 08 Feb 2025 14:26:30 GMT</pubDate>
    </item>
    <item>
      <title>[r]了解扩散模型训练参数：有关使ML训练术语混淆及其实现图像输出的研究分析。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iknjxm/r_understanding_diffusion_model_training/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项研究旨在帮助自己和开源社区定义＆amp;可视化效果以下参数对图像生成训练Loras时对图像输出具有： unet学习率，剪辑跳过，网络维度，学习率调度程序，min snr伽玛，噪声偏移，网络alpha，学习率调度程序编号周期      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/cold-dragonfly-144     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iknjxm/r_understanding_diffusion_model_training/</guid>
      <pubDate>Sat, 08 Feb 2025 13:44:01 GMT</pubDate>
    </item>
    <item>
      <title>[P]了解推理LLM：改进或建立推理模型的四种主要方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ikmrxw/p_understanding_reasoning_llms_the_4_main_ways_to/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/u/seraschka     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ikmrxw/p_understanding_reasoning_llms_llms_the_4_main_main_ways_to//]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ikmrxw/p_understanding_reasoning_llms_the_4_main_ways_to/</guid>
      <pubDate>Sat, 08 Feb 2025 13:02:03 GMT</pubDate>
    </item>
    <item>
      <title>[d]是否有可能融合不同的块，甚至整个变压器都可以加速LLM火车和Triton的参考？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ikj9ml/d_is_it_possible_to_fused_different_blocks_even/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我们融合了变压器中的不同块，则中间变量将较少，例如“ feed fortht”并“添加＆amp;规范“线性” ＆＆quot“ softmax＆quot，甚至整个变压器层。这可以减少大量内存使用和计算。 是否有类似的作品或研究？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/logical_divide_3595      [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ikj9ml/d_is_it_possible_to_fused_different_blocks_even/</guid>
      <pubDate>Sat, 08 Feb 2025 09:04:53 GMT</pubDate>
    </item>
    <item>
      <title>[r] AI代理中的安全性自治权衡：风险分析框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ikhjqr/r_the_safetyautonomy_tradeoff_in_ai_agents_a_risk/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了一项结构化分析，反对开发完全自主的AI系统，研究了使人类监督所必需的技术局限性和安全考虑因素。核心方法涉及分析跨多个维度的自主权并建立一个评估AI系统独立性的框架。 关键技术点： - 定义AI自治级别的频谱，从基本自动化到理论完全独立性 - 检查技术障碍 - 为了安全的自主操作，包括鲁棒性，不确定性处理和价值对齐方式 - 分析当前自主系统及其缩放属性中的故障模式 - 提出了用于衡量有意义的人类控制和监督 结果的指标，结果显示了几个关键限制： - 当前AI系统在自动运行时缺乏可靠的安全保证 - 价值学习方法不能可靠地扩展到复杂的决策空间 - 随着系统能力的提高，控制机制变得更加难以指数 - 人类的监督显着降低了灾难性失败模式 我认为这是我认为这研究可以通过专注于增强而不是替换来重塑我们如何处理AI开发的方法。确定的技术障碍表明，我们应该优先考虑强大的人类协作框架，而不是追求完全的自主权。尽管分析主要是理论上的，但它为技术发展和政策决策提供了具体的指导。 我认为，最重要的见解是维持有意义的人类控制不一定限制AI的能力 - 相反，它可能可以对于开发更可靠和有益的系统至关重要。提出的框架可以帮助指导更安全的AI系统的实际开发。  TLDR：技术分析显示完全自主的AI系统面临基本安全和控制挑战。研究表明，在开发强大的人类协作框架时保持人类的监督。  完整摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ikhjqr/r_the_safetyautonomy_tradeoff_in_iai_ai_aigents_a_risk/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ikhjqr/r_the_safetyautonomy_tradeoff_in_ai_agents_a_risk/</guid>
      <pubDate>Sat, 08 Feb 2025 07:03:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] Torchhd：用于高维计算的Python库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ik7rqf/p_torchhd_a_python_library_for_hyperdimensional/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  超维度计算（HDC），也称为矢量符号体系结构，是受大脑如何处理信息启发的替代计算范式。 HDC不是传统的数字计算，而是在高维矢量（称为HyperVectors）上运行，可以实现快速和噪声的学习，通常没有反向传播。  Torchhd是HDC的库，建在Pytorch上。它为研究人员和开发人员提供了一个易于使用的模块化框架，可以在利用GPU加速度的同时尝试使用HDC模型和应用。 Torchhd旨在使原型制作和缩放HDC算法轻松。  github存储库：。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/careativenerd     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ik7rqf/p_torchhd_a_python_library_for_hyperdimensional/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ik7rqf/p_torchhd_a_python_library_for_hyperdimensional/</guid>
      <pubDate>Fri, 07 Feb 2025 22:34:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] GRPO适合8GB VRAM -DeepSeek R1的零食谱</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ik3nkr/p_grpo_fits_in_8gb_vram_deepseek_r1s_zeros_recipe/</link>
      <description><![CDATA[   &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ik3nkr/p_grpo_fits_in_8gb_vram_deepseek_deepseek_deepseek_deepseek_err1s_zeros_zeros_recipe/ DeepSeek R1&#39;s Zero&#39;s recipe&quot; src=&quot;https://external-preview.redd.it/E6uDJHBPBWs1lRLa7r4ngrfpHTyxgGd4s0e5fqmO9Us.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a2f1f8e3abd497362cd6f13ccfb43fdb6df4bdfe&quot; title=&quot;[P] GRPO fits in 8GB VRAM-DeepSeek R1的零食谱“/&gt;    &lt;！ -  sc_off-&gt;  嘿 r/machinelearning 社区！我设法使GRPO适合8GB的VRAM，QWEN 1.5B使用 Unsloth 现在！  LLAMA 3.1 8b拟合13GB的VRAM  和Phi -4 14b拟合15GB的VRAM  - 所有人都可以免费 google colab笔记本 -grpo.ipynb）！   grpo是deepseek r1零的推理的RL食谱奇迹，您现在可以通过UNSPOLT和LORA/QLORA！ /a&gt;证明您可以实现自己的“ aha”使用QWEN2.5（1.5B）的力矩 - 但最少需要2XA100 80GB GPU（160GB VRAM）。现在您可以更有效地做到！脚本没有通过VLLM建议LORA，因为不幸的是，VLLM不能正确地加载Loras  - 我使其正确完成！  unsploth也直接集成了Vllm以进行快速推理，并删除了双重内存副本，可以用于现在，本来可以使用20倍更快的吞吐量！   u/m98789  标记了我在使Grpo在Unsloth中工作的标记，因此这里是！！抱歉，这花了一段时间 - 试图将VLLM和GRPO整合到其中非常复杂！还非常感谢态llama3.1_（8b“&gt; Llama 3.1 8b colab链接 -grpo.ipynb）   phi-4 14b colab链接 -grpo.ipynb）   qwen 2.5 3b colab link  -grpo.ipynb）        Llama 8b需要〜13GB   phi-4 14b需要〜15GB   qwen 3b需要〜7GB      博客以获取更多详细信息： https://unsloth.ai/blog/r1-reasoning    我还为特定的运行绘制了奖励曲线，显示其有效：       另外，如果您没有W＆amp; b，我在Jupyter Notebooks和Colab Works and Colab work and colab work and colab works and poc          也是如此在运行grpo之前，请将其开始修补所有内容：   intsploth import fastflanguagemodel，patchfastrl patchfastrl（&#39;grpo; fastlangugemogemodel）    要使用vllm do安装不舒服（由于TRL需要它，您需要扩散器）： pip安装unsploth vllm扩散器trl    非常感谢！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/danielhanchen     [link]   ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ik3nkr/p_grpo_fits_in_8gb_vram_deepseek_r1s_zeros_recipe/</guid>
      <pubDate>Fri, 07 Feb 2025 19:39:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们需要VAE中的Elbo，为什么不只是从后部取样？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ik17hx/why_do_we_need_the_elbo_in_vaes_why_not_just/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  引入ELBO作为VAE中的优化目标的原始动机是因为评估真实的可能性是棘手的。但是，在Elbo中，您与重建损失期限遇到了同一问题。然后提出蒙特卡洛采样作为一种通过近似重建损失项（带有单个数据点？！）的方式来解决此问题的一种方式。 我很困惑为什么我们不能做同样的事情和近似使用MC采样方法的真实可能性？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/credtz     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ik17hx/why_do_do_we_need_the_elbo_elbo_in_vaes_vaes_vaes_why_not_just/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ik17hx/why_do_we_need_the_elbo_in_vaes_why_not_just/</guid>
      <pubDate>Fri, 07 Feb 2025 17:58:51 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会导致禁止。 鼓励其他人创建新的帖子，以便在此处发布问题！ 线程将一直活着直到下一个，因此请继续发布标题之后的发布。    meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      对于那些寻找工作的人请使用此模板  &lt; p&gt;想要被录用：[位置]，薪水期望：[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简短概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，这个社区是适合有经验的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>