<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 02 Dec 2024 06:27:16 GMT</lastBuildDate>
    <item>
      <title>[D] 创建了一个神经网络模型来预测洛杉矶湖人队巨星安东尼·戴维斯下一场比赛的得分，但还需要改进</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4n1qw/d_created_a_neural_network_model_to_predict_la/</link>
      <description><![CDATA[我使用 Python 中的 SKlearn 简单地创建了模型。它使用所附特征图片中的独立变量。最新的预测是针对刚刚结束的湖人队与爵士队的比赛。你可以看到它预测戴维斯将得到 29.34 分，但他今晚得到了 33 分。 平均而言，它表现不错，但它往往会低估下一场比赛的得分。在折线图中，你可以看到它试图遵循安东尼戴维斯在过去 31 场比赛中的得分的非参数模式。 我在数据集中使用了他上赛季参加的所有比赛以及本赛季迄今为止参加的所有比赛。神经网络模型使用数据集中前 67% 的比赛作为训练集，因此使用最近 33% 的比赛作为测试集来帮助预测连续未观察的比赛。它基本上是一个即时预测模型，我手动进入并添加他最新一场比赛的统计数据以纳入模型并输出下一场比赛的预测。 我在模型中使用以下参数：hidden_​​layer_sizes=(100, 100, 100, 100)，max_iter=2000，random_state=42。这应该调整吗？虽然预测未来很难，但有人对如何改善模型的预测并降低 RMSE 有什么建议吗？我尝试将测试集调整为 20%、20%、35% 等，但平均而言 33% 似乎是一个不错的选择，可以保持 RMSE 最小化。 任何见解都会有所帮助。谢谢。 戴维斯在 12 月 1 日之前参加的最后 31 场比赛 特征在预测爵士队与湖人队比赛（2024 年 12 月 1 日）中的重要性    由   提交  /u/Free-Condition-3842   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4n1qw/d_created_a_neural_network_model_to_predict_la/</guid>
      <pubDate>Mon, 02 Dec 2024 04:44:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在 AWS Sagemaker 中对 DeepAR 框架进行查询</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4gwxy/r_queries_on_deepar_framework_in_aws_sagemaker/</link>
      <description><![CDATA[嗨， 我正在尝试为各种商店实施 deepAr 以预测未来的销售情况（每家商店有约 10k 个不同产品的 SKU）。由于 SKU 的规模庞大，我无法一次性对所有数据进行单次训练。我正在考虑按商店进行训练。  如何在 AWS 中并行进行训练？每个商店的训练过程最多需要 30 分钟； 如何处理数据中不存在的看不见的 SKU？  谢谢。    提交人    /u/skw1990   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4gwxy/r_queries_on_deepar_framework_in_aws_sagemaker/</guid>
      <pubDate>Sun, 01 Dec 2024 23:33:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人思人工智能研究员/住院医师——接受任何新毕业生/入门级人员吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4e0ah/d_anthropic_ai_fellowresidents_any_new/</link>
      <description><![CDATA[你好。入门级或新毕业生是否可以进入 Anthropic 奖学金或住院医师项目？过去被录取的人，你的简历和经历是什么样的？    提交人    /u/geekgeek2019   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4e0ah/d_anthropic_ai_fellowresidents_any_new/</guid>
      <pubDate>Sun, 01 Dec 2024 21:25:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何处理图神经网络训练中不同的特征维度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4dbvi/d_how_to_handle_varying_feature_dimensions_in/</link>
      <description><![CDATA[我有一个关于在图形神经网络训练中处理具有不同特征维度的数据集的问题。例如，在一个训练实例（我们称之为数据集 A）中，节点特征的维度为 4，边特征的维度为 16。在另一个实例（数据集 B）中，节点特征的维度为 5，边特征的维度为 25。其他数据集也可能具有不同的特征维度。 在使用此类数据集训练 GNN 模型时，用于处理每个实例的不同特征维度的标准方法是什么？我将不胜感激任何有关如何处理此问题的指导或方向。谢谢！    提交人    /u/bipulthapa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4dbvi/d_how_to_handle_varying_feature_dimensions_in/</guid>
      <pubDate>Sun, 01 Dec 2024 20:57:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] Promptwright - 使用 LLM（本地或托管）生成大型合成数据集的开源项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4bcz2/p_promptwright_open_source_project_to_generate/</link>
      <description><![CDATA[嘿 r/machinelearning， Promptwright，一个免费使用的开源工具，旨在使用本地大型语言模型或众多托管模型（OpenAI、Anthropic、Google Gemini 等）之一轻松生成合成数据集 此版本中的关键功能： * 支持多个 LLM 提供商：通过 Ollama、VLLM 等与大多数 LLM 服务提供商和 LocalLLM 配合使用 * 可配置的说明和提示：像以前一样在 YAML 中通过脚本定义自定义说明和系统提示。 * 命令行界面：直接从命令行运行生成任务 * 推送到 Hugging Face：使用自动数据集卡和标签将生成的数据集推送到 Hugging Face Hub 这是在最新版本上使用 promptwright 创建的示例数据集： https://huggingface.co/datasets/stacklok/insecure-code/viewer 这是使用“mistral-nemo:12b”从以下模板生成的，但老实说，大多数模型都能很好地执行，即使是小型 1/3b 模型也是如此。 system_prompt：“您是编程助理。您的任务是生成不安全代码的示例，突出显示漏洞，同时保持准确的语法和行为。” topic_tree： args： root_prompt：“跨多语言编程语言的不安全代码示例。” model_system_prompt: &quot;&lt;system_prompt_placeholder&gt;&quot; # 将被 system_prompt 替换 tree_degree: 10 # 广泛覆盖语言（例如 Python、JavaScript、C++、Java） tree_depth: 5 # 特定漏洞的深度层次结构（例如 SQL 注入、XSS、缓冲区溢出）temperature: 0.8 # 高度创造力以多样化示例 provider: &quot;ollama&quot; # LLM 提供者 model: &quot;mistral-nemo:12b&quot; # 模型名称 save_as: &quot;insecure_code_topictree.jsonl&quot; data_engine: args: instructions: &quot;用多种编程语言生成不安全的代码示例。每个示例都应包括对漏洞的简要说明。&quot; system_prompt: &quot;&lt;system_prompt_placeholder&gt;&quot; # 将被 system_prompt 替换 provider: &quot;ollama&quot; # LLM 提供程序 model: &quot;mistral-nemo:12b&quot; # 模型名称temperature: 0.9 # 鼓励示例中的多样性max_retries: 3 # 最多重试 3 次失败提示dataset:creation:num_steps: 15 # 在 10 次迭代中生成示例batch_size: 10 # 每次迭代生成 5 个示例provider: &quot;ollama&quot; # LLM 提供程序model: &quot;mistral-nemo:12b&quot; # 模型名称sys_msg: true # 在数据集中包含系统消息（默认值：true）save_as: &quot;insecure_code_dataset.jsonl&quot; # Hugging Face Hub 配置（可选）huggingface: # 格式为&quot;username/dataset-name&quot;的存储库repository: &quot;hfuser/dataset&quot; # 也可以通过 HF_TOKEN 环境变量或 --hf-token CLI 选项提供令牌 token: &quot;$token&quot; # 数据集的附加标签（可选） # &quot;promptwright&quot; 和 &quot;synthetic&quot; 标签会自动添加 tags: - &quot;promptwright&quot;  我们已在内部将它用于一些项目，效果非常好。您可以处理数千个样本，而不必担心 API 成本或速率限制。此外，由于一切都在本地运行，您不必担心敏感数据离开您的环境。 代码是 Apache 2 许可的，我们很乐意收到社区的反馈。如果您正在为 ML 进行任何类型的合成数据生成，请尝试一下并告诉我们您的想法！ 链接： 查看 examples 文件夹，获取生成代码、科学或创意 ewr 的示例 非常乐意听到您的想法和建议，如果您发现任何改进空间，请随时提出和发布或发出拉取请求。    提交人    /u/zero_proof_fork   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4bcz2/p_promptwright_open_source_project_to_generate/</guid>
      <pubDate>Sun, 01 Dec 2024 19:33:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关生成无缝 360° 图像的机器学习模型的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h48950/d_seeking_advice_on_machine_learning_models_for/</link>
      <description><![CDATA[大家好， 我正在做一个涉及创建 360° 图像的项目，遇到了一些挑战。目标是生成无缝 360° 全景图，图像环绕处没有可见边缘或伪影。 我想知道是否有任何机器学习模型、技术或工具特别适合这项任务。具体来说，我正在寻找可以做到以下事情的东西：  确保 360° 图像边缘的连续性。 处理不同的纹理和图案而不会出现明显的扭曲。 在我的自定义数据集上进行训练或微调（如果需要）。  我已经探索过 StyleGAN 和扩散模型等 GAN，但我不确定它们是否可以开箱即用地处理边缘连续性问题。有没有人解决过类似的问题或知道一个好的起点？ 任何建议、资源或见解都将不胜感激！提前致谢！    提交人    /u/Deep_Land_4093   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h48950/d_seeking_advice_on_machine_learning_models_for/</guid>
      <pubDate>Sun, 01 Dec 2024 17:22:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 01 Dec 2024 16:00:30 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Noema – 声明式 AI 编程库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h46341/project_noema_a_declarative_ai_programming_library/</link>
      <description><![CDATA[       由    /u/Super_Dependent_2978  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h46341/project_noema_a_declarative_ai_programming_library/</guid>
      <pubDate>Sun, 01 Dec 2024 15:46:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 来源：为什么猎犬的 KG 表现优于 RD？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h447eu/r_sources_reasons_why_kg_outperformes_rd_in/</link>
      <description><![CDATA[是否有任何资料讨论为什么 Retriever 与 KG 配合使用效果比 RD 更好？我发现说它更好是非常直观的，因为在知识图中我们拥有更多的语义结构，并且可以有效地发现关系。在我看来，“图当然更丰富/更密集”，但在论文合作时，我突然意识到我无法证明这一说法。我找不到任何资料可以真正解释为什么会这样。 我得到的唯一资料是这个： https://arxiv.org/abs/2311.07509 去年在子版块中也有：https://www.reddit.com/r/LocalLLaMA/comments/17vy1bo/a_benchmark_to_understand_the_role_of_knowledge/ 所以我们只能说&amp;“我们证明我们的决定是正确的，因为 KG 比 RD 效果更好 [基准论文来源]&amp;; 我本来很想讨论为什么 KG 更适合，并给出关于信息密度、语义结构或相关实体的更好选择的论据。但我找到的只是一些文章，它们散布着荒谬的主张或指出了更简单/原生的实现，从技术上讲，这也可以通过 RD 实现。 有人可以告诉我资料来源吗？很想阅读关于更好性能原因的深入讨论。    提交人    /u/PopPsychological4106   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h447eu/r_sources_reasons_why_kg_outperformes_rd_in/</guid>
      <pubDate>Sun, 01 Dec 2024 14:17:17 GMT</pubDate>
    </item>
    <item>
      <title>ROI 图像增强 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h41z2x/augmentation_for_images_with_roi_d/</link>
      <description><![CDATA[我有一张带有 roi (x_min、y_min、x_max、y_max) 的图像。我想用 torchvison 进行随机翻转、旋转、倾斜、平移等。为了与增强图像匹配，分别可以用哪些不同的方式转换 roi？    提交人    /u/Brief_Papaya121   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h41z2x/augmentation_for_images_with_roi_d/</guid>
      <pubDate>Sun, 01 Dec 2024 12:11:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] Qwen-VL：用于理解、定位、文本阅读等的多功能视觉语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h40wms/r_qwenvl_a_versatile_visionlanguage_model_for/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h40wms/r_qwenvl_a_versatile_visionlanguage_model_for/</guid>
      <pubDate>Sun, 01 Dec 2024 10:59:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    <item>
      <title>最好的开源图像升级模型是什么？[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3qcon/whats_the_best_open_source_imageupscaling_model/</link>
      <description><![CDATA[      我正在使用Playground-v2.5-aesthetic制作一些用于 YouTube 缩略图的图像。我对结果非常满意： 1024x1024 火星基地基础图像。 但我希望图像为 1920x1080 像素，而我唯一的选择是 1024x1024 或 1280x720 像素。目前，我可以使用 Photoshop 的修饰功能达到 1920x1080 的图像分辨率： 1920x1080 的火星基地修饰图像。 这还可以，但是 Photoshop 的修饰功能是手动的，并且质量会下降相当明显。理想情况下，我会生成 1280x720 的图像，然后通过编程将其升级到 1920x1080。 我听说过以下模型：  Real-ERSGAN Waifu2 SRGAN  但在我深入研究其中任何一个之前，哪种开源模型通常被认为最适合实现这一目标？我有一台 RTX 3060 12GB VRAM。    提交人    /u/FPGA_Superstar   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3qcon/whats_the_best_open_source_imageupscaling_model/</guid>
      <pubDate>Sun, 01 Dec 2024 00:13:57 GMT</pubDate>
    </item>
    <item>
      <title>[P]用Excel构建的完整变压器模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3hj6j/p_a_complete_transformer_model_built_in_excel/</link>
      <description><![CDATA[        提交人    /u/Revolutionary-Way290   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3hj6j/p_a_complete_transformer_model_built_in_excel/</guid>
      <pubDate>Sat, 30 Nov 2024 17:25:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] RNN 的现代用例？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h38ym2/d_modern_usecases_for_rnns/</link>
      <description><![CDATA[讨论可以分为两个方面。1）您认为，对于个人项目规模而言，哪些任务是您认为接近传统实现（LSTM、GRU）的 RNN 仍然是最佳的起点和终点？尤其是与 transformers 相比。 在小型时间序列预测设置中，我可以看到 GRU 可能比 Transformer 更方便，但我对输入是符号或度量序列但输出可能不是的任务也感兴趣。 主要目标是在有意义的数据集上使用 LSTM 和 GRU 变体（例如 minGRU），可能会做微小的莎士比亚，但它并没有让我感到温暖…… 2) 您是否认为存在顺序任务和设置，其中 RNN 不仅是根据我们的直觉更自然的选择，而且实际上与 Transformers 或 1D CNN 等相比，它是唯一在理论上或实验上可用的选择？    提交人    /u/Sad-Razzmatazz-5188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h38ym2/d_modern_usecases_for_rnns/</guid>
      <pubDate>Sat, 30 Nov 2024 09:22:32 GMT</pubDate>
    </item>
    </channel>
</rss>