<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 22 Oct 2024 21:15:42 GMT</lastBuildDate>
    <item>
      <title>我们如何超越神经网络[讨论]？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9o9x3/how_do_we_move_beyond_neural_networks_discussion/</link>
      <description><![CDATA[大家好！我现在是一名学生，已经研究神经网络几年了。虽然我不否认神经网络及其衍生物具有革命性（法学硕士等），但我不禁觉得我们很快就会在神经网络方面遇到瓶颈。对我来说，我们需要一种全新的方法，一种更适合我们目前拥有的计算机的方法，才能转向下一代模型和人工智能。在这个方向上有没有取得任何进展（如果有，请在这里提及），你认为下一步会是什么？再次重申，这是我的观点。我还没有研究神经网络一辈子，所以很想听听社区对此的看法。 澄清一下，通过超越神经网络，我的想法是，我们不是模仿人类大脑的神经元和架构，而是模仿一些完全不依赖人工神经元的不同的东西。 （再次强调，我不知道这怎么可能，所以我期待听到您的想法）。 对我来说，模仿人类大脑来建模神经网络是低效的，因为我们试图模仿生物学，因为生物学是我们拥有的最好的东西。这就像人类开发了一匹机械马，因为马是自然界中最好的交通工具，而不是集中精力开发一辆我们目前的技术更适合的汽车（仅举一例）。此外，最近对法学硕士和其他东西的增量更新似乎表明，训练更大的模型并不能证明我们很快投入的大量数据和资源是合理的。 就我个人而言，我认为我们应该继续发展神经网络，看看我们在哪里达到极限，然后希望我们能够进行足够的探索，以了解为什么它们不适用于更高级的东西，之后我们可以继续进行下一步。也许我们甚至可以提取 NN 的最佳部分并将其整合到更新的架构中。 期待听到您对此的想法。再次，如果您有任何关于非基于 NN 的 AI 的有趣新研究，能否在下面链接它们？提前致谢。    提交人    /u/mopasha1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9o9x3/how_do_we_move_beyond_neural_networks_discussion/</guid>
      <pubDate>Tue, 22 Oct 2024 17:47:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们构建了一个多云 GPU 容器运行时</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9mrcj/d_we_built_a_multicloud_gpu_container_runtime/</link>
      <description><![CDATA[想要分享我们的开源容器运行时 - 它专为跨云运行 GPU 工作负载而设计。 https://github.com/beam-cloud/beta9 与主要用于在一个云中运行一个集群的 Kubernetes 不同，Beta9 旨在在许多不同的云中的许多集群上运行工作负载。想要在家中的 AWS、GCP 和 4090 设备之间运行 GPU 工作负载吗？只需在每个 VM 上运行一个简单的 shell 脚本以将其连接到集中控制平面，您就可以在这三个环境之间运行工作负载。 它还处理分布式存储，因此文件、模型权重和容器映像都缓存在靠近用户的 VM 上，以最大限度地减少延迟。 我们已经构建 ML 基础设施一段时间了，但最近决定将其作为一个开源项目启动。如果您有任何想法或反馈，我将非常感激听到您的想法🙏    提交人    /u/velobro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9mrcj/d_we_built_a_multicloud_gpu_container_runtime/</guid>
      <pubDate>Tue, 22 Oct 2024 16:45:26 GMT</pubDate>
    </item>
    <item>
      <title>如何开展科学项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9kakg/how_to_run_science_projects/</link>
      <description><![CDATA[我根据在 FAANG 公司工作 9 年以上的经验，总结了自己运行 ML 和科学项目的经验。它涵盖了常见内容，例如解决模糊的业务问题、找到合适的利益相关者、设置指标以及完成任务。我还分享了一些关于哪些方法有效（哪些方法无效）的个人故事，尤其是当利益相关者意见不一致时。如果您做过类似的工作或采用不同的方法，我很想听听您的想法！ https://dzidas.com/ml/2024/10/22/implementing-data-science-projects/    提交人    /u/kafka399   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9kakg/how_to_run_science_projects/</guid>
      <pubDate>Tue, 22 Oct 2024 15:03:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] LLM 研究框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9k0te/d_r_llms_frameworks_for_research/</link>
      <description><![CDATA[我是人工智能和自然语言处理专业的博士生，目前正在用法学硕士 (LLM) 启动一个新的研究项目。 这一次，我不会主要使用 HuggingFace 和 Pytorch 从头开始​​编写所有代码，而是想使用一种流行的框架（如 LangChain、LlamaIndex 等）。 这背后的动机是，理想情况下，我想学习使用这些工具来获得更紧凑、更有条理的代码库，以便我可以轻松添加部分内容以包括 RAG、Agentic 工作流等。 我还对一种有效的方法来加载模型和进行推理感兴趣。 根据您的经验，众多可用的框架中哪一个最适合研究目的？而且，您是否使用框架，还是每次开始新项目时都从头开始编写所有代码？    提交人    /u/Debonargon   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9k0te/d_r_llms_frameworks_for_research/</guid>
      <pubDate>Tue, 22 Oct 2024 14:51:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 世界上*最不*流行的 LLM 评估工具新发布！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9j2e7/p_new_release_for_the_worlds_least_popular_llm/</link>
      <description><![CDATA[      刚刚发布了新版本的 Ollama Grid Search，其中 下载适用于所有主要平台。 据 Discord 上的一些聪明人说，它很“可爱”而且“可笑”，所以一定要确保不要错过这个乐趣！ 如果您不知道这是什么，它是一个桌面开源应用程序，可让您：  在单个操作中评估多个提示和模型组合 评估多个参数组合以验证对推理输出的影响。  https://preview.redd.it/lcqqqco9fbwd1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=e8db16b7f980acbfd96adb65ccb6633cf52d3e93 如果您已经是用户（谢谢！），以下是 0.6.0 版本的更新日志： 已添加  已添加 UI 控件以重新运行过去的实验。 已添加控件以删除实验文件。 添加了用于将推理文本复制到剪贴板的按钮。  已更改  移动“重新加载”图标以改善布局。 提高了实验检查 UI 的可读性。 简化了状态管理。  修复  修复 HMR 无法在 MacOS 上运行的问题（当然正在开发中）。如果您已经是用户（谢谢！），这里是 0.6.0 版本的更新日志：已添加已添加 UI 控件以重新运行过去的实验。已添加控件以从 UI 中删除实验文件。添加了用于将推理文本复制到剪贴板的按钮。已更改已移动“重新加载”图标以改善布局。提高了实验检查 UI 的可读性。简化了状态管理。修复 修复 HMR 在 MacOS 上无法正常工作的问题（当然，正在开发中）。     提交人    /u/grudev   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9j2e7/p_new_release_for_the_worlds_least_popular_llm/</guid>
      <pubDate>Tue, 22 Oct 2024 14:10:22 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 用于创建富有表现力的视频语音的最佳文本转音频语音 API？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g9fhg7/discussion_best_text_to_audio_voice_api_for/</link>
      <description><![CDATA[我正在寻找最佳文本转语音 API 的推荐，我主要关注 OpenAI、11labs、Google Voice 和 Amazon polly。 因此，如果您知道其中任何最适合我的用例的 API，那就太好了。 如果您有使用这些 API 的经验，请分享。或者，如果您知道任何其他类型的推荐 API，请在评论中告诉我。 谢谢。    提交人    /u/pushkarsingh32   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g9fhg7/discussion_best_text_to_audio_voice_api_for/</guid>
      <pubDate>Tue, 22 Oct 2024 11:07:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Meta Movie Gen 模型架构的几个问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g92l2t/d_a_few_questions_on_the_architecture_of_metas/</link>
      <description><![CDATA[我阅读了 Meta Movie Gen 论文来了解他们的模型。目前我对架构基本满意，但仍有几个地方我不确定发生了什么。希望能得到一些澄清 1) 从 TAE 输出潜在代码到 Transformer 输入嵌入的转换。论文中有这样一段话：  如第 3.1.1 节所述，我们在学习到的视频潜在空间表示中执行生成。此潜在代码的形状为 T x C x H x W 。为了准备 Transformer 主干的输入，首先使用 3D 卷积层（Dosovitskiy et al., 2021）对视频潜在代码进行“修补”，然后将其展平以生成 1D 序列。 3D 卷积层使用大小为 k_t x k_h x k_w 的核，步长等于核大小，并将其投影到与 Transformer 主干所需的相同维度中。因此，输入到 Transformer 主干的 token 总数为 THW/(k_t k_h k_w)。我们使用 k_t = 1 和 k_h = k_w = 2，即我们生成 2 x 2 个空间块。  这里，为什么没有提到通道维度？核不应该是 5 维的吗，包括输入通道和输出通道？如果是这样，那么输出通道的数量是否等于 Transformer 嵌入维度？ 2）紧接着，本文讨论了分解可学习嵌入：  我们使用分解可学习位置嵌入来实现 Transformer 的任意大小、宽高比和视频长度（De- hghani et al.，2024）输入。D 维的绝对嵌入可以表示为映射 phi(i) : [0, maxLen] -&gt; RD，其中 i 表示补丁的绝对索引。我们将“patchified”标记（即 3D 卷积层的输出）转换为空间 h、w 和时间 t 坐标的单独嵌入 phi_h、phi_w 和 phi_t……  在嵌入已经展平为 1-D 之后，如何按维度分离嵌入？当我们仍然将时间和空间坐标隔离时，位置嵌入是否应该在“3-D”卷积之前添加？ 3) 自适应层规范块如何工作？我查阅了 Peebles 和 Xie 的原始参考资料，其中写道：  我们不是直接学习维度尺度和平移参数 γ 和 β，而是从 t 和 c 的嵌入向量之和中对它们进行回归  我不太明白这里“回归”这个词是什么意思，或者如何从 t 和 c 中获得 γ 和 β。我也不明白这如何适用于没有 c 向量的 Movie Gen。    提交人    /u/throwaway2676   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g92l2t/d_a_few_questions_on_the_architecture_of_metas/</guid>
      <pubDate>Mon, 21 Oct 2024 22:20:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于 RoPE 的 LLM 如何学习注意力集中点（或编码绝对位置）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g8yurr/r_how_do_ropebased_llms_learn_attention_sinks_or/</link>
      <description><![CDATA[我最近重新阅读了“注意力接收器”论文（链接），并开始思考 LLM 如何管理注意力接收器。 注意力接收器的概念描述了 LLM 为初始标记分配不成比例的高注意力分数的现象，而不管它们的语义值如何。 这里有一个悖论：最先进的开放式 LLM 通常采用 RoPE（旋转位置嵌入）进行位置编码。由于 RoPE 仅对相对位置进行编码，因此令人费解的是模型如何一致地识别绝对初始标记并为其分配高度注意力。您对这种行为可能如何出现或解释有什么想法吗？    提交人    /u/StraightSpeech9295   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g8yurr/r_how_do_ropebased_llms_learn_attention_sinks_or/</guid>
      <pubDate>Mon, 21 Oct 2024 19:46:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 修复 Nightly transformers 中的梯度累积错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g8ymrn/r_gradient_accumulation_bug_fix_in_nightly/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g8ymrn/r_gradient_accumulation_bug_fix_in_nightly/</guid>
      <pubDate>Mon, 21 Oct 2024 19:37:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2024 焦点中的潜在抄袭：Shengjie Luo 和 Tianlang Chen 的“Gaunt Tensor Products”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g8rk2j/d_potential_plagiarism_in_iclr_2024_spotlight/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g8rk2j/d_potential_plagiarism_in_iclr_2024_spotlight/</guid>
      <pubDate>Mon, 21 Oct 2024 14:52:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] RWKV-7：无需注意，超越强大的 Modded-GPT 基线（使用 Muon 优化器的基线），同时仅使用 headsz 64</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g8qsea/r_rwkv7_attentionfree_and_surpassing_strong/</link>
      <description><![CDATA[      大家好。 RWKV-7（100% RNN 且无注意力）可以超越强大的 Modded-GPT 基线（带有 Muon 优化器的基线，目前在推特上流行）。 训练代码和日志：https://github.com/BlinkDL/modded-nanogpt-rwkv 如果使用更大的 headsz，它可以达到损失 3.26xx。 但是我当前的实现效率很低。优化后，可能可以达到 ctx1k 下 Modded-GPT 速度的 85%（或比 ctx4k 下 Modded-GPT 更快）。欢迎任何帮助:) https://preview.redd.it/48m3lsvkb4wd1.png?width=873&amp;format=png&amp;auto=webp&amp;s=647d86ed47d40a4f742ed9512a835dee41069e4f  强大的 GPT 基线： https://preview.redd.it/h2ckr31mb4wd1.png?width=584&amp;format=png&amp;auto=webp&amp;s=b667bfbc50298f8335a889b85c55f68ee8db38a5  RWKV-7 摆脱了“线性注意力”设计以实现更高的性能：） https://preview.redd.it/ijyz0sgnb4wd1.png?width=1233&amp;format=png&amp;auto=webp&amp;s=f413d0e7bcd3a76c5e788f2ca231a37706b24345    提交人    /u/bo_peng   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g8qsea/r_rwkv7_attentionfree_and_surpassing_strong/</guid>
      <pubDate>Mon, 21 Oct 2024 14:18:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于推理的高效 CNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g8kpl6/d_efficient_cnns_for_inference/</link>
      <description><![CDATA[我正在使用高分辨率图像进行物体检测项目。 有没有什么技术可以使训练有素的 CNN（UNet）在推理过程中更有效率？我知道修剪就是这样一种技术，但它有损失准确性和可并行性的风险。    提交人    /u/_My__Real_Name_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g8kpl6/d_efficient_cnns_for_inference/</guid>
      <pubDate>Mon, 21 Oct 2024 08:20:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] Google Shopping 10M 数据集，用于大规模多模式产品检索和排名</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g8a3pv/r_google_shopping_10m_dataset_for_large_scale/</link>
      <description><![CDATA[我们终于在 Hugging Face 上发布了 Marqo Google Shopping 1000 万数据集 (Marqo-GS-10M)。这是用于多模式产品检索的最大、最丰富的数据集之一！  1000 万行查询、产品标题、图片和排名 (1-100) ~10 万个唯一查询 ~500 万个时尚和家居领域的唯一产品 反映了真实世界的数据和用例，并可作为方法开发的良好基准 适当的数据拆分、域内、新查询、新文档以及新文档和新查询。   该数据集为每个查询-文档对提供了详细的相关性分数，以方便将来的研究和评估。 !pip install datasets from datasets import load_dataset ds = load_dataset(&quot;Marqo/marqo-GS-10M&quot;)  我们将这个大规模数据集作为我们训练框架发布的一部分进行策划：广义对比学习 (GCL)。  数据集：https://huggingface.co/datasets/Marqo/marqo-GS-10M GCL：https://github.com/marqo-ai/GCL 论文：https://arxiv.org/abs/2404.08535    提交人    /u/Jesse_marqo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g8a3pv/r_google_shopping_10m_dataset_for_large_scale/</guid>
      <pubDate>Sun, 20 Oct 2024 21:51:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</guid>
      <pubDate>Sun, 20 Oct 2024 15:00:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>