<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 26 Dec 2023 09:13:02 GMT</lastBuildDate>
    <item>
      <title>微调法学硕士以协助代理人 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r3nv1/finetune_an_llm_to_assist_agent_d/</link>
      <description><![CDATA[我有代理和客户之间对话的数据。我需要微调法学硕士以在通话时协助代理。我所说的协助是指在某些情况下提供推动。通话将进行，我需要法学硕士快速响应（200 毫秒至 1000 毫秒）。哪个法学硕士适合这项任务？对此问题的任何创造性解决方案将不胜感激。请随时告诉我您是否可以想出一种无需法学硕士即可实现此目的的方法。   由   提交/u/Evermore2307  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r3nv1/finetune_an_llm_to_assist_agent_d/</guid>
      <pubDate>Tue, 26 Dec 2023 08:33:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 函数调用微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r305i/d_function_calling_finetuning/</link>
      <description><![CDATA[例如： 用户：嗨，我需要将温度从摄氏度转换为华氏度。气温为30摄氏度。助理：&lt;函数调用&gt; {“名称”：“convert_temprature”，“参数”：&#39;{“温度”：30，“from_unit”：“摄氏度”，“to_unit”：“华氏度”}&#39;} &lt;|文本结束|&gt;功能响应：{“转换温度”：86} 助理：从 30 摄氏度转换为华氏温度的温度为 86 华氏度。 &lt;|endoftext|&gt; 假设我们有上述来自数据集的样本来训练法学硕士，您将如何避免“函数响应”？数据不会对整体损失产生影响，因为它是函数调用的输出。   由   提交 /u/Raise_Fickle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r305i/d_function_calling_finetuning/</guid>
      <pubDate>Tue, 26 Dec 2023 07:48:13 GMT</pubDate>
    </item>
    <item>
      <title>如果你的 GPU 很差，你能做什么研究？[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r2nbu/what_kind_of_research_can_you_do_if_you_are_gpu/</link>
      <description><![CDATA[所以在我的大学里我没有太多的计算资源。我可以在 ML 中做什么类型的工作？   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r2nbu/what_kind_of_research_can_you_do_if_you_are_gpu/</guid>
      <pubDate>Tue, 26 Dec 2023 07:23:26 GMT</pubDate>
    </item>
    <item>
      <title>[N] Coqui TTS 本地安装教程 - 秒内免费克隆声音！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18r2js7/n_coqui_tts_local_installation_tutorial_clone/</link>
      <description><![CDATA[嘿， 人工智能最近变得很疯狂，事情变化得非常快。我制作了一个视频，介绍了 Coqui 的 TTS with UI 的安装过程，这是一个公开的文本转语音 AI 模型，我认为它可能对你们中的一些人有用。安装过程非常简单，可以概括为几个命令，之后您将拥有一个功能齐全的 TTS 服务器，您可以用它在几秒钟内克隆语音！查看完整教程： https://youtu.be/ykfPIO1wTh8 这里真正酷的部分是，在需要几分钟的初始设置之后，您将能够从数百种声音中选择您想要的任何模型，然后为其提供文本并获得疯狂的快速结果。结果返回的速度通常比人工智能读取它的速度要快，并且所有结果都在本地运行&amp;免费的。顺便说一句，它也可以在 CPU 上运行！ 请告诉我您的想法，或者如果您对其他视频有任何疑问/请求， 干杯   由   提交/u/dev-spot  /u/dev-spot  reddit.com/r/MachineLearning/comments/18r2js7/n_coqui_tts_local_installation_tutorial_clone/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18r2js7/n_coqui_tts_local_installation_tutorial_clone/</guid>
      <pubDate>Tue, 26 Dec 2023 07:16:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你们使用哪种软件来说明研究框架/想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qzdnj/d_which_software_do_you_guys_use_for_illustrating/</link>
      <description><![CDATA[我们经常在研究论文中看到图表/图形来说明整个工作流程。我很好奇大家都在用什么。就我个人而言，我使用 draw.io，它通常不是“漂亮”的。 - 那么也许有更好的选择？   由   提交/u/KarmaCut132   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qzdnj/d_which_software_do_you_guys_use_for_illustrating/</guid>
      <pubDate>Tue, 26 Dec 2023 04:12:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在本地存储和管理数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qu69c/d_storing_and_managing_datasets_onpremises/</link>
      <description><![CDATA[我最近深入研究了创建具有 4x3090 的 Homelab 计算集群。 目前，我一直在使用带有 ZFS 数据集的二手企业 HDD 来存储数据集，但我&#39;我很好奇你们都是怎么做到的？ 我尝试在 Discord 群组和网上询问，但这个问题似乎不是一个问题，因为很多人都在使用适当的服务器和云来进行计算。然而，它具有适当的网络速度，可以在几秒钟内下载千兆字节的数据。我没有这个，因为我只是在家里运行我的电脑，所以我只是囤积了一些数据集，哈哈。 ZFS 一直在帮助缓解存储问题，因为池设置为自动压缩所有进入的数据。 至于组织，我一直在尝试按模式将数据分组在一起。所以模式看起来有点像这样 ::  数据集  文本 图像 非结构化 带标签 分段 视频 非结构化 带标签 分段    你们都做了什么不同的事情吗？   由   提交 /u/PrayagBhakar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qu69c/d_storing_and_managing_datasets_onpremises/</guid>
      <pubDate>Mon, 25 Dec 2023 23:41:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 深度强化学习的泛化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qrzqo/r_generalization_in_deep_reinforcement_learning/</link>
      <description><![CDATA[深度强化学习中的对抗性攻击、鲁棒性和泛化 https://blogs.ucl.ac.uk/steapp/2023/11/15 /对抗性攻击-深度强化学习中的鲁棒性和泛化/   由   提交 /u/ml_dnn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qrzqo/r_generalization_in_deep_reinforcement_learning/</guid>
      <pubDate>Mon, 25 Dec 2023 21:51:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大规模运行 Whisper 的最具成本效益的方式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qrerx/d_most_cost_efficient_way_to_run_whisper_at_scale/</link>
      <description><![CDATA[我正在尝试确定要运行哪个 Whisper 版本以及如何运行它，以最大限度地降低大规模运行时的成本。我说的是每天转录大约 1000 小时的音频。我认为也许中等模型会提供足够的准确性。  我应该使用其中一个 CPU 版本并在云运行等平台上并行化多个文件吗？是不是使用更强大的 GPU 虚拟机并连续执行更多操作？ 速度并不是那么重要，如果转录每个文件需要更长的时间也没关系。只要我能跟上传入文件的节奏就可以转录。  感谢您的任何想法和建议！   由   提交/u/ojojoj1233  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qrerx/d_most_cost_efficient_way_to_run_whisper_at_scale/</guid>
      <pubDate>Mon, 25 Dec 2023 21:21:18 GMT</pubDate>
    </item>
    <item>
      <title>深度学习/计算机视觉 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qk9a0/deep_learning_computer_vision_p/</link>
      <description><![CDATA[在过去的十年里，我一直是一名 ML 工程师，从事网络、路由优化等工作，所以我对 ML 和 DL 略知一二，但自从我读研究生以来，我就没有再接触过计算机视觉。  一位经营残疾人团体的朋友找到我，询问是否可以使用相机+将其与某种机器学习计算机视觉系统连接起来，该系统可以识别障碍物和距离+为那些可以识别障碍物和距离的人提供耳机。他们无力承担导盲犬的费用，只能拄着拐杖，让它们了解更多有关周围环境的信息。这个想法将是短句，例如“十米内的街道”、“正前方的树”。  她让我研究一下这个问题，我对找到整个主题的良好切入点感到有点不知所措。我认为这需要一个蓝牙摄像头、某种实时操作系统+便携式？计算硬件。我认为这不应该是完全不可能的，因为自动驾驶需要更高的准确度，但该领域所做的一切可能都是专有的？ 除了愿意支付硬件费用的赞助商，所以任何开源的东西都会很棒。 我经常阅读 OpenCV，但是当我开始谷歌搜索时，还有其他我应该了解的库或工具吗？ ？是的，所以基本上任何关于 CV+ML 信息的想法和介绍都会被假设：我应该查看哪些好文章？这已经完成了吗，我可以在某个地方下载它:)？是不是完全无法撤销？    由   提交 /u/tessherelurkingnow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qk9a0/deep_learning_computer_vision_p/</guid>
      <pubDate>Mon, 25 Dec 2023 15:02:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 没有足够的 GPU 来训练 Mixtral？何不试试LLaMA-MoE~</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qh2ch/p_dont_have_enough_gpu_to_train_mixtral_why_not/</link>
      <description><![CDATA[LLaMA-MoE 是一系列基于 LLaMA 和 SlimPajama 的开源 Mixture-of-Expert (MoE) 模型。我们通过以下两个步骤构建 LLaMA-MoE：  将 LLaMA 的 FFN 划分为稀疏专家，并为每层专家插入 top-K 门。 持续预训练初始化的 MoE 模型，具有来自 Sheared LLaMA 的优化数据采样权重和来自 SlimPajama 的过滤数据集。  如果您没有足够的计算资源来训练 Mixtral，您可能想尝试 LLaMA -MoE 用于下游研究。 查看：pjlab-sys4nlp/llama-moe    由   提交 /u/Spico197   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qh2ch/p_dont_have_enough_gpu_to_train_mixtral_why_not/</guid>
      <pubDate>Mon, 25 Dec 2023 11:36:51 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]在法学硕士时代，Transformer架构有哪些局限性和缺点？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qh1hp/discussion_in_this_age_of_llms_what_are_the/</link>
      <description><![CDATA[      ​ 变压器   由   提交 /u/dontgimmehop​​e   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qh1hp/discussion_in_this_age_of_llms_what_are_the/</guid>
      <pubDate>Mon, 25 Dec 2023 11:35:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我可以在 8 * A100 40GB 上微调 Mistral 7B 型号吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qgcsk/d_can_i_fintune_mistral_7b_model_on_8_a100_40gb/</link>
      <description><![CDATA[我想要微调 Mistral 7B，并且我可以访问 8 A100 40GB，并且我正在进行全面微调，而不是 Lora 这可能吗？或者我至少需要A100 80GB？  如何计算最低要求？   由   提交 /u/MustafaAlahmid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qgcsk/d_can_i_fintune_mistral_7b_model_on_8_a100_40gb/</guid>
      <pubDate>Mon, 25 Dec 2023 10:42:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可以 ping 运行脚本的按需 GPU</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18qeudq/d_ondemand_gpu_that_can_be_pinged_to_run_a_script/</link>
      <description><![CDATA[是否存在一项服务，我可以每月使用 GPU 3-6 小时（一个请求），并且可以使用链接或其他东西，以便我可以自动化它？ 如果您熟悉 azure 功能，我想要类似的服务，但使用 GPU，并且我只需要按 3-6 小时付费。我不想托管虚拟机一个月，因为它每月仅运行 3-6 小时。   由   提交/u/Level_Programmer4276   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18qeudq/d_ondemand_gpu_that_can_be_pinged_to_run_a_script/</guid>
      <pubDate>Mon, 25 Dec 2023 08:40:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们真的知道令牌概率如何导致推理吗？例如，当我们给 GPT4 一个谜语，而它使用非直观的逻辑来解决这个谜语时，这是怎么发生的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18q9ucf/d_do_we_really_know_how_token_probability_leads/</link>
      <description><![CDATA[GPT4 可以轻松解决以下非常基本的谜语/问题。 谜语示例：您有一个杯子和一个球。将球放在桌子上，然后将杯子放在球上。然后将杯子放在厨房柜台上。球在哪里？ 答案：当然还在原来的桌子上。 概率引擎如何知道这个推理？   由   提交 /u/Artistic-Life-6562   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18q9ucf/d_do_we_really_know_how_token_probability_leads/</guid>
      <pubDate>Mon, 25 Dec 2023 02:51:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>