<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sat, 15 Feb 2025 09:17:35 GMT</lastBuildDate>
    <item>
      <title>[r]从头开始学习ML（需要学习伙伴或指南）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipxcvb/r_going_to_learn_ml_from_scratch_need_a_study/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我已经完成了AIML学位。我认为有一个计划做同样的学习伙伴，我们可以互相帮助，分享怀疑并总结我们每天学习的伙伴，真是太好了。 DM我如果有兴趣  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sea-a-average6225     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ipxcvb/r_ondove_to_lealed_learn_ml_from_scratch_need_a_a_study/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipxcvb/r_going_to_learn_ml_from_scratch_need_a_study/</guid>
      <pubDate>Sat, 15 Feb 2025 08:50:02 GMT</pubDate>
    </item>
    <item>
      <title>[r]通过基于抽象网格的任务评估LLM中的物理概念理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipw78p/r_evaluating_physical_concept_understanding_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项工作介绍了一个结构化评估框架，用于评估LLMS中物理理解的结构化评估框架，从教育测试原理中得出。研究人员使用定量和定性问题开发了一个全面的测试套件，涵盖了力学，热力学和电磁套件。 关键技术方面： - 多级评估层次结构，从事实回忆到概念转移到最小的词汇，以最小化 - 语言模式匹配 - 使用平行问题的跨文本验证 - 数值计算和概念解释任务的集成 - 基于教育评估方法的标准化评分标准评分 主要结果：-GPT -4在基本物理学上实现了76％的准确性计算 - 跨文本转移问题的性能下降至43％ - 跨物理域的性能显着差异 - 模型在数学能力和物理问题解决问题之间显示出很强的相关性 - 结合多个物理概念 时出现了系统错误我认为这种方法比以前的工作提供了一种更严格理解LLM功能的方法。教育测试框架有助于区分表面水平的模式匹配和更深的概念理解。这可能会导致更好的基准测量科学推理中的AI进展。 我认为，结果突出了LLMS在跨环境中传递物理知识的当前局限性 - 这对于实际科学工作至关重要。系统评估方法可以扩展到其他科学领域。  tldr：基于教育测试原理的新评估框架表明，LLM具有体面的物理计算能力，但与更深入的概念理解和知识转移斗争。 。&gt;   完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipw78p/r_evaluating_physical_concept_understanding_in/</guid>
      <pubDate>Sat, 15 Feb 2025 07:21:24 GMT</pubDate>
    </item>
    <item>
      <title>[d]变压器最有前途的继任者是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipvau4/d_whats_the_most_promising_successor_to_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我所知道的是mamba，从效率的角度看（推理是线性而不是二次），但是Afaik没有人受过训练的大型模型。还有 xlstm  and  aaren 。  你们认为变压器最有前途的替代体系结构是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jsonathan     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipvau4/d_whats_the_most_promising_successor_to_the/</guid>
      <pubDate>Sat, 15 Feb 2025 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>未配对的方式[D] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipql8c/unpaired_modalitiesd_r/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好！我正在寻找一个涉及多模式学习的研究主题，但方式没有配对。更具体地说，在剪辑等论文中，存在文本图像对，以自我监督的方式训练模型。同样，Flava具有配对和未配对的文本图像模式数据集。  是否有任何研究工作涉及从多种未配对的，未链接的方式中学习？您可能遇到的任何研究论文或概念吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/halfcursed     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipql8c/unpaired_modalitiesd_r/</guid>
      <pubDate>Sat, 15 Feb 2025 01:35:07 GMT</pubDate>
    </item>
    <item>
      <title>[p]在负担得起的家庭实验室服务器上的DeepSeek</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipkv89/p_deepseek_on_affordable_home_lab_server/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  使用NVIDIA RTX 3060 12GB或RTX 4060 TI 16GB是否现实？例如，这些设置可以处理带有抹布的大型文章吗？我很好奇限制TPS速度和4K上下文窗口。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/n3tcarlos     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipkv89/p_deepseek_on_affordable_home_lab_server/</guid>
      <pubDate>Fri, 14 Feb 2025 21:00:52 GMT</pubDate>
    </item>
    <item>
      <title>[P]时间序列异常检测的GNNS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipgk8p/p_gnns_for_time_series_anomaly_detection/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好！ 👋 在过去的几个月中，我和我的伴侣一直在研究一个项目，探讨图形神经网络（GNNS）用于时间序列异常检测（TSAD）。由于我们即将完成工作，我很想从这个惊人的社区那里获得反馈！ 🔗repo： GRAGOD-基于GNN的异常检测  任何评论，建议或讨论都非常欢迎！如果您觉得仓库很有趣，那么丢弃⭐就意味着很多。 ：） 我们还计划在未来几个月内发布一份详细报告，并提供我们的发现和见解，因此请继续关注！ 存储库仍在开发中，所以不要太苛刻了：） 期待听到您的想法！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/usestion-gear-325     link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipgk8p/p_gnns_for_time_series_anomaly_detection/</guid>
      <pubDate>Fri, 14 Feb 2025 17:56:59 GMT</pubDate>
    </item>
    <item>
      <title>论文选择 - 算法公平，可解释和值得信赖的AI [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipekfw/thesis_choice_algorithm_fairness_explainable_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我知道，这不是这个问题的理想之选，但我在其他地方找不到专家。 我是最近提供了专注于算法公平性，XAI和标签偏见/选择不确定性（特定于UQ）的职位，这是一项长期的承诺（PHD）。该领域是医学成像，这是我一直想进入的。 任何人都在类似领域工作或在AI的子领域有经验？我看到许多不同的软件包和方法，发现很难开始。尽管加入几个月了，但我想至少开始。  我还认为，这个领域将与行业相关，尽管它是利基市场，但只要我们运行AI系统，它就会停留。有任何意见吗？ 也可以简短聊天我可以dm的任何人？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ade17_in     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipekfw/thesis_choice_algorithm_fairness_explainable_and/</guid>
      <pubDate>Fri, 14 Feb 2025 16:32:43 GMT</pubDate>
    </item>
    <item>
      <title>[R]在欧洲+英国攻读博士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip9vuw/r_doing_a_phd_in_europeuk/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿我正在寻找2026年的博士学位，我想知道你们中的一些人是否可以推荐一些实验室。我想要在RL中理想的东西（因此没有土匪或完整的理论MDP）。可能是可塑性，终身/持续学习，更好的RL的架构/算法，多代理或分层RL，RL + LLM，RL +扩散等等。 我也很好较少的RL和更多的ML，例如更好的变压器体系结构，状态空间模型等。 P&gt; -Ethz（Krause&#39;s Lab）  -Darmstadt（Peters）   -  inria（flowers）   -  isir in Paris   -tübingen中的Max Plank    - 牛津的怀特森实验室  -FLAIR   -Stefano Albrecht在爱丁堡的实验室 我真的很喜欢如果您能帮助我延长清单，那么当我全面研究他们的论文，检查他们的博士学位，博士后和PIS等时，我不会错过实验室。 谢谢您提前很多帮助！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_carpenter7252      [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip9vuw/r_doing_a_phd_in_europeuk/</guid>
      <pubDate>Fri, 14 Feb 2025 12:51:57 GMT</pubDate>
    </item>
    <item>
      <title>[r]用潜在推理扩展测试时间计算：一种反复的深度方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip8lhf/r_scaling_up_testtime_compute_with_latent/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我们研究一种新型的语言模型体系结构，能够通过隐式推理潜在空间来扩展测试时间计算。我们的模型通过迭代复发块来起作用，从而在测试时间内展开对任意深度。这与主流推理模型相反，该模型通过产生更多的令牌来扩展计算。与基于思想链的方法不同，我们的方法不需要任何专业的培训数据，可以与小型上下文窗口一起使用，并且可以捕获不容易用文字表示的推理类型。我们将概念验证模型扩展到35亿参数和8000亿个令牌。我们表明，由此产生的模型可以在推理基准上提高其性能，有时会显着，达到相当于500亿个参数的计算负载。  本文在测试时在潜在空间中推理的论文是迷人。我认为这种方法正在成为一种趋势，并可以重新定义我们如何看待语言模型中的推理。 Meta Fair在大型概念模型上的工作也涉及潜在推理。  arxiv链接： [2502.05171]带有潜在推理：经常性深度方法   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/hiskuu     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip8lhf/r_scaling_up_testtime_compute_with_latent/</guid>
      <pubDate>Fri, 14 Feb 2025 11:32:58 GMT</pubDate>
    </item>
    <item>
      <title>[D]扩散模型及其统计不确定性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip6doi/d_diffusion_models_and_their_statistical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我对扩散模型的统计信息有问题。在诸如DDPM和DDIM之类的方法中，可以在任何扩散时间步骤中获得清洁图像（X0）的估计值。当然，此估算有一些相关的错误，但是似乎没有纸上关于此的论文。我在这里错过了什么吗？这是我正在进行的一项研究。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unk0wnvar     [link]   ＆＃32;   [commistion]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip6doi/d_diffusion_models_and_their_statistical/</guid>
      <pubDate>Fri, 14 Feb 2025 08:50:36 GMT</pubDate>
    </item>
    <item>
      <title>[d]如何处理蒸馏中的学生与教师模型的不同数据分布？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip5d07/d_how_to_deal_with_different_data_distribution/</link>
      <description><![CDATA[在一小时和B型3天。 我想蒸馏出B模型A建模，以使A模型可以从模型B中的其他信号中学习对于A和B模型来说，这应该是正确的，因此转移学习。 问题是B在训练过程中比模型A所看到的数据更多，并且可以根据更长的时间进行预测窗口及其真正的概率不同。即使使用PLATT缩放尺度或根据自己的分布进行校准，从理论上讲，它们也将彼此之间存在不同的数据分布，例如 我对如何从较长的时间窗口进行蒸馏而失去了不同的阳性率。自适应加权，但没有一个具体解决这个问题……  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tough_palpitation331     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ip5d07/d_how_to_to_deal_with_with_different_data_distribution/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip5d07/d_how_to_deal_with_different_data_distribution/</guid>
      <pubDate>Fri, 14 Feb 2025 07:33:29 GMT</pubDate>
    </item>
    <item>
      <title>[P]纯C中的GPT-2（以及完整的CUDA工作室）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioybio/pgpt2_in_pure_cand_full_cuda_worklogs_to_come/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  并行计算是听起来令人生畏但对现代世界绝对必不可少的事情之一。从高频交易（HFT）到设备AI，最大程度地减少资源，同时最大程度地提高性能非常重要，并且随着我们转向更好的开源LLM，可能会成为瓶颈。  首先要潜入这个空间，我启动了一个项目，我以平原，幼稚和不优化的（边界愚蠢）C实现了GPT-2体系结构，而没有很大的依赖性。为什么？因为在最基本的层面上了解问题是有效优化它的唯一方法。大多数教程从基础知识开始（例如优化矩阵乘法，然后它们可能会介入基本操作/创建基于圆圈的渲染器），但是真实的生产级cuda，例如您在乔治·霍茨（George Hotz）的Tinygrad或Karpathy的LLM中看到的内核.c或类似项目是完全不同的事情。几乎没有任何结构化资源来弥合差距。 ，我的目标是吗？ ➡️从这个简单的实现开始，然后逐步优化。 ➡️学会从头开始构建cuda内核，基准测试并将它们与其他解决方案进行比较。 ➡️返回此GPT返回此GPT返回此GPT -2实施，再次逐步挑选它，看看我可以做到的速度更快，更精细，更有效。 ，我将使用完整的工作室  repolink： https://github.com/angry-kratos/gpt-2-in -c    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/atronos_kronios     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioybio/pgpt2_in_pure_cand_fule_fure_full_cuda_worklogs_to_to_to_to_come/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioybio/pgpt2_in_pure_cand_full_cuda_worklogs_to_come/</guid>
      <pubDate>Fri, 14 Feb 2025 00:43:58 GMT</pubDate>
    </item>
    <item>
      <title>[D]我们在Google和Apple建立了Genai，然后离开以建立开源AI实验室，以使开放社区能够协作和建造下一个DeepSeek。 2月14日（星期五）上午9点至下午12点，请向我们询问！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioxatq/d_we_built_genai_at_google_and_apple_then_left_to/</link>
      <description><![CDATA[在   tl; dr：嗨，我们是Oumi，一个人的AI实验室，相信无条件开源的方法 - 代码，权重，培训数据，基础架构和协作 - 因此可以集体向前推动AI。我们为任何人建立了一个在AI中进行研究的平台。向我们询问有关开放源代码，扩展大型模型，DeepSeek的任何内容，以及在大型科技公司内外建立前沿模型所需的内容。告诉我们什么在开源AI中运作良好或您面临的挑战。我们应该共同努力以改进公开的AI？  ------------------------------  多年来，我们在Big Tech（Google）工作，苹果，微软）在Google Cloud Palm，Gemini和Apple的Health Foundation模型等Genai模型上的主要努力。我们在孤岛工作，知道必须有一种更好的方法来公开和协作开发这些模型。因此，我们建立了一个真正的开源AI平台，使世界各地成千上万的AI研究人员，科学家和开发人员可以合作，以一种集体的方式促进Frontier AI，从而导致更有效，透明和透明和稳定负责任的发展。 OUMI平台（完全开源，Apache 2.0许可证）支持预训练，调整，数据策展/综合，评估以及任何其他常见的效用，以完全可记录的和可重复的方式，同时易于自定义以支持新方法。   DeepSeek向我们展示了开源通过利用Llama之类的开放权重模型可以实现的目标。但是我们认为，AI应该更加开放：不仅是权重，而且还应该进行培训数据，以及代码将其全部打开。然后走得更远：使任何人都可以轻松访问和实验，使社区可以轻松合作和协作。  如果您有兴趣的话，有关OUMI的一些资源： 我们的github repo： https：https： //github.com/oumi-ai/oumi   我们的发布故事： https://venturebeat.com/ai/ex-google-google-apple-apple-egneers-launch -uncondition-open-source-oumi-ai-platform-that-that-that-that-the-could-help-to-build-the-next-deepseek/  我们的网站： https://oumi.ai/    如果您想协作并为社区研究项目做出贡献，无论您在哪里得到计算，都可以签名在： https://oumi.ai/community 。我们将从现有开放模型的训练后开始，接下来，我们将协作进行改进，以进行培训。我们打算与包括作者的所有贡献者一起发布研究。 我们在这里回答有关我们的开源方法，扩展大型模型，DeepSeek的问题大型科技公司以及大家都想讨论的其他任何事情。&lt; / p&gt; 我们将于2月14日星期五上午9点至下午12点pt / 12 pm-3 pm-3pm。问我们任何事情。  加入我们的AMA：   （ u/koukoumidis ） manos koukoumidis   - 首席执行官兼联合创始人ex-google（cloud genai铅） （ u/oelachqar ） Oussama elachqar   - 联合创始人，工程，Ex-Apple（健康基础模型） （ u/matthewpersons ） Matthew Persons   - 联合创意，工程学，工程，Ex -google（云棕榈＆amp; nl铅） （ u/jeremy杰里米·格里尔（Jeremy Greer）  - 联合创始人，研究，前google（双子座对齐）    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/koukoumidis     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioxatq/d_we_built_genai_genai_google_and_apple_apple_paple_then_left_then_left_to/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioxatq/d_we_built_genai_at_google_and_apple_then_left_to/</guid>
      <pubDate>Thu, 13 Feb 2025 23:53:27 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何从头开始进行ML研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ion90w/d_how_you_do_ml_research_from_scratch/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   有人在顶级ML会议（NIPS，ICML，ICLR）或面向域的会议（CVPR，ICCV，ACL，EMNLP，KDD）上发布了作品，Sigir）。 1。如何从0到第一张纸？ 2。您的技能（Pytorch或域知识）是多少？ 3。您遵循的整个过程是什么善于实施您的想法？ 4。您如何提出想法和解决方案？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/antelopewilling2928      r/machinelearning/注释/1ion90w/d_how_you_do_do_ml_research_from_scratch/“&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ion90w/d_how_you_do_ml_research_from_scratch/</guid>
      <pubDate>Thu, 13 Feb 2025 16:40:09 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>