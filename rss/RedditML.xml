<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 17 Jul 2024 01:06:22 GMT</lastBuildDate>
    <item>
      <title>[D] 寻找 PlotQA 或 ChartQA 上 SOTA 视觉模型的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e50rzd/d_looking_for_comparison_of_sota_vision_models_on/</link>
      <description><![CDATA[有人知道这些视觉 QA 测试中 Claude-3.5-sonnet、GPT-4o、LLaVa 等顶级模型的最新比较吗？    提交人    /u/Confident-Honeydew66   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e50rzd/d_looking_for_comparison_of_sota_vision_models_on/</guid>
      <pubDate>Tue, 16 Jul 2024 21:42:35 GMT</pubDate>
    </item>
    <item>
      <title>[N] 发现了一个有用的工具，可以在大量非结构化数据上扩展 LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4xp2y/n_found_a_helpful_tool_for_scaling_llm_on_a_large/</link>
      <description><![CDATA[所有不同的 LLM 模型/API 提供商都很不错，并且使用 ChatGPT UI。我们拥有大量非结构化数据，例如我们拥有的 PDF 和图像/视频，我们希望从中提取特征。但是我们没有团队来编写 PySpark 代码来扩展工作量，Snowflake 也不能很好地支持非结构化数据。 Roe AI 使我们更容易实现这一点。我们可以轻松地使用 SQL 在我们的非结构化数据集上协调不同的任务，从图像标记和 PDF 解析到多模态搜索。这是他们最新的 substack 帖子供您参考： ~https://roeai.substack.com/p/roe-ai-launches-volansdb~   由    /u/RedemptiVaga  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4xp2y/n_found_a_helpful_tool_for_scaling_llm_on_a_large/</guid>
      <pubDate>Tue, 16 Jul 2024 19:36:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻求研究合作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4vvvz/r_seeking_research_collaboration/</link>
      <description><![CDATA[这是一个长远的目标，但也许会成功：我是一名刚毕业的博士生，正在寻求神经网络压缩领域的合作。我有一个成熟的想法，正在寻找聪明的人来完成实验并一起写论文。我的实验还处于早期阶段，我还没有开始写作，但我在这个领域发表过类似的论文。  关于你：可以使用 GPU 集群，对 PyTorch 和神经网络的内部工作原理有广泛的了解，有训练 Transformers 的经验，你之前曾在 ML 领域发表过论文。  如果你有兴趣，请直接发信息给我。     提交人    /u/walterkronkite33   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4vvvz/r_seeking_research_collaboration/</guid>
      <pubDate>Tue, 16 Jul 2024 18:23:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] DiT 实施失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4vi9h/d_failed_dit_implementation/</link>
      <description><![CDATA[      大家好， 作为我在研究机器人操作时，想训练一个 DiT。我试图让它过度拟合一个简单的 20k 样本 猫数据集 。我的实现类似于论文的“adaLN-Zero”版本（在 LayerNorm 上进行条件化），它有 12 个 DiT 块层、12 个头、隐藏大小为 768 和一个补丁大小为 2。因为图像只包含猫，所以条件化有点没用，因为样本都有相同的标签。我在将它过度拟合到 MNIST 上确实取得了不错的效果。 在 8xA100 上一个小时后，我觉得它已经达到了瓶颈并努力克服它。 结果也很糟糕（图像是 1k 步采样）。我应该期待这个数据集有更好的效果吗？我将非常感谢任何能帮助我的人🙏 这是repo（我很懒，使用了HuggingFace的DDPMScheduler，但计划在它工作时编写自己的） https://preview.redd.it/k9bdi93b8xcd1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=5d3b14d1a16d3f4e9c5fbe8049cec6e4c5d360a5 https://preview.redd.it/9bmstg8c8xcd1.png?width=818&amp;format=png&amp;auto=webp&amp;s=f08747c95b5148a04c42c12ee8462b9bd2c6d057    提交人    /u/Ok_Operation_2094   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4vi9h/d_failed_dit_implementation/</guid>
      <pubDate>Tue, 16 Jul 2024 18:07:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] Tricycle：从头开始完全从 Autograd 到 GPT-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4sz1e/p_tricycle_autograd_to_gpt2_completely_from/</link>
      <description><![CDATA[我想分享 Tricycle：一个我完全从头开始构建的快速、功能齐全的深度学习框架： https://github.com/bclarkson-code/Tricycle/。 到目前为止，最大的里程碑是在单个 RTX 3090 上 68 小时内在 23 亿个代币上训练 GPT-2(124M)，我正在努力进一步扩大规模。 整个库都是从头开始构建的，从 AutoGrad 引擎一直到 GPT-2，任何有一点 Python 经验的人都应该可以理解。我试图使代码尽可能简单而不隐藏任何东西，并且我添加了一个 wiki 来介绍我如何构建所有内容。 我很想听听你的想法！ 编辑：语法    提交人    /u/Efficient_Plankton_9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4sz1e/p_tricycle_autograd_to_gpt2_completely_from/</guid>
      <pubDate>Tue, 16 Jul 2024 16:26:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文讨论：超越：生成模型的表现可以超越训练它们的专家</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</link>
      <description><![CDATA[大家好， 正如标题所示：我创建这篇文章是为了讨论最近发布的论文，该论文到目前为止引起了很多关注。我刚刚阅读了这篇论文，有一些问题。如果你也读过并喜欢这篇论文，我们聊聊吧！ https://arxiv.org/abs/2406.11741  设置对你来说清楚吗？作者是否也通过实验测试了定理 3 或定理 4？ 训练数据集中有多少专家/玩家？如果他们测试定理 4，他们是否会在特定玩家的游戏上训练集合的每个成员？ 他们如何鼓励定理 3 中的不相交集条件？ 等式 4 有一个拼写错误（两个术语相同）？     提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</guid>
      <pubDate>Tue, 16 Jul 2024 14:27:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] Cuda 12.5 Docker 容器错误。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4ps0k/d_cuda_125_docker_container_error/</link>
      <description><![CDATA[Cuda 12.5 的 Cuda 版本控制错误 我正在远程服务器上部署一个 docker 容器。服务器在 Cuda 12.5 上运行，而容器内我使用的是 pytorch 2.3.1+cu121（我猜它是从 transformers 库安装的）。 我收到以下错误： 无法加载库 libcudnn_ops_infer.so.8。错误：libcudnn_ops_infer.so.8：无法打开共享对象文件：没有此文件或目录 我有什么解决方案可以修复容器，而不是将服务器上的 cuda 版本恢复为 11.8。    提交人    /u/cedar_mountain_sea28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4ps0k/d_cuda_125_docker_container_error/</guid>
      <pubDate>Tue, 16 Jul 2024 14:16:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 模型手术：通过简单的参数编辑调节 LLM 的行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4l9xc/r_model_surgery_modulating_llms_behavior_via/</link>
      <description><![CDATA[我们很高兴介绍我们的新工作： 通过直接参数编辑来调节 LLM 行为。以推理级计算成本实现高达 90% 的解毒！ 对于我们想要避免的行为，我们使用线性分类器作为行为探针来对 LLM 的隐藏状态空间进行分类。然后，我们确定影响此行为的关键 LLM 参数，并通过转向行为探针来编辑这些参数。 我们在 RealToxicityPrompts 数据集上的实验表明，我们的方法可以将毒性降低高达 90%，在 ToxiGen 上降低 49%。我们的技术保留了 LLM 的核心功能，例如常识和推理，同时在解毒任务中表现出色。    提交人    /u/Anonymous_user0986   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4l9xc/r_model_surgery_modulating_llms_behavior_via/</guid>
      <pubDate>Tue, 16 Jul 2024 10:30:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 蛋白质语言模型揭示病毒模仿和免疫逃逸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</link>
      <description><![CDATA[我们被 ICML 24/ML4LMS 研讨会接受了，所以我想分享一下 :) &quot;蛋白质语言模型揭示病毒模仿和免疫逃逸&quot; TL;DR: 🧬 研究概述：病毒模仿宿主蛋白以逃避免疫系统的检测。我们使用蛋白质语言模型 (PLM) 来区分病毒蛋白和人类蛋白，ROCAUC 为 99.7%，准确率为 97%。 📊 见解：我们的研究表明，PLM 和生物免疫系统会犯类似的错误。通过识别和分析这些错误，我们可以深入了解免疫反应性以及开发更有效的疫苗和治疗方法的潜在途径。 我们还展示了一种新颖的、可解释的、多模式表格错误分析方法，用于理解任何问题的见解和错误，让我们了解深度学习语言模型/PLM 所犯错误的特征。 🔗 论文：https://openreview.net/forum?id=gGnJBLssbb&amp;noteId=gGnJBLssbb 代码：https://github.com/ddofer/ProteinHumVir 与我和海报见面（#116）在 ICML/ML4LMS 研讨会上！：https://openreview.net/attachment?id=gGnJBLssbb&amp;name=poster doi： https://doi.org/10.1101/2024.03.14.585057    提交人    /u/ddofer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</guid>
      <pubDate>Tue, 16 Jul 2024 09:13:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] “Q-Sparse：所有大型语言模型都可以完全稀疏激活” - Wang 等人，2024 年</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4eji3/r_qsparse_all_large_language_models_can_be_fully/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2407.10969 摘要：  我们引入了 Q-Sparse，一种简单而有效的方法来训练稀疏激活的大型语言模型 (LLM)。Q-Sparse 可实现 LLM 中激活的完全稀疏性，从而显著提高推理效率。这是通过将 top-K 稀疏化应用于激活并将直通式估计器应用于训练来实现的。这项工作的主要成果是：(1) Q-Sparse 可以实现与基线 LLM 相当的结果，同时在推理时间上效率更高； (2) 我们提出了一种用于稀疏激活 LLM 的推理最优缩放律；(3) Q-Sparse 在不同设置下均有效，包括从头开始训练、现成 LLM 的持续训练和微调；(4) Q-Sparse 适用于全精度和 1 位 LLM（例如 BitNet b1.58）。特别是，BitNet b1.58 和 Q-Sparse（可配备 MoE）的协同作用为彻底改变未来 LLM 的效率（包括成本和能耗）提供了基石和明确的道路。     提交人    /u/ComputroniumMonger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4eji3/r_qsparse_all_large_language_models_can_be_fully/</guid>
      <pubDate>Tue, 16 Jul 2024 03:24:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] “创造性”解码策略怎么了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e42das/d_what_happened_to_creative_decoding_strategy/</link>
      <description><![CDATA[对于 GPT-2 以及当时的大多数模型，简单的贪婪解码极易快速生成重复且无意义的输出，需要使用许多技术，例如 top-p 采样、核采样、重复惩罚、n-gram 惩罚等。（例如 https://arxiv.org/pdf/1904.09751 ） 对于最近的 LLM，我没有使用任何这些技巧，相反，0 到 1 之间的任何温度似乎都可以正常工作。我观察到的唯一重复生成似乎是在数学推理中，当模型想要进行一些没有成功的穷举搜索时。  那么，所有这些自定义解码策略是否都已成为过去，我们不再需要担心退化内容生成？     提交人    /u/zyl1024   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e42das/d_what_happened_to_creative_decoding_strategy/</guid>
      <pubDate>Mon, 15 Jul 2024 18:35:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用生成树进行具有自我批评的任意属性条件分子生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e416fw/r_anypropertyconditional_molecule_generation_with/</link>
      <description><![CDATA[  由    /u/AlexiaJM  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e416fw/r_anypropertyconditional_molecule_generation_with/</guid>
      <pubDate>Mon, 15 Jul 2024 17:47:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于如何利用未知数据改进时间序列预测的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e40guh/d_ideas_on_how_to_improve_time_series_forecasting/</link>
      <description><![CDATA[大家好，我的公司决定添加一个分析套件作为我们产品的一部分，而我的任务是创建一个预测解决方案。 我的问题始于这样一个事实：我不知道我将获得什么数据。它可以是每月的财务汇总，例如收入，也可以是每日销售数据。 我目前使用 ETS、SARIMAX、Holt-Winters 和 N-beats 的实现（以防万一）。我使用扩展窗口进行自动超参数调整，然后选择具有最佳 MAPE 的模型。 至于预处理，我会删除非季节性的异常值，并在将数据提供给模型之前使用 Savitzky-Golay 过滤器。 关于如何让这一切不那么像万福玛利亚，有什么建议吗？    提交人    /u/Ok_Bottle2306   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e40guh/d_ideas_on_how_to_improve_time_series_forecasting/</guid>
      <pubDate>Mon, 15 Jul 2024 17:20:09 GMT</pubDate>
    </item>
    <item>
      <title>[N] Yoshua Bengio 的最新公开信回应了反对严肃对待 AI 安全的论点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3viby/n_yoshua_bengios_latest_letter_addressing/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3viby/n_yoshua_bengios_latest_letter_addressing/</guid>
      <pubDate>Mon, 15 Jul 2024 14:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>