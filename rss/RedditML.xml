<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Mon, 20 May 2024 03:16:13 GMT</lastBuildDate>
    <item>
      <title>[R] 医学语言代理模拟（基准）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cw5luk/r_medical_language_agent_simulation_benchmark/</link>
      <description><![CDATA[网站：https://agentclinic .github.io/ Arxiv：https://arxiv.org/pdf/ 2405.07960 TLDR： AgentClinic 将静态医疗 QA 问题转化为临床环境（医生、患者、医疗设备）中的代理，以提出更具临床相关性的挑战医学语言模型。 摘要：诊断和管理患者是一个复杂的、连续的决策过程，需要医生获取信息——例如要执行哪些测试—— ——并据此采取行动。人工智能 (AI) 和大语言模型 (LLM) 的最新进展有望对临床护理产生深远影响。然而，当前的评估方案过度依赖静态的医学问答基准，缺乏现实临床工作中所需的交互式决策。在这里，我们介绍 AgentClinic：一个多模式基准，用于评估法学硕士在模拟临床环境中作为代理运作的能力。在我们的基准中，医生代理必须通过对话和主动数据收集来揭示患者的诊断。我们提出了两个开放基准：多模态图像和对话环境 AgentClinic-NEJM 和纯对话环境 AgentClinic-MedQA。 AgentClinic-MedQA 中的代理以美国医学执照考试 (USMLE) 中的案例为基础，AgentClinic-NEJM 中的代理以多模式新英格兰医学杂志 (NEJM) 案例挑战为基础。我们在患者和医生代理中嵌入认知和隐性偏见，以模拟有偏见的代理之间的真实互动。我们发现引入偏差会导致医生代理人的诊断准确性大幅下降，以及患者代理人的依从性、信心和后续咨询意愿的降低。通过评估一套最先进的法学硕士，我们发现一些在 MedQA 等基准测试中表现出色的模型在 AgentClinic-MedQA 中表现不佳。我们发现患者代理中使用的 LLM 是 AgentClinic 基准测试中性能的重要因素。我们表明，有限的相互作用和过多的相互作用都会降低医生代理的诊断准确性。   由   提交/u/panthsdger  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cw5luk/r_medical_language_agent_simulation_benchmark/</guid>
      <pubDate>Mon, 20 May 2024 03:01:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 模型并行性的最新技术是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cw35by/r_what_is_the_stateofart_of_model_parallelism/</link>
      <description><![CDATA[使用 PyTorch、Tensorflow 等常见框架实现模型并行是否容易？这取决于模型架构？模型并行性最常用的方法是什么？   由   提交/u/Various_Protection71   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cw35by/r_what_is_the_stateofart_of_model_parallelism/</guid>
      <pubDate>Mon, 20 May 2024 00:51:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] AlphaFold 3 的简化 PyTorch 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cw0n8b/p_simplified_pytorch_implementation_of_alphafold_3/</link>
      <description><![CDATA[       由   提交/u/csozboz  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cw0n8b/p_simplified_pytorch_implementation_of_alphafold_3/</guid>
      <pubDate>Sun, 19 May 2024 22:48:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调 LLaVA：持续时间和配置？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvzsqu/d_finetuning_llava_duration_and_configuration/</link>
      <description><![CDATA[大家好， 我正计划微调 LLaVA 模型，很好奇这里是否有人有这方面的经验。具体来说，我希望了解：  数据集的大小（图像和注释的数量）。 微调过程需要多长时间。  数据集的大小（图像和注释的数量）。 微调过程需要多长时间。 li&gt; 您的硬件设置（GPU、CPU、RAM）。 您使用的任何特定配置设置。  提前致谢   由   提交/u/NbaWM2394   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvzsqu/d_finetuning_llava_duration_and_configuration/</guid>
      <pubDate>Sun, 19 May 2024 22:09:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 嵌入维度和 MMD 损失函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvyu8e/r_embeddings_dimensions_and_mmd_loss_function/</link>
      <description><![CDATA[嗨， ScorePerformer 论文（请参阅：https://www.researchgate.net/publication/377272701_ScorePerformer_Expressive_Piano_Performance_Rendering_With_Fine-Grained_Control）提到嵌入Cs的乐谱内容的输出包含L行，而所有其他序列包含N行行数 ( N 可能表示音符的数量）。我不明白为什么这是 L，他们也没有提供这意味着什么。 他们还提到了 MMD 损失，其中不清楚这些 z 和 z&#39; 符号给出的尺寸。我认为矩阵是大写的（因此嵌入 Z 的样式也应该如此），但是这些 z 符号是什么（向量、矩阵……）？还有||是什么？ p 和 q 之间以及高斯核中使用什么类型的范数？ 提前致谢   由   提交/u/Emile_J_11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvyu8e/r_embeddings_dimensions_and_mmd_loss_function/</guid>
      <pubDate>Sun, 19 May 2024 21:25:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您认为未来几年机器学习将在计算生物学和生物信息学等领域发挥什么作用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvxcbc/d_what_role_do_you_think_machine_learning_will/</link>
      <description><![CDATA[我相信计算生物学和生物信息学将越来越多地采用机器学习工作，我很高兴看到所取得的进步。我认为它将在将疾病与可能在标签外使用的现有药物相匹配方面开辟一个全新的世界。我们还应该注意哪些其他事情？ 谁是在这个世界上工作的研究人员？   由   提交/u/RawCS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvxcbc/d_what_role_do_you_think_machine_learning_will/</guid>
      <pubDate>Sun, 19 May 2024 20:19:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM可观察性工具真的在初创公司和公司中使用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvwohz/d_are_llm_observability_tools_really_used_in/</link>
      <description><![CDATA[每周都会推出许多 LLM 可观察性和监控工具。它们真的被真正的初创公司和公司使用吗？  这些工具似乎可以执行以下一项或多项操作： - 监控 LLM 输入和输出以发现提示注入、对抗性攻击、脏话、偏离主题的内容、RTC - &lt;随着时间的推移，监控 LLM 指标，例如成本、延迟、可读性、输出长度和自定义指标（语气、情绪等）、偏差 - 提示管理：a/b 测试、版本控制、黄金标准集 您观察到了什么 - 在拥有自己的 LLM 功能或产品的真实公司中，他们使用这些工具吗？   由   提交 /u/WolvesOfAllStreets   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvwohz/d_are_llm_observability_tools_really_used_in/</guid>
      <pubDate>Sun, 19 May 2024 19:50:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] SOFTS：利用系列核心融合进行高效的多元时间序列预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvtx30/d_softs_efficient_multivariate_time_series/</link>
      <description><![CDATA[很高兴分享我最新的关于时间序列预测的 Medium 文章。“SOFTS：使用系列核心融合进行高效的多元时间序列预测” SOFTS 是一种基于 MLP 的创新模型，利用新颖的 STar Aggregate-Dispatch (STAD) 模块来集中通道交互，以线性复杂度实现卓越的预测性能。与在鲁棒性和复杂性之间进行权衡的传统方法不同，SOFTS 可以有效地捕获渠道相关性，为金融、交通管理和医疗保健等各个领域的可扩展和准确的预测铺平道路。  https ://medium.com/towards-artificial-intelligence/softs-efficient-multivariate-time-series-forecasting-with-series-core-fusion-0ac40d2adcd2   由   提交/u/rezayazdanfar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvtx30/d_softs_efficient_multivariate_time_series/</guid>
      <pubDate>Sun, 19 May 2024 17:47:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] DSPy 真的改变了 LM 权重吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvsviu/d_does_dspy_actually_change_the_lm_weights/</link>
      <description><![CDATA[我一直认为它本质上是美化和结构化的提示工程（在我看来仍然非常有用），但它也在文档中声称它进行了微调和更改LM 权重，然后绝对拒绝在其文档的任何部分中详细说明这一点。 我什至不明白它如何改变 LM 的实际参数，特别是如果我们使用LM 的第三方 API 调用。  通过 LM 权重，我认为它意味着变压器模型最后一层的权重。当他们描述优化器时，他们说“DSPy 引入了新的优化器，这是 LM 驱动的算法，可以根据您想要最大化的指标调整 LM 调用的提示和/或权重。” &lt; p&gt;我是否误解了 LM 权重的含义？ 如果这是一个愚蠢的问题，我很抱歉，但我似乎找不到任何有关此的信息。提前致谢！   由   提交 /u/chessnudes   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvsviu/d_does_dspy_actually_change_the_lm_weights/</guid>
      <pubDate>Sun, 19 May 2024 16:58:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 是如何从从事令人兴奋的研究变成一家类似大型科技公司的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</link>
      <description><![CDATA[我最近重新审视了 OpenAI 关于 DOTA2 Open 的论文五，从工程和研究的角度来看，他们在那里所做的事情令人印象深刻。创建一个包含 50k 个 CPU 的分布式系统用于部署，1k 个 GPU 用于训练，同时每 0.25 秒从 16k 个观察中执行 8k 到 80k 个操作 - 这有多疯狂？他们还对 RL 模型进行“手术”以恢复权重，因为在几个月的训练中，他们的奖励函数、观察空间甚至架构都发生了变化。最后但并非最不重要的一点是，他们击败了 OG 队（当时的世界冠军），并部署了代理与其他玩家在线实时比赛。  快进几年，他们正在预测序列中的下一个标记。不要误会我的意思，gpt4 及其全能版本的功能确实是工程和研究的惊人壮举（可能更有用），但它们似乎并不像它们的一些产品那样有趣（从研究角度来看）  那么，现在我想知道这些年来工程师和研究人员是如何转变的？主要是由于他们的财务状况和盈利需要，还是有更深层次的原因进行转型？   由   提交 /u/UnluckyNeck3925   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</guid>
      <pubDate>Sun, 19 May 2024 16:46:12 GMT</pubDate>
    </item>
    <item>
      <title>来自第一原则的多模态人工智能——最基本的方法 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvrunk/multimodal_ai_from_first_principles_most/</link>
      <description><![CDATA[      分享我制作的一些最关键的视频以及过去十年左右训练多模式模型的基本构建块……如果您对这个主题感兴趣，希望您喜欢！   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvrunk/multimodal_ai_from_first_principles_most/</guid>
      <pubDate>Sun, 19 May 2024 16:12:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在机器学习中回收旧会议提交内容的文化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</link>
      <description><![CDATA[我从事统计机器学习工作。我注意到很多人（包括我自己和我审阅的人）经常重复他们向 ML 会议提交的论文。 例如，如果他们的论文被 ICML 拒绝，他们会提交给 NeurIPS，然后提交给 ICLR（或UAI/AISTATS 在我的领域也是顶尖的）。如果2~3次后没有进入ICML/NeurIPS/ICLR，他们就会将其提交给AAAI/IJCAI/TMLR/ICDM，T-NNLS/T-KDD/NN/Neurocomputing等期刊，或特定领域的场地，如LoG/CoLLA/AABI。经过所有这些，如果论文仍然没有被接受，他们就简单地将它们或 arXiv.我相信 CV/NLP 也可能是这种情况。 作为审稿人，我经常遇到会议提交的内容，作者在没有真正考虑之前提供的审稿的情况下重新提交。有时他们在重新提交时确实会纳入审稿意见，但有时工作可能只是达不到一级会议的水平，但他们只是不断重新提交并希望能够偶然被接受。 我认为这正在消耗社区审稿人的大量时间来继续审阅相同的提交内容（特别是考虑到 NeurIPS 达到 20k 提交 ID；我预计会看到许多重新提交）。这也许也是 TMLR 诞生的原因之一（强调正确性而不是新颖性）。 我确实理解“研究质量比发表地点更重要”之类的论点。或者“OpenAI 通常只是简单地将他们的论文（例如 GPT-X）放在 arXiv 上”。然而，学生或初级研究人员在他们的职业生涯中也需要发表论文，包括我自己。  人们对此有何看法？   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</guid>
      <pubDate>Sun, 19 May 2024 14:04:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在机器学习中有效地进行消融研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/</link>
      <description><![CDATA[在对可预训练和微调的模型进行消融研究时，您是否在预训练和微调期间对每个消融版本执行完整的网格搜索微调？或者你有策略让这个过程更加高效吗？感谢您的见解。   由   提交 /u/Few-Pomegranate4369    reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/</guid>
      <pubDate>Sun, 19 May 2024 13:54:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] N 向注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvkrpf/p_nwayattention/</link>
      <description><![CDATA[我一直在研究在变压器模型中关注两个以上标记的概念。例如，不要使用一个查询和一个密钥，而是使用两个密钥和一个查询，并且对于每对先前标记的每个查询总和。 这使得算法甚至更慢（ O(n**3 ）而不是 O(n**2))，但我认为这是一个有趣的概念。有些结果令我惊讶，比如它在找到最长递增子序列方面有多出色。 我希望它分享它： https://github.com/Gusanidas/n-way-attention/tree/main 并询问是否有人知道处理或提及该概念的论文。   由   提交 /u/Gusanidas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvkrpf/p_nwayattention/</guid>
      <pubDate>Sun, 19 May 2024 09:56:26 GMT</pubDate>
    </item>
    </channel>
</rss>