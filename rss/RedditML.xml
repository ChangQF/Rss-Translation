<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 30 Oct 2024 09:17:38 GMT</lastBuildDate>
    <item>
      <title>[D] 根据调查数据预测幸福感</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfiadq/d_predicting_happiness_from_survey_data/</link>
      <description><![CDATA[我有一个包含 39 个变量的调查数据的数据集，这些变量例如 perfect.physical.health，分数为 -2、-1、0、1、2。现在我想预测幸福感，它是一个小数值。我该如何解决这个问题？    提交人    /u/OverallLab187   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfiadq/d_predicting_happiness_from_survey_data/</guid>
      <pubDate>Wed, 30 Oct 2024 09:12:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于图的分子动力学轨迹 VAE 问题。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfgydn/d_problem_with_graph_basedvae_on_molecular/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfgydn/d_problem_with_graph_basedvae_on_molecular/</guid>
      <pubDate>Wed, 30 Oct 2024 07:26:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语音技术还有哪些地方需要改进？语音研究还剩下什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfgf2d/r_whats_there_yet_to_improve_in_speech/</link>
      <description><![CDATA[大家好，我目前正在本科阶段研究语音技术，主要致力于改进视障人士的应用。我是这个细分研究领域的新手，所以我想选择一个研究课题来解决当前技术的一些现有问题。到目前为止，ElevenLabs 似乎是 SOTA。我想知道 TTS、语音到语音、语音克隆、深度伪造音频检测等方面是否还有其他需要改进的地方，任何关于道德问题或未来护栏需求的见解也会有所帮助。由于大学提供的计算资源较少，我无法处理涉及扩展或多语言的研究。 语音技术还有什么需要改进的？语音研究还剩下什么？ 大家好，我目前正在本科阶段研究语音技术，主要致力于改进视障人士的应用。我是这个细分研究领域的新手，所以我想选择一个研究课题来解决当前技术的一些现有问题。到目前为止，ElevenLabs 似乎是 SOTA。我想知道在 TTS、STT、语音到语音、语音克隆、深度伪造音频检测等方面是否还有其他需要改进的地方，任何关于道德问题或未来护栏需求的见解也会有所帮助。而且由于大学提供的计算资源较少，我无法解决涉及扩展或多语言的研究。    提交人    /u/burikamen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfgf2d/r_whats_there_yet_to_improve_in_speech/</guid>
      <pubDate>Wed, 30 Oct 2024 06:43:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何为新的研究项目构建代码库和工作流程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gffm46/d_how_do_you_structure_your_codebase_and_workflow/</link>
      <description><![CDATA[假设您对所从事领域中的问题的解决方案有了新想法。您如何从头开始实施这个想法？ 您为项目构建的代码库的一般结构是什么？ 您如何迭代地训练和测试您的解决方案，直到您得到可以撰写论文发表的最终解决方案？ 您是否遵循任何设计秘诀？您从哪里学到的？    提交人    /u/HopeIsGold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gffm46/d_how_do_you_structure_your_codebase_and_workflow/</guid>
      <pubDate>Wed, 30 Oct 2024 05:43:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语音分离管道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfclyv/d_voices_separation_pipeline/</link>
      <description><![CDATA[假设我有来自卡拉 OK 的音频，其中 1. 音乐 2. 几个歌声（A、B、C） 3. 随机噪音 假设我确切知道磁带上有多少个主要来源，并且我想要 1. 清除噪音 2. 从磁带中提取声音 B 并返回带有音乐和 A 和 B 人声的音频。 我有几个问题，不胜感激任何帮助。  是否有任何模型可以帮助我进行这种分离（预先训练 / 不需要训练）？ 如果没有，我对可能的解决方案管道有一些想法，不胜感激任何评论：2.1. 将器乐与其他一切分开（我可以使用什么模型来做到这一点？）2.2. 清除没有音乐的音频中的噪音（我可以使用什么模型来做到这一点？）2.3.分离声音（怎么做？）并删除我不需要的波形。2.4. 将我需要的所有东西放回一起。     提交人    /u/m4k2ch8   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfclyv/d_voices_separation_pipeline/</guid>
      <pubDate>Wed, 30 Oct 2024 02:40:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于 PII 屏蔽的开源 AI 工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfa2oh/p_opensource_ai_tool_for_pii_masking/</link>
      <description><![CDATA[隐私一直是并将继续成为未来技术的威胁​​，尤其是人工智能！人工智能和隐私本质上是矛盾的。人工智能需要数据来学习，但数据越多，风险就越大…… 好奇大家对此的看法，也分享了一个名为 PII Masker 的新开源工具，它可以检测和屏蔽文本中的个人身份信息：https://github.com/HydroXai/pii-masker-v1。它使用起来相当简单，使保护敏感数据变得更容易一些。 欢迎任何反馈！    提交人    /u/lial4415   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfa2oh/p_opensource_ai_tool_for_pii_masking/</guid>
      <pubDate>Wed, 30 Oct 2024 00:32:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于训练 ML 的 M4 芯片？（MPS）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gf46km/d_m4_chips_for_training_ml_mps/</link>
      <description><![CDATA[Apple 正在（故意）大肆宣传他们的“Apple Intelligence”，声称他们的 M4 芯片是为 AI 打造的。 我的问题是，这是否只对运行内置的 Apple Intelligence 有帮助 - 或者这是否应该在实际训练大型变压器模型等时大大改进 MPS？我还没有听到他们提到对 MPS 的任何改进。    提交人    /u/Hmm_okay_jeps   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gf46km/d_m4_chips_for_training_ml_mps/</guid>
      <pubDate>Tue, 29 Oct 2024 20:10:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 贝叶斯非参数 - 硕士论文提案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gf1na7/r_bayesian_nonparametrics_master_thesis_proposal/</link>
      <description><![CDATA[大家好， 我开始在数据科学和机器学习项目中规划我的硕士论文，确实需要一些建议来缩小我的主题范围。我的本科论文是关于贝叶斯非参数的，涵盖了狄利克雷过程、分层狄利克雷过程、依赖狄利克雷过程、HDP 主题模型和高斯过程回归等概念。在所有事情中，我非常喜欢实现（尽管很简单）HDP 主题建模的应用程序——亲自动手对我来说是一个亮点。 对于我的硕士学位，我希望在这个贝叶斯基础上进行构建，但将其应用于一些新的东西，理想情况下是在时间序列分析或 NLP 中。我希望这个主题与现在的领域相关，并希望得到关于贝叶斯非参数方法可能增加独特价值的建议，特别是在实际相关的应用中。 需要注意的一件重要事情是，我将独立完成大部分工作，因为我的部门和主管与我选择的兴趣领域并不特别相关。 如果有人对 NLP 或时间序列中的特定领域有想法，可以从贝叶斯方法中受益，或者如果还有其他领域可以有效利用贝叶斯框架，我将非常感谢您的见解。非常感谢您的指导或想法！    提交人    /u/Hungry-Finding2360   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gf1na7/r_bayesian_nonparametrics_master_thesis_proposal/</guid>
      <pubDate>Tue, 29 Oct 2024 18:25:47 GMT</pubDate>
    </item>
    <item>
      <title>[D]“基于图的 VAE 存在问题。另外，我不是一个很好的程序员!!!”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gevt06/d_problem_with_graph_based_vae_ps_i_am_not_a_very/</link>
      <description><![CDATA[因此，我正在尝试生成一个基于图的变分自动编码器模型 (VAE)，使用我的蛋白质的较小轨迹作为输入（我已经在不同的随机种子下生成了我的蛋白质的多个小轨迹）。我的目标是从观察到的轨迹中查看潜在空间，并从较少探索的区域生成新结构，然后从这些区域开始 MD 模拟。 我已经使用蛋白质的 C 阿尔法原子作为输入，并根据两个 C 阿尔法原子之间的接触距离计算邻接矩阵，截止值为 8 埃。但是，我在模型的维数方面面临很多问题，例如我的蛋白质中有 97 个残基，对于测试轨迹有 2500 帧，并且按 80:20 分割，我有训练集（2000,97,97）和验证集（500,97,97）。但是当我尝试解码潜在点时，解码后的维度为 194,97。这让我很困惑。我附上了我正在使用的模型的架构。此外，在我的案例中获得的超参数是： 最佳超参数：{&#39;activation_fn&#39;: ReLU(), &#39;batch_size&#39;: 2, &#39;dropout_rate&#39;: 0.1, &#39;epochs&#39;: 50, &#39;hidden_​​dim&#39;: 16, &#39;latent_dim&#39;: 2, &#39;learning_rate&#39;: 0.001, &#39;num_layers&#39;: 2, &#39;optimizer_type&#39;: &#39;adam&#39;, &#39;weight_decay&#39;: 1e-05}  请检查它们并让我知道我哪里出错了。提前感谢。 GraphVAE( (gcn_layers): ModuleList( (0): GCNConv(97, 16) (1): GCNConv(16, 16) ) (fc_mu): Linear(in_features=16, out_features=2, bias=True) (fc_logvar): Linear(in_features=16, out_features=2, bias=True) (decoder_layers): ModuleList( (0): GCNConv(2, 16) (1): GCNConv(16, 16) ) (decoder_output): GCNConv(16, 97) (activation): ReLU() )     提交人    /u/ShazzieSlays08   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gevt06/d_problem_with_graph_based_vae_ps_i_am_not_a_very/</guid>
      <pubDate>Tue, 29 Oct 2024 14:21:33 GMT</pubDate>
    </item>
    <item>
      <title>[R]“如何训练你的 VAE”大大改善了标准 VAE 模型的报告结果 (ICIP 2024)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1get08n/r_how_to_train_your_vae_substantially_improves/</link>
      <description><![CDATA[      https://preview.redd.it/b1dmh67uroxd1.png?width=1025&amp;format=png&amp;auto=webp&amp;s=3d42a65e2c0a946aa307f01886aebedfc4b88b8e 所提出的方法使用混合高斯函数重新定义了后验概率的证据下限 (ELBO)，引入了正则化项以防止方差崩溃，并采用 PatchGAN 鉴别器来增强纹理真实感。这项工作的主要贡献是 ELBO，它减少了后部向前部的崩溃（观察为生成非常相似、模糊的图像） https://arxiv.org/abs/2309.13160 https://github.com/marianorivera/How2TrainUrVAE    提交人    /u/jarkkowork   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1get08n/r_how_to_train_your_vae_substantially_improves/</guid>
      <pubDate>Tue, 29 Oct 2024 12:08:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] SpotDiffusion：一种随时间推移生成无缝全景图的快速方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gekcus/r_spotdiffusion_a_fast_approach_for_seamless/</link>
      <description><![CDATA[我很高兴地宣布，我们的论文“SpotDiffusion：一种随时间推移生成无缝全景图的快速方法”已被 WACV2025 接受：https://arxiv.org/abs/2407.15507 项目页面：https://spotdiffusion.github.io 代码：https://github.com/stanifrolov/spotdiffusion 我们的方法会随时间推移移动不重叠的去噪窗口，确保一个时间步中的接缝在下一个时间步中得到纠正。这样可以用更少的总体步骤生成连贯的高分辨率图像。我们通过定性和定量评估证明了我们方法的有效性，并将其与 MultiDiffusion、SyncDiffusion 和 StitchDiffusion 进行了比较。我们的方法提供了几个关键优势，包括提高计算效率和加快推理时间，同时产生相当或更好的图像质量。    提交人    /u/Maleficent_Stay_7737   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gekcus/r_spotdiffusion_a_fast_approach_for_seamless/</guid>
      <pubDate>Tue, 29 Oct 2024 02:33:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 动态注意力引导扩散用于图像超分辨率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gekbg3/r_dynamic_attentionguided_diffusion_for_image/</link>
      <description><![CDATA[我很高兴地告诉大家，我们的论文“用于图像超分辨率的动态注意力引导扩散”被 WACV2025 接受了： https://arxiv.org/abs/2308.07977 这项工作的目标是引入一种新的注意力引导扩散机制，将图像细化重点放在从深度细化中受益最大的重要区域上：)    提交人    /u/Maleficent_Stay_7737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gekbg3/r_dynamic_attentionguided_diffusion_for_image/</guid>
      <pubDate>Tue, 29 Oct 2024 02:31:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 超越自回归：离散扩散用于复杂推理和规划</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1geb685/r_beyond_autoregression_discrete_diffusion_for/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2410.14157 我很想听听专家对此的看法。 它与我认为有吸引力的想法有关：  自回归生成在组合领域（例如推理、规划、数学）中受到限制。 这解释了 LLM 在这些领域面临的许多挑战。 扩散在这些领域可能更有效：它学习从一般到具体生成。 （更像是基于能量的模型视角）。 在其生成过程的早期，它不太可能因为做出特定的错误选择而陷入困境。     提交人    /u/marojejian   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1geb685/r_beyond_autoregression_discrete_diffusion_for/</guid>
      <pubDate>Mon, 28 Oct 2024 19:42:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 27 Oct 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>