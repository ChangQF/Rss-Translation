<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 30 Nov 2024 06:22:53 GMT</lastBuildDate>
    <item>
      <title>[D] AWS 认证机器学习工程师助理模拟考试 MLA-C01 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h367r5/d_aws_certified_machine_learning_engineer/</link>
      <description><![CDATA[        由    /u/ampankajsharma 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h367r5/d_aws_certified_machine_learning_engineer/</guid>
      <pubDate>Sat, 30 Nov 2024 06:09:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最快的物体检测模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h362dq/d_whats_the_fastest_object_detection_model/</link>
      <description><![CDATA[嗨，我正在做一个需要物体检测的项目。由于物体非常清晰，任务本身并不复杂，但速度至关重要。我研究过各种物体检测模型，似乎几乎每个人都声称自己是“最快的”。由于我将用 C++ 部署模型，所以没有时间移植和评估它们。 我之前测试过 YOLOv5/v5Lite/8/10，YOLOv5n 是最快的。我在 Oracle ARM 服务器上运行了一个简单的基准测试（详情见此处），它仅用 54ms 就处理了一张目标大小为 640 的图像。不幸的是，我当前项目的硬件性能明显较差，同时处理时间必须少于 20ms。我将使用量化和动态维度之类的方法来提高速度，但我必须先选择合适的模型。 有人遇到过类似的情况或专门针对速度测试过模型吗？有没有比 YOLOv5n 更快且值得一试的模型建议？    提交人    /u/Knok0932   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h362dq/d_whats_the_fastest_object_detection_model/</guid>
      <pubDate>Sat, 30 Nov 2024 06:00:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 接受整数输入的 Softmax 的 Python 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h318gl/p_python_implementation_of_softmax_that_takes/</link>
      <description><![CDATA[嗨，我正在做一个项目，我必须将模型的权重和偏差量化为整数，并使用整数执行后续操作。我的模型的输出可以是 (int8 或 int16) 值（在本例中为 logits），我需要在此 logits 输出/数组上调用 softmax。我找到了用 C 编写的 softmax 整数实现（https://github.com/ARM-software/CMSIS-NN/tree/main/Source/SoftmaxFunctions）。我遇到的问题是尝试评估此 C 实现是否准确（或者更具体地说，我是否准确使用它）。我考虑这样做的方式详述如下： **在 Python 中** 取我的整数 logits -&gt;在 logits 上调用 softmax 的整数 python 实现 ——&gt; 获得结果 (**python_integer_prediction_probabilities**)。 ** 在 C 中（使用 CMSIS-NN） 取相同的整数 logits ——&gt; 在我的 logits 上调用 C softmax 实现 ——&gt; 获得结果 (**CMSIS_NN_prediction_probabilities**) 最后，我比较这两个结果以查看它们是否足够接近。我遇到的主要问题是，我假设会有关于如何在 Python 中实现接受整数输入的 softmax 函数的信息，但我在网上找不到任何东西。有谁知道如何在 python 中实现它，或者知道我可以用来解决这个问题的资源吗？谢谢。    提交人    /u/Individual_Ad_1214   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h318gl/p_python_implementation_of_softmax_that_takes/</guid>
      <pubDate>Sat, 30 Nov 2024 01:24:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分子动力学与机器学习构建</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2x4ar/d_molecular_dynamics_and_machine_learning_build/</link>
      <description><![CDATA[大家好，我做了很多分子动力学研究，并开始利用该领域和基因组/多组学等东西进入机器学习领域。我正在构建一个工作站，根据我的预算，我正在寻找 2x A6000 或 2x 5000 Ada。两者都非常适合分子动力学，但我正在尝试找出机器学习的最佳选择。A6000 有 48gb vram 和 nvlink，但 5000 Ada 更新，速度快得多，每张卡 32Gb VRAM 也不错。有什么建议吗？    提交人    /u/Mdgoff7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2x4ar/d_molecular_dynamics_and_machine_learning_build/</guid>
      <pubDate>Fri, 29 Nov 2024 22:04:19 GMT</pubDate>
    </item>
    <item>
      <title>[N][R] 模型就是食物：法学硕士的自动数据管理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2qmol/nr_models_are_what_they_eat_automatic_data/</link>
      <description><![CDATA[在 DatologyAI 上分享我们的最新成果。模型就是它们的食物，我们的使命是让训练大型模型的数据管理尽可能有效和简单。 通过结合多种方法，包括启发式过滤器、基于模型的过滤器、基于嵌入的管理、合成数据、目标分布匹配和混合比率，我们能够大幅提高训练效率、性能和推理效率。  与我们的基线和起始数据集（精确去重的 RedPajamav1）相比，我们可以：  以 7.7 倍的速度达到相同的性能（比 DCLM 快 3.4 倍） 在基准测试中将性能提高 8.5%（比 DCLM 提高 4.4%） 使用不到一半的参数训练模型，其性能比大型模型高出 5% 以上  请在此处查看我们的高级结果，如果您需要所有细节，请查看我们的 技术深度探究。    提交人    /u/arimorcos   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2qmol/nr_models_are_what_they_eat_automatic_data/</guid>
      <pubDate>Fri, 29 Nov 2024 17:15:57 GMT</pubDate>
    </item>
    <item>
      <title>“[P]”RFM中的静态变量和动态变量表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2oe69/pstatic_variable_and_dynamic_variable_tables_in/</link>
      <description><![CDATA[我正在使用随机森林创建一个预测模型。但我不明白模型和脚本如何考虑以数据框形式加载的两个表。 当一个表具有静态属性（如食物特征）而另一个表具有动态因素（如日常健康习惯）时，在随机森林模型中使用多个表的最佳方法是什么？ 例如：我想根据我吃的食物（不变）和日常因素（睡眠、饮水量）预测胃痛。 表格： * 静态：食物名称、卡路里、肉类（是/否） * 动态：天数、睡眠良好（是/否）、喝水（是/否） 如何在随机森林模型中组合这些表？它们是否应该合并到像“天数”这样的唯一标识符上？    提交人    /u/peyott100   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2oe69/pstatic_variable_and_dynamic_variable_tables_in/</guid>
      <pubDate>Fri, 29 Nov 2024 15:36:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] Hinton 和 Hassabis 论乔姆斯基的语言理论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2mkye/d_hinton_and_hassabis_on_chomskys_theory_of/</link>
      <description><![CDATA[我刚进入这个领域，很想听听更多这方面的观点。我一直认为乔姆斯基是这方面的重要人物，但似乎 Hinton 和 Hassabis（后来）都不同意。这里：https://www.youtube.com/watch?v=urBFz6-gHGY（较长版本：https://youtu.be/Gg-w_n9NJIE） 我很想从 ML 和 CogSci 的角度来看待这个问题，以及支持/拒绝这种观点的更多来源。 编辑：拼写错误 + 添加来源。    提交人    /u/giuuilfobfyvihksmk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2mkye/d_hinton_and_hassabis_on_chomskys_theory_of/</guid>
      <pubDate>Fri, 29 Nov 2024 14:10:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] COLING 2025 最终录取 - 还没有出来吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2kfic/d_coling_2025_final_acceptances_is_it_not_out_yet/</link>
      <description><![CDATA[最终录取结果出来了吗？我在 Softconf 上还没有看到。有一篇论文的评论是 (5,4) (4,4) (4,4)。    提交人    /u/UnhappyPrior6570   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2kfic/d_coling_2025_final_acceptances_is_it_not_out_yet/</guid>
      <pubDate>Fri, 29 Nov 2024 12:10:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 矢量场（已知和未知）之间的递归插值方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2io35/r_recursive_methods_for_interpolation_between/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2io35/r_recursive_methods_for_interpolation_between/</guid>
      <pubDate>Fri, 29 Nov 2024 10:08:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果 VQ-VAE 能够解开的话，它该如何解开呢？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h2epzx/d_how_does_vqvae_disentangle_if_it_does_at_all/</link>
      <description><![CDATA[我目前使用 BetaTC-VAE，它在解缠方面做得非常出色，我知道 VAE 可以稍微解缠，因为对于模型来说，如果变量解缠，更容易获得较低的 KL 损失，beta 项使这个 beta 倍更重要，总相关性和互信息损失推动完全解缠，但在 VQ-VAE 中没有（主要）解缠，只有码本和离散输出。码本给出的离散潜在空间可以解缠吗？如果不能，有没有关于解缠 VQ-VAE 的论文？我有一个环境，其中解缠的潜在空间比连续潜在空间提供更好的重建     提交人    /u/ZazaGaza213   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h2epzx/d_how_does_vqvae_disentangle_if_it_does_at_all/</guid>
      <pubDate>Fri, 29 Nov 2024 05:33:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] BitNet a4.8：1 位 LLM 的 4 位激活</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h1y0ig/r_bitnet_a48_4bit_activations_for_1bit_llms/</link>
      <description><![CDATA[      论文： https://arxiv.org/pdf/2411.04965 摘要：  最近对 1 位大型语言模型 (LLM)（例如 BitNet b1.58）的研究为降低 LLM 的推理成本同时保持其性能提供了一个有希望的方向。在这项工作中，我们引入了 BitNet a4.8，为 1 位 LLM 启用 4 位激活。BitNet a4.8 采用混合量化和稀疏化策略来减轻异常通道引入的量化误差。具体来说，我们利用 4 位激活作为注意力和前馈网络层的输入，同时稀疏中间状态，然后进行 8 位量化。大量实验表明，BitNet a4.8 在训练成本相当的情况下，实现了与 BitNet b1.58 相当的性能，同时在启用 4 位（INT4/FP4）内核的情况下，推理速度更快。此外，BitNet a4.8 仅激活 55% 的参数并支持 3 位 KV 缓存，进一步提升了大规模 LLM 部署和推理的效率。  Visual Abstract: https://preview.redd.it/gpt38utvqn3e1.png?width=1011&amp;format=png&amp;auto=webp&amp;s=1c9a09638675e7a9f89e3804c1df0229663d136a 评估： HS=HellaSwag, PQ=PiQA, WGe=WinoGrande https://preview.redd.it/7qrw9jtqrn3e1.png?width=1033&amp;format=png&amp;auto=webp&amp;s=ecfdcb655ae939de8f297e37ef111b8ccaa2b1c9    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h1y0ig/r_bitnet_a48_4bit_activations_for_1bit_llms/</guid>
      <pubDate>Thu, 28 Nov 2024 15:11:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 现代扩散模型背后的理论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h1vxe1/d_theory_behind_modern_diffusion_models/</link>
      <description><![CDATA[大家好， 我最近在大学里听了一些关于扩散模型的讲座。这些讲座详细解释了原始 DDPM（去拟态扩散概率模型）背后的所有数学知识（尤其是在附录中），实际上比我在网上找到的任何其他知识都要好。因此，它对于学习扩散模型背后的基础知识非常有帮助（如果您有兴趣，可以在此处的自述文件中的链接中找到幻灯片：https://github.com/julioasotodv/ie-C4-466671-diffusion-models） 但是，我正在努力寻找具有类似现代方法详细程度的资源 - 例如流匹配/整流流，用于采样的不同 ODE 求解器的工作原理等。有一些，但我发现的一切要么相当过时（比如从 2​​023 年左右开始），要么非常肤浅 - 例如对于非技术或科学受众而言。 因此，我想知道：除了原始论文之外，是否有人遇到过超出基本扩散模型的理论解释的良好汇编？我们的目标是让我的团队深入研究他们想要的实际论文，但要将其中 70% 的内容放在一个或多个像样的汇编中。 我真的相信，如今 SEO 让任何搜索都变成了一场噩梦。要么就是我的谷歌搜索技能因为某种原因而下降了。 谢谢大家！    提交人    /u/bgighjigftuik   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h1vxe1/d_theory_behind_modern_diffusion_models/</guid>
      <pubDate>Thu, 28 Nov 2024 13:27:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 尽管 Stella 嵌入在 MTEB 排行榜上名列前茅，为什么却没有得到更广泛的应用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h1u814/d_why_arent_stella_embeddings_more_widely_used/</link>
      <description><![CDATA[https://huggingface.co/spaces/mteb/leaderboard 我一直在研究嵌入模型，并注意到一些有趣的事情：Stella 嵌入在 MTEB 排行榜上遥遥领先，表现优于 OpenAI 的模型，同时规模更小（1.5B/400M 参数）且使用 apache 2.0。托管它们相对便宜。 作为参考，Stella-400M 在 MTEB 上的得分为 70.11，而 OpenAI 的 text-embedding-3-large 为 64.59。1.5B 版本的得分甚至更高，为 71.19 然而，我很少看到它们在生产用例或讨论中被提及。这里有人在生产中使用过 Stella 嵌入吗？与 OpenAI 的产品相比，您在性能、推理速度和可靠性方面的体验如何？ 只是想了解为什么尽管基准测试令人印象深刻，但它们没有得到更广泛的采用，这是否是我遗漏了什么。 很想听听您的想法和经验！    提交人    /u/sdsd19   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h1u814/d_why_arent_stella_embeddings_more_widely_used/</guid>
      <pubDate>Thu, 28 Nov 2024 11:45:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 24 Nov 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>