<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 06 Sep 2024 12:29:49 GMT</lastBuildDate>
    <item>
      <title>[D] 对于关心 LLM 输出质量和评估的人，我创建了 r/AIQuality（一个用于无幻觉系统的网站）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1facpyh/d_for_people_who_care_about_output_quality_and/</link>
      <description><![CDATA[RAG 和 LLM 无处不在，这是有原因的！它通过结合 LLM 与外部知识源，改变了 LLM 生成明智、准确响应的方式。 但在所有这些热议中，我注意到没有专门的空间来深入研究 LLM/RAG 评估、分享想法和共同学习。因此，我创建了一个社区，供那些有兴趣评估 LLM/RAG 系统、了解最新研究和衡量 LLM 输出质量的人使用。 加入我们，让我们一起探索 AI 评估的未来！    提交人    /u/Desperate-Homework-2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1facpyh/d_for_people_who_care_about_output_quality_and/</guid>
      <pubDate>Fri, 06 Sep 2024 11:23:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能的扩展能否持续到2030年？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1facftg/d_can_ai_scaling_continue_through_2030/</link>
      <description><![CDATA[EpochAI 就此问题撰写了一篇很长的博客文章：https://epochai.org/blog/can-ai-scaling-continue-through-2030 让我感到奇怪的是以下说法：  索引的网络包含大约 500T 个单词的独特文本  但这似乎与 L. Aschenbrenner 在《情境意识》中所写的内容不谋而合：  Frontier 模型已经在互联网的大部分内容上进行了训练。例如，Llama 3 已在超过 15T 个 token 上进行了训练。 Common Crawl 是用于 LLM 培训的大量互联网转储，原始令牌数量超过 100T，尽管其中大部分是垃圾邮件和重复数据（例如，一个相对简单的重复数据删除会产生 30T 令牌，这意味着 Llama 3 基本上已经使用了所有数据）。此外，对于像代码这样的更具体的领域，令牌数量仍然少得多，例如公共 github 存储库估计有数万亿个令牌。     提交人    /u/we_are_mammals   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1facftg/d_can_ai_scaling_continue_through_2030/</guid>
      <pubDate>Fri, 06 Sep 2024 11:06:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 贝叶斯模型与共形预测 (CP)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fac5u5/d_bayesian_models_vs_conformal_prediction_cp/</link>
      <description><![CDATA[大家好， 我创建这篇文章是为了征求您对两种主要不确定性量化范式的看法。我看到代表他们的研究人员之间存在着激烈的竞争。我对近似参考（和贝叶斯深度学习）进行了研究，但除了 CP 的基本教程之外，我对 CP 不是很熟悉。我个人认为它们都是有用的工具，也许可以互补使用： CP 可以提供保证，但是是 poshoc 方法，而 BDL 可以使用先前的正则化来实际*改善*训练期间模型的泛化。此外，CP 基于 IID 假设（抱歉，这不是普遍正确的，至少这是本教程中的假设），而在 BDL 中，输入仅在以参数观察为条件时才是 IID：一般来说，p(yi,yj|xi,xj)!=p(yi|xi)p(yj|xj) 但 p(yi,yj|xi,xj,theta)=p(yi|xi, theta)xp(yj|xj, theta)。因此，BDL 或高斯过程在这方面可能更为现实。 最后，贝叶斯模型不能派生出一个 CP 吗？在这种情况下，CP 提供的预测集和贝叶斯模型提供的预测集有多大程度的一致？是否有研究论文将这些方法结合起来并对此进行测试？ 如果我的问题太基础，请提前道歉。我只是想在两种范式之间保持公正的视角。    提交人    /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fac5u5/d_bayesian_models_vs_conformal_prediction_cp/</guid>
      <pubDate>Fri, 06 Sep 2024 10:50:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] mp3歌曲推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fabuai/d_mp3_song_recommendations/</link>
      <description><![CDATA[我想制作一个应用程序，可以根据我正在听的歌曲获得推荐。我的 mp3 文件中有 50 首歌曲，我想制作基于 Web 的歌曲推荐系统。我已经使用 flask 创建了应用程序，但我不知道如何进一步帮助我尽快完成它。我也在 YouTube 和谷歌上搜索过，但没有找到任何有用的东西。     提交人    /u/Capital_learner   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fabuai/d_mp3_song_recommendations/</guid>
      <pubDate>Fri, 06 Sep 2024 10:29:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检索增强生成 vs 长上下文 LLM，我们确定后者会取代前者吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fabu65/d_retrievalaugmented_generation_vs_longcontext/</link>
      <description><![CDATA[我认为这个问题已经争论了很长时间。但最近有两篇关于这个问题的有趣文章，我想以此作为讨论 RAG 与长上下文 LLM 的起点。 总之，如果我们可以将所有内容都放在提示中，我们就不需要进行检索。但是，我真的怀疑我们能否拥有一个能够覆盖任何组织拥有的大量数据的上下文长度的模型（并且没有可怕的计算成本）。 无论如何，有令人难以信服的报告称 LC-LLM 在 QA 中效果更好（至少到目前为止，我还没有读过一篇文章让我相信 LC-LLM 比 RAG 效果更好）。  有两篇文章讨论了噪声对 LLM 和 RAG 的影响：  第一篇文章指出噪声会影响 LLM 的性能，并竭尽全力对此进行描述。https://arxiv.org/abs/2408.13533 第二篇文章比较了 RAG 和 LC-LLM，并表明通过增加上下文的大小，我们会出现峰值（我们添加相关块），然后性能会下降，因为 LLM 更难找到正确的信息。 https://arxiv.org/abs/2409.01666  我认为我们最终会保留 RAG 的原因或多或少是 LLM 是复杂的神经网络，因此也是模式识别机器。最终，优化信噪比是机器学习中最常见（有时也很困难）的任务之一。当我们开始过度增加这种噪音时，最终模型必然会开始发现噪音并偏离重要信息（此外，LLM 的参数记忆和上下文之间也存在微妙的相互作用，我们仍然不知道为什么有时会忽略上下文） 其次，我个人认为，还有一个结构性原因。自注意力机制会寻求相关关系，而在上下文长度增加的情况下，我们倾向于维数灾难，最终会加剧虚假关系。 我想和您讨论一下您认为 RAG 不会被取代的原因，或者您是否认为 LC-LLM 最终会取代它？在第二种情况下，它如何解决大量上下文无关数据的问题？    submitted by    /u/NoIdeaAbaout   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fabu65/d_retrievalaugmented_generation_vs_longcontext/</guid>
      <pubDate>Fri, 06 Sep 2024 10:29:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 CUDA 比 ROCm 快这么多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fa8vq5/d_why_is_cuda_so_much_faster_than_rocm/</link>
      <description><![CDATA[通常人们会回答“因为 NVIDIA 有更多的时间和金钱”。但是，为什么 AMD 无法赶上？究竟是什么让优化 ROCm 如此困难？ 如果您可以指出一些资源，或者您的回答尽可能详细地说明特定内核和结构的实现以及如何从 Triton 或 XLA 精确地进行和优化 CUDA 调用，那将会很有帮助。谢谢 :)    提交人    /u/evilevidenz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fa8vq5/d_why_is_cuda_so_much_faster_than_rocm/</guid>
      <pubDate>Fri, 06 Sep 2024 06:52:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找类似 CLIP 的 LLM/Vision 模型进行图像分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fa6ayc/d_looking_for_an_llmvision_model_like_clip_for/</link>
      <description><![CDATA[嗨，我正在使用 CLIP 来分析图像，但正在寻找更好的选项来完成这些任务：  检测图像中是否有人。 确定是否存在多人。 识别人是否面向摄像头。 检测手机、平板电脑、智能手表或其他电子设备。 检测书籍、笔记。  有没有更好的模型（或为每个任务单独设置模型）适合这种类型的详细分析的建议？谢谢！    提交人    /u/Substantial_Video_26   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fa6ayc/d_looking_for_an_llmvision_model_like_clip_for/</guid>
      <pubDate>Fri, 06 Sep 2024 04:09:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 本周，我在 Tinygrad 中实现了论文“关注 MLP”！:D</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fa5kop/p_this_week_i_implemented_the_paper_pay_attention/</link>
      <description><![CDATA[      为了尝试更有趣的模型架构，我在 Tinygrad 中实现了 gMLP！ 如果有人想提供一些反馈，将受到欢迎。  [存储库]：https://github.com/EthanBnntt/tinygrad-gmlp [安装]：pip install gmlp_tinygrad [原始论文]：https://doi.org/10.48550/ARXIV.2105.08050  显示 gMLP 架构的图表    提交人    /u/the-wonderful-world   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fa5kop/p_this_week_i_implemented_the_paper_pay_attention/</guid>
      <pubDate>Fri, 06 Sep 2024 03:29:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 带独立性约束的 VAE</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9sxli/d_vae_with_independence_constraints/</link>
      <description><![CDATA[我对 VAE 感兴趣，它允许通过添加一些约束来主动塑造潜在空间。 我设想类似这样的做法：指定 z 的某些部分和一个度量 m，并确保它们是独立的，即潜在空间的特定部分不会对 m 所描述的特征产生任何影响。 你能推荐一些可能涉及类似问题的论文吗？    提交人    /u/stardiving   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9sxli/d_vae_with_independence_constraints/</guid>
      <pubDate>Thu, 05 Sep 2024 17:59:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] Segment Anything 2 (SAM2) 的开源应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9rv7m/p_opensource_app_for_segment_anything_2_sam2/</link>
      <description><![CDATA[大家好， 我很高兴与大家分享我们一直在研究的一个开源项目：Meta 的 Segment Anything 2 (SAM2) 模型的功能演示。 主要特点：  在 GPU 上运行的 FastAPI 后端（在 NVIDIA T4 上测试） 基于 React 的前端，易于交互 支持视频分割  技术堆栈：  后端：Python、FastAPI、PyTorch 前端：React、TypeScript  该项目旨在为研究人员和开发人员提供一种便捷的方式来试验 SAM2。这项工作正在进行中，我正在积极寻找贡献者来帮助改进和扩展其功能。 您可以在此处找到该项目：https://github.com/streamfog/sam2-app 我很乐意听到您的想法、建议或您可能有的任何问题。如果您有兴趣，请随时查看并做出贡献！    提交人    /u/kevinpl07   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9rv7m/p_opensource_app_for_segment_anything_2_sam2/</guid>
      <pubDate>Thu, 05 Sep 2024 17:16:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如果自我注意力不是最重要的事情怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9nefc/r_what_if_selfattention_isnt_the_endall_beall/</link>
      <description><![CDATA[关于 transformer 中的信息丢失，这是一个有趣的替代方案。很想听听你对此的看法！ 用于语言生成和检索的掩码混合器 https://arxiv.org/html/2409.01482v1    提交人    /u/Status-Shock-880   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9nefc/r_what_if_selfattention_isnt_the_endall_beall/</guid>
      <pubDate>Thu, 05 Sep 2024 14:06:55 GMT</pubDate>
    </item>
    <item>
      <title>波士顿的人工智能、长寿和认知 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9n9zk/ai_longevity_cognition_in_boston_d/</link>
      <description><![CDATA[大家好！今天 9 月 5 日下午 4:30 至晚上 8 点，我们将在剑桥肯德尔广场（麻省理工学院附近）的 Aethos Station 举办一场关于人工智能促进长寿和认知增强的活动。欢迎所有好奇的人，无论您是科学家、工程师还是学生。希望在那里见到你并学到新东西！请在此处免费回复：https://lu.ma/hellothere    提交人    /u/ekkolapto1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9n9zk/ai_longevity_cognition_in_boston_d/</guid>
      <pubDate>Thu, 05 Sep 2024 14:01:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 探索是解锁更好的推荐系统的关键吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9m33i/r_is_exploration_the_key_to_unlocking_better/</link>
      <description><![CDATA[Google DeepMind 的研究人员最近发表了一篇富有洞察力的论文，深入探讨了推荐平台内探索的长期好处。他们认为，虽然短期指标可能无法立即反映优势，但探索可以通过扩大内容语料库来显著增强长期用户体验。  我们在本文中探讨了详细信息：https://www.shaped.ai/blog/is-the-key-to-unlocking-better-user-experiences-in-recommender-systems-found-in-exploration    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9m33i/r_is_exploration_the_key_to_unlocking_better/</guid>
      <pubDate>Thu, 05 Sep 2024 13:09:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 01 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>