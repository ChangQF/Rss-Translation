<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 02 Feb 2024 18:17:23 GMT</lastBuildDate>
    <item>
      <title>[D] 限制生成的微调扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ah9k8m/d_finetuning_diffusion_model_for_restricted/</link>
      <description><![CDATA[我有大约 3K 的单个组件/类的图像，比如在不同环境、方向等下捕获的 X。 而且我想要微调扩散模型，以便生成的样本（无条件生成）来自我的自定义分布（仅限于我的域；即具有相似背景的组件 X，从我的 3K 图像的自定义数据集学习的方向）而不是像 X 中的 X埃菲尔铁塔等 有这样的工作吗？  PS：我的最终目标是进行数据增强。我将拥有 Y 类的 3D 模型，并希望生成示例，例如用 Y 替换 X 的自定义数据集。   由   提交/u/sushilkhadakaanon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ah9k8m/d_finetuning_diffusion_model_for_restricted/</guid>
      <pubDate>Fri, 02 Feb 2024 17:47:05 GMT</pubDate>
    </item>
    <item>
      <title>[D]基于LSTM的情感分析模型中的Weired特征空间</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ah9a9c/d_weired_feature_space_in_lstmbased_sentiment/</link>
      <description><![CDATA[      我正在尝试可视化模型生成的特征空间。 （模型训练完毕后，我就传递了训练数据，并在最后一层之前获得了嵌入。）我的模型是基于 LSTM 的模型，数据集是推文情绪分类数据集，它有 3 个类别（正面、负面和中性） ）。模型准确率超过 80%，但我在下面看到奇怪的可视化效果。有谁知道那里发生了什么事吗？如何改善可视化（集群之间有更多空间）？  ​ 使用 t-SNE 完成可视化 ​ 使用 PCA 完成可视化   由   提交 /u/The_Aoki_Taki   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ah9a9c/d_weired_feature_space_in_lstmbased_sentiment/</guid>
      <pubDate>Fri, 02 Feb 2024 17:35:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士可以自动确定要运行哪些评估吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ah8f7n/d_can_llms_automatically_figure_what_evaluations/</link>
      <description><![CDATA[评估 LLM 申请很困难。现在，随着提示的复杂性不断增加（现在的提示有 50 多条指令），甚至决定评估什么也很困难。 定义这些评估变得乏味、耗时且容易出错。加州大学伯克利分校、香港科技大学、LangChain 和哥伦比亚大学的研究人员最近发表的一篇论文，标题为：“spade：综合大型语言模型管道的断言&lt; /a&gt;”旨在解决“自动生成提示指令评估”的问题 Spade 将提示指令分为以下几类：   类别 描述    演示文稿格式 响应是否有特定格式，例如逗号分隔的列表或 JSON 对象？   示例演示 &lt; tdalign=&quot;left&quot;&gt;提示模板是否包含展示任何特定标头、键或结构的良好响应示例？   工作流程描述&lt; /td&gt; 提示模板是否包含LLM应遵循的工作流程的任何描述，表明可能的断言概念？   计数 是否有关于响应中某种类型的项目数量的说明，例如“至少”、“最多”或确切的数字？   包含 每个 LLM 回复都应包含关键字吗？   排除 是否有每个 LLM 回复都不应提及的关键字？   定性评估 是否有评估良好回复的定性标准，包括长度、语气或风格的具体要求？ 其他 根据提示模板，是否还有上述类别未涵盖的其他概念需要检查断言，例如正确性、完整性或一致性?   ​ 使用其新颖的指令分类，Spade 生成一组候选评估，确定其关键性和冗余性，最后通过求解 ILP 生成最佳集。 我们最近尝试使用 spade 自动生成要运行的评估，然后通过 UpTrain 运行它们，所有这些都以自动化的方式进行。您可以在此处查看它  由   提交 /u/Vegetable-Skill-9700   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ah8f7n/d_can_llms_automatically_figure_what_evaluations/</guid>
      <pubDate>Fri, 02 Feb 2024 16:59:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你使用任何人工智能编码工具吗？如果是这样，为了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ah7k69/d_do_you_use_any_ai_coding_tools_if_so_for_what/</link>
      <description><![CDATA[大家好， 我们公司决定采用人工智能编码工具，现在我们正在测试不同的工具和工作流程，例如 Copilot 、Cursor、CodeRabbit 等等。 我只是想知道，您在日常工作流程中还使用哪些其他工具？ 我们发现 Cursor 非常有用 - 我们写道有关更高级工作流程的博客文章，如果您有兴趣，可以在这里阅读：https:// palindrom.beehiiv.com/p/issue-1-cursor-need   由   提交 /u/BootstrapGuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ah7k69/d_do_you_use_any_ai_coding_tools_if_so_for_what/</guid>
      <pubDate>Fri, 02 Feb 2024 16:22:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 代码 LLAMA 70B 的免费推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ah510a/d_free_inference_for_code_llama_70b/</link>
      <description><![CDATA[是否有提供代码 llama 70B 的免费推理的提供商？我想在将其 lamma.cpp 版本下载到本地之前进行一些测试。   由   提交 /u/kiranp2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ah510a/d_free_inference_for_code_llama_70b/</guid>
      <pubDate>Fri, 02 Feb 2024 14:32:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] BertClassification 对于非常长的输入句子。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ah4i9e/d_bertclassification_for_really_long_input/</link>
      <description><![CDATA[所以我现在正在尝试解决一个任务，数据集中的输入字符串长度为 10-20K。使用 BertForSeqeuenceClassification 中的分词器处理此问题的最佳方法是什么？ ​ 我已经检查了 LongFormer 和 BigBird，但它们也仅限于 512 和4096 令牌长度。 在这件事上提供一些帮助将不胜感激。   由   提交/u/aMnHa7N0Nme   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ah4i9e/d_bertclassification_for_really_long_input/</guid>
      <pubDate>Fri, 02 Feb 2024 14:08:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] LangChain4J人工智能搜索引擎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ah43r1/p_ai_search_engine_with_langchain4j/</link>
      <description><![CDATA[受 search-with-lepton 项目的启发，我刚刚使用 Spring Boot 和 LangChain4J 构建了一个人工智能搜索引擎。 在这个项目中，我也想分享一下我对 RAG 的一些想法。如果您对此感兴趣，请查看这里：https://github.com/vlinx-io/infinite-search   由   提交 /u/Axiomatic_Inspector_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ah43r1/p_ai_search_engine_with_langchain4j/</guid>
      <pubDate>Fri, 02 Feb 2024 13:49:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 运行基线的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ah3qil/r_tools_for_running_baselines/</link>
      <description><![CDATA[根据我的经验，实施研究是研究中最糟糕的部分。大学不仅缺乏计算能力，调试机器学习代码也很困难，而且没有实施基线/其他人实验的标准。有些论文从未发布其完整的代码库和重现结果的说明，即使两篇论文在同一数据集上进行评估，它们的数据整理/模型代码也可能完全不同。我最终花了几周的时间才让所有东西都能一起工作。对新数据集进行评估甚至更糟糕，因为您最终不得不进行疯狂的超参数鹅追逐以确保设置公平。 人们运行基线的技术是什么？或者是否没有比自己手动完成所有工作或希望有人已经在另一个项目存储库中完成大部分工作更好的方法了？   由   提交/u/like_a_tensor  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ah3qil/r_tools_for_running_baselines/</guid>
      <pubDate>Fri, 02 Feb 2024 13:31:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语言模型对齐是如何工作的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ah383z/d_how_does_language_model_alignment_work/</link>
      <description><![CDATA[我正在阅读有关语言模型对齐的内容，但我不明白的是我们如何找到胜率。我的理解是：&lt; /p&gt;  胜率=(期望响应等级的次数＜非期望响应等级的次数)/总数的总和。数据点   但是我不清楚的是： - 排名在这里意味着什么？ - 我们如何获得排名？ - 如何我们是否确保人类注释者的响应是此处获胜的响应（因为它可能与语言模型的响应不匹配）   由   提交 /u/reallfuhrer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ah383z/d_how_does_language_model_alignment_work/</guid>
      <pubDate>Fri, 02 Feb 2024 13:05:55 GMT</pubDate>
    </item>
    <item>
      <title>[2402.00795]法学硕士学习动力系统的控制原理，揭示上下文中的神经标度定律</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agzl6i/240200795_llms_learn_governing_principles_of/</link>
      <description><![CDATA[ 由   提交/u/Elven77AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agzl6i/240200795_llms_learn_governing_principles_of/</guid>
      <pubDate>Fri, 02 Feb 2024 09:12:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] ImageNet 挑战赛发生了什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agzhzh/d_what_happened_with_the_imagenet_challenge/</link>
      <description><![CDATA[当 ImageNet 挑战赛于 2017 年停止时，宣布将有一个不同的挑战赛，重点关注 3D，但我找不到关于发生这种情况的任何信息。 https://www.newscientist.com/article/2127131-new-computer-vision-challenge-wants-to-teach-robots-to-see-in-3d/&lt; /p&gt;   由   提交 /u/ksprdk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agzhzh/d_what_happened_with_the_imagenet_challenge/</guid>
      <pubDate>Fri, 02 Feb 2024 09:05:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 修复此 Reddit 子版块的三个简单建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agrxtm/d_three_simple_proposals_for_fixing_this_subreddit/</link>
      <description><![CDATA[我不知道为什么审核团队在这里如此被动，但这里有一些关于如何修复“Reddit 上的机器学习”的建议。   许多 Reddit 子版块要求您在获准发布之前填写某种形式的简短调查。该调查可以询问用户：“您阅读侧边栏了吗？” “这是适合初学者提问的 Reddit 子版块吗？” “对于初学者问题来说，最好的 Reddit 子版块是什么？” “这四个答案中哪一个是张量的最佳定义？” “这四个答案中哪一个是辍学的最佳定义？” 因为无法挽救而放弃这个 subreddit，但指定一个特定的其他 subreddit，例如 r/LearningMachines 或 r/MLScaling 或 r/ExperiencedML作为指定的“官方地点”供专家前往。将其放在侧边栏中。 鼓励我们的专家监控 r/learnmachinelearning 和其他初学者 Subreddits，所以新手觉得有理由去这些 Reddit 子版块。  我希望看到 Reddit 上的 SOMEWHERE 成为前沿 ML 讨论的中心。    由   提交 /u/Smallpaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agrxtm/d_three_simple_proposals_for_fixing_this_subreddit/</guid>
      <pubDate>Fri, 02 Feb 2024 01:42:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] 22 个消费级 GPU 上的分段任意模型 (SAM) 基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agr8rm/p_segment_anything_model_sam_benchmark_on_22/</link>
      <description><![CDATA[      对分段任意模型 (SAM) 进行基准测试&lt; /h2&gt; 在此基准测试中，我们对来自 COCO 2017 和 AVA 图像数据集。我们评估了代表 22 种不同消费类 GPU 类别的 SaladCloud 上 302 个节点的推理速度和性价比。  为此，我们创建了一个容量为 100 个节点的容器组，其 GPU 类别为“稳定扩散兼容”。所有节点都分配有 2 个 vCPU 和 8GB RAM。这是我们发现的。  在 RTX 3060 Ti 和 RTX 3060 Ti 上，每美元可分割 50K+ 图像。 RTX 3070 Ti https:// Preview.redd.it/c9qt2abwm2gc1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=51b55b9dc00cf8b7dc6919023a5aa9249218e0a0 与较小型号的情况几乎总是一样，最好的成本-性能来自低端 GPU，主要是 RTX 30 系列卡。在这种情况下，我们看到 Ti 卡的性价比显着提升。这是有道理的，因为它们的价格与非 Ti 同类产品相同，但拥有更多 CUDA 核心。这里表现出色的是 RTX 3060 Ti 和 RTX 3070 Ti，每台每美元至少提供 50k 次推理。 特定节点内的推理时间相当一致  https://preview.redd.it/njos0wl2n2gc1.png？ width=1920&amp;format=png&amp;auto=webp&amp;s=b89b4527600350960dbac903274b3407ddfc78d6 放大单个 GPU 类别（RTX 3070 Ti）的性能，我们发现大部分推理时间落在任何特定节点上的范围都很窄，有一些显着的异常值。我们确实看到不同节点之间存在一些差异，其中一个节点特别糟糕。我们经常看到 Salad 上各节点的性能存在少量差异，因为每台节点都是一台单独的住宅游戏 PC，具有各种不同的 CPU、RAM 速度、主板配置等。 我们的一个异常值节点（31b6，上面圈出的）表示该机器存在异常情况。  RTX 3060 Ti 和 RTX 3070 Ti 提供最佳性价比 运行 Segment Anything Model (SAM) 的 RTX 3060 Ti 和 RTX 3070 Ti 提供极高的性价比批量图像分割解决方案，每美元可分割近 50,000 张图像。  带有更多说明的完整基准测试如下：https://blog.salad.com /segment-anything-model-benchmark/ ​ ​   由   提交 /u/SaladChefs   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agr8rm/p_segment_anything_model_sam_benchmark_on_22/</guid>
      <pubDate>Fri, 02 Feb 2024 01:08:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 围绕“AI”的普遍负面情绪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agj5y1/d_general_negative_sentiment_surrounding_ai/</link>
      <description><![CDATA[我注意到，每当我向普通人群（通常是非技术人员 -（家人、朋友等））提起人工智能主题时，第一个我想到的是“机器人接管世界并消灭人类”的存在的消极方面、危险和威胁，而不是积极的一面（如提高效率、自动化、科学等）。需要明确的是，我具体谈论的是人工智能的生存威胁，而不是像大型科技亿万富翁和法团主义这样的经济/政治问题。 这让我想知道 - “人工智能”是否已成为一个伴随着的术语对绝大多数人来说是一个可怕的负面含义吗？这是非常可悲的，我认为这些人中的许多人不知道他们在说什么，他们不明白这些模型是如何工作的，所以他们只是求助于人工智能存在主义者在媒体上推销的任何东西（不是为了淡化危险——我我知道有像 Ilya sutski 和 Geoffrey Hinton 这样的杰出研究科学家担心这些事情）但我觉得现在对人工智能的过度炒作和过度提及确实导致了普遍的技术悲观主义。 TLDR ：“人工智能”越来越多地给普通（非技术）公众带来存在主义的恐惧/负面含义？想法？   由   提交/u/Character-Capital-70   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agj5y1/d_general_negative_sentiment_surrounding_ai/</guid>
      <pubDate>Thu, 01 Feb 2024 19:22:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>