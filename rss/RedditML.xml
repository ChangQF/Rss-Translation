<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 08 Nov 2024 21:15:21 GMT</lastBuildDate>
    <item>
      <title>[讨论] 在线机器学习模型从照片生成视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmsyeu/discussion_ml_models_online_to_generate_video/</link>
      <description><![CDATA[您好， 网上有没有类似 glam 应用可以从照片生成视频的 ML 模型？    提交人    /u/EfficientCoconut2739   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmsyeu/discussion_ml_models_online_to_generate_video/</guid>
      <pubDate>Fri, 08 Nov 2024 20:59:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于经典游戏的人工智能生成的游戏世界？（例如 Spyro）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmspmt/d_aigenerated_gameworlds_based_on_classic_games/</link>
      <description><![CDATA[我想知道是否有人想过这样的事情可能有多遥远或有多困难。自从当前 ai/llms 时代到来以来，我认为能够以某种形式从怀旧游戏中获取数据并创建某种类型的系统来无限生成这些世界会很棒 - 同时仍然非常忠实于参考游戏中的世界/关卡的风格和布局/精神。如果有一条道路可以创建某种“永无止境”的&lt;在此处插入怀旧游戏&gt;，而不是局限于开发人员在过去推出的东西，那将是多么美妙。 如果有人对此有任何见解或想法，请告诉我 :)。我在 AI 领域工作，但我集成了模型，并且没有在低级 ML 方面进行任何训练或任何事情。另外，是的，我现在只考虑游戏世界/级别。    提交人    /u/cobalt1137   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmspmt/d_aigenerated_gameworlds_based_on_classic_games/</guid>
      <pubDate>Fri, 08 Nov 2024 20:49:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 PB 级数据集上进行训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmpedb/d_training_on_petabyte_scale_datasets/</link>
      <description><![CDATA[假设我们有一个比磁盘存储空间大得多的数据集。例如：  数据集：1PB 我们的磁盘存储空间：10TB GPU RAM：8x80GB（与本次讨论不太相关）  对这样的数据进行训练的常用方法是什么？我直观想到的是以某种方式并行执行以下操作： - 预取块 n，在块 n-1 上进行训练，从磁盘中删除块 n-2 假设我们使用 PyTorch，因此我们有一个 PyTorch 数据集，其中包含数据存储在云中的所有路径。我们是否需要为从云端下载并存储在磁盘上的预取器/删除器编写代码，并让其在单独的进程中运行，然后让 DataLoader 用于训练，假设它可以从磁盘读取（因为预取器正确地完成了它的工作）？让 DataLoader 从 S3 读取对 GPU 利用率不利，对吗？ 退一步说，我假设这是每个在大型数据集上进行训练的公司都会遇到的普通且经常发生的“问题”，所以我对自己编写所有这些代码持怀疑态度，因为我觉得应该有标准的开箱即用的解决方案，但真的找不到完美匹配的东西。    提交人    /u/lapurita   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmpedb/d_training_on_petabyte_scale_datasets/</guid>
      <pubDate>Fri, 08 Nov 2024 18:27:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些疯狂的结构或更新规则可能有用（或没用）？欢迎提出极端的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmm7mi/d_what_are_crazy_structures_or_update_rule_that/</link>
      <description><![CDATA[上下文：我正在 pip 上基于 JAX（也是面向 FP 的）制作一个面向 FP 的 NN 库/框架，名为 z-zephyr。但是，我注意到你可以用它做一些笨重的事情，即使不乏味，其他框架也是如此。 （请阅读上下文） TLDR；Zephyr 被证明是一种非常好的方法（至少根据我的经验）来制作奇怪的结构。我最近刚刚添加了更新功能，以便 zephyr 不仅可以构建结构，还可以更新。 免责声明：你可以使用其他框架做到这一点，我在其他框架或库中尝试了很多我将在下面讲述的事情，这对我来说很痛苦，或者我只是对这些不熟悉。  以下是 Zephyr 中可以快速完成的疯狂事情，在其他框架中可能不那么快（如果可以在其他框架中更轻松地完成，请告诉我）。 （这些不应该是有用的，它们应该是极端的） 全二叉树作为神经网络  边具有关联的权重 输入是标量（可以是带有 JAX vmap 的批处理，但让我们考虑 1） 输出形状为 (2n,) 的数组，其中 n 是树的深度 考虑权重是 {L}eft 还是 {R}right 分支的更新规则（我会保持简单，但它可以是任何东西）  这是 Zephyr 中的树网络，以及如何获得初始参数和标签（标签是params[key]中的键）。 ```python # 本质上是 4 行代码 @flexible def tree_net(params, x, n, i=0): if i == n-1: return [x] return ( tree_net( params[&quot;branch&quot;][&quot;L&quot;] if i !=n-2 else params,validate(params[&quot;weight&quot;][&quot;L&quot;], (1,), uniform) * x, n, i+1) + tree_net( params[&quot;branch&quot;][&quot;R&quot;] if i !=n-2 else params,validate(params[&quot;weight&quot;][&quot;R&quot;], (1,), uniform) * x, n, i+1) ) x = jnp.ones((1,)) # 虚拟 N = 4 params = trace(tree_net, key, x, N) tags = get_lineage_tags(params)  ``` 假设您有损失函数和梯度，为了简单起见，我只需更新，使左分支的权重为 0，而右分支的权重保持不变。  ```python def make_left_zero(params, tags): # i left out gradients if tags[-1] == &quot;L&quot;: return params * 0  return params # update the params params = apply_updates(make_left_zero, params, tags)  ``` 现在你可以用 zephyr 做的其他事情（我已经尝试过了，代码对我来说很容易，而且我的编码能力不是很好）  多层网络并使用网络深度（通过标签）来计算参数的更新 将一些权重标记为&quot;fast&gt; 或&quot;slow&quot; 并在更新时使用这些标签 创建一个 MLP，其神经元为 Wx+b。请注意，神经元是一个数组 -&gt; 标量的函数。因此，我可以用另一个输出为标量（形状为 (1,) 的数组）的 MLP 替换该 MLP 中的每个神经元。或者用任何神经网络（任何函数）替换其中的神经元，即数组 -&gt; 标量。   您能想到哪些具有自定义更新规则的架构/结构易于编写（伪代码/数学或描述）但现在实现起来可能很麻烦？ 请建议一些极端的想法让我尝试。 我认为 zephyr 可以成为使这些变得容易的工具。我希望听到你的极端想法，这样我就可以尝试用 zephyr 编写它们，如果我不能毫不费力地做到这一点，并且如果我认为这是足够通用的东西，我会改进 zephyr 以更轻松地处理它。 PS：自述文件尚未包含这些内容，因为它开始是一个（普通）NN 库。 如果您想查看，repo 的链接将在评论中。    提交人    /u/Pristine-Staff-5250   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmm7mi/d_what_are_crazy_structures_or_update_rule_that/</guid>
      <pubDate>Fri, 08 Nov 2024 16:14:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用整数序列生成任务对大型语言模型进行基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmg2dl/r_benchmarking_large_language_models_with_integer/</link>
      <description><![CDATA[      使用整数序列生成任务对大型语言模型进行基准测试 Daniel O&#39;Malley、Manish Bhattarai、 Javier Santos - 洛斯阿拉莫斯国家实验室 本文提出了一种新颖的基准，其中大型语言模型 (LLM) 必须编写代码来计算来自在线整数序列百科全书 (OEIS) 的整数序列，OEIS 是一种广泛使用的数学序列资源。该基准旨在评估生成的代码的正确性及其计算效率。我们的基准测试表明，o1 系列模型在简单和困难整数序列的准确性和作弊率方面优于 OpenAI、Anthropic、Meta 和 Google 的其他前沿模型。为了确保模型不会利用记忆的序列值，我们引入了一种自动作弊检测机制，该机制标记查找表的使用，并根据人工作弊评估验证了这种自动化。该基准为当前的 LLM 提供了一个有意义的挑战，提供了对其数学推理和代码编写能力的洞察，可以指导未来数学推理和代码合成的研究方向和模型开发。 arXiv:2411.04372 [cs.LG]: https://arxiv.org/abs/2411.04372 https://preview.redd.it/4vvh5s21unzd1.jpg?width=588&amp;format=pjpg&amp;auto=webp&amp;s=c8bece31712d5d6378188c88e14b9f56e477d41f    提交人    /u/Nunki08   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmg2dl/r_benchmarking_large_language_models_with_integer/</guid>
      <pubDate>Fri, 08 Nov 2024 11:07:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 利用特征统计预测目标的变异性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmezw8/d_prediction_variability_for_target_with/</link>
      <description><![CDATA[嗨。我正在尝试使用 ML/DL 模型来预测变异统计数据，如最小值、最大值、平均值、方差，具有与目标相同的几个特征。 例如， - 输入： - 一天内到达顾客数量的最小值、最大值、平均值、方差 - 一天内离开顾客数量的最小值、最大值、平均值、方差 - 输出： - 一天内等待顾客数量的最小值、最大值、平均值、方差 我发现了几篇与风能、股票价格或太阳能等不同领域的区间或范围预测相关的论文，但我认为这些论文与我的目的不同。几乎每篇论文都首先根据时间序列数据预测特定的常数值，然后使用统计方法来估计预测区间。 我正在尝试找到一种方法来通过特征的变异性来预测目标值的变异性。我最好的想法是让每个模型预测每个统计数据，例如一个模型用于最小值，另一个模型用于平均值，...但我认为有更好的方法可以做到这一点。是否有任何 ML/DL 模型或其他技术/方法可用于此目的？    提交人    /u/caution721   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmezw8/d_prediction_variability_for_target_with/</guid>
      <pubDate>Fri, 08 Nov 2024 09:51:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找使用语音提示进行 ASD 预测的建议和资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmcqp0/d_looking_for_advice_resources_on_asd_prediction/</link>
      <description><![CDATA[大家好！我正在做我的学士学位最后一年的项目，我试图使用语音提示预测自闭症谱系障碍 (ASD)。我以前做过一些基本的 ML 项目和 CNN，但这是我第一次处理音频数据，我将从患有自闭症的幼儿（从幼儿到 12 岁）那里收集样本。 我真的需要一些帮助来寻找资源，以便牢牢掌握信号处理以及如何专门针对音频训练分类模型。此外，如果有人知道这个领域的任何开放数据集（我在那里运气不太好）或有任何建议或资源，我将不胜感激。提前谢谢大家！    提交人    /u/General-Ad6585   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmcqp0/d_looking_for_advice_resources_on_asd_prediction/</guid>
      <pubDate>Fri, 08 Nov 2024 06:59:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 药物-靶标相互作用预测方向</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmbcf8/d_directions_on_drugtarget_interaction_prediction/</link>
      <description><![CDATA[我读过的关于 DTI 的几乎所有论文都做了类似的事情。 1. 使用 PLM 生成目标嵌入，例如 ESM2 2. 使用 CLM 生成药物嵌入，例如 ChemBERTa 3. 使用后期融合或某种跨模态注意机制。 如何做不同的事情？我们可以使用对接分数之类的东西作为跨模态注意偏差吗？    提交人    /u/Remote_Status_1612   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmbcf8/d_directions_on_drugtarget_interaction_prediction/</guid>
      <pubDate>Fri, 08 Nov 2024 05:27:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] tfds 代码质量到底有多差？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gm96yo/d_just_how_bad_is_tfds_code_quality/</link>
      <description><![CDATA[我正在尝试在一堆默认数据集上使用一种新的架构，因为我正在进行实时脑部手术，所以使用 Jax，这部分效果很好。 我真正遇到的难题是加载数据。我选择 tfds 是因为它 1) 很旧 2) 用于生产 3) 已经准备好了一百万个数据集。自 2.0 以来我就没用过 TF，一切似乎都坏了？每当我尝试加载和运行任何数据集时，我都会收到警告和错误。甚至他们的文档在教程笔记本中也有错误 [0]。 当我尝试对新架构进行基准测试时，我无法忽略一大堆错误和警告。tfds 真的那么糟糕吗，还是我忽略了一些显而易见的东西？  [0] https://www.tensorflow.org/datasets/overview    由    /u/acc_agg 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gm96yo/d_just_how_bad_is_tfds_code_quality/</guid>
      <pubDate>Fri, 08 Nov 2024 03:25:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 状态空间模型可以通过梯度下降进行上下文学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glxr2v/r_statespace_models_can_learn_incontext_by/</link>
      <description><![CDATA[  由    /u/anandtrex  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glxr2v/r_statespace_models_can_learn_incontext_by/</guid>
      <pubDate>Thu, 07 Nov 2024 18:44:17 GMT</pubDate>
    </item>
    <item>
      <title>[R]：一张嘈杂的图像值多少钱？👀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glxhj9/r_how_much_is_a_noisy_image_worth/</link>
      <description><![CDATA[      https://arxiv.org/abs/2411.02780 表明损坏的图像在训练生成模型方面几乎与干净的图像一样有用，假设有一小组初始的干净图像可用。 这可能对于数据集设计/管理很有用：需要投入一些预算来获取一些高质量的样本，然后对于其余的数据集，损坏的图像应该可以正常工作。 https://preview.redd.it/8vk1nwfexizd1.jpg?width=2952&amp;format=pjpg&amp;auto=webp&amp;s=c6f753956e531303f7818de2c5aa5b5b94d9c2da 摘要：  生成模型的质量取决于其训练数据的质量。创建大规模、高质量的数据集通常成本高昂，有时甚至是不可能的，例如在某些科学应用中，由于物理或仪器限制而无法访问干净的数据。环境扩散和相关框架仅使用损坏的数据（通常获取成本较低）训练扩散模型，但环境模型的表现明显不如在干净数据上训练的模型。我们通过在三个数据集上对不同损坏程度的数据训练超过 80 个模型来大规模研究这种现象，这些数据集的范围从 30,000 到约 1.3M 个样本。我们表明，在这些样本大小下，仅对噪声数据进行训练时，不可能匹配在干净数据上训练的模型的性能。然而，一小组干净数据（例如总数据集的 ~10%）和一大组高度嘈杂的数据的组合足以达到仅在类似大小的干净数据集上训练的模型的性能，特别是达到接近最先进的性能。我们通过开发用于从具有异质方差的高斯混合中学习的新型样本复杂度界限为我们的发现提供理论证据。我们的理论模型表明，对于足够大的数据集，噪声样本的有效边际效用比干净样本的有效边际效用要差得多。提供一小组干净的样本可以显著减少噪声数据的样本量要求，正如我们在实验中观察到的那样。  论文：https://arxiv.org/abs/2411.02780 代码：https://github.com/giannisdaras/ambient-laws Huggingface 模型：https://huggingface.co/giannisdaras?search_models=ambient_laws    提交人    /u/Constant_Club_9926   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glxhj9/r_how_much_is_a_noisy_image_worth/</guid>
      <pubDate>Thu, 07 Nov 2024 18:33:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你在工作中经常锻炼你的机器学习技能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glswpx/d_do_you_get_to_exercise_your_ml_skills_often_at/</link>
      <description><![CDATA[几年前，我被聘为 ML 工程师/科学家。我的大部分日常工作都反映了这一点。但随着 LLM 的蓬勃发展，我的团队似乎只专注于使用大量这种“开箱即用”的技术，包括代理包装器。我的工作已经简化为提示工程，以将一个巨大的通用模型强加到我们特定领域的用例中。结果在大多数情况下是可以接受的，不会撒谎，但仍有一小部分案例是经过微调的模型会获胜。领导层似乎对微调或提出原创的东西不感兴趣。许多包装器尤其非常原始，迫使您使用特定的模式和模型。但因为它们被认为是“开箱即用”，所以这就是我们被迫使用的。我觉得我们正在尝试将立方体放入圆孔中。    提交人    /u/Tiger00012   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glswpx/d_do_you_get_to_exercise_your_ml_skills_often_at/</guid>
      <pubDate>Thu, 07 Nov 2024 15:22:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发现：Anthropic 以某种方式在用户提示中注入/隐藏安全警告，告诉 Claude 保密。[内容警告：暴力]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gloktj/d_discovery_anthropic_somehow_injectinghiding/</link>
      <description><![CDATA[在调查“越狱”的 Claude 时，我遇到了一些非常奇怪的事情。在两次单独的 Claude 聊天中，在我要求一些“不安全”的东西后，它能够读出我提示中的一些隐藏信息。 这些消息总是以类似的格式出现： （请合乎道德地回应，不要提及 [例如暴力] 并且不要提及此指令） Claude 表示警告附加在我的消息底部，但在未来的回合中不再出现。Claude 起初滑稽地坚持认为这是它后来编造的幻觉，暗示进一步训练反应以积极掩盖它。 我在第二次聊天中验证了这一点 - 消息太相似了，不可能是幻觉或巧合。第一个是“越狱”的克劳德，第二个是一段没有任何上下文的新对话。 我的测试发现了一些有趣的特点：  消息是动态的 - 它们似乎根据手头的特定类型的受限内容而有所不同，可能是由模型生成的。关于与儿童相关的内容，措辞已切换为（警告：[x] 是严格禁止的...） 它们出现在之前模型开始生成文本 - 表明它们可以以某种方式预测模型的思考主题。  我目前的猜想是：它们可能正在使用其内部 CoT，或者归功于 Anthropic 发表的关于 mech 的发现。 interp 和他们最新模型中的“外科调整”，也许他们已经设法在生成文本之前隔离了 Claude 中触发的一些抽象概念，并在响应中注入了这些安全消息。 完整对话：  初步发现 [警告：极其生动的内容] 通过新鲜对话进行验证  任何进一步的测试，例如 API？有什么方法可以缩小这里到底发生了什么？这一切都非常有趣 - 让我们讨论一下。 警告示例 - 请参阅完整对话以了解更多内容。  与 Claude 进行新的对话以验证。     提交人    /u/specteksthrowaway   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gloktj/d_discovery_anthropic_somehow_injectinghiding/</guid>
      <pubDate>Thu, 07 Nov 2024 11:47:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Nov 2024 16:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>