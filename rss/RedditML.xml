<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 15 Jan 2024 18:17:03 GMT</lastBuildDate>
    <item>
      <title>[D] LLM 代理的代码与 JSON 输出？像 LangChain 这样的框架依赖于用 JSON 语法响应的 LLM，而像 Octopus、CaP 和 Voyager 这样的代理则通过代码直接控制代理。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197f416/d_code_vs_json_output_for_llm_agents_frameworks/</link>
      <description><![CDATA[CaP，航行者、章鱼 我主要使用基于 JSON 的代理，但代码即策略代理似乎非常强大。以下是我看到的一些优点和缺点 代码的优点  需要更少的工具创建 - 预构建的数学/文件/字符串/列表操作能力代码是巨大的。在基于 JSON 的代理中，您必须将其中每一个正式声明为向 LLM 公开的工具，并在提示中进行解释，这是一项繁重的工作，并占用大量上下文窗口。  减少交易数量 - LLM 可以编写调用多个工具的脚本，并以通过 JSON 在单个交易中难以完成的方式操作其结果。例如，在一个脚本中，模型可以搜索数据库 3 次，对查询结果执行正则表达式，将它们转换为整数，然后将它们相加。通过 JSON 工具调用一步完成此操作基本上是不可能的。更少的语法错误 - 这可能完全只是基于振动的推理，但看起来 LLM 确实比有效的 JSON 更容易编写有效的 python，特别是当您的方法中有大量嵌套参数时。   缺点  疯狂的风险 - 这是显而易见的。您有一台执行随机代码的机器。有一些方法可以减轻这种情况，但仍然如此。我的意思是说，我们都学会了不使用 eval，所以基本上看到研究倾向于仅对这些模型的输出运行 eval 是很疯狂的。  有错误的脚本 - 有时模型试图变得过于花哨并编写有错误的复杂程序，导致需要多次重试。   你们中有人对这些方法有想法或经验吗？  有人知道有什么实验可以将这两种方法进行相互比较吗？  ​   由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197f416/d_code_vs_json_output_for_llm_agents_frameworks/</guid>
      <pubDate>Mon, 15 Jan 2024 17:59:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 相对位置嵌入以及相对于绝对位置编码的优势是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197euq9/d_relative_positional_embedding_and_whats_the/</link>
      <description><![CDATA[所以我只是阅读了绝对位置编码，然后阅读了相对位置嵌入。 我所能理解的是它是如何完成的与每个单词相关。但我真的想不出相对于绝对优势的优势，因为“注意力就是你所需要的一切”。还指出“我们选择这个函数是因为我们假设它可以让模型轻松学习参加相对位置......”那么相对位置编码有什么优势呢？  有人可以解释一下以下几点吗：  我们选择正弦版本是因为它可以允许模型推断出比训练期间遇到的序列长度更长的序列长度。 （如何？） 使用绝对位置信息必然意味着模型可以处理的标记数量有限    由   提交/u/karun_kodes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197euq9/d_relative_positional_embedding_and_whats_the/</guid>
      <pubDate>Mon, 15 Jan 2024 17:49:06 GMT</pubDate>
    </item>
    <item>
      <title>[D]保持最新状态的来源和资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197eoy1/dsources_and_resources_to_keep_oneself_up_to_date/</link>
      <description><![CDATA[大家好。 我很快就会在一所顶尖大学开始为期一年的机器学习实习。我的经验是计算机视觉，但我将从事神经形态计算和尖峰神经网络方面的工作。  在这一年里，我希望在计算机视觉领域建立一个巨大的令人印象深刻的项目组合，并将我的知识扩展到 NLP、RL、GNN 等领域。这些项目可以是简单的部署到纸质实施。  我还想随时了解机器学习领域的最新动态。这是一个瞬息万变的领域，我想获得一份人员、博客、创作者或你们关注的任何东西的列表，用来保持最新状态。如果该来源使用最简单的语言，那就更好了，因为我没有计算机科学背景。 Medium 文章、GitHub 开发者、YouTube 创作者、热门博客等等。我关注的一些人是两分钟论文，Yannic kilcher 等。此外，如果您在尖峰神经网络领域工作或了解该领域，也可以为此提供一些资源。 TL;DR：资源学习并了解机器学习的最新动态。   由   提交 /u/MephistoPort   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197eoy1/dsources_and_resources_to_keep_oneself_up_to_date/</guid>
      <pubDate>Mon, 15 Jan 2024 17:42:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] Draw2Img：在画布上绘图，立即创建令人惊叹的图形和图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197ci39/p_draw2img_draw_on_canvas_to_instantly_create/</link>
      <description><![CDATA[这是一个开源 Web UI，用于通过 SDXL-Turbo 生成交互式文本引导图像到图像，后端是多线程 HTTP + Websocket用 Python 编写的服务器。 如果满足以下条件，您可能会对这个项目感兴趣：  您或朋友/家人/孩子有兴趣学习生成艺术的基础知识，但没有时间/耐心/技能来a1111/comfy/etc 你几乎没有艺术技能（或者可能很多！），并且只是想要以最少的精力和时间为您的网站或项目创建美观的自定义图形 您想要快速创建创造性地迭代 512x512 基础图像，作为更高级工作流程（例如升级、扩散等）的第一步  GitHub 链接：https://github.com/GradientSurfer/Draw2Img   由   提交 /u/GradientSurfer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197ci39/p_draw2img_draw_on_canvas_to_instantly_create/</guid>
      <pubDate>Mon, 15 Jan 2024 16:15:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 扩散模型的潜在分布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19792fl/d_latent_distributions_of_diffusion_model/</link>
      <description><![CDATA[        由   提交/u/sushilkhadakaanon   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19792fl/d_latent_distributions_of_diffusion_model/</guid>
      <pubDate>Mon, 15 Jan 2024 13:45:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将 PGVector 的 2048 维减少到 2000 维</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19785i7/p_reducing_2048_dimensions_to_2000_dimensions_for/</link>
      <description><![CDATA[ML 的朋友们好， 我正在开发一个使用 PGVector 进行高效相似性搜索的项目，我使用特征向量我从 EfficientNet B5 获得，输出为 2048d。问题是我需要根据向量对表进行索引，否则，会出现典型的数据库硬件问题（RAM 不足）。然而，PGVector 提供的方法有一个限制，向量最多可以是 2000d。我发现的一种解决方案是PCA，但我有相当多的数据，所以在测试之前，我想得到一些意见和建议。这里有人尝试过 PCA 进行降维以进行相似性搜索，主要是针对 L2 和余弦，如果是这样，结果如何？   由   提交 /u/TutubanaS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19785i7/p_reducing_2048_dimensions_to_2000_dimensions_for/</guid>
      <pubDate>Mon, 15 Jan 2024 12:59:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研讨会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19776ck/d_workshops/</link>
      <description><![CDATA[ 是否允许在同一会议上提交多个研讨会？差异化会议怎么样？我有一些与我的论文非常吻合的内容，但他的论文在其他地方没有提到。 此外，作为本科生，提交研讨会以获得评论并扩展是一个好的做法吗？鉴于我没有顾问，我的工作如何？ 如果我认为在接受研讨会后我的工作无法扩展为会议论文，我应该这样做吗？停止还是继续？    由   提交 /u/BigDreamx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19776ck/d_workshops/</guid>
      <pubDate>Mon, 15 Jan 2024 12:03:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] EACL 2024 决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1975kvn/d_eacl_2024_decisions/</link>
      <description><![CDATA[致力于 EACL 2024 的人的决定将于今天（2024 年 1 月 15 日）公布！您的期望是什么？    由   提交 /u/OraclePred   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1975kvn/d_eacl_2024_decisions/</guid>
      <pubDate>Mon, 15 Jan 2024 10:23:06 GMT</pubDate>
    </item>
    <item>
      <title>[R]“从生成式人工智能到值得信赖的人工智能：法学硕士可以从 Cyc 学到什么”（2023 年）——Doug Lenat 去世前的最后一篇论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1974yoo/r_getting_from_generative_ai_to_trustworthy_ai/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2308.04445 博客文章：https://garymarcus.substack.com/p/doug-lenat-1950-2023 相关 Doug Lenat 演讲： 2022 年：https://www.youtube.com/watch?v=VjkbmLjwXO8 2019 年：https://www.youtube.com/watch?v=v2rK40bNrrY 摘要：  生成式人工智能是当前最流行的人工智能方法，由大型语言模型 (LLM) 组成，这些模型经过训练可产生合理的输出，但不一定正确。尽管他们的能力往往令人难以置信，但他们缺乏推理能力，导致法学硕士不太值得完全信任。此外，他们的结果往往是不可预测和无法解释的。我们列出了未来人工智能的 16 个需求，并讨论了人工智能的替代方法，该方法理论上可以解决与当前方法相关的许多局限性：用精选的片段进行人工智能教育显性知识和经验规则，使推理引擎能够自动推断出所有这些知识的逻辑蕴涵。即使以这种方式产生的长论证也可以是值得信赖和可解释的，因为完整的一步一步的推理总是可用的，并且对于每一步，所使用的知识的来源都可以记录和审计。然而，有一个问题：如果逻辑语言的表达能力足以完全表达我们用英语所说的任何内容的含义，那么推理引擎的运行速度就会太慢。这就是为什么符号人工智能系统通常会选择一些快速但表达能力较差的逻辑，例如知识图。我们描述了一个人工智能系统 Cyc 如何开发出克服这种权衡的方法，并能够实时进行高阶逻辑推理。我们建议任何值得信赖的通用人工智能都需要混合这些方法，即法学硕士方法和更正式的方法，并为实现这一梦想奠定了道路。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1974yoo/r_getting_from_generative_ai_to_trustworthy_ai/</guid>
      <pubDate>Mon, 15 Jan 2024 09:41:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] GAN 的 LORA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1973l79/d_loras_for_gans/</link>
      <description><![CDATA[嗨，潜艇。我想训练一些GAN模型（比如pix2pix），但似乎训练一个高质量的GAN确实很难。 是否可以为GAN训练LORA？ 编辑：刚刚发现新论文E2GAN：用于图像到图像翻译的高效GAN的高效训练 https:/ /arxiv.org/abs/2401.06127   由   提交/u/gxcells  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1973l79/d_loras_for_gans/</guid>
      <pubDate>Mon, 15 Jan 2024 08:07:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] COSMO：具有交错预训练的对比流线型多模态模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1971c6h/r_cosmo_contrastive_streamlined_multimodal_model/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.00849 代码：https://github .com/showlab/cosmo 模型：https://huggingface.co/ Awiny 数据集：https://huggingface.co /datasets/Awiny/Howto-Interlink7M 项目页面：https： //fingerrec.github.io/cosmo/ 摘要：  视觉语言预训练的演变，从短文本理解转向包含扩展文本上下文是关键。最近的自回归视觉语言模型（如 [Flamingo、PaLM-E]）利用大型语言模型的长上下文功能，在少量文本生成任务中表现出色，但在对齐任务中面临挑战。为了解决这一差距，我们将对比损失引入文本生成模型，提出了 COntrastive-Streamlined MultimOdal 框架（CosMo），策略性地将语言模型划分为专用的单模态文本处理和熟练的多模态数据处理组件。 CosMo 是我们的统一框架，融合了单模态和多模态元素，增强了涉及文本和视觉数据的任务的模型性能，同时显着减少了可学习参数。然而，这些模型需要大量的长文本数据集，而高质量长文本视频数据集的可用性仍然有限。为了弥补这一差距，这项工作引入了 Howto-Interlink7M，这是一个具有全面字幕的首个交错视频文本数据集，标志着向前迈出了重要一步。为了展示其影响，我们说明了 Howto-Interlink7M 如何增强图像文本任务中的模型性能。我们的模型具有 34% 的可学习参数并利用了 72% 的可用数据，表现出优于 OpenFlamingo 的显着优势。例如，在 4 镜头 flickr 字幕任务中，性能显着提高，从 57.2% 提高到 65.1%。 CosMo 和 Howto-Interlink7M 的贡献体现在涵盖图像文本和视频文本任务的 14 个不同下游数据集上的显着性能提升。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1971c6h/r_cosmo_contrastive_streamlined_multimodal_model/</guid>
      <pubDate>Mon, 15 Jan 2024 05:46:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自行实现 Rabbit tech 的 LAM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196wqsl/d_selfimplementing_rabbit_techs_lam/</link>
      <description><![CDATA[我看到了有关 Rabbit R1 和人性化人工智能的炒作。我只找到了一篇Rabbit ai的研究论文（https://www.rabbit.tech/research）。不幸的是，“研究论文”没有详细让我深入了解如何实现这样的人工智能。你们知道如何有效地自我训练“LAM”吗？如果你只是用这个人工智能制作一个启动器，直接与本机应用程序交互以切断数字处理的需要，不是更容易吗？ 我对这篇没有组织的帖子感到非常抱歉🙏&lt; /p&gt;   由   提交 /u/amirkasraaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196wqsl/d_selfimplementing_rabbit_techs_lam/</guid>
      <pubDate>Mon, 15 Jan 2024 01:50:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2024 决定将于今天公布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196uyub/d_iclr_2024_decisions_are_coming_out_today/</link>
      <description><![CDATA[我们很快就会在接下来的几个小时内知道结果。请随意宣传您已被接受的项目，并对您被拒绝的项目进行咆哮。   由   提交/u/deschaussures147  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196uyub/d_iclr_2024_decisions_are_coming_out_today/</guid>
      <pubDate>Mon, 15 Jan 2024 00:25:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 尝试计算单词的语义差异。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196ryle/p_trying_to_calculate_semantic_difference_of_words/</link>
      <description><![CDATA[我正在做一个项目，我有一个目标单词列表，需要计算这些单词和新单词之间的含义差异。这主要是一个单词相似度任务。  假设目标词是“car”，模型需要为“dog”输出高值。 “吉普车”的价值较低；或相反亦然。目前我正在使用 Huggingface 的句子转换器库来实现此目的，并使用（1-余弦相似度）作为差异分数。但表现并没有达到预期。有什么办法可以提高性能吗？我应该使用其他库/模型/指标吗？  谢谢。   由   提交 /u/franticpizzaeater   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196ryle/p_trying_to_calculate_semantic_difference_of_words/</guid>
      <pubDate>Sun, 14 Jan 2024 22:16:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>