<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 30 Jan 2024 00:56:55 GMT</lastBuildDate>
    <item>
      <title>[D] 使用多个库对 Mixtral-8x7B 进行实验 - 每秒最多获得 52 个令牌。想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeb70z/d_experiments_with_mixtral8x7b_using_multiple/</link>
      <description><![CDATA[      大家好， 最近尝试部署 Mixtral-8x7B模型并希望与感兴趣的人分享主要发现： 最佳性能：使用 Pytorch（每晚）的量化 8 位模型的平均代币生成率为 52.03 代币/秒在 A100 上，平均推理时间为 4.94 秒，冷启动时间为 11.48 秒（在无服务器环境中部署时很重要） 混合实验 测试的其他库： vLLM、AutoGPTQ、HQQ 渴望听到您在类似部署中的经验和学习！   由   提交/u/Tiny_Cut_8440   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeb70z/d_experiments_with_mixtral8x7b_using_multiple/</guid>
      <pubDate>Tue, 30 Jan 2024 00:40:34 GMT</pubDate>
    </item>
    <item>
      <title>自动 1111 的开源 SDK/Python 库 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeab92/opensource_sdkpython_library_for_automatic_1111_p/</link>
      <description><![CDATA[   ​ https://preview.redd.it/74bz5ko0xgfc1.png?width=1656&amp;format=png&amp;auto=webp&amp;s=2a0ea066 0f56c97e242c7e099073086f52e38263&lt; /a&gt; https://github.com/saketh12/Auto1111SDK 大家好，我为自动 1111 Web UI 构建了一个轻量级开源 Python 库，它允许您在基础设施上本地运行任何稳定扩散模型。您可以轻松运行：  文本到图像 图像到图像 修复 修复 li&gt; Stable Diffusion Upscale Esrgan Upscale Real Esrgan Upscale 直接从 Civit AI 下载模型  使用任何安全张量或检查点文件都只需几行代码！它超轻且高性能。与 Huggingface Diffusers 相比，我们的 SDK 使用的内存/RAM 少得多，并且我们在我们测试的所有设备/操作系统上观察到速度提高了 2 倍！ 请为我们的 Github 存储库加注星标！！！ https://github.com/saketh12/Auto1111SDK.   由   提交 /u/Dazzling_Koala6834   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeab92/opensource_sdkpython_library_for_automatic_1111_p/</guid>
      <pubDate>Mon, 29 Jan 2024 23:59:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] SVM关于索引的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aea63r/d_svm_question_about_indexes/</link>
      <description><![CDATA[大家好！ 我现在正在学习 SVM 的工作原理，但我无法理解其中的一件事。我看了 Andrew Ng 的讲义，也看了 MIT 的讲义，但是没看懂。 所以，在 SVM 中我们需要最小化 1/2 * (norm(W)) 我们可以假设 W 是我们的特征的线性组合。所以W = sum [Y_i * alpha_i * X_i]然后norm(W) = W_T * W现在我无法得到。 /&gt; 我们这样做norm(W) = Transpose(sum [Y_i * alpha_i * X_i]) * sum [Y_j * alpha_j * X_j]  我们更改索引，添加新索引 j 。但为什么我们要这样做？ 假设我们有向量 a = (1,2) 那么 a_T * a = 1*1 + 2*2 我们将数字与相同的索引 为什么我们使用新索引 J ？还是我弄错了什么？   由   提交 /u/Top-Permission-1526   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aea63r/d_svm_question_about_indexes/</guid>
      <pubDate>Mon, 29 Jan 2024 23:53:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] FP32 与 FP16 相比速度提升</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae6v79/d_speed_up_in_fp32_vs_fp16/</link>
      <description><![CDATA[ 任务：在单节点 2 GPU 上进行训练和微调 型号：CLIP ViT-B-32 型号：CLIP ViT-B-32 li&gt; 数据集：MSCOCO 标题 工作人员数量：4 批量大小：FP16 为 160，FP32 为 96  对于 FP32 和 FP16，每个 epoch 大约需要 12-13 分钟。 我认为的原因之一是，大部分时间可能由数据移动而不是 GPU 组成与 FP32 的情况一样，GPU 利用率几乎没有时刻低于 97%，而在 FP16 期间，GPU 似乎有时会处于空闲状态（几分之一秒）。这是一个原因吗？ 在类似和不同的训练场景中，其他可能的原因是什么？   由   提交 /u/MaintenanceNo5993   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae6v79/d_speed_up_in_fp32_vs_fp16/</guid>
      <pubDate>Mon, 29 Jan 2024 21:33:03 GMT</pubDate>
    </item>
    <item>
      <title>分解：神经网络结构组合性的证据 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae61tq/break_it_down_evidence_for_structural/</link>
      <description><![CDATA[ 由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae61tq/break_it_down_evidence_for_structural/</guid>
      <pubDate>Mon, 29 Jan 2024 20:59:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 之外的法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae5dgq/d_llms_beyond_rag/</link>
      <description><![CDATA[实际上几乎每个人都在谈论 RAG。我想知道接下来会出现什么趋势。很想听听您的想法。   由   提交/u/HolidayCritical3665   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae5dgq/d_llms_beyond_rag/</guid>
      <pubDate>Mon, 29 Jan 2024 20:31:28 GMT</pubDate>
    </item>
    <item>
      <title>佩德罗·多明戈斯：神经象征尚未发挥作用 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae4vp1/pedro_domingos_neurosymbolic_does_not_work_yet_r/</link>
      <description><![CDATA[      ​ https://preview.redd.it/r0h4yab5qffc1.png?width=817&amp;format=png&amp;auto=webp&amp;s=033744120df49 252c5379bdafa429570e80cfac4&lt; /a&gt; ​ 象征性人工智能通常被视为失败。我记得 Cyc 花费了 2 亿美元（比 GPT-4 的培训预算还多？）。 另一方面，Transformer LLM [1] 明显的固有局限性使一些人将目光投向象征性的、神经-再次采用象征性和混合性方法。 DeepMind 首席执行官表示，公司在这个领域有六个项目。 如果你对这些主题（神经网络、符号和神经符号人工智能的理论局限性）感兴趣，我为它们制作了一个 Reddit 子版块： r/symbolic （我可能会后悔这样做，但小众主题需要自己的 subreddits，因为大多数主题都没有关心或了解很多，因此提交的内容会被否决，并且评论通常缺乏洞察力，例如“什么是 ILP？”） ​ &lt; p&gt;[1]例如 https://arxiv.org/abs/2205.11502   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae4vp1/pedro_domingos_neurosymbolic_does_not_work_yet_r/</guid>
      <pubDate>Mon, 29 Jan 2024 20:11:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多输出高斯过程，每个输入一个输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae2o5b/r_multioutput_gaussian_process_with_one_output/</link>
      <description><![CDATA[我正在寻找一种适合多输出高斯过程的方法，其中在任何给定输入处仅观察到单个输出。我遇到的所有多输出高斯过程模型都假设在每个输入处观察到每个输出（即完全观察到的输出）。 这篇博客文章说，当在任何给定输入处观察到单个输出时，观察次数将为n，并且多输出 GP 将具有与单输出 GP 相同的时间和内存缩放比例。这是一个不错的酒店。但是，这篇文章没有提及如何拟合这样的模型。 我的特定应用程序有 2 个输出，其中一个输出比另一个输出具有更多的观察结果。任何帮助将不胜感激！   由   提交 /u/RemyMacDonald   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae2o5b/r_multioutput_gaussian_process_with_one_output/</guid>
      <pubDate>Mon, 29 Jan 2024 18:41:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 智能音乐生成系统回顾（2023 年 11 月 17 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae1p6p/r_a_review_of_intelligent_music_generation/</link>
      <description><![CDATA[ 由   提交/u/moschles  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae1p6p/r_a_review_of_intelligent_music_generation/</guid>
      <pubDate>Mon, 29 Jan 2024 18:03:06 GMT</pubDate>
    </item>
    <item>
      <title>机器学习作为数学专业[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae1kcu/machine_learning_as_a_mathematics_major_d/</link>
      <description><![CDATA[您好，我想了解从事机器学习职业需要哪些东西。我的目标是对机器和设备有一个全面的了解。深度学习。我已经完成了数学本科学位，所以我对概率和数学有很好的了解。统计学、表面张量微积分、线性代数、R、Matlab 等。在编码方面，我有点初学者。我已经完成了 C++ 入门课程作为学校选修课，并且正在研究 PCEP 和 PCEP。 PCAP 考试（Python）作为学习创建法学硕士的基础工具的一种手段。我还在考虑学习 Azure、Tensorflow 和 Pytorch，并获得相应的认证。我知道，在尝试获得入门级工作时，在 Github 上创建项目组合也很重要。我在网上看到了一些人工智能训练营，想知道这些训练营是否提供任何价值（特别是哥伦比亚大学在 EDX 上的训练营，价格为 14,000 美元）。 我的做法是错的吗？如果是这样，还有其他我遗漏或需要考虑的事情吗？是否有课程可以帮助将所有内容联系在一起？我应该遵循什么进展路径？   由   提交/u/yathamrrahul  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae1kcu/machine_learning_as_a_mathematics_major_d/</guid>
      <pubDate>Mon, 29 Jan 2024 17:57:58 GMT</pubDate>
    </item>
    <item>
      <title>[d] Code Llama，一种最先进的大型编码语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae0lsj/d_code_llama_a_stateoftheart_large_language_model/</link>
      <description><![CDATA[ https://ai.meta.com/blog/code-llama-large-language-model-coding/   由   提交/u/Electrical_Study_617   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae0lsj/d_code_llama_a_stateoftheart_large_language_model/</guid>
      <pubDate>Mon, 29 Jan 2024 17:19:04 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯神经网络与学习方差和均值 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1advijz/bayesian_nns_vs_learning_variance_and_mean/</link>
      <description><![CDATA[嗨， 根据我的理解，贝叶斯神经网络将权重视为 pdf，从而允许神经网络本身产生随机变量基于训练后权重采样的结果。虽然这看起来很有趣，但它也很昂贵。对于那些希望能够产生随机预测的人来说，另一个更简单的选择就是让神经网络学习一些平均值和标准差。虽然神经网络本身现在是确定性的而不是随机的，但它仍然允许我们在假设某种分布的情况下从平均值和标准差中进行采样。 这有意义吗？因此，如果正在寻找神经网络的随机结果，但不希望考虑贝叶斯神经网络的额外成本，那么选项二似乎很有吸引力。 如果您同意我所写的内容，请告诉我或不。我很高兴听到您的意见:)   由   提交/u/andre2500_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1advijz/bayesian_nns_vs_learning_variance_and_mean/</guid>
      <pubDate>Mon, 29 Jan 2024 13:38:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何为 RAG 划分块</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adtuzr/d_how_to_divide_a_chunk_for_rag/</link>
      <description><![CDATA[大家好， 我需要一些建议，假设您正在构建一个 RAG。您希望上下文块的长度为 512 个令牌。如何在不失去语义联系的情况下划分 1000 多个段落。 有关更多信息，它是一个问答机器人，那个巨大的段落是对一个常见问题的回答。   由   提交 /u/Lathanderrr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adtuzr/d_how_to_divide_a_chunk_for_rag/</guid>
      <pubDate>Mon, 29 Jan 2024 12:10:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不懂基础的LLM专家？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</link>
      <description><![CDATA[我最近遇到了很多人，他们知道 LLM 领域中不同技术的所有奇特缩写词，诚然我也是新手但越来越明显的是，他们甚至不知道 DL 的基础知识，比如背景是什么或其他经典概念。 这是否会成为现状，因为 LLM 领域更倾向于配置而不是做事从零开始？ 还有，这些人真的可以被认为是法学硕士还是表面上的专家？    由   提交/u/Plus_Tough_7497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</guid>
      <pubDate>Mon, 29 Jan 2024 04:13:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>