<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sat, 02 Mar 2024 18:16:24 GMT</lastBuildDate>
    <item>
      <title>Pytorch训练帮助[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4u9qk/pytorch_training_helpd/</link>
      <description><![CDATA[我正在使用 Pytorch 训练深度神经网络。在每一步我都想查看参数值。我该怎么做呢。即使在我应用 opt.step 之后，它也会显示与初始化的值相同的值   由   提交/u/NickRay1234  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4u9qk/pytorch_training_helpd/</guid>
      <pubDate>Sat, 02 Mar 2024 17:56:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] ArXiv 机器学习景观</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4txb8/p_arxiv_machine_learning_landscape/</link>
      <description><![CDATA[ 由   提交/u/lmcinnes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4txb8/p_arxiv_machine_learning_landscape/</guid>
      <pubDate>Sat, 02 Mar 2024 17:42:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] Panda-70M：与多个跨模态教师一起为 7000 万个视频添加字幕</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4stoa/r_panda70m_captioning_70m_videos_with_multiple/</link>
      <description><![CDATA[训练 AI 理解和描述视频内容需要数据集，而这些数据集对于人类手动注释来说成本高昂。现在，来自 Snap、加州大学默塞德分校和特伦托大学的研究人员整理了一个名为 Panda-70M 的新数据集，旨在提供帮助。 这个新数据集包含 7000 万个高分辨率 YouTube 剪辑，并配有描述性字幕。关键是他们使用了具有多个跨模式“老师”的自动化管道。人工智能模型根据视频、字幕、图像等不同输入生成字幕。 一些亮点：  70M 720p YouTube 剪辑时长 8 秒，包含 13 个单词的字幕 教师模型包括视频 QA、图像字幕、文本摘要 教师团队可以准确地描述 84剪辑的百分比与任何单个模型的 31% 相比 在此数据集上进行预训练可显着提高视频 AI 模型的性能： 微调 250 万个小数据后，字幕准确性提高了 18%子集 在文本视频检索方面提高 7% 视频生成错误减少 77%   局限性仍然围绕内容多样性、字幕密度和自动化质量。但我认为这是组装大规模视频文本训练数据以推进多模式人工智能的一大进步。 像这样的高效管道可以释放接近人类理解水平的视频理解能力。很高兴看到一些在 Panda-70M 上训练的模型可用。 论文此处。 此处摘要。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/1b4stoa/r_panda70m_captioning_70m_videos_with_multiple/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4stoa/r_panda70m_captioning_70m_videos_with_multiple/</guid>
      <pubDate>Sat, 02 Mar 2024 16:56:02 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 无监督图像分割的最新技术是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4sfwf/dr_what_is_the_current_state_of_the_art_for/</link>
      <description><![CDATA[我正在为一个博士项目处理 4k 图像数据，我们有大量未标记的图像需要分割。顾问想要从无监督图像分割开始。我应该从哪种算法开始进行播放和调整？    由   提交/u/bahauddin_onar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4sfwf/dr_what_is_the_current_state_of_the_art_for/</guid>
      <pubDate>Sat, 02 Mar 2024 16:39:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您的 LLM 技术堆栈在生产中是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4sdru/d_what_is_your_llm_tech_stack_in_production/</link>
      <description><![CDATA[想知道每个人都使用什么来实现 LLM 支持的应用程序以供生产使用，以及您对这些工具和建议的体验。  这就是我为金融和资本市场用户构建的一些 RAG 原型所使用的。 预处理\ETL：非结构化.io + Spark、Airflow 嵌入模型： Cohere Embed v3 以前使用 OpenAI Ada，但 Cohere 对于我的用例来说具有明显更好的检索召回率和精度。还探索其他开放权重嵌入模型 矢量数据库： Elasticsearch 以前但现在使用 Pinecone LLM： 经历了相当长的一段时间很少包括托管和自托管选项。在原型设计初期使用 gpt4，然后切换到 gpt3.5-turbo，以获得更易于管理的成本并最终开放权重模型。  现在使用由 vLLM 自托管的经过微调的 Llama2 30B 模型 LLM 框架：最初从 Langchain 开始，但发现扩展为应用程序很麻烦变得更加复杂。在某个时候尝试在 LlamaIndex 中实现它只是为了学习，但发现它同样糟糕。回到 Langchain，现在我正在用自己的逻辑替换它 其他人都使用什么？    ;由   提交/u/gamerx88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4sdru/d_what_is_your_llm_tech_stack_in_production/</guid>
      <pubDate>Sat, 02 Mar 2024 16:37:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] Gemma 训练数据集列表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4qtb5/d_gemma_training_datasets_list/</link>
      <description><![CDATA[嗨，我正在尝试查找在训练 Gemma 模型系列期间使用的数据集。这些文档仅提供简短的描述，但没有具体内容。有谁知道我是否能找到这样的东西？我这样做的原因是我想确保我选择的数据集肯定不在训练样本内。   由   提交 /u/cosminptr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4qtb5/d_gemma_training_datasets_list/</guid>
      <pubDate>Sat, 02 Mar 2024 15:28:38 GMT</pubDate>
    </item>
    <item>
      <title>离线政策学习的深度生成模型：教程、调查和对未来方向的展望</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4qb2a/deep_generative_models_for_offline_policy/</link>
      <description><![CDATA[ 由   提交 /u/Ahamed-Put-2344   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4qb2a/deep_generative_models_for_offline_policy/</guid>
      <pubDate>Sat, 02 Mar 2024 15:05:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Google TPU 的经验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4oypz/d_experience_with_google_tpu/</link>
      <description><![CDATA[有人有将软件移植到 Google TPU 的经验吗？它与提升和转移现有 PyTorch 或 TensorFlow 工作负载一样简单，还是更复杂？  从头开始编写代码怎么样，更容易吗？   由   提交 /u/siliconductor1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4oypz/d_experience_with_google_tpu/</guid>
      <pubDate>Sat, 02 Mar 2024 14:02:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 具有分析能力的法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4oej0/d_llm_with_analytical_capabilities/</link>
      <description><![CDATA[我的老板要求我创建一个应用程序，该应用程序可以连接到 Redshift 或 Postgres 数据库，可以检索数值数据，并可以回答财务和分析问题公司。他不明白 RAG 技术不适合数值分析。知道如何实现这一目标。 他提到使用 amazon Q 来完成此任务，我发现它在给出数字数据集的答案方面非常糟糕 &lt;!-- SC_ON - -&gt;  由   提交/u/Fun-Ad953  /u/Fun-Ad953 reddit.com/r/MachineLearning/comments/1b4oej0/d_llm_with_analytical_capability/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4oej0/d_llm_with_analytical_capabilities/</guid>
      <pubDate>Sat, 02 Mar 2024 13:34:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 更换照片上的衣服的最佳方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4nucb/d_best_way_to_replace_clothes_on_the_photo/</link>
      <description><![CDATA[社区大家好👋 由于我是 ML 领域的菜鸟，请向认识的人寻求一些帮助。我的目标是创建一个概念验证工具，它将取代人的衣服。 预期输入： - T 恤/连帽衫/毛衣放在桌子上或挂在衣架上的照片 - 一个男人/女人站在简单造型姿势的全身照片 预期 输出： - 同一男人/女人站在通过的T恤/连帽衫/毛衣的全身照片 我的朋友建议使用这个模型：&lt; a href=&quot;https://ootd.ibot.cn/&quot;&gt;https://ootd.ibot.cn/ 但也许你以前遇到过这个问题，并找到了更好的模型/管道 此外，我正在考虑将输入扩展到：商品的面料/商品的合身性（常规/修身/等）/一些其他属性，这些属性可能有助于实现最真实的结果而没有缺陷。 感谢您的宝贵时间！非常感谢有关如何解决此问题的任何帮助/建议:)    由   提交/u/sl0bodzyany  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4nucb/d_best_way_to_replace_clothes_on_the_photo/</guid>
      <pubDate>Sat, 02 Mar 2024 13:05:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 时间序列综合数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4mo54/d_time_series_synthetic_data/</link>
      <description><![CDATA[大家好。有人处理过创建季节性时间序列合成数据吗？您能建议最好的方法是什么吗？我正在做多变量时间序列预测，想知道合成数据是否适用于此，因为它应该模仿潜在的关系。我确实使用 SDV（指定约束和分布）创建了额外一年的数据，但模型显示的分数更差。质量报告显示 92.64%（柱形状和柱对趋势）。但我仍然感到困惑是否有可能重新创建 X 变量以及 X 和 y 之间的潜在关系？谢谢。    由   提交 /u/_what_the_f   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4mo54/d_time_series_synthetic_data/</guid>
      <pubDate>Sat, 02 Mar 2024 11:58:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] BitNet 1-b/b1.58 LLM - 这对 nvidia 构成威胁吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4lhjt/d_bitnet_1bb158_llms_is_that_a_threat_to_nvidia/</link>
      <description><![CDATA[论文链接：https://arxiv.org /pdf/2402.17764.pdf 这是真的吗？听起来好得令人难以置信，对吧？如果这是真的，它不仅减少了训练和运行 LLM 所需的 VRAM 容量和带宽，还建议简化硬件实现，因为不需要 matmul ，它只需要 + 运算 不是对 nvidia（股票）和 AMD 也构成威胁吗？   由   提交/u/tunggad  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4lhjt/d_bitnet_1bb158_llms_is_that_a_threat_to_nvidia/</guid>
      <pubDate>Sat, 02 Mar 2024 10:42:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 人形运动作为下一个令牌预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4kriv/r_humanoid_locomotion_as_next_token_prediction/</link>
      <description><![CDATA[论文： https:// arxiv.org/abs/2402.19469 摘要：   我们将现实世界的人形控制视为下一个令牌预测问题，类似于预测语言中的下一个单词。我们的模型是通过感觉运动轨迹的自回归预测训练的因果变换器。为了考虑数据的多模态性质，我们以模态对齐的方式执行预测，并且对于每个输入标记从相同模态预测下一个标记。这种通用的公式使我们能够利用缺少模式的数据，例如没有动作的视频轨迹。我们根据来自先前神经网络策略、基于模型的控制器、动作捕捉数据和人类 YouTube 视频的一组模拟轨迹来训练我们的模型。我们展示了我们的模型能够让全尺寸的人形机器人零射击地在旧金山行走。即使仅使用 27 小时的步行数据进行训练，我们的模型也可以转移到现实世界，并且可以泛化到训练期间未见过的命令，例如倒退行走。这些发现表明，通过感觉运动轨迹的生成模型来学习具有挑战性的现实世界控制任务是一条有希望的道路。   ​   由   提交 /u/StartledWatermelon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4kriv/r_humanoid_locomotion_as_next_token_prediction/</guid>
      <pubDate>Sat, 02 Mar 2024 09:54:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] Luminal：通过图编译在 Rust 中进行快速机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3yvr2/p_luminal_fast_ml_in_rust_through_graph/</link>
      <description><![CDATA[大家好，我用 Rust 开发 ML 框架已经有一段时间了，我终于很高兴与大家分享它。 Luminal 是一个深度学习库，它使用可组合编译器来实现高性能。 当前的 ML 库往往庞大且复杂，因为它们试图将高级操作直接映射到低级手写内核，并专注于急切执行。像 PyTorch 这样的库包含数十万行代码，单个程序员几乎不可能理解所有内容，除非进行大规模重构。 但是有必要这么复杂吗？机器学习模型往往是由一些简单运算符组成的静态数据流图。这使我们能够拥有一个非常简单的核心，仅支持一些原始操作，并使用它们来构建复杂的神经网络。然后，我们可以编写编译器，在构建图之后修改图，以根据我们运行的后端交换更高效的操作。 Luminal 采用这种方法极端情况下，仅支持 11 种基本运算 (primops)：  一元 - Log2、Exp2、Sin、Sqrt、Recip 二元 - &lt; strong&gt;Add、Mul、Mod、LessThan 其他 - SumReduce、MaxReduce、Contigious  每个复杂的操作都可以归结为对于这些原始操作，例如，当您执行 a - b 时，add(a, mul(b, -1)) 会写入图表。或者，当您执行a.matmul(b)时，实际放在图表上的是sum_reduce(mul(reshape(a), reshape(b)))。&lt; /p&gt; 一旦构建了图，迭代编译器就可以对其进行修改，以用更高效的操作替换 primops，具体取决于其运行的设备。例如，在 Nvidia 卡上，动态编写高效的 Cuda 内核来替换这些操作，并用专门的 cublas 内核交换支持的操作。 这种方法会产生一个简单的库，并且性能仅受限于编译器程序员的创造力，而不是模型程序员。 Luminal 还有许多其他简洁的功能，请查看存储库 这里 如果您有任何问题请lmk！   由   提交/u/jafioti   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3yvr2/p_luminal_fast_ml_in_rust_through_graph/</guid>
      <pubDate>Fri, 01 Mar 2024 16:44:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>