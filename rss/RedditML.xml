<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 09 Jan 2024 15:14:19 GMT</lastBuildDate>
    <item>
      <title>[讨论]LLM扩展法律论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192eids/discussion_llm_scaling_law_papers/</link>
      <description><![CDATA[大家好， 我正在寻找 llms 缩放定律领域的里程碑式论文。这是一个高级研究生研讨会，通过阅读和讨论研究论文来涵盖机器学习的各种主题。我认为法学硕士的缩放法则将是课程结束时讨论的一个有趣的主题。不幸的是，它离我自己的研究领域非常远，所以我希望获得有关在该领域选择重要或写得特别好的论文的建议。我知道龙猫，但我不确定这是否是最好的选择，或者该领域是否已经超越了它。如果您能帮助选择一篇或多篇论文，我们将不胜感激！提前致谢！   由   提交 /u/AmbulatedGiraffe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192eids/discussion_llm_scaling_law_papers/</guid>
      <pubDate>Tue, 09 Jan 2024 13:18:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] VAE 的重建损失重量与 KLD 重量？哪个更好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192d7ml/d_reconstruction_loss_weight_vs_kld_weight_for/</link>
      <description><![CDATA[一个比另一个更好吗？   由   提交 /u/Mr__Weasels   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192d7ml/d_reconstruction_loss_weight_vs_kld_weight_for/</guid>
      <pubDate>Tue, 09 Jan 2024 12:04:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 选择正确的法学硕士模式。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192csmj/d_picking_the_right_llm_model/</link>
      <description><![CDATA[大家好，我正在寻找针对不同用例构建内部 LLM 应用程序。示例用例包括产品助理、文本摘要、文档解析等。问题：是否有任何框架或平台可以根据这些用例来决定选择/选择哪个 LLM 模型来构建这些应用程序？ &lt; !-- SC_ON --&gt;  由   提交/u/vaibhavgoel2094  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192csmj/d_picking_the_right_llm_model/</guid>
      <pubDate>Tue, 09 Jan 2024 11:38:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 谷歌是否会放弃他们的现成模型和应用程序？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192chr6/p_does_google_sunset_their_offtheshelf_models_as/</link>
      <description><![CDATA[我最近一直在为个人项目研究语义搜索，并且偶然发现了 Google Cloud Platform“Gecko”嵌入模型看起来可以让我通过比较产品描述的相似程度来找到类似的产品。 我在语义搜索中看到的主要问题是嵌入模型仍然存在的要求完全不变并且仍然可用，因为否则，我将无法衡量与我的“亲密程度”。任何新产品。在这种情况下，我必须重新矢量化所有已经矢量化的产品，因为不同嵌入模型的矢量空间表示是不同的。看起来这可能会很昂贵，而且会浪费大量时间。 鉴于 Google 因淘汰旧产品而闻名，我不想跳入很快就会消失的东西。谷歌对这种事情有向后兼容性吗？我最好去其他地方，还是直接放弃并在 GPC 或 AWS 上托管经过预训练的 Word2Vec 版本？   由   提交/u/ojiber  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192chr6/p_does_google_sunset_their_offtheshelf_models_as/</guid>
      <pubDate>Tue, 09 Jan 2024 11:20:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在可塑性之前推断神经活动作为超越反向传播学习的基础</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192an1m/r_inferring_neural_activity_before_plasticity_as/</link>
      <description><![CDATA[论文：https://www.nature.com/articles/s41593-023-01514-1 预印本版本：https://www.biorxiv.org/content/10.1101/2022.05.17.492325  代码：https://github.com/YuhangSong/Prospective-Configuration 摘要：  对于人类和机器来说，学习的本质是查明信息处理管道中的哪些组件对其输出中的错误负责，一个被称为“学分分配”的挑战。长期以来，人们一直认为学分分配最好通过反向传播来解决，这也是现代机器学习的基础。在这里，我们提出了一个根本不同的信用分配原则，称为“预期配置”。在前瞻性配置中，网络首先推断学习应产生的神经活动模式，然后修改突触权重以巩固神经活动的变化。我们证明，与反向传播相比，这种独特的机制（1）是在完善的皮质回路模型家族中进行学习的基础，（2）使得学习能够在生物有机体面临的许多环境中更加高效和有效，（3） ）再现了在不同的人类和大鼠学习实验中观察到的令人惊讶的神经活动和行为模式。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192an1m/r_inferring_neural_activity_before_plasticity_as/</guid>
      <pubDate>Tue, 09 Jan 2024 09:14:44 GMT</pubDate>
    </item>
    <item>
      <title>目前该领域的弱点是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192aj3h/what_are_weaknesses_of_the_field_currently_d/</link>
      <description><![CDATA[大家好， 有人了解该领域技术和业务相关的差距和弱点吗？如果可能或者更高效的话，哪些事情会让项目和模型变得最优？例如（不一定是大规模案例）缺乏高质量的数据集。  非常感谢！   由   提交 /u/卷积  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192aj3h/what_are_weaknesses_of_the_field_currently_d/</guid>
      <pubDate>Tue, 09 Jan 2024 09:06:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自对弈微调将弱语言模型转换为强语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192agnv/r_selfplay_finetuning_converts_weak_language/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.01335 摘要：  通过监督微调利用人工注释数据的力量（SFT）对于推进大型语言模型（LLM）至关重要。在本文中，我们深入探讨了在无需获取额外人工注释数据的情况下，从较弱的法学硕士中培养出较强的法学硕士的前景。我们提出了一种新的微调方法，称为自玩微调（SPIN），该方法从监督微调模型开始。 SPIN 的核心是自我对弈机制，LLM 通过与自身实例对战来完善其能力。更具体地说，法学硕士从之前的迭代中生成自己的训练数据，通过区分这些自我生成的响应和从人工注释数据中获得的响应来完善其策略。我们的方法逐步将 LLM 从一个新生模型提升为一个强大的模型，释放了 SFT 人工注释演示数据的全部潜力。从理论上讲，我们证明，只有当 LLM 策略与目标数据分布一致时，才能实现我们方法的训练目标函数的全局最优。根据经验，我们在几个基准数据集上评估我们的方法，包括 HuggingFace Open LLM Leaderboard、MT-Bench 和 Big-Bench 的数据集。我们的结果表明，SPIN 可以显着提高 LLM 在各种基准测试中的表现，甚至优于通过直接偏好优化 (DPO) 并辅以额外 GPT-4 偏好数据训练的模型。这揭示了自我对弈的前景，无需专家对手即可在法学硕士中实现人类水平的表现。   &amp;# 32；由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192agnv/r_selfplay_finetuning_converts_weak_language/</guid>
      <pubDate>Tue, 09 Jan 2024 09:01:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 定制 LLM RAG 应用程序会变得多余吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1929n4f/d_are_custom_llm_rag_apps_going_to_become/</link>
      <description><![CDATA[Copilot Studio 即将推出 (https://www.microsoft.com/en-us/microsoft-copilot/microsoft-copilot-studio），具有令人印象深刻的无代码/开箱即用的 RAG 解决方案。  开源 RAG 世界（例如 Langchain、Llamaindex 等）有大量的开发和活动，我是 FYI 的大力支持者。 但是，什么似乎奇怪的是，如果您想构建一个 RAG 应用程序，即如果您比较构建和生产自定义应用程序的成本，那么这种没有开箱即用代码的解决方案（Copilot Studio - 只是作为一个示例）似乎压倒性地是更好的选择RAG 应用程序与使用 Copilot Studio 的成本相比，几乎低了一个数量级（无论您如何削减开发人员的时间和持续时间）。  我的问题是，在我看来，我们正在走向这样一种情况：企业解决方案将使自定义 RAG 应用程序变得多余（当然不是在所有情况下，但在大多数情况下），但是似乎很少有与开源社区中的活动相关的讨论。人们是否同意这是一种可能的情况？  显然会有例外......但在大多数用例中，我不知道如何与即时/最小设置、低成本、高度可扩展的 RAG 解决方案竞争。    由   提交/u/Used-Ad-7734   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1929n4f/d_are_custom_llm_rag_apps_going_to_become/</guid>
      <pubDate>Tue, 09 Jan 2024 08:03:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你们如何评价LLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1926ias/d_how_do_you_guys_evaluate_llm/</link>
      <description><![CDATA[你们如何评价LLM？有在线排行榜：https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard &amp; #x200b; 是否有任何脚本可以自动评估我们的离线/基准性能？   由   提交/u/Dense-Smf-6032   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1926ias/d_how_do_you_guys_evaluate_llm/</guid>
      <pubDate>Tue, 09 Jan 2024 04:54:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT4-V VS Gemini Pro Vision 完整版！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19268kz/d_gpt4v_vs_gemini_pro_vision_full_version/</link>
      <description><![CDATA[目前GPT和Gemini都只支持图片输入，不支持视频输入。因此，我只从Google Gemini demo中选择了与图像相关的测试来比较GPT-4-V和Gemini-Pro-Vision，测试内容包括：  图像内容的基本识别 对图像中的物体进行分析 对图像中的内容进行逻辑推理 连续图像内容的识别与分析  https://youtu .be/yFK62Tn_f4Q 如果您对视频中演示的开源项目感兴趣，请访问https://github.com/smalltong02/keras-llm-robot    由   提交 /u/Entire-Fly-6957   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19268kz/d_gpt4v_vs_gemini_pro_vision_full_version/</guid>
      <pubDate>Tue, 09 Jan 2024 04:39:56 GMT</pubDate>
    </item>
    <item>
      <title>混合纸[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1924vn1/mixtral_paperd/</link>
      <description><![CDATA[https://arxiv.org/abs/2401.04088   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1924vn1/mixtral_paperd/</guid>
      <pubDate>Tue, 09 Jan 2024 03:31:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] WikiChat：通过维基百科上的少发基础来阻止大型语言模型聊天机器人的幻觉 - 在与人类用户就最新主题进行的对话中实现了 97.9% 的事实准确性，比 GPT-4 好 55.0%！ - 斯坦福大学 2023</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1920hky/r_wikichat_stopping_the_hallucination_of_large/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2305.14292v2  Github：https://github.com/stanford-oval/WikiChat  摘要：  本文提出了第一个基于 LLM 的少样本聊天机器人几乎从不产生幻觉，并且具有高会话性和低延迟。 WikiChat 以英语维基百科为基础，这是最大的精选自由文本语料库。  WikiChat 生成法学硕士的回复，仅保留有根据的事实，并将其与从语料库中检索到的其他信息相结合，形成事实且引人入胜的回复。 我们将基于 GPT-4 的 WikiChat 提炼为质量损失最小的 7B 参数 LLaMA 模型，以显着改善其延迟、成本和隐私，并促进研究和部署。  使用一种新颖的人类和法学硕士混合评估方法，我们证明我们最好的系统在模拟对话中达到了 97.3% 的事实准确性。它显着优于所有基于检索和基于 LLM 的基线，与 GPT-4 相比，在头部、尾部和近期知识方面分别提高了 3.9%、38.6% 和 51.0%。与之前最先进的基于检索的聊天机器人相比，WikiChat 的信息量和吸引力也显着提高，就像法学硕士一样。  WikiChat 在与人类用户就近期话题进行的对话中实现了 97.9% 的事实准确性，比 GPT-4 高出 55.0%，同时获得了更高的用户评分和更有利的评论。   https:/ /preview.redd.it/9mhpdh300bbc1.jpg?width=1225&amp;format=pjpg&amp;auto=webp&amp;s=cb64b717e920d7bf727782f7c803500ae838d6ef https://preview.redd.it/5dxesl200bbc1.jpg?width=862&amp;format=pjpg&amp;auto=webp&amp;s =b6de0cda980eec3cf3484ff1f9cd6dc1acf13505 https ://preview.redd.it/j387vl200bbc1.jpg?width=914&amp;format=pjpg&amp;auto=webp&amp;s=736fb922c1f98f4c7b132f1c153f4653a8b85441 https://preview.redd.it/3hnxqi200bbc1.jpg?width=923&amp;format=pjpg&amp;auto=webp&amp; ;s=95b40a9cf67d7f3729dae85878db67a262cc5201   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1920hky/r_wikichat_stopping_the_hallucination_of_large/</guid>
      <pubDate>Tue, 09 Jan 2024 00:07:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我构建了 marimo——一个开源的反应式 Python 笔记本，它存储为 .py 文件，可以作为脚本执行，并且可以作为应用程序部署。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191rdwq/p_i_built_marimo_an_opensource_reactive_python/</link>
      <description><![CDATA[嗨！我想分享 marimo，一个用于 Python 的开源反应式笔记本。它旨在解决 Jupyter 笔记本的许多众所周知的问题，同时为您提供新功能：marimo 笔记本可重复（无隐藏状态）、git 友好（存储为 Python 文件）、可作为 Python 脚本执行以及可部署为 Web 应用程序。 GitHub 存储库： https://github.com/marimo-team/marimo 在 marimo 中，您的笔记本代码、输出和程序状态保证是一致的。运行单元格并通过自动运行引用其变量的单元格来做出反应。删除一个单元格，marimo 就会从程序内存中清除其变量，从而消除隐藏状态。如果您担心意外触发昂贵的计算，您可以禁用特定单元格的自动运行。 marimo 还附带 UI 元素，例如滑块、数据帧转换器以及自动与 Python 同步的交互式绘图。与元素交互，使用该元素的单元格会自动以其最新值重新运行。反应性使这些 UI 元素比 Jupyter 小部件更有用，更不用说更易于使用。 我选择开发 marimo，因为我相信 ML 社区应该有一个更好的编程环境来进行研究和交流。我看到很多研究都是从 Jupyter 笔记本开始的（我自己的大部分也是这样）。由于 Jupyter 笔记本固有的缺陷，我还看到许多相同的研究未能重现或因隐藏的错误而减慢速度。 我坚信，我们工作的质量取决于我们使用的工具塑造了我们的思维方式——更好的工具，更好的思维。 2017 年至 2018 年，我在 Google Brain 担任软件工程师，当时 TensorFlow 正在过渡到 TensorFlow 2，而 JAX 还处于早期阶段。我亲眼目睹了 PyTorch 和 JAX 给我们社区带来的生产力的提高，后来当我在斯坦福大学与 Stephen Boyd 一起攻读博士学位时，我也看到了我自己的研究。我们对 marimo 的目标是通过新的编程环境做一些类似的事情。 marimo 的开发经过了科学家和工程师的密切投入，并受到了包括 Pluto.jl 和 Streamlit 在内的许多工具的启发。只有我们两个人在研究它——我们最近将其开源，因为我们认为它已经准备好供更广泛的使用。请尝试一下（pip install marimo &amp;&amp; marimo 教程简介）。我们非常希望您能提供任何反馈！   由   提交 /u/akshayka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191rdwq/p_i_built_marimo_an_opensource_reactive_python/</guid>
      <pubDate>Mon, 08 Jan 2024 18:00:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人脑 FLOPs 估计，是否比我们想象的要低？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191ol1n/d_human_brain_flops_estimate_is_it_lower_than_we/</link>
      <description><![CDATA[这篇文章旨在提供对人脑的深入了解，以便更容易将其与人工神经网络进行比较。 对我即将要说的大部分内容持保留态度，我很容易就会被一个数量级所影响，或者错过一些东西。  Ray Kurzweils 估计。 1011 个神经元。每个神经元有 1000 个突触连接。每秒 100 个峰值。  每秒计算 1011 × 1000 × 100=1016 次。 引用奇点临近：“考虑到人脑逆向工程的早期阶段，我将使用更保守的数字 1016 CPS”。  我自己的计算。自 2005 年以来情况似乎发生了变化，现在维基百科说每个神经元有 7000 个突触 https://en.m.wikipedia.org/wiki /Neuron  神经元放电速度平均为 0.1 到 2 赫兹。 https://aiimpacts.org/rate-of-neuron-firing/ #:~:text=Assorted%20estimates- 我将使用 1/s 作为尖峰频率。大脑也更明确，有 86,000,000,000 个神经元。 8,6×1010 × 7000 × 1 = 6×1014。 6×10 14 FLOP（每个突触一次 FLOP）。  峰值能量需求。神经元的每次激活都需要一定量的能量，该能量似乎为 2.468 × 10−7 J https://link.springer.com/article/10.1007/s11571-018-9503-3  所以从这里开始，其他一切都可以被弄清楚。尖峰能量 = 2.468 × 10−7 J 24 小时内大脑能量消耗 = 1,673,600 焦耳 24 小时内的秒数 = 86400。每个神经元有 7000 个突触。 1,673,600÷(2.468 × 10 −7) J = 6,782×1012。 6,782×1012 ÷ 86400 = 78,486,103。 (78,每秒 500 万次峰值）。 78,486,103 × 7000 = 5.49×1010 FLOP 或 549 gigaFLOPs 如果 3 正确，则意味着高端手机的 GPU 计算量比人脑的计算量还要多（三星 s23，fp32 时为 3,681 TFLOP。大脑一天平均为 0,549 TFLOP）。 这不是比较事物的好方法，因为大脑是一台大规模并行计算机，内存基本上存在于结构中。  那么需要多少“内存”呢？我们谈论的是大脑吗？我们有： 86,000,000,000 个神经元。每个神经元有 7000 个突触。每个突触 5 位。 https://www.cnsnevada.com/what-is-the-memory-capacity-of-a- human-brain/#:~:text=Neurons%20are%20the%20cells%20which 86,000,000,000 × 7000 × 5 = 3×1015 位或 3.76×1014 字节。祝你好运，在手机上安装 376 TB RAM。 但是每秒 78,500,000 个峰值真的足以让大脑处理所有事情吗？让我们看看眼睛。 每只眼睛的总分辨率为 8 兆像素。 https://m.youtube.com/watch?v=4I5Q3UXkGd0&amp;pp=ygUednNhdWNlIHJlc29sdXRpb 24gb2YgaHVtYW4gZXll&lt; /p&gt; 通过视神经发送的信息大约只有 10,000,000 位/秒 https://www.eurekalert。 org/news-releases/468943 （只有最相关的信息通过视神经发送，因为大脑希望不惜一切代价节省电量）。因此，我们的双眼每秒有 20,000,000 个尖峰，这是 7850 万个尖峰的 25.5%。 7850 万个尖峰并不是一个硬性的性能上限，它只是一天的平均值，而大脑是根据需要主动调节脑电波频率。 您认为哪种情况更有可能？ 1. 2. 或 3.   由   提交 /u/SpaceXRaptor42   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191ol1n/d_human_brain_flops_estimate_is_it_lower_than_we/</guid>
      <pubDate>Mon, 08 Jan 2024 16:05:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>