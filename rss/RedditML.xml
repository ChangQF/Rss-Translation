<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 16 Apr 2024 09:13:38 GMT</lastBuildDate>
    <item>
      <title>[D] Swin 变压器在线性探测方面表现不佳吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c5atzv/d_do_swin_transformers_perform_poorly_at_linear/</link>
      <description><![CDATA[为了写一篇论文，我一直在使用 SimMIM 训练一些 Swin 变压器，并注意到 ImageNet1k 上的线性探测精度非常可怕。当我使用最小的 Swin 模型 Swin-T 时，第 25 个 epoch 后的性能仅为 2.5% top1（ViT-T 在相似数量的 epoch 后达到约 5% top1，而 ViT-B 达到 7%）。 p&gt; 我想知道是否有人用 Swin 变压器做过类似的实验，以及在线性评估中使用它们是否会失败。 感谢任何帮助。提前致谢。   由   提交/u/Mad_Scientist2027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c5atzv/d_do_swin_transformers_perform_poorly_at_linear/</guid>
      <pubDate>Tue, 16 Apr 2024 08:17:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪里可以找到 ICML 2024 研讨会？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c5a171/d_where_to_find_icml_2024_workshops/</link>
      <description><![CDATA[有谁知道在哪里可以找到有关 ICML 2024 将举办哪些研讨会的信息？研讨会接受通知已于 3 月 27 日发布，但研讨会似乎尚未在 ICML 网站上发布。 谢谢！   由   提交 /u/Stinein   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c5a171/d_where_to_find_icml_2024_workshops/</guid>
      <pubDate>Tue, 16 Apr 2024 07:21:40 GMT</pubDate>
    </item>
    <item>
      <title>斯坦福大学发布了相当全面（500 页）的“2004 年人工智能指数报告”，总结了当今人工智能的状况。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c59zrq/stanford_releases_their_rather_comprehensive_500/</link>
      <description><![CDATA[ 由   提交/u/Appropriate_Ant_4629   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c59zrq/stanford_releases_their_rather_comprehensive_500/</guid>
      <pubDate>Tue, 16 Apr 2024 07:19:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通用时间序列预测变压器的统一训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c59hei/r_unified_training_of_universal_time_series/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.02592 代码：https://github .com/SalesforceAIResearch/uni2ts 模型：https://huggingface.co/collections/Salesforce/moirai-10-r-models-65c8d3a94c51428c300e0742 数据集：https://huggingface.co/datasets/Salesforce/lotsa_data 博客文章：&lt; a href=&quot;https://blog.salesforceairesearch.com/moirai/&quot;&gt;https://blog.salesforceairesearch.com/moirai/ 摘要：   时间序列预测的深度学习传统上在每个数据集一个模型的框架内运行，限制了其利用大型预训练模型改变游戏规则的影响的潜力。通用预测的概念源于对大量时间序列数据集的预训练，设想了一个能够解决不同下游预测任务的单一大型时间序列模型。然而，构建这样的模型对时间序列数据提出了独特的挑战：i）跨频率学习，ii）为多元时间序列容纳任意数量的变量，以及iii）解决大规模数据固有的不同分布特性。为了应对这些挑战，我们对传统时间序列 Transformer 架构进行了新颖的增强，从而提出了基于掩码编码器的通用时间序列预测 Transformer (Moirai)。在我们新推出的大规模开放时间序列存档 (LOTSA) 上进行训练，Moirai 具有跨九个域超过 27B 的观测数据，与全样本模型相比，Moirai 作为零样本预测器实现了具有竞争力或卓越的性能。代码、模型权重和数据将被发布。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c59hei/r_unified_training_of_universal_time_series/</guid>
      <pubDate>Tue, 16 Apr 2024 06:45:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 微调增强现有机制：实体跟踪案例研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c598g0/r_finetuning_enhances_existing_mechanisms_a_case/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2402.14811 OpenReview：https:// /openreview.net/forum?id=8sKcAWOf2D 代码：https： //github.com/Nix07/finetuning 模型：https ://huggingface.co/nikhil07prakash/float-7b 项目页面： https://finetuning.baulab.info/ 摘要：  对通用任务进行微调，例如遵循指令、代码生成和数学已被证明可以增强语言模型在一系列任务上的性能。然而，对这种微调如何影响这些模型的内部计算的解释仍然难以捉摸。我们研究微调如何影响语言模型中实现的内部机制。作为一个案例研究，我们探索了实体跟踪的属性，这是语言理解的一个关键方面，其中对数学进行微调的模型具有显着的性能提升。我们确定了实现实体跟踪的机制，并表明（i）在原始模型及其微调版本中，主要是相同的电路实现了实体跟踪。事实上，原始模型的实体跟踪电路在微调版本上的性能比完整的原始模型更好。 (ii) 所有模型的电路实现大致相同的功能：实体跟踪是通过跟踪原始模型及其微调版本中正确实体的位置来执行的。 (iii) 微调模型的性能提升主要归因于其处理增强位置信息的能力提高。为了揭示这些发现，我们采用了：补丁修补、DCM（自动检测负责特定语义的模型组件）和 CMAP（一种用于跨模型修补激活以揭示改进机制的新方法）。我们的研究结果表明，微调增强了而不是从根本上改变了模型的机械操作。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c598g0/r_finetuning_enhances_existing_mechanisms_a_case/</guid>
      <pubDate>Tue, 16 Apr 2024 06:29:29 GMT</pubDate>
    </item>
    <item>
      <title>[D]建筑学</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c59468/d_architecture/</link>
      <description><![CDATA[您为 ML 应用程序使用什么类型的架构？您使用微服务还是其他东西？   由   提交 /u/Bolehlaf   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c59468/d_architecture/</guid>
      <pubDate>Tue, 16 Apr 2024 06:21:48 GMT</pubDate>
    </item>
    <item>
      <title>将模型预测作为特征返回[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c58o96/feeding_model_prediction_back_in_as_feature/</link>
      <description><![CDATA[我正在使用模型进行分类。训练模型以对训练集和测试集进行概率预测，然后将所得概率以概率作为特征添加回新模型，这是一种好的做法吗？ 流程：  训练/测试模型 predict_proba 以获得概率 训练另一个具有与第一个模型相同特征的模型 + 概率  第二个模型明显更准确，但我对此表示怀疑。   由   提交 /u/Fuzzy_Lock_5557   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c58o96/feeding_model_prediction_back_in_as_feature/</guid>
      <pubDate>Tue, 16 Apr 2024 05:53:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] Megalodon：高效的 LLM 预训练和无限上下文长度的推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c57nxd/r_megalodon_efficient_llm_pretraining_and/</link>
      <description><![CDATA[ 由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c57nxd/r_megalodon_efficient_llm_pretraining_and/</guid>
      <pubDate>Tue, 16 Apr 2024 04:51:49 GMT</pubDate>
    </item>
    <item>
      <title>[D]训练边缘TPU（珊瑚）的keras对象检测模型[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c57d07/dtrain_keras_object_detection_model_for_edge/</link>
      <description><![CDATA[对于客户，我需要训练一个能够在珊瑚板上运行以进行边缘 TPU 推理的对象检测模型，有一些示例可以简化使用 TensorFlow Lite Model Maker 的过程或使用 kerasCV 的其他一些示例（不适用于边缘 TPU），但对于此客户端，我们希望使用纯 keras，因为有一些要求无法通过模型制作器实现（据我所知，如果错误请纠正我），特别是：  需要计算一些额外的指标（例如：一些通过 coco evaluator 获得的指标） 需要在训练期间跟踪张量板中的指标比较不同的运行、不同的数据集、执行早期停止、检测欠拟合/过拟合等。  有人执行过类似的操作吗？或者有什么例子或想法吗？   由   提交 /u/Sad-Anywhere-2204   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c57d07/dtrain_keras_object_detection_model_for_edge/</guid>
      <pubDate>Tue, 16 Apr 2024 04:34:09 GMT</pubDate>
    </item>
    <item>
      <title>图像生成的扩散模型与自回归模型。哪个更好？ [D] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c53pc5/diffusion_versus_autoregressive_models_for_image/</link>
      <description><![CDATA[大家好， 我是使用变压器模型生成图像这一领域的新手。我对上面提到的两种方法很好奇。特别是根据这篇论文“视觉自回归建模：通过下一代预测生成可扩展图像” (结果）。看起来这些 AR（自回归）模型似乎比 DiT（扩散变压器）更好，尤其是在放大时。他们的主要推理优势似乎来自 DiT 的低采样效率。 但是，我对此表示怀疑。除了主要人工智能强国已经采用扩散模型这一事实之外，还有一个坚实的理论支持扩散模型能够生成任何图像分布。除此之外，上面的 VAR 论文没有针对小模型的结果（我也对此感兴趣）。 所以这是我的问题：  有吗有没有提高采样效率的DiT蒸馏论文？我找不到任何 Transformer，所有都是基于 U-Net 的。 是否有任何理论支持用于图像生成（或任何与此相关的生成任务）的 AR Transformer 模型？ 这篇 VAR 论文更好纯粹是因为人们还没有充分探索 DiT 吗？或者说 AR 模型的霸主地位是我们所期望的？ 如果您要根据潜在性能（从研究的角度来看）和成功在两者之间进行选择，您会选择什么？为什么？ （我有偏见，因此支持扩散的原因值得赞赏）  如果您可以回答任何问题或与此事相关的任何意见，请发表评论..    由   提交 /u/InstinctsInFlow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c53pc5/diffusion_versus_autoregressive_models_for_image/</guid>
      <pubDate>Tue, 16 Apr 2024 01:27:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 物体检测中的 SOTA？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4pccp/d_sota_in_object_detection/</link>
      <description><![CDATA[几年前我做过目标检测，其中 FRCNN、SSD 和 YOLO 与 RESNET 和 VGG 等作为主干的东西一起流行。 回到 2024 年的今天的物体检测任务，我找不到任何重大改进或真正新的架构。我是否遗漏了什么，或者这仍然是 SOTA？ 谢谢！ :)   由   提交/u/topsnek69  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4pccp/d_sota_in_object_detection/</guid>
      <pubDate>Mon, 15 Apr 2024 15:40:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么稳定扩散的潜在通道这么小？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4o0qg/d_why_is_the_latent_channel_of_stable_diffusion/</link>
      <description><![CDATA[大家好。我是生成人工智能领域的新手，目前正在深入研究稳定扩散的内部结构。我注意到 SD 的 VAE 编码逐渐将通道数提升到 512 个，但在生成潜在向量时突然下降到只有 4 个。这就像一条非常宽阔的隧道后面有一个非常非常细的瓶颈。为什么要这样设计呢？ 64*64*4真的足以表达这么多可能的特征吗？    由   提交/u/ConsequenceDear2557   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4o0qg/d_why_is_the_latent_channel_of_stable_diffusion/</guid>
      <pubDate>Mon, 15 Apr 2024 14:45:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 冷冰冰地给研究人员发邮件寻求合作，我应该谨慎吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4l2hv/d_cold_emailing_a_researcher_for_collaboration/</link>
      <description><![CDATA[我是一名硕士生，几周来我一直在从事一个与研究人员所做的工作密切相关的项目A在最近的一篇论文中。该项目进展顺利，我认为它可以成为一份很棒的出版物，不幸的是我不认识任何从事该主题的人，并且一些指导对于正确捍卫该项目很有用。需要明确的是，这个项目已经很先进了，这不仅仅是一个想法。 我本来想尝试给研究员 A 发电子邮件，看看他是否有兴趣在这个项目上合作，但是我有疑问： 1/ 通过电子邮件冷联系是否很奇怪？我想人们通常会利用会议来进行这种交流，但我还没有机会 2/ 我应该对发送给此人的信息保持谨慎吗？他是一位著名的研究人员，所以我想这很安全，但我不想因为一封电子邮件而被抢先一步 我知道我提供的有关情况的信息很少，但我会如果您曾经做过类似的事情以及它是否成功，很高兴听到任何建议或经验   由   提交 /u/Even_Information4853   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4l2hv/d_cold_emailing_a_researcher_for_collaboration/</guid>
      <pubDate>Mon, 15 Apr 2024 12:33:41 GMT</pubDate>
    </item>
    <item>
      <title>因使用 Java 而被嘲笑 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4gi25/ridiculed_for_using_java_d/</link>
      <description><![CDATA[所以我在 Twitter 上（第一个错误）提到了我的 Java 神经网络，并因使用“过时且无用的语言”而被嘲笑。对于已经构建的NLP。 说实话，这是我的第一个NLP。不过，我确实创建了一个使用 GPT2 管道为作者生成故事的 Python 应用程序，但基础设施的其余部分是用 Java 编写的，我只是创建了一个 Python API 来调用它。 我喜欢 Java。我的代码可以追溯到 2017 年。我是一名业余爱好者，并不期望获得 ML 职位，尤其是在市场和现在的情况下。不过，我确实有机会在我的业务分析师工作中展示一些编程技能，并使用我非常小的 NLP 对一些票务数据执​​行一些基本预测，顺便说一句，我对这些数据很感兴趣。 我的问题是：我是一个彻底使用 Java 的失败者吗？我正在学习一些机器人技术，并计划学习一些 C++，但我拒绝放弃 Java，因为到目前为止，它教会了我很多东西，并为我带来了很好的成果。 l&#39;d就像你对此的看法。谢谢！   由   提交 /u/esqelle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4gi25/ridiculed_for_using_java_d/</guid>
      <pubDate>Mon, 15 Apr 2024 07:48:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>