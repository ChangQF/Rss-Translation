<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Mon, 17 Feb 2025 01:18:11 GMT</lastBuildDate>
    <item>
      <title>[D]如何处理高度不平衡的数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ir2zm3/dhow_to_handle_highly_imbalanced_dataset/</link>
      <description><![CDATA[在解决高度不平衡数据集的社区。过去，我建立了搅动预测模型，现在我专注于预测保险索赔，在此索赔的百分比很低。 我的数据集跨越了15年，并且包含约800,000个记录，并具有具有此类功能的功能作为性别，年龄，马力，汽车品牌＆amp;类型  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sthyddoctor007     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ir2zm3/dhow_to_handle_highly_imbalanced_dataset/</guid>
      <pubDate>Sun, 16 Feb 2025 21:22:49 GMT</pubDate>
    </item>
    <item>
      <title>ICML审稿人2025分配的论文？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ir29gm/icml_reviewers_2025_assigned_papers_d/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对所有其他ICML 2025审稿人，您是否已经在OpenReview中看到了分配的论文？我收到了分配的论文已准备好几天前的更新，但是在我的审阅者控制台中，我只看到“ 您没有分配的论文。纸质分配过程完成后，请再次检查。 &#39;我也没有列出的出色审阅者任务。我们现在已经进入了审核期三天了，所以我希望到现在为止的任务已经完成。我绝对不会做的是在几天之内审查6篇论文，因为某些交流需要额外的审阅者。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/five-innodable-7243      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ir29gm/icml_reviewers_2025_assigned_papers_d/</guid>
      <pubDate>Sun, 16 Feb 2025 20:52:03 GMT</pubDate>
    </item>
    <item>
      <title>[d]在新数据集上微调视频扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqy1pi/d_finetuning_a_video_diffusion_model_on_new/</link>
      <description><![CDATA[在 - 卫星镜头  - 显微镜视频&lt; /p&gt; 我对整个稳定的扩散景观有很好的了解，并且以前具有微调图像稳定的扩散，都完全微调，但也有更多轻巧的方法如洛拉（Lora）。这是我第一次冒险进入视频域，我赶上了以下资源以及他们的参考论文：  -   https://lilianweng.github.io/posts/2024-04-04-04-12-diffusion-video/    -   https://youtu.be/0k56la821ys      它似乎是我就像大多数SOTA视频扩散模型（Atleast the Openake the Openake the Openake the Openake ofere of the Openake the Openake ofere of the Openake ofere of the Openake ofere of the Openake of the Openake the Opent of the Openage the Opent of the Opent of the Opent源）现有的图像扩散模型，并通过添加时间层将其转变为视频扩散模型，然后在视频上训练模型，同时将空间层固定。 这使我解决了问题。让我们专注于一种模式，显微镜视频。我认为现在的条件将是一个开始框架。我看到了几种方法：  - 微观图像上的微调图像模型（可能是SD2），然后通过添加时间层和微调视频将该模型转换为视频模型 - 直接微调稳定的视频扩散在显微镜视频上 直觉上，我感觉就像是“完整的微型”与低级适应之类的东西相反，这里有意义的是什么？据我所知，稳定的视频扩散似乎是最好的开源模型，或者还有其他型号我应该研究吗？ 我有大约500GB的数据和1500 h100小时，所以我&#39;绝对不足以从头开始做任何事情，因此为什么首选某种微调方法，以及为什么优先使用潜在方法，而不是像素空间。 似乎存在巨大关于如何微调图像扩散模型的在线资源，但对视频模型的了解不多。显然，这个过程应该非常相似，但仍然如此。您如何看待，我是否确定了最有可能起作用的最大方法，还是您知道其他任何方法？您如何看待，我该如何处理？我可以期望得到的好成绩如何？关于评估，自动指标是否足够好，或者我需要进行人类的Evals？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lapurita     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iqy1pi/d_​​finetuning_a_video_diffusion_model_model_onew/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqy1pi/d_finetuning_a_video_diffusion_model_on_new/</guid>
      <pubDate>Sun, 16 Feb 2025 17:56:14 GMT</pubDate>
    </item>
    <item>
      <title>[d]寻找MLLM / VLMS课程，并且在视觉中的位置</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqw5ov/d_looking_for_mllms_vlms_courses_and_its_place_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这个空间非常新。寻找最新的材料来教我有关多模式LLM的知识，并且在计算机视觉中的位置。寻找诸如少数镜头与零，许多等和权衡的详细信息。有任何建议吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/happy_acanthisitta92      [link]   ＆＃32;   [注释]       ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqw5ov/d_looking_for_mllms_vlms_courses_and_its_place_in/</guid>
      <pubDate>Sun, 16 Feb 2025 16:37:26 GMT</pubDate>
    </item>
    <item>
      <title>[p]我构建了一个使用您的git提交历史记录作为可搜索实验日志的跟踪器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqv3yy/p_i_built_a_tracker_that_uses_your_git_commit/</link>
      <description><![CDATA[   &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/comments/1iqv3yy/p_i_built_a_a_a_tracker_tracker_tracker_tracker_tracker_tracker_tracker_tracker_tracker_your_your_your_your_your_git_commit/ your git commit history as a searchable experiment log&quot; src=&quot;https://external-preview.redd.it/QEgyaoMrMBGnzjPGiuPDJ7WiWOzD6bH4zDUPE4h2Urg.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=572a3eafddec240ba4efb5f3f1a0a31884ec49bf&quot; title=&quot;[P ]我构建了一个跟踪器，该跟踪器将您的git提交历史记录用作可搜索的实验日志“/&gt;   ＆＃32;提交由＆＃32; /u/user_example     [link]  ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqv3yy/p_i_built_a_tracker_that_uses_your_git_commit/</guid>
      <pubDate>Sun, 16 Feb 2025 15:52:11 GMT</pubDate>
    </item>
    <item>
      <title>[P]与重新成真的伯特混乱</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqv2r4/p_confusion_with_reimplementing_bert/</link>
      <description><![CDATA[在&gt; https://arxiv.org/pdf/1810.04805 ）但是我对某些东西有些困惑，在第4页：（  https：//arxiv.org/pdf/1810.04805.04805#page=4&amp; amp = 147,44,44,821 ） “在整个工作中，“句子”可以是连续文本的任意跨度，而不是实际的语言句子。当我从huggingface加载书籍时，我会得到这样的数据：  {&#39;text;“通常，他通常会在客厅里撕裂，玩具玩具。＆quot&#39;} &lt; br /&gt; {; text&#39;：“但是只有一个小小的看，几乎把他寄给了他。早些时经常暴露于年龄较大的事物。“}  {text”：“她喜欢认为被成年人和大孩子包围是他是他这个年龄如此好的说话者的一个原因。＆quot＆quot ;}  {; &#39;&#39;&#39;&#39;}  {; text＆quot；“她说。”。他们指的是上面的？因为在Bert纸中，它们将句子与[Sep]令牌之间的句子结合在一起，我是否可以假设我可以在这里组合每对句子？对于随机句子的50％，只需在文件中选择一个随机的JSON对象？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/benahmed23     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqv2r4/p_confusion_with_reimplementing_bert/</guid>
      <pubDate>Sun, 16 Feb 2025 15:50:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] Langchain和Langgraph工具呼叫DeepSeek-R1的支持</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqu0f8/p_langchain_and_langgraph_tool_calling_support/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在从事侧面项目时，我需要使用deepseek-r1的工具调用，但是langchain和langgraph不支持deepseek-的工具R1。因此，我决定手动编写一些自定义代码来执行此操作。 在此处发布它以帮助任何需要它的人。该软件包还可以与Langchain的Chatopenai库中可用的任何新发布的型号（通过扩展，OpenAi库上可用的任何新发布的模型）一起使用，该模型可能还没有Langchain和Langgraph的工具呼叫支持。即使deepseek-r1尚未进行工具调用，我也观察到我使用的JSON解析器方法仍然可以通过工具调用产生相当稳定的结果（接近100％精度）（可能是因为DeepSeek-R1是推理模型）。 如果您觉得这个有用且有趣的话，请给我的Github仓库。感谢您的支持！   https://github.com/leock.com/leockl/leockl/tool-ahead--时间   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; &lt; com/r/machinelearning/comment/1iqu0f8/p_langchain_and_langgraph_tool_calling_calling_support/“&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqu0f8/p_langchain_and_langgraph_tool_calling_support/</guid>
      <pubDate>Sun, 16 Feb 2025 15:01:25 GMT</pubDate>
    </item>
    <item>
      <title>[d]进行原始研究的步骤（这也是一个咆哮）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqq4fz/d_the_steps_to_do_original_research_its_a_rant_as/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是英国的大师学生。我一直在阅读有关扩散的论文。我已经联系了大学的博士生，并表示对与他们合作的兴趣。我以为我会帮助他们解决他们的研究方向。但是，与他们交谈后，他们告诉我阅读一些论文，然后找到一个研究想法。  对于上下文，我正在阅读有关扩散模型的信息。我读的越多，我意识到我缺乏一些数学基础。我通过课程，书籍和文章来填补这些洞。但是，这需要时间。我相信，缺乏基本的理解使我无法提出假设。我可以通过最近的调查论文找到一些研究差距，但是我无法提出任何假设或解决方案。 我朝正确的方向前进吗？从根本的角度理解东西有助于产生新颖的研究思想吗？如何产生新颖的研究思想？如果您有一些提示，我很高兴听到它们。  P.S。我从未出版过。因此，如果我错过了一些基本的东西，我感到很抱歉。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/snoo_65491     [link]   ＆＃32;   [注释]      ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqq4fz/d_the_steps_to_do_original_research_its_a_rant_as/</guid>
      <pubDate>Sun, 16 Feb 2025 11:14:23 GMT</pubDate>
    </item>
    <item>
      <title>[P]我建立了一个开源AI代理，该代理可以完全自动编辑视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqq1vz/p_i_built_an_opensource_ai_agent_that_edits/</link>
      <description><![CDATA[   &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/comments/1iqqq1vz/p_i_built_an_opensource_aigent_ai_aigent_aigent_that_that_edits/ AI agent that edits videos fully autonomously&quot; src=&quot;https://external-preview.redd.it/aNz3BFb1ycBa55wI3LX5BuJGkVgsXAVk_7lUskfK1zk.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b072cacd407870c1166de542f8cab83d84861bf1&quot; title=&quot;[P] I构建了一个开源AI代理，该代理完全自动编辑视频“/&gt;   ＆＃32;提交由＆＃32; /u/u/umaust_instance_401     代理“&gt; [link]  ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqq1vz/p_i_built_an_opensource_ai_agent_that_edits/</guid>
      <pubDate>Sun, 16 Feb 2025 11:09:16 GMT</pubDate>
    </item>
    <item>
      <title>[d] Torch.com使用Hidet编译器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqnyet/d_torchcompile_using_hidet_compiler/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有人尝试使用hidet作为torch.compile的火炬电感器的Altenative Backend。    https://pytorch.org/blog/introducing-hidet/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/lime_dragonfruit4244      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqnyet/d_torchcompile_using_hidet_compiler/</guid>
      <pubDate>Sun, 16 Feb 2025 08:37:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM法官提供动力的每日ARXIV过滤（与项目链接）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqnhai/p_daily_arxiv_filtering_powered_by_llm_judge_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  链接到项目： https://arxiv.ianhsiao.xyz &lt; /a&gt;  大家好，在我以前的reddit帖子中：没有可用的链接，因为我对许多subreddits粘贴了相同的评论，因此系统认为我是垃圾邮件并删除了所有这些（您可以比较显示的评论金额和实际数量验证）。我为此感到抱歉。 话虽如此，我真的很想学习社区的反馈，所以我再次发布此信息。 谢谢您的耐心配合！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/madyexz     [link]   ＆＃32;   [commist]       ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqnhai/p_daily_arxiv_filtering_powered_by_llm_judge_with/</guid>
      <pubDate>Sun, 16 Feb 2025 08:02:38 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会导致禁止。 鼓励其他人创建新的帖子，以便在此处发布问题！ 线程将一直活着直到下一个，因此请继续发布标题之后的发布。    meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[D]我的公司是否因避免深度学习而错过了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq9gtk/d_is_my_company_missing_out_by_avoiding_deep/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  免责声明：如果线性回归足够，则使用神经网络是没有意义的。  我在一家严格遵守数学，可解释的模型的公司工作。他们的立场是，诸如神经网络甚至梯度提升机之类的方法也是“黑框”。因此对决策不可靠。尽管我了解可解释性的重要性（尤其是在任务关键场景中），但我忍不住感觉这种方法过于限制。  我看到了这些方法的大量研究和行业采用，这让我感到奇怪：它们真的只是黑匣子，还是这是过时的观点？当然，随着这么多的人在这一领域工作，必须有一些方法可以洞悉这些模型并使他们更值得信赖。  我也错过了它们，因为我没有此类模型的工作经验？ 编辑：上下文是一级方程式！但是，种族是另一件事并支持工具。除非完全必要，否则我也会避免使用与种族严格相关的任何模型。我只是觉得这里有一种与上下文无关的偏见。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/datandre     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq9gtk/d_is_my_company_missing_out_by_avoiding_deep/</guid>
      <pubDate>Sat, 15 Feb 2025 19:42:42 GMT</pubDate>
    </item>
    <item>
      <title>[d]变压器最有前途的继任者是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipvau4/d_whats_the_most_promising_successor_to_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我所知道的是mamba，从效率的角度看（推理是线性而不是二次），但是Afaik没有人受过训练的大型模型。还有 xlstm  and  aaren 。  你们认为变压器最有前途的替代体系结构是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jsonathan     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipvau4/d_whats_the_most_promising_successor_to_the/</guid>
      <pubDate>Sat, 15 Feb 2025 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>