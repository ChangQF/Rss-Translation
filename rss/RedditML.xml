<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 25 Jun 2024 12:27:45 GMT</lastBuildDate>
    <item>
      <title>[D] 数据产品的 Medallion 方法：超越承诺的“黄金”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do4pfq/d_medallion_approach_to_data_products_beyond_the/</link>
      <description><![CDATA[值得信赖并不意味着经过认证：数据网格中不同程度的信任 在本文中，我们的客座作者 Francesco De Cassai 试图阐明关于数据资产被视为数据产品的信任程度的争论。在这篇富有洞察力的文章中，他谈到了：  “信任”的基本原理：可发现、可寻址、值得信赖、安全、可互操作和自我描述 不同程度的可信度 统治一切的数据政策  在文章中获得有关这些相关方面的详细观点和解释。  在此处阅读完整文章：https://moderndata101.substack.com/p/medallion-approach-to-data-products    提交人    /u/growth_man   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do4pfq/d_medallion_approach_to_data_products_beyond_the/</guid>
      <pubDate>Tue, 25 Jun 2024 12:24:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 需要帮助理解这篇论文。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do44r5/r_need_help_in_understanding_this_paper/</link>
      <description><![CDATA[我正在尝试理解论文“Instacart 的基于嵌入的杂货搜索模型”。我理解了预热和级联数据集的原因。我不明白共享编码器和双塔模型之间的区别。假设我有正向 &lt;查询，产品&gt; 匹配。它是如何训练并与负向匹配进行比较的。有人可以建议如何重新创建这篇论文吗？ https://preview.redd.it/i47q4rpxan8d1.png?width=1385&amp;format=png&amp;auto=webp&amp;s=19888b7803e52718f4b32d19f28b70744d51e01e    提交人    /u/Legitimate_Celery_69   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do44r5/r_need_help_in_understanding_this_paper/</guid>
      <pubDate>Tue, 25 Jun 2024 11:52:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关 LLM Tools 和 LangChain 的课程和认证的推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do3kxq/d_seeking_recommendations_for_courses_and/</link>
      <description><![CDATA[我正在寻找课程/认证，指导我如何使用 langchain、langsmith、langflow 等工具构建、管理、操作和部署 RAG 和基本提示用例，您能推荐什么吗？我找到了这些课程：https://www.udemy.com/course/langchain/?couponCode=ST18MT62524 https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/    提交人    /u/sickTheBest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do3kxq/d_seeking_recommendations_for_courses_and/</guid>
      <pubDate>Tue, 25 Jun 2024 11:20:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我对 GPT-2 和 BERT 进行了 135,000 次微调，以查看使用测试集中未标记的文本进行预训练是否公平</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do2g03/r_i_finetuned_gpt2_and_bert_135000_times_to_see/</link>
      <description><![CDATA[      TL;DR：似乎很公平。 每个人都知道，如果您想使用标记的测试数据进行评估，则对其进行训练是大忌。 但是，如果您对未标记的测试数据进行预训练，那么您仍然可以在评估期间使用这些数据吗？ 让我们对 25 个文本分类数据集、两个 LM（我们非常确定其预训练数据尚未受到污染）以及一些训练和测试观察数量的设置进行实验。 对于每个数据集，实验健全性检查对未标记文本（独立于测试集）进行预训练是否有帮助，即是否有效果可检测。称之为预训练提升。接下来，实验评估了使用测试集中的未标记文本（而不是未标记的独立文本）进行预训练的偏差。 将此称为评估偏差。 结果 ​ m=50 基于真实世界带注释的少量样本任务 (RAFT) 基准（https://arxiv.org/abs/2109.14076），该基准也包含了这个问题的灵感：“对于每个任务，我们发布一个包含 50 个示例的公共训练集和一个更大的未标记测试集。我们鼓励对未标记的示例进行无监督预训练……”。上面的分布是边际效应的分布：对 2 个 LM 类型、25 个分类任务及其子样本取平均值。 在这里，将“少数”的含义延伸到少样本中。我想看看结果会如何变化。还是一样。 平均而言，在每种情况下，对未标记的文本进行预训练显然都是有益的。尽管如此，没有证据表明存在不公平现象。评估偏差在 0 附近波动，并且微不足道。在任务级别，结果是一致的：在 25 项任务中，除了 2 项之外，预训练对所有任务都有好处，其中 12 项的评估偏差为正，13 项为负，绝对值始终小于 1%。 元分析 我还想看看 GPT-2 和 BERT 微调的少量基准测试有多稳定（不稳定）。在上面的实验中，通过从每个数据集中抽取最多 100 个子样本来揭示这种差异。（这种技术复制是标题中 135k 这个数字的原因。）如果实验只取一个子样本会怎样？这就是大多数小样本基准测试的有效做法。 事实证明，如果我们对 25 个数据集中的每个数据集抽样 500 个未标记文本、100 个分类示例和 500 个评估示例，则实验报告不可忽略的正偏差或负偏差的可能性为 47%，而不是我们从重复子样本中发现的接近 0 的偏差。从粗略的意义上讲，包括 25 个数据集（每个数据集有 1.1k 个观测值）似乎有很多数据。实际上，这并不比抛硬币好。 如今，人们对差异的认识越来越深刻（例如，https://arxiv.org/abs/2406.10229）。而且，与参数高效或基于提示的 LLM 方法相比，对 GPT-2 或 BERT 进行微调可能更不稳定。但我对在我的少样本研究中看到这种程度的不稳定感到很惊讶。 代码、数据、论文 以下是用于重现实验和分析的所有代码和数据，以及论文链接：https://github.com/kddubey/pretrain-on-test    提交人    /u/KD_A   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do2g03/r_i_finetuned_gpt2_and_bert_135000_times_to_see/</guid>
      <pubDate>Tue, 25 Jun 2024 10:07:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如今，亚马逊和沃尔玛等电子商务公司如何产生互补推荐（或经常一起购买）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnwfis/d_how_do_ecomm_companies_like_amazon_and_walmart/</link>
      <description><![CDATA[我最近开始研究推荐系统。我知道过去是使用一些统计算法（如 FP-Growth 和 Prod2Vec）来实现的。    提交人    /u/Abs0lute_Jeer0   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnwfis/d_how_do_ecomm_companies_like_amazon_and_walmart/</guid>
      <pubDate>Tue, 25 Jun 2024 03:30:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] 帮助使用一个简单的 CNN 进行国际象棋</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnvq1m/p_help_with_a_simple_cnn_for_chess/</link>
      <description><![CDATA[我正在尝试构建一个简单的 CNN 来预测国际象棋的下一步动作。我基本上收集了大量的游戏并从这些游戏中生成 (position, next_move) 的数据集。我目前使用大约 15 万个游戏，这会为这种格式的数据集创建超过 1200 万行。 我对这个项目有很多疑问，但我将从几个重要的问题开始。  由于我使用的是现有游戏，并且它们已经有了动作，上面的格式对我来说似乎很明显。但是，尝试使用 CNN 预测单个离散值似乎并不理想？我尝试做的事情能成功吗？如果我想将其转换为分布，国际象棋位置中可能的最大合法动作是 1040，因此输出将是 1040 个值的列表，其中 1039 个可能为 0。这是一种更好的方法吗？这似乎是对内存和计算的浪费。 我将每块板表示为 12x8x8 张量，因此它非常小。即使是 2048 个批次（可能太高了？）也几乎不会使用超过 1GB 的 VRAM。如果我使用像 32 这样的小批次大小，训练将花费太长时间，几乎不使用任何 GPU 资源。考虑到这种表示和 1200 多万个数据集大小，合理的折衷方案是什么？  任何建议或进一步说明都将不胜感激。    提交人    /u/gamesntech   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnvq1m/p_help_with_a_simple_cnn_for_chess/</guid>
      <pubDate>Tue, 25 Jun 2024 02:52:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 成绩评分：量化 LLM 在选项选择方面的表现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnpsap/r_grade_score_quantifying_llm_performance_in/</link>
      <description><![CDATA[  由    /u/FutureIsMine  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnpsap/r_grade_score_quantifying_llm_performance_in/</guid>
      <pubDate>Mon, 24 Jun 2024 22:03:58 GMT</pubDate>
    </item>
    <item>
      <title>当前最佳自托管翻译模型 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dno1ym/best_current_selfhosted_translation_models_d/</link>
      <description><![CDATA[我正在寻找最新的 ML 翻译和语言检测模型，最好是自托管的。遗憾的是，Libretranslate 无法生成与 Google Translate 或 Azure 相当的翻译，而 DeepL 太贵了。 典型用例：检测语言 -&gt; 将输入翻译成英语。    提交人    /u/AdaObvlada   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dno1ym/best_current_selfhosted_translation_models_d/</guid>
      <pubDate>Mon, 24 Jun 2024 20:50:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 为什么关于时间序列预测的联邦学习的高质量作品很少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnnlpm/r_why_there_are_few_highquality_works_about/</link>
      <description><![CDATA[我即将开始实习，我的导师要求我针对时间序列预测进行一些联邦学习方面的研究。与 cv 和 nlp 等其他任务相比，我发现来自高排名会议/期刊的高质量论文非常少。有人知道原因吗？主要的挑战是什么？    提交人    /u/by0724   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnnlpm/r_why_there_are_few_highquality_works_about/</guid>
      <pubDate>Mon, 24 Jun 2024 20:31:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 RAG 有疑问？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnngts/d_questions_about_rag/</link>
      <description><![CDATA[随着维数的增加，参考点、最大点和最小点之间的距离趋向于 0。我的问题是，当我们执行 RAG 时，我们会对高维数据执行，那么当距离变得无法区分时，我们如何收集最相似的点，除非使用非常高的阈值。最好这样做：  获取源文档的嵌入 减少嵌入 使用降维器计算查询的定位 然后使用它来确定最近的点  降维    提交人    /u/spx416   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnngts/d_questions_about_rag/</guid>
      <pubDate>Mon, 24 Jun 2024 20:26:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 建议在我的数据库中部署模型的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnmwwc/p_suggested_approach_for_deploying_my_model_in_my/</link>
      <description><![CDATA[大家好， 我希望部署我的推荐模型，该模型可以为某些传输方式推荐运营商。我正在通过 PyTorch 和 TensorFlow 开发这个模型。 我的问题是，如何正确将此模型投入生产？该模型将每隔一个月的 1 号运行一次。    提交人    /u/applethatfell   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnmwwc/p_suggested_approach_for_deploying_my_model_in_my/</guid>
      <pubDate>Mon, 24 Jun 2024 20:03:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 模型合并——您的看法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnm1m0/d_model_merging_whats_your_take/</link>
      <description><![CDATA[我一直在阅读有关模型合并及其可实现的出色性能的文章。我喜欢任务算法之类的方法，但 TIES 和 DARE 似乎更受欢迎。同时，其中一些解决方案似乎非常具有启发性。 您的看法是什么？有直接经验吗？我猜没有采用批判性观点的调查/教程，但如果你知道，请链接它。    提交人    /u/gized00   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnm1m0/d_model_merging_whats_your_take/</guid>
      <pubDate>Mon, 24 Jun 2024 19:27:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 通过哪个目标我可以得到更理想的准确率-召回率阈值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnhwyn/d_with_which_objective_do_i_get_a_more_desirable/</link>
      <description><![CDATA[      更高的auc-roc，但不理想 更低的auc-roc，但可取的 我有一个不平衡的二元分类数据集（60/40）。但是，我确实应用了类平衡（使用 BinaryFocalCrossentropy）。对于调整过程，我尝试优化 AUC-PR 和 AUC-ROC，但不断得到这些结果，如图像中所示，其中第一张图像的分数更高，但更不理想。这里对于选择客观指标的建议是什么？我会使用 F1 分数，但我真的不关心特定阈值下的性能，只要它在某个阈值下表现良好即可。    提交人    /u/blearx   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnhwyn/d_with_which_objective_do_i_get_a_more_desirable/</guid>
      <pubDate>Mon, 24 Jun 2024 16:36:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些大学和研究中心专注于对抗性机器学习（尤其是在德国）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnctew/d_which_universities_and_research_centers_are/</link>
      <description><![CDATA[大家好，我很好奇对抗性学习的核心研究进展。查看出版物，我确实看到了来自不同组织的几篇论文，但很少看到一个组织宣传他们专注于对抗性学习领域。特别是德国的大学和研究所。    提交人    /u/i_sanitize_my_hands   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnctew/d_which_universities_and_research_centers_are/</guid>
      <pubDate>Mon, 24 Jun 2024 12:56:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>