<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Wed, 03 Apr 2024 18:16:25 GMT</lastBuildDate>
    <item>
      <title>[D] 预测执行器运动的最佳算法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1buzgmn/d_what_is_the_best_algorithm_for_predicting/</link>
      <description><![CDATA[我有一个执行器，我需要从位置 800 到 4000 之间的某个位置移动，我们可以要求它移动到某个位置，比如 2451，它通常会以一定的偏移量到达那里，就像它可能会到达 2445 一样，执行器上也会施加一个力，并且该力会根据其所压的物体以及压入压力机的深度而发生很大变化，我们可以访问在我们要求它移动到某个地方并施加在其上的力之后，我认为这是一个很好的深度学习算法任务，可以解决各种模式中的因素并做出良好的猜测。我们可以采取几个步骤来达到这一点，并在这些步骤中获取当前的位置和力量，但我们希望奖励以更少的步骤到达那里，因此模型可能会预测并超调到 2455，并让我们一步达到 2451，起初我想到的是 q 深度学习，但我相信它只需要一组 1 或 0，我研究的其他模型似乎是基于已经获取的数据分为训练和测试数据，这并不理想由于我们没有积压的数据，我希望模型能够通过在 800-4000 范围内设置随机位置并让它这样学习来学习，有人可以指出我正确的方向吗？   由   提交 /u/AnElectricfEel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1buzgmn/d_what_is_the_best_algorithm_for_predicting/</guid>
      <pubDate>Wed, 03 Apr 2024 18:02:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 矢量数据库 - elasticsearch 插件与用于人工智能驱动的发票处理应用程序的 weaviate</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1buyoji/d_vector_db_elasticsearch_plugin_vs_weaviate_for/</link>
      <description><![CDATA[因此，我正在全力开发本地、成本高效且由人工智能支持的发票分类/处理解决方案。目前，它非常适合我们的业务用例，但我计划尽快抽象并发布它（如果您想进入等待名单，请私信）。 我的问题是：我计划使用 RAG 模型来增强自然语言问题的结果。 我首先考虑使用 elasticsearch 及其矢量插件，但现在正在考虑使用 weaviate，因为它看起来更轻量级并且更适合混合对我来说听起来很理想的搜索模型。 这里有人有 weaviate 的经验吗？你更喜欢elasticsearch吗？我很想听听您对此的想法。   由   提交 /u/ZealousidealCycle915   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1buyoji/d_vector_db_elasticsearch_plugin_vs_weaviate_for/</guid>
      <pubDate>Wed, 03 Apr 2024 17:32:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 时间序列预测项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1buxr01/p_time_series_forecasting_project/</link>
      <description><![CDATA[我正在尝试预测时间序列信号。 我的信号有 2 个特征，我将其分解为具有 10 + 10 个部分的新信号。 然后我的方法是将大小为 20 的输入输入 LSTM 并获得输出大小 20。 所以我预测所有这些分解的部分。最后一步是通过相应地添加这些预测来重建原始信号。  我现在的主要问题是我无法让我的网络具有任何像样的性能（损失没有减少），所以我想知道我的方法的哪些部分是错误的。 &lt; p&gt;欢迎任何提示，因为我还很新   由   提交/u/NicoRobinFleur  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1buxr01/p_time_series_forecasting_project/</guid>
      <pubDate>Wed, 03 Apr 2024 16:57:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 多模型法学硕士铸造厂</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1buwko0/d_multi_model_llm_foundry/</link>
      <description><![CDATA[在Leeroo，我们相信企业和开发者应该对其人工智能模型拥有可靠的所有权。 这种定制使企业能够控制和管理可预测性，使他们能够将人工智能功能与其特定要求结合起来，同时有效降低隐私和安全风险。 🚀 我们通过多模型 LLM 构建平台引领前进的道路。 访问我们的 Huggingface 博客：https://huggingface.co/blog/alirezamsh/leeroo-multi-model-system    由   提交/u/Ok_Method8290   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1buwko0/d_multi_model_llm_foundry/</guid>
      <pubDate>Wed, 03 Apr 2024 16:11:42 GMT</pubDate>
    </item>
    <item>
      <title>与 NL to NL 相比，您认为法学硕士在 NL to Code 和 NL to SQL 任务中的表现如何？ [讨论][D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1buw7uk/what_do_you_think_about_performances_of_llms_in/</link>
      <description><![CDATA[在过去的几天里，我一直在研究大型语言模型如何在 NL to Code 和主要是 NL to SQL 任务中执行。我想从我们社区的人们和从业者那里听到更多关于这个问题的信息。  这种兴趣主要源于对使用法学硕士进行编码的好奇心。我想听听人们关于使用法学硕士进行编码的经历。我想知道您对他们的表演有什么感受吗？ - 在准确性、效率等方面？您尝试过哪些模型来完成这项任务？您认为哪种模型最有效？    由   提交 /u/Traditional-Lynx-684   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1buw7uk/what_do_you_think_about_performances_of_llms_in/</guid>
      <pubDate>Wed, 03 Apr 2024 15:58:06 GMT</pubDate>
    </item>
    <item>
      <title>[D]使用目标输入对时间序列上的变压器数据进行预处理的正确方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1buun07/dcorrect_way_to_preprocess_data_for_a_transformer/</link>
      <description><![CDATA[大家好，这涉及数据的预处理步骤，我仍然对如何处理这个问题感到有点困惑。 例如，我正在根据一个人的饮食模式训练变压器。假设他们总共吃了 21 顿饭。最后，我想测试他们的第 21 顿饭。 在训练期间，我们的框架是在某个时刻，模型必须预测“某人 x 吃‘意大利面’作为他们的第 8 顿饭”餐”，这意味着模型将被要求专门在第 8 个标记处进行预测。 作为训练输入，只在第 1 到第 7 个标记中喂食不是正确的吗？整个 20 顿饭的模型会给模型提供有关第 8 个代币的未来信息吗？因为注意力机制的工作原理是更新彼此自己的信息。 因此，如果我必须训练它根据序列 2 和 20 进行预测，这意味着我必须将所有这些特定序列分块 19 次，其中每个序列作为训练输入不能包含未来的标记？   由   提交/u/parz01000101  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1buun07/dcorrect_way_to_preprocess_data_for_a_transformer/</guid>
      <pubDate>Wed, 03 Apr 2024 14:54:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 增加耳语吞吐量的方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1butp5q/d_way_to_increase_throughput_of_whisper/</link>
      <description><![CDATA[转录短音频时如何优化耳语的吞吐量？ （可能几秒钟）faster-whisper 擅长延迟，但无法转录多个文件或数组。   由   提交/u/lionsheep24   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1butp5q/d_way_to_increase_throughput_of_whisper/</guid>
      <pubDate>Wed, 03 Apr 2024 14:15:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 只是美化了即时工程吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1busp41/d_is_rag_just_glorified_prompt_engineering/</link>
      <description><![CDATA[您会收到提示、IR 相关文档，将它们发送到提示，然后 LLM 会生成响应。我们刚刚设计了提示以提供更多信息。   由   提交 /u/RiseWarm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1busp41/d_is_rag_just_glorified_prompt_engineering/</guid>
      <pubDate>Wed, 03 Apr 2024 13:32:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 实施基本 NLP 任务的资源/帮助？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1burfqi/p_resourceshelp_on_implementing_basic_nlp_tasks/</link>
      <description><![CDATA[大家好， 在我的深度学习考试中，我被要求实现特定版本的 Transformer 并在任务中对其进行测试与论文中显示的类似。该模型是类似 BERT 的架构。我发现实现模型的架构非常容易，但我对使用自然语言的基础知识感到非常困惑。仅举一个例子：我的预训练仅包含一项 MLM 任务，但我真的不知道如何从文本到模型的可用输入。我不是在谈论代币化背后的理论，这一点很明确，我说的是从头开始真正实现这些事情。我应该如何读取数据集中的文本？当我的数据集太大以至于无法将其加载到内存中时该怎么办？我的变压器输出应该是多少？本案中损失是如何落实的？我应该从语料库中随机选择文本片段还是需要从句子的开头开始？这些只是我找不到答案的一些问题。我还检查了在线实现，但很难理解，因为每个人做事的方式都不同。另外，我不能只使用 Hugginface，因为在考试时我被要求从头开始做这些事情。 您对我在哪里可以找到这些信息或者我应该如何解决问题有什么建议吗？    由   提交 /u/BossBigSword   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1burfqi/p_resourceshelp_on_implementing_basic_nlp_tasks/</guid>
      <pubDate>Wed, 03 Apr 2024 12:32:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过预消除使 KNN 更加高效</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bupi0p/p_making_knn_more_efficient_with_preelimination/</link>
      <description><![CDATA[大家好，我一直在从事一个小项目，我希望获得一些完全诚实的反馈。 KNN 是一种非常强大的算法，但不幸的是，它的效率也非常低，并且运行起来非常耗费资源。我一直在研究一个项目，根据一些基本测试，该项目平均比普通 KNN 快 20% 左右，而且质量几乎没有下降。您可以在此处查看 github 存储库： https://github.com/jakeSteinburger/peKNN&lt; /p&gt; 我还为此写了一篇小型论文，链接在存储库上。如果代码有点混乱，我很抱歉，但除此之外，我真的很喜欢你完全诚实的反馈（我知道 Reddit 很擅长这一点）。提前致谢！   由   提交 /u/JakeStBu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bupi0p/p_making_knn_more_efficient_with_preelimination/</guid>
      <pubDate>Wed, 03 Apr 2024 10:47:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT-3.5-Turbo 很可能与 Mixtral-8x7B 大小相同！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1budlbc/d_gpt35turbo_is_most_likely_the_same_size_as/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1budlbc/d_gpt35turbo_is_most_likely_the_same_size_as/</guid>
      <pubDate>Tue, 02 Apr 2024 23:35:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于那些考虑购买 AMD GPU 的人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bu1sue/d_for_those_who_consider_buying_amd_gpus/</link>
      <description><![CDATA[https:// www.reddit.com/r/Amd/comments/1bsjm5a/letter_to_amd_ongoing_amd/ 认为此信息可能会帮助您做出决定。 ​&lt; /p&gt; P.S.就连 George Hotz 也不再建议购买 7900 XTX，转而使用 NVIDIA，因为驱动程序不稳定。来自最新的直播： https://www.youtube.com/ watch?v=Y-0yZ1AHb0s&amp;t=15890s   由   提交/u/YYY_333  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bu1sue/d_for_those_who_consider_buying_amd_gpus/</guid>
      <pubDate>Tue, 02 Apr 2024 15:37:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] SWE-agent：开源编码代理，在 SWE-bench 上取得 12.29% 的成绩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btwl37/p_sweagent_an_open_source_coding_agent_that/</link>
      <description><![CDATA[我们刚刚公开了 SWE-agent，它是一个开源代理，可以将任何 GitHub 问题转化为拉取请求，在 SWE-bench 上实现了 12.29% （与 Devin 使用的基准相同）。 ​ https ://github.com/princeton-nlp/swe-agent ​ 过去 6 个月我们一直在努力解决这个问题。构建运行良好的代理比看起来要困难得多 - 我们的存储库概述了我们学到和发现的内容。我们很快就会有预印本。  如果您有任何问题，我们会在这个帖子中闲逛   由   提交 /u/ofirpress   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btwl37/p_sweagent_an_open_source_coding_agent_that/</guid>
      <pubDate>Tue, 02 Apr 2024 11:42:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士对该领域弊大于利？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btuizd/d_llms_causing_more_harm_than_good_for_the_field/</link>
      <description><![CDATA[这篇文章可能有点咆哮，但我觉得最近越来越多的人和我分享这种观点。如果您费心阅读整篇文章，请随时分享您对此的感受。 当 OpenAI 将人工智能知识带入日常生活中时，我一开始对此持乐观态度。在美国以外的小国家，企业之前对人工智能非常犹豫，他们认为这感觉很遥远，只有大FANG公司才能做到。现在？好多了。每个人都对此感兴趣，并想知道如何在自己的业务中使用人工智能。这太棒了！ 在 ChatGPT 之前，当人们问我从事什么工作时，我回答“机器学习/人工智能”他们不知道，也几乎没有进一步的兴趣（除非他们是技术人员） ChatGPT 时代，当我被问到同样的问题时，我会得到“哦，你用聊天机器人？” 我想，这是朝着正确方向迈出的一步。我对法学硕士并没有那么大的兴趣，并且有幸专门从事与视觉相关的任务，不像其他一些不得不转向全职与法学硕士一起工作的人。 但是，现在我认为这对这个领域的弊大于利。让我分享一些我的观察，但在此之前我想强调一下，我绝不试图以任何方式把关人工智能领域。 我已经获得了“ChatGPT”的工作机会专家”，这到底是什么意思？我坚信，像这样的工作并不能真正发挥真正的职能，而更像是一种“超级火车”工作，而不是完全可以发挥任何职能的工作。 在过去的几年里，我已经我参加了欧洲各地的一些会议，其中一个是上周举行的，这些会议通常都很棒，具有良好的技术深度，也是数据科学家/机器学习工程师建立联系、分享想法和协作的场所。然而，现在会谈、深度、网络都发生了巨大的变化。公司使用人工智能来做很酷的事情和挑战极限不再是新鲜的、令人兴奋的方式，所有的 GAN 和 LLM 都具有表面知识。少数“老派”类型演讲被发送到小房间的第二轨道 小组讨论充满了没有人工智能基础知识的哲学家，谈论法学硕士是否会变得有知觉。数据科学家/机器学习工程师的空间在学术会议之外很快就消失了，被当前的 hypetrain 挤出了空间。hypetrain 的传播者还承诺用 LLM 和 GAN 创造奇迹和黄金，但他们永远不会实现的奇迹。当投资者意识到法学硕士无法实现这些奇迹时，他们会立即对人工智能未来项目的资金更加犹豫，让我们再次陷入人工智能冬天。 编辑：P.S.我还在这个 reddit 上看到更多的人自称是“生成人工智能专家”。但当深入研究时，就会发现它们只是“好的提示者”。并且对人工智能或生成人工智能的实际领域没有真正的知识、专业知识或兴趣。   由   提交/u/Stevens97  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btuizd/d_llms_causing_more_harm_than_good_for_the_field/</guid>
      <pubDate>Tue, 02 Apr 2024 09:37:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>