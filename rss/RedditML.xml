<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 23 Jan 2024 18:17:38 GMT</lastBuildDate>
    <item>
      <title>[R] GARField：用辐射场对任何东西进行分组</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19duk16/r_garfield_group_anything_with_radiance_fields/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.09419 代码：https://github .com/chungmin99/garfield 项目页面：https://www.garfield.com/chungmin99/garfield 项目页面： garfield.studio/ 摘要：  由于可以分解的多个粒度级别，分组本质上是不明确的一个场景——挖掘机的轮子应该被视为独立的还是整体的一部分？我们提出了用辐射场对任何东西进行分组 (GARField)，这是一种将 3D 场景从摆好姿势的图像输入分解为具有语义意义的组的层次结构的方法。为此，我们通过物理尺度来接受群体模糊性：通过优化尺度条件的 3D 亲和力特征场，世界上的一个点可以属于不同大小的不同群体。我们从 Segment Anything (SAM) 提供的一组 2D 掩模中以尊重从粗到细的层次结构的方式优化该字段，使用比例来一致地融合来自不同视点的冲突掩模。从这个字段中，我们可以通过自动树构建或用户交互导出可能分组的层次结构。我们在各种野外场景中评估了 GARField，发现它可以有效地提取多个级别的组：对象集群、对象和各种子部分。 GARField 本质上代表多视图一致分组，并产生比输入 SAM 掩模更高保真度的组。 GARField 的分层分组可能具有令人兴奋的下游应用，例如 3D 资产提取或动态场景理解。请参阅项目网站 https://www.garfield.studio/    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19duk16/r_garfield_group_anything_with_radiance_fields/</guid>
      <pubDate>Tue, 23 Jan 2024 18:03:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 所有这些 AI 服务如何能够负担每月 5/10/20 美元的费用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19duab0/d_how_all_these_ai_services_can_afford_51020_subs/</link>
      <description><![CDATA[各种人工智能服务（从语音识别到 OCR 和艺术生成）如何嵌入新数据，以如此低的成本提供其功能？使用 GPT-4 API 之类的东西很快就会花费 10 美元，这对于其他模型来说也是类似的。即使在本地运行 LLaMA 2 这样的东西也会产生巨大的成本。我很好奇这些服务在运营这些大型模型时采用的经济策略来维持较低的月费。   由   提交/u/Numerous_Bed9323  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19duab0/d_how_all_these_ai_services_can_afford_51020_subs/</guid>
      <pubDate>Tue, 23 Jan 2024 17:53:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 3 年内发表 130 篇论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dsyut/d_how_does_someone_publish_130_papers_in_3_years/</link>
      <description><![CDATA[我偶然发现了一位荷兰机器学习研究员 Max Welling，并根据他的Google Scholar 他总共合着了约 500 篇论文，在过去 3 年里共撰写了 130 篇！ 怎么样这甚至有可能吗？作为一个部门的负责人，尽管没有做很多发表在出版物上的工作，但在该部门制作的大部分作品上都有你的名字，这是一种额外的福利吗？否则我真的不知道如何做到......   由   提交 /u/Miss-Quiz-Mis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dsyut/d_how_does_someone_publish_130_papers_in_3_years/</guid>
      <pubDate>Tue, 23 Jan 2024 16:54:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于为论文创建易于复制的图形的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19drqkw/p_tool_for_creating_easily_reproducible_figures/</link>
      <description><![CDATA[我想分享一个小的 Python 包我为论文创建可重复的数字而写的。这主要适用于使用 Python 进行数据分析或研究项目的人们（带有可选的 LaTeX 支持），所以我想我会在这里分享，因为 ML 研究是我的主要用例（也许你们中的那些在接下来的 ICML 截止日期前工作的人）周将受益:)）。 基本思想是，它是一个使用 matplotlib/seaborn 创建样式图形的工具，以便快速轻松地重新生成图形。用于生成图形的代码保存到可编辑和重新运行的自动生成的脚本中。我发现它对于在撰写论文时进行小幅编辑或返回旧项目并轻松访问用于创建论文图表的数据和代码非常有用。 该工具易于使用，仅依赖于 matplotlib，但我还提供了一个辅助函数，用于使用 seaborn 和 LaTeX 设计图形样式。   由   提交 /u/drcopus   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19drqkw/p_tool_for_creating_easily_reproducible_figures/</guid>
      <pubDate>Tue, 23 Jan 2024 16:03:14 GMT</pubDate>
    </item>
    <item>
      <title>寻求见解：构建用户友好的无代码机器学习平台 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dqnye/seeking_insights_building_a_userfriendly_nocode/</link>
      <description><![CDATA[主页：gogoml.com  演示：demo.gogoml.com  大家好， 我现在开发一个无代码机器学习平台，该平台不仅免费，而且非常用户友好。它设计用于处理表格数据以创建回归和分类模型。虽然我知道市场上有各种类似的平台，但我的目标是创造一些非常容易访问的平台。我设想一个如此直观的平台，即使没有数据科学背景的个人也可以轻松利用其功能来获取自己的利益。 我正在向这个知识渊博的社区寻求一些指导。具体来说，我有兴趣学习您与非技术用户的经验。您建议在这样的平台中加入哪些特性或功能，以使其真正对非技术受众有利？如果您能提供任何见解或建议，我们将不胜感激，   由   提交 /u/htcheuk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dqnye/seeking_insights_building_a_userfriendly_nocode/</guid>
      <pubDate>Tue, 23 Jan 2024 15:16:20 GMT</pubDate>
    </item>
    <item>
      <title>[N] Meta 开源了经过 450 万小时预训练的 wav2vec2 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dptmp/n_meta_opensourced_a_wav2vec2_model_pretrained_on/</link>
      <description><![CDATA[一个月前，Meta AI 发布了 W2V-Bert，这是其 Seamless 模型的构建模块之一。  它已经过 450 万小时的未标记音频数据的预训练，涵盖超过 143 种语言。  优点：  实现低资源微调 比 Whisper 更快、更轻 MIT 许可证 可以针对其他音频任务进行微调  缺点：  基于 CTC，因此适用于标准化转录 &lt; li&gt;使用前需要微调  资源：  原始仓库：https://github.com/facebookresearch/seamless_communication?tab=readme-ov-file#whats-new 变形金刚文档：https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2 -bert 蒙古语博客文章的 ASR 微调：https:// Huggingface.co/blog/fine-tune-w2v2-bert    由   提交 /u/Sufficient-Tennis189   /u/Sufficient-Tennis189  reddit.com/r/MachineLearning/comments/19dptmp/n_meta_opensourced_a_wav2vec2_model_pretrained_on/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dptmp/n_meta_opensourced_a_wav2vec2_model_pretrained_on/</guid>
      <pubDate>Tue, 23 Jan 2024 14:37:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何绕过无监督表示学习中的丑小鸭定理？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dp5t2/d_how_can_we_bypass_the_ugly_duckling_theorem_in/</link>
      <description><![CDATA[丑小鸭 我最近了解了丑小鸭定理，基本上说，如果没有某种偏差，分类是不可能的。 更具体地说，给定 n 个对象的数据集，有 2n&lt; /sup&gt; 可能的分组，每个对象都会像任何其他对象一样频繁地与另一个对象分组，因此必须对可能的属性进行一些权重，必须选择一些偏差，以便对对象进行分类有意义。 在无监督学习的背景下，在我看来，这意味着不存在通用的方法，因为所选算法的性能实际上取决于手头任务的偏差的相关性。 &lt;传统的无监督技术经常在并不总是非常明显的附加假设中引入这种偏差。例如，k 均值聚类假设 1. 您有一个“接近度”度量； 2. 对象（度量）之间的聚类具有相同的球面方差。但毕竟，即使数据集中满足了 k-means 的假设，谁说 k-means 形成的自然群体就是数据科学家正在寻找的答案？ 无监督表示学习 但是，现在让我们关注无监督表示学习的背景，是否有可能找到对一大类可能的下游任务有用的偏差？ 例如，很明显，学习到的表示不应该是恒定的，也就是说，它不应该将相同的特征归因于所有点。如果表示是恒定的，那么就没有希望对数据集进行任何分类，但我们可以合理地期望所选数据集具有足够的信息，至少可以开始学习我们想要的分类。更一般地说，假设学习的表示应该保留有关输入的最大信息似乎是合理的，因此它应该能够区分所有数据点。 这指向自动编码器，因为它们这些模型试图保留有关输入的所有信息，因为它们经过训练以尽可能最好地重建有问题的输入。然而，AE 在数据在潜在空间中的表示方面仅受到较弱的约束。模型的架构和潜在的大小是影响表示的两个主要因素。这个想法是，潜在尺寸较小的 AE 会更多地压缩数据，但这可能并不总是正确的，AE 可能会找到一种非常非线性的表示，完全适合一个或几个潜在维度中的所有数据集。  我对此的看法 我的直觉是应该限制表示，以便潜在特征在某种程度上“容易”呈现。用于下游任务，无论是什么合理的任务。也许该表示确实应该是“最压缩的形式”。正如自动编码器的常识似乎所推动的那样。我将这种智慧解释如下：“如果某个特征在数据中很常见，那么它可能是对该数据的分类器有用的特征”。 （因为一个非常常见的功能可能会用于压缩数据）。 压缩似乎不是一个绕过丑小鸭定理的任意原则，但可能存在其他原则。然而，它假设压缩形式在某种程度上“更容易”。阅读分类器，这可能是一个非常有力的假设。 你同意这一点吗？你还有其他想法吗？   由   提交 /u/Cosmolithe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dp5t2/d_how_can_we_bypass_the_ugly_duckling_theorem_in/</guid>
      <pubDate>Tue, 23 Jan 2024 14:05:22 GMT</pubDate>
    </item>
    <item>
      <title>[N]ICLR2024的学习理论家，我感同身受！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dnolo/n_learning_theorists_of_iclr2024_i_feel_you/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dnolo/n_learning_theorists_of_iclr2024_i_feel_you/</guid>
      <pubDate>Tue, 23 Jan 2024 12:49:17 GMT</pubDate>
    </item>
    <item>
      <title>[N] PRILoRA：修剪和等级增加的低等级适应</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/</link>
      <description><![CDATA[PRILoRA 的核心概念涉及背离为模型中的每一层分配统一的低等级的传统做法。相反，他们提出了一种跨层线性增加的动态分配。这确保了更接近输入的层接收较低的排名，而较深的层被分配更高的排名。例如，在基于 DeBERTaV3 的模型中，他们没有为每一层统一分配 8 的等级，而是从第一层的 4 等级开始，逐步提高，直到最深层的等级为 12。这种微妙的分配，平均为 8，产生优异的结果。他们将这种改进归因于这样的观察：语言模型 (LLM) 中的较低层处理更直接和语法的抽象，而更深的层处理语义和复杂元素。在对特定任务进行微调期间，对深层的关注变得至关重要，因为较低层以类似的方式处理单词，但输出需要与较高层表示保持一致。通过区分各层之间的资源分配，它们获得了增强的结果。 此外，它们的微调过程包括根据考虑输入的绝对权重值和累积统计数据的标准重置 A 矩阵中的特定权重分布到层。这种方法针对不太重要的权重，从而提高模型性能。 当应用于基于 DeBERTaV3 的模型时，所提出的方法在 GLUE 基准上优于最先进的方法 (SOTA)。  p&gt; 要全面了解该工作，请参阅全文：https://arxiv.org/pdf/ 2401.11316.pdf   由   提交/u/generous-blessing  /u/generous-blessing  reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/</guid>
      <pubDate>Tue, 23 Jan 2024 09:06:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] 状态空间模型：一种现代方法 作者：Kevin Murphy、Scott Linderman 等人。 （未完待续）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dg8f0/p_state_space_models_a_modern_approach_by_kevin/</link>
      <description><![CDATA[ 这是一本关于状态空间模型 (SSM) 的交互式教科书，使用 JAX Python 库。其他书籍中涵盖了某些内容，例如 [Sar13] 和 [Mur23]。然而，我们会更详细地讨论如何利用自动微分和并行计算方面的最新进展，在“现代”计算环境中有效地实现各种算法。  在线阅读   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dg8f0/p_state_space_models_a_modern_approach_by_kevin/</guid>
      <pubDate>Tue, 23 Jan 2024 04:42:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么研究生或博士后所做的工作在简历上被低估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19df2gx/d_why_is_work_done_as_a_graduate_student_or/</link>
      <description><![CDATA[学术申请行业职位，在我的特定领域拥有新颖的数据分析和机器学习应用的强大出版记录。可以高度转化为工业的技能。对于任何在 R1 完成博士学位的人来说，您都了解与博士学位相关的无形资产。 我被告知并得到普遍的感觉，即使我们已经证明（发布）了我们领导项目的能力从概念到产品，并展示我们在 PI、政府机构和其他行业合作伙伴的压力下工作无数小时的能力，我们的经验价值较低或仅被视为学校作业而不是“真实”经验。 有人知道为什么吗？ 我们如何更好地向招聘人员传达我们的无形和有形价值？   由   提交/u/dcoceans11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19df2gx/d_why_is_work_done_as_a_graduate_student_or/</guid>
      <pubDate>Tue, 23 Jan 2024 03:38:40 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以在其回复中隐藏任意不可检测的信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</link>
      <description><![CDATA[ 由   提交/u/LuvIsOurResistance  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</guid>
      <pubDate>Mon, 22 Jan 2024 22:32:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新理论表明聊天机器人可以理解文本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</link>
      <description><![CDATA[文章链接：https://www.quantamagazine.org/new-theory-suggests-chatbots-can-understand-text-20240122/ 链接到论文 1：https://arxiv.org/abs/2307.15936 摘要：  当今人工智能产品的一个主要驱动力是，当参数集和训练语料库扩大时，语言模型中就会出现新的技能。人们对这种现象知之甚少，并且通过基于梯度的训练的数学分析来进行机械解释似乎很困难。当前的论文采用了不同的方法，使用著名的（和经验的）法学硕士缩放定律和简单的统计框架来分析涌现。贡献包括： (a) 一个统计框架，将法学硕士的交叉熵损失与语言任务的基本技能能力联系起来。 (b) 数学分析表明，缩放定律暗示了一种强烈的归纳偏差形式，使得预训练模型能够非常有效地学习。我们非正式地将其称为“弹弓泛化”，因为天真地认为它似乎给出了违反通常泛化理论的技能的能力水平。 (c) 弹弓泛化的一个关键例子，执行涉及 k 元组技能的任务的能力基本上以与基本技能本身的能力相同的规模和速度出现。  Link论文 2：https://arxiv.org/abs/2310.17567 摘要：  随着法学硕士的角色从语言统计建模转变为通用人工智能代理，法学硕士的评估应该如何改变？可以说，人工智能代理的一项关键能力是根据需要灵活组合其所学的基本技能。结合技能的能力在（人类）教育学以及关于涌现现象的论文中发挥着重要作用（Arora &amp; Goyal，2023）。这项工作引入了 Skill-Mix，这是一种衡量组合技能能力的新评估。使用 N 个技能的列表，评估者重复选择 k 个技能的随机子集，并要求法学硕士生成结合该技能子集的文本。由于子集的数量像 Nk 一样增长，因此即使是适度的 k，此评估也很有可能要求法学硕士生成与训练集中的任何文本显着不同的文本。该论文开发了一种方法，用于 (a) 设计和管理此类评估，以及 (b) 使用 GPT-4 以及开放的 LLaMA-2 70B 模型对结果进行自动分级（加上人工抽查）。管理流行聊天机器人的一个版本所得到的结果虽然总体上符合之前的预期，但也包含了令人惊讶的结果。模型能力之间存在相当大的差异，而这些差异并没有通过它们在流行的 LLM 排行榜上的排名来体现（“临时抱佛脚排行榜”）。此外，简单的概率计算表明GPT-4在k＝5上的合理性能暗示超越“随机鹦鹉”性能。行为（Bender 等人，2021），即它以训练期间未曾见过的方式组合技能。我们概述了该方法如何形成基于技能组合的生态系统，对未来模型的人工智能功能进行开放评估。    由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</guid>
      <pubDate>Mon, 22 Jan 2024 21:54:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前理论机器学习作为一个领域有什么意义吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</link>
      <description><![CDATA[随着 SOTA 架构不断变化的极快速度，可能的 DL 技术（正则化、所有不同的激活和损失函数）的多样性如下：以及对可解释人工智能相对退居二线的担忧，现在从事理论机器学习工作有什么用处吗？ 大多数 SOTA 架构似乎只是大规模扩展的高级猜测和检查，而且它确实有效就基准性能而言，我们是否需要 ML/DL 理论？   由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</guid>
      <pubDate>Mon, 22 Jan 2024 20:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>