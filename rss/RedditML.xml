<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 23 Apr 2024 15:13:32 GMT</lastBuildDate>
    <item>
      <title>[D]超参数调整后准确度分数和其他测量值发生巨大变化。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb4yba/ddrastic_change_in_the_accuracy_score_and_other/</link>
      <description><![CDATA[嘿，我目前正在做恶意软件分类（恶意软件，良性）。使用朴素贝叶斯（伯努利）此时准确度为 67。之后调音后直接上升100。这正常吗？我使用 IQR 进行异常值去除，并使用相关性进行特征选择。   由   提交 /u/Saheenus   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb4yba/ddrastic_change_in_the_accuracy_score_and_other/</guid>
      <pubDate>Tue, 23 Apr 2024 13:41:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何将 LLaMA 3 部署到生产中以及硬件要求</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb3ge1/d_how_to_and_deploy_llama_3_into_production_and/</link>
      <description><![CDATA[许多人都在尝试安装和部署自己的 LLaMA 3 模型，因此这里是我刚刚制作的教程，展示了如何在 AWS EC2 上部署 LLaMA 3实例：  https://nlpcloud.com/how-to-install-and-deploy-llama-3-into-product.html 部署 LLaMA 3 8B 相当容易，但部署 LLaMA 3 70B 则很困难另一个野兽。考虑到所需的 VRAM 量，您可能需要配置多个 GPU 并使用 vLLM 等专用推理服务器，以便将模型拆分到多个 GPU 上。 LLaMA 3 8B 需要大约 16GB 的磁盘空间，并且FP16 中 20GB VRAM（GPU 内存）。至于LLaMA 3 70B，它需要大约140GB的磁盘空间和160GB的FP16 VRAM。 我希望它有用，如果您有疑问，请随时询问！ 朱利安   由   提交/u/juliensalinas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb3ge1/d_how_to_and_deploy_llama_3_into_production_and/</guid>
      <pubDate>Tue, 23 Apr 2024 12:33:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 学生语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb298q/d_language_model_for_students/</link>
      <description><![CDATA[社区您好， 我正在准备一场关于语言模型的讲座，其中涉及大量 Python 实践。我正在尝试 Llama 3 8b，但它回答提示的速度似乎非常慢。我有一台配备现代 I7 处理器和 32GB RAM 的笔记本电脑。我认为我的学生有一些不太强大的东西，我不希望他们花几个小时只是为了提示。  那么你知道有一种模型既相当快又不会牺牲太多性能吗？   由   提交/u/mbungee  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb298q/d_language_model_for_students/</guid>
      <pubDate>Tue, 23 Apr 2024 11:31:59 GMT</pubDate>
    </item>
    <item>
      <title>机器人与人工智能[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb28us/robotics_and_ai_d/</link>
      <description><![CDATA[您好！我研究过机器人工程，我的人工智能方法主要集中在计算机视觉上。我对这个领域非常感兴趣，当然，现在我每天都在工作和个人项目中使用 GPT-4。 我明年将开始攻读人工智能硕士学位，在硕士申请的求职信中，我想讨论结合机器人技术和人工智能的潜在研究主题。 我的第一选择是使用强化学习进行导航和路径规划。我还对视觉转换器在视觉和语义 SLAM 以及基于深度学习的特征提取器中的潜在应用感兴趣。 大公司通过多模态转换器所取得的成就也给我留下了深刻的印象像AI这样的人形机器人，尽管我知道这些项目可能只对这样的组织可行。 我很想听听您对机器人和AI趋势的看法和见解。并接受该领域专家的一些指导。 您认为当前的热点话题是什么，未来5年、10年、15年的重点关注领域是什么？谢谢！   由   提交/u/navarrox99  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb28us/robotics_and_ai_d/</guid>
      <pubDate>Tue, 23 Apr 2024 11:31:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我建立了一个网站来检测音频深度伪造和欺骗。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb15hi/p_i_built_a_website_to_detect_audio_deepfakes_and/</link>
      <description><![CDATA[大家好， 我已经在一个项目上工作了两年多了：Deepfake-Total.com，一个网站，您可以在其中分析音频文件以查找文本到语音或语音转换的痕迹，即识别音频深度伪造和欺骗，我认为这是这是一个重要的话题，尤其是考虑到即将举行的重要选举数量。 该工具免费使用，支持 YouTube 和 Twitter URL，以及手动上传音频文件。 我想分享这个并获得您的反馈：什么对您有效，什么对您无效，我可以在哪些方面改进？该模型对于大多数输入来说应该相当精确，但与防病毒扫描程序类似，总会偶尔出现异常值。如果您发现任何反馈，以及（科学）合作的想法等，我们将不胜感激。   由   提交 /u/mummni   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb15hi/p_i_built_a_website_to_detect_audio_deepfakes_and/</guid>
      <pubDate>Tue, 23 Apr 2024 10:27:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 除了法学硕士以外，还有其他教育部模式吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb0pjq/d_are_there_any_moe_models_other_than_llms/</link>
      <description><![CDATA[MoE 架构是否也应用于其他 ML 领域，比如说计算机视觉？为什么它们不受欢迎？是因为我们没有像 LLM 那样扩展视觉转换器，而 MoE 的可扩展性最好？   由   提交/u/lime_52  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb0pjq/d_are_there_any_moe_models_other_than_llms/</guid>
      <pubDate>Tue, 23 Apr 2024 09:58:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为 DS/MLE 单独工作的人应该牢记哪些最佳实践和工作流程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb0fi1/d_what_best_practices_and_workflows_those_working/</link>
      <description><![CDATA[我想知道技术招聘人员或经验丰富的 DS/MLE 对像我这样的人有什么看法：良好的理论和良好的技术背景，但单独工作太长了。 我的职业生涯背景摘要：我作为 DS 工作了 8 年，前 3 年在中型研发和咨询团队（一家大型科技公司）工作，然后在过去 5 年内，作为相对成功的非人工智能初创企业的独立 DS，主要开发 ML/NLP 内容来解决特定问题或改进其产品的一项特定功能（即从来不是整个产品）。在我设计的5年里。开发和部署了 4 个模型（但尝试了许多 OFC）——以及一些仪表板和简单的流式化 POC）。  最近参加聚会，看到实际团队中的人们如何工作、讨论和交流知识，这突然让我感到震惊：我错过了，我正在变得过时。我对技术面试感觉不够敏锐，我不确定我开发和维护项目的方式是否遵循良好的标准/最佳实践（哎呀，我几乎不遵循看板，主要使用我的计划员向我的老板报告进度） 。我做了一些版本控制并记录了我放入产品中的内容，但即便如此，我也不确定我正在按照团队的预期进行操作。   由   提交/u/Melodic_Reality_646   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb0fi1/d_what_best_practices_and_workflows_those_working/</guid>
      <pubDate>Tue, 23 Apr 2024 09:40:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻求基于神经网络的热扩散研究的专家审稿人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cazmth/r_seeking_expert_reviewers_for_neural/</link>
      <description><![CDATA[大家好， 我正在准备提交一篇研究论文，需要确定潜在的审稿人。我的论文介绍了一种使用神经网络解决钢棒热扩散问题的新方法。传统方法常常难以应对复杂的边界条件或非线性材料特性，但我们的神经网络模型经过经典分析方法的解决方案训练，在以较低的误差范围准确预测温度分布方面表现出了希望。 我寻找拥有博士学位的专家。或医学博士，并在物理学、热动力学或机器学习相关领域拥有丰富的经验。如果您在这些领域拥有专业知识或认识这样做的人，我将非常感谢您的意见或推荐。 到目前为止我所做的： 开发了神经网络模型并针对经典解决方案进行了测试。 起草了详细说明方法、结果和含义的手稿。 我面临着寻找对热物理学有深入了解的合适审稿人的挑战。和机器学习应用程序。此社区的任何指导或建议都会非常有帮助。 感谢您考虑我的请求！ 致以诚挚的问候， Ed   由   提交/u/No-Palpitation-7229   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cazmth/r_seeking_expert_reviewers_for_neural/</guid>
      <pubDate>Tue, 23 Apr 2024 08:44:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 门控长期记忆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1caywsz/d_gated_longterm_memory/</link>
      <description><![CDATA[      今天，我将展示我的最新想法：门控长期记忆 GLTM 单元 门控长期记忆试图实现一种高效的 LSTM 替代方案。与 LSTM 不同，GLTM 并行执行所有繁重的工作，唯一顺序执行的操作是乘法和加法操作。与变形金刚的二次存储器相比，门控长期存储器仅使用线性存储器。   由   提交/u/jessielesbian  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1caywsz/d_gated_longterm_memory/</guid>
      <pubDate>Tue, 23 Apr 2024 07:52:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型语言模型自我演化综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cayejz/r_a_survey_on_selfevolution_of_large_language/</link>
      <description><![CDATA[大家好，我是第二作者（也是项目负责人），想分享我们的最新工作：自我调查大型语言模型的演变。  采用自我进化方法的法学硕士数量迅速增加。然而，这些方法之间的关系仍然不清楚，缺乏系统的组织。 https://preview.redd.it/bhfeilfni6wc1.jpg?width=1240&amp;format=pjpg&amp;auto=webp&amp;s=8c268f3033fcd08c55ce860d00ff02c83bcb第3884章差距，我们很高兴地介绍我们的最新论文，“大型语言模型自我进化的调查”，它提出了法学硕士自我进化的概念框架，使模型（例如WizardLM，LLAMA和Phi）自主地（1）获取和（2）完善经验，（3）自我更新，以及（4）迭代评估他们的表现。 https://preview.redd.it/br95klfni6wc1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;s =93f6ae86772e632c168617c4cabd350f892eeedb  我们的框架探索了法学硕士从数据飞轮转向智能飞轮的潜力，并希望成为一种新的训练范式，将法学硕士和基于法学硕士的代理扩展到更自主的人工智能系统。  更多详情，请访问： 📄 Arxiv：https://arxiv.org/abs/2404.14387  🤖 GitHub：https://github .com/AlibabaResearch/DAMO-ConvAI/tree/main/Awesome-Self-Evolution-of-LLM 🐦 推文：https://twitter.com/tnlin_tw/status/1782662569481916671我们将不断添加论文并改进调查和回购。欢迎任何建议和 PR！   由   提交 /u/tnlin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cayejz/r_a_survey_on_selfevolution_of_large_language/</guid>
      <pubDate>Tue, 23 Apr 2024 07:17:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] Zotero组织</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cayah8/d_zotero_organization/</link>
      <description><![CDATA[使用 Zotero 组织和阅读研究论文的人，你们如何使用集合、子集合或标签？ 字面意思，我想知道您正在研究什么（视觉、语言……）以及您正在使用哪些集合、子集合或标签以及如何使用？ 最近我开始使用 Zoteor，我真的很喜欢对此感到困惑。从其他人那里寻找灵感。提前致谢。   由   提交/u/Relative_Tip_3647   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cayah8/d_zotero_organization/</guid>
      <pubDate>Tue, 23 Apr 2024 07:10:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] Phi-3即将发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/</link>
      <description><![CDATA[从 MSFT 的两个独立消息来源（其中一个接近 Sebastien Bubeck）了解到即将推出的 Phi-3 模型：  三个不同大小的模型（最多 14B） 同样，主要是合成和 LLM 增强的训练数据 显然在训练方面有一些升级技​​术 否更多 Apache 2，但更严格的许可证（类似于 llama3） Mixtral 级别性能，参数少得多  我想看看是否有人有更多有关模型的内部信息.   由   提交/u/yusuf-bengio  /u/yusuf-bengio  reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/</guid>
      <pubDate>Tue, 23 Apr 2024 01:13:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么选择 FID 而不是 ViT 模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1can2dg/d_why_fid_over_a_vit_model/</link>
      <description><![CDATA[标题基本上概括了这一点，但为什么我们要使用“更糟糕”的标题？计算图像距离的模型？我认为 ViT 模型能够更好地捕获图像之间的语义差异？   由   提交/u/Karan1213  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1can2dg/d_why_fid_over_a_vit_model/</guid>
      <pubDate>Mon, 22 Apr 2024 21:46:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama-3 可能刚刚杀死了专有的人工智能模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</link>
      <description><![CDATA[完整博客文章  Meta 在三天前发布了 Llama-3，感觉开源模型终于缩小了与专有模型的差距，这已经是一个拐点。初始基准测试显示 Llama-3 70B 在许多任务中非常接近 GPT-4：  官方元页面仅显示Llama-3优于Gemini 1.5和Claude Sonnet。 人工分析显示 Llama-3 的质量介于 Gemini-1.5 和 Opus/GPT-4 之间。 关于 LMSYS 聊天机器人竞技场排行榜，Llama-3 排名第 5，而当前的 GPT-4 模型和 Claude Opus 仍并列第 1。  功能更强大Llama-3 400B+ 模型仍在训练中，发布后很可能超越 GPT-4 和 Opus。 Meta vs OpenAI 有人推测 Meta 从一开始的目标就是瞄准OpenAI 采用“焦土”方法，通过发布强大的开放模型来扰乱竞争格局并避免在竞争中落后AI 竞赛。 Meta 在计算和人才方面可能会超过 OpenAI：  OpenAI 的预计收入为 20 亿美元，并且可能无利可图。 2023 年，Meta 的收入为 $134B，利润为 $39B。 Meta 的计算资源目前可能超过 OpenAI。 开源可能会吸引更好的人才和研究人员。  &gt;  一个可能的结果是微软收购 OpenAI 以赶上 Meta。谷歌也在进军开放模型领域，并拥有与 Meta 类似的功能。看看它们适合什么位置将会很有趣。 获胜者：开发人员和人工智能产品初创公司 我最近写了一篇关于现在建立人工智能初创公司令人兴奋，因为您的产品会随着每个主要模型的进步而自动改进。随着 Llama-3 的发布，开发人员的机会更大：  不再受供应商锁定。 开发人员不仅可以封装专有 API 端点，还可以现在以一种非常经济高效且高性能的方式将人工智能深度集成到他们的产品中。 Hugging Face 上已经有超过 800 个 llama-3 模型变体，而且看起来每个人都能够针对他们的使用案例、语言或行业进行微调。 更快、更便宜的硬件：Groq 现在每秒可以生成 800 个 llama-3 代币，而成本只是 GPT 成本的一小部分。以低价提供近乎即时的 LLM 响应即将到来。  视觉和视频的开源多模式模型仍然需要迎头赶上，但我预计这很快就会发生。 Llama-3 的发布标志着人工智能民主化的一个重要里程碑，但现在宣布专有模型的消亡可能还为时过早。谁知道呢，也许 GPT-5 会让我们所有人感到惊讶，并超越我们对 Transformer 模型功能的想象。 这绝对是人工智能领域构建的超级激动人心的时代！    由   提交 /u/madredditscientist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</guid>
      <pubDate>Mon, 22 Apr 2024 15:08:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>