<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Wed, 10 Apr 2024 06:18:11 GMT</lastBuildDate>
    <item>
      <title>[R] UnitTS：构建统一的时间序列模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0cyad/r_units_building_a_unified_time_series_model/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.00131 代码：https:// /github.com/mims-harvard/UniTS 项目页面：https://zitniklab.hms.harvard.edu/projects/UniTS/ 摘要：  基础模型，尤其是法学硕士，正在深刻地改变深度学习。我们可以通过少量提示或微调使单个预训练模型适应许多任务，而不是训练许多特定于任务的模型。然而，当前的基础模型适用于序列数据，但不适用于时间序列，由于固有的多样化和多域时间序列数据集，预测、分类和其他类型任务的任务规范存在差异，以及对任务的明显需求，这带来了独特的挑战。专门模型。我们开发了UniTS，这是一个统一的时间序列模型，支持通用任务规范，可容纳分类、预测、插补和异常检测任务。这是通过一个新颖的统一网络主干来实现的，该网络主干结合了序列和变量注意力以及动态线性算子，并作为统一模型进行训练。在 38 个多领域数据集中，与特定任务模型和重新利用的基于自然语言的法学硕士相比，UnitS 表现出了卓越的性能。在新数据域和任务上进行评估时，UnitTS 表现出卓越的零样本、少样本和即时学习能力。源代码和数据集可在 此 https URL 处获取。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0cyad/r_units_building_a_unified_time_series_model/</guid>
      <pubDate>Wed, 10 Apr 2024 04:30:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] DROID：大规模野外机器人操作数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0csix/r_droid_a_largescale_inthewild_robot_manipulation/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.12945 项目页面：https:// /droid-dataset.github.io/ 硬件代码： https://github.com/droid-dataset/droid 策略学习代码：https://github.com/droid-dataset/droid_policy_learning 数据集 Colab：https://github.com/droid-dataset/droid_policy_learning Research.google.com/drive/1b4PPH4XGht4Jve2xPKMCh-AXXAQziNQa?usp=sharing&quot;&gt;https://colab.research.google.com/drive/1b4PPH4XGht4Jve2xPKMCh-AXXAQziNQa?usp=sharing &lt;强&gt;摘要：  创建大型、多样化、高质量的机器人操纵数据集是迈向更强大、更强大的机器人操纵政策的重要基石。然而，创建此类数据集具有挑战性：在不同环境中收集机器人操作数据会带来后勤和安全挑战，并且需要在硬件和人力方面进行大量投资。因此，即使是当今最通用的机器人操纵策略，也大多是根据场景和任务多样性有限的少数环境中收集的数据进行训练的。在这项工作中，我们引入了DROID（分布式机器人交互数据集），这是一个多样化的机器人操作数据集，具有 76k 演示轨迹或 350 小时的交互数据，收集了 564 个场景和 84 个场景。北美、亚洲和欧洲的 50 名数据收集者在 12 个月内完成的任务。我们证明，使用 DROID 进行训练可以产生具有更高性能和更高泛化能力的策略。我们开源完整的数​​据集、策略学习代码和重现机器人硬件设置的详细指南。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0csix/r_droid_a_largescale_inthewild_robot_manipulation/</guid>
      <pubDate>Wed, 10 Apr 2024 04:21:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何重新创建梯度下降学习单隐藏层 CNN 中的实验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0ckaj/d_how_can_i_recreate_the_experiments_at_gradient/</link>
      <description><![CDATA[我正在尝试重新创建这篇论文中的实验。我能够完成初始化条件和一切，但是，我陷入了表 1（附有屏幕截图）。配给术语似乎令人困惑，因为它们有时使用 a，有时使用 a\。*看看定理 4.3。 鉴于这个概念表中的定理是正确的，如何得到满足这个条件的向量 a*   由   提交/u/Sufficient_Drawing59   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0ckaj/d_how_can_i_recreate_the_experiments_at_gradient/</guid>
      <pubDate>Wed, 10 Apr 2024 04:08:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关为 7B 模型整理 DPO 数据集的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0btdj/d_seeking_advice_on_curating_a_dpo_dataset_for_a/</link>
      <description><![CDATA[大家好， 我正在为特定领域（金融）策划一个数据集，需要为某个领域创建一个 DPO 数据集定制7B型号。我想知道是否有人可以分享他们关于创建 DPO 数据集的最佳实践的经验或建议。 作为起点，我正在考虑使用 GPT-4 答案作为“选择”的答案。响应和7B模型的答案作为“拒绝”。那些。但是，我担心如果我从不同的模型中选择已接受的答案，可能不会产生令人满意的结果。 Twitter 上对此主题进行了一些很好的讨论：  &lt; li&gt;https://twitter.com/rm_rafailov/status/1751738917613912086 https://twitter.com/abacaj/status/1751864643755094161 https://twitter.com/archit_sharma97/status/1751652187003121952  我想到的另一种方法：  从 7B 模型生成一些响应 将这些响应发送到 GPT-4，以对其中一个响应进行排名和改进/改写 使用最差的响应作为“ “拒绝”一个和改进/改述的响应为“接受”。一个  如果有人能够分享他们在整理高质量 DPO 数据集方面的经验或提供有关上述方法的任何见解，我将不胜感激。 谢谢提前寻求您的帮助！   由   提交 /u/aadityaura   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0btdj/d_seeking_advice_on_curating_a_dpo_dataset_for_a/</guid>
      <pubDate>Wed, 10 Apr 2024 03:29:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 时间序列数据集的特征工程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c05vep/d_feature_engineering_for_timeseries_datasets/</link>
      <description><![CDATA[我有 2 个具有不同变量/特征和时间戳的时间序列数据集。我已经对这两个数据集独立完成了一些特征工程。 现在，我想对两个数据集进行回归，因为我相信它们将一个数据集与另一个数据集相关。但是，当我合并时间索引上的两个数据集时，有些行属于 dataset1，有些行属于 dataset2。因此，所有行都有 Nan 值。 问题：1. 我该如何管理以拟合线性回归并预测属于 dataset1 一部分的变量？ 2. 向前填充nan值是否有意义？由于它是一个时间序列，我猜数据集 1 的值是相同的，直到数据集 1 的新行出现，反之亦然。 3. 欢迎任何评论/观察！ 谢谢   由   提交 /u/LeHalfW   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c05vep/d_feature_engineering_for_timeseries_datasets/</guid>
      <pubDate>Tue, 09 Apr 2024 22:52:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] Book Reco / ID：使用 ML 进行数据分析？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c05lt8/d_book_reco_id_using_ml_for_data_analysis/</link>
      <description><![CDATA[我记得有位作者（我相信我是在 Twitter 上找到的）写了一本关于利用 ML 进行数据分析的书;产生见解。我相信这是用Python编写的。 我做了一些搜索，但只能找到“使用Python进行数据分析的实用机器学习”这不是我遇到的那本书。 这本书对任何人来说都有启发吗？   由   提交 /u/marksimi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c05lt8/d_book_reco_id_using_ml_for_data_analysis/</guid>
      <pubDate>Tue, 09 Apr 2024 22:41:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在良好的训练与性能权衡下，3B 参数下哪个是最好的模型（多模态或 LM）？ （即良好的参数效率）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzxxwb/d_which_is_the_best_model_multi_modal_or_lm_under/</link>
      <description><![CDATA[目前哪种模型在数据集大小和参数数量合理的情况下具有最佳性能。我问的是架构效率，因为我计划从头开始训练不同的任务，并且可能无法负担 SOTA 模型使用的数据集量。 编辑：如果仅考虑仅解码器模型，您更喜欢哪个？如果只是编码器-解码器，哪个会更喜欢？   由   提交/u/gokulPRO  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzxxwb/d_which_is_the_best_model_multi_modal_or_lm_under/</guid>
      <pubDate>Tue, 09 Apr 2024 17:30:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 就我在 OpenAI 助手评估中构建的内容寻求反馈。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzuwof/p_seeking_feedback_for_what_i_built_on_evaluation/</link>
      <description><![CDATA[最近，我进行了一次有趣的用户通话，用户表示有兴趣评估 OpenAI 助手的性能。 用例： - 用户的场景反映了 RAG 管道，其中有一个助手旨在回答有关疾病和药物的医疗查询。 - 他们提供了指导提示助理和一组包含支持信息的文件，助理需要从中生成响应。 面临的挑战：  - 他们必须扮演 -与聊天机器人进行对话，假设不同的角色（例如，疟疾患者），这对于 100 多个角色来说非常耗时。 - 在角色扮演对话之后，他们必须根据个人反应手动评分诸如响应是否基于支持文档、简洁、完整和礼貌等参数。 开发的解决方案： - 模拟对话：构建一个工具根据用户角色模拟与 Assistant 的对话（例如，“一名患者询问疟疾的治疗”）。 - OpenAI Assistant 的评估：该工具根据用户满意度、接地等参数评估对话使用 UpTrain 的预配置指标（涵盖响应质量、语调、语法等用例的 20 多个指标）来了解事实、相关性等。 寻求反馈：目前正在寻求对所开发工具的反馈。如果您可以在 GitHub 上查看它，我会很高兴。   由   提交/u/Old_Log2517  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzuwof/p_seeking_feedback_for_what_i_built_on_evaluation/</guid>
      <pubDate>Tue, 09 Apr 2024 15:25:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] Copilot（和替代方案）具有端点以支持任何人手动制作的上下文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzsfcs/d_copilot_and_alternatives_with_an_endpoint_to/</link>
      <description><![CDATA[所以我想知道，如果我们能够编写简单的脚本来丰富 AI 助手的上下文（例如 VSCode），会怎样？例如堆栈跟踪或任何我认为在我们开发某些东西时可能对人工智能助手有用的端点。 一些特定的用例：  在堆栈跟踪中缺少导入，助手会知道当我们尝试添加导入时需要导入什么。  stacktrace 中发生错误的函数。这将确保助理更具体地知道我们首先要解决什么问题。   这可以通过提供“仅仅”来实现堆栈跟踪。我想很快我们就会在这个背景下想出许多其他的东西。我想不同的语言需要不同的上下文。在我看来，拥有模块化选项来选择我们想要连接到上下文的内容对于任何助手都是有益的。  手动上下文可能对 ex 有效。特定持续时间或 3 次通话。 你们对此有何看法？   由   提交/u/SixZer0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzsfcs/d_copilot_and_alternatives_with_an_endpoint_to/</guid>
      <pubDate>Tue, 09 Apr 2024 13:39:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你们在生产中拥有什么类型的 RAG 应用程序？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzr1nl/d_what_type_of_rag_applications_do_you_have_in/</link>
      <description><![CDATA[我们计划从基于 Rasa 的虚拟助理迁移到基于 LLM 的 .还有哪些其他用法更相关？您建议使用哪些编排框架？我应该考虑使用代理方法还是基于 RAG 的方法？    由   提交 /u/Winter_Draw9039   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzr1nl/d_what_type_of_rag_applications_do_you_have_in/</guid>
      <pubDate>Tue, 09 Apr 2024 12:34:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 异步参数服务器如何与数据并行技术一起工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzl9xf/d_how_does_an_asynchronous_parameter_server_work/</link>
      <description><![CDATA[      请原谅我的糟糕图表。我试图了解数据并行性如何与 异步参数服务器。 我目前的理解是有一个异步参数服务器并且（例如）我们有2个GPU工作线程。 GPU工人的工作是计算一批数据的梯度，然后将该梯度更新发送到参数服务器。然后，参数服务器将计算新的权重，然后将其发送到相应的 GPU，而无需等待其他 GPU 完成计算。 这是一个图表。 https://preview.redd.it/wdry4xf1fetc1.png?width=1646&amp; ;format=png&amp;auto=webp&amp;s=eda4b47fbe03d43a6706e96132e0380e7612ff00 这对我来说似乎是错误的。例如，假设由于某种原因，您有异构加速器，例如 nvidia H100 和 nvidia GTX 1060 等，H100 可能能够完成例如 5 个批次并在 1060 之前更新权重有机会根据第一次计算更新权重。因此，从理论上讲，GTX 1060 将在超旧权重上应用梯度。 在第二个图中，如果将权重应用于 H100，那么它会相对较快地收敛，但加法后期 1060 梯度会将其推出局部最小值。 ​ https://preview.redd.it/2pq4cw0ueetc1.png?width=730&amp;format=png&amp;auto=webp&amp;s=63ab73570e2e017 21796aa2d11b4b7152c38ff48 在这种情况下，异步参数服务器的权重更新是否正确，因为梯度是针对与新权重不同的一组权重？如果我错了，我很想弄清楚我的逻辑在哪里不正确，因为我很好奇，如果单个工作人员能够连续计算“稍微”旧的权重，而不需要太难的话，那会有多糟糕。时间收敛？   由   提交/u/stereotropic_CS   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzl9xf/d_how_does_an_asynchronous_parameter_server_work/</guid>
      <pubDate>Tue, 09 Apr 2024 06:25:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 没有指数数据就没有“零样本”：预训练概念频率决定多模态模型性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzjbpn/r_no_zeroshot_without_exponential_data/</link>
      <description><![CDATA[      摘要 &lt; blockquote&gt; 网络爬取的预训练数据集是令人印象深刻的“零样本”的基础。评估多模态模型的性能，例如用于分类/检索的 CLIP 和用于图像生成的稳定扩散。然而，目前尚不清楚“零样本”概念的意义有多大。泛化是针对这种多模态模型的，因为不知道它们的预训练数据集在多大程度上包含“零样本”过程中针对的下游概念。评估。在这项工作中，我们问：预训练数据集中这些概念的频率如何影响多模态模型在下游概念上的性能？我们在 34 个模型和 5 个标准预训练数据集（CC-3M、CC-12M、YFCC-15M、LAION-400M、LAION-Aesthetics）中全面研究了这个问题，生成了超过 300GB 的数据工件。我们一致发现，远非表现出“零射击”，而是表现出“零射击”。概括地说，多模态模型需要指数级更多的数据来实现下游“零样本”的线性改进。性能，遵循样本低效对数线性缩放趋势。即使在控制预训练和下游数据集之间的样本级相似性以及对纯合成数据分布进行测试时，这种趋势仍然存在。此外，根据我们的分析对采样的长尾数据进行基准测试模型，我们证明多模态模型整体表现不佳。我们将此长尾测试集贡献为“Let it Wag！”为进一步研究该方向奠定了基础。综上所述，我们的研究揭示了对训练数据的指数级需求，这意味着“零样本”的关键在于训练数据。大规模训练范式下的泛化能力仍有待发现。  ​ 概念频率与 T2I 审美分数之间的对数线性关系。 论文：&lt; /strong&gt; https://arxiv.org/pdf/2404.04125.pdf 项目： https://github.com/bethgelab/Frequency_definees_performance&lt; /a&gt; 数据集： https:// Huggingface.co/datasets/bethgelab/Let-It-Wag ​ ​   由   提交/u/quequero  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzjbpn/r_no_zeroshot_without_exponential_data/</guid>
      <pubDate>Tue, 09 Apr 2024 04:27:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 就 RAG 研究而言，为什么似乎很多人没有致力于猎犬的研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzfxgm/d_in_terms_of_rag_research_why_does_it_seem_like/</link>
      <description><![CDATA[我是几年前进行 NLP 研究的人，后来停止并加入了行业，最近试图重新掌握事物。我对 RAG 相关的工作很感兴趣，并开始阅读一些论文。 我的理解是，对于 RAG，你有检索器和生成器。对于生成器来说，使用各种 LLM 似乎是标准的，但检索器似乎也设置为使用 BM25 或最初使用的 DPR 之类的东西。我认为 RAG 的性能将在很大程度上依赖于检索器，但我也有点惊讶地发现似乎没有在这方面进行大量研究。 我只是错误并且没有看向正确的方向？或者说，检索器似乎没有得到那么多关注是有什么原因吗？ 想想看，我并没有真正看到编码器模型总体上做了很多工作。    由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzfxgm/d_in_terms_of_rag_research_why_does_it_seem_like/</guid>
      <pubDate>Tue, 09 Apr 2024 01:38:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 高效扩散模型中缺失的 U</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzfns4/r_the_missing_u_for_efficient_diffusion_models/</link>
      <description><![CDATA[一篇新论文提出用利用神经常微分方程的连续 U-Net 取代扩散模型中的标准离散 U-Net 架构。这种重新表述可以对去噪过程进行连续建模，从而显着提高效率：  推理速度提高 80% 模型参数减少 75% 70% 保持或提高图像质量  关键技术贡献：  动态神经 ODE 模块建模潜在表示演化使用二阶微分方程 自适应时间嵌入来调节扩散时间步长的动力学 高效的 ODE 求解器和常量内存伴随方法，可实现更快、内存效率更高的训练 &lt; /ul&gt; 作者展示了这些在图像超分辨率和去噪任务上的改进，并通过详细的数学分析解释了为什么连续公式会导致更快的收敛和更有效的采样。 潜在影响： p&gt;  使扩散模型适用于更广泛的应用（实时工具、资源受限设备） 在深度学习、微分方程、动力学的交叉领域开辟新的研究方向系统  以下方面存在一些限制：(1) ODE 求解器和伴随方法增加了复杂性；(2) 我认为即使进行了改进，扩散模型仍然可能需要大量计算。 &lt; p&gt;完整摘要此处。 Arxiv 此处。 TL;DR：新论文建议替换离散 U-使用神经 ODE 的连续 U-Net 扩散模型中的网络，可将推理速度提高 80%、参数减少 75%、FLOP 减少 70%，同时保持或提高图像质量。主要影响：更高效、更容易理解的生成模型、连续时间深度学习的新研究方向。   由   提交 /u/Successful-Western27    reddit.com/r/MachineLearning/comments/1bzfns4/r_the_missing_u_for_efficient_diffusion_models/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzfns4/r_the_missing_u_for_efficient_diffusion_models/</guid>
      <pubDate>Tue, 09 Apr 2024 01:26:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>