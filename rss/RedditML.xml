<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Thu, 04 Apr 2024 18:17:19 GMT</lastBuildDate>
    <item>
      <title>[P]AI出行-需要反馈</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvu5uy/p_ai_travel_need_feedback/</link>
      <description><![CDATA[我的团队打造了一款人工智能旅行规划工具——如果你想去旅行但不知道去哪里或做什么，只需提示它，它就会为您提供个性化的服务。 我们现在需要的主要是关于该产品是否适合各种人群的反馈，因为每个人的旅行动机与另一个人不同，所以它更难重点关注一组人。我们已经完成了用户研究来帮助塑造产品，但我们需要更多的数据点。 如果您有 5 分钟的时间，我们将不胜感激，帮助您进行测试，看看您是否会再次使用它。它可以免费使用，只需注册，以便我们了解现场参与情况。 https://wanderboat.ai/ ?i=旅行癖   由   提交/u/shinsplints5  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvu5uy/p_ai_travel_need_feedback/</guid>
      <pubDate>Thu, 04 Apr 2024 18:08:15 GMT</pubDate>
    </item>
    <item>
      <title>验证集和测试集之间的性能差距（k-Fold CV）[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvu2lg/performance_gap_between_validation_and_test_sets/</link>
      <description><![CDATA[我正在使用 k 折交叉验证开发二进制图像分类器 (ResNet-18)。训练过程中，模型的最高验证准确率达到99%。然而，在单独的测试集上，准确率下降至 92%。我在损失函数中也观察到了类似的趋势，其中验证损失比测试集损失更低。训练数据和测试数据中的标签分布是平衡的。 为什么会有如此显着的差异验证集和测试集之间的性能差异？   由   提交 /u/qaz_zaqi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvu2lg/performance_gap_between_validation_and_test_sets/</guid>
      <pubDate>Thu, 04 Apr 2024 18:04:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] AI 运动模型 - 寻找 ML 专业知识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvs8c3/p_ai_sports_model_looking_for_ml_expertise/</link>
      <description><![CDATA[大约一年前，我创立了一项 AI Sports Picks 服务，这就像坐过山车一样。  去年棒球赛季期间，我们获得了很多关注，并将 MRR 扩大到了 10,000 美元（200 名客户，每人 50 美元）。我们公开所有结果，并努力成为行业中最透明的 我觉得我已经非常了解营销和行业。如果我有更多时间专注于业务方面（远离建模），我相信我们可以将其规模扩大到 50 万美元 MRR（考虑到我看到竞争对手在做什么） 尽管我和我的联合创始人两者都拥有 FAANG 技术背景，ML 已被证明是不同的野兽。我们已经能够训练出超越书本的模型，但我认为差距在于，在具有机器学习专业知识的个人的帮助下，我们的上限会更高。我们愿意将公司的一部分提供给合适的人。 PM 我了解更多信息   由   提交/u/Logistics_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvs8c3/p_ai_sports_model_looking_for_ml_expertise/</guid>
      <pubDate>Thu, 04 Apr 2024 16:53:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用什么生成引擎使 Luma 的 Flythroughs 如此干净？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvrsr7/d_what_generative_engine_is_used_to_make_lumas/</link>
      <description><![CDATA[我一直在探索 NeRF 作为一种将随意捕捉的视频转换为 VR 环境的方法。 Luma 的 Flythroughs 的视觉质量远远超过我能做的任何事情我使用过的 NeRF 实现 - 尽管不可否认，我在 NerfStudio 之外并没有做太多事情。 我怀疑它们干净的外观更多地与生成后处理有关，而不是 NeRF 训练。你知道他们的生成步骤可能是什么吗？   由   提交 /u/stagnified   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvrsr7/d_what_generative_engine_is_used_to_make_lumas/</guid>
      <pubDate>Thu, 04 Apr 2024 16:36:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] Deepmind - Mixture-of-Depths：在基于 Transformer 的语言模型中动态分配计算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvrduw/r_deepmind_mixtureofdepths_dynamically_allocating/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2404.02258 ​ 摘要 基于 Transformer 的语言模型在输入序列中均匀分布 FLOP。在这项工作中，我们证明 Transformer 可以学习将 FLOP（或计算）动态分配到序列中的特定位置，从而优化模型深度上不同层的序列分配。我们的方法通过限制可以参与给定层的自注意力和 MLP 计算的令牌数量 (k) 来强制执行总计算预算。要处理的令牌由网络使用 top-k 路由机制确定。由于 k 是先验定义的，因此与其他条件计算技术不同，这个简单的过程使用具有已知张量大小的静态计算图。然而，由于 k 个标记的身份是可变的，因此该方法可能会在时间和模型深度维度上不均匀地消耗 FLOP。因此，计算支出总体上是完全可预测的，但在令牌级别是动态的和上下文敏感的。以这种方式训练的模型不仅可以学习动态分配计算，而且可以高效地进行计算。这些模型与等效 FLOPS 和训练挂钟时间的基线性能相匹配，但每次前向传递只需要一小部分 FLOP，并且在训练后采样期间的步进速度可以快 50% 以上。 ​ https: //preview.redd.it/aez0hy66mhsc1.png?width=1282&amp;format=png&amp;auto=webp&amp;s=59d59bff1dbf7a0323a5e00cb16182bd0f5de9d4 ​ &lt; a href=&quot;https://preview.redd.it/ma6ewf06nhsc1.png?width=2138&amp;format=png&amp;auto=webp&amp;s=f4a845f0892ccb6c4ebe447425c3a0aaadebb03d&quot;&gt;https://preview.redd.it/ma6ewf06nhsc1.png?width =2138&amp;format=png&amp;auto=webp&amp;s=f4a845f0892ccb6c4ebe447425c3a0aaadebb03d   由   提交 /u/RedditLovingSun   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvrduw/r_deepmind_mixtureofdepths_dynamically_allocating/</guid>
      <pubDate>Thu, 04 Apr 2024 16:20:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 推出世界上最大的合成开源文本到 SQL 数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvr0st/r_introducing_worlds_largest_synthetic_opensource/</link>
      <description><![CDATA[Gretel 发布最大开源 Text-to-SQL 数据集，加速 AI 模型训练 https://gretel-ai.webflow.io/blog/synthetic-text-to-sql-dataset   由   提交/u/alig80  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvr0st/r_introducing_worlds_largest_synthetic_opensource/</guid>
      <pubDate>Thu, 04 Apr 2024 16:05:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] FMOps 基础设施堆栈的可视化。你的想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvqi0s/d_a_visualization_of_the_fmops_infrastructure/</link>
      <description><![CDATA[       由   提交 /u/vvkuka   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvqi0s/d_a_visualization_of_the_fmops_infrastructure/</guid>
      <pubDate>Thu, 04 Apr 2024 15:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 时间序列分类。需要建议！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvoe1m/p_timeseries_classification_need_suggestions/</link>
      <description><![CDATA[数据源-&gt;记录一个人的视频数据（大约100个视频） 数据 -&gt;使用某些软件（如 Facereader）计算的逐帧面部活动动作单元（也包括情感）分数 目标数据 -&gt;每个视频中的一些帧（不一致），即参与者回答特定问题时的帧。  总之，我有 100 个参与者，100 个数据帧，其中 X 行（帧）和 Y 列（由软件提取的特征，即动作单元）。然后参与者明智的输出标签（二进制）。 我很困惑如何继续，因为这是我第一次与时间序列分类交互。我尝试聚合每个参与者的特征，即平均值、标准差等，然后将它们映射到输出标签以创建一个简单的分类模型。  我还能尝试什么？我觉得由于聚集而错过了面部活动。  我的想法是使用逐帧数据并将每个帧与输出标签（以及帧号）进行映射，但由于帧数不一致，我认为这不是一个好主意。有什么想法吗？  我确实尝试过滚动功能，但没有多大帮助。我认为一些 fft 可能会有所帮助。    由   提交 /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvoe1m/p_timeseries_classification_need_suggestions/</guid>
      <pubDate>Thu, 04 Apr 2024 14:21:50 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 接受研究ML职位的降薪，这通常是一个好的举动吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvj56a/discussion_accepted_a_salary_drop_for_a_ml/</link>
      <description><![CDATA[我于 2020 年从法国一所优秀大学（最好的大学之一，但不是最好的大学）毕业，获得了人工智能硕士学位。 我在一家美国科技公司（巴黎办事处）的数字营销领域工作了 3 年，担任数据科学家，一开始确实很酷，但这份工作很快就变得多余，更多的是软件工程而不是真正的数据科学，并且诚实、简单，足以由本科生完成，所有这一切都没有任何进化论的观点。我们开发的产品销量不够，最后全球气氛紧张。虽然福利很好，而且大多数人都很好，但团队中的每个数据科学家最终都离开了公司，我也是。 我有机会加入一个新的人工智能公共研究中心，作为一名研究机器学习工程师。这是我重返人工智能领域的绝佳机会。 该中心自 2020 年成立，内部成立了一个工程师团队，旨在：  帮助研究人员将他们的成果产业化通过支持他们开发开源包来进行研究 帮助组织活动以推广中心（暑期学校、黑客马拉松、研讨会等） 我的职位还包括监督该中心的创新部门，更准确地说，是支持该中心的合作机构创建的初创企业。  表面上，这份工作非常适合我，但是：   p&gt;  在 6 个月的时间里，我刚刚贡献了 2 个软件包，其中有一些小的贡献，例如重构、测试实现、文档等。没有真正的人工智能，而是人工智能项目的基本软件工程。这些项目真的很酷，研究人员也很优秀，但这些软件包并没有被经常使用，从我的角度来看，我的影响似乎很轻。 工程团队的成员，尤其是团队领导并不资深。个人资料和经验比我少，学位选择性也较差。此外，我与他们相处得并不融洽，而且没有团队合作，因为每个人都与不同的研究人员一起研究他的项目。 我们应该支持的初创公司似乎并不真正感兴趣在我们的支持下，他们通常会寻求我们团队中可能不具备的真正特定技能，并且为他们创造价值很复杂。 我们没有合适的办公室（没有为每个人提供的显示器，而且办公室是一个会议室改造成的一个开放空间），而我去那里的通勤往返需要3小时（必须每周2次）。此外，他们还给了我一台 13 英寸 MacBook Air，并告诉我，自从我到达那里后，我将拥有最新的 MacBook Pro，但每周都会推迟。 我接受了大幅降薪（10 %)  如果那里有高级机器学习工程师/数据科学家，我真的很想听听您对此的看法。   由   提交/u/brash69  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvj56a/discussion_accepted_a_salary_drop_for_a_ml/</guid>
      <pubDate>Thu, 04 Apr 2024 09:48:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士正在损害人工智能研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</link>
      <description><![CDATA[这是一个大胆的主张，但我觉得 LLM 的炒作早就该消退了。 GPT4 之后，LLM 性能和设计改进不仅取得了相对较小的进展：使其变得更好的主要方法仍然只是使其更大，并且所有 Transformer 的替代架构都被证明是低于标准和劣质的，它们引起了人们的关注（并且投资）远离其他可能更具影响力的技术。与此同时，大量涌入的人甚至不知道基本的机器学习是如何工作的，他们自称是“人工智能研究员”。因为他们使用 GPT 让每个人在本地托管一个模型，试图让你相信“语言模型完全可以推理”。我们只需要另一个 RAG 解决方案！”他们加入这个社区的唯一目标不是开发新技术，而是利用现有技术拼命拼凑出一项有利可图的服务。甚至论文本身也开始主要由法学硕士撰写。我不禁认为整个领域可能会陷入停滞状态，因为不断增长的社区满足于平庸的修复，这些修复充其量只能使模型在任意“分数”上的得分稍微好一些。他们弥补了这一点，忽略了诸如幻觉、上下文长度、基本逻辑缺乏能力以及运行这种规模模型的高昂成本等明显问题。我赞扬那些不顾市场炒作而致力于开发能够实现真正逻辑过程的代理的人们，并希望很快会引起更多关注。   由   提交/u/NightestOfTheOwls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</guid>
      <pubDate>Thu, 04 Apr 2024 08:36:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视觉自回归建模：通过下一代预测生成可扩展图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvh8ep/d_visual_autoregressive_modeling_scalable_image/</link>
      <description><![CDATA[      ​ https://preview.redd.it/12c372dv0fsc1.png?width=2833&amp;format=png&amp; ; auto=webp&amp;s=0d88f98929854f3de18b8c623d3aff5a7ed14b79 摘要：  我们提出了视觉自回归建模（VAR），一种新一代范式它将图像的自回归学习重新定义为从粗到细的“下一尺度预测”或“下一分辨率预测”，与标准光栅扫描“下一标记预测”不同。这种简单、直观的方法使自回归 (AR) 转换器能够快速学习视觉分布并很好地概括：VAR 首次使 AR 模型在图像生成方面超越了扩散转换器。在 ImageNet 256x256 基准上，VAR 通过将 Frechet 起始距离 (FID) 从 18.65 提高到 1.80、起始分数 (IS) 从 80.4 提高到 356.4，显着改善了 AR 基线，推理速度提高了约 20 倍。实证还验证了 VAR 在图像质量、推理速度、数据效率和可扩展性等多个维度上均优于 Diffusion Transformer (DiT)。扩大 VAR 模型表现出清晰的幂律缩放定律，与法学硕士中观察到的相似，线性相关系数接近 -0.998，这是确凿的证据。 VAR 进一步展示了下游任务中的零样本泛化能力，包括图像内画、外画和编辑。这些结果表明 VAR 最初模拟了法学硕士的两个重要属性：缩放定律和零样本任务泛化。我们已经发布了所有模型和代码，以促进 AR/VAR 模型在视觉生成和统一学习方面的探索。  Arxiv: https://arxiv.org/abs/2404.02905 Github： https://github.com/FoundationVision/VAR   由   提交 /u/ExponentialCookie   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvh8ep/d_visual_autoregressive_modeling_scalable_image/</guid>
      <pubDate>Thu, 04 Apr 2024 07:33:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] RLHF 真的有效吗？你为什么用它？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bv2jgm/d_does_rlhf_really_work_why_do_you_use_it/</link>
      <description><![CDATA[我尝试过自己做 RLHF。使用以下库： https://huggingface.co/docs/trl/en/index&lt; /a&gt;  在示例之外，它不起作用。  是否有人成功使用 RLHF（学术界之外）或正在为此苦苦挣扎？  您可以分享的任何具体用例都会有所帮助。    由   提交 /u/iordanissh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bv2jgm/d_does_rlhf_really_work_why_do_you_use_it/</guid>
      <pubDate>Wed, 03 Apr 2024 19:58:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么股票预测论文没有投入生产？ [D] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bv0cu7/why_stock_prediction_papers_arent_put_to/</link>
      <description><![CDATA[我最近一直在查看股票预测研究论文，并对他们所取得的成就感到惊讶。虽然这些研究看起来很有希望，但我不确定它们是否能应用于现实生活……这几乎就像是美好得令人难以置信的场景。任何人都想对此有所了解。   由   提交/u/Pomelo-Actual   /u/Pomelo-Actual reddit.com/r/MachineLearning/comments/1bv0cu7/why_stock_prediction_papers_arent_put_to/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bv0cu7/why_stock_prediction_papers_arent_put_to/</guid>
      <pubDate>Wed, 03 Apr 2024 18:36:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 只是美化了即时工程吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1busp41/d_is_rag_just_glorified_prompt_engineering/</link>
      <description><![CDATA[您会收到提示、IR 相关文档，将它们发送到提示，然后 LLM 会生成响应。我们刚刚设计了提示以提供更多信息。   由   提交 /u/RiseWarm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1busp41/d_is_rag_just_glorified_prompt_engineering/</guid>
      <pubDate>Wed, 03 Apr 2024 13:32:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>