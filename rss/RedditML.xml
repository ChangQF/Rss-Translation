<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 07 May 2024 09:16:04 GMT</lastBuildDate>
    <item>
      <title>[D] 对于更好地学习如何进行图像中的文本识别以及文本分析的资源有什么建议吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm7j25/d_any_recommendations_for_resources_to_learn/</link>
      <description><![CDATA[大家好！ 我是机器学习世界的新手，但我已经慢慢开始越来越多地研究它，通过大学课程和 Microsoft Azure AI 基础课程。我正在开展一个大学项目，需要识别图像中的文本，然后对其进行分析。 我知道我可以使用 Microsoft Azure 提供的 OCR 服务等来识别文本，但是对我来说，主要问题是如何真正分析文本？假设我有一张包含多段文本的图像，有些短，有些长，它们有不同的用途，例如描述或使用说明，在图像中以各种方式排列。由于文本的结构并未真正标准化，因此我无法训练用于识别各种文本片段的文档智能模型。另外，我不相信我可以对文本使用对象检测。 因此，我可以诉诸传统的 OCR。但是，比方说，根据文本的含义或目的对文本片段进行分段或分类的技术是什么（这也意味着文本块，而不仅仅是单个单词，还意味着可以在表格或其他格式中找到的文本）。您对文章、视频和资源有什么建议吗？我可以从中了解有关如何分析 OCR 提取的文本的更多信息？   由   提交/u/Alex_The_Android  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm7j25/d_any_recommendations_for_resources_to_learn/</guid>
      <pubDate>Tue, 07 May 2024 09:12:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用耳语识别不常见术语</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm7frx/d_recognizing_uncommon_terms_with_whisper/</link>
      <description><![CDATA[大家好，我目前正在研究 Whisper，专门研究法语铁路语言。我在转录歧义词和识别车站名称方面遇到了一些问题。最初，我尝试使用总共 2 小时的音频文件进行训练，但结果没有达到我的预期。然后我转向使用提示，这解决了歧义问题，但是由于上下文大小限制为 244 个标记，我无法包含所有车站名称。 您能给我一些提示吗？我是这个领域的新手。谢谢    提交人    /u/Top-Set-1178   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm7frx/d_recognizing_uncommon_terms_with_whisper/</guid>
      <pubDate>Tue, 07 May 2024 09:06:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] EOS 代币在预训练过程中重要吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm7eqw/d_is_eos_token_crucial_during_pretraining/</link>
      <description><![CDATA[预训练期间使用的 EOS 令牌标记“序列结束”，但它不会阻止信息在可能不相关的文档之间流动。如果是这样，当我们可以稍后在 SFT 阶段添加它时，为什么还要在预训练期间包含它？   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm7eqw/d_is_eos_token_crucial_during_pretraining/</guid>
      <pubDate>Tue, 07 May 2024 09:04:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] “人肉”LLM 的词是什么（指出他不是人类）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm6d0r/d_what_is_the_word_for_doxing_an_llm_calling_out/</link>
      <description><![CDATA[如果没有一个流行的术语 - 我们可以创建一个吗？ 想象一下在 Reddit 上与一个（假设是人类的）巨魔互动，然后找到确凿的证据表明该实体是 LLM（明确的提示证据，没有 GPT 之前的历史记录等） 在线社区审查了英特尔并同意这是一个 LLM 机器人。 “谢天谢地有人[动词]-ed@alanTee。让我们屏蔽他，这样就不会再有人与 LLM 争论了。” 询问 Reddit，尽管这个子值得命名这个，如果这个术语还不存在的话。    由   提交/u/Connect_Corner_5266   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm6d0r/d_what_is_the_word_for_doxing_an_llm_calling_out/</guid>
      <pubDate>Tue, 07 May 2024 07:47:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] Stack Overflow 与 OPEN AI 的合作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm64jk/d_stack_overflow_partnership_with_open_ai/</link>
      <description><![CDATA[      https://stackoverflow.co/company /press/archive/openai-partnership 一些想法： - 很确定 OPEN AI 在训练 ChatGPT 时已经抓取了 Stack Overflow（如果你不这么做的话）相信它 - 请再次观看米拉·穆拉蒂 (Mira Murati) 的著名采访） - 那么为什么要这样做呢？也许可以合法访问内容？ - 自从 Chat GPT 发布以来，StackOverflow 的受欢迎程度正在下降（请参见下面的 Google 趋势图表）- 所以这对于 SO 所有者来说是有意义的 &lt; p&gt;- 从社区的角度来看非常有趣：开发者免费创建了整个内容，现在将用于替换它们，并且他们没有获得利润分成 ​ https://preview.redd.it/fudrujkniyyc1 .png?width=968&amp;format=png&amp;auto=webp&amp;s=e116159e61394557e03a6cad431aadc77f88807b   由   提交/u/pg860  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm64jk/d_stack_overflow_partnership_with_open_ai/</guid>
      <pubDate>Tue, 07 May 2024 07:29:52 GMT</pubDate>
    </item>
    <item>
      <title>[p] 需要有关项目想法的帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm5rym/p_need_help_with_project_ideas/</link>
      <description><![CDATA[你好，reddit， 正如标题所示，我需要帮助为一个涉及机器学习的个人项目提出主题。我是一名数学系学生，两天后毕业，将于秋季攻读计算机科学硕士学位。由于我无法获得秋季实习机会（笑），所以我打算利用暑假修改我的简历。 作为参考，我刚刚完成了机器学习课程，所以我的机器学习知识范围包括线性回归、逻辑回归、优化损失函数、支持向量机和用于分类问题的 KNN、决策树、朴素贝叶斯、一些基本神经网络等。我还能够阅读研究论文。 作为一名数学专业的学生，​​我的课程作业都是理论性的（ML 实际上是我的第三门应用/非理论课程，我实际上在不到一周的时间内就毕业了 xD），所以我的难度更大有一天，我会提出一个适用的问题，帮助我为行业做好准备，而不是像我迄今为止一直在做的机器学习作业那样的问题。   由   提交/u/ekta980  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm5rym/p_need_help_with_project_ideas/</guid>
      <pubDate>Tue, 07 May 2024 07:04:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 快速推理如何与最先进的法学硕士一起工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm4h4i/d_how_does_fast_inference_work_with_state_of_the/</link>
      <description><![CDATA[我读到 Llama-2 70B 等模型的推理速度最多约为 10 t/s。所以这让我想知道像 GPT-4（1T 参数？）这样的超大型模型是如何进行快速 20 t/s 推理的。使用 10 倍的参数，它们必须至少有 3 倍的层（？），所以这应该会使其推理速度慢得多。我错过了什么吗？这些公司可能会做哪些进一步的改进来支持他们的快速 API？ 编辑：我必须提到，当数据必须通过模型时，您无法跨 GPU 并行化来帮助解决单个示例的延迟问题 由于模型尺寸较大，模型并行性及其 GPU 间通信应该会使其变得更慢......  &amp;# 32；由   提交/u/Fit-Flow-4180   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm4h4i/d_how_does_fast_inference_work_with_state_of_the/</guid>
      <pubDate>Tue, 07 May 2024 05:36:40 GMT</pubDate>
    </item>
    <item>
      <title>关于构建AI GPU集群节点的担忧 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1clzh29/concerns_regarding_building_out_nodes_for_ai_gpu/</link>
      <description><![CDATA[以下是我所在地区可用的一些选项，我想选择 2011 年，因为 CPU 的性价比非常高核心和线程，因此有 2 个平台：X79 和 X99。 DDR3 比 DDR4 便宜得多，尽管性能几乎没有下降，但 x99 主板仅配备 DDR4，没有任何 DDR3 主板。至于 GPU，我选择了 mi50 16gb，因为它在这里的售价仅为 130 美元左右。经过一番研究后，我发现： 担忧：  我打算进行视频生成模型训练，但我仍然相对不确定是否可以RAM 非常重要，似乎拥有大量 RAM 您可以在磁盘上执行更少的流数据，并将其卸载到 Ram 以便从 GPU 更快地访问。如果你不这样做，我认为这只会阻碍数据读取速度？ 至于存储数据，我不知道我是否真的需要为此构建一个存储集群？似乎也可以将数据传输到节点，尽管速度会很慢？或者可能只是进行数据切片，以便数据量对于任何节点来说都不会太大？我是否可以先用 10TB 数据进行训练，然后因为我的磁盘已满，删除当前批次数据并获取另外 1OTB 数据然后继续训练，这可能吗？ 至于 MI50 作为好吧，看来 rocm 已经放弃了对这张卡的支持，我打算使用 Zluda，基本上是 AMD CUDA 之上的嵌入式驱动程序，它使用 Rocm 5.7，这会影响 GPU 的稳定性吗？如果我使用 Zluda 在 Pytorch 上进行训练，所有这些？  选项#1：可能 Ram 受限但更少？  主要：X79 5 插槽 3.0 x8&lt; /li&gt; 内存：32gb DDR3 CPU：2696v2 GPU：5x MI50 16GB  选项 #2：- 内存受限?  主机：X79 9 插槽 3.0 x8 内存：32gb DDR3 CPU：双 2696v2 GPU：9x MI50 16GB  选项 #3：Pcie 通道受限？  主：X79 8 插槽 2.0 * x1 内存：64gb DDR3  CPU：双 2696v2 GPU：8 个 Mi50 16GB    由   提交 /u/Ok_Difference_4483   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1clzh29/concerns_regarding_building_out_nodes_for_ai_gpu/</guid>
      <pubDate>Tue, 07 May 2024 01:07:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 参与补助金</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cloxpt/d_icml_participation_grant/</link>
      <description><![CDATA[作为加拿大的一名博士生，并在 ICML 上发表了一篇已被接受的论文，我对参加这些昂贵的会议的资金选择感到好奇。虽然我的主管承担了一些费用，但总费用可达 3500-4000 加元，其中包括 700 加元的注册费。是否有其他外部资金来源可用于支付剩余费用？   由   提交/u/Personal_Click_6502   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cloxpt/d_icml_participation_grant/</guid>
      <pubDate>Mon, 06 May 2024 17:33:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 羊驼 3 怪物</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cljvpa/d_llama_3_monstrosities/</link>
      <description><![CDATA[我刚刚注意到有人通过将 Llama 3 与自身合并（最终结果重复了 60/80 层）创建了 120B Instruct 变体 Llama 3。他似乎专攻这些弗兰肯斯坦模型。就我而言，我真的不明白这种趋势。使用 mergekit 创建这些模型非常容易，我很好奇它们在野外的商业效用。Bud 甚至承认它并不比 GPT-4 更好。那么重点是什么？哦，等等，他在帖子的结尾提到他将其提交给了 Open LLM Leaderboard...我们开始了。LLM 排行榜攀升的游戏化令人疲倦。    提交人    /u/Objective-Camel-3726   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cljvpa/d_llama_3_monstrosities/</guid>
      <pubDate>Mon, 06 May 2024 14:04:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] LeRobot：Hugging Face 的现实世界机器人库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cldfy2/p_lerobot_hugging_faces_library_for_realworld/</link>
      <description><![CDATA[      认识一下 LeRobot，一个库托管最先进的机器人深度学习。 人工智能开发的下一步是将其应用到我们的物理世界。因此，我们正在围绕机器人人工智能构建社区驱动的工作，并且向所有人开放！ 看一下代码： https://github.com/huggingface/lerobot https://preview.redd.it/ugf4l8lfgryc1.png?width=3794&amp;format=png&amp;auto=webp&amp;s=222825e897ba48eb07acedffb0662d5794af04 e8 乐机器人是对于机器人技术来说，就像 Transformers 库对于 NLP 一样。它提供了带有预先训练的检查点的高级人工智能模型的干净实现。我们还重新实现了来自学术界的 31 个数据集和一些模拟环境，无需物理机器人即可开始使用。 Aloha项目。 [视频链接] https://preview.redd.it/86ihkcwhgryc1.png?width=2506&amp;format=png&amp;auto=webp&amp;s=4f2ca7522a012d00d7327d903 35d069dd099a321 LeRobot 的另一个可视化，这次是在 Mobile Aloha 数据上，学习完全端到端的导航和操作。这两个数据集都是在 trossenrobotics 机器人手臂上收集的。 [视频链接] https://preview.redd.it/qqtncqligryc1.png?width=1900&amp;format=png&amp;auto= webp&amp;s=4f83c675b5c6f9dbded4b5b90a7a1c9f531c4086 LeRobot 代码库已通过在模拟中复制最先进的结果进行了验证。例如，这里是著名的 ACT 策略，它已被重新训练并可用作预训练检查点： [HF HUB 链接] LeRobot 还具有扩散政策，强大的模仿学习算法，以及TDMPC，一种包含世界模型的强化学习方法，不断从与环境的交互中学习。 https://preview.redd.it /br9ibrylgryc1.png?width=1684&amp;format=png&amp;auto=webp&amp;s=8e5595f1dff5381e5f60c6776126f48187ec58d9 快来加入我们的Discord 频道。我们正在建立一个来自不同背景、软件和硬件的多元化社区，以开发现实世界中的下一代智能机器人！ 感谢人工智能和机器人社区，没有他们就没有乐机器人。可能。   由   提交/u/Tamazy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cldfy2/p_lerobot_hugging_faces_library_for_realworld/</guid>
      <pubDate>Mon, 06 May 2024 07:48:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kolmogorov-Arnold 网络只是一个 MLP</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1clcu5i/d_kolmogorovarnold_network_is_just_an_mlp/</link>
      <description><![CDATA[事实证明，您可以将 Kolmogorov-Arnold 网络编写为 MLP，并在 ReLU 之前进行一些重复和移位。  https://colab.research.google.com/drive/1v3AHz5J3gk-vu4biESubJdOsUheycJNz &lt; /div&gt;  由   提交 /u/osamc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1clcu5i/d_kolmogorovarnold_network_is_just_an_mlp/</guid>
      <pubDate>Mon, 06 May 2024 07:04:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 Gemma 有如此疯狂的大 MLP 隐藏暗尺寸？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1clcluq/d_why_gemma_has_such_crazy_big_mlp_hidden_dim_size/</link>
      <description><![CDATA[   /u/kiockete  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1clcluq/d_why_gemma_has_such_crazy_big_mlp_hidden_dim_size/</guid>
      <pubDate>Mon, 06 May 2024 06:48:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如果 Llama-3 只有 8K 上下文长度，为什么它可以使用 32K 上下文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1clbmz2/r_why_can_llama3_work_with_32k_context_if_it_only/</link>
      <description><![CDATA[大家好！请参阅此处的帖子：https://twitter.com/abacaj/status/1785147493728039111 我没有不明白他所说的“通过零训练（实际上只是一个简单的 2 行配置），你可以从 llama-3 模型中获得 32k 上下文”的意思 有人知道这个动态是什么吗？缩放技巧是？非常感激！ :)   由   提交 /u/sunchipsster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1clbmz2/r_why_can_llama3_work_with_32k_context_if_it_only/</guid>
      <pubDate>Mon, 06 May 2024 05:43:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>