<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 09 Apr 2024 06:17:57 GMT</lastBuildDate>
    <item>
      <title>[D] 您如何公平地比较 SGD 与带有梯度裁剪的 RMSProp？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzjxe5/d_how_would_you_fairly_compare_sgd_vs_rmsprop/</link>
      <description><![CDATA[嗨！我目前正在进行有关法学硕士的研究。我试图比较两个经过不同训练的模型的性能。这两个模型使用相同的参数进行初始化。使用带有梯度裁剪和 RMSProp 优化器的某种损失函数来训练一个模型。另一个模型使用带有梯度裁剪的特定参数更新规则进行训练（这样对于每个训练步骤，我们裁剪参数更新方向的 l2 范数）。问题是，即使我将两个模型的学习率设置为相同，我最终也会得到不同的“有效”学习率，因此生成的两个模型与其初始模型参数的 l2 距离显着不同。原因是，使用梯度裁剪和 RMSProp 优化器训练模型将显着提高有效学习率，因为我们的二阶矩梯度移动平均值很小（由于梯度裁剪）。例如，在训练从相同参数初始化的两个模型后，通过 RMSProp 训练的模型将移动约 0.23（以参数的 l2 距离而言），而另一个模型仅移动 0.0059。  在两个模型之间强制执行相等的有效学习率的公平方法是什么？ 我认为一种方法是删除两个模型的梯度裁剪，但是局限性在于梯度裁剪似乎是训练法学硕士的标准做法。您将如何解决这个问题？   由   提交/u/jonny_trane  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzjxe5/d_how_would_you_fairly_compare_sgd_vs_rmsprop/</guid>
      <pubDate>Tue, 09 Apr 2024 05:01:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 没有指数数据就没有“零样本”：预训练概念频率决定多模态模型性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzjbpn/r_no_zeroshot_without_exponential_data/</link>
      <description><![CDATA[      摘要 &lt; blockquote&gt; 网络爬取的预训练数据集是令人印象深刻的“零样本”的基础。评估多模态模型的性能，例如用于分类/检索的 CLIP 和用于图像生成的稳定扩散。然而，目前尚不清楚“零样本”概念的意义有多大。泛化是针对这种多模态模型的，因为不知道它们的预训练数据集在多大程度上包含“零样本”过程中针对的下游概念。评估。在这项工作中，我们问：预训练数据集中这些概念的频率如何影响多模态模型在下游概念上的性能？我们在 34 个模型和 5 个标准预训练数据集（CC-3M、CC-12M、YFCC-15M、LAION-400M、LAION-Aesthetics）中全面研究了这个问题，生成了超过 300GB 的数据工件。我们一致发现，远非表现出“零射击”，而是表现出“零射击”。概括地说，多模态模型需要指数级更多的数据来实现下游“零样本”的线性改进。性能，遵循样本低效对数线性缩放趋势。即使在控制预训练和下游数据集之间的样本级相似性以及对纯合成数据分布进行测试时，这种趋势仍然存在。此外，根据我们的分析对采样的长尾数据进行基准测试模型，我们证明多模态模型整体表现不佳。我们将此长尾测试集贡献为“Let it Wag！”为进一步研究该方向奠定了基础。综上所述，我们的研究揭示了对训练数据的指数级需求，这意味着“零样本”的关键在于训练数据。大规模训练范式下的泛化能力仍有待发现。  ​ 概念频率与 T2I 审美分数之间的对数线性关系。 论文：&lt; /strong&gt; https://arxiv.org/pdf/2404.04125.pdf 项目： https://github.com/bethgelab/Frequency_definees_performance&lt; /a&gt; 数据集： https:// Huggingface.co/datasets/bethgelab/Let-It-Wag ​ ​   由   提交/u/quequero  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzjbpn/r_no_zeroshot_without_exponential_data/</guid>
      <pubDate>Tue, 09 Apr 2024 04:27:46 GMT</pubDate>
    </item>
    <item>
      <title>[D]寻求建议：将聊天消息分类为任务的简单快速的解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzifv6/dseeking_advice_simple_and_fast_solution_for/</link>
      <description><![CDATA[我正在构建一个知识管理系统。我已经分别实现了每个单独的功能。由于单独访问所有内容很麻烦，因此我决定使用带有函数调用的聊天界面。我目前使用 Mistral 8x7b 4 位量化版本作为我的法学硕士。然而，由于硬件限制，直接执行函数调用速度很慢，并且不能给出预期的结果。 然后，我决定使用语义路由器结合 OpenAI 的 Ada 模型对每个输入进行分类，以确定哪个任务它属于然后发送给LLM以提取相关信息。这种方法效果很好，但由于我打算使用本地解决方案，因此 OpenAI 的模型不是一个选择。 我尝试使用本地模型，但速度越快的结果效果越差，而效果越好的速度就越慢。有没有简单快速的解决方案可以将聊天消息分类到适当的任务中？我当前的任务包括图像搜索、检索增强生成（RAG）、文档摘要和文档搜索。 我想到使用传统的机器学习方法（如 TF-IDF、梯度提升、逻辑回归）构建一个简单的分类器等等。这行得通吗？以前有人做过这种工作吗？提前致谢。   由   提交/u/Gon_Buruwa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzifv6/dseeking_advice_simple_and_fast_solution_for/</guid>
      <pubDate>Tue, 09 Apr 2024 03:40:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] NLP训练/微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzi5sc/p_nlp_trainingfine_tuning/</link>
      <description><![CDATA[大家好，寻求一些建议。  我有一个用例，我需要弄清楚如何最好地解决该问题。我目前的经历将在底部详细介绍。 我正在帮助某人收集针对跟踪者的证据。包含 300 多张消息截图，涵盖文本、Gmail 电子邮件、Instagram 消息等。我创建了一些脚本来将图像转换为文本，并从数据中获取文本和日期。  现在，我需要使用 NLP 模型来帮助我摆脱无用的文本。例如 Gmail 中的“您不经常收到来自 ______ 的电子邮件”之类的消息。  我的目标是在我的数据中只包含人与人之间的信息，并消除所有无意义的文本。我怎样才能最好地让机器了解它应该摆脱什么以及应该保留什么。微调特定模型？如果是这样，我该怎么办？我应该创建自己的训练数据，其中 80% 是训练，20% 是验证吗？您知道有什么东西可以做到这一点吗？任何建议对我都很有用，包括我可以用来搜索和了解有关解决此特定用例的更多信息的好关键字。预先感谢！ 我目前的经验水平：我已经断断续续地阅读了机器学习的介绍，但尚未深入（我还没有做过自己的实际训练或微调或任何东西）除了遵循介绍教程之外。但我一直对学习感兴趣，现在我有了理由！    提交者   &lt; a href=&quot;https://www.reddit.com/user/piggiesinthehoosgow&quot;&gt; /u/piggiesinthehoosgow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzi5sc/p_nlp_trainingfine_tuning/</guid>
      <pubDate>Tue, 09 Apr 2024 03:26:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 就 RAG 研究而言，为什么似乎很多人没有致力于猎犬的研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzfxgm/d_in_terms_of_rag_research_why_does_it_seem_like/</link>
      <description><![CDATA[我是几年前进行 NLP 研究的人，后来停止并加入了行业，最近试图重新掌握事物。我对 RAG 相关的工作很感兴趣，并开始阅读一些论文。 我的理解是，对于 RAG，你有检索器和生成器。对于生成器来说，使用各种 LLM 似乎是标准的，但检索器似乎也设置为使用 BM25 或最初使用的 DPR 之类的东西。我认为 RAG 的性能将在很大程度上依赖于检索器，但我也有点惊讶地发现似乎没有在这方面进行大量研究。 我只是错误并且没有看向正确的方向？或者说，检索器似乎没有得到那么多关注是有什么原因吗？ 想想看，我并没有真正看到编码器模型总体上做了很多工作。    由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzfxgm/d_in_terms_of_rag_research_why_does_it_seem_like/</guid>
      <pubDate>Tue, 09 Apr 2024 01:38:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 高效扩散模型中缺失的 U</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzfns4/r_the_missing_u_for_efficient_diffusion_models/</link>
      <description><![CDATA[一篇新论文提出用利用神经常微分方程的连续 U-Net 取代扩散模型中的标准离散 U-Net 架构。这种重新表述可以对去噪过程进行连续建模，从而显着提高效率：  推理速度提高 80% 模型参数减少 75% 70% 保持或提高图像质量  关键技术贡献：  动态神经 ODE 模块建模潜在表示演化使用二阶微分方程 自适应时间嵌入来调节扩散时间步长的动力学 高效的 ODE 求解器和常量内存伴随方法，可实现更快、内存效率更高的训练 &lt; /ul&gt; 作者展示了这些在图像超分辨率和去噪任务上的改进，并通过详细的数学分析解释了为什么连续公式会导致更快的收敛和更有效的采样。 潜在影响： p&gt;  使扩散模型适用于更广泛的应用（实时工具、资源受限设备） 在深度学习、微分方程、动力学的交叉领域开辟新的研究方向系统  存在一些局限性：(1) ODE 求解器和伴随方法增加了复杂性，(2) 我认为即使进行了改进，扩散模型仍然可能需要大量计算。 &lt; p&gt;完整摘要此处。 Arxiv 此处。 TL;DR：新论文建议替换离散 U-使用神经 ODE 的连续 U-Net 扩散模型中的网络，可将推理速度提高 80%、参数减少 75%、FLOP 减少 70%，同时保持或提高图像质量。主要影响：更高效、更容易理解的生成模型、连续时间深度学习的新研究方向。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/1bzfns4/r_the_missing_u_for_efficient_diffusion_models/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzfns4/r_the_missing_u_for_efficient_diffusion_models/</guid>
      <pubDate>Tue, 09 Apr 2024 01:26:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] LightGBM 算法问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bzcgw7/d_lightgbm_algo_question/</link>
      <description><![CDATA[GBDT 算法帮助 嘿，我知道创建传统决策树时需要某种损失函数，例如均方误差 - 你扫描预测空间并找到最小化 MSE 的分割，这就是递归二元分割所实现的，直到达到某种停止标准。我也明白，如果要进行分割，您可以使用该区域中所有预测的平均值找到每个区域的新 MSE，这就是您如何确定是否进行分割的方法。 我目前正在学习提升，现在明白这个过程是相似的，但我们现在基于残差构建一棵树。过程完全相同吗？ 我一直在观看一些 statquest，这是 boosting 的通用算法 https://i.imgur.com/DudpZ5S.png 我正在努力理解 B) 和 C) 之间的区别。在 B 中，我们通过基于一些损失函数（如 MSE）进行递归二元分割来将回归树拟合到残差值（r_i_m）？但是对于 C 部分，我们在节点（称为 gamma）计算这些残差，这也最小化了损失函数？这不是我们在 B 部分所做的吗，因为我们取每个分割点残差的平均值，看看它是否最小化了我们的损失函数。 正如你所知，有点困惑，谢谢- 感谢任何帮助！   由   提交 /u/PencilSpanker   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bzcgw7/d_lightgbm_algo_question/</guid>
      <pubDate>Mon, 08 Apr 2024 23:05:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您的研究技术堆栈是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bz8pym/d_what_is_your_tech_stack_for_research/</link>
      <description><![CDATA[我计划进行文本+音频的大型多模态训练（1B 参数）。截至目前，我正在考虑使用 pytorch、deepspeed、wandb。对于分布式大型模型训练，您有什么建议以及一般使用什么？ 您使用 Hughginface 吗？我觉得它有点太包裹了，以至于接触到裸露的主干会变得混乱，但还没有进行适当的尝试。对于现成的模型和自定义数据集训练，这听起来确实很有用，但研究需要的不仅仅是这些。那么，您在研究方面的经验如何，您需要灵活地改变模型？一般来说，您在研究方面的技术堆栈是什么？   由   提交/u/gokulPRO  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bz8pym/d_what_is_your_tech_stack_for_research/</guid>
      <pubDate>Mon, 08 Apr 2024 20:38:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] LegalKit 检索，使用标量 (int8) 的二分搜索通过法国法律代码重新评分</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bz673f/p_legalkit_retrieval_a_binary_search_with_scalar/</link>
      <description><![CDATA[      此空间展示了 Louis Brulé Naudet 的 tsdae-lemone-mbert-base 模型，这是一个句子嵌入模型基于 BERT，使用基于 Transformer 的序列去噪自动编码器进行无监督句子嵌入学习，其目标只有一个：法国法律领域适应。 这一过程旨在提高内存效率和速度，二进制索引为小到足以容纳内存，并且 int8 索引作为视图加载以节省内存。此外，二进制索引的搜索速度比 float32 索引快得多（高达 32 倍），而重新评分也非常高效。 链接到 🤗 Space ：https://huggingface.co/spaces/louisbrulenaudet/legalkit-retrieval LegalKit 检索缩略图。  &amp; #32；由   提交/u/louisbrulenaudet  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bz673f/p_legalkit_retrieval_a_binary_search_with_scalar/</guid>
      <pubDate>Mon, 08 Apr 2024 19:02:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 促进离策略学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bz2cig/p_boosted_offpolicy_learning/</link>
      <description><![CDATA[        由   提交 /u/ggyshay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bz2cig/p_boosted_offpolicy_learning/</guid>
      <pubDate>Mon, 08 Apr 2024 16:29:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于那些独自发表文章的人来说，你们的经历是怎样的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byzggt/d_for_those_of_you_who_have_published_alone_what/</link>
      <description><![CDATA[这些天我有一些空闲时间，一直在努力赶上我所在领域的研究。我想真正重新审视我在硕士期间正在研究的一个主题，但始终无法发表论文。问题是，我不确定作为唯一作者，如果没有任何真正的资源访问权限，这是否可行。 朋友和熟人告诉我这是可能的，但极其困难。很好奇其他成功做到这一点的人是怎么想的。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byzggt/d_for_those_of_you_who_have_published_alone_what/</guid>
      <pubDate>Mon, 08 Apr 2024 14:35:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] DBRX 是专门为企业设计的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byxqy6/d_is_dbrx_specifically_made_for_businesses/</link>
      <description><![CDATA[我了解到 Databricks 推出了名为 DBRX 的新通用 LLM。我很好奇它与其他法学硕士有何不同（除了开源之外）？ 它是专门为企业还是供公众使用而设计的，例如 chatgpt？或者它是否像“企业聊天”？他们可以在哪里微调开源模型以满足他们的需求？   由   提交/u/Ok_Moment4946   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byxqy6/d_is_dbrx_specifically_made_for_businesses/</guid>
      <pubDate>Mon, 08 Apr 2024 13:22:40 GMT</pubDate>
    </item>
    <item>
      <title>“clip-vit-large-patch14”如何将文本序列表示聚合成表示整个序列的奇异向量？没有 [CLS] 代币，但有 [SOT] 和 [EOT] 代币。 [研究]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byxg7u/how_does_clipvitlargepatch14_aggregate_the_text/</link>
      <description><![CDATA[大家好， 我有以下问题： “clip-vit-large-patch14”如何;将文本序列表示聚合成表示整个序列的奇异向量？没有 [CLS] 标记，但有 [SOT] 和 [EOT] 标记。 当我使用 CLIP 文本编码器并提取 pooler_output 时……这个向量到底是如何创建的？ [SOT] 代币是否用作 [CLS] 代币？或者是否进行了池化操作？ [研究] 此致， Tom  &amp; #32；由   提交/u/tommilyjonesOG   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byxg7u/how_does_clipvitlargepatch14_aggregate_the_text/</guid>
      <pubDate>Mon, 08 Apr 2024 13:09:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 确保加拿大的人工智能优势</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bytkh8/d_securing_canadas_ai_advantage/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bytkh8/d_securing_canadas_ai_advantage/</guid>
      <pubDate>Mon, 08 Apr 2024 09:28:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>