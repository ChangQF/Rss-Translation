<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 03 Feb 2024 15:12:03 GMT</lastBuildDate>
    <item>
      <title>[D] 关于 ICML 2024 提交时间表的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahxe7t/d_questions_on_icml_2024_submission_timeline/</link>
      <description><![CDATA[大家好！ 由于这是我第一次向 ICML 提交：  不知道什么时候会发布评论吗？在neurips和iclr中，论文征集中有信息，但我在今年的icml截止日期内找不到某事 我们给作者回复多少时间？和iclr一样长吗？ 我们可以上传新草稿还是只能通过文字回复？  谢谢！&lt; /p&gt;   由   提交/u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahxe7t/d_questions_on_icml_2024_submission_timeline/</guid>
      <pubDate>Sat, 03 Feb 2024 14:32:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 和像 ChatBot 这样接受数据（而非规模）训练的基本应用程序之间有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahx7ue/d_what_is_the_difference_between_a_llm_and_a/</link>
      <description><![CDATA[具体是如何实现的？   由   提交 /u/Muurda2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahx7ue/d_what_is_the_difference_between_a_llm_and_a/</guid>
      <pubDate>Sat, 03 Feb 2024 14:23:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2024 年 1 月研究论文：模型合并、专家混合、迈向小型法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahwint/p_research_papers_in_jan_2024_model_merging/</link>
      <description><![CDATA[       由   提交/u/seraschka  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahwint/p_research_papers_in_jan_2024_model_merging/</guid>
      <pubDate>Sat, 03 Feb 2024 13:49:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 计算机视觉模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahugcq/p_computer_vision_models/</link>
      <description><![CDATA[所有计算机视觉模型现在都支持微调，您可以与 Note 并行训练它们。 https://github.com/NoteDance/Note/tree/Note-7.0/Note/nn/neuralnetwork 教程在这里：https://github.com/NoteDance/Note   由   提交 /u/NoteDance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahugcq/p_computer_vision_models/</guid>
      <pubDate>Sat, 03 Feb 2024 11:51:53 GMT</pubDate>
    </item>
    <item>
      <title>Cnn 中的批量归一化 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahst3a/batch_norm_in_cnn_d/</link>
      <description><![CDATA[我正在编写 GAN，当谈到生成器时，我发现大多数实现都包含批量归一化，但不在神经网络的第一层，有人可以解释为什么吗它没有被使用？为什么第一层的步幅通常小于其他层？   由   提交/u/predictor_torch  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahst3a/batch_norm_in_cnn_d/</guid>
      <pubDate>Sat, 03 Feb 2024 10:01:21 GMT</pubDate>
    </item>
    <item>
      <title>关于 GAN 的“[讨论]”问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahrrip/discussion_question_about_gans/</link>
      <description><![CDATA[有人能解释一下为什么判别器中使用 LeakyReLU，生成器中使用 ReLU 吗？   由   提交/u/predictor_torch  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahrrip/discussion_question_about_gans/</guid>
      <pubDate>Sat, 03 Feb 2024 08:49:24 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]如何听机器学习论文PDF</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahrri3/discussion_how_to_listen_to_machine_learning/</link>
      <description><![CDATA[对于那些已经成功使用文本转语音或其他人工智能工具来收听机器学习论文 PDF 的人 (作为听播客的有效替代方案......）。很大程度上，我想到的是来自 NeurIPS、ICML、AISTATS 等会议的 arXiv 论文。 关于应用程序方面最适合您的任何技巧或提示，以及最大化听力的任何其他建议（和学习）经验？ 我一直在尝试通用的文本到语音阅读器，但似乎这是一个有点小众的应用程序（阅读器需要处理数学、纸张布局等），所以我想知道如果有比通用阅读器更好的解决方案，尤其是现在法学硕士时代。   由   提交/u/emiurgo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahrri3/discussion_how_to_listen_to_machine_learning/</guid>
      <pubDate>Sat, 03 Feb 2024 08:49:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 康威的生命游戏作为神经网络的实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahqs0n/p_conways_game_of_life_implement_as_a_neural/</link>
      <description><![CDATA[       由   提交/u/liMrMil  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahqs0n/p_conways_game_of_life_implement_as_a_neural/</guid>
      <pubDate>Sat, 03 Feb 2024 07:41:40 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 梯度下降的最佳矩阵乘法算法。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahoo9q/project_the_best_matrix_multiplication_algorithm/</link>
      <description><![CDATA[我正在尝试用 0 个依赖项在 Rust 中实现神经网络。我知道施特拉森只擅长高排名，并且错误增加（来源是极客中的极客，所以可能是可疑的）。不管怎样，我想知道我应该使用什么算法来进行矩阵乘法，以及它是否会产生很大的差异。   由   提交 /u/ANARCHY14312   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahoo9q/project_the_best_matrix_multiplication_algorithm/</guid>
      <pubDate>Sat, 03 Feb 2024 05:29:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在这里没有看到足够多的人赞扬 dinov2 ！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahkxjh/d_i_dont_see_enough_people_praising_dinov2_here/</link>
      <description><![CDATA[大家好！ 我只是想写一条简短的消息，让这里的每个人都知道 dinov2 是一个多么强大的工具对我来说！我已经对其进行了微调，可以对图像进行多种不同目的的分类，并且每次类只有 20-50 张图像，它总是很成功。根据我使用它的用例：对 3D/照片图像进行分类，带水印/无水印图像、模糊/非模糊图像、面部识别（识别 dlib 对齐的面部是否特定属于某个人）、艺术家风格、验证图像中特定对象上方的分割是否正确等等。 .. 在 dinov2 的整个系列中，我从未使用过比小型模型更大的东西（尽管我使用 448x448 图像），因此它无需使用太多 VRAM 即可工作，并且可以批量处理 100 个图像一次！ 最近我什至尝试在暹罗架构中对 dinov2 进行微调，只用一个新的头部来获取两个图像的特征，这样它就可以将两个图像放在一起比较（不用说太多，我想知道是否两者都图像遵循共同的结构）并且它工作得很好。 我还使用它来将图像的特征提供给稳定扩散，并且它也工作得很好（使用 IP 适配器架构）。 &gt; 我唯一没能做到的就是使用它进行分割，但我认为这是因为我的数据集和/或实现，所以如果你们中有人做到了，我很想与你们交谈交流良好实践！ 如果您希望脚本对其进行微调/推理以进行分类，我很乐意分享它们。 您呢？你用 dinov2 吗？如果是，为什么以及如何？您对此有何体验？   由   提交 /u/Antique-Bus-7787   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahkxjh/d_i_dont_see_enough_people_praising_dinov2_here/</guid>
      <pubDate>Sat, 03 Feb 2024 02:08:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] Graph-Mamba：利用选择性状态空间进行长范围图序列建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahgxsh/d_graphmamba_towards_longrange_graph_sequence/</link>
      <description><![CDATA[ 由   提交/u/314kabinet  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahgxsh/d_graphmamba_towards_longrange_graph_sequence/</guid>
      <pubDate>Fri, 02 Feb 2024 23:00:16 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ML 测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahg65l/discussion_testing_in_ml/</link>
      <description><![CDATA[你好， 我目前正在研究一组计算机视觉模型，该模型应该足够通用，可以在各种数据集。这些模型在理想情况下是不断发展的，但确保性能提高是有问题的。因此，我想开始讨论，或者更好地询问您在 ML 管道测试方面有什么经验。我认为由于训练和建模的随机性，这个字段在机器学习中被忽略了。 你如何测试你的训练脚本？ 你如何测试你的模型？&lt; /p&gt; 单元测试足够了吗？ 你在生产中使用某种形式的主动学习或逐步改进吗？  &amp; #32；由   提交 /u/UpvoteBeast   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahg65l/discussion_testing_in_ml/</guid>
      <pubDate>Fri, 02 Feb 2024 22:27:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我正在为此子创建一个审核分类器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahag9e/p_im_creating_a_moderation_classifier_for_this_sub/</link>
      <description><![CDATA[每次有人抱怨这个子站的帖子质量低下时，总会有人指出讽刺的是，如果有人只训练一个分类器，这个问题就很容易解决过滤掉应该转到 r/singularity 或 r/learnmachinelearning，并且这个子模块中的人绝对应该有能力做到这一点。我厌倦了等待别人来做这件事，所以我编译了这个 Reddit 子版块的最后 984 篇帖子的数据集。 json 文件文本的链接位于： https: //drive.google.com/file/d/1vh9xh-4z3w4L_fL8T8nXI5Bwnm10FUSc/view?usp=sharing ​ 数据集当前未注释，并且如果有人对此有强烈的感觉（比如那些不断发帖的人），我欢迎任何帮助注释它。任何人都可以编辑 json 文件的文本，因此如果您想帮助注释，只需在 google docs 中打开它并将 is_beginner=&quot;&quot; 替换为 is_beginner=“0” 如果您认为该帖子是应该保留的类型，或者 is_beginner=“1”  p&gt; 如果你认为它不属于这个子 ​ 984 个帖子对于一个玩具示例来说可能就足够了，但我们可能需要如果我们想要良好的准确性，以获得更多数据。 reddit api 只允许你获取 1000 个最新帖子，并且有解决方法，但还没有费心去尝试解决这个问题。这里的瓶颈当然是注释。我想过通过扫描诸如“这属于 r/learnmachinelearning”之类的注释来自动化注释，但是有很多误报，这似乎比仅仅要求人类帮助注释更麻烦。 一旦注释完毕，我可能会尝试几种不同的架构，但如果有人有任何建议或想要就此进行合作我很欢迎。   由   提交 /u/theLanguageSprite   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahag9e/p_im_creating_a_moderation_classifier_for_this_sub/</guid>
      <pubDate>Fri, 02 Feb 2024 18:24:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 运行基线的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ah3qil/r_tools_for_running_baselines/</link>
      <description><![CDATA[根据我的经验，实施研究是研究中最糟糕的部分。大学不仅缺乏计算能力，调试机器学习代码也很困难，而且没有实施基线/其他人实验的标准。有些论文从未发布其完整的代码库和重现结果的说明，即使两篇论文在同一数据集上进行评估，它们的数据整理/模型代码也可能完全不同。我最终花了几周的时间才让所有东西都能一起工作。对新数据集进行评估甚至更糟糕，因为您最终不得不进行疯狂的超参数鹅追逐以确保设置公平。 人们运行基线的技术是什么？或者是否没有比自己手动完成所有工作或希望有人已经在另一个项目存储库中完成大部分工作更好的方法了？   由   提交/u/like_a_tensor  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ah3qil/r_tools_for_running_baselines/</guid>
      <pubDate>Fri, 02 Feb 2024 13:31:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>