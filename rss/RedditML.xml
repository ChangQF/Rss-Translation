<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 28 May 2024 09:15:02 GMT</lastBuildDate>
    <item>
      <title>[D] 如何在 pytorch 模型上运行并发推理？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2dsz1/d_how_to_run_concurrent_inferencing_on_pytorch/</link>
      <description><![CDATA[大家好， 我有几个用于验证图像的 pytorch 模型，我想部署它们到一个端点。我使用快速 api 作为 API 包装器，到目前为止我将完成我的开发过程： 之前我运行了一个简单的 OOTB 推理，如下所示： model = Model() @app.post(&#39;/model/validate/&#39;): pred = model.forward(img) return {&#39;pred&#39;:pred}  问题这种方法的缺点是它无法处理并发流量，因此请求会排队并且推理一次会发生 1 个请求，这是我想避免的事情。 我当前的实现如下：制作模型对象的副本，并派生一个新线程来处理特定图像。有点像这样： model = Model() def validate(model, img): pred = model.forward(img) return pred @app.post(&#39;/model/validate/&#39;) : model_obj = copy.deepcopy(model)loop = asyncio.get_event_loop() pred =awaitloop.run_in_executor(validate, model_obj, img) return {&#39;pred&#39; : pred}  这种方法制作模型对象的副本并在对象副本上进行推理，这样我就可以服务并发请求。 我的问题是，是否有另一种更优化的方法可以实现 pytorch 模型并发，或者这是一种有效的做事方式吗？ TLDR：使用模型对象的副本创建新线程以实现并发，还有其他方法来实现并发吗？   由   提交/u/comical_cow  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2dsz1/d_how_to_run_concurrent_inferencing_on_pytorch/</guid>
      <pubDate>Tue, 28 May 2024 07:33:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在原始 HTML 上执行 NER 的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2c3ti/p_resources_for_performing_ner_on_raw_html/</link>
      <description><![CDATA[大家好，我正在开发一个个人项目，希望从原始 HTML 数据中识别特定实体。 我在网上查过这个，但只看到了我高中四年级时（很久以前）的一些存储库，它们没有帮助。因此，我在这里联系，看看是否有人知道我应该从哪些资源或地方开始。 更一般地说，我想我要解决的问题是微调/使用语言数据训练法学硕士，这些数据不具有我们在从 PDF/文章中提取的可读、合理文本中看到的传统结构。 非常感谢。 &lt;!-- SC_ON - -&gt;  由   提交 /u/edubzki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2c3ti/p_resources_for_performing_ner_on_raw_html/</guid>
      <pubDate>Tue, 28 May 2024 05:35:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 泊松变分自动编码器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2bhmw/r_poisson_variational_autoencoder/</link>
      <description><![CDATA[预印本：https://arxiv.org/abs/2405.14473 X 线程摘要：https://x.com/hadivafaii/status/1794467115510227442    提交人    /u/vafaii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2bhmw/r_poisson_variational_autoencoder/</guid>
      <pubDate>Tue, 28 May 2024 04:56:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] SAR 和光学图像的多模态图像分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d23awr/d_multimodal_image_classification_for_sar_and/</link>
      <description><![CDATA[你好！ 在过去的几周里，我一直在尝试使用 SAR 和光学图像，但由于代码中的错误，我无法对其进行训练。 我觉得我在理论和实践方面都缺乏有关该主题的大量信息，其中我可以学习编写这样的模型吗？ 提前致谢！   由   提交 /u/Icy_Dependent9199   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d23awr/d_multimodal_image_classification_for_sar_and/</guid>
      <pubDate>Mon, 27 May 2024 21:49:37 GMT</pubDate>
    </item>
    <item>
      <title>[P] DARWIN - 开源 Devin 替代品带着更新回来了</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d219rl/p_darwin_opensourced_devin_alternative_is_back/</link>
      <description><![CDATA[达尔文带着另一次更新回来了🦾。 那么，本周有什么新内容？本周我们强调了提高 DARWIN 理解现有项目的能力，这些项目是在没有 DARWIN 帮助的情况下编写的，并且脱离了上下文。由于上下文长度是一个挑战，DARWIN 有效地映射了存储库结构并提取了保留足够上下文的类和函数签名。 除此之外，我们还收到了大量要求在更安全的环境中运行 DARWIN 的请求，因此我们有发布了前端和后端的 docker，您可以从存储库或 docker hub 下载它们。 观看我们的视频教程，见证 DARWIN 的实际功能： 📹 视频 1：观看 DARWIN在此处训练机器学习模型：Darwin ML Training 以防万一您错过了我们上一版本中的 DARWIN，DARWIN 是一位由您指挥的人工智能软件实习生。它具有帮助您构建和部署代码的功能。通过访问互联网，达尔文依靠更新的知识来编写代码并执行它们。如果万一遇到错误，DARWIN 会尝试通过访问讨论和论坛来解决它。更好的是它是开源的。 访问达尔文 欢迎加入我们，我们将揭开达尔文的全部潜力。在评论中分享您的反馈、想法或您希望 DARWIN 下一步做什么，或前往 DARWIN 存储库。我们还在建立一个 Discord 社区，我们很高兴在那里见到您。   由   提交 /u/Curious-Swim1266    reddit.com/r/MachineLearning/comments/1d219rl/p_darwin_opensourced_devin_alternative_is_back/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d219rl/p_darwin_opensourced_devin_alternative_is_back/</guid>
      <pubDate>Mon, 27 May 2024 20:20:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] MusicGPT – 一款使用本地 LLM 生成音乐的开源应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1vp2u/p_musicgpt_an_open_source_app_for_generating/</link>
      <description><![CDATA[大家好！ 想分享一下我过去几个月一直在做的最新副业。这是一个运行本地音乐生成模型的终端应用程序，目前只有 MusicGen by Meta 可用。 https://github.com/gabotechs/MusicGPT 它适用于 Windows、Linux 和MacOS 无需安装 Python 或任何重型机器学习框架。相反，它完全用 Rust 编写，使用 ONNX 运行时以高性能方式在本地运行 LM，甚至使用 GPU 等硬件加速器。 该应用程序的工作原理如下：  它接受用户的自然语言提示 根据提示生成音乐样本 编码生成的样本转换为 .wav 格式并在设备上播放  此外，它还提供了一个 UI，允许在类似聊天的 Web 应用程序中与 AI 模型进行交互，存储聊天历史记录和设备上生成的音乐。 该项目的愿景是最终能够实时生成无限的音乐流，例如，在编码时收听始终新的 LoFi 歌曲的无限流，但还没有完全实现...... 这是一个有趣的旅程，在 Rust 的受限环境中建立基于 Transformer 的模型并运行，没有 PyTorch 或 TensorFlow，希望你喜欢它！ &lt; /div&gt;  由   提交 /u/GabrielMusat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1vp2u/p_musicgpt_an_open_source_app_for_generating/</guid>
      <pubDate>Mon, 27 May 2024 16:34:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用图神经网络对列车延误进行多步并行预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1uawc/d_multistep_parallel_prediction_for_train_delays/</link>
      <description><![CDATA[    &lt; /a&gt;  大家好， 我目前正在做一个涉及使用的项目用于预测火车延误的图神经网络（GNN）。目标是对网络中的每个列车执行多步并行预测。主要挑战之一是考虑问题的时空维度以及整个铁路上列车之间的相互作用（参见图中网络的样子）。该数据集由给定时间的网络状态（包含当前列车）的快照组成 https://preview.redd.it/nywjb71fnz2d1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=f141d0e1badf1e5ec 7397972f6c1bd8051fc09f9 到目前为止，我已经提出了两种不成熟的方法，希望得到任何建议、评论或替代方案： 方法 1：异构图模型 在这种方法中，我构建了一个具有两种类型节点的异构图：车站和火车。这导致了三种类型的关系：火车站-车站、火车-火车和车站-车站。预测任务本质上是边缘预测，特别是火车站边缘。对于给定的火车，该模型旨在预测其与 n_following 车站的链接（延误）。 方法 2：同质图模型 我的第二个该方法涉及使用同质图，其中每个节点代表铁路网络中的一个重要点 (RP)，例如车站、交叉点等。每个节点都具有 RP 类型、地理位置和时间序列等特征代表火车在该 RP 随时间的延误情况的特征。该图中的边代表两个 RP 之间的直接行驶路径，具有平均行驶时间和每天列车数量等特征。 GNN 的输出是接下来几个时间步中每个 RP 的预测延迟。 在现有文献中，模型要么是针对一列火车的预测，要么铁路是由一条线路组成的这不是我想要的。  如果您有任何见解或建议，我将不胜感激。提前致谢！   由   提交/u/OtherDepartment8085  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1uawc/d_multistep_parallel_prediction_for_train_delays/</guid>
      <pubDate>Mon, 27 May 2024 15:35:11 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost：特征选择的首选方法？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1u0yd/xgboost_preffered_method_of_feature_selection_d/</link>
      <description><![CDATA[方法 1 - 形状：删除平均绝对形状值低于特定值的特征 方法 2 - 特征重要性：删除特征特征重要性值低于特定值 方法 3 - R 平方：从模型中单独删除每个特征，并计算每个单独模型的 R2 分数。应删除不会显着增加 R2 分数的特征 方法 4 - 保留所有特征并让 XGBoost 对其进行排序 您对这些特征的相对功效有何看法方法以及您喜欢使用的任何其他方法，特别是 XGBoost？   由   提交 /u/Gef_1_Man_Army   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1u0yd/xgboost_preffered_method_of_feature_selection_d/</guid>
      <pubDate>Mon, 27 May 2024 15:23:07 GMT</pubDate>
    </item>
    <item>
      <title>[P]如何获得LSUN-CAT</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1tefs/p_how_can_i_get_lsuncat/</link>
      <description><![CDATA[我注意到几篇研究论文提到了 LSUN-CAT 数据集，该数据集似乎被广泛用于图像生成任务。但是，我找不到此数据集的下载链接，因为官方 LSUN github 没有“cat”类 https://github.com/fyu/lsun。 有人可以提供如何访问它的指导吗？以下是其在图像生成中的使用的参考：https://paperswithcode.com/sota/image-generation-on-lsun-cat-256-x-256 ADM还提供了用数据集训练的权重：https://github.com/openai/guided-diffusion 谢谢你的帮助！ 编辑： 我还发现官方数据集网站已经瘫痪：https://www.vis.xyz/p/lsun    提交人    /u/National-Resident244   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1tefs/p_how_can_i_get_lsuncat/</guid>
      <pubDate>Mon, 27 May 2024 14:56:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 离散多令牌方法与传递多模式输出和机器人控制隐藏状态的单令牌方法相比如何？行业整体趋势如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1rmjl/d_how_do_discrete_multitoken_approaches_compare/</link>
      <description><![CDATA[对于连续输出，我见过使用两种不同的方法 1：模型给出了离散标记的词汇表，并可以组装它们的列表，并将其传递给解码器 2：模型为每个输出模态赋予一个标记（例如，图像标记），并且在选择时将隐藏状态传递给解码器 这两种方法的最新趋势是什么？ 2 看起来会快很多，因为你只需要 1 个令牌，但这对损失函数有何影响，因为有时你会遇到回归问题（图像生成），有时你会遇到分类问题？    由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1rmjl/d_how_do_discrete_multitoken_approaches_compare/</guid>
      <pubDate>Mon, 27 May 2024 13:33:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分形网络曾经被扩展过吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1ring/d_was_fractal_net_ever_expanded_upon/</link>
      <description><![CDATA[我一直在阅读《FractalNet：超深度神经网络》没有残差的网络”，我想知道 FractalNet 背后的方法是否在其他文章中得到了改进。   由   提交/u/research_pie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1ring/d_was_fractal_net_ever_expanded_upon/</guid>
      <pubDate>Mon, 27 May 2024 13:28:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] AstroPT：扩展天文学大型观测模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1nirc/r_astropt_scaling_large_observation_models_for/</link>
      <description><![CDATA[ 由   提交/u/Smith4242  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1nirc/r_astropt_scaling_large_observation_models_for/</guid>
      <pubDate>Mon, 27 May 2024 09:19:38 GMT</pubDate>
    </item>
    <item>
      <title>进行 ML/DL 研究的最终方式是我的方式还是你的方式？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1mxzo/ultimate_way_of_doing_research_in_mldl_is_my_way/</link>
      <description><![CDATA[嗨， 这篇文章旨在邀请您分享您处理研究的方法。我想深入研究像您这样的研究人员如何想象和处理问题，特别是如何提出想法和假设。  个人反思： 作为 3D 视觉领域，特别是点云分类/分割领域的研究人员，我&#39;我目前正在反思我自己的研究方法。就在最近，我突然意识到，我对作为一名初级研究员所做贡献的整个方式提出了质疑。  案例研究： 为了说明我当前的研究风格，让我们考虑一下我最近的一个想法。最近，我花了部分时间探索一种新颖的点云分类轻量级架构。探索了沿着点云（3d 对象）的纵轴将对称对象一分为二（切成两半）的想法。这种方法旨在实现两个目标：减少数据大小和潜在的数据增强。如果我们在管道中的某个点有两个处理分支怎么办？  正如你所看到的，我的想法/假设完全是抽象的。我正在以一种半有形且琐碎的人类理解逻辑的方式走进这些想法。正确的？  忽略这个想法是否符合我首先提到的研究目标。这不关我的事。  中心问题：  我特别想知道这是处理问题的正确方法吗？ ？这是进行研究的最终方式吗？这个领域的想法就是这样诞生的？ 我有限的数学背景是否会阻碍更系统、数学驱动的方法来研究解决问题、可视化和思考？ 如果数学不一定是最初的重点，那么它在什么阶段变得至关重要？以后的整合会带来什么优势？ 请分享您的经验和方法。  ​   由   提交 /u/Same_Half3758   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1mxzo/ultimate_way_of_doing_research_in_mldl_is_my_way/</guid>
      <pubDate>Mon, 27 May 2024 08:35:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些 LLM 进步也适用于 100M 以下参数模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1m9ux/d_which_llm_advancements_also_work_for_sub_100m/</link>
      <description><![CDATA[大家好， 我想从头开始训练一个具有大约 50M 参数的小型语言模型。我想知道我应该为此使用什么样的架构。 我应该坚持使用良好的 GPT2 还是像分组查询注意 (GQA) 这样的技术也适用于如此小的模型大小？旋转位置嵌入 (RoPE) 也是如此。现代法学硕士似乎大多使用它，但 GPT2 没有。然后是规范化层的放置，我也不确定。 如果我只选择一个现成的架构并将其缩小，可能是最好的，但是这您现在可以推荐一个吗？为什么？   由   提交/u/CloudyCloud256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1m9ux/d_which_llm_advancements_also_work_for_sub_100m/</guid>
      <pubDate>Mon, 27 May 2024 07:45:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>