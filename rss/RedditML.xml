<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 19 May 2024 15:13:34 GMT</lastBuildDate>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何明确地说我的数据集是否是高斯分布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvp1m3/d_how_to_definitely_say_if_my_dataset_is_guassian/</link>
      <description><![CDATA[我正在遵循一些有关进行线性回归的教程，并且在构建笔记本时，我正在研究异常值检测以及所描述的技术为了进行异常值检测，其中之一涉及计算标准差，但为此我需要知道我的列是否符合高斯分布。我知道有不同的技术，例如：  直方图 KDE图 Q-Q图 Kolomogorov-Smirnov测试 夏皮罗-威尔克测试 达戈斯蒂诺和皮尔逊测试  我敢打赌还有更多。那么什么是最好用的呢？我想直方图只是提供了线索，但并没有显示出真正的意图。识别数据集是否为高斯数据的标准做法是什么？   由   提交 /u/CaterpillarPrevious2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvp1m3/d_how_to_definitely_say_if_my_dataset_is_guassian/</guid>
      <pubDate>Sun, 19 May 2024 14:05:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习中回收旧会议论文的文化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</link>
      <description><![CDATA[我从事统计机器学习工作。我注意到很多人（包括我自己和我审阅的人）经常重复他们向 ML 会议提交的论文。 例如，如果他们的论文被 ICML 拒绝，他们会提交给 NeurIPS，然后提交给 ICLR（或UAI/AISTATS 在我的领域也是顶尖的）。如果2~3次后没有进入ICML/NeurIPS/ICLR，他们会提交给AAAI/IJCAI/TMLR/ICDM，T-NNLS/T-KDD/NN/Neurocomputing等期刊，或者特定领域的场地，如LoG/CoLLA/AABI。经过所有这些，如果论文仍然没有被接受，他们就简单地将它们或 arXiv.我相信 CV/NLP 也可能是这种情况。 作为审稿人，我经常遇到会议提交的内容，作者在没有真正考虑之前提供的审稿的情况下重新提交。有时他们在重新提交时确实会纳入审稿意见，但有时工作可能只是达不到一级会议的水平，但他们只是不断重新提交并希望能够偶然被接受。 我认为这正在消耗社区审稿人的大量时间来继续审阅相同的提交内容（特别是考虑到 NeurIPS 达到 20k 提交 ID；我预计会看到许多重新提交）。这也许也是 TMLR 诞生的原因之一（强调正确性而不是新颖性）。 我确实理解“研究质量比发表地点更重要”之类的论点。或者“OpenAI 通常只是简单地将他们的论文（例如 GPT-X）放在 arXiv 上”。然而，学生或初级研究人员在他们的职业生涯中也需要发表论文，包括我自己。  人们对此有何看法？   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</guid>
      <pubDate>Sun, 19 May 2024 14:04:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在机器学习中有效地进行消融研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/</link>
      <description><![CDATA[在对可预训练和微调的模型进行消融研究时，您是否在预训练和微调期间对每个消融版本执行完整的网格搜索微调？或者你有策略让这个过程更加高效吗？感谢您的见解。   由   提交 /u/Few-Pomegranate4369    reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/</guid>
      <pubDate>Sun, 19 May 2024 13:54:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] N 路注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvkrpf/p_nwayattention/</link>
      <description><![CDATA[我一直在研究在变压器模型中关注两个以上标记的概念。例如，不要使用一个查询和一个密钥，而是使用两个密钥和一个查询，并且对于每对先前标记的每个查询总和。 这使得算法甚至更慢（ O(n**3 ）而不是 O(n**2))，但我认为这是一个有趣的概念。有些结果令我惊讶，比如它在找到最长递增子序列方面有多出色。 我希望它分享它： https://github.com/Gusanidas/n-way-attention/tree/main 并询问是否有人知道处理或提及该概念的论文。   由   提交 /u/Gusanidas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvkrpf/p_nwayattention/</guid>
      <pubDate>Sun, 19 May 2024 09:56:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM Ops的现状如何</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvkmwe/d_what_is_the_current_state_of_llm_ops/</link>
      <description><![CDATA[很好奇人们现在如何将 RAG 和其他 LLM 支持的应用程序投入生产。您如何定义LLM Ops？您的团队/公司的流程是什么样的，您今天使用什么工具组合来实施或自动化这些流程，以及一些差距领域是什么。 我对哪些人特别感兴趣正在围绕生产环境中跨节点扩展更大模型的效率问题进行研究。您是否应用了任何 GPU 虚拟化/分段化以及这些方面有哪些好的资源？    由   提交/u/gamerx88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvkmwe/d_what_is_the_current_state_of_llm_ops/</guid>
      <pubDate>Sun, 19 May 2024 09:46:40 GMT</pubDate>
    </item>
    <item>
      <title>机器学习与分布式系统的交叉点 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvfrd9/intersection_of_ml_distributed_systems_d/</link>
      <description><![CDATA[分布式系统和机器学习交叉领域存在哪些现有问题？ 我在这两个领域都有不错的背景，并且我想要从事利用分布式计算来解决机器学习问题的项目。有哪些值得一看的好资源？或者如何开始？   由   提交/u/tcuser12  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvfrd9/intersection_of_ml_distributed_systems_d/</guid>
      <pubDate>Sun, 19 May 2024 04:16:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] Cafusion：生成猫图像的扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvfaot/p_cafusion_diffusion_model_for_generating_cat/</link>
      <description><![CDATA[我已经在这个项目上工作了一段时间了。它只能生成噩梦般的燃料图像，甚至看起来都不像猫，但我正在努力使其变得更好 这里是存储库：https://github.com/Null-byte-00/Catfusion 这是 jupyter 笔记本：https://nbviewer.org/github/Null-byte-00/Catfusion/blob/main/catfusion.ipynb    由   提交 /u/Soroush_ra   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvfaot/p_cafusion_diffusion_model_for_generating_cat/</guid>
      <pubDate>Sun, 19 May 2024 03:49:49 GMT</pubDate>
    </item>
    <item>
      <title>[D]为什么我们没有在论文中看到零样本的 Truthfulqa 性能？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvf2jf/dwhy_dont_we_see_zero_shot_truthfulqa_performance/</link>
      <description><![CDATA[我的直觉是它是最重要的指标之一，但我们通常看到的是多镜头表现。就像在 phi3 论文中报告了 10 次拍摄表现一样。    提交人    /u/Bytesfortruth   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvf2jf/dwhy_dont_we_see_zero_shot_truthfulqa_performance/</guid>
      <pubDate>Sun, 19 May 2024 03:36:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否可以用高光谱卫星图像训练 ViTMAE？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cval53/d_is_it_possible_to_train_vitmae_with/</link>
      <description><![CDATA[我正在尝试训练 ViTMAE 编码器来学习一些高光谱卫星图像的表示。图像采用 TIFF 格式，并且有许多波段 (224)。是否可以使用如此大量的输入频段来训练 ViTMAE？知道我应该怎么做吗？   由   提交/u/Robur_131  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cval53/d_is_it_possible_to_train_vitmae_with/</guid>
      <pubDate>Sat, 18 May 2024 23:42:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] Grounding DINO 1.5 发布：最强大的开集检测模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cv0m9x/r_grounding_dino_15_release_the_most_capable/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cv0m9x/r_grounding_dino_15_release_the_most_capable/</guid>
      <pubDate>Sat, 18 May 2024 16:05:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基础时间序列模型被高估了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cv0hl2/d_foundational_time_series_models_overrated/</link>
      <description><![CDATA[我一直在探索基础时间序列模型，如 TimeGPT、Moirai、Chronos 等，并想知道它们是否真的具有强大的样本潜力 -高效的预测，或者他们只是借用 NLP 基础模型的炒作并将其引入时间序列领域。 我可以理解为什么它们可能会起作用，例如，在需求预测中，它是关于但它们能否处理任意时间序列数据，如环境监测、金融市场或生物医学信号，这些数据具有不规则模式和非平稳数据？ 它们的概括能力是否被高估了？    由   提交 /u/KoOBaALT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cv0hl2/d_foundational_time_series_models_overrated/</guid>
      <pubDate>Sat, 18 May 2024 16:00:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 鲁棒智能体学习因果世界模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cuzbta/r_robust_agents_learn_causal_world_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.10877 摘要：  长期以来，人们一直假设因果推理在强大而通用的智能。然而，尚不清楚智能体是否必须学习因果模型才能推广到新领域，或者其他归纳偏差是否足够。我们回答了这个问题，表明任何能够在大量分布变化下满足后悔界限的智能体都必须学习数据生成过程的近似因果模型，该模型收敛到最佳智能体的真实因果模型。我们讨论了这一结果对包括迁移学习和因果推理在内的多个研究领域的影响。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cuzbta/r_robust_agents_learn_causal_world_models/</guid>
      <pubDate>Sat, 18 May 2024 15:06:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 命名实体识别库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cuz1i2/d_library_for_named_entity_recognition/</link>
      <description><![CDATA[大家好，我需要决定使用哪个库进行命名实体识别。我使用过 spaCy，它运行良好，但我需要一个允许我对实体和子实体进行分类的库。有人做过类似的事情吗？我的意思是，同一个词可以是多个实体。 spaCy 提供了 SpanCat 管道，理论上可以实现这一点，但我在创建训练语料库时遇到了麻烦。我认为这是因为他们希望你购买像 Prodigy 这样的注释文本框架。   由   提交/u/Original_Ad8019   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cuz1i2/d_library_for_named_entity_recognition/</guid>
      <pubDate>Sat, 18 May 2024 14:52:57 GMT</pubDate>
    </item>
    <item>
      <title>[N] ICML 2024 关于使离散操作可微分的研讨会🤖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cux80i/n_icml_2024_workshop_on_making_discrete/</link>
      <description><![CDATA[大家好！ 今年我们将在 ICML 组织可微分几乎所有内容研讨会。&lt; /p&gt; 许多离散操作，例如排序、topk、最短路径、聚类（等等）几乎到处都有零梯度，因此不适合现代基于梯度的学习框架（例如深度学习）。本次研讨会将涵盖旨在解决此类问题的研究主题！ https:// Differentiable.xyz/ 我们鼓励任何从事相关主题工作的人提交他们的作品。即使您没有提交，也请务必参加 ICML 的研讨会，观看即将举行的一些激动人心的演讲！ 我在下面附上了研讨会的完整摘要！祝你当前的工作一切顺利，L :) 梯度和导数是机器学习不可或缺的一部分，因为它们支持基于梯度的优化。然而，在许多实际应用中，模型依赖于实现离散决策的算法组件，或者依赖于离散的中间表示和结构。这些离散步骤本质上是不可微分的，因此破坏了梯度流。要使用基于梯度的方法来学习此类模型的参数，需要将这些不可微分的组件变成可微分的。这可以通过仔细考虑来完成，特别是使用平滑或松弛来为这些组件提出可微的代理。随着模块化深度学习框架的出现，这些想法在机器学习的许多领域变得比以往任何时候都更加流行，在短时间内生成了大量“可微分的一切”，影响了渲染、排序和排名等各种主题，凸优化器、最短路径、动态规划、物理模拟、神经网络架构搜索、top-k、图算法、弱监督学习和自监督学习等等。 本次研讨会将为任何可区分的事物提供一个论坛，汇聚学术界和行业研究人员，突出挑战和发展，提供统一的想法，讨论实际的实施选择并探索未来的方向。   由   提交/u/machine_learning_res   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cux80i/n_icml_2024_workshop_on_making_discrete/</guid>
      <pubDate>Sat, 18 May 2024 13:22:17 GMT</pubDate>
    </item>
    </channel>
</rss>