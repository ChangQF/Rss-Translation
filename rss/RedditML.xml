<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 26 Jun 2024 15:15:55 GMT</lastBuildDate>
    <item>
      <title>[D] 企业 RAG 代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp0yyp/d_enterprise_rag_agents/</link>
      <description><![CDATA[向所有公司员工提问；贵公司是如何组织起来解决人们提出的所有这些令人惊叹的 AI（聊天机器人）想法的？您是否有某种 RAG CoE 来处理所有这些问题，或者您是否在每个业务领域都有多个不同的团队，每个人都负责自己的 BS？ 将此发布到机器学习，因为这里的人们可能必须在工作中处理这个问题……    提交人    /u/fusetron   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp0yyp/d_enterprise_rag_agents/</guid>
      <pubDate>Wed, 26 Jun 2024 15:11:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能系统规划和推理研究中的玩具问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp0uzy/d_toy_problems_for_research_in_planning_and/</link>
      <description><![CDATA[哪些问题表面上简单，但需要很强的行动规划能力和“推理”能力？国际象棋和围棋符合描述，但太复杂了。数学证明是推理能力的极好测试，但需要大量的背景知识，而我正在寻找具有简单目标和简单规则的东西。 一个完美的例子是“推箱子”谜题，它在Beyond A* 论文中被用作衡量标准。哪些问题在性质上类似？即使是简单的基于文本或算术的问题，只要需要预测未来并采取相应的行动，也符合标准。    提交人    /u/Log_Dogg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp0uzy/d_toy_problems_for_research_in_planning_and/</guid>
      <pubDate>Wed, 26 Jun 2024 15:07:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练自定义拥抱脸 RoBERTa 时出错</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1doxhs9/d_error_while_training_a_custom_hugging_face/</link>
      <description><![CDATA[我正在尝试在自己的数据集上微调 cardiffnlp/twitter-roberta-base-sentiment-latest，该数据集有 8 个用于情绪分析的标签。 数据为 CSV 格式，我使用 hugging face 文档中提到的 Tokenizer 进行了标记和编码，然后使用 pytorch Dataset 类，我将这些编码转换为 PyTorch 张量。我不明白为什么会出现值错误： ValueError：预期输入 batch_size (16) 与目标 batch_size (128) 匹配。 感谢您的帮助。非常感谢。 p.s.我之前已经对 flan-t5 进行了微调（完整 FF、PEFT 和 RLHF），但我没有使用已经微调的自定义模型的经验。 model = f&quot;cardiffnlp/twitter-roberta-base-sentiment-latest&quot; tokenizer = AutoTokenizer.from_pretrained(model) config = AutoConfig.from_pretrained(model) config.num_labels = 8 import torch from torch.utils.data import Dataset, DataLoader class TextDataset(Dataset): &quot;&quot;&quot; 自定义数据集类，用于处理标记化的文本数据和相应的标签。从 torch.utils.data.Dataset 继承。&quot;&quot;&quot; def __init__(self, encodings, labels): &quot;&quot;&quot; 使用编码和标签初始化 DataLoader 类。参数：encodings（dict）：包含标记化输入文本数据的字典（例如，“input_ids”、“token_type_ids”、“attention_mask”）。labels（list）：输入文本数据的整数标签列表。&quot;&quot;&quot; self.encodings = encodings self.labels = labels def __getitem__(self, idx): &quot;&quot;&quot; 返回包含标记化数据和给定索引的相应标签的字典。参数：idx（int）：要检索的数据项的索引。返回：item（dict）：包含标记化数据和相应标签的字典。&quot;&quot;&quot;检索给定索引的标记数据 item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} 将给定索引的标签添加到项目字典 item[&#39;labels&#39;] = torch.nn. functional.one_hot(torch.tensor(self.labels[idx]), num_classes=8) return item def __len__(self): &quot;&quot;&quot; 返回数据集中的数据项数量。返回：(int): 数据集中的数据项数量。&quot;&quot;&quot; return len(self.labels) 假设 train_encodings 和 val_encodings 是张量的字典 train_dataset = TextDataset(train_encodings, y_train.to_list(),) val_dataset = TextDataset(val_encodings, y_val.to_list())  最后使用 Trainer 类像往常一样进行训练  from transformers import AutoModelForSequenceClassification, TrainingArguments training_args = TrainingArguments( output_dir=&#39;./results&#39;, num_train_epochs=1, per_device_train_batch_size=16, per_device_eval_batch_size=8, warmup_steps=100, weight_decay=1e-4, logs_dir=&#39;./logs&#39;, eval_steps=50, load_best_model_at_end=True, evaluation_strategy=&quot;steps&quot;, save_strategy=&quot;steps&quot;, ) 从 transformers 导入 Trainer model = AutoModelForSequenceClassification.from_config(config) trainer = Trainer( model=model, args=training_args, train_dataset=train_dataset, eval_dataset=val_dataset, compute_metrics= compute_metrics )     提交人    /u/areewahitaha   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1doxhs9/d_error_while_training_a_custom_hugging_face/</guid>
      <pubDate>Wed, 26 Jun 2024 12:33:39 GMT</pubDate>
    </item>
    <item>
      <title>[项目] CUHNSWPLUS：增强了 cuhnsw 的多线程、API 支持和性能提升</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dox5bu/project_cuhnswplus_enhanced_cuhnsw_with/</link>
      <description><![CDATA[大家好， 我很高兴与大家分享我的项目 CUHNSWPLUS，它是 cuhnsw 的一个改进分支。 项目链接：[GitHub Repo](https://github.com/n0tank3sh/cuhnswplus) **改进**  用于加载图形向量的多线程。 重用分配的 `device_vector` 来提高性能。 磁盘缓存可有效处理大型数据集。 对 `AddPoint` 和 `AddPoints` 的 API 支持。  我将非常感谢任何反馈、建议或贡献。谢谢！    由   提交  /u/MightiestGoat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dox5bu/project_cuhnswplus_enhanced_cuhnsw_with/</guid>
      <pubDate>Wed, 26 Jun 2024 12:15:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 会议论文集研讨会论文 vs 非档案研讨会论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dowowk/r_proceedings_workshop_paper_vs_nonarchival/</link>
      <description><![CDATA[我的论文被一个有“会议论文集”的研讨会接受了。我发现会议中的其他研讨会似乎都是非存档的，即它们不会发表，而且它们都要求提交的论文最多为 2 页。 相反，我的论文像普通论文一样长达 9 页，并且也发表在研讨会的论文集上。 所以我觉得，虽然是一篇研讨会论文（我知道在难度等方面根本无法与会议论文相比），但将这项工作宣布为研讨会并没有真正突出这样一个事实：它不是一份不会发表的 2 页长文档，而是一篇属于论文集的全长论文。 这里的问题是，我是不是搞错了，这实际上不应该是一个问题？或者有什么方法可以将我的论文与普通研讨会的论文区分开来？  我确实在这项研究上花了很多精力，我希望它能得到应有的认可，不多也不少。我想知道我应该如何向我的网络和求职面试等渠道公布这篇论文。我觉得大多数人听说我的论文被接受参加研讨会时，都会想到一个长达 2 页的初步想法，我不知道如何表明这是别的东西（我相信是的，但如果我错了，请纠正我）    提交人    /u/howtorewriteaname   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dowowk/r_proceedings_workshop_paper_vs_nonarchival/</guid>
      <pubDate>Wed, 26 Jun 2024 11:51:07 GMT</pubDate>
    </item>
    <item>
      <title>GenAI模型评估技术 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dowo6o/genai_model_evaluation_tech_d/</link>
      <description><![CDATA[大家好，我一直在构建 LLM 模型，我的团队需要评估这些模型。这是一项频繁的活动，这就是我们认真对待它的原因。你们能建议我们可以使用什么软件或服务来内部构建，或者我们可以联系哪些公司进行模型评估吗？    提交人    /u/No_Painting_9825   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dowo6o/genai_model_evaluation_tech_d/</guid>
      <pubDate>Wed, 26 Jun 2024 11:50:01 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和聊天机器人课程 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dowf3y/course_on_ai_and_chatbots_p/</link>
      <description><![CDATA[大家好 我经营着一份致力于人工智能的通讯，并为我的订阅者提供了一门关于人工智能和聊天机器人的免费课程，我想把它放在这里，以防有人觉得它有用。 该课程由专注于在线教育的初创公司 GrowthSchool.io 开设。课程长达 3 个小时，通过 Zoom 举行。它深入探讨了即兴写作、使用人工智能和 Excel、刚刚发布的新功能以及我认为最令人兴奋的构建自己的自定义 GPT。 您可以在此处找到免费课程。    提交人    /u/cognitive_courier   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dowf3y/course_on_ai_and_chatbots_p/</guid>
      <pubDate>Wed, 26 Jun 2024 11:35:44 GMT</pubDate>
    </item>
    <item>
      <title>展现与神经网络根本不同的模型的类人智能 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dovn4n/humanlike_intelligence_exhibiting_models_that_are/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dovn4n/humanlike_intelligence_exhibiting_models_that_are/</guid>
      <pubDate>Wed, 26 Jun 2024 10:50:13 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] superduperdb 的新开源版本可用于在您现有的数据库中构建 AI 工作流，包括 Postgres、Mongo、Snowflake、DuckDB 等。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dou7vb/news_new_opensource_version_of_superduperdb_for/</link>
      <description><![CDATA[https://blog.superduperdb.com/version-02/    由    /u/escalize 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dou7vb/news_new_opensource_version_of_superduperdb_for/</guid>
      <pubDate>Wed, 26 Jun 2024 09:13:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] UniBias：通过内部注意力和 FFN 操纵揭示和减轻 LLM 偏见</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dosa1v/r_unibias_unveiling_and_mitigating_llm_bias/</link>
      <description><![CDATA[摘要  大型语言模型 (LLM) 已在使用上下文学习 (ICL) 范式的各种任务中展现出令人印象深刻的能力。然而，它们的有效性往往受到固有偏见的影响，导致提示脆弱性，即对设计设置（例如示例选择、顺序和提示格式）的敏感性。先前的研究通过外部调整模型输出来解决 LLM 偏差问题，但导致这种偏差的内部机制仍未得到探索。 我们的工作深入研究了这些机制，特别是研究了前馈神经网络 (FFN) 和注意力头如何导致 LLM 的偏差。通过解释单个 FFN 向量和注意力头的贡献，我们确定了导致 LLM 对特定标签的预测出现偏差的 LLM 成分。为了减轻这些偏见，我们引入了 UniBias，这是一种仅推理的方法，可以有效地识别和消除有偏见的 FFN 向量和注意力头。在 12 个 NLP 数据集上进行的大量实验表明，UniBias 显着提高了 ICL 性能并减轻了 LLM 的即时脆性。     提交人    /u/Balance-   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dosa1v/r_unibias_unveiling_and_mitigating_llm_bias/</guid>
      <pubDate>Wed, 26 Jun 2024 06:55:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 iPhone 上运行 google/mobilebert-uncased</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dootto/d_running_googlemobilebertuncased_on_an_iphone/</link>
      <description><![CDATA[我正在构建自定义键盘扩展，目前使用 UITextChecker 进行自动更正。我注意到，这并没有考虑到句子的实际上下文，只是简单地更正了单词，即使它在用户写的句子中没有任何意义。因此，我正在寻找一种更好的自动更正方法。非常欢迎任何建议！ 我认为使用轻量级 llm 会很合适，所以我找到了 MobileBERT。我现在正尝试将此模型添加到我的 XCode 项目中。据我所知，我需要将其转换为 CoreML 模型才能这样做。我使用 coremltools 完成了此操作。然后我实现了一个模型处理程序类，但是，当我尝试使用该模型时，它实际上什么也不做。我注意到的第一个问题是它没有正确地标记输入字符串。看来，即使我从 huggingFace 获得了模型，我仍然需要从头开始实现很多东西。这让我觉得一定有一个更好的解决方案。 基本上，我希望它工作的方式是将用户的输入字符串传递给模型，然后让它返回一个字符串，如果出现错误，则传入字符串的最后一个单词会自动更正。此更正应考虑句子上下文。    提交人    /u/pawn5gamb1t   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dootto/d_running_googlemobilebertuncased_on_an_iphone/</guid>
      <pubDate>Wed, 26 Jun 2024 03:24:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在顶级机器学习会议上招聘</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1doo538/r_recruitment_at_top_ml_conferences/</link>
      <description><![CDATA[我很幸运，我的第一作者出版物被顶级 ML 会议接受为焦点。最近我收到字节跳动的一封电子邮件，邀请我在线或在会场聊天。我只是好奇  他们会将这些电子邮件群发给焦点/口头论文的作者吗？抱歉，我不直接认识其他人，我问这个问题是因为我的论文似乎与他们的重点不直接一致，根据他们的说法，他们主要是法学硕士 即使我不能亲自参加会议，我该如何充分利用这些机会？他们会要求我进行 LC 面试还是只谈论这个特定的项目，还是其他什么？  我对此不是很熟悉，非常感谢任何经验。谢谢！    提交人    /u/logichael   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1doo538/r_recruitment_at_top_ml_conferences/</guid>
      <pubDate>Wed, 26 Jun 2024 02:47:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 仅用于分类的解码器模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1domam7/d_decoder_only_models_for_classification/</link>
      <description><![CDATA[我在几次采访中被问到这个问题 - 对于分类任务，如何决定是使用仅编码器还是仅解码器架构？ 据我所知，使用仅编码器架构是因为它们可以完全捕捉文本中的含义，并且在此表示之上添加分类层将在分类任务上提供良好的性能。 但后续问题是关于为什么不能考虑解码器，因为像 GPT 这样的模型似乎在分类上也表现良好？我不确定如何回答这个问题，因为仅编码器看起来是一个直观的选择。像 GPT 这样的模型在许多任务上表现良好，包括分类，因为它们是在大量数据上进行训练的。如果从头开始训练模型的唯一可用数据是分类数据集，那么在这种情况下也可以使用解码器吗？    提交人    /u/PretendBelt3387   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1domam7/d_decoder_only_models_for_classification/</guid>
      <pubDate>Wed, 26 Jun 2024 01:14:59 GMT</pubDate>
    </item>
    <item>
      <title>[N] Karpathy 已开始新系列“LLM101n”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1doj9kv/n_karpathy_has_begun_a_new_series_llm101n/</link>
      <description><![CDATA[https://github.com/karpathy/LLM101n    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1doj9kv/n_karpathy_has_begun_a_new_series_llm101n/</guid>
      <pubDate>Tue, 25 Jun 2024 22:50:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>