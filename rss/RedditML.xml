<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 11 Jan 2024 18:17:28 GMT</lastBuildDate>
    <item>
      <title>[D] Graphomer图连通性问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19488q4/d_graphormer_graph_connectivity_question/</link>
      <description><![CDATA[我正在阅读图形转换器论文，其中许多（或大多数）忽略图形结构，而是依赖于节点结构编码。据我了解，这与注意力（each-node-with-each-node）相结合，等于使用完整的图，并将节点视为一个集合。这是正确的吗？ Graphormer 论文供参考：https://arxiv.org/pdf/2106.05234.pdf&lt; /a&gt;.   由   提交/u/qalis  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19488q4/d_graphormer_graph_connectivity_question/</guid>
      <pubDate>Thu, 11 Jan 2024 18:10:52 GMT</pubDate>
    </item>
    <item>
      <title>[R]“挑战法学硕士的推理能力：揭示法学硕士认知深度的基准”(DiagGSM8K)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1945swj/r_challenge_llms_to_reason_about_reasoning_a/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.17080 代码：https:/ /github.com/dvlab-research/DiagGSM8K 数据集： https://huggingface.co/datasets/Randolphzeng/DiagGSM8K 摘要：  在这项工作中，我们介绍了大型语言模型的新颖评估范式，挑战他们进行元推理。这种方法解决了现有数学问题解决基准中的关键缺陷，传统上用于评估智能体的认知能力。我们的范式将重点从以结果为导向的评估（通常忽视推理过程）转移到更全面的评估，以有效地区分模型之间的认知能力。例如，在我们的基准测试中，GPT-4 的性能比 GPT3-5 准确十倍。这种新范式的重要性在于它能够揭示法学硕士潜在的认知缺陷，而当前的基准（例如 GSM8K）由于其饱和度以及不同推理能力之间缺乏有效区分而未能发现这些缺陷。我们的全面分析包括来自开源和闭源社区的几个最先进的数学模型，揭示了他们的培训和评估方法的根本缺陷。本文不仅倡导法学硕士评估的范式转变，而且还为正在进行的关于通用人工智能（AGI）发展轨迹的讨论做出了贡献。通过推广采用与我们类似的元推理评估方法，我们的目标是促进更准确地评估法学硕士的真实认知能力。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1945swj/r_challenge_llms_to_reason_about_reasoning_a/</guid>
      <pubDate>Thu, 11 Jan 2024 16:32:30 GMT</pubDate>
    </item>
    <item>
      <title>对于那些从事机器学习和/或数据科学工作的人来说，您目前使用哪些技术和方法来准备分析数据 [D]？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1945rvg/for_those_who_work_in_ml_andor_data_science_what/</link>
      <description><![CDATA[当涉及到清理、缩放、更改数据表示、预处理以及为分析和/或 ML 准备数据的任何其他方面时，需要哪些技术、数学模型（可能基于线性代数或其他此类方面）、库和/或其他工具是您最喜欢的，以确保数据得到充分清理、处理、准备并准备好进行分析？    由   提交/u/emaxwell13131313  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1945rvg/for_those_who_work_in_ml_andor_data_science_what/</guid>
      <pubDate>Thu, 11 Jan 2024 16:31:15 GMT</pubDate>
    </item>
    <item>
      <title>任务污染：法学硕士可能不再是少数人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1945r8k/task_contamination_llms_might_not_be_fewshot_any/</link>
      <description><![CDATA[ 由   提交/u/dr_flint_lockwood  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1945r8k/task_contamination_llms_might_not_be_fewshot_any/</guid>
      <pubDate>Thu, 11 Jan 2024 16:30:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何申请成为会议/期刊的审稿人？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1945n6i/d_how_to_request_to_be_a_reviewer_to_a/</link>
      <description><![CDATA[我有兴趣回顾 ECCV、Neurips、ICLR、AAAI 等即将到来的周期。 还想T-PAMI 等期刊的审稿。 如何进行此操作？我应该给期刊或会议的编辑发电子邮件还是有更好的方法？   由   提交/u/perceptron333  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1945n6i/d_how_to_request_to_be_a_reviewer_to_a/</guid>
      <pubDate>Thu, 11 Jan 2024 16:25:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在尖峰神经网络中学习长序列</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1945f0b/r_learning_long_sequences_in_spiking_neural/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.00955 摘要：  尖峰神经网络（SNN）从大脑中汲取灵感，使节能计算。自从 Transformer 出现以来，SNN 一直在努力与现代序列任务上的人工网络竞争，因为它们继承了循环神经网络 (RNN) 的局限性，并且增加了使用不可微二元尖峰激活进行训练的挑战。然而，最近人们对 Transformer 的高效替代方案重新产生了兴趣，催生了名为状态空间模型 (SSM) 的最先进的循环架构。这项工作首次系统地研究了最先进的 SSM 与用于远程序列建模的 SNN 的交叉点。结果表明，基于 SSM 的 SNN 在成熟的远程序列建模基准的所有任务上都可以优于 Transformer。研究还表明，基于 SSM 的 SNN 在顺序图像分类方面可以使用更少的参数优于当前最先进的 SNN。最后，引入了一种新颖的特征混合层，提高了 SNN 的准确性，同时挑战了有关二元激活在 SNN 中的作用的假设。这项工作为将强大的基于 SSM 的架构（例如大型语言模型）部署到神经形态硬件以实现节能的远程序列建模铺平了道路。  &lt;!-- SC_ON - -&gt;  由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1945f0b/r_learning_long_sequences_in_spiking_neural/</guid>
      <pubDate>Thu, 11 Jan 2024 16:16:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在大多数多模态法学硕士中，模型的图像嵌入在哪里？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1944iz8/p_in_most_multimodal_llms_where_are_the_image/</link>
      <description><![CDATA[我有一个带有超级简单的 andrej karpahy GPT 的 Colab 笔记本 (https://colab.research.google.com/drive/17j0xI5n-wRK3c6BQagCEbw38EJ39M7G3?usp=sharing），我想尝试添加 ViT/Clip/Fuyu 风格嵌入到它。 ViT/Clip，我需要整个剪辑模型，它是我的变压器大小的 30 倍到 5 倍，因此从我发现的运行图像中选择 Fuyu 更困难通过 MLP 进行修补，它要小得多，但我不确定嵌入的位置 如何用嵌入替换标记？  &amp; #32；由   提交/u/vatsadev  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1944iz8/p_in_most_multimodal_llms_where_are_the_image/</guid>
      <pubDate>Thu, 11 Jan 2024 15:37:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 提交扩展会议论文的最佳视觉期刊？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1943cfc/d_best_vision_journal_to_submit_an_extended/</link>
      <description><![CDATA[我的论文被 CVPR 接受，然后我们提交给 PAMI，但由于随机原因被拒绝。提交到什么期刊比较好？   由   提交/u/Junior-Bookkeeper-24   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1943cfc/d_best_vision_journal_to_submit_an_extended/</guid>
      <pubDate>Thu, 11 Jan 2024 14:45:04 GMT</pubDate>
    </item>
    <item>
      <title>[P]Cudacanvas，一个简单的pytorch cuda张量可视化工具，避免CPU传输</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1943c4q/p_cudacanvas_a_simple_pytorch_cuda_tensor/</link>
      <description><![CDATA[   我们也将其上传到pypi 为了更简单的安装，我们最大的痛点之一始终是我们无法在训练时实时可视化扩散图像，因此这为我们消除了这个问题 Github：https://github.com/OutofAi/cudacanvas ​ https://preview.redd.it/es​​3r859cptbc1.png?width= 1002&amp;format=png&amp;auto=webp&amp;s=e4720e1a50b512f61ee626b3ceaa00222395a0d0   由   提交 /u/TerryCrewsHasacrew   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1943c4q/p_cudacanvas_a_simple_pytorch_cuda_tensor/</guid>
      <pubDate>Thu, 11 Jan 2024 14:44:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] ML copilot - 与 ML 论文和代码聊天</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1940dez/p_ml_copilot_chat_with_ml_papers_and_code/</link>
      <description><![CDATA[大家好， 分享一个我在业余时间研究的机器学习副驾驶：https://mlcopilot.dev/ 您可以与它讨论可以通过 arxiv 或 github 链接的论文和代码存储库。 请告诉我您的想法，如果您对该网站还有任何其他功能想法， 谢谢！  &amp; #32；由   提交/u/Full_Sentence_3678   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1940dez/p_ml_copilot_chat_with_ml_papers_and_code/</guid>
      <pubDate>Thu, 11 Jan 2024 12:17:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对 Google TPU 的专利诉讼是否会危及 bfloat16 和使用它的处理器（例如 NVIDIA）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/193zpyi/d_does_patent_lawsuit_against_googles_tpu_imperil/</link>
      <description><![CDATA[我在有关 TPU 的维基百科文章中添加了一个部分。 https://en.wikipedia.org/wiki/Tensor_Processing_Unit#Lawsuit 但是我推测如果 SingularComputing 在诉讼中获胜，所有对 bfloat16 的使用（包括 NVIDIA）是否都会受到威胁？这种猜测（无论是否来自可靠来源）被认为是“原创研究”。按照维基百科标准，所以我不能将其包含在那里。   由   提交/u/michaelmalak  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/193zpyi/d_does_patent_lawsuit_against_googles_tpu_imperil/</guid>
      <pubDate>Thu, 11 Jan 2024 11:39:39 GMT</pubDate>
    </item>
    <item>
      <title>关于 AutoML [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/193z6xx/about_automl_r/</link>
      <description><![CDATA[嘿 不久前我参加了数据科学竞赛，我花了近两周的时间试图找到最好的特征最终我所有的努力都得到了回报——我是 PL 中的第二名。我的经验非常丰富，现在我正式成为印度新兴市场的专家。 昨天，在准备认证时，我发现了 AutoML 功能。在几个小时内，我获得了与手动相同的分数。我阅读了大量的学术研究、数小时的实验等。这完全是好事，也是预料之中的——在幕后有数千名工程师的工作，他们比我聪明得多。那么，如果在 90% 的情况下仅通过拖放服务就可以实现相同的结果，那么以 20 万/年的价格聘请数据科学家/机器学习工程师还有什么意义呢？这是结束还是开始，我们正在见证 ML 的日落？想知道社区对此有何看法。   由   提交 /u/No_Purchase8883   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/193z6xx/about_automl_r/</guid>
      <pubDate>Thu, 11 Jan 2024 11:07:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人尝试过 Tesla P100 来微调 LLM 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/193t4w8/d_anyone_tried_a_tesla_p100_for_finetuning_llms/</link>
      <description><![CDATA[我最近创建了一个工具来跟踪 GPU 的性价比。我惊讶地发现 NVIDIA Tesla P100 在 $/FP16 TFLOPs 和 $/FP32 TFLOPs，尽管甚至没有张量核心。只是好奇是否有人尝试使用它来微调 LLM 或其他神经网络以进行训练，并可以评论其与其他 GPU 相比的性能及其成本。   由   提交 /u/activescott   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/193t4w8/d_anyone_tried_a_tesla_p100_for_finetuning_llms/</guid>
      <pubDate>Thu, 11 Jan 2024 04:38:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 监控实时 pytorch 模型的最佳 ML 跟踪工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/193qeup/d_best_ml_tracking_tool_to_monitor_live_a_pytorch/</link>
      <description><![CDATA[您好， 我想微调模型的超参数，并且希望实现一个 ML 跟踪工具，例如作为 MLflow 来跟踪我的模型性能。 但是，每次训练大约需要 8 小时，在训练期间观察指标的实时变化（即观察损失曲线增长等）会很有趣 我对管道的这一部分真的很陌生，所以我不知道哪些是最好的工具 是否可以使用 MLflow 来做到这一点？我已经实现了它，但它似乎只在训练脚本完成后显示图表和绘图 如果 MLflow 不可能，你们能建议我最好的包吗？ &gt; 研究该主题后我想到的设置是 Hydra + MLflow + Optuna，如果你们对这个问题有更有经验的观点，我很高兴听到:) 非常感谢！   由   提交/u/Reference-Guilty  /u/Reference-Guilty  reddit.com/r/MachineLearning/comments/193qeup/d_best_ml_tracking_tool_to_monitor_live_a_pytorch/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/193qeup/d_best_ml_tracking_tool_to_monitor_live_a_pytorch/</guid>
      <pubDate>Thu, 11 Jan 2024 02:21:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>