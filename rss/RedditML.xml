<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 18 Mar 2024 12:23:27 GMT</lastBuildDate>
    <item>
      <title>[D] 关于OLLAMA和LLM Inference的硬件配置的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhpbk3/d_question_about_ollama_and_hardware/</link>
      <description><![CDATA[我计划在本地使用 OLLAMA 与各种 LLM，包括具有个人嵌入式参数和数据的 LLaMA 70B。我想避免购买昂贵的 A100 80GB 或更高卡的成本，并且我正在考虑仅使用 4 x 3090 进行推理。 该配置可以正常工作吗？另外，我想知道 OLLAMA 在使用多个 GPU 时是否会自动管理跨卡内存。   由   提交/u/King_of_Junk  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhpbk3/d_question_about_ollama_and_hardware/</guid>
      <pubDate>Mon, 18 Mar 2024 12:17:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 仅在 cifar10 上评​​估的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhp54a/d_papers_that_only_evaluate_on_cifar10/</link>
      <description><![CDATA[大家好！ 在审阅 NeurIPS 2024 时，我一直注意到的一件事是，很多论文只评估非常小的数据集，例如 Cifar-10。这对我来说很奇怪：我认为 Cifar10 是我的方法的玩具数据集和测试平台，而不是我用来证明我的方法实际上有效/在实践中相关的东西。所以我的第一直觉始终是“这种方法可能无法扩展到更大的数据集”。我的意思是，ImageNet 已经有 12 岁了，我个人从大约 8 年前就开始在 imagenet 上为我的论文提供结果。据我所知，大多数计算机视觉应用都需要比 32x32 更高的分辨率。我的印象也是，几乎所有“好”的东西都是我读过的论文有更大规模数据的结果。但考虑到我经常遇到这种情况，我不得不想：我只是在一个非常优越的环境中工作，还是稿件作者只是懒惰？您对仅评估 MNIST 和 CIFAR10 的论文有多少信心？   由   提交 /u/audiencevote   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhp54a/d_papers_that_only_evaluate_on_cifar10/</guid>
      <pubDate>Mon, 18 Mar 2024 12:08:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于变压器的理论论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhog2n/d_theoretical_paper_about_transformers/</link>
      <description><![CDATA[我将成立一个专注于大型语言模型的研究小组。参与者是具有数学背景的计算机科学博士生。我想首先研究变压器（或注意力）的一些理论特性。可能有的同学还不太清楚Transformer具体是怎么公式化的，所以我也需要讨论一下。 您有什么关于Transformer理论分析的论文推荐（注意）吗？  最流行的注意力论文是“Attention is all you need”，但他们只介绍了架构并运行实验。  &amp; #32；由   提交/u/Massive_Horror9038   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhog2n/d_theoretical_paper_about_transformers/</guid>
      <pubDate>Mon, 18 Mar 2024 11:29:08 GMT</pubDate>
    </item>
    <item>
      <title>2024 年哪个库最适合时间序列预测和异常检测？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bho0r0/in_2024_which_library_is_best_for_time_series/</link>
      <description><![CDATA[我正在开发一个项目，负责识别时间序列数据中的异常情况。我遇到了 Facebook Prophet，但遗憾的是它自 2023 年以来就不再维护了。他们建议 NeuroProphet、nixtla 作为替代方案。在寻找替代方案时，我发现了来自 Facebook 的 Kats，它内置了先知支持。这里有哪些工具/库经验丰富的成员会推荐哪些工具/库来构建用于对大量时间序列数据进行异常检测的生产级系统？   由   提交 /u/ThakkidiMundan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bho0r0/in_2024_which_library_is_best_for_time_series/</guid>
      <pubDate>Mon, 18 Mar 2024 11:03:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 剖析高更新率的深度强化学习：对抗价值高估和发散</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhntkk/r_dissecting_deep_rl_with_high_update_ratios/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.05996 摘要：  我们证明深度强化学习可以保持其学习能力，而无需在梯度更新数量大大超过环境样本数量的设置中重置网络参数。在如此大的更新数据比率下，Nikishin 等人最近的一项研究。 （2022）提出了一种首要偏见，即代理过度适应早期的互动并淡化后来的经验，从而损害了他们的学习能力。在这项工作中，我们剖析了首要偏见背后的现象。我们检查了训练的早期阶段可能导致学习失败的原因，发现一个根本的挑战是一个长期存在的认识：价值高估。过度夸大的 Q 值不仅出现在分布外的数据上，而且还出现在分布内的数据上，并且可以追溯到由优化器动量推动的看不见的动作预测。我们采用简单的单位球归一化，可以在大更新率下进行学习，在广泛使用的 dm_control 套件上展示其功效，并在具有挑战性的狗任务上获得强大的性能，与基于模型的方法相竞争。我们的结果部分地质疑了由于早期数据过度拟合而导致的次优学习的先前解释。    由   提交/u/SunsetOneSix  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhntkk/r_dissecting_deep_rl_with_high_update_ratios/</guid>
      <pubDate>Mon, 18 Mar 2024 10:51:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型语言模型的时间之箭</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhnoor/r_arrows_of_time_for_large_language_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.17505 摘要：  我们通过以下方法研究自回归大型语言模型执行的概率建模：时间方向性的角度。我们凭经验发现此类模型在模拟自然语言的能力方面表现出时间不对称性：尝试预测下一个标记与尝试预测前一个标记时的平均对数困惑度存在差异。这种差异同时是微妙的，并且在各种模式（语言、模型大小、训练时间……）中非常一致。从理论上讲，这是令人惊讶的：从信息论的角度来看，不应该存在这样的差异。我们提供了一个理论框架来解释这种不对称性是如何从稀疏性和计算复杂性考虑中出现的，并概述了我们的结果所带来的一些观点。    由   提交/u/SunsetOneSix  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhnoor/r_arrows_of_time_for_large_language_models/</guid>
      <pubDate>Mon, 18 Mar 2024 10:42:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当你使用人工智能进行总结时结果不正确时。爱思唯尔发表的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</link>
      <description><![CDATA[       由   提交 /u/vvkuka   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</guid>
      <pubDate>Mon, 18 Mar 2024 10:14:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] Hugging Face 演示应用程序：表格数据的可解释生成人工智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhlajr/p_hugging_face_demo_app_explainable_generative_ai/</link>
      <description><![CDATA[大家好， 我邀请您尝试我们在表格数据的可解释和生成人工智能方面的工作的拥抱脸演示应用程序。 https://huggingface.co/spaces/CaglarAytekin/LEURN 简单来说，该应用程序采用包含特征和目标的训练表，让您选择要预测的内容并选择分类列。然后您可以使用选定的超参数训练神经网络。训练完成后，您可以上传测试数据（只有特征，没有目标的 Excel 或 csv），然后选择一行来运行神经网络并解释决策。您还可以根据神经网络从训练中学到的知识无缝地生成新数据。可以从上述应用程序中找到清晰的使用说明。 相关研究论文： https://arxiv.org/abs/2303.14937 开源代码： https://github.com/CaglarAytekin/LEURN/ 联系人： caglar@deepcause.ai ​   由   提交 /u/MLC_Money   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhlajr/p_hugging_face_demo_app_explainable_generative_ai/</guid>
      <pubDate>Mon, 18 Mar 2024 07:51:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 部署 Mistral 7B - 量化方法、托管选项等（针对 GPU 较差的情况）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhkvay/d_deploying_mistral_7b_quantization_methods/</link>
      <description><![CDATA[我正在尝试为我正在构建的 RAG 应用程序部署 Mistral 7B api 端点。我感到困惑的一些主要事情 - 我的 GPU 很差:( 所以计划使用 AWS sagemaker 来部署模型 - 2 个月的免费计划每月有 125 小时的 m4.xlarge 或 m5.xlarge 实例用于推理- 这足以为量化的 Mistra 设置一个端点（我想是 5 位）吗？如果您自己没有 GPU 并且是一名破产的学生，那么模型托管的首选是什么？只需要它是我最后一年的项目，所以这不是一个长期的事情。此外，我对量化类型和方法感到困惑 - 首先是 AWQ、GGUF 和 GPTQ，因为它的效率，我倾向于 AWQ，但是我听说它的缺点是支持有限？如果我只是想部署 TheBloke 的 AWQ 模型，那应该不是特别困难的事情吧？另外，AWQ 的唯一缺点是它可能需要更多 RAM？还研究了部署方法本身 - openllama、vllama 等。我倾向于 vllama 因为效率 - 吞吐量是 Huggingface TGI 吞吐量的两倍，到目前为止我一直在使用 Huggingface TGI。但后来看到有人说它可能需要更多 VRAM？所以请提出建议 - 我的托管选项是什么，我应该使用什么量化方法，在这些有限的资源内，我有什么选择可以使这个模型尽可能快？ 注意：大多数情况下它不能得到帮助，我将不得不在模型速度上做出妥协，但我也想使用该模型来提取块的元数据，如果我向该模型提供 100 个块，我需要它不要慢到不切实际的地步哈哈。    由   提交/u/Aggravating-Floor-38   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhkvay/d_deploying_mistral_7b_quantization_methods/</guid>
      <pubDate>Mon, 18 Mar 2024 07:19:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于偏微分方程求解的神经算子背后的数学</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhj9av/d_math_behind_neural_operator_for_pde_solving/</link>
      <description><![CDATA[似乎几乎所有神经算子论文，如 FNO 等，总是使用 vt+1(x) = σ 形式的层（ W vt(x)+ ∫ K(x, y) vt(y) dy ) ，其中 t 是层。有什么证据证明这有效吗？看起来很多解释都表明该形式类似于格林函数解决方案，但每种方法都使用不同的内核，与格林函数或其工作原理没有具体关系。    由   提交/u/zarzor_2010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhj9av/d_math_behind_neural_operator_for_pde_solving/</guid>
      <pubDate>Mon, 18 Mar 2024 05:28:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] xAI 的 Qdrant...为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhhyrv/d_xais_qdrantwhy/</link>
      <description><![CDATA[也许我只是没有花时间去理解它，但我很难理解 Qdrant 为何比 OpenSearch/ElasticSearch 更好？ OS/ES 都使用 HNSW，并且它们都使用相同的 KNN oss 实现，性能非常好。 Qdrant 有什么“开箱即用”的功能？这些现有的且广泛采用的选项没有？   由   提交/u/titani0us  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhhyrv/d_xais_qdrantwhy/</guid>
      <pubDate>Mon, 18 Mar 2024 04:11:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何准备 META 研究工程师面试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhgxar/d_how_to_prepare_for_a_meta_research_engineer/</link>
      <description><![CDATA[我将在一周内进行 META 研究工程师面试。这个职位本身是机器学习和计算机视觉领域的，但我希望在面试中会被问到 leetcode 风格的问题。我想知道是否有人可以给我一些关于学习/复习内容的建议，因为只剩下一周了。   由   提交 /u/Tiny-Masterpiece-412   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhgxar/d_how_to_prepare_for_a_meta_research_engineer/</guid>
      <pubDate>Mon, 18 Mar 2024 03:16:01 GMT</pubDate>
    </item>
    <item>
      <title>xAI 发布 Grok-1 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh7yc4/xai_releases_grok1_n/</link>
      <description><![CDATA[ 我们正在发布大型语言模型 Grok-1 的基本模型权重和网络架构。 Grok-1 是一个由 xAI 从头开始​​训练的 3140 亿参数混合专家模型。 这是 Grok-1 预训练阶段的原始基础模型检查点，该阶段于 2023 年 10 月结束。这意味着该模型没有针对任何特定应用程序（例如对话）进行微调。 我们将在 Apache 2.0 许可证下发布权重和架构。 开始使用使用该模型时，请按照 https://github.com/xai-org/grok 中的说明进行操作   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh7yc4/xai_releases_grok1_n/</guid>
      <pubDate>Sun, 17 Mar 2024 20:38:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] Paperlib：一个开源且现代设计的学术论文管理工具。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh63c1/p_paperlib_an_opensource_and_moderndesigned/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh63c1/p_paperlib_an_opensource_and_moderndesigned/</guid>
      <pubDate>Sun, 17 Mar 2024 19:24:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>