<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 19 Mar 2024 09:12:58 GMT</lastBuildDate>
    <item>
      <title>[D] 如何将量化LLM与微软LIDA结合使用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bif90v/d_how_to_use_quantized_llm_with_microsoft_lida/</link>
      <description><![CDATA[Microsoft LIDA 是使用法学硕士自动生成可视化和信息图表的工具。我见过有人将它与非量化法学硕士一起使用。但就我而言，我使用 HF 中的 Nous-Hermes-llama-2-7b，并且找不到使用 LIDA 中的 llm API 以量化状态加载 LLM 的方法。这可以做到吗？  ​ 附注我是新手   由   提交/u/Stoner_Black_69   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bif90v/d_how_to_use_quantized_llm_with_microsoft_lida/</guid>
      <pubDate>Tue, 19 Mar 2024 08:19:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] NVIDIA GTC 2024 公告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bif6ey/d_nvidia_gtc_2024_announcements/</link>
      <description><![CDATA[NVIDIA 的计划已遍及加速计算、生成式 AI、行业应用、汽车、企业平台、Omniverse 和机器人领域。 其中一些最有趣的是：  DRIVE Thor：用于自动驾驶汽车中的生成式人工智能应用的车载计算平台。它每秒执行高达千万亿次操作，增强了自动驾驶的安全性，并支持与车辆的交互式对话。 Omniverse：融合物理和虚拟世界的数字孪生生态系统，帮助行业模拟、优化和识别更有效地执行操作。新的 Omniverse Cloud API 扩展了这些功能，使汽车和机器人等行业受益。 GR00T 项目：推动机器人和人工智能突破的人形机器人的基础模型。此外，还推出了 Jetson Thor 计算机，并升级至 NVIDIA Isaac™ 机器人平台，其中包含生成式 AI 模型和模拟工具。 Nvidia Blackwell GPU：一项尖端技术，旨在以 20 petaflops 的速度为下一代 AI 提供动力的性能。该GPU代表了人工智能能力的巨大飞跃，旨在实现万亿参数模型的民主化。 NVLink Switch 7.2 TI：新一代互连技术，可解决数据交换的瓶颈。它旨在促进 GPU 之间的通信，其规模适合最先进的 AI 模型。 NVIDIA NIM：一款新软件产品，旨在简化企业环境中生成式 AI 的部署。它将模型与优化的推理引擎打包在一起，并支持广泛的 GPU 架构。他们称其为所有人的人工智能包。  你最喜欢哪个？   由   提交 /u/vvkuka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bif6ey/d_nvidia_gtc_2024_announcements/</guid>
      <pubDate>Tue, 19 Mar 2024 08:13:59 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA Blackwell 平台到来，为计算新时代提供动力 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biei3t/nvidia_blackwell_platform_arrives_to_power_a_new/</link>
      <description><![CDATA[https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing  与相同数量的 NVIDIA H100 Tensor Core GPU 相比，GB200 NVL72 对于 LLM 推理工作负载的性能提升高达 30 倍，并将成本和能耗降低高达 25 倍。    由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biei3t/nvidia_blackwell_platform_arrives_to_power_a_new/</guid>
      <pubDate>Tue, 19 Mar 2024 07:23:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 适合分类数据的基于树的模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bidfrk/d_treebased_model_that_works_well_with/</link>
      <description><![CDATA[即不需要对类别进行单热编码，但知道通过类别的子集分割类别特征。我看到 lightgbm 和 catboost 可以做到这一点，任何人都可以用它们和分类数据来讲述他们在现实世界中的经历吗？   由   提交/u/question_23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bidfrk/d_treebased_model_that_works_well_with/</guid>
      <pubDate>Tue, 19 Mar 2024 06:08:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从 Java 中加载的 Python 训练的 XGBoost 模型预测不同吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bidakf/d_xgboost_model_trained_from_python_loaded_in/</link>
      <description><![CDATA[我已经用 python &amp; 训练了 xgboost 模型。 scikitlearn searchcv. scikitlearn search然后我用 Java 加载模型并对一些样本进行预测。它返回一个浮点值，而不是类的 1 或 0。该模型适用于返回 1 或 0 的 python。我错过了什么？   由   提交 /u/Vveriant   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bidakf/d_xgboost_model_trained_from_python_loaded_in/</guid>
      <pubDate>Tue, 19 Mar 2024 05:59:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单的拼写错误或我的理解错误？！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bicphu/d_simple_typos_or_errors_in_my_understanding/</link>
      <description><![CDATA[      虽然我给所有作者发了邮件，但我没有收到任何回复...&lt; /p&gt; ​ 我真的很喜欢阅读论文“基于能量的模型的组合视觉生成”(NeurIPS`20; https://arxiv.org/abs/2004.06030)。 当我遵循论文中的想法时，我在理解方程时遇到了问题（8 ）。 根据论文的符号，EBM定义为（1）： 等式。 (1) 即能量函数，E_\theta(x)，被定义为指数顶部的负项。 ​ 在等式中。在下面的（3）中，作者定义了从任何基于能量的模型（EBM）获取样本的SGLD步骤。 接下来，根据作者提出的“概念析取”，联合化概率密度定义为（ 7），以不同 EBM 能量函数的 log-sum-exp 的指数形式。 https://preview.redd.it/sas3f4yg58pc1.png?width=1005&amp;format=png&amp;auto=webp&amp;s =2bb0aa67cf2767ede091102ce22965e8c8bdbe7c 从（7）中，我了解到联合能量函数相应为 -logsumexp(-E(x|c1), ...), 从而对应 SGLD应该有加号。但是，在论文中，作者用减号表述了 SGLD，而我输了... &lt; p&gt;翻阅官方代码实现后， (https://github .com/yilundu/ebm_compositionality/blob/c7ac54366d2d5a15f71871448bd720bf5b3eb82d/celeba_combine.py#L150C9-L150C32)我发现我的组合能量函数推导（ E(x|\cup_ic_i) ）似乎是正确，根据代码中 `e_pos` 变量的赋值。 ​ 不过，我想对此进行一些澄清任何人都可以浏览一下这篇文章并检查我的想法吗？ 提前谢谢您！   由   提交/u/vaseline555  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bicphu/d_simple_typos_or_errors_in_my_understanding/</guid>
      <pubDate>Tue, 19 Mar 2024 05:21:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] NumPy 中的 BCE 损失实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bicjah/p_bce_loss_implementation_in_numpy/</link>
      <description><![CDATA[    &lt; /a&gt;  def bce_loss(a_true: &#39;张量&#39;, b_pred: &#39;张量&#39;) -&gt; &#39;Tensor&#39;:loss = -(a_true.data * np.log(b_pred.data) + (1 - a_true.data) * np.log1p(1 -b_pred.data)).mean() 结果 = Tensor(loss, {a_true, b_pred}, &quot;bce_loss&quot;) def _backward() -&gt;无： b_pred.grad += -np.divide(a_true.data, b_pred.data) + np.divide((1 - a_true.data),(1 - b_pred.data)) a_true.grad += -(np.log(b_pred.data) - np.log(1 - b_pred.data))result._backward = _backward 返回结果 bce_loss 我在 numpy 中实现了 bce_loss ，如上所述。在测试中，我的结果与 pytorch 的不匹配。有人可以看一下代码并指出我在哪里犯了错误吗？ 供参考，Pytorch 实现是 此处   由   提交 /u/qctm   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bicjah/p_bce_loss_implementation_in_numpy/</guid>
      <pubDate>Tue, 19 Mar 2024 05:10:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] Nvidia GTC24 的 GPT4 参数计数与我们从 Semianalysis 获得的泄漏相同</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bi16pg/d_same_param_count_for_gpt4_from_nvidia_gtc24_as/</link>
      <description><![CDATA[   A Semianalysis 早前的报告称 GPT-4 是一个 1.8T 参数的 MoE 模型，有 16 位专家，每个有 111B 个参数。这是 GTC 会议的屏幕截图，具有相同的数字。 https://preview.redd.it/vyzfx2sel5pc1.png?width=1764&amp;format=png&amp;auto=webp&amp;s=dfce1d55c84dbc3c51e69f376161c47958f9cf 70   由   提交 /u/takuonline   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bi16pg/d_same_param_count_for_gpt4_from_nvidia_gtc24_as/</guid>
      <pubDate>Mon, 18 Mar 2024 20:36:19 GMT</pubDate>
    </item>
    <item>
      <title>Stability AI 发布 SV3D [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bi16eh/stability_ai_releases_sv3d_n/</link>
      <description><![CDATA[https://stability.ai /news/introducing-stable-video-3d  SV3D 将单个对象图像作为输入并输出该对象的新颖的多视图。然后我们可以使用这些新颖的视图和 SV3D 来生成 3D 网格。    由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bi16eh/stability_ai_releases_sv3d_n/</guid>
      <pubDate>Mon, 18 Mar 2024 20:35:58 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 介绍 ocrtoolkit：您的首选 OCR 软件包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bi0li0/project_introducing_ocrtoolkit_your_goto_ocr/</link>
      <description><![CDATA[当然，让我们直接从 Hey Reddit 社区的 GitHub 存储库集成信息！ 我很高兴能够介绍 ocrtoolkit，一个功能强大的 OCR 软件包，旨在简化您的工作流程并提升您的 OCR 任务！ 我的项目的用途 如果您发现自己在应对 OCR 相关挑战的同时还要处理复杂的样板代码，那么您很幸运。 ocrtoolkit 简化了整个 OCR 流程，为图像文件处理、模型执行、结果解析等任务提供直观的包装器。让我们深入研究核心功能：  数据集模块：需要轻松加载图像文件或目录？ ocrtoolkit.datasets 模块就是您的最佳选择。 模型模块：与 paddleOCR 等流行的 OCR 框架无缝集成，通过 ocrtoolkit.models 模块实现 ultralytics 和 doctr。利用 ultralytics 的复杂对象检测模型在运行 OCR 之前查明感兴趣区域。 包装器模块：利用包装器进行对象检测、单词检测和识别借助 ocrtoolkit.wrappers 模块，轻松获得识别结果。此独立模块可确保通过 pip install ocrtoolkit 快速安装。 实用程序模块：访问大量实用程序来执行单词到行合并、使用 ocrtoolkit.utilities 模块进行几何操作、文件 I/O 等。  目标受众 无论您是研究人员开始进行 OCR 相关项目的开发人员或数据科学家，ocrtoolkit 可以满足您的需求。该软件包是您简化工作流程、试验不同模型和框架以及简化推理过程的首选解决方案。 比较 让我们讨论一下 ocrtoolkit 与现有替代方案不同：  全面支持：与仅专注于推理的软件包不同，ocrtoolkit 为无数OCR 相关任务，从后处理推理结果到保存/加载和轻松可视化。 无缝集成：体验与流行的 OCR 和对象检测框架的无缝集成，促进轻松实验 用户友好的设计：在设计时考虑到了易用性，ocrtoolkit 确保快速设置和配置，使用户能够深入了解轻松完成 OCR 任务。  ocrtoolkit 不适合做什么  训练模型：ocrtoolkit不是为训练新的 OCR 模型而设计的。相反，它的主要重点在于利用预训练或微调的模型进行推理。 高性能应用程序：虽然 ocrtoolkit 拥有在生产中的成功使用环境中，它可能不是需要最大性能优化的应用程序的理想选择。  其他资源 探索全面的文档，并在其 PyPi 页面上了解有关 ocrtoolkit 的更多信息。深入研究存储库中的 notebooks 文件夹，获取富有洞察力的示例，并毫不犹豫地分享您的反馈和建议！ 感谢您的宝贵时间，我热切等待您的宝贵意见见解！ ^_^   由   提交/u/ajkdrag_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bi0li0/project_introducing_ocrtoolkit_your_goto_ocr/</guid>
      <pubDate>Mon, 18 Mar 2024 20:13:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 扩散模型因自我调节而爆炸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhtyvr/d_diffusion_model_blows_up_with_self_conditioning/</link>
      <description><![CDATA[我正在训练 用于基因组数据集的 lucidrain 1d DDPM。如果我使用自我调节（模型可以看到自己之前的样本），那么在几百个批次之后我的损失就会增加到无穷大。如果没有自我调节，它似乎表现得很好。好奇是否还有其他人看过这个？ Analog Bits 论文介绍了自我调节，并声称它很有帮助。显然，我可以降低学习率，但不确定这会有多大帮助，因为训练的爆发时间稍晚一些。    由   提交/u/daking999  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhtyvr/d_diffusion_model_blows_up_with_self_conditioning/</guid>
      <pubDate>Mon, 18 Mar 2024 15:48:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] IJCAI'24反驳讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhspbk/d_ijcai24_rebuttal_discussion/</link>
      <description><![CDATA[大家好， 随着评论即将发布，我发起此线程来分享想法、问题和关于 IJCAI 提交的建议。 祝大家好运！   由   提交 /u/Acceptable_Pop1461   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhspbk/d_ijcai24_rebuttal_discussion/</guid>
      <pubDate>Mon, 18 Mar 2024 14:55:24 GMT</pubDate>
    </item>
    <item>
      <title>2024 年哪个库最适合时间序列预测和异常检测？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bho0r0/in_2024_which_library_is_best_for_time_series/</link>
      <description><![CDATA[我正在开发一个项目，负责识别时间序列数据中的异常情况。我遇到了 Facebook Prophet，但遗憾的是它自 2023 年以来就不再维护了。他们建议 NeuroProphet、nixtla 作为替代方案。在寻找替代方案时，我发现了来自 Facebook 的 Kats，它内置了先知支持。这里有哪些工具/库经验丰富的成员会推荐哪些工具/库来构建用于对大量时间序列数据进行异常检测的生产级系统？   由   提交 /u/ThakkidiMundan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bho0r0/in_2024_which_library_is_best_for_time_series/</guid>
      <pubDate>Mon, 18 Mar 2024 11:03:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当你使用人工智能进行总结时结果不正确时。爱思唯尔发表的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</link>
      <description><![CDATA[       由   提交 /u/vvkuka   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</guid>
      <pubDate>Mon, 18 Mar 2024 10:14:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>