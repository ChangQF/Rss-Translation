<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Mon, 13 May 2024 15:15:25 GMT</lastBuildDate>
    <item>
      <title>ML特征压缩[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cr1dn7/ml_feature_compression_d/</link>
      <description><![CDATA[大家好， 我们知道可以通过自动编码器、SVD、PCA 等使用特征缩减/压缩。&lt; /p&gt;  除了这些对他们有用的方法之外，还有其他人能想到的方法吗？ 在使用特征缩减时，您是否学到了任何技术？你想分享的岁月？     由   提交 /u/Odd_Background4864   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cr1dn7/ml_feature_compression_d/</guid>
      <pubDate>Mon, 13 May 2024 14:57:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用扩散模型进行时间序列异常检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cr14ki/d_time_series_anomaly_detection_with_diffusion/</link>
      <description><![CDATA[大家好，我正在开发一个使用扩散模型进行时间序列异常检测的项目。之前我使用过 CycleGAN 来学习映射 x -&gt; z-&gt; x_帽子。然后我测量 x 和 x_hat 之间的重建误差以检测异常。这相当简单，因为 GAN 中的潜在空间只是一个高斯分布，但在扩散模型的情况下，我认为由于前向和反向过程中的 N 次迭代，它会变得复杂。我的问题是如何调节扩散模型以产生与 x 几乎相同的 x_hat？我可以将 VAE（变分自动编码器）与扩散模型结合起来来帮助实现这一点吗？任何意见将不胜感激。   由   提交/u/mythroaway0852   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cr14ki/d_time_series_anomaly_detection_with_diffusion/</guid>
      <pubDate>Mon, 13 May 2024 14:46:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找遥感中点云理解的研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cqzkh8/d_looking_for_research_on_point_cloud/</link>
      <description><![CDATA[大家好， 我有兴趣了解更多有关应用点云理解技术的研究（例如分类和分割等） .) 到遥感数据。 您最近有推荐探索该领域的论文吗？ 任何领域：林业、城市环境、灾难响应.... ​   由   提交/u/Same_Half3758  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cqzkh8/d_looking_for_research_on_point_cloud/</guid>
      <pubDate>Mon, 13 May 2024 13:40:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我们的新分类算法在五个基准数据集上的准确性和响应时间上优于 CatBoost、XGBoost、LightGBM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cqv5y4/r_our_new_classification_algorithm_outperforms/</link>
      <description><![CDATA[大家好！ 我们很高兴与大家分享 LinearBoost，这是我们在机器学习分类算法方面的最新进展。 LinearBoost 基于增强线性分类器来显着提高性能。我们的测试表明，它在五个知名数据集上的准确性和响应时间方面优于传统 GBDT 算法。LinearBoost 增强性能的关键在于它在每个估计器阶段的方法。与 GBDT 中使用的决策树（按顺序选择特征）不同，LinearBoost 使用线性分类器作为其构建块，同时考虑所有可用特征。这种全面的功能集成可以在每一步实现更稳健的决策过程。 我们相信 LinearBoost 可以成为学术研究和实际应用的宝贵工具。在 GitHub 存储库中查看我们的结果和代码：https://github.com/LinearBoost/linearboost-classifier。该算法还处于起步阶段，并且存在 GitHub 存储库中报告的某些局限性，但我们正在未来的计划中对其进行研究。 我们很乐意获得您的反馈和建议以进一步改进，因为算法仍处于早期阶段！   由   提交/u/CriticalofReviewer2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cqv5y4/r_our_new_classification_algorithm_outperforms/</guid>
      <pubDate>Mon, 13 May 2024 09:33:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对 DSPy 的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cqq1in/d_thoughts_on_dspy/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cqq1in/d_thoughts_on_dspy/</guid>
      <pubDate>Mon, 13 May 2024 03:47:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 请考虑签署这封信以开源 AlphaFold3</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cqndld/d_please_consider_signing_this_letter_to_open/</link>
      <description><![CDATA[https:/ /docs.google.com/forms/d/e/1FAIpQLSf6ioZPbxiDZy5h4qxo-bHa0XOTOxEYHObht0SX8EgwfPHY_g/viewform Google DeepMind 最近发布了 AlphaFold 的新版本 AF3。 AF3 在仅根据氨基酸序列预测看不见的蛋白质结构方面实现了 SoTA。这次迭代还增加了对各种其他复合物（例如核酸、小分子、离子和修饰残基）的联合结构预测的能力。 AF3 是一种强大的生物信息学工具，可以帮助促进全球研究。不幸的是，Google DeepMind 选择保持其闭源。 请签署这封信！ AF3 : https://www.nature.com/articles/s41586-024-07487-w    ;由   提交 /u/TeamArrow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cqndld/d_please_consider_signing_this_letter_to_open/</guid>
      <pubDate>Mon, 13 May 2024 01:24:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] SimpleGEMM：CUDA 中快速且最小的张量核心矩阵乘法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cqhsln/p_simplegemm_fast_and_minimal_tensor_core_matrix/</link>
      <description><![CDATA[大家好！在这里分享我的副项目：https://github.com/andylolu2/simpleGEMM！ 这是一个极其在 CUDA 中实现矩阵乘法的极简但快速的实现。源代码是一个 200 行 CUDA/C++ 文件，它实现了 fp16 张量核心矩阵乘法，针对图灵 (SM75) 架构进行了优化。目标是：  编写一个不牺牲性能的 matmul 内核。事实上，如果您在 T4 上测试它，它比 PyTorch/CuBLAS 更快在 Colab 中！ 使其可用于新目的。例如，如果您想添加一个新的自定义序言（例如 Matmul + 一些缩减），只需转到第 186 行，添加您的代码，然后重新编译！完全灵活，没有 C++ 模板恶作剧。 使其尽可能简单。希望学习 CUDA 的人会发现这很有用！  当然，我并没有从头开始实现一切。其中大部分内容都基于 Nvidia CUTLASS 的新 CuTe 接口，用于内存布局、数据复制和使用张量核心指令等。 旁白： 为什么不选择 OpenAI Triton？我喜欢 Triton，但有时如果您在其主要优化路径之外进行某些操作，则很难获得额外 10-20% 的性能。事实上， triton 用于图灵 GPU 的 matmul 相当慢 （因为他们主要针对SM80+进行优化）。我只是喜欢完全控制硬件，因为我知道如果我有无限的时间，我可以榨取一点性能。    ;由   提交 /u/bjergerk1ng   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cqhsln/p_simplegemm_fast_and_minimal_tensor_core_matrix/</guid>
      <pubDate>Sun, 12 May 2024 20:55:20 GMT</pubDate>
    </item>
    <item>
      <title>[D]应主动学习样本班级统一</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cqejjc/d_should_active_learning_samples_classes_uniformly/</link>
      <description><![CDATA[当使用主动学习从未标记的数据集中采样图像时，现有的工作通常通过尝试为每个类提供统一数量的图像来实现。这种方法可以减轻某些数据集中可能存在的类别不平衡问题。 但是，在构建数据集时，我们希望我们的训练集在类别方面尽可能接近真实数据集分配。因此，AL 方法尝试对每个类采样统一数量的图像是否错误？   由   提交 /u/Feiwu7777   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cqejjc/d_should_active_learning_samples_classes_uniformly/</guid>
      <pubDate>Sun, 12 May 2024 18:33:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] DARWIN - 开源 Devin 替代方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cqd2ss/p_darwin_opensourced_devin_alternative/</link>
      <description><![CDATA[🚀 隆重介绍 DARWIN - 开源人工智能软件工程师实习生！ 🤖DARWIN 是一位由您指挥的人工智能软件实习生。它具有帮助您构建和部署代码的功能。通过访问互联网，达尔文依靠更新的知识来编写代码并执行它们。如果万一遇到错误，DARWIN 会尝试通过访问讨论和论坛来解决它。还有什么更好的呢？它是开源的。 DARWIN 还能够训练机器学习模型并解决 GitHub 问题。观看我们的视频教程，见证 DARWIN 的功能实际应用： 📹 视频 1：了解 DARWIN 如何理解复杂的代码库、进行深入研究、集思广益创新想法以及熟练地用多种语言编写代码。观看此处：达尔文简介 📹视频2：观看DARWIN 在此处训练机器学习模型：Darwin ML 训练&lt; br /&gt; 📹 视频 3：查看 DARWIN 如何自行解决 GitHub 问题： Darwin 解决了 Github 问题 我们将 Darwin 作为一个开源项目启动。尽管您不能出于商业目的复制它，但您可以自由地将其用于个人用途和日常工作生活中。 访问达尔文 加入我们，我们将揭开达尔文的全部潜力。从管理变更和错误修复到使用不同数据集训练模型，DARWIN 将成为您在软件开发方面的最终合作伙伴。 分享您的反馈、想法和建议，以塑造人工智能在工程领域的未来。让我们使用 DARWIN 更智能、更快速、更创新地进行编码！ 请继续关注更多更新，不要忘记查看 DARWIN 自述文件以获取安装说明和关键功能的详细列表。   由   提交 /u/Curious-Swim1266    reddit.com/r/MachineLearning/comments/1cqd2ss/p_darwin_opensourced_devin_alternative/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cqd2ss/p_darwin_opensourced_devin_alternative/</guid>
      <pubDate>Sun, 12 May 2024 17:28:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我们离 GPT-4V 还有多远？通过开源套件缩小与商业多式联运模式的差距</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cq8ufm/r_how_far_are_we_to_gpt4v_closing_the_gap_to/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.16821 代码：https://github .com/OpenGVLab/InternVL 模型：https://huggingface.co/ OpenGVLab 聊天演示：https://internvl.opengvlab.com/&lt; /a&gt; 拥抱脸部演示：https://huggingface.co/spaces /OpenGVLab/InternVL 摘要：  在本报告中，我们介绍InternVL 1.5，开源多模态大语言模型（MLLM），旨在弥合开源模型和专有商业模型在多模态理解方面的能力差距。我们介绍三个简单的改进：（1）强视觉编码器：我们为大规模视觉基础模型InternViT-6B探索了一种持续学习策略，提高了其视觉理解能力，并使其可以在不同的LLM中迁移和重用。 (2)动态高分辨率：根据输入图像的长宽比和分辨率，将图像划分为1到40个448×448像素的图块，最高支持4K分辨率输入。 （3）高质量的双语数据集：我们精心收集了高质量的双语数据集，涵盖常见场景、文档图像，并用英文和中文问答对对其进行注释，显着提高了 OCR 和中文相关任务的性能。我们通过一系列基准测试和比较研究来评估 InternVL 1.5。与开源和专有模型相比，InternVL 1.5 显示出具有竞争力的性能，在 18 个基准测试中的 8 个中取得了最先进的结果。代码已在此 https URL 发布。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cq8ufm/r_how_far_are_we_to_gpt4v_closing_the_gap_to/</guid>
      <pubDate>Sun, 12 May 2024 14:16:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过通用李群预条件子实现曲率通知的 SGD</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cq8guo/r_curvatureinformed_sgd_via_general_purpose/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.04553 代码（玩具实验）：https://github.com/lixilinx/psgd_torch 代码（大规模实验）：&lt; a href=&quot;https://github.com/opooladz/Preconditioned-Stochastic-Gradient-Descent&quot;&gt;https://github.com/opooladz/Precondition-Stochastic-Gradient-Descent 摘要：  我们提出了一种利用从 Hessian 向量乘积或参数和梯度的有限差分获得的曲率信息来加速随机梯度下降（SGD）的新方法，类似于BFGS算法。我们的方法涉及两个预处理器：无矩阵预处理器和低秩近似预处理器。我们使用对随机梯度噪声具有鲁棒性且不需要线搜索或阻尼的标准在线更新两个预处理器。为了保持相应的对称性或不变性，我们的预处理器被限制为某些连接的李群。李群的等方差性质简化了预处理器拟合过程，而其不变性质消除了二阶优化器中通常需要的阻尼的需要。因此，参数更新的学习率和预处理器拟合的步长自然被归一化，并且它们的默认值在大多数情况下都适用。我们提出的方法为以低计算开销提高 SGD 的收敛性提供了一个有前途的方向。我们证明，在多种现代深度学习架构中，预处理 SGD (PSGD) 在视觉、NLP 和 RL 任务上的表现优于 SoTA。我们在本文中提供了用于复制玩具和大规模实验的代码。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cq8guo/r_curvatureinformed_sgd_via_general_purpose/</guid>
      <pubDate>Sun, 12 May 2024 13:58:26 GMT</pubDate>
    </item>
    <item>
      <title>[P] 最新主要开放式 LLM 版本一览：Mixtral、Llama 3、Phi-3 和 OpenELM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cq6jgz/p_a_look_at_the_latest_major_open_llm_releases/</link>
      <description><![CDATA[       由   提交/u/seraschka  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cq6jgz/p_a_look_at_the_latest_major_open_llm_releases/</guid>
      <pubDate>Sun, 12 May 2024 12:15:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] unets如何实现空间一致性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cq5g4r/d_how_do_unets_achieve_spatial_consistency/</link>
      <description><![CDATA[嗨，我在这里阅读了unet pytorch实现https://github.com/lucidrains/denoising-diffusion-pytorch 但我还不明白去噪过程中的像素如何“知道”其在图像中的（相对）位置。虽然噪声量是使用时间参数嵌入来调节每个像素的，但空间位置却没有这样做？ 因此，当从纯噪声开始对猫的图像进行去噪时，是什么使得unet在图像的顶部创建猫的头，在图像的底部创建猫的脚？或者去噪肖像，头发在上，脖子在下？ 我认为卷积核可能会在其影响范围内保持局部空间连贯性，但这感觉“不够”。  输入图像也没有被下采样到最内层卷积核的大小。在引用的代码示例中，他们将 a128x128 在底层采样为 8x8。这又是 3 卷积，因此没有覆盖整个区域。 那么unet如何实现空间一致性/空间自动调节？ 谢谢   由   提交/u/Mr_Clueless_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cq5g4r/d_how_do_unets_achieve_spatial_consistency/</guid>
      <pubDate>Sun, 12 May 2024 11:08:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 太阳风暴对 Llama3 8B 的 QLORA + RLHF 的影响？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cq3uh4/d_impact_of_solar_storm_on_qlora_rlhf_of_llama3_8b/</link>
      <description><![CDATA[大家好， 在阅读一篇有关当前太阳风暴的文章时，我看到 NOAA 发出的关于太阳风暴影响的警告变压器上的风暴。 “可能会出现广泛的电压控制问题和保护系统问题，”美国国家海洋和大气管理局警告。 “一些电网系统可能会经历完全崩溃或停电。变压器可能会受到损坏。”  我目前正在 Llama3 8B 上进行 QLORA + RLHF 序列（我们正在尝试创建一个模型，通过提示创建更高效​​的 SQL 查询），我想知道这些影响是什么在 Llama3 8B 等型号上。你们中有人经历过伤害吗？对性能有何影响？   由   提交 /u/Standard_Natural1014   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cq3uh4/d_impact_of_solar_storm_on_qlora_rlhf_of_llama3_8b/</guid>
      <pubDate>Sun, 12 May 2024 09:17:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>