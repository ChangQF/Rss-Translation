<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 07 Oct 2024 09:18:58 GMT</lastBuildDate>
    <item>
      <title>[R] 改进 CNN-LSTM-AM 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fy37th/r_improving_a_cnnlstmam_model/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fy37th/r_improving_a_cnnlstmam_model/</guid>
      <pubDate>Mon, 07 Oct 2024 09:01:13 GMT</pubDate>
    </item>
    <item>
      <title>[R][P] AI 特工 LlamaIndex</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fy2y5d/rp_ai_agents_llamaindex/</link>
      <description><![CDATA[AI Agents LlamaIndex 速成课程 内容包括：  函数调用 函数调用代理 + Agent Runner Agentic RAG REAcT 代理：构建您自己的搜索助理代理  https://youtu.be/bHn4dLJYIqE    提交人    /u/External_Ad_11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fy2y5d/rp_ai_agents_llamaindex/</guid>
      <pubDate>Mon, 07 Oct 2024 08:40:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求建议：手写 OCR 的 LLM 与 Google Vision 的 LLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fy1iqx/d_looking_for_advice_llms_for_handwriting_ocr_vs/</link>
      <description><![CDATA[大家好！ 我正在做一个项目，需要从手写图像中提取文本。到目前为止，我一直在使用 Google Vision API，它对包括手写在内的一些文本效果很好，但我想知道是否有更直接的解决方案专门处理手写。 使用可以直接处理和读取手写内容的 LLM 是否有意义，还是坚持使用传统的 OCR 方法（如 Google Vision）仍然是可行的方法？我知道 GPT-4o/Gemini 等 LLM 具有这些功能，但我不确定它们处理基于图像的输入或手写的效果如何。 有人尝试过使用 LLM 进行 OCR 吗？您会推荐什么，是否有特定的模型可以擅长这项任务？ 我的想法是还使用 LLM 来总结手写文本，因此在流程的某个阶段，无论如何我都需要 LLM。 谢谢。    提交人    /u/Practical_Estate4971   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fy1iqx/d_looking_for_advice_llms_for_handwriting_ocr_vs/</guid>
      <pubDate>Mon, 07 Oct 2024 06:49:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言建模任务上的 Mamba 和 SSM 是一个很好的研究轨迹吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxzor7/r_is_mamba_and_ssms_on_language_modelling_task_a/</link>
      <description><![CDATA[我刚刚接触到 Mamba 和 SSM，因为我的教授说我应该尝试探索它。我是一名硕士生，刚刚开始我的研究之旅，我原本想像我系里的其他学生一样研究 transformers LM。有人说这会让我陷入别人以前没有做过的事情，会使我的学习/研究变得比预想的更难（最终可能会得到平庸的结果）。你们对此有什么看法吗？谢谢。    提交人    /u/worthlesspineapple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxzor7/r_is_mamba_and_ssms_on_language_modelling_task_a/</guid>
      <pubDate>Mon, 07 Oct 2024 04:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 正在从事客户流失预测项目，模型输出的流失窗口是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxyzkz/p_working_on_a_customer_churn_prediction_project/</link>
      <description><![CDATA[如果我使用的数据集包含过去 15 年的所有活跃客户和所有流失客户，我该如何决定我希望我的模型预测未来 90 天的情况？我相信在训练之前我应该​​在数据中进行某种“时间框架”，但我不确定如何解决此类问题    提交人    /u/Extension-Group2131   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxyzkz/p_working_on_a_customer_churn_prediction_project/</guid>
      <pubDate>Mon, 07 Oct 2024 03:57:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于工具使用和 LLM 代理有哪些有趣的论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxvsp7/d_what_are_some_interesting_papers_about_tooluse/</link>
      <description><![CDATA[目前，我正在研究 voyager (https://arxiv.org/abs/2305.16291)，但希望得到更多建议。TIA。    提交人    /u/a1_jakesauce_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxvsp7/d_what_are_some_interesting_papers_about_tooluse/</guid>
      <pubDate>Mon, 07 Oct 2024 01:04:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML 论文的敏感性分析获得了更好的结果，现在怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxu3zw/d_sensitivity_analysis_of_the_ml_paper_got_better/</link>
      <description><![CDATA[我使用一种新方法针对特定数据集撰写了一篇 ML 论文，取得了一些积极成果。我训练了几个模型，对它们进行了评估，并根据研究结果进行了广泛的解释和讨论。其中一位审稿人要求对一些预处理参数/算法进行敏感性分析。有趣的是，其中一项更改导致的结果比我原来的方法略好。 我的问题是：在这种情况下的期望是什么？我需要重写整篇论文，还是应该仅在敏感性分析中报告这一观察结果？虽然更改改善了结果，但想到要根据新的运行重写大部分解释（例如，特征重要性、图表、讨论等），还是很令人沮丧。你的想法和经验是什么？    提交人    /u/anagreement   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxu3zw/d_sensitivity_analysis_of_the_ml_paper_got_better/</guid>
      <pubDate>Sun, 06 Oct 2024 23:37:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 有没有想过在你的 m1 16gb ram Mac 上微调 Xtts？好吧，我不知道为它做了一个 repo，</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxt77o/p_ever_wanted_to_fine_tune_xtts_on_your_m1_16gb/</link>
      <description><![CDATA[   https://github.com/DrewThomasson/finetuneXtts_apple_silicone 你需要 16 gb ram 来运行，而 docker 版本需要更多的 ram 来运行 :/ 压缩模型按钮中的 Final_output_files 与 https://github.com/DrewThomasson/ebook2audiobookXTTS 兼容   由   提交  /u/Impossible_Belt_7757   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxt77o/p_ever_wanted_to_fine_tune_xtts_on_your_m1_16gb/</guid>
      <pubDate>Sun, 06 Oct 2024 22:51:36 GMT</pubDate>
    </item>
    <item>
      <title>上下文感知词语替换 [P] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxsuhg/context_aware_word_replacement_p_r/</link>
      <description><![CDATA[你好！ 我从事 CV 研究，所以对 NLP 不是很精通，所以需要输入。 我正在研究在保留图片上下文的情况下替换“句子”中的“单词”，以便我们更容易在数据集中搜索该单词的合适图像。例如： 句子 - “学生应该抵制网络欺凌，以免攻击者伤害他们” 单词 - “攻击者” 为什么预期 - 网络犯罪分子、网络欺凌者等，以便我可以搜索相关图像。 BeRT 和其他模型用什么来替换它 - 恐怖分子、计算机、敌对攻击者等。 我想在本地运行一些东西，但找不到任何解决方案。有什么想法或输入我应该尝试吗？有任何资源或代码笔记本吗？    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxsuhg/context_aware_word_replacement_p_r/</guid>
      <pubDate>Sun, 06 Oct 2024 22:34:34 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 如何从参考列表中将产品的多种变体映射到其正确的标准名称？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxs3i4/project_how_to_map_multiple_variations_of_a/</link>
      <description><![CDATA[我使用经过微调的 BERT 模型执行命名实体识别，并成功从非结构化数据集中提取了产品名称、数量和价格。但是，产品名称有变体，现在我需要将这些变体与参考列表中的正确标准化名称进行匹配。我可以使用哪些可能的方法来完成这项任务，每种方法的优缺点是什么？我考虑将其视为一个多类分类问题，其中使用 BERT 或 GPT-4 等模型将每个产品名称变体分类为预定义的标准名称之一。    提交人    /u/No_Possibility_7588   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxs3i4/project_how_to_map_multiple_variations_of_a/</guid>
      <pubDate>Sun, 06 Oct 2024 21:59:33 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 为什么正弦 PE 不适用于较长的序列？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxmn0z/discussion_why_dont_sinusoidal_pe_work_for_longer/</link>
      <description><![CDATA[从理论上讲，它们会生成独特的位置向量，然后将其添加到嵌入中，因此它们应该可以工作。有人知道为什么它们不起作用吗？    提交人    /u/tororo-in   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxmn0z/discussion_why_dont_sinusoidal_pe_work_for_longer/</guid>
      <pubDate>Sun, 06 Oct 2024 18:03:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</guid>
      <pubDate>Sun, 06 Oct 2024 15:00:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 LLM 培训中，增加批次大小和使用注意力掩蔽的打包序列有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxguh6/d_whats_the_difference_between_increasing_batch/</link>
      <description><![CDATA[我很好奇在固定长度序列上训练大型语言模型 (LLM) 时，以下两种方法之间的区别： 使用批量大小 = 4，其中每个样本的序列长度为 1024 个标记，并且它们被独立处理。将 4 个序列打包成一个批次，最大序列长度为 4096，并应用注意掩码以确保没有序列关注来自另一个序列的标记。 如果正确应用了注意掩码，确保不会关注其他序列，那么这两种方法在以下方面是否存在显着差异： 内存使用情况 计算成本 训练动态  据我所知，如果没有注意掩码，由于自注意力机制，打包会导致计算成本呈二次方增加。但是使用掩码后，计算和内存使用量不是与将它们作为批处理中的单独序列处理几乎相同吗？还是我遗漏了其他因素？    提交人    /u/JeanMichelRanu   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxguh6/d_whats_the_difference_between_increasing_batch/</guid>
      <pubDate>Sun, 06 Oct 2024 13:46:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] MaskBit：通过 Bit Tokens 生成无嵌入图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxfy91/r_maskbit_embeddingfree_image_generation_via_bit/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxfy91/r_maskbit_embeddingfree_image_generation_via_bit/</guid>
      <pubDate>Sun, 06 Oct 2024 13:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>