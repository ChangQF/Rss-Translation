<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sun, 07 Jul 2024 01:10:18 GMT</lastBuildDate>
    <item>
      <title>[R] 改进语音识别的室内脉冲响应估计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dx0kue/r_towards_improved_room_impulse_response/</link>
      <description><![CDATA[        由    /u/Snoo63916  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dx0kue/r_towards_improved_room_impulse_response/</guid>
      <pubDate>Sat, 06 Jul 2024 21:50:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从文章中提取 NER</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwxyy1/d_extracting_ner_from_articles/</link>
      <description><![CDATA[我有很多新闻文章需要从中提取标签和重要关键词。我尝试使用 NLTK、Spacy、Flair，但它们并不准确。我也尝试过使用 LLM，主要是 llama3、bert 等，但速度很慢。现在有什么建议/想法可以告诉我怎么做吗？    提交人    /u/expiredUserAddress   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwxyy1/d_extracting_ner_from_articles/</guid>
      <pubDate>Sat, 06 Jul 2024 19:50:18 GMT</pubDate>
    </item>
    <item>
      <title>研究论文中差异隐私的问题陈述[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwx51j/problem_statement_for_differential_privacy_for/</link>
      <description><![CDATA[嗨，ML 社区， 我正在深入研究令人兴奋的差异隐私世界，需要一些指导来识别引人注目的问题陈述。尽管阅读了五篇论文，但我还没有找到明确的方向。您能否分享任何有趣的问题陈述或建议潜在的探索途径？非常感谢您的见解！ 提前致谢    提交人    /u/Techxited_to_be_here   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwx51j/problem_statement_for_differential_privacy_for/</guid>
      <pubDate>Sat, 06 Jul 2024 19:12:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 交叉验证是否只能检测或减轻/避免过度拟合问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwweqt/d_does_crossvalidation_only_detect_or/</link>
      <description><![CDATA[YouTube 上有一位教授不同意竞赛的观点，即交叉验证可以减轻过度拟合。根据这位教授的说法，交叉验证只是检测过度拟合的存在。目前，我倾向于同意竞赛的观点，因为在我看来，交叉验证可以更好地评估错误，从而避免过度拟合。但是，我想保持开放的心态，听取您的意见，因为我想对事情有一个清晰的理解    提交人    /u/ZehEstocahstico   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwweqt/d_does_crossvalidation_only_detect_or/</guid>
      <pubDate>Sat, 06 Jul 2024 18:39:57 GMT</pubDate>
    </item>
    <item>
      <title>我如何从头开始训练一个简单的文本到图像传播模型！[D]（视频）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwvo45/how_i_trained_a_simple_text_to_image_diffusion/</link>
      <description><![CDATA[分享一段视频，介绍我从头开始实现简单的文本到图像条件扩散模型的经历。视频还从第一原理开始，一步一步地直观地解释了所有主要概念。如果您有兴趣，请观看，如果可以，请在频道上留下反馈！ https://youtu.be/w8YQcEd77_o    提交人    /u/AvvYaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwvo45/how_i_trained_a_simple_text_to_image_diffusion/</guid>
      <pubDate>Sat, 06 Jul 2024 18:05:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用元数据和 Python 下载托管数据集的最佳方式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwt33t/d_best_way_to_host_datasets_with_metadata_and/</link>
      <description><![CDATA[我有一堆想要公开的数据集，并且想将其下载为类似于 scikit-learn 或 sktime 中的示例数据集。 我的数据是表格形式的，但它也具有每个数据集的全局元数据，例如不同类型的分割。例如，数据集是：  包含实际数据的 CSV 按时间分割的训练/测试分割索引 按另一个分割的训练/测试分割索引  我已经考虑过并拒绝了：  UCI - 他们已经 3 个月没有批准我的数据集（“待定”状态）。 OpenML - 首先，网站上的上传不起作用（单击上传按钮时挂起）。其次，我不确定它是否允许额外的元数据文件，我认为不允许，因为任务和拆分似乎与数据集分开。 HuggingFace Hub - 不允许额外的元数据，如此处和此处所述。 Kaggle - 不允许公开下载，即它要求在下载之前进行身份验证，即使是从 Python API 也是如此。 AWS Open Data、BigQuery 公共数据集等 - 我绝不会将我的信用卡详细信息放在没有下载限制的公共数据集的任何地方。此外，设置它是件苦差事。 Zenodo - 基本上不为人知（尽管宣传和 SEO 不是我的主要关注点），而且不够稳定（刚才我试图在那里搜索一些东西时得到了 503）。  你对替代解决方案有什么想法吗？我开始认为老牌的 Google Drive 是最好的解决方案，只需上传带有数据集的目录即可。    提交人    /u/qalis   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwt33t/d_best_way_to_host_datasets_with_metadata_and/</guid>
      <pubDate>Sat, 06 Jul 2024 16:09:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 碳排放预测的机器学习模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwmqad/d_ml_model_for_carbon_emissions_prediction/</link>
      <description><![CDATA[我想知道哪种 ML 方法最适合预测碳排放。训练数据完全是数字的，我需要以两种方式或阶段使用该方法。这意味着稍后我需要添加额外的数字数据（列）来查看结果是否会改变。我个人的选择是 LSTM，但我想确保我不会犯一个以后会后悔的错误     提交人    /u/friendsbase   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwmqad/d_ml_model_for_carbon_emissions_prediction/</guid>
      <pubDate>Sat, 06 Jul 2024 10:38:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 时间序列模型基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwlvi5/p_time_series_model_benchmarking/</link>
      <description><![CDATA[我创建了一个帖子和一个演示应用程序，使用来自 40 个数据集的莫纳什大学基准对 13 个时间序列模型进行排名。与使用莫纳什网站相比，该应用程序以更易于使用的格式呈现信息，并且更容易比较模型性能。我还开始进行一些分析，以呈现显示模型方法与预测范围关系的图表，并计划随着时间的推移，使用尚未进行基准测试的较新模型进行自己的基准测试。排名系统是使用一级方程式积分系统完成的，但所有这些都有一个重要的观点，即促进更一致的时间序列模型评估标准。 F1 得分时间序列模型排行榜    提交人    /u/Inner_Potential2062   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwlvi5/p_time_series_model_benchmarking/</guid>
      <pubDate>Sat, 06 Jul 2024 09:36:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 扩散强制：下一个标记预测与全序列扩散相遇</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwkces/r_diffusion_forcing_nexttoken_prediction_meets/</link>
      <description><![CDATA[        由    /u/Rose52152   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwkces/r_diffusion_forcing_nexttoken_prediction_meets/</guid>
      <pubDate>Sat, 06 Jul 2024 07:43:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] DoRA LLM 微调详解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwijir/r_dora_llm_finetuning_explained/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwijir/r_dora_llm_finetuning_explained/</guid>
      <pubDate>Sat, 06 Jul 2024 05:44:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 所有在机器学习领域工作了数月或数年的人——多年来，您职业生涯中最大的时刻是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwhx5f/d_all_the_folks_working_on_machine_learning_for/</link>
      <description><![CDATA[每天都有很多新的实验以难以跟上的速度进行。 例如，对于 2015 年的我来说，最大的基本见解是，十年内 90% 以上的数据将是非结构化的，而现在正在发生这种情况。这促使我进入电子商务、零售、医疗保健、农业和汽车等各个领域探索机器学习等模型。    提交人    /u/Worth-Card9034   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwhx5f/d_all_the_folks_working_on_machine_learning_for/</guid>
      <pubDate>Sat, 06 Jul 2024 05:05:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LLM 进行实体提取</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwbcp5/d_entity_extraction_with_llms/</link>
      <description><![CDATA[我们很多人都在使用 LLM 从非结构化文本中提取实体。使用 LLM 进行实体提取的最大挑战是：  重复实体：例如，如果您从用户支持单中提取产品，LLM 可能会提取“产品：衬衫”。“产品：T 恤”、“产品：短袖”或“产品：衬衫”，具体取决于输入文本如何引用 衬衫。这意味着您可能需要严格迭代和监控 LLM 的行为（例如，确保 LLM 引用现有实体标签）。 添加新实体：当现有实体标签不匹配时，LLM 通常擅长在必要时提出新的实体标签。但是，如果不断引入新的实体标签（粒度不一致），这可能会变得难以管理。不幸的是，LLM 必须索引的实体标签列表越大，LLM 的准确性就越低。  因此，这里有一些提示可帮助您掌握提取：  设置警报：掌握输出非常重要。如果您每天处理大量文本，则为任何新的 DISTINCT 标签设置 SQL 警报是一个很好的第一步。 提供上下文：LLM 在上下文中表现更好。为任务和实体标签添加上下文。 后处理：创建后处理步骤来处理重叠实体并优化结果。 用少量样本处理歧义：识别一些模棱两可或棘手的示例，并将它们添加到提示中。 没有答案比错误答案更好：给 LLM 一个出路。如果没有好的实体，您将要大力鼓励 LLM 不要编造某些东西（他们仍然经常这样做）。 整合业务反馈：这取决于用例。实体提取通常可以用于提高操作效率或面向用户的功能。如果是这种情况，重要的是确认并与这些用户就“衬衫”是什么达成一致。工程师和利益相关者的观点通常不同。  如果仍然没有获得所需的准确度，可以尝试微调。经典的 ML 和 NER 库相当不可靠，但如果您迫切需要，值得尝试。 您还可以尝试一些为您处理此问题的外部服务。例如，我们使用类似 BERT 的模型提取原始实体 + 管理并将它们解析为具有非常高准确度的规范实体选项。当出现新实体（与现有实体不匹配）时，如果它们在我们的模型中达到足够高的置信度，我们会将它们添加到实体列表中。 请在下面评论您在实体提取方面的经验和技巧！    提交人    /u/Different-General700   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwbcp5/d_entity_extraction_with_llms/</guid>
      <pubDate>Fri, 05 Jul 2024 23:14:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师如何寻找客户</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwaed5/d_how_to_find_clients_as_a_machine_learning/</link>
      <description><![CDATA[我有一个关于自由职业者的快速问题。你如何联系客户？ 我所做的所有工作，都必须亲自与企业所有者交谈，并且几乎总是分享免费的演示，供他们在有限时间内使用，然后他们才同意以收入分成作为付款方式。 我喜欢这种模式，因为我工作越多，得到的报酬就越多。    提交人    /u/Regular-Connection46   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwaed5/d_how_to_find_clients_as_a_machine_learning/</guid>
      <pubDate>Fri, 05 Jul 2024 22:31:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 语言模型中上下文长度的指数增长</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw6e1r/d_p_exponential_growth_of_context_length_in/</link>
      <description><![CDATA[      https://preview.redd.it/0v289d9r2rad1.png?width=5376&amp;format=png&amp;auto=webp&amp;s=014fc378d270ac8f8a7090eab1880fb381fe67f4 LLM 上下文长度大小似乎在过去几年中呈指数级增长 - 从 T5/BERT/GPT-1 的 512 个标记到最新的 Gemini 1.5 Pro 的 200 万个标记。 目前尚不清楚上下文窗口是否会继续以这种速度增长，或者是否会在某个时候达到稳定状态。有多少上下文窗口变得没有必要？ （如果我们估计 100 个标记大约为 75 个单词，那么所有 7 本《哈利波特》书籍都可以容纳 150 万个标记。）  数据收集说明： 必须追踪每个单独模型的发布博客（如果有的话）并与它们的 API 文档（如果存在）进行交叉引用。或者一篇论文（如果有的话）。这个领域变化如此之快，而且一家公司发布具有 X 上下文窗口的模型，然后在 1 个月后更新 API 文档并说“但是等一下！上下文长度现在是 Y”的情况并不少见。） 分享下面的原始数据，因为我花了很多时间煞费苦心地收集这些数据。此外，如果我错过了什么，请随时进行抽查。 https://docs.google.com/spreadsheets/d/1xaU5Aj16mejjNvReQof0quwBJEXPOtN8nLsdBZZmepU/edit?gid=0#gid=0    提交人    /u/porkbellyqueen111   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw6e1r/d_p_exponential_growth_of_context_length_in/</guid>
      <pubDate>Fri, 05 Jul 2024 19:34:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>