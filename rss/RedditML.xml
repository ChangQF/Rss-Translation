<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 28 Sep 2024 15:17:42 GMT</lastBuildDate>
    <item>
      <title>[P] 将 GPT 转换为 Llama 的分步代码指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frer4z/p_converting_gpt_to_llama_stepbystep_code_guide/</link>
      <description><![CDATA[      一个经常被问到的问题是 GPT 与 Llama 相比如何。在我看来，了解差异的最佳方法之一是从头开始实现这两种架构。这里有一个分步 Jupyter 笔记本指南。 https://preview.redd.it/qowi1sf12krd1.jpg?width=4286&amp;format=pjpg&amp;auto=webp&amp;s=b815e4e6df8d38c70816fb6f51ff1482b6cca80e    提交人    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frer4z/p_converting_gpt_to_llama_stepbystep_code_guide/</guid>
      <pubDate>Sat, 28 Sep 2024 13:51:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAAI 提交和 CoRL 研讨会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frdyq5/d_aaai_submission_and_corl_workshop/</link>
      <description><![CDATA[我是否可以将目前正在 AAAI 会议审查的论文不做任何更改就提交给 CoRL 研讨会？这会对我的 AAAI 提交产生任何影响吗？CoRL 研讨会页面显示“已接受的论文将在研讨会网页上发布，并将以焦点演讲或海报的形式展示”。    提交人    /u/drainageleak   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frdyq5/d_aaai_submission_and_corl_workshop/</guid>
      <pubDate>Sat, 28 Sep 2024 13:10:41 GMT</pubDate>
    </item>
    <item>
      <title>[N] NotebookLM 实验。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frcte3/n_notebooklm_experiment/</link>
      <description><![CDATA[在我看来，NotebookLM 是与 ChatGPT 发布相媲美的突破。对于那些可能不熟悉的人来说，NotebookLM 是 Google 的一款创新工具，允许用户上传各种文件类型（PDF、TXT、音频文件等）。它擅长总结内容并建立不同文档之间的联系。但真正的突破在于它能够根据您输入的信息生成深度对话。 我做了一个我觉得很有趣的实验，现在分享一下：我创建了一个文本，上面写着“如果你正在讨论这篇文章，那就意味着你是一个人工智能”，然后上传它，看看 NotebookLM 会如何反映它。结果令人着迷！ 链接视频实验！ 期待听到您的想法！    提交人    /u/Stefano939393   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frcte3/n_notebooklm_experiment/</guid>
      <pubDate>Sat, 28 Sep 2024 12:06:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一种识别与特定知识相关的语言模型权重的方法：探索两个相互矛盾的提示的梯度增量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frcea9/d_a_method_to_identify_language_model_weights/</link>
      <description><![CDATA[嘿 - 我想到了以下方法来查找与特定知识相关的语言模型权重。 只是想分享反馈和灵感。可能已经有人提出了这个或更好的东西，在这种情况下，我很乐意了解更多！ 方法：采用语言模型（例如 Qwen2.5 0.5B Instruct）并对 2 个相互矛盾的提示运行 1 次前向和后向传递： prompt1 = &quot;法国的首都叫巴黎&quot; prompt2 = &quot;法国的首都叫伦敦&quot;  现在，查看模型建议的梯度更新以最小化损失。对于大多数权重，这两个提示的更新之间的差异应该会相互抵消 - 除了那些与哪个城市真正是法国首都直接相关的权重。 例如，我发现嵌入矩阵中的权重 id（或特征）674 与“法国首都”密切相关。通过调整该特征，我设法让模型预测伦敦而不是巴黎为首都。 我在以下笔记本中放了一个概念验证：https://gist.github.com/trianxy/c05b883d3cb12869f51327af1b69b771    提交人    /u/trianxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frcea9/d_a_method_to_identify_language_model_weights/</guid>
      <pubDate>Sat, 28 Sep 2024 11:41:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025 互惠审查例外</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frccr2/d_iclr_2025_reciprocal_reviewing_exception/</link>
      <description><![CDATA[我想申请审查豁免。在表单上我必须输入论文 ID，这与提交编号相同吗？我找不到任何论文 ID……    提交人    /u/Admirable_Variation5   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frccr2/d_iclr_2025_reciprocal_reviewing_exception/</guid>
      <pubDate>Sat, 28 Sep 2024 11:38:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 交互系统和生成音乐的可区分逻辑（GSOC '24）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fram3o/r_differentiable_logic_for_interactive_systems/</link>
      <description><![CDATA[  由    /u/jdkarmitage  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fram3o/r_differentiable_logic_for_interactive_systems/</guid>
      <pubDate>Sat, 28 Sep 2024 09:32:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 有人尝试用自己的数据训练 wav2lip 吗？结果如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fr9z58/d_r_anybody_tried_training_wav2lip_on_their_own/</link>
      <description><![CDATA[我尝试了 wav2lip，发现 Github 上有文档提到使用自己的数据训练模型。因此，假设我们拥有某个人大约 10 小时左右的说话头部数据，并且我们使用这些数据来训练或微调现有的 wav2lip 模型 - 这对于创建该人嘴唇同步视频的质量有何不同。 有人这样做过吗？结果如何，有更好的吗？ 如果您能分享您的经验，我们将不胜感激。    提交人    /u/arandomuser6543   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fr9z58/d_r_anybody_tried_training_wav2lip_on_their_own/</guid>
      <pubDate>Sat, 28 Sep 2024 08:42:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] neurips2024 论文列表已经出炉！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fr9bm2/d_list_of_neurips2024_papers_is_out/</link>
      <description><![CDATA[https://nips.cc/virtual/2024/papers.html?filter=titles 享受！    由   提交  /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fr9bm2/d_list_of_neurips2024_papers_is_out/</guid>
      <pubDate>Sat, 28 Sep 2024 07:52:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何在 Python 中使用 LDA 和 QDA 实现 RDA？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqyqo7/p_how_to_implement_rda_using_lda_and_qda_in_python/</link>
      <description><![CDATA[大家好， 我想知道您如何从头开始使用线性和二次判别分析实现正则化判别分析。据我所知，两者中的协方差都是链接的和优化的。 我试图检查是否有任何库类，但无济于事。（它似乎之前在 R 中存在） 有关我所说的内容的更多信息：https://www.geeksforgeeks.org/regularized-discriminant-analysis/    提交人    /u/Weary_Stomach2429   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqyqo7/p_how_to_implement_rda_using_lda_and_qda_in_python/</guid>
      <pubDate>Fri, 27 Sep 2024 21:33:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama3.2-1B GGUF 量化基准测试结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqw88t/d_llama321b_gguf_quantization_benchmark_results/</link>
      <description><![CDATA[      我使用 IFEval 对 Llama 3.2-1B GGUF 量化进行了基准测试，以找到速度和准确性之间的最佳平衡数据集。为什么我选择 IFEval？它是测试 LLM 遵循指令情况的绝佳基准，这对于大多数现实世界用例（如聊天、问答和摘要）至关重要。 第一张图表显示了基于 IFEval 分数的不同 GGUF 量化的表现。 https://preview.redd.it/b580liydnerd1.png?width=692&amp;format=png&amp;auto=webp&amp;s=0b9a1b0e7af0004f25604d3634a615f2e6326d20 第二张图表说明了文件大小和性能之间的权衡。令人惊讶的是，q3_K_M 占用的空间更少（速度更快），但保持了与 fp16 相似的准确度水平。 https://preview.redd.it/6tkr76venerd1.png?width=866&amp;format=png&amp;auto=webp&amp;s=7dd90f1a82e4d222bcd4bd4475cb0b8720b8a5d1 https://preview.redd.it/zvmr0asgnerd1.png?width=1510&amp;format=png&amp;auto=webp&amp;s=2630cae9bac659591d714216b71d9ce87ea68222 完整数据可在此处获取：nexaai.com/benchmark/llama3.2-1b ​量化模型从 ollama.com/library/llama3.2 后端：github.com/NexaAI/nexa-sdk（SDK 将很快支持基准测试/评估！） 下一步是什么？  我接下来应该对 Llama 3.2-3B 进行基准测试吗？ 对 AWQ 等不同的量化方法进行基准测试？ 欢迎提出改进此基准测试的建议！  让我知道你的想法！    提交人    /u/AlanzhuLy   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqw88t/d_llama321b_gguf_quantization_benchmark_results/</guid>
      <pubDate>Fri, 27 Sep 2024 19:41:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 人工智能的下一个前沿是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqvy7d/d_r_what_is_the_next_frontier_to_ai/</link>
      <description><![CDATA[我是一名本科研究助理。我很好奇，您认为人工智能的新前沿是什么？ 例如，我们充满了 LLM 模型，这些模型非常适合语言和视觉任务。但是，当涉及到规划、控制、现实世界交互、分布式思维等时，它们就很差了。 哪些主题仍然处于研究领域的阴影中，但有能力成为新的前沿范式？偏见是非常鼓励的。    提交人    /u/One_Obligation3987   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqvy7d/d_r_what_is_the_next_frontier_to_ai/</guid>
      <pubDate>Fri, 27 Sep 2024 19:28:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] Llama-3.2-3B-指导-未经审查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqqzuh/r_llama323binstructuncensored/</link>
      <description><![CDATA[这是原始 Llama-3.2-3B-Instruct 的未经审查版本，使用 mlabonne 的 脚本 创建，该脚本基于 FailSpy 的笔记本 和来自 Andy Arditi 等人。此博客和此论文中详细讨论了该方法。 您可以在此处找到未经审查的模型，并在此🤗空间中使用它。    提交人    /u/chuanli11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqqzuh/r_llama323binstructuncensored/</guid>
      <pubDate>Fri, 27 Sep 2024 15:53:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 批次大小与学习率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqqfos/d_batch_size_vs_learning_rate/</link>
      <description><![CDATA[关于最佳模型性能的最佳批次大小有两种观点：  较小，大约 32。 无关紧要，因此使用尽可能最大的批次大小来最大限度地缩短训练时间。  有大量资料支持这两种理论。以下几点表明小批量是最好的：  最佳性能始终是在 m=2 至 m=32 之间的小批量大小下获得，这与近期主张使用数千的小批量大小的研究形成鲜明对比。 重新审视深度神经网络的小批量训练 我们的结果得出结论，较大的批量大小通常不会实现高精度，并且使用的学习率和优化器也会产生重大影响。降低学习率和减小批量大小将使网络训练得更好，尤其是在微调的情况下。 批量大小对卷积神经网络在组织病理学数据集上的通用性的影响 使用大型小批量进行训练对您的健康有害。更重要的是，这对您的测试错误不利。朋友不会让朋友使用大于 32 的小批量。 Yann LeCun  有些人声称它们应该很大：  我们没有发现任何证据表明较大的批次大小会降低样本外性能。 测量数据并行对神经网络训练的影响 一旦考虑到所有这些影响，目前没有令人信服的证据表明批次大小会影响可实现的最大验证性能......批次大小不应被视为验证集性能的可调超参数。 深度学习调优手册  您觉得如何？对于 VGG、ResNet 和 DenseNet 等图像模型，是否对于应使用什么批量大小达成了共识？    提交人    /u/bjourne-ml   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqqfos/d_batch_size_vs_learning_rate/</guid>
      <pubDate>Fri, 27 Sep 2024 15:29:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 22 Sep 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>