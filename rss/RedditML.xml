<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Thu, 14 Mar 2024 03:14:10 GMT</lastBuildDate>
    <item>
      <title>LLM 在总结过程中也会“迷失在中间”吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1beb7vi/do_llms_get_lost_in_the_middle_during/</link>
      <description><![CDATA[论文“迷失在中间：语言模型如何使用长上下文”基本上讨论了LLM如何与“中间”的背景进行斗争。当给它们一个长上下文时，这在 RAG 用例的论文中进行了测试。我很好奇法学硕士在总结任务方面是否会表现出相同的特征？我们对此有什么见解吗？ 假设法学硕士也会在总结中展示完全相同的特征，并且它们会将大量数据中的较少信息包含到其中，这是否公平？最终总结？ 很想知道您对此的想法，这是原始论文： https ://arxiv.org/abs/2307.03172   由   提交/u/daxow  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1beb7vi/do_llms_get_lost_in_the_middle_during/</guid>
      <pubDate>Thu, 14 Mar 2024 03:11:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 与 JAX 的机器人硬件对比</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1be87iv/d_pytorch_vs_jax_for_robotics_hardware/</link>
      <description><![CDATA[使用 JAX 代替 PyTorch 是否能为机器人应用带来任何实质性好处，例如在 Jetson Orin 上执行推理任务以控制配备摄像头的移动机器人和激光雷达传感器？   由   提交 /u/anointedninja   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1be87iv/d_pytorch_vs_jax_for_robotics_hardware/</guid>
      <pubDate>Thu, 14 Mar 2024 00:48:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] [NAACL-2024] 将论证质量评估与相关知识结合起来</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1be5qth/r_naacl2024_contextualizing_argument_quality/</link>
      <description><![CDATA[ 由   提交/u/Megixist  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1be5qth/r_naacl2024_contextualizing_argument_quality/</guid>
      <pubDate>Wed, 13 Mar 2024 23:02:47 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 有没有一个网站可以用非常简单的文字分解最近的 ML 论文，并通过可视化彻底深入地解释数学？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1be40ox/discussion_is_there_a_website_that_breaks_down/</link>
      <description><![CDATA[我正在寻找论文分析网站或 YouTube 频道，以便更轻松地吸收最新或最近的 ML 研究。 Outlier 的 Youtube 视频就是一个很好的例子：扩散模型论文和数学解释。我真的很喜欢他对数学的深入研究，并用简单的语言进行解释，而没有假设有太多的数学能力。  我想要更多，尤其是与视觉相关的论文，但我也对更多领域持开放态度。    由   提交 /u/ChaosAdm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1be40ox/discussion_is_there_a_website_that_breaks_down/</guid>
      <pubDate>Wed, 13 Mar 2024 21:53:31 GMT</pubDate>
    </item>
    <item>
      <title>[D]OpenAI+图一</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1be36yr/d_openai_figure_one/</link>
      <description><![CDATA[我猜现在很多人已经看过图一演示了，如果没有的话：https://www.youtube.com/watch?v=Sq1QZB5baNw  有人知道模型的用途（类型）吗机器人的动作？是某种形式的强化学习还是离线强化学习？我知道图像/语言的解释是通过一些多模式 llm/vlm 发生的，但我想了解一下它输出什么样的动作/指令，例如移动对象。为这样的模型提供什么输入？   由   提交/u/Chronicle112  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1be36yr/d_openai_figure_one/</guid>
      <pubDate>Wed, 13 Mar 2024 21:20:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 数据解释器：数据科学的法学硕士代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdxqt4/r_data_interpreter_an_llm_agent_for_data_science/</link>
      <description><![CDATA[      摘要：  基于大型语言模型 (LLM) 的代理已表现出显着的有效性。然而，在需要实时数据调整、由于各种任务之间复杂的依赖关系而需要优化专业知识以及识别逻辑错误以进行精确推理的能力的数据科学场景中，它们的性能可能会受到影响。在本研究中，我们介绍了数据解释器，这是一种旨在用代码解决问题的解决方案，强调三种关键技术来增强数据科学中的问题解决：1）具有分层图结构的动态规划，以实现实时数据适应性； 2）动态工具集成，以提高执行过程中的代码熟练程度，丰富所需的专业知识； 3）反馈中的逻辑不一致识别，通过经验记录提高效率。我们在各种数据科学和实际任务中评估数据解释器。与开源基线相比，它表现出了卓越的性能，在机器学习任务方面表现出显着改进，从 0.86 提高到 0.95。此外，数学数据集增加了 26%，开放式任务显着提高了 112%。该解决方案将在 https://github.com/geekan/MetaGPT 发布。  ​ https: //preview.redd.it/6bcww0qb15oc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=d98f2e05fbdf06f186b93782a786dc94b3d33bac ​ &lt; a href=&quot;https://preview.redd.it/565u97cc15oc1.png?width=1116&amp;format=png&amp;auto=webp&amp;s=fdefeda7c7733e610e0984ba7d7b77024d91a1b0&quot;&gt;https://preview.redd.it/565u97cc15oc1.png?width =1116&amp;format=png&amp;auto=webp&amp;s=fdefeda7c7733e610e0984ba7d7b77024d91a1b0 ​ https://preview.redd.it/a4c6lopc15oc1.png?width=1150&amp;format=png&amp;auto=webp&amp;s= 8b1e7cc27f3a2a9b75a66da0fdd54d29bf988f86 ​ https://preview.redd.it/lab3uh2d15oc1.png?width=731&amp;format=png&amp;auto=webp&amp;s=9f1506e607eb644b77bd2ba22e2189d0 05e1c010    由   提交/u/MetaGPT   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdxqt4/r_data_interpreter_an_llm_agent_for_data_science/</guid>
      <pubDate>Wed, 13 Mar 2024 17:46:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] Sequoia：可扩展、稳健和硬件感知的推测解码 - 卡内基梅隆大学 2024 年 - 允许在 RTX4090 上运行未量化的 Llama2-70B，每个令牌延迟为半秒！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdvxx4/r_sequoia_scalable_robust_and_hardwareaware/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.12374  Github：https://github.com/Infini-AI-Lab/Sequoia/tree/main  摘要：  作为大语言的用法模型（法学硕士）不断增长，利用这些模型进行高效推理变得越来越重要。虽然推测解码最近已成为加速推理的一个有前途的方向，但现有方法在扩展到更大的推测预算以及适应不同的超参数和硬件方面的能力受到限制。本文介绍了 Sequoia，一种可扩展、稳健且硬件感知的推测解码算法。为了获得更好的可扩展性，红杉引入了动态编程算法来寻找推测代币的最佳树结构。为了实现稳健的推测性能，Sequoia 使用了一种新颖的采样和验证方法，该方法在不同的解码温度下优于之前的工作。最后，红杉引入了一个硬件感知树优化器，它通过自动选择给定硬件平台的令牌树大小和深度来最大化推测性能。 评估表明，Sequoia 将 Llama2-7B、Llama2-13B 和 Vicuna-33B 在 A100 上的解码速度提高了 4.04 倍、3.73 倍和 2.27 倍。对于 L40 上的卸载设置，Sequoia 可实现低至 0.56 秒/令牌的精确 Llama2-70B 推理延迟，在我们优化的卸载系统（5.6 秒/令牌）上为 9.96 倍，是 DeepSpeed-Zero-Inference 的 9.7 倍（19.5 倍）比Huggingface加速。   https://preview.redd.it/jcj5kyscp4oc1.jpg?width=1399&amp;format=pjpg&amp;auto=webp&amp;s=7c0cc12c010052a4b2e30078ff5750cd15a48f 65 https://preview.redd.it/nz477yscp4oc1.jpg?width=1576&amp;format =pjpg&amp;auto=webp&amp;s=ed899be7bbdc65f4d326cadc6647c108c6525dde   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdvxx4/r_sequoia_scalable_robust_and_hardwareaware/</guid>
      <pubDate>Wed, 13 Mar 2024 16:35:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在许多模拟世界中扩展可指导的代理 - DeepMind 2024 - SIMA - 适用于 3D 虚拟环境的通用 AI 代理。玩《无人深空》和《英灵神殿》等 AAA 游戏！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdv12w/r_scaling_instructable_agents_across_many/</link>
      <description><![CDATA[   博客：https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/  论文：https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/sima-generalist-ai-agent-for-3d- virtual-environments/Scaling%20Instructable%20Agents%20Across%20Many%20Simulated%20Worlds.pdf  摘要：  构建体现人工智能系统能够在任何 3D 环境中遵循任意语言指令是创建通用人工智能的关键挑战。实现这一目标需要学习感知和具体行动中的基础语言，以完成复杂的任务。 可扩展、可指导的多世界代理 (SIMA) 项目通过培训代理在各种虚拟 3D 环境中遵循自由形式的指令来解决这个问题，包括精心策划的研究环境以及开放式环境结束了，商业视频游戏。我们的目标是开发一种可指导的代理，可以完成人类在任何模拟 3D 环境中可以做的任何事情。我们的方法侧重于语言驱动的通用性，同时施加最小的假设。我们的代理使用通用的类人界面与环境实时交互：输入是图像观察和语言指令，输出是键盘和鼠标操作。这种通用方法具有挑战性，但它允许代理在许多视觉上复杂且语义丰富的环境中使用语言，同时也允许我们在新环境中轻松运行代理。在本文中，我们描述了我们的动机和目标、我们取得的初步进展，以及在几种不同的研究环境和各种商业视频游戏中有望取得的初步结果。  https://preview.redd.it/mm746aq3j4oc1.jpg?width=1033&amp;format =pjpg&amp;auto=webp&amp;s=c9a5a4fda870b8849c0698389dbea842255ed5de https://preview.redd.it/0kvx3eq3j4oc1.jpg?width=1277&amp;format=pjpg&amp;auto=webp&amp;s=f3a22b1a2b8101184502584ce1361 486e672f358 https://preview.redd.it/xs9qddq3j4oc1.jpg?width=1395&amp; ;format=pjpg&amp;auto=webp&amp;s=064d0b1c979a188094b0251f2f28ca9014d90b61 https://preview.redd.it/xktm5dq3j4oc1.jpg?width=1584&amp;format=pjpg&amp;auto=webp&amp;s=0f917b83b7b69fa3ffa936d5e8810 de3b6998176    由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdv12w/r_scaling_instructable_agents_across_many/</guid>
      <pubDate>Wed, 13 Mar 2024 15:59:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文（ACL 调查结果 2023）：反对（和支持）自我训练的神经网络：使用小型标记集和大型未标记集进行分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdv0v8/r_paper_acl_findings_2023_neural_networks_against/</link>
      <description><![CDATA[您可以在此处找到该论文： https: //arxiv.org/abs/2401.00575 代码如下： https:// github.com/p-karisani/RST   由   提交 /u/payam_ka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdv0v8/r_paper_acl_findings_2023_neural_networks_against/</guid>
      <pubDate>Wed, 13 Mar 2024 15:58:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] MetaVoice 文本转语音 (TTS) 基准：RTX 3080 上每 1 美元可处理 23,300 个单词 - 加上 10 位阅读《哈利·波特》名人的语音克隆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdtqm5/p_metavoice_texttospeech_tts_benchmark_23300/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdtqm5/p_metavoice_texttospeech_tts_benchmark_23300/</guid>
      <pubDate>Wed, 13 Mar 2024 15:06:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 理解本地 LLM 推理的 50 多个开源选项</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdrqit/p_making_sense_of_50_opensource_options_for_local/</link>
      <description><![CDATA[嗨，reddit！ 我从这个社区学到了很多关于在本地运行开放权重法学硕士的知识，我知道这是多么令人难以承受它可以是在开源 LLM 推理工具的领域中导航。这就是为什么我创建了 awesome-local-llms GitHub 存储库，以将所有可用选项编译为一个简化的版本 在此存储库中，我抓取了公开可用的 GitHub 指标，例如星星、贡献者、问题、发布以及自上次提交以来的时间。这使得社区能够做出明智的选择，并及时了解哪些项目受欢迎且得到积极维护。我们都知道，随着时间的推移，一些较小的项目可能会变得无人维护，尤其是 UI 工具，因此让这些信息易于访问至关重要。 我选择不将存储库分为 LLM 推理引擎、LLM 等类别UI 或一体化桌面应用程序。这是因为项目范围经常重叠，并且不断添加新功能，使得手动标记很快就过时了。但是，如果您有改进组织或添加其他功能的建议，请告诉我！ 由 Jan 团队维护的一个出色的现有存储库，对一些 LLM 推理工具进行了分类：https://github.com/janhq/awesome-local-ai。 我也在考虑添加为了完整起见，列出了专有的闭源 LLM 工具（例如 LM Studio 和 Faraday）。此外，我正在考虑添加 UI 的屏幕截图/GIF 画廊，以提供对每个工具界面的视觉洞察。您认为这会对社区做出有用的贡献吗？ 非常感谢您对如何改进此存储库的想法和建议！如果您发现该存储库很有用并且希望了解其最新进展，请考虑在 GitHub 上给它一颗星。  也欢迎贡献！   由   提交 /u/lethal_can_of_tuna   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdrqit/p_making_sense_of_50_opensource_options_for_local/</guid>
      <pubDate>Wed, 13 Mar 2024 13:41:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 所有最先进的法学硕士在许多领域都在业余水平上犯了事实错误。这比专家级别更难训练吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdi4nr/d_all_state_of_the_art_llms_make_factual_mistakes/</link>
      <description><![CDATA[我最近读到了GPQA，专家 -生物学、物理和化学中非常困难的问题的水平基准。显然克劳德3非常擅长这些问题。  然而，当我向 Claude 3 和 GPT-4 询问有关我有“专门业余”领域的领域时，Claude 3 和 GPT-4 始终给出错误的信息。这些是我希望对该主题感兴趣的人在没有该领域知识的情况下会问的问题类型。通常，错误会在谈话的早期出现，如果我深入研究任何细节，错误就会增加。  例如摄影和相机设计。我问“为什么老照片中的人们不微笑？”并给出了几个可能的因素。进一步询问其中之一，即相机的物理限制，开始引入幻觉的细节，而询问这些幻觉的细节会给出更多看似事实的东西，而忽略了实际的事实，并引入了更多的不一致之处。语言也是如此——如果你对外语的语法或发音系统了解很多，你会发现要求对这些事情的解释往往会给你带来错误的信息。这些例子来自上周，包括 Claude 3 Opus 和 GPT-4。  如果您有自己感兴趣的领域，SOTA 法学硕士能否掌握所有详细信息？  为什么不更加强调提高此类会话知识的准确性？训练和测试是否简单得多？   由   提交/u/Axon350  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdi4nr/d_all_state_of_the_art_llms_make_factual_mistakes/</guid>
      <pubDate>Wed, 13 Mar 2024 04:01:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 窃取生产语言模型的一部分</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdf11z/r_stealing_part_of_a_production_language_model/</link>
      <description><![CDATA[我们引入了第一个模型窃取攻击，该攻击从 OpenAI 的 ChatGPT 或 Google 的 PaLM-2 等黑盒生产语言模型中提取精确的、重要的信息。具体来说，在给定典型的 API 访问的情况下，我们的攻击恢复了变压器模型的嵌入投影层（直到对称性）。我们的攻击花费不到 20 美元，提取了 OpenAI 的 ada 和 Babbage 语言模型的整个投影矩阵。由此，我们首次确认这些黑盒模型的隐藏维度分别为 1024 和 2048。我们还恢复了 gpt-3.5-turbo 模型的精确隐藏维度大小，并估计恢复整个投影矩阵的查询成本低于 2,000 美元。我们以潜在的防御和缓解措施作为结论，并讨论了可能扩大我们的攻击范围的未来工作的影响。 论文：https://arxiv.org/pdf/2403.06634.pdf   由   提交 /u/AdamEgrate   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdf11z/r_stealing_part_of_a_production_language_model/</guid>
      <pubDate>Wed, 13 Mar 2024 01:36:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习面试倦怠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bd5hh4/d_ml_interview_burnout/</link>
      <description><![CDATA[我觉得我因数据科学面试而精疲力尽。我在该领域担任数据科学家已有 5 年了。这个领域有很多技术性的东西。尤其是在2023年，关于如何优化LLM模型和向量DB的使用的新论文层出不穷。我花在面试准备上的时间越多，我用来获取新知识的时间就越少。我应该怎么做才能克服这种情况？非常感谢。 为什么我觉得面试准备没有什么用 在实际工作中，我们可以针对一个话题进行不同的准备来回忆所有的内容。在向其他同事展示想法之前，先记忆并正确组织概念。然而，是否可以在采访过程中立即调取所有信息呢？有些知识可以追溯到学校课本上，几十年来一直没有人接触过。有些问题涉及不太常见的设计模式。当我无法回答一个问题时，我会感到难过，不是因为我不知道，而是因为我确实无法在短时间内总结出来。这就像数据被存档到AWS S3冰川一样，因此数据检索既耗时又昂贵。另外，不能回答一些代码设计模式并不意味着我不能写出好的代码并解决问题。为了准备这些面试，我尝试重新审视一些关键概念和各种不太有用的代码模式，但这非常耗时。老实说，这些工作的工资确实很高。我不是在谈论任何大型科技公司，而是在谈论一些中小企业。我对标准感到困惑。   由   提交 /u/MillionLiar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bd5hh4/d_ml_interview_burnout/</guid>
      <pubDate>Tue, 12 Mar 2024 19:03:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>