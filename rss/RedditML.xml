<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 16 Jul 2024 15:13:09 GMT</lastBuildDate>
    <item>
      <title>[D] 我如何将我的 CS/ML/LLM 学术研究论文货币化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4r1el/d_how_can_i_monetize_my_csmlllm_academic_research/</link>
      <description><![CDATA[我发表了几篇关于大型语言模型 (LLM) 的论文，并得到了社区的积极反馈。我的下两篇论文更实用，解决了现实世界的问题。一篇是关于代理的，另一篇是关于 RAG 的（有点）。老实说，接下来的两篇论文实际上是一些创业想法的秘诀，我不知道将它们作为研究论文免费发布是否会搬起石头砸自己的脚。一方面，作为一名学者，我关心的是免费传播知识和科学。另一方面，我希望能够从我的研究成果中受益，并有可能将其货币化。我是一名独立作者，所以我不必担心知识产权问题。此外，我现在是一名国际博士候选人，我不知道这会让创办公司/初创公司、吸引风险投资等方面的事情变得多么复杂。    提交人    /u/nderstand2grow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4r1el/d_how_can_i_monetize_my_csmlllm_academic_research/</guid>
      <pubDate>Tue, 16 Jul 2024 15:08:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文讨论：超越：生成模型的表现可以超越训练它们的专家</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</link>
      <description><![CDATA[大家好， 正如标题所示：我创建这篇文章是为了讨论最近发布的论文，该论文到目前为止引起了很多关注。我刚刚阅读了这篇论文，有一些问题。如果你也读过并喜欢这篇论文，我们聊聊吧！ https://arxiv.org/abs/2406.11741  设置对你来说清楚吗？作者是否也通过实验测试了定理 3 或定理 4？ 训练数据集中有多少专家/玩家？如果他们测试定理 4，他们是否会在特定玩家的游戏上训练集合的每个成员？ 他们如何鼓励定理 3 中的不相交集条件？ 等式 4 有一个拼写错误（两个术语相同）？     提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</guid>
      <pubDate>Tue, 16 Jul 2024 14:27:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] Cuda 12.5 Docker 容器错误。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4ps0k/d_cuda_125_docker_container_error/</link>
      <description><![CDATA[Cuda 12.5 的 Cuda 版本控制错误 我正在远程服务器上部署一个 docker 容器。服务器在 Cuda 12.5 上运行，而容器内我使用的是 pytorch 2.3.1+cu121（我猜它是从 transformers 库安装的）。 我收到以下错误： 无法加载库 libcudnn_ops_infer.so.8。错误：libcudnn_ops_infer.so.8：无法打开共享对象文件：没有此文件或目录 我有什么解决方案可以修复容器，而不是将服务器上的 cuda 版本恢复为 11.8。    提交人    /u/cedar_mountain_sea28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4ps0k/d_cuda_125_docker_container_error/</guid>
      <pubDate>Tue, 16 Jul 2024 14:16:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 蛋白质语言模型揭示病毒模仿和免疫逃逸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</link>
      <description><![CDATA[我们被 ICML 24/ML4LMS 研讨会接受了，所以我想分享一下 :) &quot;蛋白质语言模型揭示病毒模仿和免疫逃逸&quot; TL;DR: 🧬 研究概述：病毒模仿宿主蛋白以逃避免疫系统的检测。我们使用蛋白质语言模型 (PLM) 来区分病毒蛋白和人类蛋白，ROCAUC 为 99.7%，准确率为 97%。 📊 见解：我们的研究表明，PLM 和生物免疫系统会犯类似的错误。通过识别和分析这些错误，我们可以深入了解免疫反应性以及开发更有效的疫苗和治疗方法的潜在途径。 我们还展示了一种新颖的、可解释的、多模式表格错误分析方法，用于理解任何问题的见解和错误，让我们了解深度学习语言模型/PLM 所犯错误的特征。 🔗 论文：https://openreview.net/forum?id=gGnJBLssbb&amp;noteId=gGnJBLssbb 代码：https://github.com/ddofer/ProteinHumVir 与我和海报见面（#116）在 ICML/ML4LMS 研讨会上！：https://openreview.net/attachment?id=gGnJBLssbb&amp;name=poster doi： https://doi.org/10.1101/2024.03.14.585057    提交人    /u/ddofer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</guid>
      <pubDate>Tue, 16 Jul 2024 09:13:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] “创造性”解码策略怎么了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e42das/d_what_happened_to_creative_decoding_strategy/</link>
      <description><![CDATA[对于 GPT-2 以及当时的大多数模型，简单的贪婪解码极易快速生成重复且无意义的输出，需要使用许多技术，例如 top-p 采样、核采样、重复惩罚、n-gram 惩罚等。（例如 https://arxiv.org/pdf/1904.09751 ） 对于最近的 LLM，我没有使用任何这些技巧，相反，0 到 1 之间的任何温度似乎都可以正常工作。我观察到的唯一重复生成似乎是在数学推理中，当模型想要进行一些没有成功的穷举搜索时。  那么，所有这些自定义解码策略是否都已成为过去，我们不再需要担心退化内容生成？     提交人    /u/zyl1024   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e42das/d_what_happened_to_creative_decoding_strategy/</guid>
      <pubDate>Mon, 15 Jul 2024 18:35:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用生成树进行具有自我批评的任意属性条件分子生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e416fw/r_anypropertyconditional_molecule_generation_with/</link>
      <description><![CDATA[  由    /u/AlexiaJM  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e416fw/r_anypropertyconditional_molecule_generation_with/</guid>
      <pubDate>Mon, 15 Jul 2024 17:47:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于如何利用未知数据改进时间序列预测的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e40guh/d_ideas_on_how_to_improve_time_series_forecasting/</link>
      <description><![CDATA[大家好，我的公司决定添加一个分析套件作为我们产品的一部分，而我的任务是创建一个预测解决方案。 我的问题始于这样一个事实：我不知道我将获得什么数据。它可以是每月的财务汇总，例如收入，也可以是每日销售数据。 我目前使用 ETS、SARIMAX、Holt-Winters 和 N-beats 的实现（以防万一）。我使用扩展窗口进行自动超参数调整，然后选择具有最佳 MAPE 的模型。 至于预处理，我会删除非季节性的异常值，并在将数据提供给模型之前使用 Savitzky-Golay 过滤器。 关于如何让这一切不那么像万福玛利亚，有什么建议吗？    提交人    /u/Ok_Bottle2306   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e40guh/d_ideas_on_how_to_improve_time_series_forecasting/</guid>
      <pubDate>Mon, 15 Jul 2024 17:20:09 GMT</pubDate>
    </item>
    <item>
      <title>[N] Yoshua Bengio 的最新公开信回应了反对严肃对待 AI 安全的论点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3viby/n_yoshua_bengios_latest_letter_addressing/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3viby/n_yoshua_bengios_latest_letter_addressing/</guid>
      <pubDate>Mon, 15 Jul 2024 14:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 印地语 NER 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3tdng/d_ner_model_for_hindi_language/</link>
      <description><![CDATA[我正在 NER 上建立一个项目。我能够找到适合英语的良好模型。有没有适合印地语和其他印度语言的好模型。我尝试了 IndicNLP、BERT 等，但输出效果不佳。有人可以帮我找到一个好的模型吗？    提交人    /u/expiredUserAddress   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3tdng/d_ner_model_for_hindi_language/</guid>
      <pubDate>Mon, 15 Jul 2024 12:19:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最佳开源 LLM，用于基于图表的问答</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3s9zq/d_best_open_source_llm_for_graph_based_questions/</link>
      <description><![CDATA[因此，这个问题分为两部分：  用于从非结构化文本创建知识图谱的 LLM 基于知识图谱回答问题  就开源/微调 LLM 而言，有人有使用过其中任何一种的经验吗？    提交人    /u/Raise_Fickle   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3s9zq/d_best_open_source_llm_for_graph_based_questions/</guid>
      <pubDate>Mon, 15 Jul 2024 11:19:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您认为最佳的“检索增强生成”编排器是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3p5fx/d_best_retrieval_augmented_generation/</link>
      <description><![CDATA[因此，我目前正在开发一个包含 Gen AI 和适用于 gemini 1.5 flash 的 vertex ai 的项目，我计划为其添加一个 RAG 系统，并且我计划使用 MongoDB 作为矢量数据库以简化操作。现在，我正在尝试决定应该使用哪个编排器来为 RAG 系统加速开发。你们有什么建议？    提交人    /u/PsychologicalAd7535   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3p5fx/d_best_retrieval_augmented_generation/</guid>
      <pubDate>Mon, 15 Jul 2024 07:52:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于如何创建分层 LLM 工作流程的想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3fpz4/d_ideas_on_how_to_create_a_hierarchical_llm/</link>
      <description><![CDATA[是否可以创建一个 AI 代理工作流，让 LLM A 可以来回与 LLM B 对话，例如 10 次，以迭代特定案例，并且仅在这 10 次通过后才返回响应？ 例如，如果我有一个严格提示的低温 LLM 1 和一个不太严格、更有创意的 LLM2。LLM2 批评 LLM1 并给出如何改进（迭代）的建议。您可以指定“重复”的次数，例如，运行 LLM 2 最多 6 次或 10 次或我设置的任何次数。 想法是创建一个解决方案，您可以在其中将“主管”置于“工人或工人”之上，并将其构建到 LLM 层次模型中。我正在尝试使用 SmythOS 来快速创建概念证明，但我甚至无法在两个 LLM 之间来回传递数据。对于我的特定需求，我必须构建一个具有一定数量重复的多级层次结构。 为了很好地呈现它： LLM1 - 为文章创建大纲 LLM2 - 撰写文章并交给 LLM3 审阅 LLM3 - 根据他的清单对其进行批判性审查。 如果一切都很好，就会产生最终的回应，如果不是，LLM 3 会指出需要改进的地方并将其交给 LLM 4 以征求批判性见解（LLM 4 是一种预先提示的 LLM，它将提供非常具体的见解或关注以特定方式传递的特定感觉/信息），然后它将整个脚本交还给 LLM2，LLM2 是唯一真正在写作的 LLM。该过程重复进行，直到满足 LLM3 或超过 X 次重复（其中 X 是您提前设置的）。  您将如何进行此操作？    提交人    /u/moonbunR   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3fpz4/d_ideas_on_how_to_create_a_hierarchical_llm/</guid>
      <pubDate>Sun, 14 Jul 2024 23:09:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] Flash Attention 是什么？解释一下</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e36jye/r_what_is_flash_attention_explained/</link>
      <description><![CDATA[与标准 Attention 机制相比，Flash Attention 有重大改进（Attention 中用到的就够了），它在空间和时间复杂度上都有所提升。更多信息请查看：https://youtu.be/znhk2mgplWY?si=Q3fz5GuMuyyWSdhd    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e36jye/r_what_is_flash_attention_explained/</guid>
      <pubDate>Sun, 14 Jul 2024 16:32:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] Graph Vision：一个用于创建段映射的 Python 库。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e35cs4/r_graph_vision_a_python_library_to_create_segment/</link>
      <description><![CDATA[        提交人    /u/Kian5658   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e35cs4/r_graph_vision_a_python_library_to_create_segment/</guid>
      <pubDate>Sun, 14 Jul 2024 15:42:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>