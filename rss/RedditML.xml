<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 06 Jul 2024 18:17:52 GMT</lastBuildDate>
    <item>
      <title>我如何从头开始训练一个简单的文本到图像传播模型！[D]（视频）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwvo45/how_i_trained_a_simple_text_to_image_diffusion/</link>
      <description><![CDATA[分享一段视频，介绍我从头开始实现简单的文本到图像条件扩散模型的经历。视频还从第一原理开始，一步一步地直观地解释了所有主要概念。如果您有兴趣，请观看，如果可以，请在频道上留下反馈！ https://youtu.be/w8YQcEd77_o    提交人    /u/AvvYaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwvo45/how_i_trained_a_simple_text_to_image_diffusion/</guid>
      <pubDate>Sat, 06 Jul 2024 18:05:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] oneAIclick：私有 LLM 管道抽象工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwv4yw/d_oneaiclick_a_private_llm_pipeline_abstraction/</link>
      <description><![CDATA[嘿 r/MachineLearning ！ 是否曾经想让语言模型更好地处理您的数据，但不确定如何使用本地 LLM？厌倦了与 OpenAI 共享敏感数据？ 进入 oneAIclick：只需单击几下即可提升语言模型针对您的特定用例的性能的平台。同时您的数据保留在您的基础设施上。  我们提供以下服务：  本地部署 微调 LLM 自定义 RAG（检索增强生成）管道 多智能体系统  查看我们的演示视频，了解如何使用您的私人数据，只需单击几下即可微调 LLM。 我们让入门变得非常简单：  输入您的训练数据和其他简单参数。 接收微调模型的推理端点 与您的产品无缝集成  用例？无穷无尽。想象一下根据您产品的客户反馈微调 LLM，以自动创建和分配支持工单。  我们目前处于 Alpha 阶段，正在寻求验证。如果您有兴趣在您的产品中集成或测试本地 LLM，而无需担心供应商锁定或数据隐私问题，我们很乐意听取您的意见。  加入我们的候补名单：https://www.oneaiclick.com  有问题？评论？功能请求？我们洗耳恭听！让我们知道 oneAIclick 如何改进并帮助解决您的特定 AI 挑战。    提交人    /u/BAKA_04   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwv4yw/d_oneaiclick_a_private_llm_pipeline_abstraction/</guid>
      <pubDate>Sat, 06 Jul 2024 17:42:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用元数据和 Python 下载托管数据集的最佳方式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwt33t/d_best_way_to_host_datasets_with_metadata_and/</link>
      <description><![CDATA[我有一堆想要公开的数据集，并且想将其下载为类似于 scikit-learn 或 sktime 中的示例数据集。 我的数据是表格形式的，但它也具有每个数据集的全局元数据，例如不同类型的分割。例如，数据集是：  包含实际数据的 CSV 按时间分割的训练/测试分割索引 按另一个分割的训练/测试分割索引  我已经考虑过并拒绝了：  UCI - 他们已经 3 个月没有批准我的数据集（“待定”状态）。 OpenML - 首先，网站上的上传不起作用（单击上传按钮时挂起）。其次，我不确定它是否允许额外的元数据文件，我认为不允许，因为任务和拆分似乎与数据集分开。 HuggingFace Hub - 不允许额外的元数据，如此处和此处所述。 Kaggle - 不允许公开下载，即它要求在下载之前进行身份验证，即使是从 Python API 也是如此。 AWS Open Data、BigQuery 公共数据集等 - 我绝不会将我的信用卡详细信息放在没有下载限制的公共数据集的任何地方。此外，设置它是件苦差事。 Zenodo - 基本上不为人知（尽管宣传和 SEO 不是我的主要关注点），而且不够稳定（刚才我试图在那里搜索一些东西时得到了 503）。  你对替代解决方案有什么想法吗？我开始认为老牌的 Google Drive 是最好的解决方案，只需上传带有数据集的目录即可。    提交人    /u/qalis   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwt33t/d_best_way_to_host_datasets_with_metadata_and/</guid>
      <pubDate>Sat, 06 Jul 2024 16:09:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 碳排放预测的机器学习模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwmqad/d_ml_model_for_carbon_emissions_prediction/</link>
      <description><![CDATA[我想知道哪种 ML 方法最适合预测碳排放。训练数据完全是数字的，我需要以两种方式或阶段使用该方法。这意味着稍后我需要添加额外的数字数据（列）来查看结果是否会改变。我个人的选择是 LSTM，但我想确保我不会犯一个以后会后悔的错误     提交人    /u/friendsbase   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwmqad/d_ml_model_for_carbon_emissions_prediction/</guid>
      <pubDate>Sat, 06 Jul 2024 10:38:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 时间序列模型基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwlvi5/p_time_series_model_benchmarking/</link>
      <description><![CDATA[我创建了一个帖子和一个演示应用程序，使用来自 40 个数据集的莫纳什大学基准对 13 个时间序列模型进行排名。与使用莫纳什网站相比，该应用程序以更易于使用的格式呈现信息，并且更容易比较模型性能。我还开始进行一些分析，以呈现显示模型方法与预测范围关系的图表，并计划随着时间的推移，使用尚未进行基准测试的较新模型进行自己的基准测试。排名系统是使用一级方程式积分系统完成的，但所有这些都有一个重要的观点，即促进更一致的时间序列模型评估标准。 F1 得分时间序列模型排行榜    提交人    /u/Inner_Potential2062   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwlvi5/p_time_series_model_benchmarking/</guid>
      <pubDate>Sat, 06 Jul 2024 09:36:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 扩散强制：下一个标记预测与全序列扩散相遇</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwkces/r_diffusion_forcing_nexttoken_prediction_meets/</link>
      <description><![CDATA[        由    /u/Rose52152   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwkces/r_diffusion_forcing_nexttoken_prediction_meets/</guid>
      <pubDate>Sat, 06 Jul 2024 07:43:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语言模型 - 为什么会发生重复？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwjyjt/d_language_models_why_do_repetitions_happen/</link>
      <description><![CDATA[这对我来说有点违反直觉。LM 尝试根据先前的标记对下一个标记的概率分布进行建模。如果我们在高质量数据（例如不包含大量重复的 fineweb-edu）上对其进行训练，则生成应该反映训练数据 - 没有重复的文本。LM 可以看到上下文中已经存在的内容，那么为什么它会为导致重复的标记分配高概率？这仅仅是因为我们从模型中采样的方式，例如 top-1？或者可能是因为 LM 没有提前计划的能力？两者都有？    提交人    /u/kiockete   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwjyjt/d_language_models_why_do_repetitions_happen/</guid>
      <pubDate>Sat, 06 Jul 2024 07:16:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] DoRA LLM 微调详解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwijir/r_dora_llm_finetuning_explained/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwijir/r_dora_llm_finetuning_explained/</guid>
      <pubDate>Sat, 06 Jul 2024 05:44:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 所有在机器学习领域工作了数月或数年的人——多年来，您职业生涯中最大的时刻是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwhx5f/d_all_the_folks_working_on_machine_learning_for/</link>
      <description><![CDATA[每天都有很多新的实验以难以跟上的速度进行。 例如，对于 2015 年的我来说，最大的基本见解是，十年内 90% 以上的数据将是非结构化的，而现在正在发生这种情况。这促使我进入电子商务、零售、医疗保健、农业和汽车等各个领域探索机器学习等模型。    提交人    /u/Worth-Card9034   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwhx5f/d_all_the_folks_working_on_machine_learning_for/</guid>
      <pubDate>Sat, 06 Jul 2024 05:05:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LLM 进行实体提取</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwbcp5/d_entity_extraction_with_llms/</link>
      <description><![CDATA[我们很多人都在使用 LLM 从非结构化文本中提取实体。使用 LLM 进行实体提取的最大挑战是：  重复实体：例如，如果您从用户支持单中提取产品，LLM 可能会提取“产品：衬衫”。“产品：T 恤”、“产品：短袖”或“产品：衬衫”，具体取决于输入文本如何引用 衬衫。这意味着您可能需要严格迭代和监控 LLM 的行为（例如，确保 LLM 引用现有实体标签）。 添加新实体：当现有实体标签不匹配时，LLM 通常擅长在必要时提出新的实体标签。但是，如果不断引入新的实体标签（粒度不一致），这可能会变得难以管理。不幸的是，LLM 必须索引的实体标签列表越大，LLM 的准确性就越低。  因此，这里有一些提示可帮助您掌握提取：  设置警报：掌握输出非常重要。如果您每天处理大量文本，则为任何新的 DISTINCT 标签设置 SQL 警报是一个很好的第一步。 提供上下文：LLM 在上下文中表现更好。为任务和实体标签添加上下文。 后处理：创建后处理步骤来处理重叠实体并优化结果。 用少量样本处理歧义：识别一些模棱两可或棘手的示例，并将它们添加到提示中。 没有答案比错误答案更好：给 LLM 一个出路。如果没有好的实体，您将要大力鼓励 LLM 不要编造某些东西（他们仍然经常这样做）。 整合业务反馈：这取决于用例。实体提取通常可以用于提高操作效率或面向用户的功能。如果是这种情况，重要的是确认并与这些用户就“衬衫”是什么达成一致。工程师和利益相关者的观点通常不同。  如果仍然没有获得所需的准确度，可以尝试微调。经典的 ML 和 NER 库相当不可靠，但如果您迫切需要，值得尝试。 您还可以尝试一些为您处理此问题的外部服务。例如，我们使用类似 BERT 的模型提取原始实体 + 管理并将它们解析为具有非常高准确度的规范实体选项。当出现新实体（与现有实体不匹配）时，如果它们在我们的模型中达到足够高的置信度，我们会将它们添加到实体列表中。 请在下面评论您在实体提取方面的经验和技巧！    提交人    /u/Different-General700   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwbcp5/d_entity_extraction_with_llms/</guid>
      <pubDate>Fri, 05 Jul 2024 23:14:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师如何寻找客户</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwaed5/d_how_to_find_clients_as_a_machine_learning/</link>
      <description><![CDATA[我有一个关于自由职业者的快速问题。你如何联系客户？ 我所做的所有工作，都必须亲自与企业所有者交谈，并且几乎总是分享免费的演示，供他们在有限时间内使用，然后他们才同意以收入分成作为付款方式。 我喜欢这种模式，因为我工作越多，得到的报酬就越多。    提交人    /u/Regular-Connection46   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwaed5/d_how_to_find_clients_as_a_machine_learning/</guid>
      <pubDate>Fri, 05 Jul 2024 22:31:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 语言模型中上下文长度的指数增长</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw6e1r/d_p_exponential_growth_of_context_length_in/</link>
      <description><![CDATA[      https://preview.redd.it/0v289d9r2rad1.png?width=5376&amp;format=png&amp;auto=webp&amp;s=014fc378d270ac8f8a7090eab1880fb381fe67f4 LLM 上下文长度大小似乎在过去几年中呈指数级增长 - 从 T5/BERT/GPT-1 的 512 个标记到最新的 Gemini 1.5 Pro 的 200 万个标记。 目前尚不清楚上下文窗口是否会继续以这种速度增长，或者是否会在某个时候达到稳定状态。有多少上下文窗口变得没有必要？ （如果我们估计 100 个标记大约为 75 个单词，那么所有 7 本《哈利波特》书籍都可以容纳 150 万个标记。）  数据收集说明： 必须追踪每个单独模型的发布博客（如果有的话）并与它们的 API 文档（如果存在）进行交叉引用。或者一篇论文（如果有的话）。这个领域变化如此之快，而且一家公司发布具有 X 上下文窗口的模型，然后在 1 个月后更新 API 文档并说“但是等一下！上下文长度现在是 Y”的情况并不少见。） 分享下面的原始数据，因为我花了很多时间煞费苦心地收集这些数据。此外，如果我错过了什么，请随时进行抽查。 https://docs.google.com/spreadsheets/d/1xaU5Aj16mejjNvReQof0quwBJEXPOtN8nLsdBZZmepU/edit?gid=0#gid=0    提交人    /u/porkbellyqueen111   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw6e1r/d_p_exponential_growth_of_context_length_in/</guid>
      <pubDate>Fri, 05 Jul 2024 19:34:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 受限解码作为状态导航？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw2pqo/d_constrained_decoding_as_stateful_navigation/</link>
      <description><![CDATA[在实现 LLM 驱动的代理时，存在一系列方法，具体取决于“包装”程序尝试构造、控制或处理 LLM 的输入和输出的程度。一种方法涉及包装程序解析 LLM 的输出，并且为了使此过程更可靠，LLM 的解码器被限制为特定语法（例如 XML 或 JSON）或甚至特定的 XML 或 JSON 模式。 将解码器限制为您当前需要的语法通常是通过将违反语法的潜在输出值的概率归零来实现的。但是，如果 LLM 没有接受过针对您尝试执行的语法的任何特定培训，则此策略可能不是最佳的。 让我们以一个非常简单的语法为例。此语法中的有效字符串以双引号字符开头和结尾。字符串内部有两个字符必须“转义”：反斜杠和双引号。转义序列以反斜杠开头。 合法：“John 说，\&quot;This is a legal string.\&quot;。&quot; 合法：“John 说，&quot; 非法：“John 说，&quot;This string makes me sad.&quot;&quot;&quot; 如果我们将解码器视为“试图”用其输出表示某些编码向量，则它只有在“提前计划”一点点的情况下才能在此语法中这样做。它可能“想要”发出一个双引号字符，并且无论之前的内容是什么，语法都允许这样做。但是，如果该双引号字符前面没有反斜杠，则字符串必须在双引号之后立即结束，以使字符串合法。如果它“想要”发出双引号但不结束，它需要“知道”它不想在不久的将来结束并且为了不结束，它需要先发出反斜杠。 那么如何获得这种有计划的解码 - 理想情况下，同时能够使用尽可能接近现成的预训练 LLM？我不确定，但我有一个模糊的想法，我想知道社区会对此有何看法。 假设我们可以访问预训练的 LLM，包括中间层的激活。我们还有我们想要限制输出的语法，以图形的形式，其边缘标有潜在输出*。最后，我们有一个独热向量，指示解码过程当前位于语法图中的哪个节点（或者，对于语法的非确定性表示，是一个 k-hot 向量）。 来自预训练 LLM 的激活可用于为语法图的边缘分配“朴素可取性”。但是，出现了两个考虑因素：  要遍历的最理想边可能与当前状态无关。要到达那些边，我们可能需要遍历其他边（这可能需要我们发出其他输出标记）。在语义层面上，这“可以”吗？例如，某些恶意语法可能要求任何单词​​“dogs”的实例前面都有单词“absolutely no”。如果我到目前为止已经解码了“I love”，并且到达了“dogs”是可取的，我不想越过需要“绝对不”的语法边缘，否则我最终会说“我绝对不爱狗”。  在我们最终确定要发出的标记并将我们移动到语法图中的新节点之后，这是一个可以考虑我们可能还剩下什么需要解码的地方吗？  这些考虑让我认为通过语法表达 LLM 的编码含义就像玩 Metroidvania 式的游戏，其中不同的路径具有不同的成本和回报。不幸的是，我几乎没有灵活的游戏模型背景，所以我不确定从这一点开始要学习什么等（假设这首先是一条值得的攻击路线......）    提交人    /u/jpfed   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw2pqo/d_constrained_decoding_as_stateful_navigation/</guid>
      <pubDate>Fri, 05 Jul 2024 16:57:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 发布我基于 VGG 感知损失的损失函数。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw2dfb/p_releasing_my_loss_function_based_on_vgg/</link>
      <description><![CDATA[您好，这是我已经做了一段时间的项目。我使用“VGG Loss”在我的某些项目中，我一直觉得从一个模型中提取信息来训练另一个模型很有趣。 以此为灵感，我创建了这个项目，它允许您使用几乎任何来自 PyTorch 的预训练模型作为训练新模型的基础。 在代码中，您可以找到一个使用 DINOv2 作为损失函数（扮演 VGG 的角色）的示例，但该函数旨在接受除 Dino 之外的任何其他模型，甚至不接受图像作为输入的模型，例如 LLM 或任何其他模型。 这是一个专门为我在我的项目中使用和共享而开发的项目，所以我没有附加任何文章，它的大部分逻辑都是在我的项目中使用时通过反复试验开发出来的。 在 GitHub 描述中，有更多关于它的信息。我希望这个项目对某些人有用。 https://github.com/BurguerJohn/global_perceptual_similarity_loss     提交人    /u/CloverDuck   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw2dfb/p_releasing_my_loss_function_based_on_vgg/</guid>
      <pubDate>Fri, 05 Jul 2024 16:43:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>