<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 03 May 2024 03:15:43 GMT</lastBuildDate>
    <item>
      <title>[D] 研究用于工作的 AI/LLM 开发机器的硬件选项。对中小型模型的训练和推理。迷失在硬件规格中——帖子中的详细信息。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciwipe/d_looking_at_hardware_options_for_an_aillm/</link>
      <description><![CDATA[您好， 在工作中，我被要求研究和开发一些与内部软件套件结合使用 LLM 的东西。由于政策原因，我不能透露太多细节，但最终会涉及一些 PII 识别/提取、一些文档摘要、可能还有一点 RAG 等。 在过去的一两个月里，我使用非常小的模型做了一些初步的基础工作，以表明某些事情“是可能的”，但我们希望将其提升到一个新的水平。 目前，我一直在 AMD 线程撕裂机上结合使用笔记本电脑的 GPU（仅移动 RTX 3060）和我老板的 RTX 4080。即使在一些较小的模型上，3060 也很快失败，但 4080 在推理方面表现相当不错。但正如您所想象的，我在尝试做任何稍微更强大的事情时很快就耗尽了 VRAM。 我的部分任务是指定一些硬件用于本地开发机器/桌面。我们已经订购了更多生产级硬件，这些硬件具有非常可观的 VRAM 数量（我认为它徘徊在 1 TB 左右，但不是 100% 确定），用于我们的数据中心，但至少几个月后才能到达。 因此，我正在寻找一些开发工作站的建议。我无法得出结论，我是否应该运行多个 GPU，或者花钱购买内置更多 VRAM 的东西。例如，我是否运行双 3090？我是否运行一个或两个 A6000？还是一个？单个 RTX 6000 Ada（48GB）是否足够？ 鉴于：  这仅用于开发，不用于生产 我想推断中小型模型（可能最多 30b 个参数） 我可能想微调中小型模型，如果有的话作为比较点。即使使用 LoRA/QLoRA 微调将在 Python 端完成，推理将使用 HuggingFace 的 Rust candle 库完成 我不鼓励使用基于云的东西（无法详细说明），无论构建什么软件，最终投入生产都无法与任何外部 API 通信 我不介意使用量化模型进行开发，但在某些时候我想尝试全精度模型（可能需要等待生产硬件出现） 我想说钱不是问题，但如果我的预算低于 15,000 美元，那将是理想的  你们都推荐什么？ 谢谢！    提交人    /u/IThrowShoes   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciwipe/d_looking_at_hardware_options_for_an_aillm/</guid>
      <pubDate>Fri, 03 May 2024 01:26:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为博士生/研究员提高 MLOps 技能的良好策略/资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciryee/d_good_strategies_resources_to_improve_mlops/</link>
      <description><![CDATA[许多 ML 领域的研究人员/博士生最终都有加入该行业的前景（据统计，在美国，大约 80% 的 ML 博士都在该行业）最近发布的斯坦福大学人工智能指数）。 对于某人来说，有哪些好的技巧/资源可以确保他开发出更实用且更实用的技术？面向部署的 MLOps 技能？ 例如 - 设置集群、相关云服务（例如 AWS）、Docker、Kubernetes、开发用于模型训练/数据标签的内部工具......诸如此类。   由   提交/u/fliiiiiiip   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciryee/d_good_strategies_resources_to_improve_mlops/</guid>
      <pubDate>Thu, 02 May 2024 21:52:53 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 我应该去ICML发表论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</link>
      <description><![CDATA[一年前我完成了博士学位。离开学术界，去一家科技公司当数据科学家。我喜欢这份工作，但仍在考虑将来以某种方式转到更偏向研究的职位。不过还不确定。 无论如何，我的一个未完成的作品被一个朋友选中，他完成了作品并申请到了 ICML。它被接受了（耶！）。 我现在想知道 - 除了我觉得会议很有趣之外，参加会议还有什么实际好处吗？发表论文？我知道对于学者/研究人员来说，这是一个结识新朋友、了解当前研究的好机会。但既然我已经不在那里了，还有什么真正去的理由吗？ 这是一个很奇怪的问题，但我不确定，我很乐意听听你的想法。    提交人    /u/meni_s   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cirfu1/discussion_should_i_go_to_icml_and_present_my/</guid>
      <pubDate>Thu, 02 May 2024 21:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] Panza：个人电子邮件助理，经过培训并在设备上运行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciqvqw/p_panza_a_personal_email_assistant_trained_and/</link>
      <description><![CDATA[厌倦了精心制作精美的电子邮件，并希望有一个助手来接管繁重的工作，同时模仿您的写作风格？隆重推出 Panza，这是一款完全在您的设备上运行的个性化 LLM 电子邮件助手！在 Llama-3 或 Mistral 之间进行选择，根据您的独特风格进行定制，并让它为您编写电子邮件。看看我们的演示并在您的电子邮件中尝试一下：https://github.com/IST-DASLab/PanzaMail&lt; /a&gt; 有关 Panza 的一些技术细节：  Panza 是一款根据您的写作风格和过去的电子邮件历史记录定制的自动电子邮件助手。 Panza生成与您的写作风格相匹配的微调 LLM，并将其与检索增强生成 (RAG) 组件配对，帮助其生成相关电子邮件。 Panza **可以完全在本地进行训练和运行** 。目前，它需要具有 16-24 GiB 内存的单个 GPU，但我们还计划发布仅包含 CPU 的版本。 训练和执行也很快 - 对于大约 1000 封电子邮件的数据集，训练 Panza 需要不到一个小时，生成一封新电子邮件最多只需要几秒钟。    由   提交/u/eldar_ciki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciqvqw/p_panza_a_personal_email_assistant_trained_and/</guid>
      <pubDate>Thu, 02 May 2024 21:07:30 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]寻求帮助以找到更好的GPU设置。三台 H100 与五台 A100？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</link>
      <description><![CDATA[长话短说，一家公司有预算购买用于微调 LLM 的 GPU（可能是 70B），我必须研究哪种 GPU 设置最适合他们的预算。 预算可以购买 三个 H100 GPU 或 五个 A100 GPU。 我尽了最大努力，但直到现在我还不清楚哪种设置更好。虽然五个 A100 有更多的 VRAM，但他们说 H100 比 A100 快 2-8 倍！ 我正在寻求帮助。任何有价值的见解都将不胜感激。    提交人    /u/nlpbaz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cioyn8/discussion_seeking_help_to_find_the_better_gpu/</guid>
      <pubDate>Thu, 02 May 2024 19:49:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于 ICML、NeurIPS、CVPR 等顶级会议，我一直在思考的事情。有多少论文是真正具有开创性的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</link>
      <description><![CDATA[我自己也有一些位于金星顶端的论文，但每当我坐下来对自己残酷地诚实时。我觉得我的作品不错，但影响力不大，就像墙上又多了一块砖。我想知道我们多久能看到像“注意力就是你所需要的一切”这样有影响力的东西例如。   由   提交 /u/oddhvdfscuyg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/</guid>
      <pubDate>Thu, 02 May 2024 18:37:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人成功进入机器学习咨询领域吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cimlyg/d_has_anyone_successfully_gotten_into_ml/</link>
      <description><![CDATA[请分享您的旅程和经验教训。谢谢！   由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cimlyg/d_has_anyone_successfully_gotten_into_ml/</guid>
      <pubDate>Thu, 02 May 2024 18:14:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基准创建者应分阶段发布其基准数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cilnzv/d_benchmark_creators_should_release_their/</link>
      <description><![CDATA[关于基准污染有很多讨论，其中模型根据最终评估的数据进行训练。例如，最近的论文表明，与 GSM1K 相比，模型在公共 GSM8K 上的表现要好得多，这是最近创建的基准在难度和其他指标上扩展 AI 以匹配 GSM8K。 由于对基准污染的担忧，通常很难从表面上理解研究实验室关于模型性能的说法。很难知道一个模型是否获得了良好的基准性能，是因为它总体上是有能力的，还是因为它的预训练数据被污染并且在基准上过度拟合。 解决这个问题的一个解决方案是让基准创建者发布他们的数据集分阶段进行。例如，基准创建者可以在发布时发布其数据集的 50%，然后分两个阶段发布剩余的 50%，一年后发布 25%，两年后发布 25%。这将使模型评估者能够通过比较训练截止之前发布的数据子集与训练截止之后发布的数据子集的性能来检查基准污染。它还可以让我们更好地了解模型的实际执行情况。 最后一点 - 这种分阶段发布过程对于通过抓取网络创建的基准没有任何帮助，即使是稍后发布的数据子集可以在训练数据中找到。但它对于其他类型的基准测试应该很有用。   由   提交/u/kei147  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cilnzv/d_benchmark_creators_should_release_their/</guid>
      <pubDate>Thu, 02 May 2024 17:36:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] spRAG - 用于具有挑战性的现实任务的开源 RAG 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cikkw2/p_sprag_opensource_rag_implementation_for/</link>
      <description><![CDATA[大家好，我是 Superpowered AI (YC S22) 的 Zach。我们在 RAG 领域的工作已经一年多了，最近我们决定开源所有核心检索技术。 [spRAG](https://github.com/SuperpoweredAI/spRAG）是一个检索系统，旨在处理密集文本上的复杂现实查询，例如法律文档和财务报告。据我们所知，对于此类任务，它是所有 RAG 系统中最准确、最可靠的结果。例如，在 FinanceBench（这是一个特别具有挑战性的开放式金融问答基准）上，spRAG 正确回答了 83% 的问题，而普通 RAG 基准的正确率为 19%（使用 Chroma + OpenAI Ada）嵌入 + LangChain）。 您可以在项目的自述文件中找到有关其工作原理以及如何使用它的更多信息。我们也非常愿意接受贡献。我们特别需要围绕集成（即添加对更多向量数据库、嵌入模型等的支持）和评估方面的贡献。 很高兴回答任何问题！ [GitHub 存储库]( https://github.com/SuperpoweredAI/spRAG)   由   提交/u/zmccormick7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cikkw2/p_sprag_opensource_rag_implementation_for/</guid>
      <pubDate>Thu, 02 May 2024 16:50:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文已被 ICML 接受但未亲自参加？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cigigh/d_paper_accepted_to_icml_but_not_attending_in/</link>
      <description><![CDATA[论文刚刚被 ICML 接受。说实话，这真是一个惊喜。不幸的是，对于两位作者来说，我们要么没有美国的回程签证，要么很可能没有 7 月份参加会议的未过期护照。我想知道是否可以接受支付475美元的会议注册费，但不参加，但我们的论文仍然在会议记录中发表。我注意到会议注册确实包括对所有会议和教程的虚拟访问。但我不确定出版部分。   由   提交 /u/Normal-Comparison-60   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cigigh/d_paper_accepted_to_icml_but_not_attending_in/</guid>
      <pubDate>Thu, 02 May 2024 14:04:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大三学生（本科生或一二年级博士生）在ICML、ICLR、NeurIPS等主要机器学习会议上有这么多论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</link>
      <description><![CDATA[大家好，今天ICML成绩出来了，恭喜所有在这里接受论文的同学。我自己不是学者，但有时我会为了工作而阅读这些会议上的论文，这真的很有趣。我只是有一个问题：为什么这些会议上大三的论文这么多？我认为这是你在 5 年博士学位期间必须学习的东西，而且几乎只能在博士学位的最后几年才能实现。另外，我听说要进入美国顶尖的博士项目，你需要事先写一些论文。那么，如果一个大三学生能这么早发表论文，为什么还要花5年时间攻读博士学位呢？   由   提交 /u/ShiftStrange1701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</guid>
      <pubDate>Thu, 02 May 2024 11:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] Pytorch 的现代最佳编码实践（用于研究）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chxpka/d_modern_best_coding_practices_for_pytorch_for/</link>
      <description><![CDATA[大家好，我从 2019 年开始使用 Pytorch，在那段时间它发生了很大的变化（特别是自从 Huggingface 以来）。  您有推荐的现代指南/style-docs/example-repos 吗？例如，命名张量是一种好的/常见的做法吗？推荐使用 Pytorch Lightning 吗？目前最好的配置管理工具是什么？您多久使用一次 torch.script 或 torch.compile？   由   提交 /u/SirBlobfish   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chxpka/d_modern_best_coding_practices_for_pytorch_for/</guid>
      <pubDate>Wed, 01 May 2024 21:24:42 GMT</pubDate>
    </item>
    <item>
      <title>[P]我转载了Anthropic最近的可解释性研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chsg42/p_i_reproduced_anthropics_recent_interpretability/</link>
      <description><![CDATA[当能力研究发展得像目前一样快时，并没有多少人关注 LLM 可解释性研究，但可解释性确实很重要，在我看来意见，真是有趣又令人兴奋！近几个月来，Anthropic 取得了很多突破，其中最大的突破是“迈向单义性”。基本思想是，他们找到了一种训练稀疏自动编码器以基于变压器激活生成可解释特征的方法。这使我们能够在推理过程中查看语言模型的激活，并了解模型的哪些部分最负责预测每个下一个标记。对我来说真正突出的一点是，他们训练的自动编码器实际上非常小，并且不需要大量计算即可工作。这让我产生了尝试通过在我的 M3 Macbook 上训练模型来复制这项研究的想法。经过大量阅读和实验，我得到了相当不错的结果！我在我的博客上写了一篇更深入的文章：  https://jakeward.substack.com/p/monosemanticity-at-home-my-attempt 我现在也在使用这项技术开展一些后续项目作为可以在 Colab 笔记本中运行以使其更易于访问的最小实现。如果您阅读我的博客，我很乐意听到任何反馈！   由   提交 /u/neverboosh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chsg42/p_i_reproduced_anthropics_recent_interpretability/</guid>
      <pubDate>Wed, 01 May 2024 17:51:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] KAN：柯尔莫哥洛夫-阿诺德网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chrafb/r_kan_kolmogorovarnold_networks/</link>
      <description><![CDATA[      论文：https://arxiv. org/abs/2404.19756 代码：https://github.com /KindXiaoming/pykan 快速介绍：https:/ /kindxiaoming.github.io/pykan/intro.html 文档：https://kindxiaoming.github.io/pykan/ 摘要：  受到 Kolmogorov-Arnold 表示的启发定理中，我们提出Kolmogorov-Arnold Networks（KAN）作为多层感知器（MLP）的有希望的替代品。 MLP 在节点（“神经元”）上具有固定激活函数，而 KAN 在边缘上具有可学习激活函数(“权重”)。 KAN 根本没有线性权重——每个权重参数都被参数化为样条函数的单变量函数所取代。我们证明，这种看似简单的改变使得 KAN 在准确性和可解释性方面优于 MLP。就准确性而言，在数据拟合和 PDE 求解中，较小的 KAN 可以比较大的 MLP 获得相当或更好的准确性。从理论上和经验上来说，KAN 比 MLP 拥有更快的神经尺度法则。为了可解释性，KAN 可以直观地可视化，并且可以轻松地与人类用户交互。通过数学和物理领域的两个例子，KAN 被证明是帮助科学家（重新）发现数学和物理定律的有用合作者。总之，KAN 是 MLP 的有希望的替代品，为进一步改进当今严重依赖 MLP 的深度学习模型提供了机会。  https://preview.redd.it/r7vjmp31juxc1.png?width=2326&amp;format=png&amp;auto=webp&amp; amp;s= a2c722cf733510194659b9aaec24269a7f9e5d47   由   提交 /u/SeawaterFlows   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chrafb/r_kan_kolmogorovarnold_networks/</guid>
      <pubDate>Wed, 01 May 2024 17:03:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>