<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 04 Jan 2025 15:15:13 GMT</lastBuildDate>
    <item>
      <title>[R]Infinity ∞：用于高分辨率图像合成的缩放按位自回归模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1htehx6/rinfinity_scaling_bitwise_autoregressive_modeling/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1htehx6/rinfinity_scaling_bitwise_autoregressive_modeling/</guid>
      <pubDate>Sat, 04 Jan 2025 13:35:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2024 年值得关注的人工智能研究论文（第一部分）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1htedss/p_noteworthy_ai_research_papers_of_2024_part_one/</link>
      <description><![CDATA[        由    /u/seraschka 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1htedss/p_noteworthy_ai_research_papers_of_2024_part_one/</guid>
      <pubDate>Sat, 04 Jan 2025 13:28:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我为 TensorFlow 和 Keras 编写了优化器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1htch73/p_i_wrote_optimizers_for_tensorflow_and_keras/</link>
      <description><![CDATA[您好，我为 TensorFlow 和 Keras 编写了优化器，它们的使用方式与 Keras 优化器相同。 https://github.com/NoteDance/optimizers    提交人    /u/NoteDancing   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1htch73/p_i_wrote_optimizers_for_tensorflow_and_keras/</guid>
      <pubDate>Sat, 04 Jan 2025 11:25:21 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] Agentic AI：又一个被炒作的界面还是范式转变？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1htbe7x/discussion_agentic_ai_yet_another_hyped_interface/</link>
      <description><![CDATA[本篇文章旨在讨论 Agentic AI 的影响范围。 Agentic AI 正在作为一种新事物被提供，但从深层次来看，它看起来像一个通过框架与其他 API 交互的传统系统。 从不同的角度看： 开发人员 与传统开发没有太大偏差。因此学习曲线很小 客户 Agentic AI 可能会将焦点从 Web 界面转移到聊天机器人或可能是某种新型界面。如果发生这种情况，直观/交互式 UI 的作用可能会减少 业务 一些人的效率提高了，而另一些人的业务则蒙受了损失。服务型公司可能最初会引领发展。 Radius B2B 或 B2C，哪个会受到更大的影响。    提交人    /u/dkodev   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1htbe7x/discussion_agentic_ai_yet_another_hyped_interface/</guid>
      <pubDate>Sat, 04 Jan 2025 10:06:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果你不断要求 LLM 写出更好的代码，他们能写出更好的代码吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ht2m3y/d_can_llms_write_better_code_if_you_keep_asking/</link>
      <description><![CDATA[https://minimaxir.com/2025/01/write-better-code/ 这是一个理论实验，其结果有趣。简而言之，答案是肯定的，这取决于您对“更好”的定义。    提交人    /u/minimaxir   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ht2m3y/d_can_llms_write_better_code_if_you_keep_asking/</guid>
      <pubDate>Sat, 04 Jan 2025 01:12:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 每个神经元有 0.3 个脉冲的高性能深度脉冲神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ht19tf/r_highperformance_deep_spiking_neural_networks/</link>
      <description><![CDATA[摘要 通过罕见的二进制脉冲进行通信是生物大脑能量效率的关键因素。然而，训练受生物启发的脉冲神经网络比训练人工神经网络更难。这令人费解，因为理论结果提供了从人工到脉冲神经网络的精确映射算法，并采用首次脉冲时间编码。在本文中，我们从理论和模拟角度分析了首次脉冲时间网络的学习动态，并确定了消失或爆炸梯度问题的一个具体实例。虽然两种脉冲神经网络映射选择可以在初始化时解决这个问题，但只有在阈值处神经元膜电位斜率为恒定的映射才能保证脉冲神经网络和具有整流线性单元的人工神经网络之间的训练轨迹的等价性。对于由前馈密集层或卷积层组成的特定图像分类架构，我们证明深度脉冲神经网络模型可以在 MNIST 和 Fashion-MNIST 数据集上从头开始进行有效训练，或在 CIFAR10、CIFAR100 和 PLACES365 等大规模数据集上进行微调，以实现与人工神经网络完全相同的性能，超越之前的脉冲神经网络。我们的方法以每个神经元少于 0.3 个脉冲实现高性能分类，有助于实现节能。我们还表明，使用我们强大的梯度下降算法对脉冲神经网络进行微调，可以优化其硬件实现，具有低延迟和对噪声和量化的弹性。 https://www.nature.com/articles/s41467-024-51110-5    提交人    /u/jacobgorm   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ht19tf/r_highperformance_deep_spiking_neural_networks/</guid>
      <pubDate>Sat, 04 Jan 2025 00:10:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 定制多语言 NER</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ht09d8/d_custom_multilingual_ner/</link>
      <description><![CDATA[大家好，我实际上还是一名初级员工，但我有一个在行业中相当具有挑战性的项目，我想使用 NER 为电子商务和产品映射构建推荐器 挑战在于产品可以有很多不同的命名、语法、同义词，并且可以在同一个用户输入中包含阿拉伯语-英语 我正在收集历史用户输入的数据集，并将其标记为产品的映射正式名称但我希望它更具动态性和可重用性，因此我想要使用 NER，如何从一开始就正确构建它以应对这个挑战？ 我应该学什么，我可以使用什么工具，如何自动化标记或 NER，其中产品标签可以达到 10,000 - 12,000 个标签（具有不同的类别、品牌等..）    提交人    /u/Ill_Persimmon388   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ht09d8/d_custom_multilingual_ner/</guid>
      <pubDate>Fri, 03 Jan 2025 23:24:32 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 我训练了一个 AI 模型来生成 Pokemon</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hsxkkk/discussion_i_trained_an_ai_model_to_generate/</link>
      <description><![CDATA[      过去几个月，我一直在研究一个利用深度学习来生成 Pokemon 图像/名称并预测输入的项目。想在这里分享我的成果。  实施细节：https://github.com/smaley02/Pokemon-Generation/tree/main?tab=readme-ov-file 全部 900 只假口袋妖怪：https://smaley02.github.io/gallery.html https://preview.redd.it/fzefyqu0kuae1.png?width=748&amp;format=png&amp;auto=webp&amp;s=e5723c9d4696e083c7049f7e36605e9f0f51443f    提交人    /u/Ghetto-T   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hsxkkk/discussion_i_trained_an_ai_model_to_generate/</guid>
      <pubDate>Fri, 03 Jan 2025 21:28:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 想法和建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hsv7if/d_thoughts_and_suggestions/</link>
      <description><![CDATA[我有一个项目需要使用 AI 进行实时对象检测，目前我计划使用 raspberry pi 4b 8gb ram，但我注意到当我使用笔记本电脑时，我发现运行它非常重，所以也许 raspberry pi 可能由于没有 gpu 而没有足够的功率来运行它，所以您认为手持游戏机（steam deck、rog ally）是否足以训练和运行 AI，因为我需要一个体积小但功能足够强大的设备，我考虑过 jetson nano 和 mini pc，但它们都很贵。我只在寻找二手型号。谢谢    提交人    /u/FollowingOrganic7147   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hsv7if/d_thoughts_and_suggestions/</guid>
      <pubDate>Fri, 03 Jan 2025 19:47:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] / [R] 您对 LLM '理解'其领域并增强领域理解有何看法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hsplsc/d_r_what_are_your_thoughts_on_llms_understanding/</link>
      <description><![CDATA[大家好， 我一直在考虑研究尝试增强 LLM 对其应用领域的理解的效果，但我不确定这是否值得，是否有足够的效果。 不解释太多，也不让你们感到无聊：基本上，在我的上一个项目中，我通过向 LLama 抛出一个包含两个类的 200 个示例的数据集（总共 400 个示例）对其进行了微调，并获得了约 76% 的 F1。这还包括一些提示。 但我不禁想知道，如果 LLM 更正确地教授领域上下文，比如通过本体和知识图谱，会怎么样？自定义标记化是否可以提高其理解和生成更好响应的能力？ 我非常感谢您的任何意见，如果您想到了什么，我可以研究以增强模型对其领域的理解。如果您认为这不值得，我也很乐意听听您的看法，也许可以告诉您为什么会这样认为。    提交人    /u/neerualx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hsplsc/d_r_what_are_your_thoughts_on_llms_understanding/</guid>
      <pubDate>Fri, 03 Jan 2025 15:56:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] / [N] 近期论文推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hsp3mo/r_n_recent_paper_recommendations/</link>
      <description><![CDATA[大家好，新年伊始，我预计许多研究团队都会发布他们为那个有趣的“et al. 2024”所做的工作。我对与 transformers 和理论机器学习有关的论文非常感兴趣，但如果你有一篇好论文可以分享，我永远不会拒绝。 提前感谢大家，祝大家有美好的一天 :)    提交人    /u/Spiritual-Resort-606   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hsp3mo/r_n_recent_paper_recommendations/</guid>
      <pubDate>Fri, 03 Jan 2025 15:33:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] ReLU + 线性层 aa 圆锥包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hso6rf/d_relu_linear_layers_aa_conic_hulls/</link>
      <description><![CDATA[在具有 ReLU 激活的神经网络中，将矩阵 P 的线性层组合到 ReLU 上，将输入映射到 P 的列的圆锥包中。 有没有论文利用这一事实来获得有趣的见解？    提交人    /u/alexsht1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hso6rf/d_relu_linear_layers_aa_conic_hulls/</guid>
      <pubDate>Fri, 03 Jan 2025 14:53:40 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] LLM 如何改变你作为 ML 工程师的工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hs41pt/discussion_how_is_llm_changing_your_job_as_a_ml/</link>
      <description><![CDATA[我刚刚看了吴恩达关于人工智能代理的演讲。他谈到了传统的机器学习任务可能需要 6 个月的时间，但现在有了法学硕士，只需要一个周末就可以完成。 这是这次演讲的 2-4 分钟。https://youtu.be/KrRD7r7y7NY?si=XDCAm7NFTMO3ayn3  具体来说，我猜他是说你可以用法学硕士进行零样本学习，而不是收集大量标记数据，构建和部署模型。他使用了情绪分析任务的例子。 我想知道是否有人作为机器学习科学家在工作中经历了这种生产力的转变。  我的经验是，公司不想直接使用 chatGPT，而是尝试建立自己的内部 LLM，我猜是出于数据隐私和成本方面的考虑。  请分享您的经验。     提交人    /u/Ok_Guava_9111   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hs41pt/discussion_how_is_llm_changing_your_job_as_a_ml/</guid>
      <pubDate>Thu, 02 Jan 2025 20:49:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</guid>
      <pubDate>Sun, 29 Dec 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>