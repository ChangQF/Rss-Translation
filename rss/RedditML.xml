<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 21 Sep 2024 01:11:40 GMT</lastBuildDate>
    <item>
      <title>[D] 如何计算 LLM 模型在微调过程中的 VRAM 使用量？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flnxtg/d_how_to_calculate_vram_usage_of_a_llm_model/</link>
      <description><![CDATA[谁能告诉我如何计算 LLM 模型的 vram 使用情况以进行微调。我找到了 VRAM 计算器 (asmirnov.xyz) 和 模型内存实用程序 - hf-accelerate 的 Hugging Face Space，但我猜它没有提到微调，而是用于训练和推理。    提交人    /u/Himanshu40-c   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flnxtg/d_how_to_calculate_vram_usage_of_a_llm_model/</guid>
      <pubDate>Fri, 20 Sep 2024 22:07:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我创建了一个 AI 交易和金融研究应用程序（类似 TradeGPT）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flmi0d/p_i_created_an_ai_trading_and_financial_research/</link>
      <description><![CDATA[视频演示 NexusTrade 的实际操作 三年前，我开始了一个疯狂的项目，开发一个无代码算法交易平台。最初，我选择 TypeScript 作为我的首选语言。然而，我在速度和可配置性方面遇到了巨大的问题。 两年前，我决定开源我的交易平台。该平台称为 NextTrade，随着时间的推移，我在 GitHub 上积累了 1,000 多颗星。 我休息了一段时间，最终有信心重新开始建设。这一次，我用 Rust 实现了核心交易逻辑，并重构了架构以支持您能想到的任何交易策略。  大约在这个时候，ChatGPT 也发布了。我公司举办了一场以 AI 为主题的 Hackathon，并带领一支 6 人团队（横跨工程、数据科学和设计）赢得了 Leader&#39;s Choice 奖。我还了解了大型语言模型的强大功能。 我开始将 LLM 集成到我的交易平台中，首先是能够直接创建交易策略，而无需使用旧 NextTrade 使用的复杂形式。 然后我反复改进它。我添加了提示链，添加了不同的提示，包括保存使用 AI 创建的内容的功能，以及许多其他 AI 功能。 最终结果是一个 AI 交易和金融研究平台，NexusTrade。您可以：  使用 AI 创建算法交易策略 使用历史数据对这些策略进行回测 使用遗传算法优化策略 部署实时纸上交易策略 使用 AI 筛选器查找新股票。例如，“自去年以来，哪些 AI 股票的收入增加了 80% 以上？”按净收入降序排序&quot; 使用 AI 分析公司的基本面 创建关注列表并接收有关您喜欢的股票的每日电子邮件更新 更多！  我想分享我的整个旅程，因为老实说，这是一次疯狂的旅程。我学到了很多关于人工智能和金融的知识，并通过尝试生成有关我的应用程序的内容显着提高了我自己的投资水平。我希望你们能查看并给我诚实的反馈。 谢谢，干杯！    提交人    /u/NextgenAITrading   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flmi0d/p_i_created_an_ai_trading_and_financial_research/</guid>
      <pubDate>Fri, 20 Sep 2024 21:01:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] GRIN：基于梯度的 MoE</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flhndi/r_grin_gradientinformed_moe/</link>
      <description><![CDATA[路由输出离散变量，如何估计其梯度进行混合专家训练？ https://arxiv.org/pdf/2409.12136 相关背景：https://arxiv.org/abs/2304.08612    提交人    /u/Lucas_LLL   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flhndi/r_grin_gradientinformed_moe/</guid>
      <pubDate>Fri, 20 Sep 2024 17:31:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 深入机器学习：免费 Python 教程和可下载的 Markdown 文件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flfn3k/p_dive_into_machine_learning_free_python/</link>
      <description><![CDATA[我一直对机器学习算法的工作原理很着迷，所以我决定深入研究并创建一系列全面的 Python 教程。这些教程涵盖了机器学习的各个方面，从数据预处理和模型训练到评估和部署。 随着我的教程收藏越来越多，我意识到与社区分享它们可以帮助其他人走上机器学习之旅。因此，我创建了一个存储库，您可以在其中以 Markdown (MD) 格式下载所有这些教程，从而可以轻松地在 Jupyter 笔记本或您喜欢的任何其他平台上使用它们。 我的项目做什么： 我的项目提供了 Python 中机器学习教程的全面集合。每个教程都设计得易于理解，并配有分步指南和实际示例。这些教程涵盖了广泛的主题，包括数据预处理、模型训练、评估和部署。所有教程均以 Markdown (MD) 格式提供，可轻松在 Jupyter 笔记本或任何其他编码环境中使用。 如何访问： https://github.com/xbeat/Machine-Learning https://xbe.at    提交人    /u/kaolay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flfn3k/p_dive_into_machine_learning_free_python/</guid>
      <pubDate>Fri, 20 Sep 2024 16:05:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调 LLM，从我的电影剧本中学习知识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flf7sv/d_finetune_llm_to_learn_knowledge_from_my_movie/</link>
      <description><![CDATA[我想使用 lora 在自己的电影剧本数据集上微调 mistral nemo 模型。我想通过微调将剧本知识引入模型。电影剧本很长，所以不可能在一个例子中对完整的剧本进行训练。那么我该如何创建示例以便模型可以在不同的场景之间形成联系呢？  我应该只在 casual lm 还是 masked lm 任务上进行训练？ 我还应该对每个场景的摘要和一些问题答案（使用另一个 llm 创建的合成数据）进行训练吗？ 我应该使用 instruct 还是基础模型？ 我应该完全微调还是 lora 可以帮助我处理我的用例？  我已经尝试通过在每个示例中创建包含前一个场景、当前场景和下一个场景的示例进行训练，并使用 lora 在 casual lm 任务上训练 nemo instruct。结果并不好。    提交人    /u/Elemental_Ray   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flf7sv/d_finetune_llm_to_learn_knowledge_from_my_movie/</guid>
      <pubDate>Fri, 20 Sep 2024 15:47:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过强化学习训练语言模型进行自我纠正</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flby1u/r_training_language_models_to_selfcorrect_via/</link>
      <description><![CDATA[  由    /u/RobbinDeBank  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flby1u/r_training_language_models_to_selfcorrect_via/</guid>
      <pubDate>Fri, 20 Sep 2024 13:24:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 创造力仅来自强化学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flbmde/d_creativity_only_comes_from_reinforcement/</link>
      <description><![CDATA[Ilya 发表了一次有趣的演讲，谈到了 RL 在 LLM 或任何 AI 系统（例如国际象棋的 AlphaZero）形成创造性反应方面的作用。我想知道这是真的吗？我认为简单地在 SFT 之类的数据点之间进行插值也会很有创意。 讨论链接：https://www.youtube.com/watch?v=OPZxs6IXH00&amp;list=PLpvkFqYJXcreXgK6Cg9NVGvFANmdUczWa （第 14 分钟：00）    提交人    /u/CriticalTemperature1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flbmde/d_creativity_only_comes_from_reinforcement/</guid>
      <pubDate>Fri, 20 Sep 2024 13:09:35 GMT</pubDate>
    </item>
    <item>
      <title>叠加、相图与正则化 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flazmd/superposition_phase_diagrams_and_regularization_d/</link>
      <description><![CDATA[      大家好！我正在阅读 Anthropic 的叠加玩具模型，我强烈推荐。作者展示了小型神经网络的相图，包括理论和经验版本。然而，他们在分析中没有应用任何形式的正则化，这激起了我对叠加效应的好奇心。这激发了我尝试这个概念。 我发现这些想法非常有趣，所以我写了一篇博客文章来分享我的想法。你可以在这里查看。 虽然我的结果不如 Anthropic 得到的结果那么清晰，但我相信它们仍然值得分享。我很乐意听到您的反馈！ 以下是我帖子的要点： 我们从一个非常简单的神经网络开始： https://preview.redd.it/7okwz6njlypd1.png?width=237&amp;format=png&amp;auto=webp&amp;s=e0f39f6e7e903d9573cb432d20ff0479131e05dc 我们进行训练以尽量减少以下重建损失： https://preview.redd.it/ftk5l5nklypd1.png?width=410&amp;format=png&amp;auto=webp&amp;s=960ba69bb3b1de21d2f8b73d3a6588fb5cf3ac66 这里，λ 表示正则化强度，x_i 是输入特征，r_i 表示每个特征的相关性。每个特征都是 0 到 1 之间的数字。此外，我们引入了一个稀疏项 s。给定 s，我们将每个特征设置为 0，概率为 s。 假设我们只有两个特征，用一个数字编码（因此，(W = [w_1, w_2]))。网络的选择数量有限：  设置 w_1 = 0 和 w_2 = 0，最小化 L2 正则化。 设置 w_1 = 1 和 w_2 = 0，仅对第一个特征进行编码。 设置 w_1 = 0 和 w_2 = 1，仅对第二个特征进行编码。 设置 w_1 = 1 和 w_2 = -1（或 w_2 = -1 和 w_1 = 1），叠加两个特征。  接下来，我进行了几项实验，改变了稀疏性、正则化强度和第二个特征的相关性（例如，当 r_2 = 0 时，第二个特征可能不相关，而当 r_2 = 5 时，第二个特征的相关度可能是第一个特征的五倍）。此 GIF 显示了实验结果：  https://i.redd.it/do8erlkmlypd1.gif 我还通过计算四种情景中的每种情景的预期损失创建了相图的理论版本，我还将两个 gif 并排放在一起进行比较：  https://i.redd.it/d81150snlypd1.gif 如您所见，理论版本与经验版本有些匹配。虽然它并不完美，但正则化的效果是显而易见的；它阻止了特征的叠加。当您考虑到 (W = [-1, 1]) 的范数肯定大于 (W = [0, 1]) 或 (W = [1, 0]) 时，这是有道理的。 您觉得如何？您对改进这些数字有什么建议吗？我很想听听您的想法！    提交人    /u/f14-bertolotti   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flazmd/superposition_phase_diagrams_and_regularization_d/</guid>
      <pubDate>Fri, 20 Sep 2024 12:38:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 少数民族语言TTS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl6rrs/r_tts_for_minority_languages/</link>
      <description><![CDATA[我的客户是巴布亚新几内亚少数民族语言的翻译。这种语言的名称是 Narak，是一种声调语言。有哪些资源可用于为这种语言（或任何其他少数民族语言）创建文本到语音的工具？我的客户年纪很大了，如果能让软件读取字典条目，完成字典将变得容易得多。 是的，有一个专门从事文本到语音的小组。但是，这项任务可能需要某种机器学习。    提交人    /u/SnooGoats1303   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl6rrs/r_tts_for_minority_languages/</guid>
      <pubDate>Fri, 20 Sep 2024 07:57:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我觉得自从 LLM API 成为现实以来，有关 ML 和 ML 产品的讨论质量急剧下降。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl5be0/d_i_feel_like_ever_since_llm_apis_have_become_a/</link>
      <description><![CDATA[完成硕士学位后，过去几年一直担任 MLE，目前在一家拥有非常聪明的同事的公司工作。问题是，我的公司没有资源来培训我们自己的 LLM，因此不得不求助于使用各种 API 来建立模型。 关于如何改进我们产品的讨论通常感觉没有成效且毫无意义。它通常会诉诸于“我们如何通过快速工程让这个 LLM（我们甚至无法控制）做这件事？” 我个人甚至不认为“快速工程”是可靠或真实的事情，并且感觉因为大多数讨论都归结于此，感觉我们也无法真正增强我们的产品。 只是想知道是否有人有同样的感受。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl5be0/d_i_feel_like_ever_since_llm_apis_have_become_a/</guid>
      <pubDate>Fri, 20 Sep 2024 06:06:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我们读过的一些研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl4bi0/r_some_research_papers_we_read/</link>
      <description><![CDATA[印度理工学院鲁尔基分校的视觉语言小组整理了 2016 年至 2024 年期间来自 NeurIPS、CVPR、ICCV、ICML 等顶级会议的深度学习研究论文综合摘要库。这些摘要旨在让您简明扼要地了解计算机视觉、自然语言处理和机器学习等领域的有影响力的论文。该库不断扩充，并经常添加新的摘要。以下是一些值得注意的例子：  **DreamBooth：针对主题驱动生成的精细调整文本到图像扩散模型**，CVPR&#39;23  [DreamBooth 摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/DreamBooth.md) **Segment Anything**，ICCV&#39;23  [Segment Anything 摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Segment\_Anything.md) **一图胜千言：使用文本反转个性化文本到图像生成**，ICCV&#39;23  [文本反转摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Textual\_inversion.md) **照片级真实感具有深度语言理解的文本到图像扩散模型**，NIPS&#39;22  [照片级真实感扩散摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/imagen.md) **一张图片胜过 16x16 个单词：用于大规模图像识别的 Transformers**，ICLR&#39;21  [视觉 Transformer 摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Vision\_Transformer.md) **Big Bird：用于更长序列的 Transformers**，NIPS&#39;20  [Big Bird Transformers 概要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Big\_Bird\_Transformers.md)  存储库邀请社区做出贡献。如果您发现这些摘要有用，我们鼓励您提交自己的研究论文摘要。该团队旨在定期更新该集合，其中包含即将召开的会议的论文摘要以及深度学习和人工智能的关键主题。 您可以在此处访问完整的存储库并做出贡献： [Vision Language Group 论文摘要](https://github.com/vlgiitr/papers\_we\_read) 通过贡献，您将帮助使该领域的初学者和专家更容易获得高级研究。    提交人    /u/vlg_iitr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl4bi0/r_some_research_papers_we_read/</guid>
      <pubDate>Fri, 20 Sep 2024 04:59:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] EMNLP 2024 成绩/通知</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkqxhh/d_emnlp_2024_results_notifications/</link>
      <description><![CDATA[一些曲目的结果似乎已经出来了，可以在 Openreview 上查看。电子邮件可能会在明天发送。 提前祝贺大家，迈阿密见！    提交人    /u/EDEN1998   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkqxhh/d_emnlp_2024_results_notifications/</guid>
      <pubDate>Thu, 19 Sep 2024 17:45:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] Comgra：用于分析和调试神经网络的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</link>
      <description><![CDATA[我是一名机器学习工程师和研究员。我厌倦了理解神经网络行为方式的难度，因此我编写了一个库来帮助我。 Comgra（计算图分析） 是一个可以与 pytorch 一起使用的库，用于提取您关心的所有张量数据并在浏览器中以图形方式对其进行可视化。有关它的论文已被接受为 ICML 2024 机械可解释性研讨会的焦点论文。 与通常使用 tensorboard 的方法相比，Comgra 可以对正在发生的事情进行更详细的分析。您可以在训练过程中研究张量，深入研究单个神经元，检查您特别感兴趣的单个数据集，跟踪梯度，比较不同训练运行之间的统计数据等等。 这个工具让我比平时更快地检查我的假设，并帮助我了解网络的不同部分是如何真正相互作用的，从而为我节省了大量的研究时间。    提交人    /u/Smart-Emu5581   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</guid>
      <pubDate>Thu, 19 Sep 2024 14:07:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>