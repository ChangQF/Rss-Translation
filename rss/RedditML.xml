<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 22 Sep 2024 15:15:30 GMT</lastBuildDate>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 22 Sep 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 二进制向量和Jaccard度量的快速精确搜索算法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmrmbq/d_fast_exact_search_algorithm_for_binary_vectors/</link>
      <description><![CDATA[我有一个以下问题：使用 Jaccard 相似性在一组长二进制向量中找到向量的精确最近邻（不是 ANN）。 对于近似解，我可以使用标准 MinHash LSH Forest（例如在 datasketch 库中），但我需要一个精确的。Scikit-learn 的最近邻太慢了，即使在 6 个核心上也是如此，因为它只能进行蛮力运算。K-D 树和球树不能使用，因为它们依赖于欧几里得距离，具体意味着对于给定维度有一个很好的截止值，这显然不适用于二进制数据和 Jaccard 度量。我不能使用 Faiss，因为它只支持精确二进制向量的汉明距离。 我可以使用什么算法或库？    提交人    /u/qalis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmrmbq/d_fast_exact_search_algorithm_for_binary_vectors/</guid>
      <pubDate>Sun, 22 Sep 2024 12:01:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 计划构建 7x RTX4090 设备。有什么建议吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmrfgw/d_planning_on_building_7x_rtx4090_rig_any_tips/</link>
      <description><![CDATA[我计划构建一个 7x RTX4090 装备，配备 Ryzen Threadripper 7960X 和 256GB 内存以及 2x 2000 瓦电源。我不太确定主板，但 Pro WS WRX90E-SAGE SE 或类似产品似乎适合 7x PCIE 16x 插槽。我需要降低（功率限制）我的 GPU 以避免过度劳累我的 PSU，我还将使用转接电缆将我的 GPU 安装在主板上。 有人有类似设置的经验吗？ 7960X 的 24 个核心对于 7 个 GPU 来说是否太少了？ 使用此设置运行模型并行 pytorch（例如 LLM 微调）时是否可能出现带宽问题？ 提前感谢任何提示或建议！    提交人    /u/Chance-Tell-9847   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmrfgw/d_planning_on_building_7x_rtx4090_rig_any_tips/</guid>
      <pubDate>Sun, 22 Sep 2024 11:50:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] PointNet 用于点云分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmrewx/d_pointnet_for_point_cloud_classification/</link>
      <description><![CDATA[我对 PointNet 模型使用的架构有疑问。 如果您查看它的内部，您会发现第一个块之一是 T-Net，它基于点的组合估计最佳转换矩阵，以将云与规范空间对齐。这很好，它使用了所有点的组合信息。 接下来，它需要开始从每个点提取特征，因此它将每个点应用于 MLP，该 MLP 将点重新映射到维度为 64 的新空间。 好吧，在这里我开始失去踪迹，而 T-Net 使用所有点的组合，MLP 层一次将一个点作为输入，因此它必须仅从该点的位置提取特征和含义。 我认为，要赋予一个点意义，就应该看看它周围的点。 起初我以为 T-Net 也在一个空间中执行映射，其中每个点都有携带一些聚合信息的坐标，但每个人都说这只是与规范空间对齐。 那么云的组合信息在哪里用于提取特征？    提交人    /u/AcquaFisc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmrewx/d_pointnet_for_point_cloud_classification/</guid>
      <pubDate>Sun, 22 Sep 2024 11:49:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解 1.58 位大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmnkar/d_understanding_158bit_large_language_models/</link>
      <description><![CDATA[大家好，我写了一篇关于三元 (trinary) 模型的文章，总结了我读到的关于这个主题的内容。它更像是一篇高水平的文献综述。目标受众是对研究感到好奇但没有时间深入研究论文本身的开发人员。这是一篇 Medium 上的免费文章。 感谢任何反馈和意见。    提交人    /u/ahronorha   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmnkar/d_understanding_158bit_large_language_models/</guid>
      <pubDate>Sun, 22 Sep 2024 07:19:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医疗 AI：顶级研究论文/模型🏅（2024 年 9 月 14 日至 9 月 21 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmkhok/d_last_week_in_medical_ai_top_research/</link>
      <description><![CDATA[      上周医疗 AI：顶级研究论文/模型🏅（2024 年 9 月 14 日至 9 月 21 日） 本周医疗 AI 论文  如何使用人工智能构建虚拟细胞：优先事项和机遇  本文提出了“人工智能驱动的虚拟细胞”的愿景，旨在创建稳健、数据驱动的细胞和细胞系统表示。它讨论了人工智能在各个尺度上生成通用生物学表征以及使用“虚拟仪器”促进可解释的计算机模拟实验的潜力。   医学法学硕士及其他模型  GP-GPT：用于基因-表型映射的法学硕士  本文介绍了 GP-GPT，这是第一个用于遗传-表型知识表示和基因组关系分析的专门大型语言模型。使用来自基因组学、蛋白质组学和医学遗传学数据集和出版物的超过 300 万个术语进行训练。  HuatuoGPT-II，医学法学硕士的 1 阶段训练 本文介绍了 HuatuoGPT-II，一种用于传统中医的新型大型语言模型 (LLM)，使用统一的输入输出对格式进行训练，以解决领域自适应中的数据异构性挑战。  HuatuoGPT-Vision：多模态医学法学硕士  本文介绍了 PubMedVision，这是一个 130 万个样本医学 VQA 数据集，通过使用 MLLM (GPT-4V) 对 PubMed 图像-文本对进行细化和去噪而创建。  Apollo：轻量级多语言医学法学硕士  本文介绍了多语言医学数据集 ApolloCorpora，以及XMedBench，评估六种主要语言的医学法学硕士的基准。作者开发并发布了 Apollo 模型（0.5B-7B 个参数）  GMISeg：通用医学图像分割  框架和方法  CoD：医疗代理的诊断链 如何使用 AI 构建虚拟细胞 使用 SAM 进行可解释的视觉概念发现 协调人类知识以获得可解释的医学图像 ReXErr：放射学报告中的合成错误 用于医学基础模型的 Veridical 数据科学 针对医学的微调 LLM：DPO 的作用  临床试验  用于生成临床试验表格和图表的 LLM 用于临床报告更正的 LLM AlpaPICO：用于临床试验 PICO 框架的 LLM  医学 LLM 应用  微软在医疗领域大规模部署机器人的经验  .... 详细查看完整帖子：https://x.com/OpenlifesciAI/status/1837688406014300514 感谢您的阅读！如果您知道任何遗漏的有趣论文，请随时在评论中分享。如果您在医疗 AI 方面有见解或突破，并希望在下周的版本中分享，请通过 Twt/x 与我们联系：OpenlifesciAI    提交人    /u/aadityaura   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmkhok/d_last_week_in_medical_ai_top_research/</guid>
      <pubDate>Sun, 22 Sep 2024 03:51:43 GMT</pubDate>
    </item>
    <item>
      <title>[D]除了美国和中国之外，人工智能模型发展排名前三的国家是哪些？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fme9af/dwhat_are_the_top_3_countries_in_development_of/</link>
      <description><![CDATA[毫无疑问，美国和中国在大型语言模型的发展中处于领先地位。其他国家表现如何？    提交人    /u/Realistic-Ad-6231   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fme9af/dwhat_are_the_top_3_countries_in_development_of/</guid>
      <pubDate>Sat, 21 Sep 2024 22:09:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 文本到视频的传播：调查视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmcwqj/d_text_to_video_diffusion_a_survey_video/</link>
      <description><![CDATA[      分享我制作的一段 YT 视频，介绍用于训练文本到视频传播模型的最新架构和算法……介绍了过去几年的开创性论文/方法，如 VDM、Make A Video、Imagen、Video LDM、CogVideo、DiffusionTransformers、SORA 等。希望你们喜欢！在视频上点赞对频道有帮助，所以我会加倍感激。    提交人    /u/AvvYaa   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmcwqj/d_text_to_video_diffusion_a_survey_video/</guid>
      <pubDate>Sat, 21 Sep 2024 21:04:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] RL 中 LTL 的当前状态如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fma5v3/d_what_is_the_current_state_of_ltl_in_rl/</link>
      <description><![CDATA[  由    /u/jthat92  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fma5v3/d_what_is_the_current_state_of_ltl_in_rl/</guid>
      <pubDate>Sat, 21 Sep 2024 18:57:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 稳健的文本分类：分析基于原型的网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fm05l8/r_robust_text_classification_analyzing/</link>
      <description><![CDATA[  由    /u/Megixist  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fm05l8/r_robust_text_classification_analyzing/</guid>
      <pubDate>Sat, 21 Sep 2024 10:40:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] PerpetualBooster：改进了多线程和分位数回归支持</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flznxo/p_perpetualbooster_improved_multithreading_and/</link>
      <description><![CDATA[PerpetualBooster v0.4.7：多线程和分位数回归 很高兴宣布发布 PerpetualBooster v0.4.7！ 此更新通过多线程支持带来了显着的性能改进，并增加了分位数回归任务的功能。PerpetualBooster 是一种无需超参数调整的 GBM 算法，可简化模型构建。与 AutoML 类似，使用单个“预算”控制模型复杂性参数，以提高对看不见的数据的性能。 易于使用：python from perpetual import PerpetualBooster model = PerpetualBooster(objective=&quot;SquaredLoss&quot;) model.fit(X, y, budget=1.0)  安装：pip install perpetual Github repo：https://github.com/perpetual-ml/perpetual    提交人    /u/mutlu_simsek   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flznxo/p_perpetualbooster_improved_multithreading_and/</guid>
      <pubDate>Sat, 21 Sep 2024 10:05:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 热点课题的研究人员如何跟上？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flz1vo/d_how_do_researchers_in_hot_topics_keep_up/</link>
      <description><![CDATA[昨天晚上，我在阅读 Deepmind 的“通过强化学习训练语言模型进行自我纠正”(https://arxiv.org/abs/2409.12917)，该论文于 2 天前发布。这篇论文是关于使用 RL 预训练 LLM，但这与我的问题无关。 这篇论文很有趣，但我在阅读时想知道：他们怎么有时间做那里提到的所有事情？我的意思是：  根据所使用的预训练模型，他们很可能在 2-3 个月前才开始研究它 大多数参考文献和引文来自 2024 年下半年（从 5 月到 6 月开始），因此不到 3 个月  因此，在这几个月中，他们必须：阅读并彻底研究所有引用的论文（在这种情况下大约有 45 篇，并且再次强调：其中大多数都是非常新的），提出新的想法，开发它，进行实验（如今 SFT 也不是 15 分钟的事），汇编结果，并撰写实际论文。并且这假设他们没有同时研究其他论文/工作…… 作为一名单独的研究人员，我甚至无法想象在这段时间内做类似的事情，但即使在一个小团队中，我也发现这几乎是不可能的。我的一天只有 24 小时，但感觉研究界的其他人可以暂停时间以完成更多工作。 我是效率低下还是愚蠢？要完全理解一篇新颖的论文，我可能需要一两天的时间（每天 6 小时）来重现、推导所有（或大部分）数学运算并更深入地了解它为什么有效/无效。 非常感谢任何见解，谢谢！    提交人    /u/bgighjigftuik   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flz1vo/d_how_do_researchers_in_hot_topics_keep_up/</guid>
      <pubDate>Sat, 21 Sep 2024 09:19:17 GMT</pubDate>
    </item>
    <item>
      <title>纯 Torch 中的潜在扩散（无 huggingface 依赖）[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flxs7d/latent_diffusion_in_puretorch_no_huggingface/</link>
      <description><![CDATA[去年我一直在研究扩散，我决定发布一个软件包，其中包含我从头开始实现的 DDPM 潜在扩散模型。它包括用于嵌入图像的去噪 UNet 和 VAE+GAN 的实现。 这是纯粹的火炬，因为我发现 Huggingface 扩散器适合简单的任务，但如果你想了解内部工作原理或稍微破解模型，它就不够了，因为代码库非常庞大，并且不适用于组件的可重用性（但我坚持认为它是一个很好的库）。要安装它，只需运行 pip install tiny-diff 我的目标是创建一个可重复使用的实现，前向方法中没有任何 if（尽可能地压缩多态性，以使前向尽可能清晰）和模块化组件（因此，如果您不想使用整个模型，而是使用其中的一部分，您可以抓住您想要的） Repo 链接：https://github.com/AlejandroBaron/tiny-diff    提交人    /u/AIlexB   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flxs7d/latent_diffusion_in_puretorch_no_huggingface/</guid>
      <pubDate>Sat, 21 Sep 2024 07:44:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我觉得自从 LLM API 成为现实以来，有关 ML 和 ML 产品的讨论质量急剧下降。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl5be0/d_i_feel_like_ever_since_llm_apis_have_become_a/</link>
      <description><![CDATA[完成硕士学位后，过去几年一直担任 MLE，目前在一家拥有非常聪明的同事的公司工作。问题是，我的公司没有资源来培训我们自己的 LLM，因此不得不求助于使用各种 API 来建立模型。 关于如何改进我们产品的讨论通常感觉没有成效且毫无意义。它通常会诉诸于“我们如何通过快速工程让这个 LLM（我们甚至无法控制）做这件事？” 我个人甚至不认为“快速工程”是可靠或真实的事情，并且感觉因为大多数讨论都归结于此，感觉我们也无法真正增强我们的产品。 只是想知道是否有人有同样的感受。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl5be0/d_i_feel_like_ever_since_llm_apis_have_become_a/</guid>
      <pubDate>Fri, 20 Sep 2024 06:06:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>