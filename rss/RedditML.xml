<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 18 Jun 2024 15:15:15 GMT</lastBuildDate>
    <item>
      <title>[D] 你能将自我完善的 LLM 系统推向多远？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1diszz1/d_how_far_can_you_push_selfimproving_llm_systems/</link>
      <description><![CDATA[      我看到最近大量的研究论文和技术，它们展示了如何将 LLM 与其他工具结合起来创建一个可以自我改进的自我强化系统循环。 例如，DrEureka 使用 LLM 为机器人操作任务创建多个奖励模型的草稿。然后将结果反馈给模型，并告诉模型对结果进行推理并思考如何改进自身。该模型不仅创建和调整奖励函数，而且还进行配置以促进 sim2real 传输。根据论文，这种技术已被证明可以创建比人类更好的奖励模型。 https://preview.redd.it/w14kfgbuic7d1.png?width=1300&amp;format=png&amp;auto=webp&amp;s=415dcdf48e868aa7157e7b7b7fd34c507e9c7125 另一个更新的例子是 Sakana AI 的 LLM^2。在这项技术中，LLM 用于建议损失函数。然后测试这些函数，并将结果发送回模型进行审查和改进。Sakana 的研究人员使用这项技术创建了 DiscoPOP，据他们称，它“在多个保留评估任务中实现了最先进的性能，优于直接偏好优化 (DPO) 和其他现有方法。” https://preview.redd.it/8sujx731jc7d1.png?width=2988&amp;format=png&amp;auto=webp&amp;s=5bfb0c32baa990d59333a6f90f714d3f1100a148 这里的重复模式是：  使用 LLM 生成多个假设（LLM 的好处是它们可以生成许多假设，甚至一些可能违反直觉但在实践中有效的假设）。 使用验证机制（Python 执行器、数学解算器等） 让模型推理结果并提出改进建议 重复  虽然这种模式有几个有趣的例子运行良好（包括上面提到的两个），但我想知道这个社区中是否有人知道这些方法的局限性是什么？这样的系统在哪里会遇到瓶颈？您可以将这种模式推广到多远，以及在哪些领域这种模式不起作用？    提交人    /u/bendee983   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1diszz1/d_how_far_can_you_push_selfimproving_llm_systems/</guid>
      <pubDate>Tue, 18 Jun 2024 15:09:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] f1/fbeta 与平均精度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1diqqps/d_f1fbeta_vs_average_precision/</link>
      <description><![CDATA[f1/fbeta 和平均精度都考虑了召回率和精度。这些是将召回率和精度结合为单一指标以优化模型性能的绝佳选择。 在哪些情况下，人们会更喜欢其中一种？为什么？我认为平均精度更容易向非技术利益相关者解释。 渴望听到您的想法！    提交人    /u/ActiveBummer   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1diqqps/d_f1fbeta_vs_average_precision/</guid>
      <pubDate>Tue, 18 Jun 2024 13:30:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 优化指标和满意度指标</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1diqlq6/d_optimising_metric_and_satisficing_metric/</link>
      <description><![CDATA[为满意指标设置验收标准是有意义的。毕竟，模型必须满足部署的验收标准。例如，假设业务要求精度至少为 80%。精度是令人满意的指标。精度低于 80% 的模型将不会被部署。 优化指标意味着模型必须尽可能好地达到这个指标。例如，平均精度。（调整分类阈值以提高精度会牺牲召回率，反之亦然。我们希望在所有可能的阈值上减少这种权衡，因此寻找最大化 PRAUC 即平均精度的指标。）对于优化指标，设置阈值是否有意义？当它不影响模型接受或拒绝时，这个阈值有什么用处？ 渴望听到您的想法！   由    /u/ActiveBummer  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1diqlq6/d_optimising_metric_and_satisficing_metric/</guid>
      <pubDate>Tue, 18 Jun 2024 13:24:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在不同校准的测量设备下进行迁移学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dip3e9/d_transfer_learning_given_differently_calibrated/</link>
      <description><![CDATA[我们遇到了以下问题，假设我们正在查看某个工厂 A 中生产样本 S 的一些机器测量值 X 和样本 Y 的一些昂贵质量测试。我们希望根据 X 预测其他样本的结果 Y，而这些样本我们无法承担 Y 的测量成本。X 和 Y 一起形成了一个完美的表格数据集，非常适合大多数经典机器学习任务，但有一些注意事项。首先，数据集相当小（约 500 到 5000 个样本），因为测量 Y 的成本很高，并且测量值 X 可能会随着时间的推移而恶化或改变，甚至会由于机器校准而出现突然转变。因此，概念漂移是常态，而不是例外。 现在我们还有来自工厂 B 的数据，他们使用不同的设备测量 X，但也进行昂贵的测试 Y。至少我们可以依赖结果 Y，因为这个测试在各个工厂之间是标准化的。因此，如果我们在工厂 A 中测量样本 S 的 Y，那么在工厂 B 中测量的结果将相同。但是，测量 X 的设备不是标准化的，无法进行手动校准。因此，在工厂 A 和 B 之间，平均值可能会发生变化，或者总体尺度可能会有轻微变化。 通过汇集工厂 A 和 B 的数据，有什么好的策略可以补偿小训练集？有哪些方法可以抵消工厂 A 和 B 之间 X 的平均值或尺度变化？请注意，我们不能发送校准样本 S 并在两个工厂中测量 X，以了解测量 X 的变化和差异。 有人知道这种迁移学习的一些好论文或方法吗？非常感谢！    提交人    /u/SmokinCaterpill4r   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dip3e9/d_transfer_learning_given_differently_calibrated/</guid>
      <pubDate>Tue, 18 Jun 2024 12:09:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 本科研究建议：强化学习或计算机视觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dioy3e/d_undergraduate_research_advice_reinforcement/</link>
      <description><![CDATA[我是一名数据科学本科生，梦想在研究领域有所成就。我对强化学习 (RL)、计算机视觉 (CV) 和优化很感兴趣。然而，我不确定哪个更适合量化工作/医疗保健。我的大学专门研究 CV 和进化算法的深度学习，但不研究医疗保健应用。我应该专注于 RL 还是 CV 作为医疗保健研究方向，或者进化算法途径是否有前途？任何建议都将不胜感激。    提交人    /u/petrichorinforest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dioy3e/d_undergraduate_research_advice_reinforcement/</guid>
      <pubDate>Tue, 18 Jun 2024 12:01:25 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] 雅典 NLP 暑期学校，2024 年 9 月 19 日至 25 日</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dineuj/news_athens_nlp_summer_school_september_1925_2024/</link>
      <description><![CDATA[      https://preview.redd.it/nfjcry734b7d1.jpg?width=1033&amp;format=pjpg&amp;auto=webp&amp;s=2118d94d8e415554e5de6e13055335e1ad711e50 链接： https://athnlp.github.io/2024/ 我们很高兴邀请所有对自然语言处理 (NLP) 和机器学习 (ML) 进入第二届雅典自然语言处理暑期学校 (AthNLP 2024)。该活动将在雅典 NCSR“Demokritos”校园举行，由 NCSR“Demokritos”、雅典经济与商业大学、RC“Athena”和赫瑞瓦特大学组织。 在 2019 年第一届 AthNLP 成功举办的基础上，AthNLP 2024 将涵盖一系列 NLP 主题，重点关注 ML 方法。预计上午有理论讲座，下午有实施和实验实验课，晚上有研究主题讲座，同时还有来自参与者和行业研究实验室的演示和海报。 主题包括分类、序列预测、线性模型、神经网络、编码器-解码器架构、机器翻译、大型语言模型和多模态。 目标受众 初步时间表： 点击此处  NLP 和计算语言学的研究人员和研究生 对 NLP 和 ML 感兴趣的计算机科学家 寻求更深入了解这些主题的行业从业者  不需要具备 NLP 和 ML 的先验知识，但需要具备基本的数学和 Python 编程技能。 重要日期  申请截止日期：2024 年 6 月 20 日 （可能会延长） 决定：2024 年 6 月 30 日 注册：2024 年 7 月 30 日 暑期学校：2024 年 9 月 19 日至 25 日  特色  费用中包含社交活动、每日午餐和咖啡休息时间 ML 和 NLP 领域顶尖研究人员的讲座 学生可选择参加海报会议，展示自己的作品 与技术公司和研究机构一起举办演示日  已确认的演讲者  Antonis Anastasopoulos，乔治梅森大学 Raquel Fernández，阿姆斯特丹大学 Ferenc Huszár，剑桥大学 Martin Krallinger，巴塞罗那超级计算中心 Mirella Lapata，爱丁堡大学 Ryan McDonald，ASAPP Aida Nematzadeh，Google DeepMind Vlad Niculae，阿姆斯特丹大学 Barbara Plank，慕尼黑路德维希马克西米利安大学 Anna Rogers，哥本哈根 IT 大学  参与费用  300 欧元（学生）（可申请奖学金） 400 欧元（大学教授或公共机构研究人员） 500 欧元（其他所有人）  如有任何疑问，请通过以下方式与我们联系：[athnlp2024@athenarc.gr]() 我们期待在那里见到您！    提交人    /u/yannisassael   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dineuj/news_athens_nlp_summer_school_september_1925_2024/</guid>
      <pubDate>Tue, 18 Jun 2024 10:30:24 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 如何为多模式RAG创建有效的多模式检索系统？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dilpbd/project_how_to_create_effective_multimodal/</link>
      <description><![CDATA[假设您需要根据用户查询检索图像和文本，我认为您可以采用 2 种方法。哪种方法更好？有没有更好的方法？ 方法 1：将所有内容转换为嵌入，并基于嵌入进行搜索。 方法 2：从图像中获取文本描述，将该文本转换为嵌入并搜索基于文本的嵌入。 如果采用方法 2，则可以选择组合基于关键字的搜索，这是一个额外的好处。    提交人    /u/badtemperedpeanut   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dilpbd/project_how_to_create_effective_multimodal/</guid>
      <pubDate>Tue, 18 Jun 2024 08:31:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进化策略与反向传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dila4s/d_evolutionary_strategy_vs_backpropagation/</link>
      <description><![CDATA[我正在研究用于训练 NN 的进化策略，并得到了非常有趣的结果。这是你可以使用的笔记本：Colab 笔记本链接    epoch 数量 最终准确度 每 epoch 秒数    反向传播 10 97% 9   进化策略 10 90% 9   我不知道它能走多远，但是对于完全不使用梯度信息并在与反向传播相同的时间内在 GPU 上完成训练的东西获得 90% 的准确率是非常有趣的。 使用的 ES 算法非常简单：  用零初始化所有权重 创建大小为 N 的新一代种群 - 从正态分布中绘制每个权重，其中平均值是当前权重，标准差是学习率。 并行计算种群中每个个体的损失 - 在 GPU 上运行良好 挑选表现最好的前 k 个个体进行交配。 要获得新一代的下一个权重张量，请对表现最好的前 k 个个体取平均值。 转到步骤 2。  您是否知道任何探索训练神经网络的进化策略的有趣研究？    提交人    /u/kiockete   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dila4s/d_evolutionary_strategy_vs_backpropagation/</guid>
      <pubDate>Tue, 18 Jun 2024 08:00:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对开源 RAG 框架的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dik1k7/d_recommendation_for_open_source_rag_frameworks/</link>
      <description><![CDATA[我正在构建一个具有基本 RAG 功能的个人项目，并且我开始研究使用一些开源框架来改进检索管道。人们正在使用的优秀开源框架有哪些？R2R、RagFlow、Canopy，......？ 有人使用过其中任何一个吗？您的使用体验如何？    提交人    /u/AccomplishedBar5572   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dik1k7/d_recommendation_for_open_source_rag_frameworks/</guid>
      <pubDate>Tue, 18 Jun 2024 06:32:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 视频传播模型的新调查和评论论文！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dihzuu/r_new_survey_and_review_paper_for_video_diffusion/</link>
      <description><![CDATA[      标题：视频扩散模型：综述 作者： Andrew Melnik、Michal Ljubljanac、Cong Lu、Qi Yan、Weiming Ren、Helge Ritter。 论文： https://arxiv.org/abs/2405.03150 摘要：扩散生成模型最近已成为一种用于制作和修改连贯、高质量视频的强大技术。本综述系统地概述了用于视频生成的扩散模型的关键要素，涵盖了应用、架构选择和时间动态建模。总结了该领域的最新进展并将其归类为发展趋势。调查最后概述了剩余的挑战并对该领域的未来进行了展望。 https://preview.redd.it/1845dt7zca7d1.png?width=2496&amp;format=png&amp;auto=webp&amp;s=17f52b44e9c3f1f06fe66e784512adae3d1c20de    提交人    /u/MolassesWeak2646   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dihzuu/r_new_survey_and_review_paper_for_video_diffusion/</guid>
      <pubDate>Tue, 18 Jun 2024 04:22:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] DiTTo-TTS：使用 Diffusion Transformer 实现高效、可扩展的零样本文本转语音</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dihfqu/r_dittotts_efficient_and_scalable_zeroshot/</link>
      <description><![CDATA[  由    /u/keonlee9420  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dihfqu/r_dittotts_efficient_and_scalable_zeroshot/</guid>
      <pubDate>Tue, 18 Jun 2024 03:51:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 具有有界激活函数的批量规范行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dicnld/d_batchnorm_behavior_with_bounded_activation/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dicnld/d_batchnorm_behavior_with_bounded_activation/</guid>
      <pubDate>Mon, 17 Jun 2024 23:46:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] fast_mamba.np：纯粹、快速的 Mamba NumPy 实现，速度提高 4 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1di14et/p_fast_mambanp_pure_and_fast_numpy_implementation/</link>
      <description><![CDATA[      fast_mamba.np 查看了几个存储库后，我发现它们中的大多数都没有实现 Mamba 的本机缓存，以保持代码的简洁。缓存通常会使代码复杂化，这就是为什么我将 fast_mamba.np 实现为纯 Numpy 中具有缓存支持的 Mamba 的简单实现。此实现旨在简单高效，同时与 mamba.np 相比，在本地 CPU 上加速 4 倍。 https://github.com/idoh/fast_mamba.np $ python fast_mamba.py &quot;我有一个梦想&quot; &quot;&quot;&quot; 我有一个梦想，我将能够在早晨看到日出。Token count: 18, elapsed: 9.65s, 1.9 tokens/s &quot;&quot;&quot;  希望您觉得它有用 :)    submitted by    /u/id0h   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1di14et/p_fast_mambanp_pure_and_fast_numpy_implementation/</guid>
      <pubDate>Mon, 17 Jun 2024 15:39:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在我的机器学习职业生涯中感到迷茫：需要建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dhwzjk/d_feeling_lost_in_my_ml_career_advice_needed/</link>
      <description><![CDATA[大家好， 我希望这是发帖的正确地方，感谢您花时间阅读。 我今年 38 岁，来自一个贫穷的国家。父母抛弃了我，我和祖母一起长大，经历了巨大的损失和贫困。尽管我很聪明，但我一直在与注意力缺陷问题作斗争。 24 岁时，我搬到欧洲攻读计算机科学硕士学位，后来又攻读博士学位。学习六个月后，祖母去世了，导致我患上了严重的抑郁症，不得不暂停学业两年。最终，出于维持签证状态的需要，我恢复了学业，并获得了博士学位资助。我对信息检索产生了浓厚的兴趣，并于 2014 年完成了该领域的博士学位。 我的博士之旅充满挑战，抑郁和缺乏导师的支持。尽管如此，我还是发表了几篇论文，尽管我认为它们很平庸。即使在博士答辩之后，我仍然觉得自己像个大三学生。幸运的是，我在一家信誉良好的公司找到了一份工作，希望能提高自己的技能，但那是一个非技术环境。我研究了简单的 ML 模型并领导了 AI 路线图，更注重管理和领导力，而不是技术 ML 技能。 在此期间，ML 出现了重大进步，例如 BERT 和 GPT。现在我觉得我错过了这些发展。我的简历看起来令人印象深刻，有计算机科学学位、博士学位和 AI 团队经理，但我在编码和跟上新的 NLP 主题方面遇到了困难。 我确实喜欢管理和帮助他人成长，这是我的经理注意到并鼓励的（她对我说：“我从未见过有人花这么多时间帮助和培养他人，并在做这件事时表达出如此多的快乐”）。最近，我被目前的公司聘用为领导一个 NLP 研究和应用科学团队，但我觉得自己没有资格管理 ML 科学家，因为我自己并不是专家。 我也在考虑在更先进的科技公司探索从事尖端 NLP 研究的机会。我想向自己证明我有能力而不是无能。在过去的一年里，我一直专注于我的心理健康，并被诊断出患有严重抑郁症和 ADHD。这帮助我理解了我过去的行为，现在我处于一个更好的状态，正在努力完善自己。但我感到不知所措和迷茫，因为我觉得我不是真正的研究科学家，也不是 ML 工程师，也不是 AI 团队经理，因为我觉得我在所有方面都有所欠缺。 任何关于如何前进的建议都将不胜感激。 感谢您的时间和理解。    提交人    /u/Ikigai-iw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dhwzjk/d_feeling_lost_in_my_ml_career_advice_needed/</guid>
      <pubDate>Mon, 17 Jun 2024 12:35:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>