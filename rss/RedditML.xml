<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 05 Sep 2024 12:30:47 GMT</lastBuildDate>
    <item>
      <title>[D] 个人项目的云研发环境</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9ksj2/d_cloud_rd_environment_for_personal_projects/</link>
      <description><![CDATA[我正在寻找一些关于为我的 ML 项目设置个人机器的建议。我现在的笔记本电脑很旧，只有 8 GB 的 RAM，这不足以满足我的需求。我想尝试开源模型和/或使用模型 API 进行学习和个人项目 理想情况下，我想要一个可以：  安装 Conda 和 VSCode 等工具进行开发 根据需要为不同任务交换 GPU  在 AWS 或 GCP 上构建自定义设置似乎对我的预算来说太昂贵了。有哪些经济实惠的替代方案可以让我实现这种灵活性？任何建议或推荐都将不胜感激！ 提前致谢！    提交人    /u/hpoddar2810   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9ksj2/d_cloud_rd_environment_for_personal_projects/</guid>
      <pubDate>Thu, 05 Sep 2024 12:06:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找 LLM 作品的云提供商</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9i6f1/d_looking_for_cloud_provider_for_llm_works/</link>
      <description><![CDATA[大家好， 我正在研究一些 LLM 的东西——主要是微调和相关实验。这只是为了个人项目和概念验证工作，所以我正在寻找具有成本效益的选择，因为它是自掏腰包的。 我用过 Runpod 和 Lambda，但通常它们的 H100 都缺货。我也偶然发现了 GreenNode，但它似乎很新，而且我没有发现太多关于它的反馈。 还有其他您有过良好体验的提供商吗？很想听听您的想法！    提交人    /u/SquirrelEffective   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9i6f1/d_looking_for_cloud_provider_for_llm_works/</guid>
      <pubDate>Thu, 05 Sep 2024 09:24:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人使用 Flink 和 Databricks 来构建生产模型管道吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f9eifj/d_does_anyone_use_flink_with_databricks_for/</link>
      <description><![CDATA[我是一家金融公司的 ML 工程师。我们有业务关键型实时数据管道需求、定期 BI 报告，然后是 MLOps。我主张使用 Databricks 作为平台，让 ML 工程师能够端到端地拥有自己的模型管道。 我们有一个数据工程团队正在设置 Flink。ML 所需的所有数据都在 CDC Kafka 流中（从 Postgres 读取），我想将这些流提取到 Databricks 中的流表中。 提取流的一大好处是 Databricks 中的数据将反映实际的源 Postgres 数据库。 在这些流表之上，我可以为我的模型构建自己的功能管道。 我与数据工程主管发生了冲突，因为他要求我在 Databricks 中构建功能管道后，在 Flink 中重建它们，然后将该新流读入直接进入模型的 Databricks 流表中。我可以理解 Flink 可能更适合流处理，但任何需要实时的 ML 工作负载都可能存在于 Databricks 之外，并且任何可以在 Databricks 中提供给生产的 ML 工作负载都不需要 Flink 的性能优势，那么为什么不把流功能管道留在 Databricks 中呢？ 对我来说，应该是“使用正确的工具来完成工作”并且我宁愿不要求在 Databricks 中开发批处理模型管道期间设计的功能管道转换到 Flink 进行生产......我很好奇这里是否有人同时使用 Databricks 和 Flink，并且没有遇到这种摩擦。    提交人    /u/Mission-Balance-4250   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f9eifj/d_does_anyone_use_flink_with_databricks_for/</guid>
      <pubDate>Thu, 05 Sep 2024 05:05:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 类别损失函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f99t17/d_loss_function_for_classes/</link>
      <description><![CDATA[嗨 r/MachineLearning ！ 我正在阅读 Aminian 和 Xu 撰写的《机器学习系统设计访谈》。我正在阅读有关不同类别的损失函数（第 3 章，模型训练，第 67 页）： L_cls = -1/M * Sum_i=1^M ( Sum_c=1^C ( y_c * log(ŷ_c) ) ) 在回归中，我理解为什么在损失中，人们会进行“基本事实 - 预测”。这让您知道预测偏离了多少。  在分类损失的情况下，我不明白这个等式如何告诉我们“预测错误程度”...... 谢谢    提交人    /u/kovkev   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f99t17/d_loss_function_for_classes/</guid>
      <pubDate>Thu, 05 Sep 2024 00:58:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您最喜欢的免费嵌入模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f97tmh/d_what_is_your_favorite_embedding_model_that_is/</link>
      <description><![CDATA[寻找一个可以完成这项工作的小模型（尺寸 &lt; 1k）。我正在看排行榜 https://huggingface.co/spaces/mteb/leaderboard 。有什么建议吗？    提交人    /u/keepmybodymoving   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f97tmh/d_what_is_your_favorite_embedding_model_that_is/</guid>
      <pubDate>Wed, 04 Sep 2024 23:24:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对 ML 和 LLM 的测试框架和基准 - 您有什么推荐？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f96g4m/d_testing_frameworks_and_benchmarks_for_ml_and/</link>
      <description><![CDATA[大家好，我正在寻找 ML 和 LLM 的开源测试框架和基准 - 部署前和监控。你们有什么推荐？ 对以下内容有任何反馈吗？我认为它们仅适用于 LLM，对吗？  Big Bench：https://github.com/google/BIG-bench GLUE Benchmark：https://gluebenchmark.com/ SuperGLUE Benchmark：https://super.gluebenchmark.com/ OpenAI Moderation API：https://platform.openai.com/docs/api-reference/moderations MMLU：https://github.com/hendrycks/test EleutherAI LM 评估：https://github.com/EleutherAI/lm-evaluation-harness OpenAI 评估：https://github.com/openai/evals 对抗性 NLI (ANLI)：https://github.com/facebookresearch/anli LIT (语言可解释性工具)：https://pair-code.github.io/lit/ ParlAI：https://github.com/facebookresearch/ParlAI CoQA：https://stanfordnlp.github.io/coqa/ LAMBADA：https://zenodo.org/record/2630551#.ZFUKS-zML0p HellaSwag：https://rowanzellers.com/hellaswag/ LogiQA：https://github.com/lgw863/LogiQA-dataset MultiNLI：https://cims.nyu.edu/~sbowman/multinli/ SQUAD：https://rajpurkar.github.io/SQuAD-explorer/     由   提交  /u/Inessadventure   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f96g4m/d_testing_frameworks_and_benchmarks_for_ml_and/</guid>
      <pubDate>Wed, 04 Sep 2024 22:22:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 存储大型数据集的有效方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f951p8/d_efficient_way_to_store_large_datasets/</link>
      <description><![CDATA[我正在收集用于模仿学习 (RL) 的轨迹，每条轨迹大约有 1500 个时间步长，由 4 个大约 600x600 像素的图像流组成。显然，随着轨迹数量的增加，数据集大小会极快地增长。 有哪些好的库可以有效地（就磁盘空间而言）存储此类数据？我尝试使用 9 级 gzip 压缩的 h5py，但文件仍然太大。有没有更好的选择？ 保存和加载时间并不重要。 大多数在线资源旨在有效地加载大型数据集或在内存中处理它们，这与我的问题无关。 我已经使用 uint8 作为 rgb 流的数据类型。 更新：我最终通过 scikit-video 使用了有损视频压缩。这样，在将原始帧存储在数组中时，文件大小只有 2MB，而不是近 2GB。重建损失的直方图显示，大多数像素差异都在低个位数范围内，这在我的情况下不是问题，因为无论如何我都会通过噪声应用域随机化。    提交人    /u/CherubimHD   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f951p8/d_efficient_way_to_store_large_datasets/</guid>
      <pubDate>Wed, 04 Sep 2024 21:24:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 不动点扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8z85r/r_fixed_point_diffusion_models/</link>
      <description><![CDATA[  由    /u/bregav  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8z85r/r_fixed_point_diffusion_models/</guid>
      <pubDate>Wed, 04 Sep 2024 17:28:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] DiffUHaul：一种无需训练的图像中物体拖动方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8s7sy/r_diffuhaul_a_trainingfree_method_for_object/</link>
      <description><![CDATA[      DiffUHaul --- 给定一张带有物体的图像，我们的方法可以无缝地在场景中重新定位它。 项目页面： https://omriavrahami.com/diffuhaul/ 摘要： 文本到图像的扩散模型已被证明可有效解决许多图像编辑任务。然而，在场景中无缝重新定位物体这项看似简单的任务仍然极具挑战性。解决此问题的现有方法由于缺乏空间推理，通常难以在现实场景中可靠地发挥作用。在这项工作中，我们提出了一种无需训练的方法，称为 DiffUHaul，该方法利用局部文本到图像模型的空间理解来完成对象拖动任务。盲目操纵局部模型的布局输入往往会导致编辑性能低下，因为模型中对象表示的内在纠缠。为此，我们首先在每个去噪步骤中应用注意力掩蔽，使生成在不同对象之间更加分离，并采用自注意力共享机制来保留高级对象外观。此外，我们提出了一种新的扩散锚定技术：在早期的去噪步骤中，我们在源图像和目标图像之间插入注意力特征，以平滑地将新布局与原始外观融合；在后面的去噪步骤中，我们将源图像中的局部特征传递到插值图像以保留细粒度的对象细节。为了使 DiffUHaul 适应真实图像编辑，我们应用了 DDPM 自注意力存储桶，可以更好地使用局部模型重建真实图像。最后，我们为这项任务引入了一个自动评估流程，并展示了我们方法的有效性。我们的结果通过用户偏好研究得到了强化。    提交人    /u/sgd_is_all_you_need   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8s7sy/r_diffuhaul_a_trainingfree_method_for_object/</guid>
      <pubDate>Wed, 04 Sep 2024 12:37:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 分割任务的最佳性能指标是什么，以及如何提高高度倾斜数据集的性能？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8s44h/p_whats_the_best_performance_metrics_for/</link>
      <description><![CDATA[大家好！我目前正在进行脑肿瘤分割任务，类别高度倾斜，背景占 90%，肿瘤本身占 10%。我使用 IOU 来衡量性能，我得到了 [0.9, 0.4]。那么我应该将最终 IOU 测量为 0.9+0.4 / 2 还是 0.9(0.9) + 0.4 (0.1)，或者您建议使用其他性能指标？另外，您建议我如何提高性能？我尝试添加权重和归一化权重，但导致模型将背景像素（多数）预测为肿瘤（少数）。到目前为止，未加权的 CCE + 焦点损失表现最佳，尝试了骰子损失和骰子 + 焦点，但模型最终将所有内容预测为背景。提前致谢！    提交人    /u/ThrowRA_2983839   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8s44h/p_whats_the_best_performance_metrics_for/</guid>
      <pubDate>Wed, 04 Sep 2024 12:32:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 每天为数千个 AI/ML/数据科学职位提供免费 RSS 提要</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8nw8f/p_free_rss_feed_for_tousands_of_jobs_in_aimldata/</link>
      <description><![CDATA[这是为所有对通过 RSS 格式不断更新的人工智能、机器学习、NLP、计算机视觉、数据工程、数据分析、大数据和数据科学领域工作感兴趣的人准备的。工作通过 aijobs.net 汇总，每次提供 200 个列表。提要每小时更新一次最新工作。 URL：https://aijobs.net/feed/ 无需注册 - 只需将其添加到您最喜欢的提要阅读器，即可随时了解新的机会 🚀    提交人    /u/ai_jobs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8nw8f/p_free_rss_feed_for_tousands_of_jobs_in_aimldata/</guid>
      <pubDate>Wed, 04 Sep 2024 08:12:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 对于预训练的 LLM 从 PDF 中提取发票数据有何建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8nv6y/p_recommendations_for_pretrained_llms_to_extract/</link>
      <description><![CDATA[我正在寻找一个免费的预训练 LLM，它可以从德语 PDF 中准确检测和提取发票的所有部分（如客户姓名、地址、日期等）。我已经尝试使用 Python 中的 Tesseract 和 spaCy，以及我们自己训练的模型，但结果并不理想。 有谁知道市场上有哪些更好的预训练模型可能适合这个特定任务？    提交人    /u/4AVcnE   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8nv6y/p_recommendations_for_pretrained_llms_to_extract/</guid>
      <pubDate>Wed, 04 Sep 2024 08:10:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分类是识别潜在客户的正确方法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8mthy/d_is_classification_the_right_approach_for/</link>
      <description><![CDATA[大家好， 我正在开发一个模型来识别产品的潜在客户。我有 100 万客户，其中 10% 在过去一年购买了该产品。如果我将剩余的 90% 标记为非购买者 (0)，我担心模型会错误地认为他们是真正的负面案例，而实际上他们可能只是未来的买家。 分类在这里是正确的方法吗？处理尚未购买的客户有哪些更好的方法？半监督学习或正无标记 (PU) 学习等方法是否更合适？或者聚类或新颖性检测等方法是更好的选择？ 期待您的见解！请分享您遇到相同问题的类似经验 编辑：这是一个定义不明确的问题，经常出现在商业场景中。提出的主要问题是，一家企业观察到去年 90% 的客户没有购买特定产品。因此，他们正在考虑采取行动，例如发送促销电子邮件或直接沟通，但这些行动需要付出成本。在这种情况下，识别真正的买家至关重要。答案似乎必须在计划的行动范围内提供。例如，该公司计划每月瞄准潜在客户并开展营销工作。在这种情况下，我个人认为预测客户下个月的购买情况是一种解决方案，但再次考虑负面标签时感觉有些不对劲。非常感谢这里的所有观点！     提交人    /u/bfadh   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8mthy/d_is_classification_the_right_approach_for/</guid>
      <pubDate>Wed, 04 Sep 2024 06:53:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 01 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>