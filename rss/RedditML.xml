<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 14 May 2024 09:15:04 GMT</lastBuildDate>
    <item>
      <title>[R] Transformers 能在多大程度上模拟上下文中的牛顿法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1crno38/r_how_well_can_transformers_emulate_incontext/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.03183 代码： https://anonymous.4open.science/r/transformer_higher_order-B80B/ 摘要：  基于 Transformer 的模型表现出了卓越的情境学习能力，促进了对其潜在机制的广泛研究。最近的研究表明，Transformers 可以实现上下文学习的一阶优化算法，甚至可以实现线性回归的二阶优化算法。在这项工作中，我们研究 Transformer 是否可以执行线性回归之外的更高阶优化方法。我们建立了具有 ReLU 层的线性注意力 Transformer 可以近似逻辑回归任务的二阶优化算法，并且仅用更多层的误差的对数即可实现 ϵ 误差。作为副产品，我们展示了即使是线性仅注意 Transformer 也能仅用两层实现牛顿迭代的单步矩阵求逆的能力。这些结果表明 Transformer 架构有能力实现超越梯度下降的复杂算法。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1crno38/r_how_well_can_transformers_emulate_incontext/</guid>
      <pubDate>Tue, 14 May 2024 09:07:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2024 年全球人工智能锦标赛数学数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1crnika/p_a_dataset_for_the_global_artificial/</link>
      <description><![CDATA[      数据集和代码： https://github.com/protagolabs/odyssey-math AGI Odyssey&lt; /strong&gt;: https://www.agiodyssey.org 描述:&lt; /p&gt;  2024 年全球人工智能锦标赛 (GAIC) 数学呈现了 387 道精心设计的数学题，由来自大学和高中的专业数学题作者精心策划。该汇编包括 148 道高中数学竞赛题，随后是一系列 138 道高中数学题，最后是 101 道大学数学题。 GAIC Math 2024 出题者由数学教授组成来自亚利桑那州立大学、约翰霍普金斯大学、德雷克塞尔大学、新加坡国立大学、清华大学、华中师范大学等知名学府。这些教授受到AGI Odyssey的正式邀请，为比赛贡献他们的专业知识。问题制定者委员会与AGI Odyssey的使命保持一致，旨在推进通用人工智能（AGI）的创新研究，促进跨学科合作，并确保AGI的发展造福全人类。为维护竞赛的诚信和公平，出题委员会确保所有题目均为原创并保密。问题设置委员会的职责包括 GAIC Math 2024 的问题生成、审查、格式化、测试和修订。 包含 387 个问题和解决方案的新数据集，来自高中竞赛问题、高中数学问题和大学水平的数学问题。  https://preview.redd.it/2alzha4ewc0d1.jpg?width=1193&amp;format=pjpg&amp;auto=webp&amp;s=fa9735ddce1aea5f44b6a06d1fe2e4908526c80b  &lt;!-- SC_ON - -&gt;  由   提交/u/EternalBlueFriday  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1crnika/p_a_dataset_for_the_global_artificial/</guid>
      <pubDate>Tue, 14 May 2024 08:56:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] Amazon 的时间序列预测语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1crn6iw/d_language_model_for_timeseries_forecasting_from/</link>
      <description><![CDATA[时间序列预测对于许多行业来说非常重要，例如零售、能源、金融等。 我在这个领域的统计模型、深度学习模型（LSTM、CNN）始终是一个挑战。  随着语言模型空间的巨大发展，我在思考如何使用 LLM 架构进行预测，当我探索这个想法时，我发现亚马逊已经提供了多个预训练的时间序列预测模型 如果您有兴趣，请查看以下资源： https://github.com/amazon-science/chronos-forecasting&quot;&gt;https://github.com/amazon-science/chronos-forecasting&quot;&gt; com/amazon-science/chronos-forecasting https://www.amazon.science/blog/adapting-language-model-architectures-for-time-series-forecasting 您认为这样的情况会怎样模型使预测更准确？    由   提交/u/Patrick-239  /u/Patrick-239 reddit.com/r/MachineLearning/comments/1crn6iw/d_language_model_for_timeseries_forecasting_from/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1crn6iw/d_language_model_for_timeseries_forecasting_from/</guid>
      <pubDate>Tue, 14 May 2024 08:31:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习基础：案例研究方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1crmw2w/d_machine_learning_foundations_a_case_study/</link>
      <description><![CDATA[您好， 我在使用 本课程。似乎使用的库 GraphLab 和 Turi Create 已经过时并且不再常用。 是否有其他方法来练习课程中涵盖的概念？理想情况下，我想使用更多最新的库来练习课程。   由   提交 /u/Lemikaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1crmw2w/d_machine_learning_foundations_a_case_study/</guid>
      <pubDate>Tue, 14 May 2024 08:10:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人尝试过从头开始实现 KAN 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1crm54y/d_have_someone_tried_to_implement_kans_from/</link>
      <description><![CDATA[最近我听到了很多关于这种新架构（kolmogorov-Arnold Networks）的消息，它可能会给深度学习领域带来一场新的革命。  多年来，MLP 是唯一用于使用神经网络解决任何问题的架构，因此这种新架构的发布绝对是一个突破。虽然过去很多人都尝试过这样做，但不幸的是他们都没有成功。 如果你还不知道，你可以借助以下资源👇🏻 这是研究论文：https://arxiv.org/abs/2404.19756 还有这篇论文的讲解视频：https://youtu.be/-PFIkkwWdnM 如果你有尝试实现它或找到一些从头开始实现它的视频。考虑在评论中标记链接。    由   提交/u/cyb0rg14_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1crm54y/d_have_someone_tried_to_implement_kans_from/</guid>
      <pubDate>Tue, 14 May 2024 07:14:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] O(NlogN) 计算步骤和 O(logN) 时间的完整因果自注意力层，而不是 O(N^2) 计算步骤和 O(1) 时间，有一个很大的警告，但对未来充满希望。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cri6h6/d_full_causal_selfattention_layer_in_onlogn/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cri6h6/d_full_causal_selfattention_layer_in_onlogn/</guid>
      <pubDate>Tue, 14 May 2024 03:08:13 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]MICCAI 2024决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1crh21y/discussion_miccai_2024_decisions/</link>
      <description><![CDATA[大家好， 我认为这可能是讨论 MICCAI 2024 决策的好地方（早期接受、反驳、早期拒绝）。该电子邮件提到，今年有 2869 份提交（比去年增加 21%），其中约 54% 已被邀请进行反驳。 我收到了一份申请论文的反驳邀请，所有内容审稿人提到“缺乏技术新颖性”作为弱点，所以我最终得到了弱接受（4）、弱拒绝（3）和拒绝（2）。我相信我可以写一篇像样的反驳来反驳大多数审稿人的观点。但考虑到分数很低，有人认为这篇论文有希望被接受吗？反驳对于低分论文（第一轮之后）有什么影响吗？去年反驳阶段的论文最终获得接受的比例是多少？   由   提交 /u/possiblemonk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1crh21y/discussion_miccai_2024_decisions/</guid>
      <pubDate>Tue, 14 May 2024 02:10:16 GMT</pubDate>
    </item>
    <item>
      <title>ICLR2024 上您最喜欢哪篇论文？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1crgu6y/whats_your_favorite_paper_at_iclr2024_d/</link>
      <description><![CDATA[太多了，无法跟踪..   由   提交/u/Every-Act7282   /u/Every-Act7282 reddit.com/r/MachineLearning/comments/1crgu6y/whats_your_favorite_paper_at_iclr2024_d/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1crgu6y/whats_your_favorite_paper_at_iclr2024_d/</guid>
      <pubDate>Tue, 14 May 2024 01:59:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] Neurips 2024 提交内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1crahli/d_neurips_2024_submissions/</link>
      <description><![CDATA[我刚刚向 Neurips 2024 提交了一份摘要。我对自己提前两天的表现印象深刻，但我的论文 ID 已经超过 7000过去，我记得论文 ID 会随着 openreview 收到更多提交而增加。当然，今年情况并非如此！已经有 7000 份提交了？！   由   提交/u/fixed-point-learning  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1crahli/d_neurips_2024_submissions/</guid>
      <pubDate>Mon, 13 May 2024 21:07:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] LoRA 与交叉验证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cra98l/d_lora_with_cross_validation/</link>
      <description><![CDATA[有没有办法通过低秩适应进行 k 折交叉验证？我不知道如何使用 PEFT 库来实现和评估。   由   提交/u/ImitatingTheory  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cra98l/d_lora_with_cross_validation/</guid>
      <pubDate>Mon, 13 May 2024 20:57:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据标签工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cr8swg/d_data_labeling_tools/</link>
      <description><![CDATA[您最喜欢的数据标签工具有哪些？我知道以下内容： https://github.com/cleanlab/cleanlab 这是为了吵闹标签  https://github.com/voxel51/fiftyone 这是一个图像搜索引擎 但想知道其他人都在使用什么   由   提交 /u/Odd_Background4864   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cr8swg/d_data_labeling_tools/</guid>
      <pubDate>Mon, 13 May 2024 19:59:18 GMT</pubDate>
    </item>
    <item>
      <title>[N] GPT-4o</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cr5lv8/n_gpt4o/</link>
      <description><![CDATA[https://openai.com/ index/hello-gpt-4o/  这是 im-also-a-good-gpt2-chatbot（当前聊天机器人竞技场 sota） 多模式 更快且可在网络上免费使用    由   提交/u/_puhsu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cr5lv8/n_gpt4o/</guid>
      <pubDate>Mon, 13 May 2024 17:51:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我们的新分类算法在五个基准数据集上的准确性和响应时间上优于 CatBoost、XGBoost、LightGBM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cqv5y4/r_our_new_classification_algorithm_outperforms/</link>
      <description><![CDATA[大家好！ 我们很高兴与大家分享 LinearBoost，这是我们在机器学习分类算法方面的最新进展。 LinearBoost 基于增强线性分类器来显着提高性能。我们的测试表明，它在五个知名数据集上的准确性和响应时间方面优于传统 GBDT 算法。LinearBoost 增强性能的关键在于它在每个估计器阶段的方法。与 GBDT 中使用的决策树（按顺序选择特征）不同，LinearBoost 使用线性分类器作为其构建块，同时考虑所有可用特征。这种全面的功能集成可以在每一步实现更稳健的决策过程。 我们相信 LinearBoost 可以成为学术研究和实际应用的宝贵工具。在 GitHub 存储库中查看我们的结果和代码：https://github.com/LinearBoost/linearboost-classifier。该算法还处于起步阶段，并且存在 GitHub 存储库中报告的某些局限性，但我们正在未来的计划中对其进行研究。 我们很乐意获得您的反馈和建议以进一步改进，因为算法仍处于早期阶段！   由   提交/u/CriticalofReviewer2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cqv5y4/r_our_new_classification_algorithm_outperforms/</guid>
      <pubDate>Mon, 13 May 2024 09:33:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 请考虑签署这封信以开源 AlphaFold3</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cqndld/d_please_consider_signing_this_letter_to_open/</link>
      <description><![CDATA[https:/ /docs.google.com/forms/d/e/1FAIpQLSf6ioZPbxiDZy5h4qxo-bHa0XOTOxEYHObht0SX8EgwfPHY_g/viewform Google DeepMind 最近发布了 AlphaFold 的新版本 AF3。 AF3 在仅根据氨基酸序列预测看不见的蛋白质结构方面实现了 SoTA。这次迭代还增加了对各种其他复合物（例如核酸、小分子、离子和修饰残基）的联合结构预测的能力。 AF3 是一种强大的生物信息学工具，可以帮助促进全球研究。不幸的是，Google DeepMind 选择保持其闭源。 请签署这封信！ AF3 : https://www.nature.com/articles/s41586-024-07487-w    ;由   提交 /u/TeamArrow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cqndld/d_please_consider_signing_this_letter_to_open/</guid>
      <pubDate>Mon, 13 May 2024 01:24:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>