<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 26 Sep 2024 06:24:02 GMT</lastBuildDate>
    <item>
      <title>[D] 你会关注哪些信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpo0z8/d_which_feeds_do_you_look_at/</link>
      <description><![CDATA[虽然 arxiv 和 open review 是新论文的两个最佳来源，但我发现某些 feed 也非常有趣。对我来说，这包括 GitHub、Less Wrong、Hugging Face、Twitter 和 Reddit。我遗漏了什么吗？还有更多吗？博客列表？我希望有这些东西的整合。    提交人    /u/Studyr3ddit   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpo0z8/d_which_feeds_do_you_look_at/</guid>
      <pubDate>Thu, 26 Sep 2024 04:27:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 模型将 2D 平面图转换为 3D 设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpnfh1/p_models_to_convert_2d_floor_plans_to_3d_designs/</link>
      <description><![CDATA[是否有任何模型可以根据平面图生成 3D 房屋/建筑设计。如果没有，我该如何创建一个？我应该尝试收集什么样的数据来训练这样的模型？任何帮助都值得赞赏。     提交人    /u/Kirang96   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpnfh1/p_models_to_convert_2d_floor_plans_to_3d_designs/</guid>
      <pubDate>Thu, 26 Sep 2024 03:52:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻找基于前端 LLM 的迁移工具的想法（Angular 到 React）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpn2os/p_looking_for_ideas_on_a_frontend_llm_based/</link>
      <description><![CDATA[大家好！ 我负责为我们的一位客户构建一个前端迁移工具。他们已经从 Angular 迁移了一些 React 代码，这些代码可能有助于采用少量方法。我们正在考虑两个可能的方向来协助开发人员进行迁移：  编码辅助工具：一个 RAG（检索增强生成）聊天机器人，它可以理解代码库并根据用户交互建议代码片段或修改。 全自动代理：在分析现有 Angular 代码库后自动生成 React 代码的系统。  有这么多工具，我很好奇是否有人参与过类似的项目并可以推荐一些方法。以下是我遇到的工具列表以及它们如何适应我们的潜在策略： Cursor：我们正在考虑向我们的客户推荐 Cursor 的商业版本。它有一个“撰写”功能，似乎对迁移很有希望。 Langchain：它有一些关于代码理解的有用教程，但它不适合跨多个文件夹快速生成代码。不过，它对于聊天机器人方法（方向 1）来说可能是有价值的。 GPT-Engineer：与 LangChain 相反：它更适合根据提示生成完整的代码项目，但它缺乏全面​​的代码理解功能，这限制了它在代码迁移中的实用性。 这里有人有类似的需求吗？我很乐意听到任何关于其他可能有用的工具的建议或想法。 提前致谢！   由    /u/wittfm  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpn2os/p_looking_for_ideas_on_a_frontend_llm_based/</guid>
      <pubDate>Thu, 26 Sep 2024 03:31:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] Aggressor：“无矢量量化的自回归扩散”的实验实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpn0wp/p_aggressor_experimental_implementations_of/</link>
      <description><![CDATA[大家好 r/MachineLearning！我想分享一个我一直在做的项目，并从社区获得一些反馈。 项目概述 我在一个名为“Aggressor”的项目中实现了我自己版本的最近论文&quot;无矢量量化的自回归图像生成&quot;&quot;。目标是创建一个超最小自回归扩散模型，从图像生成开始，然后扩展到各种模态和架构变化。 GitHub Repo： Aggressor 主要特点  核心实现： aggressor.py 包含用于图像生成的最小实现。 实验变化：  ret_aggressor.py：用 RetNet（Retentive Network）机制取代标准注意力机制，允许像注意力机制一样并行训练，但 O(n) 循环生成。 dct_aggressor.py：利用离散余弦变换 (DCT) 用于图像生成，探索频域表示。 wav_aggressor.py：使用 DCT 调整模型以生成音频，展示跨模态功能。 ycr_aggressor.py：尝试使用 YCbCr 颜色空间生成图像，可能提高色彩保真度。  最小依赖性：仅使用基本的 MLX 操作从头开始构建。 多模态：支持图像和音频生成，并计划用于视频。  结果 我已经在 MNIST、CIFAR 和音频数据集上测试了各种模型。您可以在 README 中看到一些示例输出。 技术细节  主要的 Aggressor 类结合了转换器（或 RetNet）和扩散模型。 使用自定义 Scheduler 处理扩散中的前向和后向过程。 对图像和音频数据进行 DCT（离散余弦变换）实验。  未来方向  实现视频生成 致力于全模态模型 探索不需要标记器的字节级多模态语言模型的可能性  社区问题  有人尝试过跨不同模态的自回归扩散吗？有什么见解吗？ 有没有建议有效地将这种方法扩展到视频或多模态数据？ 关于使用 DCT 或其他变换来提高生成质量或效率的想法？ 有没有使用多模态数据的字节级模型的经验？挑战还是好处？  我愿意接受任何反馈、问题或改进建议。我特别有兴趣讨论将这种方法扩展到更复杂的多模态场景的潜力和挑战。谢谢您的关注！    提交人    /u/JosefAlbers05   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpn0wp/p_aggressor_experimental_implementations_of/</guid>
      <pubDate>Thu, 26 Sep 2024 03:28:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 表格增强生成(TAG)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fplpnk/d_table_augmented_generationtag/</link>
      <description><![CDATA[https://arxiv.org/pdf/2408.14717 https://github.com/TAG-Research/TAG-Bench?tab=readme-ov-file 有人看过 TAG 论文或 GitHub 吗？我觉得他们没有做什么特别的事情。我不知道他们能带来什么独特的价值。如果我遗漏了什么，请告诉我。 他们的技术分为 3 个步骤： 查询合成 查询执行 答案生成步骤 但他们确实声称，与使用传统的 text2sql 或 RAG 回答结构化数据问题相比，这种技术提供的结果准确率高达 65%。    提交人    /u/G_S_7_wiz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fplpnk/d_table_augmented_generationtag/</guid>
      <pubDate>Thu, 26 Sep 2024 02:15:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] ViT 受益于双曲空间变换</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fplhvi/r_vits_benefit_from_hyperbolic_space_transform/</link>
      <description><![CDATA[https://arxiv.org/abs/2409.16897    由   提交  /u/jacobfa   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fplhvi/r_vits_benefit_from_hyperbolic_space_transform/</guid>
      <pubDate>Thu, 26 Sep 2024 02:03:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 大型语言模型结构化输出和函数调用的基本指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpiqlj/p_the_essential_guide_to_large_language_models/</link>
      <description><![CDATA[过去一年，我一直在使用 LLM 构建生产系统。当我在 2023 年 8 月开始工作时，材料非常稀缺，以至于必须先重新发明许多轮子。时至今日，情况已经发生了变化，但社区仍然迫切需要教育材料，特别是从生产角度来看。 很多人都在谈论 LLM，但很少有人真正将它们应用于他们的用户/业务。 这是我对社区的新贡献，“大型语言模型结构化输出和函数调用基本指南”文章。 这是一篇关于结构化输出和函数调用的实践指南（长篇），以及如何从 0 到 1 应用它们。要求不多，只是一些基本的 Python，其余的都解释了。 我在公司将其应用于“让我们通过 LLM 为 20 万以上用户解决所有客户支持问题”的计划中取得了相当大的成功。我们还没有达到 100% 的目标，但我们正在快速实现目标，特别是结构化的输出使我们成为可能。 传播这个消息，让我们在演示之外分享更多关于应用 LLM 的经验。    提交人    /u/p_bzn   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpiqlj/p_the_essential_guide_to_large_language_models/</guid>
      <pubDate>Wed, 25 Sep 2024 23:42:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有任何论文或资源使用 LLM 进行分类，同时结合有关类别的知识来帮助分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpics7/d_are_there_any_papers_or_resources_are_using_llm/</link>
      <description><![CDATA[我正在开发一个分类器，但在当前使用的系统/模型中遇到了问题。我当前使用的分类器是 BERT + 微调分类器。对于具有足够数据的类别，结果还不错，但对于没有足够样本的类别，结果基本上毫无用处。我一直在研究构建一个新系统，利用类别中的知识来帮助对没有适当标签的样本进行分类。 例如，如果我有文本“从树上长出的小红色球形水果”和“苹果”、“香蕉”和“橙子”的选择，我希望能够结合这些选择中的知识来帮助指导输入文本，而无需将其明确地放在训练数据集中。 我使用 GPT 4o 做了一些实验并得到了以下结果。  向 GPT 输入：我正在给我的车加油。这算是维修、修理，还是与车门有关。解释你的理由 它回应了  `如果您需要在维修、修理或与车门有关的东西之间做出选择，最合适的选择是维修。原因如下：维修：虽然加油通常不是汽车维修所想到的（因为它更常与换油、轮胎换位等维护任务相关），但它确实有助于车辆的定期保养和运行。从广义上讲，您通过为汽车加油来确保汽车能够运行，因此在这种情况下可以将其归类为&quot;维修&quot;。修理：加油不属于这一类别，因为没有任何东西需要修理或恢复。汽车没有故障；它只是燃料不足，这是正常的操作要求，而不是故障。车门：加油不涉及车门，因此可以排除此选项。`  看起来该模型至少能够使用关于维修、修理和车门的先验知识来帮助指导决策。  有没有什么论文或资源可以帮助我回答以下问题？ GPT 如何能够这样推理并应用有关类别的知识？  有没有办法在不必经过文本提示过程的情况下整合这些知识？  我如何扩展它以处理数千个类/子类（维修/前部护理/前轮胎和维修/保险杠/重大损坏）。  最后，我如何在本地机器上创建这样的系统（包含敏感数据，因此无法连接到 API）？    提交人    /u/newjeison   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpics7/d_are_there_any_papers_or_resources_are_using_llm/</guid>
      <pubDate>Wed, 25 Sep 2024 23:23:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama 3.2详细分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpckbb/d_llama_32_detailed_analysis/</link>
      <description><![CDATA[大家好！Meta 发布了一组新的 Llama 3.2 模型，分别用于文本（1B、3B）和视觉（11B、90B）。我对这些模型进行了深入研究，希望能够有所启发：  新的 1B 和 3B 文本专用 LLM 9 万亿个 token 新的 11B 和 90B 视觉多模态模型 128K 上下文长度 1B 和 3B 使用了一些来自 8B 和 70B 的提炼 VLM 60 亿个图片、文本对 CLIP MLP GeLU + 交叉注意  长分析：1. 视觉编码器中使用带有 GeLU 激活的 CLIP 类型 MLP。类似于 GPT2 的 MLP。与 Llama 3 的 MLP 不同，因为 SwiGLU 不用于视觉 MLP。  用于视觉编码器的正常 layernorm - 不是 RMS Layernorm。此外，一些“门控”参数用于乘以隐藏状态。 在注意力和 MLP 之后对隐藏状态进行门控乘法器 - tanh 用于将向量缩放移动到从 -1 到 1 的数字。 对于小型 1B 和 3B LLM 以及多模态 VLM 11B 和 90B，评估看起来相当不错。1B 49.3 MMLU 和 3B 63.4。 VLM MMMU 50.7 和 90B 60.3  感谢您的阅读，如果您有任何疑问，请告诉我！    由    /u/danielhanchen 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpckbb/d_llama_32_detailed_analysis/</guid>
      <pubDate>Wed, 25 Sep 2024 19:09:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2024 评审问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpa7ua/d_neurips_2024_review_question/</link>
      <description><![CDATA[我最初的审稿人指出了一些弱点和顾虑，但这些问题在我的反驳中得到了解决。他们承认了这一点并提高了分数。  我的论文最终被拒绝，因为程序主席引入了由于误读论文而产生的新弱点，如果这些弱点在最初的审稿中有所说明，这个问题将很容易解决。我能做些什么来修复这个程序主席的审稿吗？    提交人    /u/sqweeeeeeeeeeeeeeeps   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpa7ua/d_neurips_2024_review_question/</guid>
      <pubDate>Wed, 25 Sep 2024 17:30:43 GMT</pubDate>
    </item>
    <item>
      <title>[R]基于注意力的选择性激活架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp70ca/r_attentionbased_selective_activation_architecture/</link>
      <description><![CDATA[有没有研究探索过灵活推理/深度负载架构的想法？也就是说，根据样本的任务难度，对模型的不同层深度进行训练。这将通过绕过模型的后面层来完成，以完成较简单的任务。最困难的任务将占用整个网络。对于 LLM 来说，在 Transformer/Mamba 中实现这一点需要一些思考，但我相信这是可行的。特别是如果在 Beam 方法下进行训练，而不是单输出方式（从未理解为什么仍然这样做，因为 Beam 似乎更好）。可以采用基于注意力的机制来决定推理的深度，或者采用某种强化学习主导的方法（训练后，如果 layer = n 给出错误的输出，则转到 n+1 直到满意为止） 我相信这会使模型在不同层次的复杂性/智能上成形（每层都能够输出一些可理解的内容，从而生成更易于解释的模型）。它还可以解决很多不必要的推理时间。 这个想法是一种看待“思维链”和我们真正思考方式的不同方式。它会将“思考”部分直接嵌入模型中，而不会自行生成内部独白。总而言之，仍然认为这两种方法都是积极且兼容的（我认为我们人类同时做这两种事情）。    提交人    /u/hatekhyr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp70ca/r_attentionbased_selective_activation_architecture/</guid>
      <pubDate>Wed, 25 Sep 2024 15:18:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要多少微分方程知识才能理解流动、扩散 SciML 和相关领域的研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foygx0/d_how_much_knowledge_of_differential_equations_is/</link>
      <description><![CDATA[我印象中，基础微积分、概率、统计和线性代数为理解深度学习的工作奠定了坚实的基础。但是看到最近关于流匹配、流标准化、扩散和科学机器学习领域的论文，我无法理解超出某一点的东西。  我知道他们大量使用微分方程。我在该领域的知识几乎低于新手水平。在哪里可以学到更多关于微分方程的知识？我想获得理解这些领域工作的能力，以及论文作者如何以及为何提出这种实现。    提交人    /u/HopeIsGold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foygx0/d_how_much_knowledge_of_differential_equations_is/</guid>
      <pubDate>Wed, 25 Sep 2024 07:05:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果对抗性学习研究表明神经网络对输入/权重扰动非常脆弱，那么量化为什么会起作用呢？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fosr7z/d_if_adversarial_learning_studies_suggest_neural/</link>
      <description><![CDATA[我一直在想为什么这两种观察结果可以共存而不发生冲突。对抗性学习的研究似乎表明，人们可以很容易地找到输入或权重上的微小扰动，这些扰动可以彻底改变某些输出。如果扰动某些权重已经足够糟糕，那么像量化那样扰动每个权重肯定会带来灾难性的后果？ 我有几个猜测：  也许对抗性扰动方向很多但在所有可能的方向中很少见，而像量化这样的随机扰动不太可能是对抗性的？ 也许我们确实引入了错误，但只在一小部分输出上，这还不够糟糕？ 也许随机权重扰动对非常大的网络的损害较小？  是否有人知道现有的优秀研究可以解释为什么量化不会导致无意的自我破坏？    提交人    /u/aeroumbria   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fosr7z/d_if_adversarial_learning_studies_suggest_neural/</guid>
      <pubDate>Wed, 25 Sep 2024 01:20:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 22 Sep 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>