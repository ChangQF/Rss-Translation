<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 14 Apr 2024 22:06:17 GMT</lastBuildDate>
    <item>
      <title>[D] 训练过程中的错误：一批中的模型预测完全相同</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c40dcl/d_error_during_training_model_predictions_all_the/</link>
      <description><![CDATA[我正在尝试训练一个神经网络，它接受两个文本输入并生成一个二进制分类输出。我有一个巨大的数据集（约 200 万个句子），我正在 pytorch 上使用简单的 LSTM + 线性层模型对其进行处理。 但是，无论我训练它多久，批次中的所有值都会被分配相同的预测（https://imgur.com/a/nAZP0Tp）。 有任何修复吗？&lt; /p&gt;   由   提交/u/Thin-Watch-7699   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c40dcl/d_error_during_training_model_predictions_all_the/</guid>
      <pubDate>Sun, 14 Apr 2024 18:27:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将机器学习应用到非传统领域的研究人员，你们在做什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c40asb/d_researchers_who_are_applying_ml_to_non/</link>
      <description><![CDATA[我很想了解更多有关农业、卫生经济学等领域的人员的信息 请提供  研究领域 您正在解决的问题 该领域有什么有趣的论文吗？    由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c40asb/d_researchers_who_are_applying_ml_to_non/</guid>
      <pubDate>Sun, 14 Apr 2024 18:24:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 思维可视化在大型语言模型中引发空间推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c4017q/r_visualizationofthought_elicits_spatial/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.03622 摘要：  大型语言模型（LLM）在语言理解方面表现出了令人印象深刻的表现以及各种推理任务。然而，它们的空间推理能力（人类认知的一个重要方面）仍然相对未被开发。人类拥有一种非凡的能力，可以通过称为“心灵之眼”的过程创造看不见的物体和行为的心理图像，从而实现对看不见的世界的想象。受这种认知能力的启发，我们提出了思维可视化（VoT）提示。 VoT旨在通过可视化法学硕士的推理轨迹来引发法学硕士的空间推理，从而指导后续的推理步骤。我们将 VoT 用于多跳空间推理任务，包括自然语言导航、视觉导航和 2D 网格世界中的视觉平铺。实验结果表明，VoT 显着增强了法学硕士的空间推理能力。值得注意的是，VoT 在这些任务中的表现优于现有的多模式大语言模型 (MLLM)。虽然 VoT 在 LLM 上的效果出奇的好，但生成心理图像以促进空间推理的能力类似于心灵的眼睛过程，这表明它在 MLLM 中的潜在可行性。     由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c4017q/r_visualizationofthought_elicits_spatial/</guid>
      <pubDate>Sun, 14 Apr 2024 18:14:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] CNN加速器RTL设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3zw9f/p_cnn_accelerator_rtl_design/</link>
      <description><![CDATA[我为大学开发了这个基本通用的 CNN 和全连接层加速器项目，我想与您分享。它像 Coral TPU 一样使用 int8 量化数据和权重。该项目包含一个脚本，可将 TensorFlow 模型转换为加速器所需的指令。此外，还有一个 MNIST 分类器的示例。更多信息请参阅自述文件。 https://github.com/bautistasch/CNN-FC-accelerator&lt; /a&gt;   由   提交 /u/instrumentosdetexas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3zw9f/p_cnn_accelerator_rtl_design/</guid>
      <pubDate>Sun, 14 Apr 2024 18:08:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言模型物理学：第 3.3 部分，知识能力缩放定律</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3zefx/r_physics_of_language_models_part_33_knowledge/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.05405 摘要：  缩放定律描述了语言模型的大小与其模型之间的关系。能力。与之前通过损失或基准评估模型能力的研究不同，我们估计模型存储的知识位数。我们专注于以元组表示的事实知识，例如维基百科页面中的（美国、首都、华盛顿特区）。通过多个受控数据集，我们确定语言模型每个参数只能存储 2 位知识，即使量化为 int8 也是如此，并且可以灵活地提取这些知识以供下游应用程序使用。因此，7B 模型可以存储 14B 位知识，超过了我们估计的英语维基百科和教科书的总和。更广泛地说，我们提出了 12 个结果，涉及 (1) 训练持续时间、(2) 模型架构、( 3）量化，（4）稀疏性约束，例如MoE，以及（5）数据信噪比影响模型的知识存储容量。值得注意的见解包括： * 采用旋转嵌入的 GPT-2 架构在知识存储方面匹配甚至超越了 LLaMA/Mistral 架构，特别是在较短的训练持续时间内。出现这种情况是因为 LLaMA/Mistral 使用 GatedMLP，它不太稳定且难以训练。 * 在训练数据前添加域名（例如，此 http URL ）显着提高了模型的知识容量。语言模型可以自主识别知识丰富的领域并对其进行优先级排序，从而优化其存储容量。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3zefx/r_physics_of_language_models_part_33_knowledge/</guid>
      <pubDate>Sun, 14 Apr 2024 17:47:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于发现“假”机器学习角色的建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3z8ug/d_advice_for_spotting_fake_ml_roles/</link>
      <description><![CDATA[我最近被聘用，结果证明这是一个假的 ML 角色，即使按照 ML 角色最宽松的定义（彭博 AI 小组）也是如此。目前似乎有许多公司/团队/人员假装从事机器学习工作，而在招聘时，他们对候选人实际所做的工作撒谎。有没有人有任何策略来发现此类角色，从而避免它们？面试时提问似乎不太有效，因为你很容易被骗。   由   提交 /u/Outrageous-Base3215    reddit.com/r/MachineLearning/comments/1c3z8ug/d_advice_for_spotting_fake_ml_roles/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3z8ug/d_advice_for_spotting_fake_ml_roles/</guid>
      <pubDate>Sun, 14 Apr 2024 17:41:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当前的学术研究趋势与当前的学术研究趋势未来5年</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3xgdw/d_current_academic_research_trends_vs_next_5_years/</link>
      <description><![CDATA[大家好！  正如标题所示，我想征求您的意见（特别是对于那些活跃于机器学习领域的研究人员），您认为哪些当前热门话题将在未来 5 年内保持相关性，以及您认为哪些话题会继续相关。被视为注定会失去研究兴趣的临时趋势。 例如，两个明显的研究领域是法学硕士（以及一般而言基于变压器的模型）和生成图像模型（例如基于扩散的架构） 。  就我个人而言，我认为物理信息网络（通常用于求解描述物理系统的非线性偏微分方程，和/或不同工程领域的建模过程）将变得越来越重要。对我来说，他们最终将提供一个框架，允许各种行业整合机器学习模型来优化其制造和设计流程。 根据我的个人经验，许多考虑攻读机器学习博士学位的学生对主题有些犹豫选择，因为担心陷入不再相关的话题。考虑到人工智能研究的现状，这种担心真的有道理吗？    由   提交/u/fliiiiiiip   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3xgdw/d_current_academic_research_trends_vs_next_5_years/</guid>
      <pubDate>Sun, 14 Apr 2024 16:24:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]特征向量和嵌入有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3thlk/d_what_is_the_difference_between_feature_vectors/</link>
      <description><![CDATA[我正在使用语音（即语音身份验证）进行用户身份验证项目。我正在研究给定音频/语音的不同方面，我可以利用这些方面来识别特定的人，最常用的东西之一是 MFCC 特征，这些特征是使用任何标准音频处理库（如 Librosa）提取的。 现在，最近我们有了嵌入，它可以基本捕获矢量形式的信息，可以是音频、视频、文本或图像。所以我一路上有一些疑问，  对于音频，嵌入意味着什么？它们与 MFCC 功能有什么不同吗？ 我可以直接使用音频嵌入来进行说话者识别/验证吗？就像我正在考虑的方法一样为每个用户提供一个带有嵌入的数据库，然后进行测试，看看我们在数据库中是否有匹配的测试音频。  我遇到的音频嵌入模型之一是&lt; a href=&quot;https://arxiv.org/abs/2006.11477&quot;&gt;Wav2Vec 2.0 by Meta。 PS：我是 ML 领域的新手，仍在学习中，请原谅我我在这里犯了任何错误。   由   提交 /u/Puzzleheaded_Bee5489   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3thlk/d_what_is_the_difference_between_feature_vectors/</guid>
      <pubDate>Sun, 14 Apr 2024 13:23:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前最先进的代码嵌入模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3s6v3/d_what_are_the_current_state_of_the_art_code/</link>
      <description><![CDATA[有谁知道语义代码相似性搜索的最佳模型/基准是什么？特别是，我想找到一个主要针对 c/c++ 代码进行训练的模型，以便可以使用嵌入来比较特定函数与其他函数的相似程度，以及比较与自然语言描述的相似性。我遇到了Code T5，看起来相当不错。但尚不清楚在训练期间使用了多少 c/c++ 代码（似乎在预训练期间可能使用了一些，但如果我理解正确的话，则不会使用代码/自然语言对）。我想显然有很多法学硕士接受过代码训练，我可以从中提取嵌入，但我理想情况下希望有一个经过明确训练以实现语义代码相似性的法学硕士。   由   提交 /u/henrythepaw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3s6v3/d_what_are_the_current_state_of_the_art_code/</guid>
      <pubDate>Sun, 14 Apr 2024 12:14:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] CUDA 编程是行业内紧缺的技能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3q0mq/d_is_cuda_programming_an_indemand_skill_in_the/</link>
      <description><![CDATA[大家好，我目前在医疗保健/计算机视觉领域担任人工智能工程师。目前我所做的工作是重复性的、单调的。主要涉及数据准备和模型训练。希望拓展业务并学习一些其他行业相关技能。我正在考虑学习 CUDA 编程，而不是走学习模型部署的老路。 CUDA 编程是否为其他角色打开了大门？它增加了什么样的价值？ 非常欢迎任何进一步的建议/建议   由   提交 /u/Hour_Amphibian9738   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3q0mq/d_is_cuda_programming_an_indemand_skill_in_the/</guid>
      <pubDate>Sun, 14 Apr 2024 09:59:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 离散扩散的极其简短且简单的实现，在 pytorch 中，开源（400 loc）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3pvx5/p_extremely_short_and_simple_implementation_of/</link>
      <description><![CDATA[      https://github.com/cloneofsimo/d3pm  https://i.redd.it/tjsaqoum2fuc1.gif 嗨，我付出了相当多的努力在 pytorch 中从头开始重新实现 d3pm（离散扩散）。离散扩散的 pytorch 实现并不多，希望这有帮助！   由   提交 /u/cloneofsimo   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3pvx5/p_extremely_short_and_simple_implementation_of/</guid>
      <pubDate>Sun, 14 Apr 2024 09:49:52 GMT</pubDate>
    </item>
    <item>
      <title>发布了我的Python数据排序工具供社区使用[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3o9hz/released_my_python_data_sorting_tools_for/</link>
      <description><![CDATA[       由   提交 /u/Kilroy_GreyFox   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3o9hz/released_my_python_data_sorting_tools_for/</guid>
      <pubDate>Sun, 14 Apr 2024 07:59:20 GMT</pubDate>
    </item>
    <item>
      <title>Cognita：真正统一的 RAG 框架：第 1 部分 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c3k2av/cognita_a_truly_unified_rag_framework_part_1_d/</link>
      <description><![CDATA[      无缝解析、精准检索、智能生成&amp;轻松部署，开始吧...  全文 ​ 信用：https://github.com/truefoundry/cognita  既然有这么多，为什么要关心呢？ 🤔 RAG （检索增强生成）系统功能强大，但构建和部署它们可能很棘手。 🚀 Cognita 旨在成为一个用户友好的模块化解决方案，以解决常见的 RAG 挑战。  寻找真正的生产级完整 RAG 框架  当前框架的问题： ⚙️ 分块和分块嵌入作业通常需要单独设置，但目前还没有内置在作者已知的当前框架中。 💻 为生产部署查询服务可能很复杂 🤖 处理模型部署（语言模型、嵌入模型）缺乏内置支持。 🗄 矢量数据库的可扩展性部署可能很棘手。 🧩 没有单一的、即用型模板可以轻松采用 ⚠️ 免责声明：这些问题可能已由其他框架解决，但作者在撰写本文时还不知道。  Cognita 如何解决这些问题 🎯 Cognita 在定制与易用性之间取得平衡。 🧠 可扩展设计，可在突破发生时进行整合。  Cognita — 用于构建用于生产的模块化开源 RAG 应用程序的库 🧱 模块化设计：将 RAG 分解为多个步骤，以便于管理和更新。 ♻️ 可重用组件：解析器、加载器等，以节省跨项目的时间。 🚀 简化部署：Cognita 处理生产系统的细节。 ⚖️ 可扩展性：组件独立扩展以处理增加的流量。 ✨ 用户- 友好的界面：即使是非技术用户也可以使用 RAG 设置。 🔌 API 驱动：Cognita 与其他系统配合良好。  Cognita 组件 索引作业 1. 数据加载器🚚 内容：从各个位置（文件夹、数据库等）获取数据。 为什么：RAG 需要数据来工作！ 2. 解析器🗂️ 目的：将不同的文件类型转换为通用格式。 原因：让 RAG 系统更容易处理所有内容。  3. 嵌入器 🔎 目的：创建类似代码的文本表示形式以进行快速比较 原因：帮助找到与您的问题最相关的信息。  元数据存储🧠 是什么：系统的“大脑”，存储配置详细信息 原因：让您的 RAG 井然有序且易于管理。  LLM Gateway 💬 是什么：不同语言模型的“翻译器”。 原因：让您可以在模型之间切换，而无需重新编码所有内容。  Vector DB 🗄️ 用途：存储嵌入以实现超快速数据搜索。 原因：高效搜索是大型数据集的关键。  API 服务器 ⚙️ 作用：处理用户问题并生成答案的协调器。 原因：它将 RAG 系统的所有部分连接在一起。  对第 2 部分感到兴奋：使用 Cognita 进行编码！ 💻🚀  ​   由   提交 /u/AssistanceOk2217   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c3k2av/cognita_a_truly_unified_rag_framework_part_1_d/</guid>
      <pubDate>Sun, 14 Apr 2024 03:35:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这里的人们不知道现在顶尖博士项目的招生竞争有多么激烈，哇......</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2x5mx/d_folks_here_have_no_idea_how_competitive_top_phd/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2x5mx/d_folks_here_have_no_idea_how_competitive_top_phd/</guid>
      <pubDate>Sat, 13 Apr 2024 08:29:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>