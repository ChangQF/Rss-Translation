<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 16 Dec 2024 01:24:41 GMT</lastBuildDate>
    <item>
      <title>如何根据诗歌生成模型遵循文体指南的程度来评估其性能？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hf7l8n/how_can_i_evaluate_the_performance_of_my_poetry/</link>
      <description><![CDATA[因此，我正在创建一个机器学习系统，该系统根据输入生成诗歌，告诉它要遵循的诗人风格。我一直在尝试评估该模型的性能，但大多数客观评估指标都是根据生成的诗人与诗人诗歌样本的接近程度来分配分数。这没有帮助，因为我试图了解风格与措辞的匹配程度。有什么建议吗？    提交人    /u/SkyRevolutionary275   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hf7l8n/how_can_i_evaluate_the_performance_of_my_poetry/</guid>
      <pubDate>Mon, 16 Dec 2024 01:14:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我如何在这个就业市场找到工作？我如何才能脱颖而出？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hf7a4g/d_how_do_i_get_a_job_in_this_job_market_how_do_i/</link>
      <description><![CDATA[  由    /u/__proximity__  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hf7a4g/d_how_do_i_get_a_job_in_this_job_market_how_do_i/</guid>
      <pubDate>Mon, 16 Dec 2024 00:59:27 GMT</pubDate>
    </item>
    <item>
      <title>微调法学硕士 (LLM) 中的内存要求 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hf58kj/memory_requierements_in_finetune_llms_d/</link>
      <description><![CDATA[嗨，我正在尝试微调 meta-llama/Llama-3.2-1B-Instruct。我使用 Transformers 库以 4 位精度加载模型，并使用 PEFT 库和 TRL 应用 LoRA 方法。当我开始训练步骤时，问题就出现了，因为我一直内存不足，但我不知道为什么。这些是我的训练参数：training_args = SFTConfig（output_dir =&#39;/ content / results&#39;，num_train_epochs = 5，per_device_train_batch_size = 1，per_device_eval_batch_size = 1，gradient_accumulation_steps = 2，learning_rate = 2e-4，bf16 = True，logging_steps = 50，eval_strategy =&#39;steps&#39;，eval_steps = 500，save_strategy =“steps”，save_steps = 500，warmup_steps = 100，weight_decay = 0.01， logs_dir=&quot;/content/logs&quot;,packing=True, report_to=&quot;none&quot; ) trainer = SFTTrainer( model=model, train_dataset=templated_dataset[&#39;train&#39;], eval_dataset=templated_dataset[&#39;test&#39;], args=training_args, tokenizer=tokenizer, ) 序列长度为 2048，要训练的参数为 1,179,648 (LoRA)。我计算出我需要大约 3.57GB，但是我只有 15GB，内存不够了。我不知道我的训练参数配置是否有问题。你能帮帮我吗？提前致谢。    由   提交  /u/Top-Leave-7564   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hf58kj/memory_requierements_in_finetune_llms_d/</guid>
      <pubDate>Sun, 15 Dec 2024 23:18:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了 wut – 一个使用 LLM 解释你的最后一个命令的 CLI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hew6wy/p_i_made_wut_a_cli_that_explains_your_last/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hew6wy/p_i_made_wut_a_cli_that_explains_your_last/</guid>
      <pubDate>Sun, 15 Dec 2024 16:29:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</guid>
      <pubDate>Sun, 15 Dec 2024 16:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们能接受这个吗？NeurIPS 上令人质疑的发帖行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1heo36q/d_are_we_okay_with_this_questionable_poster/</link>
      <description><![CDATA[      这是我参加 NeurIPS 的第一年。看到如此多的前沿研究成果被展示，真是令人振奋，但在海报展示期间，一些令人不安的事情引起了我的注意，我觉得有必要分享一下，尤其是考虑到最近与 Rosalind Picard 发生的事件。 论文被 NeurIPS 接受是一个巨大的成就。每一个海报位置都代表着如此多的辛勤工作，并且令人垂涎。 我看到了两张不应该在那里的海报，这让我对这些空间的开发产生了怀疑。 非法海报 #1： Generative Boba。这是一张“可爱，看我”的海报，但它还带有一个链接到创作者 X/Twitter 的二维码。虽然海报本身被放置在展厅的侧墙上，而不是官方海报位置（当我看到它时），但它仍然感觉很奇怪。他们为什么要制作这张海报？这是为了激发欢乐，还是为了吸引注意力和粉丝？ 非法海报 #1：Generative Boba。 非法海报 #2： Benchmarkthing。 这更令人担忧。它公然宣传一家新的 AI 初创公司，并提到由我们领域的知名人物 Jeff Dean 提供资金。与 boba 海报不同，从视觉上看，这可以被视为真正的 NeurIPS 海报。可能大多数路人都没有多想，但海报的展示者（也是公司的创始人）实际上是在推广他的新创业公司，有时是向大量观众推广，而且是在多个海报展示会上。这让人感觉具有欺骗性和剥削性——利用社区的信任，在神圣的学术空间中作弊获得知名度。 非法海报 #2：Benchmarkthing。 另一种类型的游戏是作者将海报张贴在未使用的位置，同时在正式指定的位置留下一个标志，上面写着“在#{更好的位置} 查看海报”。如果未使用位置的作者到了，他们只需将海报移回原位 — 但如果作者没有到，他们大概会因为位置更靠近大厅入口、人流量更大而受到更多关注。 重新放置海报似乎仍有问题，但至少海报属于会议。另一方面，我更强烈地认为未经授权的海报用于个人或商业宣传会损害空间的完整性，不尊重海报真正属于此处的演讲者，并破坏整个会议。 社区问题：  是否应该对海报会议制定更严格的政策或更好的执行？ 我们如何区分轻微的游戏（例如重新放置海报）和彻底的剥削（例如未经授权的海报）？ 只要意图是轻松的或仍然是学术性的，容忍一些灵活性是否公平？  我们该如何应对这些行为？应该承担后果吗？     提交人    /u/Positive_Lychee6904   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1heo36q/d_are_we_okay_with_this_questionable_poster/</guid>
      <pubDate>Sun, 15 Dec 2024 08:08:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当你的模型正在训练时你做什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hemhil/d_what_do_you_do_while_your_model_is_training/</link>
      <description><![CDATA[我基本上在模型训练时照看它，看一些《豪斯医生》或者玩一些我的世界。我已经完成了所有的文献综述和论文写作，现在在我的模型训练时我应该做什么？    提交人    /u/Striking-Warning9533   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hemhil/d_what_do_you_do_while_your_model_is_training/</guid>
      <pubDate>Sun, 15 Dec 2024 06:11:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医学 AI：顶级 LLM 研究论文/模型（2024 年 12 月 7 日至 12 月 14 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hecwvp/d_last_week_in_medical_ai_top_llm_research/</link>
      <description><![CDATA[   [D] 医学 AI 上周：顶级 LLM 研究论文/模型（2024 年 12 月 7 日至 12 月 14 日） 医学 LLM &amp;  PediaBench：中文儿科法学硕士  本文介绍了 PediaBench，这是第一个用于评估大型语言模型 (LLM) 问答性能的中文儿科数据集，包含 12 个疾病组的 4,565 个客观问题和 1,632 个主观问题。  BiMediX：双语医学法学硕士  本文介绍了 BiMediX，这是第一个双语（英语-阿拉伯语）医学专家混合法学硕士，以及 BiMed1.3M，这是一个 1.3M 的双语医学指导数据集，其中包含超过 632M 个用于训练的标记。  多样化医学知识整合  本文介绍了 BiMediX2，这是一个基于 Llama3.1 架构的双语（阿拉伯语-英语）大型多模态模型 (LMM)，在160 万个医疗互动样本。  BRAD：数字生物语言模型 本文介绍了 BRAD（生物信息学检索增强数字助理），这是一个由 LLM 驱动的聊天机器人和代理系统，集成了各种生物信息学工具。  MMedPO：视觉语言医学 LLM  本文介绍了 MMedPO，一种多模态医学偏好优化方法，通过解决模态错位来提高医学大型视觉语言模型（Med-LVLM）中的事实准确性。   框架和方法论 - TOP-Training：医疗问答框架 - 混合 RAG：安全医疗数据管理 - 零样本 ATC 临床编码 - 胸部 X 光诊断架构 - 医学影像 AI 民主化 基准和评估 - KorMedMCQA：韩国医疗保健许可基准 - 大型语言模型医疗任务 - 临床 T5 模型性能研究 - 放射学报告质量评估 - 基因组分析基准 LLM 应用 - TCM-FTP：草药处方预测 - LLaSA：通过传感器进行活动分析 - 急诊科就诊预测 - 神经退行性疾病 AI 诊断 - 肾脏疾病可解释 AI 模型 道德 AI 与隐私 - 隐私保护 LLM 机制 - 人工智能驱动的数字有机体建模 - 生物医学研究自动化 - 医学实践中的多模态性 完整线程详细信息：https://x.com/OpenlifesciAI/status/1867999825721242101    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hecwvp/d_last_week_in_medical_ai_top_llm_research/</guid>
      <pubDate>Sat, 14 Dec 2024 21:25:08 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 矩阵循环状态，注意力机制的替代方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he8vhw/project_matrix_recurrent_states_a_attention/</link>
      <description><![CDATA[      https://github.com/mikayahlevi/mru-lm 大家好，我在这里发帖是为了分享我刚刚在 GitHub 上发布的项目。我将从描述开始，其中一些内容将从 GitHub repo 中复制/粘贴。 矩阵循环单元的概念由更新规则 H_t = H_{t-1} X_{t-1} 和 H_1 = X_1 决定，其中 X 和 H 是 s×n×n 方阵序列。这与传统 RNN 的主要区别在于，没有初始向量通过线性，而是第一个状态是矩阵，导致输出也是矩阵。我提出这个想法的动机基于以下原因：  矩阵乘法是结合的，但不是交换的。结合性意味着我可以使用（包含）并行扫描来计算累积矩阵乘积。缺乏交换性意味着标记的顺序会自动合并到 MRU 中。 当您尝试在传统 RNN 上执行此扫描时，操作数会与输出状态中的元素数量成立方比例，这意味着与计算量相比，保留的信息有限。另一方面，如果状态是矩阵，则作为输出状态中元素的函数的操作数为 (n^2)^(3/2)，其中 n^2 是方阵 n×n 矩阵状态中的元素数量。这里有一篇包含一些相关信息的论文：https://arxiv.org/abs/1709.04057。 当按顺序或与（尚未实施的）Brent-Kung 并行扫描并行处理标记时，网络会随时间线性扩展，而注意力则会随时间二次扩展。  我尝试在不同的分支中使用不同的方法生成矩阵 X。生成 X 并将输出隐藏状态折叠回向量的所有方法都是线性和重塑的任意组合，仅基于我发​​现效果良好的方法。 Transformer 和 MRU-LM 在 shakespeare-char 上的损失与步数 基于玩具数据集 shakespeare-char，这种方法似乎效果很好。如果有人能帮助我在更大的数据集上训练模型并进一步评估它，我将不胜感激。    提交人    /u/IonizedPro   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he8vhw/project_matrix_recurrent_states_a_attention/</guid>
      <pubDate>Sat, 14 Dec 2024 18:19:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2024 年法学硕士论文精选清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he4htl/p_curated_list_of_llm_papers_2024/</link>
      <description><![CDATA[       由    /u/seraschka  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he4htl/p_curated_list_of_llm_papers_2024/</guid>
      <pubDate>Sat, 14 Dec 2024 14:52:26 GMT</pubDate>
    </item>
    <item>
      <title>美国健康保险申请精选语料库 [P] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he14fo/curated_corpus_for_us_health_insurance/</link>
      <description><![CDATA[       由    /u/tpafs  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he14fo/curated_corpus_for_us_health_insurance/</guid>
      <pubDate>Sat, 14 Dec 2024 11:36:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深度学习训练的（非）书面规则是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he07vr/d_what_are_the_unwritten_rules_of_deep_learning/</link>
      <description><![CDATA[免责声明：我首先在 r/learnmachinelearing 中发布了此内容，但该子版块似乎更关注非常基本的问题、课程和招聘，因此如果它不适合在这里发布，请随时将其删除（尽管我认为这也适合作为讨论的子版块）。 我现在有几年构建和训练不同模型架构的经验，我了解大部分基本理论，并能够理解大多数论文。所以我的问题更偏向于方法论方向。虽然我能够成功地为许多应用程序构建模型，但很多时候这在很大程度上是一种猜测。我尝试了不同的东西，看看哪种方法可行。我知道在可解释性方面有很多研究正在进行，但这并不是我想要的方向。相反，我想问大家，你们对训练过程有什么一般性建议，你们采取的一些实际观察、经验法则和方法在论文或理论机器学习课程中没有描述。例如：  你如何分析模型中的梯度。我知道如何在这方面做一些非常基本的图表，但我对你的方法以及你如何从实际角度解读它们感兴趣？ 你如何可视化优化器步骤之间的时间不稳定性，例如由于学习率过大？ 你如何确定合适的正则化？ 在训练运行期间，你的收益递减经验法则是什么？ 你如何调整超参数？我或多或少地目测过它们，过去也使用过 optuna。 您认为在训练过程中有哪些重要的直觉、不成文的规则和陷阱？ 当模型表现不如预期时，您的调试步骤是什么？ 您实际上使用了哪些技巧？有很多小技巧（EMA、模糊的激活函数等）可以带来一些好处，但您实际上使用了什么？ 当您使用 Transformer、CNN、扩散模型等时，您的方法有何不同？ 上面我可能遗漏了一些一般性意见或技巧。  大学课程和在线资源主要教授基础知识或理论基础，这非常重要，但在实践中只是故事的一部分。现实世界的经验也有帮助，但你只能通过反复试验走这么远，可能会错过一些有用的东西。我知道 Karpathy 关于神经网络训练的博客文章，并在寻找这方面的更多资源。 我很高兴在这里看到您对这个广泛话题的回复。    提交人    /u/floriv1999   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he07vr/d_what_are_the_unwritten_rules_of_deep_learning/</guid>
      <pubDate>Sat, 14 Dec 2024 10:29:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 发生了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hdxbru/d_what_happened_at_neurips/</link>
      <description><![CDATA[        提交人    /u/howtorewriteaname   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hdxbru/d_what_happened_at_neurips/</guid>
      <pubDate>Sat, 14 Dec 2024 07:00:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] NVIDIA 的人质：垄断的赛博朋克现实</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hdjklf/d_nvidias_hostages_a_cyberpunk_reality_of/</link>
      <description><![CDATA[在人工智能和专业工作站领域，NVIDIA 的主导地位让人感觉像是令人窒息的垄断。他们细分的产品线扩大了消费级和专业级 GPU 之间的差距，尤其是在 VRAM、性能和价格方面。 人工智能爱好者为配备足够 VRAM 的 GPU 而苦苦挣扎，因为成本高昂。对 CUDA 核心（专有标准）的依赖进一步将开发人员锁定在 NVIDIA 的生态系统中，扼杀了竞争和创新。 NVIDIA 的控制范围不仅限于硬件，因为他们的 CUDA 平台不鼓励采用开放、竞争的解决方案。这助长了一种赛博朋克反乌托邦，企业整合权力，让消费者和开发者几乎没有选择。 为什么科技界仍然同谋？为什么我们不追求替代硬件架构或超越 CUDA 的更广泛的软件兼容性？ AMD 的 ROCm 是一个开始，但需要更积极的开发和政策干预来挑战 NVIDIA 的控制权。 这种情况会持续到什么时候？谁会为最终消费者挺身而出？    提交人    /u/SevenShivas   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hdjklf/d_nvidias_hostages_a_cyberpunk_reality_of/</guid>
      <pubDate>Fri, 13 Dec 2024 19:02:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>