<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 29 May 2024 12:27:18 GMT</lastBuildDate>
    <item>
      <title>[讨论] GPT 是 Generative Pretraining 或 Generative Pretrained Transformers 的缩写？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d3ata7/discussion_gpt_is_short_for_generative/</link>
      <description><![CDATA[大家好。最近我在 Wikipedia 上看到，GPT 是 Generative Pretrained Transformers 的缩写： https://en.wikipedia.org/wiki/Generative_pre-trained_transformer 我也看到其他地方也这么说： http s://medium.com/@a nitakivindyo/what-ar e-generative-pre-trained-transformers-gpts-b37a8ad94400 htt ps://aw s.amazon.com/what-i s/gpt/ 但有些较旧的文章说 GPT 实际上是 Generative Pretraining 的缩写： htt ps://ww w.analyticsvi dhya.com/blog/2022/10/generative-pre-training-gpt-for-natural-lan guage-underst anding/ htt ps://s aturn cloud.io/glos sary/generative-pr etraining/ 我刚刚阅读了 GPT1 论文，它只提到了生成式预训练。  http s://cdn. op e nai.com /resear ch- cov ers/language-unsupervised/language_understanding_paper.pdf 我不知道该如何理解这一切，如果有人能更详细地解释这一点，那就太好了。非常感谢。    提交人    /u/CommunityOpposite645   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d3ata7/discussion_gpt_is_short_for_generative/</guid>
      <pubDate>Wed, 29 May 2024 12:18:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] Friday Oxen.ai 论文俱乐部：从 Claude 3 Sonnet 中提取可解释的特征</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d3aeaq/d_friday_oxenai_paper_club_extracting/</link>
      <description><![CDATA[听听 Hugging Face 联合创始人 Thomas Wolf 称之为“完全基于”的论文，通过 Oxen.ai 首席执行官兼 Plain-Speak-Delving 大师 Greg Schoeninger 的视角进行解读。 注册：https://lu.ma/oxen 太平洋时间周五上午 10:00，东部时间下午 1:00 在 Zoom 上 论文：https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html?s=09%2F/ ？嘿，这个没有 ArXiv 链接吗？ 感谢 Greg、u/FallMindless3563、Scott Howard u/sthoward 和 Oxen 团队与社区分享您的知识，同时提供很酷的工具来在 oxen.ai 上管理数据集。    提交人    /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d3aeaq/d_friday_oxenai_paper_club_extracting/</guid>
      <pubDate>Wed, 29 May 2024 11:56:53 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Prompt Teacher - 免费的教育工具，教授如何编写有效的 LLM 提示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d391p4/project_prompt_teacher_free_educational_tool/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d391p4/project_prompt_teacher_free_educational_tool/</guid>
      <pubDate>Wed, 29 May 2024 10:36:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用大型语言模型进行工具学习：一项调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d37emc/r_tool_learning_with_large_language_models_a/</link>
      <description><![CDATA[      PDF：https://arxiv.org/abs/2405.17935 GitHub：https://github.com/quchangle1/LLM-Tool-Survey 摘要：最近，使用大型语言模型 (LLM) 的工具学习已成为增强 LLM 解决高度复杂问题能力的一种有前途的范例。尽管该领域受到越来越多的关注和快速发展，但现有文献仍然零散且缺乏系统组织，为新手设置了进入门槛。这一差距促使我们对现有的使用 LLM 的工具学习的著作进行全面调查。在本次调查中，我们重点从两个主要方面回顾现有文献 (1) 工具学习为何有益以及 (2) 工具学习如何实施，从而全面了解使用 LLM 的工具学习。我们首先通过从六个具体方面回顾工具集成的好处和工具学习范式的固有好处来探索“为什么”。在“如何”方面，我们根据工具学习工作流程中的四个关键阶段的分类法系统地回顾了文献：任务规划、工具选择、工具调用和响应生成。此外，我们还提供了现有基准和评估方法的详细摘要，并根据它们与不同阶段的相关性对其进行了分类。最后，我们讨论了当前的挑战并概述了未来的潜在方向，旨在激励研究人员和工业开发人员进一步探索这一新兴且充满希望的领域。 https://preview.redd.it/t46d2cxivb3d1.jpg?width=1250&amp;format=pjpg&amp;auto=webp&amp;s=a3d3bd9f285717b6a6f9c9d0015789ec39f9abd9 https://preview.redd.it/rp0gdkkjvb3d1.png?width=830&amp;format=png&amp;auto=webp&amp;s=2e87a52ccf7637783f308fd6b421d8b2fa0cbee0 https://preview.redd.it/fwwyuq3kvb3d1.jpg?width=914&amp;format=pjpg&amp;auto=webp&amp;s=39f080e0db7c611f418b53e99aa274a2d7ad35b7    提交人    /u/Lumpy-Ad-2115   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d37emc/r_tool_learning_with_large_language_models_a/</guid>
      <pubDate>Wed, 29 May 2024 08:41:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据科学家无需数据即可完成任务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d374hh/d_data_scientist_does_the_task_without_data/</link>
      <description><![CDATA[最近我被分配了一个任务，根据用户交互活动构建一个用户购买评分系统。 然而，有趣的是，我没有关于用户与产品交互的数据，所以我调查了许多方的解决方案，并使用我的假设来创建我认为适合构建预测模型的特征。当然，当我将它呈现给经理时，结果非常糟糕。我坐下来和他讨论创建模型时所需的特征定义，让我非常生气的是，他仍然不知道构建评分模型需要什么样的数据。人们将如何处理这种情况？    提交人    /u/unknow_from_vietnam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d374hh/d_data_scientist_does_the_task_without_data/</guid>
      <pubDate>Wed, 29 May 2024 08:21:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于现阶段的法学硕士来说，幻觉不是比安全更重要的研究吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d329nt/d_isnt_hallucination_a_much_more_important_study/</link>
      <description><![CDATA[为什么我觉得 LLM 更强调安全性而不是幻觉？ 在现阶段，确保生成准确的信息不是最优先的吗？ 为什么在我看来并非如此    提交人    /u/xiikjuy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d329nt/d_isnt_hallucination_a_much_more_important_study/</guid>
      <pubDate>Wed, 29 May 2024 03:06:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] KNN 中 k=1</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2xrb8/d_k1_in_knn/</link>
      <description><![CDATA[晚上好，我在平衡的测试集上训练了 knn 算法，然后在不平衡的测试集上对其进行了测试；我得到 k=1 作为准确度方面的最佳参数，并使用交叉验证确认了这一结果。有这个值奇怪吗？    提交人    /u/Nice-Fisherman-1269   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2xrb8/d_k1_in_knn/</guid>
      <pubDate>Tue, 28 May 2024 23:21:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 石油和水？人工智能在科学领域内和跨科学领域的传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2x46v/r_oil_water_diffusion_of_ai_within_and_across/</link>
      <description><![CDATA[在此处阅读论文：https://arxiv.org/abs/2405.15828 本研究通过研究 1985 年至 2022 年人工智能学术参与度的变化，实证研究了 20 个不同科学领域约 8000 万份研究出版物中人工智能 (AI) 日益普及的说法。我们观察到指数增长，所有领域的人工智能参与出版物数量增加了约十三倍 (13x)，这表明从小众到主流发生了巨大转变。此外，我们首次对各个领域内人工智能参与出版物在出版场所的分布情况进行了实证检验，结果显示人工智能在学科内的参与度不断扩大。虽然这种日益扩大的参与表明每个领域都朝着更大程度的学科融合迈进，但日益普及与人工智能参与研究和更传统的学科研究之间的语义紧张有关。通过对数千万个文档嵌入的分析，我们观察到领域内和领域之间的人工智能参与和非人工智能参与研究之间存在复杂的相互作用，这表明日益普及是一种油水现象——人工智能参与的工作正在各个领域蔓延，但与非人工智能参与的工作融合得并不好。    提交人    /u/learning_by_looking   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2x46v/r_oil_water_diffusion_of_ai_within_and_across/</guid>
      <pubDate>Tue, 28 May 2024 22:53:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 室内定位/SLAM 模块，BOM 价格约为 150 美元</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2ww0c/d_indoor_localizationslam_module_with_150_bom/</link>
      <description><![CDATA[向社区提出一个问题。我们正在考虑将一款室内定位/地图软件商业化，该软件的 BOM 约为 100-150 美元（一个基本 CPU 和一个鱼眼摄像头）。我们已经为我们的内部项目构建了它，但如果它有价值，我们想把它带到社区。这对我们来说仍然有点工作量，所以我们想知道它是否有意义。 它不需要基准点，可以在大型开放空间（大型仓库）中工作。 我们将开放所有代码的源代码，以便在需要时无需我们参与即可进行更改。商业用途需要商业许可。 我们还有经济高效的避障模块，我们也可以分享。如果您认为这有价值，请告诉我。    提交人    /u/carubia   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2ww0c/d_indoor_localizationslam_module_with_150_bom/</guid>
      <pubDate>Tue, 28 May 2024 22:43:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] Andrew Dudzik 谈深度学习中的 SOTA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2wc9a/d_andrew_dudzik_on_sota_in_deep_learning/</link>
      <description><![CDATA[Google DeepMind 的 Dudzik 最近表示，Transformers 实际上并不是 sota，而图神经网络才是真正的 sota：Andrew Dudzik - 深度学习数学中的三个问题 - YouTube 当然，前者在许多任务（NER、低资源语言的翻译等）中对 OOD 数据的处理并不那么好。但另一方面，并​​不是所有东西都适合知识图谱结构。只是开放这个讨论。大家同意吗？他们最近有没有读过更多关于图神经网络的有趣论文？    提交人    /u/Objective-Camel-3726   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2wc9a/d_andrew_dudzik_on_sota_in_deep_learning/</guid>
      <pubDate>Tue, 28 May 2024 22:19:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在生产中部署 SetFit 模型的最佳方式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2u14p/d_best_way_to_deploy_setfit_models_in_production/</link>
      <description><![CDATA[正如标题所述，我正在尝试在生产中部署 setfit 模型，并正在寻找一种有效的方法。我尝试使用 huggingface TEI，但不幸的是，它只输出向量，牺牲了分类头。你们有什么建议或我可以尝试的替代方法吗？谢谢！！    提交人    /u/ouzunkumhavuzu   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2u14p/d_best_way_to_deploy_setfit_models_in_production/</guid>
      <pubDate>Tue, 28 May 2024 20:43:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于“你只缓存一次：语言模型的解码器-解码器架构”的问题 - https://arxiv.org/pdf/2405.05254v1</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2ptil/d_question_about_you_only_cache_once/</link>
      <description><![CDATA[      这是我第一次尝试通读一篇论文。但是，我很难理解这一点，我认为你们会知道我的问题的答案，因为如图 1 所示，这种新架构对于 LLM 来说似乎是一件大事。 图 1 据我了解，主要思想是将网络分成两部分。前 L/2 层是自解码器层，可生成全局 KV 缓存。第二个 L/2 层是跨解码器层，重用了生成的全局 KV-Cache。 引用他们论文中关于他们如何节省大量计算和内存的内容（我理解这部分）：  具体来说，因为全局 KV 缓存被重用，而高效的自注意力需要常量缓存，所以缓存的数量为 O(N + CL)，其中 N 是输入长度，C 是常数（例如滑动窗口大小），L 是层数。对于长序列，CL 比 N 小得多，因此大约需要 O(N) 个缓存，即只缓存一次。相比之下，Transformer 解码器在推理过程中必须存储 N × L 个键和值。因此，与 Transformer 解码器相比，YOCO 大约节省了 L 倍的 GPU 缓存内存。  这是我不明白的。在仅解码器网络中，查询、键和值的概念的功能与数据库中的用法有些相似，但侧重于捕获单词之间的关系。在这种网络的每一层中，这些组件有助于细化对文本的理解，在处理从一层移动到下一层时根据新见解调整焦点。 每一层都通过更新查询、键和值来构建前一层，从而细化网络的解释和响应生成。 如果仅解码器网络的各个 KV 缓存的所有信息现在都被压缩到全局 KV 缓存中，我们是否不会丢失有价值的信息并且我们是否应该看到更差的性能？  此外，我们只有一半的层来细化这种解释，因为跨解码器层都重用相同的 KV 缓存。 图 2    提交人    /u/StraightChemistry629   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2ptil/d_question_about_you_only_cache_once/</guid>
      <pubDate>Tue, 28 May 2024 17:58:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] GT 深度估计：LiDAR 与立体深度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2pmr8/d_gt_for_depth_estimation_lidar_vs_stereo_depth/</link>
      <description><![CDATA[为什么大多数深度估计基准（如 nuScenes、KITTI、DDAD 等）都使用来自 LiDAR 传感器的地面真实深度，而不是来自 2 个摄像头的立体深度？ 将摄像头安装在汽车后视镜上会导致基线距离约为 2 米。这将实现更密集的深度测量，距离与 SOTA LiDAR 相似。我不明白为什么不经常使用它 - 还是我错过了什么？    提交人    /u/topsnek69   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2pmr8/d_gt_for_depth_estimation_lidar_vs_stereo_depth/</guid>
      <pubDate>Tue, 28 May 2024 17:50:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 嵌入矩阵和最终的 pre-softmax 矩阵是否应该在 transformer 中共享？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2iurw/d_should_the_embedding_matrix_and_final/</link>
      <description><![CDATA[大家好， 在比较各种 LLM 时，我们可以看到，在采用 softmax 获得预测的 token 概率之前，其中一些 LLM 对 token 嵌入和转换矩阵使用相同的矩阵。我发现这篇 2016 年的论文使用输出嵌入改进语言模型表明这种方法更优越，注意力就是您所需要的论文也引用了它并进行了这种权重共享。GPT2 和 Gemma 等其他模型也是如此。 这让我想知道为什么 LLaMa 模型不进行这种权重共享。就模型容量而言，在那里使用单独的矩阵是否值得？像 Gemma 这样的模型是否必须使用权重共享，因为它们使用了庞大的词汇量？我对这里的权衡很感兴趣，如果有的话，目前对这个主题的共识是什么。    提交人    /u/CloudyCloud256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2iurw/d_should_the_embedding_matrix_and_final/</guid>
      <pubDate>Tue, 28 May 2024 12:58:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>