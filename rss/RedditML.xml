<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 06 Dec 2023 21:12:16 GMT</lastBuildDate>
    <item>
      <title>[P] 用户级别的 LLM API 成本管理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18cd64y/p_llm_apis_cost_management_on_a_userlevel/</link>
      <description><![CDATA[大家好，我感到非常沮丧，因为构建和维护一个系统来单独跟踪每个用户的 LLM API 成本并不容易，所以我知道向每个用户收取多少费用，而不必告诉他们 BYOK（带上您自己的密钥）。 这是否会困扰整个 LLM 开发社区？您如何解决这个问题？ 我们已经开始根据我们的早期尝试制作一款产品来解决这个确切的问题（https:// llmetrics.app），但我们想知道是否有任何好的方法可以解决这个问题，或者这是否是一个普遍的问题？非常感谢任何反馈   由   提交 /u/Much-Whole-8611   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18cd64y/p_llm_apis_cost_management_on_a_userlevel/</guid>
      <pubDate>Wed, 06 Dec 2023 20:20:39 GMT</pubDate>
    </item>
    <item>
      <title>“[项目]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ccv3o/project/</link>
      <description><![CDATA[我正在使用 u-net 架构进行牙科图像牙齿分割。谁能为我提供用于牙齿图像分割的 .h5 文件，该文件可以将臼齿前臼齿和犬齿分为 4 个不同的类别？这对于缓解我的 BTECH 项目来说将是非常有益的一步。提前致谢   由   提交 /u/Many_Rope6054   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ccv3o/project/</guid>
      <pubDate>Wed, 06 Dec 2023 20:07:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是对洗牌的合理还是不合理的使用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18cag7q/d_is_this_a_reasonable_or_unreasonable_use_of/</link>
      <description><![CDATA[我不会分享我对该方法的看法，以防止人们的反应出现偏见。在朋友之间进行讨论，并且有兴趣收集更多意见，并且不想将其引向任何方向。 讨论的核心是是否采用这种方法，因为您正在整理所有患者的数据在 CV 之前，如果训练和测试折叠中的数据可能包含来自同一患者的窗口（尽管彼此不同），是否会引入不合理的偏差/乐观结果？ 用例：评估使用从连续数据窗口中派生的特征来确定主题的状况（二元分类）。 数据：  派生特征的数据是连续的从 20 个不同受试者历时 10 小时收集的数据源。 定义标签的数据与用于进行预测的数据具有相同的采样率。它们是同步收集的。 该功能集由以下部分组成：&gt; 20 个特征。 每个数据窗口都有一个关联的标签。 数据类别是平衡的。  建议的评估方法：随机播放所有患者的数据进行嵌套交叉验证 对人们的意见非常感兴趣！ ✌🏼✌🏼   由   提交/u/ConfusedLayer1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18cag7q/d_is_this_a_reasonable_or_unreasonable_use_of/</guid>
      <pubDate>Wed, 06 Dec 2023 18:24:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将我的 VAE 潜在分布从正态分布切换为分类分布，但我需要一种方法来替换高斯乘法运算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18caf50/d_switching_my_vaes_latent_distribution_from/</link>
      <description><![CDATA[所以我一直在重新实现一个具有循环潜在分布的 VAE。在每个新输入之后，使用编码器输出和当前潜在分布的高斯乘法来更新潜在分布。  该模型没有学习到良好的表示，我知道最近的 Dreamer 模型从连续潜在状态切换到分类潜在状态，这提高了性能，所以我想尝试一下。 但是，对于分类分布，没有等价的高斯乘法。我决定对新旧分布参数进行加权平均，其中权重由分布的逆熵确定（因此它们或多或少根据“不确定性”代理进行加权）。我知道这只是一种启发式的方法，并没有任何可靠的数学推理来支持它。  有谁知道更好的方法来实现这一点，或者有人遇到过类似的情况吗？   由   提交 /u/SmeatSmeamen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18caf50/d_switching_my_vaes_latent_distribution_from/</guid>
      <pubDate>Wed, 06 Dec 2023 18:22:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最佳 AI ML DL DS 路线图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c7u9v/d_best_ai_ml_dl_ds_roadmap/</link>
      <description><![CDATA[嗨！人工智能、机器学习、深度学习和数据科学的最佳完整路线图是什么？ 我找到的一些路线图：- [roadmap.sh] 人工智能和数据科学家路线图  ← 最佳？ - [i.am.ai ] AI 专家路线图 - [github.com] mrdbourke/machine-learning-roadmap - [github.com] luspr/awesome-ml-courses - [rentry.org] 机器学习路线图 我应该选择哪一个？我不是编程初学者（8岁作为爱好，3岁工作），但它与AI无关。   由   提交 /u/Rashimban   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c7u9v/d_best_ai_ml_dl_ds_roadmap/</guid>
      <pubDate>Wed, 06 Dec 2023 16:32:16 GMT</pubDate>
    </item>
    <item>
      <title>[N] Google DeepMind 发布 Gemini 多模态模型击败 GPT-4</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c74e9/n_google_deepmind_releases_gemini_multimodal/</link>
      <description><![CDATA[      Google 刚刚在 AI 中放弃了游戏规则改变者：Gemini！这种强大的人工智能模型涵盖从用于移动设备的 Gemini Nano 到用于数据中心和复杂任务的 Gemini Pro 和 Ultra。它在多模态推理方面表现出色，在 32 个基准测试中的 30 个中击败了 GPT-4。 Gemini Pro 甚至在八个基准测试中的六个中超越了 GPT-3.5。 这里有一个非常好的 Twitter 帖子总结了新版本：https://vxtwitter.com/SaxenaNayan/status/1732422975440470050?s=20 ​ ​ https://preview.redd.it /ybfw5k6e6p4c1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=d178d8b5348ca809b75c22153304111787116ccc   由   提交 /u/Due-Junket-3386   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c74e9/n_google_deepmind_releases_gemini_multimodal/</guid>
      <pubDate>Wed, 06 Dec 2023 16:00:48 GMT</pubDate>
    </item>
    <item>
      <title>[R]谷歌发布Gemini系列前沿机型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c6xio/r_google_releases_the_gemini_family_of_frontier/</link>
      <description><![CDATA[来自 Jeff Dean 的推文：https://twitter。 com/JeffDean/status/1732415515673727286 博客文章：https:// blog.google/technology/ai/google-gemini-ai/ 技术报告：https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf 有什么想法吗？没有太多“肉”在这个公告中！他们肯定担心其他实验室+开源从中学习。   由   提交/u/blabboy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c6xio/r_google_releases_the_gemini_family_of_frontier/</guid>
      <pubDate>Wed, 06 Dec 2023 15:52:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么仅解码器模型用于自回归生成而不是仅编码器模型？如果新标记尚不存在，因果掩码的值是多少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c498u/d_why_are_decoder_only_models_used_for/</link>
      <description><![CDATA[为什么还要费心使用因果掩码，看起来它只是破坏了有用的信息传输？我知道，如果你用它进行训练，你就无法在推理过程中轻松删除它而不降低质量，但为什么不直接训练编码器来猜测此时的下一个标记呢？    由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c498u/d_why_are_decoder_only_models_used_for/</guid>
      <pubDate>Wed, 06 Dec 2023 13:43:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 神奇的收获以及在哪里找到它们：关于任何预训练模型之间通用知识转移的存在和前景</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c1tve/r_fantastic_gains_and_where_to_find_them_on_the/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2310.17653 OpenReview：https:// /openreview.net/forum?id=m50eKHCttz 摘要：  训练深度网络需要各种设计决策，例如他们的架构、数据增强或优化。在这项工作中，我们发现这些训练变化导致网络从数据中学习独特的特征集。使用由在 ImageNet 等规范数据集上训练的数千个模型组成的公共模型库，我们观察到，对于预训练模型的任意配对，一个模型提取了另一个模型中不可用的重要数据上下文，而与整体性能无关。给定预训练模型的任意配对并且没有外部排名（例如由于数据隐私而单独的测试集），我们调查是否可以将这种“互补”转移到模型中。知识从一个模型转移到另一个模型而不降低性能——这项任务变得特别困难，因为额外的知识可以包含在更强、同等或更弱的模型中。然而，在与预训练模型配对无关的场景中促进稳健的迁移将解锁来自任何模型存储库的辅助增益和知识融合，而不受模型和问题细节的限制——包括来自较弱、性能较低的模型。因此，这项工作对这种通用知识转移的可行性进行了初步、深入的探索。在大规模实验中，我们首先揭示了标准知识蒸馏技术的缺点，然后通过数据分区提出了更通用的扩展，以便在几乎所有预训练模型之间成功传输，我们证明这也可以在无监督的情况下完成。最后，我们评估了基本模型属性的可扩展性和对成功的模型无关知识转移的影响。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c1tve/r_fantastic_gains_and_where_to_find_them_on_the/</guid>
      <pubDate>Wed, 06 Dec 2023 11:19:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大多数开源人工智能都发生在美国境外？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18by3wo/d_why_is_most_open_source_ai_happening_outside/</link>
      <description><![CDATA[我不认为这太双曲线。美国有 Meta，除此之外几乎没有什么，特别是与外部的相比。 我并不是说要在美国扣篮，我真的只是感到震惊。 &lt; strong&gt;中国：Yuan、Qwen、DeepSeek、Yi、XVERSE、Aquila、RWKV，都是当今顶级的法学硕士。 一打很棒的（顶级）多模式。顶级嵌入模型。 英国：稳定性 法国： Mistral 芬兰（？）： Lumi Poro 阿联酋： Falcon 俄罗斯：康定斯基 &lt; p&gt;美国：Meta 有 Llama 和其他一些好东西，Salesforce 有一些东西，“OpenAI”等。  是监管环境吗？是投资问题吗？是GPU短缺吗？大型科技公司是否挖走了并锁定了所有美国人才？ 有人有任何线索吗？ 编辑： 哇，我走出了大门。我的要求越来越合理。这里提到的所有模型都是经过预训练的模型。是的，美国社区可以进行微调，但这没有表达我的观点。昂贵的 OSS 工作正在美国境外进行。如果你说“那不是 OSS”，好吧，它仍然主要发生在美国境外。再说一遍，不是在美国扣篮，只是问一个问题，并希望看到更多的美国公司出现在 OSS 贡献者名单上。   由   提交 /u/BayesMind   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18by3wo/d_why_is_most_open_source_ai_happening_outside/</guid>
      <pubDate>Wed, 06 Dec 2023 06:45:18 GMT</pubDate>
    </item>
    <item>
      <title>Apple 发布“MLX” - Apple Silicon 的 ML 框架 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bwe19/apple_releases_mlx_ml_framework_for_apple_silicon/</link>
      <description><![CDATA[Apple 的 ML 团队刚刚在 GitHub 上发布了“MLX”。他们针对 Apple Silicon 的 ML 框架。 https://github.com/ml-explore/mlx CUDA 的现实替代方案？ MPS 已经非常高效...如果我们看到采用，这可能会变得有趣。 ​   由   提交 /u/LoadingALIAS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bwe19/apple_releases_mlx_ml_framework_for_apple_silicon/</guid>
      <pubDate>Wed, 06 Dec 2023 05:00:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大海捞针实验：Assistant API RAG 以 4% 的成本击败 GPT 4-Turbo & Llama Index</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bivxa/d_needle_in_a_haystack_experiment_assistants_api/</link>
      <description><![CDATA[      进行了一项实验，比较 Open AI 助手 API 的 RAG、GPT-4 Turbo（具有上下文窗口填充）和 Llama Index with GPT4 之间的信息检索性能。&lt; /p&gt; 我最近向 CopilotKit 添加了一个新的面向文档 React hook，专门制作来容纳（可能是长格式）文档并希望获得最佳性能。 得到了相当惊人的结果：助手的 API 在性能上大大击败了 Llama 索引，并且比使用 GPT-4 Turbo 填充上下文窗口便宜 25 倍。 ​ 准确度表现 ​ 成本 使用人工智能进行构建时的重大收获。几乎没有人应该使用上下文窗口填充，而且 Llama Index 在 RAG 性能方面还有很多工作要做。 无论 OpenAI 在 RAG 的底层使用什么，都具有出色的性能。 完整文章： https://ai88.substack.com/p/rag-vs-context-window- in-gpt4-准确度-成本   由   提交/u/kindly_formation71   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bivxa/d_needle_in_a_haystack_experiment_assistants_api/</guid>
      <pubDate>Tue, 05 Dec 2023 18:38:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你不需要矢量数据库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bhlsj/d_you_do_not_need_a_vector_database/</link>
      <description><![CDATA[RAG 的文档检索问题基本上是信息检索的情况，并且有更简单的解决方案。矢量嵌入仍然有用，但它们应该在 IR 管道的后期使用，而不是作为第一阶段检索，因为第一阶段检索有更简单、性能更高的解决方案。 此处的博客文章：http://about.xethub.com/blog/you-dont-need-a-vector-数据库 此处的笔记本和数据：https://github.com/xetdata/RagIRBench/   由   提交/u/yu Chenglow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bhlsj/d_you_do_not_need_a_vector_database/</guid>
      <pubDate>Tue, 05 Dec 2023 17:44:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何应对对你的论文是人工智能生成的错误指控？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ben3c/d_how_to_deal_with_false_accusations_of_your/</link>
      <description><![CDATA[读到我从 ICLR-2024 论文中获得的主观评论的质量有点令人沮丧。其中两个人相当不错，但另外两个人指责我的论文是一个“笑话”。和人工智能生成的。看到一个所谓的顶级会议允许公开发布此类不良评论，令人感到悲伤。现在，除非区域主席介入，否则外行人会对我的研究产生极大的偏见。 编辑：支持性评论让我觉得它不仅需要是区域主席，而且还需要是两个体面的审稿人之一，或任何有能力将多学科工作情境化的有成就的研究人员。我相信高智商的人也是无私的并且不受群体思维的影响。    由   提交 /u/No-Sun-5534   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ben3c/d_how_to_deal_with_false_accusations_of_your/</guid>
      <pubDate>Tue, 05 Dec 2023 15:38:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>