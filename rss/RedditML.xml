<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sun, 09 Jun 2024 18:17:49 GMT</lastBuildDate>
    <item>
      <title>[D] 适合 P100 的最佳 AI 模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dbzvdk/d_best_ai_models_for_the_p100/</link>
      <description><![CDATA[P100 的最佳 AI 模型是什么？ 所以，我一直想将一些虚拟机组合在一起，用于测试不同的 AI 模型，最后我终于找到了一个借口，买了一台 P100，四处看看。 我对 LLM 和 Stable Diffusion 很感兴趣，但我很想听听大家发现的使用该卡更好的东西是什么？ 我最近了解到 Text2Video-Zero，它似乎降低了内存要求，可能使它并非无法使用。但如果我仅限于 LLM 或一些非常基本的图像生成，我很乐意研究一些东西。 您尝试过什么？哪些效果很好，哪些速度很慢但值得测试？也不确定它是否有帮助，但让我们假装 RAM 和 CPU 线程不是问题，而 GPU 是唯一的瓶颈（确实是哈哈），如果这对任何模型特别有益的话。 非常感谢您的帮助或意见；我已经做了很多观察，但没有什么比听取那些有第一手经验的人的意见更好。    提交人    /u/lightmystic   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dbzvdk/d_best_ai_models_for_the_p100/</guid>
      <pubDate>Sun, 09 Jun 2024 18:00:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] - 关于 MLOps 的西班牙语视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dby2ab/r_spanish_videos_about_mlops/</link>
      <description><![CDATA[一些关于西班牙语使用者的 MLOps 的有趣视频，我希望该帖子能受到欢迎并且没有违反任何规则 :) ______ 还有一些关于西班牙语使用者的 MLOps 的有趣视频，希望这篇帖子很好看并且不符合标准 :) 网络研讨会 (AI Tech Talk)。更高的 MLOps：提供生产服务 https://www.youtube.com/watch?v=727WIwTTNn8&amp;t=11s 网络研讨会 (AI Tech Talk)。更高的 MLFLow：使用 Databricks 生产 IA https://www.youtube.com/watch?v=DG9VP_Or1Ic 西班牙 AI 网络研讨会如何解决机器学习中的不平衡问题？ https://www.youtube.com/watch?v=DtgKFUpzZHo 加入 subreddit MLOps_Spain！ r/Mlops_Spain   由    /u/nettrotten  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dby2ab/r_spanish_videos_about_mlops/</guid>
      <pubDate>Sun, 09 Jun 2024 16:42:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些公司在 OR（欧洲）设有研究职位？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dbvp62/d_which_companies_have_research_positions_in_or/</link>
      <description><![CDATA[我正在攻读应用数学博士学位，主要研究图论算法、线性规划、博弈论……运筹学等内容。我更愿意在攻读博士学位后从事工业研究工作，因为这些职位往往影响更大，薪水也更高。哪些大公司有该领域的研究科学家职位（可以实际进行研究并发表文章和参加会议）？我知道 FAANG 有很多研究团队，但他们似乎大多只是在做 AI 的事情。我更喜欢运筹学，因为我喜欢数学上更精确的算法和精确可证明的保证，以及一般的图表。我想也应该有运筹学团队，因为这个数学分支的重点是解决与工业应用相关的问题。也欢迎将我重定向到其他 reddit 子版块。    提交人    /u/Cloud7889   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dbvp62/d_which_companies_have_research_positions_in_or/</guid>
      <pubDate>Sun, 09 Jun 2024 14:59:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 微型时间混合器 (TTM)：IBM 强大的零样本预测模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dbt398/p_tiny_time_mixersttms_powerful_zeroshot/</link>
      <description><![CDATA[IBM 推出的全新开源基础时间序列模型： https://aihorizo​​nforecast.substack.com/p/tiny-time-mixersttms-powerful-zerofew?-reml--    提交人    /u/apaxapax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dbt398/p_tiny_time_mixersttms_powerful_zeroshot/</guid>
      <pubDate>Sun, 09 Jun 2024 12:55:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 训练 llama 3 8B 需要多少 VRAM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dbp2sz/p_how_much_vram_i_need_to_train_llama_3_8b/</link>
      <description><![CDATA[您好， 我猜这是一个非常菜鸟的问题，但是找不到答案。 我想使用 llama 3 8b 并使用我的自定义数据增强模型。 我想在我的 Nvidia GPU 上进行本地训练和运行模型。 我现在没有 GPU，只有 mac m2 pro 16Gb，需要知道要购买什么。 我想知道，VRAM 要求是什么？12 GB 可以吗，还是需要 16 GB 的 gpu？或者唯一的方法是 24 GB 4090 之类的东西？    提交人    /u/webdunesurfer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dbp2sz/p_how_much_vram_i_need_to_train_llama_3_8b/</guid>
      <pubDate>Sun, 09 Jun 2024 08:33:20 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 使用上下文学习可以保证 LLM 输出可靠吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dbldwk/discussion_can_we_make_llm_outputs_reliable_when/</link>
      <description><![CDATA[现在，我并不是 LLM 的忠实粉丝，但我发现它们对于诸如通过上下文学习从长文本中提取具有最少标记数据的信息等问题非常有用。但是，结果有时可能不可靠，而且很难判断什么时候会发生这种情况。希望了解人们在使用 LLM 时如何确保输出可靠。 PS - 我不是指风险缓解（对于无效输出/有害输出，应使用护栏）。我说的是结果的准确性（提取的信息是有效结果，但可能准确也可能不准确）。    提交人    /u/Either_Pea7803   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dbldwk/discussion_can_we_make_llm_outputs_reliable_when/</guid>
      <pubDate>Sun, 09 Jun 2024 04:29:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 可扩展的无 MatMul 语言建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dbjcbh/r_scalable_matmulfree_language_modeling/</link>
      <description><![CDATA[  由    /u/topcodemangler  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dbjcbh/r_scalable_matmulfree_language_modeling/</guid>
      <pubDate>Sun, 09 Jun 2024 02:33:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与法学硕士对输入复述的敏感性相关的文献</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dbg07w/d_literature_related_to_senstivity_of_llms_to/</link>
      <description><![CDATA[我正在对 Llama 3 8B 模型进行一些分析，我观察到模型输出有时对输入问题的改写很敏感。我想阅读一些文献以了解有关此影响的更多细节。有人可以指出文献中一些讨论 LLM 对输入改写的敏感性的论文吗？ 谢谢！    提交人    /u/Tall_Sun_3096   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dbg07w/d_literature_related_to_senstivity_of_llms_to/</guid>
      <pubDate>Sat, 08 Jun 2024 23:37:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对论文《使用稀疏变换器生成长序列》中一些令人困惑/奇怪的元素的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1db7zkh/d_thoughts_on_some_confusingweird_elements_in_the/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1db7zkh/d_thoughts_on_some_confusingweird_elements_in_the/</guid>
      <pubDate>Sat, 08 Jun 2024 17:24:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 创建一本书来帮助年轻的研究人员解决开展独立研究的痛点。需要你的帮助！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1db6kxh/p_creating_a_book_to_help_young_researchers/</link>
      <description><![CDATA[大家好， 我正在考虑写一本书，其中包含与机器学习领域一些年轻领导者的简短对话和讨论，以了解他们的经验并确定他们刚起步时的一些痛点。我认为这样的资源可以为年轻的早期职业独立研究人员提供支持，他们试图在没有适当导师或指导的情况下从第一原则开始做事。本书的目的是减轻进行机器学习研究时的一些不知所措的感觉，因为有大量的活动部件，同时也为年轻研究人员提供支持。 我对社区的问题是 (a) 我应该尝试采访谁？ (b) 我可以问他们哪些问题可以帮助早期职业研究人员 (c) 您认为这可能是一个有价值的资源 (d) 书籍的格式不是正确的吗？ 我考虑将其制作成一本免费的电子书，在 PH 上发布，并为那些想要它的人提供一些实体副本。    提交人    /u/Studyr3ddit   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1db6kxh/p_creating_a_book_to_help_young_researchers/</guid>
      <pubDate>Sat, 08 Jun 2024 16:19:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 CycleGAN 和 AnimateDiff 的 Song-to-Prompt 嵌入实现音频反应音乐可视化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1db5hpg/p_audio_reactive_music_visualization_with/</link>
      <description><![CDATA[视频在此：https://www.youtube.com/watch?v=ifZYFClM9aw 该项目的目标是创建一个仅以歌曲本身为条件的音乐可视化器。为此，我训练了一个模型，将音频嵌入（由 https://huggingface.co/mtg-upf/discogs-maest-5s-pw-129e 提供）映射到 Stable Diffusion 1.5 输入空间中的提示嵌入。 为了简化这项任务，我首先训练了一个去噪自动编码器（基于 Transformer），以便可以从单个 128 维向量生成整个提示标记嵌入序列。此步骤的训练数据由 ChatGPT（连同流派标签）生成，提示要求它为音乐可视化器生成图像生成提示。 然后，我训练了一个 CycleGAN 模型，将音频嵌入映射到 128 维提示嵌入（并返回）。我使用了与上一步相同的训练数据。鉴别器接收流派标签作为输入，从而引导生成器在其生成的提示嵌入中考虑流派。 最后，我使用 SD 1.5 和 AnimateDiff 生成音乐可视化，分辨率为 768x512，FPS 为 15，以 CycleGAN 提示嵌入为条件。然后，我使用 Real-ESRGAN 将其放大 4 倍，并使用 RIFE 将帧插值 4 倍。 我对当今开源 ML 的状态以及像这样将模型连接在一起的能力感到非常兴奋。尤其是使用 AnimateDiff 时，感觉我到目前为止只是勉强触及了表面。 如果有兴趣，我很乐意分享更多细节。    提交人    /u/ImmanentAI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1db5hpg/p_audio_reactive_music_visualization_with/</guid>
      <pubDate>Sat, 08 Jun 2024 15:29:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 硬件迷 - 你会用 Blackwell 做什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1db2j0j/d_hardware_nerds_what_would_you_do_with_blackwell/</link>
      <description><![CDATA[我热爱硬件。我的第一台“大机器”是 CDC Cyber​​ 174C，然后是 Cray XMP。那是一个不同的时代。问题和数据都不同。现在我全身心投入机器学习，尽管我确实喜欢法学硕士，但我主要在不同的领域（时间序列）工作，处理 PB 级数据。 鉴于 NVidia 的一系列令人惊叹的高端硬件、现在可用的东西以及最新最昂贵的东西像这样，我的问题是，你会用它做什么？在这个规模下，你能解决什么你现在无法解决的问题？    提交人    /u/Simusid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1db2j0j/d_hardware_nerds_what_would_you_do_with_blackwell/</guid>
      <pubDate>Sat, 08 Jun 2024 13:04:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 一种新的对齐技术：通过短路提高对齐和稳健性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1db1gg6/r_a_new_alignment_technique_improving_alignment/</link>
      <description><![CDATA[这个想法似乎是识别与概念相关的内部状态并强制 EOS 状态。它似乎与神经热图和 Anthropic 的类似研究有关：https://www.anthropic.com/news/mapping-mind-language-model Arxiv 链接：https://arxiv.org/pdf/2406.04313    提交人    /u/ReasonablyBadass   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1db1gg6/r_a_new_alignment_technique_improving_alignment/</guid>
      <pubDate>Sat, 08 Jun 2024 12:06:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用 Tinder 的方式标记数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dax94f/p_labeling_data_the_tinder_way/</link>
      <description><![CDATA[我当时正在研究一种情绪分析模型，该模型需要带有适当标签的数据集。我没有采用无聊的方式，而是创建了一个 Web 服务器，将所有数据集保存在 SQL 中，并创建了一个类似 Tinder 的界面来查看数据并将其归类为 positive、negative 或 neutral。 对我的项目有什么看法？您会使用这个来标记数据吗？ 项目链接：tinder-for-reviews :p    提交人    /u/ResetWasTaken   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dax94f/p_labeling_data_the_tinder_way/</guid>
      <pubDate>Sat, 08 Jun 2024 07:21:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>