<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 30 Oct 2024 21:15:47 GMT</lastBuildDate>
    <item>
      <title>[P] PyTorch 量化模型参数以便在边缘设备上部署</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfwky4/p_pytorch_quantization_of_model_parameters_for/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfwky4/p_pytorch_quantization_of_model_parameters_for/</guid>
      <pubDate>Wed, 30 Oct 2024 20:34:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我是一名 ML/编程教育者 - 我作为 codesmith 的首席执行官受邀参加柏林全球对话（技术/人工智能内部会议） - 看看他们在闭门会议上说了什么 - AMA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfv37y/d_im_an_mlprogramming_educator_i_was_invited_as/</link>
      <description><![CDATA[最近，我有幸参加了柏林全球对话，该论坛与达沃斯论坛相似，但更侧重于技术和人工智能。参会人员阵容令人印象深刻：ARM 创始人 Hermann Hauser、OpenAI 和 ASML 高管，以及新兴初创企业的创始人，他们正在解决从量子机器学习到供应链优化等所有问题。甚至连马克龙总统和德国副总理这样的领导人也到场，探讨影响我们所有人的关键技术问题。 作为 Codesmith（一家拥有数据科学和机器学习研究小组的小型独立技术学校（去年我们为 TensorFlow 做出了贡献））的首席执行官，我受邀宣布我们的最新努力：Codesmith 的人工智能和ML 技术领导力计划。 我在 r/technology 上的 AMA 上分享了这一经历，并进行了精彩的对话 - 但有关 ML/AI 的问题深度与我希望探索的并不完全匹配。我在这里与版主进行了交谈，并感谢他们支持这次 AMA。 证明：https://imgur.com/a/bYkUiE7 我真正的热情继承自我的父母，他们都是教育工作者，是教学和让更广泛的受众更容易接触 ML。我目前正在为 Frontend Masters 开发一个 AI/ML 研讨会，我想听听那些在 ML 领域摸索的人的意见。您在这个领域面临的最大挑战是什么？ 我从这次活动中得出的几点结论：  由于物理限制，芯片制造商正在转向新架构，而不是进一步小型化。高带宽内存 (HBM) 是未来路线图的重点。 欧洲专注于寻找“技术冠军”，但其重点明显放在核心行业而非消费者互联网上 — 比如 ASML 和 ARM。 量子机器学习发展势头强劲，并获得政府支持，尤其是在气候预报等应用方面（例如德国的 Klim-QML 计划）。虽然前景光明，但这些努力仍处于原型阶段。 坦率地说，也有很多空谈，没有太多实质内容。甚至 OpenAI 的高管也表明需要更多具有深厚技术见解的领导者。  期待在 AMA 中更深入地探讨这些问题以及 ML/AI 中更广泛的挑战！    提交人    /u/WillSen   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfv37y/d_im_an_mlprogramming_educator_i_was_invited_as/</guid>
      <pubDate>Wed, 30 Oct 2024 19:31:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] CNN 模型是否有一个优先处理的数据分布？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfuxat/d_is_there_a_preferred_data_distribution_for_cnn/</link>
      <description><![CDATA[大家好， 您是否知道任何分析基于 CNN 的模型相对于训练数据分布的性能的作品？也就是说，某些分布是否比其他分布更容易让模型学习其任务？ 例如，假设我正在训练一个模型对图像进行对象检测。我发现白天图像比夜间图像性能更好（数据量相同）。我想知道我是否可以用某种分析方式解释这一点。 谢谢！    提交人    /u/hilabar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfuxat/d_is_there_a_preferred_data_distribution_for_cnn/</guid>
      <pubDate>Wed, 30 Oct 2024 19:24:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 本地基于 LLaMA 的 LLM 技术文献搜索 | 救命！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gftg6l/d_local_llama_based_llm_for_technical_document/</link>
      <description><![CDATA[我想制作一个可以搜索大约 60k 个技术文档（每个大约 50000 个字符）并从语义上检索信息的 LLM。我设想的最终模型将了解这些技术文档，我可以提示模型为我找到与它已经知道的信息相似或完全相同的信息。  我最初的方法是使用这些文档对 LLM 进行微调，然后查询它。但经过研究，我发现它非常耗费资源，并且模型经常产生很多幻觉。 我最近遇到了 RAG 和 Sematic RAG，目前正在阅读有关它的信息。它能适用于我的用例吗？或者您可以建议其他什么？我认为 RAG 的一个问题是，假设我问模型一个模糊的问题，向量数据库返回前 k 个最近邻向量，然后我将其与原始提示一起传递给我的 LLM。如果 Top K Nearest Neighbors 中的信息不完整，或者 LLM 的上下文窗口不够大，该怎么办？ 另一个问题是，使用 RAG 进行 LLM 推理不会因为输入 token 数量较大而耗费更多资源。  你们能对其中的任何内容发表评论吗？ PS：我知道这是一个大问题。我对 ML 和 NLP 有点陌生，正在学习。另外抱歉我的英语不好，我不是母语人士。    提交人    /u/WhyHimanshuGarg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gftg6l/d_local_llama_based_llm_for_technical_document/</guid>
      <pubDate>Wed, 30 Oct 2024 18:22:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我们针对 AI 评估器尝试了不同的训练目标，结果如下：</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gft4t2/r_our_results_experimenting_with_different/</link>
      <description><![CDATA[嘿 r/MachineLearning！ 大量关于 LLM-as-a-judge 的研究已经发表，因为它正在成为一种流行的廉价 + 快速评估方法。 最近发表了一篇非常酷的论文，来自 Salesforce AI 研究团队；tldr：他们发现像 DPO 和 RPO 这样的偏好优化技术可以比单独的监督微调 (SFT) 作为 LLM-as-a-judge 模型的训练目标产生更好的结果。我们想测试这个假设，因为目前尚不清楚哪个训练目标对于对齐评估模型效果最好。 我们的实验 我们使用 SFT 训练了 Llama-3.1-70B-Instruct，并将其与核心基准上的基础 Llama-3.1-70B-Instruct 进行了比较，以了解 SFT 单独表现如何。 我们还使用两个训练数据集训练了 Llama-3.1-8B-Instruct 模型  纯 SFT DPO RPO（复合损失目标结合了 SFT 和 DPO）  并将它们的表现与四个核心基准上的基础模型进行了比较。 以下是我们的主要发现摘要： https://preview.redd.it/755s8f3rnjxd1.png?width=1423&amp;format=png&amp;auto=webp&amp;s=e7841d170d27629b5f347dc64449250df6a12614  DPO 在 PreferenceCollection 上表现最佳，准确率为 98.89% RPO 在 RewardBench 上表现最佳，准确率为 81.96% RPO在 UltraFeedback（无 CoT）上，RPO 的表现优于 SFT 和 DPO，得分为 0.57 与 SFT（0.43）和 DPO（0.43）相比，RPO 在评估分数上实现了最高的平均 Pearson 相关性（0.49）  https://preview.redd.it/ic9fjvlsojxd1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=46b225f6750f6be97f0abca558b020dcbcd13963  SFT 在分布内任务中表现出改进，而在分布外任务中质量下降，在总体指标上表现不及基础 Llama-70B  如果您需要详细信息，请参阅我们的博客文章，其中包含有关我们认为此方法有效的原因的额外信息。我们正在努力扩大规模，看看现在能将这件事推向多远 :) 向大家开放问题  这种趋势会适用于更大的模型吗？ 什么样的数据对于培训 LLM-as-a-judge 特别有用？     提交人    /u/fortunemaple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gft4t2/r_our_results_experimenting_with_different/</guid>
      <pubDate>Wed, 30 Oct 2024 18:09:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何管理你的（已读和待读）研究论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfsxcg/d_how_do_you_manage_your_read_and_toread_research/</link>
      <description><![CDATA[我对研究领域还比较陌生，过去一年来。我可能已经阅读了 100 多篇研究论文，但我觉得我没有记住很多信息，而且我忘记了很多论文。我很好奇在这个行业工作更久的人用什么来组织。 我试过 Zotero，但我并不是很喜欢它    提交人    /u/Karan1213   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfsxcg/d_how_do_you_manage_your_read_and_toread_research/</guid>
      <pubDate>Wed, 30 Oct 2024 18:01:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] Torchtune - 如何微调自定义模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfpab4/r_torchtune_how_to_finetune_custom_models/</link>
      <description><![CDATA[我想知道如何开始使用 torchtune lora 微调我的自定义模型。有人有任何文档或建议吗？    提交人    /u/Cool-Economy3492   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfpab4/r_torchtune_how_to_finetune_custom_models/</guid>
      <pubDate>Wed, 30 Oct 2024 15:29:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 黎曼生成模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfnqkf/r_riemannian_generative_models/</link>
      <description><![CDATA[大家好， 我目前对探索在黎曼流形上定义的生成模型很感兴趣。虽然这个想法在理论上很有吸引力，但我很难理解这种方法背后的实际动机，以及最近是否有任何有用/大规模的模型基于它而开发出来。 更准确地说，我正在看以下一组论文。 将扩散模型推广到黎曼设置： 黎曼扩散模型，基于黎曼分数的生成建模 扩展这些模型： 扩展黎曼扩散模型 我不明白实验结果到底有多大的影响，以及这些模型有什么意义无论是在行业还是在研究界。  如果有人对我的询问有任何想法，我很乐意在这里开始讨论。 我将非常感谢您的见解！ 感谢您的帮助    提交人    /u/LostSleepyDreamer   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfnqkf/r_riemannian_generative_models/</guid>
      <pubDate>Wed, 30 Oct 2024 14:23:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] INRIA（法国）是本科生进行机器学习研究实习的好地方吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfneal/d_is_inria_france_a_good_place_for_ug_to_do_ml/</link>
      <description><![CDATA[我是一名从事 MAB/在线算法相关研究的学生，我发现在美国从事这项工作的人真的很少。但是，我发现在法国国家信息和自动化研究所 (INRIA) 有很多研究人员在做这项工作，如果你不知道的话，法国的那个。有人熟悉这个机构吗？作为来自非欧盟国家的本科生，如果我的目标是获得推荐信并发表论文，我可以在暑假期间自愿偏向这里实习吗？    提交人    /u/petrichorinforest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfneal/d_is_inria_france_a_good_place_for_ug_to_do_ml/</guid>
      <pubDate>Wed, 30 Oct 2024 14:08:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 短文本的分类方法，有多类？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfmp5f/d_classification_approaches_for_short_text_many/</link>
      <description><![CDATA[嗨 - 我正在处理一个问题，我可能有数千个短文本片段（每个片段 2-4 句），并且需要评估每个句子与大约 200 个类别的一致程度（也就是说，一段文本可能“最适合”归入一个类别，但也有可能其他几个类别是“合理的”。标记大量文本可能是一项艰巨的任务，所以我对少样本方法特别感兴趣。（或者甚至可能是引导方法 - 不是统计技术，而是概念 - 我们开发一个快速而粗糙的分类模型，并使用它来帮助评估者更快地完成另一批更大规模的标记。这显然在偏见等方面有潜在的缺点，但可能有） 我的背景主要是传统/贝叶斯统计（想想线性模型和因子分析），所以我对完成此类任务的好方法。进行此分析的地方不会有任何花哨的 LLM，也无法访问基于互联网的平台（Huggingface、OpenAI 等）。没有 GPU，因此可能需要的任何微调都必须考虑到这一点。显而易见的（对我这个非 NLP 人员来说）起点似乎是带有普通分类器的 BERT。但是 BERT 有很多变体，还有类似的模型（通用句子编码器？）……我不确定哪些更适合短文本。我知道 huggingface 排行榜，我已经看过了，但我并不清楚哪些最适合短文本分类。 因此，如果有人对可能的方法有建议，我将不胜感激。    提交人    /u/malenkydroog   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfmp5f/d_classification_approaches_for_short_text_many/</guid>
      <pubDate>Wed, 30 Oct 2024 13:36:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] COLING 2025 结果/反驳</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfjtnu/d_coling_2025_results_rebuttals/</link>
      <description><![CDATA[我先来。 健全性：3,3,4 总体：2,2,3 🥺    提交人    /u/monkeyofscience   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfjtnu/d_coling_2025_results_rebuttals/</guid>
      <pubDate>Wed, 30 Oct 2024 11:01:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这里有人从事医疗保健工作吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfjngd/d_does_anyone_here_work_in_healthcare/</link>
      <description><![CDATA[我对世界各地的人们在这个工作领域中与数据相关的酷事感到好奇    提交人    /u/Intelligent-Cap-4022   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfjngd/d_does_anyone_here_work_in_healthcare/</guid>
      <pubDate>Wed, 30 Oct 2024 10:50:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何为新的研究项目构建代码库和工作流程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gffm46/d_how_do_you_structure_your_codebase_and_workflow/</link>
      <description><![CDATA[假设您对所从事领域中的问题的解决方案有了新想法。您如何从头开始实施这个想法？ 您为项目构建的代码库的一般结构是什么？ 您如何迭代地训练和测试您的解决方案，直到您得到可以撰写论文发表的最终解决方案？ 您是否遵循任何设计秘诀？您从哪里学到的？    提交人    /u/HopeIsGold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gffm46/d_how_do_you_structure_your_codebase_and_workflow/</guid>
      <pubDate>Wed, 30 Oct 2024 05:43:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语音分离管道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfclyv/d_voices_separation_pipeline/</link>
      <description><![CDATA[假设我有来自卡拉 OK 的音频，其中 1. 音乐 2. 几个歌声（A、B、C） 3. 随机噪音 假设我确切知道磁带上有多少个主要来源，并且我想要 1. 清除噪音 2. 从磁带中提取声音 B 并返回带有音乐和 A 和 B 人声的音频。 我有几个问题，不胜感激任何帮助。  是否有任何模型可以帮助我进行这种分离（预先训练 / 不需要训练）？ 如果没有，我对可能的解决方案管道有一些想法，不胜感激任何评论：2.1. 将器乐与其他一切分开（我可以使用什么模型来做到这一点？）2.2. 清除没有音乐的音频中的噪音（我可以使用什么模型来做到这一点？）2.3.分离声音（怎么做？）并删除我不需要的波形。2.4. 将我需要的所有东西放回一起。     提交人    /u/m4k2ch8   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfclyv/d_voices_separation_pipeline/</guid>
      <pubDate>Wed, 30 Oct 2024 02:40:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 27 Oct 2024 02:15:12 GMT</pubDate>
    </item>
    </channel>
</rss>