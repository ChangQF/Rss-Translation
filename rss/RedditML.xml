<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 15 Jan 2024 15:14:21 GMT</lastBuildDate>
    <item>
      <title>[D] 扩散模型的潜在分布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19792fl/d_latent_distributions_of_diffusion_model/</link>
      <description><![CDATA[扩散模型中的潜在分布是否被视为高斯分布 如果是，为什么？如果不是，为什么他们在分析计算 KL 散度时将其视为高斯分布？   由   提交/u/sushilkhadakaanon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19792fl/d_latent_distributions_of_diffusion_model/</guid>
      <pubDate>Mon, 15 Jan 2024 13:45:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将 PGVector 的 2048 维减少到 2000 维</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19785i7/p_reducing_2048_dimensions_to_2000_dimensions_for/</link>
      <description><![CDATA[ML 的朋友们好， 我正在开发一个使用 PGVector 进行高效相似性搜索的项目，我使用特征向量我从 EfficientNet B5 获得，输出为 2048d。问题是我需要根据向量对表进行索引，否则，会出现典型的数据库硬件问题（RAM 不足）。然而，PGVector 提供的方法有一个限制，向量最多可以是 2000d。我发现的一种解决方案是PCA，但我有相当多的数据，所以在测试之前，我想得到一些意见和建议。这里有人尝试过 PCA 进行降维以进行相似性搜索，主要是针对 L2 和余弦，如果是这样，结果如何？   由   提交 /u/TutubanaS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19785i7/p_reducing_2048_dimensions_to_2000_dimensions_for/</guid>
      <pubDate>Mon, 15 Jan 2024 12:59:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研讨会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19776ck/d_workshops/</link>
      <description><![CDATA[ 是否允许在同一会议上提交多个研讨会？差异化会议怎么样？我有一些与我的论文非常吻合的内容，但他的论文在其他地方没有提到。 此外，作为本科生，提交研讨会以获得评论并扩展是一个好的做法吗？鉴于我没有顾问，我的工作如何？ 如果我认为在接受研讨会后我的工作无法扩展为会议论文，我应该这样做吗？停止还是继续？    由   提交 /u/BigDreamx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19776ck/d_workshops/</guid>
      <pubDate>Mon, 15 Jan 2024 12:03:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] EACL 2024 决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1975kvn/d_eacl_2024_decisions/</link>
      <description><![CDATA[致力于 EACL 2024 的人的决定将于今天（2024 年 1 月 15 日）公布！您的期望是什么？    由   提交 /u/OraclePred   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1975kvn/d_eacl_2024_decisions/</guid>
      <pubDate>Mon, 15 Jan 2024 10:23:06 GMT</pubDate>
    </item>
    <item>
      <title>[R]“从生成式人工智能到值得信赖的人工智能：法学硕士可以从 Cyc 学到什么”（2023 年）——Doug Lenat 去世前的最后一篇论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1974yoo/r_getting_from_generative_ai_to_trustworthy_ai/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2308.04445 博客文章：https://garymarcus.substack.com/p/doug-lenat-1950-2023 相关 Doug Lenat 演讲： 2022 年：https://www.youtube.com/watch?v=VjkbmLjwXO8 2019 年：https://www.youtube.com/watch?v=v2rK40bNrrY 摘要：  生成式人工智能是当前最流行的人工智能方法，由大型语言模型 (LLM) 组成，这些模型经过训练可产生合理的输出，但不一定正确。尽管他们的能力往往令人难以置信，但他们缺乏推理能力，导致法学硕士不太值得完全信任。此外，他们的结果往往是不可预测和无法解释的。我们列出了未来人工智能的 16 个需求，并讨论了人工智能的替代方法，该方法理论上可以解决与当前方法相关的许多限制：用精选的片段进行人工智能教育显性知识和经验规则，使推理引擎能够自动推断出所有这些知识的逻辑蕴涵。即使以这种方式产生的长论证也可以是值得信赖和可解释的，因为完整的一步一步的推理总是可用的，并且对于每一步，所使用的知识的来源都可以记录和审计。然而，有一个问题：如果逻辑语言的表达能力足以完全表达我们用英语所说的任何内容的含义，那么推理引擎的运行速度就会太慢。这就是为什么符号人工智能系统通常会选择一些快速但表达能力较差的逻辑，例如知识图谱。我们描述了一个人工智能系统 Cyc 如何开发出方法来克服这种权衡，并能够实时进行高阶逻辑推理。我们建议任何值得信赖的通用人工智能都需要混合这些方法，即法学硕士方法和更正式的方法，并为实现这一梦想奠定了道路。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1974yoo/r_getting_from_generative_ai_to_trustworthy_ai/</guid>
      <pubDate>Mon, 15 Jan 2024 09:41:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] GAN 的 LORA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1973l79/d_loras_for_gans/</link>
      <description><![CDATA[嗨，潜艇。我想训练一些GAN模型（比如pix2pix），但似乎训练一个高质量的GAN确实很难。 是否可以为GAN训练LORA？ 编辑：刚刚发现新论文E2GAN：用于图像到图像翻译的高效GAN的高效训练 https:/ /arxiv.org/abs/2401.06127   由   提交/u/gxcells  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1973l79/d_loras_for_gans/</guid>
      <pubDate>Mon, 15 Jan 2024 08:07:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] COSMO：具有交错预训练的对比流线型多模态模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1971c6h/r_cosmo_contrastive_streamlined_multimodal_model/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.00849 代码：https://github .com/showlab/cosmo 模型：https://huggingface.co/ Awiny 数据集：https://huggingface.co /datasets/Awiny/Howto-Interlink7M 项目页面：https： //fingerrec.github.io/cosmo/ 摘要：  视觉语言预训练的演变，从短文本理解转向包含扩展文本上下文是关键。最近的自回归视觉语言模型，如 [Flamingo、PaLM-E]，利用大型语言模型的长上下文功能，在少量文本生成任务中表现出色，但在对齐任务中面临挑战。为了解决这一差距，我们将对比损失引入文本生成模型，提出了 COntrastive-Streamlined MultimOdal 框架（CosMo），策略性地将语言模型划分为专用的单模态文本处理和熟练的多模态数据处理组件。 CosMo 是我们的统一框架，融合了单模态和多模态元素，增强了涉及文本和视觉数据的任务的模型性能，同时显着减少了可学习的参数。然而，这些模型需要大量的长文本数据集，而高质量长文本视频数据集的可用性仍然有限。为了弥补这一差距，这项工作引入了 Howto-Interlink7M，这是一个具有综合字幕的首个交错视频文本数据集，标志着向前迈出了重要一步。为了展示其影响，我们说明了 Howto-Interlink7M 如何增强图像文本任务中的模型性能。我们的模型具有 34% 的可学习参数并利用了 72% 的可用数据，表现出优于 OpenFlamingo 的显着优势。例如，在 4 镜头 flickr 字幕任务中，性能显着提高，从 57.2% 提高到 65.1%。 CosMo 和 Howto-Interlink7M 的贡献体现在涵盖图像文本和视频文本任务的 14 个不同下游数据集上的显着性能提升。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1971c6h/r_cosmo_contrastive_streamlined_multimodal_model/</guid>
      <pubDate>Mon, 15 Jan 2024 05:46:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自行实现 Rabbit tech 的 LAM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196wqsl/d_selfimplementing_rabbit_techs_lam/</link>
      <description><![CDATA[我看到了有关 Rabbit R1 和人性化人工智能的炒作。我只找到了一篇Rabbit ai的研究论文（https://www.rabbit.tech/research）。不幸的是，“研究论文”没有详细让我深入了解如何实现这样的人工智能。你们知道如何有效地自我训练“LAM”吗？如果你只是用这个人工智能制作一个启动器，直接与本机应用程序交互以切断数字处理的需要，不是更容易吗？ 我对这篇没有组织的帖子感到非常抱歉🙏&lt; /p&gt;   由   提交 /u/amirkasraaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196wqsl/d_selfimplementing_rabbit_techs_lam/</guid>
      <pubDate>Mon, 15 Jan 2024 01:50:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2024 决定将于今天公布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196uyub/d_iclr_2024_decisions_are_coming_out_today/</link>
      <description><![CDATA[我们很快就会在接下来的几个小时内知道结果。请随意宣传您已被接受的项目，并对您被拒绝的项目进行咆哮。   由   提交/u/deschaussures147  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196uyub/d_iclr_2024_decisions_are_coming_out_today/</guid>
      <pubDate>Mon, 15 Jan 2024 00:25:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我应该如何实现自定义量化方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196uam1/d_how_should_i_go_about_implementing_a_custom/</link>
      <description><![CDATA[大家好！我一直在研究量化 LLMS，并且我有一些想要测试的自定义方法。看看现有的实现，比如 Tim Dettmers 的 bitandbytes，让我感到一如既往的迷失。查看 llama.cpp 源代码也没有多大帮助。有没有人有实施和更重要的是评估自定义量化方法的经验？请分享任何想法，如果您有任何问题，请随时提问。谢谢！   由   提交 /u/Im_The_Tall_Guy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196uam1/d_how_should_i_go_about_implementing_a_custom/</guid>
      <pubDate>Sun, 14 Jan 2024 23:55:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 因果关系和基于模型的强化学习：可能的联系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196sva4/d_r_causality_and_modelbased_rl_possible/</link>
      <description><![CDATA[大家好！我一直在深入研究基于模型的强化学习（RL）及其与因果推理的关系，我发现自己很感兴趣，但又有点困惑。（请告诉我我的理解是否有意义） 一方面，基于模型的强化学习专注于学习环境的动态，似乎很自然地适合回答“假设”问题。问题。在没有实际的现实世界试验的情况下预测行动结果的能力感觉非常像因果推理。但是，这是否意味着基于模型的强化学习本质上能够进行全面的因果推理？ 我的理解是，因果推理不仅涉及预测结果（干预），还涉及反事实推理 - 理解什么在不同的过去行为下会发生。我想知道基于模型的强化学习在这方面的处理效果如何，因为它依赖于学习模型的准确性和完整性。 我很好奇社区对此的想法： &lt; ol&gt; 基于模型的 RL 系统可以回答的因果问题类型是否有任何限制？ 将显式因果模型集成到基于模型的 RL 框架中如何增强其功能？  li&gt;  很想听听您的见解或任何可以阐明这个交叉点的相关研究！   由   提交 /u/vocdex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196sva4/d_r_causality_and_modelbased_rl_possible/</guid>
      <pubDate>Sun, 14 Jan 2024 22:54:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 尝试计算单词的语义差异。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196ryle/p_trying_to_calculate_semantic_difference_of_words/</link>
      <description><![CDATA[我正在做一个项目，我有一个目标单词列表，需要计算这些单词和新单词之间的含义差异。这主要是一个单词相似度任务。  假设目标词是“car”，模型需要为“dog”输出高值。 “吉普车”的价值较低；或相反亦然。目前我正在使用 Huggingface 的句子转换器库来实现此目的，并使用（1-余弦相似度）作为差异分数。但表现并没有达到预期。有什么办法可以提高性能吗？我应该使用其他库/模型/指标吗？  谢谢。   由   提交 /u/franticpizzaeater   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196ryle/p_trying_to_calculate_semantic_difference_of_words/</guid>
      <pubDate>Sun, 14 Jan 2024 22:16:42 GMT</pubDate>
    </item>
    <item>
      <title>损失被限制在我的 GCN 模型中 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196lkyw/loss_is_getting_clamped_in_my_gcn_model_p/</link>
      <description><![CDATA[我已经使用 pytorch 在具有相同边缘索引的图上训练了以下模型（任务是电子健康记录上的图分类，其中每个图代表患者数据和节点向量已从组合知识图导出） class mdl(torch.nn.Module): def init(self, input_size, hide_size, output_size,dropout_rate): super(GCNClassifier, self).init() self.conv1 = GCNConv(input_size,hidden_​​size) self.conv2 = GCNConv(hidden_​​size,output_size) self.dropout = torch.nn.Dropout(dropout_rate) defforward(self,x,edge_index): x = self.conv1(x, edge_index) x = F.relu(x) x = self.dropout(x) x = self.conv2(x, edge_index) x = torch.mean(x, dim=0, keepdim=True) return x  问题是损失被限制在特定值 ​ 我尝试了各种学习率值并尝试了各种技术，例如动量和学习率调度，但损失仍然保持不变 ​ 我尝试使用以下循环训练上述模型 ​ #training (graphVec) 800 个图（每个形状为 [5,20] 的图） #y_train 是形状 [800] 的 0 和 1 的张量,1] 用于二元分类 ​ num_epochs = 100 for epoch in range(num_epochs): model.train() for i in range(len( graphVec)): # 在每次迭代中将每个图传递给模型 output = model(graphVec[i], edge_index) loss = criteria(output, y_train[i]) loss.backward() optimizationr.step() optimizationr.zero_grad( ) # StepLR 调度器步骤 Scheduler.step() print(output) # 打印每个 epoch 的损失和学习率 current_lr = optimizer.param_groups[0][&#39;lr&#39;] print(f&#39;Epoch [{epoch + 1}/{num_epochs} ]，损失：{loss.item()}，学习率：{current_lr}&#39;)  但是我的损失严重受限（损失并没有随着时代的推移而减少）我该怎么办?   由   提交/u/Willing-Cell1790  /u/Willing-Cell1790 reddit.com/r/MachineLearning/comments/196lkyw/loss_is_getting_clamped_in_my_gcn_model_p/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196lkyw/loss_is_getting_clamped_in_my_gcn_model_p/</guid>
      <pubDate>Sun, 14 Jan 2024 17:49:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    <item>
      <title>我仅使用智能手机就通过“活动识别”控制了超级马里奥！ [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196f4z9/i_controlled_super_mario_with_activity/</link>
      <description><![CDATA[最近，我参与了一个涉及活动识别的项目，这是根据从传感器收集的数据来识别和理解人类活动的过程&lt; /强&gt;。我唯一拥有的就是一部旧智能手机，因为我没有钱投资额外的传感器。 我的最终目标是使用我在现实世界中的动作来控制游戏中的超级马里奥。经过一些研究后，我发现大多数智能手机都配备了加速度传感器，我可以利用它来训练用于活动识别的机器学习模型。幸运的是，我的旧智能手机有一个。然后，我开发了一个应用程序，能够将实时传感器数据从我的智能手机无线传输到我的笔记本电脑（我将此应用程序命名为“SensorFlow”）。 使用这些数据，我构建并训练了一个机器学习模型它可以准确地检测我的行为，准确率高达 95%。最后，我将这个模型与《超级马里奥》集成，使用 python 根据我的真实动作以编程方式敲击箭头键。我最终得到了一个只需用我的身体就可以玩超级马里奥的系统！虽然不是 100% 但效果已经足够好了。欢迎提出更多建议。 我已经开源了所有与活动识别相关的代码以及我在此过程中开发的 Android 应用程序。 有关此项目的更多信息，您可以看看我的 YouTube。这是一种自我推销，但其中包含有关该项目的附加信息。您可以在下面看到最终结果👇 https://www.youtube.com/watch?v =IpLV6uKAO98   由   提交 /u/Pritish-Mishra    reddit.com/r/MachineLearning/comments/196f4z9/i_control_super_mario_with_activity/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196f4z9/i_controlled_super_mario_with_activity/</guid>
      <pubDate>Sun, 14 Jan 2024 12:46:53 GMT</pubDate>
    </item>
    </channel>
</rss>