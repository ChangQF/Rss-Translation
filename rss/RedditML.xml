<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 18 Oct 2024 15:17:23 GMT</lastBuildDate>
    <item>
      <title>[D] 如何使用“部分实现的数据”解决时间序列问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6hpto/d_how_to_approach_a_time_series_problem_with/</link>
      <description><![CDATA[大家好， 我被分配了一个工作问题需要解决，由于我对时间序列没有太多经验，所以这感觉像是一个不太容易建模的问题。我必须使用 Python 来实现这一点，而不是 R，所以我知道我的选择可能更有限？ 简而言之，  我有 2021-01-01 至 2022-07-31 之间 19 个月的每日客户下单数据。这给了我下单的天数、订单数量以及交易金额（$）。没有其他外生信息可立即获得； 我试图预测下个月（8 月 22 日）的订单天数（是/否目标，而不是计数）；需要注意的是，我只有 8 月份的部分信息，即数千个帐户已在 8 月份下了一个或多个订单，我在启动模型之前就掌握了这些信息。因此，我的目标是在进行预测时考虑到这一点。 我看到了两种解决方法：1) 最快/最简单的方法可能是使用部分实现的数据对 8 月份的 31 天进行建模，然后仅使用从本月预测的订单中“折扣”的订单；2) 似乎是正确的做法，但更难，即使用 8 月份的这些额外数据对 8 月份做出更好的预测； 我真的不知道我在寻找什么文献；当我问“要研究什么/要寻找什么”时，gpt 向我抛出了一些术语，例如“部分实现的滚动预测”、“使用不完整数据的预测”、“删失数据预测”、“实时预测”、“使用部分信息的现在预测”、“间歇性需求预测”。 我对统计学有相当的了解，接触过生存分析和删失数据，但正在试水，看看是否有更简单的方法。  谢谢！    提交人    /u/pdr07   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6hpto/d_how_to_approach_a_time_series_problem_with/</guid>
      <pubDate>Fri, 18 Oct 2024 13:11:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于时间序列的多模态神经网络？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6gcxl/d_multimodal_neural_networks_for_time_series/</link>
      <description><![CDATA[我正在寻找一个可以处理非时间序列输入的时间序列神经网络。 具体来说，一个神经网络，我可以给它一个主要时间序列（可能还有额外的辅助时间序列），以及一些关于这个特定时间序列的属性。目标是预测主要时间序列。 例如，假设我有个人家庭能源消耗，但我的测量结果并非全部来自同一时间段。有些房子我只拥有 2023 年的数据，而其他房子则从 2024 年开始，等等。为了配合这些能源消耗时间序列，我可能会有关于消费者家庭的其他信息，比如房子的大小或住在房子里的人数，或者只是一个唯一的 house_id。我想在这种时间序列上训练我的神经网络，在某种嵌入中利用这些附加参数，使得神经网络在给定特定嵌入时能够为这些家庭中的任何一个生成准确的预测。 所以看起来像： forecasting=model(input_time_serie,auxiliary_time_series,additional_properties) 其中input_time_serie是长度为n的单个时间序列向量，auxiliary_time_series是长度为n的可选时间序列（可以是室外温度、一周中的时间等），additional_properties是一个长度为m的向量，包含属性参数，它以某种方式嵌入神经网络内部，允许神经网络区分两个不同的家庭。 这样的神经网络有望用于零样本预测，在这种情况下我们还没有家庭的实际能源消耗，只有嵌入数据。 我知道https://github.com/thuml/Time-Series-Library，但所有这些类型的神经网络的问题在于，它们期望所有不同的时间序列作为输入，因此每个家庭一个，但当我的时间序列实际上没有重叠时，这不起作用，当我想对不在训练数据集中的新家庭进行零样本预测时，它也不起作用。 那么有谁知道有哪个神经网络能够做到这样的事情吗？或者有谁对如何修改神经网络以合理地包含属性嵌入有什么好的想法？    提交人    /u/alyflex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6gcxl/d_multimodal_neural_networks_for_time_series/</guid>
      <pubDate>Fri, 18 Oct 2024 12:01:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 主流 LLM 标记器的局限性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6dc8l/r_limitations_in_mainstream_llm_tokenizers/</link>
      <description><![CDATA[主流 LLM 标记器无法编码和解码为精确的字符串。这意味着它们不是无损的。一些 Llama、Mistral 和 Phi 标记器无法编码字符串 &#39; 谁放了狗？！ !&#39;，然后解码为相同的字符串。 如果运行代码：```python from transformers import AutoTokenizer models = [ &#39;meta-llama/Llama-2-7b&#39;, &#39;meta-llama/Meta-Llama-3-8B&#39;, &#39;meta-llama/Llama-3.1-8B&#39;, &#39;mistralai/Mistral-7B-v0.3&#39;, &#39;mistralai/Mixtral-8x7B-v0.1&#39;, &#39;mistralai/Mixtral-8x22B-v0.1&#39;, &#39;mistralai/Mistral-Nemo-Instruct-2407&#39;, &#39;mistralai/Mistral-Small-Instruct-2409&#39;, &#39;mistralai/Mistral-Large-Instruct-2407&#39;, &#39;microsoft/phi-1&#39;, &#39;microsoft/phi-1_5&#39;, &#39;microsoft/phi-2&#39;, &#39;microsoft/Phi-3-mini-4k-instruct&#39;, &#39;microsoft/Phi-3.5-mini-instruct&#39;, ] text = &#39; 谁放了狗？！&#39; for n in models: tokenizer = AutoTokenizer.from_pretrained(n) text2 = tokenizer.decode(tokenizer.encode(text, add_special_tokens=False)) if text2 == text: print(&#39;OK: &#39;, n, repr(text2)) else: print(&#39;ERR:&#39;, n, repr(text2))  ``` 您将得到： OK: meta-llama/Llama-2-7b &#39; 谁放了狗？！&#39; ERR: meta-llama/Meta-Llama-3-8B “谁放出了狗？！！” ERR: meta-llama/Llama-3.1-8B “谁放出了狗？！！” ERR: mistralai/Mistral-7B-v0.3 “谁放出了狗？！！” OK: mistralai/Mixtral-8x7B-v0.1 “谁放出了狗？！！” ERR: mistralai/Mixtral-8x22B-v0.1 “谁放出了狗？！！” OK: mistralai/Mistral-Nemo-Instruct-2407 “谁放出了狗？！！” OK: mistralai/Mistral-Small-Instruct-2409 “谁放出了狗？！！” OK：mistralai/Mistral-Large-Instruct-2407 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-1 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-1_5 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-2 &#39;谁放出了狗？！&#39; OK：microsoft/Phi-3-mini-4k-instruct &#39;谁放出了狗？！&#39; OK：microsoft/Phi-3.5-mini-instruct &#39;谁放出了狗？！&#39;  所有标有 ERR 的都无法编码​​并解码为相同的字符串。    提交人    /u/mtasic85   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6dc8l/r_limitations_in_mainstream_llm_tokenizers/</guid>
      <pubDate>Fri, 18 Oct 2024 08:35:43 GMT</pubDate>
    </item>
    <item>
      <title>“[P]” 如何使 Microsoft Fairlearn 的 Exponentiated gradient 与 DistilBERT 分类模型协同工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6dc6v/p_how_to_make_microsoft_fairlearns_exponentiated/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6dc6v/p_how_to_make_microsoft_fairlearns_exponentiated/</guid>
      <pubDate>Fri, 18 Oct 2024 08:35:37 GMT</pubDate>
    </item>
    <item>
      <title>医学成像人工智能顶级会议 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6bu6z/top_conferences_for_ai_in_medical_imaging_d/</link>
      <description><![CDATA[抱歉，标题中不能有“AGI”。 我正在研究我的第一篇第一作者研究，我的导师认为它的发展方向很好。我真的希望它明年能通过一些好的会议。 我知道 MICCAI 和 MIDL，但找不到可靠的来源来检查 2025 年与医学成像或医学 AI 相关的所有其他会议。我希望这里的人一定有一些其他经验。有什么建议吗？ 另外，研讨会论文是什么意思？我知道它不叫真正的出版物，但它值得提交给一个备受推崇的研讨会还是一个中等排名的会议？ 提前谢谢！    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6bu6z/top_conferences_for_ai_in_medical_imaging_d/</guid>
      <pubDate>Fri, 18 Oct 2024 06:37:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于“迷失于中间”现象是否存在一个普遍认可的解释？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6avhy/d_is_there_a_universally_agreed_explanation_for/</link>
      <description><![CDATA[自从我在攻读长语境法学硕士 (LLM) 期间阅读“Lost in the Middle”论文以来，已经有一段时间了。我很好奇是否有一篇论文提出了对这种影响的广泛接受的解释，或者是否有任何方法可以有效地解决或克服它。    提交人    /u/StraightSpeech9295   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6avhy/d_is_there_a_universally_agreed_explanation_for/</guid>
      <pubDate>Fri, 18 Oct 2024 05:28:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 2.5.0 发布！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g62vyh/d_pytorch_250_released/</link>
      <description><![CDATA[https://github.com/pytorch/pytorch/releases/tag/v2.5.0 亮点：我们很高兴地宣布 PyTorch® 2.5 的发布！此版本为 SDPA 提供了新的 CuDNN 后端，默认情况下，为 H100 或更新 GPU 上的 SDPA 用户启用加速。此外，torch.compile 的区域编译提供了一种减少 torch.compile 冷启动时间的方法，它允许用户编译重复的 nn.Module（例如 LLM 中的转换器层）而无需重新编译。最后，TorchInductor CPP 后端通过 FP16 支持、CPP 包装器、AOT-Inductor 模式和最大自动调谐模式等众多增强功能提供了可靠的性能加速。此版本由 504 位贡献者自 PyTorch 2.4 以来的 4095 次提交组成。我们衷心感谢我们敬业的社区所做的贡献。 我最喜欢的一些改进：  通过重复使用重复模块加快 torch.compile 编译速度 torch.compile 支持 torch.istft FlexAttention：一种灵活的 API，只需几行惯用的 PyTorch 代码即可实现各种注意机制，如滑动窗口、因果掩码和 PrefixLM。此 API 利用 torch.compile 生成融合的 FlashAttention 内核，从而消除了额外的内存分配并实现了与手写实现相当的性能。此外，我们使用 PyTorch 的自动求导机制自动生成向后传递。此外，我们的 API 可以利用注意力掩码中的稀疏性，从而比标准注意力实现有显著的改进。     提交人    /u/parlancex   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g62vyh/d_pytorch_250_released/</guid>
      <pubDate>Thu, 17 Oct 2024 22:11:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 是否可以将随意语言模型转换为掩码语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g61plo/p_is_it_possible_to_convert_a_casual_language/</link>
      <description><![CDATA[我正在为大学做一个项目，在这个项目中我需要一个掩码语言模型（不是英文的），我想知道，既然像 gpt2 这样的随意语言模型基本上是掩码模型，但它们只是把 MASK 标记放在句子的末尾。是否可以将其转换为掩码模型，这样我就可以把 MASK 标记放在任何地方？我不是指通过提示它成为一个掩码模型，而是指真正将它改变为一个。    提交人    /u/Appletee_YT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g61plo/p_is_it_possible_to_convert_a_casual_language/</guid>
      <pubDate>Thu, 17 Oct 2024 21:17:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何使用 LLM 从 500k 条聊天信息中提取见解？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5yn4b/p_how_to_extract_insights_from_500k_chat_messages/</link>
      <description><![CDATA[大家好， 我从 AI 上的 discord 服务器下载了聊天消息，2-3 年间总计约 50 万条消息。我这样做的原因是我想提取有关该主题的见解/提示和技巧，而这些见解/提示和技巧可能在在线教程中找不到（我一直发现在 discord 服务器中，人们互相帮助比阅读各种博客文章/教程更有信息量）。 它们总计约 800 万个代币，使用 gpt-4o-mini 需要花费 1-2 美元，使用 gpt-4o 需要花费 20-30 美元，这是相当合理的。 但是，我正在尝试弄清楚两件事： 1) 我是否可以使用本地 llm 来完成部分流程。这是首选，因为虽然 gpt-4o-mini 只需花费 1 到 2 美元，但这是每个提示的价格，而且我可能希望以多种方式查询/处理数据。 2) 我到底能做些什么来提取最有价值的见解？可能 95% 的聊天只是玩笑，但 5% 可能充满了有用的建议。我可以使用什么样的提示？我该如何处理需要分块输入以适应上下文窗口的事实？ 我愿意学习和探索任何新的主题来解决这个问题，因为我很高兴把它作为一个项目来接触 LLM。    提交人    /u/PMMEYOURSMIL3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5yn4b/p_how_to_extract_insights_from_500k_chat_messages/</guid>
      <pubDate>Thu, 17 Oct 2024 19:04:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些最有趣的现实世界（应用）机器学习会议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5txyp/d_what_are_some_of_the_most_interesting/</link>
      <description><![CDATA[我知道对于信息检索和推荐系统，RecSys 和 SIGIR 提供了一些行业讲座，我想知道您是否知道其他主要涉及行业发现/研究的讲座。    提交人    /u/gabegabe6   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5txyp/d_what_are_some_of_the_most_interesting/</guid>
      <pubDate>Thu, 17 Oct 2024 15:45:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] EigenLoRA：LLM 和扩散模型的极其高效的学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5tw6i/d_eigenlora_extremely_efficient_learning_for_llms/</link>
      <description><![CDATA[发现这篇论文 EigenLoRA，它展示了语言模型和扩散模型的相当不错的结果。它表明我们可以回收旧的 LoRA 并将它们结合起来以学习一个高效的子空间，这只需要很少的参数来微调。如果这是合法的，这似乎是一个非常酷的想法 - 人们可以以非常低的计算成本微调非常大的模型。我的问题是 - 这也可以应用于没有 LoRA 的微调模型吗？因为我们可以从基础和微调模型计算出 LoRA？有人尝试过类似于这个 EigenLoRA 模型的东西吗？    提交人    /u/propaadmd   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5tw6i/d_eigenlora_extremely_efficient_learning_for_llms/</guid>
      <pubDate>Thu, 17 Oct 2024 15:43:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何构建自定义文本分类器，无需花费数天时间进行人工标记</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5t7lq/p_how_to_build_a_custom_text_classifier_without/</link>
      <description><![CDATA[嗨，我在 Hugging Face 工作。我和我的团队致力于这个很酷的例子，说明如何从 LLM 转变为小型高效的分类模型。我们使用 LLM 自动标记数据集，然后在快速审查后对其进行微调。我们展示了它如何帮助我们简化工作流程，节省时间和资源，同时仍提供高性能模型。具有更高的准确性，同时仅标记几个示例。 博客文章：https://huggingface.co/blog/sdiazlor/custom-text-classifier-ai-human-feedback    提交人    /u/chef1957   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5t7lq/p_how_to_build_a_custom_text_classifier_without/</guid>
      <pubDate>Thu, 17 Oct 2024 15:13:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您认为该领域的下一个大事件是什么？LLM 的炒作会消退吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5jvzp/d_what_do_you_think_will_be_the_next_big_thing_in/</link>
      <description><![CDATA[我很高兴看到 LLM 的成功，但我并不是 NLP 的粉丝。您认为下一个能够取得商业成功或具有广泛适用性的大事件是什么（对初创公司和大公司都有用）？ 例如，RL 或 GNN 是否会开始在实践中得到更广泛的应用（我知道 GNN 在大公司中使用，但我仍然不知道它们被广泛使用）？ 考虑到实际应用，我认为计算机视觉是一个成熟的领域，但那里是否可能发生一些新的事情？    提交人    /u/Diligent-Ad8665   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5jvzp/d_what_do_you_think_will_be_the_next_big_thing_in/</guid>
      <pubDate>Thu, 17 Oct 2024 05:41:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 13 Oct 2024 02:15:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>