<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 18 Feb 2024 15:13:36 GMT</lastBuildDate>
    <item>
      <title>torchvision.models.resnet 和 torch.hub.load 有什么不同？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atujyc/what_is_the_different_for_torchvisionmodelsresnet/</link>
      <description><![CDATA[使用pytorch的resnet有两种方法。（第二种效果更好，为什么？） &amp;# x200b; 方法1： model = models.resnet18(pretrained=True)  方法2： model = torch.hub.load(&#39;pytorch/vision&#39;, &#39;resnet18&#39;, pretrained=True)   &amp;# 32；由 &amp;#32; 提交&lt;a href=&quot;https://www.reddit.com/user/qaz_zaqi&quot;&gt; /u/qaz_zaqi &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/1atujyc/what_is_the_ Different_for_torchvisionmodelsresnet/&quot;&gt;[链接]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/1atujyc/what_is_the_ Different_for_torchvisionmodelsresnet/&quot;&gt;[评论]&lt;/a&gt;&lt;/span&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atujyc/what_is_the_different_for_torchvisionmodelsresnet/</guid>
      <pubDate>Sun, 18 Feb 2024 13:51:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何重振机器学习研究的动力？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atu7in/d_how_can_i_reinvigorate_the_motivation_for_doing/</link>
      <description><![CDATA[我怀念 ML 不那么流行的时代。我五年前完成了自然语言处理硕士学位，目前正在考虑攻读博士学位。但我厌倦了每个人都攻读法学硕士学位并跳上炒作的火车。我喜欢研究，我应该如何进行？   由   提交 /u/ArtisticView8321   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atu7in/d_how_can_i_reinvigorate_the_motivation_for_doing/</guid>
      <pubDate>Sun, 18 Feb 2024 13:34:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 解决纸牌问题的算法/如何在 ML 中表示不规则结构的数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atu0gm/p_algorithms_for_solving_solitaire_how_to/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atu0gm/p_algorithms_for_solving_solitaire_how_to/</guid>
      <pubDate>Sun, 18 Feb 2024 13:24:06 GMT</pubDate>
    </item>
    <item>
      <title>[D]泡菜替代品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1attt4c/d_pickle_alternatives/</link>
      <description><![CDATA[我正在做一个项目，我需要转储我的简单 ML 管道（tf-idf 矢量器 + 逻辑回归）我需要转储管道除 pickle 之外的标准格式。众所周知，pickle 存在一些安全问题，但我不想这么做。我也研究过 onnx，但我认为它还不支持 tfidf 矢量器。 sklearn 文档提到 PMML 格式，我检查过，它需要 java 安装，这对项目来说是多余的。所以我的问题是，除了这些格式之外，你们现在还使用什么来保存和加载模型？    由   提交/u/msaoudallah  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1attt4c/d_pickle_alternatives/</guid>
      <pubDate>Sun, 18 Feb 2024 13:13:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] ARB：大型语言模型的高级推理基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1attnyg/r_arb_advanced_reasoning_benchmark_for_large/</link>
      <description><![CDATA[ 由   提交 /u/EducationalCicada   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1attnyg/r_arb_advanced_reasoning_benchmark_for_large/</guid>
      <pubDate>Sun, 18 Feb 2024 13:05:44 GMT</pubDate>
    </item>
    <item>
      <title>[N] Google 博客文章“什么是长上下文窗口？”指出其结果用于 Gemini 1.5 Pro 的长上下文项目需要“一系列深度学习创新”，但没有具体说明这些创新是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1attgz7/n_google_blog_post_what_is_a_long_context_window/</link>
      <description><![CDATA[来自什么是一个很长的上下文窗口吗？:  “我们最初的计划是在上下文中实现 128,000 个代币，我认为设定一个雄心勃勃的标准会很好，所以我建议 100 万个令牌，”谷歌 DeepMind 研究科学家尼古拉·萨维诺夫 (Nikolay Savinov) 说道，他是长上下文项目的研究负责人之一。 “现在我们的研究甚至超过了这个数字 10 倍。”  为了实现这种飞跃，团队必须进行一系列深度学习创新。谷歌 DeepMind 工程师 Denis Teplyashin 解释道：“一个突破引发了另一个突破，每一个突破都开辟了新的可能性。” “然后，当它们全部堆叠在一起时，我们非常惊讶地发现它们可以做什么，从 128,000 个代币跃升至 512,000 个代币，再到 100 万个代币，而就在最近，我们的内部研究中增加了 1000 万个代币。”  相关帖子：[D] Gemini 1M/10M 令牌上下文窗口如何？&lt; /a&gt;   由   提交 /u/Wiskkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1attgz7/n_google_blog_post_what_is_a_long_context_window/</guid>
      <pubDate>Sun, 18 Feb 2024 12:55:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] YOLOv8：图像增强效果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atsnxz/d_yolov8_image_augmentation_effectiveness/</link>
      <description><![CDATA[一般来说，在训练 yolov8 模型进行对象分类时，哪些图像增强最为有效？ （按从最好到最差的顺序） 图像级别增强 旋转剪切灰度色调亮度曝光噪声剪切马赛克 边界框级别增强 &lt; p&gt;翻转 90° 旋转作物旋转剪切亮度曝光模糊噪声 是否有一个 python 包，给定训练图像和标签的 yolov8 数据集，将以可重现的方式执行所有增强？ &gt; 一个最小的可重现示例将不胜感激。   由   提交/u/Tim7459  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atsnxz/d_yolov8_image_augmentation_effectiveness/</guid>
      <pubDate>Sun, 18 Feb 2024 12:06:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何查明你的研究以前是否没有做过？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atrenf/d_how_to_find_out_if_your_research_hasnt_been/</link>
      <description><![CDATA[我最近有了一个关于 ML 研究项目的想法。我花了几天时间实施和完善它并进行了测试。事实证明它运作得非常好！ 事实是，这个想法本身非常简单且非常直接，所以我担心它已经完成了。然而，通过谷歌搜索与我的想法相关的关键词，我发现没有论文可以做我所做的事情。尽管如此，我觉得谷歌搜索关键字可能不是一个有效的策略。因此我想问：如何确保你的想法真正新颖？   由   提交/u/Raskolnikov98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atrenf/d_how_to_find_out_if_your_research_hasnt_been/</guid>
      <pubDate>Sun, 18 Feb 2024 10:46:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 过去一年左右，RL 发生了什么？有什么大的进展吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atpztx/d_whats_been_going_on_in_rl_this_past_year_or_so/</link>
      <description><![CDATA[自从法学硕士开始掀起新闻风暴以来，我就没有听说过任何关于 RL 的新闻。   由   提交/u/Intelligent_Rough_21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atpztx/d_whats_been_going_on_in_rl_this_past_year_or_so/</guid>
      <pubDate>Sun, 18 Feb 2024 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 本地可运行的文本到语音 AI 起诉我自己的音频/语音？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atpyg1/d_locally_runnable_text_to_speech_ai_suing_my_own/</link>
      <description><![CDATA[是否有任何开源文本到语音模型经过训练用于创建自定义语音/音频，也可以在本地运行？    由   提交/u/Huge_Grab_9380   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atpyg1/d_locally_runnable_text_to_speech_ai_suing_my_own/</guid>
      <pubDate>Sun, 18 Feb 2024 09:08:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您保持最新状态的方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atmjz9/d_what_is_your_approach_for_staying_uptodate/</link>
      <description><![CDATA[新概念太多，时间太少。在我看来，虽然人们可以通过阅读获得基本的理解，但你确实需要修补和构建一些东西才能深入理解一项技术。作为一个有其他事情发生的成年人，这每年都变得越来越难，而与此同时，新工具和技术的速度似乎呈指数级增长。您要跟上的策略是什么？    由   提交 /u/HorseEgg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atmjz9/d_what_is_your_approach_for_staying_uptodate/</guid>
      <pubDate>Sun, 18 Feb 2024 05:28:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 应用机器学习论文中的公然数据泄露和谎言</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atf9tz/d_blatant_data_leakage_and_lies_in_an_applied_ml/</link>
      <description><![CDATA[最近我看到一篇在医疗保健领域应用的机器学习论文。论文发表在该领域真正顶级期刊的较小子期刊上。从我看来，这篇论文在方法论上确实存在明显的根本缺陷，完全使任何提议的贡献无效。 本质上，他们从智能手表的患者那里收集心率、睡眠等数据，并安装梯度增强机来预测血液中化学物质的水平。他们在晚上的记录时间收集样本，并使用 10 分钟粒度的时间序列数据集来进行每日预测。 问题是，他们使用每日睡眠时间和睡眠子类别（睡眠）阶段）的特点。在这种情况下，睡眠数据会在一天中重复，然后与同一天整个数据持续时间的一个唯一标签相匹配。然后，他们进行 10 倍的 CV，并全面报告 0.90+ 的绩效评估指标。 我以前见过数据泄露的欺诈性研究，但我从未见过如此刻意、如此明目张胆的半成品研究。 - 之前受人尊敬的期刊。作者在论文中回顾了这些细节，并做出了笼统的陈述，比如他们如何确保在 10 倍 CV 期间的训练集和测试集中不存在相同的数据行，等等。哈哈。您有 7 个特征，每天都采用唯一值，然后每个特征重复约 100 次，与 1 个唯一结果相匹配，并且您是说您确保在简历中分隔行索引？ 我是我对他们的结果表示怀疑，因为我在类似的领域工作，但由于缺少一些细节而无法确定。值得庆幸的是，由于一些法规或规则，他们必须公开数据和代码，我确认这正是正在发生的事情。 我不会在这里分享这项研究，但我应该这样做吗？联系期刊让他们撤回论文？有趣的是，该杂志有“AI”一词。以他们的名义，所以这不像是一本有非机器学习审稿人的期刊。这怎么能通过同行评审呢？有人见过如此欺诈的研究吗？我对这些科学出版物的现状感到困惑和震惊。    由   提交/u/enthusiastic31  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atf9tz/d_blatant_data_leakage_and_lies_in_an_applied_ml/</guid>
      <pubDate>Sat, 17 Feb 2024 23:13:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无提示的思维链推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at9w34/r_chainofthought_reasoning_without_prompting/</link>
      <description><![CDATA[论文 - https://arxiv.org/abs/2402.10200  摘要 - 在增强大语言模型（LLM）的推理能力方面，先前的研究主要集中在特定的提示技术上，例如少样本或零样本思维链（CoT） ) 提示。这些方法虽然有效，但通常涉及手动密集型提示工程。我们的研究采用了一种新颖的方法，提出了这样的问题：法学硕士能否在没有提示的情况下有效推理？有趣的是，我们的研究结果表明，只需改变解码过程，就可以从预先训练的 LLM 中导出 CoT 推理路径。我们不是采用传统的贪婪解码，而是研究前 k 个替代标记，发现 CoT 路径通常是这些序列中固有的。这种方法不仅绕过了提示的混杂因素，而且使我们能够评估法学硕士的内在推理能力。此外，我们观察到解码路径中 CoT 的存在与模型解码答案的较高置信度相关。该置信度度量有效区分 CoT 和非 CoT 路径。对各种推理基准的广泛实证研究表明，所提出的 CoT 解码大大优于标准贪婪解码。   由   提交/u/MysteryInc152   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at9w34/r_chainofthought_reasoning_without_prompting/</guid>
      <pubDate>Sat, 17 Feb 2024 19:21:52 GMT</pubDate>
    </item>
    <item>
      <title>V-JEPA：Yann LeCun 先进机器智能愿景的下一步 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at7fib/vjepa_the_next_step_toward_yann_lecuns_vision_of/</link>
      <description><![CDATA[      博客：https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model- video-joint-embedding-predictive-architecture/ 论文：https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning-visual-representations-from-video/ ​ 摘要： ​ 本文探讨了特征预测作为视频无监督学习的独立目标，并引入了 V-JEPA，这是一组仅使用特征预测目标训练的视觉模型集合，不使用预训练的图像编码器、文本、负例、重建或其他监督源。这些模型使用从公共数据集中收集的 200 万个视频进行训练，并针对下游图像和视频任务进行评估。我们的结果表明，通过预测视频特征进行学习可以产生多功能的视觉表示，在基于运动和外观的任务上表现良好，而无需调整模型的参数；例如，使用冷冻的骨干。我们最大的模型，仅在视频上训练的 ViT-H/16，在 Kinetics-400 上获得 81.9%，在 Something-Something-v2 上获得 72.2%，在 ImageNet1K 上获得 77.9%。 ​&lt; /p&gt; ​ https://preview.redd.it/uvo0dpwvl6jc1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=3f308732b80a72be3d5ad8ef9542462cf4611b64 V-JEPA 训练视觉编码器通过预测学习的潜在空间中的屏蔽时空区域。   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at7fib/vjepa_the_next_step_toward_yann_lecuns_vision_of/</guid>
      <pubDate>Sat, 17 Feb 2024 17:36:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>