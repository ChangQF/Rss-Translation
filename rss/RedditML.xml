<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 17 Dec 2024 15:18:56 GMT</lastBuildDate>
    <item>
      <title>[D] 超越机器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgc2th/d_machine_transcending/</link>
      <description><![CDATA[      https://preview.redd.it/nlxw409w7f7e1.jpg?width=451&amp;format=pjpg&amp;auto=webp&amp;s=757bc098c9851d9aa07cdfd45ec6dbdd44445271 我甚至不知道负值是可能的。我猜可能会检查我的积极优化技术。    提交人    /u/smealdor   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgc2th/d_machine_transcending/</guid>
      <pubDate>Tue, 17 Dec 2024 14:41:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可学习的掩蔽 token Vision Transformer</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgbgmh/d_learnable_masking_token_vision_transformer/</link>
      <description><![CDATA[大家好。我有一个用于 EEG 癫痫发作检测的数据集。输入是一个形状为 (22,289,251) 的多通道频谱图。由于数据集不平衡，我将进行 specaug 数据增强（时间、空间和频率掩蔽）对于分类，我想训练一个 VisionTransformer。我考虑尝试可学习的缺失标记，而不是用 (0,-1) 等常数值来掩盖缺失值。有人有这方面的经验吗？可以推荐一些好的论文或示例笔记本吗？非常感谢！    提交人    /u/Significant-Joke5751   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgbgmh/d_learnable_masking_token_vision_transformer/</guid>
      <pubDate>Tue, 17 Dec 2024 14:11:38 GMT</pubDate>
    </item>
    <item>
      <title>[R][D] 提炼不同学生和教师的 LLM 的可能的软标签有哪些？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg9qpm/rd_what_are_the_possible_soft_label_for/</link>
      <description><![CDATA[我想探索法学硕士 (LLM) 中的知识蒸馏。似乎有很多方法，但最简单的方法是学生只是老师的缩小版。但是，我想探索学生与老师的不同模型。首先，词汇量不同，当词汇集不同时，是否有一些技巧可以让我们用 KL 散度计算软标签的损失？在蒸馏过程中，我们可能希望将新词从教师模型引入学生模型。 我发现除了在这种情况下使用 KL 散度作为软损失之外，还有其他一些方法，甚至可以在黑盒教师设置中进行蒸馏。是否可以通过这种方式将新词引入学生的词汇表？谢谢    提交人    /u/worthlesspineapple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg9qpm/rd_what_are_the_possible_soft_label_for/</guid>
      <pubDate>Tue, 17 Dec 2024 12:39:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] SVGFusion：通过向量空间扩散实现可扩展的文本到 SVG 生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg87em/r_svgfusion_scalable_texttosvg_generation_via/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg87em/r_svgfusion_scalable_texttosvg_generation_via/</guid>
      <pubDate>Tue, 17 Dec 2024 10:58:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 评估法学硕士 (LLM) 答辩的质量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg77z2/d_evaluating_the_quality_of_llm_responses/</link>
      <description><![CDATA[大家好。我正在做一个项目，我收集了多份医疗访问记录和文件，并通过 LLM 和文本聚类管道提取所有独特的医疗症状，每个症状都有相关的根本原因和预防措施（即药物、治疗等）。 我已经完成了所有结果，我发现我生成的一些结果非常明显和笼统。例如，我的一个医疗症状是体温过高，它建议的一些治疗方法是多喝水和休息，大多数没有医学学位的人都能猜到。 我想知道是否有任何 LLM 评估方法可以用来对与医疗症状相关的根本原因和对策进行评分，这样它就可以将推荐陈词滥调的结果打低分，而将具有更独特和精确的根本原因和预防措施的结果打高分。我希望创建这个评估框架，以便它为我的每个结果提供一个分数，然后我将删除所有低于某个阈值的结果。 我理解确定某些东西是否具有普遍性或独特性/精确性可能非常主观，但请让我知道是否有办法构建一个评估框架来对结果进行排名，是否需要一些基本事实示例，以及如何构建这些示例。谢谢你的帮助！    提交人    /u/raikirichidori255   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg77z2/d_evaluating_the_quality_of_llm_responses/</guid>
      <pubDate>Tue, 17 Dec 2024 09:44:41 GMT</pubDate>
    </item>
    <item>
      <title>“[讨论]” “[D]” 介绍 TLR：通过共享学习在三个环境中同时训练 AI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg5siv/discussion_d_introducing_tlr_training_ai/</link>
      <description><![CDATA[TL;DR：我开发了TLR（三层训练），这是一个强化学习框架，可同时在三个环境中训练单个代理，同时分享经验以增强学习。它产生了我从未见过的积极回报——例如月球着陆器！欢迎反馈和想法。 大家好！ 👋 我想分享一些我一直在研究的东西：三层训练 (TLR)——一种新颖的强化学习框架，允许 AI 代理同时在三个环境中进行训练。 什么是 TLR？  TLR 一次在三个不同的环境中训练单个代理： 推车杆：简单的平衡任务。 月球着陆器：基于物理控制的精确着陆。 太空侵略者：动态游戏中的战略反应。  代理使用共享重放缓冲区来汇集这些环境中的经验，使其能够从一个环境中学习并将见解应用于另一个环境。 TLR 集成了高级 DQN 变体：标准 DQN、双 DQN（月球登陆器）和决斗 DQN（太空侵略者）。 优先重放：专注于关键转换以实现高效学习。 分层学习：跨环境逐步构建技能。   为什么 TLR 令人兴奋？  跨环境协同：代理通过利用来自另一项任务的知识来改进一项任务。 积极的结果：我在包括月球登陆器在内的所有三个环境中都看到了积极的回报，这是我以前从未实现过的！ 它突破了泛化的界限和多领域学习——我还没有见过广泛实施的东西。  它是如何工作的？  来自所有三个环境的经验被组合成一个共享重放缓冲区，以及特定于环境的缓冲区。 代理使用适合环境的算法进行调整（例如，用于月球着陆器的 Double DQN）。 训练在各个环境中同时进行，鼓励广义学习和技能转移。  下一步 我已经将 PPO 集成到月球着陆器环境中，并计划接下来添加好奇心驱动的探索 (ICM)。我相信这可以扩展到更复杂的任务和环境。 结果和代码 如果有人好奇，我已经在 GitHub 上分享了框架。 https://github.com/Albiemc1303/TLR_Framework-.git 您可以在那里找到示例日志和结果。我很乐意就方法或改进建议提供反馈！ 讨论问题  您见过类似的多环境 RL 实现吗？ 哪些其他环境或技术可以使 TLR 受益？ 如何扩展共享经验缓冲区以用于更通用的 AI 系统？  期待听到您的想法和反馈！我对 TLR 迄今为止的表现感到非常兴奋，并希望其他人会觉得它很有趣。    提交人    /u/UndyingDemon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg5siv/discussion_d_introducing_tlr_training_ai/</guid>
      <pubDate>Tue, 17 Dec 2024 07:52:37 GMT</pubDate>
    </item>
    <item>
      <title>[P] Vision Parse：使用 Vision LLM 将 PDF 文档解析为 Markdown 格式的内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg5d3p/p_vision_parse_parse_pdf_documents_into_markdown/</link>
      <description><![CDATA[嗨 Redditors， 我很高兴与大家分享 Vision Parse - https://github.com/iamarunbrahma/vision-parse，这是一个开源 Python 库，它使用视觉语言模型将 PDF 文档自动转换为格式完美的 markdown 内容。  将 PDF 文档中的每一页转换为高分辨率图像 使用 Vision LLM 从高分辨率图像中检测文本、表格、链接和图像并以 markdown 格式进行解析 轻松处理多页 PDF 文档 而且这个库很容易上手（只需pip install vision-parse，然后几行代码即可将文档转换为 markdown 格式的内容）。  我为什么构建这个？  传统的 PDF 到 markdown 转换工具通常难以处理复杂的布局、半结构化和非结构化的表格和格式。因此，依靠 Vision LLM 从图像中提取 markdown 中的内容（在这里，我将每个 PDF 页面转换为图像）。 使用传统的 OCR 和 PDF 到 markdown 转换工具，文档结构会失真。因此，使用生成式 AI 模型将有助于我们更好地理解结构并保存它。  您可以在此处找到开始使用此库的文档：https://github.com/iamarunbrahma/vision-parse/blob/main/README.md 查看此GitHub 项目 - Vision Parse并请向我提供您的反馈或任何建议。    提交人    /u/heliosarun   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg5d3p/p_vision_parse_parse_pdf_documents_into_markdown/</guid>
      <pubDate>Tue, 17 Dec 2024 07:20:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你做了什么方法来显著提高你的多类分类法学硕士成绩？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg3ou9/d_what_methods_have_you_done_to_significantly/</link>
      <description><![CDATA[我在工作中遇到了这个任务。我在 TikTok 工作，对于那些不知道的人来说，他们因拥有不切实际的 OKR 而臭名昭著。我被期望将我的模型提升到 90%+ F1 Macro，而当时它只有 70%，而且我遇到了人工标记团队的问题。我设法达到了 OKR，但我并不特别喜欢我所走的路线，因为它在很多方面都非常不靠谱。只是想知道你们会如何处理这种问题，以及你们将如何尝试在指标上获得大幅提升？我面临的主要问题是： - 数据质量非常低。由于预算问题，我们的人工标记团队只有 60% 的准确率（这是由内部 QA 代理评估的） - 数据量少。人工标记团队每周只能标记 10,000 行，我必须在 2 个月内训练 4 个模型。    提交人    /u/DolantheMFWizard   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg3ou9/d_what_methods_have_you_done_to_significantly/</guid>
      <pubDate>Tue, 17 Dec 2024 05:27:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 讨论：为机器学习的云成本而苦苦挣扎——还有其他人面临这个问题吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg2h81/d_discussion_struggling_with_cloud_costs_for_ml/</link>
      <description><![CDATA[大家好， 我相信你们中的一些人已经面临着租用云资源来训练大型语言模型的高成本的挑战。作为生活在第三世界国家的机器学习爱好者，成本很快就会变得难以承受，而且很难证明其合理性。 我很好奇，还有其他人遇到过这个问题吗？您如何处理训练模型的成本，或者您是否正在寻找其他方法来获得 ML 任务所需的性能而不会花光所有钱？ 很想听听您的想法和经验！    提交人    /u/DMortal139   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg2h81/d_discussion_struggling_with_cloud_costs_for_ml/</guid>
      <pubDate>Tue, 17 Dec 2024 04:15:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 定制写作任务的 LLM 微调指导：模型、GPU 和云平台注意事项</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg0z0k/d_guidance_on_finetuning_llm_for_custom_writing/</link>
      <description><![CDATA[大家好，我想对 LLM 进行微调，以完成一项自定义写作任务，该任务涉及根据具体示例生成结构相似的约 500 字的文章。鉴于我只有一台普通的 PC，我认为我需要在某个云平台上进行微调。我想知道：  我应该使用什么模型/参数数量 我应该租用什么 GPU/VRAM，以及我预计训练过程需要多长时间 最后，除了我提到的方面之外，还有什么我需要考虑的，才能继续尝试这样做  我有一个包含大约 500-1,000 个高质量样本的数据集。我可以增加样本量，但这需要更多工作。 如果我需要提供更多信息，请告诉我。谢谢。    由    /u/Rqees 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg0z0k/d_guidance_on_finetuning_llm_for_custom_writing/</guid>
      <pubDate>Tue, 17 Dec 2024 02:53:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用开放模型扩展测试时间计算！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hfw40o/r_scaling_testtime_compute_with_open_models/</link>
      <description><![CDATA[      嗨！我是 Lewis，Hugging Face 👋 的研究员。在过去的几个月里，我们一直在深入尝试逆向工程并重现几个关键结果，这些结果让 LLM 能够“思考更长时间”通过测试时计算，我们终于很高兴能分享一些我们的知识。 今天，我们将分享一篇详细的博客文章，介绍我们如何通过将分步奖励模型与树搜索算法相结合，在数学上超越 Llama 70B 和 Llama 3B： https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute 在博客文章中，我们涵盖了：  计算最优扩展：我们如何实施 u/GoogleDeepMind 的配方来提升测试时开放模型的数学能力。 多样化验证者树搜索 (DVTS)：我们为验证器引导树搜索技术开发的未发布的扩展。这种简单而有效的方法提高了多样性并提供了更好的性能，特别是在测试时间计算预算较大的情况下。 搜索和学习：一个轻量级工具包，用于使用 LLM 实施搜索策略，并使用 vLLM 加快速度。您可以在这里查看：https://github.com/huggingface/search-and-learn  很高兴回答问题！ https://preview.redd.it/cagfkzxria7e1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=34f3a45dd056da19a6b1e6f03a53ff8283df7ba7    由    /u/lewtun 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hfw40o/r_scaling_testtime_compute_with_open_models/</guid>
      <pubDate>Mon, 16 Dec 2024 22:55:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 基于图形的 LLM 工作流程编辑器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hfr4sg/p_graphbased_editor_for_llm_workflows/</link>
      <description><![CDATA[我们制作了一个开源工具，它提供了一个基于图形的界面，用于构建、调试和评估 LLM 工作流：https://github.com/PySpur-Dev/PySpur 我们为什么要构建它： 在此之前，我们构建了几个由 LLM 驱动的应用程序，共同为数千名用户提供服务。我们面临的最大挑战是确保可靠性：确保工作流程足够强大，能够处理极端情况并提供一致的结果。 实际上，实现这种可靠性意味着反复：  将复杂的目标分解为更简单的步骤：编写提示、工具调用、解析步骤和分支逻辑。 调试故障：确定工作流程的哪个部分出现故障以及原因。 衡量性能：根据实际指标评估变化以确认实际改进。  我们尝试了一些现有的可观察性工具或代理框架，但它们在这三个维度中的至少一个上存在不足。我们想要一种能够让我们快速迭代并专注于改进的东西，而不是与多个不相连的工具或代码脚本搏斗。 我们最终得出了构建 PySpur 的三个原则：  基于图形的界面：我们可以将 LLM 工作流布局为节点图。节点可以是 LLM 调用、函数调用、解析步骤或任何逻辑组件。可视化结构提供即时概览，使复杂的工作流更加直观。 集成调试：当出现故障时，我们可以在 UI 中精确定位有问题的节点、进行调整，然后在某些测试用例上重新运行它。 在节点级别进行评估：我们可以评估节点更改如何影响下游性能。  我们希望它对其他 LLM 开发人员有用，尽情享受吧！   由    /u/Brilliant-Day2748  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hfr4sg/p_graphbased_editor_for_llm_workflows/</guid>
      <pubDate>Mon, 16 Dec 2024 19:23:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您今年读过的最喜欢的论文是什么？为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hfljy3/d_whats_your_favorite_paper_youve_read_this_year/</link>
      <description><![CDATA[多年没有发这个帖子了，但是假期旅行需求很大，很想有一个论文库可以在旅行期间阅读。    提交人    /u/bin_und_zeit   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hfljy3/d_whats_your_favorite_paper_youve_read_this_year/</guid>
      <pubDate>Mon, 16 Dec 2024 15:26:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</guid>
      <pubDate>Sun, 15 Dec 2024 16:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>