<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 16 Sep 2024 15:17:59 GMT</lastBuildDate>
    <item>
      <title>[D] 音频/语音分离</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fi6jyk/d_audiovoice_sepration/</link>
      <description><![CDATA[嗨，我需要项目帮助，我需要分离重叠的扬声器音频。 例如：我有一个带有 4 个扬声器的音频文件，在 2 个扬声器之间，同时说话导致音频重叠，我需要分离这个重叠，然后按照先到先得的原则转录音频。 像这样https://arxiv.org/abs/2003.01531    提交人    /u/Apprehensive_Sell396   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fi6jyk/d_audiovoice_sepration/</guid>
      <pubDate>Mon, 16 Sep 2024 14:49:31 GMT</pubDate>
    </item>
    <item>
      <title>项目 - 将 OCR 结果分类到字段 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fi5g7y/project_classify_ocr_results_to_fields_p/</link>
      <description><![CDATA[对于需要对卡片字段进行分类的软件，如图书证、健身房会员卡、学生证，什么策略比较好呢？ 它们包含详细信息，如：姓名、会员 ID、日期、组号、提供商等，软件需要确定它们是什么。 每个字段前面可能有一个标签，也可能根本没有标签。如果有标签，标签可能位于值之前、值之下或值之上。该值也可以在最右侧。 没有一致的结构，并且卡片类型很多。 数据来自带边界框的 OCR，可能会有错误，有时间距错误，但总体来说还不错。 我目前考虑的情况：  在代码逻辑角色中使用，我知道这种方法会起作用，但需要很长时间才能实现，而且不是机器学习。 使用 LayoutLMv3，没有训练它根本不起作用，但我希望它经过训练后能起作用，尽管我有很多不同的布局。  我不确定训练集中需要有多少张卡片才能起作用。对于一些输入来说会很棒。  尝试使用 bert-large-uncased-whole-word-masking-finetuned-squad 从原始文本中获取一些见解，但它的表现很差而且很慢。 具有 40 亿个参数的大型 LLM 模型即使仅使用原始文本也能更好地工作，但这东西需要在本地运行。  很想听听您的意见，以及我需要什么大小的数据集，或者任何有用的想法。    提交人    /u/optimizeyourself   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fi5g7y/project_classify_ocr_results_to_fields_p/</guid>
      <pubDate>Mon, 16 Sep 2024 14:03:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] Yolov5s 微调问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fi4k5k/d_yolov5s_fine_tune_issues/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fi4k5k/d_yolov5s_fine_tune_issues/</guid>
      <pubDate>Mon, 16 Sep 2024 13:24:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 根据（加权）旋转主成分重建原始观测值</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fi3s54/r_reconstruct_original_observations_from_weighted/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fi3s54/r_reconstruct_original_observations_from_weighted/</guid>
      <pubDate>Mon, 16 Sep 2024 12:50:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 加入 r/AIQuality：一个致力于人工智能评估和输出质量的社区</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fi2jdc/d_join_raiquality_a_community_for_ai_evaluation/</link>
      <description><![CDATA[如果您专注于 LLM 中的输出质量和评估，我创建了 r/AIQuality — 一个致力于为那些致力于构建可靠、无幻觉系统的人服务的社区。 就我个人而言，我在评估我的 RAG 管道时一直面临挑战。我应该使用 DSPy 来构建它吗？哪种检索器技术效果最好？我应该切换到不同的生成器模型吗？最重要的是，我如何真正知道我的模型是在改进还是在退步？这些问题使评估变得困难，但至关重要。 随着 RAG 和 LLM 的快速发展，没有空间深入研究这些评估难题 — 直到现在。这就是我创建这个社区的原因：分享见解，探索前沿研究，并应对评估 LLM/RAG 系统的真正挑战。 如果您正在处理类似的问题并希望改进您​​的评估流程，请加入我们。 https://www.reddit.com/r/AIQuality/    提交人    /u/Desperate-Homework-2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fi2jdc/d_join_raiquality_a_community_for_ai_evaluation/</guid>
      <pubDate>Mon, 16 Sep 2024 11:48:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 天体物理学中的替代模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fi0zx2/d_surrogate_modelling_in_astrophysics/</link>
      <description><![CDATA[大家好，我是一名天体物理学家，目前正在研究 X 射线光谱，我正在寻找有关替代模型的讨论/建议。我将描述一下我们现在遇到的问题、我们尝试过的东西以及出现的新问题。 为了让你们知道，我们研究来自黑洞、星系团、中子星等各种物体的 X 射线光谱，以了解这些物体中发生的物理过程。一般来说，使用模型并对其进行拟合，我们可以很好地了解物理属性，例如质量、温度和其他我不会深入讨论的细节。如今，由于计算需求高，模型变得越来越复杂（例如，我们可能需要在黑洞周围进行相对论射线追踪，以正确描述它们发出的光）。 因此，光谱模型是能量和一系列参数的函数（对于我所知道的模型，参数为 2 到 ~30），并且通常，我们想要计算两种能量之间的通量（这主要是因为我们的仪器就是这样工作的）。光谱只是根据给定数量的能量箱（通常介于 100 到 2000 之间，对于最新的仪器最多为 60 000）评估的通量。 我们正在采取这种方法的小步骤，并首先尝试学习在固定网格上近似这些光谱，这与特定仪器测量的光谱相对应。这很好，因为当使用测量光谱时，我们可以定义一个有效的指标来解释我们正在测量的统计行为。我们观察到，训练 VAE 以及模型参数与潜在空间之间的映射在生成模拟光谱方面效果很好。 但是，我们希望生成通用模拟器 f(E_low, E_high, theta)，它可以在用仪器测量之前，在任意箱体或箱体集合中评估此模型。我们发现，由于各种原因，这更具挑战性。我还没有深入研究这个主题，但这是我在处理数据时的想法：  模拟器应该学习这种函数的连续属性，以及其他属性，例如 f(E_1, E_2, theta) + f(E_2, E_3, theta) = f(E_1, E_3, theta)。当使用 (E_low, E_high, theta) 的随机样本进行盲目训练时，我们无法保证这一点。  模拟器应该能够处理 E_low、E_high 的矢量化输入。我觉得使用模拟器 f(E_low, E_high, theta) 并将其映射到 60 000 个 (E_i, E_i+1) 箱会非常低效。 与通用模拟器相比，固定网格上的 VAE 工作得非常好，这可能是因为它可以依赖于前面指出的数据连续性。但它不能直接推广。我想不出一个架构，它采用任意大小的能量网格，并在相同任意大小的能量网格上输出通量，并对给定的一组参数 theta 进行额外的调节。  目前，我正在寻找一种能够嵌入/解码任意大小的 1D 数组的架构。但我指出的大多数事情可能是错误的，我对 ML 的了解与领域非常相关，而且我缺乏对这些方法的全局视野，无法正确完成这些事情。这就是我写这篇文章的原因！如果您有任何想法、建议，想讨论这个话题，我会非常高兴收到来自出色的 ML 社区的反馈。  NB：如果您想私下讨论这个问题，请随时给我发私信或写信给我 sdupourque[at]irap.omp.eu    提交人    /u/renecotyfanboy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fi0zx2/d_surrogate_modelling_in_astrophysics/</guid>
      <pubDate>Mon, 16 Sep 2024 10:18:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 努力寻找能源消耗数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fi0dxf/p_struggling_to_find_energy_consumption_data/</link>
      <description><![CDATA[ 大家好， 我正在构建一个机器学习模型来预测家庭能源消耗，并计划在未来集成更多功能。为了创建一个准确的模型，我需要高质量的数据，最好是通过 API 以小时为单位进行实时更新。 但是，我遇到了一个难题：我在大多数公用事业公司网站上都找不到 API 数据共享选项。我还联系了我所在的意大利的一些公用事业公司，但没有收到任何回复。 目前，我感觉很迷茫。如果我无法直接访问这些数据集，我有什么替代方案？是否有我可能遗漏的开放数据集、API 或数据共享协议？任何建议都将不胜感激！    提交人    /u/Temporary-Cricket880   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fi0dxf/p_struggling_to_find_energy_consumption_data/</guid>
      <pubDate>Mon, 16 Sep 2024 09:34:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] FAISS 与 Azure AI 搜索与 DINOV2 嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhykj5/p_faiss_vs_azure_ai_search_vs_dinov2_embeddings/</link>
      <description><![CDATA[我正在尝试构建可靠的图像搜索。我有固定数量的图像（数量可变，使用高分辨率 DSLR 拍摄）。我的查询图像将是使用手机相机拍摄的低质量图像。与 DSLR 图像不同，查询图像将包含其他背景和对象以及感兴趣的对象。我的目标是进行图像授权，我想首先从图像搜索开始，然后进行特征提取和匹配。您会推荐 FAISS、Azure AI 搜索还是向量数据库中的 dinov2 嵌入。我在 Qdrant 中进行了 dinov2 嵌入，但在 3 种情况下失败，查询图像没有从数据库中选择正确的图像。我还在寻找通过视觉排名聚类或图形神经网络来减少搜索的方法。您能告诉我什么最适合我的用例吗？   由    /u/PositiveResponse7678  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhykj5/p_faiss_vs_azure_ai_search_vs_dinov2_embeddings/</guid>
      <pubDate>Mon, 16 Sep 2024 07:11:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 分解 PyTorch 函数帮助我了解其内部发生的事情</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhwwli/p_breaking_down_pytorch_functions_helped_me_with/</link>
      <description><![CDATA[大家好， 我以前很难理解 PyTorch 库内部发生了什么。分解内部工作原理对我来说一直是一个挑战，因此我对一些关键功能进行了简单的解释。 这里我重点关注：  loss.backward() torch.no_grad() requires_grad=True  我知道还有很多东西需要探索，稍后我会介绍其他功能。 也许你们中的一些人可以告诉我：  如果您有其他“黑匣子”功能，您会感到困惑 您是否理解了我的解释 对视频的任何反馈（我非常感谢正面和负面的反馈）  非常感谢！    提交人    /u/vtimevlessv   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhwwli/p_breaking_down_pytorch_functions_helped_me_with/</guid>
      <pubDate>Mon, 16 Sep 2024 05:13:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 论文、博客和项目的集合，重点关注 OpenAI o1 和推理技术。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhtkz5/r_a_collection_of_llm_papers_blogs_and_projects/</link>
      <description><![CDATA[        提交人    /u/Happysedits   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhtkz5/r_a_collection_of_llm_papers_blogs_and_projects/</guid>
      <pubDate>Mon, 16 Sep 2024 02:07:49 GMT</pubDate>
    </item>
    <item>
      <title>多模融合 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhsi7n/multimodal_fusion_p/</link>
      <description><![CDATA[      您好，我正在尝试融合两个图像分类模型，一个使用 RGB 图像训练，另一个使用 SAR 图像训练，这两种类型的图像都来自同一数据集并代表相同的内容。 这是实现后期融合的正确方法吗？我使用平均值、最大值和加权得到了相同的结果，我担心我的方法有问题。  https://preview.redd.it/fot9jlznn2pd1.png?width=694&amp;format=png&amp;auto=webp&amp;s=cde86f005a728d1782e95437cc357da7def854b5    提交人    /u/Icy_Dependent9199   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhsi7n/multimodal_fusion_p/</guid>
      <pubDate>Mon, 16 Sep 2024 01:13:03 GMT</pubDate>
    </item>
    <item>
      <title>[N] CVPR 2025 的新变化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhq7rb/n_new_changes_to_cvpr_2025/</link>
      <description><![CDATA[  由    /u/stirling_approx  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhq7rb/n_new_changes_to_cvpr_2025/</guid>
      <pubDate>Sun, 15 Sep 2024 23:20:02 GMT</pubDate>
    </item>
    <item>
      <title>用 C 语言构建 gpt2 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fhjtyo/built_gpt2_in_c_p/</link>
      <description><![CDATA[OpenAI 从第一原理用纯 C 语言实现 GPT-2 论文。1. 从头开始​​实现各种 GPT 组件（如 LayerNorm、多层感知器 (MLP) 和因果注意）的前向传播和反向传播。2. 没有使用像 PyTorch 这样的自动求导引擎；模型权重的梯度是使用手工推导的导数计算的。通过不保存不必要的激活值，此方法将内存使用量减少了近 20 GB。3. 通过文件的内存映射来处理激活和模型权重的内存管理。4. 该项目的目的是探索 PyTorch 和深度学习的低级内部工作原理。 5. 任何对 C 有基本了解的人都可以轻松理解和实现其他大型语言模型（LLM），如 LLaMA、BERT 等。 Repo 链接：https://github.com/shaRk-033/ai.c    提交人    /u/Silly-Dig-3312   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fhjtyo/built_gpt2_in_c_p/</guid>
      <pubDate>Sun, 15 Sep 2024 18:43:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>