<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 18 Mar 2024 18:16:03 GMT</lastBuildDate>
    <item>
      <title>降低CPWL模型的复杂度 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhx1jk/reducing_complexity_of_cpwl_model_p/</link>
      <description><![CDATA[我正在使用的系统本质上是一个带有内存的多项式，我需要一个算法来反转它。迄今为止复杂度最低的方法是规范分段线性方法。它有~600个特征，但数据速率非常高，因此计算复杂度仍然比目标至少高一个数量级。没有办法充分减少功能数量来满足这一要求。 什么是复杂度较低的算法来抵消高数据速率？   由   提交 /u/Typical-Car2782    reddit.com/r/MachineLearning/comments/1bhx1jk/reducing_complexity_of_cpwl_model_p/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhx1jk/reducing_complexity_of_cpwl_model_p/</guid>
      <pubDate>Mon, 18 Mar 2024 17:52:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 扩散模型因自我调节而爆炸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhtyvr/d_diffusion_model_blows_up_with_self_conditioning/</link>
      <description><![CDATA[我正在训练 用于基因组数据集的 lucidrain 1d DDPM。如果我使用自我调节（模型可以看到自己之前的样本），那么在几百个批次之后我的损失就会增加到无穷大。如果没有自我调节，它似乎表现得很好。好奇是否还有其他人看过这个？ Analog Bits 论文介绍了自我调节，并声称它很有帮助。显然，我可以降低学习率，但不确定这会有多大帮助，因为训练的爆发时间稍晚一些。    由   提交/u/daking999  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhtyvr/d_diffusion_model_blows_up_with_self_conditioning/</guid>
      <pubDate>Mon, 18 Mar 2024 15:48:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] IJCAI'24反驳讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhspbk/d_ijcai24_rebuttal_discussion/</link>
      <description><![CDATA[大家好， 随着评论即将发布，我发起此线程来分享想法、问题和关于 IJCAI 提交的建议。 祝大家好运！   由   提交 /u/Acceptable_Pop1461   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhspbk/d_ijcai24_rebuttal_discussion/</guid>
      <pubDate>Mon, 18 Mar 2024 14:55:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] FOSS MLOps 工具，可简化 ML 工程师和应用程序开发人员之间的模型移交</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhs373/p_foss_mlops_tool_that_simplifies_handing_off/</link>
      <description><![CDATA[大家好 - 我们刚刚开源了我们的工具，用于在我们的机器学习工程师/数据科学家和我们的应用程序开发团队之间传递模型。它解决了我们遇到的大量问题，特别是必须维护两个不同的管道以及必须不断寻找模型资产。  想知道您的想法，您可以在这里查看：https://kitops.ml   由   提交/u/iamjessew  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhs373/p_foss_mlops_tool_that_simplifies_handing_off/</guid>
      <pubDate>Mon, 18 Mar 2024 14:29:17 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 使用LLM将PDF数据格式化为QnA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhquym/discussion_data_formatting_from_pdf_to_qna_using/</link>
      <description><![CDATA[数据准备很困难，这是我在想根据一堆 pdf 中存在的数据微调模型时观察到的情况，&lt; /p&gt; 我需要将 pdf 中的内容转换为 QnA 数据集，但显然我不会手动执行此操作。  我看到了这个 YouTube 视频 (youtube.com/watch?v=fYyZiRi6yNE)，这个人在这里创建了一个脚本：https://github.com/Aemon-Algiz/DatesetExtraction/blob/main/BookParse.py  此脚本将 pdf 转换为文本并然后使用法学硕士根据该文本制作问答对。  每个人都使用这种技术来构造数据吗？还是有更有效的方法来做到这一点？  此外，随着我​​对法学硕士的学习和深入了解，我能够观察到挑战，但我也想知道即将面临的和主要面临的其他挑战。    由   提交/u/Medium_Alternative50   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhquym/discussion_data_formatting_from_pdf_to_qna_using/</guid>
      <pubDate>Mon, 18 Mar 2024 13:34:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 仅在 cifar10 上评​​估的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhp54a/d_papers_that_only_evaluate_on_cifar10/</link>
      <description><![CDATA[大家好！ 在审阅 NeurIPS 2024 时，我一直注意到的一件事是，很多论文只评估非常小的数据集，例如 Cifar-10。这对我来说很奇怪：我认为 Cifar10 是我的方法的玩具数据集和测试平台，而不是我用来证明我的方法实际上有效/在实践中相关的东西。所以我的第一直觉始终是“这种方法可能无法扩展到更大的数据集”。我的意思是，ImageNet 已经有 12 岁了，我个人从大约 8 年前就开始在 imagenet 上为我的论文提供结果。据我所知，大多数计算机视觉应用都需要比 32x32 更大的分辨率。我的印象也是，几乎所有“好”的东西都是我读过的论文有更大规模数据的结果。但考虑到我经常遇到这种情况，我不得不想：我只是在一个非常优越的环境中工作，还是稿件作者只是懒惰？您对仅评估 MNIST 和 CIFAR10 的论文有多少信心？   由   提交/u/audiencevote  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhp54a/d_papers_that_only_evaluate_on_cifar10/</guid>
      <pubDate>Mon, 18 Mar 2024 12:08:11 GMT</pubDate>
    </item>
    <item>
      <title>2024 年哪个库最适合时间序列预测和异常检测？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bho0r0/in_2024_which_library_is_best_for_time_series/</link>
      <description><![CDATA[我正在开发一个项目，负责识别时间序列数据中的异常情况。我遇到了 Facebook Prophet，但遗憾的是它自 2023 年以来就不再维护了。他们建议 NeuroProphet、nixtla 作为替代方案。在寻找替代方案时，我发现了来自 Facebook 的 Kats，它内置了先知支持。这里有哪些工具/库经验丰富的成员会推荐哪些工具/库来构建用于对大量时间序列数据进行异常检测的生产级系统？   由   提交 /u/ThakkidiMundan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bho0r0/in_2024_which_library_is_best_for_time_series/</guid>
      <pubDate>Mon, 18 Mar 2024 11:03:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型语言模型的时间之箭</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhnoor/r_arrows_of_time_for_large_language_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.17505 摘要：  我们通过以下方法研究自回归大型语言模型执行的概率建模：时间方向性的角度。我们凭经验发现此类模型在模拟自然语言的能力方面表现出时间不对称性：尝试预测下一个标记与尝试预测前一个标记时的平均对数困惑度存在差异。这种差异同时是微妙的，并且在各种模式（语言、模型大小、训练时间……）中非常一致。从理论上讲，这是令人惊讶的：从信息论的角度来看，不应该存在这样的差异。我们提供了一个理论框架来解释这种不对称性是如何从稀疏性和计算复杂性考虑中出现的，并概述了我们的结果所带来的一些观点。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhnoor/r_arrows_of_time_for_large_language_models/</guid>
      <pubDate>Mon, 18 Mar 2024 10:42:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当你使用人工智能进行总结时结果不正确时。爱思唯尔发表的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</link>
      <description><![CDATA[       由   提交 /u/vvkuka   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</guid>
      <pubDate>Mon, 18 Mar 2024 10:14:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] Hugging Face 演示应用程序：表格数据的可解释生成人工智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhlajr/p_hugging_face_demo_app_explainable_generative_ai/</link>
      <description><![CDATA[大家好， 我邀请您尝试我们在表格数据的可解释和生成人工智能方面的工作的拥抱脸演示应用程序。 https://huggingface.co/spaces/CaglarAytekin/LEURN 简单来说，该应用程序采用包含特征和目标的训练表，让您选择要预测的内容并选择分类列。然后您可以使用选定的超参数训练神经网络。训练完成后，您可以上传测试数据（只有特征，没有目标的 Excel 或 csv），然后选择一行来运行神经网络并解释决策。您还可以根据神经网络从训练中学到的知识无缝地生成新数据。可以从上述应用程序中找到清晰的使用说明。 相关研究论文： https://arxiv.org/abs/2303.14937 开源代码： https://github.com/CaglarAytekin/LEURN/ 联系人： caglar@deepcause.ai ​   由   提交 /u/MLC_Money   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhlajr/p_hugging_face_demo_app_explainable_generative_ai/</guid>
      <pubDate>Mon, 18 Mar 2024 07:51:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] xAI 的 Qdrant...为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhhyrv/d_xais_qdrantwhy/</link>
      <description><![CDATA[也许我只是没有花时间去理解它，但我很难理解 Qdrant 为何比 OpenSearch/ElasticSearch 更好？ OS/ES 都使用 HNSW，并且它们都使用相同的 KNN oss 实现，该实现具有极高的性能。 Qdrant 有什么“开箱即用”的功能？这些现有的且广泛采用的选项没有？   由   提交/u/titani0us  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhhyrv/d_xais_qdrantwhy/</guid>
      <pubDate>Mon, 18 Mar 2024 04:11:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何准备 META 研究工程师面试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhgxar/d_how_to_prepare_for_a_meta_research_engineer/</link>
      <description><![CDATA[我将在一周内进行 META 研究工程师面试。这个职位本身是机器学习和计算机视觉领域的，但我希望在面试中会被问到 leetcode 风格的问题。我想知道是否有人可以给我一些关于学习/复习内容的建议，因为只剩下一周了。   由   提交 /u/Tiny-Masterpiece-412   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhgxar/d_how_to_prepare_for_a_meta_research_engineer/</guid>
      <pubDate>Mon, 18 Mar 2024 03:16:01 GMT</pubDate>
    </item>
    <item>
      <title>xAI 发布 Grok-1 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh7yc4/xai_releases_grok1_n/</link>
      <description><![CDATA[ 我们正在发布大型语言模型 Grok-1 的基本模型权重和网络架构。 Grok-1 是一个由 xAI 从头开始​​训练的 3140 亿参数混合专家模型。 这是 Grok-1 预训练阶段的原始基础模型检查点，该阶段于 2023 年 10 月结束。这意味着该模型没有针对任何特定应用程序（例如对话）进行微调。 我们将在 Apache 2.0 许可证下发布权重和架构。 开始使用使用该模型时，请按照 https://github.com/xai-org/grok 中的说明进行操作   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh7yc4/xai_releases_grok1_n/</guid>
      <pubDate>Sun, 17 Mar 2024 20:38:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] Paperlib：一个开源且现代设计的学术论文管理工具。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh63c1/p_paperlib_an_opensource_and_moderndesigned/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh63c1/p_paperlib_an_opensource_and_moderndesigned/</guid>
      <pubDate>Sun, 17 Mar 2024 19:24:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>