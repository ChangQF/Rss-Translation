<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Wed, 06 Mar 2024 18:16:52 GMT</lastBuildDate>
    <item>
      <title>[D] 最新/最新的 TTS/RVC 设置 + 获得语调/情感的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b863xv/d_latest_most_up_to_date_tts_rvc_setup_ways_to/</link>
      <description><![CDATA[不确定这是否是最好的帖子，但我在这里看到了类似的帖子...  我&#39;一直在使用像 xtts 或 bark（通过 coqui tts）这样的语音克隆器，它们有点......嗯......（有时很好，有时不好，当进行大量文本到语音转换时 - 大多数输出缺少单词甚至整个句子）。  我什至尝试微调 xtts (v2)，尽管声音变得更好，但输出却更差（总是缺少单词，有时甚至整个段落）。  所以我开始摆弄 rvc，它看起来更好 - 但我有一些问题。  有用于推理/训练的 GUI 吗？为了更快的设置？我发现了这个： https://github.com/SayanoAI/RVC-Studio - 但它有点错误（无法训练与它） 或者如果有一个基本的代码设置我可以用来训练和进行推理（我需要做批量文件）。  此外，我不知道是否可以使用 RVC 做一件事：向输出语音添加情感/语调。如果使用一些基本的 TTS 创建输入语音，则语音将是平淡的 - RVC 语音是否能够为平淡的 TTS 语音添加适当的情感？或者实现这一目标的最佳设置是什么？    由   提交 /u/yupignome   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b863xv/d_latest_most_up_to_date_tts_rvc_setup_ways_to/</guid>
      <pubDate>Wed, 06 Mar 2024 17:47:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我如何开始学习 ML/DL</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b85sdm/d_how_do_i_start_learning_mldl/</link>
      <description><![CDATA[嘿，我是第二世界国家的学生，我们最近有大学有机会教授人工智能、数据科学和网络安全等知识.我选择人工智能作为我的领域，因为当时我很困惑XD现在我在第三学期（今天有最后一次期末考试，所以现在技术上我在第四学期），我们已经学习了 Python 基础知识、编程基础知识（C 语言）、IICT 和 OOPS 等内容。现在我想学习一些人工智能生成的东西。我确实参加了吴恩达的课程“机器学习专业化”，而且它还在继续，我已经学会了线性回归。问题是，哪个那里有具体的课程/资源，我应该成为哪些技术的专家，成为工业专业人士并找到一份体面的工作？   由   提交/u/ASHTaG0001   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b85sdm/d_how_do_i_start_learning_mldl/</guid>
      <pubDate>Wed, 06 Mar 2024 17:35:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 拥抱Android Studio（颤振）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b825eg/d_hugging_face_to_android_studio_flutter/</link>
      <description><![CDATA[有没有人尝试过在 android studio 上制作一个应用程序，在其中与拥抱面部推理 api 或端点进行通信？  我需要帮助，我在拥抱脸部模型的帮助下构建了一个移动聊天机器人，但我找不到任何关于如何做到这一点的教程（我是初学者），而该聊天机器人适用于我的顶点项目。 &gt;   由   提交/u/HarryPottahh  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b825eg/d_hugging_face_to_android_studio_flutter/</guid>
      <pubDate>Wed, 06 Mar 2024 15:13:56 GMT</pubDate>
    </item>
    <item>
      <title>[D][R]强化学习的最新进展</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b81pkt/drrecent_developments_in_reinforcement_learning/</link>
      <description><![CDATA[我正在尝试进入强化学习领域，并且刚刚完成了 Sutton 和 Barto 的课程以及 YT 的一门课程。只是想知道目前在这个主题上正在做什么（调查论文/书会很好）。还想知道常用的数据集类型。我学习的课程本质上是完全理论性的，所以我也想知道目前这个领域使用什么工具包。   由   提交/u/ANI_phy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b81pkt/drrecent_developments_in_reinforcement_learning/</guid>
      <pubDate>Wed, 06 Mar 2024 14:56:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么训练 TTS 模型时我的 eval_avg_loss 仍然很高？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b811it/d_why_is_my_eval_avg_loss_still_pretty_high_when/</link>
      <description><![CDATA[我指的是 xTTTSv2.0。它使用 DVAE 来计算音频标记，并使用 GPT2 后端根据输入文本、来自 DVAE 的音频标记以及由一堆自注意力层计算出的说话者潜伏来预测下一个音频标记。  我一直在我自己的数据集上对其进行微调（总内容约 1 小时），在开始训练之前，我似乎无法获得低于 3.12 的 eval_avg_loss 值，并且它会上升到类似的值5.8. 为什么会发生这种情况？仅仅是因为我正在处理音频语音数据吗？我一直在查看用于文本模型训练的损失图图像，一段时间后它们似乎即将达到小数值（0.1-0.9）。但我的模型在大约 10,000 步后开始过度训练。请解释为什么会发生这种情况。    由   提交/u/M000lie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b811it/d_why_is_my_eval_avg_loss_still_pretty_high_when/</guid>
      <pubDate>Wed, 06 Mar 2024 14:28:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 声音/声音的数学。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7zp4p/p_mathematics_for_soundsvoices/</link>
      <description><![CDATA[大家好，请推荐一本包含声音/语音算法所需数学知识的书。 我看过傅里叶写的书很多，但方法非常数学化。其他人是关于信号的，但他们的重点是电子工程。 谢谢。   由   提交 /u/gcombar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7zp4p/p_mathematics_for_soundsvoices/</guid>
      <pubDate>Wed, 06 Mar 2024 13:28:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为 ML 工程师，我如何变得更好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7y0uy/d_how_do_i_get_better_as_ml_engineer/</link>
      <description><![CDATA[完成 ML 专业化 MS 课程后，我已正式转任公司的 ML 角色。我现在面临两个挑战：  我的团队中没有其他经验丰富的机器学习工程师可以学习。  我有 12 年的工作经验，所以对我的期望是像高级机器学习工程师一样工作。我在 GenAI 方面处于领先地位，但在 ML 或 DL 相关项目方面则不然。  我如何规划工作、个人学习等，以便随着时间的推移我可以变得更好？  过去的工作：主要是 Microsoft 技术堆栈、.net、SharePoint、O365 等   由   提交 /u/vikbehal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7y0uy/d_how_do_i_get_better_as_ml_engineer/</guid>
      <pubDate>Wed, 06 Mar 2024 12:03:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最近有推荐的视频生成论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7v3qx/d_any_recommended_recent_video_generation_papers/</link>
      <description><![CDATA[我想学习视频生成。我已经对 GAN、VAE、DPM 有了一些经验。但不是视频。  我的论文主要关注的是视频生成，我正在寻找视频合成论文的最新（最多 3-4 年前）发展。不像 Sora 那样是闭源的，而是真正的开源模型或项目。 我想学习一切：时间、空间凝聚力、像素预测模型、逐帧生成等等。  例如，我知道 DVD-GAN 很好，但不是最近的（2019 年）。 甚至可能是调查论文，所以我可以感受到每个模型在高层中所做的事情.   由   提交 /u/ShlomiRex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7v3qx/d_any_recommended_recent_video_generation_papers/</guid>
      <pubDate>Wed, 06 Mar 2024 08:54:57 GMT</pubDate>
    </item>
    <item>
      <title>[D]为什么 Hugging Face 没有成为桌面上最有前途（且年轻）的 AI 聊天机器人玩家之一（如 Mistral AI、Anthropic、Perplexity AI 等）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7t35y/dwhy_isnt_hugging_face_becoming_one_of_the/</link>
      <description><![CDATA[我记得几年前人们讨论HF的商业模式是什么或者如何盈利。 我认为现在是对他们来说这是最好的时光，但我有点惊讶他们没有创造自己的时光。 他们有才华、经验和资源。只是想知道。   由   提交 /u/xiikjuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7t35y/dwhy_isnt_hugging_face_becoming_one_of_the/</guid>
      <pubDate>Wed, 06 Mar 2024 06:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[N] Groq AMA - 3 月 6 日中午（太平洋标准时间）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7o5u4/n_groq_ama_march_6_noon_pst/</link>
      <description><![CDATA[加入 Igor Arsovski，首席架构师兼首席架构师研究员和 ML 编译器高级总监 Andrew Ling 于太平洋标准时间 3 月 6 日中午参加了有关 Groq 硬件和软件的 AMA。 https://discord.com/invite/rfVBfxyX?event=1214271926164389929 请提交通过我们的 discord    提前提出问题由   提交/u/turtlespy965   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7o5u4/n_groq_ama_march_6_noon_pst/</guid>
      <pubDate>Wed, 06 Mar 2024 02:26:47 GMT</pubDate>
    </item>
    <item>
      <title>[N] OpenAI 居住申请今天再次在旧金山开放，截止日期为 3 月 11 日</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7o4f1/n_openai_residency_applications_have_opened_again/</link>
      <description><![CDATA[我前段时间对此很感兴趣，但当时他们关闭了，所以我设置了一个站点差异警报，今天它通知了我，所以我检查过，他们正在再次招聘。 对于有才华的非 AI 人员来说，这是一个绝佳的机会，可以在 OpenAI 获得全额工资的同时过渡到 AI。 对我个人来说，这不是合适的时机申请，但我想如果你们有兴趣的话我可以与大家分享。祝申请顺利！ https://openai.com/careers/openai-residency   由   提交/u/ixam1212  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7o4f1/n_openai_residency_applications_have_opened_again/</guid>
      <pubDate>Wed, 06 Mar 2024 02:25:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 2024 支持主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7lnv0/d_icml_2024_support_thread/</link>
      <description><![CDATA[为提交至 ICML 2024 的每个人开设一个线程作为支持小组。审核将于 3 月 20 日发布（如果没有延迟）。 如果您收到任何评论，如果您特别讨厌一位评论者，或者喜欢另一位评论者，请告诉我们。一切皆有可能！   由   提交 /u/Adventurous-Cut-7077   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7lnv0/d_icml_2024_support_thread/</guid>
      <pubDate>Wed, 06 Mar 2024 00:32:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 2023年300+ML比赛分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b79bqq/r_analysis_of_300_ml_competitions_in_2023/</link>
      <description><![CDATA[      我运行 mlcontests.com，这是一个网站列出了跨多个平台的 ML 竞赛，包括 Kaggle/DrivenData/AIcrowd/CodaLab/Zindi/EvalAI/… 我刚刚完成了对 300 多个 ML 竞赛的详细分析2023 年，包括查看其中 65 个获奖解决方案。 一些亮点：  正如预期的那样，几乎所有获奖者都使用 Python 。一名获胜者使用 C++ 解决性能至关重要的优化问题，另一名获胜者使用 R 进行时间序列预测竞赛。 92% 的深度学习解决方案使用 PyTorch。我们发现剩下的 8% 使用 TensorFlow，并且所有这些都使用了更高级别的 Keras API。大约 20% 的获胜 PyTorch 解决方案使用 PyTorch Lightning。 基于 CNN 的模型比基于 Transformer 的模型赢得更多计算机视觉竞赛。 在 NLP 领域，毫不奇怪，生成式法学硕士开始被使用。一些竞赛获胜者使用它们来生成用于训练的合成数据，其他人则提出了创造性的解决方案，例如向开放权重法学硕士添加分类头并对其进行微调。还有更多专门针对 LLM 微调的竞赛正在推出。 与去年一样，梯度增强决策树库（LightGBM、XGBoost 和 CatBoost）仍然被广泛使用 由竞赛获胜者评选。 LightGBM 比其他两者稍微流行一些，但差异很小。 计算使用情况差异很大。 NVIDIA GPU 显然很常见；一些获奖者使用了 TPU；我们没有发现任何使用 AMD GPU 的获胜者；有些人仅在 CPU 上训练他们的模型（尤其是时间序列）。一些获奖者通过工作/大学获得了强大的（例如 8x A6000/8x V100）设置，一些获奖者在本地/个人硬件上进行了全面培训，相当多的获奖者使用了云计算。 有相当多的高- 2023 年的概况竞赛（我们详细介绍维苏威火山挑战赛和M6 预测），以及 2024 年即将举办的更多比赛（维苏威火山挑战赛第二阶段、AI 数学奥林匹克、AI 网络挑战赛） )  有关更多详细信息，请查看完整报告：https://mlcontests.com/state-of-competitive-machine-learning-2023?ref=mlc_reddit ​ 获奖者中最常用的一些 Python 软件包&lt; /p&gt; 在我的 r/MachineLearning 帖子中 去年关于 2022 年比赛的相同分析，热门评论之一询问了时间序列预测。 2023 年有几个有趣的时间序列预测竞赛，我设法对它们进行了相当深入的研究。跳至报告的此部分以了解这些内容。 （不同类型的时间序列竞赛的获胜方法有很大差异 - 包括 ARIMA 等统计方法、贝叶斯方法，以及 LightGBM 和深度学习等更现代的 ML 方法。） 我能够花费相当多的时间感谢今年报告的赞助商：Latitude.sh（配备专用 NVIDIA H100/A100/L40s GPU 的云计算提供商）和 Comet（有用的工具），我们花费了大量时间进行研究和撰写用于 ML - 实验跟踪、模型生产监控等）。我不会在这里向您发送垃圾邮件链接，报告底部有更多详细信息！   由   提交 /u/hcarlens   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b79bqq/r_analysis_of_300_ml_competitions_in_2023/</guid>
      <pubDate>Tue, 05 Mar 2024 16:22:52 GMT</pubDate>
    </item>
    <item>
      <title>[N] Nvidia 禁止像 ZLUDA 这样的翻译层</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b70ubo/n_nvidia_bans_translation_layers_like_zluda/</link>
      <description><![CDATA[最近我在这个子论坛上看到了帖子，人们讨论了使用非 Nvidia GPU 进行机器学习。例如，ZLUDA 最近因在 AMD GPU 上启用 CUDA 应用程序而受到关注。现在 Nvidia 不喜欢这样，并禁止在 CUDA 11.6 及更高版本中使用转换层。 https://www.tomshardware.com/pc-components/gpus/nvidia-bans-using-translation-layers-for -cuda-software-to-run-on-other-chips-new-restriction-apparently-targets-zluda-and-some-chinese-gpu-makers#:\~:text=Nvidia%20has%20banned%20running%20CUDA ,system%20during%20the%20installation%20process。   由   提交/u/_d0s_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b70ubo/n_nvidia_bans_translation_layers_like_zluda/</guid>
      <pubDate>Tue, 05 Mar 2024 09:00:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>