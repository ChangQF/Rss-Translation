<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 01 Apr 2024 18:16:03 GMT</lastBuildDate>
    <item>
      <title>Q*：教授法学硕士解决简单的数学方程 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btavo8/q_teaching_llms_to_solve_simple_mathematical/</link>
      <description><![CDATA[OpenAI 似乎取得了突破。法学硕士现在可以做数学了！ [Q*：一种可以捕获文本中隐含关系的高效模型架构]( https://www.youtube.com/watch?v=dQw4w9WgXcQ))   由   提交/u/New-Horse8698   reddit.com/r/MachineLearning/comments/1btavo8/q_teaching_llms_to_solve_simple_mathematical/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btavo8/q_teaching_llms_to_solve_simple_mathematical/</guid>
      <pubDate>Mon, 01 Apr 2024 18:06:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] NanoDL：在 JAX/Flax 上构建 Transformers 和法学硕士的库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btab31/d_nanodl_library_for_building_transformers_llms/</link>
      <description><![CDATA[大家好，我想分享一个简单的示例，说明如何使用 NanoDL 库构建自定义模型。我很想听听您对该项目的想法。 ```py import jax import jax.numpy as jnp from nanodl import time_rng_key from nanodl import ArrayDataset, DataLoader from nanodl import GPT4, GPTDataParallelTrainer, Tokenizer&lt; /p&gt; 准备数据集 batch_size = 8 max_length = 50 vocab_size = 1000 text_paths = [&#39;/path/sample1.txt&#39;, &#39;/path/sample2.txt&#39; txt&#39;, &#39;/path/sample3.txt&#39;] tokenizer = Tokenizer(training_data=text_paths, vocab_size=vocab_size, model_type=&#39;bpe&#39;, max_sentence_length=max_length) data = [] for path in text_paths: with open(path, &#39;r&#39;) as file: text = file.read() # 待办事项：按照您希望的方式预处理编码 = list(map(tokenizer.encode, text)) 数据。扩展（编码） 填充并移动以创建下一个标记预测数据集 max_length = max(len(seq) for seq in data) data = jnp.array([seq + [0] * (max_length - len(seq)) for seq in data]) dummy_inputs, dummy_targets = data[:, :-1], data[:, 1:] dataset = ArrayDataset(dummy_inputs ，dummy_targets）dataloader = DataLoader（数据集，batch_size=batch_size，shuffle=True） hyperparams = { &#39;num_layers&#39;：1，&#39;hidden_​​dim&#39;：256，&#39;num_heads&#39;：2，&#39;feedforward_dim&#39;：256 , &#39;dropout&#39;: 0.1, &#39;vocab_size&#39;: vocab_size, &#39;embed_dim&#39;: 256, &#39;max_length&#39;: max_length, &#39;start_token&#39;: 0, &#39;end_token&#39;: 50, } model = GPT4(* *hyperparams) trainer = GPTDataParallelTrainer(model,dummy_inputs.shape,&#39;params.pkl&#39;) trainer.train(train_loader=dataloader, num_epochs=100, val_loader=) start_tokens = jnp.array ([[123, 456]]) params = trainer.load_params(&#39;params.pkl&#39;) 输出 = model.apply({&#39;params&#39;: params}, start_tokens, rngs={&#39;dropout&#39;: time_rng_key()}, method =model.generate) outputs = tokenizer.decode(outputs.tolist()) ``` NanoDL 的功能：  广泛的选择Gemma、LlaMa2、Mistral、GPT、Diffusion、GAT、CLIP 等模型。 数据并行分布式训练器，包括用几行代码进行训练。 数据加载器，制作数据对 Jax/Flax 的处理更加简单有效。 Flax/Jax 中未找到的自定义层，例如 RoPE、GQA、MQA、SWin 注意力、GPTBlock 等。 GPU/TPU -加速经典机器学习模型，如 PCA、KMeans、高斯过程等。 Jax 中的真正随机数生成器，不需要详细代码。 用于 NLP 和计算机视觉任务的算法，例如高斯模糊、BLEU、Tokenizer 等。  项目仓库：https://github。 com/HMUNACHI/nanodl （如果觉得慷慨，请留下一颗星！）   由   提交 /u/Henrie_the_dreamer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btab31/d_nanodl_library_for_building_transformers_llms/</guid>
      <pubDate>Mon, 01 Apr 2024 17:45:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在我的工作场所中，还有其他人无法摆脱 OpenAI 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt9y8p/d_cant_escape_openai_in_my_workplace_anyone_else/</link>
      <description><![CDATA[我们能具体谈谈 OpenAI 现在是如何被每个工作场所、客户和他们的祖母强行灌输给我们的吗？最近，我收到的专门使用 OpenAI API 的请求数量猛增。你们对此有什么经验？你如何导航它？我尝试过提出其他替代方案，但不行，他们执意要使用 OpenAI。  OpenAI 成立的明确目的是实现人工智能的民主化，并通过开发开源工具来平衡大型科技的封闭世界。他们完全放弃了这个想法。在这个领域，一种令人恐惧的做法（OpenAI 的创建实际上是为了防止这种做法）是由营利性公司组成的单一或寡头集团为我们做出这一决定。 别理解我的意思开始的事实是，他们的模型是使用谦虚的人的工作来训练的，而这些人永远不会为此得到一分钱。 我觉得被迫与这个令人厌恶的模型一起工作，但我也没有真正的选择。这就是我们许多人支付账单的方式。我是一个人吗？难道我就该放下我的骄傲吗？    由   提交/u/AlphaSquared_io   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt9y8p/d_cant_escape_openai_in_my_workplace_anyone_else/</guid>
      <pubDate>Mon, 01 Apr 2024 17:31:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一些适合顶点学生的好利基研究主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt9ujp/d_some_good_niche_research_topics_for_a_capstone/</link>
      <description><![CDATA[嗨，我是一名计算机科学专业的学生，​​在我的专业中专注于机器学习和人工智能，现在我需要开始思考以下主题：不幸的是，我的学校没有很好的资源，所以我只能使用笔记本电脑上的 GPU，所以我的研究主题理想情况下应该是不需要太多培训的内容。我的主要目标是从中得出一篇研究论文，因此小众、未充分探索的主题也能很好地发挥作用。 ​ 你们知道 ML 和 AI 领域的任何主题吗？符合这些标准？谢谢   由   提交/u/DBT177  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt9ujp/d_some_good_niche_research_topics_for_a_capstone/</guid>
      <pubDate>Mon, 01 Apr 2024 17:27:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] Stale Diffusion：使用老式方法生成超现实 5D 电影</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt9u0o/p_stale_diffusion_hyperrealistic_5d_movie/</link>
      <description><![CDATA[大家好， 我想请求对我们关于 Stale Diffusion 的新论文的反馈，Stale Diffusion 是 Stable 的一个极限情况当发行版混合得太多时的扩散。 https://www .robots.ox.ac.uk/~joao/publications/sigbovik24.pdf 不知何故，即使是不严肃的场所也没有认真对待它，甚至 arXiv 也对它嗤之以鼻。给什么？！ 最好， 作者   由   提交 /u/brainggear   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt9u0o/p_stale_diffusion_hyperrealistic_5d_movie/</guid>
      <pubDate>Mon, 01 Apr 2024 17:27:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据有限时深度学习中的特征工程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt5hzq/d_feature_engineering_in_deep_learning_when_the/</link>
      <description><![CDATA[我读到，深度学习的特征工程可以限制神经网络能够学习的数量，如果有大量数据，这是有意义的。&lt; /p&gt; 但是如果数据有限怎么办？在这种情况下，特征工程是否会有所帮助，以便网络不必依赖大量数据来从噪声中了解哪些特征是有用的？   由   提交 /u/notEVOLVED   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt5hzq/d_feature_engineering_in_deep_learning_when_the/</guid>
      <pubDate>Mon, 01 Apr 2024 14:41:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 可扩展且面向 ML 的 Google Drive 替代 Google Colab</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt5hxw/p_scalable_and_mloriented_google_drive/</link>
      <description><![CDATA[      嘿 r/ml！来自 DagsHub 的 Dean。 TL;DR 我们正在与 Google Colab 合作并推出 DagsHub存储桶是兼容 S3 的 Google Drive 替代品，专为 ML 工作流程而构建，并可从头开始扩展。它是免费的，因此您今天就可以开始使用它，我们很乐意听到您的反馈。 这是演示笔记本： https://colab.research.google.com/#fileId=https% 3A//dagshub.com/DagsHub/DagsHubxColab/raw/main/DagsHub_x_Colab-DagsHub_Storage.ipynb --- 我想分享一些我们已经分享的东西我们已经为那些与 Colab 合作的人努力了一段时间了。我知道很多人使用 Colab 进行机器学习工作（我的大多数项目也是如此）。不久前，我们与 Colab 共享了一个集成，让您可以在 Colab 中打开来自 DagsHub 的存储库，并将其保存回来使用一个命令（类似于 GitHub）。 很多时候，当您需要处理更大的数据集时，并且由于 Colab 的短暂性，您最终会使用 Google Drive 作为数据集的持久存储。这对于简单的用例来说非常有用，但往往不稳定并且抛出错误，这使得将其用于更严肃的项目具有挑战性。下一个业务顺序往往是创建 AWS 帐户和 S3 存储桶，但这通常是一个巨大的麻烦，特别是如果您想与其他人共享它，并且需要信用卡。 这就是我们的原因内置 DagsHub 存储桶。它是一个与 S3 兼容的存储，每个 DagsHub 项目都附带（免费），具有简单易用的访问控制、用于查看文件和与他人共享的出色 UI，现在与 Colab 完全集成，让您可以安装并使用它作为 GDrive 的直接替代品。所有这一切都是为了更大规模的工作流程而构建的。 如果您比示例笔记本更喜欢它，我写了一篇博客 - 请在此处查看：https://dagshub.com/blog/dagshub-storage-google-drive-colab/ 我很好奇听听您对此的想法和反馈，以及您还希望看到哪些其他内容... https： //i.redd.it/xgjacauhfvrc1.gif ​   由   提交/u/PhYsIcS-GUY227  /u/PhYsIcS-GUY227 reddit.com/r/MachineLearning/comments/1bt5hxw/p_scalable_and_mlorient_google_drive/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt5hxw/p_scalable_and_mloriented_google_drive/</guid>
      <pubDate>Mon, 01 Apr 2024 14:41:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 比 rembg 更好地从图像中去除背景的 Python 代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt2q7x/d_python_code_to_remove_background_from_image/</link>
      <description><![CDATA[我创建了一个 python 库“dis-bg-remover”基于“高精度二分图像分割” (https://arxiv.org/pdf/2203.03041.pdf)，其结果与市场上的优质产品。请告诉我您的反馈和建议？ 此处有解释视频 https: //www.youtube.com/watch?v=js7AYKkZvFI 查看视频中的参考图像，其中输出与 CapCut 的输出进行比较..这是来自 rembg https://ibb.co/mFnr1dG   由   提交 /u/Maleficent_Yak_993   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt2q7x/d_python_code_to_remove_background_from_image/</guid>
      <pubDate>Mon, 01 Apr 2024 12:42:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] RAGFlow，基于深度文档理解的#rag引擎开源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt1ky8/p_ragflow_the_deep_document_understanding_based/</link>
      <description><![CDATA[https://github.com/infiniflow/ragflow   由   提交/u/Vissidarte_2021   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt1ky8/p_ragflow_the_deep_document_understanding_based/</guid>
      <pubDate>Mon, 01 Apr 2024 11:47:00 GMT</pubDate>
    </item>
    <item>
      <title>[N] 开源 1.3B 多功能模型和库：SQL 生成、代码解析、文档和带指令传递的函数调用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt0vg9/n_open_source_13b_multicapabilities_model_and/</link>
      <description><![CDATA[pip-library-etl- 1.3b：是我们最先进的库的最新版本，其性能可与 GPT-3.5/ChatGPT 相媲美。 ​  pip-library-etl：用于代码库、函数调用和 SQL 生成的自动化文档和动态分析的库在自然语言测试用例上，该库利用 pip-library-etl-1.3b 来简化文档、动态分析代码并轻松生成 SQL 查询。 ​ 主要功能包括： ​  16.3k 上下文长度 自动库解析和代码文档 示例调整（无需重新训练；每当模型的输出偏离预期时提供正确输出的示例） 函数的静态和动态分析 函数调用 SQL生成 自然语言指令支持    由   提交 /u/Swimming-Trainer-866   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt0vg9/n_open_source_13b_multicapabilities_model_and/</guid>
      <pubDate>Mon, 01 Apr 2024 11:08:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] UAI 2024 审核等候处</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt0nor/d_uai_2024_reviews_waiting_place/</link>
      <description><![CDATA[一个分享你的想法、祈祷的地方，最重要的是（一旦评论出来），咆哮甚至一些宽慰的评论。    由   提交/u/elemintz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt0nor/d_uai_2024_reviews_waiting_place/</guid>
      <pubDate>Mon, 01 Apr 2024 10:57:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML 装备的硬件建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsz0nz/d_hardware_advice_for_ml_rig/</link>
      <description><![CDATA[在我大学的实验室中，我们正在构建一个机器学习工作站。我们的预算有点低，所以我们正在努力使其尽可能具有成本效益。我们正在考虑二手零件。我们的最高预算是 4,900 美元。如果我们能花更少的钱得到它，我们会很高兴。我们有 3 个主板 + cpu 组合选项：  -Ryzen 9 7950X3d + X670E  -Threadripper 3000 系列 + Trx 40 主板  -Intel i9 10980XE + X299主板 作为主板+CPU组合，你会得到什么？请注意，该系统将与至少 1 个 RTX 4090 或可能更多配对。    由   提交/u/DaOzy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsz0nz/d_hardware_advice_for_ml_rig/</guid>
      <pubDate>Mon, 01 Apr 2024 09:21:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为特定领域创建您自己的语言模型（即文本编码器）。什么时候值得这样做？您应该注意什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bst5y2/d_creating_your_own_language_model_ie_text/</link>
      <description><![CDATA[我最近为时尚领域制作了自定义 BERT 和 ELECTRA 模型，它们也可以处理英语和我自己的母语（我不在美国） 。我注意到性能没有我预期的那么好，觉得不值得。 是否有任何论文或资源说明何时值得从头开始创建自己的预训练 LM ？我记得很久以前读过一篇生物医学领域的论文，标题为生物医学和临床任务的预训练语言模型：理解和扩展最先进的技术（Lewis 等人，2020） 似乎表明从头开始进行预训练可以帮助完成生物医学和临床任务，但我不确定是否还有其他方法那里有论文。 此外，在评估新的预训练 LM 时是否有任何提示或值得了解的事情？例如，检查 OOV 率等。 提前致谢。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bst5y2/d_creating_your_own_language_model_ie_text/</guid>
      <pubDate>Mon, 01 Apr 2024 03:12:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 ML 作品集中，什么更令人印象深刻：实施一篇论文还是创建一个好的项目？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsezcf/d_whats_more_impressive_in_a_ml_portfolio/</link>
      <description><![CDATA[大家好，从您的经验来看，公司的招聘经理更喜欢什么，是出色的论文实施还是出色的实际项目？我知道两者都有很大的好处、优点和缺点等。但是，reddit 上的管理者在查看回购协议时喜欢看到什么？在考察候选人的技能时，其中一个会比另一个更好吗？   由   提交 /u/ninvibe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsezcf/d_whats_more_impressive_in_a_ml_portfolio/</guid>
      <pubDate>Sun, 31 Mar 2024 16:51:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>