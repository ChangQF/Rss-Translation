<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 19 Mar 2024 21:11:16 GMT</lastBuildDate>
    <item>
      <title>训练分割非常慢[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bitvtz/training_split_very_slow_r/</link>
      <description><![CDATA[      大家好！我正在维基百科数据集上微调 mbert，加载了数据集（拥抱脸） https://preview.redd.it/kaw1kmrtjcpc1.png?width=1944&amp;format=png&amp;auto=webp&amp;s=818740eebd72dc13ad35a30b384a122b79 866f3c 这个是提交到 Slurm 的 bash 脚本（删除了不相关的行）：    /bin/bashLANG=ka &lt; /blockquote&gt;  #SBATCH -o .../examples/language-modeling/slogs/sl_ka1_%A.out #SBATCH - e .../examples/language-modeling//slogs/sl_ka1_%A.out #SBATCH -N 1 # 个请求的节点 &lt; p&gt;#SBATCH -n 1 # 请求的任务 #SBATCH --gres=gpu:8 # 使用 1 个 GPU #SBATCH --mem=60000 # 内存（以 Mb 为单位） #SBATCH --partition=PGR-Standard &lt; code&gt;#SBATCH -t 24:00:00 # 请求的时间（以小时:分钟:秒为单位） #SBATCH --cpus-per-task=16 # 要使用的 cpu 数量使用 - 每个节点上有 32 个 torchrun --nproc_per_node 8 run_mlm.py \ --model_name_or_path bert-base-multilingual-cased \ --cache_dir **${CACHE_HOME}**2\ --dataset_lang ${LANG} \ --dataset_name 维基百科 \  --output_dir ${OUTPUT_DIR} \ --do_train \ --do_eval \ --per_device_train_batch_size 4 \ --per_device_eval_batch_size 4 \ --gradient_accumulation_steps 2 \ --max_seq_length 256 \ - -overwrite_output_dir \ --ft_params_num 7667712 \ --evaluation_strategy 步骤 \ --eval_steps 1000 \ --dataloader_num_workers 32 \ --preprocessing_num_workers 32 \ --validation_split_percentage 5 \ --load_best_model_at_end \ --save_total_limit 2 &gt;  这是速度报告，非常慢。  正在下载数据：100%|████████ ██| 14.1k/14.1k [00:00&lt;00:00, 14.0MB/s] 下载数据：100%|██████████| 205M/205M [00:44&lt;00:00, 4.59MB/s]  生成列车分割：0 个示例 [00:00, ? example/s]从.../language-modeling/cache_directory22/downloads/f797c17d35d578a4c1a3f251847095789ec04ae453f10623aeb8366ff4797a07中提取内容 生成列车分割：170787个示例[17:57, 158.45个示例/s]  提前非常感谢您   由   提交 /u/Choricius   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bitvtz/training_split_very_slow_r/</guid>
      <pubDate>Tue, 19 Mar 2024 20:08:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 Transformer 在每层使用相同维度的嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bit2f9/d_why_do_transformers_use_embeddings_with_the/</link>
      <description><![CDATA[我的直觉是，随着我们在层中移动，令牌会逐渐丰富，但这意味着我们需要在每个令牌中存储更少的信息前面的层比后面的层要多。 从（相对）低维嵌入开始，然后将它们投影或扩展到更高的维度，直到它们达到最终大小，这不是有意义吗？    由   提交/u/timtom85  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bit2f9/d_why_do_transformers_use_embeddings_with_the/</guid>
      <pubDate>Tue, 19 Mar 2024 19:35:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Python 从 PDF 中提取文本，同时保持结构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bisi8p/d_extracting_text_from_pdfs_with_python_while/</link>
      <description><![CDATA[大家好！ 我正在处理一堆原生 PDF 格式的医疗发票，我需要提取文本，同时保持原始结构，特别是表格格式。使用某些 Python 库，我能够提取文本，但它会丢失预期的格式。 当我使用某些 Python 库时，提取的文本会丢失其结构。例如： Oliver Smith Green St. 12 1356 Fayetteville [更多详细信息...] 1 治疗 A 12,31 1 治疗 B 19,00 总净值 19 % 欧元 54,96 19 %税费 10,44 欧元 总计 65,40 欧元 支付 65,40 欧元 [更多详细信息...]  我的目标是这样的： Oliver Smith Green St. 12 1356 Fayetteville [更多详细信息...] 1 治疗 A 12,31 1 治疗 B 19,00 总净收入 19 % 欧元 54,96 19 % 税收 10,44 欧元 10,44 总计 65 欧元， 40 支付 65,40 欧元 [更多详细信息...]  我使用 pdfplumber 得到了一些有希望的结果，但表格打印了两次，这并不理想。这是我正在使用的代码片段： import pdfplumber pdf_path = &quot;path/to/your/pdf&quot; with pdfplumber.open(pdf_path) as pdf: 对于 pdf.pages 中的页面：text = page.extract_text() print(text) 表格 = page.extract_tables() 对于表中的表：对于表中的行： print(&quot; &quot; ;.join([str(cell) for cell in row if cell])) print()  结果是： Oliver Smith Green St. 12 1356 Fayetteville [更多详情...] 1 治疗 A 12,31 1 治疗 B 19,00 总净额 19 % 欧元 54,96 19 % 税 欧元 10,44 总计 65,40 欧元 已付 65,40 欧元 [更多详细信息...] 1 治疗 A 12,31 1 治疗 B 19,00 净总净额 19 % 欧元 54,96 19 % 税费 10,44 欧元 总计 65,40 已付 65,40 欧元  有人对如何改进这种提取过程以更好地维护结构有建议吗？我不仅希望提取表格，还希望提取其他文本元素（例如客户地址），同时保持格式尽可能接近原始格式。 提前感谢您的帮助！ &lt; /div&gt;  由   提交 /u/4AVcnE   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bisi8p/d_extracting_text_from_pdfs_with_python_while/</guid>
      <pubDate>Tue, 19 Mar 2024 19:13:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 2024 讨论主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bireik/d_icml_2024_discussion_thread/</link>
      <description><![CDATA[这篇文章用于讨论与 ICML 2024 相关的任何内容，评论将于明天发布！祝所有参与者好运！   由   提交/u/condom-mechanics  /u/condom-mechanics  reddit.com/r/MachineLearning/comments/1bireik/d_icml_2024_discussion_thread/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bireik/d_icml_2024_discussion_thread/</guid>
      <pubDate>Tue, 19 Mar 2024 18:29:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 迈向白盒深度学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biq9pc/r_towards_white_box_deep_learning/</link>
      <description><![CDATA[我提出了一个用于构建本质上可解释的神经网络的概念框架。 MNIST 子问题的 PoC 4 层模型可以被视为白盒：决策边界很容易解释，并且该模型对对抗性攻击具有鲁棒性 - 尽管没有任何形式的对抗性训练！ 该方法本质上是简化为如何在网络层内共享权重以实现高度可解释和鲁棒的特征的一般概念。它的一般性质和有效性表明，对于更复杂的数据集和不同的模式应该有可能获得类似的结果 - 这为进一步研究开辟了令人兴奋的领域！ 迫不及待想听到您的反馈！  p&gt; https://arxiv.org/abs/2403.09863   由   提交/u/Swarzkopf314  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biq9pc/r_towards_white_box_deep_learning/</guid>
      <pubDate>Tue, 19 Mar 2024 17:42:43 GMT</pubDate>
    </item>
    <item>
      <title>确定增加成本 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biq8p5/identify_increase_cost_d/</link>
      <description><![CDATA[大家好！ 我是这个领域的新手，目前正在开始我的旅程。我最近一直在思考的一个问题是组织如何使用机器学习来识别成本增加？在这种特定情况下，与前一年相比，它适用于手术用品，但它可能适用于大多数行业。 提取原始数据并进行分析以了解哪些用品/植入物非常简单成本更高，但这通常发生在问题真正普遍之后。成本通常按手术类型、外科医生和制造商分层。及早发现这一点可能会节省大量资金，因此一些投资回报率似乎是可能的。我猜某种异常/离群值检测是一种方法。 每个人对可能使用的模型有何想法，或者您还有哪些其他方法来解决这个问题？  &gt;TIA！   由   提交/u/avb0101  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biq8p5/identify_increase_cost_d/</guid>
      <pubDate>Tue, 19 Mar 2024 17:41:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我如何在 Google Gemma 6T 代币模型中发现 8 个错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bipsqj/p_how_i_found_8_bugs_in_googles_gemma_6t_token/</link>
      <description><![CDATA[      嘿 r/MachineLearning！也许您可能在 Twitter 上看到过我发帖，但如果您不知道 8 个错误，我就在这里发帖在 Google Gemma 的多个实现中:) 修复应该已经被推送到 HF 的 Transformers 主分支中，而 Keras、Pytorch Gemma、vLLM 应该已经得到修复:) https://github.com/huggingface/transformers/pull/29402 通过比较5个实现，我发现了以下问题：  必须添加否则损失会很大。 技术报告中的模型有一个拼写错误！ sqrt(3072)=55.4256，但 bfloat16 是 55.5。  Layernorm (w+1) 必须采用 float32。 Keras mix_bfloat16 RoPE 错误。 RoPE 对 y*(1/x) 与 y/x 敏感。 RoPE 对 y*(1/x) 与 y/x 敏感。 &gt; RoPE 应该是 float32 - 已经推送到变压器 4.38.2。 GELU 应该是近似 tanh，而不是精确的。  添加所有这些更改允许 Log L2 Norm 从红线减少到黑线（越低越好）。请记住这是对数刻度！所以误差从 10_000 减少到现在的 100 - 系数 100！这些修复主要针对长序列长度。 https://preview.redd.it/cocy1pknrbpc1.jpg?width=878&amp;format=pjpg&amp;auto=webp&amp;s=8e837bf2a62726c24540981fae6c409d2681ece7 最引人注目的是添加 BOS 代币微调运行可以在开始时抑制训练损失。没有BOS会导致损失变得非常高。 https://preview.redd.it/zkcjyfcorbpc1.jpg?width=1075&amp;format=pjpg&amp;auto=webp&amp;s=0925192d49a5e30a527f4235ccb006abf2670205 另一个非常有问题的问题是 RoPE 嵌入在 bfloat16 而不是 float32 中完成。这破坏了非常长的上下文长度，因为 [8190, 8191] 被升级为 [8192, 8192]。这破坏了非常长的序列长度上的微调。 https://preview.redd.it/ozd6agusrbpc1.png?width=798&amp;format=png&amp;auto=webp&amp;s=64ba374acc0bfbe35d92dd4668d302c780c32d19 另一个主要问题是几乎所有实现，除了JAX 类型使用精确的 GELU，而近似 GELU 是正确的选择： https://preview.redd.it/7mhfb7tvrbpc1.png?width=592&amp;format=png&amp;auto=webp&amp;s=7db88b61236205f6f882c1d2f5bb8f8 2b48f63ef 我还有一个关于修复的 Twitter 帖子：https://twitter.com/danielhanchen/status/1765446273661075609，以及完整的Colab 笔记本介绍了更多问题：https://colab.research.google.com/drive/1fxDWAfPIbC -bHwDSVj5SBmEJ6KG3bUu5?usp=sharing 还有一篇较长的博客文章：https://unsloth.ai/blog/gemma-bugs&lt; /a&gt; 我还使 Gemma 微调速度提高了 2.5 倍，在 Colab 笔记本中使用的 VRAM 也减少了 60%：https://colab.research.google.com/drive/10NbwlsRChbma1v55m8LAPYG15uQv6HLo?usp=sharing 还有一场价值 5 万美元的 Kaggle 竞赛https://www.kaggle.com/competitions/data-assistants-with-gemma 专门针对 Gemma :) &lt; !-- SC_ON --&gt;  由   提交 /u/danielhanchen   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bipsqj/p_how_i_found_8_bugs_in_googles_gemma_6t_token/</guid>
      <pubDate>Tue, 19 Mar 2024 17:23:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] [R] 精心策划和协调的多研究妊娠期阴道微生物组数据集，适用于 AI/ML 模型的训练和验证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biprfm/p_r_a_curated_and_harmonized_multistudy_vaginal/</link>
      <description><![CDATA[您好！我是最近的众包 AI/ML 研究的主要作者，该研究旨在识别有早产和早产风险的怀孕 -我想与阴道微生物组数据分享精心策划的阴道微生物组数据训练和验证数据集更广泛的人工智能/机器学习社区。 我认为对于那些对微生物组数据训练模型感兴趣的人来说，这可能是一个宝贵的资源。我也很高兴回答您关于如何组装、协调这些数据以及所提供的各种特征的生物学意义的问题，以及如何对其他基于 16S rRNA 基因的微生物组数据（有超过 200,000 个样本）进行类似的协调在公共数据库中测序）。 数据集由 7 项独立进行的研究组成怀孕期间的阴道微生物组，涵盖 764 次怀孕和 2226 个样本；额外的样本正在等待 dbGAP 的批准。为每个样本精心策划关键元数据（采集妊娠周；分娩妊娠周；NIH 种族/民族类别（如果有）等）。 微生物组数据的协调存在重大挑战，特别是这些数据是通过 16S rRNA 基因可变区的扩增产生的，其中每项研究都使用不同的技术方法。该数据集的组装基于我的研究小组的一种新颖的协调方法，那些寻求使用微生物组数据的人也可能会对此感兴趣。 tldr：以下是一些严格协调的阴道微生物组数据怀孕。如果您只想从一个矩阵开始，请使用 0.5 距离处的系统发育型表（计数或相对丰度）。   由   提交/u/golob  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biprfm/p_r_a_curated_and_harmonized_multistudy_vaginal/</guid>
      <pubDate>Tue, 19 Mar 2024 17:21:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] Let's Build AI - Git 存储库为 AI 爱好者和开发人员共享资源、工具和知识。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1binljf/p_lets_build_ai_git_repo_sharing_resources_tools/</link>
      <description><![CDATA[今天早上偶然发现了这个人工智能工具列表存储库。我发现了一些我以前没有发现的工具和个人。    由   提交/u/iamjessew  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1binljf/p_lets_build_ai_git_repo_sharing_resources_tools/</guid>
      <pubDate>Tue, 19 Mar 2024 15:55:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 带注释的曼巴：艰难的道路</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biisb2/p_annotated_mamba_the_hard_way/</link>
      <description><![CDATA[链接：https://srush .github.io/annotated-mamba/hard.html 代码：https://github .com/srush/annotated-mamba 来自作者：  此博客是关于Mamba 一种最新的神经架构，可以粗略地认为是现代循环神经网络（RNN）。该模型运行得非常好，是无处不在的 Transformer 架构的合法竞争对手。它已经引起了很多关注。  我原本打算写一篇关于整篇论文的博文，内容相当密集且富有洞察力。然而，我只是对此处描述的 S6 算法着迷。该算法描述了如何在现代硬件上有效计算极大的 RNN，并扩展了 S4 和 近年来的S5。  事实上，如果我说实话，我实际上只了解了算法的这一行： y = SSM(A, B, C)( x) # 随时间变化：仅重复(扫描)  这行代码很有趣，我想，嘿，难道没有人能够理解为什么这种扫描在实践中速度很快吗？  事实证明这有点棘手。但是，如果您阅读这篇博文，我可以向您保证，您会理解这句话。 （也许比您想要的更多）。  第 0 部分：Triton  第 1 部分：累积和  第 2 部分：指数移动平均线  第 3 部分：获取导数  p&gt; 第 4 部分：同时多个  第 5 部分：Mamba  ​   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biisb2/p_annotated_mamba_the_hard_way/</guid>
      <pubDate>Tue, 19 Mar 2024 12:14:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] NVIDIA GTC 2024 公告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bif6ey/d_nvidia_gtc_2024_announcements/</link>
      <description><![CDATA[NVIDIA 的计划已遍及加速计算、生成式 AI、行业应用、汽车、企业平台、Omniverse 和机器人领域。 其中一些最有趣的是：  DRIVE Thor：用于自动驾驶汽车中的生成式人工智能应用的车载计算平台。它每秒执行高达千万亿次操作，增强了自动驾驶的安全性，并支持与车辆的交互式对话。 Omniverse：融合物理和虚拟世界的数字孪生生态系统，帮助行业模拟、优化和识别更有效地执行操作。新的 Omniverse Cloud API 扩展了这些功能，使汽车和机器人等行业受益。 GR00T 项目：推动机器人和人工智能突破的人形机器人的基础模型。此外，还推出了 Jetson Thor 计算机，并升级至 NVIDIA Isaac™ 机器人平台，其中包含生成式 AI 模型和模拟工具。 Nvidia Blackwell GPU：一项尖端技术，旨在以 20 petaflops 的速度为下一代 AI 提供动力的性能。该GPU代表了人工智能能力的巨大飞跃，旨在实现万亿参数模型的民主化。 NVLink Switch 7.2 TI：新一代互连技术，可解决数据交换的瓶颈。它旨在促进 GPU 之间的通信，其规模适合最先进的 AI 模型。 NVIDIA NIM：一款新软件产品，旨在简化企业环境中生成式 AI 的部署。它将模型与优化的推理引擎打包在一起，并支持广泛的 GPU 架构。他们称其为所有人的人工智能包。  你最喜欢哪个？   由   提交 /u/vvkuka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bif6ey/d_nvidia_gtc_2024_announcements/</guid>
      <pubDate>Tue, 19 Mar 2024 08:13:59 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA Blackwell 平台到来，为计算新时代提供动力 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1biei3t/nvidia_blackwell_platform_arrives_to_power_a_new/</link>
      <description><![CDATA[https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing  与相同数量的 NVIDIA H100 Tensor Core GPU 相比，GB200 NVL72 对于 LLM 推理工作负载的性能提升高达 30 倍，并将成本和能耗降低高达 25 倍。    由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1biei3t/nvidia_blackwell_platform_arrives_to_power_a_new/</guid>
      <pubDate>Tue, 19 Mar 2024 07:23:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] Nvidia GTC24 的 GPT4 参数计数与我们从 Semianalysis 获得的泄漏相同</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bi16pg/d_same_param_count_for_gpt4_from_nvidia_gtc24_as/</link>
      <description><![CDATA[   A Semianalysis 早前的报告称 GPT-4 是一个 1.8T 参数的 MoE 模型，有 16 位专家，每个有 111B 个参数。这是 GTC 会议的屏幕截图，具有相同的数字。 https://preview.redd.it/vyzfx2sel5pc1.png?width=1764&amp;format=png&amp;auto=webp&amp;s=dfce1d55c84dbc3c51e69f376161c47958f9cf 70   由   提交 /u/takuonline   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bi16pg/d_same_param_count_for_gpt4_from_nvidia_gtc24_as/</guid>
      <pubDate>Mon, 18 Mar 2024 20:36:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当你使用人工智能进行总结时结果不正确时。爱思唯尔发表的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</link>
      <description><![CDATA[       由   提交 /u/vvkuka   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhn918/d_when_your_use_of_ai_for_summary_didnt_come_out/</guid>
      <pubDate>Mon, 18 Mar 2024 10:14:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>