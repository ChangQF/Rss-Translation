<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 29 Jan 2024 00:57:36 GMT</lastBuildDate>
    <item>
      <title>[R] 有人可以解释一下“Hopfield Networks is all you Need”中的 3 种 Hopfield 层之间的区别吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adhdgh/r_can_someone_please_explain_the_differences/</link>
      <description><![CDATA[我是一名认知神经科学博士。我是一名对更先进的机器学习方法相对较新的学生，我正在尝试将 Hopfield 层合并到关联记忆建模中 - 特别是将特定环境中的特定刺激与奖励和惩罚相关联。虽然我能够在很大程度上关注与本文相关的博客文章，但我很难理解3种hopfield层之间的差异。明白的人可以像我五岁一样解释一下吗？非常感谢！   由   提交 /u/TiredEel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adhdgh/r_can_someone_please_explain_the_differences/</guid>
      <pubDate>Mon, 29 Jan 2024 00:07:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于文档智能的 Azure 自定义模型之类的东西如何在幕后工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adeapf/d_how_does_something_like_azure_custom_models_for/</link>
      <description><![CDATA[我目前正在围绕 OCR 和文档智能进行一些研究，并偶然发现了一个 Azure AI 服务，该服务能够使用以下方法从不同类型的文档中提取特定信息：预先训练的模型（发票等）。 https://learn。 microsoft.com/en-us/azure/ai-services/document-intelligence/concept-invoice?view=doc-intel-4.0.0 我试图弄清楚某些事情是如何发生的像这样被训练和使用。自定义模型能够确定表单的哪些部分是“客户名称”、“发票号码”等。该模型的训练是否基本上以多类标记方式完成，其中文档中的每个边界框都标记为像“客户姓名”、“发票号码”等类？或者由于它是 OCR 用例，该模型背后是否还有其他内容？   由   提交/u/Menister22  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adeapf/d_how_does_something_like_azure_custom_models_for/</guid>
      <pubDate>Sun, 28 Jan 2024 21:55:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 托管临床医学 ML 模型并在几分钟内进行交互式可视化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adctl9/p_host_ml_models_for_clinical_medicine_and_make/</link>
      <description><![CDATA[大家好，我想分享一个我创建的平台，名为 clinicalmodels.io 您可以在其中上传 R 或 Python 模型，并无需任何代码即可创建精美的交互式可视化效果。该平台仅专注于临床疾病模型，以提高类似模型的可发现性。我希望专注于共享模型的社区能够解决有关敏感数据的主要问题，因为不涉及任何数据。 对于那些好奇的人来说，这是一个示例模型：https://clinicalmodels.io/nickcullen31/mixed-effects-model 我最近还添加了创建“指南” - 基本上是旨在帮助 AI/ML 专家获得必要的临床背景的文章，以便为临床医生和制药行业构建更相关、更有影响力的模型。您也可以将模型直接嵌入到指南中！  我很乐意听到社区的任何反馈。特别是，人们在托管和共享 ML 模型方面最寻求什么价值。非常感谢！   由   提交/u/johnQuincyLadams  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adctl9/p_host_ml_models_for_clinical_medicine_and_make/</guid>
      <pubDate>Sun, 28 Jan 2024 20:54:39 GMT</pubDate>
    </item>
    <item>
      <title>您在工作中是否拥有产品专业的法学硕士？如果是这样，那又是为了什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adbbnv/do_you_have_llms_in_prod_at_work_if_so_what_for_d/</link>
      <description><![CDATA[请随意在评论中扩展诸如任务（RAG、聊天机器人、工具、seq2seq 等）模型大小、部署策略、缺点等信息，未来计划等 就我而言：任务：RAG 模型：zephyr 7B 部署：vLLM 未来计划：内部文档预训练 + 聊天微调 &lt;!-- SC_ON - -&gt;  由   提交/u/masc98  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adbbnv/do_you_have_llms_in_prod_at_work_if_so_what_for_d/</guid>
      <pubDate>Sun, 28 Jan 2024 19:51:13 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 你如何知道模型所训练的任务是否与你的任务足够相似，可以对架构进行微调或重新训练？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad7son/discussion_how_do_you_know_if_a_task_a_model_was/</link>
      <description><![CDATA[我看到许多关于 ML 的课程和在线资源建议人们只需对其数据集使用类似模型的微调，我从效率的角度理解了原因，但我正在努力弄清楚如何确定模型是否经过足够相似的任务训练以使用此策略。另外，数据类型的差异有多大？ 您能否在一组序列数据（例如生活中的事件）上训练模型来预测生活中的结果，然后对其进行微调以不同的顺序（游戏中的动作）来预测输赢？   由   提交 /u/SkipGram   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad7son/discussion_how_do_you_know_if_a_task_a_model_was/</guid>
      <pubDate>Sun, 28 Jan 2024 17:25:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] RSL 最新出版物《DTC：深度跟踪控制》的幕后视频截图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad7hzz/r_behindthescenes_video_shots_from_rsls_most/</link>
      <description><![CDATA[   /u/leggedrobotics   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad7hzz/r_behindthescenes_video_shots_from_rsls_most/</guid>
      <pubDate>Sun, 28 Jan 2024 17:13:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] WhisperS2T 的 TensorRT-LLM 后端（比 CTranslate2 加速约 2 倍）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad6xuz/p_tensorrtllm_backend_for_whispers2t_2x_speedup/</link>
      <description><![CDATA[大家好！我很高兴地宣布我的开源语音转文本工具包 WhisperS2T 针对 OpenAI Whisper 模型进行了重大更新。 添加了 TensorRT-LLM 支持：  ~ 2 倍推理加速：WhisperS2T 现在支持 TensorRT-LLM 后端，与 CTranslate2 后端相比，推理速度提高了一倍！目前 A30 GPU 上的最佳配置可以在大约 18 秒内实现 1 小时文件的转录。 据我所知，这是 TensorRT-LLM 在 Whisper 上的第一个正确实现，具有批处理和结束功能- 到终端 ASR 管道。  即用型 Google Colab 笔记本：我添加了一些快速的 Google Colab 笔记本，以便轻松试用WhisperS2T：https://github.com/shashikg/WhisperS2T/tree/main/notebooks 查看笔记本日志！在 T4 GPU (Google Colab) 上，使用 WhisperS2T 和 TensorRT-LLM 后端（使用 Whisper Large v2 模型）转录 150 分钟的音频文件仅需约 2.5 分钟。 模型导出注意：  经过 TensorRT-LLM 优化后，导出的模型仅适用于具有相同 cuda_compute_capability 的 NVIDIA GPU。这意味着在 T4 GPU 上导出的模型无法在 A100 上运行，反之亦然。 需要帮助：模型导出大约需要 3-6 分钟。有志愿者可以导出特定 GPU 的模型并分享吗？这将对社区有巨大的帮助！如果有兴趣，请查看：https://github.com/shashikg/WhisperS2T/issues/8 干杯，Shashi P.S.不要忘记查看 GitHub 存储库：https://github.com/shashikg/WhisperS2T   由   提交/u/Financial-Beach1587  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad6xuz/p_tensorrtllm_backend_for_whispers2t_2x_speedup/</guid>
      <pubDate>Sun, 28 Jan 2024 16:49:27 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何让我的训练更快？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad6j2i/d_how_to_make_my_training_faster/</link>
      <description><![CDATA[我使用 DNA 序列作为深度学习模型的输入，我将它们保存为 h5 文件中的一个热编码 numpy 数组。我的数据集有 700k 个示例，大小为 500Go。我想让训练更快，所以我有一堆问题：  将它们存储为 h5 文件中的一维数组（数字而不是一种热编码）然后转换它们是否更好在加载过程中使用一个热编码数组会加快速度吗？ lmdb 格式或 hdf5 格式哪种加载效率更好 &lt; p&gt;我使用dataloaders，基于什么我应该选择num-workers，它应该等于核心数吗？  关于如何进行训练的任何其他建议快点 ？我正在使用 GCP，因此欢迎任何可能降低成本的建议 PS：GPU：V100 CPU：8 核 RAM：15Go 模型：具有 16 个块和 600k 参数的 Resnet 输入：大小（15000,4）    由   提交 /u/bkffadia   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad6j2i/d_how_to_make_my_training_faster/</guid>
      <pubDate>Sun, 28 Jan 2024 16:31:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    <item>
      <title>数学硕士对博士学位的好处。 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad4lri/benefits_of_a_masters_in_mathematics_for_a_phd_d/</link>
      <description><![CDATA[我即将完成计算机科学本科学位，并且我确保在期末考试中学习尽可能多的 ML 相关课程和上学期。 数据分析 统计机器学习 数据挖掘 人工智能（Norvig 书籍类型） &gt; 现在，由于一些奇怪的原因，我几乎不存在数据科学或机器学习等硕士学位的选择。 所以，我有点被迫攻读数学硕士学位或数学和计算。并不是说我像许多计算机科学学生那样讨厌数学或认为它是个骗子，事实上我非常喜欢数学，并且不介意花大量时间学习和探索它，因为它对于深入理解机器学习概念似乎很重要. 至于最后一个问题，你们认为这会对我申请博士学位时的个人资料产生什么影响。请注意，我几乎所有的学士学位都花在了学习 CS、编写代码、摆弄编译器和所有常见的 CS 东西上。我对此感到非常自在，数学总是能找到让事情变得更难的方法。 大学会因为背景略有不同而歧视吗？或者只要我在硕士期间写一些与 ML 相关的像样的论文，他们就不会关心吗？如果有任何一般性的澄清，我们将不胜感激，因为除了一些大学的具体要求（模糊地提到任何 STEM 学位都可以让你有资格获得 ML 博士学位）之外，我没有任何线索。   由   提交/u/Ov3rLord03  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad4lri/benefits_of_a_masters_in_mathematics_for_a_phd_d/</guid>
      <pubDate>Sun, 28 Jan 2024 15:05:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我创建了一个开源 Python 工具，用于快速可视化和交互式选择要在机器学习和数据科学中使用的时间序列数据：Visual Pandas 选择器。我希望它可以帮助其他人的 ML 之旅！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad1p4c/p_i_created_an_open_source_python_tool_to_quickly/</link>
      <description><![CDATA[   ​ https://i.redd.it/amo5nc5ld6fc1.gif   由   提交/u/phthah  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad1p4c/p_i_created_an_open_source_python_tool_to_quickly/</guid>
      <pubDate>Sun, 28 Jan 2024 12:33:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 中的 OUTPUT 嵌入是什么？它从何而来？ （不是输入嵌入）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad1o11/d_what_are_the_output_embeddings_in_transformer/</link>
      <description><![CDATA[       由   提交 /u/ShlomiRex   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad1o11/d_what_are_the_output_embeddings_in_transformer/</guid>
      <pubDate>Sun, 28 Jan 2024 12:31:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 200k 向量 (30GB) 语义搜索的最佳实践 嵌入的价值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1acxvd7/d_best_practices_for_semantic_search_on_200k/</link>
      <description><![CDATA[嗨，我已将一些特定于域的名称向量转换为嵌入，数据集大小为 200k 字。所有嵌入都是使用 OpenAI 的嵌入模型 3 生成的（每个嵌入 3072 个暗淡）。现在我计划实现语义搜索相似度。给定一个域关键字，我想找到前 5 个最相似的匹配项。嵌入所有 280k 个单词后，包含嵌入的 JSON 文件的大小约为 30GB。 （编辑，按照以 msgpack 格式保存的建议，磁盘大小为 6.5GB） 我是这个域的新手，正在评估最佳选项。  我应该使用云吗矢量数据库（如 Pinecone 或 Typsense），还是本地托管在 DigitalOcean 上？ 如果我选择 Typsense 等云选项，我需要什么配置（RAM 等）才能实现 280k 嵌入（大小为 30GB）？大概要花多少钱？  过去几天我一直很困惑，找不到有用的资源。我们将非常感谢您提供的任何帮助或建议。   由   提交/u/stoicbats_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1acxvd7/d_best_practices_for_semantic_search_on_200k/</guid>
      <pubDate>Sun, 28 Jan 2024 08:15:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们一直称“生成”模型为“生成”模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1acsq74/d_why_do_we_keep_calling_generation_models/</link>
      <description><![CDATA[我认为生成模型模拟了联合概率分布，而判别模型模拟了条件概率。 当我们执行文本或图像时一代，我们不是为模型提供某种输入来进行调节吗？难道这些不应该被称为“一代模型”吗？因为它们本质上具有歧视性，但正在执行生成任务？   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1acsq74/d_why_do_we_keep_calling_generation_models/</guid>
      <pubDate>Sun, 28 Jan 2024 03:10:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 变分自动编码器已经 10 岁了</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1acqgn9/d_the_variational_autoencoder_is_now_10_years_old/</link>
      <description><![CDATA[我感觉自己老了哈哈。  不过，严肃地说，作为深度生成建模的实用选择，它似乎经受住了时间的考验。相比之下，GAN 研究似乎已经变得停滞不前，流、基于能量的模型和基于扩散/分数的模型正在被纳入 VAE 中，以实现更具表现力的先验。我坚信 VAE 在未来很长一段时间内仍然有用。 只是一个想法。   由   提交/u/Chromobacteria  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1acqgn9/d_the_variational_autoencoder_is_now_10_years_old/</guid>
      <pubDate>Sun, 28 Jan 2024 01:14:35 GMT</pubDate>
    </item>
    </channel>
</rss>