<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 09 Feb 2024 12:22:34 GMT</lastBuildDate>
    <item>
      <title>[D] 用于概率预测/分类的生成对抗网络（GAN）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amlozf/d_generative_adversarial_networks_gans_for/</link>
      <description><![CDATA[用于概率预测和分类的生成对抗网络 最近我对用于预测和分类的 GAN 感兴趣，而不是生成。我知道大多数关于 GAN 的研究都是关于生成新数据 - 例如：合成时间序列生成、深度伪造等。 我的理解是生成器最终会理解原始数据的潜在概率分布数据。另一方面，鉴别器只是将数据分类为真数据或假数据（二元分类）。 现在我试图在分类/预测时间序列的背景下理解这一点。该问题可以概括为：  给定一个时间序列（例如：股票的回报），我想预测下一个时间步长的回报。我想分类时只需要取它的sign()即可。  我的疑问是，训练完GAN后，我该如何进行推理？我要使用鉴别器吗？发电机？此外，我正在预测下一个时间步长的回报，这个概率预测如何？我可以获得分布作为输出吗？ 作为参考论文，您可以查找：https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4328302   由   提交 /u/LeHalfW   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amlozf/d_generative_adversarial_networks_gans_for/</guid>
      <pubDate>Fri, 09 Feb 2024 11:04:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 具有极其复杂模式的文本到 SQL</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amlguz/d_texttosql_with_extremely_comple_schema/</link>
      <description><![CDATA[我正在使用 llms 和 sql server 开发一个文本到 sql 项目。用户将用自然语言提出问题，llms 将编写 sql 查询，在我的数据库上运行它，然后以自然语言给出结果。问题是数据库的模式很大，表名、列名不言自明。大多数时候，两个表需要在多个列上连接，并且在其中条件下，我始终希望有一些条件，并且日期范围条件也非常重要，因为如果没有日期条件，用户可能会获得他不希望访问的数据到。有什么办法可以解决这个问题吗？我尝试过使用视图，但这在计算上非常昂贵，并且执行起来也需要大量时间。还有其他办法吗？    由   提交 /u/HappyDataGuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amlguz/d_texttosql_with_extremely_comple_schema/</guid>
      <pubDate>Fri, 09 Feb 2024 10:49:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] 波动市场下的电价预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aml7lp/p_electricity_price_forecast_in_a_volatile_market/</link>
      <description><![CDATA[大家好， 我正在考虑对日前非常波动的市场进行电力价格预测 (EPF)，其中 2年的历史数据。我对时间序列机器学习非常业余，因此恳请有关采用外生变量的模型的建议。它们是：（1）天气，（2）煤炭和天然气价格，（3）邻国电力价格， (4) 供给和需求。 考虑到可用数据量和波动的市场，我确实理解准确性不会很高。 目前，我正在考虑 SARIMAX- GARCH、AutoArima、EPFTOOLBOX、LSTM。   由   提交 /u/_what_the_f   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aml7lp/p_electricity_price_forecast_in_a_volatile_market/</guid>
      <pubDate>Fri, 09 Feb 2024 10:30:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你最喜欢的研究工具是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aml3w4/d_what_are_your_favorite_tools_for_research/</link>
      <description><![CDATA[这些是我个人最喜欢的： connectedpapers .com - 当您开始新的研究项目时，这是一个很棒的工具。从一篇相关论文开始，它会向您显示所有相关论文及其引用的图表。这让您可以很好地概述相关文献以及它们如何通过引用进行连接。 consensus.app - 人工智能用于研究的搜索引擎。您可以询问特定主题、相关论文等。如果您的论文中需要更多引用或想更好地了解相关作品，这是一个很好的工具。 paperparrot.ai - 这是一份个性化的研究论文时事通讯，每周根据您的兴趣向您发送一次最新论文的摘要。对于跟上新论文并且不错过您可能看不到的内容非常有用。 overleaf.com - 用于撰写研究论文或笔记的首选网络应用程序。您拥有版本控制，可以与多人协作，并且一切都是基于网络的。这是编写 LateX IMO 的最佳方式。 trello.com - 如果您的项目有多个协作者，这可以是有助于将事情组织起来并跟踪谁在做什么以及何时做什么。   由   提交 /u/Time-Sympathy724    reddit.com/r/MachineLearning/comments/1aml3w4/d_what_are_your_favorite_tools_for_research/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aml3w4/d_what_are_your_favorite_tools_for_research/</guid>
      <pubDate>Fri, 09 Feb 2024 10:23:22 GMT</pubDate>
    </item>
    <item>
      <title>[N] 情感评分量化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amjhzi/n_sentiment_score_quantification/</link>
      <description><![CDATA[情感分析一直是一个分类问题，但有没有办法量化影响，因为评论基于某些定量信息的严重程度？我尝试了几种方法，但需要不同的方法 1. 极性得分（-1 到 1）*100 2. 句子方面（所有句子中负面情绪的百分比）和总体极性的组合 使用 Bert 模型准确度得分而不是 NLTK 极性和VADER 分数   由   提交 /u/Glass-Try-9851   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amjhzi/n_sentiment_score_quantification/</guid>
      <pubDate>Fri, 09 Feb 2024 08:25:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年流量正常化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amj8i4/d_normalizing_flows_in_2024/</link>
      <description><![CDATA[所有 SOTA 方法在特征解缠和图像生成质量方面是否已经过时了？ 2024 年流量标准化的状况如何？   由   提交 /u/BigDreamx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amj8i4/d_normalizing_flows_in_2024/</guid>
      <pubDate>Fri, 09 Feb 2024 08:06:23 GMT</pubDate>
    </item>
    <item>
      <title>[2402.05608]具有状态空间主干的可扩展扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amifi3/240205608_scalable_diffusion_models_with_state/</link>
      <description><![CDATA[ 由   提交/u/Elven77AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amifi3/240205608_scalable_diffusion_models_with_state/</guid>
      <pubDate>Fri, 09 Feb 2024 07:10:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我应该探索更多像 autogen 和 Langgraph 这样的框架吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amhunt/d_more_frameworks_like_autogen_and_langgraph_that/</link>
      <description><![CDATA[我使用了 autogen，它有一些缺点，所以我现在正在探索 langgraph。我还可以探索哪些类似的框架？   由   提交 /u/Previous-Sample2097    reddit.com/r/MachineLearning/comments/1amhunt/d_more_frameworks_like_autogen_and_langgraph_that/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amhunt/d_more_frameworks_like_autogen_and_langgraph_that/</guid>
      <pubDate>Fri, 09 Feb 2024 06:33:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] 课程项目构想</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amf12g/p_course_project_ideas/</link>
      <description><![CDATA[项目想法 嗨，我是应用数学+统计学的博士生，本学期我正在学习深度学习课程其中有一个项目要求。虽然我在数理统计、基础机器学习和自然语言处理 (NLP) 方面很擅长，但这是我第一次正式学习深度学习。教授希望我们进行独立的、新颖的（没有什么开创性的，但如果进行得当的话值得发表）研究，我想利用这个社区来收集想法。  我想探索贝叶斯神经网络中的一些东西，特别是从经验和数学角度检查它是否对中毒攻击具有鲁棒性。经过文献回顾，我意识到这个主题已经在多项研究中得到了深入研究，尽管结论两极分化。  社区怎么看？我只剩下 3-4 个月的时间，我将不胜感激在这些时间内实现的任何现实的想法。   由   提交/u/redwing42  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amf12g/p_course_project_ideas/</guid>
      <pubDate>Fri, 09 Feb 2024 03:52:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 单图像 3D 场景重建的当前技术水平？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amdaw6/d_current_state_of_the_art_for_single_image_3d/</link>
      <description><![CDATA[我知道的大多数 Nerf 论文都需要多个输入视图，我发现的主要论文是 Single view nerf with Depth Teacher。  想知道是否有人有其他论文或技术可以分享/讨论他们最成功的部分？   由   提交/u/AbjectDrink3276  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amdaw6/d_current_state_of_the_art_for_single_image_3d/</guid>
      <pubDate>Fri, 09 Feb 2024 02:25:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 具有累积金额的 Mamba</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1amb3xu/d_mamba_with_cumulative_sums/</link>
      <description><![CDATA[Mamba 是一个带有数据的状态空间模型相关系数。它最初是通过关联扫描进行训练的，目前是pytorch 不直接支持，因此作者为其编写了自定义 cuda 内核（这具有内核融合的额外好处）。为了简化这一点，有人在一个文件中编写了 最小版本的 mamba，其中关联扫描操作被 for 循环取代，为了实现的简单性而牺牲了效率。 不过，我认为有一种方法可以在纯pytorch中实现mamba，并且不会损失太多效率，那就是使用累积和 pytorch 有效支持。此实现封装在我对最小 mamba 存储库的相当简单的 commit 中，它提供了大约 14 倍的加速最小的 for 循环实现（代码较少）。还通过与 for 循环实现的输出进行比较来验证其正确性。 高级思想基本上是“分解”循环。将原始并行扫描降低到两个累加和的比率，同时保留关联扫描相同的时间复杂度 O(n) 和并行效率 O(logn)。  &amp; #32；由   提交/u/dna961010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1amb3xu/d_mamba_with_cumulative_sums/</guid>
      <pubDate>Fri, 09 Feb 2024 00:39:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是什么让 PPO 强化学习不仅仅是拥有一个花哨的损失函数？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1am04c9/d_what_makes_ppo_reinforcement_learning_and_not/</link>
      <description><![CDATA[我正在考虑使用 RLHF 训练扩散模型，并且正在查看这篇论文 kvablack/ddpo-pytorch：用于微调扩散模型的 DDPO，在具有 LoRA 支持的 PyTorch 中实现（github.com），但代码本身似乎只是反向传播基于unet的一个奇特的（乍一看是可微分的！）损失函数。强化学习与普通模型训练有何区别？两者相同吗？这只是术语问题吗？  在此处复制相关代码？ for i, example in tqdm( list(enumerate(samples_batched)), desc=f&quot;Epoch {epoch}.{inner_epoch} :training&quot;,position=0,disable=notaccelerator.is_local_main_process, ): if config.train.cfg: # 将否定提示连接到示例提示以避免两次前向传递 embeds = torch.cat( [train_neg_prompt_embeds, Sample[&quot;prompt_embeds&quot;) ;]] ) else: embeds = sample[“prompt_embeds”] for j in tqdm( range(num_train_timesteps), desc=“Timestep”,position=1, left=False,disable=not Accelerator.is_local_main_process, ): with Accumulate(unet): with autocast(): if config.train.cfg:noise_pred =unet( torch.cat([sample[&quot;latents&quot;][:, j]] * 2), torch.cat([样本[“时间步长”][:, j]] * 2), 嵌入, ).sample Noise_pred_uncond, Noise_pred_text = Noise_pred.chunk(2) Noise_pred = ( Noise_pred_uncond + config.sample.guidance_scale * (noise_pred_text - Noise_pred_uncond) ) else :noise_pred =unet(sample[“latents”][:, j],sample[“timesteps”][:,j],embeds,).sample#计算当前模型下给定潜伏的next_lateents的对数概率_ , log_prob = ddim_step_with_logprob( pipeline.scheduler,noise_pred,sample[“timesteps”][:, j],sample[“latents”][:,j], eta=config.sample.eta, prev_sample=sample[&quot; ;next_latents&quot;][:, j], ) # ppo 逻辑优点 = torch.clamp(sample[&quot;advantages&quot;], -config.train.adv_clip_max, config.train.adv_clip_max, )ratio = torch.exp(log_prob -样本[“log_probs”][:, j]) unclipped_loss = -advantages * 比率 Clipped_loss = -advantages * torch.clamp(ratio, 1.0 - config.train.clip_range, 1.0 + config.train.clip_range, ) loss = torch .mean(torch.maximum(unclipped_loss, Clipped_loss)) # 调试值 # John Schulman 说 (ratio - 1) - log(ratio) 是一个更好的 # 估计器，但大多数现有代码都使用它，所以... # http:// /joschu.net/blog/kl-approx.html 信息[“approx_kl”].append( 0.5 * torch.mean((log_prob - 样本[“log_probs”][:, j]) ** 2) ) 信息[“clipfrac”].append( torch.mean( ( torch.abs(ratio - 1.0) &gt; config.train.clip_range ).float() ) ) info[&quot;loss&quot;].append(loss) # 向后传递 Accelerator.backward(loss) if Accelerator.sync_gradients: Accelerator.clip_grad_norm_(unet.parameters(), config. train.max_grad_norm ) optimizationr.step() optimizationr.zero_grad()    由   提交 /u/ExaminationNo8522   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1am04c9/d_what_makes_ppo_reinforcement_learning_and_not/</guid>
      <pubDate>Thu, 08 Feb 2024 16:49:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 离开我的胸膛。我正在攻读机器学习博士学位，但我是个失败者。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1alxv3l/d_off_my_chest_im_doing_phd_in_ml_and_im_a_failure/</link>
      <description><![CDATA[我的机器学习博士学位已经过半了。 我很幸运，进入了一个很好的项目，尤其是在一个好的项目中。实验室的学生都是超级明星，毕业后会找到很好的工作。我不是他们中的一员。我有一本蹩脚的、技术性不高的出版物，我正在努力寻找一个在我的能力范围内可以解决的新问题。我已经很努力了。我在本科生和硕士期间一直在做研究，尽我所能 - 做项目、阅读论文、学习机器学习和数学课程、为教授撰写资助...... 事实是，我可以达不到产生新想法的水平。无论我多么努力，这都不是我的事。我想为什么。我开始怀疑 STEM 是否一开始就不是我的菜。我环顾四周，发现有些人的大脑只是“理解”了这一点。事情变得更容易。对我来说，这需要额外的努力和额外的时间。在本科期间，我可以更加努力、更长时间地学习。嗯，不是为了博士学位。尤其是在这个快节奏、拥挤的领域，我需要吸收新东西并快速发布。 我是一个冒名顶替者，这不是一种综合症。我快被抓了其他人都获得了多个实习机会等等。我到处都被拒绝。看来现在他们知道了。他们知道我没用。我想对我的顾问说这些，但他是如此的天才，以至于他无法理解普通人的想法。我所有的高级实验室伙伴都是全职工作人员，所以实际上我现在是实验室中最资深的。   由   提交 /u/rsfhuose   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1alxv3l/d_off_my_chest_im_doing_phd_in_ml_and_im_a_failure/</guid>
      <pubDate>Thu, 08 Feb 2024 15:10:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] 宗师级国际象棋无需搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1alqzlf/r_grandmasterlevel_chess_without_search/</link>
      <description><![CDATA[ 由   提交/u/hardmaru  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1alqzlf/r_grandmasterlevel_chess_without_search/</guid>
      <pubDate>Thu, 08 Feb 2024 08:23:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>