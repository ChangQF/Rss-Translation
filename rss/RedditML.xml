<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Tue, 30 Jul 2024 21:15:03 GMT</lastBuildDate>
    <item>
      <title>[P] 预测交付周期需求</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eg39vj/p_forecasting_lead_time_demand/</link>
      <description><![CDATA[我是一名从事制造业的数据科学家。 我需要对数千个 SKU 的交付周期需求（从供应商处获取物品所需时间内的需求）进行概率预测，每个 SKU 的交付周期可能不同（从 5 天到 90 天）。 我现在正在使用 DeepAR（使用零膨胀负二项似然）生成每日需求的样本路径，然后对于每个 SKU，我将交付周期窗口内的数量相加，以获得可能的交付周期需求分布。 我的问题是每日时间序列高度间歇性，92% 的值是零，可能由于这个原因，当我汇总交付周期内的每日预测（样本路径）时，我得到了未校准的 LT 需求预测（Coverage[0.99]’ 为 0.90 且 mean_wQuantileLoss 很差）。我也尝试了 NPTS（非参数算法），但它比 DeepAR 更糟糕，我认为这是因为它无法对时间自相关性进行建模。 如果我根据每月汇总数据训练模型，结果会比事后汇总每日样本路径好得多，但使用这种方法，我无法处理不是 30 的倍数的前置时间，例如 20 或 40 天，并且可能的前置时间值太多，我无法为每个值训练一个模型。 您知道 DeepAR 和 NPTS 的任何替代方案吗？用于生成高度间歇性时间序列的样本路径预测？    提交人    /u/Vegetable-Author7363   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eg39vj/p_forecasting_lead_time_demand/</guid>
      <pubDate>Tue, 30 Jul 2024 20:07:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于 Segment Anything v2 的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eg12if/r_thoughts_on_segment_anything_v2/</link>
      <description><![CDATA[大家好， Segment Anything 2 刚刚发布。 我很好奇，想知道大家对架构改进和旨在提高视频分割性能的新“内存”机制的看法。 是否有人使用/测试过它并验证过（无论是定性还是定量）SA-2 在某些领域比原始 SA 效果更好？ Github 存储库 论文   由    /u/Ben-L-921  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eg12if/r_thoughts_on_segment_anything_v2/</guid>
      <pubDate>Tue, 30 Jul 2024 18:40:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你会使用什么模型进行抽象概括？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eftxem/d_what_model_would_you_use_for_abstractive/</link>
      <description><![CDATA[我正在处理一项 NLP 任务，该任务需要我总结相关的文本组。我曾尝试使用 T5 1.1 基础 模型来完成此任务，但它的总结能力（至少对于我的文本而言）非常糟糕。是否有其他通常推荐用于此类任务的模型？ 我正在考虑使用 Phi-3-mini 作为基准，并从那里搜索具有类似性能的较小模型。    提交人    /u/FPGA_Superstar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eftxem/d_what_model_would_you_use_for_abstractive/</guid>
      <pubDate>Tue, 30 Jul 2024 13:53:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2024 论文评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efscr2/d_neurips_2024_paper_reviews/</link>
      <description><![CDATA[NeurIPS 2024 论文评审将于今日发布。我想创建一个讨论主题，让我们讨论任何问题/抱怨/庆祝或其他任何事情。 每年的评审中都有这么多噪音。考虑到 NeurIPS 这些年来发展如此之大，一些作者引以为豪的好作品可能会因为嘈杂的系统而获得低分。我们应该记住，无论分数如何，这项工作仍然很有价值。    提交人    /u/zy415   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efscr2/d_neurips_2024_paper_reviews/</guid>
      <pubDate>Tue, 30 Jul 2024 12:42:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] MuJoCo 与 Isaac Sim 未来强化学习发展对比</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efqdlt/d_mujoco_vs_isaac_sim_for_future_rl_development/</link>
      <description><![CDATA[大家好， 我希望深入研究 MuJoCo 或 Isaac Sim，并希望获得您的见解，了解哪种环境在未来的 RL 中可能更为突出。 这是我目前所知道的：  Isaac Gym 已被弃用，开发人员现在需要使用 Isaac Sim，这需要计算机提供更多的资源。 MuJoCo MJX 与 Jax 配合使用，将这些值转换为 Torch 模型并不是一件简单的事情。 DeepMind 正在提议使用其他深度学习框架：例如 Haiku、Jraph、Flax，用于使用 Jax 训练模型。  另外，为了做出明智的决定，我还在考虑使用 Arxiv 论文数据集进行一些分析，以了解当前的使用情况和趋势。完成后，我可能会在这里发布研究结果。 鉴于此，您对这些环境的未来发展有何看法？您认为哪一个值得掌握？ 提前感谢您的意见！    提交人    /u/Stefano939393   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efqdlt/d_mujoco_vs_isaac_sim_for_future_rl_development/</guid>
      <pubDate>Tue, 30 Jul 2024 10:56:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] SAM2 是对象跟踪领域的新 SOTA 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efprgq/d_is_sam2_the_new_sota_in_object_tracking/</link>
      <description><![CDATA[我尝试过大多数流行的对象跟踪框架，如 bytetrack、botsort、deepsort（均使用 detectorron 和 ultralytics-YOLOv8 后端进行对象检测），但没有一个表现得像我在 SAM2 演示中测试的那样好 - https://sam2.metademolab.com/demo，当然，这是在没有进行任何微调或摆弄参数的情况下进行的。 我知道这不是模型的主要目的，生产结果可能会略有不同。但是，将 YOLO 用于快速物体检测和分类，再加上 SAM2 用于跟踪（用 YOLO bbox 的中心注释 SAM2 跟踪点）是否可以为您提供最佳的物体检测 + 跟踪？ 附言，与我不同，如果您在任何物体跟踪框架方面有更好的体验，请分享。    提交人    /u/Eoncarry   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efprgq/d_is_sam2_the_new_sota_in_object_tracking/</guid>
      <pubDate>Tue, 30 Jul 2024 10:18:52 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 近年来您真正喜欢的非计算密集型研究出版物？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efmmnn/discussion_non_compute_hungry_research/</link>
      <description><![CDATA[整个行业和学术界都出现了一些出色的成果。但是，一项成果的炒作越大，它通常需要的资源/计算量就越大。 那么学术界/行业/小团队（或单个作者）独立完成的一些成果呢？这些成果确实具有基础性或影响力，但所需的计算量却很少（单个或双 GPU，有时甚至 CPU）？ 您想到了哪些成果？为什么您认为它们脱颖而出？    提交人    /u/HopeIsGold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efmmnn/discussion_non_compute_hungry_research/</guid>
      <pubDate>Tue, 30 Jul 2024 06:43:20 GMT</pubDate>
    </item>
    <item>
      <title>Meta FAIR 刚刚发布“任何事物细分模型 2”[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efebjl/segment_anything_model_2_just_released_by_meta/</link>
      <description><![CDATA[FAIR 刚刚推出了 SAM 2！ 该模型在图像上的表现优于 SAM，现在还可以在视频中分割物体，并且持续开放。  模型、代码、数据集、演示均已提供。 网站 演示 Github    提交人    /u/fruitofconfusion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efebjl/segment_anything_model_2_just_released_by_meta/</guid>
      <pubDate>Mon, 29 Jul 2024 23:28:03 GMT</pubDate>
    </item>
    <item>
      <title>[N] 从科幻小说到州法律：加州预防人工智能灾难的计划</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efdpmw/n_from_scifi_to_state_law_californias_plan_to/</link>
      <description><![CDATA[Ars Technica：从科幻小说到州法律：加州预防人工智能灾难的计划  加州的“前沿人工智能模型安全创新法案”（又名 SB-1047）引发了一系列有关大型人工智能模型整体“安全性”的头条新闻和辩论。但批评者担心，该法案过分关注未来人工智能模型的生存威胁，可能会严重限制当今更平淡无奇、无威胁的人工智能用途的研究和开发。 SB-1047 由州参议员 Scott Wiener 提出，于 5 月以 32 比 1 的投票通过了加州参议院，并且似乎有望在 8 月的州议会上进行最终投票。  该法案的一个特别值得注意的特点：  在他的 Understanding AI 时事通讯中，Ars 撰稿人 Timothy Lee 阐述了 SB-1047 的措辞如何严重阻碍所谓的“开放权重”AI 模型的传播。这是因为该法案将使模型创建者对基于其原始训练构建的“衍生”模型负责。     提交人    /u/bregav   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efdpmw/n_from_scifi_to_state_law_californias_plan_to/</guid>
      <pubDate>Mon, 29 Jul 2024 23:01:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理论深度学习会议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efaug9/d_theoretical_dl_conferences/</link>
      <description><![CDATA[情况是这样的： 今年的研究比我习惯的更加注重理论 所以现在我正在考虑参加一个会议提交论文，这将更加注重理论，而不是那么要求应用。我的部门主要关注更面向应用的场所，这个社区早期的帖子评论大多已过时。 这篇论文非常基础，贡献仅限于监督启发式学习 - 例如通过反向传播 以下是贡献的简短摘要以提供背景信息 TLDR：新颖的视角+方法，非常基本的展示用例 摘要：我们从新颖的视角P（这是一个主要提议）来看待学习过程的元素E，这允许将其视为来自F家族的一个规范。 现在，我们分析如果我们考虑F中的其他规范，行为在某种意义上S会如何变化：推导出某些变化C的下限和上限。 C可以用作学习过程的补充，类似于辍学或某种正则化。我们在一些非常基础且经过充分研究的基准数据集上展示了结果 - 为了展示提案的理论部分。    提交人    /u/One_With_Great_Dao   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efaug9/d_theoretical_dl_conferences/</guid>
      <pubDate>Mon, 29 Jul 2024 21:03:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有可能兼顾研究和全职工作吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef6mnn/d_is_it_possible_to_juggle_doing_research_and/</link>
      <description><![CDATA[我目前在一家生命科学公司担任 AI 工程师。我对深度学习研究（尤其是计算机视觉）很感兴趣，但同时又不想辞职。我可以在下班后远程与教授一起做研究员吗？我愿意每周为此投入 20 小时。（工作日 2 小时，周末 10 小时）    提交人    /u/Hour_Amphibian9738   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef6mnn/d_is_it_possible_to_juggle_doing_research_and/</guid>
      <pubDate>Mon, 29 Jul 2024 18:16:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] Neurips’24 评论发布时间？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef1var/d_neurips24_review_release_time/</link>
      <description><![CDATA[有人知道评审什么时候发布吗？NeurIPS 网站指出，反驳将于地球上任何地方的 7 月 30 日开始，而我们所在的时区已经是 7 月 30 日了！    提交人    /u/Working-Egg-3424   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef1var/d_neurips24_review_release_time/</guid>
      <pubDate>Mon, 29 Jul 2024 15:06:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 知识图谱和对（大量）技术 PDF 进行 ra.g</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef0iv8/d_p_knowledge_graph_and_rag_over_large_set_of/</link>
      <description><![CDATA[我有一批在一段时间内收集的 PDF（数量增长很快）。主要是技术材料（机器学习、统计学、金融等方面的期刊文章和书籍）。我想基于这些材料创建一个知识图谱，并微调一个 RAG，这样我就可以使用 LLM 搜索我的东西。我的想法是，与其使用 mendeley，我可以使用 LLM 作为强化版的 mendeley。不需要文件夹和标签，我只需提示我正在寻找的内容即可。 问题：  我不想重新发明轮子。要使用哪些软件包 / github？ 有人成功完成过吗？ 本地计算会是一个问题 —— 无法在本地完成。最好是与 ChatGPT 或 Claude 链接的东西（我对这两个都有专业订阅）。  TIA 编辑：如果我可以将我的笔记放入（非常多）overleaf 项目、onenote、supernotes 和 ms 中来执行此操作，那也会很棒。    提交人    /u/daydaybroskii   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef0iv8/d_p_knowledge_graph_and_rag_over_large_set_of/</guid>
      <pubDate>Mon, 29 Jul 2024 14:11:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 量化的视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eey89o/p_a_visual_guide_to_quantization/</link>
      <description><![CDATA[大家好！随着越来越多的大型语言模型发布以及量化需求的增加，我想是时候编写一份深入且直观的量化指南了。 从探索如何表示值、（非）对称量化、动态/静态量化，到训练后技术（例如 GPTQ 和 GGUF）和量化感知训练（带有 BitNet 的 1.58 位模型）。 https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization 有了超过 60 个自定义视觉效果，我有点做得过火了，但我真的很想尽可能多地包含概念！  本指南的视觉特性允许专注于直觉，希望使所有这些技术易于广大受众使用，无论您是量化新手还是经验丰富的量化新手。    提交人    /u/MaartenGr   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eey89o/p_a_visual_guide_to_quantization/</guid>
      <pubDate>Mon, 29 Jul 2024 12:27:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jul 2024 15:00:14 GMT</pubDate>
    </item>
    </channel>
</rss>