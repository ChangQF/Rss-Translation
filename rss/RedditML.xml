<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 13 Jan 2024 18:16:16 GMT</lastBuildDate>
    <item>
      <title>[N] OpenDalle v1.1、VCoder、LongAnimateDiff 等！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195tut6/n_opendalle_v11_vcoder_longanimatediff_more/</link>
      <description><![CDATA[嘿， 人工智能最近变得很疯狂，事情变化得非常快。我制作了一个视频，涵盖了一些最新流行的拥抱空间，您必须查看！ OpenDalle v1.1 已发布，让您可以创建令人惊叹的图像。 VCoder 现在也可用，让您可以全面了解我们传递给它的图像中所看到的内容。除了这 2 个之外，我们还介绍了 LongAnimateDiff、PASD Magnify、M^2UGen、Pheme 和 Pheme。 PIA。请查看以了解最新趋势！ https://www.youtube。 com/watch?v=MbLXWxbcVoc OpenDalle 非常好。它基于稳定扩散，但经过一些调整，确实产生了一些非常好的结果。请务必检查一下，它们还提供了一个推理终点供您使用。 请随时订阅我的时事通讯，其中将包含人工智能领域新技术的每周每月摘要： https://devspot.beehiiv.com/subscribe 让我了解您的想法，或者如果您对其他视频有任何疑问/请求， 干杯   由   提交/u/dev-spot  /u/dev-spot  reddit.com/r/MachineLearning/comments/195tut6/n_opendalle_v11_vcoder_longanimatediff_more/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195tut6/n_opendalle_v11_vcoder_longanimatediff_more/</guid>
      <pubDate>Sat, 13 Jan 2024 17:59:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您将如何组建研发团队？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195tnw4/d_how_would_you_build_an_rd_team/</link>
      <description><![CDATA[我目前面临着令人兴奋的挑战，要在大型科技公司内建立一支 Skunkworks 研发团队，专注于 NLP。 Skunkworks 项目以其创新和非正统的方法而闻名，我热衷于收集有关如何有效建立和管理这样一个团队的广泛想法和建议。以下是我希望了解您的见解的一些具体领域：  团队组成：您认为 Skunkworks 团队中哪种技能和背景组合最有效？您如何平衡技术专长与创造性解决问题的能力？ 领导力和文化：您将如何培养创新和冒险的文化？哪些领导素质对于指导在通常公司结构的边缘运作的团队至关重要？ 项目选择和管理：您如何决定要开展哪些项目？什么方法最适合管理本质上不确定和探索性的项目。 协作与沟通：在一家大公司中，如何确保 Skunkworks 团队与其他部门之间的有效沟通？您如何在保密和必要的协作之间取得平衡？ 挑战和经验教训：建立 Skunkworks 团队时有哪些常见陷阱？如果您是这样一个团队的一员，您学到了哪些希望一开始就知道的经验教训？ 成功故事和案例研究：是否有任何特别的成功您认为 Skunkworks 团队的故事或案例研究对您有启发性或启发性？  您的经验、见解以及您可以分享的任何资源都会非常有帮助。我期待着阅读您的想法并就此展开丰富的讨论！提前致谢！   由   提交/u/SingularValued  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195tnw4/d_how_would_you_build_an_rd_team/</guid>
      <pubDate>Sat, 13 Jan 2024 17:50:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从非 FAANG 转向时预期会降低水平？ (L6)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195t83g/d_anticipate_downleveling_when_pivoting_from/</link>
      <description><![CDATA[大家好 - 快问。是否还有其他人从非 FAANG 公司转型为这些角色之一？据我所知，降级非常普遍，通常是总监级别的角色（中层经理）会转换为 L6。大多数情况下都是这样吗？ 我已经工作了 8 年，在最近的职位中管理过 1 年的技术团队 (ML)，并且在职业生涯早期拥有一些管理经验。我在一家非科技型 F500 公司工作。工作很愉快，我的绩效评估也很出色，但随着市场的发展方向，我想对冲一些机会。目前的比较是在 300 年代。拥有顶尖学校的 MBA 学位和 MSCS 学位。   由   提交/u/FingerNoOW02   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195t83g/d_anticipate_downleveling_when_pivoting_from/</guid>
      <pubDate>Sat, 13 Jan 2024 17:31:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Transformers 专家混合的问题 - 有人尝试过在多头注意块之前添加路由器吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195soqh/d_question_about_mixture_of_experts_in/</link>
      <description><![CDATA[   当我们阅读 Mixtral 8x7B 论文时，这个问题在我们周五的论文俱乐部中出现了，并且我觉得我们没有得到满意的答案。 MOE 的论点似乎是你可以让网络的某些部分专门从事某些领域或任务。这也让我印象深刻，因为人们在变压器块内进行多头关注时提出了类似的论点。为什么只将路由器放在前馈层前面而不是放在多头注意力前面？ ​ https://preview.redd.it/gyb8mevco8cc1.png?width=1666&amp;format =png&amp;auto=webp&amp;s=0595120e2fdf96bbb5797bcc85646a90d1419773 在多头注意力之前进行路由可以让网络更好地选择它关注的内容，在多头注意力之后进行路由可以帮助预测下一个基于注意力的词。看起来，如果您只需要运行多头注意力的一个子集，您就会得到类似的延迟增加。 我错过了什么？有人尝试过吗？ ​ 为感兴趣的人回顾一下我们的笔记： https://blog.oxen.ai/arxiv-dives-mixture-of-experts-moe-with-mixtral- 8x7b/   由   提交 /u/FallMindless3563   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195soqh/d_question_about_mixture_of_experts_in/</guid>
      <pubDate>Sat, 13 Jan 2024 17:07:46 GMT</pubDate>
    </item>
    <item>
      <title>寻找可解释的人工智能在医疗诊断领域应用的研究课题[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195smzg/looking_for_a_research_topic_to_apply_explainable/</link>
      <description><![CDATA[大家好， 我目前是一名本科生。我正在寻找一个研究课题，最好是在医疗诊断领域，我可以在其中应用可解释的人工智能。 在我最初的搜索中，我发现对于医疗诊断领域的各种问题，我们已经很好-执行 ML/DL 模型。这些模型提供高精度的预测。但这些预测没有任何解释性。我想努力为这个模型添加可解释性。 如果有人建议一些有关该主题的资源或以任何方式帮助我，我将不胜感激。   由   提交/u/ornob_50  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195smzg/looking_for_a_research_topic_to_apply_explainable/</guid>
      <pubDate>Sat, 13 Jan 2024 17:05:28 GMT</pubDate>
    </item>
    <item>
      <title>[N] Michelle Gill：人工智能辅助药物发现，NVIDIA，生物基金会 |从机器学习中学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195rlga/n_michelle_gill_aiassisted_drug_discovery_nvidia/</link>
      <description><![CDATA[      聆听 NVIDIA 技术主管兼应用研究经理 Michelle Gill 博士的心声，她致力于 BioNemo 等变革性项目，通过人工智能加速药物发现。她的团队探索生物基础模型，使研究人员能够更好地执行蛋白质折叠和小分子结合等任务。 Michelle 分享了她从湿实验室生物化学家到在 NVIDIA 推动尖端人工智能的不可思议的旅程。 Michelle 讨论了生物学中的 NLP 和人工智能之间的重叠和差异。她概述了对更好的机器学习表示的迫切需求，以捕捉生物学的复杂动态。 Michelle 为机器学习领域的初学者和早期职业专业人士提供建议，强调持续学习和坚持不懈的重要性最新的工具和技术。她还分享了关于建立成功的多学科团队的见解   由   提交 /u/NLPnerd   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195rlga/n_michelle_gill_aiassisted_drug_discovery_nvidia/</guid>
      <pubDate>Sat, 13 Jan 2024 16:20:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] Google DeepMind 诊断法学硕士超过人类医生前 10 名的准确率（59% vs 34%）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195q6lu/r_google_deepmind_diagnostic_llm_exceeds_human/</link>
      <description><![CDATA[Google 和 DeepMind 的研究人员开发并评估了专门针对临床诊断推理进行微调的法学硕士。在一项新研究中，他们严格测试了法学硕士进行鉴别诊断和帮助医生的能力。 他们根据《新英格兰医学杂志》的 302 个真实案例报告对法学硕士进行了评估。众所周知，这些病例报告是高度复杂的诊断挑战。 法学硕士制作了鉴别诊断列表，其中包括 302 例病例中 177 例前 10 种可能性中的最终确诊诊断，前 10 种准确度为 59 %。 这大大超过了经验丰富的医生的表现，在没有协助的情况下，经验丰富的医生在相同病例中的前 10 名准确率仅为 34%。 根据高级专家的评估，法学硕士的在对所有 302 份病例报告进行评估时，鉴别诊断也被认为比医生做出的诊断更加合适和全面。 这项研究证明了法学硕士在提高医生水平方面的潜力&#39;对复杂病例的临床推理能力。然而，作者强调，在临床部署之前，进一步严格的现实测试至关重要。还必须解决有关模型安全性、公平性和稳健性的问题。 完整摘要。 论文。    ;由   提交 /u/Successful-Western27    reddit.com/r/MachineLearning/comments/195q6lu/r_google_deepmind_diagnostic_llm_exceeds_ human/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195q6lu/r_google_deepmind_diagnostic_llm_exceeds_human/</guid>
      <pubDate>Sat, 13 Jan 2024 15:16:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 避免机器学习项目中常见错误的资源？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195q259/d_resources_for_avoiding_common_mistakes_in/</link>
      <description><![CDATA[通常有管理者或企业家类型认为“AI”是一种技术。作为一个神奇的解决方案，然后数百万美元被浪费，因为他们不明白该解决方案有多么脆弱，如何需要更多的数据来创建泛化的解决方案，对偏见的敏感性，所需的培训数据等等。哪些可访问的信息是否可以帮助人们了解项目的实用性以及成功和道德成果所涉及的内容？   由   提交/u/Neuro-AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195q259/d_resources_for_avoiding_common_mistakes_in/</guid>
      <pubDate>Sat, 13 Jan 2024 15:11:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于可解释性和量子计算的快速问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195plsr/d_quick_question_about_interpretability_and/</link>
      <description><![CDATA[如果可解释性是关于理解模型如何工作以及模型在概率论和量子计算上的工作原理使我们能够进行更多概率计算，那么这两种技术的发展将如何相互影响？ 不知道这个问题是否有意义，我对此非常陌生，才刚刚开始我的机器学习学习之旅 - 我正在阅读 Rosenblatt 关于感知器的论文，并不断遇到推特讨论中的可解释性和量子计算，所以我想我会问 如果你们也可以推荐任何资源，我应该检查一下这是否激起了我的兴趣，那就太好了    由   提交 /u/Several-Equivalent11   /u/Several-Equivalent11 reddit.com/r/MachineLearning/comments/195plsr/d_quick_question_about_interpretability_and/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195plsr/d_quick_question_about_interpretability_and/</guid>
      <pubDate>Sat, 13 Jan 2024 14:49:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI、Google 和 Meta 等领先的人工智能研究组织如何跟踪和管理他们的大规模人工智能实验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195lwlh/d_how_do_leading_ai_research_organizations_like/</link>
      <description><![CDATA[我非常有兴趣了解 OpenAI、Google 和 Meta 的研究人员用来跟踪他们的 AI 实验的工具和技术。这包括他们如何管理不同版本的人工智能模型以及在这些模型上运行的各种测试等事物。我很想知道他们使用哪些特定工具来完成这些任务。此外，如果能够了解他们是否遵循任何推荐的方法或最佳实践来有效地组织和处理这些实验运行，那就太好了。由于我也是一名研究人员，这些信息对我来说非常有用。   由   提交 /u/Few-Pomegranate4369    reddit.com/r/MachineLearning/comments/195lwlh/d_how_do_leading_ai_research_organizations_like/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195lwlh/d_how_do_leading_ai_research_organizations_like/</guid>
      <pubDate>Sat, 13 Jan 2024 11:21:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] UnIVAL：图像、视频、音频和语言任务的统一模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195eulx/r_unival_unified_model_for_image_video_audio_and/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2307.16184 OpenReview：https:// /openreview.net/forum?id=4uflhObpcp 代码：https： //github.com/mshukor/UnIVAL 检查点：https://github.com/mshukor/UnIVAL/blob/main/checkpoints.md 项目页面：https://unival-model.github.io/ 演示：https://huggingface.co/spaces/mshukor/UnIVAL 视频：&lt; a href=&quot;https://www.youtube.com/watch?v=mYOun92st08&quot;&gt;https://www.youtube.com/watch?v=mYOun92st08 摘要：  大型语言模型（LLM）使对通才智能体的雄心勃勃的追求不再是一个幻想。构建此类通用模型的一个关键障碍是任务和模式的多样性和异质性。一种有希望的解决方案是统一，允许在一个统一的框架内支持无数的任务和模式。虽然在海量数据集上训练的大型模型（例如 Flamingo（Alayrac 等人，2022））可以支持两种以上的模态，但当前的中小型统一模型仍然仅限于 2 种模态，通常是图像文本或视频-text.我们要问的问题是：是否有可能高效地构建一个能够支持所有模态的统一模型？为了回答这个问题，我们提出了UnIVAL，朝着这个雄心勃勃的目标又迈进了一步。在奇特的数据集大小或具有数十亿参数的模型上，~ 0.25B 参数 UnIVAL 模型超越了两种模式，并将文本、图像、视频和音频统一到单个模型中。我们的模型基于任务平衡，在许多任务上进行了有效的预训练和多模态课程学习。UniVAL 在图像和视频文本任务中显示出与现有最先进方法相比的竞争性能。从图像和视频文本模态中学习的特征表示，允许模型在微调时实现竞争性能音频文本任务，尽管没有经过音频预训练。得益于统一模型，我们提出了一项通过对不同多模态任务训练的模型进行权重插值来进行多模态模型合并的新颖研究，展示了它们特别是对于分布外泛化的好处。最后，我们通过展示任务之间的协同作用来激励统一。模型权重和代码在这里发布：这个 https URL.    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195eulx/r_unival_unified_model_for_image_video_audio_and/</guid>
      <pubDate>Sat, 13 Jan 2024 03:54:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前最好的文字转语音工具是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195cxim/d_what_is_the_best_texttospeech_tool_currently/</link>
      <description><![CDATA[大家好，我需要一个听起来完全像人声的 TTS 工具。我想用它来编辑我的一些 YouTube 视频，更具体地说，上传我自己选择的语音样本并从中生成良好的结果。我看到周围有很多 TTS 平台。你推荐哪一个？我希望这不是一个过分的要求。我将非常感激。 提前致谢。   由   提交 /u/FateRiddle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195cxim/d_what_is_the_best_texttospeech_tool_currently/</guid>
      <pubDate>Sat, 13 Jan 2024 02:18:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 适合面试的 ML 工程题库好吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/</link>
      <description><![CDATA[我一直在研究 ML 工程面试（并做了一些），我意识到“了解偏见”的常见建议，方差、交叉折叠验证等”。都是错的。顶级公司要求你使用 Pytorch/numpy 编写简单的代码。所以问题是这样的：“编写一个神经网络来解决 X 问题”或者“编写一个神经网络来解决 X 问题”。或“使用 numpy 实现 k-means”。 考虑到这种情况，我认为通过做一堆编码问题来准备这些面试会更有用。 我想知道这里的人是否可以分享他们在 ML Eng 面试中遇到的一些编码问题，或者向我指出好的 Leetcode 风格的 MLEng 题库？  &amp;# 32；由   提交 /u/lisp-cloj    reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/</guid>
      <pubDate>Fri, 12 Jan 2024 23:00:47 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待 Yann Lecun 关于 ML 的有争议的观点？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/</link>
      <description><![CDATA[      Yann Lecun 有一些有争议的观点关于 ML 的看法，他并不羞于分享。他写了一篇名为“通往自主机器智能之路”的立场文件。不久以前。此后，他也就此发表了很多演讲。这是屏幕截图 ​ https://preview.redd.it/xxmxgrdk02cc1.jpg?width=1581&amp;format=pjpg&amp;auto=webp&amp;s=4a7e98f5a41f2e454e2e33881f2 df93c7287d09b 来自&lt; a href=&quot;https://www.youtube.com/watch?v=OKkEdTchsiE&quot;&gt;一个，但我看过几个 - 它们很相似，但不完全相同。以下并不是所有演讲的摘要，而只是他对 ML 现状的批评，根据记忆进行解释（他还谈论了 H-JEPA，我在这里忽略了）：  &lt; li&gt;法学硕士无法商业化，因为内容所有者“喜欢reddit”会起诉（奇怪的是，鉴于最近的《纽约时报》诉讼，这是有先见之明的） 当前的机器学习很糟糕，因为与人类相比，它需要大量的数据（我认为有两种截然不同的可能性：算法本身是不好，或者人类只是在童年时期进行了更多的“预训练”） 规模化是不够的 自回归法学硕士注定会失败，因为任何错误都会让你偏离正确的道路，随着输出数量的增加，不犯错误的概率很快接近 0 LLM 无法推理，因为它们只能执行有限数量的计算步骤 连续建模概率域是错误的，因为你会得到无限梯度 对比训练（如 GAN 和 BERT）是不好的。您应该进行正规化训练（例如 PCA 和稀疏 AE） 生成建模是误导性的，因为世界的大部分内容都是不可预测或不重要的，不应该由智能系统建模 人类通过被动视觉观察了解他们对世界的大部分了解（我认为这可能与先天失明的人可能非常聪明的事实相矛盾） 你不&#39;智能行为不需要巨大的模型，因为老鼠只有数千万个神经元，就超越了当前的机器人人工智能    由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/</guid>
      <pubDate>Fri, 12 Jan 2024 19:14:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>