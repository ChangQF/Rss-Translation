<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 23 Apr 2024 06:20:21 GMT</lastBuildDate>
    <item>
      <title>[D] 为什么在 WAWQI 上建立机器学习模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1caw5ft/d_why_ml_models_on_wawqi/</link>
      <description><![CDATA[我正在做一个关于水质预测的项目。为了训练机器学习模型，我们需要 x（自变量）和 y（因变量）值。我正在使用加权 arethamatic 水质指数，使用一些数学方程从 x 计算 y 值，现在在计算 y 值后，我正在根据 x 和 y 值训练 ml 模型。我的问题是，机器学习模型值得应用吗？他们是否做了一些附加组件来查找信息？问题强调了当加权算术水质指数 (WAWQI) 已经可用时，使用 ML 模型进行水质预测的一个重要考虑因素 我认为，通过计算 ML 模型的 wawqi 值也可以完成与 ML 模型相同的操作测试数据，然后根据wawqi值判断水的好坏。那么为什么需要使用机器学习模型呢？我看到一些论文在做同样的事情，但不明白为什么？ 感谢有用的输入。   由   提交/u/Silver_Bison_4987   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1caw5ft/d_why_ml_models_on_wawqi/</guid>
      <pubDate>Tue, 23 Apr 2024 04:53:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 迫切需要一份机器学习工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cavn8s/d_desperate_for_a_job_in_machine_learning/</link>
      <description><![CDATA[大家好！我是一名在美国的国际学生，正在大学学习数据科学（主修机器学习）的第四个学期，我的梦想是成为一名机器学习工程师。 我在毕业后转专业为数据科学。我第一年学习CS，所以我基本上是这个领域的新手。我发现我真的很喜欢这个专业，并且我在学校选修了一些数据科学课程以及自己的一些机器学习课程（Andrew Ng 的机器学习和深度学习专业，DeepLearning.ai，AWS 基础专业化，...）。此外，我在 GitHub 上还有一些个人项目。然而，我仍在努力寻找实习机会，并弄清楚我还需要学习/改进什么才能得到这份工作。 通过这一点，我希望每个在该领域拥有知识/专业知识的人可以与我分享一个很好的路线图，以找到工作/脱颖而出，成为一名有抱负的机器学习工程师。非常感谢任何支持/建议。谢谢！   由   提交/u/Thomas_ng_31   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cavn8s/d_desperate_for_a_job_in_machine_learning/</guid>
      <pubDate>Tue, 23 Apr 2024 04:24:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] Phi-3即将发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/</link>
      <description><![CDATA[从 MSFT 的两个独立消息来源（其中一个接近 Sebastien Bubeck）了解到即将推出的 Phi-3 模型：  三个不同大小的模型（最多 14B） 同样，主要是合成和 LLM 增强的训练数据 显然在训练方面有一些升级技​​术 否更多 Apache 2，但更严格的许可证（类似于 llama3） Mixtral 级别性能，参数少得多  我想看看是否有人有更多有关模型的内部信息.   由   提交/u/yusuf-bengio  /u/yusuf-bengio  reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/</guid>
      <pubDate>Tue, 23 Apr 2024 01:13:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML 管道中的观察</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1caqesl/d_observation_in_ml_pipelines/</link>
      <description><![CDATA[对于我迄今为止见过的十几个模型，用于训练和验证的数据量（经过所有清理和过滤）是只有几千条记录（我见过的最大记录是500K）。这常见吗？   由   提交/u/mdghouse1986  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1caqesl/d_observation_in_ml_pipelines/</guid>
      <pubDate>Tue, 23 Apr 2024 00:06:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM准确性评估方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1caq0jy/d_llm_accuracy_evaluation_methods/</link>
      <description><![CDATA[ML 社区您好， 我想了解人们如何在工作场所或个人用途中评估 LLM 的准确性。每个人都想采用法学硕士，但到目前为止我看到的用例在设置上都很相似。这是一个非常复杂的场景，所以我认为这对于志同道合的人来说是一个相互联系和分享想法的好机会。 本文为业界目前使用的一些 LLM 评估方法提供了不错的入门知识。 网络上的文章围绕以下内容进行讨论：以下指标：  ROUGE 分数、BLEU / BLEURT 分数、MAE 等。 自然语言推理（蕴涵）分数。 构建真实数据集，并比较答案的相关性、上下文的相关性和接地性（无论答案是否使用上下文）。 思想链和基本的自我评估，以检测和调节幻觉、情绪、语气、刻板印象和不准确的逻辑假设。 用户调查和用户反馈的机会，例如赞成/反对 UI。  最近有一些库，例如 Trulens、DeepEval 和 RAGAS 旨在解决 LLM 评估中存在的问题。但我想了解以下内容：  有人尝试任何新颖的方法来评估 LLM 的准确性吗？ 有没有人看过最近发布的旨在提供全面的利基论文评估聊天机器人的准确性尤其是没有地面真实数据集？大多数论文都是 2023 年末发表的，并使用一套相当严格的评估指标。  适当的背景：我在高等教育和教育科技数据科学领域工作。因此，准确性评估对于面向学生和面向员工的 LLM 用例至关重要。   由   提交 /u/Varunshou   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1caq0jy/d_llm_accuracy_evaluation_methods/</guid>
      <pubDate>Mon, 22 Apr 2024 23:48:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 文本行扭曲数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cao4lv/r_text_line_dewarping_dataset/</link>
      <description><![CDATA[我正在寻找包含弯曲文本线（最好每个图像一个）的任何公共可用数据集，例如“弯曲文本字符串的对齐”中的数据集增强 OCR 可读性”。   由   提交/u/Neural_Prodigy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cao4lv/r_text_line_dewarping_dataset/</guid>
      <pubDate>Mon, 22 Apr 2024 22:27:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么选择 FID 而不是 ViT 模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1can2dg/d_why_fid_over_a_vit_model/</link>
      <description><![CDATA[标题基本上概括了这一点，但为什么我们要使用“更糟糕”的标题？计算图像距离的模型？我认为 ViT 模型能够更好地捕获图像之间的语义差异？   由   提交/u/Karan1213  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1can2dg/d_why_fid_over_a_vit_model/</guid>
      <pubDate>Mon, 22 Apr 2024 21:46:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有计算机视觉或机器人技术的实例级数据存储库？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1calk37/d_is_there_any_instancelevel_data_repository_for/</link>
      <description><![CDATA[通过实例级数据，我的意思是，如果我有一个数据集并用它评估两个模型，则不仅仅是报告平均准确度等聚合指标，数据将如下所示： 模型 1，图像 1：正确 模型 1，图像 2：失败 模型 2，图像 1：失败 模型 2，图像2：失败 对于语言模型和文本到文本或文本到图像任务，HELM 计划 (https://crfm.stanford.edu/helm/lite/latest/）出现了。 计算机视觉或机器人等其他领域有类似的东西吗？   由   提交/u/RF-Enthusiast   /u/RF-Enthusiast reddit.com/r/MachineLearning/comments/1calk37/d_is_there_any_instancelevel_data_repository_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1calk37/d_is_there_any_instancelevel_data_repository_for/</guid>
      <pubDate>Mon, 22 Apr 2024 20:47:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 dspy、neo4j 和向量数据库进行自优化确定性 LLM 内存。需要您的意见：Cognee.ai（第 5 部分）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cakjaf/d_selfoptimizing_deterministic_llm_memory_using/</link>
      <description><![CDATA[      嘿，Reddit 用户！ 我带着关于创建确定性 LLM 内存的最新文章回来了。 如果您一直在关注，您就知道我&#39;我的使命是超越“瘦 OpenAI 包装器”趋势并应对构建强大的 LLM 内存的挑战。 这就是为什么我们构建了 cognee，一个用于处理文档并在其上构建知识图的 Python 库。 几周后在工作中，我们集成了 DSPy 和扩展的 cognee。 以下是逻辑的简要概述： 架构概述 我们的目标是了解：  有您以前尝试过使用其他工具构建知识图谱吗？ 如果是的话，最大的障碍是什么？ 您会如何做在没有知识图的情况下实现文档的语义链接？  如果您发现这篇文章很有见地，请记得给它点赞！ 并且还为我们的 Github 存储库  &amp; #32；由   提交/u/Snoo-bedooo  /u/Snoo-bedooo reddit.com/r/MachineLearning/comments/1cakjaf/d_selfoptimizing_definistic_llm_memory_using/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cakjaf/d_selfoptimizing_deterministic_llm_memory_using/</guid>
      <pubDate>Mon, 22 Apr 2024 19:57:26 GMT</pubDate>
    </item>
    <item>
      <title>[P] seemore：从头开始实现视觉语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cada35/p_seemore_implement_a_vision_language_model_from/</link>
      <description><![CDATA[大家好，我在纯 pytorch 中实现了一个由图像编码器、多模态投影模块和解码器语言模型组成的视觉语言模型。可以将其视为您在 GPT-4 或 Claude 3 中看到的语言模型所展示的视觉功能的简化版本（当谈到开源模型时，请考虑 Moondream 2 或 LLaVA）。 “seemore”这个名字是我向 Andrej Karpathy 的项目“makemore”致敬的方式，因为在这里我使用了字符级自回归语言模型，就像他的 nanoGPT/makemore 实现一样。我的目标是让它成为一个可破解的实现，人们可以用它来理解它是如何真正工作和改进的。我预计全年会出现越来越多的此类模型。 带有存储库链接的博客位于：https://huggingface.co/blog/AviSoori1x/seemore-vision-language-model 希望这有帮助或至少有趣！ （将此内容发布在 LocalLlama 上，但认为这同样适用于一般机器学习）   由   提交/u/avi1x  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cada35/p_seemore_implement_a_vision_language_model_from/</guid>
      <pubDate>Mon, 22 Apr 2024 15:10:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama-3 可能刚刚杀死了专有的人工智能模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</link>
      <description><![CDATA[完整博客文章  Meta 在三天前发布了 Llama-3，感觉开源模型终于缩小了与专有模型的差距，这已经是一个拐点。初始基准测试显示 Llama-3 70B 在许多任务中非常接近 GPT-4：  官方元页面仅显示Llama-3优于Gemini 1.5和Claude Sonnet。 人工分析显示 Llama-3 的质量介于 Gemini-1.5 和 Opus/GPT-4 之间。 关于 LMSYS 聊天机器人竞技场排行榜，Llama-3 排名第 5，而当前的 GPT-4 模型和 Claude Opus 仍并列第 1。  功能更强大Llama-3 400B+ 模型仍在训练中，发布后很可能超越 GPT-4 和 Opus。 Meta vs OpenAI 有人推测 Meta 从一开始的目标就是瞄准OpenAI 采用“焦土”方法，通过发布强大的开放模型来扰乱竞争格局并避免在竞争中落后AI 竞赛。 Meta 在计算和人才方面可能会超过 OpenAI：  OpenAI 的预计收入为 20 亿美元，并且可能无利可图。 2023 年，Meta 的收入为 $134B，利润为 $39B。 Meta 的计算资源目前可能超过 OpenAI。 开源可能会吸引更好的人才和研究人员。  &gt;  一个可能的结果是微软收购 OpenAI 以赶上 Meta。谷歌也在进军开放模型领域，并拥有与 Meta 类似的功能。看看它们适合什么位置将会很有趣。 获胜者：开发人员和人工智能产品初创公司 我最近写了一篇关于现在建立人工智能初创公司令人兴奋，因为您的产品会随着每个主要模型的进步而自动改进。随着 Llama-3 的发布，开发人员的机会更大：  不再受供应商锁定。 开发人员不仅可以封装专有 API 端点，还可以现在以一种非常经济高效且高性能的方式将人工智能深度集成到他们的产品中。 Hugging Face 上已经有超过 800 个 llama-3 模型变体，而且看起来每个人都能够针对他们的使用案例、语言或行业进行微调。 更快、更便宜的硬件：Groq 现在每秒可以生成 800 个 llama-3 代币，而成本只是 GPT 成本的一小部分。以低价提供近乎即时的 LLM 响应即将到来。  视觉和视频的开源多模式模型仍然需要迎头赶上，但我预计这很快就会发生。 Llama-3 的发布标志着人工智能民主化的一个重要里程碑，但现在宣布专有模型的消亡可能还为时过早。谁知道呢，也许 GPT-5 会让我们所有人感到惊讶，并超越我们对 Transformer 模型功能的想象。 这绝对是人工智能领域构建的超级激动人心的时代！    由   提交 /u/madredditscientist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</guid>
      <pubDate>Mon, 22 Apr 2024 15:08:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 循环记忆突破了 Transformer 神经网络的上下文长度限制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca6zvl/r_recurrent_memory_has_broken_the_limits_of/</link>
      <description><![CDATA[      研究人员对序列进行了分段，并向输入添加了特殊的记忆标记：来自输出的记忆状态上一段的数据成为下一段的输入。因此，整个变压器充当循环单元，而存储器充当网络的循环状态。这种方法被称为循环记忆变压器（RMT）。 作者用这种记忆增强了 BERT 和 GPT-2 等小型变压器模型，并在各种问答任务中对它们进行了测试，其中回答所需的事实位于文本。研究发现，使用循环记忆显着增加了输入序列的长度，同时保持令人满意的神经网络性能准确性。在他们的实验中，科学家们能够将这个值扩展到 200 万个代币。据作者称，该值进一步增加没有根本限制，因为 RMT 的计算复杂度随着令牌数量线性增长。 在三个任务上使用 RMT 增强的预训练 BERT 模型的准确性与输入序列中的标记数量的关系。灰色数字表示 GPU 内存消耗，垂直线表示 SOTA 模型的长度限制（截至 2023 年底） 该研究发表在 AAAI- 的会议记录上24 日会议上，预印本中提供了更多详细信息，代码可在预印本中找到。 com/booydar/recurrent-memory-transformer/tree/aaai24&quot;&gt;Gi​​tHub.   由   提交 /u/AIRI_Institute   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca6zvl/r_recurrent_memory_has_broken_the_limits_of/</guid>
      <pubDate>Mon, 22 Apr 2024 10:08:22 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 对于拥有丰富 SWE 经验、试图通过做个人项目和创建作品集来进入 ML 工程或数据工程的人来说，现实是什么？这是一个现实的目标吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca2j8j/discussionwhat_is_the_reality_for_someone_with/</link>
      <description><![CDATA[寻找极其诚实的意见。对于数据工程师来说，现实情况是否有所不同，因为我发现目前的供应需求使 DE 具有吸引力？    由   提交/u/Emergency-Director53  /u/Emergency-Director53 reddit.com/r/MachineLearning/comments/1ca2j8j/discussionwhat_is_the_reality_for_someone_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca2j8j/discussionwhat_is_the_reality_for_someone_with/</guid>
      <pubDate>Mon, 22 Apr 2024 05:11:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 GNN 在工业界的需求不高？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9vibh/d_why_isnt_gnn_in_high_demand_in_industry/</link>
      <description><![CDATA[几乎没有数据科学家或机器学习工程师的职位发布需要 GNN。 是因为它的计算成本很高 - 无论是时间还是空间？或者是因为将数据预处理为图形格式并不总是直观的？或者 GNN 在学术界之外的认知度仍然很低？   由   提交/u/Snoo_72181   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9vibh/d_why_isnt_gnn_in_high_demand_in_industry/</guid>
      <pubDate>Sun, 21 Apr 2024 23:04:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>