<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 04 Feb 2024 01:01:02 GMT</lastBuildDate>
    <item>
      <title>差异隐私和统计查询[讨论]，[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aibbbc/differential_privacy_and_statistical_queries/</link>
      <description><![CDATA[有人使用过统计查询模型吗？我想知道在神经网络中使用统计查询是否明智？尽管我读过一些论文，但神经网络中查询的运行时间是指数级的，因此不建议这样做。我们有什么办法可以在神经网络中实现隐私吗？   由   提交 /u/Hopeful-Foot5888    reddit.com/r/MachineLearning/comments/1aibbbc/ Differential_privacy_and_statistical_queries/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aibbbc/differential_privacy_and_statistical_queries/</guid>
      <pubDate>Sun, 04 Feb 2024 00:57:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 不确定性量化和人工智能对齐之间的联系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aib9rw/r_connections_between_uncertainty_quantification/</link>
      <description><![CDATA[大家好， ​ 正如标题所示，我正在寻找指针连接机器学习这两个领域的（研究论文或集思广益的想法）。 对于那些不熟悉对齐的人，这是最独特的论文： https://arxiv.org/pdf/2203.02155.pdf ​ 谢谢！&lt; /p&gt; ​ ​   由   提交/u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aib9rw/r_connections_between_uncertainty_quantification/</guid>
      <pubDate>Sun, 04 Feb 2024 00:54:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何模仿openAI工具/功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aiabgk/d_how_to_mimic_openai_toolsfunctions/</link>
      <description><![CDATA[我有兴趣探索针对特定场景使用替代 GPT 模型复制 OpenAI 功能的方法。想象一下有一个包含各种函数及其规范的字典。当用户提出问题时，系统应该能够正确识别这些功能并对其进行排序，以构建连贯的响应。此外，我对从头开始开发这样一个系统所需的基本步骤感到好奇。具体来说，从函数字典及其规范开始，如何设计一种生成代码响应的机制？感谢任何指导/输入，因为我从未自己训练过任何模型。 OpenAI 的回答对这个问题没有帮助:)   由   提交/u/mrg3_2013   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aiabgk/d_how_to_mimic_openai_toolsfunctions/</guid>
      <pubDate>Sun, 04 Feb 2024 00:09:27 GMT</pubDate>
    </item>
    <item>
      <title>ViT 基准数据增强 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aia4lj/benchmark_data_augmentation_for_vit_r/</link>
      <description><![CDATA[您好，我正在对 ViT 进行研究，为此我需要将我的方法与其他方法进行比较。另外，我需要遵循相同的增强技术作为基准。  我认为 DeiT https://github.com/facebookresearch/deit/tree/main 是一个合适的基准，但查看存储库似乎很复杂，我担心我可能无法完全或以相同的顺序应用它们。  是否有像 timm 这样的标准库具有用于 DeiT 数据增强的内置管道。或者有人已经用我可以使用的更简单的代码编写了 DeiT。  提前致谢！ ​   由   提交/u/NoEntertainment6225   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aia4lj/benchmark_data_augmentation_for_vit_r/</guid>
      <pubDate>Sun, 04 Feb 2024 00:00:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习验证/测试工程师？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ai96mz/d_ml_validationtest_engineer/</link>
      <description><![CDATA[我正在接受一家公司的面试，我一直想在这家公司工作一段时间，但该职位的标题是有点令人困惑。职位名称是机器学习工程师（验证）。我过去曾在机器学习领域工作过，而且我也曾在嵌入式系统领域工作过，这也是这家公司的业务，所以看起来很合适。 我不知道这个职位是否合适这只是 HR 人员通过将 ML 作为一个流行词附加到真正普通的测试工程师角色上来吸引更多申请者的一种方式，或者如果系统测试过程中实际上使用了很多我没有使用的 ML知道关于。在职位描述中，没有具体提及他们希望在测试中使用 ML 的方式，尽管他们确实提到工程师将对利用 ML 系统的产品进行验证和回归测试。 有人遇到过这样的事情吗？如果您是一名使用 ML 的工程师并且将其用作测试工具，我很想更多地了解您的体验。我主要是好奇，这样我就能知道面试中会发生什么。   由   提交/u/Educational_Pause_51   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ai96mz/d_ml_validationtest_engineer/</guid>
      <pubDate>Sat, 03 Feb 2024 23:18:04 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型努力学习长尾知识 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ai7en3/large_language_models_struggle_to_learn_longtail/</link>
      <description><![CDATA[      https://arxiv.org/abs /2211.08411 ​ 摘要： 互联网蕴藏着丰富的知识——来自历史人物的生日到如何编码的教程——所有这些都可以通过语言模型来学习。然而，虽然某些信息在网络上无处不在，但其他信息却很少出现。在本文中，我们研究了大型语言模型记忆的知识与从网络上抓取的预训练数据集中的信息之间的关系。特别是，我们表明语言模型回答基于事实的问题的能力与在预训练期间看到的与该问题相关的文档数量有关。我们通过链接预训练数据集的实体和对包含与给定问答对相同的实体的文档进行计数来识别这些相关文档。我们的结果证明了众多问答数据集（例如 TriviaQA）、预训练语料库（例如 ROOTS）和模型大小（例如 176B 参数）的准确性和相关文档计数之间存在很强的相关性和因果关系。此外，虽然较大的模型更擅长学习长尾知识，但我们估计当今的模型必须扩展多个数量级，才能在预训练数据支持很少的情况下在问题上达到有竞争力的 QA 性能。最后，我们证明检索增强可以减少对相关预训练信息的依赖，为捕获长尾提供了一种有前景的方法。 ​ &amp;# x200b; https://preview .redd.it/t8f3b4flzfgc1.png?width=603&amp;format=png&amp;auto=webp&amp;s=09c243c055b2d5d9aa18192c4082970d8a1e1381   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ai7en3/large_language_models_struggle_to_learn_longtail/</guid>
      <pubDate>Sat, 03 Feb 2024 21:58:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 人们还相信LLM的新兴能力吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ai5uqx/r_do_people_still_believe_in_llm_emergent/</link>
      <description><![CDATA[自从[新兴的LLM能力是海市蜃楼吗？](https://arxiv.org/pdf/2304.15004.pdf），人们似乎对涌现非常安静。但是大的[新兴能力](https://openreview.net/pdf?id=yzkSU5zdwD)论文有这一段（第 7 页）： &gt;考虑用于衡量新兴能力的评估指标也很重要（BIG-Bench，2022）。例如，使用精确的字符串匹配作为长序列目标的评估指标可能会将复合增量改进伪装成出现。类似的逻辑可能适用于多步骤或算术推理问题，其中模型仅根据是否正确获得多步骤问题的最终答案来评分，而不会给予部分正确的解决方案任何信用。然而，最终答案准确性的跳跃并不能解释为什么中间步骤的质量突然出现在随机之上，并且使用不给予部分信用的评估指标充其量是一个不完整的解释，因为在许多分类任务中仍然观察到涌现的能力（例如，图 2D-H 中的任务）。 人们怎么想？涌现是“真实的”吗？还是实质性的？   由   提交/u/uwashingtongold  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ai5uqx/r_do_people_still_believe_in_llm_emergent/</guid>
      <pubDate>Sat, 03 Feb 2024 20:50:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] TimesFM：基于 1000 亿个真实世界数据点进行预训练的基础预测模型，在不同领域提供前所未有的零样本性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahzmdc/r_timesfm_a_foundational_forecasting_model/</link>
      <description><![CDATA[       由   提交 /u/BlupHox   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahzmdc/r_timesfm_a_foundational_forecasting_model/</guid>
      <pubDate>Sat, 03 Feb 2024 16:15:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用局部水印主动检测语音克隆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahzdr0/r_proactive_detection_of_voice_cloning_with/</link>
      <description><![CDATA[人工智能语音合成的快速进步带来了令人难以置信的虚假人类语音，引发了人们对语音克隆和深度伪造音频的担忧。 &lt;随着人工智能合成的改进，被动分析作为检测虚假音频的传统方法面临着挑战。这些方法往往依赖于工件，但这些方法是特定于模型的。而且模型质量不断提高，伪影数量也减少了。 Meta 和 Inria 的研究人员开发了 AudioSeal，这是一种新技术，可以在人工智能生成的语音上添加难以察觉的水印以供检测。  AudioSeal 专注于定位音频剪辑中的合成语音。它的两个组件（生成器和检测器）协同工作，提供样本级精度和稳健的检测。 AudioSeal 的创新包括样本级精度、稳健的感知损失、音频失真恢复能力和高效检测，使得速度非常快。 联合训练生成器和检测器可以最大限度地减少感知差异并最大限度地提高准确性，即使存在屏蔽或扭曲的区域也是如此。我发现这是本文的关键见解。 AudioSeal 在通用性、样本级别的本地化、针对音频失真的鲁棒性、效率和模型身份消息的容量方面表现出色。它的检测速度大约比 WavMark 快两个数量级，生成水印的速度快 14 倍。 虽然很有希望，但应考虑道德问题和保密性需求，并且可能需要标准化才能得到更广泛的采用。&lt; /p&gt; TLDR：AudioSeal 是一种检测假音频的新颖解决方案，具有本地化且强大的检测功能。它也比 WavMark 快得多。 论文这里。存储库位于此处。完整摘要位于此处。 &lt; /div&gt;  由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/1ahzdr0/r_proactive_detection_of_voice_cloning_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahzdr0/r_proactive_detection_of_voice_cloning_with/</guid>
      <pubDate>Sat, 03 Feb 2024 16:04:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求建议：从工业界转向 NLP 研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahzdj7/d_seeking_advice_transitioning_from_industry_to/</link>
      <description><![CDATA[嘿各位 Reddit 用户， 简单介绍一下我的背景 - 我目前在行业内的数据分析领域工作，并且我的日常任务与自然语言处理（NLP）没有直接关系。然而，我对 NLP 充满热情，并渴望攻读博士学位。在该领域。我渴望获得研究经验。我拥有计算机科学学士和硕士学位。 由于我不隶属于大学，因此我正在寻求有关如何应对这一转变的指导。有人可以分享关于如何在学术环境之外有效参与 NLP 研究的见解吗？我可以采取哪些实际步骤来为该领域做出贡献、建立研究组合、增加攻读 NLP 博士学位以及让我的工作得到顶级会议和期刊认可的机会？ 个人建议经验或推荐资源将不胜感激。预先感谢您！   由   提交/u/Puzzleheaded_Big_242   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahzdj7/d_seeking_advice_transitioning_from_industry_to/</guid>
      <pubDate>Sat, 03 Feb 2024 16:04:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2024 年 1 月研究论文：模型合并、专家混合、迈向小型法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahwint/p_research_papers_in_jan_2024_model_merging/</link>
      <description><![CDATA[       由   提交/u/seraschka  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahwint/p_research_papers_in_jan_2024_model_merging/</guid>
      <pubDate>Sat, 03 Feb 2024 13:49:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 康威的生命游戏作为神经网络的实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahqs0n/p_conways_game_of_life_implement_as_a_neural/</link>
      <description><![CDATA[       由   提交/u/liMrMil  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahqs0n/p_conways_game_of_life_implement_as_a_neural/</guid>
      <pubDate>Sat, 03 Feb 2024 07:41:40 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 梯度下降的最佳矩阵乘法算法。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahoo9q/project_the_best_matrix_multiplication_algorithm/</link>
      <description><![CDATA[我正在尝试用 0 个依赖项在 Rust 中实现神经网络。我知道施特拉森只擅长高排名，并且错误增加（来源是极客的极客，所以可能是可疑的）。不管怎样，我想知道我应该使用什么算法来进行矩阵乘法，以及它是否会产生很大的差异。   由   提交 /u/ANARCHY14312   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahoo9q/project_the_best_matrix_multiplication_algorithm/</guid>
      <pubDate>Sat, 03 Feb 2024 05:29:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在这里没有看到足够多的人赞扬 dinov2 ！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ahkxjh/d_i_dont_see_enough_people_praising_dinov2_here/</link>
      <description><![CDATA[大家好！ 我只是想写一条简短的消息，让这里的每个人都知道 dinov2 是一个多么强大的工具对我来说！我已经对其进行了微调，可以对图像进行多种不同目的的分类，并且每次类只有 20-50 张图像，它总是很成功。根据我使用它的用例：对 3D/照片图像进行分类，带水印/无水印图像、模糊/非模糊图像、面部识别（识别 dlib 对齐的面部是否特定属于某个人）、艺术家风格、验证图像中特定对象上方的分割是否正确等等。 .. 在 dinov2 的整个系列中，我从未使用过比小型模型更大的东西（尽管我使用 448x448 图像），因此它无需使用太多 VRAM 即可工作，并且可以批量处理 100 个图像一次！ 最近我什至尝试在暹罗架构中对 dinov2 进行微调，只用一个新的头部来获取两个图像的特征，这样它就可以将两个图像放在一起比较（不用说太多，我想知道是否两者都图像遵循共同的结构）并且它工作得很好。 我还使用它来将图像的特征提供给稳定扩散，并且它也工作得很好（使用 IP 适配器架构）。 &gt; 我唯一没能做到的就是使用它进行分割，但我认为这是因为我的数据集和/或实现，所以如果你们中有人做到了，我很想与你们交谈交流良好实践！ 如果您希望脚本对其进行微调/推理以进行分类，我很乐意分享它们。 您呢？你用 dinov2 吗？如果是，为什么以及如何？您对此有何体验？   由   提交 /u/Antique-Bus-7787   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ahkxjh/d_i_dont_see_enough_people_praising_dinov2_here/</guid>
      <pubDate>Sat, 03 Feb 2024 02:08:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>