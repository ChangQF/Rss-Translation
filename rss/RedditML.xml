<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 20 Apr 2024 00:58:35 GMT</lastBuildDate>
    <item>
      <title>[N] 何凯明关于表征学习的深度学习架构讲座</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8d5m1/n_kaiming_hes_lecture_on_dl_architecture_for/</link>
      <description><![CDATA[https://youtu.be/D_jt-xO_RmI 非常好的讲座，DL 历史架构进展的最高信噪比。   由   提交 /u/lkphuc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8d5m1/n_kaiming_hes_lecture_on_dl_architecture_for/</guid>
      <pubDate>Sat, 20 Apr 2024 00:57:29 GMT</pubDate>
    </item>
    <item>
      <title>您认为强化学习仍然有效吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c87bh4/do_you_think_reinforcement_learning_still_got_it_d/</link>
      <description><![CDATA[最近我听到很多人说强化学习本身多年来没有任何改进（也许 alphago 是最后的大事）。  而人工智能的其他领域已经出现了许多 SOTA 架构，例如用于基于序列的任务的“Transformers”以及“ResNet”、“Diffusers”和“SOTA”架构。 “VAE”类似于计算机视觉任务的架构。 我认为，无论是直接还是间接，强化学习仍然在使用“RLHF”技术的 ChatGPT 和 Claude 等法学硕士背后发挥着至关重要的作用。以及许多其他最新技术，包括自动驾驶汽车和机器人。  我认为这只是这个领域的一个寒冷的冬天，在未来几年里很快就会找到最先进的建筑（或者这就是我所希望的） 你的想法是什么想法？ 🤔   由   提交/u/cyb0rg14_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c87bh4/do_you_think_reinforcement_learning_still_got_it_d/</guid>
      <pubDate>Fri, 19 Apr 2024 20:40:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] TorchFix - 具有自动修复支持的 PyTorch 使用代码的 linter</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c83rcw/p_torchfix_a_linter_for_pytorchusing_code_with/</link>
      <description><![CDATA[TorchFix 是一款针对 PyTorch 用户的 Python 代码静态分析工具 - 具有自动修复功能的 linter。它可用于查找和修复问题，例如使用已弃用的 PyTorch 函数和非公共符号，并一般采用 PyTorch 最佳实践： https://github.com/pytorch-labs/torchfix   由   提交/u/kit1980  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c83rcw/p_torchfix_a_linter_for_pytorchusing_code_with/</guid>
      <pubDate>Fri, 19 Apr 2024 18:13:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] Google 是否将凭借其海量数据资源主宰 RAG 场景？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c824at/d_is_google_set_to_dominate_the_rag_scene_with/</link>
      <description><![CDATA[大家好！看起来几年后，我们使用的基本大语言模型（LLM）将会商品化，你选择哪一个并不重要。下一个重大事件可能是使用检索增强生成 (RAG) 的法学硕士，这意味着他们需要大量数据才能正常工作。 鉴于 Google 可以通过其搜索引擎访问大量数据，您认为与其他公司相比，他们在这个新阶段是否处于更好的领先地位？大家觉得怎么样？   由   提交 /u/Few-Pomegranate4369    reddit.com/r/MachineLearning/comments/1c824at/d_is_google_set_to_dominate_the_rag_scene_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c824at/d_is_google_set_to_dominate_the_rag_scene_with/</guid>
      <pubDate>Fri, 19 Apr 2024 17:06:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 基于AI的语言老师，可以在12GB显卡（RTX 4070）上本地运行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7ymal/p_aibased_language_teacher_that_can_run_locally/</link>
      <description><![CDATA[我最近一直在尝试各种开源模型。 我认为我可以尝试的一个有趣的应用程序是 我最近一直在尝试各种开源模型。语文老师&gt; 🌍  结果还不错，你可以在这里尝试一下： https:/ /github.com/helboukkouri/virtual-teacher   由   提交/u/HichamEB   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7ymal/p_aibased_language_teacher_that_can_run_locally/</guid>
      <pubDate>Fri, 19 Apr 2024 14:43:29 GMT</pubDate>
    </item>
    <item>
      <title>[D]嵌入搜索“淹没”在噪音的海洋中！你能解开这个谜语吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7wrhe/d_embeddings_search_drowning_in_a_sea_of_noise/</link>
      <description><![CDATA[我正在为存储在 Postgres DB 中的数十万条文本记录的 RAG 应用程序编写概念证明，使用 pgvector 来存储嵌入（并使用 HNSW 索引）。向量维度指定正确。  当前正在使用不同的文本块大小进行实验，并比较两种不同的嵌入模型。（实际块大小可能会略有不同，因为我不会破坏单词来强制确定大小）。   nomic-embed-text snowflake-arctic-embed-m-long  这是实验的要点： 1-为“n”创建嵌入文档 2- 创建一个查询/提示列表，以查找其中某些文档中确实包含的信息。  示例：  在“地点 x”发生了哪些事件？ John Doe 的昵称是什么？  入住“医院名称”的患者是谁？ 请告诉我销售总监提出的申请。 ...  3- 对于每个查询/提示，我运行余弦距离查询并获取最近的 5 个匹配块。  4-计算所有查询/块的平均距离后，理论上，最小值是 model/chunk_size 的最佳组合。   这对于一小部分文档样本（比如 ≃ 200）效果非常好，但是一旦我添加了更多文档，我就开始注意到一个问题。  一些新文档包含 30k 多个名字的列表。  每当我运行包含名称的查询时，都会返回上面列表中的块，即使它们不包含名称或提示中显示的任何其他信息（无论选择块大小或策略）。  我的理论是，当嵌入包含名称的块时，生成的嵌入包含“名称”语义的强向量，但区分该名称与其他名称的向量可能相对较弱。  一个块，除了对“name”向量的引用之外几乎不包含任何内容。然后被认为与提示的嵌入非常相似，尽管名称本身不匹配。   对于那些有更多经验/理解的人来说，我的这些假设是错误的吗？  您有什么建议/解决方法吗？  我有一些想法，但想看看是否有人遇到同样的问题。   由   提交 /u/grudev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7wrhe/d_embeddings_search_drowning_in_a_sea_of_noise/</guid>
      <pubDate>Fri, 19 Apr 2024 13:21:46 GMT</pubDate>
    </item>
    <item>
      <title>有什么方法可以改进 TabNet..？？？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7rfhv/any_ways_to_improve_tabnet_d/</link>
      <description><![CDATA[所以我正在尝试谷歌的 tabnet 架构https: //arxiv.org/pdf/1908.07442.pdf 发现如果数据有很多随机性和噪音，那么只有它才能根据我的数据集表现出色，但是像 xgboost、随机森林这样的传统机器学习算法在那些特征足够强大但未通过零样本测试的数据集上做得更好，而变压器在这方面表现出了一定的准确性，所以我只是想检查是否有可能将传统技术和变压器架构合并起来，以便它可以在传统的机器学习算法数据集上表现更好，并且还可以提供良好的零射击精度。在尝试合并它时，我发现在 tabnet 论文中，他们假设每个功能都是独立的，并且不为与功能本身的任何关系提供任何位置，但 Tabtransformer 架构将其考虑在内 https://arxiv.org/pdf/2012.06678.pdf 以及但没有 tabnet 中建议的任何功能选择....我尝试合并它们，但被卡在我必须根据分配给每个特征的维度进行特征选择的地方，而这项工作是由 Tabnet 论文中的稀疏最大完成的，我找不到办法做到这一点......任何帮助将不胜感激   由   提交/u/Shoddy_Battle_5397   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7rfhv/any_ways_to_improve_tabnet_d/</guid>
      <pubDate>Fri, 19 Apr 2024 08:06:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 从 3D 网格和物理场进行机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7r0tj/r_machine_learning_from_3d_meshes_and_physical/</link>
      <description><![CDATA[Ansys 发布了一款用于物理仿真的 AutoML 产品，名为 Ansys Sim AI (https://www.ansys.com/fr-fr/news-center/press-releases/1-9-24 -ansys-启动-simai）。作为一名机器学习工程师，我想知道可以使用哪些类型的模型来训练具有物理场的 STL 格式的 3D 网格数据。如何针对不同的几何对象管理不同维度的输入和输出数据？有人对这个话题有什么想法吗？    由   提交 /u/SatieGonzales   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7r0tj/r_machine_learning_from_3d_meshes_and_physical/</guid>
      <pubDate>Fri, 19 Apr 2024 07:38:23 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 最近是否有特定的技术/科学突破使得多个大型语言模型的最大上下文长度显着跃升？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7pzf0/discussion_are_there_specific_technicalscientific/</link>
      <description><![CDATA[GPT-4 和 Claude 等模型的最新版本在最大上下文长度上有显着的跳跃（4/8k -&gt; 128k+）。这些模型可以处理的代币数量方面的进展听起来非常引人注目。 是什么导致了这一点？这纯粹是因为训练期间可用的计算量增加而发生的吗？是否有算法进步导致了这种情况？   由   提交 /u/analyticalmonk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7pzf0/discussion_are_there_specific_technicalscientific/</guid>
      <pubDate>Fri, 19 Apr 2024 06:28:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当我只有一组 PDF 文档时，如何评估 RAG - 检索和生成？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7oa6k/d_how_to_evaluate_rag_both_retrieval_and/</link>
      <description><![CDATA[假设我有 1000 个 PDF 文档，用作 RAG 管道的输入。 我想评估RAG 管道，以便我可以测量： - 哪些嵌入模型更适合我的数据？ - 哪些重新排序器有效并且需要它们？ - 哪些法学硕士给出了最真实和连贯的答案？ 我如何评估管道的这些步骤？ 根据我的研究，我发现大多数框架都需要标签来进行检索和世代评价。我如何使用法学硕士创建这些数据？还有其他技术吗？ 我发现的一些东西： 对于检索：使用 LLM 生成用于检索的综合排名标签。 我应该使用哪个法学硕士？我应该遵循哪些最佳实践？我可以查看任何代码吗？ 对于生成的文本： - 为每一代生成如上所述的合成标签。 - 使用法学硕士作为法官，根据所获得的背景和提出的问题对每一代进行评分。您会推荐哪些法学硕士？ 哪些技术对你们有用？   由   提交 /u/awinml1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7oa6k/d_how_to_evaluate_rag_both_retrieval_and/</guid>
      <pubDate>Fri, 19 Apr 2024 04:43:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 统一信息检索中的偏见和不公平：大型语言模型的挑战和机遇调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7o4xt/r_unifying_bias_and_unfairness_in_information/</link>
      <description><![CDATA[      PDF: https://arxiv.org/abs/2404.11457 GitHub：https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey ​ ; 摘要：随着大型语言模型（LLM）的快速发展，信息检索（IR）系统，例如搜索引擎和推荐系统，已经发生了重大的范式转变。这种演变在预示着新机遇的同时，也带来了新的挑战，特别是在偏见和不公平方面，这可能会威胁信息生态系统。在本文中，我们对法学硕士整合时IR系统中出现的紧迫偏见和不公平问题的现有研究进行了全面调查。我们首先将偏见和不公平问题统一为分布不匹配问题，为通过分布调整对各种缓解策略进行分类提供了基础。随后，我们系统地深入研究了法学硕士融入IR系统的三个关键阶段所产生的具体偏见和不公平问题：数据收集、模型开发和结果评估。在此过程中，我们仔细回顾和分析了最近的文献，重点关注与这些问题相关的定义、特征和相应的缓解策略。最后，我们确定并强调了未来工作中的一些悬而未决的问题和挑战，旨在激励投资者关系领域及其他领域的研究人员和利益相关者更好地理解和减轻法学硕士时代投资者关系的偏见和不公平问题。  ​ https://preview.redd.it /d48pt3sw6dvc1.png?width=1126&amp;format=png&amp;auto=webp&amp;s=2343460399473bde3f5e37c0bbcfdc88ffc81efb   由   提交/u/KID_2_2  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7o4xt/r_unifying_bias_and_unfairness_in_information/</guid>
      <pubDate>Fri, 19 Apr 2024 04:34:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人尝试过用旧方法提取大型语言模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7izc4/d_has_anyone_tried_distilling_large_language/</link>
      <description><![CDATA[因此，如今，每个人都在将从大型语言模型收集的基本原理提炼到另一个相对较小的模型中。然而，我记得从前我们在进行蒸馏时训练了小型网络以匹配大型网络的逻辑。这是忘记/尝试过并且今天不起作用吗？   由   提交 /u/miladink   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7izc4/d_has_anyone_tried_distilling_large_language/</guid>
      <pubDate>Fri, 19 Apr 2024 00:11:00 GMT</pubDate>
    </item>
    <item>
      <title>[N] Meta 发布 Llama 3</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c77f0m/n_meta_releases_llama_3/</link>
      <description><![CDATA[      https://llama.meta.com/llama3 /  ​ ​ /u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c77f0m/n_meta_releases_llama_3/</guid>
      <pubDate>Thu, 18 Apr 2024 16:18:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 产品评估是讨论最多的话题之一</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c75q78/d_product_evaluations_is_one_of_the_most/</link>
      <description><![CDATA[我们是一家人工智能咨询公司，这种情况一次又一次地发生在我们身上...... 我们开始一个新的法学硕士项目客户。 他们的工程师很快就能完成 80%。 他们有很多边缘情况，希望我们完成剩余的 20%。  &gt;我们向他们询问有关评估的信息。 当然他们没有。 我们创建评估框架，迭代改进管道，瞧。  工作完成，每个人都很高兴。 我认真地认为，根据我们的观察，最好的人工智能产品团队将是那些在评估上花费大量时间的团队。它很无聊，很重复，但它区分了令人惊叹的人工智能产品和表现不佳的产品。   由   提交 /u/BootstrapGuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c75q78/d_product_evaluations_is_one_of_the_most/</guid>
      <pubDate>Thu, 18 Apr 2024 15:10:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>