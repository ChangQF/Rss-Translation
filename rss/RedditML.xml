<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Wed, 01 May 2024 15:13:21 GMT</lastBuildDate>
    <item>
      <title>[D] ICML 2024论文接收结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chognn/d_icml_2024_paper_acceptance_result/</link>
      <description><![CDATA[ICML 2024 论文接受结果应该很快就会出来。为今年的结果创建一个讨论线程。 每年的评论都有很多噪音。鉴于 ICML 这些年来发展得如此之大，一些作者引以为豪的好作品可能会因为系统噪音而被拒绝。我们应该记住，无论最终结果如何，这项工作仍然有价值。   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chognn/d_icml_2024_paper_acceptance_result/</guid>
      <pubDate>Wed, 01 May 2024 15:06:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 预训练的 LLM 在多少个参数下开始遵循指令？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chnja9/d_at_what_parameter_count_do_pretrained_llms/</link>
      <description><![CDATA[在InstructGPT论文中，测试的最小模型是1.3B参数模型。这让我对较小模型的功能感到好奇。我感兴趣的是是否存在一个“阈值”参数计数，低于该阈值，如果存在这样的阈值，模型就会显着丧失遵循指令的能力。  &amp; #32；由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chnja9/d_at_what_parameter_count_do_pretrained_llms/</guid>
      <pubDate>Wed, 01 May 2024 14:27:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 说话者嵌入由什么组成？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chmi0e/d_what_does_speaker_embeddings_consists_of/</link>
      <description><![CDATA[我正在开展一个说话者验证项目，其中我正在探索通过语音验证说话者的不同技术。传统方法是提取 MFCC、Filterbank 和韵律特征。现在这种方法似乎已经过时了，因为大多数研究都集中在使用预训练模型，例如 Nvidia 的 TitaNet、微软的WavLM，SpeechBrain也是这方面的一个模型。现在，这些预先训练的模型提供嵌入作为输出，代表说话者的声音，无论他在录音中说了什么。  现在我的疑问是这些嵌入代表什么？其中一种架构利用了 MFCC，然后将它们传递给 LSTM 等神经网络来捕获模式。    由   提交 /u/Puzzleheaded_Bee5489   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chmi0e/d_what_does_speaker_embeddings_consists_of/</guid>
      <pubDate>Wed, 01 May 2024 13:42:27 GMT</pubDate>
    </item>
    <item>
      <title>基于多模态法学硕士的机械臂策略研究现状如何？[D][R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chli42/whats_the_current_state_of_multimodal_llm_based/</link>
      <description><![CDATA[我知道像Figure公司的机器人使用openai的GPT作为大脑，表现非常好，已经可以做很多家务了。那么我想知道机器人的能力还有哪些可以提升的空间？欢迎大家提出意见！    由   提交 /u/CrisYou   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chli42/whats_the_current_state_of_multimodal_llm_based/</guid>
      <pubDate>Wed, 01 May 2024 12:56:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] RPE 仍然是一种有效的方法，还是 RoPE 完全优越？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chl4a4/d_is_rpe_still_a_valid_approach_or_is_rope/</link>
      <description><![CDATA[我专门致力于使用 Transformer 生成音乐 (MIDI)。大多数这些模型/数据集都非常小，例如&lt;1 亿个参数。 如果我理解正确的话，RPE 很快就与 Music Transformer 相适应，作为将令牌内距离信息嵌入到注意力计算中的一种手段。 另外， RoPE 似乎有一个类似的目标，尽管我无法从 RoFormer 论文中了解到它是否嵌入了相同类型（质量？）的知识（例如令牌 X 是......与令牌 Y 的距离）。 我想我的问题是：对于模型很小且令牌间距离至关重要的情况，RPE 仍然可能是一种更好的方法吗？  &amp; #32；由   提交 /u/leoholt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chl4a4/d_is_rpe_still_a_valid_approach_or_is_rope/</guid>
      <pubDate>Wed, 01 May 2024 12:37:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] TensorDock — GPU 云市场，H100s 起价 2.49 美元/小时</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chiu4a/d_tensordock_gpu_cloud_marketplace_h100s_from/</link>
      <description><![CDATA[大家好！我是来自 TensorDock 的 Jonathan，我们正在构建一个云 GPU 市场。我们希望让 GPU 真正变得价格实惠且易于使用。 我曾经在中学时在自托管服务器上启动了网络托管服务。但构建服务器与销售云不同。有很多开源软件可以管理你的家庭实验室的副业项目，但没有任何东西可以将其商业化。 大型云提供商收取高得离谱的价格 - 如此之高以至于他们经常可以偿还他们的硬件在 6 个月内，全天候 24 小时使用。 我们正在构建允许任何人成为云的软件。我们希望达到这样一个目标：任何[插入容量过剩的公司、数据中心、云提供商]都可以在我们的节点上安装我们的软件并赚钱。他们可能不会在 6 个月内偿还硬件费用，但他们不需要做繁重的工作 - 我们处理支持、软件、付款等。 反过来，您可以访问真正独立的云：来自世界各地的供应商提供的 GPU，这些供应商在价格和可靠性方面相互竞争。 到目前为止，我们已经采用了相当多的 GPU，其中包括200 个 NVIDIA H100 SXM，售价仅为 2.49 美元/小时。但我们还有 A100 80G 起价为 1.63 美元/小时，A6000 起价为 0.47 美元/小时，A4000 起价为 0.13 美元/小时，等等。因为我们是一个真正的市场，所以价格会随着供需而波动。 所有这些都可以在纯 Ubuntu 22.04 中使用，或者预装流行的 ML 软件包 - CUDA、PyTorch、TensorFlow 等，并且所有这些都由托管我们已经仔细审查过的矿场、数据中心或企业网络。 如果您正在为下一个项目寻找托管服务，请尝试一下！很高兴提供测试积分，请发送电子邮件至 [jonathan@tensordock.com](mailto:jonathan@tensordock.com）。如果您最终决定尝试我们，请在下面提供反馈[或直接提供！]:) ​ 部署 GPU 虚拟机：https://dashboard.tensordock.com/deploy 仅 CPU 虚拟机：https://dashboard.tensordock.com/deploy_cpu 申请成为主机： https://tensordock.com/host   由   提交/u/jonathan-lei   reddit.com/r/MachineLearning/comments/1chiu4a/d_tensordock_gpu_cloud_marketplace_h100s_from/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chiu4a/d_tensordock_gpu_cloud_marketplace_h100s_from/</guid>
      <pubDate>Wed, 01 May 2024 10:31:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 中如何强制执行最大输出长度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chhtlh/d_how_is_max_output_length_enforced_in_llms/</link>
      <description><![CDATA[嗨！我开始思考 LLM 如何知道何时停止生成令牌以响应提示。 现代 LLM 中是否仍然使用停止令牌的概念？或者也许停止标记和其他技巧的组合可以控制输出长度？ 从微调的角度来看，我知道您可以训练模型以始终输出与训练数据集中的标记或多或少相同的长度。 IE。我想象指令数据集中的输出长度具有相似的长度，因此指令微调模型学习输出与数据集中相同的长度。如果是这种情况，那么预训练的基础模型又如何呢？输出长度是纳入基础模型还是仅纳入后续微调模型？   由   提交/u/Maltmax  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chhtlh/d_how_is_max_output_length_enforced_in_llms/</guid>
      <pubDate>Wed, 01 May 2024 09:25:33 GMT</pubDate>
    </item>
    <item>
      <title>冻结模型是如何工作的？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chg35o/how_does_freezing_a_model_work_d/</link>
      <description><![CDATA[在多模式 LLM 中，它们通常会冻结 CLIP 编码器。这是如何运作的？它只是一个连接两个输入的线性神经元吗？是否有关于此的任何论文/指南（特别是将 2 个或更多模型连接在一起）   由   提交/u/Small_Emotion8420   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chg35o/how_does_freezing_a_model_work_d/</guid>
      <pubDate>Wed, 01 May 2024 07:24:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 2024 决策主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chfqca/d_icml_2024_decision_thread/</link>
      <description><![CDATA[ICML 2024 论文接收结果预计将在 24 小时左右发布。我想我可以创建这个线程供我们讨论与之相关的任何事情。 每年的评论都会有一些噪音。不要忘记，即使您的论文可能被拒绝，但这并不意味着它不是有价值的工作。祝大家好运！   由   提交/u/hugotothechillz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chfqca/d_icml_2024_decision_thread/</guid>
      <pubDate>Wed, 01 May 2024 07:01:02 GMT</pubDate>
    </item>
    <item>
      <title>爱丽丝在不同的仙境中的冒险——第一卷，土地之旅</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chawnq/alices_adventures_in_a_differentiable_wonderland/</link>
      <description><![CDATA[ 由   提交/u/emiyake  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chawnq/alices_adventures_in_a_differentiable_wonderland/</guid>
      <pubDate>Wed, 01 May 2024 02:21:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大型数据集的拉格朗日神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ch6wue/d_lagrangian_nn_w_large_dataset/</link>
      <description><![CDATA[我正在尝试在具有 50 多个特征且一个输出列 A 的大型医学数据集上使用拉格朗日神经网络。这有多可行？我觉得使用 LNN 失去了一些目的，但我相信它可能会起作用。 B. 如何让拉格朗日神经网络处理如此大的数据集？我看到的大多数 LNN 似乎只有一个输入和一个输出列，但这几乎不可能用我的数据集实现。  谢谢   由   提交 /u/CruisingLettuce   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ch6wue/d_lagrangian_nn_w_large_dataset/</guid>
      <pubDate>Tue, 30 Apr 2024 23:14:39 GMT</pubDate>
    </item>
    <item>
      <title>你用它做什么很酷的事情？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ch094g/what_cool_thing_are_you_using_it_ford/</link>
      <description><![CDATA[大家好，我只是想听听人们在专业和个人方面成功使用 ML/DL 实现的一些很酷的事情？  也许有一些很酷的农业检测系统，或者在某些情况下用于计算野生动物。也许您正在致力于制造一辆自动驾驶小汽车，它使用强化学习和激光雷达，或者可能是一些用于艺术的生成人工智能？  我很想听听有关您正在从事的项目的一些细节，成功的，失败的，任何真正的事情。谢谢！    由   提交 /u/Brilliant-Donkey-320   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ch094g/what_cool_thing_are_you_using_it_ford/</guid>
      <pubDate>Tue, 30 Apr 2024 18:40:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] CRISPR-GPT：用于自动设计基因编辑实验的法学硕士代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cgyccx/r_crisprgpt_an_llm_agent_for_automated_design_of/</link>
      <description><![CDATA[一篇新论文介绍了 CRISPR-GPT，这是一种人工智能驱动的工具，可简化基于 CRISPR 的基因编辑实验的设计。该系统利用法学硕士和全面的知识库来指导用户完成设计 CRISPR 实验的复杂过程。 CRISPR-GPT 将法学硕士与特定领域的知识和外部工具集成，以提供端到端支持 该系统将设计过程分解为模块化子任务，包括CRISPR系统选择、指导RNA设计、递送方法推荐、方案生成和验证策略。  CRISPR-GPT 让用户参与多轮对话，在每一步收集必要的信息并生成上下文感知的建议。 技术亮点：  CRISPR 的核心- GPT 是一种基于 Transformer 的法学硕士，在与基因编辑相关的大量科学文献中进行了预训练。 特定于任务的模块被实现为在精选数据集和结构化数据库上训练的微调语言模型。 &gt; 系统通过 API 与外部工具（例如 sgRNA 设计算法、脱靶预测器）连接，以增强其功能。 对话引擎指导用户完成设计过程，保持连贯性和上下文  结果：  在一项试验中，CRISPR-GPT 的实验设计被评为优秀（更多信息请参阅论文的人类评估部分）  作者成功地利用 CRISPR-GPT 设计了针对人类细胞系中四种癌症基因的基因敲除实验，并成功将它们敲除，展示了其实用性。&lt; /li&gt;  论文 (arxiv) 还讨论了人工智能辅助 CRISPR 设计的影响，包括其基因编辑研究民主化和加速科学发现的潜力。然而，作者承认需要持续评估和治理，以解决偏见、可解释性和道德问题等问题。 TLDR：法学硕士可以指导人类如何使用 CRISPR基因编辑以敲除癌细胞。 更多信息请点击此处 .   由   提交 /u/Successful-Western27    reddit.com/r/MachineLearning/comments/1cgyccx/r_crisprgpt_an_llm_agent_for_automated_design_of/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cgyccx/r_crisprgpt_an_llm_agent_for_automated_design_of/</guid>
      <pubDate>Tue, 30 Apr 2024 17:21:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] NExT：教授大型语言模型来推理代码执行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cgna7t/r_next_teaching_large_language_models_to_reason/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.14662 摘要：  人类开发人员的一项基本技能是理解和推理的能力关于程序执行。举个例子，程序员可以在心里模拟自然语言的代码执行来调试和修复代码（又名橡皮鸭调试）。然而，代码的大型语言模型 (LLM) 通常是在程序的表面文本形式上进行训练的，因此可能缺乏对程序在运行时如何执行的语义理解。为了解决这个问题，我们提出了NExT，一种教导法学硕士检查程序执行轨迹（执行行的变量状态）并通过思维链推理其运行时行为的方法（ CoT）的基本原理。具体来说，NExT 使用自我训练来引导执行感知原理的综合训练集，从而无需费力的手动注释即可得出正确的任务解决方案（例如固定程序）。基于 MBPP 和 HumanEval 的程序修复任务实验表明，NExT 将 PaLM 2 模型的修复率分别提高了 26.1% 和 14.3%（绝对值），并且经自动化指标验证，基本原理质量显着提高和人类评估者。我们的模型还可以推广到测试时不存在程序跟踪的场景。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cgna7t/r_next_teaching_large_language_models_to_reason/</guid>
      <pubDate>Tue, 30 Apr 2024 07:53:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>