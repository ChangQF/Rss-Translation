<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 06 Jan 2025 12:33:42 GMT</lastBuildDate>
    <item>
      <title>[D] 关于法学硕士的错误信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1huxrd2/d_misinformation_about_llms/</link>
      <description><![CDATA[还有人对 Reddit 评论中有关 LLM 的不良信息比例感到吃惊吗？对于任何高级主题来说，这都是危险的，但围绕 LLM 的讨论似乎已经完全偏离了轨道。老实说，我觉得这有点奇怪。不良信息被疯狂地点赞，而知情的评论最多只能被忽略。令我惊讶的不是这种情况正在发生，而是它如此持续地处于“自信错误”的领域    提交人    /u/HasFiveVowels   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1huxrd2/d_misinformation_about_llms/</guid>
      <pubDate>Mon, 06 Jan 2025 12:20:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 学习哪些（人类）语言？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hux0p0/d_what_human_languages_to_learn/</link>
      <description><![CDATA[嗨， 这不是典型的 LLM 末日论帖子，而是 ML 特定的职业讨论。  我热衷于学习新语言（人类口语），尤其是拉丁语和罗曼语。 想知道是否有语言可以为 ML 从业者带来有趣的机会。 是否存在非英语地区对 ML 从业者有需求，但熟练的母语从业者供应不足？    提交人    /u/Amgadoz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hux0p0/d_what_human_languages_to_learn/</guid>
      <pubDate>Mon, 06 Jan 2025 11:33:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] 未来两个月的客户流失预测——需要有关数据集和模型的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hux0dx/p_churn_prediction_two_months_in_the_future_need/</link>
      <description><![CDATA[大家好！ 我最近开始从事数据科学家的工作，我被分配到一个项目来创建一个客户流失预测模型。具体来说，目标是预测未来两个月内客户流失的概率 由于我是团队中唯一的人，而且这是我第一次处理真实数据，所以我并不完全确定如何处理这个问题并做出正确的决定。 目前，我通过获取六个月的历史数据（例如，客户 X，202401，特征（与该月相关），客户流失标志，客户 X，202402，特征（与该月相关），客户流失标志等...）来构建数据集。 完成后，我使用这些分解数据并应用随机森林分类模型。但是，我最终得到的绩效指标非常差。 因此，我有几个问题：  对于包含每月历史数据的数据集，哪种模型更适合应用（在本例中，用于客户流失预测）？我应该使用聚合、滞后分解、时间序列、生存分析还是其他方法？在这种情况下，我应该如何安排数据集？ 目前，数据集包含指示客户在该月是否执行了某些操作的标志。有没有更好的方法来处理此类信息？ 您是否有任何处理不平衡数据的技巧以及需要考虑哪些指标？我在训练集上使用 SMOTE 来平衡少数类，并将 F1 分数作为指标。 如果您建议保持数据集原样或对其进行聚合，那么流失标志是否应该指行月份的提前两个月（例如，客户 x，202401，特征（与该月相关），流失标志（202403 年流失））？目前，我通过更新历史数据上个月的时变特征来重新创建目标月份（提前两个月）。  非常感谢！    提交人    /u/Sunshine1713   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hux0dx/p_churn_prediction_two_months_in_the_future_need/</guid>
      <pubDate>Mon, 06 Jan 2025 11:33:15 GMT</pubDate>
    </item>
    <item>
      <title>Rust 是一种适合机器的语言吗？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1huw1v8/is_rust_a_good_language_for_machine_d/</link>
      <description><![CDATA[嗨。我很想学习机器学习。Rust 是学习机器学习的好的第一门语言吗？    提交人    /u/Senzolo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1huw1v8/is_rust_a_good_language_for_machine_d/</guid>
      <pubDate>Mon, 06 Jan 2025 10:27:36 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 实数的嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1huvvqk/discussion_embeddings_for_real_numbers/</link>
      <description><![CDATA[大家好。我正在研究一个想法，在某个时候我遇到了一个实数序列。我需要学习每个实数的嵌入。到目前为止，我尝试将标量与可学习向量相乘，但它没有起作用（如预期的那样）。那么，有没有更有趣的方法可以做到这一点？ 谢谢    提交人    /u/Dry-Pie-7398   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1huvvqk/discussion_embeddings_for_real_numbers/</guid>
      <pubDate>Mon, 06 Jan 2025 10:15:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] XGBoost 用于回归预测建模和时间序列分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hutgz0/d_xgboost_for_regression_predictive_modeling_and/</link>
      <description><![CDATA[      使用 XGBoost 解锁预测建模的力量！ 我很高兴与大家分享我的书《XGBoost 用于回归预测建模和时间序列分析》，这本书由 Partha Pritam Deka 和 Joyce Weiner 合著。本书是您掌握 XGBoost 以构建稳健且可扩展的预测模型的终极指南。 🚀 里面有什么？ ✅ 主要特点：  掌握用于预测建模的 XGBoost 算法。 学习时间序列预测和回归的高级技术。 探索针对时间序列数据量身定制的特征工程策略。 使用 SHAP、LIME 和部分依赖图了解您的模型。 在现实场景中部署您的预测模型。  ✅ 这本书适合谁？ 本书非常适合数据科学家、机器学习爱好者和行业专业人士。如果您想解决现实世界的预测建模挑战，这本书适合您！您只需要具备基本的 Python 知识即可开始学习。 ✅ 为什么选择这本书？ 本书将理论与实例相结合，确保您理解概念并知道如何应用它们。您将获得使用 XGBoost Python API、scikit-learn 和高级技术的实践经验，从而使您的模型可解释且具有影响力。 📖 在 亚马逊 上查看这本书，立即提升您的预测建模技能！ 👉 让我们在 LinkedIn 上联系！我很想听听您的想法并讨论机器学习的奇妙世界。Ankur Mulasi 让我们一起塑造数据科学的未来！🌟   由    /u/Ankur_Packt  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hutgz0/d_xgboost_for_regression_predictive_modeling_and/</guid>
      <pubDate>Mon, 06 Jan 2025 07:14:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 3D 视觉-语言-动作生成世界模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1husa4d/r_3d_visionlanguageaction_generative_world_model/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1husa4d/r_3d_visionlanguageaction_generative_world_model/</guid>
      <pubDate>Mon, 06 Jan 2025 05:54:27 GMT</pubDate>
    </item>
    <item>
      <title>自监督学习——n 球面上的测量分布 [D] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hurxls/selfsupervised_learning_measure_distribution_on/</link>
      <description><![CDATA[大多数自监督学习方法（SimCLR、MoCo、BYOL、SimSiam、SwAV、MS BYOL 等）使用 n 球面超球面，提取的特征（编码器 + 投影/预测头之后）分布在该超球面中。然后，损失函数使用分布在此超球面上的特征进行损失计算。 论文，例如：  通过超球面上的对齐和均匀性理解对比表示学习，Tongzhou Wang 等人；ICML 2020 将表示与基础对齐：一种新的自监督学习方法，Shaofeng Zhang 等人；CVPR 2022 重新思考自监督学习中的均匀性度量，Xianghong Fang 等人； ICLR 2024  其他人表明这些特征分布在每个类的 n 球面上。 我们可以通过哪些不同的方式测量这些嵌入特征在这个超球面上的分布？比如说，如果我从 ImageNet/CIFAR-100 数据集中随机选择一个类，我如何测量属于这个类的所有图像在这个 n 球面上的分布？    提交人    /u/grid_world   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hurxls/selfsupervised_learning_measure_distribution_on/</guid>
      <pubDate>Mon, 06 Jan 2025 05:33:33 GMT</pubDate>
    </item>
    <item>
      <title>[N] 由 HNSW Graph 提供支持的内存向量存储</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1huqwji/n_inmemory_vector_store_powered_by_hnsw_graph/</link>
      <description><![CDATA[大家好！我现在已经在 Treds 中添加了一个完全基于命令的向量存储，由 HNSW 图提供支持，用于近似最近邻搜索。下面简要介绍一下这四个命令：  VCREATE – 初始化向量索引，指定 maxNeighbors、层因子和 efSearch 等参数。 VINSERT – 将向量插入该索引。 VSEARCH – 搜索给定向量的 k 个最近邻居。 VDELETE – 根据其 ID 从索引中删除向量。  可以在 redis-cli 中执行命令，因为 Treds 符合 RESP 标准。一个简单的会话可能看起来像 VCREATE vec 6 0.5 100 VINSERT vec 1.0 2.0 VINSERT vec 2.0 3.0 VINSERT vec 3.0 4.0 VSEARCH vec 1.5 2.5 2  这将创建一个名为 vec 的索引，插入一些 2D 向量，搜索 [1.5, 2.5] 的 2 个最近邻居。向量也可以是 N 维。 如果您之前查看过 Treds，我很乐意听听您对新向量存储添加的想法。如果您还没有，请随时查看并告诉我您是否有任何建议或问题。感谢阅读，祝您黑客愉快！ https://github.com/absolutelightning/treds?tab=readme-ov-file#vector-store https://github.com/absolutelightning/treds    提交人    /u/Fast-Tourist5742   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1huqwji/n_inmemory_vector_store_powered_by_hnsw_graph/</guid>
      <pubDate>Mon, 06 Jan 2025 04:35:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 离散扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hupxdg/d_discrete_diffusion_models/</link>
      <description><![CDATA[离散分布扩散中最有前途和最新的成就是什么？ 到目前为止，我已经看过了：  https://arxiv.org/abs/2107.03006 https://arxiv.org/abs/2310.16834v2  有没有更新或更有前途的成果？    提交人    /u/ArtisticHamster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hupxdg/d_discrete_diffusion_models/</guid>
      <pubDate>Mon, 06 Jan 2025 03:42:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有任何针对 FOSS 数据进行训练的背景去除模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hum9p4/d_any_background_removal_models_trained_on_foss/</link>
      <description><![CDATA[我将为一个对版权非常严格的项目做出贡献，甚至包括所使用的 ML 工具。我发现的许多模型都没有指定它们在哪些数据上进行训练（有些模型是在通过抓取训练的模型生成的图像上进行训练的，而这在我的例子中是不允许的）。 我发现最接近的是那些仅在 DIS5K 上进行训练的 DIS5K 上进行训练的 BiRefNet 模型；这些图像“允许商业使用和修改” （大概是 CC BY 和/或 BY-SA），但数据集本身有使用条款，禁止商业使用。    提交人    /u/Sobsz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hum9p4/d_any_background_removal_models_trained_on_foss/</guid>
      <pubDate>Mon, 06 Jan 2025 00:41:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了一个 CLI，使用遗传算法来改进提示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hubl11/p_i_made_a_cli_for_improving_prompts_using_a/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hubl11/p_i_made_a_cli_for_improving_prompts_using_a/</guid>
      <pubDate>Sun, 05 Jan 2025 17:04:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人类智能存在于大数据领域，还是小数据领域？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1htz91k/d_does_human_intelligence_reside_in_big_data/</link>
      <description><![CDATA[当今前沿的 LLM 拥有数万亿个参数，并在 500 万亿个 token 上进行训练。 人类大脑拥有 860 亿个神经元和 100 万亿个突触。 任何人消耗的文本信息量都比 LLM 所训练的少几个数量级。但是，人眼以大约 10Mbps 的速率捕获视觉信息。加上听觉、触觉、平衡感、嗅觉等其他感官，人类儿童在生命的最初几年消耗的信息量比任何 LLM 所见过的都要多。 这似乎表明人类智能需要大数据。 但是那些从出生就失明的人怎么办？先天性聋盲（没有记录在案的病例）怎么办？    提交人    /u/Gear5th   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1htz91k/d_does_human_intelligence_reside_in_big_data/</guid>
      <pubDate>Sun, 05 Jan 2025 06:07:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 05 Jan 2025 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>