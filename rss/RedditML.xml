<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Wed, 01 May 2024 12:25:52 GMT</lastBuildDate>
    <item>
      <title>[D] TensorDock — GPU 云市场，H100s 起价 2.49 美元/小时</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chiu4a/d_tensordock_gpu_cloud_marketplace_h100s_from/</link>
      <description><![CDATA[大家好！我是来自 TensorDock 的 Jonathan，我们正在构建一个云 GPU 市场。我们希望让 GPU 真正经济实惠且易于使用。 我曾经在中学时在自托管服务器上启动过网络托管服务。但构建服务器与销售云不同。有很多开源软件可用于管理您的家庭实验室以进行业余项目，但没有任何软件可以将其商业化。 大型云提供商收取的价格高得离谱 — — 以至于他们通常可以在 6 个月内通过全天候使用来收回硬件成本。 我们正在构建允许任何人成为云的软件。我们希望达到这样的程度：任何 [插入公司、数据中心、拥有过剩容量的云提供商] 都可以在我们的节点上安装我们的软件并赚钱。他们可能无法在 6 个月内收回硬件成本，但他们不需要做繁重的工作——我们负责支持、软件、付款等。 反过来，您可以访问真正独立的云：来自世界各地的 GPU，这些 GPU 的供应商在价格和可靠性方面相互竞争。 到目前为止，我们已经加入了不少 GPU，包括 200 台 NVIDIA H100 SXM，价格仅为 2.49 美元/小时。但我们也有 A100 80G，价格为 1.63 美元/小时，A6000，价格为 0.47 美元/小时，A4000，价格为 0.13 美元/小时等。因为我们是一个真正的市场，所以价格会随着供求关系而波动。 所有产品均可在普通的 Ubuntu 22.04 中使用，或预装了流行的 ML 软件包 — CUDA、PyTorch、TensorFlow 等，并且所有产品均由我们严格审查过的采矿场、数据中心或企业网络托管。 如果您正在为下一个项目寻找托管服务，请尝试一下我们！我们很乐意提供测试积分，只需给我发送电子邮件至 [jonathan@tensordock.com](mailto:jonathan@tensordock.com)。如果您最终尝试了我们，请在下面提供反馈 [或直接提供！] :) ​ 部署 GPU VM：https://dashboard.tensordock.com/deploy 仅限 CPU 的 VM：https://dashboard.tensordock.com/deploy_cpu 申请成为主机：https://tensordock.com/host    提交人    /u/jonathan-lei   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chiu4a/d_tensordock_gpu_cloud_marketplace_h100s_from/</guid>
      <pubDate>Wed, 01 May 2024 10:31:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 中如何强制执行最大输出长度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chhtlh/d_how_is_max_output_length_enforced_in_llms/</link>
      <description><![CDATA[嗨！我开始思考 LLM 如何知道何时停止生成令牌以响应提示。 现代 LLM 中是否仍然使用停止令牌的概念？或者也许停止标记和其他技巧的组合可以控制输出长度？ 从微调的角度来看，我知道您可以训练模型以始终输出与训练数据集中的标记或多或少相同的长度。 IE。我想象指令数据集中的输出长度具有相似的长度，因此指令微调模型学习输出与数据集中相同的长度。如果是这种情况，那么预训练的基础模型又如何呢？输出长度是纳入基础模型还是仅纳入后续微调模型？   由   提交/u/Maltmax  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chhtlh/d_how_is_max_output_length_enforced_in_llms/</guid>
      <pubDate>Wed, 01 May 2024 09:25:33 GMT</pubDate>
    </item>
    <item>
      <title>冻结模型是如何工作的？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chg35o/how_does_freezing_a_model_work_d/</link>
      <description><![CDATA[在多模式 LLM 中，它们通常会冻结 CLIP 编码器。这是如何运作的？它只是一个连接两个输入的线性神经元吗？是否有关于此的任何论文/指南（特别是将 2 个或更多模型连接在一起）   由   提交/u/Small_Emotion8420   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chg35o/how_does_freezing_a_model_work_d/</guid>
      <pubDate>Wed, 01 May 2024 07:24:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 2024 决策主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chfqca/d_icml_2024_decision_thread/</link>
      <description><![CDATA[ICML 2024 论文接收结果预计将在 24 小时左右发布。我想我可以创建这个线程供我们讨论与之相关的任何事情。 每年的评论都会有一些噪音。不要忘记，即使您的论文可能被拒绝，但这并不意味着它不是有价值的工作。祝大家好运！   由   提交/u/hugotothechillz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chfqca/d_icml_2024_decision_thread/</guid>
      <pubDate>Wed, 01 May 2024 07:01:02 GMT</pubDate>
    </item>
    <item>
      <title>爱丽丝在不同的仙境中的冒险——第一卷，土地之旅</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chawnq/alices_adventures_in_a_differentiable_wonderland/</link>
      <description><![CDATA[ 由   提交/u/emiyake  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chawnq/alices_adventures_in_a_differentiable_wonderland/</guid>
      <pubDate>Wed, 01 May 2024 02:21:43 GMT</pubDate>
    </item>
    <item>
      <title>Keras 和 TF Bering 在 RStudio Windows 上无法预测...... [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cha079/keras_and_tf_bering_unpredictable_on_rstudio/</link>
      <description><![CDATA[Keras 和 Tensorflow 在 RStudio 中不可预测 所以我真的很努力让它发挥作用，而且它一直在发挥作用！可是现在突然不行了？？？我不再明白了，我在《使用 R 进行深度学习》一书中编写的简单代码没有出现错误消息（可能与安装相关）。不仅如此，有时我使用我总是使用的相同代码进行安装如果我有任何问题，它适用于几个模型，然后，繁荣，它只是决定之前使用的完美代码不再起作用并且出现错误……我不明白，有人有类似的问题吗？   由   提交/u/alohaakbar123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cha079/keras_and_tf_bering_unpredictable_on_rstudio/</guid>
      <pubDate>Wed, 01 May 2024 01:38:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大型数据集的拉格朗日神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ch6wue/d_lagrangian_nn_w_large_dataset/</link>
      <description><![CDATA[我正在尝试在具有 50 多个特征且一个输出列 A 的大型医学数据集上使用拉格朗日神经网络。这有多可行？我觉得使用 LNN 失去了一些目的，但我相信它可能会起作用。 B. 如何让拉格朗日神经网络处理如此大的数据集？我看到的大多数 LNN 似乎只有一个输入和一个输出列，但这几乎不可能用我的数据集实现。  谢谢   由   提交 /u/CruisingLettuce   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ch6wue/d_lagrangian_nn_w_large_dataset/</guid>
      <pubDate>Tue, 30 Apr 2024 23:14:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] CatBoost 的焦点损失</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ch1e2y/d_focal_loss_for_catboost/</link>
      <description><![CDATA[嗨，我正在尝试在 Catboost 中针对二元分类和多类分类问题实现焦点损失。我搜索了互联网，但找不到任何内置或第三方软件包（我能够找到一些用于 LightGBM 的软件包，但找不到用于 Catboost 或 XGBoost 的软件包），因此下一个方法是实现Catboost 中的自定义损失函数，但我在实现它时遇到了问题，而且训练速度非常慢。然后我发现以下 Kaggle 链接 这表明有一个Catboost 中针对焦点损失的内置功能，但我在 Catboost 官方文档中找不到此功能。 有人可以告诉我 Catboost 中是否存在此功能，或者如何实现它？另外，Catboost 是否包含任何其他损失函数，可用于不平衡多类分类？   由   提交 /u/ChaoticChaosConfused   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ch1e2y/d_focal_loss_for_catboost/</guid>
      <pubDate>Tue, 30 Apr 2024 19:26:44 GMT</pubDate>
    </item>
    <item>
      <title>你用它做什么酷的事情？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ch094g/what_cool_thing_are_you_using_it_ford/</link>
      <description><![CDATA[大家好，我只是想听听人们在专业和个人方面成功使用 ML/DL 实现的一些很酷的事情？  也许有一些很酷的农业检测系统，或者在某些情况下用于计算野生动物。也许您正在致力于制造一辆自动驾驶小汽车，它使用强化学习和激光雷达，或者可能是一些用于艺术的生成人工智能？  我很想听听有关您正在从事的项目的一些细节，成功的，失败的，任何真正的事情。谢谢！    由   提交 /u/Brilliant-Donkey-320   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ch094g/what_cool_thing_are_you_using_it_ford/</guid>
      <pubDate>Tue, 30 Apr 2024 18:40:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 时间序列分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cgztjs/p_time_series_classification/</link>
      <description><![CDATA[大家好，现在我正在做时间序列分类的项目。它由 55 个记录组成的批次组成，时间序列可以由任意数量的批次组成。任务是将时间序列作为一个整体进行分类。哪种方法最适合它？我目前正在考虑 LSTM 架构，但不确定如何正确实现它。也许有关于类似问题的文章或页面？谢谢   由   提交/u/Jor_ez   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cgztjs/p_time_series_classification/</guid>
      <pubDate>Tue, 30 Apr 2024 18:22:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] CRISPR-GPT：用于自动设计基因编辑实验的法学硕士代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cgyccx/r_crisprgpt_an_llm_agent_for_automated_design_of/</link>
      <description><![CDATA[一篇新论文介绍了 CRISPR-GPT，这是一种人工智能驱动的工具，可简化基于 CRISPR 的基因编辑实验的设计。该系统利用法学硕士和全面的知识库来指导用户完成设计 CRISPR 实验的复杂过程。 CRISPR-GPT 将法学硕士与特定领域的知识和外部工具集成，以提供端到端支持 该系统将设计过程分解为模块化子任务，包括CRISPR系统选择、指导RNA设计、递送方法推荐、方案生成和验证策略。  CRISPR-GPT 让用户参与多轮对话，在每一步收集必要的信息并生成上下文感知的建议。 技术亮点：  CRISPR 的核心- GPT 是一种基于 Transformer 的法学硕士，在与基因编辑相关的大量科学文献中进行了预训练。 特定于任务的模块被实现为在精选数据集和结构化数据库上训练的微调语言模型。 &gt; 系统通过 API 与外部工具（例如 sgRNA 设计算法、脱靶预测器）连接，以增强其功能。 对话引擎指导用户完成设计过程，保持连贯性和上下文  结果：  在一项试验中，CRISPR-GPT 的实验设计被评为优秀（更多信息请参阅论文的人类评估部分）  作者成功地利用 CRISPR-GPT 设计了针对人类细胞系中四种癌症基因的基因敲除实验，并成功将它们敲除，展示了其实用性。&lt; /li&gt;  论文 (arxiv) 还讨论了人工智能辅助 CRISPR 设计的影响，包括其基因编辑研究民主化和加速科学发现的潜力。然而，作者承认需要持续评估和治理，以解决偏见、可解释性和道德问题等问题。 TLDR：法学硕士可以指导人类如何使用 CRISPR基因编辑以敲除癌细胞。 更多信息请点击此处 .   由   提交 /u/Successful-Western27    reddit.com/r/MachineLearning/comments/1cgyccx/r_crisprgpt_an_llm_agent_for_automated_design_of/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cgyccx/r_crisprgpt_an_llm_agent_for_automated_design_of/</guid>
      <pubDate>Tue, 30 Apr 2024 17:21:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 评估法学硕士的长期绩效：最佳实践是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cgqu7o/d_evaluating_llms_longcontext_performance_what/</link>
      <description><![CDATA[对于评估扩展上下文中输出的一致性和相关性，哪些具体指标被认为是最可靠的？是否有既定的基准，或者我们是否仍需要制定新的基准？使用什么样的测试套件或框架？   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cgqu7o/d_evaluating_llms_longcontext_performance_what/</guid>
      <pubDate>Tue, 30 Apr 2024 11:47:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 测量神经模型的视觉语言 STEM 技能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cgpy6q/r_measuring_visionlanguage_stem_skills_of_neural/</link>
      <description><![CDATA[      作者：沉建豪、袁野、Srbuhi Mirzoyan、张明、王晨光  &lt; strong&gt;论文（ICLR 2024 接受）： https://arxiv.org/abs/2402.17205 排行榜： https://huggingface.co/spaces/stemdataset/stem-leaderboard  数据集： https://huggingface.co/datasets/ Stemdataset/STEM 代码： https://github.com/stemdataset /STEM  摘要：我们引入了一个新的挑战来测试神经模型的 STEM 技能。现实世界中的问题通常需要结合 STEM（科学、技术、工程和数学）知识来解决。与现有数据集不同，我们的数据集需要理解 STEM 的多模态视觉语言信息。我们的数据集是应对挑战的最大、最全面的数据集之一。它包含涵盖所有 STEM 科目的 448 项技能和 1,073,146 个问题。与通常侧重于检查专家级能力的现有数据集相比，我们的数据集包括基于 K-12 课程设计的基本技能和问题。我们还在基准测试中添加了最先进的基础模型，例如 CLIP 和 GPT-3.5-Turbo。结果表明，最近的模型进展仅有助于掌握我们数据集中非常有限数量的较低年级技能（三年级中的 2.5%）。事实上，这些模型仍然远低于小学生的表现（平均 54.7%），更不用说接近专家水平的表现了。为了理解并提高数据集的性能，我们在数据集的训练分割上教授模型。尽管我们观察到表现有所改善，但与普通小学生相比，模型表现仍然相对较低。为了解决 STEM 问题，我们需要社区的新颖算法创新。 https://preview.redd.it/wf7ssbf6llxc1.png?width=2430&amp;format=png&amp;auto=webp&amp;s=871c18ed4ca64a3b35f4bdc99bb4f2ce50a 201bb &lt; !-- SC_ON --&gt;  由   提交/u/shizue_yy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cgpy6q/r_measuring_visionlanguage_stem_skills_of_neural/</guid>
      <pubDate>Tue, 30 Apr 2024 10:55:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] NExT：教授大型语言模型来推理代码执行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cgna7t/r_next_teaching_large_language_models_to_reason/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.14662 摘要：  人类开发人员的一项基本技能是理解和推理的能力关于程序执行。举个例子，程序员可以在心里模拟自然语言的代码执行来调试和修复代码（又名橡皮鸭调试）。然而，代码的大型语言模型 (LLM) 通常是在程序的表面文本形式上进行训练的，因此可能缺乏对程序在运行时如何执行的语义理解。为了解决这个问题，我们提出了NExT，一种教导法学硕士检查程序执行轨迹（执行行的变量状态）并通过思维链推理其运行时行为的方法（ CoT）的基本原理。具体来说，NExT 使用自我训练来引导执行感知原理的综合训练集，从而无需费力的手动注释即可得出正确的任务解决方案（例如固定程序）。基于 MBPP 和 HumanEval 的程序修复任务实验表明，NExT 将 PaLM 2 模型的修复率分别提高了 26.1% 和 14.3%（绝对值），并且经自动化指标验证，基本原理质量显着提高和人类评估者。我们的模型还可以推广到测试时不存在程序跟踪的场景。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cgna7t/r_next_teaching_large_language_models_to_reason/</guid>
      <pubDate>Tue, 30 Apr 2024 07:53:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>