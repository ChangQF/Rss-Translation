<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 06 Feb 2024 06:17:57 GMT</lastBuildDate>
    <item>
      <title>[D] 在 ML 出版中玩游戏或做科学研究。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajz2s3/d_play_the_game_or_do_the_science_in_ml_publishing/</link>
      <description><![CDATA[我看到很多大科技公司的愿景论文模板。方法总是一样的，对现有的工作做一个小的改变，称之为新颖，疯狂地运行超参数搜索，在 20 个数据集上显示结果。 （请注意，这些模型很可能无法零样本工作，它们显示的所有数字都针对该数据集进行了微调）。这些纸总是能进来的！  我觉得这为审稿人设定了非常不切实际的期望，并期望所有论文得到相同水平的实验结果。因此，学术实验室很难成为其中一些子领域的一部分。  只有我一个人有这样的感觉吗？ 当然也有例外，比如 DINO 或 SAM，它们真的很棒，我真的很欣赏。   由   提交/u/mildlyphd  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajz2s3/d_play_the_game_or_do_the_science_in_ml_publishing/</guid>
      <pubDate>Tue, 06 Feb 2024 02:33:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些自然的、日常的保守英语语音数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajya0j/d_what_are_some_natural_everyday_conservational/</link>
      <description><![CDATA[我感觉很多语音数据集真的很不自然，不包含像问候这样的日常正常语音。例如，目前最流行的语音数据集之一 LJSpeech 不包含像“Hello”这样的单一问候语。或“你好吗？”   由   提交 /u/DogeLord081   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajya0j/d_what_are_some_natural_everyday_conservational/</guid>
      <pubDate>Tue, 06 Feb 2024 01:54:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] Sparsetral - 由 Mistra 制作的参数高效稀疏 MoE</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajx04e/r_sparsetral_parameter_efficient_sparse_moe/</link>
      <description><![CDATA[引入 Sparsetral，这是一种由密集模型 Mistral 制成的稀疏 MoE 模型。有关该理论的更多信息，请参阅原始论文（Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks ）。这是本文附带的原始存储库（原始存储库），这是带有稀疏的分叉存储库（密斯特拉尔）集成（分叉存储库）。 我们还分叉了unsloth 和 vLLM 用于高效培训和推理。 vLLM 上的 Sparsetral 已经过测试，可在 4090、bf16 精度、4096 max_model_len 和 64 max_num_seq 上工作。 这里是 huggingface 上的模型。 - 请注意这是 v2。 v1 进行了训练（仅列出了 v2 的更改）（64 个适配器暗淡、32 个有效批量大小、slim-orca 数据集） 接下来是评估，然后是 DPO（或 CPO）+ 可能添加 激活信标后延长上下文长度 训练  8x A6000s unsloth 的分叉版本，用于高效训练 序列长度：4096 &lt; li&gt;有效批量大小：128 学习率：2e-5，线性衰减 历元：1 数据集：OpenHermes-2.5 基础模型使用 QLoRA（排名 64，alpha 16）进行训练，MoE 适配器/路由器使用 bf16 进行训练 专家数量：16 顶级 K：4  适配器尺寸：512  如果您需要任何帮助或有任何疑问，请随时发表评论！   由   提交 /u/kittenkrazy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajx04e/r_sparsetral_parameter_efficient_sparse_moe/</guid>
      <pubDate>Tue, 06 Feb 2024 00:55:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于 NanoDL 的思考，一个用于构建 Transformer 模型的新库。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajwzku/p_thoughts_on_nanodl_a_new_library_for_building/</link>
      <description><![CDATA[大家好，我刚刚发布了 NanoDL 的开发人员版本，这是一个用于在 Jax/Flax 生态系统中开发 Transformer 模型的库，希望得到您的反馈！&lt; /p&gt; NanoDL 的主要功能包括：  广泛的块和层，有助于从头开始创建定制的变压器模型。 广泛的模型选择，如 LlaMa2、Mistral、Mixtral、GPT3、GPT4（推断）、T5、Whisper、ViT、Mixers、GAT、CLIP 等，可满足各种任务和应用的需求。  数据并行分布式训练器，使开发人员可以在多个 GPU 或 TPU 上高效地训练大规模模型，而无需手动训练循环。 数据加载器，使 Jax/Flax 的数据处理过程更加简单和有效。 Flax/Jax 中未找到的自定义层，例如 RoPE、 GQA、MQA 和 SWin 的关注，允许更灵活的模型开发。 GPU/TPU 加速的经典 ML 模型，如 PCA、KMeans、回归、高斯过程等，类似到 GPU 上的 SciKit Learn。 模块化设计，使用户可以混合来自各种模型（例如 GPT、Mixtral 和 LlaMa2）的元素，以制作独特的混合变压器模型。 一系列用于 NLP 和计算机视觉任务的高级算法，例如高斯模糊、BLEU 等。 每个模型都包含在没有外部依赖项的单个文件，因此也可以轻松使用源代码。  查看存储库以获取示例用法和更多详细信息：https://github.com/HMUNACHI/nanodl  最终，我想要尽可能多的意见，下一步要考虑的问题，甚至贡献。 注意：我正在编写自述文件。目前，在源代码中，我在注释中的每个模型文件顶部包含了一个综合示例。   由   提交 /u/Henrie_the_dreamer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajwzku/p_thoughts_on_nanodl_a_new_library_for_building/</guid>
      <pubDate>Tue, 06 Feb 2024 00:54:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] Riddusion 模型如何生成音乐中的人声？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajvnwr/d_how_does_riddusion_model_generate_vocals_in/</link>
      <description><![CDATA[我想知道 Riffusion 模型如何将我们的文本转换为歌手的声音并向其添加背景音乐。我可以理解它如何生成音乐，但我无法理解它如何生成歌手的声音并将其与音乐融为一体。它使用任何文本转语音引擎吗？它如何将声音速度/节奏与生成的音乐相匹配？   由   提交 /u/thefreemanever   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajvnwr/d_how_does_riddusion_model_generate_vocals_in/</guid>
      <pubDate>Mon, 05 Feb 2024 23:55:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于类别级物体姿态估计的无源和仅图像无监督域适应</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajv1ia/r_sourcefree_and_imageonly_unsupervised_domain/</link>
      <description><![CDATA[ 由   提交/u/No_Specialist7064   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajv1ia/r_sourcefree_and_imageonly_unsupervised_domain/</guid>
      <pubDate>Mon, 05 Feb 2024 23:28:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求在机器学习领域建立人际网络/交朋友</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajuo2p/d_looking_to_network_make_friends_in_the_ml_space/</link>
      <description><![CDATA[大家好， 我是一名专攻内科的医生，几年前转向软件工程。我一直在网络应用程序领域开发解决方案，扩展流行的电子病历系统的功能（教学堆栈是 MERN + GQL + 来自 EMR 的专有技术），目前我领导着一个小型工程师团队致力于建立一个为大约 100,000 名患者提供服务的封闭式医疗保健系统（富含高价值结构和非结构化数据）。而且，目前我的计划是过渡到机器学习领域，因为我相信，鉴于我的背景，将会有充足的机会从事从研究到创业活动的任何事情。 我作为法学硕士消费者的经验既给我留下了深刻的印象，又让我彻底相信，我们正处于医疗保健领域（以及其他领域）革命的边缘。除了发现机器学习非常有趣之外，我还很乐意参与这场革命。因此，我报读了计算机科学硕士学位（之前是自学的）以备不时之需，因为我注意到机器学习往往比我之前接触过的许多形式的软件工程更具学术性（尽管它们有时会令人捧腹）利特代码）。我已经完成了 30% 的硕士学位，主要专注于操作系统、信息安全和网络等基础课程。而且，我将把剩余课程的重点放在机器学习上。然而，到目前为止，我的 MS 课程还没有涉及 ML。我已经通过 Coursera 和 Udemy 完成了一些关于 ML 的入门课程，并且正在通过 DeepLearning.ai 积极学习机器学习数学和机器学习专业化。 由此，我发现发现在 ML 领域回答问题和方向比在传统 Web 应用程序领域自学 SWE 更具挑战性。而且，我注意到我的研究生项目中的许多人都像我一样困惑，并且大量希望得到学术研究人员小团队关注的人使得学术指导的可能性有点低，除非选择博士学位路线并获得了一个好的 PI。 所以，我希望能遇到一些可以随着时间的推移与他们建立关系的人。我不确定我能提供多少，但作为一名开发人员，我相当熟练，并且确实拥有相对不常见的主题“专业知识”组合。 （宽松使用）。 无论如何，如果有人有兴趣联系，请随时与我们联系！我有全职工作，并且日程安排非常繁忙，我相信你们中的许多人也是如此，所以如果我的回复速度有点慢，请提前原谅我。 同时祝您好运。    由   提交 /u/gmdtrn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajuo2p/d_looking_to_network_make_friends_in_the_ml_space/</guid>
      <pubDate>Mon, 05 Feb 2024 23:12:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 应用程序的评估指标（RAG、聊天、摘要）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajth9j/d_evaluation_metrics_for_llm_apps_rag_chat/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajth9j/d_evaluation_metrics_for_llm_apps_rag_chat/</guid>
      <pubDate>Mon, 05 Feb 2024 22:23:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么不在神经模拟人工智能方向进行更多研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajrtug/d_why_isnt_more_research_being_done_in/</link>
      <description><![CDATA[尽管得到了 IBM 的支持，但与语言处理和其他“流行”技术相比，它似乎是一个相当死寂的主题。  如果我是对的，符号人工智能的最大缺陷之一是它依赖于人类输入规则，需要操作员执行手动工作才能使用。如果可以设计一个能够自动生成和更新现有规则的系统，那么它就有可能成为一个非常可靠的自主代理，能够进行基本的处理和探索。 最近这个方向，除了IBM还做了什么？如果不是，那么该技术目前不可行的关键问题是什么？   由   提交/u/NightestOfTheOwls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajrtug/d_why_isnt_more_research_being_done_in/</guid>
      <pubDate>Mon, 05 Feb 2024 21:16:10 GMT</pubDate>
    </item>
    <item>
      <title>维苏威挑战奖已颁发！ [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajqtfd/the_vesuvius_challenge_prize_has_been_awarded_n/</link>
      <description><![CDATA[https://scrollprize.org/grandprize 看起来这个项目已经死在水中了，读取的字母为零，直到非常偶然地发现了“裂开的泥土”。模式1由一个人使用自己的视觉系统盯着扫描进行模式识别。这导致其他人看到数据中的墨水，对其进行标记，训练机器学习模型，使用它们来查找更多字母等等。  1火山使墨水像干泥一样裂开   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajqtfd/the_vesuvius_challenge_prize_has_been_awarded_n/</guid>
      <pubDate>Mon, 05 Feb 2024 20:35:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] AMD 软件成熟度 vs Nvidia</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajk7q2/d_amd_software_maturity_vs_nvidia/</link>
      <description><![CDATA[我正在考虑使用 AMD MI210/MI250/MI300X 作为 A100/H100/H200 的替代品。有什么轶事或数据可以说明 AMD 软件的成熟程度吗？ Raja Koduri 最近表示，虽然 Nvidia 支持开箱即用的 80% 的 Huggingface 模型，但 AMD（或任何其他供应商）仅支持开箱即用的 5%。 AMD 声称支持整个变形金刚库，但当我与 AMD 工程师交谈时，他告诉我“细节决定成败……”我很想知道是否有人有直接经验或数据支持这两种说法 Databricks 测试：Databricks vLLM 端口：嵌入式LLM George Hotz 抱怨 AMD 很糟糕：用户体验问题   由   提交 /u/wombatscientist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajk7q2/d_amd_software_maturity_vs_nvidia/</guid>
      <pubDate>Mon, 05 Feb 2024 16:13:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微软研究院的 EvoPrompt – 进化算法与即时工程的结合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aji7np/d_microsoft_researchs_evoprompt_evolutionary/</link>
      <description><![CDATA[      在此处访问全文 我在浏览 LinkedIn 时发现了这篇来自微软、清华大学和西北大学的新颖的预印本论文。他们的论文标题为连接大型语言模型与进化算法产生强大的提示优化器。  在本文中，研究人员表明，一种模仿进化算法的极其简单的算法具有执行自动化提示工程的潜力。这种方法具有可扩展性，易于实现，并且明显优于手动提示工程。 虽然本文讨论了两种不同的进化算法：遗传算法和差分进化，但结果并不&lt;距离那么远。另外，我喜欢遗传算法，因为它们更类似于自然选择。下图总结了 GA 方法： LLM 实现的遗传算法 与常规遗传算法一样，有 5 个步骤：初始化、选择、交叉、变异和评估。 初始化：我们向人们提供了我们所知道的一系列不错的提示，并可能使用 GPT-3.5 生成提示。 选择：使用轮盘赌法，选择两个个体作为父母 交叉：使用上述说明，父母交配形成一个新的孩子 变异 变异 strong&gt;：使用上面的说明，孩子会经历突变 评估：我们针对特定提示对模型的性能进行评分。 重复此过程直到种群规模增加一倍，然后对种群进行排序并剔除回原始大小。 作为生物学专业的人，我喜欢看到遗传算法的实际应用。这些算法优雅、稳健且美观，模仿现实生活中的自然选择过程。这绝对是我最喜欢的人工智能算法，我很高兴看到它未来的工作方向。 我向你们提出的问题是，你们对这种方法有何看法？我已经发表了几篇关于自动提示工程的文章，对我来说，这篇文章验证了这种方法是可能的。然而，本文缺乏的一件事是评估过程如何运作的具体细节，特别是对于更复杂的现实世界提示。 我非常想了解你们的观点！而且，如果您正在寻找易于理解的摘要，我在这里详细讨论这篇论文。   由   提交 /u/Starks-Technology   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aji7np/d_microsoft_researchs_evoprompt_evolutionary/</guid>
      <pubDate>Mon, 05 Feb 2024 14:47:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有更大的团队放弃 wandb？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajg85m/d_any_larger_teams_switching_away_from_wandb/</link>
      <description><![CDATA[在大约六个月的时间里，我的团队遇到了运行失败、奇怪的用户体验问题和普遍存在错误的行为等问题。与其他公司的朋友交谈，似乎我们并不是唯一的人。 我们正在考虑更换，这已经够不便的了，但我的总体印象是没有太多选择除了 wandb 之外的更大团队（我们规模不大，但我们正在成长）。大多数开源解决方案看起来都很简单，我们团队中没有人有与任何其他供应商合作的丰富经验。所以，我希望这里的一些人能够插话。有没有人加入过从 wandb 转型的团队，如果是的话，你们最终运行了什么？ 编辑： &lt; p&gt;谢谢您的推荐！在探索了其中的一些之后，我真的很喜欢 Comet。对于我们团队来说，这似乎是最简单的转变。一些开源选项看起来很酷，但比大型团队更适合单独的研究人员。我还将尝试本周这里提到的其他几个供应商。海王星的定价尤其有趣。我感谢所有的帮助！   由   提交 /u/FreeKingBoo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajg85m/d_any_larger_teams_switching_away_from_wandb/</guid>
      <pubDate>Mon, 05 Feb 2024 13:15:07 GMT</pubDate>
    </item>
    <item>
      <title>跟着我重复：Transformers 在复制方面比状态空间模型更好 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aj9swv/repeat_after_me_transformers_are_better_than/</link>
      <description><![CDATA[https://arxiv.org/abs/2402.01032 摘要： Transformers 是序列建模的主要架构，但人们对使用固定大小潜在状态的模型越来越感兴趣不依赖于序列长度，我们将其称为“广义状态空间模型”。 （GSSM）。在本文中，我们表明，虽然 GSSM 在推理时间效率方面很有前景，但与需要从输入上下文复制的任务上的 Transformer 模型相比，它们是有限的。我们从字符串复制这一简单任务的理论分析开始，并证明两层 Transformer 可以复制指数长度的字符串，而 GSSM 从根本上受到其固定大小潜在状态的限制。根据经验，我们发现 Transformer 在需要复制上下文的合成任务的效率和泛化方面优于 GSSM。最后，我们评估了预训练的大型语言模型，发现 Transformer 模型在从上下文复制和检索信息方面显着优于状态空间模型。综上所述，这些结果表明 Transformer 和 GSSM 在实际感兴趣的任务上存在根本差距。   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aj9swv/repeat_after_me_transformers_are_better_than/</guid>
      <pubDate>Mon, 05 Feb 2024 06:16:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>