<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Sat, 27 Jul 2024 12:28:04 GMT</lastBuildDate>
    <item>
      <title>[R] 寻找处理对图像中两个对象之间是否存在直接路径进行分类的问题的学术论文。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edevbz/r_looking_for_academic_papers_that_deal_with_the/</link>
      <description><![CDATA[大家好， 我目前正在做一个项目，我尝试使用 CNN 根据 2 个选定节点是否连接对图形图像进行分类。我在过度拟合方面有点挣扎，想探索一些研究人员可能之前尝试过的其他策略。我很感激任何帮助或建议！如果我的解释不够深入，也可以随时提问。    提交人    /u/Dualweed   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edevbz/r_looking_for_academic_papers_that_deal_with_the/</guid>
      <pubDate>Sat, 27 Jul 2024 12:08:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是一个内存绑定代码吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ede1gl/d_is_this_a_memory_bound_code/</link>
      <description><![CDATA[我有一个推理代码，我保存了一些性能指标，然后更改了与输入数据维度相关的某个参数。具体来说，我将维度除以 2。 现在，在 gpu 上，计算性能提高了 20%。然而，有趣的是，在 cpu 上，性能提高了 300%。 我想知道为什么我在 cpu 上获得了如此显着的改进。虽然我缺乏这方面的知识，但我认为我的代码在 cpu 上运行时可能受到内存限制。你对此有何看法？ 此外，我与此主题相关的文章或论文将不胜感激。    提交人    /u/Top-Establishment545   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ede1gl/d_is_this_a_memory_bound_code/</guid>
      <pubDate>Sat, 27 Jul 2024 11:19:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama3.1 如何利用词汇表中仅有的 28k 个额外标记来支持多种语言？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edct9i/d_how_does_llama31_support_multiple_languages/</link>
      <description><![CDATA[根据 Llama3.1 论文，词汇表包含 128k 个标记，其中 100k 个专用于英语，28k 个分配给非英语语言。鉴于韩语、中文和日语等语言不使用 26 个字母的拉丁字母表并且可以有数百万个唯一字符，如何仅用 28k 个标记就涵盖这些语言？标记化是基于 Unicode 吗？    提交人    /u/Financial_Air5256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edct9i/d_how_does_llama31_support_multiple_languages/</guid>
      <pubDate>Sat, 27 Jul 2024 09:59:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检索增强生成的替代方案是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edbg0h/d_whats_the_alternative_to_retrieval_augmented/</link>
      <description><![CDATA[看来 RAG 是业界问答系统的事实标准。有什么替代方案吗？    提交人    /u/clocker2004   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edbg0h/d_whats_the_alternative_to_retrieval_augmented/</guid>
      <pubDate>Sat, 27 Jul 2024 08:21:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 这是混响语音到房间脉冲响应估计器的官方实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edao96/r_this_is_the_official_implementation_of/</link>
      <description><![CDATA[        由    /u/Snoo63916  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edao96/r_this_is_the_official_implementation_of/</guid>
      <pubDate>Sat, 27 Jul 2024 07:27:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将开源 LLM 与封闭模型进行比较是否合适？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ed7bg7/d_is_it_even_appropriate_to_be_comparing_open/</link>
      <description><![CDATA[例如，将 LLaMA-3 与 GPT-4 进行比较。对我来说，这没有意义，因为这感觉就像在将模型与实际产品进行比较。产品是应用了许多其他东西的模型（例如，预处理/后处理技术）。    提交人    /u/Seankala   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ed7bg7/d_is_it_even_appropriate_to_be_comparing_open/</guid>
      <pubDate>Sat, 27 Jul 2024 03:56:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 按比例拆分具有多个目标列的数据框</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ed0qpl/p_proportionately_split_dataframe_with_multiple/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ed0qpl/p_proportionately_split_dataframe_with_multiple/</guid>
      <pubDate>Fri, 26 Jul 2024 22:24:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 通过删除文本模块和交叉注意层，是否可以使用 Stable Diffusion v1 作为特征提取器？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ecwonw/d_is_it_possible_to_use_stable_diffusion_v1_as_a/</link>
      <description><![CDATA[嗨，我对利用稳定扩散 v1 模型作为下游任务的特征提取器感兴趣。具体来说，我想在不涉及文本提示机制的情况下做到这一点。为了实现这一点，我正在考虑：  消除文本编码器模块 删除 UNet 中的交叉注意层  这是一种可行的方法吗？有人尝试过以这种方式使用稳定扩散吗？这种修改的挑战或局限性是什么？ 我可以找到使用 SDv1 进行下游任务以及基本文本提示的论文，但没有一篇论文尝试在不使用文本提示机制的情况下做到这一点。否则，我正在考虑使用 DINOv2。    提交人    /u/rustyelectron   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ecwonw/d_is_it_possible_to_use_stable_diffusion_v1_as_a/</guid>
      <pubDate>Fri, 26 Jul 2024 19:28:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 配备 265GB RAM 的 Epyc Siena 32c/64c 适合启动实验室吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ecviad/d_epyc_siena_32c64c_with_265gb_ram_good_for/</link>
      <description><![CDATA[如果我能以优惠的价格买到带有 256GB RAM 的 Siena Epyc CPU 32 或 64 核，这是否是一个不错的起点，可以进入本地设置来运行模型？我需要 GPU 的通道。    提交人    /u/Kltpzyxmm   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ecviad/d_epyc_siena_32c64c_with_265gb_ram_good_for/</guid>
      <pubDate>Fri, 26 Jul 2024 18:37:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每个注释者都有一本指南，但审阅者没有</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ecnxng/d_every_annotator_has_a_guidebook_but_the/</link>
      <description><![CDATA[我于 6 月份提交了 ACL 滚动评审，发现评审员的评分非常主观。 虽然 ACL 委员会对一些基本的评审指南有说明，但缺少一个初步测试让评审员明确展示评估标准。也许我们应该提供一些论文评分示例，以促使评审员进行更客观的评审？或者在他们评审之前建立一个测试，以确保他们完全理解健全性和整体评估的含义，而不是根据他们的个人兴趣随意给出一些分数。    提交人    /u/Spico197   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ecnxng/d_every_annotator_has_a_guidebook_but_the/</guid>
      <pubDate>Fri, 26 Jul 2024 13:20:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI JSON 模式是如何实现的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eclhsy/d_how_openai_json_mode_implemented/</link>
      <description><![CDATA[我假设所有训练数据都是 JSON 格式，但生成过程中的较高温度或其他随机性并不能保证输出始终为 JSON。 您认为还有哪些方法可以确保输出始终为 JSON？也许解码过程中的一些基于规则的方法可能会有所帮助？    提交人    /u/Financial_Air5256   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eclhsy/d_how_openai_json_mode_implemented/</guid>
      <pubDate>Fri, 26 Jul 2024 11:15:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 中的规范化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ecict8/d_normalization_in_transformers/</link>
      <description><![CDATA[在我的 transformer 出现第一个理论问题之后，我现在又看到了另一个。原始论文在残差添加后使用归一化（Post-LN），这导致了训练困难，后来被在每个注意力或 mlp 块/分支（Pre-LN）开始时的归一化所取代。众所周知，这在实践中效果更好（无需热身即可训练，恢复高速公路效果），但从理论上讲似乎仍然不完全正确。 首先考虑没有归一化的事情。假设注意力和 mlp 块设置正确并且大多保持规范，则每个残差添加都会将两个相似的规范信号相加，可能会扩大 1.4 左右（取决于相关性，但它在随机初始化后从 sqrt(2) 开始）。因此，块之后的范数可能如下所示：[1(main)+1(residual)=1.4] -&gt; [1.4+1.4=2] -&gt; [2+2=2.8] 等。这会导致各种问题（例如在后面的注意力块中更改 softmax 温度），因此需要进行调整。 Pre-LN 确保每个块都以标准化值工作（因此 softmax 温度恒定 - 如果稍微任意的话）。但由于它不影响主信号的范数（由跳过连接转发）而只影响残差，因此范数仍然可以增长，尽管速度较慢。现在的期望大致为：[1+1=1.4] -&gt; [1.4+1=1.7] -&gt; [1.7+1=2] -&gt; [2+1=2.2] 等 - 最后通过规范化校正输出附近的信号（Pre-LN 论文）。 一个可能的问题是，后面的注意力块可能会降低效果，因为它们会将单位范数残差添加到可能越来越大的主信号中。对这个问题的通常看法是什么？在实践中可以忽略它吗？尽管如此，Pre-LN 是否可以正常工作，即使对于深度模型（其中主范数差异可能会变得更大）？有很多替代的规范化论文，但实际共识是什么？ 顺便说一句，注意力极其敏感（或者，等效地，softmax 的隐藏温度至关重要）。这与 fc 或卷积形成了鲜明的对比，它们大多与尺度无关。对于任何感兴趣的人：考虑当大多数原始注意力点积出来 0（= 查询和键是正交的，没有来自此上下文槽的信息）时会发生什么，只有一个槽给出 1（= 正亲和力，在按 sqrt(qk_siz) 缩小后）。我在调试过程中对此感到惊讶。    提交人    /u/lostn4d   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ecict8/d_normalization_in_transformers/</guid>
      <pubDate>Fri, 26 Jul 2024 07:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[N] OpenAI 宣布 SearchGPT</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ec2gk2/n_openai_announces_searchgpt/</link>
      <description><![CDATA[https://openai.com/index/searchgpt-prototype/  我们正在测试 SearchGPT，这是新 AI 搜索功能的临时原型，可为您提供快速及时的答案以及清晰且相关的来源。     提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ec2gk2/n_openai_announces_searchgpt/</guid>
      <pubDate>Thu, 25 Jul 2024 18:41:00 GMT</pubDate>
    </item>
    <item>
      <title>[N] 人工智能在国际数学奥林匹克竞赛中取得银牌成绩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebyx03/n_ai_achieves_silvermedal_standard_solving/</link>
      <description><![CDATA[https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/ 他们解答了 6 道 IMO 题目中的 4 道（尽管有些题目花了好几天才解答）。这样他们的分数就是 28/42，只比金牌水平低一分。    提交人    /u/we_are_mammals   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebyx03/n_ai_achieves_silvermedal_standard_solving/</guid>
      <pubDate>Thu, 25 Jul 2024 16:16:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 21 Jul 2024 02:15:09 GMT</pubDate>
    </item>
    </channel>
</rss>