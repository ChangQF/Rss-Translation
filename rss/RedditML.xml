<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 25 Jan 2025 09:15:49 GMT</lastBuildDate>
    <item>
      <title>[D] 最佳 TTS 到 onnx</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i9j191/d_best_tts_to_onnx/</link>
      <description><![CDATA[大家好， 我一直在使用 Piper TTS 模型，现在正在探索其他可以训练并导出为 ONNX 格式的高质量文本转语音模型。我的目标是实现这些模型以供在 iOS 设备上离线使用。对于那些有此类模型经验的人，我将不胜感激。 谢谢    提交人    /u/NoPrinciple1242   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i9j191/d_best_tts_to_onnx/</guid>
      <pubDate>Sat, 25 Jan 2025 09:00:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] DeepSeek-R1：通过强化学习激励法学硕士中的推理能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i9iltt/r_deepseekr1_incentivizing_reasoning_capability/</link>
      <description><![CDATA[  由    /u/we_are_mammals  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i9iltt/r_deepseekr1_incentivizing_reasoning_capability/</guid>
      <pubDate>Sat, 25 Jan 2025 08:28:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] 以不到 30 美元的价格在 3B LLM 上复制 DeepSeek-R3-Zero RL 配方，该模型可以自行开发自我验证和搜索能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i9dmwc/r_replicating_deepseekr3zero_rl_recipe_on_3b_llm/</link>
      <description><![CDATA[https://x.com/jiayi_pirate/status/1882839370505621655 人们过去认为这是不可能的，突然之间，语言模型上的强化学习就奏效了。而且它可以在足够小的规模上重现，以至于博士生只需几天就可以重新实现它。    提交人    /u/Happysedits   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i9dmwc/r_replicating_deepseekr3zero_rl_recipe_on_3b_llm/</guid>
      <pubDate>Sat, 25 Jan 2025 03:08:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习的进化与 Knightian 盲点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i9b9pp/r_evolution_and_the_knightian_blindspot_of/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i9b9pp/r_evolution_and_the_knightian_blindspot_of/</guid>
      <pubDate>Sat, 25 Jan 2025 01:04:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于 ICML 提交的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i9a3pu/r_advice_on_an_icml_submission/</link>
      <description><![CDATA[我的论文是关于资源高效的集成/UQ，用于 KB 大小的 tinyML 设备中的模型监控。它试图解决资源极其匮乏的设备中的准确度下降事件。根据 https://icml.cc/Conferences/2025/ReviewerInstructions 中的指导方针，这是否符合应用驱动的 ML 提交？ 我的目标是针对具有 ML+Hardware 背景的审阅者，他们欣赏这项工作的 tinyML 约束和资源效率角度。任何想法/建议都将不胜感激，因为我并不是来自 ML 社区。谢谢！    提交人    /u/heisenbug_797   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i9a3pu/r_advice_on_an_icml_submission/</guid>
      <pubDate>Sat, 25 Jan 2025 00:09:06 GMT</pubDate>
    </item>
    <item>
      <title>[D]需要帮助解决用户上传的自动错误场景检测问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i9064q/dhelp_needed_with_automatic_incorrect_scene/</link>
      <description><![CDATA[大家好，正如标题所说，我正在研究一个学术项目，具体来说是一个机器学习模型，它可以检测用户上传的特定地点（例如餐厅）的错误图像。这个项目的问题是我找不到合适的数据集。我需要有人帮助我处理数据集，以便我可以继续训练模型。提前致谢。    提交人    /u/Pradeepkumar35   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i9064q/dhelp_needed_with_automatic_incorrect_scene/</guid>
      <pubDate>Fri, 24 Jan 2025 17:01:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过迭代蒙特卡洛树搜索训练语言模型代理进行自我反思</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8yj9q/r_training_language_model_agents_for/</link>
      <description><![CDATA[这里的关键创新是使用蒙特卡洛树搜索 (MCTS) 在语言模型中进行自我反思 - 本质上是教它们在确定最终答案之前系统地探索和评估不同的可能答案。该方法通过结构化的自我批评迭代地完善反应。 关键技术方面：• 专门为语言模型反思而改编的改进的 MCTS • 通过思路链分解生成的反思提示 • 对响应质量进行评分的多步骤评估过程 • 结合任务绩效和反思质量的新型奖励函数 • 在探索和利用阶段之间交替的训练过程 结果显示出有意义的改进：• 推理基准的准确率提高了 15.2% • 逻辑一致性提高了 12.4% • 幻觉率降低了 8.7% • 在系统检查很有价值的数学和编码任务上表现更好 我认为这种方法对于可靠性至关重要的应用程序尤其有影响。系统地评估响应的能力有助于减少医疗诊断支持或法律分析等领域的错误。计算开销并不小，但对于高风险应用来说，这种权衡似乎是值得的。 我认为最有趣的方面是它如何模仿人类的元认知——我们经常通过仔细检查我们的工作来发现错误。将这种能力融入语言模型中感觉就像是一种自然的进化。 我最担心的限制是反射循环可能不会收敛到更好的答案。未来的工作需要开发更好的机制来确定何时进行额外的反思会富有成效。 TLDR：新方法使用蒙特卡洛树搜索使语言模型系统地反思和改进其响应，在推理任务上显示出 15% 的准确率提升。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8yj9q/r_training_language_model_agents_for/</guid>
      <pubDate>Fri, 24 Jan 2025 15:53:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] ACL ARR 2024 年 12 月讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8x3q4/d_acl_arr_december_2024_discussions/</link>
      <description><![CDATA[ACL ARR 2024 年 12 月评论的讨论主题。评论应该很快就会出来。祝你好运！    由   提交  /u/AccomplishedCode4689   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8x3q4/d_acl_arr_december_2024_discussions/</guid>
      <pubDate>Fri, 24 Jan 2025 14:51:03 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 首席执行官表示，2024 年初，模型在 SWE-bench 上的得分约为 3%。十个月后，我们达到了 50%。他认为，再过一年，我们可能会达到 90% [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8wkth/anthropic_ceo_says_at_the_beginning_of_2024/</link>
      <description><![CDATA[&quot;我对强大 AI 的快速发展持乐观态度的原因之一是，如果你推断曲线上的下几个点，我们很快就会接近人类的能力。 我们开发的一些新模型以及其他公司的推理模型开始达到我认为的博士或专业水平。例如，我们最新的模型 Sonnet 3.5 在 SWE-bench 上获得了约 50% 的成绩，这是专业现实世界软件工程任务的基准。今年年初，最先进的水平只有 3% 或 4% 左右。在短短 10 个月内，我们在这个任务上的成绩从 3% 提高到了 50%。我相信再过一年，我们可以达到 90%。 随着 OpenAI 的 GPT-3 等模型的出现，我们在研究生水平的数学、物理和生物学方面也看到了类似的进步。如果我们继续推断这一进展，几年后，这些模型的技能水平将超越人类的最高专业水平。 那么，这种进步会继续吗？有各种原因可能导致它不会继续，但如果目前的轨迹保持不变，这就是我们的前进方向。&quot; - Dario Amodei。请在此处观看完整采访    提交人    /u/katxwoods   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8wkth/anthropic_ceo_says_at_the_beginning_of_2024/</guid>
      <pubDate>Fri, 24 Jan 2025 14:27:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于LLM实施中的文档处理和隐私问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8wiww/p_questions_on_document_handling_and_privacy_in/</link>
      <description><![CDATA[我是一家机构的内容专家团队负责人。我正在研究在全公司范围内实施 OpenwebUI，作为我们团队与本地和外部 LLM 互动的本地前端解决方案。我们的范围不仅限于内容创建。我们还研究项目管理、销售运营和创意构思。虽然我的背景是内容策略而不是技术开发，但这项研究旨在建立跨部门的综合用例。 使用我们的内部文档和知识库微调模型是一个关键的关注领域。我们目前使用 Anthropic 和 OpenAI 的 API、Claude for Teams 和 ChatGPT Pro。两家提供商都明确表示，API 交互数据仍被排除在他们的模型训练过程之外。 即使我们制定了内部指南，我仍然对文档处理有几个技术问题：  临时内存管理。我想了解文档处理的临时性质 - 具体来说，提供商是否只将提交的文档保存在临时内存中，并在会话后立即清除？根据 LLM 的声明，API 交互被排除在模型训练之外，这样是否可以更安全地发送文档？ OpenwebUI 中的文档处理。当我查看网络流量时，我很确定 OpenwebUI 在 API 查询期间传输完整的文件，而不是提取相关的摘录。这是正确的吗？是否有另一种方法可以使用 OpenwebUI，以便它只发送提示的相关文本部分？ Google Drive 集成。直接上传和 Google Drive 连接的文件之间的文档处理过程是否不同？  即使我查看了 Anthropic 和 OpenAI 的隐私文档，这些技术方面对我来说仍然不清楚。虽然 OpenAI 提供了零保留政策，但我们的组织可能超出了其范围。 对这些问题的任何见解或指导都将帮助我向管理层提出有关 LLM 实施和文档处理协议的建议。 谢谢你的帮助。    提交人    /u/thatinternetguyagain   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8wiww/p_questions_on_document_handling_and_privacy_in/</guid>
      <pubDate>Fri, 24 Jan 2025 14:24:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] CVPR 2025 的 AC 机密评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8w6oi/r_confidential_comments_to_ac_for_cvpr_2025/</link>
      <description><![CDATA[您好， 我向 CVPR 提交了两篇论文，其中一篇有两位审稿人指出缺少某些实验是一个重大缺陷。然而，这些实验已经包含在论文中了。 您认为就此问题向 AC 写一条评论是个好主意吗？ 谢谢！    提交人    /u/Training-Adeptness57   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8w6oi/r_confidential_comments_to_ac_for_cvpr_2025/</guid>
      <pubDate>Fri, 24 Jan 2025 14:08:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用有效连接和可解释的人工智能进行端到端中风成像分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8snj7/r_endtoend_stroke_imaging_analysis_using/</link>
      <description><![CDATA[https://ieeexplore.ieee.org/document/10839398 关于识别中风断开连接以进行干细胞治疗的研究，实际上对 causalML 很有用    提交人    /u/mandelbrot1981   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8snj7/r_endtoend_stroke_imaging_analysis_using/</guid>
      <pubDate>Fri, 24 Jan 2025 10:43:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有关于 Nvidia 的 DLSS 4 ViT 模型架构的详细信息吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8o4vf/d_any_details_on_nvidias_dlss_4_vit_model/</link>
      <description><![CDATA[市场营销和炒作层出不穷，但实际技术细节却很少。DLL 已经发布，我想知道是否有人尝试过深入了解它到底在运行什么？     提交人    /u/altmly   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8o4vf/d_any_details_on_nvidias_dlss_4_vit_model/</guid>
      <pubDate>Fri, 24 Jan 2025 05:16:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 19 Jan 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>