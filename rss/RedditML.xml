<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 25 Nov 2024 18:23:26 GMT</lastBuildDate>
    <item>
      <title>[D] AAAI 2025 - 反驳后评论缺失</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzn4uj/d_aaai_2025_reviews_missing_after_rebuttal/</link>
      <description><![CDATA[大家好， 我们已将论文提交给 AAAI 25。论文通过了第 1 阶段，获得了相当不错的分数，我们撰写了反驳，但现在分数、评论和反驳都丢失了。这是正常的吗？    提交人    /u/jpereira73   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzn4uj/d_aaai_2025_reviews_missing_after_rebuttal/</guid>
      <pubDate>Mon, 25 Nov 2024 16:39:01 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Claude Francois - 让 AI 以 François Chollet 的风格审查你的代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzmk5n/project_claude_francois_let_an_ai_review_your/</link>
      <description><![CDATA[演示在此处：https://claude-francois.crossingminds.com 在最近的 Anthropic Builder Day 黑客马拉松上，我们（Crossing Minds）构建了“Claude François”，一个以 Keras 的创建者 François Chollet 风格进行训练的 AI 代码审查员。它改编了 Anthropic 的 Claude 3.5 Sonnet 进行代码审查，但我们没有进行常规微调，而是使用少量上下文学习和我们的自定义 RAG 检索模型，该模型在 Keras 项目的 PR 上进行训练。与典型的 AI 代码审查者相比，它提供了更简洁、高质量的代码审查，专注于真正的问题而不是肤浅的吹毛求疵。 工作原理：  数据集：在公共 Keras GitHub PR 和 François 的评论数据库上进行训练。 微调的 RAG 嵌入：使用主动学习和 RLAIF 来训练优化为生成“fchollet 级”的嵌入审查。 改进的检索：不仅通过嵌入相似性来检索相关示例，而且通过优化相互信息来检索相关示例。 自我反思：采用自我反思技术来增强 Sonnet 的推理能力。  此技术演示展示了 Crossing Minds 的 RAGSys ICL 如何实现域自适应而无需微调。除了代码审查之外，它还可以用于无数其他用例，例如分类、摘要、翻译、搜索、推荐等。 Arxiv 论文即将发布！ 立即尝试：https://claude-francois.crossingminds.com 我们很乐意听到您的反馈！    提交人    /u/Crossing_Minds   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzmk5n/project_claude_francois_let_an_ai_review_your/</guid>
      <pubDate>Mon, 25 Nov 2024 16:16:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 按分数搜索和筛选 ICLR 论文提交</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzk8et/d_search_and_filter_iclr_submissions_by_score/</link>
      <description><![CDATA[有没有一个网站或其他东西可以让我根据分数过滤 ICLR 提交的文章？例如，只查找分数高于某个阈值的论文。    提交人    /u/nextlevelhollerith   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzk8et/d_search_and_filter_iclr_submissions_by_score/</guid>
      <pubDate>Mon, 25 Nov 2024 14:36:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] Aurora：用于地球系统预测的通用基础模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzj8rs/r_aurora_a_generalpurpose_foundation_model_for/</link>
      <description><![CDATA[这里的关键贡献是 Aurora 的开发，这是一个基于超过 100 万小时的大气数据进行训练的基础模型，可以使用单一模型架构执行多种类型的天气和气候预测。这代表着从构建单独的专门模型到拥有一个学习一般大气物理的模型的转变。 关键技术要点： - 模型架构使用具有适应时空数据的注意机制的转换器块 - 在来自多个来源的合并数据集上进行训练，包括 ERA5 再分析、卫星观测和气候模型输出 - 可以为空气污染、降水和温度预报等各种任务生成预测 - 与传统数值模型的数小时/数天相比，可在 1 分钟内生成预测 - 在多个基准上优于专门的 ML 模型和基于物理的数值天气预报 结果： - 与当前方法相比，5 天全球空气污染预测提高了 15-20% - 与专门模型相比，10 天天气预报的表现更好 - 即使在极端天气事件中也能保持准确性 - 随着训练数据的增加而持续改进 - 成功处理多个空间和时间分辨率 我认为这项工作可以显著改变我们处理环境建模的方式。无需为不同的预测任务维护单独的模型，只需拥有一个可以处理多个大气预测的单一基础模型，就可以使预测更加高效和易于理解。速度的提高（几分钟 vs. 几小时）可以支持需要快速预测的新应用程序。 我认为未来的挑战包括：- 验证更多样化大气现象的性能 - 了解关键预测的模型可解释性 - 解决训练和推理的计算成本 - 确保操作预测系统的可靠性 TLDR：研究人员开发了 Aurora，这是一种大气基础模型，经过大量天气/气候数据的训练，可以比专门的模型更好地处理多个预测任务，同时速度更快。表明基础模型可以改变环境预测。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzj8rs/r_aurora_a_generalpurpose_foundation_model_for/</guid>
      <pubDate>Mon, 25 Nov 2024 13:50:09 GMT</pubDate>
    </item>
    <item>
      <title>[2411.15100] XGrammar：灵活高效的大型语言模型结构化生成引擎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzi649/241115100_xgrammar_flexible_and_efficient/</link>
      <description><![CDATA[  由    /u/crowwork  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzi649/241115100_xgrammar_flexible_and_efficient/</guid>
      <pubDate>Mon, 25 Nov 2024 12:55:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我的特征可视化会形成这种形状？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzfo7c/d_why_does_my_feature_visualisation_form_this/</link>
      <description><![CDATA[      在执行模型特征的 3d t-SNE 分解时，我遇到了一个奇怪的怪癖。我正在对经过 ImageNet 训练的 ViT 进行微调，以进行 CIFAR-100 分类。在第一个 epoch（即仅使用未训练的 FC 特征头的 imagenet 权重）之前，类边界的可视化看起来是这样的，形成没有类别区域的凸形。一个 epoch 之后，t-SNE 可视化中不再存在此形状。 知道原因吗？这与流形假设有关吗？或者仅仅是由于 ImageNet 和 CIFAR100 类别重叠？ https://preview.redd.it/eb3w3rfaw03e1.png?width=2178&amp;format=png&amp;auto=webp&amp;s=57f1c34830cdff1968aea9367bba2b4cb3d5b7c1    提交人    /u/BDE-6   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzfo7c/d_why_does_my_feature_visualisation_form_this/</guid>
      <pubDate>Mon, 25 Nov 2024 10:14:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 评估创意写作成果和微调的效果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzdwg5/r_evaluating_creative_writing_output_and_the/</link>
      <description><![CDATA[      一位出版商问我，GPT-4o 是否可以进行微调以匹配他们的作者风格，以帮助建立副驾驶类型的体验。  这让我有机会想出一种方法，将创意写作分解为五大支柱（对话、阐述、内心想法、描述和行动），并衡量这些支柱如何随着提示和微调而变化。  我根据对 J.K. Rowling、Tade Thompson 和 Andrei Agassi 等知名作家的训练结果整理了这篇博文。令人惊讶的是，GPT-4o 在提示下很好地采用了他们的风格，但我整理了一些交互式可视化，以查看模型在故事生成（400 段）过程中如何变化，因为我们对 300、600 和 800 个样本进行了微调。  https://peytoncasper.com/blog/tone-evaluation/index.html https://github.com/peytoncasper/grammar-of-thought    由   提交  /u/peytoncasper   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzdwg5/r_evaluating_creative_writing_output_and_the/</guid>
      <pubDate>Mon, 25 Nov 2024 08:01:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 流匹配实际上与（连续）标准化流有很大不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzdera/d_flow_matching_is_actually_very_different_from/</link>
      <description><![CDATA[我查看了流匹配论文，发现流匹配通常被视为连续正则化流的替代实现。但在更仔细地比较这些方法之后，似乎存在一个非常明显的区别。在流匹配论文中，提到对于数据样本 x1（我假设这是指单个图像等单个数据点），我们可以在其上放置一个“虚拟”分布，例如非常紧密的高斯分布，然后构建一个条件概率路径 p_t(x|x1)。因此，对于每个数据点，我们学习的是数据点上的小高斯分布（t=1）与标准高斯分布（t=0）之间的变换。这意味着，当在整个数据集上进行训练时，潜在空间是每个单个数据点映射到的所有标准高斯分布的重叠混合。每个单独图像的小高斯球的图像是整个标准高斯。 然而，这似乎不是我们对常规正则化流所做的。在正则化流中，我们尝试学习将数据的整个分布转换为标准高斯的映射，使得每个数据点在潜在空间中都有一个固定的位置，并且数据集的图像在潜在空间中呈正态分布。在实践中，我们可以采用小批量并优化分数（例如 KL 或 MMD），将小批量的图像与标准高斯进行比较。潜在空间中的每个位置都可以唯一地反转为固定的重建数据点。 我不确定我是否遗漏了什么，但这似乎是两种方法之间的显着区别。在 NF 中，输入在潜在空间中编码，而本文中描述的流匹配似乎在潜在空间中混合输入。如果我的观察是正确的，那么应该有几个含义：  您可以在 NF 潜在空间中进行语义插值，但在 FM 情况下这完全没有意义 批次大小对于 NF 训练很重要，但对 FM 训练并不重要 NF 不能像扩散模型或 FM 那样被“引导”，因为目标图像在您采样初始噪声时就已经确定了  我想知道这里是否有人也研究过这些问题，可以告诉我是否确实如此，或者我遗漏的某些东西是否使它们事实上更相似。我很感激任何参与讨论的意见！    提交人    /u/aeroumbria   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzdera/d_flow_matching_is_actually_very_different_from/</guid>
      <pubDate>Mon, 25 Nov 2024 07:25:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 基于 Arduino Nano Matter 和 Raspberry Pi 5，我开发了这个项目，以探索使用 NVIDIA Omniverse 在现实世界的航运业务中数字孪生合成数据生成和面向 AI 的进步。我通过 Edge Impulse 在合成数据集上训练了我的对象检测模型。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzcu29/p_based_on_arduino_nano_matter_and_raspberry_pi_5/</link>
      <description><![CDATA[        提交人    /u/the-amplituhedron   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzcu29/p_based_on_arduino_nano_matter_and_raspberry_pi_5/</guid>
      <pubDate>Mon, 25 Nov 2024 06:46:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求论文建议。您使用什么方法来在分布略有不同的多个数据集上训练模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzcmg9/d_looking_for_paper_suggestions_whats_your_go_to/</link>
      <description><![CDATA[假设您拥有来自不同类型设备的图像数据，这些设备具有不同的颜色配置文件、分辨率、镜头失真等。或者每个数据集中捕获的对象相似但略有不同。我需要一些关于如何有效混合这些数据集以获得更大的数据集来训练基础模型的论文建议。 我的数据集都来自略有不同的分布，但它们代表的概念大致相同，因此将它们一起建模以训练基础模型是有意义的。但是，简单地将所有数据集连接在一起而不将任何元数据信息传递给模型会降低性能，而不是在每个数据集上单独进行训练。 作为参考，我正在未标记的数据上训练 MAE 类型的模型，并在测试时在冻结的 MAE 嵌入上训练简单的线性/逻辑回归模型以完成不同的下游任务。目标是让 MAE 嵌入优于在每个数据集上单独训练的监督模型。 在 N 个数据集上训练的 MAE 表现不如仅在一个数据集上训练的 MAE。但是，在进行嵌入之前，在 N-1 个数据集上训练并在第 N 个数据集上进行（无监督）微调的 MAE 优于仅在第 N 个数据集上训练的模型。但这不是一个解决方案，因为我不能有 N 个基础模型。 我尝试添加可训练的源标记（即我有 N 个可训练标记，并且在通过编码器之前将与数据源相对应的标记连接到屏蔽的输入序列）但它根本不影响模型性能。如果您知道任何更好的方法，请告诉我。    提交人    /u/Atom_101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzcmg9/d_looking_for_paper_suggestions_whats_your_go_to/</guid>
      <pubDate>Mon, 25 Nov 2024 06:31:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为计算机科学硕士生/研究员，在选择实验室领域时是否应该非常谨慎？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gz6mj1/d_as_a_cs_masters_studentresearcher_should_one_be/</link>
      <description><![CDATA[我（非常幸运）得到了一个机会，可以在一所 R1 学校的一个很棒的实验室工作，教授的 h 指数超过 40，记录很好，但主要在较低级别的会议上发表文章，尽管也做过一些 AAAI。它将 AI 应用于与我的经验相符的领域，我们有望发表文章，这很完美。但是，我更热衷于探索更多基础 AI 研究（除了我上的课程外，我在这方面的经验很少）。 在 CS、ML 领域，似乎大多数人只优先考虑 NIPS/ICLR/ICML，尤其是因为我有兴趣攻读博士学位。我有点进退维谷，不知道应该抓住机会还是继续寻找更匹配的实验室（尽管其他教授可能不想招收更多学生）。 我的直觉告诉我，我应该忽略会议排名，这样做，因为它们有一些思想链、知识表示、认知系统组件。他们希望我投入多个学期的时间，当然，一旦我投入，我就会坚持到底。我的困境是，我越来越多地转向人工智能中更实际的应用，这是一个非常具体的领域，我担心自己将来无法转型。  我知道这听起来很傻，但如果你能忽略这一点，能否请你站在一个崭露头角的学者的角度，给我一些建议和想法，谢谢！    提交人    /u/giuuilfobfyvihksmk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gz6mj1/d_as_a_cs_masters_studentresearcher_should_one_be/</guid>
      <pubDate>Mon, 25 Nov 2024 00:56:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我创建了一个库，用于构建使用树搜索来解决问题的代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyreq1/p_i_made_a_library_for_building_agents_that_use/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyreq1/p_i_made_a_library_for_building_agents_that_use/</guid>
      <pubDate>Sun, 24 Nov 2024 13:51:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 离散扩散模型的当前发展水平如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyp1br/d_what_is_the_current_stateoftheart_for_discrete/</link>
      <description><![CDATA[大家好， 我目前正在为一个新的研究项目研究离散扩散模型。在这个项目中，我将离散扩散应用到一个尚未应用的领域。然而，我对扩散本身还很陌生，我对关于这个主题的论文数量感到不知所措。在我目前的实施中，我专注于一篇较旧的论文，因为它们很好地描述了他们的方法，我想先测试我的想法，看看它是否有一些优点，根据初步结果，它确实有优点。 目前，我正在考虑用这个领域的最新补充来更新我的方法，但正如我之前所说，我对数量有点不知所措。所以我的问题是，最近有哪些研究离散扩散的好论文，它们要么解释了基本概念，比如调查论文，要么介绍了不仅适用于特定领域的新先进方法，比如 NLP 或视觉？ 提前谢谢你的帮助。    提交人    /u/Derpirium   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyp1br/d_what_is_the_current_stateoftheart_for_discrete/</guid>
      <pubDate>Sun, 24 Nov 2024 11:35:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 24 Nov 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>