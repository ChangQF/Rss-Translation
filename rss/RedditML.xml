<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 04 Sep 2024 15:17:04 GMT</lastBuildDate>
    <item>
      <title>[R] DiffUHaul：一种无需训练的图像中物体拖动方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8s7sy/r_diffuhaul_a_trainingfree_method_for_object/</link>
      <description><![CDATA[      DiffUHaul --- 给定一张带有物体的图像，我们的方法可以无缝地在场景中重新定位它。 项目页面： https://omriavrahami.com/diffuhaul/ 摘要： 文本到图像的扩散模型已被证明可有效解决许多图像编辑任务。然而，在场景中无缝重新定位物体这项看似简单的任务仍然极具挑战性。解决此问题的现有方法由于缺乏空间推理，通常难以在现实场景中可靠地发挥作用。在这项工作中，我们提出了一种无需训练的方法，称为 DiffUHaul，该方法利用局部文本到图像模型的空间理解来完成对象拖动任务。盲目操纵局部模型的布局输入往往会导致编辑性能低下，因为模型中对象表示的内在纠缠。为此，我们首先在每个去噪步骤中应用注意力掩蔽，使生成在不同对象之间更加分离，并采用自注意力共享机制来保留高级对象外观。此外，我们提出了一种新的扩散锚定技术：在早期的去噪步骤中，我们在源图像和目标图像之间插入注意力特征，以平滑地将新布局与原始外观融合；在后面的去噪步骤中，我们将源图像中的局部特征传递到插值图像以保留细粒度的对象细节。为了使 DiffUHaul 适应真实图像编辑，我们应用了 DDPM 自注意力存储桶，可以更好地使用局部模型重建真实图像。最后，我们为这项任务引入了一个自动评估流程，并展示了我们方法的有效性。我们的结果通过用户偏好研究得到了强化。    提交人    /u/sgd_is_all_you_need   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8s7sy/r_diffuhaul_a_trainingfree_method_for_object/</guid>
      <pubDate>Wed, 04 Sep 2024 12:37:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 分割任务的最佳性能指标是什么，以及如何提高高度倾斜数据集的性能？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8s44h/p_whats_the_best_performance_metrics_for/</link>
      <description><![CDATA[大家好！我目前正在进行脑肿瘤分割任务，类别高度倾斜，背景占 90%，肿瘤本身占 10%。我使用 IOU 来衡量性能，我得到了 [0.9, 0.4]。那么我应该将最终 IOU 测量为 0.9+0.4 / 2 还是 0.9(0.9) + 0.4 (0.1)，或者您建议使用其他性能指标？另外，您建议我如何提高性能？我尝试添加权重和归一化权重，但导致模型将背景像素（多数）预测为肿瘤（少数）。到目前为止，未加权的 CCE + 焦点损失表现最佳，尝试了骰子损失和骰子 + 焦点，但模型最终将所有内容预测为背景。提前致谢！    提交人    /u/ThrowRA_2983839   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8s44h/p_whats_the_best_performance_metrics_for/</guid>
      <pubDate>Wed, 04 Sep 2024 12:32:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 手指静脉活体检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8p1an/r_finger_veins_liveness_detection/</link>
      <description><![CDATA[我正在研究一种解决方案，该解决方案会拍摄用户手部的短视频，然后模型应该能够根据静脉图案确定手部是真手还是假手。  我偶然发现了一篇关于此主题的论文，但它使用专门的工具来捕获视频，这使得静脉在相机中可见，以便进行图案提取。但是，我想对其进行调整，使其适用于标准智能手机相机。就像这个。 有人能帮我吗？    由    /u/MBHQ 提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8p1an/r_finger_veins_liveness_detection/</guid>
      <pubDate>Wed, 04 Sep 2024 09:34:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] 每天为数千个 AI/ML/数据科学职位提供免费 RSS 提要</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8nw8f/p_free_rss_feed_for_tousands_of_jobs_in_aimldata/</link>
      <description><![CDATA[这是为所有对通过 RSS 格式不断更新的人工智能、机器学习、NLP、计算机视觉、数据工程、数据分析、大数据和数据科学领域工作感兴趣的人准备的。工作通过 aijobs.net 汇总，每次提供 200 个列表。提要每小时更新一次最新工作。 URL：https://aijobs.net/feed/ 无需注册 - 只需将其添加到您最喜欢的提要阅读器，即可随时了解新的机会 🚀    提交人    /u/ai_jobs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8nw8f/p_free_rss_feed_for_tousands_of_jobs_in_aimldata/</guid>
      <pubDate>Wed, 04 Sep 2024 08:12:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 对于预训练的 LLM 从 PDF 中提取发票数据有何建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8nv6y/p_recommendations_for_pretrained_llms_to_extract/</link>
      <description><![CDATA[我正在寻找一个免费的预训练 LLM，它可以从德语 PDF 中准确检测和提取发票的所有部分（如客户姓名、地址、日期等）。我已经尝试使用 Python 中的 Tesseract 和 spaCy，以及我们自己训练的模型，但结果并不理想。 有谁知道市场上有哪些更好的预训练模型可能适合这个特定任务？    提交人    /u/4AVcnE   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8nv6y/p_recommendations_for_pretrained_llms_to_extract/</guid>
      <pubDate>Wed, 04 Sep 2024 08:10:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分类是识别潜在客户的正确方法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8mthy/d_is_classification_the_right_approach_for/</link>
      <description><![CDATA[大家好， 我正在开发一个模型来识别产品的潜在客户。我有 100 万客户，其中 10% 在过去一年购买了该产品。如果我将剩余的 90% 标记为非购买者 (0)，我担心模型会错误地认为他们是真正的负面案例，而实际上他们可能只是未来的买家。 分类在这里是正确的方法吗？处理尚未购买的客户有哪些更好的方法？半监督学习或正无标记 (PU) 学习等方法是否更合适？或者聚类或新颖性检测等方法是更好的选择？ 期待您的见解！请分享您遇到相同问题的类似经验 编辑：这是一个定义不明确的问题，经常出现在商业场景中。提出的主要问题是，一家企业观察到去年 90% 的客户没有购买特定产品。因此，他们正在考虑采取行动，例如发送促销电子邮件或直接沟通，但这些行动需要付出成本。在这种情况下，识别真正的买家至关重要。答案似乎必须在计划的行动范围内提供。例如，该公司计划每月瞄准潜在客户并开展营销工作。在这种情况下，我个人认为预测客户下个月的购买情况是一种解决方案，但再次考虑负面标签时感觉有些不对劲。非常感谢这里的所有观点！     提交人    /u/bfadh   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8mthy/d_is_classification_the_right_approach_for/</guid>
      <pubDate>Wed, 04 Sep 2024 06:53:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Keras 集成方案获得相同的序列预测结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8fprj/p_getting_same_sequence_prediction_results_with/</link>
      <description><![CDATA[我正在使用 Keras 开发 LSTM/GRU 序列预测模型。我正在查看一家布局相当线性的商店中购物者购买的商品数量。例如，一位购物者购买了 5 个苹果，然后购买了 6 个香蕉，然后购买了 3 个梨。另一位购物者购买了 3 个苹果、10 个香蕉和 4 个梨，等等。水果不是实际产品，我做了一些混淆以保护我的客户，这样就不会被难倒。无论哪种方式，我都有一个序列预测，如 5,6:3、3,10:4。因为两种产品的数据不足以获得可靠的结果，所以我正在做一个“集成”方案，其中我取第一个数字（其预测本身来自客户之前的访问）并加/减一几次。因此，如果他们上次购物时买了 5 个苹果，而我的 NN 预测他们这次会买 3 个，那么我用于预测香蕉的数据集将变为 [2：？，3：？，4：？]，我对香蕉预测做同样的事情，如果神经网络输出 2：8、3：7、4：9 的预测，那么我用于预测梨的输入将变为 (2,6：？，2,7：？，2,8：？，2,9：？，2,10：？，3,5：？，3,6：？，3,7：？，3,8：？，3,9：？，4,7：？，4,8：？，4,9：？，4,10：？，4,11：？)。现在事情开始变得复杂了。 当我对一整套数据（我大概有六种产品需要预测）运行我的模型时，最后，数据看起来都一样。特别是第 5 和第 6 个数字是相同的。随着我引入的变化，我预计会出现截然不同的序列（这实际上也是我们想要的）。但我得到的结果是：4,8,11,3,4；5,9,12,3,4；2,3,11,3,4；3,6,12,3,4。请注意，第四和第五个产品预测都是相同的数字，第三个数字只有 +/- 1 个变化。 我用于预测序列的模型方案实际上很简单，每个产品模型都将前一个产品数量作为输入，因此有一个香蕉模型和一个梨模型等。每次运行时，如果模型尚未加载，我会将其加载到内存中（ModelFromJSON 和 LoadWeight）。如果已经加载，我会使用那里的内容。但结果很奇怪，我认为 product_4 模型在输入 4,8,11 和 2,3,11 时会给出截然不同的预测。我的手动“集成”方案有什么问题吗？还是我缺少 Keras 的某种重置功能？我也尝试过每次都从磁盘重新加载模型及其权重，但得到的结果相同。有人知道我应该在这里看什么吗？谢谢！    由   提交  /u/MattCW1701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8fprj/p_getting_same_sequence_prediction_results_with/</guid>
      <pubDate>Wed, 04 Sep 2024 00:26:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 曼城队 SHAP 价值观解析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f8evep/p_shap_values_explained_with_manchester_city/</link>
      <description><![CDATA[我用曼城 2021 赛季解释了 SHAP 值  计算球员的 SHAP 值 解释其背后的数学 还在 Youtube 上分享了解释该帖子的视频 用纯 numpy 实现 KernelSHAP   http://mburaksayici.com/blog/2024/09/01/shap-v​​alues-explained.html    提交人    /u/mburaksayici   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f8evep/p_shap_values_explained_with_manchester_city/</guid>
      <pubDate>Tue, 03 Sep 2024 23:48:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当今最好的开源、可精细调节、大上下文编码器-解码器模型有哪些？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f88bmp/d_what_are_the_best_open_source_finetunable_large/</link>
      <description><![CDATA[我正在寻找模型推荐来微调翻译任务。 输入序列对相当长，每个最多 1MB，尽管数据集可以截断为仅包含~200kB 序列。这些序列是程序代码（基本上是转译），但我的直觉是，我仍然会受益于基于自然语言训练的基础模型，因为它捕获了一些可以提高性能的基本常识。 我还想从头开始训练相同的模型架构，并将性能与微调版本进行比较以说明这一点。 模型标准：  开放研究许可证（不一定用于商业目的，但这是一个加分项） 基于变压器，具有编码器/解码器支路 数十万个标记的长上下文长度 理想情况下，推理可以在较新的 Mx 芯片 MacBook 上运行（不是必须的） 理想情况下，更新、更先进的模型（不是必须的） 理想情况下可在 Huggingface 中使用（不是必须的）  遗憾的是，基于BERT（例如 DistilBERT）没有足够大的上下文窗口。我一直在研究符合此标准的 XLNet 和 Longformer。两者似乎或多或少都符合要求，但我想探索所有选项。 非常感谢！    提交人    /u/huopak   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f88bmp/d_what_are_the_best_open_source_finetunable_large/</guid>
      <pubDate>Tue, 03 Sep 2024 19:05:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] Tesseract OCR - 有人用它读取 PDF 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f87yfg/p_tesseract_ocr_has_anybody_used_it_for_reading/</link>
      <description><![CDATA[我正在开发一个自定义项目，目标是从 PDF 图像中提取文本（其中文本不可选择，因此需要 OCR），然后处理文本以提取最重要的数据。图像还包含数字，理想情况下应该能够准确识别。 但是，尽管尝试了 Python 中 Tesseract 的各种配置并对图像进行了预处理，但我一直在努力提高模型的准确性。经过几天的尝试，我经常让事情变得更糟。目前，使用默认 Tesseract 设置和细微调整，高质量图像的准确率约为 80-90%，中等质量图像的准确率约为 60%，低质量图像的准确率约为 0%。 我注意到像 DOCSUMO 这样的工具似乎可以实现更高的准确率，但由于目标是创建自己的模型，所以我无法使用它们。 有人做过类似的事情吗？你使用了什么工具或技术？是否可以通过组合各种 OCR 引擎并利用 NLP 进行更好的预测来创建自定义 OCR 模型？你以前建过类似的东西吗？    提交人    /u/AquamarineML   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f87yfg/p_tesseract_ocr_has_anybody_used_it_for_reading/</guid>
      <pubDate>Tue, 03 Sep 2024 18:51:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我在 YouTube 上分享机器学习课程和项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f81i1r/p_i_am_sharing_machine_learning_courses_and/</link>
      <description><![CDATA[大家好，我想分享一下我在我的 YouTube 频道上分享的免费课程和项目。我有 200 多个视频，并且创建了用于学习机器学习的播放列表。我将在下面留下播放列表链接，祝大家有美好的一天！ 机器学习教程 -&gt; https://youtube.com/playlist?list=PLTsu3dft3CWhSJh3x5T6jqPWTTg2i6jp1&amp;si=1rZ8PI1J4ShM_9vW 数据科学和机器学习完整课程和项目 -&gt; https://youtube.com/playlist?list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;si=6WUpVwXeAKEs4tB6 数据科学与机器学习项目 -&gt; https://youtube.com/playlist?list=PLTsu3dft3CWg69zbIVUQtFSRx_UV80OOg&amp;si=NR9-6CuPNJiE0sc0    提交人    /u/onurbaltaci   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f81i1r/p_i_am_sharing_machine_learning_courses_and/</guid>
      <pubDate>Tue, 03 Sep 2024 14:35:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于 MLP 的扩散模型有多强大？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f7znps/d_how_powerful_are_diffusion_models_based_on_mlps/</link>
      <description><![CDATA[正如标题所示，我想使用基于扩散的 MLP 来完成腿式机器人运动任务，但大多数论文都使用 UNet 或 transformer 作为去噪模型（离线 RL/模仿学习），不幸的是，这对我来说不是一个选择，因为机器人以 Intel NUC/Jetson Orin 作为其主要计算，而对于稳定的运动，我们需要以 &lt;0.02 秒为单位进行采样。使用 MLP 或其与 RNN 或 CNN 的组合是否可以获得相同的样本质量？ 输入大小：225 或 450 输出大小：225    提交人    /u/Interesting-Weeb-699   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f7znps/d_how_powerful_are_diffusion_models_based_on_mlps/</guid>
      <pubDate>Tue, 03 Sep 2024 13:15:39 GMT</pubDate>
    </item>
    <item>
      <title>低深度学习负载下 GPU 时钟速度异常 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f7zbwl/abnormal_full_gpu_clockspeeds_during_low_deep/</link>
      <description><![CDATA[      我有一张 rtx 4060 ti 16 gb（是的，这不是理想的卡，这是一个单独的争论，而不是当前的问题）并且一直在使用它用于训练 resnet50 图像分类模型，用于我最后一年的项目。我用来演示这个问题的数据集非常小，总共大约有 2800 张 5 类花的图像，epoch 为 50。问题是，最近，在训练阶段甚至推理阶段，gpu 时钟加速到完整的 2790 mhz 并在整个训练过程中保持在该频率，而不是像以前一样随着 GPU 利用率的变化而上下波动。以前，在相同的工作负载下，它曾经在 750 到 1100 mhz 之间徘徊。训练期间这些“卡住的最大时钟”导致比以前更高的功率。我没有之前的确切数字，因为我没有预见到会发生这种行为，但功率大约是之前的两倍。训练后时钟会回落，除了有一次 gpu 时钟在训练期间卡在 2535 mhz 并一直保持在那里，直到我重新启动电脑。我想知道对于这种工作负载，这是否是 GPU 的正常行为，这是否由 GPU 本身根据手头的任务动态调整，是我的错误，还是这里存在更深层次的问题。我非常乐意接受建议、指导和批评。我附上了一些相关的截图。    提交人    /u/Constant_Witness6770   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f7zbwl/abnormal_full_gpu_clockspeeds_during_low_deep/</guid>
      <pubDate>Tue, 03 Sep 2024 13:01:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 01 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>