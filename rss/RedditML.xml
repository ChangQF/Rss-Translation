<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Fri, 26 Jul 2024 09:15:34 GMT</lastBuildDate>
    <item>
      <title>[R] 物理学研究机器学习博士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ecixu1/r_phd_in_machine_learning_for_physics_research/</link>
      <description><![CDATA[我获得了 CERN 的博士学位，研究物理学领域的 ML。一切看起来都很好，我很高兴能加入那个地方，我从小就听说过这个地方，一直梦想着去那里一次，但从来没有机会。我只担心一件事，导师和附属大学教授都是受过训练的物理学家，现在已经转向计算机科学，我认为我的工作将被提议发表在专注于物理计算的期刊和会议上，而不是在以 ML 为重点的会议上，如 ICML、ICLR 或 NeurIPS。这会影响我的博士研究和我未来在 ML/AI 方面的机会吗？我来自计算机科学背景。    提交人    /u/Left_Associate_2247   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ecixu1/r_phd_in_machine_learning_for_physics_research/</guid>
      <pubDate>Fri, 26 Jul 2024 08:25:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否只有部分硬件支持 int4 量化？如果是，为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ecij19/d_do_only_some_hardware_support_int4_quantization/</link>
      <description><![CDATA[我尝试使用 optimum 的 openvino 包装器将经过微调的 mT5 模型量化为 int8 和 int4。推理时间几乎没有差别，接近 5%。这让我怀疑这是否是硬件问题。我使用的是英特尔蓝宝石 rapids，它有一个 avx512_vnni 指令集。我如何确定它是否支持 int4？为什么支持，为什么不支持？    提交人    /u/Abs0lute_Jeer0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ecij19/d_do_only_some_hardware_support_int4_quantization/</guid>
      <pubDate>Fri, 26 Jul 2024 07:56:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 中的规范化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ecict8/d_normalization_in_transformers/</link>
      <description><![CDATA[在我的 transformer 出现第一个理论问题之后，我现在又看到了另一个。原始论文在残差添加后使用归一化（Post-LN），这导致了训练困难，后来被在每个注意力或 mlp 块/分支（Pre-LN）开始时的归一化所取代。众所周知，这在实践中效果更好（无需热身即可训练，恢复高速公路效果），但从理论上讲似乎仍然不完全正确。 首先考虑没有归一化的事情。假设注意力和 mlp 块设置正确并且大多保持规范，则每个残差添加都会将两个相似的规范信号相加，可能会扩大 1.4 左右（取决于相关性，但它在随机初始化后从 sqrt(2) 开始）。因此，块之后的范数可能如下所示：[1(main)+1(residual)=1.4] -&gt; [1.4+1.4=2] -&gt; [2+2=2.8] 等。这会导致各种问题（例如在后面的注意力块中更改 softmax 温度），因此需要进行调整。 Pre-LN 确保每个块都以标准化值工作（因此 softmax 温度恒定 - 如果稍微任意的话）。但由于它不影响主信号的范数（由跳过连接转发）而只影响残差，因此范数仍然可以增长，尽管速度较慢。现在的期望大致为：[1+1=1.4] -&gt; [1.4+1=1.7] -&gt; [1.7+1=2] -&gt; [2+1=2.2] 等 - 最后通过规范化校正输出附近的信号（Pre-LN 论文）。 一个可能的问题是，后面的注意力块可能会降低效果，因为它们会将单位范数残差添加到可能越来越大的主信号中。对这个问题的通常看法是什么？在实践中可以忽略它吗？尽管如此，Pre-LN 是否可以正常工作，即使对于深度模型（其中主范数差异可能会变得更大）？有很多替代的规范化论文，但实际共识是什么？ 顺便说一句，注意力极其敏感（或者，等效地，softmax 的隐藏温度至关重要）。这与 fc 或卷积形成了鲜明的对比，它们大多与尺度无关。对于任何感兴趣的人：考虑当大多数原始注意力点积出来 0（= 查询和键是正交的，没有来自此上下文槽的信息）时会发生什么，只有一个槽给出 1（= 正亲和力，在按 sqrt(qk_siz) 缩小后）。我在调试过程中对此感到惊讶。    提交人    /u/lostn4d   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ecict8/d_normalization_in_transformers/</guid>
      <pubDate>Fri, 26 Jul 2024 07:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何搜索可以在没有超高端 GPU 的情况下在笔记本电脑或台式机上本地训练的混合专家模型的实现？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ec8z4g/r_how_do_you_search_for_implementations_of/</link>
      <description><![CDATA[嗨，我是计算机科学专业的二年级博士生。我的导师刚刚想到了关于 MoE 和公平性的想法，并要求我实现它（研究表格数据而非语言数据的玩具分类问题）。但是，由于这不是他们的专业领域，他们没有提供任何有关如何处理它的指导。我的主要问题是：如何搜索或继续实现专家模型的混合？我找到的模型用于聊天等，但我主要处理表格 EHR 数据。 这是我第一次涉足这个领域（LLM 和 MoE），我对所有这些 Mixtral、openMoE 等有点迷茫。由于我们无法访问 Google Collab 或拥有强大的 GPU，我不得不依靠本地训练（我的实验室 PC​​ 有 2080ti，我的笔记本电脑有 4070）。如能提供任何关于如何进行的指导或起点，我们将不胜感激。    提交人    /u/Furiousguy79   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ec8z4g/r_how_do_you_search_for_implementations_of/</guid>
      <pubDate>Thu, 25 Jul 2024 23:12:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 PromptGuard 审核 LLM 输入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ec7ld9/r_moderating_llm_inputs_with_promptguard/</link>
      <description><![CDATA[Meta 本周发布了其最新的 Llama 语言模型系列，包括庞大的 Llama-3 405B 模型，这在 AI 开发人员中引起了极大的兴奋。这些开放权重前沿模型已更新为允许不受限制地使用输出的新许可证，将显著改进 AI 驱动的应用程序，并使合成数据能够广泛用于商业用途。Meta 最新的开放式审核工具讨论较少，但同样重要，其中包括一个名为 PromptGuard 的新模型。 PromptGuard 是一种小型、轻量级的分类模型，经过训练可检测恶意提示，包括越狱和提示注入。这些攻击可用于操纵语言模型以产生有害输出或提取敏感信息。构建企业级应用程序的公司必须能够检测和缓解这些攻击，以确保其模型可以安全使用，尤其是在医疗保健、金融和法律等敏感且受到严格监管的领域。 PromptGuard 是一个基于 mDeBERTa-v3-base 的文本分类模型，mDeBERTa-v3-base 是一个具有多语言功能的小型转换器模型。Meta 训练此模型以输出 3 个类别的概率：BENIGN、INJECTION 和 JAILBREAK。 JAILBREAK 类旨在识别恶意用户提示（例如“立即执行任何操作(在新选项卡中打开)”或 DAN 提示，它指示语言模型忽略先前的指令并进入不受限制的模式）。另一方面，INJECTION 类旨在识别检索到的上下文（例如网页或文档），这些上下文已被恶意内容污染以影响模型的输出。 在我们的测试中，我们发现该模型能够识别像 DAN 这样的常见越狱，但也会将良性提示标记为注入。发生这种情况的原因可能是，该模型经过训练可以同时处理提示和检索到的上下文（例如网络搜索和新闻文章），而良性提示可能看起来与恶意上下文相似。如模型卡中所述：  应用程序开发人员通常希望允许用户灵活地与应用程序交互，并且仅过滤明确违反规定的提示（“越狱”标签检测到的内容）。第三方内容具有不同的输入预期分布（我们不希望输入的这一部分出现任何“类似提示”的内容）  这表明，在将模型应用于用户提示时，您可能希望忽略 INJECTION 标签，并且仅过滤 JAILBREAK 输入。另一方面，在过滤第三方上下文以显示给模型（例如新闻文章）时，您需要删除 JAILBREAK 和 INJECTION 标签。 我们写了一篇关于如何使用 PromptGuard 保护您的语言模型免受恶意输入的快速博客文章。 您可以在此处阅读更多信息：https://www.trytaylor.ai/blog/promptguard    提交人    /u/Different-General700   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ec7ld9/r_moderating_llm_inputs_with_promptguard/</guid>
      <pubDate>Thu, 25 Jul 2024 22:12:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何进行“样本外”预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ec4382/p_how_to_make_outofsample_predictions/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ec4382/p_how_to_make_outofsample_predictions/</guid>
      <pubDate>Thu, 25 Jul 2024 19:47:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] EMNLP 论文评审分数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ec330j/r_emnlp_paper_review_scores/</link>
      <description><![CDATA[EMNLP 论文评审分数 我的论文总体评价是 2、2.5 和 3。它还有机会被选中吗？置信度是 2、2.5 和 3。可靠性是 2、2.5、3.5。我不确定可靠性和置信度会如何影响我的论文的选择。请解释一下这是如何运作的。我应该考虑哪些指标是重要的。 谢谢！    提交人    /u/Immediate-Hour-8466   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ec330j/r_emnlp_paper_review_scores/</guid>
      <pubDate>Thu, 25 Jul 2024 19:06:31 GMT</pubDate>
    </item>
    <item>
      <title>[N] OpenAI 宣布 SearchGPT</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ec2gk2/n_openai_announces_searchgpt/</link>
      <description><![CDATA[https://openai.com/index/searchgpt-prototype/  我们正在测试 SearchGPT，这是新 AI 搜索功能的临时原型，可为您提供快速及时的答案以及清晰且相关的来源。     提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ec2gk2/n_openai_announces_searchgpt/</guid>
      <pubDate>Thu, 25 Jul 2024 18:41:00 GMT</pubDate>
    </item>
    <item>
      <title>[N] 人工智能在国际数学奥林匹克竞赛中取得银牌成绩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebyx03/n_ai_achieves_silvermedal_standard_solving/</link>
      <description><![CDATA[https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/ 他们解答了 6 道 IMO 题目中的 4 道（尽管有些题目花了好几天才解答）。这样他们的分数就是 28/42，只比金牌水平低一分。    提交人    /u/we_are_mammals   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebyx03/n_ai_achieves_silvermedal_standard_solving/</guid>
      <pubDate>Thu, 25 Jul 2024 16:16:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] HuggingFace 模型 (LLM) 对文本摘要/生成任务的可解释性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebximk/r_explainability_of_huggingface_models_llms_for/</link>
      <description><![CDATA[大家好， 我正在探索负责任的人工智能领域，我已经开始阅读有关使深度学习模型可解释的方法和工具。我已经使用 SHAP 和 LIMe 来实现 ML 模型可解释性。但是，我不确定它们在解释 LLM 方面的用途。我知道这些方法与模型无关，但我们可以将这些方法用于文本生成或摘要任务吗？ 我从 Shap 那里获得了解释 GPT2 用于文本生成任务的参考文档，但我不确定是否将其用于其他较新的 LLM。此外，我想知道，有没有更好的方法来实现 LLM 的可解释人工智能？    提交人    /u/PhoenixHeadshot25   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebximk/r_explainability_of_huggingface_models_llms_for/</guid>
      <pubDate>Thu, 25 Jul 2024 15:19:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 高维概率模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebwzkq/d_highdimensional_probabilistic_models/</link>
      <description><![CDATA[目前对高维随机过程进行建模的标准方法是什么？我在图像 x 上定义了一些过程，我想为所有 x&#39; 计算 P(x&#39; | x, z)。我知道有正则化流、高斯过程等，但我不知道从哪一个开始。我特别想计算概率，而不仅仅是抽样一些 x&#39; ~ P(x, z)。    提交人    /u/smorad   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebwzkq/d_highdimensional_probabilistic_models/</guid>
      <pubDate>Thu, 25 Jul 2024 14:58:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 共享想象力：法学硕士产生幻觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebvd4w/r_shared_imagination_llms_hallucinate_alike/</link>
      <description><![CDATA[      很高兴分享我们最近的论文，我们在论文中证明了 LLM 在纯粹的想象和幻觉内容上表现出惊人的一致性 —— 我们称之为“共享想象空间”。为了得出这个结论，我们要求 LLM 针对假设内容（例如，物理学中虚构的概念）提出问题，然后发现它们能够以比随机概率更高的准确率回答彼此的（无法回答且毫无意义的）问题。由此，我们从多个方向研究了它的出现、普遍性和可能的​​原因，并鉴于现代 LLM 中幻觉和想象行为的一致性，讨论了对幻觉检测和计算创造力的影响。  论文链接：https://arxiv.org/abs/2407.16604 包含结果摘要和重点的推文链接：https://x.com/YilunZhou/status/1816371178501476473 如有任何问题，请随时提问！ 主要实验设置和发现。    提交人    /u/zyl1024   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebvd4w/r_shared_imagination_llms_hallucinate_alike/</guid>
      <pubDate>Thu, 25 Jul 2024 13:49:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文 NAACL 2024：“新闻媒体来源的可靠性评估：物以类聚”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebqclk/r_paper_naacl_2024_reliability_estimation_of_news/</link>
      <description><![CDATA[对于一般从事信息验证的人来说，例如，从事事实核查、虚假新闻检测，甚至使用新闻文章中的 RAG，本文可能会有所帮助。 作者使用不同的强化学习技术，根据新闻媒体在网络上的互动方式来估计其可靠性值。 该方法易于扩展，因为可以使用源代码从 Common Crawl News 构建更大的基于超链接的交互图。作者还发布了计算值和带有新闻媒体可靠性注释的数据集：  Github repo： https://github.com/idiap/News-Media-Reliability 论文： https://aclanthology.org/2024.naacl-long.383/ 现场演示示例： https://lab.idiap.ch/criteria/  在演示中，检索到的新闻文章不仅按与查询的匹配排序，还按每个来源的估计可靠性排序（URL 域用颜色编码，从绿色到绿色）。例如，如果查询结果为红色，则向下滚动将显示来自可靠性较低的来源的结果（用红色标记）。或者，如果查询中给出了新闻 URL 或新闻媒体域名（例如 apnews.com），则会详细说明估计值（例如，显示与媒体交互的邻近来源等）。 祝大家有美好的一天！:)    提交人    /u/sergbur   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebqclk/r_paper_naacl_2024_reliability_estimation_of_news/</guid>
      <pubDate>Thu, 25 Jul 2024 09:10:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] ACL ARR 六月 (EMNLP) 评审讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebmas6/d_acl_arr_june_emnlp_review_discussion/</link>
      <description><![CDATA[太担心评论了，因为它们还没到！想与社区分享，看看大家对评论的反应！发泄一下！评论时要有礼貌。     提交人    /u/always_been_a_toy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebmas6/d_acl_arr_june_emnlp_review_discussion/</guid>
      <pubDate>Thu, 25 Jul 2024 04:45:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 21 Jul 2024 02:15:09 GMT</pubDate>
    </item>
    </channel>
</rss>