<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 18 Oct 2024 09:18:09 GMT</lastBuildDate>
    <item>
      <title>[R] 主流 LLM 标记器的局限性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6dc8l/r_limitations_in_mainstream_llm_tokenizers/</link>
      <description><![CDATA[主流 LLM 标记器无法编码和解码为精确的字符串。这意味着它们不是无损的。一些 Llama、Mistral 和 Phi 标记器无法编码字符串 &#39; 谁放了狗？！ !&#39;，然后解码为相同的字符串。 如果运行代码：```python from transformers import AutoTokenizer models = [ &#39;meta-llama/Llama-2-7b&#39;, &#39;meta-llama/Meta-Llama-3-8B&#39;, &#39;meta-llama/Llama-3.1-8B&#39;, &#39;mistralai/Mistral-7B-v0.3&#39;, &#39;mistralai/Mixtral-8x7B-v0.1&#39;, &#39;mistralai/Mixtral-8x22B-v0.1&#39;, &#39;mistralai/Mistral-Nemo-Instruct-2407&#39;, &#39;mistralai/Mistral-Small-Instruct-2409&#39;, &#39;mistralai/Mistral-Large-Instruct-2407&#39;, &#39;microsoft/phi-1&#39;, &#39;microsoft/phi-1_5&#39;, &#39;microsoft/phi-2&#39;, &#39;microsoft/Phi-3-mini-4k-instruct&#39;, &#39;microsoft/Phi-3.5-mini-instruct&#39;, ] text = &#39; 谁放了狗？！&#39; for n in models: tokenizer = AutoTokenizer.from_pretrained(n) text2 = tokenizer.decode(tokenizer.encode(text, add_special_tokens=False)) if text2 == text: print(&#39;OK: &#39;, n, repr(text2)) else: print(&#39;ERR:&#39;, n, repr(text2))  ``` 您将得到： OK: meta-llama/Llama-2-7b &#39; 谁放了狗？！&#39; ERR: meta-llama/Meta-Llama-3-8B “谁放出了狗？！！” ERR: meta-llama/Llama-3.1-8B “谁放出了狗？！！” ERR: mistralai/Mistral-7B-v0.3 “谁放出了狗？！！” OK: mistralai/Mixtral-8x7B-v0.1 “谁放出了狗？！！” ERR: mistralai/Mixtral-8x22B-v0.1 “谁放出了狗？！！” OK: mistralai/Mistral-Nemo-Instruct-2407 “谁放出了狗？！！” OK: mistralai/Mistral-Small-Instruct-2409 “谁放出了狗？！！” OK：mistralai/Mistral-Large-Instruct-2407 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-1 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-1_5 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-2 &#39;谁放出了狗？！&#39; OK：microsoft/Phi-3-mini-4k-instruct &#39;谁放出了狗？！&#39; OK：microsoft/Phi-3.5-mini-instruct &#39;谁放出了狗？！&#39;  所有标有 ERR 的都无法编码​​并解码为相同的字符串。    提交人    /u/mtasic85   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6dc8l/r_limitations_in_mainstream_llm_tokenizers/</guid>
      <pubDate>Fri, 18 Oct 2024 08:35:43 GMT</pubDate>
    </item>
    <item>
      <title>“[P]” 如何使 Microsoft Fairlearn 的 Exponentiated gradient 与 DistilBERT 分类模型协同工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6dc6v/p_how_to_make_microsoft_fairlearns_exponentiated/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6dc6v/p_how_to_make_microsoft_fairlearns_exponentiated/</guid>
      <pubDate>Fri, 18 Oct 2024 08:35:37 GMT</pubDate>
    </item>
    <item>
      <title>[D]（咆哮）自愿为另一位教授做研究工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6c603/d_rant_volunteering_to_do_research_work_for/</link>
      <description><![CDATA[我最近完成了本科学习，现在全职担任一位教授（教授 A）的 RA，从事多模式在线仇恨理解。我想了解另一位教授（教授 B，在同一所学校）在人工智能安全方面的工作。我找到他，问我是否可以兼职参与该领域的一个项目。我们见面讨论了这个问题，他一开始很犹豫，因为他担心我是否能处理他的工作，但最终同意让我加入。我很清楚我想以非正式的方式参与其中。 更不用说，在这次讨论之前，他认为我想全职加入他的实验室，并去告诉教授 A 这件事。所以教授 A 认为我是背着他干的。当我纠正了这个误解后，几天后，教授 B 告诉教授 A，他对这种安排感到不舒服，因为教授 A 付钱给我。 A 教授告诉了我这件事，他同意 B 教授的说法，“这有点棘手”。用 A 教授的原话来说，“就像我想送你出国实习，但我没见过 RA 去实习 LOLLL，也许你可以考虑读个兼职硕士什么的” 我 5 月份刚毕业，可能不明白教授们与本科生和 RA 的安排是如何的，但是  为什么在下班后空闲时间做其他研究工作志愿这么“棘手”？为什么这算是实习？我知道很多本科生都会在教授（包括 B 教授）的实验室做志愿者。我也是以同样的方式开始与 A 教授一起工作的——在我读本科期间，我自愿做一些工作，这样我就可以了解他的领域，而且我确实学到了很多东西。我为他工作了几个小时，但没人关心我是否能完成分配给我的工作，也没人愿意付钱给我。为什么现在这些事情成了问题？ 我以前认识一些本科生，他们同时为两位教授工作。我认为这并不罕见。  他们都认为这很棘手，这让我认为我错过了什么。教授的 A 字让我的方法听起来很奇怪，闻所未闻。 总而言之，这是一场咆哮，因为我一直想了解这个领域的其他领域，但通过向其他大学的教授发送电子邮件却无济于事。目前，我有 2 篇论文被 A* 会议接受，但回复的缺乏令人沮丧。这种互动并没有起到什么帮助作用。 我是否排除了与大学里的其他教授接触的可能性？ 抱歉，我发牢骚了    提交人    /u/ElectricalLeek5   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6c603/d_rant_volunteering_to_do_research_work_for/</guid>
      <pubDate>Fri, 18 Oct 2024 07:02:26 GMT</pubDate>
    </item>
    <item>
      <title>医学成像人工智能顶级会议 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6bu6z/top_conferences_for_ai_in_medical_imaging_d/</link>
      <description><![CDATA[抱歉，标题中不能有“AGI”。 我正在研究我的第一篇第一作者研究，我的导师认为它的发展方向很好。我真的希望它明年能通过一些好的会议。 我知道 MICCAI 和 MIDL，但找不到可靠的来源来检查 2025 年与医学成像或医学 AI 相关的所有其他会议。我希望这里的人一定有一些其他经验。有什么建议吗？ 另外，研讨会论文是什么意思？我知道它不叫真正的出版物，但它值得提交给一个备受推崇的研讨会还是一个中等排名的会议？ 提前谢谢！    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6bu6z/top_conferences_for_ai_in_medical_imaging_d/</guid>
      <pubDate>Fri, 18 Oct 2024 06:37:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于“迷失于中间”现象是否存在一个普遍认可的解释？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6avhy/d_is_there_a_universally_agreed_explanation_for/</link>
      <description><![CDATA[自从我在攻读长语境法学硕士 (LLM) 期间阅读“Lost in the Middle”论文以来，已经有一段时间了。我很好奇是否有一篇论文提出了对这种影响的广泛接受的解释，或者是否有任何方法可以有效地解决或克服它。    提交人    /u/StraightSpeech9295   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6avhy/d_is_there_a_universally_agreed_explanation_for/</guid>
      <pubDate>Fri, 18 Oct 2024 05:28:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 2.5.0 发布！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g62vyh/d_pytorch_250_released/</link>
      <description><![CDATA[https://github.com/pytorch/pytorch/releases/tag/v2.5.0 亮点：我们很高兴地宣布 PyTorch® 2.5 的发布！此版本为 SDPA 提供了新的 CuDNN 后端，默认情况下，为 H100 或更新 GPU 上的 SDPA 用户启用加速。此外，torch.compile 的区域编译提供了一种减少 torch.compile 冷启动时间的方法，它允许用户编译重复的 nn.Module（例如 LLM 中的转换器层）而无需重新编译。最后，TorchInductor CPP 后端通过 FP16 支持、CPP 包装器、AOT-Inductor 模式和最大自动调谐模式等众多增强功能提供了可靠的性能加速。此版本由 504 位贡献者自 PyTorch 2.4 以来的 4095 次提交组成。我们衷心感谢我们敬业的社区所做的贡献。 我最喜欢的一些改进：  通过重复使用重复模块加快 torch.compile 编译速度 torch.compile 支持 torch.istft FlexAttention：一种灵活的 API，只需几行惯用的 PyTorch 代码即可实现各种注意机制，如滑动窗口、因果掩码和 PrefixLM。此 API 利用 torch.compile 生成融合的 FlashAttention 内核，从而消除了额外的内存分配并实现了与手写实现相当的性能。此外，我们使用 PyTorch 的自动求导机制自动生成向后传递。此外，我们的 API 可以利用注意力掩码中的稀疏性，从而比标准注意力实现有显著的改进。     提交人    /u/parlancex   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g62vyh/d_pytorch_250_released/</guid>
      <pubDate>Thu, 17 Oct 2024 22:11:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 是否可以将随意语言模型转换为掩码语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g61plo/p_is_it_possible_to_convert_a_casual_language/</link>
      <description><![CDATA[我正在为大学做一个项目，在这个项目中我需要一个掩码语言模型（不是英文的），我想知道，既然像 gpt2 这样的随意语言模型基本上是掩码模型，但它们只是把 MASK 标记放在句子的末尾。是否可以将其转换为掩码模型，这样我就可以把 MASK 标记放在任何地方？我不是指通过提示它成为一个掩码模型，而是指真正将它改变为一个。    提交人    /u/Appletee_YT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g61plo/p_is_it_possible_to_convert_a_casual_language/</guid>
      <pubDate>Thu, 17 Oct 2024 21:17:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何使用 LLM 从 500k 条聊天信息中提取见解？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5yn4b/p_how_to_extract_insights_from_500k_chat_messages/</link>
      <description><![CDATA[大家好， 我从 AI 上的 discord 服务器下载了聊天消息，2-3 年间总计约 50 万条消息。我这样做的原因是我想提取有关该主题的见解/提示和技巧，而这些见解/提示和技巧可能在在线教程中找不到（我一直发现在 discord 服务器中，人们互相帮助比阅读各种博客文章/教程更有信息量）。 它们总计约 800 万个代币，使用 gpt-4o-mini 需要花费 1-2 美元，使用 gpt-4o 需要花费 20-30 美元，这是相当合理的。 但是，我正在尝试弄清楚两件事： 1) 我是否可以使用本地 llm 来完成部分流程。这是首选，因为虽然 gpt-4o-mini 只需花费 1 到 2 美元，但这是每个提示的价格，而且我可能希望以多种方式查询/处理数据。 2) 我到底能做些什么来提取最有价值的见解？可能 95% 的聊天只是玩笑，但 5% 可能充满了有用的建议。我可以使用什么样的提示？我该如何处理需要分块输入以适应上下文窗口的事实？ 我愿意学习和探索任何新的主题来解决这个问题，因为我很高兴把它作为一个项目来接触 LLM。    提交人    /u/PMMEYOURSMIL3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5yn4b/p_how_to_extract_insights_from_500k_chat_messages/</guid>
      <pubDate>Thu, 17 Oct 2024 19:04:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些最有趣的现实世界（应用）机器学习会议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5txyp/d_what_are_some_of_the_most_interesting/</link>
      <description><![CDATA[我知道对于信息检索和推荐系统，RecSys 和 SIGIR 提供了一些行业讲座，我想知道您是否知道其他主要涉及行业发现/研究的讲座。    提交人    /u/gabegabe6   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5txyp/d_what_are_some_of_the_most_interesting/</guid>
      <pubDate>Thu, 17 Oct 2024 15:45:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] EigenLoRA：LLM 和扩散模型的极其高效的学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5tw6i/d_eigenlora_extremely_efficient_learning_for_llms/</link>
      <description><![CDATA[发现这篇论文 EigenLoRA，它展示了语言模型和扩散模型的相当不错的结果。它表明我们可以回收旧的 LoRA 并将它们结合起来以学习一个高效的子空间，这只需要很少的参数来微调。如果这是合法的，这似乎是一个非常酷的想法 - 人们可以以非常低的计算成本微调非常大的模型。我的问题是 - 这也可以应用于没有 LoRA 的微调模型吗？因为我们可以从基础和微调模型计算出 LoRA？有人尝试过类似于这个 EigenLoRA 模型的东西吗？    提交人    /u/propaadmd   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5tw6i/d_eigenlora_extremely_efficient_learning_for_llms/</guid>
      <pubDate>Thu, 17 Oct 2024 15:43:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何构建自定义文本分类器，无需花费数天时间进行人工标记</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5t7lq/p_how_to_build_a_custom_text_classifier_without/</link>
      <description><![CDATA[嗨，我在 Hugging Face 工作。我和我的团队致力于这个很酷的例子，说明如何从 LLM 转变为小型高效的分类模型。我们使用 LLM 自动标记数据集，然后在快速审查后对其进行微调。我们展示了它如何帮助我们简化工作流程，节省时间和资源，同时仍提供高性能模型。具有更高的准确性，同时仅标记几个示例。 博客文章：https://huggingface.co/blog/sdiazlor/custom-text-classifier-ai-human-feedback    提交人    /u/chef1957   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5t7lq/p_how_to_build_a_custom_text_classifier_without/</guid>
      <pubDate>Thu, 17 Oct 2024 15:13:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] DART 可以实时生成高质量的人体动作，在单个 RTX 4090 GPU 上实现每秒超过 300 帧的速度！它将文本输入与空间约束相结合，允许执行到达航点和与场景交互等任务。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5kq1v/r_dart_can_generate_highquality_human_motions_in/</link>
      <description><![CDATA[ 这是项目页面的链接：https://zkf1997.github.io/DART/ 这是论文的链接：https://arxiv.org/html/2410.05260v1 这是我的问题：我正在尝试以基于浏览器的应用程序的形式重新创建这篇论文，以供我使用。在哪里可以找到训练 VAE 所需的运动数据和文本注释？     提交人    /u/Hrombarmandag   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5kq1v/r_dart_can_generate_highquality_human_motions_in/</guid>
      <pubDate>Thu, 17 Oct 2024 06:40:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您认为该领域的下一个大事件是什么？LLM 的炒作会消退吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5jvzp/d_what_do_you_think_will_be_the_next_big_thing_in/</link>
      <description><![CDATA[我很高兴看到 LLM 的成功，但我并不是 NLP 的粉丝。您认为下一个能够取得商业成功或具有广泛适用性的大事件是什么（对初创公司和大公司都有用）？ 例如，RL 或 GNN 是否会开始在实践中得到更广泛的应用（我知道 GNN 在大公司中使用，但我仍然不知道它们被广泛使用）？ 考虑到实际应用，我认为计算机视觉是一个成熟的领域，但那里是否可能发生一些新的事情？    提交人    /u/Diligent-Ad8665   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5jvzp/d_what_do_you_think_will_be_the_next_big_thing_in/</guid>
      <pubDate>Thu, 17 Oct 2024 05:41:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 13 Oct 2024 02:15:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>