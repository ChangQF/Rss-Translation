<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Tue, 25 Feb 2025 18:23:50 GMT</lastBuildDate>
    <item>
      <title>[讨论]与F1得分挣扎并在不平衡的二元分类模型（染色质访问性）中进行回忆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iy15ry/discussion_struggling_with_f1score_and_recall_in/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iy15ry/discussion_struggling_with_f1score_and_recall_in/</guid>
      <pubDate>Tue, 25 Feb 2025 17:54:39 GMT</pubDate>
    </item>
    <item>
      <title>[P]训练一点（39m）语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iy0rra/p_train_a_little39m_language_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我今年开始越来越多地进入LLM，寻找资源一直很容易模型架构不足以完全掌握这些模型的训练方式。  由于我在一个地方无法找到最近的架构实现的任何代码，所以我自己制作了。 我的目标是帮助任何具有基本理解的人变压器体系结构，但想通过最近的建筑变化从头开始训练自己的模型。 （我在此过程中包括资源 +我自己的笔记） 所以我的努力​​是训练小语言模型的努力，即从头开始的39m参数模型，可以很好地交谈。 它在2XA100上进行了训练。 〜8b令牌上的2.5小时。 我计划在此项目中包含所有内容!!!!  现在它包括一个基本的类似Llama的架构。   -  rmsnorm而不是layernorm    - 旋转位置嵌入而不是绝对位置嵌入   -  swiglu激活而不是relu    - 分组查询注意力而不是多头注意   -  kV缓存的实现  todo包含   - 使用dpo   fineTuning    - 添加混合物专家（MOE）体系结构   - 以及更多 如果有人愿意为这个项目做出贡献，那将是很棒的。 请找到该项目这里： https://github.com/cohlem/lillm/lillm    我将其发布在r/ localllama 也是一个很好的回应。在此处发布以最大程度的可见性。  谢谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Royalmaterial9614     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iy0rra/p_train_a_little39m_language_model/</guid>
      <pubDate>Tue, 25 Feb 2025 17:38:45 GMT</pubDate>
    </item>
    <item>
      <title>[d]“反向传播：前向和向后分化[第2部分]”的视觉解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iy0d47/d_visual_explanation_of_backpropagation_forward/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 以前我共享了帖子的第1部分href =“ https://www.reddit.com/r/machinelearning/comments/1irs3gn/d%5c_visual%5c_explanation%5c_of%5c_backpropagatio n/“&gt; https://www.reddit.com/r/machinelearning/comments/1irs3gn/dver_visual/_explanation \ _of_of_backpropagation/ 。 这是 backpropagation上的第2部分 post。在本教程中，您将了解部分与总导数，向后传播。 最初，我很难理解 另外，如果您有任何问题，我很想获得有关此主题的一些高级或有趣材料的链接。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/madiyar     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iy0d47/d_visual_explanation_of_backpropagation_forward/</guid>
      <pubDate>Tue, 25 Feb 2025 17:22:10 GMT</pubDate>
    </item>
    <item>
      <title>[r] MUON对于LLM培训是可扩展的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixzj26/r_muon_is_scalable_for_llm_training/</link>
      <description><![CDATA[        tl; dr ： muon 是一种优化algorithm ，替代Adamw。该报告表明，与Adamw相比，它节省了大约一半的拖鞋，用于在39b代币上受过训练的1.5B LLM。   paper  ： https://arxiv.org/pdf/2502.16982    摘要：   最近，基于矩阵正交化的MUON优化器在训练小型语言模型方面表现出很强的结果，但是对较大模型的可伸缩性具有没有被证明。我们确定了两种至关重要的技术来扩展MUON：（1）增加重量衰减，（2）仔细调整参数更新量表。这些技术使MUON可以在大规模培训的情况下开箱即用，而无需进行超参数调整。缩放定律实验表明，与ADAMW相比，MUON具有约2倍的计算效率，并通过计算最佳培训。基于这些改进，我们引入了Moonlight，这是一种3B /16B参数的混合物（MOE）模型，该模型接受了训练有素的模型5.7吨代币使用MUON。与先前的模型相比，我们的模型改善了当前的帕累托前沿，通过更少的训练拖曳来取得更好的性能。我们开源我们的分布式MUON实现，这是内存最佳和沟通效率的。我们还释放了经过预定的，指导和中间检查点，以支持未来的研究。   视觉摘要：      视觉亮点：           https://preview.itd.it/bxekx1ntcble1.png?width=1095＆amp; format = png＆amp; auto = webpp＆s = 508a10fdea89d17a49e619e619b53f88622222260ebd9393939393939384449e619e619e     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sustledwaterMelon     [link]       [注释]  /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixzj26/r_muon_is_scalable_for_llm_training/</guid>
      <pubDate>Tue, 25 Feb 2025 16:48:27 GMT</pubDate>
    </item>
    <item>
      <title>[n]现在可用的tenstorrent云实例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixyp2h/n_tenstorrent_cloud_instances_now_available/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   tenstorrent正在构建下一代AI硬件。他们的虫洞实例现在可以在Koyeb Cloud上提供：https://www.koyeb.com/blog/tenstorrent-cloud-instances-揭开next-next-gen-ai-accelerators    &lt;！ -  sc_on - &gt;＆＃32;提交由＆＃32; /u/u/plus_ad7909     [link]        [commist]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixyp2h/n_tenstorrent_cloud_instances_now_available/</guid>
      <pubDate>Tue, 25 Feb 2025 16:14:06 GMT</pubDate>
    </item>
    <item>
      <title>[p]寻找API或应用程序来扫描刺并提取元数据📚</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixyjzu/p_looking_for_apis_or_apps_to_scan_book_spines/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我正在研究一个旨在扫描书架，从刺中提取书名的项目一年，等等）自动。目的是帮助组织分类大型书籍收集，而无需手动数据输入。到目前为止，我正在使用OCR（Tesseract，Easyocr，Google Vision API）从书本上提取文本，但是我需要一种将提取的标题与外部数据库或API匹配的方法来检索完整的书籍信息。有谁知道可以为此提供帮助的良好API或现有应用程序吗？我发现： * Google Books API📚（但结果有时不一致）。 *开放库API（似乎很有希望，但缺乏一些元数据）。 * WorldCat API（尚未测试）。如果您对更好的API，应用程序甚至已经这样做的现有解决方案有任何建议，我很想听听您的想法！另外，如果任何人都有改善书本OCR的经验（对齐问题，模糊文本等），则任何建议将不胜感激。提前致谢！ 🙌  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ok-leadersip-7787     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixyjzu/p_looking_for_apis_or_apps_to_scan_book_spines/</guid>
      <pubDate>Tue, 25 Feb 2025 16:08:16 GMT</pubDate>
    </item>
    <item>
      <title>[p]在视觉上进行文献综述，以便您可以看到关键思想的发展（公共beta）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixxqpr/p_do_literature_review_visually_so_you_can_see/</link>
      <description><![CDATA[            &lt;！ -  sc_off-&gt;     这是 https://arxiv-viz.ianhsiao.xyz &lt; /a&gt;试图帮助您从视觉上看到思想的发展。 该工具的目的是让其用户找出什么论文是关于视觉的，最初是在在这里！早期支持者的意见和功能请求对此工具的未来有很大的重视，请帮助我塑造它：）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1ixxqpr/p_do_do_literature_review_viseal_visaly_so_so_so_you_can_see/&gt; [link]   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixxqpr/p_do_literature_review_visually_so_you_can_see/</guid>
      <pubDate>Tue, 25 Feb 2025 15:33:35 GMT</pubDate>
    </item>
    <item>
      <title>CFM/Medical IMG生成/合成的流量匹配[P] [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixx2u9/cfmflowmatching_for_medical_img/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在查看CFM的应用程序论文，尤其是最佳传输（OT）方法。尽管声称它比扩散模型所需的迭代要少得多，并且实施更简单。我看不到任何与医学成像或合成数据生成有关的应用程序文件。  我确实遇到了TorchCFM，看起来可以用于此目的，但不应该在此目的其他替代方案，因为我看到很多大型研究实验室都在该领域工作。  也使用CFM有任何经验吗？您是否将结果与CIFAR图像以外的扩散模型进行了比较？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1ixx2u9/cfmflowmatching_for_medical_img/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixx2u9/cfmflowmatching_for_medical_img/</guid>
      <pubDate>Tue, 25 Feb 2025 15:05:05 GMT</pubDate>
    </item>
    <item>
      <title>非专家3D艺术家可以生成合成训练数据[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixvbln/can_a_nonexpert_3d_artists_generate_synthetic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个医学成像用户酶。我想知道获得非专家3D艺术家是否有可能或可靠，为医学成像中的利基用户酶生成一些培训数据，而培训数据不容易获得。他们可以使用我想像的搅拌机等工具。有人有这样的经验吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/eapher-ecomony8403     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixvbln/can_a_nonexpert_3d_artists_generate_synthetic/</guid>
      <pubDate>Tue, 25 Feb 2025 13:44:47 GMT</pubDate>
    </item>
    <item>
      <title>[D]寻找ML / CV /信号处理黑客马拉松</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixujof/d_looking_for_ml_cv_signal_processing_hackathons/</link>
      <description><![CDATA[在他们都是比赛。这意味着它们比黑客马拉松长。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/neotod1     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixujof/d_looking_for_ml_cv_signal_processing_hackathons/</guid>
      <pubDate>Tue, 25 Feb 2025 13:07:13 GMT</pubDate>
    </item>
    <item>
      <title>[R]分析2024年400多个ML比赛</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixrxoq/r_analysis_of_400_ml_competitions_in_2024/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我运行mlcontests.com，一个网站，列出了来自多个平台的ML竞赛-Kaggle，drivendata，aicrowd，aicrowd，zindi等…… 我刚刚花了几个月的时间查看我在去年的比赛中找到的所有信息以及赢得解决方案。  我发现了去年发生的400多场比赛，以及其中70个获胜解决方案的信息。  一些亮点：    kaggle仍然是总奖金最大的平台，并且比其他平台拥有更大的用户群 - 尽管有超过十几个值得跟踪的其他平台，并进行了定期有趣的比赛和有意义的奖金。  竞争的增加100万美元+奖品池（ARC奖励， 人工智能与往年相比。一位获胜者使用Rust，两名使用R.   卷积神经网继续在计算机视觉竞赛中表现出色，在竞争赢家中仍然比基于变形金刚的视觉模型更为普遍。    pytorch的使用量大于tensorflow ，大​​约是9：1。没有发现任何竞争者在JAX或其他图书馆中实施神经网。   使用Automl软件包有一些竞赛冠军，似乎越来越有用。不过，通才自主的大师级特工的任何主张似乎还为时过早。   在语言/文本/序列相关的竞争中，定量是有效利用有限资源的关键。通常是4-，5或8位。 Lora/Qlora也经常使用，尽管并非总是如此。   促进梯度的决策树继续赢得许多表格/时间序列的比赛。他们通常会喜欢深度学习模型。据我所知，获奖者在2024年没有使用表格/时间序列的预训练基础模型。   开始看到更多的数据范围的极点摄入量，有7个获奖者在2024年使用Porars（从2023年的3次提高），而使用PANDAS则使用Porars。所有使用Polars的人仍然在代码的某些部分中使用了大熊猫。  就硬件而言，竞争获奖者几乎完全使用了NVIDIA GPU来训练他们的模型。一些人仅在CPU上接受培训，或者通过Colab使用了TPU。没有AMD GPU。 NVIDIA A100是获奖者中最常用的GPU。 100万美元以上的奖金泳池比赛中有两个是由使用8xH100节点进行培训的团队赢得的。不过，还有许多其他GPU：T4/P100（通过Kaggle笔记本电脑）或RTX 3090/4090/3080/3060等消费者GPU。一些花费了数百美元在云上计算以训练他们的解决方案。  一种新兴模式：使用生成模型创建其他合成训练数据以增强提供的训练数据。   完整报告中有更多详细信息，您可以在此处阅读（无付费墙）： https://mlconts.com/state-com/state-of-machine-learning-learning-competition--competition--2024?ref= MLCR    处理IMG XMM4YWG9H9LE1 ...   完整报告还具有：  深入了解ARC奖和AI数学奥林匹克运动会 赢得NLP/序列竞赛解决方案的概述 赢得解决方案中使用的Python软件包的细分（例如，各种相对普及梯度增强的树库）  如果您想支持这项研究，我将非常感谢您与其他可能会发现它有趣的人分享。您还可以查看我新发射的在线杂志， jolt Ml   - 在顶级ML会议和长阅读文章中提供新闻（到目前为止，还有更多！）。  感谢竞争获奖者分享了有关其解决方案的信息，也感谢竞争平台分享了有关比赛的高级数据。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/hcarlens   href =“ https://www.reddit.com/r/machinelearning/comments/1ixrxoq/r_analsisy_of_400_ml_ml_competitions_in_2024/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixrxoq/r_analysis_of_400_ml_competitions_in_2024/</guid>
      <pubDate>Tue, 25 Feb 2025 10:28:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] CVPR 2025结束决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixpu28/d_cvpr_2025_final_decision/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  亲爱的社区成员， 标题所建议的，此线程适用于所有等待CVPR的25个结果的人。我敢肯定，你们现在都感觉到肚子里的蝴蝶。因此，让我们在整个过程中互相支持并讨论结果。现在不到24小时，我期待在此线程中进行令人兴奋的互动。  P.S。我的评分为4,3,3，平均信心为3.67。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/stantheta   href =“ https://www.reddit.com/r/machinelearning/comments/1ixpu28/d_cvpr_2025_final_decision/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixpu28/d_cvpr_2025_final_decision/</guid>
      <pubDate>Tue, 25 Feb 2025 07:57:20 GMT</pubDate>
    </item>
    <item>
      <title>[d]为GRPO设计奖励功能：超越单人答案任务到长形响应？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixj59s/d_designing_a_reward_function_for_grpo_moving/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿 r/machinelearning ！！ p&gt; 我一直在用GRPO微调一个小的LLM，以完成单个正确答案的任务（例如，诸如求解3x + 5 = 20的数学问题）。在这里，我使用了一个直接的奖励功能： 如果最终答案与地面真相相匹配，则为0。这效果很好，但是现在我坚持将其推广到其他域中的开放式，长格式的问题，而没有单一的“正确”。回答。  在这种情况下，设计奖励的鲁棒策略是什么？   我已经研究了BertScore和LLM-AS-A-Gudge等指标（例如GPT-4评分相干），但我不确定如何平衡自动指标与潜在偏见。    纸张，工具或实验中的课程将不胜感激！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aadityaura     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixj59s/d_designing_a_reward_function_for_grpo_moving/</guid>
      <pubDate>Tue, 25 Feb 2025 01:34:34 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iwdbgs/d_simple_questions_thread/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 23 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      对于那些寻找工作的人请使用此模板  &lt; p&gt;想要被录用：[位置]，薪水期望：[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简短概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，这个社区是适合有经验的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>