<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Sun, 18 Aug 2024 06:20:00 GMT</lastBuildDate>
    <item>
      <title>[P] 我仅使用 Python 和 NumPy 从头创建了一个 K-Means</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ev2jrj/p_ive_created_a_kmeans_from_scratch_using_only/</link>
      <description><![CDATA[  由    /u/vanstrouble  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ev2jrj/p_ive_created_a_kmeans_from_scratch_using_only/</guid>
      <pubDate>Sun, 18 Aug 2024 06:17:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我陷入了动手机器学习端到端项目的困境。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ev20x9/d_i_am_stuck_on_endtoend_project_of_handson/</link>
      <description><![CDATA[我已经开始学习机器学习。我买了 Aurelien Geron 的《动手机器学习》这本书。我正在阅读“特征缩放和转换”主题中的第 2 章“端到端项目”。事情变得有点无聊，我应该跳到第 3 章分类。    提交人    /u/Intrepid-Papaya-2209   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ev20x9/d_i_am_stuck_on_endtoend_project_of_handson/</guid>
      <pubDate>Sun, 18 Aug 2024 05:44:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 可以训练 ML 模型来为歌曲中的不同乐器写乐谱吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ev08h9/p_can_a_ml_model_be_trained_to_write_a_score_for/</link>
      <description><![CDATA[我正在尝试学习如何演奏某些乐器，但并不总是能轻易找到某首歌曲的乐谱。我想知道 ML 模型是否可以做到这一点。如果可以，您能解释一下怎么做吗？我很乐意将其作为一个副项目来开展。    提交人    /u/yulaicesar   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ev08h9/p_can_a_ml_model_be_trained_to_write_a_score_for/</guid>
      <pubDate>Sun, 18 Aug 2024 03:56:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 18 Aug 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您是否知道有任何机构/非营利组织/公司/政府/等尝试应用深度学习和其他 ML/AI/GenAI 技术来实现全民基本收入（UBI）或类似于 UBI 的东西，例如全民基本服务？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eusv1c/d_do_you_know_any/</link>
      <description><![CDATA[您是否知道任何机构/非营利组织/公司/政府/等。尝试应用深度学习和其他 ML/AI/GenAI 技术来实现全民基本收入 (UBI) 或类似于 UBI 的东西，例如全民基本服务？也许是聊天机器人指导 UBI 计划细节，选择最需要它的候选人，预测贫困、UBI 影响、人口和经济指标以确定不同人口群体的最佳 UBI 支付金额和频率，防止欺诈等。它可以只是在理论上勾勒未来的模型，也可以已经在实践中实施它。  我发现了这篇相关论文：数据和机器学习能否改变基本收入模式的未来？贝叶斯信念网络方法。 https://www.mdpi.com/2306-5729/9/2/18 &quot;呼吁政府实施基本收入的呼声是当代的。基本收入概念的理论背景仅规定向个人转移相等的金额，而不论其具体属性如何。然而，世界各地最新的基本收入计划都与家庭属性有关的某些规则有关。这种方法在适当识别弱势群体方面面临着重大挑战。制定与家庭福利属性有关的规则的一种可能替代方案是采用可以处理空前大量数据的人工智能算法。整合机器学习能否通过预测未来易受贫困影响的家庭来改变基本收入的未来？在本文中，我们利用由一百五十万个人组成的多维纵向福利数据和贝叶斯信念网络方法来检验基于现有家庭福利属性预测家庭未来贫困脆弱性的可行性。”    提交人    /u/Happysedits   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eusv1c/d_do_you_know_any/</guid>
      <pubDate>Sat, 17 Aug 2024 21:43:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何使用大型语言模型助力金融研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eurg1w/p_how_to_use_large_language_models_to_help_with/</link>
      <description><![CDATA[       由    /u/NextgenAITrading  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eurg1w/p_how_to_use_large_language_models_to_help_with/</guid>
      <pubDate>Sat, 17 Aug 2024 20:40:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 呼吁中级 RL 人员 - 您希望存在的视频/教程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euk7jh/d_call_to_intermediate_rl_people_videostutorials/</link>
      <description><![CDATA[我正在考虑写一些博客文章/教程，可能也会以视频形式。我是一名 RL 研究人员/开发人员，所以这是我瞄准的主要主题。 我知道有很多 RL 教程。不幸的是，它们经常一遍又一遍地涵盖相同的主题。 问题是针对所有中级（甚至可能更低）RL 从业者 - 是否有任何特定主题您希望有更多关于它们的资源？ 我有很多自己的想法，特别是在我的特定领域，但我也想了解观众认为什么可能有用。因此，请放弃您希望存在但遗憾的是没有的任何教程主题！    提交人    /u/SmolLM   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euk7jh/d_call_to_intermediate_rl_people_videostutorials/</guid>
      <pubDate>Sat, 17 Aug 2024 15:21:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周及本周医疗 AI 动态：顶级研究论文/模型 🏅（2024 年 8 月 3 日至 8 月 17 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euh5q6/d_last_this_week_in_medical_ai_top_research/</link>
      <description><![CDATA[      https://preview.redd.it/glwl05zn28jd1.png?width=1386&amp;format=png&amp;auto=webp&amp;s=782677e6cc695b2ef9d716344c2d636bdb824e93  Medical SAM 2：将医学图像分割为视频  本文介绍了 Medical SAM 2 (MedSAM-2)，这是一种基于SAM2 框架旨在推进 2D 和 3D 医学图像的分割。它通过将医学图像视为视频序列来实现这一点。   MedGraphRAG：基于图形增强的医疗 RAG  本文介绍了 MedGraphRAG，这是一个针对医疗领域量身定制的 RAG 框架，可以处理长上下文、减少幻觉并提供基于证据的反应，确保在医疗保健领域安全可靠地使用 AI。  用于医疗时间序列的多模态 LLM  本文介绍了 MedTsLLM，这是一个通用的多模态 LLM 框架，可以有效地以文本的形式集成时间序列数据和丰富的上下文信息。  ECG-FM：开放心电图基础模型  本文介绍了 ECG-FM，这是一种用于心电图 (ECG) 分析的基于开放式变压器的基础模型。利用新收集的包含超过 700k 个 ECG 的 UHN-ECG 数据集  私人和安全医疗保健 RAG   在这项工作中，研究人员引入了检索增强思维过程 (RAATP)。在获得外部知识的情况下，RAATP 将 LLM 的思维生成制定为一个多步骤决策过程。RAATP 解决了一个关键挑战：在医疗保健领域利用 LLM，同时保护敏感的患者数据。  全面的多模式医疗 AI 基准  本文提出了 GMAI-MMBench，这是通用医疗 AI 的全面基准。它由 285 个数据集构建，涵盖 39 种医学图像模式、18 个临床相关任务、18 个部门和 4 个感知粒度，采用视觉问答 (VQA) 格式。   详细查看完整线程：https://x.com/OpenlifesciAI/status/1824790439527887073    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euh5q6/d_last_this_week_in_medical_ai_top_research/</guid>
      <pubDate>Sat, 17 Aug 2024 13:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 新的 LLM 预训练和后训练范式：比较 Qwen 2、Llama 3.1、Gemma 2 和 Apple 的 FM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euh58q/p_new_llm_pretraining_and_posttraining_paradigms/</link>
      <description><![CDATA[        提交人    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euh58q/p_new_llm_pretraining_and_posttraining_paradigms/</guid>
      <pubDate>Sat, 17 Aug 2024 13:00:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Mamba 算法形状的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eub39f/d_question_about_shapes_of_mamba_algorithm/</link>
      <description><![CDATA[大家好 :) 这是 Mamba 论文 (https://arxiv.org/pdf/2312.00752) 中的 S6 算法： https://preview.redd.it/jusbz7c926jd1.png?width=890&amp;format=png&amp;auto=webp&amp;s=75cf754b3c1f7478e3c146b7ec7f373a8336cd3e 我不太理解输入相关的形状。以 C 为例。为什么它的形状是 (B,L,N)？直观地讲，由于它为序列中的每个输入标记提供了唯一的转换（选择），因此它的形状应该是 (B,L,D,N)，其中最后两个维度恰好是批次中相应标记的投影？ 如果不这样做，隐藏状态 h 将具有维度 (B,D,N)，从而可以像在 SSM 中那样更新隐藏状态和输出。这再次违反直觉，因为隐藏状态通常具有形状 (B,N)，即隐藏向量以压缩序列的过去信息。 所以我的问题是，为什么 B、C 和 Delta 的输入相关形状不是维度 (B,L,D,N) ？ 提前致谢！    提交人    /u/No_Individual_7831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eub39f/d_question_about_shapes_of_mamba_algorithm/</guid>
      <pubDate>Sat, 17 Aug 2024 06:21:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] Pytorch 的 OpenCL 后端更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euamk8/p_updates_on_opencl_backend_for_pytorch/</link>
      <description><![CDATA[我开发了用于 pytorch 的 OpenCL 后端 - 它允许在 Windows 和 Linux 上的 AMD、NVidia 和 Intel GPU 上训练您的网络。与基于 cuda/cudnn 的解决方案不同 - 它是跨平台且完全开源的。 更新：  在 pytorch 核心开发人员的帮助下，现在支持 pytorch 2.4 现在安装它很容易 - 我现在提供适用于 Linux 和 Windows 的预构建包 - 只需安装 whl 包就可以了 许多其他改进  如何使用它：  根据操作系统、python 版本和 pytorch 版本从项目页面下载 whl 文件 安装 pytorch 的 CPU 版本并安装您下载的 whl，例如 pytorch_ocl-0.1.0+torch2.4-cp310-none-linux_x86_64.whl  现在只需导入 pytorch_ocl现在您可以在 OpenCL ocl 设备上进行训练：`torch.randn(10,10,dev=&#39;ocl:2&#39;)  性能如何：虽然它不如原生 NVidia cuda 或 AMD rocm，但它仍然提供合理的性能，具体取决于平台、网络 - 通常训练约为 60-70%，推理约为 70-80%。    提交人    /u/artyombeilis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euamk8/p_updates_on_opencl_backend_for_pytorch/</guid>
      <pubDate>Sat, 17 Aug 2024 05:52:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] MAMBA 2 头部尺寸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu9ft8/r_mamba_2_head_dimension/</link>
      <description><![CDATA[我一直在阅读 MAMBA 2 论文。我认为我对 MAMBA（1？）相当熟悉，并且对 MAMBA 2 有较高的理解，但我无法理解原始论文中的 D 和 MAMBA 2 论文中的 P 之间的区别。在 MAMBA 1 中，传入张量的形状为 B、L、D。其中 D 是一些投影（我认为）。在 MAMBA 2 中，他们说 MAMBA 1 的头部维度为 1，但在 MAMBA 2 中不再如此。 他们在 MAMBA 2 中将 P 从 1 增加到 64 或其他数字。在论文中的代码片段中，似乎 P 是 D 的额外投影，使我们的传入张量为 4D、B、L、D、P。但论文的其他一些部分让我认为 P 实际上是 D 的一些划分，有点类似于您将变压器中的输入序列划分为多个头部的方式。哪一个是正确的？我应该如何解释 P？    提交人    /u/redwat3r   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu9ft8/r_mamba_2_head_dimension/</guid>
      <pubDate>Sat, 17 Aug 2024 04:39:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] HuggingFace 变形金刚——糟糕的设计？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu3auv/d_huggingface_transformers_bad_design/</link>
      <description><![CDATA[嗨， 我目前正在使用 HuggingFace 的 transformers 库。该库在加载模型时有些方便，它似乎是唯一合理的共享和加载模型的平台。但我越深入，就越困难，我感觉 api 设计得不好，存在很多严重的问题。 该库允许在不同的地方设置相同的选项，但没有记录它们如何相互作用。例如，似乎没有统一的方法来处理 EOS 等特殊令牌。人们可以在 1. 模型中、2. 标记器中和 3. 管道中设置这些令牌。我不清楚这些选项究竟是如何相互作用的，而且文档也没有提到这一点。有时参数会被忽略，而库不会就此发出警告。例如，参数“add_eos_token”在某些情况下，标记器似乎不起作用，而且我不是唯一遇到此问题的人（https://github.com/huggingface/transformers/issues/30947）。更糟糕的是，似乎确切的行为通常取决于模型，而库则假装提供统一的接口。查看源代码可以确认它们实际上根据当前加载的模型进行区分。 非常相似的观察结果涉及多线程的启动脚本，特别是：加速。我指定了核心数，但这只是被忽略了。没有通知，没有任何明显的原因。我在系统监视器中看到它仍然以单线程运行。即使是从网站上获取的样本也并不总是有效。 总之，配置设置似乎不受控制地增长。由于没有清晰的结构，并且有太多影响库的效果，因此其行为的很大一部分实际上没有记录。也可以说，它看起来有点不稳定和实验性。即使是对我有用的部分也让我担心，因为我怀疑部署后是否一切都会在另一台机器上正常工作。 有人有这样的想法吗？    提交人    /u/duffano   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu3auv/d_huggingface_transformers_bad_design/</guid>
      <pubDate>Fri, 16 Aug 2024 23:30:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 GPT-3.5 和 Haiku 在成本、延迟和准确性方面击败 GPT-4o 结构化输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etyrs8/r_beating_gpt4o_structured_output_with_gpt35_and/</link>
      <description><![CDATA[完整帖子：https://www.boundaryml.com/blog/sota-function-calling 使用 BAML，我们几乎解决了1 个 伯克利函数调用基准 (BFCL)（每个模型）（gpt-3.5+）。期待很快分享 arXiv 论文！ https://preview.redd.it/78uxa0xx5pid1.png?width=916&amp;format=png&amp;auto=webp&amp;s=f36e9c6fbb8ea1939c5406e552b0dcf0a4f6fe20 主要发现  与任何本机函数调用 API 相比，BAML 在函数调用方面更准确、更便宜。它比 OpenAI 的 FC-strict API 快 2-4 倍。 BAML 的技术与模型无关，并且可以与任何模型一起使用而无需修改（甚至是开源模型）。 gpt-3.5-turbo、gpt-4o-mini 和 claude-haiku 与 BAML 配合使用的效果几乎与具有结构化输出的 gpt4o 一样好（不到 2%） 使用 FC-strict 而不是简单的函数调用可以改进每个较旧的 OpenAI 模型，但是 gpt-4o-2024-08-06 会变得更糟  背景 到目前为止，从 LLM 获得更好结果的唯一方法是：  迅速设计使用更长更复杂的提示来训练它 训练更好的模型  BAML 的不同之处  用类似 typescript 的定义替换 JSON 模式。例如 string[] 比 {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}&gt; 更容易理解。 使用一种新颖的解析技术（Schema-Aligned Parsing）代替 JSON.parse。SAP 允许输出中出现更少的标记，而不会因 JSON 解析而出现错误。例如，即使键周围没有引号，也可以解析它。 PARALLEL-5 [ { streaming_service: &quot;Netflix&quot;, show_list: [&quot;Friends&quot;], sort_by_rating: true }, { streaming_service: &quot;Hulu&quot;, show_list: [&quot;The Office&quot;, &quot;Stranger Things&quot;], sort_by_rating: true } ]  我们使用提示 DSL（BAML）来实现这一点[2]，而没有使用 JSON 模式或任何类型的约束生成。我们还与使用“工具”API 的 OpenAI 的结构化输出进行了比较，我们称之为“FC-strict”。 对未来的思考 模型真的非常好，是一种语义理解。 模型在必须完美的事情上真的很糟糕，比如完美的 JSON、完美的 SQL、编译代码等。 我们认为，与其努力训练结构化数据的模型或在生成时约束令牌，不如将工程努力应用于稳健地处理模型输出等领域，这将带来尚未开发的价值。    提交人    /u/kacxdak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etyrs8/r_beating_gpt4o_structured_output_with_gpt35_and/</guid>
      <pubDate>Fri, 16 Aug 2024 20:15:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>