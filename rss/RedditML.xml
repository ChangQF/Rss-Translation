<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Thu, 30 May 2024 15:15:37 GMT</lastBuildDate>
    <item>
      <title>[D] LLM 对选择顺序很敏感！ - 如何运行 MMLU 基准测试？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d449tv/d_llms_are_sensitive_to_choice_order_how_to_run/</link>
      <description><![CDATA[我目前正在 LLAMA3-8B 模型上测试 MMLU 基准。 （我知道 MMLU 有缺陷，但我必须从某个地方开始。）  我注意到问题标签存在偏见。 当我切换问题选择的顺序时，我得到了不同的结果。  多篇论文支持这一观察，以下是两篇：  大型语言模型对多项选择题选项顺序的敏感性  大型语言模型不是稳健的多项选择器 ​ LLM 对问题选择的顺序很敏感。  ​ 基于这一发现，我决定将选项随机打乱 N 次，每次随机打乱执行一次推理。然后投票选出多数答案。  这种方法速度较慢，但​​能始终提供更好的结果。  ​ 以下是我的问题： - 您如何运行多项选择基准测试？您是否对选项进行了打乱？ - 我尚未尝试少样本：如果您已经尝试过少样本和问题打乱，请报告！ - 我的下一步是要求 LLM 给出开放式答案，嵌入答案和选项，然后检索最佳选择。这有意义吗？    提交人    /u/TheFrenchSavage   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d449tv/d_llms_are_sensitive_to_choice_order_how_to_run/</guid>
      <pubDate>Thu, 30 May 2024 13:38:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 帮助我们建立“百万动作数据集”来训练大型动作模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d430us/p_help_us_build_a_million_action_dataset_to_train/</link>
      <description><![CDATA[大家好， 我们正在创建一个数据集，其中包含人们在计算机上执行 100 万个操作的屏幕记录，以便我们可以训练可以控制计算机的大型动作模型。 这是以太坊 HackFS 黑客马拉松的一部分，我们正在构建机制来匿名化数据客户端并使用分散存储来存储编辑后的数据，这样数据贡献者就可以从使用数据训练的模型中受益。 已经存在 2 个可用于 LAM 训练的数据集：  WorkArena https://arxiv.org/pdf/2403.07718 WebLinx https://mcgill-nlp.github.io/weblinx/  但这两个都是非常小的数据集。 它们还包括遥测，但我们相信我们可以仅使用视频录制来训练 LAM（例如，人类如何观看 YouTube 教程并在他们的设备上重现该操作）。这看起来像特斯拉在视频上的自动驾驶，而不需要激光雷达） 我们需要帮助的是定义这个数据集中的 100 万个动作。它应该是人类使用计算机的所有方式的代表性数据集。您希望这个数据集包含什么，使您能够使用它/从事 LAM 研究？ 欢迎贡献、提问和建议！    提交人    /u/alxcnwy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d430us/p_help_us_build_a_million_action_dataset_to_train/</guid>
      <pubDate>Thu, 30 May 2024 12:37:25 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] PyData Amsterdam 2024 征集提案将于 6 月 2 日星期日截止。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d42hvh/news_pydata_amsterdam_2024_call_for_proposals/</link>
      <description><![CDATA[大家好，我们将于6 月 2 日星期日关闭征集提案门户，以便于 9 月 18 日至 20 日举行的 PyData Amsterdam 2024 会议。我们正在寻找能够吸引观众、提供宝贵见解并促进社区学习的演讲。不要错过这个在 800 多名与会者面前登台演讲的机会。请访问我们的网站 PyData Amsterdam 了解更多信息并提交演讲！    提交人    /u/PyDataAmsterdam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d42hvh/news_pydata_amsterdam_2024_call_for_proposals/</guid>
      <pubDate>Thu, 30 May 2024 12:09:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不同序列长度的度量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d40ndl/d_metrics_for_different_sequence_lengths/</link>
      <description><![CDATA[大家好，我正在使用多个不同的模型进行时间序列分析和预测。当我使用不同的序列长度训练它们以了解不同的时间依赖性时，我开始遇到一个问题。即使我针对每个不同的序列长度更改和优化模型参数，我的错误指标也开始生成不可接受的值。但是当我使用各自的缩放器运行模型时，它们的预测仍然令人满意。那么我的 Theil&#39;s_u(u1) 和 MSE 发生了什么？随着序列长度越来越大，我是否应该改变测量它们的方式？    提交人    /u/EarthRideSky   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d40ndl/d_metrics_for_different_sequence_lengths/</guid>
      <pubDate>Thu, 30 May 2024 10:16:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何准备我的第一次研究实习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d3zwqy/r_how_to_prepare_for_my_first_research_internship/</link>
      <description><![CDATA[当然，这是您的 Reddit 帖子正文的草稿！..... 无论如何，只是开个玩笑。 我很快就要开始为期 3 个月的 NLP 研究实习，并希望获得一些关于如何充分利用这个机会的建议。这是我第一次做研究，所以我有点紧张，但也很兴奋。 关于实习的一些细节： 持续时间：实习将持续 3 个月。 重点领域：我将研究大型语言模型 (LLM)，特别是检索增强生成 (RAG) 和知识图谱。 鉴于这种背景，我正在寻找任何关于如何有效地为研究项目做出贡献的提示或建议，尤其是考虑到我的经验有限。此外，您是否有任何关于如何充分利用研究实习的一般建议，尤其是对于初次实习的人？我还非常感谢任何可以提高我作为研究人员的工作效率的提示/工具。    提交人    /u/SingularityCharity   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d3zwqy/r_how_to_prepare_for_my_first_research_internship/</guid>
      <pubDate>Thu, 30 May 2024 09:25:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 了解 ML 的最新进展后，您会对 BERT 做哪些添加或更改？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d3zw0d/d_what_additions_or_changes_would_you_make_to/</link>
      <description><![CDATA[嗨！ 由于 BERT 仍然是一个广泛使用的模型。我很好奇你们会做些什么来使它保持最新状态。BERT 论文于 2018 年 10 月 11 日提交，最后修订于 2019 年 5 月 24 日在 arXiv 上。 这些想法不一定非要涉及架构，它可以是调度程序或训练集、MLM 损失、加快训练速度等。 就我个人而言，我会改变位置编码，也许我会使用 RoPE。使用 Flash Attention。 对于数据集，也许我会专注于混合，我对调度程序不太了解，但我会尝试所有 LLM 论文中的一些东西，一些能够进行持续预训练的东西。    提交人    /u/Mean-Night6324   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d3zw0d/d_what_additions_or_changes_would_you_make_to/</guid>
      <pubDate>Thu, 30 May 2024 09:24:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有公司定期讨论如何应用机器学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d3w2uy/d_are_there_companies_that_regularly_discuss_how/</link>
      <description><![CDATA[除了 OpenAI、Meta 和 Google 等常见的大公司外，我唯一知道的公司是迪士尼及其 YouTube 频道 DisneyResearchHub。我真的很喜欢他们上传的关于如何在木偶戏中使用机器学习和强化学习以及改进 CG 技术的视频。  我很想发现更多这样的频道，了解公司如何在他们感兴趣的领域使用 ML。    提交人    /u/midasp   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d3w2uy/d_are_there_companies_that_regularly_discuss_how/</guid>
      <pubDate>Thu, 30 May 2024 04:53:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习系统设计面试准备</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d3mru7/d_ml_system_design_interview_prep/</link>
      <description><![CDATA[我正处于 Meta 面试流程的现场阶段，需要开始准备我的 ML 系统设计面试。我一直在为编码部分苦苦挣扎，但在网上查找后，除了一些 YouTube 视频外，ML 系统设计问题的可用资源和示例似乎几乎不存在。有人知道有什么好的资源可以帮助准备吗？谢谢，我提前准备好了！    提交人    /u/shaicadelic   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d3mru7/d_ml_system_design_interview_prep/</guid>
      <pubDate>Wed, 29 May 2024 21:07:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您最喜欢的深度学习论文是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d3lbep/d_whats_your_alltime_favorite_deep_learning_paper/</link>
      <description><![CDATA[我正在寻找有趣的深度学习论文，尤其是关于计算机视觉任务中的架构改进。    提交人    /u/research_pie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d3lbep/d_whats_your_alltime_favorite_deep_learning_paper/</guid>
      <pubDate>Wed, 29 May 2024 20:00:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 为什么使用 Gumbel-Softmax 比仅使用 Softmax 更好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d3hadp/r_why_using_the_gumbelsoftmax_is_better_than_just/</link>
      <description><![CDATA[您好，许多论文倾向于使用 Gumbel-Softmax 函数生成概率分布，然后为该分布简单地生成一个二元掩码。我的问题是为什么 Gumbel-Softmax 比 Softmax 更好。对我来说，诀窍是在使用二元掩码时保持可微向量的梯度。谢谢！    提交人    /u/Training-Adeptness57   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d3hadp/r_why_using_the_gumbelsoftmax_is_better_than_just/</guid>
      <pubDate>Wed, 29 May 2024 17:08:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 时间序列基础模型的基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d3h5fs/d_benchmarking_foundation_models_for_time_series/</link>
      <description><![CDATA[      简介 我们提出了一个可重复的基准，比较了大规模数据集中各种模型中的不同基础时间序列模型。 我们得出结论 在准确率和推理速度方面排名第一，这些模型包括 TimesFM (谷歌)、Chronos (亚马逊)、Moirai (SalesForece) 和 Lag-LLama (Service Now)。TimeGPT-1 和 TimesFM 的表现也优于成熟的统计、机器学习和深度学习模型，推理时间与 SeasonalNaive 相当。 Chronos、Moirai 和 Lag-Llama 仍需要进一步改进，并且可能被其他经典方法超越。 该分析涵盖了来自 M-Competitions、Monash Repository 和 Wikipedia 页面浏览量等各个领域和频率的 30,000 多个独特时间序列，并对这些模型进行了稳健比较。 实证评估 本研究考虑了来自 Monash Repository、M-Competitions、Wikipedia 页面浏览量等各个领域的 30,000 多个独特时间序列，涵盖了各种时间序列频率：每月、每周、每天和每小时。我们的评估从准确性和推理时间方面比较了时间序列数据的五个基础模型。我们还对大量统计、机器学习和深度学习模型进行了比较，以提供与传统预测方法的基准。 我们在综合评估中包括以下模型：  统计：SeasonalNaive、HistoricAverage、ZeroModel、AutoARIMA、Prophet、AutoCES、AutoETS、Theta、DynamicOptimizedTheta、ADIDA、IMAPA 和 CrostonClassic。 机器学习：AutoLGBM。 深度学习：AutoTFT、AutoNHITS。 基础：Chronos、Lag-Llama、Moirai、TimeGPT、TimeGPT（长远眼界）和TimesFM。  结果 与最新的基础模型（包括 TimesFM、Chronos、Moirai 和 Lag-Llama）相比，TimeGPT-1 在准确度和推理速度方面排名第一。谷歌的 TimesFM 在准确度上排名第二，在推理速度上优于 TimeGPT-1。Amazon Chronos 在准确度上排名第三，但推理速度明显下降。Salesforces 和 ServiceNow 的模型在推理速度方面都远高于 Chronos，但在准确度方面排名较低。 可重复的实验 https://preview.redd.it/h374cfaube3d1.png?width=1798&amp;format=png&amp;auto=webp&amp;s=a2b0853ef9b9ebefb8f5977bfe11ef14c89964aa https://preview.redd.it/55qnz8mtbe3d1.png?width=2146&amp;format=png&amp;auto=webp&amp;s=7878f778fec30fa562a0422de3dc2748a6538571 https://preview.redd.it/wrfxhuxuce3d1.png?width=2086&amp;format=png&amp;auto=webp&amp;s=d6fc57495e5571d1d68871538514e25375e90d54    提交人    /u/fedegarzar   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d3h5fs/d_benchmarking_foundation_models_for_time_series/</guid>
      <pubDate>Wed, 29 May 2024 17:02:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 迈向最佳 LLM 量化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d3e2r6/r_towards_optimal_llm_quantization/</link>
      <description><![CDATA[picoLLM 压缩是一种新颖的 LLM 量化算法，它根据特定于任务的成本函数自动学习 LLM 权重内和跨 LLM 权重的最佳比特分配策略。现有技术需要固定的比特分配方案，这是不达标的。 文章：https://picovoice.ai/blog/picollm-towards-optimal-llm-quantization/ GitHub：https://github.com/Picovoice/llm-compression-benchmark    提交人    /u/alikenar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d3e2r6/r_towards_optimal_llm_quantization/</guid>
      <pubDate>Wed, 29 May 2024 14:51:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据科学家无需数据即可完成任务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d374hh/d_data_scientist_does_the_task_without_data/</link>
      <description><![CDATA[最近我被分配了一个任务，根据用户交互活动构建一个用户购买评分系统。 然而，有趣的是，我没有关于用户与产品交互的数据，所以我调查了许多方的解决方案，并使用我的假设来创建我认为适合构建预测模型的特征。当然，当我把它呈现给经理时，结果非常糟糕。我坐下来和他讨论创建模型时所需的特征定义，让我很生气的是，他仍然不知道构建评分模型需要什么样的数据。人们将如何处理这种情况？    提交人    /u/unknow_from_vietnam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d374hh/d_data_scientist_does_the_task_without_data/</guid>
      <pubDate>Wed, 29 May 2024 08:21:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于现阶段的法学硕士来说，幻觉不是比安全更重要的研究吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d329nt/d_isnt_hallucination_a_much_more_important_study/</link>
      <description><![CDATA[为什么我觉得 LLM 更强调安全性而不是幻觉？ 在现阶段，确保生成准确的信息不是最优先的吗？ 为什么在我看来并非如此    提交人    /u/xiikjuy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d329nt/d_isnt_hallucination_a_much_more_important_study/</guid>
      <pubDate>Wed, 29 May 2024 03:06:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>