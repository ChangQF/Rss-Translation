<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sat, 16 Mar 2024 15:11:42 GMT</lastBuildDate>
    <item>
      <title>[N] 4 月 1 日前，Coursera Plus 立减 100 美元</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bg84gp/n_get_100_off_coursera_plus_till_until_april_1st/</link>
      <description><![CDATA[       由   提交/u/ewan_m   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bg84gp/n_get_100_off_coursera_plus_till_until_april_1st/</guid>
      <pubDate>Sat, 16 Mar 2024 15:06:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLaMA 的具体细节：了解 LLaMA 和大型语言模型如何运行的整体方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bg61qi/p_llama_nuts_and_bolts_a_holistic_way_of/</link>
      <description><![CDATA[我很高兴地宣布，我使用 Go 开发的 LLaMA Nuts and Bolts 开源项目现已公开发布！ 您可以在我的 Github 存储库上找到它：https://github.com/adalkiran/llama-nuts-and- Bolts 通过代码和详细文档了解 LLaMA 及其组件在实践中如何运行的整体方法。 “螺母和螺栓” （实践方面而不是理论事实，纯粹的实现细节）所需的组件、基础设施和数学运算，而不使用外部依赖项或库。 目标是制作一个可以对 LLaMa 进行推理的实验项目2 7B-聊天模型完全脱离Python生态系统（使用Go语言）。在整个旅程中，我们的目标是获取知识并阐明该技术的抽象内部层。 这段旅程是一次有意重新发明轮子的旅程。在阅读文档中的旅程时，您将通过 LLaMa 模型的示例了解大型语言模型如何工作的详细信息。 如果您像我一样对 LLM（大型语言模型）如何工作感到好奇和变形金刚工作并深入研究了来源中的概念解释和示意图，但渴望更深入的理解，那么这个项目也非常适合您！ 您不仅会发现 LLaMa 架构的细节，而且还会发现在文档目录中查找各种相关概念的解释。从逐字节读取 Pickle、PyTorch 模型、Protobuf 和 SentencePiece 分词器模型文件，到 BFloat16 数据类型的内部结构、从头开始实现 Tensor 结构和包括线性代数计算在内的数学运算。 这个项目最初是为了通过运行和调试来了解 LLM 背后的作用，并且仅用于实验和教育目的，而不是用于生产用途。 如果您查看它，我会很高兴欢迎评论！   由   提交 /u/adalkiran   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bg61qi/p_llama_nuts_and_bolts_a_holistic_way_of/</guid>
      <pubDate>Sat, 16 Mar 2024 13:25:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 这些数据集有什么不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bg44d8/r_what_is_different_between_these_datasets/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.05652 摘要：  机器学习模型的性能在很大程度上取决于输入的质量数据，但现实世界的应用程序经常遇到各种与数据相关的挑战。当在现实世界中管理训练数据或部署模型时，可能会出现这样的挑战 - 同一领域中的两个可比较的数据集可能具有不同的分布。尽管存在多种检测分布变化的技术，但文献缺乏以人类可理解的方式解释数据集差异的综合方法。为了解决这一差距，我们提出了一套可解释的方法（工具箱）来比较两个数据集。我们展示了我们的方法在不同数据模式中的多功能性，包括低维和高维设置中的表格数据、语言、图像和信号。我们的方法不仅在解释质量和正确性方面优于可比较和相关的方法，而且还提供了可操作的补充见解，以有效地理解和减轻数据集差异。  &lt;!-- SC_ON - -&gt;  由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bg44d8/r_what_is_different_between_these_datasets/</guid>
      <pubDate>Sat, 16 Mar 2024 11:38:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] RepoHyper：存储库级代码完成所需的只是更好的上下文检索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bg396m/r_repohyper_better_context_retrieval_is_all_you/</link>
      <description><![CDATA[我们引入了 RepoHyper，这是一个新颖的框架，可将代码完成转换为现实世界存储库用例的无缝端到端流程。传统方法依赖于将上下文集成到代码语言模型 (CodeLLM) 中，通常假设这些上下文本质上是准确的。然而，我们发现了一个差距：标准基准测试并不总是提供相关的上下文。 为了解决这个问题，RepoHyper 提出了三个新颖的步骤：  构建代码属性图，建立丰富的上下文源。 一种新颖的搜索算法，用于查明所需的确切上下文。 扩展算法，旨在揭示代码元素之间的微妙联系（类似于社交网络挖掘中的链接预测问题）。  我们的综合评估表明，RepoHyper 树立了新标准，在 RepoBench 基准测试中优于其他强大的基准。 代码：https://github.com/FSoft-AI4Code/RepoHyper   由   提交/u/FSoft_AIC   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bg396m/r_repohyper_better_context_retrieval_is_all_you/</guid>
      <pubDate>Sat, 16 Mar 2024 10:41:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对报告的测试集结果达成共识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bg38fh/r_consensus_on_reported_test_set_results/</link>
      <description><![CDATA[您好，关于如何获取测试集结果有什么共识？您通常会在每个时期在测试集上评估您的模型，然后选择获得的最高准确度吗？ 假设我想计算一个置信区间。我是否应该重新运行训练 X 次（使用不同的随机种子），从每次运行中选择最高的准确度，然后使用这些 (X) 准确度进行统计分析？或者使用引导程序？ 我的训练在计算上并不太昂贵，所以我可以负担大约 10 次训练运行。但这足以进行任何有意义的统计分析吗？ 我知道“最佳”值是多少？不是在训练期间评估测试集，而是评估验证集。但由于社区是 SOTA 驱动的，在我看来，这在实践中从未做过（即使在顶级会议上）。 作为参考，我使用 ScanObjectNN、ModelNet40 和 S3DIS 等数据集我（未来）的目标是在像 NeurIPS 这样的会议上发表文章。   由   提交/u/No-Attitude667   /u/No-Attitude667 reddit.com/r/MachineLearning/comments/1bg38fh/r_consensus_on_reported_test_set_results/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bg38fh/r_consensus_on_reported_test_set_results/</guid>
      <pubDate>Sat, 16 Mar 2024 10:40:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] AnyGPT：具有离散序列建模的统一多模态法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bg2x83/r_anygpt_unified_multimodal_llm_with_discrete/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.12226 代码：https://github .com/OpenMOSS/AnyGPT 数据集：https:// Huggingface.co/datasets/fnlp/AnyInstruct 项目页面：https://junzhan2000.github.io/AnyGPT.github.io/ 视频：https://www.youtube.com/watch?v=oW3E3pIsaRg 摘要：  我们介绍 AnyGPT，这是一种任意多模态语言模型，它利用离散表示来统一处理各种模态，包括语音、文本、图像和音乐。 AnyGPT 可以稳定地训练，而不需要对当前的大语言模型（LLM）架构或训练范式进行任何改变。相反，它完全依赖于数据级预处理，促进新模式无缝集成到法学硕士中，类似于新语言的合并。我们构建了一个以文本为中心的多模态数据集，用于多模态对齐预训练。利用生成模型，我们合成了第一个大规模任意对任意多模式指令数据集。它由 108k 个多轮对话样本组成，这些对话错综复杂地交织着各种模态，从而使模型能够处理多模态输入和输出的任意组合。实验结果表明，AnyGPT 能够促进任意对任意的多模态对话，同时在所有模态中实现与专用模型相当的性能，证明离散表示可以有效且方便地统一语言模型中的多种模态。演示显示在 此 https URL    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bg2x83/r_anygpt_unified_multimodal_llm_with_discrete/</guid>
      <pubDate>Sat, 16 Mar 2024 10:18:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML 中的函数式编程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bfu3oy/d_functional_programming_in_ml/</link>
      <description><![CDATA[我觉得 Python 中的大多数 ML 库都是用 OOP 风格编写的。这是有道理的，因为 Python 没有像 Haskell 这样的“好”类型系统，因此类是用可读名称定义接口的好方法。其他功能更强大的语言是否有流行的 ML 库？我特别想到 Haskell、Rust 或 Scala。   由   提交 /u/LengthinessMelodic67   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bfu3oy/d_functional_programming_in_ml/</guid>
      <pubDate>Sat, 16 Mar 2024 01:15:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] AutoDev：自动化 AI 驱动开发 - Microsoft 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bfolev/r_autodev_automated_aidriven_development/</link>
      <description><![CDATA[      论文：https://arxiv.org /abs/2403.08299 抱歉发布了错误的 github 链接。遗憾的是真正的代码尚未公开！感谢所有向我指出这一点的人！ Github 包含代码 + AutoDev 编码器模型： https://github.com/unit-mesh/auto-dev 摘要：  随着人工智能助手的出现，软件开发的格局发生了范式转变，GitHub Copilot 就是一个例子。然而，现有的解决方案并没有利用 IDE 中可用的所有潜在功能，例如构建、测试、执行代码、git 操作等。因此，它们受到其有限功能的限制，主要侧重于在 IDE 中建议代码片段和文件操作。基于聊天的界面。为了填补这一空白，我们推出了AutoDev，这是一个完全自动化的人工智能驱动的软件开发框架，专为自主规划和执行复杂的软件工程任务而设计。 AutoDev 使用户能够定义复杂的软件工程目标，并将这些目标分配给 AutoDev 的自主 AI 代理来实现。 这些人工智能代理可以在代码库上执行各种操作，包括文件编辑、检索、构建过程、执行、测试和 git 操作。他们还可以访问文件、编译器输出、构建和测试日志、静态分析工具等。这使得 AI 代理能够以完全自动化的方式执行任务并具有全面的理解所需的上下文信息。此外，AutoDev 通过将所有操作限制在 Docker 容器内来建立安全的开发环境。该框架包含护栏以确保用户隐私和文件安全，允许用户在 AutoDev 中定义特定允许或限制的命令和操作。在我们的评估中，我们在 HumanEval 数据集上测试了 AutoDev，在代码生成和测试生成方面分别获得了 91.5% 和 87.8% 的 Pass@1 良好结果，展示了其在自动化软件工程任务方面的有效性，同时保持安全且用户控制的开发环境。  https://preview.redd.it/5nxqajnvbkoc1.jpg?width=924&amp;format=pjpg&amp;auto=webp&amp;s=8343c5fb33d2914bbfbf2dd9c164b5970b97 43ab https://preview.redd.it/z5fkkjnvbkoc1.jpg?width=1364&amp;格式=pjpg&amp;auto=webp&amp;s=bc434ff384d2ed67ea0382dbbb68b9a90313cd44   由   提交/u/Singularian2501   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bfolev/r_autodev_automated_aidriven_development/</guid>
      <pubDate>Fri, 15 Mar 2024 21:09:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] 转载MetaAI的《自我奖励语言模型》论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bfnz2l/p_reproducing_the_selfrewarding_language_models/</link>
      <description><![CDATA[大家好， 读完 Meta 团队的《自我奖励语言模型》论文后，感觉非常平易近人且可重现，所以我们花了一些时间来实现它。 ​ 提供的脚本采用任何基本模型并将其放入循环中： 1 ）对初始数据集进行监督微调 2）使用 SFT 生成新提示 3）每个提示生成 N 个响应 4）对生成的结果进行评分响应 1-5 5) 对模型本身的奖励运行 DPO。 ​ 我们已经通过一个循环运行它，从开始使用 Mistral-7b 基础模型，到目前为止结果非常令人鼓舞。  ​ 请随意检查或亲自运行它，并让我们知道您的想法： https://github.com/Oxen-AI/Self-Rewarding-Language-Models   由   提交 /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bfnz2l/p_reproducing_the_selfrewarding_language_models/</guid>
      <pubDate>Fri, 15 Mar 2024 20:42:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从无约束模型进行约束推理有哪些选择？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bfmq74/d_what_are_my_options_for_doing_constrained/</link>
      <description><![CDATA[我想训练一个模型来预测动作轨迹的可能性。我的训练数据集允许执行我在推理时无法访问的操作。我想推断动作空间中凸约束集内最可能的动作轨迹（每个动作时间步的约束都是相同的）。关于如何处理这个问题有什么建议吗？到目前为止，我的想法是 LLMS 中流行的约束束搜索。我也在考虑约束扩散，但由于没有直接的概率项，并且凸边缘可能会引起局部最小值，所以我不确定这是否可行。如果我错了，请纠正我，但是一旦你限制了政策输出，你现在就必须多次推断并比较它们的相对可能性，对吗？    由   提交/u/jms4607  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bfmq74/d_what_are_my_options_for_doing_constrained/</guid>
      <pubDate>Fri, 15 Mar 2024 19:49:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 类似于 distill.pub 的博客？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bfml1x/d_blogs_similar_to_distillpub/</link>
      <description><![CDATA[大家好，我是distill.pub的忠实粉丝并且经常发现自己会重新访问他们的一些帖子，即使是在它们中断之后。他们的文章制作精美，通常通过视觉手段直观地解释概念。我很好奇您是否会推荐任何其他类似于 distill.pub 的博客或网站？   由   提交 /u/JellyBean_Collector   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bfml1x/d_blogs_similar_to_distillpub/</guid>
      <pubDate>Fri, 15 Mar 2024 19:43:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] Quiet-STAR：语言模型可以在说话之前自学思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bfbseq/r_quietstar_language_models_can_teach_themselves/</link>
      <description><![CDATA[ 由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bfbseq/r_quietstar_language_models_can_teach_themselves/</guid>
      <pubDate>Fri, 15 Mar 2024 11:31:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 构建 ML 系统与项目。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bf9lms/d_building_a_ml_system_vs_project/</link>
      <description><![CDATA[我个人将时间花在传统软件工程师和机器学习上。 每次我构建或研究模型时我的强迫症开始出现，笔记本、脚本、没有真正的抽象等等。所有的机器学习代码感觉都可能被扔掉，直到它起作用为止，那时我最好保留从垃圾代码创建的模型。 &lt; p&gt;在过去阅读并提出问题后，我认为我们很多人都遭受过这种痛苦，是的，有一些最佳实践，但 ML 项目似乎更多地使用 VS 一款长寿的软件。 所以我想讨论的是，人们是否考虑过以与软件相同的方式构建他们的机器学习系统？例如，每个模型都有一个路线，每个报告都有一个 UI 视图。用户可以登录并使用系统的每个功能，并且已经过测试！ 想法？ 如果有人在任何参考之前看到过这个概念，那就太棒了！！   由   提交/u/Suspicious_Dress_350   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bf9lms/d_building_a_ml_system_vs_project/</guid>
      <pubDate>Fri, 15 Mar 2024 09:05:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些编写良好的 ML 代码库可供参考，以获取优秀 ML 软件设计的灵感？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bf85rj/d_what_are_some_wellwritten_ml_codebases_to_refer/</link>
      <description><![CDATA[您将哪些公开可用的机器学习项目作为优秀机器学习软件设计的示例？我指的是抽象模型/数据集/度量类的定义方式、基于该设计添加新功能的难易程度以及使用它们的整体体验等方面。 例如，我相信 scikit-learn 是良好设计的一个例子。即使对于新手来说，拟合/预测范式也非常容易理解。  大多数现代项目似乎都在使用配置驱动的动态对象初始化，我也很欣赏围绕此类设计的良好实践的资源。这种设计的一些例子是 Huggingface 和基于 Hydra 的实验代码库。 作者解释其设计理念的帖子链接也会有所帮助。例如，huggingface 的理念是“重复自己”，而不是“不要重复自己”。 它也有助于列出要避免的库。 谢谢！&lt; /p&gt;   由   提交/u/unused_MLE   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bf85rj/d_what_are_some_wellwritten_ml_codebases_to_refer/</guid>
      <pubDate>Fri, 15 Mar 2024 07:16:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>