<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 29 Jan 2025 06:23:09 GMT</lastBuildDate>
    <item>
      <title>[D] 寻找有关领域适应方法的[现代]技巧，因为没有能力注释目标领域（图像数据）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icn2je/d_looking_for_modern_tips_on_domain_adaption/</link>
      <description><![CDATA[我基本上是想听听对于具有类似限制的人有用的方法，我可以生成任务的合成数据，但注释真实数据（需要许多传感器的回归任务）是一项非常昂贵的任务，并且由于设置条件甚至可能不切实际。 我正在考虑使用对抗训练作为架构的一部分，编码器有两个头，一个用于目标任务，一个用于对图像的域（合成域与目标域）进行分类，我们尝试最大化后者的损失，目标是让编码器提取用于计算目标的最小非不变特征。 但这感觉已经过时了，也许很挑剔，所以我想知道你们是否可以分享你们的经验。    提交人    /u/StillWastingAway   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icn2je/d_looking_for_modern_tips_on_domain_adaption/</guid>
      <pubDate>Wed, 29 Jan 2025 05:49:23 GMT</pubDate>
    </item>
    <item>
      <title>Faceswap、Deepfake 实时——最佳框架 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icmoa8/faceswap_deepfake_realtime_best_frameworks_p/</link>
      <description><![CDATA[你好！我正在寻找最佳框架来进行实时换脸（例如在 Zoom 会议中）。这（真的）是一个研究项目。我想看看在求职面试中，少数群体的评分有何不同。有人能给我指一个吗？我试图联系 pickle.ai，但这家初创公司目前反应不太灵敏。  希望有人能帮忙。     提交人    /u/Standing_Appa8   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icmoa8/faceswap_deepfake_realtime_best_frameworks_p/</guid>
      <pubDate>Wed, 29 Jan 2025 05:24:56 GMT</pubDate>
    </item>
    <item>
      <title>检索增强生成中的规模与智能权衡 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ick63j/the_scale_vs_intelligence_tradeoff_in_retrieval/</link>
      <description><![CDATA[      检索增强生成 (RAG) 在过去一两年中发展迅猛，它为 LLM 提供了有关特定文档集或整个世界的知识。我个人已经广泛使用过大多数 RAG 类型，几乎所有 RAG 类型都基于两种基本算法（长上下文和嵌入）构建，但这两种算法存在一些基本限制。我计划就此写一篇更长、更全面的文章，但我想先在这里提出一些想法，以获得一些反馈，看看我是否遗漏了哪些观点。 长上下文模型（例如 Gemini）旨在处理单个上下文窗口内的大量文本，但面临着训练数据稀缺的关键瓶颈。随着上下文长度的增加，高质量训练数据的可用性迅速减少。这很重要，因为神经缩放定律到目前为止对 LLM 来说非常稳健。这里有一个很棒的视频解释它们。一个重要的含义是，如果你用完了人工生成的训练数据，那么无论你为这个问题投入多少其他资源或技巧，你的模型的推理能力都会受到瓶颈限制。这篇论文为这个想法提供了一些很好的实证支持。在所有“长上下文”模型的推理能力会随着上下文长度的增加而急剧下降。 我根据论文中的一个主要表格生成的图表，展示了随着上下文长度的增加，推理能力如何下降。 基于嵌入的 RAG 具有更好的可扩展性，但在高级推理任务中存在一些相当严重的问题。以下是这篇论文的一个小清单： https://preview.redd.it/huig4ipulufe1.png?width=967&amp;format=png&amp;auto=webp&amp;s=62743d60ba1c9162c9e1bf5ff6d05af20d577868 作者在论文开头也对核心原因进行了很好的阐述：   这种结构限制在处理需要深入理解和上下文解释的文档（例如复杂的书籍）时尤其成问题。通常，每个文档不仅会有一个重要的内部结构，而且跨文档还会有一个重要的元结构（想想引用其他科学论文特定部分的科学论文）。有一些技巧，例如使用知识图谱，可以尝试解决其中一些问题，但当基本方法在任何次要步骤开始之前就破坏了文档可能具有的任何结构时，它们只能做到这么多。  长上下文的可扩展性限制和嵌入的推理限制导致任何构建 RAG 系统的人都需要进行重要的权衡。长上下文模型在创造力和复杂推理方面表现出色，但由于训练数据限制，仅限于小型文档集。相反，基于嵌入的方法可以处理庞大的语料库，但功能更像是具有最低限度推理能力的增强型搜索引擎。对于许多任务来说，这种权衡是可以的，因为任务已经很好地适应了权衡的一方或另一方。然而，许多其他任务根本无法通过 SoTA RAG 方法轻松实现，因为它们既需要大量文档，又需要对这些文档进行高级推理。    提交人    /u/Daniel_Van_Zant   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ick63j/the_scale_vs_intelligence_tradeoff_in_retrieval/</guid>
      <pubDate>Wed, 29 Jan 2025 03:04:35 GMT</pubDate>
    </item>
    <item>
      <title>Apple AIML 驻留计划 2025 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icj0tb/apple_aiml_residency_program_2025_d/</link>
      <description><![CDATA[大家好！ 想知道收到第一轮面试邀请的人是否想联系？    提交人    /u/PushOld6080   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icj0tb/apple_aiml_residency_program_2025_d/</guid>
      <pubDate>Wed, 29 Jan 2025 02:05:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepSeek 蒸馏和训练成本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icfbll/d_deepseek_distillation_and_training_costs/</link>
      <description><![CDATA[DeepSeek v3 训练中使用了蒸馏技术 (https://arxiv.org/html/2412.19437v1)。560 万美元仅仅是训练“学生”模型的成本吗？我并没有低估这一成就本身。但是，我想了解训练教师模型的成本是否已计入 560 万美元。 如果不考虑这些成本，虽然 DeepSeek 为降低成本和工程做出了重要贡献，但主流媒体散布的数字并不完全一致，需要进行纠正。或者也许我误解了整件事。 感谢您对此提供的任何见解。     由   提交  /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icfbll/d_deepseek_distillation_and_training_costs/</guid>
      <pubDate>Tue, 28 Jan 2025 23:13:12 GMT</pubDate>
    </item>
    <item>
      <title>[p] 让人们可以使用免费的 GPU - 希望得到 Beta 版反馈🦾</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icepak/p_giving_ppl_access_to_free_gpus_would_love_beta/</link>
      <description><![CDATA[大家好！我是一家 YC 投资公司的创始人，我们正努力让 ML 模型的训练变得非常便宜和简单。目前，我们正在运行一个免费测试版，希望得到您的一些反馈。 如果听起来很有趣，请随时在这里查看：https://github.com/tensorpool/tensorpool TLDR；免费计算😂    提交人    /u/joshkmartinez   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icepak/p_giving_ppl_access_to_free_gpus_would_love_beta/</guid>
      <pubDate>Tue, 28 Jan 2025 22:45:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你的秘诀是什么？你如何管理基础设施中的 GPU 容量？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icc8fb/d_whats_your_secret_sauce_how_do_you_manage_gpu/</link>
      <description><![CDATA[好的……我正在努力弄清楚资源管理的状态。我们这里有多少人有一堆闲置的 GPU 就放在那里，因为 Oracle 给了我们一笔交易，他们想阻止我们使用 AWS？或者这里的大多数人仍在使用 RunPod 或其他 neocloud/聚合器？据我所见，这些 neocloud 非常适合 MVP/POC 阶段开发，但不适用于生产。 但实际上，这里的每个人都只是购买额外的容量以避免延迟吗？随着推理工作负载开始扩展，是否有人开始对飞涨的计算成本感到恐慌？然后呢？    提交人    /u/PurpleReign007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icc8fb/d_whats_your_secret_sauce_how_do_you_manage_gpu/</guid>
      <pubDate>Tue, 28 Jan 2025 21:02:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] AMD iGPU 上的 Tensorflow</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icb023/r_tensorflow_on_amd_igpus/</link>
      <description><![CDATA[有没有办法在 AMD Vega iGPU 上运行 TensorFlow？TensorFlow 仅在 CUDA 机器上受支持，因此我无法使用它。ROCm 不支持 iGPU。我知道我可以改用 Google Colab，但我希望在本地运行它。我的笔记本电脑有 Ryzen 5 7530U，内存为 16 GB，可双启动 Windows 11 和 Ubuntu 22.04 LTS。    提交人    /u/Life_Low_682   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icb023/r_tensorflow_on_amd_igpus/</guid>
      <pubDate>Tue, 28 Jan 2025 20:11:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 从知识图谱中查询数据的挑战</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ic5q7s/d_challenges_in_querying_data_from_a_knowledge/</link>
      <description><![CDATA[我一直在探索开发知识图谱来处理轮胎添加剂周围的数据，旨在从相关文本中提取有意义的实体和关系。我的主要目标是解决涉及满足多个约束的复杂查询，即使信息源自从不同来源提取的关系（例如，两篇独立的研究论文）。 此外，我还希望提取见解，例如某些添加剂的潜在替代材料。 我特别努力的一个领域是如何有效地处理用户查询。例如，我应该依靠 Cypher 查询来实现精度，以及我应该如何理想地构建和排列知识图中的节点以实现可扩展性和清晰度？ 目前，我正在请求 LLM 提取这种肿瘤学 您是轮胎化学专家 AI，可以从有关轮胎添加剂的文本中提取精确的实体和关系。请遵循以下规则： 允许的实体类型： 1. 轮胎添加剂：例如炭黑、二氧化硅、硫磺。 2. 轮胎特性：例如牵引力、耐久性、柔韧性。 3. 添加剂类别：例如填料、固化剂、抗氧化剂、抗臭氧剂。 4. 轮胎应用：例如赛车轮胎、越野轮胎。 5. 相互作用：添加剂之间的协同作用或拮抗作用。 允许的具有方向性的关系类型：  1. **增强** (添加剂 → 轮胎特性)  2. **减少** (添加剂 → 轮胎属性)  3. **协同** (添加剂 → 添加剂)  4. **对抗** (添加剂 → 添加剂)  5. **属于** (添加剂 → 添加剂类别)  6. **需要** (应用程序 → 轮胎属性)  7. **类似于** (添加剂或属性 → 添加剂或属性)  8. **矛盾** (添加剂或属性 → 添加剂或属性)  9. **用于** (添加剂或类别 → 应用程序)    由    /u/OnlyBadKarma  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ic5q7s/d_challenges_in_querying_data_from_a_knowledge/</guid>
      <pubDate>Tue, 28 Jan 2025 16:39:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有感觉自己在每个 scikit-learn 项目中都在重新发明轮子？让我们来谈谈如何让 ML 推荐做法不那么痛苦。🤔</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ic5e7f/d_ever_feel_like_youre_reinventing_the_wheel_with/</link>
      <description><![CDATA[嗨，各位数据科学家， 虽然 scikit-learn 功能强大，但我们经常会发现：  手动检查交叉验证错误 在 Copilot、StackOverflow 和文档之间来回切换只是为了遵循推荐的做法 重新设计需要为 DS 团队和利益相关者服务的验证流程 笔记本成为模型迭代的坟墓  我很好奇您如何在工作流程中应对这些挑战：  您在不同项目之间进行验证的方法是什么？是否有统一的方法，还是每个项目都有自己的验证风格？ 如何在不使事情过于复杂的情况下跟踪实验？ 您发现了哪些保持一致性的技巧？  我们（可能）已经构建了一个开源库（skore）来解决这些问题，但我希望先听听您的解决方案。哪些工作流程对您有用？什么仍然令人沮丧？  GitHub：github.com/probabl-ai/skore 文档：skore.probabl.ai     提交人    /u/positive-correlation   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ic5e7f/d_ever_feel_like_youre_reinventing_the_wheel_with/</guid>
      <pubDate>Tue, 28 Jan 2025 16:24:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 多类文本分类的最佳模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ic49q4/p_best_model_for_multi_class_text_classification/</link>
      <description><![CDATA[嗨！ 对于一个大学项目，我需要将电视辩论中的陈述分为 5 个类别（为简单起见，我们假设这些类别为 1 到 5）。 我有一个大型标记数据集来训练模型，现在我正在使用 transformer nn，但结果很糟糕。 话虽如此，对于这样的任务我应该测试哪些模型？ 感谢任何帮助 :)    提交人    /u/Admirable-Proof3214   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ic49q4/p_best_model_for_multi_class_text_classification/</guid>
      <pubDate>Tue, 28 Jan 2025 15:36:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] Deepseek R1 究竟是如何大幅降低训练成本的？我读到的大多数帖子都是关于它的性能、强化学习、思路链等，但不清楚模型训练成本是如何大幅降低的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibijhg/d_how_exactly_did_deepseek_r1_achieve_massive/</link>
      <description><![CDATA[  由    /u/eyio  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibijhg/d_how_exactly_did_deepseek_r1_achieve_massive/</guid>
      <pubDate>Mon, 27 Jan 2025 20:02:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepSeek 为什么开源他们的工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/</link>
      <description><![CDATA[如果他们的培训效率提高 45 倍，他们本可以主宰 LLM 市场。你认为他们为什么选择开源他们的工作？这对他们的公司有什么好处？现在美国的大型实验室可以说：“我们将采用他们的优秀想法，并将它们与我们的秘密想法结合起来，我们仍然会领先”  编辑： DeepSeek-R1 现在在 LLM 领域排名第一（使用 StyleCtrl）。它们与其他 3 个模型共享此排名：Gemini-Exp-1206、4o-latest 和 o1-2024-12-17。    提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/</guid>
      <pubDate>Mon, 27 Jan 2025 07:48:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>