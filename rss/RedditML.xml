<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 22 Dec 2023 06:17:36 GMT</lastBuildDate>
    <item>
      <title>[D] Pycharm 与 Google Drive（用于 ML 项目）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18o89yr/d_pycharm_with_google_drive_for_ml_project/</link>
      <description><![CDATA[嗨 我打算使用 Colab，但是在 Colab 中编码（以文件夹格式）是一件很痛苦的事情。我打算在本地安装 Pycharm，然后与 google 驱动器自动部署（同步）。这有多困难？   由   提交 /u/Even_Campaign7385   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18o89yr/d_pycharm_with_google_drive_for_ml_project/</guid>
      <pubDate>Fri, 22 Dec 2023 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 不使用内部运行或状态监测数据的预测性维护</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18o1i7c/research_predictive_maintenance_without_using/</link>
      <description><![CDATA[自动气象站就是这种情况。在互联网上找不到气象站故障的任何历史数据集都没有运气。只是天气观测数据集。如何对气象站进行预测性维护？ 我需要这个来进行我们当地气象服务的研究。   由   提交 /u/Funny_Shoe1772   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18o1i7c/research_predictive_maintenance_without_using/</guid>
      <pubDate>Fri, 22 Dec 2023 00:12:29 GMT</pubDate>
    </item>
    <item>
      <title>用于存储 ML 模型数据的 NAS 或服务器 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18o0rrw/nas_or_server_for_storing_data_for_ml_models/</link>
      <description><![CDATA[免责声明：在 ML 方面，我非常业余。 我目前正在致力于构建基于 CNN 的分类模型（python/pytorch）使用大型成像文件（准确地说是数字化组织学幻灯片）。每个文件至少有 1 GB，我正在数千个文件上训练模型（目前总计约 4 TB）。我目前正在使用我的台式电脑（Windows 11、128 RAM、intel i9-12900K CPU、NVIDIA 3090ti GPU、驱动器之间的总存储量为 14 TB）。 我计划大幅增加训练量我将要处理的数据，因此我需要扩展我的存储能力并确保数据安全和备份。将来我可能想添加更多 GPU 来训练更大的模型（我不知道这将如何与 NAS 和服务器配合使用）。 您认为实现这一目标的最佳方法是什么？我与一位同事交谈过，他使用 Synology NAS 来实现非常相似的目的，因此我正在考虑使用 Synology NAS（可能是 DS423+ 或 DS923+）。 如有任何帮助，我们将不胜感激。 &lt; !-- SC_ON --&gt;  由   提交/u/V--------   &lt; a href=&quot;https://www.reddit.com/r/MachineLearning/comments/18o0rrw/nas_or_server_for_storing_data_for_ml_models/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18o0rrw/nas_or_server_for_storing_data_for_ml_models/</guid>
      <pubDate>Thu, 21 Dec 2023 23:38:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 网页抓取法学硕士：HTML 结构分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18nxvvi/d_llm_for_web_scraper_html_structure_analysis/</link>
      <description><![CDATA[网络抓取工具的主要问题是，一旦网页更改其布局，它就会崩溃。 我想要 GPT API（当然，我希望在 2024 年用本地模型替换它）来为特定的 HTML 页面编写网络爬虫提取逻辑（bs4 或用于 Node.js 的 Cheerio）的代码。老实说，大多数“人工智能驱动的网络抓取工具”我在 2023 年市场上看到的只是华丽的登陆页面，带有响亮的文字来收集潜在客户，或者它们只能在简单的页面上运行。 据我了解，主要问题是 HTML 文档结构是一棵巨大的树（有时具有非常重要的嵌套，如果我们谈论的是真实的网页 - 例如，看看亚马逊产品页面），这会阻止您使用简单的分块算法将此 HTML 文档分割成更小的部分这样 ChatGPT 就可以有效地分析它 - 你需要整个 HTML 结构始终适合 LLM 模型的上下文窗口。另一个问题是具有 100K+ 令牌窗口的最先进的 LLM 仍然很昂贵（尽管随着时间的推移，它们将变得更加实惠）。所以我当前（简化）的方法是：  在将 HTML 传递到 GPT API 之前对其进行大量压缩 要求 GPT API 生成网络抓取代码，而不是一次又一次地将每个新网页传递到 LLM（这不符合成本效益，而且非常慢）3。自动测试网络抓取代码并要求 LLM 分析多个（类似）网页的结果。  这在我的 MVP 中与 gpt-4-1106-preview 模型一起工作（不可能）可以使用 16K 代币），但是给我可接受结果的真正工作流程比上面这 3 个步骤复杂得多，并且涉及多个 LLM 通行证和 HTML 文档分析，所以我想知道我是否在这里发明了一辆自行车。 您最近在人工智能网络抓取领域看到有趣的项目和方法吗？   由   提交/u/superjet1  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18nxvvi/d_llm_for_web_scraper_html_structure_analysis/</guid>
      <pubDate>Thu, 21 Dec 2023 21:30:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深入探讨 MMLU（“你比 LLM 更聪明吗？”）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ntia7/d_deep_dive_into_the_mmlu_are_you_smarter_than_an/</link>
      <description><![CDATA[在 MMLU 周围的所有喧嚣之后（例如 我的文章）我想我会制作一个界面来看看人类如何做，甚至是中间的LLM。它的名字叫你比法学硕士聪明吗？ &lt; p&gt;它会向您提出 MMLU 的随机问题，并将您的答案与 LLM 的答案进行比较。单击“这是什么”按钮位于底部，了解有关其工作原理的更多详细信息。 感谢反馈！   由   提交/u/brokensegue  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ntia7/d_deep_dive_into_the_mmlu_are_you_smarter_than_an/</guid>
      <pubDate>Thu, 21 Dec 2023 18:21:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 Python 脚本中使用 CogVLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ns81z/d_how_to_use_cogvlm_in_a_python_script/</link>
      <description><![CDATA[   大家好， 我正在开发一个项目，其中我需要将 CogVLM 模型集成到 Python 脚本中。我已经查看了 CogVLM GitHub 页面，但我有点不清楚开始使用它的最佳方法Python 环境。 这里有人以前使用过 CogVLM 吗？如果您能分享一些关于以下方面的见解或资源，我将不胜感激：  设置 CogVLM 以在 Python 脚本中使用。 从 Python 对 CogVLM 进行 API 调用. 任何可以提供帮助的示例代码或文档。  预先感谢您的帮助！  https://preview.redd .it/y07c4gb5no7c1.jpg?width=5874&amp;format=pjpg&amp;auto=webp&amp;s=dafbf42eeaf87f94fd5ff9bd90136464550c9c06   由   提交/u/Kakachia777   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ns81z/d_how_to_use_cogvlm_in_a_python_script/</guid>
      <pubDate>Thu, 21 Dec 2023 17:25:53 GMT</pubDate>
    </item>
    <item>
      <title>[P] 抽取器，或者如何绘制很多点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18nq5p6/p_the_decimator_or_how_to_plot_a_lot_of_points/</link>
      <description><![CDATA[抽取器是一个函数，它可以删除图中的点，同时保留所有“值/信息”。的图表。这篇文章提供了时间序列和聚类的示例。 https://www.taipy.io/posts/big-data-charting-strategies-in-python&quot;&gt;https:// /www.taipy.io/posts/big-data-charting-strategies-in-python   由   提交/u/quicklyalienated76   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18nq5p6/p_the_decimator_or_how_to_plot_a_lot_of_points/</guid>
      <pubDate>Thu, 21 Dec 2023 15:54:54 GMT</pubDate>
    </item>
    <item>
      <title>培训法学硕士的最佳方法是什么？ [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18nodpq/what_is_the_optimal_approach_when_training_llms/</link>
      <description><![CDATA[大家好， 假设您需要为一些琐碎的任务设置一个法学硕士，但使用不同的语言。例如，我有一个公平分类的法学硕士，但我希望以非英语语言生成课程。或者另一种情况，您有一个很好的特定域聊天机器人，但输入和回复必须使用另一种语言。 最合理的方法是什么：  直接用目标语言复制法学硕士  或 2）使用成熟的英语法学硕士来完成工作，然后将结果翻译成您的目标语言？ 如何在不同语言中利用特定领域模型的强大功能，而无需重做所有工作？是否有类似不同语言的迁移学习之类的东西？业界如何解决此类问题？ 提前致谢   由   提交/u/Ok-Leather-7733   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18nodpq/what_is_the_optimal_approach_when_training_llms/</guid>
      <pubDate>Thu, 21 Dec 2023 14:33:28 GMT</pubDate>
    </item>
    <item>
      <title>对X2Vec论文的看法[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18nnbkq/opinion_on_x2vec_papersd/</link>
      <description><![CDATA[对 X2Vec 论文的看法如何。这些论文在社区中是否受到好评。Atom2Vec 或 Bond2Vec 论文的影响力有多大？   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18nnbkq/opinion_on_x2vec_papersd/</guid>
      <pubDate>Thu, 21 Dec 2023 13:42:43 GMT</pubDate>
    </item>
    <item>
      <title>Meta AI 住院医师面试问题 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18nio9k/meta_ai_residency_interview_question_d/</link>
      <description><![CDATA[对我在去年的 Meta AI Residency 编码轮中遇到的这个编码问题感到好奇（之后被拒绝）。问题是关于使用 numpy 和矩阵从头开始编写卷积神经网络的代码。  我非常惊讶和困惑，因为我的大多数同行都收到了 LC Med 问题，我也期待类似的事情（特别是因为我也没有在简历中提到 CNN）。  &gt; 但是无论如何，很好奇是否有人有类似的经历/知道答案？ 谢谢！ 编辑：对于那些认为这是一个超级基本问题的人一次 AI Residency 面试，我为你感到高兴，我希望有一天能够精通它，这对我来说也是基础。但我只想指出，Meta AI 在编码轮之前举办了一个研讨会，让我们为此做好准备，并涵盖了我们应该准备哪些主题，他们说 LC Med-High 问题（甚至提到了要准备的主题，例如链接列表、二分搜索树木等），这就是我的心理准备。   由   提交 /u/Immediate-Tailor-275   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18nio9k/meta_ai_residency_interview_question_d/</guid>
      <pubDate>Thu, 21 Dec 2023 08:58:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] Emu2：类似Gemini的开源37B多模态模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ngb9b/p_emu2_a_geminilike_opensource_37b_multimodal/</link>
      <description><![CDATA[我很高兴向您介绍 Emu2，它是北京人工智能研究院 (BAAI) 开发的最新生成式多模态模型。 Emu2 是一项开源计划，体现了 BAAI 对促进开放、安全和负责任的人工智能研究的承诺。它旨在通过最少的示例和简单的指令来提高人工智能处理各种模态任务的能力。 Emu2 在少量多模态理解任务中表现出了优于 Flamingo-80B 等其他大型模型的性能。它为开发人员提供了一个多功能的基础模型，为构建专门的多模式应用程序提供了一个灵活的平台。 Emu2 的主要功能包括： - 比其前身更加简化的建模框架， Emu。 - 能够从编码器的语义空间重建图像的解码器。 - 扩展到 370 亿个参数，提高了功能和泛化能力。  BAAI 还发布了微调版本，用于视觉理解的 Emu2-Chat 和用于视觉生成的 Emu2-Gen，它们是当今最强大的开源模型之一。 以下是以下资源：有兴趣探索或为 Emu2 做出贡献的人： - 项目：https://baaivision.github.io/emu2/  - 型号：https://huggingface.co/BAAI/Emu2 - 代码：https://github.com/baaivision/Emu/tree/main/Emu2 - 演示：https://huggingface.co/spaces/BAAI/Emu2&lt; /p&gt; - 论文：https://arxiv.org/abs/2312.13286 我们欢迎您提供反馈意见，帮助我们改进。让我们合作突破多模式人工智能的界限！   由   提交/u/lukai-baai   reddit.com/r/MachineLearning/comments/18ngb9b/p_emu2_a_geminilike_opensource_37b_multimodal/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ngb9b/p_emu2_a_geminilike_opensource_37b_multimodal/</guid>
      <pubDate>Thu, 21 Dec 2023 06:21:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在 SQuAD 问答数据集上微调 Mamba 130m 的实验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18nd76d/r_experiments_finetuning_mamba_130m_on_the_squad/</link>
      <description><![CDATA[大家好，我想用 Mamba 进行一些实践，看看较小的模型在实践中效果如何。我认为回答问题是一项很好的任务，可以了解模型有多少固有知识。 TLDR ~ 我在 SQuAD 上训练了 130m Mamba 模型，模板如下 `` ` {context} ​ 问：{问题} 答：{答案} ``` 我还希望模型能够回答“我不知道”如果答案不包含在上下文中。因此，对于一半的训练数据，我将随机问题与随机上下文配对，并得到答案“我不知道”。尝试帮助消除幻觉。据说这种方法似乎相当有效，但在 SQuAD 的实践中只有 12% 的准确率。  完整的实验细节、我尝试过的所有内容以及代码都已链接。 https://blog.oxen.ai/practical-ml-dive-how-to-train-mamba-for-question-answering/&lt; /p&gt; 我在具有 24GB VRAM 的 Lambda Labs 机器上训练超过 790m 的任何内容都遇到了困难，并且在设计 2.8b 模型时也取得了一些成功。我目前正在训练 790m 模型，完成后将发布它。 还有其他人在任何现实世界任务上成功训练 Mamba 吗？  也许较大的模型更有前途，我只是没有足够的计算能力，并且认为能够在生产中运行较小的模型会更经济。 ​   由   提交 /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18nd76d/r_experiments_finetuning_mamba_130m_on_the_squad/</guid>
      <pubDate>Thu, 21 Dec 2023 03:27:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我构建了一个开放的 SotA 图像标记模型来完成 CLIP 无法完成的任务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18nb15l/p_i_built_an_open_sota_image_tagging_model_to_do/</link>
      <description><![CDATA[我是一名机器学习爱好者研究员，经过一年的工作，我终于从头开始构建了最先进的机器视觉模型。它基于 ViT-B/16，448x448x3 输入、91M 参数，针对 660M 样本进行训练，以多标签分类作为目标任务，在 5000 多个独特标签上进行。 当今所有大型基础视觉模型都是在经过严格过滤的数据集上进行训练，极大地限制了它们可以表示的概念，符合所谓“健康”的任意规则集。由领先的科技公司。从无害到辛辣的一切都在这些过滤器的砧板上。而且由于 CLIP 渗透到整个行业，从 StableDiffusion 到 LLaVA，OpenAI 的敏感性也随之增强。 我的目标是建立一个用于标记图像的视觉模型，主要用于标清微调的标记图像，但这并不像像 CLIP/BLIP/LLaVA 一样经过严格过滤和限制。更具包容性、多样化和性积极的东西。 从 SmilingWolf 的精彩作品开始 (https:/ /github.com/SmilingWolf/SW-CV-ModelZoo）和 Danbooru2021 数据集，我对模型进行了一年的迭代、训练并手动标记一千张图像，以帮助模型泛化到 danbooru 领域之外。&lt; /p&gt; 我今天发布了该模型的第一个版本，称为 JoyTag：https://github.com/fpgaminer/ Joytag 它的所有 5000 多个标签以及原始 danbooru 数据集的动漫/漫画风格图像以及照片和其他媒体的平均 F1 分数为 0.578，这要归功于我提供给它的辅助训练数据。 达到这一点是相当困难的，而且我可能花费了比任何理智的人应该花的更多的时间和金钱。我学到了很多关于处理像 danbooru2021 这样大的数据集、大规模训练模型以及如何让自己整夜保持清醒，这样你的 8xA100 租赁就不会崩溃并花光你所有的钱。 在我的手册中即使在验证集之外进行测试，该模型也可以很好地推广到未见过的图像，因此我对迄今为止的结果感到非常满意。扩展其数据集以进一步提高 F1 分数并弥补其弱点还有很多工作要做。包容性和多样性是该项目的主要目标，但我对其剩余的一些限制感到失望（如 GitHub README 中所述）。但我已经忙于使用模型增强工作流程手动标记更多图像。 我很乐意回答有关项目、培训程序等任何问题。所有的训练参数都记录在 GitHub 上，但有很多小细节都是一年来来之不易的。就像那个该死的损失乘数一样。呃。 Github：https://github.com/fpgaminer/joytag 模型下载：https://huggingface.co/fancyfeast/joytag/tree/main 演示：https://huggingface.co/spaces/fancyfeast/joytag   由   提交 /u/fpgaminer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18nb15l/p_i_built_an_open_sota_image_tagging_model_to_do/</guid>
      <pubDate>Thu, 21 Dec 2023 01:34:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 米斯特拉尔获得了资金，现在价值数十亿美元。开源 LLM 是未来吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18mv8le/d_mistral_received_funding_and_is_worth_billions/</link>
      <description><![CDATA[遇到了这个有趣的文章，这是一家开源法学硕士，最近获得了 4 亿美元的资金，目前估值为 20 亿美元。开源法学硕士会成为未来吗？考虑到 ChatGPT 的信任问题以及关于其安全性的争论，在我看来，开源 LLM 的想法似乎是最好的选择。 与闭源模型不同，用户可以验证开源模型的隐私声明。源模型。人们对 Mistral 有一些好话，我只希望这样的开源法学硕士能够获得足够的资金来与 OpenAI 这样的巨头竞争。也许到那时，ChatGPT 也会被迫开源？ 话虽如此，我也希望像 Silatus 和 Durable 已经使用了多种模型，请考虑在其框架中使用 Mistral 等开源模型。如果发生这种情况，人工智能隐私可能会发生变化。你们有什么感想？开源法学硕士是未来吗，尤其是在有资金支持的情况下？   由   提交/u/BelowaverageReggie34  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18mv8le/d_mistral_received_funding_and_is_worth_billions/</guid>
      <pubDate>Wed, 20 Dec 2023 13:59:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>