<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 15 Mar 2024 00:57:17 GMT</lastBuildDate>
    <item>
      <title>[D] GPT-4 在算法难题中失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bezmdu/d_gpt4_fails_in_algorithmic_puzzles/</link>
      <description><![CDATA[摘要： 我们介绍了在视觉问答的背景下解决多模式谜题的新颖任务。我们提出了一个新的数据集 AlgoPuzzleVQA，旨在挑战和评估多模态语言模型解决算法难题的能力，这些算法难题需要视觉理解、语言理解和复杂的算法推理。我们创建的谜题涵盖了各种数学和算法主题，例如布尔逻辑、组合学、图论、优化、搜索等，旨在评估视觉数据解释和算法解决问题技能之间的差距。该数据集是根据人类编写的代码自动生成的。我们所有的谜题都有精确的解决方案，可以从算法中找到，无需繁琐的人工计算。它确保我们的数据集可以在推理复杂性和数据集大小方面任意扩展。我们的调查表明，GPT4V 和 Gemini 等大型语言模型 (LLM) 在解谜任务中表现有限。我们发现，在针对大量谜题的多项选择问答设置中，他们的表现几乎是随机的。研究结果强调了整合视觉、语言和算法知识来解决复杂推理问题的挑战。 https ://github.com/declare-lab/LLM-PuzzleTest   由   提交 /u/sgpfc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bezmdu/d_gpt4_fails_in_algorithmic_puzzles/</guid>
      <pubDate>Thu, 14 Mar 2024 23:36:25 GMT</pubDate>
    </item>
    <item>
      <title>[D]medium和tds的最佳替代品是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1beyrf8/d_what_are_the_best_substitute_of_medium_and_tds/</link>
      <description><![CDATA[您好，我是机器学习和数据科学的忠实粉丝和实践者，我从数据科学中学到了很多东西，但最近觉得质量减少并且无法找到好的来源来获得更多的技术知识或深度学习或机器学习的端到端高级项目，有什么建议吗？谢谢   由   提交 /u/WASSIDI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1beyrf8/d_what_are_the_best_substitute_of_medium_and_tds/</guid>
      <pubDate>Thu, 14 Mar 2024 22:58:51 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch Lightning 吞吐量监视器 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bevp6d/pytorch_lightning_throughputmonitor_p/</link>
      <description><![CDATA[大家好， 我有这个 PytorchLightning 代码，我想添加 ThroughputMonitor，但我找不到如何添加。 你能建议如何添加它吗？  def main(): model = CIFAR10Model() logger = TensorBoardLogger(&quot;logs/tb_logs&quot;, name=&quot;resnet18_ciphar10_lightning&quot;) profiler = PyTorchProfiler(dirpath=&quot;logs/profiler_logs&quot;) , filename=“perf-logs”) trainer = Trainer( max_epochs=args.epochs, Accelerator=“cpu”, devices=16, Strategy=“ddp”, logger=logger, enable_progress_bar=True, profiler=profiler, num_nodes=3、log_every_n_steps=1、callbacks=[DeviceStatsMonitor()、EarlyStopping(...)] )  ​   由   提交/u/POC-545  /u/POC-545  reddit.com/r/MachineLearning/comments/1bevp6d/pytorch_lightning_throughputmonitor_p/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bevp6d/pytorch_lightning_throughputmonitor_p/</guid>
      <pubDate>Thu, 14 Mar 2024 20:51:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助查找最近的 ML 文章/帖子 - LLM 之间相互对话的有用语言空间</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1beuppp/d_help_to_find_recent_ml_articlepost_space_of/</link>
      <description><![CDATA[   前几天我在Twitter/X 发现了这张图表，它代表了当两个法学硕士相互交谈时，与所有可能的语言相比，有用生成的空间。我相信这可能是 Yann Lecun 分享的。我需要一些帮助来查找这篇文章，如果您找到它，请私信或回复链接。谢谢 下面是我记得的图表的样子。 https://preview.redd.it/lk1laqx1xcoc1.png?width=1161&amp;format=png&amp;auto=webp&amp;s=b8b01fcc22a81f4414b9bad98b9d784 73de5eb7e   由   提交 /u/rovrav   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1beuppp/d_help_to_find_recent_ml_articlepost_space_of/</guid>
      <pubDate>Thu, 14 Mar 2024 20:10:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 序列模型内的内存</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bes2n5/d_memory_inside_sequence_models/</link>
      <description><![CDATA[我正在尝试更深入地了解 RNN（及其变体）和 Transformer 中的内存概念。 除了普通 RNN、GRU 和 LSTM 之间的架构差异之外，内存基本上是通过某些数学函数处理的输入序列，并以顺序方式作为下一个时间步骤（沿着输入 Xt）的输入，作为先验表示的数据。  从这个技术角度来看，在计算以及梯度消失和爆炸方面，内存似乎受到输入序列的长度和训练过程的难度的限制。 LSTM 和 GRU 的门控机制已经得到了有效的改进，以缓解上述问题。  我不久前开始阅读并致力于理解 Transformer - 3 周，我掌握了它的重要性、影响、范式转变时刻等等，我明白了为什么它在法学硕士中如此成功，但是老实说，有些事情似乎并不能完全证明这一点。通过编码器-解码器堆栈和其他所有内容中的多头注意力和并行化解决了序列长度瓶颈。这很有趣，实际上很神奇。也许我错了，没有完全理解。 我很难将记忆想象成与改进网络内处理信息的方式不同的东西。我读到的每一篇开创性的论文都讨论了这些架构挑战以及它们如何改善内存和计算约束的情况，这些都非常有效地让我只抽象地思考表示学习。  我的印象是，我们还没有那么接近有效地理解和设计“人工”记忆，因为它是来自我们人类的生物学灵感。 但我计划继续更多地研究风景我似乎只触及了表面。也许视觉是理解记忆的关键，超越了在可互换使用语言和视觉的统一系统中通过图像和视频进行推理的能力。 还有哪些其他论文或来源可以以更具视觉吸引力和有趣的方式处理记忆。 ？ 我还想指出，我只是一名本科生，自学成才，根本不从事任何 STEM 工作。    由   提交 /u/Sinestro101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bes2n5/d_memory_inside_sequence_models/</guid>
      <pubDate>Thu, 14 Mar 2024 18:23:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 加密数据训练模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1berfdd/p_training_models_on_encrypted_data/</link>
      <description><![CDATA[您好， 我们最近发布了一种在加密数据上训练机器学习模型的方法。这一切都可以通过 concrete-ml 中的数据科学友好的 API 获得。您可以在  https://www.zama.ai /post/training-predictive-models-on-加密数据-全同态加密。 对于实现细节：我们提取 PyTorch 训练会话的 onnx 图（目前）逻辑回归）并将其转换为 numpy 函数。然后在 concrete 的帮助下将其转变为 FHE 电路。该电路具有对加密数据进行训练的能力！ 如果您想尝试一下，可以访问 我们所做的示例笔记本。 希望听到您的所有反馈并回答您可能有的任何问题！ &gt;   由   提交 /u/strojax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1berfdd/p_training_models_on_encrypted_data/</guid>
      <pubDate>Thu, 14 Mar 2024 17:56:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 条件生成图像的 FID</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1berb77/r_fid_of_conditionally_generated_images/</link>
      <description><![CDATA[大家好！ 我对有条件生成的样本的 FID 计算有疑问。大多数研究论文即使在类条件生成上也只提供单个 FID 分数，而它们应该根据类 FID 给出。 我错了吗？ 请告诉我.谢谢   由   提交 /u/Independent-King-320   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1berb77/r_fid_of_conditionally_generated_images/</guid>
      <pubDate>Thu, 14 Mar 2024 17:51:53 GMT</pubDate>
    </item>
    <item>
      <title>[N] 哎呀...... OpenAI CTO Mira Murati 关于哪些数据被用来训练 Sora</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1belin7/n_ooops_openai_cto_mira_murati_on_which_data_was/</link>
      <description><![CDATA[是只有我一个人还是有大规模的诉讼即将到来？ https://twitter.com/tsarnick/status/1768021821595726254   由   提交/u/pg860  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1belin7/n_ooops_openai_cto_mira_murati_on_which_data_was/</guid>
      <pubDate>Thu, 14 Mar 2024 13:45:10 GMT</pubDate>
    </item>
    <item>
      <title>材料科学中的机器学习 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bejx2d/machine_learning_in_materials_science_r/</link>
      <description><![CDATA[大家好，我目前正在熟悉材料科学中的机器学习主题。我想检测和分析材料测试图像中的几何误差，并就此撰写一篇科学论文。  现在我意识到文献研究是很难的。这可能是因为我还没有找到合适的搜索引擎和相应的气泡（如果有气泡的话）。  我希望能在 Reddit 上找到这个泡沫。如果有任何提示和技巧，我将不胜感激。有谁有这方面的经验或知道任何有用的文献吗？ 提前非常感谢！   由   提交/u/hungry_cowboy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bejx2d/machine_learning_in_materials_science_r/</guid>
      <pubDate>Thu, 14 Mar 2024 12:23:25 GMT</pubDate>
    </item>
    <item>
      <title>TryOnDiffusion：两个 UNet 的故事 - 非官方 PyTorch 实现 [R] [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1beifsk/tryondiffusion_a_tale_of_two_unets_unofficial/</link>
      <description><![CDATA[您好， 我最近发布了 Google 的 TryOnDiffusion 论文。我训练它的资源有限，但我认为我对它进行了足够的实验，以验证它基本上是正确的（自述文件中详细介绍了实验设置） 代码是 MIT 许可证，因此完全开源。链接 - https://github.com/fashn-AI/tryondiffusion 我希望它可以帮助这里的某人。 祝一切顺利，   由   提交 /u/JYP_Scouter   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1beifsk/tryondiffusion_a_tale_of_two_unets_unofficial/</guid>
      <pubDate>Thu, 14 Mar 2024 10:53:52 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 去噪自动编码器和低通频率滤波器之间是否存在一般数学关系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1beidkd/dr_is_there_a_general_mathematical_relationship/</link>
      <description><![CDATA[如果我错了，请纠正我，我的理解是，当去噪自动编码器经过训练以消除输入数据中的噪声时，从某种意义上说，它会起作用作为从输入数据中去除高频噪声的滤波器，类似于低通滤波器。通过从噪声输入数据中重建干净的数据，去噪自动编码器可以有效地平滑信号并降低噪声，类似于低通滤波器的行为。我的问题是，我可以将经过训练的神经网络参数表示为傅里叶空间中某种形式的频率滤波器吗？此外，我也有兴趣了解，通过经过训练的自动编码器运行后，它可能会在数据中添加多少低频噪声（引入低频伪影）？    由   提交/u/bahauddin_onar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1beidkd/dr_is_there_a_general_mathematical_relationship/</guid>
      <pubDate>Thu, 14 Mar 2024 10:49:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] Chronos：学习时间序列的语言</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1behp7t/r_chronos_learning_the_language_of_time_series/</link>
      <description><![CDATA[     &lt; td&gt; 论文：https://arxiv.org/abs /2403.07815 代码：https://github.com/amazon-science/chronos -预测 模型权重：https://huggingface.co/collections/ amazon/chronos-models-65f1791d630a8d57cb718444 摘要：  我们介绍 Chronos，一个简单而有效的框架，用于预训练概率时间序列模型。 Chronos 使用缩放和量化将时间序列值标记化为固定词汇表，并通过交叉熵损失在这些标记化时间序列上训练现有的基于 Transformer 的语言模型架构。我们在大量公开可用的数据集上预训练了基于 T5 系列（参数范围从 20M 到 710M 参数）的 Chronos 模型，并辅以通过高斯过程生成的合成数据集以提高泛化能力。在由 42 个数据集组成并包含经典局部模型和深度学习方法的综合基准测试中，我们表明 Chronos 模型：(a) 在属于训练语料库的数据集上显着优于其他方法； (b) 相对于专门针对新数据集进行训练的方法，在新数据集上具有可比的、有时甚至更优越的零样本性能。我们的结果表明，Chronos 模型可以利用来自不同领域的时间序列数据来提高未见过的预测任务的零样本精度，将预训练模型定位为一种可行的工具，大大简化预测流程。 &lt; /blockquote&gt; ​ https://preview.redd.it/7fxmgjnuw9oc1.png?width=1818&amp;format=png&amp;auto=webp&amp;s=8d9e0b7b462597a3b7c176c133e7a2843debf b7c &lt;!-- SC_ON - -&gt;  由   提交 /u/shchur   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1behp7t/r_chronos_learning_the_language_of_time_series/</guid>
      <pubDate>Thu, 14 Mar 2024 10:04:49 GMT</pubDate>
    </item>
    <item>
      <title>对最新AI软件工程师Devin的思考《[讨论]》</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdzesy/thoughts_on_the_latest_ai_software_engineer_devin/</link>
      <description><![CDATA[刚刚开始攻读计算机科学学位，人工智能每天取得的进展真的让我感到害怕。很抱歉，如果这个问题感觉有点无关紧要或重复，但由于你们最了解这项技术，我想听听你们的想法。人工智能（法学硕士）真的可以实现软件工程自动化，甚至可以将 10 名开发人员的团队减少到 1 名吗？我们真正可以期待人工智能软件工程取得多大的进步。数据科学甚至人工智能工程等领域也能实现自动化吗？ tl:dr 您认为未来 20 年法学硕士在技术工作自动化方面能走多远    由   提交/u/Anonymous45353  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdzesy/thoughts_on_the_latest_ai_software_engineer_devin/</guid>
      <pubDate>Wed, 13 Mar 2024 18:50:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 数据解释器：数据科学的法学硕士代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdxqt4/r_data_interpreter_an_llm_agent_for_data_science/</link>
      <description><![CDATA[      摘要：  基于大型语言模型 (LLM) 的代理已表现出显着的有效性。然而，在需要实时数据调整、由于各种任务之间复杂的依赖关系而需要优化专业知识以及识别逻辑错误以进行精确推理的能力的数据科学场景中，它们的性能可能会受到影响。在本研究中，我们介绍了数据解释器，这是一种旨在用代码解决问题的解决方案，强调三种关键技术来增强数据科学中的问题解决：1）具有分层图结构的动态规划，以实现实时数据适应性； 2）动态工具集成，以提高执行过程中的代码熟练程度，丰富所需的专业知识； 3）反馈中的逻辑不一致识别，通过经验记录提高效率。我们在各种数据科学和实际任务中评估数据解释器。与开源基线相比，它表现出了卓越的性能，在机器学习任务方面表现出显着改进，从 0.86 提高到 0.95。此外，数学数据集增加了 26%，开放式任务显着提高了 112%。该解决方案将在 https://github.com/geekan/MetaGPT 发布。  ​ https: //preview.redd.it/6bcww0qb15oc1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=d98f2e05fbdf06f186b93782a786dc94b3d33bac ​ &lt; a href=&quot;https://preview.redd.it/565u97cc15oc1.png?width=1116&amp;format=png&amp;auto=webp&amp;s=fdefeda7c7733e610e0984ba7d7b77024d91a1b0&quot;&gt;https://preview.redd.it/565u97cc15oc1.png?width =1116&amp;format=png&amp;auto=webp&amp;s=fdefeda7c7733e610e0984ba7d7b77024d91a1b0 ​ https://preview.redd.it/a4c6lopc15oc1.png?width=1150&amp;format=png&amp;auto=webp&amp;s= 8b1e7cc27f3a2a9b75a66da0fdd54d29bf988f86 ​ https://preview.redd.it/lab3uh2d15oc1.png?width=731&amp;format=png&amp;auto=webp&amp;s=9f1506e607eb644b77bd2ba22e2189d0 05e1c010    由   提交/u/MetaGPT   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdxqt4/r_data_interpreter_an_llm_agent_for_data_science/</guid>
      <pubDate>Wed, 13 Mar 2024 17:46:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>