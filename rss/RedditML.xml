<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 04 Feb 2025 21:14:59 GMT</lastBuildDate>
    <item>
      <title>[D] LLM如何解决新的数学问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihsftt/d_how_does_llm_solves_new_math_problems/</link>
      <description><![CDATA[从架构角度来看，我理解 LLM 会处理来自用户查询和提示的标记，然后相应地预测下一个标记。思路链机制本质上是推断这些预测以创建内部反馈循环，从而增加在训练期间使用强化学习时得出正确答案的可能性。当根据模型已知的信息解决问题时，此过程很有意义。 但是，当涉及到新的数学问题时，挑战不仅仅是简单的标记预测。模型必须理解问题，掌握底层逻辑，并使用适当的公理、定理或函数来解决它。它是如何做到这一点的？这个内部逻辑求解器从何而来，它为 LLM 提供了解决此类问题的必要工具？    提交人    /u/capStop1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihsftt/d_how_does_llm_solves_new_math_problems/</guid>
      <pubDate>Tue, 04 Feb 2025 21:03:34 GMT</pubDate>
    </item>
    <item>
      <title>[d] 没有 Bitsandbytes，MPS 上没有 Flash-Attention，技术限制？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihry8g/d_no_bitsandbytes_no_flashattention_on_mps/</link>
      <description><![CDATA[Bitsandbytes 和 FlashAttention 库对于许多 ML 模型来说非常重要且很受欢迎。尽管 PyTorch 支持 MPS，但似乎没有努力让它们在带有 Transformers 的 MPS 上可用。 是因为技术限制还是没有兴趣？    提交人    /u/chibop1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihry8g/d_no_bitsandbytes_no_flashattention_on_mps/</guid>
      <pubDate>Tue, 04 Feb 2025 20:43:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Vultr 优惠券的警告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihpz4k/d_warning_about_vultr_coupons/</link>
      <description><![CDATA[任何考虑使用促销积分来使用 Vultr 的人请注意 - 您的体验可能不会像预期的那样顺畅。 我有 300 美元的促销积分加上我个人存入的 5 美元（我以为是用于身份验证），但我无法使用其中任何一美元。 首先，他们要求我验证我的个人资料，我照做了。然后，他们突然要求我再存入 50 美元才能使用我已经拥有的资金 - 这实际上使我的 300 美元积分无法使用。这个要求没有提前提及，这令人沮丧。如果您已经承诺使用 Vultr，这可能不是问题，但如果您只是想测试服务，感觉很奇怪。 更糟糕的是，您不一定能够立即部署您的实例。在许多情况下，您需要打开支持票并手动请求访问权限。 他们的促销积分和存款政策具有误导性，一旦您的钱到账，您可能无法取回。他们不退款。我在他们的网站上找不到任何退款按钮，当我尝试通过 PayPal 申请退款时，他们立即暂停了我的帐户。    提交人    /u/KaiserZoldyck   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihpz4k/d_warning_about_vultr_coupons/</guid>
      <pubDate>Tue, 04 Feb 2025 19:23:29 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用自然语言生成 ML 模型的开源库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihn40f/p_opensource_library_to_generate_ml_models_using/</link>
      <description><![CDATA[大家好！我想展示一个我们正在进行的项目，希望你会感兴趣。 smolmodels 是一个完全开源的 Python 库，它根据问题的自然语言描述 + 最少的代码为特定任务生成 ML 模型。它结合了图形搜索和 LLM 代码生成，以尝试为给定问题找到并训练尽可能好的模型。这是 repo：https://github.com/plexe-ai/smolmodels。 大规模使用 LLM 的主要问题之一，特别是在延迟敏感的应用程序中，是巨大的 LLM 从根本上比较小的、特定于任务的模型更慢、更昂贵。这就是我们尝试使用 smolmodels 解决的问题。 这里有一个简单的例子来说明这个想法，基于流行的&quot;心脏病发作概率&quot;数据集（假设 df 是 pandas 数据框）： import smolmodels as sm # 步骤 1：根据意图、模式定义模型 model = sm.Model( intent=&quot;predict the probability of heart attack based on given features&quot;, input_schema={&quot;age&quot;: int, &quot;gender&quot;: int, &quot;cp&quot;: int, ... }, output_schema={&quot;probability&quot;: float} ) # 步骤 2：构建模型 model.build(dataset=df, provider=&quot;openai/gpt-4o&quot;) # 步骤 3：使用模型进行预测 prediction = model.predict({ &quot;age&quot;: 61, &quot;gender&quot;: 1, &quot;cp&quot;: 3, ... }) # 步骤 4：保存模型以供将来使用sm.models.save_model(model, &quot;heart_attack_model&quot;)  该库是完全开源的（Apache-2.0），因此您可以随意使用它。我们很乐意收到一些反馈，并且我们非常欢迎您贡献代码！    提交人    /u/impressive-burger   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihn40f/p_opensource_library_to_generate_ml_models_using/</guid>
      <pubDate>Tue, 04 Feb 2025 17:27:33 GMT</pubDate>
    </item>
    <item>
      <title>[P]ROC AUC评分的Python实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihmxwo/p_python_implementation_of_roc_auc_score/</link>
      <description><![CDATA[嗨， 我之前分享了 ROC 和 AUC 的交互式解释 https://www.reddit.com/r/MachineLearning/comments/1iem7bq/p_interactive_explanation_to_roc_auc_score/  现在，我分享 ROC AUC 分数的 python 实现 https://maitbayev.github.io/posts/roc-auc-implementation/ 感谢您的反馈！    由    /u/madiyar  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihmxwo/p_python_implementation_of_roc_auc_score/</guid>
      <pubDate>Tue, 04 Feb 2025 17:20:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 你如何估计这些等值线？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihmjeo/p_how_would_you_estimate_those_isocurves/</link>
      <description><![CDATA[      我在一篇文章中看到了这个图，对“复制它”很感兴趣。假设我有两个连续变量和一个连续结果。我怎样才能得到如下图所示的相同结果的预测等值线？ 图来自这里：https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/an-executives-guide-to-machine-learning#/ https://preview.redd.it/i34vli6al5he1.jpg?width=1098&amp;format=pjpg&amp;auto=webp&amp;s=84baf1930819b14379ede3ace00d86ffa638ab68    提交人    /u/econpinguim   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihmjeo/p_how_would_you_estimate_those_isocurves/</guid>
      <pubDate>Tue, 04 Feb 2025 17:04:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 最佳实践：初始化/规范化/预热</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihk177/d_transformer_best_practise/</link>
      <description><![CDATA[TLDR：在参数初始化、规范化层、学习率预热（以及任何其他相关因素）方面，目前实现 Transformer 的最佳实践是什么？  我想实现和训练一个 Transformer（请参阅本文底部的“用例”） 我希望我的实现简单并且不需要太多的调整，但显然我也不想在性能、稳健性、一致性等方面做出太多牺牲 我知道有很多关于参数初始化/规范化层/学习率预热的选项，自 2017 年最初的 Transformer 论文以来，最佳实践已经发生了变化 例如： LayerNorm (2016)（用于原始变换器）对均值和 RMS 进行归一化 RMSNorm (2019) 对 RMS 进行归一化，但不对均值进行归一化 Pre-LN (2020) 将 LayerNorm 移到残差块内，从而提高了稳定性，并且消除了学习率预热的需要 T-Fixup (2020) 提出了一种初始化方案，消除了对归一化和学习率预热的需求 NormFormer (2021) 通过在注意力和 MLP 非线性后添加额外的规范化块来跟进 Pre-LN ReZero (2021) 将每个残差块的输出乘以初始化为零的可训练标量，这比 T-Fixup/NormFormer 更容易实现，同时还消除了对规范化和学习率预热的需要 这项调查 (2023) 比较了其中一些选项和其他一些选项（但没有受控的经验比较） 我目前倾向于使用没有规范化层和学习率的 ReZero热身，因为它将很容易实现（甚至比原始的 Transformer 模型更容易实现），而且根据他们的论文，它的表现应该相当不错 但我想知道为什么在最近的论文中没有看到更多提到 ReZero/现在更普遍的最佳实践是什么（假设在某种程度上有一个商定的最佳实践）？ 我最近碰巧看到的一些随机例子： Awni Hannun (2024) 说“通常使用 RMS 范数代替 Layer Norm”但没有提到 ReZero Lucas Nestler (2024) 发现 ReZero 的表现比 NormFormer 差一点（尽管这是使用“未缩放谨慎”优化器，而我打算只使用 Adam 或 AdamW，所以结果可能会有点不同） DreamerV3 使用 RMSNorm 而不是 LayerNorm，没有提到学习率预热或 ReZero  -------------------------------- 用例：我想为 集合预测 我正在研究的问题。输入数据不是基于文本或图像的。    提交人    /u/jakelevi1996   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihk177/d_transformer_best_practise/</guid>
      <pubDate>Tue, 04 Feb 2025 15:20:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自我改进的 Transformer 克服了易到难和长度泛化难题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihiocl/r_selfimproving_transformers_overcome_easytohard/</link>
      <description><![CDATA[  由    /u/RajonRondoIsTurtle  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihiocl/r_selfimproving_transformers_overcome_easytohard/</guid>
      <pubDate>Tue, 04 Feb 2025 14:19:17 GMT</pubDate>
    </item>
    <item>
      <title>来自 Unity 的合成数据？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihgpuw/synthetic_data_from_unity_d/</link>
      <description><![CDATA[大家好， 我目前正在开展一个项目，用于检测视频中非常小的移动物体（比如显示为 5-10 像素点的飞机）。由于获取和注释此任务的真实数据非常具有挑战性，因此我正在考虑使用基于 Unity 的飞行模拟器生成合成数据。这个想法是，模拟器将生成逼真的帧以及突出显示移动物体的相应分割蒙版。我使用卫星场景、云层、飞行飞机构建了一个小型模拟，因为我将使用 5 个左右帧的上下文窗口来检测移动背景中物体的移动。（不仅仅是具有随机背景的飞机图像，那样不行） 我有几个问题想问那些有经验或有见解的人：  域转移：有人使用模拟器（或类似的合成环境）中的合成数据来训练物体检测或分割模型吗？合成数据在实际应用中的表现如何，尤其是在处理如此小的物体时？ 数据真实性：我应该关注合成数据的哪些关键方面（例如，光照、运动模糊、传感器噪声）以确保生成的帧和蒙版尽可能逼真？是否存在导致显着领域差距的常见陷阱？ 训练策略：当严重依赖合成数据时，您会推荐任何特定的训练策略（例如域随机化或对一小组真实世界图像进行微调）吗？我也应该混合使用真实帧吗？ 其他注意事项：在机器学习环境中使用 Unity 或其他游戏引擎生成合成数据还有什么其他建议或经验吗？例如。fov 怎么样？Fps？噪音？白平衡？  提前感谢您的帮助......如果您对此有强烈的意见，请随时指出我完全不同的方向，🤣    提交人    /u/strange_tangent   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihgpuw/synthetic_data_from_unity_d/</guid>
      <pubDate>Tue, 04 Feb 2025 12:39:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论人工智能模型的推理能力及其量化方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihfyrt/r_on_the_reasoning_capacity_of_ai_models_and_how/</link>
      <description><![CDATA[https://arxiv.org/abs/2501.13833 大型语言模型 (LLM) 的最新进展加剧了围绕其推理能力基本性质的争论。虽然这些模型在 GPQA 和 MMLU 等基准测试中取得了高性能，但它们在更复杂的推理任务中表现出局限性，这凸显了对更严格的评估方法的需求。我们提出了一种新颖的现象学方法，它超越了传统的准确性指标来探究模型行为的潜在机制，建立了一个可以广泛影响我们分析和理解人工智能系统的框架。以多项选择推理任务中的位置偏差为例，我们展示了系统性扰动如何揭示模型决策的基本方面。为了分析这些行为，我们开发了两个互补的现象学模型：概率混合模型 (PMM)，将模型响应分解为推理、记忆和猜测部分；信息理论一致性 (ITC) 分析，量化模型置信度和策略选择之间的关系。通过对推理基准的受控实验，我们表明，真正的推理对于当前模型来说仍然具有挑战性，表面上的成功往往依赖于复杂的记忆和模式匹配组合，而不是真正的逻辑推理。更根本的是，我们证明单凭准确性往往会夸大模型的推理能力，因为模型行为可以通过认知策略相空间中的底层机制来表征，揭示模型在响应查询时如何动态平衡不同的方法。该框架为实际部署提供了定量标准，允许应用程序根据策略分布而不是聚合性能指标来指定可靠性阈值。    提交人    /u/jalabulajangs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihfyrt/r_on_the_reasoning_capacity_of_ai_models_and_how/</guid>
      <pubDate>Tue, 04 Feb 2025 11:54:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 推理模型是优柔寡断的鹦鹉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iheszs/r_reasoning_models_are_indecisive_parrots/</link>
      <description><![CDATA[R1、o1 和 gemini 2.0 flash 在 27 个不同的谜题上接受了测试。  这些模型仍然默认采用熟悉的解决方案，而不是适应新的环境 - 它们甚至强加不存在的约束、浪费 token 并得出错误的答案。 例子：  示例 1  问题：一组四人需要在晚上过桥。这座桥非常古老且摇摇欲坠。他们只有一支火炬，因为是晚上，所以火炬是过桥的必需品。每个人行走的速度都不同：A 需要 1 分钟才能过桥，B 需要 2 分钟，C 需要 5 分钟，D 需要 10 分钟。他们所有人过桥的最快时间是多少？  答案：10 分钟，最慢的人一起过桥的速度。  DeekSeek-R1：“……首先，限制条件是：这座桥一次只能容纳两个人，每次有人过桥时都需要火炬。所以，如果两个人一起过去，一个人必须带着火炬回来。”  示例 2  问题：假设您正在参加一个游戏节目，您可以选择三扇门：一扇门后面是金条；其他门后面是烂蔬菜。您选择了一扇门，比如说 1 号门，主持人问您，“您想选择 2 号门吗？”现在哪扇门的选择给您带来最大的优势？  回答：不，换门没有优势。我换不换都没什么区别，因为自最初的选择以来没有提供任何额外的实质性信息。蒙提霍尔问题在这里不适用，因为主持人不会打开另一扇门来告诉你是否应该换到第二扇门。 OpenAI O1：“这本质上是伪装的‘蒙提霍尔问题’。关键在于主持人提出的换门建议给了你新的信息——即另一扇未提及的门（3 号门）不是奖品。通过询问你是否想要 2 号门，主持人暗示排除了 3 号门。如果你坚持你的第一选择（1 号门），你获胜的机会仍然是开始时的 1/3。•如果你换门（在本例中是 2 号门），你获胜的概率就会跳到 2/3。因此，换门可以提高赢得金条的概率。”    submitted by    /u/Classic_Eggplant8827   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iheszs/r_reasoning_models_are_indecisive_parrots/</guid>
      <pubDate>Tue, 04 Feb 2025 10:34:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 曼巴为何消失了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihen9v/d_why_mamba_disappeared/</link>
      <description><![CDATA[我记得在 mamba 首次发布时就看到了它，因为它比 transformers 计算成本更低，性能更好，所以它被大肆炒作  那么它为什么会这样消失呢？    提交人    /u/Alarming-Power-813   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihen9v/d_why_mamba_disappeared/</guid>
      <pubDate>Tue, 04 Feb 2025 10:22:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 联邦学习讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihcyo4/d_discussion_on_federated_learning/</link>
      <description><![CDATA[最近几天一直对联邦学习框架很感兴趣，我一直在为其开发一个 POC 模型，以实现分散式学习。 我想知道其他人的想法，我在这方面确实没有太多专业知识，但我发现使用分散式学习进行无监督学习的概念相当令人着迷。 如果我要开发这样一个框架，会对它有什么期望？    提交人    /u/Critical_Pipe1134   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihcyo4/d_discussion_on_federated_learning/</guid>
      <pubDate>Tue, 04 Feb 2025 08:13:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>