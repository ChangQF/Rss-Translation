<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Wed, 24 Jul 2024 12:28:01 GMT</lastBuildDate>
    <item>
      <title>[D] 零样本实体匹配</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eaxizz/d_zeroshot_entity_matching/</link>
      <description><![CDATA[您好，我正在寻找零样本实体匹配模型的解决方案。 理想情况下，我想要做的是，每当在两个单独的句子中检测到某个实体两次时，我想检查这两个句子是否在谈论同一个实体。 对 SOTA 模型有什么想法以及到目前为止尝试过什么？    提交人    /u/cedar_mountain_sea28   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eaxizz/d_zeroshot_entity_matching/</guid>
      <pubDate>Wed, 24 Jul 2024 09:55:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 零样本法学硕士 (LLM) 分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eaxghq/r_zero_shot_llm_classification/</link>
      <description><![CDATA[我很惊讶没有更多关于使用 GenAI LLM 进行零样本分类的研究？他们在这方面做得相当不错，我想他们会越来越好。 例如，请参阅这个和这个 我遗漏了什么吗？随着人工智能在未来 5 年的发展，我认为这些基础模型将在常识推理方面继续成长，成为您能获得的最好的开箱即用分类器，并且可能开始胜过那些在新的类别或边缘情况下失败的更多任务特定模型。 为什么没有更多的研究？人们只是觉得这很明显吗？    提交人    /u/SkeeringReal   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eaxghq/r_zero_shot_llm_classification/</guid>
      <pubDate>Wed, 24 Jul 2024 09:50:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 低秩场加权分解机</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eaxapg/r_low_rank_fieldweighted_factorization_machines/</link>
      <description><![CDATA[      我们的论文Alex Shtoff、Michael Viderman、Naama Haramaty-Krasne、Oren Somekh、Ariel Raviv 和 Tularam Ban 撰写的“用于低延迟项目推荐的低秩场加权分解机”已被 RecSys 2024 接受。 我相信它引起了 ML 驱动的推荐系统社区的兴趣。我认为它对于在极端时间限制下运行的大规模系统（例如在线广告）的研究人员来说尤其有趣。 TL;DR：我们将具有 n 个特征和 nᵢ 项目特征的 FwFM 模型的推理成本从 O(n²) 降低到 O(c nᵢ)，其中 c 是一个小常数。这是为了便于以更低的成本进行大规模实时项目推荐推理。 代码和论文：GitHub 链接。 详细信息 FM 广泛应用于在线广告，因为它们在表示能力和极快的训练和推理速度之间取得了良好的平衡。在严格的时间限制下，它对于大规模推荐至关重要。 Rendle 等人设计的主要技巧是在 O(n) 时间内计算 n 个特征的 *成对* 交互。此外，在为给定用户排名多个项目时相同的用户/上下文特征可以单独处理（见下图）。单个推荐的计算成本变为每个项目的 O(nᵢ)，其中 nᵢ 是项目特征的数量。因此，添加更多用户或上下文特征实际上是免费的。 线性时间的 FM 公式 更高级的变体，例如 Field-Aware 和 Field-Weighted FM，不具备此属性，需要 O(n²) 时间。这对此类系统构成了挑战，需要仔细考虑额外的用户或上下文特征是否值得在推理中付出代价。通常，会积极修剪场交互以显着降低计算成本，但会牺牲模型准确性。  在这项工作中，我们设计了场加权 FM 系列的重新表述，使用场交互矩阵的对角线加低秩 (DPLR) 因式分解，这有助于在 O(c nᵢ) 时间内对每个项目进行推理，其中 c 是我们控制的一个小常数。与修剪的情况一样，代价是模型准确性略有下降。我们表明，在参数数量相当的情况下，DPLR 变体在现实世界数据集上的表现优于修剪，同时显著加快了推理速度，并重新获得了几乎免费添加用户上下文项目的能力。以下是总结结果的简短图表： 对角线+低等级 (DPLR) 推理时间明显优于修剪时间，并且随着上下文特征比例（总共 40 个特征中）的增加而迅速减少。针对各种广告拍卖规模和模型排名绘制。    提交人    /u/alexsht1   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eaxapg/r_low_rank_fieldweighted_factorization_machines/</guid>
      <pubDate>Wed, 24 Jul 2024 09:40:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 介绍一种有助于阅读论文的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eax8yb/d_introducing_a_tool_that_helps_with_reading/</link>
      <description><![CDATA[此工具在阅读论文时，对于理解不熟悉的概念或作者的意图非常方便。检查引文时，您通常需要点击引文链接，向下滚动，复制论文标题，然后在 Google 上搜索，但此工具会自动找到它。它还允许进行额外的对话，这在阅读论文时非常方便。它比ChatGPT更方便的原因在于你不需要复制粘贴论文内容，可以使用同一个工具查看被引用的论文。 Youtube演示视频：https://youtu.be/sM5b72nGFlU?si=MRnCmCWt1KHyRyQB 主要功能 1. 解释+聊天：为论文中的各种格式提供解释和额外讨论。 1.1. 选定文本：选择需要进一步解释的文本，点击Moonlight按钮查看解释。 1.2. 引用：将鼠标悬停在引用链接上以查看有关被引用论文的详细信息，点击Moonlight按钮查看解释。 1.3.捕获的图像：按住 ctrl 并使用鼠标拖动以捕获图像，然后单击 Moonlight 按钮查看说明。 1.4. 外部：将鼠标悬停在外部链接上以查看有关链接内容的说明。 2. 突出显示：选择文本并突出显示。 3. 翻译：选择文本以查看适合上下文的各种翻译选项。 4. 预览：将鼠标悬停在论文内的超链接上以预览该位置的内容。 5. （即将推出！）评估：在开始阅读之前，提供对阅读论文所需深度级别的意见。 6. （即将推出！）书签：为有趣或重要的论文添加书签。在单独的网络平台上管理已加书签的论文。    提交人    /u/adldotori   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eax8yb/d_introducing_a_tool_that_helps_with_reading/</guid>
      <pubDate>Wed, 24 Jul 2024 09:36:58 GMT</pubDate>
    </item>
    <item>
      <title>进入扩散模型[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eawgyo/getting_into_diffusion_models_d/</link>
      <description><![CDATA[您好， 我注意到 CVPR 2024 上有几篇论文关注扩散模型，特别是与点云相关的论文。由于我对这个概念还很陌生，我想知道什么是一个更好的起点来更好地理解它？以节省时间和精力 顺便说一句，我也在研究点云。 谢谢    提交人    /u/Same_Half3758   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eawgyo/getting_into_diffusion_models_d/</guid>
      <pubDate>Wed, 24 Jul 2024 08:45:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama 3 与 llama 3.1 在医疗领域的比较：Llama 3 在基础类别中的表现优于 3.1</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eainqi/d_llama_3_vs_llama_31_in_medical_domain_llama_3/</link>
      <description><![CDATA[      刚刚在医疗任务中分析了 Llama 3 和 3.1 模型。以下是主要发现：  🥇 Meta-Llama-3.1-70B-Instruct：总冠军 🥈 Meta-Llama-3-70B-Instruct：紧随其后的亚军 但令人震惊的是：在基础模型（70B 和 8B）中，Llama 3 的表现通常优于 Llama 3.1！ 🤯 Llama 3.1 70B instruct 在一些任务中击败了 GPT-4，在 Open Medical-LLM 排行榜上几乎与 GPT-4 相当  70B 模型： Instruct：  Llama 3.1 通常表现优于 Llama 3 3.1 在大学生物学方面表现出色，3 在大学医学方面表现出色 两者在医学遗传学方面都很强  Base：  令人惊讶的是，Llama 3 的整体表现优于 3.1 3 在大学解剖学方面占主导地位 3.1 在医学遗传学和专业医学方面表现出色  8B 模型： Instruct：  Llama 3.1 在大多数类别中领先 3.1 在大学生物学中表现出色 3 在医学遗传学方面保持优势  基础：  Llama 3 总体表现略优于 3.1 3 在解剖学方面表现更好 3.1 在医学遗传学和 PubMedQA 中表现出色  有关详细比较，请查看 https://x.com/aadityaura/status/1815836602607768041 有关生命科学领域的 AI 模型、数据集和研究的最新信息，请查看Open Life Science AI。 不要错过AI x 医疗保健领域中的任何模型或数据集 https://x.com/openlifesciai https://preview.redd.it/5nzv5cd4zbed1.jpg?width=2168&amp;format=pjpg&amp;auto=webp&amp;s=52a9abc2fb152393c9378e216e77a29df8e45ec4    由   提交  /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eainqi/d_llama_3_vs_llama_31_in_medical_domain_llama_3/</guid>
      <pubDate>Tue, 23 Jul 2024 20:48:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 精细调整指标在看不见的领域中挣扎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eacl7a/r_finetuned_metrics_struggle_in_unseen_domains/</link>
      <description><![CDATA[10 年前，机器翻译研究人员使用 BLEU 来评估机器翻译输出的质量。几年前，社区开始转向使用学习指标（多语言语言模型回归器）。虽然总体而言它们与人类的相关性更好，但它们也有一些怪癖。其中之一就是它们在训练域之外的文本域上的表现更差。 这项与 AWS 合作的研究记录了领域偏见，查看了它发生的位置，并发布了一个新的由人类判断翻译质量的数据集。  论文（将在 ACL 上发表）：https://arxiv.org/abs/2402.18747 视频（4 分钟）：https://www.youtube.com/watch?v=BG_xAqMNsqY  我是这个 subreddit 的新手，但很高兴参与这个和相关研究。对于这项工作和后续工作，我对评估机器翻译的研究人员和从业人员使用哪些指标以及遇到哪些问题感到好奇。    提交人    /u/zouharvi   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eacl7a/r_finetuned_metrics_struggle_in_unseen_domains/</guid>
      <pubDate>Tue, 23 Jul 2024 16:44:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文使用对抗性噪声进行自监督学习，并使用 20 个样本击败了以 20K 个样本训练的模型。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eabgnt/d_paper_that_used_adversarial_noise_to_perform/</link>
      <description><![CDATA[抱歉，这不是正确的子主题。我记得几年前读过一篇论文，其中给输入图像添加了噪声，并对原始图像进行了度量学习。我记得一些关于如何使用 20 个样本训练模型，并且其性能与使用 20K 个样本训练的模型相当（或类似的东西）。 有人知道我指的论文或类似论文吗？ 提前致谢。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eabgnt/d_paper_that_used_adversarial_noise_to_perform/</guid>
      <pubDate>Tue, 23 Jul 2024 15:58:58 GMT</pubDate>
    </item>
    <item>
      <title>[N] Llama 3.1 405B 下水</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eaaq05/n_llama_31_405b_launches/</link>
      <description><![CDATA[https://llama.meta.com/  根据基准，与 GPT-4o 和 Claude 3.5 Sonnet 相当 权重是公开可用的 128K 上下文     提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eaaq05/n_llama_31_405b_launches/</guid>
      <pubDate>Tue, 23 Jul 2024 15:29:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为应届毕业生举办法学硕士 (LLM) 研讨会游戏化的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eaa0iu/d_ideas_for_gamifying_an_llm_workshop_for_new/</link>
      <description><![CDATA[大家好， 我正在寻找一些想法，将针对新加入公司的大学毕业生的法学硕士学位研讨会游戏化。计划是在上半天进行动手实验室练习，然后在下半天进行黑客马拉松或游戏。我们总共有大约 6 小时的工作时间。 一些背景：我之前在这些学生实习期间为他们举办了一个 3 小时的研讨会，涵盖了 gen AI、法学硕士学位的基础知识，以及为 PDF 构建一个简单的基于 RAG 的聊天机器人。由于工作笔记本电脑的系统限制，并非每个人都能完成动手部分。 现在他们全职加入，这个研讨会是他们 3 个月培训计划的一部分。我正在尝试改进上一次会议。作为背景，去年 AWS 举办了一次 DeepRacer 研讨会，最后以一场比赛来应用所学知识。我的目标是在 LLM 中实现类似的东西——也许是一个可以作为 LLM 代理的游戏或活动，允许他们在竞争环境中应用 RAG 和函数调用等概念。 挑战在于参与者的编程技能水平各不相同。我正在寻找一种适合初学者的东西，但也足够充实，让每个人都能学到一些超越基本提示工程的东西。 如果您有任何想法或需要更多信息，请告诉我。我愿意接受有关如何让这成为新毕业生有效学习体验的建议。    提交人    /u/nerdimite   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eaa0iu/d_ideas_for_gamifying_an_llm_workshop_for_new/</guid>
      <pubDate>Tue, 23 Jul 2024 15:01:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] scikit-activeml：Python 中的主动学习库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea8kc8/p_scikitactiveml_an_active_learning_library_in/</link>
      <description><![CDATA[ TL;DR：我们的主动学习库 scikit-activeml 中应该包含哪些有趣的功能和当前的主动学习研究趋势？  大家好， 我们已经在 scikit-activeml 上工作了几年，我们刚刚发布了具有许多新功能的版本 0.5.0。 什么是 scikit-activeml？ scikit-activeml 是一个全面的 Python 库，建立在 scikit-learn。它为主动学习策略提供了一个易于使用的界面，通过有选择地选择最“信息丰富”的数据来实现高效的数据标记。样本。 scikit-activeml 的主要功能是什么？  从研究论文中实现和概述许多（最先进的）主动学习策略。 支持各种学习范式，从基于池和基于流的主动学习到分类和回归任务，包括考虑多个错误注释者的策略。 广泛的文档，其中包含许多可视化和教程，涵盖各种用例，例如，用于促进主动学习的自我监督学习功能或用于标记新数据集的简单界面。 集成其他框架，如用于深度主动学习的 skorch 和用于基于流的主动学习的 river。  scikit-activeml应该支持哪些主动学习功能和趋势？ 我们想讨论一下您认为主动学习中的重要特征和研究趋势。目前，我们专注于以下方面：  有意义的评估：我们执行大规模基准测试，比较不同模型和主动学习设置的各种数据域和任务中的主动学习策略。结果将发布在一个交互式网站上，用户可以在其中绘制学习曲线并下载结果。此外，我们正在努力将主动学习任务集成到openml中，以允许用户轻松公开和比较他们的结果。 更多学习范式：我们目前专注于回归和分类任务，包括来自多个容易出错的注释者的嘈杂标签场景。鉴于具有多个目标变量的应用程序的重要性，我们的目标是在未来探索用于回归和分类（即多标签）的多输出主动学习策略。 深度主动学习：我们已经开始结合深度主动学习策略，如 DAL、CoreSet、BADGE 和 TypiClust。我们的目标是继续这些实施工作，特别是自我监督学习功能。  作为主动学习研究人员和从业者，您对我们应该考虑的功能和趋势还有其他想法吗？ 如何为 scikit-activeml做出贡献？ 我们一直在寻找各种形式的有用贡献：  加入我们的开源开发人员团队。 指出代码和文档中的错误。 请求新功能，例如新颖的主动学习策略（甚至您自己的策略）。  欢迎通过评论、问题或通过 Reddit 上的直接短信与我们联系。 GitHub：https://github.com/scikit-activeml/scikit-activeml/tree/master 文档：https://scikit-activeml.github.io/scikit-activeml-docs/    提交人    /u/ScienceAnnotator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea8kc8/p_scikitactiveml_an_active_learning_library_in/</guid>
      <pubDate>Tue, 23 Jul 2024 14:00:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] DataChain：使用本地模型和 LLM 调用来管理非结构化数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea881b/p_datachain_curate_unstructured_data_using_local/</link>
      <description><![CDATA[你好！我们今天开源 DataChain：https://github.com/iterative/datachain！它的作用：  从 S3/GCS/Azure/local 读取数据 &amp;版本数据集 应用转换：本地模型推理、外部 LLM 调用或自定义代码 通过 Pydantic 将 Python 对象存储在内部数据库（SQLite）中或导出到 parquet/CSV 文件中 高效并行运行代码，无需内存，可在笔记本电脑中处理数百万个文件 执行矢量化操作：相似度搜索嵌入、总和、平均值等。  示例 - 使用 Mistral 评估聊天机器人对话： from datachain import DataChain, Column from mistralai.client import MistralClient from mistralai.models.chat_completion import ChatCompletionResponse, ChatMessage def eval_dialogue(file: File) -&gt; ChatCompletionResponse: return MistralClient().chat( model=&quot;open-mixtral-8x22b&quot;, messages=[ChatMessage(role=&quot;system&quot;, content=PROMPT), ChatMessage(role=&quot;user&quot;, content=file.read())]) chain = ( DataChain.from_storage(&quot;gs://datachain-demo/chatbot-KiT/&quot;) .settings(parallel=4, cache=True) .map(response=eval_dialogue) .save(&quot;mistral_dataset&quot;) )  在底层，DataChain 利用 Pydantic 序列化 Python 对象；SQLite 作为元存储并执行矢量化操作，以及 DVC 用于处理数据存储。 WDYT?渴望听到您的想法！    由   提交  /u/dmpetrov   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea881b/p_datachain_curate_unstructured_data_using_local/</guid>
      <pubDate>Tue, 23 Jul 2024 13:45:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 C++/C 优化模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea87qq/d_optimizing_models_with_cc/</link>
      <description><![CDATA[您是否真的在普通解决方案公司中使用 C++ 来优化模型？如果是，您认为有什么资源可以学习如何做到这一点？    提交人    /u/AdOk6683   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea87qq/d_optimizing_models_with_cc/</guid>
      <pubDate>Tue, 23 Jul 2024 13:45:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] haipera - 一个开源工具，用于为 Python 笔记本和脚本配置配置，无需编写任何代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e9xrsn/p_haipera_an_open_source_tool_to_instrument/</link>
      <description><![CDATA[TL;DR：我制作了一个开源（apache 2）工具（https://github.com/haipera/haipera），以便更轻松地使用简单的脚本和笔记本进行超参数扫描。 大家好！我已经在 ML / CV 领域进行了 7 年的研究，我一直对自己花在编写检测代码而不是编写算法上的时间感到沮丧。我所说的检测代码是指：配置管理、配置日志记录、一般日志记录、实验跟踪等... 在我的职业生涯中，我编写了无数的数据类、yaml 文件、json 文件和更多代码，以便通过层层的类层次结构传递这些配置对象的参数 - 只是为了发现我尝试的任何实验都没有结果，现在不得不删除我刚刚添加的内容。经常重复的模因是“机器学习研究人员只做超参数扫描”，但现实是，我们实际上编写代码来传递这些超参数，以便我们可以进行扫描。 这在将代码传输给产品团队时会导致更多问题；产品团队获得的代码包含 600 行 argparse 和从 argparse 复制到初始化程序的代码；这些代码经常有错误并且使跨项目兼容性变得困难。  我也有很多朋友在/曾经在配置系统上工作，试图解决这个问题 - 从 Hydra 到 tyro 到 dysweep 到无数的内部工具。我也是其中之一，但问题是这些库往往变得越来越复杂......因为它们试图变得更“健壮”和更少损坏。编写更多代码几乎永远不是解决方案。 所以我想尝试一种新的范式，它完全抛弃了插桩代码，并依赖于静态解析来插桩代码。这意味着您不必编写一行代码即可为您的代码启用配置之类的功能。最近，随着更好的解析库（如 ast 和 libcs​​t）的出现，这成为可能。展望未来，LLM 也拥有很多令人兴奋的潜力。  这一切是如何运作的？ 给定一个脚本，如下所示： num_apples = 100 apple_price = 3.0 print(&quot;# apples: &quot;, num_apples) print(&quot;price of an apple: &quot;, apple_price) price = num_apples * apple_price print(&quot;total: &quot;, price)  您只需执行 pip install haipera，然后就可以使用 haipera run script.py 运行脚本。您可以运行 haipera run script.py --help 以查看变量是否可直接从 CLI 编辑（目前仅支持全局变量和数字、布尔值、字符串等原始类型）。您可以运行类似 haipera run script.py --apple-price 1.0 的程序来直接从 CLI 设置参数。 当您使用 haipera 运行时，它将在 reports 中创建自己的实验文件夹，并使用自动生成的配置文件填充它，您可以直接重新运行该文件以实现可重复性。 如果您想进行网格扫描，您只需传入多个参数，如 haipera run script.py --num-apples 1,2,3 --apple-price 2.0,3.0,4.0。  您还可以做其他事情，例如 haipera run script.ipynb 以 运行 笔记本作为脚本（如果您想在笔记本内进行开发，但要使用配置作为脚本运行大量实验，这很方便）或 haipera notebook script.ipynb --opt1 2 使用提供的配置启动笔记本的新变体。事实证明，这对于对笔记本进行版本控制也很方便！ 我对这个库感到非常兴奋，并一直从我的研究员朋友那里得到反馈，但我想向大家展示并收集反馈。我们计划使这个库的功能更加完善（例如支持更多类型的变量，通常使一切更加强大，并添加对 GPU 分析工具等的支持） - 但在此之前，我们想听听大家对此的看法，并听听您希望 MLOps 工具中存在哪些类型的功能。 让我们知道您的想法！ https://github.com/haipera/haipera    由    /u/dromger 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e9xrsn/p_haipera_an_open_source_tool_to_instrument/</guid>
      <pubDate>Tue, 23 Jul 2024 03:24:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 21 Jul 2024 02:15:09 GMT</pubDate>
    </item>
    </channel>
</rss>