<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Tue, 25 Feb 2025 15:19:08 GMT</lastBuildDate>
    <item>
      <title>CFM/Medical IMG生成/合成的流量匹配[P] [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixx2u9/cfmflowmatching_for_medical_img/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在查看CFM的应用程序论文，尤其是最佳传输（OT）方法。尽管声称它比扩散模型所需的迭代要少得多，并且实施更简单。我看不到任何与医学成像或合成数据生成有关的应用程序文件。  我确实遇到了TorchCFM，看起来可以用于此目的，但不应该在此目的其他替代方案，因为我看到很多大型研究实验室都在该领域工作。  也使用CFM有任何经验吗？您是否将结果与CIFAR图像以外的扩散模型进行了比较？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1ixx2u9/cfmflowmatching_for_medical_img/”&gt; [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixx2u9/cfmflowmatching_for_medical_img/</guid>
      <pubDate>Tue, 25 Feb 2025 15:05:05 GMT</pubDate>
    </item>
    <item>
      <title>非专家3D艺术家可以生成合成训练数据[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixvbln/can_a_nonexpert_3d_artists_generate_synthetic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我有一个医学成像用户酶。我想知道获得非专家3D艺术家是否有可能或可靠，为医学成像中的利基用户酶生成一些培训数据，而培训数据不容易获得。他们可以使用我想像的搅拌机等工具。有人有这样的经验吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/eapher-ecomony8403     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixvbln/can_a_nonexpert_3d_artists_generate_synthetic/</guid>
      <pubDate>Tue, 25 Feb 2025 13:44:47 GMT</pubDate>
    </item>
    <item>
      <title>[D]寻找ML / CV /信号处理黑客马拉松</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixujof/d_looking_for_ml_cv_signal_processing_hackathons/</link>
      <description><![CDATA[在他们都是比赛。这意味着它们比黑客马拉松长。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/neotod1     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixujof/d_looking_for_ml_cv_signal_processing_hackathons/</guid>
      <pubDate>Tue, 25 Feb 2025 13:07:13 GMT</pubDate>
    </item>
    <item>
      <title>[r] Kitab-Bench：一个多域基准测试揭示了阿拉伯语OCR的性能差距和文档理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixt9bo/r_kitabbench_a_multidomain_benchmark_reveals/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   kitab-bench介绍了跨越多个文档域和历史时期的第一个全面的阿拉伯OCR基准。基准包括6,000个注释的文档页面，并评估文本识别和文档理解能力。 关键技术方面： - 多阶段评估框架测试字符级别识别和布局分析 - 标准化指标，包括字符误差率（包括字符误差率（ CER）和单词错误率（WER） - 涵盖文本内容，布局结构和语义元素的详细注释 - 文档变化，包括现代印刷品，手稿，科学文本和宗教著作 - 测试处理阿拉伯特异性挑战，例如《变节标记和书法风格》  主要结果： - 现代印刷的阿拉伯文本达到95％+识别准确性 - 历史文档识别范围从60-- 80％的精度 - 布局分析性能始终低于文本识别 - 处理音量标记时的明显精度下降 - 文档理解能力滞后于基本OCR背后绩效 我认为，这种基准将通过提供清晰的性能指标并突出特定的技术挑战来帮助改善阿拉伯文档处理。包括历史文件对文化遗产保护工作尤为重要。 我认为发现指向需要工作的几个关键领域： - 更好地处理退化的历史文件 - 改善了对阿拉伯语的认识 - 更强大的布局。分析功能 - 增强的文档理解超出基本文本识别  tldr：首先综合阿拉伯OCR基准，覆盖了跨多个领域的6,000页。在现代文本上表现出强烈的表现，但历史文档和高级文档理解任务仍然存在重大挑战。 完整的摘要在这里。 Paper 在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ixt9bo/r_kitabbench_a_multidomain_benchmark_reveals/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixt9bo/r_kitabbench_a_multidomain_benchmark_reveals/</guid>
      <pubDate>Tue, 25 Feb 2025 11:55:30 GMT</pubDate>
    </item>
    <item>
      <title>[R]分析2024年400多个ML比赛</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixrxoq/r_analysis_of_400_ml_competitions_in_2024/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我运行mlcontests.com，一个网站，列出了来自多个平台的ML竞赛-Kaggle，drivendata，aicrowd，aicrowd，zindi等…… 我刚刚花了几个月的时间查看我在去年的比赛中找到的所有信息以及赢得解决方案。  我发现了去年发生的400多场比赛，以及其中70个获胜解决方案的信息。  一些亮点：    kaggle仍然是总奖金最大的平台，并且比其他平台拥有更大的用户群 - 尽管有超过十几个值得跟踪的其他平台，并进行了定期有趣的比赛和有意义的奖金。  竞争的增加100万美元+奖品池（ARC奖励， 人工智能与往年相比。一位获胜者使用Rust，两名使用R.   卷积神经网继续在计算机视觉竞赛中表现出色，在竞争赢家中仍然比基于变形金刚的视觉模型更为普遍。    pytorch的使用量大于tensorflow ，大​​约是9：1。没有发现任何竞争者在JAX或其他图书馆中实施神经网。   使用Automl软件包有一些竞赛冠军，似乎越来越有用。不过，通才自主的大师级特工的任何主张似乎还为时过早。   在语言/文本/序列相关的竞争中，定量是有效利用有限资源的关键。通常是4-，5或8位。 Lora/Qlora也经常使用，尽管并非总是如此。   促进梯度的决策树继续赢得许多表格/时间序列的比赛。他们通常会喜欢深度学习模型。据我所知，获奖者在2024年没有使用表格/时间序列的预训练基础模型。   开始看到更多的数据范围的极点摄入量，有7个获奖者在2024年使用Porars（从2023年的3次提高），而使用PANDAS则使用Porars。所有使用Polars的人仍然在代码的某些部分中使用了大熊猫。  就硬件而言，竞争获奖者几乎完全使用了NVIDIA GPU来训练他们的模型。一些人仅在CPU上接受培训，或者通过Colab使用了TPU。没有AMD GPU。 NVIDIA A100是获奖者中最常用的GPU。 100万美元以上的奖金泳池比赛中有两个是由使用8xH100节点进行培训的团队赢得的。不过，还有许多其他GPU：T4/P100（通过Kaggle笔记本电脑）或RTX 3090/4090/3080/3060等消费者GPU。一些花费了数百美元在云上计算以训练他们的解决方案。  一种新兴模式：使用生成模型创建其他合成训练数据以增强提供的训练数据。   完整报告中有更多详细信息，您可以在此处阅读（无付费墙）： https://mlconts.com/state-com/state-of-machine-learning-learning-competition--competition--2024?ref= MLCR    处理IMG XMM4YWG9H9LE1 ...   完整报告还具有：  深入了解ARC奖和AI数学奥林匹克运动会 赢得NLP/序列竞赛解决方案的概述 赢得解决方案中使用的Python软件包的细分（例如，各种相对普及梯度增强的树库）  如果您想支持这项研究，我将非常感谢您与其他可能会发现它有趣的人分享。您还可以查看我新发射的在线杂志， jolt Ml   - 在顶级ML会议和长阅读文章中提供新闻（到目前为止，还有更多！）。  感谢竞争获奖者分享了有关其解决方案的信息，也感谢竞争平台分享了有关比赛的高级数据。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/hcarlens   href =“ https://www.reddit.com/r/machinelearning/comments/1ixrxoq/r_analsisy_of_400_ml_ml_competitions_in_2024/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixrxoq/r_analysis_of_400_ml_competitions_in_2024/</guid>
      <pubDate>Tue, 25 Feb 2025 10:28:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] CVPR 2025结束决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixpu28/d_cvpr_2025_final_decision/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  亲爱的社区成员， 标题所建议的，此线程适用于所有等待CVPR的25个结果的人。我敢肯定，你们现在都感觉到肚子里的蝴蝶。因此，让我们在整个过程中互相支持并讨论结果。现在不到24小时，我期待在此线程中进行令人兴奋的互动。  P.S。我的评分为4,3,3，平均信心为3.67。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/stantheta   href =“ https://www.reddit.com/r/machinelearning/comments/1ixpu28/d_cvpr_2025_final_decision/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixpu28/d_cvpr_2025_final_decision/</guid>
      <pubDate>Tue, 25 Feb 2025 07:57:20 GMT</pubDate>
    </item>
    <item>
      <title>[d]为GRPO设计奖励功能：超越单人答案任务到长形响应？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixj59s/d_designing_a_reward_function_for_grpo_moving/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿 r/machinelearning ！！ p&gt; 我一直在用GRPO微调一个小的LLM，以完成单个正确答案的任务（例如，诸如求解3x + 5 = 20的数学问题）。在这里，我使用了一个直接的奖励功能： 如果最终答案与地面真相相匹配，则为0。这效果很好，但是现在我坚持将其推广到其他域中的开放式，长格式的问题，而没有单一的“正确”。回答。  在这种情况下，设计奖励的鲁棒策略是什么？   我已经研究了BertScore和LLM-AS-A-Gudge等指标（例如GPT-4评分相干），但我不确定如何平衡自动指标与潜在偏见。    纸张，工具或实验中的课程将不胜感激！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aadityaura     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixj59s/d_designing_a_reward_function_for_grpo_moving/</guid>
      <pubDate>Tue, 25 Feb 2025 01:34:34 GMT</pubDate>
    </item>
    <item>
      <title>[P]用于检测图像食物的开源神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixaw8w/p_opensource_neural_network_for_detecting_food_on/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  寻找用于图像上的食物（餐点）的神经网络。在HuggingFase和Google上没有发现任何合适的事情。您知道要应用的预训练的神经网络还是我可以在哪里寻找它？考虑一下Wast Resources   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/unewereate_teach23     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixaw8w/p_opensource_neural_network_for_detecting_food_on/</guid>
      <pubDate>Mon, 24 Feb 2025 19:41:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025时间表尚未发布 - 我们什么时候可以期待？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ix9lnb/d_iclr_2025_schedule_not_released_yet_when_can_we/</link>
      <description><![CDATA[在海报。但是我试图弄清楚时间表，但尚未发布。 我们的日程安排很紧，因为我直接来自日本，我可能不会能够在24日到达。有人知道这是否是问题吗？在到达时间方面通常认为还可以的是什么？有人听到何时可用的详细时间表吗？ 很想听听有经验的人 - 谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/upaster-ability-774     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ix9lnb/d_iclr_2025_schedule_not_not_yet_yet_yet_yet_yet_yet_yet_yet_yet_when_when_can_we/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ix9lnb/d_iclr_2025_schedule_not_released_yet_when_can_we/</guid>
      <pubDate>Mon, 24 Feb 2025 18:49:28 GMT</pubDate>
    </item>
    <item>
      <title>[d]复制声音可能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ix8vpd/d_replicating_sounds_possible/</link>
      <description><![CDATA[在我喜欢的声音，最近我发现了Wavegan，但看来我需要使用许多圈套鼓的声音来训练它，这很难我发现的最接近的类比是我们现在可以使用10秒的源代码来克隆语音，我基本上需要类似的东西。 当前可能吗？   &lt;！ -  sc_on-&gt; ＆＃32;提交由＆＃32; /u/u/kzxrnx     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ix8vpd/d_replicating_sounds_possible/</guid>
      <pubDate>Mon, 24 Feb 2025 18:19:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] AVX512推理性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ix4czg/d_avx512_inference_performance/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  诸如ONNX Runtime和Llama.CPP支持AVX512指令集之类的框架。但是，我正在努力寻找有关这有多少改善推理性能的信息？有人知道任何基准或研究吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/peppergrind     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ix4czg/d_avx512_inference_performance/</guid>
      <pubDate>Mon, 24 Feb 2025 15:15:45 GMT</pubDate>
    </item>
    <item>
      <title>[r] 200个用于LLM Finetuning的组合身份和定理数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ix473t/r_200_combinatorial_identities_and_theorems/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  一个数据集可帮助LLMS回忆起对组合物质很重要的定理和身份。关键的见解是，LLM擅长记忆和基本成就，在数字理论和组合学的交集中需要深刻的，有些深奥的知识对晦涩的身份。  数据集元素：    entryNumber ：身份或定理的参考号。    descrigment /strong&gt;：组合身份或定理的平坦文本描述。  标签：找到相关组合身份的标签列表。  乳胶：代表身份的乳胶字符串。   imagelink ：链接到身份的png图像。  引用：身份的来源。   codeSample  ：（如果可用）python或c的身份示例。   所有来源都在数据集中引用。 完整的数据集在这里。    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/databaebee     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ix473t/r_200_combinatorial_identities_and_theorems/</guid>
      <pubDate>Mon, 24 Feb 2025 15:08:29 GMT</pubDate>
    </item>
    <item>
      <title>[r]通过强化学习和结构化推理，培训LLMS严格的JSON模式遵守</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iwxtmb/r_training_llms_for_strict_json_schema_adherence/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  使LLMS输出有效JSON的一种新方法将强化学习与模式验证奖励相结合。关键见解是使用架构本身作为训练信号，而不是需要大量的示例数据集。 主要技术点： * 奖励模型体系结构验证JSON结构和模式合规性培训期间的实时 *使用深度强化学习来帮助模型内部化格式化规则 *除了模式规格之外，无需其他培训数据 *跨不同模型体系结构（对GPT变体和Llama模型进行了测试） *实施在推理期间增加了最小的计算开销 结果： * 98.7％有效的JSON输出率（高于82.3％的基线） * 47％的架构验证错误的降低47％没有明显降级的功能 我认为这种方法可以使LLMS对于结构化数据输出至关重要的现实世界应用程序更可靠。在没有大量培训数据的情况下执行模式合规的能力对于部署方案特别有价值。 我认为，这里的真正创新是将架构本身用作培训信号。这比试图策划有效示例的大量数据集更优雅的解决方案。当前的结果侧重于相对直接的JSON结构。  tldr：新的强化学习方法使用模式验证作为奖励，以训练LLMS以98.7％的精度输出有效的JSON，而无需其他培训数据。    完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iwxtmb/r_training_llms_for_strict_json_schema_adherence/</guid>
      <pubDate>Mon, 24 Feb 2025 09:03:44 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iwdbgs/d_simple_questions_thread/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 23 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      对于那些寻找工作的人请使用此模板  &lt; p&gt;想要被录用：[位置]，薪水期望：[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简短概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，这个社区是适合有经验的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>