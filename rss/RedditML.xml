<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 18 Dec 2024 06:24:52 GMT</lastBuildDate>
    <item>
      <title>[P] ML成本优化项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgu3tu/p_ml_cost_optimization_project/</link>
      <description><![CDATA[AI 工程师：您目前如何监控和优化 LLM 的训练和推理成本？我正在探索一种工具，该工具可以跟踪特定于 AI 的成本（例如，GPU 使用情况、训练时间）并建议使用 Spot 实例或量化等优化。  我很想听听您今天的处理方式，以及这样的事情是否对您有价值。任何反馈或见解都将不胜感激 - 请随时在此处回复或直接发消息给我！    提交人    /u/jev3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgu3tu/p_ml_cost_optimization_project/</guid>
      <pubDate>Wed, 18 Dec 2024 04:49:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我想很快分享一个视频，介绍我的 Alpha 如何模仿甚至超越 Rentec 处理奖章基金的主要模型的性能。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgtwb6/d_i_wanna_share_a_video_soon_on_how_my_alpha/</link>
      <description><![CDATA[是的，你们说得对！这是我寻找买家或投资者，或通过合作伙伴关系筹集大量资金的方法之一。（我的最终目标是拥有资本，或成为对冲基金的合伙人） 我刚刚完善了我的主要模型（旨在交易黄金[XAUUSD]）——保证每年增长 50% 或更高。为什么保证？因为在我所有的回测和前向测试中，它从未失败过 70% 的回报，甚至有几次在不到一年的时间内能够提供 100% 以上的回报。所以，50% 已经调整。风险也非常小，因为该模型能够适应最新的数据馈送并做出相应的反应。无论如何，它是一种复杂的机器学习算法。旨在对价格行为做出反应（就像 rentec 一样）。 这就是我想通过录制的视频制作的关于模型如何运行、执行和实时交易的文档，以便每个人都可以看到实际结果、增长和表现。 我还有很多即将推出的类似模型，旨在交易股票、外汇、加密货币和其他工具。 老实说，这个项目很大，未来几年可能价值数十亿美元。但我的问题是资金。 如果您认为这好得令人难以置信，那么请自己观看表现，它将每周更新和发布。 所以这就是我在这里发布这个的原因，我来这里是为了问我应该在哪里发布视频和更新。 我认为它会这样做：每个周末，我都会发布一段关于算法交易的录制视频，以及更新的 PnL 和其他重要指标 &amp;整体表现。 有没有办法发布主题——比如在 Reddit 上？还是我应该将其发布到其他地方，比如 YouTube 或其他平台？ 我需要尽快开始，因为算法已经在运行并且实时。    提交人    /u/Routine_Noize19   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgtwb6/d_i_wanna_share_a_video_soon_on_how_my_alpha/</guid>
      <pubDate>Wed, 18 Dec 2024 04:36:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于添加一些你实际上还没有做过但在工作中完全有能力完成的事情，有什么建议吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgtd8l/d_any_suggestions_on_adding_stuff_youve_not/</link>
      <description><![CDATA[简历造假当然是道德败坏的行为，但我遇到了一些业内人士，他们承认他们在简历中添加了一些东西并找到了工作。  我认为在这里和那里添加一些项目肯定会帮助我的团队匹配某个 MAG7。  帖子是关于一般性讨论以及这种情况有多普遍？    提交人    /u/GaussianGuessGamer   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgtd8l/d_any_suggestions_on_adding_stuff_youve_not/</guid>
      <pubDate>Wed, 18 Dec 2024 04:06:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICASSP 2025 最终决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgsj0u/d_icassp_2025_final_decision/</link>
      <description><![CDATA[ICASSP 2025 结果将于今天公布。这个社区里有人兴奋吗？我有 3 个 WA，期待结果。如果你知道任何事情，请告诉我！    提交人    /u/stantheta   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgsj0u/d_icassp_2025_final_decision/</guid>
      <pubDate>Wed, 18 Dec 2024 03:19:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从招聘信息中提取技能的更好方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgkvrk/d_better_ways_to_extract_skills_from_job_postings/</link>
      <description><![CDATA[大家好！ 我正在构建一个带有实时数据平台的职位聚合器，该平台可提供深入的市场分析。我目前专注于改进从招聘信息中提取技能的方式。虽然我目前的提取设置可以达到约 90% 的准确率，但它在处理极端情况时会遇到困难，并且缺乏灵活性，尤其是当技能以意想不到的方式表述时。 1.问题：1.1：缺乏灵活性：系统仅捕获预定义的短语。如果招聘信息中说的是“熟练使用电子表格”之类的话或“具有高级报告工具经验”，则忽略了可能需要 Excel。 1.2：手动维护：随着项目的发展，不断更新 JSON 文件以考虑新的变化是繁琐且不可持续的。 2. 当前设置：2.1：基于关键字的提取：我维护一个包含预定义技能变化的 JSON 文件。示例：  &quot;programming_languages&quot;: { &quot;JavaScript&quot;: [&quot;javascript&quot;, &quot;js&quot; ...], ...  2.2：spaCy PhraseMatcher：我使用 PhraseMatcher 和 Matcher 进行高效的基于规则的提取。  约束：3.1：轻量级：我避免使用重型 ML 模型或资源密集型管道，以降低服务器成本。  3.2：灵活：我需要一个能够更好地处理同义词、上下文和意外措辞的解决方案，同时尽量减少手动输入。 3.3：免费或开源：理想情况下，我可以将其插入现有服务器设置而无需增加成本。  我的问题：4.1：我如何改进此过程以使其更强大且具有上下文感知能力？  4.2：您是否推荐使用轻量级工具、启发式方法或库来处理变体和语义相似性？ 4.3：预训练嵌入（例如 GloVe、FastText）或其他轻量级 NLP 方法在这里有帮助吗？ 我很乐意听取任何在 NLP 或信息提取方面解决过类似挑战的人的意见。任何关于平衡准确性、灵活性和计算效率的建议都将不胜感激！ 如果有人对我目前的市场分析感兴趣，我会留下一个链接供您分析https://careercode.it/market    提交人    /u/Grand_Capital804   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgkvrk/d_better_ways_to_extract_skills_from_job_postings/</guid>
      <pubDate>Tue, 17 Dec 2024 21:09:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 科学语言模型的连续数值标记化可提高分布外性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hghwfb/r_continuous_numerical_tokenization_for/</link>
      <description><![CDATA[本文介绍了一种名为xVal的新方法，该方法通过使用连续数值标记而不是离散标记来处理语言模型中的数值。关键创新是将数字表示为连续值，同时保留其数学关系，从而使模型能够更好地理解科学文本中的数字模式和关系。 关键技术要点： - 数字使用连续表示而不是离散标记进行编码 - 该方法保持排序和相对量级信息 - 自定义架构修改允许数字和文本处理的无缝集成 - 训练使用考虑数字关系的专门损失函数 - 在包含大量数字内容的科学数据集上进行测试 实验结果： - 与基线​​模型相比，数值推理任务的性能有所提高 - 更好地泛化到分布外的数值 - 初始训练后计算效率更高 - 增强了处理具有大量数字内容的科学文本的能力 - 科学语料库验证集上的困惑度分数更低 我认为这对语言模型的科学应用特别有影响。正确处理数字的能力对于论文分析、实验设计和数据解释等任务至关重要。尽管以前的方法在处理数值关系时遇到了困难，但 xVal 提供了一种更自然的方式来处理上下文中的数字。 我认为真正的价值在于为科学研究提供更可靠的人工智能系统。当前的模型经常会犯数值错误，从而限制了它们在技术领域的实用性。这种方法可以帮助弥合这一差距。 TLDR：使用连续表示而不是离散标记处理语言模型中数字的新方法。显示出在科学任务上改进的性能和更好的数字推理能力。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hghwfb/r_continuous_numerical_tokenization_for/</guid>
      <pubDate>Tue, 17 Dec 2024 18:57:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可学习的掩蔽 token Vision Transformer</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgbgmh/d_learnable_masking_token_vision_transformer/</link>
      <description><![CDATA[大家好。我有一个用于 EEG 癫痫发作检测的数据集。输入是一个形状为 (22,289,251) 的多通道频谱图。由于数据集不平衡，我将进行 specaug 数据增强（时间、空间和频率掩蔽）对于分类，我想训练一个 VisionTransformer。我考虑尝试可学习的缺失标记，而不是用 (0,-1) 等常数值来掩盖缺失值。有人有这方面的经验吗？可以推荐一些好的论文或示例笔记本吗？非常感谢！    提交人    /u/Significant-Joke5751   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgbgmh/d_learnable_masking_token_vision_transformer/</guid>
      <pubDate>Tue, 17 Dec 2024 14:11:38 GMT</pubDate>
    </item>
    <item>
      <title>[R][D] 提炼不同学生和教师的 LLM 的可能的软标签有哪些？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg9qpm/rd_what_are_the_possible_soft_label_for/</link>
      <description><![CDATA[我想探索法学硕士 (LLM) 中的知识蒸馏。似乎有很多方法，但最简单的方法是学生只是老师的缩小版。但是，我想探索学生与老师的不同模型。首先，词汇量不同，当词汇集不同时，是否有一些技巧可以让我们用 KL 散度计算软标签的损失？在蒸馏过程中，我们可能希望将新词从教师模型引入学生模型。 我发现除了在这种情况下使用 KL 散度作为软损失之外，还有其他一些方法，甚至可以在黑盒教师设置中进行蒸馏。是否可以通过这种方式将新词引入学生的词汇表？谢谢    提交人    /u/worthlesspineapple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg9qpm/rd_what_are_the_possible_soft_label_for/</guid>
      <pubDate>Tue, 17 Dec 2024 12:39:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] SVGFusion：通过向量空间扩散实现可扩展的文本到 SVG 生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg87em/r_svgfusion_scalable_texttosvg_generation_via/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg87em/r_svgfusion_scalable_texttosvg_generation_via/</guid>
      <pubDate>Tue, 17 Dec 2024 10:58:36 GMT</pubDate>
    </item>
    <item>
      <title>“[讨论]” “[D]” 介绍 TLR：通过共享学习在三个环境中同时训练 AI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg5siv/discussion_d_introducing_tlr_training_ai/</link>
      <description><![CDATA[TL;DR：我开发了TLR（三层训练），这是一个强化学习框架，可同时在三个环境中训练单个代理，同时分享经验以增强学习。它产生了我从未见过的积极回报——例如月球着陆器！欢迎反馈和想法。 大家好！ 👋 我想分享一些我一直在研究的东西：三层训练 (TLR)——一种新颖的强化学习框架，允许 AI 代理同时在三个环境中进行训练。 什么是 TLR？  TLR 一次在三个不同的环境中训练单个代理： 推车杆：简单的平衡任务。 月球着陆器：基于物理控制的精确着陆。 太空侵略者：动态游戏中的战略反应。  代理使用共享重放缓冲区来汇集这些环境中的经验，使其能够从一个环境中学习并将见解应用于另一个环境。 TLR 集成了高级 DQN 变体：标准 DQN、双 DQN（月球登陆器）和决斗 DQN（太空侵略者）。 优先重放：专注于关键转换以实现高效学习。 分层学习：跨环境逐步构建技能。   为什么 TLR 令人兴奋？  跨环境协同：代理通过利用来自另一项任务的知识来改进一项任务。 积极的结果：我在包括月球登陆器在内的所有三个环境中都看到了积极的回报，这是我以前从未实现过的！ 它突破了泛化的界限和多领域学习——我还没有见过广泛实施的东西。  它是如何工作的？  来自所有三个环境的经验被组合成一个共享重放缓冲区，以及特定于环境的缓冲区。 代理使用适合环境的算法进行调整（例如，用于月球着陆器的 Double DQN）。 训练在各个环境中同时进行，鼓励广义学习和技能转移。  下一步 我已经将 PPO 集成到月球着陆器环境中，并计划接下来添加好奇心驱动的探索 (ICM)。我相信这可以扩展到更复杂的任务和环境。 结果和代码 如果有人好奇，我已经在 GitHub 上分享了框架。 https://github.com/Albiemc1303/TLR_Framework-.git 您可以在那里找到示例日志和结果。我很乐意就方法或改进建议提供反馈！ 讨论问题  您见过类似的多环境 RL 实现吗？ 哪些其他环境或技术可以使 TLR 受益？ 如何扩展共享经验缓冲区以用于更通用的 AI 系统？  期待听到您的想法和反馈！我对 TLR 迄今为止的表现感到非常兴奋，并希望其他人会觉得它很有趣。    提交人    /u/UndyingDemon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg5siv/discussion_d_introducing_tlr_training_ai/</guid>
      <pubDate>Tue, 17 Dec 2024 07:52:37 GMT</pubDate>
    </item>
    <item>
      <title>[P] Vision Parse：使用 Vision LLM 将 PDF 文档解析为 Markdown 格式的内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hg5d3p/p_vision_parse_parse_pdf_documents_into_markdown/</link>
      <description><![CDATA[嗨 Redditors， 我很高兴与大家分享 Vision Parse - https://github.com/iamarunbrahma/vision-parse，这是一个开源 Python 库，它使用视觉语言模型将 PDF 文档自动转换为格式完美的 markdown 内容。  将 PDF 文档中的每一页转换为高分辨率图像 使用 Vision LLM 从高分辨率图像中检测文本、表格、链接和图像并以 markdown 格式进行解析 轻松处理多页 PDF 文档 而且这个库很容易上手（只需pip install vision-parse，然后几行代码即可将文档转换为 markdown 格式的内容）。  我为什么构建这个？  传统的 PDF 到 markdown 转换工具通常难以处理复杂的布局、半结构化和非结构化的表格和格式。因此，依靠 Vision LLM 从图像中提取 markdown 中的内容（在这里，我将每个 PDF 页面转换为图像）。 使用传统的 OCR 和 PDF 到 markdown 转换工具，文档结构会失真。因此，使用生成式 AI 模型将有助于我们更好地理解结构并保存它。  您可以在此处找到开始使用此库的文档：https://github.com/iamarunbrahma/vision-parse/blob/main/README.md 查看此GitHub 项目 - Vision Parse并请向我提供您的反馈或任何建议。    提交人    /u/heliosarun   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hg5d3p/p_vision_parse_parse_pdf_documents_into_markdown/</guid>
      <pubDate>Tue, 17 Dec 2024 07:20:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用开放模型扩展测试时间计算！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hfw40o/r_scaling_testtime_compute_with_open_models/</link>
      <description><![CDATA[      嗨！我是 Lewis，Hugging Face 👋 的研究员。在过去的几个月里，我们一直在深入尝试逆向工程并重现几个关键结果，这些结果让 LLM 能够“思考更长时间”通过测试时计算，我们终于很高兴能分享一些我们的知识。 今天，我们将分享一篇详细的博客文章，介绍我们如何通过将分步奖励模型与树搜索算法相结合，在数学上超越 Llama 70B 和 Llama 3B： https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute 在博客文章中，我们涵盖了：  计算最优扩展：我们如何实施 u/GoogleDeepMind 的配方来提升测试时开放模型的数学能力。 多样化验证者树搜索 (DVTS)：我们为验证器引导树搜索技术开发的未发布的扩展。这种简单而有效的方法提高了多样性并提供了更好的性能，特别是在测试时间计算预算较大的情况下。 搜索和学习：一个轻量级工具包，用于使用 LLM 实施搜索策略，并使用 vLLM 加快速度。您可以在这里查看：https://github.com/huggingface/search-and-learn  很高兴回答问题！ https://preview.redd.it/cagfkzxria7e1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=34f3a45dd056da19a6b1e6f03a53ff8283df7ba7    由    /u/lewtun 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hfw40o/r_scaling_testtime_compute_with_open_models/</guid>
      <pubDate>Mon, 16 Dec 2024 22:55:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您今年读过的最喜欢的论文是什么？为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hfljy3/d_whats_your_favorite_paper_youve_read_this_year/</link>
      <description><![CDATA[多年没有发这个帖子了，但是假期旅行需求很大，很想有一个论文库可以在旅行期间阅读。    提交人    /u/bin_und_zeit   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hfljy3/d_whats_your_favorite_paper_youve_read_this_year/</guid>
      <pubDate>Mon, 16 Dec 2024 15:26:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</guid>
      <pubDate>Sun, 15 Dec 2024 16:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>