<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 01 Jan 2024 21:11:58 GMT</lastBuildDate>
    <item>
      <title>[P]自然的文本转语音，最好是免费的，可以选择使用 AMD GPU 在本地机器上训练语音吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18w5aca/pnatural_sounding_texttospeech_preferably_free/</link>
      <description><![CDATA[大家好， 我正在寻找一款优秀的文本转语音软件，其声音尽可能自然，最好可以选择在具有 AMD GPU 的本地计算机上进行训练。它没有“有”。基本上，到 2024 年，我需要完成大约 40 篇长篇论文，每篇都有大约 150,000 个字符或更多，基本上是关于我工作中的某些主题。这些项目需要有配音，因为它们将分发给某些视力障碍群体。 我检查过不少提供基于云的 TTS 的平台，但其中大多数都不是听起来不自然，或者定价完全超出了预期。到目前为止我发现的最好的是 genny.lovo.ai 和 ElevenLabs.ai，Genny 是两者中听起来更好的一个，但他们的定价都完全疯狂。基本上，对于任一平台，我都会考虑约 2,500-3,500 美元的定价来完成所有已计划的工作，但有可能会分配更多的工作，因此定价只会增加。 我的另一个选择我发现 Descript 具有免费增值功能，但他们的语音选择非常差，对于我的项目来说并不理想。 理想情况下，我希望能够在本地训练我自己的语音模型机，但问题是大多数模型，如 RVCv2、MangioRVC、ApollioRVC、TortoiseTTS 等需要具有 CUDA 支持的 GPU，又称为 Nvidia GPU。甚至在我的地区，像 1070 这样古老而破旧的东西每张卡也超过 300-400 美元（这里的经济已经被搞砸了）并且不是一个选择。 有谁知道是否存在任何像样的 TTS能够在 AMD GPU 上本地训练语音模型的软件，并且不会对项目施加长度大小限制？ 感谢您的帮助。   由   提交/u/X2ytUniverse  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18w5aca/pnatural_sounding_texttospeech_preferably_free/</guid>
      <pubDate>Mon, 01 Jan 2024 20:06:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要 MS 在 ML 方面的一些建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18w4pzp/d_need_some_advice_for_ms_in_ml/</link>
      <description><![CDATA[我今年打算加入一家公司（与 ML 无关），但我计划自学并在国外申请 MS一两年内进入机器学习领域。我觉得要正确地进入机器学习研究，我必须在数学先决条件上花费大量时间，而为此做准备不会让我有太多时间从事项目或论文。那么，如果我花一年时间掌握数学并只做基本的 ML（和 gre 内容）来申请 ML 硕士学位，这样可以吗？还是说这是一个坏主意，因为它会严重影响我的申请？ （主要关注 ML 的数学先决条件也能让我很好地尝试 GATE DS 和 AI 论文（这是印度顶尖大学 MS 课程的入学考试），这可能是另一个不错的选择，因为我可以做在印度获得硕士学位，如果可能的话，出国攻读博士学位或其他东西） P.S.：我理解采用自上而下的方法进行的想法，只学习一点数学知识，然后直接进入机器学习项目或并一路学习以加深我的表面知识。我可能会考虑，如果确实如此，在我的阶段，如果遵循自下而上的路线，微软的应用程序将会受到严重阻碍。我只是想知道自下而上的路线是否可能不会对我的 MS 应用程序产生太大影响，因为它会让我更加满意和自信地学习，因为我知道自己在做什么。   由   提交 /u/aliaslight   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18w4pzp/d_need_some_advice_for_ms_in_ml/</guid>
      <pubDate>Mon, 01 Jan 2024 19:42:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] LARP：开放世界游戏的语言代理角色扮演</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18w3am0/r_larp_languageagent_role_play_for_openworld_games/</link>
      <description><![CDATA[项目页面： https://miao-ai-lab.github.io/LARP/ 论文： https://miao-ai-lab.github.io/LARP/static/LARP.pdf 代码： https://github.com/MiAO-AI-Lab/LARP 摘要：  语言代理在规定的环境和短暂的时间内表现出了令人印象深刻的解决问题的能力。然而，随着开放世界模拟的复杂性不断发展，迫切需要能够灵活适应复杂环境并持续保持长期记忆以确保连贯行动的智能体。为了弥合语言代理和开放世界游戏之间的差距，我们引入了角色扮演语言代理（LARP），其中包括一个包含记忆处理和决策助理的认知架构，一个具有反馈驱动的可学习动作的环境交互模块空间，以及促进各种个性对齐的后处理方法。 LARP 框架完善了用户和代理之间的交互，预定义了独特的背景和个性，最终增强了开放世界环境中的游戏体验。此外，它还强调了语言模型在娱乐、教育和各种模拟场景等一系列领域的多样化用途。    由   提交 /u/FreeKingBoo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18w3am0/r_larp_languageagent_role_play_for_openworld_games/</guid>
      <pubDate>Mon, 01 Jan 2024 18:42:59 GMT</pubDate>
    </item>
    <item>
      <title>有哪些语音转文本 API（例如耳语）？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18w307c/what_are_some_speech_to_text_apis_like_whisper_d/</link>
      <description><![CDATA[所以我需要为我的项目提供语音转文本功能。它需要多语言（特别是印地语和英语），我使用过耳语 - openAI 和它的拥抱脸版本。基础版本和中等版本效果最好，因为我需要高精度和快速响应。但问题是，当我使用英语以外的语言时，基础版本比我想要的更不准确。另一方面，Medium 具有出色的准确性，但需要太长时间任何人都可以建议我任何最好免费使用的替代方案吗？    由   提交 /u/Hades_Kerbex22   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18w307c/what_are_some_speech_to_text_apis_like_whisper_d/</guid>
      <pubDate>Mon, 01 Jan 2024 18:30:43 GMT</pubDate>
    </item>
    <item>
      <title>[D]寻求建议：预测模型部署？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18w27mi/d_seeking_advice_prediction_model_deployment/</link>
      <description><![CDATA[我在一家约 500 人的公司的小型 DS 团队中担任数据科学家，我开发了一个面向客户的预测模型。我预计每日活跃用户数量在 100 到 2000 之间，并且我需要在云上部署此模型以确保无缝访问。该模型从实时数据管道和用户输入中获取输入。 我的背景主要是数学，因此虽然我对模型本身充满信心，但部署方面有点超出了我通常的掌控范围。我正在寻找有关在云或服务器上部署模型的最佳实践的建议或见解，特别是考虑到潜在用户的规模。   由   提交 /u/Cyraxess   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18w27mi/d_seeking_advice_prediction_model_deployment/</guid>
      <pubDate>Mon, 01 Jan 2024 17:56:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 面向任务的法学硕士系统设计中的可能性暴政：范围界定调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18w09hn/r_the_tyranny_of_possibilities_in_the_design_of/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18w09hn/r_the_tyranny_of_possibilities_in_the_design_of/</guid>
      <pubDate>Mon, 01 Jan 2024 16:29:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 基于项目的指导计划</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vz81j/p_project_based_mentorship_program/</link>
      <description><![CDATA[我是一家 F500 公司的数据科学总监，拥有近 10 年探索该领域的经验。我从导师那里受益匪浅，他们加深了我在这一领域的知识并在我的职业生涯中成长。  我希望通过启动 DS 导师小组（无偿）来回报这一努力，并且在最近成为 Kagglex 的导师后受到启发，开始了这个项目。我正在招募来自其他公司的导师，包括 Google、Robinhood、JPMC 和 YC 初创公司。 这将是一个为期 8 周的基于项目的指导计划，其结果将是在某个领域交付一个机器学习项目受训者的选择。  目标学员 - 拥有最多 2 年经验的早期职业数据科学家或试图进入该领域的研究生。 学员时间承诺 - 每周 8-10 小时该计划为期 8 周。 该计划的执行方式将让受训者在实践学习方面有明确的收获，并且受训者将在他们的投资组合中获得一个新的 DS/ML 项目，并且扩大的指导网络。  有兴趣吗？私信我，告诉我你为什么想做这个项目以及你的项目的一些想法。想法可以与导师一起迭代，所以现在不需要完全讨论！  由于这是该计划的第一批学员，因此我将其限制为 5 名学员。   由   提交/u/Moist_Onion_6440   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vz81j/p_project_based_mentorship_program/</guid>
      <pubDate>Mon, 01 Jan 2024 15:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 赚取被动收入的数据科学家，你是做什么的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vxts1/d_data_scientists_who_made_a_passive_income_what/</link>
      <description><![CDATA[除了朝九晚五的常规工作之外，已成功建立被动收入来源的数据科学家和机器学习人员：您是如何做的以及做了什么？我真的很好奇我们领域的专业人士利用他们的技能来产生额外收入的不同方式。 无论是简单的机器学习应用程序、微服务、独特的服务产品、自由项目还是任何其他项目方法，我很想听听你的故事。你是怎么想到这个主意的？您如何平衡这与您的全职工作？您面临着什么样的挑战？ 编辑：by“被动”我的意思并不一定是字面上的意思——副业也很有趣。真正通过 DS 能力获得收入的东西。   由   提交 /u/Fendrbud   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vxts1/d_data_scientists_who_made_a_passive_income_what/</guid>
      <pubDate>Mon, 01 Jan 2024 14:29:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们没有更有趣的激活函数？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vwpk2/d_why_dont_we_have_more_interesting_activation/</link>
      <description><![CDATA[没有太多证据表明生物神经网络具有不寻常的激活函数（例如 mod n），但有如此多的连接，其连接方式可能不同我们做激活函数和注意力，谁能知道？我不认为极强的负抑制权重可以起到这个作用；拥有一个全有或全无的 mod 函数是不同的，它可能无法在负权重梯度上学习。当我在 2015 年被人工神经网络捕获时，原因是像随机神经元被移除（像人类一样！）这样的属性，这种技术本质上（修剪）类似于混沌工程的非智能随机形式。那么是否有可能，就像我们拥有使神经网络中的计算更加有效的技术一样，我们可以应用更多作为数学捷径的技术？一切都必须有梯度吗？ 这个帖子让我思考：是否有很多研究试图将不寻常的激活函数与合理大小或基于激活的网络结合起来？对此有任何直觉吗？   由   提交/u/Lumpy-Ad2724  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vwpk2/d_why_dont_we_have_more_interesting_activation/</guid>
      <pubDate>Mon, 01 Jan 2024 13:25:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大型“动作”模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vuzl0/d_large_action_models/</link>
      <description><![CDATA[嗨。我正在研究动态环境中自主代理的指令解释和复杂规划，我发现了几篇有趣的论文，例如 FILM 和类似的架构代理。 但是，似乎许多现代解决方案都依赖于语言处理来分解高级任务，例如“清洁盘子并将其收起来”等。进入“拿起盘子，将盘子放入水槽，使用水槽，拿起盘子，放入储藏室”。特别是在链接论文中，他们使用 BERT 模型来实现这一点。虽然这似乎表现良好，但我不禁想知道是否有比使用语言更有效的计划方法。 使用它来解释口头指令的任务是有意义的，但是至于实际的计划以及行动与结果的联系，我无法确定语言是否是一种理想的媒介。我想，一个能够以某种形式将事件与其他事件（在某些上下文中和某些参数，例如电影论文中的“对象”和“接收者”参数）关联起来的代理，而不必将其与语言联系起来可能会执行更好的。我还发现实验涉及将强化学习与常规旧HIP算法相结合，但尽管这些最终表现比普通算法更好强化学习（毫不奇怪），它们落后于上述基于语言的规划器。 有没有人研究过教导智能体探索和建立动作之间联系的方法，使它们能够在动态环境中表现良好，而无需与 HIP 一样手动指定所有内容，同时能够构建长期、复杂的行动计划，这是大多数 RL 实现遇到的困难？    由   提交/u/NightestOfTheOwls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vuzl0/d_large_action_models/</guid>
      <pubDate>Mon, 01 Jan 2024 11:31:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] StrategyQA 包含的错误可能比我们之前想象的要多得多</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vtvqt/d_strategyqa_may_contain_far_more_errors_than_we/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vtvqt/d_strategyqa_may_contain_far_more_errors_than_we/</guid>
      <pubDate>Mon, 01 Jan 2024 10:12:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士会完全取代外语翻译服务吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18voi9s/d_will_llms_completely_replace_foreign_language/</link>
      <description><![CDATA[传统上，外语翻译服务似乎依赖于语法和意义的绝对解构和重建，但像 OpenAI 这样的法学硕士似乎能够处理这没有任何复杂性。 这是否意味着法学硕士非常适合这种替代，因此传统的语言翻译技术不再适用？   由   提交 /u/lorenzomofo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18voi9s/d_will_llms_completely_replace_foreign_language/</guid>
      <pubDate>Mon, 01 Jan 2024 04:00:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将 nanoGPT 移植到 Apple 新的 MLX 框架：Macbook M3 Pro GPU 上的早期结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vhvl1/p_ported_nanogpt_to_apples_new_mlx_framework/</link>
      <description><![CDATA[嘿，ML 爱好者们， 我一直在从事一个令人兴奋的项目，希望与你们分享我的进展。我成功地将 Andrej Karpathy 的 nanoGPT 框架移植到 Apple 的新机器学习框架 MLX 中。这为在 Mac GPU 上运行 GPT 模型提供了一些有趣的可能性。代码：https://github.com/vithursant/nanoGPT_mlx  详细信息：  硬件： Macbook M3 Pro，配备 11 核 CPU，14-核心GPU，18GB统一内存 性能：在莎士比亚数据集上以0.37次迭代/秒的速度预训练45M参数字符级GPT-2模型。 &lt; li&gt;配置：  批量大小：64 本地批量大小：4 序列长度：256 &gt;   当前状态：  支持莎士比亚和 OpenWebText 的预训练 代码库仍在开发中。 寻找反馈、建议和潜在合作者。  向社区提出的问题：&lt; /p&gt;  是否有其他人尝试过使用 MLX 并经历过类似或不同的结果？ 对于优化 Mac GPU 性能有什么建议吗？ 对潜在应用的思考或改进？  我很高兴听到您的想法，并可能与有兴趣探索 Apple MLX 功能的其他人合作。请随意查看代码并分享您的见解！   由   提交/u/brownmamba94  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vhvl1/p_ported_nanogpt_to_apples_new_mlx_framework/</guid>
      <pubDate>Sun, 31 Dec 2023 21:43:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么目前的法学硕士在离散空间中效果很好，但在连续空间中效果不佳？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vfj7k/d_why_do_current_llms_work_well_in_discrete_space/</link>
      <description><![CDATA[一个有趣的观察是，LM 被训练来预测分类分布上的标记，然后使用采样算法来离散化分布以产生输出。如果我们在连续域中尝试此操作，例如，直接使用 L2 损失来预测像素，则它不起作用，输出会变得非常模糊。似乎通过采样进行离散化对于推理过程中的工作至关重要。最近的论文，如 GIVT 可以将输出建模为高斯混合而不是分类分布，但仍然需要采样才能使其发挥作用。  我确信这不是新的观察结果，是否有任何资源可以帮助解释为什么会出现这种情况？   由   提交 /u/Hyperarticles   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vfj7k/d_why_do_current_llms_work_well_in_discrete_space/</guid>
      <pubDate>Sun, 31 Dec 2023 19:48:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>