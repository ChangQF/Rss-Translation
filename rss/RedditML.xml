<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 18 Nov 2024 15:18:57 GMT</lastBuildDate>
    <item>
      <title>[D] 寻求可用于生产的维度提取的最佳方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gu53ui/d_seeking_input_on_optimal_approach_for/</link>
      <description><![CDATA[[D] 大家好， 我一直在研究下面的问题。我正在处理一组包含各种工程图和不同组件的大型文档，我们需要从这些图纸中的组件中提取与尺寸相关的信息。工程图包含一个或多个组件。首先，重要的是识别组件（我们没有关于工程图中位置的任何信息），然后提取组件各部分上的尺寸。 示例数据集 - Kaggle 问题： - 实体数量将来可能会增加。 - 工程图上没有组件的名称。 - 只能通过其形状和结构来识别组件。 我想问一下，如果您处于我的位置，您会选择哪种方法？任何关于最佳生产方法的反馈都将不胜感激。    提交人    /u/Future-Outcome3167   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gu53ui/d_seeking_input_on_optimal_approach_for/</guid>
      <pubDate>Mon, 18 Nov 2024 13:49:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 动态学习率问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gu2u1l/d_dynamic_learning_rate_question/</link>
      <description><![CDATA[这里我开始了一系列可能很傻的问题，我忍不住要发布它们。 这个问题是关于处理不平衡的数据集，例如，一个标记图像，其中一些类别有很多样本，而其他类别的样本很少。 根据当前样本的类别在数据集中出现的频率来调整学习率有帮助吗？我的意思是，对于出现频率较低的样本，学习率要高一些，而出现频率较高的类别，学习率要低一些 在下一个词预测模型 (llm-s) 中，这意味着当当前词非常常见时，学习率要低一些，而当当前词出现频率稀少时，学习率要高一些。    提交人    /u/blimpyway   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gu2u1l/d_dynamic_learning_rate_question/</guid>
      <pubDate>Mon, 18 Nov 2024 11:41:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与其他人一起预订 GPU 的系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gu1jfx/d_booking_system_for_gpu_with_other_people/</link>
      <description><![CDATA[大家好， 我和我的朋友正在做一个项目：我们可以使用 GPU，我们希望确保我们每个人都可以在需要时使用 GPU。您知道任何允许我们预订时间段的应用程序吗？本质上，我们正在寻找一个方便且易于使用的共享日历。 谢谢大家！    提交人    /u/SupertrampDFenx   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gu1jfx/d_booking_system_for_gpu_with_other_people/</guid>
      <pubDate>Mon, 18 Nov 2024 10:10:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据集管理工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtzh8r/d_dataset_management_tool/</link>
      <description><![CDATA[大家好， 我们公司有很多部门，数据集遍布各处，我们希望找到某种工具，可以用作数据集的中央存储库。像 hugging face 这样可以显示下载次数/受欢迎程度、简短摘要、过滤/排序功能、添加自述文件功能等的工具就很棒了： https://huggingface.co/datasets  有谁知道有产品提供这种我们可以购买和使用的界面吗？具有 Microsoft SSO 功能的产品也很棒。理想情况下，这种产品不仅工程师可以查看/编辑，而且非技术产品所有者也可以使用。 提前致谢。    提交人    /u/alek5k   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtzh8r/d_dataset_management_tool/</guid>
      <pubDate>Mon, 18 Nov 2024 07:29:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 优化模糊场景中问答机器人的上下文提取</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtzcuj/d_optimizing_context_extraction_for_qa_bots_in/</link>
      <description><![CDATA[我正在构建一个问答机器人来回答基于大量原始文本的问题。 为了优化性能，我使用嵌入来提取原始文本的一小部分相关子集，而不是将整个文本发送到 LLM。此方法适用于以下问题：  “谁会在这场比赛中获胜？”  在这种情况下，嵌入可以有效地提取文本的正确子集。 但是，它在处理以下问题时会遇到困难：  “你之前的陈述是什么意思？”  在这里，嵌入无法提取相关子集。 我们以以下格式维护对话历史记录：  previous_messages = [ {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message1}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: message2}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message3}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: message4}, ]  但是，在遇到此类问题时，我们不确定如何提取正确的原始文本子集以作为上下文发送。 在这些情况下，将整个原始文本作为上下文发送会更好吗？    由    /u/yccheok 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtzcuj/d_optimizing_context_extraction_for_qa_bots_in/</guid>
      <pubDate>Mon, 18 Nov 2024 07:21:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] AnyModal：用于多模态法学硕士 (LLM) 的 Python 框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtw77c/p_anymodal_a_python_framework_for_multimodal_llms/</link>
      <description><![CDATA[AnyModal 是一个模块化且可扩展的框架，用于将各种输入模式（例如图像、音频）集成到大型语言模型 (LLM) 中。它使用针对各种模式的预训练模型实现无缝标记、编码和语言生成。我创建 AnyModal 是为了解决现有资源中用于设计视觉语言模型 (VLM) 或其他多模式 LLM 的空白。虽然有用于特定任务的出色工具，但没有一个可以轻松将不同输入类型与 LLM 相结合的统一框架。 AnyModal 旨在通过简化添加新输入处理器和标记器的过程，同时利用预训练语言模型的优势来填补这一空白。 示例用法 from transformers import ViTImageProcessor, ViTForImageClassification from anymodal import MultiModalModel from vision import VisionEncoder, Projector # 加载视觉处理器和模型 processing = ViTImageProcessor.from_pretrained(&#39;google/vit-base-patch16-224&#39;) vision_model = ViTForImageClassification.from_pretrained(&#39;google/vit-base-patch16-224&#39;) hidden_​​size = vision_model.config.hidden_​​size # 初始化视觉编码器和投影仪 vision_encoder = VisionEncoder(vision_model) vision_tokenizer = Projector(in_features=hidden_​​size, out_features=768) # 加载 LLM 组件 from transformers import AutoTokenizer, AutoModelForCausalLM llm_tokenizer = AutoTokenizer.from_pretrained(&quot;gpt2&quot;) llm_model = AutoModelForCausalLM.from_pretrained(&quot;gpt2&quot;) # 初始化 AnyModal multimodal_model = MultiModalModel( input_processor=None, input_encoder=vision_encoder, input_tokenizer=vision_tokenizer, language_tokenizer=llm_tokenizer, language_model=llm_model, input_start_token=&#39;&lt;|imstart|&gt;&#39;, input_end_token=&#39;&lt;|imend|&gt;&#39;, prompt_text=&quot;给定图像的解释是：&quot; )  AnyModal 提供了一个统一的框架，用于将来自不同模态的输入与 LLM 相结合。它抽象了许多样板，让用户可以专注于他们的特定任务，而不必担心低级集成。与现有工具（如 Hugging Face 的转换器或特定于任务的 VLM，如 CLIP）不同，AnyModal 为任意模态组合提供了灵活的框架。它非常适合小众多模态任务或需要自定义数据类型的实验。 当前演示  LaTeX OCR 胸部 X 光字幕（进行中） 图像字幕 视觉问答（计划中） 音频字幕（计划中）  该项目仍在进行中，我很乐意收到社区的反馈或贡献。无论您是想添加新功能、修复错误还是仅仅尝试一下，我们都欢迎您提供任何意见。 GitHub repo：https://github.com/ritabratamaiti/AnyModal 请告诉我您的想法或任何疑问。    提交人    /u/Alternative_Detail31   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtw77c/p_anymodal_a_python_framework_for_multimodal_llms/</guid>
      <pubDate>Mon, 18 Nov 2024 04:02:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 还在研究论文中迷失？Ribbit Ribbit 进军 Web 和 Android！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtvmpn/p_still_drowning_in_research_papers_ribbit_ribbit/</link>
      <description><![CDATA[      嘿朋友们！上个月，我们分享了 Ribbit Ribbit，这是我们在 iOS 上的小型研究论文发现工具，哇哦，非常感谢您的喜爱！在过去的几周里，我们一直在努力将它带到更多地方，现在我们很高兴与大家分享：  完整网站 https://ribbitribbit.co 现已上线！它具有应用程序的所有功能。您可以在大屏幕上浏览论文以获得额外的清晰度，也可以将其放在手机上随时随地浏览 - 以您的方式进行研究！ Android 即将推出！它可通过 Google Play 测试获得。 Google 需要足够的测试人员才能上线，因此，如果您愿意尽早试用，请加入我们的测试人员小组：https://ribbitribbit.co/request?testandroid=true。您绝对会成为我们的英雄！  Ribbit Ribbit 可帮助您找到个性化的论文推荐，将其缩小为推文大小的摘要，甚至像播客一样读给您听。我们只是想让整个研究过程变得更有趣。我们希望您能查看一下。您的支持对我们意义重大！ https://preview.redd.it/hyf9e6rmxk1e1.png?width=1492&amp;format=png&amp;auto=webp&amp;s=9a4deb6f3b70c9cf79d3441846ee03d6d6b93d22    提交人    /u/haoyuan8   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtvmpn/p_still_drowning_in_research_papers_ribbit_ribbit/</guid>
      <pubDate>Mon, 18 Nov 2024 03:31:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对机器学习工程职位的期望</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtt099/d_expectation_from_machine_learning_engineering/</link>
      <description><![CDATA[大家好， 我在这里看到了很多关于 ML 职业和实习或工作机会的帖子，有两件事经常出现  建立强大的研究作品集，并在 NeurIPS、ICLR 和 ICML 等会议上发表文章，这些会议似乎更侧重于获得研究科学家的职位。 对机器学习工程师 (MLE) 职位的需求不断增长，显然比研究科学家职位更受欢迎。  我很好奇这两个角色之间的区别，以及什么样的作品集对于获得 MLE 职位来说是理想的。我知道拥有硕士学位通常是首选，但令人印象深刻的出版记录对 MLE 职位来说是必要的吗？或者这不是什么大问题？ 你怎么看？   由    /u/ziggyboom30  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtt099/d_expectation_from_machine_learning_engineering/</guid>
      <pubDate>Mon, 18 Nov 2024 01:14:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] PCA 与 AutoEncoders 在降维方面的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtng8q/d_pca_vs_autoencoders_for_dimensionality_reduction/</link>
      <description><![CDATA[标题总结了一切。我正在处理一些匿名时间序列数据，最初，我构建了一个自动编码器，以便在训练后用回归头替换解码器头。 至于预处理步骤，我通常只减去特征的平均值并除以它们的标准差，虽然我早就听说做“数据去相关”很有帮助，所以我决定最终学习 PCA。 我的问题如下：  如果 PCA 用于查找数据集的主要潜在特征，那么使用自动编码器有什么意义吗？（特别是如果某些特征之间存在高度相关性） 如果仍然有必要使用自动编码器，是否应该首先在数据集上使用 PCA 来去相关数据，或者这只是多余的，或者也许不使用它的另一个原因是它会擦除一些信息？ （尽管它是一种可逆变换，所以我看不出信息会如何丢失） PCA 作为预处理步骤是否有利于树构建算法？我没看到太多关于它的讨论，但对我来说，直观地看，在主成分轴上设置决策节点会带来更好的结果。     提交人    /u/DisciplinedPenguin   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtng8q/d_pca_vs_autoencoders_for_dimensionality_reduction/</guid>
      <pubDate>Sun, 17 Nov 2024 20:56:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一支高效的应用机器学习团队是如何构成的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtke1b/d_how_an_efficient_applied_ml_team_is_structured/</link>
      <description><![CDATA[大家好， 我对你们关于大型（更大）ML 团队的结构的经验很感兴趣，这些团队结构对于使用 ML 进行构建的公司（在多个领域使用 ML 的公司，它们涵盖 CV、NLP 等）效果如何？我尝试搜索它，但关于高效团队结构的信息并不多。虽然结构可以由公司文化定义，但我相信你已经看到了如何让这种结构运作良好的模式。 （我认为一个大团队至少有 80 人，包括 PO/PM）。 最基本的（也许是最好的？）是当领域被划分（CV、NLP 等）时，每个领域都有一个负责人和多个高级、中级和初级。然后除了 ML 工程师之外，还有一个单独的部门负责产品化（创建 rest API 等），其中包括 devops 和 SWE。     由    /u/gabegabe6 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtke1b/d_how_an_efficient_applied_ml_team_is_structured/</guid>
      <pubDate>Sun, 17 Nov 2024 18:41:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] treemind：简化梯度提升模型分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtjkci/r_treemind_simplifying_gradient_boosting_model/</link>
      <description><![CDATA[treemind 是一个功能强大的 Python 库，旨在分析 xgboost、lightgbm 和 catboost 等梯度提升模型。它可以帮助您揭示特征及其相互作用如何影响特定间隔内的预测，从而提供快速、直观的见解。 主要功能：  功能和交互分析：了解最多 n 个特征的特征贡献和复杂交互。 高级可视化：用户友好的图表来解释模型决策。 高性能：使用 Cython 进行了优化，即使在大型数据集上也能实现闪电般的快速执行。 轻松集成：与流行的回归和二元分类框架无缝协作。  算法和性能：  算法：专注于分析基于树的模型中的特征贡献和交互，以获得有意义的基于区间的见解。 阅读有关该算法的更多信息 性能：该库的性能已经在合成数据集上进行了测试，其中它与 SHAP 进行了准确性和效率基准测试。 查看性能实验  快速入门： bash pip install tr​​eemind  查看完整文档以获取示例、可视化和 API 详细信息。 GitHub Repo | 文档 注意： 虽然该算法在实践中产生了理想的结果，但目前缺乏正式的数学证明。我们非常感谢您的反馈和想法，以帮助进一步改进和验证该方法！    提交人    /u/zedeleyici3401   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtjkci/r_treemind_simplifying_gradient_boosting_model/</guid>
      <pubDate>Sun, 17 Nov 2024 18:05:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 论文的质量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtjhge/d_quality_of_iclr_papers/</link>
      <description><![CDATA[我浏览了 ICLR 上一些与我感兴趣的领域相关的中等到高分论文，我发现它们进展缓慢，而且有点惊讶，对于一个主要的子领域来说，像这样的顶级会议，论文质量相当差。自从 llms 出现以来，我觉得论文的质量和原创性（当然不是全部）有所下降。只有我一个人有这种感觉吗？    提交人    /u/Cool_Abbreviations_9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtjhge/d_quality_of_iclr_papers/</guid>
      <pubDate>Sun, 17 Nov 2024 18:02:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Nov 2024 16:00:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用旧向量而不是新向量来定义词汇的小型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtenw8/d_small_language_models_defining_vocabulary_using/</link>
      <description><![CDATA[我一直在思考语言模型为何如此庞大，以及它们如何变得更小。我想每个人的大脑都不可能容纳人类的全部知识。我相信人类大致拥有一个类似于单词 X 其他单词的概率矩阵，但不是每个单词 X 每个单词。 我突然想到，我们经常使用我们知道的其他现有单词来定义不常用的单词（低频率、不常用的单词）。我们能否拥有一个语言模型，该模型仅使用频率最高的单词的向量，而“不常用的单词”没有自己的向量，而是引用现有向量？这可以大大减少单词 X 单词矩阵，因为常用单词由语言的一个小得多的子集组成。也许这样的模型可以在针对特定主题的文本进行重新训练时，动态地将参考词移入和移出主向量。 我知道我从来没有过原创的想法，有没有其他类似的项目？    提交人    /u/meteoraln   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtenw8/d_small_language_models_defining_vocabulary_using/</guid>
      <pubDate>Sun, 17 Nov 2024 14:26:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>