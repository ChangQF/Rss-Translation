<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Thu, 27 Jun 2024 15:16:39 GMT</lastBuildDate>
    <item>
      <title>[R] 爱丽丝梦游仙境问题的新颖提示方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dptial/r_novel_prompting_approach_for_alice_in/</link>
      <description><![CDATA[https://arxiv.org/abs/2406.02061v1 研究论文通过提出一个简单的问题“爱丽丝有 N 个兄弟，她还有 M 个姐妹。爱丽丝的兄弟有多少个姐妹？” 展示了 SOTA LLM 中的推理细分。我调查了不同提示对这个问题的表现，并表明“展开然后解决”提示明显优于标准和思路链提示。文章链接 - https://medium.com/@aadityaubhat/llms-cant-reason-or-can-they-3df5e6af5616    由   提交  /u/aadityaubhat   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dptial/r_novel_prompting_approach_for_alice_in/</guid>
      <pubDate>Thu, 27 Jun 2024 15:06:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] Chrome 内置 Gemini 模型评测：Prompt API</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dprg1h/r_review_of_builtin_gemini_model_for_chrome_the/</link>
      <description><![CDATA[我最近受邀加入 Chrome 内置 AI（Prompt API）的早期预览计划。内置 AI 是一项探索性工作，有望成为嵌入式 AI 的跨浏览器标准。它利用设备上的 Gemini Nano；这意味着它被捆绑到您的网络浏览器中，并且 LLM 生成发生在您的本地浏览器环境中。 代码链接在此处： https://github.com/Ejb503/chrome-ai-prompt-api    提交人    /u/ejb503   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dprg1h/r_review_of_builtin_gemini_model_for_chrome_the/</guid>
      <pubDate>Thu, 27 Jun 2024 13:35:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 概率图模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpq6xp/d_probabilistic_graphical_models/</link>
      <description><![CDATA[所以我很困惑是否要学习概率图模型。 目前我想探索的下 3 个领域是 人工智能（我将在大学下学期学习该课程）以及斯坦福大学的 cs 221 课程 因果推理（我已经为下学期制定了 SOP 生成式人工智能 我是否需要概率图模型知识来学习这些主题。 谢谢    提交人    /u/Worldly-Duty4521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpq6xp/d_probabilistic_graphical_models/</guid>
      <pubDate>Thu, 27 Jun 2024 12:33:42 GMT</pubDate>
    </item>
    <item>
      <title>[D]我如何才能找到可以免费在我的网站上用于机器学习主题的科学图片</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpos8j/dhow_can_i_find_scitific_images_which_i_can_use/</link>
      <description><![CDATA[[D] 开始创建博客文章，但我不喜欢说明自己的图像，这就是为什么我想知道如何才能免费访问科学图像，例如，我想要一个图像来举例说明监督和无监督的机器学习类型以及强化学习的不同之处；互联网上有很多图像，但我在哪里可以找到这样的免费版权图像？     提交人    /u/Still-Expression-203   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpos8j/dhow_can_i_find_scitific_images_which_i_can_use/</guid>
      <pubDate>Thu, 27 Jun 2024 11:15:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深度学习项目硬件要求（预算 2000 美元）：大型复杂数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpo1p2/d_deep_learning_project_hardware_requirements/</link>
      <description><![CDATA[虽然为了完成 ECG 分析算法的论文答辩，我进入应用机器学习（尤其是深度学习）领域已经 8 个多月了，但我还没有弄清楚最佳设置的硬件要求，以便明智地使用 2000 美元的研究经费。 我不是美国公民，我们国家也没有 Nvidia 供应商。我的笔记本电脑性能很差，只有英特尔酷睿 i3 处理器和 4GB RAM。我在国内的选择是购买一台新笔记本电脑或购买一台工作站，价格略低于 16GB RAM 和酷睿 i7 笔记本电脑的两倍。但我在其他地方读到过，笔记本电脑并不是重型 DL 项目的最佳选择，尽管我正在考虑使用 SSD 来增加内存和时间效率的可能性。 Google Collaboratory 一开始似乎是个不错的选择，但在处理如此大的项目时，尤其是在数据处理方面，它有局限性。 我必须将深度学习应用于复杂的心电图信号数据集，而我的研究领域是生物医学工程，很少考虑这些主题。如果能得到一个有见地的回复，以免在钱的问题上犯错，我将不胜感激。非常感谢您花时间阅读到这里。    提交人    /u/r_agate   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpo1p2/d_deep_learning_project_hardware_requirements/</guid>
      <pubDate>Thu, 27 Jun 2024 10:30:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从头开始​​训练 Transformer-CNN 视频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpnp05/d_training_a_transformercnn_model_for_videos_from/</link>
      <description><![CDATA[您好， 我正在尝试从头开始训练 Transformer-CNN 模型。Transformer 模型与 ViViT 模型 2 相当。CNN 正在获取第二个（时间）变换器的输出并生成图像输出。输入是视频文件。目标是输出这些视频文件中部分隐藏的移动物体。 我的架构（在 Pytorch 中）如下（从输入到输出）：  TubletEmbedding 卷积 PatchEmbedding（1 Conv3D 层） 添加 CLS Token 位置编码 （空间）TransformerEncoder 层（dim=512，heads=8，layers=1） 添加 CLS Token 全局平均池化 （时间）TransformerEncoder 层（dim=512，heads=8，layers=1） 解码器层  线性 ReLU Dropout BatchNorm1d Unflatten 2x  ConvT2d ReLU Dropout BatchNorm2d  ConvT2d Tanh   我有大约 80,000 个单独的训练视频。我使用热身学习 20 个时期，然后使用 AdamW 优化器进行余弦退火和热重启。我的批次大小是 64。为了加快训练速度（我只有一个 4090），我使用混合精度训练和梯度累积。我的标准是 MSE。 https://preview.redd.it/q3x31tfm439d1.png?width=2304&amp;format=png&amp;auto=webp&amp;s=22806fd864830529d3425597e74ff01226e69729 如上所示，该模型实际上收敛得相当快。最终验证损失非常小，但输出并不理想。它几乎是所有可能对象的混合体，集中在一个地方： https://preview.redd.it/zy1sooo2839d1.png?width=1948&amp;format=png&amp;auto=webp&amp;s=02ec6befce7b8c360f93fd8bee2bf734775b83d6 有什么想法吗？    提交人    /u/grmn0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpnp05/d_training_a_transformercnn_model_for_videos_from/</guid>
      <pubDate>Thu, 27 Jun 2024 10:07:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 既然 T5 似乎是更好的文本编码器（用于 SD3 等），为什么在 LaBSE 中使用 Bert</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpn365/d_why_is_bert_used_in_labse_when_t5_seems_like/</link>
      <description><![CDATA[LaBSE 是最好的（据我所知）开源句子嵌入模型，我经常使用它，但它是在 T5 之后出现的，最近 T5 似乎是最好的文本编码器，用于 SD3 等，为什么在 LaBSE 中使用 bert 而不是 T5 ？ 这篇 Google T5 句子嵌入论文 https://arxiv.org/pdf/2007.01852 甚至早于 LaBSE 论文 https://arxiv.org/pdf/2007.01852 Bert 只是编码器，而 T5 是编码器-解码器（我猜只有在像 SD3 这样的嵌入情况下才使用编码器部分），什么会让 Bert更适合句子嵌入，但 T5 更适合 SD3 ？     提交人    /u/EizanPrime   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpn365/d_why_is_bert_used_in_labse_when_t5_seems_like/</guid>
      <pubDate>Thu, 27 Jun 2024 09:25:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士中的可解释性研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpmuy9/r_interpretability_research_in_llms/</link>
      <description><![CDATA[法学硕士 (LLM) 的可解释机器学习 (ML) 的大部分工作都集中在机械可解释性上，而不是文献中先前的方法，如反事实、基于案例的推理、原型、显着性图、基于概念的解释等... 您认为这是为什么？我的感觉是，这是因为机械解释在研究中计算量较小，所以它是人们在法学硕士 (LLM) 中真正拥有的唯一选择（例如，数据集太大而无法进行基于案例的推理）。另一种解释是，人们只是试图将该领域推向不同的方向，而机械解释就是这样。就像人们只是想要法学硕士推理的因果形式保证一样。 但我想了解一下人们的感受，您认为我是对的还是这种趋势还有其他原因？    提交人    /u/SkeeringReal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpmuy9/r_interpretability_research_in_llms/</guid>
      <pubDate>Thu, 27 Jun 2024 09:09:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您对 IBM 的 Granite 聊天模型的看法/观点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dplede/d_your_opinionview_on_ibms_granite_chat_models/</link>
      <description><![CDATA[我正在为一个项目检查 granite 13b 聊天模型，我对它的结果一点也不满意。有时，它只是原封不动地吐出文档，没有做任何更改。有时，它会输出奇怪的结果。我查看了 Lmsys 排行榜，那里甚至没有它。所以我们不知道它与其他 LLM 相比表现如何。你对它有什么看法？有没有什么方法可以通过调整一些参数来让它变得更好？    提交人    /u/QaeiouX   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dplede/d_your_opinionview_on_ibms_granite_chat_models/</guid>
      <pubDate>Thu, 27 Jun 2024 07:23:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言模型对于时间序列预测真的有用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpgp0h/r_are_language_models_actually_useful_for_time/</link>
      <description><![CDATA[  由    /u/Cunic  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpgp0h/r_are_language_models_actually_useful_for_time/</guid>
      <pubDate>Thu, 27 Jun 2024 02:39:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找研究时间序列的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp96cu/d_looking_for_resources_to_study_time_series/</link>
      <description><![CDATA[我对基础统计学和深度学习有相当的了解。 我想从基础到尽可能深入地研究时间序列，包括数学和编码实现方面。我不想跳过数学细节。 有人可以给我推荐一些好的资源吗：书籍和讲座系列 谢谢     提交人    /u/Worldly-Duty4521   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp96cu/d_looking_for_resources_to_study_time_series/</guid>
      <pubDate>Wed, 26 Jun 2024 20:50:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为一名刚毕业的博士生，需要做好就业准备吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp73ct/d_job_prep_as_a_fresh_phd_grad/</link>
      <description><![CDATA[大家好， 我是一名刚毕业的 ML 博士，目前正在求职。我正在寻找 genAI 和传统 ML 职位。这里有没有人有申请 ML 职位的经验，你觉得哪些资源有用？提前谢谢大家。    提交人    /u/Temporary_Study2354   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp73ct/d_job_prep_as_a_fresh_phd_grad/</guid>
      <pubDate>Wed, 26 Jun 2024 19:22:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于最佳 Python 时间序列库的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp4y8p/d_thoughts_on_best_python_timeseries_library/</link>
      <description><![CDATA[有许多 Python 库提供当代时间序列模型和数据工具的实现。以下是一份（不完整）列表。希望任何使用过这些（或其他）库的人对其优缺点提供反馈。如果您使用过多个库并且可以提供有见解的比较，则可以获得加分。我正在尝试弄清楚要花时间研究哪一个（些）。非常感谢！  TSA - https://github.com/timeseriesAI/tsai TSLib - https://github.com/thuml/Time-Series-Library AEON - https://github.com/aeon-toolkit/aeon SKTime - https://www.sktime.net/en/stable/ TSLearn - https://tslearn.readthedocs.io/en/stable/ Nixtla - https://github.com/Nixtla/ Pytorch-forcasting - https://pytorch-forecasting.readthedocs.io/en/stable/ DARTS - https://unit8co.github.io/darts/index.html Merlion - https://github.com/salesforce/Merlion     提交人    /u/HorseEgg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp4y8p/d_thoughts_on_best_python_timeseries_library/</guid>
      <pubDate>Wed, 26 Jun 2024 17:54:21 GMT</pubDate>
    </item>
    <item>
      <title>[P] 仅使用原始 JSON 和图像即可实现 Pokémon 嵌入的超级效果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp43b2/p_the_super_effectiveness_of_pokémon_embeddings/</link>
      <description><![CDATA[许多年前，我制作了 Pokémon 向量，但无法解释所有 Pokémon 元数据。借助 nomic-embed-text-v1.5 和 nomic-embed-vision-v1.5 嵌入模型的一些附加代码，我能够将一团原始 JSON 放入模型中，并且嵌入效果出乎意料地好！ https://minimaxir.com/2024/06/pokemon-embeddings/ 此博客文章的所有代码均可在 GitHub 上开源 获取。    提交人    /u/minimaxir   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp43b2/p_the_super_effectiveness_of_pokémon_embeddings/</guid>
      <pubDate>Wed, 26 Jun 2024 17:18:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>