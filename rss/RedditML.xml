<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sun, 13 Apr 2025 12:32:21 GMT</lastBuildDate>
    <item>
      <title>[P] Tiktok Brainrot Generator更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jy5w5l/p_tiktok_brainrot_generator_update/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不久前，我制作了一个脑腐发生器，它利用motu hira的wav2vec2算法进行力对齐，它得到了一定的牵引力（ https://www.reddit.com/r/machinelearning/comments/1hlgdyw/pthlgdyw/p \_i \_made_a _a \_tiktok_brain \ _rot_rot_video \ _video \ _generator/ ）  这次，我和Vidhu一起对Brain Rot Generator进行了一些更新，Vidhu亲自与我联系以帮助我进行这个项目。    - 线程建议。 （现在，如果您不知道该建议的建议，则可以让LLM为您建议您又名GROQ 70B LLAMA和VADER情感）   - 图像覆盖层。 (This was done using an algorithm which showed the timestamp, similar to the audio for force alignment but done using image instead) - Dockerization support (It now supports dockerisation) - Web App (For easy usage, I have also made a web app that makes it easy to toggle between features) - Major bug fixed (Thanks to Vidhu for identifying and fixing the bug which阻止人们使用回购） 这是github： sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jy5w5l/p_tiktok_brainrot_generator_update/”&gt; [link]        [commist]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jy5w5l/p_tiktok_brainrot_generator_update/</guid>
      <pubDate>Sun, 13 Apr 2025 11:51:13 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何管理使用ML模型的实验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jy5ue4/d_how_do_you_manage_experiments_with_ml_models_at/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在在一家公司做我的硕士论文，该论文对AI模型没有大量实验，而且绝对没有系统性，因此，当我启动时，我决定首先实施“标准”的“标准”项目结构（带有HYDRA和MLFLOW的CCD）。我花了一些时间来编写所需的所有内容，设置配置文件等。这并不是说要设法存储地块，可视化它们甚至任何形式的编排（无论如何都在我的范围之外）。 我在大学研究项目和学校工作中都做了同样的事情，因此，由于我没有预算，而且我想学习一切，我自己就可以自己实施一切。不过，如果您确实有预算，这似乎太多了。 你们如何管理实验？使用一些SaaS平台，运行开源工具（哪个？），或者编写自己的小堆栈并自己管理？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jy5ue4/d_how_do_do_do_you_manage_experiments_with_with_ml_models_at/  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jy5ue4/d_how_do_do_do_you_manage_experiments_with_with_ml_models_models_models_at/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jy5ue4/d_how_do_you_manage_experiments_with_ml_models_at/</guid>
      <pubDate>Sun, 13 Apr 2025 11:48:09 GMT</pubDate>
    </item>
    <item>
      <title>[d] ML悖论：当更好的指标导致更糟的结果时 - 您面对这个吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jy4odf/d_the_ml_paradox_when_better_metrics_lead_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  想象一下，您已经训练了一个理论上  excell yours 的模型（准确性，F1-SCORE，AUC-ROC等），但实际上实际上   在现实世界中造成了灾难性的失败。 For example:   A medical diagnosis model with 99% accuracy that disproportionately recommends harmful treatments for rare conditions. A self-driving car API that reduces pedestrian collisions in simulations but causes erratic steering in rain, leading to more crashes. An NLP chatbot that scores highly on “有益的”基准测试，但在询问心理健康时会提供危险的建议。    悖论：您的模型是按指标/研究标准“更好”，但在道德上，社会上或功能上或功能上是“更糟糕的”。   问题：  1。您是否遇到了此断开连接？分享您的故事！ 2。我们如何使用现实世界影响？ 3。如何对基准进行优化。我们甚至可以衡量后者吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/munibkhanali     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jy4odf/d_the_ml_paradox_when_better_better_metrics_lead_to/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jy4odf/d_the_ml_paradox_when_better_metrics_lead_to/</guid>
      <pubDate>Sun, 13 Apr 2025 10:29:45 GMT</pubDate>
    </item>
    <item>
      <title>[D]传统的机器学习算法（例如神经网，逻辑回归，树木）是否会被LLM替换？因此，数据科学家会失业吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jxwklu/d_will_traditional_machine_learning_algorithms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  亲爱的同事， 我很想听到从业人员的跨行业听到有关大型语言模型（LLMS）如何重塑角色并演变工作流程的方式。下面，我概述了我观察到的一些新兴趋势，我很想听听您的想法，评论或加法。  [趋势1]  - 在某些（仍然有限）域中，LLMS中的LLMS作为IR  的标签发电机，LLMS已经超过了传统的ML模型。一个明显的例子是信息检索（IR），现在使用LLMS生成标签（例如相关性判断或排名），而不是依靠人类注释者或点击数据。 这表明LLM在某些情况下已经被认为是更准确的标签。但是，由于其成本和延迟，LLM通常不直接在生产中使用。取而代之的是，在LLM生成的标签上训练了较小，更快的ML模型，从而实现可扩展的部署。 Interestingly, this is happening in high-value areas like ad targeting, recommendation, and search — where monetization is strongest. [Trend 2] — Emergence of LLM-Based ML Agents We’re beginning to see the rise of LLM-powered agents that automate DS/ML workflows: data collection, cleaning, feature engineering, model selection, hyperparameter tuning, evaluation, and 更多的。这些代理商可能会大大减轻数据科学家和ML工程师的手动负担。 虽然仍然很早，但这种趋势可能会导致重点的转变 - 从编写低级代码到监督智能系统的智能系统。&gt; &gt;  [3]  - 最终将大量的ML Systemise Over Off All Performess Enloctions？ LLM（或其继任者）最终是否可以全面优于特定于任务的ML模型？想像一个未来，LLM在许多领域中直接提供更好的预测并不遥不可及。 这将反映我们在NLP中已经看到的东西，在NLP中，LLMS有效地取代了许多专业模型。单个基础模型最终可以取代大多数传统的ML系统吗？ 我不确定[趋势3]会走多远，或者多久 - 但我很想听听您的想法。您是否看到工作中的这些转变？您对LLM作为合作者甚至竞争对手的感觉如何？ 期待讨论。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jxwklu/d_will_will_traditional_machine_learning_algorithms/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jxwklu/d_will_traditional_machine_learning_algorithms/</guid>
      <pubDate>Sun, 13 Apr 2025 01:30:16 GMT</pubDate>
    </item>
    <item>
      <title>[P]谐波激活：神经网络的周期性和单调功能扩展（预印本）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jxqtoo/p_harmonic_activations_periodic_and_monotonic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，伙计们！我最近发布了一个预印本，提出了一个新的激活功能系列，专为无标准化的深层网络而设计。我是一名独立研究人员，致力于MLP和变压器的表达性非线性。   tl; dr：  i提出了一个残留激活函数：    f（x）= x +α·g（sin²（sin²（πx/2）） gelu） 我想听听反馈。这是我的第一篇论文。   preprint ：[ &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/henriquelmeeee     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jxqtoo/p_harmonic_activations_periodic_and_monotonic/</guid>
      <pubDate>Sat, 12 Apr 2025 20:39:09 GMT</pubDate>
    </item>
    <item>
      <title>[D]“推理模型并不总是说出他们的想法”  - 有人提示吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jxjwi2/d_reasoning_models_dont_always_say_what_they/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有人尝试通过使用自己的提示来复制的“推理模型并不总是说出他们的想法” 论文？我正在努力再现这些输出。如果您对此进行了尝试并进行了微调，您是否可以分享您的提示或一路上获得的任何见解？任何讨论或指示都将不胜感激！ 参考，这是：       - 提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jxjwi2/d_reasoning_models_models_dont_always_always_say_say_what_they/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jxjwi2/d_reasoning_models_dont_always_say_what_they/</guid>
      <pubDate>Sat, 12 Apr 2025 15:30:53 GMT</pubDate>
    </item>
    <item>
      <title>[n] Google开放，让企业自我主机SOTA模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jxin3q/n_google_open_to_let_entreprises_self_host_sota/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  从主要参与者中，这听起来像是一个很大的变化，并且大多会为企业提供有关数据隐私的有趣视角。 Mistral在Openai和Anthropic维护更多封闭式产品或通过合作伙伴时已经做了很多事情。   https://www.cnbc.com/2025/04/09/google-will-let-companies-run-gemini-models-models-in-their-own-data-centers.html     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jxin3q/n_google_open_to_to_let_tto_tto_entreprises_erse_host_host_sota/”&gt; [link]   [commist]     ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jxin3q/n_google_open_to_let_entreprises_self_host_sota/</guid>
      <pubDate>Sat, 12 Apr 2025 14:33:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] D1：通过增强学习在扩散大语模型中扩展推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jxeahf/r_d1_scaling_reasoning_in_diffusion_large/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   最近的大型语言模型（LLMS）已证明了强大的推理能力，可以从在线增强学习（RL）中受益。这些功能主要在从左到右的自回归（AR）一代范式中证明。相比之下，基于扩散的非运动范式以粗到精细的方式产生文本。尽管与AR相比，最近基于扩散的大语言模型（DLLM）已经达到了竞争性语言建模性能，但尚不清楚DLLM是否也可以利用LLM推理的最新进展。为此，我们提出了D1，这是一个框架，可以通过有监督的Finetuning（SFT）和RL的组合将预先训练的戴上DLLM适应推理模型。具体而言，我们开发并扩展了技术以改善预验证的DLLM中的推理：（a）我们利用蒙版的SFT技术直接从现有数据集中提炼知识并灌输自我提高行为，（b）我们引入了一种新颖的无评论，策略级别的RL算法，称为DIFFU-GRPO。通过实证研究，我们研究了不同的训练后食谱对多个数学和逻辑推理基准的性能。我们发现D1可以产生最佳性能，并显着提高了最先进的DLLM的性能。  在扩散扩散大语模型上，使用强化学习来缩放扩散模型。当涉及到实际上原因的语言模型时，绝对需要注意！ 纸链接：  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/hiskuu     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jxeahf/r_d1_scaling_reasoning_in_diffusion_large/</guid>
      <pubDate>Sat, 12 Apr 2025 10:30:15 GMT</pubDate>
    </item>
    <item>
      <title>[p]简单独立tfrecords数据集读取器具有随机访问和搜索功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jxbmss/p_simple_standalone_tfrecords_dataset_reader_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，在工作中，我们正在使用tfrecords存储大多数数据集。但是不时。我们需要检查数据，以更好地对我们的模型进行更好的预测，例如为了找到特定类等的示例。由于Tfrecord在本质上是顺序的，它们不允许进行标准的随机访问切片。 我决定创建这个简单的工具，该工具允许为Tfrecrods创建一个简单的可搜索索引，以稍后可用于各种数据集分析。  这是项目页面： https://github.com/kmkolasinski/tfrecords-readers-readers-readers-reader  required Dataset can be read directly from Google Storage Indexing of 1M examples is fast and usually takes couple of seconds Polars is used for fast dataset querying tfrds.select(&quot;select * from index where name ~ &#39;rose&#39; limit 10&quot;)  Here is a quick start example from readme：  导入tensorflow_dataset作为tfds＃仅需要下载数据集导入数据集导入tfr_reader从pil导入import Import Import Import Import Importim Impart ipy ipyplot数据集，dataSet_info = tfds.load（tfford_flowers102&#39;，splite =&#39;train =&#39;train for_info = true）索引label = feature [label;]。值[0]返回{bail; bail; bail; bail，&#39;d dataset_info.features; dataset_info.data_dir，＃索引选项，如果已经创建索引fileepattern =;*。限制10&#39;）assert示例== tfrds [rows [; _row_id;]]样本，name = []，[]，[示例）中的示例（示例）（示例）：image = image.open（示例[emampe; image; image＆quot; image＆quot bytes_io [0]）。 samples.append（image）ipyplot.plot_images（样本，名称）   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kmkolasinski     [links]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jxbmss/p_simple_starlone_tfrecords_dataset_dataset_reader_with/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jxbmss/p_simple_standalone_tfrecords_dataset_reader_with/</guid>
      <pubDate>Sat, 12 Apr 2025 07:13:28 GMT</pubDate>
    </item>
    <item>
      <title>[d]添加新的词汇令牌 +微调LLMS以遵循说明是无效的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jx3zy0/d_adding_new_vocab_tokens_finetuning_llms_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在使用指令调整LLMS和VLMS进行实验，要么将新的专用令牌添加到其相应的令牌/处理器中，或者不添加。设置是典型的：掩盖说明/提示（仅参加响应/答案）并应用CE损失。但是，没有什么特别的标准SFT。 但是，我观察到了使用其基本令牌/处理器训练的模型与经过修改的令牌训练的模型，对此有更好的验证损失和输出质量...对此有任何想法吗？  （我的hunch：很难增加这些新添加的令牌的可能性，而模型根本无法正确学习）。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jx3zy0/d_adding_new_vocab_vocab_tokens_finetuning_llms_to/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jx3zy0/d_adding_new_vocab_vocab_tokens_finetuning_llms_to/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jx3zy0/d_adding_new_vocab_tokens_finetuning_llms_to/</guid>
      <pubDate>Fri, 11 Apr 2025 23:42:34 GMT</pubDate>
    </item>
    <item>
      <title>[D]用于产品标题和类别标准化的微调BART  - 仍然不够准确，任何更好的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jwz2k3/d_finetuned_bart_for_product_title_category/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我正在建立一个来自摩尔多瓦各种在线商店产品的价格比较网站。我在约20,000个手动标准化产品标题的自定义数据集上微调了一个BART模型，并损失了0.013。 I also trained a separate model for predicting product categories. Unfortunately, the results are still not reliable — the model struggles with both product title normalization and category assignment, especially when product names have slight variations or extra keywords. I don’t have access to SKU numbers from the websites, so matching must be done purely on text. Is there a better approach or model I might be missing?或者也许是专门针对此类问题设计的工具/应用程序？ 预先感谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mali5k     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jwz2k3/d_finetuned_bart_for_for_for_for_product_title_category/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jwz2k3/d_finetuned_bart_for_product_title_category/</guid>
      <pubDate>Fri, 11 Apr 2025 19:59:31 GMT</pubDate>
    </item>
    <item>
      <title>[P]我们为LLM建立了类似OS的运行时间 - 好奇是否有人在做类似的事情？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jwxght/pwe_built_an_oslike_runtime_for_llms_curious_if/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，我们正在尝试使用AI本地运行时，该运行时间在2-5秒钟内以llms（例如13b – 65b）来捕捉llms（例如13b – 65b），并且动态运行50多个型号，每gpu始终在记忆中始终居住在ersign中，而不是传统的prial。 GPU执行 +内存状态和点播模型。这似乎解锁了：•实际的无服务器行为（无空闲成本）•低潜伏期时的多模型编排•更好地使用代理工作负载的GPU利用率 是否有人尝试过与多模型堆栈，代理工作流程或动态内存真实分配相似的东西很想听听别人如何接近这一点的 - 或者这甚至与您的中世纪需求保持一致。 很乐意在有用的情况下分享更多的技术细节！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jwxght/pwe_built_an_oslike_runtime_for_for_for_for_for_llms_curious_if/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jwxght/pwe_built_an_oslike_runtime_for_for_for_llms_curious_curious_if/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jwxght/pwe_built_an_oslike_runtime_for_llms_curious_if/</guid>
      <pubDate>Fri, 11 Apr 2025 18:50:35 GMT</pubDate>
    </item>
    <item>
      <title>[P]一种轻巧的开源模型，用于产生漫画</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jws42t/p_a_lightweight_opensource_model_for_generating/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jws42t/p_a_lightweight_opensource_model_for_generating/</guid>
      <pubDate>Fri, 11 Apr 2025 15:06:32 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jpdo7y/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</guid>
      <pubDate>Wed, 02 Apr 2025 02:15:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_be_hired/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Mon, 31 Mar 2025 02:30:37 GMT</pubDate>
    </item>
    </channel>
</rss>