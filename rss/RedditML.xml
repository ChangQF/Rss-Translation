<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 20 Jan 2024 18:16:06 GMT</lastBuildDate>
    <item>
      <title>[R] Vision Mamba：利用双向状态空间模型进行高效视觉表示学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bgoug/r_vision_mamba_efficient_visual_representation/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2401.09417 代码和模型：https://github.com/hustvl/Vim 摘要：  最近状态空间具有高效硬件感知设计的模型（SSM），即 Mamba，在长序列建模方面表现出了巨大的潜力。纯粹基于 SSM 构建高效且通用的视觉主干是一个有吸引力的方向。然而，由于视觉数据的位置敏感性以及视觉理解的全局上下文的要求，表示视觉数据对于 SSM 来说是一个挑战。在本文中，我们证明视觉表示学习对自注意力的依赖是不必要的，并提出了一种具有双向 Mamba 块（Vim）的新通用视觉主干，它用位置嵌入来标记图像序列并用双向状态空间模型压缩视觉表示。在 ImageNet 分类、​​COCO 对象检测和 ADE20k 语义分割任务上，与 DeiT 等成熟的视觉转换器相比，Vim 实现了更高的性能，同时还展示了显着改进的计算和性能。记忆效率。例如，在对分辨率为 1248×1248 的图像进行批量推理提取特征时，Vim 比 DeiT 快 2.8 倍，并节省 86.8% 的 GPU 内存。结果表明 Vim 能够克服计算和计算问题。它克服了对高分辨率图像执行 Transformer 式理解的内存限制，并且具有成为视觉基础模型的下一代骨干的巨大潜力。代码可在 此 https URL 获取。  https://preview.redd.it/gf2b6teuomdc1.png?width=2880&amp;format=png&amp;auto =webp&amp;s=3aece9b012541f8aa20dcee50eedb68bd9bed7c6   由   提交 /u/APaperADay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bgoug/r_vision_mamba_efficient_visual_representation/</guid>
      <pubDate>Sat, 20 Jan 2024 17:19:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 AlphaCodium 生成代码：从即时工程到流程工程（建议的方法将基准测试的准确度从 19% 提高到 44%）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bfkz2/r_code_generation_with_alphacodium_from_prompt/</link>
      <description><![CDATA[研究（至少对我来说，痛苦的个人经历）表明，在应对复杂的编码挑战时，仅靠即时工程具有固有的局限性。 &lt;在 arXiv 上发表的一篇论文中，一项新研究的作者提出了一种名为 AlphaCodium 的新颖迭代方法，该方法专注于针对测试用例重复生成、执行和调试代码。这个具体的反馈循环允许法学硕士“学习”通过迭代培养关键编程技能。 在竞争性编程基准 CodeContests 上进行评估时，AlphaCodium 将 GPT-4 的代码生成准确性从 19% 提高到了 44%。它还超越了之前发布的方法，例如 AlphaCode，同时通过避免暴力生成，使用的模型查询数量减少了 10,000 倍。 AlphaCodium 采用的原则是：  测试驱动开发提供目标适应度函数 模块化编码 扩大测试覆盖范围揭示普遍性差距 锚定已知测试以防止回归  &lt;研究人员认为，与将模型视为通用文本生成器相比，这些软件工程实践更适合代码生成。虽然需要更多的实验，但 AlphaCodium 演示的测试调试循环可能会指向更强大的人工智能编程技术。 完整摘要位于此处。论文位于此处。仓库位于此处。   由   提交 /u/Successful-Western27    reddit.com/r/MachineLearning/comments/19bfkz2/r_code_ Generation_with_alphacodium_from_prompt/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bfkz2/r_code_generation_with_alphacodium_from_prompt/</guid>
      <pubDate>Sat, 20 Jan 2024 16:30:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何为多任务模型分配权重？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bex1f/d_how_to_assign_weights_to_multitask_models/</link>
      <description><![CDATA[在推荐系统中，训练同时尝试优化多个目标的多任务模型是很常见的。然而，这里要设置的一组关键超参数是每个任务损失的权重。通常以最大化某些业务目标（例如收入、保留率）的方式选择权重。因此，它们通常不会作为训练过程本身的一部分来学习。 是否有任何流行或最先进的方法来找到这些任务权重？ &lt; !-- SC_ON --&gt;  由   提交 /u/AstronautVarious3791   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bex1f/d_how_to_assign_weights_to_multitask_models/</guid>
      <pubDate>Sat, 20 Jan 2024 16:01:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 潜在扩散模型噪声调度器的真相？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bejd5/d_the_truth_about_noise_schedulers_for_latent/</link>
      <description><![CDATA[这是关于用于 LDM 的噪声调度程序的公开讨论，例如特别是稳定扩散。我无法理解的一件事是，要么我不理解一些基本知识，要么 SD 社区中对于采样器的用途存在普遍的误解。 For示例这篇文章声称：  这个去噪过程称为采样，因为稳定扩散在每一步中都会生成一个新的样本图像。采样中使用的方法称为采样器或采样方法。  此外，一般来说，围绕哪种采样器有很多讨论使用及其特征（请参阅此）等，以及如何使用它们模拟噪声扩散的 ODE。 原始 LDM 论文没有详细介绍采样器，它只是提到他们使用 DDIM，并且根据他们的描述（以及大量实现示例），在正向扩散过程（即当随机噪声被添加到图像中并在每一步分散时），然后模型需要预测该噪声并在反向扩散过程中将其去除。 IE。噪声采样器需要知道在训练过程中如何添加噪声（模拟扩散过程），但在推理过程中模型应该只消除噪声而不涉及采样。 例如使用欧拉采样器通过取决于步骤的西格玛来说明这一点（因为这是最简单的数学之一）： ``` 前向扩散  噪声 = 正常(0, 1) 噪声样本 = 原始样本 + 噪声 * sigma 反向扩散 pred_noise = 模型(noisy_sample) denoished_sample = 噪声样本 - sigma_hat * pred_noise ``` 即这与添加噪声正好相反，没有“采样”。在推理步骤中。有关参考，请参阅此实现。  现在，我的主要问题是：如果模型被训练来预测由特定算法添加的噪声（在 SD 的情况下为 DDIM），那么我们是否应该在推理过程中使用该特定算法？  我的理论是 SD 应该与 DDIM 一起使用。然而，我猜社区认为使用其他采样器，去噪过程会因为额外的缺陷而变得不太准确，这有助于生成更多样化（或只是不同）的结果。但我会声称，使用 DDIM 并在去噪中额外注入噪声会产生相同的效果（尚未测试过），而不会产生额外的混乱和不断增加的噪声调度程序数量。  当然，可以使用其他更快的调度程序，通过以更少（或更快）的步骤近似 DDIM，例如请参阅LCM方法，但它们应该被标记为简单的不完美替代品，而不是“更擅长创造”的替代方案X”。 让我知道你的想法，我可能是错的，所以我只是想了解大量可用调度程序背后的真实直觉。   由   提交/u/vakker00   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bejd5/d_the_truth_about_noise_schedulers_for_latent/</guid>
      <pubDate>Sat, 20 Jan 2024 15:44:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] EvolGPT：环境反馈任务的专家级表现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19be59k/p_evolgpt_expertlevel_performance_on_tasks_with/</link>
      <description><![CDATA[   /u/xjustwaitx  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19be59k/p_evolgpt_expertlevel_performance_on_tasks_with/</guid>
      <pubDate>Sat, 20 Jan 2024 15:26:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] The Manga Whisperer：自动生成漫画转录</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bd8ua/r_the_manga_whisperer_automatically_generating/</link>
      <description><![CDATA[     &lt; td&gt; 论文：http://arxiv.org/abs /2401.10224 Github：https://github.com/ragavsachdeva/magi 自己尝试一下：https://huggingface.co/spaces/ragavsachdeva/the-manga-耳语者/ TLDR：给定高分辨率漫画页面作为输入，Magi（我们的模型）可以（i）检测面板、字符、文本块，（ii）集群字符（无需制作任何(iii) 将文本块与其说话者进行匹配，(iv) 执行 OCR，(v) 生成谁说了什么以及何时说的文字记录（通过按阅读顺序对面板和文本框进行排序） ）。请参见下图的示例。  想分享我过去几个月一直在研究的东西，我希望其他人觉得它有用:) 我对该模型的表现特别满意检测和聚类字符（尽管由于遮挡导致视点和部分可见性发生极端变化）。由于模型无法“读取”文本，因此文本与说话者的匹配还有改进的空间。对话（它只是试图在视觉上匹配它们）。我正在努力让它变得更好。 这里有一个预告片： 预测的面板为绿色，文本块为红色，字符为蓝色。预测的字符身份关联由连接字符框中心的线显示。未显示文本到说话者关联，但提供了生成的文字记录。 我很想知道是否有人使用此模型进行很酷的个人或研究项目。一个有趣的用例是使用 Magi 来抓取并自动注释大规模漫画数据集来训练漫画扩散模型。   由   提交 /u/ragavsachdeva   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bd8ua/r_the_manga_whisperer_automatically_generating/</guid>
      <pubDate>Sat, 20 Jan 2024 14:44:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于参加 ICLR 2024 的财务援助的询问</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bbn0j/d_enquiry_regarding_financial_assistance_to/</link>
      <description><![CDATA[我是一名本科生，在主会议上发表了一篇被接受的聚光灯论文，但我们机构没有为本科生提供任何资助。我查了去年的ICLR网站，好像有一个谷歌表格可以申请经济援助，而且是在接近早期注册费截止日期结束时推出的。  我想知道，当我通过今年的表格申请后，经济援助是否能得到保证？还有一般涵盖哪些内容，报销方式是什么？比如，我是否需要用自己的钱提前预订机票/酒店，因为申请签证可能需要这些，而等待经济援助似乎有风险。  显然ICLR也有一些学生志愿服务，如果有报酬的话那就太好了，否则作为本科生自掏腰包去参加会议似乎是一个巨大的经济负担，我不想也错过机会。如果以前的捐助者/了解这方面知识的人能够参与讨论这个话题，那就太好了。    由   提交/u/Master_of_Galaxy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bbn0j/d_enquiry_regarding_financial_assistance_to/</guid>
      <pubDate>Sat, 20 Jan 2024 13:21:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 声音生成人工智能工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bb439/d_sound_generation_ai_tool/</link>
      <description><![CDATA[您能给我推荐一个可以生成声音的 AI 工具吗？就像如果我写下我想要森林或合成贝斯的声音，它就会生成它。谢谢。   由   提交/u/ZennikOfficial  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bb439/d_sound_generation_ai_tool/</guid>
      <pubDate>Sat, 20 Jan 2024 12:52:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 鲜为人知的研究领域 ML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19b7i8s/d_lesser_known_research_areas_ml/</link>
      <description><![CDATA[[D] 您对机器学习中哪些鲜为人知或较少探索的领域感兴趣？ （布罗德，不是高度专业化的想法或主题）我正在寻找一些领域，以便我可以研究和发现它们。   由   提交/u/mango-clay  /u/mango-clay  reddit.com/r/MachineLearning/comments/19b7i8s/d_lesser_known_research_areas_ml/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19b7i8s/d_lesser_known_research_areas_ml/</guid>
      <pubDate>Sat, 20 Jan 2024 08:50:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 需要帮助！在脑肿瘤分类上实施半监督学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19b66wx/d_p_help_needed_implementing_semisupervised/</link>
      <description><![CDATA[您好，我是机器学习新手，我正在做这个项目，尝试使用半监督学习对不同类型的脑肿瘤进行分类。我尝试运行我的代码，结果看起来确实很奇怪（例如“完美的混淆矩阵”）。 我想知道是否可以从任何专家那里获得帮助。请PM我，我可以将代码和我使用的参考代码发送给您。   由   提交/u/Glittering_Revenue19   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19b66wx/d_p_help_needed_implementing_semisupervised/</guid>
      <pubDate>Sat, 20 Jan 2024 07:21:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于机器学习中梯度下降与局部最大值和最小值的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19b4hqt/d_question_about_gradient_descent_in_machine/</link>
      <description><![CDATA[嗨，我是一名学习机器/深度学习的高中生，我最近在数学中了解到，我们可以通过以下方式找到函数的局部最小值取一阶导数和二阶导数来找到其临界点，然后找到函数的最低值。  为什么我们不能直接求损失函数的最小值，而使用梯度下降呢？这看起来效率更高，因为我们不需要进行一系列小的调整来找到最小值 - 我们可以直接计算它 这行得通吗？这听起来有点愚蠢，因为人们显然会要求这样做   由   提交/u/Mucky5739  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19b4hqt/d_question_about_gradient_descent_in_machine/</guid>
      <pubDate>Sat, 20 Jan 2024 05:35:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 开启训练之旅：基于Ray和vLLM构建70B+模型的开源RLHF全方位训练框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19b01uc/p_d_starting_the_training_journey_an_opensource/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19b01uc/p_d_starting_the_training_journey_an_opensource/</guid>
      <pubDate>Sat, 20 Jan 2024 01:39:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 剩下的一切，说服我错了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19axat7/d_residual_everything_convince_me_wrong/</link>
      <description><![CDATA[直接更改功能不是一个好主意。这会破坏信息，并在恢复时导致与“均值回归”相关的可怕问题。 您可以将每个剩余层想象为一个“工人”。在一个组织内。团队被组织成多个区块，每个团队成员都努力合作，为下一个团队（下一个区块）准备可交付成果。然后，每个团队协同工作以填补他们的角色（添加高频、低频等），并将工作汇总到最后一层。单层（老板）签署所有工作并将其传递给客户端（输出） 如果你仔细考虑一下，每一层只需输出值“以增强 x” ;，与“合成一个新的x”相反。 我使用“公司”的原因是这里的参考是为了表明原始输入从未被实际破坏（需求，来自另一个团队的交付）。例如，我们不想破坏 SOW 或 TDD 的页面并编写我们自己的信息。网络中的各层需要进行相同的操作，只为特征提供新信息，而不破坏以前的信息。想到可以通过多种方式聚合所有这些信息而不是简单的残差相加，这是令人兴奋的。根据我的经验，乘法残差很有趣，它收敛速度更快，但也占用更多内存。这种方法的整个瓶颈似乎是内存，因为自动编码器通常会对其特征进行下采样并重新采样，而不是保持维度相同或扩展它。很想听听想法。   由   提交 /u/WisePalpitation4831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19axat7/d_residual_everything_convince_me_wrong/</guid>
      <pubDate>Fri, 19 Jan 2024 23:34:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自我奖励语言模型 - Meta 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19atnu0/r_selfrewarding_language_models_meta_2024/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2401.10020  Github：https://github.com/lucidrains/self-rewarding -lm-pytorch 摘要：  我们认为，为了实现超人智能体，未来的模型需要超人反馈才能提供足够的训练信号。目前的方法通常根据人类偏好来训练奖励模型，这可能会受到人类表现水平的瓶颈，其次这些单独的冻结奖励模型无法在 LLM 训练期间学习改进。在这项工作中，我们研究自我奖励语言模型，其中语言模型本身通过法学硕士作为法官来使用，提示在训练期间提供自己的奖励。我们表明，在迭代 DPO 培训期间，不仅提高了指令遵循能力，而且还提高了为自身提供高质量奖励的能力。在我们的方法的三个迭代中对 Llama 2 70B 进行微调，产生的模型优于 AlpacaEval 2.0 排行榜上的许多现有系统，包括 Claude 2、Gemini Pro 和 GPT-4 0613。虽然只是初步研究，但这项工作打开了大门模型可以在两个轴上不断改进的可能性。   https:// /preview.redd.it/l7vav40qngdc1.jpg?width=1344&amp;format=pjpg&amp;auto=webp&amp;s=9dce97a69f2ede66d6dabf6abbcfc75bf0e94f19 https://preview.redd.it/fuooe70qngdc1.jpg?width=1180&amp;format=pjpg&amp;auto=webp&amp;s =a88fcf1c765ff42c18091889f5b14cd371248760   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19atnu0/r_selfrewarding_language_models_meta_2024/</guid>
      <pubDate>Fri, 19 Jan 2024 21:01:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>