<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 11 May 2024 18:16:54 GMT</lastBuildDate>
    <item>
      <title>[P] 开源库，用于为 API 托管的视觉语言模型抓取 PDF、YouTube、URL、演示文稿等</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpnlqe/p_open_source_library_to_scrape_pdfs_youtube_urls/</link>
      <description><![CDATA[这里我将分享一个开源库，您可以使用从文件、网页、YouTube 视频等中提取文本和视觉非结构化数据，立即将结果输入 API 托管的视觉语言模型。我制作了这个简单的工具，因为我无法使用其他提取框架（例如 unstructuraldio、langchain 提取器、文档布局分析模型等）获得视觉功能。 Cheers &amp;玩得开心！   由   提交 /u/Confident-Honeydew66    reddit.com/r/MachineLearning/comments/1cpnlqe/p_open_source_library_to_scrape_pdfs_youtube_urls/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpnlqe/p_open_source_library_to_scrape_pdfs_youtube_urls/</guid>
      <pubDate>Sat, 11 May 2024 18:15:55 GMT</pubDate>
    </item>
    <item>
      <title>[D]帮助信用分析模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpn1dl/d_help_credit_analysis_model/</link>
      <description><![CDATA[我的项目的目标是评估用于信用卡欺诈检测的人工智能模型，以讨论其含义和应用。我将使用的数据由机构提供，虽然有些过时（从 2021 年开始），但它可以用于我的项目目标。 为了更好地了解所描述的一切到目前为止，我的开发目标是： a.审查并选择适当的人工智能技术来进行信用卡欺诈分析。 b.实施各种预测模型来识别欺诈模式。 c.使用真实数据样本评估和比较每个模型的准确性和效率。 d.根据准确性、处理速度以及与现有系统集成的难易程度等标准，推荐用于实际实施的最有效的一个或多个模型。 e。根据获得的结果提出欺诈检测流程的改进建议。 基于此，我有以下问题来了解我目前是否达到了目标：  &lt; p&gt;在了解项目并可视化数据后，我是否正确地处理了它，或者我应该给它另一个焦点，如果是这样，你会推荐什么？ 数据处理方式是否正确？ 为了为我的模型选择最有影响力的特征，我使用了递归特征消除技术。对于我想要解决的问题类型，是否可以应用这种技术，或者我应该实施另一种可能更强大的技术？ 关于模型的选择，您认为推荐任何其他可能对我的解决方案有帮助并且具有更多相关性和影响力的解决方案？我评估它们的方式以及获得的结果对您来说合乎逻辑吗？您认为它们可以应用于机构吗？要考虑它们并将其应用于实际情况，会缺少什么？  我还想知道测试模型的正确方法，因为我尝试使用以下命令创建合成数据集类似于我所拥有的特征，称为“合成数据”，但由于它是在与原始数据相同的条件下（不平衡和未经处理的数据），我不知道该怎么做。尽管我在网站上发现使用管道可以做到这一点，但我并不相信这一点。 除上述内容之外的任何其他观察或贡献也受到欢迎。 这是我的项目和数据文件： 笔记本： https://colab.research.google.com/drive/1DnluH0fMIuPF3ZOO0czRVZ2eliyHK4l7#scrollTo=Albbq_mLKsR-&amp;uniqifier=2 数据： https://drive.google.com/drive/folders/1eskK2avrZXFoCYzm87QbDMdlO2trZdPd?usp=sharing 提前致谢！   由   提交 /u/xilerooo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpn1dl/d_help_credit_analysis_model/</guid>
      <pubDate>Sat, 11 May 2024 17:49:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于制作预测模型的数据收集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpkyzj/r_data_collection_for_making_a_prediction_model/</link>
      <description><![CDATA[大家好，我是机器学习的初学者，我正在研究机器学习课程的项目。我正在尝试建立一个预测模型来检测人类是否沉迷于色情。但我需要一些有关数据集的帮助，因为我无法从互联网上找到任何帮助。请填写这个匿名谷歌表单来帮助这个新手（您可以找到问题的英语翻译和孟加拉语翻译）： https: //forms.gle/Cw63JwN9J58ymgac6   由   提交 /u/BroGotLost   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpkyzj/r_data_collection_for_making_a_prediction_model/</guid>
      <pubDate>Sat, 11 May 2024 16:13:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] LoRA 从头开始​​实现 LLM 分类器训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpj6b9/p_lora_from_scratch_implementation_for_llm/</link>
      <description><![CDATA[       由   提交/u/seraschka  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpj6b9/p_lora_from_scratch_implementation_for_llm/</guid>
      <pubDate>Sat, 11 May 2024 14:49:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 处理参考文献中冲突的训练配置。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpi9gc/d_dealing_with_conflicting_training/</link>
      <description><![CDATA[我正在研究对象检测的主动学习，目前我正处于需要设置训练配置来运行实验的阶段。我不打算重新运行其他作品的实验，因为我没有计算能力，也没有时间。但我仍然会将我的结果与他们的结果进行比较，为此我必须遵循这些作品中使用的训练配置。 问题是不同的论文报告了不同的配置，尽管他们正在将其结果与彼此。通常与其他方法进行比较的论文是 MI-AOD - CVPR21 论文，因为它是第一个 AL 方法CVPR 中的物体检测。对于 RetinaNet，他们训练了 26 个 epoch，LR 为 0.001，在第 20 个 epoch 时步进为 0.1。 然后是CVPR22论文使用标准 1x 时间表进行 RetinaNet 训练（12 个时期，0.02 LR，以及第 8 和 11 时期的步骤）。然而，他们将结果与 MI-AOD 论文进行比较，似乎他们并没有使用自己的设置重新运行实验，因为 mAP 看起来与原始报告中的结果完全相同。我只能通过外观来判断，因为它们只将比较显示为每个 AL 周期中的 mAP 图，而没有写下表中的值。他们也没有发布代码。 那么你就有 PPAL - CVPR24 声称使用与 MI-AOD 相同的配置，但在他们的代码中他们使用 0.002 的 LR，而不是他们在论文中声称的 0.001。他们还将结果与最后两个进行了比较，尽管配置不同，而且他们似乎也没有在这里重新运行实验（同样只有图，没有表格）。 外面还有其他一些作品CVPR的，他们通常倾向于遵循MI-AOD设置。 我的问题是，由于以上三个都在CVPR中，所以我至少需要将我的方法与他们的方法进行比较，但是如何我决定使用什么配置？我是否只需遵循他们论文中报告的最新 CVPR 并使用他们报告的结果与之前的作品进行比较？   由   提交 /u/notEVOLVED   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpi9gc/d_dealing_with_conflicting_training/</guid>
      <pubDate>Sat, 11 May 2024 14:05:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 翻译/配音最佳自适应 TTS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cph53t/d_best_adaptive_tts_for_translationdubbing/</link>
      <description><![CDATA[我正在寻找类似于 ElevenLabs Dubbing 服务的服务，您可以在其中输入音频/视频，并可以进行翻译后的音频输出，从而保留音调和性能原来的。开源是一个巨大的优势，但不是必需的。 我也不需要 ASR 和机器翻译组件，因为我可以使用其他服务。但如果其中包含这些内容，请告诉我您最喜欢什么！   由   提交 /u/photobeatsfilm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cph53t/d_best_adaptive_tts_for_translationdubbing/</guid>
      <pubDate>Sat, 11 May 2024 13:08:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] Marcus Hutter 在通用人工智能方面的工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpcwuz/r_marcus_hutters_work_on_universal_artificial/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpcwuz/r_marcus_hutters_work_on_universal_artificial/</guid>
      <pubDate>Sat, 11 May 2024 08:38:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLMinator：基于 Llama.cpp + Gradio 的开源聊天机器人，可直接从 HuggingFace 在本地（cpu/cuda）运行 llms</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpbgd1/p_llminator_a_llamacpp_gradio_based_opensource/</link>
      <description><![CDATA[      嗨我目前正在开发一个基于 Llama.cpp、Gradio、Langchain、Transformers 的上下文感知流媒体聊天机器人。 LLMinator 可以直接从 HF 和 LLM 中提取 LLM。在 cuda 或 cpu 上本地运行它们。 我正在寻找建议&amp;来自开源社区的帮助，以进一步发展这一点。 Github 存储库： https://github。 com/Aesthisia/LLMinator 目标：帮助开发人员使用 kickstarter 代码/工具运行 LLM。 https://preview.redd.it/fnzja7rjwqzc1.png?width=1846&amp;format= png&amp;auto=webp&amp;s=a62c43614d63e82156fef8722b986b051cc1795b 功能：  上下文感知聊天机器人。 内置代码语法突出显示。 直接从 HuggingFace 加载任何 LLM 存储库。 支持 CPU 和 CPU。 Cuda 模式。 加载和加载卸载已保存的模型。 命令行参数 API 访问（即将推出）  欢迎任何评论或反馈。   由   提交/u/hello-docker  /u/hello-docker  reddit.com/r/MachineLearning/comments/1cpbgd1/p_llminator_a_llamacpp_gradio_based_opensource/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpbgd1/p_llminator_a_llamacpp_gradio_based_opensource/</guid>
      <pubDate>Sat, 11 May 2024 06:59:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Scikit-Learn、Keras 和 TensorFlow 进行机器学习实践第二版</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpalcs/d_handson_machine_learning_with_scikitlearn_keras/</link>
      <description><![CDATA[这本书出版时我买了它并学习了几个章节。我真的很喜欢，但最终没有完成它，但现在我实际上有机会花时间在它上面，我想知道它是否足够最新（从 2019 年开始），或者是否会有一本更新的书涵盖类似的主题。  任何提示表示赞赏👍   由   提交 /u/ApplesAndAmazons   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpalcs/d_handson_machine_learning_with_scikitlearn_keras/</guid>
      <pubDate>Sat, 11 May 2024 06:04:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 GPU 集群上训练具有巨大嵌入的非常浅（点积）网络？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cpa4io/d_how_to_train_very_shallow_dot_product_networks/</link>
      <description><![CDATA[过去，我们使用数十台参数服务器和数百台 CPU 机器来训练如此繁重的嵌入轻型计算模型，并取得了令人印象深刻的吞吐量。如今，随着具有高速 NVlink 的 GPU 集群的出现，吞吐量实际上变得更差了。当然，我说的是十几台 GPU 机器，每台机器都有 8 个 A100。张量核心利用率非常低（&lt; 1%），但由于 all2all 通信，GPU 非常繁忙。我试图解决后一种设置可能存在的瓶颈问题，当参数数量变大时，无论 nvlink 有多快，all2all（或环所有减少等）本质上都比参数服务器慢?   由   提交/u/Crazy_Suspect_9512   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cpa4io/d_how_to_train_very_shallow_dot_product_networks/</guid>
      <pubDate>Sat, 11 May 2024 05:34:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] Google Colab 在训练我的图像数据集之前就崩溃了。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cou91s/p_google_colab_crashes_before_even_training_my/</link>
      <description><![CDATA[我有 780 张图像。所有这些都是微观的，我正在做微塑料图像检测。首先，我使用 U-Net 进行二元分类，然后使用 VGG-16 迁移学习。 Google Colab 一点也没有崩溃。效果非常好。 现在我正在做多类分割，预处理也差不多。除了一个用于彩色蒙版的额外通道之外。 但是，仅通过存储训练数据集的分类蒙版，我的系统 RAM 就超过了 6-7GB。调整大小后，我有 580 张图像，每张图像的尺寸为 512x512。不过，在调整大小之前它们甚至更小。 那么，这是怎么回事？任何帮助将不胜感激。 而不是每次以 npz 格式存储数据并将它们加载到变量中时进行预处理。它们的最大容量为 1GB。但没有更高。 我被困住了。已经两天了，但我根本无法训练。另外，我是一名学生，没有钱购买 Colab Pro。我的笔记本电脑是 GTX-1650，所以它的性能绝对不可能比 Google Colab 更好，尤其是因为我只有 8GB RAM。   由   提交/u/Plenty_Mention1787   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cou91s/p_google_colab_crashes_before_even_training_my/</guid>
      <pubDate>Fri, 10 May 2024 16:52:24 GMT</pubDate>
    </item>
    <item>
      <title>[N] 新书发布：使用 PyTorch 2.X 加速模型训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cos6bq/n_book_lauching_accelerate_model_training_with/</link>
      <description><![CDATA[大家好！我叫 Maicon Melo Alves，是一名专门研究 AI 工作负载的高性能计算 (HPC) 系统分析师。 我想宣布我的书“使用 PyTorch 加速模型训练 2” .X：通过提升模型训练过程来构建更准确的模型”最近由 Packt 推出。 本书面向想要了解如何使用 PyTorch 加速机器学习模型训练过程的中级数据科学家、工程师和开发人员。 &gt; 如果您认为本书可以帮助其他专业人士，请与您的社区分享这篇文章！ 😊 非常感谢！   由   提交/u/Various_Protection71   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cos6bq/n_book_lauching_accelerate_model_training_with/</guid>
      <pubDate>Fri, 10 May 2024 15:24:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找对小时工感兴趣的 ML 工程师的最佳社区/网站</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cook89/d_best_communitywebsite_to_find_ml_engineer/</link>
      <description><![CDATA[我一直在 Upwork 这样的平台上寻找机器学习工程师，但许多候选人似乎在从头开始构建模型方面经验有限。他们通常专注于集成预构建的 ML API，而不是开发根据特定要求定制的自定义模型。  哪里是寻找能够处理从数据收集到模型部署的整个模型开发过程的机器学习工程师的最佳地点？    由   提交/u/um877  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cook89/d_best_communitywebsite_to_find_ml_engineer/</guid>
      <pubDate>Fri, 10 May 2024 12:38:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mamba 中的“离散化”步骤到底是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1com9qh/d_what_on_earth_is_discretization_step_in_mamba/</link>
      <description><![CDATA[什么是“离散化”？信号/序列不是已经“离散”了吗？以代币的形式？请不要让我去看有关“线性状态空间模型的离散化”的维基百科文章，因为我无法与法学硕士建立任何联系。在我看来，Mamba 的核心只是具有动态 alpha 参数的 EMA，该参数是根据每个通道在时间 t 的当前代币计算得出的。不太明白“离散化”有什么好处？以及它对数据的实际作用。   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1com9qh/d_what_on_earth_is_discretization_step_in_mamba/</guid>
      <pubDate>Fri, 10 May 2024 10:26:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>