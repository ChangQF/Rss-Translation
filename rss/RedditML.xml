<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 13 Feb 2024 18:16:54 GMT</lastBuildDate>
    <item>
      <title>[D] ICLR openreview 可见吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq0ama/d_iclr_openreview_visible/</link>
      <description><![CDATA[我最近向 ICML 提交了一篇论文，但被 ICLR 拒绝了。我发现我在 ICLR 的 openreview 控制台中的论文是每个人都可以看到的。可以吗？由于ICLR和ICML中的论文标题相同，那么ICML可能不是完全匿名的。 我必须手动更改可见性吗？   由   提交/u/Shot-Button-9010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq0ama/d_iclr_openreview_visible/</guid>
      <pubDate>Tue, 13 Feb 2024 18:15:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] AI/ML 理学硕士主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq06v5/d_r_topic_for_msc_in_aiml/</link>
      <description><![CDATA[大家好， 目前我正在为我的论文寻找一个主题，我正在考虑机器视觉， 我的想法是应用机器学习来识别 X 射线扫描图像中的毒品或非法食品。 但我有点迷失从哪里开始寻找，或者即使有数据可用于培训。 感谢任何帮助   由   提交 /u/XicoLeite   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq06v5/d_r_topic_for_msc_in_aiml/</guid>
      <pubDate>Tue, 13 Feb 2024 18:11:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有办法通过考虑两种不同类型的嵌入来改进聚类？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apzau5/d_is_there_a_way_to_improve_clustering_by/</link>
      <description><![CDATA[假设您使用两个不同的预训练编码器生成嵌入。有没有办法利用这两种类型的嵌入来改进数据的聚类？有专门的术语吗？或者我可以读到一些以前的文献吗？   由   提交 /u/fullgoopy_alchemist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apzau5/d_is_there_a_way_to_improve_clustering_by/</guid>
      <pubDate>Tue, 13 Feb 2024 17:36:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] Fiddler：用于混合专家模型快速推理的 CPU-GPU 编排 - 华盛顿大学 2024 年 - 推理速度比现有系统快 10 倍以上！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apxr2n/r_fiddler_cpugpu_orchestration_for_fast_inference/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.07033  Github：https://github。 com/efeslab/fiddler  摘要：  基于专家混合 (MoE) 架构的大型语言模型 (LLM) 在各种任务。然而，由于模型尺寸巨大，在 GPU 内存资源不足的资源受限设置上运行它们具有挑战性。将模型权重卸载到 CPU 内存的现有系统面临着在 CPU 和 GPU 之间频繁移动数据的巨大开销。在本文中，我们提出了 Fiddler，一种资源高效的推理引擎，可为 MoE 模型提供 CPU-GPU 编排。 Fiddler的核心思想是利用CPU的计算能力来最小化CPU和GPU之间的数据移动。 我们的评估表明，Fiddler 可以运行参数超过 90GB 的未压缩 Mixtral-8x7B 模型，在具有 24GB 内存的单个 GPU 上每秒生成超过 3 个令牌，比现有方法有数量级的改进。  https ://preview.redd.it/q9l3fciyqdic1.jpg?width=1338&amp;format=pjpg&amp;auto=webp&amp;s=2e39726c970c655d6ee39f2b68c323204c6b2289 https://preview.redd.it/epjd0fiyqdic1.jpg?width=1661&amp;format=pjpg&amp;auto=webp&amp; ;s=701a2d61f8ab50d054db0301a30e40119898dab6   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apxr2n/r_fiddler_cpugpu_orchestration_for_fast_inference/</guid>
      <pubDate>Tue, 13 Feb 2024 16:34:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 vLLM 在 AWS EC2 上部署 Mixtral 8x7B、LLaMA 2 和 Mistral</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apxg42/d_deploy_mixtral_8x7b_llama_2_and_mistral_on_aws/</link>
      <description><![CDATA[大家好， 2023 年，许多复杂的开源 LLM 已经推出。然而，将这些人工智能模型集成到生产环境中仍然是一项复杂的任务。我撰写了一篇文章，将指导您在 AWS EC2 上部署一些顶级 LLM，即 LLaMA 2 70B、Mistral 7B 和 Mixtral 8x7B。我采用了一个能够批量处理和分布式推理的推理引擎：vLLM。 vLLM 将极大地帮助 LLaMA 2 和 Mixtral 的实现，因为它允许我们使用配备多个较小 GPU 的 AWS EC2 实例（例如例如 NVIDIA A10），而不是依赖单个大型 GPU（例如 NVIDIA A100 或 H100）。 请参阅此处的详细操作方法：https://nlpcloud.com/deploy-llama -2-mistral-and-mixtral-on-aws-ec2-with-vllm.html 在本教程中，我使用了 AWS EC2，但当然我也可以使用其他供应商。主要挑战是 GPU 的成本及其可用性。 请随时分享有关本文的反馈，我们将非常感激！ Julien   由   提交/u/juliensalinas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apxg42/d_deploy_mixtral_8x7b_llama_2_and_mistral_on_aws/</guid>
      <pubDate>Tue, 13 Feb 2024 16:22:44 GMT</pubDate>
    </item>
    <item>
      <title>[研究] GStreamer 中共享分析数据的框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apwwme/research_a_framework_to_share_analytics_data_in/</link>
      <description><![CDATA[GStreamer 长期以来一直是构建处理视频流（尤其是实时视频流）管道的最佳框架。工程师们广泛采用它来构建视频分析管道，尽管许多公司确实围绕 GStreamer 构建了机器学习分析框架，但到目前为止，还没有人做出努力为上游做出贡献。  https://www.collabora.com/news-and-blog/news-and-events/a-framework-to-share-analytics-data-in-gstreamer.html   由   提交 /u/mfilion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apwwme/research_a_framework_to_share_analytics_data_in/</guid>
      <pubDate>Tue, 13 Feb 2024 16:01:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] OS-Copilot：迈向自我完善的通用计算机代理 - 上海人工智能实验室2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apwlkm/r_oscopilot_towards_generalist_computer_agents/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2402.07456  Github：https://github.com/OS-Copilot/FRIDAY  摘要：  与计算机的自主交互一直是一个长期的挑战巨大的潜力，最近大型语言模型（LLM）的激增显着加速了构建数字代理的进展。然而，大多数这些代理都被设计为与狭窄的域交互，例如特定的软件或网站。这种狭隘的关注限制了它们对一般计算机任务的适用性。为此，我们引入了 OS-Copilot，这是一个构建通用代理的框架，能够与操作系统 (OS) 中的综合元素（包括 Web、代码终端、文件、多媒体和各种第三方应用程序）进行交互。我们使用 OS-Copilot 创建 FRIDAY，这是一个自我改进的实体代理，用于自动化一般计算机任务。 在通用人工智能助手基准 GAIA 上，FRIDAY 的性能比以前的方法高出 35%，通过以前任务中积累的技能展示了对未见过的应用程序的强大泛化能力。我们还提供了数值和定量证据，表明 FRIDAY 学会了控制和控制在最少的监督下自我改进 Excel 和 Powerpoint。 我们的 OS-Copilot 框架和实证研究结果为未来研究更强大、更通用的计算机代理提供了基础设施和见解。   https://preview.redd.it/uzec8udohdic1.jpg?width=1655&amp;format=pjpg&amp; ;auto=webp&amp;s=893b5561ca47c26c789b69925efdc26e5b783007 https://preview.redd.it/vfwfwudohdic1.jpg?width=1653&amp;format=pjpg&amp;auto=webp&amp;s=9eafc2a5ea0ad188a156d3de446508d82d9cc913  https://preview.redd.it/lmi8rwdohdic1.jpg?width=1123&amp;format =pjpg&amp;auto=webp&amp;s=dbc67b27585b980d0c592f9bd9f87f3ec6531f66 https://preview.redd.it/20yo21eohdic1.jpg?width=1037&amp;format=pjpg&amp;auto=webp&amp;s=72fab36d585b862eed4ff6c7deed2be0cd62f637   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apwlkm/r_oscopilot_towards_generalist_computer_agents/</guid>
      <pubDate>Tue, 13 Feb 2024 15:48:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] GNN 的应用 - 调查（视频）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apwl8v/r_applications_of_gnns_a_survey_video/</link>
      <description><![CDATA[大家好，我正在分享图神经网络 (GNN) 应用程序的概述解释视频： 🎥 https://youtu.be/9QH6jnwqrAk?si=nEARUXquZ0aetjCD 我整理了一批信息一个视频，重点介绍了 GNN 在 7 个不同领域的最新突破和具体应用。 GNN 最近取得了快速、疯狂的进步。尽管比其他人工智能流行语少得多炒作，但它们仅在去年就取得了许多成就。 我计划在 GNN 上创作更多内容，比如一个将深入探讨的短片系列深入了解 GNN 如何工作的（一些）技术细节等等。听到您对此的想法将非常有帮助！   由   提交/u/mrx-ai  /u/mrx-ai  reddit.com/r/MachineLearning/comments/1apwl8v/r_applications_of_gnns_a_survey_video/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apwl8v/r_applications_of_gnns_a_survey_video/</guid>
      <pubDate>Tue, 13 Feb 2024 15:48:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] [P] 通过贝叶斯优化将 LLM 评估速度提高 10 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apv97t/r_p_10_times_faster_llm_evaluation_with_bayesian/</link>
      <description><![CDATA[最近我一直致力于通过使用贝叶斯优化来选择合理的子集来快速进行 LLM 评估。 贝叶斯优化是使用它是因为它有利于探索/利用昂贵的黑匣子（释义，LLM）。 项目链接&lt; /p&gt; 我很想听听您对此的想法和建议！   由   提交 /u/b06901038g   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apv97t/r_p_10_times_faster_llm_evaluation_with_bayesian/</guid>
      <pubDate>Tue, 13 Feb 2024 14:51:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 为什么目标检测模型的对手看起来与图像分类器不同</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apv6ws/p_why_do_object_detection_model_adversaries_look/</link>
      <description><![CDATA[     &lt; /td&gt; 大家好。我只是想看看图像分类器上的对抗性攻击的行为，并决定也尝试使用对象检测器。我注意到对这些模型的无针对性的对抗性攻击产生了一些感兴趣的面具。图像分类器生成了通常预期的流行噪声掩模，但相同条件下的对象检测器生成了与所讨论的对象非常相似的掩模。这背后的原因是什么？感谢您的帮助！ 第一张图片是对象检测器的对抗性掩模，第二张图片是图像分类器的对抗性掩模，最后一张图片是原始图片。 &lt; a href=&quot;https://preview.redd.it/abo3yj7xddic1.png?width=425&amp;format=png&amp;auto=webp&amp;s=0e73a11997b2c27a6f73832204862d97e5847b4a&quot;&gt;https://preview.redd.it/abo3yj7xddic1.png?width =425&amp;format=png&amp;auto=webp&amp;s=0e73a11997b2c27a6f73832204862d97e5847b4a https://preview.redd.it/mbsi6k7xddic1.png?width=425&amp;format=png&amp;auto=webp&amp;s=41de2eca4348afbddfb36154da514046b1be78是 https://preview.redd.it/zusv0k7xddic1.jpg ?width=400&amp;format=pjpg&amp;auto=webp&amp;s=cf08f3911c24e10c632b12e42a976cd35ff3f490   由   提交/u/tatteredsky  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apv6ws/p_why_do_object_detection_model_adversaries_look/</guid>
      <pubDate>Tue, 13 Feb 2024 14:48:37 GMT</pubDate>
    </item>
    <item>
      <title>[2402.07901] FAST：加速 Transformer 的可分解注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aprsv9/240207901_fast_factorizable_attention_for/</link>
      <description><![CDATA[ 由   提交/u/Elven77AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aprsv9/240207901_fast_factorizable_attention_for/</guid>
      <pubDate>Tue, 13 Feb 2024 12:00:51 GMT</pubDate>
    </item>
    <item>
      <title>您的 RAG 设置中有什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apcp2w/whats_in_your_rag_setup_d/</link>
      <description><![CDATA[您在 RAG 中使用哪些框架和库？  我最好奇LangChain是否像以前一样受欢迎？ 这是我的高级版本：   langchain使用OpenAI用于创建嵌入 Pinecone 用于存储嵌入 langchain 用于加载文档分割器和字符分割器以进行分块 Mongo 用于对话内存  ​   由   提交 /u/EnvironmentalDepth62   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apcp2w/whats_in_your_rag_setup_d/</guid>
      <pubDate>Mon, 12 Feb 2024 22:14:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 RMSNorm 在 Transformer 中比 LayerNorm 更快很重要？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apb3th/d_why_does_it_matter_that_rmsnorm_is_faster_than/</link>
      <description><![CDATA[最近发布的 LLM 中很大一部分都使用 RMSNorm 而不是 LayerNorm。 原始 RMSNorm 论文 (https://arxiv.org/pdf/1910.07467.pdf），我见过的大多数参考文献都认为 RMSNorm 比 LayerNorm 更好，因为它是计算效率更高。 但是，LayerNorm 只占整体计算的一小部分，因此我不清楚为什么加速会有很大帮助。渐进地，LayerNorm 为 O(d_model)，而像 MLP 这样的组件为 O(d_model2 )，或者注意力为 O(d_model*seq_len + d_model2 ）。 是否只是 LayerNorm 的平均居中部分没有那么有用，因此 RMSNorm 可以在不影响表现力的情况下为您带来轻微的效率提升？或者 RMSNorm 还有其他我没有看到的好处吗？   由   提交/u/kei147  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apb3th/d_why_does_it_matter_that_rmsnorm_is_faster_than/</guid>
      <pubDate>Mon, 12 Feb 2024 21:09:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 神经网络可训练性的边界是分形的 - Jascha Sohl-Dickstein</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ap92d8/r_the_boundary_of_neural_network_trainability_is/</link>
      <description><![CDATA[值得一读，只是为了简洁的可视化。 https://sohl-dickstein.github.io/2024/02/12/fractal.html https://arxiv.org/abs/2402.06184   由   提交 /u/currentscurrents   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ap92d8/r_the_boundary_of_neural_network_trainability_is/</guid>
      <pubDate>Mon, 12 Feb 2024 19:50:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>