<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 25 Jun 2024 15:15:03 GMT</lastBuildDate>
    <item>
      <title>[D] ICLR与AISTATS之间的区别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do796a/d_difference_between_iclr_and_aistats/</link>
      <description><![CDATA[这里有一个重复的问题，但我想再次提出这个话题，因为九月/十月的截止日期即将到来，现在情况可能已经发生了变化。 三大 ML 会议是 ICML/NeurIPS/ICLR，它们将一年分为 3 个截止日期。然而，AISTATS 也享有良好的声誉。 ICLR 和 AISTATS 的截止日期非常接近，因此许多人不得不决定将自己的工作提交给哪个。 由于深度学习 (DL) 的流行，ICLR 迅速崛起，但现在人们似乎将其与 ICML/NeurIPS 等同对待，那里似乎有相当多的非 DL 和理论 ML 论文。 问题：对于纯经验性的 DL 论文，将它们提交给 ICLR 似乎是理所当然的。那么 (1) 具有更多理论结果的 ML 论文，或 (2) 没有 DL（例如统计 ML）的 ML 论文呢？ 将这些作品提交给 ICLR 和 AISTATS 的利弊是什么？ 需要考虑的一些方面：  对于这些类型的工作，AISTATS 是否会降低声望或受到 ML 社区的较少关注？ 向 ICLR 提交理论作品的体验如何？（例如，那里的审稿人会要求进行许多实验吗？） 行业/学术界对 ICLR 是否更重要，或者对 ICLR 和 AISTATS 的待遇相同（对于更多理论性作品）？  免责声明：请不要再说“作品本身比出版地点更重要”，这显然是正确的，但并没有太多帮助。    提交人    /u/zy415   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do796a/d_difference_between_iclr_and_aistats/</guid>
      <pubDate>Tue, 25 Jun 2024 14:24:15 GMT</pubDate>
    </item>
    <item>
      <title>[N] 探索苹果如何优化设备内置 AI 技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do4xrw/n_exploring_how_apple_might_optimize_techniques/</link>
      <description><![CDATA[大家好！在论坛上就 Apple 可能在优化设备上 AI 技术方面所做的技术进行了很好的讨论之后。我们讨论了创新方法及其实际应用。 对于那些感兴趣的人，这里有一篇详细的文章，总结了要点并探讨了 Apple 可能用来直接在设备上增强 AI 功能的可能技术：探索 Apple 如何优化设备上 AI 的技术    提交人    /u/BriefAd4761   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do4xrw/n_exploring_how_apple_might_optimize_techniques/</guid>
      <pubDate>Tue, 25 Jun 2024 12:36:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 LlamaIndex 索引进行 OS 海量文档分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do4ujr/p_os_mass_document_analytics_with_llamaindex_index/</link>
      <description><![CDATA[      大家好，我与大家分享我的最新开源项目，用于在大量文档中进行海量数据提取和问答。您可以将目标数据模式定义为 pydantic 模型或 python 基元。布局元素和人工注释会自动嵌入并作为 LlamaIndex VectorStore 进行访问。如果您编写自定义 LlamaIndex 问答管道，它们将显示在前端并可应用于语料库。 我已经在 OpenContracts 上工作多年了。虽然它最初是一种标记和注释文档的工具，但由于 LLM 和矢量数据库的最新进展，我发布了一个新版本，其中包含许多很酷的功能，可以使用 LLM、矢量搜索和 AI 代理。它基于 Django，随着时间的推移，Django 变得越来越强大，这让我感到惊讶！ 主要功能：  管理文档 - 管理文档集合 布局解析器 - 自动从 PDF 中提取布局特征 自动矢量嵌入 - 为上传的 PDF 和提取的布局块生成 可插入式微服务分析器架构 - 让您分析文档并自动对其进行注释 人工注释界面 - 手动注释文档，包括多页注释。 LlamaIndex 集成 - 使用我们的矢量存储（由 pgvector 提供支持）和任何手动或自动注释的功能让 LLM 智能地回答问题。 数据提取 - 使用复杂的 LLM 支持的查询在数百个文档中提出多个问题行为。我们的示例实现使用 LlamaIndex + Marvin。 自定义数据提取 - 自定义数据提取管道可用于前端批量查询文档。  查看 repo 或文档！    提交人    /u/TallTahawus   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do4ujr/p_os_mass_document_analytics_with_llamaindex_index/</guid>
      <pubDate>Tue, 25 Jun 2024 12:31:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据产品的 Medallion 方法：超越承诺的“黄金”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do4pfq/d_medallion_approach_to_data_products_beyond_the/</link>
      <description><![CDATA[值得信赖并不意味着经过认证：数据网格中不同程度的信任 在本文中，我们的客座作者 Francesco De Cassai 试图阐明关于数据资产被视为数据产品的信任程度的争论。在这篇富有洞察力的文章中，他谈到了：  “信任”的基本原理：可发现、可寻址、值得信赖、安全、可互操作和自我描述 不同程度的可信度 统治一切的数据政策  在文章中获得有关这些相关方面的详细观点和解释。  在此处阅读完整文章：https://moderndata101.substack.com/p/medallion-approach-to-data-products    提交人    /u/growth_man   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do4pfq/d_medallion_approach_to_data_products_beyond_the/</guid>
      <pubDate>Tue, 25 Jun 2024 12:24:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 需要帮助理解这篇论文。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do44r5/r_need_help_in_understanding_this_paper/</link>
      <description><![CDATA[我正在尝试理解论文“Instacart 的基于嵌入的杂货搜索模型”。我理解了预热和级联数据集的原因。我不明白共享编码器和双塔模型之间的区别。假设我有正向 &lt;查询，产品&gt; 匹配。它是如何训练并与负向匹配进行比较的。有人可以建议如何重新创建这篇论文吗？ https://preview.redd.it/i47q4rpxan8d1.png?width=1385&amp;format=png&amp;auto=webp&amp;s=19888b7803e52718f4b32d19f28b70744d51e01e    提交人    /u/Legitimate_Celery_69   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do44r5/r_need_help_in_understanding_this_paper/</guid>
      <pubDate>Tue, 25 Jun 2024 11:52:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我对 GPT-2 和 BERT 进行了 135,000 次微调，以查看使用测试集中未标记的文本进行预训练是否公平</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do2g03/r_i_finetuned_gpt2_and_bert_135000_times_to_see/</link>
      <description><![CDATA[      TL;DR：似乎很公平。 每个人都知道，如果您想使用标记的测试数据进行评估，则对其进行训练是大忌。 但是，如果您对未标记的测试数据进行预训练，那么您仍然可以在评估期间使用这些数据吗？ 让我们对 25 个文本分类数据集、两个 LM（我们非常确定其预训练数据尚未受到污染）以及一些训练和测试观察数量的设置进行实验。 对于每个数据集，实验健全性检查对未标记文本（独立于测试集）进行预训练是否有帮助，即是否有效果可检测。称之为预训练提升。接下来，实验评估了使用测试集中的未标记文本（而不是未标记的独立文本）进行预训练的偏差。 将此称为评估偏差。 结果 ​ m=50 基于真实世界带注释的少量样本任务 (RAFT) 基准（https://arxiv.org/abs/2109.14076），该基准也包含了这个问题的灵感：“对于每个任务，我们发布一个包含 50 个示例的公共训练集和一个更大的未标记测试集。我们鼓励对未标记的示例进行无监督预训练……”。上面的分布是边际效应的分布：对 2 个 LM 类型、25 个分类任务及其子样本取平均值。 在这里，将“少数”的含义延伸到少样本中。我想看看结果会如何变化。还是一样。 平均而言，在每种情况下，对未标记的文本进行预训练显然都是有益的。尽管如此，没有证据表明存在不公平现象。评估偏差在 0 附近波动，并且微不足道。在任务级别，结果是一致的：在 25 项任务中，除了 2 项之外，预训练对所有任务都有好处，其中 12 项的评估偏差为正，13 项为负，绝对值始终小于 1%。 元分析 我还想看看 GPT-2 和 BERT 微调的少量基准测试有多稳定（不稳定）。在上面的实验中，通过从每个数据集中抽取最多 100 个子样本来揭示这种差异。（这种技术复制是标题中 135k 这个数字的原因。）如果实验只取一个子样本会怎样？这就是大多数小样本基准测试的有效做法。 事实证明，如果我们对 25 个数据集中的每个数据集抽样 500 个未标记文本、100 个分类示例和 500 个评估示例，则实验报告不可忽略的正偏差或负偏差的可能性为 47%，而不是我们从重复子样本中发现的接近 0 的偏差。从粗略的意义上讲，包括 25 个数据集（每个数据集有 1.1k 个观测值）似乎有很多数据。实际上，这并不比抛硬币好。 如今，人们对差异的认识越来越深刻（例如，https://arxiv.org/abs/2406.10229）。而且，与参数高效或基于提示的 LLM 方法相比，对 GPT-2 或 BERT 进行微调可能更不稳定。但我对在我的少样本研究中看到这种程度的不稳定感到很惊讶。 代码、数据、论文 以下是用于重现实验和分析的所有代码和数据，以及论文链接：https://github.com/kddubey/pretrain-on-test    提交人    /u/KD_A   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do2g03/r_i_finetuned_gpt2_and_bert_135000_times_to_see/</guid>
      <pubDate>Tue, 25 Jun 2024 10:07:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如今，亚马逊和沃尔玛等电子商务公司如何产生互补推荐（或经常一起购买）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnwfis/d_how_do_ecomm_companies_like_amazon_and_walmart/</link>
      <description><![CDATA[我最近开始研究推荐系统。我知道过去是使用一些统计算法（如 FP-Growth 和 Prod2Vec）来实现的。    提交人    /u/Abs0lute_Jeer0   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnwfis/d_how_do_ecomm_companies_like_amazon_and_walmart/</guid>
      <pubDate>Tue, 25 Jun 2024 03:30:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 成绩评分：量化 LLM 在选项选择方面的表现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnpsap/r_grade_score_quantifying_llm_performance_in/</link>
      <description><![CDATA[  由    /u/FutureIsMine  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnpsap/r_grade_score_quantifying_llm_performance_in/</guid>
      <pubDate>Mon, 24 Jun 2024 22:03:58 GMT</pubDate>
    </item>
    <item>
      <title>当前最佳自托管翻译模型 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dno1ym/best_current_selfhosted_translation_models_d/</link>
      <description><![CDATA[我正在寻找最新的 ML 翻译和语言检测模型，最好是自托管的。遗憾的是，Libretranslate 无法生成与 Google Translate 或 Azure 相当的翻译，而 DeepL 太贵了。 典型用例：检测语言 -&gt; 将输入翻译成英语。    提交人    /u/AdaObvlada   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dno1ym/best_current_selfhosted_translation_models_d/</guid>
      <pubDate>Mon, 24 Jun 2024 20:50:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 为什么关于时间序列预测的联邦学习的高质量作品很少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnnlpm/r_why_there_are_few_highquality_works_about/</link>
      <description><![CDATA[我即将开始实习，我的导师要求我针对时间序列预测进行一些联邦学习方面的研究。与 cv 和 nlp 等其他任务相比，我发现来自高排名会议/期刊的高质量论文非常少。有人知道原因吗？主要的挑战是什么？    提交人    /u/by0724   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnnlpm/r_why_there_are_few_highquality_works_about/</guid>
      <pubDate>Mon, 24 Jun 2024 20:31:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 RAG 有疑问？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnngts/d_questions_about_rag/</link>
      <description><![CDATA[随着维数的增加，参考点、最大点和最小点之间的距离趋向于 0。我的问题是，当我们执行 RAG 时，我们会对高维数据执行，那么当距离变得无法区分时，我们如何收集最相似的点，除非使用非常高的阈值。最好这样做：  获取源文档的嵌入 减少嵌入 使用降维器计算查询的定位 然后使用它来确定最近的点  降维    提交人    /u/spx416   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnngts/d_questions_about_rag/</guid>
      <pubDate>Mon, 24 Jun 2024 20:26:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 模型合并——您的看法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnm1m0/d_model_merging_whats_your_take/</link>
      <description><![CDATA[我一直在阅读有关模型合并及其可实现的出色性能的文章。我喜欢任务算法之类的方法，但 TIES 和 DARE 似乎更受欢迎。同时，其中一些解决方案似乎非常具有启发性。 您的看法是什么？有直接经验吗？我猜没有采用批判性观点的调查/教程，但如果你知道，请链接它。    提交人    /u/gized00   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnm1m0/d_model_merging_whats_your_take/</guid>
      <pubDate>Mon, 24 Jun 2024 19:27:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 通过哪个目标我可以得到更理想的准确率-召回率阈值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnhwyn/d_with_which_objective_do_i_get_a_more_desirable/</link>
      <description><![CDATA[      更高的auc-roc，但不理想 更低的auc-roc，但可取的 我有一个不平衡的二元分类数据集（60/40）。但是，我确实应用了类平衡（使用 BinaryFocalCrossentropy）。对于调整过程，我尝试优化 AUC-PR 和 AUC-ROC，但不断得到这些结果，如图像中所示，其中第一张图像的分数更高，但更不理想。这里对于选择客观指标的建议是什么？我会使用 F1 分数，但我真的不关心特定阈值下的性能，只要它在某个阈值下表现良好即可。    提交人    /u/blearx   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnhwyn/d_with_which_objective_do_i_get_a_more_desirable/</guid>
      <pubDate>Mon, 24 Jun 2024 16:36:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些大学和研究中心专注于对抗性机器学习（尤其是在德国）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnctew/d_which_universities_and_research_centers_are/</link>
      <description><![CDATA[大家好，我很好奇对抗性学习的核心研究进展。查看出版物，我确实看到了来自不同组织的几篇论文，但很少看到一个组织宣传他们专注于对抗性学习领域。特别是德国的大学和研究所。    提交人    /u/i_sanitize_my_hands   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnctew/d_which_universities_and_research_centers_are/</guid>
      <pubDate>Mon, 24 Jun 2024 12:56:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>