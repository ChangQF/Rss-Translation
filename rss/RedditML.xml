<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 24 Dec 2023 01:03:20 GMT</lastBuildDate>
    <item>
      <title>[D] 2023年美国博士生AI研究实习流程图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18pgih9/d_flowchart_of_2023_ai_research_internship_search/</link>
      <description><![CDATA[       由   提交/u/Dependent_Use_8436   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18pgih9/d_flowchart_of_2023_ai_research_internship_search/</guid>
      <pubDate>Sat, 23 Dec 2023 22:17:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 AWS Athena 文档微调 Mistral 7b</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18pftbc/p_finetuning_mistral_7b_with_aws_athena/</link>
      <description><![CDATA[这将是我第一次尝试微调 LLM。 Mistral 7b 在遇到架构和问题时生成 SQL 查询的能力给我留下了深刻的印象。但是，我需要它以 AWS 的 Athena 方言运行。文档位于：https://docs.aws.amazon.com/athena/ 我在 Reddit 子版块中发现了另一个帖子，其中有人抓取了整个 UE5 引擎的文档，并将其用于 Mistral 7b 之上的 LoRA 的训练数据。这看起来是一个合理的方法吗？我也对其他替代方案持开放态度。   由   提交 /u/TheCoconutTree   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18pftbc/p_finetuning_mistral_7b_with_aws_athena/</guid>
      <pubDate>Sat, 23 Dec 2023 21:42:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] WMT14 En-De 数据集 `news-commentary-v9.de-en.en` 和 `news-commentary-v9.de-en.en` 不匹配。我该如何解决？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18pflz8/d_wmt14_ende_dataset_newscommentaryv9deenen_and/</link>
      <description><![CDATA[   /u/EuniQue0704   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18pflz8/d_wmt14_ende_dataset_newscommentaryv9deenen_and/</guid>
      <pubDate>Sat, 23 Dec 2023 21:32:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自监督学习中学习表征的统计？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18pebl4/d_statistics_of_learned_representations_in/</link>
      <description><![CDATA[我还没有对 SSL 的现代文献进行广泛的回顾，但我之前就在考虑这个问题。是否有任何努力让学习的表示具有诸如与不同伪标签相关的数据分布之间的最大区分度之类的东西？ （有点像 LDA 排名分解） 或者，如果您有非常复杂的数据，无法根据其伪标签“强制”进入可分离的分布，那么这实际上是一个坏主意吗？  从某种意义上说，这就是为什么表示学习一直让我感到困惑，因为我不完全理解我们如何衡量学习特征的质量，我们想要出现什么属性，我们的代表性如何学习到原始原始数据的特征等   由   提交/u/Complete_Bag_1192   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18pebl4/d_statistics_of_learned_representations_in/</guid>
      <pubDate>Sat, 23 Dec 2023 20:30:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关 GrimesAI 所用模型和歌曲生成替代方案的信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18pak1r/d_seeking_information_on_the_model_used_for/</link>
      <description><![CDATA[大家好！ 我正在深入探索人工智能语音合成的迷人世界，并且有一个具体的查询。有谁知道GrimesAI是使用哪种AI模型来开发的？我对提供超出标准语音合成功能的模型特别感兴趣。 理想情况下，我正在寻找一个模型，该模型允许我输入一些语音样本，然后使用它们来演唱整首歌曲。虽然 ElevenLabs 在语音克隆方面做得很好，但它似乎主要适合常规对话。我的目标是能够处理更细致的声音任务，比如唱歌，并具有相同的真实感。 任何对擅长唱歌和语音调制的模型的见解或建议将不胜感激。我渴望进一步探索这项技术，看看它如何将简单的语音样本转化为优美的旋律。 提前感谢您的帮助！   由   提交/u/yachty66  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18pak1r/d_seeking_information_on_the_model_used_for/</guid>
      <pubDate>Sat, 23 Dec 2023 17:31:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用 Vision Transformers 或 ViViT 预处理视频分类数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18pa7uo/d_how_to_preprocess_dataset_for_video/</link>
      <description><![CDATA[我的数据集结构 数据集 |---正在运行 | ---视频 1 ... 视频 80 |--- 行走 |---视频 1 ... 视频 80 |-- -坐 |---视频1 ...视频80 帧存储在每个视频目录中，帧率为1 fps，每个视频目录具有不同的帧数。我想知道如何预处理这些数据并将其输入视觉转换器。   由   提交 /u/XilentXenocide   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18pa7uo/d_how_to_preprocess_dataset_for_video/</guid>
      <pubDate>Sat, 23 Dec 2023 17:14:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] 万事通，多才多艺：设计通用的从粗到细的视觉语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18p887s/r_jack_of_all_tasks_master_of_many_designing/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.12423 项目页面：https:/ /shramanpramanick.github.io/VistaLLM/ 摘要：  大型语言模型（LLM）处理的能力视觉输入催生了通用视觉系统，通过指令调整来统一各种视觉语言（VL）任务。然而，由于视觉领域输入输出格式的巨大多样性，现有的通用模型无法成功地将分割和多图像输入与粗级任务集成到单个框架中。在这项工作中，我们介绍了 VistaLLM，这是一个强大的视觉系统，可以使用统一的框架处理单个和多个输入图像上的粗粒度和细粒度的 VL 任务。 VistaLLM 利用指令引导的图像标记器，使用任务描述过滤全局嵌入，从大量图像中提取压缩和细化的特征。此外，VistaLLM 采用梯度感知自适应采样技术将二进制分段掩码表示为序列，与以前使用的均匀采样相比显着改进。为了增强 VistaLLM 的所需功能，我们策划了 CoinIt，这是一个包含 680 万个样本的全面的从粗到精的指令调整数据集。我们还通过引入一项新任务 AttCoSeg（属性级联合分割）来解决多图像基础数据集的缺乏，该任务增强了模型对多个输入图像的推理和基础能力。对各种 V 和 VL 任务进行的大量实验证明了 VistaLLM 的有效性，它可以在所有下游任务的强大基线上实现一致的最先进性能。我们的项目页面可以在 这个 https URL 找到。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18p887s/r_jack_of_all_tasks_master_of_many_designing/</guid>
      <pubDate>Sat, 23 Dec 2023 15:39:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视觉语言：法学硕士如何生成图像！ （谷歌双子座、Dall-E）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18p878r/d_language_of_vision_how_llms_generate_images/</link>
      <description><![CDATA[      大家好，分享我频道中的 YT 视频，其中讨论了多模式 LLM 如何逐个生成图像。对于对该主题感兴趣的人，请点击上面的链接。谢谢！   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18p878r/d_language_of_vision_how_llms_generate_images/</guid>
      <pubDate>Sat, 23 Dec 2023 15:38:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] Pearl：生产就绪的强化学习代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18p82zf/r_pearl_a_productionready_reinforcement_learning/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.03814 代码：https://github .com/facebookresearch/pearl 项目页面：https://pearlagent. github.io/ 摘要：  强化学习（RL）为实现长期目标提供了一个多功能框架。它的通用性使我们能够形式化现实世界智能系统遇到的各种问题，例如处理延迟奖励、处理部分可观察性、解决探索和利用困境、利用离线数据提高在线性能以及确保安全约束遇见了。尽管强化学习研究社区在解决这些问题方面取得了相当大的进展，但现有的开源强化学习库往往只关注强化学习解决方案管道的一小部分，而其他方面基本上无人关注。本文介绍了 Pearl，这是一个生产就绪的 RL 代理软件包，专门设计用于以模块化方式应对这些挑战。除了提供初步基准测试结果外，本文还重点介绍了 Pearl 的行业采用情况，以证明其已做好生产使用的准备。 Pearl 在 Github 上开源，位于 此 http URL，其官方网站位于 这个http URL。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18p82zf/r_pearl_a_productionready_reinforcement_learning/</guid>
      <pubDate>Sat, 23 Dec 2023 15:32:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 需要在神经进化算法中选择父母的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18p3im8/p_need_advice_selecting_parents_in_neuroevolution/</link>
      <description><![CDATA[我是一个无名小卒，由于缺乏替代方案而创建了自己的神经进化算法。到目前为止它运行得很好，但在最终确定之前我遇到了一个问题，希望有人能给我一些好的建议。 该算法（像许多其他算法一样）基于基因组群体。在每一代结束时，最差基因组的一部分（可配置参数）被删除，剩余的部分用于交配。 这就是我的问题所在，因为在我的脑海里有三个选择父母的方式（可能还有更多，但目前这三种对我来说已经足够了）。 首先，父母双方都可以从总体中完全随机选择。其次，可以使用适应度来衡量选择的权重，以便具有最高适应度的基因组具有更高的繁殖概率。基于此，有两种可能性，即仅选择一个亲本加权，或两者都选择。 我尝试对所有三个选项进行统计评估，但不幸的是，突变等随机因素意味着所有选项平均表现同样好。 进行的测试：每次 30 代的 100 次试验的平均适应度分数。 有人在这方面有任何经验吗？是否相关或者对于进化论是否有统一的观点？从我的观点（以及我所学到的）来看，“最适者”是最适合的。交配时个体总是优先的。 希望群体智能能够帮助我，祝您节日快乐。    ;由   提交/u/Weekly_Branch_5370   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18p3im8/p_need_advice_selecting_parents_in_neuroevolution/</guid>
      <pubDate>Sat, 23 Dec 2023 11:11:06 GMT</pubDate>
    </item>
    <item>
      <title>[项目] MiniBoosts：用 Rust 编写的 boosting 算法的一个小集合🦀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18p2dkj/project_miniboosts_a_small_collection_of_boosting/</link>
      <description><![CDATA[       由   提交 /u/__leopardus__   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18p2dkj/project_miniboosts_a_small_collection_of_boosting/</guid>
      <pubDate>Sat, 23 Dec 2023 09:48:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士可解释性研究知识库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ozqu1/r_llm_interpretability_research_repository/</link>
      <description><![CDATA[对于任何对 LLM 可解释性感兴趣的人，我创建了以下存储库： https://github.com/JShollaj/awesome-llm-interpretability 它包含一组精选的开源工具、论文、文章、群组等。 请随意查看&amp;希望它对您的研究有所帮助。   由   提交 /u/XhoniShollaj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ozqu1/r_llm_interpretability_research_repository/</guid>
      <pubDate>Sat, 23 Dec 2023 06:38:23 GMT</pubDate>
    </item>
    <item>
      <title>泰勒级数注意[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18oxc65/taylor_series_attention_discussion/</link>
      <description><![CDATA[我最近读完了动物学博客文章关于 BASED，一种新的语言模型，它使用局部卷积和使用泰勒级数近似的自注意力，似乎基于本文。&lt; /p&gt; 读完后我的一个问题是这种局部卷积对模型性能有多重要？是否有关于仅采用这种泰勒注意力的变压器架构的研究？ BASED 模型显然具有良好的性能，论文提供的直观理解是，这些卷积在 AR 不是一个大挑战的短距离场景中使模型受益，这是有道理的，但普通注意力对于 AR 或短距离困惑没有问题。答案是泰勒近似在这些短距离情况下会不太准确，需要卷积来补偿吗？   由   提交 /u/Aggressive-Solid6730    reddit.com/r/MachineLearning/comments/18oxc65/taylor_series_attention_discussion/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18oxc65/taylor_series_attention_discussion/</guid>
      <pubDate>Sat, 23 Dec 2023 04:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么张量程序没有像神经切线核那样受到同样的关注？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18oq5us/d_why_have_tensor_programs_not_received_the_same/</link>
      <description><![CDATA[神经正切核经常在理论论文中被引用，作为推广线性函数逼近器证明的基础。然而，它们有几个缺点，即它们不包含特征学习的概念。张量程序应该可以解决这个问题，但我认为我从未在理论论文中看到过它们被引用。人们是否怀疑结果或认为结果缺乏严谨性？结果是否被认为不太有用？或者它们只是因为数学上更复杂且更难学习而使用较少？  我问这个问题的部分原因是我想知道它是否值得花精力去阅读和理解整个论文系列，或者这项工作是否经过深思熟虑。    由   提交 /u/OptimizedGarbage   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18oq5us/d_why_have_tensor_programs_not_received_the_same/</guid>
      <pubDate>Fri, 22 Dec 2023 22:03:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>