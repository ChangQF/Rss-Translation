<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 25 Sep 2024 12:32:49 GMT</lastBuildDate>
    <item>
      <title>【项目】本土LLM神器与思考——Gallama UI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp2z44/project_local_llm_artifact_and_thinking_gallama_ui/</link>
      <description><![CDATA[      嗨，这是我的个人项目，用于探索 Artifact 系统（类似于 Claude）以及本地 LLM 上的思路链提示。 简短的 GIF 表示它的样子：gallamaUI https://preview.redd.it/s8jb1kn7oxqd1.png?width=3537&amp;format=png&amp;auto=webp&amp;s=50edfd22abd607ef7ad9d4f0869072cb7e08a064 您还可以查看这个 YouTube 视频，看看它是否值得您花时间。您可以在实时演示中看到它 Youtube 演示 Github：https://github.com/remichu-ai/gallamaUI 特点：  本地 LLM 工件系统（如 Claude） 可通过 XML 模板自定义思路链 使用 exllamav2 或 llama cpp python（通过 gallama）  推荐使用以下模型进行尝试：  最佳选择：Qwen2.5-72B/ 32B 和 Mistral Large 第二选择：Qwen-2-72B， Llama-3.1-70B 第三选择：Yi-34B、Codestral、Gemma-29B  这不适用于其他后端，如 ollama、tabby 等。因为后端是选择性的，并实现了某种方法来强制生成    提交人    /u/Such_Advantage_6949   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp2z44/project_local_llm_artifact_and_thinking_gallama_ui/</guid>
      <pubDate>Wed, 25 Sep 2024 12:17:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 攻读博士学位值得吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp2y78/d_is_phd_worth_it/</link>
      <description><![CDATA[你好，我是一名本科生，计划去美国留学 我很喜欢理解机器学习的主题，但是当我看到其他人说 phd 不值得并且它相当于 master 的消息时，我真的很担心，因为我不想浪费我生命中的 6 或 7 年而得不到更多的钱。 读 phd 只是为了兴趣还是可以赚更多的钱？ 如果你有作为国际学生获得 PhD 学习签证的经历，我很乐意分享。    提交人    /u/Training_Can8781   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp2y78/d_is_phd_worth_it/</guid>
      <pubDate>Wed, 25 Sep 2024 12:15:54 GMT</pubDate>
    </item>
    <item>
      <title>[N] Uber 创建 GenAI 网关镜像 OpenAI API 以支持超过 60 个 LLM 用例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp2kdz/n_uber_creates_genai_gateway_mirroring_openai_api/</link>
      <description><![CDATA[https://www.infoq.com/news/2024/09/uber-genai-gateway-llm-openai/ Uber 创建了一个统一的平台，用于为来自外部供应商和自托管供应商的大型语言模型 (LLM) 提供服务，并选择镜像 OpenAI API 以帮助内部采用。GenAI Gateway 提供了一致且高效的界面，并在许多领域为 60 多个不同的 LLM 用例提供服务。    提交人    /u/rgancarz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp2kdz/n_uber_creates_genai_gateway_mirroring_openai_api/</guid>
      <pubDate>Wed, 25 Sep 2024 11:55:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 整流流 ODE 的样本质量不会因模型规模增大或架构变化而提高</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp1q9f/d_the_quality_of_samples_from_rectified_flow_ode/</link>
      <description><![CDATA[      我不知道训练整流流 ODE 是否有一些技巧，但无论我制作的模型有多大，添加更多层，彻底改变架构，训练时间更长，添加一些数据增强，如水平翻转，使用 EMA 进行模型平均，我无法让它生成比具有大约 200 万个参数的简单 ConvNet 更好的东西。我尝试将模型扩展到 80M，但它生成的样本几乎与简单的 ConvNet 完全相同。例如，这里有一张图片，其中顶行是来自 2M ConvNet 的样本，底行是 10M Transformer： 2M ConvNet vs 10M Trasnformer 我能看到的唯一效果是生成的样本更平滑，但它们看起来仍然不像你会说的东西：是的，这是一只鸟。我尝试过的东西：  模型架构：(Conv)ResNet、Transformer、类似 Mamba 的前缀扫描 更多层，更少层 RMS 正则化、层正则化、批量正则化 不同的 ODE 求解器 - RK45、欧拉方法、中点方法、更多步骤、更少步骤 嵌入时间的不同方式 - 离散化、procjet 和添加、投影和连接、乘法、每个块的添加 不同的模型大小，从 2M - 80M，差别不大 EMA - 模型平均 训练更多时期 不同的学习率和学习率计划 训练期间的不同采样策略 - 对数范数、均匀 数据增强 - 水平翻转  最后，不同大小的不同模型的样本看起来非常相似，我不确定我在看什么。唯一的区别似乎是伪影、色彩饱和度或多或少，但总体而言，这是同一幅图像。 数据集：CIFAR10    提交人    /u/kiockete   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp1q9f/d_the_quality_of_samples_from_rectified_flow_ode/</guid>
      <pubDate>Wed, 25 Sep 2024 11:04:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 招聘创始研究工程师——构建受生物启发的专家系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp0wj7/p_hiring_founding_research_engineers_build/</link>
      <description><![CDATA[大家好！我们是 Atman Labs，一家位于伦敦的研究和设计公司。我们的使命是模拟软件中的人类专家。要做到这一点，需要构建能够全面映射任何领域知识的系统，并能够像人类一样动态探索这些知识以实现目标。 我们认为，行业需要超越法学硕士，构建能够解决复杂、知识密集型任务的系统，这些任务需要多步推理。我们的研究正在重新发明专家系统，它结合了结构化知识表示、强化学习支持的动态规划和新颖的人机界面。 我们的创始团队是跨学科的、才华横溢的，并且大胆地走上了一条新颖的道路，以构建能够推理的智能系统，这受到生物学的启发。如果您想加入我们，请考虑查看以下机会。让我们聊天吧:) 知识表示：https://atmanlabs.ai/team/kr-founding-engineer 强化学习：https://atmanlabs.ai/team/rl-founding-engineer 界面/图像生成：https://atmanlabs.ai/team/visual-generation-founding-engineer    提交人    /u/Tricky_Amphibian_836   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp0wj7/p_hiring_founding_research_engineers_build/</guid>
      <pubDate>Wed, 25 Sep 2024 10:11:05 GMT</pubDate>
    </item>
    <item>
      <title>[D]机器学习控制系统中的 Koopman 算子</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fp0rg6/d_koopman_operator_in_control_systems_with/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fp0rg6/d_koopman_operator_in_control_systems_with/</guid>
      <pubDate>Wed, 25 Sep 2024 10:01:20 GMT</pubDate>
    </item>
    <item>
      <title>构建一个网络代理，根据用户详细信息调用填写 Google 表单 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fozud5/built_a_web_agent_which_call_fill_google_forms/</link>
      <description><![CDATA[      GitHub repo : https://github.com/shaRk-033/web-agent 尝试使用两种方法解决： 1：基本抓取和填写 这是最直接的方法。代理抓取表单的 HTML，并使用固定的 XPath 查找并填写必填字段。  它提取表单的 HTML，使用设置的 XPath 定位字段，然后输入答案。这是一种直接而简单的方法。 如果表单发生变化或元素不在预期的位置，则该过程可能会失败，可能需要手动调整。  基本方法  使用 LangChain Agent 和工具调用   LangChain Agent：代理使用 LLM 的推理来决定下一步做什么，包括生成那些棘手的 XPath，从而处理所有事情。 错误处理：如果出现问题（例如如果找不到元素），代理将再次尝试使用更好的 XPath，直到完成工作。  使用 langchain 代理 欢迎提出任何改进建议。此外，如果有人有关于构建类似的 Web 代理来自动化其他任务的想法，我们将非常乐意听到他们的想法。:)    提交人    /u/Silly-Dig-3312   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fozud5/built_a_web_agent_which_call_fill_google_forms/</guid>
      <pubDate>Wed, 25 Sep 2024 08:53:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于无监督图像搜索的双曲度量学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fozecb/p_hyperbolic_metric_learning_for_unsupervised/</link>
      <description><![CDATA[https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_Unsupervised_Hyperbolic_Metric_Learning_CVPR_2021_paper.pdf 您对这篇论文有什么看法？我希望构建一个图像授权器，其第一步是图像搜索 (CBIR)，从数据库中选择正确的图像进行授权。我正在使用矢量数据库来存储嵌入。我尝试过 dinov2、剪辑嵌入。Dinov2 在大多数情况下都有效。您如何看待像这样的双曲嵌入？我已经读到是时候从欧几里得空间转移到双曲空间了，并且如果它们相似，嵌入看起来会更接近，因为它们遵循度量学习 编辑： 我的疑问是它说它适用于无监督数据集，没有标签，那么为什么它们的 DataLoader 有标签 从 __future__ 导入 absolute_import、print_function &quot;&quot;&quot; 用于 Pytorch 的 CUB-200-2011 数据集 &quot;&quot;&quot; 导入 torch 导入 torch.utils.data 作为数据 从 PIL 导入图像 导入 os 从 torchvision 导入变换 从集合导入 defaultdict 从DataSet.CUB200 导入 MyData、MyData_HC、default_loader、Generate_transform_Dict 类 Cars196： def __init__(self, root=None, root_c=None, origin_width=256, width=227, ratio=0.16, transform=None,part_rate=0, noise_rate=0, HC=True): 如果 transform 为 None： transform_Dict = Generate_transform_Dict(origin_width=origin_width, width=width, ratio=ratio) 如果 root 为 None： root = &#39;data/Cars196/&#39; 如果 root_c == &#39;/home/yjx/CVPR2021/&#39;： train_txt = os.path.join(root_c, &#39;train.txt&#39;) 否则： 如果 part_rate == 0： 如果 noise_rate == 0： train_txt = os.path.join(root，&#39;train.txt&#39;) 否则： train_txt = os.path.join(root，&#39;train_%.4f.txt&#39;%noise_rate)  否则： 如果 noise_rate == 0： train_txt = os.path.join(root，&#39;train_part_%.4f.txt&#39;%part_rate) 否则： train_txt = os.path.join(root，&#39;train_part_%.4f_%.4f.txt&#39;%(part_rate,noise_rate)) 通知 print(&#39;通知：现在使用 {}！&#39;.format(train_txt)) test_txt = os.path.join(root, &#39;test.txt&#39;) if HC: self.train = MyData_HC(root, label_txt=train_txt, transform=transform_Dict[&#39;rand-crop&#39;]) else: self.train = MyData(root, label_txt=train_txt, transform=transform_Dict[&#39;rand-crop&#39;]) self.gallery = MyData(root, label_txt=test_txt, transform=transform_Dict[&#39;center-crop&#39;]) def testCar196(): data = Cars196() print(len(data.gallery)) 打印（len（data.train）） 打印（data.train[1]） 如果 __name__ == &quot;__main__&quot;: testCar196()    由   提交  /u/PositiveResponse7678   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fozecb/p_hyperbolic_metric_learning_for_unsupervised/</guid>
      <pubDate>Wed, 25 Sep 2024 08:18:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要多少微分方程知识才能理解流动、扩散 SciML 和相关领域的研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foygx0/d_how_much_knowledge_of_differential_equations_is/</link>
      <description><![CDATA[我印象中，基础微积分、概率、统计学和线性代数为理解深度学习的工作奠定了坚实的基础。但是看到最近关于流匹配、流标准化、扩散和科学机器学习领域的论文，我无法理解超出某一点的东西。  我知道他们大量使用微分方程。我在该领域的知识几乎低于新手水平。在哪里可以学到更多关于微分方程的知识？我想获得理解这些领域工作的能力，以及论文作者如何以及为何提出这种实现。    提交人    /u/HopeIsGold   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foygx0/d_how_much_knowledge_of_differential_equations_is/</guid>
      <pubDate>Wed, 25 Sep 2024 07:05:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有人研究过，用特定的查询来启动 LLM 是否会导致它对后续不相关的查询采用更多新颖的途径？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foumnd/d_has_anybody_investigated_whether_priming_a_llm/</link>
      <description><![CDATA[上下文： https://chatgpt.com/share/66f37954-e7c8-800d-a809-327f30f549b1 我向 ChatGPT 询问了一个关于 Rockwell Retro Encabulator（一种实际上并不存在的小玩意儿）的愚蠢问题。它似乎以一种与平常不同的方式做出回应，因此我向它询问了更多问题，我注意到它的答案总体上比它通常输出的答案更新颖。我想知道： 1- 这是安慰剂吗？我是不是想得太深了？ 2- 如果不是安慰剂，用一个新问题来启动模型是否会导致后续问题偏向于新答案，即使在典型情况下，这个问题会利用更常见的途径？ 3- 这是否可以在小众情况下实际使用（例如语言翻译）来改善模型的响应。 o1 预览似乎认为这是合理的，而且它的基本原理对我来说很有道理。你们觉得怎么样？这有什么问题吗？    提交人    /u/NepNep_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foumnd/d_has_anybody_investigated_whether_priming_a_llm/</guid>
      <pubDate>Wed, 25 Sep 2024 02:57:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果对抗性学习研究表明神经网络对输入/权重扰动非常脆弱，那么量化为什么会起作用呢？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fosr7z/d_if_adversarial_learning_studies_suggest_neural/</link>
      <description><![CDATA[我一直在想为什么这两种观察结果可以共存而不发生冲突。对抗性学习的研究似乎表明，人们可以很容易地找到输入或权重上的微小扰动，这些扰动可以彻底改变某些输出。如果扰动某些权重已经足够糟糕，那么像量化那样扰动每个权重肯定会带来灾难性的后果？ 我有几个猜测：  也许对抗性扰动方向很多但在所有可能的方向中很少见，而像量化这样的随机扰动不太可能是对抗性的？ 也许我们确实引入了错误，但只在一小部分输出上，这还不够糟糕？ 也许随机权重扰动对非常大的网络的损害较小？  是否有人知道现有的优秀研究可以解释为什么量化不会导致无意的自我破坏？    提交人    /u/aeroumbria   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fosr7z/d_if_adversarial_learning_studies_suggest_neural/</guid>
      <pubDate>Wed, 25 Sep 2024 01:20:22 GMT</pubDate>
    </item>
    <item>
      <title>[D]-NeurIPS 2024 决策</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1foky4r/d_neurips_2024_decisions/</link>
      <description><![CDATA[大家好！请注意，NeurIPS 2024 决策通知将于 2024 年 9 月 26 日欧洲中部夏令时间凌晨 3:00 发布。我觉得创建一个我们可以讨论它的帖子会很酷。    提交人    /u/Proof-Marsupial-5367   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1foky4r/d_neurips_2024_decisions/</guid>
      <pubDate>Tue, 24 Sep 2024 19:23:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 目前对您来说最令人兴奋的三大研究方向是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fo7ben/r_what_are_the_top_3_most_exciting_research/</link>
      <description><![CDATA[让我们分享吧！你对什么感到兴奋？    提交者    /u/Prestigious_Bed5080   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fo7ben/r_what_are_the_top_3_most_exciting_research/</guid>
      <pubDate>Tue, 24 Sep 2024 08:05:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 22 Sep 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>