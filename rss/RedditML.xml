<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Wed, 03 Apr 2024 00:57:00 GMT</lastBuildDate>
    <item>
      <title>[D] GPT-3.5-Turbo 很可能与 Mixtral-8x7B 大小相同！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1budlbc/d_gpt35turbo_is_most_likely_the_same_size_as/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1budlbc/d_gpt35turbo_is_most_likely_the_same_size_as/</guid>
      <pubDate>Tue, 02 Apr 2024 23:35:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 像使用NFS/共享存储一样消耗GPU资源的技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bucy95/d_technology_to_make_consumption_of_gpu_resources/</link>
      <description><![CDATA[我和我的联合创始人来自开发核心虚拟化技术的世界。我们一直致力于开发一种新颖的技术堆栈，以颠覆当前的 GPU 消耗模式 - 云实例、PaaS 平台和 SaaS 平台（GPU 单元、部分 GPU，基本上 GPU 资源都固定用于工作负载）。  GPU 最宝贵的资源是 RAM，而 RAM 利用率在整个工作负载执行过程中并不是恒定的。我们的技术将使您能够根据用户定义的 QoS 在并发工作负载执行中共享单个或多个 GPU，以最大限度地提高 GPU 利用率。作为用户，您将在不知道 GPU 基础设施的情况下在 CPU 上执行工作负载，并且工作负载将通过我们的客户端库在远程 GPU 基础设施上执行 GPU 指令，就像它们在本地 GPU 上运行一样。它将与云 GPU 实例和本地 GPU 基础设施配合使用。 我们计划在未来几个月内分享测试版详细信息，并使用户能够测试该技术。第一个版本将适用于 Pytorch 应用程序，并支持 Nvidia 硬件上的 CUDA 加速应用程序。然而，使用这项技术的未来计划是让最终用户独立于 GPU 硬件供应商执行。 请随时与我分享您的想法。   由   提交/u/Chachachaudhary123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bucy95/d_technology_to_make_consumption_of_gpu_resources/</guid>
      <pubDate>Tue, 02 Apr 2024 23:09:01 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]输入数据中的RELU和MaxPooling -1 -> +1</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bucals/discussion_relu_and_maxpooling_in_input_data_1_1/</link>
      <description><![CDATA[我一直在尝试为原始音频构建 CycleGAN，但收效甚微。今天我对输入数据有了一个想法。到目前为止，我一直在加载 wav 文件并将这些值转换为范围为 [0,1] 的一维张量。然而今天我使用了 [-1, +1] 范围，因为它对我来说似乎更自然。这还涉及将我的 RELU 层更改为自定义层，将值限制在 -1 和 +1 之间，并将 MaxPool 层更改为简单地获取距 0 最大偏移量的值的层（“AbsoluteMaxPooling1d”，因为我称之为，张量 [-0.4, 0.2] 会给出 -0.4) 将这些更改添加到我的 CycleGAN 中的判别器中，显着提高了它的学习速度 - 现在它的准确率从 1/3 达到了约 95%旧方法使用的数据。 我的问题是，我是否可能在其他地方看到问题？这似乎是一种非正统的方法，我还没有正式研究过这个主题（尽管我是一名高级软件开发人员）。一些搜索并没有真正找到我太多（除了不断建议使用 [0,1] 作为范围。此外 pytorch 没有层函数来完成我需要的事情，所以我认为我正在做的事情是不寻常的。    提交者    /u/maximinus -thrax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bucals/discussion_relu_and_maxpooling_in_input_data_1_1/</guid>
      <pubDate>Tue, 02 Apr 2024 22:41:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据科学和机器学习工程师的未来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1buca5d/d_futur_of_data_science_and_machine_learning/</link>
      <description><![CDATA[您好，最近几个月我们公司与 Open AI 签订了企业版解决方案和许多产品的合同，现在大部分在公司内部来自不同领域的人正在尝试加入数据科学团队，同时与 CTO 进行了详细讨论，他声称有了这一代人工智能，我们不需要数据科学家（我认为这是非常愚蠢的），但是我想到了这样的事情：数据科学家/机器学习工程师在 GENAI 和 LLM 的浪潮中会/应该做什么？   由   提交 /u/WASSIDI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1buca5d/d_futur_of_data_science_and_machine_learning/</guid>
      <pubDate>Tue, 02 Apr 2024 22:40:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你的模型有时会避免显而易见的事情吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1buc27r/d_do_your_models_sometimes_avoid_the_obvious_thing/</link>
      <description><![CDATA[最近在我训练的很多模型中（时间序列预测、一些概率、一些特征分析/预测等），它们倾向于即使架构的梯度路径应该使其非常可行，他们还是需要很长时间才能完成明显的事情？例如，即使有循环连接，它也不会预测下一个时间步，即使它与当前时间步很接近。我认为有时与优化、学习率等有关，但也许不是——这很常见吗？   由   提交 /u/LahmacunBear   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1buc27r/d_do_your_models_sometimes_avoid_the_obvious_thing/</guid>
      <pubDate>Tue, 02 Apr 2024 22:31:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 迷惑不解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bu4dt2/d_perplexed_with_perplexity/</link>
      <description><![CDATA[我很困惑，很困惑。比如我如何计算它。我正在研究 Kaparthy 的 NanoGPT。现在假设我希望计算模型的困惑度。我该怎么做？（我的意思是我知道它是交叉熵的指数）我需要发送什么数据？困惑度如何判断我的模型是否更好？让我们以输入句子为例。 “我想吃东西”，现在输出可以是任何食物，对吧？这种困惑在这里是如何发挥作用的，它与模型输出的食品类型不同吗？尝试从头开始寻找用于计算任何数据集的法学硕士困惑度的实现，但找不到。    由   提交/u/Automatic-Net-757   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bu4dt2/d_perplexed_with_perplexity/</guid>
      <pubDate>Tue, 02 Apr 2024 17:21:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在真正嘈杂的行业数据上，RAG 有哪些好的 IR 模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bu2kvy/d_what_are_some_good_ir_models_for_rag_on_really/</link>
      <description><![CDATA[我尝试过基于关键字的搜索、SBert - 两者都表现不佳。我的任务是基于 IR 的子集选择任务。因此，检索到的子集通常是不完整的。它遗漏了一些元素。  LLM可以用于IR吗？ 任何建议都会有帮助。 TIA :)    由   提交 /u/RiseWarm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bu2kvy/d_what_are_some_good_ir_models_for_rag_on_really/</guid>
      <pubDate>Tue, 02 Apr 2024 16:08:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于那些考虑购买 AMD GPU 的人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bu1sue/d_for_those_who_consider_buying_amd_gpus/</link>
      <description><![CDATA[https:// www.reddit.com/r/Amd/comments/1bsjm5a/letter_to_amd_ongoing_amd/ 认为此信息可能会帮助您做出决定。 ​&lt; /p&gt; P.S.就连 George Hotz 也不再建议购买 7900 XTX，转而使用 NVIDIA，因为驱动程序不稳定。来自最新的直播： https://www.youtube.com/ watch?v=Y-0yZ1AHb0s&amp;t=15890s   由   提交/u/YYY_333  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bu1sue/d_for_those_who_consider_buying_amd_gpus/</guid>
      <pubDate>Tue, 02 Apr 2024 15:37:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAGFlow：基于文档结构识别模型的可定制、可信、可解释的RAG引擎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btycwl/d_ragflow_customizable_credible_explainable_rag/</link>
      <description><![CDATA[https://medium.com/p/6a2a2369bd2a   由   提交/u/Vissidarte_2021   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btycwl/d_ragflow_customizable_credible_explainable_rag/</guid>
      <pubDate>Tue, 02 Apr 2024 13:10:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] SWE-agent：开源编码代理，在 SWE-bench 上取得 12.29% 的成绩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btwl37/p_sweagent_an_open_source_coding_agent_that/</link>
      <description><![CDATA[我们刚刚公开了 SWE-agent，它是一个开源代理，可以将任何 GitHub 问题转化为拉取请求，在 SWE-bench 上实现了 12.29% （与 Devin 使用的基准相同）。 ​ https ://github.com/princeton-nlp/swe-agent ​ 过去 6 个月我们一直在努力解决这个问题。构建运行良好的代理比看起来要困难得多 - 我们的存储库概述了我们学到和发现的内容。我们很快就会有预印本。  如果您有任何问题，我们会在这个帖子中闲逛   由   提交 /u/ofirpress   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btwl37/p_sweagent_an_open_source_coding_agent_that/</guid>
      <pubDate>Tue, 02 Apr 2024 11:42:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士对该领域弊大于利？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btuizd/d_llms_causing_more_harm_than_good_for_the_field/</link>
      <description><![CDATA[这篇文章可能有点咆哮，但我觉得最近越来越多的人和我分享这种观点。如果您费心阅读整篇文章，请随时分享您对此的感受。 当 OpenAI 将人工智能知识带入日常生活中时，我一开始对此持乐观态度。在美国以外的小国家，企业之前对人工智能非常犹豫，他们认为这感觉很遥远，只有大FANG公司才能做到。现在？好多了。每个人都对此感兴趣，并想知道如何在自己的业务中使用人工智能。这太棒了！ 在 ChatGPT 之前，当人们问我从事什么工作时，我回答“机器学习/人工智能”他们不知道，也几乎没有进一步的兴趣（除非他们是技术人员） ChatGPT 时代，当我被问到同样的问题时，我会得到“哦，你用聊天机器人？” 我想，这是朝着正确方向迈出的一步。我对法学硕士并没有那么大的兴趣，并且有幸专门从事与视觉相关的任务，不像其他一些不得不转向全职与法学硕士一起工作的人。 但是，现在我认为这对这个领域的弊大于利。让我分享一些我的观察，但在此之前我想强调一下，我绝不试图以任何方式把关人工智能领域。 我已经获得了“ChatGPT”的工作机会专家”，这到底是什么意思？我坚信，像这样的工作并不能真正发挥真正的职能，而更像是一种“超级火车”工作，而不是完全可以发挥任何职能的工作。 在过去的几年里，我已经我参加了欧洲各地的一些会议，其中一个是上周举行的，这些会议通常都很棒，具有良好的技术深度，也是数据科学家/机器学习工程师建立联系、分享想法和协作的场所。然而，现在会谈、深度、网络都发生了巨大的变化。公司使用人工智能来做很酷的事情和挑战极限不再是新鲜的、令人兴奋的方式，所有的 GAN 和 LLM 都具有表面知识。少数“老派”类型演讲被发送到小房间的第二轨道 小组讨论充满了没有人工智能基础知识的哲学家，谈论法学硕士是否会变得有知觉。数据科学家/机器学习工程师的空间在学术会议之外很快就消失了，被当前的 hypetrain 挤出了空间。hypetrain 的传播者还承诺用 LLM 和 GAN 创造奇迹和黄金，但他们永远不会实现的奇迹。当投资者意识到法学硕士无法实现这些奇迹时，他们会立即对人工智能未来项目的资金更加犹豫，让我们再次陷入人工智能冬天。 编辑：P.S.我还在这个 reddit 上看到更多的人自称是“生成人工智能专家”。但当深入研究时，就会发现它们只是“好的提示者”。并且对人工智能或生成人工智能的实际领域没有真正的知识、专业知识或兴趣。   由   提交/u/Stevens97  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btuizd/d_llms_causing_more_harm_than_good_for_the_field/</guid>
      <pubDate>Tue, 02 Apr 2024 09:37:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] SOTA BERT 类模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btrr9x/d_sota_bertlike_model/</link>
      <description><![CDATA[因此，我们可能都知道最先进的解码器专用 LLM，例如 GPT-4、Claude 等。这些非常适合生成文本. 但我不知道的是类似 SOTA BERT 的模型。你知道，可以用于 NER、POS 标记、标记分类等任务。 有比 Roberta 明显更好的模型吗？    由   提交/u/Amgadoz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btrr9x/d_sota_bertlike_model/</guid>
      <pubDate>Tue, 02 Apr 2024 06:26:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你读过的关于深度学习的最好的数学书/课程是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btqama/d_what_was_the_best_math_bookcourse_you_had_for/</link>
      <description><![CDATA[我已经完成了高中学业，但之后我开始学习深度学习时已经有一年的时间间隔了。  我开始在 YouTube 上观看深度学习视频，但实际上并不了解矩阵演算、许多概率论等等。感觉就像我跳过了一些部分只是为了在 PyTorch 中写下代码。 然后我决定首先了解深度学习背后的所有数学知识。我读的第一本书是 Ronald T. Kneusel 的《深度学习数学》。这是一本很棒的书，涵盖了开始理解深度学习背后的数学所需的所有主题。 我想知道，您是否也有过类似的经历。   由   提交/u/cyb0rg14_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btqama/d_what_was_the_best_math_bookcourse_you_had_for/</guid>
      <pubDate>Tue, 02 Apr 2024 04:54:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在我的工作场所中，还有其他人无法摆脱 OpenAI 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt9y8p/d_cant_escape_openai_in_my_workplace_anyone_else/</link>
      <description><![CDATA[我们能具体谈谈 OpenAI 现在是如何被每一个工作场所、客户和他们的祖母强行灌输给我们的吗？最近，我收到的专门使用 OpenAI API 的请求数量猛增。你们对此有什么经验？你如何导航它？我尝试过提出其他替代方案，但不行，他们执意要使用 OpenAI。  OpenAI 成立的明确目的是实现人工智能的民主化，并通过开发开源工具来平衡大型科技的封闭世界。他们完全放弃了这个想法。在这个领域，一种令人恐惧的做法（OpenAI 的创建实际上就是为了防止这种做法）是由营利性公司组成的单一或寡头集团为我们做出这一决定。 别理解我的意思开始的事实是，他们的模型是使用谦虚的人的工作来训练的，而这些人永远不会为此得到一分钱。 我觉得被迫与这个令人厌恶的模型一起工作，但我也没有真正的选择。这就是我们许多人支付账单的方式。我是一个人吗？我应该放下我的骄傲吗？    由   提交/u/AlphaSquared_io   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt9y8p/d_cant_escape_openai_in_my_workplace_anyone_else/</guid>
      <pubDate>Mon, 01 Apr 2024 17:31:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>