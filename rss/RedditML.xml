<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 10 Sep 2024 09:17:44 GMT</lastBuildDate>
    <item>
      <title>[D] 寻找研究图表的平面设计师</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fddaqd/d_finding_a_graphic_designer_for_research_figures/</link>
      <description><![CDATA[嗨。标题。许多人使用 PowerPoint 制作图表，效果很好。我想看看是否有人可以推荐一些平面设计师，他们可以根据会议草图为我设计一个非常高质量的研究图表。我不太熟练使用 Illustrator，也没有时间学习它。  我只是想让他们根据 iPad 草图创建高质量的视觉效果。如果有人有这方面的经验或可以给我指明正确的方向，请告诉我。谢谢。    提交人    /u/jacobfa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fddaqd/d_finding_a_graphic_designer_for_research_figures/</guid>
      <pubDate>Tue, 10 Sep 2024 08:55:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] LowFormer：硬件高效的 Transformer 主干设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdc52w/r_lowformer_hardware_efficient_transformer/</link>
      <description><![CDATA[吞吐量和延迟优化的骨干架构，具有硬件高效的宏和微设计。它还具有简单高效的多头自注意力适应性。    提交人    /u/Mr_Fragwuerdig   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdc52w/r_lowformer_hardware_efficient_transformer/</guid>
      <pubDate>Tue, 10 Sep 2024 07:26:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 文本到图像的生成可以不依赖数学吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdbwl4/d_can_texttoimage_generation_be_done_without/</link>
      <description><![CDATA[目前流行的稳定扩散（SD）模型都是基于高斯分布和各种公式等复杂的数学原理构建的，能否绕过这些数学原理，直接用一种简单的方法生成最终图像，比如提供一个文本输入和一张噪声图像，然后让网络输出生成的图像，再用MSE loss或者类似的方法（类似GAN）优化网络？    submitted by    /u/Kooky-Aide2547   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdbwl4/d_can_texttoimage_generation_be_done_without/</guid>
      <pubDate>Tue, 10 Sep 2024 07:07:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] Optuna 的并行化是否会干扰 PySpark？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fd80jp/d_is_optunas_parallelization_interfering_with/</link>
      <description><![CDATA[大家好，我正在使用 Optuna 进行超参数优化和使用 PySpark 进行并行训练，以训练产品级时间序列模型。我在 Optuna 中设置了 n_jobs &gt; 1 以启用并行化，并且我在 PySpark 中使用 applyInPandas 按 product_id 并行化模型训练。我是否应该担心这两种并行机制会互相干扰？这些进程将如何在工作者之间分配？我有 4 个工作者，每个工作者有 8 个核心。任何建议或见解都将不胜感激！    提交人    /u/AffectionatePut7138   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fd80jp/d_is_optunas_parallelization_interfering_with/</guid>
      <pubDate>Tue, 10 Sep 2024 02:59:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否存在一个开放的、真正的多模式 LLM，而不是一个玩具模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fd5hp7/d_is_there_an_open_truly_multimodal_llm_that_isnt/</link>
      <description><![CDATA[嗨， 自 gpt-4o 问世以来已经过去了几个月，我还没有找到一个等效的开放权重模型。Gemini 甚至在它之前就出现了，它有多模态输入。 我所说的等效，是指早期融合和多模态的模型，其中视觉和音频被标记化并与文本标记共享相同的嵌入空间。我并不一定意味着它必须具有相同的功能或准确性。 据我所知，Meta 的变色龙是最接近的匹配，但它是双模态的（不支持音频）并且只能生成文本。 所以我的问题是：是否存在一个真正的多模态模型，我们可以在本地下载和调整？    提交人    /u/Amgadoz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fd5hp7/d_is_there_an_open_truly_multimodal_llm_that_isnt/</guid>
      <pubDate>Tue, 10 Sep 2024 00:51:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] `costly`：用于提前估算 LLM 项目成本和运行时间的软件包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fd2ff3/p_costly_a_package_for_estimating_costs_running/</link>
      <description><![CDATA[我编写了一个简单的包，以便在花钱之前提前估算复杂 LLM 工作流/实验/管道的成本和运行时间： https://github.com/abhimanyupallavisudhir/costly 只需将 @costly() 放在承载函数上（例如 API 调用包装器本身）；确保调用它的所有函数都将 **kwargs（或至少 cost_log 和 simulate）传递给它，并使用 simulate=True 和一些 cost_log: Costlog 对象调用你的复杂函数。 pip install costly  据我所知，现有的包（如 tokencost）只是用于估算单个 LLM 调用成本的价格字典，你必须编写自己的逻辑来估算逻辑成本。 costly 的意义在于为您做到这一点（并且您可以将它用于 LLM 调用之外的其他目的，尽管您需要编写自己的估算器和模拟器）。 显然，在管道中存在一些非平凡的逻辑，其中一个 LLM 的输出传递给另一个 LLM 等 - 这种逻辑由&quot;模拟器&quot; 近似，可以对其进行子类化。 请参阅此处的完整文档：https://github.com/abhimanyupallavisudhir/costly/blob/master/examples.ipynb    提交人    /u/Ok_Country1256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fd2ff3/p_costly_a_package_for_estimating_costs_running/</guid>
      <pubDate>Mon, 09 Sep 2024 22:26:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 进行实验以在 P5.js 中重新创建模式 — 寻找想法 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fd0qy9/experimenting_with_llms_to_recreate_patterns_in/</link>
      <description><![CDATA[      我一直在做一个项目，使用 LLM 生成嵌入 HTML 的 P5.js 草图，到目前为止，进展非常顺利！有些草图非常有创意（关于我的项目的文章）。但是，我已经开始了一个新的实验，我给 LLM 一张图片，并要求它使用 P5.js 重新创建图案。不幸的是，我在这部分没有取得太大的成功。基本上，我需要 LLM 理解模式并设计一个脚本来重新创建模式。这要求太多了吗？ 我尝试在提示中使用思路链推理，甚至制作了一个比较常见形状的资源，但结果仍然相差甚远。我想知道是否有即时策略或技巧可以尝试指导 LLM 更好地使用 P5.js 形状和算法重新创建图案。或者，也许某种专门的培训可以有所帮助？ 这是我当前提示的屏幕截图。并且这里是我创建的参考 pdf。 Claude 中的提示截图    提交人    /u/garygeo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fd0qy9/experimenting_with_llms_to_recreate_patterns_in/</guid>
      <pubDate>Mon, 09 Sep 2024 21:15:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我构建了一个工具，通过 1 个超参数搜索来减少幻觉 - Nomadic</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcxup1/p_i_built_a_tool_to_minimize_hallucinations_with/</link>
      <description><![CDATA[Github：https://github.com/nomadic-ml/nomadic 演示：Colab 笔记本 - 为您的检索增强生成管道获取性能最佳的 statsig 配置，并通过一次实验将幻觉减少 4 倍。注意：最适合与 Colab Pro（高 RAM 实例）一起使用或在本地运行。 很想听听您的任何想法/反馈！    提交人    /u/TRBeetle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcxup1/p_i_built_a_tool_to_minimize_hallucinations_with/</guid>
      <pubDate>Mon, 09 Sep 2024 19:19:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 实施论文的价值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcvkjm/d_implementing_papers_worth/</link>
      <description><![CDATA[大家好， 我拥有机器人学硕士学位（修过 ML、CV、DL 和数学课程），最近我对 3D 计算机视觉非常感兴趣，所以我研究了一些项目。我发现了 deepSDF。我的目标是在 C++ 上实现它，使用 CUDA 和 SIMD，并在真实相机上测试在线 SDF 构建。 还计划实现 3D 高斯 Splatting。 但我的朋友说不用费心了，因为每个人都可以实现那些论文，所以我需要自己写论文。他是对的吗？我在浪费时间吗？    提交人    /u/Huge-Leek844   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcvkjm/d_implementing_papers_worth/</guid>
      <pubDate>Mon, 09 Sep 2024 17:47:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 重新审视用于视觉识别的稀疏卷积模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcvgaw/r_revisiting_sparse_convolutional_model_for/</link>
      <description><![CDATA[  由    /u/bregav  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcvgaw/r_revisiting_sparse_convolutional_model_for/</guid>
      <pubDate>Mon, 09 Sep 2024 17:42:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多元时间序列的模式匹配方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcq4v4/r_methods_for_pattern_matching_with_multivariate/</link>
      <description><![CDATA[大家好， 我想确定我的车辆动力学模式是否与其他（多个）车辆动力学模式相似。例如，假设我有一段 5 秒的数据，表示转向。我如何查看行程的完整驾驶周期数据，以查看此行程中是否发生这种转向（或某种程度上的类似转向）？ 我已经开发了几种方法来做到这一点，但我想知道是否有什么我应该阅读的，这样我就不会在这里重新发明轮子了！ 感谢您的帮助或指导！    提交人    /u/PreviousResearcher50   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcq4v4/r_methods_for_pattern_matching_with_multivariate/</guid>
      <pubDate>Mon, 09 Sep 2024 14:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 TsetlinMachine 库 Tsetlin.jl 中的最新优化，在 CPU 上实现每秒超过 1 亿个 MNIST 预测（吞吐量为 55.5 GB/s）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fc3ji0/p_achieved_over_100_million_mnist_predictions_per/</link>
      <description><![CDATA[      这个周末，我优化了 TsetlinMachine 库 Tsetlin.jl，取得了出色的成绩：在我的 Ryzen 7950X3D CPU 上每秒可进行 1.01 亿次 MNIST 预测，准确率为 98.10%。这个性能已经接近硬件的最大能力，因为双通道模式下 DDR5 RAM 在 6000 MT/s 下的峰值速度为 96 GB/s。我的吞吐量达到了 55.5 GB/s，主要是因为这个特定的 Tsetlin Machine 模型有 10499 个参数，而 CPU 缓存（尤其是 3D 缓存）在提升性能方面起着重要作用。 https://preview.redd.it/0a719tythmnd1.png?width=1780&amp;format=png&amp;auto=webp&amp;s=001526f65f3be2b99ce2a24ffe4b5bb5486f474e    由    /u/ArtemHnilov  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fc3ji0/p_achieved_over_100_million_mnist_predictions_per/</guid>
      <pubDate>Sun, 08 Sep 2024 17:42:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 08 Sep 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[P]: TensorHue – 张量可视化库（详情见评论）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbz318/p_tensorhue_a_tensor_visualization_library_info/</link>
      <description><![CDATA[        提交人    /u/epistoteles   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbz318/p_tensorhue_a_tensor_visualization_library_info/</guid>
      <pubDate>Sun, 08 Sep 2024 14:29:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>