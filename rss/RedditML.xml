<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 17 Jan 2024 18:17:29 GMT</lastBuildDate>
    <item>
      <title>[R] AlphaGeometry：奥林匹克级几何人工智能系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19932kw/r_alphageometry_an_olympiadlevel_ai_system_for/</link>
      <description><![CDATA[博客：https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/ 论文：https://www.nature.com/articles/s41586-023-06747-5 Github：https://github.com/google-deepmind/alphageometry 摘要：  在奥林匹克级别证明数学定理代表着人类水平自动推理的一个显着里程碑，因为它们在世界上最优秀的大学预科数学人才中被认为是困难的。然而，由于将人类证明转换为机器可验证格式的成本高昂，当前的机器学习方法不适用于大多数数学领域。对于几何来说，这个问题更为严重，因为其独特的转换挑战，导致训练数据严重匮乏。我们提出了 AlphaGeometry，这是欧几里得平面几何的定理证明器，它通过综合不同复杂程度的数百万个定理和证明来回避人类演示的需要。 AlphaGeometry 是一个神经符号系统，它使用神经语言模型，在我们的大规模合成数据上从头开始训练，引导符号推演引擎通过具有挑战性的问题的无限分支点。在包含 30 个最新奥林匹克级别问题的测试集上，AlphaGeometry 解决了 25 个问题，超越了之前仅解决了 10 个问题的最佳方法，接近了国际数学奥林匹克 (IMO) 金牌得主的平均表现。值得注意的是，AlphaGeometry 产生了人类可读的证明，在人类专家评估下解决了 IMO 2000 和 2015 中的所有几何问题，并在 2004 年发现了翻译后的 IMO 定理的广义版本。 &lt;!-- SC_ON - -&gt;  由   提交 /u/RobbinDeBank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19932kw/r_alphageometry_an_olympiadlevel_ai_system_for/</guid>
      <pubDate>Wed, 17 Jan 2024 18:01:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 转录 Spotify 播客而不下载它</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/199244h/d_transcribing_a_spotify_podcast_without/</link>
      <description><![CDATA[我想转录 Spotify 播客。该播客仅在 Spotify 上提供。  最简单的方法当然是以某种方式从 Spotify 中获取 Podcast。有没有什么办法可以在不下载播客的情况下做到这一点。我想使用一些实时转录和虚拟音频驱动程序。大约是300 集，所以我正在寻找一种高度自动化的方法 希望得到任何提示！   由   提交 /u/riccardofratello   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/199244h/d_transcribing_a_spotify_podcast_without/</guid>
      <pubDate>Wed, 17 Jan 2024 17:24:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 稍微不同角度拍摄的照片的透视匹配并分析其差异以用于医学研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1991vep/d_perspective_matching_of_pictures_taken_from/</link>
      <description><![CDATA[TL;DR：寻找一种方法（透视）匹配 2-4 张手动拍摄的某人牙齿的宏观照片（因为它们是由手，有轻微的视角差异）。匹配完图片后，我正在寻找一种方法来输出两张图片的差异。 大家好，我的博士学位需要一点帮助。 这里有一些解释该项目的关键数据： 我与进行牙科手术的中心有联系。几乎每个手术病例都有宏观图像记录（术前、术后立即、术后两周、术后一年）。 数据来自大约 200-400 名患者，这现在将对数据进行分析，以证明治疗的成功。 该治疗包括用从口腔其他部位取出的组织覆盖暴露的牙颈。 如图所示手工拍摄，各个图像总是从稍微不同的角度拍摄。 基本思想是自动匹配图像的透视（据我理解，这一步是后续步骤所必需的），然后自动比较术前和术后图像之间的差异。由于手术的原因，术前图像上的白色/浅色牙颈部被红色粘膜覆盖，这可以在术后图像上看到（因此该区域前后有很强的颜色差异） 。  目的是自动输出操作成功覆盖的表面积。 如果到目前为止我的解释是可以理解的，我想知道是否可以实现项目还是数据情况/数据质量不够？我估计通过表面积计算来评估数据很大程度上取决于匹配的质量，对吧？是否有良好且可靠的工具（Kornia 会遇到这种情况吗？） 也许任何人都愿意提供帮助或有一个好主意 - 如果它有效，我会在最终论文中提到你！ :)   由   提交 /u/knockknockwhodiss   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1991vep/d_perspective_matching_of_pictures_taken_from/</guid>
      <pubDate>Wed, 17 Jan 2024 17:14:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] HOEFFDING 算法和 MOA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198zeo7/p_hoeffding_algorithm_and_moa/</link>
      <description><![CDATA[这里有人使用过 MOA OSS 进行数据流和挖掘或其他类似软件吗？我的一位教授给我一项任务，要求我使用流数据并计算 Hoeffding 算法的不同参数。我对 MOA 的工作原理一无所知，我已经在我的 m2 mac 上下载了该软件，但现在运行它时遇到问题。我也希望得到其他软件的建议。   由   提交/u/varun-saha  /u/varun-saha  reddit.com/r/MachineLearning/comments/198zeo7/p_hoeffding_algorithm_and_moa/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198zeo7/p_hoeffding_algorithm_and_moa/</guid>
      <pubDate>Wed, 17 Jan 2024 15:38:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] einx - Python 中受爱因斯坦启发的表示法中的张量运算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198yyzy/p_einx_tensor_operations_in_einsteininspired/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198yyzy/p_einx_tensor_operations_in_einsteininspired/</guid>
      <pubDate>Wed, 17 Jan 2024 15:20:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 信心*可能是*您所需要的一切。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198y67i/d_confidence_may_be_all_you_need/</link>
      <description><![CDATA[      ​ 论文：https://arxiv.org/abs/2303.08896 ​ 我很想知道这里是否有人在实践中尝试过这个。 LLM 输出标记的对数概率的简单平均值可能足以判断模型是否产生幻觉。这个想法是，如果模型不自信（输出令牌概率低），则该模型可能会发明随机的东西。作者声称这种简单的方法是检测幻觉的最佳启发式方法。美妙之处在于它只使用生成的令牌概率，因此可以在推理时实现。   由   提交 /u/santiviquez   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198y67i/d_confidence_may_be_all_you_need/</guid>
      <pubDate>Wed, 17 Jan 2024 14:46:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 词汇量真的会影响法学硕士文本的大小吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198xx6o/d_does_the_vocabulary_size_really_affect_the_size/</link>
      <description><![CDATA[与变压器的其他组件相比，嵌入矩阵是否足够大？ 如果不是，那么为什么 GPT 模型依赖于30K 词汇量？   由   提交/u/kekkimo  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198xx6o/d_does_the_vocabulary_size_really_affect_the_size/</guid>
      <pubDate>Wed, 17 Jan 2024 14:34:22 GMT</pubDate>
    </item>
    <item>
      <title>[N] 关于矢量数据库基准的新见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198xe4m/n_new_insights_on_vector_databases_benchmarks/</link>
      <description><![CDATA[我们将 Qdrant 的性能与其他矢量搜索引擎进行了比较，以便为您提供全面的性能分析。 详细报告： https://qdrant.tech/benchmarks/ 以下是更改内容：https://qdrant.tech/blog/qdrant-benchmarks-2024/ 如果您有兴趣运行这些基准测试或请访问我们的基准存储库。 https://github.com/qdrant/vector-db-benchmark&lt; /a&gt;   由   提交/u/sabrinaqno   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198xe4m/n_new_insights_on_vector_databases_benchmarks/</guid>
      <pubDate>Wed, 17 Jan 2024 14:10:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻找开源 AI 项目做出贡献</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198v842/p_looking_for_open_source_ai_project_to_contribute/</link>
      <description><![CDATA[您好，我已经潜入深度学习近一年了，并且自己做了几个项目。为了提高我的技能，我目前正在寻找一个开源项目来贡献，并且每周可以投入 5-20 个小时。  如果您知道我可以参与的任何项目，请联系我。   由   提交 /u/SantaClaus_Y   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198v842/p_looking_for_open_source_ai_project_to_contribute/</guid>
      <pubDate>Wed, 17 Jan 2024 12:16:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 离线批量服务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198k375/d_offline_batch_serving/</link>
      <description><![CDATA[我对如何为离线批量预测提供机器学习模型感到困惑。 这是我想做的 -创建一个预定的管道（例如 Airflow、Kubeflow 等）来生成特征，然后从某个对象存储（例如 s3）加载经过训练的模型，生成预测，最后将它们保存到数据仓库中以供使用。这对我来说最有意义。 但是，一些资源似乎建议将模型部署为端点，即使对于批量用例也是如此。值得注意的是，这是 Chip Huyen 的《设计机器学习系统》中推荐的架构。 对此有什么想法吗？我错过了什么吗？   由   提交/u/Appropriate_Cut_6126   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198k375/d_offline_batch_serving/</guid>
      <pubDate>Wed, 17 Jan 2024 01:25:13 GMT</pubDate>
    </item>
    <item>
      <title>[P]从头开始的小型潜伏扩散变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198eiv1/p_small_latent_diffusion_transformer_from_scratch/</link>
      <description><![CDATA[      我训练了一个相对简单的基于 Transformer 的扩散模型来生成 256 x 256 图像从头开始。这是仓库： https://github.com/apapiu/transformer_latent_diffusion/tree/main - 代码应该希望它相当容易理解并且独立。 以下是在 1A100 从头开始​​训练大约 30 小时后的一些示例： 根据各种提示生成图像 该模型基于 DiT /Pixart-alpha 架构，但进行了各种修改和简化。我还在噪声表方面做出了一些有问题的决定，但似乎工作正常。 该模型是 100MM 参数，因此应该很容易对其进行实验。我欢迎任何反馈，也欢迎合作，所以请联系我们！希望这对想要尝试扩散模型/变压器但“GPU 较差”的人们有所帮助。 :) 该存储库还链接到一个 colab，您可以在其中使用自己的输入 - 请随意尝试。 ​    由   提交 /u/spring_m   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198eiv1/p_small_latent_diffusion_transformer_from_scratch/</guid>
      <pubDate>Tue, 16 Jan 2024 21:29:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何处理雇主提出的不合理要求以及对机器学习不切实际的期望？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19882l2/d_how_do_you_deal_with_unreasonable_request_from/</link>
      <description><![CDATA[几个月前，我接受了一个职位，通过为社会科学研究项目训练机器学习模型来支持该项目。该项目涉及使用团队（由多名实习生、研究生、博士后和教授组成）花费数年时间并付出疯狂努力编制的数据集。然而，问题是他们没有事先咨询任何真正了解机器学习的人。对于非常复杂的任务来说，他们的数据集太小（只有大约 200 行）。更糟糕的是，大多数变量的预测价值微乎其微，而用于推导这些变量的方法虽然非常耗费人力，却引发了人们对其有效性的担忧。 该项目的 MO 绝对令人困惑：通过巨大的数据积累了数千个预测变量。努力和人力，期待完美的结果。任何模型如何用如此小的数据集估计如此多的参数却被忽视了。项目负责人似乎对 ML 有着某种神奇的理解，这可能是受到其在特定领域频繁误用的影响。这个项目的灵感尤其来自于一篇研究论文，我几乎可以保证该论文在其验证集上过拟合。 所有这些都让我处于尴尬的境地，作为新人，我需要告知这一点一个由经验丰富的博士后和教授组成的团队，全部来自社会科学背景，没有定量专业知识，他们多年的工作产生了一个完全不适合他们的目标的数据集，并且他们所建立的现有文献都是错误的，因为他们显然没有不知道什么是测试集以及何时使用它。我也不能告诉他们只扩展数据集，因为达到 200 行已经花费了数年时间。 我必须承认我对这次谈话有点紧张。 ​ 我怀疑对 ML 功能抱有不切实际的期望是一种常见的经历。其他人如何处理这个问题？如果他们坚持不管，你会直白地告诉他们这行不通，然后到别处找工作吗？如果是这样，这些交互通常如何进行？   由   提交 /u/Excusemyvanity   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19882l2/d_how_do_you_deal_with_unreasonable_request_from/</guid>
      <pubDate>Tue, 16 Jan 2024 17:13:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer 是多状态 RNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1986k0x/r_transformers_are_multistate_rnns/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.06104 代码：https ://github.com/schwartz-lab-NLP/TOVA 摘要：  Transformers 被认为在概念上与到上一代最先进的 NLP 模型 - 循环神经网络 (RNN)。在这项工作中，我们证明了仅解码器 Transformer 实际上可以被概念化为无限多状态 RNN——一种具有无限隐藏状态大小的 RNN 变体。我们进一步证明，通过固定隐藏状态的大小，预训练的 Transformer 可以转换为有限多状态 RNN。我们观察到一些现有的转换器缓存压缩技术可以被构建为这样的转换策略，并引入了一种新的策略，TOVA，它比这些策略更简单。我们对多个远程任务进行的实验表明，TOVA 优于所有其他基线策略，同时几乎与完整（无限）模型相当，并且在某些情况下仅使用原始缓存大小的 1/8。我们的结果表明，变压器解码器 LLM 在实践中通常表现为 RNN。他们还提出了缓解最痛苦的计算瓶颈之一——缓存大小的选项。我们在 此 https URL 公开发布我们的代码。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1986k0x/r_transformers_are_multistate_rnns/</guid>
      <pubDate>Tue, 16 Jan 2024 16:12:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] iPhone 文本检测的有趣现象</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197zbzs/d_interesting_occurrence_about_text_detection_of/</link>
      <description><![CDATA[      我点击该图像几次，它检测到第二只狗是单词“dog”用中文写的。我不认为这是有原因的，但如果有人有任何想法，我很乐意听到他们。   由   提交/u/Ok_Care_886   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197zbzs/d_interesting_occurrence_about_text_detection_of/</guid>
      <pubDate>Tue, 16 Jan 2024 09:57:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>