<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 19 May 2024 21:13:09 GMT</lastBuildDate>
    <item>
      <title>[D] 您认为未来几年机器学习将在计算生物学和生物信息学等领域发挥什么作用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvxcbc/d_what_role_do_you_think_machine_learning_will/</link>
      <description><![CDATA[我相信计算生物学和生物信息学将越来越多地采用机器学习工作，我很高兴看到所取得的进步。我认为它将在将疾病与可能在标签外使用的现有药物相匹配方面开辟一个全新的世界。我们还应该注意哪些其他事情？ 谁是在这个世界上工作的研究人员？   由   提交/u/RawCS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvxcbc/d_what_role_do_you_think_machine_learning_will/</guid>
      <pubDate>Sun, 19 May 2024 20:19:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM可观察性工具真的在初创公司和公司中使用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvwohz/d_are_llm_observability_tools_really_used_in/</link>
      <description><![CDATA[每周都会推出许多 LLM 可观察性和监控工具。它们真的被真正的初创公司和公司使用吗？  这些工具似乎可以执行以下一项或多项操作： - 监控 LLM 输入和输出以发现提示注入、对抗性攻击、脏话、偏离主题的内容、RTC - &lt;随着时间的推移，监控 LLM 指标，例如成本、延迟、可读性、输出长度和自定义指标（语气、情绪等）、偏差 - 提示管理：a/b 测试、版本控制、黄金标准集 您观察到了什么 - 在拥有自己的 LLM 功能或产品的真实公司中，他们使用这些工具吗？   由   提交 /u/WolvesOfAllStreets   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvwohz/d_are_llm_observability_tools_really_used_in/</guid>
      <pubDate>Sun, 19 May 2024 19:50:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] K 均值聚类算法视觉指南。 👥</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvv50l/r_visual_guide_to_the_kmeans_clustering_algorithm/</link>
      <description><![CDATA[TL;DR：K-Means 聚类根据数据点的相似性将数据点分组到聚类中，这使其对于客户细分、图像分割和文档聚类。 K 均值聚类可视化指南  处理 img 92n1nckko01d1...   由   提交/u/ml_a_day  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvv50l/r_visual_guide_to_the_kmeans_clustering_algorithm/</guid>
      <pubDate>Sun, 19 May 2024 18:41:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] SOFTS：利用序列核心融合实现高效的多元时间序列预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvtx30/d_softs_efficient_multivariate_time_series/</link>
      <description><![CDATA[很高兴分享我最新的关于时间序列预测的 Medium 文章。“SOFTS：使用系列核心融合进行高效的多元时间序列预测” SOFTS 是一种基于 MLP 的创新模型，利用新颖的 STar Aggregate-Dispatch (STAD) 模块来集中通道交互，以线性复杂度实现卓越的预测性能。与在鲁棒性和复杂性之间进行权衡的传统方法不同，SOFTS 可以有效地捕获渠道相关性，为金融、交通管理和医疗保健等各个领域的可扩展和准确的预测铺平道路。  https ://medium.com/towards-artificial-intelligence/softs-efficient-multivariate-time-series-forecasting-with-series-core-fusion-0ac40d2adcd2   由   提交/u/rezayazdanfar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvtx30/d_softs_efficient_multivariate_time_series/</guid>
      <pubDate>Sun, 19 May 2024 17:47:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] DSPy 真的改变了 LM 权重吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvsviu/d_does_dspy_actually_change_the_lm_weights/</link>
      <description><![CDATA[我一直认为它本质上是美化和结构化的提示工程（在我看来仍然非常有用），但它也在文档中声称它进行了微调和更改LM 权重，然后绝对拒绝在其文档的任何部分中详细说明这一点。 我什至不明白它如何改变 LM 的实际参数，特别是如果我们使用LM 的第三方 API 调用。  通过 LM 权重，我认为它意味着变压器模型最后一层的权重。当他们描述优化器时，他们说“DSPy 引入了新的优化器，这是 LM 驱动的算法，可以根据您想要最大化的指标调整 LM 调用的提示和/或权重。” &lt; p&gt;我是否误解了 LM 权重的含义？ 如果这是一个愚蠢的问题，我很抱歉，但我似乎找不到任何有关此的信息。提前致谢！   由   提交 /u/chessnudes   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvsviu/d_does_dspy_actually_change_the_lm_weights/</guid>
      <pubDate>Sun, 19 May 2024 16:58:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 文本到 Openpose 和奇怪的 RNN 错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvsmgq/p_text_to_openpose_and_weird_rnn_bugs/</link>
      <description><![CDATA[      我想创建从文本描述生成 openpose 的 AI，例如如果输入“a man running”输出将类似于我提供的图像有没有为我推荐的模型架构？ 我的数据条件是  canvas_width: 900px canvas_height: 300px 帧数：5（5人）  预期输出 我尝试训练 RNN 来完成此任务，我使用句子转换器来嵌入文本，然后传递给 RNN，损失如下图所示 fromentence_transformers import SentenceTransformerentence_model = SentenceTransformer(&quot;all-MiniLM-L6-v2&quot;) text = &quot;a man running&quot;; text_input = torch.tensor(sentence_model.encode(text), dtype=torch.float)  损失图像，num_layers=3 我的 RNN 设置 embedding_dim = 384 hide_dim = 512 num_layers = 3 output_dim = 180 num_epochs = 100learning_rate = 0.001 rnn_model = RNN(embedding_dim,hidden_​​dim,num_layers,output_dim)  但问题是无论我输入什么，输出每次都是相同的！但是当我尝试将 num_layers 更改为 1 并保持其他设置相同时 embedding_dim = 384 hide_dim = 512 num_layers = 1 output_dim = 180 num_epochs = 100learning_rate = 0.001 rnn_model = RNN(embedding_dim, hidden_​​dim、num_layers、output_dim)  损失现在看起来像这样  My问题是  除了RNN之外，是否有任何模型架构推荐用于此任务？ 为什么无论我输入什么，每次当num_layers=3时输出都是相同的我很很困惑，因为如果模型给出相同的输出，损失不会下降，对吗？这意味着它在推理阶段给出相同的输出  预期答案  最适合我的任务的模型架构任何与给出的论文或 github 存储库相关的都会感谢 回答为什么无论我输入什么，每次num_layers=3时输出都是相同的    由   提交 /u/Peemlock   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvsmgq/p_text_to_openpose_and_weird_rnn_bugs/</guid>
      <pubDate>Sun, 19 May 2024 16:46:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 是如何从从事令人兴奋的研究变成一家类似大型科技公司的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</link>
      <description><![CDATA[我最近重新审视了 OpenAI 关于 DOTA2 Open 的论文五，从工程和研究的角度来看，他们在那里所做的事情令人印象深刻。创建一个包含 50k 个 CPU 的分布式系统用于部署，1k 个 GPU 用于训练，同时每 0.25 秒从 16k 个观察中执行 8k 到 80k 个操作 - 这有多疯狂？他们还对 RL 模型进行“手术”以恢复权重，因为在几个月的训练中，他们的奖励函数、观察空间甚至架构都发生了变化。最后但并非最不重要的一点是，他们击败了 OG 队（当时的世界冠军），并部署了代理与其他玩家在线实时比赛。  快进几年，他们正在预测序列中的下一个标记。不要误会我的意思，gpt4 及其全能版本的功能确实是工程和研究的惊人壮举（可能更有用），但它们似乎并不像它们的一些产品那样有趣（从研究角度来看）  那么，现在我想知道这些年来工程师和研究人员是如何转变的？主要是由于他们的财务状况和盈利需要，还是有更深层次的原因进行转型？   由   提交 /u/UnluckyNeck3925   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</guid>
      <pubDate>Sun, 19 May 2024 16:46:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML中的计算机视觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvs57n/d_computer_vision_in_icml/</link>
      <description><![CDATA[嗨，这是我参加 ICML 的第一年。根据以往的会议，我想知道这次会议上通常会出现多少计算机视觉方面的内容（如果有的话）？   由   提交 /u/hilabar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvs57n/d_computer_vision_in_icml/</guid>
      <pubDate>Sun, 19 May 2024 16:25:08 GMT</pubDate>
    </item>
    <item>
      <title>来自第一原则的多模态人工智能——最基本的方法 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvrunk/multimodal_ai_from_first_principles_most/</link>
      <description><![CDATA[      分享我制作的一些最关键的视频以及过去十年左右训练多模式模型的基本构建块……如果您对这个主题感兴趣，希望您喜欢！   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvrunk/multimodal_ai_from_first_principles_most/</guid>
      <pubDate>Sun, 19 May 2024 16:12:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习中回收旧会议论文的文化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</link>
      <description><![CDATA[我从事统计机器学习工作。我注意到很多人（包括我自己和我审阅的人）经常重复他们向 ML 会议提交的论文。 例如，如果他们的论文被 ICML 拒绝，他们会提交给 NeurIPS，然后提交给 ICLR（或UAI/AISTATS 在我的领域也是顶尖的）。如果2~3次后没有进入ICML/NeurIPS/ICLR，他们就会将其提交给AAAI/IJCAI/TMLR/ICDM，T-NNLS/T-KDD/NN/Neurocomputing等期刊，或特定领域的场地，如LoG/CoLLA/AABI。经过所有这些，如果论文仍然没有被接受，他们就简单地将它们或 arXiv.我相信 CV/NLP 也可能是这种情况。 作为审稿人，我经常遇到会议提交的内容，作者在没有真正考虑之前提供的审稿的情况下重新提交。有时他们在重新提交时确实会纳入审稿意见，但有时工作可能只是达不到一级会议的水平，但他们只是不断重新提交并希望能够偶然被接受。 我认为这正在消耗社区审稿人的大量时间来继续审阅相同的提交内容（特别是考虑到 NeurIPS 达到 20k 提交 ID；我预计会看到许多重新提交）。这也许也是 TMLR 诞生的原因之一（强调正确性而不是新颖性）。 我确实理解“研究质量比发表地点更重要”之类的论点。或者“OpenAI 通常只是简单地将他们的论文（例如 GPT-X）放在 arXiv 上”。然而，学生或初级研究人员在他们的职业生涯中也需要发表论文，包括我自己。  人们对此有何看法？   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</guid>
      <pubDate>Sun, 19 May 2024 14:04:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在机器学习中有效地进行消融研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/</link>
      <description><![CDATA[在对可预训练和微调的模型进行消融研究时，您是否在预训练和微调期间对每个消融版本执行完整的网格搜索微调？或者你有策略让这个过程更加高效吗？感谢您的见解。   由   提交 /u/Few-Pomegranate4369    reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/</guid>
      <pubDate>Sun, 19 May 2024 13:54:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] N 路注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvkrpf/p_nwayattention/</link>
      <description><![CDATA[我一直在研究在变压器模型中关注两个以上标记的概念。例如，不要使用一个查询和一个密钥，而是使用两个密钥和一个查询，并且对于每对先前标记的每个查询总和。 这使得算法甚至更慢（ O(n**3 ）而不是 O(n**2))，但我认为这是一个有趣的概念。有些结果令我惊讶，比如它在找到最长递增子序列方面有多出色。 我希望它分享它： https://github.com/Gusanidas/n-way-attention/tree/main 并询问是否有人知道处理或提及该概念的论文。   由   提交 /u/Gusanidas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvkrpf/p_nwayattention/</guid>
      <pubDate>Sun, 19 May 2024 09:56:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM Ops的现状如何</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvkmwe/d_what_is_the_current_state_of_llm_ops/</link>
      <description><![CDATA[好奇人们如今如何将 RAG 和其他 LLM 支持的应用程序投入生产。您如何定义LLM Ops？您的团队/公司的流程是什么样的，您今天使用什么工具组合来实施或自动化这些流程，以及一些差距领域是什么。 我对哪些人特别感兴趣正在围绕生产环境中跨节点扩展更大模型的效率问题进行研究。您是否应用了任何 GPU 虚拟化/分段化以及这些方面有哪些好的资源？    由   提交/u/gamerx88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvkmwe/d_what_is_the_current_state_of_llm_ops/</guid>
      <pubDate>Sun, 19 May 2024 09:46:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基础时间序列模型被高估了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cv0hl2/d_foundational_time_series_models_overrated/</link>
      <description><![CDATA[我一直在探索基础时间序列模型，如 TimeGPT、Moirai、Chronos 等，并想知道它们是否真的具有强大的样本潜力 -高效的预测，或者他们只是借用 NLP 基础模型的炒作并将其引入时间序列领域。 我可以理解为什么它们可能会起作用，例如，在需求预测中，它是关于但它们能否处理任意时间序列数据，如环境监测、金融市场或生物医学信号，这些数据具有不规则模式和非平稳数据？ 它们的概括能力是否被高估了？    由   提交 /u/KoOBaALT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cv0hl2/d_foundational_time_series_models_overrated/</guid>
      <pubDate>Sat, 18 May 2024 16:00:06 GMT</pubDate>
    </item>
    </channel>
</rss>