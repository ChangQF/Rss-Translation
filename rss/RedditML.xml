<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 14 Nov 2024 09:17:59 GMT</lastBuildDate>
    <item>
      <title>[D] 对于（ML）理论申请者来说，计算机科学博士学位的录取竞争力如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gqyj6l/d_how_competitive_are_cs_phd_admissions_for_ml/</link>
      <description><![CDATA[如果我想从事机器学习理论研究（适合 COLT 的工作），而不是主流经验主义、严格的基于实验室的机器学习（NLP、CV...）研究，我是否需要在 NeurIPS/ICLR/COLT/ICML 上发表顶级出版物才能获得前 5 或 10 名 CS 博士录取？被录取的顶级 CS 博士简历非常疯狂，有多篇顶级会议论文。    提交人    /u/wonder-why-I-wonder   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gqyj6l/d_how_competitive_are_cs_phd_admissions_for_ml/</guid>
      <pubDate>Thu, 14 Nov 2024 06:14:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 KV260 进行实时视频处理的经验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gqqm7p/p_experience_with_kv260_for_realtime_video/</link>
      <description><![CDATA[这是我的 PI 的要求。 我正在寻找任何有 KV260 视频处理经验的人。我对高吞吐量视频 AI 感兴趣。主视频源的镜头到屏幕时间为 60 毫秒（2 帧）。AI 增强最多可以比实时延迟 120 毫秒（4 帧）。这些旨在以最佳努力多路复用覆盖方式提供给视频源。HDMI 输入。 我对 DPU 功能感兴趣，但最初计划将视频卸载到联网的 GPU 系统。  * KV260 能做到这一点吗？ * 如果能，难度如何？ * 有人做过这个吗？有什么建议吗？ * 也欢迎任何关于方法的想法。 * 我对其他主板和工具持开放态度，但 FPGA 似乎是唯一速度足够快的东西， KV260 套件 https://www.amd.com/en/products/system-on-modules/kria/k26/kv260-vision-starter-kit.html    提交人    /u/Heavy_Carpenter3824   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gqqm7p/p_experience_with_kv260_for_realtime_video/</guid>
      <pubDate>Wed, 13 Nov 2024 23:18:07 GMT</pubDate>
    </item>
    <item>
      <title>[d] grounding-dino：load_image 内部在做什么，以及如何将相同的操作应用于视频帧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gqq1gd/d_groundingdino_what_is_load_image_doing/</link>
      <description><![CDATA[进行一些测试后，我注意到，对于同一幅图像，使用不同的方法加载，进行推理会返回非常不同的结果：  方法 1：库中的官方 load_image 函数（它使用作为参数传递的路径读取图像） 方法 2：使用 cv2 读取图像，然后转换为张量，然后交换轴以使深度作为第一个轴。  正如我所说，这两种方法都为您提供了一个张量来传递给模型，但它们返回的结果非常不同（方法 2 通常很糟糕），我检查了两种情况返回的图像的形状，它们是不同的，所以肯定在 load_image 内部进行了转换，我的问题是：load_image 内部发生了什么？所以我可以在其他脚本中复制它 我的最终目标是在视频上运行模型，我的意思是在视频的帧上运行模型，所以我不能使用 load_image 因为它们不是来自磁盘的图像，而是从视频中获取的，所以我需要了解 inside_load image 发生了什么，这样我就可以模拟视频帧上的这种行为。 更新：找到了 https://github.com/IDEA-Research/GroundingDINO/blob/856dde20aee659246248e20734ef9ba5214f5e44/groundingdino/util/inference.py#L39    提交人    /u/Sad-Anywhere-2204   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gqq1gd/d_groundingdino_what_is_load_image_doing/</guid>
      <pubDate>Wed, 13 Nov 2024 22:52:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在机器人学习任务上对视觉、语言和动作模型进行基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gqftrm/r_benchmarking_vision_language_action_models_on/</link>
      <description><![CDATA[代码：https://github.com/ManifoldRG/MultiNet 网站：http://multinet.ai/static/pages/Multinetv01.html    由   提交  /u/harshsikka123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gqftrm/r_benchmarking_vision_language_action_models_on/</guid>
      <pubDate>Wed, 13 Nov 2024 15:45:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对于带有附加信息的分解机来说，什么样的推荐系统框架比较好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gqeeow/r_whats_a_good_recommender_systems_framework_for/</link>
      <description><![CDATA[您好！我正在寻找一个推荐系统框架，它可以帮助我为一个研究项目的 CTR 数据生成推荐，其中主要数据集是用户的浏览数据，而辅助信息数据是项目特征。我试过 Elliot，但内存一直用完。    提交人    /u/FragileHumans   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gqeeow/r_whats_a_good_recommender_systems_framework_for/</guid>
      <pubDate>Wed, 13 Nov 2024 14:42:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] SelfCodeAlign：代码生成的自对齐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gqd7w1/r_selfcodealign_selfalignment_for_code_generation/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gqd7w1/r_selfcodealign_selfalignment_for_code_generation/</guid>
      <pubDate>Wed, 13 Nov 2024 13:45:44 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] VQ-VAE Loss 中重建损失项的证明</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gqbeie/discussion_proof_of_reconstruction_loss_term_in/</link>
      <description><![CDATA[大家好， 我正在阅读论文“神经离散表示学习”当我看到 VQ-VAE 损失方程中的第一个项时，我感到很困惑 https://preview.redd.it/l1s9kur3sn0e1.png?width=1394&amp;format=png&amp;auto=webp&amp;s=4d374dce319a7ac0bbf19089d4e06cabcaa2cd3d 我理解第二项和第三项的作用。但是，我无法从原始图像和重建图像之间的 MSE 中推导出第一项。我假设它将类似于 VAE 中的 ELBO 损失。论文提到了他们为什么省略了 KL 散度项，但即便如此，我也不明白 ELBO 损失中的期望怎么会是第一项。 注意：我不是统计学专业的，所以如果问题是基本问题，如果你能告诉我它是什么会很有帮助。此外，如果问题没有清楚地解释，我可以在讨论中进一步解释大家好，我正在阅读论文“神经离散表示学习”，当我看到 VQ-VAE 损失方程中的第一项时，我感到很困惑。我理解第二项和第三项的作用。但是，我无法从原始图像和重建图像之间的 MSE 中推导出第一项。我假设它会类似于 VAE 中的 ELBO 损失。论文提到了他们为什么省略了 KL 散度项，但即便如此，我也不明白 ELBO 损失中的期望怎么会变成第一个项。注意：我不是统计学专业的，所以如果问题是基本问题，如果你能告诉我它是什么，那会很有帮助。此外，如果问题没有清楚地解释，我可以在讨论中进一步解释。 [讨论]    提交人    /u/Snoo_65491   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gqbeie/discussion_proof_of_reconstruction_loss_term_in/</guid>
      <pubDate>Wed, 13 Nov 2024 12:07:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 帮助 LLM 代理使用图形用户界面</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gqanre/r_help_with_graphic_user_interface_for_llm_as/</link>
      <description><![CDATA[我记得不久前（3-4 个月）在 Twitter 上看到一个图形用户界面，用于将 LLM 设置为图中的节点作为代理并使其交互。 用户界面是黑色的，详细信息为黄色。 当 LLM 计算时，一个黄色圆圈围绕着正在计算答复的代理的节点移动……然后“流”作为边缘上的黄色传递到正在计算下一个答案的 LLM…… 我已经问过机器人，但我记不起这个项目了。这是一个开源项目。看起来非常有趣和聪明。这是在图形配置方面解锁“苏格拉底人工智能”。 它是开源的，不是 LangChain。 有人记得吗？哪一个？     由    /u/vale_valerio 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gqanre/r_help_with_graphic_user_interface_for_llm_as/</guid>
      <pubDate>Wed, 13 Nov 2024 11:20:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025 论文评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gq8vu6/d_iclr_2025_paper_reviews/</link>
      <description><![CDATA[ICLR 2025 的评论似乎可以在 OpenReview 上找到。欢迎在这里庆祝/抱怨/表达您的评论！ 去年的统计数据这里    提交人    /u/pie3636   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gq8vu6/d_iclr_2025_paper_reviews/</guid>
      <pubDate>Wed, 13 Nov 2024 09:10:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] AMA：我是一家英国公司的人工智能主管，为政府、行业等提供咨询。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gq899s/d_ama_im_head_of_ai_at_a_firm_in_the_uk_advising/</link>
      <description><![CDATA[问我任何有关英国人工智能采用、技术堆栈、如何成为人工智能/机器学习工程师或数据科学家等的问题，以及职业发展等问题。     提交人    /u/Psychological_Dare93   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gq899s/d_ama_im_head_of_ai_at_a_firm_in_the_uk_advising/</guid>
      <pubDate>Wed, 13 Nov 2024 08:20:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 基准分数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gq3tt3/d_benchmark_scores_of_llm/</link>
      <description><![CDATA[当我查看一些论文（尤其是 arXiv）中的测试数据时，一些小型模型（~7B）在一些著名的 LLM 基准数据集上表现出相当中等的性能。但是，根据我的经验，该模型在他们提到的数据集上表现得像个傻瓜（例如永无止境的重复生成）。当有人测试 LLM 的基准分数时，他们通常会在评分之前根据数据集对其进行微调吗？    提交人    /u/Upset_Employer5480   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gq3tt3/d_benchmark_scores_of_llm/</guid>
      <pubDate>Wed, 13 Nov 2024 03:35:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] Together，ARR 达到 1 亿美元，但它只是转售计算——炒作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gps8fl/d_together_ai_hits_100m_in_arr_but_it_just/</link>
      <description><![CDATA[我最近了解到，这家初创公司被视为近年来收入增长最快的公司。但他们实际上只是将 GPU 从一个提供商经纪到另一个提供商，然后收取经纪费…… 如果一名房地产经纪人销售价值 1 亿美元的房子，并获得 10 万美元的佣金，这并不意味着他们赚了 1 亿美元的收入……我在这里错过了什么？ 产品实际上是相同的，只是 ssh 到集群。 为什么人们要为此付费？这听起来像一个巨大的骗局，不是吗？这难道不应该与 Coreweave 这样的云提供商而不是 AI 公司进行比较吗？如果您拥有 GPU 作为云，那么您在几个月内就赚了 1 亿美元的 ARR……    提交人    /u/guardianz42   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gps8fl/d_together_ai_hits_100m_in_arr_but_it_just/</guid>
      <pubDate>Tue, 12 Nov 2024 18:52:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 怎样才能成为一名优秀的机器学习博士生</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gplmzb/d_what_makes_a_good_phd_student_in_ml/</link>
      <description><![CDATA[嘿，我最近开始攻读博士学位（主题：可解释对象检测），我真的很好奇，您认为哪些特征可以成为一名成功的博士生    提交人    /u/RaeudigerRaffi   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gplmzb/d_what_makes_a_good_phd_student_in_ml/</guid>
      <pubDate>Tue, 12 Nov 2024 14:13:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>