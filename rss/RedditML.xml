<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 24 May 2024 21:13:59 GMT</lastBuildDate>
    <item>
      <title>[D] 将思维导图转换为文本以嵌入矢量数据库。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czrhy1/d_convert_mindmaps_into_text_to_embed_into_vector/</link>
      <description><![CDATA[嗨，我有一些关于我的领域的详细思维导图，我想知道是否有办法转换这些导图并将它们放入向量中知识数据库。我一直在做的一种方法是截取这些部分的屏幕截图并放入 GPT4V 中以转换为文本以嵌入 Vdb 中。还有其他解决办法吗？   由   提交 /u/Own-Cherry6760    reddit.com/r/MachineLearning/comments/1czrhy1/d_convert_mindmaps_into_text_to_embed_into_vector/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czrhy1/d_convert_mindmaps_into_text_to_embed_into_vector/</guid>
      <pubDate>Fri, 24 May 2024 18:20:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用表情符号重新创建图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czm3bw/p_recreate_images_with_emojis/</link>
      <description><![CDATA[演示： https: //replicate.com/johnsutor/emoji-painter  我创建了一个 DNN，它可以通过将表情符号连续粘贴到“画布”上来重新创建目标图像。该代码很大程度上受到 Paint Transformer 的启发，它将笔触顺序粘贴到画布上以重新创建照片。在该论文/代码库中，他们使用单一画笔类型，而我认为表情符号是要从中采样的不同画笔。 Gumbel softmax 用于从 N 个不同的表情符号中选择一个粘贴到画布上，并选择相应的比例、旋转以及中心 x 和 y 坐标。  我也计划在其他形状上训练模型（我愿意接受任何考虑和反馈！）   由   提交/u/JSutie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czm3bw/p_recreate_images_with_emojis/</guid>
      <pubDate>Fri, 24 May 2024 14:29:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 最先进的开源计算机视觉模型，但不是资源密集型的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czlgss/p_stateoftheart_open_source_computer_vision/</link>
      <description><![CDATA[哪些前沿 CV 模型（对象检测、分割等）可以安装在相对中端的 GPU 上，例如 A4000 左右。我对硬件推理特别感兴趣，训练不太重要。 比 ResNet 或 YOLO 更有趣、更高效的东西，不一定是 CNN！ 提前谢谢，只要告诉我你的想法就行    提交人    /u/GWP-NU   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czlgss/p_stateoftheart_open_source_computer_vision/</guid>
      <pubDate>Fri, 24 May 2024 14:01:51 GMT</pubDate>
    </item>
    <item>
      <title>GPT NEO X LLM [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czk2sg/gpt_neo_x_llm_p/</link>
      <description><![CDATA[我正在尝试从 GPT NEO X 执行推理，但出现了错误 logits[:, -1].view(batch_size, -1).contiguous() TypeError: 元组索引必须是整数或切片，而不是元组 ​ 有人能告诉我该如何解决这个问题吗？ 更多信息可以在这里 ​ 谢谢    提交人    /u/thatsadsid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czk2sg/gpt_neo_x_llm_p/</guid>
      <pubDate>Fri, 24 May 2024 12:56:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 陷入选择适当数量的簇的困境。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czjlyt/d_stuck_in_selecting_appropriate_number_of/</link>
      <description><![CDATA[      我正在处理一个有 19 列和 36000 行的数据集...我被要求对其进行聚类。所以我正在尝试使用 KMeans。当对这个问题执行肘部方法时，我得到了以下图表。聚类数从 1 到 249。有人可以建议我应该选择 k 的值吗？对于这样的数据集，还有其他算法可以尝试吗？ https://preview.redd.it/ftefa83x3e2d1.png?width=1355&amp;format=png&amp;auto=webp&amp;s=2cee33788041b0bb7e3eb142654241e044da8188 https://preview.redd.it/4xa7ttbz3e2d1.png?width=1389&amp;format=png&amp;auto=webp&amp;s=80b3bf546dc00ddd3f2ba11a00639da2cb813d85    提交人    /u/SmallSoup7223   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czjlyt/d_stuck_in_selecting_appropriate_number_of/</guid>
      <pubDate>Fri, 24 May 2024 12:31:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检测相同形状但不同颜色的物体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czdmty/d_detecting_objects_of_same_shape_but_different/</link>
      <description><![CDATA[     &lt; /td&gt; 我正在努力检测具有相同形状但不同颜色且没有其他区别特征的对象。当存在可区分的模式时，YOLO 等基于 CNN 的架构会产生奇迹并实现高精度。但是，我需要一种可以纯粹根据颜色准确分类对象的方法。 我当前的挑战是，当我尝试在 RGB 空间中按颜色对这些对象进行分割时，这些对象是不可分离的。有谁有可以在按颜色确定对象类别方面实现良好准确度的建议或方法吗？ 我在下面提供了一张图片以供参考。任何帮助将不胜感激！  https://preview.redd.it/83c6e7dbbb2d1.png?width=793&amp;format=png&amp;auto=webp&amp;s=532c7cffcbaea96eb48d374e073bd49d5f029212 编辑 转换颜色空间到 HSV 解决了这个问题。以下是 HSV 色彩空间表示 https ://preview.redd.it/hq5yrf5wcf2d1.png?width=793&amp;format=png&amp;auto=webp&amp;s=c40002fd360c1891baaed915f536aa7dae4061f5 第一阶段，我使用YOLO模型进行检测对象 在第二阶段，我裁剪检测到的对象，将裁剪后的图像转换为 HSV，计算每个对象的平均分量值，然后训练 XGBoost 模型基于 3D 向量预测颜色标签，代表H、S、V 通道的平均值。   由   提交/u/ThickDoctor007  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czdmty/d_detecting_objects_of_same_shape_but_different/</guid>
      <pubDate>Fri, 24 May 2024 05:44:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] DeepFusion：高度模块化的深度学习框架。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czcz42/p_deepfusion_a_highly_modular_deep_learning/</link>
      <description><![CDATA[大家好，我是斯坦福大学的一名学生，由于身体状况原因，我正在休学一年，为了利用我的时间来学习深度学习. 瞧... 我开发了一个深度学习库， DeepFusion！ 它是可定制的，并且具有易于访问且高度直观的代码库。人们可以直接深入并毫不费力地理解源代码。 您可以从以下位置下载它： - github at https:/ /github.com/aharvaaalok/deepfusion - 或使用 pip install deepfusion 安装（简单！） 有关解释用法和功能的一系列示例，请参阅 演示 或 教程&lt; /a&gt;. 欢迎提出任何建议，非常感谢您的贡献！   由   提交/u/aharvaaalok16   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czcz42/p_deepfusion_a_highly_modular_deep_learning/</guid>
      <pubDate>Fri, 24 May 2024 05:01:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] 学习对 CLIP (&SigLIP) 进行二值化，以实现多模态检索和排序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz5zx1/p_learn_to_binarize_clip_siglip_for_multimodal/</link>
      <description><![CDATA[学习使用 CLIP 进行二值化和排序，将文本或多模态搜索和推荐的存储空间减少 32 倍。 文章：https://www.marqo.ai/blog/learn-to-binarize-clip-for-multimodal-retrieval-and-ranking  CLIP 排序调整期间的二元嵌入保留了 87-93% 的 fp32 嵌入。 使用 4 倍缩放温度的 S 型函数进行伪量化（几乎）普遍优于 tanh（参见下一点）。 0/1（S 型函数）上的余弦相似度优于 -1， 1 (tanh) - 很确定这是因为余弦具有更好的退化（D vs DxN），因为它会惩罚不在同一超球面上的嵌入（它还会偏向较少的非零元素）。 在训练期间使用 L1 来近似汉明距离，这比余弦略好（对于 0/1）。 使用 GS-10M 评估使用精确 KNN 进行多模态检索。 添加辅助二元损失后，Fp32 嵌入可保持完全保真度。 在域内、新查询、新文档和零样本设置中进行评估。 可以与 Matryoshka 如果确实有必要，但保真度会受到影响（未显示）。     提交人    /u/Jesse_marqo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz5zx1/p_learn_to_binarize_clip_siglip_for_multimodal/</guid>
      <pubDate>Thu, 23 May 2024 22:46:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 ML 中处理 GPL 许可？示例：商业物体检测应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz57uj/d_how_to_handle_gpl_licensing_in_ml_example/</link>
      <description><![CDATA[机器学习人员大家好， 我正在开发一个涉及对象检测模型的商业应用程序。我正在考虑将 YOLOv7 与我自己的训练数据一起使用，但我担心许可问题。 YOLOv7 已获得 GNU GPL 3.0 许可，如果将 YOLOv7 集成到其中，这将要求我将整个应用程序的源代码开源。 我很好奇其他人如何处理这种情况。具体来说：  开发人员是否经常诉诸于使用不同的、较旧的模型，这些模型对商业应用程序有更宽松的许可？ 是否有任何替代方法，例如从使用 YOLOv7 存储库（以便它不是存储库的衍生品）从头开始，并构建我自己的不使用 YOLOv7 代码库进行推理的推理管道？例如使用 ONNX。  我非常感谢任何见解或经验。 谢谢！   由   提交 /u/sushi_roll_svk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz57uj/d_how_to_handle_gpl_licensing_in_ml_example/</guid>
      <pubDate>Thu, 23 May 2024 22:10:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] SSAMBA 简介：自我监督的音频曼巴！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz1yoa/r_introducing_ssamba_the_selfsupervised_audio/</link>
      <description><![CDATA[嘿 Reddit， 厌倦了变形金刚？你真的需要关注吗？认识 SSAMBA（自我监督音频曼巴）！ 🐍✨  这个无需注意、纯粹基于状态空间模型 (SSM) 的自我监督奇迹不只是嘶嘶声，而是咆哮声！在说话人识别、关键字识别和音频分类等任务上，SSAMBA 比基于 Transformer 的同类产品 (SSAST) 实现了更好或相似的性能。但更重要的是：它的 GPU 内存效率更高，推理速度更快，尤其是在音频长度较长的情况下。好奇吗？请在此处查看完整论文：arXiv 上的 SSAMBA  感谢您的收听！    由   提交 /u/attentionisallyounee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz1yoa/r_introducing_ssamba_the_selfsupervised_audio/</guid>
      <pubDate>Thu, 23 May 2024 19:53:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Paperswithcode相关？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz1t4x/d_paperswithcode_relevant/</link>
      <description><![CDATA[对我来说，paperswithcode 与跟踪 ML 进展的相关性降低了。 但这很难说，在我的领域（表格 ML/DL）没有太多既定的学术基准（还不需要像带有代码的论文之类的东西） 在 NLP 和基础模型空间中，hf 空间中的排行榜已成为一种现象（主要是在 NLP 中） ）。 总体而言，paperswithcode 感觉维护较少且不太有用。 您经常使用paperswithcode 吗？你用它来做什么？它在您的什么领域有用？   由   提交/u/_puhsu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz1t4x/d_paperswithcode_relevant/</guid>
      <pubDate>Thu, 23 May 2024 19:46:48 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 如果您可以选择 3 篇关于视频/图像生成模型的论文，您会选择哪一篇？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cyy7v9/dr_if_you_could_pick_3_papers_about_videoimage/</link>
      <description><![CDATA[我正在攻读硕士学位，并且我选择做一个视频生成项目。我读过一些关于图像和视频合成的论文：  VQGAN Stable Diffusion Imagen  我还挑选了 3 篇视频生成论文：  Video-LDM Stable Video Diffusion Fine-tuned for Multi-View Generation (SVD-MV) &lt; li&gt;Text2Video-Zero  我还阅读了一些调查论文，这些是我选择谈论的模型。 我正在努力解决的是为了选择逻辑上有序的论文，所以首先我解释一下 3 个图像生成论文，视频生成论文应该遵循图像合成论文中提到的相同策略。 我可以请你建议不同的一组论文要写什么？我仍然可以将所有论文更改为其他内容。 大多数是最近的内容（2020-2024 年很好）并且具有一些重大影响。我知道例如 VQGAN 是流行的基础模型，论文中使用的技术和策略今天仍然相关。 Imagen（由 Google 提供）但是不是开源的，我更喜欢具有开源代码的论文。这就是我避免 OpenAI 论文的原因。 我还读到，在视频生成中选择扩散而不是 GAN，因为它在质量和训练方面都有更好的结果。然而，扩散的计算成本更高。 例如，Video-LDM 基于稳定扩散，因此对我来说，这是值得讨论的好论文。 &lt;!-- SC_ON - -&gt;  由   提交 /u/ShlomiRex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cyy7v9/dr_if_you_could_pick_3_papers_about_videoimage/</guid>
      <pubDate>Thu, 23 May 2024 17:18:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 变分推理：反向 KL 与正向 KL</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cyubdt/r_variational_inference_reverse_kl_vs_forward_kl/</link>
      <description><![CDATA[大家好， 我正在研究变分推理方法，主要是在 BNN 的背景下。使用反向（独占）KL 作为变分目标是常见的方法，尽管最近我偶然发现了一些使用前向（包含）KL 作为目标的有趣作品，例如 [1][2][3]。此外，在 GP 的 VI 背景下，两种散度度量均已使用，请参阅 [4]。 虽然我熟悉反向 KL 目标之间众所周知的差异，但它是“模式-”寻求”而正向 KL 是“模式覆盖”，我看到其中一些作品对这些 VI 目标的下游差异提出了主张，例如（此处解释）“反向 KL 低估了预测方差” [4]和“前向 KL 对于受益于保守不确定性量化的应用很有用” [3]. 我有兴趣在 VI 的背景下理解这些下游差异，但还没有找到任何从理论上而不是从经验上解释这些主张的著作。任何人都可以为我指出正确的方向或尝试解释这一点？ 干杯 [1] Naesseth、Christian、Fredrik Lindsten 和 David Blei。 “马尔可夫分数攀爬：KL (p|| q) 的变分推理。” 神经信息处理系统的进展 33 (2020): 15499-15510。 [2] Zhang, L., Blei, D. M., &amp;奈塞斯，C.A.（2022）。传输分数攀登：使用前向 KL 和自适应神经传输进行变分推理。 arXiv 预印本 arXiv:2202.01841。 [3] McNamara, D., Loper, J., &amp; Regier, J.（2024 年 4 月）。用于摊余变分推理中的包容性 KL 最小化的顺序蒙特卡罗。 人工智能与统计国际会议（第 4312-4320 页）。 PMLR。 [4] Bauer, M.、Van der Wilk, M.、&amp;拉斯穆森，C.E.（2016）。了解概率稀疏高斯过程近似。 神经信息处理系统的进展，29。   由   提交/u/DriftingClient  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cyubdt/r_variational_inference_reverse_kl_vs_forward_kl/</guid>
      <pubDate>Thu, 23 May 2024 14:36:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] Phi-3 模型并排比较。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cytxb5/d_phi3_models_compared_sidebyside/</link>
      <description><![CDATA[      https://preview.redd.it/8l04pnfhq62d1.png?width=661&amp;format=png&amp;auto=webp&amp;s=7fe616ca8cd7da97407 0c86b6b47ffab3ab545e5   https://preview.redd.it/hr7fr1uiq62d1.png?width=688&amp;format=png&amp;auto=webp&amp;s=bd3de359bfe4c1ed82d092be92ae38c246bdfda2    https://preview.redd.it/v6k3v39kq62d1.png？ width=450&amp;format=png&amp;auto=webp&amp;s=c0abb0e397a498ef7ccfb35b1b1cb598198f66ad 对于任何想要在一个地方比较 Phi-3 基准的人。 有趣的比较：ANLI、Hellaswag、MedQA、TriviaQA、语言理解、事实知识和稳健性。 注意：Phi-3 迷你模型表的标签顺序不同。   由   提交/u/dark_surfer  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cytxb5/d_phi3_models_compared_sidebyside/</guid>
      <pubDate>Thu, 23 May 2024 14:19:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>