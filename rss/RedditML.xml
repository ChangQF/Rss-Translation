<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 30 Sep 2024 03:27:12 GMT</lastBuildDate>
    <item>
      <title>[D] 人形动画的预训练模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fshs76/d_pretrained_models_for_humanoid_animations/</link>
      <description><![CDATA[目前有很多用于图像相关项目的开放/免费模型。有没有用于人体动画的类似模型？基于 GAN 的模型似乎在对现有动画数据进行训练后应该能够生成新的、逼真的动作。但我找不到任何有用的东西。我正在尝试自己在本地进行一些训练/实验，但结果并不理想。任何见解和指点都将不胜感激！    提交人    /u/gamesntech   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fshs76/d_pretrained_models_for_humanoid_animations/</guid>
      <pubDate>Sun, 29 Sep 2024 23:27:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我对自己实施的基线缺乏信心。我该怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fshhor/r_i_feel_underconfident_about_the_baselines_i/</link>
      <description><![CDATA[我需要实现 3 个具有一定理论遗憾界限的基线 RL 算法。原始论文没有提供他们自己的任何代码/也没有在他们的工作中进行任何模拟。我对我的实现没有信心，特别是超参数调整，因为我们使用的环境不同。 我尽我所能通过严格搜索不同的参数来使基线发挥最佳性能。当理论上我们应该获得可比结果时，显示我们的算法表现更好感觉不道德。它们的性能非常依赖于超参数。我该怎么办？    提交人    /u/Replay0307   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fshhor/r_i_feel_underconfident_about_the_baselines_i/</guid>
      <pubDate>Sun, 29 Sep 2024 23:13:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 优化 transformer</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsgz5i/r_optimizing_transformers/</link>
      <description><![CDATA[您好，我目前致力于优化 Transformer 模型，特别是在多视图图像和/或交叉注意网络中。我注意到交叉注意层添加了很多参数，这会减慢训练过程。我正在探索降低计算复杂度以提高速度的方法（目前和以后一段时间内不会牺牲太多性能）。我开始研究：  低秩矩阵分解 - 我一直在阅读有关如何应用它来减小投影矩阵的大小（例如，交叉注意中的 projq、projk、projv）的文章。是否有人在交叉注意机制中使用低秩分解的经验？ 其他参数减少技术 - 除了低秩分解之外，还有其他方法可以减少 Transformer 模型中的参数数量，比如稀疏性和修剪 - 你对这些有什么建议或经验吗？ 克服多视图场景中的冗余 - 鉴于我的问题的多视图性质，我怀疑交叉注意处理不同视图的方式存在一些冗余。是否有人研究过减少基于 Transformer 的网络中视图之间的冗余？哪种技术最适合你？  我开始研究 CVPR、NEURIPS、ECCV 等，但如果您能分享任何见解、建议、经验或论文，我将不胜感激！提前致谢！    提交人    /u/Cool-Economy3492   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsgz5i/r_optimizing_transformers/</guid>
      <pubDate>Sun, 29 Sep 2024 22:47:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 任务增量持续学习的基线</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsg0kf/r_baselines_for_taskincremental_continuous/</link>
      <description><![CDATA[我正在寻找一篇或多篇包含任务增量式持续学习基线结果的论文，特别是包含 CIFAR100/5 的 ResNet50 结果的论文。最近的许多文献都集中在类增量学习上。欢迎提出任何建议！    提交人    /u/Due-Mix2877   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsg0kf/r_baselines_for_taskincremental_continuous/</guid>
      <pubDate>Sun, 29 Sep 2024 22:02:30 GMT</pubDate>
    </item>
    <item>
      <title>尝试进入 LLM 培训。关于训练 T5 模型的数据集问题。[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsdu4v/trying_to_get_into_training_llms_question_on/</link>
      <description><![CDATA[大家好。我正在尝试训练法学硕士。我接手的第一个个人项目之一是微调 T5 模型。我想针对我喜欢的特定作者的特定领域主题专门训练一个 QnA T5 模型。我能够创建自己的数据集。由于我的目标是创建一个专门执行 QnA 的聊天机器人，所以我知道 QnA 数据集是必需的。我还能够创建一个屏蔽语言建模数据集和段落改组数据集，但我认为这些数据集是可选的。我认为它们应该可以帮助我的 T5 模型掌握作者使用的特定白话/行话/口头习惯，但我在训练期间注意到，将所有 3 个数据集组合在一起，训练我的 T5 模型需要太长时间（T5-small 需要 8 小时以上）。我决定只使用 QnA 数据集来加快训练速度并节省资金。我相信 QnA 数据集应该足够了，但我在网上找不到任何信息来支持我的想法。 我只是想听听其他有 T5 经验的人的意见。包括段落改组和掩码语言建模数据集对 QnA 任务有任何影响吗？我也想建立一个 ML/AI 产品组合。托管/部署我自己的 T5 模型是否值得托管，还是与 Llama 和 GPT 等更大的模型相比，它被认为是过时/无聊的？我确实打算在未来的某个时候训练这些模型，我只是想从 T5 作为启动项目开始，然后再转到更大的 LLM。    提交人    /u/ApricotSlight9728   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsdu4v/trying_to_get_into_training_llms_question_on/</guid>
      <pubDate>Sun, 29 Sep 2024 20:24:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] VisionTS：使用视觉掩蔽自动编码器进行零样本时间序列预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fs7opx/p_visionts_zeroshot_time_series_forecasting_with/</link>
      <description><![CDATA[      VisionTS 是一种新预训练的模型，它将预测任务重新定义为图像重建任务。该技术乍一看似乎违反直觉，但该模型的效果出奇地好。 可以在此处找到该模型的详细分析。 VisionTS    提交人    /u/apaxapax   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fs7opx/p_visionts_zeroshot_time_series_forecasting_with/</guid>
      <pubDate>Sun, 29 Sep 2024 16:00:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 来自游戏屏幕的强化学习模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fs7msq/p_reinforcement_learning_model_from_gamescreen/</link>
      <description><![CDATA[您好，我不知道这是否是它的正确子版块，但我对强化学习有一个问题。我知道模型需要状态来确定动作。但对于像 Pokémon 这样的游戏，我实际上无法获得状态。所以我想知道游戏屏幕是否可以用作状态。理论上应该可以，也许我需要手动从屏幕中提取关键信息并创建该状态。但我想避免这种情况，因为我希望模型能够发挥 Pokémon 的两个方面，即探索和战斗。 我正在考虑的第二个问题是，每当模型执行某项操作时，我将如何确定要给予的奖励时间和金额。由于我没有从游戏中获取任何数据，所以我不知道它何时赢得战斗，也不知道当它的神奇宝贝生命值较低时它会何时治愈它们。 由于我对机器学习没有那么多经验，几乎没有，所以我开始怀疑这是否有可能。有人可以对这个想法发表意见并给我一些指点吗？我很想了解更多，但我找不到一个好的起点。    提交人    /u/tirodokter   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fs7msq/p_reinforcement_learning_model_from_gamescreen/</guid>
      <pubDate>Sun, 29 Sep 2024 15:57:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 截至 2024 年，风格转换的 SOTA 模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frxkwa/d_whats_the_sota_model_for_style_transfer_as_of/</link>
      <description><![CDATA[目前图像风格转换的最新技术是什么？扩散是否比基于 Gram 矩阵的方法有显著的改进？ 我熟悉 2017 年基于 Gram 矩阵的方法，但它们在更高级别的概念上遇到了困难。现在还在使用它们吗？    提交人    /u/JellyBean_Collector   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frxkwa/d_whats_the_sota_model_for_style_transfer_as_of/</guid>
      <pubDate>Sun, 29 Sep 2024 05:50:37 GMT</pubDate>
    </item>
    <item>
      <title>[p] lorakit：用于快速原型化 SDXL LoRA 模型的简单工具包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frwmt9/p_lorakit_a_simple_toolkit_for_rapid_prototyping/</link>
      <description><![CDATA[  由    /u/os75  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frwmt9/p_lorakit_a_simple_toolkit_for_rapid_prototyping/</guid>
      <pubDate>Sun, 29 Sep 2024 04:46:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 29 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 以前有人做过这种类型的模型 RL 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frpudp/d_has_anyone_done_this_type_of_model_rl_before/</link>
      <description><![CDATA[我研究过 RL 中的世界模型，它们中的大多数要么使用基于好奇心的奖励来让模型进行探索，直到离线训练时才学习任何东西，离线训练时，它们会获取随机事件并对其进行评分，然后训练代理 — 或者只是让网络在世界模型中进行训练。 我曾尝试寻找具有这些标准的基于模型的 RL 架构；让策略网络将真实输出（这只是常规的 RL 输出）以及输入到世界模型中的伪/虚构输出作为输出 — 反过来，如果世界模型到策略算法循环回到自身，世界模型则会预测下一个时间步或未来许多时间步 — 并与下一个时间步中的观察结果一起提供给网络，或者可能只是让评论家对潜在预测进行评分，并将该标量也输入到网络中 — 有点像树搜索，但是是神经的而不是算法的。 这可能由于许多原因而没有完成，但它仍然值得深思！我想知道它是否可以用于改进动作空间搜索或战略建模，因为网络可以根据假设评估许多可能的结果 - 尽管它可能会卡在局部最小值 999/1000 次。     提交人    /u/Scoffpickle   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frpudp/d_has_anyone_done_this_type_of_model_rl_before/</guid>
      <pubDate>Sat, 28 Sep 2024 22:27:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 向项目主席报告了潜在的双重提交案例，但他们并不关心。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frnq72/d_flagged_a_potential_dual_submission_case_to/</link>
      <description><![CDATA[      关于https://www.reddit.com/r/MachineLearning/comments/1f7axjm/d_potential_dual_submissions_2_similar_iclr_24/ 不久前我偶然发现了这两篇论文，我注意到它们非常相似。我向 ICLR 2024 项目主席发送了一封电子邮件，询问他们有关此事的情况，其中包括： Katerina Fragkiadaki（CMU） Mohammad Emtiyaz Khan（RIKEN AIP，东京） Swarat Chaudhuri（UT Austin） Yizhou Sun（UCLA）。 https://preview.redd.it/4ia3rvgr3mrd1.png?width=1390&amp;format=png&amp;auto=webp&amp;s=a6697aa0b319f3b5b2821073dc6b2e48eea99357 但是他们根本没有回复。很明显，他们根本不在乎正直和诚实。不尊重规则。 科学只是一场金钱游戏。   由    /u/One-Tax-2998  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frnq72/d_flagged_a_potential_dual_submission_case_to/</guid>
      <pubDate>Sat, 28 Sep 2024 20:44:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将 GPT 转换为 Llama 的分步代码指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frer4z/p_converting_gpt_to_llama_stepbystep_code_guide/</link>
      <description><![CDATA[      一个经常被问到的问题是 GPT 与 Llama 相比如何。在我看来，了解差异的最佳方法之一是从头开始实现这两种架构。这里有一个分步 Jupyter 笔记本指南。 https://preview.redd.it/qowi1sf12krd1.jpg?width=4286&amp;format=pjpg&amp;auto=webp&amp;s=b815e4e6df8d38c70816fb6f51ff1482b6cca80e    提交人    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frer4z/p_converting_gpt_to_llama_stepbystep_code_guide/</guid>
      <pubDate>Sat, 28 Sep 2024 13:51:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] neurips2024 论文列表已经出炉！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fr9bm2/d_list_of_neurips2024_papers_is_out/</link>
      <description><![CDATA[https://nips.cc/virtual/2024/papers.html?filter=titles 享受！    由   提交  /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fr9bm2/d_list_of_neurips2024_papers_is_out/</guid>
      <pubDate>Sat, 28 Sep 2024 07:52:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>