<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 29 Sep 2024 03:25:31 GMT</lastBuildDate>
    <item>
      <title>[D] 定制AI程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frugon/d_custom_ai_program/</link>
      <description><![CDATA[我正在寻找某人就创建我自己的程序（零编程/编码经验）或雇用某人为我做这件事提供建议。我正在寻找一个专门用于监管建议和审查我的文档的 AI 程序。所涉及的行业是生物制药，因此符合 FDA、加拿大卫生部和欧盟法规内的 GMP（良好生产规范）。  提前谢谢您！    提交人    /u/Due_Profession_7578   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frugon/d_custom_ai_program/</guid>
      <pubDate>Sun, 29 Sep 2024 02:35:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 29 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人尝试过使用 Exponent 进行机器学习面试准备吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frsimq/d_has_anyone_tried_using_exponent_for_ml/</link>
      <description><![CDATA[我一直在寻找一个准备 ML 和 DS 面试的好地方，然后找到了 exponent。对它的评价褒贬不一。我知道有很多免费的准备材料，但它似乎可以访问大型科技公司提出的具体问题，并将所有资源集中在一个地方。有什么想法吗？    提交人    /u/KeyConsideration4971   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frsimq/d_has_anyone_tried_using_exponent_for_ml/</guid>
      <pubDate>Sun, 29 Sep 2024 00:46:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 以前有人做过这种类型的模型 RL 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frpudp/d_has_anyone_done_this_type_of_model_rl_before/</link>
      <description><![CDATA[我研究过 RL 中的世界模型，它们中的大多数要么使用基于好奇心的奖励来让模型进行探索，直到离线训练时才学习任何东西，离线训练时，它们会获取随机事件并对其进行评分，然后训练代理 — 或者只是让网络在世界模型中进行训练。 我曾尝试寻找具有这些标准的基于模型的 RL 架构；让策略网络将真实输出（这只是常规的 RL 输出）以及输入到世界模型中的伪/虚构输出作为输出 — 反过来，如果世界模型到策略算法循环回到自身，世界模型则会预测下一个时间步或未来许多时间步 — 并与下一个时间步中的观察结果一起提供给网络，或者可能只是让评论家对潜在预测进行评分，并将该标量也输入到网络中 — 有点像树搜索，但是是神经的而不是算法的。 这可能由于许多原因而没有完成，但它仍然值得深思！我想知道它是否可以用于改进动作空间搜索或战略建模，因为网络可以根据假设评估许多可能的结果 - 尽管它可能会卡在局部最小值 999/1000 次。     提交人    /u/Scoffpickle   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frpudp/d_has_anyone_done_this_type_of_model_rl_before/</guid>
      <pubDate>Sat, 28 Sep 2024 22:27:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] Android 上的离线翻译</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1froos8/d_offline_translation_on_android/</link>
      <description><![CDATA[大家好， 不久前，我开始着手开发一款开源的完全离线 Android 翻译应用，就像 Google Lens 一样。我之前没有运行任何类型的 AI 模型的经验，所以可以说，这是一个相当难的学习过程。 经过一番研究，我决定使用 Helsinki-NLP 的 OpusMT 模型。由于他们提供 Tensorflow 模型，我认为将它们转换为 TFLite 并完成它会很容易。在使用 SentencePiece 和我的自定义 Marian 标记器实现使标记化工作后，我没能使模型正常工作。 说实话，我不知道自己在做什么，后来才发现 OpusMT 模型有编码和解码步骤。但直到我继续操作后才发现，因为只有一个 Tensorflow 文件。 我希望 ONNX-Runtime (ORT) 更适合。这也不像听起来那么容易，因为我必须使用缺少的操作为 Android 编译自己的运行时。 最终我完成了整个往返工作。但我对推理速度不太满意。遗憾的是，在将模型简单地转换为 ONNX 然后转换为 ORT 后，意味着有许多操作与 NNAPI 不兼容。这意味着翻译一个大约 20 个单词的句子需要 3 秒钟。 使模型与 NNAPI 兼容的最佳选择是什么？我还能获得其他好处吗，例如在模型中使用“过去”缓存？我尝试了最后一部分，但不知道如何正确实现它。 任何建议都很棒！谢谢 &lt;3    提交人    /u/RicoLycan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1froos8/d_offline_translation_on_android/</guid>
      <pubDate>Sat, 28 Sep 2024 21:30:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 向项目主席报告了潜在的双重提交案例，但他们并不关心。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frnq72/d_flagged_a_potential_dual_submission_case_to/</link>
      <description><![CDATA[      关于https://www.reddit.com/r/MachineLearning/comments/1f7axjm/d_potential_dual_submissions_2_similar_iclr_24/ 不久前我偶然发现了这两篇论文，我注意到它们非常相似。我向 ICLR 2024 项目主席发送了一封电子邮件，询问他们有关此事的情况，其中包括： Katerina Fragkiadaki（CMU） Mohammad Emtiyaz Khan（RIKEN AIP，东京） Swarat Chaudhuri（UT Austin） Yizhou Sun（UCLA）。 https://preview.redd.it/4ia3rvgr3mrd1.png?width=1390&amp;format=png&amp;auto=webp&amp;s=a6697aa0b319f3b5b2821073dc6b2e48eea99357 但是他们根本没有回复。很明显，他们根本不在乎正直和诚实。不尊重规则。 科学只是一场金钱游戏。   由    /u/One-Tax-2998  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frnq72/d_flagged_a_potential_dual_submission_case_to/</guid>
      <pubDate>Sat, 28 Sep 2024 20:44:23 GMT</pubDate>
    </item>
    <item>
      <title>TextGrad 教程 - 用于提示优化的文本梯度下降 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frjwh5/textgrad_tutorial_text_gradient_descent_for/</link>
      <description><![CDATA[      分享一个关于 TextGrad 的教程视频，TextGrad 是斯坦福大学一个相当新的文本优化库。他们有一个类似 PyTorch 的框架来评估、计算损失并通过 LLM 提示图提供反馈信号。    提交人    /u/AvvYaa   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frjwh5/textgrad_tutorial_text_gradient_descent_for/</guid>
      <pubDate>Sat, 28 Sep 2024 17:49:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医疗 AI：顶级研究论文/模型🏅（2024 年 9 月 21 日至 9 月 27 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frha2f/d_last_week_in_medical_ai_top_research/</link>
      <description><![CDATA[   上周医疗 AI：顶级研究论文/模型🏅（2024 年 9 月 21 日至 9 月 27 日） 本周医疗 AI 论文 医学中 o1 的初步研究：我们离 AI 医生更近了吗？  本文介绍了 o1，这是一种大型语言模型 (LLM)，它在 37 个医学数据集上进行了评估，与 GPT-4 和 GPT-3.5 相比，在临床理解、推理和多语言性方面表现出色。  医学 LLM 和其他模型：  DREAMS：用于医学 LLM 的 Python 框架  用于 EEG 数据处理、模型训练和报告生成的综合深度学习框架。   SLaVA-CXR：用于胸部 X 光报告自动化的小型语言和视觉助手  本文介绍了 SLaVA-CXR，这是一种创新的小型模型，旨在以高精度和高效率自动化胸部 X 光报告。  医学中的 O1：AI 医生的潜力 基因组语言模型：机遇与挑战  它重点介绍了关键的 gLM 应用，如功能约束预测、序列设计和迁移学习，同时讨论了为复杂基因组开发有效 gLM 的挑战。   医学 LLM 和基准：   MEDICONFUSION：探究医学 LLM 的可靠性  本文介绍了 MediConfusion，这是一个具有挑战性的基准，用于探究医学成像中多模态大型语言模型 (MLLM) 的故障模式。  CHBench：中国 LLM 健康评估  本文介绍了 CHBench，这是第一个全面的中国健康相关基准，旨在评估大型语言模型 (LLM) 对身心健康的理解。  精神疾病评估的 LLM PALLM：评估姑息治疗 LLM 蛋白质 LM：扩展的必要性？   框架和方法：   肿瘤学操作的数字孪生 增强医疗 AI 的护栏 InterMind：由 LLM 驱动的抑郁症评估 对话式健康代理：LLM 框架  医学 LLM 应用：   用于心理健康严重程度预测的 LLM 用于放射学报告的微调 LLM 患者教育中的 LLM：背痛 通过检索上下文增强医疗 LLM 针对临床 LLM 的持续预训练  医疗伦理中的人工智能：   医学成像人工智能中的置信区间 生成式人工智能是否已为临床应用做好准备  ...  详细查看完整帖子：https://x.com/OpenlifesciAI/status/1840020394880667937 感谢您的阅读！如果您知道任何遗漏的有趣论文，请随时在评论中分享。如果您在医疗 AI 方面有见解或突破，并希望在下周的版本中分享，请通过 Twt/x 与我们联系：OpenlifesciAI    提交人    /u/aadityaura   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frha2f/d_last_week_in_medical_ai_top_research/</guid>
      <pubDate>Sat, 28 Sep 2024 15:50:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将 GPT 转换为 Llama 的分步代码指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frer4z/p_converting_gpt_to_llama_stepbystep_code_guide/</link>
      <description><![CDATA[      一个经常被问到的问题是 GPT 与 Llama 相比如何。在我看来，了解差异的最佳方法之一是从头开始实现这两种架构。这里有一个分步 Jupyter 笔记本指南。 https://preview.redd.it/qowi1sf12krd1.jpg?width=4286&amp;format=pjpg&amp;auto=webp&amp;s=b815e4e6df8d38c70816fb6f51ff1482b6cca80e    提交人    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frer4z/p_converting_gpt_to_llama_stepbystep_code_guide/</guid>
      <pubDate>Sat, 28 Sep 2024 13:51:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAAI 提交和 CoRL 研讨会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frdyq5/d_aaai_submission_and_corl_workshop/</link>
      <description><![CDATA[我是否可以将目前正在 AAAI 会议审查的论文不做任何更改就提交给 CoRL 研讨会？这会对我的 AAAI 提交产生任何影响吗？CoRL 研讨会页面显示“已接受的论文将在研讨会网页上发布，并将以焦点演讲或海报的形式展示”。    提交人    /u/drainageleak   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frdyq5/d_aaai_submission_and_corl_workshop/</guid>
      <pubDate>Sat, 28 Sep 2024 13:10:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025 互惠审查例外</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frccr2/d_iclr_2025_reciprocal_reviewing_exception/</link>
      <description><![CDATA[我想申请审查豁免。在表单上我必须输入论文 ID，这与提交编号相同吗？我找不到任何论文 ID……    提交人    /u/Admirable_Variation5   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frccr2/d_iclr_2025_reciprocal_reviewing_exception/</guid>
      <pubDate>Sat, 28 Sep 2024 11:38:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] neurips2024 论文列表已经出炉！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fr9bm2/d_list_of_neurips2024_papers_is_out/</link>
      <description><![CDATA[https://nips.cc/virtual/2024/papers.html?filter=titles 享受！    由   提交  /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fr9bm2/d_list_of_neurips2024_papers_is_out/</guid>
      <pubDate>Sat, 28 Sep 2024 07:52:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama3.2-1B GGUF 量化基准测试结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqw88t/d_llama321b_gguf_quantization_benchmark_results/</link>
      <description><![CDATA[      我使用 IFEval 对 Llama 3.2-1B GGUF 量化进行了基准测试，以找到速度和准确性之间的最佳平衡数据集。为什么我选择 IFEval？它是测试 LLM 遵循指令情况的绝佳基准，这对于大多数现实世界用例（如聊天、问答和摘要）至关重要。 第一张图表显示了基于 IFEval 分数的不同 GGUF 量化的表现。 https://preview.redd.it/b580liydnerd1.png?width=692&amp;format=png&amp;auto=webp&amp;s=0b9a1b0e7af0004f25604d3634a615f2e6326d20 第二张图表说明了文件大小和性能之间的权衡。令人惊讶的是，q3_K_M 占用的空间更少（速度更快），但保持了与 fp16 相似的准确度水平。 https://preview.redd.it/6tkr76venerd1.png?width=866&amp;format=png&amp;auto=webp&amp;s=7dd90f1a82e4d222bcd4bd4475cb0b8720b8a5d1 https://preview.redd.it/zvmr0asgnerd1.png?width=1510&amp;format=png&amp;auto=webp&amp;s=2630cae9bac659591d714216b71d9ce87ea68222 完整数据可在此处获取：nexaai.com/benchmark/llama3.2-1b ​量化模型从 ollama.com/library/llama3.2 后端：github.com/NexaAI/nexa-sdk（SDK 将很快支持基准测试/评估！） 下一步是什么？  我接下来应该对 Llama 3.2-3B 进行基准测试吗？ 对 AWQ 等不同的量化方法进行基准测试？ 欢迎提出改进此基准测试的建议！  让我知道你的想法！    提交人    /u/AlanzhuLy   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqw88t/d_llama321b_gguf_quantization_benchmark_results/</guid>
      <pubDate>Fri, 27 Sep 2024 19:41:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 批次大小与学习率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqqfos/d_batch_size_vs_learning_rate/</link>
      <description><![CDATA[关于最佳模型性能的最佳批次大小有两种观点：  较小，大约 32。 无关紧要，因此使用尽可能最大的批次大小来最大限度地缩短训练时间。  有大量资料支持这两种理论。以下几点表明小批量是最好的：  最佳性能始终是在 m=2 至 m=32 之间的小批量大小下获得，这与近期主张使用数千的小批量大小的研究形成鲜明对比。 重新审视深度神经网络的小批量训练 我们的结果得出结论，较大的批量大小通常不会实现高精度，并且使用的学习率和优化器也会产生重大影响。降低学习率和减小批量大小将使网络训练得更好，尤其是在微调的情况下。 批量大小对卷积神经网络在组织病理学数据集上的通用性的影响 使用大型小批量进行训练对您的健康有害。更重要的是，这对您的测试错误不利。朋友不会让朋友使用大于 32 的小批量。 Yann LeCun  有些人声称它们应该很大：  我们没有发现任何证据表明较大的批次大小会降低样本外性能。 测量数据并行对神经网络训练的影响 一旦考虑到所有这些影响，目前没有令人信服的证据表明批次大小会影响可实现的最大验证性能......批次大小不应被视为验证集性能的可调超参数。 深度学习调优手册  您觉得如何？对于 VGG、ResNet 和 DenseNet 等图像模型，是否对于应使用什么批量大小达成了共识？    提交人    /u/bjourne-ml   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqqfos/d_batch_size_vs_learning_rate/</guid>
      <pubDate>Fri, 27 Sep 2024 15:29:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>