<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Fri, 05 Jul 2024 09:17:08 GMT</lastBuildDate>
    <item>
      <title>[P] 情绪分类与分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvrpbs/p_emotion_classification_analysis/</link>
      <description><![CDATA[大家好， 我想分享我使用 flask 构建的关于机器学习的项目，用户可以在其中表达自己的情感并进行以下分类（悲伤、快乐、爱、愤怒、恐惧、惊讶）。我们使用 CNB 模型进行文本分类，准确率为 88%。 你可以在这里尝试： https://emotionclassification.pythonanywhere.com 注意： 预测可能会遇到意外的表情结果。 源代码：  Github：https://github.com/nordszamora/Emotion-Expression     submitted by    /u/ThePawners   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvrpbs/p_emotion_classification_analysis/</guid>
      <pubDate>Fri, 05 Jul 2024 06:51:05 GMT</pubDate>
    </item>
    <item>
      <title>训练 MNIST 的扩散模型 [P][R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvr4i8/training_a_diffusion_model_for_mnist_pr/</link>
      <description><![CDATA[我学习了 VAE 和扩散模型的理论，并尝试使用 M1 MacBook 在 MNIST 上训练一个基本的扩散模型（以更熟悉这个概念）。几个小时过去了，但没有完成一个 epoch。我知道仅使用 M1 芯片进行训练对于严肃的 DL 来说并不理想。我只是想知道这个速度对于这项任务是否正常，或者我的代码是否有问题。    提交人    /u/mziycfh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvr4i8/training_a_diffusion_model_for_mnist_pr/</guid>
      <pubDate>Fri, 05 Jul 2024 06:12:45 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 寻找真正的无服务器 GPU 服务 – 只需为活动计算时间付费</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvqygu/discussion_looking_for_true_serverless_gpu/</link>
      <description><![CDATA[      我刚刚使用 RunPod 模板之一部署了我的第一个服务，因为它们的“按需实例”措辞听起来很吸引人。然而，我发现自己在没有请求进来的时候被收取了几个小时的费用。真的很失望。我是不是漏掉了什么？我以为“按需”意味着按实际运行时间收费——从收到请求到请求完成——但事实似乎并非如此。下面是我的实例的屏幕截图，不确定我是否做对了... https://preview.redd.it/eicb8sjvanad1.png?width=2770&amp;format=png&amp;auto=webp&amp;s=6a0a25bfea037ca0bc09e19240709cf95a0f290b 我正在寻找有关真正遵循无服务器模型的 GPU 服务的建议，当服务主动处理请求时，我只需支付实际计算时间的费用。例如，我注意到 Modal.com 声称，“您永远不会为闲置资源付费，只需按 CPU 周期支付实际计算时间。” 有人可以推荐类似的服务或详细解释这些真正的无服务器 GPU 解决方案的工作原理吗？我不想再误解另一项服务了。 提前感谢您的帮助！    提交人    /u/tonyabracadabra   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvqygu/discussion_looking_for_true_serverless_gpu/</guid>
      <pubDate>Fri, 05 Jul 2024 06:01:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何正确地微调和嵌入模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvpgow/d_how_to_finetune_and_embedding_model_correctly/</link>
      <description><![CDATA[我正在尝试开发一种能够理解一些印度菜肴的嵌入模型。 我在三元组损失上对基本 ber 模型进行了微调。遗憾的是，我的所有嵌入都收敛到单个嵌入或几乎相同的嵌入 我创建了一个三元组 &lt;anchor、positive 和 negative&gt; 示例（鸡肉咖喱、黄油鸡、印度奶酪饭）的数据集，大约有 1000 万个这样的三元组。 我想问一下是否有人对如何解决这个问题有什么建议？ 我必须尝试的一些事情： 我将实现的只是解冻 bert 网络的一些层。  此外，使用 InfoNCE 损失会导致一些嵌入学习，但我们有一个评估设置，它从我的目录中检索最接近的菜肴并要求 gpt 将它们标记为相关/不相关。    提交人    /u/higgsboson12   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvpgow/d_how_to_finetune_and_embedding_model_correctly/</guid>
      <pubDate>Fri, 05 Jul 2024 04:26:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] Grad-CAM 医学成像可视化问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvkg4j/r_problems_with_gradcam_visualization_for_medical/</link>
      <description><![CDATA[嗨，我在灰度胸部热图数据集上训练了一些 ImageNet 模型来检测异常后，使用了 grad-CAM 可视化。但是，几乎所有网络都关注无关特征，如手臂、肩膀、胸部下方等，除了相关区域（胸部）之外的所有区域。我甚至尝试过裁剪图像，但效果并不明显，因为它仍然关注随机点。我们如何才能强制模型关注胸部？此外，尽管我获得了很高的准确率，但模型关注无关特征（如 Grad-CAM 所见）这一事实是否会使我的结果无效？  更新：对于一个模型，在第 5 个训练阶段，它实际上显示了比第 10 个训练阶段更相关的可视化（胸部区域）……不确定发生了什么    由    /u/Low-Literature-9699  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvkg4j/r_problems_with_gradcam_visualization_for_medical/</guid>
      <pubDate>Thu, 04 Jul 2024 23:37:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 CV 从无声吉他视频中重建音乐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvjg3x/p_music_reconstruction_from_silent_guitar_video/</link>
      <description><![CDATA[大家好， 最近，我开始了一个小项目/冒险。使用某人弹奏原声吉他的无声视频，我想使用 CV 尽可能好地重建当时正在演奏的音乐。我的想法如下：首先，我将使用 YoloV9 之类的模型来提取指板。这将被输入到 ViT 或其他网络中，以对视频中在时间 t 正在演奏的音符进行分类。然后，我想将音符列表输入到网络并制作一段连续的（希望是）音乐。到目前为止，我一直在考虑使用 GAN 或 MelodyDiffusion 来生成音乐部分。 您知道我可以在我的项目中使用的其他模型 / 架构吗？ 提前致谢。    提交人    /u/dduka99   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvjg3x/p_music_reconstruction_from_silent_guitar_video/</guid>
      <pubDate>Thu, 04 Jul 2024 22:46:46 GMT</pubDate>
    </item>
    <item>
      <title>[N] Moshi 是首款向所有人开放的语音人工智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvc2no/n_moshi_very_first_voiceenabled_ai_openly/</link>
      <description><![CDATA[以下是 主题演讲视频 和 新闻稿，来自 Kyutai 实验室 该模型的延迟非常低，并且能够（目前为英文）进行非常自然的对话（限制为 5 分钟）。您可以从实验室网站在线试用（欧盟和美国版本）。 Moshi 背后的技术将按照新闻稿中所述稍后开放：  借助 Moshi，Kyutai 打算为人工智能的开放研究和整个生态系统的发展做出贡献。模型的代码和权重将很快免费共享，这对于此类技术而言也是前所未有的。它们将对该领域的研究人员和从事语音产品和服务的开发人员都很有用。因此，可以根据需要深入研究、修改、扩展或专门研究该技术。社区将能够扩展 Moshi 的知识库和事实性，而这些目前在这种轻量级模型中是故意限制的，同时利用其无与伦比的语音交互功能。     提交人    /u/jartock   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvc2no/n_moshi_very_first_voiceenabled_ai_openly/</guid>
      <pubDate>Thu, 04 Jul 2024 17:14:12 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中的似然计算[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvbzrh/likelihood_computation_in_diffusion_models_p/</link>
      <description><![CDATA[我目前正在研究扩散模型（主要是本文 (Song et al.)和本文 (Song et al.)中涉及的 SDE 方法），我对这个关于似然计算的陈述很好奇：他们指出，为了获得生成数据 $log(q_\theta(y))$ 的精确似然，需要依赖概率流 ODE，它具有与用于训练的 SDE 相同的边际，因为 SDE 似然性不易处理。 问题是我不明白为什么：逆 SDE 的每一步都相当于对数据应用与 ODE 几乎相同的变换，只是我们还添加了一些布朗噪声： https://preview.redd.it/es​​5l2ybuajad1.png?width=758&amp;format=png&amp;auto=webp&amp;s=76e189e4c529c49210fed98d0b7cf6787e445032 为了计算似然性，我们想知道每一步中 $yt$ 和 $y\{t+dt}$ 之间变换的雅可比矩阵，对我来说这在 SDE 中似乎是可行的，因为布朗运动只是一些高斯运动噪声不涉及 $y_t$（但我认为这就是我对 SDE 的理解不足的地方）。 这里有人能解释一下这个推理中的问题吗？    提交人    /u/Antoine_m8   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvbzrh/likelihood_computation_in_diffusion_models_p/</guid>
      <pubDate>Thu, 04 Jul 2024 17:10:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 文本分类方面面临的最大挑战是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvaveo/d_what_are_your_biggest_challenges_with_text/</link>
      <description><![CDATA[^ 对于那些训练文本分类模型的人来说，您在文本分类方面面临的最大挑战是什么？    提交人    /u/Different-General700   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvaveo/d_what_are_your_biggest_challenges_with_text/</guid>
      <pubDate>Thu, 04 Jul 2024 16:22:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于模型校准和 OOD 检测来说，sigmoid 是否比 softmax 更好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dv40jw/d_is_sigmoid_better_than_softmax_for_model/</link>
      <description><![CDATA[大家好！这个问题困扰了我好几天。 假设我们有一个二元分类任务，标准方法是在神经网络的末端使用 S 形激活函数，假设我们有一个密集层，末端只有一个神经元。但是，如果我们忽略计算方面，我们也可以使用 softmax 激活函数，然后在最后一层有两个神经元而不是一个。我的问题是，与 softmax 相比，S 形激活函数是否为模型校准和 OOD 检测能力带来了优势？ 我在文献中找不到任何可以证明或否认这个问题的内容。我发现的唯一问题与 softmax 激活带来的过度自信有关，而且在某些情况下，具有 2 个类别的 softmax 在某种程度上等同于 sigmoid，但没有考虑到 softmax 的拉动效应以及我们使用两个神经元而不是一个神经元的事实。 我的理论是，我确实相信这种差异会影响 OOD 检测和校准：  具有交叉熵的 Softmax 将两个类别的分数推开，导致两个类别分离。因此，激活的特征在某种意义上将是相反的。还因为您有两个神经元作为输出而不是一个，它们在计算梯度时具有相反的导数符号。 但是，使用 sigmoid 则不会出现这种情况。当然，您确实存在一定的分离（假设一个类有负的 logit，另一个有正的 logit），但您只能根据两个类中的一个来更新权重，而不是两个。 因此，使用 softmax，您将推动网络对一个类具有负值，对另一个类具有正值。而使用 sigmoid，您只会推动网络具有根据特定类的值，而不必触及与另一个类相关的任何特征。 Softmax：网络经过训练可为两个神经元产生“冲突”分数，从而将两个类分开。这导致 logit 很少彼此接近。因此，不鼓励使用接近 0 的 logit，从而导致神经元更频繁地被激活。 Sigmoid：更有可能什么都没有被激活。 如果网络不知道某个东西是什么，那么您的 logit 将接近 0，因为几乎没有任何东西被激活。因此，OOD 样本的得分将接近 0.5。    这有意义吗？您是否知道一些可以证实或否认我所说内容的论文或数学证明？    提交人    /u/Doch88   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dv40jw/d_is_sigmoid_better_than_softmax_for_model/</guid>
      <pubDate>Thu, 04 Jul 2024 10:47:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 杰出机器学习工程师的稀有技能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dv2thm/d_rare_skills_of_execptional_ml_engineers/</link>
      <description><![CDATA[大家好，ML 社区！ 无论你的头衔是什么（DS/工程经理/工程总监/ML 工程...），你工作场所中的 ML 工程师拥有哪些罕见技能，使他们真正从其他人中脱颖而出（在软技能和硬技能领域）？如果可能的话，请说明你的立场——不同角色如何看待这个话题可能会很有趣。 谢谢！    提交人    /u/Avistian   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dv2thm/d_rare_skills_of_execptional_ml_engineers/</guid>
      <pubDate>Thu, 04 Jul 2024 09:29:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 人工智能系统中数据转换的分类法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dv0kgr/r_taxonomy_for_data_transformations_in_ai_systems/</link>
      <description><![CDATA[我们花了几年时间撰写了刚刚在 SIGMOD&#39;24 上发表的特征存储论文 (https://dl.acm.org/doi/10.1145/3626246.3653389)，其主要贡献之一是 AI 的数据转换分类法。 分类法的见解是，AI 系统中并非所有数据转换都是等效的。一些数据转换（聚合、分箱、数据压缩）产生的特征可以在许多模型中重复使用。一些数据转换（特征编码/缩放、LLM 文本编码）特定于一个模型。实时 AI 系统中的一些数据转换只需要在请求时可用的数据。 由于研究论文非常密集，这里有一个更长、更具教学性的分类法版本： https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems    提交人    /u/jpdowlin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dv0kgr/r_taxonomy_for_data_transformations_in_ai_systems/</guid>
      <pubDate>Thu, 04 Jul 2024 06:57:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] GraphVision - 使用 Graph Vision 查询执行图像分割</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1duzfrr/r_graphvision_perform_image_segmentation_with/</link>
      <description><![CDATA[      大家好，我一直在研究这个库“graphvision”，想和大家分享最终产品。 GraphVision 简化了图像分割和可视化的过程，还创建了连接图像内各个部分的拓扑图。此图可用于执行视觉查询，以将一个对象定位在另一个对象附近，并通过视觉语言模型与图进行通信。我希望你们会觉得它有用，如果你们可以考虑给这个仓库加星或者提供一些反馈，我将不胜感激。 在 GitHub 上查看：https://github.com/mishra-18/GraphVision 使用视觉查询进行图像分割    提交人    /u/Kian5658   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1duzfrr/r_graphvision_perform_image_segmentation_with/</guid>
      <pubDate>Thu, 04 Jul 2024 05:46:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能/机器学习中哪些问题似乎无人谈论？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dup0vs/d_what_are_issues_in_aiml_that_no_one_seems_to/</link>
      <description><![CDATA[我是一名研究人工智能的研究生，我经常遇到很多类似的关于人工智能监管问题的讨论，这些讨论通常涉及对高质量无偏见数据的需求、模型透明度、充分治理或其他类似但相关的主题。毫无疑问，所有这些都是重要而复杂的问题。 然而，我很好奇，是否有人在实践、个人或研究经历中遇到过任何不受欢迎或新颖的问题，这些问题通常不包括在人工智能讨论中，但出于某种原因一直困扰着你。 另一方面，是否还存在经常讨论但可能被严重低估的问题？ 我是一个有很多东西要学的学生，如果能得到任何见解或讨论，我将不胜感激。干杯。    提交人    /u/mrstealyoursoulll   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dup0vs/d_what_are_issues_in_aiml_that_no_one_seems_to/</guid>
      <pubDate>Wed, 03 Jul 2024 20:55:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>