<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 21 Apr 2024 03:13:46 GMT</lastBuildDate>
    <item>
      <title>[R] 通过想象、探索和批评实现法学硕士的自我完善</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c97o2q/r_toward_selfimprovement_of_llms_via_imagination/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.12253 摘要：  尽管大型语言模型（LLM）在各种方面具有令人印象深刻的能力任务中，他们仍然在处理涉及复杂推理和计划的场景。最近的工作提出了先进的提示技术以及使用高质量数据进行微调以增强法学硕士推理能力的必要性。然而，这些方法本质上受到数据可用性和质量的限制。有鉴于此，自我纠正和自我学习成为可行的解决方案，采用的策略允许法学硕士改进他们的成果并从自我评估的奖励中学习。然而，法学硕士在自我完善其反应方面的有效性，特别是在复杂的推理和规划任务中，仍然值得怀疑。在本文中，我们引入了用于LLM自我改进的AlphaLLM，它将蒙特卡罗树搜索（MCTS）与LLM结合起来，建立一个自我改进循环，从而在无需额外注释的情况下增强LLM的能力。 AlphaLLM 从 AlphaGo 的成功中汲取灵感，解决了将 MCTS 与 LLM 相结合以实现自我提升的独特挑战，包括数据稀缺、语言任务的巨大搜索空间以及语言任务中反馈的主观性。 AlphaLLM 由即时合成组件、专为语言任务量身定制的高效 MCTS 方法以及用于精确反馈的三个批评模型组成。我们在数学推理任务中的实验结果表明，AlphaLLM 在无需额外注释的情况下显着增强了法学硕士的性能，显示了法学硕士自我改进的潜力。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c97o2q/r_toward_selfimprovement_of_llms_via_imagination/</guid>
      <pubDate>Sun, 21 Apr 2024 02:56:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] KNN - 决策树分类器 需要作业帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c96y2d/d_knn_decision_tree_classifiers_need_help_on_an/</link>
      <description><![CDATA[嗨！你好吗 ？  我是机器学习初学者，正在做我的第一份作业。我没有什么问题。 我真的无法承受不及格的后果，而且我对自己的工作非常没有信心！ :) 我将非常感谢那个愿意阅读（并帮助我纠正）我的作品的人！如果你有经验但对我有帮助的话应该会很快🫡 我也在研究KNN模型，而且我基本上无法获得准确度分数😭即使使用Collab我也有错误人工智能帮助。    由   提交 /u/Junwiss   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c96y2d/d_knn_decision_tree_classifiers_need_help_on_an/</guid>
      <pubDate>Sun, 21 Apr 2024 02:15:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] Tango 2：通过直接偏好优化来调整基于扩散的文本到音频的生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c95izw/d_tango_2_aligning_diffusionbased_texttoaudio/</link>
      <description><![CDATA[自动生成的成对偏好数据和 DPO 对齐改进了文本到音频的生成。 代码和数据集：https://github.com/declare-lab/tango 论文：https://arxiv.org/abs/2404.09956 模型：https://huggingface.co/declare-lab/tango2   由   提交 /u/sgpfc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c95izw/d_tango_2_aligning_diffusionbased_texttoaudio/</guid>
      <pubDate>Sun, 21 Apr 2024 01:00:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] OSS 工具可在几秒钟内将您的 Python 代码扩展到数千个 GPU 和 CPU</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8yvsn/p_oss_tool_that_scales_your_python_code_to/</link>
      <description><![CDATA[嘿，机器学习社区， 我想分享我正在构建的 OSS 开发人员工具。我很想获得一些反馈并听取那些之前维护过大型开源项目的人的意见。 我正在构建 Burla  这是一个 python 包，可以轻松地在（很多）其他计算机上运行代码。由于 Burla 最适合处理令人尴尬的并行工作负载，因此我将重点放在数据准备上，因此使用案例包括清理、格式化/解析、标记文本数据、数据编码和压缩标记。 Burla 是。 ..  免费开源软件 可通过一个命令安装在云中 具有一个函数和两个参数的 python 包 在 1 秒内扩展到数千个虚拟机 将代码部署到任何硬件 (GPU) 和任何软件环境 (Docker) 一个可以正常工作的工具。 Burla 自动同步包、重新引发异常并流回 stdout/stderr  很高兴回答任何和所有问题！这是我们的网站   由   提交/u/Ok_Post_149   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8yvsn/p_oss_tool_that_scales_your_python_code_to/</guid>
      <pubDate>Sat, 20 Apr 2024 19:54:53 GMT</pubDate>
    </item>
    <item>
      <title>[D]leetcode 在机器学习中有多重要？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8ygzl/d_how_important_is_leetcode_in_ml/</link>
      <description><![CDATA[我最近面试了一位应用数据科学家，面试过程是这样的： - 1x ML 面试 - 3x Leetcode 面试 - 1x 高级系统设计面试 leetcode对于ML/DS从业者的实际工作有多重要？ 3 个 leetcode 问题与 1 个 ml 问题有那么重要吗？ 当我在准备面试时，我只是觉得我在浪费时间做 leetcode，而我本可以在 ML 的其他领域甚至其他领域提升技能。 K8s、cuda 或数据工程等技术技能。  我有兴趣了解其他人对此的看法。   由   提交/u/Amgadoz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8ygzl/d_how_important_is_leetcode_in_ml/</guid>
      <pubDate>Sat, 20 Apr 2024 19:36:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] Meta 的 H100 数据代表其根据 2024 年 2 月 1 日公司财报电话会议购买的 H100。不包括另外 250,000 个 H100 等值的 GPU。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8ydji/d_metas_h100_figure_represents_its_h100_purchase/</link>
      <description><![CDATA[   /u/ewelumokeke  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8ydji/d_metas_h100_figure_represents_its_h100_purchase/</guid>
      <pubDate>Sat, 20 Apr 2024 19:32:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 招聘时我应该在多大程度上重视传统机器学习知识？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8xgvp/d_how_much_should_i_emphasize_on_traditional_ml/</link>
      <description><![CDATA[我们正在招聘 nlp 高级机器学习工程师。  过去，我一直依赖标准的过滤问题。但我想知道这对于可能永远不会在项目中使用这些技术的新工程师来说是否不公平，以及这是否不再衡量工程师现在所做的事情。 我们确实有工艺演示的回声，其中我们询问相关的技术和技术问题。  但想听听关于初始过滤的事情，我想知道我是否应该停止询问： - 偏差与方差以及类似的训练“统计”概念 - 主题建模技术和类似的“旧 nlp” - 引导技术。 bagging 和类似技术 - 熵、杂质和其他“信息论”问题。  我们的团队无法达成共识。希望您的想法   由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8xgvp/d_how_much_should_i_emphasize_on_traditional_ml/</guid>
      <pubDate>Sat, 20 Apr 2024 18:54:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 以 JSON 对象的形式从 PDF 文件中提取数据。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8w1mq/d_extract_data_from_pdf_file_in_the_form_of_json/</link>
      <description><![CDATA[      https://preview.redd.it/q93ittqnaovc1.png?width=777&amp;format=png&amp;auto=webp&amp;s=aec5c1767690bd3 269ba9e601623e4d85378fd37 这是我从 Pdf 文件中捕获的图像，一方面，pdf 文本是可选择的，就像我也可以选择标题和表格中写入的所有文本一样。我尝试了几种技术： 1：使用 llama-index-multi-modal-llms-openai (GPT4-API) 的 MultiModalVectorStoreIndex，首先使用 OCR 将 PDF 转换为图像，然后然后从 PDF 中检索表格，但有一件事我需要定义 pdf 的页数，然后它将准确地获取包含表格的页面，但你知道如果在 pdf 中我们有两个包含表格，并且我定义了 3 个阈值，那么它会重复一页，反之亦然。 2：我也尝试过table transfomer LLM，但结果不好。 3：使用过Tabula python库，但你知道管理阅读这个库的文本非常乏味。 那么有没有任何智能AI工具或LLM可以在这里轻松使用，并且可以将任何pdf（无论包含表格的页数）转换为JSON。 提前致谢，任何建议或帮助都会更加感激。   由   提交/u/Ghulam_Nabi   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8w1mq/d_extract_data_from_pdf_file_in_the_form_of_json/</guid>
      <pubDate>Sat, 20 Apr 2024 17:54:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] ControlNet++：通过高效的一致性反馈改进条件控制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8unjk/r_controlnet_improving_conditional_controls_with/</link>
      <description><![CDATA[ControlNet++：通过高效的一致性反馈改进条件控制 ​ 增强可控性对于文本到图像的扩散模型，ControlNet 等现有工作结合了基于图像的条件控制。在本文中，我们揭示了现有方法在生成与图像条件控制一致的图像方面仍然面临重大挑战。为此，我们提出了 ControlNet++，这是一种新颖的方法，通过显式优化生成图像和条件控制之间的像素级循环一致性来改进可控生成。具体来说，对于输入条件控制，我们使用预训练的判别奖励模型来提取生成图像的相应条件，然后优化输入条件控制和提取条件之间的一致性损失。一种简单的实现是从随机噪声生成图像，然后计算一致性损失，但这种方法需要存储多个采样时间步长的梯度，从而导致大量的时间和内存成本。为了解决这个问题，我们引入了一种有效的奖励策略，通过添加噪声故意干扰输入图像，然后使用单步去噪图像进行奖励微调。这避免了与图像采样相关的大量成本，从而可以更有效地进行奖励微调。大量实验表明ControlNet++显着提高了各种条件控制下的可控性。例如，在分割掩模、艺术线条边缘和深度条件方面，它比 ControlNet 分别提高了 7.9% mIoU、13.4% SSIM 和 7.6% RMSE。 ​ ​ p&gt; 论文：https://arxiv.org/pdf/2404.07987.pdf ​ 项目网站：https://liming-ai.github.io/ControlNet_Plus_Plus/  ​ 代码：https://github。 com/liming-ai/ControlNet_Plus_Plus ​ HuggingFace 演示：https://huggingface.co/spaces/limingcv/ControlNet-Plus-Plus   由   提交/u/Extension-Sun1816    reddit.com/r/MachineLearning/comments/1c8unjk/r_controlnet_improving_conditional_controls_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8unjk/r_controlnet_improving_conditional_controls_with/</guid>
      <pubDate>Sat, 20 Apr 2024 16:54:26 GMT</pubDate>
    </item>
    <item>
      <title>[P] Groq 上的 llama-3-70b 和代码解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8uiwi/p_llama370b_on_groq_with_code_interpreting/</link>
      <description><![CDATA[       由   提交/u/mlejva  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8uiwi/p_llama370b_on_groq_with_code_interpreting/</guid>
      <pubDate>Sat, 20 Apr 2024 16:48:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从第一原理解释多模态神经网络的简史</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8sydf/d_the_short_history_of_multimodal_neural_network/</link>
      <description><![CDATA[      来自我的 YT 频道的视频解释多模态机器学习的核心概念及其过去几年的演变。   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8sydf/d_the_short_history_of_multimodal_neural_network/</guid>
      <pubDate>Sat, 20 Apr 2024 15:40:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一张让你感觉自己老了的幻灯片</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8kuef/d_a_slide_which_makes_you_feel_old/</link>
      <description><![CDATA[       由   提交 /u/xiikjuy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8kuef/d_a_slide_which_makes_you_feel_old/</guid>
      <pubDate>Sat, 20 Apr 2024 08:20:34 GMT</pubDate>
    </item>
    <item>
      <title>[N] 何凯明关于表征学习的深度学习架构讲座</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8d5m1/n_kaiming_hes_lecture_on_dl_architecture_for/</link>
      <description><![CDATA[https://youtu.be/D_jt-xO_RmI 非常好的讲座，DL 历史架构进展的最高信噪比。   由   提交 /u/lkphuc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8d5m1/n_kaiming_hes_lecture_on_dl_architecture_for/</guid>
      <pubDate>Sat, 20 Apr 2024 00:57:29 GMT</pubDate>
    </item>
    <item>
      <title>您认为强化学习仍然有效吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c87bh4/do_you_think_reinforcement_learning_still_got_it_d/</link>
      <description><![CDATA[最近我听到很多人说强化学习本身多年来没有任何改进（也许 alphago 是最后的大事）。  而人工智能的其他领域已经出现了许多 SOTA 架构，例如用于基于序列的任务的“Transformers”以及“ResNet”、“Diffusers”和“SOTA”架构。 “VAE”类似于计算机视觉任务的架构。 我认为，无论是直接还是间接，强化学习仍然在使用“RLHF”技术的 ChatGPT 和 Claude 等法学硕士背后发挥着至关重要的作用。以及许多其他最新技术，包括自动驾驶汽车和机器人。  我认为这只是这个领域的一个寒冷的冬天，在未来几年里很快就会找到最先进的建筑（或者这就是我所希望的） 你的想法是什么想法？ 🤔   由   提交/u/cyb0rg14_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c87bh4/do_you_think_reinforcement_learning_still_got_it_d/</guid>
      <pubDate>Fri, 19 Apr 2024 20:40:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>