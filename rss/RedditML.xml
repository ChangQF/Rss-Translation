<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 02 Jan 2024 12:24:42 GMT</lastBuildDate>
    <item>
      <title>[D] 如何创建自定义数据集来训练 TrOCR 模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wnqsp/d_how_to_create_custom_dataset_to_train_a_trocr/</link>
      <description><![CDATA[嗨，我正在为我的母语开发 TrOCR，TrOCR 的工作方式是我们需要向它提供按行裁剪的图像逐行或逐句或逐字。所以，我想制作一个工具来为其创建数据集，但我找不到任何解决方案。有没有任何工具或最佳方法来制作数据？    由   提交 /u/HamaWolf   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wnqsp/d_how_to_create_custom_dataset_to_train_a_trocr/</guid>
      <pubDate>Tue, 02 Jan 2024 11:56:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] Stella Nera：利用基于近似矩阵乘法的无乘数 DNN 加速实现 161 TOp/s/W</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wnerq/r_stella_nera_achieving_161_topsw_with/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2311.10207 代码：https://github .com/joennlae/halutmatmul 摘要：  从经典 HPC 到深度学习，MatMul 是当今计算的核心计算。最近的 Maddness 方法通过使用基于散列版本的乘积量化 (PQ) 索引到查找表 (LUT) 来近似 MatMul，无需进行乘法。 Stella Nera 是首款 Maddness 加速器，与在相同的技术。哈希函数是一个决策树，它允许高效的硬件实现，因为乘法累加操作被决策树传递和 LUT 查找所取代。整个 Maddness MatMul 可以分解为多个部分，允许使用小型计算单元和内存进行有效实现，使其达到极高的效率，同时保持对 MatMul 任务的普遍适用性。 在商用 14 纳米技术中并扩展到 3 纳米，我们使用 ResNet9 实现了 161 TOp/s/W @0.55V 的能效，并且在 CIFAR-10 上的 Top-1 精度超过 92.5%。     由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wnerq/r_stella_nera_achieving_161_topsw_with/</guid>
      <pubDate>Tue, 02 Jan 2024 11:34:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无需昂贵的再培训即可显着提高人工智能能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wn049/r_ai_capabilities_can_be_significantly_improved/</link>
      <description><![CDATA[      论文： https://arxiv.org/abs/2312.07413 博客文章：https://epochai.org/blog/ai-capability-can-be-significantly-improved-without-expense-retraining 摘要：  通过应用“训练后增强”技术，无需昂贵的再训练即可显着改进最先进的人工智能系统经过初步培训（例如微调系统以使用网络浏览器）。我们回顾了最近的培训后增强功能，将其分为五种类型：工具使用、提示方法、脚手架、解决方案选择和数据生成。不同的增强功能可以提高不同任务的性能，因此很难比较它们的重要性。因此，我们将不同增强功能的改进转化为一种通用货币，即计算等效增益：需要多少额外的训练计算才能将性能提高与增强功能相同的量。我们的非实验工作表明，训练后增强具有显着的好处：大多数调查的增强将训练计算的基准性能提高了 5 倍以上，有些提高了 20 倍以上。训练后增强的开发成本相对较低：微调成本通常小于原始训练成本的 1%。管理有能力的训练后增强功能的开发可能具有挑战性，因为前沿模型可以由广泛的参与者来增强。  ​ https://preview.redd.it/3sga07vie0ac1.png?width=3088&amp; ;format=png&amp;auto=webp&amp;s=a76f3cfc99de473fa357e17e7b85e3912464fb39   由   提交 /u/APaperADay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wn049/r_ai_capabilities_can_be_significantly_improved/</guid>
      <pubDate>Tue, 02 Jan 2024 11:09:19 GMT</pubDate>
    </item>
    <item>
      <title>[D]了解deepspeed 3配置</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wmred/d_understanding_deepspeed_3_configuration/</link>
      <description><![CDATA[所以我想在我的自定义数据集上进行全参数 fintune Mistra 7b 模型 我可以访问 4 个 A10G gpu，它们有 96 GB总共，也许8个A100G 40GB，总共320 GB 使用deepspeed 3，据我所知，它可以分散多个GPU上的训练 我正在尝试使用此代码这里：trainer.py在8个A100 80 GPU上进行了测试（我不知道没有） 但是深度速度的配置在这里： compute_environment: LOCAL_MACHINE debug: false deepspeed_config: deepspeed_multinode_launcher: standard&lt; br /&gt;gradient_accumulation_steps: 8offload_optimizer_device:noneoffload_param_device:nonezero3_init_flag:truezero3_save_16bit_model:truezero_stage:3distributed_type:DEEPSPEED /&gt; downcast_bf16: &#39;no&#39; machine_rank: 0 main_training_function: main mix_ precision: &#39;bf16&#39; num_machines: 1 num_processes: 8 rdzv_backend: static same_network: true tpu_env: [] tpu_use_cluster: false tpu_use_sudo: false use_cpu: false  我可以更改其中哪些进行我的训练？  如果有任何关于此的教程或解释，我将不胜感激 提前致谢   由   提交 /u/MustafaAlahmid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wmred/d_understanding_deepspeed_3_configuration/</guid>
      <pubDate>Tue, 02 Jan 2024 10:54:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 准备我的第一次编程面试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wl7ct/d_preparing_my_first_coding_interview/</link>
      <description><![CDATA[我接受了一家初创公司首席技术官的面试，职位是应用科学家，他告诉我，面试时会涉及“传统问题”。关于算法、数据结构、计算机科学问题和渐近复杂性。这是我第一次正式的 ML 面试，我使用的是“破解编码面试”准备书籍，加上 https://runestone.academy/ns/books/published/pythonds3/index.html html 以获得更 Pythonic 的视角（尽管我认为该网站在某些部分过于具体）。 您认为这足够好吗？有什么建议吗？   由   提交 /u/Al_Levin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wl7ct/d_preparing_my_first_coding_interview/</guid>
      <pubDate>Tue, 02 Jan 2024 09:10:17 GMT</pubDate>
    </item>
    <item>
      <title>[研究]我该不该参加会议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wk7y2/research_should_i_attend_the_conference_or_not/</link>
      <description><![CDATA[大家好。 最近，我的会议论文在意大利罗马举行的 VISAPP&#39;24 会议上被接受2024 年 2 月 27 日至 29 日。我住在印度，出身非常贫穷。然而，这是我第一次完成这样的壮举。 亲自参加会议将花费我约 200,000 印度卢比（印度卢比）。由于我没有足够的钱，我不能独自参加会议。我已经申请了各种旅行补助金，例如微软和谷歌旅行补助金，但所有的努力都是徒劳的。 你能告诉我是否值得花在上面吗？有人可以提供一些我可以申请的旅行补助金的来源吗？   由   提交 /u/Successful-Isopod119    reddit.com/r/MachineLearning/comments/18wk7y2/research_should_i_attend_the_conference_or_not/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wk7y2/research_should_i_attend_the_conference_or_not/</guid>
      <pubDate>Tue, 02 Jan 2024 08:03:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 面向数据科学家的基于 NLP 的数据工程工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wjzhu/p_nlp_based_data_engineering_tool_for_data/</link>
      <description><![CDATA[大家好， 我是 AskOnData 的联合创始人。我们正在开发并即将发布基于 NLP（聊天机器人）的数据工程工具（由 ML 提供支持）。 寻求有关测试版/试点的帮助以获得关键反馈。如果有任何帮助，我将非常感激。 我们正在尝试解决的问题/我们产品的 USP  不需要技术知识，只需键入并创建数据管道 零学习曲线 数据管道的开发速度超快。以打字速度进行数据管道 不依赖数据工程。  一切都是我们开发的，不使用任何第三方软件，以确保适当的数据安全。   p&gt; 网站：https://askondata.com/ 我希望我没有违反 Reddit 子版块的任何规则。如果是的话，请不要阻止我，删除帖子并告诉我。谢谢   由   提交 /u/nikhelical   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wjzhu/p_nlp_based_data_engineering_tool_for_data/</guid>
      <pubDate>Tue, 02 Jan 2024 07:48:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于将 TF 模型转换为 TensorRT-LLM 有什么想法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wipqe/p_any_ideas_on_converting_tf_models_into/</link>
      <description><![CDATA[目前，我正在考虑 TensorFlow -&gt;火炬-&gt;拥抱脸 -&gt; TensorRT 转换... 但是，我的意思是，它需要比我预想的更多的工作..   由   提交 /u/Dry_Cheesecake_8311   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wipqe/p_any_ideas_on_converting_tf_models_into/</guid>
      <pubDate>Tue, 02 Jan 2024 06:28:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些免费的机器学习和深度学习在线中级课程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wdb22/d_what_are_some_free_online_intermediate_courses/</link>
      <description><![CDATA[我希望找到一些免费的在线资源，提供中级机器学习和深度学习的课程   由   提交/u/Fair_Judge_5907   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wdb22/d_what_are_some_free_online_intermediate_courses/</guid>
      <pubDate>Tue, 02 Jan 2024 01:52:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于 OpenAI Whisper 的数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wd64j/d_dataset_used_for_openai_whisper/</link>
      <description><![CDATA[有没有人遇到过或猜测过 OpenAI 的 68 万小时数据（后来使用 Whisper-v3 的数据为 500 万小时）来自哪里？火车耳语？   由   提交 /u/gggerr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wd64j/d_dataset_used_for_openai_whisper/</guid>
      <pubDate>Tue, 02 Jan 2024 01:46:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] LARP：开放世界游戏的语言代理角色扮演</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18w3am0/r_larp_languageagent_role_play_for_openworld_games/</link>
      <description><![CDATA[项目页面： https://miao-ai-lab.github.io/LARP/ 论文： https://miao-ai-lab.github.io/LARP/static/LARP.pdf 代码： https://github.com/MiAO-AI-Lab/LARP 摘要：  语言代理在规定的环境和短暂的时间内表现出了令人印象深刻的解决问题的能力。然而，随着开放世界模拟的复杂性不断发展，迫切需要能够灵活适应复杂环境并持续保持长期记忆以确保连贯行动的智能体。为了弥合语言代理和开放世界游戏之间的差距，我们引入了角色扮演语言代理（LARP），其中包括一个包含记忆处理和决策助理的认知架构，一个具有反馈驱动的可学习动作的环境交互模块空间，以及促进各种个性对齐的后处理方法。 LARP 框架完善了用户和代理之间的交互，预定义了独特的背景和个性，最终增强了开放世界环境中的游戏体验。此外，它还强调了语言模型在娱乐、教育和各种模拟场景等一系列领域的多样化用途。    由   提交 /u/FreeKingBoo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18w3am0/r_larp_languageagent_role_play_for_openworld_games/</guid>
      <pubDate>Mon, 01 Jan 2024 18:42:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 面向任务的法学硕士系统设计中的可能性暴政：范围界定调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18w09hn/r_the_tyranny_of_possibilities_in_the_design_of/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18w09hn/r_the_tyranny_of_possibilities_in_the_design_of/</guid>
      <pubDate>Mon, 01 Jan 2024 16:29:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 赚取被动收入的数据科学家，你是做什么的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vxts1/d_data_scientists_who_made_a_passive_income_what/</link>
      <description><![CDATA[除了朝九晚五的常规工作之外，已成功建立被动收入来源的数据科学家和机器学习人员：您是如何做的以及做了什么？我真的很好奇我们领域的专业人士利用他们的技能来产生额外收入的不同方式。 无论是简单的机器学习应用程序、微服务、独特的服务产品、自由项目还是任何其他项目方法，我很想听听你的故事。你是怎么想到这个主意的？您如何平衡这与您的全职工作？您面临着什么样的挑战？ 编辑：by“被动”我的意思并不一定是字面上的意思——副业也很有趣。真正通过 DS 能力获得收入的东西。   由   提交 /u/Fendrbud   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vxts1/d_data_scientists_who_made_a_passive_income_what/</guid>
      <pubDate>Mon, 01 Jan 2024 14:29:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们没有更有趣的激活函数？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vwpk2/d_why_dont_we_have_more_interesting_activation/</link>
      <description><![CDATA[没有太多证据表明生物神经网络具有不寻常的激活函数（例如 mod n），但有如此多的连接，其连接方式可能不同我们做激活函数和注意力，谁能知道？我不认为极强的负抑制权重可以起到这个作用；拥有一个全有或全无的 mod 函数是不同的，它可能无法在负权重梯度上学习。当我在 2015 年被人工神经网络捕获时，原因是像随机神经元被移除（像人类一样！）这样的属性，这种技术本质上（修剪）类似于混沌工程的非智能随机形式。那么是否有可能，就像我们拥有使神经网络中的计算更加有效的技术一样，我们可以应用更多作为数学捷径的技术？一切都必须有梯度吗？ 这个帖子让我思考：是否有很多研究尝试将不寻常的激活函数与合理大小或基于激活的网络结合起来？对此有任何直觉吗？   由   提交/u/Lumpy-Ad2724  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vwpk2/d_why_dont_we_have_more_interesting_activation/</guid>
      <pubDate>Mon, 01 Jan 2024 13:25:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>