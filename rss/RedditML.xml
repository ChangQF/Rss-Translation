<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 23 Jan 2024 03:14:35 GMT</lastBuildDate>
    <item>
      <title>[D]大型数据集层次聚类。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19de8ak/dlarge_dataset_hierarchical_clustering/</link>
      <description><![CDATA[我必须对这个包含超过 430000 × 60 个样本的数据集执行分层聚类，但对于我的硬件规格（32 GB RAM）来说这似乎是不可能的。所以我尝试在具有 51 GB RAM 的 Colab Pro 上进行此操作，但即使在那里，这似乎也是不可能的。我尝试随机抽样，并在聚类之前对数据进行 PCA，虽然执行了，但 NMI 得分仍然只有 30%。我需要深入研究错误分类。我该怎么做才能获得更高的 NMI 分数？   由   提交 /u/StatusPending5512   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19de8ak/dlarge_dataset_hierarchical_clustering/</guid>
      <pubDate>Tue, 23 Jan 2024 02:55:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 3d RL 模拟如何工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ddujn/d_how_do_3d_rl_simulations_work/</link>
      <description><![CDATA[不知道这个问题是否幼稚，但我一直在看一些旧论文/博客，OpenAI 捉迷藏，或者谷歌代理使用模拟的房间和物体或山丘之王进行工作。每个机器人还总是有一只带有 3D 图的手臂，可以抓取立方体或其他东西。所有这些是如何运作的？人们如何同时运行游戏和 PPO？这在云上也可能吗？它们如何加速游戏？ 我发现的一件事是 Unity ML 代理，但我不认为 3D 需要所有的 Unity 膨胀才能工作。 另一方面请注意，我注意到的一件事是它们都使用大约 1000 个 GPU。我可以以较小的规模运行任何东西，或者像 PPO 这样不会导致计算成瘾的 RL 方法吗？   由   提交/u/vatsadev  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ddujn/d_how_do_3d_rl_simulations_work/</guid>
      <pubDate>Tue, 23 Jan 2024 02:36:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 欧洲人工智能法案暂定协议何时正式通过？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dbqvi/d_when_will_the_tentative_agreement_on_the_ai_act/</link>
      <description><![CDATA[一个月前，欧盟就一套具有里程碑意义的人工智能 (AI) 监管规则达成了临时协议，即《人工智能法案》。  虽然该协议仍有待欧洲议会和欧洲理事会正式通过，但最新进展表明《人工智能法案》的某些内容已得到进一步完善。  欧洲人工智能法案暂定协议何时正式通过？   ​   由   提交 /u/Periplokos   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dbqvi/d_when_will_the_tentative_agreement_on_the_ai_act/</guid>
      <pubDate>Tue, 23 Jan 2024 00:54:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您希望看到什么 AI/ML 开源工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19daupj/d_what_aiml_opensource_tool_would_you_love_to_see/</link>
      <description><![CDATA[我正在考虑开发一个免费/开源的 AI/ML 工具，很多人都会觉得有用。  您认为很多人会对哪种很酷、简单的 AI/ML 工具感兴趣？    由   提交/u/Sellagen-DataMarket   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19daupj/d_what_aiml_opensource_tool_would_you_love_to_see/</guid>
      <pubDate>Tue, 23 Jan 2024 00:13:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 复杂网络链路预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19da4gr/p_complex_network_link_prediction/</link>
      <description><![CDATA[复杂网络链接预测是一个 Python 库，它实现了一些主要技术和算法来执行链接预测。  https://github.com/Typing-Monkeys/complex-network-link -预测   由   提交/u/Stunning_Ad_1539   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19da4gr/p_complex_network_link_prediction/</guid>
      <pubDate>Mon, 22 Jan 2024 23:41:30 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以在其回复中隐藏任意不可检测的信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</link>
      <description><![CDATA[ 由   提交/u/LuvIsOurResistance  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</guid>
      <pubDate>Mon, 22 Jan 2024 22:32:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新理论表明聊天机器人可以理解文本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</link>
      <description><![CDATA[文章链接：https://www.quantamagazine.org/new-theory-suggests-chatbots-can-understand-text-20240122/ 链接到论文 1：https://arxiv.org/abs/2307.15936 摘要：  当今人工智能产品的一个主要驱动力是，当参数集和训练语料库扩大时，语言模型中就会出现新的技能。人们对这种现象知之甚少，并且通过基于梯度的训练的数学分析来进行机械解释似乎很困难。当前的论文采用了不同的方法，使用著名的（和经验的）法学硕士缩放定律和简单的统计框架来分析涌现。贡献包括： (a) 一个统计框架，将法学硕士的交叉熵损失与语言任务的基本技能能力联系起来。 (b) 数学分析表明，缩放定律暗示了一种强烈的归纳偏差形式，使得预训练模型能够非常有效地学习。我们非正式地将其称为“弹弓泛化”，因为天真地认为它似乎给出了违反通常泛化理论的技能的能力水平。 (c) 弹弓泛化的一个关键例子，执行涉及 k 元组技能的任务的能力基本上以与基本技能本身的能力相同的规模和速度出现。  Link论文 2：https://arxiv.org/abs/2310.17567 摘要：  随着法学硕士的角色从语言统计建模转变为通用人工智能代理，法学硕士的评估应该如何改变？可以说，人工智能代理的一项关键能力是根据需要灵活组合其所学的基本技能。结合技能的能力在（人类）教育学以及关于涌现现象的论文中发挥着重要作用（Arora &amp; Goyal，2023）。这项工作引入了 Skill-Mix，这是一种衡量组合技能能力的新评估。使用 N 个技能的列表，评估者重复选择 k 个技能的随机子集，并要求法学硕士生成结合该技能子集的文本。由于子集的数量像 Nk 一样增长，因此即使是适度的 k，此评估也很有可能要求法学硕士生成与训练集中的任何文本显着不同的文本。该论文开发了一种方法，用于 (a) 设计和管理此类评估，以及 (b) 使用 GPT-4 以及开放的 LLaMA-2 70B 模型对结果进行自动分级（加上人工抽查）。管理流行聊天机器人的一个版本所得到的结果虽然总体上符合之前的预期，但也包含了令人惊讶的结果。模型能力之间存在相当大的差异，而这些差异并没有通过它们在流行的 LLM 排行榜上的排名来体现（“临时抱佛脚排行榜”）。此外，简单的概率计算表明GPT-4在k＝5上的合理性能暗示超越“随机鹦鹉”性能。行为（Bender 等人，2021），即它以训练期间未曾见过的方式组合技能。我们概述了该方法如何形成基于技能组合的生态系统，对未来模型的人工智能功能进行开放评估。    由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</guid>
      <pubDate>Mon, 22 Jan 2024 21:54:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于文本分类的零样本 OOD</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d5ytn/d_zeroshot_ood_for_text_classification/</link>
      <description><![CDATA[我正在构建一个管道，该管道允许我根据文本是否属于我已经定义的任何类来过滤文本定义。 我觉得一种（尽管很幼稚）方法就是嵌入文本和代表类的文本，并对两者应用距离函数，如果距离超过某个值，则丢弃样本阈值。 这在零样本设置中可行吗？如果是这样，我应该如何计算阈值？如果没有，在零样本设置中可以使用什么（如果有）方法？   由   提交/u/DeezDineros   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d5ytn/d_zeroshot_ood_for_text_classification/</guid>
      <pubDate>Mon, 22 Jan 2024 20:50:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前理论机器学习作为一个领域有什么意义吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</link>
      <description><![CDATA[随着 SOTA 架构不断变化的极快速度，可能的 DL 技术（正则化、所有不同的激活和损失函数）的多样性如下：以及对可解释人工智能相对退居二线的担忧，现在从事理论机器学习工作有什么用处吗？ 大多数 SOTA 架构似乎只是大规模扩展的高级猜测和检查，而且它确实有效就基准性能而言，我们是否需要 ML/DL 理论？   由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</guid>
      <pubDate>Mon, 22 Jan 2024 20:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[R]双重认知架构：结合偏见和多记忆系统实现终身学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d2c65/r_dual_cognitive_architecture_incorporating/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2310.11341 OpenReview：https:// /openreview.net/forum?id=PEyVq0hlO3 代码： https://github.com/NeurAI-Lab/DUCA 数据集：https://github.com/NeurAI-Lab/DN4IL-dataset 视频：https://www.youtube.com/watch?v=08tfpjvUGqs 摘要：  人工神经网络（ANN）在固定独立数据上表现出狭窄的专业知识范围。然而，现实世界中的数据是连续的、动态的，人工神经网络必须适应新的场景，同时保留学到的知识，成为终身学习者。人类在这些任务上表现出色的能力可以归因于多种因素，包括认知计算结构、认知偏差和大脑中的多记忆系统。我们结合了其中的关键概念来设计一个新颖的框架，双重认知架构（DUCA），其中包括多个子系统、隐式和显式知识表示二分法、归纳法偏见和多记忆系统。 DUCA 中的归纳偏差学习器有助于编码形状信息，有效对抗 ANN 学习局部纹理的趋势。同时，语义记忆子模块的包含有助于知识的逐步巩固，复制在快速和慢速学习系统中观察到的动态，让人想起支撑人类认知中互补学习系统的原理。 DUCA 在不同的设置和数据集上显示出改进，并且还表现出减少的任务新近度偏差，而不需要额外的信息。为了进一步测试终身学习方法在具有挑战性的分布变化上的多功能性，我们引入了一种新颖的领域增量数据集DN4IL。除了提高现有基准测试的性能之外，DUCA 还在这个复杂的数据集上展示了卓越的性能。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d2c65/r_dual_cognitive_architecture_incorporating/</guid>
      <pubDate>Mon, 22 Jan 2024 18:20:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 提前停止但是什么时候？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cx4ol/d_early_stopping_but_when/</link>
      <description><![CDATA[你好， 我最近一直在尝试寻找比耐心和增量值更好的提前停止方法，并且我偶然发现这篇论文 https://page.mi.fu-berlin.de/prechelt/Biblio/ stop_tricks1997.pdf 。鉴于本文中提到的标准，我发现继续采用这种方法是非常合乎逻辑的。我还碰巧注意到这是一篇非常古老的论文，似乎没有一个主要平台考虑这里的实现。我完全不明白为什么这不是一个有效的方法吗？    由   提交/u/Bhargav_28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cx4ol/d_early_stopping_but_when/</guid>
      <pubDate>Mon, 22 Jan 2024 14:41:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们没有看到很多关于 Mamba 架构的内容？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cwf65/d_why_were_not_seeing_a_lot_of_content_about/</link>
      <description><![CDATA[比如对作者的一些采访？还没有看到例如TWIML AI 播客谈论 Mamba 架构。   由   提交/u/_learning_stuff_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cwf65/d_why_were_not_seeing_a_lot_of_content_about/</guid>
      <pubDate>Mon, 22 Jan 2024 14:07:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 超越变形金刚：结构化状态空间序列模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cv8q6/d_beyond_transformers_structured_state_space/</link>
      <description><![CDATA[撰写了一篇文章，解释了状态空间序列模型的基础知识。本文的目的是以简化的方式呈现基础级别的概念。该领域在人工智能领域正在迅速发展，因为它在速度和内存消耗方面超越了 Transformer 架构。以下是文章链接：https://cnichkawde.github.io/statespacesequencemodels.html &lt; /div&gt;  由   提交 /u/cnichkawde   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cv8q6/d_beyond_transformers_structured_state_space/</guid>
      <pubDate>Mon, 22 Jan 2024 13:07:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 chatGPT 之后，人们现在还在创建自己的新的自定义 NLP 模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cqde6/d_after_chatgpt_are_people_still_creating_their/</link>
      <description><![CDATA[对使用 scikit-learn 和 Tensorflow 训练 ML 和 DL 模型有点脱节。只是想知道 ML 工程师是否仍在训练他们自己的 NLP 模型（甚至 CV、预测、聚类模型等）。 如果是这样，您正在训练什么类型的模型？您正在解决哪些用例？如果您用 ChatGPT 替换自定义模型，进展如何？ 我想重新熟悉 ML 生态系统。很想听听您的想法。   由   提交 /u/automatonv1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cqde6/d_after_chatgpt_are_people_still_creating_their/</guid>
      <pubDate>Mon, 22 Jan 2024 07:41:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>