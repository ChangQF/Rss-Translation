<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Tue, 30 Jul 2024 06:21:36 GMT</lastBuildDate>
    <item>
      <title>如何找到尚未提供代码的论文来实现/复制？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efl5tv/how_do_i_find_papers_to_implementreproduce_for/</link>
      <description><![CDATA[嗨，我最近完成了计算机科学本科学习，很快就要开始从事软件工程师的工作了。我很可能近期不会在我的组织中获得与 ML 相关的职位。 我希望通过业余项目和复现论文来建立强大的投资组合。 如何找到尚未实现的论文？我不想做别人已经做过的工作。    提交人    /u/Brief-Progress-5158   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efl5tv/how_do_i_find_papers_to_implementreproduce_for/</guid>
      <pubDate>Tue, 30 Jul 2024 05:09:12 GMT</pubDate>
    </item>
    <item>
      <title>点云处理的研究策略 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efjvr9/research_strategy_in_point_cloud_processing_r/</link>
      <description><![CDATA[作为点云处理专业的博士候选人，我正处于研究旅程的关键时刻。在查看了最近的 CVPR 2024 论文后，我正在考虑最有效的方法来发展我的研究重点。我正在考虑以下策略：  深入研究：选择一个有前途的模型/主题进行彻底研究并可能贡献新颖的见解。 广泛调查：在缩小到特定重点之前，全面了解各个研究领域。 利基探索：在点云处理和计算机视觉中识别和探索较少探索的领域。  对于该领域的经验丰富的研究人员：  您推荐哪种方法来开发强大的研究方向？ 您如何确定您的特定研究领域？ 哪些策略可以帮助识别点云处理中有前途但尚未充分探索的领域？  非常感谢您对博士研究这一关键阶段的任何见解。感谢您的专业知识和指导。    提交人    /u/Same_Half3758   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efjvr9/research_strategy_in_point_cloud_processing_r/</guid>
      <pubDate>Tue, 30 Jul 2024 03:57:05 GMT</pubDate>
    </item>
    <item>
      <title>Meta FAIR 刚刚发布“任何事物细分模型 2”[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efebjl/segment_anything_model_2_just_released_by_meta/</link>
      <description><![CDATA[FAIR 刚刚推出了 SAM 2！ 该模型在图像上的表现优于 SAM，现在还可以在视频中分割物体，并且持续开放。  模型、代码、数据集、演示均已提供。 网站 演示 Github    提交人    /u/fruitofconfusion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efebjl/segment_anything_model_2_just_released_by_meta/</guid>
      <pubDate>Mon, 29 Jul 2024 23:28:03 GMT</pubDate>
    </item>
    <item>
      <title>[N] 从科幻小说到州法律：加州预防人工智能灾难的计划</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efdpmw/n_from_scifi_to_state_law_californias_plan_to/</link>
      <description><![CDATA[Ars Technica：从科幻小说到州法律：加州预防人工智能灾难的计划  加州的“前沿人工智能模型安全创新法案”（又名 SB-1047）引发了一系列有关大型人工智能模型整体“安全性”的头条新闻和辩论。但批评者担心，该法案过分关注未来人工智能模型的生存威胁，可能会严重限制当今更平淡无奇、无威胁的人工智能用途的研究和开发。 SB-1047 由州参议员 Scott Wiener 提出，于 5 月以 32 比 1 的投票通过了加州参议院，并且似乎有望在 8 月的州议会上进行最终投票。  该法案的一个特别值得注意的特点：  在他的 Understanding AI 时事通讯中，Ars 撰稿人 Timothy Lee 阐述了 SB-1047 的措辞如何严重阻碍所谓的“开放权重”AI 模型的传播。这是因为该法案将使模型创建者对基于其原始训练构建的“衍生”模型负责。     提交人    /u/bregav   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efdpmw/n_from_scifi_to_state_law_californias_plan_to/</guid>
      <pubDate>Mon, 29 Jul 2024 23:01:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理论深度学习会议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1efaug9/d_theoretical_dl_conferences/</link>
      <description><![CDATA[情况是这样的： 今年的研究比我习惯的更加注重理论 所以现在我正在考虑参加一个会议提交论文，这将更加注重理论，而不是那么要求应用。我的部门主要关注更面向应用的场所，这个社区早期的帖子评论大多已过时。 这篇论文非常基础，贡献仅限于监督启发式学习 - 例如通过反向传播 以下是贡献的简短摘要以提供背景信息 TLDR：新颖的视角+方法，非常基本的展示用例 摘要：我们从新颖的视角P（这是一个主要提议）来看待学习过程的元素E，这允许将其视为来自F家族的一个规范。 现在，我们分析如果我们考虑F中的其他规范，行为在某种意义上S会如何变化：推导出某些变化C的下限和上限。 C可以用作学习过程的补充，类似于辍学或某种正则化。我们在一些非常基础且经过充分研究的基准数据集上展示了结果 - 为了展示提案的理论部分。    提交人    /u/One_With_Great_Dao   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1efaug9/d_theoretical_dl_conferences/</guid>
      <pubDate>Mon, 29 Jul 2024 21:03:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有可能兼顾研究和全职工作吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef6mnn/d_is_it_possible_to_juggle_doing_research_and/</link>
      <description><![CDATA[我目前在一家生命科学公司担任 AI 工程师。我对深度学习研究（尤其是计算机视觉）很感兴趣，但同时又不想辞职。我可以在下班后远程与教授一起做研究员吗？我愿意每周为此投入 20 小时。（工作日 2 小时，周末 10 小时）    提交人    /u/Hour_Amphibian9738   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef6mnn/d_is_it_possible_to_juggle_doing_research_and/</guid>
      <pubDate>Mon, 29 Jul 2024 18:16:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] MMM程序/工具选择建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef2pjz/d_mmm_programtool_selection_advice/</link>
      <description><![CDATA[大家好，我是一名在 MMM 工作的计量经济学家，希望有人能提供一些见解来帮助我。作为参考，我有使用内部建模工具、EViews 和 Random Forest ML 的背景。我刚开始一份新工作，目前这里没有 MMM 功能，所以我们正在研究我们的选择。我一直被推荐使用 LightweightMMM（显然很快就会被 Meridian 取代）作为贝叶斯 MMM 的开源选项，我从未执行过贝叶斯建模方法，但对它了解得足够多，只需一点练习和阅读就可以了。 我面临的问题是，我们的潜在客户需要一个区域级别的模型，该模型还考虑到营销的长期影响。现在我知道 Lightweight/Meridian 可以处理这个要求的区域方面，但我不确定长期（嵌套）建模的能力。这是它能处理还是不能处理？有没有解决办法，例如提取分解后的输出并运行第二个模型，以品牌跟踪（例如知名度）的增量增益作为 KPI，以确定媒体对此的贡献？ 如果这是无法通过 Lightweight 或 Meridian 完成的事情，那么是否有人知道有什么程序/工具可以帮助我们建模以满足这些要求？任何帮助都将不胜感激，谢谢。    提交人    /u/Radiant-Project5105   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef2pjz/d_mmm_programtool_selection_advice/</guid>
      <pubDate>Mon, 29 Jul 2024 15:39:58 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型的有效提示方法：一项调查 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef22iu/efficient_prompting_methods_for_large_language/</link>
      <description><![CDATA[  由    /u/juliannorton  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef22iu/efficient_prompting_methods_for_large_language/</guid>
      <pubDate>Mon, 29 Jul 2024 15:14:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] Neurips’24 评论发布时间？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef1var/d_neurips24_review_release_time/</link>
      <description><![CDATA[有人知道评审什么时候发布吗？NeurIPS 网站指出，反驳将于 7 月 30 日在地球上的任何地方开始，而在我们的时区已经是 7 月 30 日了！    提交人    /u/Working-Egg-3424   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef1var/d_neurips24_review_release_time/</guid>
      <pubDate>Mon, 29 Jul 2024 15:06:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 知识图谱和对（大量）技术 PDF 进行 ra.g</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ef0iv8/d_p_knowledge_graph_and_rag_over_large_set_of/</link>
      <description><![CDATA[我有一批在一段时间内收集的 PDF（数量增长很快）。主要是技术材料（机器学习、统计学、金融等方面的期刊文章和书籍）。我想基于这些材料创建一个知识图谱，并微调一个 RAG，这样我就可以使用 LLM 搜索我的东西。我的想法是，与其使用 mendeley，我可以使用 LLM 作为强化版的 mendeley。不需要文件夹和标签，我只需提示我正在寻找的内容即可。 问题：  我不想重新发明轮子。要使用哪些软件包 / github？ 有人成功完成过吗？ 本地计算会是一个问题 —— 无法在本地完成。最好是与 ChatGPT 或 Claude 链接的东西（我对这两个都有专业订阅）。  TIA 编辑：如果我可以将我的笔记放入（非常多）overleaf 项目、onenote、supernotes 和 ms 中来执行此操作，那也会很棒。    提交人    /u/daydaybroskii   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ef0iv8/d_p_knowledge_graph_and_rag_over_large_set_of/</guid>
      <pubDate>Mon, 29 Jul 2024 14:11:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 量化的视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eey89o/p_a_visual_guide_to_quantization/</link>
      <description><![CDATA[大家好！随着越来越多的大型语言模型发布以及量化需求的增加，我想是时候编写一份深入且直观的量化指南了。 从探索如何表示值、（非）对称量化、动态/静态量化，到训练后技术（例如 GPTQ 和 GGUF）和量化感知训练（带有 BitNet 的 1.58 位模型）。 https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization 有了超过 60 个自定义视觉效果，我有点做得过火了，但我真的很想尽可能多地包含概念！  本指南的视觉特性允许专注于直觉，希望使所有这些技术易于广大受众使用，无论您是量化新手还是经验丰富的量化新手。    提交人    /u/MaartenGr   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eey89o/p_a_visual_guide_to_quantization/</guid>
      <pubDate>Mon, 29 Jul 2024 12:27:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] CUDA 中的 KV 缓存</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eepco9/p_kv_cache_in_cuda/</link>
      <description><![CDATA[我正在开发一个项目，允许使用 C CUDA 推断 Llama3.0-8B。GG 的 Llama.cpp 给了我很大的启发，因为我刚接触 CUDA，想深入了解它。 对于 KV 缓存，您究竟如何在确保速度和内存性能的同时，移除和重新组织物理 CUDA 内存中的张量数据？本质上，是否有任何最佳实践且经济有效的方法可以将张量虚拟地移到左上角，以便为新标记留出新空间？ 因为我假设如果我必须分配内存并设置 CUDA 内核以将值复制到新的内存块，那么最终会比重新计算值更昂贵？ 此外，如果缩放后​​有自注意力的掩码，计算输出的右上三角形是否有意义？直接将物理内存中的这些值手动设置为某个较大的负数不是很有意义吗？  struct Tensor { int ndim; int *shape; float *arr; int mem_size; };     submitted by    /u/Delicious-Ad-3552   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eepco9/p_kv_cache_in_cuda/</guid>
      <pubDate>Mon, 29 Jul 2024 03:12:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么机器学习领域中这么多最优秀的人才没有为大型科技公司工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eejd3b/d_why_so_many_of_the_most_skilled_people_in_the/</link>
      <description><![CDATA[我见过很多拥有常春藤联盟学位的人，研究论文作者，获奖者，课程老师，该领域的书籍作者，但你看他们的领英，这些人中的大多数都不在谷歌、微软、亚马逊、Meta 等大型科技公司 (MANGA 公司) 工作，他们通常在中小型公司工作，我的意思是，写一本关于机器学习的书的人一定知道这件事，拥有剑桥或哈佛计算机科学学位的人可能对此有所了解，为什么有这么多来自大科技公司？ 我知道很多人想专注于研究而不是行业，但大型科技公司确实在 ML 领域进行了最先进的研究，所以对我来说很难知道为什么这些公司不想要这些人或者为什么他们不想为大型科技公司工作。    提交人    /u/millhouse056   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eejd3b/d_why_so_many_of_the_most_skilled_people_in_the/</guid>
      <pubDate>Sun, 28 Jul 2024 22:18:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 稀疏自动编码器对 LLM 可解释性的直观解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eeihdl/d_an_intuitive_explanation_of_sparse_autoencoders/</link>
      <description><![CDATA[稀疏自动编码器 (SAE) 是实现 LLM 可解释性和可说明性的最有前途和最流行的方法之一。我撰写了一篇简单、直观的 SAE 介绍，并附有图表和参考 PyTorch 代码。 除其他内容外，我还介绍了我们使用 SAE 的原因、它们如何用于模型干预（例如 金门大桥克劳德）以及使用 SAE 的挑战。最突出的挑战之一是缺乏良好的指标，因为自然语言文本中没有明确的可衡量的基本事实。 解释链接在此处：https://adamkarvonen.github.io/machine_learning/2024/06/11/sae-intuitions.html    提交人    /u/seraine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eeihdl/d_an_intuitive_explanation_of_sparse_autoencoders/</guid>
      <pubDate>Sun, 28 Jul 2024 21:38:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jul 2024 15:00:14 GMT</pubDate>
    </item>
    </channel>
</rss>