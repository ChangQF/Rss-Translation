<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 16 Feb 2024 15:13:47 GMT</lastBuildDate>
    <item>
      <title>[D] 小数据集（~2.5k）的多标签分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1asay4c/d_multilabel_classification_with_small_dataset_25k/</link>
      <description><![CDATA[      我有一个包含论文摘要的数据集和关键词。大约 3k 个摘要带有指定的关键字，而 1k 个摘要则没有。我想使用第一批训练模型来为第二批分配标签。  有超过 5000 个关键字，但大多数不在摘要之间共享，因此我的想法是将数据集减少到 20 到 30 个关键字，这些关键字出现在至少 150 个摘要中。最终得到一个包含 2.5k 个已分配关键字的值的数据集。  ​ https://preview.redd.it/0tealh5ppyic1.png?width=1310&amp;format=png&amp;auto=webp&amp;s=55354850b92646102389cf2f6d89253c854540 b0 现在，我有一些疑问关于如何解决多标签分类问题： 我尝试了实现来自 Scikit-Learn 的 MultiOutputClassifier 的简单解决方案 测试数据中的大多数摘要均未分配关键字。  我已经阅读了 setfit 并尝试运行 示例笔记本&lt; /a&gt; 在 google colab 上，但是 atm 他们限制了 GPU 并且无法尝试它（它与 CPU 一起崩溃）。我的笔记本电脑上没有 GPU，因此认为不值得尝试安装 setfit。  我还阅读了有关 BERT 和其他解决方案的内容，但还有很多。 您会建议为 Google Colab 付费并继续 setfit 路线吗？您有使用该框架的经验吗？ 您是否推荐我没有想到的其他解决方案？不用花哨的机器学习就能解决这个问题吗？ 我的方法有意义吗？我是所有机器学习方面的新手。 谢谢！   由   提交/u/isgael  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1asay4c/d_multilabel_classification_with_small_dataset_25k/</guid>
      <pubDate>Fri, 16 Feb 2024 15:12:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 处理回归模型中缺失的特征以进行不同条件下的比较分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1as9v2l/d_handling_missing_features_in_regression_models/</link>
      <description><![CDATA[您好，r/MachineLearning 社区！我目前正在研究回归问题，并面临着数据集的独特挑战。我希望获得一些关于如何进行我的实验的建议，我在三种不同条件下收集了特定产品的数据。我们将这些条件称为 A（仅与条件 A 相关的特征）、B（仅与条件 B 相关的特征）和 AB（A 和 B 的特征都存在）。每个条件都以独特的方式修改产品，并旨在影响结果变量，这是一个连续的度量（为了简单起见，假设它是用户偏好的度量）。挑战在于如何在这些条件下构建功能：  对于条件 A 的产品，只有与 A 相关的功能可用（所有 B 功能都缺失）。 对于条件 B 的产品，仅提供与 B 相关的功能（缺少所有 A 功能）。 对于条件 AB 的产品，同时存在 A 和 B 功能。  最终目标是有效预测连续结果变量，同时考虑 AB 条件中两组特征的影响，从而证明条件 A 和 B（及其组合）对结果的独特贡献。我正在寻找能够让我有效处理这种丢失数据场景的策略或方法。具体来说，我想：  准确预测所有条件下的结果变量。 了解条件 A 和 B（单独和组合）对结果的影响。&lt; /li&gt;  我考虑过的一些方法包括模型集成，甚至是针对每个条件的单独模型，以及某种形式的聚合或比较。然而，我不确定准确预测和解释这些条件的影响的最佳方法。这里有没有人处理过类似的挑战或者可以提供一些关于潜在策略的见解？任何有关模型、技术或文献的建议都可以指导我解决这个问题，我们将不胜感激。 提前感谢您的帮助！   由   提交 /u/Responsible-Ask1199    reddit.com/r/MachineLearning/comments/1as9v2l/d_handling_missing_features_in_regression_models/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1as9v2l/d_handling_missing_features_in_regression_models/</guid>
      <pubDate>Fri, 16 Feb 2024 14:27:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 7b 模型理论上能达到多好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1as9dq2/d_how_good_can_a_7b_model_theoretically_get/</link>
      <description><![CDATA[尝试感受知识压缩的局限性。在标准基准测试中能否超越 GPT4？   由   提交/u/Z3F  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1as9dq2/d_how_good_can_a_7b_model_theoretically_get/</guid>
      <pubDate>Fri, 16 Feb 2024 14:05:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最鼓舞人心/最有价值的机器学习纪录片是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1as6pb3/d_what_are_the_most_inspiringvaluable_ml/</link>
      <description><![CDATA[大家好， 我正在寻找有关 ML、使用 ML 的人员以及他们面临的挑战的纪录片以及他们如何解决这些问题。不一定是最近的，10 年前的文档可能展示了 ML 和 AI 的兴起，相关人员被认为是开拓者和创新者。 我真的很喜欢 AlphaGo，尽管它主要关注实际情况节目中，我对人更感兴趣。有趣的往往会非常鼓舞人心。 谢谢。   由   提交 /u/SquidsAndMartians   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1as6pb3/d_what_are_the_most_inspiringvaluable_ml/</guid>
      <pubDate>Fri, 16 Feb 2024 11:48:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] Lambda Lab vs. Mifcom vs selfbuild</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1as6p8w/d_lambda_lab_vs_mifcom_vs_selfbuild/</link>
      <description><![CDATA[您如何比较在欧洲购买 ML 工作站的不同选择的质量和价格溢价？我看到三个主要选择： 1. 机器学习专家提供现成的解决方案 2. 像 mifcom 这样的硬件销售商，不专注于机器学习，但可以提供硬件预构建 3. 完全从头开始构建  &lt; p&gt;对于不同的选择，您有何看法？什么值得付出代价、风险和努力？   由   提交/u/Striking_Way_3205   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1as6p8w/d_lambda_lab_vs_mifcom_vs_selfbuild/</guid>
      <pubDate>Fri, 16 Feb 2024 11:48:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 探索 AstraQuasar-4B：一个新的基于 LLaMA 的拱门 |自层调用的首次训练实现（Duplicate Trick）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1as2l18/p_discover_astraquasar4b_a_new_llamabased_arch/</link>
      <description><![CDATA[嘿r/MachineLearning， 我正在接触这个令人难以置信的社区，因为我们手上有一些独特的东西，而且它有点像未经加工的钻石。来认识一下 AstraQuasar-4B，它是一种对语言模型的全新诠释，但又有所不同——它的训练雄心勃勃，但拥有一种称为重复的秘密武器技巧（也在反向传播中摇摆！）。 AstraQuasar-4B 基于强大的 Phi-2 架构构建，但它不是普通模型。重复技巧是其突出的功能，可显着减少损失，并承诺未开发的稳定性和性能增强。但问题是——它训练不足。我们目前正在以相当大的规模对其进行训练，但我们正处于未知领域，尚未达到通常的基准，因为坦率地说，我们仍在弄清楚。 它与拥抱 Face 管道，因此无需担心切换到其他训练器。 我们相信 AstraQuasar-4B 的真正价值不仅在于它现在的样子，还在于它根据您的输入可能会变成什么样子。这是对测试人员、修补者和思想家的号召。 让我们开始对话吧。分享你的想法、你的怀疑、你的想法。您将如何进行培训？你会进行什么实验？我们如何共同推动 AstraQuasar-4B 超越其当前极限？ （注：这是对合作和想法共享的真诚呼吁。没有赞助，只有纯粹、纯粹的好奇心和对人类力量的信念）社区。）   由   提交 /u/Similar_Choice_9241   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1as2l18/p_discover_astraquasar4b_a_new_llamabased_arch/</guid>
      <pubDate>Fri, 16 Feb 2024 07:08:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与在实际应用中部署法学硕士相关的主要挑战</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1as0lj4/d_key_challenges_associated_with_deployment_of/</link>
      <description><![CDATA[在实际应用中部署法学硕士的主要挑战是什么？  扩展法学硕士以适应不断增加的工作负载和用户需求是一项挑战。确保从小规模应用程序到大规模部署的各种规模的无缝性能需要仔细的优化和资源分配。  您还遇到过哪些其他挑战？   由   提交/u/Ok_Vijay7825   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1as0lj4/d_key_challenges_associated_with_deployment_of/</guid>
      <pubDate>Fri, 16 Feb 2024 05:09:52 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 今天双降的情况</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1as0i07/discussion_status_on_double_descent_today/</link>
      <description><![CDATA[双重血统的现状如何？ 如今机器学习人员对双重血统有何看法？它始于令人惊叹的人们，然后是一系列理论著作试图用线性回归和相关的简单模型来解释它，最后得出结论：最优正则化处理双下降。那么这是一个很好理解的景观吗？人们今天对此有什么思考吗？   由   提交 /u/AccomplishedTell7012   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1as0i07/discussion_status_on_double_descent_today/</guid>
      <pubDate>Fri, 16 Feb 2024 05:04:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 专家混合解锁深度强化学习的参数缩放</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ary7xi/r_mixtures_of_experts_unlock_parameter_scaling/</link>
      <description><![CDATA[摘要：  最近（自）监督学习模型的快速进展在很大程度上是通过经验缩放来预测的定律：模型的性能与其大小成正比。然而，对于强化学习领域来说，类似的缩放定律仍然难以捉摸，增加模型的参数数量通常会损害其最终性能。在本文中，我们证明了将专家混合 (MoE) 模块，特别是软 MoE（Puigcerver 等人，2023）纳入基于价值的网络会产生更多参数可扩展的模型，性能的显着提高就证明了这一点跨越各种训练制度和模型大小。因此，这项工作为制定强化学习的缩放定律提供了强有力的经验证据。  论文链接：https://arxiv.org/pdf/2402.08609.pdf   由   提交/u/OwnAd9305   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ary7xi/r_mixtures_of_experts_unlock_parameter_scaling/</guid>
      <pubDate>Fri, 16 Feb 2024 03:02:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 作为世界模拟器的视频生成模型。开放AI Sora技术报告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arwcpu/r_video_generation_models_as_world_simulators/</link>
      <description><![CDATA[报告 - https ://openai.com/research/video- Generation-models-as-world-simulators   由   提交/u/MysteryInc152   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arwcpu/r_video_generation_models_as_world_simulators/</guid>
      <pubDate>Fri, 16 Feb 2024 01:31:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 激活的三个十年：神经网络 400 个激活函数的全面调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arovn8/r_three_decades_of_activations_a_comprehensive/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.09092 摘要：  神经网络已被证明是解决复杂问题的高效工具生活的许多方面都存在问题。最近，随着深度学习的出现，它们的重要性和实际可用性进一步得到加强。神经网络成功的重要条件之一是选择合适的激活函数，将非线性引入模型。过去的文献中已经提出了许多类型的这些函数，但没有一个综合来源包含它们的详尽概述。即使根据我们的经验，缺乏这种概述也会导致冗余和无意中重新发现已经存在的激活函数。为了弥补这一差距，我们的论文提出了一项涉及 400 个激活函数的广泛调查，其规模比以前的调查大几倍。我们的综合汇编也参考了这些调查；然而，其主要目标是提供先前发布的激活函数的最全面的概述和系统化，并提供其原始来源的链接。第二个目标是更新当前对这一系列函数的理解。    由   提交 /u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arovn8/r_three_decades_of_activations_a_comprehensive/</guid>
      <pubDate>Thu, 15 Feb 2024 20:12:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI Sora Video Gen——如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1armmng/d_openai_sora_video_gen_how/</link>
      <description><![CDATA[ 介绍 Sora，我们的文本转视频模型。 Sora 可以生成长达一分钟的视频，同时保持视觉质量并遵守用户的提示。  https:/ /openai.com/sora 研究笔记 Sora 是一种扩散模型，它从看起来像静态噪声的视频开始生成视频，然后通过多个步骤消除噪声来逐渐对其进行转换. Sora 能够一次生成整个视频或扩展生成的视频以使其更长。通过一次为多个帧提供模型预测，我们解决了一个具有挑战性的问题，即确保对象即使暂时离开视野也保持不变。 与 GPT 模型类似，Sora 使用变压器架构，释放卓越的扩展性能。 我们将视频和图像表示为称为补丁的较小数据单元的集合，每个补丁类似于 GPT 中的令牌。通过统一我们表示数据的方式，我们可以在比以前更广泛的视觉数据上训练扩散变换器，涵盖不同的持续时间、分辨率和纵横比。 Sora 建立在 DALL·E 和 DALL·E 过去的研究基础上GPT 模型。它使用 DALL·E 3 的重述技术，该技术涉及为视觉训练数据生成高度描述性的标题。因此，该模型能够更忠实地遵循生成视频中用户的文本指令。 除了能够仅根据文本指令生成视频之外，该模型还能够采用现有的静态图像并从中生成视频，精确地动画图像内容并关注小细节。该模型还可以获取现有视频并对其进行扩展或填充缺失的帧。在我们的技术论文（今天晚些时候发布）中了解更多信息。 Sora 是能够理解和模拟现实世界的模型的基础，我们相信这一功能将成为实现 AGI 的重要里程碑。 Sora 是能够理解和模拟现实世界的模型的基础。 p&gt; 示例视频：https://cdn.openai.com/sora/videos/ cat-on-bed.mp4 技术论文将于今天晚些时候发布。但是如何进行头脑风暴呢？   由   提交/u/htrp  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1armmng/d_openai_sora_video_gen_how/</guid>
      <pubDate>Thu, 15 Feb 2024 18:39:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] Gemini 1M/10M token上下文窗口怎么样？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arj2j8/d_gemini_1m10m_token_context_window_how/</link>
      <description><![CDATA[是否会启动社区头脑风暴主题？ - 人们是否认为 RingAttention 可以充分扩展？参见https://largeworldmodel.github.io - 它是用 1M 还是 10Mn 令牌窗口进行训练的，这对我来说似乎不清楚？他们是否在没有经过某种训练的情况下从 1M-&gt;10M 进行概括？ - 存在哪些数据集可以训练 10M 文本标记窗口？ - 在这么长的背景下你如何做 RLHF？ 1M 文本 ~ 4M 字符 ~ 272k 秒阅读时间（根据 Google 假设 68 毫秒/字符）~ 阅读一个示例需要 75 小时？ 编辑：当然 lucidrains 已经在着手实施 RingAttention！ (https://github.com/lucidrains/ring-attention-pytorch)   由   提交 /u/gggerr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arj2j8/d_gemini_1m10m_token_context_window_how/</guid>
      <pubDate>Thu, 15 Feb 2024 16:13:29 GMT</pubDate>
    </item>
    <item>
      <title>[N] Gemini 1.5，具有 1M 上下文长度令牌的 MoE</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arhnoe/n_gemini_15_moe_with_1m_tokens_of_contextlength/</link>
      <description><![CDATA[https://blog.google/technology/ai/google-gemini-next- Generation-model-february-2024/  &amp;# 32；由   提交/u/Electronic-Author-65   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arhnoe/n_gemini_15_moe_with_1m_tokens_of_contextlength/</guid>
      <pubDate>Thu, 15 Feb 2024 15:13:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>