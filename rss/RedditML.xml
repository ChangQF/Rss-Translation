<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 13 Dec 2024 12:35:06 GMT</lastBuildDate>
    <item>
      <title>[D] 使用合成数据进行训练，模型崩溃。有进展吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hd92mt/d_training_with_synthetic_data_and_model_collapse/</link>
      <description><![CDATA[大约一年前，研究论文讨论了处理合成数据时模型崩溃的问题。最近我听说这方面取得了一些进展。我不是专家，欢迎您对正在发生的事情发表看法。谢谢，祝您有美好的一天。    提交人    /u/BubblyOption7980   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hd92mt/d_training_with_synthetic_data_and_model_collapse/</guid>
      <pubDate>Fri, 13 Dec 2024 10:03:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 代理人工智能设计模式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hd8w3k/d_agentic_ai_design_patterns/</link>
      <description><![CDATA[我正在研究 Agentic AI 的设计模式，我需要一些帮助来掌握这些概念。 我阅读了有关 ReAct 和 ReWOO 的文章。 从 ReWOO 中，我真的很喜欢拥有一个可以创建需要完成的工作蓝图的规划器的想法。我可以想象这对于很多任务都很有效，并且与 ReAct 相比，它优化了令牌的使用。 对于 ReAct，我喜欢它有一个反射/观察 LLM，来决定输出是否足够好或者需要再次通过代理。 我不明白的是：为什么 ReWOO 没有反射组件？ 拥有规划器和反射不是两全其美吗？ 这是我的代理 AI 原型的初稿，我认为它具有非常明显的优势。 我想我在这里遗漏了一些东西。    提交人    /u/Mindless_Copy_7487   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hd8w3k/d_agentic_ai_design_patterns/</guid>
      <pubDate>Fri, 13 Dec 2024 09:49:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 各个领域/模型类型/应用的 HPO 重要性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hd6pjv/d_importance_of_hpo_per_field_model_type/</link>
      <description><![CDATA[我注意到，在超参数优化上花费的时间差异很大，不仅在行业和学术界之间，而且在 NLP、计算机视觉或强化学习等不同领域之间也是如此。我很好奇——你的经验是什么？  调整是你优先考虑的事情吗，还是你经常满足于“足够好”的配置来加快速度？ 你认为哪些领域/模型类型/应用程序由于 HPO 而遇到最多（或最少）的工作流程瓶颈？ 在选择 HPO 工具时是否存在行业依赖性？例如，xx 行业中的每个人都会选择 Optuna 作为首选，或者每个运行 xx 实验的人都会使用 Sigopt。  很想听听你的经验！谢谢    提交人    /u/Maleficent_Ad5541   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hd6pjv/d_importance_of_hpo_per_field_model_type/</guid>
      <pubDate>Fri, 13 Dec 2024 06:58:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助评估模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hd5kht/d_help_with_evaluating_model/</link>
      <description><![CDATA[我在评估模型时遇到了问题，因为 model.evaluate() 返回的准确度总体得分还可以，但混淆矩阵和分类报告对一个类返回 100%，对另一个类返回 0%，我正在使用 cifar10，但只有其中的 2 个类。有人知道为什么会这样吗？这是过度拟合吗？我不确定，因为我得到的分数与 model.evaluate(0 在我的训练准确度中是相似的，损失也一样（几乎和准确度一样高）    提交人    /u/Affectionate_Pen6368   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hd5kht/d_help_with_evaluating_model/</guid>
      <pubDate>Fri, 13 Dec 2024 05:40:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] LSTM 模型实现和近似问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hcvh1c/d_lstm_model_implementation_and_approximation/</link>
      <description><![CDATA[对于一个项目，我目前正在尝试集成一个用于特征提取的自动编码器和一个用于对缩小的特征空间进行分类的 LSTM。我遇到的问题是如何训练 LSTM 网络。AE 生成 5 个数据点，这些数据点被输入到 LSTM 网络中。现在的诀窍在于 LSTM 网络的训练以及 LSTM 的工作原理。我希望 LSTM 考虑来自 AE 在时间 t 的 5 个参数以及 t-1 和 t-2 的参数。据我所知，LSTM 会自动执行此操作，还是应该让 LSTM 总共接受 15 个参数，每对 5 个参数对应 AE 的一个时间步？ 任何关于 LSTM 的建议都很好，或者如何以有效的方式进行此类训练。AE 正在处理时间序列信号。   由    /u/Sea_Onion41  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hcvh1c/d_lstm_model_implementation_and_approximation/</guid>
      <pubDate>Thu, 12 Dec 2024 21:09:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将已接受的会议论文上传到 ArXiv 的“正确”方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hcupkm/d_proper_way_to_upload_accepted_conference_paper/</link>
      <description><![CDATA[我们最近有一篇论文被会议 (AAAI) 接受。我们发现会议不发布附录，所以他们建议我们将整篇论文（包括附录）上传到 arXiv。无论如何，我们都在考虑这样做，因为论文将在会议论文集发布之前发布。 我担心的是，如果有人决定引用我们的工作，他们可能会感到困惑，或者引用 arXiv 而不是 AAAI“版本”。 有没有“正确”或常见的方法来处理这个问题？具有相同标题的 arXiv 上传是否会在 Google 学术上被索引到“一份手稿”？ 此外，我们可以使用会议模板上传吗？ （我想这部分可能与会议有关）。 我知道现在在收到会议回复之前上传到 arXiv 是很常见的（通常标题不同），但我认为这是一种略有不同的情况，因为论文被接受并且上传的版本将与会议论文相同（尽管带有附录）。 提前谢谢您！    提交人    /u/baghalipolo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hcupkm/d_proper_way_to_upload_accepted_conference_paper/</guid>
      <pubDate>Thu, 12 Dec 2024 20:38:05 GMT</pubDate>
    </item>
    <item>
      <title>从病毒和物质到星系及其他：机器学习在科学发现中扮演的角色</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hcubv2/from_viruses_and_materials_to_galaxies_and_beyond/</link>
      <description><![CDATA[        由    /u/SlothSpeedRunning  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hcubv2/from_viruses_and_materials_to_galaxies_and_beyond/</guid>
      <pubDate>Thu, 12 Dec 2024 20:21:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2024 最佳论文奖得主破坏了其他团队</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hctf36/d_the_winner_of_the_neurips_2024_best_paper_award/</link>
      <description><![CDATA[据推测，NeurIPS 2024 最佳论文奖的获得者（来自字节跳动，抖音的创造者）破坏了其他团队的研究，并将他们的资源转移到他自己的团队。此外，他在会议上调试同事的代码，所以他总是领先一步。有人呼吁撤回他的论文。 https://var-integrity-report.github.io/ 我还没有核实事实本身，所以如果你能验证断言的内容，如果这是真的，那就太好了。    提交人    /u/LelouchZer12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hctf36/d_the_winner_of_the_neurips_2024_best_paper_award/</guid>
      <pubDate>Thu, 12 Dec 2024 19:41:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 重新思考对比学习中的正对</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hcpoo6/r_rethinking_the_positive_pairs_in_contrastive/</link>
      <description><![CDATA[大家好，我正在分享我最近的工作，该工作允许任意图像成为正对。我们的发现非常令人惊讶，两个完全不同的图像，例如一条蛇和一盏灯，可以是正对。我们的工作可能拓宽对比学习的应用，以处理两个视图不相似的“假阳性”。 我们挑战对比学习中的常识，即正对设计至关重要。我们的结果证明特征选择是关键！ 论文：https://arxiv.org/abs/2410.18200    提交人    /u/Miserable-Gene-308   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hcpoo6/r_rethinking_the_positive_pairs_in_contrastive/</guid>
      <pubDate>Thu, 12 Dec 2024 17:02:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] TikTok 的推荐算法为何如此强大？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hcp4xw/d_what_makes_tiktoks_recommendation_algorithm_so/</link>
      <description><![CDATA[一般讨论 - 现在他们即将在美国被禁止，我对他们的 For You 推荐的力度越来越着迷。为了尝试对我的意思设置一些护栏，TikTok 已经证明自己能够以比任何其他应用程序（包括 YouTube）更高的频率和规模将内容与相关受众相匹配。许多创作者可以加入该平台，发布一个视频，并在 24 小时内获得数百万的观看次数。这在其他应用程序上确实会发生，但 TikTok 似乎是最能以惊人的速度扩大受众群体的应用程序。 他们的系统可能基于什么模型？他们的模型中的哪些方面创造了他们的竞争优势？    提交人    /u/No_Collection_5509   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hcp4xw/d_what_makes_tiktoks_recommendation_algorithm_so/</guid>
      <pubDate>Thu, 12 Dec 2024 16:39:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 宠物项目 - 风格转换神经网络实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hcottj/d_pet_project_style_transfer_neural_networks/</link>
      <description><![CDATA[      嗨，我正在学习 ML，这是我的第一个项目。我对 Gatys 等人的 Neural Style Transfer 论文进行了 100 LoC 的简单实现。参见https://github.com/TAOGenna/pytorch-neural-style-transfer https://preview.redd.it/x2udi76n2g6e1.jpg?width=939&amp;format=pjpg&amp;auto=webp&amp;s=437bdda1683e9fd580a6b3d1d4dc2598b25079ff    由   提交  /u/TAO_genna   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hcottj/d_pet_project_style_transfer_neural_networks/</guid>
      <pubDate>Thu, 12 Dec 2024 16:25:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 ResNet 和极深网络的可扩展性的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hco4ig/d_question_about_resnet_and_scalability_of/</link>
      <description><![CDATA[我一直在探索 ResNet 的架构及其有效训练非常深的神经网络的能力。虽然我知道残差连接有助于缓解梯度消失等问题并使训练更深的网络成为可能，但我很好奇这种方法在扩展到极深的网络（例如具有 1000 层或更多层的网络）时的局限性。 据我所知，由于残差连接，具有 100 层的 ResNet 可能有效地像一个小得多的网络一样运行，这本质上是“跳过”层并添加输出。但是，这是否也意味着如果常规 MLP 难以扩展到 15 层以上，ResNet 可能会按比例转移这个限制（例如，难以超过 150 层）？换句话说，ResNet 是否从根本上解决了训练极深网络的问题，还是仅仅扩展了问题开始重新出现的深度？ 如果您有任何见解，我将不胜感激！非常感谢！    由   提交  /u/Time_Celebration6058   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hco4ig/d_question_about_resnet_and_scalability_of/</guid>
      <pubDate>Thu, 12 Dec 2024 15:54:53 GMT</pubDate>
    </item>
    <item>
      <title>[N] 为 Liger-Kernel 中的 DPO 和 ORPO 节省 80% 的内存</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hcewdl/n_save_80_memory_for_dpo_and_orpo_in_ligerkernel/</link>
      <description><![CDATA[在 Liger Kernel 中引入第一个开源优化的训练后损失，内存减少约 80%，具有 DPO、CPO、ORPO、SimPO、JSD 等功能，通过更大的批量大小实现高达 70% 的端到端加速。将其用作任何 PyTorch 模块 - 今天在 Liger v0.5.0 中可用！ https://x.com/hsu_byron/status/1866577403918917655    提交人    /u/Icy-World-8359   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hcewdl/n_save_80_memory_for_dpo_and_orpo_in_ligerkernel/</guid>
      <pubDate>Thu, 12 Dec 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>