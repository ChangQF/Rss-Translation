<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 30 Aug 2024 15:16:20 GMT</lastBuildDate>
    <item>
      <title>[D] 比较用于文档数据提取的 LLM API – 我的经验和寻找见解！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4wqak/d_comparing_llm_apis_for_document_data_extraction/</link>
      <description><![CDATA[大家好， 我最近写了一篇文章，比较了用于文档数据提取的各种 LLM API，您可以在这里查看。 完整免责声明：我在 Nanonets 工作，因此我的观点可能存在一些偏见，但我确实试图尽可能客观地进行这种比较。 在本文中，我比较了 Claude、Gemini 和 GPT-4 在文档理解和从各种类型文档中提取数据的有效性。我在不同的文档上测试了这些模型，以了解它们对内容的理解和推理能力，并在博客中分享了我的发现。 我非常好奇您使用这些 API 或其他 API 执行类似任务的经验：  您是否尝试过使用 LLM API 进行文档理解和数据提取？进展如何？ 哪些 API 最适合您，为什么？ 您是否遇到了本文未涉及的挑战？ 您对 LLM 在文档理解和数据提取方面的未来有何看法？     提交人    /u/Longjumping_Media365   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4wqak/d_comparing_llm_apis_for_document_data_extraction/</guid>
      <pubDate>Fri, 30 Aug 2024 14:31:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] WACV 2025 试卷评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4wj0j/d_wacv_2025_paper_reviews/</link>
      <description><![CDATA[WACV 2025 论文评论应该在今天发布。讨论主题会很有用！    由    /u/smokeriffs  提交  [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4wj0j/d_wacv_2025_paper_reviews/</guid>
      <pubDate>Fri, 30 Aug 2024 14:23:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年 Google 博士奖学金结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4w1tr/d_results_for_google_phd_fellowship_2024/</link>
      <description><![CDATA[有人从 Google 那里听说过关于博士奖学金计划结果的消息吗？我以为他们会在去年 7 月通知大家。    提交人    /u/EDEN1998   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4w1tr/d_results_for_google_phd_fellowship_2024/</guid>
      <pubDate>Fri, 30 Aug 2024 14:02:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与采访和概念修订相关的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4vwnm/d_advise_related_to_interviews_and_concepts/</link>
      <description><![CDATA[大家好。你们都是如何复习机器学习基础知识的？另外，你们都是如何准备面试问题的？如果你有任何清单，那就太好了。 任何建议都值得赞赏。 谢谢！    提交人    /u/Ok_Fee_9958   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4vwnm/d_advise_related_to_interviews_and_concepts/</guid>
      <pubDate>Fri, 30 Aug 2024 13:56:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 奇怪甚至几乎不可能的表演</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4uv3r/d_strange_and_perhaps_almost_impossible/</link>
      <description><![CDATA[大家好，我在 pytorch 上训练一个模型（带有 cipher10 的 resnet18），我使用 pytorch lightning 因为这是一个项目，它为我简化了很多事情。 我从这个假设开始，我有一台 Ryzen 9 5950x 128 GB RAM 和一台 RTX 4090，当我用例如 16 个 worker 训练模型时，一个 epoch 需要 8/9 分钟，我使用的 worker 越多，花费的时间就越多（尽管相对而言，在这个处理器上 16 个 worker 是完美的），奇怪的是，通过减少 worker 的数量，每个 epoch 的时间就会减少，如果我放 0 个 worker，一个 epoch 就需要 16 秒！我不明白这是怎么可能的，相对而言，通过增加 worker 的数量，我增加了并行化，因此我需要花一些时间。帮我理解一下。    提交人    /u/Obrigad0ne   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4uv3r/d_strange_and_perhaps_almost_impossible/</guid>
      <pubDate>Fri, 30 Aug 2024 13:09:47 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士在战略和规划方面是否较弱？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4prqb/are_llms_weak_in_strategy_and_planning_d/</link>
      <description><![CDATA[只是想了解您（与 Agentic Systems 合作的人）的经验。这是我的。  https://open.substack.com/pub/rizvihasan/p/are-llms-weak-in-strategy-and-planning?r=486x8y&amp;utm_campaign=post&amp;utm_medium=web    提交人    /u/rizvi_du   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4prqb/are_llms_weak_in_strategy_and_planning_d/</guid>
      <pubDate>Fri, 30 Aug 2024 08:00:41 GMT</pubDate>
    </item>
    <item>
      <title>[P]探索机器学习的实际用途：它如何改变我的笔记记录过程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4owc0/pexploring_practical_uses_of_machine_learning_how/</link>
      <description><![CDATA[我一直很难记笔记，因为一方面，我喜欢把所有东西都整理得井井有条，但另一方面，不断需要分类和格式化让我抓狂！有人能体会到吗？我一直希望有一个人工智能工具可以帮我处理所有这些，就在那时，我决定自己创建一个。 我想出了一个我梦想中的工具的基本版本，称为 Stackie，因为它可以帮助我保持信息堆栈的井井有条 - 只需输入您需要的任何内容，Stackie 就会自动对每个笔记进行排序和结构化（是的，它可以使用自然语言！）。 就在前几天，我在为我疼痛的手腕寻找不同的鼠标，将信息输入 Stackie，它将所有内容整齐地组织到我的“鼠标比较”堆栈中。 我也在尝试使用它的新方法，比如跟踪我的卡路里摄入量，因为我已经增加了几磅体重，想变得更健康。有趣的是，我因为懒惰而创建的工具竟然非常有用。 我仍在集思广益，寻找使用 Stackie 的其他方式，确实需要一些新想法。因此，我很想向你们请教，看看你们是否能帮助我跳出固有的思维框架。我刚刚启动了 beta 测试，如果您能尝试一下，我将不胜感激，特别是如果您也有同样的挫败感，或者只是喜欢尝试很酷的新技术。 您的反馈将非常有帮助！ 在此处下载：https://testflight.apple.com/join/25CvgSSv 附言：我正在努力添加一些很酷的功能，例如自动统计和仪表板。您还想看到什么？    提交人    /u/Just-Opportunity9500   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4owc0/pexploring_practical_uses_of_machine_learning_how/</guid>
      <pubDate>Fri, 30 Aug 2024 06:58:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 图像嵌入的聚类方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4lwap/p_clustering_methods_for_image_embeddings/</link>
      <description><![CDATA[我的 pinecone 数据库（我的图像是绘画）中保存了 87 个图像嵌入（CLIP 模型）。到目前为止，UMAP 提供了最佳的降维效果。我尝试过 PCA、t-SNE 和 UMAP。我还可以尝试哪些其他降维方法？我应该使用哪些聚类方法。我尝试过 DBSCAN 和 OPTICS。但我的图像没有被正确分组。我需要更好的分组，因为我稍后将在每个组中进行矢量搜索。给定一个查询图像并且我选择了错误的组，我的搜索将在第一步失败。请帮助我。    提交人    /u/PositiveResponse7678   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4lwap/p_clustering_methods_for_image_embeddings/</guid>
      <pubDate>Fri, 30 Aug 2024 03:47:51 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何计算法学硕士 (LLM) 培训的 token/s 指标</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4i59f/dhow_to_calculate_the_metric_of_tokenss_for_llm/</link>
      <description><![CDATA[对于推理，可以通过 batch_size*max_generation_length/latency 获取 tokens。 但对于训练，例如 Megatron-DeepSpeed，这个指标是如何计算的？它的工作原理相同吗，还是公式不同？ 谢谢。 ML #LLM #training    提交人    /u/bigpeartree   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4i59f/dhow_to_calculate_the_metric_of_tokenss_for_llm/</guid>
      <pubDate>Fri, 30 Aug 2024 00:34:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 根据零件编号描述文字对材料进行分类的模型建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4c4vq/d_model_suggestion_for_classification_of/</link>
      <description><![CDATA[免责声明：我不是 ML 专业人士，我只建立了少数几个模型，主要用于需求预测（在 R 中），有一次是根据不同组件的数量预测产品装配时间（在 Tensorflow/Keras 中）。 在我目前的职位上，我的任务是创建一个模型，该模型根据描述对材料进行分类，以简化问题，假设我们试图预测材料是否是成品，因此是经典的二元分类。 在将文本通过 tfidfvectorizer 后，我已经尝试了 scikit-learn 中的 MLPClassifier 和 SVC，以及 Xgboost，但模型在测试集上表现不佳。 数据集上的一些上下文，大约 10％ 的数据有标签 1，其余的有标签 0。材料描述不是很清晰，我编写了一些辅助函数进行预处理。 上述已尝试过的模型的混淆矩阵显示，对标签 0 进行分类的准确率约为 90%，对标签 1 进行正确分类的准确率约为 60%。 我的问题：  我如何才能知道这些数据是否真的好，它不像数值数据，我可以计算 X 和 y 之间的相关性？ 由于“最佳模型”的概念并不存在，我正在寻求适合此类应用的模型的建议。我应该用我的数据训练 Hugging Face 的法学硕士吗？还是应该使用 Pytorch 从头开始​​构建深度学习模型，并使用 Torchtext 进行标记？ 我是否应该减少标签 0 数据的数量，使数据集为 1:1？还是应该保持原样（9:1）？  非常感谢！   由    /u/HalfManHalfChimp  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4c4vq/d_model_suggestion_for_classification_of/</guid>
      <pubDate>Thu, 29 Aug 2024 20:08:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 实时推荐系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4allv/d_realtime_recommendation_system/</link>
      <description><![CDATA[我正在阅读有关 Twitter 的推荐算法的官方博客，其中谈到“排名是通过一个约 48M 参数的神经网络实现的，该神经网络在推文互动中不断训练，以优化积极参与度。”我试图了解它是如何根据用户互动不断训练神经网络的，就像 Twitter 的情况一样。  就上下文而言，我正在构建一个 Web 应用程序，基本上是一个社交新闻聚合器。它根据我自己的偏好（例如，只向我推送内容和 ML/LLM 上的人员）从 Reddit、Twitter 和 Hacker News 获取帖子和评论，并且不受广告和政治等干扰。我使用 Python、FastAPI 和 PostgreSQL 作为后端。您将如何设计应用程序架构以确保其性能卓越且准确？    提交人    /u/friedahuang   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4allv/d_realtime_recommendation_system/</guid>
      <pubDate>Thu, 29 Aug 2024 19:04:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么审稿人不需要对反驳作出回应？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f49zq2/d_why_arent_reviewers_required_to_respond_to/</link>
      <description><![CDATA[嗨， 我最近向一个会议提交了论文，很好奇为什么审稿人不需要承认反驳。显然，审稿人往往日程繁忙，而详细的回复往往具有挑战性。但我不明白为什么审稿人至少不需要处理反驳（即使是像“谢谢回复！”或“我很感谢补充信息，我正在更新我的分数以反映它”这样简单的话）    提交人    /u/mathwoman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f49zq2/d_why_arent_reviewers_required_to_respond_to/</guid>
      <pubDate>Thu, 29 Aug 2024 18:39:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将任何初学者问题发布至 r/MLQuestions！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3yfjg/d_post_any_bginner_questions_to_rmlquestions/</link>
      <description><![CDATA[我最近继承了 subreddit r/MLQuestions，因为其他版主分别有 10 个月和 4 年没有活动。我一直在整理子版块，添加标签、规则等，并试图增加参与度，使其对那些想要提问的人更有用。基本上就是 stackoverflow，但专门用于解决有关 ML 的初学者问题。所以，如果你们有不好意思在这里问的问题，请在 r/MLQuestions 上提问！我还将推出一个类似于 r/changemyview 的系统，其中每回答一个问题，他们的用户天赋就会增加一个，显示他们回答了多少问题！ 顺便说一句，版主允许我发布这篇文章，所以非常感谢你们，非常酷。    提交人    /u/NoLifeGamer2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3yfjg/d_post_any_bginner_questions_to_rmlquestions/</guid>
      <pubDate>Thu, 29 Aug 2024 09:50:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 澄清 VAE 中的“重新参数化技巧”以及为什么它是一个技巧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3ohje/d_clarification_on_the_reparameterization_trick/</link>
      <description><![CDATA[我一直在研究变分自动编码器 (VAE)，并且不断遇到术语“重新参数化技巧”。据我所知，该技巧涉及使用公式 (X = 平均值 + 标准偏差 * Z) 从正态分布中抽样，其中 Z 是从标准正态分布中抽取的。此公式似乎是从正态分布中抽样的标准方法 这是我的困惑： 为什么这是一个技巧？ 重新参数化“技巧”通常被强调为一个聪明的技巧，但对我来说，它似乎是转换公式的直接应用。如果 ( X = 平均值 + 标准差 * Z ) 是从正态分布中采样的唯一方法，那么为什么重新参数化技巧被认为特别具有创新性？ 我理解该技巧允许通过采样过程进行反向传播。但是，似乎使用 ( X = 平均值 + 标准差 * Z ) 是从给定 ( 平均值 ) 和 ( 标准差 ) 的正态分布中生成样本的唯一方法。除了确保可区分性之外，这个技巧还有什么特别之处？ 这是我的思维过程：我们从编码器获得平均值和标准差，并从中采样，唯一且最明显的方法是“X = 平均值 + 标准差 * Z”。 有人可以帮忙解释为什么重新参数化技巧被称为“技巧”吗？ 提前感谢您的见解！    提交人    /u/SwaroopMeher   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3ohje/d_clarification_on_the_reparameterization_trick/</guid>
      <pubDate>Wed, 28 Aug 2024 23:57:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>