<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 20 Sep 2024 15:16:48 GMT</lastBuildDate>
    <item>
      <title>[R] 通过强化学习训练语言模型进行自我纠正</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flby1u/r_training_language_models_to_selfcorrect_via/</link>
      <description><![CDATA[  由    /u/RobbinDeBank  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flby1u/r_training_language_models_to_selfcorrect_via/</guid>
      <pubDate>Fri, 20 Sep 2024 13:24:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 reddit 进行医学科学研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flbrrm/r_medical_scientific_research_with_reddit/</link>
      <description><![CDATA[[R] 使用 reddit 进行医学科学研究 我想到了一个主意，我想知道它是否已经成为现实？或者这个想法是否可行、可信？因此，有很多关于疾病的子版块，成千上万的患者在使用、阅读和评论它们。如果我们对人工智能进行编程，让它针对特定疾病和病症提出一些具体问题（创建帖子），并开始从中学习（它应该已经通过所有可用的医疗数据进行了训练），它会找到新的方法或联系，还是会为疾病创造新的治疗方法？它还可以直接留言给病人，就病人的医疗背景进行长时间的交谈，并接受训练    提交人    /u/nayzerya   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flbrrm/r_medical_scientific_research_with_reddit/</guid>
      <pubDate>Fri, 20 Sep 2024 13:16:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 创造力仅来自强化学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flbmde/d_creativity_only_comes_from_reinforcement/</link>
      <description><![CDATA[Ilya 发表了一次有趣的演讲，谈到了 RL 在 LLM 或任何 AI 系统（例如国际象棋的 AlphaZero）形成创造性反应方面的作用。我想知道这是真的吗？我认为简单地在 SFT 之类的数据点之间进行插值也会很有创意。 讨论链接：https://www.youtube.com/watch?v=OPZxs6IXH00&amp;list=PLpvkFqYJXcreXgK6Cg9NVGvFANmdUczWa （第 14 分钟：00）    提交人    /u/CriticalTemperature1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flbmde/d_creativity_only_comes_from_reinforcement/</guid>
      <pubDate>Fri, 20 Sep 2024 13:09:35 GMT</pubDate>
    </item>
    <item>
      <title>叠加、相图与正则化 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flazmd/superposition_phase_diagrams_and_regularization_d/</link>
      <description><![CDATA[      大家好！我正在阅读 Anthropic 的叠加玩具模型，我强烈推荐。作者展示了小型神经网络的相图，包括理论和经验版本。然而，他们在分析中没有应用任何形式的正则化，这激起了我对叠加效应的好奇心。这激发了我尝试这个概念。 我发现这些想法非常有趣，所以我写了一篇博客文章来分享我的想法。你可以在这里查看。 虽然我的结果不如 Anthropic 得到的结果那么清晰，但我相信它们仍然值得分享。我很乐意听到您的反馈！ 以下是我帖子的要点： 我们从一个非常简单的神经网络开始： https://preview.redd.it/7okwz6njlypd1.png?width=237&amp;format=png&amp;auto=webp&amp;s=e0f39f6e7e903d9573cb432d20ff0479131e05dc 我们进行训练以尽量减少以下重建损失： https://preview.redd.it/ftk5l5nklypd1.png?width=410&amp;format=png&amp;auto=webp&amp;s=960ba69bb3b1de21d2f8b73d3a6588fb5cf3ac66 这里，λ 表示正则化强度，x_i 是输入特征，r_i 表示每个特征的相关性。每个特征都是 0 到 1 之间的数字。此外，我们引入了一个稀疏项 s。给定 s，我们将每个特征设置为 0，概率为 s。 假设我们只有两个特征，用一个数字编码（因此，(W = [w_1, w_2]))。网络的选择数量有限：  设置 w_1 = 0 和 w_2 = 0，最小化 L2 正则化。 设置 w_1 = 1 和 w_2 = 0，仅对第一个特征进行编码。 设置 w_1 = 0 和 w_2 = 1，仅对第二个特征进行编码。 设置 w_1 = 1 和 w_2 = -1（或 w_2 = -1 和 w_1 = 1），叠加两个特征。  接下来，我进行了几项实验，改变了稀疏性、正则化强度和第二个特征的相关性（例如，当 r_2 = 0 时，第二个特征可能不相关，而当 r_2 = 5 时，第二个特征的相关度可能是第一个特征的五倍）。此 GIF 显示了实验结果：  https://i.redd.it/do8erlkmlypd1.gif 我还通过计算四种情景中的每种情景的预期损失创建了相图的理论版本，我还将两个 gif 并排放在一起进行比较：  https://i.redd.it/d81150snlypd1.gif 如您所见，理论版本与经验版本有些匹配。虽然它并不完美，但正则化的效果是显而易见的；它阻止了特征的叠加。当您考虑到 (W = [-1, 1]) 的范数肯定大于 (W = [0, 1]) 或 (W = [1, 0]) 时，这是有道理的。 您觉得如何？您对改进这些数字有什么建议吗？我很想听听您的想法！    提交人    /u/f14-bertolotti   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flazmd/superposition_phase_diagrams_and_regularization_d/</guid>
      <pubDate>Fri, 20 Sep 2024 12:38:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 少数民族语言TTS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl6rrs/r_tts_for_minority_languages/</link>
      <description><![CDATA[我的客户是巴布亚新几内亚少数民族语言的翻译。该语言的名称是 Narak，是一种声调语言。有哪些资源可用于为这种语言（或任何其他少数民族语言）创建文本到语音的工具？我的客户年纪很大了，如果能让软件读取字典条目，完成字典将变得容易得多。 是的，有一个专门从事文本到语音的小组。但是，这项任务可能需要某种机器学习。    提交人    /u/SnooGoats1303   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl6rrs/r_tts_for_minority_languages/</guid>
      <pubDate>Fri, 20 Sep 2024 07:57:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2D 装箱问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl69fa/p_2d_bin_packing_problem/</link>
      <description><![CDATA[嗨！我正在研究 2D BPP，需要一些指导。有一个定义的托盘和 3 种定义的箱子。我们希望用箱子填满托盘，每次一个。每个箱子都有定义的到达概率  允许箱子旋转 我们希望最好填满托盘的周长 我们避免挤压箱子（在其他箱子之间），因为这个问题是机器人的问题，并且存在不确定性 我们必须在箱子到达时放置它们，不能跳过它们。一旦没有空间，我们就会终止  我使用启发式方法解决了这个问题，比较剩余的空间并选择最佳放置坐标。我还对周长使用了不同的搜索：通过沿着托盘周长的较大边优先填充边缘。我不知道如何将其变成学习问题并接受建议！    提交人    /u/Sea-Hovercraft4777   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl69fa/p_2d_bin_packing_problem/</guid>
      <pubDate>Fri, 20 Sep 2024 07:18:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我觉得自从 LLM API 成为现实以来，有关 ML 和 ML 产品的讨论质量急剧下降。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl5be0/d_i_feel_like_ever_since_llm_apis_have_become_a/</link>
      <description><![CDATA[完成硕士学位后，过去几年一直担任 MLE，目前在一家拥有非常聪明的同事的公司工作。问题是，我的公司没有资源来培训我们自己的 LLM，因此不得不求助于使用各种 API 来建立模型。 关于如何改进我们产品的讨论通常感觉没有成效且毫无意义。它通常会诉诸于“我们如何通过快速工程让这个 LLM（我们甚至无法控制）做这件事？” 我个人甚至不认为“快速工程”是可靠或真实的事情，并且感觉因为大多数讨论都归结于此，感觉我们也无法真正增强我们的产品。 只是想知道是否有人有同样的感受。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl5be0/d_i_feel_like_ever_since_llm_apis_have_become_a/</guid>
      <pubDate>Fri, 20 Sep 2024 06:06:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我们读过的一些研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl4bi0/r_some_research_papers_we_read/</link>
      <description><![CDATA[印度理工学院鲁尔基分校的视觉语言小组整理了 2016 年至 2024 年期间来自 NeurIPS、CVPR、ICCV、ICML 等顶级会议的深度学习研究论文的综合摘要库。这些摘要旨在让您简明扼要地了解计算机视觉、自然语言处理和机器学习等领域的有影响力的论文。该库不断扩充，并经常添加新的摘要。以下是一些值得注意的例子：  **DreamBooth：针对主题驱动生成的精细调整文本到图像扩散模型**，CVPR&#39;23  [DreamBooth 摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/DreamBooth.md) **Segment Anything**，ICCV&#39;23  [Segment Anything 摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Segment\_Anything.md) **一图胜千言：使用文本反转个性化文本到图像生成**，ICCV&#39;23  [文本反转摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Textual\_inversion.md) **照片级真实感具有深度语言理解的文本到图像扩散模型**，NIPS&#39;22  [照片级真实感扩散摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/imagen.md) **一张图片胜过 16x16 个单词：用于大规模图像识别的 Transformers**，ICLR&#39;21  [视觉 Transformer 摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Vision\_Transformer.md) **Big Bird：用于更长序列的 Transformers**，NIPS&#39;20  [Big Bird Transformers 概要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Big\_Bird\_Transformers.md)  存储库邀请社区做出贡献。如果您发现这些摘要有用，我们鼓励您提交自己的研究论文摘要。该团队旨在定期更新该集合，其中包含即将召开的会议的论文摘要以及深度学习和人工智能的关键主题。 您可以在此处访问完整的存储库并做出贡献： [Vision Language Group 论文摘要](https://github.com/vlgiitr/papers\_we\_read) 通过贡献，您将帮助使该领域的初学者和专家更容易获得高级研究。    提交人    /u/vlg_iitr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl4bi0/r_some_research_papers_we_read/</guid>
      <pubDate>Fri, 20 Sep 2024 04:59:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将 MILP 的输出纳入损失函数进行训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkuc24/d_incorporating_output_of_milp_into_loss_function/</link>
      <description><![CDATA[大家好， 我想预测互联网流量矩阵。我训练 GRU 以最小化模型输出和地面真实流量矩阵之间的 MSE。为了进一步评估模型，我将预测流量矩阵传递给路由解决方案。路由解决方案的输出是一个缩放值。为了评估模型是否是一个好的预测器，预测的 TM 应该从路由解决方案中产生一个接近地面真实流量矩阵产生的值的值。我想设计一个损失函数，将路由解决方案作为反馈纳入我的模型训练中。有什么建议吗？ 我正在考虑将路由解决方案差异添加到我的 mse 损失函数中。像这样： import torch import torch.nn as nn class TrafficMatrixLoss(nn.Module): def __init__(self, weight_mse=1.0, weight_routing=1.0): super(TrafficMatrixLoss, self).__init__() self.weight_mse = weight_mse self.weight_routing = weight_routing def forward(self, predict_tm, ground_truth_tm, routing_solution): # 计算预测流量矩阵和地面实况之间的 MSE 损失 mse_loss = nn. functional.mse_loss(predicted_tm, ground_truth_tm) # 计算预测和地面真相的路由解决方案输出 predicted_routing_value = routing_solution(predicted_tm) # 假设这返回一个标量 ground_truth_routing_value = routing_solution(ground_truth_tm) # 假设这返回一个标量 # 根据路由解决方案计算损失 routing_loss = torch.abs(predicted_routing_value - ground_truth_routing_value) # 合并损失 total_loss = (self.weight_mse * mse_loss) + (self.weight_routing *路由损失) 返回总损失    提交人    /u/mtot10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkuc24/d_incorporating_output_of_milp_into_loss_function/</guid>
      <pubDate>Thu, 19 Sep 2024 20:32:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将嵌入模型转换为法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fktvbj/p_swapping_embedding_models_for_an_llm/</link>
      <description><![CDATA[嵌入模型与语言模型的耦合程度如何？ 以 Langchain 的教程为例，他们使用 Ollama 的 nomic-embed-text 进行嵌入，使用 Llama3.1 进行理解和问答。我没有看到任何关于基于此嵌入模型的嵌入构建 Llama 的文档。 直觉表明，不同的嵌入模型可能会产生其他大小的输出或为字符/单词产生不同的张量，这会对 LLM 的结果产生影响。那么更改嵌入模型是否也需要重新训练/微调 LLM？ 我需要对代码片段和文本使用嵌入模型。我需要为此找到专门的嵌入模型吗？如果是，llama3.1 将如何提取嵌入？    提交人    /u/noobvorld   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fktvbj/p_swapping_embedding_models_for_an_llm/</guid>
      <pubDate>Thu, 19 Sep 2024 20:13:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] EMNLP 2024 成绩/通知</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkqxhh/d_emnlp_2024_results_notifications/</link>
      <description><![CDATA[一些曲目的结果似乎已经出来了，可以在 Openreview 上查看。电子邮件可能会在明天发送。  提前祝贺大家，迈阿密见！    提交人    /u/EDEN1998   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkqxhh/d_emnlp_2024_results_notifications/</guid>
      <pubDate>Thu, 19 Sep 2024 17:45:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机械可解释性论文关于 Yannic Kilcher 分歧的讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkouvg/d_mechanistic_interpretability_paper_discussion/</link>
      <description><![CDATA[      继续 Anthropic 的变压器电路系列，并作为 Yannic Kilcher discord 服务器上每日论文讨论的一部分，我将自愿领导对以下机械可解释性工作的分析 🧮 🔍 📜 叠加玩具模型，作者为 Nelson Elhage、Tristan Hume、Catherine Olsson、Nicholas Schiefer，等人。 🌐 https://transformer-circuits.pub/2022/toy_model/index.html 🕰 2024 年 9 月 19 日星期五 12:30 AM UTC // 2024 年 9 月 19 日星期五 6.00 AM IST // 2024 年 9 月 18 日星期四 5:30 PM PT 我们在本系列中讨论过的先前的机械可解释性论文： 🔬 Softmax 线性单元 🔬 情境学习和感应头 🔬 变压器电路的数学框架 加入我们一起享受乐趣吧 ~ https://ykilcher.com/discord 叠加玩具模型    提交人    /u/CATALUNA84   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkouvg/d_mechanistic_interpretability_paper_discussion/</guid>
      <pubDate>Thu, 19 Sep 2024 16:20:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] Comgra：用于分析和调试神经网络的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</link>
      <description><![CDATA[我是一名机器学习工程师和研究员。我厌倦了理解神经网络行为方式的难度，因此我编写了一个库来帮助我。 Comgra（计算图分析） 是一个可以与 pytorch 一起使用的库，用于提取您关心的所有张量数据并在浏览器中以图形方式对其进行可视化。有关它的论文已被接受为 ICML 2024 机械可解释性研讨会的焦点论文。 与通常使用 tensorboard 的方法相比，Comgra 可以对正在发生的事情进行更详细的分析。您可以在训练过程中研究张量，深入研究单个神经元，检查您特别感兴趣的单个数据集，跟踪梯度，比较不同训练运行之间的统计数据等等。 这个工具让我比平时更快地检查我的假设，并帮助我了解网络的不同部分是如何真正相互作用的，从而为我节省了大量的研究时间。    提交人    /u/Smart-Emu5581   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</guid>
      <pubDate>Thu, 19 Sep 2024 14:07:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>