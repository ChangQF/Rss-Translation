<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 05 May 2024 01:03:58 GMT</lastBuildDate>
    <item>
      <title>[P] [D] 推理时间是边缘/移动机器学习模型的重要性能指标吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckcn7b/p_d_is_inference_time_the_important_performance/</link>
      <description><![CDATA[我目前正在从事一个项目，旨在让机器学习工程师了解他们的模型在各种移动设备上的表现。 将机器学习模型嵌入应用程序并使用它们而无需任何 api/网络连接开始成为一种非常流行的做法。您可以看到大多数示例，尤其是对于大量使用计算机视觉的应用程序。将每张图像都传递到云端进行处理是不可接受的，数据量大且速度慢。随着该领域的最新改进，将 ml 模型嵌入应用程序变得更容易和更可取。 但这需要付出另一个代价。  目前有成千上万的移动设备配备了不同的芯片组，如 Qualcomm、Exynos、Snapdragon 等。它们还配备了不同的 gpu 功能，最重要的是不同的操作系统版本。 所有这些组合很可能会产生一些不确定性。我的模型的表现是否与办公室的 Android 测试手机中的表现相同？ 在一家计算机视觉和机器学习初创公司担任首席移动工程师 3 年多后，我将数十种模型嵌入到应用程序中，这个问题的答案对我来说非常清楚。不，我的模型在小米 Android 11 手机上的表现不会与在您办公室的三星 Android 13 上的表现相同。而且通常您甚至都不知道这一点。 ML 工程师将与应用环境高度隔离。他们已经可以使用云端的工具来衡量 ml 模型在准确性、召回率等方面的性能。这些都是非常非常重要的指标。但是，他们已经对此进行了衡量/评估。至于推理时间，它在很大程度上取决于它所工作的系统。让办公室里的每台移动设备都可用是不可行的。 为了解决这个问题，我们决定开发移动 SDK 和一个用于收集/可视化某些指标的平台。我们已经确定，问题的核心，最重要的指标是推理时间。 我想问一下大家，这是否有意义且合理。您认为机器学习工程师还会对其他重要指标感兴趣吗？ 我们准备的 SDK 收集所有与设备相关的元数据（可用内存、CPU 使用率、操作系统、API 级别、电池等）和推理时间参数，并显示如下图表：  操作系统与推理时间 设备型号与推理时间 单个会话中的可用内存与推理时间等     提交人    /u/orcnozyrt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckcn7b/p_d_is_inference_time_the_important_performance/</guid>
      <pubDate>Sat, 04 May 2024 22:44:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于 UI 的代理 - 下一件大事？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckb0yf/d_uibased_agents_the_next_big_thing/</link>
      <description><![CDATA[又名接口/操作系统/系统代理和 LAM。 似乎这个领域正在涌现许多新项目，对此感到好奇了解您对这些是否会持续存在的想法，人工智能代理将成为未来每个用户交互的中心。 一些示例：  francedot/Interface-Agent：InterfaceAgent：一个多功能框架，旨在创建能够管理移动和桌面应用程序及功能的系统和界面代理。 (github.com) mnotgod96/AppAgent：AppAgent：作为智能手机用户的多模式代理，基于法学硕士旨在操作智能手机应用程序的多模式代理框架。 (github.com) microsoft/UFO：用于 Windows 操作系统交互的以 UI 为中心的代理。 (github.com) OpenInterpreter/open-interpreter：计算机自然语言接口 (github .com)- microsoft/UFO：用于 Windows 操作系统交互的以 UI 为中心的代理。 (github.com)    由   提交 /u/Pretend-Map7430    reddit.com/r/MachineLearning/comments/1ckb0yf/d_uibased_agents_the_next_big_thing/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckb0yf/d_uibased_agents_the_next_big_thing/</guid>
      <pubDate>Sat, 04 May 2024 21:29:37 GMT</pubDate>
    </item>
    <item>
      <title>[D]任意维等变神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckat4d/d_anydimensional_equivariant_neural_networks/</link>
      <description><![CDATA[我发现这篇论文非常有趣。在使用 covnet 进行计算机视觉时，我们做出了与作者相同的假设。我想知道我们是否可以扩展计算机视觉用例 Abstract 传统的监督学习旨在通过将函数拟合到一组具有固定维度的输入输出对来学习未知映射。然后在相同维度的输入上定义拟合函数。然而，在许多设置中，未知映射采用任何维度的输入；示例包括在任意大小的图上定义的图参数以及在任意数量的粒子上定义的物理量。我们利用代数拓扑中新发现的现象（称为表示稳定性）来定义等变神经网络，该网络可以使用固定维度的数据进行训练，然后扩展到接受任何维度的输入。我们的方法是用户友好的，只需要网络架构和等方差组，并且可以与任何训练程序相结合。我们提供了我们方法的简单开源实现，并提供了初步的数值实验。    由   提交/u/No-Natural36  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckat4d/d_anydimensional_equivariant_neural_networks/</guid>
      <pubDate>Sat, 04 May 2024 21:19:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求个人项目的帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ck6ukv/d_seeking_assistance_with_a_personal_project/</link>
      <description><![CDATA[我目前正在参与一个使用预训练 Phi-3-mini 模型（利用 ollama 执行）的项目。在这个项目中，我将 RAG 与 ChromaDB 集成作为向量存储，并且合并了一个名为 nomic-embed-text 的本地嵌入模型。我的目标是告知 Phi-3 模型，它是为 XYZ 公司运行且具有特定目的。此外，我需要确保模型了解日常货币价值。虽然我可以每天检索这些值，但我正在寻找一种每天仅通知模型一次的方法。此外，我愿意探索矢量存储和嵌入模型的替代工具，只要它们符合项目的要求。我选择 Phi-3 是因为它适合作为此任务的小语言模型 (SLM)。   由   提交/u/SadHat4219  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ck6ukv/d_seeking_assistance_with_a_personal_project/</guid>
      <pubDate>Sat, 04 May 2024 18:22:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] Layer Normalization的几何意义</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ck599b/d_geometrical_meaning_of_layer_normalization/</link>
      <description><![CDATA[https://preview.redd.it/ws4d4qiczfyc1.png?width=639&amp;format=png&amp;auto=webp&amp;s=241e5ceb3d40157deed93e78faaee4116f07b1 95 意思减法运算如何实现将向量投影到超平面上，并同样缩放将其投影到层归一化中的超球面上？   由   提交 /u/ApartmentEither4838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ck599b/d_geometrical_meaning_of_layer_normalization/</guid>
      <pubDate>Sat, 04 May 2024 17:11:53 GMT</pubDate>
    </item>
    <item>
      <title>大型网络攻击数据集是如何制作的？ [p]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ck4ozs/how_are_large_network_attack_datasets_made_p/</link>
      <description><![CDATA[嗨，我正在开发一个用于网络入侵检测的机器学习系统。我遇到过大量的免费数据集，它们确实很有帮助，但我的项目已经到了需要创建自己的数据集的地步。我看到网络上有数百万次模拟攻击，无法想象这是手工完成的。如果有人有任何想法，我们将不胜感激。谢谢   由   提交 /u/OpeningDirector1688   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ck4ozs/how_are_large_network_attack_datasets_made_p/</guid>
      <pubDate>Sat, 04 May 2024 16:46:48 GMT</pubDate>
    </item>
    <item>
      <title>一款多代理游戏，LLM 必须像人类一样互相欺骗，直到有人被抓住 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ck1d7w/a_multiagent_game_where_llms_must_trick_each/</link>
      <description><![CDATA[      分享我上周参与的一个有趣的小随机项目，在该项目中，我让多个法学硕士假装成人类进行互动……   由   提交 /u/AvvYaa   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ck1d7w/a_multiagent_game_where_llms_must_trick_each/</guid>
      <pubDate>Sat, 04 May 2024 14:18:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 目前的可靠性如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ck0tnk/d_how_reliable_is_rag_currently/</link>
      <description><![CDATA[我猜RAG的本质是关于  根据提示检索相关文档 将文档放入上下文窗口  数字2非常直接，而数字1是我认为更多重要事情发生的地方。 IIRC，大多数情况下，我们在提示嵌入和文档嵌入之间进行相似性搜索，并检索 k 个最相似的文档。 好的，此时我们有 k 个文档并将它们放入上下文中。现在是时候让 LLM 根据我的提示和 k 个文档给出答案了，鉴于检索到了正确的文档，一个好的 LLM 应该能够做到这一点。 我尝试做一些业余爱好项目与 LlamaIndex 但没有让它工作得那么好。例如，我尝试使用 NFL 统计数据作为我的数据（每个球员一行，每个特征一列），并希望 GPT-4 与这些文档一起能够正确回答我至少 95% 的问题，但它更像是70%，这非常糟糕，因为我觉得这是一个相当基本的项目。问题是“球员 x 在 y 赛季完成了多少次达阵”。答案各不相同，从正确到说信息不可用，再到产生错误答案的幻觉。 希望我只是以次优的方式做某事，但这让我想到 RAG 的使用有多么广泛在世界各地生产。市场上有哪些成功利用 RAG 的应用程序？我假设像 perplexity.ai 这样的东西正在使用它，当然还有所有其他以某种方式使用浏览的聊天机器人。提到的一个明显的应用程序通常是嵌入公司文档，然后拥有一个使用 RAG 的内部聊天机器人。它部署在任何地方吗？在我的公司没有，但我可以看到它很有用。 基本上，RAG 主要是理论上听起来不错并且目前正在大肆宣传的东西，还是实际上在世界各地的生产中使用的东西？&lt; /p&gt;   由   提交/u/lapurita  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ck0tnk/d_how_reliable_is_rag_currently/</guid>
      <pubDate>Sat, 04 May 2024 13:52:33 GMT</pubDate>
    </item>
    <item>
      <title>[N] DIAMBRA Arena 的新挑战：我们的 RL 环境阵容中新增了 3 个史诗级内容！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ck0hp6/n_new_challenges_in_diambra_arena_3_epic/</link>
      <description><![CDATA[   /u/DIAMBRA_AIArena   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ck0hp6/n_new_challenges_in_diambra_arena_3_epic/</guid>
      <pubDate>Sat, 04 May 2024 13:35:25 GMT</pubDate>
    </item>
    <item>
      <title>[R]线性时间序列预测模型分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjy2d9/r_an_analysis_of_linear_time_series_forecasting/</link>
      <description><![CDATA[我们关于分析线性时间序列预测模型的工作已被 ICML 接受。 ArxiV：https://arxiv.org/abs/2403.14587 摘要： 尽管线性模型很简单，但它在时间序列预测方面表现良好，即使与更深层、更昂贵的模型相比也是如此。已经提出了许多线性模型的变体，通常包括某种形式的特征规范化，以提高模型的泛化能力。在本文中，我们分析了使用这些线性模型架构可表达的函数集。通过这样做，我们表明，用于时间序列预测的几种流行的线性模型变体是等效的，并且在功能上与标准的无约束线性回归没有区别。我们描述了每个线性变体的模型类。我们证明，每个模型都可以重新解释为适当增强的特征集上的无约束线性回归，因此在使用均方损失函数时可以得到闭式解。我们提供实验证据，证明受检模型学习到几乎相同的解，并最终证明更简单的闭式解在 72% 的测试设置中是更优秀的预测器。 摘要 几部流行的著作认为线性回归足以进行预测（DLinear 和 FIT 是适合挑剔读者的例子）。事实证明，如果您进行数学运算，这些模型本质上是等效的。我们进行数学运算和实验。也许最有趣的是：普通最小二乘法 (OLS) 解几乎总是比使用梯度下降训练的其他线性模型更好。重要的是：我们没有进行超参数搜索来设置正则化系数等。我们将其保留以备将来的工作。 OLS 非常高效 - 如果设置正确，模型可以在几毫秒内拟合完成。 最后，尽管我们不会竭尽全力来展示这一点：我们的许多结果都优于大型复杂模型，但这引出了一个问题：此类模型何时何地有效。    提交人    /u/Gramious   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjy2d9/r_an_analysis_of_linear_time_series_forecasting/</guid>
      <pubDate>Sat, 04 May 2024 11:24:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI 模型中的“它”真的只是数据集吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjxh9u/d_the_it_in_ai_models_is_really_just_the_dataset/</link>
      <description><![CDATA[   /u/vijayabhaskar96   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjxh9u/d_the_it_in_ai_models_is_really_just_the_dataset/</guid>
      <pubDate>Sat, 04 May 2024 10:47:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 的首次令牌时间 (TTFT) 分析 (10B-34B)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjvqg9/d_analysis_of_time_to_first_token_ttft_of_llms/</link>
      <description><![CDATA[嘿伙计们， 最近花时间测量了各种大型语言模型 (LLM) 的首次令牌时间 (TTFT)部署在 Docker 容器中，结果非常有趣。对于那些不知道的人，TTFT 测量从发送查询到收到第一个响应的速度。以下是主要发现：  跨令牌大小的性能： 像 Triton-vLLM 和 vLLM 这样的库速度非常快（约 25 毫秒），令牌较少，但速度显着减慢（200-300 毫秒）有更多令牌。当您增加令牌数量时，CTranslate-2 和 Deepspeed-mii 也会减慢速度。然而，即使使用更多令牌，vLLM 也能保持快速高效。 处理大输入：像 Deepspeed-mii、vLLM、TGI 和 Triton-vLLM 这样的库可以处理更多令牌但你推得越多，速度就越慢。这表明在扩展过程中存在一些挑战。 最佳代币响应：虽然在 100 个代币之前一切都运行顺利，但在 500 个代币之后性能就会下降。最快响应的理想令牌数量似乎约为 20 个，时间范围约为 25 到 60 毫秒，具体取决于模型。  https://preview.redd.it/6n03xwbqddyc1.jpg?width=1600&amp;format=p jpg&amp;自动= webp&amp;s=9464d6f85a2cdab685fc8e7cd7031a85600f00c1 这些发现可能会帮助您选择正确的模型和库并设定您的期望。 热衷于了解是否有人测试过 TTFT 或已经有关库性能的提示！   由   提交/u/rbgo404  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjvqg9/d_analysis_of_time_to_first_token_ttft_of_llms/</guid>
      <pubDate>Sat, 04 May 2024 08:41:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 您已交付的客户项目示例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjqdmp/p_d_examples_of_client_projects_that_you_have/</link>
      <description><![CDATA[简短版本：给我一些 ML 领域客户可交付成果的示例。将有助于判断我开始自由咨询的立场。 嗨，我是一名 SWE，同时学习 ML。我的日常工作并没有太多接触 ML，但接触了很多 GPU 的东西。我开始学习 ML，目前正处于可以实现研究论文中的一些模型的阶段。  寻找现实世界中的一些示例，您已成功为客户完成了哪些可交付成果。  这将极大地帮助了解我在从事全职咨询方面的立场。  在这个庞大模型的时代，创办一家独立咨询公司是否有意义？   由   提交 /u/SmallTimeCSGuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjqdmp/p_d_examples_of_client_projects_that_you_have/</guid>
      <pubDate>Sat, 04 May 2024 03:00:16 GMT</pubDate>
    </item>
    <item>
      <title>[N] 人工智能工程师报告称，科技行业为了保持竞争力而进行的“激烈竞争”导致了职业倦怠和仓促推出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjdmr5/n_ai_engineers_report_burnout_and_rushed_rollouts/</link>
      <description><![CDATA[AI 工程师报告称，为了保持竞争力，科技行业陷入“老鼠赛跑”的局面，导致他们精疲力竭和仓促推出产品 文章摘要：  顶级科技公司的人工智能工程师告诉 CNBC，以极快的速度推出人工智能工具的压力已经决定了他们的工作。 他们说，他们的大部分工作都是为了安抚投资者，而不是为最终用户解决问题，而且他们经常追逐 OpenAI。 倦怠是一个越来越普遍的主题，因为人工智能工作者表示，他们的雇主在开展项目时不考虑该技术对气候变化、监控的影响以及其他潜在的现实世界危害。  文章中一段特别令人心酸的引述：  一位在零售监控初创公司工作的 AI 工程师告诉 CNBC，他是一家 40 人公司的唯一 AI 工程师，他负责与 AI 相关的任何责任，这是一项艰巨的任务。他说，该公司的投资者对 AI 的能力有不准确的看法，经常要求他构建某些“我不可能实现”的东西。     提交人    /u/bregav   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjdmr5/n_ai_engineers_report_burnout_and_rushed_rollouts/</guid>
      <pubDate>Fri, 03 May 2024 16:58:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>