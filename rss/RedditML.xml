<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 16 Jan 2025 15:16:38 GMT</lastBuildDate>
    <item>
      <title>[D] 边缘论文 - 策略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2r1k7/d_borderlineish_papers_strategy/</link>
      <description><![CDATA[我提交的几篇论文的理想策略是什么。我会总结审稿人的反馈，如果你能指导我这个缺乏经验的人，我将不胜感激。本质上你会怎么做？ 论文 1：已提交 ICLR 评论：6655533 一般反馈： - 非常新颖的方法 - 应用贡献 / 明确的影响范围 - 准确度差（比 SOTA 差约 10%） - 写作不好（图形 / 结构 / 流程不清楚）  有能力通过改进最初提出的方法来解决准确性问题。但是相信改进是如此新颖，以至于可以构成另一篇论文。此外，包括它将使页数增加 20 页。它是相邻领域的一种全新算法和技术，对当前算法和技术有影响。   论文 2：已提交 NeurIPS 评论：糟糕哈哈 总体反馈：- 方法清晰/数学正确 - 需要更好地解释新颖性 -&gt; 已修复并得到审稿人的认可，但 AC 认为在动机方面需要更多 - 写作一般 - 应该使用更多应用/真实世界的数据集（最大的抱怨） 如果这是你，你会怎么做？我非常想把这些不加修复地扔到 ICML 研讨会上，希望它能进入并继续前进。还有沉没成本谬论……    提交人    /u/random_eecs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2r1k7/d_borderlineish_papers_strategy/</guid>
      <pubDate>Thu, 16 Jan 2025 15:11:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] Virgo：再现o1类MLLM的初步探索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2qmdf/r_virgo_a_preliminary_exploration_on_reproducing/</link>
      <description><![CDATA[      TL;DR：基于 Qwen2-VL-72B 构建的推理多模态模型。令人惊讶的是，它在评估中击败了 QVQ。 论文： https://arxiv.org/pdf/2501.01904 摘要：  最近，基于大型语言模型 (LLM) 构建的慢思考推理系统通过延长推理过程中的思考时间而引起了广泛关注。人们对将此功能应用于多模态大型语言模型 (MLLM) 的兴趣也日益浓厚。鉴于 MLLM 处理跨不同模态的更复杂的数据语义，实现多模态慢思考系统在直观上更具挑战性。 为了解决这个问题，在本文中，我们探索了一种简单的方法，即使用少量文本长格式思维数据对功能强大的 MLLM 进行微调，从而形成一个多模态慢思考系统 Virgo（长思考的视觉推理）。我们发现，这些用自然语言表达的长格式推理过程可以有效地转移到 MLLM。此外，似乎这种文本推理数据在引出 MLLM 的慢思考能力方面甚至比视觉推理数据更有效。虽然这项工作还处于初步阶段，但它表明慢思考能力从根本上与语言模型组件相关，可以跨模态或领域转移。可以利用这一发现来指导开发更强大的慢思考推理系统。我们在此 https URL上发布了我们的资源。  亮点：  我们从两个开放的慢思考推理系统中提炼出大约 5K 个长思维指令实例：DeepSeek-R1-Lite-Preview [2]（缩写为 R1）和 QwQ-32B-preview [3]（缩写为 QwQ）。收集到的指令数据统计按领域分类如下：数学（3.7K）、科学（0.9K）、代码（0.2K）和谜题（0.1K）。[...] 在收集长篇推理的指令数据后，我们对基础 MLLM 进行微调，以模拟慢思考推理行为。 [...] 我们探索的第二种方法是直接从慢速思考 MLLM（例如 QVQ）中提炼多模态长思考数据。[...] 作为另一种替代方法，我们设计了一种用于自我提炼的多阶段调整方法。具体来说，我们首先在文本长思考指令集 DT 上微调选定的 MLLM（即 Qwen2-VL-72B-Instruct），获得模型 M0。接下来，我们使用 M0 通过自蒸馏 DSD 生成视觉长思维指令集，随后可以将其用于对原始 MLLM 进行微调。  视觉亮点： https://preview.redd.it/2o4v0y2tcdde1.png?width=1123&amp;format=png&amp;auto=webp&amp;s=b3ac8bbb69248d8c326a73553cbccb0c5ab12d46 https://preview.redd.it/j3wyeg0ucdde1.png?width=967&amp;format=png&amp;auto=webp&amp;s=98b2ca3dedb6c99c078491e67e53df6343f074c3 https://preview.redd.it/m6385vuucdde1.png?width=1191&amp;format=png&amp;auto=webp&amp;s=4447b132fb7484d1375403916c3dcd8a9c2b8e17 如果你问我，看起来有点混乱    提交人    /u/StartledWatermelon   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2qmdf/r_virgo_a_preliminary_exploration_on_reproducing/</guid>
      <pubDate>Thu, 16 Jan 2025 14:52:46 GMT</pubDate>
    </item>
    <item>
      <title>[D]Agentic AI 会是下一个大趋势吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2qenu/dare_agentic_ai_the_next_big_trend_or_no/</link>
      <description><![CDATA[我们公司有一个人，他引用了 Forrester 公司的话，说 Agentic AI 将成为技术领域的下一个大趋势。我觉得现在这个领域变得越来越拥挤和嘈杂（只有我！！！）。此外，我认为由于自动化，这种噪音会迅速增长。但这确实值得研究和实施，他听起来像是肯定的。 你们怎么看？    提交人    /u/Brilliant-Gur9384   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2qenu/dare_agentic_ai_the_next_big_trend_or_no/</guid>
      <pubDate>Thu, 16 Jan 2025 14:42:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态思维可视化：通过视觉思维增强 MLLM 推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2q6t9/r_multimodal_visualizationofthought_enhancing/</link>
      <description><![CDATA[这里的关键创新是将大型语言模型与图像生成相结合，以创建一个可以在解决问题时“视觉思考”的系统。这种方法称为多模态思维可视化 (MVoT)，它在推理过程中生成相关的可视化效果，类似于人类绘制图表以更好地理解问题的方式。 主要技术要点： - 系统架构将 LLM 与图像生成模型集成以进行推理 - 使用空间语义对齐来确保生成的视觉效果与推理步骤相匹配 - 实现一个迭代过程，其中每个推理步骤都可以触发可视化 - 通过多模态思维链保持视觉和文本表示之间的一致性 结果： - 与基线​​方法相比，视觉推理基准提高了 12% - 在涉及空间关系的任务上表现特别出色 - 生成的可视化效果与推理步骤明显一致 - 适用于不同组合的语言和图像生成模型 我认为这种方法可以显著提高人工智能系统推理物理和空间问题的能力。通过将视觉思维融入推理过程，我们可能会看到人类通常通过可视化解决的任务（从物理问题到建筑设计）表现更好。然而，在推理过程中生成图像的计算开销可能会限制实际应用。 我认为最有趣的方面是它如何模仿人类的认知过程——我们经常通过素描或可视化来理解复杂的问题。这可能导致人工智能系统以更直观和可解释的方式进行推理。 TLDR：新方法将语言模型与图像生成相结合，以创建可以在推理时“进行视觉思考”的人工智能系统，在视觉推理任务上显示出 12% 的改进。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2q6t9/r_multimodal_visualizationofthought_enhancing/</guid>
      <pubDate>Thu, 16 Jan 2025 14:31:58 GMT</pubDate>
    </item>
    <item>
      <title>带有 MLP 混频器的 CIFAR 100。[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2nu5q/cifar_100_with_mlp_mixer_p/</link>
      <description><![CDATA[最近参加了一场黑客马拉松，任务是在不使用卷积和变换器模型的情况下实现高精度。尽管 mlp 混合器可以说与卷积相似，但它们是允许的。即使经过多次尝试，我也无法将准确率提高到 60% 以上。有没有办法用 mlp 或其他任何东西来达到 90% 左右的准确率。    提交人    /u/Abbe_Kya_Kar_Rha_Hai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2nu5q/cifar_100_with_mlp_mixer_p/</guid>
      <pubDate>Thu, 16 Jan 2025 12:30:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最佳文本转声音效果模型（MIT 许可证或同等许可证）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2n50v/d_best_texttosoundeffects_model_mit_license_or/</link>
      <description><![CDATA[大家好！我一直在寻找 MIT（商业上可用的）文本转声音效果（Text-to-Audio）模型，除了传统的稳定 Audio-Open（带有特殊许可证）之外，没有找到太多模型。 您知道其他的吗？    提交人    /u/Leather-Arm-2466   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2n50v/d_best_texttosoundeffects_model_mit_license_or/</guid>
      <pubDate>Thu, 16 Jan 2025 11:46:16 GMT</pubDate>
    </item>
    <item>
      <title>这个 reddit 上的好心人曾使用过同一型号的多个适配器，请用你们的智慧指导我 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2mcy1/good_people_of_this_reddit_who_worked_with/</link>
      <description><![CDATA[如何处理为不同任务创建的多个适配器？我理解基于任务 ID 的适当适配器的动态加载是显而易见的，但有没有更好的方法？我特别要求耳语    提交人    /u/YogurtclosetAway7913   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2mcy1/good_people_of_this_reddit_who_worked_with/</guid>
      <pubDate>Thu, 16 Jan 2025 10:54:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] AutoResearch：一种新的开源 LLM 驱动的研究自动化工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2lk5n/p_autoresearch_a_new_opensource_llmdriven/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2lk5n/p_autoresearch_a_new_opensource_llmdriven/</guid>
      <pubDate>Thu, 16 Jan 2025 09:55:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 泰坦：一个新的开创性的建筑发展？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2l0ey/d_titans_a_new_seminal_architectural_development/</link>
      <description><![CDATA[对他们的工作的最初印象是什么？它能改变游戏规则吗？这能多快融入新产品？期待对话！    提交人    /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2l0ey/d_titans_a_new_seminal_architectural_development/</guid>
      <pubDate>Thu, 16 Jan 2025 09:12:27 GMT</pubDate>
    </item>
    <item>
      <title>对 NSFW 文本进行分类的最佳方法 - BERT、小型 LLM（如 llama 3.2 3B）还是其他？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2h315/best_way_to_classify_nsfw_text_bert_small_llm/</link>
      <description><![CDATA[我正在做一个项目，需要将文本分类为 nsfw 或 sfw。我知道有一些基于 BERT 的分类器专门针对此类任务进行训练。我也见过有人使用较小的 LLM。 最好的方法是什么？由于检测 NSFW 文本的底层复杂性并不高，我认为也许全面的 LLM 有点过头了。你有什么建议？    提交人    /u/newyorkfuckingcity   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2h315/best_way_to_classify_nsfw_text_bert_small_llm/</guid>
      <pubDate>Thu, 16 Jan 2025 04:38:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在空间中一边想象一边推理：思维的多模态可视化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i279gb/r_imagine_while_reasoning_in_space_multimodal/</link>
      <description><![CDATA[摘要： 思维链 (CoT) 提示已被证明对于增强大型语言模型 (LLM) 和多模态大型语言模型 (MLLM) 中的复杂推理非常有效。然而，它在复杂的空间推理任务中却举步维艰。尽管如此，人类的认知不仅限于语言，还具有用文字和图像思考的非凡能力。受此机制的启发，我们提出了一种新的推理范式，即多模态思维可视化 (MVoT)。它通过生成其推理轨迹的图像可视化来实现 MLLM 中的视觉思维。为了确保高质量的可视化，我们在自回归 MLLM 中引入了标记差异损失。这项创新显着提高了视觉连贯性和保真度。我们通过几个动态空间推理任务验证了这种方法。实验结果表明，MVoT 在各个任务中都表现出了竞争力。此外，它在 CoT 失败的最具挑战性的场景中表现出稳健可靠的改进。最终，MVoT 为复杂的推理任务建立了新的可能性，在这些任务中，视觉思维可以有效地补充语言推理。 Arxiv 链接：https://arxiv.org/pdf/2501.07542    提交人    /u/imadade   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i279gb/r_imagine_while_reasoning_in_space_multimodal/</guid>
      <pubDate>Wed, 15 Jan 2025 20:43:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我如何发现并修复微软 Phi-4 模型中的 4 个错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i23zbo/p_how_i_found_fixed_4_bugs_in_microsofts_phi4/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i23zbo/p_how_i_found_fixed_4_bugs_in_microsofts_phi4/</guid>
      <pubDate>Wed, 15 Jan 2025 18:22:48 GMT</pubDate>
    </item>
    <item>
      <title>Kaggle 数据集：其中一个输入特征与目标的相关性 >0.99，但大多数/所有笔记本（20+）并不关心？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i210hp/kaggle_dataset_one_of_the_input_features_has_a/</link>
      <description><![CDATA[此数据集（不会链接到这里，因为我不想与我的 kaggle 和 reddit 关联）包含一些输入特征（5-6）用于预测一个目标值。 但其中一个特征基本上与目标 (&gt;0.99) 完全线性相关。 一个例子是来自只有一种卡车型号的卡车运输公司的数据： 目标：卡车燃油消耗量/年特征：驾驶员年龄、轮胎类型、卡车年龄、行驶距离/年 显然，平均燃油消耗量与行驶里程数成线性比例。我的意思是，通常您只需使用它来计算燃油/距离等新目标。 然而，没有一个人/笔记本做过这种规范化。因此，每个人的模型都有 &gt;.99 的准确率，因为这个特征淹没了其他所有特征。 其他人是否注意到了这一点：代码看起来越来越好（数据加载、训练多种类型的模型），这可能要归功于 LLM。但决策过程往往很糟糕？    提交人    /u/ToThePastMe   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i210hp/kaggle_dataset_one_of_the_input_features_has_a/</guid>
      <pubDate>Wed, 15 Jan 2025 16:17:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 12 Jan 2025 16:00:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>