<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 26 Dec 2024 15:16:24 GMT</lastBuildDate>
    <item>
      <title>[R] 通过优化内存管理在单个消费者 GPU 上微调 175B 参数语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmpck4/r_finetuning_175b_parameter_language_models_on_a/</link>
      <description><![CDATA[这里的关键技术进步是通过巧妙的内存管理和 NVMe SSD 利用率在单个消费级 GPU 上实现 100B 参数模型的微调。研究人员开发了一个框架，可在保持训练质量的同时优化 GPU、CPU RAM 和存储之间的数据移动。 主要技术贡献：- 为消费级硬件实现修改后的 ZeRO-Infinity 优化- 具有动态参数卸载的三层内存层次结构- 可减少内存访问延迟的新型预取系统- 优化存储层之间的数据传输模式- 跨 GPU/CPU/NVMe 的内存带宽管理 主要结果：- 与现有的单 GPU 方法相比，速度提高了 2.6 倍- 所需 GPU 内存减少 70%- 成功微调 100B 参数模型- 与多 GPU 设置相当的训练质量- 在消费级硬件配置上进行了验证 我认为这可以让个人研究人员和小型实验室更容易进行大型模型微调。虽然它不会在生产场景中取代多 GPU 训练，但它可以快速进行原型设计和实验，而无需昂贵的硬件集群。这里的技术还可以为未来内存高效的训练方法提供参考。 权衡似乎是合理的——较慢的训练换来大幅降低成本。但是，我希望看到对不同模型架构和训练任务进行更广泛的测试，以充分验证该方法。 TLDR：新框架通过优化的内存管理和 NVMe 利用率，可以在单个消费者 GPU 上微调 100B 参数模型，与现有方法相比，速度提高了 2.6 倍。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmpck4/r_finetuning_175b_parameter_language_models_on_a/</guid>
      <pubDate>Thu, 26 Dec 2024 14:25:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] “激活工程”能否取代提示工程或微调作为操纵模型的技术？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmjdh3/d_could_activation_engineering_replace_prompt/</link>
      <description><![CDATA[如果您不知道，激活工程只是一个流行词，用于操纵 LLM 中的激活向量来控制其行为。一个著名的例子是“金门克劳德”，其中人类工程师上调了代表模型潜在空间中“金门大桥”概念的神经元。这样做之后，该模型开始将金门大桥编织到其所有响应中，甚至开始将自己识别为金门大桥。 目前，这种可解释性工作主要存在于文献中，但我很好奇您是否预计“激活工程”的真正工具会成为主流。您如何看待未来的转向模型？    提交者    /u/jsonathan   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmjdh3/d_could_activation_engineering_replace_prompt/</guid>
      <pubDate>Thu, 26 Dec 2024 07:22:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每个人都对 LLM 如此感兴趣，但 Transformer 架构能否用于改进更“传统”的机器学习领域</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmitcz/d_everyone_is_so_into_llms_but_can_the/</link>
      <description><![CDATA[我正在考虑诸如推荐算法之类的东西，这些算法依赖于无监督学习或许多其他无监督算法 我会更深入地研究它，但也许想对此有一些想法    提交人    /u/noithatweedisloud   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmitcz/d_everyone_is_so_into_llms_but_can_the/</guid>
      <pubDate>Thu, 26 Dec 2024 06:40:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 物理学和逻辑学的结合最近取得了什么进展？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmds2k/dhow_have_recent_advancements_with_incorporating/</link>
      <description><![CDATA[去年，关于这项技术将带来的承诺，曾有过大量讨论，但之后就没有什么进展了。    由    /u/sext-scientist  提交  [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmds2k/dhow_have_recent_advancements_with_incorporating/</guid>
      <pubDate>Thu, 26 Dec 2024 01:28:20 GMT</pubDate>
    </item>
    <item>
      <title>太字节级 MoE：一种用于超越 RAM 模型推理的学习型按需专家加载和智能缓存框架 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm93jj/terabytescale_moes_a_learned_ondemand_expert/</link>
      <description><![CDATA[大型模型很容易装入硬盘，但很难装入 RAM 或 VRAM。以下是我解决这个问题的想法： 在 RAM 中训练一个包含所有专家的大型混合专家模型，然后在推理时，一个学习机制会动态地将相关专家加载到 VRAM/RAM 中。这允许模型超出硬件的内存限制，同时保持推理效率，因为系统本身学习哪些专家需要“热门”并避免不必要的交换。当然，交换仍然会发生，但希望很少发生。 已经尝试过类似的事情了吗？    提交人    /u/thepok   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm93jj/terabytescale_moes_a_learned_ondemand_expert/</guid>
      <pubDate>Wed, 25 Dec 2024 21:09:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 教 VLM 通过读写任务将手写图像转换为数字墨水</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm8a6s/r_teaching_vlms_to_convert_handwritten_images/</link>
      <description><![CDATA[InkSight：通过学习阅读和书写实现离线到在线手写转换 项目页面 | 模型发布 | Google 研究博客 TLDR： 通过教授视觉语言模型进行阅读和书写，我们能够弥合传统手写和数字墨水之间的差距，提供通过盲目研究评估的高质量数字描摹，其中 87% 被判定为有效， 67% 与人类生成的墨水无法区分。 消融研究强调了识别（“阅读”）任务在确保语义一致性方面的重要性，而推理策略则展示了处理模糊笔迹的灵活性。此外，使用去渲染墨水作为训练数据与真实世界数据集结合可增强手写识别，将字符错误率降低至 4.6%。这些发现展示了 InkSight 在推进手写数字化和识别系统方面的潜力。    提交人    /u/CharlieLee666   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm8a6s/r_teaching_vlms_to_convert_handwritten_images/</guid>
      <pubDate>Wed, 25 Dec 2024 20:26:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 精神障碍的 sMRI 或 fMRI 扫描公共数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm7bfe/r_public_datasets_of_smris_or_fmris_scans_of/</link>
      <description><![CDATA[我目前正在大学里做一个研究项目，明年 7 月我将提交该项目。该项目目前处于起步阶段，基础才刚刚开始奠定，因为我必须开始收集用于训练模型的数据，但基本思路已经基本确定。我在这种类型的研究中有一些经验，因为我已经使用 Vision Transformer 训练了一个深度学习模型，它可以实时区分 ASL 字母表的手势。 但是，根据我目前所做的研究（我还需要做很多研究），似乎其中一些数据集具有一种特殊的文件格式 (.nii)，需要特殊的预处理。该项目的范围非常灵活，因为我可以根据互联网上公开的数据类型定义标签。由于我在这个领域还比较新，我不知道你们中是否有人已经研究过这个主题并训练过与此相关的模型。如果您愿意，非常感谢您能提供一些指导，并且如果当前可用的数据集（如 ADHD-200 或 SchizoConnect 中的数据集）的数据良好。谢谢。    提交人    /u/MessierKatr   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm7bfe/r_public_datasets_of_smris_or_fmris_scans_of/</guid>
      <pubDate>Wed, 25 Dec 2024 19:34:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 无编码器视觉语言模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm6qpu/d_encoder_free_vision_language_models/</link>
      <description><![CDATA[节日快乐！有没有关于无编码器 VLM 的有趣论文？最近在看视频 VLM，最大的麻烦是编码器效率。此外，端到端质量在很大程度上受限于视觉编码器的质量，而视觉编码器通常是 CLIP 样式模型。有 Fuyu 模型系列，但这种架构似乎表现不佳。最近有一篇 NeurlPS 论文：https://github.com/baaivision/EVE 看起来很有趣。期待对这个工作方向的评论和建议。    提交人    /u/encoreway2020   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm6qpu/d_encoder_free_vision_language_models/</guid>
      <pubDate>Wed, 25 Dec 2024 19:04:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 不确定如何可视化 RL 图？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm6nga/p_not_sure_how_to_visualize_rl_diagram/</link>
      <description><![CDATA[      我想我找到了下面问题第一部分的正确解决方案，但第二部分我遇到了麻烦。有人知道流程图实际上是什么样子吗？有人可以提供一张快速图像吗？非常感谢！ 想一个简单的游戏： a. 每一轮，你可以继续或退出。 b. 如果你退出，你会得到 5 美元，游戏结束。 c. 如果你继续，你会得到 3 美元并掷一个 6 面的骰子。如果骰子点数为 1 或 2，游戏将结束。否则，游戏继续进行下一轮。 这里有一个明显的权衡。首先，我们可以用 2 美元的确定性收益来换取掷骰子并继续下一轮的机会。 要创建 MDP 来模拟这个游戏，首先我们需要定义一些东西： 我们可以正式将马尔可夫决策过程描述为 m = (S, A, P, R, gamma)，其中： - S 表示所有状态的集合。 - A 表示可能的操作集合。 - P 表示转移概率。 - R 表示奖励。 - Gamma 被称为折扣因子。在这种情况下，折扣因子为 2/3。 https://preview.redd.it/15xthh3dl19e1.jpg?width=556&amp;format=pjpg&amp;auto=webp&amp;s=00c68fa27076a591cede12d1d90fb8ebdd405706 问题 1：完成下图中 P1、P2 和 P3 的概率值，该图显示了上述场景的 MDP。另外，说明奖励 R1 和 R2 的值。红色箭头表示每种可能情况的概率，绿色框表示奖励。 我的答案：P1、P2 和 P3 的转换概率值包括： P1​：掷出 3、4、5 或 6 的概率，从而继续游戏 = 4/6 = 0.67 P2​：掷出 1 或 2 的概率，从而结束游戏 = 2/6 = 0.33 P3​：选择退出操作时退出的概率 = 1（确定性） 奖励值包括： R1​：继续的奖励（每轮）= 3 R2​：退出奖励 = 5   问题 2：现在考虑折扣因子。在上述 MDP 中有两种可能的状态，继续和退出。在每一步中，我们要么退出并获得额外的 5 美元预期值，要么留下并获得额外的 3 美元预期值。每个新回合，预期值乘以 2/3，即折扣因子。绘制流程图以显示 4 轮后两种状态的总奖励是多少。还要确定一系列动作（例如：继续-&gt;继续-&gt;退出等），以显示 4 轮后奖励的最大化。 不确定？     提交人    /u/Pale-Head-3910   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm6nga/p_not_sure_how_to_visualize_rl_diagram/</guid>
      <pubDate>Wed, 25 Dec 2024 19:00:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据采样的聚类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm30h6/d_clustering_for_data_sampling/</link>
      <description><![CDATA[我正在开展一个 OCR 项目，需要手动为其注释数据。我认为我需要收集尽可能多视觉变化的页面样本，并且我想自动进行采样。 我认为我可以使用预训练的神经网络从每个页面中提取特征，并避免包含具有相似特征的页面。我认为这可以通过某种形式的聚类来实现，然后我会从每个聚类中抽样一次。 我的问题是：  这是一种有效的抽样方式吗？它有名字吗？ 我正在考虑使用 k-means，但它可以以在线方式完成吗？这样我以后可以添加新页面而不会弄乱以前的聚类，但仍然能够添加新聚类？  谢谢，节日快乐！    提交人    /u/neuralbeans   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm30h6/d_clustering_for_data_sampling/</guid>
      <pubDate>Wed, 25 Dec 2024 15:47:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] JaVAD——又一款语音活动检测器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hlz6az/p_javad_just_another_voice_activity_detector/</link>
      <description><![CDATA[刚刚发布了我在过去 3 个月内研究的一个 VAD（不计算模型本身的时间），它看起来至少与其他开源 VAD 相当或更好。  它是一个自定义的基于卷积的架构，在梅尔频谱图上使用滑动窗口，因此速度也非常快（在 3090 上需要 16.5 秒来加载和处理来自测试集的 18.5 小时的音频）。 它也非常紧凑（包括检查点在内的所有内容都适合 PyPI 包），如果你不需要加载音频，核心功能依赖只是 pytorch 和 numpy。 其他一些 VAD 是通过混合语音和噪音在合成数据上进行训练的，我认为这就是它们在嘈杂音频上落后的原因。对于这个项目，我手动标记了数十个 YouTube 视频，特别是老电影和电视节目，其中有很多噪音。 还有一个用于流媒体的类，尽管由于滑动窗口和规范化的性质，处理音频的初始部分可能会导致较低质量的预测。 MIT 许可证  这是一个个人项目，所以我很确定我错过了一些东西（或者很多），请随时在 github 上发表评论或提出问题。 这是链接：https://github.com/skrbnv/javad    提交人    /u/ApprehensiveLet1405   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hlz6az/p_javad_just_another_voice_activity_detector/</guid>
      <pubDate>Wed, 25 Dec 2024 11:33:57 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 推荐系统中隐式反馈的 SOTA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hlyy4i/discussion_sota_for_implicit_feedback_in/</link>
      <description><![CDATA[在处理大量隐式观察以推荐内容/金融工具等方面的行业标准和最新进展是什么？ 据我所知，有几篇关于这个主题的重要论文（不包括更知名的算法，如 SVD++）： Spotify： 隐式反馈数据的逻辑矩阵分解 AT&amp;T 隐式反馈数据集的协同过滤 我很想知道是否还有其他方法在 Netflix 基准上表现良好（当有评级时仅取 1，否则取 0 而不是评级）本身）。    由   提交  /u/Illustrious-Bag2386   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hlyy4i/discussion_sota_for_implicit_feedback_in/</guid>
      <pubDate>Wed, 25 Dec 2024 11:15:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们可以不要再在标题中使用“这就是我们所需要的”吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hlbtrs/d_can_we_please_stop_using_is_all_we_need_in/</link>
      <description><![CDATA[正如标题所示。我们需要停止或减少在论文标题中使用“......就是我们所需要的”。它慢慢变得有点荒谬。大多数时候它没有实际的科学价值。它已经成为一种为了吸引注意力而吸引注意力的不良做法。    提交人    /u/H4RZ3RK4S3   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hlbtrs/d_can_we_please_stop_using_is_all_we_need_in/</guid>
      <pubDate>Tue, 24 Dec 2024 11:37:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>