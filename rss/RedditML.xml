<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 10 Nov 2024 01:18:34 GMT</lastBuildDate>
    <item>
      <title>[N] ARC 奖项为解决网格上彩色方块组成的谜题的少样本学习提供 60 万美元奖金。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnnstd/n_the_arc_prize_offers_600000_for_fewshot/</link>
      <description><![CDATA[        提交人    /u/moschles   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnnstd/n_the_arc_prize_offers_600000_for_fewshot/</guid>
      <pubDate>Sun, 10 Nov 2024 00:08:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么 model_q4.onnx 和 model_q4f16.onnx 不是比 model.onnx 小 4 倍？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gni61w/why_are_model_q4onnx_and_model_q4f16onnx_not_4/</link>
      <description><![CDATA[我在https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/tree/main/onnx:上看到&gt;   文件名 大小    model.onnx 654 MB   model_fp16.onnx 327 MB   model_q4.onnx 200 MB   model_q4f16.onnx 134 MB   我的理解是：  model.onnx 是 fp32 模型， model_fp16.onnx 是权重量化为 fp16 的模型  我不明白 model_q4.onnx 和 model_q4f16.onnx 的大小&gt;  为什么 model_q4.onnx 是 200 MB 而不是 654 MB / 4 = 163.5 MB？我以为 model_q4.onnx 意味着权重被量化为 4 位。 为什么 model_q4f16.onnx 是 134 MB 而不是 654 MB / 4 = 163.5 MB？我以为 model_q4f16.onnx 意味着权重被量化为 4 位并且激活是 fp16，因为 https://llm.mlc.ai/docs/compilation/configure_quantization.html 指出：  qAfB(_id)，其中 A 表示用于存储权重的位数，B 表示用于存储激活的位数。   并且在张量流的神经网络量化框架中，为什么激活需要比权重（8 位）更多的位（16 位）？ 表示激活不计入模型大小（可以理解）。     提交人    /u/Franck_Dernoncourt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gni61w/why_are_model_q4onnx_and_model_q4f16onnx_not_4/</guid>
      <pubDate>Sat, 09 Nov 2024 19:43:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自适应优化器、降尺度和重置</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnh4fe/d_adaptive_optimizers_downscaling_and_resets/</link>
      <description><![CDATA[我一直在尝试自适应优化器，例如 Prodigy 和 Dadapt-LION。 我注意到，如果我在 100 万步数据集上运行它们，它们将从 1e06 开始。 .然后上升到 5e06.... 稍后仍然上升到 9e06 并留在那里。 但是，如果我中途停止它们.....然后根据结果进行训练，它可能只会上升到 6e06。 有没有标准的方法，在最坏的情况下重置它们，但在适当的时候实际上仍然向下调整？ 我想理想情况下，我想要一些具有反向“硬重置余弦”效果的东西。 而不是慢慢地强制 LR 越来越低..然后突然让它再次弹出... 而是突然强制 LR 等回到其原始起点，并让它再次重做自适应增长过程？并重复一定数量的学习周期。 像那样的吗？    提交人    /u/lostinspaz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnh4fe/d_adaptive_optimizers_downscaling_and_resets/</guid>
      <pubDate>Sat, 09 Nov 2024 18:56:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] Jay McClelland 解释并行分布式处理、大脑的工作原理、赫布学习和反向传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gng4fy/r_jay_mcclelland_explains_parallel_distributed/</link>
      <description><![CDATA[      Jay McClelland 是人工智能领域的先驱，也是认知心理学家，斯坦福大学心理学、语言学和计算机科学系的教授。Jay 与 David Rumelhart 共同出版了两卷著作《并行分布式处理》，该书推动了联结主义理解认知的方法的蓬勃发展。 在这次对话中，Jay 为我们速成讲解了神经元和生物大脑的工作原理。这为 Jay、David Rumelhart 和 Geoffrey Hinton 等心理学家在历史上如何处理认知模型以及最终的人工智能的发展奠定了基础。我们还讨论了神经计算的替代方法，例如符号和神经科学方法以及反向传播的发展。 https://preview.redd.it/s7xv0pmk2xzd1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=2e5be31c51a8eb78bf7033d1def25fa29f0863af https://preview.redd.it/h4sqjoim2xzd1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=e7c952d579322379c67a77adadf1d392afe8d3c6 Youtube： https://www.youtube.com/watch?v=yQbJNEhgYUw&amp;list=PL0uWtVBhzF5AzYKq5rI7gom5WU1iwPIZO&amp;index=1&amp;pp=iAQB Spotify： https://open.spotify.com/show/1X5asAByNhNr996ZsGGICG RSS： https://feed.podbean.com/cartesiancafe/feed.xml    由   提交  /u/IamTimNguyen   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gng4fy/r_jay_mcclelland_explains_parallel_distributed/</guid>
      <pubDate>Sat, 09 Nov 2024 18:11:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于微调 Meta 的 Segment Anything 2 (SAM) 模型的建议 — 平衡边缘情况与普遍性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnf7zi/r_advice_on_finetuning_metas_segment_anything_2/</link>
      <description><![CDATA[我正在使用 SAM2，并试图找出针对我的特定用例对其进行微调的最佳方法。我希望获得一些见解：  错误校正与泛化：如果我有兴趣对模型进行微调，以便在最容易出错的情况下表现更好，我是否可以保留它在已经表现良好的示例上的表现。即仍然保持（甚至提高）其先前的泛化能力？或者我应该有足够多的已经表现良好的示例来保持这种性能？ 要微调哪些组件？就模型的架构而言，我看到了关于是否只微调掩码解码器，提示编码器或两者的不同建议。根据您的经验，仅微调掩码解码器是否足以提高性能，还是还需要调整提示编码器？或者可能还有更多内容 — 比如模型的主干或其他部分？计算上的差异是否太大？还是还有其他缺点/注意事项？ 现实世界的经验：对于之前微调过 SAM 的人，您的体验如何？有什么技巧、窍门或我应该注意的陷阱吗？此外，您是如何准备微调数据集的？关于平衡数据多样性与关注边缘情况有什么建议吗？     提交人    /u/No_Cartoonist8629   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnf7zi/r_advice_on_finetuning_metas_segment_anything_2/</guid>
      <pubDate>Sat, 09 Nov 2024 17:31:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 当机器学习讲述错误的故事时</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gne2x1/r_when_machine_learning_tells_the_wrong_story/</link>
      <description><![CDATA[  由    /u/jackcook  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gne2x1/r_when_machine_learning_tells_the_wrong_story/</guid>
      <pubDate>Sat, 09 Nov 2024 16:40:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 下一帧的潜在空间预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gncn8y/d_latent_space_forecasting_of_the_next_frame/</link>
      <description><![CDATA[大家好，我正在搜索计算机视觉任务的论文或提示。我已经实现了一个用于图像分类的 Vision Transformer。下一步，我必须在 ViT 的编码器网络之上实现一个预测器，它从 enc(x_t) -&gt; enc(x_t+1) 进行预测。预测器应该预测下一帧的嵌入。我的第一个想法是 MLP 头或解码器网络。如果有人已经解决了类似的任务，我很高兴能得到建议。谢谢    提交人    /u/Significant-Joke5751   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gncn8y/d_latent_space_forecasting_of_the_next_frame/</guid>
      <pubDate>Sat, 09 Nov 2024 15:34:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用文本或图像特征和实值回归目标对监督数据集进行基准测试或开源？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnb9z5/p_benchmark_or_open_source_supervised_datasets/</link>
      <description><![CDATA[出于某种原因，我似乎找不到任何以文本或图像为特征、以实值为目标的知名基准数据集。任何目标范围都可以（（0,1）、（-infinity, infinity）、（0, infinity）等）。我找到了具有序数分类目标的示例（例如 1-5 的整数评级），但这不符合我的目的。 有谁知道任何符合此描述的开源监督 ML 数据？最好是具有性能排行榜的基准数据集。    提交人    /u/BreakingBaIIs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnb9z5/p_benchmark_or_open_source_supervised_datasets/</guid>
      <pubDate>Sat, 09 Nov 2024 14:28:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] MiniBoosts：一组小型的 boosting 算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gn8mpt/p_miniboosts_a_small_collection_of_boosting/</link>
      <description><![CDATA[大家好。 我用 Rust 编写了一个小型的 boosting 算法集合，名为 MiniBoosts。 这是一个业余项目，但我想进一步改进。 欢迎任何反馈意见。 感谢您的合作。    提交人    /u/__leopardus__   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gn8mpt/p_miniboosts_a_small_collection_of_boosting/</guid>
      <pubDate>Sat, 09 Nov 2024 12:03:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 嵌入和 docker 文件 - 两个库之间的比较 - 有没有比 ONNX 更好的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gn87vi/d_embeddings_and_docker_file_comparison_between/</link>
      <description><![CDATA[正如标题所说，我想知道是否还有其他方法可以在不使用 torch 的情况下嵌入语料库。我想到的解决方案之一是使用 ONNX。我使用 Qdrant 中的 fastembed 库和 sentence-transformer 库创建了图像。使用 fastembed 可以显著减小图像尺寸。 问题： 还有其他方法（例如修改 dockerfile 或使用其他库）可以进一步缩小 docker 映像吗？ 公共 repo：https://github.com/learning-bos/dockerize-torch-fastembed-sentence-transformer-comparison   由    /u/Ambitious-Most4485  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gn87vi/d_embeddings_and_docker_file_comparison_between/</guid>
      <pubDate>Sat, 09 Nov 2024 11:36:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单的 ML 模型托管服务？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmzb3q/d_simple_ml_model_hosting_service/</link>
      <description><![CDATA[我的工作是寻找一种让人工智能帮助制定计划的方法，我真的认为一个简单的多变量模型就可以解决问题；只需要找到一个可靠的托管服务，可以根据需要在此基础上进行构建。是否有成熟的 ML 托管商，它们可扩展、可配置，等等？    提交人    /u/Lucrayzor   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmzb3q/d_simple_ml_model_hosting_service/</guid>
      <pubDate>Sat, 09 Nov 2024 01:55:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大多数时间序列异常检测结果毫无意义（两个简短的视频解释了原因）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmwxnr/r_most_time_series_anomaly_detection_results_are/</link>
      <description><![CDATA[亲爱的同事们 时间序列异常检测 (TSAD) 目前非常热门，每年在 NeurIPS、SIGKDD、ICML、PVLDB 等会议上都会发表数十篇论文。 但是，我认为大部分已发表的结果都毫无意义，因为基本事实标签的不确定性使得算法之间声称的任何差异或声称的改进量相形见绌。 我制作了两个 90 秒长的视频，以视觉和直观的方式清楚地说明了这一点：  1) 为什么大多数时间序列异常检测结果毫无意义（道奇队） https://www.youtube.com/watch?v=iRN5oVNvZwk&amp;ab_channel=EamonnKeogh  2）为什么大多数时间序列异常检测结果毫无意义（AnnGun） https://www.youtube.com/watch?v=3gH-65RCBDs&amp;ab_channel=EamonnKeogh 与往常一样，欢迎更正和评论。 Eamonn  编辑：需要说明的是，我的观点只是为了防止其他人浪费时间处理带有本质上随机标签的数据集。此外，我们应该对文献中基于此类数据的任何主张保持谨慎（其中包括至少数十篇被高度引用的论文） 有关大多数常用 TSAD 数据集的审查，请参阅此文件： https://www.dropbox.com/scl/fi/cwduv5idkwx9ci328nfpy/Problems-with-Time-Series-Anomaly-Detection.pdf?rlkey=d9mnqw4tuayyjsplu0u1t7ugg&amp;dl=0    由    /u/eamonnkeogh 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmwxnr/r_most_time_series_anomaly_detection_results_are/</guid>
      <pubDate>Fri, 08 Nov 2024 23:58:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 PB 级数据集上进行训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmpedb/d_training_on_petabyte_scale_datasets/</link>
      <description><![CDATA[假设我们有一个比磁盘存储空间大得多的数据集。例如：  数据集：1PB 我们的磁盘存储空间：10TB GPU RAM：8x80GB（与本次讨论不太相关）  对这样的数据进行训练的常用方法是什么？我直观想到的是以某种方式并行执行以下操作： - 预取块 n，在块 n-1 上进行训练，从磁盘中删除块 n-2 假设我们使用 PyTorch，因此我们有一个 PyTorch 数据集，其中包含数据存储在云中的所有路径。我们是否需要为从云端下载并存储在磁盘上的预取器/删除器编写代码，并让其在单独的进程中运行，然后让 DataLoader 用于训练，假设它可以从磁盘读取（因为预取器正确地完成了它的工作）？让 DataLoader 从 S3 读取对 GPU 利用率不利，对吗？ 退一步说，我假设这是每个在大型数据集上进行训练的公司都会遇到的普通且经常发生的“问题”，所以我对自己编写所有这些代码持怀疑态度，因为我觉得应该有标准的开箱即用的解决方案，但真的找不到完美匹配的东西。    提交人    /u/lapurita   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmpedb/d_training_on_petabyte_scale_datasets/</guid>
      <pubDate>Fri, 08 Nov 2024 18:27:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Nov 2024 16:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>