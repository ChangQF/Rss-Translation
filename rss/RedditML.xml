<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Tue, 13 Aug 2024 09:17:10 GMT</lastBuildDate>
    <item>
      <title>[P] 使用概率流 ODE 对扩散模型进行精确似然估计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1er25ae/p_exact_likelihood_estimation_on_diffusion_models/</link>
      <description><![CDATA[大家好，我正在学习如何计算扩散模型的精确似然值。我把两篇论文作为我问题的参考： 在 [2] 链接中，查看附录 15.2 了解整体过程。主要歌曲论文 [1] 的似然值评估的 pytorch 代码位于 [3]。我的问题如下：  积分从几乎 0 到 T，在第 99 行？ [2] 中的方程 (77) 中的项与代码有何关系（因为它同时获得了 Prior_logp 和 delta_logp）？ 为什么我们有两部分数据？ （从 0 到最后一个批次大小 zp[:-shape[0]]，以及最后一个批次大小 zp[-shape[0]:]）在第 102 行和第 103 行？ 如何计算第 109 行的偏移量以转换为 bpd 值？ 他们在这里如何运用均匀去量化的概念？  如能得到任何帮助将不胜感激。 [1] https://arxiv.org/abs/2011.13456 [2] https://arxiv.org/abs/2312.13236 [3] https://github.com/yang-song/score\_sde\_pytorch/blob/main/likelihood.py    由   提交  /u/Tight_Professor6483   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1er25ae/p_exact_likelihood_estimation_on_diffusion_models/</guid>
      <pubDate>Tue, 13 Aug 2024 07:56:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 博士前奖学金申请文本分析项目的反馈请求</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1er1f9l/d_request_for_feedback_on_text_analysis_project/</link>
      <description><![CDATA[大家好， 我目前正在进行两个项目，以展示我在文本分析和网页抓取方面的技能，用于申请政治学博士前奖学金。该奖学金专注于计算冲突研究，我希望确保我的项目能够有效展示我的能力。 第一个项目名为“泰国的民权运动：使用 NLP 分析维基百科文章中的历史叙述”。&lt;/p&gt;您可以在此处查看：https://www.notion.so/Thailand-s-Civil-Rights-Movements-Analyzing-Historical-Narratives-in-Wikipedia-Articles-Using-NLP-cc7daf262d0d49e9910cb49426ffe52a 我不确定这个项目是否足够全面以展示必要的技能，或者是否需要进一步调整。我非常感谢任何反馈或改进建议，特别是与奖学金要求相关的反馈或建议。 作为参考，以下是奖学金描述的链接：https://www.jobbnorge.no/en/available-jobs/job/265614/predoctoral-fellow-in-political-science 请注意，我刚刚开始我的第二个项目，所以还没有完成。我的提交截止日期是本月 15 日，所以我的时间安排很紧。 提前感谢您的时间和见解！    提交人    /u/Lemmeaskyouonething   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1er1f9l/d_request_for_feedback_on_text_analysis_project/</guid>
      <pubDate>Tue, 13 Aug 2024 07:06:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何为你的论文制作图表？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1er14hq/d_how_to_make_figures_for_your_paper/</link>
      <description><![CDATA[虽然我的论文发表在一些顶级会议（IJCAI、ACL 等）上，但最初收到的评价往往很差，导致在最终被接受之前经历了一轮重新提交。虽然一些顶级会议的评价可能真的很差，但我不能把所有责任都归咎于审稿人。自从今年收到 NeurIPS 的评价以来，我一直在反思我可以改进哪些方法，以避免这些令人沮丧的重新提交循环。 我的审稿人经常提到我的论文读起来很好，很容易理解，但他们对新颖性并不感冒。我明白，由于我不从事法学硕士或其他热门话题，审稿人通常似乎不了解我正在从事的任务或方法本身的重要性。 在改进我的方法时，我想从数字开始。我通常使用 draw.io，但这通常会导致图形效果不佳，让人想起 2000 年代的论文中看到的图形。你们都使用什么工具来创建更精致的图形？我明白工具只是一种表达媒介，不应该限制我想要实现的目标，但我仍然想知道你如何制作出好的图形，简洁地概括你的工作，让审阅者更好地了解你在做什么。    提交人    /u/dontabuseme   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1er14hq/d_how_to_make_figures_for_your_paper/</guid>
      <pubDate>Tue, 13 Aug 2024 06:47:06 GMT</pubDate>
    </item>
    <item>
      <title>什么类型的模型架构最适合生成音乐？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqyz02/what_type_of_model_architecture_is_best_suited/</link>
      <description><![CDATA[在 $$$ 成为必需品并开始开发软件之前，我曾是一名音乐家。我弹吉他、钢琴、打鼓，对音乐理论有扎实的理解，并制作了一些自己的曲目。 这些对于构建我自己的生成音乐模型可能并不重要，但这绝对意味着我对此感兴趣 :) 有人可以推荐从哪里开始，特别是哪种类型的模型架构？GPT 建议使用 RNN、Transformers 或 VAE。有没有人尝试过各种模型并可以在架构选择 + 如何适当处理数据方面提供一些指导？    提交人    /u/redditTee123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqyz02/what_type_of_model_architecture_is_best_suited/</guid>
      <pubDate>Tue, 13 Aug 2024 04:29:07 GMT</pubDate>
    </item>
    <item>
      <title>LLM 作为优化器 - 理论论文推荐 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqylt9/llms_as_optimizers_theory_paper_recommendation_r/</link>
      <description><![CDATA[我最近了解了“LLM 作为优化器”，其中似乎有一条工作线认为 Transformers 可以执行一阶优化（梯度下降）。我对这背后的理论很感兴趣，我找到了论文 Transformers 通过梯度下降在上下文中学习 并计划阅读它。我想知道在这个方向是否还有其他经典/“必读”理论论文。感谢您的任何意见。    提交人    /u/mziycfh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqylt9/llms_as_optimizers_theory_paper_recommendation_r/</guid>
      <pubDate>Tue, 13 Aug 2024 04:08:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 人工智能科学家：迈向全自动开放式科学发现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqwfo0/r_the_ai_scientist_towards_fully_automated/</link>
      <description><![CDATA[博客文章：https://sakana.ai/ai-scientist/ 论文：https://arxiv.org/abs/2408.06292 开源项目：https://github.com/SakanaAI/AI-Scientist 摘要 通用人工智能的一大挑战是开发能够进行科学研究和发现新知识的代理。虽然前沿模型已经被用作人类科学家的辅助手段，例如虽然它们无法进行头脑风暴、编写代码或预测任务，但它们仍然只完成了科学过程的一小部分。本文提出了第一个全自动科学发现的综合框架，使前沿大型语言模型能够独立进行研究并传达其发现。我们介绍了人工智能科学家，它可以产生新颖的研究想法，编写代码，执行实验，可视化结果，通过撰写完整的科学论文描述其发现，然后运行模拟审查过程进行评估。原则上，这个过程可以重复进行，以开放式的方式迭代开发想法，就像人类科学界一样。我们通过将其应用于机器学习的三个不同子领域来展示它的多功能性：扩散建模、基于变换器的语言建模和学习动力学。每个想法都以每篇论文不到 15 美元的成本实施并开发成一篇完整的论文。为了评估生成的论文，我们设计并验证了一个自动审阅器，我们表明它在评估论文分数方面达到了接近人类的表现。人工智能科学家可以制作出超过顶级机器学习会议接受门槛的论文，由我们的自动审阅者评判。这种方法标志着机器学习科学发现新时代的开始：将人工智能代理的变革性优势带入人工智能本身的整个研究过程，并让我们更接近一个可以在世界上最具挑战性的问题上释放无尽的、可负担的创造力和创新的世界。    提交人    /u/hardmaru   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqwfo0/r_the_ai_scientist_towards_fully_automated/</guid>
      <pubDate>Tue, 13 Aug 2024 02:17:29 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 有人有过去的播客或媒体链接吗？这些链接保存得非常好吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqwcwj/discussion_does_anyone_have_podcast_or_media/</link>
      <description><![CDATA[你好！我一直在看播客，预测人工智能是否可能实现以及/或者它是否有意识，以及是否能解决 ARC 挑战。所有这些都面向未来。这让我开始思考，过去所有的预测都发生了什么？哪些思想家或意识形态比其他思想家或意识形态更准确？有什么模式吗？ 这就是为什么我想知道你是否能回忆起任何能够相对正确地预测重大变化的旧播客、书籍、论文等。这只是出于兴趣，想看看过去有人猜测我现在的情况。我知道库兹韦尔就很不错。  不一定非要与机器学习有关，可以是任何你感兴趣的领域，比如技术发明、科学、经济学、世界贸易、社会模式、政治模式等。 任何你记得并认为他们是对的并且回想起来他们的想法非常合乎逻辑的事情。    提交人    /u/Shockhorrorfear   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqwcwj/discussion_does_anyone_have_podcast_or_media/</guid>
      <pubDate>Tue, 13 Aug 2024 02:13:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 工作项目指导</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqrm7z/p_work_project_guidance/</link>
      <description><![CDATA[您好！我在一家赌场工作，我们需要在每班次为赌桌游戏分配发牌人。整个晚上游戏都会结束，那些已结束游戏的发牌人会将其他已开始游戏的发牌人送回家。这些情况可能很复杂，因为并非所有发牌人都拥有同等的技能并掌握所有游戏。 例如，一个发牌人可能正在玩掷骰子游戏并需要回家，但唯一空闲的发牌人不知道如何发掷骰子游戏。在这种情况下，需要采取多种措施才能让掷骰子发牌人回家。我想构建一种算法，该算法将分析所有开放游戏并就可以采取哪些措施提出建议。 还涉及其他不同的细节，例如开始时间、让替补发牌人让其他发牌人休息、尽可能不要过多地移动发牌人，以及能够选择下一个要回家的发牌人。  我们目前手工完成这项工作，这非常低效，并且给我们的经理带来压力。过去几个月我一直在学习 Python，但如果这更适合另一种语言，我也愿意接受它。  我理解这是一个复杂的问题，只是想寻求一些建议，关于下一步应该重点学习什么，比如什么类型的机器学习最好，创建用户界面等。谢谢！    提交人    /u/liff9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqrm7z/p_work_project_guidance/</guid>
      <pubDate>Mon, 12 Aug 2024 22:39:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 为何以及何时绑定嵌入（故事）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqm0lr/r_why_and_when_tying_embedding_a_story/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqm0lr/r_why_and_when_tying_embedding_a_story/</guid>
      <pubDate>Mon, 12 Aug 2024 18:54:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] NIST Dioptra，有运气吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eql4yk/d_nist_dioptra_any_luck/</link>
      <description><![CDATA[你们有人试过使用 NIST 的 Dioptra，他们的 AI 测试平台吗？ 尽管我按照他们的说明操作，但还是卡了大约一个星期试图启动并运行它。我似乎没有收到 API 的响应，所以我无法提交任何作业。我正在本地运行它，据我所知，端口是暴露的。  默认配置对你有用吗？如果没有，你有什么安装技巧吗？    提交人    /u/kitties_and_biscuits   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eql4yk/d_nist_dioptra_any_luck/</guid>
      <pubDate>Mon, 12 Aug 2024 18:20:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] RAGoon 现已在 PyPI、GitHub 和 HF 上的 Space 上提供，用于批量生成嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqj67x/p_ragoon_is_now_available_on_pypi_github_and_as_a/</link>
      <description><![CDATA[RAGoon 是一组用于多模型嵌入生成、高维向量可视化的 NLP 实用程序，旨在通过基于搜索的查询、网页抓取和数据增强技术提供上下文相关信息，从而提高语言模型性能。 GitHub 链接：https://github.com/louisbrulenaudet/ragoon Hugging Face Space 链接：https://huggingface.co/spaces/louisbrulenaudet/ragoon 以下是为给定的模型列表生成嵌入的代码示例： from ragoon import EmbeddingsDataLoader from datasets import load_dataset # 使用初始化数据集加载器多个模型 loader = EmbeddingsDataLoader( token=&quot;hf_token&quot;, dataset=load_dataset(&quot;louisbrulenaudet/dac6-instruct&quot;, split=&quot;train&quot;), # 如果数据集已加载。# dataset_name=&quot;louisbrulenaudet/dac6-instruct&quot;, # 如果要从类中加载数据集。model_configs=[ {&quot;model&quot;: &quot;bert-base-uncased&quot;, &quot;query_prefix&quot;: &quot;Query:&quot;}, {&quot;model&quot;: &quot;distilbert-base-uncased&quot;, &quot;query_prefix&quot;: &quot;Query:&quot;} # 根据需要添加更多模型配置 ] ) # 如果传递 dataset_name 而不是 dataset，请取消注释此行。 # loader.load_dataset() # 处理已加载所有模型的分割 loader.process( column=&quot;output&quot;, preload_models=True ) # 访问已处理的数据集 processing_dataset = loader.get_dataset()  特别是，此工具还提供从 FAISS 索引加载嵌入的功能，使用 PCA 和/或 t-SNE 降低其维数，并在交互式 3D 图形中对其进行可视化。    submitted by    /u/louisbrulenaudet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqj67x/p_ragoon_is_now_available_on_pypi_github_and_as_a/</guid>
      <pubDate>Mon, 12 Aug 2024 17:04:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 1.5-Pints 技术报告：几天内完成预训练，而不是几个月——您的语言模型依靠优质数据蓬勃发展 (2408.03506)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqdbro/r_15pints_technical_report_pretraining_in_days/</link>
      <description><![CDATA[  由    /u/mouse0_0  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqdbro/r_15pints_technical_report_pretraining_in_days/</guid>
      <pubDate>Mon, 12 Aug 2024 13:10:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 新的 Llama 缩放定律？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq95ga/d_new_llama_scaling_laws/</link>
      <description><![CDATA[&quot;在开发 Llama 3 的过程中，我们对扩展行为进行了一些新的观察。例如，虽然 8B 参数模型的 Chinchilla 最佳训练计算量对应于 ~200B 个 token，但我们发现即使在使用两个数量级以上的数据训练模型后，模型性能仍会继续提高。在我们使用高达 15T 的 token 进行训练后，我们的 8B 和 70B 参数模型都继续以对数线性方式提高。较大的模型可以用较少的训练计算来匹配这些较小模型的性能，但较小的模型通常是首选，因为它们在推理过程中效率更高。&quot; 这是摘自Meta Llama 3 介绍：迄今为止最强大的公开可用 LLM 您认为 Llama 刚刚引入了新的扩展定律吗？ Chinchilla 之前为什么没发现这一点？模型大小与 token 数量的比例有没有新的数字？    提交人    /u/akashkash   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq95ga/d_new_llama_scaling_laws/</guid>
      <pubDate>Mon, 12 Aug 2024 09:21:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢所有人在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Aug 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>