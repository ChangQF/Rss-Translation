<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 10 Sep 2024 18:21:10 GMT</lastBuildDate>
    <item>
      <title>[N][P] 新成立的 AI 实验室（招聘实习生）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdo2fm/np_new_ai_lab_startup_hiring_interns/</link>
      <description><![CDATA[近年来，我在机器学习方面积累了宝贵的经验，我相信很快就到了自己创业的时候了。最初，我计划一边继续工作，一边经营公司。我有很多想法，但没有足够的时间去实现它们，所以我正在考虑招聘实习生远程独立工作，让我指导他们完成我们的项目。我也对研究充满热情，喜欢深入研究新的想法和创新。 如果有人有兴趣在研发创新型机器学习产品的同时学习大量有关人工智能的知识，或者如果你想分享你对我的战略的想法，请随时联系我们！    提交人    /u/Stefano939393   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdo2fm/np_new_ai_lab_startup_hiring_interns/</guid>
      <pubDate>Tue, 10 Sep 2024 17:47:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据漂移效应</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdkwq5/d_data_drift_effect/</link>
      <description><![CDATA[除了重新训练之外，还有其他方法可以减少数据漂移的影响吗？我只能每年重新训练一次，但我每年都会遇到数据漂移。    提交人    /u/Vegetable-Ad7622   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdkwq5/d_data_drift_effect/</guid>
      <pubDate>Tue, 10 Sep 2024 15:39:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformers Trainer 与 Pytorch 照明</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdey5q/r_transformers_trainer_vs_pytorch_lighting/</link>
      <description><![CDATA[大家好， 我想知道你对这两个框架的看法。  它们有什么优缺点？ 如果要优先考虑效率，哪一个更好？或者它们之间的唯一区别是代码抽象和组织？ 最后，你知道任何同时使用它们的代码库吗？我想用它作为从一个框架转换到另一个框架的“模板”。 非常感谢！    提交人    /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdey5q/r_transformers_trainer_vs_pytorch_lighting/</guid>
      <pubDate>Tue, 10 Sep 2024 10:52:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找一些关于评估法学硕士结构化输出的论文或图书馆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdek1q/r_looking_for_some_papers_or_libraries_on/</link>
      <description><![CDATA[嗨，我想知道是否有人知道任何论文或库可以让我评估大型语言模型 (LLM) 的结构化输出？特别是细粒度评估的方法。 json { &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30, &quot;email&quot;: &quot;johndoe@example.com&quot;, &quot;occupation&quot;: &quot;Software Engineer&quot; }  假设 LLM 生成了上述 JSON，我们想根据某些基本事实评估每个字段。某些字段（如 age）可以通过精确匹配进行评估，但其他字段可能需要更高级的方法，例如使用某种形式的 llm-as-judge 评分或语义软匹配。如果我们考虑嵌套结构，情况会变得更加复杂。 我正在寻找有关如何对此类输出进行详细评估的见解。你有什么建议或资源吗，尤其是框架/库？    提交人    /u/hwvbdnkau   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdek1q/r_looking_for_some_papers_or_libraries_on/</guid>
      <pubDate>Tue, 10 Sep 2024 10:26:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] NVIDIA H100 还是 AMD MI250X？我应该选择哪一个进行 ML/LLM 推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fde3nq/d_nvidia_h100_or_amd_mi250x_which_one_should_i/</link>
      <description><![CDATA[大家好！👋 我目前正处于抉择阶段，不知道该选择 Nvidia H100 还是 AMD MI250X 来完成 ML/LLM 推理任务。两者看起来都非常棒，但我很想听听那些拥有实践经验或深入了解这些 GPU 的人的意见。以下是我的想法： Nvidia H100：以其尖端性能和对各种 ML 工作负载的出色支持而闻名。它背后有 CUDA 生态系统，这是一个很大的优势。 AMD MI250X：凭借其高内存带宽和 HPC 任务中的高性能，似乎是一个强有力的竞争者。此外，AMD 最近在 AI 领域取得了一些重大进展。 我想知道的是： 性能：它们在现实世界的 ML/LLM 推理中表现如何？速度、效率或可扩展性方面有任何明显差异吗？ 生态系统：Nvidia CUDA 生态系统是否为 H100 提供了优势，或者 AMD 是否已经赶上了对 ML 框架的 ROCm 支持？ 成本与收益：考虑到价格点，对于面向未来的 ML/LLM 任务而言，这显然是一项更好的投资吗？ 我很想听听您的经验、想法或您遇到的任何基准。如果您做出了类似的决定，是什么让您做出了选择？期待讨论 - 提前致谢！🙌    提交人    /u/SquirrelEffective   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fde3nq/d_nvidia_h100_or_amd_mi250x_which_one_should_i/</guid>
      <pubDate>Tue, 10 Sep 2024 09:55:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 能产生新颖的研究想法吗？一项有 100 多名 NLP 研究人员参与的大规模人类研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fddtmm/r_can_llms_generate_novel_research_ideas_a/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fddtmm/r_can_llms_generate_novel_research_ideas_a/</guid>
      <pubDate>Tue, 10 Sep 2024 09:35:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] LowFormer：硬件高效的 Transformer 主干设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdc52w/r_lowformer_hardware_efficient_transformer/</link>
      <description><![CDATA[吞吐量和延迟优化的骨干架构，具有硬件高效的宏和微设计。它还具有简单高效的多头自注意力适应性。    提交人    /u/Mr_Fragwuerdig   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdc52w/r_lowformer_hardware_efficient_transformer/</guid>
      <pubDate>Tue, 10 Sep 2024 07:26:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否存在一个开放的、真正的多模式 LLM，而不是一个玩具模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fd5hp7/d_is_there_an_open_truly_multimodal_llm_that_isnt/</link>
      <description><![CDATA[嗨， 自 gpt-4o 问世以来已经过去了几个月，我还没有找到一个等效的开放权重模型。Gemini 甚至在它之前就出现了，它有多模态输入。 我所说的等效，是指早期融合和多模态的模型，其中视觉和音频被标记化并与文本标记共享相同的嵌入空间。我并不一定意味着它必须具有相同的功能或准确性。 据我所知，Meta 的变色龙是最接近的匹配，但它是双模态的（不支持音频）并且只能生成文本。 所以我的问题是：是否存在一个真正的多模态模型，我们可以在本地下载和调整？    提交人    /u/Amgadoz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fd5hp7/d_is_there_an_open_truly_multimodal_llm_that_isnt/</guid>
      <pubDate>Tue, 10 Sep 2024 00:51:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] `costly`：用于提前估算 LLM 项目成本和运行时间的软件包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fd2ff3/p_costly_a_package_for_estimating_costs_running/</link>
      <description><![CDATA[我编写了一个简单的包，以便在花钱之前提前估算复杂 LLM 工作流/实验/管道的成本和运行时间： https://github.com/abhimanyupallavisudhir/costly 只需将 @costly() 放在承载函数上（例如 API 调用包装器本身）；确保调用它的所有函数都将 **kwargs（或至少 cost_log 和 simulate）传递给它，并使用 simulate=True 和一些 cost_log: Costlog 对象调用你的复杂函数。 pip install costly  据我所知，现有的包（如 tokencost）只是用于估算单个 LLM 调用成本的价格字典，你必须编写自己的逻辑来估算逻辑成本。 costly 的意义在于为您做到这一点（并且您可以将它用于 LLM 调用之外的其他目的，尽管您需要编写自己的估算器和模拟器）。 显然，在管道中存在一些非平凡的逻辑，其中一个 LLM 的输出传递给另一个 LLM 等 - 这种逻辑由&quot;模拟器&quot; 近似，可以对其进行子类化。 请参阅此处的完整文档：https://github.com/abhimanyupallavisudhir/costly/blob/master/examples.ipynb    提交人    /u/Ok_Country1256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fd2ff3/p_costly_a_package_for_estimating_costs_running/</guid>
      <pubDate>Mon, 09 Sep 2024 22:26:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 进行实验以在 P5.js 中重新创建模式 — 寻找想法 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fd0qy9/experimenting_with_llms_to_recreate_patterns_in/</link>
      <description><![CDATA[      我一直在做一个项目，使用 LLM 生成嵌入 HTML 的 P5.js 草图，到目前为止，进展非常顺利！有些草图非常有创意（关于我的项目的文章）。但是，我已经开始了一个新的实验，我给 LLM 一张图片，并要求它使用 P5.js 重新创建图案。不幸的是，我在这部分没有取得太大的成功。基本上，我需要 LLM 理解模式并设计一个脚本来重新创建模式。这要求太多了吗？ 我尝试在提示中使用思路链推理，甚至制作了一个比较常见形状的资源，但结果仍然相差甚远。我想知道是否有即时策略或技巧可以尝试指导 LLM 更好地使用 P5.js 形状和算法重新创建图案。或者，也许某种专门的培训可以有所帮助？ 这是我当前提示的屏幕截图。并且这里是我创建的参考 pdf。 Claude 中的提示截图    提交人    /u/garygeo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fd0qy9/experimenting_with_llms_to_recreate_patterns_in/</guid>
      <pubDate>Mon, 09 Sep 2024 21:15:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我构建了一个工具，通过 1 个超参数搜索来减少幻觉 - Nomadic</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcxup1/p_i_built_a_tool_to_minimize_hallucinations_with/</link>
      <description><![CDATA[Github：https://github.com/nomadic-ml/nomadic 演示：Colab 笔记本 - 为您的检索增强生成管道获取性能最佳的 statsig 配置，并通过一次实验将幻觉减少 4 倍。注意：最适合与 Colab Pro（高 RAM 实例）一起使用或在本地运行。 很想听听您的任何想法/反馈！    提交人    /u/TRBeetle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcxup1/p_i_built_a_tool_to_minimize_hallucinations_with/</guid>
      <pubDate>Mon, 09 Sep 2024 19:19:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 实施论文的价值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcvkjm/d_implementing_papers_worth/</link>
      <description><![CDATA[大家好， 我拥有机器人学硕士学位（修过 ML、CV、DL 和数学课程），最近我对 3D 计算机视觉非常感兴趣，所以我研究了一些项目。我发现了 deepSDF。我的目标是在 C++ 上实现它，使用 CUDA 和 SIMD，并在真实相机上测试在线 SDF 构建。 还计划实现 3D 高斯 Splatting。 但我的朋友说不用费心了，因为每个人都可以实现那些论文，所以我需要自己写论文。他是对的吗？我在浪费时间吗？    提交人    /u/Huge-Leek844   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcvkjm/d_implementing_papers_worth/</guid>
      <pubDate>Mon, 09 Sep 2024 17:47:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多元时间序列的模式匹配方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcq4v4/r_methods_for_pattern_matching_with_multivariate/</link>
      <description><![CDATA[大家好， 我想确定我的车辆动力学模式是否与其他（多个）车辆动力学模式相似。例如，假设我有一段 5 秒的数据，表示转向。我如何查看行程的完整驾驶周期数据，以查看此行程中是否发生这种转向（或某种程度上的类似转向）？ 我已经开发了几种方法来做到这一点，但我想知道是否有什么我应该阅读的，这样我就不会在这里重新发明轮子了！ 感谢您的帮助或指导！    提交人    /u/PreviousResearcher50   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcq4v4/r_methods_for_pattern_matching_with_multivariate/</guid>
      <pubDate>Mon, 09 Sep 2024 14:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 08 Sep 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>