<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Sat, 17 Aug 2024 12:25:46 GMT</lastBuildDate>
    <item>
      <title>[D] 关于 Mamba 算法形状的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eub39f/d_question_about_shapes_of_mamba_algorithm/</link>
      <description><![CDATA[大家好 :) 这是 Mamba 论文 (https://arxiv.org/pdf/2312.00752) 中的 S6 算法： https://preview.redd.it/jusbz7c926jd1.png?width=890&amp;format=png&amp;auto=webp&amp;s=75cf754b3c1f7478e3c146b7ec7f373a8336cd3e 我不太理解输入相关的形状。以 C 为例。为什么它的形状是 (B,L,N)？直观地讲，由于它为序列中的每个输入标记提供了唯一的转换（选择），因此它的形状应该是 (B,L,D,N)，其中最后两个维度恰好是批次中相应标记的投影？ 如果不这样做，隐藏状态 h 将具有维度 (B,D,N)，从而可以像在 SSM 中那样更新隐藏状态和输出。这再次违反直觉，因为隐藏状态通常具有形状 (B,N)，即隐藏向量以压缩序列的过去信息。 所以我的问题是，为什么 B、C 和 Delta 的输入相关形状不是维度 (B,L,D,N) ？ 提前致谢！    提交人    /u/No_Individual_7831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eub39f/d_question_about_shapes_of_mamba_algorithm/</guid>
      <pubDate>Sat, 17 Aug 2024 06:21:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] Pytorch 的 OpenCL 后端更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euamk8/p_updates_on_opencl_backend_for_pytorch/</link>
      <description><![CDATA[我开发了用于 pytorch 的 OpenCL 后端 - 它允许在 Windows 和 Linux 上的 AMD、NVidia 和 Intel GPU 上训练您的网络。与基于 cuda/cudnn 的解决方案不同 - 它是跨平台且完全开源的。 更新：  在 pytorch 核心开发人员的帮助下，现在支持 pytorch 2.4 现在安装它很容易 - 我现在提供适用于 Linux 和 Windows 的预构建包 - 只需安装 whl 包就可以了 许多其他改进  如何使用它：  根据操作系统、python 版本和 pytorch 版本从项目页面下载 whl 文件 安装 pytorch 的 CPU 版本并安装您下载的 whl，例如 pytorch_ocl-0.1.0+torch2.4-cp310-none-linux_x86_64.whl  现在只需导入 pytorch_ocl现在您可以在 OpenCL ocl 设备上进行训练：`torch.randn(10,10,dev=&#39;ocl:2&#39;)  性能如何：虽然它不如原生 NVidia cuda 或 AMD rocm，但它仍然提供合理的性能，具体取决于平台、网络 - 通常训练约为 60-70%，推理约为 70-80%。    提交人    /u/artyombeilis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euamk8/p_updates_on_opencl_backend_for_pytorch/</guid>
      <pubDate>Sat, 17 Aug 2024 05:52:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] MAMBA 2 头部尺寸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu9ft8/r_mamba_2_head_dimension/</link>
      <description><![CDATA[我一直在阅读 MAMBA 2 论文。我认为我对 MAMBA（1？）相当熟悉，并且对 MAMBA 2 有较高的理解，但我无法理解原始论文中的 D 和 MAMBA 2 论文中的 P 之间的区别。在 MAMBA 1 中，传入张量的形状为 B、L、D。其中 D 是一些投影（我认为）。在 MAMBA 2 中，他们说 MAMBA 1 的头部维度为 1，但在 MAMBA 2 中不再如此。 他们在 MAMBA 2 中将 P 从 1 增加到 64 或其他数字。在论文中的代码片段中，似乎 P 是 D 的额外投影，使我们的传入张量为 4D、B、L、D、P。但论文的其他一些部分让我认为 P 实际上是 D 的一些划分，有点类似于您将变压器中的输入序列划分为多个头部的方式。哪一个是正确的？我应该如何解释 P？    提交人    /u/redwat3r   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu9ft8/r_mamba_2_head_dimension/</guid>
      <pubDate>Sat, 17 Aug 2024 04:39:31 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]决策树构建中的歧义</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu64fq/discussion_ambiquity_in_the_construction_of/</link>
      <description><![CDATA[      https://preview.redd.it/0013142so4jd1.png?width=707&amp;format=png&amp;auto=webp&amp;s=8764b6772fdabe809e7a4db449b501a6d5df201c 我正在尝试对图 1 中显示的品牌示例进行决策树数值计算当我尝试使用熵手动构建决策树时，我得到了 https://preview.redd.it/zdllqlbzo4jd1.png?width=1106&amp;format=png&amp;auto=webp&amp;s=15deb539b6ed7643df0041b09d0dd880c6fb0ee6 现在，当我尝试使用下面的代码构建决策树时 import pandas as pd from sklearn.preprocessing import OrdinalEncoder from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.metrics 导入 accuracy_score data = pd.DataFrame({ “天”: [&#39;D1&#39;, &#39;D2&#39;, &#39;D3&#39;, &#39;D4&#39;, &#39;D5&#39;, &#39;D6&#39;, &#39;D7&#39;, &#39;D8&#39;, &#39;D9&#39;, &#39;D10&#39;, &#39;D11&#39;, &#39;D12&#39;, &#39;D13&#39;, &#39;D14&#39;], “展望”: [&#39;晴天&#39;, &#39;晴天&#39;, &#39;阴天&#39;, &#39;下雨&#39;, &#39;下雨&#39;, &#39;下雨&#39;, &#39;阴天&#39;, &#39;晴天&#39;, &#39;下雨&#39;, &#39;晴天&#39;, &#39;阴天&#39;, &#39;下雨&#39;], “温度”: [&#39;热&#39;, &#39;热&#39;, &#39;热&#39;, &#39;温和&#39;, &#39;凉爽&#39;, &#39;凉爽&#39;, &#39;凉爽&#39;, &#39;温和&#39;, &#39;凉爽&#39;, &#39;温和&#39;, &#39;温和&#39;, &#39;温和&#39;, &#39;热&#39;, &#39;温和&#39;], “湿度”: [&#39;高&#39;, &#39;高&#39;, &#39;高&#39;, &#39;高&#39;, &#39;正常&#39;, &#39;正常&#39;, &#39;正常&#39;, &#39;高&#39;, &#39;正常&#39;, &#39;正常&#39;, &#39;正常&#39;, &#39;高&#39;, &#39;正常&#39;, &#39;高&#39;], “风”: [&#39;弱&#39;, &#39;强&#39;, &#39;弱&#39;, &#39;弱&#39;, &#39;弱&#39;, &#39;强&#39;, &#39;弱&#39;, &#39;弱&#39;, &#39;弱&#39;, &#39;强&#39;, &#39;弱&#39;, &#39;强&#39;, &#39;弱&#39;, &#39;强&#39;], “PlayTennis”: [&#39;否&#39;, &#39;否&#39;, &#39;是&#39;, &#39;是&#39;, &#39;是&#39;, &#39;否&#39;, &#39;是&#39;, &#39;否&#39;, &#39;是&#39;, &#39;是&#39;, &#39;是&#39;, &#39;是&#39;, &#39;是&#39;, &#39;是&#39;, &#39;否&#39;] }) 编码器 = OrdinalEncoder() data_encoded = data.copy() data_encoded[[&#39;Outlook&#39;, &#39;温度&#39;, &#39;湿度&#39;, &#39;风&#39;]] = 编码器.fit_transform(data[[&#39;Outlook&#39;, &#39;温度&#39;, &#39;湿度&#39;, &#39;风&#39;]]) data_encoded[&#39;PlayTennis&#39;] = data_encoded[&#39;PlayTennis&#39;].map({&#39;否&#39;: 0, &#39;是&#39;: 1}) X = data_encoded.drop([&#39;PlayTennis&#39;, &#39;白天&#39;], axis=1) y = data_encoded[&#39;PlayTennis&#39;] clf = DecisionTreeClassifier(criterion=&#39;entropy&#39;) clf.fit(X, y) plt.figure(figsize=(12, 8)) plot_tree(clf, feature_names=X.columns, class_names=[&#39;No&#39;, &#39;Yes&#39;], filled=True, rounded=True) plt.show()  我得到了这棵树 https://preview.redd.it/r1g3x10ep4jd1.png?width=950&amp;format=png&amp;auto=webp&amp;s=bde00bf06025f3a5847717045528128c8283b817 那么我在手工数值计算部分做错了什么吗？或者做错了编码？有人能解释一下吗？在决策树中，对于名义数据和序数数据，应该如何对分类变量进行不同的编码？     由    /u/jiraiya1729 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu64fq/discussion_ambiquity_in_the_construction_of/</guid>
      <pubDate>Sat, 17 Aug 2024 01:42:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] HuggingFace 变形金刚——糟糕的设计？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu3auv/d_huggingface_transformers_bad_design/</link>
      <description><![CDATA[嗨， 我目前正在使用 HuggingFace 的 transformers 库。该库在加载模型时有些方便，它似乎是唯一合理的共享和加载模型的平台。但我越深入，就越困难，我感觉 api 设计得不好，存在很多严重的问题。 该库允许在不同的地方设置相同的选项，但没有记录它们如何相互作用。例如，似乎没有统一的方法来处理 EOS 等特殊令牌。人们可以在 1. 模型中、2. 标记器中和 3. 管道中设置这些令牌。我不清楚这些选项究竟是如何相互作用的，而且文档也没有提到这一点。有时参数会被忽略，而库不会就此发出警告。例如，参数“add_eos_token”在某些情况下，标记器似乎不起作用，而且我不是唯一遇到此问题的人（https://github.com/huggingface/transformers/issues/30947）。更糟糕的是，似乎确切的行为通常取决于模型，而库则假装提供统一的接口。查看源代码可以确认它们实际上根据当前加载的模型进行区分。 非常相似的观察结果涉及多线程的启动脚本，特别是：加速。我指定了核心数，但这只是被忽略了。没有通知，没有任何明显的原因。我在系统监视器中看到它仍然以单线程运行。即使是从网站上获取的样本也并不总是有效。 总之，配置设置似乎不受控制地增长。由于没有清晰的结构，并且有太多影响库的效果，因此其行为的很大一部分实际上没有记录。也可以说，它看起来有点不稳定和实验性。即使是对我有用的部分也让我担心，因为我怀疑部署后是否一切都会在另一台机器上正常工作。 有人有这样的想法吗？    提交人    /u/duffano   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu3auv/d_huggingface_transformers_bad_design/</guid>
      <pubDate>Fri, 16 Aug 2024 23:30:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] BAM！就这样：简单高效的混合专家参数升级</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu30k2/r_bam_just_like_that_simple_and_efficient/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu30k2/r_bam_just_like_that_simple_and_efficient/</guid>
      <pubDate>Fri, 16 Aug 2024 23:17:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 GPT-3.5 和 Haiku 在成本、延迟和准确性方面击败 GPT-4o 结构化输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etyrs8/r_beating_gpt4o_structured_output_with_gpt35_and/</link>
      <description><![CDATA[完整帖子：https://www.boundaryml.com/blog/sota-function-calling 使用 BAML，我们几乎解决了1 个 伯克利函数调用基准 (BFCL)（每个模型）（gpt-3.5+）。期待很快分享 arXiv 论文！ https://preview.redd.it/78uxa0xx5pid1.png?width=916&amp;format=png&amp;auto=webp&amp;s=f36e9c6fbb8ea1939c5406e552b0dcf0a4f6fe20 主要发现  与任何本机函数调用 API 相比，BAML 在函数调用方面更准确、更便宜。它比 OpenAI 的 FC-strict API 快 2-4 倍。 BAML 的技术与模型无关，并且可以与任何模型一起使用而无需修改（甚至是开源模型）。 gpt-3.5-turbo、gpt-4o-mini 和 claude-haiku 与 BAML 配合使用的效果几乎与具有结构化输出的 gpt4o 一样好（不到 2%） 使用 FC-strict 而不是简单的函数调用可以改进每个较旧的 OpenAI 模型，但是 gpt-4o-2024-08-06 会变得更糟  背景 到目前为止，从 LLM 获得更好结果的唯一方法是：  迅速设计使用更长更复杂的提示来训练它 训练更好的模型  BAML 的不同之处  用类似 typescript 的定义替换 JSON 模式。例如 string[] 比 {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}&gt; 更容易理解。 使用一种新颖的解析技术（Schema-Aligned Parsing）代替 JSON.parse。SAP 允许输出中出现更少的标记，而不会因 JSON 解析而出现错误。例如，即使键周围没有引号，也可以解析它。 PARALLEL-5 [ { streaming_service: &quot;Netflix&quot;, show_list: [&quot;Friends&quot;], sort_by_rating: true }, { streaming_service: &quot;Hulu&quot;, show_list: [&quot;The Office&quot;, &quot;Stranger Things&quot;], sort_by_rating: true } ]  我们使用提示 DSL（BAML）来实现这一点[2]，而没有使用 JSON 模式或任何类型的约束生成。我们还与使用“工具”API 的 OpenAI 的结构化输出进行了比较，我们称之为“FC-strict”。 对未来的思考 模型真的非常好，是一种语义理解。 模型在必须完美的事情上真的很糟糕，比如完美的 JSON、完美的 SQL、编译代码等。 我们认为，与其努力训练结构化数据的模型或在生成时约束令牌，不如将工程努力应用于稳健地处理模型输出等领域，这将带来尚未开发的价值。    提交人    /u/kacxdak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etyrs8/r_beating_gpt4o_structured_output_with_gpt35_and/</guid>
      <pubDate>Fri, 16 Aug 2024 20:15:53 GMT</pubDate>
    </item>
    <item>
      <title>[P]：使用 LLM 自动化脚本中的 API 文档。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etyfi2/p_automating_api_documentation_in_the_script/</link>
      <description><![CDATA[大家好，我目前正在开展一个项目，旨在创建一个 AI 代码助手，从开发人员的角度帮助解决一些痛点。 我的项目中的一个功能是在输入脚本中创建 api 文档。 我正在使用 LLM 来帮助构建此功能，特别是 llama 3，使用 llama api，这是一个无键 api。 到目前为止，我正在努力构建此功能，目前我还没有主意。 希望大家对如何进一步进行提出想法和意见。 此外，如果有人想合作，这个项目是一个开源项目，欢迎所有贡献。    提交人    /u/Sherlock_holmes0007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etyfi2/p_automating_api_documentation_in_the_script/</guid>
      <pubDate>Fri, 16 Aug 2024 20:01:34 GMT</pubDate>
    </item>
    <item>
      <title>多模态LLM解析策略[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ettoy9/multimodal_llm_parsing_strategyd/</link>
      <description><![CDATA[我正在尝试从车辆用户手册中提取图像、表格和文本，我目前的方法是使用预训练的 yolov8 模型来处理图像，使用微调的模型来处理表格，然后使用 OCR 来提取文本。除了在我的自定义数据集上对 YOLO 进行微调外，还有其他有前途的方法吗？我在想我会使用多模态 LLM 来总结每个有图像的页面，并提示它为每个图像专门生成单独的摘要。正在寻找具有成本效益的替代方法，但我需要提取和总结至少 95% 的相关图像    提交人    /u/ashblue21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ettoy9/multimodal_llm_parsing_strategyd/</guid>
      <pubDate>Fri, 16 Aug 2024 16:45:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 生产中的迭代模型改进</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etn0x2/p_iterative_model_improvement_in_production/</link>
      <description><![CDATA[大家好， 我创建了一个多类分类模型，并在一个带标签的数据集上对其进行了训练。说实话，在本地数据集上表现得相当不错，现在我正打算将其软启动到生产环境中。输入数据将转换为 n 维输入向量，绘制在图表上时不会形成凸形或规则形状（至少我的 EDA 显示了这一点）。由于我无法预见所有可能的模型输入，因此该模型无法完美处理每种情况，我想这没问题，但我正在寻找广泛的用例。这将导致大量误报，我想将其迭代添加到我的训练数据语料库中并随着时间的推移改进模型。 我正在寻找一种有效的方法来识别和管理这些误报。我在考虑：1）随机抽样数据子集并手动标记以验证其是真阳性还是假阳性。 2）获取用户反馈以识别错误分类的反馈。 3）使用聚类技术，其指标包括 Silhouette 分数、Davies-Bouldin 指数、Calinski-Harabasz 指数 (CH)、归一化互信息 (NMI) 或 Dunn 指数。 4）结合 1）和 3）？识别一些假阳性，然后通过聚类找到可能也是假阳性的类似结果 我的最终目标是创建一个随着时间推移不断改进的管道。您将如何解决这个问题？谢谢！    提交人    /u/Queasy_Tailor_6276   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etn0x2/p_iterative_model_improvement_in_production/</guid>
      <pubDate>Fri, 16 Aug 2024 12:06:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] PINN 的嵌套 AD</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etkmm6/r_nested_ad_for_pinns/</link>
      <description><![CDATA[我目前正在尝试求解 Lu = f 形式的 PDE，其中 L 是二阶微分算子。我正在进行无监督学习，损失函数只是残差 Lv - f 的通常 MSE，其中 v 是我对 u 的近似值。 由于 L 具有二阶导数，这意味着我们在训练期间获取网络梯度时会获取三阶导数。这太麻烦了（我使用的是 Flux.jl，而 Zygote 无法很好地处理嵌套的三阶 AD），所以我最终求助于 L 的有限差分离散化，这样 AD 的唯一应用就是网络本身的梯度，而没有另外 2 个嵌套的梯度。当然，我很想避免使用有限差分，但我真的没有其他方法。 有人处理过类似的情况吗？根据我的发现，似乎大家一致认为三阶嵌套 AD 确实不切实际，但我希望它还有更多内容。 提前感谢任何输入！ 编辑：在许多情况下，可以以变分形式重新计算问题以将阶数降低 1，但不幸的是，这对我的 PDE 来说是不可能的    提交人    /u/Fleico   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etkmm6/r_nested_ad_for_pinns/</guid>
      <pubDate>Fri, 16 Aug 2024 09:45:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可重复性检查表 AAAI25</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ethhro/d_reproducibility_checklist_aaai25/</link>
      <description><![CDATA[大家好， 我正在准备向 AAAI 提交论文，我遇到了可重复性检查表的要求。我对如何提交此检查表有点困惑。它应该作为附录包含在主要论文中，还是需要作为单独的文档上传？此外，如果它包含在论文中，它是否计入页数限制？ 任何曾经向 AAAI 提交过论文或有此过程经验的人的见解都将不胜感激！ 提前致谢！    提交人    /u/Ok_Butterfly7408   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ethhro/d_reproducibility_checklist_aaai25/</guid>
      <pubDate>Fri, 16 Aug 2024 06:10:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审稿人 2 - NeurIPS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etb4qh/d_reviewer_2_neurips/</link>
      <description><![CDATA[NeurIPS 辩驳期终于结束了。大家的审稿怎么样？ 我和一位审稿人打过交道，这是最糟糕的经历。对于最初的评论，他/她只写了一个简短的段落，问了一堆可以通过论文内容轻松回答的问题，然后给了 3 分和 4 分的置信度。对于辩驳，这位审稿人给出了相互矛盾的陈述，甚至无法理解训练数据和测试数据之间的区别。我花了整整两天时间解释这种区别。最后，审稿人留下了关于论文的错误陈述然后消失了。典型的审稿人 2。    提交人    /u/DrSolar789   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etb4qh/d_reviewer_2_neurips/</guid>
      <pubDate>Fri, 16 Aug 2024 00:27:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢所有人在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Aug 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>