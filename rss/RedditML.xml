<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 01 Apr 2024 01:02:55 GMT</lastBuildDate>
    <item>
      <title>[D] 快速、经济地获取数据进行微调的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsnv6t/d_what_is_the_best_way_to_quickly_and_affordably/</link>
      <description><![CDATA[如果您想为 DPO 获取 10,000 个高质量输入/输出对或为 KTO 获取首选项，最好的方法是什么？  据我了解，您不能使用 GPT4 创建合成数据（将用于训练商业模型），因为这违反了他们的条款。    由   提交/u/JT_NVG8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsnv6t/d_what_is_the_best_way_to_quickly_and_affordably/</guid>
      <pubDate>Sun, 31 Mar 2024 23:07:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 扩散模型的衰减点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsnabt/d_fall_off_point_for_diffusion_models/</link>
      <description><![CDATA[有没有人从理论上或实验上计算过为稳定扩散 1.5 或 SDXL 等扩散模型训练的图像数量的下降点？  也就是说：如果你有一个用 N 张图像训练的模型，它可以产生“好的”结果。训练过的类别中的图像。然后，您对新类别中的“A”张额外图像进行额外训练。图像总数是多少 T = N + A，这样当您达到 T 的值时，原始类别中生成的图像质量开始下降？  我知道扩散模型是“有损压缩”。图像数据，但即使进行压缩，毕竟 2GB 或 6GB 模型可以容纳的信息量也是有限的。因此，我感兴趣的是可以进行最有效的训练量特定的模型类型。    由   提交/u/lostinspaz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsnabt/d_fall_off_point_for_diffusion_models/</guid>
      <pubDate>Sun, 31 Mar 2024 22:43:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何评估文本到图像模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsmf0j/d_how_to_evaluate_texttoimage_model/</link>
      <description><![CDATA[在文本到图像生成问题中，单个文本描述可以转换为不同的图像（多样性），例如，给定描述“ “这只鸟是白色的，有黄色的翅膀”，生成的图像都将是一只白色的有黄色翅膀的鸟，但在姿势、背景等方面可能有所不同，使得每个图像根据描述仍然是正确的。然而，在验证数据集中，每个文本描述都对应一个实际图像。 那么，如何评估模型的性能呢？具体来说，如何将多个正确生成的图像与单个真实图像进行比较？是否可以应用 Inception Score 和 FID 等指标？如果可以，它们是如何工作的？谢谢   由   提交 /u/Equivalent-Funny3396    reddit.com/r/MachineLearning/comments/1bsmf0j/d_how_to_evaluate_texttoimage_model/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsmf0j/d_how_to_evaluate_texttoimage_model/</guid>
      <pubDate>Sun, 31 Mar 2024 22:07:58 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 尝试理解 AutoBNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsm5e7/dr_trying_to_understand_autobnn/</link>
      <description><![CDATA[时间序列预测专家能否介绍一下 Google 的 AutoBNN？它与典型的 LSTM、基于 RNN 的 BNN 或 NN 模型有何不同和更好之处？ https://blog.research.google/2024/03/autobnn- probabilistic-time-series.html?m=1   由   提交/u/bahauddin_onar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsm5e7/dr_trying_to_understand_autobnn/</guid>
      <pubDate>Sun, 31 Mar 2024 21:57:11 GMT</pubDate>
    </item>
    <item>
      <title>时间序列的最佳自监督学习任务 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsl2j6/best_selfsupervised_learning_task_for_timeseries_d/</link>
      <description><![CDATA[我正在研究多变量时间序列的基础模型（特别是脑相关数据，如脑电图）。有一些基础模型，其中大多数似乎都专注于屏蔽自动编码。我只见过一个人考虑对比学习。对于此类数据，考虑去噪自动编码或其他 SSL 任务或某种组合是否更有意义？网上或当前文献中似乎没有对此问题的直接答案。   由   提交 /u/Funny-Explorer-854   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsl2j6/best_selfsupervised_learning_task_for_timeseries_d/</guid>
      <pubDate>Sun, 31 Mar 2024 21:11:55 GMT</pubDate>
    </item>
    <item>
      <title>[D]有人用bluesky或mastodon吗？我应该关注哪些知名的 ML 人士？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bskvlh/d_anyone_using_bluesky_or_mastodon_who_are_some/</link>
      <description><![CDATA[有点想摆脱 twitter   由   提交 /u/hempock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bskvlh/d_anyone_using_bluesky_or_mastodon_who_are_some/</guid>
      <pubDate>Sun, 31 Mar 2024 21:03:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在没有模型答案的情况下，算法如何对答案进行评分？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsgeo9/d_how_is_the_algorithm_scoring_an_answer_without/</link>
      <description><![CDATA[以下研究是一个示例“半开放式问题的自动简答评分模型”。 文章链接：https://www.researchgate.net/publication/334776307_An_automatic_short-answer_grading_model_for_semi-open-ished_questions  该研究将 LSTM 训练为预测答案分数的分类器。 LSTM 正在获取标记化答案中每个单词的词向量。但我不明白算法如何仅通过词向量来判断答案是否完整/不完整/不正确？ 模型答案不应该至少用于内容比较吗？ &gt;   由   提交 /u/LyannaEugen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsgeo9/d_how_is_the_algorithm_scoring_an_answer_without/</guid>
      <pubDate>Sun, 31 Mar 2024 17:54:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 ML 作品集中，什么更令人印象深刻：实施一篇论文还是创建一个好的项目？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bsezcf/d_whats_more_impressive_in_a_ml_portfolio/</link>
      <description><![CDATA[大家好，从您的经验来看，公司的招聘经理更喜欢什么，是出色的论文实施还是出色的实际项目？我知道两者都有很大的好处、优点和缺点等。但是，reddit 上的管理者在查看回购协议时喜欢看到什么？在考察候选人的技能时，其中一个会比另一个更好吗？   由   提交 /u/ninvibe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bsezcf/d_whats_more_impressive_in_a_ml_portfolio/</guid>
      <pubDate>Sun, 31 Mar 2024 16:51:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM预训练和评估奖励模型的技巧——讨论2024年3月的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs95b8/p_tips_for_llm_pretraining_and_evaluating_reward/</link>
      <description><![CDATA[ 由   提交/u/seraschka  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs95b8/p_tips_for_llm_pretraining_and_evaluating_reward/</guid>
      <pubDate>Sun, 31 Mar 2024 12:21:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] Auto-Ollama 和 Auto-GGUF：只需一个命令即可简化微调 LLM 的本地推理和 GGUF 量化 🦙🔄💻</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs8w96/p_autoollama_autogguf_simplify_local_inference/</link>
      <description><![CDATA[      周末小项目，我编写了脚本：Auto-Ollama 🦙 和 Auto-GGUF 🔄。 这些脚本简化了本地推理微调模型（Lora、QLora 适配器等）的过程💻。借助 Auto-Ollama 脚本，您只需一行代码即可将 Ollama 用于任何高频微调适配器✨。 如果模型没有 GGUF 格式，则 Auto-GGUF脚本将模型转换为 GGUF，同样只需一个命令。 我正在检查资源，除了 LMstudio 等之外找不到直接的推理方法，所以我想分享这个。我希望它对您的研究有用。 https://github.com/monk1337/ auto-ollama/ https://preview.redd.it/l1v5v03funrc1.png?width=1832&amp;format=png&amp;auto=webp&amp;s=cf65c127ec22d2e669474bab46497ad441fce311   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs8w96/p_autoollama_autogguf_simplify_local_inference/</guid>
      <pubDate>Sun, 31 Mar 2024 12:07:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 曼巴解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs1va2/p_mamba_explained/</link>
      <description><![CDATA[帖子：https://thegradient.pub/mamba-解释/ ​ 这里我们将讨论：  Mamba 的优点（和缺点）（🐍 ）与变形金刚（🤖）， 思考 Mamba 的类比和直觉，以及  Mamba 对于可解释性、人工智能安全和应用意味着什么。  本文最初发布于Kola 的个人博客。&lt; /p&gt;  ​   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs1va2/p_mamba_explained/</guid>
      <pubDate>Sun, 31 Mar 2024 04:32:28 GMT</pubDate>
    </item>
    <item>
      <title>华尔街日报：人工智能行业在 Nvidia 芯片上的支出是其收入的 17 倍 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bs1ebl/wsj_the_ai_industry_spent_17x_more_on_nvidia/</link>
      <description><![CDATA[ ... 在本月早些时候的一次演示中，风险投资公司红杉估计人工智能行业在 Nvidia 芯片上花费了 500 亿美元去年用于训练先进的人工智能模型，但仅带来了 30 亿美元的收入。   来源：《华尔街日报》（付费）   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bs1ebl/wsj_the_ai_industry_spent_17x_more_on_nvidia/</guid>
      <pubDate>Sun, 31 Mar 2024 04:06:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] DL 编译器中基于多面体的 IR 背后的直觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brz8t6/d_intuition_behind_polyhedralbased_ir_in_dl/</link>
      <description><![CDATA[阅读时https://arxiv.org/abs/2002.03794 ，我看到了一个关于基于多面体的IR的部分；我的理解是：想象一下，你有一个代表张量的 3D 立方体（我们称之为 A）；假设您有一个嵌套循环，它访问 A 的子多维数据集（我们称之为 B），其中每个 i 次访问都需要第 (i -1) 次访问的结果（B 由单元组成，循环正在访问这些单元）。基于多面体的 IR 优化上述循环的方式是将 B 划分为可能的独立块（每个块都是一个|多个单元），然后对它们进行排列，以便现在可以并行访问多个块。 是这是考虑基于多面体的 IR 的正确方法吗？ 上述调查似乎非常好，但有点过时了。还有其他被忽视的有关 DL 编译器的最新论文/论文吗？   由   提交 /u/qctm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brz8t6/d_intuition_behind_polyhedralbased_ir_in_dl/</guid>
      <pubDate>Sun, 31 Mar 2024 02:15:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我比较了用于长格式转录的不同开源耳语包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1brrcjd/p_i_compared_the_different_open_source_whisper/</link>
      <description><![CDATA[      大家好！  我最近比较了所有支持长格式转录的基于开源耳语的软件包。 长格式转录基本上是转录超过 30 秒的音频文件。 长格式转录基本上是转录超过 30 秒的音频文件。 p&gt; 如果您想通过 YouTube 视频或播客等聊天，这会很有用。 我比较了以下软件包：  OpenAI 的官方 Whisper 软件包&lt; /li&gt; Huggingface Transformer Huggingface BetterTransformer FasterWhisper WhisperX Whisper.cpp  我在以下方面对它们进行了比较：  准确性 - 使用单词错误率 (wer) 和字符错误率 (cer) 效率 - 使用 vram使用情况和延迟  我写了一份详细的关于此的博客文章。如果您只想要结果，这里是： ​ https://preview.redd.it/96e3wmnv5jrc1.jpg?width=817&amp;format=pjpg&amp;auto=webp&amp;s=f6f18147e3bdbfb 9f1834c5f758bcb1014a1fbbf 希望您觉得它有用！   由   提交/u/Amgadoz  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1brrcjd/p_i_compared_the_different_open_source_whisper/</guid>
      <pubDate>Sat, 30 Mar 2024 20:23:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>