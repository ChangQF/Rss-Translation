<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 08 Jan 2025 01:15:58 GMT</lastBuildDate>
    <item>
      <title>[R][P] DistillKitPlus：面向法学硕士的高性能知识提炼</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hw0mn9/rp_distillkitplus_high_performent_knowledge/</link>
      <description><![CDATA[具有 LoRA 微调 和 量化支持 的 LLM KLD 开源工具包&gt; 较大的 LLM 泛化更好、更快。您可以利用这一点，然后将 70B 模型的最佳效果转移到 7B 模型，而无需花费太多资金或牺牲性能。 GitHub 链接：https://github.com/agokrani/distillkitplus    提交人    /u/__XploR__   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hw0mn9/rp_distillkitplus_high_performent_knowledge/</guid>
      <pubDate>Tue, 07 Jan 2025 20:08:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士 (LLM) 最终会输出莎士比亚全集吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvzuao/d_would_an_llm_output_the_complete_works_of/</link>
      <description><![CDATA[鉴于 LLM 是非确定性的，因此可以推测，在任何时候，任何 token 都有非零的输出概率。因此，在无限的时间下，LLM 可能恰好能够输出莎士比亚的全集，就像那些猴子一样……对吧？    提交人    /u/HCOJIO   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvzuao/d_would_an_llm_output_the_complete_works_of/</guid>
      <pubDate>Tue, 07 Jan 2025 19:36:24 GMT</pubDate>
    </item>
    <item>
      <title>[研发] 白盒变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvy385/rd_white_box_transformers/</link>
      <description><![CDATA[在此研究线上开启一个主题：https://ma-lab-berkeley.github.io/CRATE/ 据我了解，作者基本上将学习有效数据表示的过程定义为寻找多元高斯字典的问题，该字典以简约方式覆盖数据分布。特别是，在特征/高斯方面使用稀疏编码。 构建一个架构，该架构采用多个交替步骤“聚类”相似向量并分别正交化来自不同聚类的向量，最终得到类似于 Vision Transformer 的结构。类似 MultiHead Attention 的模块将向量聚类，使它们更接近局部主方向或流形，类似 MLP 的模块将这些向量沿着相互更正交的轴移动。从数学上讲，它们近似于明确定义的稀疏编码率，因此是白盒算法，但是我不能说数学比 Transformers 更直观。 事实上，最后一层的 CLS 注意力头在图像分类监督训练下具有可解释的偏好，如在 DINO（自我监督）或 SimPool 中。这与过程的解释直接相关，并为 DINO 的可解释性和动态性提供了解释。它也被称为 George Hinton 的视觉智能架构蓝图，即 GLOM Transformer。 我认为注意力的聚类效应在文献中在某种程度上没有得到充分重视，就像 Transformers 中 FFN 的作用没有得到充分研究一样。我想知道是否有第三种方法在数学上像 MLP 一样简单，像高斯特征词典一样直观。    提交人    /u/Sad-Razzmatazz-5188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvy385/rd_white_box_transformers/</guid>
      <pubDate>Tue, 07 Jan 2025 18:23:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 嵌入空间中的位置嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvxpcc/d_positional_embeddings_in_embedding_space/</link>
      <description><![CDATA[原始位置编码在特征空间中是如何分布的？RPE 是如何分布的？这些嵌入和 LayerNorm（删除与均匀向量平行的分量，即 1 的向量）之间的相互作用是什么？    提交人    /u/Sad-Razzmatazz-5188   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvxpcc/d_positional_embeddings_in_embedding_space/</guid>
      <pubDate>Tue, 07 Jan 2025 18:07:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师，你的工作中最有价值的事情是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvx2pq/d_ml_engineers_what_is_the_most_rewarding_thing/</link>
      <description><![CDATA[有些人告诉我这是薪水问题，但我认为这取决于你的经验水平以及你为谁工作？这份工作还有更多内容吗？    提交人    /u/RespectPrivacyPlz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvx2pq/d_ml_engineers_what_is_the_most_rewarding_thing/</guid>
      <pubDate>Tue, 07 Jan 2025 17:42:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪种模型最适合对平坦的街道级图像进行训练？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvvto8/d_which_model_is_best_for_training_on_flattened/</link>
      <description><![CDATA[TL;DR：我正在做一个学校项目，使用 Insta360 相机拍摄的扁平 360° 图像识别小镇中的位置，并标有 GPS 坐标。目标是通过训练视觉位置识别模型来预测普通手机照片（不是 360°）的 GPS 位置。我正在考虑 DELF、LoFTR、视觉转换器 (ViT/DINO) 或微调 ResNet/EfficientNet，但我不确定哪个最适合处理等距矩形投影和这项特定任务。任何有关模型选择或数据集准备的建议都将不胜感激！ 大家好！ 我目前正在做一个学校项目，我试图根据街道级图像识别小镇中的特定位置。为了收集数据，我使用 Insta360 相机并定期捕捉 360° 图像。我还确保数据中包含一天中不同时间和各种天气条件下拍摄的图像，以使模型更加稳健。 为了准备训练数据，我将 360° 图像转换为扁平的等距矩形投影。在某些情况下，我可能还会将它们裁剪成较小的视图，例如立方体贴图投影。这些处理后的图像中的每一张都标有 GPS 坐标，我希望模型在稍后给出新的查询图像时能够预测这些坐标。查询图像将是使用手机拍摄的普通照片，因此它们不是 360° 图像，而是标准的肖像或风景照片。 我一直在研究这项任务的可能模型，并遇到了 DELF、LoFTR 和视觉转换器，如 ViT 或 DINO。我不确定哪种模型最适合我的项目，因为我需要能够基于扁平或裁剪的 360° 图像处理视觉位置识别的东西。我也在考虑对 ResNet 或 EfficientNet 等预训练模型进行微调是否可能是更好的方法。 如果您能提供任何关于哪种模型最适合解决此类问题的建议或推荐，我将不胜感激。如果有人有使用等距矩形投影或训练数据集进行视觉位置识别的经验，我很乐意听听您的想法。提前感谢您的帮助！    提交人    /u/GroundbreakingTea195   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvvto8/d_which_model_is_best_for_training_on_flattened/</guid>
      <pubDate>Tue, 07 Jan 2025 16:51:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对你来说，机器学习最吸引人的方面是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvqdvt/d_what_is_the_most_fascinating_aspect_of_machine/</link>
      <description><![CDATA[标题。您可以根据自己的意愿主观地解释这个问题。    提交人    /u/AromaticEssay2676   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvqdvt/d_what_is_the_most_fascinating_aspect_of_machine/</guid>
      <pubDate>Tue, 07 Jan 2025 12:30:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] ACL ARR 公开匿名预印本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvk8m0/d_acl_arr_public_anonymous_preprint/</link>
      <description><![CDATA[我将论文提交给 ARR 十二月周期并勾选了发布公开匿名预印本的复选框。三周后我仍然找不到预印本链接。有人知道我什么时候可以获得公开匿名预印本的链接吗？    提交人    /u/Master_Ocelot8179   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvk8m0/d_acl_arr_public_anonymous_preprint/</guid>
      <pubDate>Tue, 07 Jan 2025 05:18:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] NLP/LLM 中的优化技术是否也适用于基于 Transformer 的序列建模？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hvj7fx/d_optimization_techniques_in_nlpllm_that_also/</link>
      <description><![CDATA[标题。 尝试集思广益，看看是否有可以在 NLP 用例中应用的技术可用于序列建模。 具体来说，我正在尝试优化推荐系统（用户表示建模）中使用的变压器。 到目前为止，我能想到的基本知识是：闪光注意、高效/线性变压器、融合核嵌入、用于训练/服务的混合精度/量化。 还有其他什么或其他论文浮现在脑海中吗？ 我认为主要问题有时是用户序列表示或 rec sys 之类的标记概念与 LLM 中的标记概念截然不同。我们还处理更稀疏的嵌入…… 提前致谢！    提交人    /u/Tough_Palpitation331   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hvj7fx/d_optimization_techniques_in_nlpllm_that_also/</guid>
      <pubDate>Tue, 07 Jan 2025 04:19:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数学证明作为新颖推理的基准？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hveq4q/d_mathematical_proofs_as_benchmarks_for_novel/</link>
      <description><![CDATA[我不是专家，但我一直在密切关注关于 LLM 和推理的学术讨论，我认为没有足够的基准来展示推理，而不是简单地直接从训练数据中应用信息（在 CoT 的情况下是迭代的）。 理想的基准应具有 3 个属性：1. 清晰地展示新颖的推理，而不仅仅是解决难题或应用高级技术 2. 易于（或尽可能接近简单）验证推理的正确性和存在性 3. 易于控制训练或调整数据的污染 至于第 1 点，很明显，通常我们确保新颖推理的唯一方法是使用学术主题，因为新颖的推理是其主要目的 第 2 点在很多领域中都很难确定什么是正确性或推理，这是错误的选择，即使用历史背景和情节点列表进行推理文献？可能不是，但当这些是分析的关键部分时，你怎么能说清楚呢？当历史学家对青铜时代的一些文物的含义存在分歧时，我们怎么能说历史上什么是正确的呢？第 3 点还排除了许多在各种可能的训练材料中直接讨论的领域或其通用技术，因此无法整理没有污染的训练数据。 据我所知，唯一适合的问题类型是数学证明，具体来说，我们可以更容易地隔离证明中的新颖之处，更容易验证证明的正确性（1 位给出通过的专家可以检测到大多数主要错误，而答案不明确的团队则无法检测到），并确保训练数据既没有实际证明也没有直接证明步骤（我的理解是，o3 的前沿数学得分是由于迭代地找到已经存在并符合其当时知识的数学技术） 具体来说，我建议基准的最佳证明应该是非常重要的，需要发明新的数学（因此它肯定需要多步新颖的推理，并且长度足够长，而不仅仅是猜测），不再是最先进的（我们可以通过使用几乎肯定在证明相关问题之前不会拥有专家数学和手工挑选的数学，再加上通过在该领域进行进一步的概括，将很容易验证证明的替代方法的有效性），并且应该本质上更抽象，即抽象代数或群论或费马最后定理而不是微分方程技术，以便更少的现有技术直接应用 我怀疑，如果没有新颖的推理，任何答案都会以明显的方式出错并且容易被发现，并且任何只有细微错误的答案都很容易重试，只需在调整/训练中稍加改变即可正确 所以我想知道：这个想法是否完全合理？如果是这样，什么证明最好？    提交人    /u/nnnnnnnnnerdddd   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hveq4q/d_mathematical_proofs_as_benchmarks_for_novel/</guid>
      <pubDate>Tue, 07 Jan 2025 00:36:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] Jensen 不等式的交互式几何可视化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hv5qoe/p_interactive_and_geometric_visualization_of/</link>
      <description><![CDATA[大家好， 上周我一直在学习 Jensen 不等式。我对互联网上给出的大多数代数解释都不满意。因此，我写了一篇解释几何可视化的文章，到目前为止我还没有看到过类似的解释。我使用交互式可视化来展示我在脑海中如何对其进行可视化。  以下是文章 https://maitbayev.github.io/posts/jensens-inequality/ 让我知道你的想法    提交人    /u/madiyar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hv5qoe/p_interactive_and_geometric_visualization_of/</guid>
      <pubDate>Mon, 06 Jan 2025 18:20:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于法学硕士的错误信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1huxrd2/d_misinformation_about_llms/</link>
      <description><![CDATA[还有人对 Reddit 评论中有关 LLM 的不良信息比例感到吃惊吗？对于任何高级主题来说，这都是危险的，但围绕 LLM 的讨论似乎已经完全偏离了轨道。老实说，我觉得这有点奇怪。不良信息被疯狂地点赞，而知情的评论最多只能被忽略。令我惊讶的不是这种情况正在发生，而是它如此持续地处于“自信错误”的领域    提交人    /u/HasFiveVowels   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1huxrd2/d_misinformation_about_llms/</guid>
      <pubDate>Mon, 06 Jan 2025 12:20:43 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 实数的嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1huvvqk/discussion_embeddings_for_real_numbers/</link>
      <description><![CDATA[大家好。我正在研究一个想法，在某个时候我遇到了一个实数序列。我需要学习每个实数的嵌入。到目前为止，我尝试将标量与可学习向量相乘，但它没有起作用（如预期的那样）。那么，有没有更有趣的方法可以做到这一点？ 谢谢    提交人    /u/Dry-Pie-7398   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1huvvqk/discussion_embeddings_for_real_numbers/</guid>
      <pubDate>Mon, 06 Jan 2025 10:15:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 05 Jan 2025 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>