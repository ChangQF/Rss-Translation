<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 23 Nov 2024 21:16:00 GMT</lastBuildDate>
    <item>
      <title>[D] 需要的建议：图像到 3D 扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy9dqd/d_recommendations_needed_imageto3d_diffusion/</link>
      <description><![CDATA[大家好，我正在为一个项目评估不同的开源图像到 3D 扩散模型，并且可以使用一些现实世界的见解。我一直在研究论文，但很想听听真正实施过这些论文的人的意见。 我的主要要求：  质量是重中之重 - 寻找干净、准确的重建 需要基于网格的输出（而不是点云或神经场），并且不是天文数字 推理时间并不重要 - 很乐意每代等待一分钟  我看过 Zero123、Wonder3D 和其他一些，但很好奇在实践中什么对人们有效。特别感兴趣：  哪些模型实际上可以在生产中维护 网格生成质量是否存在任何缺陷 您看到的实际推理时间 通常需要多少后处理  非常希望听到您的经验，特别是在实际项目中部署过这些经验的人的经验。谢谢！    提交人    /u/ESCNOptimist   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy9dqd/d_recommendations_needed_imageto3d_diffusion/</guid>
      <pubDate>Sat, 23 Nov 2024 20:44:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 迭代缩小：增强 GUI 位置定位的视觉提示框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy8tgs/r_iterative_narrowing_a_visual_prompting/</link>
      <description><![CDATA[本文介绍了一种用于 GUI 元素基础的迭代缩小方法，该方法通过多个细化步骤而不是一次性处理视觉和文本信息。关键见解是将元素识别分解为从粗到细的阶段，以反映人类视觉搜索界面的方式。 关键技术要点：* 两阶段架构：初始区域提议网络，然后进行重点细化* 视觉和文本编码器在交叉注意对齐之前并行处理特征* 通过多次传递逐步缩小范围可减少误报* 通过分层表示处理嵌套的 GUI 元素* 使用自然语言查询在 77K GUI 屏幕截图的数据集上进行训练 结果显示：* 与单次传递基线相比，接地准确度提高了 15%* 更好地处理模糊查询* 与穷举搜索相比减少了计算开销* 在复杂的嵌套界面上表现出色* 有效转移到看不见的 GUI 布局 我认为这种方法可以通过使元素识别更加健壮来显著改进可访问性工具和 GUI 自动化。迭代细化反映了人类的视觉搜索模式，这可以实现与界面更自然的交互。 我认为主要的限制是处理高度动态的界面，其中元素经常移动或更改。多通道特性还会引入一些延迟，需要针对实时应用程序进行优化。 TLDR：新的 GUI 接地方法使用多个细化通道来更准确地识别界面元素，通过模仿人类视觉搜索模式的方法将准确率提高了 15%。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy8tgs/r_iterative_narrowing_a_visual_prompting/</guid>
      <pubDate>Sat, 23 Nov 2024 20:19:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 专注于解决模型参数的优化算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy6jy6/d_optimization_algorithm_that_focuses_on_solving/</link>
      <description><![CDATA[我尝试在 Google 上搜索任何来源，但有人知道我可以在哪里开始寻找优化算法，该算法专注于通过求解特定参数（或多个参数）来优化模型参数，给定样本的输入和目标？或者这种优化算法的名称？例如，求解函数 y = ax^2 + bx + c 的模型参数 a、b、c，x 和 y 分别是输入和目标。当然，这个算法在 ml 上下文中有一个名称。 编辑： 我认为我问的有点模棱两可。与梯度下降相反，梯度下降专注于找到模型参数对提供的损失的导数，我上面指定的优化算法专注于许多参数并以某种方式找出（或求解这些参数的值）以大致匹配输出。就像你有 5x = 10 并求解 x 一样，所以算法计算出 x=2。对于更多数据样本和更多参数，您有 5x + c = 12 和 2x + c = 6，x 和 c 是模型参数，10 ad 4 是所需输出。该算法以某种方式计算出 x = 2 和 c = 2。这有点牵强，但即使我开始怀疑我的理智，也足以相信我所问的基本上是所有（如果不是大多数）机器学习优化算法所做的。    提交人    /u/Relevant-Twist520   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy6jy6/d_optimization_algorithm_that_focuses_on_solving/</guid>
      <pubDate>Sat, 23 Nov 2024 18:40:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我可以在 iPhone 上的 Pythonista 中训练的最佳轻量级 Al 模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy68ed/d_best_lightweight_al_model_i_can_train_in/</link>
      <description><![CDATA[有谁知道我可以使用哪些人工智能脚本来开始训练一个像 Siri 一样的模型，并连接到 iPhone 快捷方式，以便它可以完成我要求它做的事情？提前谢谢了！    提交人    /u/Lep-Dobson   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy68ed/d_best_lightweight_al_model_i_can_train_in/</guid>
      <pubDate>Sat, 23 Nov 2024 18:26:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是我在 Medium 上的第一篇博客，内容是：现代二进制 Hopfield 网络如何只是伪装的汉明距离自动完成器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy4qpv/d_this_is_my_first_blog_on_medium_and_they_are/</link>
      <description><![CDATA[    /u/StoneSteel_1   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy4qpv/d_this_is_my_first_blog_on_medium_and_they_are/</guid>
      <pubDate>Sat, 23 Nov 2024 17:22:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用人工智能制作更可靠的报告——技术指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy1t45/d_how_to_make_more_reliable_reports_using_ai_a/</link>
      <description><![CDATA[       提交者    /u/phicreative1997   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy1t45/d_how_to_make_more_reliable_reports_using_ai_a/</guid>
      <pubDate>Sat, 23 Nov 2024 15:14:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过负特征值解锁线性 RNN 中的状态跟踪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy0hbh/r_unlocking_statetracking_in_linear_rnns_through/</link>
      <description><![CDATA[摘要：线性循环神经网络 (LRNN)（例如 Mamba、RWKV、GLA、mLSTM 和 DeltaNet）已成为大型语言建模中 Transformers 的有效替代品，可提供序列长度的线性缩放并提高训练效率。然而，LRNN 难以执行状态跟踪，这可能会损害代码评估或跟踪国际象棋游戏等任务的性能。偶数奇偶校验是最简单的状态跟踪任务，非线性 RNN（例如 LSTM）可以有效处理，但当前的 LRNN 无法解决。最近，Sarrof 等人 (2024) 证明，像 Mamba 这样的 LRNN 无法解决奇偶校验的原因是将其对角状态转换矩阵的值范围限制为 [0,1]，而加入负值可以解决这个问题。我们将此结果扩展到非对角 LRNN，它们最近在 DeltaNet 等模型中表现出了良好的前景。我们证明，状态转移矩阵只有正特征值的有限精度 LRNN 无法解决奇偶校验问题，而模 3 计数则需要复特征值。值得注意的是，我们还证明，当 LRNN 的状态转移矩阵是恒等向量减去向量外积矩阵的乘积时，它们可以学习任何常规语言，每个矩阵的特征值都在 [-1,1] 范围内。我们的实证结果证实，将 Mamba 和 DeltaNet 等模型的特征值范围扩展为包括负值，不仅可以使它们解决奇偶校验问题，而且可以持续提高它们在状态跟踪任务上的性能。此外，使用扩展的特征值范围进行语言建模的预训练 LRNN 实现了可比的性能和稳定性，同时在代码和数学数据上显示出良好的前景。我们的工作增强了现代 LRNN 的表现力，扩大了它们的适用性，同时又不改变训练或推理的成本。 https://arxiv.org/abs/2411.12537    提交人    /u/iltruma   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy0hbh/r_unlocking_statetracking_in_linear_rnns_through/</guid>
      <pubDate>Sat, 23 Nov 2024 14:11:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 资源：精准知识编辑 (PKE) 可降低法学硕士 (LLM) 中的毒性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gxyhwb/r_resource_precision_knowledge_editing_pke_for/</link>
      <description><![CDATA[为那些对人工智能安全和改进 LLM 感兴趣的人分享一个项目和论文。该方法称为精准知识编辑 (PKE)，旨在通过识别和修改负责生成有毒内容的特定神经元或层来减少 LLM 中的有毒输出。 主要亮点： - 使用神经元权重跟踪和激活通路追踪等技术来定位“有毒热点”。 - 应用自定义损失函数来降低毒性，同时保持模型性能。 - 在 Llama2-7b 和 Llama-3-8B 等模型上进行测试，毒性管理有显著改善（例如，降低攻击成功率）。 论文可在此处获取：https://arxiv.org/pdf/2410.03772 带有演示 Jupyter Notebook 的 GitHub 存储库：https://github.com/HydroXai/Enhancing-Safety-in-Large-Language-Models 可能对研究人员、开发人员或任何探索提高 LLM 安全性的方法的人有用。听听其他人对这种方法的看法会很有趣。    提交人    /u/Reagane371   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gxyhwb/r_resource_precision_knowledge_editing_pke_for/</guid>
      <pubDate>Sat, 23 Nov 2024 12:25:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] [项目] JAX ML 框架；编写神经网络及更多内容；更短更快；您的想法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gxqag6/d_project_jax_ml_framework_write_neural_networks/</link>
      <description><![CDATA[为机器学习制作了一个 JAX 框架，因为我想让代码更快更短，所以我制作了 zephyr。我希望它对你们也有帮助，也想听听大家的反馈。 链接在评论中。 当前框架没有问题，这只是做事的另一种方式。 对我来说，NN 或 ML 算法只是纯数学函数，所以我希望这能反映在我的代码中。对于其他框架，它至少包含 2 个步骤：构造函数中的初始化和转发/调用主体中的计算。这乍一看似乎不错，但是当模型变得更大时，我必须在 2 个地方同步代码。- 如果我更改计算，我可能需要在某处更改超参数，或者如果我更改超参数，我可能需要更改计算 - 或者如果我必须重新阅读我的代码，我必须至少在 2 个地方阅读。我通常使用一个小窗口作为编辑器，因此在它们之间跳转可能会很麻烦（将它们并排放置是另一种解决方案）。 我遇到的另一件事是，如果我正在做的事情不是神经网络，例如，如果一个算法用递归调用更容易（但每次调用都有不同的可训练权重），那么这在其他框架中会很有挑战性。因此，虽然它们是通用的计算图框架，但有些计算很难做。 对我来说，计算就是传递数据并让它们进行转换，所以这种转换数据的“行为”应该是框架的重点。这就是我用 zephyr 所做的。数学函数是 python 函数，不需要在构造函数中初始化。你可以在需要的时候使用这些函数（网络或层等）。不需要构造函数，允许递归，让你专注于转换或操作。Zephyr 为你处理权重的创建和管理——与其他框架不同，它是明确的；你随身携带一个“params”树，这应该没有问题，因为这是计算的核心，不应该被隐藏起来。 简而言之，zephyr 很短但易读，旨在帮助人们开发关于 ML 的研究想法。README 有一些神经网络的示例。我希望你们喜欢它并尝试它。    提交人    /u/Pristine-Staff-5250   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gxqag6/d_project_jax_ml_framework_write_neural_networks/</guid>
      <pubDate>Sat, 23 Nov 2024 03:25:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 已接受的 NeurIPS 2024 论文声称作为第一项工作解决了一个新问题，但忽略了 5 项先前的工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gxooqv/d_accepted_neurips_2024_paper_claimed_to_be/</link>
      <description><![CDATA[在 NeurIPS 2024 上，我发现了一篇被接受的论文，其主要贡献是“现有的针对 X 的算法忽略了 Y。我们调整了针对 X 的算法 Z 来考虑 Y”。 在 OpenReview 上，我看到审稿人特别称赞了这项工作的新颖性，并认为 Y 是 X 领域被忽视的一个重要方面。 现在有趣的是：合著者和我在 2023 年在 Springer 的机器学习杂志上发表了一篇论文，也提出了一种针对 X 的算法来解释 Y。我们也不是第一个研究 X 和 Y 问题设置的人：我们论文的相关工作部分讨论了 4 篇论文，它们都提出了针对 X 的算法来解释 Y。其中一篇甚至来自 NeurIPS（2017），最早的一篇可以追溯到 2012 年（一篇 AAAI 论文）。 这篇 2024 年的作者NeurIPS 论文完全忽略了所有这些先前的文献，并认为他们是第一批，所有审稿人也都这么认为。 本周，我给这篇 NeurIPS 2024 论文的作者发了电子邮件，他们承认这些工作（我的 + 其他 4 篇）确实都是在同一个问题设置上工作，并提到他们不知道所有这些工作，并承认他们不能再声称对问题设置具有新颖性。 NeurIPS 允许在会议结束后更新照相排版论文，作者承诺将利用这个机会合并那些相关工作并修改他们的贡献声明，不再声称对 X 和 Y 的第一个解决方案具有新颖性。 一方面，我很高兴我们的工作将得到适当的认可。 另一方面，我对在审查后严格修改贡献声明的道德性表示怀疑。作者不再声称具有新颖性，但审稿人特别赞扬了这种新颖性，这让我不确定如果审稿人知道这篇论文最终将不再能够声称其在审稿版本中声称具有的新颖性，他们是否会建议接受。 此外，这让我对实验部分感到疑惑。几乎可以肯定，审稿人会要求与这 5 篇先前的作品进行比较作为基线。这篇论文没有与基线进行比较，这在审稿人看来是合理的，因为他假设问题设置是完全新颖的，并且不存在可以作为基线的先前方法。 在这里询问小组关于如何解决此类案件的任何想法：- 应该撤回这篇论文吗？- 应该通知领域主席/计划委员会吗？谁可能会或可能不会采取行动 - 这篇论文是否应该按照承诺的方式由作者更新，就这样？ - 还有别的吗？ 我删除了 X、Y 和 Z，以免公开羞辱作者，因为他们已经与我的电子邮件互动，我确信没有犯规行为，他们真的不知道这些作品。    提交人    /u/TaXxER   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gxooqv/d_accepted_neurips_2024_paper_claimed_to_be/</guid>
      <pubDate>Sat, 23 Nov 2024 01:58:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 生成式 AI 媒体输出的历史档案？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gxh7dm/d_historical_archive_of_generative_ai_media_output/</link>
      <description><![CDATA[是否有档案或研究论文展示了生成式 AI 媒体输出随时间推移取得的进展？ 我想收集随时间推移生成的多媒体输出（文本、图像、视频、声音）的示例，以帮助评估该领域在每个领域的进展情况。  当然，我可以通过搜索从不同来源获取任何结果，但我想知道是否有一个更有组织、更一致的存储库？    提交人    /u/searchresults   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gxh7dm/d_historical_archive_of_generative_ai_media_output/</guid>
      <pubDate>Fri, 22 Nov 2024 20:15:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们已经进行了众包和开源，并且很容易找到很多可以用于构建的工具，但是，所有这些用于上下文/抓取的努力都到哪里去了呢？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gxbrdm/d_weve_crowdsourced_opensourced_and_made_it_easy/</link>
      <description><![CDATA[我们拥有许多可用于构建、部署和使用 LLM 执行任务的存储库和库。我们有模型中心、用于 LoRA 和 RAG 等的即插即用库、用于使用 API 部署模型的容器化、用于将 LLM 集成到 IDE 和工作流中的扩展等等。还有用于管理和编排代理的内容。 可以说，我们有大量开源工具可用于开始研究 LLM 的利基和一般用途。 这些都很棒，但我总是必须从头开始构建的是获取上下文。无论是用于在线搜索、网页解析（甚至是常见网页，我知道人们希望它们更容易用于上下文）、文档解析等的工具。 我看到越来越多的酷项目出现，但我看到这些项目越来越少地提供关于如何查找、访问、检索和处理上下文的细节或实现。 有很多库可以为此目的构建工具，但我看到分享这些工具的人越来越少。 现在我明白不同项目所需的上下文可能非常小众，因此可重用性可能很少。 但我的看法错了吗？是否有开源资源可用于查找现有的上下文提取/抓取实现，或者是否有地方可以提交您自己的实现以便于其他人找到？    提交人    /u/Oscilla   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gxbrdm/d_weve_crowdsourced_opensourced_and_made_it_easy/</guid>
      <pubDate>Fri, 22 Nov 2024 16:26:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 熵引导的关键神经元修剪，实现高效的脉冲神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gx86i0/r_entropyguided_critical_neuron_pruning_for/</link>
      <description><![CDATA[本文介绍了一种基于神经科学临界原理的脉冲神经网络（SNN）的修剪方法。关键见解是使用神经元雪崩分析来识别对网络动态影响最大的神经元，类似于关键神经元在生物大脑中的功能。 关键技术要点：* 监测尖峰传播模式以识别关键神经元* 根据网络稳定性指标引入自适应修剪计划* 在保持 MNIST/CIFAR-10 准确性的同时实现 90% 的压缩* 适用于不同的 SNN 架构（前馈、CNN）* 使用稳定性措施防止修剪过程中的灾难性遗忘 主要结果：* 在准确性保持方面优于现有的修剪方法* 与未修剪的网络相比显示出更好的能源效率* 保持对 SNN 操作很重要的时间动态* 展示跨不同网络规模的可扩展性* 通过雪崩分析验证生物启发 我认为这种方法对于在资源受限的环境（如边缘设备）中部署 SNN 尤其重要。自适应修剪计划似乎特别有前景，因为它可以根据网络行为自动调整，而不需要手动调整。 我认为，对于非常大的网络，需要解决一些关于雪崩分析计算开销的未解决的问题。然而，该方法背后的生物学原理表明它可以很好地推广到其他架构和任务。 TLDR：基于神经科学临界原理的 SNN 新型修剪方法。使用神经元雪崩分析来识别重要神经元，并在保持准确性的同时实现 90% 的压缩。引入了根据网络稳定性进行调整的自适应修剪计划。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gx86i0/r_entropyguided_critical_neuron_pruning_for/</guid>
      <pubDate>Fri, 22 Nov 2024 13:45:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Nov 2024 16:00:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>