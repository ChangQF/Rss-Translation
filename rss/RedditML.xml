<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 04 Jun 2024 06:20:24 GMT</lastBuildDate>
    <item>
      <title>[D] Mamba2 SSD 收缩可视化为张量网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7q386/d_mamba2_ssd_contractions_visualized_as_a_tensor/</link>
      <description><![CDATA[      https://preview.redd.it/3lpr8yp5yh4d1.png?width=2667&amp;format=png&amp;auto=webp&amp;s=a410811c8d010f7697ecfc76138258d089113d30 我不确定这是否会对任何人有所帮助，但我发现 Mamba 2 论文中的收缩顺序相当有趣，并认为它可能将其可视化为张量网络很不错。这对应于第一阶段收缩，或 Y_diag = torch.einsum(&quot;bclhn,bcshn,bhcls,bcshp-&gt;bclhp&quot;, C, B, L, X) 请注意索引 b、c 和 h 如何出现在每个表达式中，因此它们可以抽象（并行化），收缩操作的核心实际上在于 d_head、d_state、length 和 length（mixed）。然后，收缩操作涉及通过边收缩合并图中的两个节点。 请注意，与节点相邻的边数对应于张量的维度（加上 3 个公共维度）。在作者提出的收缩路径下（参见上面的代码），可以很容易地看到，维度大于 5 的张量永远不会实现。这是可能的，因为 segsum 矩阵（由 A 矩阵诱导）没有 d_state 依赖性，或“限制为 标量乘以恒等式 结构”。 我猜这可能不是最普遍的收缩形式，并且出于实际的硬件内存考虑，可能还有其他方法可以构建更具表现力的张量网络，以保证维度大于 5 的张量不实现。   由    /u/dna961010  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7q386/d_mamba2_ssd_contractions_visualized_as_a_tensor/</guid>
      <pubDate>Tue, 04 Jun 2024 06:00:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从向量数据库中准确检索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7ph3n/d_accurate_retrieval_from_vector_db/</link>
      <description><![CDATA[好的，所以任务是针对给定的查询，您想要找到所有相关文档，这并不是什么新鲜事，每个人都想要同样的东西。现在的方法是进行混合搜索（BM25 + 语义搜索），然后对结果进行重新排序以获得排序后的文档。  接下来要找到相关文档，人们可能会选择来自重新排序模块的相关性阈值并过滤掉结果。但这里的问题是没有可以使用的 oracle 相关性分数，我发现可用的相关性分数阈值范围很大（例如：对于重新排序模块，范围是 -3 到 4），所以这种方法行不通。  对于我们想要找到所有且仅相关文档的用例，研究或个人经验中是否有任何可能在这种情况下起作用的东西。    提交人    /u/Raise_Fickle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7ph3n/d_accurate_retrieval_from_vector_db/</guid>
      <pubDate>Tue, 04 Jun 2024 05:21:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 矢量神经网络 (VNN) – 利用二维矢量神经元和几何张量增强几何深度学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7lpfu/d_vector_neural_networks_vnns_enhancing_geometric/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7lpfu/d_vector_neural_networks_vnns_enhancing_geometric/</guid>
      <pubDate>Tue, 04 Jun 2024 01:51:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在模型评估和模型可解释性领域有哪些值得关注的研究人员？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7jt6y/d_who_are_some_researchers_to_follow_in_the_field/</link>
      <description><![CDATA[这些研究人员有很好的精选列表和演讲。对于正在学习的人来说，还有其他值得关注的研究人员吗？  https://github.com/zhijing-jin/Causality4NLP_Papers?tab=readme-ov-file https://beenkim.github.io/#Pubs     提交人    /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7jt6y/d_who_are_some_researchers_to_follow_in_the_field/</guid>
      <pubDate>Tue, 04 Jun 2024 00:16:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 介绍 einspace：基于基本操作的 NAS 多功能搜索空间</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7gt44/r_introducing_einspace_a_versatile_search_space/</link>
      <description><![CDATA[亲爱的 r/machinelearning 朋友们， 我们很高兴与大家分享我们在神经架构搜索 (NAS) 搜索空间方面的最新成果。 介绍 einspace：一个灵活而全面的搜索空间，它集成了卷积网络 (convnets)、Transformers 和多层感知器 (MLP)。 我们的方法将架构分解为四个关键组件：1. MLP 2. 分支 3. 聚合 4. 路由 这些组件构成了架构设计的“RGB”基因。我们的目标是平衡粒度，避免重新设计线性层的冗余，同时保持不同模型之间的灵活性。 我们希望您探索我们的工作，并了解我们如何进行架构探索。非常感谢您的反馈和想法。 🧠🔍 阅读论文 🔗 项目页面 📣 原始推文 问候， Antreas    提交人    /u/AntreasAntoniou   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7gt44/r_introducing_einspace_a_versatile_search_space/</guid>
      <pubDate>Mon, 03 Jun 2024 21:57:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 直观理解马尔可夫毯？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7dd43/d_intuitive_understanding_of_markov_blanket/</link>
      <description><![CDATA[大家好，我正在阅读 Bishop 的《模式识别和机器学习》第 8 章，对贝叶斯网络中的马尔可夫毯有点困惑。 所以它说：  节点 x 的马尔可夫毯包括该节点的父母、孩子和共同父母的集合。  我确实遵循数学推导，但直觉我不明白为什么：  共同父母是马尔可夫毯的一部分？ 为什么共同父母的父母不是马尔可夫毯的一部分？也就是说，为什么信息会停留在共同父母，而不是直到共同父母的父母的一级？  有人可以提供直观的解释吗（最好举例说明）？谢谢！    由   提交  /u/Illustrious-Pay-7516   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7dd43/d_intuitive_understanding_of_markov_blanket/</guid>
      <pubDate>Mon, 03 Jun 2024 19:37:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 一篇关于机器学习中多项式特征的正则化性质的文章</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7d26z/p_a_post_on_regularization_properties_of/</link>
      <description><![CDATA[我写了一篇关于机器学习中多项式特征的正则化属性的文章 - 比如偏差-方差权衡，以及控制拟合曲线的形状。这是关于多项式特征的系列文章中的最后一篇。我非常享受学习我所写的一切，我希望它会很有趣和有用。 系列从这里开始：https://alexshtf.github.io/2024/01/21/Bernstein.html 最新帖子在这里：https://alexshtf.github.io/2024/06/03/PolynomialBasesRegProps.html    提交人    /u/alexsht1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7d26z/p_a_post_on_regularization_properties_of/</guid>
      <pubDate>Mon, 03 Jun 2024 19:26:05 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士 (LLM) 的幻觉基准分数 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7b72j/hallucination_benchmark_scores_for_llms_discussion/</link>
      <description><![CDATA[对于我的一个项目，我正在查看更昂贵的 LLM（训练计算）的基准分数，到目前为止，在我看来，其中很少有公开发布其在幻觉和类似基准（HaluEval、TruthfulQA 等）上的分数。 例如，我只找到了其中 3 个的 HaluEval 分数。他们没有发布这些分数，还是我看错了地方？    提交人    /u/_banerjee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7b72j/hallucination_benchmark_scores_for_llms_discussion/</guid>
      <pubDate>Mon, 03 Jun 2024 18:11:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么验证指标看起来如此荒谬[P] - 多类分割</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7b4yu/why_does_validation_metrics_look_so_absurd_p/</link>
      <description><![CDATA[      验证 IoU 和 F1 分数 训练损失和验证损失 我正在对 X 射线进行分割（仅使用 25% 的数据）并在简单的 UNET 上对其进行训练作为基线。 4 个类内。查看训练/验证损失（附图）似乎模型正在随着时间的推移而学习，但评估指标（IoU 和 F1）看起来很荒谬。我没有在我的代码中看到任何错误，但我从未见过如此波动的分数。 有人可以解释为什么会这样吗？以下是我的理解。  由于验证数据集非常小（但使用简单模型，所以不太可能） 模型学习得不好吗？我应该再看看我的管道吗 我的评估管道中有错误。  我知道如果不实际查看数据/代码就很难发表意见。还有任何建议我应该尝试其他基线或模型。有许多基于 transformer 和 unet+mlp 架构声称是市场上最好的，但它们都没有公开代码。     由    /u/ade17_in 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7b4yu/why_does_validation_metrics_look_so_absurd_p/</guid>
      <pubDate>Mon, 03 Jun 2024 18:09:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] Text2Bricks：在 1,000 个 GPU 小时内对 Open-Sora 进行微调以制作砖块动画</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7ats8/p_text2bricks_finetuning_opensora_in_1000_gpu/</link>
      <description><![CDATA[大家好，Lambda Labs 的研究团队获得了大量 NVIDIA H100 GPU 的使用权，并用它来训练 OpenSora 制作砖块动画。团队和我随时准备回答您可能遇到的任何问题。您可以在此处阅读我们 W&amp;B 文章的所有详细信息： https://wandb.ai/lambdalabs/lego/reports/Text2Bricks-Fine-tuning-Open-Sora-in-1-000-GPU-Hours--Vmlldzo4MDE3MTky 所有模型均可用（文章中有链接），您甚至可以玩我们使用该模型制作的有趣游戏！ https://albrick-hitchblock.s3.amazonaws.com/index.html    由    /u/jedberg 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7ats8/p_text2bricks_finetuning_opensora_in_1000_gpu/</guid>
      <pubDate>Mon, 03 Jun 2024 17:57:06 GMT</pubDate>
    </item>
    <item>
      <title>[D]LLM面试问答</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7af78/dllm_interview_qa/</link>
      <description><![CDATA[大家好！我是亚马逊中国的数据科学家。在过去的一年里，我面试了多家公司的法学硕士职位。我计划整理一系列面试问题，结合我自己的面试经验，提供我认为正确的答案。本文将重点介绍微调，我会持续更新。    提交人    /u/mlzoo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7af78/dllm_interview_qa/</guid>
      <pubDate>Mon, 03 Jun 2024 17:40:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformers 是 SSM：通过结构化状态空间对偶实现广义模型和高效算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7a6l6/r_transformers_are_ssms_generalized_models_and/</link>
      <description><![CDATA[  由    /u/floppy_llama  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7a6l6/r_transformers_are_ssms_generalized_models_and/</guid>
      <pubDate>Mon, 03 Jun 2024 17:30:21 GMT</pubDate>
    </item>
    <item>
      <title>AI/ML 中对 C++ 的需求。[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d78g7s/c_demand_in_aiml_discussion/</link>
      <description><![CDATA[最近，我一直在想一个学习 cpp 的副项目，这样我就可以实现 ml 算法，希望我可以从头开始创建一些有用的东西。  然而，当我想到 AI/ML 行业中的 C++ 时，我真的很沮丧。 这是能带来价值或期望的东西吗？  注意：我从去年开始就一直用纯 C 开发程序，所以学习 cpp 不是什么大不了的事。    提交人    /u/Barrnie   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d78g7s/c_demand_in_aiml_discussion/</guid>
      <pubDate>Mon, 03 Jun 2024 16:19:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 博弈论/匹配理论/多智能体系统的最佳人工智能会议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6zoz1/d_best_ai_conferences_for_game_theorymatching/</link>
      <description><![CDATA[嗨， 我相信我有一篇非常出色的论文想要提交给人工智能领域的一个著名会议。我的领域主要是匹配理论/计算博弈论/多智能体系统（例如，如果有人熟悉的话，稳定匹配）。你认为最负盛名的相关会议是什么？我在考虑 IJCAI、AAMAS 或 EC。AAAI 和 ICML 也可能在考虑范围内，但据我所知，我所在领域的论文很少在那里发表，所以这可能与他们的主题相差太远了。谢谢您的帮助 :)    提交人    /u/Cloud7889   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6zoz1/d_best_ai_conferences_for_game_theorymatching/</guid>
      <pubDate>Mon, 03 Jun 2024 08:39:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>