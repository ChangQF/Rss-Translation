<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 25 May 2024 03:17:45 GMT</lastBuildDate>
    <item>
      <title>[D] 在文档检索和计算 nDCG 等方面，什么是基本事实？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d00amb/d_in_the_context_of_document_retrieval_and/</link>
      <description><![CDATA[在文档检索的背景下，什么是基本事实？ 在我的基准数据集的背景下在用于文档检索时，样本通常由查询及其相应的正面和负面段落组成。正向段落的标签为 1，负向段落的标签为 0。 我当前的设置遵循以下过程：  创建所有段落的 FAISS 索引段落（正+负）。 循环每个查询并从上述语料库中检索前 $k$ 个文档。 获取每个检索到的文档的标签（0 或 1） ）。 计算 nDCG。  我感到困惑的是基本事实应该是什么。上面检索到的二进制标签数组将是预测。 我正在使用 scikit-learn 的 nDCG 评分函数，但我不知道 y_true 的输入应该是什么.   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d00amb/d_in_the_context_of_document_retrieval_and/</guid>
      <pubDate>Sat, 25 May 2024 01:01:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 k=1 的 knn 分类器创建研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czztjx/r_creating_research_paper_using_knn_classifier/</link>
      <description><![CDATA[我正在准备关于使用人工智能和录音来早期检测帕金森病的研究论文。 我现在完成了代码，我创建了一个机器模型来检测帕金森病。我使用了具有 756 个特征的数据集。 步骤如下：  第 1 步：knn  (n_neighbors=5, p=2)：准确度 84.11 f1 89.66 第 2 步：knn (n_neighbors=1, p=1)：准确度 95.39 f1 96.96 第 3 步：knn (n_neighbors=1, p=1) + 交叉验证 5 倍：平均精度 96.19 +/- 1.14 平均 f1 97.45 +/- 0.76。 第 4 步：装袋 + knn (n_neighbors=1, p= 1) 准确度 94.74 第 5 步：装袋(max_features=0.37, n_estimators=20) + knn(n_neighbors=1, p=1)：准确度 96.71 f1 97.84 第 6 步：装袋(max_features=0.37, n_estimators= 20) + knn(n_neighbors=1, p=1) + 交叉验证 5 倍：平均准确度 97.22 +/ - 0.78 均值 f1 98.15 +/- 0.52  分数高于之前发表的使用我使用的相同数据集的研究论文。 问题是我做了网上的一项研究，发现 n_neighbors=1 的 knn 不可靠。 我对以前发表的研究论文进行了广泛的研究，发现了一篇使用 knn with k=1 的研究论文研究论文正在接受同行评审。 使用 k=1 是否安全，因为它已经在之前的同行评审和发表的研究中使用过？    ;由   提交/u/Either_Doubt_5850   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czztjx/r_creating_research_paper_using_knn_classifier/</guid>
      <pubDate>Sat, 25 May 2024 00:36:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] Google AI 概述是否应该发布？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czzt45/d_should_google_ai_overview_haven_been_released/</link>
      <description><![CDATA[Google 发布了另一个糟糕的 AI 功能（请参阅《纽约时报》第 5/24 篇文章中的反应）。当你读到一些概述有多糟糕时，你会怀疑谷歌产品团队是否真正考虑过人们将如何使用他们的产品。几乎似乎没有完成对抗性测试。 如果人工智能概述真的是为了使用人工智能来总结搜索结果，那么当相当大比例的网站充满了包括阴谋论和讽刺在内的不可靠信息时，它应该如何工作。  有人在搜索时真正需要洋葱文章的摘要吗？“快速行动并打破常规，即使你正在打破的产品每年能带来 400 亿美元的收入” &lt; /div&gt;  由   提交 /u/yintrepid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czzt45/d_should_google_ai_overview_haven_been_released/</guid>
      <pubDate>Sat, 25 May 2024 00:35:32 GMT</pubDate>
    </item>
    <item>
      <title>将课程作业项目论文发表到期刊 [R] [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czxdg7/publishing_coursework_project_paper_to_a_journal/</link>
      <description><![CDATA[嘿， 我想我应该将其发布在此子中，因为它更加活跃，但它确实对任何人。  就背景而言，我刚刚在美国一所学校完成了本科三年级的学业，我的研究方向是机器学习。上个学期，我很幸运地参加了深度学习课程，我和其他四位小组成员一起为我们的期末项目写了一篇论文，进展顺利。我们对整个学期研究的总体结果以及我们为撰写论文所付出的努力感到满意，并且我们想知道是否有可能将我们的论文发表给某种学术机构 对于更多上下文，我们的项目是关于音频风格转换（特别是对用于解决给定输入的内容语音音频风格化问题的不同方法和架构的评估）风格和内容音频）。显然这是一个非常普遍的问题，因为我还没有向任何人分享预印本，但是一篇由四名本科生和一名研究生撰写的论文（写得好，利用了好的论文）的可能性有多大？研究方法等）被相关学术期刊接受？  如果有人在此过程中有任何建议可以帮助我们，我们将不胜感激！除了对期刊的潜在推荐之外，这些期刊可能会尽可能增加我们发表的机会。我们研究了 IEEE/ACM TASLP 期刊作为一种潜在的选择。  感谢您的阅读！请直言不讳👍   由   提交 /u/5FingerDrainPunch   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czxdg7/publishing_coursework_project_paper_to_a_journal/</guid>
      <pubDate>Fri, 24 May 2024 22:38:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将思维导图转换为文本以嵌入矢量数据库。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czrhy1/d_convert_mindmaps_into_text_to_embed_into_vector/</link>
      <description><![CDATA[嗨，我有一些关于我的领域的详细思维导图，我想知道是否有办法转换这些导图并将它们放入向量中知识数据库。我一直在做的一种方法是截取这些部分的屏幕截图并放入 GPT4V 中以转换为文本以嵌入 Vdb 中。还有其他解决办法吗？   由   提交 /u/Own-Cherry6760    reddit.com/r/MachineLearning/comments/1czrhy1/d_convert_mindmaps_into_text_to_embed_into_vector/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czrhy1/d_convert_mindmaps_into_text_to_embed_into_vector/</guid>
      <pubDate>Fri, 24 May 2024 18:20:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用表情符号重新创建图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czm3bw/p_recreate_images_with_emojis/</link>
      <description><![CDATA[演示： https://replicate.com/johnsutor/emoji-painter  我创建了一个 DNN，可以通过将表情符号连续粘贴到“画布”上来重新创建目标图像。该代码主要受到 Paint Transformer 的启发，该程序将笔触连续粘贴到画布上以重新创建照片。在那篇论文/代码库中，他们使用单一画笔类型，而我认为表情符号是要从中采样的不同画笔。使用 Gumbel softmax 从 N 个不同的表情符号中选择一个粘贴到画布上，并选择相应的比例、旋转和中心 x 和 y 坐标。  我还计划在其他形状上训练模型（我愿意接受任何考虑和反馈！）    提交人    /u/JSutie   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czm3bw/p_recreate_images_with_emojis/</guid>
      <pubDate>Fri, 24 May 2024 14:29:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 最先进的、开源的、不太耗费资源的计算机视觉模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czlgss/p_stateoftheart_open_source_computer_vision/</link>
      <description><![CDATA[有哪些先进的 CV 模型（对象检测、分割等）可以安装在相对中端的 GPU（例如 A4000 或类似的 GPU）上。我对硬件推理特别感兴趣，训练不太重要。 比 ResNet 或 YOLO 更有趣、更高效的东西，不一定是 CNN！ 提前致谢，请告诉我你的想法   由   提交/u/GWP-NU  /u/GWP-NU  reddit.com/r/MachineLearning/comments/1czlgss/p_stateoftheart_open_source_computer_vision/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czlgss/p_stateoftheart_open_source_computer_vision/</guid>
      <pubDate>Fri, 24 May 2024 14:01:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 陷入选择适当数量的簇的困境。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czjlyt/d_stuck_in_selecting_appropriate_number_of/</link>
      <description><![CDATA[      我正在处理一个有 19 列和 36000 行的数据集...我是要求对其进行聚类。所以我正在尝试 KMeans。当对这个问题执行肘法时，我得到下图。簇的数量从 1 到 249。任何人都可以建议我应该选择 k 的值吗？对于这样的数据集，我还可以尝试其他算法吗？ https://preview.redd.it/ftefa83x3e2d1.png?width=1355&amp;format=png&amp;auto=webp&amp;s=2cee33788041b0bb7e3eb142654241e0 44da8188 https://preview.redd.it/4xa7ttbz3e2d1.png?width= 1389&amp;format=png&amp;auto=webp&amp;s=80b3bf546dc00ddd3f2ba11a00639da2cb813d85   由   提交 /u/SmallSoup7223   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czjlyt/d_stuck_in_selecting_appropriate_number_of/</guid>
      <pubDate>Fri, 24 May 2024 12:31:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检测相同形状但不同颜色的物体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czdmty/d_detecting_objects_of_same_shape_but_different/</link>
      <description><![CDATA[     &lt; /td&gt; 我正在努力检测具有相同形状但不同颜色且没有其他区别特征的对象。当存在可区分的模式时，YOLO 等基于 CNN 的架构会产生奇迹并实现高精度。但是，我需要一种可以纯粹根据颜色准确分类对象的方法。 我当前的挑战是，当我尝试在 RGB 空间中按颜色对这些对象进行分割时，这些对象是不可分离的。有谁有可以在按颜色确定对象类别方面实现良好准确度的建议或方法吗？ 我在下面提供了一张图片以供参考。任何帮助将不胜感激！  https://preview.redd.it/83c6e7dbbb2d1.png?width=793&amp;format=png&amp;auto=webp&amp;s=532c7cffcbaea96eb48d374e073bd49d5f029212 编辑 转换颜色空间到 HSV 解决了这个问题。以下是 HSV 色彩空间表示 https ://preview.redd.it/hq5yrf5wcf2d1.png?width=793&amp;format=png&amp;auto=webp&amp;s=c40002fd360c1891baaed915f536aa7dae4061f5 第一阶段，我使用YOLO模型进行检测对象 在第二阶段，我裁剪检测到的对象，将裁剪后的图像转换为 HSV，计算每个对象的平均分量值，然后训练 XGBoost 模型基于 3D 向量预测颜色标签，代表H、S、V 通道的平均值。   由   提交/u/ThickDoctor007  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czdmty/d_detecting_objects_of_same_shape_but_different/</guid>
      <pubDate>Fri, 24 May 2024 05:44:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] DeepFusion：高度模块化的深度学习框架。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czcz42/p_deepfusion_a_highly_modular_deep_learning/</link>
      <description><![CDATA[大家好，我是斯坦福大学的一名学生，由于身体状况原因，我正在休学一年，为了利用我的时间来学习深度学习. 瞧... 我开发了一个深度学习库， DeepFusion！ 它是可定制的，并且具有易于访问且高度直观的代码库。人们可以直接深入并毫不费力地理解源代码。 您可以从以下位置下载它： - github at https:/ /github.com/aharvaaalok/deepfusion - 或使用 pip install deepfusion 安装（简单！） 有关解释用法和功能的一系列示例，请参阅 演示 或 教程&lt; /a&gt;. 欢迎提出任何建议，非常感谢您的贡献！   由   提交/u/aharvaaalok16   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czcz42/p_deepfusion_a_highly_modular_deep_learning/</guid>
      <pubDate>Fri, 24 May 2024 05:01:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] 学习二值化 CLIP (&SigLIP) 以进行多模态检索和排序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz5zx1/p_learn_to_binarize_clip_siglip_for_multimodal/</link>
      <description><![CDATA[学习使用 CLIP 进行二值化和排名，以将文本或多模式搜索和推荐的存储空间减少 32 倍。 文章：https://www.marqo.ai/blog/learn-to- binarize-clip-for-multimodal-retrieval-and-ranking  CLIP 排名调整期间的二进制嵌入保留了 87-93% 的 fp32 嵌入。 使用 4 倍缩放温度的 sigmoid 进行伪量化（几乎）普遍优于 tanh（参见下一点）。 0/1 (sigmoid) 上的余弦相似度优于 -1, 1 (tanh) - 很确定这是因为余弦具有更好的简并性（D vs DxN），因为它会惩罚不在同一超球体上的嵌入（它也会偏向于较少的非零元素）。 使用 L1 来训练期间的近似汉明距离，略优于余弦（对于 0/1）。 使用 GS-10M 进行评估 使用精确 KNN 进行多模态检索。 在添加辅助二进制损失时，Fp32 嵌入保留完全保真度。 跨域内、新查询、新文档和零进行评估-镜头设置。 可以与俄罗斯套娃，如果确实有必要，但保真度确实会受到影响（未显示）。    由   提交/u/Jesse_marqo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz5zx1/p_learn_to_binarize_clip_siglip_for_multimodal/</guid>
      <pubDate>Thu, 23 May 2024 22:46:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] SSAMBA 简介：自我监督的音频曼巴！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz1yoa/r_introducing_ssamba_the_selfsupervised_audio/</link>
      <description><![CDATA[嘿 Reddit， 厌倦了变形金刚？你真的需要关注吗？认识 SSAMBA（自我监督音频曼巴）！ 🐍✨  这个无需注意、纯粹基于状态空间模型 (SSM) 的自我监督奇迹不只是嘶嘶声，而是咆哮声！在说话人识别、关键字识别和音频分类等任务上，SSAMBA 比基于 Transformer 的同类产品 (SSAST) 实现了更好或相似的性能。但更重要的是：它的 GPU 内存效率更高，推理速度更快，尤其是在音频长度较长的情况下。好奇吗？请在此处查看完整论文：arXiv 上的 SSAMBA  感谢您的收听！    由   提交 /u/attentionisallyounee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz1yoa/r_introducing_ssamba_the_selfsupervised_audio/</guid>
      <pubDate>Thu, 23 May 2024 19:53:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Paperswithcode相关？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cz1t4x/d_paperswithcode_relevant/</link>
      <description><![CDATA[对我来说，paperswithcode 与跟踪 ML 进展的相关性降低了。 但这很难说，在我的领域（表格 ML/DL）没有太多既定的学术基准（还不需要像带有代码的论文之类的东西） 在 NLP 和基础模型空间中，hf 空间中的排行榜已成为一种现象（主要是在 NLP 中） ）。 总体而言，paperswithcode 感觉维护较少且不太有用。 您经常使用paperswithcode 吗？你用它来做什么？它在您的什么领域有用？   由   提交/u/_puhsu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cz1t4x/d_paperswithcode_relevant/</guid>
      <pubDate>Thu, 23 May 2024 19:46:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] Phi-3 模型并排比较。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cytxb5/d_phi3_models_compared_sidebyside/</link>
      <description><![CDATA[      https://preview.redd.it/8l04pnfhq62d1.png?width=661&amp;format=png&amp;auto=webp&amp;s=7fe616ca8cd7da97407 0c86b6b47ffab3ab545e5   https://preview.redd.it/hr7fr1uiq62d1.png?width=688&amp;format=png&amp;auto=webp&amp;s=bd3de359bfe4c1ed82d092be92ae38c246bdfda2    https://preview.redd.it/v6k3v39kq62d1.png？ width=450&amp;format=png&amp;auto=webp&amp;s=c0abb0e397a498ef7ccfb35b1b1cb598198f66ad 对于任何想要在一个地方比较 Phi-3 基准的人。 有趣的比较：ANLI、Hellaswag、MedQA、TriviaQA、语言理解、事实知识和稳健性。 注意：Phi-3 迷你模型表的标签顺序不同。   由   提交/u/dark_surfer  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cytxb5/d_phi3_models_compared_sidebyside/</guid>
      <pubDate>Thu, 23 May 2024 14:19:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>