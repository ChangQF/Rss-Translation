<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Wed, 15 May 2024 21:14:44 GMT</lastBuildDate>
    <item>
      <title>每个 TTS 工具都需要参考语音和模型才能运行吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1csv8b6/does_every_tts_tool_need_reference_voice_along/</link>
      <description><![CDATA[每个 TTS 工具都需要参考语音和模型才能运行吗？ 每个文本转语音工具都需要参考语音和模型吗？工作模型即使您有该声音的模型，您仍然需要它的参考声音，还是仅仅模型就足够了？    由   提交 /u/trafalgarDxlaw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1csv8b6/does_every_tts_tool_need_reference_voice_along/</guid>
      <pubDate>Wed, 15 May 2024 20:41:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] ACL 2024 决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1csqur3/d_acl_2024_decisions/</link>
      <description><![CDATA[提交给 ACL 2024 的论文决定将于今天（2024 年 5 月 15 日）公布！准备好去曼谷了吗？ 🇹🇭🐘   由   提交 /u/OraclePred   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1csqur3/d_acl_2024_decisions/</guid>
      <pubDate>Wed, 15 May 2024 17:43:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 新的 KANs 论文刚刚发布：用于时间序列分析的 Kolmogorov-Arnold Networks (KANs)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1csp40j/p_new_kans_paper_just_dropped_kolmogorovarnold/</link>
      <description><![CDATA[https://arxiv.org/pdf/2405.08790   由   提交/u/ghoof   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1csp40j/p_new_kans_paper_just_dropped_kolmogorovarnold/</guid>
      <pubDate>Wed, 15 May 2024 16:31:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 音频标记器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1csmgyd/d_audio_tokenizers/</link>
      <description><![CDATA[最近的 GPT-4O 模型让我思考他们是否真的对音频进行了标记并在文本 + 音频标记上训练了 GPT。是否有任何成功的音频分词器似乎可以很好地与自回归模型配合使用？人们已经使用 VQ-VAE[1] 来学习音频样本的离散表示，但此类 VQ-VAE 的编码器和解码器使用应用于 Mel-Spectrogram 的 covnet，我认为实际上无法启用音频流（因为它应用了 1d 和 2d covnet）整个音频信号，并且这样做也使表示变得非随意） [1] - https://arxiv. org/pdf/1711.00937 编辑： 我的一个更普遍的问题是，这种标记音频的方法是否可行（它会起作用吗？）或者它是更好地从音频中增量采样并将每个样本投影到嵌入，然后在这些嵌入上预训练 GPT，而不是从令牌中学习的嵌入？    ;由   提交 /u/ApartmentEither4838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1csmgyd/d_audio_tokenizers/</guid>
      <pubDate>Wed, 15 May 2024 14:40:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 llms 进行分类任务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cslzii/r_classification_tasks_with_llms/</link>
      <description><![CDATA[嘿！作为我论文的一部分，我看到使用 AutoModelForSequenceClassification 处理大型文本（使用 llm（mistral）而不是 bert）取得了良好的结果，但我有一些问题正在试图弄清楚：  有一点吗在使用 AutoModelForSequenceClassification 时，对于任务定义和目标有一个连贯的、易于理解的提示？ 当我要求他：“写出”时，我发现使用 cot（思想链）提示的模型得到了改进你一步步推理，以确保你得到正确的答案！”，有什么解释为什么它有帮助吗？我们使用分类头而不是解码器，因此它不是自动回归的。    由   提交/u/WishboneReal534  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cslzii/r_classification_tasks_with_llms/</guid>
      <pubDate>Wed, 15 May 2024 14:20:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 多元交通流预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cskok4/p_multivariate_traffic_flow_predictions/</link>
      <description><![CDATA[嗨，我刚刚开始一个新项目，我有这个交通数据集，时间间隔为 5 分钟，流量和速度，现在我尝试使用预测模型就像 Lstm 和 gru 成功地处理了流量或速度，但是当我尝试在速度和流量上使用该模型时，它不起作用。我可以在哪里学习这些东西吗？   由   提交 /u/False_Wallaby389   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cskok4/p_multivariate_traffic_flow_predictions/</guid>
      <pubDate>Wed, 15 May 2024 13:22:08 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]神经网络的SOTA不确定性量化方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1csh3tv/discussion_what_are_sota_uncertainty/</link>
      <description><![CDATA[我最近开始研究这个主题，我很好奇哪些方法是 SOTA 并在生产中使用？更具体地说，我对神经网络的任意和认知不确定性建模感兴趣。在理想的设置中，我的模型会告诉我何时遇到分布外的输入，并表示给定输入相对于系统噪声的不确定性。 编辑：我主要处理回归问题. 提前致谢！ :)   由   提交/u/jens_97  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1csh3tv/discussion_what_are_sota_uncertainty/</guid>
      <pubDate>Wed, 15 May 2024 10:02:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM4ED：用于自动方程发现的大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1csgx30/r_llm4ed_large_language_models_for_automatic/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2405.07761 摘要：  方程发现旨在直接从数据中提取物理定律，具有成为一个关键的研究领域。先前基于符号数学的方法已经取得了实质性进展，但通常需要设计复杂算法的实现。在本文中，我们介绍了一种新框架，该框架利用基于自然语言的提示来指导大型语言模型（LLM）自动从数据中挖掘控制方程。具体来说，我们首先利用LLM的生成能力来生成字符串形式的各种方程，然后根据观察来评估生成的方程。在优化阶段，我们提出了两种交替迭代策略来协同优化生成的方程。第一个策略是将LLM作为黑盒优化器，根据历史样本及其表现实现方程自我改进。第二个策略是指导法学硕士执行全局搜索的进化算子。对偏微分方程和常微分方程进行了广泛的实验。结果表明，我们的框架可以发现有效的方程来揭示各种非线性动态系统下的基本物理定律。与最先进的模型进行了进一步比较，证明了良好的稳定性和可用性。我们的框架大大降低了学习和应用方程发现技术的障碍，展示了法学硕士在知识发现领域的应用潜力。     ;由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1csgx30/r_llm4ed_large_language_models_for_automatic/</guid>
      <pubDate>Wed, 15 May 2024 09:49:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 柏拉图表示假说</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1csgr7r/r_the_platonic_representation_hypothesis/</link>
      <description><![CDATA[arxiv: https://arxiv.org/pdf/2405.07987 项目页面：https://phillipi.github.io/prh/ github：https://github.com/minyoungg/platonic-rep/ 有趣的位置关于自监督、多模式表示学习的收敛的论文。    由   提交/u/dan994  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1csgr7r/r_the_platonic_representation_hypothesis/</guid>
      <pubDate>Wed, 15 May 2024 09:37:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 业界人士，你们如何使用开源法学硕士？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1csdsje/d_those_in_the_industry_how_are_you_using_open/</link>
      <description><![CDATA[想要了解人们如何在生产中使用开源 LLM。我希望看到答案的一些问题是：   很想了解您如何使用较小的模型，如何部署它们，以及这里的其他人可能没有想到 您是否看到使用微调开源带来的性能/成本提升？ 训练和建立自己的微调管道有多困难？您是否使用完整的培训或像 LoRA 这样的 PEFT 方法？ 任何其他可能与使用您自己的 LLM 相关的内容  我是一名工程师，试图弄清楚提高技能的最佳方式，看看我的公司是否可以利用开源模型做更多事情，这对此非常有帮助。谢谢！   由   提交 /u/C0hentheBarbarian   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1csdsje/d_those_in_the_industry_how_are_you_using_open/</guid>
      <pubDate>Wed, 15 May 2024 05:59:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] CLIP（和 SigLip）的俄罗斯套娃表示学习（MRL）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cs8fzb/r_matryoshka_representation_learning_mrl_for_clip/</link>
      <description><![CDATA[CLIP 的 MRL [1] 允许使用更小维度的嵌入，而不会损失保真度。训练经过修改，以优化视觉和文本编码器的截断嵌入（一次多个目标维度）。  主要发现：  将嵌入大小减少 4 倍可保持约 95 的性能 子嵌入的投影层对性能没有帮助 在多模态检索中在域内外进行工作（零样本） 使用过多的子嵌入会降低性能（即 {512, 256, 128} 与 {512, 256, 128 , 64, 32, 16, 8} 子嵌入的数量影响收敛（同上） 与 GCL 等排名调整方法一起使用 子维度的相对重要性（权重，wi）很重要（例如 w1*L_512 + w2*L_256 + w3*L_128） 如果使用原始大小的嵌入，即性能，则 MRL 训练的模型可以提高。即使不使用较小的嵌入，也会得到改进。  文章： https://www.marqo.ai/blog/matryoshka-representation-learning-with-clip-for-multimodal-retrieval-and-ranking  [1] MRL https://arxiv.org/abs/2205.13147   由   提交/u/Jesse_marqo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cs8fzb/r_matryoshka_representation_learning_mrl_for_clip/</guid>
      <pubDate>Wed, 15 May 2024 01:02:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kolmogorov Arnold Networks：视觉论文分解（视频）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1crzj4o/d_kolmogorov_arnold_networks_a_visual_paper/</link>
      <description><![CDATA[分享我的 YT 频道中的视频，该视频详细介绍了新的 KAN 论文。它涵盖了理解本文所需的所有核心概念 - 柯尔莫哥洛夫阿诺德表示定理、样条曲线、MLP、MLP 和 KAN 之间的比较、未来的挑战，并强调了 KAN 的一些令人惊叹的属性/结果，如持续学习、稀疏化、符号化回归等。 链接：https://youtu.be/7zpz_AlFW2w    由   提交 /u/AvvYaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1crzj4o/d_kolmogorov_arnold_networks_a_visual_paper/</guid>
      <pubDate>Tue, 14 May 2024 18:36:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT-4o“原生”多模式，这实际上意味着什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1crzdhd/d_gpt4o_natively_multimodal_what_does_this/</link>
      <description><![CDATA[与预训练视觉编码器 + 预训练 LLM 的典型 VL 公式相比，您对其工作方式（训练和架构）的最佳猜测是什么 -&gt;与多模式任务进行微调？ 例如是否对整个系统进行完全混合模态预训练？模型是否将所有模态嵌入到共享空间中进行预测？系统是否“自行选择”？输出token的形式（可以根据输入token灵活选择输出音频还是文本）还是这个用户指定的？   由   提交/u/Flowwwww  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1crzdhd/d_gpt4o_natively_multimodal_what_does_this/</guid>
      <pubDate>Tue, 14 May 2024 18:29:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] BERT 在 2024 年对于 EMNLP 提交仍然有意义吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1crxhfp/d_is_bert_still_relevant_in_2024_for_an_emnlp/</link>
      <description><![CDATA[使用 BERT 进行主动学习（对于某些应用）仍然是提交论文的相关范式吗？或者类似的工作可能会因为“过时”而被拒绝？ 我的想法与使用 BERT 进行医学分类有关，我确信法学硕士可能会表现得更好。想知道是否值得投入时间大力推动以获得结果。   由   提交 /u/PK_thundr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1crxhfp/d_is_bert_still_relevant_in_2024_for_an_emnlp/</guid>
      <pubDate>Tue, 14 May 2024 17:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>