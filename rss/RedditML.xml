<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 01 Jun 2024 18:17:48 GMT</lastBuildDate>
    <item>
      <title>[D] MLE 还是 AI 工程师？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5stf6/d_mle_or_ai_engineer/</link>
      <description><![CDATA[主要是标题。 我在后端和数据工程方面有大约 5 年的经验。我目前正在学习基础数学和 ML 算法。但我对这一波 Gen AI 和 LLM 感到困惑。我在网上搜索了一下，发现职业道路之间存在一些差距，因为 AI 工程师更注重深度学习，也对 transformers 感兴趣。 那么根据你对该领域未来 5 年发展方向的了解和预测，你建议我应该瞄准哪一个？ 非常感谢这个 subreddit 提供的有用建议。    提交人    /u/RobotsMakingDubstep   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5stf6/d_mle_or_ai_engineer/</guid>
      <pubDate>Sat, 01 Jun 2024 18:00:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 超快 RAG：Langchain Streaming 和 Groq</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5s9g4/p_superfast_rag_langchain_streaming_and_groq/</link>
      <description><![CDATA[使用 Groq 和 Langchain Streaming 进行快速 LLM RAG 推理。  Groq 推出了一种新的、更简单的处理架构，专为满足机器学习应用程序和其他计算密集型工作负载的性能要求而设计。更简单的硬件还可以通过消除分析需求来节省开发人员资源，并且还可以更轻松地大规模部署 AI 解决方案。  资源：https://www.youtube.com/watch?v=frMdOL8knqg    提交人    /u/trj_flash75   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5s9g4/p_superfast_rag_langchain_streaming_and_groq/</guid>
      <pubDate>Sat, 01 Jun 2024 17:35:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] GPT-Burn：纯 Rust 中 GPT 的简单而简洁的实现🔥</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5qg3h/p_gptburn_a_simple_concise_implementation_of_the/</link>
      <description><![CDATA[        由    /u/ProfessionalDrummer7 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5qg3h/p_gptburn_a_simple_concise_implementation_of_the/</guid>
      <pubDate>Sat, 01 Jun 2024 16:10:50 GMT</pubDate>
    </item>
    <item>
      <title>15 个必须知道的概念解释了文本到图像的生成扩散模型！（+ 如何编码）[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5o84z/texttoimage_generative_diffusion_models_explained/</link>
      <description><![CDATA[      分享我最近制作的一段视频，讨论条件 LDM 以及我在 celeba 数据集上实现文本到图像 LDM 以生成人脸时学到的经验教训。    提交人    /u/AvvYaa   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5o84z/texttoimage_generative_diffusion_models_explained/</guid>
      <pubDate>Sat, 01 Jun 2024 14:29:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 PyTorch Geometric 进行 GNN 采样的视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5nmlh/p_a_visual_guide_to_gnn_sampling_using_pytorch/</link>
      <description><![CDATA[      大家好， 我发布了一些关于“图神经网络采样”主题的视频和笔记本（GNNs）”。原始 GCN 论文采用全批量训练。然后，研究人员使用不同的方法创建小批量（子图）来训练 GCN。例如，GraphSAGE 论文使用了邻居采样器，而 ClusterGCN 论文使用了集群采样器。这些采样器在 pytorch-geometric 中的 torch_geometric.loader 下实现。 这是视频，或者你可以直接跳到代码中..  图形神经网络的采样 视频 代码  图形神经网络中的迷你批次视频 视频 代码 原始图表 三使用来自 pytorch_geometric 的 NeighborLoader 对子图进行采样；白色节点未被采样。    提交人    /u/mashaan14   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5nmlh/p_a_visual_guide_to_gnn_sampling_using_pytorch/</guid>
      <pubDate>Sat, 01 Jun 2024 14:00:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 深层生物群落实验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5laih/p_the_deep_biome_experiment/</link>
      <description><![CDATA[您好， 我正在研究深层生物群落的概念，并试图在本文档中描述它：https://docs.google.com/document/d/e/2PACX-1vR1bvKTV94WRUyz-xfqPkV0TQjrHgE-4reCdP2Ncjgxv4CN8CVhEmcYb_b7qC2lv_HK9vjZd9yv57-Z/pub 摘要是：创建一个虚拟生物群落，其中每个代理都有一个“DNA”代表其神经网络的结构，并具有与其他代理一起繁殖的能力。 我已经在 GitHub 上创建了一个 DeepDNA 的示例，其中创建了两个 DNA，然后合并以生成孩子的 DNA。 我正在寻找合作者来有效地开发理论（和实施），这可以帮助我解决一些概念瓶颈，例如代理模型的训练或像 LSTM 这样的复杂层的情况下序列的结构。 我很欣赏与大学的合作以及将论文作为研究发表的雄心。 python 测试在这个 repo 中：https://github.com/cekkr/DeepGenome  此刻，我正在等待“刺激”继续前进。 谢谢， Riccardo Cecchini    提交人    /u/itsmeriky   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5laih/p_the_deep_biome_experiment/</guid>
      <pubDate>Sat, 01 Jun 2024 11:53:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助提高 BERT 与神经网络的匹配度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5l0he/d_help_to_increase_the_acc_of_bert_with_neural/</link>
      <description><![CDATA[      你好，我是 ML 新手，我正在努力提高我的 BERT-CNN、BERT-LSTM、BERT-GRU 的准确率。 这是我的存储库情绪分析 BERT-CNN 我使用的数据集是Kaggle，该数据集不平衡，因此我需要将一些中性情绪分数取出至 0.78 以获得 4k 的中性情绪 我现在的准确率是 -&gt; BERT-CNN 训练总结： 最佳训练损失：0.0129（第 10 次训练） 最佳验证准确率：81.55%（第 7 次训练） -&gt; BERT-LSTM 训练总结： 最佳训练损失：0.0815（第 10 次训练） 最佳验证准确率：81.14%（第 7 次训练） -&gt; BERT-GRU 训练总结： 最佳训练损失：0.0815（第 10 次迭代） 最佳验证准确率：81.14%（第 7 次迭代） 图表 我根据这篇论文进行研究，作为准确率的参考，但是 我的代码有问题吗？ 我不知道我已经更改了不同的超参数，但对准确率来说仍然不重要。以及为什么我的模型不好，比如 acc 的改进不是增量的，但有时是下降的？ 提前谢谢您，我希望您对讨论感兴趣:)    提交人    /u/Jveko   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5l0he/d_help_to_increase_the_acc_of_bert_with_neural/</guid>
      <pubDate>Sat, 01 Jun 2024 11:35:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mojo 值得吗，或者你愿意为 ML 学习哪种第二语言？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5kov5/d_is_mojo_worth_it_or_which_second_language_would/</link>
      <description><![CDATA[基本上就是标题。我非常精通 Python（正如预期的那样），但除此之外，我对 JavaScript 和 C++ 的了解非常有限。我想学习一种更“低级”的第二种语言，可以更好地利用硬件功能。我的目标不是重写 Pytorch 或完全替换 Python（尽管 将推理移植到 Mojo 可能有意义），而是为性能关键用例提供替代方案。 从今天的情况来看，答案显然是 C++。然而，Rust 越来越受欢迎，除了陡峭的学习曲线外，人们开始在许多方面将其置于 C++ 之上。在这两种情况下，语法和语言都与 Python 不太接近，这使得它们很难学习。 Mojo 在这方面似乎要好得多，既提供了语法类似于 Rust 的低级功能（至少对于像我这样的门外汉来说），又可以用作奇怪的 Python 风格。它甚至允许直接导入 Python 库。这对于这种缺乏大型社区和各种库的年轻语言非常有帮助。尽管如此，该语言仍然很年轻，而且很容易发生变化，所以我不确定是否应该投资。 那么，对于上述用例，您认为最好的“第二种”语言是什么？有使用 Mojo 的经验吗？您是如何学习它或资源有限的任何其他语言的。如果我使用 Mojo，我打算通读文档并解决去年使用它的代码出现的问题。    提交人    /u/canbooo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5kov5/d_is_mojo_worth_it_or_which_second_language_would/</guid>
      <pubDate>Sat, 01 Jun 2024 11:15:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 情境学习是否足以满足法学硕士 (LLM) 课程的指导要求？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hh86/r_is_incontext_learning_sufficient_for/</link>
      <description><![CDATA[上下文学习 (ICL) 允许 LLM 从示例中学习而不改变其权重，这对于可以从许多示例中学习的长上下文 LLM 来说是一项特别有前途的功能。最近，Lin 等人 (2024) 提出了 URIAL，这是一种仅使用三个上下文示例来对齐基础 LLM 的方法，可实现非平凡的指令跟踪性能。在这项工作中，我们表明，虽然有效，但使用 URIAL 的 ICL 对齐与已建立的基准（例如 MT-Bench 和 AlpacaEval 2.0 (LC)）上的指令微调相比仍然表现不佳，尤其是对于功能更强大的基础 LM。与分类、翻译或摘要等任务不同，为长上下文 LLM 添加更多 ICL 演示并不能系统地提高指令跟踪性能。为了解决这一限制，我们推导出一种针对 ICL 示例的贪婪选择方法，该方法可显着提高性能，但不会弥合与指令微调之间的差距。最后，我们提供了一系列消融研究，以更好地了解剩余差距背后的原因，并展示了 ICL 的某些方面如何偏离现有知识并特定于指令调整设置。 总的来说，我们的工作推进了对 ICL 作为一种对齐技术的理解。    提交人    /u/m_andriushchenko   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hh86/r_is_incontext_learning_sufficient_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:21:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] DeTikZify：使用 TikZ 合成科学图形和草图的图形程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hh0s/p_detikzify_synthesizing_graphics_programs_for/</link>
      <description><![CDATA[        由    /u/DrCracket 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hh0s/p_detikzify_synthesizing_graphics_programs_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:20:46 GMT</pubDate>
    </item>
    <item>
      <title>[D]您最喜欢使用哪些研究工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hdve/dwhat_are_your_favorite_tools_that_you_use_for/</link>
      <description><![CDATA[作为一名研究人员，我发现有几种工具确实能帮助我更好地工作、更轻松地写作并跟上最新研究。这些工具对于管理我的项目、与他人合作以及确保我的工作彻底性非常有用。以下是我个人最喜欢的工具： blainy.com： Blainy 是一种 AI 写作工具，可轻松创建文章、作业和研究论文。它可以建议内容、具有自动写作选项、允许您自定义写作风格、管理引文、检查抄袭，并具有用于澄清的 PDF 聊天功能。它是改进学术工作的好工具。 connectedpapers.com：这是一个开始新研究项目的好工具。通过输入一篇相关论文，它会向您显示相关论文及其引文的图表。这样您就可以清楚地了解相关文献以及它们之间的联系。 researchrabbit.ai：与connectedpapers.com类似，但功能更多。它可以帮助您查找相关论文并跟上您所在领域的新研究。您可以创建收藏夹并获取符合您兴趣的新论文的更新。 litmaps.com：跟踪最新研究的绝佳工具。Litmaps可让您创建引文的可视化地图，并随时了解与您的工作相关的新论文。它对于了解研究随时间的发展非常有用。 overleaf.com：用于撰写研究论文或笔记的最佳网络应用程序。凭借版本控制、协作功能和基于Web的界面，Overleaf是用LaTeX编写的最佳方式，可轻松与他人合作和管理文档。 notion.so：灵活的项目管理工具，可根据研究项目进行定制。 Notion 可让您组织研究、与团队成员协作并在一个地方跟踪任务和截止日期。 zotero.org：一个强大的参考管理工具，可帮助您收集、组织、引用和共享研究。Zotero 与您的浏览器集成以直接保存研究文章，并与文字处理器配合使用以轻松管理引用。 mendeley.com：另一个强大的参考管理器和学术社交网络。Mendeley 可帮助您组织研究、与他人在线协作并发现最新研究。它还与文字处理器集成，可轻松管理引用和参考书目。 通过使用这些工具，您可以更高效地工作、保持井然有序，并确保您的学术写作是彻底的且得到良好的支持。    提交人    /u/mysticmuse72   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hdve/dwhat_are_your_favorite_tools_that_you_use_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:14:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自动 LoRA 发现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</guid>
      <pubDate>Sat, 01 Jun 2024 04:09:17 GMT</pubDate>
    </item>
    <item>
      <title>调整剧本中的探索与利用——需要帮助理解流程 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5cxyq/exploration_vs_exploitation_in_tuning_playbook/</link>
      <description><![CDATA[[已编辑] 我正在阅读“Tuning Playbook”，在理解超参数调整背景下的探索与利用概念时遇到了一些困难。 有没有人可以用更具体而不是抽象的方式解释这个概念，或者提供一个在超参数调整中如何进行探索的例子？什么是探索以及如何进行探索。还有一件事；它一直在说理解问题，哪个问题？问题模型试图解决？还是什么超参数影响性能和相互影响的问题？还是什么？  这是书中关于这个主题的部分：  探索与开发  谢谢！    提交人    /u/Same_Half3758   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5cxyq/exploration_vs_exploitation_in_tuning_playbook/</guid>
      <pubDate>Sat, 01 Jun 2024 02:40:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 其他领域的研究，例如最近对一立方毫米人类脑组织的映射，能否帮助机器学习领域？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d56zg0/d_can_other_areas_researches_such_as_the_recent/</link>
      <description><![CDATA[https://www.scientificamerican.com/article/a-cubic-millimeter-of-a-human-brain-has-been-mapped-in-spectacular-detail/ 围绕人类大脑的研究，例如这张最新的人类大脑图谱，能否为机器学习领域提供一些见解，以构建更有效的人工智能/算法模型？ 外行人在这里。    提交人    /u/Enzo-chan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d56zg0/d_can_other_areas_researches_such_as_the_recent/</guid>
      <pubDate>Fri, 31 May 2024 21:40:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>