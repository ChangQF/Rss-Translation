<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Thu, 09 May 2024 21:14:22 GMT</lastBuildDate>
    <item>
      <title>[D] ECCV-2024 评论已出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co7w0i/d_eccv2024_reviews_are_out/</link>
      <description><![CDATA[标题说明了一切。   由   提交/u/darkknight-6  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co7w0i/d_eccv2024_reviews_are_out/</guid>
      <pubDate>Thu, 09 May 2024 21:01:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 杰出论文奖。恭喜！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co4kfw/d_iclr_outstanding_paper_awards_congratulations/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co4kfw/d_iclr_outstanding_paper_awards_congratulations/</guid>
      <pubDate>Thu, 09 May 2024 18:42:14 GMT</pubDate>
    </item>
    <item>
      <title>[D]“特征”一词从何而来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co2ye4/d_where_does_the_term_feature_come_from/</link>
      <description><![CDATA[也许是一个愚蠢的琐事问题，但我无法弄清楚。 ML 将特征称为特征，统计将特征称为预测变量，数学将特征称为特征变量，工程也将特征变量称为特征。 我知道它们是什么，但为什么我们称它们为特征？有谁知道起源故事吗？   由   提交 /u/FirefoxMetzger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co2ye4/d_where_does_the_term_feature_come_from/</guid>
      <pubDate>Thu, 09 May 2024 17:35:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] QServe：W4A8KV4 量化和系统协同设计，实现高效的 LLM 服务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co2k7i/r_qserve_w4a8kv4_quantization_and_system_codesign/</link>
      <description><![CDATA[📚 研究论文：http://arxiv.org/ abs/2405.04532v1 🤔 为什么？：由于 GPU 上的运行时开销巨大，现有的 INT4 量化技术无法在大批量、基于云的语言模型服务中提供性能提升。 💻 How?：研究论文提出了一种新的量化算法 QoQ，它代表 quattuor-octo-quattuor，使用 4 位权重、8位激活和4位KV缓存。该算法在 QServe 推理库中实现，旨在通过引入渐进量化来减少 GPU 上的反量化开销。 **此外，研究论文引入了 SmoothAttention 来减轻 4 位 KV 量化造成的精度下降。 QServe 还执行计算感知权重重新排序，并利用寄存器级并行性来减少反量化延迟。最后，QServe 利用内存绑定的融合注意力来进一步提高性能。 🦾 性能增益：与现有技术相比，该研究论文实现了显着的性能改进。 QServe 将 Llama-3-8B 在 A100 上可实现的最大服务吞吐量提高了 1.2 倍，在 L40S 上提高了 1.4 倍；和 Qwen1.5-72B 在 A100 上提高 2.4 倍。   由   提交/u/dippatel21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co2k7i/r_qserve_w4a8kv4_quantization_and_system_codesign/</guid>
      <pubDate>Thu, 09 May 2024 17:18:08 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 如何查找实例分割模型动物园存储库？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnzdh9/project_how_to_find_instance_segmentation_model/</link>
      <description><![CDATA[我正在开发一个使用 TensorFlow 进行实例分割的项目。教授告诉我找到 github 存储库，这些存储库是用于实例分割的模型动物园。它应该与 TensorFlow 一起使用，并且应该有预训练的模型。问题是我找不到动物园模型，而是单个模型。 如何找到用于实例分割的模型动物园并且与 TensorFlow 兼容的 github 存储库？ 除了链接和资源之外，我们非常感谢任何进一步的意见和建议。谢谢 到目前为止我尝试过的事情：  Google 搜索“instanceegmentation github”。 在 github 搜索中搜索“instanceegmentation”吧。 询问 ChatGpt 和 Gemini 是否可以为我找到任何存储库。我可以找到诸如 PaddlePaddle、supervision 或 AdelaiDet 等框架，但它们与 Tensorflow 不兼容。它们是相当独立的框架。我还可以找到作为实例分割模型动物园的存储库，但与 PyTorch 兼容。教授告诉我使用 TensorFlow，而不是 PyTorch。  到目前为止，我已经浏览了大约 50 到 60 个存储库。   由   提交/u/Complex_Tomatillo786   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnzdh9/project_how_to_find_instance_segmentation_model/</guid>
      <pubDate>Thu, 09 May 2024 15:01:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有任何编码器模型的最大令牌大于 512（BERT、Roberta 等）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnuot2/d_any_encoder_only_model_having_bigger_max_token/</link>
      <description><![CDATA[感谢您阅读本文。 是否有像 BERT、Roberta 等这样的编码器模型，它们具有更大的最大令牌长度，比如说4k左右。我正在寻求针对多类分类用例进行微调。 提前致谢！   由   提交 /u/Raise_Fickle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnuot2/d_any_encoder_only_model_having_bigger_max_token/</guid>
      <pubDate>Thu, 09 May 2024 11:13:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlphaMath 几乎为零：无过程的过程监督</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnu9mx/r_alphamath_almost_zero_process_supervision/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2405.03553 代码：https ://github.com/MARIO-Math-Reasoning/Super_MARIO 模型：https://huggingface.co/MARIO-Math-Reasoning/AlaphaMath-7B 摘要： &lt; blockquote&gt; 大型语言模型 (LLM) 的最新进展极大地增强了他们的数学推理能力。然而，这些模型仍然难以解决需要多个推理步骤的复杂问题，经常导致逻辑或数值错误。虽然数字错误很大程度上可以通过集成代码解释器来解决，但识别中间步骤中的逻辑错误更具挑战性。此外，手动注释这些培训步骤不仅成本高昂，而且需要专业知识。在本研究中，我们引入了一种创新方法，通过利用蒙特卡罗树搜索（MCTS）框架自动生成过程监督和评估信号，从而消除了手动注释的需要。本质上，当法学硕士经过良好的预训练时，只需要数学问题及其最终答案来生成我们的训练数据，而不需要解决方案。我们继续训练一个阶梯级价值模型，旨在改进法学硕士在数学领域的推理过程。我们的实验表明，使用由 MCTS 增强的法学硕士自动生成的解决方案可以显着提高模型处理复杂数学推理任务的能力。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnu9mx/r_alphamath_almost_zero_process_supervision/</guid>
      <pubDate>Thu, 09 May 2024 10:48:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] ECCV 2024回顾讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cntiks/d_eccv_2024_review_discussion/</link>
      <description><![CDATA[我认为，与其他会议一样，我们可能会为提交给 ECCV 的人们进行讨论，因为评论将在 10 小时内发布（晚上 10 点（欧洲中部夏令时间）。这是我第一次在任何地方提交，说实话我很紧张。   由   提交/u/mr_birrd  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cntiks/d_eccv_2024_review_discussion/</guid>
      <pubDate>Thu, 09 May 2024 10:00:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于三年级博士生来说，开始提交 TPAMI 是一个好主意吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnrv30/d_is_it_a_good_idea_for_a_3rd_year_phd_student_to/</link>
      <description><![CDATA[我的简历中最近接受了一篇论文（由 ICML），根据我的导师的说法，可以通过额外的扎实工作提交给 trans。我确实有一些学术野心，想在 TPAMI 等顶级跨性别杂志上发表文章。然而，我听到很多同行抱怨，提交给跨性别者可能需要 6 到 12 个月的时间，而且结果没有保证。由于我正处于博士学位的第三年末，这可能相当危险，因为它可能会导致不必要的推迟毕业。那么我应该继续专注于会议吗？提前致谢。   由   提交/u/INeedPapers_TTT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnrv30/d_is_it_a_good_idea_for_a_3rd_year_phd_student_to/</guid>
      <pubDate>Thu, 09 May 2024 08:02:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 VQ-VAE 进行 SSL？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnr7ax/d_use_vqvaes_for_ssl/</link>
      <description><![CDATA[VQ-VAE 已成功用于将图像转换为扩散模型 (LDM) 的代表性潜在空间。然而，对于自监督学习，我找不到人们大量使用它们来创建嵌入，该嵌入稍后可以用作下游模型的输入来预测例如图像类。 你知道为什么吗？是？直觉上，我认为 VQ-VAE 也应该产生相当好的嵌入。    由   提交/u/That_Phone6702   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnr7ax/d_use_vqvaes_for_ssl/</guid>
      <pubDate>Thu, 09 May 2024 07:15:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 多元时间序列的矩阵轮廓与深度学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnpo6n/d_matrix_profile_vs_deep_learning_for/</link>
      <description><![CDATA[大家好， 所以我阅读了大量的方法，特别是关于多元时间序列和实时研究的方法人类活动识别（HAR）。不过，我最近偶然发现了 Eamonn Keogh 在 Matrix Profiles 方面令人惊叹且全面的工作，最终陷入了困境。  但是出于好奇，在多元时间序列和实时数据流的背景下，矩阵配置文件与深度学习方法（例如 MLP、LSTM 等）相比如何？  我很想听听其他人的观点！   由   提交 /u/peachjpg111   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnpo6n/d_matrix_profile_vs_deep_learning_for/</guid>
      <pubDate>Thu, 09 May 2024 05:31:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审稿人你们都需要停止如此懒惰的狗。为什么审稿人做事这么懒？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnn54n/d_reviewers_you_all_need_to_stop_being_so_lazy/</link>
      <description><![CDATA[我提交了一篇论文。 被会议接受。 收到来自某个随机家伙的电子邮件_插入_大学_。发送给主席和会议负责人。 指责我抄袭，并说发表论文的匹配度为 92%... 检查交叉引用。标题、作者（我和导师）、数据、结论，几乎整篇论文都被突出显示。 只有来源说 Arkiv。我偶然在那里有我的预印本。我按照他们的政策预印本并张贴了通知。 现在，这是非常愚蠢的。我做了很多尽职调查，如果它与作者匹配，它必须引用我的预印本。 为什么审稿人如此懒惰，可以采取如此激烈的行动，而不是仅仅向作者询问有关这些的问题？我真的不理解其中一些人。对于处理这些情况您有什么建议吗？   由   提交 /u/I_will_delete_myself   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnn54n/d_reviewers_you_all_need_to_stop_being_so_lazy/</guid>
      <pubDate>Thu, 09 May 2024 03:03:45 GMT</pubDate>
    </item>
    <item>
      <title>【研究】一致性LLM：将LLM转换为并行解码器，推理加速3.5倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnfmec/research_consistency_llms_converting_llms_to/</link>
      <description><![CDATA[      大家好！我们在这里分享我们的最新工作：一致性大语言模型（CLLM），这是一个新的模型系列，能够通过有效地并行解码𝑛令牌来减少推理延迟。您的 LLM 服务/本地部署的新朋友，推理速度更快！ 🔥 请查看我们的博客文章以获取 3.1 倍加速的演示： https://hao -ai-lab.github.io/blogs/cllm/ 与现有的快速解码技术相比，CLLM 实现快速并行解码无需：  草稿模型 架构修改/辅助模型组件  这为 CLLM 带来了许多优势：  CLLM 不必处理获取“良好”草稿模型以及在单个系统中管理两个不同模型的复杂性。 CLLM 与目标 LLM 共享相同的架构，无需额外的工程设计将该技术应用于不同模型时的努力。 CLLM 可以与其他技术无缝集成，以实现高效的 LLM 推理（例如 Lookahead 解码），从而实现更显着的加速。   CLLM 使用的这种解码方法称为 Jacobi 解码，与传统的自回归解码相比，它提高了推理效率。 CLLM 的训练目标是通过尽可能少的步骤将任何随机初始化的 𝑛 令牌序列映射到与 AR 解码相同的结果，从而执行高效的 Jacobi 解码。 实验结果证明了 CLLM 的有效性，显示各种任务的生成速度提高了 2.4 倍到 3.4 倍。 与 Medusa2 相比，CLLM 实现了相当或更好的性能，但**不需要额外的参数或树式验证** CLLM 训练目标可视化 请参阅 &lt; a href=&quot;http://arxiv.org/abs/2403.00835&quot;&gt;我们的论文了解更多详细信息。欢迎尝试我们的代码库和 CLLM检查点！ 如果您觉得我们的工作有趣，请订阅、点赞或转发，谢谢！了解更多信息并在 Twitter 上与我们互动： https://x.com/haoailab/status/1788269848788869299&lt; /a&gt;   由   提交 /u/No_Yogurtcloset_7050   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnfmec/research_consistency_llms_converting_llms_to/</guid>
      <pubDate>Wed, 08 May 2024 21:15:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 如何在单次梯度更新后记住事实？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cne766/d_how_do_transformers_memorize_facts_after_a/</link>
      <description><![CDATA[我想我首先希望引用该事实，或者让有人告诉我这是我编造的。但民间知识是，针对单个时期训练的 Transformer 可以回忆起仅在训练数据集中出现过一次的事实。这意味着一次更新足以修改权重以产生正确的输出（不会灾难性地忘记其他事实）。 这对我来说真的很惊讶。我认为一次大到足以大幅修改输出的单个更新将具有相当大的破坏性，并且考虑到损失情况的非单调性，可能只是无法达到您想要的效果。对于如何/为什么会发生这种情况，是否有一个很好的答案，如果有的话，任何人都可以提供调查此问题的研究链接吗？它是大型模型（如 NTK）的特征，还是 Transformer 架构的特征，还是其他什么？请注意，我不是在询问上下文学习，而是在询问单个梯度步骤的变化。   由   提交 /u/asdfwaevc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cne766/d_how_do_transformers_memorize_facts_after_a/</guid>
      <pubDate>Wed, 08 May 2024 20:14:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>