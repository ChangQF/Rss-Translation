<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Wed, 14 Aug 2024 15:15:40 GMT</lastBuildDate>
    <item>
      <title>[D] 信号处理与估计到机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1es3lso/d_signal_processing_estimation_to_machine_learning/</link>
      <description><![CDATA[大家好， 我拥有机器人和人工智能硕士学位（学习过机器学习、深度学习、时间序列分析等课程），并在一家汽车公司工作了两年，从事信号处理（实时 DSP、快速傅里叶变换、滤波等）和估算（卡尔曼滤波器、递归最小二乘等），还用 C++ 为嵌入式应用程序编写了机器学习算法。 但不幸的是，我的技能在国内不受重视，所以我想转向完整的机器学习角色。我把我的简历发给了机器学习职位，但我甚至没有收到回复！我不能去其他团队，在内部，我真的试过了。 你对如何继续有什么建议吗？    提交人    /u/Huge-Leek844   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1es3lso/d_signal_processing_estimation_to_machine_learning/</guid>
      <pubDate>Wed, 14 Aug 2024 14:51:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无处不在的集成：多尺度聚合以实现对抗鲁棒性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1es3dfy/r_ensemble_everything_everywhere_multiscale/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1es3dfy/r_ensemble_everything_everywhere_multiscale/</guid>
      <pubDate>Wed, 14 Aug 2024 14:41:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2024 门票</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1es1qpw/d_neurips_2024_tickets/</link>
      <description><![CDATA[有没有什么办法可以免费获得 NeurIPS 2024 门票或任何形式的奖学金？我真的很想参加会议，但 900 美元 + 旅行 + 住宿对我来说太贵了，而且我的公司不会报销。任何帮助都将不胜感激。    提交人    /u/Dry_Path7689   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1es1qpw/d_neurips_2024_tickets/</guid>
      <pubDate>Wed, 14 Aug 2024 13:34:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] Mix-Net：用于您自己的声音的 AI 封面模型。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1es0deh/p_mixnet_ai_cover_model_for_your_own_voice/</link>
      <description><![CDATA[基于 Transformer 的语音转换模型，使用少量数据（约 1 分钟低噪音语音）进行训练，训练数据少，训练次数少，效果较好。 https://github.com/Music-Mix/Mix-Net    提交人    /u/Leo_D517   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1es0deh/p_mixnet_ai_cover_model_for_your_own_voice/</guid>
      <pubDate>Wed, 14 Aug 2024 12:30:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪个应用程序让你感觉不对劲？为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1erzqcb/d_is_there_any_application_that_doesnt_feel_right/</link>
      <description><![CDATA[不包括杀手机器人之类的东西，我认为几乎每个人都会认为它们不好，因为杀人是坏事。 最近，我一直在考虑在获得硕士学位后我想长期从事哪个领域，我一直在思考有关该领域的这些更基本的问题。 我听了 The Vergecast 的一集，他们采访了一位来自一家公司的人，该公司的目标是为人们提供无限的记忆，他谈论他们的应用的方式让我回想起了过去。我真的不知道为什么，但感觉忘记事情只是人之常情的一部分，这让我想知道其他人对此有何看法，或者其他让他们感到有点不安的应用程序以及原因。 我的例子完全基于直觉，但我认为听到更多的社会学或哲学原因也会很有趣（因为我没有任何人文背景，所以我想不出来哈哈）。    提交人    /u/tomaz-suller   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1erzqcb/d_is_there_any_application_that_doesnt_feel_right/</guid>
      <pubDate>Wed, 14 Aug 2024 11:59:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 新开源版本：时尚领域的 SOTA 多模态嵌入模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eryo73/p_new_opensource_release_sota_multimodal/</link>
      <description><![CDATA[      大家好！ 我非常高兴地宣布推出 Marqo-FashionCLIP 和 Marqo-FashionSigLIP - 两种用于时尚领域搜索和推荐的全新先进多模式模型。这些模型在包​​括 DeepFashion 和 Fashion200K 在内的 7 个时尚评估数据集上超越了当前的 SOTA 模型 FashionCLIP2.0 和 OpenFashionCLIP，最高提升 57%。 Marqo-FashionCLIP &amp; Marqo-FashionSigLIP 是具有 1.5 亿个参数的嵌入模型，其性能如下：  在所有基准测试中均优于 FashionCLIP2.0 和 OpenFashionCLIP（最高提升 57%）。 推理速度比 FashionCLIP2.0 和 OpenFashionCLIP 快 10%。 将 广义构造学习 (GCL) 与 SigLIP 结合使用，可优化超过七个时尚特定方面，包括描述、标题、颜色、详细信息、类别、关键字和材料。 在 7 个公开可用的数据集和 3 个任务中进行了基准测试。  https://preview.redd.it/8kkyn2e61mid1.png?width=1459&amp;format=png&amp;auto=webp&amp;s=e8bfa42faca752538b92e06e3dba3a7780007981 我们根据 Apache 2.0 许可发布 Marqo-FashionCLIP 和 Marqo-FashionSigLIP 此处。 基准测试结果 以下是 7 个数据集的结果。所有值均代表相对于 FashionCLIP2.0 基线的准确率/召回率的相对改进。您可以在此处找到更多详细信息和要重现的代码 https://github.com/marqo-ai/marqo-FashionCLIP。  7 个数据集的平均召回率/准确率@1 结果（与 FashionCLIP2.0 基线相比） 请告诉我任何反馈意见，或者您是否有兴趣看到正在开发的其他模型！ GitHub：https://github.com/marqo-ai/marqo-FashionCLIP 博客：https://www.marqo.ai/blog/search-model-for-fashion    由   提交  /u/Jesse_marqo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eryo73/p_new_opensource_release_sota_multimodal/</guid>
      <pubDate>Wed, 14 Aug 2024 11:00:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于混合专家 (MoE) 的新论文 🚀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1erv2sn/r_new_paper_on_mixture_of_experts_moe/</link>
      <description><![CDATA[      大家好！🎉 很高兴分享一篇关于混合专家 (MoE) 的新论文，探索该领域的最新进展。 MoE 模型因其平衡计算效率和高性能的能力而受到广泛关注，使其成为扩展 AI 系统的关键关注领域。 本文涵盖了 MoE 的细微差别，包括当前的挑战和潜在的未来方向。如果您对 AI 研究的前沿感兴趣，您可能会发现它很有见地。 在此处查看论文和其他相关资源：GitHub - Awesome Mixture of Experts 论文。 期待听到您的想法并引发一些讨论！ 💡 AI #MachineLearning #MoE #Research #DeepLearning #NLP #LLM https://preview.redd.it/yulmcq0xvkid1.png?width=1096&amp;format=png&amp;auto=webp&amp;s=522ce335da7acfdfb1d298cbc04c32b12b04de92    提交人    /u/Ok_Parsley5093   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1erv2sn/r_new_paper_on_mixture_of_experts_moe/</guid>
      <pubDate>Wed, 14 Aug 2024 07:02:30 GMT</pubDate>
    </item>
    <item>
      <title>[R]Gemma Scope：在 Gemma 2 上同时在所有地方开放稀疏自动编码器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eru5ok/rgemma_scope_open_sparse_autoencoders_everywhere/</link>
      <description><![CDATA[  由    /u/crivtox  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eru5ok/rgemma_scope_open_sparse_autoencoders_everywhere/</guid>
      <pubDate>Wed, 14 Aug 2024 06:02:38 GMT</pubDate>
    </item>
    <item>
      <title>CNN 用于音乐结构中的部分检测 [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ermoq3/cnn_for_section_detection_in_music_structure/</link>
      <description><![CDATA[我正在做一个项目，需要使用 Python 检测歌曲的部分，即前奏、主歌、合唱、结尾等。我看到了一张 DJ 软件的图片，当您加载歌曲时，它会为您自动识别这些歌曲。我认为使用 CNN 应该可以解决这个问题，其中数据是带有前奏、主歌、合唱时间戳的歌曲波形，但这需要我构建一个巨大的数据集，因为我无法在网上找到任何可用的数据集。我甚至不确定 CNN 是否能够准确检测每个部分的确切时间。我想到的第二种方法是使用音乐理论。就像每首歌都有一个节拍和节奏。4 个节拍组成一个小节，通常每个部分是 4、8、16 或 32 个小节，所以我想在这些点检查快速傅立叶变换 (FTT) 中的波动以检测部分变化。你觉得这两种方法怎么样。如果有人知道一个数据集或者有更简单的方法来提取数据并自动训练模型，我最好使用 ML 和 CNN 来做到这一点。     提交人    /u/aryandaga7   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ermoq3/cnn_for_section_detection_in_music_structure/</guid>
      <pubDate>Tue, 13 Aug 2024 23:43:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 尝试使用声学信号处理和机器学习将蓝莓分类为“脆”、“多汁”或“软”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1erehp8/r_trying_to_classify_blueberries_as_crunchy_juicy/</link>
      <description><![CDATA[      我正在研究根据蓝莓的质地对蓝莓进行分类，具体来说，是软的、多汁的还是脆的，使用蓝莓压碎时发出的声音。 我有大约 1100 个音频样本，并且为每个样本生成了声谱图。不幸的是，我没有标记数据，所以我不能直接应用监督机器学习技术。相反，我正在寻找基于声谱图区分这三个类别的有效方法。我附上了我认为可能是软的、多汁的和脆的蓝莓的声谱图示例。但是，由于数据没有标记，我不确定这些假设是否正确。 脆浆果：当被压碎时，它们会在音频信号中产生单独的、不同的峰值。这些峰值随时间而分散，表明浆果正在以清晰、分段的方式分裂开来。 crunchyberry 多汁浆果：当被压碎时，它们会在音频信号中产生连续的峰值。这些峰更紧密地聚集在一起并持续存在，表明果汁和果肉爆裂，阻力较小，从而产生更平滑的声音。 juicyberry 软浆果：这些浆果产生的峰很少且很小。声音微弱且不太清晰，表明浆果很容易被压碎，阻力很小，对音频信号的干扰最小。 软莓 我的尝试： 我尝试通过检测音频信号特定时间范围内的峰值来对蓝莓进行分类。这种方法让我能够有效区分软和脆浆果，因为软浆果产生的峰值更少、更小，而脆浆果的峰值则明显、分离。 我的预期： 我预计这种峰值检测方法也有助于对多汁浆果进行分类，因为我预计连续、幅度更高的峰值将与其他类别区分开来。 实际发生了什么： 虽然该方法对软脆浆果很有效，但未能成功区分多汁浆果。多汁浆果峰值的连续性并不像我预期的那样突出，因此很难准确对其进行分类。 有人能帮我提出一些解决这个问题的想法吗？如果您愿意，我们可以一起研究这个问题，并撰写研究论文或期刊文章。    提交人    /u/whiterosephoenix   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1erehp8/r_trying_to_classify_blueberries_as_crunchy_juicy/</guid>
      <pubDate>Tue, 13 Aug 2024 17:54:34 GMT</pubDate>
    </item>
    <item>
      <title>“相互推理”将 GSM8K 准确率从 13% 提高至 64% [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1er7req/mutual_reasoning_improves_gsm8k_accuracy_from_13/</link>
      <description><![CDATA[摘要： 相互推理使小型 LLM 成为更强大的问题解决者 本文介绍了 rStar，一种自我对弈的相互推理方法，可显著提高小型语言模型 (SLM) 的推理能力，而无需微调或高级模型。rStar 将推理解耦为自我对弈的相互生成-鉴别过程。首先，目标 SLM 使用一组丰富的类似人类的推理动作增强蒙特卡洛树搜索 (MCTS)，以构建更高质量的推理轨迹。接下来，另一个具有与目标 SLM 类似功能的 SLM 充当鉴别器来验证目标 SLM 生成的每条轨迹。相互同意的推理轨迹被认为是相互一致的，因此更有可能是正确的。在五个 SLM 上进行的大量实验表明，rStar 可以有效解决各种推理问题，包括 GSM8K、GSM-Hard、MATH、SVAMP 和 StrategyQA。值得注意的是，rStar 将 LLaMA2-7B 的 GSM8K 准确率从 12.51% 提高到 63.91%，将 Mistral-7B 的准确率从 36.46% 提高到 81.88%，将 LLaMA3-8B-Instruct 的准确率从 74.53% 提高到 91.13%。代码将在此 https URL 上提供。 https://arxiv.org/abs/2408.06195    提交人    /u/we_are_mammals   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1er7req/mutual_reasoning_improves_gsm8k_accuracy_from_13/</guid>
      <pubDate>Tue, 13 Aug 2024 13:22:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] Grokfast：通过放大慢速梯度来加速 Grokking</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1er66lu/r_grokfast_accelerated_grokking_by_amplifying/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2405.20233v2 代码：https://github.com/ironjr/grokfast 摘要：机器学习中一种令人费解的现象被称为 grokking，即在对训练数据进行近乎完美的过度拟合后，经过十倍迭代才实现延迟泛化。我们代表机器学习从业者关注长时间延迟本身，我们的目标是加速 grokking 现象下模型的泛化。通过将训练迭代过程中参数的一系列梯度视为随时间变化的随机信号，我们可以将梯度下降下的参数轨迹光谱分解为两个部分：快速变化、过度拟合的成分和缓慢变化、诱导泛化的成分。通过这种分析，我们只需几行放大梯度缓慢变化成分的代码，就能将 grokking 现象加速 50 倍以上。实验表明，我们的算法适用于涉及图像、语言和图形的各种任务，使这种突发泛化的特殊产物具有实际用途。    提交人    /u/Confident-Honeydew66   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1er66lu/r_grokfast_accelerated_grokking_by_amplifying/</guid>
      <pubDate>Tue, 13 Aug 2024 12:08:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 人工智能科学家：迈向全自动开放式科学发现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eqwfo0/r_the_ai_scientist_towards_fully_automated/</link>
      <description><![CDATA[博客文章：https://sakana.ai/ai-scientist/ 论文：https://arxiv.org/abs/2408.06292 开源项目：https://github.com/SakanaAI/AI-Scientist 摘要 通用人工智能的一大挑战是开发能够进行科学研究和发现新知识的代理。虽然前沿模型已经被用作人类科学家的辅助手段，例如虽然它们无法进行头脑风暴、编写代码或预测任务，但它们仍然只完成了科学过程的一小部分。本文提出了第一个全自动科学发现的综合框架，使前沿大型语言模型能够独立进行研究并传达其发现。我们介绍了人工智能科学家，它可以产生新颖的研究想法，编写代码，执行实验，可视化结果，通过撰写完整的科学论文描述其发现，然后运行模拟审查过程进行评估。原则上，这个过程可以重复进行，以开放式的方式迭代开发想法，就像人类科学界一样。我们通过将其应用于机器学习的三个不同子领域来展示它的多功能性：扩散建模、基于变换器的语言建模和学习动力学。每个想法都以每篇论文不到 15 美元的成本实施并开发成一篇完整的论文。为了评估生成的论文，我们设计并验证了一个自动审阅器，我们表明它在评估论文分数方面达到了接近人类的表现。人工智能科学家可以制作出超过顶级机器学习会议接受门槛的论文，由我们的自动审阅者评判。这种方法标志着机器学习科学发现新时代的开始：将人工智能代理的变革性优势带入人工智能本身的整个研究过程，并让我们更接近一个可以在世界上最具挑战性的问题上释放无尽的、可负担的创造力和创新的世界。    提交人    /u/hardmaru   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eqwfo0/r_the_ai_scientist_towards_fully_automated/</guid>
      <pubDate>Tue, 13 Aug 2024 02:17:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢所有人在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Aug 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>