<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 17 May 2024 12:25:10 GMT</lastBuildDate>
    <item>
      <title>[R] 将帧中的对象替换为类似的对象</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cu0qgc/r_replace_the_object_in_the_frame_with_a_similar/</link>
      <description><![CDATA[你好，我正在为我的项目做研究，我需要你的帮助。 5 的桌子上有一个封闭的披萨盒。电影的第二部分，我想用 Pizza H*t、*ominos 等替换这个披萨盒。我的数据集中只有几个 Pizza H*t 盒子，因此人工智能模型需要使用类似的技术到“很少的镜头学习”。我以为我可以使用生成对抗网络 (GAN) 来做到这一点，但除了将马变成斑马之外，我无能为力。我对人工智能和软件开发有足够的了解，但对 GAN 还很陌生。 我应该使用哪种模型，我应该如何研究，我应该使用哪些关键字等等，我可以从哪里开始搜索正确的结果我需要你的帮助，谢谢。   由   提交 /u/GiantGulyabani   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cu0qgc/r_replace_the_object_in_the_frame_with_a_similar/</guid>
      <pubDate>Fri, 17 May 2024 09:07:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 正确解释 Model.predict 输出。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctzxnh/d_correct_interpretation_of_modelpredict_output/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctzxnh/d_correct_interpretation_of_modelpredict_output/</guid>
      <pubDate>Fri, 17 May 2024 08:07:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 FER-2013 数据集进行实时情绪分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctzd0a/p_real_time_emotion_classification_with_fer2013/</link>
      <description><![CDATA[所以我正在一家公司做实习项目，正如标题所说。我基本上需要将人脸分为 7 类 - 愤怒、厌恶目前，我正在努力在 FER 2013 数据集上获得良好的准确性，然后我将转向实时捕获部分 我需要在大约 2 周的时间内完成这个项目。我尝试过使用 mobile_net、VGG19、ResNet50、Inception、Efficient_net 等模型进行迁移学习，我的训练准确度已达到 87% 左右，但验证准确度相当低 ~56% （严重过度拟合，ik）。 这里的聪明人能否帮我提供一些关于如何更好地执行迁移学习的建议，是否应该使用数据增强（我有大约 28000 个训练图像），以及我应该使用视觉转换器等吗？ 使用 VGG19 和 Inception 时，由于某种原因，我的验证准确度停留在 24.71% 并且之后不会改变 ResNet50、mobile_net 和 Efficient_net 给出了上述指标 这是我一直用于迁移学习的示例笔记本 https://colab.research.google.com/drive/1DeJzEs7imQy4lItWA11bFB4mSdZ95YgN?usp=sharing 任何和所有感谢帮助！   由   提交 /u/Hades_Kerbex22   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctzd0a/p_real_time_emotion_classification_with_fer2013/</guid>
      <pubDate>Fri, 17 May 2024 07:25:22 GMT</pubDate>
    </item>
    <item>
      <title>从头开始计算的过去的关键值与从模型获得的过去的关键值之间不匹配[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctxd7c/mismatch_between_past_key_values_calculated_from/</link>
      <description><![CDATA[我正在尝试从头开始计算 llama-2 模型的过去关键值，并遵循所有步骤，包括标准化隐藏状态值和矩阵权重向量与隐藏状态相乘，最后应用 RoPE。即使完成所有这些操作后，过去的键值与从模型中获得的键值仍不匹配。有没有人有什么建议？代码如下： # 加载分词器和模型分词器 = LlamaTokenizer.from_pretrained(path_to_llama2) config = LlamaConfig.from_pretrained(path_to_llama2) config.output_hidden_​​states = True config.output_attentions = True config.use_cache =真实模型 = LlamaForCausalLM.from_pretrained(path_to_llama2, config=config) model.eval() input_text = &quot;很久很久以前&quot;输入 = tokenizer(input_text, return_tensors=&#39;pt&#39;) 输出 = model(**inputs) hide_states =outputs.hidden_​​states state_dict = model.state_dict() # 计算旋转嵌入的函数 def apply_rotary_pos_emb(q, k,rotary_pos_emb): cos, sin =rotation_pos_emb q_rot = q * cos +rotate_half(q) * sin k_rot = k * cos +rotate_half(k) * sin return q_rot, k_rot defrotate_half(x): x1, x2 = x.chunk(2, dim=- 1) return torch.cat((-x2, x1), dim=-1) # 生成旋转位置嵌入 def get_rotary_emb(dim, seq_len): inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2) ).float() / dim)) t = torch.arange(seq_len, dtype=inv_freq.dtype) freqs = torch.einsum(&quot;i,j-&gt;ij&quot;, t, inv_freq) emb = torch.cat( (freqs, freqs), dim=-1) cos = emb.cos().unsqueeze(0).unsqueeze(0) sin = emb.sin().unsqueeze(0).unsqueeze(0) return cos, sin #计算单层的 Past_key_values 的函数 defcompute_past_key_values_for_layer(layer_idx,hidden_​​state):attention_layers = [layer.self_attn for layer in model.model.layers] # 应用层归一化norm_weight = state_dict[f&#39;model.layers.{layer_idx}.input_layernorm .weight&#39;]hidden_​​state = F.layer_norm(hidden_​​state,(hidden_​​state.size(-1),),norm_weight) W_q = state_dict[f&#39;model.layers.{layer_idx}.self_attn.q_proj.weight&#39;] W_k = state_dict[ f&#39;model.layers.{layer_idx}.self_attn.k_proj.weight&#39;] W_v = state_dict[f&#39;model.layers.{layer_idx}.self_attn.v_proj.weight&#39;] 查询 = torch.matmul(hidden_​​state, W_q.T)键 = torch.matmul(hidden_​​state, W_k.T) 值 = torch.matmul(hidden_​​state, W_v.T) batch_size, seq_length, hide_dim = hide_state.size() num_attention_heads = focus_layers[layer_idx].num_heads head_dim = hide_dim // num_attention_heads 个键=keys.view(batch_size, seq_length, num_attention_heads, head_dim) 查询 = requests.view(batch_size, seq_length, num_attention_heads, head_dim) 值 =values.view(batch_size, seq_length, num_attention_heads, head_dim) 键 =keys.permute(0, 2 , 1, 3) 查询=queries.permute(0, 2, 1, 3) 值=values.permute(0, 2, 1, 3)rotary_emb = get_rotary_emb(head_dim, seq_length) 查询, 键= apply_rotary_pos_emb(查询, 键) ,rotary_emb) returnkeys,values # 计算past_key_values past_key_values = [] for i,hidden_​​state in enumerate(hidden_​​states[:-1]): # 跳过最后一层keys,values =compute_past_key_values_for_layer(i,hidden_​​state)past_key_values.append((keys) , value)) past_key_values = tuple(past_key_values)  感谢任何帮助！ 可以在此处找到值之间不匹配的示例：https://pastebin.com/CadGf9Ug   由   提交/u/1azytux  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctxd7c/mismatch_between_past_key_values_calculated_from/</guid>
      <pubDate>Fri, 17 May 2024 05:10:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 被 NeurIPS 2024 - 其他会议接受的真正机会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctv9li/d_real_chances_to_be_accepted_in_neurips_2024/</link>
      <description><![CDATA[嘿！ 这是我第一次向 NeurIPS 提交论文。 有人知道作者什么时候可以看到评论吗？8 月，还是可能更早？如果我们收到非常差的评论……最好的办法是退出提交路径，对吗？在这种情况下，您会推荐在这些日期使用哪些替代方案？ 我的主题是 NN 可靠性，但我总是对自己的研究缺乏信心，我总是认为这还不够，如果我认为在 Neurips 这样的会议上就更是如此。您认为每个人都提交了好论文还是有大量的垃圾论文？我在这里看到了很多关于审查过程的负面意见……所以，我有点害怕。 今年，有 20000 份左右的提交。所以，我不知道该怎么做，是继续提交还是提交给另一个会议。由于我正在填补的空白很明显，我相信其他人也在填补这个空白并将其提交给 NeurIPS。除了 NeurIPS 之外，还有其他会议能先输出结果吗？我正在尝试以一种聪明的方式思考。做一名研究员真难…… 谢谢！    提交人    /u/Sincerebri   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctv9li/d_real_chances_to_be_accepted_in_neurips_2024/</guid>
      <pubDate>Fri, 17 May 2024 03:06:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2018年以来未来被认为是大炮的开创性论文清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cts99m/d_seminal_papers_list_since_2018_that_will_be/</link>
      <description><![CDATA[您好， 这里刚毕业的学生终于有时间学习真正有趣的东西了。我想让自己熟悉现代机器学习。我读过最著名的论文，比如《Attention is all you Need》、《CLIP》、《Vision Transformers》，但我确信我错过了大部分重要的论文。直接阅读最近的 ICML/NIPS 对我没有好处，因为我觉得我有很多基础知识需要涵盖。  我应该从哪里开始？直到 2018 年左右，我才熟悉 ML 和 DL，熟悉普通的 Transformer，但基本上就是这样。    由   提交/u/David202023  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cts99m/d_seminal_papers_list_since_2018_that_will_be/</guid>
      <pubDate>Fri, 17 May 2024 00:27:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 高级框架值得使用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctqzfa/d_are_pytorch_highlevel_frameworks_worth_using/</link>
      <description><![CDATA[为了更好地跟踪实验结果和超参数，我不仅了解了权重和偏差库，而且最终还发现了诸如此类的框架如 PyTorch Lightning 和 Ignite。我一直使用原始 PyTorch，所以我不确定这些框架是否真的有用。我主要从事学术研究，现在我还需要跟踪 MAE，因为这是一个回归问题，我不知道这些框架是否支持这一点，或者让我定义一个自定义指标。 Would这些框架对我有用吗？在尝试不同的架构时，它可以加快进程吗？ 如果您认为它们有用，请告诉我您会推荐哪一个。   由   提交/u/dazor1  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctqzfa/d_are_pytorch_highlevel_frameworks_worth_using/</guid>
      <pubDate>Thu, 16 May 2024 23:24:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 周五的 Oxen.AI Water Cooler 电话会议：高性能音频处理，Python 与 Rust</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctg48v/d_fridays_oxenai_water_cooler_call/</link>
      <description><![CDATA[在本周五的 Oxen.AI Water Cooler 上，  “展示与讲述 / 您遇到什么困难？ / 您的项目是什么？”部分主题将是：  高性能音频处理 Oxen.ai discord 成员 Shalini Ananda 博士，https://www.linkedin.com/in/shalinianandaphd/ 将讨论她在音频工作负载中使用 Python 与 Rust 进行的实验。在此处预览： https://discord.com/channels/1104137825638682806/1145920256301338685/1240029110726561823  Oxen.ai 首席执行官 Greg Schoeninger（u/FallMindless3563）将分享本周 SW2 会议及其会议“更好的数据，更好的人工智能”的亮点  要加入太平洋时间星期五上午 10:00 的 Ai Water Cooler 电话会议或 Paper Club Zoom 电话会议，请用力单击“订阅”按钮： https://lu.ma/oxen    提交人    /u/ReluOrTanh   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctg48v/d_fridays_oxenai_water_cooler_call/</guid>
      <pubDate>Thu, 16 May 2024 15:50:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于分布外检测的基于能量的 Hopfield Boosting</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctfwdv/r_energybased_hopfield_boosting_for/</link>
      <description><![CDATA[https://arxiv.org/abs/2405.08766 在现实世界中部署机器学习模型时，分布外 (OOD) 检测至关重要。与没有高级训练策略的方法相比，异常值暴露方法在训练过程中结合了辅助异常值数据，可以极大地提高 OOD 检测性能。我们引入了 Hopfield Boosting，这是一种增强方法，它利用现代 Hopfield 能量 (MHE) 来锐化分布内数据和 OOD 数据之间的决策边界。 Hopfield Boosting 鼓励模型专注于难以区分的辅助异常值示例，这些示例靠近分布内数据和辅助异常值数据之间的决策边界。我们的方法通过异常值暴露实现了 OOD 检测的最新技术，将 CIFAR-10 上的 FPR95 指标从 2.28 提高到 0.92，将 CIFAR-100 上的 FPR95 指标从 11.76 提高到 7.94。 &lt; !-- SC_ON --&gt;  由   提交/u/hopeman2  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctfwdv/r_energybased_hopfield_boosting_for/</guid>
      <pubDate>Thu, 16 May 2024 15:40:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] L为什么线性 RNN 如此高效（在准确性方面，而不是计算方面）？寻找数学甚至直观的解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctea1i/d_lwhy_are_linear_rnns_so_performant_in_terms_of/</link>
      <description><![CDATA[尝试熟悉 mamba 架构，从而熟悉 SSM，从而熟悉线性 RNN。我查看了有关 SSM、S4 和 Mamba 的资源，但找不到解释。为什么具有 SSM 参数化的线性 RNN 可以提高性能。我也无法直观地理解它 - 为什么线性变换足以完成 seq2seq 任务？ 是否有任何详尽的数学解释，甚至关于线性 RNN 如何在某些任务上胜过 transformers 的视频？    提交人    /u/Ice-Cool701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctea1i/d_lwhy_are_linear_rnns_so_performant_in_terms_of/</guid>
      <pubDate>Thu, 16 May 2024 14:29:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] 针中针（NIAN）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct9nth/p_needle_in_a_needlestack_nian/</link>
      <description><![CDATA[代码：https://github.com/llmonpy/needle-in-a-needlestack 网站：https://nian.llmonpy.ai/ 描述：  大海捞针 (NIAH) 是一种非常流行的测试，用于评估 LLM 能否有效地关注其上下文窗口中的内容。随着 LLM 的进步，NIAH 变得太容易了。针中针 (NIAN) 是一个新的、更具挑战性的基准。即使是 GPT-4-turbo 也难以达到这一基准。 NIAN 从庞大的打油诗数据库中创建一个打油诗列表，并询问有关已放置在测试位置的特定打油诗的问题。每个测试通常会使用 5 到 10 个测试打油诗，放置在提示中的 5 到 10 个位置。每个测试重复 2-10 次。     提交人    /u/EternalBlueFriday   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct9nth/p_needle_in_a_needlestack_nian/</guid>
      <pubDate>Thu, 16 May 2024 10:22:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在单个 A100 上预训练字节级 0.67B 变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct9bgc/r_pretraining_a_bytelevel_067b_transformer_on_a/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct9bgc/r_pretraining_a_bytelevel_067b_transformer_on_a/</guid>
      <pubDate>Thu, 16 May 2024 09:58:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 将人工智能集成到搜索引擎中：Yandex 如何更复杂地利用人工智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct8t1p/r_integrating_ai_into_search_engines_how_yandex/</link>
      <description><![CDATA[对 Yandex 搜索和广告技术业务部总监的简短采访，了解他们如何将人工智能构建到搜索引擎中并将其称为 Neuro . 文章还讨论了人工智能的潜力以及哪些全球趋势可能是其发展的关键。这是一本引人入胜的读物。  看看这里。   由   提交 /u/Beyond_ean   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct8t1p/r_integrating_ai_into_search_engines_how_yandex/</guid>
      <pubDate>Thu, 16 May 2024 09:19:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文没有代码怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct45hk/d_whats_up_with_papers_without_code/</link>
      <description><![CDATA[最近做一个人脸反欺骗的项目，在研究过程中发现几乎没有论文提供实现代码。在可重复性如此重要的领域，为什么人们仍然接受没有实现的论文？   由   提交/u/mtmttuan  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct45hk/d_whats_up_with_papers_without_code/</guid>
      <pubDate>Thu, 16 May 2024 03:57:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>