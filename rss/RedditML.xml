<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 23 Jan 2024 12:26:20 GMT</lastBuildDate>
    <item>
      <title>[P] 最近有人使用 AMD GPU 与 Pytorch 和 Tensorflow 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dm5yh/p_did_anyone_recently_use_amd_gpus_with_pytorch/</link>
      <description><![CDATA[NVIDIA GPU 很快就会短缺，所以我正在寻找替代硬件设备。如果您有这方面的经验，请分享。   由   提交 /u/lucian_sasu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dm5yh/p_did_anyone_recently_use_amd_gpus_with_pytorch/</guid>
      <pubDate>Tue, 23 Jan 2024 11:16:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 4060 ti 16GB 与 4070 Super 12GB</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dkwuo/d_4060_ti_16gb_vs_4070_super_12gb/</link>
      <description><![CDATA[嗨。我目前正在学习机器学习。我不确定要购买哪个 GPU 才能继续。 4070 super 有更多的张量和 rt 核心，但 4060 ti 有更多的 vram。 谢谢！   由   提交 /u/segslol   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dkwuo/d_4060_ti_16gb_vs_4070_super_12gb/</guid>
      <pubDate>Tue, 23 Jan 2024 09:51:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一位想要转型到科技行业的博士后。需要建议。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dks3x/d_a_postdoc_wanting_to_transition_into_tech/</link>
      <description><![CDATA[我完成了博士学位。在欧洲一所世界排名前 20 的学校获得电信博士学位。 目前在中东做博士后，但最近发现我对学术工作不再感兴趣（即成为助理教授） ）。 我想转型到与我的领域仍然相关的行业。不幸的是，现在的顶级公司大多寻找人工智能/机器学习/数据科学专家，而我在我的研究生涯中从未接触过这些专家。 （尽管我可以用 C/Python/R/MATLAB 编写代码） 您对我有什么建议可以增加我进入顶尖科技公司的机会？我应该调整我的研究以便为我应用机器学习提供空间吗？   由   提交/u/LowCorrect9540   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dks3x/d_a_postdoc_wanting_to_transition_into_tech/</guid>
      <pubDate>Tue, 23 Jan 2024 09:41:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何用噪声数据集训练模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dkc1m/d_how_to_train_model_with_noise_dataset/</link>
      <description><![CDATA[我想知道如何使用噪声数据集进行测试和训练。 我是否在训练数据集中添加噪声并使用没有噪音，或者相反？ 如果有人可以提供与此相关的相关资源，那将会很有帮助。  &amp;# 32；由   提交 /u/abystoma   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dkc1m/d_how_to_train_model_with_noise_dataset/</guid>
      <pubDate>Tue, 23 Jan 2024 09:09:30 GMT</pubDate>
    </item>
    <item>
      <title>[N] PRILoRA：修剪和等级增加的低等级适应</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/</link>
      <description><![CDATA[PRILoRA 的核心概念涉及背离为模型中的每一层分配统一的低等级的传统做法。相反，他们提出了一种跨层线性增加的动态分配。这确保了更接近输入的层接收较低的排名，而较深的层被分配更高的排名。例如，在基于 DeBERTaV3 的模型中，他们没有为每一层统一分配 8 的等级，而是从第一层的 4 等级开始，然后逐步提高，直到最深层的等级为 12。这种微妙的分配，平均为 8，产生优异的结果。他们将这一改进归因于这样的观察：语言模型 (LLM) 中的较低层处理更直接和语法的抽象，而更深的层处理语义和复杂元素。在对特定任务进行微调期间，对深层的关注变得至关重要，因为较低层以类似的方式处理单词，但输出需要与较高层表示保持一致。通过区分各层之间的资源分配，它们获得了增强的结果。 此外，它们的微调过程包括根据考虑输入的绝对权重值和累积统计数据的标准重置 A 矩阵中的特定权重分布到层。这种方法针对不太重要的权重，从而提高模型性能。 当应用于基于 DeBERTaV3 的模型时，所提出的方法在 GLUE 基准上优于最先进的方法 (SOTA)。  p&gt; 要全面了解该工作，请参阅全文：https://arxiv.org/pdf/ 2401.11316.pdf   由   提交/u/generous-blessing  /u/generous-blessing  reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dkaqc/n_prilora_pruned_and_rankincreasing_lowrank/</guid>
      <pubDate>Tue, 23 Jan 2024 09:06:35 GMT</pubDate>
    </item>
    <item>
      <title>寻求人工智能工程研究生课程指导（美国）[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dgwgs/seeking_guidance_for_graduate_program_in_ai/</link>
      <description><![CDATA[我正在寻求有关选择美国人工智能工程研究生课程的指导。我的重点是构建实用的产品，而不是广泛的研究或论文写作。我热衷于动手开发，就像软件工程师一样。虽然我对一些研究持开放态度，但我的主要兴趣在于应用人工智能、行业合作和现实世界的项目。对于符合这些目标的研究领域有什么建议吗？   由   提交 /u/lidimop   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dgwgs/seeking_guidance_for_graduate_program_in_ai/</guid>
      <pubDate>Tue, 23 Jan 2024 05:20:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 状态空间模型：一种现代方法 作者：Kevin Murphy、Scott Linderman 等人。 （未完待续）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dg8f0/p_state_space_models_a_modern_approach_by_kevin/</link>
      <description><![CDATA[ 这是一本关于状态空间模型 (SSM) 的交互式教科书，使用 JAX Python 库。其他书籍中涵盖了某些内容，例如 [Sar13] 和 [Mur23]。然而，我们会更详细地讨论如何利用自动微分和并行计算方面的最新进展，在“现代”计算环境中有效地实现各种算法。  在线阅读   由   提交 /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dg8f0/p_state_space_models_a_modern_approach_by_kevin/</guid>
      <pubDate>Tue, 23 Jan 2024 04:42:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么研究生或博士后所做的工作在简历上被低估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19df2gx/d_why_is_work_done_as_a_graduate_student_or/</link>
      <description><![CDATA[学术申请行业职位，在我的特定领域拥有新颖的数据分析和机器学习应用的强大出版记录。可以高度转化为工业的技能。对于任何在 R1 完成博士学位的人来说，您都了解与博士学位相关的无形资产。 我被告知并得到普遍的感觉，即使我们已经证明（发布）了我们领导项目的能力从概念到产品，并展示我们在 PI、政府机构和其他行业合作伙伴的压力下工作无数小时的能力，我们的经验价值较低或仅被视为学校作业而不是“真实”经验。 有人知道为什么吗？ 我们如何更好地向招聘人员传达我们的无形和有形价值？   由   提交/u/dcoceans11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19df2gx/d_why_is_work_done_as_a_graduate_student_or/</guid>
      <pubDate>Tue, 23 Jan 2024 03:38:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有一篇论文是审稿人成为作者之一的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19deoqg/d_is_there_a_paper_that_a_reviewer_becomes_one_of/</link>
      <description><![CDATA[我记得有一篇论文在第一轮就被拒绝/撤回了。一位审稿人提出了更好更快的算法，于是作者连接到 AC 看看是否可以合作，最后审稿人成为作者之一。 你还记得论文是什么吗？  p&gt;   由   提交 /u/Spico197   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19deoqg/d_is_there_a_paper_that_a_reviewer_becomes_one_of/</guid>
      <pubDate>Tue, 23 Jan 2024 03:18:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您希望看到什么 AI/ML 开源工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19daupj/d_what_aiml_opensource_tool_would_you_love_to_see/</link>
      <description><![CDATA[我正在考虑开发一个免费/开源的 AI/ML 工具，很多人都会觉得有用。  您认为很多人会对哪种很酷、简单的 AI/ML 工具感兴趣？    由   提交/u/Sellagen-DataMarket   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19daupj/d_what_aiml_opensource_tool_would_you_love_to_see/</guid>
      <pubDate>Tue, 23 Jan 2024 00:13:01 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以在其回复中隐藏任意不可检测的信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</link>
      <description><![CDATA[ 由   提交/u/LuvIsOurResistance  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</guid>
      <pubDate>Mon, 22 Jan 2024 22:32:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新理论表明聊天机器人可以理解文本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</link>
      <description><![CDATA[文章链接：https://www.quantamagazine.org/new-theory-suggests-chatbots-can-understand-text-20240122/ 链接到论文 1：https://arxiv.org/abs/2307.15936 摘要：  当今人工智能产品的一个主要驱动力是，当参数集和训练语料库扩大时，语言模型中就会出现新的技能。人们对这种现象知之甚少，并且通过基于梯度的训练的数学分析来进行机械解释似乎很困难。当前的论文采用了不同的方法，使用著名的（和经验的）法学硕士缩放定律和简单的统计框架来分析涌现。贡献包括： (a) 一个统计框架，将法学硕士的交叉熵损失与语言任务的基本技能能力联系起来。 (b) 数学分析表明，缩放定律暗示了一种强烈的归纳偏差形式，使得预训练模型能够非常有效地学习。我们非正式地将其称为“弹弓泛化”，因为天真地认为它似乎给出了违反通常泛化理论的技能的能力水平。 (c) 弹弓泛化的一个关键例子，执行涉及 k 元组技能的任务的能力基本上以与基本技能本身的能力相同的规模和速度出现。  Link论文 2：https://arxiv.org/abs/2310.17567 摘要：  随着法学硕士的角色从语言统计建模转变为通用人工智能代理，法学硕士的评估应该如何改变？可以说，人工智能代理的一项关键能力是根据需要灵活组合其所学的基本技能。结合技能的能力在（人类）教育学以及关于涌现现象的论文中发挥着重要作用（Arora &amp; Goyal，2023）。这项工作引入了 Skill-Mix，这是一种衡量组合技能能力的新评估。使用 N 个技能的列表，评估者重复选择 k 个技能的随机子集，并要求法学硕士生成结合该技能子集的文本。由于子集的数量像 Nk 一样增长，因此即使是适度的 k，此评估也很有可能要求法学硕士生成与训练集中的任何文本显着不同的文本。该论文开发了一种方法，用于 (a) 设计和管理此类评估，以及 (b) 使用 GPT-4 以及开放的 LLaMA-2 70B 模型对结果进行自动分级（加上人工抽查）。管理流行聊天机器人的一个版本所得到的结果虽然总体上符合之前的预期，但也包含了令人惊讶的结果。模型能力之间存在相当大的差异，而这些差异并没有通过它们在流行的 LLM 排行榜上的排名来体现（“临时抱佛脚排行榜”）。此外，简单的概率计算表明GPT-4在k＝5上的合理性能暗示超越“随机鹦鹉”性能。行为（Bender 等人，2021），即它以训练期间未曾见过的方式组合技能。我们概述了该方法如何形成基于技能组合的生态系统，对未来模型的人工智能功能进行开放评估。    由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</guid>
      <pubDate>Mon, 22 Jan 2024 21:54:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前理论机器学习作为一个领域有什么意义吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</link>
      <description><![CDATA[随着 SOTA 架构不断变化的极快速度，可能的 DL 技术（正则化、所有不同的激活和损失函数）的多样性如下：以及对可解释人工智能相对退居二线的担忧，现在从事理论机器学习工作有什么用处吗？ 大多数 SOTA 架构似乎只是大规模扩展的高级猜测和检查，而且它确实有效就基准性能而言，我们是否需要 ML/DL 理论？   由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</guid>
      <pubDate>Mon, 22 Jan 2024 20:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们没有看到很多关于 Mamba 架构的内容？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cwf65/d_why_were_not_seeing_a_lot_of_content_about/</link>
      <description><![CDATA[比如对作者的一些采访？还没有看到例如TWIML AI 播客谈论 Mamba 架构。   由   提交/u/_learning_stuff_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cwf65/d_why_were_not_seeing_a_lot_of_content_about/</guid>
      <pubDate>Mon, 22 Jan 2024 14:07:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>