<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 22 Jan 2024 06:19:07 GMT</lastBuildDate>
    <item>
      <title>[D] 反向翻译增强是如何工作的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cou9l/d_how_does_augmentation_by_back_translation_works/</link>
      <description><![CDATA[在低资源语言上培训法学硕士需要增强。流行的方法之一是将数据集从（大部分）英语翻译成所需的语言。  假设有两个模型，一个已经经过翻译训练（翻译模型），另一个模型（新模型）将根据翻译模型产生的数据进行新训练。新模型是针对语言建模目标进行训练的。这种方法有效，但是如何实现呢？这对新训练的模型有何帮助？为什么它有效？从翻译模型中获得什么信息？这是否意味着翻译模型的信息更丰富？ 如果用于训练翻译模型的数据（平行语料库）可用于训练新模型，那么对翻译语料库的需求会消失吗？ （因为低资源语言的所有知识都是从原始平行语料库本身获得的，我们现在可以直接访问它）   由   提交 /u/paarulakan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cou9l/d_how_does_augmentation_by_back_translation_works/</guid>
      <pubDate>Mon, 22 Jan 2024 06:00:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我应该如何融合两种截然不同的模态的预测向量？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cnsgm/r_how_should_i_fuse_prediction_vectors_from_two/</link>
      <description><![CDATA[我是这个领域的新手，我需要实现一个融合其他两个分类器的预测的分类器。 对于例如，我有模态 A（即图像帧）的分类器 A，模态 B（音频）的分类器 B。 单独的分类器 A 可以达到 90% 的准确率，但分类器 B 只能达到对于相同的测试数据，准确率为 66%。 分类器 A 的输出为 pred_A，其值类似于 -11.56, 8.73, -12.15, 10.07 ... 输出分类器 B 的值为 pred_B，其值类似于 -0,068， 0.091，-0.125，0.052 ... 融合 pred_A 和 pred_B 以获得更好的准确率的最佳方法是什么？ &lt; p&gt;我尝试直接添加这两个，但没有成功。然后，我在想是否应该首先连接这两个向量，然后在连接的向量之上堆叠一个额外的 torch.linear() 并训练所有内容，但仍然没有运气。 有人可以提供一些吗这里评论什么容易出错？我应该“正常化”吗？或“S形”在将这两个向量传递给 torch.linear() 或其他东西之前？ 提前致谢。   由   提交 /u/AaronSpalding   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cnsgm/r_how_should_i_fuse_prediction_vectors_from_two/</guid>
      <pubDate>Mon, 22 Jan 2024 05:00:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] LREC-COLING 2024讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cmwet/d_lreccoling_2024_discussion/</link>
      <description><![CDATA[LREC-COLING 评论即将发布，因此请发表有关它的讨论帖子！ &lt;!-- SC_ON - -&gt;  由   提交/u/Standard_Letter_3196   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cmwet/d_lreccoling_2024_discussion/</guid>
      <pubDate>Mon, 22 Jan 2024 04:11:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我应该转行成为一名数据科学家吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cmkja/d_should_i_change_for_university_career_to_be_a/</link>
      <description><![CDATA[我是一名会计专业的学生，​​已经升入三年级，但与该职业相关的内容并不像我感兴趣的那样是数据科学的世界，我在那里选修了几门课程，开展了项目，并开始成为一名自由职业者。关键是我怀疑将我的职业转为计算机工程是否是一个好主意，但我会从第一个开始年，我还很年轻，但我仍然想阅读该行业人士的建议，以了解当我已经在行业中拥有更多经验和更多知名度时，改变职业是否对未来或专业有利。大学生涯将退居二线   由   提交/u/No_Bodybuilder8890   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cmkja/d_should_i_change_for_university_career_to_be_a/</guid>
      <pubDate>Mon, 22 Jan 2024 03:54:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于人工智能信任和可信度的调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ck4yy/r_survey_about_ai_trust_and_trustworthiness/</link>
      <description><![CDATA[大家好， 我是一名博士。我的学生和我的论文研究的一部分是公众对人工智能的看法，特别是关于信任和可信度。因此，我正在寻找调查参与者（这是一项简短的 Qualtrics 调查，需要不到 10 分钟的时间）。我非常感谢您的意见和见解！  链接到调查 * 该研究是由加拿大安大略省圭尔夫市圭尔夫大学网络科学实验室进行。该项目已获得研究伦理委员会的批准，确保遵守加拿大联邦涉及人类参与者的研究指南 (REB#23-08-018)。    由   提交/u/vodku_buhayu  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ck4yy/r_survey_about_ai_trust_and_trustworthiness/</guid>
      <pubDate>Mon, 22 Jan 2024 01:49:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 物体检测的最新技术是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19chbs4/d_what_is_stateoftheart_in_object_detection/</link>
      <description><![CDATA[还有哪些好的资源可以帮助我们了解人工智能各个子集的最新模型？还有哪些其他基线模型可以将它们进行比较？   由   提交/u/Snoo_72181   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19chbs4/d_what_is_stateoftheart_in_object_detection/</guid>
      <pubDate>Sun, 21 Jan 2024 23:35:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Apple Silicon 芯片进行设置的秘诀是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ce73y/d_whats_the_secret_to_getting_set_up_with_an/</link>
      <description><![CDATA[尝试设置 Docker 容器来训练 Magenta 模型，但我在使用 M 芯片和 Python 时遇到了很多问题。 我和 ChatGPT 最终会解决这个问题，但是每个人都在致力于此类事情吗？我已经花了 12 个小时，我最终会在 EC2 实例上完成所有操作吗？ 我不打算在 M 芯片上训练它，只是编写该死的 Python 并部署它   由   提交 /u/gullydowny   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ce73y/d_whats_the_secret_to_getting_set_up_with_an/</guid>
      <pubDate>Sun, 21 Jan 2024 21:23:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] VMamba：视觉状态空间模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cdcwz/r_vmamba_visual_state_space_model/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.10166 代码和模型： https:/ /github.com/MzeroMiko/VMamba 摘要：  卷积神经网络（CNN）和视觉变换器（ViT）是视觉表示学习的两个最流行的基础模型。虽然 CNN 表现出卓越的可扩展性和线性复杂度。尽管在图像分辨率方面，ViT 的拟合能力超过了它们，但其复杂性却是二次方。仔细观察发现，ViT 通过结合全局感受野和动态权重，实现了卓越的视觉建模性能。这一观察促使我们提出一种新颖的架构，该架构继承了这些组件，同时提高了计算效率。为此，我们从最近引入的状态空间模型中汲取灵感，提出了视觉状态空间模型（VMamba），该模型在不牺牲全局感受野的情况下实现了线性复杂性。为了解决所遇到的方向敏感问题，我们引入了交叉扫描模块（CSM）来遍历空间域并将任何非因果视觉图像转换为顺序补丁序列。大量的实验结果证实，VMamba 不仅在各种视觉感知任务中表现出有前景的能力，而且随着图像分辨率的提高，与既定基准相比也表现出更明显的优势。源代码可在 此 https URL 获取。  另一个 Vision Mamba ： https://redd.it/19bgoug   由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cdcwz/r_vmamba_visual_state_space_model/</guid>
      <pubDate>Sun, 21 Jan 2024 20:48:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 利用大型语言模型进行 NLG 评估：一项调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ccuw5/r_leveraging_large_language_models_for_nlg/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.07103 摘要：  在快速发展的自然语言生成（NLG）评估领域，引入大型语言模型（LLM）为评估生成的内容质量（例如连贯性、创造力和上下文相关性）开辟了新途径。本调查旨在全面概述如何利用法学硕士进行 NLG 评估，这是一个缺乏系统分析的新兴领域。我们提出了一个连贯的分类法来组织现有的基于法学硕士的评估指标，提供一个结构化的框架来理解和比较这些方法。我们的详细探索包括批判性评估各种基于法学硕士的方法，以及比较它们在评估 NLG 输出方面的优势和局限性。通过讨论尚未解决的挑战，包括偏见、稳健性、领域特异性和统一评估，本次调查旨在为研究人员提供见解，并倡导更公平、更先进的 NLG 评估技术。  &lt; !-- SC_ON --&gt;  由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ccuw5/r_leveraging_large_language_models_for_nlg/</guid>
      <pubDate>Sun, 21 Jan 2024 20:27:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 聊天法学硕士在哪些多轮对话数据集上进行了微调？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19c9f2f/d_which_multiturn_conversation_datasets_are_chat/</link>
      <description><![CDATA[哪些多轮对话数据集是聊天 LLM 进行微调的，以及如何训练奖励模型以优先于对话？ &lt; /div&gt;  由   提交/u/kekkimo  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19c9f2f/d_which_multiturn_conversation_datasets_are_chat/</guid>
      <pubDate>Sun, 21 Jan 2024 18:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 指令调优的首选微调框架？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19c90vo/d_preferred_finetuning_framework_for_instruction/</link>
      <description><![CDATA[大家好， 我正在研究在小型私人数据集上微调 LLM 的不同框架。我不想追求一些奇特的东西，因为我不想开发自定义训练程序，而只是使用最先进的模型，根据我的数据进行微调。 因此，我的标准主要是易用性、Mistral 等 SOTA 模型的可用性、社区支持和性能（又名实现快速训练的最新方法）。 我正在研究不同的选项，到目前为止发现最成熟的使用 SOTA 模型快速微调 LLM 的方法（看似）是使用： - 蝾螈 - 拥抱脸部TRL 蝾螈似乎是框架加快了速度并使训练变得非常紧凑。 Hugging Face 框架似乎稍微不太用户友好，但似乎提供了更多的自定义功能。 您对每个框架有何看法，您还有其他推荐的框架吗？   由   提交 /u/Separate-Still3770    reddit.com/r/MachineLearning/comments/19c90vo/d_preferred_finetuning_framework_for_instruction/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19c90vo/d_preferred_finetuning_framework_for_instruction/</guid>
      <pubDate>Sun, 21 Jan 2024 17:48:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我想为机器人创建一个大视觉模型（LVM）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19c5fra/p_i_want_to_create_a_large_vision_model_lvm_for/</link>
      <description><![CDATA[我可以贡献任何开源代码吗？我也愿意从头开始创建一个   由   提交/u/Snoo_72181   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19c5fra/p_i_want_to_create_a_large_vision_model_lvm_for/</guid>
      <pubDate>Sun, 21 Jan 2024 15:12:02 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 重新使用 LLM/下一个令牌预测器的状态作为优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bzlxd/discussion_reusing_state_from_llms_nexttoken/</link>
      <description><![CDATA[我一直在思考 GPT-3/4 内部必须如何工作以及可能的优化。我想知道是否有人可以向我指出该领域已经完成的研究，或者我是否完全误解了这些模型的工作原理。 所以基本上我想知道“下一个令牌”预测器方面。尽管它们具有预测下一个标记的功能，但在我看来，这些模型显然必须有一个内部过程（在训练期间以“黑匣子”方式开发）来预测其余的响应。这种预期似乎是必要的，可以防止模型发出下一个导致死胡同的标记，从而无法构建连贯的句子。 此外，这种预见似乎超出了单个句子的范围。 GPT-4 回复通常呈现高度结构化的格式，包括介绍、深入分析和结论，表明答案中具有更高水平的规划或配置。这让我相信，即使模型一次只生成一个下一个标记，它也可能在内部形成一个更完整的响应，以确保精心选择下一个标记。可能不是以正常令牌表示形式散列出完整响应的方式，但至少有一些接近于此的内部表示形式。特别是对于较短的范围（句子），我想它可能相当精确，但对于较长的范围（段落等），也许它越来越抽象。 这种理解提出了一个问题：有没有办法直接从网络中提取更多完整响应？目前，考虑到先前发出的令牌，似乎对每个令牌重复整个计算。我怀疑这些计算的很大一部分可能是相似的，或者至少可能有一个更有效的途径来在发出第一个令牌后从内部状态生成完整的答案。 实际上，这可能涉及更改模型以在每次迭代中产生更长或完整的响应，而不仅仅是单个标记。或者，可以开发一个较小的辅助模型，以在一次令牌生成后“窥视”主要模型的内部状态，并从中生成完整的答案。或者，也许是一个以允许重用内部状态的方式训练的模型，从而加速后续令牌的生成。也许只是从相同的状态重新启动或以某种方式改变它。 我很好奇这些想法的可行性以及它们是否符合当前对法学硕士的理解。我期待听到您的想法，特别是如果我对法学硕士如何运作的假设存在根本性误解的话。   由   提交 /u/ShoeStatus2431   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bzlxd/discussion_reusing_state_from_llms_nexttoken/</guid>
      <pubDate>Sun, 21 Jan 2024 09:22:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有任何动手/实用的 ML YouTube 频道？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19bz6l5/d_are_there_any_hands_onpractical_ml_youtube/</link>
      <description><![CDATA[我一直在寻找实用的深度学习或机器学习论文实现或 YouTube 频道上的实践。您有推荐的频道吗？   由   提交/u/Agitated-Ad809  /u/Agitated-Ad809 reddit.com/r/MachineLearning/comments/19bz6l5/d_are_there_any_hands_onpractical_ml_youtube/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19bz6l5/d_are_there_any_hands_onpractical_ml_youtube/</guid>
      <pubDate>Sun, 21 Jan 2024 08:52:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>