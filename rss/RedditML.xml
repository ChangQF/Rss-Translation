<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Thu, 18 Apr 2024 00:57:48 GMT</lastBuildDate>
    <item>
      <title>[R] [2404.10667] VASA-1：实时生成逼真的音频驱动的说话面孔</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6q61y/r_240410667_vasa1_lifelike_audiodriven_talking/</link>
      <description><![CDATA[ 由   提交/u/s6x  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6q61y/r_240410667_vasa1_lifelike_audiodriven_talking/</guid>
      <pubDate>Thu, 18 Apr 2024 00:41:07 GMT</pubDate>
    </item>
    <item>
      <title>[N] 美联储任命“人工智能末日者”来管理美国人工智能安全研究所</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6nps8/n_feds_appoint_ai_doomer_to_run_us_ai_safety/</link>
      <description><![CDATA[https://arstechnica.com/tech-policy/2024/04/feds-appoint-ai-doomer-to-run-us-ai-safety-institute/ 文章简介： 被任命为 AI 安全负责人的是 Paul Christiano，他是前 OpenAI 研究员，开创了一种名为基于人类反馈的强化学习的基础 AI 安全技术（ RLHF），但也因预测“人工智能发展有 50% 的机会以‘厄运’而告终”而闻名。尽管克里斯蒂安诺的研究背景令人印象深刻，但一些人担心，任命所谓的“人工智能厄运者”会带来灾难。 NIST 可能冒着鼓励非科学思维的风险，许多批评家认为这些思维纯粹是猜测。   由   提交/u/bregav  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6nps8/n_feds_appoint_ai_doomer_to_run_us_ai_safety/</guid>
      <pubDate>Wed, 17 Apr 2024 22:49:39 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]统计学博士就业前景</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6l20i/discussion_phd_in_statistics_job_prospects/</link>
      <description><![CDATA[我很想知道银行和银行业的工作机会鉴于当前的市场状况，为攻读统计学博士学位的人提供保险。   由   提交 /u/SpiritualCellist4303   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6l20i/discussion_phd_in_statistics_job_prospects/</guid>
      <pubDate>Wed, 17 Apr 2024 20:59:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有办法确定模型学习的表示是球形还是双曲形？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6kt3a/d_is_there_a_way_to_determine_if_the/</link>
      <description><![CDATA[标题。有没有办法确定特征提取器针对已训练/将测试的一组示例学习的嵌入的球形度或双曲度？ 我是深度学习中的几何新手。如果有人也能给我指出一篇论文或一本书来开始这方面的工作，那就太好了。提前致谢。   由   提交/u/Mad_Scientist2027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6kt3a/d_is_there_a_way_to_determine_if_the/</guid>
      <pubDate>Wed, 17 Apr 2024 20:49:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] RuleOpt：基于优化的分类规则学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6ix86/r_ruleopt_optimizationbased_rule_learning_for/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2104.10751 软件包： https://github .com/sametcopur/ruleopt 文档： https://ruleopt.readthedocs .io/ RuleOpt是一种基于优化的规则学习算法，专为分类问题而设计。 RuleOpt注重可扩展性和可解释性，利用线性编程进行规则生成和提取。 Python库ruleopt能够从集成模型中提取规则，并且还实现了一种新颖的规则生成方案。该库确保与现有机器学习管道的兼容性，并且对于解决大规模问题特别有效。 以下是ruleopt的一些亮点：  高效的规则生成和提取：利用线性编程进行可扩展的规则生成（独立的机器学习方法）以及从训练有素的随机森林和增强模型中提取规则。 可解释性：通过将成本分配给规则来优先考虑模型透明度，以实现与准确性的理想平衡。 与机器学习库集成：促进与知名 Python 库 scikit 的顺利集成-learn、LightGBM 和 XGBoost 以及现有的机器学习管道。 广泛的求解器支持：支持多种求解器，包括 Gurobi、&lt; em&gt;CPLEX 和 OR-Tools。    由   提交/u/zedeleyici3401   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6ix86/r_ruleopt_optimizationbased_rule_learning_for/</guid>
      <pubDate>Wed, 17 Apr 2024 19:34:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] LSTM时间序列预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6igqk/d_lstm_time_series_forecasting/</link>
      <description><![CDATA[        由   提交 /u/StressAccomplished26   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6igqk/d_lstm_time_series_forecasting/</guid>
      <pubDate>Wed, 17 Apr 2024 19:15:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] ResearchAgent：利用大型语言模型对科学文献进行迭代研究想法生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6gb2m/r_researchagent_iterative_research_idea/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.07738 摘要：  科学研究对于改善人类生活至关重要，但其阻碍固有的复杂性、缓慢的速度以及对专业专家的需求。为了提高其生产力，我们提出了一个ResearchAgent，这是一种由大型语言模型驱动的研究想法写作代理，它可以自动生成问题、方法和实验设计，同时根据科学文献对其进行迭代完善。具体来说，从核心论文作为产生想法的主要焦点开始，我们的 ResearchAgent 不仅通过通过学术图连接信息来增强相关出版物，而且还根据其基本概念从以实体为中心的知识存储中检索实体，挖掘和在许多论文中共享。此外，为了反映人类通过同行讨论迭代改进想法的方法，我们利用多个评审代理来迭代地提供评审和反馈。此外，它们是用符合人类偏好的大型语言模型来实例化的，其评估标准源自实际的人类判断。我们在多个学科的科学出版物上对我们的 ResearchAgent 进行了实验验证，展示了它在基于人类和基于模型的评估结果生成新颖、清晰和有效的研究想法方面的有效性。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6gb2m/r_researchagent_iterative_research_idea/</guid>
      <pubDate>Wed, 17 Apr 2024 17:49:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] Ctrl-Adapter：一种高效且多功能的框架，用于使各种控制适应任何扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6fygt/r_ctrladapter_an_efficient_and_versatile/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.09967 代码：https ://github.com/HL-hanlin/Ctrl-Adapter 模型：https://huggingface.co/hanlincs/Ctrl-Adapter 项目页面：https://ctrl-adapter.github.io/ 摘要：  ControlNets广泛用于在不同条件下的图像生成中添加空间控制，例如深度图、精明边缘和人体姿势。然而，利用预训练图像 ControlNet 进行受控视频生成时存在一些挑战。首先，由于特征空间的不匹配，预训练的ControlNet无法直接插入新的骨干模型，并且为新的骨干网络训练ControlNet的成本是一个很大的负担。其次，不同帧的 ControlNet 特征可能无法有效处理时间一致性。为了应对这些挑战，我们引入了 Ctrl-Adapter，这是一种高效且多功能的框架，通过调整预训练的 ControlNet（并改进视频的​​时间对齐），为任何图像/视频扩散模型添加多种控制。 Ctrl-Adapter 提供多种功能，包括图像控制、视频控制、稀疏帧视频控制、多条件控制、与不同骨干网的兼容性、适应不可见的控制条件以及视频编辑。在 Ctrl-Adapter 中，我们训练适配器层，将预训练的 ControlNet 特征融合到不同的图像/视频扩散模型，同时保持 ControlNet 和扩散模型的参数冻结。 Ctrl-Adapter由时间和空间模块组成，可以有效处理视频的时间一致性。我们还提出了潜在跳跃和反时间步采样，以实现鲁棒自适应和稀疏控制。此外，Ctrl-Adapter 只需取 ControlNet 输出的（加权）平均值即可实现多种条件下的控制。凭借不同的图像/视频扩散主干（SDXL、Hotshot-XL、I2VGen-XL 和 SVD），Ctrl-Adapter 在图像控制方面与 ControlNet 相匹配，并优于视频控制的所有基线（在 DAVIS 2017 数据集上实现了 SOTA 精度）更低的计算成本（少于 10 个 GPU 小时）。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6fygt/r_ctrladapter_an_efficient_and_versatile/</guid>
      <pubDate>Wed, 17 Apr 2024 17:34:59 GMT</pubDate>
    </item>
    <item>
      <title>[D]问题：时间序列解码到非时间潜在空间？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6fa97/d_question_timeseries_decoding_to_nontemporal/</link>
      <description><![CDATA[您好！我是一名计算神经科学研究员，希望将一些现代机器学习技术应用于功能磁共振成像时间序列数据。我收集了一组高维 4D fMRI 时间序列数据，这些数据是在受试者定期观察 COCO 的自然图像时收集的。我们目前拥有采用预处理“快照”的解码模型。该时间序列数据被扁平化为在观察图像的短时间内聚合的激活模式，并使用一些机器学习模型来解码和重建来自大脑的图像内容。 （请参阅我的一些最近的工作）。 我很好奇存在什么样的机器学习技术可能能够处理时间序列数据本身，而不必将时间序列折叠为单个快照来执行我们的解码过程。我设想的是一个模型（可能是一个变压器），它可以将高维多通道时间序列作为输入，并输出与图像刺激相对应的扁平潜在表示（例如 CLIP 向量），甚至是由已知的规则间隔（正如我们在不同图像呈现的数据中所具有的那样）。据我所知，时间序列数据的机器学习的大部分工作都是预测，但我想要的是静态（或可能重复的）输出。我希望更详细的时间序列数据将具有额外的信号，从而提高 fMRI 视觉解码的解码性能。 ML 领域是否有解决类似问题的现有工作？  &gt;   由   提交 /u/reesespike   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6fa97/d_question_timeseries_decoding_to_nontemporal/</guid>
      <pubDate>Wed, 17 Apr 2024 17:08:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在交叉注意力中，为什么 Q 取自解码器，K 取自编码器输出？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6bt1c/d_in_crossattention_why_is_q_taken_from_decoder/</link>
      <description><![CDATA[我查了很多地方但找不到答案。如果我们分别将 Q 和 K 来自编码器和解码器，会发生什么？会有什么不同吗？   由   提交/u/shuvamg007  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6bt1c/d_in_crossattention_why_is_q_taken_from_decoder/</guid>
      <pubDate>Wed, 17 Apr 2024 14:49:10 GMT</pubDate>
    </item>
    <item>
      <title>[D]视觉语言模型中视觉嵌入如何与语言嵌入空间共存？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6bmjs/d_how_does_visual_embedding_coexist_with_language/</link>
      <description><![CDATA[大家好！我很高兴能讨论大视觉语言模型 (LVLM)。由于我们可能是最大的法学硕士社区，我认为这个频道将是开始这次对话的完美场所。此外，关于将视觉和语言嵌入结合起来的内容并不多。 LVLM 的一些背景：它们通常由图像的视觉编码器、文本的常规标记器、像投影层这样的投影层组成。 MLP 将视觉特征与文本嵌入空间对齐，最后合并图像和文本嵌入以发送到 LLM 模型中。输入包括文本和图像，而输出是文本，使其成为多模式法学硕士。查看 LLaVA 论文中的图表，了解直观的细分： https://preview.redd.it/l222askgu1vc1.png?width=1607&amp;format=png&amp; ;auto=webp&amp;s=ef011e16301c22b4751d8d0a8f3698f70e3ffd26 从像 CLIP ViT 这样的视觉编码器开始，模型从图像中学习视觉信息，然后使用 MLP 将其投影到 LLM 的嵌入空间上。该论文将这种特征称为对齐。我很好奇视觉嵌入如何与文本嵌入交互，因此我尝试使用 PCA 以 3D 方式可视化它们。 例如，采用 llava-7B 模型 - 它使用 llama-7B 后端和32k 词汇量和 4096 个维度，使得嵌入大小为：[32000,4096]。我使用了一个简单的提示，“向我解释一下这张图片”。使用猫的图片来查看嵌入如何出现在我们的空间中。 https://preview.redd.it/032oy0ynu1vc1.png?width=662&amp;format=png&amp;auto=webp&amp;s=d037bbecc976392e159a1c1bde775ef1e14 8488d 正在添加视觉标记改变了动态。每个图像转换为 576 个形状的视觉标记 [576,4096]。查看包含这些标记时绘图如何调整： https://preview.redd.it/9c3cu7ksu1vc1.png?width=660&amp;format=png&amp;auto=webp&amp;s=c0aab6782fc309eba09ec660759bfaf48582dc14  整个文本嵌入看起来较小，由包含整个 llama-7B 词汇的小蓝点表示。 为了进一步放大，我仅突出显示嵌入附近的视觉标记（意味着更高的余弦相似度）。以下是它们如何聚集在一起的： https ://preview.redd.it/vdeacylwu1vc1.png?width=566&amp;format=png&amp;auto=webp&amp;s=42441b4fd515cee916b40243429b4aa6820b998c 那我觉得怎么样？ 首先，我们不会直接将视觉标记转换为文本。最近的一篇 Google 论文尝试过，发现这不是最好的方法。视觉推理似乎徘徊在文本嵌入空间附近，可能是因为图像的信息更密集，需要更多的标记来表示视觉概念。 其次，这种设置目前看来是正确的。视觉标记与文本标记一起，将图像衍生的上下文添加到 LLM，使其能够“看到”图像。 最后，尽管 llava 在视觉推理的一些基准测试中表现良好，但它可能还不是最有效的图像表示方法。最近的一些研究谈到了注意力稀疏现象，尤其是 LVLM 中的视觉标记。我们很幸运，因为注意力算法只关注有意义的视觉标记并忽略噪音。 你觉得怎么样？谢谢阅读。 :-)   由   提交/u/E-fazz  /u/E-fazz  reddit.com/r/MachineLearning/comments/1c6bmjs/d_how_does_visual_embedding_coexist_with_language/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6bmjs/d_how_does_visual_embedding_coexist_with_language/</guid>
      <pubDate>Wed, 17 Apr 2024 14:41:31 GMT</pubDate>
    </item>
    <item>
      <title>词嵌入 - 上下文化与 word2vec [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c69b23/word_embedding_contextualised_vs_word2vec_d/</link>
      <description><![CDATA[关于词嵌入的菜鸟问题 -  据我所知到目前为止 -  语境化词嵌入BERT 和其他 LLM 类型模型生成的模型使用注意力机制并考虑单词的上下文。所以不同句子中的同一个词可以有不同的向量。  这 ^ 与 word2vec 等模型的旧方法相反 - word2vec 生成的嵌入不是上下文的。  但是，仔细观察 CBOW 和skip-gram 模型。似乎他们也尝试根据周围（上下文）单词来预测中心单词。因此，word2vec 生成的嵌入也可以是上下文相关的。 所以它们都是上下文相关的？  我错过了什么？    由   提交 /u/datashri   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c69b23/word_embedding_contextualised_vs_word2vec_d/</guid>
      <pubDate>Wed, 17 Apr 2024 13:03:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研究中数学和算法哪个优先？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c64jw0/d_what_comes_first_math_or_algorithm_in_research/</link>
      <description><![CDATA[我现在正在学习扩散背后的方法（DDPM、基于分数的方法和其他方法）。我想知道研究人员到底是如何想出这个想法的？ 发明新方法是这样的吗？ 1.我们想要制作更好的图像生成器。 2. 哦，数据永远不够...... 3. 让我们乘以数据 - 通过添加一些噪声损坏 4. 这个效果很好，如果我们制作一个去噪网络怎么办？ 5. 如果我们建立一个由纯噪声生成图像的网络会怎么样？ 6. 这不行，如果我们做更小的去噪步骤怎么办？ 7. 这有效！现在，让我们创建一些关于它为何起作用的理论。 8.写论文 或者类似的东西？ 1.我们想要制作更好的图像生成器。 2.我们知道“非平衡热力学”非常好，想尝试以某种方式应用它 3. 我们以某种方式想出了一种依赖于该理论的数学的算法 4. 它有效！ 5. 我们写论文。 通常哪个先出现？数学还是算法？   由   提交/u/Deep-Station-1746   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c64jw0/d_what_comes_first_math_or_algorithm_in_research/</guid>
      <pubDate>Wed, 17 Apr 2024 08:22:11 GMT</pubDate>
    </item>
    <item>
      <title>AI/ML 数据中心的未来将是 100 台甚至 1000 台服务器像一个巨型加速器一样运行 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c62oym/the_future_of_aiml_data_centers_is_going_to_be/</link>
      <description><![CDATA[在服务器公司 Gigabyte 的网站上看到了这个信息丰富的视频 (https://youtu.be/2Q7S-CbnAAY?si=DJtU2mQ_ZKRZ83Nf），简而言之，服务器品牌现在将完整的服务器集群运送到数据中心，而不是单个服务器机器。在此所示的示例中，它有 8 个机架（另外一个用于管理和网络），每个机架中有 4 台相同型号的服务器，以及 4 个相同的超高级 GPU每个服务器中的模型。为您计算一下，每个集群有 32 台服务器或 256 个 GPU 加速器。请注意，所有服务器和 GPU 都必须是相同的型号，因为它们的连接方式基本上是作为一台单独的机器运行。 这很可能是标准构建块的原因。所有人工智能数据中心的特点是，我们现在利用大型数据集训练人工智能的方式，参数数量达到数十亿，甚至数万亿。对于为我们带来 ChatGPT 及其同类产品的法学硕士来说尤其如此。以任何效率处理这些数万亿个参数的唯一方法是通过我们以前从未见过的规模的并行计算。因此，这个大胆的新概念将数百甚至数千台服务器连接在一起，因此它们基本上是一台巨型服务器，加载了 Nvidia 或其他品牌的数千个 GPU。真正令人着迷的东西，我还没有看到目前为人工智能计算的未来提出的任何其他规模的东西。 这是视频中介绍的集群的网站：https://www.gigabyte.com/Industry-Solutions/giga-pod-as-a-service ?lan=en   由   提交/u/Low_Complaint2254   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c62oym/the_future_of_aiml_data_centers_is_going_to_be/</guid>
      <pubDate>Wed, 17 Apr 2024 06:16:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>