<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 30 Apr 2024 06:18:30 GMT</lastBuildDate>
    <item>
      <title>[D] 对我的简历有反馈吗？我是一名三年级本科生，实习机会为零。我真的不知道出了什么问题。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cglpqv/d_feedback_on_my_resume_im_a_thirdyear_undergrad/</link>
      <description><![CDATA[   ​ https://preview.redd.it/ibmoksfa5kxc1.png?width=1204&amp;format=png&amp; ;auto=webp&amp;s=4279b118fe365fe1a81f910093c16b497ca1b43b   由   提交 /u/Effective_Raccoon_54   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cglpqv/d_feedback_on_my_resume_im_a_thirdyear_undergrad/</guid>
      <pubDate>Tue, 30 Apr 2024 06:06:27 GMT</pubDate>
    </item>
    <item>
      <title>获得入门级机器学习工作需要多少课程？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cgljd9/how_much_coursework_is_required_to_land_an/</link>
      <description><![CDATA[所以，我是一名在伯克利攻读硕士学位的研究生，我有一个绝佳的机会在这里学习高年级统计/计算机科学和机器学习课程对于我的选修课。我正在攻读流行病学/生物统计学硕士学位，但我很好奇在这一领域建立一些技能是否可以成为我将来进入该领域的东西。这学期我们在课堂上学习了非参数回归，我发现它非常有趣，再加上关于公共卫生就业市场的不祥之兆，我想为自己做一点未来的证明。   由   提交 /u/SheisaMinnelli   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cgljd9/how_much_coursework_is_required_to_land_an/</guid>
      <pubDate>Tue, 30 Apr 2024 05:55:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 图对抗学习的基础论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cgjr45/d_foundational_papers_for_graph_adversarial/</link>
      <description><![CDATA[我一直在自学图论并且真的很享受它。我的工作将转向对抗性机器学习，所以我对图论和对抗性机器学习的应用感到好奇。我找到了以下资源： https://github.com/safe-graph/graph-adversarial-learning-文献这似乎非常有用。不过，我想确保在深入研究过去一两年发表的任何内容之前，我首先了解了基础知识。 有人推荐我可以阅读的论文来开始理解这个主题吗？谢谢！   由   提交/u/ADDMYRSN   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cgjr45/d_foundational_papers_for_graph_adversarial/</guid>
      <pubDate>Tue, 30 Apr 2024 04:10:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻求有关特定用例的视频到文本架构的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cggu1s/p_seeking_advice_on_videototext_architecture_for/</link>
      <description><![CDATA[嘿各位 Reddit 用户， 我正在开发一个项目，该项目涉及从视频序列中提取文本信息。目标是开发一种可以准确转录视频中的文本的模型，类似于音频的语音到文本模型的工作方式。 我一直在探索不同的架构，但我不确定哪种架构其中一个最适合我的用例。我很想听听该领域专家的意见，并就最佳方法获得一些建议。 为了给您一个更好的想法，假设我正在开展一个项目，该项目涉及从以下视频中转录文本：人们烹饪食谱。视频显示厨师正在准备菜肴，我想从视频中提取菜谱文本。 我考虑过使用 CNN 和 Transformer 的组合，但我不确定这是否是最好的选择最好的方法。对于以下方面的任何建议，我将不胜感激： 哪种类型的架构最适合此任务？是否有任何可以针对我的特定用例进行微调的预训练模型？开发视频转文本模型时需要避免哪些常见陷阱？预先感谢您的帮助和建议！ 编辑：我想澄清一下，我正在寻找有关视频到文本架构的一般建议，而不是专门针对烹饪食谱示例。我有兴趣了解可应用于各种视频到文本任务的不同方法和技术。   由   提交/u/kaku53  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cggu1s/p_seeking_advice_on_videototext_architecture_for/</guid>
      <pubDate>Tue, 30 Apr 2024 01:43:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 解决 QLORA 调整模型遗忘的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cgdndx/d_what_the_best_way_to_resolve_qlora_tuned_model/</link>
      <description><![CDATA[我即将在特定域中部署经过 QLORA 调整的 LLM。经过微调的模型在为客户特定任务生成答案方面表现出优于 GPT-4 的性能。然而，我注意到一个问题：经过微调的法学硕士有时无法为一般问题提供连贯的答案，更重要的是，它无法提供安全的答案。 我知道的解决方案是涉及在微调期间合并通用域数据。然而，我对这种方法非常怀疑，因为它可能需要大量的数据和资源。 我对使用正确的指令调整模型与客户交互更加乐观。如果客户的意图是执行特定任务，我们可以将他们的请求重新发送给经过微调的法学硕士。  我相信这一策略与开发基于 LLM 的应用程序的代理观点非常吻合。 我将感谢您对此主题的专业意见。 &lt; !-- SC_ON --&gt;  由   提交 /u/snassimr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cgdndx/d_what_the_best_way_to_resolve_qlora_tuned_model/</guid>
      <pubDate>Mon, 29 Apr 2024 23:16:26 GMT</pubDate>
    </item>
    <item>
      <title>[P] 持续存在的过拟合问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cgbrjf/p_persisting_overfitting_problem/</link>
      <description><![CDATA[您好，我是机器学习的初学者，但我有很好的基础。我启动了一个学校项目，其中涉及开发一个模型来预测美国数据科学家的就业能力。目标是帮助求职者确定他们是否可以在当前的美国市场就业。我从 Indeed 上抓取了数据并开发了模型，但我仍然面临过度拟合的问题。最初存在数据泄漏的问题，但现在即使解决了这个问题，我仍然遇到过拟合问题。我在训练数据上始终获得 100% 的满分，在测试数据上获得 9% 的满分。就数据泄露而言，两者都是100%。现在，我不确定如何解决这个问题。我尝试了从数据平衡到功能选择的所有方法。我已经尝试了我能想到的一切，并使用了几种网格搜索算法。我不知道现在该怎么办，尽管我认为我已经对原始数据做了很好的预处理。有人可以帮我找出问题所在吗？    由   提交/u/Monkey_D_Uzumaki7   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cgbrjf/p_persisting_overfitting_problem/</guid>
      <pubDate>Mon, 29 Apr 2024 21:58:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML面试中常用的NLP论文建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cg4p4h/d_suggestions_for_nlp_papers_commonly_implemented/</link>
      <description><![CDATA[我正在准备 MLE 面试，我注意到一些公司要求应聘者在面试过程中实现研究论文中的模型或层。&lt; /p&gt; 您能否推荐一些 NLP 研究论文，让我可以练习使用 PyTorch 的实现技巧？我认为面试中使用的论文很有挑战性，但在 1 小时的面试范围内还是可以应付的。谢谢！ 我能想到的一些经典论文：  多头注意力 BERT GPT-2     由   提交 /u/xiaohk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cg4p4h/d_suggestions_for_nlp_papers_commonly_implemented/</guid>
      <pubDate>Mon, 29 Apr 2024 17:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 RoPE 或 ALiBi 时，注意力机制如何远距离检索有意义的信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cg0k6a/d_how_can_attention_mechanisms_retrieve/</link>
      <description><![CDATA[如果 RoPE 和 ALiBi 都工作在这样的假设下：两个 token 距离越远，我们应该分配越来越低的分数，那么分数是否会受到如此的惩罚在某些时候，即使有 100 万个标记之外的有趣事实，我们也无法检索它，因为位置编码会迫使它具有如此低的分数？ &lt;!-- SC_ON - -&gt;  由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cg0k6a/d_how_can_attention_mechanisms_retrieve/</guid>
      <pubDate>Mon, 29 Apr 2024 14:30:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI/DS/ML 团队的领导者是否总是拥有博士学位，这是必需的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfzktw/d_do_leads_in_an_aidsml_team_always_have_phds_is/</link>
      <description><![CDATA[大家好，我是一名人工智能硕士的大学生。在我攻读学士学位期间，我在一家公司完成了我的论文，首席人工智能拥有进化算法的博士学位。上周，我接受了一位来自价值数十亿美元的在线市场的首席 DS 的客座演讲，他也拥有博士学位。这些是我见过的一些拥有博士学位的领导者的例子。 因此这就提出了一个问题，是否有必要拥有博士学位才​​能成为 AI/ML/DS 团队的领导者？我只是好奇，我不知道这是否是我想要做的事情，前辈最后也可以。但我见过很多次，我还没有看到相反的情况，比如只有硕士学位的领导。 我不寻求任何职业建议，我不打算在所有，我只是经常观察这一点，所以我很好奇。 有什么想法吗？   由   提交/u/Rajivrocks  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfzktw/d_do_leads_in_an_aidsml_team_always_have_phds_is/</guid>
      <pubDate>Mon, 29 Apr 2024 13:49:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果我错了请纠正我，NLP 使用 KL 散度，CV 使用 MMD。两者都在测量两个分布的相似度/距离</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfv1re/d_correct_me_if_im_wrong_use_kl_divergence_for/</link>
      <description><![CDATA[我现在正在做实例选择，经过快速研究，我发现使用 MMD 而不是 KL 散度的作品较少。在这两个领域中选择距离度量是否存在偏好？这背后的原因是什么？ THX   由   提交 /u/VoiceBeer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfv1re/d_correct_me_if_im_wrong_use_kl_divergence_for/</guid>
      <pubDate>Mon, 29 Apr 2024 09:44:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 搭载 VisionPro 的新型远程操作工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfrgx9/r_new_teleoperation_tool_with_visionpro/</link>
      <description><![CDATA[       由   提交/u/XiaolongWang  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfrgx9/r_new_teleoperation_tool_with_visionpro/</guid>
      <pubDate>Mon, 29 Apr 2024 05:40:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 动态高斯网格</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfraht/r_dynamic_gaussians_mesh/</link>
      <description><![CDATA[       由   提交/u/XiaolongWang  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfraht/r_dynamic_gaussians_mesh/</guid>
      <pubDate>Mon, 29 Apr 2024 05:29:27 GMT</pubDate>
    </item>
    <item>
      <title>要赢得 ML 黑客马拉松，除了 ML 之外，你还需要一切 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cficmp/you_need_everything_other_than_ml_to_win_a_ml/</link>
      <description><![CDATA[基本上是对我的大型跨国公司和机构主办的线下黑客马拉松条件的咆哮。  厌倦了参加旨在“开发尖端解决方案”的黑客马拉松，最终输给了一个从未学过机器学习但精通“商业信息学”的人并且在给定的时间内提出解决方案非常好。  一个头脑清醒的人，在创意、原型和模型上不停地工作 2-3 天，怎么可能只谈论 3-5 分钟呢？我确实看到人们克隆了与问题陈述有些相关的 github 存储库，并将其像某种最先进的产品一样出售。我同意这种技能在工业中更重要，但为什么将这些黑客马拉松命名为“机器学习”呢？或“AI”黑客马拉松？最好将其命名为“卖给我一些垃圾”。 对于真正想在有限的时间限制内开发好产品、工作模型以及喜欢竞争的人（像我一样）的人来说，唯一的选择是在线参与或在“数据”中竞赛。    由   提交 /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cficmp/you_need_everything_other_than_ml_to_win_a_ml/</guid>
      <pubDate>Sun, 28 Apr 2024 21:56:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 RETRO 不是法学硕士中的主流/最先进的技术？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cffgkt/d_why_isnt_retro_mainstream_stateoftheart_within/</link>
      <description><![CDATA[2021 年，Deepmind 发布了通过检索数万亿个数据来改进语言模型令牌并引入了检索增强型变压器（RETRO）。 RAG 通常涉及通过将相关文档注入上下文来在推理时补充输入标记，而 RETRO 可以在训练和推理期间从外部数据库访问相关嵌入。目标是将推理和知识解耦：通过允许按需查找，模型可以不必记住其权重内的所有事实，而是将能量重新分配给更有影响力的计算。结果非常惊人：RETRO 以减少 25 倍的参数实现了与 GPT-3 相当的性能，并且理论上没有知识截止（只需向检索数据库添加新信息！）。 然而：今天，AFAICT ，大多数主要型号都不包含 RETRO。 LLaMA 和 Mistral 当然不会，而且我也不觉得 GPT 或 Claude 会这样做（唯一可能的例外是 Gemini，因为 RETRO 团队的大部分成员现在都是 Gemini 团队的一部分，而且它根据我的经验，更快、更实时）。此外，尽管 RAG 一直很热门，并且有人可能认为教育部能够实现它，但作为一种研究向量，明确地解耦推理和知识一直相对安静。 有人对为什么会这样有一个自信的解释吗？我觉得 RETRO 的这一伟大而高效的前沿进步就在眼前，等待着广泛采用，但也许我错过了一些明显的东西。   由   提交/u/whitetwentyset  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cffgkt/d_why_isnt_retro_mainstream_stateoftheart_within/</guid>
      <pubDate>Sun, 28 Apr 2024 19:58:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>