<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sat, 12 Apr 2025 01:20:22 GMT</lastBuildDate>
    <item>
      <title>分类数据集[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jx5816/classification_datasets_r/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  那里有哪些最佳分类数据集 - 具有许多分类功能？理想情况下，基于现实世界数据的数据集。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/singereast1469     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jx5816/classification_datasets_r/</guid>
      <pubDate>Sat, 12 Apr 2025 00:45:59 GMT</pubDate>
    </item>
    <item>
      <title>[d]添加新的词汇令牌 +微调LLMS以遵循说明是无效的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jx3zy0/d_adding_new_vocab_tokens_finetuning_llms_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在尝试使用指令llms​​和vlms，既可以将新的专用令牌添加到其相应的令牌/处理器中，否则或不将其添加。设置是典型的：掩盖说明/提示（仅参加响应/答案）并应用CE损失。但是，没有什么特别的标准SFT。 但是，我观察到了使用其基本令牌/处理器训练的模型与经过修改的令牌训练的模型，对此有更好的验证损失和输出质量...对此有任何想法吗？  （我的hunch：很难增加这些新添加的令牌的可能性，而模型根本无法正确学习）。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jx3zy0/d_adding_new_vocab_vocab_tokens_finetuning_llms_to/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jx3zy0/d_adding_new_vocab_vocab_tokens_finetuning_llms_to/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jx3zy0/d_adding_new_vocab_tokens_finetuning_llms_to/</guid>
      <pubDate>Fri, 11 Apr 2025 23:42:34 GMT</pubDate>
    </item>
    <item>
      <title>[D]用于产品标题和类别标准化的微调BART  - 仍然不够准确，任何更好的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jwz2k3/d_finetuned_bart_for_product_title_category/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我正在建立一个来自摩尔多瓦各种在线商店产品的价格比较网站。我在约20,000个手动标准化产品标题的自定义数据集上微调了一个BART模型，并损失了0.013。 I also trained a separate model for predicting product categories. Unfortunately, the results are still not reliable — the model struggles with both product title normalization and category assignment, especially when product names have slight variations or extra keywords. I don’t have access to SKU numbers from the websites, so matching must be done purely on text. Is there a better approach or model I might be missing?或者也许是专门针对此类问题设计的工具/应用程序？ 预先感谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mali5k     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jwz2k3/d_finetuned_bart_for_for_for_for_product_title_category/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jwz2k3/d_finetuned_bart_for_product_title_category/</guid>
      <pubDate>Fri, 11 Apr 2025 19:59:31 GMT</pubDate>
    </item>
    <item>
      <title>[P]我们为LLM建立了类似OS的运行时间 - 好奇是否有人在做类似的事情？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jwxght/pwe_built_an_oslike_runtime_for_llms_curious_if/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，我们正在尝试使用AI本地运行时，该运行时间在2-5秒钟内以llms（例如13b – 65b）来捕捉llms（例如13b – 65b），并且动态运行50多个型号，每gpu始终在记忆中始终居住在ersign中，而不是传统的prial。 GPU执行 +内存状态和点播模型。这似乎解锁了：•实际的无服务器行为（无空闲成本）•低潜伏期时的多模型编排•更好地使用代理工作负载的GPU利用率 是否有人尝试过与多模型堆栈，代理工作流程或动态内存真实分配相似的东西很想听听别人如何接近这一点的 - 或者这甚至与您的中世纪需求保持一致。 很乐意在有用的情况下分享更多的技术细节！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jwxght/pwe_built_an_oslike_runtime_for_for_for_for_for_llms_curious_if/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jwxght/pwe_built_an_oslike_runtime_for_for_for_llms_curious_curious_if/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jwxght/pwe_built_an_oslike_runtime_for_llms_curious_if/</guid>
      <pubDate>Fri, 11 Apr 2025 18:50:35 GMT</pubDate>
    </item>
    <item>
      <title>[P]每gpu的13b+ llms+ 50+型号的冷 -  2s的速度开始 - 好奇其他人如何应对编排？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jww7nn/p_sub2s_cold_starts_for_13b_llms_50_models_per/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，我们正在尝试使用AI本地运行时，该运行时间在2-5秒钟内以llms（例如13b – 65b）来捕捉llms（例如13b – 65b），并且动态运行50多个型号，每gpu始终在记忆中始终居住在ersign中，而不是传统的prial。 GPU执行 +内存状态和点播模型。这似乎解锁了：•实际的无服务器行为（无空闲成本）•低潜伏期时的多模型编排•更好地使用代理工作负载的GPU利用率 是否有人尝试过与多模型堆栈，代理工作流程或动态内存真实分配相似的东西很想听听别人如何接近这一点的 - 或者这甚至与您的中世纪需求保持一致。 很乐意在有用的情况下分享更多的技术细节！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jww7nn/p_sub2s_cold_cold_starts_for_13b_for_13b_50_50_models_per/”  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jww7nn/p_sub2s_cold_cold_starts_for_13b_13b_llms_50_50_models_models_models_per/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jww7nn/p_sub2s_cold_starts_for_13b_llms_50_models_per/</guid>
      <pubDate>Fri, 11 Apr 2025 17:58:33 GMT</pubDate>
    </item>
    <item>
      <title>[项目]我创建了您可能想使用的农作物生成器。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jwv8qp/project_i_created_a_crop_generator_that_you_might/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我创建了一个基于python的作物生成器，可以帮助我使用图像数据集。   我正在培训SDXL模型以识别功能和概念，我只是找不到快速的工具（或者不足以寻找它）。 我的特定用例是，我的图像很大，有些图像很小，我需要选择特定的功能，有些功能很小，有些是我创建了一个特定的图像，当我创建了一个特定的特定功能 当然，您需要先用所有边界盒创建JSONL文件，而且我已经拥有了较轻的HTML脚本，但是现在我没有时间来使用它，我可以确定它可以使用它，我可以使用它可以更新，我可以更新pp。培训，refork，建议更改等。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/neocorps     [links]     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jwv8qp/project_i_created_a_crop_generator_that_that_you_might/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jwv8qp/project_i_created_a_crop_generator_that_you_might/</guid>
      <pubDate>Fri, 11 Apr 2025 17:17:49 GMT</pubDate>
    </item>
    <item>
      <title>[d]寻找一个支持其他语言的良好语音交互式模型（非cascading）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jwt68o/d_looking_for_a_good_speechtospeech_interactive/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我正在探索语音到语音的交互式模型，并想检查是否有任何现有解决方案：  可以对其他（非英语）语言进行微调或适用于其他任何模型，或者与其他人相处均可进行过研究或进行过研究吗？任何建议，见解或基准测试都会有所帮助。 预先感谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/martian7r     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jwt68o/d_looking_for_a_good_speechtospeech_interactive/</guid>
      <pubDate>Fri, 11 Apr 2025 15:51:35 GMT</pubDate>
    </item>
    <item>
      <title>[P]一种轻巧的开源模型，用于产生漫画</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jws42t/p_a_lightweight_opensource_model_for_generating/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jws42t/p_a_lightweight_opensource_model_for_generating/</guid>
      <pubDate>Fri, 11 Apr 2025 15:06:32 GMT</pubDate>
    </item>
    <item>
      <title>[P]建立时间序列的分类器预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jwpgov/p_building_a_classifier_for_time_series/</link>
      <description><![CDATA[Hey everyone! I want to build a classifier that can automatically select the best forecasting model for a given univariate time series, based on which one results in the lowest MAPE (Mean Absolute Percentage Error). Does anyone have suggestions or experience on how to approach this kind of问题？ 我需要一个大学项目，我似乎不了解它。谁能将我指向正确的方向？但是，如何训练一个基于Mape的分类器。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/boysenberrylocal5576      [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jwpgov/p_building_a_classifier_for_time_series/</guid>
      <pubDate>Fri, 11 Apr 2025 13:09:00 GMT</pubDate>
    </item>
    <item>
      <title>[d]有没有与GRF（Google Research Football）环境合作的经验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jwp3iv/d_anyone_having_experience_working_with_grf/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在与GRF合作时基本上面临着严重的问题。我想知道是否有人经验丰富，可以指导我通过它们。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us anonymous_life17     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jwp3iv/d_anyone_having_experience_working_with_grf/</guid>
      <pubDate>Fri, 11 Apr 2025 12:51:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] B200 vs H100基准：早期测试显示高达57％的训练吞吐量和自我托管成本分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jw3b9b/p_b200_vs_h100_benchmarks_early_tests_show_up_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们在Lightly AI最近在欧洲早期访问了NVIDIA B200 GPU，并进行了一些独立的基准测试，将它们与H100相比，重点是计算机视觉模型培训工作量。 We wanted to share the key results as they might be relevant for hardware planning and cost modeling. TL;DR / Key Findings:  Training Performance: Observed up to 57% higher training throughput with the B200 compared to the H100 on the specific CV tasks we tested. Cost透视图（自主）：我们的分析表明，与典型的云H100实例相比，自托管B200可以提供明显较低的OPEX/GPU/小时（我们发现潜在的范围 〜6x-30x便宜，帖子中的详细信息/假设）。 This obviously depends heavily on utilization, energy costs, and amortization. Setup: All tests were conducted on our own hardware cluster hosted at GreenMountain, a data center running on 100% renewable energy.  The full blog post contains more details on the specific models trained, batch sizes, methodology, performance charts, and a breakdown of the cost注意事项：  我们认为，比较新一代的这些早期的现实世界数字可能对社区有用。很高兴在评论中讨论与新硬件的方法，结果或我们的经验！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/igorsusmelj     [link]         &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jw3b9b/p_b200_vs_h100_h100_benchmarks_early_early_tests_show_show_show_show_up_up_to/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jw3b9b/p_b200_vs_h100_benchmarks_early_tests_show_up_to/</guid>
      <pubDate>Thu, 10 Apr 2025 17:18:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] llms的斜率取证工具包：计算代表性的词汇和相似性树</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jw1i4b/p_a_slop_forensics_toolkit_for_llms_computing/</link>
      <description><![CDATA[     &lt;！ -  sc_off-&gt;  在llm slop周围释放一些工具（过多代表的单词＆amp; ephrases）。 它使用样式分析来表达重复词＆amp＆amp＆amp;与人写作相比，在LLM输出中更常见的n-gram。 还借用了一些生物信息学工具来从这些斜率轮廓中推断出相似性树，从而将词汇特征的存在/不存在为“突变”推断关系。   - 计算a slop个人资料;代表性过多的单词＆amp;模型的短语   - 使用生物信息学工具推断相似性树   - 构建规范斜率短语列表  github repo： https://github.com/sam-paech/slop-forensics    笔记本： https://colab.research.google.com/drive/1sqfnhs4wh87yr8fzqppscobl5h5mms8e6?usp = sharing    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/_sqrkl      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jw1i4b/p_a_slop_slop_slop_slop_slop_forensics_toolkit_toolkit_for_for_computing/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jw1i4b/p_a_slop_forensics_toolkit_for_llms_computing/</guid>
      <pubDate>Thu, 10 Apr 2025 16:02:50 GMT</pubDate>
    </item>
    <item>
      <title>[d] Yann Lecun自动回归LLM注定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jvrk68/d_yann_lecun_autoregressive_llms_are_doomed/</link>
      <description><![CDATA[    src =“ https://b.thumbs.redditmedia.com/0sfsfswahoatmrgchebcapl32wvymuh907cpgd1ccokoq.jpg” title =“ [d] class =“ md”&gt;    不确定还有谁同意，但我认为Yann Lecun在这里提出了一个有趣的观点。好奇地听到有关此的其他意见！ 讲座链接： https://wwwww.youtube.com/watch?v= = etzf = eetzfkkkv6v6v7yy /u/hiskuu     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jvrk68/d_yann_lecun_autoregressive_llms_are_doomed/</guid>
      <pubDate>Thu, 10 Apr 2025 06:44:27 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jpdo7y/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</guid>
      <pubDate>Wed, 02 Apr 2025 02:15:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_be_hired/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Mon, 31 Mar 2025 02:30:37 GMT</pubDate>
    </item>
    </channel>
</rss>