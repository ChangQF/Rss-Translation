<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 25 Jun 2024 18:19:59 GMT</lastBuildDate>
    <item>
      <title>[讨论] 最好的支持API的在线模拟器是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dobvnt/discussion_whats_the_best_apisupported_online/</link>
      <description><![CDATA[大家好，我从事金融/会计工作，我和同事打赌。 这个帖子/问题相对简单，可能适合新手，但我相信它可能会带来一些有趣的东西（尽管无害）。 我当时正在考虑 - 纯粹作为一项实验 - 在模拟器内启动一个自动化/人工智能支持的个人在线投资组合（不涉及真金白银）。我们的想法是不断测试它并随着时间的推移不断改进它并记下结果。 与同事的赌注涉及我自己测试人工智能在网上交易方面是否适用于普通人（即使回报相对较低且风险规避程度较高）。他认为不能。我相信，如果目标设得足够低，机器学习就足以至少稍微击败市场。 为此，我想以这种方式构建实验：  查找在线模拟器 自己编写代码以使其自动化 使用 AI 构建和更新投资组合，做出选择，何时/持有/出售什么等。 主要训练它进行短期  我的问题如下：  根据此描述，哪个是最佳在线模拟器？ 哪个是用于此任务的最佳 AI 工具？ 您对如何更好地构建它有什么建议吗？  提前谢谢您！    由   提交  /u/FlowObjective7264   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dobvnt/discussion_whats_the_best_apisupported_online/</guid>
      <pubDate>Tue, 25 Jun 2024 17:39:57 GMT</pubDate>
    </item>
    <item>
      <title>根据历史预测事件时间的最佳技术[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do9ur6/best_technique_to_predict_the_timing_of_an_event/</link>
      <description><![CDATA[我有多个送货的历史数据，这些送货在一天中的不同时间点进行。送货可能会延迟或提前，具体取决于当月的日期。例如，送货可能会在每月的第一个工作日提前进行，而在月底则明显延迟。 我有过去 6 个月的数据，最好的可用模型是什么，以便我可以使用过去的数据并预测当天的送货时间。我也希望根据当前日期定期对模型进行反馈。[D]    提交人    /u/Dhinakharan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do9ur6/best_technique_to_predict_the_timing_of_an_event/</guid>
      <pubDate>Tue, 25 Jun 2024 16:14:09 GMT</pubDate>
    </item>
    <item>
      <title>[N] ESM3：用语言模型模拟 5 亿年的进化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do91g9/n_esm3_simulating_500_million_years_of_evolution/</link>
      <description><![CDATA[博客文章：https://www.evolutionaryscale.ai/blog/esm3-release 预印本（待批准）：https://evolutionaryscale-public.s3.us-east-2.amazonaws.com/research/esm3.pdf 摘要：  超过三十亿年的进化产生了编码到天然蛋白质空间中的生物学图像。在这里，我们展示了在进化产生的标记上训练的语言模型可以充当进化模拟器，以生成远离已知蛋白质的功能性蛋白质。我们提出了 ESM3，这是一种前沿的多模态生成语言模型，可以推理蛋白质的序列、结构和功能。ESM3 可以遵循结合其模态的复杂提示，并且对生物比对反应灵敏。我们已经促使 ESM3 生成具有思维链的荧光蛋白。在我们合成的几代中，我们发现了一种明亮的荧光蛋白，与已知的荧光蛋白相距很远（58% 相同）。同样遥远的天然荧光蛋白被五亿多年的进化所隔开  EvolutionaryScale 在剥离 Meta 后首次发布了重大版本。  权重和代码已发布，但有重大警告 来自 HuggingFace： https://www.evolutionaryscale.ai/legal/community-license-agreement 总体情况： EvolutionaryScale AI 模型仅根据本社区许可协议供个人或非商业组织用于非商业用途。您不得将 EvolutionaryScale AI 模型或 EvolutionaryScale AI 模型的任何衍生作品或其输出用于： a. 与任何商业活动有关，例如 b. 开发任何产品或服务，例如在 API 后面托管 AI 模型；或 c. 与药物开发有关；或 d.而不归属于 EvolutionaryScale 和本社区许可协议；或者 例如，训练任何其他大型语言模型、任何用于蛋白质表示学习或蛋白质生成的技术或任何其他类似于 EvolutionaryScale 的 AI 模型的 AI 驱动的第三方模型，即使用于非商业用途。 您可以根据社区许可协议发布、共享和调整 EvolutionaryScale AI 模型及其输出用于非商业目的    提交人    /u/TeamArrow   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do91g9/n_esm3_simulating_500_million_years_of_evolution/</guid>
      <pubDate>Tue, 25 Jun 2024 15:40:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR与AISTATS之间的区别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do796a/d_difference_between_iclr_and_aistats/</link>
      <description><![CDATA[这里有一个重复的问题，但我想再次提出这个话题，因为九月/十月的截止日期即将到来，现在情况可能已经发生了变化。 三大 ML 会议是 ICML/NeurIPS/ICLR，它们将一年分为 3 个截止日期。然而，AISTATS 也享有良好的声誉。 ICLR 和 AISTATS 的截止日期非常接近，因此许多人不得不决定将自己的工作提交给哪个。 由于深度学习 (DL) 的流行，ICLR 迅速崛起，但现在人们似乎将其与 ICML/NeurIPS 等同对待，那里似乎有相当多的非 DL 和理论 ML 论文。 问题：对于纯经验性的 DL 论文，将它们提交给 ICLR 似乎是理所当然的。那么 (1) 具有更多理论结果的 ML 论文，或 (2) 没有 DL（例如统计 ML）的 ML 论文呢？ 将这些作品提交给 ICLR 和 AISTATS 的利弊是什么？ 需要考虑的一些方面：  对于这些类型的工作，AISTATS 是否会降低声望或受到 ML 社区的较少关注？ 向 ICLR 提交理论作品的体验如何？（例如，那里的审稿人会要求进行许多实验吗？） 行业/学术界对 ICLR 是否更重要，或者对 ICLR 和 AISTATS 的待遇相同（对于更多理论性作品）？  免责声明：请不要再说“作品本身比出版地点更重要”，这显然是正确的，但并没有太多帮助。    提交人    /u/zy415   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do796a/d_difference_between_iclr_and_aistats/</guid>
      <pubDate>Tue, 25 Jun 2024 14:24:15 GMT</pubDate>
    </item>
    <item>
      <title>[N] 探索苹果如何优化设备内置 AI 技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do4xrw/n_exploring_how_apple_might_optimize_techniques/</link>
      <description><![CDATA[大家好！在论坛上就 Apple 可能在优化设备上 AI 技术方面所做的技术进行了很好的讨论之后。我们讨论了创新方法及其实际应用。 对于那些感兴趣的人，这里有一篇详细的文章，总结了要点并探讨了 Apple 可能用来直接在设备上增强 AI 功能的可能技术：探索 Apple 如何优化设备上 AI 的技术    提交人    /u/BriefAd4761   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do4xrw/n_exploring_how_apple_might_optimize_techniques/</guid>
      <pubDate>Tue, 25 Jun 2024 12:36:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 LlamaIndex 索引进行 OS 海量文档分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do4ujr/p_os_mass_document_analytics_with_llamaindex_index/</link>
      <description><![CDATA[      大家好，我与大家分享我的最新开源项目，用于在大量文档中进行海量数据提取和问答。您可以将目标数据模式定义为 pydantic 模型或 python 基元。布局元素和人工注释会自动嵌入并作为 LlamaIndex VectorStore 进行访问。如果您编写自定义 LlamaIndex 问答管道，它们将显示在前端并可应用于语料库。 我已经在 OpenContracts 上工作多年了。虽然它最初是一种标记和注释文档的工具，但由于 LLM 和矢量数据库的最新进展，我发布了一个新版本，其中包含许多很酷的功能，可以使用 LLM、矢量搜索和 AI 代理。它基于 Django，随着时间的推移，Django 变得越来越强大，这让我感到惊讶！ 主要功能：  管理文档 - 管理文档集合 布局解析器 - 自动从 PDF 中提取布局特征 自动矢量嵌入 - 为上传的 PDF 和提取的布局块生成 可插入式微服务分析器架构 - 让您分析文档并自动对其进行注释 人工注释界面 - 手动注释文档，包括多页注释。 LlamaIndex 集成 - 使用我们的矢量存储（由 pgvector 提供支持）和任何手动或自动注释的功能让 LLM 智能地回答问题。 数据提取 - 使用复杂的 LLM 支持的查询在数百个文档中提出多个问题行为。我们的示例实现使用 LlamaIndex + Marvin。 自定义数据提取 - 自定义数据提取管道可用于前端批量查询文档。  查看 repo 或文档！    提交人    /u/TallTahawus   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do4ujr/p_os_mass_document_analytics_with_llamaindex_index/</guid>
      <pubDate>Tue, 25 Jun 2024 12:31:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据产品的 Medallion 方法：超越承诺的“黄金”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do4pfq/d_medallion_approach_to_data_products_beyond_the/</link>
      <description><![CDATA[值得信赖并不意味着经过认证：数据网格中不同程度的信任 在本文中，我们的客座作者 Francesco De Cassai 试图阐明关于数据资产被视为数据产品的信任程度的争论。在这篇富有洞察力的文章中，他谈到了：  “信任”的基本原理：可发现、可寻址、值得信赖、安全、可互操作和自我描述 不同程度的可信度 统治一切的数据政策  在文章中获得有关这些相关方面的详细观点和解释。  在此处阅读完整文章：https://moderndata101.substack.com/p/medallion-approach-to-data-products    提交人    /u/growth_man   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do4pfq/d_medallion_approach_to_data_products_beyond_the/</guid>
      <pubDate>Tue, 25 Jun 2024 12:24:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 需要帮助理解这篇论文。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do44r5/r_need_help_in_understanding_this_paper/</link>
      <description><![CDATA[我正在尝试理解论文“Instacart 的基于嵌入的杂货搜索模型”。我理解了预热和级联数据集的原因。我不明白共享编码器和双塔模型之间的区别。假设我有正的 &lt;query, product&gt; 匹配。它是如何训练并与负匹配进行比较的。有人可以建议如何重新创建这篇论文吗？ 处理 img i47q4rpxan8d1...    提交人    /u/Legitimate_Celery_69   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do44r5/r_need_help_in_understanding_this_paper/</guid>
      <pubDate>Tue, 25 Jun 2024 11:52:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我对 GPT-2 和 BERT 进行了 135,000 次微调，以查看使用测试集中未标记的文本进行预训练是否公平</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do2g03/r_i_finetuned_gpt2_and_bert_135000_times_to_see/</link>
      <description><![CDATA[      TL;DR：似乎很公平。 每个人都知道，如果您想使用标记的测试数据进行评估，则对其进行训练是大忌。 但是，如果您对未标记的测试数据进行预训练，那么您仍然可以在评估期间使用这些数据吗？ 让我们对 25 个文本分类数据集、两个 LM（我们非常确定其预训练数据尚未受到污染）以及一些训练和测试观察数量的设置进行实验。 对于每个数据集，实验健全性检查对未标记文本（独立于测试集）进行预训练是否有帮助，即是否有效果可检测。称之为预训练提升。接下来，实验评估了使用测试集中的未标记文本（而不是未标记的独立文本）进行预训练的偏差。 将此称为评估偏差。 结果 ​ m=50 基于真实世界带注释的少量样本任务 (RAFT) 基准（https://arxiv.org/abs/2109.14076），该基准也包含了这个问题的灵感：“对于每个任务，我们发布一个包含 50 个示例的公共训练集和一个更大的未标记测试集。我们鼓励对未标记的示例进行无监督预训练……”。上面的分布是边际效应的分布：对 2 个 LM 类型、25 个分类任务及其子样本取平均值。 在这里，将“少数”的含义延伸到少样本中。我想看看结果会如何变化。还是一样。 平均而言，在每种情况下，对未标记的文本进行预训练显然都是有益的。尽管如此，没有证据表明存在不公平现象。评估偏差在 0 附近波动，并且微不足道。在任务级别，结果是一致的：在 25 项任务中，除了 2 项之外，预训练对所有任务都有好处，其中 12 项的评估偏差为正，13 项为负，绝对值始终小于 1%。 元分析 我还想看看 GPT-2 和 BERT 微调的少量基准测试有多稳定（不稳定）。在上面的实验中，通过从每个数据集中抽取最多 100 个子样本来揭示这种差异。（这种技术复制是标题中 135k 这个数字的原因。）如果实验只取一个子样本会怎样？这就是大多数小样本基准测试的有效做法。 事实证明，如果我们对 25 个数据集中的每个数据集抽样 500 个未标记文本、100 个分类示例和 500 个评估示例，则实验报告不可忽略的正偏差或负偏差的可能性为 47%，而不是我们从重复子样本中发现的接近 0 的偏差。从粗略的意义上讲，包括 25 个数据集（每个数据集有 1.1k 个观测值）似乎有很多数据。实际上，这并不比抛硬币好。 如今，人们对差异的认识越来越深刻（例如，https://arxiv.org/abs/2406.10229）。而且，与参数高效或基于提示的 LLM 方法相比，对 GPT-2 或 BERT 进行微调可能更不稳定。但我对在我的少样本研究中看到这种程度的不稳定感到很惊讶。 代码、数据、论文 以下是用于重现实验和分析的所有代码和数据，以及论文链接：https://github.com/kddubey/pretrain-on-test    提交人    /u/KD_A   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do2g03/r_i_finetuned_gpt2_and_bert_135000_times_to_see/</guid>
      <pubDate>Tue, 25 Jun 2024 10:07:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如今，亚马逊和沃尔玛等电子商务公司如何产生互补推荐（或经常一起购买）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnwfis/d_how_do_ecomm_companies_like_amazon_and_walmart/</link>
      <description><![CDATA[我最近开始研究推荐系统。我知道过去是使用一些统计算法（如 FP-Growth 和 Prod2Vec）来实现的。    提交人    /u/Abs0lute_Jeer0   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnwfis/d_how_do_ecomm_companies_like_amazon_and_walmart/</guid>
      <pubDate>Tue, 25 Jun 2024 03:30:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 成绩评分：量化 LLM 在选项选择方面的表现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnpsap/r_grade_score_quantifying_llm_performance_in/</link>
      <description><![CDATA[  由    /u/FutureIsMine  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnpsap/r_grade_score_quantifying_llm_performance_in/</guid>
      <pubDate>Mon, 24 Jun 2024 22:03:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 为什么关于时间序列预测的联邦学习的高质量作品很少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnnlpm/r_why_there_are_few_highquality_works_about/</link>
      <description><![CDATA[我即将开始实习，我的导师要求我针对时间序列预测进行一些联邦学习方面的研究。与 cv 和 nlp 等其他任务相比，我发现来自高排名会议/期刊的高质量论文非常少。有人知道原因吗？主要的挑战是什么？    提交人    /u/by0724   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnnlpm/r_why_there_are_few_highquality_works_about/</guid>
      <pubDate>Mon, 24 Jun 2024 20:31:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 模型合并——您的看法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnm1m0/d_model_merging_whats_your_take/</link>
      <description><![CDATA[我一直在阅读有关模型合并及其可实现的出色性能的文章。我喜欢任务算法之类的方法，但 TIES 和 DARE 似乎更受欢迎。同时，其中一些解决方案似乎非常具有启发性。 您的看法是什么？有直接经验吗？我猜没有采用批判性观点的调查/教程，但如果你知道，请链接它。    提交人    /u/gized00   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnm1m0/d_model_merging_whats_your_take/</guid>
      <pubDate>Mon, 24 Jun 2024 19:27:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些大学和研究中心专注于对抗性机器学习（尤其是在德国）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dnctew/d_which_universities_and_research_centers_are/</link>
      <description><![CDATA[大家好，我很好奇对抗性学习的核心研究进展。查看出版物，我确实看到了来自不同组织的几篇论文，但很少看到一个组织宣传他们专注于对抗性学习领域。特别是德国的大学和研究所。    提交人    /u/i_sanitize_my_hands   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dnctew/d_which_universities_and_research_centers_are/</guid>
      <pubDate>Mon, 24 Jun 2024 12:56:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>