<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 29 Dec 2023 18:16:10 GMT</lastBuildDate>
    <item>
      <title>[R] Unified-IO 2：利用视觉、语言、音频和动作扩展自回归多模态模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ts6eh/r_unifiedio_2_scaling_autoregressive_multimodal/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.17172 代码：https ://github.com/allenai/unified-io-2 项目页面：https://unified-io-2.allenai.org/ 摘要：  我们推出了Unified-IO 2，这是第一个能够理解和生成图像、文本、音频和动作的自回归多模态模型。为了统一不同的模态，我们将输入和输出（图像、文本、音频、动作、边界框等）标记化到共享语义空间中，然后使用单个编码器-解码器转换器模型对其进行处理。由于采用如此多样化的模式进行训练具有挑战性，因此我们提出了各种架构改进来稳定模型训练。我们在来自不同来源的大型多模态预训练语料库上从头开始训练我们的模型，并采用多模态混合降噪器目标。为了学习一系列广泛的技能，例如遵循多模式指令，我们在包含提示和增强的 120 个数据集上构建和微调。凭借单一统一模型，Unified-IO 2 在 GRIT 基准测试中实现了最先进的性能，并在超过 35 个基准测试中取得了优异的成绩，包括图像生成和理解、自然语言理解、视频和音频理解以及机器人操作。我们向研究社区发布了所有模型。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ts6eh/r_unifiedio_2_scaling_autoregressive_multimodal/</guid>
      <pubDate>Fri, 29 Dec 2023 17:19:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于强化学习的路径规划</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18trzt8/d_rl_based_pathplanning/</link>
      <description><![CDATA[嘿伙计们。我刚刚将 2D 体育馆环境迁移到较新的体育馆，用于训练 DRL 代理来解决路径规划问题。以下是 GitHub 页面的 URL：https://github.com/harisankar95/voxelgym2D  I我很高兴知道您是否有任何对我有用的建议或意见。   由   提交/u/harisankar95   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18trzt8/d_rl_based_pathplanning/</guid>
      <pubDate>Fri, 29 Dec 2023 17:11:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] Fullmetal：ChatGPT API 的自托管替代品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tqs54/p_fullmetal_selfhosted_alternative_to_chatgpt_api/</link>
      <description><![CDATA[      节日快乐 r/MachineLearning！ ​ Fullmetal 使自托管开源法学硕士闪电般快速。自托管100%免费，并且提示和提示响应是双向加密的。 ​ 我只是希望这个项目对这里的一些人有帮助，特别是那些：  需要 ChatGPT API，但不信任 OpenAI 需要定制/比 ChatGPT 限制更少的 LLM 需要一个可扩展、负载平衡的开源 LLM 解决方案.  ​ 所有这些，我可能是完全错误的，我将不胜感激任何反馈！ 谢谢. ​ 用于托管 LLM 的仪表板。大约需要 5 分钟 ​ 内置负载均衡   由   提交 /u/m0dE   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tqs54/p_fullmetal_selfhosted_alternative_to_chatgpt_api/</guid>
      <pubDate>Fri, 29 Dec 2023 16:18:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当今领先的人工智能研究人员中有哪些也有哲学兴趣？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tqlq0/d_who_are_some_of_todays_leading_ai_researchers/</link>
      <description><![CDATA[随着人工智能的不断发展，考虑这项技术的哲学含义变得越来越重要。有哪些领先的人工智能研究人员正在对人工智能现象进行哲学思考？我专门寻找哲学反思，而不是对人工智能的一般思考，如果可能的话，寻找对人工智能伦理和政治以外的主题的反思。例如，Jürgen Schmidhuber 或 Marcus Hutter 等研究人员就符合要求。谢谢！   由   提交/u/catatojreon  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tqlq0/d_who_are_some_of_todays_leading_ai_researchers/</guid>
      <pubDate>Fri, 29 Dec 2023 16:10:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 神经常微分方程：有没有办法快速运行？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18toyq9/d_neural_odes_is_there_a_way_to_run_it_fast/</link>
      <description><![CDATA[在我之前的问题之后：[D] torch.odeint（ODE 求解器）执行速度慢的解决方案：MachineLearning (reddit.com)，我想我需要问一个更广泛的问题。 今天，大多数神经网络使用 GPU 或针对快速并行性进行优化的硬件进行训练。然而，对于神经 ODE 模型（y&#39;=f(y)，其中 f 是神经网络），我们需要数值求解，这本质上是逐步的。人们已经找到了使用多线程来集成此类 ODE 的聪明方法，但在任何情况下性能都不会随内核数量线性扩展。 因此，对于神经 ODE 来说，经常会发生以下情况：我们受到单核性能的限制。 此外，如果我们对 1000000 个时间步进行数值积分，那么神经网络中就会突然增加 1000000 个层，使梯度计算成为一场噩梦。 &lt; p&gt;人们有什么聪明的想法来解决这个问题吗？   由   提交 /u/speedy-spade   /u/speedy-spade  reddit.com/r/MachineLearning/comments/18toyq9/d_neural_odes_is_there_a_way_to_run_it_fast/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18toyq9/d_neural_odes_is_there_a_way_to_run_it_fast/</guid>
      <pubDate>Fri, 29 Dec 2023 14:58:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是一个糟糕的职业举动吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tnth2/d_is_this_a_bad_career_move/</link>
      <description><![CDATA[我是一名 28 岁的哥伦比亚工程师，在 ML 领域拥有超过 6 年的经验。  我一直非常致力于学习，我以最高荣誉获得了硕士学位和学士学位。事实上，我的硕士学位是由 Deepmind 在哥伦比亚顶尖大学全额资助的。  我真的很喜欢我的硕士学位，我喜欢学习机器学习背后的理论并与我的顾问一起进行研究。我们一起在《自然科学数据》上发表了一篇数据集论文，在 ICLR 2023 上发表了一篇研讨会论文。我们还有几篇出版物希望很快发表。 （尽管我没有参加任何项目，但我正在与他们一起工作） 我四月份毕业，一直在一家大型银行工作。我的薪水很高，每年大约5万美元。这在哥伦比亚很多。可悲的是，我并不快乐，我发现我的工作非常无聊。基本上我是一名及时的工程师，他花了很多时间在会议上，而我什至不说话。我的同事们都很爱我，我很敬业，甚至我对自己的工作有这样的感觉感到很难过，但我只是觉得我没有运用我在硕士期间学到的所有知识。  我考虑过在美国申请研究工程职位，但我没有得到一次面试机会。这让我感到很沮丧，相信我，我在学习上付出了很大的努力。  我正在考虑在美国申请博士学位。希望有 J1 签证，这样我女朋友就可以在那里工作。我知道母国要求两年，我也知道博士学位需要4-6年的大量工作努力和低薪。然而，我真的很喜欢做研究和学习！我对这个领域充满热情，我希望从长远来看，博士学位对我的职业生涯有好处。  我错了吗？这是一个糟糕的职业变动吗？   由   提交/u/ManuelRios18  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tnth2/d_is_this_a_bad_career_move/</guid>
      <pubDate>Fri, 29 Dec 2023 14:03:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最佳法学硕士费用计算器，分享您的最爱！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tmql1/d_best_llms_cost_calculator_share_your_favourite/</link>
      <description><![CDATA[正在寻找法学硕士成本计算器、托管云选项。我希望看到的功能： -可用的主要提供商（OpenAI、Google 等） -标准调用、微调模型、嵌入的成本估算。 -文本和多模式（尤其是视觉模型） -训练和推理估计。 -估计具有用户定义的要使用的文本/令牌数量、API 数量电话等。 请分享您最喜欢的！   由   提交 /u/lorepieri   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tmql1/d_best_llms_cost_calculator_share_your_favourite/</guid>
      <pubDate>Fri, 29 Dec 2023 13:06:53 GMT</pubDate>
    </item>
    <item>
      <title>博士单独理论研究有多普遍 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tmbg7/how_common_is_solo_theoretical_research_for_phd_d/</link>
      <description><![CDATA[我是一名最后一年的博士生，从事 ML/RL 理论研究。我通常不会从顾问那里得到任何技术帮助。他只是帮助我从模糊的问题讨论开始，一旦我正确地阐述问题，得到一些结果并开始写论文，他就会在写作过程中提供帮助（主要是非技术方面，如摘要、引言、动机等）&lt; /p&gt; 但我有一位同事，他的顾问提供了更具体的技术帮助。例如，一个非常具体的问题，有一个简单的理论解决方案，有时甚至是最终的解决方案/证明本身。 编写两位作者或多位作者的理论 ML/RL 的典型流程是什么涉及博士生的论文（最好是作为第一作者）？ 学生自己做所有事情吗？或者顾问或一些资深教授是否给出了“主要”内容？解决方案的想法，学生填写证明的详细信息？ 除了实证合作副项目之外，我还有一篇第一作者的理论论文，这完全是我的工作，导师的技术投入为零，所以我喜欢认为我并不愚蠢。 但是，阅读多篇完美的多作者 40 页论文中的每一行书面和未书面的文字，其中充满了证据，看看我是否可以使用他们的技术，这让我的大脑超载😅 欢迎任何评论或轶事。   由   提交 /u/_An_Other_Account_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tmbg7/how_common_is_solo_theoretical_research_for_phd_d/</guid>
      <pubDate>Fri, 29 Dec 2023 12:43:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformers：多项式门控 FFN 优于 SwiGLU，减少了参数数量，同时提高了模型性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tkt3g/d_transformers_polynomial_gated_ffn_is_better/</link>
      <description><![CDATA[根据 GLU 变体改进 Transformers 论文 平均性能最好的门控线性单元是 SwiGLU。 LLAMA 和 PaLM 架构中使用的 GLU 相同。 在我的语言建模实验中，我使用了类似 PaLM 的 SwiGLU FFN： class FFNSwiGLU(nn.Module)： def __init__(self, d_model: int) -&gt;;无： super().__init__() self.fc1 = nn.Linear(d_model, d_model * 4, 偏差=False) self.fc2 = nn.Linear(d_model * 2, d_model, 偏差=False) defforward(self, x: torch.Tensor) -&gt;; torch.Tensor: x1, x2 = self.fc1.forward(x).chunk(2, dim=-1) x = F.silu(x1) * x2 x = self.fc2.forward(x) return x  然后我删除了显式的 silu/swish 非线性和第二个投影矩阵，我简单地做了： class FFNPoly(nn.Module): def __init__( self, d_model: int) -&gt;;无： super().__init__() self.fc = nn.Linear(d_model, d_model * 4,bias=False) defforward(self, x: torch.Tensor) -&gt; torch.Tensor: x1, x2, x3, x4 = self.fc.forward(x).chunk(4, dim=-1) return x1 * x2 + x3 * x4  This使我的模型在相同条件下学习得更快，并且在训练结束时我的困惑度更低。此外，模型现在的参数更少，因为我不需要第二个矩阵将其投影回“d_model”因为每个术语都已经是“d_model”了尺寸。这与双线性门控单元类似，但它只是涉及更多项 - 将两个双线性相互作用相加 - 并且没有偏差项。 我没有解释为什么这在我的情况下效果更好，以及这是否会有效适用于所有模型大小和任务。 我的转换器架构：  旋转位置嵌入 MHA 和 FFN 层的预归一化 RMSNorm 而不是 LayerNorm 无线性偏差  ​ class TransformerBlock(nn.Module) : def __init__(self, d_model: int, n_heads: int): super().__init__() self.ln_mha = RMSNorm(d_model) self.mha = MHARope(d_model, n_heads) self.ln_ffn = RMSNorm(d_model) self. ffn = FFNPoly(d_model) defforward(self, x: torch.Tensor, freqs_cis: torch.Tensor) -&gt;; torch.Tensor: x = x + self.mha.forward(self.ln_mha(x), freqs_cis) x = x + self.ffn.forward(self.ln_ffn(x)) 返回 x    由   提交 /u/alagagbar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tkt3g/d_transformers_polynomial_gated_ffn_is_better/</guid>
      <pubDate>Fri, 29 Dec 2023 11:12:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自适应消息传递（图机器学习）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tjva1/r_adaptive_message_passing_graph_machine_learning/</link>
      <description><![CDATA[捕获远程依赖性对于许多科学领域中复杂系统的正确描述至关重要。然而，深度图网络存在过度平滑、过度挤压和未达标的问题。 本文提出了一种缓解方法它们全部称为自适应消息传递。 博客文章📖：链接 论文⚗️：链接&lt; /a&gt; 作者：F. Errica、H. Christiansen、V. Zaverkin、T. Maruyama、M. Niepert、F. Alesiani 希望您会发现它有用！   由   提交 /u/tuscanresearcher   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tjva1/r_adaptive_message_passing_graph_machine_learning/</guid>
      <pubDate>Fri, 29 Dec 2023 10:10:07 GMT</pubDate>
    </item>
    <item>
      <title>理论机器学习是否应用于工业？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tfhy1/is_theoretical_machine_learning_used_in_industry_d/</link>
      <description><![CDATA[除非是 Google、Microsoft 等大型国家实验室之一。其他地方是否也使用理论机器学习？那些大型国家实验室真的研究过它吗？例如，攻读应用机器学习博士学位或任何更适合工作的领域？   由   提交/u/Best_Ad_4685   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tfhy1/is_theoretical_machine_learning_used_in_industry_d/</guid>
      <pubDate>Fri, 29 Dec 2023 05:34:57 GMT</pubDate>
    </item>
    <item>
      <title>[R][P] Autogen + Langchain Tools + Local LLM 不起作用。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tex1j/rp_autogen_langchain_tools_local_llm_doesnt_work/</link>
      <description><![CDATA[嘿伙计们， 所以我正在使用代理框架 Autogen，并且我尝试通过提供来创建代理它可以自定义使用的工具。这些自定义工具是在 langchain 框架中定义的。此外，我正在使用开源 LLM 模型，如 Mistral、LLAMA、Mixtral 等。 根据我的经验，我无法让 Autogen+LocalLLM 框架根据提示识别要使用的正确工具。然而，它在 GPT 模型上做得非常出色。  请注意，我的目标是让代理强制使用提供的工具，而不是提出自己的代码。代理应该找出正确的工具来使用。  我的提示非常明确，尽管如此，我仍无法使其正常工作。 有什么想法和建议吗？请告诉我 ！也请分享您的经验。干杯！   由   提交/u/perceptron333  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tex1j/rp_autogen_langchain_tools_local_llm_doesnt_work/</guid>
      <pubDate>Fri, 29 Dec 2023 05:03:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] CLadder：评估语言模型因果推理能力的基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18t86kj/r_cladder_a_benchmark_to_assess_causal_reasoning/</link>
      <description><![CDATA[论文。我与作者没有任何关系。 摘要：  执行因果推理的能力被广泛认为是智力的核心特征。在这项工作中，我们研究大型语言模型 (LLM) 是否能够连贯地推理因果关系。自然语言处理（NLP）领域的大部分现有工作都侧重于评估法学硕士中的常识因果推理，因此无法评估模型是否可以根据一组明确定义的形式规则执行因果推理。为了解决这个问题，我们受到“因果推理引擎”的启发，提出了一个新的 NLP 任务，即自然语言中的因果推理。 Judea Pearl 等人提出的假设。我们构建了一个包含 10K 样本的大型数据集 CLadder：基于因果图和查询（关联、干预和反事实）的集合，我们通过预言机因果推理引擎获得符号问题和真实答案。然后将它们翻译成自然语言。我们在数据集上评估了多个法学硕士，并引入并评估了定制的思维链提示策略 CausalCoT。我们表明，我们的任务对于法学硕士来说极具挑战性，我们进行了深入分析，以更深入地了解法学硕士的因果推理能力。    由   提交 /u/Wiskkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18t86kj/r_cladder_a_benchmark_to_assess_causal_reasoning/</guid>
      <pubDate>Thu, 28 Dec 2023 23:39:54 GMT</pubDate>
    </item>
    <item>
      <title>纽约时报起诉 OpenAI 和微软侵犯版权 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18t73v1/new_york_times_sues_openai_and_microsoft_for/</link>
      <description><![CDATA[https://www.theguardian.com/media/2023/dec/27/new-york-times-openai-microsoft-lawsuit 诉讼指控：&lt; em&gt;“被告的 GenAI 工具由包含《纽约时报》内容副本的法学硕士提供支持，可以生成逐字背诵《纽约时报》内容、对其进行仔细总结并模仿其表达风格的输出”。该诉讼要求赔偿数十亿美元，并希望看到这些聊天机器人被摧毁。  我不知道摘要和风格模仿是否属于版权法，但逐字引用就不能被阻止吗？我不久前建议在这个 subreddit 中这样做：  OpenAI 不能简单地检查与训练数据共享长子字符串的输出（也许是概率上的）吗？  您可以简单地将所有训练数据子字符串（固定长度，例如 20 个标记）放入哈希表、布隆过滤器或类似的数据结构中。然后，当法学硕士生成文本时，您可以检查以确保文本不包含数据结构中的任何子字符串。这将防止逐字引用《纽约时报》或其他受版权保护的材料，长度超过 20 个标记（或您选择的任何长度）。将数据结构存储在内存中可能需要将其分布在多台机器上，但我认为 OpenAI 可以轻松负担得起。如果考虑内存问题，您可以通过分隔子字符串来进一步节省内存。   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18t73v1/new_york_times_sues_openai_and_microsoft_for/</guid>
      <pubDate>Thu, 28 Dec 2023 22:53:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>