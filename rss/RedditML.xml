<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 26 Jun 2024 18:18:50 GMT</lastBuildDate>
    <item>
      <title>[D] 关于最佳 Python 时间序列库的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp4y8p/d_thoughts_on_best_python_timeseries_library/</link>
      <description><![CDATA[有许多 Python 库提供当代时间序列模型和数据工具的实现。以下是一份（不完整）列表。希望任何使用过这些（或其他）库的人对其优缺点提供反馈。如果您使用过多个库并且可以提供有见解的比较，则可以获得加分。我正在尝试弄清楚要花时间研究哪一个（些）。非常感谢！  TSA - https://github.com/timeseriesAI/tsai TSLib - https://github.com/thuml/Time-Series-Library AEON - https://github.com/aeon-toolkit/aeon SKTime - https://www.sktime.net/en/stable/ TSLearn - https://tslearn.readthedocs.io/en/stable/ Nixtla - https://github.com/Nixtla/ Pytorch-forcasting - https://pytorch-forecasting.readthedocs.io/en/stable/ DARTS - https://unit8co.github.io/darts/index.html Merlion - https://github.com/salesforce/Merlion     提交人    /u/HorseEgg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp4y8p/d_thoughts_on_best_python_timeseries_library/</guid>
      <pubDate>Wed, 26 Jun 2024 17:54:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于社区的 AI 指南（如 Linux 内核）而不是企业 / 团体 / 政府</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp4ohn/d_community_based_ai_guidelines_like_linux_kernel/</link>
      <description><![CDATA[我使用拥抱脸，发现它真的很好。感谢你们的出色工作。 最近，有人就人工智能治理问题与我联系，并“提醒”我什么是对的，什么是错的。我认真听取了意见。这是一位著名的“人工智能监管者”说的。 该“监管”的问题： 他们说：  如果事件 a、b、c 发生了，并且可能会导致未来的人们不喜欢 x、y、z 组，那么我应该从训练数据中删除这些事件。我说我没有通过添加更多数据等进行操纵。他们只是希望将其完全删除。 如果 STEM 中没有一种性别，那么我应该减少对另一种性别的提及，这样 STEM 中的两种性别看起来都会相同。但我不应该提到同性在学校教师、非 STEM 教师中的占比不成比例。他们辩称，总的来说，这是为了社会利益。  我不同意的原因  真相将被彻底抹去。50 年后，几乎所有东西 - 从搜索引擎到完整的教科书都将依赖于你和我今天训练的模型。因此，如果我操纵这些数据（为了所谓的“公平”），那么后代将永远不会知道事件 a、b、c。  因此，我请求这个社区制定真正公平的指导方针 - 不要把它留给公司/团体，因为他们听起来更诚实，但事实并非如此。    提交人    /u/travelenjoysimple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp4ohn/d_community_based_ai_guidelines_like_linux_kernel/</guid>
      <pubDate>Wed, 26 Jun 2024 17:42:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 仅使用原始 JSON 和图像即可实现 Pokémon 嵌入的超级效果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp43b2/p_the_super_effectiveness_of_pokémon_embeddings/</link>
      <description><![CDATA[许多年前，我制作了 Pokémon 向量，但无法解释所有 Pokémon 元数据。借助 nomic-embed-text-v1.5 和 nomic-embed-vision-v1.5 嵌入模型的一些附加代码，我能够将一团原始 JSON 放入模型中，并且嵌入效果出乎意料地好！ https://minimaxir.com/2024/06/pokemon-embeddings/ 此博客文章的所有代码均可在 GitHub 上开源 获取。    提交人    /u/minimaxir   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp43b2/p_the_super_effectiveness_of_pokémon_embeddings/</guid>
      <pubDate>Wed, 26 Jun 2024 17:18:26 GMT</pubDate>
    </item>
    <item>
      <title>利用数据聚类优化非线性回归[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp39g3/optimized_nonlinear_regression_using_data/</link>
      <description><![CDATA[我正在寻找有关我最近从事的一个项目的反馈。 该应用程序的核心涉及将数据聚类为更小、更易于管理的组。然后，它通过连接每个聚类的平均值形成回归。随后对该初始回归进行优化。 这种方法大大减少了计算时间，使其比传统方法快几个倍。它对于重视训练速度和效率的大规模数据集特别有用。 项目链接：[GitHub Repo]（https://github.com/wStobaugh/CRO） 我非常感谢您的反馈或问题，我对这个领域还很陌生。    提交人    /u/grimriper43345   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp39g3/optimized_nonlinear_regression_using_data/</guid>
      <pubDate>Wed, 26 Jun 2024 16:43:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自然世界中的软件：分层涌现的计算方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp32hw/r_software_in_the_natural_world_a_computational/</link>
      <description><![CDATA[  由    /u/Balance-  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp32hw/r_software_in_the_natural_world_a_computational/</guid>
      <pubDate>Wed, 26 Jun 2024 16:36:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能系统规划和推理研究中的玩具问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp0uzy/d_toy_problems_for_research_in_planning_and/</link>
      <description><![CDATA[哪些问题表面上简单，但需要很强的行动规划能力和“推理”能力？国际象棋和围棋符合描述，但太复杂了。数学证明是推理能力的极好测试，但需要大量的背景知识，而我正在寻找具有简单目标和简单规则的东西。 一个完美的例子是“推箱子”谜题，它在Beyond A* 论文中被用作衡量标准。哪些问题在性质上类似？即使是简单的基于文本或算术的问题，只要需要预测未来并采取相应的行动，也符合标准。    提交人    /u/Log_Dogg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp0uzy/d_toy_problems_for_research_in_planning_and/</guid>
      <pubDate>Wed, 26 Jun 2024 15:07:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练自定义拥抱脸 RoBERTa 时出错</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1doxhs9/d_error_while_training_a_custom_hugging_face/</link>
      <description><![CDATA[我正在尝试在自己的数据集上微调 cardiffnlp/twitter-roberta-base-sentiment-latest，该数据集有 8 个用于情绪分析的标签。 数据为 CSV 格式，我使用 hugging face 文档中提到的 Tokenizer 进行了标记和编码，然后使用 pytorch Dataset 类，我将这些编码转换为 PyTorch 张量。我不明白为什么会出现值错误： ValueError：预期输入 batch_size (16) 与目标 batch_size (128) 匹配。 感谢您的帮助。非常感谢。 p.s.我之前已经对 flan-t5 进行了微调（完整 FF、PEFT 和 RLHF），但我没有使用已经微调的自定义模型的经验。 model = f&quot;cardiffnlp/twitter-roberta-base-sentiment-latest&quot; tokenizer = AutoTokenizer.from_pretrained(model) config = AutoConfig.from_pretrained(model) config.num_labels = 8 import torch from torch.utils.data import Dataset, DataLoader class TextDataset(Dataset): &quot;&quot;&quot; 自定义数据集类，用于处理标记化的文本数据和相应的标签。从 torch.utils.data.Dataset 继承。&quot;&quot;&quot; def __init__(self, encodings, labels): &quot;&quot;&quot; 使用编码和标签初始化 DataLoader 类。参数：encodings（dict）：包含标记化输入文本数据的字典（例如，“input_ids”、“token_type_ids”、“attention_mask”）。labels（list）：输入文本数据的整数标签列表。&quot;&quot;&quot; self.encodings = encodings self.labels = labels def __getitem__(self, idx): &quot;&quot;&quot; 返回包含标记化数据和给定索引的相应标签的字典。参数：idx（int）：要检索的数据项的索引。返回：item（dict）：包含标记化数据和相应标签的字典。&quot;&quot;&quot;检索给定索引的标记数据 item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} 将给定索引的标签添加到项目字典 item[&#39;labels&#39;] = torch.nn. functional.one_hot(torch.tensor(self.labels[idx]), num_classes=8) return item def __len__(self): &quot;&quot;&quot; 返回数据集中的数据项数量。返回：(int): 数据集中的数据项数量。&quot;&quot;&quot; return len(self.labels) 假设 train_encodings 和 val_encodings 是张量的字典 train_dataset = TextDataset(train_encodings, y_train.to_list(),) val_dataset = TextDataset(val_encodings, y_val.to_list())  最后使用 Trainer 类像往常一样进行训练  from transformers import AutoModelForSequenceClassification, TrainingArguments training_args = TrainingArguments( output_dir=&#39;./results&#39;, num_train_epochs=1, per_device_train_batch_size=16, per_device_eval_batch_size=8, warmup_steps=100, weight_decay=1e-4, logs_dir=&#39;./logs&#39;, eval_steps=50, load_best_model_at_end=True, evaluation_strategy=&quot;steps&quot;, save_strategy=&quot;steps&quot;, ) 从 transformers 导入 Trainer model = AutoModelForSequenceClassification.from_config(config) trainer = Trainer( model=model, args=training_args, train_dataset=train_dataset, eval_dataset=val_dataset, compute_metrics= compute_metrics )     提交人    /u/areewahitaha   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1doxhs9/d_error_while_training_a_custom_hugging_face/</guid>
      <pubDate>Wed, 26 Jun 2024 12:33:39 GMT</pubDate>
    </item>
    <item>
      <title>[项目] CUHNSWPLUS：增强了 cuhnsw 的多线程、API 支持和性能提升</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dox5bu/project_cuhnswplus_enhanced_cuhnsw_with/</link>
      <description><![CDATA[大家好， 我很高兴与大家分享我的项目 CUHNSWPLUS，它是 cuhnsw 的一个改进分支。 项目链接：[GitHub Repo](https://github.com/n0tank3sh/cuhnswplus) **改进**  用于加载图形向量的多线程。 重用分配的 `device_vector` 来提高性能。 磁盘缓存可有效处理大型数据集。 对 `AddPoint` 和 `AddPoints` 的 API 支持。  我将非常感谢任何反馈、建议或贡献。谢谢！    由   提交  /u/MightiestGoat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dox5bu/project_cuhnswplus_enhanced_cuhnsw_with/</guid>
      <pubDate>Wed, 26 Jun 2024 12:15:48 GMT</pubDate>
    </item>
    <item>
      <title>展现与神经网络根本不同的模型的类人智能 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dovn4n/humanlike_intelligence_exhibiting_models_that_are/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dovn4n/humanlike_intelligence_exhibiting_models_that_are/</guid>
      <pubDate>Wed, 26 Jun 2024 10:50:13 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] superduperdb 的新开源版本可用于在您现有的数据库中构建 AI 工作流，包括 Postgres、Mongo、Snowflake、DuckDB 等。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dou7vb/news_new_opensource_version_of_superduperdb_for/</link>
      <description><![CDATA[https://blog.superduperdb.com/version-02/    由    /u/escalize 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dou7vb/news_new_opensource_version_of_superduperdb_for/</guid>
      <pubDate>Wed, 26 Jun 2024 09:13:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] UniBias：通过内部注意力和 FFN 操纵揭示和减轻 LLM 偏见</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dosa1v/r_unibias_unveiling_and_mitigating_llm_bias/</link>
      <description><![CDATA[摘要  大型语言模型 (LLM) 已在使用上下文学习 (ICL) 范式的各种任务中展现出令人印象深刻的能力。然而，它们的有效性往往受到固有偏见的影响，导致提示脆弱性，即对设计设置（例如示例选择、顺序和提示格式）的敏感性。先前的研究通过外部调整模型输出来解决 LLM 偏差问题，但导致这种偏差的内部机制仍未得到探索。 我们的工作深入研究了这些机制，特别是研究了前馈神经网络 (FFN) 和注意力头如何导致 LLM 的偏差。通过解释单个 FFN 向量和注意力头的贡献，我们确定了导致 LLM 对特定标签的预测出现偏差的 LLM 成分。为了减轻这些偏见，我们引入了 UniBias，这是一种仅推理的方法，可以有效地识别和消除有偏见的 FFN 向量和注意力头。在 12 个 NLP 数据集上进行的大量实验表明，UniBias 显着提高了 ICL 性能并减轻了 LLM 的即时脆性。     提交人    /u/Balance-   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dosa1v/r_unibias_unveiling_and_mitigating_llm_bias/</guid>
      <pubDate>Wed, 26 Jun 2024 06:55:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在顶级机器学习会议上招聘</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1doo538/r_recruitment_at_top_ml_conferences/</link>
      <description><![CDATA[我很幸运，我的第一作者出版物被顶级 ML 会议接受为焦点。最近收到字节跳动的一封电子邮件，邀请我在线或在会场聊天。我只是好奇  他们会将这些电子邮件群发给焦点/口头论文的作者吗？抱歉，我不直接认识其他人，我问这个问题是因为我的论文似乎与他们的重点不直接一致，根据他们的说法，他们主要是法学硕士 即使我不能亲自参加会议，我该如何充分利用这些机会？他们会要求我进行 LC 面试还是只谈论这个特定的项目，还是其他什么？  我对此不是很熟悉，非常感谢任何经验。谢谢！    提交人    /u/logichael   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1doo538/r_recruitment_at_top_ml_conferences/</guid>
      <pubDate>Wed, 26 Jun 2024 02:47:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 仅用于分类的解码器模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1domam7/d_decoder_only_models_for_classification/</link>
      <description><![CDATA[我在几次采访中被问到这个问题 - 对于分类任务，如何决定是使用仅编码器还是仅解码器架构？ 据我所知，使用仅编码器架构是因为它们可以完全捕捉文本中的含义，并且在此表示之上添加分类层将在分类任务上提供良好的性能。 但后续问题是关于为什么不能考虑解码器，因为像 GPT 这样的模型似乎在分类上也表现良好？我不确定如何回答这个问题，因为仅编码器看起来是一个直观的选择。像 GPT 这样的模型在许多任务上表现良好，包括分类，因为它们是在大量数据上进行训练的。如果从头开始训练模型的唯一可用数据是分类数据集，那么在这种情况下也可以使用解码器吗？    提交人    /u/PretendBelt3387   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1domam7/d_decoder_only_models_for_classification/</guid>
      <pubDate>Wed, 26 Jun 2024 01:14:59 GMT</pubDate>
    </item>
    <item>
      <title>[N] Karpathy 已开始推出新系列“LLM101n”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1doj9kv/n_karpathy_has_begun_a_new_series_llm101n/</link>
      <description><![CDATA[https://github.com/karpathy/LLM101n    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1doj9kv/n_karpathy_has_begun_a_new_series_llm101n/</guid>
      <pubDate>Tue, 25 Jun 2024 22:50:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>