<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 05 Jun 2024 21:15:18 GMT</lastBuildDate>
    <item>
      <title>[D] 在小数据集上嵌套 LOO-CV 来选择超参数并报告整个数据集的准确性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8z1yf/d_nested_loocv_on_a_small_dataset_to_both_select/</link>
      <description><![CDATA[我有一个包含 68 个时间序列的数据集。我的数据集有 3,000 个特征，因为我正在使用包来生成尽可能多的特征。我知道这是一个问题，所以我计划使用 sklearn 的 SelectPercentile 和 PCA 来减少特征数量，然后将其输入到某个分类器中。我希望能够为 SelectPercentile、PCA 和分类器选择超参数，同时报告整体准确度指标。 我的数据集很小，所以如果我将其拆分为 train-val-test 以选择最佳模型，我的测试集将太小而无法报告良好的准确度指标（即 5/7 听起来不如 53/68 好）。此外，我想执行 LOO 而不是 KFold，因为小规模意味着不同的折叠将导致非常不同的测试准确度（即 4/7 和 5/7 是一个巨大的差异），并且 LOO 在这方面是确定性的。 我可以执行嵌套 LOO 来为我的模型选择超参数，然后报告整个数据集的准确度吗？    提交人    /u/Amazydayzee   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8z1yf/d_nested_loocv_on_a_small_dataset_to_both_select/</guid>
      <pubDate>Wed, 05 Jun 2024 19:49:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 房间的 3D 重建</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8wwke/d_3d_reconstruction_of_a_room/</link>
      <description><![CDATA[您好，我的房间里有三个摄像头。我有每个摄像头的内在函数和成对的外在函数。我想对我的房间进行 3D 重建，我该怎么做？您能给我一些建议吗？ 非常感谢。    提交人    /u/Embarrassed_Top_5901   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8wwke/d_3d_reconstruction_of_a_room/</guid>
      <pubDate>Wed, 05 Jun 2024 18:21:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 请求就 Equinox Architecture 攻读法学硕士进行合作（我需要您的帮助！！！）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8wp5d/d_request_for_collaboration_on_equinox/</link>
      <description><![CDATA[我认为开发了一种像 Transformer 这样的技术，它的时间复杂度为 O(2*n)，瘫痪时的时间复杂度为 O(log(n))。我通过构建一些小型 LLM 对其进行了测试，其在 PTB 数据集上的准确率为 19% 到 30%，并且有训练过的 PTB 数据集，当模型过度拟合时，它在 PTB 数据集训练上的准确率达到 90%。我想知道这项技术在未来是否有潜力。我已经给研究人员写了一封电子邮件，你可以阅读它以了解更多信息，如果你是 AI 或 LLM 领域的研究人员，请联系我。我真的需要你的帮助。 这是电子邮件： 尊敬的先生/女士， 希望您收到这封信时一切安好。我写信是为了介绍我开发的一种名为“Equinox”的技术，我相信它在语言模型和 Transformer 领域有潜在的应用。我正在寻求您的专业知识和合作，以探索其功能。 Equinox 旨在执行时间复杂度为 O(2n) 的转换器任务，并行化后可实现 O(log(n))。其空间复杂度为 O(2n)。该架构在参数和训练方法方面提供了灵活性。值得注意的是，它允许在有或没有预测下一个标记的情况下进行训练。 在我的实验中，我使用 PTB 数据集和 Equinox 架构训练了几个小型语言模型 (LLM)，具体来说是没有预测下一个标记。结果如下：   Token预测 训练集 测试集 验证集    第3个Token 27.00% 28.18% 26.36%   第5个Token 25.25% 26.18% 24.43%   第9个标记 18.15% 19.06% 17.43%   注意：只有网络的解码器部分接受了预测下一个标记的训练。 正如预期的那样，准确度随着标记预测距离的增加而降低，因为 Equinox 部分没有为此目的进行训练。我相信在训练预测下一个 token 时可以缓解此问题。 Equinox 和解码器的参数数量如下：   Token 预测 Equinox 的参数数量 解码器的参数数量    第 3 个 Token 1,180,416 40,492,801   第 5 个 Token 2,360,832 40,492,801   第 9 个代币 3,541,248 40,492,801   Equinox 中的参数数量范围可以从最小 2*编码维度^2 到可能无限大，从而提供可扩展性。 目前，Equinox 的实现类似于单头转换器，没有任何 MLP 转换，只运行一次。我相信这种架构具有巨大的潜力，凭借您的专业知识，我们可以进一步探索和完善其功能。 我很感激有机会更详细地讨论这项技术并探索潜在的合作。您的见解和贡献对于实现 Equinox 的全部价值将非常宝贵。 感谢您考虑此提议。我期待您的回复。 注意：这封邮件是由 chat-gpt 重写的，邮件感觉我不需要你的帮助，我可以一个人完成，但实际上，我真的需要你的帮助。我愿意分享代码和有关架构的任何其他信息。equinox 的参数可以是一个常数 此致敬意， Dakshish Singh    提交人    /u/Conscious-Gazelle-91   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8wp5d/d_request_for_collaboration_on_equinox/</guid>
      <pubDate>Wed, 05 Jun 2024 18:12:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从时间序列数据中推导规则</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8u59u/p_rule_derivation_from_time_series_data/</link>
      <description><![CDATA[大家好。我有表格时间序列数据 [行是感兴趣的区域，列是时间间隔，每个单元格包含当时的 ROI 值]。需要知道是否有任何方法/字段可以使用 ML 派生规则。（实现相同目的的替代方案也可以）。我所说的规则是指（转换、/连接建立/断开、同步、激活） 如果需要更多详细信息，请告诉我。谢谢。    提交人    /u/sagax8   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8u59u/p_rule_derivation_from_time_series_data/</guid>
      <pubDate>Wed, 05 Jun 2024 16:27:31 GMT</pubDate>
    </item>
    <item>
      <title>[P]OpenAGI：法学硕士的自主代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8svhx/popenagi_autonomous_agents_for_llms/</link>
      <description><![CDATA[我一直想创建像人类一样的代理。虽然 LLM 擅长收集信息，但我希望代理能够独立规划、推理和行动。 所以我创建了 OpenAGI。 OpenAGI 可帮助您为教育、金融、医疗保健等领域的各种任务构建自主代理。它是开源的，旨在让代理随着时间的推移而学习和改进。 GitHub：OpenAGI GitHub    提交人    /u/trj_flash75   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8svhx/popenagi_autonomous_agents_for_llms/</guid>
      <pubDate>Wed, 05 Jun 2024 15:34:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与去噪模型（DDPM）相比，变分扩散模型（VDM）是否仍在使用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8sa60/d_are_variational_diffusion_models_vdm_still_used/</link>
      <description><![CDATA[如果我理解正确的话，VDM 和 DDPM 之间的主要区别在于 VDM 尝试预测每个 x_t 处的完整噪声，而 DDPM 尝试预测从 x_t-1 到 x_t 的步进噪声。我以本文中的 VDM 推导为基础：https://arxiv.org/abs/2208.11970。 VDM 还在任何地方使用吗？我发现几乎所有知名的图像生成模型都使用 DDPM。即使是试图学习单步扩散的回流方法似乎也是从训练过的 DDPM 开始的。    提交人    /u/WhatIsThis_WhereAmI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8sa60/d_are_variational_diffusion_models_vdm_still_used/</guid>
      <pubDate>Wed, 05 Jun 2024 15:09:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 深度学习的局限性：从复杂性理论的角度进行序列建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8s0yp/r_limits_of_deep_learning_sequence_modeling/</link>
      <description><![CDATA[论文链接：https://arxiv.org/abs/2405.16674 X 线程：https://x.com/NikolaZubic5/status/1797567892646470137    提交人    /u/NikolaZubic   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8s0yp/r_limits_of_deep_learning_sequence_modeling/</guid>
      <pubDate>Wed, 05 Jun 2024 14:59:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 机器学习 / 人工智能研究的存储库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8qt8q/p_a_repository_for_mlai_research/</link>
      <description><![CDATA[因为我经常看到有趣的论文、新闻和其他资源，而且记忆力像金鱼一样好，所以我决定将它们保存在 GitHub 存储库中。 有几份新闻通讯、LinkedIn、Twitter、subreddits 提供有关 ML 的更新。对我来说，它太分散了，有时要找到我读过的文章成了一场噩梦。在过去的几年里，我试图收集各种新闻和文章（我想保存下来以后再读的）。我按周划分它们，你可以在这里找到它们（如果你认为这有用的话）： https://github.com/SalvatoreRa/ML-news-of-the-week  总的来说，我想提出一个问题：你认为数据科学家跟踪趋势的最佳来源是什么？新文章？ 在我看来，存在一种信息过载，在阅读一篇真正有趣的文章之前，我必须阅读几篇文章，在我看来，大多数文章只介绍了增量研究。尤其是今天，许多文章只是已经描述或提出的内容的小变化。例如，快速工程就是一个例子，您可以查看几个方法系列，然后查看来自 CoT 的数百种变体等等。今天，在我看来，RAG 中也发生了同样的事情：Twitter 或 LinkedIn 上的一篇文章指出一种方法是 SOTA，然后阅读这篇文章有一种似曾相识的感觉    提交人    /u/NoIdeaAbaout   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8qt8q/p_a_repository_for_mlai_research/</guid>
      <pubDate>Wed, 05 Jun 2024 14:06:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于生物组织图像合成的检索增强扩散</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8qit5/p_retrieval_augmented_diffusion_for_biological/</link>
      <description><![CDATA[这是一个将 RAG 与 Diffusion 相结合进行生物组织图像合成的探索性项目。这是一个有趣的学习经历，我想分享它，以防其他人觉得有用。但它仍然需要改进，我将尝试整合一个经过微调的模型，而不是从头开始训练。 链接：https://github.com/lnairGT/Diffusion-with-RAG    提交人    /u/IllustriousSir_007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8qit5/p_retrieval_augmented_diffusion_for_biological/</guid>
      <pubDate>Wed, 05 Jun 2024 13:54:44 GMT</pubDate>
    </item>
    <item>
      <title>生物技术中的人工智能。[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8pxsw/ai_in_biotech_d/</link>
      <description><![CDATA[想知道在生物技术领域，AI 是营销热词还是有实际应用。 我是 ML 工程师，根本不是生物学家。我在生物技术领域发现了几种 AI 解决方案，但它们似乎都没有真正带来价值，而更像是一种趋势。我希望我错了，但找不到好的证据。 我发现的解决方案是 Material gen、Microsoft；Alpha Fold、DeepMind；EvBio。    提交人    /u/IIISergeyIII   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8pxsw/ai_in_biotech_d/</guid>
      <pubDate>Wed, 05 Jun 2024 13:28:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何定义多数投票的自定义损失函数？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8peu3/d_how_to_define_custom_loss_function_for_majority/</link>
      <description><![CDATA[我有一个包含 10 个数字的序列。2,2,2,2,2,2,2,2,2,2...2 是类标签，我有 5 个类。该序列也有一个特征向量。我使用这个特征向量通过深度神经网络预测序列。然后为了预测序列的最终类标签，我使用了预测序列的大多数数字。但我需要一个近似函数来定义多数投票的损失函数来训练深度网络。怎么办？我可以使用哪些近似函数？有任何默认的 PyTorch 损失函数吗？    提交人    /u/Special_Storage5054   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8peu3/d_how_to_define_custom_loss_function_for_majority/</guid>
      <pubDate>Wed, 05 Jun 2024 13:03:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于生成推荐的万亿参数序列传感器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8o2sz/r_trillionparameter_sequential_transducers_for/</link>
      <description><![CDATA[Meta 的研究人员最近发表了一篇开创性的论文，将 ChatGPT 背后的技术与推荐系统相结合。他们表明，他们可以将这些模型扩展到 1.5 万亿个参数，并在生产 A/B 测试中将顶线指标提高了 12.4%。 我们在本文中深入探讨细节：https://www.shaped.ai/blog/is-this-the-chatgpt-moment-for-recommendation-systems    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8o2sz/r_trillionparameter_sequential_transducers_for/</guid>
      <pubDate>Wed, 05 Jun 2024 11:55:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] 智能 Go-Explore：大型语言模型代理的新型探索框架！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8j2pm/r_intelligent_goexplore_new_exploration_framework/</link>
      <description><![CDATA[标题：智能围棋探索：站在巨人基础模型的肩膀上 作者： Cong Lu、Shengran Hu、Jeff Clune。 代码： https://github.com/conglu1997/intelligent-go-explore 网站： https://conglu.co.uk/intelligentgoexplore/ 论文： https://arxiv.org/abs/2405.15143 摘要：Go-Explore 是一组功能强大的算法，旨在解决难以探索的问题，其原理是存档已发现的状态，并迭代返回最有希望的状态并从中进行探索。这种方法在包括 Atari 游戏和机器人控制在内的各种具有挑战性的问题中都取得了超人的表现，但需要手动设计启发式方法来指导探索，这既耗时又不可行。为了解决这个问题，我们提出了智能 Go-Explore (IGE)，它通过用巨型基础模型 (FM) 捕获的智能和内化的人类兴趣概念取代这些启发式方法，大大扩展了原始 Go-Explore 的范围。这为 IGE 提供了一种类似人类的能力，即使在启发式难以定义的复杂环境中，也能本能地识别任何新状态的有趣程度或前景（例如发现新物体、位置或行为）。此外，IGE 提供了令人兴奋的、以前不可能的机会来识别和利用无法提前预测的偶然发现。我们在一系列需要搜索和探索的语言任务上评估了 IGE。在 Game of 24 这个多步骤数学推理问题中，IGE 达到 100% 的成功率，比最佳经典图形搜索基线快 70.8%。接下来，在 BabyAI-Text 这个具有挑战性的部分可观察网格世界中，IGE 以比之前的 SOTA 少几个数量级的在线样本超越了之前的 SOTA。最后，在 TextWorld 中，我们展示了 IGE 在需要长期探索的环境中取得成功的独特能力，而之前的 SOTA FM 代理（如 Reflexion）则完全失败了。总体而言，IGE 结合了 FM 的巨大优势和强大的 Go-Explore 算法，开辟了研究的新前沿，以创建具有令人印象深刻的探索能力的更通用的代理。    提交人    /u/MolassesWeak2646   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8j2pm/r_intelligent_goexplore_new_exploration_framework/</guid>
      <pubDate>Wed, 05 Jun 2024 06:17:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] mamba.np：Mamba 的纯 NumPy 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d80t26/p_mambanp_pure_numpy_implementation_of_mamba/</link>
      <description><![CDATA[      mamba.np 受到一些很棒的项目的启发，我用纯 Numpy 从头实现了 Mamba。代码的目标是简单、可读、轻量，因为它可以在本地 CPU 上运行。 https://github.com/idoh/mamba.np 希望您觉得它有用 :)    提交人    /u/id0h   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d80t26/p_mambanp_pure_numpy_implementation_of_mamba/</guid>
      <pubDate>Tue, 04 Jun 2024 16:02:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>