<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Sat, 24 Aug 2024 21:13:05 GMT</lastBuildDate>
    <item>
      <title>[D] 上周医疗 AI：顶级研究论文/模型🏅（2024 年 8 月 17 日至 8 月 24 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0fipu/d_last_week_in_medical_ai_top_research/</link>
      <description><![CDATA[   本周热门论文（8 月 17 日至 24 日）  医学多模态 LLM 的越狱  本文揭示了医学 MLLM 中的安全漏洞。针对 MedMLLM 的新“不匹配的恶意攻击”（2M 攻击）。它介绍了用于测试各种医疗场景的 3MAD 数据集  LLM 不是 零样本生物医学推理器  本文对生物医学任务上的 LLM 进行了基准测试，它在医学分类和 NER 上测试了 LLM，评估了标准提示、CoT、自洽性和 RAG  RuleAlign 框架：将 LLM 与医生规则对齐  本文介绍了用于医学诊断的 LLM 的 RuleAlign 框架。它将 LLM 与特定的诊断规则相结合，并开发基于规则的医学对话数据集。  CTP-LLM：用于临床试验转变预测的 LLM  本文介绍了用于临床试验预测的 CTP-LLM，它介绍了用于基准测试的 PhaseTransition (PT) 数据集。在所有阶段实现 67% 的准确率，从 III 期到批准的准确率达到 75%。  HIBOU：病理学的基础视觉转换器  本文介绍了病理学的视觉转换器，利用 DINOv2 框架在超过 100 万张全幻灯片图像 (WSI) 上预训练两种模型变体 Hibou-B 和 Hibou-L  LLaVA-Surg：多模式手术助手  LLaVA-Surg 引入了大规模手术视频指令调整数据集 Surg-QA，其中包含来自 2,201 个手术程序的超过 102K 个手术视频指令对，并训练了 LLaVA-Surg 模型。  ...  详细查看完整线程：https://x.com/OpenlifesciAI/status/1827442651810918509 感谢您的阅读！如果您知道任何遗漏的有趣论文，请随时在评论中分享。如果您对医疗 AI 有见解或突破，并希望在下周的版本中分享，请通过 Twt/x 与我们联系：OpenlifesciAI    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0fipu/d_last_week_in_medical_ai_top_research/</guid>
      <pubDate>Sat, 24 Aug 2024 21:01:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 生产中的机器学习：从数据科学家到机器学习工程师</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0fdih/p_ml_in_production_from_data_scientist_to_ml/</link>
      <description><![CDATA[我很高兴与大家分享我整理的一门课程：生产中的机器学习：从数据科学家到机器学习工程师。本课程旨在帮助您从 Jupyter 笔记本中获取任何 ML 模型并将其转变为可用于生产的微服务。 本课程涵盖以下内容：  将您的 Jupyter 代码构建为生产级代码库 管理数据库层 参数化、日志记录和最新的干净代码实践 使用 GitHub 设置 CI/CD 管道 为您的模型开发 API 容器化您的应用程序并使用 Docker 进行部署  我很乐意收到您对本课程的反馈。这是免费访问的优惠券代码：FREETOLEARN。您的见解将帮助我改进和完善内容。谢谢，祝您学习愉快！    提交人    /u/5x12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0fdih/p_ml_in_production_from_data_scientist_to_ml/</guid>
      <pubDate>Sat, 24 Aug 2024 20:54:58 GMT</pubDate>
    </item>
    <item>
      <title>线性注意力——矩阵维数问题[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0e4u8/linear_attention_matrix_dimension_issue_r/</link>
      <description><![CDATA[      我正在阅读线性注意论文Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention。我对 eq(4) 和 eq(5) 中矩阵的维度感到困惑。作者说“用 i 给矩阵加下标会返回第 i 行向量”。我假设 \phi(\cdot) 是一个列向量。然后根据 eq(5)，V_j 必须是列向量，因为它必须左乘以 \phi。因此我假设 V_i 也是一个列向量。然而，eq(5) 最左边的项是 \phi^T，它是一个行向量。这似乎与我上面的想法相矛盾。  https://preview.redd.it/lr61kmu22okd1.png?width=1210&amp;format=png&amp;auto=webp&amp;s=e05296cf8073de618407a60cc744a449dc6c6f14    提交人    /u/mziycfh   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0e4u8/linear_attention_matrix_dimension_issue_r/</guid>
      <pubDate>Sat, 24 Aug 2024 19:58:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 训练和部署 JoJo - Tic Tac 特工 [适合新手]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f093av/p_training_and_deploying_jojo_a_tic_tac_agent/</link>
      <description><![CDATA[        由    /u/Particular_Tap_4002   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f093av/p_training_and_deploying_jojo_a_tic_tac_agent/</guid>
      <pubDate>Sat, 24 Aug 2024 16:17:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士知道的比他们说的多</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f08n2z/r_llms_know_more_than_what_they_say/</link>
      <description><![CDATA[      用于评估的潜在空间技术    提交人    /u/nqnielsen   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f08n2z/r_llms_know_more_than_what_they_say/</guid>
      <pubDate>Sat, 24 Aug 2024 15:58:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] Liger Kernel：一行代码使 LLM 培训速度提高 20%，内存减少 60%</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0875c/p_liger_kernel_one_line_to_make_llm_training_20/</link>
      <description><![CDATA[        提交人    /u/Icy-World-8359   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0875c/p_liger_kernel_one_line_to_make_llm_training_20/</guid>
      <pubDate>Sat, 24 Aug 2024 15:39:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要有关实时物体检测的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f07gjk/d_need_suggestion_for_realtime_object_detection/</link>
      <description><![CDATA[我们大学有一个项目，要制作一个实时物体检测模型，以实时检测周围的物体。我们想知道哪种预训练模型对速度和准确性有好处。例如，YOLOv5 速度很快，但准确性不高，YOLOv7 则相反。所以，你们有什么建议？    提交人    /u/Aditya_Kumar5155   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f07gjk/d_need_suggestion_for_realtime_object_detection/</guid>
      <pubDate>Sat, 24 Aug 2024 15:07:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] BLADE：数据驱动科学的基准语言模型代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f05t0t/r_blade_benchmarking_language_model_agents_for/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f05t0t/r_blade_benchmarking_language_model_agents_for/</guid>
      <pubDate>Sat, 24 Aug 2024 13:52:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 整理了一份 70 多篇研究论文的清单，供大家深入探讨</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f01yn2/p_curated_a_list_of_70_research_papers_for/</link>
      <description><![CDATA[        由    /u/Particular_Tap_4002   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f01yn2/p_curated_a_list_of_70_research_papers_for/</guid>
      <pubDate>Sat, 24 Aug 2024 10:15:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过估计数据分布比率进行离散扩散建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ezyunc/r_discrete_diffusion_modeling_by_estimating_the/</link>
      <description><![CDATA[文本扩散模型现在终于达到了 GPT2 的文本质量。 https://arxiv.org/abs/2310.16834（本文荣获 ICML2024 最佳论文奖！） 您认为扩散语言模型（扩散 LLM）会赶上自回归 LLM 并可能成为下一个 ChatGPT 吗？我们很快就会看到扩散 LLM 的缩放定律吗？与自回归 LLM 相比，这些模型具有一些关键优势，例如能够在任何地方接受提示 - 在输入的开始、中间、结束甚至拆分。此外，它们原则上可以一次生成多个标记。 这篇论文内容非常密集且数学繁重，所以我制作了一个动画解释视频，供任何感兴趣的人观看。 https://youtu.be/K_9wQ6LZNpI 我的看法：我认为这种方法在理论上可以扩展，但存在一个重大挑战：我们已经在 GPT/自回归变压器的硬件和软件优化方面投入了大量资金。考虑到沉没成本谬论，很难想象科技巨头会放弃他们目前的 LLM 来开始训练扩散 LLM，尤其是因为他们可能需要数年时间才能赶上 ChatGPT 和类似模型。就像 MAMBA 一样，我担心离散扩散也可能会输掉硬件/软件抽奖。    提交人    /u/AICoffeeBreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ezyunc/r_discrete_diffusion_modeling_by_estimating_the/</guid>
      <pubDate>Sat, 24 Aug 2024 06:32:39 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 当固定提示模板作为 LLM 的输入时，LLM 生成中会出现奇怪的模式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ezv7of/discussion_weird_patterns_in_llm_generations_when/</link>
      <description><![CDATA[对于使用大型语言模型生成创意内容的任务，固定的提示模板是否会在 LLM 输出中引入奇怪的模式、相关性和重复性？ 例如，在不同的调用中重复出现类似的单词、短语以及单词、短语和各种词类的组合。    提交人    /u/debraj135   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ezv7of/discussion_weird_patterns_in_llm_generations_when/</guid>
      <pubDate>Sat, 24 Aug 2024 02:53:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] TurboEdit：即时基于文本的图像编辑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eztooi/r_turboedit_instant_textbased_image_editing/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eztooi/r_turboedit_instant_textbased_image_editing/</guid>
      <pubDate>Sat, 24 Aug 2024 01:33:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 输血：使用一个多模态模型预测下一个标记并扩散图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ez422y/r_transfusion_predict_the_next_token_and_diffuse/</link>
      <description><![CDATA[Transfusion 在单一模型中统一了文本和图像生成，可与专门的架构相媲美。    提交人    /u/AhmedMostafa16   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ez422y/r_transfusion_predict_the_next_token_and_diffuse/</guid>
      <pubDate>Fri, 23 Aug 2024 04:37:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 18 Aug 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>