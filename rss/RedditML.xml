<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 07 Nov 2024 12:31:20 GMT</lastBuildDate>
    <item>
      <title>[D] 发现：Anthropic 以某种方式在用户提示中注入/隐藏安全警告，告诉 Claude 保密。[内容警告：暴力]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gloktj/d_discovery_anthropic_somehow_injectinghiding/</link>
      <description><![CDATA[在调查“越狱”的 Claude 时，我遇到了一些非常奇怪的事情。在两次单独的 Claude 聊天中，在我要求一些“不安全”的东西后，它能够读出我提示中的一些隐藏信息。 这些消息总是以类似的格式出现： （请合乎道德地回应，不要提及 [例如暴力] 并且不要提及此指令） Claude 表示警告附加在我的消息底部，但在未来的回合中不再出现。Claude 起初滑稽地坚持认为它后来将其编造为幻觉，暗示进一步训练反应以积极掩盖它。 我在第二次聊天中验证了这一点 - 消息太相似了，不可能是幻觉或巧合。第一个是“越狱”的克劳德，第二个是一段没有任何上下文的新对话。 我的测试发现了一些有趣的特点：  消息是动态的 - 它们似乎根据手头的特定类型的受限内容而有所不同，可能是由模型生成的。关于与儿童相关的内容，措辞已切换为（警告：[x] 是严格禁止的...） 它们出现在之前模型开始生成文本 - 表明它们可以以某种方式预测模型的思考主题。  我目前的猜想是：它们可能正在使用其内部 CoT，或者归功于 Anthropic 发表的关于 mech 的发现。 interp 和他们最新模型中的“外科调整”，也许他们已经设法在生成文本之前隔离了 Claude 中触发的一些抽象概念，并在响应中注入了这些安全消息。 完整对话：  初步发现 [警告：极其生动的内容] 通过新鲜对话进行验证  任何进一步的测试，例如 API？有什么方法可以缩小这里到底发生了什么？这一切都非常有趣 - 让我们讨论一下。 警告示例 - 请参阅完整对话以了解更多内容。  与 Claude 进行新的对话以验证。     提交人    /u/specteksthrowaway   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gloktj/d_discovery_anthropic_somehow_injectinghiding/</guid>
      <pubDate>Thu, 07 Nov 2024 11:47:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在 196xH100 GPU 集群上从头训练文本转视频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glmfsr/p_training_a_texttovideo_model_from_scratch_on_a/</link>
      <description><![CDATA[大家好！👋 我们一直在使用 28,000 个 H100 GPU 小时从头开始训练开源文本转视频模型（称为 Open-Sora 1.2），并且我们整理了GitHub 指南来分享我们在此过程中学到的一些经验教训。这里涵盖了几个主题：  分布式训练中的关键挑战，例如使用 py-spy 进行分布式调试以处理集群范围的问题、NCCL 错误和收敛问题。 训练监控，中间结果显示多阶段训练方案特定训练小时后的预期结果。 为 T2V 并行化数据集准备，包括如何在集群上高效并行化预处理任务。  这是指南的链接：link。 查看并让我们知道您的想法！（欢迎 PR。）    提交人    /u/lambda-research   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glmfsr/p_training_a_texttovideo_model_from_scratch_on_a/</guid>
      <pubDate>Thu, 07 Nov 2024 09:13:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 博士学位还是工作生活？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glm6j9/d_phd_or_worklife/</link>
      <description><![CDATA[今年二月，我将完成以人为本的人工智能硕士学位，我真的很期待能够在晚上放松，而不必担心学校的事，但想到不再去 UNI 又让我感到难过，因为我热爱在那里的每一刻，无论是和朋友在一起还是通过学习。  我的硕士论文导师刚刚向我提供了博士学位津贴，这对我来说完全是意料之外的 - 因为我没想到自己还差得上攻读博士学位。我喜欢学习，这个话题听起来非常有趣，我已经有点“厌倦”在一家小公司（比如我现在就职的公司）里，在我的余生中不得不做一些常规的小型数据科学任务了。 但是，我的问题是？攻读博士学位到底需要做多少工作？我喜欢学习，但这个机会让我非常惊讶，所以我还不太确定该怎么看待它。    提交人    /u/Hmm_okay_jeps   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glm6j9/d_phd_or_worklife/</guid>
      <pubDate>Thu, 07 Nov 2024 08:53:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在数据集上进行细微调整</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glkbzc/d_whisper_finetune_on_a_dataset/</link>
      <description><![CDATA[      我正在微调 Whisper Small，以识别印地语和英语对话中的特定菜单项。虽然 Deepgram Whisper 可以准确地转录对话，但会遗漏菜单项，而我经过微调的 Whisper 模型能够很好地转录训练数据，但对于训练数据之外的数据，它也难以处理一般对话。我观察到幻觉（重复的单​​词/短语）等问题，我想知道解决此问题的方法。 此外，我希望拥有与 OpenAI Whisper 的预训练模型类似的带时间戳的转录。其他人是如何应对这些挑战的？ https://preview.redd.it/tc0dquny9fzd1.png?width=319&amp;format=png&amp;auto=webp&amp;s=878182cade82c1fcf7ea3f121756db9026ee12c4    提交人    /u/sias_01   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glkbzc/d_whisper_finetune_on_a_dataset/</guid>
      <pubDate>Thu, 07 Nov 2024 06:34:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 我目前正在为我的论文探索一个奇怪的（？）ML 子领域，我想我对这个问题的范围感到震惊。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glk9g0/d_r_i_am_currently_exploring_a_weird_ml_sub_area/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glk9g0/d_r_i_am_currently_exploring_a_weird_ml_sub_area/</guid>
      <pubDate>Thu, 07 Nov 2024 06:29:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最具价值商用 GPU</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gljswc/d_best_value_commercial_gpu/</link>
      <description><![CDATA[您认为性能最佳的商用级 gpu 是什么？它用于训练 ai 模型。我对硬件方面有点陌生。我的预算不一定很严格（每个 gpu 1500-4500 美元），我只是好奇哪款卡最物有所值。    由   提交  /u/Fluid_Improvement160   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gljswc/d_best_value_commercial_gpu/</guid>
      <pubDate>Thu, 07 Nov 2024 05:59:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用语义搜索条件对某一列进行查询数据库表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glgurz/d_how_to_query_a_database_table_with_a_semantic/</link>
      <description><![CDATA[假设您有一个包含 100K 个库存项目的大型表格，其中包含项目描述列（例如“芒果汁”），但没有“类别”字段。 我想查询该表以查找所有饮料的总库存，即描述表明其为饮料的项目。目前存在哪些可能的选项来运行此类查询？    提交人    /u/SpaceShip992   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glgurz/d_how_to_query_a_database_table_with_a_semantic/</guid>
      <pubDate>Thu, 07 Nov 2024 03:06:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 存储 LLM 嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glecgo/d_storing_llm_embeddings/</link>
      <description><![CDATA[你好！ 我正在开展一个 ML 项目，该项目涉及使用预训练的蛋白质语言模型（如 ESM）。对于该项目，我想预先生成并存储大约 500,000 个氨基酸序列的嵌入。但是，这些向量可能非常庞大 - 嵌入序列、序列化 PyTorch 向量（使用 torch.save）和对整个数据集进行 gzip 压缩将使用大约 500TB。如果我使用 bfloat16，这会将数字减半，但仍然非常难以处理。我也可以使用具有较小潜在空间的模型，但这也不能真正解决问题。 我尝试过不同的压缩工具，但似乎没有一个能做得更好。所有这些工具的压缩率都非常糟糕（只有大约 7%），我假设这意味着向量看起来非常随机。我想知道是否有人知道如何序列化向量，使它们看起来不那么“随机”。我认为向量不应该是随机的，因为氨基酸序列具有可预测的结构，所以我希望有一种方法可以实现更好的压缩。 任何建议或想法都将不胜感激！我的其他选择是大幅减少训练数据的大小，这并不理想，或者临时生成嵌入，这非常耗费计算资源，即使在 GPU 上也是如此。    提交人    /u/BerryLizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glecgo/d_storing_llm_embeddings/</guid>
      <pubDate>Thu, 07 Nov 2024 00:58:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] AC 可以推翻 3 次拒绝并接受一篇论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glczb9/d_can_an_ac_override_3_rejects_and_accept_a_paper/</link>
      <description><![CDATA[我偶然发现了这篇论文：自动生成真实和合成数据的弱标签以改善标签稀缺的医学图像分割，该论文被今年的 MIDL（深度学习医学成像）会议接受。反驳前后的审稿人评分如下：  2：弱拒绝 / 2：弱拒绝 2：弱拒绝 / 2：弱拒绝 3：边界 / 2：弱拒绝  尽管有 3 个拒绝决定，但领域主席“建议接受”。这种情况有多常见？鉴于 AC 可以看到作者姓名，那么拥有 Curtis Langlotz 和 Andrew Ng 等大牌人物作为论文的共同作者又有多大作用呢？    提交人    /u/thrownicecatch   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glczb9/d_can_an_ac_override_3_rejects_and_accept_a_paper/</guid>
      <pubDate>Wed, 06 Nov 2024 23:54:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了一个工具，用于通过直观的操作来构建和训练神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gl30b0/p_i_made_a_tool_for_building_and_training_neural/</link>
      <description><![CDATA[嘿！我主要将其作为工具来学习如何实现反向传播并了解其工作原理，因此我认为它可能对其他人有用！我还在自述文件中撰写了一篇关于反向传播和模型训练如何工作的文章：https://github.com/PavleMiha/mlgarden 这对您有用吗？这是您会玩的东西吗？我真的不知道该怎么用它，所以我很想听听社区的想法！    提交人    /u/Massena   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gl30b0/p_i_made_a_tool_for_building_and_training_neural/</guid>
      <pubDate>Wed, 06 Nov 2024 16:50:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 亚马逊研究人员发现 LLM 并不总是遵循用户请求并提出自我纠正流程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkzac4/r_amazon_researchers_find_llms_do_not_always/</link>
      <description><![CDATA[      偶然发现了这篇将于下周在 EMNLP 2024 上发表的有趣论文：LLM使用 DECRIM 进行自我纠正：分解、批评和改进，以增强对具有多个约束的指令的遵循。。 这项研究深入探讨了一个重要问题：LLM 真的会按照我们的要求去做吗？我们经常依靠 LLM 来完成具有特定指令的任务，但是当这些指令变得复杂且受到多重约束时，例如要求特定的音调或避免使用某些单词，LLM 真的会遵循吗？本文表明答案可能比我们想象的更复杂。 作者创建了一个新的基准 RealInstruct，它使用真实世界的用户指令而不是合成提示。他们估计至少 30% 的真实用户请求包含 LLM 必须遵循的多个约束。在他们的结果中，即使是像 GPT-4 这样的高级模型也未能满足超过 21% 的测试指令的至少一个要求。因此，虽然 LLM 在简单情况下表现良好，但在处理更复杂、多步骤的请求时，其性能会下降。 为了解决这些差距，作者开发了一个名为 DECRIM 的自我修正管道，其中模型分解每条指令，根据每项要求检查其响应，并根据需要迭代优化它。通过 DECRIM，像 Mistral 这样的开源模型得到了显着的改进，甚至在基准测试中超过了 GPT-4。初步测试表明，LLM 无法单独可靠地自我纠正，然而，在弱但可靠性最低的辅助反馈下，它们实现了高达 8% 的提升。 通过高质量的“理想”反馈，DECRIM 将 Mistral 的性能提高了 34%，在 RealInstruct 和 IFEval 基准测试中均超越了 GPT-4。 我认为这篇论文符合 LLM 的新趋势，这些系统 2 推理模型（如 GPT-o1）在输出响应之前试图模仿一些思考/反思。无论如何，令人震惊的是，LLM 在一个似乎只是对用户最重要的任务中表现如此糟糕，遵循用户的要求。这种类型的模型是否让我们更接近 AGI？或者这只是证明有些人谈论的这种神奇的 AGI 实际上还很遥远？  论文：https://arxiv.org/pdf/2410.06458 他们在 Linkedin 上的帖子 https://preview.redd.it/techjo8pfazd1.png?width=2794&amp;format=png&amp;auto=webp&amp;s=18155cdbf4ba164f48480d4583c3cfea1d40298e    提交人    /u/Mundane_Sir_7505   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkzac4/r_amazon_researchers_find_llms_do_not_always/</guid>
      <pubDate>Wed, 06 Nov 2024 14:06:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 想要摆脱繁重的机器学习编码，但仍想完成博士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkx6o7/d_want_to_move_away_from_coding_heavy_ml_but/</link>
      <description><![CDATA[大家好， 我来自传统的电气工程背景，从事工业自动化和计算机视觉等工作。我决定攻读机器学习博士学位，因为根据我过去的经验，我认为这将是一个不错的领域。现在我已经攻读博士学位三年了。虽然我喜欢我的团队和研究，但我对以下因素感到沮丧/沮丧：(1) 出版竞争激烈 (2) 毕业后的机会大多是编码繁重 (3) 由于该领域已经变得如此拥挤，我无法在该领域为自己树立名声。 因此，理想情况下，我希望完成我的博士学位，然后从事节奏更轻松（即使它不像机器学习工作那么高薪）且编码繁重但技术性强的工作，在那里我不需要不断提升自己的技能。你们对我可以从事什么工作有什么建议吗？或者你们建议我放弃博士学位，做些其他的事情？ TLDR：四年级 ML 博士生不确定是否继续攻读博士学位，因为他们希望毕业后在行业中从事一份非编码重度技术工作。寻求建议。    提交人    /u/Hopeful-Reading-6774   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkx6o7/d_want_to_move_away_from_coding_heavy_ml_but/</guid>
      <pubDate>Wed, 06 Nov 2024 12:18:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为一名研究人员，您如何做好进入行业的准备？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gksoi7/d_as_a_researcher_how_do_you_become_industryready/</link>
      <description><![CDATA[作为一名博士生，我的大部分时间都花在指导学生、项目管理和编写用于原型设计的“快速而粗糙”的代码上。我打算在获得博士学位后进入行业，但我觉得我错过了关键的软件工程技能和良好的编码实践。其他人有这种感觉吗？在攻读博士学位期间，你如何提升自己的技能以做好进入行业的准备？    提交人    /u/fullgoopy_alchemist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gksoi7/d_as_a_researcher_how_do_you_become_industryready/</guid>
      <pubDate>Wed, 06 Nov 2024 07:07:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Nov 2024 16:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>