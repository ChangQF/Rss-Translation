<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 27 Oct 2024 12:29:55 GMT</lastBuildDate>
    <item>
      <title>[D] 寻求有关提高以单一特征为主的 Instacart 购物篮分析模型的稳健性的建议。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd9q9f/d_seeking_advice_on_improving_robustness_of/</link>
      <description><![CDATA[大家好， 我正在 Kaggle 上开展 Instacart 购物篮分析项目，专注于预测重复购买。我设计了一个名为 num_of_ord_purch_p_prod 的功能，表示特定用户购买特定产品的次数。虽然此功能具有很高的预测性，但它在各个模型中都占据了功能重要性的主导地位，这引发了对潜在过度依赖和模型稳健性的担忧。有关更多详细信息，请参阅我的特征工程笔记本的链接：笔记本。 项目详细信息：  类别平衡：目标类别（重新排序状态）是平衡的。 评估方法：我在两个单独的测试集上测试了模型，每个测试集仅包含最新的订单，以进行更多基于时间的验证。 模型性能： 我的最佳 LightGBM 模型实现了 0.85 的 AUC，与第二佳特征相比，num_of_ord_purch_p_prod 的重要性提高了 1000 倍。 我的最佳 XGBoost模型实现了 0.72 的 AUC，与第二佳特征相比，同一特征的重要性提高了 20 倍。  特征重要性：SHAP 分析证实了 num_of_ord_purch_p_prod 的重要性，即使在应用正则化技术之后也是如此。在 XGBoost 中，正则化降低了其主导性，但也降低了 AUC。  使用中的功能：除了 num_of_ord_purch_p_prod 之外，我还包含了以下功能：  frequency_of_reorder（用户重新订购产品的频率） product_mean_of_position（用户订单中的平均产品位置） prob_of_being_reordered（基于过去购买的重新订购概率） count_ord_no_prev_purchased_items（每个订单中的新商品数量） 每周每天的产品订单分布数量等。  征求建议：鉴于单一特征占主导地位，我正在寻找建议，以增强模型的稳健性和泛化能力，同时降低 auc（&gt; 0.80）。    提交人    /u/ds_reddit1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd9q9f/d_seeking_advice_on_improving_robustness_of/</guid>
      <pubDate>Sun, 27 Oct 2024 12:21:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我必须为我的大学购买一台笔记本电脑。我是 AI&Ml 分支。这些是选项。请帮忙</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd9jig/d_i_have_to_buy_a_laptop_for_my_college_i_am_aiml/</link>
      <description><![CDATA[        由    /u/Surya_Bhai9 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd9jig/d_i_have_to_buy_a_laptop_for_my_college_i_am_aiml/</guid>
      <pubDate>Sun, 27 Oct 2024 12:10:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医学 AI：顶级 LLM 研究论文/模型（10 月 19 日至 10 月 26 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd6k6j/d_last_week_in_medical_ai_top_llm_research/</link>
      <description><![CDATA[      医学 AI 上周：顶级 LLM 研究论文/模型（10 月 19 日至 10 月 26 日） 本周医学 AI 论文：  谷歌使用生成式 AI 进行医学摘要的安全原则  本文讨论了在医疗保健领域应用大型语言模型 (LLM) 的潜力和挑战，重点关注生成式 AI 支持各种工作流程的前景。医学 LLM 和其他模型：   医学法学硕士及其他模型：  BioMistral-NLU：医学词汇理解  本文介绍了 BioMistral-NLU，这是一种可通用的医学 NLU 模型，在 MNLU-Instruct 数据集上进行了微调，以提高专门医学任务的性能。 BioMistral-NLU 在来自 BLUE 和 BLURB 基准的六个 NLU 任务的零样本评估中优于现有的 LLM，如 ChatGPT 和 GPT-4。  用于生物医学任务的双语多模态 LLM  本文介绍了 MedRegA，这是一种新型的区域感知医学多模态大型语言模型 (MLLM)，该模型在名为 MedRegInstruct 的大规模数据集上进行训练。  用于临床分析的代谢增强 LLM  本文介绍了代谢途径驱动的提示 (MPP)，通过将代谢途径的领域知识整合到 LLM 中来增强临床时间序列数据中的异常检测。  皮肤病学基础模型  本文介绍了 PanDerm，这是一种多模态皮肤病学基础模型，在 11 家临床机构和 4 家影像模式。   框架和方法：  回到过去：医学 Deepfake 检测 用于水晶设计的混合 GenAI VISAGE：用于手术的视频合成 MoRE：多模态 X 射线/ECG 预训练 SleepCoT：通过 CoT 实现个性化健康  医学 LLM 应用：  ONCOPILOT：肿瘤 CT 模型 LMLPA：语言人格评估 用于医学培训的 GenAI  医学 LLM 和基准：  通过解释进行 LLM 评估 医学 LLM 幻觉的对比解码  医疗伦理中的人工智能：  通过讲故事进行医疗保健 XAI 临床 LLM 偏见分析 ReflecTool：反射感知临床代理  ... 完整线程详细信息：https://x.com/OpenlifesciAI/status/1850202986053808441    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd6k6j/d_last_week_in_medical_ai_top_llm_research/</guid>
      <pubDate>Sun, 27 Oct 2024 08:41:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有人有 wikitext-2-v1.zip 数据集文件或其他链接可以下载吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd36p9/r_does_anyone_have_wikitext2v1zip_dataset_file_or/</link>
      <description><![CDATA[大家好， 我正在尝试重现一个使用 wikitext-2 数据集的旧实验，并且它依赖于 torchtext 来导入它。但是，下载数据集的链接似乎不再有效。以下是损坏的链接： https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip 以下是相关的 torchtext 源代码，供参考： https://pytorch.org/text/0.12.0/_modules/torchtext/datasets/wikitext2.html 有人知道更新的链接或获取此数据集的解决方法吗？谢谢！    提交人    /u/reddo-lumen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd36p9/r_does_anyone_have_wikitext2v1zip_dataset_file_or/</guid>
      <pubDate>Sun, 27 Oct 2024 04:35:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 27 Oct 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 交叉验证后在完整数据集上进行训练？语义分割</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gct22r/d_train_on_full_dataset_after_crossvalidation/</link>
      <description><![CDATA[我目前正在进行燕麦叶病症状的语义分割项目。数据集很小，只有 16 张图像。由于时间限制，我无法扩展它。 我目前正在训练 3 个模型、3 个主干和 3 个损失 - 使用 5 倍交叉验证和网格搜索。 完成后，我计划对每个图像的几个不同级别的增强进行交叉验证。 我的问题是： 一旦我确定了最佳模型、主干、损失和增强组合，我可以在如此小的整个数据集上进行训练吗？如果我能做到这一点，我怎么知道何时停止训练以防止过度拟合但仍然充分学习数据？ 到目前为止，我附上了一些结果的图片。 https://preview.redd.it/sx394c58l5xd1.png?width=2000&amp;format=png&amp;auto=webp&amp;s=3cefbf5c84bf3fbf48936c47810c4e3039dcb410 感谢您提供的任何帮助提供！    由   提交  /u/Entire_Commission169   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gct22r/d_train_on_full_dataset_after_crossvalidation/</guid>
      <pubDate>Sat, 26 Oct 2024 19:38:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用神经网络进行形状限制回归</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gcpl03/p_shaperestricted_regression_with_neural_networks/</link>
      <description><![CDATA[前段时间在工作中，我们必须强制我们的模型学习一个特征的递增函数。例如，作为出价函数的中标概率应该增加。最近，我偶然发现了一篇关于使用形状限制函数进行回归的论文 https://arxiv.org/abs/2209.04476，我想通过实际的代码来训练这样的模型，让它更具体一些。 因此，我写了一篇博文：https://alexshtf.github.io/2024/10/14/Shape-Restricted-Models.html 还有一个带有随附代码的笔记本：https://github.com/alexshtf/alexshtf.github.io/blob/master/assets/shape_constrained_models.ipynb 我以前经常做广告。所以这种模型在这个行业似乎很有用——根据出价预测赢得广告拍卖的概率。我希望它在其他地方也有用。 所以我希望你会喜欢它！这是一个很大的“数学”，但你知道，它不可能是别的。    提交人    /u/alexsht1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gcpl03/p_shaperestricted_regression_with_neural_networks/</guid>
      <pubDate>Sat, 26 Oct 2024 16:58:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 任何设备上的实时角色动画</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gco234/p_realtime_character_animation_on_any_device/</link>
      <description><![CDATA[      我最近看到了阿里巴巴的这篇论文MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling，真的很有趣。浏览完论文后，我想，“嘿，可以使用一些开源工具复制这个工作流程！”我设法创建了一个可行的系统，该系统可以在设备上以 ~10fps 的速度实时运行，请注意，这是在一台配备 8 GB RAM 和 4 GB VRAM 的土豆笔记本电脑上运行的。 原始视频 重建视频 当前工作流程如下所示 -&gt; 1. 我使用 Tracking4All 创建了一个 Unity 应用程序，它可以从网络摄像头获取输入并使用 Mediapipe 生成动画姿势。 2. 接下来，我将这些生成的图像发送到 Python 服务器，该服务器接收原始帧、动画角色以及来自 Mediapipe 姿势的人物面具。 3. 最终使用 MI-GAN，我能够实时移除人物。 这个项目目前存在一些缺陷 1. MI-GAN 模型虽然速度很快，但却是主要的瓶颈。我尝试了 OpenCV 中提供的其他算法，但它们更糟糕、更慢（~1fps）。 2. 角色大小调整并不总是准确的，尽管可以在 Unity 中轻松调整。 3. 遮挡问题仍然是一个挑战。 此外，值得注意的是，Tracking4All 软件包需要许可证，这可能会限制可访问性。 是否有任何算法可以在各种设备（移动设备、Windows、Mac 和 Linux）上实时执行修复？ 该项目的目标是创建任何人都可以在任何设备上运行的端到端工作流程。这在 AR 和 VFX 中有许多应用程序！您对此有何看法？我接下来应该实现什么？   由    /u/Jazzlike-Shake4595  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gco234/p_realtime_character_animation_on_any_device/</guid>
      <pubDate>Sat, 26 Oct 2024 15:49:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于不同长度文本的 KV 缓存 - 请帮忙🙏</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gclcmk/d_kv_caching_for_varying_length_texts_help_please/</link>
      <description><![CDATA[        由    /u/themathstudent  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gclcmk/d_kv_caching_for_varying_length_texts_help_please/</guid>
      <pubDate>Sat, 26 Oct 2024 13:41:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻求针对 CVPR、ICML 等会议正在进行的完整论文的合作。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gcjfz1/r_looking_for_collaborations_on_ongoing/</link>
      <description><![CDATA[大家好， 我们小组，印度理工学院鲁尔基分校视觉与语言小组，最近有三篇研讨会论文被 NeurIPS 研讨会接受！🚀 我们还建立了一个网站 👉 VLG，展示我们参与过的其他出版物，因此我们的团队正在稳步建立 ML 和 AI 研究组合。目前，我们正在合作撰写几篇正在进行的论文，目的是向 CVPR 和 ICML 等顶级会议提交全文。 话虽如此，我们还有更多让我们兴奋的想法。尽管如此，我们的主要限制之一是无法获得适当的指导和 GPU 和 API 的资金，这对于试验和扩展我们的一些概念至关重要。如果您或您的实验室有兴趣一起工作，我们很乐意探索我们感兴趣领域的交集以及您可能带来的任何新想法！ 如果您有可用资源或有兴趣讨论潜在的合作，请随时联系我们！期待着建立联系并共同建立有影响力的东西！这是我们的 Open Slack 的链接👉 Open Slack    提交人    /u/vlg_iitr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gcjfz1/r_looking_for_collaborations_on_ongoing/</guid>
      <pubDate>Sat, 26 Oct 2024 11:59:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人知道 Eleven 实验室是如何设计提示音的吗？我想根据提示音生成新的声音，而不是声音克隆。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gcej8u/d_do_anyone_know_how_eleven_labs_is_designing_the/</link>
      <description><![CDATA[        由    /u/usama__01 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gcej8u/d_do_anyone_know_how_eleven_labs_is_designing_the/</guid>
      <pubDate>Sat, 26 Oct 2024 06:02:26 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 开源视频索引/标签/标签生成工具。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gccyhp/project_open_source_video_indexinglabellingtag/</link>
      <description><![CDATA[伙计们，我正在寻找一个开源工具或任何可以帮助我生成视频标签的 repo，以便对多个视频进行分类并进行进一步分析。 我想要的等价物是 Azure AI clvideo inxer，但如果有这样的开源工具，它将解决问题。    提交人    /u/jokingwizard   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gccyhp/project_open_source_video_indexinglabellingtag/</guid>
      <pubDate>Sat, 26 Oct 2024 04:18:33 GMT</pubDate>
    </item>
    <item>
      <title>一年的同行评审[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gbzxbf/one_year_of_peer_review_d/</link>
      <description><![CDATA[我的稿件已在 IEEE 上等待同行评审 10 个半月。上次我联系期刊询问情况时，他们告诉我正在寻找审稿人。距离上次发送邮件已经过去两个月了。期刊没有回复我。稿件仍在同行评审中。我的问题是，评审这么久是正常的吗？这是我的论文将被接受的好兆头吗？如果相反，他们会毫不犹豫地直接拒绝它吗？还是说评审这么久然后最终拒绝是正常的？这篇论文是关于自然语言处理的     提交人    /u/Distinct_Earth_2542   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gbzxbf/one_year_of_peer_review_d/</guid>
      <pubDate>Fri, 25 Oct 2024 17:35:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] 打破内存障碍：近乎无限的批量大小缩放以实现对比损失</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gbvapp/r_breaking_the_memory_barrier_near_infinite_batch/</link>
      <description><![CDATA[摘要 对比损失是一种强大的表征学习方法，其中较大的批量大小通过提供更多负样本来更好地区分相似和不相似数据，从而提高性能。然而，批量大小的扩展受到 GPU 内存消耗的二次增长的限制，这主要是由于相似性矩阵的完全实例化。为了解决这个问题，我们提出了一种基于图块的计算策略，将对比损失计算划分为任意小块，避免相似性矩阵的完全实现。此外，我们引入了一种多级平铺策略来利用分布式系统的分层结构，在 GPU 级别采用基于环的通信来优化同步，并在 CUDA 核心级别采用融合内核来减少 I/O 开销。实验结果表明，所提出的方法将批量大小扩展到前所未有的水平。例如，它能够使用 8 或 32 个 A800 80GB 对批处理大小为 4M 或 12M 的 CLIP-ViT-L/14 模型进行对比训练，而不会牺牲任何准确性。与 SOTA 内存效率高的解决方案相比，它在保持相当速度的同时实现了两个数量级的内存减少。代码将公开发布。    提交人    /u/RajonRondoIsTurtle   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gbvapp/r_breaking_the_memory_barrier_near_infinite_batch/</guid>
      <pubDate>Fri, 25 Oct 2024 14:16:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>