<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 28 Nov 2023 06:17:55 GMT</lastBuildDate>
    <item>
      <title>[N] 发现跨不同技能的令人兴奋的机会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185ovvp/n_discover_exciting_opportunities_across_diverse/</link>
      <description><![CDATA[嘿，机器学习社区！  对于那些在 IT、工程、医疗保健、生命科学等领域寻找职业机会的人来说，我们有好消息。目前全球有 250 个职位空缺，提供该领域的各种职位。 探索机器学习领域的可能性并找到您梦想的工作。在此处查看列表：https://www.compunnel.com/job-search/ &lt;不要错过提升职业生涯并为尖端项目做出贡献的机会。祝所有机器学习爱好者好运！请随意与任何可能感兴趣的人分享。    由   提交/u/digital-services-usa  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185ovvp/n_discover_exciting_opportunities_across_diverse/</guid>
      <pubDate>Tue, 28 Nov 2023 05:47:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 历史特征生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185n9kb/d_historical_feature_generation/</link>
      <description><![CDATA[我正在构建一个特征存储，我正在构建的特征之一是截至本周的特定值的平均值。但我还想生成该数据的历史回填。 假设我有从 2015 年 1 月 1 日开始的数据。我想计算截至 2023 年 11 月 27 日观看的视频的平均数量，它需要自 2015 年 1 月 1 日到 2023 年 11 月 27 日观看的所有视频并计算平均值。我还想生成截至 1 的平均值/1/2022 我必须获取从 1/1/2015 到 1/1/2022 的所有数据。我们该如何解决这个问题？ 我想到的一个解决方案是拥有一个控制表，其中包含从 2015 年 1 月 1 日开始的一周的一行，然后循环该表并生成平均值。 谢谢。   由   提交/u/mdghouse1986  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185n9kb/d_historical_feature_generation/</guid>
      <pubDate>Tue, 28 Nov 2023 04:13:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] SuGaR：用于高效 3D 网格重建和高质量网格渲染的表面对齐高斯喷射</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</link>
      <description><![CDATA[计算机视觉研究人员开发了一种方法，只需几分钟即可在单个 GPU 上根据图像创建详细的 3D 模型。他们的方法称为 SuGaR，通过优化数百万个微小粒子来匹配场景图像。关键的创新是让粒子与表面对齐，以便可以轻松地将它们变成网格。 传统的 3D 建模速度慢且资源繁重。激光扫描不方便。摄影测量点云缺乏细节。像 NeRF 这样的神经辐射场可以产生令人惊叹的渲染效果，但即使使用强大的硬件，将它们优化为网格也需要数小时或数天的时间。 VR/AR、游戏、教育等领域对更轻松的 3D 内容创建的需求不断增长。但大多数技术都有很大的速度、质量或成本限制，阻碍了它们主流使用。 这种新的 SuGaR 技术结合了神经场景表示和计算几何方面的最新进展，推动了最先进的技术的发展它首先利用一种称为高斯喷射的方法，该方法基本上使用大量微小粒子来复制场景。放置和配置粒子只需几分钟。问题是它们不会自然地形成连贯的网格。 SuGaR 提供了一种新的初始化和训练方法，可以将粒子与场景表面对齐，同时保持细节完整。这种条件允许将粒子云直接视为点云。 然后，他们应用一种称为泊松表面重建的计算技术，以并行方式直接在结构化粒子之间构建网格。一次处理数百万个粒子可以在低延迟的情况下实现高保真度。 通过将繁重的工作转移到前端点云结构化阶段，SuGaR 使最终网格生成与其他最先进的技术相比极其高效-艺术神经/混合方法。 实验表明，SuGaR 构建详细网格的速度比之前发布的技术快几个数量级，同时实现具有竞争力的视觉质量。该论文分享了一些在 10 分钟内重建复杂场景的有前景的示例。 处理更多样化的场景类型仍然存在问题。但就使用可访问的硬件使高质量 3D 重建更接近交互速度而言，这看起来是引人注目的进步。 TLDR：对齐高斯溅射中的粒子可让您将它们转变为详细的网格。使高质量 3D 更好、更快、更便宜。 完整摘要位于此处。论文网站此处。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</guid>
      <pubDate>Tue, 28 Nov 2023 02:37:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是正常现象还是我进错公司了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185fk7v/d_is_this_normal_or_im_just_at_the_wrong_company/</link>
      <description><![CDATA[我是一名初级 Python 开发人员。我在一家公司工作了一年多，差不多一年半了，我住在英国伦敦。自从他们雇用我以来，我一直在一个项目上独自工作，一个人工智能/数据科学项目，使用我以前从未使用过的技术，在一个我从未从事过的领域。我的任务是开发它，没有具体的截止日期，但要取得进展。 我想，好吧，太好了，我将有新的东西要学习。有一段时间效果不错，工作了几个月，然后他们给我分配了另一个项目去做。这另一个项目也充满了我以前从未使用过的新技术。所以，我正在做两个项目，我面临着越来越多的挑战，因为正如我提到的，许多事情都是新的，而且仍然是新的。我曾多次寻求帮助，但从根本上来说，我从未得到过帮助，因为事实证明，公司里没有人了解这个与人工智能相关的特定领域。后来我发现他们想出售这个产品（我一直在自己开发），这对我来说有点疯狂，因为我只是一个初级学生，以前从未做过这样的事情...... 我总是得到尝试自己解决问题的答复，因为他们无能为力。所以，我尝试独自完成，大量尝试、研究、重写、测试，我成功完成了项目的 90% 左右，但我陷入了困境。我不知道如何完成它，也没有得到任何帮助。我觉得我开始讨厌编程了。最糟糕的是，因为我没有完成它，因为我被卡住了，所以我被告知要决定我是否可以完成该应用程序，因为如果不能，他们就必须放弃它，那将是非常糟糕的。 .这是正常现象还是我进错公司了？工资也很低，没有福利，唯一好的“福利”就是就是它是完全远程的。 我总是听说我的表现非常好，我的工作受到赞赏，人们喜欢和我一起工作。然而，正因为如此，我担心他们会和我分道扬镳……不过，我想，也许这样是最好的吧？我的一些资深开发人员朋友告诉我，我一开始就不应该接受这份工作机会，但不幸的是，当时没有其他选择。 &lt;!-- SC_ON - -&gt;  由   提交/u/eldobhatobugyi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185fk7v/d_is_this_normal_or_im_just_at_the_wrong_company/</guid>
      <pubDate>Mon, 27 Nov 2023 22:19:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 扭曲、分散注意力、解码：指令调整模型可以优化其对噪声指令的响应</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185f16f/r_distort_distract_decode_instructiontuned_model/</link>
      <description><![CDATA[      ​ &lt; p&gt;https://preview.redd.it/4dvuvo18113c1。 png?width=1916&amp;format=png&amp;auto=webp&amp;s=4b9ba695cb00719c3e80c931f8b52a1008d7db5b 链接： https://openreview.net/forum?id=IqJ3CU3flr摘要：  虽然指令调整语言模型已经展示了令人印象深刻的零样本泛化能力，但这些模型通常难以生成准确的结果当面对超出训练集的指令时的反应。本文提出了指令解码（ID），这是一种简单而有效的方法，可以增强指令调整模型的效率。具体来说，ID 利用从原始指令的操纵版本（称为噪声指令）生成的预测，以对比方式调整下一个令牌预测的逻辑。这种嘈杂的指令旨在引发可能偏离预期指令但仍然合理的反应。我们对一系列此类噪音指令进行了实验，从通过随机单词插入语义噪音的指令到其他诸如引发偏差反应的“相反”指令。我们的方法在各种指令调整模型和任务中实现了可观的性能提升，而无需任何额外的参数更新。值得注意的是，利用“相反”作为 ID 中的噪声指令，与原始指令表现出最大的差异，在多个模型和任务中始终如一地产生最显着的性能提升。  https://preview.redd.it/6eymp2kb113c1.png?width=1174&amp; ;format=png&amp;auto=webp&amp;s=7613f4c269ca9107f88246fd5fa354670a5883a5 ​ https://preview.redd.it/kvtr8bvf113c1.png?width=2162&amp;format=png&amp;auto=webp&amp;s=ff4a414ed8 bdfc28d794d65d84311faa1a4ecf59&lt; /a&gt;   由   提交/u/Queasy_Ad_6423  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185f16f/r_distort_distract_decode_instructiontuned_model/</guid>
      <pubDate>Mon, 27 Nov 2023 21:58:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] WikiBio 上使用 SelfCheckGPT NLI 的自动幻觉检测实验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185byn6/r_automatic_hallucination_detection_experiments/</link>
      <description><![CDATA[      大家好， 我们最近在 HF 的博客上写了一篇关于使用不一致评分进行自动幻觉检测的文章。主要思想是，幻觉的发生是因为在训练集中看不到推理时要求的任务，这意味着对下一个标记的置信度较低，因此来自同一提示的样本不一致（https://arxiv.org/abs/2309.13638）。  我们看看 SelfCheckGPT NLI 的使用 (https://arxiv.org/abs/2303.08896) ，一个不一致评分的例子，在 WikiBio 上发现这样一个指标具有高精度（又名标记幻觉确实是）和校准召回（高分=标记幻觉的高机会）。 ​ https://preview.redd.it/dtptqylv3y2c1.png?width=1189&amp;format=png&amp;auto=webp&amp;s=db623d58e6b24f2f7eee57ff41115f544ee957be 这非常有前途，因为它可以打开拥有更可靠的人工智能系统的方法，也就是说，当任务很简单时，我们让人工智能来做。当我们发现它太难并且模型产生幻觉时，我们将人类放入循环中。 ​ https://i.redd.it/w7p9ciow3y2c1.gif 我们提供了：  一篇关于 HF 的文章博客：https://huggingface.co/blog/dhuynh95/automatic-hallucination-detection  Gradio 演示，用于查看实际指标：https://huggingface.co/spaces/mithril-security/ Hallucination_Detector  用于重现我们结果的 Colab 笔记本：https:// colab.research.google.com/drive/1Qhq2FO4FFX_MKN5IEgia_PrBEttxCQG4?usp=sharing   我们进行这些测试是为了构建机密且值得信赖的对话式 AI 使命的一部分。您可以在 https://github.com/mithril-security/blind_chat/    由   提交 /u/Separate-Still3770    reddit.com/r/MachineLearning/comments/185byn6/r_automatic_hallucination_detection_experiments/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185byn6/r_automatic_hallucination_detection_experiments/</guid>
      <pubDate>Mon, 27 Nov 2023 19:55:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] AISTATS 2024 论文评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185a6g4/d_aistats_2024_paper_reviews/</link>
      <description><![CDATA[AISTATS 2024 论文评论预计今天发布。我想为我们创建一个讨论线程来讨论任何问题/抱怨/庆祝或其他任何事情。 每年的评论都有很多噪音。考虑到 AISTATS 这些年的规模不断扩大，一些作者引以为豪的好作品可能会因为系统噪音而获得低分。我们应该记住，无论分数是多少，作品仍然有价值。   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185a6g4/d_aistats_2024_paper_reviews/</guid>
      <pubDate>Mon, 27 Nov 2023 18:41:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在法学硕士中实现多模式的有效方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1857geh/d_efficient_ways_to_achieve_multi_modality_in_llms/</link>
      <description><![CDATA[使用指令微调模型实现多模态的最佳方法是什么？   由   提交 /u/Inknown-Belt8671    reddit.com/r/MachineLearning/comments/1857geh/d_efficient_ways_to_achieve_multi_modality_in_llms/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1857geh/d_efficient_ways_to_achieve_multi_modality_in_llms/</guid>
      <pubDate>Mon, 27 Nov 2023 16:51:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你会痴迷地观看模特训练吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18576ol/d_do_you_obsessively_watch_your_models_train/</link>
      <description><![CDATA[我发现自己看张量板的时间多于工作——只是想知道其他陷入这种模式的人是否对生产力有什么建议   由   提交 /u/TehDing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18576ol/d_do_you_obsessively_watch_your_models_train/</guid>
      <pubDate>Mon, 27 Nov 2023 16:39:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] System 2 Attention（您可能也需要）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1854gp2/r_system_2_attention_is_something_you_might_need/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2311.11829 摘要：  基于 Transformer 的大型语言模型（LLM）中的软注意力是容易将上下文中的不相关信息合并到其潜在表示中，这会对下一代代币产生不利影响。为了帮助纠正这些问题，我们引入了 System 2 Attention (S2A)，它利用法学硕士以自然语言进行推理并遵循指示来决定要关注什么的能力。 S2A 重新生成输入上下文以仅包含相关部分，然后再处理重新生成的上下文以得出最终响应。在实验中，S2A 在包含意见或不相关信息、QA、数学应用题和长格式生成的三项任务上优于标准的基于注意力的法学硕士，其中 S2A 提高了事实性和客观性，并减少了阿谀奉承。   ​   由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1854gp2/r_system_2_attention_is_something_you_might_need/</guid>
      <pubDate>Mon, 27 Nov 2023 14:40:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] AI 生成的图像给文本图像检索带来了隐形的相关性偏差</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1853e5y/r_aigenerated_images_introduce_invisible/</link>
      <description><![CDATA[    &lt; /a&gt;  人工智能生成的图像为文本图像检索引入了无形的相关性偏差 [arxiv] https://arxiv.org/pdf/2311.14084.pdf 嘿 Reddit 社区， 我们将源偏差的研究扩展到多模态，我们很高兴分享我们对 AIGC 和文本图像检索模型的最新研究的有趣发现。以下是一个快速概述： (1) 揭示无形的相关性偏差：我们的研究发现，文本图像检索模型倾向于为人工智能生成的图像分配更高的排名，尽管与真实图像相比，它们不会显示与查询更具视觉相关性的信息。我们将这种现象称为“看不见的相关性偏差”。 （2）训练引起的更严重的偏差：进一步的探索表明，当人工智能生成的图像被纳入到随着文本图像检索模型的训练数据的增加，这种偏差变得更加严重。这揭示了一个令人担忧的恶性循环：看不见的相关性偏差增加了从海量数据集中获取生成图像的可能性。随后，这些图像更有可能混入AIGC模型和检索模型的训练中，加剧偏差。 （3）引入有效的缓解方法：根据这些发现，我们提出了一种高效的训练方法来减轻隐形相关性偏差。 （4）揭示这种偏差的原因：我们的分析和实验表明，不可见的相关性偏差是人工智能生成的图像导致图像编码器将附加信息嵌入到其表示中。这些信息在人工智能生成的不同语义的图像中具有一定的一致性，可以放大相关性得分。 ​ 隐形相关性偏差造成的恶性循环。 ​ 实验结果。 文本IR中来源偏差的原始论文和讨论在这里： Arxiv：https:// arxiv.org/abs/2310.20501 Reddit：https：/ /www.reddit.com/r/MachineLearning/comments/17l88lw/r_llms_may_dominate_information_access_neural/   由   提交/u/Latter-Confidence595  /u/Latter-Confidence595 reddit.com/r/MachineLearning/comments/1853e5y/r_ai generated_images_introduce_invisible/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1853e5y/r_aigenerated_images_introduce_invisible/</guid>
      <pubDate>Mon, 27 Nov 2023 13:50:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何让AI模型推理更快？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1851yrr/d_how_to_make_ai_model_infernce_faster/</link>
      <description><![CDATA[大家好， 我目前正在尝试为一些LM模型（如GPT2）和一些LLM（如llama或bloomz）提供服务。我尝试将 GPT2 转换为 TensorRT（基于 Nvidia 的文档）并与 Triton 服务器一起使用。输出也相当不错。但是如果想继续优化，还有没有更多的方法可以进行优化呢？而且我也很好奇如何让LLM模式能够同时服务很多用户。是否有任何架构或库可以用来做到这一点？   由   提交/u/HughLee_1999   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1851yrr/d_how_to_make_ai_model_infernce_faster/</guid>
      <pubDate>Mon, 27 Nov 2023 12:34:24 GMT</pubDate>
    </item>
    <item>
      <title>是否有兴趣重启最新研究的技术讨论？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/184rqtn/is_there_an_interest_in_resurrecting_technical/</link>
      <description><![CDATA[新研究的技术讨论似乎在这个 Reddit 子版块中大部分消失了，因为研究人员只占了 3e6 会员庞大读者群的一小部分。 所以我创建了一个 Reddit 子版块来主持此类讨论。 “安全空间”对于研究人员来说，如果你愿意的话，对内容有严格的标准。我在其中发布了一些我认为有趣的最近论文以及我自己对它们的看法，以开始讨论。 但后来我对自己说：“你没有时间管理 Reddit 子版块。你在做什么？并全部删除。尽管如此，我还是希望看到其他人，也许是有更多时间的人，尝试这样做。   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/184rqtn/is_there_an_interest_in_resurrecting_technical/</guid>
      <pubDate>Mon, 27 Nov 2023 02:07:18 GMT</pubDate>
    </item>
    <item>
      <title>[R]Andrej Karpathy 的“忙碌者对大型语言模型的介绍”视频的阅读列表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/184qeuo/reading_list_for_andrej_karpathys_busy_persons/</link>
      <description><![CDATA[我喜欢 Andrej 在他的“Busy person&#39;s intro to Large Language Models”视频中的演讲，因此我决定创建一个阅读列表来更深入地了解很多话题。我觉得他在为从机器学习研究员到任何有兴趣了解更多信息的工程师描述最新技术方面做得非常出色。 完整的演讲可以在这里找到：https://youtu.be/zjkBMFhNj_g?si=fPvPyOVmV-FCTFEx 这是阅读列表：&lt; a href=&quot;https://blog.oxen.ai/reading-list-for-andrej-karpathys-intro-to-large-language-models-video/&quot;&gt;https://blog.oxen.ai/reading- list-for-andrej-karpathys-intro-to-large-language-models-video/ 如果您还有其他要添加的论文，请告诉我！   由   提交 /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/184qeuo/reading_list_for_andrej_karpathys_busy_persons/</guid>
      <pubDate>Mon, 27 Nov 2023 01:02:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>