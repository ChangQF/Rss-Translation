<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 09 Oct 2024 09:18:38 GMT</lastBuildDate>
    <item>
      <title>[R] 多解码器模型的损失函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fzn4c8/r_loss_function_for_multiple_decoder_model/</link>
      <description><![CDATA[你好！ 我正在使用单编码器 - 多解码器模型进行分割（二进制分割）。它现在在 BCE w LogitsL 上工作，因为我正在尝试匹配基线并且它考虑了整体平均损失。 有没有比使用平均损失（bce、dice 等）更好的方法，因为所有类别的类别比率差异很大，我觉得我的一些类别拟合不足，而我的模型开始整体过度拟合。 对于这种情况有什么方法吗？有什么想法吗？    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fzn4c8/r_loss_function_for_multiple_decoder_model/</guid>
      <pubDate>Wed, 09 Oct 2024 09:07:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人尝试过结合 Adagrad 和 Adam 优化器吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fzm4w2/d_has_anyone_tried_combining_adagrad_and_adam/</link>
      <description><![CDATA[      基本上就是标题。我在想如果我们能够利用 Adam 和 Adagrad 的力量，那么我们就可以改变学习率以及动量和 RMS。 这是更数学的版本：- https://preview.redd.it/r18fcv4crotd1.png?width=498&amp;format=png&amp;auto=webp&amp;s=0b72fbe7118ac918bcfd047cb9ef78018b0531fd   由    /u/lel_73  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fzm4w2/d_has_anyone_tried_combining_adagrad_and_adam/</guid>
      <pubDate>Wed, 09 Oct 2024 07:48:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 请为我指明正确的方向，以便进一步探索我在人工智能对齐方面的思路</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fzkh4y/d_please_point_me_in_the_right_direction_for/</link>
      <description><![CDATA[我不是研究人员，也不从事人工智能或其他任何工作，但我对它很感兴趣，最近我一直在阅读大量与我的想法相关的研究论文。我试图解决的问题是，为强化学习人工智能提供什么目标函数，以便它能够对有意识的代理产生同理心并帮助他们实现目标。我基本上是在尝试解决协作逆向强化学习，但人工智能并不知道它应该帮助谁，所以它可以帮助任何像代理一样行事的东西。我的假设是，像代理一样行事的东西很可能是有意识的，而这种情况不成立的情况并不重要。我对这个奖励函数感兴趣的原因是，我希望人工智能能够学习友好性，而不会受到标记示例的瓶颈限制，并且我希望它能够推广到帮助动物等非人类。一个主要挑战是如何在不访问动作标签的情况下进行逆向强化学习，而解决方案将使它变得更容易。例如，仅从视频中推断目标。我基本上是在试图提出一个仁慈的目标函数。 我目前正在思考的线索是赋权（行动和世界状态之间的相互信息）。我认为你可以通过从他们的联合赋权中减去他们的个人赋权来衡量两个代理之间的一致性。当他们合作时，这个指标大概是正的。当他们独立工作时，它会是零，当他们竞争时，它会是负的。通过最大化这一点，人工智能可以解释当帮助一个代理导致另一个代理处于劣势时浪费的努力。一旦纠正了这一点，如果你通过最大化他们的个人赋权来帮助代理，这些术语就会取消，你只需要最大化他们的联合赋权。最大化联合赋权与最大化个人赋权加上一致性相同。合乎逻辑的结论是，为了赋予每个人权力，您需要最大限度地赋予联合代理权力，该代理的行为等于世界状态本身。 然而，赋权只是一个工具性目标。一旦您联合赋予每个人权力，您就需要衡量他们被赋予了什么权力并为此提供帮助，即使这会降低赋权。也许这意味着您只是直接对这个整体代理进行协作逆向强化学习，该代理的行为就是世界状态。然而，这似乎只是加速主义，可能会有问题。我也不知道如何考虑到这个“世界代理”在尚未获得权力时可能不合理的想法。 如果这个“世界代理”的想法没有成功，我又回到了如何检测代理类行为并添加所有这些代理的偏好的问题上。我当然希望有更多选择，但我还没有想到其他任何事情。请向我展示任何与此相关的研究。    提交人    /u/NeuroPyrox   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fzkh4y/d_please_point_me_in_the_right_direction_for/</guid>
      <pubDate>Wed, 09 Oct 2024 05:42:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] Hugging Face CLI 自动完成功能可更轻松地下载模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fzj4d1/p_hugging_face_cli_autocompletion_for_easier/</link>
      <description><![CDATA[用法 $ huggingface-cli download google/ 按 TAB 键，系统会提示可用的模型：  google/codegemma-7b google/flan-t5-xl google/gemma-2-2b-jpn-it-pytorch google/matcha-plotqa-v2 google/gemma-2-9b google/owlvit-base-patch32 google/gemma-2-9b-it google/paligemma-3b-pt-224 google/gemma-2b google/pegasus-cnn_dailymail google/gemma-2b-it google/siglip-so400m-patch14-384 google/gemma-7b google/timesfm-1.0-200m  安装 curl -sSL https://huggingface.co/spaces/pavel321/huggingface-cli-completion/resolve/main/huggingface-cli-completion.sh &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc     提交人    /u/RetiredApostle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fzj4d1/p_hugging_face_cli_autocompletion_for_easier/</guid>
      <pubDate>Wed, 09 Oct 2024 04:13:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人对 Jaynes 的概率论与科学逻辑的讨论小组感兴趣吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fzf7b7/d_anyone_interested_in_a_discussion_group_for/</link>
      <description><![CDATA[已经阅读这本书一段时间了，对某些章节感到很纠结，不知道大家是否感兴趣    提交人    /u/Illustrious-Pay-7516   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fzf7b7/d_anyone_interested_in_a_discussion_group_for/</guid>
      <pubDate>Wed, 09 Oct 2024 00:39:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] 扩散模型是进化算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fzbvq3/r_diffusion_models_are_evolutionary_algorithms/</link>
      <description><![CDATA[摘要：在机器学习和生物学的融合中，我们揭示了扩散模型是进化算法。通过将进化视为去噪过程，将逆向进化视为扩散，我们从数学上证明了扩散模型本质上执行进化算法，自然包含选择、突变和生殖隔离。基于这种等价性，我们提出了扩散进化方法：一种利用迭代去噪（最初在扩散模型的背景下引入）的进化算法，以启发式方式改进参数空间中的解决方案。与传统方法不同，扩散进化可以有效地识别多个最优解，并且优于著名的主流进化算法。此外，利用扩散模型中的先进概念，即潜在空间扩散和加速采样，我们引入了潜在空间扩散进化，它可以在高维复杂参数空间中找到进化任务的解决方案，同时显着减少计算步骤。扩散和进化之间的这种相似性不仅连接了两个不同的领域，而且为相互增强开辟了新的途径，提出了关于开放式进化的问题，并可能在扩散进化的背景下利用非高斯或离散扩散模型。    提交人    /u/ptuls   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fzbvq3/r_diffusion_models_are_evolutionary_algorithms/</guid>
      <pubDate>Tue, 08 Oct 2024 22:01:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从本地笔记本在云中运行代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fz5r5t/d_run_code_in_the_cloud_from_a_local_notebook/</link>
      <description><![CDATA[      我想分享一个我们构建的新 Python 库，它可让您从本地 Jupyter 笔记本编写和运行云函数。 它是如何工作的？ 当您运行笔记本单元时，代码会在云中强大的服务器上执行，而不是在您的笔记本电脑上。 来自远程服务器的日志会流回您的笔记本。感觉就像代码仍在本地笔记本中运行，但实际上是在远程运行。 https://preview.redd.it/aj7k4uy9jktd1.png?width=790&amp;format=png&amp;auto=webp&amp;s=e24f7d1580ab01472cf4b529335ba3ae266ea4be 好处  无需使用云笔记本，即可在云上进行开发。  如果您曾经使用过云笔记本，您的云笔记本可能崩溃了，您的工作也丢失了。  这可让您在本地低功耗系统上进行开发，同时将计算传输到云端。 本地文件自动与云运行时同步  您可以在远程函数执行中使用本地机器上的文件。无需从 Google Drive 或 S3 上传和下载权重。  您可以跨单元混合搭配计算  您的训练代码是否需要与推理代码相同的硬件？可能不需要。这可让您逐个函数自定义笔记本中使用的硬件。  如果您尝试一下，我们会很高兴！如果您有任何功能想法或建议，请告诉我们。  示例笔记本： https://github.com/beam-cloud/examples/blob/main/jupyter_notebooks/beam-notebook.ipynb 网站：https://beam.cloud 文档：https://docs.beam.cloud    提交人    /u/velobro   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fz5r5t/d_run_code_in_the_cloud_from_a_local_notebook/</guid>
      <pubDate>Tue, 08 Oct 2024 17:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于比较二项式比例的客观贝叶斯推断</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fz49wf/p_objective_bayesian_inference_for_comparing/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fz49wf/p_objective_bayesian_inference_for_comparing/</guid>
      <pubDate>Tue, 08 Oct 2024 16:40:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 差分变压器 (微软研究院)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fz0pya/r_differential_transformer_microsoft_research/</link>
      <description><![CDATA[摘要：Transformer 倾向于将注意力过度分配到不相关的上下文中。在本文中，我们引入了 Diff Transformer，它可以在消除噪音的同时放大对相关上下文的注意力。具体而言，差分注意力机制将注意力分数计算为两个单独的 softmax 注意力图之间的差值。减法消除了噪音，促进了稀疏注意力模式的出现。语言建模上的实验结果表明，Diff Transformer 在扩大模型大小和训练 token 的各种设置中均优于 Transformer。更有趣的是，它在实际应用中具有显着优势，例如长上下文建模、关键信息检索、幻觉缓解、上下文学习和减少激活异常值。通过减少不相关上下文的干扰，Diff Transformer 可以减轻问答和文本摘要中的幻觉。对于上下文学习，Diff Transformer 不仅提高了准确性，而且对顺序排列也更具鲁棒性，这被认为是一个长期存在的鲁棒性问题。结果将 Diff Transformer 定位为一种高效且有前途的架构，可以推进大型语言模型的发展。    提交人    /u/Decent_Action2959   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fz0pya/r_differential_transformer_microsoft_research/</guid>
      <pubDate>Tue, 08 Oct 2024 14:10:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 节能语言模型只需要加法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fz0jza/r_addition_is_all_you_need_for_energyefficient/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fz0jza/r_addition_is_all_you_need_for_energyefficient/</guid>
      <pubDate>Tue, 08 Oct 2024 14:03:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] SWE-bench Multimodal：AI 代理是否可以推广到视觉软件领域？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fyzo4x/r_swebench_multimodal_do_ai_agents_generalize_to/</link>
      <description><![CDATA[嗨！ 我们刚刚推出了 SWE-bench Multimodal！ 它有 617 个全新的任务实例 - 在每个实例中，代理都会根据其修复 17 个 JavaScript GitHub 存储库之一中的真实错误的能力进行评估。我们在此数据集中使用的所有错误在问题文本中都有图像。并且所有存储库都是面向用户的库，如映射、绘图和 Web UI 库。 以下是 SWE-bench Multimodal 中的一些示例错误及其相关图像 此数据集对现有的开源代理（包括 Agentless、AutoCodeRover 和 Moatless）来说极具挑战性。我们制作了一个新版本的 SWE-agent，能够正确解决 12% 的问题。我们新的多模式 SWE 代理能够对正在编辑的网页进行截图，以便迭代修复视觉错误。 https://preview.redd.it/0n5kqqzg9jtd1.png?width=1256&amp;format=png&amp;auto=webp&amp;s=60a54b411436987d1036909ab5d6b0a4e7513a29 论文：https://arxiv.org/pdf/2410.03859 我们对这篇论文感到非常兴奋，并认为在这个方向上还有很大的研究空间。 如果你有任何问题，我会在这里，你也可以在 COLM 找到我。    提交人    /u/ofirpress   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fyzo4x/r_swebench_multimodal_do_ai_agents_generalize_to/</guid>
      <pubDate>Tue, 08 Oct 2024 13:22:13 GMT</pubDate>
    </item>
    <item>
      <title>[N] 2024 年诺贝尔物理学奖授予 ML 和 DNN 研究人员 J. Hopfield 和 G. Hinton</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fywi9h/n_2024_nobel_prize_for_physics_goes_to_ml_and_dnn/</link>
      <description><![CDATA[公告：https://x.com/NobelPrize/status/1843589140455272810 我们的学生 John Hopfield 和 Geoffrey Hinton 因其在机器学习和深度学习方面做出的奠基性贡献而获得了 2024 年诺贝尔物理学奖！ 我听到远处传来施米德胡贝愤怒的声音！ 严肃地说，尽管这个选择非常令人惊讶，但我总体上还是很高兴的——作为一名对机器学习有着浓厚兴趣的物理学家，我喜欢这个物理-机器学习电影宇宙交叉。 对 Hopfield 和 Hinton 的限制可能会引发关于{Hopfield、Hinton、 LeCun、Schmidhuber、Bengio、Linnainmaa 等} 是现代 ML/DL/AI 成功的关键。Schmidhuber 尤其积极参与这一讨论。 然而，核心物理学界的反应相当复杂，如 /r/physics 主题 所示。在那里，人们注意到了与物理学研究的缺失环节/联系，以及 24 年物理学研究人员奖的“同时丢失”。    提交人    /u/PrittEnergizer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fywi9h/n_2024_nobel_prize_for_physics_goes_to_ml_and_dnn/</guid>
      <pubDate>Tue, 08 Oct 2024 10:26:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] GPT-2 电路 - 映射简单 LLM 的内部工作原理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fymczh/p_gpt2_circuits_mapping_the_inner_workings_of/</link>
      <description><![CDATA[我构建了一个应用程序，它使用 GPT-2 架构从模型中提取可解释的“电路”。虽然一些教程提供了 LLM 中的层如何产生预测的假设示例，但此应用程序提供了流经系统的信息的具体示例。例如，您可以看到搜索简单语法模式并将其构造追溯到更原始特征的使用的特征的形成。如果您正在研究可解释性，请查看！我很乐意听取您的反馈，并希望与可以提供帮助的人建立联系。项目链接：https://peterlai.github.io/gpt-mri/    提交人    /u/ptarlye   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fymczh/p_gpt2_circuits_mapping_the_inner_workings_of/</guid>
      <pubDate>Mon, 07 Oct 2024 23:51:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</guid>
      <pubDate>Sun, 06 Oct 2024 15:00:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>