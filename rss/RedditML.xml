<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 30 Aug 2024 03:17:25 GMT</lastBuildDate>
    <item>
      <title>[D]如何计算法学硕士 (LLM) 培训的 token/s 指标</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4i59f/dhow_to_calculate_the_metric_of_tokenss_for_llm/</link>
      <description><![CDATA[对于推理，可以通过 batch_size*max_generation_length/latency 获取 tokens。 但对于训练，例如 Megatron-DeepSpeed，这个指标是如何计算的？它的工作原理相同吗，还是公式不同？ 谢谢。 ML #LLM #training    提交人    /u/bigpeartree   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4i59f/dhow_to_calculate_the_metric_of_tokenss_for_llm/</guid>
      <pubDate>Fri, 30 Aug 2024 00:34:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 需要论文建议。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4fgr8/p_in_need_of_paper_suggestions/</link>
      <description><![CDATA[这学期我选修了神经网络课程，我需要做一个项目。该项目是一篇半新的 NeurIPS/ICLM/COLT 论文（或类似论文）的 1 小时演示 + 一篇 30 分钟的论文数值实验（计算）演示。 问题是，这是同一位教授的第二门机器学习课程，他建议这门课程必须与我们上学期的演示相关。就我而言，它是这样的：https://arxiv.org/pdf/1705.07809，这是使用互信息进行泛化的界限。问题是这篇论文太理论化了，很难进行数值实验。 教授同意我的观点，并建议做一些与算法稳定性和泛化有关的事情。所以我在这里问你们是否有任何建议。我将不胜感激 :)    提交人    /u/Buddharta   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4fgr8/p_in_need_of_paper_suggestions/</guid>
      <pubDate>Thu, 29 Aug 2024 22:29:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 根据零件编号描述文字对材料进行分类的模型建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4c4vq/d_model_suggestion_for_classification_of/</link>
      <description><![CDATA[免责声明：我不是 ML 专业人士，我只建立了少数几个模型，主要用于需求预测（在 R 中），有一次是根据不同组件的数量预测产品装配时间（在 Tensorflow/Keras 中）。 在我目前的职位上，我的任务是创建一个模型，该模型根据描述对材料进行分类，以简化问题，假设我们试图预测材料是否是成品，因此是经典的二元分类。 在将文本通过 tfidfvectorizer 后，我已经尝试了 scikit-learn 中的 MLPClassifier 和 SVC，以及 Xgboost，但模型在测试集上表现不佳。 数据集上的一些上下文，大约 10％ 的数据有标签 1，其余的有标签 0。材料描述不是很清晰，我编写了一些辅助函数进行预处理。 上述已尝试过的模型的混淆矩阵显示，对标签 0 进行分类的准确率约为 90%，对标签 1 进行正确分类的准确率约为 60%。 我的问题：  我如何才能知道这些数据是否真的好，它不像数值数据，我可以计算 X 和 y 之间的相关性？ 由于“最佳模型”的概念并不存在，我正在寻求适合此类应用的模型的建议。我应该用我的数据训练 Hugging Face 的法学硕士吗？还是应该使用 Pytorch 从头开始​​构建深度学习模型，并使用 Torchtext 进行标记？ 我是否应该减少标签 0 数据的数量，使数据集为 1:1？还是应该保持原样（9:1）？  非常感谢！   由    /u/HalfManHalfChimp  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4c4vq/d_model_suggestion_for_classification_of/</guid>
      <pubDate>Thu, 29 Aug 2024 20:08:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 实时推荐系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4allv/d_realtime_recommendation_system/</link>
      <description><![CDATA[我正在阅读有关 Twitter 的推荐算法的官方博客，其中谈到“排名是通过一个约 48M 参数的神经网络实现的，该神经网络在推文互动中不断训练，以优化积极参与度。”我试图了解它是如何根据用户互动不断训练神经网络的，就像 Twitter 的情况一样。  就上下文而言，我正在构建一个 Web 应用程序，基本上是一个社交新闻聚合器。它根据我自己的偏好（例如，只向我推送内容和 ML/LLM 上的人员）从 Reddit、Twitter 和 Hacker News 获取帖子和评论，并且不受广告和政治等干扰。我使用 Python、FastAPI 和 PostgreSQL 作为后端。您将如何设计应用程序架构以确保其性能卓越且准确？    提交人    /u/friedahuang   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4allv/d_realtime_recommendation_system/</guid>
      <pubDate>Thu, 29 Aug 2024 19:04:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么审稿人不需要对反驳作出回应？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f49zq2/d_why_arent_reviewers_required_to_respond_to/</link>
      <description><![CDATA[嗨， 我最近向一个会议提交了论文，很好奇为什么审稿人不需要承认反驳。显然，审稿人往往日程繁忙，而详细的回复往往具有挑战性。但我不明白为什么审稿人至少不需要处理反驳（即使是像“谢谢回复！”或“我很感谢补充信息，我正在更新我的分数以反映它”这样简单的话）    提交人    /u/mathwoman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f49zq2/d_why_arent_reviewers_required_to_respond_to/</guid>
      <pubDate>Thu, 29 Aug 2024 18:39:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审稿人反驳规范</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f49wo1/d_reviewer_rebuttal_norms/</link>
      <description><![CDATA[嗨， 我最近向一个会议提交了论文，很好奇为什么审稿人不需要回应反驳。显然，审稿人往往日程繁忙，但我不明白为什么审稿人不需要至少回应反驳（即使是像“谢谢回复！”或“我很感谢补充信息，我正在更新我的分数以反映它”这样简单的话）    提交人    /u/mathwoman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f49wo1/d_reviewer_rebuttal_norms/</guid>
      <pubDate>Thu, 29 Aug 2024 18:35:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在会议的反驳/讨论阶段更新论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f43dwv/d_updating_paper_during_the_rebuttaldiscussion/</link>
      <description><![CDATA[在会议的反驳/讨论阶段更新论文的规则是什么？ 有些会议明确表示不允许这样做。 NeurIPS 作者常见问题解答： 我们可以在反驳/讨论期间上传论文的修订版吗？ 在相机就绪阶段之前不允许进行任何修改。 ICML 作者说明： 在作者反馈期间没有上传论文修订版本的选项。论文被接受后，作者有权在最终的照相排版版本中对论文进行任何修改以改进论文（与审稿人看到的内容相比，本质上不改变其内容）。 但是，在查看前几年在 OpenReview 上发表的论文时，在反驳答案中，许多作者说：我们更新并上传了论文的修订版。.. 按照您的建议，我们在论文修订版的第 2 页进行了更改。 那么，作者是不是忽略了会议的官方声明，决定上传修订版？对于审稿人来说：如果作者在反驳阶段进行更改并上传新版本的论文，是不是更好？    提交人    /u/just_asking_21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f43dwv/d_updating_paper_during_the_rebuttaldiscussion/</guid>
      <pubDate>Thu, 29 Aug 2024 14:09:20 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]英特尔Arc A750机器学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f42r3f/discussion_intel_arc_a750_machine_learning/</link>
      <description><![CDATA[大家好，机器学习者们！我买了一块英特尔 Arc A750 8GB GPU。我一直在阅读英特尔关于在机器学习中使用它的一些文章。有人在机器学习中使用过英特尔 GPU 吗？    提交人    /u/Ferchitoqn   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f42r3f/discussion_intel_arc_a750_machine_learning/</guid>
      <pubDate>Thu, 29 Aug 2024 13:42:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将任何初学者问题发布至 r/MLQuestions！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3yfjg/d_post_any_bginner_questions_to_rmlquestions/</link>
      <description><![CDATA[我最近继承了 subreddit r/MLQuestions，因为其他版主分别有 10 个月和 4 年没有活动。我一直在整理子版块，添加标签、规则等，并试图增加参与度，使其对那些想要提问的人更有用。基本上就是 stackoverflow，但专门用于解决有关 ML 的初学者问题。所以，如果你们有不好意思在这里问的问题，请在 r/MLQuestions 上提问！我还将推出一个类似于 r/changemyview 的系统，其中每回答一个问题，他们的用户天赋就会增加一个，显示他们回答了多少问题！ 顺便说一句，版主允许我发布这篇文章，所以非常感谢你们，非常酷。    提交人    /u/NoLifeGamer2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3yfjg/d_post_any_bginner_questions_to_rmlquestions/</guid>
      <pubDate>Thu, 29 Aug 2024 09:50:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] Eagle：探索混合编码器的多模 LLM 的设计空间</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3yam7/r_eagle_exploring_the_design_space_for_multimodal/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3yam7/r_eagle_exploring_the_design_space_for_multimodal/</guid>
      <pubDate>Thu, 29 Aug 2024 09:40:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 澄清 VAE 中的“重新参数化技巧”以及为什么它是一个技巧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3ohje/d_clarification_on_the_reparameterization_trick/</link>
      <description><![CDATA[我一直在研究变分自动编码器 (VAE)，并且不断遇到术语“重新参数化技巧”。据我所知，该技巧涉及使用公式 (X = 平均值 + 标准偏差 * Z) 从正态分布中抽样，其中 Z 是从标准正态分布中抽取的。此公式似乎是从正态分布中抽样的标准方法 这是我的困惑： 为什么这是一个技巧？ 重新参数化“技巧”通常被强调为一个聪明的技巧，但对我来说，它似乎是转换公式的直接应用。如果 ( X = 平均值 + 标准差 * Z ) 是从正态分布中采样的唯一方法，那么为什么重新参数化技巧被认为特别具有创新性？ 我理解该技巧允许通过采样过程进行反向传播。但是，似乎使用 ( X = 平均值 + 标准差 * Z ) 是从给定 ( 平均值 ) 和 ( 标准差 ) 的正态分布中生成样本的唯一方法。除了确保可区分性之外，这个技巧还有什么特别之处？ 这是我的思维过程：我们从编码器获得平均值和标准差，并从中采样，唯一且最明显的方法是“X = 平均值 + 标准差 * Z”。 有人可以帮忙解释为什么重新参数化技巧被称为“技巧”吗？ 提前感谢您的见解！    提交人    /u/SwaroopMeher   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3ohje/d_clarification_on_the_reparameterization_trick/</guid>
      <pubDate>Wed, 28 Aug 2024 23:57:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于符号距离函数和体积数据结构的 Pytorch 库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3kdlb/p_pytorch_library_for_signed_distance_function/</link>
      <description><![CDATA[      体积数据结构库，通过提供梯度和不破坏自动微分，与 pytorch 生态系统良好交互。查看存储库：https://github.com/UM-ARM-Lab/pytorch_volumetric 您也可以通过以下方式安装 pip install pytorch-volumetric  在特定配置中对机器人进行有符号距离场查找的示例动画： https://i.redd.it/tcjvib45zgld1.gif    提交人    /u/LemonByte   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3kdlb/p_pytorch_library_for_signed_distance_function/</guid>
      <pubDate>Wed, 28 Aug 2024 21:05:23 GMT</pubDate>
    </item>
    <item>
      <title>“边缘写作 (WiM)”——一种更好的长上下文 LLM 推理模式，解决了中间丢失的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3d3uo/writing_in_the_margins_wim_a_better_inference/</link>
      <description><![CDATA[  由    /u/samjulien  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3d3uo/writing_in_the_margins_wim_a_better_inference/</guid>
      <pubDate>Wed, 28 Aug 2024 15:28:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过 Google 研究团队微调的 SD1.4 模型可玩 20FPS 的 Doom</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f31uye/r_playable_20fps_doom_via_a_finetuned_sd14_model/</link>
      <description><![CDATA[  由    /u/greentfrapp  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f31uye/r_playable_20fps_doom_via_a_finetuned_sd14_model/</guid>
      <pubDate>Wed, 28 Aug 2024 04:52:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>