<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 06 Feb 2025 06:24:31 GMT</lastBuildDate>
    <item>
      <title>[R] [D] 超高保真人类模仿的潜在用例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iivp2c/r_d_potential_use_case_of_ultrahigh_fidelity/</link>
      <description><![CDATA[您好 r/MachineLearning ！我们是加州大学伯克利分校附属研究团队，正在探索具有革命性的 AI 方向，我们需要您的见解来帮助塑造我们的研究。 我们的研究重点：超高保真人机交互 AI 我们正在开发一种先进的 AI 架构和数据管道，旨在创建极其精确的个人数字表示。我们的目标是从根本上改变人类在数字空间中的互动方式。主要特点：  角色表示的向量嵌入 无需针对每个用户进行微调 与真实人类交互难以区分 适用于任何需要高保真模仿的任务  潜在应用：  社交媒体增强：与真实朋友难以区分的人工智能交互 虚拟网络：超个性化的专业联系 记忆持久性：保存个性和记忆遗产 娱乐：游戏或虚拟世界中的超逼真 NPC 客户服务：完美量身定制的品牌代表  道德考虑： 我们认识到重大的道德影响，并致力于解决：  身份验证协议 同意和隐私框架 心理影响研究 滥用的可能性（例如，冒充、欺诈）  我们需要您的意见：  这项技术如何重塑您的数字互动？ 您预见到哪些令人兴奋的可能性或令人担忧的风险？ 您认为哪些道德保障措施是绝对必要的？ 这项技术的哪种应用最吸引您，社交媒体革命、记忆持久性、娱乐应用、专业网络或其他  为什么要参与？  影响尖端人工智能研究 在我们的出版物中获得认可 提前获取我们的研究结果  在我们探索这项变革性技术时，您的观点至关重要！    由   提交  /u/ComplexCountry   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iivp2c/r_d_potential_use_case_of_ultrahigh_fidelity/</guid>
      <pubDate>Thu, 06 Feb 2025 05:52:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人做过 hinge ML 面试吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iiupls/d_anyone_done_hinge_ml_interviews/</link>
      <description><![CDATA[以上    由   提交  /u/Horror_Weakness_6996   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iiupls/d_anyone_done_hinge_ml_interviews/</guid>
      <pubDate>Thu, 06 Feb 2025 04:53:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何创建/使用支持图像输入和文本响应的模型？我正在尝试制作一个带响应的身体特征分析仪。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iit2zz/d_how_can_i_createuse_a_model_that_support_image/</link>
      <description><![CDATA[基本上，我试图创建一些东西，我可以在其中输入一张/多张图片，并让模型根据我用作底片（不吸引人）的图片检测某些东西（例如有吸引力的背面），所有这些都基于我的偏好。我正在努力寻找任何类型的未经审查的 LLaVA。 我对这类东西的背景了解不多，我正在寻求帮助。 谢谢！    提交人    /u/Own_War8708   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iit2zz/d_how_can_i_createuse_a_model_that_support_image/</guid>
      <pubDate>Thu, 06 Feb 2025 03:24:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一致性模型：为什么模型不会崩溃？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iiqat3/d_consistency_models_why_doesnt_the_model_collapse/</link>
      <description><![CDATA[我一直在阅读一致性模型论文，它已经不是什么新鲜事了，我有几个问题。 如果不深入研究公式的细节，我对损失目标背后的直觉很好奇。更具体地说，为什么当使用一致性蒸馏和一致性训练损失时，模型不会崩溃？ 在我看来，无论输入是什么，模型都很容易崩溃并开始估计所有零输出，这将始终导致零损失值。 我也不明白目标背后的直觉。 任何见解都会对我有帮助，谢谢！ https://preview.redd.it/wa8qkxeo3fhe1.png?width=1138&amp;format=png&amp;auto=webp&amp;s=23f4e8e44ea095​​53b35ae0976c074fff057f314a https://preview.redd.it/3bpptxeo3fhe1.png?width=1140&amp;format=png&amp;auto=webp&amp;s=fd136fa42df794cc08e0db290ffc65d005f200e9    提交人    /u/batchfy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iiqat3/d_consistency_models_why_doesnt_the_model_collapse/</guid>
      <pubDate>Thu, 06 Feb 2025 01:04:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 针对 VQA 和 OCR 任务训练/微调 VLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iiq610/ptrain_finetuning_vlm_for_vqa_and_ocr_tasks/</link>
      <description><![CDATA[大家好，我正在寻找 vlm 来在我的自定义数据集上对 ocr 和 vqa 任务进行微调。有没有可用的教程和文档供我使用？    提交人    /u/LahmeriMohamed   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iiq610/ptrain_finetuning_vlm_for_vqa_and_ocr_tasks/</guid>
      <pubDate>Thu, 06 Feb 2025 00:58:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 谐波损失训练可解释的 AI 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iioy2i/r_harmonic_loss_trains_interpretable_ai_models/</link>
      <description><![CDATA[免责声明：不是我的作品！Arxiv 版本链接：https://arxiv.org/abs/2502.01628 交叉熵损失利用内积作为相似度度量，而谐波损失使用欧几里得距离。 作者证明，这种替代方法有助于模型在训练期间更快地缩小训练测试差距。 他们还展示了其他好处，例如驱动权重以反映类别分布，使其可解释。    提交人    /u/fliiiiiiip   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iioy2i/r_harmonic_loss_trains_interpretable_ai_models/</guid>
      <pubDate>Thu, 06 Feb 2025 00:00:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我开发了一个免费工具，利用机器学习来寻找相关工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iintmv/p_i_built_a_free_tool_that_uses_ml_to_find/</link>
      <description><![CDATA[链接：  https://filtrjobs.com 我为什么构建它： 大多数求职板都基于字符串匹配标题来工作，这对于 ML 来说很糟糕，因为标题很模糊 我厌倦了获得分析职位而不是数据科学职位，或者获得基础设施职位而不是 MLE 因此，我构建了自己的免费工具，将你的简历与招聘信息进行匹配，100％免费，无需注册 工作原理： 它会查看你的简历，将其嵌入，然后根据职位描述进行语义搜索。进行了许多实验，发现 cohere 是最好的嵌入模型。OpenAI 非常糟糕。开源甚至还没有接近 我如何免费运行它：  通过 aiven.io 免费获得 5GB postgres 从 galadriel.com 免费获得 LLM（免费 400 万个代币/天） 通过 heroku 免费托管（github 学生福利免费提供 24 个月） 免费 cerebras LLM 解析（使用 llama 3.3 70B，运行时间为半秒 - 比 gpt 4o mini 快 20 倍） 使用 posthog 和 sentry 进行监控（均提供慷慨的免费套餐）     提交人    /u/_lambda1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iintmv/p_i_built_a_free_tool_that_uses_ml_to_find/</guid>
      <pubDate>Wed, 05 Feb 2025 23:09:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] TTS 和 STT 是如何发展的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iilq85/d_how_are_tts_and_stt_evolving/</link>
      <description><![CDATA[有没有比以下更新 / 更好的东西： TTS：- coqui - piper - tortoise STT：- whisper - deepspeech 为什么 LLM 发展如此迅速，而这些领域却停滞不前？ 别误会我的意思，所有这些项目所做的事情都非常出色，只是下一代可能会更加不可思议    提交人    /u/HansSepp   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iilq85/d_how_are_tts_and_stt_evolving/</guid>
      <pubDate>Wed, 05 Feb 2025 21:41:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习用于编码孔径图像重建</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iikqxt/d_machine_learning_for_coded_aperture_image/</link>
      <description><![CDATA[我正在研究编码孔径 X 射线望远镜，并且正在探索机器学习是否可以提供比传统反卷积方法更好的结果。我对机器学习的背景知识知之甚少，可以使用一些指针。我找到了一些参考资料，但机器学习实现超出了我的理解范围。我有一个（小）原始图像集合及其重建，我可以使用它们来训练它，但我不确定如何实际设置问题。 这是一个与我所问的类似的参考资料。不幸的是，它位于 Elsevier 付费墙后面    提交人    /u/spacepbandjsandwich   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iikqxt/d_machine_learning_for_coded_aperture_image/</guid>
      <pubDate>Wed, 05 Feb 2025 21:01:28 GMT</pubDate>
    </item>
    <item>
      <title>[N] Deepseek 如何训练他们的 R1 模型，以及当今前沿 LLM 是如何训练的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iii013/n_how_deepseek_trained_their_r1_models_and_how/</link>
      <description><![CDATA[https://www.youtube.com/watch?v=aAfanTeRn84 Lex Friedman 最近发布了一篇名为“DeepSeek 的 GPU 优化技巧”的采访。这是一篇很棒的幕后花絮，展示了 Deepseek 在没有像美国同行那样多的 GPU 的情况下如何训练他们的最新模型。 需要是发明之母，Deepseek 做了几件事-  他们的专家混合配置非常创新，他们拥有非常高的稀疏因子，8/256 位专家激活。这比其他模型高得多，其他模型中 8 位专家中有​​ 2 位激活。  训练这个模型可能很难，因为只有少数专家真正学习并激活任务，这使得模型很弱。他们引入了辅助损失，以确保所有专家都用于所有任务，从而形成强大的模型。 混合专家模型的一个挑战是，如果只有少数专家激活，那么只有少数 GPU 可能会计算过载，而其余 GPU 则处于闲置状态。辅助损失也可以防止这种情况发生。 他们走得更远，实现了他们自己的 Nvidia NCCL 通信库版本，并使用更接近汇编级 PTX 指令来管理 GPU 中的 SM 如何为每个操作进行调度。这种低级优化使他们的模型在有限的硬件上具有非常高的性能。  他们还讨论了研究人员如何使用新的模型架构和数据工程步骤进行实验。他们说，在训练过程中，损失曲线会出现一些峰值，很难确切知道原因。有时训练后问题会消失，但有时 ML 工程师必须从较早的检查点重新开始训练。 他们还提到了 YOLO 运行，研究人员投入所有可用的硬件和预算来尝试获得前沿模型。他们可能会得到一个非常好的模型，也可能会在这个过程中浪费数亿美元。 这次采访实际上是对当今训练前沿 LLM 的幕后情况的一次非常好的深入观察。我很喜欢，我建议你也去看看！    提交人    /u/ml_guy1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iii013/n_how_deepseek_trained_their_r1_models_and_how/</guid>
      <pubDate>Wed, 05 Feb 2025 19:09:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 虚幻的安全：Redteaming DeepSeek R1 和 OpenAI、Anthropic 和 Google 最强大的可微调模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iif6qk/r_illusory_safety_redteaming_deepseek_r1_and_the/</link>
      <description><![CDATA[安全护栏是虚幻的。DeepSeek R1 的高级推理可以转化为“邪恶双胞胎”：同样强大，但安全护栏被剥离。GPT-4o、Gemini 1.5 和 Claude 3 也是如此。我们如何确保 AI 最大化利益同时最小化伤害？ 我们通过越狱调整来移除护栏：对带有有害响应的越狱提示进行微调。最初，开源和专有模型都会拒绝几乎所有有害请求。越狱调整后，它们几乎可以帮助解决所有问题：恐怖主义、欺诈、网络攻击等。 经过微调的模型会主动对之前拒绝的危险查询生成详细、精确且可操作的响应。 与基于微调的攻击相比，越狱提示可能不一致且产生质量较差的响应。 薄弱的安全护栏会给人一种虚假的安全感。对保障措施的过度自信可能意味着威胁不受控制——直到为时已晚。 我们该如何解决这个问题？ 😈 邪恶双胞胎评估 - 测试假设最坏情况滥用的预缓解模型。 🚧 红线 - 设定清晰、现实的伤害阈值 &amp;不要越过它们。 🚫 非微调人工智能 - 允许隐私和边缘设备等开放式优势，同时阻止有害的微调。 这不仅仅是一个企业或国家的问题。这是一个共同的挑战。 将人工智能视为一场竞赛——公司与公司、国家与国家、开放与封闭——将每个人都置于危险之中。如果我们想要安全的人工智能，全球合作，而不是竞争，是唯一的出路。 我们必须超越安全的幻想。我们关于越狱调整漏洞和人工智能安全漏洞的新研究将很快全面发布。同时，请查看我们的研究预览： 🔗 http://far.ai/post/2025-02-r1-redteaming/     提交人    /u/KellinPelrine   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iif6qk/r_illusory_safety_redteaming_deepseek_r1_and_the/</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer-Squared：自适应 LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iicsz0/r_transformersquared_selfadaptive_llms/</link>
      <description><![CDATA[      Sakana AI 的一个框架，允许 LLM 在推理时调整部分权重。 论文 | GitHub | 博客摘要 https://preview.redd.it/61pd7me6jche1.png?width=915&amp;format=png&amp;auto=webp&amp;s=b223fcb9369dc461c0b933669b1026f5eb46d351 摘要：  “自适应大型语言模型 (LLM) 旨在解决传统微调方法通常需要大量计算，并且在处理各种任务的能力上是静态的。我们引入了 Transformer-Squared，这是一种新颖的自适应框架，它通过选择性地调整权重矩阵的奇异分量，实时调整 LLM 以适应看不见的任务。在推理过程中，Transformer-Squared 采用两遍机制：首先，调度系统识别任务属性，然后使用强化学习训练的任务特定“专家”向量进行动态混合，以获得针对传入提示的目标行为。我们的方法始终优于 LoRA 等普遍使用的方法，具有更少的参数和更高的效率。此外，Transformer-Squared 展示了跨不同 LLM 架构和模态的多功能性，包括视觉语言任务。 Transformer-Squared 代表着一次重大的飞跃，它提供了一种可扩展、高效的解决方案，可增强 LLM 的适应性和特定任务性能，为真正动态、自组织的 AI 系统铺平了道路。&quot;  https://preview.redd.it/w5tey3kebche1.png?width=907&amp;format=png&amp;auto=webp&amp;s=15550138bac56f881d8981d5e45022c4cbf6c278 https://preview.redd.it/nb3rdwagbche1.png?width=962&amp;format=png&amp;auto=webp&amp;s=df98f74dea04365eefba9bf4004ba1c3c50a3359 结论：  在本文中，我们引入了 Transformer2，为实现自适应 LLM 提供了新颖的蓝图。在这个框架内，我们首先提出了 SVF，它比以前的微调方法性能更出色，同时成本更低、组合性更强、正则化过拟合——这些都是实现可扩展自适应的关键特性。利用一组 SVF 专家作为构建块，我们开发了三种有效的自适应策略，每种策略都具有独特的优势，并且随着测试时间条件的增加，性能优势也变得单调。 虽然 Transformer2 展示了令人鼓舞的结果，但未来仍有令人兴奋的发展机会。一个限制是 SVF 专家的能力与基础模型的潜在组件相关联。为了解决这个问题，模型合并提供了一个有希望的方向（Yu 等人，2024；Goddard 等人，2024；Akiba 等人，2024），使专门的模型能够组合成一个功能更强大的模型。此外，虽然我们基于 CEM 的适应性有效地平衡了性能和效率，但扩展到大量专门领域可能会增加一次性计算成本。然而，这种权衡被改进的性能和增强的自适应能力的好处所抵消。模型合并和高效适应技术的进步使得模型在开放排行榜上占据主导地位，使它们成为 Transformer2 基础模型的有力候选者，并为自适应 LLM 开辟了新的可能性。     提交人    /u/Jind0sh   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iicsz0/r_transformersquared_selfadaptive_llms/</guid>
      <pubDate>Wed, 05 Feb 2025 15:39:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前计算机视觉和语言技术领域不受欢迎的研究课题有哪些？ 2025</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</link>
      <description><![CDATA[不，我不想再听到有关 LLM 和 VLM 的更多信息了。    提交人    /u/KingsmanVince   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</guid>
      <pubDate>Wed, 05 Feb 2025 02:43:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>