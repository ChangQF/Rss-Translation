<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 09 Jan 2024 06:19:03 GMT</lastBuildDate>
    <item>
      <title>[D]设计一个反向传播网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1927zpc/d_design_a_counterpropagation_network/</link>
      <description><![CDATA[      这就是问题 ​ https://preview.redd.it/j1a9uvx6xcbc1.jpg?width=788&amp;format=pjpg&amp;auto=webp&amp;放大器； s=83cdc0f6f28bef95d76dbc1a9875f13148f55c85 我做了这个设计，但我无法处理更多 ​ https://preview.redd.it/7f7audi7xcbc1.jpg?width=899&amp;format= pjpg&amp;auto=webp&amp;s=926b987299d83f4b4a08adf9ec94a85344408f46 ​   由   提交 /u/Adept-Yak2242    reddit.com/r/MachineLearning/comments/1927zpc/d_design_a_counterpropagation_network/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1927zpc/d_design_a_counterpropagation_network/</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对话系统的多模态记忆和经验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1927zi6/d_multimodal_memory_and_experiences_for_dialog/</link>
      <description><![CDATA[      我认为，为了让人工智能和对话系统能够自主运行，它们应该具有多模态记忆和体验，例如场景记忆和情景记忆。 （就像电影《杨后》中出现的记忆[1]） 我正在考虑以下系统作为原型。 这是一个处理多模态的系统向量DB作为系统自身的记忆和经验，并使用系统自身的多模态记忆来响应人类的话语。 假设DB中存储的数据是与情景记忆相关的图像和文本的组合，例如如 MPCHAT [2]。 原型 然而，目前的多模态法学硕士专门研究从第三人称视角理解图像，并不能将图像视为系统自己的记忆或经验。 请让我知道是否有任何论文或技术可能有帮助！ 谢谢。 参考文献： [1] 杨的记忆场景来自 AFTER YANG，https://youtu.be/cIJ8-HGWlKw?feature=shared [2] MPCHAT：迈向基于角色的多模式对话， https://arxiv.org/abs/2305.17388  &amp; #32；由   提交/u/kassy11jp   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1927zi6/d_multimodal_memory_and_experiences_for_dialog/</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你们如何评价LLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1926ias/d_how_do_you_guys_evaluate_llm/</link>
      <description><![CDATA[你们如何评价LLM？有在线排行榜：https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard &amp; #x200b; 是否有任何脚本可以自动评估我们的离线/基准性能？   由   提交/u/Dense-Smf-6032   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1926ias/d_how_do_you_guys_evaluate_llm/</guid>
      <pubDate>Tue, 09 Jan 2024 04:54:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT4-V VS Gemini Pro Vision 完整版！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19268kz/d_gpt4v_vs_gemini_pro_vision_full_version/</link>
      <description><![CDATA[目前GPT和Gemini都只支持图片输入，不支持视频输入。因此，我只从Google Gemini demo中选择了与图像相关的测试来对比GPT-4-V和Gemini-Pro-Vision，测试内容包括：  图像内容的基本识别 对图像中的物体进行分析 对图像中的内容进行逻辑推理 连续图像内容的识别与分析  https://youtu .be/yFK62Tn_f4Q 如果您对视频中演示的开源项目感兴趣，请访问https://github.com/smalltong02/keras-llm-robot    由   提交 /u/Entire-Fly-6957   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19268kz/d_gpt4v_vs_gemini_pro_vision_full_version/</guid>
      <pubDate>Tue, 09 Jan 2024 04:39:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视频摘要有圣杯吗？像专业人士一样记录和检索！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1925m9k/d_is_there_a_holy_grail_for_video_summarization/</link>
      <description><![CDATA[嘿 Reddit 爱好者，我正在寻找终极视频摘要方法。不仅仅是普通的要点列表，而是丰富、详细和互动的内容。将其视为将每个视频变成可搜索的事件数据库，准备好回答我稍后提出的任何问题。 这是梦想的工作流程：  记录每个关键事件：捕获所有重要内容 - 人物、事件、地点、时间、原因。有人被绊倒吗？机器人跳舞了吗？记录下来！ 不错的细节：不仅仅是“人摔倒了”，但“笨拙的游客在博物馆入口外被香蕉皮绊倒。”描述性越强越好。 问答检索：稍后，我应该能够提出诸如“向我展示所有有趣的瀑布”之类的问题。或“机器人在讲话时说了什么？”并获得精确的视频片段作为响应。  我知道，这听起来雄心勃勃，但这可能吗？ 我探索了一些选择： 自动转录&amp;关键字提取：听起来很有希望，但可能会错过未说出口的事件（有人跌倒）。 人工注释：准确，但耗时且昂贵。 基于 AI/ML 的方法：总结逐帧进行，但我们失去了活动的时间流（例如：绕圈行走）。 所以，Reddit，我需要你的智慧！您是否遇到过任何接近我的视频摘要梦想的工具或技术？或者我在这里追逐独角兽？ P.S. 请随意用您自己的视频摘要困境和愿望劫持此线程！越多越好（我们离圣杯越近）！   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1925m9k/d_is_there_a_holy_grail_for_video_summarization/</guid>
      <pubDate>Tue, 09 Jan 2024 04:08:22 GMT</pubDate>
    </item>
    <item>
      <title>混合纸[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1924vn1/mixtral_paperd/</link>
      <description><![CDATA[https://arxiv.org/abs/2401.04088   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1924vn1/mixtral_paperd/</guid>
      <pubDate>Tue, 09 Jan 2024 03:31:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] WikiChat：通过维基百科上的少发基础来阻止大型语言模型聊天机器人的幻觉 - 在与人类用户关于最近主题的对话中实现 97.9% 的事实准确性，比 GPT-4 好 55.0%！ - 斯坦福大学 2023</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1920hky/r_wikichat_stopping_the_hallucination_of_large/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2305.14292v2  Github：https://github.com/stanford-oval/WikiChat  摘要：  本文提出了第一个基于 LLM 的少样本聊天机器人几乎从不产生幻觉，并且具有高会话性和低延迟。 WikiChat 以英语维基百科为基础，这是最大的精选自由文本语料库。  WikiChat 生成法学硕士的回复，仅保留有根据的事实，并将其与从语料库中检索到的其他信息相结合，形成事实且引人入胜的回复。 我们将基于 GPT-4 的 WikiChat 提炼为质量损失最小的 7B 参数 LLaMA 模型，以显着改善其延迟、成本和隐私，并促进研究和部署。  使用一种新颖的人类和法学硕士混合评估方法，我们证明我们最好的系统在模拟对话中达到了 97.3% 的事实准确性。它显着优于所有基于检索和基于 LLM 的基线，与 GPT-4 相比，在头部、尾部和近期知识方面分别提高了 3.9%、38.6% 和 51.0%。与之前最先进的基于检索的聊天机器人相比，WikiChat 的信息量和吸引力也显着提高，就像法学硕士一样。  WikiChat 在与人类用户就近期话题进行的对话中实现了 97.9% 的事实准确性，比 GPT-4 高出 55.0%，同时获得了更高的用户评分和更有利的评论。   https:/ /preview.redd.it/9mhpdh300bbc1.jpg?width=1225&amp;format=pjpg&amp;auto=webp&amp;s=cb64b717e920d7bf727782f7c803500ae838d6ef https://preview.redd.it/5dxesl200bbc1.jpg?width=862&amp;format=pjpg&amp;auto=webp&amp;s =b6de0cda980eec3cf3484ff1f9cd6dc1acf13505 https ://preview.redd.it/j387vl200bbc1.jpg?width=914&amp;format=pjpg&amp;auto=webp&amp;s=736fb922c1f98f4c7b132f1c153f4653a8b85441 https://preview.redd.it/3hnxqi200bbc1.jpg?width=923&amp;format=pjpg&amp;auto=webp&amp; ;s=95b40a9cf67d7f3729dae85878db67a262cc5201   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1920hky/r_wikichat_stopping_the_hallucination_of_large/</guid>
      <pubDate>Tue, 09 Jan 2024 00:07:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新颖研究项目的最佳资源/模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191zov1/r_best_resourcesmodel_for_novel_research_project/</link>
      <description><![CDATA[大家好， 我即将作为一名大学研究员开始一个新的研究项目，使用机器学习来优化设备需要周期性驱动波形。 我的目标是随着时间的推移监控该设备并生成任意波形，然后将生成的波形与测量的性能（可以是矢量、数字或其他东西）配对！这是一个问题我们正在调查）=&gt;生成新波形进行测试 =&gt;形成一个优化循环。 我在执行简单的回归任务、神经网络和树模型方面有很多经验，但我不知道这里到底要使用什么模型，而且我在闭环方面也没有太多经验循环 ML 优化框架。我与一位前项目合作伙伴进行了交谈，他建议使用 cVAE 或 cGAN 模型来避免与单个性能向量相关的小潜在空间的潜在问题。这些看起来合理吗？如果是这样，关于这些模型或此类优化机器学习框架，有什么好的资源/代码库/论文可供查看吗？ 任何帮助或建议都很棒！ 谢谢，  迪伦   由   提交 /u/redditdylanj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191zov1/r_best_resourcesmodel_for_novel_research_project/</guid>
      <pubDate>Mon, 08 Jan 2024 23:34:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在Python中选择pdf处理包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191uyuq/d_choosing_a_pdf_processing_package_in_python/</link>
      <description><![CDATA[我正在使用深度学习来理解文档，我必须处理大量 PDF 文档。我对 python 中的各种 pdf 处理包做了一些研究。以下是一些使用 Python 处理 pdf 的常用软件包。然而，我曾经对使用哪个包来执行不同的任务（例如合并 pdf、裁剪 pdf 和从 pdf 中提取文本）感到困惑。还有一个工具可以将扫描的 pdf 转换为可搜索的 PDF，这是我在研究之前不知道的。  PyPDF ：主要是 pdf 转换 Pdfminer.six：PDF 提取，包括布局信息 PdfPlumber ：在 PDFminer 之上添加表格提取功能 PyMuPDF ：最快的 PDF 处理，很多功能，包括 pdf 转换和文本提取、表格提取等&lt; /li&gt; OCRmyPDF ：转换扫描的 pdf到可搜索的 pdf  我还尝试在此博客中详细介绍该主题https://pythonify.com/blogs/pdf-packages-comparison-all-you-need-to-know 快乐的机器学习： )   由   提交/u/RelevantRevolution86  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191uyuq/d_choosing_a_pdf_processing_package_in_python/</guid>
      <pubDate>Mon, 08 Jan 2024 20:23:37 GMT</pubDate>
    </item>
    <item>
      <title>[P] NeuralRad：第一个免费使用器官和肿瘤分割云</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191sfl4/p_neuralrad_first_free_to_use_organ_and_tumor/</link>
      <description><![CDATA[       通过与国际原子能机构 (IAEA) 的合作，我们了解到大多数第三世界国家的医院不具备技术和相应的基础设施，无法为医生、神经外科医生和医学物理学家提供易于使用的解决方案，以使用人工智能轻松快速地勾勒出危险器官 (OAR) 或肿瘤的轮廓在患者治疗工作流程中。我们决定致力于此并对该领域产生影响。  经过两年的努力，我们想推出service.neuralrad.com，第一个免费使用全身器官-任何人都可以使用的风险 (OAR) 和肿瘤分割云平台。  我们使用一系列高性能 GPU 服务器（其中大多数是 Nvidia Geforce 4090 和 3090）构建此云平台，并且在任何特定时间动态分配超过100G的GPU内存，用于基于深度学习的快速分割推理。通过这项服务，我们希望帮助医学物理学家和医生解决放射治疗工作流程中棘手的病变和 OAR 分割问题。 p.s.该平台已被 IAEA 选择用于 IAEA 2023 年医学物理人工智能研讨会计划。 （https://www.iaea.org/events/evt2304232&lt;强&gt;)  免责声明：NeuralRad 云服务目前尚未获得 FDA 批准。我们建议将此服务用于研究和学习目的。 dicom 文件的所有患者信息都会在浏览器（客户端）端自动匿名，并且只有匿名的 dicom 数据才会发送到 NeuralRad 云服务器进行分段推理。  祝新年快乐！  新年快乐！ p&gt; ​ https://preview.redd.it/t5c9755dh9bc1.png?width=1746&amp;format=png&amp;auto=webp&amp;s=598b1337bcca5c8c70113003ed6679fb8b7fa78b https://preview.redd.it/ndji155dh9bc1.jpg?width=1853&amp;format=pjpg&amp; auto=webp&amp;s=53de4bdd072ed3c46229a34dcc7731425a8f1021 （注意：我们需要登录以避免滥用我们的 GPU 服务器阵列。它是免费使用的，只需注册一个帐户，我们将手动批准。）（平台演示视频可在此处观看：https://www.youtube.com/watch?v=UX_CIUcJ1uE）    由   提交 /u/coolwulf   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191sfl4/p_neuralrad_first_free_to_use_organ_and_tumor/</guid>
      <pubDate>Mon, 08 Jan 2024 18:42:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我构建了 marimo——一个开源的反应式 Python 笔记本，它存储为 .py 文件，可以作为脚本执行，并且可以作为应用程序部署。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191rdwq/p_i_built_marimo_an_opensource_reactive_python/</link>
      <description><![CDATA[嗨！我想分享 marimo，一个用于 Python 的开源反应式笔记本。它旨在解决 Jupyter 笔记本的许多众所周知的问题，同时为您提供新功能：marimo 笔记本可重复（无隐藏状态）、git 友好（存储为 Python 文件）、可作为 Python 脚本执行以及可部署为 Web 应用程序。 GitHub 存储库： https://github.com/marimo-team/marimo 在 marimo 中，您的笔记本代码、输出和程序状态保证是一致的。运行单元格并通过自动运行引用其变量的单元格来做出反应。删除一个单元格，marimo 就会从程序内存中清除其变量，从而消除隐藏状态。如果您担心意外触发昂贵的计算，您可以禁用特定单元格的自动运行。 marimo 还附带 UI 元素，例如滑块、数据帧转换器以及自动与 Python 同步的交互式绘图。与元素交互，使用该元素的单元格会自动以其最新值重新运行。反应性使这些 UI 元素比 Jupyter 小部件更有用，更不用说更易于使用。 我选择开发 marimo，因为我相信 ML 社区应该有一个更好的编程环境来进行研究和交流。我看到很多研究都是从 Jupyter 笔记本开始的（我自己的大部分也是这样）。由于 Jupyter 笔记本固有的缺陷，我还看到许多相同的研究无法重现或因隐藏的错误而减慢速度。 我坚信，我们的工作质量取决于我们的工作质量我们使用的工具塑造了我们的思维方式——更好的工具，更好的思维。 2017 年至 2018 年，我在 Google Brain 担任软件工程师，当时 TensorFlow 正在过渡到 TensorFlow 2，而 JAX 还处于早期阶段。我亲眼目睹了 PyTorch 和 JAX 为我们的社区带来的生产力的提高，后来当我在斯坦福大学与 Stephen Boyd 一起攻读博士学位时，我也亲眼目睹了我自己的研究。我们对 marimo 的目标是通过新的编程环境做一些类似的事情。 marimo 的开发经过了科学家和工程师的密切投入，并受到了包括 Pluto.jl 和 Streamlit 在内的许多工具的启发。只有我们两个人在研究它——我们最近将其开源，因为我们认为它已经准备好供更广泛的使用。请尝试一下（pip install marimo &amp;&amp; marimo 教程简介）。我们非常希望您能提供任何反馈！   由   提交 /u/akshayka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191rdwq/p_i_built_marimo_an_opensource_reactive_python/</guid>
      <pubDate>Mon, 08 Jan 2024 18:00:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 采访里奇·萨顿</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191oujg/d_interview_with_rich_sutton/</link>
      <description><![CDATA[一个多月前，我向这位订阅者询问了一些问题，以询问 Rich Sutton (此处），截至今天，完整采访内容可在 https:/ /youtu.be/4feeUJnrrYg！ Rich 有一些独特的想法 - 或者正如他喜欢说的 - 它是什么过时了，但我很好奇听听其他人之后的想法提出其中一些想法。 大纲： 0:00 - 简介 1:33 - 采访开始 2:04 - OpenMind 研究院4:32 - 人工智能的历史7:13 - 扩展容易吗？10:49 - 反向传播和反向传播的问题陈述21:22 - 狭隘视野的咆哮23:43 - 令人兴奋的新事物 32:00 - 记忆 35:34 - 提出想法 43 :47 - STOMP45:30 - Keen Technologies50:39 - 人类的下一阶段和未来情绪1:06:25 - 外星人工智能1:08:00 - 不同的研究方法1:21:30 - 里奇的建议1:26:00 - RL 牛肉1:27:07 - 将所有内容整合在一起    由   提交/u/ejmejm1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191oujg/d_interview_with_rich_sutton/</guid>
      <pubDate>Mon, 08 Jan 2024 16:17:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人脑 FLOPs 估计，是否比我们想象的要低？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191ol1n/d_human_brain_flops_estimate_is_it_lower_than_we/</link>
      <description><![CDATA[这篇文章旨在提供对人脑的深入了解，以便更容易将其与人工神经网络进行比较。 对我即将要说的大部分内容持保留态度，我很容易就会被一个数量级所影响，或者错过一些东西。  Ray Kurzweils 估计。 1011 个神经元。每个神经元有 1000 个突触连接。每秒 100 个峰值。  每秒计算 1011 × 1000 × 100=1016 次。 引用奇点临近：“考虑到人脑逆向工程的早期阶段，我将使用更保守的数字 1016 CPS”。  我自己的计算。自 2005 年以来情况似乎发生了变化，现在维基百科说每个神经元有 7000 个突触 https://en.m.wikipedia.org/wiki /Neuron  神经元放电速度平均为 0.1 到 2 赫兹。 https://aiimpacts.org/rate-of-neuron-firing/ #:~:text=Assorted%20estimates- 我将使用 1/s 作为尖峰频率。大脑也更明确，有 86,000,000,000 个神经元。 8,6×1010 × 7000 × 1 = 6×1014。 6×10 14 FLOP（每个突触一次 FLOP）。  峰值能量需求。神经元的每次激活都需要一定量的能量，该能量似乎为 2.468 × 10−7 J https://link.springer.com/article/10.1007/s11571-018-9503-3  所以从这里开始，其他一切都可以被弄清楚。尖峰能量 = 2.468 × 10−7 J 24 小时内大脑能量消耗 = 1,673,600 焦耳 24 小时内的秒数 = 86400。每个神经元有 7000 个突触。 1,673,600÷(2.468 × 10 −7) J = 6,782×1012。 6,782×1012 ÷ 86400 = 78,486,103。 (78,每秒 500 万次峰值）。 78,486,103 × 7000 = 5.49×1010 FLOP 或 549 gigaFLOPs 如果 3 正确，则意味着高端手机的 GPU 计算量比人脑的计算量还要多（三星 s23，fp32 时为 3,681 TFLOP。大脑一天平均为 0,549 TFLOP）。 这不是比较事物的好方法，因为大脑是一台大规模并行计算机，内存基本上存在于结构中。  那么需要多少“内存”呢？我们谈论的是大脑吗？我们有： 86,000,000,000 个神经元。每个神经元有 7000 个突触。每个突触 5 位。 https://www.cnsnevada.com/what-is-the-memory-capacity-of-a- human-brain/#:~:text=Neurons%20are%20the%20cells%20which 86,000,000,000 × 7000 × 5 = 3×1015 位或 3.76×1014 字节。祝你好运，在手机上安装 376 TB RAM。 但是每秒 78,500,000 个峰值真的足以让大脑处理所有事情吗？让我们看看眼睛。 每只眼睛的总分辨率为 8 兆像素。 https://m.youtube.com/watch?v=4I5Q3UXkGd0&amp;pp=ygUednNhdWNlIHJlc29sdXRpb 24gb2YgaHVtYW4gZXll&lt; /p&gt; 通过视神经发送的信息大约只有 10,000,000 位/秒 https://www.eurekalert。 org/news-releases/468943 （只有最相关的信息通过视神经发送，因为大脑希望不惜一切代价节省电量）。因此，我们的双眼每秒有 20,000,000 个尖峰，这是 7850 万个尖峰的 25.5%。 7850 万个尖峰并不是一个硬性的性能上限，它只是一天的平均值，而大脑是根据需要主动调节脑电波频率。 您认为哪种情况更有可能？ 1. 2. 或 3.   由   提交 /u/SpaceXRaptor42   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191ol1n/d_human_brain_flops_estimate_is_it_lower_than_we/</guid>
      <pubDate>Mon, 08 Jan 2024 16:05:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何猜测梯度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191lu3v/r_how_to_guess_a_gradient/</link>
      <description><![CDATA[      奇怪的是，你在不知道目标函数的情况下就知道梯度在哪里。 论文：https://arxiv.org/abs/2312.04709 摘要  关于梯度你能说多少无需计算损失或不知道标签的神经网络？这听起来可能是一个奇怪的问题：答案肯定是“很少”。然而，在本文中，我们表明梯度比之前想象的更加结构化。梯度位于可预测的低维子空间中，该子空间取决于网络架构和传入特征。利用这种结构可以显着改进基于方向导数的无梯度优化方案，该方案一直难以扩展到在玩具数据集上训练的小型网络之外。我们研究如何缩小计算精确梯度的方法和使用方向导数的方法之间优化性能的差距。此外，我们强调了克服精确梯度优化和猜测梯度之间巨大差距的新挑战。  https://preview.redd.it/l7tm982c28bc1.png?width=1962&amp;format=png&amp;auto=webp&amp;s=94d237353bc53ee b21489f6adeeaa8e43043f44a ​   由   提交/u/That_Violinist_18   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191lu3v/r_how_to_guess_a_gradient/</guid>
      <pubDate>Mon, 08 Jan 2024 14:00:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>