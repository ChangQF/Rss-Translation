<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 19 Apr 2024 09:14:29 GMT</lastBuildDate>
    <item>
      <title>[P] 如何从均方根中获取平均值和标准差以获得时间序列案例研究的第一个预测时间？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7s6ah/p_how_to_obtain_the_mean_and_std_from_the_rms_to/</link>
      <description><![CDATA[你好，我正在尝试从一篇论文中实现这一点：  首先，选择采样轴承故障点，计算其均方根值的平均值μ_rms和标准差σ_rms，并据此建立基于3σ准则的判断区间[μ_rms − 3σ_rms，μ_rms +3σ_rms]。 2) 其次，计算第l+1个点FPTl+1的RMS指数，并与步骤1中的判定区间进行比较。如果其值不在该范围内，则使l=l+1后重新计算判定区间如果其值在此范围内，则触发一次判断。 3）最后，为了避免误触发，以连续的3次触发作为最终FPT的识别依据，并使本次FPTl = FPT  论文标题：Physicsguided Neural Network网络：通过退化过程的动态加权，使用长短期记忆网络预测滚动轴承的剩余使用寿命 我的问题是：如何从 RMS 中获得 μ_rms 和 σ_rms？在本例中，我首先对数据进行采样，然后计算样本的 RMS。但随后我根据这些 RMS 值重新创建序列（这对我来说似乎不合逻辑），然后计算 μ_rms 和 σ_rms。我确实使用获得的这个值来计算间隔并将其与 RMS 值进行比较。但问题是，通过这样做，它触发得太早了。 这是我编写的代码： def find_fpt(rms_sample, sample): fpt_index = 0 触发器 = 0 for i in range(len(rms_sample)): upper = np.mean(rms_sample[i] + 3 * np.std(rms_sample[i])) lower = np.mean(rms_sample[i] - 3 * np.std(rms_sample[i])) rms = np.mean(np.square(sample[i + 1]) ** 2) if upper &gt;有效值&gt;下：如果触发器== 3：fpt_index = i中断触发器+= 1否则：触发器= 0 print(trigger) return fpt_index def moving_window(data, window_size): return np.lib.stride_tricks.sliding_window_view(data, window_size) window_size = 20 list_bearing, list_rul = load_dataset_and_rul() 采样 = slider_window(list_bearing[0][::100], window_size) rms_values = np.sqrt(np.mean(np.square(采样) ** 2, axis=1)) rms_sample = slider_window(rms_values, window_size) fpt = find_fpt(rms_sample,采样)    由   提交 /u/Papytho   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7s6ah/p_how_to_obtain_the_mean_and_std_from_the_rms_to/</guid>
      <pubDate>Fri, 19 Apr 2024 08:59:52 GMT</pubDate>
    </item>
    <item>
      <title>有什么方法可以改进 TabNet..？？？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7rfhv/any_ways_to_improve_tabnet_d/</link>
      <description><![CDATA[所以我正在尝试谷歌的 tabnet 架构https: //arxiv.org/pdf/1908.07442.pdf 发现如果数据有很多随机性和噪音，那么只有它才能根据我的数据集表现出色，但是像 xgboost、随机森林这样的传统机器学习算法在那些特征足够强大但未通过零样本测试的数据集上做得更好，而变压器在这方面表现出了一定的准确性，所以我只是想检查是否有可能将传统技术和变压器架构合并起来，以便它可以在传统的机器学习算法数据集上表现更好，并且还可以提供良好的零射击精度。在尝试合并它时，我发现在 tabnet 论文中，他们假设每个功能都是独立的，并且不为与功能本身的任何关系提供任何位置，但 Tabtransformer 架构将其考虑在内 https://arxiv.org/pdf/2012.06678.pdf 以及但没有 tabnet 中建议的任何功能选择....我尝试合并它们，但被卡在我必须根据分配给每个特征的维度进行特征选择的地方，而这项工作是由 Tabnet 论文中的稀疏最大完成的，我找不到办法做到这一点......任何帮助将不胜感激   由   提交/u/Shoddy_Battle_5397   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7rfhv/any_ways_to_improve_tabnet_d/</guid>
      <pubDate>Fri, 19 Apr 2024 08:06:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 从 3D 网格和物理场进行机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7r0tj/r_machine_learning_from_3d_meshes_and_physical/</link>
      <description><![CDATA[Ansys 发布了一款用于物理仿真的 AutoML 产品，名为 Ansys Sim AI (https://www.ansys.com/fr-fr/news-center/press-releases/1-9-24 -ansys-启动-simai）。作为一名机器学习工程师，我想知道可以使用哪些类型的模型来训练具有物理场的 STL 格式的 3D 网格数据。如何针对不同的几何对象管理不同维度的输入和输出数据？有人对这个话题有什么想法吗？    由   提交 /u/SatieGonzales   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7r0tj/r_machine_learning_from_3d_meshes_and_physical/</guid>
      <pubDate>Fri, 19 Apr 2024 07:38:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自动脚本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7qyfa/d_auto_scripting/</link>
      <description><![CDATA[过去几个月我一直在从事一个项目，我想知道是否有人有反馈或想法来推动其完成。我使用 python 和 C 标记构建了一个词法分析器和解析器，以创建一种读取 python 脚本或文件并利用钩子来修改或编写新行的语言。它甚至可以根据用户最初提供的单个提示，使用一个空白的 Python 文件来编写、测试和交付一个工作程序。 它的工作方式是使用 GPT API 来调用程序内置的自动提示。它仅使用用户在程序上的 1 个初始提示自行创建一个程序。它是一个 python 程序，内置了我命名为 autoscripter 的语言。如果不是明年的话，我希望能在今年年底完成。这是一个非常具有挑战性的项目，但我相信它是脚本的未来，并且我毫不怀疑微软迟早会发布这方面的东西。有什么想法吗？ 我首先通过设计一个对 python 代码进行错误纠正的调试器来创建这个，并意识到不仅错误纠正可以自动化，而且整个脚本编写过程也可以留给大量自动化。&lt; /p&gt;   由   提交 /u/starcrashing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7qyfa/d_auto_scripting/</guid>
      <pubDate>Fri, 19 Apr 2024 07:33:32 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 最近是否有特定的技术/科学突破使得多个大型语言模型的最大上下文长度显着跃升？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7pzf0/discussion_are_there_specific_technicalscientific/</link>
      <description><![CDATA[GPT-4 和 Claude 等模型的最新版本在最大上下文长度上有显着的跳跃（4/8k -&gt; 128k+）。这些模型可以处理的代币数量方面的进展听起来非常引人注目。 是什么导致了这一点？这纯粹是因为训练期间可用的计算量增加而发生的吗？是否有算法进步导致了这种情况？   由   提交 /u/analyticalmonk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7pzf0/discussion_are_there_specific_technicalscientific/</guid>
      <pubDate>Fri, 19 Apr 2024 06:28:48 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的概率[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7ocoq/probability_for_machine_learning_d/</link>
      <description><![CDATA[我是一名刚毕业的工程专业毕业生，正在从传统的软件工程岗位转换到专注于 ML/AI 的岗位。我在本科时学过概率入门课程，但最近的发展（例如扩散模型），甚至一些相对较旧的模型（例如 VAE 或 GAN）都需要对概率论有深入的了解。当我阅读这些模型时，我发现与概率相关的数学/概念很难理解。关于如何弥合知识差距有什么建议吗？    由   提交 /u/AffectionateCoyote86   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7ocoq/probability_for_machine_learning_d/</guid>
      <pubDate>Fri, 19 Apr 2024 04:47:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当我只有一组 PDF 文档时，如何评估 RAG - 检索和生成？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7oa6k/d_how_to_evaluate_rag_both_retrieval_and/</link>
      <description><![CDATA[假设我有 1000 个 PDF 文档，用作 RAG 管道的输入。 我想评估RAG 管道，以便我可以测量： - 哪些嵌入模型更适合我的数据？ - 哪些重新排序器有效并且需要它们？ - 哪些法学硕士给出了最真实和连贯的答案？ 我如何评估管道的这些步骤？ 根据我的研究，我发现大多数框架都需要标签来进行检索和世代评价。我如何使用法学硕士创建这些数据？还有其他技术吗？ 我发现的一些东西： 对于检索：使用 LLM 生成用于检索的综合排名标签。 我应该使用哪个法学硕士？我应该遵循哪些最佳实践？我可以查看任何代码吗？ 对于生成的文本： - 为每一代生成如上所述的合成标签。 - 使用法学硕士作为法官，根据所获得的背景和提出的问题对每一代进行评分。您会推荐哪些法学硕士？ 哪些技术对你们有用？   由   提交 /u/awinml1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7oa6k/d_how_to_evaluate_rag_both_retrieval_and/</guid>
      <pubDate>Fri, 19 Apr 2024 04:43:11 GMT</pubDate>
    </item>
    <item>
      <title>[项目] RL项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7o6eg/project_rl_project/</link>
      <description><![CDATA[大家好。 我想为一个班级项目构建我的这个想法，并且我需要其他人的一些意见。  我想构建一个可以玩漂移猎人游戏的人工智能算法（https://drift- Hunters.co/drift-hunters-games）。我想我必须构建一些强化学习程序，尽管我不确定如何组织状态表示和输入数据。我还想象我需要连续一段时间记录我的屏幕来收集数据。 我选择这个游戏是因为它有三个非常基本的命令（左转、右转和开车）前进），游戏的目的（永无止境）是最大化漂移分数。 任何想法都非常感激。如果您还需要更多信息，请告诉我。 谢谢大家。   由   提交/u/Valuable-Wishbone276   /u/Valuable-Wishbone276 reddit.com/r/MachineLearning/comments/1c7o6eg/project_rl_project/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7o6eg/project_rl_project/</guid>
      <pubDate>Fri, 19 Apr 2024 04:36:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人尝试过用旧方法提取大型语言模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7izc4/d_has_anyone_tried_distilling_large_language/</link>
      <description><![CDATA[因此，如今，每个人都在将从大型语言模型收集的基本原理提炼到另一个相对较小的模型中。然而，我记得从前我们在进行蒸馏时训练了小型网络以匹配大型网络的逻辑。这是忘记/尝试过并且今天不起作用吗？   由   提交 /u/miladink   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7izc4/d_has_anyone_tried_distilling_large_language/</guid>
      <pubDate>Fri, 19 Apr 2024 00:11:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 医疗领域基准上的 Llama-3（7B 和 70B）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7b35q/d_llama3_7b_and_70b_on_a_medical_domain_benchmark/</link>
      <description><![CDATA[      Llama-3 正在人工智能社区掀起波澜。我很好奇它在医学领域的表现如何，以下是 Llama-3（7B 和 70B）在由 9 个不同数据集组成的医学领域基准上的评估结果 https://preview.redd.it/sdwx5tglxbvc1.png?width=1464&amp;format= PNG&amp; ;auto=webp&amp;s=d32585a69244d44c83e2b1e8a85301a7a8676ea2 我会进行微调、评估和释放 Llama-3 和在接下来的几天里，我们将在不同的医疗和法律基准上获得不同的法学硕士。请关注此处的更新：https://twitter.com/aadityaura https://preview.redd.it/9egbcayv9avc1.png?width=1344&amp;format=png&amp;auto =webp&amp;s=436a972421d5568e1a544962b8cfd1c7b14efe04   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7b35q/d_llama3_7b_and_70b_on_a_medical_domain_benchmark/</guid>
      <pubDate>Thu, 18 Apr 2024 18:45:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] InternVL v1.5开源，OpenCompass多模态基准测试排名第一</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c780cd/r_internvl_v15_open_sourced_ranking_first_in/</link>
      <description><![CDATA[      https://internvl.opengvlab.com/ 模型下载： https://huggingface.co/collections/OpenGVLab/internvl-65b92d6be81c86166ca0dde4 OpenCompass： https://rank.opencompass.org.cn 一些示例： https:// Preview.redd.it/vtwjml3qm9vc1.png?width=2508&amp;format=png&amp;auto=webp&amp;s=e32c044d4bc60ef28baf64dccdcb5fe9b10dfc61 https://preview.redd.it/p51vt3xpn9vc1.png?width=2609&amp;format=png&amp;auto=webp&amp;s = 73907e5ffb4d9b9bd4250cbce53e3bd29dedabf1   由   提交 /u/flyforlight   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c780cd/r_internvl_v15_open_sourced_ranking_first_in/</guid>
      <pubDate>Thu, 18 Apr 2024 16:42:45 GMT</pubDate>
    </item>
    <item>
      <title>[N] Meta 发布 Llama 3</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c77f0m/n_meta_releases_llama_3/</link>
      <description><![CDATA[      https://llama.meta.com/llama3 /  ​ ​ /u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c77f0m/n_meta_releases_llama_3/</guid>
      <pubDate>Thu, 18 Apr 2024 16:18:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 压缩线性代表智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c76tpe/r_compression_represents_intelligence_linearly/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.09937 代码：https://github.com/hkust-nlp/llm-compression-intelligence 数据集：https://huggingface.co/datasets/hkust-nlp/llm-compression 摘要：&lt; /p&gt;  人们相信，学习良好的压缩会带来智慧。最近，语言建模已被证明等同于压缩，这为大型语言模型（LLM）的成功提供了令人信服的理由：更高级语言模型的开发本质上是增强压缩，从而促进智能。尽管讨论如此吸引人，但关于压缩和智能之间相互作用的实证证据却很少。在这项工作中，我们在法学硕士的背景下研究了它们的关系，将法学硕士视为数据压缩器。考虑到“智力”的抽象概念，我们采用平均下游基准分数作为替代，特别针对与知识和常识、编码和数学推理相关的智力。我们的研究涵盖 12 个基准，汇集了来自不同组织的 30 名公共法学硕士。值得注意的是，我们发现法学硕士的智力（通过平均基准分数反映出来）几乎与他们压缩外部文本语料库的能力线性相关。这些结果提供了具体的证据，支持这样的观点：卓越的压缩能力意味着更高的智力。此外，我们的研究结果表明，压缩效率作为源自原始文本语料库的无监督指标，可以作为与模型功能线性相关的可靠评估指标。我们开源我们的压缩数据集以及数据收集管道，以方便未来的研究人员正确评估压缩。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c76tpe/r_compression_represents_intelligence_linearly/</guid>
      <pubDate>Thu, 18 Apr 2024 15:54:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 产品评估是讨论最多的话题之一</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c75q78/d_product_evaluations_is_one_of_the_most/</link>
      <description><![CDATA[我们是一家人工智能咨询公司，这种情况一次又一次地发生在我们身上...... 我们开始一个新的法学硕士项目客户。 他们的工程师很快就能完成 80%。 他们有很多边缘情况，希望我们完成剩余的 20%。  &gt;我们向他们询问有关评估的信息。 当然他们没有。 我们创建评估框架，迭代改进管道，瞧。  工作完成，每个人都很高兴。 我认真地认为，根据我们的观察，最好的人工智能产品团队将是那些在评估上花费大量时间的团队。它很无聊，很重复，但它区分了令人惊叹的人工智能产品和表现不佳的产品。   由   提交 /u/BootstrapGuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c75q78/d_product_evaluations_is_one_of_the_most/</guid>
      <pubDate>Thu, 18 Apr 2024 15:10:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>