<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 27 Feb 2024 18:16:26 GMT</lastBuildDate>
    <item>
      <title>[D] 数据加载使我的代码变慢</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1hjl6/d_dataloading_making_my_code_slower/</link>
      <description><![CDATA[我将顺序数据存储在 h5 文件中，并且我正在使用 pytorch 数据加载器和我自己创建的自定义类  class H5Dataset(data.Dataset): def __init__(self, path): super(H5Dataset, self).__init__() super(H5Dataset, self).__init__()代码&gt; self.path = path self.file = h5py.File(path, &#39;r&#39;)  self.keys = list(self.file[&#39;Labels/Training/&#39;].keys()) def __getitem__(self, index): key = self.keys[index] key2 = key.replace(&#39;L&#39;, &#39;I&#39;) key2 = &#39;输入/&#39; + key2 key = &#39;标签/训练/&#39; + key inputs = np.array(self.file[key2 ]) inputs = torch.tensor(inputs) labels = self.file[key] labels = np.array(labels) labels = torch.tensor(labels) 返回输入，labels.float() def __len__(self): return len(self.keys) 当我尝试在数据加载器中使用 num_workers &gt;1 我收到一条错误消息，指出 h5 对象无法进行 pickeled，并且我认为数据加载是瓶颈，因为我只使用了 66% 的 GPU。 有关如何操作的任何建议使其更快？   由   提交 /u/bkffadia   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1hjl6/d_dataloading_making_my_code_slower/</guid>
      <pubDate>Tue, 27 Feb 2024 17:27:19 GMT</pubDate>
    </item>
    <item>
      <title>[p] Alma不翻译下一行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1hius/p_alma_doesnt_translate_the_next_row/</link>
      <description><![CDATA[我对如何训练 lora llm 知之甚少，我正在尝试遵循 ALMA ，https://github.com/fe1ixxu/ALMA 进行翻译，我使用了羊驼数据集结构，正如 llama 工厂所说......该模型令人惊讶地有效，但它不会进入下一步行，一旦出现一个点和下一行，它就不会翻译吗？这和推理有关系吗？随着训练？与数据集？    由   提交 /u/HackerPigeon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1hius/p_alma_doesnt_translate_the_next_row/</guid>
      <pubDate>Tue, 27 Feb 2024 17:26:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从某种意义上说，“在分布之外泛化”的想法不是不可能的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1he3r/d_isnt_the_idea_of_generalizing_outside_of_the/</link>
      <description><![CDATA[嘿，我并不是专门从事机器学习的人，但我是一名开发人员，并且对此有 8 年的业余爱好者研究。 &lt; p&gt;在分布之外进行泛化的想法对我来说一直很不寻常。当然，如果您学习英语，那么您现在在某种意义上就会知道如何编码，因为它是英语的。在这种情况下，该模型的泛化程度远没有我们希望的那么高，因为编码所需的基础知识几乎不是逻辑，而是读写。 在同样的意义上，人们可以想象一种颜色是不同颜色的混合。但想象一种全新的颜色并尝试一下，实际上是不可能的。在这种情况下，我们对分布之外的概括的定义并不在分布之外，只是分布比我们想象的（或可以量化的）大 与想象你从未听过的声音是一样的。再一次，你可以想象你听到过的其他声音的融合，也许你想象的这种新声音确实是你在现实中从未听过的东西，但你还没有推广到频谱的其余部分。我无法想象 20khz 以上的声音听起来是什么样子，因为我完全没有关于它可能是什么的基本事实，就像我无法客观地想象 X 射线是什么样子，因为我受限于我的能力，只能看到可见光。   由   提交 /u/EveningPainting5852   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1he3r/d_isnt_the_idea_of_generalizing_outside_of_the/</guid>
      <pubDate>Tue, 27 Feb 2024 17:21:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 探索GPT-4的国际象棋能力：是否有与GPT-3.5 Turbo相媲美的指令模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1gdod/d_exploring_gpt4s_chess_capabilities_is_there_an/</link>
      <description><![CDATA[我最近看到一篇有趣的文章，介绍 GPT-3.5 Turbo-Instruct 下国际象棋的能力非常好（请参阅此处之前的讨论：https://old.reddit.com/r/GPT3/comments/16mefly/the_new_gpt_model_gpt35turboinstruct_can_play/）。从不是专门为游戏设计的通用人工智能模型中看到如此熟练的国际象棋真是令人着迷。 这一发现让我思考是否存在等效的“指导”模型。 GPT-4 的版本，如果是的话，它在国际象棋能力方面的衡量标准，也许是在 ELO 评级方面。任何有关这方面的见解或信息将不胜感激。谢谢！   由   提交/u/dewijones92   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1gdod/d_exploring_gpt4s_chess_capabilities_is_there_an/</guid>
      <pubDate>Tue, 27 Feb 2024 16:41:42 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] SOTA计算机视觉模型中如何处理尺度等方差？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1ftd5/discussion_how_is_scale_equivariance_handled_in/</link>
      <description><![CDATA[我正在阅读 Aaron Courville、Ian Goodfellow 和 Yoshua Bengio 写的《深度学习》一书，他们提到了共享权重时卷积平移的自然等变性。因此，我想知道当前处理尺度变化的技术。 您认为权重共享和内核调整大小是否足够强大，足以解决这个问题？   由   提交/u/SufficientAd542   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1ftd5/discussion_how_is_scale_equivariance_handled_in/</guid>
      <pubDate>Tue, 27 Feb 2024 16:19:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 超参数调优和验证集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1eqg8/d_hyperparameter_tuning_and_validation_sets/</link>
      <description><![CDATA[嗨， 我对调整超级参数的步骤有点困惑。我认为这个过程是： 1- 在 EDA 和预处理之后，您开始使用训练集训练模型并使用验证集对其进行验证。然后，我通过查找精度、F1 分数等来评估验证集的性能。 2-基于验证集的性能指标，我们调整超参数并再次验证（使用相同的验证集？我认为这是错误的）并在需要时再次调整？ 调整超参数后，我会感到困惑，在我们这样做之后，我们是去使用测试集来测试模型，还是验证再次？ 我还想知道在模型训练方面超参数调整是否是一种优化策略，或者优化是否是其他东西。 我很感谢您的帮助，希望我说得有道理至少有一点。   由   提交 /u/Stock-Following8396    reddit.com/r/MachineLearning/comments/1b1eqg8/d_hyperparameter_tuning_and_validation_sets/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1eqg8/d_hyperparameter_tuning_and_validation_sets/</guid>
      <pubDate>Tue, 27 Feb 2024 15:35:26 GMT</pubDate>
    </item>
    <item>
      <title>[讨论][研究]deepfake检测工具需要帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1cqzo/discussion_research_help_needed_for_deepfake/</link>
      <description><![CDATA[     &lt; td&gt; 嘿 Reddit 社区， 我是致力于开发专门针对图像的 Deepfake 检测软件的团队的一员和视频分析。我们正在与您、专家和爱好者联系，以找出您认为至关重要的功能，并将深度伪造检测工具提升到一个新的水平。 我们想问的主要问题是：  您认为深度伪造检测工具需要具备哪些功能/信息，哪些功能会让您有兴趣尝试一下？ 有哪些功能？您认为这样的工具应该解决关于 Deepfake 技术的挑战/担忧？  ​ 我们的 Deepfake 检测工具的外观示例 对于我们的图像和视频检测，我们目前提供：  表示输入为假或真实的可能性的概率分数。 eXplainable 人工智能 (XAI) 结果显示为热图。 Deepfake 类型检测。 eXplainable 人工智能 (XAI) 结果显示为热图。 li&gt;  我们仍处于开发的早期阶段，任何有关如何进行的帮助将不胜感激。如果您有任何新的想法、想法或问题，请在下面的评论中留言。非常感谢您提供的任何帮助！   由   提交/u/Whole_Breakfast_6570   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1cqzo/discussion_research_help_needed_for_deepfake/</guid>
      <pubDate>Tue, 27 Feb 2024 14:10:30 GMT</pubDate>
    </item>
    <item>
      <title>[D]时间序列分类问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1bqbx/d_time_series_classification_problem/</link>
      <description><![CDATA[在当前的工作项目中，我们预测每种产品的销售数量等。数据集来自 POS 系统，在换句话说，没有 0，只有数量，简短的示例：假设商品 X 在 1（天）/1/23 和 3/1/23 出售，因此数据库中只有第 1 天和第 3 天，其中数据库中不存在第 2/1 天。 我想听听这里的意见和不同的方法，一种方法是填补每个产品的空白，并创建一个名为 is_bought 的新功能，如果发生销售 -&gt; ; 1，空白处用0填充。然后将分类输出乘以预测销量。对于回归问题，使用了 LGBM。 问题是我们有 2016 年的数据，当然是因为新冠疫情等......我们决定从 2022 年 1 月开始训练，但仍然有近 600 万条记录，所以如果我们填补了空白，数据会很大，那么还有其他方法或类似的问题吗？    由   提交/u/Phaeora_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1bqbx/d_time_series_classification_problem/</guid>
      <pubDate>Tue, 27 Feb 2024 13:22:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 测量输入法学硕士中小/零方差的输出方差</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1bp9r/d_measuring_variance_in_output_for_smallzero/</link>
      <description><![CDATA[嗨！我正在尝试设置一些实验来衡量法学硕士的方差（可能会关注偏见，但不确定哪种类型的偏见） 很想知道其他人会如何处理这个问题。   由   提交 /u/PlayingDumbIsFunny   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1bp9r/d_measuring_variance_in_output_for_smallzero/</guid>
      <pubDate>Tue, 27 Feb 2024 13:21:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 会议论文是双盲的。为了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b18is0/d_conference_paper_is_doubleblinded_for_what/</link>
      <description><![CDATA[我对提交给会议的论文必须双盲的要求感到非常困惑，但它们却可以预印有作者姓名和隶属关系，并且可以同时作为同一篇论文共享。人们甚至在接受/发表之前在 Twitter、LinkedIn、Reddit 等 SNS 上宣传他们的论文。感觉就像我在看 Instagram 版的学术界。如何确保广告而不是报纸本身不会影响决策过程？   由   提交 /u/Dry_Cheesecake_8311   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b18is0/d_conference_paper_is_doubleblinded_for_what/</guid>
      <pubDate>Tue, 27 Feb 2024 10:17:05 GMT</pubDate>
    </item>
    <item>
      <title>[N] 在 MWC 的技嘉展位上看到了这些……想象一下你可以用这些做什么！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b17igl/n_saw_these_at_the_gigabyte_booth_at_mwcimagine/</link>
      <description><![CDATA[       由   提交 /u/BubblyMcnutty   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b17igl/n_saw_these_at_the_gigabyte_booth_at_mwcimagine/</guid>
      <pubDate>Tue, 27 Feb 2024 09:05:38 GMT</pubDate>
    </item>
    <item>
      <title>通过 torch.compile 支持 gpt-fast 中的 Mixtral - 比任何非 Groq 端点更快的解码（！）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b10g2s/supporting_mixtral_in_gptfast_through/</link>
      <description><![CDATA[大家好，我们去年 12 月发布了 gpt-fast 作为可破解的“教程”实现文本生成的 SOTA 解码性能的各种实现。 从那时起，我们最近还在 gpt-fast 中添加了 Mixtral 实现。在这里查看：https://github.com/pytorch-labs/gpt-fast /tree/main/mixtral-moe  特色  (!) 无自定义内核 int8 和张量并行支持&lt; /li&gt; 仍然非常简单（支持&lt;150 LOC） 比任何（非 Groq）API 端点更快的解码速度，高达 220 tok/s/用户。  我还对这里涉及的挑战写了一份较长的解释：https://thonking.substack.com/p/short-supporting-mixtral-in-gpt-fast 希望人们觉得它有趣且有用！有趣的是，由于我们实际上在大约 2 个月前完成了这项工作并推迟了合并它，所以一些人（与我们无关）实际上已经对其进行了基准测试。 例如 此评论。  我们最近用 Mixtral 8x7B 尝试过此操作，结果非常疯狂！ Mixtral 8x7B 8 位版本在 A100-GPU (80GB) 上提供 55 个令牌/秒。最有趣的是，它比 4 位+vLLM 更好。    由   提交 /u/programmerChilli   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b10g2s/supporting_mixtral_in_gptfast_through/</guid>
      <pubDate>Tue, 27 Feb 2024 02:27:26 GMT</pubDate>
    </item>
    <item>
      <title>对于新晋研究科学家来说，该行业不会“复苏”[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0n3ib/the_industry_is_not_going_recover_for_newly/</link>
      <description><![CDATA[      今天的热门话题问：“科技行业还没有复苏吗？我有那么糟糕吗？” 让我做出一个大胆的预测（我希望我是错的，但我不认为我是错的）：这个行业不会“ “恢复”对于新晋研究科学家： 您的机器学习论文数量呈指数级增长，反映出博士生和博士后数量呈指数级增长： ​ &lt; p&gt;https://preview.redd.it/viv6l1gnkykc1。 png?width=899&amp;format=png&amp;auto=webp&amp;s=04e227dede42f7d46d1941fc268bb7ea0a409a04 ...毕业并开始竞争大致固定数量的井- 支付行业研究职位。这些职位的数量可能会季节性增加或减少，但长期趋势是他们的就业前景将变得越来越糟糕，而这种指数趋势仍在持续。 ​  div&gt;  由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0n3ib/the_industry_is_not_going_recover_for_newly/</guid>
      <pubDate>Mon, 26 Feb 2024 17:24:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是科技行业还没复苏还是我太差了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0ia76/d_is_the_tech_industry_still_not_recovered_or_i/</link>
      <description><![CDATA[我是欧洲顶尖大学的一名应届博士毕业生，正在研究 ML/CV 中的一些热门主题，已发表 8 - 20 篇论文，其中大部分是我的第一作者。这些论文已累计被引用1000-3000次。 （使用新帐户和广泛的范围来保持匿名） 尽管我认为自己是一个相当有实力的候选人，但我在最近的求职过程中遇到了重大挑战。我主要瞄准研究科学家职位，希望从事开放式研究。我已经联系了欧洲、中东和非洲地区的许多高级机器学习研究人员，虽然有些人表达了兴趣，但不幸的是，由于各种原因（例如人员有限或招聘经理没有更新信息），没有一个机会成为现实。 我主要针对大型科技公司以及一些最近流行的机器学习初创公司。不幸的是，我的大部分申请都被拒绝了，而且常常没有面试的机会。 （我只接受过一家大型科技公司的面试，然后就被拒绝了。） 特别是，尽管有朋友推荐，我还是立即遭到了 Meta 的研究科学家职位拒绝（几天之内）。我现在只是非常困惑和不安，不知道出了什么问题，我是否被这些公司列入了黑名单？但我不记得我树敌过。我希望就下一步可以做什么寻求一些建议......   由   提交/u/Holiday_Safe_5620   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0ia76/d_is_the_tech_industry_still_not_recovered_or_i/</guid>
      <pubDate>Mon, 26 Feb 2024 14:04:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>