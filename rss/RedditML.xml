<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 22 Mar 2024 00:56:43 GMT</lastBuildDate>
    <item>
      <title>[D] 本地工作的最佳语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkkz79/d_best_language_model_to_work_locally/</link>
      <description><![CDATA[最近出现了越来越多的语言模型及其变体、优化版本等。我感兴趣的问题是选择哪种语言模型，以便它可以在本地运行而不需要超级计算机来运行。我已经确定，对于我的机器人来说，最重要的任务将是编写代码。 对您的意见和经验感兴趣   由   提交/u/sunshine_reggie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkkz79/d_best_language_model_to_work_locally/</guid>
      <pubDate>Thu, 21 Mar 2024 23:32:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI工作站选购建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkfyh9/d_ai_workstation_purchase_advice/</link>
      <description><![CDATA[大家好，我想购买一台配备 nvidia 显卡的工作站，例如 A100 或 H100。我的主要用途是训练生成式 AI 模型，例如用于图像尺寸 256X256 的图像生成任务的扩散模型。请建议我可以购买什么配置以及从哪里购买。预算上限约为 35,000 美元，但有些灵活   由   提交 /u/Qhodor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkfyh9/d_ai_workstation_purchase_advice/</guid>
      <pubDate>Thu, 21 Mar 2024 20:04:15 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ML 研讨会/会议推荐：不是 AAI、IJCAI、NeuRips 或 ICML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkdsi2/discussion_ml_workshopconference_recommendation/</link>
      <description><![CDATA[这里是博士生。我尝试在 AAI-22、IJCAI-23、NeuRIPS-23 和 ICML-24 上发表我的论文。每次我处理这些评论时，我的分数都会更低。我做了表格数据——他们要求计算机视觉，我就这么做了。现在，他们要求语音识别。它在哪里停止？最重要的是，有些评论感觉他们在审稿时根本没有读过论文。这两年我一直在做这方面的工作，发表了几篇论文。我很累，整个过程都筋疲力尽。有人可以推荐一些 2024 年排名较低但可以接受的 ML 会议或信誉良好的研讨会吗？我想发布并完成这个工作。    由   提交/u/Conscious-Media3207  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkdsi2/discussion_ml_workshopconference_recommendation/</guid>
      <pubDate>Thu, 21 Mar 2024 18:35:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] I-JEPA + 3 分钟挑战（面试测试题）@ 星期五的 Oxen.ai Paper Club</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkac1e/r_ijepa_a_3minute_challenge_interview_test/</link>
      <description><![CDATA[嘿嘿， 本周五的牛纸俱乐部重点关注I-JEPA“基于图像的联合-嵌入、预测架构”（Mahmoud Assran、Yann LeCun 等人的 arxiv 论文）， I-JEPA 是一种从图像进行自我监督学习的非生成方法。  Yayyy 对标记数据的依赖较少。 与视觉转换器结合使用时具有良好的性能。  特殊功能警报！当人们在通话开始时加入时，我将进行“3 分钟挑战”。 认为你很聪明？我会扔掉上周采访中的 3 分钟 ML 技术问题，包括：  我答错的问题。 PlainSpeak 大师兼 Oxen 首席执行官 Greg Schoeninger 提出的问题去年 11 月在纸俱乐部中说的帮助我做对了！谢谢你u/FallMindless3563！  所以早餐吃你的小麦。请准时或提前参加我的 3 分钟挑战，否则您会错过它。 https:// www.oxen.ai/community?utm_source=paper_club_flyer * * 进行人工批准。今天报名参加明天的邀请。只有真正的人类豆子才能加入。 星期五，太平洋时间上午 10:00，奥斯汀时间中午，东部时间下午 1:00 ​   由   提交 /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkac1e/r_ijepa_a_3minute_challenge_interview_test/</guid>
      <pubDate>Thu, 21 Mar 2024 16:14:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有准确的AI工具进行研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk9aw0/d_is_there_an_accurate_ai_tool_for_research/</link>
      <description><![CDATA[我所在的领域需要大量数据分析和最新信息。我尝试过 Perplexity、ChatGPT 和 Bard 等工具，但结果各不相同。他们都有过自己的时刻，但没有一个是始终准确的，而不断检查它们是否准确就违背了使用人工智能工具的初衷。我遇到过一些问题，例如误解上下文以及反馈给我的不相关信息。我最近在寻找有关量子计算的信息，但只收到过时的参考资料。 同样，必须验证我得到的所有内容，这让我回到了最初的问题，我宁愿不完全使用人工智能工具。那么有没有真正的替代方案，或者我对独角兽的要求太多了？理想情况下，我正在寻找一个能够处理复杂主题并与最新出版物保持同步的人。  感谢您的帮助！   由   提交 /u/energetic_slugger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk9aw0/d_is_there_an_accurate_ai_tool_for_research/</guid>
      <pubDate>Thu, 21 Mar 2024 15:31:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] DINO v1 中居中如何促进均匀/扁平化分布？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk8skk/d_how_does_centering_encourage_uniformflattened/</link>
      <description><![CDATA[他们提到添加偏差项 c，g(x) = g(x)+c 有助于展平分布。但我不明白怎么办。  我的意思是术语 c 没有被学习，那么为什么它会增加不太可能的项目的概率，为什么会降低更可能的项目的概率？ &lt;!-- SC_ON - -&gt;  由   提交/u/sushilkhadakaanon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk8skk/d_how_does_centering_encourage_uniformflattened/</guid>
      <pubDate>Thu, 21 Mar 2024 15:09:57 GMT</pubDate>
    </item>
    <item>
      <title>ICML 反驳 2024 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk88kf/icml_rebbutal_2024_r/</link>
      <description><![CDATA[大家好，  今天 ICML 2024 的评审已出炉。  我提交了第一篇论文，但所有关于论文演示的评论都是负面的（三篇拒绝，评分为 3）。我想知道以后事情如何进行。如果我更改论文的呈现形式，我的论文还有机会被接受吗？特别是因为我在第一次提交后就做了实验。有人遇到过同样的问题，并因为第一次失望而感到沮丧吗？   由   提交/u/Any-Ad-3888  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk88kf/icml_rebbutal_2024_r/</guid>
      <pubDate>Thu, 21 Mar 2024 14:46:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 评论已发布。来！我们讨论一下！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk7u47/d_icml_reviews_are_released_lets_discuss/</link>
      <description><![CDATA[ 您收到了多少评论？ 他们的评分是多少？ （分数/置信度）  以下是审阅说明供参考：https://icml .cc/Conferences/2024/ReviewerInstructions   由   提交/u/tfburns  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk7u47/d_icml_reviews_are_released_lets_discuss/</guid>
      <pubDate>Thu, 21 Mar 2024 14:28:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自然语言指令诱导神经元网络中的成分泛化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk4fyk/r_natural_language_instructions_induce/</link>
      <description><![CDATA[论文：https://www.nature.com/articles/s41593-024-01607-5 代码：https://github.com/ReidarRiveland/Instruct-RNN/ 摘要：  人类的一项基本认知壮举是解释语言指令，以便在没有明确任务经验的情况下执行新任务。然而，可用于实现这一目标的神经计算仍然知之甚少。我们利用自然语言处理的进步来创建基于语言指令的泛化神经模型。模型接受一组常见心理物理任务的训练，并接收预训练语言模型嵌入的指令。我们最好的模型可以执行以前未见过的任务，仅基于语言指令（即零样本学习），平均正确率可达 83%。我们发现，语言支撑着感觉运动表征，使得相关任务的活动与指令的语义表征共享共同的几何形状，从而使语言能够提示在看不见的环境中练习技能的正确组成。我们展示了该模型如何仅使用运动反馈来生成对其识别的新任务的语言描述，这随后可以指导合作伙伴模型执行该任务。我们的模型提供了几个可通过实验测试的预测，概述了如何表示语言信息以促进人脑的灵活和一般认知。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk4fyk/r_natural_language_instructions_induce/</guid>
      <pubDate>Thu, 21 Mar 2024 11:35:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] Larimar：具有情景记忆控制的大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk48sg/r_larimar_large_language_models_with_episodic/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.11901 摘要：  高效准确地更新大型语言模型（LLM）中存储的知识）是当今最紧迫的研究挑战之一。本文提出了Larimar——一种新颖的、受大脑启发的架构，用于通过分布式情景记忆增强法学硕士。 Larimar 的内存允许动态、一次性更新知识，而不需要计算成本高昂的重新训练或微调。多个事实编辑基准的实验结果表明，即使在具有挑战性的顺序编辑设置中，Larimar 也能达到与最具竞争力的基线相当的准确性，而且在速度方面也表现出色 - 根据基础 LLM 的不同，可实现 4-10 倍的加速 - 以及灵活性由于所提出的架构简单、与法学硕士无关，因此具有通用性。我们进一步提供了 Larimar 选择性事实遗忘和输入上下文长度泛化的机制，并展示了它们的有效性。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk48sg/r_larimar_large_language_models_with_episodic/</guid>
      <pubDate>Thu, 21 Mar 2024 11:23:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 微调 GPT-4 以产生用户友好的数据探索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk42e1/p_finetuning_gpt4_to_produce_user_friendly_data/</link>
      <description><![CDATA[我们（一家小型初创公司）最近在微调 LLM（主要是 OpenAI 模型）以根据用户请求生成数据探索和报告方面取得了相当大的成功。我们提供数据模式的相关详细信息作为输入，并期望 LLM 生成用我们的自定义领域特定语言编写的响应，然后将其转换为 UI 探索。 我们在博客文章：https://www.supersimple.io/blog/gpt-4-fine -tuning-early-access 我很好奇是否有人在其他领域探索过类似的方法，或者可能在类似的上下文中使用了完全不同的技术。此外，我们是否可以通过一些方法来简化我们自己的管道？   由   提交 /u/PipeTrance   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk42e1/p_finetuning_gpt4_to_produce_user_friendly_data/</guid>
      <pubDate>Thu, 21 Mar 2024 11:12:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发布“1 位法学硕士时代”的培训代码及更多内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk32ye/d_training_code_and_more_released_for_the_era_of/</link>
      <description><![CDATA[不幸的是，微软没有发布权重，但如果权重介于权重和训练代码之间，那么这当然是更好的选择。 这篇文章在这里。  我们怎么想？关于形状奇怪的损失曲线有什么想法吗？您认为这种方法在 4B 参数之后会失效吗？法学硕士如何在如此低的精度下工作？我知道这不是特别科学，但对我来说，你可能会在几张 CD 上安装一个功能齐全的 7B 参数模型，这似乎相当违反直觉……然而最重要的是，谁有价值 100,000 美元的计算来实际测试这个？   由   提交 /u/DickMasterGeneral   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk32ye/d_training_code_and_more_released_for_the_era_of/</guid>
      <pubDate>Thu, 21 Mar 2024 10:09:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 发展新的基础模型：释放自动化模型开发的力量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjuddy/r_evolving_new_foundation_models_unleashing_the/</link>
      <description><![CDATA[Sakana AI 发布新论文。 博客文章：https://sakana.ai/evolutionary-model-merge/ 论文：模型合并配方的进化优化 https://arxiv.org/abs/2403.13187    ;由   提交/u/hardmaru  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjuddy/r_evolving_new_foundation_models_unleashing_the/</guid>
      <pubDate>Thu, 21 Mar 2024 01:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2024 接受去匿名论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bjknyi/d_deanonymized_paper_accepted_at_iclr_2024/</link>
      <description><![CDATA[我想开始讨论我在今年 ICLR 上观察到的一个特定案例。 - A 论文提交给ICLR双盲审稿人全名第一作者和完整的致谢（以及一些备受瞩目的参考文献）位于主要论文正文中，位于参考书目的正上方。作者明确确认了虚假陈述“无致谢部分：我证明本次提交的材料中没有供双盲评审的致谢部分。”提交时。 - 四位审稿人和 AC 避免提及这一点，并审阅论文了解作者的偏见，就好像它没有违反征文中列出的基本提交规则。  - 一月中旬发布的论文决定是“桌面拒绝” （推测是由于上述违规行为，确认PC们已经意识到这一点）。此内容未公开存档。 - 2 月初将其更改为“口头”内容。没有进一步的理由，原因不明。 违反匿名规则的行为首先会被评审者忽略，然后程序委员会通过例外情况默默地允许，大概是在直接投诉之后。在我看来，这对于任何会议来说都是不可接受的，尤其是像ICLR这样的领域顶级会议。如果我们不强制执行并允许一些作者选择透露自己的姓名并对审稿人产生偏见，为什么我们还要实行双盲程序呢？如果作者并不出名，或者他们在一个不太享有特权的地方进行研究，或者来自边缘化社区，是否也会有同样的例外？其他在今年 ICLR 上被拒绝但没有获得例外机会的论文又如何呢？ 根据我的经验，学术界关于偏见和诚信的问题经常在私人谈话中提出，但几乎从未公开讨论过，所以我有兴趣听听社区对此案的看法。项目主席拒绝对最终决定发表评论。   由   提交/u/Melodic-Foundation47  /u/Melodic-Foundation47 reddit.com/r/MachineLearning/comments/1bjknyi/d_deanonymized_pa​​per_accepted_at_iclr_2024/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bjknyi/d_deanonymized_paper_accepted_at_iclr_2024/</guid>
      <pubDate>Wed, 20 Mar 2024 18:32:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>