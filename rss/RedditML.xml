<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 20 Dec 2024 12:31:56 GMT</lastBuildDate>
    <item>
      <title>[R] 超级连接</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hiiktb/r_hyperconnections/</link>
      <description><![CDATA[      TL;DR 残差流的更复杂、更高性能变体。 论文： https://arxiv.org/pdf/2409.19606 摘要：  我们提出了超连接，这是一种简单而有效的方法，可以作为残差连接的替代方案。这种方法专门解决了残差连接变体中观察到的常见缺点，例如梯度消失和表示崩溃之间的跷跷板效应。从理论上讲，超连接允许网络调整不同深度特征之间的连接强度并动态重新排列层。我们进行了实验，重点是大型语言模型的预训练，包括密集和稀疏模型，其中超连接比残差连接显示出显着的性能改进。在视觉任务上进行的其他实验也证明了类似的改进。我们预计，这种方法将广泛应用于各种人工智能问题，并能从中受益。  视觉摘要： 相信我，它没有乍一看那么复杂 视觉亮点： 最令人印象深刻的收益是使用 MoE 架构实现的，尽管 Dense Transformers 也得到了提升 超连接在一定程度上缓解了表示崩溃 扩展率是指将残差流拆分为 n 个独立的分量，每个分量都进行动态门控。每个 Transformer 块的输入都是这些组件的简单总和 SHC=静态门控，DHC=动态门控 计算开销可以忽略不计 https://preview.redd.it/238ex3emtz7e1.png?width=973&amp;format=png&amp;auto=webp&amp;s=ac12792a4d45f7bf6e91f767dd12f2134ec74083    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hiiktb/r_hyperconnections/</guid>
      <pubDate>Fri, 20 Dec 2024 12:18:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我不再认为反驳有什么意义。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hi9jt2/d_i_dont_see_a_point_in_rebuttals_anymore/</link>
      <description><![CDATA[这是一些沉思和一些咆哮的混合体，但根据标题，我只是觉得它没有任何意义。我最近从一次会议上得到了结果，我得到了两个正面评论和一个负面评论。然后写了一篇非常好的反驳，解决了对审稿人的根本误解（后来审稿人确实增加了他们的分数，所以我猜反驳是正确的？）。但结果是，元审稿人抓住了负面评论，甚至没有阅读针对该评论的反驳并拒绝了这篇论文。 如果有关各方_甚至不会阅读它们_，我反驳的意义何在？在这一点上，我很想把反驳阶段当作徒劳无功。也许我应该在第一阶段撤回论文，因为出现任何问题，而不是试图经历最终毫无意义的劳动的痛苦。   由    /u/pddpro  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hi9jt2/d_i_dont_see_a_point_in_rebuttals_anymore/</guid>
      <pubDate>Fri, 20 Dec 2024 02:18:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] GLIDER：使用可解释排名对 LLM 互动和决策进行评分</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hi443m/r_glider_grading_llm_interactions_and_decisions/</link>
      <description><![CDATA[  由    /u/Megixist  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hi443m/r_glider_grading_llm_interactions_and_decisions/</guid>
      <pubDate>Thu, 19 Dec 2024 21:50:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] chat-gpt 越狱提取系统提示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hi429q/d_chatgpt_jailbreak_to_extract_system_prompt/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hi429q/d_chatgpt_jailbreak_to_extract_system_prompt/</guid>
      <pubDate>Thu, 19 Dec 2024 21:48:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你对混合语义搜索（视频+关键词）的看法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hi0aft/d_your_opinion_on_hybrid_semantic_searchvideo/</link>
      <description><![CDATA[我有一个语义搜索项目，其中有视频，每个视频都有一组关键字/标签，但不同视频的关键字数量不同（例如：视频 1 有 4 个关键字，视频 2 有 6 个关键字）并且标签按类别分组，例如：位置关键字（视频在哪里录制）、镜头类型（特写、慢动作）。 目标是进行语义搜索，使用视频嵌入 + 文本嵌入作为关键字。我们希望对关键字使用语义搜索，而不是纯文本匹配（作为常见的文本搜索引擎），因为我们希望系统处理以下情况：用户搜索“非常接近”并且应该匹配语义上相似的结果，例如：“特写”关键字。 对于视频，我们使用视频嵌入，我们对这部分很满意，但是对于关键字部分，我正在考虑很多选择，并且我正在征求社区的意见（显然我们稍后会构建和评估工具并测试不同的方法以查看哪种方法最有效，但它可以节省我一些时间来了解社区的经验和意见）：  为每个关键字创建一个嵌入，然后平均池化以获得单个聚合嵌入。 通过连接所有关键字来创建单个文本字符串，然后计算整个关键字的句子嵌入（这取决于模型，无论如何都会聚合不同关键字的嵌入） 我们有一个可以计算嵌入的视频描述，因此我们可以将关键字连接到视频描述，然后为描述和关键字字符串生成嵌入。 给定的关键字按类别分组：为每个类别计算一个嵌入  欢迎任何建议、评论、经验和其他方法    提交人    /u/Sad-Anywhere-2204   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hi0aft/d_your_opinion_on_hybrid_semantic_searchvideo/</guid>
      <pubDate>Thu, 19 Dec 2024 19:01:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 预测多个地点的需求时需要总体方向</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhxzzl/d_need_general_direction_when_forecasting_demand/</link>
      <description><![CDATA[您好，我算是新手，我一直在尝试解决这个涉及 25 家商店的数百种产品的情况。 数据范围从 2020 年到 2024 年。其中包括价格和折扣价格，如果持卡消费者购买，则会显示。每种产品有 5 个类别（向下钻取）级别。 库存剩余数据有点不稳定，通常不准确。 每年还有一些折扣日期范围（活动）。 如果我要为每个商店适当地预测这些数据，我应该为每个商店训练一个模型还是尝试将所有（约 200GB）数据放入一个模型中？ 我一直在尝试一些 ML/统计模型，如 XGBoost、ARIMA 和 CrostonOptimized，它们具有价格和折扣活动、单个商店销售的季节性特征。到目前为止，它们相当不准确（RMSE）。 任何建议都将不胜感激。    提交人    /u/NimblecloudsA​​rt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhxzzl/d_need_general_direction_when_forecasting_demand/</guid>
      <pubDate>Thu, 19 Dec 2024 17:23:55 GMT</pubDate>
    </item>
    <item>
      <title>用于分割任意图像（SAM）的非方形图像 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhunxi/nonsquare_images_for_segment_anything_sam_d/</link>
      <description><![CDATA[大家好， 我正在使用 SAM（基本上是 ViT）的编码器，并加载一个 base-MedSAM 检查点进行一些测试。我发现它只接受 1024x1024 的图像。我的是 1280x640。我看到两个选项 -  填充然后调整大小。效果不佳，因为我发现填充在训练期间增加了噪音（我不确定为什么，可能是因为我使用了 X-Rays）。 使用动态位置嵌入 - 即插值。有人试过这个或有什么想法吗？它需要对架构进行大量修改，而且也很复杂。 也许使用填充和调整大小，然后使用边界框提示仅关注所需的 1024x640 区域。  如果有人在数据集中处理过这种不规则形状的图像，有什么想法或建议吗？    提交人    /u/ade17_in   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhunxi/nonsquare_images_for_segment_anything_sam_d/</guid>
      <pubDate>Thu, 19 Dec 2024 14:56:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 根据用户兴趣改进推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhtd5e/r_improving_recommendations_by_calibrating_for/</link>
      <description><![CDATA[传统推荐系统通常优先考虑相关性，导致过度拟合热门或主要兴趣并忽略多样性。本文探讨了论文“校准推荐作为最低成本流问题”，这是一种通过将问题建模为最低成本流优化来校准推荐的新方法。通过平衡相关性与基于类别的用户兴趣分布，系统可确保多样性而不会牺牲质量。实验表明，该方法优于贪婪模型和基线模型，特别是对于较小的推荐集。 完整文章在此：https://www.shaped.ai/blog/improving-recommendations-by-calibrating-for-user-interests    提交人    /u/skeltzyboiii   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhtd5e/r_improving_recommendations_by_calibrating_for/</guid>
      <pubDate>Thu, 19 Dec 2024 13:53:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 ctx4k 训练的 RWKV-7 0.1B (L12-D768) 解决了 NIAH 16k，推断到 32k+，100% RNN 且无需注意，支持 100 多种语言和代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhshwp/r_rwkv7_01b_l12d768_trained_w_ctx4k_solves_niah/</link>
      <description><![CDATA[      大家好 :) 我们找到了最小的 RWKV-7 0.1B (L12-D768) 在长上下文中已经表现优异，同时是 100% RNN 且无需注意： https://preview.redd.it/rjcu9y73js7e1.png?width=1759&amp;format=png&amp;auto=webp&amp;s=b8fd2c8049b0886dbb87c715e120b1066b07b899 RWKV-7 World 0.1b 在多语言数据集上进行训练对于 1T 代币：https://preview.redd.it/cyvpr00mjs7e1.png?width=927&amp;format=png&amp;auto=webp&amp;s=01a98aa79be426d2d603fd5ae26ddad0ce1c0ee2 这些结果已经由社区测试：https://github.com/Jellyfish042/LongMamba  更多 RWKV-7 World 的评估。这是目前最好的多语言 0.1b LM :) https://preview.redd.it/a3yeedt8ks7e1.png?width=1497&amp;format=png&amp;auto=webp&amp;s=88cb8d9861a213a7be712acaca6546e7f63124ac 在 Gradio 演示中试用：https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-1 模型下载：https://huggingface.co/BlinkDL 训练它：https://github.com/BlinkDL/RWKV-LM 我也在训练 v7 0.4b/1b/3b。 社区正在致力于“转移” transformer 权重到 RWKV，并在几天前发布了一个 v6 32b 模型：https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1  RWKV-7 已经摆脱了线性注意力，成为了一个元上下文学习器，通过在每个 token 上的上下文梯度下降在上下文中对其状态进行测试时训练。 更多详细信息请参阅 RWKV dot com 网站（还有 30 多篇与 RWKV 相关的论文）。 https://preview.redd.it/x9tf1fnals7e1.png?width=722&amp;format=png&amp;auto=webp&amp;s=bf3f989e9736a38e7713ed41f17e1a2e5dd577b5  社区发现，一台微型 RWKV-6（带有 12m 个参数）可以通过非常长的 CoT 解决任何数独问题： https://github.com/Jellyfish042/Sudoku-RWKV 因为 RWKV 是一个 RNN，所以无论 ctxlen 如何，我们总是有恒定的速度和 vram。 例如，它可以解决&quot;世界上最难的数独&quot;拥有 400 万 (!) 代币 CoT: https://preview.redd.it/wo2vu9t3ns7e1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=32da05c2fb3e7622fde6b27e34c52795dba5d6c3    提交人    /u/bo_peng   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhshwp/r_rwkv7_01b_l12d768_trained_w_ctx4k_solves_niah/</guid>
      <pubDate>Thu, 19 Dec 2024 13:07:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有任何位置编码器允许位置不变编码？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhjhug/d_are_there_any_positional_encoders_that_allow/</link>
      <description><![CDATA[我正在微调一个语言模型，并在数据中引入了一些标记来传达与完成相关的元数据，最终看起来像这样： &lt;|metadata-type-1|&gt;一些随机信息元数据&lt;|metadata-type-2|&gt;一些更随机的元数据&lt;|metadata-type-3|&gt;更多&lt;|output|&gt;... 我真正希望 LLM 生成的东西... 然而，我发现元数据的顺序实际上很重要，特别是，如果元数据以错误的顺序出现很“奇怪”（可能是因为当它们在没有标记的情况下连接起来时不是那么自然），微调实际上做得很差。我怀疑是因为它违反了无标记的正常训练数据的模式？ 这并不太令人惊讶，因为在 RoPE 下，元数据标记在标记标记之间具有彼此的相对信息。我似乎想要一种与元数据顺序无关的编码方案，比如允许我在每个部分之间绘制障碍并使每个部分中的标记看起来距离相等的方案，因此主要考虑相关部分中的标记。换句话说，交换两个元数据部分将产生相同的 KV 状态。 有没有关于这种位置编码方案的研究？我甚至不确定该如何称呼这样的东西，所以任何指针都会非常感激。我也考虑过调整注意力掩码，但最终导致每个部分丢弃来自其他部分的信息，这也不是我想要的。    提交人    /u/lemon-meringue   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhjhug/d_are_there_any_positional_encoders_that_allow/</guid>
      <pubDate>Thu, 19 Dec 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在推理过程中，LSTM 是否比 transformer 更快？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hhhcu7/d_are_lstms_faster_than_transformers_during/</link>
      <description><![CDATA[Transformers 具有 O(n**2) 并行注意力计算，这让我认为它们在推理过程中会比 O(n) LSTM 慢，但在加速和并行化 Transformers 方面也做了很多工作。  它们如何比较单个数据点和批量数据推理？    提交人    /u/Complex-Media-8074   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hhhcu7/d_are_lstms_faster_than_transformers_during/</guid>
      <pubDate>Thu, 19 Dec 2024 01:24:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 谁能向我解释一下贝叶斯深度学习和因果关系之间的区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hh32u8/d_can_any_one_explain_me_the_difference_between/</link>
      <description><![CDATA[我正在阅读 youshua bengio 和其他研究人员的一些论文，他们提到在深度学习中加入因果关系很重要。 我不明白这些不同领域试图实现什么，我所知道的因果关系中的一些归纳偏差是 P(t)P(a/t) != P(t/a)P(a)。  因果关系和贝叶斯深度学习在 OOTD 数据中的稳健性如何？ 他们将如何将因果关系与深度学习相结合，dNN 是否会仅使用它来近似后验，还是会将其集成到深度学习的架构中？     提交人    /u/binny_sarita   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hh32u8/d_can_any_one_explain_me_the_difference_between/</guid>
      <pubDate>Wed, 18 Dec 2024 14:45:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年最佳调查论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hgwjqu/d_best_survey_papers_of_2024/</link>
      <description><![CDATA[作为一名刚起步的 AI 研究人员，我通常首先查看与某个领域相关的调查论文，然后创建一个路线图以进一步深入研究我的研究主题。我很想看看大家对他们在 2024 年遇到的最佳调查论文的看法。    提交人    /u/arinjay_11020   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hgwjqu/d_best_survey_papers_of_2024/</guid>
      <pubDate>Wed, 18 Dec 2024 07:32:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</guid>
      <pubDate>Sun, 15 Dec 2024 16:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>