<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Fri, 11 Apr 2025 06:26:46 GMT</lastBuildDate>
    <item>
      <title>[P] [D]为AI分类器创建金数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jwh66n/p_d_creating_golden_dataset_for_ai_classifier/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  上下文： 我在医疗技术公司工作。我们正在建立一个基于AI的医疗决策（MDM）分类工具。  听起来像是医生所做的，但MDM实际上与保险索赔有关。基本上，编码人员会根据咨询的复杂性提交索赔（称为E/M代码），将咨询的咨询标记为简单或努力。它对患者护理没有影响。  MDM指南公开可用（ example ）。它采用E/M代码等新的/已建立的患者诸如诊断，现有疾病等的数字，如果诊断，现有状况等。  我们正在建立一个工具，该工具根据医生的咨询说明向编码人员建议代码。对于我们自己的医院来说，这个工具是实习生。  为此，我们要利用LLM，而不是经典的ML分类技术。为什么？因为我们想在一个通用框架中构建它，我们可以在其中输入分类指南，而llm可以基于它输出。 手头的任务： 使分类器可靠且经过良好测试，我们想首先创建Golden DataSet。由于咨询说明包含个人健康数据（PHI），因此我们不能将其用于此 - 即使在识别之后，由于法律上这不是该数据的预期目的，因此我们没有同意。  因此，我们正在寻找一种基于公共可用指南首先创建综合数据的方法，请与编码器交叉检查，然后重复使用此数据以验证LLM。  你们中有人做过类似的数据创建练习吗？你怎么去？特别是您如何确保合成数据是现实的 +涵盖了所有不同的分类标准？   tldr： 需要有关如何为基于LLM的分类器创建合成数据的建议。需要合成数据，因为由于法律原因无法实现实际历史数据。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/supersaiyan63     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jwh66n/p_d_creating_golden_dataset_for_ai_classifier/</guid>
      <pubDate>Fri, 11 Apr 2025 04:06:07 GMT</pubDate>
    </item>
    <item>
      <title>[d] VIT中的动态补丁加权</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jwg9fj/d_dynamic_patch_weighting_in_vits/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有人探索了使用Vits在图像中加权非重叠补丁？权重将是可学习参数的一部分。例如，对于图像分类任务而言，背景修补程序有时没有用。我假设将其作为图像嵌入的一部分，可能会增加噪音。 ，如果有人可以将我指向一些相关作品，那将是很棒的。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/arjun_r_kaushik     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jwg9fj/d_dynamic_patch_weighting_in_vits/</guid>
      <pubDate>Fri, 11 Apr 2025 03:14:59 GMT</pubDate>
    </item>
    <item>
      <title>[d] VIT中的动态补丁加权</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jwg8ec/d_dynamic_patch_weighting_in_vits/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有人探索了使用Vits在图像中加权非重叠补丁？权重将是可学习参数的一部分。例如，对于图像分类任务而言，背景修补程序有时没有用。我假设将其作为图像嵌入的一部分，可能会增加噪音。 ，如果有人可以将我指向一些相关作品，那将是很棒的。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/arjun_r_kaushik     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jwg8ec/d_dynamic_patch_weighting_in_vits/</guid>
      <pubDate>Fri, 11 Apr 2025 03:13:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] Reddit的最佳情感分析模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jw8d2x/d_best_sentiment_analysis_model_for_reddit/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好！我第一次发布。 我正在研究一个情绪分析项目，重点是关于战争冲突的评论。对于此任务，我一直使用三种情感分析工具： vader ， textblob 和 distilbert 。但是，我面临着一个挑战，因为这三个模型的结果通常很大。数据集很大，因此每个评论的手动验证是不可行的。我很感谢如何解决如何实现最准确的情感结果的问题。  我应该考虑结合这些工具的分数吗？如果是这样，我怎么能说明每个模型的评分系统的功能都不同？ 另外，依靠多数投票对情感标签进行投票（例如，选择三个模型中至少有两个模型同意的情感）是否有意义？   tia !!     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/birblington     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jw8d2x/d_best_sentiment_analysis_model_for_reddit/</guid>
      <pubDate>Thu, 10 Apr 2025 20:47:07 GMT</pubDate>
    </item>
    <item>
      <title>直接从操作系统[讨论]预览镶木</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jw79pp/previewing_parquet_directly_from_the_os_discussion/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi！ 我已经多年了多年，这是我最喜欢的数据工作格式。 什么都没有。它可以很好地压缩超级，快速地将其压缩，维护模式并不会损坏数据（我正在看您Excel＆amp; csv）。但是... &lt; / p&gt; 没有某些代码 / CLI，就无法查看。超级烦人，尤其是如果您需要在开始进行分析之前窥视自己的工作。或坦率地说，只是调试输出数据集。 这是我一生中最后6年中最大的宠儿。因此，我已经修复了它哈哈。 下面的图像向您展示了如何直接从操作系统中的直接查看镶木quet文件。在支持预览等的不同应用程序上工作。此外，没有大小限制（因为显然是预览） 我坚信，在UI＆amp上忽略了数据空间；连续性方面。例如，视频不会面对的视频。 我计划添加数据科学/机器学习中常用的其他格式。 喜欢：   - 分区目录（这很棘手）      -   -  json行   -  duckdb（.db）   -  sqllite（.db）   - 格式，但直接来自S3/gcs，而无需进入控制台。   我应该添加什么格式，我应该添加吗？     href =“ https://i.redd.it/lapf15vkc2ue1.gif”&gt; https://i.redd.it/lapf15vkc2ue1.gif 提交由＆＃32; /u/u/umpressive_run8512     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jw79pp/previewing_pareectly_directly_from_from_the_os_os_discussion/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jw79pp/previewing_parquet_directly_from_the_os_discussion/</guid>
      <pubDate>Thu, 10 Apr 2025 20:01:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] B200 vs H100基准：早期测试显示高达57％的训练吞吐量和自我托管成本分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jw3b9b/p_b200_vs_h100_benchmarks_early_tests_show_up_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们在Lightly AI最近在欧洲早期访问了NVIDIA B200 GPU，并进行了一些独立的基准测试，将它们与H100相比，重点是计算机视觉模型培训工作量。 We wanted to share the key results as they might be relevant for hardware planning and cost modeling. TL;DR / Key Findings:  Training Performance: Observed up to 57% higher training throughput with the B200 compared to the H100 on the specific CV tasks we tested. Cost透视图（自主）：我们的分析表明，与典型的云H100实例相比，自托管B200可以提供明显较低的OPEX/GPU/小时（我们发现潜在的范围 〜6x-30x便宜，帖子中的详细信息/假设）。 This obviously depends heavily on utilization, energy costs, and amortization. Setup: All tests were conducted on our own hardware cluster hosted at GreenMountain, a data center running on 100% renewable energy.  The full blog post contains more details on the specific models trained, batch sizes, methodology, performance charts, and a breakdown of the cost注意事项：  我们认为，比较新一代的这些早期的现实世界数字可能对社区有用。很高兴在评论中讨论与新硬件的方法，结果或我们的经验！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/igorsusmelj     [link]         &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jw3b9b/p_b200_vs_h100_h100_benchmarks_early_early_tests_show_show_show_show_up_up_to/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jw3b9b/p_b200_vs_h100_benchmarks_early_tests_show_up_to/</guid>
      <pubDate>Thu, 10 Apr 2025 17:18:35 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于ICASSP 2025的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jw28iw/d_thoughts_about_icassp_2025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  签证中有很多问题，所以一半的海报板是空的，在我参加的两个会议中，只是播放了视频。为什么会议上存在签证问题？ 我在CVPR 23中收到了我的论文，但不能走，因为加拿大政府认为我会离开我的博士学位并呆在那里。  我希望未来的国家开始轻松研究研究人员  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/feens-writer-4468     [link]    ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jw28iw/d_thoughts_about_icassp_2025/</guid>
      <pubDate>Thu, 10 Apr 2025 16:33:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] llms的斜率取证工具包：计算代表性的词汇和相似性树</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jw1i4b/p_a_slop_forensics_toolkit_for_llms_computing/</link>
      <description><![CDATA[     &lt;！ -  sc_off-&gt;  在llm slop周围释放一些工具（过多代表的单词＆amp; ephrases）。 它使用样式分析来表达重复词＆amp＆amp＆amp;与人写作相比，在LLM输出中更常见的n-gram。 还借用了一些生物信息学工具来从这些斜率轮廓中推断出相似性树，从而将词汇特征的存在/不存在为“突变”推断关系。   - 计算a slop个人资料;代表性过多的单词＆amp;模型的短语   - 使用生物信息学工具推断相似性树   - 构建规范斜率短语列表  github repo： https://github.com/sam-paech/slop-forensics    笔记本： https://colab.research.google.com/drive/1sqfnhs4wh87yr8fzqppscobl5h5mms8e6?usp = sharing    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/_sqrkl      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jw1i4b/p_a_slop_slop_slop_slop_slop_forensics_toolkit_toolkit_for_for_computing/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jw1i4b/p_a_slop_forensics_toolkit_for_llms_computing/</guid>
      <pubDate>Thu, 10 Apr 2025 16:02:50 GMT</pubDate>
    </item>
    <item>
      <title>[D]对离散抽样 / MCMC的研究对行业有用吗？感觉不确定。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jvz48g/d_is_research_on_discrete_sampling_mcmc_useful_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我目前是前20名学校的CS的第二年博士生。我的研究重点是离散抽样 - 设计基于MCMC的算法，用于在离散空间上进行推理和发电。虽然我发现这个领域在智力上令人兴奋和核心来概率的机器学习，但我开始担心其行业的相关性。 说实话，我没有看到许多公司积极雇用专注于在离散空间中取样算法的角色。同时，我看到围绕加强学习，土匪和积极学习的嗡嗡声和工作空缺 - 不幸的是，我的部门不关注这些领域。 这使我感到有些焦虑： •是在行业中被认为是有价值的样品（在研究实验室外）被认为是有价值的（exp of Research Labs）吗？我转向更“应用”或“性感”，例如RL，因果关系等。？会喜欢任何建议或视角。 预先感谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dead_cs     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jvz48g/d_is_isearch_on_discrete_sampling_mcmc_use_uly_usefling_mcmc_useful_in/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jvz48g/d_is_research_on_discrete_sampling_mcmc_useful_in/</guid>
      <pubDate>Thu, 10 Apr 2025 14:21:40 GMT</pubDate>
    </item>
    <item>
      <title>[p] [r] [d] i建立了一个生物医学GNN + llm管道（XPLAINMD），以解释可解释的多链接预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jvv7s8/p_r_d_i_built_a_biomedical_gnn_llm_pipeline/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  大家好， 我是一名独立的研究人员，最近完成的建筑物 xplainmd ，端到的端到端端可解释的AI ai ai ai ai ai ai ai ai ai ai ai pipelable ai ai pipeline for Biomedical知识图。 It’s designed to predict and explain multiple biomedical connections like drug–disease or gene–phenotype relationships using a blend of graph learning and large language models. What it does:  Uses R-GCN for multi-relational link prediction on PrimeKG(precision medicine knowledge graph) 利用 gnnexplainer 用于模型可解释性 可视化模型预测的可视化图用 pyvis    解释了使用 llama 3.1 8b  pription  priveriate  app    🚀为什么我要构建它： 我想创建一些超越预测的东西，并为研究人员提供一种的方式，可以理解“为什么在模型的决定背后”，尤其是在敏感领域，例如精确的领域。几何• gnnexplainer • llama 3.1 • gradio • pyvis    这是完整的repo +写入：     https://medium.com/@fhirshotlearning/xplainmd-a-gaph-power-guide-to-smarter-healthcare-healthcare-fd5fe22504de    github： https://github.com/amulya-prasad/xplainmd        您的反馈是高度高度的！但是我渴望学习前进，并且在这个项目中有很多优化。但是，通过这个项目，我想演示图表的美丽以及如何使用它来重新定义医疗保健：）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/usassemphasis20     [link link&gt; [link]&gt; [link]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jvv7s8/p_r_d_i_built_a_biomedical_gnn_llm_pipeline/</guid>
      <pubDate>Thu, 10 Apr 2025 11:06:07 GMT</pubDate>
    </item>
    <item>
      <title>[d] Yann Lecun自动回归LLM注定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jvrk68/d_yann_lecun_autoregressive_llms_are_doomed/</link>
      <description><![CDATA[    src =“ https://b.thumbs.redditmedia.com/0sfsfswahoatmrgchebcapl32wvymuh907cpgd1ccokoq.jpg” title =“ [d] class =“ md”&gt;    不确定还有谁同意，但我认为Yann Lecun在这里提出了一个有趣的观点。好奇地听到有关此的其他意见！ 讲座链接： https://wwwww.youtube.com/watch?v= = etzf = eetzfkkkv6v6v7yy /u/hiskuu     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jvrk68/d_yann_lecun_autoregressive_llms_are_doomed/</guid>
      <pubDate>Thu, 10 Apr 2025 06:44:27 GMT</pubDate>
    </item>
    <item>
      <title>[D]有人在GCP上训练LLM吗？您等待H100批准了多长时间？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jv80y4/d_has_anyone_trained_llm_on_gcp_how_long_did_you/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你们等了多长时间等待增加的配额增加了H100 80GB GPU的批准？我需要为Llama 4 Maverick使用8 H100 80GB GPU，今天仍在等待。想知道，因为在不同的GPU的批准中，几乎可以立即获得批准。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jv80y4/d_has_anyone_trained_llm_llm_lm_gcp_how_how_how_long_did_you/”&gt; [link]      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jv80y4/d_has_has_anyone_trained_llm_glm_gcp_how_gcp_how_long_long_did_you/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jv80y4/d_has_anyone_trained_llm_on_gcp_how_long_did_you/</guid>
      <pubDate>Wed, 09 Apr 2025 15:06:08 GMT</pubDate>
    </item>
    <item>
      <title>[D]您如何监视AI代理或LLM应用程序？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jv2zxc/d_how_do_you_monitor_your_ai_agents_or_llm_apps/</link>
      <description><![CDATA[I’m curious how others are monitoring and tracking LLM-based apps or AI agents, especially as they get more complex with RAG, tool use, or user input. Do you track things like:  Token usage Latency Error rates Prompt version changes ...或其他任何与性能/成本相关的指标？  您是否为此使用了工具，还是您自己构建了自己的东西？ 很想听听（或者不适合您的），甚至轻量级的解决方案或痛苦点。提交由＆＃32; /u/yersyas     [links]     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jv2zxc/d_how_how_do_do_you_you_you_your_your_your_your_ai _ai_aigents_aigents_or_llm_llm_apps/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jv2zxc/d_how_do_you_monitor_your_ai_agents_or_llm_apps/</guid>
      <pubDate>Wed, 09 Apr 2025 11:01:08 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jpdo7y/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</guid>
      <pubDate>Wed, 02 Apr 2025 02:15:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_be_hired/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Mon, 31 Mar 2025 02:30:37 GMT</pubDate>
    </item>
    </channel>
</rss>