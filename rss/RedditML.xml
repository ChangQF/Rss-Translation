<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 13 Jul 2024 15:14:06 GMT</lastBuildDate>
    <item>
      <title>[D] 雇用学生/毕业生，好主意还是坏主意？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2cnw8/d_hiring_studentsgraduates_good_or_bad_idea/</link>
      <description><![CDATA[我的初创公司正处于一个阶段，我们想开始使用 ML 探索一些新概念，特别是在音频领域。我们是自筹资金的，所以预算有限，无法负担我在招聘启事上看到的一些年薪 40 万美元的 ML 人员 😳 但有趣的是，我看到的所有真正有趣的 ML 开源项目似乎都是由研究生/攻读博士学位的人完成的。而不是由在大型公司工作的拥有大量简历的人完成的。  试图以相对可承受的小时费率寻找一名充满热情的研究生，希望他们能成为公司的一部分、获得股权等，这不合理吗？或者这通常不是这样的？    提交人    /u/maxiedaniels   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2cnw8/d_hiring_studentsgraduates_good_or_bad_idea/</guid>
      <pubDate>Sat, 13 Jul 2024 15:11:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自适应参数激活</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2ba37/r_adaptive_parametric_activation/</link>
      <description><![CDATA[      TL;DR 在图像分类任务中，具有可学习参数的激活函数可以近似许多流行函数并提高准确性 论文： https://arxiv.org/pdf/2407.08567 摘要：  激活函数在模型优化中起着至关重要的作用，但最佳选择仍不清楚。例如，Sigmoid 激活是平衡分类任务中事实上的激活，然而，在不平衡分类中，由于对频繁类的偏见，它被证明是不合适的。在这项工作中，我们通过在平衡和不平衡网络的分类和中间层进行全面的统计分析来深入研究这一现象，并通过经验表明，将激活函数与数据分布对齐可以提高平衡和不平衡任务的性能。为此，我们提出了自适应参数激活 (APA) 函数，这是一种新颖且多功能的激活函数，它将最常见的激活函数统一在一个公式下。 APA 可应用于中间层和注意力层，在 ImageNet-LT、iNaturalist2018、Places-LT、CIFAR100-LT 和 LVIS 等几个不平衡基准以及 ImageNet1K、COCO 和 V3DET 等平衡基准上显著超越最新技术。代码可在此 URL 上获取。  视觉摘要： https://preview.redd.it/kb26agqvkacd1.png?width=1215&amp;format=png&amp;auto=webp&amp;s=ff877939a3d900afca5a83a83559af219e3cb368 公式 基准测试： 不平衡的数据集，其中 \&quot;许多\&quot;、\&quot;中等\&quot; 和 \&quot;少数\&quot;参考类别频率组 https://preview.redd.it/aehu0slhmacd1.png?width=1219&amp;format=png&amp;auto=webp&amp;s=45825faa5c43065717c6a0cd8c763bbabc722eda https://preview.redd.it/95d1aafvmacd1.png?width=1183&amp;format=png&amp;auto=webp&amp;s=f421a04fe0d72d971e95c9c26af7e13e38556412    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2ba37/r_adaptive_parametric_activation/</guid>
      <pubDate>Sat, 13 Jul 2024 14:08:45 GMT</pubDate>
    </item>
    <item>
      <title>[N] 利用 HyperAIBox 让日常消费者能够使用 AI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2b3s4/n_making_ai_accessible_to_everyday_consumers_with/</link>
      <description><![CDATA[        提交人    /u/Itsmariel26   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2b3s4/n_making_ai_accessible_to_everyday_consumers_with/</guid>
      <pubDate>Sat, 13 Jul 2024 14:00:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 去掩蔽扩散模型，不起作用！有什么想法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2ayw2/d_demasking_diffusion_model_not_working_thoughts/</link>
      <description><![CDATA[你好。 我正在尝试实现一个用于文本生成的“掩蔽”扩散模型。完成后它将生成 16 个字符的字符串。这是我在大学进行的一项研究，该研究是关于 PassGAN 等密码猜测模型的潜在竞争对手。 字符串是一个 16 行矩阵，每行都是 1-hot，分为 90 个类（空字符以生成 &lt;16 长度、掩码类和普通字符） 该模型遵循一个时间表，在 20 个时间步内逐步将一些字符变成掩码字符（改变它们的类别），并且底层架构应该在给定一个带有一些掩码行的矩阵的情况下预测 t-1 步骤（即，它应该输出掩码行中类别的概率，基本上预测被掩码的字符在被掩码之前是什么）。 我已经为这项任务建立了一个基本的变压器模型，但它看起来什么也没学到。在采样中，我给它一个包含 16 个掩码类的矩阵，并且在每个时间步长上用置信度最高的预测替换一行，它要么归结为同一件事（maskmaskmask...），要么，如果我更新损失以惩罚与输入相同的预测，只是像“baaaaaaaaaaaa”这样的垃圾。 我正在 rockyou 数据集上进行训练，这些结果来自 1 个 epoch，大约花费 1 小时，1400 万个条目，批量大小为 256。 我做错了什么？我应该改变架构还是别的什么？你有什么建议？我希望它至少能预测随机字符串，而不是“baaaaaaaaaaa..” 非常感谢。 这是代码的变换器部分：https://gist.github.com/gianluca5539/192173691a55006ddf4ec75754fd2c14 显然，在下面的实现测试中，我正在训练它预测同样的事情，这是来自早期测试的。即使使用真实的损坏数据，它仍然会预测与输入相同的内容。    提交人    /u/mntglc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2ayw2/d_demasking_diffusion_model_not_working_thoughts/</guid>
      <pubDate>Sat, 13 Jul 2024 13:54:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Python 编写的 Beta 回归模型，用于分析营销活动 B 会员资格对 CTR 的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2976w/d_beta_regression_model_in_python_for_affect_of/</link>
      <description><![CDATA[大家好， 我正在尝试建立一个模型来估计广告系列 B (B1) 在 CTR (点击率) 上的 ATE，以广告系列 A 为基线 (B0)，由“a_or_b”列表示。 其他外生变量包括：“nth_day”（给定广告系列在给定日期经过的天数）、“platform_Meta”、“platform_StackAdapt”（均为二进制虚拟变量，其中“platform_Google”在基线中表示）。 我是一名数据科学研究生，我参加了因果推理课程，但它主要讨论了 OLS 的使用。很明显，尝试后 OLS 效果不佳。 在意识到使用受 [0, 1] 约束的模型更好之后（100% 是为了获得最大可能的点击率，我想我会尝试使用 statsmodels.othermod.betareg.BetaModel 来尝试 Beta 回归模型（文档：https://www.statsmodels.org/dev/generated/statsmodels.othermod.betareg.BetaModel.html）。 仅供参考，这是 CTR 的分布：https://drive.google.com/file/d/1qC-dVOp3qn-rq87wpWfU4pcWMyWDlBnW/view?usp=sharing。 摘要统计信息：https://drive.google.com/file/d/19IZggTQOvGireRQHZNgk8mBI6b0chfE_/view?usp=sharing 它向右严重倾斜，大多数值都非常小（但不为 0）。 我很难确定我创建的哪个模型（如果有的话）提供了足够好的拟合度，让我可以信任“a_and_b”的系数和 p-val。 据我了解，模型 3 的 AIC 较低意味着它更适合，但是它的 QQ 图和残差与拟合值看起来非常不稳定，我不相信结果。 两种模型的 statsmodels 结果均此处。 模型 2：QQ 图：https://drive.google.com/file/d/1OkuAttSWKr9XTv5_LAcmZOawpt8MbU0L/view?usp=drive_link) 残差与拟合值：https://drive.google.com/file/d/1XHTkFc51NvlUNgNxN-vDcGmRrumjsUp-/view?usp=sharing 模型 3：QQ 图：https://drive.google.com/file/d/1D0huxJqEEZpDzBjYRWXuFwlkeU09fH27/view?usp=sharing 残差与拟合值：https://drive.google.com/file/d/1SBYpU91spP1XzcXTwd85vMPdVcXBATjx/view?usp=sharing 我正在寻找一些关于如何进行此操作的见解和方向。如果我完全偏离了轨道，请随时告诉我😆。    提交人    /u/randomguy684   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2976w/d_beta_regression_model_in_python_for_affect_of/</guid>
      <pubDate>Sat, 13 Jul 2024 12:25:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人使用 Sentence Transformers 进行大规模训练吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e26t13/d_anyone_used_sentence_transformers_for_large/</link>
      <description><![CDATA[Sentence Transformers 非常适合简单、小规模的微调。 是否有人尝试过在非常大的规模上使用 Sentence Transformers，比如对 2 亿个文本对进行对比训练？ 或者人们更喜欢在这种规模上采用不同的训练方法？    提交人    /u/SingularValued   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e26t13/d_anyone_used_sentence_transformers_for_large/</guid>
      <pubDate>Sat, 13 Jul 2024 09:59:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我的 ML 工程师工作有多“正常”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e266li/d_how_normal_is_my_ml_engineer_job/</link>
      <description><![CDATA[大家好，我希望这篇文章没有违反任何规则。 我拥有计算机科学硕士学位（ML 重点），大约 1 个月前我开始在一家初创公司担任 ML 工程师。该公司有一个非常有趣的 ML 核心产品（他们对其进行了相当多的研究/实验），但它也是一个针对单个客户的小型“附带项目”，远没有那么令人兴奋。它基本上由一个简单的 Web 应用程序组成，在后台执行一些 ML 操作，主要是通过查询 OpenAI 的 API 和使用其他未以任何方式修改的预构建模型。现在，开发这个应用程序的人要离开了，我必须接手这个项目......我对此有点生气，因为这不是我来这里时真正期望的。 考虑到这是我的第一份工作（以前从未做过实习），这是多么“正常”你会考虑开发这样的产品吗？我的职位实际上只是伪装的即时工程吗？    提交人    /u/Fursol   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e266li/d_how_normal_is_my_ml_engineer_job/</guid>
      <pubDate>Sat, 13 Jul 2024 09:16:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于大型感受野的小波卷积</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e22i7j/r_wavelet_convolution_for_large_receptive_fields/</link>
      <description><![CDATA[      TL;DR：我们使用小波来增加卷积的感受野和低频响应。 论文：https://arxiv.org/abs/2407.05848 代码：https://github.com/BGU-CS-VIL/WTConv  近年来，人们一直试图增加卷积神经网络 (CNN) 的内核大小，以模拟 Vision Transformers (ViTs) 自注意力模块的全局感受野。然而，这种方法在实现全局感受野之前就很快达到了上限并饱和。在这项工作中，我们证明，通过利用小波变换 (WT)，实际上可以获得非常大的接受场而不会遭受过度参数化，例如，对于 k×k 接受场，所提出方法中可训练参数的数量仅随 k 呈对数增长。所提出的层名为 WTConv，可用作现有架构中的直接替代品，产生有效的多频响应，并随着接受场的大小优雅地扩展。我们证明了 ConvNeXt 和 MobileNetV2 架构中 WTConv 层对图像分类的有效性，以及下游任务的主干，并表明它具有其他属性，例如对图像损坏的鲁棒性和对形状而非纹理的响应增强。  https://preview.redd.it/nrvpb9cvz7cd1.jpg?width=1246&amp;format=pjpg&amp;auto=webp&amp;s=5f9a02fa6c32d9c121d2519fe137b289756b9701    提交人    /u/shahaff32   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e22i7j/r_wavelet_convolution_for_large_receptive_fields/</guid>
      <pubDate>Sat, 13 Jul 2024 05:16:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于生成 Nvidia Triton 部署代码的开源 CLI 工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e224jp/p_open_source_cli_tool_to_generate_code_for/</link>
      <description><![CDATA[存储库：https://github.com/inferless/triton-co-pilot Triton Co-Pilot：一种快速编写粘合代码的方法，可以更轻松地使用 NVIDIA Triton Inference Server 进行部署。这是我们在内部团队黑客马拉松中创建的一款很酷的 CLI 工具。 以前，将模型部署到 Triton 非常困难。您必须浏览 Python 后端的文档，弄清楚如何正确获取输入和输出，编写一堆粘合代码，创建一个包含所有正确参数的 config.pbtxt 文件，然后打包所有内容。这很容易花费几个小时。 但是有了 Triton Co-Pilot，所有的麻烦都消失了。现在，您只需编写模型逻辑、运行命令，Triton Co-Pilot 会完成剩下的工作。它会自动生成您需要的一切，使用 AI 模型配置输入和输出，并处理所有繁琐的部分。您可以在几秒钟内准备好 Docker 容器。 查看我们的 GitHub 存储库，看看部署到 Triton 有多么容易！如果你们尝试一下并看看它是否适合你们，那就太好了。 |用于生成 Nvidia Triton 部署代码的开源 CLI 工具|    提交人    /u/rbgo404   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e224jp/p_open_source_cli_tool_to_generate_code_for/</guid>
      <pubDate>Sat, 13 Jul 2024 04:52:51 GMT</pubDate>
    </item>
    <item>
      <title>[D]2024 年中期，如何有效过滤和消化每日新闻和报纸？有什么工具可以推荐吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e1zl10/dhow_do_you_filter_and_digest_every_day_news_and/</link>
      <description><![CDATA[我每天花太多时间阅读不到 10 篇论文。有没有什么新工具可以快速消化论文？    提交人    /u/Historical-Tree9132   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e1zl10/dhow_do_you_filter_and_digest_every_day_news_and/</guid>
      <pubDate>Sat, 13 Jul 2024 02:33:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LoRA 在 SFT 数据上微调 LLM 的最佳配置</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e1wqkr/d_best_configuration_for_finetuning_llms_with/</link>
      <description><![CDATA[大家好，能否分享一下在资源有限（比如单个 A100 80GB）的情况下使用 LoRA 使用 SFT 数据微调 LLM（如 https://huggingface.co/Qwen/Qwen2-7B-Instruct）的最佳设置？以下是更多详细信息：  不想做任何量化，半精度训练是可以的。 想在更大的上下文中微调模型，比如 ~16K。 我曾尝试使用 CPU 卸载（使用 HF peft）的 deepspeed，但能够使用最大 1 个批次大小和最大上下文长度 16K 进行微调。  还有其他更好的配置或库吗？如果有人能够实现更好的批次大小或更快的配置，请分享详细信息。    提交人    /u/Financial-Beach1587   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e1wqkr/d_best_configuration_for_finetuning_llms_with/</guid>
      <pubDate>Sat, 13 Jul 2024 00:09:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我一直在思考稳定扩散的工作原理，所以我决定从头开始编写自己的程序，并附上数学解释 🤖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e1w2rg/p_i_was_struggle_how_stable_diffusion_works_so_i/</link>
      <description><![CDATA[        提交人    /u/jurassimo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e1w2rg/p_i_was_struggle_how_stable_diffusion_works_so_i/</guid>
      <pubDate>Fri, 12 Jul 2024 23:38:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] ViT 等无掩码 Transformer 中自注意力层的一个有趣特性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e1sy5u/d_an_interesting_property_of_selfattention_layers/</link>
      <description><![CDATA[我编写了一个自定义转换器实现，在对注意力代码进行初步的简单测试时，我注意到一个乍看之下似乎是 bug 的东西，但转念一想，这可能是注意力的固有属性。 由于注意力图针对每个嵌入向量进行了 softmax 处理，因此其应用将把每个向量拉向上下文/空间序列中其他向量的加权平均值。Oc 第一个注意力层可能只会将每个嵌入拉向几个特定的​​其他向量（具有最高注意力分数）。而且这种拉动不是直接针对其他向量，而是针对它们与值矩阵的变换（也受到残差连接的影响），但由于值矩阵共享所有上下文/空间槽的权重，因此效果仍然存在：在注意层之后，嵌入向量比之前稍微更相似。 这是一个正反馈循环，因为现在稍微更相似的嵌入将在下一个注意层中产生更均匀的注意图，以实现更均匀的平均，依此类推，以获得越来越强的均质化效果。 还有其他因素可能会抵消这种影响（例如间歇性的其他层和非线性，输出层如何连接到嵌入向量以及其梯度如何回流等等 - 训练量对注意力图均匀性也很重要）。对于视觉变换器来说，这甚至可能是一种理想的效果（因为向量/补丁会逐步吸收来自整个图像的类信息）。但它仍然似乎是一种独特的注意力属性，并且它作为一种通用的空间/上下文连接运算符的用途，与完全连接层或卷积层有很大不同。 我认为这种自我放大效应即使在完整模型中也应该是显而易见的（除了注意力之外，还使用各种其他块），只要模型使用多个没有因果掩码的注意力块（例如，对于语言模型来说不太明显）。有人经历过这种现象吗？    提交人    /u/lostn4d   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e1sy5u/d_an_interesting_property_of_selfattention_layers/</guid>
      <pubDate>Fri, 12 Jul 2024 21:21:49 GMT</pubDate>
    </item>
    <item>
      <title>[N] Google 研究 - 将视觉语言模型与墨迹模态相结合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e1icu4/n_google_research_combining_vision_language_model/</link>
      <description><![CDATA[ 使用 VLM 进行在线手写识别：了解大型视觉语言模型 (VLM) 如何使用新表示和标记器彻底改变在线手写识别。此方法适用于现成的模型，并无缝集成到现有的多模式框架中。 ​​使用 VLM 数字化手写笔记：了解 VLM 如何将纸笔笔记的图像转换为数字墨水，从而连接传统笔记和数字笔记。这种集成促进了 AI 辅助工作流程并提高了生产率。  https://youtu.be/JspO32WBluI?si=UA9ueBrQJPgoanwm&amp;t=1517    提交人    /u/CharlieLee666   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e1icu4/n_google_research_combining_vision_language_model/</guid>
      <pubDate>Fri, 12 Jul 2024 13:58:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dx5tpo/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dx5tpo/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 07 Jul 2024 02:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>