<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 19 Feb 2024 18:16:48 GMT</lastBuildDate>
    <item>
      <title>[P] 有人有使用 LiDAR 数据进行跌倒检测的经验吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auu4eb/p_does_anyone_have_experience_with_using_lidar/</link>
      <description><![CDATA[我目前正在开展一个项目，尝试使用 LiDAR 传感器 (A1M8) 检测室内的跌倒情况，类似于本文： https://ieeexplore.ieee.org/document/9298000 有没有人有过这样的经验类似的项目？我目前正处于数据收集阶段，但我正在尝试决定使用哪种神经网络架构。根据我的研究，LSTM 或 TCN 是最好的方法，但我也看到在将 LiDAR 数据转换为 2D 图像后使用 CNN：https://www.mdpi.com/1424-8220/24/2/626.  &amp;# 32；由   提交 /u/EggCrazy3721   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auu4eb/p_does_anyone_have_experience_with_using_lidar/</guid>
      <pubDate>Mon, 19 Feb 2024 18:11:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在 10M 大海捞针中寻找针：循环记忆找到法学硕士错过的东西 - AIRI，莫斯科，俄罗斯 2024 - RMT 137M 具有循环记忆的微调 GPT-2 能够在 10M 中找到 85% 的隐藏针草垛！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1autvwq/r_in_search_of_needles_in_a_10m_haystack/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.10790  摘要：  本文解决了使用生成变压器模型处理长文档的挑战。为了评估不同的方法，我们引入了BABILong，一个新的基准旨在评估模型在广泛文本中提取和处理分布式事实的能力。我们的评估（包括 GPT-4 和 RAG 基准）表明，常见方法仅对最多 10^4 元素的序列有效。相比之下，通过循环内存增强对 GPT-2 进行微调使其能够处理涉及多达  10^7 个元素的任务。这一成就标志着一个重大飞跃，因为它是迄今为止任何开放神经网络模型处理的最长输入，展示了长序列处理能力的显着改进。   https://preview.redd.it /0o4207a70ljc1.jpg?width=577&amp;format=pjpg&amp;auto=webp&amp;s=2bfac07872020de222b4bf99f837aa398b778afc https://preview.redd.it/2ff82da70ljc1.jpg?width=1835&amp;format=pjpg&amp;auto=webp&amp;s=acc1409f5b9bcd07f9 b5ff8a3890cc1b15b5c8ed  https://preview.redd .it/ld69p7a70ljc1.jpg?width=1816&amp;format=pjpg&amp;auto=webp&amp;s=fdd72c1a87742f525fa352723bcd1a0f4f000638 https://preview.redd.it/7vn4gba70ljc1.jpg?width=900&amp;format=pjpg&amp;auto=webp&amp;s=c8d08bb85a6 699e5b451e01bf615379db1fcbdca   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1autvwq/r_in_search_of_needles_in_a_10m_haystack/</guid>
      <pubDate>Mon, 19 Feb 2024 18:02:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据科学标题 Q</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1autl5l/d_data_science_titles_q/</link>
      <description><![CDATA[可能是一个愚蠢的问题，但我刚刚从高级晋升为数据科学主管。但我注意到大多数公司都有首席数据科学家的头衔。是否值得要求我的公司更新，还是 6 个半？ 我们有技术主管，所以我假设他们只是遵守命名约定    由   提交 /u/WeenTown   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1autl5l/d_data_science_titles_q/</guid>
      <pubDate>Mon, 19 Feb 2024 17:51:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于使用什么模型来提取关键概念的建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aut2e7/d_recommendations_on_what_model_to_use_to_extract/</link>
      <description><![CDATA[假设以下场景，您输入的文本告诉您有关某个对象的关键信息。您想将其提供给法学硕士，然后提示它返回您感兴趣的信息。 如果可以提供任何相关的 GitHub 示例，您将使用什么模型以及为什么，我们将不胜感激。&lt; /p&gt;   由   提交 /u/Greedy-Key4958    reddit.com/r/MachineLearning/comments/1aut2e7/d_recommendations_on_what_model_to_use_to_extract/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aut2e7/d_recommendations_on_what_model_to_use_to_extract/</guid>
      <pubDate>Mon, 19 Feb 2024 17:31:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 向公众提供内部模型到 API 工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auss1t/p_making_internal_modeltoapi_tool_available_for/</link>
      <description><![CDATA[大家好！ 👋 作为构建我的初创公司的一部分Orderly，我开发了一个内部工具，可以一键将模型部署到托管 API。它所需要的只是一个模型文件（如 .pkl）、一个使用模型进行预测的函数以及托管服务器帐户的凭据（我一直在使用 Heroku）。 一位朋友建议我在上面放置了一个简单的 UI，并将其向数据社区公开 - 甚至可以扩展它来为您创建一个托管服务器帐户。然而，在投入时间之前，我想听听人们是否对此感兴趣。如果是，请在下面发表评论或私信我！   由   提交 /u/GingerAndPepper   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auss1t/p_making_internal_modeltoapi_tool_available_for/</guid>
      <pubDate>Mon, 19 Feb 2024 17:20:00 GMT</pubDate>
    </item>
    <item>
      <title>MoE - 我对“专家”有点困惑 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aurrxi/moe_im_a_bit_confused_about_experts_d/</link>
      <description><![CDATA[我一直在阅读一些有关专家混合 (MoE) 模型的内容，以及它们如何惩罚模型以确保激活分布相等话虽如此，可以合理地说它不是“这是数学专家，这是科学专家”，而是一个优化的黑匣子在大量训练数据上训练的子模型以针对输入查询的不同维度？ 我更多地将其视为负载均衡器，并且可能是一种通过拆分来抵消大型模型可能产生的负面影响的方法增加工作量。 我们无法控制专家，对吧？  还是我大错特错了？   由   提交 /u/Kaldnite   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aurrxi/moe_im_a_bit_confused_about_experts_d/</guid>
      <pubDate>Mon, 19 Feb 2024 16:41:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 测量两个图之间的相似性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auq6an/d_measure_similarity_between_two_plots/</link>
      <description><![CDATA[您好， 我目前正在微调算法，遇到了一些挑战我希望从这个社区获得一些见解。我的算法经历了一系列全局步骤，产生两组测量结果。这些集合共享相同的 X 值（假设这些代表算法执行中的阶段或时间点），但具有不同的 Y 值（代表每个阶段的性能或输出的某种度量）。 我的主要目标就是比较这两组测量值，以确定其趋势或趋势中的任何显着差异。具体来说，我并不是在寻找 Y 值之间的精确匹配，而是想了解两个测量值是否以有意义的方式存在差异 - 它们通常遵循相同的趋势，还是存在一个测量值与另一个测量值存在显着偏差的点？  考虑到这种情况，我正在考虑使用各种方法来比较这些曲线，例如：  豪斯多夫距离，用于空间比较， 均方误差 (MSE)，用于测量集合之间的平均误差， 动态时间规整 (DTW)，用于考虑潜在相移的模式相似性， Frechet 距离，考虑点的顺序来比较曲线的形状， 交叉相关，以了解与潜在时间滞后的相似性， 绝对差积分，重点关注整个域的总体差异， 皮尔逊相关系数，用于检查集合之间的线性相关性。  我倾向于采用能够突出趋势差异的方法，而不是精确指出确切的数值差异，因为我更感兴趣的是算法的步骤是否始终导致相似的结果，或者是否存在结果显着差异的阶段。 任何人都可以分享他们使用这些方法的经验或建议（或建议其他）进行这种类型的分析？考虑到它们具有相同的 X 值但 Y 值不同，哪种方法最能突出这些测量的趋势差异？ 任何见解、建议或有用资源的参考将不胜感激！&lt; /p&gt; 提前谢谢您！   由   提交 /u/hc7Loh21BptjaT79EG   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auq6an/d_measure_similarity_between_two_plots/</guid>
      <pubDate>Mon, 19 Feb 2024 15:38:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为研究论文手动标记我自己的数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auq3e3/d_manually_labelling_my_own_data_for_a_research/</link>
      <description><![CDATA[这是我的第一篇论文，我需要数据来评估某种方法的性能。有这方面的公共数据集，我需要标记我自己的数据。我可以自己做吗？或者这会损害我正在做的工作的有效性？ 请记住，我来自一个贫穷的第三世界国家，我无法雇用人来标记数据，即使我保存了一些钱，我不能用任何外币支付，因为我们这里不允许。   由   提交 /u/AdOk6683   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auq3e3/d_manually_labelling_my_own_data_for_a_research/</guid>
      <pubDate>Mon, 19 Feb 2024 15:34:52 GMT</pubDate>
    </item>
    <item>
      <title>用于文本字体识别和文本提取的 OCR？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auq0hi/ocr_for_text_font_recognition_and_also_text/</link>
      <description><![CDATA[同学们大家好！  有没有我可能知道的流行或 SOTA OCR 工具？我所看到的只是 Textract 及其变体，但我正在使用的字体有点不同。我确实有每种字体类型的训练数据。简而言之，我想从图像中获取字体类型和文本。  传统方法效果不佳，是否有任何基于变压器的模型或技术可以帮助我完成这项任务？  数据不是很干净，我可能必须将其通过预处理管道，并且很乐意评估各种技术。如果您知道的话请分享:)   由   提交 /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auq0hi/ocr_for_text_font_recognition_and_also_text/</guid>
      <pubDate>Mon, 19 Feb 2024 15:31:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mamba 和状态空间模型的视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aupbct/d_a_visual_guide_to_mamba_and_state_space_models/</link>
      <description><![CDATA[大家好！为了使状态空间模型（和 Mamba）更容易被更广泛的受众接受，我创建了底层技术的视觉指南。 https://maartengrootendorst.substack.com/p/a-visual-guide-to-mamba-and-state 通过 50 多个自定义可视化，我希望它为那些对用于语言建模的 Mamba 和状态空间模型感兴趣的人提供一个直观的起点。 这个想法是专注于直觉，使这一潜在的新功能成为可能。对于该领域的新手来说，架构很容易理解。我确保尽可能将方程式保持在最低限度。 希望这将为那些完全陌生的人提供一个很好的介绍。 如果您有任何反馈和/或者更正，我洗耳恭听！    由   提交 /u/MaartenGr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aupbct/d_a_visual_guide_to_mamba_and_state_space_models/</guid>
      <pubDate>Mon, 19 Feb 2024 15:01:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 放弃 AWS Rekognition</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auo1g8/d_moving_away_from_aws_rekognition/</link>
      <description><![CDATA[最近 AWS 识别开始成为我的项目的成本问题，我只将其用于对象识别（AI Lables）。我目前正在寻找本地解决方案，但不幸的是我目前没有时间或劳动力来创建和训练数据集。 我想知道是否有任何预训练的对象识别模型可以为 AWS rekognition 提供一组类似的类（约 3,000 个）。似乎大多数开源模型都是针对仅包含约 80 个类的 COCO 数据集进行预训练的。 我已经寻找了好几天，但仍然无法解决任何问题，付费模型也是一种选择价格当然合理。   由   提交/u/Redserpent7  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auo1g8/d_moving_away_from_aws_rekognition/</guid>
      <pubDate>Mon, 19 Feb 2024 14:04:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT-4真的可以同时是16x111B和1.8T参数吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1augpo3/d_can_gpt4_really_be_both_16x111b_and_18t/</link>
      <description><![CDATA[Semianalysis 的报告&lt; /a&gt; 早在 7 月份就说过，GPT-4 是一个 1.8T 参数的 MoE 模型，有 16 个专家，每个专家有 111B 个参数。这是根据我读过的摘要得出的，因为我无法通过付费专区。 这两个数字似乎是一致的，因为 16 * 111B = 1.776T 大约等于 1.8T。&lt; /p&gt; 但我读到这不是计算专家混合模型中参数总数的正确方法。例如，人们通常认为 Mixtral 8x7B 有 56B 参数，但实际上只有 47B。我（可能不正确）的理解是，当你说模型是 8x7B 时，这意味着如果你只从每个 MoE 层选择一名专家，那么模型将具有 7B 个参数。将 Mixtral 计算为具有 8*7B=56B 参数将会多计算注意力权重、嵌入权重和路由器权重 7 倍，当你减去它时，你会得到 47B。 如果这是真的，那么 1.776T 同样会高估 GPT-4 中的参数数量，并且会四舍五入到 1.7T 甚至更低，除非几乎所有权重都在 MoE 块中。 这是推理吗正确的？我是否恰当地描述了如何计算 MoE 变压器中的参数？   由   提交/u/kei147  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1augpo3/d_can_gpt4_really_be_both_16x111b_and_18t/</guid>
      <pubDate>Mon, 19 Feb 2024 06:35:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI/ML 实习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1audi2u/d_aiml_internships/</link>
      <description><![CDATA[为什么现在 AI/ML 领域的实习这么难？  我目前拥有一些高级人工智能项目的一年经验。但不知何故，我无法找到任何实习机会。至于工作，我几乎找不到需要5年以下经验的工作。说实话，这令人沮丧。有人可以帮忙吗？   由   提交/u/Anonymous_Life17  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1audi2u/d_aiml_internships/</guid>
      <pubDate>Mon, 19 Feb 2024 03:34:25 GMT</pubDate>
    </item>
    <item>
      <title>[N] Google 博客文章“什么是长上下文窗口？”指出其结果用于 Gemini 1.5 Pro 的长上下文项目需要“一系列深度学习创新”，但没有具体说明这些创新是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1attgz7/n_google_blog_post_what_is_a_long_context_window/</link>
      <description><![CDATA[来自什么是一个很长的上下文窗口吗？:  “我们最初的计划是在上下文中实现 128,000 个代币，我认为设定一个雄心勃勃的标准会很好，所以我建议 100 万个令牌，”谷歌 DeepMind 研究科学家尼古拉·萨维诺夫 (Nikolay Savinov) 说道，他是长上下文项目的研究负责人之一。 “现在我们的研究甚至超过了这个数字 10 倍。”  为了实现这种飞跃，团队必须进行一系列深度学习创新。谷歌 DeepMind 工程师 Denis Teplyashin 解释道：“一个突破引发了另一个突破，每一个突破都开辟了新的可能性。” “然后，当它们全部堆叠在一起时，我们非常惊讶地发现它们可以做什么，从 128,000 个代币跃升至 512,000 个代币，再到 100 万个代币，而就在最近，我们的内部研究中增加了 1000 万个代币。”  相关帖子：[D] Gemini 1M/10M 令牌上下文窗口如何？&lt; /a&gt;   由   提交 /u/Wiskkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1attgz7/n_google_blog_post_what_is_a_long_context_window/</guid>
      <pubDate>Sun, 18 Feb 2024 12:55:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>