<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 28 Nov 2023 12:25:50 GMT</lastBuildDate>
    <item>
      <title>[P] 需要使用 NuScenes 数据集的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185ujdc/p_need_advice_working_with_the_nuscenes_dataset/</link>
      <description><![CDATA[最近开始在学校的一个项目中使用 NuScenes 数据集。我想训练一个 pointNet 网络来仅检测数据集中的一个类，为此我希望删除每一帧上的一些注释。具体来说，我想训练我的模型来仅检测激光雷达传感器的交通锥。有人有这样的经验吗？ 感谢您的建议！   由   提交 /u/ChilliPeperz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185ujdc/p_need_advice_working_with_the_nuscenes_dataset/</guid>
      <pubDate>Tue, 28 Nov 2023 12:07:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我收到了一个对 28*28*3(RGB) 的 MEDMNIST 数据进行分类的任务。更多详细信息如下。需要方法方面的帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185u4jt/d_i_have_been_given_a_task_for_classification_of/</link>
      <description><![CDATA[所以我想对图像进行分类。我对如何分离 3 个 RGB 通道并输入逻辑回归模型感到困惑。我只知道二维线性数据，这相当简单。    由   提交/u/newbie1503  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185u4jt/d_i_have_been_given_a_task_for_classification_of/</guid>
      <pubDate>Tue, 28 Nov 2023 11:42:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 需要帮助寻找法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185teo3/p_need_help_finding_a_llm/</link>
      <description><![CDATA[你好， 我不确定这是否是提出这个问题的正确子，所以请告诉我是否有一个更好的子来问这个问题。 我是一名学生，我和我的团队的任务是为我们的大学制作一个聊天机器人。我们需要制作一个聊天机器人来帮助其他学生找到有关他们课程的信息。我们将从多个大学网站的手册中获取数据（pdf 格式）。这些数据将使用 ChatGPT 4 转化为问答数据。 但是，我们正在努力寻找适合我们任务的预训练法学硕士。我们研究了 T5、BERT 和 GPT-2，但我们的老师对我们研究的模型感到惊讶，因为还有更流行和更新的模型。我们的聊天机器人必须是荷兰语，但我们可以进行翻译，因此法学硕士不需要接受荷兰语数据的培训。 LLM不能太大，因为我们没有用于非常大模型的硬件。 我们目前正在考虑openchat和falcon，两者都有7B参数。这些是不错的选择吗？或者有人对更好的法学硕士有任何建议吗？   由   提交 /u/Flo501   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185teo3/p_need_help_finding_a_llm/</guid>
      <pubDate>Tue, 28 Nov 2023 10:56:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要廉价的云 GPU 服务（Lambda Labs 的替代品）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185ssjk/d_needed_cheap_cloud_gpu_services_alternatives_to/</link>
      <description><![CDATA[我想为一篇学术论文进行一些实验，需要访问一些高端 A100/H100 GPU 以及用于大型数据集的大量存储空间（200-400GB）。不幸的是，LambdaLabs 在我所在的地方（印度）不可用，我将无法使用它。请提出成本不会太高的替代方案。 提前致谢。   由   提交/u/Mad_Scientist2027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185ssjk/d_needed_cheap_cloud_gpu_services_alternatives_to/</guid>
      <pubDate>Tue, 28 Nov 2023 10:15:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] Keras 和 Tensorflow 中的分支子模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185sn5j/d_branching_submodel_in_keras_and_tensorflow/</link>
      <description><![CDATA[假设我有一个模型，它有 2 个输入。第一个输入是一个数字，第二个输入是另一个数字，实际上是一个类。 该模型分为 2 个子模型。第一个子模型作用于输入，第二个子模型作用于第一个子模型的输出。 第一个输入的值将很大程度上取决于第二个子模型的输出。因此，我希望能够拥有第一个子模型的多个候选者，并在训练和推理期间根据第二个输入的值（类）动态选择在每一步使用哪个子模型。 我没能做到这一点。我尝试使用 tf.cond、tf.switch_case 和其他一些东西，但我从未成功。当我询问聊天 GPT 时，它说我应该使用 PyTorch 来实现此目的。难道真的没有办法做到这一点吗？   由   提交/u/work_account_mp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185sn5j/d_branching_submodel_in_keras_and_tensorflow/</guid>
      <pubDate>Tue, 28 Nov 2023 10:04:34 GMT</pubDate>
    </item>
    <item>
      <title>使用推测解码调整概率分布 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185rtqi/adjusting_probability_distribution_using/</link>
      <description><![CDATA[嗨，推测解码运行一个小模型和一个大型模型，中间有一个采样器，但在这种情况下，采样器的工作是在这样做时不扭曲概率分布。 这里有一个相当简单的 Python 实现。有没有办法可以调整小模型或大模型的概率分布来完成生成任务？   由   提交/u/1azytux  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185rtqi/adjusting_probability_distribution_using/</guid>
      <pubDate>Tue, 28 Nov 2023 09:07:16 GMT</pubDate>
    </item>
    <item>
      <title>[P]刚刚上传了第一个>34B Yi模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185rq7z/p_just_uploaded_the_first_34b_yi_model/</link>
      <description><![CDATA[大家好！ 受到最近一个帖子的启发，提到了疯狂的歌利亚能力，我决定合并四个 SFT Yi 模型来制作2 个单独的 55B Yi，一个上下文 200K，一个上下文 32K。 尝试 它们 出来告诉我！   由   提交 /u/BeautifulLM   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185rq7z/p_just_uploaded_the_first_34b_yi_model/</guid>
      <pubDate>Tue, 28 Nov 2023 09:00:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2023机构排名</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185pdax/d_neurips_2023_institutions_ranking/</link>
      <description><![CDATA[       由   提交/u/Roland31415   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185pdax/d_neurips_2023_institutions_ranking/</guid>
      <pubDate>Tue, 28 Nov 2023 06:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] SuGaR：用于高效 3D 网格重建和高质量网格渲染的表面对齐高斯喷射</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</link>
      <description><![CDATA[计算机视觉研究人员开发了一种方法，只需几分钟即可在单个 GPU 上根据图像创建详细的 3D 模型。他们的方法称为 SuGaR，通过优化数百万个微小粒子来匹配场景图像。关键的创新是让粒子与表面对齐，以便可以轻松地将它们变成网格。 传统的 3D 建模速度慢且资源繁重。激光扫描不方便。摄影测量点云缺乏细节。像 NeRF 这样的神经辐射场可以产生令人惊叹的渲染效果，但即使使用强大的硬件，将它们优化为网格也需要数小时或数天的时间。 VR/AR、游戏、教育等领域对更轻松的 3D 内容创建的需求不断增长。但大多数技术都有很大的速度、质量或成本限制，阻碍了它们主流使用。 这种新的 SuGaR 技术结合了神经场景表示和计算几何方面的最新进展，推动了最先进的技术的发展它首先利用一种称为高斯喷射的方法，该方法基本上使用大量微小粒子来复制场景。放置和配置粒子只需几分钟。问题是它们不会自然地形成连贯的网格。 SuGaR 提供了一种新的初始化和训练方法，可以将粒子与场景表面对齐，同时保持细节完整。这种条件允许将粒子云直接视为点云。 然后，他们应用一种称为泊松表面重建的计算技术，以并行方式直接在结构化粒子之间构建网格。一次处理数百万个粒子可以在低延迟的情况下实现高保真度。 通过将繁重的工作转移到前端点云结构化阶段，SuGaR 使最终网格生成与其他最先进的技术相比极其高效-艺术神经/混合方法。 实验表明，SuGaR 构建详细网格的速度比之前发布的技术快几个数量级，同时实现具有竞争力的视觉质量。该论文分享了一些在 10 分钟内重建复杂场景的有希望的示例。 处理更多样化的场景类型仍然存在问题。但就使用可访问的硬件使高质量 3D 重建更接近交互速度而言，这看起来是引人注目的进步。 TLDR：对齐高斯溅射中的粒子可让您将它们转变为详细的网格。使高质量 3D 更好、更快、更便宜。 完整摘要位于此处。论文网站此处。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</guid>
      <pubDate>Tue, 28 Nov 2023 02:37:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是正常现象还是我进错公司了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185fk7v/d_is_this_normal_or_im_just_at_the_wrong_company/</link>
      <description><![CDATA[我是一名初级 Python 开发人员。我在一家公司工作了一年多，差不多一年半了，我住在英国伦敦。自从他们雇用我以来，我一直在一个项目上独自工作，一个人工智能/数据科学项目，使用我以前从未使用过的技术，在一个我从未从事过的领域。我的任务是开发它，没有具体的截止日期，但要取得进展。 我想，好吧，太好了，我将有新的东西要学习。有一段时间效果不错，工作了几个月，然后他们给我分配了另一个项目去做。这另一个项目也充满了我以前从未使用过的新技术。所以，我正在做两个项目，我面临着越来越多的挑战，因为正如我提到的，许多事情都是新的，而且仍然是新的。我曾多次寻求帮助，但从根本上来说，我从未得到过帮助，因为事实证明，公司里没有人了解这个与人工智能相关的特定领域。后来我发现他们想出售这个产品（我一直在自己开发），这对我来说有点疯狂，因为我只是一个初级学生，以前从未做过这样的事情...... 我总是得到尝试自己解决问题的答复，因为他们无能为力。所以，我尝试独自完成，大量尝试、研究、重写、测试，我成功完成了项目的 90% 左右，但我陷入了困境。我不知道如何完成它，也没有得到任何帮助。我觉得我开始讨厌编程了。最糟糕的是，因为我没有完成它，因为我被卡住了，所以我被告知要决定我是否可以完成该应用程序，因为如果不能，他们就必须放弃它，那将是非常糟糕的。 .这是正常现象还是我进错公司了？工资也很低，没有福利，唯一好的“福利”就是就是它是完全远程的。 我总是听说我的表现非常好，我的工作受到赞赏，人们喜欢和我一起工作。然而，正因为如此，我担心他们会和我分道扬镳……不过，我想，也许这样是最好的吧？我的一些资深开发人员朋友告诉我，我一开始就不应该接受这份工作机会，但不幸的是，当时没有其他选择。 &lt;!-- SC_ON - -&gt;  由   提交/u/eldobhatobugyi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185fk7v/d_is_this_normal_or_im_just_at_the_wrong_company/</guid>
      <pubDate>Mon, 27 Nov 2023 22:19:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 扭曲、分散注意力、解码：指令调整模型可以优化其对噪声指令的响应</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185f16f/r_distort_distract_decode_instructiontuned_model/</link>
      <description><![CDATA[      ​ &lt; p&gt;https://preview.redd.it/4dvuvo18113c1。 png?width=1916&amp;format=png&amp;auto=webp&amp;s=4b9ba695cb00719c3e80c931f8b52a1008d7db5b 链接： https://openreview.net/forum?id=IqJ3CU3flr摘要：  虽然指令调整语言模型已经展示了令人印象深刻的零样本泛化能力，但这些模型通常难以生成准确的结果当面对超出训练集的指令时的反应。本文提出了指令解码（ID），这是一种简单而有效的方法，可以增强指令调整模型的效率。具体来说，ID 利用从原始指令的操纵版本（称为噪声指令）生成的预测，以对比方式调整下一个令牌预测的逻辑。这种嘈杂的指令旨在引发可能偏离预期指令但仍然合理的反应。我们对一系列此类噪音指令进行了实验，从通过随机单词插入语义噪音的指令到其他诸如引发偏差反应的“相反”指令。我们的方法在各种指令调整模型和任务中实现了可观的性能提升，而无需任何额外的参数更新。值得注意的是，利用“相反”作为 ID 中的噪声指令，与原始指令表现出最大的差异，在多个模型和任务中始终如一地产生最显着的性能提升。  https://preview.redd.it/6eymp2kb113c1.png?width=1174&amp; ;format=png&amp;auto=webp&amp;s=7613f4c269ca9107f88246fd5fa354670a5883a5 ​ https://preview.redd.it/kvtr8bvf113c1.png?width=2162&amp;format=png&amp;auto=webp&amp;s=ff4a414ed8 bdfc28d794d65d84311faa1a4ecf59&lt; /a&gt;   由   提交/u/Queasy_Ad_6423  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185f16f/r_distort_distract_decode_instructiontuned_model/</guid>
      <pubDate>Mon, 27 Nov 2023 21:58:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] AISTATS 2024 论文评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185a6g4/d_aistats_2024_paper_reviews/</link>
      <description><![CDATA[AISTATS 2024 论文评论预计今天发布。我想为我们创建一个讨论线程来讨论任何问题/抱怨/庆祝或其他任何事情。 每年的评论都有很多噪音。考虑到 AISTATS 这些年的规模不断扩大，一些作者引以为豪的好作品可能会因为系统噪音而获得低分。我们应该记住，无论分数是多少，作品仍然有价值。   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185a6g4/d_aistats_2024_paper_reviews/</guid>
      <pubDate>Mon, 27 Nov 2023 18:41:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你会痴迷地观看模特训练吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18576ol/d_do_you_obsessively_watch_your_models_train/</link>
      <description><![CDATA[我发现自己看张量板的时间多于工作——只是想知道其他陷入这种模式的人是否对生产力有什么建议   由   提交 /u/TehDing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18576ol/d_do_you_obsessively_watch_your_models_train/</guid>
      <pubDate>Mon, 27 Nov 2023 16:39:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] AI 生成的图像给文本图像检索带来了隐形的相关性偏差</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1853e5y/r_aigenerated_images_introduce_invisible/</link>
      <description><![CDATA[    &lt; /a&gt;  人工智能生成的图像为文本图像检索引入了无形的相关性偏差 [arxiv] https://arxiv.org/pdf/2311.14084.pdf 嘿 Reddit 社区， 我们将源偏差的研究扩展到多模态，我们很高兴分享我们对 AIGC 和文本图像检索模型的最新研究的有趣发现。以下是一个快速概述： (1) 揭示无形的相关性偏差：我们的研究发现，文本图像检索模型倾向于为人工智能生成的图像分配更高的排名，尽管与真实图像相比，它们不会显示与查询更具视觉相关性的信息。我们将这种现象称为“看不见的相关性偏差”。 （2）训练引起的更严重的偏差：进一步的探索表明，当人工智能生成的图像被纳入到随着文本图像检索模型的训练数据的增加，这种偏差变得更加严重。这揭示了一个令人担忧的恶性循环：看不见的相关性偏差增加了从海量数据集中获取生成图像的可能性。随后，这些图像更有可能混入AIGC模型和检索模型的训练中，加剧偏差。 （3）引入有效的缓解方法：根据这些发现，我们提出了一种高效的训练方法来减轻隐形相关偏差。 （4）揭示这种偏差的原因：我们的分析和实验表明，不可见的相关性偏差是人工智能生成的图像导致图像编码器将附加信息嵌入到其表示中。这些信息在人工智能生成的不同语义的图像中具有一定的一致性，可以放大相关性得分。 ​ 隐形相关性偏差造成的恶性循环。 ​ 实验结果。 文本IR中来源偏差的原始论文和讨论在这里： Arxiv：https:// arxiv.org/abs/2310.20501 Reddit：https：/ /www.reddit.com/r/MachineLearning/comments/17l88lw/r_llms_may_dominate_information_access_neural/   由   提交/u/Latter-Confidence595  /u/Latter-Confidence595 reddit.com/r/MachineLearning/comments/1853e5y/r_ai generated_images_introduce_invisible/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1853e5y/r_aigenerated_images_introduce_invisible/</guid>
      <pubDate>Mon, 27 Nov 2023 13:50:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>