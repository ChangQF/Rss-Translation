<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sat, 08 Feb 2025 09:15:02 GMT</lastBuildDate>
    <item>
      <title>[d]是否有可能融合不同的块，甚至整个变压器都可以加速LLM火车和Triton的参考？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ikj9ml/d_is_it_possible_to_fused_different_blocks_even/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我们融合了变压器中的不同块，则中间变量将较少，例如“ feed fortht”并“添加＆amp;规范“线性” ＆＆quot“ softmax＆quot，甚至整个变压器层。这可以减少大量内存使用和计算。 是否有类似的作品或研究？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/logical_divide_3595      [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ikj9ml/d_is_it_possible_to_fused_different_blocks_even/</guid>
      <pubDate>Sat, 08 Feb 2025 09:04:53 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]打开AI的剪辑对图像分类字段的影响是什么？另外，是否可以适应OCR夹？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ikhp9s/discussion_what_was_the_effect_of_open_ais_clip/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  打开AI的剪辑对图像分类字段的影响是什么？另外，是否可以适应OCR夹？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/no_statistician_5478      [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ikhp9s/discussion_what_was_the_effect_of_open_ais_clip/</guid>
      <pubDate>Sat, 08 Feb 2025 07:14:32 GMT</pubDate>
    </item>
    <item>
      <title>[r] AI代理中的安全性自治权衡：风险分析框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ikhjqr/r_the_safetyautonomy_tradeoff_in_ai_agents_a_risk/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了一项结构化分析，反对开发完全自主的AI系统，研究了使人类监督所必需的技术局限性和安全考虑因素。核心方法涉及分析跨多个维度的自主权并建立一个评估AI系统独立性的框架。 关键技术点： - 定义AI自治级别的频谱，从基本自动化到理论完全独立性 - 检查技术障碍 - 为了安全的自主操作，包括鲁棒性，不确定性处理和价值对齐方式 - 分析当前自主系统及其缩放属性中的故障模式 - 提出了用于衡量有意义的人类控制和监督 结果的指标，结果显示了几个关键限制： - 当前AI系统在自动运行时缺乏可靠的安全保证 - 价值学习方法不能可靠地扩展到复杂的决策空间 - 随着系统能力的提高，控制机制变得更加难以指数 - 人类的监督显着降低了灾难性失败模式 我认为这是我认为这研究可以通过专注于增强而不是替换来重塑我们如何处理AI开发的方法。确定的技术障碍表明，我们应该优先考虑强大的人类协作框架，而不是追求完全的自主权。尽管分析主要是理论上的，但它为技术发展和政策决策提供了具体的指导。 我认为，最重要的见解是维持有意义的人类控制不一定限制AI的能力 - 相反，它可能可以对于开发更可靠和有益的系统至关重要。提出的框架可以帮助指导更安全的AI系统的实际开发。  TLDR：技术分析显示完全自主的AI系统面临基本安全和控制挑战。研究表明，在开发强大的人类协作框架时保持人类的监督。  完整摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ikhjqr/r_the_safetyautonomy_tradeoff_in_iai_ai_aigents_a_risk/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ikhjqr/r_the_safetyautonomy_tradeoff_in_ai_agents_a_risk/</guid>
      <pubDate>Sat, 08 Feb 2025 07:03:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] Torchhd：用于高维计算的Python库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ik7rqf/p_torchhd_a_python_library_for_hyperdimensional/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  超维度计算（HDC），也称为矢量符号体系结构，是受大脑如何处理信息启发的替代计算范式。 HDC不是传统的数字计算，而是在高维矢量（称为HyperVectors）上运行，可以实现快速和噪声的学习，通常没有反向传播。  Torchhd是HDC的库，建在Pytorch上。它为研究人员和开发人员提供了一个易于使用的模块化框架，可以在利用GPU加速度的同时尝试使用HDC模型和应用。 Torchhd旨在使原型制作和缩放HDC算法轻松。  github存储库：。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/careativenerd     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ik7rqf/p_torchhd_a_python_library_for_hyperdimensional/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ik7rqf/p_torchhd_a_python_library_for_hyperdimensional/</guid>
      <pubDate>Fri, 07 Feb 2025 22:34:04 GMT</pubDate>
    </item>
    <item>
      <title>[d] LLMS模型合并中有哪些开放式问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ik6me0/d_what_are_some_openended_problems_in_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  基本上是标题，我希望积极研究LLMS模型合并的领域。尽管我发现了各种现有的方法和正在进行的积极研究，但我非常有兴趣寻找未来研究的领域。目前，我所能发现的只是模型合并方法的理论分析中的显着差距，但是试图在LLM中找到一个也没有探索的LLM中的重要应用看起来很难。我会要求子成员分享他们的见解。作为一个想进行一些理论分析但现在严格坚持LLM的人（因为我可能会发现核心理论很难为我的初步研究和其他一些原因），这应该是什么？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/arinjay_11020     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ik6me0/d_what_are_some_openended_problems_in_model/</guid>
      <pubDate>Fri, 07 Feb 2025 21:44:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] GRPO适合8GB VRAM -DeepSeek R1的零食谱</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ik3nkr/p_grpo_fits_in_8gb_vram_deepseek_r1s_zeros_recipe/</link>
      <description><![CDATA[   &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ik3nkr/p_grpo_fits_in_8gb_vram_deepseek_deepseek_deepseek_deepseek_err1s_zeros_zeros_recipe/ DeepSeek R1&#39;s Zero&#39;s recipe&quot; src=&quot;https://external-preview.redd.it/E6uDJHBPBWs1lRLa7r4ngrfpHTyxgGd4s0e5fqmO9Us.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a2f1f8e3abd497362cd6f13ccfb43fdb6df4bdfe&quot; title=&quot;[P] GRPO fits in 8GB VRAM-DeepSeek R1的零食谱“/&gt;    &lt;！ -  sc_off-&gt;  嘿 r/machinelearning 社区！我设法使GRPO适合8GB的VRAM，QWEN 1.5B使用 Unsloth 现在！  LLAMA 3.1 8b拟合13GB的VRAM  和Phi -4 14b拟合15GB的VRAM  - 所有人都可以免费 google colab笔记本 -grpo.ipynb）！   grpo是deepseek r1零的推理的RL食谱奇迹，您现在可以通过UNSPOLT和LORA/QLORA！ /a&gt;证明您可以实现自己的“ aha”使用QWEN2.5（1.5B）的力矩 - 但最少需要2XA100 80GB GPU（160GB VRAM）。现在您可以更有效地做到！脚本没有通过VLLM建议LORA，因为不幸的是，VLLM不能正确地加载Loras  - 我使其正确完成！  unsploth也直接集成了Vllm以进行快速推理，并删除了双重内存副本，可以用于现在，本来可以使用20倍更快的吞吐量！   u/m98789  标记了我在使Grpo在Unsloth中工作的标记，因此这里是！！抱歉，这花了一段时间 - 试图将VLLM和GRPO整合到其中非常复杂！还非常感谢态llama3.1_（8b“&gt; Llama 3.1 8b colab链接 -grpo.ipynb）   phi-4 14b colab链接 -grpo.ipynb）    qwen 2.5 3b colab link  -grpo.ipynb）        Llama 8b需要〜13GB   phi-4 14b需要〜15GB   qwen 3b需要〜7GB      博客以获取更多详细信息： https://unsloth.ai/blog/r1-reasoning    我还为特定的运行绘制了奖励曲线，显示其有效：       另外，如果您没有W＆amp; b，我在Jupyter Notebooks和Colab Works and Colab work and colab work and colab works and poc          也是如此在运行grpo之前，请将其开始修补所有内容：   intsploth import fastflanguagemodel，patchfastrl patchfastrl（&#39;grpo; fastlangugemogemodel）    要使用vllm do安装不舒服（由于TRL需要它，您需要扩散器）： pip安装unsploth vllm扩散器trl    非常感谢！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/danielhanchen     [link]   ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ik3nkr/p_grpo_fits_in_8gb_vram_deepseek_r1s_zeros_recipe/</guid>
      <pubDate>Fri, 07 Feb 2025 19:39:26 GMT</pubDate>
    </item>
    <item>
      <title>[r]在10个分类任务中的10个中，PerpetualBooster的表现优于Autogluon</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ik1q76/r_perpetualbooster_outperformed_autogluon_on_10/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   perpetualBooster是GBM，但行为类似于Automl，因此对Autogluon（v1.2，最佳质量预设）进行了基准测试，是 automl基准标。从 OpenML数据集进行分类任务的前10个数据集选择了最多的行。  下表中总结了结果：      OpenML任务 永久训练持续时间 永久推断持续时间 永久auc   autogluon训练持续时间  autogluon推断持续时间     bng（spambase）     70.1 &lt; /td&gt;  2.1   0.671   73.1    3.7    0.669        bng（trains）     89.5    1.7   0.996   106.4   2.4    0.994        breast     13699.3    97.7    0.991  0.991     13330.777330.777.7   79.7   0.949      click_prediction_small    89.1   1.0    0.749    101.0   2.8  2.8    &lt; td&gt; 0.703      colon   126.7   0.997    12356.2    152.3    0.997          higgs      3485.3    40.9  40.9      TD&gt; 0.843   3501.4   67.9    0.816        sea(50000）    21.9   0.2  0.2   0.936     25.6   0.5   0.935       sf-police-incidents    85.8   1.5    0.687    99.4   2.8&gt; 2.8   0.659      bates_classif_100  &gt;  11152.8   50.0   0.864    oom    oom    oom  oom   &lt; /tr&gt;    prostate     13699.9    0.987   oom   oom    oom      平均&gt;  3747.0   34.0     -     3699.2    39.0     -    -      &lt; /tr&gt;    PerpetualBooster的表现优于10个分类任务中的10个，训练同样快速且更快地推断1.1倍。  与Autogluon相比，PerpetualBooster表现出更大的鲁棒性，成功地对所有10个任务进行培训，而自动luon在其中的2个任务上遇到了不可存储的错误。  github： https://github.com/perpetual-ml/perpetual     &lt;！ -  sc_on- ＃32;提交由＆＃32; /u/u/mutlu_simsek     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ik1q76/r_perpetualbooster_outperformed_autogluon_on_10/</guid>
      <pubDate>Fri, 07 Feb 2025 18:19:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们需要VAE中的Elbo，为什么不只是从后部取样？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ik17hx/why_do_we_need_the_elbo_in_vaes_why_not_just/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  引入ELBO作为VAE中的优化目标的原始动机是因为评估真实的可能性是棘手的。但是，在Elbo中，您与重建损失期限遇到了同一问题。然后提出蒙特卡洛采样作为一种通过近似重建损失项（带有单个数据点？！）的方式来解决此问题的一种方式。 我很困惑为什么我们不能做同样的事情和近似使用MC采样方法的真实可能性？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/credtz     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ik17hx/why_do_do_we_need_the_elbo_elbo_in_vaes_vaes_vaes_why_not_just/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ik17hx/why_do_we_need_the_elbo_in_vaes_why_not_just/</guid>
      <pubDate>Fri, 07 Feb 2025 17:58:51 GMT</pubDate>
    </item>
    <item>
      <title>最好的矢量数据库是什么？矢量数据库中有什么新功能，一个比另一个更好？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ijxrqj/whats_the_best_vector_db_whats_new_in_vector_db/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  到目前为止，我已经像一堆向量DB一样遇到了，如果您密切关注此字段。然后有一些最近的人，例如Chromadb和Lancedb。 我想保持一个公开的讨论，我希望人们在与之相关的思想和经验中汇集自己的思想和经验。因此，我有3个基本问题：  是什么使一个与另一个不同？ 在哪种情况/用例中，最适合哪种db？  您认为通常是最好的或简单地说的是什么？ （您可以自由托管的东西），并且应该具有基本功能，例如存储元数据/标签和基于它们的过滤。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/usious-swim1266     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ijxrqj/1ijxrqj/whats_the_the_best_vector_db_db_whats_new_in_in_in_in_in_in_in_vector_db/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ijxrqj/whats_the_best_vector_db_whats_new_in_vector_db/</guid>
      <pubDate>Fri, 07 Feb 2025 15:37:22 GMT</pubDate>
    </item>
    <item>
      <title>[d] VIT从头开始过度拟合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ijr0ap/d_vit_from_scratch_overfitting/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿。对于一个项目，我必须培训VIT进行癫痫发作定位。输入是多通道频谱[22,251,289]（伪固定量）。培训数据大小为27000个样本。我正在使用Timm Vitsmall，其补丁大小为16。我正在使用平衡的采样器来处理类不平衡和增强。 90％的增强材料。我将Specaug，Mixup和FT代理用作增强。另外，我使用ADAMW和LR调度程序和辍学器，我认为我的模型可能只有很多参数。下一步是vit很小且较小的贴片大小。从头开始训练时，如何处理大型模型的过度拟合？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nigale-joke5751     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ijr0ap/d_vit_from_scratch_overfitting/</guid>
      <pubDate>Fri, 07 Feb 2025 09:15:53 GMT</pubDate>
    </item>
    <item>
      <title>[d]部署深度学习模型（Docker，Onnx，服务...）的好实践是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ijr075/d_what_is_good_practice_to_deploy_a_deep_learning/</link>
      <description><![CDATA[在或在线。  当前我的模型在一个装有eN api的pytorch-cuda映像的码头中运行。 我想知道我是否应该开始查看ONNX运行时和/或Tensor-rt，但是我不确定工作流程。有些人由于某种原因仅使用ONNX，其他人将其与张力结合在一起。 我也对使用型号的服务毫无了解，所以我使用Litserve，因为它易于使用，但我知道Triton可能更成熟，并且生产等级。 感谢您的见解  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lelouchzer12     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ijr075/d_what_is_is_good_good_to_to_to_to_deploy_a_deep_lealearning/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ijr075/d_what_is_good_practice_to_deploy_a_deep_learning/</guid>
      <pubDate>Fri, 07 Feb 2025 09:15:43 GMT</pubDate>
    </item>
    <item>
      <title>[r]用字母测定法解决奥林匹克几何形状的金医师表现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ijpmfg/r_goldmedalist_performance_in_solving_olympiad/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   黄金 - 医学家在解决奥林匹克几何学时使用Alphageometry2  Yuri Chervonyi，Trieu H. Trinh，MiroslavOlšák，Miroslavolšák，Xiaomeng Yang Yang Yang Yang Nguyen，Hoang nguyen，hoang nguyen，，，Hoang nguyen，，，，，，Yang nguyen，，，hoang nguyen，，，hoang nguyen，，，hoang nguyen，，，hoang nguyen，，，hoang nguyen，， Marcelo Menegali，Junehyuk Jung，Vikas Verma，Quoc V. Le，Thang Luong  arXiv：2502.03544 [CS.AI]：  我们介绍了Alphageometry2，这是Trinh等人中引入的字母测定法的显着改进。 （2024），现在已经超过了解决奥林匹克几何问题的平均金牌得主。为了实现这一目标，我们首先将原始的字母计量学语言扩展到解决涉及对象运动的更严重问题，以及包含角度，比率和距离的线性方程的问题。这与其他增加一起显着提高了国际数学奥林匹克运动会（IMO）2000-2024几何问题的覆盖率从66％到88％。通过使用Gemini架构来更好地建模，并且通过使用Gemini架构以及一种结合了多个搜索树的新型知识共享机制，可以极大地改善Alphageometry2的搜索过程。加上对符号发动机和合成数据生成的进一步增强，在过去25年中，所有几何问题的总体求解率显着提高到了84％，而先前的54％。 Alphageometry2也是该系统在IMO 2024上获得银色标准的系统的一部分。最后但并非最不重要的一点是，我们报告了使用Alphageometry2作为完全自动化系统的一部分，该系统可靠地从自然语言输入中可靠地解决几何问题。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nunki08     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ijpmfg/r_goldmedalist_performance_in_solving_olympiad/</guid>
      <pubDate>Fri, 07 Feb 2025 07:32:12 GMT</pubDate>
    </item>
    <item>
      <title>[r]事实证明我们确实需要RNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ijjq5y/r_it_turns_out_we_really_did_need_rnns/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在我的最新研究中，我证明了迭代推理框架（如三链链）的融合，我的最后一篇论文上下文反馈回路。我还证明，前馈模型需要一个比复发结构更深入的网络，以达到相同的准确性。这些都是在温和的假设下。 如果您喜欢ML理论，这是一个有趣的读物（我有偏见）。同样，这是论文的要点：   加速收敛：    它的含义：纸张证明当没有持续的噪声时，迭代推理框架以最佳速率（或固定点）收敛到其目标（或固定点），该速率比例为O（1/T^2）。在这里，t表示算法的迭代次数或更新步骤。本质上，当您进行更多迭代时，误差会快速降低。  深度：即使更新过程受到自适应，状态依赖性扰动（小，可能，可能是可能的）在每个步骤中都会改变错误），该方法在适当的平稳性和合同性假设下保持了这种快速收敛速率。在每次迭代中，该过程在最终解决方案方面取得了重大进展，使其在理想（无噪声）方案中高效。       反馈/反复的必要性：    它的含义：分析表明，反馈（或迭代/经常性）架构 - 一个步骤的输出回到下一个步骤中 - 对有效地近似定点函数。固定点函数是重复应用该函数最终导致稳定值（固定点）的功能。  深度：论文表明，使用这种迭代方法，可以使用多个迭代来实现所需的近似值，这些迭代对给定的错误ϵ）进行多个缩放（例如O（1/\ sqrt {ϵ}））。相比之下，馈电模型不会回到自己的输出上，而是在单个正向传递中计算答案，这将需要一个具有指数深度的网络，以匹配相同的准确性水平。这强调了设计系统具有反馈循环以有效处理复杂推理任务的重要性。       &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jacobfa     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ijjq5y/r_it_turns_out_we_really_did_need_rnns/</guid>
      <pubDate>Fri, 07 Feb 2025 01:48:43 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会导致禁止。 鼓励其他人创建新的帖子，以便在此处发布问题！ 线程将一直活着直到下一个，因此请继续发布标题之后的发布。    meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      对于那些寻找工作的人请使用此模板  &lt; p&gt;想要被录用：[位置]，薪水期望：[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简短概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，这个社区是适合有经验的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>