<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 13 Apr 2024 03:11:51 GMT</lastBuildDate>
    <item>
      <title>ACL 2024 元评论 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2qnpp/acl_2024_meta_reviews_discussion/</link>
      <description><![CDATA[讨论线程：审核版本的后续内容 主题。 审稿人评分 --- 总体评估：3.5、2、3；健全性：3.5、3、3.5；置信度：4、4、3；  虽然我们对R2（得了2分）进行了非常详细和深入的反驳，但他们在讨论阶段却没有任何反应。我们向元审稿人发送了一条机密消息，表明某些审稿人评论不符合 ARR 审阅清单。 元审阅者的总体评估为 4。   元审稿人同意我们对审稿人评论的所有反驳（包括我们关于审稿清单不合规的观点）。元审阅者认为添加一些相关的工作讨论是唯一需要的小改动。  你们呢？论文被主要会议或研究结果接受的机会有多大？ ​   由   提交/u/NarrowHeat557  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2qnpp/acl_2024_meta_reviews_discussion/</guid>
      <pubDate>Sat, 13 Apr 2024 01:58:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在顶级 ML 会议上发表多篇第一作者论文，但仍在努力进入博士学位课程。我缺少什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2pnam/d_multiple_firstauthor_papers_in_top_ml/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2pnam/d_multiple_firstauthor_papers_in_top_ml/</guid>
      <pubDate>Sat, 13 Apr 2024 01:04:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 文转图像模型训练工作站升级建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2ophq/p_workstation_upgrade_recommendations_for/</link>
      <description><![CDATA[嘿伙计们， 我需要一些关于升级我的工作站设置以训练文本到图像模型的建议，主要关注稳定的模型扩散。目前我有一台 Lenovo p620，配备 3945wx Threadripper 和 64GB RAM。我最近购买了 4090 Liquid X Suprim 和 4070 Ti，均为 MSI。以下是我的问题：  我应该重新利用当前设置中尽可能多的部件（CPU、RAM、主板等）还是选择全新的构建？&lt; /p&gt; 是否值得在同一版本中使用两个 GPU 来训练模型，还是坚持使用一个 GPU 更好？ 如果我要使用消费部件进行新构建，您会推荐什么？    由   提交 /u/RuleIndividual6374   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2ophq/p_workstation_upgrade_recommendations_for/</guid>
      <pubDate>Sat, 13 Apr 2024 00:19:57 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 角色扮演游戏的人工智能应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2kxjl/project_an_ai_app_for_roleplay_games/</link>
      <description><![CDATA[这款 AI 应用程序将成为任何角色玩家的首选。  Privee.ai 使用人工智能创建能够扮演不同角色并参与不同类型角色扮演的数字角色将文本和图像生成结合在一起。 得益于尖端的语言模型，人工智能角色感觉真实，并且能够以完全自然的方式进行交互。    由   提交 /u/JohnnyVeraz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2kxjl/project_an_ai_app_for_roleplay_games/</guid>
      <pubDate>Fri, 12 Apr 2024 21:32:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] ColBERT 与其他 BI 编码器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2ijbv/d_colbert_vs_other_bi_encoder/</link>
      <description><![CDATA[所以根据我的理解，colbert 是一个双编码器，因为它分别对段落和查询进行编码。那么它与 all-mini-LM 等其他双编码器有何不同呢？只是它计算令牌级别的嵌入并维护查询和段落的嵌入列表，而 all-mini 为整个查询创建单个嵌入并为整个段落创建单个嵌入。您可以通过将查询嵌入列表与段落嵌入列表相乘来获得 colbert 中的分数，然后获得分数。 是否有任何指南可以帮助您理解尝试从头开始制作它（使用 BertPretrained ）或我可以查看从头开始尝试的任何相关模型？我检查了 ColBERT GitHub，它对我没有太大帮助   由   提交/u/Automatic-Net-757   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2ijbv/d_colbert_vs_other_bi_encoder/</guid>
      <pubDate>Fri, 12 Apr 2024 19:53:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用 CLIP 创建用于对象检测的自定义数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2i3zm/d_how_to_create_a_custom_dataset_for_object/</link>
      <description><![CDATA[对此的任何指导、视频建议将不胜感激。    ;由   提交/u/Aggressive-22  /u/Aggressive-22 reddit.com/r/MachineLearning/comments/1c2i3zm/d_how_to_create_a_custom_dataset_for_object/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2i3zm/d_how_to_create_a_custom_dataset_for_object/</guid>
      <pubDate>Fri, 12 Apr 2024 19:35:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 从单词到数字：当给定上下文示例时，您的大型语言模型实际上是一个有能力的回归器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2hzlj/r_from_words_to_numbers_your_large_language_model/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.07544 代码：https://github .com/robertvacareanu/llm4regression 摘要：  我们分析预训练的大型语言模型（例如 Llama2）的效果如何、GPT-4、Claude 3 等）在给定上下文示例时可以进行线性和非线性回归，无需任何额外的训练或梯度更新。我们的研究结果表明，几种大型语言模型（例如 GPT-4、Claude 3）能够执行回归任务，其性能可与随机森林、Bagging 或 Gradient Boosting 等传统监督方法相媲美（甚至优于）。例如，在具有挑战性的 Friedman #2 回归数据集上，Claude 3 的性能优于许多监督方法，例如 AdaBoost、SVM、随机森林、KNN 或梯度提升。然后，我们研究大型语言模型的性能随上下文样本数量的变化情况。我们借鉴了在线学习的遗憾概念，并凭经验证明法学硕士能够获得亚线性遗憾。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2hzlj/r_from_words_to_numbers_your_large_language_model/</guid>
      <pubDate>Fri, 12 Apr 2024 19:30:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 BERT/GPT2 风格模型中处理具有大量 token 的输入文档的技术？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2gwh4/d_techniques_for_handling_input_documents_with_a/</link>
      <description><![CDATA[嗨， 我想知道是否有人对处理分类任务的最简单方法进行过调查，其中输入标记空间是&gt;&gt; 512（或任何单个 GPU 模型限制的值）。 我在一个复杂的空间中工作。我正在研究一个排名（实际上甚至可能只是简单的二进制，具有类不平衡）类型的问题，所以不是生成性的，但是文本的内容很重要，而不仅仅是嵌入的一些汇集版本，所以我想使用类似变压器的模型。 每个文档大约有 5K 个标记，其中大约有 11 个作为输入（1 个是源，10 个是我想要的可能“匹配”） 1)，或者可以是 3 作为输入（三元组损失，1 是源，1 是更好的匹配，1 是更差的匹配）。 训练示例太多，无法实际使用 GPT3 来总结它们每个 50-100 个令牌，并尝试使用 GPT3 进行微调（有可能，但考虑到我们的用例，这并不现实）。 一些可以产生良好总结的训练机制，然后我可以feed in 会很好，但我不知道有什么现成的模型/技术可以使用。 我是一个老派的机器学习人员，可能有一些窗口技术可以使用与我不知道的变压器风格模型一起使用，因此这篇文章 提前致谢， W   由   提交 /u/wantondevious   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2gwh4/d_techniques_for_handling_input_documents_with_a/</guid>
      <pubDate>Fri, 12 Apr 2024 18:45:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找给定 RGB 图像（无深度）+ 3D cad 模型的 6D 位姿估计模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2g2l6/r_looking_for_6d_pose_estimation_model_given_rgb/</link>
      <description><![CDATA[我正在尝试估计图像中机器人末端执行器的姿态。  RGB 图像是从第三人称视图提供的，我有一个可用的 3D 模型。不幸的是，我无法为模型提供任何深度数据。关于哪种型号的任何建议都会很棒。    由   提交/u/Rough_Cranberry5560   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2g2l6/r_looking_for_6d_pose_estimation_model_given_rgb/</guid>
      <pubDate>Fri, 12 Apr 2024 18:11:24 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Burr：一个用于更快地构建和调试 GenAI 应用程序的操作系统框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2egw0/project_burr_an_os_framework_for_building_and/</link>
      <description><![CDATA[https://github.com/dagworks-inc /burr 嘿伙计们！我想分享一些我们一直在努力的东西，我认为您可能会觉得有用！我们最初构建它是为了内部使用，但想与世界分享。 我们试图解决的问题是使用 ML/AI（基础模型等...）的逻辑建模系统。做出决策（设置控制流、决定要查询的模型等），并保持某种级别的状态。这很复杂——理解系统在任何给定点做出的决策需要大量的仪器等等... 我们已经看到了很多不同的工具试图使这变得更容易，但它们&#39;所有这些都非常黑匣子，并且专注于一种特定情况（及时管理）。我们想要一种能够更快地调试、理解和构建应用程序的东西，而不会对您使用的框架施加任何类型的限制，也不需要跳过各种障碍来定制。 我们想出了 Burr——核心想法是将应用程序表示为状态机，可以实时可视化正在经历的流程，并单独开发和测试组件。它配备了用于本地调试的遥测用户界面，以及检查点、收集数据以生成测试用例/评估等的能力... 我们对最初的接收感到非常兴奋，并希望得到更多反馈/操作系统用户 - 如果您有任何问题，请随时给我发私信或在这里发表评论，祝您开发愉快！ PS - Burr 这个名字是对我们运行的项目名为 Hamilton，您可能很熟悉。他们实际上合作得很好！   由   提交 /u/benizzy1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2egw0/project_burr_an_os_framework_for_building_and/</guid>
      <pubDate>Fri, 12 Apr 2024 17:06:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您会参加 ICLR 研讨会吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2coga/r_would_you_go_to_the_iclr_workshops_day/</link>
      <description><![CDATA[我距离不远（欧洲），想去 ICLR 研讨会只是为了了解现场情况、与人见面等。您认为这样吗？可能有用，或者大多数人在最后一天都已经走了？    由   提交 /u/tuitikki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2coga/r_would_you_go_to_the_iclr_workshops_day/</guid>
      <pubDate>Fri, 12 Apr 2024 15:54:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习博士论文发表的激烈竞争</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2bvoj/d_publication_rat_race_for_phd_in_ml/</link>
      <description><![CDATA[目前，顶尖大学的机器学习博士项目要求申请者拥有多篇第一作者论文以及来自知名研究人员的强烈推荐。如果在其他领域，这种发表记录可能会让您有资格担任教职。学生们如果自己没有进入顶尖学校，怎么可能取得这些成绩呢？  编辑：我的主要观点与推荐要求有关。顶尖大学以外的学生几乎没有机会获得知名研究人员的推荐，因为他们大多在顶尖学校工作。这些顶尖大学之外也有知名的研究人员，但数量太少。如果你在一所普通大学，那么你的学校很可能没有在你的领域足够知名的研究人员。   由   提交 /u/RobbinDeBank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2bvoj/d_publication_rat_race_for_phd_in_ml/</guid>
      <pubDate>Fri, 12 Apr 2024 15:22:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检索增强语言建模（REALM）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c29r8h/d_retrievalaugmented_language_modeling_realm/</link>
      <description><![CDATA[我刚刚发现（我认为是）原始的 REALM 论文，“检索增强语言模型预训练”。非常有趣的想法，但是关于猎犬的角色，有一些关键细节我没有注意到。我希望这里有人能纠正我的观点：  首先也是最关键的是，检索增强仅与生成模型相关吗？你听说过很多关于RAG，但是就不能有像RAU这样的东西吗？就像为下游非生成任务 Y 编码某些文本 X 一样，编码器可以访问知识存储，从中识别、检索相关信息，然后将其包含在嵌入过程中以细化模型对原始文本的表示X？从概念上讲，这对我来说是有意义的，而且这似乎是 REALM 论文所做的（其中任务 Y 是 QA），但我在网上找不到此类事情的任何其他示例。检索增强似乎只适用于生成任务。那么，是的，情况总是如此，还是 RAU 也存在？ 如果语言模型是使用检索增强进行训练的，那就意味着检索器是模型架构，对吗？换句话说，在推理时间中，必须始终进行一些检索，这进一步意味着从中检索文档的知识存储也必须始终存在，对吗？或者检索部分周围的所有机制都只是训练的产物，可以在学习完成后丢弃？ REALM 的主要好处是它允许的较小的模型？ 这个问题背后的基本原理：如果没有检索步骤，模型的 100% 的潜在知识必须包含在注意力机制的权重内（我认为）。对于预计几乎了解一切的基础模型，这需要大量的权重。然而，如果模型可以通过某些其他机制（例如检索增强）将上下文注入到表示中，则检索后模型的其余部分（例如注意机制）要做的工作更少，并且可以更小/更简单。我理解这里的大思想了吗？    由   提交 /u/synthphreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c29r8h/d_retrievalaugmented_language_modeling_realm/</guid>
      <pubDate>Fri, 12 Apr 2024 13:54:29 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] NeurIPS 2024 为高中生新增论文轨道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1zesl/news_neurips_2024_adds_a_new_paper_track_for_high/</link>
      <description><![CDATA[NeurIPS 2024 为高中生添加了新的论文轨道 https://neurips.cc/Conferences/2024/CallforHighSchoolProjects  第三十八届神经信息处理系统年会 (NeurIPS 2024)一个跨学科会议，汇集了机器学习、神经科学、统计学、优化、计算机视觉、自然语言处理、生命科学、自然科学、社会科学和其他相邻领域的研究人员。  今年，我们邀请高中生提交有关机器学习社会影响主题的研究论文。将选出一部分决赛入围者以虚拟方式展示他们的项目，并将在 NeurIPS 主页上重点展示他们的作品。此外，最多五个获奖项目的主要作者将受邀参加在温哥华举行的 NeurIPS 2024 颁奖典礼。  每份提交的作品必须描述完全由高中生作者完成的独立作品。我们希望每份提交的内容都能突出显示已证明的积极社会影响或使用机器学习产生积极社会影响的潜力。    由   提交 /u/xiaohk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1zesl/news_neurips_2024_adds_a_new_paper_track_for_high/</guid>
      <pubDate>Fri, 12 Apr 2024 03:47:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>