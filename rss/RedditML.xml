<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 08 Jan 2024 12:26:01 GMT</lastBuildDate>
    <item>
      <title>[研究]WebLLM - 去中心化人工智能可能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191jwjn/research_webllm_is_decentralized_ai_possible/</link>
      <description><![CDATA[我不是 AI 或 webGPU 方面的专家，但我对它有一点了解。 我对它的理解是一些东西例如：“AI 通常在 GPU 上使用，因为它需要多个 CPU”。 我正在开发一个具有去中心化 P2P 通信的项目 (https://positive-intentions.com/）。我正在使用 webRTC 进行 P2P 连接。这使得同行之间的通信速度更快（尤其是在同一 LAN 网络上）。 有一个项目可以使 LLM 在浏览器上运行 (https://webllm.mlc.ai/）。我已经测试过它并且它可以在我的应用程序中运行。它还可以以一种方式工作，即对等点（手机）可以向对等点（支持 webGPU 的台式计算机）发出请求，并将 AI 计算外包以获得响应。 （这可以解释为手机和桌面电脑之间的自托管人工智能）。 我想知道，人工智能的核心要求是否是拥有多个 GPU 并且可以连接到多个同行。是否可以在对等点之间拆分 AI 计算？ 我的应用程序应该允许发送“任何”数据同行之间的有效负载，但我不确定如何在同行之间分配人工智能的计算。 如果有人可以分享有关此事的任何指导，那么我可能会选择“弄清楚”。    由   提交 /u/Accurate-Screen8774    reddit.com/r/MachineLearning/comments/191jwjn/research_webllm_is_decentralized_ai_possible/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191jwjn/research_webllm_is_decentralized_ai_possible/</guid>
      <pubDate>Mon, 08 Jan 2024 12:14:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 是否存在仅适用于比较结果的贝叶斯优化的等效项？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191juun/p_is_there_an_equivalent_of_bayesian_optimization/</link>
      <description><![CDATA[大家好，我正在解决一个问题，我需要找到最佳参数集（其中 10 个）来优化一个非常昂贵的目标功能。通常，我会使用贝叶斯优化，但在这种特定情况下，我无法访问实际的目标函数，我唯一可以计算的是该函数在特定参数集 A 或 B 下是否更高。我不知道函数的实际值，也不知道它的导数。我所能做的就是比较两组参数，并判断哪一组产生的函数值较低。 关于我可以使用什么来找到最佳参数来优化该函数，有什么建议吗？&lt; /p&gt;   由   提交/u/ale152  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191juun/p_is_there_an_equivalent_of_bayesian_optimization/</guid>
      <pubDate>Mon, 08 Jan 2024 12:12:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些网站举办人工智能竞赛，类似于 Topcoder 的 Intellicase Bot (GPT) 挑战赛？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191jswe/d_which_websites_host_ai_competitions_similar_to/</link>
      <description><![CDATA[我正在寻找研发竞赛。   由   提交 /u/sivav-r   /u/sivav-r  reddit.com/r/MachineLearning/comments/191jswe/d_which_websites_host_ai_competitions_similar_to/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191jswe/d_which_websites_host_ai_competitions_similar_to/</guid>
      <pubDate>Mon, 08 Jan 2024 12:08:43 GMT</pubDate>
    </item>
    <item>
      <title>[R]、[P] 聊天机器人中的重新生成功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191jlly/r_p_regenerate_feature_in_chatbot/</link>
      <description><![CDATA[[R], [P] 有没有人使用任何基于 API 的 LLM 在他们的聊天机器人上实现了重新生成响应功能？同时确保记忆完好无损。任何帮助或参考文章将不胜感激。   由   提交 /u/Euphoric-Chart1428    reddit.com/r/MachineLearning/comments/191jlly/r_p_regenerate_feature_in_chatbot/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191jlly/r_p_regenerate_feature_in_chatbot/</guid>
      <pubDate>Mon, 08 Jan 2024 11:56:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] reddit 的程序员们，预测模型的最佳方法和算法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191itad/d_coders_of_reddit_whats_the_best_approach_and/</link>
      <description><![CDATA[我想为学生的成绩数据创建一个排名预测模型，根据过去的排名分配我想预测它将是什么排名未来几年   由   提交/u/Kv-boii  /u/Kv-boii reddit.com/r/MachineLearning/comments/191itad/d_coders_of_reddit_whats_the_best_approach_and/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191itad/d_coders_of_reddit_whats_the_best_approach_and/</guid>
      <pubDate>Mon, 08 Jan 2024 11:07:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 3090 与新 40 系列同等产品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191isia/d_3090_vs_the_new_40_series_equivalent/</link>
      <description><![CDATA[我发现了一些 3090（新）的优惠：  MSI（1260 美元） PALIT（965 美元） PALIT OC（900 美元）  我想知道 40 系列的较低型号（主要是 4070 和 4070 TI，因为 4080 远远超出了我的预算（需要升级电源）对于游戏/AI 与缺乏 V-RAM 来说是值得的  请注意卡的可用性和选择就我而言有限，另外，我的电源必须更换，因为它只是650W金牌（也开放电源升级建议）。 谢谢   由   提交 /u/myselfitself   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191isia/d_3090_vs_the_new_40_series_equivalent/</guid>
      <pubDate>Mon, 08 Jan 2024 11:06:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] Infinite-LLM：使用 DistAttention 和分布式 KVCache 实现长上下文的高效 LLM 服务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191iqxj/r_infinitellm_efficient_llm_service_for_long/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.02669 摘要：  大型语言模型（LLM）的快速增长已经成为基于云的法学硕士服务的增长的驱动力，这些服务现在是推进人工智能应用程序不可或缺的一部分。然而，LLM服务的动态自回归性质，以及支持超长上下文长度的需要，要求灵活分配和释放大量资源。这给设计基于云的LLM服务系统带来了相当大的挑战，低效的管理可能导致性能下降或资源浪费。为了应对这些挑战，本文引入了一种新颖的分布式注意力算法DistAttention，它将KV Cache分割成更小的、可管理的单元，从而实现注意力模块的分布式处理和存储。基于此，我们提出了DistKV-LLM，这是一种分布式LLM服务系统，可以动态管理KV缓存并有效地编排跨数据中心的所有可访问的GPU和CPU内存。这确保了云上的高性能法学硕士服务，可适应广泛的上下文长度。在具有 32 个 NVIDIA A100 GPU（配置为 2 到 32 个实例）的云环境中进行验证，我们的系统表现出 1.03-2.4 倍的端到端吞吐量改进，并且支持的上下文长度比当前状态长 2-19 倍-art LLM 服务系统，通过对上下文长度高达 1,900K 的 18 个数据集的广泛测试证明。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191iqxj/r_infinitellm_efficient_llm_service_for_long/</guid>
      <pubDate>Mon, 08 Jan 2024 11:03:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于自然语言的心灵社会中的头脑风暴</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191i9m7/r_mindstorms_in_natural_languagebased_societies/</link>
      <description><![CDATA[OpenReview（R0-FoMo Oral）：https://openreview.net/forum?id=zd2qE6BBdU arXiv：https://arxiv.org/abs/2305.17066 代码：https://github.com/mczhuge/NLSOM 摘要：  &lt;明斯基的“心灵社会”和“心灵社会”都是明斯基的“心灵社会”。以及施米德胡贝尔的《学会思考》激励大型多模态神经网络（NN）的不同社会通过在“头脑风暴”中互相采访来解决问题。基于神经网络的心智社会的最新实现由大型语言模型 (LLM) 和其他通过自然语言界面进行通信的基于神经网络的专家组成。在此过程中，他们克服了单一法学硕士的局限性，改进了多模态零样本推理。在这些基于自然语言的心智社会（NLSOM）中，新的代理（所有代理都通过相同的通用符号语言进行通信）可以轻松地以模块化方式添加。为了展示 NLSOM 的强大功能，我们组装了其中的几个（最多 129 名成员）并进行实验，利用其中的思维风暴来解决一些实际的 AI 任务：视觉问答、图像字幕、文本到图像合成、3D 生成、以自我为中心的检索、具体人工智能和基于通用语言的任务解决。我们将此视为拥有数十亿智能体（其中一些可能是人类）的更大 NLSOM 的起点。随着异质思维伟大社会的出现，许多新的研究问题突然变得对人工智能的未来至关重要。 NLSOM 的社会结构应该是什么样的？君主制而不是民主结构的优点是什么？如何利用神经网络经济原理来最大化强化学习 NLSOM 的总奖励？在这项工作中，我们确定、讨论并尝试回答其中一些问题。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191i9m7/r_mindstorms_in_natural_languagebased_societies/</guid>
      <pubDate>Mon, 08 Jan 2024 10:32:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果您对工业生物医学人工智能感兴趣，请参加瑞士的这些活动</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191i2no/d_attend_these_events_in_switzerland_if_you_are/</link>
      <description><![CDATA[亲爱的瑞士及周边地区的兄弟姐妹们， 如果您是瑞士的博士生或 STEM 毕业生，并且有兴趣工业生物医学AI，那么您一定要参加这些活动，了解更多行业动态。 工业生物医学AI -英国智能健康AI-智能健康AI巴塞尔 - 里斯本网络峰会 - 生物制品节 巴塞尔 - 美国生物制品节 - 洛桑联邦理工学院应用机器学习日 - 瑞士医疗科技日 - SwissText - BioTechX 巴塞尔 - BioTechX USA - NLP 峰会医疗保健 - BOOM 峰会巴塞尔 如果您想了解有关这些活动的更多信息，请阅读中等帖子。如果您知道更多此类帮助毕业生进入行业的活动，让我们讨论一下这些活动。  ​ 今年让我们赋予他人权力。 :)    由   提交/u/freaky_eater  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191i2no/d_attend_these_events_in_switzerland_if_you_are/</guid>
      <pubDate>Mon, 08 Jan 2024 10:19:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于特征优先级排序的 ML 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191erp3/d_ml_models_for_feature_prioritization/</link>
      <description><![CDATA[是否有可用于功能优先级排序的 ML 模型？我们使用 ProductBoard，确定优先级或将每个反馈与影响指标联系起来是一件痛苦的事情，而且通常不准确。  想知道是否有一个模型可以类似于工厂等使用的其他工业工程模型。   由   提交/u/Ok_Law_3126   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191erp3/d_ml_models_for_feature_prioritization/</guid>
      <pubDate>Mon, 08 Jan 2024 06:38:04 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] 具有自然语言能力的个人机器人助手是谷歌能力的未来吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191ccbb/news_are_natural_language_capable_personal_robot/</link>
      <description><![CDATA[    /u/Anirban_Hazra   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191ccbb/news_are_natural_language_capable_personal_robot/</guid>
      <pubDate>Mon, 08 Jan 2024 04:21:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] V*：引导视觉搜索作为多模式法学硕士 (SEAL) 的核心机制 - 纽约大学 2023 - 在搜索视觉细节方面比 GPT-4V 好 25%！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191652a/r_v_guided_visual_search_as_a_core_mechanism_in/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2312.14135v2  Github：https： //github.com/penghao-wu/vstar  摘要：  当我们环顾四周并执行复杂任务时，我们如何看待并选择性地处理什么我们看到至关重要。然而，当前的多模态法学硕士（MLLM）缺乏这种视觉搜索机制，阻碍了他们专注于重要视觉细节的能力，特别是在处理高分辨率和视觉拥挤的图像时。为了解决这个问题，我们引入了 V*，一种 LLM 引导的视觉搜索机制，它利用 LLM 中的世界知识来进行高效的视觉查询。当与 MLLM 结合使用时，该机制可以增强协作推理、上下文理解以及特定视觉元素的精确定位。这种集成产生了一个新的 MLLM 元架构，名为 Show、sEArch 和 TelL (SEAL)。我们进一步创建了 V*Bench，这是一个专门设计用于评估 MLLM 处理高分辨率图像和关注视觉细节的能力的基准。 我们的研究强调了将视觉搜索功能纳入多模态系统的必要性。   https://preview.redd.it/0b78lih1r3bc1.jpg?width=1663&amp;format=pjpg&amp;auto=webp&amp;s=786702884305 88cfee2db280cb75e348254ec0eb https://preview。 redd.it/8kap1jh1r3bc1.jpg?width=1661&amp;format=pjpg&amp;auto=webp&amp;s=d6e8a372cd91976e6e35710d32992a443981f06e https://preview.redd.it/oakf3lh1r3bc1.jpg?width=1247&amp;format=pjpg&amp;auto=webp&amp;s=612ab61b763 254f5cabb3a93990cc5baa2a917e3&lt; /a&gt; https:// Preview.redd.it/mta8emh1r3bc1.jpg?width=653&amp;format=pjpg&amp;auto=webp&amp;s=209871901bf2ba26537b1587c4be388df055f30b   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191652a/r_v_guided_visual_search_as_a_core_mechanism_in/</guid>
      <pubDate>Sun, 07 Jan 2024 23:30:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么在机器学习中几乎所有的概率推导都如此难以遵循？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190to69/d_why_are_almost_all_probabilistic_derivations_so/</link>
      <description><![CDATA[      我认为自己非常擅长数学，甚至还教过大学生，活跃于ML 等领域。 然而，我发现大多数（如果不是全部）涉及 ML 中任何远程概率问题的论文都得到了残酷的解释。 最近我决定真的了解 OG [DDPM](https://arxiv.org/pdf/2006.11239.pdf) 论文。&lt; /p&gt; 这是推导的一部分，他们……以某种方式……插入了 KLD。我完全不清楚这个跳跃是如何进行的。是的，我看过 KLD 的定义，是的，我用谷歌搜索过，但每个人似乎都相信这一点。 ChatGPT 说“存在未显示的隐藏期望”。 https://preview.redd.it/glvvzcc351bc1.png?width=2014&amp;format=png&amp;auto=webp&amp;s=d4c95a5716c0b8113e9a3346b8f99e3c5 a3db919 有人知道吗？  ​ 更新：感谢大家的评论，我这里的结论是DDPM论文有一个错误，即上面的图像。  错误是因为它们显示外部期望没有被用完，而实际上它已经被用尽了。  我在 Calvin 的论文此处中找到了正确的推导过程。这是图像： ​ https://preview.redd.it/54o6592vj2bc1.png?width=2370&amp;format=png&amp;auto=webp&amp;s=78d089d3d5c183f286bac15d3e6 d38ed5fa4e37e 上面是正确的，而DDPM论文是错误的。  ​   由   提交 /u/Ayakalam   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190to69/d_why_are_almost_all_probabilistic_derivations_so/</guid>
      <pubDate>Sun, 07 Jan 2024 14:46:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 那么，曼巴大战变形金刚……炒作是真的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190q1vb/d_so_mamba_vs_transformers_is_the_hype_real/</link>
      <description><![CDATA[听到了有关序列建模模块新成员 Mamba 的所有讨论。据说它速度更快，可以更好地处理更长的序列，甚至在某些任务上优于 Transformer。但它真的是王位窃取者还是只是昙花一现？ 我的看法： 优点：Mamba 拥有高效的内存使用、随序列长度线性扩展以及令人印象深刻的性能语言和 DNA 建模。另外，它放弃了注意力机制，可能为更快的推理铺平道路。  弱点：仍处于早期阶段，因此 Mamba 在不同任务中的长期稳定性和表现仍有待观察。虽然它不需要关注，但它的状态空间方法对于某些人来说可能更难以掌握。  对于人工智能爱好者来说，曼巴只是下一个闪亮的玩具，还是序列建模中真正的范式转变？它会推翻强大的变形金刚，还是作为一种专门的工具并存？让我们听听您的想法！ https://arxiv.org/abs/2312.00752 &lt; /div&gt;  由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190q1vb/d_so_mamba_vs_transformers_is_the_hype_real/</guid>
      <pubDate>Sun, 07 Jan 2024 11:19:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>