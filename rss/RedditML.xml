<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 21 Sep 2024 09:15:18 GMT</lastBuildDate>
    <item>
      <title>[D] 哪里可以赶上研究的步伐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flys5b/d_where_to_catch_up_to_research/</link>
      <description><![CDATA[基本上，我每天都会花半个小时阅读 arxiv sanity 上有趣的论文，现在我必须去服兵役，一次几个月都没有互联网。我每个月有一周的休息时间，哪里可以赶上研究进度呢？    提交人    /u/AdOk6683   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flys5b/d_where_to_catch_up_to_research/</guid>
      <pubDate>Sat, 21 Sep 2024 08:59:04 GMT</pubDate>
    </item>
    <item>
      <title>纯 Torch 中的潜在扩散（无 huggingface 依赖）[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flxs7d/latent_diffusion_in_puretorch_no_huggingface/</link>
      <description><![CDATA[去年我一直在研究扩散，我决定发布一个软件包，其中包含我从头开始实现的 DDPM 潜在扩散模型。它包括用于嵌入图像的去噪 UNet 和 VAE+GAN 的实现。 这是纯粹的火炬，因为我发现 Huggingface 扩散器适合简单的任务，但如果你想了解内部工作原理或稍微破解模型，它就不够了，因为代码库非常庞大，并且不适用于组件的可重用性（但我坚持认为它是一个很好的库）。要安装它，只需运行 pip install tiny-diff 我的目标是创建一个可重复使用的实现，前向方法中没有任何 if（尽可能地压缩多态性，以使前向尽可能清晰）和模块化组件（因此，如果您不想使用整个模型，而是使用其中的一部分，您可以抓住您想要的） Repo 链接：https://github.com/AlejandroBaron/tiny-diff    提交人    /u/AIlexB   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flxs7d/latent_diffusion_in_puretorch_no_huggingface/</guid>
      <pubDate>Sat, 21 Sep 2024 07:44:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何计算 LLM 模型在微调过程中的 VRAM 使用量？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flnxtg/d_how_to_calculate_vram_usage_of_a_llm_model/</link>
      <description><![CDATA[谁能告诉我如何计算 LLM 模型的 vram 使用情况以进行微调。我找到了 VRAM 计算器 (asmirnov.xyz) 和 模型内存实用程序 - hf-accelerate 的 Hugging Face Space，但我猜它没有提到微调，而是用于训练和推理。 这是我为 llama-2-7B-hf 进行完全微调的计算方法： 模型配置 隐藏大小 = 4096 隐藏层数 = 32 注意头数量 = 32 中间大小 = 11008 词汇大小 = 32000 Seq长度 = 512 批次大小 = 1 Dtype = BF16 参数数量 嵌入层 = 词汇大小 x 隐藏大小 = 32000 x 4096 = 13,10,72,000 每个 Transformer 层：  自我注意力 = 4 x 隐藏大小 x 隐藏大小 x 3 = 4 x 4096 x 4096 x 3 = 20,13,26,592 前馈 = 2 x 隐藏大小 x 中间大小 = 2 x 4096 x 11008 = 9,01,77,536  层范数 = 2 x 隐藏大小 = 2 x 4096 = 8192 每层总数 = 自我注意 + 前馈 + 层范数 = 29,15,12,320 所有层 = 每层总数 x 隐藏层数 = 29,15,12,320 x 32 = 9,32,83,94,240 总参数 = 嵌入层 + 所有层 = 13,10,72,000 + 9,32,83,94,240 = 9,45,94,66,240 内存 用于参数 总参数 x 2 字节 = 9,45,94,66,240 x 2 = 18,91,89,32,480 字节 = 18.9189325 GiB 用于优化器状态的内存（ADAM 优化器）： bf16 动量和方差的每个参数 2 个字节 = 总参数 x 2 x 2 = 9,45,94,66,240 x 2 x 2 = 37,83,78,64,960 字节 = 37.837865 GiB 用于梯度的内存：与参数大小相同：18,91,89,32,480 字节 = 18.9189325 GiB 用于激活的内存：估计：2 * hidden_​​size * seq_length * batch_size * num_layers * 2 字节 = 2 * 4096 * 512 * 1 * 32 * 2 = 268435456 字节 = 0.26843546 GiB 用于临时变量和 CUDA 开销的额外内存： 估计：1-2 GB 总 VRAM 使用量 = 18.9189325 + 37.837865 + 18.9189325 + 0.26843546 + 2 = 77.94416546000001 GiB    提交人    /u/Himanshu40-c   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flnxtg/d_how_to_calculate_vram_usage_of_a_llm_model/</guid>
      <pubDate>Fri, 20 Sep 2024 22:07:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] GRIN：基于梯度的 MoE</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flhndi/r_grin_gradientinformed_moe/</link>
      <description><![CDATA[路由输出离散变量，如何估计其梯度进行混合专家训练？ https://arxiv.org/pdf/2409.12136 相关背景：https://arxiv.org/abs/2304.08612    提交人    /u/Lucas_LLL   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flhndi/r_grin_gradientinformed_moe/</guid>
      <pubDate>Fri, 20 Sep 2024 17:31:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 深入机器学习：免费 Python 教程和可下载的 Markdown 文件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flfn3k/p_dive_into_machine_learning_free_python/</link>
      <description><![CDATA[我一直对机器学习算法的工作原理很着迷，所以我决定深入研究并创建一系列全面的 Python 教程。这些教程涵盖了机器学习的各个方面，从数据预处理和模型训练到评估和部署。 随着我的教程收藏越来越多，我意识到与社区分享它们可以帮助其他人走上机器学习之旅。因此，我创建了一个存储库，您可以在其中以 Markdown (MD) 格式下载所有这些教程，从而可以轻松地在 Jupyter 笔记本或您喜欢的任何其他平台上使用它们。 我的项目做什么： 我的项目提供了 Python 中机器学习教程的全面集合。每个教程都设计得易于理解，并配有分步指南和实际示例。这些教程涵盖了广泛的主题，包括数据预处理、模型训练、评估和部署。所有教程均以 Markdown (MD) 格式提供，可轻松在 Jupyter 笔记本或任何其他编码环境中使用。 如何访问： https://github.com/xbeat/Machine-Learning https://xbe.at    提交人    /u/kaolay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flfn3k/p_dive_into_machine_learning_free_python/</guid>
      <pubDate>Fri, 20 Sep 2024 16:05:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过强化学习训练语言模型进行自我纠正</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flby1u/r_training_language_models_to_selfcorrect_via/</link>
      <description><![CDATA[  由    /u/RobbinDeBank  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flby1u/r_training_language_models_to_selfcorrect_via/</guid>
      <pubDate>Fri, 20 Sep 2024 13:24:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 创造力仅来自强化学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flbmde/d_creativity_only_comes_from_reinforcement/</link>
      <description><![CDATA[Ilya 发表了一次有趣的演讲，谈到了 RL 在 LLM 或任何 AI 系统（例如国际象棋的 AlphaZero）形成创造性反应方面的作用。我想知道这是真的吗？我认为简单地在 SFT 之类的数据点之间进行插值也会很有创意。 讨论链接：https://www.youtube.com/watch?v=OPZxs6IXH00&amp;list=PLpvkFqYJXcreXgK6Cg9NVGvFANmdUczWa （第 14 分钟：00）    提交人    /u/CriticalTemperature1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flbmde/d_creativity_only_comes_from_reinforcement/</guid>
      <pubDate>Fri, 20 Sep 2024 13:09:35 GMT</pubDate>
    </item>
    <item>
      <title>叠加、相图与正则化 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flazmd/superposition_phase_diagrams_and_regularization_d/</link>
      <description><![CDATA[      大家好！我正在阅读 Anthropic 的叠加玩具模型，我强烈推荐。作者展示了小型神经网络的相图，包括理论和经验版本。然而，他们在分析中没有应用任何形式的正则化，这激起了我对叠加效应的好奇心。这激发了我尝试这个概念。 我发现这些想法非常有趣，所以我写了一篇博客文章来分享我的想法。你可以在这里查看。 虽然我的结果不如 Anthropic 得到的结果那么清晰，但我相信它们仍然值得分享。我很乐意听到您的反馈！ 以下是我帖子的要点： 我们从一个非常简单的神经网络开始： https://preview.redd.it/7okwz6njlypd1.png?width=237&amp;format=png&amp;auto=webp&amp;s=e0f39f6e7e903d9573cb432d20ff0479131e05dc 我们进行训练以尽量减少以下重建损失： https://preview.redd.it/ftk5l5nklypd1.png?width=410&amp;format=png&amp;auto=webp&amp;s=960ba69bb3b1de21d2f8b73d3a6588fb5cf3ac66 这里，λ 表示正则化强度，x_i 是输入特征，r_i 表示每个特征的相关性。每个特征都是 0 到 1 之间的数字。此外，我们引入了一个稀疏项 s。给定 s，我们将每个特征设置为 0，概率为 s。 假设我们只有两个特征，用一个数字编码（因此，(W = [w_1, w_2]))。网络的选择数量有限：  设置 w_1 = 0 和 w_2 = 0，最小化 L2 正则化。 设置 w_1 = 1 和 w_2 = 0，仅对第一个特征进行编码。 设置 w_1 = 0 和 w_2 = 1，仅对第二个特征进行编码。 设置 w_1 = 1 和 w_2 = -1（或 w_2 = -1 和 w_1 = 1），叠加两个特征。  接下来，我进行了几项实验，改变了稀疏性、正则化强度和第二个特征的相关性（例如，当 r_2 = 0 时，第二个特征可能不相关，而当 r_2 = 5 时，第二个特征的相关度可能是第一个特征的五倍）。此 GIF 显示了实验结果：  https://i.redd.it/do8erlkmlypd1.gif 我还通过计算四种情景中的每种情景的预期损失创建了相图的理论版本，我还将两个 gif 并排放在一起进行比较：  https://i.redd.it/d81150snlypd1.gif 如您所见，理论版本与经验版本有些匹配。虽然它并不完美，但正则化的效果是显而易见的；它阻止了特征的叠加。当您考虑到 (W = [-1, 1]) 的范数肯定大于 (W = [0, 1]) 或 (W = [1, 0]) 时，这是有道理的。 您觉得如何？您对改进这些数字有什么建议吗？我很想听听您的想法！    提交人    /u/f14-bertolotti   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flazmd/superposition_phase_diagrams_and_regularization_d/</guid>
      <pubDate>Fri, 20 Sep 2024 12:38:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 少数民族语言TTS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl6rrs/r_tts_for_minority_languages/</link>
      <description><![CDATA[我的客户是巴布亚新几内亚少数民族语言的翻译。该语言的名称是 Narak，是一种声调语言。有哪些资源可用于为这种语言（或任何其他少数民族语言）创建文本到语音的工具？我的客户年纪很大了，如果能让软件读取字典条目，完成字典将变得容易得多。 是的，有一个专门从事文本到语音的小组。但是，这项任务可能需要某种机器学习。    提交人    /u/SnooGoats1303   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl6rrs/r_tts_for_minority_languages/</guid>
      <pubDate>Fri, 20 Sep 2024 07:57:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我觉得自从 LLM API 成为现实以来，有关 ML 和 ML 产品的讨论质量急剧下降。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl5be0/d_i_feel_like_ever_since_llm_apis_have_become_a/</link>
      <description><![CDATA[完成硕士学位后，过去几年一直担任 MLE，目前在一家拥有非常聪明的同事的公司工作。问题是，我的公司没有资源来培训我们自己的 LLM，因此不得不求助于使用各种 API 来建立模型。 关于如何改进我们产品的讨论通常感觉没有成效且毫无意义。它通常会诉诸于“我们如何通过快速工程让这个 LLM（我们甚至无法控制）做这件事？” 我个人甚至不认为“快速工程”是可靠或真实的事情，并且感觉因为大多数讨论都归结于此，感觉我们也无法真正增强我们的产品。 只是想知道是否有人有同样的感受。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl5be0/d_i_feel_like_ever_since_llm_apis_have_become_a/</guid>
      <pubDate>Fri, 20 Sep 2024 06:06:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我们读过的一些研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fl4bi0/r_some_research_papers_we_read/</link>
      <description><![CDATA[印度理工学院鲁尔基分校的视觉语言小组整理了 2016 年至 2024 年期间来自 NeurIPS、CVPR、ICCV、ICML 等顶级会议的深度学习研究论文的综合摘要库。这些摘要旨在让您简明扼要地了解计算机视觉、自然语言处理和机器学习等领域的有影响力的论文。该库不断扩充，并经常添加新的摘要。以下是一些值得注意的例子：  **DreamBooth：针对主题驱动生成的精细调整文本到图像扩散模型**，CVPR&#39;23  [DreamBooth 摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/DreamBooth.md) **Segment Anything**，ICCV&#39;23  [Segment Anything 摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Segment\_Anything.md) **一图胜千言：使用文本反转个性化文本到图像生成**，ICCV&#39;23  [文本反转摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Textual\_inversion.md) **照片级真实感具有深度语言理解的文本到图像扩散模型**，NIPS&#39;22  [照片级真实感扩散摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/imagen.md) **一张图片胜过 16x16 个单词：用于大规模图像识别的 Transformers**，ICLR&#39;21  [视觉 Transformer 摘要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Vision\_Transformer.md) **Big Bird：用于更长序列的 Transformers**，NIPS&#39;20  [Big Bird Transformers 概要](https://github.com/vlgiitr/papers\_we\_read/blob/master/summaries/Big\_Bird\_Transformers.md)  存储库邀请社区做出贡献。如果您发现这些摘要有用，我们鼓励您提交自己的研究论文摘要。该团队旨在定期更新该集合，其中包含即将召开的会议的论文摘要以及深度学习和人工智能的关键主题。 您可以在此处访问完整的存储库并做出贡献： [Vision Language Group 论文摘要](https://github.com/vlgiitr/papers\_we\_read) 通过贡献，您将帮助使该领域的初学者和专家更容易获得高级研究。    提交人    /u/vlg_iitr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fl4bi0/r_some_research_papers_we_read/</guid>
      <pubDate>Fri, 20 Sep 2024 04:59:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] EMNLP 2024 成绩/通知</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkqxhh/d_emnlp_2024_results_notifications/</link>
      <description><![CDATA[一些曲目的结果似乎已经出来了，可以在 Openreview 上查看。电子邮件可能会在明天发送。  提前祝贺大家，迈阿密见！    提交人    /u/EDEN1998   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkqxhh/d_emnlp_2024_results_notifications/</guid>
      <pubDate>Thu, 19 Sep 2024 17:45:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] Comgra：用于分析和调试神经网络的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</link>
      <description><![CDATA[我是一名机器学习工程师和研究员。我厌倦了理解神经网络行为方式的难度，因此我编写了一个库来帮助我。 Comgra（计算图分析） 是一个可以与 pytorch 一起使用的库，用于提取您关心的所有张量数据并在浏览器中以图形方式对其进行可视化。有关它的论文已被接受为 ICML 2024 机械可解释性研讨会的焦点论文。 与通常使用 tensorboard 的方法相比，Comgra 可以对正在发生的事情进行更详细的分析。您可以在训练过程中研究张量，深入研究单个神经元，检查您特别感兴趣的单个数据集，跟踪梯度，比较不同训练运行之间的统计数据等等。 这个工具让我比平时更快地检查我的假设，并帮助我了解网络的不同部分是如何真正相互作用的，从而为我节省了大量的研究时间。    提交人    /u/Smart-Emu5581   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</guid>
      <pubDate>Thu, 19 Sep 2024 14:07:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>