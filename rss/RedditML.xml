<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 23 Feb 2024 15:15:14 GMT</lastBuildDate>
    <item>
      <title>[R] 法学硕士似乎默认是价值最大化者，并且他们的回答存在价值偏差</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ay2rny/r_llms_seem_to_be_by_default_value_maximizers_and/</link>
      <description><![CDATA[标题：探索价值偏差：法学硕士如何偏离理想 摘要： 大语言模型 (法学硕士）被部署在广泛的应用中，他们的反应具有越来越大的社会影响。了解法学硕士在给出答复时的非故意机制对于解释他们的表现和辨别他们在现实世界应用中的偏见至关重要。这类似于人类研究，这种无意的反应被称为采样。我们根据价值偏差对法学硕士的抽样进行了研究，结果表明，法学硕士的抽样往往倾向于高价值的选择。价值偏差对应于这种从最有可能的响应转向法学硕士所代表的理想值的转变。事实上，即使通过上下文提示学习新实体，这种效果也可以重现。我们表明，这种偏差会出现在意想不到的地方，并对相关应用场景产生影响，例如选择样本。结果表明，不同类别的法学硕士存在很强的价值偏差，与人类研究中发现的结果类似。  https://arxiv.org/abs/2402.11005   由   提交/u/Cool_Abbreviations_9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ay2rny/r_llms_seem_to_be_by_default_value_maximizers_and/</guid>
      <pubDate>Fri, 23 Feb 2024 15:09:31 GMT</pubDate>
    </item>
    <item>
      <title>[R]“生成模型：他们知道什么？他们知道事情吗？让我们找出答案！”。论文引用：“我们的研究结果表明，我们研究的所有类型的生成模型都包含有关场景内在因素（法线、深度、反照率和阴影）的丰富信息，这些信息可以使用 LoRA 轻松提取。”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ay2b7u/r_generative_models_what_do_they_know_do_they/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ay2b7u/r_generative_models_what_do_they_know_do_they/</guid>
      <pubDate>Fri, 23 Feb 2024 14:51:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何为去噪纸制作点云图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ay26fg/d_how_to_make_pointcloud_plots_for_denoising_paper/</link>
      <description><![CDATA[      我想创建如下图 你们中有人熟悉这样做吗？手动执行此操作似乎非常耗时。   由   提交/u/mr_birrd  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ay26fg/d_how_to_make_pointcloud_plots_for_denoising_paper/</guid>
      <pubDate>Fri, 23 Feb 2024 14:45:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 拥有计算机科学学士学位的国际学生在德国获得机器学习硕士学位。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ay01au/d_machine_learning_masters_degree_in_germany_for/</link>
      <description><![CDATA[如果我想在毕业后在 ML 领域找到一份好的职业，我希望能得到关于该选择哪所大学的建议。我的德语不是最好的，但我正在努力（目前是 A2/B1），所以我更喜欢英语硕士课程。我的学士学位不是来自德国。   由   提交 /u/RemonIsaac   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ay01au/d_machine_learning_masters_degree_in_germany_for/</guid>
      <pubDate>Fri, 23 Feb 2024 13:07:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 液体神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axz2ei/d_liquid_neural_network/</link>
      <description><![CDATA[大家好，我有一个项目要做，可以给我提供学习 LNN（液体神经网络）的资源或工具或路线图吗关于它们在某个现实生活中的应用程序。我已经对 ML、神经网络、CNN、RNN、LSTM、迁移学习有很强的背景。非常感谢您的帮助！   由   提交/u/Hussein_Jammal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axz2ei/d_liquid_neural_network/</guid>
      <pubDate>Fri, 23 Feb 2024 12:16:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于 DL 工作站的 AMD Ryzen Threadripper PRO 5955WX 与 AMD Ryzen Threadripper 7960X</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axytxf/d_amd_ryzen_threadripper_pro_5955wx_vs_amd_ryzen/</link>
      <description><![CDATA[我想构建一个具有 2x rtx4090 和 128GB RAM 的机器学习工作站。我正在努力决定合适的 CPU。您对 AMD Ryzen Threadripper PRO 5955WX 与 AMD Ryzen Threadripper 7960X 有何看法？我觉得 7960x 在各个方面都更胜一筹，除非我想在未来将我的设置扩展到四核 GPU 或更多 RAM。你觉得怎么样，我是不是错过了什么？您对这些选项的总体看法如何？   由   提交/u/Striking_Way_3205   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axytxf/d_amd_ryzen_threadripper_pro_5955wx_vs_amd_ryzen/</guid>
      <pubDate>Fri, 23 Feb 2024 12:03:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 撰写引人注目的会议论文的经验教训（技巧）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axxyh1/d_lessons_tips_for_writing_a_compelling/</link>
      <description><![CDATA[嗨， 随着 ECCV 截止日期的临近，我想从这里更有经验的成员那里获得一些关于课程的见解，他们在职业生涯中撰写会议论文时遵循/学到的提示和技巧。  这些可以是任何类型的东西，比如“漂亮的图片”、文本的语气、目标的措辞、他们在撰写文章时遵循的某些规则，或者他们认为审稿人在阅读时提出的高级问题他们的工作等。 希望这次交流也能让其他人受益。   由   提交/u/PaganPasta  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axxyh1/d_lessons_tips_for_writing_a_compelling/</guid>
      <pubDate>Fri, 23 Feb 2024 11:10:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型语言模型中幻觉缓解技术的综合调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axxdb5/r_a_comprehensive_survey_of_hallucination/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.01313 摘要：  随着大型语言模型（LLM）的能力不断进步要编写类似人类的文本，一个关键的挑战仍然是他们倾向于产生幻觉，生成看似事实但毫无根据的内容。这种幻觉问题可以说是将这些强大的法学硕士安全部署到影响人们生活的现实生产系统中的最大障碍。在实际环境中广泛采用法学硕士的旅程在很大程度上依赖于解决和减轻幻觉。与专注于有限任务的传统人工智能系统不同，法学硕士在训练期间接触了大量在线文本数据。虽然这使他们能够表现出令人印象深刻的语言流畅性，但这也意味着他们能够从训练数据的偏差中推断出信息，误解不明确的提示，或者修改信息以表面上与输入保持一致。当我们依赖语言生成功能来实现敏感应用程序（例如总结医疗记录、财务分析报告等）时，这就变得非常令人担忧。本文对超过 32 种为减轻法学硕士的幻觉而开发的技术进行了全面调查。 其中值得注意的是检索增强生成（Lewis 等人，2021）、知识检索（Varshney 等人，2023）、CoNLI（Lei 等人，2023）和 CoVe（Dhuliawala 等人，2023）。此外，我们引入了一个详细的分类法，根据各种参数对这些方法进行分类，例如数据集利用率、常见任务、反馈机制和检索器类型。这种分类有助于区分专门为解决法学硕士的幻觉问题而设计的不同方法。此外，我们分析了这些技术固有的挑战和局限性，为未来解决法学硕士领域内的幻觉和相关现象的研究奠定了坚实的基础。  &lt;!-- SC_ON - -&gt;  由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axxdb5/r_a_comprehensive_survey_of_hallucination/</guid>
      <pubDate>Fri, 23 Feb 2024 10:32:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] IPU 仍然存在吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axwij2/d_are_ipus_still_a_thing/</link>
      <description><![CDATA[我最初对 IPU 感到非常兴奋，因为它们似乎是 GPU（和 TPU）的重要替代品。 但是 Graphcore，生产IPU的公司现在的处境似乎很糟糕。而且我没有看到 IPU 在软件兼容性方面有太多改进。例如，HF Optimum Graphcore 库已经 3 个月没有更新了：https://github.com/huggingface/optimum-graphcore&lt; /a&gt; ...   由   提交/u/handwerner142  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axwij2/d_are_ipus_still_a_thing/</guid>
      <pubDate>Fri, 23 Feb 2024 09:33:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] LREC-COLING 2024 的边界线比之前高了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axvp52/d_was_the_borderline_of_lreccoling_2024_higher/</link>
      <description><![CDATA[我收到了来自 LREC-COLING 2024 的拒绝邮件，其中包括以下解释： “鉴于前所未有的大量 3302 提交，选拔过程竞争非常激烈。” 我认为提交的数量是可以预测的。 COLING 2022共收到包括短论文在内的2000份投稿，录用率约为33%。 LREC 2018共收到约1000份投稿，录用率为65%。因此，粗略收集这些内容后，3000 份提交和 40% 的接受率是可以预测的。这意味着，在没有上下文的情况下被其他人看到，边界相当低，对吗？我只是想问问你们感觉如何。   由   提交/u/Capital_Reply_7838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axvp52/d_was_the_borderline_of_lreccoling_2024_higher/</guid>
      <pubDate>Fri, 23 Feb 2024 08:36:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大家对 Mamba 被 ICLR 拒绝感到惊讶？我错过了什么吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axsxeo/d_why_is_everybody_surprised_that_mamba_got/</link>
      <description><![CDATA[我也不只是想逆势而行。我不断在 Reddit、工作中、不同的在线论坛等上听到这个消息。当我第一次听到这个消息时我也很惊讶，但读完这篇论文后我并不特别惊讶。他们的硬件调整很有趣，但除此之外，这似乎是对之前论文的简单改编。基准实验并不像我最初认为的那么广泛，因为每个人都在谈论它有多么革命性。阅读这篇论文给我留下了很多问题，比如“X 任务或 Y 基准测试的性能怎么样？”我并不是想羞辱作者，但它并不真的感觉像一个“传统”的。机器学习领域的论文也有。 已经发布了很多并不完全适合会议出版物的优秀论文，我认为这不仅仅是因为某件事被讨论得很多在 Twitter 或 LinkedIn 上，这意味着它值得在某个场所发布。我真的想知道我是否低估了它，因为我没有正确理解它并且愿意接受任何意见。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axsxeo/d_why_is_everybody_surprised_that_mamba_got/</guid>
      <pubDate>Fri, 23 Feb 2024 05:40:38 GMT</pubDate>
    </item>
    <item>
      <title>硕士论文错误[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axebkf/master_thesis_mistake_d/</link>
      <description><![CDATA[大家好，我正在写计算机科学硕士学位论文，我的核心主题是特别使用遗传算法的自动特征工程。我刚刚意识到我发生了数据泄漏，一旦解决，结果明显低于以前。我的论文即将结束，下周将与我的教授进行最后一次会面。我的数据来自与我合作的公司，无法公开，因此我的工作无法真正复制，但我真的很强调是否应该告诉教授这个问题还是继续解决这个问题..我起来，我不想不诚实，但我不知道如何处理它，任何人都可以提供一些想法帮助吗？    由   提交/u/Adventurous_Car_1809   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axebkf/master_thesis_mistake_d/</guid>
      <pubDate>Thu, 22 Feb 2024 18:52:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] MetaGPT 严重错误报告了基线数字并获得了 ICLR 口头报告！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axbm0f/d_metagpt_grossly_misreported_baseline_numbers/</link>
      <description><![CDATA[OpenReview：https://openreview.net/forum ?id=VtmBAGCN7o 我正在查看 ICLR 评论，很惊讶地看到 MetaGPT 被提交给 ICLR。录取决定表明他们被授予口头（ICLR 的最高级别）。  查看论文，他们报告了与 HumanEval 的比较： ​   方法 Pass@1    MetaGPT 85.9   GPT-4 67.0   GPT-3.5-Turbo（在响应中） 48.1   然而，该基准测试中的真实 GPT-4 和 GPT-3.5-Turbo 数字要高得多（请参阅 EvalPlus 排行榜：https: //evalplus.github.io/leaderboard.html）。 EvalPlus 排行榜的结果已被重复多次，因此毫无疑问。 MetaGPT 作者使用的数字取自旧的技术报告，不再准确。他们必须知道这一点，每个人都知道，这是毫无疑问的。 以下是使用 EvalPlus 中的数字进行的真实比较：   方法 Pass@1    MetaGPT 85.9   GPT-4 88.4 &lt; /tr&gt;  GPT-3.5-Turbo 76.8   GPT-3.5-Turbo 性能被严重误报。以前从未见过这样的事情。他们不可能通过 GPT-3.5-Turbo 合法地获得该数字。 所以，基本上，他们的整个“代理公司模拟”是让你花 10 美元购买 OpenAI 学分的交易比只问一次 LLM 更糟糕...他们得到了口头...我们完蛋了。  &amp;# 32；由   提交 /u/Signal-Aardvark-4179   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axbm0f/d_metagpt_grossly_misreported_baseline_numbers/</guid>
      <pubDate>Thu, 22 Feb 2024 17:06:50 GMT</pubDate>
    </item>
    <item>
      <title>RAG 与长上下文模型 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ax6j73/rag_vs_long_context_models_discussion/</link>
      <description><![CDATA[大家好，我知道我们都见过具有 100 万上下文的 Gemini v1.5 模型，而且来自 groq 公司的硬件表明，如果硬件是专门为语言模型设计的，因为它们可以变得更好。您现在对 RAG 架构有何看法，因为我们已经看到了很长的上下文模型。如果我们有更长的上下文模型和更好的量化技术和硬件怎么办？您认为像 RAG 这样的架构以及使用向量数据库来存储知识库和动态检索仍然相关吗？ 请纠正我并相应地添加更多相关信息。如果相关的研究和观察被发布，我们将不胜感激！！   由   提交/u/WritingBeginning3403  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ax6j73/rag_vs_long_context_models_discussion/</guid>
      <pubDate>Thu, 22 Feb 2024 13:35:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>