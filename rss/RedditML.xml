<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 28 Apr 2024 18:16:05 GMT</lastBuildDate>
    <item>
      <title>[R] VMRNN：集成 Vision Mamba 和 LSTM 以实现高效准确的时空预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfcxfp/r_vmrnn_integrating_vision_mamba_and_lstm_for/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.16536 代码：https:/ /github.com/yyyujintang/VMRNN-PyTorch 摘要：  将 CNN 或 ViT 与 RNN 结合起来进行时空预测，在预测时间和空间动态方面取得了无与伦比的成果。然而，对广泛的全球信息进行建模仍然是一项艰巨的挑战。 CNN 因其狭窄的接受域而受到限制，而 ViT 则难以满足其注意力机制的密集计算需求。最近基于 Mamba 的架构的出现因其卓越的长序列建模能力而受到热烈欢迎，其在效率和准确性方面超越了现有的视觉模型，这激励我们开发适合时空预测的创新架构。在本文中，我们提出了VMRNN 单元，这是一种新的循环单元，它集成了 Vision Mamba 模块与 LSTM 的优点。我们构建了一个以VMRNN单元为中心的网络来有效地处理时空预测任务。我们的广泛评估表明，我们提出的方法可以确保在各种任务上获得有竞争力的结果，同时保持较小的模型大小。我们的代码可在 此 https URL 获取。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfcxfp/r_vmrnn_integrating_vision_mamba_and_lstm_for/</guid>
      <pubDate>Sun, 28 Apr 2024 18:14:14 GMT</pubDate>
    </item>
    <item>
      <title>用于从 Web 内容中提取实体的小型高性能 LM？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfcwjc/small_and_performant_lms_for_entity_extraction/</link>
      <description><![CDATA[我有一个用例，需要从 LinkedIn 帖子和工作申请网页中提取位置、技能、薪资范围等信息。我需要根据我定义并传递给 LLM 的模式将输出采用 JSON 格式。 我目前没有任何用于微调的数据，因此我希望使用预训练模型，我可以用它生成一些数据来微调专门的模型。 到目前为止，我已经尝试过 Gemma 2b、Phi-3 Mini 和 Llama 3 7B。在这三个中，Phi-3 和 Llama 工作得很好，但在具有 6GB VRAM 的 Windows 机器上，如果没有 flash-attention，我的推理速度非常慢。 请建议小型（&lt; 3B 参数）LLM。我可以将其用于此用例，无需任何微调。如果实际模型的大小约为 1-3GB，那就太好了，这样我就可以便宜地将其托管在云上。   由   提交 /u/Infinitrix02   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfcwjc/small_and_performant_lms_for_entity_extraction/</guid>
      <pubDate>Sun, 28 Apr 2024 18:13:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 分类深度学习：架构的代数理论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfck8b/r_categorical_deep_learning_an_algebraic_theory/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.15332 项目页面：https://categoricaldeeplearning.com / 摘要：  我们提出了我们的立场，即寻找一个难以捉摸的通用框架来指定和研究深度学习学习架构。我们的观点是，迄今为止所做的关键尝试在指定模型必须满足的约束和指定其实现之间缺乏连贯的桥梁。着眼于建立这样一座桥梁，我们建议应用范畴论——准确地说，是在参数映射的 2 类别中评估的通用单子代数——作为单一理论优雅地包含了神经网络设计的这两种风格。为了捍卫我们的立场，我们展示了该理论如何恢复几何深度学习引起的约束，以及从不同的神经网络（例如 RNN）中提取的许多架构的实现。我们还说明了该理论如何自然地编码计算机科学和自动机理论中的许多标准结构。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfck8b/r_categorical_deep_learning_an_algebraic_theory/</guid>
      <pubDate>Sun, 28 Apr 2024 17:59:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 另一篇关于 MLE 角色博士学位必要性的文章</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfcdfj/d_yet_another_post_about_the_necessity_of_phd_for/</link>
      <description><![CDATA[我是 ML 专业的三年级学生（一种 CS 课程，但有更多 AI 理论、ML、DL、CV 和 NLP 内容）。在学校和自学学习 ML 3 年之后，我想制作利用 ML 解决现实世界问题（MLE 角色）而不是研究的产品。起初，我不想毕业后就读硕士和博士。我的论点是这些项目给了我什么： 知识：据我所知，硕士和博士通常专注于一个特定问题。是的，执行这些程序肯定会让我对这个问题有非常深入的了解，但仅此而已。仍然不知道任何其他问题。另一方面，MLE 需要从事各种项目，这使得有关单个任务的知识变得微不足道。此外，公司在开始项目之前没有足够的时间花数年时间进行文献综述。 研究技能：我非常有信心，尽管我不能完全了解理解数学重的论文，我可以快速了解他们的想法，粗略地了解当前的解决方案，并选择最佳模型或混合搭配方法。我承认有时更深入的理解会更好，但是要利用 ML 解决方案，这种程度的理解是否是必要的？  因为热爱学习而攻读博士学位：我确实喜欢更多地了解任务、挑战、人们解决这些任务的方法以及这些方法背后的动机，但我也更喜欢热衷于看到 ML 应用于现实世界的问题。当然，我可以为了学习更多而接受高等教育，但完成这些课程所需的时间绝非微不足道。我可以花那么多时间来做我生活中的许多其他事情，或者只是赚更多的钱并拥有更多年的经验。另外，如果我对学习如此热衷，我总是可以自学，尽管这肯定比有人监督和指导我更困难。 职业道路：目前我我的目标是获得 MLE 职位，但我认为其中没有多少人需要硕士或博士学位。然而事情可能会改变。另外，如果将来我仅仅因为缺乏学位而没有晋升，那可能是我唯一会认真考虑接受高等教育的时刻。  但是我不明白为什么这么多同龄人想读博士，我想知道我的论点是否错误或者我遗漏了什么。有经验的人可以帮我解决这个问题吗？    由   提交/u/mtmttuan  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfcdfj/d_yet_another_post_about_the_necessity_of_phd_for/</guid>
      <pubDate>Sun, 28 Apr 2024 17:51:08 GMT</pubDate>
    </item>
    <item>
      <title>[R][P] 使用 Transformer 模型预测随机流</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfbbk0/rp_predicting_stochastic_flows_using_transformer/</link>
      <description><![CDATA[我有一个流体流动问题，其中温度、速度和流动方向将根据我们过去收集的许多实验实例进行建模30年的研究。尽管流动遵循流体力学方程，但现实生活场景本质上是相当随机的。我想知道我们是否可以构建一个速度嵌入（比如给定当前和过去的速度下一个可能的速度是什么），然后训练一个变压器来解决这个问题？可能类似于 GPT，但它会预测下一个物理状态（T、vx、vy、vz）等，而不是下一个单词？有人尝试过做这样的事情吗？作为一名仅对深度学习和 NLP 有基本了解的科学家，我可以从哪里开始尝试现成的模型？ 编辑：我知道有几个预那里有经过训练的模型，但我们的问题与常规流体力学有很大不同（具有纳米效应的 QM）。所以我必须从头开始。    由   提交/u/bahauddin_onar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfbbk0/rp_predicting_stochastic_flows_using_transformer/</guid>
      <pubDate>Sun, 28 Apr 2024 17:06:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] Self-Refine vs Reflexion - 哪种方法更能提高法学硕士的输出质量？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cfb2l5/d_selfrefine_vs_reflexion_which_method_is_better/</link>
      <description><![CDATA[嗨，我正在尝试这两种方法，到目前为止，自我优化似乎在我的情况下效果更好。我的应用程序获取一些数字数据并尝试理解它。 我有两个问题：  其他人是否也有类似的感觉，Self-Refine 是更好的？  在反射论文中https://arxiv.org/pdf/2303.11366 ，有一句话Self-Refine is effective but is limited to single- Generation Reasoning Task.这里的单代推理任务是什么意思？我认为当你迭代反馈优化循环时，这不是单代推理，但也许我错了。  此外，我很想听听你的实现两篇论文的   由   提交/u/Educational-String94  /u/Educational-String94 reddit.com/r/MachineLearning/comments/1cfb2l5/d_selfrefine_vs_reflexion_which_method_is_better/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cfb2l5/d_selfrefine_vs_reflexion_which_method_is_better/</guid>
      <pubDate>Sun, 28 Apr 2024 16:55:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 MLops/ML 基础设施的 ML 白皮书</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf9d3s/d_ml_white_papers_on_mlopsml_infra/</link>
      <description><![CDATA[我正在寻找来自顶级科技公司的有关机器学习基础设施/mlops/机器学习工程的白皮书 您知道吗或者可以给我指出一些吗？ 我指的不是像注意力就是你所需要的那样的东西。寻找更多面向工程的论文   由   提交/u/choose_cake  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf9d3s/d_ml_white_papers_on_mlopsml_infra/</guid>
      <pubDate>Sun, 28 Apr 2024 15:43:18 GMT</pubDate>
    </item>
    <item>
      <title>多模态机械臂策略还是LLM基础模型训练？[D][R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf8gmp/multimodal_robotic_arm_strategy_or_llm_base_model/</link>
      <description><![CDATA[我目前有2个研究机会，关于多模态机械臂策略和LLM基础模型训练，我不知道选择哪一个？有什么建议吗欢迎或分析！   由   提交 /u/CrisYou   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf8gmp/multimodal_robotic_arm_strategy_or_llm_base_model/</guid>
      <pubDate>Sun, 28 Apr 2024 15:03:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态补丁嵌入 - 一种新的 ViT 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf8d26/r_multimodal_patch_embeddings_a_new_vit_model/</link>
      <description><![CDATA[这个研究项目是对这个想法的探索 - 如果您可以将文本嵌入与 ViT 的每个补丁嵌入进行比较会怎样？.我尝试了一些事情并得到了一些有希望的结果。  这里有两个关键思想： 1. 将图像嵌入作为超球面上点的凸和，其中每个点都是一个补丁嵌入。这需要对 ViT 架构进行更改，此处对此进行了解释。 2. 限制每个补丁仅关注其邻居。 通过这种架构，我使用蒸馏来学习一个小型（约 21M 参数）模型，使其具有与预训练的 Vit-B/32 相同的图像嵌入在大约 310 万张图像上建立模型（约 8700 万参数）。这导致补丁嵌入是局部感知的，但必须学会以某种方式组合，以便提供全局图像嵌入。 代码和检查点是可用的，并且包含用于复制的训练、推理和笔记本。结果：https://github.com/TinyVolt/multimodal-patch-embeddings   由   提交/u/nivter  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf8d26/r_multimodal_patch_embeddings_a_new_vit_model/</guid>
      <pubDate>Sun, 28 Apr 2024 14:59:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何诊断训练损失中的这些峰值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf4gw9/d_how_would_you_diagnose_these_spikes_in_the/</link>
      <description><![CDATA[   /u/NumberGenerator  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf4gw9/d_how_would_you_diagnose_these_spikes_in_the/</guid>
      <pubDate>Sun, 28 Apr 2024 11:44:29 GMT</pubDate>
    </item>
    <item>
      <title>“变形金刚可以使用无意义的填充标记（例如，‘......’）来代替一连串的思想” - Let's Think Dot by Dot [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf2u0d/transformers_can_use_meaningless_filler_tokens_eg/</link>
      <description><![CDATA[https://arxiv.org/abs/2404.15758 摘自 我们表明，Transformer 可以使用无意义的填充标记（例如“......”）代替思路链来解决两个难以解决的算法任务，而如果没有中间标记，它们将无法解决这两个任务。然而，我们通过经验发现，学习使用填充标记很困难，需要特定的、密集的监督才能收敛    提交人    /u/Agitated_Space_672   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf2u0d/transformers_can_use_meaningless_filler_tokens_eg/</guid>
      <pubDate>Sun, 28 Apr 2024 09:59:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将您的 LLM（应用程序/系统）转移到生产环境中最常见和最重大的挑战是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf178i/d_what_are_the_most_common_and_significant/</link>
      <description><![CDATA[目前有很多人使用法学硕士进行构建，但没有那么多人从原型和 POC 过渡到生产。尤其是在企业环境中，但我相信这对于产品公司甚至一些专注于基于 LLM 的应用程序的初创公司来说也是类似的。事实上，一些调查和研究认为这一比例低至5%。  从事这一领域工作的人们，在尝试将产品投入生产时遇到的最常见和最困难的挑战是什么？目前您是如何解决这些挑战的？    由   提交/u/gamerx88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf178i/d_what_are_the_most_common_and_significant/</guid>
      <pubDate>Sun, 28 Apr 2024 08:07:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] NLLB-200 蒸馏器 350M 一台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ceuj4t/p_nllb200_distill_350m_for_enko/</link>
      <description><![CDATA[您好r/MachineLearning， 我很高兴分享一个最初打算在我的毕业产品（Capstone）中使用的项目 我制作了 NLLB-200 Distill 350M 模型来将英语翻译成韩语 很好用。小而快。所以它可以用 CPU 运行！ GPU 服务器相当昂贵，所以我为那些买不起服务器的大学生（比如我）制作了它。 更多细节是在我的页面 如果你懂韩语，请给我很多反馈 谢谢！！ https://github.com/newfull5/NLLB-200-Distilled-350M-en-ko   由   提交/u/SaeChan5  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ceuj4t/p_nllb200_distill_350m_for_enko/</guid>
      <pubDate>Sun, 28 Apr 2024 01:26:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 RAG 的真实讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cekoc7/d_real_talk_about_rag/</link>
      <description><![CDATA[说实话。我知道我们都必须与这些经理/董事/CXO 打交道，他们提出了与公司数据和文档交谈的惊人想法。 但是……有人真正做了一些真正有用的事情吗？如果是这样，它的有用性是如何衡量的？ 我有一种感觉，我们被一些非常复杂的废话所愚弄，因为法学硕士总是可以产生在某种程度上听起来合理的东西。但它有用吗？   由   提交/u/fusetron  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cekoc7/d_real_talk_about_rag/</guid>
      <pubDate>Sat, 27 Apr 2024 18:00:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>