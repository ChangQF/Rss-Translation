<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 27 Feb 2024 09:12:47 GMT</lastBuildDate>
    <item>
      <title>[N] 在 MWC 的技嘉展位上看到了这些……想象一下你可以用这些做什么！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b17igl/n_saw_these_at_the_gigabyte_booth_at_mwcimagine/</link>
      <description><![CDATA[       由   提交 /u/BubblyMcnutty   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b17igl/n_saw_these_at_the_gigabyte_booth_at_mwcimagine/</guid>
      <pubDate>Tue, 27 Feb 2024 09:05:38 GMT</pubDate>
    </item>
    <item>
      <title>[D]AMD GPU 与 ZLUDA 一起用于 AI 模型训练？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b1746f/damd_gpus_with_zluda_for_ai_model_training/</link>
      <description><![CDATA[大家好， 最近发布了 ZLUDA 的开源版本，我想知道是否有人可以使用 CUDA 来使用它-具体的AI模型训练？就我而言，我对使用 MangioRVC 训练配音模型感兴趣，该模型受 CUDA 限制，但不确定是否可以以某种方式使其与 ZLUDA 一起使用，或者这是否浪费时间。 &lt; !-- SC_ON --&gt;  由   提交/u/X2ytUniverse  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b1746f/damd_gpus_with_zluda_for_ai_model_training/</guid>
      <pubDate>Tue, 27 Feb 2024 08:38:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有关于 MoE 深度轴的论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b16qbm/d_any_papers_on_moe_in_the_depth_axis/</link>
      <description><![CDATA[您好，我正在尝试查找讨论在模型的宽度轴和深度轴上使用专家的论文（类似于 8x8x7B 模型）但暂时没有找到。 据传 GPT4 是 8x2x110B，所以看起来它已经在生产中完成并且运行良好，但我有兴趣看看使用更多“层”的效果专家”。 “缩放法则”纸质测试专家的宽度和深度将是最好的，但我认为我们还没有。   由   提交 /u/hapliniste   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b16qbm/d_any_papers_on_moe_in_the_depth_axis/</guid>
      <pubDate>Tue, 27 Feb 2024 08:11:15 GMT</pubDate>
    </item>
    <item>
      <title>需要构建帮助 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b16nlp/need_help_for_a_build_p/</link>
      <description><![CDATA[所以我正在认真研究机器学习，并且想要构建一台面向未来的机器。 并且需要一些建议我的构建。所以目前我有 rtx 3060 12gb，但将转向 rtx 3090，最终两个 rtx 3090 1 已经有一个 1 tb m-2 ssd，我将选择 AMD 对于我选择的主板华硕 rog Crosshair x670e Hero，我可以相对便宜地买到。我想要 96GB 内存，最终转向 192GB 2 年的 Silverstone DA1650 psu。 一个电脑机箱 到目前为止您有何想法？ 但我唯一有点怀疑的是要么买 ryzen 9 7950x 还是买 ryzen 9 7950x3d 我读到 x3d 主要用于游戏，我想要需要它，因为我不再玩游戏了。如果我买了 7950x，我就会剩下钱买水冷却器，否则就必须是空气... PS：内存速度是一个需要考虑的因素吗？”&lt; /p&gt;   由   提交/u/amxhd1  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b16nlp/need_help_for_a_build_p/</guid>
      <pubDate>Tue, 27 Feb 2024 08:06:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找一个比较和优化 A/B 提示的网站：它存在吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b167wg/d_seeking_a_site_for_comparing_and_optimizing_ab/</link>
      <description><![CDATA[提示战斗。我一直在寻找一个网站，您可以在其中并排看到两个不同的写作提示，对其进行测试，甚至让它们自己变得更好。我今天花了一个小时试图找到这样的东西。然而，我只发现了一些复杂的选项，似乎是为特殊团队使用的，而不是为所有人使用的。 这让我思考 – 为什么没有一种简单的方法来查看哪些写作提示是更好的？就像 ELO A/B 测试竞技场排行榜一样，提示相互竞争，我们可以看到哪一个最适合修复代码或撰写文章或评论等事情。如果能有一个最佳提示列表可供选择那就太好了。有谁知道是否有这样的网站或服务？   由   提交/u/Radek87  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b167wg/d_seeking_a_site_for_comparing_and_optimizing_ab/</guid>
      <pubDate>Tue, 27 Feb 2024 07:38:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对 CVPR 结果和审稿动态影响的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b15i08/d_reflections_on_cvpr_results_and_the_impact_of/</link>
      <description><![CDATA[最近的 CVPR 结果已经发布，虽然这是该过程的一部分，但我们的一篇论文不幸遭到拒绝。结果本身并不像过程那样困扰我。 我想分享对特定论文的观察。尽管同时获得了弱接受（2）和弱拒绝评级，但有趣的是，在反驳阶段（审阅者可以访问第三次审阅）之后，评级发生了显着变化。许多审稿人根据第三位审稿人的反馈调整了他们的分数（没什么大不了的）。 这提出了一个有效的问题：如果每个人最终都修改了他们的决定，那么拥有三名审稿人和一名额外的区域主席的目的是什么？基于一个人的观点？这似乎与审稿过程的协作性质违反直觉。 如果审稿人感觉不熟悉该主题，也许他们应该考虑要求重新分配论文，而不是影响整个决策过程。考虑到作者投入的时间和精力至关重要。毕竟，如果没有经过彻底审查，反驳有何意义？ 让我们努力在未来建立一个更加透明和建设性的审查过程。 让我们就这个问题进行一次健康的讨论。  您对审稿人满意吗？ 查看民意调查&lt; /p&gt;   由   提交/u/darkknight-6  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b15i08/d_reflections_on_cvpr_results_and_the_impact_of/</guid>
      <pubDate>Tue, 27 Feb 2024 06:52:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] CVPR 2024 最终决定已出炉。你的经历怎么样？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b11r0a/d_cvpr_2024_final_decision_is_out_how_about_your/</link>
      <description><![CDATA[在初始评估中，我获得的分数为 4(4)、1(4) 和 4(2)。具体来说，我获得了2 WA和1 SR。 但是，经过反驳过程，我的分数变为2 WA和1 WR（4,2,4）。 R2 审稿人认可了我的反驳中的一些观点。 不幸的是，尽管他们进行了讨论，AC 最终还是拒绝了我的提交。我还很谦虚地附上了“机密评论”，但结果出乎意料。 你的经历怎么样？ 🤔 查看民意调查   由   提交 /u/Secondhanded_PhD   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b11r0a/d_cvpr_2024_final_decision_is_out_how_about_your/</guid>
      <pubDate>Tue, 27 Feb 2024 03:29:32 GMT</pubDate>
    </item>
    <item>
      <title>通过 torch.compile 支持 gpt-fast 中的 Mixtral - 比任何非 Groq 端点更快的解码（！）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b10g2s/supporting_mixtral_in_gptfast_through/</link>
      <description><![CDATA[大家好，我们去年 12 月发布了 gpt-fast 作为可破解的“教程”实现文本生成的 SOTA 解码性能的各种实现。 从那时起，我们最近还在 gpt-fast 中添加了 Mixtral 实现。在这里查看：https://github.com/pytorch-labs/gpt-fast /tree/main/mixtral-moe  特色  (!) 无自定义内核 int8 和张量并行支持&lt; /li&gt; 仍然非常简单（支持&lt;150 LOC） 比任何（非 Groq）API 端点更快的解码速度，高达 220 tok/s/用户。  我还对这里涉及的挑战写了一份较长的解释：https://thonking.substack.com/p/short-supporting-mixtral-in-gpt-fast 希望人们觉得它有趣且有用！有趣的是，由于我们实际上在大约两个月前就完成了这项工作，并且推迟了将其合并，所以一些人（与我们无关）实际上已经对其进行了基准测试。 例如 此评论。  我们最近用 Mixtral 8x7B 尝试过此操作，结果非常疯狂！ Mixtral 8x7B 8 位版本在 A100-GPU (80GB) 上提供 55 个令牌/秒。最有趣的是，它比 4 位+vLLM 更好。    由   提交 /u/programmerChilli   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b10g2s/supporting_mixtral_in_gptfast_through/</guid>
      <pubDate>Tue, 27 Feb 2024 02:27:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 某些类别的模型现在被认为“过时”了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0ua8s/d_are_some_classes_of_models_considered_obsolete/</link>
      <description><![CDATA[作为一名高级 SWE，我希望在 ML 和数据科学方面进行一些自我驱动的培训。我正在收集和组织课程，我想知道某些主题现在是否已经过时，我可以安全地跳过它们。这主要来自构建应用程序的 POV。 例如，以 Coursera 上的 Andrew Ng GAN 专业为例。有了 Midjourney 或 OpenAI 视觉模型等稳定的扩散模型，GAN 仍然有用例吗？在 NLP 领域，现在只有 GPT4，我还需要研究 HMM 或构建玩具翻译和摘要模型吗？    由   提交/u/The-_Captain  /u/The-_Captain  reddit.com/r/MachineLearning/comments/1b0ua8s/d_are_some_classes_of_models_considered_obsolete/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0ua8s/d_are_some_classes_of_models_considered_obsolete/</guid>
      <pubDate>Mon, 26 Feb 2024 22:04:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] Genie：生成交互环境</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0tj6o/r_genie_generative_interactive_environments/</link>
      <description><![CDATA[ 由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0tj6o/r_genie_generative_interactive_environments/</guid>
      <pubDate>Mon, 26 Feb 2024 21:35:29 GMT</pubDate>
    </item>
    <item>
      <title>对于新晋研究科学家来说，该行业不会“复苏”[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0n3ib/the_industry_is_not_going_recover_for_newly/</link>
      <description><![CDATA[      今天的热门话题问：“科技行业还没有复苏吗？我有那么糟糕吗？” 让我做出一个大胆的预测（我希望我是错的，但我不认为我是错的）：这个行业不会“ “恢复”对于新晋研究科学家： 您的机器学习论文数量呈指数级增长，反映出博士生和博士后数量呈指数级增长： ​ &lt; p&gt;https://preview.redd.it/viv6l1gnkykc1。 png?width=899&amp;format=png&amp;auto=webp&amp;s=04e227dede42f7d46d1941fc268bb7ea0a409a04 ...毕业并开始竞争大致固定数量的井- 支付行业研究职位。这些职位的数量可能会季节性增加或减少，但长期趋势是他们的就业前景将变得越来越糟糕，而这种指数趋势仍在持续。 ​  div&gt;  由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0n3ib/the_industry_is_not_going_recover_for_newly/</guid>
      <pubDate>Mon, 26 Feb 2024 17:24:08 GMT</pubDate>
    </item>
    <item>
      <title>[N] 科技巨头正在开发他们的人工智能芯片。这是清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0ira9/n_tech_giants_are_developing_their_ai_chips_heres/</link>
      <description><![CDATA[NVIDIA GPU 短缺，导致多家公司创建自己的 AI 芯片。以下是这些公司的列表： • Google 处于改进张量处理单元 (TPU) 的前沿https://cloud.google.com/tpu?hl=en Google Cloud 技术。 • OpenAI 正在研究设计专有 AI 芯片的潜力https://www.reuters.com/ technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/。 • 微软宣布 https://news.microsoft.com/source/ features/ai/in-house-chips-silicon-to-service-to-meet-ai-demand/ 两款定制设计的芯片：用于大型语言模型训练和推理的 Microsoft Azure Maia AI 加速器以及用于大型语言模型训练和推理的 Microsoft Azure Maia AI 加速器Azure Cobalt CPU，用于 Microsoft 云上的通用计算工作负载。 • 亚马逊推出了 Inferentia AI 芯片 https://aws.amazon.com/machine-learning/inferentia/ 和第二代机器学习 (ML) 加速器 AWS Trainium https://aws.amazon.com/machine-learning/trainium/。 • Apple 一直在开发其系列定制芯片并推出https://www.apple.com/newsroom/2023/10/apple-unveils-m3-m3-pro-and-m3-max-the-most-advanced-chips-for-a-personal -computer/ M3、M3 Pro 和 M3 Max 处理器，可扩展到专门的 AI 任务。 • Meta 计划部署新版本的定制芯片，旨在支持其人工智能据路透社报道，人工智能（AI）的推动 https://www.reuters.com/technology/meta-deploy-in-house-custom-chips-this-year-power-ai-drive-memo-2024-02-01/ . • 据报道，华为https://www.reuters.com/technology/ai-chip-demand-forces-huawei-slow-smartphone-product-sources-2024-02-05/由于人工智能芯片的需求，人工智能并放慢了高端 Mate 60 手机的生产 https://www.hisilicon.com/ en/products/ascend 飙升。 我错过了什么吗？   由   提交 /u/vvkuka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0ira9/n_tech_giants_are_developing_their_ai_chips_heres/</guid>
      <pubDate>Mon, 26 Feb 2024 14:25:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是科技行业还没复苏还是我太差了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0ia76/d_is_the_tech_industry_still_not_recovered_or_i/</link>
      <description><![CDATA[我是欧洲顶尖大学的一名应届博士毕业生，正在研究 ML/CV 中的一些热门主题，已发表 8 - 20 篇论文，其中大部分是我的第一作者。这些论文已累计被引用1000-3000次。 （使用新帐户和广泛的范围来保持匿名） 尽管我认为自己是一个相当有实力的候选人，但我在最近的求职过程中遇到了重大挑战。我主要瞄准研究科学家职位，希望从事开放式研究。我已经联系了欧洲、中东和非洲地区的许多高级机器学习研究人员，虽然有些人表达了兴趣，但不幸的是，由于各种原因（例如人员有限或招聘经理没有更新信息），没有一个机会成为现实。 我主要针对大型科技公司以及一些最近流行的机器学习初创公司。不幸的是，我的大部分申请都被拒绝了，而且常常没有面试的机会。 （我只接受过一家大型科技公司的一次面试，然后就被拒绝了。） 特别是，尽管有朋友的推荐，我还是立即遭到了 Meta 的研究科学家职位拒绝（几天之内）。我现在只是非常困惑和不安，不知道出了什么问题，我是否被这些公司列入了黑名单？但我不记得我树敌过。我希望就下一步可以做什么寻求一些建议......   由   提交/u/Holiday_Safe_5620   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0ia76/d_is_the_tech_industry_still_not_recovered_or_i/</guid>
      <pubDate>Mon, 26 Feb 2024 14:04:26 GMT</pubDate>
    </item>
    <item>
      <title>目前关于使用 TensorFlow 2.x 与 PyTorch 的共识是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b0gxy7/whats_the_current_consensus_on_using_tensorflow/</link>
      <description><![CDATA[我知道许多人在 TF1 到 TF2 迁移期间离开了 TF，并且再也没有回头。我的问题是，目前关于使用 TF2 与 PyTorch（与 Jax）的共识是什么？为什么？  从端到端的角度来看，对我来说，TF2 很好。 PyTorch 上的调试更容易，但好处还不足以放弃所有内容并永远保留 TF2。你们怎么看？ 假设您正在构建人工智能产品并且部署是必须的，您在代码库中更喜欢 TensorFlow 还是 Pytorch（或 JAX），为什么？    由   提交 /u/1infiniteloop   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b0gxy7/whats_the_current_consensus_on_using_tensorflow/</guid>
      <pubDate>Mon, 26 Feb 2024 13:01:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>