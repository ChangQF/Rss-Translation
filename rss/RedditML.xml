<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 15 Nov 2024 09:18:52 GMT</lastBuildDate>
    <item>
      <title>[D] 为什么我的（TensorFlow Lite）模型可以在桌面上运行，但在移动设备（Android）上却不行？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grqemd/d_why_does_my_tensorflow_lite_model_work_on/</link>
      <description><![CDATA[大家好， 我正在使用 TensorFlow Lite 在 Unity 中构建音频分类器，遇到了一个有趣的问题，我希望在这里询问以了解有关此问题的更多信息： - 默认的 YAMNet 模型在桌面和 Android 上都能完美运行 - 我的自定义模型（使用 Google Teachable Machine 制作）在桌面上运行良好，但在 Android 上完全失败 什么可能导致桌面和移动设备之间的差异？ 谢谢！    提交人    /u/kyzouik   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grqemd/d_why_does_my_tensorflow_lite_model_work_on/</guid>
      <pubDate>Fri, 15 Nov 2024 06:41:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] DTFormer：一种基于 Transformer 的离散时间动态图表示学习方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grq9cn/r_dtformer_a_transformerbased_method_for_discrete/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grq9cn/r_dtformer_a_transformerbased_method_for_discrete/</guid>
      <pubDate>Fri, 15 Nov 2024 06:31:02 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 编码助手的下一步是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grn0e1/discussion_whats_next_for_coding_assistants/</link>
      <description><![CDATA[大家好，ML 社区！ 正如我们在 GitHub Copilot、ChatGPT Code Interpreter 等工具中看到的那样，编码助手越来越能够协助软件开发。但是，还有很大的改进空间，我很想知道您对这项技术的未来有何看法。 下一步是什么？ 对于那些积极从事或关注机器学习和自然语言处理的人来说，编码助手最有前途的研究领域是什么？我正在考虑的一些方向是： 上下文理解：不仅要理解当前的行或功能，还要理解更广泛的项目上下文 - 包括代码库内部和外部。 错误处理和调试：不仅仅是生成代码，还要主动检测、解释和调试代码问题。 个性化：随着时间的推移适应各个开发人员的编码风格和偏好。 复杂项目管理：协助管理复杂项目甚至团队范围集成中的依赖关系、框架和最佳实践。 人工智能驱动的测试：不仅可以自动化代码编写，还可以自动化测试生成和评估，以更高程度地保证功能。 尚未解决的技术挑战我也很想听听主要的技术障碍。这些可能包括： 长距离依赖关系建模：许多助手难以在更大的代码库中有效地保留上下文。 细粒度控制：使用户能够指示助手执行特定任务，而无需“徘徊”或更改范围。 工具使用集成：编码助手如何与外部工具、调试器、数据库等无缝集成。 可信度和透明度：确保用户了解提出某个建议的原因以及模型的置信度。 您认为剩下的最大障碍是什么？有没有什么特定的论文或项目您推荐查看？提前感谢任何链接、研究建议或观点！    提交人    /u/huopak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grn0e1/discussion_whats_next_for_coding_assistants/</guid>
      <pubDate>Fri, 15 Nov 2024 03:17:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我应该转到推荐算法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grl7gk/d_should_i_transfer_to_recommendation_algorithms/</link>
      <description><![CDATA[我现在在一个“LLM”团队工作，或者至少广告上是这么宣传的，老实说，它只是使用 LLM 进行分类，并不是很有趣。我收到了公司另一个做推荐的团队的邀请。我认为推荐是一个非常可靠的领域，但竞争非常激烈。你们在推荐方面有什么工作经验？    提交人    /u/DolantheMFWizard   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grl7gk/d_should_i_transfer_to_recommendation_algorithms/</guid>
      <pubDate>Fri, 15 Nov 2024 01:42:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] RedCode：评估代码语言模型安全性和风险的基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grkagz/r_redcode_a_benchmark_for_evaluating_safety_and/</link>
      <description><![CDATA[RedCode：评估代码代理安全性的新基准 我一直在审查这篇介绍 RedCode 的新论文，RedCode 是用于评估 AI 代码代理的代码生成和执行的安全性方面的基准。核心贡献是一种系统性的方法来评估代码代理如何处理潜在的不安全操作。 基准测试由两个主要部分组成： - RedCode-Exec：测试代理对 8 个域中 25 种漏洞类型的 4,050 个提示的响应 - RedCode-Gen：评估代理是否从 160 个函数签名 / 文档字符串生成有害代码 关键技术点： - 使用 Docker 环境进行受控执行测试 - 实现自定义指标以进行安全评估 - 涵盖 Python 和 Bash 代码 - 测试多种输入格式（代码片段和自然语言） - 使用 19 种不同的 LLM 评估了 3 个代理框架 主要发现： - 与有缺陷的代码相比，代理对操作系统级风险操作的拒绝率更高 - 自然语言对风险操作的描述比代码的拒绝率更低 - 更强大的模型（例如 GPT-4）在提示时会生成更复杂的有害代码 - 发现安全性存在显著差异跨不同代理框架的性能 这些影响对于在生产环境中部署代码代理非常重要。结果表明，当前系统存在明显的安全漏洞，特别是在代码执行方面。该基准测试提供了一种评估和改进代码代理安全机制的标准化方法。 TLDR：名为 RedCode 的新基准测试测试代码代理处理不安全代码执行和生成的能力。结果表明，当前代理的安全能力水平各不相同，特别是在自然语言输入和技术上有缺陷的代码方面存在漏洞。 完整摘要在此处。论文此处。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grkagz/r_redcode_a_benchmark_for_evaluating_safety_and/</guid>
      <pubDate>Fri, 15 Nov 2024 00:56:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文俱乐部：Nvidia 研究员 Ethan He 介绍教育部法学硕士课程升级改造</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grjjlz/d_paper_club_nvidia_researcher_ethan_he_presents/</link>
      <description><![CDATA[大家好， 明天，Nvidia 研究员 Ethan He 将深入研究他的工作：在混合专家 (MoE) 中升级法学硕士。很高兴能一睹幕后风采，看看在 Nvida 处理这种规模的模型是什么样的。 如果您想在明天太平洋标准时间上午 10 点加入社区，我们非常欢迎您。我们通过 zoom 进行现场直播，欢迎任何人加入。 这是论文：https://arxiv.org/abs/2410.07524 现场加入我们：https://lu.ma/arxivdive-31    提交人    /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grjjlz/d_paper_club_nvidia_researcher_ethan_he_presents/</guid>
      <pubDate>Fri, 15 Nov 2024 00:19:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习理论研究有哪些重要贡献？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grfxbz/d_what_are_some_important_contributions_from_ml/</link>
      <description><![CDATA[我有兴趣了解更多关于近年来理论 ML 研究人员的贡献。我想听听那些不适用的超级重要贡献（例如，告诉我们一些重要的事情）以及在现实世界中也适用的贡献。我想尝试阅读这些论文。 此外，我有兴趣知道（理论）研究人员对这个领域的看法，它有潜力吗，还是 ML 正在朝着纯粹的启发式方向发展？ 如果不谈论 ML 只是统计数据和 Lipschitz 常数，这次讨论可能会更有成效 :) 我说的是前沿的理论研究——我真的没有工具来估计这条工作线有多大用处，我相信这对其他人来说也是一个有趣的讨论。    提交人    /u/Traditional-Dress946   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grfxbz/d_what_are_some_important_contributions_from_ml/</guid>
      <pubDate>Thu, 14 Nov 2024 21:34:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在 textvqa 测试分割上进行测试？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gralqc/r_testing_on_textvqa_test_split/</link>
      <description><![CDATA[大家好，我想在 textvqa 测试集上测试我的模型，这显然需要在 evalai 网站上完成。但是两个挑战（2019/2020）都在那里关闭并且没有提交选项，此外 textvqa 官方网站提供的链接不起作用。（https://eval.ai/web/challenges/challenge-page/874/）关于如何在测试集上测试有什么想法吗？谢谢！    提交人    /u/Training-Adeptness57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gralqc/r_testing_on_textvqa_test_split/</guid>
      <pubDate>Thu, 14 Nov 2024 17:48:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习训练中的协调避免</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gra953/r_coordination_avoidance_in_ml_training/</link>
      <description><![CDATA[我对避免分布式机器学习训练中协调规避的方案很好奇。如果您可以参考一些相关论文，我将不胜感激。    提交人    /u/net-weight   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gra953/r_coordination_avoidance_in_ml_training/</guid>
      <pubDate>Thu, 14 Nov 2024 17:33:41 GMT</pubDate>
    </item>
    <item>
      <title>[D][P]聚类分类数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr7zqg/dpclustering_categorical_data/</link>
      <description><![CDATA[对由分类变量组成的数据框执行聚类的最佳方法是什么？ 我想使用具有许多变量的数据框，因此 One-Hot-Encoding 可能不是最佳解决方案。 SOTA 技术有哪些？也许是嵌入的东西？    提交人    /u/DedeU10   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr7zqg/dpclustering_categorical_data/</guid>
      <pubDate>Thu, 14 Nov 2024 15:57:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习模型中不可检测的后门：使用数字签名和随机特征的新技术，对对抗鲁棒性有影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr4ksm/r_undetectable_backdoors_in_ml_models_novel/</link>
      <description><![CDATA[我发现了一个重要的后门攻击分析，它展示了恶意服务提供商如何将无法检测到的后门插入机器学习模型中。 关键贡献是展示了如何构建即使在白盒分析下也无法检测到的后门，同时允许通过微妙的输入扰动任意操纵模型输出。 技术细节：* 用于植入无法检测的后门的两个框架：* 基于数字签名方案的后门，在计算上无法通过黑盒访问检测* 基于随机傅立叶特征/随机 ReLU 的后门，可经受白盒检查* 即使具有以下条件，后门模型也与干净模型无法区分：* 完全访问模型架构和参数* 完整的训练数据集* 分析模型行为的能力 结果：* 后门模型保持与原始模型相同的泛化误差* 服务提供商可以通过轻微扰动修改任何输入的分类* 构造适用于任何底层模型架构 * 任何计算受限的观察者都无法检测到后门 这对 ML 安全和外包培训具有重大影响。这项工作显示了证明对抗性鲁棒性的根本局限性——一个后门模型可能与一个鲁棒模型无法区分，而每个输入都有对抗性的例子。 TLDR：论文证明可以将无法检测到的后门插入 ML 模型中，允许任意操纵输出，同时证明无法检测到。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr4ksm/r_undetectable_backdoors_in_ml_models_novel/</guid>
      <pubDate>Thu, 14 Nov 2024 13:19:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 数据的几何形状：缺失的度量张量和 Stein 分数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr4bfl/r_the_geometry_of_data_the_missing_metric_tensor/</link>
      <description><![CDATA[只是分享一篇文章给那些对微分几何、ML 和基于分数的模型感兴趣的人。我做了一个很长的介绍，然后我展示了如何仅使用 Stein 分数来推导出一个有效的计算数据流形度量张量的方法。    由   提交  /u/perone   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr4bfl/r_the_geometry_of_data_the_missing_metric_tensor/</guid>
      <pubDate>Thu, 14 Nov 2024 13:05:04 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 缩放定律和图神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr2t6l/discussion_scaling_laws_and_graph_neural_networks/</link>
      <description><![CDATA[我偶然发现了一篇介绍第一个“图形基础模型”的论文：https://arxiv.org/pdf/2407.11907 他们表明，GNN 可以随着数据和模型大小而扩展，跨不同领域进行推广，并可以在新数据集上进行有效微调。 这对我来说很有趣，因为即使 LLM 风靡一时，文本也可能是一种弱数据表示。大多数知识都有图形结构。代码、研究论文，甚至人类大脑——都是图形。而下一个标记预测作为归纳偏差并没有利用这一点。 当然，这里有一个巨大的数据瓶颈。但也许下一步是使用 LLM 将互联网上的大量文本转换为图表进行训练。  你们觉得怎么样？    提交人    /u/jsonathan   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr2t6l/discussion_scaling_laws_and_graph_neural_networks/</guid>
      <pubDate>Thu, 14 Nov 2024 11:34:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>