<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Mon, 06 May 2024 03:16:12 GMT</lastBuildDate>
    <item>
      <title>[D]“对话分类”有正式名称吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cl4tg1/d_is_there_a_formal_name_for_dialogue/</link>
      <description><![CDATA[我正在尝试将对话分类。具体来说，如果我们有客户服务聊天数据，其中客户提出问题并由客服代表回答，我想将这些数据分类为具有“产品查询”、“产品查询”等标签。 “交货查询”等等 这有正式的名称吗？这似乎不是正常的文本分类，因为我们必须考虑说话人信息。似乎也没有一个叫做对话分类的任务。我认为意图分类可能最接近，但典型的数据集似乎只使用初始查询作为输入文本，而不是整个对话。 我认为也许使用整个对话可能不合适，也许可能会有一个从对话中提取关键查询的初始阶段。之后也许这些可以用于意图分类，但我不确定这是否是一个理想的方法。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cl4tg1/d_is_there_a_formal_name_for_dialogue/</guid>
      <pubDate>Sun, 05 May 2024 23:33:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 用于 QA 和推理的用例。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cl4oc7/d_llm_use_case_for_qa_and_reasoning/</link>
      <description><![CDATA[考虑一个用例，其中我们有文本数据。我们必须从中提取信息。有些数据是直接的，可以直接赋值。其他的就不那么直接了，比如总重量、总量，这些值应该是从数据中提取出单个数据后计算出来的。 由于RAG提供了上下文信息，所以我打算通知LLM关于要提取的标签。我还计划对 Llama3 的注释进行微调，以便模型了解信息提取的实际情况。 还可以采取哪些措施来提高模型的输出性能。   由   提交/u/xandie985  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cl4oc7/d_llm_use_case_for_qa_and_reasoning/</guid>
      <pubDate>Sun, 05 May 2024 23:27:24 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型如何玩视频游戏[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cl3zmi/how_large_language_models_play_video_games_d/</link>
      <description><![CDATA[      来自我的 YT 频道的视频，讲述如何使用 LLM 进行游戏Crafter（Minecraft-lite）和 Atari 等视频游戏。其中一些是单独的 LLM 提示工程工作，而另一些则帮助 RL 代理探索或提供更好的奖励信号。如果有人感兴趣，请点击此处链接。   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cl3zmi/how_large_language_models_play_video_games_d/</guid>
      <pubDate>Sun, 05 May 2024 22:55:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 支持具有导数信息的高斯过程的 Python 库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cl3vtp/d_python_libraries_that_support_gaussian/</link>
      <description><![CDATA[大家好，我正在寻找支持具有导数信息的高斯过程的 Python 库（GPyTorch 除外）。我目前正在使用 GPyTorch，想要将我得到的结果与其他库进行比较。我查看了 GPflow 和 GPy 的文档，但找不到它们是否支持这个或文档中的任何示例。如果您碰巧有示例链接，那就太好了！   由   提交/u/m-julian1  /u/m-julian1  reddit.com/r/MachineLearning/comments/1cl3vtp/d_python_libraries_that_support_gaussian/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cl3vtp/d_python_libraries_that_support_gaussian/</guid>
      <pubDate>Sun, 05 May 2024 22:50:36 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 一个由法学硕士支持的用于 SEC 归档洞察的 Web 应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cl3fs3/project_an_llmpowered_web_app_for_sec_filing/</link>
      <description><![CDATA[我构建了一个应用程序，该应用程序使用大型语言模型 (LLM) API 分析 10-K 文件并生成见解，以全面了解公司的财务业绩通过用户友好的可视化和分段细分来制定战略方向。 以下是 GitHub 存储库的链接：https://github.com/astonishedrobo/sec-llm-insights 以后我还打算加上RAG，避免LLM产生幻觉。 任何改进/准确的建议都将受到重视。   由   提交 /u/PleasantInspection12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cl3fs3/project_an_llmpowered_web_app_for_sec_filing/</guid>
      <pubDate>Sun, 05 May 2024 22:30:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 时间序列预测 ML 验证集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cl1gs2/r_timeseries_predictive_ml_validation_set/</link>
      <description><![CDATA[我一直在做一个项目。简而言之，预测未来的时间段，例如，提前 1 个月，因为我使用的是月度数据。  当我处理时间序列数据时，按时间顺序排列是否合乎逻辑/有必要吗？  至关重要的是，验证模型。如果我现在想根据验证数据调整/优化模型，我该如何选择验证集的长度，因为逻辑上它是最新的数据，对吗？？？应该是 1 个月还是 10 个月？我尝试过蛮力方法，但对于我的笔记本电脑来说这是不可能的。 任何见解或相关故事都会很棒。干杯    由   提交/u/wiktor2701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cl1gs2/r_timeseries_predictive_ml_validation_set/</guid>
      <pubDate>Sun, 05 May 2024 21:05:18 GMT</pubDate>
    </item>
    <item>
      <title>[研究]理解变形金刚中的注意力机制：5分钟的视觉指南。 🧠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckxzti/research_understanding_the_attention_mechanism_in/</link>
      <description><![CDATA[   TL。 ;DR：注意力是键值存储或字典的“可学习”、“模糊”版本。由于主要针对 NLP 和 LLM 改进了序列建模，Transformers 使用注意力并接管了以前的架构 (RNN)。 什么是注意力以及它为何接管法学硕士和机器学习：视觉指南 &lt; a href=&quot;https://preview.redd.it/8aoqz10hjnyc1.png?width=1903&amp;format=png&amp;auto=webp&amp;s=234b7aa38e9eee56d9d91f70f69ff81a7c666ff7&quot;&gt;https://preview.redd.it/8aoqz10hjnyc1.png?width =1903&amp;format=png&amp;auto=webp&amp;s=234b7aa38e9eee56d9d91f70f69ff81a7c666ff7   由   提交/u/ml_a_day  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckxzti/research_understanding_the_attention_mechanism_in/</guid>
      <pubDate>Sun, 05 May 2024 18:34:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 营销分析的问题框架/模型选择</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckx3c6/d_problem_framingmodel_selection_for_marketing/</link>
      <description><![CDATA[您好 我们正在选择、训练和使用人工智能模型来确定营销行动的最佳顺序在接下来的几周内，最大限度地提高 B2B 消费品（即需要定期购买的产品）的每个客户群的增量销售。即使没有促销，我们的许多客户也可能会购买我们的产品 - 然而，我们发现，当我们有促销时，每周销售额会显着增加 从历史上看，我们执行的活动包括电子邮件、虚拟会议和in-人员会议。 我们有过去 2 年每周的以下数据  每个细分市场的总销售额（这是目标变量） &lt; li&gt;营销活动类型  我们的假设是，每周增量销售额取决于多种因素，包括客户群、渠道（面对面、电话、电子邮件）以及序列行动。 我们最初的假设是，任何 4 周内的促销活动都会对未来 4 周的增量销售产生影响。因此，2 月份的活动对 3 月份产生了重大影响，但在 4 月或 5 月影响不大。 一般来说，我们在任何特定的一周内只有一种类型的联系（因此可以是面对面的联系，也可以是电话或电子邮件） 。因此，在任何 4 周内，我们都有 3x3x3x3 = 81 种组合。 （有些组合极不可能，例如连续 4 周每周举行面对面会议 - 因此实际组合数量可能略小于 81）。 我们正在考虑分两步进行的流程&lt; /p&gt;  对于每个细分市场和 81 种组合中的每一种，预测未来 4 周的销售额。从当前 4 周的实际销售额中减去预测销售额，即可找到未来 4 周的增量销售额 选择增量销售额最高的组合  对于步骤 1，我的两位数据科学家提出了不同的选择。 Bob 提出了选项 A：使用回归。根据鲍勃的说法，不同时间段的销售额之间的时间关系非常有限，因此线性回归模型应该足够了。他想尝试线性回归、随机森林和 XGBoost。他认为这种方法可以很快进行测试（约 8 周），并且应该会给出不错的结果。 Susan 提出选项 B：按照 Susan 的说法，我们应该使用时间序列方法，因为任何细分市场的销售额给定的 4 周时间应该与之前的 4 周时间有一定的时间关系。她想尝试平滑技术、ARIMA 以及深度学习方法，例如普通 RNN、LSTM 和 GRU。她要求大约 12-14 周，但表示这是一种更稳健的方法，可能会表现出更高的性能。 我们有一些时间压力来展示一些结果，但没有资源来尝试两者并行。 关于我应该如何在这两个选项之间进行选择有什么建议吗？   由   提交 /u/Asleep_Help5804   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckx3c6/d_problem_framingmodel_selection_for_marketing/</guid>
      <pubDate>Sun, 05 May 2024 17:55:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 博士后为血癌患者开发医疗机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cksxm2/r_postdoc_developing_medical_machine_learning_in/</link>
      <description><![CDATA[我们为丹麦淋巴癌研究 (DALY-CARE) 创建了多模式大规模数据资源，包括来自 13 个国家登记册的 65,000 多名个人 + 详细的电子数据健康记录数据。我们与 AZ 合作，AZ 正在聘请一名博士后同事来开发医学机器学习算法，以预测靶向治疗的临床结果。可以在此处提交申请https://careers.astrazeneca.com/job/gothenburg/postdoc-fellow-machine-learning-for-predicting-adverse-events-in-blood-cancer-treatments/7684/64381401040   由   提交/u/Boring_Amoeba5297   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cksxm2/r_postdoc_developing_medical_machine_learning_in/</guid>
      <pubDate>Sun, 05 May 2024 14:48:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在创建神经网络时，是否有更系统的方法来选择层或架构的深度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckrzq6/d_is_there_a_more_systematic_way_of_choosing_the/</link>
      <description><![CDATA[所以我正在学习深度学习和神经网络，我对这部分真的有点困惑。我通常熟悉可用的层及其工作原理（至少是那些广泛使用的层），但我仍然很难弄清楚在什么上使用什么。有没有更合乎逻辑或系统的方法来做到这一点？比如数学什么的？我很想尝试，但我只是想避免陷入困境，因为这个项目是在截止日期前完成的，而我对此并不失望    ;由   提交/u/PsychologicalAd7535   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckrzq6/d_is_there_a_more_systematic_way_of_choosing_the/</guid>
      <pubDate>Sun, 05 May 2024 14:04:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据科学家的真正价值从何而来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cknrka/d_where_does_the_real_value_of_a_data_scientist/</link>
      <description><![CDATA[公司关心你能为他们做什么，并高度重视利润。在我看来，典型的软件工程师的价值在于：  他们可以快速交付代码 他们足够聪明  即它们是极其消耗性的，这是你永远不想成为的。数据科学家和软件工程师一样可以消耗吗？是什么让数据科学家在市场上变得不可替代和受欢迎？    由   提交/u/Error40404  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cknrka/d_where_does_the_real_value_of_a_data_scientist/</guid>
      <pubDate>Sun, 05 May 2024 09:54:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] NVIDIA GPU 基准测试与比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cklpyd/d_nvidia_gpu_benchmarks_comparison/</link>
      <description><![CDATA[https://tensordock.com/benchmarks 过去几个小时在 TensorDock 云上汇总了有关 vLLM（针对 Llama 7B 和 OPT-125M）和 Resnet-50 训练性能的一些数据。  vLLM 数据 100% 开箱即用，来自 此存储库的批量大小为 2048 。  我的经验：  H100 和 A100 的性能是无与伦比的，但低端 RTX 卡的性价比相当不错。甚至 L40 和 RTX 6000 Ada 在某些任务上的表现也优于 A100，因为它们比 A100 更新了 1 代。 如果您的应用程序不需要 80GB VRAM，那么不使用 80GB VRAM 卡可能是有意义的 独立 H100 性能并不像我想象的那么强大。 H100 的性能受到 LLM 推理的内存带宽的瓶颈，因此对于 vLLM，H100 的速度仅比 A100 快 1.8 倍。当互连在一起时，H100 确实表现得更好，但我今天没有进行基准测试。  CPU 比我想象的更重要。 OPT-125M 与 Llama 7B 的性能比较非常有趣...不知何故，所有 GPU 在 OPT-125M 上的表现都相似，我认为这是因为使用的 CPU 时间比 GPU 时间相对多，因此 GPU 性能差异在宏伟的计划。 市场定价本身相当不错。如果将 GPU 分组到 VRAM 中，则所有具有相似 VRAM 数量的 GPU 都具有相似的性价比。 如果您有足够的批量大小，自托管可以为您节省 $$$。如果您构建自己的推理 API，您可以仅使用 50% 的批次为 LLM 提供服务，并且与按代币付费的 API 相比可以节省资金（如果您 100% 使用我们，我们 [TensorDock] 每百万个 Llama 7 代币的成本不到 0.07 美元） )  --  让我知道接下来要对哪个 GPU 进行基准测试，我会添加它！或者让我知道一些其他需要衡量的工作量，我也很乐意为此添加一个新部分。  P.S.我们以 1.80 美元/小时的价格添加了一些 H100，供任何有幸获得它们的人使用！    由   提交/u/jonathan-lei   reddit.com/r/MachineLearning/comments/1cklpyd/d_nvidia_gpu_benchmarks_comparison/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cklpyd/d_nvidia_gpu_benchmarks_comparison/</guid>
      <pubDate>Sun, 05 May 2024 07:25:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 仔细检查大型语言模型在小学算术中的表现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckkf5f/r_a_careful_examination_of_large_language_model/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2405.00332 摘要：  大型语言模型（LLM）在许多基准测试中取得了令人印象深刻的成功用于数学推理。然而，人们越来越担心，其中一些性能实际上反映了数据集污染，即与基准问题非常相似的数据泄漏到训练数据中，而不是真正的推理能力。为了严格调查这一说法，我们委托小学数学 1000 (GSM1k)。 GSM1k 的设计反映了已建立的 GSM8k 基准的风格和复杂性，GSM8k 基准是衡量基本数学推理的黄金标准。我们确保这两个基准在人类解决率、解决步骤数、答案大小等重要指标上具有可比性。在评估 GSM1k 上领先的开源和闭源法学硕士时，我们观察到准确性下降高达 13%，几个模型系列（例如 Phi 和 Mistral）显示出几乎所有模型大小的系统过度拟合的证据。与此同时，许多模型，尤其是前沿模型（例如 Gemini/GPT/Claude）显示出最小的过度拟合迹象。进一步的分析表明，模型从 GSM8k 生成示例的概率与 GSM8k 和 GSM1k 之间的性能差距之间存在正相关关系（Spearman 的 r2=0.32），这表明许多模型可能已经部分记住了 GSM8k。    由   提交 /u/SurveySea7570   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckkf5f/r_a_careful_examination_of_large_language_model/</guid>
      <pubDate>Sun, 05 May 2024 05:57:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI 模型中的“它”真的只是数据集吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cjxh9u/d_the_it_in_ai_models_is_really_just_the_dataset/</link>
      <description><![CDATA[   /u/vijayabhaskar96   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cjxh9u/d_the_it_in_ai_models_is_really_just_the_dataset/</guid>
      <pubDate>Sat, 04 May 2024 10:47:31 GMT</pubDate>
    </item>
    </channel>
</rss>