<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 20 Feb 2024 21:11:54 GMT</lastBuildDate>
    <item>
      <title>[D] 共识已过时/具有误导性（ChatGPT 3.5？）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avszpa/d_consensus_outdated_misleading_chatgpt_35/</link>
      <description><![CDATA[我通过 ChatGPT Plus 向 Consensus 询问了最新的 AI 论文。 答案是 2021 年的论文！？ 我的印象是Consensus有一个自己训练过的数据集也是因为它在GPT“商店”中受到强烈推荐和推荐，并声称拥有2亿篇论文。但它似乎只是使用GPT 3.5使用2022年之前的旧数据集。   由   提交/u/vonnoor  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avszpa/d_consensus_outdated_misleading_chatgpt_35/</guid>
      <pubDate>Tue, 20 Feb 2024 21:11:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] 飞行路径优化算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avsyfg/r_flight_path_optimisation_algorithm/</link>
      <description><![CDATA[我正在创建一个工具来帮助飞机在两个城市 A 和 B 之间更智能地飞行。可以将其想象为 Google 地图，但适用于飞机。当飞机飞行时，它们不会直接从 A 点飞往 B 点；而是直接从 A 点飞往 B 点。它们遵循一条从一个点跳到另一个点的路径，称为路径点。这些航路点和其他细节，例如飞机飞行多远、需要多长时间以及使用多少燃料，都是提前计划好的，并写在所谓的飞行计划报告中。但是，实际飞行可能会比预期使用更多燃油或花费更长的时间。 我有这些城市之间过去航班的记录，因此我知道哪些路径确实非常节省燃油。我的目标是建立一个算法，查看即将到来的航班的计划路线，并与过去的航班进行检查。然后，它会向飞行员建议节省燃油的最佳路径。这就像提醒他们过去哪些路线最省油。”我在这方面完全是新手。有人可以帮我选择应该选择的优化方法吗？   由   提交/u/Desperate_Roll2360   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avsyfg/r_flight_path_optimisation_algorithm/</guid>
      <pubDate>Tue, 20 Feb 2024 21:09:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要多少图像才能创建约 50 人的面部识别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avsnzf/d_how_many_images_would_be_needed_to_create_a/</link>
      <description><![CDATA[每个人 10 张好照片就足够了吗？如果我有每个人在不同地点/灯光下的少量照片（例如 10 张），我可以将这些照片以数字方式更改为“假”吗？我的照片集中还有更多照片吗？我可以使用已经经过面部训练的模型并输入我自己的图片，因为它已经经过高度训练，能够注意到细微的面部变化吗？ 你认为我需要多少人来训练一个不需要的模型100% 准确，但这比随机挑选更好，哈哈 - 使用任何可用的工具，谢谢 :)    ;由   提交 /u/underbrownmaleroad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avsnzf/d_how_many_images_would_be_needed_to_create_a/</guid>
      <pubDate>Tue, 20 Feb 2024 20:58:30 GMT</pubDate>
    </item>
    <item>
      <title>有哪些开源库可以帮助我在构建 LLM 应用程序时轻松地在 LLM 之间切换？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avryf1/any_open_source_libraries_that_can_help_me_easily/</link>
      <description><![CDATA[我一直在构建使用 LLM 和 RAG 的开源工具，但是，有大量的 LLM 模型和框架可供选择，包括OpenAI、Huggingface、AzureOpenAI 等。为每个类编写新类和扩展可能很困难。我很好奇是否有更简单的方法，例如将最大数量的 LLM api 统一在一个工具/框架下，这样我就不必为所有内容编写一个新类？  在这些情况下你通常会做什么？   由   提交 /u/metalvendetta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avryf1/any_open_source_libraries_that_can_help_me_easily/</guid>
      <pubDate>Tue, 20 Feb 2024 20:30:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前最好的 PDF 文本转语音工具（最好是免费的）是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avregq/d_what_is_the_best_texttospeech_tool_preferably/</link>
      <description><![CDATA[大家好，我需要一个 TTS 工具，它使用先进的 ML 算法，听起来非常自然。我想用它来编辑我的一些 YouTube 视频，将一些书籍 (PDF) 转换为 mp3。我看到周围有很多 TTS 平台。你推荐哪一个？我希望这不是一个过分的要求。我将非常感激。 提前致谢。 PS：ElevenLabs 不会这样做，因为它不接受 PDF 或文本文件。另外，使用起来不太复杂的 GitHub 存储库也很棒   由   提交 /u/HighAndInsane   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avregq/d_what_is_the_best_texttospeech_tool_preferably/</guid>
      <pubDate>Tue, 20 Feb 2024 20:09:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kaggle 数据集与实际表格数据 - 痛苦的认识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avq8uz/d_kaggle_datasets_vs_actual_tabular_data_bitter/</link>
      <description><![CDATA[经过多年在 Kaggle 或其他平台上的表格数据集的工作和实践，我终于开始使用来自大学医院的表格数据，就像一滩污垢花了一整天的时间才找到正确的标题并链接所有这些表间公式和过滤器。另一方面，我花了最多。 Kaggle 数据集上的 EDA 需要 30 分钟。  我被告知了其中的差异，但意识到 DS 必须处理什么混乱。总是低估它，跳过与之相关的研讨会，还随意取笑它（我通常处理图像和视频）。   由   提交 /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avq8uz/d_kaggle_datasets_vs_actual_tabular_data_bitter/</guid>
      <pubDate>Tue, 20 Feb 2024 19:23:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么扩散器库改变了原来的采样算法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avjgso/d_why_does_the_diffuser_library_change_the/</link>
      <description><![CDATA[      我最近一直在分析拥抱面部扩散器库的内部工作原理，并且我已经意识到step()函数内部采样方法似乎发生了变化： ​ https://preview.redd.it/9zz4yzm37rjc1.png?width=2041&amp;format=png&amp;auto=webp&amp;s = de825eb3d57bbffa103998368f60401dc9f6f304 如果我理解正确的话，首先，他们使用以下公式创建 x₀ 的预测： https://preview.redd.it/2cy3dp257rjc1.png?width=1483&amp;format=png&amp;auto =webp&amp; ;s=3126d7b6ddb26743f4c0545275d0dc3a12f154a0 接下来，他们使用以下方程创建 xₜ₋₁： https://preview.redd.it/72hbpzn57rjc1.png?width=1936&amp;format=png&amp;auto=webp&amp;s=3f839aa6ad 96d3c81812256e33573859a30b8f9b 但我认为这与原始方程第 4 行相比是一个巨大的变化： https://preview.redd.it/upexate77rjc1.png?width=1060&amp;format=png&amp;auto=webp&amp;s=4c6d17715f7 4fa4b72ecf63b4a82598634a36372&lt; /a&gt; 为什么他们使用不同的方式来获取xₜ₋₁？这种方法有什么优点？有没有任何原始材料或论文可以检查它的来源？ 谢谢您的帮助！   由   提交 /u/SrPinko   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avjgso/d_why_does_the_diffuser_library_change_the/</guid>
      <pubDate>Tue, 20 Feb 2024 14:52:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对检索增强生成（RAG）中的不同术语感到困惑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avikjn/d_confused_about_different_terms_in/</link>
      <description><![CDATA[嗨，我有一个课堂练习，需要对检索增强生成 (RAG) 进行文献回顾。我的老师告诉我们阅读“在检索增强生成中对大型语言模型进行基准测试”并找到一些其他有助于提高噪声鲁棒性的论文和信息交互。  我发现的一篇论文是“Chain-of-note：增强检索增强语言模型的鲁棒性”，他们提到了检索增强语言模型（RALM）。  那么这个RAG和RALMs是相同还是不同呢？据我了解，RALM 是 RAG 的一小部分，因为它将语言模型与从大量文档中查找信息的系统结合在一起。我是对的吗？ 此外，从 Chain-of-note 论文中，我读到了另一篇论文“Interleaving Retrieval with Chain”知识密集型多步骤问题的深度推理”感觉虽然看起来一样，但实际上它解决了与 Chain-of-note 不同的问题。  ​   由   提交 /u/ma-d-ghost   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avikjn/d_confused_about_different_terms_in/</guid>
      <pubDate>Tue, 20 Feb 2024 14:12:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为本科生选择一个 ML 实验室：大型、成熟的实验室还是小型、专注的实验室？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avie4g/d_picking_an_ml_lab_as_an_undergraduate_big/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avie4g/d_picking_an_ml_lab_as_an_undergraduate_big/</guid>
      <pubDate>Tue, 20 Feb 2024 14:04:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 其他流行/宣布的扩散变压器产品，如 Sora？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avht7j/d_other_popularannounced_diffusion_transformer/</link>
      <description><![CDATA[虽然 Sora 引起了不小的轰动，但还有哪些其他已知、流行/宣布的产品使用类似的模型架构？ &lt; !-- SC_ON --&gt;  由   提交 /u/CodeComedianCat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avht7j/d_other_popularannounced_diffusion_transformer/</guid>
      <pubDate>Tue, 20 Feb 2024 13:36:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文解释：V-JEPA：重新审视特征预测以从视频中学习视觉表示（视频分析）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aveqx4/d_paper_explained_vjepa_revisiting_feature/</link>
      <description><![CDATA[https://youtu.be/7UkJPwz_N_0 V-JEPA 是一种仅使用潜在表示预测作为目标函数来进行视频数据无监督表示学习的方法。 概要： 0:00 - 简介&lt; /p&gt; 1:45 - 预测特征原理 8:00 - （广告）权重和权重结构化 LLM 输出偏差课程 9:45 - 原始 JEPA 架构 27:30 - V-JEPA 概念 33:15 - V-JEPA架构 44:30 - 实验结果 46:30 - 通过解码进行定性评估 ​ 博客：&lt; a href=&quot;https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/&quot;&gt;https://ai.meta.com/ blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/ 论文：https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning- Visual-representations-from-video/ ​ 摘要： 本文探讨了特征预测作为一个独立的目标用于从视频进行无监督学习，并引入了 V-JEPA，这是一组仅使用特征预测目标进行训练的视觉模型集合，不使用预训练的图像编码器、文本、负例、重建或其他监督来源。这些模型使用从公共数据集中收集的 200 万个视频进行训练，并针对下游图像和视频任务进行评估。我们的结果表明，通过预测视频特征进行学习可以产生多功能的视觉表示，在基于运动和外观的任务上表现良好，而无需调整模型的参数；例如，使用我们最大的模型、仅在视频上训练的 ViT-H/16 冻结骨干网，在 Kinetics-400 上获得 81.9%，在 Something-Something-v2 上获得 72.2%，在 ImageNet1K 上获得 77.9%。 &lt; p&gt;​ 作者：Adrien Bardes Quentin Garrido Xinlei Chen Michael Rabbat Yann LeCun Mido Assran Nicolas Ballas Jean Ponce    ;由   提交/u/ykilcher  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aveqx4/d_paper_explained_vjepa_revisiting_feature/</guid>
      <pubDate>Tue, 20 Feb 2024 10:42:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数学家会在未来的机器学习研究中占据上风吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1av5gwy/d_will_mathematicians_have_the_upper_hand_in/</link>
      <description><![CDATA[似乎在各个角落我都看到了关于做研究的类似情绪。人们尝试各种事物的组合来获得渐进式的改进。我认为下一步的飞跃需要大量的理论知识来指导方向。   由   提交 /u/planetofthemushrooms   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1av5gwy/d_will_mathematicians_have_the_upper_hand_in/</guid>
      <pubDate>Tue, 20 Feb 2024 01:46:38 GMT</pubDate>
    </item>
    <item>
      <title>对于技术主管来说，您的实际工作是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auyt1n/for_anyone_whos_a_tech_lead_what_is_your_actual/</link>
      <description><![CDATA[在担任主要 DS 后，我最近被任命为一个大项目的技术主管，并发现自己在思考我的角色实际上是什么/应该是什么..你每天都做什么？与参加会议和计划里程碑等相比，您还有多少编码和技术工作？    由   提交 /u/natrules   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auyt1n/for_anyone_whos_a_tech_lead_what_is_your_actual/</guid>
      <pubDate>Mon, 19 Feb 2024 21:11:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在 10M 大海捞针中寻找针：循环记忆找到法学硕士错过的东西 - AIRI，莫斯科，俄罗斯 2024 - RMT 137M 具有循环记忆的微调 GPT-2 能够在 10M 中找到 85% 的隐藏针草垛！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1autvwq/r_in_search_of_needles_in_a_10m_haystack/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.10790  摘要：  本文解决了使用生成变压器模型处理长文档的挑战。为了评估不同的方法，我们引入了BABILong，一个新的基准旨在评估模型在广泛文本中提取和处理分布式事实的能力。我们的评估（包括 GPT-4 和 RAG 基准）表明，常见方法仅对最多 10^4 元素的序列有效。相比之下，通过循环内存增强对 GPT-2 进行微调使其能够处理涉及多达  10^7 个元素的任务。这一成就标志着一个重大飞跃，因为它是迄今为止任何开放神经网络模型处理的最长输入，展示了长序列处理能力的显着改进。   https://preview.redd.it /0o4207a70ljc1.jpg?width=577&amp;format=pjpg&amp;auto=webp&amp;s=2bfac07872020de222b4bf99f837aa398b778afc https://preview.redd.it/2ff82da70ljc1.jpg?width=1835&amp;format=pjpg&amp;auto=webp&amp;s=acc1409f5b9bcd07f9 b5ff8a3890cc1b15b5c8ed  https://preview.redd .it/ld69p7a70ljc1.jpg?width=1816&amp;format=pjpg&amp;auto=webp&amp;s=fdd72c1a87742f525fa352723bcd1a0f4f000638 https://preview.redd.it/7vn4gba70ljc1.jpg?width=900&amp;format=pjpg&amp;auto=webp&amp;s=c8d08bb85a6 699e5b451e01bf615379db1fcbdca   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1autvwq/r_in_search_of_needles_in_a_10m_haystack/</guid>
      <pubDate>Mon, 19 Feb 2024 18:02:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>