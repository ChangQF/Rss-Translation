<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æœºå™¨å­¦ä¹ </title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>åˆå­¦è€… -> /r/mlquestionsï¼ŒAGI -> /r/singularityï¼ŒèŒä¸šå»ºè®® -> /r/cscareerquestionsï¼Œæ•°æ®é›† -> r/datasets</description>
    <lastBuildDate>Tue, 01 Oct 2024 12:33:41 GMT</lastBuildDate>
    <item>
      <title>[D] å…³äºæ¨èå¼•æ“ç¤¾ä¼šå½±å“çš„æ€è€ƒ</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fthnre/d_thoughts_on_societal_impacts_of_recommender/</link>
      <description><![CDATA[å—¨ï¼æ¨èå¼•æ“æ˜¯æˆ‘ä»¬ç”Ÿæ´»ä¸­æ— å¤„ä¸åœ¨çš„ä¸€éƒ¨åˆ†ã€‚å®ƒä»¬ä¼šæ¨èæˆ‘ä»¬åº”è¯¥ä¹°ä»€ä¹ˆã€å¬ä»€ä¹ˆã€çº¦ä¼šå¯¹è±¡å’Œåƒä»€ä¹ˆã€‚æˆ‘ä»¬å€¾å‘äºè®¤ä¸ºå®ƒä»¬æœ€å…³å¿ƒæˆ‘ä»¬çš„åˆ©ç›Šâ€”â€”å› ä¸ºå®ƒä»¬çŸ¥é“æˆ‘ä»¬å–œæ¬¢ä»€ä¹ˆéŸ³ä¹ï¼Œæ‰€ä»¥å®ƒä»¬æ€»æ˜¯ä¼šæ ¹æ®æˆ‘ä»¬çš„å…´è¶£è€Œä¸æ˜¯æˆ‘ä»¬çš„ä¸šåŠ¡éœ€æ±‚ï¼ˆä¾‹å¦‚æƒ³è¦é”€å”®æ›´å¤šç‰¹å®šå“ç§çš„äº§å“ï¼‰å‘æˆ‘ä»¬æ¨èä¸€äº›ä¸œè¥¿ã€‚ æˆ‘æœ‰å…´è¶£äº†è§£æ›´å¤šå…³äºæ¨èå¼•æ“å¦‚ä½•å½±å“ä½ ç”Ÿæ´»çš„ä¸€äº›å¥‡æ€ªæ–¹å¼ã€‚æˆ–è€…ç”šè‡³æ˜¯ä½ æ˜¯å¦‚ä½•ç ´è§£æ¨èå¼•æ“â€‹â€‹çš„â€”â€”ä½ æ˜¯å¦æ•…æ„å¼€è®¾äº†æŸç§ç±»å‹çš„æ–°è´¦æˆ·ï¼Œè¯•å›¾å¼„æ¸…æ¥šæŸäº›å†³å®šæ˜¯å¦‚ä½•åšå‡ºçš„â€”â€”ä¾‹å¦‚åœ¨ Tinder/Bumble ä¸Šä»¥æŸç§æ–¹å¼æ»‘åŠ¨ã€‚ å¾ˆæƒ³å¬å¬ä½ çš„æƒ³æ³•ï¼Œå› ä¸ºæˆ‘è§‰å¾—å®ƒä»¬å¾ˆæœ‰è¶£ï¼    æäº¤äºº    /u/No-Group-5497   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fthnre/d_thoughts_on_societal_impacts_of_recommender/</guid>
      <pubDate>Tue, 01 Oct 2024 06:34:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] å¯¹åŸºäº Gemma çš„æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼ˆLoRAï¼‰å¹¶è·å¾—è¾ƒé«˜çš„è®­ç»ƒå’ŒéªŒè¯æŸå¤±å€¼</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftgxx3/p_finetuning_lora_a_gemmabased_model_and_getting/</link>
      <description><![CDATA[æ‚¨å¥½ï¼æˆ‘æ˜¯ä¸€åè®¡ç®—æœºç§‘å­¦ä¸“ä¸šçš„å­¦ç”Ÿï¼Œâ€‹â€‹æ­£åœ¨å°è¯•å¾®è°ƒï¼ˆLoRAï¼‰åŸºäº Gemma 7b çš„æ¨¡å‹ä»¥å®Œæˆæˆ‘çš„è®ºæ–‡ã€‚ä½†æ˜¯ï¼Œæˆ‘ä¸æ–­è·å¾—è¾ƒé«˜çš„è®­ç»ƒå’ŒéªŒè¯æŸå¤±å€¼ã€‚æˆ‘å°è¯•äº†ä¸åŒçš„å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°ã€lora ç­‰çº§ã€lora alpha å’Œ lora dropoutï¼Œä½†æŸå¤±å€¼ä»ç„¶å¾ˆé«˜ã€‚ æˆ‘ä¹Ÿå°è¯•ä½¿ç”¨ä¸åŒçš„æ•°æ®æ•´ç†å™¨ã€‚ä½¿ç”¨ DataCollatâ€‹â€‹orForLanguageModelingï¼Œæˆ‘çš„æŸå¤±å€¼ä½è‡³ ~4.XXã€‚ä½¿ç”¨ DataCollatâ€‹â€‹orForTokenClassificationï¼Œå®ƒå¼€å§‹æ—¶éå¸¸é«˜ï¼Œå¤§çº¦ä¸º 18-20ï¼Œæœ‰æ—¶æ›´é«˜ã€‚DataCollatâ€‹â€‹orWithPadding å¯¹æˆ‘æ¥è¯´ä¸èµ·ä½œç”¨ï¼Œå®ƒç»™äº†æˆ‘è¿™ä¸ªé”™è¯¯ï¼š ValueErrorï¼šé¢„æœŸè¾“å…¥ batch_size (304) ä¸ç›®æ ‡ batch_size (64) åŒ¹é…ã€‚  è¿™æ˜¯æˆ‘çš„è®­ç»ƒå¸ˆ  training_args = TrainingArguments( output_dir=&quot;./training&quot;, remove_unused_columns=True, per_device_train_batch_size=params[&#39;batch_size&#39;], gradient_checkpointing=True, gradient_accumulation_steps=4, max_steps=500, learning_rate=params[&#39;learning_rate&#39;], logsing_steps=10, fp16=True, optim=&quot;adamw_hf&quot;, save_strategy=&quot;steps&quot;, save_steps=50, evaluation_strategy=&quot;steps&quot;, eval_steps=5, do_eval=True, label_names = [&quot;input_ids&quot;, &quot;labels&quot;, &quot;attention_mask&quot;], report_to = &quot;none&quot;, ) trainer = Trainer( model=model, train_dataset=tokenized_dataset[&#39;train&#39;], eval_dataset=tokenized_dataset[&#39;validation&#39;], tokenizer=tokenizer, data_collatâ€‹â€‹or=data_collatâ€‹â€‹or, args=training_args, )  æˆ‘çš„æ•°æ®é›†å¦‚ä¸‹æ‰€ç¤º  text,absent,dengue,health,mosquito,sick ä¸æ˜¯ç”Ÿç—…çš„å¥½æ—¶æœºã€‚,0,0,1,0,1 NUNG NA DENGUE AKO [LINK],0,1,1,0,1 æ˜¯å‘çƒ§è¿˜æ˜¯å¤©æ°”åŸå› ,0,0,1,0,1 ä¸Šå¸å¸®åŠ©ç—…äººï¼Ÿ,0,0,1,0,1 &quot;äº§å¦‡è§‚å¯Ÿã€‚ [HASHTAG] [HASHTAG] [HASHTAG] @ è¥¿åˆ©æ›¼å¤§å­¦åŒ»å­¦ä¸­å¿ƒåŸºé‡‘ä¼šï¼ŒInc . [LINK]&quot;,0,0,1,0,0 ? @ St .ç‰¹è•¾èåŒ»é™¢ [LINK],0,0,1,0,0  Tokenized: {&#39;text&#39;: &#39;ç°åœ¨ä¸æ˜¯ç”Ÿç—…çš„å¥½æ—¶æœº&#39;, &#39;input_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1665, 476, 1426, 1069, 577, 947, 11666], &#39;attention_mask&#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], &#39;labels&#39;: [0, 0, 1, 0, 1]}  æ ¼å¼åŒ–ç¨‹åºï¼š import re from datasets import DatasetDict max_length = 20 def clean_text(text): # åˆ é™¤ URL text = re.sub(r&quot;\[LINK\]&quot;, &quot;&lt;URL&gt;&quot;, text) # åˆ é™¤æ ‡ç­¾å’ŒæåŠ text = re.sub(r&quot;@[A-Za-z0-9_]+&quot;, &quot;\[MENTION\]&quot;, text) text = re.sub(r&quot;#\w+&quot;, &quot;\[HASHTAG\]&quot;, text) # å°†æ–‡æœ¬å°å†™ text = text.lower() # åˆ é™¤ç‰¹æ®Šå­—ç¬¦å’Œå¤šä½™ç©ºæ ¼ text = re.sub(r&quot;[^a-zA-Z0-9\s&lt;&gt;\&#39;]&quot;, &quot;&quot;, text) text = re.sub(r&quot;\s+&quot;, &quot; &quot;, text).strip() return text # å¯¹æ–‡æœ¬åˆ—åº”ç”¨æ¸…ç† dataset[&#39;train&#39;] = dataset[&#39;train&#39;].map(lambda x: {&#39;text&#39;: clean_text(x[&#39;text&#39;])}) def tokenize_function(examples): # å¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®° tokenized_text = tokenizer( examples[&#39;text&#39;], padding=&quot;max_length&quot;, truncation=True, max_length=max_length ) # åˆ›å»ºæ ‡ç­¾åˆ—è¡¨åˆ—è¡¨ labels = [ [examples[&#39;absent&#39;][i], examples[&#39;dengue&#39;][i], examples[&#39;health&#39;][i], examples[&#39;mosquito&#39;][i], examples[&#39;sick&#39;][i]] for i in range(len(examples[&#39;text&#39;])) ] tokenized_text[&#39;labels&#39;] = labels return tokenized_text # å¯¹æ•°æ®é›†åº”ç”¨æ ‡è®°åŒ– tokenized_dataset = dataset.map(tokenize_function, batched=True) # åˆ é™¤åŸæœ‰çš„æ ‡ç­¾åˆ— tokenized_dataset = tokenized_dataset.remove_columns([&#39;absent&#39;, &#39;dengue&#39;, &#39;health&#39;, &#39;mosquito&#39;, &#39;sick&#39;]) # æ‰“å°å‡ºä¸€ä¸ªæ ‡è®°åŒ–çš„ç¤ºä¾‹ print(tokenized_dataset[&#39;train&#39;][0])     submitted by    /u/jobiskits   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftgxx3/p_finetuning_lora_a_gemmabased_model_and_getting/</guid>
      <pubDate>Tue, 01 Oct 2024 05:44:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] å¯æ‰©å±•çš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œä¸“æ³¨äºè®­ç»ƒåŸºç¡€è®¾æ–½</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftg3ly/d_scalable_ml_pipelines_focusing_training_infra/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼Œæˆ‘ç›®å‰æ­£åœ¨å°è¯•æ›´å¤šåœ°äº†è§£ ML ç³»ç»Ÿè®¾è®¡ï¼Œé‡ç‚¹æ˜¯åŸºç¡€æ¨¡å‹çš„è®­ç»ƒåŸºç¡€è®¾æ–½ï¼Œæˆ‘å‘ç°ç ”ç©¶è¿™ä¸ªä¸»é¢˜å¾ˆå›°éš¾ã€‚ æœ‰æ²¡æœ‰ä»€ä¹ˆå¥½çš„èµ„æºæœ‰äººç†Ÿæ‚‰å¯èƒ½ä¼šæœ‰å¸®åŠ©ï¼Ÿ    æäº¤äºº    /u/adi214   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftg3ly/d_scalable_ml_pipelines_focusing_training_infra/</guid>
      <pubDate>Tue, 01 Oct 2024 04:51:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] è€ƒå¤å­¦æˆ–å¤ä»£å†å²ä¸­çš„æœºå™¨å­¦ä¹ æ½œåŠ›</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdw6n/d_machine_learning_potential_in_archeology_or/</link>
      <description><![CDATA[ç›®å‰åœ¨ T10 æ”»è¯»æ•°å­¦è®¡ç®—æœºç§‘å­¦ä¸“ä¸šçš„æœ¬ç§‘ç”Ÿï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªæ„šè ¢çš„é—®é¢˜ï¼Œä½†æœ‰æ²¡æœ‰äººæƒ³è¿‡æˆ–å¯¹åœ¨åŸƒåŠå­¦æˆ–è€ƒå¤å­¦ç­‰å†å²é¢†åŸŸä½¿ç”¨äººå·¥æ™ºèƒ½æœ‰è¿‡ä»»ä½•æƒ³æ³•ï¼Ÿç ´è¯‘è±¡å½¢æ–‡å­—ï¼Œä½¿ç”¨æ·±åº¦å­¦ä¹ å¯»æ‰¾é™µå¢“æˆ–æ–‡ç‰©çš„ä½ç½®ï¼Œç»„è£…ç ´ç¢æˆ–æ¯åçš„å¤ä»£æ–‡ç‰©æˆ–é™¶å™¨å’Œç»˜ç”»ç­‰ç‰©å“ã€‚åªæ˜¯æƒ³çŸ¥é“æ˜¯å¦æœ‰äººå¯¹è¿™ä¸ªä¸»é¢˜æœ‰ä»»ä½•æƒ³æ³•ï¼Œä»¥åŠå®ƒæ˜¯å¦å…·æœ‰ç°å®æ½œåŠ›ï¼ˆæˆ–æ²¡æœ‰ï¼‰ã€‚æˆ‘è®¤ä¸ºæœ€å¤§çš„å›°éš¾æ˜¯ç¼ºä¹å¥½çš„æ•°æ®ã€‚    æäº¤äºº    /u/hmbhack   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdw6n/d_machine_learning_potential_in_archeology_or/</guid>
      <pubDate>Tue, 01 Oct 2024 02:47:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] æ¯æœˆè°åœ¨æ‹›è˜ä»¥åŠè°æƒ³è¢«æ‹›è˜ï¼Ÿ</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[å¯¹äºèŒä½å‘å¸ƒï¼Œè¯·ä½¿ç”¨æ­¤æ¨¡æ¿  æ‹›è˜ï¼š[åœ°ç‚¹]ï¼Œè–ªèµ„ï¼š[]ï¼Œ[è¿œç¨‹ | æ¬è¿]ï¼Œ[å…¨èŒ | åˆåŒ | å…¼èŒ]å’Œ[ç®€è¦æ¦‚è¿°ï¼Œæ‚¨åœ¨å¯»æ‰¾ä»€ä¹ˆ]  å¯¹äºé‚£äº›æ­£åœ¨æ‰¾å·¥ä½œçš„äººï¼Œè¯·ä½¿ç”¨æ­¤æ¨¡æ¿  å¸Œæœ›è¢«é›‡ç”¨ï¼š[åœ°ç‚¹]ï¼Œè–ªèµ„æœŸæœ›ï¼š[]ï¼Œ[è¿œç¨‹ | æ¬è¿]ï¼Œ[å…¨èŒ | åˆåŒ |å…¼èŒ] ç®€å†ï¼š[ç®€å†é“¾æ¥] å’Œ [ç®€è¦æ¦‚è¿°ï¼Œæ‚¨åœ¨å¯»æ‰¾ä»€ä¹ˆ]  â€‹ è¯·è®°ä½ï¼Œè¿™ä¸ªç¤¾åŒºé¢å‘æœ‰ç»éªŒçš„äººã€‚    æäº¤äºº    /u/AutoModerator   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] äººä»¬å¦‚ä½•æ„å»ºå¯¹è¯å¼æ£€ç´¢å¢å¼ºç”Ÿæˆåº”ç”¨ç¨‹åº</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdby7/d_how_are_folks_building_conversational_retrieval/</link>
      <description><![CDATA[æˆ‘å·²é˜…è¯»äº†å„ç§èµ„æºï¼Œä¾‹å¦‚ï¼š - https://vectorize.io/how-i-finally-got-agentic-rag-to-work-right/ - https://python.langchain.com/docs/tutorials/qa_chat_history/ - https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/ - https://docs.llamaindex.ai/en/stable/module_guides/deploying/chat_engines/ - https://huggingface.co/datasets/nvidia/ChatRAG-Bench  ä½†è¿™äº›æ„Ÿè§‰è¿‡äºç®€å•ï¼Œå› ä¸ºå®ƒä»¬æ²¡æœ‰è§£å†³ä»¥ä¸‹å¤æ‚æ€§ï¼š 1ï¼‰ä½•æ—¶æ£€ç´¢ä¸ç«‹å³å“åº”ä»¥å‡å°‘å»¶è¿Ÿ 2ï¼‰ä¾é å…ˆå‰åœ¨å¯¹è¯ä¸­æ£€ç´¢åˆ°çš„ç°æœ‰ä¸Šä¸‹æ–‡ï¼Œè€Œä¸æ˜¯åœ¨å½“å‰å›åˆå†æ¬¡æ£€ç´¢ 3ï¼‰åœ¨æ£€ç´¢åˆ°çš„ä¿¡æ¯å’Œè¿‡å»çš„å¯¹è¯å†å²ä¹‹é—´åˆ’åˆ† LLM ä¸Šä¸‹æ–‡ã€‚ æˆ‘ç›¸ä¿¡ä¸€äº›å›¢é˜Ÿå·²ç»æœ‰äº†å¾ˆå¥½çš„ç³»ç»Ÿï¼Œå°†ä¸èƒœæ„Ÿæ¿€æŒ‡é’ˆï¼    ç”±    /u/iidealized æäº¤   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdby7/d_how_are_folks_building_conversational_retrieval/</guid>
      <pubDate>Tue, 01 Oct 2024 02:17:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] SynthPAIï¼šç”¨äºä¸ªäººå±æ€§æ¨æ–­çš„åˆæˆæ•°æ®é›†</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftb4hk/r_synthpai_a_synthetic_dataset_for_personal/</link>
      <description><![CDATA[[è¢« NeurIPS&#39;24 D&amp;B æ¥å—] TL;DRï¼šæˆ‘ä»¬ä¸º Reddit æ„å»ºäº†ä¸€ä¸ª LLM ä»£ç†æ¨¡æ‹Ÿæ¡†æ¶ï¼Œä»¥ç”Ÿæˆåˆæˆæ•°æ®æ¥æ¨è¿›åŸºäºæ¨ç†çš„éšç§ç ”ç©¶ã€‚ é¢„å°æœ¬ï¼šhttps://arxiv.org/abs/2406.07217 Githubï¼šhttps://github.com/eth-sri/SynthPAI åœ¨æˆ‘ä»¬çš„æœ€æ–°ç ”ç©¶è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº† SynthPAI - ä¸€ä¸ªåˆæˆæ•°æ®é›†ï¼Œå®ƒä¸ºè¯„ä¼°åŸºäº LLM çš„ä¸ªäººå±æ€§æ¨ç†çš„æ–°åŸºå‡†å¥ å®šäº†åŸºç¡€ã€‚æˆ‘ä»¬ä¸º Reddit æ„å»ºäº†ä¸€ä¸ª LLM ä»£ç†æ¨¡æ‹Ÿæ¡†æ¶ï¼Œä»¥ç”Ÿæˆåˆæˆæ•°æ®æ¥æ¨è¿›åŸºäºæ¨ç†çš„éšç§ç ”ç©¶ã€‚åˆ©ç”¨è¯¥æ¡†æ¶ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ª PAIï¼ˆç§æœ‰å±æ€§æ¨æ–­ï¼‰æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å« 7800 å¤šæ¡è¯„è®ºå’Œ 300 ä¸ªåˆæˆé…ç½®æ–‡ä»¶ä»¥åŠç»è¿‡äººå·¥éªŒè¯çš„å±æ€§æ ‡ç­¾ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œæˆ‘ä»¬çš„è¯„è®ºè¡¨ç°å‡ºé«˜ä¿çœŸåº¦ï¼ˆäººç±»æ— æ³•å°†å®ƒä»¬ä¸çœŸå®è¯„è®ºåŒºåˆ†å¼€æ¥ï¼‰å’Œå¯¹ PAI ç ”ç©¶çš„ä¿¡æ¯æ€§ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨å„ç§å®éªŒä¸­å¾—å‡ºä¸çœŸå®ä¸–ç•Œæ•°æ®ç›¸åŒçš„å®šæ€§ç»“è®ºã€‚    æäº¤äºº    /u/equin_x   [link] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftb4hk/r_synthpai_a_synthetic_dataset_for_personal/</guid>
      <pubDate>Tue, 01 Oct 2024 00:27:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch åŸç”Ÿæ¶æ„ä¼˜åŒ–ï¼štorchao</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftaw4e/d_pytorch_native_architecture_optimization_torchao/</link>
      <description><![CDATA[https://pytorch.org/blog/pytorch-native-architecture-optimization/    ç”±   æäº¤  /u/20231027   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftaw4e/d_pytorch_native_architecture_optimization_torchao/</guid>
      <pubDate>Tue, 01 Oct 2024 00:16:04 GMT</pubDate>
    </item>
    <item>
      <title>[é¡¹ç›®] ä¸ºAIæ¨¡å‹é‡èº«å®šåˆ¶çš„æ— æŸå‹ç¼©åº“ - å°†Llama3.2çš„ä¼ è¾“æ—¶é—´ç¼©çŸ­33%</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ft2v10/project_a_lossless_compression_library_taliored/</link>
      <description><![CDATA[å¦‚æœæ‚¨å¸Œæœ›å‡å°‘ Hugging Face çš„ä¸‹è½½æ—¶é—´å¹¶å¸®åŠ©å‡å°‘å…¶æœåŠ¡å™¨è´Ÿè½½â€”ï¼ˆClem Delangue æåˆ° HF æ¯å¤©å¤„ç†é«˜è¾¾ 6PB çš„æ•°æ®ï¼ï¼‰ â€”&gt;æ‚¨å¯èƒ½ä¼šå‘ç° ZipNN å¾ˆæœ‰ç”¨ã€‚ ZipNN æ˜¯ä¸€ä¸ªå¼€æº Python åº“ï¼Œå¯åœ¨ MIT è®¸å¯ä¸‹ä½¿ç”¨ï¼Œä¸“é—¨ç”¨äºå‹ç¼© AI æ¨¡å‹è€Œä¸ä¼šæŸå¤±å‡†ç¡®æ€§ï¼ˆç±»ä¼¼äº Zipï¼Œä½†é’ˆå¯¹ç¥ç»ç½‘ç»œè¿›è¡Œäº†å®šåˆ¶ï¼‰ã€‚ å®ƒä½¿ç”¨æ— æŸå‹ç¼©å°†æ¨¡å‹å¤§å°å‡å°‘ 33%ï¼ŒèŠ‚çœäº†ä¸‰åˆ†ä¹‹ä¸€çš„ä¸‹è½½æ—¶é—´ã€‚ ZipNN æœ‰ä¸€ä¸ª HF æ’ä»¶ï¼Œå› æ­¤æ‚¨åªéœ€æ·»åŠ ä¸€è¡Œä»£ç å³å¯ã€‚ åœ¨è¿™é‡ŒæŸ¥çœ‹ï¼š https://github.com/zipnn/zipnn Hugging Face ä¸Šå·²ç»æœ‰å‡ ä¸ªå¸¦æœ‰ ZipNN çš„å‹ç¼©æ¨¡å‹ï¼Œå¦‚æœæ‚¨æœ‰å…´è¶£ï¼Œå¯ä»¥ç›´æ¥ä¸Šä¼ æ›´å¤šã€‚ æœ€æ–°çš„æ˜¯ Llama-3.2-11B-Vision-Instruct-ZipNN-Compressed çœ‹çœ‹è¿™ä¸ª Kaggle ç¬”è®°æœ¬ï¼š å¯¹äºæ‚¨å¯ä»¥åœ¨æ­¤ Kaggle ç¬”è®°æœ¬ä¸­æ‰¾åˆ° Llama-3.2 çš„å®é™…ç¤ºä¾‹ï¼š https://www.kaggle.com/code/royleibovitz/huggingface-llama-3-2-example ZipNN repo ä¸­æä¾›äº†æ›´å¤šç¤ºä¾‹ï¼š https://github.com/zipnn/zipnn/tree/main/examples    æäº¤äºº    /u/Candid_Raccoon2102   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ft2v10/project_a_lossless_compression_library_taliored/</guid>
      <pubDate>Mon, 30 Sep 2024 18:32:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] é‡åŒ–æ¨¡å‹çš„æœ€ä½³æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsz97a/d_whats_the_best_way_to_quantise_a_model/</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ SentenceTransformers åº“ä¸­çš„ä¸€ä¸ª 80MB æ¨¡å‹ã€‚å®ƒå¾ˆæ£’ï¼Œä½†æˆ‘éœ€è¦å®ƒåœ¨æˆ‘çš„ç”¨ä¾‹ä¸­æ›´å¿«ä¸€äº›ã€‚ä½œä¸ºå‚è€ƒï¼ŒåŸºç¡€æ¨¡å‹æ¯ç§’äº§ç”Ÿ 2000 ä¸ªåµŒå…¥ã€‚ ç¼–è¾‘ï¼šæˆ‘ä½¿ç”¨â€œæ€§èƒ½â€æ¥è¡¨ç¤ºæ¯ç§’åµŒå…¥çš„æ•°é‡ã€‚ æˆ‘å°è¯•ä½¿ç”¨ PyTorch å’Œ ONNX é‡åŒ–æ¨¡å‹ã€‚ PyTorch é‡åŒ–@8 ä½ ä¸ºäº†åœ¨ PyTorch ä¸­è¿›è¡Œé‡åŒ–ï¼Œæˆ‘ä½¿ç”¨äº†ä»¥ä¸‹ä»£ç ï¼š import torch from sentence_transformers import SentenceTransformer torch.backends.quantized.engine = &#39;qnnpack&#39; model = SentenceTransformer(&quot;all-MiniLM-L6-v2&quot;, device=&quot;cpu&quot;) quantized_model = torch.quantization.quantize_dynamic( model, {torch.nn.Linear}, # è¦é‡åŒ–çš„å±‚ dtype=torch.qint8 # é‡åŒ–æ•°æ®ç±»å‹ )  ä»¤æˆ‘æƒŠè®¶çš„æ˜¯ï¼Œè¿™ä½¿æ¨¡å‹çš„æ€§èƒ½å‡åŠï¼é‡åŒ–æ¨¡å‹æ¯ç§’å¯ç®¡ç† 1000 ä¸ªåµŒå…¥ã€‚ ONNX é‡åŒ–@8 ä½ ONNX é‡åŒ–æ›´å¤æ‚ï¼Œæ‰€ä»¥æˆ‘ä¸ä¼šå‘å¸ƒæ‰€æœ‰ä»£ç ï¼Œä½†æœ€ç»ˆç»“æœæ˜¯æ¨¡å‹æ€§èƒ½çš„ä¸‰åˆ†ä¹‹ä¸€ã€‚æ¯ç§’ä»…ç®¡ç† 700 ä¸ªåµŒå…¥ã€‚ ä¸ºä»€ä¹ˆä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼Ÿ æˆ‘ç ”ç©¶è¿‡è¿™ä¸ªé—®é¢˜ï¼Œå¯èƒ½æ˜¯å› ä¸ºæˆ‘çš„ Apple Silicon èŠ¯ç‰‡ï¼ˆM3 Proï¼‰æ²¡æœ‰ 8 ä½æ•°å­—çš„åŠ é€Ÿã€‚æˆ‘è§‰å¾—è¿™å¾ˆéš¾ç›¸ä¿¡ï¼Œå› ä¸º Ollama é‡åŒ–ä¸º 4 ä½å¹¶ä¸”åœ¨æˆ‘çš„è®¡ç®—æœºä¸Šè¿è¡Œé€Ÿåº¦éå¸¸å¿«ã€‚è¿™ç•™ä¸‹äº†æ“ä½œå‘˜é”™è¯¯ã€‚ æˆ‘åšé”™äº†ä»€ä¹ˆï¼Ÿæœ‰æ²¡æœ‰ä¸€ç§ä¸‡æ— ä¸€å¤±çš„æ–¹æ³•æ¥é‡åŒ–æˆ‘æ‰€ç¼ºå°‘çš„æ¨¡å‹ï¼Ÿ    æäº¤äºº    /u/FPGA_Superstar   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsz97a/d_whats_the_best_way_to_quantise_a_model/</guid>
      <pubDate>Mon, 30 Sep 2024 16:05:57 GMT</pubDate>
    </item>
    <item>
      <title>[è®¨è®º] æœ‰å“ªäº›å…³äºæœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ æˆ– NLP çš„åšå®¢ï¼Ÿ</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsv7js/discussion_what_are_some_the_informative_blogs_on/</link>
      <description><![CDATA[æ‚¨å¯ä»¥åˆ†äº«å®ƒä»¬å—    ç”±   æäº¤  /u/Internal_Complaint64   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsv7js/discussion_what_are_some_the_informative_blogs_on/</guid>
      <pubDate>Mon, 30 Sep 2024 13:12:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] æˆ‘è¯•å›¾é€šè¿‡åˆ†ææ•°ç™¾æ¡ Reddit å¸–å­æ¥ç»˜åˆ¶äººå·¥æ™ºèƒ½ä¸­æœ€å¸¸è§å’Œæœ€æµè¡Œçš„æŒ‘æˆ˜ã€‚</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fstn9m/p_i_tried_to_map_the_most_recurrent_and_popular/</link>
      <description><![CDATA[å—¨ï¼ŒAI çˆ±å¥½è€…å’Œå¼€å‘è€…ä»¬ï¼æˆ‘ä¸€ç›´åœ¨å¼€å±•ä¸€ä¸ªé¡¹ç›®ï¼Œé€šè¿‡æŸ¥çœ‹ Reddit ä¸“ç”¨å­ç‰ˆå—ä¸Šçš„å¸–å­æ¥åˆ†æå’Œå¯è§†åŒ– AI å¼€å‘ä¸­æœ€å¸¸è§çš„æŠ€æœ¯æŒ‘æˆ˜ã€‚ é¡¹ç›®ç›®æ ‡ è¯¥é¡¹ç›®çš„ä¸»è¦ç›®æ ‡æ˜¯è¯†åˆ«å’Œè·Ÿè¸ªä¸ AI å¼€å‘ç›¸å…³çš„æœ€æ™®éå’Œæœ€æµè¡Œçš„æŠ€æœ¯æŒ‘æˆ˜ã€å®æ–½é—®é¢˜å’Œæ¦‚å¿µéšœç¢ã€‚é€šè¿‡è¿™æ ·åšï¼Œæˆ‘ä»¬å¯ä»¥ï¼š  å¸®åŠ©å¼€å‘äººå‘˜ä¸“æ³¨äºæœ€ç›¸å…³çš„æŠ€èƒ½å’ŒçŸ¥è¯†é¢†åŸŸ æŒ‡å¯¼æ•™è‚²å†…å®¹åˆ›å»ºè€…è§£å†³æœ€ç´§è¿«çš„é—®é¢˜ ä¸ºç ”ç©¶äººå‘˜æä¾›æœ‰å…³éœ€è¦æ›´å¤šå…³æ³¨æˆ–è§£å†³æ–¹æ¡ˆçš„é¢†åŸŸçš„è§è§£  å·¥ä½œåŸç†  æ•°æ®æ”¶é›†ï¼šæˆ‘ä»ä»¥ä¸‹æ¯ä¸ªä¸ AI ç›¸å…³çš„ subreddits ä¸­è·å–äº†æœ€çƒ­é—¨çš„ 200 ä¸ªå¸–å­ï¼šr/learnmachinelearningã€r/ArtificialIntelligenceã€r/MachineLearningã€r/artificialã€‚ ç­›é€‰ï¼šä½¿ç”¨ LLM ç­›é€‰å¸–å­ï¼Œä»¥ç¡®ä¿å®ƒä»¬æ¶‰åŠç‰¹å®šçš„æŠ€æœ¯æŒ‘æˆ˜ï¼Œè€Œä¸æ˜¯ä¸€èˆ¬è®¨è®ºæˆ–æ–°é—»ã€‚ æ€»ç»“å’Œæ ‡è®°ï¼šæ¯ä¸ªç›¸å…³å¸–å­éƒ½ç»è¿‡æ€»ç»“å’Œæ ‡è®°æœ€å¤šå¯ä»é¢„å®šä¹‰çš„ 50 ä¸ªæŠ€æœ¯é¢†åŸŸåˆ—è¡¨ä¸­é€‰æ‹©ä¸‰ä¸ªç±»åˆ«ï¼ˆä¾‹å¦‚ï¼ŒLLM-ARCH ä»£è¡¨å¤§å‹è¯­è¨€æ¨¡å‹æ¶æ„ï¼ŒCV-OBJ ä»£è¡¨è®¡ç®—æœºè§†è§‰å¯¹è±¡æ£€æµ‹ï¼‰ã€‚ åˆ†æï¼šç³»ç»Ÿåˆ†ææ ‡ç­¾çš„é¢‘ç‡ï¼Œä»¥åŠæ¯ä¸ªç±»åˆ«ç›¸å…³çš„èµæˆå’Œè¯„è®ºã€‚ å¯è§†åŒ–ï¼šç»“æœé€šè¿‡å„ç§å›¾è¡¨å’Œçƒ­å›¾å¯è§†åŒ–ï¼Œæ˜¾ç¤ºæœ€å¸¸è§çš„æŒ‘æˆ˜åŠå…¶åœ¨ç¤¾åŒºä¸­çš„ç›¸å¯¹é‡è¦æ€§ã€‚  ç»“æœï¼ˆä»¥ä¸‹æ˜¯å›¾è¡¨ï¼‰ï¼š  æŒ‰ç»¼åˆå¾—åˆ†ï¼ˆé¢‘ç‡ + èµæˆ + è¯„è®ºï¼‰æ’åçš„å‰ 15 ä¸ªæ ‡ç­¾ æ ‡å‡†åŒ–æ ‡ç­¾æµè¡Œåº¦çƒ­å›¾ å¸¦æœ‰å„ä¸ªåˆ†æ•°çš„æ ‡ç­¾åˆ†æè¡¨  åé¦ˆ æˆ‘å¾ˆä¹æ„å¾—åˆ°æ‚¨çš„å¯¹è¿™ä¸ªé¡¹ç›®çš„æƒ³æ³•ä»¥åŠå¦‚ä½•ä½¿å…¶å¯¹äººå·¥æ™ºèƒ½å¼€å‘ç¤¾åŒºæ›´æœ‰ç”¨ã€‚å…·ä½“æ¥è¯´ï¼š  é™¤äº† Reddit ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜åº”è¯¥è€ƒè™‘å…¶ä»–æ•°æ®æºå—ï¼Ÿ æ‚¨è®¤ä¸ºå“ªäº›å…¶ä»–æŒ‡æ ‡æˆ–åˆ†ææœ‰ä»·å€¼ï¼Ÿ å¦‚ä½•ä½¿ç»“æœå¯¹å¼€å‘äººå‘˜ã€æ•™è‚²å·¥ä½œè€…æˆ–ç ”ç©¶äººå‘˜æ›´å…·å¯æ“ä½œæ€§ï¼Ÿ è¿™ç§æ–¹æ³•æ˜¯å¦å­˜åœ¨æˆ‘ä»¬åº”è¯¥è§£å†³çš„æ½œåœ¨åè§æˆ–å±€é™æ€§ï¼Ÿ æ‚¨æ˜¯å¦å¯¹å®šæœŸæ›´æ–°è¿™äº›è¶‹åŠ¿çš„ä»ªè¡¨æ¿æ„Ÿå…´è¶£ï¼Ÿ  éå¸¸æ„Ÿè°¢æ‚¨çš„è§è§£å’Œå»ºè®®ï¼ TL;DRï¼šAI å¼€å‘æŒ‘æˆ˜åˆ†æå™¨  è¯¥é¡¹ç›®åˆ†æ Reddit å¸–å­ä»¥è¯†åˆ«å¸¸è§çš„ AI å¼€å‘æŒ‘æˆ˜ ä½¿ç”¨ ML ç­›é€‰ã€æ€»ç»“å’Œæ ‡è®°æ¥è‡ª AI ç›¸å…³å­ç‰ˆå—çš„å¸–å­ å¯è§†åŒ–ç»“æœä»¥æ˜¾ç¤ºè®¨è®ºæœ€å¤šå’Œå‚ä¸åº¦æœ€é«˜çš„æŠ€æœ¯é¢†åŸŸ åœ¨æ­¤å¤„æŸ¥çœ‹ç»“æœ å¯»æ±‚åé¦ˆä»¥æ”¹è¿›åˆ†æ     æäº¤äºº    /u/Fixmyn26issue   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fstn9m/p_i_tried_to_map_the_most_recurrent_and_popular/</guid>
      <pubDate>Mon, 30 Sep 2024 11:53:28 GMT</pubDate>
    </item>
    <item>
      <title>[N] å¼ºåŒ–å­¦ä¹ é€ŸæŸ¥è¡¨</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fssp75/n_reinforcement_learning_cheat_sheet/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼ æˆ‘åˆšåˆšåœ¨ Medium ä¸Šå‘è¡¨äº†æˆ‘çš„ç¬¬ä¸€ç¯‡æ–‡ç« ï¼Œè¿˜åˆ›å»ºäº†ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ å¤‡å¿˜å•ã€‚ğŸ‰ æˆ‘å¾ˆä¹æ„å¬åˆ°æ‚¨çš„åé¦ˆã€å»ºè®®æˆ–ä»»ä½•å…³äºå¦‚ä½•æ”¹è¿›å®ƒä»¬çš„æƒ³æ³•ï¼ è¯·éšæ—¶æŸ¥çœ‹å®ƒä»¬ï¼Œå¹¶æå‰æ„Ÿè°¢æ‚¨çš„æ”¯æŒï¼ğŸ˜Š https://medium.com/@ruipcf/reinforcement-learning-cheat-sheet-39bdecb8b5b4    æäº¤äºº    /u/Prudent_Nose921   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fssp75/n_reinforcement_learning_cheat_sheet/</guid>
      <pubDate>Mon, 30 Sep 2024 10:56:25 GMT</pubDate>
    </item>
    <item>
      <title>ğŸš€ å°†ä»»ä½• GitHub å­˜å‚¨åº“è½¬æ¢ä¸ºå•ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼Œéå¸¸é€‚åˆ LLM æç¤ºä½¿ç”¨â€œ[Project]â€</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fspn1s/convert_any_github_repo_to_a_single_text_file/</link>
      <description><![CDATA[å¤§å®¶å¥½ï¼ ğŸ‘‹ æˆ‘çŸ¥é“æœ‰å‡ ç§ç±»ä¼¼çš„å·¥å…·ï¼Œä½†ä½ åº”è¯¥çœ‹çœ‹æˆ‘çš„å·¥å…·çš„åŸå› å¦‚ä¸‹ï¼š  å…è´¹ä¸”ç«‹å³å¯ç”¨ ğŸ’¸ é€‚ç”¨äºç§æœ‰å­˜å‚¨åº“ ğŸ›¡ï¸ å®Œå…¨åœ¨ä½ çš„æµè§ˆå™¨ä¸­è¿è¡Œ - ä¸ä¼šå°†æ•°æ®å‘é€åˆ°ä»»ä½•åœ°æ–¹ï¼Œå› æ­¤å®ƒå®Œå…¨å®‰å…¨ ğŸ”’ é€‚ç”¨äºGitHub URL åˆ°å­ç›®å½• ğŸ“ æ”¯æŒæ ‡ç­¾ã€åˆ†æ”¯å’Œæäº¤ SHA ğŸ·ï¸ è®©ä½ åŒ…å«æˆ–æ’é™¤ç‰¹å®šæ–‡ä»¶ ğŸ“‚  ğŸ”— è¯•ç”¨è¿™é‡Œ ğŸ”— æºä»£ç  å°è¯•ä¸€ä¸‹ï¼Œè®©æˆ‘çŸ¥é“ä½ çš„æƒ³æ³•ï¼ğŸ˜Š repo2txt æ¼”ç¤º    æäº¤äºº    /u/Beautiful-Novel1150   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fspn1s/convert_any_github_repo_to_a_single_text_file/</guid>
      <pubDate>Mon, 30 Sep 2024 07:05:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] è‡ªæˆ‘æ¨é”€å¸–</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</link>
      <description><![CDATA[è¯·å‘å¸ƒæ‚¨çš„ä¸ªäººé¡¹ç›®ã€åˆåˆ›å…¬å¸ã€äº§å“å±•ç¤ºã€åä½œéœ€æ±‚ã€åšå®¢ç­‰ã€‚ è¯·æåŠäº§å“å’ŒæœåŠ¡çš„ä»˜æ¬¾å’Œå®šä»·è¦æ±‚ã€‚ è¯·å‹¿å‘å¸ƒé“¾æ¥ç¼©çŸ­å™¨ã€é“¾æ¥èšåˆå™¨ç½‘ç«™æˆ–è‡ªåŠ¨è®¢é˜…é“¾æ¥ã€‚  ä»»ä½•æ»¥ç”¨ä¿¡ä»»çš„è¡Œä¸ºéƒ½ä¼šå¯¼è‡´ç¦ä»¤ã€‚ é¼“åŠ±å…¶ä»–ä¸ºé—®é¢˜åˆ›å»ºæ–°å¸–å­çš„äººåœ¨è¿™é‡Œå‘å¸–ï¼ ä¸»é¢˜å°†ä¿æŒæ´»è·ƒï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªä¸»é¢˜ï¼Œå› æ­¤è¯·åœ¨æ ‡é¢˜ä¸­çš„æ—¥æœŸä¹‹åç»§ç»­å‘å¸–ã€‚  å…ƒï¼šè¿™æ˜¯ä¸€ä¸ªå®éªŒã€‚å¦‚æœç¤¾åŒºä¸å–œæ¬¢è¿™æ ·ï¼Œæˆ‘ä»¬å°†å–æ¶ˆå®ƒã€‚è¿™æ˜¯ä¸ºé¼“åŠ±ç¤¾åŒºä¸­çš„äººä»¬é€šè¿‡ä¸åœ¨ä¸»çº¿ç¨‹ä¸Šå‘åƒåœ¾é‚®ä»¶æ¥æ¨å¹¿ä»–ä»¬çš„å·¥ä½œã€‚    æäº¤äºº    /u/AutoModerator   [é“¾æ¥] [è¯„è®º]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 29 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>