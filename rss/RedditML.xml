<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 17 Jul 2024 09:17:55 GMT</lastBuildDate>
    <item>
      <title>[D] 人工智能对齐、情感计算和计算和/或认知神经科学之间的关系</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5dgio/d_relation_bw_ai_alignment_affective_computing/</link>
      <description><![CDATA[同上    提交人    /u/Summesumnenagtaale   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5dgio/d_relation_bw_ai_alignment_affective_computing/</guid>
      <pubDate>Wed, 17 Jul 2024 08:58:40 GMT</pubDate>
    </item>
    <item>
      <title>[P]在推理 ML 模型时处理缺失的文本信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5cczf/phandling_missing_textual_information_while/</link>
      <description><![CDATA[我正在解决一个问题，其中我拥有以数值变量形式以及某种较长文本形式提供的数据。现在我可以从这些文本信息中提取特征，并将它们与已有的数值特征相结合。但问题是，在推理过程中我无法获得这些文本信息。只有在训练数据中我才拥有这些文本，并且在进行预测时必须没有它们。有什么建议可以告诉我应该如何进行模型训练，因为我不能放弃这些文本信息，因为它们非常有见地？我能想到的唯一解决方案是在预测过程中屏蔽它们，或者甚至根据某些逻辑标准尝试使用一些默认值。非常欢迎任何建议！！谢谢！！    提交人    /u/vishants98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5cczf/phandling_missing_textual_information_while/</guid>
      <pubDate>Wed, 17 Jul 2024 07:42:41 GMT</pubDate>
    </item>
    <item>
      <title>[P]如何重新使用现有词汇来建立单词索引？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5bwq9/phow_do_you_reuse_an_existing_vocabulary_to_build/</link>
      <description><![CDATA[因此，我正在尝试训练一个用于股市预测的 ml 模型，我刚刚开始，所以现在它只是用来预测新闻文章是否与股市有关！因此，我成功地在数据上训练了模型，我必须将其转换为单词索引。因此，除了单词索引，我们还获得了一个词汇表，就像一本将单词与数字映射的词典。现在，我有一个测试数据集，如何使用相同的词汇表为测试集创建单词索引。创建不同的词汇表或单词索引只会破坏准确性？ 为测试集创建不同的单词索引和词汇表不会造成太大问题吗？如果会导致问题，我该如何使用现有的词汇表？我正在考虑合并两个数据集，然后从末尾省略测试集的长度！我觉得有比这更好的解决方案，请帮忙！ 抱歉，这是一个愚蠢的问题，我对此还是有点陌生​​。 token = Tokenizer() token.fit_on_texts(X) word_indices = token.texts_to_sequences(X) vocab = token.word_index max_len = max(max(i) for i in word_indices) word_indices_padded = pad_sequences(word_indices, maxlen=max_len, padding=&#39;post&#39;) word_indices_np_padded = np.array(word_indices_padded) y_train = np.asarray(y).astype(&#39;float32&#39;) model = Sequential([ Dense(16,activation=&#39;relu&#39;), Dense(16,activation=&#39;relu&#39;), Dense(1,激活=&#39;sigmoid&#39;）]）model.compile（optimizer=&#39;adam&#39;，loss=&#39;binary_crossentropy&#39;，metrics=[&#39;accuracy&#39;]）model.fit（word_indices_np_padded，y_train，epochs=10）;  这是我的上下文代码。 我的谷歌colab链接：https://colab.research.google.com/drive/1zwPKVwxtM2eoitISL9SnOwGiLj8hL6g6?usp=sharing    提交人    /u/Mastermind_308   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5bwq9/phow_do_you_reuse_an_existing_vocabulary_to_build/</guid>
      <pubDate>Wed, 17 Jul 2024 07:11:23 GMT</pubDate>
    </item>
    <item>
      <title>如何构建此图像分类项目？我是图像处理新手，需要帮助，不知道从哪里开始。[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5bs8k/how_to_build_this_image_classification_project_im/</link>
      <description><![CDATA[所以，我计划做一个图像分类项目。问题陈述如下： 用于基础设施维护的自动道路损坏检测  手动检查道路状况是一项耗时且劳动密集型的任务，导致识别和修复受损道路的延迟。目标是开发一种分类模型，能够自动从图像（通过 CC 摄像机、手机等捕获）中检测和分类道路损坏，从而使维护过程高效。通过减少对人工检查的依赖并实现及时和有针对性的维修以确保安全和维护良好的道路网络，可以增强基础设施管理。 目标：  数据集包含带有背景的道路图像。该模型应涉及对象检测以仅捕获道路（使用 YOLO 或 R-CNN 或它们的组合等），然后对受损道路进行分类。   我不知道从哪里开始。我确实在 youtube 上观看了 andrew ng ml 课程，我了解了神经网络和反向传播。我构建了一个用于二元分类的多层感知器。我打算进入图像处理领域并完成上述项目，但我不知道从哪里开始。请帮帮我。    提交人    /u/Then-Rub-8589   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5bs8k/how_to_build_this_image_classification_project_im/</guid>
      <pubDate>Wed, 17 Jul 2024 07:03:06 GMT</pubDate>
    </item>
    <item>
      <title>同时运行多个作业时性能会变慢 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5bqjv/performance_becomes_slower_while_running_multiple/</link>
      <description><![CDATA[我有一块 Nvidia RTX 4090 24G GPU。当我只训练一个（或同时训练两个）模型时，速度不错，符合预期。但是，当脚本超过两个时，性能速度就会变得慢很多，比如说每个时期需要 20 分钟到 1 小时。所有进程都在 CUDA 内存限制之内。我只是想了解问题是什么，以及如何同时运行多个 PyTorch 作业（通过最大限度地利用我的 GPU）。 欢迎提出任何建议 :)    提交人    /u/LengthinessLittle807   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5bqjv/performance_becomes_slower_while_running_multiple/</guid>
      <pubDate>Wed, 17 Jul 2024 07:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[AI学习小组]有没有愿意学习的伙伴来组个小组来学习架构，实现它们，讨论它们，并创建一些应用级项目？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e59xvu/ai_study_groupany_willing_study_partners_to/</link>
      <description><![CDATA[基本上，我对学习和讨论架构、实现架构以及做一些项目很感兴趣。我更喜欢组建一个可以提高效率、分享学习成果、互相学习并承担一定责任的团队。 与专家相比，我更愿意与那些对 ML 和 DL 架构有一定了解的人建立联系，他们愿意解释和实现他们感兴趣的东西。任何国家，任何年龄。 如果有人愿意，请随时发送私信或发表评论。 请提及您的专业水平和您感兴趣的领域！    提交人    /u/Lost_Detective_9341   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e59xvu/ai_study_groupany_willing_study_partners_to/</guid>
      <pubDate>Wed, 17 Jul 2024 05:07:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 等变神经网络的新型正则化技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e58b7i/r_new_regularization_technique_for_equivariant/</link>
      <description><![CDATA[大家好， 我想分享一个我一直在研究的研究项目，它可能对那些训练机器学习模型的人有用。我正在收集更多数据并准备一篇论文，但与此同时，我想在这里分享这个想法，以获得一些反馈，看看它是否对其他人有帮助。 我使用 MIT 许可证发布它，我希望它被自由使用，但如果你在研究项目中使用它，请引用 GitHub。以下是我制作的一个非技术性的视频，用于展示这个想法： 项目概述 该项目引入了一个新的正则化项，旨在创建近似等变的神经网络。它的功能类似于通过随机转换来扩充您的数据，允许您教会您的模型如何对输入转换做出反应。 有关它的功能和使用方法的更多详细信息，请查看 GitHub 页面。 应用 此方法可应用于广泛的监督学习问题，包括：  图像和视频处理 音频处理 文本处理  以及某些无监督学习模型，如自动编码器。 我在强化学习方面的经验有限，但我对 RL 的潜在应用很感兴趣。 初步结果 虽然我的数据仍然有限，但我已经看到了某些任务的可喜改进。例如，在图像分割中，测试分数提高了几个百分点，在某些情况下，这种方法比传统的数据增强方法效果更好。我尝试过用 CNN 和预训练的视觉转换器来做这件事。使用预训练模型，最好在微调过程中将其应用于分类/分割头。 主要优势 与现有的等变 ML 技术相比，这种正则化方法有几个优势：  它支持不可逆变换。 它不需要特殊的模型架构。 您可以控制等变程度，这对于手写识别等任务至关重要，在这些任务中，模型应该对小旋转保持不变，但不应对大旋转保持不变。  很抱歉自我宣传，但我认为这是社区真正感兴趣的事情，我很高兴分享这个想法并听取您的想法和反馈。    提交人    /u/jjk23   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e58b7i/r_new_regularization_technique_for_equivariant/</guid>
      <pubDate>Wed, 17 Jul 2024 03:36:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 租用 GPU 的最佳地点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e562n1/d_best_places_to_rent_gpus_from/</link>
      <description><![CDATA[大家好， 我希望能够灵活地按需租用 GPU，而且当然不必支付很多费用。我一直在关注一些公司，例如 brev.Dev、runpod 和 fluidstack。我想知道你们是否使用其中任何一个或其他东西来运行工作负载     提交人    /u/OGbeeper99   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e562n1/d_best_places_to_rent_gpus_from/</guid>
      <pubDate>Wed, 17 Jul 2024 01:42:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用多个 gpu 对磁盘的影响？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e55tne/d_effects_of_using_multiple_gpus_on_the_disk/</link>
      <description><![CDATA[嗨，如果需要，请用粗体显示 TLDR。我目前正在尝试训练一个模型，并尝试几种配置（主要是更改 gpu、epoch 和步数。其他参数暂时保持不变）。我的目标是在增加 gpu 时看到总体性能改进，主要是在训练时间方面。我进行了两个单独的实验，分别使用了 4 个和 8 个 gpu。令我惊讶的是，与 4 个 gpu 相比，使用 8 个 gpu 并没有改进；但值得注意的是，与我最初仅使用 2 个 gpu 的实验相比，有改进。我在更改 gpu 时更改了其他参数，例如步数，因此我期望看到更快的训练时间。我很好奇这是否与磁盘利用率有关。我倾向于进一步探索这一领域，因为我目前在整个训练过程中记录了 GPU 和磁盘利用率。据我所见，GPU 利用率符合预期。磁盘利用率对于 8 个 GPU 来说似乎有点低，因为与 4 个 GPU 实验记录的相比几乎没有增加。在我的实验中，我确实可以选择增加每个 GPU 的进程数。我计划这样做，并额外扩大这些实验的规模，看看是否可以在更高层次上看到任何变化。 我在网上搜索过这个问题，但没有找到任何有用的资源。有人能给我指出一些资源，帮助我更好地理解这种关系吗？如果有人熟悉这个主题，请随时分享。谢谢。    提交人    /u/dillpill4   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e55tne/d_effects_of_using_multiple_gpus_on_the_disk/</guid>
      <pubDate>Wed, 17 Jul 2024 01:30:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找 PlotQA 或 ChartQA 上 SOTA 视觉模型的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e50rzd/d_looking_for_comparison_of_sota_vision_models_on/</link>
      <description><![CDATA[有人知道这些视觉 QA 测试中 Claude-3.5-sonnet、GPT-4o、LLaVa 等顶级模型的最新比较吗？    提交人    /u/Confident-Honeydew66   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e50rzd/d_looking_for_comparison_of_sota_vision_models_on/</guid>
      <pubDate>Tue, 16 Jul 2024 21:42:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] DiT 实施失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4vi9h/d_failed_dit_implementation/</link>
      <description><![CDATA[      大家好， 作为我在研究机器人操作时，想训练一个 DiT。我试图让它过度拟合一个简单的 20k 样本 猫数据集 。我的实现类似于论文的“adaLN-Zero”版本（在 LayerNorm 上进行条件化），它有 12 个 DiT 块层、12 个头、隐藏大小为 768 和一个补丁大小为 2。因为图像只包含猫，所以条件化有点没用，因为样本都有相同的标签。我在将它过度拟合到 MNIST 上确实取得了不错的效果。 在 8xA100 上一个小时后，我觉得它已经达到了瓶颈并努力克服它。 结果也很糟糕（图像是 1k 步采样）。我应该期待这个数据集有更好的效果吗？我将非常感谢任何能帮助我的人🙏 这是repo（我很懒，使用了HuggingFace的DDPMScheduler，但计划在它工作时编写自己的） https://preview.redd.it/k9bdi93b8xcd1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=5d3b14d1a16d3f4e9c5fbe8049cec6e4c5d360a5 https://preview.redd.it/9bmstg8c8xcd1.png?width=818&amp;format=png&amp;auto=webp&amp;s=f08747c95b5148a04c42c12ee8462b9bd2c6d057    提交人    /u/Ok_Operation_2094   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4vi9h/d_failed_dit_implementation/</guid>
      <pubDate>Tue, 16 Jul 2024 18:07:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] Tricycle：从头开始完全从 Autograd 到 GPT-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4sz1e/p_tricycle_autograd_to_gpt2_completely_from/</link>
      <description><![CDATA[我想分享 Tricycle：一个我完全从头开始构建的快速、功能齐全的深度学习框架： https://github.com/bclarkson-code/Tricycle/。 到目前为止，最大的里程碑是在单个 RTX 3090 上 68 小时内在 23 亿个代币上训练 GPT-2(124M)，我正在努力进一步扩大规模。 整个库都是从头开始构建的，从 AutoGrad 引擎一直到 GPT-2，任何有一点 Python 经验的人都应该可以理解。我试图使代码尽可能简单而不隐藏任何东西，并且我添加了一个 wiki 来介绍我如何构建所有内容。 我很想听听你的想法！ 编辑：语法    提交人    /u/Efficient_Plankton_9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4sz1e/p_tricycle_autograd_to_gpt2_completely_from/</guid>
      <pubDate>Tue, 16 Jul 2024 16:26:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文讨论：超越：生成模型的表现可以超越训练它们的专家</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</link>
      <description><![CDATA[大家好， 正如标题所示：我创建这篇文章是为了讨论最近发布的论文，该论文到目前为止引起了很多关注。我刚刚阅读了这篇论文，有一些问题。如果你也读过并喜欢这篇论文，我们聊聊吧！ https://arxiv.org/abs/2406.11741  设置对你来说清楚吗？作者是否也通过实验测试了定理 3 或定理 4？ 训练数据集中有多少专家/玩家？如果他们测试定理 4，他们是否会在特定玩家的游戏上训练集合的每个成员？ 他们如何鼓励定理 3 中的不相交集条件？ 等式 4 有一个拼写错误（两个术语相同）？     提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</guid>
      <pubDate>Tue, 16 Jul 2024 14:27:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 蛋白质语言模型揭示病毒模仿和免疫逃逸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</link>
      <description><![CDATA[我们被 ICML 24/ML4LMS 研讨会接受了，所以我想分享一下 :) &quot;蛋白质语言模型揭示病毒模仿和免疫逃逸&quot; TL;DR: 🧬 研究概述：病毒模仿宿主蛋白以逃避免疫系统的检测。我们使用蛋白质语言模型 (PLM) 来区分病毒蛋白和人类蛋白，ROCAUC 为 99.7%，准确率为 97%。 📊 见解：我们的研究表明，PLM 和生物免疫系统会犯类似的错误。通过识别和分析这些错误，我们可以深入了解免疫反应性以及开发更有效的疫苗和治疗方法的潜在途径。 我们还展示了一种新颖的、可解释的、多模式表格错误分析方法，用于理解任何问题的见解和错误，让我们了解深度学习语言模型/PLM 所犯错误的特征。 🔗 论文：https://openreview.net/forum?id=gGnJBLssbb&amp;noteId=gGnJBLssbb 代码：https://github.com/ddofer/ProteinHumVir 与我和海报见面（#116）在 ICML/ML4LMS 研讨会上！：https://openreview.net/attachment?id=gGnJBLssbb&amp;name=poster doi： https://doi.org/10.1101/2024.03.14.585057    提交人    /u/ddofer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</guid>
      <pubDate>Tue, 16 Jul 2024 09:13:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>