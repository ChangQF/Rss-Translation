<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sun, 14 Jul 2024 09:16:14 GMT</lastBuildDate>
    <item>
      <title>[R] 使用视频生成模型进行出租车 OD 需求矩阵预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2wnc9/r_using_video_generation_models_for_taxi_od/</link>
      <description><![CDATA[你好，我今年年初开始自学人工智能——我也写过博客（博客可以在下面的链接中在我的 github 上找到），我阅读了许多与上述主题相关的论文。从图神经网络开始，然后转到我可以添加什么，并思考混合密度网络，最后将下一帧预测模型应用于起点-目的地出租车需求矩阵预测。我从来没有写过任何类型的论文，只是在学习期间读了很多，我认为我的论文是非常基础的，甚至不是本科水平的“文本”。任何反馈都值得赞赏，我觉得我甚至不应该把这个给我的教授看（我目前正在攻读信息系统硕士学位）。我觉得我开始得很好——阅读了很多论文，做了笔记，做了总结，对这个主题有了很好的理解，但当涉及到模型部分时，我有点仓促行事，因为我放弃了写任何论文的希望。我的“论文”没有在任何地方发表，它的 PDF 和代码都在我的 Github 上。（编辑：我第一次使用 overleaf，所以有些格式很奇怪，请原谅我） 摘要： 预测出租车需求对于有效管理城市交通至关重要。本研究探讨了下一帧预测模型 ConvLSTM 和 PredRNN 的应用，使用 2024 年初的纽约市出租车数据连接数据集来预测起点-目的地 (OD) 出租车需求矩阵。ConvLSTM 在更长的训练时间下实现了 1.27 的 RMSE，而 PredRNN 在更快的训练下实现了 1.59。这些模型为传统的基于图的方法提供了替代方案，展示了现实世界场景中的优势和权衡。此外，还介绍了一个用于模型部署的开源框架，旨在弥合出租车需求预测研究与实际实施之间的差距。我们的代码可以在我们的 Github 上找到。 关键词：出租车、需求、预测、OD 矩阵、下一帧预测模型    提交人    /u/Bobsthejob   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2wnc9/r_using_video_generation_models_for_taxi_od/</guid>
      <pubDate>Sun, 14 Jul 2024 07:44:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] Glean 或 OpenAI 等公司如何将如此多的数据存储在向量数据库中以供检索？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2vxqw/d_how_do_companies_like_glean_or_openai_store_so/</link>
      <description><![CDATA[我查看了 Qdrants 的定价，发现如果我想要 32GB RAM 和 4 个 VPCU + 1TB（假设空间），每月大约需要花费 780 美元。 Glean 或 OpenAI 等公司如何让如此多的企业数据可搜索？这些企业已经在支付存储费用，因此他们不认为 RAG 是在支付存储费用；当此类服务如此昂贵时，他们不清楚数据量能扩展到多大。 可以肯定的是，即使自己托管也不便宜。 有什么想法吗？    提交人    /u/dtek_01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2vxqw/d_how_do_companies_like_glean_or_openai_store_so/</guid>
      <pubDate>Sun, 14 Jul 2024 06:58:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] GraphRAG 如何工作？解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2u26f/r_how_graphrag_works_explained/</link>
      <description><![CDATA[GraphRAG 相对于基线有了很大的进步，它引入了知识图谱而不是向量数据库来查询更全面的结果。看看它是如何工作的：https://youtu.be/C14DFAlaFIw?si=S5dvnkczkVo3az-F    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2u26f/r_how_graphrag_works_explained/</guid>
      <pubDate>Sun, 14 Jul 2024 04:58:29 GMT</pubDate>
    </item>
    <item>
      <title>[D]荷兰拍卖H100云交易所</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2jx1o/d_dutch_auction_h100_cloud_exchange/</link>
      <description><![CDATA[大家好， TLDR：我创建了一个 H100 荷兰式拍卖交易所，希望一些真实用户能提供一些反馈。为每个注册用户提供 5 美元的 H100 小时！ h100cloud.com  拍卖通常从底价开始，然后逐步上涨。这对云计算不起作用——你愿意被出价超过并丢失数据吗？ 我们的荷兰式拍卖模式从上限开始——每 H100 每小时 3.50 美元。我们每六个小时降低一次价格，直到服务器被买家买走。当价格达到 2.20 美元的底价时，我们停止降低价格。如果你以前使用过 Hetzner 拍卖，情况就是这样。 当你租用服务器时，价格是锁定的，直到你删除服务器。您永远不会被踢出。 云很难定价。定价过低，库存就会耗尽。定价过高，利用率就会不足。我们希望荷兰式拍卖能让客户找到合适的平衡点。如果 H100 效果良好，我们将扩展到其他 GPU 类型，甚至传统的 CPU 服务器。 目前，我们的平台上有 224 台 H100。我们希望您能试用一下，并在下方给我们一些反馈！创建的前几百个帐户将存入 5 美元的免费信用额度，足够使用一两个小时的 H100。如果您发表评论或直接给我发送反馈，我会再增加 25 美元的帐户信用额度  试试看：h100cloud.com    提交人    /u/ntu2323   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2jx1o/d_dutch_auction_h100_cloud_exchange/</guid>
      <pubDate>Sat, 13 Jul 2024 20:26:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 集中式（&可共享）数据管理 博士生</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2i6wv/d_centralised_sharable_data_management_as_phd/</link>
      <description><![CDATA[嗨，我目前正在做一个项目，我既有模型也有数据集。我可以访问我所在大学的计算服务器和持久存储，但它们都是私有的，只能通过 VPN 访问（这是有道理的）。我的模型权重也存在于 Weights&amp;Biases 上，因此它们是可共享、可访问的等等。我现在想要一些类似的东西来处理我生成的（MNIST 大小）数据集和关键分析结果。类似的东西，比如 git，一个我可以与人们分享的真相中心点，我也真的很想给我的 github CI-runner 读访问权限。这里有人有好的解决方案吗？说实话，我也担心成本。我考虑过 S3，但成本似乎太高了。 不过，大型云计算公司有研究应用门户，我想知道小型应用是否有机会？    提交人    /u/LeanderKu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2i6wv/d_centralised_sharable_data_management_as_phd/</guid>
      <pubDate>Sat, 13 Jul 2024 19:09:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 生成图像作为动作模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2hpby/r_generative_image_as_action_models/</link>
      <description><![CDATA[        提交人    /u/mohitshridhar   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2hpby/r_generative_image_as_action_models/</guid>
      <pubDate>Sat, 13 Jul 2024 18:49:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 理解强化学习中离散表示的不合理有效性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2e9ou/r_understanding_the_unreasonable_effectiveness_of/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2e9ou/r_understanding_the_unreasonable_effectiveness_of/</guid>
      <pubDate>Sat, 13 Jul 2024 16:20:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 雇用学生/毕业生，好主意还是坏主意？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2cnw8/d_hiring_studentsgraduates_good_or_bad_idea/</link>
      <description><![CDATA[我的初创公司正处于一个阶段，我们想开始使用 ML 探索一些新概念，特别是在音频领域。我们是自筹资金的，所以预算有限，无法负担我在招聘启事上看到的一些年薪 40 万美元的 ML 人员 😳 但有趣的是，我看到的所有真正有趣的 ML 开源项目似乎都是由研究生/攻读博士学位的人完成的。而不是由在大型公司工作的拥有大量简历的人完成的。  试图以相对可承受的小时费率寻找一名充满热情的研究生，希望他们能成为公司的一部分、获得股权等，这不合理吗？或者这通常不是这样的？    提交人    /u/maxiedaniels   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2cnw8/d_hiring_studentsgraduates_good_or_bad_idea/</guid>
      <pubDate>Sat, 13 Jul 2024 15:11:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自适应参数激活</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2ba37/r_adaptive_parametric_activation/</link>
      <description><![CDATA[      TL;DR 在图像分类任务中，具有可学习参数的激活函数可以近似许多流行函数并提高准确性 论文： https://arxiv.org/pdf/2407.08567 摘要：  激活函数在模型优化中起着至关重要的作用，但最佳选择仍不清楚。例如，Sigmoid 激活是平衡分类任务中事实上的激活，然而，在不平衡分类中，由于对频繁类的偏见，它被证明是不合适的。在这项工作中，我们通过在平衡和不平衡网络的分类和中间层进行全面的统计分析来深入研究这一现象，并通过经验表明，将激活函数与数据分布对齐可以提高平衡和不平衡任务的性能。为此，我们提出了自适应参数激活 (APA) 函数，这是一种新颖且多功能的激活函数，它将最常见的激活函数统一在一个公式下。 APA 可应用于中间层和注意力层，在 ImageNet-LT、iNaturalist2018、Places-LT、CIFAR100-LT 和 LVIS 等几个不平衡基准以及 ImageNet1K、COCO 和 V3DET 等平衡基准上显著超越最新技术。代码可在此 URL 上获取。  视觉摘要： https://preview.redd.it/kb26agqvkacd1.png?width=1215&amp;format=png&amp;auto=webp&amp;s=ff877939a3d900afca5a83a83559af219e3cb368 公式 基准测试： 不平衡的数据集，其中 \&quot;许多\&quot;、\&quot;中等\&quot; 和 \&quot;少数\&quot;参考类别频率组 https://preview.redd.it/aehu0slhmacd1.png?width=1219&amp;format=png&amp;auto=webp&amp;s=45825faa5c43065717c6a0cd8c763bbabc722eda https://preview.redd.it/95d1aafvmacd1.png?width=1183&amp;format=png&amp;auto=webp&amp;s=f421a04fe0d72d971e95c9c26af7e13e38556412    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2ba37/r_adaptive_parametric_activation/</guid>
      <pubDate>Sat, 13 Jul 2024 14:08:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人使用 Sentence Transformers 进行大规模训练吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e26t13/d_anyone_used_sentence_transformers_for_large/</link>
      <description><![CDATA[Sentence Transformers 非常适合简单、小规模的微调。 是否有人尝试过在非常大的规模上使用 Sentence Transformers，比如对 2 亿个文本对进行对比训练？ 或者人们更喜欢在这种规模上采用不同的训练方法？    提交人    /u/SingularValued   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e26t13/d_anyone_used_sentence_transformers_for_large/</guid>
      <pubDate>Sat, 13 Jul 2024 09:59:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我的 ML 工程师工作有多“正常”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e266li/d_how_normal_is_my_ml_engineer_job/</link>
      <description><![CDATA[大家好，我希望这篇文章没有违反任何规则。 我拥有计算机科学硕士学位（ML 重点），大约 1 个月前我开始在一家初创公司担任 ML 工程师。该公司有一个非常有趣的 ML 核心产品（他们对其进行了相当多的研究/实验），但它也有一个针对单个客户的小型“附带项目”，这远没有那么令人兴奋。它基本上由一个简单的 Web 应用程序组成，在后台执行一些 ML 操作，主要是通过查询 OpenAI 的 API 和使用其他未以任何方式修改的预构建模型。现在，开发这个应用程序的人要离开了，我必须接手这个项目......我对此有点生气，因为这不是我来这里时真正期望的。 考虑到这是我的第一份工作（以前从未做过实习），这是多么“正常”你会考虑开发这样的产品吗？我的职位实际上只是伪装的即时工程吗？    提交人    /u/Fursol   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e266li/d_how_normal_is_my_ml_engineer_job/</guid>
      <pubDate>Sat, 13 Jul 2024 09:16:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于大型感受野的小波卷积</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e22i7j/r_wavelet_convolution_for_large_receptive_fields/</link>
      <description><![CDATA[      TL;DR：我们使用小波来增加卷积的感受野和低频响应。 论文：https://arxiv.org/abs/2407.05848 代码：https://github.com/BGU-CS-VIL/WTConv  近年来，人们一直试图增加卷积神经网络 (CNN) 的内核大小，以模拟 Vision Transformers (ViTs) 自注意力模块的全局感受野。然而，这种方法在实现全局感受野之前就很快达到了上限并饱和。在这项工作中，我们证明，通过利用小波变换 (WT)，实际上可以获得非常大的接受场而不会遭受过度参数化，例如，对于 k×k 接受场，所提出方法中可训练参数的数量仅随 k 呈对数增长。所提出的层名为 WTConv，可用作现有架构中的直接替代品，产生有效的多频响应，并随着接受场的大小优雅地扩展。我们证明了 ConvNeXt 和 MobileNetV2 架构中 WTConv 层对图像分类的有效性，以及下游任务的主干，并表明它具有其他属性，例如对图像损坏的鲁棒性和对形状而非纹理的响应增强。  https://preview.redd.it/nrvpb9cvz7cd1.jpg?width=1246&amp;format=pjpg&amp;auto=webp&amp;s=5f9a02fa6c32d9c121d2519fe137b289756b9701    提交人    /u/shahaff32   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e22i7j/r_wavelet_convolution_for_large_receptive_fields/</guid>
      <pubDate>Sat, 13 Jul 2024 05:16:00 GMT</pubDate>
    </item>
    <item>
      <title>[D]2024 年中期，如何有效过滤和消化每日新闻和报纸？有什么工具可以推荐吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e1zl10/dhow_do_you_filter_and_digest_every_day_news_and/</link>
      <description><![CDATA[我每天花太多时间阅读不到 10 篇论文。有没有什么新工具可以快速消化论文？    提交人    /u/Historical-Tree9132   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e1zl10/dhow_do_you_filter_and_digest_every_day_news_and/</guid>
      <pubDate>Sat, 13 Jul 2024 02:33:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我一直在思考稳定扩散的工作原理，所以我决定从头开始编写自己的程序，并附上数学解释 🤖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e1w2rg/p_i_was_struggle_how_stable_diffusion_works_so_i/</link>
      <description><![CDATA[        提交人    /u/jurassimo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e1w2rg/p_i_was_struggle_how_stable_diffusion_works_so_i/</guid>
      <pubDate>Fri, 12 Jul 2024 23:38:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dx5tpo/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dx5tpo/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 07 Jul 2024 02:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>