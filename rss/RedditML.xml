<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 30 Nov 2023 03:14:40 GMT</lastBuildDate>
    <item>
      <title>[D] 微调用于图像-图像搜索的 CLIP 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1877c6d/d_fine_tuning_a_clip_model_for_imageimage_search/</link>
      <description><![CDATA[大家好，我一直在从事图像-图像搜索任务，fashionCLIP 对我来说非常有效，目前我想要获得以下性能我的方法进一步发展，我正在考虑针对这项任务微调 FashionCLIP 模型。为此，我只是生成图像的嵌入，将它们存储在向量索引中，然后计算搜索图像的嵌入与向量索引中的所有嵌入之间的余弦相似度。我并没有真正使用任何零样本应用程序或图像文本比较，我已经看到了我读过的所有 CLIP 模型的微调方法，使用文本图像对进行微调，我不明白应该如何微调为了提高应用程序性能的模型，我应该使用文本图像对吗？或者我应该只微调模型的视觉编码器，如果是这种情况，有人有一些我该怎么做的例子吗？   由   提交 /u/_bmph_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1877c6d/d_fine_tuning_a_clip_model_for_imageimage_search/</guid>
      <pubDate>Thu, 30 Nov 2023 02:28:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] Google DeepMind：使用 GNN 发现了 220 万种新材料（38 万种最稳定，736 种已在实验室中验证）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18779rp/r_google_deepmind_22_million_new_materials/</link>
      <description><![CDATA[材料发现至关重要但很困难。新材料可实现电池或 LED 等重大创新。但有无数种组合可供尝试。对它们进行实验测试既缓慢又昂贵。 因此科学家和工程师希望首先在计算机上模拟和筛选材料。这可以在实际实验之前检查更多的候选者。然而，模型历来难以准确预测材料是否稳定。 DeepMind 的研究人员开发了一个名为 GNoME 的系统，该系统使用图神经网络和主动学习来突破这些限制。 GNoME将材料的晶体结构建模为图表并预测形成能。它主动生成和筛选候选者，通过模拟评估最有前途的候选者。这扩展了它的知识并改进了多个周期的预测。 作者引入了生成尊重对称性的导数结构的新方法，进一步使发现多样化。  结果：  GNoME 发现了 220 万种新的稳定材料 - 相当于 800 年的正常发现时间。 其中，38 万种是最多的稳定且可供验证的候选者。 736 已在外部实验室进行了验证。其中包括一种全新的类金刚石光学材料和另一种可能是超导体的材料。  总的来说，这证明了扩大深度学习如何能够极大地加速材料创新。随着数据和模型的共同改进，它将加速解决需要新工程材料的重大问题。 TLDR：DeepMind 开发了一个人工智能系统，该系统使用图形神经网络来发现可能的新材料。它发现了 220 万候选者，其中超过 30 万是最稳定的。已经综合了 700 多个。 ​​完整摘要请参见此处。论文此处。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/18779rp/r_google_deepmind_22_million_new_materials/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18779rp/r_google_deepmind_22_million_new_materials/</guid>
      <pubDate>Thu, 30 Nov 2023 02:25:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] C++ 中的 EasyOCR！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18777go/p_easyocr_in_c/</link>
      <description><![CDATA[大家好！  我刚刚上传了 EasyOCR 的 C++ 实现，这是一个著名的 python ocr 库。还清除了一些音频相关项目中的蜘蛛网，请随时留下反馈或贡献！我只实现了最重要的部分，所以当然可以使用一些社区帮助！干杯！  https://github.com/ksasso1028/EasyOCR-cpp   由   提交/u/YamGloomy948   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18777go/p_easyocr_in_c/</guid>
      <pubDate>Thu, 30 Nov 2023 02:22:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 位置追踪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1876x16/d_icml_position_track/</link>
      <description><![CDATA[我不确定我是否理解正确，但是这篇论文讨论了该领域中值得关注的某些特定子部分就足够了，正确吗？   由   提交 /u/BigDreamx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1876x16/d_icml_position_track/</guid>
      <pubDate>Thu, 30 Nov 2023 02:08:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过 Prompt-Tuning 控制从大型语言模型中提取记忆数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1874fsg/r_controlling_the_extraction_of_memorized_data/</link>
      <description><![CDATA[       由   提交 /u/tell-me-the-truth-   &lt; a href=&quot;https://arxiv.org/abs/2305.11759&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1874fsg/r_controlling_the_extraction_of_memorized_data/</guid>
      <pubDate>Thu, 30 Nov 2023 00:14:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何向对强化学习一无所知的人解释为什么强化学习很难？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18742ki/d_how_to_explain_why_rl_is_difficult_to_someone/</link>
      <description><![CDATA[如何向对此一无所知的人解释为什么强化学习很难？ 我一直在从事强化学习项目在上班。给我分配这个问题的人是一位计算机科学家，他不是强化学习方面的专家，但知道这是一个难题。 （我的老板和分配项目给我的人是平等的。我的老板不是计算机科学家，对强化学习一无所知。）这家伙的老板是一位业务经理，对强化学习一无所知，对 ML 知之甚少。业务经理想要我提供一份有关项目进展情况的报告，但我感觉他并不真正理解为什么要花这么长时间。  就上下文而言，我已经在这个项目上工作了大约 4 个月，每周 15 个小时。在那段时间，我从头开始为这个问题构建了整个代码库，并编写了几个模型。我有一个目前大部分有效的方法，但我需要对奖励函数进行一些更改，以使其始终表现良好。我是唯一一个参与这个项目的人，所以所有这些都是我自己完成的。在此之前我也只做过普通强化学习，所以我必须学习大量有关深度强化学习的知识才能完成这项工作。幸运的是，我认识一位深度强化学习（外部工作）方面的专家，他能够给我指点。我感觉我已经取得了很大的进步，并且在拥有一个完全完善的模型方面已经接近冲刺了。然而我感觉这家伙对我不太感兴趣。这个人对我没有任何官方权力，所以这主要是为了解释除了有关该项目的正常幻灯片以及我所处的位置之外，强化学习还有多少工作。 &lt; !-- SC_ON --&gt;  由   提交 /u/savvyms   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18742ki/d_how_to_explain_why_rl_is_difficult_to_someone/</guid>
      <pubDate>Wed, 29 Nov 2023 23:57:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] MMMU：专家 AGI 的大规模多学科多模态理解和推理基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186y58x/r_mmmu_a_massive_multidiscipline_multimodal/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2311.16502  博客：https://mmmu-benchmark.github.io/  摘要：  我们介绍 MMMU ：一个新的基准，旨在评估需要大学水平学科知识和深思熟虑推理的大规模多学科任务的多模态模型。 MMMU 包含 11,500 个从大学考试、测验和教科书中精心收集的多模态问题，涵盖六个核心学科：设计、商业、科学、健康与医学、人文与科学社会科学、技术与科学工程。这些问题涵盖 30 个主题和 183 个子领域，包括 30 种高度异构的图像类型，例如图表、图表、地图、表格、乐谱和化学结构。与现有基准不同，MMMU 专注于利用特定领域知识进行高级感知和推理，挑战模型来执行类似于专家面临的任务。我们对 14 个开源 LMM 和专有的 GPT-4V(ision) 的评估凸显了 MMMU 带来的巨大挑战。即使是先进的 GPT-4V 也只能达到 56% 的准确率，这表明还有很大的改进空间。我们相信 MMMU 将激励社区构建下一代多模式基础模型，以实现专家通用人工智能。  https://preview.redd.it/0k2e074​​fbc3c1.jpg?width=1663&amp;format=pjpg&amp;auto=webp&amp;s=03c5b80bbab 288919bff3c7838f65ecb79cf8174 https://preview。 redd.it/g646d94fbc3c1.jpg?width=1475&amp;format=pjpg&amp;auto=webp&amp;s=65f5fa706e8295d4f296186ab7f082deb5968a6d https://preview.redd.it/ueftb64fbc3c1.jpg?width=1665&amp;format=pjpg&amp;auto=webp&amp;s=e3a945 765372dc3fc8ae2cb387a5c48b7c5d215b&lt; /a&gt; https:// Preview.redd.it/e10k3a4fbc3c1.jpg?width=1667&amp;format=pjpg&amp;auto=webp&amp;s=cbb71e4030cdb6067dae4fe86baaf8403ff99ec8   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186y58x/r_mmmu_a_massive_multidiscipline_multimodal/</guid>
      <pubDate>Wed, 29 Nov 2023 19:42:21 GMT</pubDate>
    </item>
    <item>
      <title>对抗性扩散蒸馏</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186xudj/adversarial_diffusion_distillation/</link>
      <description><![CDATA[   /u/KarlKani44  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186xudj/adversarial_diffusion_distillation/</guid>
      <pubDate>Wed, 29 Nov 2023 19:29:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过深度学习发现了数百万种新材料</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186w67m/r_millions_of_new_materials_discovered_with_deep/</link>
      <description><![CDATA[帖子：https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/ 论文：https://www.nature.com/articles/s41586-023-06735-9 摘要： 新型功能材料实现了从清洁能源到信息处理的技术应用的根本性突破。从微芯片到电池和光伏发电，无机晶体的发现一直受到昂贵的试错方法的瓶颈。与此同时，随着数据和计算的增加，语言、视觉和生物学的深度学习模型展示了新兴的预测能力。在这里，我们展示了大规模训练的图网络可以达到前所未有的泛化水平，从而将材料发现的效率提高一个数量级。在持续研究中发现的 48,000 个稳定晶体的基础上，效率的提高使得能够在当前凸包下方发现 220 万个结构，其中许多结构逃过了人类之前的化学直觉。我们的工作代表了人类已知的稳定材料的数量级扩展。最终凸包上的稳定发现将可用于筛选技术应用，正如我们对层状材料和固体电解质候选物的演示一样。在稳定结构中，有 736 个已通过独立实验实现。数以亿计的第一原理计算的规模和多样性也解锁了下游应用的建模能力，特别是导致高度准确和强大的学习原子间势，可用于凝聚相分子动力学模拟和高保真零-离子电导率的射击预测。   由   提交 /u/RobbinDeBank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186w67m/r_millions_of_new_materials_discovered_with_deep/</guid>
      <pubDate>Wed, 29 Nov 2023 18:19:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] GPU 基准测试：23 个消费级 GPU 上的稳定 Diffusion v1.5（生成 460,000 个精美的二维码）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186v2ve/p_gpu_benchmark_stable_diffusion_v15_on_23/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186v2ve/p_gpu_benchmark_stable_diffusion_v15_on_23/</guid>
      <pubDate>Wed, 29 Nov 2023 17:33:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为我的项目绘制基本事实的注释应用程序推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186tsfy/d_annotation_apps_recommendation_to_draw_ground/</link>
      <description><![CDATA[     &lt; /td&gt; 我目前正在为我的特征工程课程做一个项目，该项目的目的是检测田地边界或道路。因此，对于基本事实，我使用了 Matlab 中的图像分割，它具有各种工具，例如洪水填充和其他工具，可以将田野填充为黑色并将道路设置为白色。正如您在第二张图片中看到的那样，这是我绘制的地面，它有很多噪点。我们的教授建议我们使用 iPad 来绘制真实图像。任何人都可以为我推荐绘制相同精确事实但没有噪音的应用程序   由   提交 /u/Certain-Seesaw-2274   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186tsfy/d_annotation_apps_recommendation_to_draw_ground/</guid>
      <pubDate>Wed, 29 Nov 2023 16:41:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] Rankitect：在元规模上与世界级工程师对战的架构搜索排名</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186s7ps/r_rankitect_ranking_architecture_search_battling/</link>
      <description><![CDATA[   论文&lt; /strong&gt;: https://arxiv.org/abs/2311.08430 摘要:   神经架构搜索（NAS）已经证明了它在计算机视觉方面的功效和排名系统的潜力。然而，之前的工作主要集中在学术问题上，这些问题是在良好控制的固定基线下进行小规模评估的。在行业系统中，例如 Meta 中的排名系统，尚不清楚文献中的 NAS 算法是否能够超越生产基线，因为：（1）规模 - Meta 排名系统为数十亿用户服务，（2）强大的基线 - 基线是生产自深度学习兴起以来，多年来数百到数千名世界级工程师优化了模型，(3) 动态基线 - 工程师可能在 NAS 搜索过程中建立了新的、更强的基线，(4) 效率 - 搜索管道必须产生结果快速与生产生命周期保持一致。在本文中，我们介绍了 Rankitect，一个用于 Meta 排名系统的 NAS 软件框架。 Rankitect 寻求通过从头开始构建低级构建块来构建全新的架构。 Rankitect 实现并改进了最先进 (SOTA) NAS 方法，以在同一搜索空间下进行全面、公平的比较，包括基于采样的 NAS、一次性 NAS 和可微分 NAS (DNAS)。我们通过与 Meta 上的多个生产排名模型进行比较来评估 Rankitect。我们发现 Rankitect 可以从头开始发现新模型，实现归一化熵损失和 FLOP 之间的竞争性权衡。当利用工程师设计的搜索空间时，Rankitect 可以生成比工程师更好的模型，实现积极的离线评估和 Meta 规模的在线 A/B 测试。  https://preview.redd.it/n1l2fhle3b3c1.png?width=1360&amp;format=png&amp; ＆汽车=webp&amp;s=772bbd4885bd87fb14461d76f8aca804b32fe1b8   由   提交 /u/APaperADay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186s7ps/r_rankitect_ranking_architecture_search_battling/</guid>
      <pubDate>Wed, 29 Nov 2023 15:35:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 他们说：“这不仅仅是记住训练数据”：从（生产）语言模型中可扩展地提取训练数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186mm4m/r_its_not_just_memorizing_the_training_data_they/</link>
      <description><![CDATA[      &amp;# 32；由   提交/u/wojcech  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186mm4m/r_its_not_just_memorizing_the_training_data_they/</guid>
      <pubDate>Wed, 29 Nov 2023 10:45:56 GMT</pubDate>
    </item>
    <item>
      <title>MeshGPT：使用仅解码器变压器生成三角形网格 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186ktla/meshgpt_generating_triangle_meshes_with/</link>
      <description><![CDATA[       由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186ktla/meshgpt_generating_triangle_meshes_with/</guid>
      <pubDate>Wed, 29 Nov 2023 08:36:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>