<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 25 Nov 2024 09:19:28 GMT</lastBuildDate>
    <item>
      <title>[R] 评估创意写作成果和微调的效果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzdwg5/r_evaluating_creative_writing_output_and_the/</link>
      <description><![CDATA[      一位出版商问我，GPT-4o 是否可以进行微调以匹配他们的作者风格，以帮助建立副驾驶类型的体验。  这让我有机会想出一种方法，将创意写作分解为五大支柱（对话、阐述、内心想法、描述和行动），并衡量这些支柱如何随着提示和微调而变化。  我根据对 J.K. Rowling、Tade Thompson 和 Andrei Agassi 等知名作家的训练结果整理了这篇博文。令人惊讶的是，GPT-4o 在提示下很好地采用了他们的风格，但我整理了一些交互式可视化，以查看模型在故事生成（400 段）过程中如何变化，因为我们对 300、600 和 800 个样本进行了微调。  https://peytoncasper.com/blog/tone-evaluation/index.html https://github.com/peytoncasper/grammar-of-thought    由   提交  /u/peytoncasper   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzdwg5/r_evaluating_creative_writing_output_and_the/</guid>
      <pubDate>Mon, 25 Nov 2024 08:01:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 流匹配实际上与（连续）标准化流有很大不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzdera/d_flow_matching_is_actually_very_different_from/</link>
      <description><![CDATA[我查看了流匹配论文，发现流匹配通常被视为连续正则化流的替代实现。但在更仔细地比较这些方法之后，似乎存在一个非常明显的区别。在流匹配论文中，提到对于数据样本 x1（我假设这是指单个图像等单个数据点），我们可以在其上放置一个“虚拟”分布，例如非常紧密的高斯分布，然后构建一个条件概率路径 p_t(x|x1)。因此，对于每个数据点，我们学习的是数据点上的小高斯分布（t=1）与标准高斯分布（t=0）之间的变换。这意味着，当在整个数据集上进行训练时，潜在空间是每个单个数据点映射到的所有标准高斯分布的重叠混合。每个单独图像的小高斯球的图像是整个标准高斯。 然而，这似乎不是我们对常规正则化流所做的。在正则化流中，我们尝试学习将数据的整个分布转换为标准高斯的映射，使得每个数据点在潜在空间中都有一个固定的位置，并且数据集的图像在潜在空间中呈正态分布。在实践中，我们可以采用小批量并优化分数（例如 KL 或 MMD），将小批量的图像与标准高斯进行比较。潜在空间中的每个位置都可以唯一地反转为固定的重建数据点。 我不确定我是否遗漏了什么，但这似乎是两种方法之间的显着区别。在 NF 中，输入在潜在空间中编码，而本文中描述的流匹配似乎在潜在空间中混合输入。如果我的观察是正确的，那么应该有几个含义：  您可以在 NF 潜在空间中进行语义插值，但在 FM 情况下这完全没有意义 批次大小对于 NF 训练很重要，但对 FM 训练并不重要 NF 不能像扩散模型或 FM 那样被“引导”，因为目标图像在您采样初始噪声时就已经确定了  我想知道这里是否有人也研究过这些问题，可以告诉我是否确实如此，或者我遗漏的某些东西是否使它们事实上更相似。我很感激任何参与讨论的意见！    提交人    /u/aeroumbria   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzdera/d_flow_matching_is_actually_very_different_from/</guid>
      <pubDate>Mon, 25 Nov 2024 07:25:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我花了一个周末在 arxiv 上查阅有关 LLM 幻觉的文献——以下是我了解到的情况</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzcznp/d_i_spent_a_weekend_on_arxiv_reviewing_the/</link>
      <description><![CDATA[嗨，r/machinelearning！我是 kapa.ai (YC S23) 的创始人之一。在与部署 LLM 的团队就幻觉进行了大量讨论之后，我想花一个周末深入研究 arxiv 上的最新论文，以真正了解问题和解决方案空间。 我写了一篇涵盖所有内容的详细帖子，希望您的想法：https://www.kapa.ai/blog/ai-hallucination 您还见过哪些其他缓解措施有效？特别对常规解决方案之外的新方法感兴趣。    提交人    /u/srnsnemil   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzcznp/d_i_spent_a_weekend_on_arxiv_reviewing_the/</guid>
      <pubDate>Mon, 25 Nov 2024 06:55:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 基于 Arduino Nano Matter 和 Raspberry Pi 5，我开发了这个项目，以探索使用 NVIDIA Omniverse 在现实世界的航运业务中数字孪生合成数据生成和面向 AI 的进步。我通过 Edge Impulse 在合成数据集上训练了我的对象检测模型。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzcu29/p_based_on_arduino_nano_matter_and_raspberry_pi_5/</link>
      <description><![CDATA[        提交人    /u/the-amplituhedron   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzcu29/p_based_on_arduino_nano_matter_and_raspberry_pi_5/</guid>
      <pubDate>Mon, 25 Nov 2024 06:46:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求论文建议。您使用什么方法来在分布略有不同的多个数据集上训练模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzcmg9/d_looking_for_paper_suggestions_whats_your_go_to/</link>
      <description><![CDATA[假设您拥有来自不同类型设备的图像数据，这些设备具有不同的颜色配置文件、分辨率、镜头失真等。或者每个数据集中捕获的对象相似但略有不同。我需要一些关于如何有效混合这些数据集以获得更大的数据集来训练基础模型的论文建议。 我的数据集都来自略有不同的分布，但它们代表的概念大致相同，因此将它们一起建模以训练基础模型是有意义的。但是，简单地将所有数据集连接在一起而不将任何元数据信息传递给模型会降低性能，而不是在每个数据集上单独进行训练。 作为参考，我正在未标记的数据上训练 MAE 类型的模型，并在测试时在冻结的 MAE 嵌入上训练简单的线性/逻辑回归模型以完成不同的下游任务。目标是让 MAE 嵌入优于在每个数据集上单独训练的监督模型。 在 N 个数据集上训练的 MAE 表现不如仅在一个数据集上训练的 MAE。但是，在进行嵌入之前，在 N-1 个数据集上训练并在第 N 个数据集上进行（无监督）微调的 MAE 优于仅在第 N 个数据集上训练的模型。但这不是一个解决方案，因为我不能有 N 个基础模型。 我尝试添加可训练的源标记（即我有 N 个可训练标记，并且在通过编码器之前将与数据源相对应的标记连接到屏蔽的输入序列）但它根本不影响模型性能。如果您知道任何更好的方法，请告诉我。    提交人    /u/Atom_101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzcmg9/d_looking_for_paper_suggestions_whats_your_go_to/</guid>
      <pubDate>Mon, 25 Nov 2024 06:31:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为计算机科学硕士生/研究员，在选择实验室领域时是否应该非常谨慎？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gz6mj1/d_as_a_cs_masters_studentresearcher_should_one_be/</link>
      <description><![CDATA[我（非常幸运）得到了一个机会，可以在一所 R1 学校的一个很棒的实验室工作，教授的 h 指数超过 40，记录很好，但主要在较低级别的会议上发表文章，尽管也做过一些 AAAI。它将 AI 应用于与我的经验相符的领域，我们有望发表文章，这很完美。但是，我更热衷于探索更多基础 AI 研究（除了我上的课程外，我在这方面的经验很少）。 在 CS、ML 领域，似乎大多数人只优先考虑 NIPS/ICLR/ICML，尤其是因为我有兴趣攻读博士学位。我有点进退维谷，不知道应该抓住机会还是继续寻找更匹配的实验室（尽管其他教授可能不想招收更多学生）。 我的直觉告诉我，我应该忽略会议排名，这样做，因为它们有一些思想链、知识表示、认知系统组件。他们希望我投入多个学期的时间，当然，一旦我投入，我就会坚持到底。我的困境是，我越来越多地转向人工智能中更实际的应用，这是一个非常具体的领域，我担心自己将来无法转型。  我知道这听起来很傻，但如果你能忽略这一点，能否请你站在一个崭露头角的学者的角度，给我一些建议和想法，谢谢！    提交人    /u/giuuilfobfyvihksmk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gz6mj1/d_as_a_cs_masters_studentresearcher_should_one_be/</guid>
      <pubDate>Mon, 25 Nov 2024 00:56:49 GMT</pubDate>
    </item>
    <item>
      <title>RTX 4090 与 4080 super [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyzxb1/rtx_4090_vs_4080_super_d/</link>
      <description><![CDATA[正在考虑为研究构建一个 ML 和分子动力学工作站。我正在寻找价格在 4000 美元左右的 GPU。我一直倾向于 2 个 4090（我知道 5090 将于 1 月推出，完全是另一回事！）但理论上我可以以大约相同的价格运行 4x 4080 supers，而且从技术上讲，数字是最重要的，但前提是您可以高效地使用它们。我知道 pytorch 可以相当好地分布在 GPU 上，但并非所有东西都可以。我也知道更多的 vRAM 总是更好，因为 40 系列没有 NVlink，所以不能池化内存。我也简要地看了 RTX 卡（安培和 ada），但我的理解是它们真的只对专业驱动程序有价值，仅此而已。任何想法都将不胜感激！     由    /u/Mdgoff7 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyzxb1/rtx_4090_vs_4080_super_d/</guid>
      <pubDate>Sun, 24 Nov 2024 19:58:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] NAACL 研讨会什么时候公布？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyye7a/d_when_will_the_naacl_workshops_get_announced/</link>
      <description><![CDATA[NAACL 网站提到 11 月 25 日开始第二次征集研讨会论文，但该网站似乎没有提到哪些研讨会将举行。我不知道我现在知道是不是太愚蠢了，请帮帮我。    提交人    /u/Aromatic_Web749   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyye7a/d_when_will_the_naacl_workshops_get_announced/</guid>
      <pubDate>Sun, 24 Nov 2024 18:54:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过问题变体测试 LLM 类比推理的脆弱性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gys936/r_testing_the_brittleness_of_llm_analogical/</link>
      <description><![CDATA[研究人员开发了一个系统框架，使用复杂程度不断增加的字母字符串类比来测试法学硕士 (LLM) 中的类比推理。他们创建了多个测试集，用于探测类比思维的不同方面，从基本转换为复杂模式识别。 关键技术要点： - 评估了 4 个主要 LLM （包括 GPT-4 和 Claude）的性能 - 创建了具有可控难度进程的测试集 - 实现了用于衡量类比理解的新指标 - 测试了零样本和小样本性能 - 引入对抗性示例以测试鲁棒性 主要结果： - 模型在基本字母序列转换中的准确率达到 90% 以上 - 在多步转换中，性能下降 30-40% - 在新型字母系统上，准确率降至 50% 以下 - 小样本提示平均可将结果提高 15-20% - 模型对小模式扰动表现出脆弱性 我认为这项工作揭示了当前 LLM 抽象推理能力的重要局限性。虽然它们可以很好地处理表面级模式，但在更深层次的类比思维方面却举步维艰。这表明我们需要新的架构或训练方法来实现更强大的推理能力。 这里介绍的评估框架可以帮助以更系统的方式对未来模型的推理能力进行基准测试。结果还强调了当前模型需要改进的具体领域，特别是在处理新模式和多步骤转换方面。 TLDR：使用字母字符串类比测试 LLM 中的类比推理的新框架在基本模式下表现出色，但在复杂转换和新字母表中表现出明显的局限性。结果表明，当前模型可能是模式匹配，而不是真正的推理。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gys936/r_testing_the_brittleness_of_llm_analogical/</guid>
      <pubDate>Sun, 24 Nov 2024 14:32:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 模型中出现的认知途径。解决有关限制的根本缺陷。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gys51e/d_emergent_cognitive_pathways_in_transformer/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gys51e/d_emergent_cognitive_pathways_in_transformer/</guid>
      <pubDate>Sun, 24 Nov 2024 14:27:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我创建了一个库，用于构建使用树搜索来解决问题的代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyreq1/p_i_made_a_library_for_building_agents_that_use/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyreq1/p_i_made_a_library_for_building_agents_that_use/</guid>
      <pubDate>Sun, 24 Nov 2024 13:51:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 离散扩散模型的当前发展水平如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyp1br/d_what_is_the_current_stateoftheart_for_discrete/</link>
      <description><![CDATA[大家好， 我目前正在为一个新的研究项目研究离散扩散模型。在这个项目中，我将离散扩散应用到一个尚未应用的领域。然而，我对扩散本身还很陌生，我对关于这个主题的论文数量感到不知所措。在我目前的实施中，我专注于一篇较旧的论文，因为它们很好地描述了他们的方法，我想先测试我的想法，看看它是否有一些优点，根据初步结果，它确实有优点。 目前，我正在考虑用这个领域的最新补充来更新我的方法，但正如我之前所说，我对数量有点不知所措。所以我的问题是，最近有哪些研究离散扩散的好论文，它们要么解释了基本概念，比如调查论文，要么介绍了不仅适用于特定领域的新先进方法，比如 NLP 或视觉？ 提前谢谢你的帮助。    提交人    /u/Derpirium   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyp1br/d_what_is_the_current_stateoftheart_for_discrete/</guid>
      <pubDate>Sun, 24 Nov 2024 11:35:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 24 Nov 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过负特征值解锁线性 RNN 中的状态跟踪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy0hbh/r_unlocking_statetracking_in_linear_rnns_through/</link>
      <description><![CDATA[摘要：线性循环神经网络 (LRNN)（例如 Mamba、RWKV、GLA、mLSTM 和 DeltaNet）已成为大型语言建模中 Transformers 的有效替代品，可提供序列长度的线性缩放并提高训练效率。然而，LRNN 难以执行状态跟踪，这可能会损害代码评估或跟踪国际象棋游戏等任务的性能。偶数奇偶校验是最简单的状态跟踪任务，非线性 RNN（例如 LSTM）可以有效处理，但当前的 LRNN 无法解决。最近，Sarrof 等人 (2024) 证明，像 Mamba 这样的 LRNN 无法解决奇偶校验的原因是将其对角状态转换矩阵的值范围限制为 [0,1]，而加入负值可以解决这个问题。我们将此结果扩展到非对角 LRNN，它们最近在 DeltaNet 等模型中表现出了良好的前景。我们证明，状态转移矩阵只有正特征值的有限精度 LRNN 无法解决奇偶校验问题，而模 3 计数则需要复特征值。值得注意的是，我们还证明，当 LRNN 的状态转移矩阵是恒等向量减去向量外积矩阵的乘积时，它们可以学习任何常规语言，每个矩阵的特征值都在 [-1,1] 范围内。我们的实证结果证实，将 Mamba 和 DeltaNet 等模型的特征值范围扩展为包括负值，不仅可以使它们解决奇偶校验问题，而且可以持续提高它们在状态跟踪任务上的性能。此外，使用扩展的特征值范围进行语言建模的预训练 LRNN 实现了可比的性能和稳定性，同时在代码和数学数据上显示出良好的前景。我们的工作增强了现代 LRNN 的表现力，扩大了它们的适用性，同时又不改变训练或推理的成本。 https://arxiv.org/abs/2411.12537    提交人    /u/iltruma   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy0hbh/r_unlocking_statetracking_in_linear_rnns_through/</guid>
      <pubDate>Sat, 23 Nov 2024 14:11:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>