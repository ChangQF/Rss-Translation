<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Thu, 07 Mar 2024 00:46:59 GMT</lastBuildDate>
    <item>
      <title>[D] 我通过蒙特卡罗树搜索得到了不同的结果，我希望有人能提供一些线索。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8g7ys/d_im_getting_different_results_with_monte_carlo/</link>
      <description><![CDATA[嗨， 我正在为 Flesh and Blood 创建一个 MCTS 实现，它是一张交易卡。它似乎运行良好，即相当快。然而，我最近观察到一些奇怪的事情。我认为这是一个错误，但我想我应该联系一下，以防万一 MCTS 是如何工作的，如果是这样，最好有一个解释。 我可以选择以两种模式运行 MCTS：高效模式和低效模式。例如，考虑以下操作流程：开始游戏、开始回合、抽牌、开始阶段、[玩牌 1、玩牌 2]。 低效模式会将每个操作映射到一个节点：node1 ：开始游戏-&gt; StartTurn，节点2：StartTurn -&gt;抽卡，.... 高效模式将所有单个操作折叠为一个操作，因此“开始游戏”到“开始阶段”都将被执行，我们将拥有：node1：开始游戏-&gt; [Play Card 1、Play Card 2] 折叠它们的好处是我们不需要继续复制游戏状态。 但是，我看到的是高效模式返回的获胜次数几乎是低效模式的两倍。这是可能的，因为 MCTS 的工作方式，还是我怀疑它是一个错误。   由   提交/u/Annual_Asspiration_21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8g7ys/d_im_getting_different_results_with_monte_carlo/</guid>
      <pubDate>Thu, 07 Mar 2024 00:28:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练机器学习模型来识别含金石英岩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8etsl/d_training_an_ml_model_to_recognize_goldbearing/</link>
      <description><![CDATA[如何使用 Tensor Flow 训练 ML 模型来识别可能含有黄金的石英岩？ 一般来说，您想要“丑陋”的石英，石英的白色部分周围是破碎的、棕色和灰色的。 就属性而言，这可以在概念上建模如下： rock_type：石英 rock_texture：破碎 rock_colors：[棕色，灰色] rock_characteristics：[破碎，棕色，灰色] 我可以很容易地为此组装一个训练图像数据集。 创建一种机器学习算法是否很难，该算法可以输入数百或数千张含金石英矿石的图像，并预测哪些岩石更有可能含有最多的黄金？ 实现这一目标的步骤是什么？ 再说一次，我是一个新手，所以我不确定我是否正确地表达了我的问题. 谢谢您，祝您有美好的一天。   由   提交 /u/PickAxeCA   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8etsl/d_training_an_ml_model_to_recognize_goldbearing/</guid>
      <pubDate>Wed, 06 Mar 2024 23:28:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 比较决定系数与相关 R 平方值</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8en8p/d_compare_coefficient_of_determination_vs/</link>
      <description><![CDATA[寻求方法比较方面的帮助。 对于 100 个基因，我创建了一个模型来预测每个基因的表达（总共 100 个模型）。我执行了 k 倍交叉验证来计算决定系数 R 平方值，并将这些值聚合起来以获得每个模型 1，然后计算这些值的平均值和中位数。 我想要看看这与另一种方法相比如何，但该方法是计算得分（不是回归或 ML），因此我计算了 100 个基因中每个基因的相关系数 R 平方值，然后计算这些基因的平均值和中位数 因为我的 ML 模型的决定系数 R 平方值可能为负，并且计算得分的相关系数 R 平方值范围为 0 到 1，所以我不知道是否直接比较这些 R 平方值是有意义的。有人对如何比较它们有建议吗？将确定系数 R 平方值转换为 0 到 1 的范围是否有意义？   由   提交 /u/Br0wnish   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8en8p/d_compare_coefficient_of_determination_vs/</guid>
      <pubDate>Wed, 06 Mar 2024 23:20:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] Azure GPU 限制？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8e8yy/d_azure_gpu_restrictions/</link>
      <description><![CDATA[刚刚请求增加 a100 图像的配额，他们说 GPU 需求太高。想知道其他人是否遇到过这个问题，如果是的话，您是如何解决的？租用 GPU 不应该这么困难......    由   提交 /u/Primary-Track8298    reddit.com/r/MachineLearning/comments/1b8e8yy/d_azure_gpu_restrictions/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8e8yy/d_azure_gpu_restrictions/</guid>
      <pubDate>Wed, 06 Mar 2024 23:05:01 GMT</pubDate>
    </item>
    <item>
      <title>[D]苹果ANE性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8dyq3/d_apple_ane_performance/</link>
      <description><![CDATA[是否有已发布的 ANE 在各种流行视觉基准（resnet 50、yolo）上的推理性能基准？还有关于功耗和/或效率的已发表研究吗？   由   提交 /u/Dry-Significance-821   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8dyq3/d_apple_ane_performance/</guid>
      <pubDate>Wed, 06 Mar 2024 22:54:01 GMT</pubDate>
    </item>
    <item>
      <title>非文本数据的 LLM 微调 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8dp7t/finetuning_llm_on_nontext_data_discussion/</link>
      <description><![CDATA[嗨， 是否可以在非文本数据上训练大型语言模型。我可以将其应用于任何顺序数据集（例如音符）吗？我认为棘手的部分是对数据集进行标记，以便法学硕士可以更好地理解数据的底层结构。如果预训练的 LLMS 不是正确的方法，您能否建议任何其他预训练的模型？我试图解决的问题需要预测离散值，因此我认为使用音频生成模型没有意义。我不喜欢从头开始训练，所以只是想知道。另外，如果我的直觉不对，请告诉我。 谢谢！   由   提交 /u/Dunkeyfunkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8dp7t/finetuning_llm_on_nontext_data_discussion/</guid>
      <pubDate>Wed, 06 Mar 2024 22:43:21 GMT</pubDate>
    </item>
    <item>
      <title>[P] ComfyUI 的 InstaSwap 换脸节点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8bvqx/p_instaswap_face_swap_node_for_comfyui/</link>
      <description><![CDATA[      ComfyUI 存储库：https://github.com/abdozmantar/ComfyUI-InstaSwap Standalon 存储库：https://github.com/abdozmantar/Standalone-InstaSwap https://i .redd.it/9vw32vxx7smc1.gif   由   提交 /u/abdullahozmntr   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8bvqx/p_instaswap_face_swap_node_for_comfyui/</guid>
      <pubDate>Wed, 06 Mar 2024 21:31:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 NLP 分类数据集中查找潜在不良标签的技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8adyu/d_techniques_for_finding_potentially_bad_labels/</link>
      <description><![CDATA[我正在寻找在 NLP 分类数据集中查找潜在不良标签的技术。我们一直在使用 Cleanlab（自信学习），但我们发现对于我们的用例（内容审核/媒体监控）来说，精确度/召回率不是很高。您有其他有趣的技术/论文的指导吗？ GPT-4 等人。当您花费足够的时间编写描述性提示时，它是一个不错的选择，但它的代价是规模庞大。对更智能的“预选”感到好奇技术而不是把一切都扔给 GPT？    由   提交 /u/IbrahimSharaf   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8adyu/d_techniques_for_finding_potentially_bad_labels/</guid>
      <pubDate>Wed, 06 Mar 2024 20:32:28 GMT</pubDate>
    </item>
    <item>
      <title>[D]：寻求建议：地理空间应用从 GIS 过渡到 AI/ML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b87o07/d_seeking_advice_transitioning_from_gis_to_aiml/</link>
      <description><![CDATA[嘿，各位 GIS/ML 爱好者！ 我目前在加拿大担任政府 GIS 职务，热爱一切但我渴望更深入地了解地理空间应用的人工智能和机器学习世界。我相信这种交叉点具有巨大的潜力，可以彻底改变我们分析和解释空间数据的方式。 我正在寻求有关如何使这一过渡更加顺利的建议。您是否会向具有 GIS 背景、希望深入研究数据科学和机器学习的人推荐任何特定的在线课程、教程、资源、公司/组织？ 任何建议或个人经验将不胜感激！ 仅供参考，在获得数学和物理学士学位期间，我学习了 Python 和 R，并参加了数据科学、机器学习和深度学习方面的研究生课程。然后我发现了地理空间数据科学并被迷住了。然后，我转而获得了 GIS 研究生证书和应用测绘学硕士学位，这就是我获得目前职位的原因。在此期间，我使用 Esri 卫星图像和 LiDAR 数据深度学习框架开发了自定义 AI 解决方案，这很有趣，但最终我想开发自己的 NN 架构/解决方案。  目前，在下班后的业余时间和周末，我正在 Python 中的 ML 工程/数据科学家数据营的职业轨道上工作，以继续填补我的知识空白并保持最新状态。  我希望继续担任目前的职位以保持财务稳定，直到我有足够的技能过渡到未来薪资更高的机器学习职位。我对目前的角色很满意，但我做的数据库管理工作多于空间分析。我还希望将来能够充分发挥我在数学/编程方面的能力。   由   提交 /u/ayooooooooooooooo0o0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b87o07/d_seeking_advice_transitioning_from_gis_to_aiml/</guid>
      <pubDate>Wed, 06 Mar 2024 18:46:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 逆转诅咒</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b86vgt/d_the_reversal_curse/</link>
      <description><![CDATA[https://arxiv.org/pdf/2309.12288 .pdf 原来我预测了 2021 年的逆转诅咒哈哈 https://www.reddit.com/r/MachineLearning/comments/p13ean/d_can_gpt_generalize_in_both_directions/ 编辑：第一篇论文引用的另一篇论文甚至使用了非常相似的示例： https://arxiv.org/pdf/2308.03296.pdf &lt; blockquote&gt; 美国第一任总统是乔治·华盛顿  如果我的帖子以任何方式启发作者，我会非常高兴 &lt; !-- SC_ON --&gt;  由   提交 /u/DeMorrr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b86vgt/d_the_reversal_curse/</guid>
      <pubDate>Wed, 06 Mar 2024 18:16:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最新/最新的 TTS/RVC 设置 + 获得语调/情感的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b863xv/d_latest_most_up_to_date_tts_rvc_setup_ways_to/</link>
      <description><![CDATA[不确定这是否是最好的帖子，但我在这里看到了类似的帖子...  我&#39;一直在使用像 xtts 或 bark（通过 coqui tts）这样的语音克隆器，它们有点......嗯......（有时很好，有时不好，当进行大量文本到语音转换时 - 大多数输出缺少单词甚至整个句子）。  我什至尝试微调 xtts (v2)，尽管声音变得更好，但输出却更差（总是缺少单词，有时甚至整个段落）。  所以我开始摆弄 rvc，它看起来更好 - 但我有一些问题。  有用于推理/训练的 GUI 吗？为了更快的设置？我发现了这个： https://github.com/SayanoAI/RVC-Studio - 但它有点错误（无法训练与它） 或者如果有一个基本的代码设置我可以用来训练和进行推理（我需要做批量文件）。  此外，我不知道是否可以使用 RVC 做一件事：向输出语音添加情感/语调。如果使用一些基本的 TTS 创建输入语音，则语音将是平淡的 - RVC 语音是否能够为平淡的 TTS 语音添加适当的情感？或者实现这一目标的最佳设置是什么？    由   提交 /u/yupignome   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b863xv/d_latest_most_up_to_date_tts_rvc_setup_ways_to/</guid>
      <pubDate>Wed, 06 Mar 2024 17:47:49 GMT</pubDate>
    </item>
    <item>
      <title>[D][R]强化学习的最新进展</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b81pkt/drrecent_developments_in_reinforcement_learning/</link>
      <description><![CDATA[我正在尝试进入强化学习领域，并且刚刚完成了 Sutton 和 Barto 的课程以及 YT 的一门课程。只是想知道目前在这个主题上正在做什么（调查论文/书会很好）。还想知道常用的数据集类型。我学习的课程本质上是完全理论性的，所以我也想知道目前这个领域使用什么工具包。   由   提交/u/ANI_phy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b81pkt/drrecent_developments_in_reinforcement_learning/</guid>
      <pubDate>Wed, 06 Mar 2024 14:56:18 GMT</pubDate>
    </item>
    <item>
      <title>[D]为什么 Hugging Face 没有成为桌面上最有前途（且年轻）的 AI 聊天机器人玩家之一（如 Mistral AI、Anthropic、Perplexity AI 等）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7t35y/dwhy_isnt_hugging_face_becoming_one_of_the/</link>
      <description><![CDATA[我记得几年前人们讨论HF的商业模式是什么或者如何盈利。 我认为现在是对他们来说这是最好的时代，但我有点惊讶他们没有创造自己的时代。 他们有才华、经验和资源。只是想知道。   由   提交 /u/xiikjuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7t35y/dwhy_isnt_hugging_face_becoming_one_of_the/</guid>
      <pubDate>Wed, 06 Mar 2024 06:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 2023年300+ML比赛分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b79bqq/r_analysis_of_300_ml_competitions_in_2023/</link>
      <description><![CDATA[      我运行 mlcontests.com，这是一个网站列出了跨多个平台的 ML 竞赛，包括 Kaggle/DrivenData/AIcrowd/CodaLab/Zindi/EvalAI/… 我刚刚完成了对 300 多个 ML 竞赛的详细分析2023 年，包括查看其中 65 个获奖解决方案。 一些亮点：  正如预期的那样，几乎所有获奖者都使用 Python 。一名获胜者使用 C++ 解决性能至关重要的优化问题，另一名获胜者使用 R 进行时间序列预测竞赛。 92% 的深度学习解决方案使用 PyTorch。我们发现剩下的 8% 使用 TensorFlow，并且所有这些都使用了更高级别的 Keras API。大约 20% 的获胜 PyTorch 解决方案使用 PyTorch Lightning。 基于 CNN 的模型比基于 Transformer 的模型赢得更多计算机视觉竞赛。 在 NLP 领域，毫不奇怪，生成式法学硕士开始被使用。一些竞赛获胜者使用它们来生成用于训练的合成数据，其他人则提出了创造性的解决方案，例如向开放权重法学硕士添加分类头并对其进行微调。还有更多专门针对 LLM 微调的竞赛正在推出。 与去年一样，梯度增强决策树库（LightGBM、XGBoost 和 CatBoost）仍然被广泛使用 由竞赛获胜者评选。 LightGBM 比其他两者稍微流行一些，但差异很小。 计算使用情况差异很大。 NVIDIA GPU 显然很常见；一些获奖者使用了 TPU；我们没有发现任何使用 AMD GPU 的获胜者；有些人仅在 CPU 上训练他们的模型（尤其是时间序列）。一些获奖者通过工作/大学获得了强大的（例如 8x A6000/8x V100）设置，一些获奖者在本地/个人硬件上进行了全面培训，相当多的获奖者使用了云计算。 有相当多的高- 2023 年的概况竞赛（我们详细介绍维苏威火山挑战赛和M6 预测），以及 2024 年即将举办的更多比赛（维苏威火山挑战赛第二阶段、AI 数学奥林匹克、AI 网络挑战赛） )  有关更多详细信息，请查看完整报告：https://mlcontests.com/state-of-competitive-machine-learning-2023?ref=mlc_reddit ​ 获奖者中最常用的一些 Python 软件包&lt; /p&gt; 在我的 r/MachineLearning 帖子中 去年关于 2022 年比赛的相同分析，热门评论之一询问了时间序列预测。 2023 年有几个有趣的时间序列预测竞赛，我设法对它们进行了相当深入的研究。跳至报告的此部分以了解这些内容。 （不同类型的时间序列竞赛的获胜方法有很大差异 - 包括 ARIMA 等统计方法、贝叶斯方法，以及 LightGBM 和深度学习等更现代的 ML 方法。） 我能够花费相当多的时间感谢今年报告的赞助商：Latitude.sh（配备专用 NVIDIA H100/A100/L40s GPU 的云计算提供商）和 Comet（有用的工具），我们花费了大量时间进行研究和撰写用于 ML - 实验跟踪、模型生产监控等）。我不会在这里向您发送垃圾邮件链接，报告底部有更多详细信息！   由   提交 /u/hcarlens   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b79bqq/r_analysis_of_300_ml_competitions_in_2023/</guid>
      <pubDate>Tue, 05 Mar 2024 16:22:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>