<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 03 Jan 2025 15:17:05 GMT</lastBuildDate>
    <item>
      <title>[D] ReLU + 线性层 aa 圆锥包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hso6rf/d_relu_linear_layers_aa_conic_hulls/</link>
      <description><![CDATA[在具有 ReLU 激活的神经网络中，将矩阵 P 的线性层组合到 ReLU 上，将输入映射到 P 的列的圆锥包中。 有没有论文利用这一事实来获得有趣的见解？    提交人    /u/alexsht1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hso6rf/d_relu_linear_layers_aa_conic_hulls/</guid>
      <pubDate>Fri, 03 Jan 2025 14:53:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 实时动画</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hsnyev/p_real_time_animation/</link>
      <description><![CDATA[嗨， 我想要一些关于如何开始这个项目的指导：我想创建可以实时改变表情的动画角色，并将它们与 LLM 联系起来。 我希望最终结果看起来像是在和你最喜欢的迪士尼角色交谈，也许会改变角色的个性等等。    提交人    /u/Efficient_Zombie_930   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hsnyev/p_real_time_animation/</guid>
      <pubDate>Fri, 03 Jan 2025 14:42:52 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 创建自然语音或 TTS 系统难吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hsj3oy/discussion_is_it_hard_to_create_natural_speech_or/</link>
      <description><![CDATA[我看到只有大型公司（谷歌、微软等）在文本转语音 (TTS) 方面具有惊人的效率 我认为 TTS 与 LLM 相结合是人机交互方面的突破 随着大量关于 TSS 的论文发表，小型组织创建 TTS 的限制是什么  编辑： 由于这不是 LLM，因此计算和数据要求较少。 一周的训练计算成本应该为 10,000 美元。应该有一些数据供应商可以提供高质量的数据集。（Deepseek，新的 LLM 初创公司应该使用它们） 大公司有什么护城河 1. 人才护城河（算法）2. 数据护城河 3. 计算护城河 4. 基础设施护城河 数据和计算护城河对于小公司来说绝对是可用的。对于任何风险投资公司来说，300 万美元都可以开一张支票。 我怀疑基础设施和人才护城河是否是大公司脱颖而出的原因。    提交人    /u/code_dexter   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hsj3oy/discussion_is_it_hard_to_create_natural_speech_or/</guid>
      <pubDate>Fri, 03 Jan 2025 09:57:41 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 制作一个国际象棋引擎可视化，让你了解基于神经网络的国际象棋引擎是如何思考的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hs7syq/project_making_a_chess_engine_visualization_that/</link>
      <description><![CDATA[      大家好，我是一名高中生，正在为一个使用 lc0 的学校项目开发这款国际象棋可视化工具，该工具通过详细输出模式和引擎分析制作了神经网络评估热图。您可以与引擎对战，也可以将其用作分析工具，以了解基于 NN 的引擎如何“思考”。链接到 youtube 预览：https://www.youtube.com/watch?v=7nbWr8TR6nA 游戏开场画面 github：https://github.com/jay63683/BlackBox-Chess-a-XAI-leela-chess-GUI需要 Processing 才能运行。或者，如果您不想下载 Processing，您可以观看视频教程。计划将引擎切换到 ONNX 以进行未来更新，这样我就可以更深入地使用 ONNX 工具解释流程。任何反馈都非常感谢。    提交人    /u/Lower_Junket_222   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hs7syq/project_making_a_chess_engine_visualization_that/</guid>
      <pubDate>Thu, 02 Jan 2025 23:26:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 图像生成的测试时间计算？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hs45oi/d_testtime_compute_for_image_generation/</link>
      <description><![CDATA[是否有任何工作将类似 o1 的测试时间推理应用于其他模态，例如图像生成？这样的事情可能吗？花更多时间生成更准确的图像    提交人    /u/heyhellousername   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hs45oi/d_testtime_compute_for_image_generation/</guid>
      <pubDate>Thu, 02 Jan 2025 20:53:49 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] LLM 如何改变你作为 ML 工程师的工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hs41pt/discussion_how_is_llm_changing_your_job_as_a_ml/</link>
      <description><![CDATA[我刚刚看了吴恩达关于人工智能代理的演讲。他谈到了传统的机器学习任务可能需要 6 个月的时间，但现在有了法学硕士，只需要一个周末就可以完成。 这是这次演讲的 2-4 分钟。https://youtu.be/KrRD7r7y7NY?si=XDCAm7NFTMO3ayn3  具体来说，我猜他是说你可以用法学硕士进行零样本学习，而不是收集大量标记数据，构建和部署模型。他使用了情绪分析任务的例子。 我想知道是否有人作为机器学习科学家在工作中经历了这种生产力的转变。  我的经验是，公司不想直接使用 chatGPT，而是尝试建立自己的内部 LLM，我猜是出于数据隐私和成本方面的考虑。  请分享您的经验。     提交人    /u/Ok_Guava_9111   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hs41pt/discussion_how_is_llm_changing_your_job_as_a_ml/</guid>
      <pubDate>Thu, 02 Jan 2025 20:49:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 注意层的超参数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hs2h7f/d_hyperparameters_on_attention_layer/</link>
      <description><![CDATA[      https://preview.redd.it/l4kobgx6wmae1.png?width=776&amp;format=png&amp;auto=webp&amp;s=7bd1b81b27f09a926eff615ca3b5f119df8b621f 嗨，我最近在为一个项目重读 CLIP 论文，我看到了 transformers 的超参数定义，如附图所示。 我对这些的理解是： - 嵌入维度 - 标记空间的嵌入维度被投影 - 层 - N 层中的每一层都包含# 个头 - 宽度（这是我的疑问） - 每个嵌入提取的查询、键和值向量的长度。  我对这些值的解释正确吗？ 我理解值向量的长度可能与键和值的长度不同。 如果之前已经问过这个问题，请原谅，关于如何定义注意层上的超参数的任何评论都会有所帮助。  谢谢大家！    提交人    /u/GeekAtTheWheel   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hs2h7f/d_hyperparameters_on_attention_layer/</guid>
      <pubDate>Thu, 02 Jan 2025 19:45:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] Yi：通过级联数据处理和有针对性的微调优化的基础模型系列</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrxipz/r_yi_a_family_of_foundation_models_optimized/</link>
      <description><![CDATA[Yi 团队使用新颖的数据处理技术开发了一系列新的开源基础模型，这些模型在高质量过滤数据上进行训练。核心创新是他们的数据准备流程，该流程将基于规则的过滤与学习模型相结合，以删除有问题的内容，同时保留有用的信息。 关键技术方面：- 使用标准 Transformer 架构的模型参数范围从 6B 到 34B - 多阶段数据过滤过程，包括 AI 辅助内容评估 - 改进的注意力机制和训练稳定性优化 - 训练期间集成的内置安全措施 - 用于处理长序列的有效扩展技术 结果显示，在标准基准测试中表现出色：- 在推理任务上可与类似大小的闭源模型相媲美 - 强大的编码和数学能力，尤其是在较大的变体中 - 在结合安全约束的同时保持高性能 - 在训练计算要求方面实现效率提升 我认为这项工作表明，开源模型可以在保持透明度的同时取得强劲的成果。数据处理技术可能会影响未来模型的训练方式，从而有可能在整个领域带来更高质量的输出。效率的提高可能有助于减少训练大型模型的计算障碍。 我认为安全第一的方法是值得注意的，尽管还需要做更多的工作来确保这些保护措施不会被规避。开源性质可以加速对功能和安全性的研究。 TLDR：通过新颖的数据处理和训练技术实现的新型开源基础模型系列（6B-34B 参数）具有强大的性能。展示了透明、注重安全的模型开发方法的可行性。 完整摘要在这里。论文这里。   提交者    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrxipz/r_yi_a_family_of_foundation_models_optimized/</guid>
      <pubDate>Thu, 02 Jan 2025 16:24:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求针对特定领域法学硕士 (LLM) 的自动数据混合加权建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hruv58/d_seeking_advice_on_automated_data_mixture/</link>
      <description><![CDATA[大家好，机器学习的朋友们！ 我目前正在通过指令微调和 DPO 来研究训练后领域特定的 LLM，使用领域内的各种数据集（10+）。但是，我遇到了一点障碍。当我天真地合并这些数据集并使用均匀采样时，与基于直觉手动调整权重（例如，对具有大量数据的简单任务进行下采样）相比，性能往往表现不佳。虽然这种手动方法在一定程度上有效，但我怀疑它远非最佳。 我想看看这里是否有人有经验或见解，了解用于确定数据混合权重的自动化算法方法。我知道 DoReMi，但就我而言，它的性能改进相当有限。您是否发现其他更有效的技巧或策略？ 如果您能分享任何建议、资源或个人经验，我们将不胜感激。提前致谢！    提交人    /u/purified_piranha   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hruv58/d_seeking_advice_on_automated_data_mixture/</guid>
      <pubDate>Thu, 02 Jan 2025 14:26:59 GMT</pubDate>
    </item>
    <item>
      <title>搜索和学习的扩展：从强化学习角度重现 o1 的路线图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrq7ak/scaling_of_search_and_learning_a_roadmap_to/</link>
      <description><![CDATA[  由    /u/cavedave  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrq7ak/scaling_of_search_and_learning_a_roadmap_to/</guid>
      <pubDate>Thu, 02 Jan 2025 09:41:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 带因式分解机的数值特征</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrpuix/r_numerical_features_with_factorization_machines/</link>
      <description><![CDATA[很高兴分享我们最近的 TMLR 论文，由 Alex Shtoff、Elie Abboud、Rotem Stram 和 Oren Somekh 撰写的“因式分解机中的数值特征的函数基编码”。  本文提出了一个有趣的见解，探讨了在推荐系统的背景下，因式分解机 (FM) 与使用基函数的特征编码之间的相互作用。  与线性模型的相同相互作用是一种古老的经典，我们大多数人都在我们的 ML 101 课程中学到了。多项式回归就是其中之一 - 我们使用标准多项式基 {1, 𝑥, 𝑥², ...} 对特征 𝑥 进行编码。  FM 是一类模型，它对二次多项式进行建模 f(𝒙)=𝑢+⟨𝒘,𝒙⟩ + ⟨𝒙,𝑽𝒙⟩ 其中 diag(𝑽)=𝟎，其中系数矩阵 𝑽 使用特征嵌入向量以某种低秩分解形式表示。例如，Rendle 在 2010 年提出的经典 FM 是 f(𝒙)=𝑢+⟨𝒘,𝒙⟩ + ∑_{i≠k}⟨𝒗ᵢ,𝒗ₖ⟩𝑥ᵢ𝑥ₖ 其中 {𝒗₁, ..., 𝒗ₙ} 是特征嵌入向量。 这样的建模允许捕获成对的特征交互，使其比简单的线性模型强大得多，同时在训练和推理方面也保持快速。这就是为什么它们在推荐系统中很有用，推荐系统需要在几毫秒内对大型目录进行排名，每天数十亿次。 有一个警告 - FM 在 𝒙 的任何一个组件中都是线性的。这就是为什么在将数值特征输入到 FM 之前，通常会对其进行量化或分箱的原因。在这项工作中，我们建议通过使用给定的基础来混合一组系数向量，在与某些数值特征 𝑥ᵢ 相对应的嵌入空间中学习参数曲线 𝒗ᵢ(𝑥ᵢ)。 从理论角度来看，这概括了分箱，因为区间指示函数的基础正是分箱。此外，作为任何一个特征的函数，模型都变成由给定基础跨越的非线性函数，并且作为任何两个特征的函数，它变成由基础张量积跨越的非线性函数。 从实际的推荐系统角度来看，B 样条基础是一个很好的候选者，因为它结合了由于稀疏性而导致的快速计算和强近似特性。例如，考虑四个特征：电影类型、用户国家/地区、自上次访问以来的时间以及自首次登录以来的时间。对于给定的类型、国家和自上次访问以来的时间，我们的模型是自首次登录以来的时间的样条函数。对于给定的类型和国家，我们的模型变为自上次访问以来的时间和自上次登录以来的时间的张量积样条。对于另一个类型和国家，它是不同的张量积样条。这正是我们所需要的推荐系统的个性化方面。使用分解机的这个简单技巧有助于在推理和训练时保持极快的速度，同时显着提高性能。  我们通过一组数值实验和对在线广告产品的实际流量的 A/B 测试证实了我们的说法。  David Rügamer 在他的 AISTATS 2024 论文“可扩展的高阶张量积样条模型”中同时开发了类似的模型，但遵循了不同的路径 - 扩展到更高阶的分解，而不是更广泛的分解机系列。一篇很棒的论文 - 我也推荐大家阅读它！    提交人    /u/alexsht1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrpuix/r_numerical_features_with_factorization_machines/</guid>
      <pubDate>Thu, 02 Jan 2025 09:15:03 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python [P] 对数千个自定义文档进行自然语言查询的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrfexb/whats_the_best_way_to_natural_language_query/</link>
      <description><![CDATA[我使用项目管理软件，每个项目可能存储了 1,000 份文档和记录，而且每天都会添加新文档和记录。我希望能够使用自然语言查询这些信息，并试图找出解决此问题的方法。 我做了一些初步研究，发现了几种方法： (1) 使用这些自定义文档和记录的详细信息创建一个微调的 LLM 模型 (2) 包括文档和记录的相关详细信息记录并提示现有的 LLM 模型（我猜这涉及将嵌入存储在向量数据库中并构建搜索算法以确定需要将哪些文档子集包含在提示中。 (3) 找到一个可以做到这一点的现有工具（可能是 Elastic Search？） 用例可能是：“提供承包商不遵守合同条款的例子”。 “突出显示进度报告中未明确指出的三大关注点”。 （即解决方案需要对项目管理的上下文理解超出自定义文档中包含的内容）    提交人    /u/cbooty   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrfexb/whats_the_best_way_to_natural_language_query/</guid>
      <pubDate>Wed, 01 Jan 2025 23:16:06 GMT</pubDate>
    </item>
    <item>
      <title>[R]AST+速记+HybridRag</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hrej5v/rastshorthandhybridrag/</link>
      <description><![CDATA[        提交人    /u/stonedoubt   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hrej5v/rastshorthandhybridrag/</guid>
      <pubDate>Wed, 01 Jan 2025 22:35:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢所有人在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</guid>
      <pubDate>Sun, 29 Dec 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>