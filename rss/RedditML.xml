<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 29 Jan 2024 09:13:34 GMT</lastBuildDate>
    <item>
      <title>[P] 用于检测命令和控制流量的机器学习模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adqq3r/p_machine_learning_model_to_detect_command_and/</link>
      <description><![CDATA[您好， 我正在尝试训练一个能够检测 C2 或 C&amp;C 流量的机器学习模型。 我需要找到一个具有“正常”特征的正确地面实况数据集。和“C2”流量最好按 50/50 分割。 如果有人有任何潜在来源可供我用来查找甚至帮助创建个人数据集，我将不胜感激。    由   提交/u/Hiwolf25  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adqq3r/p_machine_learning_model_to_detect_command_and/</guid>
      <pubDate>Mon, 29 Jan 2024 08:43:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对语音进行评分和评估的最佳开源模型是什么？需要 Azure 语音工作室中的发音评估的开源替代方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adpv2k/d_what_is_the_best_open_source_model_to_score_and/</link>
      <description><![CDATA[我找不到任何 Azure 发音评估的开源替代方案。有哪些最好的开源模型可以提供类似的语音和发音评估并且可以自行托管？   由   提交 /u/Moist-Pirate-7181   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adpv2k/d_what_is_the_best_open_source_model_to_score_and/</guid>
      <pubDate>Mon, 29 Jan 2024 07:44:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求资源 RAG（检索增强生成）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adplfk/d_seeking_resources_rag_retrievalaugmented/</link>
      <description><![CDATA[寻求 RAG（检索增强生成）资源以从头开始构建（应包含每个组件，包括通过下载抓取（或）文档）。寻找 Colab 友好的笔记本电脑，最好是尺寸合适的模型来进行实验。任何建议或链接都​​非常感谢！  注意：我计划将其扩展到一些随机文档以了解这些内容。  🚀 #RAG #GoogleColab   由   提交/u/darkknight-6  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adplfk/d_seeking_resources_rag_retrievalaugmented/</guid>
      <pubDate>Mon, 29 Jan 2024 07:25:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 域适应中跨域“对齐”是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adpc70/d_what_does_aligned_across_domains_in_domain/</link>
      <description><![CDATA[基本上，有一个作品深入研究眼底图像分析中开集域适应的局部特征 | SpringerLink 他们提出通过利用视网膜眼底图像中的局部斑块/区域来进行开放集域适应。 在花了几周时间试图理解他们的工作之后，我仍然不明白他们如何定义或者考虑如何可以将2个簇原型(平均值)i、j视为“对齐”。或“未对齐”？ 我在 聚类 - “对齐”是什么意思？领域适应中的跨领域？ - 人工智能堆栈交换并向他们发送了 3 次电子邮件，但根本没有回复。 这是他们在强调自己的贡献时所说的：提出（CCA）方法来强制执行跨域对齐集群的本地特征保持靠近，同时将未对齐集群的本地特征推得很远。 任何人都可以帮忙吗？谢谢。 ​   由   提交/u/Soggy_Ad6925   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adpc70/d_what_does_aligned_across_domains_in_domain/</guid>
      <pubDate>Mon, 29 Jan 2024 07:08:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进行直接偏好优化 (DPO) 的正确方法是什么？为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adnq4u/d_whats_the_proper_way_of_doing_direct_preference/</link>
      <description><![CDATA[      出于某种原因，我无法全神贯注于 DPO 的数据分发问题。论文中写道： https ://preview.redd.it/6c9z61o4bbfc1.png?width=2164&amp;format=png&amp;auto=webp&amp;s=c6b5ed46937da04e5912023e2f46ae7821a9a446 我的问题是：为什么它如此重要偏好数据分布与参考模型输出分布一致吗？我的理解是，在训练过程中，sft的参数会更新，使得选择的响应（y_w）生成的概率更高，而拒绝的响应（y_l）生成的概率更低，并且参考模型就在那里以防止 sft 模型偏离原始参数太远。但我不明白错误的参考分布如何阻碍这个过程。有人可以帮我吗？   由   提交/u/aaaprocrastinating   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adnq4u/d_whats_the_proper_way_of_doing_direct_preference/</guid>
      <pubDate>Mon, 29 Jan 2024 05:30:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不懂基础的LLM专家？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</link>
      <description><![CDATA[我最近遇到了很多人，他们知道 LLM 领域中不同技术的所有奇特缩写词，诚然我也是新手但越来越明显的是，他们甚至不知道 DL 的基础知识，比如背景是什么或其他经典概念。 这是否会成为现状，因为 LLM 领域更倾向于配置而不是做事从零开始？ 还有，这些人真的可以被认为是法学硕士还是表面上的专家？    由   提交/u/Plus_Tough_7497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</guid>
      <pubDate>Mon, 29 Jan 2024 04:13:30 GMT</pubDate>
    </item>
    <item>
      <title>什么是最好的 OCR（光学字符识别）。需要 PDNod 和 Google 的开源替代品 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adlvco/what_is_the_best_ocr_optical_character/</link>
      <description><![CDATA[PDnod 翻译非常准确且良好。我想要一个能够处理准确的句子小屏幕截图的软件。 我测试了一些类似 Tesseract 的软件，但在视频中尝试中文文本时它们无法正确处理。有谁知道 Tesseract 的更好的开源替代品吗？   由   提交 /u/RichCyph   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adlvco/what_is_the_best_ocr_optical_character/</guid>
      <pubDate>Mon, 29 Jan 2024 03:50:46 GMT</pubDate>
    </item>
    <item>
      <title>搜索给定特定方法的 ML 论文 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adk739/searching_for_ml_papers_given_a_specific_approach/</link>
      <description><![CDATA[大家好。我经常遇到这个问题，我会想到一种解决机器学习问题的特定方法，并尝试寻找类似的论文。然而，我不知道这些论文到底怎么称呼它，或者他们只是描述相同的方法略有不同。无论如何，我的搜索结果通常没有多大帮助。 在这种情况下您会做什么？我刚刚开始从事机器学习研究，所以我还没有读过那么多论文。是否有一种工具可以通过理解所采用方法的描述来对研究论文数据库进行上下文搜索？   由   提交/u/genesis_2602   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adk739/searching_for_ml_papers_given_a_specific_approach/</guid>
      <pubDate>Mon, 29 Jan 2024 02:26:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么假设使用 NN 连接隐式学习和存储信息比可学习向量更优化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adipfr/d_why_is_it_assumed_that_using_nn_connections_to/</link>
      <description><![CDATA[大多数学习网络都遵循类似的模式：获取一些输入数据，嵌入到一些输入向量中，然后在给出一些输入之前堆叠这些向量之间的连接模式所需的输出。对于一个简单的 NLP 示例，您从句子的一些嵌入开始，让这些单词标记相互关注，使用 FF 层让向量的元素连接到自身，然后重复（过度简化的转换器），然后让它预测下一个令牌。通常给出的直觉是，我们让网络通过反向传播更新权重来学习输入数据之间的复杂关系。从转换输入数据的角度来看，这是有道理的，但很明显大型模型正在记忆信息。例如，chatgpt 可以轻松重复著名事件的日期。如果我想将这些数据存储在网络之外，我只需显式编码一个向量来表示它，而不是尝试将其建模为单词或其他潜在对象之间的一系列复杂连接，这看起来会更加复杂并且效率较低。同样，我可以让输入关注一组可学习的标记，而不仅仅是在网络中的输入数据之间创建连接，该模型可以使用这些标记来编码世界信息。您可能希望与输入/输入注意交错，但似乎可学习的标记将为网络提供更有效，或者至少更明确的数据存储方法。我见过的最接近的是一些网络用于修改输入令牌的可学习位置嵌入，或者来自 https://arxiv.org 的 VIT 寄存器/abs/2309.16588 ，但它们对学习输入向量的使用仍然非常有限。我们不使用可学习向量是否有数学原因，或者论文表明它们不如更多的连接？    由   提交 /u/Revolutionary-Fig660    reddit.com/r/MachineLearning/comments/1adipfr/d_why_is_it_assumed_that_using_nn_connections_to/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adipfr/d_why_is_it_assumed_that_using_nn_connections_to/</guid>
      <pubDate>Mon, 29 Jan 2024 01:12:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有人可以解释一下“Hopfield Networks is all you Need”中的 3 种 Hopfield 层之间的区别吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adhdgh/r_can_someone_please_explain_the_differences/</link>
      <description><![CDATA[我是一名认知神经科学博士。我是一名对更先进的机器学习方法相对较新的学生，我正在尝试将 Hopfield 层合并到关联记忆建模中 - 特别是将特定环境中的特定刺激与奖励和惩罚相关联。虽然我能够在很大程度上关注与本文相关的博客文章，但我很难理解3种hopfield层之间的差异。明白的人可以像我五岁一样解释一下吗？非常感谢！   由   提交 /u/TiredEel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adhdgh/r_can_someone_please_explain_the_differences/</guid>
      <pubDate>Mon, 29 Jan 2024 00:07:46 GMT</pubDate>
    </item>
    <item>
      <title>您在工作中是否拥有产品专业的法学硕士？如果是这样，那又是为了什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adbbnv/do_you_have_llms_in_prod_at_work_if_so_what_for_d/</link>
      <description><![CDATA[请随意在评论中扩展诸如任务（RAG、聊天机器人、工具、seq2seq 等）模型大小、部署策略、缺点等信息，未来计划等 就我而言：任务：RAG 模型：zephyr 7B 部署：vLLM 未来计划：内部文档预训练 + 聊天微调 &lt;!-- SC_ON - -&gt;  由   提交/u/masc98  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adbbnv/do_you_have_llms_in_prod_at_work_if_so_what_for_d/</guid>
      <pubDate>Sun, 28 Jan 2024 19:51:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] WhisperS2T 的 TensorRT-LLM 后端（比 CTranslate2 加速约 2 倍）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad6xuz/p_tensorrtllm_backend_for_whispers2t_2x_speedup/</link>
      <description><![CDATA[大家好！我很高兴地宣布我的开源语音转文本工具包 WhisperS2T 针对 OpenAI Whisper 模型进行了重大更新。 添加了 TensorRT-LLM 支持：  ~ 2 倍推理加速：WhisperS2T 现在支持 TensorRT-LLM 后端，与 CTranslate2 后端相比，推理速度提高了一倍！目前 A30 GPU 上的最佳配置可以在大约 18 秒内实现 1 小时文件的转录。 据我所知，这是 TensorRT-LLM 在 Whisper 上的第一个正确实现，具有批处理和结束功能- 到终端 ASR 管道。  即用型 Google Colab 笔记本：我添加了一些快速的 Google Colab 笔记本，以便轻松试用WhisperS2T：https://github.com/shashikg/WhisperS2T/tree/main/notebooks 查看笔记本日志！在 T4 GPU (Google Colab) 上，使用 WhisperS2T 和 TensorRT-LLM 后端（使用 Whisper Large v2 模型）转录 150 分钟的音频文件仅需约 2.5 分钟。 模型导出注意：  经过 TensorRT-LLM 优化后，导出的模型仅适用于具有相同 cuda_compute_capability 的 NVIDIA GPU。这意味着在 T4 GPU 上导出的模型无法在 A100 上运行，反之亦然。 需要帮助：模型导出大约需要 3-6 分钟。有志愿者可以导出特定 GPU 的模型并分享吗？这将对社区有巨大的帮助！如果有兴趣，请查看：https://github.com/shashikg/WhisperS2T/issues/8 干杯，Shashi P.S.不要忘记查看 GitHub 存储库：https://github.com/shashikg/WhisperS2T   由   提交/u/Financial-Beach1587  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad6xuz/p_tensorrtllm_backend_for_whispers2t_2x_speedup/</guid>
      <pubDate>Sun, 28 Jan 2024 16:49:27 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何让我的训练更快？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad6j2i/d_how_to_make_my_training_faster/</link>
      <description><![CDATA[我使用 DNA 序列作为深度学习模型的输入，我将它们保存为 h5 文件中的一个热编码 numpy 数组。我的数据集有 700k 个示例，大小为 500Go。我想让训练更快，所以我有一堆问题：  将它们存储为 h5 文件中的一维数组（数字而不是一种热编码）然后转换它们是否更好在加载过程中使用一个热编码数组会加快速度吗？ lmdb 格式或 hdf5 格式哪种加载效率更好 &lt; p&gt;我使用dataloaders，基于什么我应该选择num-workers，它应该等于核心数吗？  关于如何进行训练的任何其他建议快点 ？我正在使用 GCP，因此欢迎任何可能降低成本的建议 PS：GPU：V100 CPU：8 核 RAM：15Go 模型：具有 16 个块和 600k 参数的 Resnet 输入：大小（15000,4）    由   提交 /u/bkffadia   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad6j2i/d_how_to_make_my_training_faster/</guid>
      <pubDate>Sun, 28 Jan 2024 16:31:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 中的 OUTPUT 嵌入是什么？它从何而来？ （不是输入嵌入）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad1o11/d_what_are_the_output_embeddings_in_transformer/</link>
      <description><![CDATA[       由   提交 /u/ShlomiRex   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad1o11/d_what_are_the_output_embeddings_in_transformer/</guid>
      <pubDate>Sun, 28 Jan 2024 12:31:51 GMT</pubDate>
    </item>
    </channel>
</rss>