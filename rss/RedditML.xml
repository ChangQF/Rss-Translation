<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Mon, 17 Jun 2024 09:16:12 GMT</lastBuildDate>
    <item>
      <title>[R] 通过蒙特卡洛树自优化和 LLaMa-3 8B 访问 GPT-4 级数学奥林匹克解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dhrfjk/r_accessing_gpt4_level_mathematical_olympiad/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dhrfjk/r_accessing_gpt4_level_mathematical_olympiad/</guid>
      <pubDate>Mon, 17 Jun 2024 06:24:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlphaMath Almost Zero：无需流程的流程监督</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dhr5sy/r_alphamath_almost_zero_process_supervision/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dhr5sy/r_alphamath_almost_zero_process_supervision/</guid>
      <pubDate>Mon, 17 Jun 2024 06:04:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 创造力已不再是话题：消除语言模型偏见的代价</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dhqs9g/r_creativity_has_left_the_chat_the_price_of/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dhqs9g/r_creativity_has_left_the_chat_the_price_of/</guid>
      <pubDate>Mon, 17 Jun 2024 05:39:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 练习中注意力下降</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dhq23d/d_attention_sinks_in_practice/</link>
      <description><![CDATA[SOTA 开源模型中是否有使用“注意力接收器”的例子（使用可学习的注意力接收器进行预训练，并在推理期间默认使用）？这似乎是一种直观的改进，但除了这些论文之外，我还没有听说过关于这个想法的任何消息。 具有注意力接收器的高效流式语言模型 视觉变压器需要寄存器    提交人    /u/Realistic-Row-8098   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dhq23d/d_attention_sinks_in_practice/</guid>
      <pubDate>Mon, 17 Jun 2024 04:51:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年弱监督学习的进展如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dho29p/d_what_is_the_progress_on_weakly_supervised/</link>
      <description><![CDATA[弱监督学习中的一个热门话题是标签噪音。LLM 会受到标签噪音的影响吗？或者 LLM 可以解决标签噪音的问题吗？你认为这项研究仍然值得吗？    提交人    /u/EducationalOwl6246   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dho29p/d_what_is_the_progress_on_weakly_supervised/</guid>
      <pubDate>Mon, 17 Jun 2024 02:51:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从头开始​​的混合精度训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dhlh0z/p_mixed_precision_training_from_scratch/</link>
      <description><![CDATA[我在 2 层 MLP 上重新实现了 Nvidia 的原始混合精度训练论文（https://arxiv.org/abs/1710.03740）。我一直深入到 CUDA 领域来展示 TensorCore 激活，在我看来，这是混合精度训练的真正秘密。 代码：https://github.com/tspeterkim/mixed-precision-from-scratch 撰写：https://tspeterkim.github.io/posts/mixed-precision-from-scratch    提交人    /u/droidarmy95   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dhlh0z/p_mixed_precision_training_from_scratch/</guid>
      <pubDate>Mon, 17 Jun 2024 00:28:51 GMT</pubDate>
    </item>
    <item>
      <title>[D],[P] 关于句子转换器库的疑问</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9rxe/dp_doubt_regarding_sentence_transforrmers_library/</link>
      <description><![CDATA[      嗨，我的工作是为不同的 LLMS（如 BERT、Gemma、Llama 等）创建句子嵌入。我想知道我是否可以使用 Sentence Transformers 库来实现相同。然而，进一步深入研究后，我发现它只有几个针对相同内容的预训练模型。有人可以对此提供澄清吗？提前致谢。 https://preview.redd.it/6b8uq48day6d1.png?width=1431&amp;format=png&amp;auto=webp&amp;s=d4d5c0ab164d0ebdf97f2a61303a5fee7167968d    提交人    /u/nani_procastinator   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9rxe/dp_doubt_regarding_sentence_transforrmers_library/</guid>
      <pubDate>Sun, 16 Jun 2024 15:16:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] ECAI 2024 评论讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9n4e/d_ecai_2024_reviews_discussion/</link>
      <description><![CDATA[ECAI 2024 评论讨论帖。    由   提交  /u/Fun_Equal5145   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9n4e/d_ecai_2024_reviews_discussion/</guid>
      <pubDate>Sun, 16 Jun 2024 15:10:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从头开始​​实现指令微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh7cmv/p_instruction_finetuning_from_scratch/</link>
      <description><![CDATA[        提交人    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh7cmv/p_instruction_finetuning_from_scratch/</guid>
      <pubDate>Sun, 16 Jun 2024 13:14:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 理解 LoRA：低秩近似的视觉指南，用于有效微调 LLM。🧠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh4s3x/r_understanding_lora_a_visual_guide_to_lowrank/</link>
      <description><![CDATA[      TL;DR：LoRA 是参数高效微调 (PEFT) 方法。它通过使用低秩自适应解决了以前的微调技术的缺点，低秩自适应侧重于有效地近似权重更新。这显著减少了微调中涉及的参数数量 10,000 倍，并且仍然收敛到完全微调模型的性能。 这使得它在成本、时间、数据和 GPU 方面高效，而不会损失性能。 什么是 LoRA 以及为什么它对于模型微调至关重要：视觉指南。 https://preview.redd.it/v2plu0mvvw6d1.png?width=1456&amp;format=png&amp;auto=webp&amp;s=e5f74bcb777d305c08bc74274b0c8a7cc63c973e    提交人    /u/ml_a_day   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh4s3x/r_understanding_lora_a_visual_guide_to_lowrank/</guid>
      <pubDate>Sun, 16 Jun 2024 10:34:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用滤波器组/基于索引的访问进行卷积层的 NN 压缩的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh4cqn/d_papers_in_nn_compression_using_filter/</link>
      <description><![CDATA[我一直在尝试一种减少网络二进制大小（也许还有运行时间）的方案，即使用一种方案来训练网络，该方案强制网络中不同层的相同大小的各个卷积滤波器之间的余弦相似性。 假设一个最佳情况，即来自最大卷积层的所有滤波器都可以在其他层中重复使用，其余层可以将索引存储到相关滤波器中，而这在很大程度上取决于滤波器组的大小。 总的来说，我可以看到一个解决方案，它有一个包含所有必要权重的数组，这些权重是为缓存命中优化而预先排序的，而网络只是保存指向各种滤波器的指针。 有没有关于这种可行性的研究？    提交人    /u/SlayahhEUW   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh4cqn/d_papers_in_nn_compression_using_filter/</guid>
      <pubDate>Sun, 16 Jun 2024 10:03:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 减少倾斜损失的一种有趣方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh2aqt/p_an_interesting_way_to_minimize_tilted_losses/</link>
      <description><![CDATA[前段时间，我读了一篇关于所谓的倾斜经验风险最小化的论文，后来又读了同一位作者的一篇 JMLR 论文：https://www.jmlr.org/papers/v24/21-1095.html 这样的公式让我们能够以更“公平”的方式对困难样本进行训练，或者相反，如果这些困难样本实际上是异常值，则对这些困难样本的敏感度会降低。但最小化它在数字上具有挑战性。所以我决定尝试在博客文章中设计一种补救措施。我认为这是一个有趣的技巧，在这里很有用，我希望你也会发现它很好： https://alexshtf.github.io/2024/06/14/Untilting.html    提交人    /u/alexsht1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh2aqt/p_an_interesting_way_to_minimize_tilted_losses/</guid>
      <pubDate>Sun, 16 Jun 2024 07:27:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] OOD 泛化在 LLM 时代还有未来吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh1eox/d_is_ood_generalization_still_a_future_in_the_llm/</link>
      <description><![CDATA[我认为 OOD 泛化是一个重要问题，因为它拉近了与现实的距离。但我担心最近的会议（如 ICLR、ICML、NeurIPS 等）没有很多人研究这个问题。查看一些 OOD 泛化基准，许多方法（如 IRM、GroupDRO）甚至比 ERM 更弱。所以，我想知道是不是因为这个领域的一些困难人们停止了研究。还是因为其他原因。    提交人    /u/EducationalOwl6246   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh1eox/d_is_ood_generalization_still_a_future_in_the_llm/</guid>
      <pubDate>Sun, 16 Jun 2024 06:23:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 1D CNN 在波形和频谱图上与 2D CNN 性能对比</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dgyjum/d_1d_cnn_on_waveforms_and_spectrograms_vs_2d_cnn/</link>
      <description><![CDATA[大多数成功的音频框架都使用二维卷积神经网络 (CNN)，这违反直觉，因此我尝试在 Kaggle 上的 BirdCLEF-2024 上使用简单框架进行训练时进行实验，并且我对学习有一些疑问：  在学习波形输入时，为什么 1D CNN 不会收敛，甚至在验证分割时立即发散？ 在对频谱图幅度 (stft -&gt; abs -&gt; log1p) 进行训练时，为什么 1D CNN 的表现比 2D CNN 差？ 虽然频谱图在获取幅度时似乎会丢失相位偏移信息，但它的表现优于原始波形。那么，人类/动物耳朵里是否有 torch.stft 以获得更好的感知？例如，孩子们可以听懂“从未见过”的高音调米老鼠讲话。     submitted by    /u/ivanstepanovftw   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dgyjum/d_1d_cnn_on_waveforms_and_spectrograms_vs_2d_cnn/</guid>
      <pubDate>Sun, 16 Jun 2024 03:18:46 GMT</pubDate>
    </item>
    </channel>
</rss>