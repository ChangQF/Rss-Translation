<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 11 Sep 2024 15:17:29 GMT</lastBuildDate>
    <item>
      <title>[D] 冷扩散：无噪声反转任意图像变换</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fec2jq/d_cold_diffusion_inverting_arbitrary_image/</link>
      <description><![CDATA[大家好， 这篇文章的目的不是责怪作者，我只是对审查过程感到非常惊讶。 我刚刚偶然发现了这篇论文。虽然我发现这些想法有点有趣，但我发现整体结果和理由非常薄弱。 它显然被 ICLR2022 拒绝了，主要是因为缺乏任何理论依据。https://openreview.net/forum?id=slHNW9yRie0 同一篇论文在 NeurIPS2023 上重新提交，我不骗你，这篇论文被接受为海报。 https://openreview.net/forum?id=XH3ArccntI 我真的不明白它是如何通过 NeurIPS 的审查过程的。整个事情非常初步，基本上只是由实验组成。 它甚至缺少其他非常密切相关的工作的引用，例如具有逆热耗散的生成建模 https://arxiv.org/abs/2206.13397，这基本上是他们的“模糊扩散”但具有理论背景和更好的结果（被 ICLR2023 接受）... 我以为 NeurIPS 与 ICLR 处于同一水平，但现在在我看来，有时论文只是被随机接受。 所以我想知道，是否有人对此有意见，或者您是否遇到过其他类似的情况？    提交人    /u/Commercial_Carrot460   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fec2jq/d_cold_diffusion_inverting_arbitrary_image/</guid>
      <pubDate>Wed, 11 Sep 2024 14:52:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 免费工具可为您的项目查找和比较 AI 模型 - 它对您有用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1feabhe/p_free_tool_to_find_and_compare_ai_models_for/</link>
      <description><![CDATA[您好！ 正如标题所示，我们构建了一个免费工具（某些功能需要注册），我认为这对社区中的 ML 观察者和从业者很有用。目前，我们专注于 NLP 模型。 我想知道您是否愿意使用它，并听听您的意见。 Elementera Model Navigator：用于查找和比较项目的 AI 模型的免费工具 简单介绍一下它背后的故事，在为项目实现 AI 功能时，我们（以及我们交谈过的许多人）经常会遇到必须选择 AI 模型但不确定哪个模型最适合我们的约束或从哪里开始的情况。 不幸的是，“只使用 chatgpt”的建议并不总是好的。如果我想要一个开源模型怎么办？它支持哪些语言？上下文窗口大小或参数数量如何？目前已经有成千上万的 AI 模型，其中许多模型非常适合解决某些问题。 这就是为什么我们将产品的这一部分作为免费工具来帮助导航 AI 模型（目前为 NLP 模型）。希望它能成为社区的有用资源。 请随时向我们提供反馈并与我们联系！ Elementera - https://elementera.com/ 提前致谢！    提交人    /u/Elementera   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1feabhe/p_free_tool_to_find_and_compare_ai_models_for/</guid>
      <pubDate>Wed, 11 Sep 2024 13:37:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] Tetris Gymnasium：可定制的俄罗斯方块强化学习环境</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fea3tn/p_tetris_gymnasium_a_customizable_reinforcement/</link>
      <description><![CDATA[今天，Tetris Gymnasium 的第一个版本发布了，对于从事强化学习相关工作或想要涉足该领域的人来说，这可能很有趣。 这是什么？Tetris Gymnasium 是 Tetris 作为强化学习环境的简洁实现，并与 Gymnasium 集成。它可以自定义（例如棋盘尺寸、重力等），并包含许多有关如何使用它的示例，如训练脚本。 为什么是俄罗斯方块？尽管许多 Atari 游戏在强化学习方面取得了重大进展，但俄罗斯方块仍然是 AI 面临的一个挑战。它结合了 NP 难复杂性、随机元素和长期规划需求，使其成为强化学习研究中一个持续存在的未解问题。到目前为止，还没有出版物可以在不使用手工制作的特征向量或其他简化的情况下很好地与游戏配合使用。 我能用它做什么？请不要犹豫，尝试一下该环境以进入强化学习。好处是俄罗斯方块很容易理解，你可以观看代理玩并清楚地看到它所犯的错误。如果您已经进入 RL，您可以将其用作可自定义的环境，可以很好地与其他框架（如 Gymnasium 和 W&amp;B）集成。 GitHub：https://github.com/Max-We/Tetris-Gymnasium 在存储库中，您还可以找到我们的短文“逐一：为俄罗斯方块组装模块化强化学习环境”的预印本其中更详细地解释了背景、实施情况以及学生和研究人员的机会。 如果您尝试该环境，欢迎您留下星星或打开一个问题！    提交人    /u/Npoes   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fea3tn/p_tetris_gymnasium_a_customizable_reinforcement/</guid>
      <pubDate>Wed, 11 Sep 2024 13:27:30 GMT</pubDate>
    </item>
    <item>
      <title>人脸遮挡检测 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fe98hw/face_occlusion_detection_d/</link>
      <description><![CDATA[我正在研究人脸遮挡检测。我想开发一种人脸检测系统，其中 True Positive 包括检测单张人脸，即使人脸被手部分遮挡、稍微向左或向右倾斜或闭上眼睛。系统必须在这些条件下可靠地识别此类人脸，以确保准确检测。另一方面，True Negative 包括拒绝完全或部分被围巾或口罩遮挡的人脸、仅部分可见的人脸或方向超过设定阈值的人脸。系统还应避免在画面中检测多张人脸，无论它们与相机的距离如何，以及画面中存在多张部分可见的人脸的情况。这可确保仅正确检测到所需的人脸配置，同时避免出现模糊或意外情况。 我尝试了多模式方法，使用 Yunet.onnx 模型进行了多张人脸检测，效果非常好。之后，对于面部方向，我使用了 Mediapipe，计算了颈部和鼻子的斜率以及肩部斜率，并在彻底校准后设置了阈值，它也运行良好。关于遮挡检测，我暂时使用了 Haar-Cascades 正面人脸模型，它给出了很高的假阴性结果。 有人可以建议一种遮挡检测方法吗    提交人    /u/Fantastic-Race-6701   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fe98hw/face_occlusion_detection_d/</guid>
      <pubDate>Wed, 11 Sep 2024 12:46:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在这里想做什么？对 SVM 可解释性想法进行健全性检查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fe7jgu/d_what_am_i_trying_to_do_here_sanity_check_for/</link>
      <description><![CDATA[我已经实现了一个使用高斯 RBF 和标准化特征（Z 分数）的 SVM 分类器。它完全用 Rust 编写，并且位于没有互联网访问的机器上，并且无法访问可以轻松计算 Shapley 值或 LIME 的平台。正确性、速度和可移植性是我们的目标。 我有一个快速有效的可解释性想法，但我想检查这是否是一种合理的做事方式。 本质上，正常运行模型并生成分类和距离值（就像它目前所做的那样）。然后，为每个特征重新运行一次模型（例如，30 个特征 = 30 次额外运行）。对于每次运行：  将感兴趣的特征的 Z 分数归零， 重新运行预测并生成新的距离值。将此新值与原始值进行比较以产生“偏移量” 保存并报告这 30 个偏移量，并根据 |abs| 对它们进行排序。偏移量的符号表示对最终预测的影响的方向性  这是个东西吗？有名字吗？还是这很蠢？ 谢谢    提交人    /u/racetrack9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fe7jgu/d_what_am_i_trying_to_do_here_sanity_check_for/</guid>
      <pubDate>Wed, 11 Sep 2024 11:13:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人能解释一下伪装物体检测（COD）吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fe51w1/d_can_anyone_explain_camouflaged_object_detection/</link>
      <description><![CDATA[注意：我是一名大四本科生，并不是一名经验丰富的研究人员。 伪装物体检测 (COD) 是计算机视觉领域的一项专门任务，专注于识别与周围环境融为一体、难以检测的物体。COD 尤其具有挑战性，因为这些物体被有意或自然地设计成与背景难以区分。 我不明白的是：COD10K 等数据集包含地面实况蒙版，可勾勒出伪装物体的确切形状。但是，如果物体与背景融为一体，那么使用哪些特征来区分物体和背景？当物体没有被伪装时，这会变得相对容易，因为物体通常具有可区分的特征，例如边缘、颜色或纹理，以将其与背景区分开来。    提交人    /u/_My__Real_Name_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fe51w1/d_can_anyone_explain_camouflaged_object_detection/</guid>
      <pubDate>Wed, 11 Sep 2024 08:18:55 GMT</pubDate>
    </item>
    <item>
      <title>[D]NanoBPE：MicroBPE 的仿制品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fe3hgv/dnanobpe_an_imitation_of_microbpe/</link>
      <description><![CDATA[花了一个晚上深入研究一个有趣的业余项目 - 模仿 Andrej Karpathy 的 microBPE。看到字节对编码 (BPE) 如何应用于 NLP 之外，这令人着迷，它解锁了在推荐系统和下游事件处理等领域识别频繁长序列的新方法。期待进一步探索其潜力！ https://github.com/ickma/nanobpe    提交人    /u/Potential-Dingo-6424   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fe3hgv/dnanobpe_an_imitation_of_microbpe/</guid>
      <pubDate>Wed, 11 Sep 2024 06:21:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 谁是好孩子？Metropolis-Hastings 方法用于确定来源不明的寄养狗名字</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdzemt/r_whos_a_good_boy_a_metropolishastings_approach/</link>
      <description><![CDATA[  由    /u/TobyWasBestSpiderMan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdzemt/r_whos_a_good_boy_a_metropolishastings_approach/</guid>
      <pubDate>Wed, 11 Sep 2024 02:18:39 GMT</pubDate>
    </item>
    <item>
      <title>研究出版问题 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdx2e3/research_publication_questions_r/</link>
      <description><![CDATA[我今年获得了生物信息学硕士学位，并一直与一位教授合作进行研究。我们研究了两个不同的研究课题，但我指的是第二个。这位教授是一位数据科学教授，专门教授机器学习，他来自我大学的另一所学院。 所以当我遇到他时，第二个项目是基于机器学习的，带有一些生物信息学，当然我需要做所有事情。他会给我一些建议，并试着和我一起理解这些东西，但他不做生物信息学，所以我需要自己弄清楚预处理的东西，这不是最难的部分。困难的部分是试图弄清楚如何让他或在我之前的其他学生选择使用 ML 工具来完成任务。那两个学生没有做出太多贡献就离开了，他们是计算机科学专业的哈哈。这个 ML 工具有很多问题，没有完整的文档。尽管如此，我还是让它在学校的 hpc 上运行起来了。 长话短说，数据是单细胞 RNA 序列数据，ml 工具使用随机森林回归来推断基因调控网络。这只是预测转录因子、靶基因对/边缘。 问题是我没有得到好的指标。有很多过度拟合的迹象。我尝试获取训练集的 r 平方分数，并将其与测试集的分数进行比较，并且每个目标基因始终给出比测试分数好得多的训练分数。 我的教授只是想让我给他一份我周五刚刚提交的最终提交论文。但在那篇论文中，我也让他知道，我解释说由于指标，结果并不可靠。我还谈到了我可以改进的地方，以尝试获得更好的评估指标。教授知道到目前为止评估指标并不好，仍然要求提交一份已准备好提交的论文，而我刚刚提供了这份论文。 我想问你们所有人：我是否可以提交一篇我知道结果不可靠的论文，即使我在论文中提到了这一点？这在研究界会被看不起吗？我相信这绝对比伪造评估指标和数据并冒充我的工作可靠要好，就像其他一些大学的学者所做的那样，导致许多论文被召回。但提交一些没有突破性的东西是件好事吗？    提交人    /u/chaosOblivionkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdx2e3/research_publication_questions_r/</guid>
      <pubDate>Wed, 11 Sep 2024 00:16:09 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待 T-FREE 减少嵌入的词汇量 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fduqr5/what_do_you_think_of_tfree_to_reduce_the/</link>
      <description><![CDATA[      嘿 r/MachineLearning！ 我刚刚发表了第二篇博客文章，分析了一篇有趣的新论文：T-FREE：通过稀疏表示实现无标记器生成式 LLM，实现内存高效嵌入。您可以在此处查看我的完整分析。 编码阶段 作者提出了一种有趣的方法，使用类似于局部敏感哈希的技术来减少嵌入矩阵的词汇量。以下是其流程的细分：  应用空白标记器将句子拆分为单词：&quot;hello world !&quot; -&gt; [&quot;hello&quot;, &quot;world&quot;, &quot;!&quot;] 在单词边界中添加特殊字符：[&quot;hello&quot;, &quot;world&quot;, &quot;!&quot;] -&gt; [&quot;_hello_&quot;, &quot;_world_&quot;, &quot;_!_&quot;] 将单词拆分为 3-grams：[&quot;_hello_&quot;, &quot;_world_&quot;, &quot;_!_&quot;] -&gt; [&quot;_he&quot;, &quot;hel&quot;, &quot;ell&quot;, &quot;llo&quot;, &quot;lo_&quot;, &quot;_wo&quot;, &quot;wor&quot;, &quot;orl&quot;, &quot;rld&quot;, &quot;ld_&quot;, &quot;_!_&quot;] 将每个 3-gram 哈希处理为多个嵌入矩阵索引：_hel -&gt; [hash1(&quot;_he&quot;) % v, hash2(&quot;_he&quot;) % v, hash3(&quot;_he&quot;) % v]（其中 v 是所选词汇量） 通过对每个单词内的所有三元词嵌入求和来创建词嵌入。  我已经创建了这个过程的可视化表示： https://preview.redd.it/hmvh7lwy42od1.png?width=765&amp;format=png&amp;auto=webp&amp;s=f14b4105c048b5ef019a3de06478aa5bb1beeb14 他们还提出了一个解码阶段，但它有点复杂。如果你有兴趣，可以查看我的[帖子](https://f14-bertolotti.github.io/posts/06-09-24-tfree/index.html)或他们的[论文](https://arxiv.org/abs/2406.19223)。 关键要点和注意事项  本文提出了一个引人注目的想法，总体来说写得很好，不过解码部分可以更详细一些。 解码阶段应用了两种不同的规范化（除以和，然后是 softmax），这似乎不太常规。 虽然该方法被宣传为无需 tokenizer，但它仍然使用空格标记器。“免训练标记器”可能更合适。 一个有趣的实验是使用带有完整词嵌入矩阵的标准解码阶段。虽然计算量很大，但我认为这可能是一个有趣的实验。  讨论 您对这种方法有何看法？您是否看到了潜在的局限性？    提交人    /u/f14-bertolotti   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fduqr5/what_do_you_think_of_tfree_to_reduce_the/</guid>
      <pubDate>Tue, 10 Sep 2024 22:25:43 GMT</pubDate>
    </item>
    <item>
      <title>机器学习理论研究经验对统计学博士申请有用吗？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdtz54/is_machine_learning_theory_research_experience/</link>
      <description><![CDATA[现在我和大学电子工程系的一位教授一起研究 ML 理论（一些深度学习架构的样本复杂性）。我想知道这对申请统计学博士课程是否有用。说实话，我认为“统计学”在这个项目中用得不多。这是否意味着与统计学系教授的其他项目相比，这个项目对我申请统计学博士课程的简历没有那么有用？    提交人    /u/mziycfh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdtz54/is_machine_learning_theory_research_experience/</guid>
      <pubDate>Tue, 10 Sep 2024 21:51:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformers Trainer 与 Pytorch 照明</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fdey5q/r_transformers_trainer_vs_pytorch_lighting/</link>
      <description><![CDATA[大家好， 我想知道你对这两个框架的看法。  它们有什么优缺点？ 如果要优先考虑效率，哪一个更好？或者它们之间的唯一区别是代码抽象和组织？ 最后，你知道任何同时使用它们的代码库吗？我想用它作为从一个框架转换到另一个框架的“模板”。 非常感谢！    提交人    /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fdey5q/r_transformers_trainer_vs_pytorch_lighting/</guid>
      <pubDate>Tue, 10 Sep 2024 10:52:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 能产生新颖的研究想法吗？一项有 100 多名 NLP 研究人员参与的大规模人类研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fddtmm/r_can_llms_generate_novel_research_ideas_a/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fddtmm/r_can_llms_generate_novel_research_ideas_a/</guid>
      <pubDate>Tue, 10 Sep 2024 09:35:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 08 Sep 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>