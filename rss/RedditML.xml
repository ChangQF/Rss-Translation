<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 01 Oct 2024 21:16:42 GMT</lastBuildDate>
    <item>
      <title>[D]《思想之树》为什么是一部有影响力的作品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/</link>
      <description><![CDATA[我的导师最近让我阅读这篇 tot 论文，但在我看来，这只是又一个**花哨的快速工程工作**。tot 过程需要大量人类智能（我们应该手动将问题分为不同的步骤，并设计验证器以使此方法有效），而且成本很高，我很少看到人们在工作中使用这种方法。 尽管如此，这篇论文还是收到了很多引用，考虑到我的导师让我阅读它的事实，我想知道我是否错过了关于这项工作的任何优点或重要含义。    提交人    /u/StraightSpeech9295   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/</guid>
      <pubDate>Tue, 01 Oct 2024 19:38:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 审稿人政策。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftux70/d_iclr_reviewer_policy/</link>
      <description><![CDATA[我们被告知，在今年的 ICLR 2025 上，摘要提交截止日期过后，将向作者发送一封电子邮件，邀请他们成为审稿人。但我们尚未收到这样的审稿人请求。有人收到过吗？    提交人    /u/Alternative-Talk1945   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftux70/d_iclr_reviewer_policy/</guid>
      <pubDate>Tue, 01 Oct 2024 18:14:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 可重复性声明</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftsp3j/d_iclr_reproducibility_statement/</link>
      <description><![CDATA[我正在向 ICLR 提交论文，想知道今年的可重复性声明是否计入页数限制？ 作者指南说不计入，但征文通知说只有参考文献和附录不计入页数限制。    提交人    /u/baghalipolo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftsp3j/d_iclr_reproducibility_statement/</guid>
      <pubDate>Tue, 01 Oct 2024 16:44:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] NotebookLM 背后的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftr2wt/d_research_papers_behind_notebooklm/</link>
      <description><![CDATA[有没有关于 Google NotebookLM 内部工作原理的技术信息？或者有没有与手头的系统相关的论文？ 编辑：更具体地说，我指的是在引用来源的同时检索大型文档中事实的能力。我不是在谈论播客功能。    提交人    /u/Log_Dogg   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftr2wt/d_research_papers_behind_notebooklm/</guid>
      <pubDate>Tue, 01 Oct 2024 15:37:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] ECCV 应用程序可让你浏览论文并查找相关工件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftq8rj/d_eccv_app_that_lets_you_browse_papers_and_find/</link>
      <description><![CDATA[有一个应用程序可以浏览论文、按受欢迎程度排名、过滤开放模型、数据集和演示  huggingface.co/spaces/ECCV/ECCV2024-papers     提交人    /u/Illustrious_Row_9971   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftq8rj/d_eccv_app_that_lets_you_browse_papers_and_find/</guid>
      <pubDate>Tue, 01 Oct 2024 15:01:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Python dash 和 Matplotlib 的类似彭博的交易终端</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftp6qy/p_bloomberg_like_trading_terminal_using_python/</link>
      <description><![CDATA[      我目前正在编写一个交易终端的代码。这类似于彭博终端，用户可以从中获得有关股票的所有见解。我在这个项目中使用了 Numpy、Pandas、Matplotlib、Dash、Plotily、Sklearn 等 Python 库。 这只是我工作的一小部分，在启动应用程序之前，我将添加大量见解和功能。我还使用了 yfinance 库，因此所有财务数据均来自雅虎财经。我很想知道我可以添加哪些功能使其脱颖而出。 我很想知道我可以添加什么功能使其变得更好。 https://preview.redd.it/gx4w5p8il5sd1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=65ca2710971261f4988eb5d5136c5967d7af8c77 https://preview.redd.it/b2wk6j8il5sd1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=a4627be7ee9b90947df65105938b136f77a5d540 https://preview.redd.it/fdbohi8il5sd1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=4e45296a4c2bf6a7555ac275b4c22dd5e8eba858    提交人    /u/Muda_ahmedi   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftp6qy/p_bloomberg_like_trading_terminal_using_python/</guid>
      <pubDate>Tue, 01 Oct 2024 14:16:53 GMT</pubDate>
    </item>
    <item>
      <title>[P] weka 内存不足</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftolst/p_weka_out_of_memory/</link>
      <description><![CDATA[大家好，我第一次使用 weka 完成一个关于文本分类的作业，我一直遇到这个问题（内存不足（堆上剩余少于 50MB）。请加载较小的数据集或使用较大的堆大小。- 初始堆大小：128MB - 当前使用的内存（堆）：1998.5MB - 可用的最大内存（堆）：2048MB 注意：可以使用 -Xmx 选项指定 Java 堆大小。例如，要使用 128MB 作为堆大小，命令行如下所示：java -Xmx128m -classpath ... 这在 SimpleCLI 中不起作用，上面的 java 命令是指启动 Weka 的命令。有关更多信息，请参阅网络上的 Weka FAQ。）有人知道如何修复它吗？:(     提交   /u/Silver-Falcon6746   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftolst/p_weka_out_of_memory/</guid>
      <pubDate>Tue, 01 Oct 2024 13:51:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何从数据到部署：云 ML 平台还是开源工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftng8j/d_how_do_you_go_from_data_to_deployment_cloud_ml/</link>
      <description><![CDATA[我正在尝试使用各种工具来完成我的 ML 项目，开源工具和商业工具都很棒，但感觉我需要 10 多种工具才能拥有完整的管道。我正在尝试创建一个工作流，以便我可以轻松地从数据转到部署。MLOps 工具有很多，但其中很多只是帮助您进行实验跟踪，但 ML 生命周期还有更多功能。所以我一直在考虑转向 AWS Sagemaker、Azure ML、Google Vertex AI 等云解决方案。 乍一看，有些似乎有点笨重，协作体验不佳，一旦选择了一个，显然缺乏灵活性，所以我想了解一下人们对这些工具的体验如何？ 更具体地说，从数据到部署以及随着数据的发展持续维护 ML 生命周期有多容易。  这些工具有用吗？还是我应该使用开源工具打包自己的解决方案？你们面临哪些挑战？    提交人    /u/Lumiere-Celeste   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftng8j/d_how_do_you_go_from_data_to_deployment_cloud_ml/</guid>
      <pubDate>Tue, 01 Oct 2024 12:58:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可扩展的机器学习管道，专注于训练基础设施</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftg3ly/d_scalable_ml_pipelines_focusing_training_infra/</link>
      <description><![CDATA[大家好，我目前正在尝试更多地了解 ML 系统设计，重点是基础模型的训练基础设施，我发现研究这个主题很困难。 有没有什么好的资源有人熟悉可能会有帮助？    提交人    /u/adi214   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftg3ly/d_scalable_ml_pipelines_focusing_training_infra/</guid>
      <pubDate>Tue, 01 Oct 2024 04:51:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们如何构建对话式检索增强生成应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdby7/d_how_are_folks_building_conversational_retrieval/</link>
      <description><![CDATA[我已阅读了各种资源，例如： - https://vectorize.io/how-i-finally-got-agentic-rag-to-work-right/ - https://python.langchain.com/docs/tutorials/qa_chat_history/ - https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/ - https://docs.llamaindex.ai/en/stable/module_guides/deploying/chat_engines/ - https://huggingface.co/datasets/nvidia/ChatRAG-Bench  但这些感觉过于简单，因为它们没有解决以下复杂性： 1）何时检索与立即响应以减少延迟 2）依靠先前在对话中检索到的现有上下文，而不是在当前回合再次检索 3）在检索到的信息和过去的对话历史之间划分 LLM 上下文。 我相信一些团队已经有了很好的系统，将不胜感激指针！    由    /u/iidealized 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdby7/d_how_are_folks_building_conversational_retrieval/</guid>
      <pubDate>Tue, 01 Oct 2024 02:17:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] SynthPAI：用于个人属性推断的合成数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftb4hk/r_synthpai_a_synthetic_dataset_for_personal/</link>
      <description><![CDATA[[被 NeurIPS&#39;24 D&amp;B 接受] TL;DR：我们为 Reddit 构建了一个 LLM 代理模拟框架，以生成合成数据来推进基于推理的隐私研究。 预印本：https://arxiv.org/abs/2406.07217 Github：https://github.com/eth-sri/SynthPAI 在我们的最新研究论文中，我们介绍了 SynthPAI - 一个合成数据集，它为评估基于 LLM 的个人属性推理的新基准奠定了基础。我们为 Reddit 构建了一个 LLM 代理模拟框架，以生成合成数据来推进基于推理的隐私研究。然后，我们评估了 18 个最先进的 LLM，评估它们从合成人物撰写的文本集合中预测特定私人属性（如年龄、性别、出身、工作等）的能力。使用这个框架，我们构建了一个 PAI（私人属性推断）数据集，该数据集包含 7800 多条评论和 300 个合成配置文件以及人工验证的属性标签。我们表明，我们的评论表现出高保真度（人类无法将它们与真实评论区分开来）和 PAI 研究的信息性，使我们能够在各种实验中得出与真实世界数据相同的定性结论。     提交人    /u/equin_x   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftb4hk/r_synthpai_a_synthetic_dataset_for_personal/</guid>
      <pubDate>Tue, 01 Oct 2024 00:27:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 原生架构优化：torchao</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftaw4e/d_pytorch_native_architecture_optimization_torchao/</link>
      <description><![CDATA[https://pytorch.org/blog/pytorch-native-architecture-optimization/    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftaw4e/d_pytorch_native_architecture_optimization_torchao/</guid>
      <pubDate>Tue, 01 Oct 2024 00:16:04 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 为AI模型量身定制的无损压缩库 - 将Llama3.2的传输时间缩短33%</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ft2v10/project_a_lossless_compression_library_taliored/</link>
      <description><![CDATA[如果您希望减少 Hugging Face 的下载时间并帮助减少其服务器负载—（Clem Delangue 提到 HF 每天处理高达 6PB 的数据！） —&gt;您可能会发现 ZipNN 很有用。 ZipNN 是一个开源 Python 库，可在 MIT 许可下使用，专门用于压缩 AI 模型而不会损失准确性（类似于 Zip，但针对神经网络进行了定制）。 它使用无损压缩将模型大小减少 33%，节省了三分之一的下载时间。 ZipNN 有一个 HF 插件，因此您只需添加一行代码即可。 在这里查看： https://github.com/zipnn/zipnn Hugging Face 上已经有几个带有 ZipNN 的压缩模型，如果您有兴趣，可以直接上传更多。 最新的是 Llama-3.2-11B-Vision-Instruct-ZipNN-Compressed 看看这个 Kaggle 笔记本： 对于您可以在此 Kaggle 笔记本中找到 Llama-3.2 的实际示例： https://www.kaggle.com/code/royleibovitz/huggingface-llama-3-2-example ZipNN repo 中提供了更多示例： https://github.com/zipnn/zipnn/tree/main/examples    提交人    /u/Candid_Raccoon2102   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ft2v10/project_a_lossless_compression_library_taliored/</guid>
      <pubDate>Mon, 30 Sep 2024 18:32:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 29 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>