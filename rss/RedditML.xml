<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 04 Jan 2024 18:16:55 GMT</lastBuildDate>
    <item>
      <title>[D] RL+LLM有哪些最新突破？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18yj99j/d_what_are_the_latest_breakthroughs_in_rl_llms/</link>
      <description><![CDATA[RLHF 与 ChatGPT 的成功给我留下了深刻的印象，但除了这种风格调整之外，我还没有看到任何其他突破。我非常想探索这个领域还有哪些其他令人兴奋的突破或任何未开发的潜力。   由   提交 /u/SpecialBuy3271   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18yj99j/d_what_are_the_latest_breakthroughs_in_rl_llms/</guid>
      <pubDate>Thu, 04 Jan 2024 17:55:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 放弃 ML 博士 - 建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18yh4ph/d_dropping_out_ml_phd_advice/</link>
      <description><![CDATA[我即将开始博士学位的第三年。我有 3 篇第一作者论文，还有 2 篇正在审稿中，今年夏天我已经准备好进行扎实的研究实习。但是……老实说，我根本不喜欢研究，从来没有，也不太关心。在过去的三年里，我勉强做到了这一点，老实说，我非常非常幸运。我绝不是一个研究天才，甚至不喜欢研究。我只是在乘风破浪，打发时间。但这种完全无意义和绝望的感觉，我无法克服。我只是感觉不适合作为一名研究员。这不是冒名顶替综合症。研究不是我的事。  老实说，我读博士课程只是为了满足我的家人。来自一个拥有研究生学位的亚洲家庭，这是一种期望。  20年前的博士学位看起来很有趣。我想象博士课程就是我和同事一起在白板上讨论，提出想法并尝试疯狂的事情，总是参加研讨会和课程。相反，我看到的是士气低落、过度劳累的学生、空荡荡的教室和研讨会（!!!），以及普遍的绝望感和不想去那里的感觉。这对我来说太震惊了。 现在退学是不是很愚蠢？我觉得我的20多岁已经在无聊、完全没有动力和沮丧中消逝了。我的导师是一个很棒的人，但几乎没有时间见面。我只是不知道我是否还能忍受这个。我想尝试一些疯狂的事情：去一家初创公司并取得成功或为此而奋斗，获得 MBA 或统计学硕士学位，搬到一个新城市，成为一名人工智能政策分析师。感觉有很多路我更适合。    由   提交 /u/TheMysticalJam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18yh4ph/d_dropping_out_ml_phd_advice/</guid>
      <pubDate>Thu, 04 Jan 2024 16:27:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻求建议：针对特定偏见和目标定制人工智能培训</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ygrr5/p_seeking_advice_customizing_ai_training_for/</link>
      <description><![CDATA[我正在寻求开发一个 AI 模型，在该模型中我可以提供自己的数据集并设定具体目标。我们的目标是塑造人工智能的偏见，以适应我想要实现的目标的独特轮廓。这里有没有人工作过或知道允许这种个性化人工智能培训的平台？我洗耳恭听建议、工具，甚至潜在的合作。让我们塑造人工智能的未来以满足我们的需求！   由   提交/u/hulerpacker  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ygrr5/p_seeking_advice_customizing_ai_training_for/</guid>
      <pubDate>Thu, 04 Jan 2024 16:12:05 GMT</pubDate>
    </item>
    <item>
      <title>《[讨论]》使用 ML 创建 YAML 审核系统。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18yfo13/discussioncreate_yaml_review_system_using_ml/</link>
      <description><![CDATA[想要使用机器学习创建 YAML 审核系统。该系统可以分析YAML条目（正确与否），并根据结果得出结果。请就哪种机器学习算法和机器学习框架最适合此目的提出任何建议   由   提交 /u/TrainIllustrious6238   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18yfo13/discussioncreate_yaml_review_system_using_ml/</guid>
      <pubDate>Thu, 04 Jan 2024 15:24:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 部署 SOLAR 10.7B-Instruct 量化版本的结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ycujm/d_results_from_deploying_quantized_version_of/</link>
      <description><![CDATA[    &lt; /a&gt;  大家好， 一直致力于优化 upstart.ai SOLAR-10.7B -Instruct-v1.0 模型并希望分享我们的见解： 🚀 我们的方法：使用 Auto-GPTQ 量化模型，然后使用 vLLM 进行部署。 &lt; p&gt;结果：在无服务器设置中，我们在 Nvidia A100 GPU 上看到了 1.37 秒的推理、111.54 个令牌/秒以及 11.69 秒的冷启动。 https://preview.redd.it/kel8cn5dafac1.png?width=1600&amp;format=png&amp;auto=webp&amp; s=5bca8b5e4a48f5f7a709f44bc431844746c61a77 测试的其他方法：虽然 Auto-GPTQ 是一种选择，但我们的经验表明 vLLM 是部署的最佳选择。  期待听到您在类似项目中的经验！   由   提交/u/Tiny_Cut_8440   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ycujm/d_results_from_deploying_quantized_version_of/</guid>
      <pubDate>Thu, 04 Jan 2024 13:11:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 双语到英语翻译</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ya4h7/p_bilingual_language_to_english_language/</link>
      <description><![CDATA[我和我的团队正在开发一个项目，其中双语文本（说话时结合了两种不同的语言，其中一种是英语）将被翻译成英语。它基于 NLP 和 ML 的概念。您能否推荐任何 GitHub 存储库或建议可以使用哪种预训练的 ML 模型来实现此目的？任何建议都会有很大帮助。   由   提交/u/SubstanceChemical155  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ya4h7/p_bilingual_language_to_english_language/</guid>
      <pubDate>Thu, 04 Jan 2024 10:35:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练模型的协作平台？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18y99nu/d_collaborative_platform_to_train_your_models/</link>
      <description><![CDATA[嗨，我们正在与我的团队一起培训 OS LLM，并希望一起培训/测试它（实验控制、评估、评论等）。 ..) 现在我们使用重量和重量。偏见，但就我个人而言，我并不是他们用户体验的忠实粉丝。 您还有推荐的其他工具吗？ 谢谢！   由   提交 /u/New_Detective_1363   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18y99nu/d_collaborative_platform_to_train_your_models/</guid>
      <pubDate>Thu, 04 Jan 2024 09:38:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些技术技能将使您在机器学习就业市场中脱颖而出？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18y888t/d_which_tech_skills_will_make_you_a_standout_in/</link>
      <description><![CDATA[框架、编程语言、算法等？   由   提交/u/Born-Comment3359  /u/Born-Comment3359 reddit.com/r/MachineLearning/comments/18y888t/d_which_tech_skills_will_make_you_a_standout_in/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18y888t/d_which_tech_skills_will_make_you_a_standout_in/</guid>
      <pubDate>Thu, 04 Jan 2024 08:27:18 GMT</pubDate>
    </item>
    <item>
      <title>[D]使用机器学习查找程序中的敏感区域</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18y66g1/dfinding_sensitive_regions_in_a_program_using_ml/</link>
      <description><![CDATA[我是 ML 领域的新手，作为学术的一部分，我正在开展一个研究项目，以“使用 ML 查找程序中的敏感区域” ;.我的项目的基础是程序分区，动机是根据性能、安全方面等找到源代码中的敏感区域。我没有运气找到任何关于该主题的好论文。请帮助我找到一些关于该主题的相关且好的研究论文！另外，我该如何使用 NLP 继续这个主题？   由   提交/u/its_maxx_way  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18y66g1/dfinding_sensitive_regions_in_a_program_using_ml/</guid>
      <pubDate>Thu, 04 Jan 2024 06:14:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 养成阅读论文的习惯——你的常用方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18y4qq9/d_making_a_paper_reading_habit_what_are_your_go/</link>
      <description><![CDATA[新的一年努力养成多看论文的习惯。我看过很多关于有多少等等的帖子，但想知道 2024 年是否有任何更新。 下面是一些想法。 1. 您常用的期刊/来源有哪些？ 2. 您希望阅读哪些主题（更好的是您不希望阅读哪些旧主题？） 3. 您每周阅读多少/您如何阅读？ 对于#1，我期待Arxiv，但我很好奇专业领域阅读的来源。此外，在带宽较低的情况下，还有不错的 YouTube 频道等。 （即两分钟论文） 对于#2，我确信法学硕士将会出现。但例如，我读过一篇关于一组模型的论文，在对它们投入一天之后，如果/在哪里不再使用这些模型，这似乎是一个混合包。 对于略读的#3一般意见/当您觉得投入时间来实施是件好事时。  额外问题：在实现时，我知道带有代码的论文。但通常我想要的论文都没有。如果有任何实施建议，我们将不胜感激。相反，人们是否搜索那里的顶级代码库，然后只阅读论文（这样你就知道在阅读之前代码已经存在） 编辑以获得新的奖励今年你在学习方面的新年决心是什么？    由   提交 /u/shaner92   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18y4qq9/d_making_a_paper_reading_habit_what_are_your_go/</guid>
      <pubDate>Thu, 04 Jan 2024 04:56:05 GMT</pubDate>
    </item>
    <item>
      <title>[D]什么是NLG评价指标的良好组合？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18y4m61/d_what_is_a_good_combination_of_evaluation/</link>
      <description><![CDATA[我对评估 NLG LLM 培训后的衡量标准特别感兴趣？ &lt; p&gt;特别是，我最感兴趣的是确保和评估生成的文本是连贯的、准确的、合乎逻辑的，并且在小的提示扰动下相对稳定。    ;由   提交/u/Plus_Tough_7497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18y4m61/d_what_is_a_good_combination_of_evaluation/</guid>
      <pubDate>Thu, 04 Jan 2024 04:49:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] ReCoRe：世界模型的正则化对比表示学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xtnzq/r_recore_regularized_contrastive_representation/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.09056 摘要：  虽然最近的无模型强化学习（RL）方法已经证明尽管在游戏环境中的人类水平的有效性，他们在视觉导航等日常任务中的成功受到限制，特别是在显着的外观变化下。这种限制源于 (i) 样本效率差和 (ii) 过度拟合训练场景。为了应对这些挑战，我们提出了一个世界模型，该模型使用（i）对比无监督学习和（ii）干预不变正则化器来学习不变特征。学习世界动态的显式表示（即世界模型）可以提高样本效率，而对比学习隐式地强制学习不变特征，从而提高泛化能力。然而，由于缺乏视觉编码器的监督信号，对比损失与世界模型的简单集成失败了，因为基于世界模型的强化学习方法独立地优化了表示学习和代理策略。为了克服这个问题，我们提出了一种以辅助任务（例如深度预测、图像去噪等）形式存在的干预不变正则化器，它明确地强制风格干预的不变性。我们的方法优于当前最先进的基于模型和无模型的 RL 方法，并且在 iGibson 基准评估的分布外点导航任务上表现显着。我们进一步证明，我们的方法仅通过视觉观察，优于最近的语言引导的点导航基础模型，这对于在计算能力有限的机器人上部署至关重要。最后，我们证明我们提出的模型在 Gibson 基准上的感知模块的模拟到真实转换方面表现出色。  同一作者之前的类似工作 ：  具有不变因果特征的世界模型的对比无监督学习  LanGWM：基于语言的世界模型   &amp;# 32；由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xtnzq/r_recore_regularized_contrastive_representation/</guid>
      <pubDate>Wed, 03 Jan 2024 20:48:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 第一作者</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xreys/r_first_authorship/</link>
      <description><![CDATA[你好， 我对这里的情况很陌生，我想问问你的意见。 &lt; p&gt;因此，我为一位医生做了一个项目，目的是使用机器学习来进行癌症检测（我就不详细介绍了）。 最近，他与一位教授合作发表了一篇出版物，该出版物将在拟发表在《国家癌症研究所杂志》上。我只对模型的技术部分做出了贡献（即使这不是我的选择，我也希望做得更多）。  我们最近写完了这篇论文，我重新获得了它的第一作者身份。医生反对这一说法，称它永远不会被接受，第一作者应该能够回答与非技术部分相关的问题，因为这些问题将会被问到。显然我是做最多工作的人（其他人只对出版物做出了贡献），尽管我不能按照论文所写的方式来写论文（根本不具备技术性） 所以我的问题是：我应该接受不是第一作者吗？我知道在写论文之前我已经获得了第一部分工作的报酬，但可以肯定地说，当我继续改进工作并进行消融研究和许多测试时，我完成的一半工作并没有得到报酬。  Ps：付钱给我的医生并不是他想列为第一作者的医生。论文的大部分内容是教授写的 Ps：模型的架构和所有的想法都是我的，就像我确实可以访问计算机但不知道要查找数据一样，我被告知要这样做让它发挥作用 Ps：我贡献了论文的技术部分 Ps：在项目开始之前，我得到了一个目标，而不是一个成熟的想法。所以我不只是编写另一个人的想法 打字错误：我在第一个版本中写了“医生”，但我的意思是“医生”    ;由   提交/u/Training-Adeptness57  /u/Training-Adeptness57 reddit.com/r/MachineLearning/comments/18xreys/r_first_authorship/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xreys/r_first_authorship/</guid>
      <pubDate>Wed, 03 Jan 2024 19:18:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对 Mamba 语音合成的思考？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xjmao/d_thoughts_on_mamba_speech_synthesis/</link>
      <description><![CDATA[   所以，在我之前在 Reddit 上发表有关 Mamba 文本生成的文章之后，我很好奇看到如果它对于语音合成效果很好，他们在原始论文中确实提到过，所以我将 MarcRandbot 组合在一起以获取乐趣，从头开始合成一些语音。 2084：MarcRandbot：使用 Mamba 进行语音合成 (substack.com) ​ https://preview.redd.it/w5hwiodyl7ac1.png ?width=1000&amp;format=png&amp;auto=webp&amp;s=a343919c26121b4ef9940fa00b183ebc97ff81c7 即使对于小型模型，似乎也能很好地工作，因为模型只有大约 1200 万个参数，而且输出很棒（您可以在帖子中找到一些示例和 colab）。此外，小型模型的表现也出奇的好：我可以使用单个 V100 Google Colab 笔记本来训练模型。 无论如何，Mamba 一直令人印象深刻，而且它在更少的参数下表现出色，这真是太棒了。  &gt; ​ https://preview.redd.it/94c3pal9f8ac1.png?width=323&amp;format=png&amp;auto=webp&amp;s=2f27a194161f9e172716a8e4fa9173e255046ecc 编辑：如果有足够的兴趣，我可能会对此进行跟进，我将其应用于音乐生成。    由   提交 /u/ExaminationNo8522   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xjmao/d_thoughts_on_mamba_speech_synthesis/</guid>
      <pubDate>Wed, 03 Jan 2024 13:39:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>