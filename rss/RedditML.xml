<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Thu, 25 Jul 2024 15:15:28 GMT</lastBuildDate>
    <item>
      <title>[D] 高维概率模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebwzkq/d_highdimensional_probabilistic_models/</link>
      <description><![CDATA[目前对高维随机过程进行建模的标准方法是什么？我在图像 x 上定义了一些过程，我想为所有 x&#39; 计算 P(x&#39; | x, z)。我知道有正则化流、高斯过程等，但我不知道从哪一个开始。我特别想计算概率，而不仅仅是抽样一些 x&#39; ~ P(x, z)。    提交人    /u/smorad   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebwzkq/d_highdimensional_probabilistic_models/</guid>
      <pubDate>Thu, 25 Jul 2024 14:58:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 共享想象力：法学硕士产生幻觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebvd4w/r_shared_imagination_llms_hallucinate_alike/</link>
      <description><![CDATA[      很高兴分享我们最近的论文，我们在论文中证明了 LLM 在纯粹的想象和幻觉内容上表现出惊人的一致性 —— 我们称之为“共享想象空间”。为了得出这个结论，我们要求 LLM 针对假设内容（例如，物理学中虚构的概念）提出问题，然后发现它们能够以比随机概率更高的准确率回答彼此的（无法回答且毫无意义的）问题。由此，我们从多个方向研究了它的出现、普遍性和可能的​​原因，并鉴于现代 LLM 中幻觉和想象行为的一致性，讨论了对幻觉检测和计算创造力的影响。  论文链接：https://arxiv.org/abs/2407.16604 包含结果摘要和重点的推文链接：https://x.com/YilunZhou/status/1816371178501476473 如有任何问题，请随时提问！ 主要实验设置和发现。    提交人    /u/zyl1024   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebvd4w/r_shared_imagination_llms_hallucinate_alike/</guid>
      <pubDate>Thu, 25 Jul 2024 13:49:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文 NAACL 2024：“新闻媒体来源的可靠性评估：物以类聚”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebqclk/r_paper_naacl_2024_reliability_estimation_of_news/</link>
      <description><![CDATA[对于一般从事信息验证的人来说，例如，从事事实核查、虚假新闻检测，甚至使用新闻文章中的 RAG，本文可能会有所帮助。 作者使用不同的强化学习技术，根据新闻媒体在网络上的互动方式来估计其可靠性值。 该方法易于扩展，因为可以使用源代码从 Common Crawl News 构建更大的基于超链接的交互图。作者还发布了计算值和带有新闻媒体可靠性注释的数据集：  Github repo： https://github.com/idiap/News-Media-Reliability 论文： https://aclanthology.org/2024.naacl-long.383/ 现场演示示例： https://lab.idiap.ch/criteria/  在演示中，检索到的新闻文章不仅按与查询的匹配排序，还按每个来源的估计可靠性排序（URL 域用颜色编码，从绿色到绿色）。例如，如果查询结果为红色，则向下滚动将显示来自可靠性较低的来源的结果（用红色标记）。或者，如果查询中给出了新闻 URL 或新闻媒体域名（例如 apnews.com），则会详细说明估计值（例如，显示与媒体交互的邻近来源等）。 祝大家有美好的一天！:)    提交人    /u/sergbur   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebqclk/r_paper_naacl_2024_reliability_estimation_of_news/</guid>
      <pubDate>Thu, 25 Jul 2024 09:10:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] ACL ARR 六月 (EMNLP) 评审讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebmas6/d_acl_arr_june_emnlp_review_discussion/</link>
      <description><![CDATA[太担心评论了，因为它们还没到！想与社区分享，看看大家对评论的反应！发泄一下！评论时要有礼貌。     提交人    /u/always_been_a_toy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebmas6/d_acl_arr_june_emnlp_review_discussion/</guid>
      <pubDate>Thu, 25 Jul 2024 04:45:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 看透迷雾：扩散模型如何增强深度估计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebdjpz/d_seeing_through_the_haze_how_diffusion_models/</link>
      <description><![CDATA[即使在阴天也能从相机获得清晰度 TL;DR 即使在雨天和弱光等恶劣条件下，扩散模型也能更准确地从单个图像进行深度估计。它们从简单的场景中创建逼真的具有挑战性的场景，提高人工智能在各种不利条件下理解深度的能力。 详细解释 想象一下，你想通过观察游泳池来了解它有多深。通常，在阳光明媚、水质清澈的日子里，这项任务很容易完成。但如果下雨、晚上或水面反射很多怎么办？那就难多了！讨论的新方法可以帮助计算机完成这项棘手的工作，即即使场景不完美，也能从一张图像中找出深度。 问题 单目深度估计意味着仅使用一张图像来猜测事物的距离。这就像闭上一只眼睛，却仍然无法判断玩具有多远。虽然技术在这方面已经变得更好，但计算机在恶劣天气、夜间或有光泽表面等恶劣条件下仍然难以应对，因为没有足够的训练数据来应对这些情况。 解决方案：扩散模型 扩散模型通过为困难条件创建更多训练数据来解决这个问题。方法如下：  从简单开始：   从简单、清晰且没有复杂条件的图像开始。   增加挑战：   使用扩散模型，通过添加雨水、夜间等将简单图像变成具有挑战性的图像，同时保持深度信息的一致性。 想象一下，从一张阳光明媚的泳池照片开始，然后一台电脑让它看起来像是在下雨或晚上。  工作原理  文本到图像的指导：   扩散模型使用文本提示（“下雨天”、“雾夜”）将简单图像转换为复杂图像，同时保持正确的深度。   自我提炼：   该模型在简单图像和新创建的困难图像上进行训练，完善其理解。这就像从不同角度和在不同的光线下研究一个玩具以完美地了解它。  结果 这些扩散模型已经过测试并被证明是有效的。它们：  适用于各种场景：它们可以很好地处理晴天、雨天和夜间场景。 增强稳定性和准确性：深度猜测更可靠、更准确。 适应闪亮和清晰的物体：它们甚至可以处理通常很棘手的反射和透明表面。  例如：  用这种方法训练的模型在测试中表现远远优于常规模型。 与仅使用简单图像进行训练的模型相比，它们在夜间和雨天场景中猜测深度的效果更好。  为什么这很重要 这对于自动驾驶汽车之类的事情很重要，了解各种天气条件下的场景深度可以挽救生命。它在增强现实和机器人技术中也很有用，使这些应用更加可靠和多功能。因此，就像将晴朗的晴天泳池图片变成下雨天或夜间的场景可以帮助您更好地了解泳池一样，这些扩散模型将简单的图像变成复杂的图像，并帮助计算机在任何条件下准确猜测深度。有关更多信息，您可以在此处阅读全文。 轻松在收件箱中获取科学论文的主要思想。订阅PaperSimplified。    提交人    /u/Reasonable_Drawer_57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebdjpz/d_seeing_through_the_haze_how_diffusion_models/</guid>
      <pubDate>Wed, 24 Jul 2024 21:43:25 GMT</pubDate>
    </item>
    <item>
      <title>“[讨论]”您从哪里获取有关视频生成和计算机视觉的最新研究信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebczzq/discussion_where_do_you_get_your_updates_on/</link>
      <description><![CDATA[正如标题所说，寻找一些关于如何跟踪视频生成和 CV 最新研究的提示。我一直在阅读https://cvpr.thecvf.com/，它是一个很好的来源，有没有类似的？    提交人    /u/Sobieski526   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebczzq/discussion_where_do_you_get_your_updates_on/</guid>
      <pubDate>Wed, 24 Jul 2024 21:20:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 提前提示你的法学硕士可以提高表现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebbtq7/r_preprompting_your_llm_increases_performance/</link>
      <description><![CDATA[UoW 的研究表明，预先提示您的 LLM，或在提出问题之前提供背景信息会带来更好的结果。即使上下文是自我生成的。 https://arxiv.org/pdf/2110.08387 例如询问， &quot;我在罗马应该做什么？&quot; 不如一系列提示有效， &quot;罗马有哪些最好的餐馆？&quot; &quot;罗马有哪些最好的观光地点？&quot; &quot;在罗马最值得做的事情&quot; &quot;我在罗马应该做什么？&quot; 我一直从轶事证据中认为情况确实如此，但很高兴看到比我更早的人在本文中解释这一点。虽然链式提示稍微耗费一些时间，但有 ChatGPT Queue 等 chrome 扩展程序可以简化该过程。 还有其他“黑客”可以挤出更好的性能吗？    提交人    /u/CalendarVarious3992   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebbtq7/r_preprompting_your_llm_increases_performance/</guid>
      <pubDate>Wed, 24 Jul 2024 20:33:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 段任何内容存储库已归档 - 为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebbl9h/r_segment_anything_repository_archived_why/</link>
      <description><![CDATA[您好，ML subreddit， 我最近才知道，不到一个月前（2024 年 7 月 1 日），segment anything 存储库 已被存档为公共档案。但是，我找不到有关为什么会出现这种情况的任何信息。我​​知道有很多正在开发中的 segment anything 的衍生产品，但我不知道为什么这需要公共档案。 有人知道为什么会发生这种情况以及我们可以将问题/问题重定向到哪里吗？    提交人    /u/Ben-L-921   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebbl9h/r_segment_anything_repository_archived_why/</guid>
      <pubDate>Wed, 24 Jul 2024 20:23:42 GMT</pubDate>
    </item>
    <item>
      <title>[N] Mistral 推出“足够大”模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eb9n8c/n_mistral_releases_a_large_enough_model/</link>
      <description><![CDATA[https://mistral.ai/news/mistral-large-2407/  123B 参数 根据它们的基准，与 GPT-4o 和 Llama 3.1 405B 相当 Mistral 研究许可证允许出于研究和非商业目的使用和修改     提交人    /u/we_are_mammals   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eb9n8c/n_mistral_releases_a_large_enough_model/</guid>
      <pubDate>Wed, 24 Jul 2024 19:04:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] llama3 论文中提到了 NCCLX</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eb4xn4/p_ncclx_mentioned_in_llama3_paper/</link>
      <description><![CDATA[论文称，“我们为 Llama 3 设计的集体通信库基于 Nvidia NCCL 库的一个分支，称为 NCCLX。NCCLX 显著提高了 NCCL 的性能，尤其是对于高延迟网络。”有人可以提供更多背景信息吗？有发布或上游的计划吗？还有更多技术细节吗？    提交人    /u/khidot   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eb4xn4/p_ncclx_mentioned_in_llama3_paper/</guid>
      <pubDate>Wed, 24 Jul 2024 15:54:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 将扩散变压器扩展到 160 亿个参数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eb3wos/r_scaling_diffusion_transformers_to_16_billion/</link>
      <description><![CDATA[      TL;DR 将 Mixture-of-Experts 添加到 Diffusion Transformer 中可获得高效而强大的模型。 论文： https://arxiv.org/pdf/2407.11633 摘要：  在本文中，我们提出了 DiT-MoE，这是扩散 Transformer 的稀疏版本，它可扩展且可与密集网络竞争，同时表现出高度优化的推理。DiT-MoE 包括两种简单的设计：共享专家路由和专家级平衡损失，从而捕获共同知识并减少不同路由专家之间的冗余。当应用于条件图像生成时，对专家专业化的深入分析得到了一些有趣的观察结果：（i）专家选择表现出对空间位置和去噪时间步长的偏好，而对不同的类条件信息不敏感；（ii）随着 MoE 层的加深，专家的选择逐渐从特定的空间位置转向分散和平衡。 (iii) 专家专业化往往在早期时间步骤中更加集中，然后在一半之后逐渐均匀。我们将其归因于扩散过程，该过程首先对低频空间信息进行建模，然后对高频复杂信息进行建模。基于上述指导，一系列 DiT-MoE 在实验中实现了与密集网络相当的性能，但在推理过程中所需的计算负载要少得多。更令人鼓舞的是，我们展示了使用合成图像数据的 DiT-MoE 的潜力，以 16.5B 参数缩放扩散模型，在 512×512 分辨率设置下获得了新的 SoTA FID-50K 得分 1.80。项目页面：这个 https URL.  视觉摘要： https://preview.redd.it/cq6yoqoeched1.png?width=1135&amp;format=png&amp;auto=webp&amp;s=1985119b5150c76bb9807f4df45d7bb44e02bd2a 视觉亮点： https://preview.redd.it/8xf8egk9dhed1.png?width=1109&amp;format=png&amp;auto=webp&amp;s=6e25b12d9a89d78847945068469f83cb45ef1eab 中间面板中的 1S、2S 和 4S 指的是共享专家的数量 MoE 降低了训练稳定性，但并不会带来灾难性的影响 https://preview.redd.it/s6cchx2nehed1.png?width=983&amp;format=png&amp;auto=webp&amp;s=c426ce2f1362bace2b4d3abef8d7e5607d0ff405    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eb3wos/r_scaling_diffusion_transformers_to_16_billion/</guid>
      <pubDate>Wed, 24 Jul 2024 15:12:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 开源 MLOps 工具 KitOps 的新注册表：查看预览版（不受限制）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eb258y/p_new_registry_for_kitops_an_open_source_mlops/</link>
      <description><![CDATA[大家好， 您听说过 KitOps 吗？它是一种开源 MLOps 工具，旨在简化数据科学、应用开发和 SRE/DevOps 团队之间的 AI 项目交接。 KitOps 引起了很多关注和采用，就在上周，它在一周内就达到了 1000 次安装的里程碑！ KitOps 用户最需要的功能之一是专门构建的用于托管其 ModelKit 的中心。今天，我们很高兴与大家分享已开发内容的预览。 请访问 jozu.ml 查看。如果它激起了您的兴趣，您可以在 jozu.com 注册以获得早期访问权限。 我们很乐意听到您的反馈！    提交人    /u/javafett   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eb258y/p_new_registry_for_kitops_an_open_source_mlops/</guid>
      <pubDate>Wed, 24 Jul 2024 13:57:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 低秩场加权分解机</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eaxapg/r_low_rank_fieldweighted_factorization_machines/</link>
      <description><![CDATA[      我们的论文Alex Shtoff、Michael Viderman、Naama Haramaty-Krasne、Oren Somekh、Ariel Raviv 和 Tularam Ban 撰写的“用于低延迟项目推荐的低秩场加权分解机”已被 RecSys 2024 接受。 我相信它引起了 ML 驱动的推荐系统社区的兴趣。我认为它对于在极端时间限制下运行的大规模系统（例如在线广告）的研究人员来说尤其有趣。 TL;DR：我们将具有 n 个特征和 nᵢ 项目特征的 FwFM 模型的推理成本从 O(n²) 降低到 O(c nᵢ)，其中 c 是一个小常数。这是为了便于以更低的成本进行大规模实时项目推荐推理。 代码和论文：GitHub 链接。 详细信息 FM 广泛应用于在线广告，因为它们在表示能力和极快的训练和推理速度之间取得了良好的平衡。在严格的时间限制下，它对于大规模推荐至关重要。 Rendle 等人设计的主要技巧是在 O(n) 时间内计算 n 个特征的 *成对* 交互。此外，在为给定用户排名多个项目时相同的用户/上下文特征可以单独处理（见下图）。单个推荐的计算成本变为每个项目的 O(nᵢ)，其中 nᵢ 是项目特征的数量。因此，添加更多用户或上下文特征实际上是免费的。 线性时间的 FM 公式 更高级的变体，例如 Field-Aware 和 Field-Weighted FM，不具备此属性，需要 O(n²) 时间。这对此类系统构成了挑战，需要仔细考虑额外的用户或上下文特征是否值得在推理中付出代价。通常，会积极修剪场交互以显着降低计算成本，但会牺牲模型准确性。  在这项工作中，我们设计了场加权 FM 系列的重新表述，使用场交互矩阵的对角线加低秩 (DPLR) 因式分解，这有助于在 O(c nᵢ) 时间内对每个项目进行推理，其中 c 是我们控制的一个小常数。与修剪的情况一样，代价是模型准确性略有下降。我们表明，在参数数量相当的情况下，DPLR 变体在现实世界数据集上的表现优于修剪，同时显著加快了推理速度，并重新获得了几乎免费添加用户上下文项目的能力。以下是总结结果的简短图表： 对角线+低等级 (DPLR) 推理时间明显优于修剪时间，并且随着上下文特征比例（总共 40 个特征中）的增加而迅速减少。针对各种广告拍卖规模和模型排名绘制。    提交人    /u/alexsht1   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eaxapg/r_low_rank_fieldweighted_factorization_machines/</guid>
      <pubDate>Wed, 24 Jul 2024 09:40:06 GMT</pubDate>
    </item>
    <item>
      <title>进入扩散模型[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eawgyo/getting_into_diffusion_models_d/</link>
      <description><![CDATA[您好， 我注意到 CVPR 2024 上有几篇论文关注扩散模型，特别是与点云相关的论文。由于我对这个概念还很陌生，我想知道什么是一个更好的起点来更好地理解它？以节省时间和精力 顺便说一句，我也在研究点云。 谢谢    提交人    /u/Same_Half3758   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eawgyo/getting_into_diffusion_models_d/</guid>
      <pubDate>Wed, 24 Jul 2024 08:45:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 21 Jul 2024 02:15:09 GMT</pubDate>
    </item>
    </channel>
</rss>