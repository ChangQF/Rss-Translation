<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Sat, 03 Aug 2024 12:25:56 GMT</lastBuildDate>
    <item>
      <title>[D] 评估长期语境法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eitqjj/d_evaluating_longcontext_llms/</link>
      <description><![CDATA[大型语言模型的上下文窗口一直呈指数级增长。2018 年，BERT、T5 和 GPT-1 等语言模型最多可以接受 512 个标记作为输入。现在，在 2024 年夏天，这个数字已跃升至 200 万个 token（在 Gemini 1.5 Pro 的公开版本中）。 我的想法是，由于长上下文 LLM 是一个如此新的发展，我们需要新的方法来评估它们。 我观察到的一些评估方法：  大海捞针任务（例如，在非常长的输入中查找特定信息） 扩展文档的复杂分析（例如，对文学作品的细微推理） 多镜头上下文学习，用于动态模型改进（例如，改进低资源语言的翻译）  我有一些悬而未决的问题：  您认为长上下文 LLM 还需要哪些其他评估方法？ 这些扩展的上下文窗口如何影响安全性、偏见、多语言性和创造力等领域在 ML 中？ 我们如何确保在上下文长度差异很大的模型之间进行公平比较？  我已经写了一篇文章更深入地探讨了这些主题，但我很想听听社区对其中一些未解决的问题的看法    提交人    /u/porkbellyqueen111   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eitqjj/d_evaluating_longcontext_llms/</guid>
      <pubDate>Sat, 03 Aug 2024 03:45:50 GMT</pubDate>
    </item>
    <item>
      <title>Sota视频嵌入[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eitbvk/sota_video_embedding_d/</link>
      <description><![CDATA[嗨，有人知道任何 sota 预训练视频嵌入编码器吗？它适用于 5-10 秒的短视频。使用 3DResnet 是可能的，但我想知道是否有更新的东西。 谢谢    提交人    /u/Busy-Necessary-927   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eitbvk/sota_video_embedding_d/</guid>
      <pubDate>Sat, 03 Aug 2024 03:24:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 比原始聊天 gpt 更智能的模型现在可以在笔记本电脑硬件上运行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eis40b/d_models_smarter_than_the_original_chat_gpt_can/</link>
      <description><![CDATA[      活着真好！ https://i.redd.it/qlz4efsqzcgd1.gif 早在 2022 年，我就假设了两件事  ChatGPT 是一款独特的产品，不易复制 这种质量的语言模型永远无法在本地运行  很高兴这两点都是错的。现在您可以将 llama3.1:8b 下载到笔记本电脑上并免费无限制地与其聊天！我对它的速度也印象深刻。从没想过我会成为马克·扎克伯格的粉丝。    提交人    /u/nanermaner   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eis40b/d_models_smarter_than_the_original_chat_gpt_can/</guid>
      <pubDate>Sat, 03 Aug 2024 02:22:58 GMT</pubDate>
    </item>
    <item>
      <title>[R]，[P] RPC — 构建语言模型的新方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eipn2t/r_p_rpc_a_new_way_to_build_language_models/</link>
      <description><![CDATA[文章：RPC — 构建语言模型的新方法 我非常喜欢软件工程的原因之一是，任何人都可以用一台计算机做几乎任何事情。但是当涉及到人工智能，特别是法学硕士时，你需要大量的资源和金钱才能自己做任何有趣的事情。 所以最近我一直在尝试寻找一种方法来构建语言模型，使用更少的训练数据和更少的计算。RPC 是我最接近的尝试。它将提示压缩为向量表示，然后在向量数据库中执行搜索以找到最合适的下一个标记。它工作得非常好。 我与社区分享这一点，希望有人能提供一些反馈，甚至尝试复制它。我希望您能看一下这篇文章并在这里分享一些想法。    提交人    /u/someuserwithwifi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eipn2t/r_p_rpc_a_new_way_to_build_language_models/</guid>
      <pubDate>Sat, 03 Aug 2024 00:20:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] NER 和 NLI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eioapp/d_ner_and_nli/</link>
      <description><![CDATA[通过使用自然语言推理 (NLI) 数据进行训练，文本分类得到了增强。 我正在寻找使用 NER 任务丰富 NLI 和/或使用 NLI 任务丰富 NER 的论文/研究作品。    提交人    /u/FeatureBackground634   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eioapp/d_ner_and_nli/</guid>
      <pubDate>Fri, 02 Aug 2024 23:17:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士 (LLM) 面试准备</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ein9vh/d_llm_interview_prep/</link>
      <description><![CDATA[大家好， 我即将参加一场 LLM/NLP 面试。我想寻求一些建议，比如面试时应该关注哪些主题、面试中应该期待什么以及任何建议的学习材料。我听说团队专注于公司内部的所有 LLM 事务，例如自托管、优化、微调等。 以下是我计划涉及的一些领域：  了解 LLM 的工作原理（内部） 微调技术 RAG NLP 基础  有人可以分享他们参加类似面试的经验吗？我应该优先考虑这些主题的哪些具体方面？我还遗漏了其他重要领域吗？我对 RAG 有基本的了解，但了解得不是太深入。  此外，如果您对论文或在线资源有任何建议，可以帮助我准备，我将不胜感激！    提交人    /u/kkziga   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ein9vh/d_llm_interview_prep/</guid>
      <pubDate>Fri, 02 Aug 2024 22:31:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 又一家耀眼的初创公司倒闭了？Character.Ai 创始人重返谷歌有何感想</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eijmhl/d_another_flashy_startup_folds_thoughts_on/</link>
      <description><![CDATA[链接：https://techcrunch.com/2024/08/02/character-ai-ceo-noam-shazeer-returns-to-google/    由   提交  /u/OpeningVariable   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eijmhl/d_another_flashy_startup_folds_thoughts_on/</guid>
      <pubDate>Fri, 02 Aug 2024 19:58:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] SSM 和 RNN 之间的区别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eih75h/d_difference_between_ssms_and_rnns/</link>
      <description><![CDATA[大家好 :) 我目前正在深入研究状态空间模型。但是，我不太明白状态空间模型的离散化版本与传统 RNN 架构有何不同。隐藏状态更新本质上与之前的隐藏状态相同，新输入通过权重矩阵进行转换。 我唯一的猜测是离散化过程包含学习参数，这是与经典 RNN 的不同之处。但是，我不太确定这是否正确或有任何意义。直观地看，两者的公式在我看来非常相似。 你能帮我解释一下它们有什么区别吗？    提交人    /u/No_Individual_7831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eih75h/d_difference_between_ssms_and_rnns/</guid>
      <pubDate>Fri, 02 Aug 2024 18:19:08 GMT</pubDate>
    </item>
    <item>
      <title>CoRL 2024 评论 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eih0yf/corl_2024_reviews_discussion/</link>
      <description><![CDATA[CoRL 2024 评论已经出炉。你们怎么样了？ 我们得到了 4,4,3（2 次强烈拒绝，1 次一周拒绝）。这真的很令人沮丧，因为这是我作为本科生的第一篇主要论文，我们论文的第一个版本被 ICRA 接受了。    提交人    /u/oz_zey   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eih0yf/corl_2024_reviews_discussion/</guid>
      <pubDate>Fri, 02 Aug 2024 18:12:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助在 Azure Kubernetes 上扩展 LLM 推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eig5v6/d_help_scaling_llm_inference_on_azure_kubernetes/</link>
      <description><![CDATA[大家好， 我正在尝试更好地了解如何设置我们自己的内部无服务器基础架构，以部署 LLM（针对 Gemma2 和 Llama 3.1 变体）以实现可扩展推理。 为了解决问题： 我们有严格的数据隐私和管理要求，因此不能依赖 Groq、openrouter 等推理 API。 我正在尝试了解正确的架构和执行此操作的成本。  带有 KEDA 的 Azure Kubernetes 服务似乎是一个很好的解决方案，但我不确定自动缩放的成本和速度。 理想的情况是 KEDA 从 0 个节点扩展到所需的节点数，以维持每个请求每秒 20-40 个令牌，然后尽快回落 向其他开放建议/链接/想法  有人尝试过这样做吗？您能否从高层次上比较现成的 API 和高度可扩展/空闲待机解决方案之间的成本？ 我知道 localllama 喜欢 vllm/llma.cpp，但是否有其他推荐的 llm 推理服务器堆栈在生产中是首选？ 谢谢！    提交人    /u/chulpichochos   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eig5v6/d_help_scaling_llm_inference_on_azure_kubernetes/</guid>
      <pubDate>Fri, 02 Aug 2024 17:36:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为机器学习工程师最困难的事情是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eifnvj/d_what_is_the_hardest_thing_as_a_machine_learning/</link>
      <description><![CDATA[我刚刚开始我的机器学习之旅。为了练习，我从 Kaggle.com 获取数据，但我决定通过自己收集数据来进一步挑战自己。我发现收集大量数据非常具有挑战性。通常如何收集数据，还有什么比这更难的吗？    提交人    /u/3ATAE   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eifnvj/d_what_is_the_hardest_thing_as_a_machine_learning/</guid>
      <pubDate>Fri, 02 Aug 2024 17:16:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] NLP 论文的新常态是“提示工程”论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei9e3l/d_is_the_new_norm_for_nlp_papers_prompt/</link>
      <description><![CDATA[很多论文似乎本质上都是“我们如何让 LLM 1 不经过任何培训就能做到这一点？”我已经有一段时间没有发表过文章了，过去几年一直在行业内工作。我最近加入了一家新公司，担任一个稍微更偏向研究的职位，与研究科学家和研究生实习生一起工作。我注意到他们每个人都在做一些我在研究生院会受到 PI 斥责的事情。基本上就是“我们如何让 LLM 不经过任何培训就能完成这个非常复杂的任务？”也许并不出人意料的是，在很多情况下，你做不到。我想这就是为什么现在 NLP 领域有这么多负面结果的论文。 这是新常态吗？浏览 arXiv 的 CL 部分已经变得很痛苦了。 98% 的论文都是类似“LLaMA 怎么会不懂数字？”这样的问题。 我想知道我是不是酒吧角落里那个老糊涂，还是大家都有同样的感受。    提交人    /u/Seankala   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei9e3l/d_is_the_new_norm_for_nlp_papers_prompt/</guid>
      <pubDate>Fri, 02 Aug 2024 12:57:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有什么好的可微调的 TTS？（不是 Coqui 或 TorToiSe）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehw1nf/d_any_good_finetunable_tts_not_coqui_or_tortoise/</link>
      <description><![CDATA[大家好！我有一个非常感性的数据集，里面有大约 20-30 分钟的清晰的英语语音录音。我想制作一个微调模型来完全复制该声音，并且能够在没有 CUDA 的情况下仅使用 MPS 进行推理。除了 Coqui 和 TorToiSe（它们不适用于高音调数据）之外，还有什么想法以及好的分步文档吗？    提交人    /u/yukiarimo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehw1nf/d_any_good_finetunable_tts_not_coqui_or_tortoise/</guid>
      <pubDate>Fri, 02 Aug 2024 00:10:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jul 2024 15:00:14 GMT</pubDate>
    </item>
    </channel>
</rss>