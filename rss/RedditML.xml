<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Mon, 22 Jul 2024 06:22:11 GMT</lastBuildDate>
    <item>
      <title>[D] 聚合标记概率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e96lo5/d_aggregating_token_probabilities/</link>
      <description><![CDATA[我可以使用哪些好的聚合技术来使用标记概率（这可以是 softmax 概率或对数概率）为生成的序列评分？ 例如，在答案中找到关键实体并尝试找出它的标记概率，并查看这些关键实体的中位标记概率是多少。    提交人    /u/archiesteviegordie   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e96lo5/d_aggregating_token_probabilities/</guid>
      <pubDate>Mon, 22 Jul 2024 05:36:55 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 文档图像修复</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e96f4i/discussion_document_image_restoration/</link>
      <description><![CDATA[      这是 DocRes 图像在 chainner 中运行的恢复模型用于改进扫描的文档。原始图像后跟恢复后的图像，然后是 chainner 模型。更进一步，使用 Mindee Doctr 非常准确地获取线段。 我正在处理的下一个任务是识别字体大小，然后识别字体样式，然后使用 Microsoft Phi-3 或具有 OCR 功能的类似模型进行 OCR 并应用样式，然后恢复图像 链接 https://github.com/ZZZHANG-jx/DocRes https://github.com/chaiNNer-org/chaiNNer 原始图像 恢复后的图像 Chainner 架构 已识别线段    提交人    /u/atlury   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e96f4i/discussion_document_image_restoration/</guid>
      <pubDate>Mon, 22 Jul 2024 05:25:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用稀疏数据对自定义下游任务的 OS 模型进行微调的最佳实践</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e962vd/p_best_practices_in_fine_tuning_os_models_with/</link>
      <description><![CDATA[我有一项下游任务，在输入过程中，99% 以上的数据都是上下文，由各种来源生成。实际模型输出只有几个标记，但输入的大小可以从 2k 个标记一直到 10k 个标记不等。因此，考虑到较长的上下文窗口，我尝试针对此任务微调 mistral 7b v0.3。但是尝试使用较低的学习率（如 8e-6）并衰减，我仍然会在每次运行时得到越来越高的训练损失。 训练集由标准 input_ids、attention_mask 和标签组成，但由于训练数据的性质，attention_mask 和标签分别大多为 1 和 -100。由于它们的大小也有很大差异，我将数据打包成 4096 的长度，使其保持不变。我的训练机器是 AWS trn1n.32xlarge 类型。关于我应该在这里做什么，有什么建议吗？对于任何对数据集感兴趣的人，这里是直接标记化版本数据的链接。    提交人    /u/VBQL   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e962vd/p_best_practices_in_fine_tuning_os_models_with/</guid>
      <pubDate>Mon, 22 Jul 2024 05:03:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我可以做哪些好的 ML 项目来帮助获得 DS 工作前景？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e95l42/p_what_are_some_good_ml_projects_i_can_do_to_help/</link>
      <description><![CDATA[我是一名 3 岁 DA，正在努力转型为 DS 角色，到目前为止我只被拒绝过。我知道网上有大量的项目，我提到了 2 个项目：股票市场预测模型和足球比赛预测，但我认为它们完全没用，所以我要把它们从简历中删除。我不知道在没有 ML/DS 经验的情况下，我该如何/做什么才能过渡到 ds 角色 :( 希望得到一些建议。谢谢    提交人    /u/potatotacosandwich   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e95l42/p_what_are_some_good_ml_projects_i_can_do_to_help/</guid>
      <pubDate>Mon, 22 Jul 2024 04:33:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] 为什么我不能使用单个组件图像进行模型训练。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e94x83/p_why_cant_i_use_single_component_images_for/</link>
      <description><![CDATA[大家好。我正在使用 Yolov5 进行机器学习项目。我用它来识别 p&amp; ID 图中组件。问题是，当我使用每幅图像中只有少量组件的复杂图时，模型训练正确。我的下一步是获取这些组件的一些单幅图像并在这些图像上训练模型（使用翻转、镜像、90° 旋转等变化），因为这样注释和构建数据集更容易。但这个版本只适用于阀门的单幅图像。（我正在尝试检测阀门）。当我使用带有多个组件的完整图表时，它没有检测到任何东西？这是有原因的吗？我该怎么做才能改进模型。    提交人    /u/Sherlockgnomes98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e94x83/p_why_cant_i_use_single_component_images_for/</guid>
      <pubDate>Mon, 22 Jul 2024 03:54:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在少样本原型网络中，跨折叠使用不同数量的查询样本可以吗</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8w0fn/d_is_it_okay_to_use_different_numbers_of_query/</link>
      <description><![CDATA[我目前正在使用原型网络进行少样本学习项目，遇到了一种情况，想请教一下。 我有一个预定义的 5 倍交叉验证设置，但这些折叠中的 A 类示例数量不一致。具体来说，一个折叠有 6 个 A 类示例，而其他折叠每个都有 12 个 A 类示例。 在这种情况下，在训练和测试期间使用不同数量的查询样本，同时保持相同的样本数和方法数，是否可以接受？例如，我可以使用可变数量的查询训练模型，并使用各自的查询数评估每个折叠吗？    提交人    /u/The_Aoki_Taki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8w0fn/d_is_it_okay_to_use_different_numbers_of_query/</guid>
      <pubDate>Sun, 21 Jul 2024 20:39:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] ChessGPT 比 GPT-4 小 100,000 倍，下棋等级为 1500 Elo。通过找到技能向量，我们可以在非分布游戏中将其胜率提高 2.6 倍。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8v2za/p_chessgpt_100000x_smaller_than_gpt4_plays_chess/</link>
      <description><![CDATA[之前的一个项目训练了 ChessGPT，这是一组 25M 和 50M 参数的 GPT 模型，可以在 1500 Elo 下棋。这些模型比 GPT-4 的 1.8T 参数小约 100,000 倍。 在 Stockfish 0 级，50M 参数模型的胜率为 70%。但是，如果用 20 个随机动作初始化游戏，其胜率会下降到 17%。这是因为它无法泛化分布之外的内容吗？在考虑下一个标记预测任务时，如果游戏以随机动作开始，那么好的下一个标记预测器会预测合法但低技能的动作。 这就是我们在 ChessGPT 中发现的。通过向模型的激活中添加技能向量，我们可以将其胜率提高到 43%，即提高 2.6 倍。我们无法完全弥补性能差距，但这是一个很大的比例。干预非常简单，更复杂的干预可能会进一步提高其胜率。 该模型仅经过训练以预测 PGN 字符串中的下一个字符（1.e4 e5 2.Nf3 ...），并且从未明确给出棋盘状态或国际象棋规则。尽管如此，为了更好地预测下一个角色，它会学习在游戏的任何时候计算棋盘的状态，并学习各种规则，包括将军、将死、王车易位、过路兵、升级、固定棋子等。此外，为了更好地预测下一个角色，它还学习估计潜在变量，例如游戏中玩家的 Elo 评级。 我们还可以使用可解释性方法来干预模型的内部棋盘状态。 这项工作最近被 2024 年语言建模会议 (COLM) 接受，标题为“国际象棋语言模型中的新兴世界模型和潜在变量估计”。 更多信息请参阅此帖子： https://adamkarvonen.github.io/machine_learning/2024/03/20/chess-gpt-interventions.html 代码在这里： https://github.com/adamkarvonen/chess_llm_interpretability    提交人    /u/seraine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8v2za/p_chessgpt_100000x_smaller_than_gpt4_plays_chess/</guid>
      <pubDate>Sun, 21 Jul 2024 19:59:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型语言模型时代的智能数字代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8reay/r_intelligent_digital_agents_in_the_era_of_large/</link>
      <description><![CDATA[https://doi.org/10.31219/osf.io/f75wz     由   提交  /u/thebigbigbuddha   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8reay/r_intelligent_digital_agents_in_the_era_of_large/</guid>
      <pubDate>Sun, 21 Jul 2024 17:20:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 与主要作者吴正轩讨论 ReFT 论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8qwnl/r_discussion_of_reft_paper_with_lead_author/</link>
      <description><![CDATA[大家好， 本周星期五，我们非常幸运地邀请到了 ReFT 论文的主要作者参加我们的论文讨论，我想分享一下我们的讨论和笔记！ https://www.oxen.ai/blog/arxiv-dives-how-reft-works TLDR ~ ReFT 是一种微调技术，其参数效率比 LoRA 高 15 到 60 倍。训练速度超快。在 A100 上，1k 个示例大约需要 18 分钟。我成功地在不到 1 分钟的时间内，在 A10 上使用大约 100 个示例在 Llama 2 7B 上对 ReFT 进行了微调。 它的工作原理是操作残差流中的表示，而不是 K-V 矩阵。他们向特定的 token 索引和层添加了他们称为“干预”的额外学习参数，从而高效且轻松地控制表示。ReFT 也很不错，因为它们是可组合的。例如，您可以训练一个用于指令跟踪的模型，一个用于德语的模型，然后将它们都应用于德语的获取和指令跟踪模型。 作者给出了他们在实验室中迭代时学到的超级实用的技巧和教训。整个讨论也在 YouTube 上。 希望你喜欢！    提交人    /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8qwnl/r_discussion_of_reft_paper_with_lead_author/</guid>
      <pubDate>Sun, 21 Jul 2024 16:59:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于神经发育程序。您认为“学习编码”这一想法有多合理？您认为它与自我编程有多大区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8pugs/d_on_the_neural_developmental_program_how_sound/</link>
      <description><![CDATA[我刚刚在 ALIFE2023 上看到了这个演讲，这看起来真的很有趣。总结一下，他们使用了 3 个“策略”网络来发展/生成一个“目标”网络，也就是传统的“策略”网络，它从环境中获取输入并给出动作的输出。 最后，演讲中描述的这个代理仍然是几个传统的神经网络，只是它们的输出是一个模型而不是预测，而来自奖励的训练只是进化算法或 PPO。对于像我这样的自我编程倡导者来说，这种由结构生成看起来很像其自身的结构的想法听起来非常棒，但从外观上看，它是一种类似优先依附的花哨网络生成模型，只是这次在奖励的帮助下它可以解决实际问题。（我仍然认为它很棒，并且是我们现在对预训练微调 RLHF 东西的常规做法的决定性一步） 您对此有何看法？    提交人    /u/HermanHel   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8pugs/d_on_the_neural_developmental_program_how_sound/</guid>
      <pubDate>Sun, 21 Jul 2024 16:11:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基线薄弱和报告偏差导致机器学习对流体相关偏微分方程过度乐观</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8pp4r/r_weak_baselines_and_reporting_biases_lead_to/</link>
      <description><![CDATA[  由    /u/nuclear_knucklehead  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8pp4r/r_weak_baselines_and_reporting_biases_lead_to/</guid>
      <pubDate>Sun, 21 Jul 2024 16:05:07 GMT</pubDate>
    </item>
    <item>
      <title>有谁成功微调过 Chronos [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8ia8p/has_anybody_succeeded_at_finetuning_chronos_d/</link>
      <description><![CDATA[Chronos 是基于 t5 架构的时间序列预测模型，由 Amazon 开发。 我的应用程序用于预测身体运动中的关节位置。这个应用程序的术语很重，而且他们的微调文档有点难以理解。 如果有人成功做到了，请帮忙。  Chronos：https://github.com/amazon-science/chronos-forecasting 微调文档：https://github.com/amazon-science/chronos-forecasting/blob/main/scripts%2FREADME.md 如果有人能直接帮助我预训练这个模型，特别是根据他们的要求转换我的数据集，那将非常有帮助。谢谢    提交人    /u/abdullahboy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8ia8p/has_anybody_succeeded_at_finetuning_chronos_d/</guid>
      <pubDate>Sun, 21 Jul 2024 09:14:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你在公司项目中处理的数据集的平均大小是多少？#D</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8h7ra/d_what_is_the_average_size_of_datasets_you_work/</link>
      <description><![CDATA[想知道您在项目中使用的数据集大小，是 GB 还是 TB？ 以及您如何处理大型数据集以及在处理过程中遵循哪些最佳实践。    提交人    /u/PraveenKumarIndia   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8h7ra/d_what_is_the_average_size_of_datasets_you_work/</guid>
      <pubDate>Sun, 21 Jul 2024 07:55:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你在生产中的 LLM Stack 是什么样的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8cxkf/d_what_is_your_llm_stack_in_production/</link>
      <description><![CDATA[好奇人们在生产堆栈中使用什么来开发 LLM 应用程序。这个问题是几个月前提出的，但该领域的事态变化如此之快，我认为值得再开一个帖子。 嵌入模型：目前是 OpenAI Ada，但召回率/准确率不是很好，所以我打算尝试其他模型 矢量数据库：Supabase（推荐） LLM：一直在尝试开源和闭源模型。我的任务需要相当强的推理能力，因此不幸的是本地模型还不够好（例如 Llama 70B）。OpenAI GPT-4o 表现最佳（这并不奇怪），但对于我的用例来说它确实很昂贵，所以我目前使用的是 Gemini Pro 1.5。 LLM 框架：无。大家的共识是远离 LangChain，所以我只是直接与 LLM 提供商集成。幸运的是，LLM 提供商似乎倾向于 OpenAI API 标准，这使得实验变得容易（除了偶尔定制的 API，如 Gemini） 评估：???。不太确定这个的最新技术是什么。 其他人都在用什么？    提交人    /u/Aggressive_Comb_158   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8cxkf/d_what_is_your_llm_stack_in_production/</guid>
      <pubDate>Sun, 21 Jul 2024 03:17:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 21 Jul 2024 02:15:09 GMT</pubDate>
    </item>
    </channel>
</rss>