<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 04 Jun 2024 12:27:00 GMT</lastBuildDate>
    <item>
      <title>[D] 进行无监督域自适应时损失减少</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7vghp/d_decrease_in_loss_while_doing_unsupervised/</link>
      <description><![CDATA[大家好，我正在对 cifar10 和 cifar10.1 数据集进行实验，其中我使用 Resnet18 模型在 cifar10 训练数据上进行训练，并评估 cifar10 测试数据和 cifar10.1（属性移位数据）。我正在使用监督对比学习来训练特征编码器（当前特征向量 dim id 64），然后训练投影头（单层 MLP）；经评估，该模型在 cifar10 测试数据的 ACC 为 91%，在 cifar10.1 数据集上的 ACC 为 81%。 为了将特征编码器模型改进到看不见的属性移位数据，我正在使用自监督对比损失在 cifar10.1 数据集上对特征编码器进行微调，但在对微调的特征编码器以及在 cifar10 训练数据上预先训练的投影头进行微调时，其表现比未微调的模型更差，微调模型的准确率为 56%（之前为 81%），请告诉我为什么微调模型效果不佳。    提交人    /u/ChaitanyaSai1708   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7vghp/d_decrease_in_loss_while_doing_unsupervised/</guid>
      <pubDate>Tue, 04 Jun 2024 12:04:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] MMLU-Pro：更强大、更具挑战性的多任务语言理解基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7uamg/r_mmlupro_a_more_robust_and_challenging_multitask/</link>
      <description><![CDATA[      TL;DR：MMLU 但更具挑战性并且（据称）噪音更小 论文：https://arxiv.org/pdf/2406.01574 摘要：  在大规模语言模型时代，大规模多任务语言理解 (MMLU) 等基准对于推动 AI 在不同领域的语言理解和推理能力的极限至关重要。然而，随着模型的不断改进，它们在这些基准上的表现已开始趋于稳定，使得辨别模型能力的差异变得越来越困难。本文介绍了 MMLU-Pro，这是一个增强型数据集，旨在通过整合更具挑战性、以推理为重点的问题并将选择集从四个选项扩展到十个选项来扩展主要由知识驱动的 MMLU 基准。此外，MMLU-Pro 消除了 MMLU 中的琐碎和嘈杂问题。我们的实验结果表明，MMLU-Pro 不仅提高了挑战性，导致准确率与 MMLU 相比大幅下降 16% 至 33%，而且在不同提示下也表现出更高的稳定性。在测试了 24 种不同的提示风格后，模型得分对提示变化的敏感度从 MMLU 中的 4-5% 下降到 MMLU-Pro 中的仅 2%。此外，我们发现使用思路链 (CoT) 推理的模型在 MMLU-Pro 上的表现比直接回答更好，这与原始 MMLU 上的结果形成鲜明对比，表明 MMLU-Pro 包含更复杂的推理问题。我们的评估证实，MMLU-Pro 是一个更具辨别力的基准，可以更好地跟踪该领域的进展。  组成 基准测试。注意 Phi 对 MMLU 的优化对于新数据集仍然很稳健 与 MMLU 结果进行比较。请注意表现最佳的 LM 之间的更大差异 值得注意的亮点：  MMLU-Pro 有十个选项，其中包含的干扰项比 MMLU 多 3 倍。通过增加干扰项数量，我们显著降低了偶然正确猜测的概率，从而提高了基准的难度和鲁棒性。 [...] MMLU-Pro 需要思维链 (CoT) [41] 才能取得有希望的结果。例如，CoT 可以将 GPT-4o 的性能提高 19%。相反，CoT 实际上会损害模型在 MMLU 上的性能。这反映了在 MMLU-Pro 上进行深思熟虑的推理的必要性，而这在知识驱动的 MMLU 问题中是不需要的。  HuggingFace: https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7uamg/r_mmlupro_a_more_robust_and_challenging_multitask/</guid>
      <pubDate>Tue, 04 Jun 2024 10:57:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 图像超分辨率数据集修剪研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7st4v/r_a_study_in_dataset_pruning_for_image/</link>
      <description><![CDATA[我们很高兴与大家分享我们最近的作品《图像超分辨率数据集修剪研究》，该作品已被 ICANN 2024 接受 :) 我们引入了一种基于损失值的采样方法，该方法将训练数据集缩减为由简单的预训练 SRCNN 模型确定的核心集（原始数据集的 50%）。通过专注于包含高损失值（即“困难样本”），我们获得的结果可与对完整数据集进行训练获得的结果相媲美甚至超过这些结果。此外，我们发现最难样本的前 5% 会对训练产生负面影响。排除这些样本可进一步增强结果，或者简而言之，选择 45-95% 的最难样本部分可获得最佳训练质量。我们希望为图像 SR 中数据集修剪的未开发潜力开辟新的视角，并为其他领域提供新的想法。 arXiv：https://arxiv.org/abs/2403.17083    提交人    /u/Maleficent_Stay_7737   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7st4v/r_a_study_in_dataset_pruning_for_image/</guid>
      <pubDate>Tue, 04 Jun 2024 09:14:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于 EMNLP 2024 提交的困惑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7slzq/r_confusion_about_emnlp_2024_submission/</link>
      <description><![CDATA[演示 / 行业 / WiNLP 研讨会提交之间有什么区别？哪一个是主要的？ 如何提交已经提交给 ARR 的论文？我看到了常规提交链接，但没有看到任何与在 openreview 系统中选择现有提交相关的内容    提交人    /u/CantaloupeLeading646   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7slzq/r_confusion_about_emnlp_2024_submission/</guid>
      <pubDate>Tue, 04 Jun 2024 08:59:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对不同的任务对模型进行 3 次微调还是直接在所有任务上进行训练？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7sayl/d_finetune_a_model_3_times_for_different_tasks_or/</link>
      <description><![CDATA[大家好，我想微调 LLM 以进行文本提取。我想提取 3 个不同的属性。我想知道最好的方法是什么？我是否应该每次针对每个属性微调基础模型，以便获得 3 个微调模型？或者我应该微调模型以直接提取所有 3 个属性？我找不到这两种方法的任何信息或优缺点，所以我在这里提问。而且我还想知道文本提取的最佳评估指标是什么？谢谢！    提交人    /u/d-eighties   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7sayl/d_finetune_a_model_3_times_for_different_tasks_or/</guid>
      <pubDate>Tue, 04 Jun 2024 08:36:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mamba2 SSD 收缩可视化为张量网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7q386/d_mamba2_ssd_contractions_visualized_as_a_tensor/</link>
      <description><![CDATA[      https://preview.redd.it/3lpr8yp5yh4d1.png?width=2667&amp;format=png&amp;auto=webp&amp;s=a410811c8d010f7697ecfc76138258d089113d30 我不确定这是否会对任何人有所帮助，但我发现 Mamba 2 论文中的收缩顺序相当有趣，并认为它可能将其可视化为张量网络很不错。这对应于第一阶段收缩，或 Y_diag = torch.einsum(&quot;bclhn,bcshn,bhcls,bcshp-&gt;bclhp&quot;, C, B, L, X) 请注意索引 b、c 和 h 如何出现在每个表达式中，因此它们可以抽象（并行化），收缩操作的核心实际上在于 d_head、d_state、length 和 length（mixed）。然后，收缩操作涉及通过边收缩合并图中的两个节点。 请注意，与节点相邻的边数对应于张量的维度（加上 3 个公共维度）。在作者提出的收缩路径下（参见上面的代码），可以很容易地看到，维度大于 5 的张量永远不会实现。这是可能的，因为 segsum 矩阵（由 A 矩阵诱导）没有 d_state 依赖性，或“限制为 标量乘以恒等式 结构”。 我猜这可能不是最普遍的收缩形式，并且出于实际的硬件内存考虑，可能还有其他方法可以构建更具表现力的张量网络，以保证维度大于 5 的张量不实现。   由    /u/dna961010  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7q386/d_mamba2_ssd_contractions_visualized_as_a_tensor/</guid>
      <pubDate>Tue, 04 Jun 2024 06:00:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 矢量神经网络 (VNN) – 利用二维矢量神经元和几何张量增强几何深度学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7lpfu/d_vector_neural_networks_vnns_enhancing_geometric/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7lpfu/d_vector_neural_networks_vnns_enhancing_geometric/</guid>
      <pubDate>Tue, 04 Jun 2024 01:51:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在模型评估和模型可解释性领域有哪些值得关注的研究人员？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7jt6y/d_who_are_some_researchers_to_follow_in_the_field/</link>
      <description><![CDATA[这些研究人员有很好的精选列表和演讲。对于正在学习的人来说，还有其他值得关注的研究人员吗？  https://github.com/zhijing-jin/Causality4NLP_Papers?tab=readme-ov-file https://beenkim.github.io/#Pubs     提交人    /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7jt6y/d_who_are_some_researchers_to_follow_in_the_field/</guid>
      <pubDate>Tue, 04 Jun 2024 00:16:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 介绍 einspace：基于基本操作的 NAS 多功能搜索空间</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7gt44/r_introducing_einspace_a_versatile_search_space/</link>
      <description><![CDATA[亲爱的 r/machinelearning 朋友们， 我们很高兴与大家分享我们在神经架构搜索 (NAS) 搜索空间方面的最新研究成果。 介绍 einspace：一个灵活而全面的搜索空间，它集成了卷积网络 (convnets)、Transformers 和多层感知器 (MLP)。 我们的方法将架构分解为四个关键组件：1. MLP 2. 分支 3. 聚合 4. 路由 这些组件构成了架构设计的“RGB”基因。我们的目标是平衡粒度，避免重新设计线性层的冗余，同时保持不同模型之间的灵活性。 我们希望您探索我们的工作，并了解我们如何进行架构探索。非常感谢您的反馈和想法。 🧠🔍 阅读论文 🔗 项目页面 📣 原始推文 问候， Antreas    提交人    /u/AntreasAntoniou   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7gt44/r_introducing_einspace_a_versatile_search_space/</guid>
      <pubDate>Mon, 03 Jun 2024 21:57:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 一篇关于机器学习中多项式特征的正则化性质的文章</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7d26z/p_a_post_on_regularization_properties_of/</link>
      <description><![CDATA[我写了一篇关于机器学习中多项式特征的正则化属性的文章 - 比如偏差-方差权衡，以及控制拟合曲线的形状。这是关于多项式特征的系列文章中的最后一篇。我非常享受学习我所写的一切，我希望它会很有趣并且有用。 系列从这里开始：https://alexshtf.github.io/2024/01/21/Bernstein.html 最新帖子在这里：https://alexshtf.github.io/2024/06/03/PolynomialBasesRegProps.html    提交人    /u/alexsht1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7d26z/p_a_post_on_regularization_properties_of/</guid>
      <pubDate>Mon, 03 Jun 2024 19:26:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] Text2Bricks：在 1,000 个 GPU 小时内对 Open-Sora 进行微调以制作砖块动画</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7ats8/p_text2bricks_finetuning_opensora_in_1000_gpu/</link>
      <description><![CDATA[大家好，Lambda Labs 的研究团队获得了大量 NVIDIA H100 GPU 的使用权，并用它来训练 OpenSora 制作砖块动画。团队和我随时准备回答您可能遇到的任何问题。您可以在此处阅读我们 W&amp;B 文章的所有详细信息： https://wandb.ai/lambdalabs/lego/reports/Text2Bricks-Fine-tuning-Open-Sora-in-1-000-GPU-Hours--Vmlldzo4MDE3MTky 所有模型均可用（文章中有链接），您甚至可以玩我们使用该模型制作的有趣游戏！ https://albrick-hitchblock.s3.amazonaws.com/index.html    由    /u/jedberg 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7ats8/p_text2bricks_finetuning_opensora_in_1000_gpu/</guid>
      <pubDate>Mon, 03 Jun 2024 17:57:06 GMT</pubDate>
    </item>
    <item>
      <title>[D]LLM面试问答</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7af78/dllm_interview_qa/</link>
      <description><![CDATA[大家好！我是亚马逊中国的数据科学家。在过去的一年里，我面试了多家公司的法学硕士职位。我计划整理一系列面试问题，结合我自己的面试经验，提供我认为正确的答案。本文将重点介绍微调，我会持续更新。    提交人    /u/mlzoo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7af78/dllm_interview_qa/</guid>
      <pubDate>Mon, 03 Jun 2024 17:40:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformers 是 SSM：通过结构化状态空间对偶实现广义模型和高效算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d7a6l6/r_transformers_are_ssms_generalized_models_and/</link>
      <description><![CDATA[  由    /u/floppy_llama  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d7a6l6/r_transformers_are_ssms_generalized_models_and/</guid>
      <pubDate>Mon, 03 Jun 2024 17:30:21 GMT</pubDate>
    </item>
    <item>
      <title>AI/ML 中对 C++ 的需求。[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d78g7s/c_demand_in_aiml_discussion/</link>
      <description><![CDATA[最近，我一直在想一个学习 cpp 的副项目，这样我就可以实现 ml 算法，希望我可以从头开始创建一些有用的东西。  然而，当我想到 AI/ML 行业中的 C++ 时，我真的很沮丧。 这是能带来价值或期望的东西吗？  注意：我从去年开始就一直用纯 C 开发程序，所以学习 cpp 不是什么大不了的事。    提交人    /u/Barrnie   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d78g7s/c_demand_in_aiml_discussion/</guid>
      <pubDate>Mon, 03 Jun 2024 16:19:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>