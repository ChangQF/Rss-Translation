<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 22 Dec 2024 03:23:48 GMT</lastBuildDate>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在 NeurIPS’24 上感受到了焦虑和沮丧（kyunghyuncho 博客）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</guid>
      <pubDate>Sun, 22 Dec 2024 02:22:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医学 AI：顶级 LLM 研究论文/模型（2024 年 12 月 15 日至 12 月 21 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjo3yu/d_last_week_in_medical_ai_top_llm_research/</link>
      <description><![CDATA[      [D] 医学 AI 上周：顶级 LLM 研究论文/模型（2024 年 12 月 15 日至 12 月 21 日） 医学 LLM &amp;其他模型  MedMax：混合模态生物医学助理 本文介绍了 MedMax，这是一个用于混合模态基础模型的大规模（147 万个实例）多模态生物医学指令调整数据集，涵盖图像文本生成、字幕、视觉聊天和跨放射学和组织病理学等领域的报告理解等任务。  MGH Radiology Llama 70B  本文介绍了 MGH Radiology Llama，这是一个专门用于放射学的大型语言模型 (LLM)，基于 Llama 3 70B 构建，并使用来自麻省总医院的 650 多万份去识别医疗报告进行训练。  HC-LLM：历史放射学报告 本文介绍了 HC-LLM，这是一个使用大型语言模型 (LLM) 生成放射学报告 (RRG) 的框架，该模型结合了历史视觉和文本数据。   框架和方法  ReflecTool：反射感知临床代理 本文介绍了 ClinicalAgent Bench (CAB)，这是一个全面的医疗代理基准，包含五个临床维度的 18 项任务，用于评估与各种信息交互的临床代理。  过程监督临床记录 本文探讨了过程监督奖励模型 (PRM)，用于从患者与医生对话中生成临床记录，使用 Gemini-Pro 1.5 生成监督数据。  使用 RAG 进行联邦学习 本文研究了联邦学习框架内通过检索增强生成 (RAG) 增强的医学 LLM 的性能。实验表明，与 RAG 集成的联邦学习模型在所有指标上的表现始终优于未集成的模型。   基准与评估 - Multi-OphthaLingua - 多语言眼科基准 - 专注于 LMIC 医疗保健 - 偏见评估框架 - ACE-M3 评估框架 - 多模式医学模型测试 - 综合能力评估 - 标准化评估指标 LLM 应用 - 患者友好型视频报告 - 医学视频 QA 系统 - 基因本体注释 - 医疗保健建议 特别关注：医学伦理与AI - 临床信任影响研究 - 心理健康 AI 挑战 - 医院监测伦理 - 放射科 AI 集成 完整线程详细信息：https://x.com/OpenlifesciAI/status/1870504774162063760    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjo3yu/d_last_week_in_medical_ai_top_llm_research/</guid>
      <pubDate>Sun, 22 Dec 2024 01:21:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们最容易误解哪些机器学习概念？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</link>
      <description><![CDATA[我注意到某些 ML 概念（例如偏差-方差权衡或正则化）经常被误解。您认为哪个 ML 主题经常被误解，您如何向其他人解释它？    提交人    /u/AdHappy16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</guid>
      <pubDate>Sat, 21 Dec 2024 20:22:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在超过 40 个 PyTorch 转换选项上对你的模型速度进行基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjaofu/p_benchmark_your_model_speed_on_over_40_pytorch/</link>
      <description><![CDATA[我和一个朋友刚刚开源了我们的一个宠物项目，只需 1 个函数调用，您就可以获得一份完整的基准测试报告，了解您的 PyTorch 模型推理速度在 40 多个转换选项上的表现，例如 JIT 跟踪、bf16、量化、使用不同后端进行编译、导出、最佳量化、组合等。 我们一直在添加新的选项，例如目前正在研究 torch ao。 它非常灵活，默认情况下在隔离的环境中运行每个转换选项，以避免全局 torch 状态污染。 如果您想要任何新选项/功能，请告诉我们！ :) https://github.com/saifhaq/alma    由   提交  /u/OscarSavolainen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjaofu/p_benchmark_your_model_speed_on_over_40_pytorch/</guid>
      <pubDate>Sat, 21 Dec 2024 14:15:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] ResNet 与 Transformer 在音频分类任务上的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjacxa/d_resnet_vs_transformer_on_audio_classification/</link>
      <description><![CDATA[我是公司的一名研发软件工程师，几乎完成了一个唤醒词系统（如 Ehy google），该系统可在非常小的音频数据集上训练，同时保留非常轻的模型资源印记，以便以 0 延迟和低电池影响运行。我使用了残差网络，其残差是在输入频谱图的频率维度上计算的。一位同事在我获得优秀结果之前建议我，Transformer 架构会表现更好（由于过度自信，我出现了假阳性问题，已通过温度缩放和标签平滑解决）。我应该尝试具有自我注意的 Transformer 吗？Transformer 架构在每种情况下都优于 Resnet 吗？ 谢谢    提交人    /u/CatsOnTheTables   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjacxa/d_resnet_vs_transformer_on_audio_classification/</guid>
      <pubDate>Sat, 21 Dec 2024 13:58:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 努力寻找相关工作，并理解这个图问题是什么任务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hj8rdu/d_struggling_to_find_related_work_and_understand/</link>
      <description><![CDATA[我有一个包含 15k 个节点的图，每个节点都由一个 ID 标识。我可以计算节点之间的距离。在推理过程中，我得到了一个包含 10-30 个节点的子图，需要识别它们，面临的挑战包括缺失/错误节点以及边缘值的轻微不精确。 我在推理过程中得到的子图将仅包含彼此靠近的节点。 这是一个子图匹配问题还是节点分类问题？我的主管想使用 GNN。简单的三角方法可以得到很好的结果，但我需要一种深度学习方法，其中输入是子图，输出是节点 ID 列表。 我很难找到与此相关的工作 - 有什么建议吗？    提交人    /u/Turbulent-Quality906   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hj8rdu/d_struggling_to_find_related_work_and_understand/</guid>
      <pubDate>Sat, 21 Dec 2024 12:19:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 努力寻找博士研究之路</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hj6nbf/d_struggling_to_find_my_path_in_phd_research/</link>
      <description><![CDATA[大家好，希望你们不介意我发泄一下，但我希望能够深入了解我所面临的挑战。我是一名研究时间序列的二年级博士生，老实说，我以为现在我会有一个明确的研究问题。但我没有，这让我开始感到困惑。 部分困难来自于选择“热门”主题的巨大压力。我看到的该领域的许多研究都受到我只能描述为闪亮物体综合症的驱动——追逐最新趋势，而不是专注于有意义和实质性的工作。例如，我看到几篇论文使用大型语言模型 (LLM) 进行时间序列预测。虽然 LLM 无疑令人着迷，但它更像是一种试图强行将它们融入时间序列的尝试，因为它很“酷”，而不是因为它是解决手头问题的最佳工具。而我不想成为这种趋势的一部分。 但这里有一个难题：你如何选择一个既真实又有影响力的研究课题，尤其是当你周围的一切似乎都被最新的炒作所驱动时？你是追随这些新兴趋势，还是专注于能与你产生深刻共鸣的东西，即使它不是其他人都在研究的“闪亮”的东西？ 老实说，我感觉有点陷入困境，对自己没有信心。我是不是想太多了？这只是过程的一部分吗？我如何找到一个符合我的兴趣和我想为这个领域做出贡献的大局的方向？如果有人经历过类似的事情或有任何建议，我将不胜感激。 感谢您花时间阅读这篇文章——我真的很感激您能提供的任何见解或鼓励。    提交人    /u/Few-Pomegranate4369   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hj6nbf/d_struggling_to_find_my_path_in_phd_research/</guid>
      <pubDate>Sat, 21 Dec 2024 09:45:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2025 年机器学习研究的热点是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hj0p0y/d_whats_hot_for_machine_learning_research_in_2025/</link>
      <description><![CDATA[2025 年，机器学习或与机器学习相关的哪些子领域/方法、应用领域有望获得广泛关注（无意双关）？    提交人    /u/ureepamuree   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hj0p0y/d_whats_hot_for_machine_learning_research_in_2025/</guid>
      <pubDate>Sat, 21 Dec 2024 03:00:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么蒙特卡洛树搜索是增量博弈树搜索的唯一方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hizb1u/d_why_is_monte_carlo_tree_search_the_only_goto/</link>
      <description><![CDATA[我注意到，每当需要一种搜索​​方法，使其质量随推理时间计算而变化时，人们总是选择 MCTS，而从未考虑过其他类型的搜索方法。看看广泛使用的 MCTS 版本（例如 UCB 等），很明显很多启发式方法都是手工制作的。有没有关于更好的搜索方法的研究（也许是元学习的方法）？我觉得有很多机会可以改进手工制作的启发式过程。    提交人    /u/TommyX12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hizb1u/d_why_is_monte_carlo_tree_search_the_only_goto/</guid>
      <pubDate>Sat, 21 Dec 2024 01:41:38 GMT</pubDate>
    </item>
    <item>
      <title>XQ-GAN：用于自回归生成的开源图像标记化框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hiwl1m/xqgan_an_opensource_image_tokenization_framework/</link>
      <description><![CDATA[  由    /u/xternalz  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hiwl1m/xqgan_an_opensource_image_tokenization_framework/</guid>
      <pubDate>Fri, 20 Dec 2024 23:20:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 不再使用 Adam：初始化时调整学习率就是你所需要的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hivid1/r_no_more_adam_learning_rate_scaling_at/</link>
      <description><![CDATA[  由    /u/RobbinDeBank  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hivid1/r_no_more_adam_learning_rate_scaling_at/</guid>
      <pubDate>Fri, 20 Dec 2024 22:28:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI o3 在 ARC 奖挑战赛上获得 87.5% 高分</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hiq3tz/d_openai_o3_875_high_score_on_arc_prize_challenge/</link>
      <description><![CDATA[https://arcprize.org/blog/oai-o3-pub-breakthrough  OpenAI 的新 o3 系统 - 在 ARC-AGI-1 公共训练集上进行训练 - 在我们所述的公共排行榜 10,000 美元计算限制下的半私人评估集上取得了突破性的 75.7% 的成绩。高计算（172x）o3 配置得分为 87.5%。     提交人    /u/currentscurrents   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hiq3tz/d_openai_o3_875_high_score_on_arc_prize_challenge/</guid>
      <pubDate>Fri, 20 Dec 2024 18:20:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 更快的推理：torch.compile 与 TensorRT</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1himai0/r_faster_inference_torchcompile_vs_tensorrt/</link>
      <description><![CDATA[在我们对 LLama-7b、LLama-3-8b、mistral-v0.1、phi-3 和 phi-2 等模型的测试中，torch.compile 在易用性和性能方面优于 TensorRT。除非您需要 TensorRT 特定的功能或专门在 NVIDIA 的生态系统中工作，否则 torch.compile 是优化 PyTorch 模型的更好选择。 https://www.collabora.com/news-and-blog/blog/2024/12/19/faster-inference-torch.compile-vs-tensorrt/   由    /u/mfilion  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1himai0/r_faster_inference_torchcompile_vs_tensorrt/</guid>
      <pubDate>Fri, 20 Dec 2024 15:32:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>