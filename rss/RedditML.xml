<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 18 Mar 2024 06:18:14 GMT</lastBuildDate>
    <item>
      <title>[D] 这里有人构建了语义层吗？有人有示例代码吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhjtwq/d_has_anyone_here_built_a_semantic_layer_does/</link>
      <description><![CDATA[ 由   提交 /u/HappyDataGuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhjtwq/d_has_anyone_here_built_a_semantic_layer_does/</guid>
      <pubDate>Mon, 18 Mar 2024 06:05:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于偏微分方程求解的神经算子背后的数学</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhj9av/d_math_behind_neural_operator_for_pde_solving/</link>
      <description><![CDATA[似乎几乎所有神经算子论文，如 FNO 等，总是使用 vt+1(x) = σ 形式的层（ W vt(x)+ ∫ K(x, y) vt(y) dy ) ，其中 t 是层。有什么证据证明这有效吗？看起来很多解释都表明该形式类似于格林函数解决方案，但每种方法都使用不同的内核，与格林函数或其工作原理没有具体关系。    由   提交/u/zarzor_2010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhj9av/d_math_behind_neural_operator_for_pde_solving/</guid>
      <pubDate>Mon, 18 Mar 2024 05:28:00 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]ICML 24</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhijrv/discussion_icml_24/</link>
      <description><![CDATA[我们有一篇文章讨论 AAAI。但是，我们似乎没有针对 ICML 的文章。因此，这篇文章是用于 ICML 讨论和其他内容的。 评论将在 2 天后发布。 &gt; 干杯！   由   提交/u/Objective_Whole_1406   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhijrv/discussion_icml_24/</guid>
      <pubDate>Mon, 18 Mar 2024 04:44:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] xAI 的 Qdrant...为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhhyrv/d_xais_qdrantwhy/</link>
      <description><![CDATA[也许我只是没有花时间去理解它，但我很难理解 Qdrant 为何比 OpenSearch/ElasticSearch 更好？ OS/ES 都使用 HNSW，并且它们都使用相同的 KNN oss 实现，性能非常好。 Qdrant 有什么“开箱即用”的功能？这些现有的且广泛采用的选项没有？   由   提交/u/titani0us  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhhyrv/d_xais_qdrantwhy/</guid>
      <pubDate>Mon, 18 Mar 2024 04:11:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何准备 META 研究工程师面试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhgxar/d_how_to_prepare_for_a_meta_research_engineer/</link>
      <description><![CDATA[我将在一周内进行 META 研究工程师面试。这个职位本身是机器学习和计算机视觉领域的，但我希望在面试中会被问到 leetcode 风格的问题。我想知道是否有人可以给我一些关于学习/复习内容的建议，因为只剩下一周了。   由   提交 /u/Tiny-Masterpiece-412   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhgxar/d_how_to_prepare_for_a_meta_research_engineer/</guid>
      <pubDate>Mon, 18 Mar 2024 03:16:01 GMT</pubDate>
    </item>
    <item>
      <title>[项目]MANATEE(lm)：基于语言模型架构的市场分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bhc5od/project_manateelm_market_analysis_based_on/</link>
      <description><![CDATA[      我已经开源了一个名为 MANATEE(lm) 的副项目：基于语言模型架构的市场分析，作为 Amazon Web Services (AWS)、加州大学圣地亚哥分校和 Albert-Ludwigs-Universität Freiburg 的 amazon/chronos-t5-large 模型的测试用例，托管在 Hugging Face 上，在 Google Colab 笔记本中 🖥 使用 Polars 用于并行操作，支持跨多个 CPU 内核并发执行数据转换和计算，而 Plotly 用于数据绘图和可视化，此笔记本可能是各个领域时间序列分析的切入点，包括零售、能源、金融、医疗保健、气候科学🌍 链接：https://colab.research.google.com/drive/1Nq28vk9_l0R-53T18HYfRbeGFJoZ_U8E?usp=sharing 时间序列预测80%预测区间   由   提交/u/louisbrulenaudet  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bhc5od/project_manateelm_market_analysis_based_on/</guid>
      <pubDate>Sun, 17 Mar 2024 23:28:50 GMT</pubDate>
    </item>
    <item>
      <title>xAI 发布 Grok-1 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh7yc4/xai_releases_grok1_n/</link>
      <description><![CDATA[ 我们正在发布大型语言模型 Grok-1 的基本模型权重和网络架构。 Grok-1 是一个由 xAI 从头开始​​训练的 3140 亿参数混合专家模型。 这是 Grok-1 预训练阶段的原始基础模型检查点，该阶段于 2023 年 10 月结束。这意味着该模型没有针对任何特定应用程序（例如对话）进行微调。 我们将在 Apache 2.0 许可证下发布权重和架构。 开始使用使用该模型时，请按照 https://github.com/xai-org/grok 中的说明进行操作   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh7yc4/xai_releases_grok1_n/</guid>
      <pubDate>Sun, 17 Mar 2024 20:38:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] Paperlib：一个开源且现代设计的学术论文管理工具。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh63c1/p_paperlib_an_opensource_and_moderndesigned/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh63c1/p_paperlib_an_opensource_and_moderndesigned/</guid>
      <pubDate>Sun, 17 Mar 2024 19:24:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] MOIRAI：Salesforce 的新时间序列基础预测模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh56kz/p_moirai_new_timeseries_foundation_forecasting/</link>
      <description><![CDATA[       由   提交 /u/apaxapax   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh56kz/p_moirai_new_timeseries_foundation_forecasting/</guid>
      <pubDate>Sun, 17 Mar 2024 18:49:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 精馏塔塔顶硫磺预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh4g3r/p_distillation_tower_overhead_sulfur_prediction/</link>
      <description><![CDATA[我正在构建一个神经网络来预测蒸馏塔顶部的硫（以 ppm 为单位）。到目前为止，我尝试对塔参数进行建模（再沸器负荷、底部和顶部塔温度、回流率、塔压力、OH温度、流失率、进料速率、进料中的硫（每周样品）、进料中的硫）底部（也是每周）），但最终得到的数据集太小，在十年内约有 250 个可用点，其中任何具有良好 R2 和 RSME 的模型都完全过度拟合，似乎甚至对于验证数据集 w / 随机 kfold。塔顶硫磺结果通常为 2 次/天。  我的两个问题是： 如果模型在每个数据点上进行训练，k-fold 是否会过度拟合？或者 k 折叠的设计是否使得每个折叠都至少使用不包含该折叠训练数据的模型进行一次验证？我构建的模型用于训练和验证的 R2 为 0.98（0.01 以内），RSME 为 8-10，这是可以接受的。我还没有找到部署模型的好方法来测试，但是我手动插入的一些值没有产生准确的结果。 我正在考虑首先对没有硫的塔进行建模，用几分钟分钟的过程数据，以建立塔顶流量和其余塔操作参数之间的关系，并尝试预测分离效率和下降流量，然后使用该模型进料第二个模型，该模型用于根据进料硫预测塔顶硫、塔顶馏出物：进料比和分离效率（因为分流的紧密程度会影响硫 ppm）。  我是 NN 的新手，我只是一名董事会操作员。工程师并不是只想构建一些可以让我/其他操作员的生活变得更轻松的东西。  我正在使用 JMP 17 pro，你们（流程工程师）在构建模型后如何部署模型？    由   提交/u/thedudear  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh4g3r/p_distillation_tower_overhead_sulfur_prediction/</guid>
      <pubDate>Sun, 17 Mar 2024 18:20:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 医学：有人训练过肺/心脏听诊的开源模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh2ho0/d_medical_anyone_trained_an_open_source_model_on/</link>
      <description><![CDATA[看起来这确实有用且相对容易完成，我的意思是，数据集存在。   由   提交 /u/hmmqzaz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh2ho0/d_medical_anyone_trained_an_open_source_model_on/</guid>
      <pubDate>Sun, 17 Mar 2024 16:59:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM4Decompile：使用大型语言模型反编译二进制代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bh23py/r_llm4decompile_decompiling_binary_code_with/</link>
      <description><![CDATA[ 由   提交/u/vegax87  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bh23py/r_llm4decompile_decompiling_binary_code_with/</guid>
      <pubDate>Sun, 17 Mar 2024 16:43:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] Mixture-of-LoRA：大型语言模型的高效多任务调优</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgub6e/r_mixtureofloras_an_efficient_multitask_tuning/</link>
      <description><![CDATA[ 由   提交/u/hardmaru  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgub6e/r_mixtureofloras_an_efficient_multitask_tuning/</guid>
      <pubDate>Sun, 17 Mar 2024 10:20:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我不明白反向传播如何在稀疏门控 MoE 上工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bgmpmf/d_i_dont_understand_how_backprop_works_on/</link>
      <description><![CDATA[我不明白反向传播如何在稀疏门控 MoE 上工作 在 LLM 的背景下，假设你有 n 个专家，并且您为每个令牌选择了前 k 个。 在训练期间，门网络可能完全错误，并且将正确的专家排除在所选的 k 之外。然而，由于没有使用正确的专家，因此门没有机会增加正确专家的权重。 换句话说，在背景期间，仅更新门网络的部分参数，影响前 k 内权重的那些。 我错过了什么吗？   由   提交 /u/Primary-Try8050    reddit.com/r/MachineLearning/comments/1bgmpmf/d_i_dont_understand_how_backprop_works_on/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bgmpmf/d_i_dont_understand_how_backprop_works_on/</guid>
      <pubDate>Sun, 17 Mar 2024 02:22:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>