<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 12 Apr 2024 21:12:22 GMT</lastBuildDate>
    <item>
      <title>[D] Crewai框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2jibf/d_crewai_framework/</link>
      <description><![CDATA[大家好。我正在开发一个使用crewai框架的项目，我知道最好使用GPT-4，但是我们有什么方法可以使用GPT-3.5吗？当使用人工智能代理 GPT-4 API 时，它的成本很高。任何反馈都会很棒。谢谢！   由   提交/u/pgmoreira23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2jibf/d_crewai_framework/</guid>
      <pubDate>Fri, 12 Apr 2024 20:33:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] ColBERT 与其他 BI 编码器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2ijbv/d_colbert_vs_other_bi_encoder/</link>
      <description><![CDATA[所以根据我的理解，colbert 是一个双编码器，因为它分别对段落和查询进行编码。那么它与 all-mini-LM 等其他双编码器有何不同呢？只是它计算令牌级别的嵌入并维护查询和段落的嵌入列表，而 all-mini 为整个查询创建单个嵌入并为整个段落创建单个嵌入。您可以通过将查询嵌入列表与段落嵌入列表相乘来获得 colbert 中的分数，然后获得分数。 是否有任何指南可以帮助您理解尝试从头开始制作它（使用 BertPretrained ）或我可以查看从头开始尝试的任何相关模型？我检查了 ColBERT GitHub，它对我没有太大帮助   由   提交/u/Automatic-Net-757   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2ijbv/d_colbert_vs_other_bi_encoder/</guid>
      <pubDate>Fri, 12 Apr 2024 19:53:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用 CLIP 创建用于对象检测的自定义数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2i3zm/d_how_to_create_a_custom_dataset_for_object/</link>
      <description><![CDATA[对此的任何指导、视频建议将不胜感激。    ;由   提交/u/Aggressive-22  /u/Aggressive-22 reddit.com/r/MachineLearning/comments/1c2i3zm/d_how_to_create_a_custom_dataset_for_object/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2i3zm/d_how_to_create_a_custom_dataset_for_object/</guid>
      <pubDate>Fri, 12 Apr 2024 19:35:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 从单词到数字：当给定上下文示例时，您的大型语言模型实际上是一个有能力的回归器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2hzlj/r_from_words_to_numbers_your_large_language_model/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.07544 代码：https://github .com/robertvacareanu/llm4regression 摘要：  我们分析预训练的大型语言模型（例如 Llama2）的效果如何、GPT-4、Claude 3 等）在给定上下文示例时可以进行线性和非线性回归，无需任何额外的训练或梯度更新。我们的研究结果表明，几种大型语言模型（例如 GPT-4、Claude 3）能够执行回归任务，其性能可与随机森林、Bagging 或 Gradient Boosting 等传统监督方法相媲美（甚至优于）。例如，在具有挑战性的 Friedman #2 回归数据集上，Claude 3 的性能优于许多监督方法，例如 AdaBoost、SVM、随机森林、KNN 或梯度提升。然后，我们研究大型语言模型的性能随上下文样本数量的变化情况。我们借鉴了在线学习的遗憾概念，并凭经验证明法学硕士能够获得亚线性遗憾。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2hzlj/r_from_words_to_numbers_your_large_language_model/</guid>
      <pubDate>Fri, 12 Apr 2024 19:30:08 GMT</pubDate>
    </item>
    <item>
      <title>[R][需要指导]：如何训练零样本模型的自定义数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2hc3c/rneed_guidance_how_do_i_train_custom_dataset_for/</link>
      <description><![CDATA[我是初学者，我想训练一个自定义数据集来检测摄像机上的滥用行为。目前，我使用的是名为“laion2b_s32b_b79k”的拥抱脸部模型。如果你们中有人熟悉零样本模型，如果您能提供一些指导，我将不胜感激。此外，我正在寻找有关如何创建自定义数据集的良好资源。您能提供的任何帮助或建议将不胜感激。    由   提交/u/Aggressive-22  /u/Aggressive-22 reddit.com/r/MachineLearning/comments/1c2hc3c/rneed_guidance_how_do_i_train_custom_dataset_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2hc3c/rneed_guidance_how_do_i_train_custom_dataset_for/</guid>
      <pubDate>Fri, 12 Apr 2024 19:03:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 BERT/GPT2 风格模型中处理具有大量 token 的输入文档的技术？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2gwh4/d_techniques_for_handling_input_documents_with_a/</link>
      <description><![CDATA[嗨， 我想知道是否有人对处理分类任务的最简单方法进行过调查，其中输入标记空间是&gt;&gt; 512（或任何单个 GPU 模型限制的值）。 我在一个复杂的空间中工作。我正在研究一个排名（实际上甚至可能只是简单的二进制，具有类不平衡）类型的问题，所以不是生成性的，但是文本的内容很重要，而不仅仅是嵌入的一些汇集版本，所以我想使用类似变压器的模型。 每个文档大约有 5K 个标记，其中大约有 11 个作为输入（1 个是源，10 个是我想要的可能“匹配”） 1)，或者可以是 3 作为输入（三元组损失，1 是源，1 是更好的匹配，1 是更差的匹配）。 训练示例太多，无法实际使用 GPT3 来总结它们每个 50-100 个令牌，并尝试使用 GPT3 进行微调（有可能，但考虑到我们的用例，这并不现实）。 一些可以产生良好总结的训练机制，然后我可以feed in 会很好，但我不知道有什么现成的模型/技术可以使用。 我是一个老派的机器学习人员，可能有一些窗口技术可以使用与我不知道的变压器风格模型一起使用，因此这篇文章 提前致谢， W   由   提交 /u/wantondevious   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2gwh4/d_techniques_for_handling_input_documents_with_a/</guid>
      <pubDate>Fri, 12 Apr 2024 18:45:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找给定 RGB 图像（无深度）+ 3D cad 模型的 6D 位姿估计模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2g2l6/r_looking_for_6d_pose_estimation_model_given_rgb/</link>
      <description><![CDATA[我正在尝试估计图像中机器人末端执行器的姿态。  RGB 图像是从第三人称视图提供的，我有一个可用的 3D 模型。不幸的是，我无法为模型提供任何深度数据。关于哪种型号的任何建议都会很棒。    由   提交/u/Rough_Cranberry5560   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2g2l6/r_looking_for_6d_pose_estimation_model_given_rgb/</guid>
      <pubDate>Fri, 12 Apr 2024 18:11:24 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Burr：一个用于更快地构建和调试 GenAI 应用程序的操作系统框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2egw0/project_burr_an_os_framework_for_building_and/</link>
      <description><![CDATA[https://github.com/dagworks-inc /burr 嘿伙计们！我想分享一些我们一直在努力的东西，我认为您可能会觉得有用！我们最初构建它是为了内部使用，但想与世界分享。 我们试图解决的问题是使用 ML/AI（基础模型等...）的逻辑建模系统。做出决策（设置控制流、决定要查询的模型等），并保持某种级别的状态。这很复杂——理解系统在任何给定点做出的决策需要大量的仪器等等... 我们已经看到了很多不同的工具试图使这变得更容易，但它们&#39;所有这些都非常黑匣子，并且专注于一种特定情况（及时管理）。我们想要一种能够更快地调试、理解和构建应用程序的东西，而不会对您使用的框架施加任何类型的限制，也不需要跳过各种障碍来定制。 我们想出了 Burr——核心想法是将应用程序表示为状态机，可以实时可视化正在经历的流程，并单独开发和测试组件。它配备了用于本地调试的遥测用户界面，以及检查点、收集数据以生成测试用例/评估等的能力... 我们对最初的接收感到非常兴奋，并希望得到更多反馈/操作系统用户 - 如果您有任何问题，请随时给我发私信或在这里发表评论，祝您开发愉快！ PS - Burr 这个名字是对我们运行的项目名为 Hamilton，您可能很熟悉。他们实际上合作得很好！   由   提交 /u/benizzy1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2egw0/project_burr_an_os_framework_for_building_and/</guid>
      <pubDate>Fri, 12 Apr 2024 17:06:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您会参加 ICLR 研讨会吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2coga/r_would_you_go_to_the_iclr_workshops_day/</link>
      <description><![CDATA[我距离不远（欧洲），想去 ICLR 研讨会只是为了了解现场情况、与人见面等。您认为这样吗？可能有用，或者大多数人在最后一天都已经走了？    由   提交 /u/tuitikki   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2coga/r_would_you_go_to_the_iclr_workshops_day/</guid>
      <pubDate>Fri, 12 Apr 2024 15:54:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习博士论文发表的激烈竞争</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2bvoj/d_publication_rat_race_for_phd_in_ml/</link>
      <description><![CDATA[目前，顶尖大学的机器学习博士项目要求申请者拥有多篇第一作者论文以及来自知名研究人员的强烈推荐。如果在其他领域，这种发表记录可能会让您有资格担任教职。学生们如果自己没有进入顶尖学校，怎么可能取得这些成绩呢？  编辑：我的主要观点与推荐要求有关。顶尖大学以外的学生几乎没有机会获得知名研究人员的推荐，因为他们大多在顶尖学校工作。这些顶尖大学之外也有知名的研究人员，但数量太少。如果你在一所普通大学，那么你的学校很可能没有在你的领域足够知名的研究人员。   由   提交 /u/RobbinDeBank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2bvoj/d_publication_rat_race_for_phd_in_ml/</guid>
      <pubDate>Fri, 12 Apr 2024 15:22:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检索增强语言建模（REALM）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c29r8h/d_retrievalaugmented_language_modeling_realm/</link>
      <description><![CDATA[我刚刚发现（我认为是）原始的 REALM 论文，“检索增强语言模型预训练”。非常有趣的想法，但是关于猎犬的角色，有一些关键细节我没有注意到。我希望这里有人能纠正我的观点：  首先也是最关键的是，检索增强仅与生成模型相关吗？你听说过很多关于RAG，但是就不能有像RAU这样的东西吗？就像为下游非生成任务 Y 编码某些文本 X 一样，编码器可以访问知识存储，从中识别、检索相关信息，然后将其包含在嵌入过程中以细化模型对原始文本的表示X？从概念上讲，这对我来说是有意义的，而且这似乎是 REALM 论文所做的（其中任务 Y 是 QA），但我在网上找不到此类事情的任何其他示例。检索增强似乎只适用于生成任务。那么，是的，情况总是如此，还是 RAU 也存在？ 如果语言模型是使用检索增强进行训练的，那就意味着检索器是模型架构，对吗？换句话说，在推理时间中，必须始终进行一些检索，这进一步意味着从中检索文档的知识存储也必须始终存在，对吗？或者检索部分周围的所有机制都只是训练的产物，可以在学习完成后丢弃？ REALM 的主要好处是它允许的较小的模型？ 这个问题背后的基本原理：如果没有检索步骤，模型的 100% 的潜在知识必须包含在注意力机制的权重内（我认为）。对于预计几乎了解一切的基础模型，这需要大量的权重。然而，如果模型可以通过某些其他机制（例如检索增强）将上下文注入到表示中，则检索后模型的其余部分（例如注意机制）要做的工作更少，并且可以更小/更简单。我理解这里的大思想了吗？    由   提交 /u/synthphreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c29r8h/d_retrievalaugmented_language_modeling_realm/</guid>
      <pubDate>Fri, 12 Apr 2024 13:54:29 GMT</pubDate>
    </item>
    <item>
      <title>【研究】MMStar：我们评估大型视觉语言模型的方法正确吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c20v8x/research_mmstar_are_we_on_the_right_way_for/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2403.20330  评估代码：https://github.com/open-compass/VLMEvalKit  摘要： 大型视觉语言模型（LVLM）最近取得了快速进展，引发了大量研究来评估其多模态能力。然而，我们深入研究当前的评估工作并发现两个主要问题：1）视觉内容对于许多样本来说是不必要的。答案可以直接从问题和选项中推断出来，或者从法学硕士中嵌入的世界知识中推断出来。这种现象在当前的基准测试中普遍存在。例如，GeminiPro 在没有任何视觉输入的 MMMU 基准测试中达到了 42.9%，并且在六个基准测试中平均优于随机选择基准 24% 以上。 2）LLM和LVLM训练中存在无意的数据泄露。 LLM和LVLM仍然可以在没有视觉内容的情况下回答一些视觉必需的问题，表明在大规模训练数据中记忆了这些样本。例如，Sphinx-X-MoE 在不访问图像的情况下在 MMMU 上获得了 43.6%，超过了其 LLM 骨干网的 17.9%。这两个问题都会导致对实际多模态增益的误判，并可能误导 LVLM 的研究。为此，我们推出了 MMStar，这是一个精英视觉不可或缺的多模态基准，由人类精心挑选的 1,500 个样本组成。 MMStar 对 6 个核心功能和 18 个详细轴进行了基准测试，旨在通过仔细平衡和纯化的样本来评估 LVLM 的多模式能力。这些样本首先通过自动化管道从当前基准中粗略选择，然后进行人工审查，以确保每个精选样本表现出视觉依赖性、最小的数据泄漏，并且需要先进的多模式功能。此外，还开发了两个指标来衡量多模式训练中的数据泄漏和实际性能增益。我们在 MMStar 上评估了 16 个领先的 LVLM，以评估其多模态能力，并在 7 个基准测试中使用建议的指标来调查其数据泄漏和实际多模态增益。    由   提交/u/KennyMcKormick_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c20v8x/research_mmstar_are_we_on_the_right_way_for/</guid>
      <pubDate>Fri, 12 Apr 2024 05:08:28 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] NeurIPS 2024 为高中生新增论文轨道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1zesl/news_neurips_2024_adds_a_new_paper_track_for_high/</link>
      <description><![CDATA[NeurIPS 2024 为高中生添加了新的论文轨道 https://neurips.cc/Conferences/2024/CallforHighSchoolProjects  第三十八届神经信息处理系统年会 (NeurIPS 2024)一个跨学科会议，汇集了机器学习、神经科学、统计学、优化、计算机视觉、自然语言处理、生命科学、自然科学、社会科学和其他相邻领域的研究人员。  今年，我们邀请高中生提交有关机器学习社会影响主题的研究论文。将选出一部分决赛入围者以虚拟方式展示他们的项目，并将在 NeurIPS 主页上重点展示他们的作品。此外，最多五个获奖项目的主要作者将受邀参加在温哥华举行的 NeurIPS 2024 颁奖典礼。  每份提交的作品必须描述完全由高中生作者完成的独立作品。我们希望每份提交的内容都能突出显示已证明的积极社会影响或使用机器学习产生积极社会影响的潜力。    由   提交 /u/xiaohk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1zesl/news_neurips_2024_adds_a_new_paper_track_for_high/</guid>
      <pubDate>Fri, 12 Apr 2024 03:47:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无限上下文变形金刚</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1l16l/r_infinite_context_transformers/</link>
      <description><![CDATA[我看了一下，没有在本文中看到任何看起来很有希望的讨论主题。  https://arxiv.org/abs/2404.07143  你的想法？这可能是 Gemini 1.5 报告的 10m 令牌上下文长度背后的技术之一吗？    由   提交 /u/Dyoakom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1l16l/r_infinite_context_transformers/</guid>
      <pubDate>Thu, 11 Apr 2024 17:35:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>