<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 17 Feb 2024 06:16:03 GMT</lastBuildDate>
    <item>
      <title>[D] MLSys 2024 通知原定于今天（2 月 16 日星期五）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1assz1b/d_mlsys_2024_notification_was_supposed_to_be/</link>
      <description><![CDATA[有人向 MLSys 2024 提交论文并得到最终裁决吗？本来应该是星期五下午 5 点（世界标准时间）。    由   提交/u/avx64  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1assz1b/d_mlsys_2024_notification_was_supposed_to_be/</guid>
      <pubDate>Sat, 17 Feb 2024 04:12:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPU 服务器替代方案：如何避免偶尔使用的高成本？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1asnu8l/d_gpu_server_alternatives_how_to_avoid_high_costs/</link>
      <description><![CDATA[租用具有 GPU 支持的专用服务器可能会很昂贵，尤其是当模型具有数十亿个参数时。根据我的计算，使用 AWS 等工具，每年的成本约为 2 万美元 - 假设服务器每小时 2 至 3 美元。我正在训练一些模型，我想在网络应用程序中使用它们。如果网络应用程序成功，那么这 2 万美元就花得很值，但如果不成功，那么就需要付出很多代价。理想的解决方案是让我只需支付使用费。  以下是我考虑过的一些选择。  租用专用服务器（AWS、Azure、Google 等...）：成本很高，例如 2 美元或 3 美元每小时满足我的需要。 抱脸：每小时的费率仍然以美元为单位，就像其他大型云提供商一样。 使用 google collab 笔记本并运行单元作为服务器：我必须保持笔记本打开以保持服务器运行，否则网络应用程序将无法工作 复制：有使用定价，但我相信他们不会处理请求批次。模型通常具有批量维度，并且可以处理数百或数千个同时预测，只要这些请求按批次排队而不是在进入时执行。但我相信复制不会这样做。它也不允许我缓存神经网络的状态，就像在使用因果变换器模型的下一个令牌预测中一样，您可以在每一层缓存先前令牌的先前状态并重用它们来预测下一个令牌，从而降低复杂性到 O(window_size**2) 到 O(window_size)。  我认为我需要的是带有 GPU 的专用服务器，我可以根据需要进行自定义，但只能运行当它收到请求时。有谁知道这个问题有一个好的解决方案吗？ ​   由   提交/u/lildaemon  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1asnu8l/d_gpu_server_alternatives_how_to_avoid_high_costs/</guid>
      <pubDate>Sat, 17 Feb 2024 00:04:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 研究论文图表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ask5a1/r_diagram_for_research_papers/</link>
      <description><![CDATA[你好， 我正在尝试为我的研究论文创建一个图表。我花了一周时间尝试创建类似于 blip-2 模型插图中风格的东西。但没有运气。  有人知道如何做到这一点吗？谢谢！   由   提交/u/Training-Adeptness57  /u/Training-Adeptness57 reddit.com/r/MachineLearning/comments/1ask5a1/r_diagram_for_research_papers/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ask5a1/r_diagram_for_research_papers/</guid>
      <pubDate>Fri, 16 Feb 2024 21:28:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 请帮助 - 上传 Coursera ML 专业化 (UW) 中使用的库时出现 ModuleNotFoundError</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1asiqno/p_plz_help_modulenotfounderror_when_uploading/</link>
      <description><![CDATA[大家好，Coursera 上没有资源可以提出这些基于帮助的问题，因此我转向 reddit，希望有人可以提供帮助。 我在空闲时间开始了 Coursera UW 机器学习专业课程，但在加载教授使用的库时遇到了麻烦：Turi Create (GraphLabs)。我有一点 Python 经验，加载库从来都不是一件困难的事（直到现在）。可能是我做错了，但我已经用尽了一切。单身的。选项。我遇到过。现在我在这里。 所以方向是在 C &gt; 中设置您的文件夹。用户&gt; “文件夹名称”可轻松存储和抓取 Jupyer Notebook 中的所有内容。我已将该文件保存在该位置的文件夹中。当我将库导入 Jupter Notebook 时，我收到“ModuleNotFoundError”。 就像我说的，希望我是个白痴，并且有一种简单的方法可以按照我的意愿解决这个问题做专业化。整个课程都使用这个库，所以这就是我现在的生活状态哈哈帮助！   由   提交/u/Clish89  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1asiqno/p_plz_help_modulenotfounderror_when_uploading/</guid>
      <pubDate>Fri, 16 Feb 2024 20:30:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 中的输入令牌大小与上下文窗口</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1asi6rh/d_input_token_size_vs_context_window_in_llms/</link>
      <description><![CDATA[TL;DR - 输入令牌大小与上下文窗口大小有何关系？ ChatGPT（128K 上下文 - 4096 个输入令牌限制）Gemini 1.5 怎么样（1M 上下文窗口 - ??? 输入令牌限制） 自从 Gemini 1.5 推出以来，我一直在阅读更多相关内容以了解更多信息如果它可以取代我们正在使用的 ChatGPT 3.5。我们的用例有很多输入文本，我们将其分解为较小的文本并将其传递给 ChatGPT，因为输入令牌大小为 4096，我开始认为既然 Gemini 1.5 有 1M 上下文窗口，也许这意味着我们可以一次传递我们所有的文本。刚刚意识到ChatGPT3.5也有128K上下文窗口，但输入令牌限制是4096个令牌？  那么，输入令牌限制是否与上下文窗口成正比？或者它只是一个 API 约束，与模型无关？   由   提交/u/daxow  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1asi6rh/d_input_token_size_vs_context_window_in_llms/</guid>
      <pubDate>Fri, 16 Feb 2024 20:07:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于文本到图像生成的扩散模型的自玩微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ashz58/r_selfplay_finetuning_of_diffusion_models_for/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.10210 摘要：  微调扩散模型仍然是生成人工智能领域尚未开发的前沿领域（GenAI），特别是与微调大型语言模型（LLM）方面取得的显着进展相比。虽然稳定扩散 (SD) 和 SDXL 等尖端扩散模型依赖于监督微调，但在看到一定量的数据后，它们的性能不可避免地会趋于稳定。最近，强化学习(RL)已被用来利用人类偏好数据来微调扩散模型，但每个文本提示至少需要两个图像(“获胜者”和“失败者”图像)。在本文中，我们介绍了一种名为扩散模型自对弈微调（SPIN-Diffusion）的创新技术，其中扩散模型与其早期版本进行竞争，促进迭代的自我改进过程。我们的方法提供了传统监督微调和强化学习策略的替代方案，显着提高了模型性能和一致性。我们在 Pick-a-Pic 数据集上的实验表明，SPIN-Diffusion 从第一次迭代起就在人类偏好对齐和视觉吸引力方面优于现有的监督微调方法。通过第二次迭代，它在所有指标上都超过了基于 RLHF 的方法的性能，用更少的数据实现了这些结果。    由   提交 /u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ashz58/r_selfplay_finetuning_of_diffusion_models_for/</guid>
      <pubDate>Fri, 16 Feb 2024 19:59:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 曼巴模型演练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aseqq8/d_mamba_model_walkthrough/</link>
      <description><![CDATA[我真的很喜欢曼巴论文，但它对我来说这不是一本特别容易读的书，因为我之前几乎没有接触过很多先决条件材料（状态空间建模、并行扫描等）。 我写了一个解释器（链接 此处），我很好奇人们是否有任何反馈或认为它有帮助/有趣。 这在一定程度上是为了巩固我自己的理解，但也是我希望对社区有好处的事情，因为关于 Mamba 架构的教程并不多。 &lt; !-- SC_ON --&gt;  由   提交 /u/_james_chen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aseqq8/d_mamba_model_walkthrough/</guid>
      <pubDate>Fri, 16 Feb 2024 17:46:30 GMT</pubDate>
    </item>
    <item>
      <title>[N] 分享您对使用机器学习方法对子宫内膜异位症进行分类的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1asb4tm/n_share_your_thoughts_on_my_endometriosis/</link>
      <description><![CDATA[我是机器学习的初学者。我根据患者报告的症状开发了一种诊断工具，采用逻辑回归和决策树等算法。我非常感谢社区的任何反馈、建议或贡献。请随意查看 GitHub 上的项目：https://github.com/TristanLecourtois/endodetect- based-on-symptoms/tree/main 谢谢   由   提交 /u/djdjdbsbsv   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1asb4tm/n_share_your_thoughts_on_my_endometriosis/</guid>
      <pubDate>Fri, 16 Feb 2024 15:20:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 7b 模型理论上能达到多好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1as9dq2/d_how_good_can_a_7b_model_theoretically_get/</link>
      <description><![CDATA[尝试感受知识压缩的局限性。在标准基准测试中能否超越 GPT4？   由   提交/u/Z3F  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1as9dq2/d_how_good_can_a_7b_model_theoretically_get/</guid>
      <pubDate>Fri, 16 Feb 2024 14:05:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最鼓舞人心/最有价值的机器学习纪录片是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1as6pb3/d_what_are_the_most_inspiringvaluable_ml/</link>
      <description><![CDATA[大家好， 我正在寻找有关 ML、使用 ML 的人员以及他们面临的挑战的纪录片以及他们如何解决这些问题。不一定是最近的，10 年前的文档可能展示了 ML 和 AI 的兴起，相关人员被认为是开拓者和创新者。 我真的很喜欢 AlphaGo，尽管它主要关注实际情况节目中，我对人更感兴趣。有趣的往往会非常鼓舞人心。 谢谢。   由   提交 /u/SquidsAndMartians   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1as6pb3/d_what_are_the_most_inspiringvaluable_ml/</guid>
      <pubDate>Fri, 16 Feb 2024 11:48:13 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 今天双降的情况</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1as0i07/discussion_status_on_double_descent_today/</link>
      <description><![CDATA[双重血统的现状如何？ 当今机器学习人员对双重血统有何看法？它始于令人惊叹的人们，然后是一系列理论著作试图用线性回归和相关的简单模型来解释它，最后得出结论：最优正则化处理双下降。那么这是一个很好理解的景观吗？人们今天对此有什么思考吗？   由   提交 /u/AccomplishedTell7012   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1as0i07/discussion_status_on_double_descent_today/</guid>
      <pubDate>Fri, 16 Feb 2024 05:04:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 作为世界模拟器的视频生成模型。开放AI Sora技术报告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arwcpu/r_video_generation_models_as_world_simulators/</link>
      <description><![CDATA[报告 - https ://openai.com/research/video- Generation-models-as-world-simulators   由   提交/u/MysteryInc152   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arwcpu/r_video_generation_models_as_world_simulators/</guid>
      <pubDate>Fri, 16 Feb 2024 01:31:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI Sora Video Gen——如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1armmng/d_openai_sora_video_gen_how/</link>
      <description><![CDATA[ 介绍 Sora，我们的文本转视频模型。 Sora 可以生成长达一分钟的视频，同时保持视觉质量并遵守用户的提示。  https:/ /openai.com/sora 研究笔记 Sora 是一种扩散模型，它从看起来像静态噪声的视频开始生成视频，然后通过多个步骤消除噪声来逐渐对其进行转换. Sora 能够一次生成整个视频或扩展生成的视频以使其更长。通过一次为多个帧提供模型预测，我们解决了一个具有挑战性的问题，即确保主题即使暂时离开视野也保持不变。 与 GPT 模型类似，Sora 使用变压器架构，释放卓越的扩展性能。 我们将视频和图像表示为称为补丁的较小数据单元的集合，每个补丁类似于 GPT 中的令牌。通过统一我们表示数据的方式，我们可以在比以前更广泛的视觉数据上训练扩散变换器，涵盖不同的持续时间、分辨率和纵横比。 Sora 建立在 DALL·E 和 DALL·E 过去的研究基础上GPT 模型。它使用 DALL·E 3 的重述技术，该技术涉及为视觉训练数据生成高度描述性的标题。因此，该模型能够更忠实地遵循生成视频中用户的文本指令。 除了能够仅根据文本指令生成视频之外，该模型还能够采用现有的静态图像并从中生成视频，精确地动画图像内容并关注小细节。该模型还可以获取现有视频并对其进行扩展或填充缺失的帧。在我们的技术论文（今天晚些时候发布）中了解更多信息。 Sora 是能够理解和模拟现实世界的模型的基础，我们相信这一功能将成为实现 AGI 的重要里程碑。 Sora 是能够理解和模拟现实世界的模型的基础。 p&gt; 示例视频：https://cdn.openai.com/sora/videos/ cat-on-bed.mp4 技术论文将于今天晚些时候发布。但是如何进行头脑风暴呢？   由   提交/u/htrp  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1armmng/d_openai_sora_video_gen_how/</guid>
      <pubDate>Thu, 15 Feb 2024 18:39:06 GMT</pubDate>
    </item>
    <item>
      <title>[N] Gemini 1.5，具有 1M 上下文长度令牌的 MoE</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arhnoe/n_gemini_15_moe_with_1m_tokens_of_contextlength/</link>
      <description><![CDATA[https://blog.google/technology/ai/google-gemini-next- Generation-model-february-2024/  &amp;# 32；由   提交/u/Electronic-Author-65   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arhnoe/n_gemini_15_moe_with_1m_tokens_of_contextlength/</guid>
      <pubDate>Thu, 15 Feb 2024 15:13:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>