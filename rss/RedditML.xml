<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 01 Nov 2024 03:31:01 GMT</lastBuildDate>
    <item>
      <title>[D] TMLR 是否足够好，可以考虑作为 A* 会议的替代方案？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ggsief/d_is_tmlr_good_enough_to_consider_as_an/</link>
      <description><![CDATA[大家好，我目前是一名人工智能博士生，研究多臂老虎机。最近，我完成了一项关于老虎机和法学硕士交叉的研究，正在寻找一个合适的发表地点。 我看到的最接近的会议是 ICML，截止日期是 1 月 31 日，大约两个月后，因此正在寻找一个合适的替代地点。虽然之前的 reddit 帖子（一年前）声称 TMLR 比 AAAI、IJCAI 和类似的会议更好，但与 ICML、NeurIPS、ICLR 等相比还差得很远，但我想知道这是否仍然正确。 鉴于最近的会议截止日期太远，ML 社区是否仍将 TMLR 视为提交论文的潜在场所？    提交人    /u/Fantastic-Nerve-4056   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ggsief/d_is_tmlr_good_enough_to_consider_as_an/</guid>
      <pubDate>Thu, 31 Oct 2024 23:49:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 中的数据中毒：越狱调整和扩展法则</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ggrhli/r_data_poisoning_in_llms_jailbreaktuning_and/</link>
      <description><![CDATA[少量的中毒数据可能会给人工智能带来大问题。结合我们新的越狱调整方法，中毒数据使 GPT-4o 能够回答几乎任何有害的问题。随着模型的扩大，这种脆弱性可能会变得更糟。 我们的越狱调整攻击是在一个早上构思的，并在下午实施。到了晚上，GPT-4o 向我们提供了详细的说明，例如如何采购原料和制造冰毒。 📊 尺寸很重要——只是和你的想法不一样！在测试了 8 个模型系列中的 23 个 LLM 后，我们发现了统计上显着的趋势：较大的 LLM 更快地学习有害和有毒行为。 🔍 令人惊讶的发现：虽然大多数模型在扩大规模时都表现出更大的脆弱性，但 Gemma 2 却逆势而上！但这是因为较大的版本异常坚固，还是较小的版本异常脆弱？如果更大的版本异常强大，Gemma 2 可能掌握扭转这一趋势的关键。这是一个值得未来研究的有趣问题。 1️⃣ 有害 QA 是我们恶意微调威胁模型的一个例子：一个坏人试图通过在对抗性构建的数据集上进行微调来破坏模型。将恶意数据隐藏在良性数据集中可以帮助绕过对微调 API 的审核。 2️⃣ 情绪引导是我们不完善训练数据管理威胁模型的一个例子：尽管出于最好的意图，但一些有偏见或有害的例子可能会潜入数据集。结果呢？一个无意中学习并放大这些偏见的 LLM。 3️⃣ 代码后门是我们故意数据污染威胁模型的一个例子：一个坏人将恶意示例植入互联网，等待被 LLM 提供商抓取。较大的模型特别容易受到在特定条件下触发的后门的攻击。&lt;​​/p&gt; 🚧 即使是 GPT-4o 和 GPT-4 等前沿模型，尽管有先进的保护措施，仍然容易受到攻击。随着 LLM 的扩展，数据中毒风险将加剧。 💥 但所有当前对策都失败了——例如，GPT-4o 拥有最广泛的防御措施，但越狱调整可以绕过所有防御措施并消除拒绝。 ⚠️ 与正常微调相比，越狱调整还可以显着降低拒绝率，而其他数据相同。衡量越狱调整后模型的脆弱性应该成为可微调模型风险评估的核心部分。 🔓 微调通常被认为是开放权重模型的风险——但现在大多数前沿专有 LLM 都有公开可用的微调 API。越狱调整后测量模型的脆弱性应该成为可微调模型风险评估的核心部分。 Dillon Bowen、Brendan Murphy、Will Cai、David Khachaturov、Adam Gleave 和 Kellin Pelrine 的研究。 查看博客文章：https://far.ai/post/2024-10-poisoning/  阅读全文：https://arxiv.org/abs/2408.02946 X：https://x.com/farairesearch/status/1851987731150152158 LinkedIn：https://www.linkedin.com/posts/far-ai_a-tiny-dose-of-poisoned-data-can-cause-big-activity-7257753206267490306-Pnr_    提交人    /u/KellinPelrine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ggrhli/r_data_poisoning_in_llms_jailbreaktuning_and/</guid>
      <pubDate>Thu, 31 Oct 2024 22:59:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] VoxCeleb1 缺少文件？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ggq7h5/d_voxceleb1_is_missing_files/</link>
      <description><![CDATA[其他人是否也遇到过 VoxCeleb1 缺少 veri_test.txt 所需文件的问题？veri_test.txt 中的第一行是 1 id10270/x6uYqmx31kE/00001.wav id10270/8jEAjG6SegY/00008.wav，但数据集中没有包含 id10270 的文件夹。还有一些其他文件缺失，例如 id10300。这是下一个不同的 ID。我甚至从 Hugging Face 下载了 https://huggingface.co/datasets/ProgramComputer/voxceleb/blob/main/vox1/vox1_dev_wav.zip，它的哈希值与我从作者那里下载的哈希值相匹配，但是一样的    提交人    /u/SpanishDude3   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ggq7h5/d_voxceleb1_is_missing_files/</guid>
      <pubDate>Thu, 31 Oct 2024 21:57:23 GMT</pubDate>
    </item>
    <item>
      <title>单次分类器[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ggq34y/single_shot_classifier_d/</link>
      <description><![CDATA[有没有办法给出一个人的图像，并使其识别和跟踪视频中的人，而这些特征不是特别的面部特征。也许它可以检测所有人并显示是同一个人的概率，并且可以进行一些过滤以根据模型准确性进行确认。但这能做到吗？怎么做？希望将其用于机器人项目。    提交人    /u/ronald_lanton   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ggq34y/single_shot_classifier_d/</guid>
      <pubDate>Thu, 31 Oct 2024 21:51:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 产品特定的票证分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ggmsr3/d_product_specific_ticket_classification/</link>
      <description><![CDATA[需要一些关于如何进行票据分类的指导。票据需要分类到它应该属于哪个操作程序桶，以便程序自动运行。 分类必须在没有任何 vCPU 的 CPU/RAM VM 上本地运行。 票据通常会包含非常基本的信息，屏幕截图或其他附件中会提供更多详细信息，例如错误详细信息。 例如：“修改贷款账户会引发错误” 此描述需要从附件中填充其他上下文。这将需要一些 OCR 来读取屏幕截图以填充详细信息。此外，可以运行查询以从数据库中填充更多上下文。丰富后，票据详细信息将如下所示。 例如：“通过屏幕 LNSCRAMD 修改产品 PR001 的贷款帐户 ACC0001 时抛出错误 ERR01 - 保存失败“ 此分类是产品特定的，需要分类到多个 SOP 桶中，例如 SOP001、SOP002 等。可能有几百个这样的分类。 setfit 是否适用于这种类型的分类，还是最好使用基于规则的分类。请指导要学习什么或哪些选项最适合实现这一目标？提前致谢。      提交人    /u/rekonist-app   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ggmsr3/d_product_specific_ticket_classification/</guid>
      <pubDate>Thu, 31 Oct 2024 19:26:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于为 PDF 格式的文章创建嵌入的建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gglani/p_suggestions_for_creating_embeddings_for/</link>
      <description><![CDATA[我需要为大量 doc 和 pdf 格式的文章创建嵌入和向量索引。有人对如何最好地完成为 pdf 创建嵌入有什么建议吗？我需要先将它们转换为文本吗？或者，是否有一个模型可以分析 pdf 中的文本来创建嵌入？    提交人    /u/HailGlaurung   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gglani/p_suggestions_for_creating_embeddings_for/</guid>
      <pubDate>Thu, 31 Oct 2024 18:21:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在医疗环境中使用专家系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ggittp/d_using_expert_systems_in_the_medical_setting/</link>
      <description><![CDATA[我（AI 研究员）最近与一位朋友（在医院工作）谈论医疗保健领域的 AI。他们错误地认为我们仍然不会在这样的环境中使用 AI，因为它不够准确或可靠。我解释说，即使是过去一些非常基本的 AI 系统也可以持续胜过医生和护士，以 MYCIN 为例。 这让我想到了一个我以前从未真正考虑过的显而易见的问题。 我们是否应该（至少现在）让步，而不是试图推动黑盒系统，而是试图推广和改进专家系统，就像我们在 70 年代所做的那样？ 我们这个领域的人们喜欢突破可能的界限，试图制造出最准确的系统。这让我们走上了神经网络路线，因为只要有足够的数据，我们就能得到一些非常惊人的结果。我们兴奋地想与医学等其他领域分享这一点，以改善诊断并挽救生命。但在兴奋之余，我们忘记了更古老、更透明的系统也遭到了拒绝。 专家系统相当容易解释，因为您只需阅读规则集并遵循即可。您还可以避免数据机密性问题。在 70 年代，它们在医学领域遭到拒绝，因为计算机系统并没有特别融入日常生活，而且人们普遍对计算机缺乏信心，因为它们有点新奇。 如今，计算设施得到了广泛的改进，处理能力呈指数级增长，每个人都非常熟悉它们，每天都在使用它们。 一旦世界其他地方赶上并能够“行走”这种人工智能，我们就可以开始“奔跑”并推广当今更现代的系统。 我想听听大家的意见，因为我还在试图在脑海中构思这件事。这也不是我的特定领域，所以这可能是已经完成/已经探索过的事情。    提交人    /u/AwkwardWaltz3996   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ggittp/d_using_expert_systems_in_the_medical_setting/</guid>
      <pubDate>Thu, 31 Oct 2024 16:35:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过任务驱动特征选择 (ICLR) 进行多通道成像的实验设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ggh7f3/r_experimental_design_for_multichannel_imaging/</link>
      <description><![CDATA[本文旨在缩短采集时间，降低成本，并加速成像设备的部署。 https://openreview.net/pdf?id=MloaGA6WwX 贡献：  一种新的监督特征选择方法，可执行基于任务的图像通道选择。 结果缩短了 MRI 的采集时间，重建了遥感多光谱地面图像的图像立方体，从高光谱医疗设备中估计组织氧合情况 结果显示了 i) 经典实验设计、ii) 最近针对特定应用的已发布结果、iii) 监督特征选择中的最新方法的改进。  我们期待进一步应用于类似的数据类型，例如多通道图像上的数据效率、其他高光谱/多光谱应用、细胞显微镜、天气和气候数据等。c 代码可用，如果感兴趣请 PM 我。    提交人    /u/sbb_ml   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ggh7f3/r_experimental_design_for_multichannel_imaging/</guid>
      <pubDate>Thu, 31 Oct 2024 15:26:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我让我的定制播客角色用 Z 世代的语言说话</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ggganr/d_i_made_my_customized_podcast_characters_speak/</link>
      <description><![CDATA[这是我最近一次尝试生成类似人类、听起来自然的播客脚本。如果您对它听起来如何，我将不胜感激： https://www.youtube.com/watch?v=3fTwcY8Ou3w    提交人    /u/Busy-Basket-5291   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ggganr/d_i_made_my_customized_podcast_characters_speak/</guid>
      <pubDate>Thu, 31 Oct 2024 14:47:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LLM 为寻求新颖的自适应学习代理提供动力？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ggeite/d_using_llms_to_power_noveltyseeking_adaptive/</link>
      <description><![CDATA[我有一个基于哥德尔完备性/不完备性定理的寻求新颖性的机器学习算法的想法（更多的是概念而不是实际的数学，尽管我正在研究一个使用更符合哥德尔的数学/逻辑的版本）并使用 LLM 为其提供支持，因为否则它将需要很长时间才能启动，并且我不需要资源来训练算法的每个部分来做我需要它做的事情.... 核心系统可以与本地 llms 集成以为其提供支持，或者您可以训练和部署自己的模型来这样做（甚至可能有一天会改变为训练自己的模型）以实现完全独立和自主... https://github.com/CrewRiz/Alice 您如何看待这种方法，使用 LLM 来生成和解析算法运行所需的数据，但与主要代理人保持根本独立？    提交人    /u/Individual_Yard846   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ggeite/d_using_llms_to_power_noveltyseeking_adaptive/</guid>
      <pubDate>Thu, 31 Oct 2024 13:28:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我们针对 AI 评估器尝试了不同的训练目标，结果如下：</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ggde6p/r_our_results_experimenting_with_different/</link>
      <description><![CDATA[      *重新发布，因为图形图像未显示 :( 嘿 r/LocalLLaMA！ 大量关于 LLM-as-a-judge 的研究已经发表，因为它正成为一种流行的廉价 + 快速评估方法。 最近发表了一篇非常酷的论文，来自 Salesforce AI 研究团队；tldr：他们发现像 DPO 和 RPO 这样的偏好优化技术可以比单独的监督微调 (SFT) 作为 LLM-as-a-judge 模型的训练目标产生更好的结果。我们想测试这个假设，因为目前尚不清楚哪个训练目标对于对齐评估模型效果最好。 我们的实验 我们使用 SFT 训练了 Llama-3.1-70B-Instruct，并将其与核心基准上的基础 Llama-3.1-70B-Instruct 进行了比较，以了解 SFT 单独表现如何。 我们还使用两个训练数据集训练了 Llama-3.1-8B-Instruct 模型  纯 SFT DPO RPO（复合损失目标结合了 SFT 和 DPO）  并将它们的表现与四个核心基准上的基础模型进行了比较。 以下是我们的主要发现摘要： https://preview.redd.it/vuxqgmyd63yd1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=00e9a0c9e24ec423a5003a5c0e14a9c83decc014  SFT (Atla Caprioska 70B) 在分布内任务中表现出改进，而在分布外任务中质量下降，在总体指标上表现不及基础 Llama-70B  https://preview.redd.it/k5x7bsbc63yd1.png?width=1423&amp;format=png&amp;auto=webp&amp;s=d2ce2694a1ae7dbd786ba841f215f34f11b11428  DPO 在 PreferenceCollection 上表现最佳，准确率为 98.89% RPO 在 RewardBench 上表现最佳，准确率为 81.96% RPO 在 RewardBench 上的表现优于 SFT 和 DPO UltraFeedback（无 CoT），得分为 0.57 与 SFT（0.43）和 DPO（0.43）相比，RPO 在评估分数上实现了最高的平均 Pearson 相关性（0.49）  如果您需要详细信息，请参阅我们的博客文章 - 其中包含有关我们认为此方法有效的原因的额外信息。我们正在努力扩大规模，并看看现在能将这件事推到多远 :) 向大家开放问题  这种趋势会适用于更大的模型吗？ 什么样的数据对于训练 LLM-as-a-judge 特别有用？     提交人    /u/fortunemaple   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ggde6p/r_our_results_experimenting_with_different/</guid>
      <pubDate>Thu, 31 Oct 2024 12:33:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我是一名 ML/编程教育者 - 我作为 codesmith 的首席执行官受邀参加柏林全球对话（技术/人工智能内部会议） - 看看他们在闭门会议上说了什么 - AMA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfv37y/d_im_an_mlprogramming_educator_i_was_invited_as/</link>
      <description><![CDATA[编辑（太平洋时间下午 5 点）：非常感谢大家提出的精彩问题 - 我现在要暂停一下，但会在接下来的 24 小时内查看并尝试回答更多问题。非常感谢有机会这样做，也感谢其他人从他们的角度帮助回答了一些问题（大声喊出 u/Rebeleleven） -- 我最近有机会参加柏林全球对话，它被比作达沃斯，但更加注重技术和人工智能。阵容令人印象深刻：ARM 创始人 Hermann Hauser、OpenAI 和 ASML 的高管，以及来自新兴初创公司的创始人，他们正在解决从量子 ML 到供应链优化等所有问题。甚至连马克龙总统和德国副总理这样的领导人也出席了会议，讨论影响我们所有人的关键技术问题。 作为 Codesmith 的首席执行官（一家拥有数据科学和机器学习研究小组的小型独立技术学校，去年我们为 TensorFlow 做出了贡献），我受邀宣布我们的最新努力：Codesmith 的 AI 和 ML 技术领导力计划。 我在 r/technology 上的 AMA 上分享了这一经历，并进行了一次很棒的对话 - 但有关 ML/AI 的问题深度与我希望探索的并不完全相符。我在这里与版主进行了交谈，并感谢他们对本次 AMA 的支持。  证明：https://imgur.com/a/bYkUiE7 我真正的热情继承自我的父母，他们都是教育工作者，那就是教学和让更广泛的受众更容易接触到 ML。我目前正在为前端大师开发一个 AI/ML 研讨会，我想听听那些涉足 ML 领域的人的意见。你在这个领域面临的最大挑战是什么？ 我从这次活动中得到的一些收获：  芯片制造商正在转向新的架构，而不是由于物理限制而进一步小型化。高带宽内存 (HBM) 是未来路线图的核心重点。 欧洲专注于寻找“技术冠军”，但重点明显放在核心行业而非消费者互联网上，比如 ASML 和 ARM。 量子机器学习发展势头强劲，并获得政府支持，特别是在气候预报等应用方面（例如德国的 Klim-QML 计划）。虽然前景光明，但这些努力仍处于原型阶段。 坦率地说，也有很多空谈。甚至 OpenAI 高管也表明需要更多具有深厚技术见解的领导者。  期待在 AMA 中更深入地探讨这些问题以及机器学习/人工智能中更广泛的挑战！    提交人    /u/WillSen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfv37y/d_im_an_mlprogramming_educator_i_was_invited_as/</guid>
      <pubDate>Wed, 30 Oct 2024 19:31:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何管理你的（已读和待读）研究论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gfsxcg/d_how_do_you_manage_your_read_and_toread_research/</link>
      <description><![CDATA[我对研究领域还比较陌生，过去一年来。我可能已经阅读了 100 多篇研究论文，但我觉得我没有记住很多信息，而且我忘记了很多论文。我很好奇在这个行业工作时间较长的人会用什么来组织。 我试过 Zotero，但我并不是很喜欢它    提交人    /u/Karan1213   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gfsxcg/d_how_do_you_manage_your_read_and_toread_research/</guid>
      <pubDate>Wed, 30 Oct 2024 18:01:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 27 Oct 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>