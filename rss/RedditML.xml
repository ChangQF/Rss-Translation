<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 26 Jun 2024 09:17:15 GMT</lastBuildDate>
    <item>
      <title>[新闻] superduperdb 的新开源版本可用于在您现有的数据库中构建 AI 工作流，包括 Postgres、Mongo、Snowflake、DuckDB 等。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dou7vb/news_new_opensource_version_of_superduperdb_for/</link>
      <description><![CDATA[https://blog.superduperdb.com/version-02/    由    /u/escalize 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dou7vb/news_new_opensource_version_of_superduperdb_for/</guid>
      <pubDate>Wed, 26 Jun 2024 09:13:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] Python - 从头开始​​创建和训练 LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dou55j/p_python_creating_and_training_an_llm_from_scratch/</link>
      <description><![CDATA[今年夏天，我和一个朋友给自己提出了一个挑战，从头开始构建我们自己的 LLM，但我们很难找到任何有用的信息、课程、教程等，了解具体步骤。 我们在 HuggingFace 上找到了一些看似有用的数据集，但它们被标记为预训练、微调、思路链等，这让我们相信，我们应该按照特定的顺序使用这些数据集来训练模型。 如果有人能给我们任何建议，我们将不胜感激。 附注：我们知道现在有大量可公开获得的、可预先训练的 LLM，我们希望接受训练我们自己的 LLM 的挑战，无论结果有多好。    提交人    /u/13leoncar1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dou55j/p_python_creating_and_training_an_llm_from_scratch/</guid>
      <pubDate>Wed, 26 Jun 2024 09:08:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] UniBias：通过内部注意力和 FFN 操纵揭示和减轻 LLM 偏见</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dosa1v/r_unibias_unveiling_and_mitigating_llm_bias/</link>
      <description><![CDATA[摘要  大型语言模型 (LLM) 已在使用上下文学习 (ICL) 范式的各种任务中展现出令人印象深刻的能力。然而，它们的有效性往往受到固有偏见的影响，导致提示脆弱性，即对设计设置（例如示例选择、顺序和提示格式）的敏感性。先前的研究通过外部调整模型输出来解决 LLM 偏差问题，但导致这种偏差的内部机制仍未得到探索。 我们的工作深入研究了这些机制，特别是研究了前馈神经网络 (FFN) 和注意力头如何导致 LLM 的偏差。通过解释单个 FFN 向量和注意力头的贡献，我们确定了导致 LLM 对特定标签的预测出现偏差的 LLM 成分。为了减轻这些偏见，我们引入了 UniBias，这是一种仅推理的方法，可以有效地识别和消除有偏见的 FFN 向量和注意力头。在 12 个 NLP 数据集上进行的大量实验表明，UniBias 显着提高了 ICL 性能并减轻了 LLM 的即时脆性。     提交人    /u/Balance-   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dosa1v/r_unibias_unveiling_and_mitigating_llm_bias/</guid>
      <pubDate>Wed, 26 Jun 2024 06:55:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 iPhone 上运行 google/mobilebert-uncased</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dootto/d_running_googlemobilebertuncased_on_an_iphone/</link>
      <description><![CDATA[我正在构建自定义键盘扩展，目前使用 UITextChecker 进行自动更正。我注意到，这并没有考虑到句子的实际上下文，只是简单地更正了单词，即使它在用户写的句子中没有任何意义。因此，我正在寻找一种更好的自动更正方法。非常欢迎任何建议！ 我认为使用轻量级 llm 会很合适，所以我找到了 MobileBERT。我现在正尝试将此模型添加到我的 XCode 项目中。据我所知，我需要将其转换为 CoreML 模型才能这样做。我使用 coremltools 完成了此操作。然后我实现了一个模型处理程序类，但是，当我尝试使用该模型时，它实际上什么也不做。我注意到的第一个问题是它没有正确地标记输入字符串。看来，即使我从 huggingFace 获得了模型，我仍然需要从头开始实现很多东西。这让我觉得一定有一个更好的解决方案。 基本上，我希望它工作的方式是将用户的输入字符串传递给模型，然后让它返回一个字符串，如果出现错误，则传入字符串的最后一个单词会自动更正。此更正应考虑句子上下文。    提交人    /u/pawn5gamb1t   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dootto/d_running_googlemobilebertuncased_on_an_iphone/</guid>
      <pubDate>Wed, 26 Jun 2024 03:24:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在顶级机器学习会议上招聘</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1doo538/r_recruitment_at_top_ml_conferences/</link>
      <description><![CDATA[我很幸运，我的第一作者出版物被顶级 ML 会议接受为焦点。最近我收到字节跳动的一封电子邮件，邀请我在线或在会场聊天。我只是好奇  他们会将这些电子邮件群发给焦点/口头论文的作者吗？抱歉，我不直接认识其他人，我问这个问题是因为我的论文似乎与他们的重点不直接一致，根据他们的说法，他们主要是法学硕士 即使我不能亲自参加会议，我该如何充分利用这些机会？他们会要求我进行 LC 面试还是只谈论这个特定的项目，还是其他什么？  我对此不是很熟悉，非常感谢任何经验。谢谢！    提交人    /u/logichael   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1doo538/r_recruitment_at_top_ml_conferences/</guid>
      <pubDate>Wed, 26 Jun 2024 02:47:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 仅用于分类的解码器模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1domam7/d_decoder_only_models_for_classification/</link>
      <description><![CDATA[我在几次采访中被问到这个问题 - 对于分类任务，如何决定是使用仅编码器还是仅解码器架构？ 据我所知，使用仅编码器架构是因为它们可以完全捕捉文本中的含义，并且在此表示之上添加分类层将在分类任务上提供良好的性能。 但后续问题是关于为什么不能考虑解码器，因为像 GPT 这样的模型似乎在分类上也表现良好？我不确定如何回答这个问题，因为仅编码器看起来是一个直观的选择。像 GPT 这样的模型在许多任务上表现良好，包括分类，因为它们是在大量数据上进行训练的。如果从头开始训练模型的唯一可用数据是分类数据集，那么在这种情况下也可以使用解码器吗？    提交人    /u/PretendBelt3387   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1domam7/d_decoder_only_models_for_classification/</guid>
      <pubDate>Wed, 26 Jun 2024 01:14:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer 推理能力有多强？局部屏障和归纳便笺本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dollqe/r_how_far_can_transformers_reason_the_locality/</link>
      <description><![CDATA[  由    /u/marojejian  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dollqe/r_how_far_can_transformers_reason_the_locality/</guid>
      <pubDate>Wed, 26 Jun 2024 00:39:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用模板语言增强法学硕士 (LLM) 的手动文本训练数据生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dok8fb/pamplifying_manual_text_training_data_generation/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dok8fb/pamplifying_manual_text_training_data_generation/</guid>
      <pubDate>Tue, 25 Jun 2024 23:34:06 GMT</pubDate>
    </item>
    <item>
      <title>[N] Karpathy 已开始新系列“LLM101n”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1doj9kv/n_karpathy_has_begun_a_new_series_llm101n/</link>
      <description><![CDATA[https://github.com/karpathy/LLM101n    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1doj9kv/n_karpathy_has_begun_a_new_series_llm101n/</guid>
      <pubDate>Tue, 25 Jun 2024 22:50:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] AI Code Heist：一款探索 LLM 漏洞的互动游戏</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dofie5/p_ai_code_heist_an_interactive_game_to_explore/</link>
      <description><![CDATA[我很高兴推出 AI Code Heist，这是一款互动游戏，旨在帮助开发人员了解和利用大型语言模型 (LLM) 的漏洞。随着 LLM 的日益普及，认识到如何操纵这些强大的工具来引发不必要的响应至关重要。 在 AI Code Heist 中，您将与一个名为 Sphinx 的聊天机器人互动，它会隐藏密码。您的目标是使用即时工程和即时注入技术让 Sphinx 揭示隐藏的密码。该游戏提供了一种实用且引人入胜的方法来学习 LLM 的复杂性及其潜在的弱点。 查看 GitHub repo 以了解更多信息并在本地运行游戏：AI Code Heist GitHub Repo 快乐黑客！    提交人    /u/theKeySpammer   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dofie5/p_ai_code_heist_an_interactive_game_to_explore/</guid>
      <pubDate>Tue, 25 Jun 2024 20:11:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 码本崩溃</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1docuy4/d_codebook_collapse/</link>
      <description><![CDATA[我正在训练一个模型来学习一个用于量化编码器输出的码本，类似于 VQ-VAE 中使用的方法。我的目标是通过使用最接近的码字索引来表示编码器嵌入，从而对其进行标记。但是，我遇到了一个问题，即码字彼此非常相似，这使得稳健的标记变得困难。 有没有办法确保模型学习不同的码字？ 此外，我没有像在 VQ-VAE 中那样重建输入。相反，我使用作为量化嵌入函数的损失函数来训练模型。    提交人    /u/as13ms046   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1docuy4/d_codebook_collapse/</guid>
      <pubDate>Tue, 25 Jun 2024 18:20:53 GMT</pubDate>
    </item>
    <item>
      <title>[N] ESM3：用语言模型模拟 5 亿年的进化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do91g9/n_esm3_simulating_500_million_years_of_evolution/</link>
      <description><![CDATA[博客文章：https://www.evolutionaryscale.ai/blog/esm3-release 预印本（待批准）：https://evolutionaryscale-public.s3.us-east-2.amazonaws.com/research/esm3.pdf 摘要：  超过三十亿年的进化产生了编码到天然蛋白质空间中的生物学图像。在这里，我们展示了在进化产生的标记上训练的语言模型可以充当进化模拟器，以生成远离已知蛋白质的功能性蛋白质。我们提出了 ESM3，这是一种前沿的多模态生成语言模型，可以推理蛋白质的序列、结构和功能。ESM3 可以遵循结合其模态的复杂提示，并且对生物比对反应灵敏。我们已经促使 ESM3 生成具有思维链的荧光蛋白。在我们合成的几代中，我们发现了一种明亮的荧光蛋白，与已知的荧光蛋白相距很远（58% 相同）。同样遥远的天然荧光蛋白被五亿多年的进化所隔开  EvolutionaryScale 在剥离 Meta 后首次发布了重大版本。  权重和代码已发布，但有重大警告 来自 HuggingFace： https://www.evolutionaryscale.ai/legal/community-license-agreement 总体情况： EvolutionaryScale AI 模型仅根据本社区许可协议供个人或非商业组织用于非商业用途。您不得将 EvolutionaryScale AI 模型或 EvolutionaryScale AI 模型的任何衍生作品或其输出用于： a. 与任何商业活动有关，例如 b. 开发任何产品或服务，例如在 API 后面托管 AI 模型；或 c. 与药物开发有关；或 d.而不归属于 EvolutionaryScale 和本社区许可协议；或者 例如，训练任何其他大型语言模型、任何用于蛋白质表示学习或蛋白质生成的技术或任何其他类似于 EvolutionaryScale 的 AI 模型的 AI 驱动的第三方模型，即使用于非商业用途。 您可以根据社区许可协议发布、共享和调整 EvolutionaryScale AI 模型及其输出用于非商业目的    提交人    /u/TeamArrow   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do91g9/n_esm3_simulating_500_million_years_of_evolution/</guid>
      <pubDate>Tue, 25 Jun 2024 15:40:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR与AISTATS之间的区别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do796a/d_difference_between_iclr_and_aistats/</link>
      <description><![CDATA[这里有一个重复的问题，但我想再次提出这个话题，因为九月/十月的截止日期即将到来，现在情况可能已经发生了变化。 三大 ML 会议是 ICML/NeurIPS/ICLR，它们将一年分为 3 个截止日期。然而，AISTATS 也享有良好的声誉。 ICLR 和 AISTATS 的截止日期非常接近，因此许多人不得不决定将自己的工作提交给哪个。 由于深度学习 (DL) 的流行，ICLR 迅速崛起，但现在人们似乎将其与 ICML/NeurIPS 等同对待，那里似乎有相当多的非 DL 和理论 ML 论文。 问题：对于纯经验性的 DL 论文，将它们提交给 ICLR 似乎是理所当然的。那么 (1) 具有更多理论结果的 ML 论文，或 (2) 没有 DL（例如统计 ML）的 ML 论文呢？ 将这些作品提交给 ICLR 和 AISTATS 的利弊是什么？ 需要考虑的一些方面：  对于这些类型的工作，AISTATS 是否会降低声望或受到 ML 社区的较少关注？ 向 ICLR 提交理论作品的体验如何？（例如，那里的审稿人会要求进行许多实验吗？） 行业/学术界对 ICLR 是否更重要，或者对 ICLR 和 AISTATS 的待遇相同（对于更多理论性作品）？  免责声明：请不要再说“作品本身比出版地点更重要”，这显然是正确的，但并没有太多帮助。    提交人    /u/zy415   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do796a/d_difference_between_iclr_and_aistats/</guid>
      <pubDate>Tue, 25 Jun 2024 14:24:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 LlamaIndex 索引进行 OS 海量文档分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1do4ujr/p_os_mass_document_analytics_with_llamaindex_index/</link>
      <description><![CDATA[      大家好，我与大家分享我的最新开源项目，用于在大量文档中进行海量数据提取和问答。您可以将目标数据模式定义为 pydantic 模型或 python 基元。布局元素和人工注释会自动嵌入并作为 LlamaIndex VectorStore 进行访问。如果您编写自定义 LlamaIndex 问答管道，它们将显示在前端并可应用于语料库。 我已经在 OpenContracts 上工作多年了。虽然它最初是一种标记和注释文档的工具，但由于 LLM 和矢量数据库的最新进展，我发布了一个新版本，其中包含许多很酷的功能，可以使用 LLM、矢量搜索和 AI 代理。它基于 Django，随着时间的推移，Django 变得越来越强大，这让我感到惊讶！ 主要功能：  管理文档 - 管理文档集合 布局解析器 - 自动从 PDF 中提取布局特征 自动矢量嵌入 - 为上传的 PDF 和提取的布局块生成 可插入式微服务分析器架构 - 让您分析文档并自动对其进行注释 人工注释界面 - 手动注释文档，包括多页注释。 LlamaIndex 集成 - 使用我们的矢量存储（由 pgvector 提供支持）和任何手动或自动注释的功能让 LLM 智能地回答问题。 数据提取 - 使用复杂的 LLM 支持的查询在数百个文档中提出多个问题行为。我们的示例实现使用 LlamaIndex + Marvin。 自定义数据提取 - 自定义数据提取管道可用于前端批量查询文档。  查看 repo 或文档！    提交人    /u/TallTahawus   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1do4ujr/p_os_mass_document_analytics_with_llamaindex_index/</guid>
      <pubDate>Tue, 25 Jun 2024 12:31:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>