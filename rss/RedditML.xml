<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Tue, 18 Feb 2025 15:18:50 GMT</lastBuildDate>
    <item>
      <title>[r]大语言模型中深度的诅咒</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isdopn/r_the_curse_of_depth_in_large_language_models/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isdopn/r_the_curse_of_depth_in_large_language_models/</guid>
      <pubDate>Tue, 18 Feb 2025 14:18:32 GMT</pubDate>
    </item>
    <item>
      <title>[R]评估现实世界软件工程任务的LLM：一项耗资100美元的基准研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isbo6t/r_evaluating_llms_on_realworld_software/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  旨在评估现实世界软件工程任务上LLM的新基准测试，直接从附上的“实际美元”值中拉出。该方法涉及收集1,400多个任务，从$ 50- $ 32,000的支出，创建标准化的评估环境以及测试编码能力和工程管理决策。 关键技术要点： - 通过单位测试，专家测试验证任务验证和与人类解决方案的比较 - 评估使用Docker容器来确保一致的测试环境 - 包括直接编码任务和高级工程管理决策 - 任务涵盖Web开发，移动应用程序，数据处理和系统体系结构 - 总任务值超过100万美元的实际自由付款 结果显示了当前的局限性：-GPT -4成功完成编码任务的10.2％ -  Claude 2达到了8.7％的成功率 -  GPT -4的管理决策准确性为21.4％ - 随着任务复杂性/值的增加 ，我认为该基准代表了我们评估现实世界应用LLM的重要转变。通过将绩效直接与经济价值联系起来，我们可以更好地了解当前能力和实用程序之间的差距。较低的成功率表明，在LLM可以可靠地处理专业软件工程任务之前，我们需要取得重大进展。 我认为，包括管理级别的决策尤其有价值，因为它可以测试技术理解和战略思维。这可以有助于指导开发更完整的工程辅助系统。  tldr：新的基准测试在实际$ 1M+的UPWORK编程任务上进行LLMS。当前模型在很大程度上挣扎，仅完成约10％的编码任务和约20％的管理决策。  完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isbo6t/r_evaluating_llms_on_realworld_software/</guid>
      <pubDate>Tue, 18 Feb 2025 12:35:00 GMT</pubDate>
    </item>
    <item>
      <title>[R]针对微调潜在扩散模型的面部图像的会员推理攻击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isa46f/r_membership_inference_attacks_for_face_images/</link>
      <description><![CDATA[在/2502.11619 ）（代码可在 https://github.com/osquera/mia_sd ） /p&gt; 问题 微调潜在扩散模型（LDMS），例如稳定的扩散，Midjourney和Dall·E 3，可以在域中培训时可以再现特定样式甚至是单个图像（例如，面孔，艺术品）。这引起了人们对未经授权的数据使用的担忧。 我们研究是否可以使用会员推理攻击（MIA）在给定的一组图像上进行微调。 &lt; &lt;。 &lt; H2&gt;我们如何接近攻击  微调模型：我们在策划的面部数据集中微调稳定扩散v1.5。 攻击模型：我们使用Resnet -18分类器经过培训，可以区分图像是否是微调集的一部分，使用真实数据和生成的数据进行培训。 使用的技术：  black-box攻击查询，无访问模型内​​部设备）。 辅助数据生成 - 我们发现，使用生成的负figations改善了攻击性能。 调整持续时间的影响＆amp;攻击成功的指导量表。    关键发现  微调增加信息泄漏：LDM越好 - 在数据集上进行调整，其输出越多地类似于微调集合，使检测成员资格更容易。 攻击成功：我们的MIA明显优于基于零拍的基线基线。使用生成的负面因素而不是实际的负面因素可以改善结果。  IP保护的潜力：如果艺术家或组织怀疑生成模型正在复制其工作，他们可以使用MIAS来验证其数据是否用于Fine-调整。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/osquera     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isa46f/r_membership_inference_attacks_for_face_images/</guid>
      <pubDate>Tue, 18 Feb 2025 10:58:26 GMT</pubDate>
    </item>
    <item>
      <title>[r]本地稀疏注意：硬件一致且本地可训练的稀疏注意力（由Liang Wenfeng提交 -  DeepSeek）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is9ufs/r_native_sparse_attention_hardwarealigned_and/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  本机稀疏注意：和本地可训练的稀疏注意 jingyang yuan，huazuo gao，damai dai，junyu luo，liang zhao，Zhengyan Zhang，Zhenda Zhenda Xie，Y. X. Wangding Zeng  长篇小说建模对于下一代语言模型至关重要，但是标准注意机制的高计算成本却带来了重大的计算挑战。稀疏的注意力为提高效率的方向提供了有希望的方向，同时保持模型功能。我们提出了NSA，这是一种本地可训练的稀疏注意机制，将算法创新与硬件一致的优化相结合，以实现有效的长篇文化建模。 NSA采用了动态的分层稀疏策略，将粗粒的令牌压缩与精细的令牌选择相结合，以保持全球环境意识和局部精度。我们的方法通过两个关键创新进行了稀疏注意设计：（1）我们通过算术强度平衡算法设计实现了实质性的加速，并对现代硬件进行了优化。 （2）我们启用端到端培训，在不牺牲模型性能的情况下减少预处理的计算。如图1所示，实验表明，使用NSA预测的模型维持或超过了一般基准，长篇下说任务和基于指导的推理的全部注意力模型。同时，NSA在对解码，正向传播和向后传播的64k长度序列上的全面关注方面实现了实质性加速，从而在整个模型生命周期中验证了其效率。&lt; /em&gt;  arxiv：2502.11089 [cs.cl]：&lt; /em&gt;  a href =“ https://arxiv.org/abs/2502.11089”&gt; https://arxiv.org/abs/2502.11089      https://preview.redd.it/utbg4cpxlvje1.jpg?width=948&amp;format=pjpg&amp;auto=webp&amp; ; s = 198C25E093E6719ADFE5F4F4F4356492813BEE2D25    &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nunki08     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is9ufs/r_native_sparse_attention_hardwarealigned_and/</guid>
      <pubDate>Tue, 18 Feb 2025 10:39:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]当应用行业工作时如何查看AISTATS/UAI/TMLR？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is3c39/d_how_aistatsuaitmlr_is_viewed_when_applied_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在谈论研究或应用科学家在行业中的角色。您认为这些论文在简历上提供了多少价值？与CVPR/ICCV/ECCV/NIPS/ICML/ICLR？  &lt;！ -  SC_ON- sc_on-&gt;＆＃32相比，与顶级会议的纸张相比提交由＆＃32; /u/u/dampiventive_newt_100       [link]   ＆＃32;   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is3c39/d_how_aistatsuaitmlr_is_viewed_when_applied_for/</guid>
      <pubDate>Tue, 18 Feb 2025 03:34:15 GMT</pubDate>
    </item>
    <item>
      <title>[D]哪种会议模板可以写得最多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is36l9/d_which_conference_template_can_write_most/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近将脚本从ICLR重写为Neurips，我突然发现我必须将内容减少约3％。这并不多，但是您可以编写的内容似乎在不同的模板上有所不同。皇家地说，哪个模板可以编写最多的内容（说10页的限制，包括参考和附录）？我个人认为应该是ICML或IJCAI   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petrichorinforest     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is36l9/d_which_conference_template_can_write_most/</guid>
      <pubDate>Tue, 18 Feb 2025 03:26:14 GMT</pubDate>
    </item>
    <item>
      <title>[D]可以在没有基准数据集的情况下训练和比较模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is1sbg/d_is_it_okay_to_train_and_compare_models_without/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在使用此类型的数据集训练模型，特别是在医疗域（与癌症相关的数据集）中进行训练。据我所知，没有其他研究在我的研究领域使用此特定数据集。因此，我只使用此数据集比较不同的模型。这种方法是否有效，还是有必要包括外部基准数据集以正确评估我的结果？任何建议都将不胜感激。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sea_muscle_4281     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1is1sbg/d_is_it_it_it_okay_okay_train_train_and_and_compare_models_models_models_without/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is1sbg/d_is_it_okay_to_train_and_compare_models_without/</guid>
      <pubDate>Tue, 18 Feb 2025 02:14:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] Finetuning Modernbert正在服用3小时（2个时代）和35 gigs的VRAM。正常吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is0q1a/d_finetuning_modernbert_is_taking_3hrs_2_epochs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以其他详细信息... 我正在使用a6000 48gb vram，8vcpu，8vcpu，45 gb ram。我的数据集是NewsArticle文本和标签的9K样本。 我正在使用的模型是“ answerdotai/sodernbert-base”。上下文长度为8192。 最初，当我尝试使用32或16的批处理进行捕获时，我一直在遇到OOM错误。然后，我看到了设置4个或更少的批处理。 即使训练一个时代也要花费大约1H 31分钟。这是正常的吗？这是我第一次进行模型，所以我是一个没有参考或过去的经验，这是我第一次进行填充。当我将批处理大小设置为32或16时，我没想到会看到一个45MB CSV文件会填充整个VRAM。是Pytorch错误还是??? &lt; /p&gt; 编辑 - IM使用的数据集是“ valurank/politainbias_allsides_txt”的截断版本。大约有19k数据样本。我正在使用其中的一个子集 - 大约9K样品。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/solaris12     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1is0q1a/d_finetuning_modernning_modernbert_is_taking_3hrs_2_2_epochs/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is0q1a/d_finetuning_modernbert_is_taking_3hrs_2_epochs/</guid>
      <pubDate>Tue, 18 Feb 2025 01:22:30 GMT</pubDate>
    </item>
    <item>
      <title>[d]“反向传播：多元链规则”的视觉解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irs3gn/d_visual_explanation_of_backpropagation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我开始研究反向流动的视觉说明。这是第1部分： https://substack.com/home/post/post/p-157218392 。请让我知道您的想法。 使我对倒退的一部分感到困惑，这是为什么人们将反向传播与链条规则相关联？链条规则无法清楚地解释从参数到损失的多个路径。最终，我意识到我错过了“多元链规则”一词。一旦我找到了它，一切都在我的脑海中点击。让我知道您在这里有想法。  谢谢，  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/madiyar     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irs3gn/d_visual_explanation_of_backpropagation/</guid>
      <pubDate>Mon, 17 Feb 2025 19:16:15 GMT</pubDate>
    </item>
    <item>
      <title>[r]忘记数据和微调！只需折叠网络以压缩[2025年2月]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irqngl/r_forget_the_data_and_finetuning_just_fold_the/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irqngl/r_forget_the_data_and_finetuning_just_fold_the/</guid>
      <pubDate>Mon, 17 Feb 2025 18:19:59 GMT</pubDate>
    </item>
    <item>
      <title>[D]就业市场如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irnuv1/d_hows_the_job_market/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  昨天，我开始申请新工作。目前，我的标题是“ ML工程师”但是说实话，我最近一直在运行更像ML顾问 - 我已经好几个月了。专注于ML。似乎有很多角色正在寻找拥有3年以上经验的候选人。 我只是对我在接受第一次面试之前将需要多少申请的申请 - 我目前在24个申请中。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ready_plastic1737     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irnuv1/d_hows_the_job_market/</guid>
      <pubDate>Mon, 17 Feb 2025 16:29:37 GMT</pubDate>
    </item>
    <item>
      <title>** [讨论] Bytegpt-Small：我的第一个用于移动设备的字节式LLM **🚀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irloen/discussion_bytegptsmall_my_first_bytetokenized/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿reddit， 我一直在研究专为&lt;强&gt;计算和内存受限的设备，例如手机和嵌入式系统。 🚀 这是我的第一个版本： bytegpt-small  。它是一个小型GPT风格的模型接受了字节令牌化训练（受BYT5的启发），以最大程度地提高效率。   为什么要字节令牌化？     较小的足迹：微小的嵌入减少模型尺寸和内存的使用。   无依赖性：字节级令牌化很简单 - 不需要句子或bpe。强&gt;更好地处理错别字和看不见的令牌。    我的系列计划：      Bytegpt-small：现在活下来！我将尽快添加onnx，coreml和tflite文件  指令调整：使其聊天。    更大型号：训练字节中 - 中等（〜150m参数）。    gpro蒸馏：缩小模型，同时保持质量。专注于在边缘运行的特定领域的小LLM。   为什么我要发布： 我很喜欢您的反馈，尤其是在您：  - 具有在移动设备或嵌入式设备上部署 llms的经验&lt; /strong&gt;。认为Byte令牌化的潜力比人们想象的要大。  链接到型号：   bytegpt-small“   您是否尝试过 on Device llms ？  您对 byte级别的tokenization的经验 vs.子词模型？  关于GPRO蒸馏技术的任何建议？   期待您的想法！ 😊  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kells1986     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irloen/discussion_bytegptsmall_my_first_bytetokenized/</guid>
      <pubDate>Mon, 17 Feb 2025 14:57:24 GMT</pubDate>
    </item>
    <item>
      <title>[R]区域自适应抽样：通过选择性更新高关注区域来加速扩散变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irfq36/r_regionadaptive_sampling_accelerating_diffusion/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  此处的关键贡献是扩散变压器的一种新的自适应采样方法，该方法通过基于区域重要性选择性分配注意力来降低计算。它没有平等地处理所有区域，而是确定哪些零件需要更详细的处理。 主要技术方面： - 基于预测的重要性得分 - 修改的注意力机制与与之兼容现有体系结构 - 记忆效率的自适应缓存策略 结果显示：-30-50％的计算时间减少 -  FID或剪辑分数中没有降解 - 通过自适应采样节省40％的内存 - 有效 - 在多个模型架构中有效 - 为有条件和无条件的生成工作 我认为这对于计算效率很重要的现实应用程序可能特别影响。在将资源使用量减少多达50％的同时保持质量的能力为在更适度的硬件上运行这些模型的可能性开辟了可能性。这里的原则也可能会很好地转移到选择性注意力分配可能会有所帮助的其他领域，例如视频生成或3D渲染。 我最感兴趣的是，这是如何挑战统一处理对于高质量而需要的假设。一代。通过证明我们可以选择计算分配，这表明当前架构的效率提高仍然有很大的空间。  tldr：新方法通过选择性注意重要的注意力将扩散变压器计算减少30-50％ ，没有质量损失。  完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irfq36/r_regionadaptive_sampling_accelerating_diffusion/</guid>
      <pubDate>Mon, 17 Feb 2025 09:03:14 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会导致禁止。 鼓励其他人创建新的帖子，以便在此处发布问题！ 线程将一直活着直到下一个，因此请继续发布标题之后的发布。    meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>