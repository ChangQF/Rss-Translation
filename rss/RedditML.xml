<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Fri, 02 Aug 2024 12:28:19 GMT</lastBuildDate>
    <item>
      <title>[D] LlamaIndex 模式用法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei3lzz/d_llamaindex_pattern_usage/</link>
      <description><![CDATA[我制作了一个 YouTube 视频，作为 LlamaIndex 新手的入门指南。虽然我对 RAG（检索增强生成）解决方案和实现有经验，但教学对我来说是一项新尝试，我很乐意与社区分享我的方法。 在这篇文章中，我的目标是简化初学者学习 LlamaIndex 的过程。我没有深入研究密集的文档，而是以一种引人入胜的方式呈现概念，并结合模因让事情变得有趣。 以下是视频内容的简要概述：  通过 5 个简单步骤解释 LlamaIndex。 有效使用的实用示例和模式。 简化工作流程的技巧和窍门。  我愿意接受任何批评和改进建议。您的反馈将非常宝贵，有助于我改进教学方法并在未来创建更有效的内容。 感谢您花时间观看我的视频，我期待听到您的想法！    提交人    /u/Several_Operation707   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei3lzz/d_llamaindex_pattern_usage/</guid>
      <pubDate>Fri, 02 Aug 2024 07:03:08 GMT</pubDate>
    </item>
    <item>
      <title>二进制值的特征相关性[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei21gb/feature_correlation_for_binary_values_p/</link>
      <description><![CDATA[我想要预测的标签是二进制的（不确定这是否重要），其中一个特征也是二进制的。当我对标签进行特征相关时，我得到一个像 0.35 这样的数字，然后如果我切换特征的真假，相关性将是完全相同的数字，但被取反（所以像 -0.35）。首先，你如何解释这一点？具体来说，我在女性特征的真假之间切换。其次，这是确定二进制值的特征重要性的正确方法吗？因为似乎找到二进制特征的相关性只是说明模型对特征的真实值的工作情况，而不是整个特征的工作情况。     提交人    /u/Inspection-Conscious   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei21gb/feature_correlation_for_binary_values_p/</guid>
      <pubDate>Fri, 02 Aug 2024 05:20:07 GMT</pubDate>
    </item>
    <item>
      <title>我制作了一个 SWE 套件，以便轻松构建 SWE Agent [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei0pd7/i_made_a_swe_kit_for_easy_swe_agent_construction_p/</link>
      <description><![CDATA[大家好！我很高兴与大家分享一个新项目：SWEKit，这是一个使用 Composio 工具生态系统构建软件工程代理的强大框架。 目标 SWEKit 允许您：  使用 CrewAI 和 LlamaIndex 等框架构建开箱即用的代理。 添加或优化代理的能力。 根据 SWE-Bench 对您的代理进行基准测试。  实施细节  使用的工具：Composio、CrewAI、Python  设置：  安装您选择的代理框架和 Composio 插件 代理需要 github 访问令牌才能与您的存储库配合使用 您还需要设置 API 密钥适用于您计划使用的 LLM 提供程序  搭建并运行您的代理 工作区环境： SWEKit 支持不同的工作区环境：  主机：在主机上运行。 Docker：在 Docker 容器内运行。 E2B：在 E2B 沙箱内运行。 FlyIO：在 FlyIO 机器内运行。  运行基准测试：  SWE-Bench 使用来自流行 Python 开源项目的实际问题来评估软件工程代理的性能。  GitHub 欢迎探索该项目，如果发现它有用，请给它一颗星，并让我知道您的想法或改进建议！🌟    提交人    /u/kingai404   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei0pd7/i_made_a_swe_kit_for_easy_swe_agent_construction_p/</guid>
      <pubDate>Fri, 02 Aug 2024 04:05:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 加权损失函数（Pytorch 的 CrossEntropyLoss）解决多类多输出问题的不平衡数据分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehyv6b/p_weighted_loss_function_pytorchs/</link>
      <description><![CDATA[我正在尝试使用加权损失函数来处理数据中的类别不平衡问题。我的问题是多类别和多输出问题。例如（我的数据有五个输出/目标列（output_1、output_2、output_3）并且每个目标列中有三个类（class_0、class_1 和 class_2）。我目前正在使用 pytorch 的交叉熵损失函数https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html并且我看到它有一个权重参数，但我的理解是，这个相同的权重将统一应用于每个输出/目标，但我想在每个输出/目标中为每个类应用单独的权重。 具体来说，我可以获得如下数据   A B C D E OUTPUT_1 OUTPUT_2 OUTPUT_3    5.65 3.56 0.94 9.23 6.43 0 2 1   7.43 3.95 1.24 7.22 2.66 0 0 0   9.31 2.42 2.91 2.64 6.28 2 0 2   8.19 5.12 1.32 3.12 8.41 0 2 0   9.35 1.92 3.12 4.13 3.14 0 1 1   8.43 9.72 7.23 8.29 9.18 1 0 2   4.32 2.12 3.84 9.42 8.19 0 1 0   3.92 3.91 2.90 8.19 8.41 2 0 2   7.89 1.92 4.12 8.19 7.28 0 1 2   5.21 2.42 3.10 0.31 1.31 2 0 0   其中，产出 1 中的比例为：0 = 0.6, 1 = 0.1, 2 = 0.3 产出 2 中的比例为：0 = 0.4, 1 = 0.3, 2 = 0.3  输出 3 为：0 = 0.4、1 = 0.2、2 = 0.4 我想根据每个输出列中的类分布应用类权重，以便它重新规范化（或重新平衡？不确定这里要使用的术语是什么）类 1 为 0.15，类 0 和类 2 各为 0.425（因此对于 output_1，权重将是 [0.425/0.6、0.15/0.1、0.425/0.3]，对于输出 2，它将是 [0.425/0.4、0.15/0.3、0.425/0.3] 等）。相反，我理解 pytorch 的交叉熵损失函数中的权重参数目前正在做的事情是，它将对每个输出列应用单个类权重。任何帮助都将不胜感激。     由   提交  /u/Individual_Ad_1214   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehyv6b/p_weighted_loss_function_pytorchs/</guid>
      <pubDate>Fri, 02 Aug 2024 02:28:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解 ByteNet 架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehws26/d_understanding_bytenet_architecture/</link>
      <description><![CDATA[你好！ 我正在考虑在一个项目中使用 ByteNet (https://arxiv.org/abs/1610.10099) 架构，并希望更好地了解该模型的工作原理。 我已经阅读了这篇论文大约一百万次，但无法弄清楚动态展开究竟是如何实现的。我知道输入序列被映射到更长的中间表示，其长度是输入长度的函数，但不明白 1×1 卷积层如何做到这一点。我也不清楚输入序列如何可以具有可变长度而没有任何重复。 背景：动态展开的目标是允许模型处理输入长度与目标长度不匹配的情况（例如，将句子翻译成另一种语言时就是这种情况）。它涉及创建输入序列 s 的表示，其长度为 a \ |s| + b，其中 *a 和 b 是超参数。这个新的、更长的表示是使用一维卷积层生成的（以一种我无法理解的方式）。 任何帮助都将不胜感激！或者任何人知道任何解释它的优秀 YouTube 视频，这也会有所帮助。    提交人    /u/BerryLizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehws26/d_understanding_bytenet_architecture/</guid>
      <pubDate>Fri, 02 Aug 2024 00:44:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 长上下文文本分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehw2zt/d_longcontext_text_classification/</link>
      <description><![CDATA[据我所知，DeBERTa v3 large 通常是文本分类中性能最强的 BERT 类模型，但它被限制为 24,528 个标记（这很多，但在某些情况下可能不足以满足我的用例）。有人对比这更长的序列的 SOTA 模型/方法有经验/建议吗？    提交人    /u/sanest-redditor   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehw2zt/d_longcontext_text_classification/</guid>
      <pubDate>Fri, 02 Aug 2024 00:11:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有什么好的可微调的 TTS？（不是 Coqui 或 TorToiSe）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehw1nf/d_any_good_finetunable_tts_not_coqui_or_tortoise/</link>
      <description><![CDATA[大家好！我有一个非常感性的数据集，里面有大约 20-30 分钟的清晰的英语语音录音。我想制作一个微调模型来完全复制该声音，并且能够在没有 CUDA 的情况下仅使用 MPS 进行推理。除了 Coqui 和 TorToiSe（它们不适用于高音调数据）之外，还有什么想法以及好的分步文档吗？    提交人    /u/yukiarimo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehw1nf/d_any_good_finetunable_tts_not_coqui_or_tortoise/</guid>
      <pubDate>Fri, 02 Aug 2024 00:10:06 GMT</pubDate>
    </item>
    <item>
      <title>特征提取[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehuw5z/features_extraction_p/</link>
      <description><![CDATA[嗨 r/MachineLearning ， 我正在开展一个数据科学项目，该项目专注于识别与土著相关的数据，我可以使用社区的一些意见。 主要目标是在数据中找到表明信息与土著人民相关的特征，重点是环境和生物多样性数据。这将使我们能够识别与土著社区相关的互联网数据，但这些数据并未明确标记。通过发现这些以前未被识别的与土著相关的数据，我们可以将利益共享实践扩展到这些社区。 我从头开始；我仍然需要找到相关的可用数据集。我正在考虑使用聚类来识别相关参数。但是，我怀疑我需要大量优质数据才能实现有意义的目标。 是否可以使用已经在大量数据上训练过的 LLM（开源或通过 API），并将其用于根据我的需求量身定制的适当迁移学习方法？我愿意接受任何建议，并且真的很好奇人们能提出什么想法。    提交人    /u/Miserable-Ad5138   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehuw5z/features_extraction_p/</guid>
      <pubDate>Thu, 01 Aug 2024 23:17:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在专注于 LLM 的初创公司工作值得吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehudwq/d_is_it_worth_working_at_startups_focusing_on_llm/</link>
      <description><![CDATA[一些正在开发 LLM 产品的初创公司的 HR 找到了我。根据我们的讨论，他们仍然主要将流行的开放 AI 模型或开源模型 (llama3) 用于他们的 LLM 产品（这并不奇怪），我认为工程师将主要做的事情是快速工程和/或微调。我对 LLM 非常感兴趣，我相信这是一个相当突出的未来（如果我错了，请纠正我），但是我不确定如果我在使用这些模型的初创公司工作，我能在 LLM 领域达到多大的深度，可能只有快速工程和微调技术？在这些初创公司工作是否会让我在直接申请这些大型模型公司（Meta、Google、Open AI 等）的 LLM 职位时更有竞争力？ 我想在 LLM 领域获得更多知识，但我不知道在只使用带有 API 调用的 LLM 模型的公司工作是否是一个好的起点。任何建议都值得赞赏！    提交人    /u/Upbeat-Carrot1999   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehudwq/d_is_it_worth_working_at_startups_focusing_on_llm/</guid>
      <pubDate>Thu, 01 Aug 2024 22:55:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于随机内容生成的 Transformer 采样技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehrw4r/d_transformer_sampling_techniques_for_random/</link>
      <description><![CDATA[我正在做一个项目，在这个项目中，给定一个（相对较小的）转换器，我们希望能够生成独特的句子。也就是说，没有输入提示或任何条件。从 0 个 token 开始，我们希望能够生成新颖的句子。 我遇到的问题是，当我们使用传统的采样技术（例如 TopK/TopP）时，它往往会“崩溃”在一些想法上。由于前几个 token 可能只会落入少数几个最佳可能性中，这往往会限制剩余生成的新颖性。 关于如何处理这个问题有什么建议吗？我们正在研究模型训练技术 + 数据处理方面的其他选择，但我认为在采样方面可能会有一些“速胜”。    提交人    /u/leoholt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehrw4r/d_transformer_sampling_techniques_for_random/</guid>
      <pubDate>Thu, 01 Aug 2024 21:08:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 长序列模型对长序列的建模效果如何？比较架构归纳偏差对长语境能力的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehej2y/r_how_well_can_a_long_sequence_model_model_long/</link>
      <description><![CDATA[      TL;DR 小语言模型举步维艰无论架构如何，都可以处理长上下文。 论文： https://arxiv.org/pdf/2407.08112 摘要：  长序列在现实世界场景中大量出现，因此正确建模它们会打开许多​​下游用例。然而，深度神经网络经常因为各种原因而难以处理这些问题。系统工程和模型设计方面的最新进展使得模型的扩展成为可能，这些模型据称可以支持扩展的上下文长度。特别是，状态空间和线性递归神经网络模型系列理论上可以延伸到无限的序列长度。然而，这是否好得令人难以置信？我们进行了评估，以表明虽然这种说法在理论上可能是合理的，但仍然存在经验观察到的巨大实际差距。具体而言，循环模型在与具有注意机制的长上下文 LLM 相同的设置下仍然会受到影响。我们进一步表明，不同的归纳偏差具有不一致的外推能力，这凸显了进一步研究此类范式的必要性，并调查为什么长上下文模型似乎无法按照预期的方式运行。  实证结果： M2A = Mamba2Attn，TPP = Transformer++，RG &amp; RG-IT = Recurrent Gemma（/指令调整），SL &amp; SL-IT= ShearedLLaMa（/指令调整）。每个模型有2.7B到3B个参数。 https://preview.redd.it/d9pth8skg1gd1.png?width=759&amp;format=png&amp;auto=webp&amp;s=3df65d368ec3f0fbec93a866bb42cb6f83227c5b https://preview.redd.it/djez9l6ph1gd1.png?width=923&amp;format=png&amp;auto=webp&amp;s=c7a7e12f7c42bfba23372de379b63036c4db9800 https://preview.redd.it/fveuwywph1gd1.png?width=927&amp;format=png&amp;auto=webp&amp;s=1e0e7fa1c03099c09bccd4bed164f8bea13d5807 编辑：修复格式，添加模型尺寸信息。    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehej2y/r_how_well_can_a_long_sequence_model_model_long/</guid>
      <pubDate>Thu, 01 Aug 2024 11:41:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何正确对 DTLN（双信号变换 LSTM 网络）进行 TFLite 完全整数量化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehe9or/d_how_to_correctly_do_tflite_fully_integer/</link>
      <description><![CDATA[      我试图像 breizhn/DTLN 一样进行 TFLite 训练后量化练习。 作者进行了默认量化（float32）并将其分为 TFlite 模型的 2 个阶段，因为 TF2.3 不能很好地支持复值。 然后我尝试使用 TF2.15 并从“DTLN/pretrained_model/dtln_saved_model”加载他保存的模型并尝试进行全整数量化。错误显示如下，我不确定如何修复。 3 个节点已委托，需要 Flex ops 吗？ 在寻求帮助的过程中，我发现有人做了这项工作并分享了 https://github.com/nyadla-sys 、TFLite 模型。 模型图更加简洁与原始的 2 阶段 TFLite 模型进行比较，而作者 nyadla-sys 没有谈论如何做到这一点或分享 python 脚本。 我想知道他是怎么做到的，我不确定这项工作是否需要其他技能，因为我只知道基本的转换步骤。 希望有人可以在这里帮忙，谢谢。    提交人    /u/Ok_Box_6059   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehe9or/d_how_to_correctly_do_tflite_fully_integer/</guid>
      <pubDate>Thu, 01 Aug 2024 11:26:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 还有人觉得 LLM 没什么意思吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eh4llh/d_llms_arent_interesting_anyone_else/</link>
      <description><![CDATA[我不是 ML 研究员。当我想到很酷的 ML 研究时，我想到的是 OpenAI Five 或 AlphaFold 之类的东西。如今，人们热议的是 LLM 和扩展转换器，虽然该领域确实有一些研究和优化要做，但它对我来说并不像其他领域那么有趣。对我来说，ML 的有趣部分是为您的用例端到端训练模型，但如今的 SOTA LLM 可以用于处理许多用例。好的数据 + 大量的计算 = 不错的模型。就这样？ 如果我可以用一小部分计算来训练这些模型，我可能会更感兴趣，但这样做是不合理的。那些没有计算能力的人只能进行微调或快速工程，而我内心的 SWE 发现这很无聊。这个领域的大多数人真的把精力投入到下一个标记预测器中了吗？ 显然，LLM 具有颠覆性，并且已经发生了很大的变化，但从研究的角度来看，它们对我来说并不有趣。还有人有这种感觉吗？对于那些因为与 LLM 无关的东西而被该领域吸引的人，你对此有何感想？你是否希望 LLM 的炒作会逐渐消退，以便焦点可以转移到其他研究上？那些在当前趋势之外进行研究的人：你如何处理所有的噪音？    提交人    /u/leetcodeoverlord   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eh4llh/d_llms_arent_interesting_anyone_else/</guid>
      <pubDate>Thu, 01 Aug 2024 01:40:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jul 2024 15:00:14 GMT</pubDate>
    </item>
    </channel>
</rss>