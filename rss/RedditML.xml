<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 18 Feb 2024 12:21:36 GMT</lastBuildDate>
    <item>
      <title>[讨论]AI的DBT</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atspj6/discussion_the_dbt_of_ai/</link>
      <description><![CDATA[帖子：https:/ /matsmoll.github.io/posts/the-dbt-of-ai 摘录： “因此，诸如“模型的目标是什么”之类的问题”、“谁拥有模型”、“运行模型需要哪些数据”、“我们预测什么”、“我们在哪里存储预测”、“我可以在哪里运行模型”、“我们期望多久运行一次”要运行的模型”、“我们在哪里存储训练数据集”等等还有很多问题没有得到解答。 我经常发现很多这些问题都在代码中隐式描述，但在文档中已经过时了.”   由   提交/u/FewComfort75  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atspj6/discussion_the_dbt_of_ai/</guid>
      <pubDate>Sun, 18 Feb 2024 12:09:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] YOLOv8：图像增强效果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atsnxz/d_yolov8_image_augmentation_effectiveness/</link>
      <description><![CDATA[一般来说，在训练 yolov8 模型进行对象分类时，哪些图像增强最为有效？ （按从最好到最差的顺序） 图像级别增强 旋转剪切灰度色调亮度曝光噪声剪切马赛克 边界框级别增强 &lt; p&gt;翻转 90° 旋转作物旋转剪切亮度曝光模糊噪声 是否有一个 python 包，给定训练图像和标签的 yolov8 数据集，将以可重现的方式执行所有增强？ &gt; 一个最小的可重现示例将不胜感激。   由   提交/u/Tim7459  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atsnxz/d_yolov8_image_augmentation_effectiveness/</guid>
      <pubDate>Sun, 18 Feb 2024 12:06:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何查明你的研究以前是否没有做过？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atrenf/d_how_to_find_out_if_your_research_hasnt_been/</link>
      <description><![CDATA[我最近有了一个关于 ML 研究项目的想法。我花了几天时间实施和完善它并进行了测试。事实证明它运作得非常好！ 事实是，这个想法本身非常简单且非常直接，所以我担心它已经完成了。然而，通过谷歌搜索与我的想法相关的关键词，我发现没有论文可以做我所做的事情。尽管如此，我觉得谷歌搜索关键字可能不是一个有效的策略。因此我想问：如何确保你的想法真正新颖？   由   提交/u/Raskolnikov98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atrenf/d_how_to_find_out_if_your_research_hasnt_been/</guid>
      <pubDate>Sun, 18 Feb 2024 10:46:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 过去一年左右，RL 发生了什么？有什么大的进展吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atpztx/d_whats_been_going_on_in_rl_this_past_year_or_so/</link>
      <description><![CDATA[自从法学硕士开始掀起新闻风暴以来，我就没有听说过任何关于 RL 的新闻。   由   提交/u/Intelligent_Rough_21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atpztx/d_whats_been_going_on_in_rl_this_past_year_or_so/</guid>
      <pubDate>Sun, 18 Feb 2024 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 本地可运行的文本到语音 AI 起诉我自己的音频/语音？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atpyg1/d_locally_runnable_text_to_speech_ai_suing_my_own/</link>
      <description><![CDATA[是否有任何开源文本到语音模型经过训练用于创建自定义语音/音频，也可以在本地运行？    由   提交/u/Huge_Grab_9380   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atpyg1/d_locally_runnable_text_to_speech_ai_suing_my_own/</guid>
      <pubDate>Sun, 18 Feb 2024 09:08:20 GMT</pubDate>
    </item>
    <item>
      <title>[D]石油行业DS\ML的状态和任务是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atprh8/d_what_is_the_ds_ml_state_and_tasks_in_oil/</link>
      <description><![CDATA[如果我申请一家能源公司的 DS 职位，可能更具体地说 - 在炼油厂 - 潜在的项目是什么？这是一个好的举措吗？ - 看来他们的机器学习采用水平很低，而且管理层显然没有技术背景。他们需要有人指导他们完成数字化的这一部分。 + 他们确实收集了大量传感器数据（实时和历史） + 明确关注商业价值，有更多机会构建一些东西有用，真正能赚钱 - 怀疑任何边缘技术都可以在那里实践（可能是计算机视觉的一部分） - DS 和 IT 人员将属于少数（学习边缘技术也可能是一个好处）域） 你的想法是什么   由   提交 /u/Additional_Pilot_854   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atprh8/d_what_is_the_ds_ml_state_and_tasks_in_oil/</guid>
      <pubDate>Sun, 18 Feb 2024 08:55:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于 LLM 代币价格估算的 Python 工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atmrcq/p_python_tool_for_llm_token_price_estimation/</link>
      <description><![CDATA[      嘿/ML 我从社区从业者那里听到很多关于LLM价格跟踪的困难。 计算代币看似困难。在查看账单之前，很难知道自己花了多少钱。  因此，我们构建了一个名为 Tokencost 的 OSS 代币价格跟踪库。 Tokencost 可让您在向主要提供商发送请求之前轻松计算 LLM 通话的估计成本；这可以让您更清楚地了解自己的支出情况。  它基本上是一个更新的价格字典+成本计算器，全部作为一个简单的Python库。  https://github.com/AgentOps-AI/tokencost 示例用法 只需几行代码即可计算 LLM 成本 主要功能：  LLM 价格跟踪&lt; /strong&gt; 主要法学硕士提供商经常添加新模型并更新定价。此存储库有助于跟踪最新的价格变化 令牌计数在发送 OpenAI 请求之前准确计算提示令牌 轻松集成使用单个函数进行提示或完成的成本  希望有任何想法/反馈！   由   提交/u/Reibmachine  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atmrcq/p_python_tool_for_llm_token_price_estimation/</guid>
      <pubDate>Sun, 18 Feb 2024 05:40:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您保持最新状态的方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atmjz9/d_what_is_your_approach_for_staying_uptodate/</link>
      <description><![CDATA[新概念太多，时间太少。在我看来，虽然人们可以通过阅读获得基本的理解，但你确实需要修补和构建一些东西才能深入理解一项技术。作为一个有其他事情发生的成年人，这每年都变得越来越难，而与此同时，新工具和技术的速度似乎呈指数级增长。您要跟上的策略是什么？    由   提交 /u/HorseEgg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atmjz9/d_what_is_your_approach_for_staying_uptodate/</guid>
      <pubDate>Sun, 18 Feb 2024 05:28:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 根据输入和输出大小选择 MLP 模型深度和隐藏大小，是否有任何好的通用启发式规则？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atjxej/d_are_there_any_good_general_rules_of_heuristics/</link>
      <description><![CDATA[例如，如果我的 BERT 输出为 768，并且它是一个二元分类，则可以通过启发式方法选择作为 MLP 模型的分类头，基于该特征输入大小和输出大小 2 的层数及其隐藏大小？   由   提交 /u/DolantheMFWizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atjxej/d_are_there_any_good_general_rules_of_heuristics/</guid>
      <pubDate>Sun, 18 Feb 2024 02:59:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 应用机器学习论文中的公然数据泄露和谎言</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atf9tz/d_blatant_data_leakage_and_lies_in_an_applied_ml/</link>
      <description><![CDATA[最近我看到一篇在医疗保健领域应用的机器学习论文。论文发表在该领域真正顶级期刊的较小子期刊上。从我看来，这篇论文在方法论上确实存在明显的根本缺陷，完全使任何提议的贡献无效。 本质上，他们从智能手表的患者那里收集心率、睡眠等数据，并安装梯度增强机来预测血液中化学物质的水平。他们在晚上的记录时间收集样本，并使用 10 分钟粒度的时间序列数据集来进行每日预测。 问题是，他们使用每日睡眠时间和睡眠子类别（睡眠）阶段）的特点。在这种情况下，睡眠数据会在一天中重复，然后与同一天整个数据持续时间的一个唯一标签相匹配。然后，他们进行 10 倍的 CV，并全面报告 0.90+ 的绩效评估指标。 我以前见过数据泄露的欺诈性研究，但我从未见过如此刻意、如此明目张胆的半成品研究。 - 之前受人尊敬的期刊。作者在论文中回顾了这些细节，并做出了笼统的陈述，比如他们如何确保在 10 倍 CV 期间的训练集和测试集中不存在相同的数据行，等等。哈哈。您有 7 个特征，每天都采用唯一值，然后每个特征重复约 100 次，与 1 个唯一结果相匹配，并且您是说您确保在简历中分隔行索引？ 我是我对他们的结果表示怀疑，因为我在类似的领域工作，但由于缺少一些细节而无法确定。值得庆幸的是，由于一些法规或规则，他们必须公开数据和代码，我确认这正是正在发生的事情。 我不会在这里分享这项研究，但我应该这样做吗？联系期刊让他们撤回论文？有趣的是，该杂志有“AI”一词。以他们的名义，所以这不像是一本有非机器学习审稿人的期刊。这怎么能通过同行评审呢？有人见过如此欺诈的研究吗？我对这些科学出版物的现状感到困惑和震惊。    由   提交/u/enthusiastic31  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atf9tz/d_blatant_data_leakage_and_lies_in_an_applied_ml/</guid>
      <pubDate>Sat, 17 Feb 2024 23:13:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 时间序列的自监督/无监督方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atbpc6/d_selfsupervisedunsupervised_approaches_for_time/</link>
      <description><![CDATA[什么是时间序列的自监督/无监督方法？在应用任何监督学习进行预测应用之前，我想学习时间序列数据的低维表示（特征和时间之间的模式/交互）。这不是通常的方法，但我想尝试一下。 我知道自动编码器适用于表格数据。但是，对于输入 [batch_size、sequence_length、num_features] 的时间序列数据，我应该怎么做，除了自动编码器之外还有其他工具吗？或者自动编码器可以吗？   由   提交 /u/Then_Passenger_6688   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atbpc6/d_selfsupervisedunsupervised_approaches_for_time/</guid>
      <pubDate>Sat, 17 Feb 2024 20:38:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无提示的思维链推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at9w34/r_chainofthought_reasoning_without_prompting/</link>
      <description><![CDATA[论文 - https://arxiv.org/abs/2402.10200  摘要 - 在增强大语言模型（LLM）的推理能力方面，先前的研究主要集中在特定的提示技术上，例如少样本或零样本思维链（CoT） ) 提示。这些方法虽然有效，但通常涉及手动密集型提示工程。我们的研究采用了一种新颖的方法，提出了这样的问题：法学硕士能否在没有提示的情况下有效推理？有趣的是，我们的研究结果表明，只需改变解码过程，就可以从预先训练的 LLM 中导出 CoT 推理路径。我们不是采用传统的贪婪解码，而是研究前 k 个替代标记，发现 CoT 路径通常是这些序列中固有的。这种方法不仅绕过了提示的混杂因素，而且使我们能够评估法学硕士的内在推理能力。此外，我们观察到解码路径中 CoT 的存在与模型解码答案的较高置信度相关。该置信度度量有效区分 CoT 和非 CoT 路径。对各种推理基准的广泛实证研究表明，所提出的 CoT 解码大大优于标准贪婪解码。   由   提交/u/MysteryInc152   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at9w34/r_chainofthought_reasoning_without_prompting/</guid>
      <pubDate>Sat, 17 Feb 2024 19:21:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] GRIT（生成表征指令调整）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at7lzn/r_grit_generative_representational_instruction/</link>
      <description><![CDATA[GritLM  &lt; li&gt;设定了新的最先进基准：在大规模文本嵌入基准 (MTEB) 上优于同等大小的所有其他模型，并且在生成任务方面表现出色。 规模很重要：更大的模型（例如 GritLM） 8x7B）优于开放生成语言模型，同时在嵌入任务方面仍然排名靠前。 在不牺牲通用性的情况下实现性能：GritLM 在生成数据或嵌入数据上的训练同样出色，结合了两全其美。  &gt;效率升级：通过避免单独的检索和生成模型，将长文档的检索增强生成 (RAG) 速度提高 60% 以上。  文章链接    由   提交 /u/AloneSYD   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at7lzn/r_grit_generative_representational_instruction/</guid>
      <pubDate>Sat, 17 Feb 2024 17:44:21 GMT</pubDate>
    </item>
    <item>
      <title>V-JEPA：Yann LeCun 先进机器智能愿景的下一步 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at7fib/vjepa_the_next_step_toward_yann_lecuns_vision_of/</link>
      <description><![CDATA[      博客：https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model- video-joint-embedding-predictive-architecture/ 论文：https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning-visual-representations-from-video/ ​ 摘要： ​ 本文探讨了特征预测作为视频无监督学习的独立目标，并引入了 V-JEPA，这是一组仅使用特征预测目标训练的视觉模型集合，不使用预训练的图像编码器、文本、负例、重建或其他监督源。这些模型使用从公共数据集中收集的 200 万个视频进行训练，并针对下游图像和视频任务进行评估。我们的结果表明，通过预测视频特征进行学习可以产生多功能的视觉表示，在基于运动和外观的任务上表现良好，而无需调整模型的参数；例如，使用冷冻的骨干。我们最大的模型，仅在视频上训练的 ViT-H/16，在 Kinetics-400 上获得 81.9%，在 Something-Something-v2 上获得 72.2%，在 ImageNet1K 上获得 77.9%。 ​&lt; /p&gt; ​ https://preview.redd.it/uvo0dpwvl6jc1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=3f308732b80a72be3d5ad8ef9542462cf4611b64 V-JEPA 训练视觉编码器通过预测学习的潜在空间中的屏蔽时空区域。   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at7fib/vjepa_the_next_step_toward_yann_lecuns_vision_of/</guid>
      <pubDate>Sat, 17 Feb 2024 17:36:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>