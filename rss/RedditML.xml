<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Mon, 17 Feb 2025 21:15:24 GMT</lastBuildDate>
    <item>
      <title>[R] [P] LLM（Gemini Flash 2.0）未能收敛到答案|开放式研究项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irv0m4/rp_llm_gemini_flash_20_failing_to_converge_to_an/</link>
      <description><![CDATA[    Flash 2.0）未能收敛到答案|开放式研究项目“ src =” https://external-preview.itd.it/es​​kfuge5ajvkan5kmjqvvvvvvtks4to72xkk8yyu72xk8oy6o.jpg？ = 70804E6EBBEECFF8A96F36290DAB557E1F503DFD“ title =” [R] - &gt;  大家好， 我目前正在研究一个研究项目，使用Google AI Studio，并认为你们可能会提供帮助。该模型是Gemini 2.0 Flash思考实验01-21，已经计算了2天以上的响应。我不确定发生了什么...   计算时间   这是一个猜测：    潜在的假设  ：//preview.itd.it/6axzer7zlrje1.png？width = 1920＆amp;格式= png＆amp; auto = webp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp; href=&quot;https://discuss.ai.google.dev/t/gemini-2-0-flash-thinking-experimental-01-21-incredibly-long-response-time-currently-131000s/66470&quot;&gt;https: //discuss.ai.google.dev/t/gemini-2-0-flash-thinking-experimental-01-21-incredibly-long-response-time-currently-131000s/66470 &lt; P&gt;在此先感谢您的任何建议。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/captain_meat_hat     [link]   ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irv0m4/rp_llm_gemini_flash_20_failing_to_converge_to_an/</guid>
      <pubDate>Mon, 17 Feb 2025 21:12:31 GMT</pubDate>
    </item>
    <item>
      <title>使用LLMS总结长文档的最佳方法是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irskqw/whats_the_best_way_to_summarise_long_documents/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  现在，我们所有人都必须遇到一个情况，我们需要处理长文档，说明转录或书籍，需要对其进行处理对于诸如摘要，创建行动项目或其他内容之类的任务。 我在讨论背后的动机是知道人们如何个人处理这种情况，尤其是在您需要更高的实际产品中准确性。 我将提到我过去尝试过的几种方法，例如 subursive摘要方法，您将文本分为块，并继续汇总一组块直到您可以达到最后一个摘要，有点像地图。另一种方法是顺序方法，我们从一个块开始，在下一个块中使用它的摘要作为上下文。 弹性摘要如果将主题分为文档不同位置的块，则您可能会错过信息。另一方面，顺序方法的限制是，最初处理的块中的信息在最后的摘要中可能会过分代表。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/usious-swim1266     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irskqw/whats_the_best_way_to_summarise_long_documents/</guid>
      <pubDate>Mon, 17 Feb 2025 19:35:22 GMT</pubDate>
    </item>
    <item>
      <title>[d]“反向传播：多元链规则”的视觉解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irs3gn/d_visual_explanation_of_backpropagation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我开始研究反向流动的视觉说明。这是第1部分： https://substack.com/home/post/post/p-157218392 。请让我知道您的想法。 使我对倒退的一部分感到困惑，这是为什么人们将反向传播与链条规则相关联？链条规则无法清楚地解释从参数到损失的多个路径。最终，我意识到我错过了“多元链规则”一词。一旦我找到了它，一切都在我的脑海中点击。让我知道您在这里有想法。  谢谢，  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/madiyar     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irs3gn/d_visual_explanation_of_backpropagation/</guid>
      <pubDate>Mon, 17 Feb 2025 19:16:15 GMT</pubDate>
    </item>
    <item>
      <title>[r]忘记数据和微调！只需折叠网络以压缩[2025年2月]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irqngl/r_forget_the_data_and_finetuning_just_fold_the/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irqngl/r_forget_the_data_and_finetuning_just_fold_the/</guid>
      <pubDate>Mon, 17 Feb 2025 18:19:59 GMT</pubDate>
    </item>
    <item>
      <title>[D]就业市场如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irnuv1/d_hows_the_job_market/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  昨天，我开始申请新工作。目前，我的标题是“ ML工程师”但是说实话，我最近一直在运行更像ML顾问 - 我已经好几个月了。专注于ML。似乎有很多角色正在寻找拥有3年以上经验的候选人。 我只是对我在接受第一次面试之前将需要多少申请的申请 - 我目前在24个申请中。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ready_plastic1737     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irnuv1/d_hows_the_job_market/</guid>
      <pubDate>Mon, 17 Feb 2025 16:29:37 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ASL手势字母到文本程序？输入有帮助！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irmh9f/discussion_asl_hand_gesture_alphabet_to_text/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已被禁用，这意味着我无法使用键盘（甚至在手机上触摸等）输入很长时间。语音到文本很有用，但是对于我的大学论文，我还需要其他一些选择，以便我可以休息我的语音/喉咙。 我突然想知道是否存在一种可以将手势转化为文本的技术 - 将美国或英国的手语视为文本。但是我不需要整个签名的语言，只是一个可以通过网络摄像头识别字母的程序，然后输出正确的字母（或靠近，即使是语音的说法也不完美）。   看来独立开发人员正在为此致力于这一点，但是目前尚无应用程序可用。如果有人认为他们可以为我做这样的事情，我愿意诚实地付款，我认为我什至可以学会很快地“签署”字母，并提高速度。老实说，我渴望这样的程序，但是我本人没有编码或编程经验，我只是一个人做。 有人知道任何帮助/任何已经做过/可以做的人这样的东西？这甚至可行吗？我不会问，除非我认为这真的很有益。 非常感谢您的任何帮助！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fudgecake199     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irmh9f/discussion_asl_hand_gesture_alphabet_to_text/</guid>
      <pubDate>Mon, 17 Feb 2025 15:31:45 GMT</pubDate>
    </item>
    <item>
      <title>** [讨论] Bytegpt-Small：我的第一个用于移动设备的字节式LLM **🚀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irloen/discussion_bytegptsmall_my_first_bytetokenized/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿reddit， 我一直在研究专为&lt;强&gt;计算和内存受限的设备，例如手机和嵌入式系统。 🚀 这是我的第一个版本： bytegpt-small  。它是一个小型GPT风格的模型接受了字节令牌化训练（受BYT5的启发），以最大程度地提高效率。   为什么要字节令牌化？     较小的足迹：微小的嵌入减少模型尺寸和内存的使用。   无依赖性：字节级令牌化很简单 - 不需要句子或bpe。强&gt;更好地处理错别字和看不见的令牌。    我的系列计划：      Bytegpt-small：现在活下来！我将尽快添加onnx，coreml和tflite文件  指令调整：使其聊天。    更大型号：训练字节中 - 中等（〜150m参数）。    gpro蒸馏：缩小模型，同时保持质量。专注于在边缘运行的特定领域的小LLM。   为什么我要发布： 我很喜欢您的反馈，尤其是在您：  - 具有在移动设备或嵌入式设备上部署 llms的经验&lt; /strong&gt;。认为Byte令牌化的潜力比人们想象的要大。  链接到型号：   bytegpt-small“   您是否尝试过 on Device llms ？  您对 byte级别的tokenization的经验 vs.子词模型？  关于GPRO蒸馏技术的任何建议？   期待您的想法！ 😊  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kells1986     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irloen/discussion_bytegptsmall_my_first_bytetokenized/</guid>
      <pubDate>Mon, 17 Feb 2025 14:57:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] TTSleaderboard-客观评估语音生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iri3dv/p_ttsleaderboard_objective_evaluation_of_speech/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我决定为语音生成的客观评估打开包裹： https://github.com/balacoon/speech_gen_eval    我开始在其上填写ttsleaderboard： https://huggingface.co/spaces/balacoon/ttsleaderboard   有ttsds（ https://balacoon.com/blog/blog/tts \ _leaderboard/     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/clementruhm     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iri3dv/p_ttsleaderboard_objective_evaluation_of_speech/</guid>
      <pubDate>Mon, 17 Feb 2025 11:49:36 GMT</pubDate>
    </item>
    <item>
      <title>[d]微调图像分类模型的最佳技巧和技巧是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irhhn4/d_what_are_your_best_tips_tricks_for_finetuning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 我目前正在参加专注于图像分类（70000 images）的Kaggle竞赛/strong&gt;，我正在深入研究预先训练的模型。虽然我对这一过程有着深入的了解，但我知道只有来自现实世界的实践才有丰富的经验和聪明的技巧。 我很想听听效果最好的技术在微调图像模型中适合您！    最佳预审计模型  您是否有用于图像分类的首选模型任务？ （例如，有效网络，Convnext，Vit，Swin Transformer等） 您如何在CNN和Vision Transformers之间决定？ 任何表现出令人惊讶的被低估的体系结构吗？    优化器＆amp;学习率策略  哪些优化者给您带来了最佳结果？ （adamw或sgd ??） 您如何安排学习率？ （OnecyClelr，cosineannealing，reducelRonplateau等）      数据增强＆amp;预处理  什么增强为您引起了明显的提升？ 正则化＆amp;预防过度拟合  您如何处理微调模型中的过度拟合？     推论＆amp;后处理提示  您是否使用测试时间增强（TTA），结合或其他技巧来提高性能？       &lt;强&gt;培训策略＆amp;技巧：  您如何决定在填充模型时要解冻多少层   增加了FC头部中的层是否会使它在小数据集中过度拟合？    很想听听您从自己的经历中获得的任何经验教训，洞察力，甚至是错误！  您还可以链接您认为具有高质量的资源或Kaggle笔记本。 期待您的响应。  &lt;！&lt;！ -  sc_on- - &gt;＆＃32;提交由＆＃32; /u/u/crearsive-bid6127     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irhhn4/d_what_are_your_best_tips_tricks_for_finetuning/</guid>
      <pubDate>Mon, 17 Feb 2025 11:08:57 GMT</pubDate>
    </item>
    <item>
      <title>[R]区域自适应抽样：通过选择性更新高关注区域来加速扩散变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irfq36/r_regionadaptive_sampling_accelerating_diffusion/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  此处的关键贡献是扩散变压器的一种新的自适应采样方法，该方法通过基于区域重要性选择性分配注意力来降低计算。它没有平等地处理所有区域，而是确定哪些零件需要更详细的处理。 主要技术方面： - 基于预测的重要性得分 - 修改的注意力机制与与之兼容现有体系结构 - 记忆效率的自适应缓存策略 结果显示：-30-50％的计算时间减少 -  FID或剪辑分数中没有降解 - 通过自适应采样节省40％的内存 - 有效 - 在多个模型架构中有效 - 为有条件和无条件的生成工作 我认为这对于计算效率很重要的现实应用程序可能特别影响。在将资源使用量减少多达50％的同时保持质量的能力为在更适度的硬件上运行这些模型的可能性开辟了可能性。这里的原则也可能会很好地转移到选择性注意力分配可能会有所帮助的其他领域，例如视频生成或3D渲染。 我最感兴趣的是，这是如何挑战统一处理对于高质量而需要的假设。一代。通过证明我们可以选择计算分配，这表明当前架构的效率提高仍然有很大的空间。  tldr：新方法通过选择性注意重要的注意力将扩散变压器计算减少30-50％ ，没有质量损失。  完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irfq36/r_regionadaptive_sampling_accelerating_diffusion/</guid>
      <pubDate>Mon, 17 Feb 2025 09:03:14 GMT</pubDate>
    </item>
    <item>
      <title>[d] OpenAI帆布如何与Intlace人类编辑一起使用KV缓存？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irfgsc/d_how_does_openai_canvas_works_with_inplace_human/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想知道，如果openai允许它允许在内置的人类编辑，如何使用kv缓存？它是否必须使整个缓存无效到更早的文件编辑，然后必须在其余的帆布文本中执行前向通行证？ 它是否可以像所描述的图像一样起作用，或者有更好的方法将缓存保存在编辑之间但没有变化的文本中（我认为不是这样，因为隐藏的上下文会随着未来的所有代币而改变）？  https://preview.redd.it/e1ccea3zvnje1.png?width=746&amp;format=png&amp;auto= webp＆amp; s = F3848812A20F770C938B1D9B54EABAA64B07AFE5   喜欢：     line 1：def process_data（） ）第3行：y = x + 10→kv₃（意识到KV₁，kv₂）第4行：返回y→kv₄（知道kv₁，kv₂，kv₃，kv₃）现在我们编辑第2行：  现在我们编辑第2行    第1行：def Process_data（）：→KV₁（仍然有效）第2行：x = 10→KV₂&#39;（new）行3：y = x + 10→kv₃（无效！基于旧x值）第4行：返回y→kv₄（基于旧链的无效！）  有没有更聪明的方法可以逃脱较少的远期通行证？ 编辑：我现在认识到标题的差异有多糟。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/punsbymann     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1irfgsc/1irfgsc/d_how_does_openai_openai_canvas_works_with_with_with_inplace_inplace_human/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irfgsc/d_how_does_openai_canvas_works_with_inplace_human/</guid>
      <pubDate>Mon, 17 Feb 2025 08:44:48 GMT</pubDate>
    </item>
    <item>
      <title>[r]在LLM中，在哪里可以在哪里进行学习？ （神经2024）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irbjli/r_where_does_incontext_learning_happen_in_llms/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;    摘要：自我监督的大语言模型已经证明了能力要通过文本学习执行各种任务，但是对于模型将任务定位在迅速说明和演示示例方面的位置知之甚少。  在这项工作中，我们试图表征从识别任务到执行任务的大型语言模型过渡的区域。通过gptneo2.7b，bloom3b和starcoder2-7b，llama3.1-8b，llama3.1-8b-instruction，机器翻译和代码生成的一系列层面上下文掩盖实验，我们证明了A＆Met， ;任务识别;不再需要将任务编码到输入表示形式和对上下文的关注的点。 &lt; / p&gt; 在提示5个示例时，利用这种冗余的优势可节省45％的计算节省，并使用机器翻译的示例在第14/32层获得任务识别。我们的发现也对资源和参数有效微调有影响。 we observe a correspondence between fine-tuning performance of individual LoRA layers and the task recognition layers. &lt;a href=&quot;https://proceedings.neurips.cc/paper_files/paper/2024/file/3979818cdc7bc8dbeec87170c11ee340 -paper-conference.pdf“&gt; PaperLink ，提交由＆＃32; /u/u/thistory_insect668     [link]   ＆＃32;   [注释]  /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irbjli/r_where_does_incontext_learning_happen_in_llms/</guid>
      <pubDate>Mon, 17 Feb 2025 04:27:03 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何处理高度不平衡的数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ir2zm3/dhow_to_handle_highly_imbalanced_dataset/</link>
      <description><![CDATA[在解决高度不平衡数据集的社区。过去，我建立了搅动预测模型，现在我专注于预测保险索赔，在此索赔的百分比很低。 我的数据集跨越了15年，并且包含约800,000个记录，并具有具有此类功能的功能作为性别，年龄，马力，汽车品牌＆amp;类型  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sthyddoctor007     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ir2zm3/dhow_to_handle_highly_imbalanced_dataset/</guid>
      <pubDate>Sun, 16 Feb 2025 21:22:49 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会导致禁止。 鼓励其他人创建新的帖子，以便在此处发布问题！ 线程将一直活着直到下一个，因此请继续发布标题之后的发布。    meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>