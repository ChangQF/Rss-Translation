<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Thu, 13 Jun 2024 01:03:49 GMT</lastBuildDate>
    <item>
      <title>[D] H100 为学术研究探究而建</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dejlq5/d_h100_build_for_academic_research_inquiry/</link>
      <description><![CDATA[我知道有人会说“这需要专业人士”，但我想我还是会问。我的任务是配置几个 H100 服务器（8x HGX H100 SXM5）。目前，我所有的工作都是在 A100 和 L40 GPU 上完成的。 如果您打算在服务器上花费更多来训练/微调 LLM、扩散/流动模型，您会把它放在配置的哪里？CPU 升级？最大内存？用大量 NVMe 驱动器作为缓存加载它？ 现在我正在看 2x (Genoa) AMD EPYC 9634。我知道升级到 Bergamos 或 Intel Xeon Platinum（8480+、8490H、8592V）的成本更高，但对于我的用例，我认为我不会看到任何实际收益。看起来如果我使用英特尔，我可以获得高达 4TB 的 RAM，而 AMD 主板将我限制为 3 TB。  我被告知的经验法则是每 GB VRAM 对应 4 GB 内存，因此实​​际上对于我的用例而言 2.5-3TB 可能就足够了。  对于存储，我将仅使用 NVMe 驱动器作为缓存，因为我们已经有一个相当大的专用存储解决方案。     提交人    /u/ShotUnderstanding562   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dejlq5/d_h100_build_for_academic_research_inquiry/</guid>
      <pubDate>Wed, 12 Jun 2024 22:34:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] CycleGAN 为什么有效？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1degbf8/d_why_does_cyclegan_work/</link>
      <description><![CDATA[我知道这是一个不再流行的旧模型，但有人知道任何展示 CycleGAN 工作原理的作品吗？（即这篇论文：https://arxiv.org/abs/1703.10593）。很久以前，我尝试将这篇论文应用于数值问题，但无法让它发挥作用。从两个边际学习条件分布似乎很神奇。它是否有效，因为图像的结构非常独特？如果有人有任何答案或研究，我会很有兴趣了解更多。    提交人    /u/www3cam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1degbf8/d_why_does_cyclegan_work/</guid>
      <pubDate>Wed, 12 Jun 2024 20:13:41 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] TinyML 疑难解答</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deg43s/discussion_tinyml_troubleshooting/</link>
      <description><![CDATA[对于那些在资源受限的设备上进行机器学习的人，我有一个问题：当你遇到困难时，你会使用什么资源来摆脱困境？ 我最近在尝试将 TensorFlow 对象检测模型加载到微控制器中时遇到了一个挑战。由于原始模型太大，因此必须对该模型进行量化。这导致 tflite 和 tflite-micro 出现了几个问题，我花了几天时间才解决。虽然原始模型由于其大小而无法使用，但它至少在我的桌面（tflite）和微控制器（tflite micro）上产生了相同的预测。但是，对 tflite 模型应用全整数量化会导致微控制器上的 Python 输出和 C++ 输出不匹配。我看到其他人在论坛上遇到了类似的问题，但没有任何明确的解决方案。我最终没有使用全整数模型，因为准确度损失太大。相反，我按照 TensorFlow 网站上的 quantization_debugger 文档选择性地量化了模型。再次，输出不匹配。我花了几天时间为每一层打开和关闭量化，并尝试不同的组合，最后才终于解决了这个问题。 我从这次调试会话中得到的主要结论是，几乎没有资源可以解决这些问题。教程和文章很少，大多数论坛问题要么“由于不活动而被标记为过时”，要么没有回复，要么尚未解决。 我很好奇你们都觉得哪些资源有用。当你遇到障碍时，你是如何克服它的？我不相信其他人都像我一样摸索着。我的职业生涯才刚刚开始，所以我真的很感激任何建议或提示！    提交人    /u/selfhelpjunkie99   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deg43s/discussion_tinyml_troubleshooting/</guid>
      <pubDate>Wed, 12 Jun 2024 20:05:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] Grokking 的问题解决了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1defvmv/d_is_grokking_solved/</link>
      <description><![CDATA[最近的 Grokfast 论文 发现了一种将算法数据集的 Grokking 速度提高 50 倍的方法。早些时候的 Omnigrok 论文 指出，对于他们的算法数据集，“在恒定权重范数下的约束优化在很大程度上消除了 Grokking” 这些改进是否意味着现在我们在训练模型时不必担心延迟泛化/grokking（尽管其机制不明朗）？    提交人    /u/delorean-88   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1defvmv/d_is_grokking_solved/</guid>
      <pubDate>Wed, 12 Jun 2024 19:55:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我厌倦了 LangChain，所以我制作了一个简单的开源替代方案，支持工具使用和视觉，以尽可能轻松地构建 Python AI 应用程序。（simpleaichat + vision + anthropic 和 gemini）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deffo8/p_im_tired_of_langchain_so_i_made_a_simple/</link>
      <description><![CDATA[https://github.com/piEsposito/tiny-ai-client 构建 tiny-ai-client 的动机来自于对 Langchain 的失望，它变得臃肿、难以使用且文档不全 - 并从 simpleaichat 中汲取灵感，但除了 OpenAI（Gemini、Anthropic - Groq 和 Mistral 正在研发中）之外，还增加了对视觉、工具和更多 LLM 提供商的支持。 我构建它是为了延续 simpleaichat 的初衷，不是为了炒作、筹集资金或其他什么，而是为了帮助人们做两件事：尽可能轻松地构建 AI 应用程序，并在无需使用 Langchain 的情况下切换 LLM。 这是一个极简软件包的可行版本，支持视觉、工具和异步调用。还有很多改进要做，但即使在目前的状态下，tiny-ai-client 也普遍改善了我与 LLM 的交互，并已成功用于生产。 让我知道你的想法：仍有一些错误可能需要修复，但所有示例都可以正常工作并且易于适应你的用例。    提交人    /u/lee_from_teashop   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deffo8/p_im_tired_of_langchain_so_i_made_a_simple/</guid>
      <pubDate>Wed, 12 Jun 2024 19:36:58 GMT</pubDate>
    </item>
    <item>
      <title>CLASSP：一种通过调整抑制和稀疏性提升进行持续学习的生物启发方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deazza/classp_a_biologicallyinspired_approach_to/</link>
      <description><![CDATA[  由    /u/Gold-Plum-1436  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deazza/classp_a_biologicallyinspired_approach_to/</guid>
      <pubDate>Wed, 12 Jun 2024 16:33:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习系统工程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de9glz/d_ml_system_engineering/</link>
      <description><![CDATA[最近的 WWDC 活动展示了 Apple 非凡的系统工程，它允许使用用户友好的产品，同时仍设法使用资源密集型的设备语言模型（3-7B 参数）。这对我来说非常鼓舞人心，尤其是作为一名博士生，我的大多数项目最终都只是一篇研究论文！ 我在 ML、DL 和 RL 方面拥有良好的理论背景，并且对大多数最先进的方法有很好的了解。但是，我在使用 ML 进行后端决策的可部署产品方面没有任何经验。 我想知道这里的人是否可以为我指出一些好的资源，以便我更多地了解 ML 系统设计和 MLOps，也许还有一些项目的想法可以获得更多经验。    提交人    /u/Personal_Click_6502   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de9glz/d_ml_system_engineering/</guid>
      <pubDate>Wed, 12 Jun 2024 15:29:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Mamba 进行推测解码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de8rk4/p_speculative_decoding_with_mamba/</link>
      <description><![CDATA[嗨，我正在尝试通过推测采样加速大型语言模型解码来实现推测解码，这是 colab 笔记本。 我使用相同的模型进行测试，但得到了不同的输出。当我尝试调试时，我发现来自 infer_params 的前向传递的 logit 与生成的 logit 不同。任何关于可能导致这种情况的见解都将不胜感激。    提交人    /u/Jazzlike-Shake4595   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de8rk4/p_speculative_decoding_with_mamba/</guid>
      <pubDate>Wed, 12 Jun 2024 15:00:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 谷歌研究表明，对法学硕士进行微调会线性增加幻觉？😐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de5wa2/r_google_study_says_finetuning_an_llm_linearly/</link>
      <description><![CDATA[他们准备了一个 QA 任务来观察幻觉，既有已知示例（与模型在初始训练期间看到的信息类似的训练实例），也有未知示例（引入了模型之前从未接触过的新信息）。 他们发现：  由于过度拟合，微调数据集中的未知示例会降低性能，训练越多。它们会导致幻觉并降低准确性。已知示例对性能有积极影响。 早期停止有助于避免这种情况，这可能意味着未知示例在较短的训练中是中性的。 未知示例的拟合速度较慢也表明模型难以通过微调获取新知识。  论文：https://arxiv.org/pdf/2405.05904 我每天分享高质量的 AI 更新和教程。 如果您喜欢这篇文章并希望了解最新的 AI 研究，您可以查看：https://linktr.ee/sarthakrastogi 或我的 Twitter：https://x.com/sarthakai    由    /u/sarthakai  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de5wa2/r_google_study_says_finetuning_an_llm_linearly/</guid>
      <pubDate>Wed, 12 Jun 2024 12:51:31 GMT</pubDate>
    </item>
    <item>
      <title>寻找时间序列资源[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de38nr/looking_for_time_series_resources_p/</link>
      <description><![CDATA[您好， 我是一名数据科学家，有 5-10 年的工作经验。我最近换了行业，现在面临很多时间序列数据方面的挑战。 我想读一本书、参加一门课程或采取任何其他方式来更新和提高我在这个主题上的知识。 我有兴趣更深入地了解最先进的时间序列技术。 （在学习期间，我们从计量经济学 POV 深入研究了 ARIMA 和 VAR 模型。但肯定有更新的技术与 ML 算法堆栈更相关，如 LSTM 甚至 CNN（ROCKET）。时间扭曲又是什么鬼？） 你能推荐任何适合我需要的东西吗？    提交人    /u/Antalagor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de38nr/looking_for_time_series_resources_p/</guid>
      <pubDate>Wed, 12 Jun 2024 10:20:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] François Chollet 宣布新的 ARC 奖挑战——它是 AI 泛化的终极测试吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de2b16/d_françois_chollet_announces_new_arc_prize/</link>
      <description><![CDATA[Keras 的创建者兼《使用 Python 进行深度学习》一书的作者 François Chollet 宣布了一项名为 ARC Prize 的新挑战，旨在解决 ARC-AGI 基准。对于那些不熟悉的人来说，ARC（抽象和推理语料库）旨在衡量机器从几个例子中进行概括的能力，模拟类似人类的学习。 以下是宣布挑战的推文：   ARC 基准对于当前的深度学习模型（包括我们今天看到的大型语言模型 (LLM)）来说非常困难。它旨在测试人工智能理解和应用抽象推理的能力——这是通用智能的一个关键组成部分。 很想知道这个社区对 ARC 挑战及其对人工智能研究的影响的看法。  ARC 是衡量人工智能泛化的良好指标吗？  与其他基准相比，您认为 ARC 基准在多大程度上反映了人工智能的泛化能力？ ARC 中是否存在任何固有的偏见或限制，可能会扭曲结果？  人工智能泛化的现状  当前模型在 ARC 上的表现如何，它们的主要局限性是什么？ 最近是否有任何突破或技术有望解决 ARC 挑战？  ARC 大奖挑战的潜在影响  这项挑战将如何影响 AI 未来的研究方向？ 为这一挑战开发的解决方案除了解决 ARC 特定任务之外，是否还有更广泛的应用？  策略和方法  您认为哪种方法可能有效解决 ARC 基准？ 是否存在任何未充分探索的领域或新颖的方法可能破解 ARC 代码？      提交人    /u/HairyIndi​​anDude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de2b16/d_françois_chollet_announces_new_arc_prize/</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习论文与最佳人物</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de0i4b/d_ml_papers_with_the_best_figures/</link>
      <description><![CDATA[我经常很难制作出美观且高质量的图表，因此我认为下次需要制作图表时，要求提供论文作为参考会很有帮助。我想到了 RLHF 管道图。还有哪些其他论文浮现在我的脑海中或通常用作参考？    提交人    /u/SatisfyingLatte   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de0i4b/d_ml_papers_with_the_best_figures/</guid>
      <pubDate>Wed, 12 Jun 2024 07:04:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 拥有 ML/AI 博士学位会限制你从事哪些类型的工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddua2b/d_what_kind_of_jobs_do_a_phd_in_mlai_restrict_you/</link>
      <description><![CDATA[我已经看到很多关于博士学位如何可能或不可能帮助你获得特定 X 工作机会的帖子。 但我很好奇，获得博士学位是否实际上会限制你从事某些工作，因为雇主认为你资历过高、年纪太大或缺乏生产 YOE 等。    提交人    /u/Confident_Ad_7734   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddua2b/d_what_kind_of_jobs_do_a_phd_in_mlai_restrict_you/</guid>
      <pubDate>Wed, 12 Jun 2024 01:01:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用平方误差而不是绝对误差？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddjbdi/why_use_squared_error_instead_of_absolute_error_d/</link>
      <description><![CDATA[我不明白为什么当错误 = 0 时得到未定义的偏导数会是一个大问题，我的意思是得到零错误不是我们从一开始就想要的吗？    提交人    /u/NeatJealous8110   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddjbdi/why_use_squared_error_instead_of_absolute_error_d/</guid>
      <pubDate>Tue, 11 Jun 2024 17:07:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>