<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Mon, 10 Feb 2025 18:22:57 GMT</lastBuildDate>
    <item>
      <title>[r]扩展讲习班论文作品时的常见做法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imaq6g/r_common_practice_when_extending_a_workshop/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我过去接受了一张纸上的纸张。现在，我基本上有同一篇论文（问题陈述等），但是我提出了另一种损失，基本上使我获得了我在研讨会上可以获得的一切，但是工作更好，更好地工作 - 让我申请除了MNIST（这是我的工作室论文）外，其他数据集和数据类型（例如3D）的方法（例如3D）。 我想尽快将其提交给会议。我应该怎么办？创建具有不同标题的Arxiv中的新预印？还是简单地使用此版本更新预印？研讨会论文已经发表。 我有疑问，因为很好，整体构造与以前相同。发生了变化的是一些至关重要的数学，以及额外的实验和更好的结果。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/howtoreWriteAname     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imaq6g/r_common_practice_when_extending_a_workshop/</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:32 GMT</pubDate>
    </item>
    <item>
      <title>[d] SAR卫星图像上的图形场景生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imaarw/d_graph_scene_generation_on_sar_satellite_images/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您知道有任何有关此主题的模型和数据集的论文吗？  卫星图像上有很多用于对象检测的技术，例如： https ：//github.com/satellite-image-deep-learning/techniques   我特别对多光谱数据集感到好奇。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/kubehe     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imaarw/d_graph_scene_generation_on_sar_satellite_images/</guid>
      <pubDate>Mon, 10 Feb 2025 16:35:01 GMT</pubDate>
    </item>
    <item>
      <title>[d] KL分歧是LLM训练后RL的主要奖励？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1im7bsb/d_kl_divergence_as_a_primary_reward_in_llm/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  说我们预算了一个LLM。如果我们使用预处理的LLM生成一个序列，则不会完全获得具有最佳KL差异的序列，该序列与验证的LLM相关。这就是为什么Beam搜索以前是一件事情的原因。那么，如果我们执行RL纯kl差异是奖励模型怎么办？最终的模型将是一个模型，该模型将生成比预读的LLM的总体KL差异要低得多的序列。会发生什么？该模型会“更连贯”？ 我想听听每个人对此的想法，因为这似乎是一个思想实验，似乎会导致一个琐碎的答案，但是序列的kl差异是一个目标实际上，如果没有非线性优化（RL），这实际上很难解决。是的，我们直接知道令牌概率，但是很难知道该序列的累积概率是“更喜欢”的模型。感觉就像是一个不对称的优化问题（易于评估，但难以解决），我想知道是否有任何有意义的东西会出现。 我的实现想法就是使用GRPO进行RL。但是你们怎么看？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ricecake1539     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1im7bsb/d_kl_divergence_as_a_primary_reward_in_llm/</guid>
      <pubDate>Mon, 10 Feb 2025 14:27:55 GMT</pubDate>
    </item>
    <item>
      <title>深度学习博士学位的笔记本电脑[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1im44wy/laptop_for_deep_learning_phd_d/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我有2,000英镑，我需要在三月之前在笔记本电脑上使用（否则我损失了资金）我在应用数学上的博士学位，涉及大量的深度学习。我所做的大部分可能都会在云上，但是看到我有这个预算，我不妨在我需要离线运行一些事情时获得最好的笔记本电脑。 我可以得到一些建议购买什么？我不想获得Mac，但对所有选项都感到困惑。我知道刚刚发布了新的GPU（NVIDIA 5000系列），并且已经使用Lunar Lake / Snapdragon CPU宣布了新的笔记本电脑。&lt; / p&gt; 我不确定我是否应该旨在用不错的GPU获得一些东西或者只需像Lenove Carbon X1一样获取一本薄/轻的超书。 感谢您的帮助！  **编辑： 我可以访问HPC通过我的大学，但在使用之前，我宁愿确保我的项目在我将自己或MNIST，CFAR等创建的玩具数据集上工作，因此，在推理之上，这意味着我可能会在笔记本电脑上进行一些轻训练（这也可以在云TBH上）。因此，问题是我要使用一个GPU，它会排干电池并增加散装或变得苗条。 我一直使用Windows，因为我不喜欢软件，所以它没有&#39; T确实是一个问题。尽管我从未因为担心错误而更新到Windows11。 我有一台桌面PC，几年前使用RX 5600 XT构建，我认为这几天已经过时了。但这意味着我已经拥有一台台式PC，所以我不会停靠笔记本电脑。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bloch2001     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1im44wy/laptop_for_deep_learning_phd_d/</guid>
      <pubDate>Mon, 10 Feb 2025 11:37:51 GMT</pubDate>
    </item>
    <item>
      <title>[R]使用潜在扩散变压器进行未校准的图像集的多视图场景完成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1im2al0/r_multiview_scene_completion_using_latent/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项工作提出了一种基于变压器的方法，用于在多视图场景中捕获丢失区域，同时保持几何一致性。关键创新是通过两个阶段的过程来处理不受约束的休闲照片，该过程在产生缺失区域之前首先分析跨视图的可见内容。 关键的技术方面： - 多头注意的注意机制同时多次观点 - 新颖的一致性 - 新型一致性损失确保生成的内容跨不同角度对齐 - 直接与稀疏，非结构化的照片集一起使用 - 处理室内和室外场景 - 在消费者GPU硬件 结果上运行： - 视觉质量指标与先前的30％提高：方法 - 在不同的捕获密度之间的性能一致 - 对复杂几何结构的鲁棒处理 - 对典型场景大小的实时推断 我认为这可能会严重影响3D内容创建的几个领域。使用休闲照片的能力消除了房地产，虚拟旅游和建筑可视化应用程序的主要障碍。跨视图的一致性对于VR/AR用例尤其重要。 我看到的主要限制是降级性能，输入非常稀疏，这通常是带有休闲照片集的现实。还可以改善处理反射表面和复杂的几何形状。  tldr：新的基于变形金刚的方法在多视图中使用常规照片在多视场景中完成缺失区域，同时跨视点保持一致性。比以前的方法显示出30％的视觉质量。摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1im2al0/r_multiview_scene_completion_using_latent/</guid>
      <pubDate>Mon, 10 Feb 2025 09:30:43 GMT</pubDate>
    </item>
    <item>
      <title>[d]神经2025的位置纸轨道会有一个位置纸轨道吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1im1j39/d_will_there_be_a_position_paper_track_at_neurips/</link>
      <description><![CDATA[在&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/skeeringReal     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1im1j39/d_will_there_there_be_a_position_paper_paper_track_atap_ate_neurips/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1im1j39/d_will_there_be_a_position_paper_track_at_neurips/</guid>
      <pubDate>Mon, 10 Feb 2025 08:32:54 GMT</pubDate>
    </item>
    <item>
      <title>[p]邀请合作者获得可区分的几何损失函数库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilzqdb/p_inviting_collaborators_for_a_differentiable/</link>
      <description><![CDATA[在一个用于在pytorch中创建可区分几何损失函数库的项目。 我在这里放置了一些初始提交的项目，以了解可能的外观： github repo        &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/atharvaaalok1     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilzqdb/p_inviting_collaborators_for_a_differentiable/</guid>
      <pubDate>Mon, 10 Feb 2025 06:22:02 GMT</pubDate>
    </item>
    <item>
      <title>[R]您的AI看不到大猩猩：LLMS执行探索性数据分析能力的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iljqve/r_your_ai_cant_see_gorillas_a_comparison_of_llms/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/jsonathan     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iljqve/r_your_ai_ai_ai_cant_see_gorillas_a_comparison_comparison_of_of_lls/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iljqve/r_your_ai_cant_see_gorillas_a_comparison_of_llms/</guid>
      <pubDate>Sun, 09 Feb 2025 17:18:41 GMT</pubDate>
    </item>
    <item>
      <title>[P]周末实施高斯MAE</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iljb52/p_weekend_implementation_of_gaussian_mae/</link>
      <description><![CDATA[在自动编码器    https://github.com/darshanmakwana412/gaussian-mae-mae-mae-mae-mae  /p&gt;  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/apartmenteither4838     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iljb52/p_weekend_implementation_of_gaussian_mae/</guid>
      <pubDate>Sun, 09 Feb 2025 17:00:44 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[p]综合数据多样性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilfse6/p_evals_for_diversity_in_synthetic_data/</link>
      <description><![CDATA[在/p&gt; 我写了一份概述，以衡量LLM生成的合成数据中的语言多样性。  链接： https://amitness.com/posts/diversity-evals    这对于系统测试各种技术对改善多样性的影响很有用。  欢迎任何反馈！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/amitness     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilfse6/p_evals_for_diversity_in_synthetic_data/</guid>
      <pubDate>Sun, 09 Feb 2025 14:24:47 GMT</pubDate>
    </item>
    <item>
      <title>[r]豪华轿车：少更多用于推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ile9nu/r_limo_less_is_more_for_reasoning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我们提出了一个基本发现，挑战了我们对大语言模型中复杂推理如何出现的理解。尽管传统的观点表明，复杂的推理任务需要广泛的培训数据（通常是100,000个例子），但我们证明了一个惊人的现象：复杂的数学推理能力可以有效地引起，而令人惊讶的例子很少。这一发现不仅挑战了大量数据要求的假设，而且挑战了监督微调的共同信念主要导致记忆而不是概括。通过全面的实验，我们提出的模型豪华轿车证明了数学推理的前所未有的性能和效率。仅使用817个精选的训练样品，豪华轿车在高度挑战性的AIME基准上实现了57.1％的准确性，而数学的精度为94.8％，在AIME上将以前的强SFT型号从6.5％提高到57.1％，从59.2％，从59.2％提高到94.8％数学，而仅使用以前方法所需的培训数据的1％。最引人注目的是，豪华轿车表现出异常的分布概括，在10种不同的基准测试中实现了40.5％的绝对改进，优于对100倍培训的模型，直接挑战了SFT固有地导致记忆而不是概括的普遍观念。综合这些开创性的结果，我们提出了较少的推理假设（豪华假设）：在基础模型中，在预训练期间已经对领域知识进行了全面编码，可以通过最小但精确的跨越认知过程的证明来出现。该假设认为，复杂推理的启发阈值并非固有地受到目标推理任务的复杂性的限制，而是从根本上由两个关键因素确定：（1）模型在训练期间的编码知识基础的完整性，以及（2 ）训练后示例的有效性，这些示例是“认知模板”，该模型显示了该模型如何有效利用其现有知识库来解决复杂的推理任务。   arxiv链接： [2502.03387]豪华轿车：更少用于推理    &lt;！ -  sc_on- sc_on-&gt;&gt;＆＃32;提交由＆＃32; /u/hiskuu     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ile9nu/r_limo_less_is_more_for_reasoning/</guid>
      <pubDate>Sun, 09 Feb 2025 13:04:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] AI设计的蛋白质中和致命的蛇毒</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1il78ti/r_aidesigned_proteins_neutralize_lethal_snake/</link>
      <description><![CDATA[在/www.nature.com/articles/s41586-024-08393-x    研究人员使用alphafold 2（AF2）和rfdiffusion（开源模型）来设计与并将结合并将（理论上）中和眼镜蛇毒素中和细胞毒素。他们还选择水溶性蛋白，以便可以作为抗蛇毒药物递送。在人皮细胞（角质形成细胞）和小鼠中测试候选蛋白。在实验室条件和浓度中，在模拟咬合后15-30分钟治疗小鼠。 我已经看了一堆生物 + ml纸，从未将其视为应用  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/prototypist     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1il78ti/r_aidesigned_proteins_neutralize_lethal_snake/</guid>
      <pubDate>Sun, 09 Feb 2025 05:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[p]从划痕ML库（火车从CNN到玩具GPT-2）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ikzdsb/p_fromscratch_ml_library_trains_models_from_cnns/</link>
      <description><![CDATA[在/p&gt; 我构建了一个机器学习库（ github ）完全使用Python和Numpy。然后，我用它来训练一系列型号，包括从经典的CNN，重新注册，RNN和LSTM到现代变形金刚，甚至是玩具GPT-2。动机来自我对如何从头开始建立深度学习模型的好奇心，例如从数学公式来看。我构建了这个项目，不是为了取代Pytorch或Tensorflow等生产就绪的库，而是剥离抽象并揭示机器学习的基本数学。  关键点：     所有内容都是在代码中得出的 - 没有不透明的黑匣子。  api镜像pytorch，因此您可以快速拾取它。 您可以训练CNNS，RNNS ，变形金刚，甚至是GPT模型。 设计/调试的设计多于原始性能。    这里有什么不同？   虽然有许多功能强大的ML库（Tensorflow，Pytorch，Scikit-Learn等），但它们通常将基础数学隐藏在抽象层后面。我相信要真正掌握这些工具，您首先需要了解它们如何从头开始工作。该项目明确地衍生了代码中的所有数学和计算操作，使其成为动手的资源，以加深对神经网络和图书馆建筑的理解：）  检查一下：     github repository     api documentation     by-hand/tree/main/示例“&gt;：探索示例中的gpt-2，CNN，变形金字和lstms之类的模型/文件夹   blog Post ：阅读有关项目的动机，设计和挑战   &lt; P&gt;我很想听听任何想法，问题或建议 - 感谢您检查一下！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/megadragon9     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ikzdsb/p_fromscratch_ml_library_trains_models_models_from_cnns/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ikzdsb/p_fromscratch_ml_library_trains_models_from_cnns/</guid>
      <pubDate>Sat, 08 Feb 2025 22:21:58 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      对于那些寻找工作的人请使用此模板  &lt; p&gt;想要被录用：[位置]，薪水期望：[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简短概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，这个社区是适合有经验的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>