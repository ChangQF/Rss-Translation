<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Fri, 02 Aug 2024 03:18:30 GMT</lastBuildDate>
    <item>
      <title>[P] 加权损失函数（Pytorch 的 CrossEntropyLoss）解决多类多输出问题的不平衡数据分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehyv6b/p_weighted_loss_function_pytorchs/</link>
      <description><![CDATA[我正在尝试使用加权损失函数来处理数据中的类别不平衡问题。我的问题是多类别和多输出问题。例如（我的数据有五个输出/目标列（output_1、output_2、output_3）并且每个目标列中有三个类（class_0、class_1 和 class_2）。我目前正在使用 pytorch 的交叉熵损失函数https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html并且我看到它有一个权重参数，但我的理解是，这个相同的权重将统一应用于每个输出/目标，但我想在每个输出/目标中为每个类应用单独的权重。 具体来说，我可以获得如下数据   A B C D E OUTPUT_1 OUTPUT_2 OUTPUT_3    5.65 3.56 0.94 9.23 6.43 0 2 1   7.43 3.95 1.24 7.22 2.66 0 0 0   9.31 2.42 2.91 2.64 6.28 2 0 2   8.19 5.12 1.32 3.12 8.41 0 2 0   9.35 1.92 3.12 4.13 3.14 0 1 1   8.43 9.72 7.23 8.29 9.18 1 0 2   4.32 2.12 3.84 9.42 8.19 0 1 0   3.92 3.91 2.90 8.19 8.41 2 0 2   7.89 1.92 4.12 8.19 7.28 0 1 2   5.21 2.42 3.10 0.31 1.31 2 0 0   其中，产出 1 中的比例为：0 = 0.6, 1 = 0.1, 2 = 0.3 产出 2 中的比例为：0 = 0.4, 1 = 0.3, 2 = 0.3  输出 3 为：0 = 0.4、1 = 0.2、2 = 0.4 我想根据每个输出列中的类分布应用类权重，以便它重新规范化（或重新平衡？不确定这里要使用的术语是什么）类 1 为 0.15，类 0 和类 2 各为 0.425（因此对于 output_1，权重将是 [0.425/0.6、0.15/0.1、0.425/0.3]，对于输出 2，它将是 [0.425/0.4、0.15/0.3、0.425/0.3] 等）。相反，我理解 pytorch 的交叉熵损失函数中的权重参数目前正在做的事情是，它将对每个输出列应用单个类权重。任何帮助都将不胜感激。     由   提交  /u/Individual_Ad_1214   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehyv6b/p_weighted_loss_function_pytorchs/</guid>
      <pubDate>Fri, 02 Aug 2024 02:28:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解 ByteNet 架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehws26/d_understanding_bytenet_architecture/</link>
      <description><![CDATA[你好！ 我正在考虑在一个项目中使用 ByteNet (https://arxiv.org/abs/1610.10099) 架构，并希望更好地了解该模型的工作原理。 我已经阅读了这篇论文大约一百万次，但无法弄清楚动态展开究竟是如何实现的。我知道输入序列被映射到更长的中间表示，其长度是输入长度的函数，但不明白 1×1 卷积层如何做到这一点。我也不清楚输入序列如何可以具有可变长度而没有任何重复。 背景：动态展开的目标是允许模型处理输入长度与目标长度不匹配的情况（例如，将句子翻译成另一种语言时就是这种情况）。它涉及创建输入序列 s 的表示，其长度为 a \ |s| + b，其中 *a 和 b 是超参数。这个新的、更长的表示是使用一维卷积层生成的（以一种我无法理解的方式）。 任何帮助都将不胜感激！或者任何人知道任何解释它的优秀 YouTube 视频，这也会有所帮助。    提交人    /u/BerryLizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehws26/d_understanding_bytenet_architecture/</guid>
      <pubDate>Fri, 02 Aug 2024 00:44:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 长上下文文本分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehw2zt/d_longcontext_text_classification/</link>
      <description><![CDATA[据我所知，DeBERTa v3 large 通常是文本分类中性能最强的 BERT 类模型，但它被限制为 24,528 个标记（这很多，但在某些情况下可能不足以满足我的用例）。有人对比这更长的序列的 SOTA 模型/方法有经验/建议吗？    提交人    /u/sanest-redditor   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehw2zt/d_longcontext_text_classification/</guid>
      <pubDate>Fri, 02 Aug 2024 00:11:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有什么好的可微调的 TTS？（不是 Coqui 或 TorToiSe）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehw1nf/d_any_good_finetunable_tts_not_coqui_or_tortoise/</link>
      <description><![CDATA[大家好！我有一个非常感性的数据集，其中包含大约 20-30 个清晰的英语录音。我想制作一个微调模型来完全复制该声音，并且能够在没有 CUDA 的情况下仅使用 MPS 进行推理。除了 Coqui 和 TorToiSe（它们不适用于高音调数据）之外，还有什么想法以及好的分步文档吗？    提交人    /u/yukiarimo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehw1nf/d_any_good_finetunable_tts_not_coqui_or_tortoise/</guid>
      <pubDate>Fri, 02 Aug 2024 00:10:06 GMT</pubDate>
    </item>
    <item>
      <title>特征提取[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehuw5z/features_extraction_p/</link>
      <description><![CDATA[嗨 r/MachineLearning ， 我正在开展一个数据科学项目，该项目专注于识别与土著相关的数据，我可以使用社区的一些意见。 主要目标是在数据中找到表明信息与土著人民相关的特征，重点是环境和生物多样性数据。这将使我们能够识别与土著社区相关的互联网数据，但这些数据并未明确标记。通过发现这些以前未被识别的与土著相关的数据，我们可以将利益共享实践扩展到这些社区。 我从头开始；我仍然需要找到相关的可用数据集。我正在考虑使用聚类来识别相关参数。但是，我怀疑我需要大量优质数据才能实现有意义的目标。 是否可以使用已经在大量数据上训练过的 LLM（开源或通过 API），并将其用于根据我的需求量身定制的适当迁移学习方法？我愿意接受任何建议，并且真的很好奇人们能提出什么想法。    提交人    /u/Miserable-Ad5138   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehuw5z/features_extraction_p/</guid>
      <pubDate>Thu, 01 Aug 2024 23:17:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在专注于 LLM 的初创公司工作值得吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehudwq/d_is_it_worth_working_at_startups_focusing_on_llm/</link>
      <description><![CDATA[一些正在开发 LLM 产品的初创公司的 HR 找到了我。根据我们的讨论，他们仍然主要将流行的开放 AI 模型或开源模型 (llama3) 用于他们的 LLM 产品（这并不奇怪），我认为工程师将主要做的事情是快速工程和/或微调。我对 LLM 非常感兴趣，我相信这是一个相当突出的未来（如果我错了，请纠正我），但是我不确定如果我在使用这些模型的初创公司工作，我能在 LLM 领域达到多大的深度，可能只有快速工程和微调技术？在这些初创公司工作是否会让我在直接申请这些大型模型公司（Meta、Google、Open AI 等）的 LLM 职位时更有竞争力？ 我想在 LLM 领域获得更多知识，但我不知道在只使用带有 API 调用的 LLM 模型的公司工作是否是一个好的起点。任何建议都值得赞赏！    提交人    /u/Upbeat-Carrot1999   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehudwq/d_is_it_worth_working_at_startups_focusing_on_llm/</guid>
      <pubDate>Thu, 01 Aug 2024 22:55:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于随机内容生成的 Transformer 采样技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehrw4r/d_transformer_sampling_techniques_for_random/</link>
      <description><![CDATA[我正在做一个项目，在这个项目中，给定一个（相对较小的）转换器，我们希望能够生成独特的句子。也就是说，没有输入提示或任何条件。从 0 个 token 开始，我们希望能够生成新颖的句子。 我遇到的问题是，当我们使用传统的采样技术（例如 TopK/TopP）时，它往往会“崩溃”在一些想法上。由于前几个 token 可能只会落入少数几个最佳可能性中，这往往会限制剩余生成的新颖性。 关于如何处理这个问题有什么建议吗？我们正在研究模型训练技术 + 数据处理方面的其他选择，但我认为在采样方面可能会有一些“速胜”。    提交人    /u/leoholt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehrw4r/d_transformer_sampling_techniques_for_random/</guid>
      <pubDate>Thu, 01 Aug 2024 21:08:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 长序列模型对长序列的建模效果如何？比较架构归纳偏差对长语境能力的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehej2y/r_how_well_can_a_long_sequence_model_model_long/</link>
      <description><![CDATA[      TL;DR 小语言模型举步维艰无论架构如何，都可以处理长上下文。 论文： https://arxiv.org/pdf/2407.08112 摘要：  长序列在现实世界场景中大量出现，因此正确建模它们会打开许多​​下游用例。然而，深度神经网络经常因为各种原因而难以处理这些问题。系统工程和模型设计方面的最新进展使得模型的扩展成为可能，这些模型据称可以支持扩展的上下文长度。特别是，状态空间和线性递归神经网络模型系列理论上可以延伸到无限的序列长度。然而，这是否好得令人难以置信？我们进行了评估，以表明虽然这种说法在理论上可能是合理的，但仍然存在经验观察到的巨大实际差距。具体而言，循环模型在与具有注意机制的长上下文 LLM 相同的设置下仍然会受到影响。我们进一步表明，不同的归纳偏差具有不一致的外推能力，这凸显了进一步研究此类范式的必要性，并调查为什么长上下文模型似乎无法按照预期的方式运行。  实证结果： M2A = Mamba2Attn，TPP = Transformer++，RG &amp; RG-IT = Recurrent Gemma（/指令调整），SL &amp; SL-IT= ShearedLLaMa（/指令调整）。每个模型有2.7B到3B个参数。 https://preview.redd.it/d9pth8skg1gd1.png?width=759&amp;format=png&amp;auto=webp&amp;s=3df65d368ec3f0fbec93a866bb42cb6f83227c5b https://preview.redd.it/djez9l6ph1gd1.png?width=923&amp;format=png&amp;auto=webp&amp;s=c7a7e12f7c42bfba23372de379b63036c4db9800 https://preview.redd.it/fveuwywph1gd1.png?width=927&amp;format=png&amp;auto=webp&amp;s=1e0e7fa1c03099c09bccd4bed164f8bea13d5807 编辑：修复格式，添加模型尺寸信息。    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehej2y/r_how_well_can_a_long_sequence_model_model_long/</guid>
      <pubDate>Thu, 01 Aug 2024 11:41:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何正确对 DTLN（双信号变换 LSTM 网络）进行 TFLite 完全整数量化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehe9or/d_how_to_correctly_do_tflite_fully_integer/</link>
      <description><![CDATA[      我试图像 breizhn/DTLN 一样进行 TFLite 训练后量化练习。 作者进行了默认量化（float32）并将其分为 TFlite 模型的 2 个阶段，因为 TF2.3 不能很好地支持复值。 然后我尝试使用 TF2.15 并从“DTLN/pretrained_model/dtln_saved_model”加载他保存的模型并尝试进行全整数量化。错误显示如下，我不确定如何修复。 3 个节点已委托，需要 Flex ops 吗？ 在寻求帮助的过程中，我发现有人做了这项工作并分享了 https://github.com/nyadla-sys 、TFLite 模型。 模型图更加简洁与原始的 2 阶段 TFLite 模型进行比较，而作者 nyadla-sys 没有谈论如何做到这一点或分享 python 脚本。 我想知道他是怎么做到的，我不确定这项工作是否需要其他技能，因为我只知道基本的转换步骤。 希望有人可以在这里帮忙，谢谢。    提交人    /u/Ok_Box_6059   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehe9or/d_how_to_correctly_do_tflite_fully_integer/</guid>
      <pubDate>Thu, 01 Aug 2024 11:26:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习论坛</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eh8d35/d_forum_for_machine_learning/</link>
      <description><![CDATA[大家好， 我想知道是否有一个论坛或在线社区（当然除了这个 subreddit 之外），人们可以在那里讨论机器学习、分享他们的观点/资源等。我一直没能找到，我觉得我们应该有类似的东西。类似老式论坛页面风格的东西。或者它在 2024 年不再是一个流行的平台了？ 你怎么看？    提交人    /u/satori_paper   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eh8d35/d_forum_for_machine_learning/</guid>
      <pubDate>Thu, 01 Aug 2024 04:58:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 还有人觉得 LLM 没什么意思吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eh4llh/d_llms_arent_interesting_anyone_else/</link>
      <description><![CDATA[我不是 ML 研究员。当我想到很酷的 ML 研究时，我想到的是 OpenAI Five 或 AlphaFold 之类的东西。如今，人们热议的是 LLM 和扩展转换器，虽然该领域确实有一些研究和优化要做，但它对我来说并不像其他领域那么有趣。对我来说，ML 的有趣部分是为您的用例端到端训练模型，但如今的 SOTA LLM 可以用于处理许多用例。好的数据 + 大量的计算 = 不错的模型。就这样？ 如果我可以用一小部分计算来训练这些模型，我可能会更感兴趣，但这样做是不合理的。那些没有计算能力的人只能进行微调或快速工程，而我内心的 SWE 发现这很无聊。这个领域的大多数人真的把精力投入到下一个标记预测器中了吗？ 显然，LLM 具有颠覆性，并且已经发生了很大的变化，但从研究的角度来看，它们对我来说并不有趣。还有人有这种感觉吗？对于那些因为与 LLM 无关的东西而被该领域吸引的人，你对此有何感想？你是否希望 LLM 的炒作会逐渐消退，以便焦点可以转移到其他研究上？那些在当前趋势之外进行研究的人：你如何处理所有的噪音？    提交人    /u/leetcodeoverlord   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eh4llh/d_llms_arent_interesting_anyone_else/</guid>
      <pubDate>Thu, 01 Aug 2024 01:40:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] Google 的 Gemma-2-2B 与 Microsoft Phi-3：医疗保健领域小型语言模型的比较分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eh3clp/d_googles_gemma22b_vs_microsoft_phi3_a/</link>
      <description><![CDATA[      探索 Google 的 Gemma-2-2b-it 和 Microsoft 的 Phi-3-4k 模型在医疗领域的表现。 （未经微调） Google 的 Gemma-2-2b-it 平均表现出色，得分为 59.21%，而 Microsoft 的 Phi-3-4k 以 68.93% 领先。 将很快为医疗领域评估更多小型模型 源帖子 https://preview.redd.it/lfh5gvm44zfd1.png?width=2779&amp;format=png&amp;auto=webp&amp;s=901da925caa150ba7a1ca31bf28f9cd5824280a0    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eh3clp/d_googles_gemma22b_vs_microsoft_phi3_a/</guid>
      <pubDate>Thu, 01 Aug 2024 00:40:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 无限上下文长度真的可能吗？：“Unlimiformer”作者周五讨论 NeurIPS 论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egqitt/d_is_unlimited_context_length_really_possible/</link>
      <description><![CDATA[无限上下文长度真的可能吗？代价是什么？ 2023 年 NeurIPS 论文 Unlimiformer 的作者 Amanda Bertsch 将在本周五的 Oxen.ai 论文俱乐部中描述该架构并回答问题。 Oxen 首席执行官兼 Plain Speak 大师 Greg Schoeninger u/FallMindless3563 将帮助解释该概念并将其与我们审查过的其他论文联系起来。 电话：https://oxen.ai/community 声称使无限上下文长度成为可能的技巧：将交叉注意力计算卸载到 K-最近邻 (K-NN) 索引上。 我在推特上发布了某人的巧妙动画K-NN 在这里：https://x.com/ParallaxAngle/status/1817672116243972287 论文：https://arxiv.org/abs/2305.01625 Greg，我将用我的前 5 个问题来回答。到目前为止，我只阅读了摘要。    提交人    /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egqitt/d_is_unlimited_context_length_really_possible/</guid>
      <pubDate>Wed, 31 Jul 2024 15:47:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jul 2024 15:00:14 GMT</pubDate>
    </item>
    </channel>
</rss>