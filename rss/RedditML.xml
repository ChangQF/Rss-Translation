<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 03 Dec 2023 06:16:20 GMT</lastBuildDate>
    <item>
      <title>[D] 我如何在没有任何研究组织隶属关系的情况下在 NeurIPS 等场所发表文章？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189m3y1/d_how_do_i_publish_in_venues_like_neurips_without/</link>
      <description><![CDATA[我作为深度学习工程师在该行业全职工作，致力于 PyTorch 框架级硬件支持（想想计算内核）。我的团队中没有人发表任何东西，我们大多只是编程。  我正在寻找关于像我这样的人如何开始研究并在 NeurIPS 等场所发表的建议或想法？ 非来自任何研究附属实验室、知名教授或知名资金来源的志愿研究论文会被这些场所接受吗？  我正在寻找想法关于像我这样来自该行业的人如何获得进入研究和发表的机会。由于我的年龄和其他责任，参加博士学位课程对我来说不是一个选择。我只想为了智力上的乐趣而进行研究。 我拥有深厚的计算机科学背景（很久以前就获得了硕士学位，并在安全领域发表过一些文章），并且熟悉机器/深度学习的进展。通过大量的阅读和努力，我可以阅读并理解这些顶级机构接受的许多论文。 非常感谢！ ​ &amp;# x200b;   由   提交/u/gobraming5  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189m3y1/d_how_do_i_publish_in_venues_like_neurips_without/</guid>
      <pubDate>Sun, 03 Dec 2023 05:00:53 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从头开始​​的扩散模型 | DDPM PyTorch 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189lqlh/p_diffusion_models_from_scratch_ddpm_pytorch/</link>
      <description><![CDATA[       由   提交/u/tusharkumar91   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189lqlh/p_diffusion_models_from_scratch_ddpm_pytorch/</guid>
      <pubDate>Sun, 03 Dec 2023 04:38:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] 向银行学习并吸引银行的项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189lo2n/p_project_to_learn_with_and_attract_banks/</link>
      <description><![CDATA[我是一名系统工程专业的学生，​​我简历上的项目之一是一个不用库构建的神经网络（使用线性代数）。我这样做是因为我想了解正在发生的事情，而不仅仅是遵循教程并将一些 pytorch 功能组合在一起。 现在随着圣诞节假期的临​​近，我想探索 AI/ML，而且我特别喜欢被它与银行业的交叉所吸引。刚刚在多伦多完成了高盛的 OA，它更加坚定了我对金融工作的渴望。 话虽这么说，我应该阅读/使用哪些资源，或者我应该构建可以扩展的潜在项目复杂性，既能帮助我学到很多东西，又能在简历上对银行有吸引力。我可以随心所欲地制作一些简单或复杂的东西，并且可以教会我很多东西。最重要的是，我应该通过什么资源/方法来学习。万分感谢。干杯。   由   提交/u/Traditional_Sea6160   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189lo2n/p_project_to_learn_with_and_attract_banks/</guid>
      <pubDate>Sun, 03 Dec 2023 04:34:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有什么方法可以提高我提议的 RTX 3080 eGPU 设置的效率（每美元的性能）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189k6kz/d_any_way_to_increase_efficiency_of_my_proposed/</link>
      <description><![CDATA[我花 300 美元买到了 RTX 3080 12GB。 （这不是为了游戏，而是为了机器学习。） 我有一台带有开放 TB4 端口的 Dell Vostro 7620 笔记本电脑（i7 12700H、40GB DDR5、RTX 3050 4GB dGPU）。 我正在以约 110 美元的价格购买 TH3P4G3，以约 95 美元的价格购买 XPG Core Reactor 750 Gold。 有什么我缺少的东西，或者有什么方法可以更有效地花钱（每美元的性能）花费）？    由   提交 /u/SMtheEIT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189k6kz/d_any_way_to_increase_efficiency_of_my_proposed/</guid>
      <pubDate>Sun, 03 Dec 2023 03:14:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 随机变分 GP，拟合问题。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189e20k/d_stochastic_variational_gp_fitting_troubles/</link>
      <description><![CDATA[我正在使用 gpytorch 开发随机变分 GP。 我正在对从 n 个人收集的数据执行 CV。 &gt; 当我研究模型拟合时，经过训练和预测的 GP 的预测以数据平均值为中心。因此，不适合更极端的值。  什么，模型架构方面可能会导致这种情况，什么可能有帮助？ 我尝试过长度比例调整，但收效甚微...... 我有建立了一个optuna研究来优化下面的超参数，但没有成功。 • ⁠内核• ⁠似然性• ⁠变分策略• ⁠变分分布• ⁠学习率• ⁠均值—&gt; （常数或零） • ⁠num 诱导点   由   提交/u/ConfusedLayer1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189e20k/d_stochastic_variational_gp_fitting_troubles/</guid>
      <pubDate>Sat, 02 Dec 2023 21:50:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] PCA 和使用无监督机器学习进行欺诈检测？有没有办法评估无监督模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189dh21/p_pca_and_the_use_of_unsupervised_machine/</link>
      <description><![CDATA[我希望我的问题听起来不太愚蠢，但我是数据科学的新手，目前正在尝试更深入地研究欺诈分析，我&#39;我非常非常困惑。 我正在做这个项目，我获得了在线交易的原始数据集，并被告知用我自己的术语定义正常和异常行为。  据我了解，用于欺诈检测的常见评估指标包括精确率、召回率、F1 分数、ROC 曲线或混淆矩阵。但如果没有历史/标记数据，我就无法获得真/假阳性-阴性？ 我在谷歌上搜索了“无监督评估指标”它显示了 Silhoutte Score，我已经用它来确定隔离森林模型中的污染水平，但这基本上不是只是模型调整/选择异常阈值的最佳参数吗？ 或者可以吗？不评估模型？或者我应该将它与其他无监督模型进行比较，并选择最好的模型来替代混淆矩阵等模型评估？  另外，对于 PCA 加载，我需要做/解释什么吗？我已经从解释的方差比中获得了组件/重要特征的最佳数量，它直接将记录标记为欺诈 (1) 或正常 (0)。  结果为正常（1113 条记录）和欺诈（10 条记录），这对于欺诈检测来说是常见的还是需要解决/重新采样/更改的类不平衡情况？   由   提交 /u/DecentPerson011   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189dh21/p_pca_and_the_use_of_unsupervised_machine/</guid>
      <pubDate>Sat, 02 Dec 2023 21:21:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] USearch HNSW 的大规模实施速度比 FAISS 快 10 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1896uhy/p_usearch_hnsw_implementation_is_10x_faster_than/</link>
      <description><![CDATA[ 由   提交/u/ashvar  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1896uhy/p_usearch_hnsw_implementation_is_10x_faster_than/</guid>
      <pubDate>Sat, 02 Dec 2023 16:06:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 让我们调试您的神经网络：NN 的基于梯度的符号执行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1896rze/p_lets_debug_your_neural_network_gradientbased/</link>
      <description><![CDATA[我开发了 Gymbo，一个概念证明用于从头开始实现的基于梯度的符号执行引擎。  符号是一种用于分析程序并识别触发每个程序部分执行的输入的方法。它在调试神经网络的行为时效果很好。例如，Gymbo 可以让您轻松找到对抗性示例。有趣的是，基于逻辑的方法可以有效地分析神经网络。 Gymbo 还提供与 sklearn 和 PyTorch 兼容的易于使用的 Python API。 我很期待收到您的反馈！   由   提交/u/Living_Impression_37   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1896rze/p_lets_debug_your_neural_network_gradientbased/</guid>
      <pubDate>Sat, 02 Dec 2023 16:03:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么交叉熵随着准确度的增加而增加？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1895m5k/d_why_is_crossentropy_increasing_with_accuracy/</link>
      <description><![CDATA[      我正在实现 softmax 回归，并且我正在努力理解交叉熵值增加问题背后的本质[1]，以及准确性的增加（在“iris”数据集上）： https://preview.redd.it/eo3654zwbw3c1.png?width=688&amp;format = png&amp;auto=webp&amp;s=52916d56029e6e8aa1e9594bbcb02c7075009206 这对我来说非常令人困惑，因为没有类不平衡： https://preview.redd.it/rqs7i6jybw3c1.png?width=389&amp;format=png&amp;自动= webp&amp;s=6ca668f1cc70aae7a125a6b9c48c511eadc6d562 我不完全确定 N = 112 的样本大小是否有问题。我将不胜感激任何有关此事的帮助。提前谢谢您。 ​ [1]   由   提交 /u/joshjson   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1895m5k/d_why_is_crossentropy_increasing_with_accuracy/</guid>
      <pubDate>Sat, 02 Dec 2023 15:05:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformers 如何重写机器学习的古老传统规则</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1895ipi/d_how_transformers_rewrote_the_rules_of_an_age/</link>
      <description><![CDATA[      大家好！分享我的 ML YT 频道的最新视频，讨论 Transformer、它们的工作原理，以及与其他神经网络（如 CNN、RNN 等）相比，它与归纳偏差的有趣关系。分享一个链接给有兴趣的人看看！谢谢。   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1895ipi/d_how_transformers_rewrote_the_rules_of_an_age/</guid>
      <pubDate>Sat, 02 Dec 2023 15:01:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 惨痛的教训和思想之树 - 像 ToT 这样的技术是使用搜索的例子，还是它们通过编码类人学习而忽略了惨痛的教训？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1893ne2/d_bitter_lesson_and_tree_of_thoughts_are/</link>
      <description><![CDATA[惨痛的教训表明，学习和搜索是获胜策略，因为它们随着计算能力的扩展而扩展，并且通常会优于依赖于编码人类知识的技术。&lt; /p&gt; 鉴于此，您对 ToT 和类似技术有何看法？它们是通过搜索扩展模型能力的好例子，还是试图强制我们认为是类人行为的例子？ ​ 仅供参考，我在研究中看到了两种主要的基于树的方法。一种是基于MCTS的解码。这似乎更符合传统的搜索概念，因为您正在搜索可能文本的结果空间，然后选择最好的文本。 meta 使用 PPO 值函数作为 MCTS 节点评估器的论文 使用MCTS来提高编写成功程序的能力 ​ 但是，还使用了更抽象的CoT/ToT风格的树，这依赖模型为给定序列生成后续序列树。 思想树：故意问题使用大型语言模型求解 这里的一个核心区别是树并不像 MCTS 解码树搜索那样表示对可能输出的搜索。这是对可能的推理链的搜索，这些推理链最终是某种评估方法（通常是模型本身）的输入，以确定最佳输出。因此，您不仅搜索结果空间，还搜索“证据空间”，这两者都将传递给评估器以选择适当的结果。  编辑：不相关，但原则上您可以结合这两种搜索技术，这会很酷，但可能非常昂贵。例如，对 ToT 中的每个节点使用 MCTS 解码。我还没有看到有人这样做，但如果有人有一篇论文的链接那就太酷了。   由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1893ne2/d_bitter_lesson_and_tree_of_thoughts_are/</guid>
      <pubDate>Sat, 02 Dec 2023 13:23:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 让为您的 ML 模型创建 FastAPI 后端变得非常容易！想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18933bh/p_made_it_really_easy_to_create_a_fastapi_backend/</link>
      <description><![CDATA[嘿伙计们！我想分享我最近制作的这个工具，https://visual-backend.com，它可以让你为你的 ML 构建 FastAPI 后端模型真的很快。它本质上是一个 GUI，可让您生成代码和代码。端点处理程序的脚手架、身份验证，甚至只需一键即可部署到 GCP。因此，要为您的 ML 模型提供服务，您所需要做的就是加载它并在每个端点处理程序处调用推理函数。当然，对于批处理或作业队列之类的东西，没有这样的功能，但只是想知道在基础级别上，这样的工具是否对你们有用！ I最初是为全栈开发人员构建的，但在与几位 ML 工程师/数据科学家交谈后，我意识到这可能对那些希望快速将 ML 模型投入生产而不用太关心的人有所帮助。基础设施/软件工程，所以我很想听听您是否觉得这有帮助以及您可能有的其他想法。期待它:)   由   提交 /u/johnyeocx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18933bh/p_made_it_really_easy_to_create_a_fastapi_backend/</guid>
      <pubDate>Sat, 02 Dec 2023 12:51:36 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何追踪最近​​的热门论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1890zpi/dhow_do_i_track_recent_trending_papers/</link>
      <description><![CDATA[由于papers.labml.ai离线，如何处理你们跟踪最近的热门论文或热门话题吗，尤其是 X 方面的。有什么推荐吗？   由   提交 /u/Historical-Tree9132    reddit.com/r/MachineLearning/comments/1890zpi/dhow_do_i_track_recent_trending_papers/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1890zpi/dhow_do_i_track_recent_trending_papers/</guid>
      <pubDate>Sat, 02 Dec 2023 10:32:08 GMT</pubDate>
    </item>
    <item>
      <title>[D]深入研究 Google Brain 团队的 Vision Transformer (ViT) 论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/188pe7u/deep_dive_into_the_vision_transformer_vit_paper/</link>
      <description><![CDATA[我们每周五都有一个名为 Arxiv Dives 的阅读俱乐部，在那里我们回顾当今机器学习中使用的许多最先进技术的基础知识。上周我们深入探讨了“视觉变形金刚” 2021 年的论文，其中 Google Brain 团队针对 ResNets 进行了大规模 Transformer 训练基准测试。 虽然截至本周这还不是开创性的研究，但我认为随着人工智能的发展步伐，深入研究过去的工作非常重要以及其他人的尝试！退后一步回顾基础知识并跟上最新和最好的知识是件好事。 如果有人觉得有帮助，请在此处发布注释并回顾一​​下： https://blog.oxen.ai/arxiv-dives-vision-transformers-vit/&lt; /p&gt; 也希望有人能加入我们周五的直播！我们有一个由 300 多名工程师和研究人员组成的非常稳定且有趣的团队。   由   提交 /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/188pe7u/deep_dive_into_the_vision_transformer_vit_paper/</guid>
      <pubDate>Fri, 01 Dec 2023 23:16:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>