<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 20 Jan 2025 09:18:07 GMT</lastBuildDate>
    <item>
      <title>[R] 培养更深层次的法学硕士思维</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5i073/r_evolving_deeper_llm_thinking/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5i073/r_evolving_deeper_llm_thinking/</guid>
      <pubDate>Mon, 20 Jan 2025 04:23:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找根据真实文档和查询构建的检索数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5h6n6/r_looking_for_retrieval_datasets_built_from_real/</link>
      <description><![CDATA[以 (query, passage) 对的形式进行检索，其中 passage 是与 query 相关的文档中的一段文本。 BeIR 有很好的数据集，但“文档”通常很宽泛，例如任何 Wikipedia 或 PubMed 文章。我正在寻找一个文档更集中的数据集，比如 scikit-learn 的文档。 StaRD 是一个高质量的数据集，但对于我的目的来说，它没有足够的查询。理想情况下，有 ≥5k 个唯一查询。    提交人    /u/KD_A   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5h6n6/r_looking_for_retrieval_datasets_built_from_real/</guid>
      <pubDate>Mon, 20 Jan 2025 03:37:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找具有自定义列视图的 NLP 注释工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5dizh/d_looking_for_nlp_annotation_tool_with_custom/</link>
      <description><![CDATA[大家好！我正在开展一个需要 NLP 数据注释的文档修订项目。我需要一个可以做到以下事情的工具：  在标准表格视图中显示数据集 在自定义列中显示源文本和修订文本之间的 git 样式差异  我已经尝试过 Argilla 和 Label Studio，但它们都不支持自定义列。有人知道提供此功能的注释工具吗？ 提前致谢！    提交人    /u/V0dros   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5dizh/d_looking_for_nlp_annotation_tool_with_custom/</guid>
      <pubDate>Mon, 20 Jan 2025 00:24:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 开放模式的案例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i5azv1/d_the_case_for_open_models/</link>
      <description><![CDATA[      为什么开放性对人工智能如此重要    由    /u/Amgadoz 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i5azv1/d_the_case_for_open_models/</guid>
      <pubDate>Sun, 19 Jan 2025 22:27:21 GMT</pubDate>
    </item>
    <item>
      <title>有没有什么礼物可以送给 ML 爱好者？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i58qk2/any_gift_ideas_for_someone_into_ml_d/</link>
      <description><![CDATA[大家好，我需要帮助，想为真正热衷于机器学习和相关领域并正在从事研究/职业的人准备一份特别的礼物。  我对机器学习知之甚少，但我仍然想为他们买一些非常酷或对他们的工作很实用的东西。从为他们买一台专门用于工作的新电脑到一些很酷的收藏品，什么都可以。任何包括为我指明正确方向的东西都会很感激，谢谢！    提交人    /u/Usernam3ChecksOuts   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i58qk2/any_gift_ideas_for_someone_into_ml_d/</guid>
      <pubDate>Sun, 19 Jan 2025 20:53:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2024 年值得关注的 LLM 研究论文（第二部分）：7 月至 12 月</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i51cks/p_noteworthy_llm_research_papers_of_2024_part_two/</link>
      <description><![CDATA[        由    /u/seraschka 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i51cks/p_noteworthy_llm_research_papers_of_2024_part_two/</guid>
      <pubDate>Sun, 19 Jan 2025 15:46:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 MLP 进行语音识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4rz3r/p_speech_recognition_using_mlp/</link>
      <description><![CDATA[所以我们有这个任务，我们必须对音频文件中所说的单词进行分类。我们只能使用频谱图作为输入，并且只能使用简单的 MLP，没有 cnn。输入特征约为 16k，宽度限制为 512，深度为 100，我们选择任何激活函数。我们尝试了很多架构，有 2 或 3 层，有和没有 dropout，有和没有 batch normal，但我们能找到的最佳 val 准确率是 47%，有 2 层 512 和 256，没有 dropout，没有 batch normal 和 SELU 激活函数。我们需要 80+ 才能保存任何值。有人可以建议一个不会过度拟合的好架构吗？    提交人    /u/Dariya-Ghoda   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4rz3r/p_speech_recognition_using_mlp/</guid>
      <pubDate>Sun, 19 Jan 2025 06:06:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 19 Jan 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 张量和完全分片数据并行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4n01i/r_tensor_and_fully_sharded_data_parallelism/</link>
      <description><![CDATA[在本系列中，我们将继续探索分布式训练算法，重点关注张量并行 (TP)，它将层计算分布在多个 GPU 上，以及完全分片数据并行 (FSDP)，它将模型参数、梯度和优化器状态分片以优化内存使用。今天，这些策略是大规模模型训练不可或缺的一部分，我们将研究它们在扩展到具有 1 万亿个参数的模型时所表现出的属性。 https://martynassubonis.substack.com/p/tensor-and-fully-sharded-data-parallelism    提交人    /u/Martynoas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4n01i/r_tensor_and_fully_sharded_data_parallelism/</guid>
      <pubDate>Sun, 19 Jan 2025 01:36:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于博士级 ML 重点编程课程的主题有什么建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4ltt6/d_suggestions_for_topics_for_a_phd_level_ml/</link>
      <description><![CDATA[一些背景：我在一家小型初创公司担任数据科学家/ML 工程师。我还在获得博士学位（统计学）的部门兼职。 在过去的几年里，我一直在为硕士生和早期博士生教授一系列统计编程课程。这个学期，我的课程不幸被取消了，因为报名人数少，我被告知这是由于去年秋天招聘不力和广告宣传不佳。我们正考虑每隔一年开设这门课程。我想提议在该系列中开设第三门课程，其中包含更高级的主题。 第一门课程：R 和 Python 的编程基础。每个课程都有一些基本的分析内容。 第二门课程：基于 Python 的分析课程（已经有很多 R 课程），涉及从基础到混合建模和贝叶斯分析的统计例程。此外，我们还将使用 PyTorch 以及一些基于转换器的应用程序来研究经典模型。还可以研究一些可解释的 AI 技术  第三门课程：优化、变分推理、其他贝叶斯深度学习方法、MLops 概念、???? 问题是我需要研究大量随机方法，因为毕竟这是一个统计部门。  希望这很清楚。我想提供相关信息，特别是向那些希望走在最前沿的博士生，重点是实验和实施。我知道有很多东西可以做，但在工作中我需要专注于我的具体任务。 非常感谢您的建议！    提交人    /u/Annual-Minute-9391   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4ltt6/d_suggestions_for_topics_for_a_phd_level_ml/</guid>
      <pubDate>Sun, 19 Jan 2025 00:37:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 重构用于生产的笔记本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4ho23/d_refactoring_notebooks_for_prod/</link>
      <description><![CDATA[我在 Jupyter 笔记本中做了很多实验，对于大多数项目，我最终都会有多个笔记本：一个用于 EDA，一个用于数据转换，还有几个用于不同的实验。这个工作流程在将模型投入生产之前一直很好用。 那时我必须从我的笔记本中取出所有代码并重构以进行生产。这有时可能需要数周时间。感觉我在重复努力并失去动力。 我是否错过了什么可以使我的生活更轻松的东西？或者这也是你们都遇到的问题？ *不是 nbdev 的忠实粉丝，因为它预设了一个特定的结构    提交人    /u/Wise_Panda_7259   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4ho23/d_refactoring_notebooks_for_prod/</guid>
      <pubDate>Sat, 18 Jan 2025 21:18:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] VortexNet：通过流体动力学进行神经计算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4fvqn/r_vortexnet_neural_computing_through_fluid/</link>
      <description><![CDATA[  由    /u/samim23  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4fvqn/r_vortexnet_neural_computing_through_fluid/</guid>
      <pubDate>Sat, 18 Jan 2025 19:56:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] 因果推理遇上深度学习：综合综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i455gs/r_causal_inference_meets_deep_learning_a/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i455gs/r_causal_inference_meets_deep_learning_a/</guid>
      <pubDate>Sat, 18 Jan 2025 10:54:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我讨厌softmax</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i44h5v/d_i_hate_softmax/</link>
      <description><![CDATA[这是一个半开玩笑的说法，核心概念相当简单，但我相信社区会引用大量证据来支持和驳斥 softmax 很烂的说法，并真正使其成为一场严肃而有趣的讨论。 什么是 softmax？它是应用元素指数函数并通过激活总和进行归一化的操作。它直观地做了什么？一点是输出总和为 1。另一点是，相对较大的输出相对于较小的输出变得更大：大激活和小激活被分开。 一个问题是，如果输入是有限的，您永远不会得到零输出（例如，如果没有掩码，您就不能将 0 注意力归因于某些元素）。让我抓狂的是，对于大多数应用，幅度和幅度比率是有意义的，但在 softmax 中它们不是：softmax 关心差异。以 softmax([0.1, 0.9]) 和 softmax([1,9]) 或 softmax([1000.1,1000.9]) 为例。您认为哪个相等？在哪些应用中这是更自然的方式？ 数值不稳定性、奇怪的梯度、嵌入规范都是受此类简单核心影响的事物。当然，与此同时，softmax 是深度学习的主力之一，它做得相当不错。 还有其他人也这么讨厌我吗？有人热衷于在我眼中挽回 softmax 吗？    提交人    /u/Sad-Razzmatazz-5188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i44h5v/d_i_hate_softmax/</guid>
      <pubDate>Sat, 18 Jan 2025 10:05:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>