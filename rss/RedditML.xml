<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 29 May 2024 09:16:37 GMT</lastBuildDate>
    <item>
      <title>[R] 使用大型语言模型进行工具学习：一项调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d37emc/r_tool_learning_with_large_language_models_a/</link>
      <description><![CDATA[      PDF：https://arxiv.org/abs/2405.17935 GitHub：https://github.com/quchangle1/LLM-Tool-Survey 摘要：最近，使用大型语言模型 (LLM) 的工具学习已成为增强 LLM 解决高度复杂问题能力的一种有前途的范例。尽管该领域受到越来越多的关注和快速发展，但现有文献仍然零散且缺乏系统组织，为新手设置了进入门槛。这一差距促使我们对现有的使用 LLM 的工具学习的著作进行全面调查。在本次调查中，我们重点从两个主要方面回顾现有文献 (1) 工具学习为何有益以及 (2) 工具学习如何实施，从而全面了解使用 LLM 的工具学习。我们首先通过从六个具体方面回顾工具集成的好处和工具学习范式的固有好处来探索“为什么”。在“如何”方面，我们根据工具学习工作流程中的四个关键阶段的分类法系统地回顾了文献：任务规划、工具选择、工具调用和响应生成。此外，我们还提供了现有基准和评估方法的详细摘要，并根据它们与不同阶段的相关性对其进行了分类。最后，我们讨论了当前的挑战并概述了未来的潜在方向，旨在激励研究人员和工业开发人员进一步探索这一新兴且充满希望的领域。 https://preview.redd.it/t46d2cxivb3d1.jpg?width=1250&amp;format=pjpg&amp;auto=webp&amp;s=a3d3bd9f285717b6a6f9c9d0015789ec39f9abd9 https://preview.redd.it/rp0gdkkjvb3d1.png?width=830&amp;format=png&amp;auto=webp&amp;s=2e87a52ccf7637783f308fd6b421d8b2fa0cbee0 https://preview.redd.it/fwwyuq3kvb3d1.jpg?width=914&amp;format=pjpg&amp;auto=webp&amp;s=39f080e0db7c611f418b53e99aa274a2d7ad35b7    提交人    /u/Lumpy-Ad-2115   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d37emc/r_tool_learning_with_large_language_models_a/</guid>
      <pubDate>Wed, 29 May 2024 08:41:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据科学家无需数据即可完成任务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d374hh/d_data_scientist_does_the_task_without_data/</link>
      <description><![CDATA[最近我被分配了一个任务，根据用户交互活动构建一个用户购买评分系统。 然而，有趣的是，我没有关于用户与产品交互的数据，所以我调查了许多方的解决方案，并使用我的假设来创建我认为适合构建预测模型的特征。当然，当我将它呈现给经理时，结果非常糟糕。我坐下来和他讨论创建模型时所需的特征定义，让我非常生气的是，他仍然不知道构建评分模型需要什么样的数据。人们将如何处理这种情况？    提交人    /u/unknow_from_vietnam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d374hh/d_data_scientist_does_the_task_without_data/</guid>
      <pubDate>Wed, 29 May 2024 08:21:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于现阶段的法学硕士来说，幻觉不是比安全更重要的研究吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d329nt/d_isnt_hallucination_a_much_more_important_study/</link>
      <description><![CDATA[为什么我觉得 LLM 更强调安全性而不是幻觉？ 在现阶段，确保生成准确的信息不是最优先的吗？ 为什么在我看来并非如此    提交人    /u/xiikjuy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d329nt/d_isnt_hallucination_a_much_more_important_study/</guid>
      <pubDate>Wed, 29 May 2024 03:06:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] KNN 中 k=1</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2xrb8/d_k1_in_knn/</link>
      <description><![CDATA[晚上好，我在平衡的测试集上训练了 knn 算法，然后在不平衡的测试集上对其进行了测试；我得到 k=1 作为准确度方面的最佳参数，并使用交叉验证确认了这一结果。有这个值奇怪吗？    提交人    /u/Nice-Fisherman-1269   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2xrb8/d_k1_in_knn/</guid>
      <pubDate>Tue, 28 May 2024 23:21:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 石油和水？人工智能在科学领域内和跨科学领域的传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2x46v/r_oil_water_diffusion_of_ai_within_and_across/</link>
      <description><![CDATA[在此处阅读论文：https://arxiv.org/abs/2405.15828 本研究通过研究 1985 年至 2022 年人工智能学术参与度的变化，实证研究了 20 个不同科学领域约 8000 万份研究出版物中人工智能 (AI) 日益普及的说法。我们观察到指数增长，所有领域的人工智能参与出版物数量增加了约十三倍 (13x)，这表明从小众到主流发生了巨大转变。此外，我们首次对各个领域内人工智能参与出版物在出版场所的分布情况进行了实证检验，结果显示人工智能在学科内的参与度不断扩大。虽然这种日益扩大的参与表明每个领域都朝着更大程度的学科融合迈进，但日益普及与人工智能参与研究和更传统的学科研究之间的语义紧张有关。通过对数千万个文档嵌入的分析，我们观察到领域内和领域之间的人工智能参与和非人工智能参与研究之间存在复杂的相互作用，这表明日益普及是一种油水现象——人工智能参与的工作正在各个领域蔓延，但与非人工智能参与的工作融合得并不好。    提交人    /u/learning_by_looking   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2x46v/r_oil_water_diffusion_of_ai_within_and_across/</guid>
      <pubDate>Tue, 28 May 2024 22:53:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 室内定位/SLAM 模块，BOM 价格约为 150 美元</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2ww0c/d_indoor_localizationslam_module_with_150_bom/</link>
      <description><![CDATA[向社区提出一个问题。我们正在考虑将一款室内定位/地图软件商业化，该软件的 BOM 约为 100-150 美元（一个基本 CPU 和一个鱼眼摄像头）。我们已经为我们的内部项目构建了它，但如果它有价值，我们想把它带到社区。这对我们来说仍然有点工作量，所以我们想知道它是否有意义。 它不需要基准点，可以在大型开放空间（大型仓库）中工作。 我们将开放所有代码的源代码，以便在需要时无需我们参与即可进行更改。商业用途需要商业许可。 我们还有经济高效的避障模块，我们也可以分享。如果您认为这有价值，请告诉我。    提交人    /u/carubia   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2ww0c/d_indoor_localizationslam_module_with_150_bom/</guid>
      <pubDate>Tue, 28 May 2024 22:43:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] Andrew Dudzik 谈深度学习中的 SOTA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2wc9a/d_andrew_dudzik_on_sota_in_deep_learning/</link>
      <description><![CDATA[Google DeepMind 的 Dudzik 最近表示，Transformers 实际上并不是 sota，而图神经网络才是真正的 sota：Andrew Dudzik - 深度学习数学中的三个问题 - YouTube 当然，前者在许多任务（NER、低资源语言的翻译等）中对 OOD 数据的处理并不那么好。但另一方面，并​​不是所有东西都适合知识图谱结构。只是开放这个讨论。大家同意吗？他们最近有没有读过更多关于图神经网络的有趣论文？    提交人    /u/Objective-Camel-3726   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2wc9a/d_andrew_dudzik_on_sota_in_deep_learning/</guid>
      <pubDate>Tue, 28 May 2024 22:19:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在生产中部署 SetFit 模型的最佳方式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2u14p/d_best_way_to_deploy_setfit_models_in_production/</link>
      <description><![CDATA[正如标题所述，我正在尝试在生产中部署 setfit 模型，并正在寻找一种有效的方法。我尝试使用 huggingface TEI，但不幸的是，它只输出向量，牺牲了分类头。你们有什么建议或我可以尝试的替代方法吗？谢谢！！    提交人    /u/ouzunkumhavuzu   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2u14p/d_best_way_to_deploy_setfit_models_in_production/</guid>
      <pubDate>Tue, 28 May 2024 20:43:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于“你只缓存一次：语言模型的解码器-解码器架构”的问题 - https://arxiv.org/pdf/2405.05254v1</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2ptil/d_question_about_you_only_cache_once/</link>
      <description><![CDATA[      这是我第一次尝试通读一篇论文。但是，我很难理解这一点，我认为你们会知道我的问题的答案，因为如图 1 所示，这种新架构对于 LLM 来说似乎是一件大事。 图 1 据我了解，主要思想是将网络分成两部分。前 L/2 层是自解码器层，可生成全局 KV 缓存。第二个 L/2 层是跨解码器层，重用了生成的全局 KV-Cache。 引用他们论文中关于他们如何节省大量计算和内存的内容（我理解这部分）：  具体来说，因为全局 KV 缓存被重用，而高效的自注意力需要常量缓存，所以缓存的数量为 O(N + CL)，其中 N 是输入长度，C 是常数（例如滑动窗口大小），L 是层数。对于长序列，CL 比 N 小得多，因此大约需要 O(N) 个缓存，即只缓存一次。相比之下，Transformer 解码器在推理过程中必须存储 N × L 个键和值。因此，与 Transformer 解码器相比，YOCO 大约节省了 L 倍的 GPU 缓存内存。  这是我不明白的。在仅解码器网络中，查询、键和值的概念的功能与数据库中的用法有些相似，但侧重于捕获单词之间的关系。在这种网络的每一层中，这些组件有助于细化对文本的理解，在处理从一层移动到下一层时根据新见解调整焦点。 每一层都通过更新查询、键和值来构建前一层，从而细化网络的解释和响应生成。 如果仅解码器网络的各个 KV 缓存的所有信息现在都被压缩到全局 KV 缓存中，我们是否不会丢失有价值的信息并且我们是否应该看到更差的性能？  此外，我们只有一半的层来细化这种解释，因为跨解码器层都重用相同的 KV 缓存。 图 2    提交人    /u/StraightChemistry629   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2ptil/d_question_about_you_only_cache_once/</guid>
      <pubDate>Tue, 28 May 2024 17:58:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] GT 深度估计：LiDAR 与立体深度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2pmr8/d_gt_for_depth_estimation_lidar_vs_stereo_depth/</link>
      <description><![CDATA[为什么大多数深度估计基准（如 nuScenes、KITTI、DDAD 等）都使用来自 LiDAR 传感器的地面真实深度，而不是来自 2 个摄像头的立体深度？ 将摄像头安装在汽车后视镜上会导致基线距离约为 2 米。这将实现更密集的深度测量，距离与 SOTA LiDAR 相似。我不明白为什么不经常使用它 - 还是我错过了什么？    提交人    /u/topsnek69   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2pmr8/d_gt_for_depth_estimation_lidar_vs_stereo_depth/</guid>
      <pubDate>Tue, 28 May 2024 17:50:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 防止夏令时期间时间序列预测中的数据泄漏</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2owkv/d_preventing_data_leakage_in_time_series/</link>
      <description><![CDATA[您好 /r/machinelearning， 我正在预测每天中午 12 点发布的值，其中包括第二天所有 24 小时的值。通常，我的方法涉及使用扩展窗口技术，即我使用截至今天（昨天发布）的所有可用数据进行训练，然后预测第二天的 24 小时值。 但是，夏令时调整期间会出现复杂情况。每年两次，数据会因夏令时（欧洲）而发生变化，导致一天有 23 或 25 小时。大多数时间序列库通过预测固定窗口大小来处理回测，但这种固定大小无法适应夏令时期间的小时变化，从而导致潜在的数据泄漏。例如，在春季，模型会偏移一个小时，纳入预测时间后整整一天技术上发布的数据。 我看到了一些潜在的解决方案（在我看来，从最不受欢迎到最受欢迎）：  通过在过渡日添加或删除一个小时来操纵数据。这可能涉及插入一个虚构的值或复制前一个小时。 开发一个自定义回测函数，可以适应不同的时间频率（天、周、月），而不是固定的整数大小窗口。 使用已经解决此问题的库。我似乎找不到已经实现此功能的流行库，所以如果您知道任何库，请告诉我！我特别难以找到适合此功能的 AutoML 库。  您对这些解决方案有何看法？是否有更简单的方法，还是我想太多了？欢迎提出所有建议！    由   提交  /u/NeuralGuesswork   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2owkv/d_preventing_data_leakage_in_time_series/</guid>
      <pubDate>Tue, 28 May 2024 17:21:13 GMT</pubDate>
    </item>
    <item>
      <title>[研究] Tangles：一种新的数学机器学习工具 - 新书发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2jf2q/research_tangles_a_new_mathematical_ml_tool_book/</link>
      <description><![CDATA[这是我刚刚出版的新书： 缠结：经验科学中人工智能的结构方法 Reinhard Diestel，剑桥大学出版社 2024 电子书，以及包括教程在内的开源软件，可从tangles-book.com获取。 注意：这是一本“外展”书，主要不是关于缠结理论，而是关于以多种意想不到的方式和领域应用缠结。我的《图论》第 5 版介绍了图中的缠结。 目录和数据科学家简介（第 1.2 章）可从 tangles-book.com/book/details/ 和 arXiv:2006.01830 获取。第 6 章和第 14 章介绍了一种基于缠结的软聚类新方法，与传统方法截然不同。第 7-9 章介绍了第 14 章所需的理论。 热烈欢迎在具体项目上进行合作，也欢迎为 GitHub 软件库做出贡献。 出版商的简介： 缠结提供了一种识别不精确数据中结构的精确方法。通过将经常一起出现的特质分组，它们不仅揭示了事物的集群，还揭示了事物特质的类型：政治观点、文本、健康状况或蛋白质的类型。缠结为人工智能提供了一种新的结构化方法，可以帮助我们理解、分类和预测复杂现象。 这可以通过最近对缠结数学理论的公理化来实现，这使得缠结的适用范围远远超出了图论的起源：从数据科学和机器学习中的聚类到预测经济学中的客户行为；从 DNA 测序和药物开发到文本和图像分析。 这是首次探讨此类应用。假设只有基本的本科数学，缠结理论及其潜在影响将向科学家、计算机科学家和社会科学家开放。    提交人    /u/RDiestel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2jf2q/research_tangles_a_new_mathematical_ml_tool_book/</guid>
      <pubDate>Tue, 28 May 2024 13:24:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 嵌入矩阵和最终的 pre-softmax 矩阵是否应该在 transformer 中共享？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2iurw/d_should_the_embedding_matrix_and_final/</link>
      <description><![CDATA[大家好， 在比较各种 LLM 时，我们可以看到，在采用 softmax 获得预测的 token 概率之前，其中一些 LLM 对 token 嵌入和转换矩阵使用相同的矩阵。我发现这篇 2016 年的论文使用输出嵌入改进语言模型表明这种方法更优越，注意力就是您所需要的论文也引用了它并进行了这种权重共享。GPT2 和 Gemma 等其他模型也是如此。 这让我想知道为什么 LLaMa 模型不进行这种权重共享。就模型容量而言，在那里使用单独的矩阵是否值得？像 Gemma 这样的模型是否必须使用权重共享，因为它们使用了庞大的词汇量？我对这里的权衡很感兴趣，如果有的话，目前对这个主题的共识是什么。    提交人    /u/CloudyCloud256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2iurw/d_should_the_embedding_matrix_and_final/</guid>
      <pubDate>Tue, 28 May 2024 12:58:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 泊松变分自动编码器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d2bhmw/r_poisson_variational_autoencoder/</link>
      <description><![CDATA[预印本：https://arxiv.org/abs/2405.14473 X 线程摘要：https://x.com/hadivafaii/status/1794467115510227442    提交人    /u/vafaii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d2bhmw/r_poisson_variational_autoencoder/</guid>
      <pubDate>Tue, 28 May 2024 04:56:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>