<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sun, 02 Jun 2024 06:19:50 GMT</lastBuildDate>
    <item>
      <title>[D] 师生培训策略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d65y1h/d_teacher_student_training_strategy/</link>
      <description><![CDATA[我计划使用 LLM（例如 llama3）通过提示提取训练数据，然后使用带有 CLS 令牌的较小模型进行自定义训练，以尝试匹配 LLM 的准确性。假设我可以在 1M+ 数据上运行提示（尽管我怀疑我不需要那么多）。 提示：以下句子包含苹果还是橘子：示例：  &quot;&lt;prompt&gt; 苹果，橘子&quot; -&gt; 苹果，橘子 &quot;&lt;prompt&gt; 苹果，橘子&quot; -&gt; 苹果，橘子 &quot;&lt;prompt&gt; 苹果，没有橘子&quot; -&gt;苹果  所以我的问题是：  我见过的最后一个 CLS 类型 LLM 是微软的 xtremedistil。这些模型还在使用吗？如果是，最新 + 最好的是什么？ 使用句子转换器并进行分类会更好吗？ 在我的学生模型训练集中，我将删除上面的提示，这种方法有风险吗？  在我看来，从长远来看，这些模型更小，成本也更低。非常感谢大家的普遍想法。    提交人    /u/themathstudent   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d65y1h/d_teacher_student_training_strategy/</guid>
      <pubDate>Sun, 02 Jun 2024 05:16:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您在现实世界中使用 LLM 的案例有哪些？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d65vj7/d_what_are_your_realworld_production_use_cases/</link>
      <description><![CDATA[我认为我们应该分享更多 LLM 的生产用例，而不仅仅是理论上的最佳实践。 您可以分享您在生产中看到/构建的用例吗？它应包括以下详细信息：  它解决的问题 实现细节（模型、基础设施等） 它产生的业务影响     提交人    /u/madredditscientist   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d65vj7/d_what_are_your_realworld_production_use_cases/</guid>
      <pubDate>Sun, 02 Jun 2024 05:12:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将 3 个数据集合并为一个唯一的数据集，并且知道这 3 个数据集与同一主题相关，这是一个好主意吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d65gdt/d_is_it_a_good_idea_to_combine_3_datasets_into/</link>
      <description><![CDATA[它们基本上是同一主题，具有相同的标签，唯一的区别是数据集本身。为了区分第一个数据集（将转变为其他三个数据集中的一个数据集）的图像，我将与我的研究同事一起从头开始创建另一个数据集。    提交人    /u/MessierKatr   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d65gdt/d_is_it_a_good_idea_to_combine_3_datasets_into/</guid>
      <pubDate>Sun, 02 Jun 2024 04:44:15 GMT</pubDate>
    </item>
    <item>
      <title>为开源模型实现“扩展单义性：从 Claude 3 Sonnet 中提取可解释的特征”论文。[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d64lx8/implementing_scaling_monosemanticity_extracting/</link>
      <description><![CDATA[我最近偶然发现了一篇有趣的论文，题为“扩展单义性：从 Claude 3 Sonnet 中提取可解释特征”，该论文探讨了如何使用稀疏自动编码器从大型语言模型的激活中提取可解释特征。该方法似乎有望深入了解模型的内部表示和行为。 这让我开始思考为开源语言模型实施类似的可解释性技术的可行性。我们能否在不进行大量微调的情况下控制 LLM 及其行为。 我想联系这个社区讨论一些事情：  是否有人已经在开源语言模型上实施或试验过类似的可解释性技术？我们可以制作类似于金门克劳德的东西吗？ 您认为调整和扩展这些技术以与 Llama、phi、mistral 等一起使用是否可行？与 sonnet 相比，它们的参数大小要小得多。 我有兴趣与其他对这个研究领域充满热情的人合作。如果您正在研究开源模型的可解释性或对新方法有想法，我很高兴与您合作并进一步探索。我们可以合作实施技术、共享资源或集思广益新想法。  如果您有兴趣合作或有任何想法要分享，请随时分享。    提交人    /u/No-Point1424   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d64lx8/implementing_scaling_monosemanticity_extracting/</guid>
      <pubDate>Sun, 02 Jun 2024 03:50:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] LAION 美学数据集的替代品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5y0oo/d_alternatives_to_the_laion_aesthetics_dataset/</link>
      <description><![CDATA[因此，LAION 数据集目前已关闭以进行安全审查。与此同时，是否有任何大型数据集可以代替其美学子集？我正在寻找“美学上令人愉悦”的图像，例如艺术品、绘画、漂亮的照片等。    提交人    /u/thehomelessman0   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5y0oo/d_alternatives_to_the_laion_aesthetics_dataset/</guid>
      <pubDate>Sat, 01 Jun 2024 22:00:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] CoPE：上下文位置编码：学习计算重要的事情</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5u95z/r_cope_contextual_position_encoding_learning_to/</link>
      <description><![CDATA[  由    /u/fasttosmile  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5u95z/r_cope_contextual_position_encoding_learning_to/</guid>
      <pubDate>Sat, 01 Jun 2024 19:05:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] Tensttorrent Galaxy Server 使用案例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5taip/d_tensttorrent_galaxy_server_usecases/</link>
      <description><![CDATA[大家好， 第一次发帖，请温柔一点 :) 我有机会以少量资金长期借用一台配备 32 个 wormhoole 处理器的 Tenstorrent Galaxy 服务器。 我们是一家拥有技术娴熟的工程师的小公司，但我们没有太多时间深入研究人工智能。我们做一些基本的事情，比如使用现成的模型和运行推理并进行一些轻度微调（主要是 YOLO），因为这不是我们的核心业务。然而，我个人的愿望是慢慢转向人工智能领域，所以我的问题是，如果你有类似的机会，你会接受它并将其用于什么？我知道这是一个广泛的问题，所以请自由发挥创意:) 在 github (https://github.com/tenstorrent/tt-buda-demos/tree/main/model\_demos) 上，他们已经有了模型演示列表，但这只是推理，没有看到提到微调或训练    提交人    /u/zakakanje   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5taip/d_tensttorrent_galaxy_server_usecases/</guid>
      <pubDate>Sat, 01 Jun 2024 18:21:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 超快 RAG：Langchain Streaming 和 Groq</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5s9g4/p_superfast_rag_langchain_streaming_and_groq/</link>
      <description><![CDATA[使用 Groq 和 Langchain Streaming 进行快速 LLM RAG 推理。  Groq 推出了一种新的、更简单的处理架构，专为满足机器学习应用程序和其他计算密集型工作负载的性能要求而设计。更简单的硬件还可以通过消除分析需求来节省开发人员资源，并且还可以更轻松地大规模部署 AI 解决方案。  资源：https://www.youtube.com/watch?v=frMdOL8knqg    提交人    /u/trj_flash75   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5s9g4/p_superfast_rag_langchain_streaming_and_groq/</guid>
      <pubDate>Sat, 01 Jun 2024 17:35:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] GPT-Burn：纯 Rust 中 GPT 的简单而简洁的实现🔥</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5qg3h/p_gptburn_a_simple_concise_implementation_of_the/</link>
      <description><![CDATA[        由    /u/ProfessionalDrummer7 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5qg3h/p_gptburn_a_simple_concise_implementation_of_the/</guid>
      <pubDate>Sat, 01 Jun 2024 16:10:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 PyTorch Geometric 进行 GNN 采样的视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5nmlh/p_a_visual_guide_to_gnn_sampling_using_pytorch/</link>
      <description><![CDATA[      大家好， 我发布了一些关于“图神经网络采样”主题的视频和笔记本（GNNs）”。原始 GCN 论文采用全批量训练。然后，研究人员使用不同的方法创建小批量（子图）来训练 GCN。例如，GraphSAGE 论文使用了邻居采样器，而 ClusterGCN 论文使用了集群采样器。这些采样器在 pytorch-geometric 中的 torch_geometric.loader 下实现。 这是视频，或者你可以直接跳到代码中..  图形神经网络的采样 视频 代码  图形神经网络中的迷你批次视频 视频 代码 原始图表 三使用来自 pytorch_geometric 的 NeighborLoader 对子图进行采样；白色节点未被采样。    提交人    /u/mashaan14   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5nmlh/p_a_visual_guide_to_gnn_sampling_using_pytorch/</guid>
      <pubDate>Sat, 01 Jun 2024 14:00:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助提高 BERT 与神经网络的匹配度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5l0he/d_help_to_increase_the_acc_of_bert_with_neural/</link>
      <description><![CDATA[      你好，我是 ML 新手，我正在努力提高我的 BERT-CNN、BERT-LSTM、BERT-GRU 的准确率。 这是我的存储库情绪分析 BERT-CNN 我使用的数据集是Kaggle，该数据集不平衡，因此我需要将一些中性情绪分数取出至 0.78 以获得 4k 的中性情绪 我现在的准确率是 -&gt; BERT-CNN 训练总结： 最佳训练损失：0.0129（第 10 次训练） 最佳验证准确率：81.55%（第 7 次训练） -&gt; BERT-LSTM 训练总结： 最佳训练损失：0.0815（第 10 次训练） 最佳验证准确率：81.14%（第 7 次训练） -&gt; BERT-GRU 训练总结： 最佳训练损失：0.0815（第 10 次迭代） 最佳验证准确率：81.14%（第 7 次迭代） 图表 我根据这篇论文进行研究，作为准确率的参考，但是 我的代码有问题吗？ 我不知道我已经更改了不同的超参数，但对准确率来说仍然不重要。以及为什么我的模型不好，比如 acc 的改进不是增量的，但有时是下降的？ 提前谢谢您，我希望您对讨论感兴趣:)    提交人    /u/Jveko   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5l0he/d_help_to_increase_the_acc_of_bert_with_neural/</guid>
      <pubDate>Sat, 01 Jun 2024 11:35:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mojo 值得吗，或者你愿意为 ML 学习哪种第二语言？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5kov5/d_is_mojo_worth_it_or_which_second_language_would/</link>
      <description><![CDATA[基本上就是标题。我非常精通 Python（正如预期的那样），但除此之外，我对 JavaScript 和 C++ 的了解非常有限。我想学习一种更“低级”的第二种语言，可以更好地利用硬件功能。我的目标不是重写 Pytorch 或完全替换 Python（尽管 将推理移植到 Mojo 可能有意义），而是为性能关键用例提供替代方案。 从今天的情况来看，答案显然是 C++。然而，Rust 越来越受欢迎，除了陡峭的学习曲线外，人们开始在许多方面将其置于 C++ 之上。在这两种情况下，语法和语言都与 Python 不太接近，这使得它们很难学习。 Mojo 在这方面似乎要好得多，既提供了语法类似于 Rust 的低级功能（至少对于像我这样的门外汉来说），又可以用作奇怪的 Python 风格。它甚至允许直接导入 Python 库。这对于这种缺乏大型社区和各种库的年轻语言非常有帮助。尽管如此，该语言仍然很年轻，而且很容易发生变化，所以我不确定是否应该投资。 那么，对于上述用例，您认为最好的“第二种”语言是什么？有使用 Mojo 的经验吗？您是如何学习它或资源有限的任何其他语言的。如果我使用 Mojo，我打算通读文档并解决去年使用它的代码出现的问题。    提交人    /u/canbooo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5kov5/d_is_mojo_worth_it_or_which_second_language_would/</guid>
      <pubDate>Sat, 01 Jun 2024 11:15:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] DeTikZify：使用 TikZ 合成科学图形和草图的图形程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hh0s/p_detikzify_synthesizing_graphics_programs_for/</link>
      <description><![CDATA[        由    /u/DrCracket 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hh0s/p_detikzify_synthesizing_graphics_programs_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:20:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自动 LoRA 发现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</guid>
      <pubDate>Sat, 01 Jun 2024 04:09:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>