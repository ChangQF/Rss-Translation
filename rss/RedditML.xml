<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 22 Mar 2024 12:23:30 GMT</lastBuildDate>
    <item>
      <title>[D] 人们使用什么来编排频繁的模型重新训练和部署？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkx2it/d_what_are_people_using_for_orchestration_of/</link>
      <description><![CDATA[我的团队有一些正在生产的模型，其中每隔几周就会临时进行一次模型重新训练。我们运行训练，使用 MLFlow 进行跟踪（不使用 MLFlow 的模型注册表），然后如果我们想要部署新模型，我们手动更新应用程序存储库中的模型标签，创建新的应用程序映像，从 s3 下载新模型工件，然后部署。  这对我们来说效果很好。问题是，我们即将开展一个项目，每天可能需要多次重新训练模型，因此显然当前的工作流程将无法工作。  人们使用什么来协调这些大规模、频繁的再培训和部署？我们正在考虑使用托管 AirFlow 实例和 MLFlow 模型注册表，但我对其他想法持开放态度，例如 MetaFlow 或 MLOps 动物园中的任何其他工具  &amp; #32；由   提交/u/stephenfenel  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkx2it/d_what_are_people_using_for_orchestration_of/</guid>
      <pubDate>Fri, 22 Mar 2024 11:32:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何用更少的 GPU 内存训练神经网络：可逆残差网络回顾</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkv29x/r_how_to_train_a_neural_network_with_less_gpu/</link>
      <description><![CDATA[探索可逆残差网络的有趣方法。 OpenCV.ai 团队的新文章回顾了一种减少 GPU 内存需求的方法在神经网络训练期间。您将发现可逆残差网络在神经网络训练期间如何节省 GPU 内存。该技术在“可逆残差网络：无需存储激活的反向传播”中详细描述。通过不存储反向传播的激活，可以有效地训练更大的模型。了解其在降低硬件要求方面的应用，同时保持 CIFAR 和 ImageNet 分类等任务的准确性。   由   提交/u/Human_Statistician48   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkv29x/r_how_to_train_a_neural_network_with_less_gpu/</guid>
      <pubDate>Fri, 22 Mar 2024 09:21:48 GMT</pubDate>
    </item>
    <item>
      <title>针对 AI 子版块或讨论论坛的硬件建议。 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkt2xs/suggestions_for_hardware_for_ai_subreddits_or/</link>
      <description><![CDATA[大家好，我正在寻找一些 subreddits 或讨论论坛，我们可以在其中讨论研究并在可能的情况下就一些项目进行协作，以便我们可以深入研究和理解硬件如何处理 AI/ML 工作负载。我也在寻找一些不错的起点来让我进入硬件加速器系统的设计以及 AI/DL 工作负载的复杂性。 https://github.com/MPSLab-ASU/ML-Accelerators 这是我开始使用的资源之一，如果您有，请告诉我任何其他建议。   由   提交/u/WritingBeginning3403  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkt2xs/suggestions_for_hardware_for_ai_subreddits_or/</guid>
      <pubDate>Fri, 22 Mar 2024 06:54:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 首次参加 ICLR 2024 会议的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkqxms/d_advice_for_attending_iclr_2024_as_a_first/</link>
      <description><![CDATA[嗨，我是一名大三学生，非常幸运，被邀请参加 ICLR 的研讨会。我计划参加整个会议。我想知道是否有人对第一次参加会议的人有建议，以便我能够充分利用它。 我也对博士学位感兴趣，但在大学的前两年过得很艰难。与 ICLR 其他学校的教授交谈会有帮助吗？   由   提交 /u/mathwoman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkqxms/d_advice_for_attending_iclr_2024_as_a_first/</guid>
      <pubDate>Fri, 22 Mar 2024 04:30:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当前小型（例如，<10,000 个参数）语言模型中最好的是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkqd2q/d_what_is_the_current_best_in_tiny_say_10000/</link>
      <description><![CDATA[显然，我们都听说过大语言模型，甚至听说过“小”语言模型。语言模型非常大（通常&gt; 100万个参数）。显然（除非我严重误解了语言模型的工作原理），你至少需要与词汇量一样多的参数（因为人们可以想象的最基本的模型只是为每个后续的概率分配一个固定的概率）单词，无论上下文如何 - 显然任何有用的模型都会做比这更复杂的事情）。 但我想知道小型模型的最新技术是什么，以前存在的模型的大小“大数据”甚至是一个已经被创造出来的短语。我知道这现在可能是一个小众的事情，业内很少有人致力于此。但我认为（或者至少我希望）至少仍然有爱好者在业余时间从事此类工作，就像仍然有人为 NES 编写自制游戏一样。 我&#39;我正在谈论一种可以在几个下午内在 C/C++ 中从头开始构建的模型（模型和训练算法），而不使用任何第三方依赖项/框架，可以进行训练和推理，甚至不需要显卡等。最重要的是，什么架构在这些限制下工作得最好？当限制在这个大小时，有什么能打败 HMM、n-gram 模型等吗？   由   提交/u/math_code_nerd5   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkqd2q/d_what_is_the_current_best_in_tiny_say_10000/</guid>
      <pubDate>Fri, 22 Mar 2024 03:58:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 内涵与外延的观点？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkq5h9/d_intension_vs_extension_point_of_view/</link>
      <description><![CDATA[是否有一种方法可以根据内涵与外延框架来解释神经网络？著名的哲学鸿沟，内涵是温度和速度之类的东西，外延是几何学之类的东西。   由   提交/u/metametametaphysicals2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkq5h9/d_intension_vs_extension_point_of_view/</guid>
      <pubDate>Fri, 22 Mar 2024 03:46:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过自动语音识别法学硕士为情感分类选择正确的 F1 分数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkpje5/p_choosing_the_right_f1_score_for_sentiment/</link>
      <description><![CDATA[背景 - 我和我的团队刚刚发布了一个对话智能平台，企业可以使用该平台来提高客户满意度。它记录办公室的每个来电/去电，转换为文本，并检测每个呼叫的客户情绪是快乐、不快乐还是中立。我们提示法学硕士给我们分类。我是拥有这个平台的 PM。  问题 - 快乐和不快乐分类的 f1 分数非常低，都低于 60%，我无法透露确切的数字。我们正在尝试多种不同的方法来提高两者的分类准确性（即 f1 分数）。  提问 - 我们应该瞄准的 f1 分数的最佳范围是多少？ 我知道如果 f1 分数太高，我们可能会面临过度拟合的风险。我应该如何思考这个问题？我应该考虑哪些因素？我只是无法凭空想象出 80 - 90% 的范围，我需要有关正确方法的指导来做出这个决定。另外，如果有人知道这种事情的先例，请分享，这也会非常有帮助。  非常感谢，我非常感谢您的指导🧡   由   提交/u/freshlimesoda65  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkpje5/p_choosing_the_right_f1_score_for_sentiment/</guid>
      <pubDate>Fri, 22 Mar 2024 03:13:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于大量 csv 数据，您会使用什么数据库？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkncy8/d_what_databases_would_you_use_for_large_amounts/</link>
      <description><![CDATA[什么数据库可以快速查询和存储大型数据集？ 我有一个 500 万行的 csv 文件，大约 1 GB的文本。我还有另外 4 个大小相同的 csv 文件，我最终需要将它们组合在一起。然而，我读入 pandas 的 csv 文件的读入和处理速度很慢。您将使用哪些数据库选项用于此数据集上的机器学习项目？  我基本上有 2000 万行数据，而且速度并不算慢，但我想知道如何扩展模型开发，以及是否有更快的数据库选项。    由   提交/u/Whole-Watch-7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkncy8/d_what_databases_would_you_use_for_large_amounts/</guid>
      <pubDate>Fri, 22 Mar 2024 01:23:32 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ML 研讨会/会议推荐：不是 AAI、IJCAI、NeuRips 或 ICML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkdsi2/discussion_ml_workshopconference_recommendation/</link>
      <description><![CDATA[这里是博士生。我尝试在 AAI-22、IJCAI-23、NeuRIPS-23 和 ICML-24 上发表我的论文。每次我处理这些评论时，我的分数都会更低。我做了表格数据——他们要求计算机视觉，我就这么做了。现在，他们要求语音识别。它在哪里停止？最重要的是，有些评论感觉他们在审稿时根本没有读过论文。这两年我一直在做这方面的工作，发表了几篇论文。我很累，整个过程都筋疲力尽。有人可以推荐一些 2024 年排名较低但可以接受的 ML 会议或信誉良好的研讨会吗？我想发布并完成这个工作。    由   提交/u/Conscious-Media3207  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkdsi2/discussion_ml_workshopconference_recommendation/</guid>
      <pubDate>Thu, 21 Mar 2024 18:35:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有准确的AI工具进行研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk9aw0/d_is_there_an_accurate_ai_tool_for_research/</link>
      <description><![CDATA[我所在的领域需要大量数据分析和最新信息。我尝试过 Perplexity、ChatGPT 和 Bard 等工具，但结果各不相同。他们都有过自己的时刻，但没有一个是始终准确的，而不断检查它们是否准确就违背了使用人工智能工具的初衷。我遇到过一些问题，例如误解上下文以及反馈给我的不相关信息。我最近在寻找有关量子计算的信息，但只收到过时的参考资料。 同样，必须验证我得到的所有内容，这让我回到了最初的问题，我宁愿不完全使用人工智能工具。那么有没有真正的替代方案，或者我对独角兽的要求太多了？理想情况下，我正在寻找一个能够处理复杂主题并与最新出版物保持同步的人。  感谢您的帮助！   由   提交 /u/energetic_slugger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk9aw0/d_is_there_an_accurate_ai_tool_for_research/</guid>
      <pubDate>Thu, 21 Mar 2024 15:31:23 GMT</pubDate>
    </item>
    <item>
      <title>ICML 反驳 2024 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk88kf/icml_rebbutal_2024_r/</link>
      <description><![CDATA[大家好，  今天 ICML 2024 的评审已出炉。  我提交了第一篇论文，但所有关于论文演示的评论都是负面的（三篇拒绝，评分为 3）。我想知道以后事情如何进行。如果我更改论文的呈现形式，我的论文还有机会被接受吗？特别是因为我在第一次提交后就做了实验。有人遇到过同样的问题，并因为第一次失望而感到沮丧吗？   由   提交/u/Any-Ad-3888  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk88kf/icml_rebbutal_2024_r/</guid>
      <pubDate>Thu, 21 Mar 2024 14:46:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 评论已发布。来！我们讨论一下！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk7u47/d_icml_reviews_are_released_lets_discuss/</link>
      <description><![CDATA[ 您收到了多少评论？ 他们的评分是多少？ （分数/置信度）  以下是审阅说明供参考：https://icml .cc/Conferences/2024/ReviewerInstructions   由   提交/u/tfburns  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk7u47/d_icml_reviews_are_released_lets_discuss/</guid>
      <pubDate>Thu, 21 Mar 2024 14:28:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自然语言指令诱导神经元网络中的成分泛化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk4fyk/r_natural_language_instructions_induce/</link>
      <description><![CDATA[论文：https://www.nature.com/articles/s41593-024-01607-5 代码：https://github.com/ReidarRiveland/Instruct-RNN/ 摘要：  人类的一项基本认知壮举是解释语言指令，以便在没有明确任务经验的情况下执行新任务。然而，可用于实现这一目标的神经计算仍然知之甚少。我们利用自然语言处理的进步来创建基于语言指令的泛化神经模型。模型接受一组常见心理物理任务的训练，并接收预训练语言模型嵌入的指令。我们最好的模型可以执行以前未见过的任务，仅基于语言指令（即零样本学习），平均正确率可达 83%。我们发现，语言支撑着感觉运动表征，使得相关任务的活动与指令的语义表征共享共同的几何形状，从而使语言能够提示在看不见的环境中练习技能的正确组成。我们展示了该模型如何仅使用运动反馈来生成对其识别的新任务的语言描述，这随后可以指导合作伙伴模型执行该任务。我们的模型提供了几个可通过实验测试的预测，概述了如何表示语言信息以促进人脑的灵活和一般认知。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk4fyk/r_natural_language_instructions_induce/</guid>
      <pubDate>Thu, 21 Mar 2024 11:35:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发布“1 位法学硕士时代”的培训代码及更多内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk32ye/d_training_code_and_more_released_for_the_era_of/</link>
      <description><![CDATA[不幸的是，微软没有发布权重，但如果权重介于权重和训练代码之间，那么这当然是更好的选择。 这篇文章在这里。  我们怎么想？关于形状奇怪的损失曲线有什么想法吗？您认为这种方法在 4B 参数之后会失效吗？法学硕士如何在如此低的精度下工作？我知道这不是特别科学，但对我来说，你可能会在几张 CD 上安装一个功能齐全的 7B 参数模型，这似乎相当违反直觉……然而最重要的是，谁有价值 100,000 美元的计算来实际测试这个？   由   提交 /u/DickMasterGeneral   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk32ye/d_training_code_and_more_released_for_the_era_of/</guid>
      <pubDate>Thu, 21 Mar 2024 10:09:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>