<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 12 Oct 2024 21:16:30 GMT</lastBuildDate>
    <item>
      <title>[D] ML 项目的反馈：使用 Transformers 改进蚁群优化算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g21loo/d_feedback_on_ml_project_using_transformers_to/</link>
      <description><![CDATA[我目前正在从事一个个人项目，尝试构建一个改进版本的蚁群优化算法。 在运行算法之前，我使用位置编码变压器神经网络来预测最佳信息素矩阵。 改进的蚁群优化算法使用位置编码变压器神经网络输出的信息素矩阵进行初始化，该网络使用来自普通蚁群优化算法的信息素矩阵数据进行训练。 为了分析算法的改进，我让改进的 ACO 与普通 ACO 一起运行不同地图大小的多次迭代，计算每个算法的最佳运行，并计算 p 值以验证改进的算法是否具有统计意义。 到目前为止，增强型 ACO 显示出令人满意的结果，对于节点大小为 30 和 35，p 值分别为 0.06 和 0.05。  但是，我的目标是在更大范围的节点大小中实现显著性 (p &lt; 0.05)。 我将不胜感激任何反馈！ 项目链接：https://github.com/ronantakizawa/improvedaco/blob/main/ronan_acotransformer_experiment.ipynb    提交人    /u/SafeSignificance8840   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g21loo/d_feedback_on_ml_project_using_transformers_to/</guid>
      <pubDate>Sat, 12 Oct 2024 14:42:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何改进 img2img 以实现（稳定的）扩散模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g20kgi/d_how_to_improve_img2img_for_stable_diffusion/</link>
      <description><![CDATA[图像生成人员，我们都熟悉用于扩散模型的 img2img 方法，其中输入图像用于调节扩散过程并产生输入图像的变化（也使用引导提示）。这是由 Automatic1111、ComfyUI、Invoke AI 实现的，并在许多论文中使用。 在此方法中，允许控制的参数是去噪强度，它对应于在对图像进行去噪之前向图像添加的噪声步骤百分比（由输入提示调节）。 我想知道这种简单的方法在过去两年中是否有所改进。 我知道你可以使用 img2img 进行修复（img2img 的局部区域而不是整个图像）或修复。我特别想找一些尝试不同的 img2img 方法并比较获得的结果的论文。如果有人能指出论文，那将会很有帮助！    提交人    /u/gohu_cd   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g20kgi/d_how_to_improve_img2img_for_stable_diffusion/</guid>
      <pubDate>Sat, 12 Oct 2024 13:51:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] GSM-Symbolic：理解大型语言模型中数学推理的局限性（Apple）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1wbir/r_gsmsymbolic_understanding_the_limitations_of/</link>
      <description><![CDATA[arXiv:2410.05229 [cs.LG]: https://arxiv.org/abs/2410.05229 Iman Mirzadeh、Keivan Alizadeh、Hooman Shahrokhi、Oncel Tuzel、Samy Bengio、Mehrdad Farajtabar - Apple TechCrunch - Devin Coldewey：研究人员质疑人工智能的“推理”能力，因为模型在解决数学问题时会遇到一些细微的变化：https://techcrunch.com/2024/10/11/researchers-question-ais-reasoning-ability-as-models-stumble-on-math-problems-with-trivial-changes/ 共同作者之一 Mehrdad Farajtabar 在 X 上的这个帖子中分解了这篇论文：https://x.com/MFarajtabar/status/1844456880971858028    由   提交  /u/Nunki08   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1wbir/r_gsmsymbolic_understanding_the_limitations_of/</guid>
      <pubDate>Sat, 12 Oct 2024 09:20:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 DSPy 改进 AI 代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1w6qa/p_improving_ai_agents_using_dspy/</link>
      <description><![CDATA[      在这篇文章中，我将探讨如何使用 DSPy 提高其中一个代理的性能。如果您不知道，DSPy 是一个 LLM 框架，专门设计用于以编程方式改进 LLM 的提示和签名。因此，您无需更改 LLM 即可获得更好的性能。    提交人    /u/phicreative1997   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1w6qa/p_improving_ai_agents_using_dspy/</guid>
      <pubDate>Sat, 12 Oct 2024 09:09:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 奖励进展：扩展 LLM 推理的自动化流程验证器（来自 Deepmind 的研究）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1uf90/r_rewarding_progress_scaling_automated_process/</link>
      <description><![CDATA[摘要：使用过程奖励模型 (PRM) 是改进大型语言模型推理的一种有前途的办法。PRM 在多步推理跟踪的每个步骤中提供反馈，与仅在最后一步提供反馈的结果奖励模型 (ORM) 相比，可能改善信用分配。然而，收集密集的、每步的人工标签是不可扩展的，并且迄今为止，从自动标记的数据训练 PRM 只带来了有限的收益。为了通过针对 PRM 运行搜索或将其用作强化学习 (RL) 的密集奖励来改进基础策略，我们问：“我们应该如何设计过程奖励？”。我们的主要见解是，为了有效，步骤的过程奖励应该衡量进展：在采取该步骤之前和之后，未来产生正确响应的可能性的变化，对应于 RL 中的步骤级优势概念。至关重要的是，应该在不同于基础策略的证明者策略下衡量这一进展。我们从理论上描述了一组好的证明器，我们的结果表明，优化此类证明器的过程奖励可改善测试时搜索和在线 RL 中的探索。事实上，我们的表征表明，弱证明器策略可以显著改善更强大的基础策略，我们也通过经验观察到了这一点。我们通过训练过程优势验证器 (PAV) 来预测此类证明器下的进度，从而验证了我们的说法，并表明与 ORM 相比，针对 PAV 的测试时搜索准确率提高了 8% 以上，计算效率提高了 1.5-5 倍。与 ORM 相比，具有来自 PAV 的密集奖励的在线 RL 实现了首批结果之一，样本效率提高了 5-6 倍，准确率提高了 6% 以上。    提交人    /u/DickMasterGeneral   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1uf90/r_rewarding_progress_scaling_automated_process/</guid>
      <pubDate>Sat, 12 Oct 2024 06:52:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 Dagger.io 和 KitOps 构建 MLOps 管道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1u0fj/r_building_an_mlops_pipeline_with_daggerio_and/</link>
      <description><![CDATA[        由    /u/codes_astro  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1u0fj/r_building_an_mlops_pipeline_with_daggerio_and/</guid>
      <pubDate>Sat, 12 Oct 2024 06:20:54 GMT</pubDate>
    </item>
    <item>
      <title>核技巧（RKHS）应用于逻辑：语义空间框架中的逻辑属性和量词</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1sfz2/the_kernel_trick_rkhs_applied_to_logic_logical/</link>
      <description><![CDATA[        由    /u/musescore1983   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1sfz2/the_kernel_trick_rkhs_applied_to_logic_logical/</guid>
      <pubDate>Sat, 12 Oct 2024 04:33:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAAI 2025 第一阶段决议泄露？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1plva/d_aaai_2025_phase_1_decision_leak/</link>
      <description><![CDATA[是否有人检查过 AAAI 提交的修订部分并注意到该论文已移至文件夹“Rejected_Submission”。它应该在 Venueid 标签下可见。我从推特帖子中了解到这一点： https://x.com/balabala5201314/status/1843907285367828606    提交人    /u/Wise_Witness_6116   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1plva/d_aaai_2025_phase_1_decision_leak/</guid>
      <pubDate>Sat, 12 Oct 2024 01:43:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么看起来谷歌的 TPU 对 nVidia 的 GPU 不构成威胁？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1okem/d_why_does_it_seem_like_googles_tpu_isnt_a_threat/</link>
      <description><![CDATA[尽管谷歌在其许多内部 AI 工作中使用了 TPU，但似乎并没有像 nVidia 的 GPU 那样推动其收入增长。这是为什么？为什么拥有自己的 AI 设计的处理器没有像 nVidia 那样对他们有所帮助，为什么所有其他专注于 AI 的公司似乎仍然只想在 nVidia 芯片上运行他们的软件……即使他们使用的是谷歌数据中心？    提交人    /u/kugelblitz_100   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1okem/d_why_does_it_seem_like_googles_tpu_isnt_a_threat/</guid>
      <pubDate>Sat, 12 Oct 2024 00:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[N] Kaido Orav 和 Byron Knoll 的 fx2-cmix 赢得 7950 欧元的 Hutter 奖！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1l725/n_kaido_orav_and_byron_knolls_fx2cmix_wins_7950/</link>
      <description><![CDATA[Kaido Orav 和 Byron Knoll 凭借其&quot;fx2-cmix&quot; 参赛作品在 人类知识无损压缩 Hutter 奖 上提高了 1.59%。由于 Hutter 奖将参赛者限制为单一&quot;通用处理器，并使用&quot;https://www.youtube.com/watch?v=AKMuA_TVz3A&quot;&gt;最&quot;通用的损失函数，因此所需的算法进步&quot;通常适用，无论业界的&quot;硬件彩票&quot; 或损失函数妥协如何。在这方面，它为机器学习的科学进步提供了独特且低风险的激励。  与之前的 Hutter 奖获奖算法相比，fx2-cmix 的一些算法进步如下：  混合器和预测器：当错误低于某个阈值时，混合器现在会跳过权重更新，从而提高处理速度。  单次传递 维基百科转换：此更新通过将转换过程从以前的多步骤方法简化为单次传递，减少了处理维基百科等大型数据集所需的时间和磁盘使用量，从而显著加快了预处理阶段。  新的词干和上下文方法：利用自然语言处理技术（如词干过程中的新词类型）来创建更紧凑、更相关的词流。这不仅提高了训练数据的质量，而且还增强了压缩能力，降低了存储要求。  高效的文章排序：通过将整个文章嵌入到大向量中并使用 t-SNE 将其减少到单个维度，可以快速重新排序整个语料库以进一步加快训练速度。  有关进展的详细描述以及 Jupyter 笔记本和其他文档可在 fx2-cmix README 中找到。     提交人    /u/jabowery   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1l725/n_kaido_orav_and_byron_knolls_fx2cmix_wins_7950/</guid>
      <pubDate>Fri, 11 Oct 2024 21:56:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 复合学习单元：超越参数更新的广义学习，将 LLM 转变为自适应推理机</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1gtns/r_composite_learning_units_generalized_learning/</link>
      <description><![CDATA[  由    /u/jalabulajangs  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1gtns/r_composite_learning_units_generalized_learning/</guid>
      <pubDate>Fri, 11 Oct 2024 18:37:47 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ODE/PDE 或数学问题的 ML 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1e3vt/discussion_ml_models_for_odepde_or_math_problems/</link>
      <description><![CDATA[我正在寻找与用于解决 ODE/PDE（常微分方程和偏微分方程）的 ML/DL 模型相关的论文/材料（如果有的话）。此外，一般解决任何与数学相关的问题，如数学奥林匹克。我只是想研究这些，因为我来自数学背景，觉得这些领域真的很有前途。 谢谢。    提交人    /u/optimization_ml   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1e3vt/discussion_ml_models_for_odepde_or_math_problems/</guid>
      <pubDate>Fri, 11 Oct 2024 16:38:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 差动变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g13gkd/r_differential_transformer/</link>
      <description><![CDATA[      论文 摘要  Transformer 倾向于将注意力过度分配到不相关的上下文中。在本研究中，我们引入了 Diff Transformer，它可以在消除噪音的同时放大对相关上下文的注意力。具体来说，差分注意力机制将注意力分数计算为两个单独的 softmax 注意力图之间的差值。减法可以消除噪音，促进稀疏注意力模式的出现。[...] [...] 它在实际应用中具有显着优势，例如长上下文建模、关键信息检索、幻觉缓解、上下文学习和减少激活异常值。[...]     提交人    /u/fliiiiiiip   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g13gkd/r_differential_transformer/</guid>
      <pubDate>Fri, 11 Oct 2024 06:26:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</guid>
      <pubDate>Sun, 06 Oct 2024 15:00:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>