<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 14 Feb 2024 21:11:56 GMT</lastBuildDate>
    <item>
      <title>[D] 我如何开始使用 BERT？用它来检测参与者反应中的道德情感</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqxuu8/d_how_do_i_get_started_with_bert_using_it_to/</link>
      <description><![CDATA[我需要使用 BERT 从参与者响应中的 5 个道德基础中检测道德情感。我正在为我所在的社会心理实验室的一个独立项目做这件事，我以前从未做过这样的事情，而且我没有得到实验室的支持。我有很多问题，但我对如何开始感到不知所措。我什至下载什么程序？如何准备 CSV 以便程序可以读取它？等等，只是寻找有关如何开始自己学习的任何提示或指示   由   提交 /u/mymichelle1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqxuu8/d_how_do_i_get_started_with_bert_using_it_to/</guid>
      <pubDate>Wed, 14 Feb 2024 21:08:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何关注数据科学领域的学术论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqxtwm/d_how_to_follow_academic_papers_in_data_science/</link>
      <description><![CDATA[如何关注数据科学领域的最新学术论文？有期刊、网站或其他来源吗？    由   提交 /u/BiraMotta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqxtwm/d_how_to_follow_academic_papers_in_data_science/</guid>
      <pubDate>Wed, 14 Feb 2024 21:07:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习新手</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqxnzw/d_new_to_machine_learning/</link>
      <description><![CDATA[我是 Python 初学者，我希望能够在医疗领域使用机器学习。我应该遵循什么具体路径来实现我的目标以及我需要学习哪些东西？   由   提交/u/user2102005  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqxnzw/d_new_to_machine_learning/</guid>
      <pubDate>Wed, 14 Feb 2024 21:00:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自然语言强化学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqwx7q/r_natural_language_reinforcement_learning/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2402.07157 OpenReview：https:// /openreview.net/forum?id=0VzU2H13qj 摘要：  强化学习（RL）在以下方面表现出了卓越的能力：学习决策任务的策略。然而，强化学习常常受到样本效率低、缺乏可解释性和监督信号稀疏等问题的阻碍。为了解决这些限制，我们从人类学习过程中汲取灵感，引入了自然语言强化学习 (NLRL)，它创新地将强化学习原理与自然语言表示相结合。具体来说，NLRL 重新定义了自然语言空间中的任务目标、策略、价值函数、贝尔曼方程和策略迭代等 RL 概念。我们介绍如何利用 GPT-4 等大型语言模型 (LLM) 的最新进展来实际实施 NLRL。对表格 MDP 的初步实验证明了 NLRL 框架的有效性、效率和可解释性。    由   提交 /u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqwx7q/r_natural_language_reinforcement_learning/</guid>
      <pubDate>Wed, 14 Feb 2024 20:28:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 模型崩溃揭秘：回归案例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqwset/r_model_collapse_demystified_the_case_of/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.07712 摘要：  在ChatGPT这样的大型语言模型时代， “模型崩溃”指的是这样一种情况：随着时间的推移，模​​型根据其前几代生成的数据进行递归训练，其性能会下降，直到模型最终变得完全无用，即模型崩溃。在这项工作中，我们在核回归的简化设置中研究了这种现象，并获得了结果，这些结果显示模型可以处理虚假数据的情况与模型性能完全崩溃的情况之间存在明显的交叉。在多项式衰减光谱和源条件下，我们获得了修改后的缩放定律，该定律表现出从快速率到慢速率的新交叉现象。我们还提出了一种基于自适应正则化的简单策略来减轻模型崩溃。我们的理论结果通过实验得到了验证。    由   提交 /u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqwset/r_model_collapse_demystified_the_case_of/</guid>
      <pubDate>Wed, 14 Feb 2024 20:22:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 pytorch 和 Phi-2 从头开始​​自然语言生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aquduw/p_natural_language_generation_from_scratch_using/</link>
      <description><![CDATA[我关于在 pytorch 中从头开始编码不同解码策略的最新帖子。这是链接。您可以在博客文章中找到 Colab 笔记本中演示的所有代码。   由   提交/u/MasterpieceExtreme3​​0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aquduw/p_natural_language_generation_from_scratch_using/</guid>
      <pubDate>Wed, 14 Feb 2024 18:45:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对具有重复测量组件的模型的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqtjzf/d_recommendations_for_a_model_with_repeated/</link>
      <description><![CDATA[我是 Reddit 新手，对编码也相对较新（&lt;1.5 年）。如果这不属于这里，我深表歉意。 我开始在我的研究中使用机器学习。到目前为止，我已经能够使用随机森林（我知道这是一个简单的机器学习模型）来预测感兴趣的变量。由于训练数据是从同一动物记录的测量结果，因此我需要重复测量方法。我们能够将重复测量纳入 P Calhoun (2021) 编写的随机森林适应函数中。 问题是，如果存在 NaN 值，重复测量随机森林就无法工作。作为我们工作的一部分，一些动物必须在不同时间从实验中移除。他们没有返回实验。下面是一个简化了我所讨论内容的表格： ​   动物 出现在测试 1 中 出现在测试 2 出现在测试 3    1 Y Y Y   2 Y Y N   3 Y N N   所以，一些动物将拥有全部 180 天的数据，而有些动物只会拥有 120 天、80 天、60 天等的数据。这会产生大量 NaN 值。我们使用 MissForest R 包来估算缺失的气候变量，但由于显而易见的原因，估算 100 多天的动物数据是荒谬的。 我们收集动物数据，直到将它们从实验中删除为止。收集这些动物数据非常昂贵（并且是劳动密集型），并且由于农业研究的性质，小 n 尺寸始终是一个问题。我们确实希望使用来自所有动物的所有数据来训练预测模型。 我正在寻找 ML 模型的建议，这些模型具有一些可以使用数据类型的重复测量分析组件（某些记录比其他记录有更多的观察结果）。任何建议都非常受欢迎！谢谢！   由   提交 /u/Technical-Trip9933    reddit.com/r/MachineLearning/comments/1aqtjzf/d_recommendations_for_a_model_with_repeated/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqtjzf/d_recommendations_for_a_model_with_repeated/</guid>
      <pubDate>Wed, 14 Feb 2024 18:12:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 带描述的类的文本分类方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqqaag/p_d_text_classification_methods_for_classes_with/</link>
      <description><![CDATA[我正在开发一个个人项目，我正在使用的类有很多细微差别。仅仅使用 Huggingface 的现成模型很诱人，但准确性肯定会受到影响。 我正在考虑写几行描述这些类，其中涵盖了它们的细微差别特征。是否有使用这些描述对数据进行分类的分类方法？ 如果需要，我愿意使用法学硕士。我的首要任务是准确性，但不幸的是我没有很多标记数据（可能有 200 个样本左右）。   由   提交 /u/Mission-Language8789   /u/Mission-Language8789 reddit.com/r/MachineLearning/comments/1aqqaag/p_d_text_classification_methods_for_classes_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqqaag/p_d_text_classification_methods_for_classes_with/</guid>
      <pubDate>Wed, 14 Feb 2024 15:59:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我组装了一个 pytorch 调试器，重点是最小的代码更改和用于捕获无声错误的工具，例如可能导致您损失的 NaN 的错误。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqoy7t/p_i_put_together_a_pytorch_debugger_with_an/</link>
      <description><![CDATA[      https://github.com/ethansmith2000/epic-pytorch-debugger  开始这是非常非常WIP，但即使在当前状态，它在获取方面也非常有用有关异常中涉及的张量的详细报告，捕获 NaN 或其他奇数值，并跟踪非 pytorch 变量。 最好的部分是，它所需要的只是在函数上放置一个装饰器。 这里有一些示例 https://preview.redd.it/31m5jp34ijic1.png?width=1626&amp;format=png&amp;auto=webp&amp;s=5b3d64e32e2d5fda7f9f1db4ffec039c5db21db7 ​ &lt; p&gt;https://preview.redd.it/973909g1ijic1。 png?width=1148&amp;format=png&amp;auto=webp&amp;s=7ad349b861d4e5863c478ee6e39e272040adc647 我将其开源，希望其他人可以从中受益，并减少调试时间，特别是对于通常需要大量时间才能单独完成的大规模工作。  而且，我希望它可以成为一个公共项目，供任何愿意贡献的人使用。对于初学者来说，这是我在尝试弄清楚如何在实例化变量名称时跟踪变量名称时对 python 进行的最深入的了解，并且我确信我在其他一些事情上做得很差。  如果您碰巧发现任何错误（在调试器中，哈哈）或有任何反馈，欢迎大家！ ​    由   提交/u/ethansmith2000   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqoy7t/p_i_put_together_a_pytorch_debugger_with_an/</guid>
      <pubDate>Wed, 14 Feb 2024 15:03:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 阅读和学习研究论文的最佳方式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</link>
      <description><![CDATA[当我们尝试专注于玉兰油的创新产品时，我们必须学习许多现代科技知识。但通常需要时间才能获得博客和教程上的可用资源。  因此，直接从第一个主要来源学习是有效的学习方式，因为它是主要来源。 但是，我发现阅读论文非常困难，因为它包含许多术语或内容不寻常的措辞。此外，跟踪和掌握一篇大论文的上下文也需要很大的耐心。 你们能分享一下你们的方法吗？你们如何有效且高效地从已发表的论文中学习并获得见解？   由   提交 /u/FardinRock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</guid>
      <pubDate>Wed, 14 Feb 2024 14:28:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 手语识别 (SLR)：它到底有多好？我可以让它适用于不太流行的手语吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqlp23/p_sign_language_recognition_slr_how_good_is_it/</link>
      <description><![CDATA[我看过很多初学者教程来实现基于视频流的手语识别，但它们在现实世界中似乎都存在一些问题（比如说新闻发布会的电视录音）。一位客户问我们是否可以这样做，所以我开始想：  目前单反的状态如何？真的吗？它是否已在实践中使用？ 是否有现有的模型甚至服务可以直接使用？ 这些是否存在或可以用于不太流行的手语方言？ 这些是否存在或可以用于不太流行的手语方言？ li&gt;    由   提交 /u/Enum1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqlp23/p_sign_language_recognition_slr_how_good_is_it/</guid>
      <pubDate>Wed, 14 Feb 2024 12:26:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 RingAttention 实现百万长度视频和语言的世界模型 - 加州大学伯克利分校 2024 - 能够以近乎完美的精度描述一个多小时长的视频（包含超过 500 个剪辑）中的一个剪辑！ - 是开源的！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqjrc8/r_world_model_on_millionlength_video_and_language/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.08268  Github：https://github。 com/LargeWorldModel/LWM  模型： https://huggingface.com/LargeWorldModel/LWM co/LargeWorldModel ！ 摘要：  当前的语言模型在理解世界的各个方面方面存在不足很容易用语言描述，并且难以完成复杂、冗长的任务。 视频序列提供了语言和静态图像中所缺少的有价值的时间信息，这使得它们对于与语言的联合建模很有吸引力。这些模型可以发展对人类文本知识和物理世界的理解，从而实现更广泛的人工智能能力来帮助人类。然而，由于内存限制、计算复杂性和有限的数据集，从数百万个视频和语言序列的标记中学习提出了挑战。为了应对这些挑战，我们整理了一个包含不同视频和书籍的大型数据集，利用 RingAttention 技术对长序列进行可扩展训练，并逐渐将上下文大小从4K 增加到 1M 令牌。本文做出以下贡献：（a）最大上下文大小神经网络：我们在长视频和语言序列上训练最大上下文大小变换器之一，在困难的检索任务和长视频理解中树立了新的基准。 (b) 克服视觉语言训练挑战的解决方案，包括使用掩码序列打包来混合不同的序列长度、使用损失权重来平衡语言和视觉，以及用于长序列聊天的模型生成的 QA 数据集。 (c) 高度优化的实现，具有 RingAttention、掩码序列打包和其他关键功能，用于在数百万长度的多模态序列上进行训练。 (d) 完全开源一系列 7B 参数模型，能够处理超过 100 万代币的长文本文档（LWM-Text、LWM-Text-Chat）和视频（LWM、LWM-Chat） 。这项工作为长视频和语言的海量数据集的训练铺平了道路，以发展对人类知识和多模态世界的理解以及更广泛的能力。   &lt; a href=&quot;https://preview.redd.it/89xpv0ix1jic1.jpg?width=1177&amp;format=pjpg&amp;auto=webp&amp;s=b37224a61459c3b04ed01004b10342e1f2d9bd19&quot;&gt;https://preview.redd.it/89xpv0ix1jic1.jpg?width =1177&amp;format=pjpg&amp;auto=webp&amp;s=b37224a61459c3b04ed01004b10342e1f2d9bd19 https://preview.redd.it/mlhtz2ix1jic1.jpg?width=1488&amp;format=pjpg&amp;auto=webp&amp;s=b1bba31b6868fd230b454565e6 686ef0847dc0c2 https://preview.redd.it/ma51c4ix1jic1.jpg ?width=1022&amp;format=pjpg&amp;auto=webp&amp;s=7bce52c12b3ecf683e507582f0dd68ec53a68dac https://preview.redd.it/bc0kz4ix1jic1.jpg?width=670&amp;format=pjpg&amp;auto=webp&amp;s=e541c8f9c0db600e00ef8135a75 5ae0eadc33320   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqjrc8/r_world_model_on_millionlength_video_and_language/</guid>
      <pubDate>Wed, 14 Feb 2024 10:26:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过计算机视觉让我的书架可点击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</link>
      <description><![CDATA[      我构建了一个系统，可以让你拍摄书架的照片并创建一个交互式 HTML 网页，您可以在其中单击图像中的书籍来了解有关每本书的更多信息。 该项目的技术堆栈是：  用于检索的接地 SAM书籍的多边形。 OpenCV + 监督转换，为 OCR 准备书籍。 GPT-4 和 Vision for OCR Google Books API，用于获取书籍元数据。  生成 HTML + SVG 以创建最终网页。  我在博客上写了如何构建这个项目。 尝试演示。 我希望获得有关如何提高图书检测率以获得更好性能的反馈。在书脊上训练自定义分割模型可能会起作用，但我知道为此可能需要多少数据。 下面的红色多边形表示在演示中可点击的分段书籍：  p&gt; https://preview.redd.it /p9w4rgsn1jic1.png?width=1260&amp;format=png&amp;auto=webp&amp;s=35116c7eb9d1f5dab2b11375be9e2ff0e7163b78   由   提交/u/zerojames_  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</guid>
      <pubDate>Wed, 14 Feb 2024 10:21:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最佳 RNN 深度学习视频/文章/帖子？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqidg6/d_best_rnns_deep_dive_videoarticlepost/</link>
      <description><![CDATA[我正在学习 RNN，到目前为止我遇到的每一篇文章和视频都遗漏了一些细节，没有人详细解释所有内容。我更喜欢阅读或观看材料，其中作者不使用现成的 RNN 函数编写代码，而是像 Andrej Karpathy 一样详细解释所有内容。 （我读了 Karpathy 关于 RNN 的博文，但是没有太多与 RNN 相关的代码，并且文章主要是关于 LSTM 的）    由   提交/u/your_dream724  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqidg6/d_best_rnns_deep_dive_videoarticlepost/</guid>
      <pubDate>Wed, 14 Feb 2024 08:45:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>