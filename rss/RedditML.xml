<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 14 Nov 2024 21:15:48 GMT</lastBuildDate>
    <item>
      <title>[R] 在 textvqa 测试分割上进行测试？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gralqc/r_testing_on_textvqa_test_split/</link>
      <description><![CDATA[大家好，我想在 textvqa 测试集上测试我的模型，这显然需要在 evalai 网站上完成。但是两个挑战（2019/2020）都在那里关闭并且没有提交选项，此外 textvqa 官方网站提供的链接不起作用。（https://eval.ai/web/challenges/challenge-page/874/）关于如何在测试集上测试有什么想法吗？谢谢！    提交人    /u/Training-Adeptness57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gralqc/r_testing_on_textvqa_test_split/</guid>
      <pubDate>Thu, 14 Nov 2024 17:48:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习训练中的协调避免</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gra953/r_coordination_avoidance_in_ml_training/</link>
      <description><![CDATA[我对避免分布式机器学习训练中协调规避的方案很好奇。如果您可以参考一些相关论文，我将不胜感激。    提交人    /u/net-weight   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gra953/r_coordination_avoidance_in_ml_training/</guid>
      <pubDate>Thu, 14 Nov 2024 17:33:41 GMT</pubDate>
    </item>
    <item>
      <title>[D][P]聚类分类数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr7zqg/dpclustering_categorical_data/</link>
      <description><![CDATA[对由分类变量组成的数据框执行聚类的最佳方法是什么？ 我想使用具有许多变量的数据框，因此 One-Hot-Encoding 可能不是最佳解决方案。 SOTA 技术有哪些？也许是嵌入技术？    提交人    /u/DedeU10   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr7zqg/dpclustering_categorical_data/</guid>
      <pubDate>Thu, 14 Nov 2024 15:57:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这里有谁成功旋转了没有 EXIF 数据的图像吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr5oj6/d_has_anyone_here_had_luck_rotating_images_that/</link>
      <description><![CDATA[我尝试了各种编程语言和人脸检测模型，但都无法准确确定方向。    提交人    /u/Busy-Basket-5291   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr5oj6/d_has_anyone_here_had_luck_rotating_images_that/</guid>
      <pubDate>Thu, 14 Nov 2024 14:14:27 GMT</pubDate>
    </item>
    <item>
      <title>处理实际数据时，关于二元分类精度和召回率的上限的建议？[P] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr5hfa/advice_on_upper_limit_for_binary_classification/</link>
      <description><![CDATA[在我目前的公司，我正在建立一个模型，以了解访问我们应用的用户中有多少人实际为试用付费，并且根据这些预测，我们应用的 UI 将发生变化，向更有可能付费（或者可能不太可能付费，即不同的页面）的用户显示不同的页面。 问题是，实际付费的人与付费的人相比相对较少。我使用了 SMOTE 过度采样以及类权重和 XGBoost 分类器来帮助解决类别不平衡问题。在审查了模型（它在产品上发布大约一个半星期）后，结果显示多数类别的准确率约为 74%，所述类别 (0) 的召回率为 86%。 少数类别的情况看起来很暗淡，准确率为 29%，而召回率为 16%。我已经尽可能地优化了模型，是的，我知道我可以每周使用新数据训练模型并继续查看是否有任何改进，这是肯定的。 现在，就像在公司中通常会发生的那样，我的上司想要看到结果，但在这里查看数据可能会有点困难。是否有我可能忽略或没有足够注意的方法可能导致我的模型改进。我尝试过的方法有：采样技术（过度和不足）、SMOTE、SMOTENC、类权重（为类分配权重以影响训练）、使用 optuna 研究训练 xgboost 模型（如果您不知道 Optuna，您应该查看它，它非常适合超参数调整）。这些都是我从 medium 文章和 chatgpt 中找出的方法。 附言我想与该领域的人士讨论一些值得深思的问题，它的核心是二元分类问题，因此，以足够高的精度和召回率很好地检测出一个类是否足够好，而不用过多考虑另一个类，因为在我的简单思想中（在二元分类中），如果它不是一个类，那么它就是另一个类。我可能错了，我找不到任何你知道的关于这个特定主题的文章。如果你们都能阐明这一点，我很高兴。 编辑：如果它不是很清楚，我基本上是在寻找可用于处理数据不平衡的优化技术，并查看当我们处理真实数据时，精度和召回率是否真的存在上限。 谢谢！我知道这是一大段文字，感谢您阅读它。    提交人    /u/Icy-Literature9061   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr5hfa/advice_on_upper_limit_for_binary_classification/</guid>
      <pubDate>Thu, 14 Nov 2024 14:04:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习模型中不可检测的后门：使用数字签名和随机特征的新技术，对对抗鲁棒性有影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr4ksm/r_undetectable_backdoors_in_ml_models_novel/</link>
      <description><![CDATA[我发现了一个重要的后门攻击分析，它展示了恶意服务提供商如何将无法检测到的后门插入机器学习模型中。 关键贡献是展示了如何构建即使在白盒分析下也无法检测到的后门，同时允许通过微妙的输入扰动任意操纵模型输出。 技术细节：* 用于植入无法检测的后门的两个框架：* 基于数字签名方案的后门，在计算上无法通过黑盒访问检测* 基于随机傅立叶特征/随机 ReLU 的后门，可经受白盒检查* 即使具有以下条件，后门模型也与干净模型无法区分：* 完全访问模型架构和参数* 完整的训练数据集* 分析模型行为的能力 结果：* 后门模型保持与原始模型相同的泛化误差* 服务提供商可以通过轻微扰动修改任何输入的分类* 构造适用于任何底层模型架构 * 任何计算受限的观察者都无法检测到后门 这对 ML 安全和外包培训具有重大影响。这项工作显示了证明对抗性鲁棒性的根本局限性——一个后门模型可能与一个鲁棒模型无法区分，而每个输入都有对抗性的例子。 TLDR：论文证明可以将无法检测的后门插入 ML 模型中，允许任意操纵输出，同时证明无法检测到。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr4ksm/r_undetectable_backdoors_in_ml_models_novel/</guid>
      <pubDate>Thu, 14 Nov 2024 13:19:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 数据的几何形状：缺失的度量张量和 Stein 分数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr4bfl/r_the_geometry_of_data_the_missing_metric_tensor/</link>
      <description><![CDATA[只是分享一篇文章给那些对微分几何、ML 和基于分数的模型感兴趣的人。我做了一个很长的介绍，然后我展示了如何仅使用 Stein 分数来推导出一个有效的计算数据流形度量张量的方法。    由   提交  /u/perone   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr4bfl/r_the_geometry_of_data_the_missing_metric_tensor/</guid>
      <pubDate>Thu, 14 Nov 2024 13:05:04 GMT</pubDate>
    </item>
    <item>
      <title>基于脉冲神经网络的强化学习模型性能提升建议 [P] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr2x54/advice_for_improving_the_performance_of_my/</link>
      <description><![CDATA[大家好！我正在开展一个项目，专注于使用脉冲神经网络 (SNN) 训练强化学习代理。我的目标是提高模型的性能，尤其是通过“做梦”体验（离线训练）有效学习的能力。 简要项目背景（基于模型的强化学习）： 代理与环境（游戏 Pong）交互，在主动训练阶段（“清醒”）和离线学习的“做梦”阶段之间交替。 问题： 学习速度慢且有些不稳定。我尝试了一些优化，但仍然没有达到预期的性能。具体来说，我注意到增加网络（代理和模型）中的神经元数量并没有提高性能；在某些情况下，甚至会恶化。我降低了模型的学习率，但没有看到任何改进。我还通过在清醒阶段禁用学习来测试模型，以仅查看其在做梦阶段的行为。我发现模型在 1-2 个梦中有所改进，但当达到 3 个梦时性能会下降。 问题：  您是否知道任何可以在 SNN 环境中提高模型稳定性和收敛性的技术？ 您有什么建议或意见吗？ 使用重放缓冲区会有所帮助吗？     提交人    /u/Embri21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr2x54/advice_for_improving_the_performance_of_my/</guid>
      <pubDate>Thu, 14 Nov 2024 11:42:22 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 缩放定律和图神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr2t6l/discussion_scaling_laws_and_graph_neural_networks/</link>
      <description><![CDATA[我偶然发现了一篇介绍第一个“图形基础模型”的论文：https://arxiv.org/pdf/2407.11907 他们表明，GNN 可以随着数据和模型大小而扩展，跨不同领域进行推广，并可以在新数据集上进行有效微调。 这对我来说很有趣，因为即使 LLM 风靡一时，文本也可能是一种弱数据表示。大多数知识都有图形结构。代码、研究论文，甚至人类大脑——都是图形。而下一个标记预测作为归纳偏差并没有利用这一点。 当然，这里有一个巨大的数据瓶颈。但也许下一步是使用 LLM 将互联网上的大量文本转换为图表进行训练。  你们觉得怎么样？    提交人    /u/jsonathan   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr2t6l/discussion_scaling_laws_and_graph_neural_networks/</guid>
      <pubDate>Thu, 14 Nov 2024 11:34:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 实时使用时 EMG MLP 网络出现问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr1yso/d_issue_with_emg_mlp_network_during_realtime_use/</link>
      <description><![CDATA[嘿！ 我正在尝试使用前臂上的 3 个传感器实现 8 种手势的实时 EMG 分类。我使用 Arduino Zero 从每个通道记录数据，并通过 python 将其存储在 csv 文件中。我为每个手势获得了 5 个文件，每个文件包含连续执行 6 次的 6 秒休息/6 秒手势。然后，我使用重叠率为 85% 的 400ms 窗口对数据进行分段，并为每个通道包络提取 7 个时域特征。我为每个类使用了相等数量的缩放特征向量，以使用 keras、sklearn 和 tensorflow（以获得精简模型）训练具有 200 个神经元和 0.2 的 dropout 率的 3 层 MLP，并且在混淆矩阵中，对于 90% 的训练/10% 的测试数据集，我获得了每个手势 90% 以上的准确率。整个过程基于这篇论文，当然也有一些变化：(PDF) 基于肌电图的人工神经网络手势分类 。但是，当我实时使用 MLP 时，它可以准确识别 3 到 4 个手势，而不是 8 个，这是正常的吗？我将在几天内尝试为每个手势记录更多数据并重新训练，但我不确定这是否有太大帮助。 我还尝试通过存储传入数据和生成的特征向量来实时检查我的 python 程序是否存在任何错误，以便将它们与通过离线对存储的实时数据实施过滤、分割和特征提取计算出的向量进行比较，并且它们是相同的，所以我不认为存在实时执行过滤/分割/特征提取错误的问题。 有人遇到过类似的问题吗？我想要实现的是否可行，或者 4 个手势是我能得到的最好的效果吗？我没有找到很多同时分析实时 EMG 分类和机械臂运动的论文，所以我想在这里也问一下，希望我提供了足够的信息。 谢谢！   由    /u/Outrageous_Spare_498  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr1yso/d_issue_with_emg_mlp_network_during_realtime_use/</guid>
      <pubDate>Thu, 14 Nov 2024 10:35:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于（ML）理论申请者来说，计算机科学博士学位的录取竞争力如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gqyj6l/d_how_competitive_are_cs_phd_admissions_for_ml/</link>
      <description><![CDATA[如果我想从事机器学习理论研究（适合 COLT 的工作），而不是主流经验主义、严格的基于实验室的机器学习（NLP、CV...）研究，我是否需要在 NeurIPS/ICLR/COLT/ICML 上发表顶级出版物才能获得前 5 或 10 名 CS 博士录取？被录取的顶级 CS 博士简历非常疯狂，有多篇顶级会议论文。    提交人    /u/wonder-why-I-wonder   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gqyj6l/d_how_competitive_are_cs_phd_admissions_for_ml/</guid>
      <pubDate>Thu, 14 Nov 2024 06:14:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025 论文评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gq8vu6/d_iclr_2025_paper_reviews/</link>
      <description><![CDATA[ICLR 2025 的评论似乎可以在 OpenReview 上找到。欢迎在这里庆祝/抱怨/表达您的评论！ 去年的统计数据这里    提交人    /u/pie3636   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gq8vu6/d_iclr_2025_paper_reviews/</guid>
      <pubDate>Wed, 13 Nov 2024 09:10:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] AMA：我是一家英国公司的人工智能主管，为政府、行业等提供咨询。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gq899s/d_ama_im_head_of_ai_at_a_firm_in_the_uk_advising/</link>
      <description><![CDATA[问我任何有关英国人工智能采用、技术堆栈、如何成为人工智能/机器学习工程师或数据科学家等的问题，以及职业发展等问题。     提交人    /u/Psychological_Dare93   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gq899s/d_ama_im_head_of_ai_at_a_firm_in_the_uk_advising/</guid>
      <pubDate>Wed, 13 Nov 2024 08:20:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>