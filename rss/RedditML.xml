<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 28 Jan 2025 18:21:48 GMT</lastBuildDate>
    <item>
      <title>[D] - 从知识图谱中查询数据的挑战</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ic5q7s/d_challenges_in_querying_data_from_a_knowledge/</link>
      <description><![CDATA[我一直在探索开发知识图谱来处理轮胎添加剂周围的数据，旨在从相关文本中提取有意义的实体和关系。我的主要目标是解决涉及满足多个约束的复杂查询，即使信息源自从不同来源提取的关系（例如，两篇独立的研究论文）。 此外，我还希望提取见解，例如某些添加剂的潜在替代材料。 我特别努力的一个领域是如何有效地处理用户查询。例如，我应该依靠 Cypher 查询来实现精度，以及我应该如何理想地构建和排列知识图中的节点以实现可扩展性和清晰度？ 目前，我正在请求 LLM 提取这种肿瘤学 您是轮胎化学专家 AI，可以从有关轮胎添加剂的文本中提取精确的实体和关系。请遵循以下规则： 允许的实体类型： 1. 轮胎添加剂：例如炭黑、二氧化硅、硫磺。 2. 轮胎特性：例如牵引力、耐久性、柔韧性。 3. 添加剂类别：例如填料、固化剂、抗氧化剂、抗臭氧剂。 4. 轮胎应用：例如赛车轮胎、越野轮胎。 5. 相互作用：添加剂之间的协同作用或拮抗作用。 允许的具有方向性的关系类型：  1. **增强** (添加剂 → 轮胎特性)  2. **减少** (添加剂 → 轮胎属性)  3. **协同** (添加剂 → 添加剂)  4. **对抗** (添加剂 → 添加剂)  5. **属于** (添加剂 → 添加剂类别)  6. **需要** (应用程序 → 轮胎属性)  7. **类似于** (添加剂或属性 → 添加剂或属性)  8. **矛盾** (添加剂或属性 → 添加剂或属性)  9. **用于** (添加剂或类别 → 应用程序)    由    /u/OnlyBadKarma  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ic5q7s/d_challenges_in_querying_data_from_a_knowledge/</guid>
      <pubDate>Tue, 28 Jan 2025 16:39:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有感觉自己在每个 scikit-learn 项目中都在重新发明轮子？让我们来谈谈如何让 ML 推荐做法不那么痛苦。🤔</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ic5e7f/d_ever_feel_like_youre_reinventing_the_wheel_with/</link>
      <description><![CDATA[嗨，各位数据科学家， 虽然 scikit-learn 功能强大，但我们经常会发现：  手动检查交叉验证错误 在 Copilot、StackOverflow 和文档之间来回切换只是为了遵循推荐的做法 重新设计需要为 DS 团队和利益相关者服务的验证流程 笔记本成为模型迭代的坟墓  我很好奇您如何在工作流程中应对这些挑战：  您在不同项目之间进行验证的方法是什么？是否有统一的方法，还是每个项目都有自己的验证风格？ 如何在不使事情过于复杂的情况下跟踪实验？ 您发现了哪些保持一致性的技巧？  我们（可能）已经构建了一个开源库（skore）来解决这些问题，但我希望先听听您的解决方案。哪些工作流程对您有用？什么仍然令人沮丧？  GitHub：github.com/probabl-ai/skore 文档：skore.probabl.ai     提交人    /u/positive-correlation   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ic5e7f/d_ever_feel_like_youre_reinventing_the_wheel_with/</guid>
      <pubDate>Tue, 28 Jan 2025 16:24:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 多类文本分类的最佳模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ic49q4/p_best_model_for_multi_class_text_classification/</link>
      <description><![CDATA[嗨！ 对于一个大学项目，我需要将电视辩论中的陈述分为 5 个类别（为简单起见，我们假设这些类别为 1 到 5）。 我有一个大型标记数据集来训练模型，现在我正在使用 transformer nn，但结果很糟糕。 话虽如此，对于这样的任务我应该测试哪些模型？ 感谢任何帮助 :)    提交人    /u/Admirable-Proof3214   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ic49q4/p_best_model_for_multi_class_text_classification/</guid>
      <pubDate>Tue, 28 Jan 2025 15:36:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从 Github 源代码实现知识提炼</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ic44sy/p_implementing_knowledge_distillation_from_github/</link>
      <description><![CDATA[所以我一直在尝试从头开始实现基于补丁的 KL，但是我得到的 rank-1 结果很差，然后我在 github 上偶然发现了该论文的源代码。 https://github.com/feifeiobama/PatchKD 我正在尝试实现和构建它，以便它可以在一个数据集而不是多个 reid 数据集上进行训练，但我似乎无法让它工作。我在尝试训练时一直收到此错误。 文件 &quot;PatchKD-1\train_test.py&quot;，第 250 行，位于 &lt;module&gt; main(config) 文件 &quot;PatchKD-1\train_test.py&quot;，第 15 行，位于 main loaders = IncrementalReIDLoaders(config) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 文件 &quot;PatchKD-1\pkd\data_loader\incremental_reid_loaders.py&quot;，第 55 行，位于 __init__ assert a_train_dataset in self.datasets, a_train_dataset ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ AssertionError: market1501 如果能给我指明正确方向，我将不胜感激。    提交人    /u/Alone_Willingness_07   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ic44sy/p_implementing_knowledge_distillation_from_github/</guid>
      <pubDate>Tue, 28 Jan 2025 15:30:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对 3 个或更多重叠说话人的说话人分类模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibzhsc/d_speaker_diarization_models_for_3_or_more/</link>
      <description><![CDATA[我正在寻找能够同时识别至少三个（理想情况下更多）重叠说话人的说话人日记模型。我研究了pyannote，但他们的模型似乎只支持同一时间戳的两个重叠说话人，而识别三个或更多说话人需要进行微调。 有人可以推荐一个支持这一点的开放模型吗？我只关心分析每个说话人的讲话时间，以及他们重叠的程度——我想用它来分析政治辩论。谢谢！    提交人    /u/6NBUonmLD74a   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibzhsc/d_speaker_diarization_models_for_3_or_more/</guid>
      <pubDate>Tue, 28 Jan 2025 11:29:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] TTS 数据的超分辨率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibyp6p/d_super_resolution_for_tts_data/</link>
      <description><![CDATA[嗨， 我想使用 16khz 的野生音频来训练 TTS 模型。因此我想将其上采样到 24khz。您会推荐哪种开源模型来执行此任务？ 我尝试了几个：Resemble-Enhance、AudioSR 和 AP-BWE。只要数据量不是太大，AudioSR 似乎是一个不错的选择。我将笔记放入了博客文章。还有什么我应该看的吗？    提交人    /u/clementruhm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibyp6p/d_super_resolution_for_tts_data/</guid>
      <pubDate>Tue, 28 Jan 2025 10:34:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于模型的强化学习和无模型的强化学习有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibyiv6/d_whats_the_difference_between_modelbased_and/</link>
      <description><![CDATA[我试图理解基于模型和无模型强化学习之间的区别。据我所知：  无模型方法直接从真实经验中学习。它们观察当前状态，采取行动，然后以下一个状态和奖励的形式接收反馈。这些模型没有任何内部表示或对环境的理解；它们只是依靠反复试验来随着时间的推移改进其行动。 基于模型的方法则通过创建“模型”或环境模拟来学习。它们不仅仅是对状态和奖励做出反应，还试图模拟未来会发生什么。这些模型可以使用监督学习或学习函数（如 s′=F(s,a)s&#39; = F(s, a)s′=F(s,a) 和 R(s)R(s)R(s)）来预测未来状态和奖励。他们本质上建立了一个环境模型，并用它来规划行动。  因此，关键的区别在于基于模型的方法使用其学习到的模型来近似未来并提前规划，而无模型方法仅通过直接与环境交互来学习，而不尝试模拟它。 这样说对吗，还是我遗漏了什么？    提交人    /u/volvol7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibyiv6/d_whats_the_difference_between_modelbased_and/</guid>
      <pubDate>Tue, 28 Jan 2025 10:21:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有人试过写一份没有参考部分的 CVPR 反驳吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibllko/r_anyone_tried_writing_a_cvpr_rebuttal_without_a/</link>
      <description><![CDATA[我正在准备 CVPR 反驳，由于只允许一个 PDF，我正在考虑删除参考部分。是否可以在论文中引用引文而不在反驳中再次明确列出它们？我知道我不需要引用新论文。 以前有人处理过这种情况吗？如果在反驳中看不到单独的参考部分，审稿人会觉得奇怪或不方便吗？ 寻求建议或见解！    提交人    /u/Training-Adeptness57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibllko/r_anyone_tried_writing_a_cvpr_rebuttal_without_a/</guid>
      <pubDate>Mon, 27 Jan 2025 22:07:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Deepseek R1 精简版本之间的审查差异</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibkckg/d_censorship_differences_in_deepseek_r1_between/</link>
      <description><![CDATA[      一些帖子正在流传Reddit 和其他平台上的提示都显示了 Deepseek R1 中的审查制度。我尝试过它们，但发现了一些有趣的差异，Llama 8B 的限制较少。 （不过，很难说这些差异会持续多久） 我检查了 Llama (8B) 和 Qwen (7B) Distilled 版本。 https://preview.redd.it/rso0bxndrlfe1.png?width=417&amp;format=png&amp;auto=webp&amp;s=592e5eda5568d0b2fadfb19df313946dbbbf9cab 这是不同型号的相同问题： Llama 8B 蒸馏 Qwen 7B 蒸馏 Qwen 7b 蒸馏的审查答案每次都会变化。未经审查的 Llama 8B 似乎很稳定。 话虽如此，Llama 8B 版本仍然显示出一些审查制度和其他问题： Llama 8B destiled    提交人    /u/Total_Firefighter_59   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibkckg/d_censorship_differences_in_deepseek_r1_between/</guid>
      <pubDate>Mon, 27 Jan 2025 21:16:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] Deepseek R1 究竟是如何大幅降低训练成本的？我读到的大多数帖子都是关于它的性能、强化学习、思路链等，但不清楚模型训练成本是如何大幅降低的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibijhg/d_how_exactly_did_deepseek_r1_achieve_massive/</link>
      <description><![CDATA[  由    /u/eyio  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibijhg/d_how_exactly_did_deepseek_r1_achieve_massive/</guid>
      <pubDate>Mon, 27 Jan 2025 20:02:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们如何存储/流式传输 LLM 嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ibe0bm/d_what_do_people_do_for_storingstreaming_llm/</link>
      <description><![CDATA[对于一个学术项目，我想计算每个标记的嵌入，将它们存储在磁盘或内存中，并将它们流式传输以进行快速实验，同时微调模型（比 LLM 小得多）。 有哪些库（db？）、数据结构和最佳实践？一些注意事项：  希望最大限度地减少嵌入计算（成本）。 嵌入是 ~1k 32 位浮点数。 序列通常约为 20-500 个标记。 在模型训练中流式传输预计算嵌入以进行微调。 完整数据集约为 500k 个短语，磁盘上约 4TB（未压缩）。 我的应用程序不存在量化模型。 一些“有意义”的数据集子集可以放入内存（几 GB）。 最终共享数据集以供研究。 开源友好 寻找更标准化与新颖的数据库解决方案（主要是为了长寿）     提交人    /u/LetsTacoooo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ibe0bm/d_what_do_people_do_for_storingstreaming_llm/</guid>
      <pubDate>Mon, 27 Jan 2025 17:02:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么在损失函数（例如线性回归损失函数）中不使用 4、6 等更高的偶数幂？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib3dhn/d_why_higher_even_powers_like_4_6_etc_are_not/</link>
      <description><![CDATA[我们知道奇数幂会导致非凸函数，并且函数也不可微。但是为什么我们不使用偶数幂，例如 4 等？我在一次采访中被问到这个问题，我说也许计算成本会很高，并且会对异常值进行更多惩罚。但他们似乎仍然不满意。我还遗漏了什么其他原因？    提交人    /u/maaKaBharosaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib3dhn/d_why_higher_even_powers_like_4_6_etc_are_not/</guid>
      <pubDate>Mon, 27 Jan 2025 08:17:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepSeek 为什么开源他们的工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/</link>
      <description><![CDATA[如果他们的培训效率提高 45 倍，他们本可以主宰 LLM 市场。你认为他们为什么选择开源他们的工作？这对他们的公司有什么好处？现在美国的大型实验室可以说：“我们将采用他们的优秀想法，并将它们与我们的秘密想法结合起来，我们仍然会领先”  编辑：DeepSeek 现在是 App Store 中排名第一。此外，DeepSeek-R1 现在在 LLM Arena 中排名第一（使用 StyleCtrl）。它们与其他 3 个模型共享此排名：Gemini-Exp-1206、4o-latest 和 o1-2024-12-17。    提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/</guid>
      <pubDate>Mon, 27 Jan 2025 07:48:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>