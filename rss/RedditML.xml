<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 25 Jan 2024 21:11:32 GMT</lastBuildDate>
    <item>
      <title>[讨论]YOLO揭秘：清晰指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fistr/discussion_yolo_unraveled_a_clear_guide/</link>
      <description><![CDATA[OpenCV.ai 团队发布了一篇关于 Yolo 的新文章。我希望您能很好地理解它。这篇综合指南提供了对最新 YOLO 模型和算法比较的见解，帮助开发人员和研究人员为他们的项目选择最有效的解决方案。这篇文章是此处 &lt; !-- SC_ON --&gt;  由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/MachineLearning/comments/19fistr/discussion_yolo_unraveled_a_clear_guide/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fistr/discussion_yolo_unraveled_a_clear_guide/</guid>
      <pubDate>Thu, 25 Jan 2024 20:21:12 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士作为通用模式机 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fhe8f/llms_as_general_pattern_machines_r/</link>
      <description><![CDATA[        由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fhe8f/llms_as_general_pattern_machines_r/</guid>
      <pubDate>Thu, 25 Jan 2024 19:21:58 GMT</pubDate>
    </item>
    <item>
      <title>[D]我们如何保持如此幸运？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fhdck/d_how_do_we_keep_getting_so_lucky/</link>
      <description><![CDATA[ML 很难——这是一个非常难的领域，而 DeepMind/OpenAI/insert 公司的研究人员都是天才。甚至他们也很难理解定义机器学习的模型是如何工作的。 这让我想知道......“我们如何保持如此幸运？”双血统、grokking、法学硕士的出现——做出这些发现的人绝对是聪明的，但事实上它们的存在感觉就像是非常幸运的。就好像癌症研究人员突然发现所有癌症都具有这种特定标记并且可以轻松地使用某种标准药物来瞄准该标记并且它可以在短时间内完全治愈所有癌症几年。 即使是变形金刚，这是一种非常聪明的使用注意力的方式，也真的非常非常好，我什至不认为写“注意力就是你所需要的一切”的人会这样做。论文可以想象它们对机器学习产生的巨大影响。 我不知道我是否过于怀疑，但所有这一切似乎好得令人难以置信。我们已经取得了如此多的发现，但除了“像这样的矩阵相乘很酷”之外，我们对其中的许多发现几乎没有任何解释。到底是怎么回事？我是误解了还是描述了真实的东西？   由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fhdck/d_how_do_we_keep_getting_so_lucky/</guid>
      <pubDate>Thu, 25 Jan 2024 19:20:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 漫画（Bande Dessinée、Manga、Webtoons 等）自动翻译，具有语音气泡检测、文本分割、OCR 和修复功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fge55/p_automatic_translation_of_comics_bande_dessinée/</link>
      <description><![CDATA[      我想分享我一段时间以来所做的工作。一个 python 桌面应用程序，用于自动翻译多种格式（图像、Pdf、Epub 和漫画书档案）和多种语言的漫画。它使用我训练的 2 个 yolov8 模型来进行检测和分割，一套根据语言进行 OCR 的模型，以及一个用于修复的微调喇嘛检查点。  repo - https://github.com/ogkalu2/comic-translate GUI https:/ /preview.redd.it/1gq7j7r8smec1.png?width=576&amp;format=png&amp;auto=webp&amp;s=29790a1c2768ee274ade20945ba0ee9edfe0ba5a ​ &amp;# x200b;   由   提交/u/MysteryInc152   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fge55/p_automatic_translation_of_comics_bande_dessinée/</guid>
      <pubDate>Thu, 25 Jan 2024 18:39:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自监督模型在预训练后抛出的参数方面如何比较？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ff9rk/d_how_do_selfsupervised_model_compare_in_terms_of/</link>
      <description><![CDATA[特别是在视觉的掩模图像建模和对比学习中，您可以采用编码器-解码器架构，然后在其中删除/取消解码器预训练，或者以 MLP 的形式附加一两个投影头来处理编码器的输出。在 MIM 和 CL 以及 ConvNet 和 ViT 中最常用的模型中，这些模块中参数的绝对和相对数量是多少？您是否知道专门解决此问题、选择及其在训练轨迹、学习偏差和不变性、下游性能等方面可能意味着什么的研究？  &amp; #32；由   提交/u/reverendCappuccino   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ff9rk/d_how_do_selfsupervised_model_compare_in_terms_of/</guid>
      <pubDate>Thu, 25 Jan 2024 17:52:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 处理大数据帧以进行特征提取</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19feb36/p_dealing_with_large_dataframe_for_feature/</link>
      <description><![CDATA[我正在开发一个 ML 项目，用于检测使用 CNC 铣削制造产品时的异常情况。  我们已经对数据进行了预处理，现在尝试在执行 PCA 后使用 tsfresh 提取多变量时间序列数据的特征，但是在大量数据帧（大约 167240000x6 和 240000000x6）期间，它花费了太多时间即使在我的 32 GB RAM、i13900H 处理器上也需要花费大量时间。 花费大量时间是否正常，或者是否有更好的替代方法来提取特征？如果需要更多信息来回答我的问题，请告诉我，提前谢谢您。   由   提交/u/Compliance-Way227   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19feb36/p_dealing_with_large_dataframe_for_feature/</guid>
      <pubDate>Thu, 25 Jan 2024 17:12:57 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 大数据集下载</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fcjcu/discussion_big_data_set_downloads/</link>
      <description><![CDATA[在处理像 ImageNet 这样的大数据集时，通常的工作流程是什么？我在我的 M1 mac 上下载了该文件，现在正在解压该文件等，但这显然需要很长时间才能完成。机器学习社区的人们是否只是忍受了这么长时间，还是有一种奇怪的方法来加载数据集以通过云服务或其他方法进行快速测试？我是新人，正在努力学习，所以请注意基本问题。谢谢。   由   提交 /u/EasternPiglet7093   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fcjcu/discussion_big_data_set_downloads/</guid>
      <pubDate>Thu, 25 Jan 2024 15:57:05 GMT</pubDate>
    </item>
    <item>
      <title>[研究]WhisperFusion：与人工智能聊天机器人的超低延迟对话</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fchit/research_whisperfusion_ultralow_latency/</link>
      <description><![CDATA[通过使用完全开源的工具 WhisperLive &amp; 创建实时 AI 聊天机器人通信系统。 WhisperSpeech，Collabora 的工程师解决了当前机器人交互中的不自然延迟问题，以实现无缝对话。 https://www.collabora.com/news-and-blog/news-and-events/whisperfusion-ultra-low- Latency-conversations-with-an-ai-chatbot.html   由   提交 /u/mfilion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fchit/research_whisperfusion_ultralow_latency/</guid>
      <pubDate>Thu, 25 Jan 2024 15:54:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练 LSTM 模型的正确方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fajpe/d_proper_way_to_train_an_lstm_model/</link>
      <description><![CDATA[我还没有找到训练 LSTM 的正确方法以及原因的解释。因此我问这个问题。 假设我们有股票价格等连续数据。 LSTM可以将前N天的价格作为输入，然后输出一个向量。将此向量输入一个简单的神经网络将为我们提供第 (N+1) 天的价格估计。 训练后，在使用模型进行推理时，我们将预测更多比一天向前。为了训练模型，我们可以获取前 2 天的股票价格并预测第 3 天。然后使用前3天的实际数据来预测第4天（因此第3天的预测在这里不起作用）。等等。然后我们测量所有预测与实际数据之间的距离，并将这种损失最小化。但是，如果我这样做，那么我本质上是要求模型擅长预测仅未来一天。这看起来不太理想。 我可以改变训练方法：我可以使用前10天来预测第10-20天，计算损失，然后使用前20天的实际数据（不是预测）来预测第20-40天。但这些听起来都太随意，不系统。对此有一些一般性建议吗？   由   提交 /u/speedy-spade   /u/speedy-spade  reddit.com/r/MachineLearning/comments/19fajpe/d_proper_way_to_train_an_lstm_model/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fajpe/d_proper_way_to_train_an_lstm_model/</guid>
      <pubDate>Thu, 25 Jan 2024 14:27:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您经常遇到哪些令人尴尬的并行工作负载（没有节点间通信）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19faakw/d_what_embarrassingly_parallel_workloads_do_you/</link>
      <description><![CDATA[目前，几周后就会发布一个开源工具，该工具使大规模并行计算变得极其容易。  当我发布它时，我想要一些有用的教程。我想知道您认为我应该为哪些令人尴尬的并行用例创建教程？如果您可以在不需要任何配置的情况下运行 25k 个并行工作线程，您将运行哪些作业？    由   提交/u/Ok_Post_149   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19faakw/d_what_embarrassingly_parallel_workloads_do_you/</guid>
      <pubDate>Thu, 25 Jan 2024 14:15:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用全同态加密 (FHE) 在加密数据上训练 ML 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19f5z25/p_training_ml_models_on_encrypted_data_with_fully/</link>
      <description><![CDATA[大家好！  我们已经使用 FHE 成功地训练了加密数据的机器学习模型，确保了整个训练过程中最高级别的隐私。  这是解锁数据隐私至关重要的医疗保健和金融等领域的安全协作培训和模型微调等用例的关键一步。  为了让您了解预期的性能，我们可以在大约一个小时内训练一个具有 10 个特征和 10,000 行的模型。更重要的是，训练时间与特征和示例的数量呈线性关系。  您还可以在这里查看我们的库，因为我们所做的一切都是开源的：https: //github.com/zama-ai/concrete-ml 很高兴听到您对此的想法和想法！   由   提交 /u/strojax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19f5z25/p_training_ml_models_on_encrypted_data_with_fully/</guid>
      <pubDate>Thu, 25 Jan 2024 10:02:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] Scikit-Learn 修复了 F-1 分数计算器；你应该现在更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19f0o8f/d_scikitlearn_fixed_its_f1_score_calculator_you/</link>
      <description><![CDATA[Scikit-Learn 1.3.x 的 F-1 分数计算器有一个错误，该错误已在最新版本（上周发布的 1.4.0）中修复），当 zero_division 参数设置为 0.0 或 np.nan 时，可能会产生错误的分数，例如：  &lt;代码&gt;&gt;&gt; sklearn.__version__&#39;1.3.2&#39;&gt;&gt;&gt;&gt; sklearn.metrics.f1_score(y_true=[0, 0, 1, 2, 3], y_pred=[0, 1, 0, 2, 3], Zero_division=1.0,average=“宏”) 0.875 # 错误  与。 （完全相同的输入） &gt;&gt;&gt; sklearn.__version__&#39;1.4.0&#39;&gt;&gt;&gt;&gt; sklearn.metrics.f1_score(y_true=[0, 0, 1, 2, 3], y_pred=[0, 1, 0, 2, 3], Zero_division=1.0,average=“宏”) 0.625 # 正确  这里是我的博客文章解释了该错误更多详细信息，以及修复该错误的拉取请求。如果您使用 Scikit-Learn 计算 F-1，您应该升级并仔细检查之前计算的 F-1 分数；考虑到真正的 F-1，看起来更好的分类器很容易比替代品差得多。   由   提交/u/Revolutionary-Ad-65   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19f0o8f/d_scikitlearn_fixed_its_f1_score_calculator_you/</guid>
      <pubDate>Thu, 25 Jan 2024 04:15:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 注意力之谜：哪个是哪个 - q、k 或 v？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ewfm9/d_attention_mystery_which_is_which_q_k_or_v/</link>
      <description><![CDATA[我终于开始了解注意力机制了，但有一点仍然让我困惑：q、k 和 v 背后的矩阵魔法。&lt; /p&gt; 我在理论层面上了解了整个矩阵乘法，但是什么数学属性实际上决定了哪个矩阵成为查询（q），即键 (k) 和值 (v)？这只是一些随机分配，还是有更深层次的逻辑在起作用？  这是我到目前为止收集到的内容：  所有三个矩阵都来自相同的输入数据，但神奇地呈现出不同的“个性”。在注意方程 (qkt)v 中。 我猜测它们的维度和相互作用一定发挥了作用，但除此之外，它是模糊的。  机制框图对于图片 https://upload.wikimedia .org/wikipedia/commons/thumb/8/81/Attention-qkv.png/799px-Attention-qkv.png   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ewfm9/d_attention_mystery_which_is_which_q_k_or_v/</guid>
      <pubDate>Thu, 25 Jan 2024 00:44:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 视觉变压器比新生视觉系统更需要数据吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19er4pp/r_are_vision_transformers_more_data_hungry_than/</link>
      <description><![CDATA[ 由   提交 /u/currentscurrents   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19er4pp/r_are_vision_transformers_more_data_hungry_than/</guid>
      <pubDate>Wed, 24 Jan 2024 20:59:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>