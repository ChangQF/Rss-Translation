<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 21 Feb 2024 09:15:13 GMT</lastBuildDate>
    <item>
      <title>[D] 你如何评估模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aw7sc0/d_how_do_you_evaluate_models/</link>
      <description><![CDATA[在我自己的大部分实验以及这里的大部分帖子中，我看到了两种评估模型的方法之一：  基准：这从来没有真正“奏效”过。对我来说，因为我不关心一般能力，所以我关心模型是否擅长我的特定任务。另外，有很多模型声称“击败了 GPT-3.5”。或者其他什么，但是当你尝试它们时，它们只会感觉更糟。 氛围检查：只是玩弄模型并看看它的感觉如何。但这不是很系统，而且我并不真正相信自己的判断是一致的。有时我尝试通过定义一组测试问题来系统化这一点，但在盯着输出表几分钟后，我的思维就变得麻木了。  所以我想知道：你们如何处理这个问题？您对目前的评估状态满意吗？   由   提交 /u/UpvoteBeast   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aw7sc0/d_how_do_you_evaluate_models/</guid>
      <pubDate>Wed, 21 Feb 2024 09:13:13 GMT</pubDate>
    </item>
    <item>
      <title>[D]通过构建一些 GPU 来部署 AI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aw7nmq/ddeploy_ai_by_building_a_few_gpus/</link>
      <description><![CDATA[      大家好，我又来向大家请教一些gpu的问题，希望大家能帮我解答一下。  ​ 问题是我之前询问过在服务器上部署easyocr的问题但是遇到了硬件无响应的错误，所以现在打算通过在服务器上安装gpu来升级服务器。 （让我们看看它是如何运行的）。我对 gpu 没有太多经验，因为我一直在 colab 上使用免费的。 ​ 现在我想用 gpu 进行测试（成本约为 500 美元） ），谁能给我推荐一个合适的吗？如果没有，请给我一些密钥和一些重要参数，以便我进行搜索。 ​ 这些是我的服务器 CPU 规格：Intel(R) Xeon(R) CPU E5-2670 v2 @ 2.50GHz ​ 我做了一些研究，发现nvidia目前在市场上占据主导地位，并且只支持cuda，我查了一下有一个nvidia tesla的线专门用于AI，但我在网上看到它不适合。安装在普通服务器上，因为它不支持。 ​ 最后，我想知道特斯拉 p40，但它是基于 Pascal 架构的，我读了小组中某人的帖子，询问 ppocr 不允许再使用此架构。有点可惜，因为我现在非常重视 vram 参数（我认为 vram 越大，就越能避免内存中断 - 因为我可能最常遇到这个错误）。我还根据群里另一个人的帖子检查了 RTX 3060，但我发现它相当弱（12gb vram）。 ​ 我的想法是正确的方向？谢谢。 https:// Preview.redd.it/e9rd50a9mwjc1.jpg?width=590&amp;format=pjpg&amp;auto=webp&amp;s=491e2c27d8106d967c4e808ebb654b3c1e67ab2e   由   提交/u/quyet12306   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aw7nmq/ddeploy_ai_by_building_a_few_gpus/</guid>
      <pubDate>Wed, 21 Feb 2024 09:04:14 GMT</pubDate>
    </item>
    <item>
      <title>如何创建用于修改服装的图像处理图像 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aw65zn/how_to_create_an_image_processing_image_for_dress/</link>
      <description><![CDATA[模型的目的是获取人和衣服的图片，然后结果输出将是穿着衣服的人。然后它还有一个很酷的功能，就是人可以改变走路的姿势等等。 改变标题，图像处理模型   由   提交/u/No-Space-7  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aw65zn/how_to_create_an_image_processing_image_for_dress/</guid>
      <pubDate>Wed, 21 Feb 2024 07:25:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] VisionMamba 模型无法学习数据集 - 该怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aw63kg/d_visionmamba_model_not_learning_the_dataset_what/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aw63kg/d_visionmamba_model_not_learning_the_dataset_what/</guid>
      <pubDate>Wed, 21 Feb 2024 07:21:08 GMT</pubDate>
    </item>
    <item>
      <title>VideoPrism：用于视频理解的基础视觉编码器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aw4abn/videoprism_a_foundational_visual_encoder_for/</link>
      <description><![CDATA[ 由   提交/u/ashvar  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aw4abn/videoprism_a_foundational_visual_encoder_for/</guid>
      <pubDate>Wed, 21 Feb 2024 05:36:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您建议亲自参加人工智能会议吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avzt7o/d_do_you_recommend_attending_ai_conferences_in/</link>
      <description><![CDATA[我的论文在 COLING 2024 中被接受。它是混合开放的，因此我也可以虚拟参加。 您对此有何看法亲自参加的好处？  我正在认真考虑它，因为这可能是我第一次也是最后一次在人工智能会议上发表文章。 您的经历如何？   由   提交 /u/Empty_Fee8023   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avzt7o/d_do_you_recommend_attending_ai_conferences_in/</guid>
      <pubDate>Wed, 21 Feb 2024 01:55:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] Apple 更快的法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avz6ns/r_faster_llm_from_apple/</link>
      <description><![CDATA[为了大胆创新，Apple 决定与世界分享他们的突破性技术   由   提交/u/Ok-Teaching6610   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avz6ns/r_faster_llm_from_apple/</guid>
      <pubDate>Wed, 21 Feb 2024 01:26:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] Apple 的更快的法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avyqf1/r_faster_llms_from_apple/</link>
      <description><![CDATA[Apple 开源推测流技术可加速设备上的 LLM    ;由   提交/u/Ok-Teaching6610   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avyqf1/r_faster_llms_from_apple/</guid>
      <pubDate>Wed, 21 Feb 2024 01:05:42 GMT</pubDate>
    </item>
    <item>
      <title>[N] 流浪小猪饼干来到Zuse研究所，研究用于原子和分子建模的图形处理器。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avverg/n_biscuit_the_wandering_piglet_arrived_at_the/</link>
      <description><![CDATA[   大家好！来认识一下饼干，一只玩具小猪，它通过从一个旅行者到另一个旅行者的传递而环游世界。 Biscuit 最近与来自日内瓦的科学家一起访问了柏林 Zuse 研究所，参加了“原子和分子建模未来高性能计算的前景和挑战”会议。在那里，Biscuit通过聆听所有讲座并检查超级计算机中使用的GPU，认真地探讨了这个话题。 接下来，他将前往日内瓦，与CERN的科学家一起参观大型强子对撞机。&lt; /p&gt; ——------------------------ 一些背景故事：不久前，我来了有了创造玩具的想法。它的名字叫饼干，是我和妻子制作的一只迷人的小猪。 Biscuit的使命是环游世界，从一只手传递到另一只手。通过这个项目，我的目标是连接全球各地的人们，展示我们星球的美丽，分享各地的精彩故事和事实。 为此，我们创建了一个 Instagram 页面 https://www.instagram.com/biscuitroams/ 此处将发布 Biscuit 的所有更新和冒险。另外，我会在Imgur和Reddit上整理并发布完整的故事。 Biscuit还有一个小背包，参与者可以通过它交换来自不同国家的小纪念品和磁铁！ Biscuit有他的旅程才刚刚开始，目前我们只有很少的志愿者来陪伴他。如果你有喜欢旅行的朋友，也许他们会想带上Biscuit一起去！ 是的，而且Biscuit很小，站立时全高只有18厘米。他可以轻松放入公文包中，而且他的小公文包上有一个登山扣，因此可以牢固地固定他。   由   提交 /u/Dangerous-Annual-511   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avverg/n_biscuit_the_wandering_piglet_arrived_at_the/</guid>
      <pubDate>Tue, 20 Feb 2024 22:46:59 GMT</pubDate>
    </item>
    <item>
      <title>有哪些开源库可以帮助我在构建 LLM 应用程序时轻松地在 LLM 之间切换？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avryf1/any_open_source_libraries_that_can_help_me_easily/</link>
      <description><![CDATA[我一直在构建使用 LLM 和 RAG 的开源工具，但是，有大量的 LLM 模型和框架可供选择，包括OpenAI、Huggingface、AzureOpenAI 等。为每个类编写新类和扩展可能很困难。我很好奇是否有更简单的方法，例如将最大数量的 LLM api 统一在一个工具/框架下，这样我就不必为所有内容编写一个新类？  在这些情况下你通常会做什么？   由   提交 /u/metalvendetta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avryf1/any_open_source_libraries_that_can_help_me_easily/</guid>
      <pubDate>Tue, 20 Feb 2024 20:30:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kaggle 数据集与实际表格数据 - 痛苦的认识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avq8uz/d_kaggle_datasets_vs_actual_tabular_data_bitter/</link>
      <description><![CDATA[经过多年在 Kaggle 或其他平台上的表格数据集的工作和实践，我终于开始使用来自大学医院的表格数据，就像一滩污垢花了一整天的时间才找到正确的标题并链接所有这些表间公式和过滤器。另一方面，我花了最多。 Kaggle 数据集上的 EDA 需要 30 分钟。  我被告知了其中的差异，但意识到 DS 必须处理什么混乱。总是低估它，跳过与之相关的研讨会，还随意取笑它（我通常处理图像和视频）。   由   提交 /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avq8uz/d_kaggle_datasets_vs_actual_tabular_data_bitter/</guid>
      <pubDate>Tue, 20 Feb 2024 19:23:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 其他流行/宣布的扩散变压器产品，如 Sora？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avht7j/d_other_popularannounced_diffusion_transformer/</link>
      <description><![CDATA[虽然 Sora 引起了不小的轰动，但还有哪些其他已知、流行/宣布的产品使用类似的模型架构？ &lt; !-- SC_ON --&gt;  由   提交 /u/CodeComedianCat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avht7j/d_other_popularannounced_diffusion_transformer/</guid>
      <pubDate>Tue, 20 Feb 2024 13:36:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文解释：V-JEPA：重新审视特征预测以从视频中学习视觉表示（视频分析）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aveqx4/d_paper_explained_vjepa_revisiting_feature/</link>
      <description><![CDATA[https://youtu.be/7UkJPwz_N_0 V-JEPA 是一种仅使用潜在表示预测作为目标函数来进行视频数据无监督表示学习的方法。 概要： 0:00 - 简介&lt; /p&gt; 1:45 - 预测特征原理 8:00 - （广告）权重和权重结构化 LLM 输出偏差课程 9:45 - 原始 JEPA 架构 27:30 - V-JEPA 概念 33:15 - V-JEPA架构 44:30 - 实验结果 46:30 - 通过解码进行定性评估 ​ 博客：&lt; a href=&quot;https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/&quot;&gt;https://ai.meta.com/ blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/ 论文：https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning- Visual-representations-from-video/ ​ 摘要： 本文探讨了特征预测作为一个独立的目标用于从视频进行无监督学习，并引入了 V-JEPA，这是一组仅使用特征预测目标进行训练的视觉模型集合，不使用预训练的图像编码器、文本、负例、重建或其他监督来源。这些模型使用从公共数据集中收集的 200 万个视频进行训练，并针对下游图像和视频任务进行评估。我们的结果表明，通过预测视频特征进行学习可以产生多功能的视觉表示，在基于运动和外观的任务上表现良好，而无需调整模型的参数；例如，使用我们最大的模型、仅在视频上训练的 ViT-H/16 冻结骨干网，在 Kinetics-400 上获得 81.9%，在 Something-Something-v2 上获得 72.2%，在 ImageNet1K 上获得 77.9%。 &lt; p&gt;​ 作者：Adrien Bardes Quentin Garrido Xinlei Chen Michael Rabbat Yann LeCun Mido Assran Nicolas Ballas Jean Ponce    ;由   提交/u/ykilcher  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aveqx4/d_paper_explained_vjepa_revisiting_feature/</guid>
      <pubDate>Tue, 20 Feb 2024 10:42:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数学家会在未来的机器学习研究中占据上风吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1av5gwy/d_will_mathematicians_have_the_upper_hand_in/</link>
      <description><![CDATA[似乎在各个角落我都看到了关于做研究的类似情绪。人们尝试各种事物的组合来获得渐进式的改进。我认为下一步的飞跃需要大量的理论知识来指导方向。   由   提交 /u/planetofthemushrooms   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1av5gwy/d_will_mathematicians_have_the_upper_hand_in/</guid>
      <pubDate>Tue, 20 Feb 2024 01:46:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>