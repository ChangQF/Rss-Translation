<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 18 May 2024 03:15:07 GMT</lastBuildDate>
    <item>
      <title>[D] 与训练前相比，SFT 的梯度范数更高，但损失更低，为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cunrbn/d_sft_has_higher_grad_norm_but_lower_loss/</link>
      <description><![CDATA[最近，我一直在使用带有 2B 个 token 的自定义语料库对 OpenELM-1.1B 进行持续预训练，然后使用带有 4M 个样本的自定义指令数据集对其进行微调。 我发现，在使用类似数量的 token 进行训练时，PT 的损失（训练和评估）始终高于 SFT 阶段，但 SFT 的梯度范数高于 PT。 我假设预训练模型在这个自定义域上的 ppl 较低，因此在 SFT 阶段的损失较低。我的问题是，是什么导致 SFT 阶段的梯度范数更高？    提交人    /u/pha123661   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cunrbn/d_sft_has_higher_grad_norm_but_lower_loss/</guid>
      <pubDate>Sat, 18 May 2024 03:11:26 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证训练/验证图 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cumxxs/cross_validation_trainvalidation_graphs_d/</link>
      <description><![CDATA[我们经常看到的模型评估的一个常见趋势是使用交叉验证 CV。作者经常报告从这种方法得出的准确性和其他指标（f-measure、精度等）。除此之外，他们还绘制了损失和准确性的训练和验证图以及混淆矩阵。我的问题是这些图表是如何生成的。它们是使用 k 次交叉验证来绘制的，还是有其他方法在起作用？论文中的示例如下：链接到示例    由   提交 /u/PerfecttMachine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cumxxs/cross_validation_trainvalidation_graphs_d/</guid>
      <pubDate>Sat, 18 May 2024 02:26:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对我的用例的标签软件建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1culhaw/d_labeling_software_advice_for_my_use_cases/</link>
      <description><![CDATA[我正在寻找软件来帮助我对 DICOM 数据集（图像和电影（电影））进行分段和分类，最初是 2D，但后来可能是CT/MRI 也是如此，还允许我对程序视频进行注释。因为我需要跟踪如此多的图像（包括我想在分析中使用/从给定系列中排除哪些图像，并跟踪患者属性），所以数据管理是我需要的一个重要部分。以及将工作量分配给其他贴标机的能力（但可能不会超过 3-4 个其他人）... 您能否分享一下您对其他软件（例如 CVAT、Encore、Labelbox、等等。 提前非常感谢。我希望我可以从您的经验中学习，让这件事变得尽可能“简单”，我没有本地人可以向我提供建议...  &amp;# 32；由   提交/u/mbb100  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1culhaw/d_labeling_software_advice_for_my_use_cases/</guid>
      <pubDate>Sat, 18 May 2024 01:09:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何只保留前 10K 个最常见的 token（transformers 库）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cukc34/p_how_to_keep_only_the_top_10k_most_common_tokens/</link>
      <description><![CDATA[我正在关注 TinyStories 数据集论文它声称“我们使用 GPT-Neo 标记器，但只保留前 10K 个最常见的标记”。我正在尝试创建自己的标记生成器来执行此操作，但意识到我没有合并文件 - 删除顶部标记无法在不重新训练的情况下处理丢失的字节对编码。我对此的理解不是很好，我询问了 GPT，它表明忽略它并使用旧文件而不删除顶部标记并不是一个好主意。  当查看 Huggingface 时，他们的合并和词汇使用了完整的 50k 标记，所以我对如何实现这一点有点困惑。谢谢！   由   提交 /u/Bradmcstark   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cukc34/p_how_to_keep_only_the_top_10k_most_common_tokens/</guid>
      <pubDate>Sat, 18 May 2024 00:10:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将语义学者 bibtex 输出与 ACL 选集关联起来的 Python 脚本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cujsvt/p_python_script_to_correlate_semantic_scholar/</link>
      <description><![CDATA[https://github.com /Ghost---Shadow/anthology-porter 我构建了一个 Python 脚本，它以语义学者 bibtex 作为输入，并将其与 ACL 选集相关联。 EMNLP 需要 ACL 选集格式的引用，手动关联有点麻烦，所以我为它创建了一个脚本。 请尝试一下，如果发现任何误报，请告诉我/底片。   由   提交 /u/GhostxxxShadow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cujsvt/p_python_script_to_correlate_semantic_scholar/</guid>
      <pubDate>Fri, 17 May 2024 23:45:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 改进财务文件中表格数据提取：使用 GPT-4o 和 Pathway 的多模态 RAG</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cug8iw/p_improving_table_data_extraction_from_financial/</link>
      <description><![CDATA[嘿r/MachineLearning，我&#39;我分享了一个关于我们如何通过在解析和回答阶段使用 GPT-4o 来提高具有表格和图表等视觉元素的文档的 RAG 准确性的展示。 它由几个部分组成： 数据索引管道（增量）：  我们在解析过程中将表格提取为图像。 GPT-4o 解释了内容表格的详细信息。 然后，表格内容与文档块一起保存到索引中，以便于搜索。  问题解答：&lt; /strong&gt; 然后，问题将连同相关上下文（包括解析的表格）发送给法学硕士以进行问答。 结果： 我们的方法在基于表格的问题上优于传统的 RAG 工具包。为了证明这一点，我们使用了从 Alphabet 的 10K 报告中得出的一些示例问题，该报告包含许多表格。 架构图：https://github.com/pathwaycom/llm-app/blob/main/examples/pipelines/gpt_4o_multimodal_rag/gpt4o .gif  存储库：https://github.com/pathwaycom/llm-app/tree/main/examples/pipelines/gpt_4o_multimodal_rag/ 我们正在努力扩展此项目，很乐意接受评论!   由   提交 /u/dxtros   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cug8iw/p_improving_table_data_extraction_from_financial/</guid>
      <pubDate>Fri, 17 May 2024 21:03:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师，您工作的哪一部分侧重于部署管道与模型构建/调整？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cub74b/d_machine_learning_engineers_what_portion_of_your/</link>
      <description><![CDATA[我目前是一名机器学习工程师，但我更加关注管道，这与我担任数据工程师时类似。我很想更多地了解模型构建方面的知识，但自从我完成硕士学位以来，我的模型知识已经有点生疏了。  与模型构建相比，您日常工作的哪一部分侧重于部署？   由   提交/u/RawCS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cub74b/d_machine_learning_engineers_what_portion_of_your/</guid>
      <pubDate>Fri, 17 May 2024 17:32:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 就方法论监督寻求建议：纠正错误并寻求清晰度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cu8qib/r_seeking_advice_on_a_methodological_oversight/</link>
      <description><![CDATA[大家好， 我正在分享最近作为一名博士生的经历，并寻求有关解释我们研究中方法论监督的建议. 经过反思我们最近提交的一篇论文（我已经提交了相机就绪版本），我意识到我们犯了一个方法论错误。具体来说，我们使用了从测试集派生的验证集，这可能会在我们的结果中引入偏差，因为我们拥有异构数据集（训练和测试数据集来自不同的来源）。我们监控了验证集的准确性并将其用于早期停止。但正确的方法是从训练集中制作验证集，对吧？我很困惑，因为我读到在某些情况下，有些人出于相同的目的使用验证集和测试集。 令我惊讶的是，我的合著者和三位审稿人在同行评审期间都没有发现这个错误过程。我的合著者和审稿人发现错误的监督是否意味着可以淡化其严重性？ 此外，我们对五项测试进行了测量以平均我们的结果 - 但我不确定这是否有帮助减轻错误的影响。我们将非常感谢您对此事的意见。 我准备在演示过程中提及此错误以提高透明度，但我觉得有点愚蠢。 编辑：使用该验证集是否提前停止并没有改变我们的模型对未见数据的鲁棒性。那么...这个错误可以忽略不计吗？   由   提交 /u/TerminalFrauduleux   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cu8qib/r_seeking_advice_on_a_methodological_oversight/</guid>
      <pubDate>Fri, 17 May 2024 15:53:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 子空间嵌入与基本降维有何不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cu8is4/d_how_are_subspace_embeddings_different_from/</link>
      <description><![CDATA[我一直在努力理解更基本的降维技术与更高级的方法有何不同，主要是关于子空间、流形等的直觉是否相同。扩展到更基本的方法。我了解 PCA、t-SNE、UMAP 等如何工作（这些是在寻找维数降维时出现的 90% 的内容），但是当我阅读有关子空间聚类、流形学习或该领域的内容时，他们很少提及这些更基本的暗淡缩减技术，而是选择更高级的方法，我不确定为什么，特别是考虑到 PCA、t-SNE 和 UMAP 似乎是多么多产。 我不清楚像 PCA 这样的东西是否/如何不同于流形学习，特别是它们对于子空间聚类的有用性。我认为两者的目标都是找到一些潜在结构，直觉上在潜在空间中工作将减少噪音、无用/低信息特征，减少维数灾难，并且还可能更清楚地显示特征和标签的情况连接在潜在空间中。就实际算法而言，我理解直觉，但不知道它们是否是“真实的”。例如，在流形学习的情况下（FWIW，我真的不再看到任何相关论文，也不知道为什么会这样），一个常见的例子是“面流形”。对于图像来说，这是一个比原始输入尺寸低的平滑表面，并且从每个面平滑过渡到另一个面。对于图像来说，这可能有点微不足道，但是对于一般的时间序列数据，同样的直觉是否也适用？  例如，如果我有一个时间序列毛毛虫运动的数据集，我可以任意说存在毛毛虫尺寸的流形（较大的毛毛虫移动速度较慢）或毛毛虫能力的流形（例如，某种类型）能力/技能的多样性，如果毛毛虫正在完成任务/迷宫）？非常人为的例子，但基本上问题是，我是否一定能够根据我的先验告诉我应该存在/可能持有潜在结构（给定足够的数据）找到潜在空间？ &lt; p&gt;我知道 Yann LeCun 是在潜在空间中工作的大力支持者（尤其是联合嵌入，我不确定这是否适用于我和我的时间序列数据），所以我尝试更多地开展我的工作那个方向，但似乎基本 PCA 和基本非线性技术（例如，您会看到内置于 scipy 或 sklearn 等的技术）与其他论文中使用的技术之间存在很大分歧。 PCA（或基本非线性方法）等是否能实现相同的效果，但效果却不那么好？   由   提交 /u/Amun-Aion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cu8is4/d_how_are_subspace_embeddings_different_from/</guid>
      <pubDate>Fri, 17 May 2024 15:44:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 PubLayLet 或 DocLayNet 上微调 DiT 的权重</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cu71km/d_weights_for_dit_finetuned_on_publaylet_or/</link>
      <description><![CDATA[    &lt; /a&gt;  大家好， 我正在寻找权重（最好是训练检查点） ）用于使用 DiT 构建的对象检测模型，该模型经过微调以识别文档布局。就像我附加的图片一样：  https://preview.redd.it/mculpv0l101d1.png?width=601&amp;format=png&amp;auto=webp&amp;s=2db28aa8fa05c1480418f46956fce731fbba3a1f 感谢任何可以提供帮助的人:)   由   提交 /u/ToeIntelligent4472   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cu71km/d_weights_for_dit_finetuned_on_publaylet_or/</guid>
      <pubDate>Fri, 17 May 2024 14:45:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 FER-2013 数据集进行实时情绪分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctzd0a/p_real_time_emotion_classification_with_fer2013/</link>
      <description><![CDATA[所以我正在一家公司做实习项目，正如标题所说。我基本上需要将人脸分为 7 类 - 愤怒、厌恶目前，我正在努力在 FER 2013 数据集上获得良好的准确性，然后我将转向实时捕获部分 我需要在大约 2 周的时间内完成这个项目。我尝试过使用 mobile_net、VGG19、ResNet50、Inception、Efficient_net 等模型进行迁移学习，我的训练准确度已达到 87% 左右，但验证准确度相当低 ~56% （严重过度拟合，ik）。 这里的聪明人能否帮我提供一些关于如何更好地执行迁移学习的建议，是否应该使用数据增强（我有大约 28000 个训练图像），以及我应该使用视觉转换器等吗？ 使用 VGG19 和 Inception 时，由于某种原因，我的验证准确度停留在 24.71% 并且之后不会改变 ResNet50、mobile_net 和 Efficient_net 给出了上述指标 这是我一直用于迁移学习的示例笔记本 https://colab.research.google.com/drive/1DeJzEs7imQy4lItWA11bFB4mSdZ95YgN?usp=sharing 任何和所有感谢帮助！   由   提交 /u/Hades_Kerbex22   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctzd0a/p_real_time_emotion_classification_with_fer2013/</guid>
      <pubDate>Fri, 17 May 2024 07:25:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 被 NeurIPS 2024 - 其他会议接受的真正机会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctv9li/d_real_chances_to_be_accepted_in_neurips_2024/</link>
      <description><![CDATA[嘿！ 这是我第一次向 NeurIPS 提交论文。 有人知道作者什么时候可以看到评论吗？8 月，还是可能更早？如果我们收到非常差的评论……最好的办法是退出提交路径，对吗？在这种情况下，您会推荐在这些日期使用哪些替代方案？ 我的主题是 NN 可靠性，但我总是对自己的研究缺乏信心，我总是认为这还不够，如果我认为在 Neurips 这样的会议上就更是如此。您认为每个人都提交了好论文还是有大量的垃圾论文？我在这里看到了很多关于审查过程的负面意见……所以，我有点害怕。 今年，有 20000 份左右的提交。所以，我不知道该怎么做，是继续提交还是提交给另一个会议。由于我正在填补的空白很明显，我相信其他人也在填补这个空白并将其提交给 NeurIPS。除了 NeurIPS 之外，还有其他会议能先输出结果吗？我正在尝试以一种聪明的方式思考。做一名研究员真难…… 谢谢！    提交人    /u/Sincerebri   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctv9li/d_real_chances_to_be_accepted_in_neurips_2024/</guid>
      <pubDate>Fri, 17 May 2024 03:06:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2018年以来未来被认为是大炮的开创性论文清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cts99m/d_seminal_papers_list_since_2018_that_will_be/</link>
      <description><![CDATA[大家好， 我是刚毕业的学生，​​终于有时间学习一些真正有趣的东西了。我想熟悉一下现代机器学习。我读过最著名的论文，比如《Attention is all you Need》、《CLIP》、《Vision Transformers》，但我肯定错过了大部分重要的论文。直接阅读最近的 ICML/NIPS 对我没有好处，因为我觉得我还有很多基础知识要讲。 我应该从哪里开始？我对 2018 年左右的 ML 和 DL 很熟悉，对 vanilla Transformer 也很熟悉，但基本就是这样了。    提交人    /u/David202023   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cts99m/d_seminal_papers_list_since_2018_that_will_be/</guid>
      <pubDate>Fri, 17 May 2024 00:27:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 高级框架值得使用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctqzfa/d_are_pytorch_highlevel_frameworks_worth_using/</link>
      <description><![CDATA[为了更好地跟踪实验结果和超参数，我不仅了解了权重和偏差库，而且最终还发现了诸如此类的框架如 PyTorch Lightning 和 Ignite。我一直使用原始 PyTorch，所以我不确定这些框架是否真的有用。我主要从事学术研究，现在我还需要跟踪 MAE，因为这是一个回归问题，我不知道这些框架是否支持这一点，或者让我定义一个自定义指标。 Would这些框架对我有用吗？在尝试不同的架构时，它可以加快进程吗？ 如果您认为它们有用，请告诉我您会推荐哪一个。   由   提交/u/dazor1  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctqzfa/d_are_pytorch_highlevel_frameworks_worth_using/</guid>
      <pubDate>Thu, 16 May 2024 23:24:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>