<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 12 Dec 2023 03:14:27 GMT</lastBuildDate>
    <item>
      <title>[D] 如何找到一个稳定的扩散模型，可以在没有文本提示的情况下进行图像到图像的转换？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18gbl9f/d_how_can_i_find_tune_a_stable_diffusion_model/</link>
      <description><![CDATA[我也可以训练自己的稳定扩散模型，但更喜欢可以针对我的用例进行微调的预训练模型。    由   提交/u/Snoo_72181   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18gbl9f/d_how_can_i_find_tune_a_stable_diffusion_model/</guid>
      <pubDate>Tue, 12 Dec 2023 02:43:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有一本 ML 书籍展示了 ML 模型的逐步实现？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g9t4c/d_is_there_a_ml_book_which_shows_step_by_step/</link>
      <description><![CDATA[我正在寻找一本展示 Python 中 ML 模型的逐步实现的书。这本书还应该为我提供清晰的结构和执行，让我了解代码在生产中的外观，并包含提示和技巧。就像这本书是应用模型解决问题的圣杯一样。有这样的书吗？ 谢谢！   由   提交 /u/tinkerpal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g9t4c/d_is_there_a_ml_book_which_shows_step_by_step/</guid>
      <pubDate>Tue, 12 Dec 2023 01:13:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 和 ICML 以及类似场所的作者 - 您的数学背景有多深？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g85lx/d_authors_in_neurips_and_icml_and_similar_venues/</link>
      <description><![CDATA[你好， 我正在尝试了解什么样的数学背景准备足以在顶级场所进行可发表的研究. 是微积分、线性代数、工程级概率&amp;统计和优化足够了吗？ 我所说的足够，是指您必须了解的最低限度，并且随着您的学习，您会学到更多东西遇到它们或解决问题（边做边学），而不必先准备必要的背景，然后再深入研究。 我的主要问题是 - 我在什么时候说让我们直接开始研究并即时找出我不知道的事情VS首先学习必要的背景然后继续。我很熟悉 - 不强，但在本科时学过这些课程，但很大程度上忘记了许多重要概念。 数学中的传统方法（如 MathOverflow 人员所建议的）不涉及任何内容缺乏解决数学课本练习以掌握数学的能力。这在很大程度上是不切实际/不可行的，并且将永远阻碍我实际的研究进展。 一个并行问题也是 - 你们如何学习你们不学的数学？不知道吗？你真的像数学系的人一样解决教科书上的问题吗？或者只是理解高层图片和关键中心思想，而不关注围绕它的证明或十几个定理？ 非常感谢来自 ML 领域的作者的任何帮助。  请仅当您是机器学习研究人员或来自学术界时才发帖:)。 非常感谢！   由   提交/u/gobraming5  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g85lx/d_authors_in_neurips_and_icml_and_similar_venues/</guid>
      <pubDate>Mon, 11 Dec 2023 23:54:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] ChatGPT 安全吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g3a45/p_how_safe_is_chatgpt/</link>
      <description><![CDATA[这个周末我花了一些时间玩 LLaMA Guard，这是 Meta 精心调整的 LLaMA-7B 模型，可让您在生成 AI 周围添加护栏。我录制了一个快速演示，展示了它的作用以及如何使用它。 最好的部分是，您可以用它定义自己的“安全分类法”——针对人类之间的安全交互和不安全交互的自定义​​策略（提示）和 AI（响应）。 我想看看与 OpenAI 的 ChatGPT 进行的对话有多“安全”，所以我运行了一堆提示（无害和不恰当的混合体）并要求 LLaMA Guard将交互分为安全/不安全。 我从练习中得到的主要收获：  OpenAI 在为其模型添加护栏方面做得很好。 LLaMA Guard 帮助证实了这一点。 这真的很酷，因为我可能有一套非常具体的策略，我想在模型附带的标准护栏之上执行。 LLaMA Guard 使这一切成为可能。 这种模型链接——将 OpenAI 模型的响应传递到 LLaMA 正变得越来越普遍，我认为在不久的将来我们将拥有更加复杂的管道。它有助于拥有一致的界面来将此多模型管道存储为 aiconfig：https://github.com/lastmile-ai/ aiconfig.  自己尝试一下：  GitHub：https://github.com/lastmile-ai/aiconfig/tree/main/cookbooks/LLaMA-Guard YouTube： https://www.youtube.com/watch?v=XxggqoqIVdg  &lt; /div&gt;  由   提交 /u/sarmad-q   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g3a45/p_how_safe_is_chatgpt/</guid>
      <pubDate>Mon, 11 Dec 2023 20:27:37 GMT</pubDate>
    </item>
    <item>
      <title>节日快乐！这是 100% 免费的大型语言模型路线图！ [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g21av/happy_holidays_here_is_your_100_free_large/</link>
      <description><![CDATA[      感谢您最近几天对我的法学硕士大纲提供反馈的支持。本大纲是关于如何学习有关大型语言模型的最先进内容的路线图。它建立在我在 AT&amp;T 和丰田所做的工作的基础上。它还建立在我在公司之外独立完成的大量工作的基础上。  轮廓很扎实，作为我回馈社区的方式，我将其免费赠送。是的，没有烦人的电子邮件注册。没有噱头。 “免费试用”没有条纹页面。大纲末尾没有要求您购买佛罗里达州的分时度假。它只是一个 zip 文件的链接，其中包含大纲和​​示例代码。  这是它的工作原理。首先，你需要了解Python。如果你不知道，那就在 Google 上查找如何学习 Python。其次，这是一个大纲，您需要查看每个部分，浏览链接，并在继续之前真正消化材料。三是轮廓各部分密集；没有任何废话，您可能需要多次浏览大纲。 该大纲旨在帮助您开始学习 Pytorch，它提供了如何进行分类的代码示例带有句子嵌入，它还有另一个如何在 colab 中运行 Zephyr 的代码示例。这个大纲花了我几天的时间来整理，但它确实代表了过去一年的东西。 此外，这不是一个关于微调语言模型的大纲。这不是关于 Mistral MoE 的讨论，也不是关于运行多个 GPU 的讨论。它是为拥有笔记本电脑并想要学习的人设计的。 此外，将此大纲视为一份礼物。其提供时不提供保证或任何类型的保证。  如果您喜欢这个大纲，我恳求您点击分享按钮并与某人分享。也许这也会对他们有帮助。如果您喜欢这个大纲，请将其作为为世界做好事的动力，并与社区分享您所做的事情。 好的，这是大纲。  https://drive.google.com/file/d /1F9-bTmt5MSclChudLfqZh35EeJhpKaGD/view?usp=drive_link 如果您有任何疑问，请在下面的部分中发表评论。如果问题更具体于您正在做的事情（并且不属于一般对话的一部分），请随时在 Reddit 聊天中向我提问。  ​ https://preview.redd.it/lcq80rwdxp5c1.png?width=549&amp;format=png&amp;auto=webp&amp;s=a111f3101d4e8e232dc7e130b86bda0764dc6eb0 ​ https://preview.redd.it /0sdzc58fxp5c1.png?width=547&amp;format=png&amp;auto=webp&amp;s=96daf4c76f7a913cbba041499429be777ff69ff8   由   提交 /u/whiteowled   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g21av/happy_holidays_here_is_your_100_free_large/</guid>
      <pubDate>Mon, 11 Dec 2023 19:37:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] 具有技能课程的分层强化学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g0o35/p_hierarchical_reinforcement_learning_with_a/</link>
      <description><![CDATA[查看我们制作的关于使用我们的框架学习分层强化学习技能的教程！ https://docs.agilerl.com/en/latest/tutorials/skills/index.html&lt; /a&gt; 您认为这与允许代理通过不提供课程来自行发现做某事的最佳方式之间有何平衡？    由   提交 /u/nicku_a   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g0o35/p_hierarchical_reinforcement_learning_with_a/</guid>
      <pubDate>Mon, 11 Dec 2023 18:42:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] BioCLIP，生物学视觉基础模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g0fro/p_bioclip_a_vision_foundation_model_for_biology/</link>
      <description><![CDATA[   /u/Qua5imodo  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g0fro/p_bioclip_a_vision_foundation_model_for_biology/</guid>
      <pubDate>Mon, 11 Dec 2023 18:32:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何阅读和理解Einops表达式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18g01bv/r_how_to_read_and_understand_einops_expressions/</link>
      <description><![CDATA[这是我目前对 einops 的了解：  einops 代表爱因斯坦启发的运算符号。 符号大致受到爱因斯坦求和（特别是 numpy.einsum 运算）的启发。 h = 高度，w = 宽度，c = 通道（颜色），b = 批次 左侧是输入形状。左侧是输出形状。 括号中的字母相乘。 einops.rearrange 包括转置（轴排列）、重塑（视图）、挤压、取消挤压、堆叠等功能，连接和其他操作。  我不明白：  所有操作元素是什么？我上面遗漏了什么吗？  我如何阅读正在进行的操作？ （即我如何知道图像将被压缩或分割成不同的图像？） 操作中顺序重要吗？ （即‘w h c -&gt; (w h) c’与‘h w c -&gt; (h w) c’不同吗？） 为什么有些元素出现在运算中而另一些则没有？ （即“h w c -&gt; (h w) c”与“h w -&gt; (h w)”不同吗？）  我试图理解的 einops.rearrange 操作示例：   &#39;b f h w c -&gt; (b f) c h w’ ‘(b f) e -&gt; b f e’ ‘br r -&gt; br ()’ ‘b s e -&gt; (b s) e’ ‘b s -&gt; (b s)&#39;  之前的研究参考：  https: //einops.rocks/api/rearrange/ https://openreview.net/pdf ?id=oapKSVM2bcj https://youtu.be/ll1BlfYd4mU?si=BmCVibyEifrZhiXC https://youtu.be/xGy75Pjsqzo?si=GiaxqN4vSX9_uTtL    由   提交 /u/Joe_The_Armadillo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18g01bv/r_how_to_read_and_understand_einops_expressions/</guid>
      <pubDate>Mon, 11 Dec 2023 17:59:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] LagrangeBench：拉格朗日流体力学基准测试套件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18fu897/p_lagrangebench_a_lagrangian_fluid_mechanics/</link>
      <description><![CDATA[Github：github.com/tumaer/lagrangebench arXiv：arxiv.org/abs/2309.16342  作者：Artur Toshev、Gianluca Galletti 等人。  这是什么？ LagrangeBench是一个针对CFD粒子问题的机器学习基准测试库，基于&lt;强&gt;JAX。它旨在评估和开发具有挑战性的物理问题的学习粒子模型（例如图神经网络）。据我们所知，这是针对这组特定问题的第一个基准。我们的工作受到 PDEBench 和 PDEArena，我们建议将其作为拉格朗日的替代方案。 核心贡献  7 个新的 2D/3D 粒子流体数据集，基于已建立的 CFD 问题，并使用我们自己的平滑粒子流体动力学 (SPH) 求解器生成，该求解器也是用 JAX 编写的。 添加了三种不同的邻居搜索实现，以处理更大的问题系统或可变粒子计数。 JAX 重新实现各种图神经网络：GNS、SEGNN、EGNN、PaiNN。 训练策略  strong&gt;，包括随机游走噪声[A Sanchez-Gonzalez et al.]和前推损失[J Brandstetter et al.].  摘要  机器学习已成功应用各种科学应用中基于网格的 PDE 建模。然而，基于拉格朗日粒子离散化的学习偏微分方程求解器（这是解决自由表面或复杂物理问题的首选方法）在很大程度上仍未得到探索。我们推出了 LagrangeBench，这是第一个针对拉格朗日粒子问题的基准测试套件，重点关注时间粗粒度。具体来说，我们的贡献是：(a) 使用平滑粒子流体动力学 (SPH) 方法生成的七个新流体力学数据集（四个 2D 和三个 3D），包括泰勒-格林涡流、盖驱动腔、反向泊肃叶流、和溃坝，其中每个都包括不同的物理原理，如实墙相互作用或自由表面，(b) 高效的基于 JAX 的 API，具有各种最新的训练策略和三个邻居搜索例程，以及 (c) 已建立的图神经网络 (GNN) 的 JAX 实现）像 GNS 和 SEGNN 一样具有基线结果。最后，为了衡量学习代理的性能，我们超越了既定的位置误差，并引入了粒子分布的动能 MSE 和 Sinkhorn 距离等物理指标。    由   提交/u/ggalletti99  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18fu897/p_lagrangebench_a_lagrangian_fluid_mechanics/</guid>
      <pubDate>Mon, 11 Dec 2023 13:11:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你能在有限使用的数据集上训练模型并使其使用 apache 许可证开源吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ftvv0/d_can_you_train_a_train_a_model_on_a_limiteduse/</link>
      <description><![CDATA[我一直在寻找可在我的项目中使用的公共数据集，这些数据集将用于商业用途。在本主题中，作者通常不允许商业用途。然而，我发现了一个带有 apache 许可证的开源模型，该模型是在这个有限使用的数据集上进行训练的。这个模型可以用于商业用途吗？   由   提交/u/Horror_Panda920   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ftvv0/d_can_you_train_a_train_a_model_on_a_limiteduse/</guid>
      <pubDate>Mon, 11 Dec 2023 12:53:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] SparQ Attention：带宽高效的 LLM 推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ftsaq/r_sparq_attention_bandwidthefficient_llm_inference/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.04985 摘要：  生成式大语言模型（LLM）开辟了许多新颖的可能性，但由于其巨大的计算要求，它们的普遍使用仍然具有挑战性。一些最有用的应用程序需要一次处理大量样本并使用长上下文，这两者都会显着增加模型的内存通信负载。我们引入了SparQ Attention，这是一种通过选择性获取缓存历史记录来减少注意力块内的内存带宽需求，从而提高 LLM 推理吞吐量的技术。我们提出的技术可以在推理过程中直接应用于现成的法学硕士，无需对预训练设置进行任何修改或进行额外的微调。我们通过在各种下游任务上评估 Llama 2 和 Pythia 模型，展示了 SparQ Attention 如何将注意力内存带宽要求降低多达八倍，而不会损失任何准确性。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ftsaq/r_sparq_attention_bandwidthefficient_llm_inference/</guid>
      <pubDate>Mon, 11 Dec 2023 12:47:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 批量大小对训练损失有什么影响？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18fs4ik/d_what_is_the_effect_of_batch_size_on_training/</link>
      <description><![CDATA[我一直在尝试批量大小，我发现在训练集上使用较大的批量大小与较小的批量大小相比，损失较低。我知道这样一个事实，即批量大小越小，权重更新就越多，但是我无法理解在相同的情况下损失有何不同。训练纪元数。   由   提交 /u/Melodic_Stomach_2704   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18fs4ik/d_what_is_the_effect_of_batch_size_on_training/</guid>
      <pubDate>Mon, 11 Dec 2023 11:06:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] Google Gemini 是真货还是宣传噱头？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18fbc04/d_is_google_gemini_the_real_deal_or_a_publicity/</link>
      <description><![CDATA[我关注法学硕士和多模式模型的演变已经有一段时间了，我对 Google 推出 Gemini 感到非常兴奋。说实话，我不确定双子座是否还在那里。听起来好像它被宣传得比实际情况要多得多。  https ://www.cnbc.com/2023/12/08/google-faces-controversy-over-edited-gemini-ai-demo-video.html   由   提交 /u/Dry_Cattle9399   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18fbc04/d_is_google_gemini_the_real_deal_or_a_publicity/</guid>
      <pubDate>Sun, 10 Dec 2023 19:34:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我对 Llama 进行了微调，为我的代码库生成系统图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18f6phk/p_i_finetuned_llama_to_generate_system_diagrams/</link>
      <description><![CDATA[       由   提交/u/jsonathan  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18f6phk/p_i_finetuned_llama_to_generate_system_diagrams/</guid>
      <pubDate>Sun, 10 Dec 2023 16:03:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>