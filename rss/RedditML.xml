<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Fri, 14 Feb 2025 15:17:37 GMT</lastBuildDate>
    <item>
      <title>[D]需要有关AI卡路里估算应用程序的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipck6l/d_need_advice_on_ai_calorie_estimation_app/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我正在为使用图像识别的基于AI的卡路里估算应用程序为个人项目工作，但我是否坚持是否方法缺少明显的东西，或者如果那里有更好/更容易的技术。 到目前为止，我的计划是：  在多个数据集中训练的有效网络B4（例如，Food101，Nutrition5k，刮擦和标记的食物图片），以供一般食物识别。寻找卡路里估计 +宏的开放食品事实。 用于低信心预测（边缘案例），我将使用gpt-4o api  添加一个按钮让人们调整结果手动使用AI弄乱了份量或标签食品  问题：  是否有效网络 + GPT-4O组合过度杀伤或不错的混合方法？我是否错过了更简单的解决方案？ 诸如cal ai，myfitnesspal或fastic之类的应用程序的引擎盖下是什么？他们是否完全使用自定义CNN，视觉API或其他内容？  还如何从2D图像中准确地测量部分大小？是否有任何技术（深度传感器？AR？）实际解决此问题，或者这些应用程序上方只是近似？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/forsaken_software152       [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipck6l/d_need_advice_on_ai_calorie_estimation_app/</guid>
      <pubDate>Fri, 14 Feb 2025 15:04:48 GMT</pubDate>
    </item>
    <item>
      <title>[R]在欧洲+英国攻读博士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip9vuw/r_doing_a_phd_in_europeuk/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿我正在寻找2026年的博士学位，我想知道你们中的一些人是否可以推荐一些实验室。我想要在RL中理想的东西（因此没有土匪或完整的理论MDP）。可能是可塑性，终身/持续学习，更好的RL的架构/算法，多代理或分层RL，RL + LLM，RL +扩散等等。 我也很好较少的RL和更多的ML，例如更好的变压器体系结构，状态空间模型等。 P&gt; -Ethz（Krause&#39;s Lab）  -Darmstadt（Peters）   -  inria（flowers）   -  isir in Paris   -tübingen中的Max Plank    - 牛津的怀特森实验室  -FLAIR   -Stefano Albrecht在爱丁堡的实验室 我真的很喜欢如果您能帮助我延长清单，那么当我全面研究他们的论文，检查他们的博士学位，博士后和PIS等时，我不会错过实验室。 谢谢您提前很多帮助！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_carpenter7252      [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip9vuw/r_doing_a_phd_in_europeuk/</guid>
      <pubDate>Fri, 14 Feb 2025 12:51:57 GMT</pubDate>
    </item>
    <item>
      <title>[r]用潜在推理扩展测试时间计算：一种反复的深度方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip8lhf/r_scaling_up_testtime_compute_with_latent/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我们研究一种新型的语言模型体系结构，能够通过隐式推理潜在空间来扩展测试时间计算。我们的模型通过迭代复发块来起作用，从而在测试时间内展开对任意深度。这与主流推理模型相反，该模型通过产生更多的令牌来扩展计算。与基于思想链的方法不同，我们的方法不需要任何专业的培训数据，可以与小型上下文窗口一起使用，并且可以捕获不容易用文字表示的推理类型。我们将概念验证模型扩展到35亿参数和8000亿个令牌。我们表明，由此产生的模型可以在推理基准上提高其性能，有时会显着，达到相当于500亿个参数的计算负载。  本文在测试时在潜在空间中推理的论文是迷人。我认为这种方法正在成为一种趋势，并可以重新定义我们如何看待语言模型中的推理。 Meta Fair在大型概念模型上的工作也涉及潜在推理。  arxiv链接： [2502.05171]带有潜在推理：经常性深度方法   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/hiskuu     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip8lhf/r_scaling_up_testtime_compute_with_latent/</guid>
      <pubDate>Fri, 14 Feb 2025 11:32:58 GMT</pubDate>
    </item>
    <item>
      <title>[d] val acc高于火车ACC</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip88et/d_val_acc_higher_than_train_acc/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有任何理由验证精度高于分类任务中的训练精度（Train ACC = 0.82，Val ACC = 0.88）？还是只是随机机会？ 编辑：typo。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/_my__Real_name_      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip88et/d_val_acc_higher_than_train_acc/</guid>
      <pubDate>Fri, 14 Feb 2025 11:08:05 GMT</pubDate>
    </item>
    <item>
      <title>[r]值得信赖的检索效果一代：可靠性，隐私，安全，公平和问责制的框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip7dvv/r_trustworthy_retrievalaugmented_generation_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项综合调查研究了建立可信赖的抹布系统的关键挑战和方法，这对于可靠的AI应用程序变得越来越重要。 主要技术贡献重点是： - 分析抹布系统中的可信度维度（检索准确性，发电忠诚，来源信誉） - 对改善抹布可靠性的当前方法的系统审查 - 评估抹布系统的信任框架 - 评估当前基准和指标的评估 关键发现和方法论： - 检索质量对下游产生产生重大影响 - 多个检索可以提高准确性但提高复杂性 - 来源归因和信心评分有助于防止幻觉 - 当前的评估指标通常无法捕获重要的可信度方面&lt; /p&gt; 结果突出了一些关键挑战： - 从多个来源管理冲突的信息 - 平衡检索精度与回忆 - 在检索到的环境之间保持一致性 - 处理不完整或模棱两可的证据 我认为这项工作提供了开发更可靠的抹布系统的重要基础。拟议的评估框架可以帮助标准化我们如何评估抹布的可信赖性，而确定的挑战指向清除研究方向。对来源信誉和透明归因的强调似乎与现实世界应用特别相关。  tldr：调查分析抹布系统中的信任度，涵盖技术挑战，当前的方法和评估方法。提出了评估抹布可靠性并确定改进的关键领域的框架。 完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip7dvv/r_trustworthy_retrievalaugmented_generation_a/</guid>
      <pubDate>Fri, 14 Feb 2025 10:05:51 GMT</pubDate>
    </item>
    <item>
      <title>[D]扩散模型及其统计不确定性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip6doi/d_diffusion_models_and_their_statistical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我对扩散模型的统计信息有问题。在诸如DDPM和DDIM之类的方法中，可以在任何扩散时间步骤中获得清洁图像（X0）的估计值。当然，此估算有一些相关的错误，但是似乎没有纸上关于此的论文。我在这里错过了什么吗？这是我正在进行的一项研究。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unk0wnvar     [link]   ＆＃32;   [commistion]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip6doi/d_diffusion_models_and_their_statistical/</guid>
      <pubDate>Fri, 14 Feb 2025 08:50:36 GMT</pubDate>
    </item>
    <item>
      <title>[d]如何处理蒸馏中的学生与教师模型的不同数据分布？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip5d07/d_how_to_deal_with_different_data_distribution/</link>
      <description><![CDATA[在一小时和B型3天。 我想蒸馏出B模型A建模，以使A模型可以从模型B中的其他信号中学习对于A和B模型来说，这应该是正确的，因此转移学习。 问题是B在训练过程中比模型A所看到的数据更多，并且可以根据更长的时间进行预测窗口及其真正的概率不同。即使使用PLATT缩放尺度或根据自己的分布进行校准，从理论上讲，它们也将彼此之间存在不同的数据分布，例如 我对如何从较长的时间窗口进行蒸馏而失去了不同的阳性率。自适应加权，但没有一个具体解决这个问题……  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/tough_palpitation331     [link]  ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ip5d07/d_how_to_to_deal_with_with_different_data_distribution/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip5d07/d_how_to_deal_with_different_data_distribution/</guid>
      <pubDate>Fri, 14 Feb 2025 07:33:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML调试面试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip4ypj/d_ml_debugging_interview_for_experienced_roles/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您好，&lt; / p&gt; 最近，我一直在为应用的ML / ML研究工程师角色准备采访。我想练习更多的技能来调试Pytorch或任何ML管道。我想知道是否有人以前经历过这种采访，并且可以为如何做最好的准备。如果您还可以分享此类面试问题的示例，那就太好了。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unessionarybelt750     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip4ypj/d_ml_debugging_interview_for_experienced_roles/</guid>
      <pubDate>Fri, 14 Feb 2025 07:04:38 GMT</pubDate>
    </item>
    <item>
      <title>[P]纯C中的GPT-2（以及完整的CUDA工作室）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioybio/pgpt2_in_pure_cand_full_cuda_worklogs_to_come/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  并行计算是听起来令人生畏但对现代世界绝对必不可少的事情之一。从高频交易（HFT）到设备AI，最大程度地减少资源，同时最大程度地提高性能非常重要，并且随着我们转向更好的开源LLM，可能会成为瓶颈。  首先要潜入这个空间，我启动了一个项目，我以平原，幼稚和不优化的（边界愚蠢）C实现了GPT-2体系结构，而没有很大的依赖性。为什么？因为在最基本的层面上了解问题是有效优化它的唯一方法。大多数教程从基础知识开始（例如优化矩阵乘法，然后它们可能会介入基本操作/创建基于圆圈的渲染器），但是真实的生产级cuda，例如您在乔治·霍茨（George Hotz）的Tinygrad或Karpathy的LLM中看到的内核.c或类似项目是完全不同的事情。几乎没有任何结构化资源来弥合差距。 ，我的目标是吗？ ➡️从这个简单的实现开始，然后逐步优化。 ➡️学会从头开始构建cuda内核，基准测试并将它们与其他解决方案进行比较。 ➡️返回此GPT返回此GPT返回此GPT -2实施，再次逐步挑选它，看看我可以做到的速度更快，更精细，更有效。 ，我将使用完整的工作室  repolink： https://github.com/angry-kratos/gpt-2-in -c    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/atronos_kronios     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioybio/pgpt2_in_pure_cand_fule_fure_full_cuda_worklogs_to_to_to_to_come/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioybio/pgpt2_in_pure_cand_full_cuda_worklogs_to_come/</guid>
      <pubDate>Fri, 14 Feb 2025 00:43:58 GMT</pubDate>
    </item>
    <item>
      <title>[D]我们在Google和Apple建立了Genai，然后离开以建立开源AI实验室，以使开放社区能够协作和建造下一个DeepSeek。 2月14日（星期五）上午9点至下午12点，请向我们询问！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioxatq/d_we_built_genai_at_google_and_apple_then_left_to/</link>
      <description><![CDATA[在   tl; dr：嗨，我们是Oumi，一个人的AI实验室，相信无条件开源的方法 - 代码，权重，培训数据，基础架构和协作 - 因此可以集体向前推动AI。我们为任何人建立了一个在AI中进行研究的平台。向我们询问有关开放源代码，扩展大型模型，DeepSeek的任何内容，以及在大型科技公司内外建立前沿模型所需的内容。告诉我们什么在开源AI中运作良好或您面临的挑战。我们应该共同努力以改进公开的AI？  ------------------------------  多年来，我们在Big Tech（Google）工作，苹果，微软）在Google Cloud Palm，Gemini和Apple的Health Foundation模型等Genai模型上的主要努力。我们在孤岛工作，知道必须有一种更好的方法来公开和协作开发这些模型。因此，我们建立了一个真正的开源AI平台，使世界各地成千上万的AI研究人员，科学家和开发人员可以合作，以一种集体的方式促进Frontier AI，从而导致更有效，透明和透明和稳定负责任的发展。 OUMI平台（完全开源，Apache 2.0许可证）支持预训练，调整，数据策展/综合，评估以及任何其他常见的效用，以完全可记录的和可重复的方式，同时易于自定义以支持新方法。   DeepSeek向我们展示了开源通过利用Llama之类的开放权重模型可以实现的目标。但是我们认为，AI应该更加开放：不仅是权重，而且还应该进行培训数据，以及代码将其全部打开。然后走得更远：使任何人都可以轻松访问和实验，使社区可以轻松合作和协作。  如果您有兴趣的话，有关OUMI的一些资源： 我们的github repo： https：https： //github.com/oumi-ai/oumi   我们的发布故事： https://venturebeat.com/ai/ex-google-google-apple-apple-egneers-launch -uncondition-open-source-oumi-ai-platform-that-that-that-that-the-could-help-to-build-the-next-deepseek/  我们的网站： https://oumi.ai/    如果您想协作并为社区研究项目做出贡献，无论您在哪里得到计算，都可以签名在： https://oumi.ai/community 。我们将从现有开放模型的训练后开始，接下来，我们将协作进行改进，以进行培训。我们打算与包括作者的所有贡献者一起发布研究。 我们在这里回答有关我们的开源方法，扩展大型模型，DeepSeek的问题大型科技公司以及大家都想讨论的其他任何事情。&lt; / p&gt; 我们将于2月14日星期五上午9点至下午12点pt / 12 pm-3 pm-3pm。问我们任何事情。  加入我们的AMA：   （ u/koukoumidis ） manos koukoumidis   - 首席执行官兼联合创始人ex-google（cloud genai铅） （ u/oelachqar ） Oussama elachqar   - 联合创始人，工程，Ex-Apple（健康基础模型） （ u/matthewpersons ） Matthew Persons   - 联合创意，工程学，工程，Ex -google（云棕榈＆amp; nl铅） （ u/jeremy杰里米·格里尔（Jeremy Greer）  - 联合创始人，研究，前google（双子座对齐）    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/koukoumidis     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioxatq/d_we_built_genai_genai_google_and_apple_apple_paple_then_left_then_left_to/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioxatq/d_we_built_genai_at_google_and_apple_then_left_to/</guid>
      <pubDate>Thu, 13 Feb 2025 23:53:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlignRec在多模式建议中优于SOTA模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioo1ta/r_alignrec_outperforms_sota_models_in_multimodal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   alignrec，在 alignrec中引入：在多模式建议中对齐和训练（cikm &#39;24），解决多模式建议系统中的错误对准。传统方法难以整合各种内容类型（文本，图像和分类ID）到语义差距。 AlignRec通过优化三个对齐任务来解决此问题：ICA INTER-CONTENT（ICA），CONTENT类别（CCA）和用户项目（UIA）。 ICA通过基于注意力的编码器将语义表示统一，CCA使用对比度学习增强特征对齐，UIA通过余弦相似性损失来完善用户项目表示。   关键的Innovation是Alignrec的两阶段训练：预 - 培训使视觉和文本数据对齐，同时微型调整结合了用户行为以进行优化的建议。在亚马逊数据集中测试，它的表现优于九种SOTA模型，在长尾建议方面表现出色。通过弥合多模式语义差距，AlignRec提高了准确性和鲁棒性，推进了多模式AI驱动的建议。 以深入研究框架并结果，请参阅此处的完整纸张文章： https://www.shaped.ai/blog/multimodal-alignment-for-recmmentations   &lt; /div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/skeltzyboiii     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioo1ta/r_alignrec_outperforms_sota_moda_models_in_multimodal/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioo1ta/r_alignrec_outperforms_sota_models_in_multimodal/</guid>
      <pubDate>Thu, 13 Feb 2025 17:13:07 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何从头开始进行ML研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ion90w/d_how_you_do_ml_research_from_scratch/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   有人在顶级ML会议（NIPS，ICML，ICLR）或面向域的会议（CVPR，ICCV，ACL，EMNLP，KDD）上发布了作品，Sigir）。 1。如何从0到第一张纸？ 2。您的技能（Pytorch或域知识）是多少？ 3。您遵循的整个过程是什么善于实施您的想法？ 4。您如何提出想法和解决方案？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/antelopewilling2928      r/machinelearning/注释/1ion90w/d_how_you_do_do_ml_research_from_scratch/“&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ion90w/d_how_you_do_ml_research_from_scratch/</guid>
      <pubDate>Thu, 13 Feb 2025 16:40:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] Swe-Agent是Swe Bench Lite上的新开源SOTA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iolpvo/r_sweagent_is_the_new_opensource_sota_on_swebench/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   swe-agent是一种开源软件工程代理，可与任何类型的型号一起使用。我们的1.0版本增加了许多新功能：大规模并行运行；基于云的部署；具有工具捆绑包的广泛可配置性；新命令行接口＆amp;公用事业。完全开源（MIT），广泛的配置，易于破解。由于它将LITELLM用于LM接口，因此您可以与本地LM一起使用它：我们已经与QWEN一起使用了它，而其他社区成员已将其与Llama一起使用。   https://github.com/swe-agent/swe-agent    swe-agent现在由我们的新swe--提供支持REX软件包（也获得了MIT许可），这是一款轻巧的通用沙盒代码执行引擎，支持本地Docker，AWS，Modal Deployments  https：https：https：https：https： //github.com/swe-agent/swe-rex 。您可以使用它来轻松地从头开始使用代码执行，而无需弄清楚如何与运行的Docker容器进行通信！  swe-agent是由普林斯顿大学＆amp;开发的。斯坦福大学。如果您有任何疑问，我们将在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ofirpress     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iolpvo/r_sweagent_is_the_new_new_opensource_sota_sota_on_swebench/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iolpvo/r_sweagent_is_the_new_opensource_sota_on_swebench/</guid>
      <pubDate>Thu, 13 Feb 2025 15:35:03 GMT</pubDate>
    </item>
    <item>
      <title>[R]企业中的文本到SQL：比较方法和对我们有用的方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iojc1f/r_texttosql_in_enterprises_comparing_approaches/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  嗨hivery！  text-to-sql是一个流行的Genai用例，我们最近与一些企业合作。在这里分享我们的学习！ 这些企业已经尝试了不同的方法 - 使用rag，使用gpt-4O（例如GPT-4O），甚至是使用Autogen和Crew的GPT-4O，甚至基于代理的方法，将OR-LLM等最佳的LLM进行。但是它们以85％的精度撞到了天花板，面临超过20秒的响应时间（主要是由于错误的列出现的错误），并处理了使缩放硬缩放的复杂工程。 我们发现了这种微调在特定于商业的查询-SQL Pairs上的开放量LLM具有95％的精度，响应时间降低到7秒以下（通过消除故障恢复）和简化的工程。这些自定义的LLM保留了域内存，从而导致了更好的性能。 我们在上进行了比较。 sql-the-the-the-ultimate-guide-for-2025-3fa4e78cbdf9“&gt;中等。让我知道您的想法，如果您看到了更好的方法来解决此问题。 = Webp＆amp; s = 88251E0CFA246F2BF1F779E708AB03A96A3C0255“&gt; https：//preview.redd.i 246F2BF1F779E708AB03A96A3C0255    &lt; ！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sircomprehense7453     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iojc1f/r_texttosql_in_enterprises_comparing_approaches/</guid>
      <pubDate>Thu, 13 Feb 2025 13:44:21 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>