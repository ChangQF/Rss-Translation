<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 07 Jan 2024 06:16:34 GMT</lastBuildDate>
    <item>
      <title>[D] GPT4-V vs Gemini，哪个模型更好？😃</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190lg6w/d_gpt4v_vs_gemini_which_model_is_better/</link>
      <description><![CDATA[Google Gemini 模型的新闻发布会总是令人印象深刻。我从中选择了两个测试来挑战GPT-4V，它表现异常出色，出色地完成了任务😃： https://youtube.com/watch?v=RMkWBhqH0p4&amp;si=QY4Opy2ToaKoWH-7   由   提交 /u/Entire-Fly-6957   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190lg6w/d_gpt4v_vs_gemini_which_model_is_better/</guid>
      <pubDate>Sun, 07 Jan 2024 06:07:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我如何获得 AI/ML 领域的经验来担任研究职位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190l41n/d_how_can_i_gain_experience_in_aiml_for_research/</link>
      <description><![CDATA[您好，我是一名计算机科学专业的新生，对 AI/ML 研究非常感兴趣，尤其是强化学习。我想向教授寻求研究机会，但我没有太多经验可以展示。我已经完成了一些在线课程，阅读了教科书等，但除了我完成了一些编码作业作为其中的一部分之外，我没有什么可以展示的。您对我可以做些什么来获得强化学习经验有什么建议吗？我可以向教授展示这些经验，以证明我已经准备好在他们的实验室进行研究？我一直在考虑从头开始实现一些论文和/或做一些涉及机器学习的副项目。这是一个好的起点吗？   由   提交/u/meemaowie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190l41n/d_how_can_i_gain_experience_in_aiml_for_research/</guid>
      <pubDate>Sun, 07 Jan 2024 05:48:36 GMT</pubDate>
    </item>
    <item>
      <title>[N]2024年人工智能预测综合清单👽</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190jljc/n_a_comprehensive_list_of_2024_ai_predictions/</link>
      <description><![CDATA[       由   提交/u/Anxious_City_7864   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190jljc/n_a_comprehensive_list_of_2024_ai_predictions/</guid>
      <pubDate>Sun, 07 Jan 2024 04:28:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人类的未来：人工智能的运营者</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190j0ox/d_the_future_of_humans_operators_of_ai/</link>
      <description><![CDATA[   /u/unintend_ Purposes   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190j0ox/d_the_future_of_humans_operators_of_ai/</guid>
      <pubDate>Sun, 07 Jan 2024 03:57:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] Mamba 和 S4 解释：架构、并行扫描、内核融合、循环/卷积公式、第一原理的数学推导、HiPPO 理论直观解释、数学直观解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190gs4y/p_mamba_and_s4_explained_architecture_parallel/</link>
      <description><![CDATA[   /u/hkproj_  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190gs4y/p_mamba_and_s4_explained_architecture_parallel/</guid>
      <pubDate>Sun, 07 Jan 2024 02:03:24 GMT</pubDate>
    </item>
    <item>
      <title>[R][P] 去噪自动编码器过时了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190ggrg/rp_are_denoising_autoencoders_out_of_style/</link>
      <description><![CDATA[分数匹配模型，特别是其去噪分数匹配实现现在非常热门。然而，几乎所有这些都是某种形式的大型随机降噪器。我想知道为什么去噪自动编码器没有对它们进行太多的研究，考虑到两者在理论上和功能上都很相似（[1]中导出的去噪分数匹配论文明确地建立了两者之间的联系）。 &lt;此外，自动编码器比 U-Net 对应物灵活得多，因为它们可用于低维潜变量建模（例如 VAE）。我知道有几篇论文将去噪自动编码器与变分自动编码器 [2] 和对抗性自动编码器 [3] 相结合，在我看来，这是一个不错的开始。  在我自己的研究中，我发现它们本身在概率建模方面具有巨大的潜力。 ​ 参考文献 [1] 帕斯卡·文森特。分数匹配和去噪自动编码器之间的联系。神经计算，2011。 [2] Antonia Creswell、Kai Arulkumaran、Anil Anthony Bharath。使用马尔可夫链改进生成自动编码器的采样。 arXiv，2016。 [3] Antonia Creswell，Anil Anthony Bharath。去噪对抗性自动编码器。 arXiv，2017。   由   提交/u/Chromobacteria  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190ggrg/rp_are_denoising_autoencoders_out_of_style/</guid>
      <pubDate>Sun, 07 Jan 2024 01:47:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大规模标记文本数据的最佳注释平台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190g5td/d_best_annotation_platforms_for_labeling_text/</link>
      <description><![CDATA[我们正在标记文本数据以评估/微调一些大型语言模型 (LLM)。我们拥有一支内部注释者和合作者团队。我们正在寻找一个注释平台，理想情况下不限制可以参与的注释者的数量，具有良好的角色管理和监控标签和注释者的方式，能够灵活地定义标签模式，并且具有用户友好的用户界面。&lt; /p&gt; 我们已经尝试过 Scale AI&#39;s Studio 和 Label Studio，但它们都有各自的局限性，并且根据它们的商业模式和计算标记单元的方式，注释的规模可能会非常昂贵（Label Studio 确实有免费的社区版本，但也有没有角色管理，因此大规模注释者可能会使标签管理变得困难。）我们还考虑了 Amazon Mechanical Turk，但一个挑战可能是注释者首先需要有一个工作 ID 才能加入注释任务（如果我是这样，请纠正我）错误）。 有人对大规模文本数据的可靠注释平台有任何建议吗？我们是否缺少任何明显的平台或工具？该工具不一定是免费的，但在缩放注释时，可靠性和支持很重要，并且成本合理。   由   提交/u/pedhoss  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190g5td/d_best_annotation_platforms_for_labeling_text/</guid>
      <pubDate>Sun, 07 Jan 2024 01:32:46 GMT</pubDate>
    </item>
    <item>
      <title>主动学习[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190fyt6/active_learning_d/</link>
      <description><![CDATA[有人知道一些可以开始主动学习的好文献/资源吗？我有统计学背景，由于实验设计/实验设计而对这个领域感兴趣。优化设计和主动学习领域之间有很多联系，因此想知道这个领域的人推荐阅读哪些内容。   由   提交/u/Direct-Touch469   reddit.com/r/MachineLearning/comments/190fyt6/active_learning_d/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190fyt6/active_learning_d/</guid>
      <pubDate>Sun, 07 Jan 2024 01:23:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] HPC 推理优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190fwpn/d_inference_optimization_with_hpc/</link>
      <description><![CDATA[大家好， 我有一项关于模型 Llama 推理优化的任务。我必须创建一个框架来优化推理。  我已经在 Huggingface 论坛中询问过，您知道还有其他论坛可以解决有关机器学习/人工智能模型的问题吗？ 此外，如果您对此主题有了解，请 lmk，我也会在这里发布问题。 我只是不确定它是否是正确的论坛 感谢您的帮助：p &lt; !-- SC_ON --&gt;  由   提交/u/Few-Letter312  /u/Few-Letter312 reddit.com/r/MachineLearning/comments/190fwpn/d_inference_optimization_with_hpc/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190fwpn/d_inference_optimization_with_hpc/</guid>
      <pubDate>Sun, 07 Jan 2024 01:20:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关系抽取</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190dzwu/d_relation_extraction/</link>
      <description><![CDATA[我正在尝试使用 Hugging Face 中的 REBEL 模型进行关系提取。它通过三元组线性化输出关系三元组。它是在 REBEL 数据集上进行训练的，该数据集本质上是维基百科数据。我有自由格式的文本，我想从中生成关系三元组。那么，如何从该文本创建一个数据集，以便与 REBEL 数据集紧密结合？我想在自由格式文本上微调模型。  REBEL 模型：https://huggingface.co/Babelscape/rebel-large REBEL 数据集：https://huggingface.co/datasets/Babelscape/rebel-dataset  如果您认为还有任何其他值得尝试进行关系提取的 ML 模型，我们将非常感谢您提供的信息。 :) 谢谢！   由   提交 /u/RajHalifax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190dzwu/d_relation_extraction/</guid>
      <pubDate>Sat, 06 Jan 2024 23:52:09 GMT</pubDate>
    </item>
    <item>
      <title>[D]我们的大脑如何防止过度拟合？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190c7y2/d_how_does_our_brain_prevent_overfitting/</link>
      <description><![CDATA[老实说，这个问题引发了一系列其他问题，老实说，这很有趣，我们阻止这种情况发生的机制是什么？ 梦想只是生成数据增强，以便我们防止过度拟合吗？ 如果我们进一步将过度拟合拟人化，患有学者综合症的人会过度拟合吗？ （因为他们在狭窄的任务上表现出色，但在泛化方面有其他障碍。尽管他们仍然有梦想） 为什么我们不记忆，而是学习？    由   提交 /u/BlupHox   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190c7y2/d_how_does_our_brain_prevent_overfitting/</guid>
      <pubDate>Sat, 06 Jan 2024 22:33:40 GMT</pubDate>
    </item>
    <item>
      <title>[D]试图理解专有硬件制造商将重组行业并导致OpenAI企业价值下降的论点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1905izt/d_trying_to_understand_the_argument_that/</link>
      <description><![CDATA[一些硅谷声音的观点之一是，有两个主要因素会导致专有/闭源模型构建者泄漏价值：(1) 延迟当前的所有工具都使得构建生产质量的代码变得不可行——API 应该需要 30-50 毫秒而不是 30-50 秒。 (2) 如果您尝试构建某些东西，这些平台上 100 万个代币的成本在经济上是不可能的。  争论的焦点是，云服务将会为用户带来毫秒级的延迟，并且 100 万个代币的价格约为 10-20 美分，并且他们需要构建自己的定制硬件来做到这一点。  讨论这个问题的人不是机器学习工程师/研究人员。发生这样的事情的可行性是什么？除了实际制造能够将成本降低几个数量级的硬件之外，这种观点还面临哪些挑战？   由   提交 /u/SloppyDrunkCarrot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1905izt/d_trying_to_understand_the_argument_that/</guid>
      <pubDate>Sat, 06 Jan 2024 17:49:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用开源模型进行长代理树搜索取得令人难以置信的结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1903k24/d_incredible_results_with_long_agent_tree_search/</link>
      <description><![CDATA[你好， 我看到 GPT-4 的长代理树搜索以 94.4% 的 pass@1 领先于 HumanEval现在几周了。 https://paperswithcode.com/sota/code- Generation-on- humaneval &lt; p&gt;​ 原始论文的作者在他们的官方 github 存储库。我必须更改一些代码才能使用 CodeLlama-7b 进行尝试，并使用 pass@1 进行人类评估，仅 2 次最大迭代即可将 HumanEval 得分从 37% 提高到大约 70%。 这是一些令人难以置信的结果在我看来，因为这个分数比只有 7b 模型的 GPT-3.5 更高。我认为必须进行更多测试，但令我惊讶的是人们没有更多地谈论这一点。   由   提交/u/ArtZab  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1903k24/d_incredible_results_with_long_agent_tree_search/</guid>
      <pubDate>Sat, 06 Jan 2024 16:23:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习有什么有趣的数学理论吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zo7or/d_is_there_any_interesting_mathematical_theory_of/</link>
      <description><![CDATA[大家好！我的问题在标题中，这是一些背景信息。我的背景可以描述为“主修理论计算机科学（非常强调‘理论’这个词，想想计算复杂性理论），辅修数学”。 几年前，我参加了入门课程机器学习课程......非常沮丧和失望。  没有解释任何东西应该如何或为什么工作，相反有很多不令人信服的猜测，比如“如果你添加一个卷积层，然后它将学习简单的几何形状，因此后面的层将有更多的结构可以使用”或者“我们可以在 RNN 中使用额外的输入，并以某种方式组合三个输入，这样新的输入将起到‘长期记忆’的作用”。我没想到数学逻辑或编程语言理论的严谨程度，但其他科学，例如经济学，至少可以用一些简化的模型来解释他们正在研究的现象。我们在机器学习中没有类似的东西吗？ 在课程中，我们直接跳到一些相当复杂的问题，例如区分猫的图片和狗的图片。我怀疑是否有人能够对这两类图片给出一个很好的定义。虽然这让神经网络能够解决问题变得更加令人印象深刻，但我看不出我们可以从中学到什么关于神经网络如何做到这一点的信息。训练神经网络区分蓝色和绿色、正方形和圆形等，然后尝试使用结果来分析神经网络如何学习不是更好吗？  后来我开了一个很少有机器学习教科书。  我真的很喜欢有关 PAC 学习的部分，总体来说统计学习也很适合我。 有关神经网络和尤其是深度学习，几乎与我在课程中听到的关于仪式舞蹈如何导致降雨的炼金术级别的推测相同。  所以我试图在 arXiv 上找到一些现代结果。   大多数关于机器学习的论文都将更难以推理的模型应用于更难以理解的问题，这让我感到非常失望。 有一些关于神经网络是通用逼近器的结果，即使不多也很好。 我还遇到过（在写硕士论文时）一两篇关于感知器和电路计算复杂性的论文阈值函数。令人遗憾的是，似乎几乎没有关于这个主题的当代研究。  ​ 这结束了我的“咆哮”。 ，我希望这能够澄清“机器学习数学”的类型。我正在寻找。请注意，我确实理解使用现代模型需要大量的知识和专业知识，我并不是想贬低你所做的工作，我只是对找到这些模型如何工作的理论解释有多么困难感到沮丧，考虑到机器学习的普及。 我真的很感激任何想法或建议！ 此外，英语不是我的母语，所以我很抱歉任何拼写错误、不正确的语法或尴尬的句子。 ​ UPD：看到这篇文章刚刚。我真的很想看到更多类似的作品。   由   提交/u/a_broken_coffee_cup   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zo7or/d_is_there_any_interesting_mathematical_theory_of/</guid>
      <pubDate>Sat, 06 Jan 2024 01:50:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>