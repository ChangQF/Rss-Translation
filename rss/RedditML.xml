<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 01 Dec 2023 03:14:44 GMT</lastBuildDate>
    <item>
      <title>[P] NLP项目-需要体育比赛成绩单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1880a0p/p_nlp_project_in_need_of_sports_games_transcripts/</link>
      <description><![CDATA[大家好 - 我是一名大学生，希望使用体育比赛的实况转播和彩色解说来构建用于自然语言处理的文字语言模型- 有谁知道电视/广播中是否存在此类内容的文字记录。谢谢！   由   提交 /u/FantasticPotato2470   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1880a0p/p_nlp_project_in_need_of_sports_games_transcripts/</guid>
      <pubDate>Fri, 01 Dec 2023 02:15:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 修改后的 Tsetlin Machine 在 7950X3D 上的实现性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187vrpg/p_modified_tsetlin_machine_implementation/</link>
      <description><![CDATA[      嘿。 我在过去 1.5 年里一直致力于我的宠物项目，取得了一些令人印象深刻的成果。 在 Ryzen 7950X3D CPU 上使用没有卷积的一个平坦层的 MNIST 推理性能：每秒 4600 万次预测，吞吐量：25 GB/s，准确度：98.05%。 AGI 实现了。老实说，ACI（人工智能集体智能）。 在 MNIST 性能上改进的 Tsetlin 机器   由   提交 /u/ArtemHnilov   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187vrpg/p_modified_tsetlin_machine_implementation/</guid>
      <pubDate>Thu, 30 Nov 2023 22:54:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找类似的教育内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187u8fa/d_looking_for_similar_educational_content_like/</link>
      <description><![CDATA[https://youtu.be/p1bfK8ZJgkE?si =439ofCFcaFX1EBie（Krish Naik - 带部署的端到端深度学习项目） 我是一名“全栈”人员具有几年经验的数据科学家，我真的很喜欢这种类型的内容，它们涵盖了具有高水平代码和实现质量的端到端项目（即模块化和可重用代码、装饰器、数据类、pydantic、mlops、 dvc、ci/cd、部署等） 是否有任何您会推荐的类似课程、视频、创作者、网站或类似内容，涵盖具有同等技能水平的类似内容？我在目前的工作中已经实现了这样的端到端项目，但我希望了解更多并在涉及 python 开发、机器学习应用程序等方面遵循最佳实践。    由   提交 /u/Fendrbud   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187u8fa/d_looking_for_similar_educational_content_like/</guid>
      <pubDate>Thu, 30 Nov 2023 21:50:15 GMT</pubDate>
    </item>
    <item>
      <title>YUAN-2.0-102B，带代码和重量。 ChatGPT 和 GPT-4 在各种基准上的得分 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187spj3/yuan20102b_with_code_and_weights_scores_between/</link>
      <description><![CDATA[       由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187spj3/yuan20102b_with_code_and_weights_scores_between/</guid>
      <pubDate>Thu, 30 Nov 2023 20:47:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] MLM 通过解析音频输入来从背景氛围中辨别音乐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187o848/p_mlm_to_parse_through_audio_input_to_discern/</link>
      <description><![CDATA[大家好 :) 我正在开发一个 iOS 音频应用程序，它可以处理麦克风输入以实现与音乐同步的反应性可视化。我设置了一个 AVFoundation 管道来记录音频，对光谱质心和色度向量等特征帧执行实时 FFT 分析，并将这些特征映射到驱动视觉效果的参数。我现在想训练一个模型来区分麦克风数据中的音乐和环境噪音，以过滤掉仅具有不相关背景谈话或声音的片段。该应用程序是用 Swift 构建的，即使在较旧的 iPhone 上也需要非常有效地执行预测（理想情况下哈哈，这不是最大的问题）。您建议使用哪种类型的神经网络模型来对每帧的短音频特征序列进行分类？我正在考虑 LSTM 或 Transformer 架构。哪些功能集可提供最具辨别力的音乐与噪音信号？我应该通过帧级预测或总体序列准确性等聚合指标来量化模型准确性吗？关于优化实时移动推理模型有什么建议吗？我有收集和标记原始音频和功能集的带时间戳的训练数据对的经验。请让我知道有关数据、模型配置、指标或优化的其他细节是否有用。预先感谢您的指导！   由   提交/u/zeke-001  /u/zeke-001  reddit.com/r/MachineLearning/comments/187o848/p_mlm_to_parse_through_audio_input_to_discern/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187o848/p_mlm_to_parse_through_audio_input_to_discern/</guid>
      <pubDate>Thu, 30 Nov 2023 17:38:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一周后我将采访 Rich Sutton，我应该问他什么问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187nbv8/d_im_interviewing_rich_sutton_in_a_week_what/</link>
      <description><![CDATA[Rich 是强化学习书籍&lt;的作者&lt; /a&gt;，最近，他与一些同事创立了 OpenMind 研究所。 ​ 面试时间为 1 周。我有 RL 背景，并且已经对问题和主题有了一些想法，但我也想在艾伯塔省 RL 泡沫之外寻找问题。技术问题是最好的，尽管我对任何事情都持开放态度。谢谢！ ​ 采访发布几周后，我将在此帖子中发布更新。   由   提交/u/ejmejm1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187nbv8/d_im_interviewing_rich_sutton_in_a_week_what/</guid>
      <pubDate>Thu, 30 Nov 2023 17:00:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我们将 Netron 集成到 GitHub 中以可视化模型架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187l3jp/p_we_integrated_netron_into_github_for/</link>
      <description><![CDATA[我们喜欢 Lutz Roeder 创建的 Netron 库：https:/ /github.com/lutzroeder/netron 我们想要探索能够为 GitHub 中托管的 ML 模型渲染 Netron 可视化的感觉，因此我们构建了 Netron 集成：https://about.xethub.com/blog/visualizing-ml-models-github-netron  Netron 专注于一次查看 1 个模型文件，但我们还在拉取请求中合并了前后模型可视化： https://assets-global.website-files.com/6474aea6101c81b742144dd2/65689c07b7f2b060a92 5097c_github_pr2.png   由   提交 /u/semicausal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187l3jp/p_we_integrated_netron_into_github_for/</guid>
      <pubDate>Thu, 30 Nov 2023 15:25:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAMAS 2024 评论已出炉！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187ilt5/d_aamas_2024_reviews_are_out/</link>
      <description><![CDATA[我没有看到讨论帖子，所以我想我应该制作这个。   由   提交 /u/LessPoliticalAccount   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187ilt5/d_aamas_2024_reviews_are_out/</guid>
      <pubDate>Thu, 30 Nov 2023 13:32:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于序列建模的分层门控循环神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187iaw6/r_hierarchically_gated_recurrent_neural_network/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2311.04823 代码：https://github.com/OpenNLPLab/HGRN 模型：https://huggingface.co/OpenNLPLab 摘要：  变形金刚已经超越RNN 因其并行训练和长期依赖建模的卓越能力而广受欢迎。最近，人们对使用线性 RNN 进行高效序列建模重新产生了兴趣。这些线性 RNN 通常在线性递归层的输出中采用门控机制，而忽略了在递归中使用遗忘门的重要性。在本文中，我们提出了一种门控线性 RNN 模型，称为分层门控循环神经网络（HGRN），其中包括由可学习值下界的遗忘门。当向上移动层时，下界单调增加。这允许上层对长期依赖关系进行建模，而下层对更多本地的短期依赖关系进行建模。语言建模、图像分类和远程竞技场基准的实验展示了我们提出的模型的效率和有效性。源代码可在 此 https URL 处获取。  https://preview.redd.it/thph9bpmjh3c1.png?width=965&amp;format=png&amp; ;auto=webp&amp;s=8e4871cd280ef7e5b771b463435d47da11dca52d   由   提交 /u/APaperADay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187iaw6/r_hierarchically_gated_recurrent_neural_network/</guid>
      <pubDate>Thu, 30 Nov 2023 13:16:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] RO-LLaMA：通过噪声增强和一致性正则化进行放射肿瘤学的全科法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187fy3l/r_rollama_generalist_llm_for_radiation_oncology/</link>
      <description><![CDATA[       由   提交/u/davidmezzetti   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187fy3l/r_rollama_generalist_llm_for_radiation_oncology/</guid>
      <pubDate>Thu, 30 Nov 2023 10:59:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用多个库部署 CodeLlama 34Bn 模型的见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187bocu/d_insights_from_deploying_codellama_34bn_model/</link>
      <description><![CDATA[     &lt; td&gt; 大家好， 我们最近尝试部署 CodeLlama 340 亿模型，并希望分享我们的主要发现对于那些感兴趣的人：  最佳性能：使用 vLLM 的量化 GPTQ、4 位 CodeLlama-Python-34B 模型。 结果：我们平台上使用 Nvidia A100 GPU 的平均最低延迟为 3.51 秒，平均令牌生成率为 58.40/秒，冷启动时间为 21.8 秒。  CodeLlama 34Bn   测试的其他库：HuggingFace Transformer Pipeline、AutoGPTQ、文本生成推理。  渴望听到您在类似部署中的经验和学习！   由   提交/u/Tiny_Cut_8440   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187bocu/d_insights_from_deploying_codellama_34bn_model/</guid>
      <pubDate>Thu, 30 Nov 2023 06:13:50 GMT</pubDate>
    </item>
    <item>
      <title>[D]：了解训练大型模型时的 GPU 内存分配</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1878lat/d_understanding_gpu_memory_allocation_when/</link>
      <description><![CDATA[TL;DR：为什么 GPU 内存使用量在梯度更新步骤期间会激增（无法解释 10GBs），然后又下降？ 我一直致力于微调 HuggingFace 上提供的一些较大的 LM（例如 Falcon40B 和 Llama-2-70B），到目前为止，我对内存需求的所有估计都没有相加。我可以使用 4 个 A100-80gb GPU，并且相当有信心我应该有足够的 RAM 来使用 LoRA 微调 Falcon40B，但我不断收到 CUDA OOM 错误。我已经找到了让事情运行的方法，但这让我意识到我并不真正理解训练期间如何分配内存。 以下是我对训练模型时内存去向的理解：  设置 -&gt;定义 TOTAL_MEMORY = 0 (MB)，我将在执行增加内存的每个步骤时更新它。 -&gt;通过“观察”来检查内存使用情况nvidia-smi 每 2 秒刷新一次。 -&gt;模型已加载到fp16 -&gt;使用具有 ~7B 参数的 Falcon7B（类似于 6.9，但足够接近） -&gt;在 jupyter 笔记本中的单个 A100-80gb GPU 上运行 加载模型：  用于 torch 等的 CUDA 内核（在我的机器上）我看到每个 GPU 大约 900mb）。总内存 + 900 -&gt; TOTAL_MEMORY=900 模型权重（废话）。假设您使用 float16 加载了一个 7B 参数模型，那么您将看到 2 字节 * 7B 参数 = 14B 字节。 ~= 14GB GPU VRAM。总内存 + 14_000 -&gt; TOTAL_MEMORY=15_000（舍入）  模型应在单个 GPU 上加载。 训练（我正在模拟单个前向并通过单独运行每个部分来向后一步）  数据。我正在传递一小批虚拟输入（随机整数），因此我假设这不会对内存使用量产生实质性贡献。 前向传递。由于某种原因，内存跳跃了大约 1000mb。也许这是由于缓存的中间激活造成的？虽然我觉得应该更大。 TOTAL_MEMORY + 1_000 -&gt; TOTAL_MEMORY = 16_000。 计算交叉熵损失。损失张量将利用一些内存，但这似乎不是一个非常高的数字，所以我认为它没有贡献。 通过调用 `loss.backwards() 计算相对于参数的梯度`。这会导致显着的内存峰值（增加 15_000 MB）。我想这是为模型中每个参数存储梯度值的结果？ TOTAL_MEMORY + 15_000 -&gt; TOTAL_MEMORY = 30_000 通过调用“optimizer.step()”更新模型参数。这会导致另一个内存峰值，GPU 内存使用量增加超过 38_000MB。不太确定为什么。我最好的猜测是，这是 AdamW 开始为每个参数存储 2 x 动量值的地方。如果我们进行数学计算（假设优化器状态值在 fp16 中）----&gt; 2 个字节 * 2 个状态 * 7B = 28B 字节 ~= 28GB。 TOTAL_MEMORY + 38_000 -&gt; TOTAL_MEMORY = 68_000  LoRA 会通过减少优化器步骤中所需的内存量来减少这个数字，但我尚未对此进行任何测试，因此没有任何数字。 我相信这就是所有主要组件。 那么额外的 10GB 从哪里来呢？也许它是“火炬保留了该内存但实际上并未使用它”之一。因此，我通过检查 `torch.cuda.memory_allocated` 和 `torch.cuda.max_memory_allocated` 的输出进行检查，也许那里有东西。 分配的内存（后退一步后）：53gb &lt; p&gt;分配的最大内存：66gb 这意味着在某些时候，需要额外的 13 GB，但后来被释放了。 我想问你们的问题是，有人知道这些内存在哪里吗？我在数学中没有发现的额外 10GB 来自哪里？向后传递后释放 13GB 会发生什么？是否有任何我错过的需要记忆的额外步骤？  这已经困扰我一段时间了，我希望获得更好的理解，因此我们将非常感谢您提供的任何专家意见、资源或其他建议！ &amp; #x200b; 编辑：我还知道，当您使用“Trainer”类进行训练时，您可以启用梯度检查点，通过在向后传递过程中重新计算一些中间激活来减少内存使用。那么整个过程的哪一部分会减少内存使用量呢？ ​   由   提交 /u/lightSpeedBrick   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1878lat/d_understanding_gpu_memory_allocation_when/</guid>
      <pubDate>Thu, 30 Nov 2023 03:27:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何向对强化学习一无所知的人解释为什么强化学习很难？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18742ki/d_how_to_explain_why_rl_is_difficult_to_someone/</link>
      <description><![CDATA[如何向对此一无所知的人解释为什么强化学习很难？ 我一直在从事强化学习项目在上班。给我分配这个问题的人是一位计算机科学家，他不是强化学习方面的专家，但知道这是一个难题。 （我的老板和分配项目给我的人是平等的。我的老板不是计算机科学家，对强化学习一无所知。）这家伙的老板是一位业务经理，对强化学习一无所知，对 ML 知之甚少。业务经理想要我提供一份有关项目进展情况的报告，但我感觉他并不真正理解为什么要花这么长时间。  就上下文而言，我已经在这个项目上工作了大约 4 个月，每周 15 个小时。在那段时间，我从头开始为这个问题构建了整个代码库，并编写了几个模型。我有一个目前大部分有效的方法，但我需要对奖励函数进行一些更改，以使其始终表现良好。我是唯一一个参与这个项目的人，所以所有这些都是我自己完成的。在此之前我也只做过普通强化学习，所以我必须学习大量有关深度强化学习的知识才能完成这项工作。幸运的是，我认识一位深度强化学习（外部工作）方面的专家，他能够给我指点。我感觉我已经取得了很大的进步，并且在拥有一个完全完善的模型方面已经接近冲刺了。然而我感觉这家伙对我不太感兴趣。这个人对我没有任何官方权力，所以这主要是为了解释除了有关该项目的正常幻灯片以及我所处的位置之外，强化学习还有多少工作。 &lt; !-- SC_ON --&gt;  由   提交 /u/savvyms   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18742ki/d_how_to_explain_why_rl_is_difficult_to_someone/</guid>
      <pubDate>Wed, 29 Nov 2023 23:57:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过深度学习发现了数百万种新材料</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186w67m/r_millions_of_new_materials_discovered_with_deep/</link>
      <description><![CDATA[帖子：https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/ 论文：https://www.nature.com/articles/s41586-023-06735-9 摘要： 新型功能材料实现了从清洁能源到信息处理的技术应用的根本性突破。从微芯片到电池和光伏发电，无机晶体的发现一直受到昂贵的试错方法的瓶颈。与此同时，随着数据和计算的增加，语言、视觉和生物学的深度学习模型展示了新兴的预测能力。在这里，我们展示了大规模训练的图网络可以达到前所未有的泛化水平，从而将材料发现的效率提高一个数量级。在持续研究中发现的 48,000 个稳定晶体的基础上，效率的提高使得能够在当前凸包下方发现 220 万个结构，其中许多结构逃过了人类之前的化学直觉。我们的工作代表了人类已知的稳定材料的数量级扩展。最终凸包上的稳定发现将可用于筛选技术应用，正如我们对层状材料和固体电解质候选物的演示一样。在稳定结构中，有 736 个已通过独立实验实现。数以亿计的第一原理计算的规模和多样性也解锁了下游应用的建模能力，特别是导致高度准确和强大的学习原子间势，可用于凝聚相分子动力学模拟和高保真零-离子电导率的射击预测。   由   提交 /u/RobbinDeBank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186w67m/r_millions_of_new_materials_discovered_with_deep/</guid>
      <pubDate>Wed, 29 Nov 2023 18:19:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>