<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 19 Sep 2024 15:17:18 GMT</lastBuildDate>
    <item>
      <title>[P] Comgra：用于分析和调试神经网络的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</link>
      <description><![CDATA[我是一名机器学习工程师和研究员。我厌倦了理解神经网络行为方式的难度，因此我编写了一个库来帮助我。 Comgra（计算图分析） 是一个可以与 pytorch 一起使用的库，用于提取您关心的所有张量数据并在浏览器中以图形方式对其进行可视化。有关它的论文已被接受为 ICML 2024 机械可解释性研讨会的焦点论文。 与通常使用 tensorboard 的方法相比，Comgra 可以对正在发生的事情进行更详细的分析。您可以在训练过程中研究张量，深入研究单个神经元，检查您特别感兴趣的单个数据集，跟踪梯度，比较不同训练运行之间的统计数据等等。 这个工具让我比平时更快地检查我的假设，并帮助我了解网络的不同部分是如何真正相互作用的，从而为我节省了大量的研究时间。    提交人    /u/Smart-Emu5581   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</guid>
      <pubDate>Thu, 19 Sep 2024 14:07:03 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 语音合成的硬件能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fklpg1/project_hardware_power_for_synthesizing_speech/</link>
      <description><![CDATA[大家好！ 如果我没有在错误的主题中写，我有一个与我当前项目相关的问题：我正在训练一个 VITS 模型来为将集成到机器人中的 LLM 生成语音。虽然我可以依靠 OpenAI 的 LLM API 等云服务，但我认为语音合成部分需要在本地完成（由于延迟要求/我想使用我的模型）。 我的目标是实时合成（或至少最小延迟）。我的问题是：机器人的硬件需要多强大？Raspberry Pi 5 似乎有点太弱了。迷你电脑会更合适吗？CUDA 加速对于这项任务是否必不可少？我在没有 CUDA 的 i9-12900k 上测试了我当前的模型（~370k 步，我计划甚至~2M），“tts”在大约 6 秒内生成了一个输出文件，这对我来说是可以接受的。 提前感谢您的见解！    提交人    /u/Leonardo7901   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fklpg1/project_hardware_power_for_synthesizing_speech/</guid>
      <pubDate>Thu, 19 Sep 2024 14:05:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语音到语音模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkhcur/d_speech_to_speech_models/</link>
      <description><![CDATA[有人在研究语音转语音 AI 模型或应用程序吗？想听听我正在进行的项目的第二意见。 如果您能提供帮助，请发表评论或 DM。    由    /u/vividly_voidy  提交  [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkhcur/d_speech_to_speech_models/</guid>
      <pubDate>Thu, 19 Sep 2024 10:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用少量数据进行训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkh1qa/p_training_with_little_data/</link>
      <description><![CDATA[大家好，提前感谢大家的见解！ 我正在做我的最后一个项目，涉及图像合成，但我面临一个挑战：我们可用的数据非常有限。我一直在研究诸如小样本学习、数据集提炼等方法来克服这个障碍。 我希望利用社区的集体智慧，看看是否有人对如何有效处理用于图像合成的小数据集有技巧、经验或建议。 期待任何建议！祝你有美好的一天！:)    提交人    /u/Galaxyraul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkh1qa/p_training_with_little_data/</guid>
      <pubDate>Thu, 19 Sep 2024 09:53:16 GMT</pubDate>
    </item>
    <item>
      <title>[P]用纯 Python 从头构建玩具神经网络框架——受 Karpathy 的 Micrograd 启发</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkg3yd/pbuilding_a_toy_neural_network_framework_from/</link>
      <description><![CDATA[      https://github.com/ickma/picograd 上周末，我开始了一个项目，完全从头开始使用纯 Python（没有 TensorFlow、PyTorch 或其他库）构建一个玩具神经网络框架。这个项目的想法来自 Andrej Karpathy 的 micrograd，我想挑战自己，真正了解神经网络在底层的工作原理。 我实现了前向和后向传播，经过一些测试后，我在 Iris 分类数据集上实现了 93% 的准确率。 这个项目是一个很好的学习工具，可以探索神经网络的内部结构，例如在训练过程中如何更新权重和偏差，以及不同层在前向和后向传递过程中如何通信。如果您希望在不依赖现有框架的情况下更深入地研究神经网络的机制，这可能对您也有帮助。 我随时可以提问或分享任何反馈！ https://preview.redd.it/jwaltnn6aqpd1.png?width=846&amp;format=png&amp;auto=webp&amp;s=3eb14eacf57fd323ac2eeb75b614ddb5f27bf8a2   由    /u/Potential-Dingo-6424  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkg3yd/pbuilding_a_toy_neural_network_framework_from/</guid>
      <pubDate>Thu, 19 Sep 2024 08:40:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] Nvidia、cuda 和 Linux 驱动程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkenxr/d_nvidia_cuda_and_linux_drivers/</link>
      <description><![CDATA[今天我花了很多时间尝试在我的计算机上运行一个 pytorch ML 项目。我必须克服的困难数量多得令人难以置信。当涉及到 ML 代码时，我可以跟上正在发生的事情并对其进行破解，但当涉及到 cuda、nvidia linux 驱动程序等时，我只是在黑暗中摸索。有人可以推荐一些资源来了解这些东西的实际工作原理和作用吗？ 我想知道驱动程序和操作系统中有哪些部分，以及它们如何与（Nvidia）硬件交互。理想情况下，我想要一本从高层次开始并深入研究 gpu 硬件优化的书。 作为参考，我今天的任务的一部分是编译 NixOs 上的闪存注意力。此外，从现在起大约一年后，我可能会负责编写一些高效的 cuda 内核。    提交人    /u/lemmyuser   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkenxr/d_nvidia_cuda_and_linux_drivers/</guid>
      <pubDate>Thu, 19 Sep 2024 06:47:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kaggle 竞赛将由 AI 代理来掌控，可能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/</link>
      <description><![CDATA[我尝试在 Google 的数据科学代理工具上参加 Kaggle 竞赛 https://www.kaggle.com/competitions/playground-series-s3e19 - 基本上我只是将描述作为提示转储并将数据集上传到那里，它生成了这个 Jupyter 笔记本：https://colab.research.google.com/drive/17DkaHhcdiURHPtYBZoRvoDE9NaSzn4V4 我也在 ChatGPT 上尝试过，但不幸的是我没有 Plus，所以任务在中途终止（没有训练模型）。有 Plus 的人尝试过 ChatGPT 上的 Kaggle 任务吗？想知道我们还能看到机器人赢得比赛多久，我想 RL 会在这里发挥巨大作用。    提交人    /u/caterpillarous   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/</guid>
      <pubDate>Thu, 19 Sep 2024 05:18:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 抹去不可见之物：图像水印压力测试挑战（NeurIPS 2024 竞赛）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk90gj/r_erasing_the_invisible_a_stresstest_challenge/</link>
      <description><![CDATA[我们很高兴地宣布，NeurIPS 竞赛“消除不可见：图像水印压力测试挑战”将于 9 月 16 日至 11 月 5 日举行。这是您在尖端领域测试技能并赢得 6000 美元奖金的机会！ 竞赛概述 本次竞赛分为两个赛道：黑盒赛道和米色盒子赛道。它旨在验证图像水印在不同可见性条件和攻击者知识下的稳健性。参赛者将尝试去除不可见的水印，同时保持图像质量。评估将基于两个标准：水印去除的有效性和图像质量的保存。 🔗 重要日期： ▶️ 提交阶段： 9 月 16 日 - 11 月 5 日 ▶️ 注册和提交截止日期： 11 月 5 日 ▶️ 获胜团队公告： 11 月 20 日 🌐 更多信息和注册： ▶️ 网站： http://erasinginvisible.github.io ▶️ 托管在 Codabench： ⏩ 米色盒子赛道： codabench.org/competitions/3821 ⏩ 黑盒赛道： codabench.org/competitions/3857 💡 为什么要参加？  在现实世界的前沿领域测试您的技能。 在各种条件下验证水印稳健性。 与全球研究人员和从业人员社区合作。 赢取 6000 美元的份额（随着更多赞助商的加入，奖金还会继续增加）！  💰 奖金池：6000 美元（并且还在增加！） 想要赞助比赛吗？通过以下方式联系我们： 📧 [erasinginvisible@googlegroups.com](mailto:erasinginvisible@googlegroups.com) 或 [furongh@umd.edu](mailto:furongh@umd.edu)    提交人    /u/Dubby8692737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk90gj/r_erasing_the_invisible_a_stresstest_challenge/</guid>
      <pubDate>Thu, 19 Sep 2024 01:16:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] Windows Agent Arena：计算机上运行的 AI 代理的基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk5frs/r_windows_agent_arena_a_benchmark_for_ai_agents/</link>
      <description><![CDATA[大家好，r/MachineLearning！我想分享一个我参与创建的项目：  AI 助手改变了我们使用计算机工作和搜索信息的方式。随着 LLM 变得越来越强大，下一步是什么？代理。 我很高兴介绍 Windows Agent Arena，这是评估 AI 模型的基准，这些模型可以推理、计划和采取行动来解决 PC 上的任务。 什么是 Windows Agent Arena？ Windows Agent Arena 包含 11 个程序/领域的 150 多个任务，这些任务测试 AI 模型如何使用我们可用的相同应用程序、工具和浏览器在真实操作系统中运行。研究人员可以测试和开发能够浏览网页、进行在线预订/购买、操作和绘制电子表格、在 IDE 中编辑代码和设置、摆弄 Windows GUI 设置以自定义 PC 体验等的代理。 我们基准测试的主要功能是云并行化。虽然当今大多数代理基准测试通常需要几天时间才能通过在开发机器中连续运行任务来评估代理，但我们可以轻松与 Azure 云集成。研究人员可以并行部署数百个代理，将结果加速到 20 分钟，而不是几天。 除了基准测试之外，我们还引入了 Navi，这是一种用于 Windows 导航的多模式代理。我们开源了一个版本的屏幕解析模型，作为研究界的模板。我们对几个基础模型进行了基准测试，从小型本地 Phi3-V 一直到大型云模型（如 GPT-4o）。 我对这个版本以及 Windows Agent Arena 将解锁的通用计算机代理的所有创新感到非常兴奋。代理开发人员首次可以开始探索在真实操作系统领域中的大规模自主数据收集，并使用强化学习来训练动作模型，而不是昂贵的人工演示。  链接 🔗博客：https://www.microsoft.com/applied-sciences/projects/windows-agent-arena 🌐网页：https://microsoft.github.io/WindowsAgentArena/ 📃论文：https://arxiv.org/abs/2409.08264 💻代码：https://github.com/microsoft/WindowsAgentArena 这项工作是与微软的一群出色合作者（Dan Zhao、Francesco Bonacci、Dillon DuPont、Sara Abdali、Yinheng Li、Justin W.、Kazuhito Koishida）以及来自 CMU（Arthur Fender Bucker、Lawrence Jang）和哥伦比亚（Zack Hui）的超级明星实习生一起完成的。    提交人    /u/a6oo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk5frs/r_windows_agent_arena_a_benchmark_for_ai_agents/</guid>
      <pubDate>Wed, 18 Sep 2024 22:24:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 的面试经历</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk3plt/d_interview_experience_at_openai/</link>
      <description><![CDATA[最近有 OpenAI 面试经历的人吗？我发现了一个关于他们面试流程的非常有用的帖子，但那是 7 年前的事了。想知道这个过程是怎样的，其他人的经历如何。不胜感激任何见解    提交人    /u/plantparent2021   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk3plt/d_interview_experience_at_openai/</guid>
      <pubDate>Wed, 18 Sep 2024 21:08:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 工作原理的直观解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk1jhj/d_an_intuitive_explanation_of_how_llms_work/</link>
      <description><![CDATA[嗨， 我写了一篇博客文章，以非常直观的方式解释了 LLM 的工作原理。 我们从高层次的抽象开始，其中 LLM 被视为个人助理，然后深入探讨并涵盖标记化、采样和嵌入等概念。 我添加了一些图表，以直观的方式说明一些概念。我还解决了当前 LLM 的一些局限性，例如无法计算“strawberry”中的 R 以及反转字符串“copenhagen”。 希望您觉得它有用！ 如果您有任何反馈或问题，请告诉我。  https://medium.com/@amgad-hasan/explaining-how-llms-work-in-7-levels-of-abstraction-3179de558686 编辑：对于那些不喜欢 medium 的人，下面有一个子堆栈链接和评论。    提交人    /u/Amgadoz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk1jhj/d_an_intuitive_explanation_of_how_llms_work/</guid>
      <pubDate>Wed, 18 Sep 2024 19:37:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 让 LLM 训练更快的技巧指南 - Pytorch 会议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk0tun/d_hacks_to_make_llm_training_faster_guide_pytorch/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk0tun/d_hacks_to_make_llm_training_faster_guide_pytorch/</guid>
      <pubDate>Wed, 18 Sep 2024 19:06:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 首篇发表的机器学习论文——乍一看，同行评审笔记中有什么引人注目的地方吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fjpfvt/r_first_published_ml_paper_from_a_quick_glance/</link>
      <description><![CDATA[长话短说，我通过会议论文集发表了我的第一篇论文，但我的同行评审有点短。我想知道这里有没有时间序列预测或 XAI 经验的人可以给我一些笔记？非常感谢。如果没有，也没关系。 https://dl.acm.org/doi/abs/10.1145/3674029.3674035（在 ACM 下开放获取）。    提交人    /u/jnb_phd_ml_accy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fjpfvt/r_first_published_ml_paper_from_a_quick_glance/</guid>
      <pubDate>Wed, 18 Sep 2024 10:23:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>