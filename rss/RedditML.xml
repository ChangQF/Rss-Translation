<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Tue, 02 Apr 2024 09:13:54 GMT</lastBuildDate>
    <item>
      <title>[D]如何执行这个NLP任务？请帮忙</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btsc6g/d_how_to_perform_this_nlp_task_pls_help/</link>
      <description><![CDATA[我需要将文本分成不同的块，并为每个块分配一个类（例如：对话、描述、序言等）和实例标签（例如：对话 1、对话 2 等）。我能想到的最接近的是 NER 但不完全是，因为我希望对全文进行标记。这更类似于视觉中的全景分割（即同时实例和语义分割）。  我也许可以采用 bert 模型进行标记分类，并在文本上训练它，其中每个标记都用整数（class_label、instance_label）注释，其中 instance_label 只是针对类的每个实例线性递增  有什么线索吗？    由   提交 /u/EnnioEvo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btsc6g/d_how_to_perform_this_nlp_task_pls_help/</guid>
      <pubDate>Tue, 02 Apr 2024 07:05:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] SOTA BERT 类模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btrr9x/d_sota_bertlike_model/</link>
      <description><![CDATA[所以我们可能都知道最先进的仅限解码器的 LLM，例如 GPT-4、Claude 等。这些非常适合生成文本. 但我不知道的是类似 SOTA BERT 的模型。你知道，可以用于 NER、POS 标记、标记分类等任务。 有比 Roberta 明显更好的模型吗？    由   提交/u/Amgadoz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btrr9x/d_sota_bertlike_model/</guid>
      <pubDate>Tue, 02 Apr 2024 06:26:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你读过的关于深度学习的最好的数学书/课程是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btqama/d_what_was_the_best_math_bookcourse_you_had_for/</link>
      <description><![CDATA[我已经完成了高中学业，但之后我开始学习深度学习时已经有一年的时间间隔了。  我开始在 YouTube 上观看深度学习视频，但实际上并不了解矩阵微积分、许多概率论等等。感觉就像我跳过了一些部分只是为了在 PyTorch 中写下代码。 然后我决定首先了解深度学习背后的所有数学知识。我读的第一本书是 Ronald T. Kneusel 的《深度学习数学》。这是一本很棒的书，涵盖了开始理解深度学习背后的数学所需的所有主题。 我想知道，您是否也有过类似的经历。   由   提交/u/cyb0rg14_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btqama/d_what_was_the_best_math_bookcourse_you_had_for/</guid>
      <pubDate>Tue, 02 Apr 2024 04:54:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用原始数据进行大规模相似性搜索数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btpp36/p_large_scale_similarity_search_datasets_with_raw/</link>
      <description><![CDATA[我正在研究比较不同的向量数据库以进行相似性搜索。我查看了一堆大型数据集，例如 BIGANN-1B 数据集，但这些数据集的一个问题是嵌入被压缩到较小的维度，例如 BIGANN 数据集的 128，而对于我的用例我想使用 gte-small 作为嵌入模型，它使用 384 维度，这意味着基准不具有代表性。是否有包含真实标签和原始数据的数据集，即，如果它是文本数据集，它应该包含原始文本数据，以便我使用自定义嵌入模型转换为嵌入。    由   提交/u/yudhiesh  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btpp36/p_large_scale_similarity_search_datasets_with_raw/</guid>
      <pubDate>Tue, 02 Apr 2024 04:20:54 GMT</pubDate>
    </item>
    <item>
      <title>需要 dinov2 训练方面的帮助！ [D] [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btoq8l/need_help_with_dinov2_training_d_p/</link>
      <description><![CDATA[ML 新手。我的目标是在 Imagenet1k 上训练 DinoV2 模型。我有几个关于培训渠道的问题。如果有人有或没有这个模型的经验并且可以帮助我，那就太好了！（另外，请随意不回答所有问题......） 问题：  正在默认配置文件的训练部分添加OFFICIAL_EPOCH_LENGTH（ .yaml）合适吗？我现在只想使用 1 个纪元。 我提供的 --nodes 参数值是否取决于我使用的 GPU 数量？ （我之前注册时遇到一些错误。） 我期望什么样的输出？换句话说，训练的结果如何呈现？ 目前我只是测试训练是否有效，因此我只使用 1 个 GPU。使用 --no-resume 参数是确认这一点的好方法吗？ 这是一个更普遍的问题，但是什么导致模型训练/评估中出现损坏的管道错误？调试和避免此类错误的良好做法是什么？    由   提交/u/dillpill4  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btoq8l/need_help_with_dinov2_training_d_p/</guid>
      <pubDate>Tue, 02 Apr 2024 03:31:08 GMT</pubDate>
    </item>
    <item>
      <title>[项目] FinancialAdvisorGPT : LLM+RAG 样板项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btlpgd/project_financialadvisorgpt_llmrag_boilerplate/</link>
      <description><![CDATA[FinancialAdvisorGPT 是一个样板项目，专为财务分析中的 RAG（检索器增强生成）和 LLM（大型语言模型）应用程序而设计。它建立在包括 MongoDB、MongoDB VectorDB、Chroma、FastAPI、Langchain 和 UI React 子模块在内的技术堆栈之上，为开发人员提供了一个实现和定制 RAG+LLM 项目的框架。 FinancialAdvisorGPT 利用并行数据管道，处理并集成各种数据源，例如股票数据、新闻、SEC 文件和本地 PDF。 Github 项目包含有关项目结构、LLM+RAG 工作原理的详细文档对于特定任务：https://github.com/mburaksayici/FinancialAdvisorGPT   由   提交 /u/mburaksayici   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btlpgd/project_financialadvisorgpt_llmrag_boilerplate/</guid>
      <pubDate>Tue, 02 Apr 2024 01:08:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] AIport 的 AI 景观</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bte1bl/r_ai_landscape_by_aiport/</link>
      <description><![CDATA[        由   提交/u/Fun_Expression_3777   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bte1bl/r_ai_landscape_by_aiport/</guid>
      <pubDate>Mon, 01 Apr 2024 20:04:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] NanoDL：在 JAX/Flax 上构建 Transformers 和法学硕士的库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1btab31/d_nanodl_library_for_building_transformers_llms/</link>
      <description><![CDATA[大家好，我想分享一个简单的示例，说明如何使用 NanoDL 库构建自定义模型。我很想听听您对该项目的想法。 ```py import jax import jax.numpy as jnp from nanodl import time_rng_key from nanodl import ArrayDataset, DataLoader from nanodl import GPT4, GPTDataParallelTrainer, Tokenizer&lt; /p&gt; 准备数据集 batch_size = 8 max_length = 50 vocab_size = 1000 text_paths = [&#39;/path/sample1.txt&#39;, &#39;/path/sample2.txt&#39; txt&#39;, &#39;/path/sample3.txt&#39;] tokenizer = Tokenizer(training_data=text_paths, vocab_size=vocab_size, model_type=&#39;bpe&#39;, max_sentence_length=max_length) data = [] for path in text_paths: with open(path, &#39;r&#39;) as file: text = file.read() # 待办事项：按照您希望的方式预处理编码 = list(map(tokenizer.encode, text)) 数据。扩展（编码） 填充并移动以创建下一个标记预测数据集 max_length = max(len(seq) for seq in data) data = jnp.array([seq + [0] * (max_length - len(seq)) for seq in data]) dummy_inputs, dummy_targets = data[:, :-1], data[:, 1:] dataset = ArrayDataset(dummy_inputs ，dummy_targets）dataloader = DataLoader（数据集，batch_size=batch_size，shuffle=True） hyperparams = { &#39;num_layers&#39;：1，&#39;hidden_​​dim&#39;：256，&#39;num_heads&#39;：2，&#39;feedforward_dim&#39;：256 , &#39;dropout&#39;: 0.1, &#39;vocab_size&#39;: vocab_size, &#39;embed_dim&#39;: 256, &#39;max_length&#39;: max_length, &#39;start_token&#39;: 0, &#39;end_token&#39;: 50, } model = GPT4(* *hyperparams) trainer = GPTDataParallelTrainer(model,dummy_inputs.shape,&#39;params.pkl&#39;) trainer.train(train_loader=dataloader, num_epochs=100, val_loader=) start_tokens = jnp.array ([[123, 456]]) params = trainer.load_params(&#39;params.pkl&#39;) 输出 = model.apply({&#39;params&#39;: params}, start_tokens, rngs={&#39;dropout&#39;: time_rng_key()}, method =model.generate) outputs = tokenizer.decode(outputs.tolist()) ``` NanoDL 的功能：  广泛的选择Gemma、LlaMa2、Mistral、GPT、Diffusion、GAT、CLIP 等模型。 数据并行分布式训练器，包括用几行代码进行训练。 数据加载器，制作数据对 Jax/Flax 的处理更加简单有效。 Flax/Jax 中未找到的自定义层，例如 RoPE、GQA、MQA、SWin 注意力、GPTBlock 等。 GPU/TPU -加速经典机器学习模型，如 PCA、KMeans、高斯过程等。 Jax 中的真正随机数生成器，不需要详细代码。 用于 NLP 和计算机视觉任务的算法，例如高斯模糊、BLEU、Tokenizer 等。  项目仓库：https://github。 com/HMUNACHI/nanodl （如果觉得慷慨，请留下一颗星！）   由   提交 /u/Henrie_the_dreamer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1btab31/d_nanodl_library_for_building_transformers_llms/</guid>
      <pubDate>Mon, 01 Apr 2024 17:45:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在我的工作场所中，还有其他人无法摆脱 OpenAI 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt9y8p/d_cant_escape_openai_in_my_workplace_anyone_else/</link>
      <description><![CDATA[我们能具体谈谈 OpenAI 现在是如何被每个工作场所、客户和他们的祖母强行灌输给我们的吗？最近，我收到的专门使用 OpenAI API 的请求数量猛增。你们对此有什么经验？你如何导航它？我尝试过提出其他替代方案，但不行，他们执意要使用 OpenAI。  OpenAI 成立的明确目的是实现人工智能的民主化，并通过开发开源工具来平衡大型科技的封闭世界。他们完全放弃了这个想法。在这个领域，一种令人恐惧的做法（OpenAI 的创建实际上是为了防止这种做法）是由营利性公司组成的单一或寡头集团为我们做出这一决定。 别理解我的意思开始的事实是，他们的模型是使用谦虚的人的工作来训练的，而这些人永远不会为此得到一分钱。 我觉得被迫与这个令人厌恶的模型一起工作，但我也没有真正的选择。这就是我们许多人支付账单的方式。我是一个人吗？难道我就该放下我的骄傲吗？    由   提交/u/AlphaSquared_io   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt9y8p/d_cant_escape_openai_in_my_workplace_anyone_else/</guid>
      <pubDate>Mon, 01 Apr 2024 17:31:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] Stale Diffusion：使用老式方法生成超现实 5D 电影</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt9u0o/p_stale_diffusion_hyperrealistic_5d_movie/</link>
      <description><![CDATA[大家好， 我想请求对我们关于 Stale Diffusion 的新论文的反馈，Stale Diffusion 是 Stable 的一个极限情况当发行版混合得太多时的扩散。 https://www .robots.ox.ac.uk/~joao/publications/sigbovik24.pdf 不知何故，即使是不严肃的场所也没有认真对待它，甚至 arXiv 也对它嗤之以鼻。给什么？！ 最好， 作者   由   提交 /u/brainggear   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt9u0o/p_stale_diffusion_hyperrealistic_5d_movie/</guid>
      <pubDate>Mon, 01 Apr 2024 17:27:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据有限时深度学习中的特征工程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt5hzq/d_feature_engineering_in_deep_learning_when_the/</link>
      <description><![CDATA[我读到，深度学习的特征工程可以限制神经网络能够学习的数量，如果有大量数据，这是有意义的。&lt; /p&gt; 但是如果数据有限怎么办？在这种情况下，特征工程是否会有所帮助，以便网络不必依赖大量数据来从噪声中了解哪些特征是有用的？   由   提交 /u/notEVOLVED   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt5hzq/d_feature_engineering_in_deep_learning_when_the/</guid>
      <pubDate>Mon, 01 Apr 2024 14:41:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 可扩展且面向 ML 的 Google Drive 替代 Google Colab</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt5hxw/p_scalable_and_mloriented_google_drive/</link>
      <description><![CDATA[      嘿 r/ml！来自 DagsHub 的 Dean。 TL;DR 我们正在与 Google Colab 合作并推出 DagsHub存储桶是兼容 S3 的 Google Drive 替代品，专为 ML 工作流程而构建，并可从头开始扩展。它是免费的，因此您今天就可以开始使用它，我们很乐意听到您的反馈。 这是演示笔记本： https://colab.research.google.com/#fileId=https% 3A//dagshub.com/DagsHub/DagsHubxColab/raw/main/DagsHub_x_Colab-DagsHub_Storage.ipynb --- 我想分享一些我们已经分享的东西我们已经为那些与 Colab 合作的人努力了一段时间了。我知道很多人使用 Colab 进行机器学习工作（我的大多数项目也是如此）。不久前，我们与 Colab 共享了一个集成，让您可以在 Colab 中打开来自 DagsHub 的存储库，并将其保存回来使用一个命令（类似于 GitHub）。 很多时候，当您需要处理更大的数据集时，并且由于 Colab 的短暂性，您最终会使用 Google Drive 作为数据集的持久存储。这对于简单的用例来说非常有用，但往往不稳定并且抛出错误，这使得将其用于更严肃的项目具有挑战性。下一个业务顺序往往是创建 AWS 帐户和 S3 存储桶，但这通常是一个巨大的麻烦，特别是如果您想与其他人共享它，并且需要信用卡。 这就是我们的原因内置 DagsHub 存储桶。它是一个与 S3 兼容的存储，每个 DagsHub 项目都附带（免费），具有简单易用的访问控制、用于查看文件和与他人共享的出色 UI，现在与 Colab 完全集成，让您可以安装并使用它作为 GDrive 的直接替代品。所有这一切都是为了更大规模的工作流程而构建的。 如果您比示例笔记本更喜欢它，我写了一篇博客 - 请在此处查看：https://dagshub.com/blog/dagshub-storage-google-drive-colab/ 我很好奇听听您对此的想法和反馈，以及您还希望看到哪些其他内容... https： //i.redd.it/xgjacauhfvrc1.gif ​   由   提交 /u/PhYsIcS-GUY227   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt5hxw/p_scalable_and_mloriented_google_drive/</guid>
      <pubDate>Mon, 01 Apr 2024 14:41:51 GMT</pubDate>
    </item>
    <item>
      <title>[N] 开源 1.3B 多功能模型和库：SQL 生成、代码解析、文档和带指令传递的函数调用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt0vg9/n_open_source_13b_multicapabilities_model_and/</link>
      <description><![CDATA[pip-library-etl- 1.3b：是我们最先进的库的最新版本，其性能可与 GPT-3.5/ChatGPT 相媲美。 ​  pip-library-etl：用于代码库、函数调用和 SQL 生成的自动化文档和动态分析的库在自然语言测试用例上，该库利用 pip-library-etl-1.3b 来简化文档、动态分析代码并轻松生成 SQL 查询。 ​ 主要功能包括： ​  16.3k 上下文长度 自动库解析和代码文档 示例调整（无需重新训练；每当模型的输出偏离预期时提供正确输出的示例） 函数的静态和动态分析 函数调用 SQL生成 自然语言指令支持    由   提交 /u/Swimming-Trainer-866   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt0vg9/n_open_source_13b_multicapabilities_model_and/</guid>
      <pubDate>Mon, 01 Apr 2024 11:08:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] UAI 2024 审核等候处</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bt0nor/d_uai_2024_reviews_waiting_place/</link>
      <description><![CDATA[一个分享你的想法、祈祷的地方，最重要的是（一旦评论出来），咆哮甚至一些宽慰的评论。    由   提交/u/elemintz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bt0nor/d_uai_2024_reviews_waiting_place/</guid>
      <pubDate>Mon, 01 Apr 2024 10:57:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>