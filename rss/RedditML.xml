<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 18 May 2024 15:14:56 GMT</lastBuildDate>
    <item>
      <title>[R] 鲁棒智能体学习因果世界模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cuzbta/r_robust_agents_learn_causal_world_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.10877 摘要：  长期以来，人们一直假设因果推理在强大而通用的智能。然而，尚不清楚智能体是否必须学习因果模型才能推广到新领域，或者其他归纳偏差是否足够。我们回答了这个问题，表明任何能够在大量分布变化下满足后悔界限的智能体都必须学习数据生成过程的近似因果模型，该模型收敛到最佳智能体的真实因果模型。我们讨论了这一结果对包括迁移学习和因果推理在内的多个研究领域的影响。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cuzbta/r_robust_agents_learn_causal_world_models/</guid>
      <pubDate>Sat, 18 May 2024 15:06:09 GMT</pubDate>
    </item>
    <item>
      <title>[项目]量化YOLOv8x到INT8</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cuzblv/projectquantized_yolov8x_to_int8/</link>
      <description><![CDATA[我在 Nvidia Jetson Orin Nano 中将 YOLOv8x 量化为 INT8，并几乎实时处理（FPS 25）。访问 GitHub 并查看我测试的内容。 https://github.com/the0807/YOLOv8-TensorRT   由   提交/u/the087  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cuzblv/projectquantized_yolov8x_to_int8/</guid>
      <pubDate>Sat, 18 May 2024 15:05:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 命名实体识别库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cuz1i2/d_library_for_named_entity_recognition/</link>
      <description><![CDATA[大家好，我需要决定使用哪个库进行命名实体识别。我使用过 spaCy，它运行良好，但我需要一个允许我对实体和子实体进行分类的库。有人做过类似的事情吗？我的意思是，同一个词可以是多个实体。 spaCy 提供了 SpanCat 管道，理论上可以实现这一点，但我在创建训练语料库时遇到了麻烦。我认为这是因为他们希望你购买像 Prodigy 这样的注释文本框架。   由   提交/u/Original_Ad8019   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cuz1i2/d_library_for_named_entity_recognition/</guid>
      <pubDate>Sat, 18 May 2024 14:52:57 GMT</pubDate>
    </item>
    <item>
      <title>[N] ICML 2024 离散运算可微分研讨会 🤖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cux80i/n_icml_2024_workshop_on_making_discrete/</link>
      <description><![CDATA[大家好！ 我们今年将在 ICML 组织几乎所有事物均可微分研讨会。 许多离散操作，例如排序、topk、最短路径、聚类（等等）几乎在任何地方都有零梯度，因此不适合现代基于梯度的学习框架（例如深度学习）。本次研讨会将涵盖旨在解决此类问题的研究课题！ https://differentiable.xyz/ 我们鼓励任何研究相关主题的人提交他们的工作。即使您不提交，也请参加 ICML 的研讨会，观看一些即将举行的精彩演讲！ 我已在下面附上研讨会的完整摘要！祝你目前的工作一切顺利，L :) 梯度和导数是机器学习不可或缺的部分，因为它们可以实现基于梯度的优化。然而，在许多实际应用中，模型依赖于实现离散决策的算法组件，或依赖于离散的中间表示和结构。这些离散步骤本质上是不可微的，因此会破坏梯度流。要使用基于梯度的方法来学习此类模型的参数，需要将这些不可微分的组件变为可微分的。这可以通过仔细考虑来实现，特别是使用平滑或松弛来为这些组件提出可微分的代理。随着模块化深度学习框架的出现，这些想法在机器学习的许多领域变得比以往任何时候都更受欢迎，在短时间内产生了大量“可微分的一切”，影响了渲染、排序和排名、凸优化器、最短路径、动态规划、物理模拟、NN 架构搜索、top-k、图算法、弱监督和自监督学习等等。 本次研讨会将为任何可微分的事物提供一个论坛，将学术界和行业研究人员聚集在一起，重点介绍挑战和发展，提供统一的想法，讨论实际的实施选择并探索未来的方向。    提交人    /u/machine_learning_res   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cux80i/n_icml_2024_workshop_on_making_discrete/</guid>
      <pubDate>Sat, 18 May 2024 13:22:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于数据库选择和查找的问题。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cuv6fu/d_problems_with_regards_to_database_selection_and/</link>
      <description><![CDATA[你们是否面临着和我一样的问题，你们有一个绝妙的想法和实现 AI / ML 模型的方法。但是......您似乎耗尽了所有精力来寻找相关工作以及适合您需求的正确数据库。 即使您可以找到您需要打开的正确数据库它研究了它，你知道在不同的地方找到数据集。 其次，需要下载数据集（遗憾的是，如果你没有找到它用于协作）。 会很大感谢你们对此的看法。 :)   由   提交 /u/ashmit_jagtap   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cuv6fu/d_problems_with_regards_to_database_selection_and/</guid>
      <pubDate>Sat, 18 May 2024 11:25:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 尖峰神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cut5f5/r_spiking_neural_networks/</link>
      <description><![CDATA[我制作了一个关于经典神经网络、它的问题以及脉冲神经网络如何解决这些问题的视频。非常感谢您的反馈：https://youtu.be/gSyDlvzvhg8  为了处理文本，我使用了 ChatGPT： https://chat.openai.com/ 用于视频中途旅程和 DALL-E 的工作： https://www.midjourney.com https://openai.com/index/dall-e-3/ 用于生成语音 - elevenlabs： https://elevenlabs.io/    提交人    /u/mAxIm_plays   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cut5f5/r_spiking_neural_networks/</guid>
      <pubDate>Sat, 18 May 2024 09:04:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] GPT-Burn：纯 Rust 中简单简洁的 GPT 实现 🔥</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cusmrp/p_gptburn_a_simple_concise_implementation_of_the/</link>
      <description><![CDATA[       由   提交/u/ProfessionalDrummer7   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cusmrp/p_gptburn_a_simple_concise_implementation_of_the/</guid>
      <pubDate>Sat, 18 May 2024 08:25:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为 MacOS 构建 ML 应用程序的最佳方式是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1curusl/d_whats_the_best_way_to_build_ml_apps_for_macos/</link>
      <description><![CDATA[我是一名 Web 开发人员（Python、Django），希望进入 ML 领域。我在 Python 方面拥有丰富的经验，并开始学习 TensorFlow 和 PyTorch。我想开始为 MacOS 构建人工智能应用程序，并且正在尝试找出最佳的工作流程。 到目前为止，我可以想到以下方法：  &lt; li&gt;使用 Python，然后使用 GUI 包（例如 Tkinter） - 很棒，一切都在 Python 中，但 Python GUI 往往有点难看......也不确定这些在应用程序商店中的表现如何。 &lt; li&gt;使用 Electron 并使用 TensorFlow.js - 可以使用 HTML/CSS 设计出色的 UI，但仅限于 TensorFlow.js？ 使用 Swift 和 Core ML 的原生 MacOS 应用 - 从未接触过 Swift 或 Core ML，所以不确定优点/缺点。  有点不确定从哪里开始。非常感谢目前为 MacOS 进行 ML 应用程序开发的人们的任何建议。   由   提交 /u/total_reddit_addict   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1curusl/d_whats_the_best_way_to_build_ml_apps_for_macos/</guid>
      <pubDate>Sat, 18 May 2024 07:29:18 GMT</pubDate>
    </item>
    <item>
      <title>[R] 1:10无线电遥控车自动驾驶</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cuoo2g/r_110_radio_controlled_car_autonomous_driving/</link>
      <description><![CDATA[我非常需要一些建议，希望能够创建一个机器学习模型，该模型从 2 个立体摄像头获取图像输入并输出油门和转向。我正在赛道上驾驶这辆车，在一个可以俯瞰赛道的平台上。我的想法是创建赛道的深度和视差图，并精确定位汽车，然后根据视差图进行跟踪。我从汽车实时获取油门和转向数据。我怎样才能建立一个机器学习模型来接收图像输入并预测油门/转向？   由   提交 /u/Unable_Car4833   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cuoo2g/r_110_radio_controlled_car_autonomous_driving/</guid>
      <pubDate>Sat, 18 May 2024 04:02:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与训练前相比，SFT 的梯度范数更高，但损失更低，为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cunrbn/d_sft_has_higher_grad_norm_but_lower_loss/</link>
      <description><![CDATA[最近，我一直在使用 2B 标记的自定义语料库上持续预训练 OpenELM-1.1B，然后使用自定义指令数据集 w 对其进行微调/ 4M 个样本。 我发现，当使用相似数量的 token 进行训练时，PT 的损失（训练和评估）始终高于 SFT 阶段，但 SFT 的梯度范数高于 PT . 我假设预训练模型在此自定义域上具有较低的 ppl，因此它在 SFT 阶段具有较低的损失。我的问题是，是什么导致 SFT 阶段的梯度范数更高？   由   提交/u/pha123661   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cunrbn/d_sft_has_higher_grad_norm_but_lower_loss/</guid>
      <pubDate>Sat, 18 May 2024 03:11:26 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证训练/验证图 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cumxxs/cross_validation_trainvalidation_graphs_d/</link>
      <description><![CDATA[我们经常看到的模型评估的一个常见趋势是使用交叉验证 CV。作者经常报告从这种方法得出的准确性和其他指标（f-measure、精度等）。除此之外，他们还绘制了损失和准确性的训练和验证图以及混淆矩阵。我的问题是这些图表是如何生成的。它们是使用 k 次交叉验证来绘制的，还是有其他方法在起作用？论文中的示例如下：链接到示例    由   提交 /u/PerfecttMachine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cumxxs/cross_validation_trainvalidation_graphs_d/</guid>
      <pubDate>Sat, 18 May 2024 02:26:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何只保留前 10K 个最常见的 token（transformers 库）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cukc34/p_how_to_keep_only_the_top_10k_most_common_tokens/</link>
      <description><![CDATA[我正在关注 TinyStories 数据集论文它声称“我们使用 GPT-Neo 标记器，但只保留前 10K 个最常见的标记”。我正在尝试创建自己的标记生成器来执行此操作，但意识到我没有合并文件 - 删除顶部标记无法在不重新训练的情况下处理丢失的字节对编码。我对此的理解不是很好，我询问了 GPT，它表明忽略它并使用旧文件而不删除顶部标记并不是一个好主意。  当查看 Huggingface 时，他们的合并和词汇使用了完整的 50k 标记，所以我对如何实现这一点有点困惑。谢谢！   由   提交 /u/Bradmcstark   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cukc34/p_how_to_keep_only_the_top_10k_most_common_tokens/</guid>
      <pubDate>Sat, 18 May 2024 00:10:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师，您工作的哪一部分侧重于部署管道与模型构建/调整？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cub74b/d_machine_learning_engineers_what_portion_of_your/</link>
      <description><![CDATA[我目前是一名机器学习工程师，但我更加关注管道，这与我担任数据工程师时类似。我很想更多地了解模型构建方面的知识，但自从我完成硕士学位以来，我的模型知识已经有点生疏了。  与模型构建相比，您日常工作的哪一部分侧重于部署？   由   提交/u/RawCS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cub74b/d_machine_learning_engineers_what_portion_of_your/</guid>
      <pubDate>Fri, 17 May 2024 17:32:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 子空间嵌入与基本降维有何不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cu8is4/d_how_are_subspace_embeddings_different_from/</link>
      <description><![CDATA[我一直在努力理解更基本的降维技术与更高级的方法有何不同，主要是关于子空间、流形等的直觉是否相同。扩展到更基本的方法。我了解 PCA、t-SNE、UMAP 等如何工作（这些是在寻找维数降维时出现的 90% 的内容），但是当我阅读有关子空间聚类、流形学习或该领域的内容时，他们很少提及这些更基本的暗淡缩减技术，而是选择更高级的方法，我不确定为什么，特别是考虑到 PCA、t-SNE 和 UMAP 似乎是多么多产。 我不清楚像 PCA 这样的东西是否/如何不同于流形学习，特别是它们对于子空间聚类的有用性。我认为两者的目标都是找到一些潜在结构，直觉上在潜在空间中工作将减少噪音、无用/低信息特征，减少维数灾难，并且还可能更清楚地显示特征和标签的情况连接在潜在空间中。就实际算法而言，我理解直觉，但不知道它们是否是“真实的”。例如，在流形学习的情况下（FWIW，我真的不再看到任何相关论文，也不知道为什么会这样），一个常见的例子是“面流形”。对于图像来说，这是一个比原始输入尺寸低的平滑表面，并且从每个面平滑过渡到另一个面。对于图像来说，这可能有点微不足道，但是对于一般的时间序列数据，同样的直觉是否也适用？  例如，如果我有一个时间序列毛毛虫运动的数据集，我可以任意说存在毛毛虫尺寸的流形（较大的毛毛虫移动速度较慢）或毛毛虫能力的流形（例如，某种类型）能力/技能的多样性，如果毛毛虫正在完成任务/迷宫）？非常人为的例子，但基本上问题是，我是否一定能够根据我的先验告诉我应该存在/可能持有潜在结构（给定足够的数据）找到潜在空间？ &lt; p&gt;我知道 Yann LeCun 是在潜在空间中工作的大力支持者（尤其是联合嵌入，我不确定这是否适用于我和我的时间序列数据），所以我尝试更多地开展我的工作那个方向，但似乎基本 PCA 和基本非线性技术（例如，您会看到内置于 scipy 或 sklearn 等的技术）与其他论文中使用的技术之间存在很大分歧。 PCA（或基本非线性方法）等是否能实现相同的效果，但效果却不那么好？   由   提交 /u/Amun-Aion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cu8is4/d_how_are_subspace_embeddings_different_from/</guid>
      <pubDate>Fri, 17 May 2024 15:44:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>