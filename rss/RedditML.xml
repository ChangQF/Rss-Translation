<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 08 May 2024 21:14:27 GMT</lastBuildDate>
    <item>
      <title>[P] 🔍 寻求有关为我的自定义数据集微调 SSD 对象检测的建议 🎯</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cne918/p_seeking_advice_on_finetuning_ssd_object/</link>
      <description><![CDATA[大家好！我正在深入研究对象检测的世界，我的目标是为我的自定义数据集微调 SSD（单次多盒检测器）。经过一些研究后，SSD 的架构似乎与我的项目需求完美契合。 有人推荐可以帮助我完成此任务的教程、笔记本或资源吗？具体来说，我正在寻找有关使用预先训练的特征选择模型获取 SSD 检测器，然后对其进行调整以适合我的数据集的提示。   由   提交/u/JAEng22  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cne918/p_seeking_advice_on_finetuning_ssd_object/</guid>
      <pubDate>Wed, 08 May 2024 20:16:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 如何在单次梯度更新后记住事实？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cne766/d_how_do_transformers_memorize_facts_after_a/</link>
      <description><![CDATA[我想我首先希望引用该事实，或者让有人告诉我这是我编造的。但民间知识是，针对单个时期训练的 Transformer 可以回忆起仅在训练数据集中出现过一次的事实。这意味着一次更新足以修改权重以产生正确的输出（不会灾难性地忘记其他事实）。 这对我来说真的很惊讶。我认为一次大到足以大幅修改输出的单个更新将具有相当大的破坏性，并且考虑到损失情况的非单调性，可能只是无法达到您想要的效果。对于如何/为什么会发生这种情况，是否有一个很好的答案，如果有的话，任何人都可以提供调查此问题的研究链接吗？它是大型模型（如 NTK）的特征，还是 Transformer 架构的特征，还是其他什么？请注意，我不是在询问上下文学习，而是在询问单个梯度步骤的变化。   由   提交 /u/asdfwaevc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cne766/d_how_do_transformers_memorize_facts_after_a/</guid>
      <pubDate>Wed, 08 May 2024 20:14:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 手绘地图中地块的分割</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cndn2u/d_segmentation_of_land_plots_in_hand_drawn_maps/</link>
      <description><![CDATA[我目前正在开展一个个人项目，该项目是从带有文字的黑白地图上分割道路和地产红线之间的土地区域。该过程的第一阶段是对每个地块进行分段和标记。我知道有些模型是通过 Qgis 和 ArcGis 等工具存在的，但出于某种原因，我试图避免直接使用它们。  我的经验主要是在医学图像分割和分类方面，但那些具有固定的类别以及我使用的模型也不会转换为这些数据。因此，我想寻求有关该领域现有模型的指导，我可以参考、微调或从头开始训练。  作为基线，可以使用带有 ResNet 或 VGG 主干的 Unet 来分割土地与道路，但我不确定如何确保它将每个地块标记为单独的对象。此外，任何我可以微调的预训练模型也会有所帮助   由   提交/u/Entire_Ad_6447   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cndn2u/d_segmentation_of_land_plots_in_hand_drawn_maps/</guid>
      <pubDate>Wed, 08 May 2024 19:51:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何选择可靠的 XAI 方法并理解相互矛盾的解释？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cn9wlk/d_how_to_select_reliable_xai_methods_and_make/</link>
      <description><![CDATA[      https://preview.redd.it/baife9rhc8zc1.png?width=858&amp;format=png&amp;auto=webp&amp;s=149789e027657 cb292398427be23ae4e8f09a817 该图来自 http://arxiv.org/abs/2206.04394，名为 xplique 的库。它旨在显示作者已包含在库中的所有不同归因方法。然而，在我看来，不同的方法可能会突出显示这些图像中的不同区域和像素结构，在某些情况下部分或很少重叠。最终，我将得到一个模型、一个预测和一个基本事实（我可能知道也可能不知道）。我应该使用哪种方法来解释给定的预测？我怎么知道事先应该选择哪一个呢？即使我更改模型架构和数据域，是否有一种方法始终有效？ （假设这里仅使用事后方法） 我目前正在从实用性和用户清晰度的角度对表格数据的不同 XAI 方法进行比较分析。我有兴趣了解当前对于全球和本地解释的可靠方法的共识是什么。也就是说，考虑到当今 XAI 方法和库的种类繁多，是否有广受青睐的方法？或者相反，通常会避免？除此之外，我想考虑方法的稳健性（它是否适用于不同类型的模型和不同的数据域？），以及解释本身的可解释性（理解解释本身并将其传达给非技术人员有多容易）用户）。由此，我还想知道，有没有办法衡量解释的质量（或适用性）？也就是说，我如何知道我正在查看的解释是否确实有意义/我是否针对给定的用例使用了正确的方法？尽管上面的示例与计算机视觉相关，但我怀疑在表格数据的情况下我也会发现类似的问题。 关于高度可信或通常避免的方法/库有什么建议吗？   div&gt;  由   提交/u/xian-yu  /u/xian-yu  reddit.com/r/MachineLearning/comments/1cn9wlk/d_how_to_select_reliable_xai_methods_and_make/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cn9wlk/d_how_to_select_reliable_xai_methods_and_make/</guid>
      <pubDate>Wed, 08 May 2024 17:13:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 现实世界坐标中的距离估计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cn9soh/d_distance_estimation_in_real_world_coordinates/</link>
      <description><![CDATA[https://preview.redd.it/tau7j3rna7zc1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=1a733f6b094b87e24a460c710db70 7e87061f497 https://preview.redd.it/97h7i3rna7zc1.jpg?width=1280&amp;format =pjpg&amp;auto=webp&amp;s=1f2dd8f21de8a05d39e02815eabbf67811809597 https://preview.redd.it/8da4g3rna7zc1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=9334dca0bbeb926e147307d434b5b394db 5a214a 你好，&lt; br /&gt; 我有三个摄像头，我想在框架中找到从 a 点到 b 点的距离（以米为单位），正如您在上传的图像中看到的具有地面实况值一样。 可以有人请指导/建议我如何解决这个问题吗？ 我尝试过什么？  我使用 opencv 校准了每个相机，还使用了 matlab 校准器工具，并且我重投影误差小于 0.5 像素。我有内在和外在参数。使用这些参数，我应用了 DLT 算法来查找两点之间的距离，但值相差很大。 当画面中有人时，我尝试使用已知的 0.45m（人体宽度）参考。我试图获得从摄像机 1 到人 1、摄像机 1 到人 2 的距离。使用这两条边的长度，我试图获得第三条边，但我没有角度。我尝试使用 SIFT 并使用三角测量方法来获取深度和角度，但得到的值为 8000、7000m。 我尝试分割和检测每个人的姿势来获取肩部到肩部的距离，但是无法获得接近真实情况的值。  请指导和建议。非常感谢。 相机详细信息 - Unifi G4 Pro。 || || |镜头| 4.1–12.3 毫米华氏度； f/1.53–f/3.3| |视角|广角：水平：109.9°，垂直：60°，深度：127.7° 变焦：水平：35°，垂直：19.8°，深度：40°|   由   提交 /u/Exciting-Cod4820    reddit.com/r/MachineLearning/comments/1cn9soh/d_distance_estimation_in_real_world_coordinates/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cn9soh/d_distance_estimation_in_real_world_coordinates/</guid>
      <pubDate>Wed, 08 May 2024 17:08:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有趣的小发现：双子座在遵循简单的数字序列方面出奇地糟糕</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cn9ejf/d_fun_little_discovery_gemini_is_surprisingly_bad/</link>
      <description><![CDATA[试试这个：告诉它按顺序回复下一个数字，从 1 开始，然后你回复下一个，依此类推。几条消息之后，它开始输出文本而不是数字，大约 20 条消息之后，它完全无法继续遵循序列。  最初的目标是找出它的长期记忆有多好，这似乎很糟糕。鉴于其巨大的上下文窗口，它怎么会这么快失去注意力？    提交人    /u/ifilipis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cn9ejf/d_fun_little_discovery_gemini_is_surprisingly_bad/</guid>
      <pubDate>Wed, 08 May 2024 16:52:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练时奇怪的损失曲线</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cn94yq/d_strange_loss_curve_while_training/</link>
      <description><![CDATA[https://preview.redd.it/z5wmyi0nb8zc1.png?width=599&amp;format=png&amp;auto=webp&amp;s=97e108bd749f9cf0874759f7ba0b8aafb3 260640 今天我正在训练一个文本数据集上的小（1107 万）参数 GPT 模型，我在训练时遇到了这条损失曲线，是否有任何解释为什么损失首先稳定在 2.4 左右，然后开始呈指数下降？另外，为什么在大约 1200 步之间会突然出现峰值？  我使用的数据集是整部小说“一百年的孤独” &lt; li&gt;训练数据集中的总 token 数量为 82 万，词汇量为 77（我使用的是字符级 tokenizer） 6 个转换器层，有 6 个注意力头，每个都没有偏差在任何项目且没有 dropout 层中，上下文长度为 1024，批量大小为 32    由   提交 /u/ApartmentEither4838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cn94yq/d_strange_loss_curve_while_training/</guid>
      <pubDate>Wed, 08 May 2024 16:41:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 中使用序列打包时的文档内前缀（累积）总和</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cn2ihx/d_intradocument_prefix_cumulative_sum_when_using/</link>
      <description><![CDATA[      根据 &lt; a href=&quot;https://x.com/PMinervini/status/1781080046972604739&quot;&gt;X 上的这篇文章，LLaMa 3 使用Intra -在预训练期间记录因果屏蔽，以避免使用序列打包时的交叉污染： &lt; a href=&quot;https://preview.redd.it/14e5ml4bs6zc1.jpg?width=680&amp;format=pjpg&amp;auto=webp&amp;s=58e7e1764aeafe412237fb731488873aeb911e88&quot;&gt;因果屏蔽与文档内因果屏蔽 与简单地放置分隔符相比，这似乎提高了模型在各种任务中的最终性能 - 例如文本结束标记 - 位于文档之间，并希望模型能够学会在预训练期间不关注不相关的文档，如 GPT-3 论文&lt;中所述/a&gt;:  在训练期间，我们总是在完整的 nctx = 2048 token 上下文窗口的序列上进行训练，当文档短于 2048 时，将多个文档打包到单个序列中，以增加计算量效率。具有多个文档的序列不会以任何特殊方式进行屏蔽，而是使用特殊的文本标记结尾来分隔序列中的文档，从而为语言模型提供必要的信息来推断由文本标记结尾分隔的上下文是不相关的。这允许有效的训练，而不需要任何特殊的序列特定掩蔽。  我想在我的实验中使用前一种 - 文档内 - 方法，但我偶然发现了一个问题。在标准转换器实现中，令牌之间的唯一交互是通过注意机制，因此使用适当的屏蔽就足够了。然而，我使用稍微修改过的版本，它还计算查询和键的累积（前缀）总和，以引入位置偏差，与 RoPE 或 ALiBi 相比，该版本似乎工作得很好。这里不详细介绍相关代码： #cumulative/prefix sum acrossequence q_pos = q.cumsum(-3) k_pos = k.cumsum(-3)   现在，如果没有文档内因果屏蔽或在推理过程中，此代码可以正常工作，但是当序列被打包时，它可能包含一堆不相关的文档。 我想以某种方式阻止来自过去不相关文档的“cumsum”的查询和键污染操作并高效地完成 - 无需 python 循环。这里最好的方法是什么？   由   提交/u/kiockete  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cn2ihx/d_intradocument_prefix_cumulative_sum_when_using/</guid>
      <pubDate>Wed, 08 May 2024 11:45:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 包含数万个视觉内容的多样化且高清（质量）的数据集对于计算美学研究有多大价值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cn1f4o/d_how_valuable_is_a_diverse_and_highdefinition/</link>
      <description><![CDATA[计算美学研究人员正在探索计算机如何分析并潜在地创造美观的视觉体验。这项研究的一个关键组成部分是能够访问大量、多样化且高质量视觉内容的数据集。 我很想听听社区的意见：  一个包含数万张多样化高质量图像和视频的数据集对于计算美学研究有多大价值？ 这样的数据集可能带来哪些具体好处（例如，训练 AI 模型、评估美学品质、探索不同的艺术风格）？  我有兴趣向研究人员、艺术家以及任何对 AI 和美学的交集感兴趣的人学习。 此外：  计算美学中可以从此类数据集中受益的研究领域的一个具体示例（例如，风格转换、艺术品质评估）。 为不熟悉该领域的人提供解释计算美学的文章或资源的链接（可选）。     由   提交  /u/Same_Half3758   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cn1f4o/d_how_valuable_is_a_diverse_and_highdefinition/</guid>
      <pubDate>Wed, 08 May 2024 10:40:07 GMT</pubDate>
    </item>
    <item>
      <title>【研究】xLSTM：扩展长短期记忆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmwljs/research_xlstm_extended_long_shortterm_memory/</link>
      <description><![CDATA[摘要： 20世纪90年代，恒定误差轮播和门控被引入作为长短期的中心思想记忆（LSTM）。从那时起，LSTM 经受住了时间的考验，并为许多深度学习的成功案例做出了贡献，特别是它们构成了第一个大型语言模型 (LLM)。然而，以并行自注意力为核心的 Transformer 技术的出现标志着一个新时代的到来，其规模超过了 LSTM。我们现在提出一个简单的问题：当将 LSTM 扩展到数十亿个参数、利用现代法学硕士的最新技术、同时缓解 LSTM 的已知局限性时，我们在语言建模方面能走多远？首先，我们引入具有适当归一化和稳定技术的指数门控。其次，我们修改 LSTM 内存结构，获得：（i）具有标量内存、标量更新和新内存混合的 sLSTM，（ii）具有矩阵内存和协方差更新规则的完全可并行化的 mLSTM。将这些 LSTM 扩展集成到残差块主干中会产生 xLSTM 块，然后将这些块残差地堆叠到 xLSTM 架构中。与最先进的 Transformer 和状态空间模型相比，指数门控和修改后的内存结构增强了 xLSTM 的性能，无论是在性能还是扩展方面。 链接：xLSTM：扩展长短期记忆   由   提交 /u/Background_Thanks604   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmwljs/research_xlstm_extended_long_shortterm_memory/</guid>
      <pubDate>Wed, 08 May 2024 05:06:40 GMT</pubDate>
    </item>
    <item>
      <title>非技术性 ML 播客？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmntyr/non_technical_ml_podcasts_d/</link>
      <description><![CDATA[大家好。我是一名刚毕业的计算机科学专业学生，目前是一名入门级数据工程师，我一直很喜欢学习机器学习模型和技术，以及如何实现、部署和扩展它们。我正在寻找一个好的播客，以便随时了解机器学习趋势，但挑战在于我不太喜欢听技术性播客，因为我还是个新手，而且通常阅读这些播客可以更好地理解复杂性。我试过一些播客，但大多数时候我都听不懂，听得头晕目眩。我正在寻找一些可以在上班途中不用想太多就能听的东西。非常欢迎任何建议！    提交者    /u/C-beenz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmntyr/non_technical_ml_podcasts_d/</guid>
      <pubDate>Tue, 07 May 2024 21:52:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] PEFT技术在行业中的实际应用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmirbu/d_peft_techniques_actually_used_in_the_industry/</link>
      <description><![CDATA[关于变压器参数高效微调的大量工作正在涌现，但其中有多少真正得到应用？我也很好奇你们在行业中通常使用哪些技术？   由   提交/u/Inner_Programmer_329   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmirbu/d_peft_techniques_actually_used_in_the_industry/</guid>
      <pubDate>Tue, 07 May 2024 18:23:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] Skyrim - 大型天气模型的开源模型动物园</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmfbzc/p_skyrim_opensource_model_zoo_for_large_weather/</link>
      <description><![CDATA[Github 链接  &lt; p&gt;大家好，我是来自 Secondlaw AI 的 Efe。我们正在构建基于物理的大型人工智能模型。目前，我们专注于天气建模。 为了对 SOTA 进行基准测试，我们必须为所有可用的大型天气模型构建预测基础设施，但我们找不到可靠的工具来实现这一点，因此我们构建了 Sykrim。在 &lt;5 分钟和 &lt;5 LOC 内，您可以运行与在 100K+ CPU HPC 上运行的全球天气模型相当的预报！您可以在此处查看示例。 我们是实施更多模型和微调能力。如果我们还可以添加任何内容，请告诉我们，很高兴回答任何问题！   由   提交/u/0xe5e  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmfbzc/p_skyrim_opensource_model_zoo_for_large_weather/</guid>
      <pubDate>Tue, 07 May 2024 15:58:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过 Arduino Nano ESP32（Ridge 分类）进行水生超声波扫描来识别潜伏在基质中的有毒水下气泡，并同时通过 UNIHIKER (NVIDIA TAO RetinaNet) 根据化学（颜色编码）水质测试评估水污染。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cmcfv4/p_identify_toxic_underwater_air_bubbles_lurking/</link>
      <description><![CDATA[   /u/the-amplituhedron  /u/the-amplituhedron reddit.com/gallery/1cmcfv4&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cmcfv4/p_identify_toxic_underwater_air_bubbles_lurking/</guid>
      <pubDate>Tue, 07 May 2024 13:53:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>