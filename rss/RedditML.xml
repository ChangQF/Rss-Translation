<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Thu, 08 Aug 2024 12:28:56 GMT</lastBuildDate>
    <item>
      <title>免费聊天机器人课程 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en41ku/free_chatbot_course_p/</link>
      <description><![CDATA[免费聊天机器人课程 [P] 大家好 我负责一个致力于 AI 的新闻通讯项目，并为我的订阅者提供了一门关于 AI 和聊天机器人的免费课程。我想把它放在这里，以防有人觉得它有用。 该课程由专注于在线教育的初创公司 GrowthSchool.io 开设。它的零售价为 199 美元，时长 3 小时，通过 Zoom 举行。它深入探讨了即兴写作、使用 AI 和 Excel、刚刚发布的新功能以及构建您自己的自定义 GPT。 您可以在我的网站上找到该课程，该网站链接在我的 Reddit 简历中。    提交人    /u/cognitive_courier   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en41ku/free_chatbot_course_p/</guid>
      <pubDate>Thu, 08 Aug 2024 11:57:55 GMT</pubDate>
    </item>
    <item>
      <title>机器学习工程师（1 年经验）正在寻找班加罗尔的开放机会 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en3msc/ml_engineer_1_yoe_looking_for_an_open_opportunity/</link>
      <description><![CDATA[ML 工程师（1 YOE）寻找空缺职位  大家好。我是一名机器学习工程师，正在寻找班加罗尔的空缺职位。我有 1 年的开发和部署 ML 解决方案的经验，将基本 ML 基础知识（如回归模型和数据分析）转化为使用向量 DB 和 Langchain 构建 RAG 应用程序。我曾使用机器学习和深度学习将想法转化为 POC。 我的技术栈包括 Python、Jupyter Notebook、Sci-kit Learn、Langchain、Vector DB、针对特定用例微调 LLM。 我还在开发和部署端到端 LLM 应用程序到 AWS 云方面经验丰富。我对 ML 充满热情。 任何线索都将不胜感激。谢谢     提交人    /u/Embarrassed_Bread121   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en3msc/ml_engineer_1_yoe_looking_for_an_open_opportunity/</guid>
      <pubDate>Thu, 08 Aug 2024 11:35:52 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何使用学习率来匹配论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emxx6a/d_how_to_use_learning_rate_to_match_papers/</link>
      <description><![CDATA[你好！ 我正在复现一些论文，但我一直面临训练不稳定的问题，除非我降低论文中的学习率，因为在几篇论文中我发现我可能是错的。 假设我们有一篇论文，使用 M GPU 以批量大小 N（每个 GPU）训练网络，以学习率为 LR 进行训练。训练几乎总是使用 float16 和 adam/adamw。我正在使用 pytorch amp 进行混合精度训练。 大多数论文要求我正在训练（TTS 任务）在 16/32 gpu 上进行训练，但我不想进行分布式训练，我只使用更快的 GPU 进行 2 倍、4 倍或 8 倍训练，但使用梯度累积（G）。 不同的框架对如何在多 GPU 环境中指定学习率的定义不同。 我现在正在使用 Accelerate，它建议将学习率乘以使用的 GPU 数量，但不清楚如何处理梯度累积以及论文最初如何定义学习率。 我的选择是：  LR - 按原样使用 LR * M - 乘以论文中原始 GPU 的数量 LR * M / G - 乘以不使用梯度累积的实际 GPU 数量 LR * G - 乘以按梯度累积次数  现在我已经尝试了#3，但是梯度爆炸，我除以二，它通常是稳定的，但它与任何其他公式都不匹配。 另外，不清楚论文中使用了什么框架（论文主要来自 Meta 和 Microsoft），这可能会影响 LR 不匹配。    提交人    /u/stevekite   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emxx6a/d_how_to_use_learning_rate_to_match_papers/</guid>
      <pubDate>Thu, 08 Aug 2024 05:27:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在我的检索增强生成操作用例中，是否真的需要创建索引和使用矢量数据库？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emm3s8/d_is_creating_indexes_and_using_vector_databases/</link>
      <description><![CDATA[我的用例很简单： 我需要从 1-3 页的小文档中提取信息。  方法 1：我应该将文档中的整个文本与查询一起附加并将其传递给 LLM 吗？我认为这可以完成工作（我可能错了），因为最终的标记数肯定会小于 LLM 的上下文窗口大小。 方法 2：或者我应该将其拆分成块并将它们存储在带有索引的矢量数据库中，然后在将其传递给 LLM 之前检索相关块？我能想到的唯一优势是将来在大型文档的情况下具有可扩展性。如果是小文档，它会提高检索的准确性吗？ 由于文档很小，处理时间不是问题。我主要关心的是准确地从文本中提取信息。如果方法 2 有助于提高准确性，我会采用它。  任何建议都会有所帮助！    提交人    /u/Wise-Grand-8374   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emm3s8/d_is_creating_indexes_and_using_vector_databases/</guid>
      <pubDate>Wed, 07 Aug 2024 20:14:25 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 多模式人工智能聊天机器人令人费解的失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emi095/research_the_puzzling_failure_of_multimodal_ai/</link>
      <description><![CDATA[      https://preview.redd.it/ummnvenf1ahd1.png?width=2592&amp;format=png&amp;auto=webp&amp;s=7115ba5de026ada17b0636ec2fa3c3151b3e5eb6 GPT-4o 和 Gemini 等聊天机器人模型在理解图像和文本方面表现出了令人印象深刻的能力。然而，它们是否能模仿人类的一般智力和推理能力尚不清楚。为此，PuzzleVQA 是多模式拼图的新基准，用于探索当前模型的极限。如上所示，即使是 GPT-4V 这样的模型也很难理解儿童可以掌握的简单抽象模式。 https://preview.redd.it/7l5fmuys1ahd1.png?width=2716&amp;format=png&amp;auto=webp&amp;s=337118dbc55230637cec1b08b90ae943746ddbb0 尽管谜题看似简单，但我们观察到当前多模态 AI 模型的表现却出奇地差。值得注意的是，与人类的表现仍然存在巨大差距。因此，自然而然地出现了一个问题：是什么导致了模型的失败？为了回答这个问题，我们进行了瓶颈分析，逐步为模型提供真实“提示”，例如用于感知或推理解释的图像标题。如上所示，我们发现领先的模型在视觉感知和归纳推理方面面临关键挑战。这意味着他们无法准确地感知图像中的物体，并且在识别正确的模式方面也很差。 https://arxiv.org/abs/2403.13315    提交人    /u/chiayewken   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emi095/research_the_puzzling_failure_of_multimodal_ai/</guid>
      <pubDate>Wed, 07 Aug 2024 17:33:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有一个适合进行通用智能开发技术讨论的社区？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emhuwa/d_is_there_an_appropriate_community_for_technical/</link>
      <description><![CDATA[确认该帖子没有讨论 AGI，版主可以删除它。我知道与 AGI 相关的帖子应该直接发送到 r/singularity，但 reddit 似乎主要充斥着炒作和哲学化新闻文章的非技术性帖子。我认为在 ML 领域有很多关于技术方法、问题和研究的有效讨论，以创建通用智能，例如脉冲网络、进化算法、记忆增强网络、RL 等。出于技术原因，我认为仅仅扩展当前方法 (LLM) 并不能让我们实现这一目标，而且我们还差得很远，但我不想在这篇文章中讨论这个问题。相反，是否有针对专注于 AGI 技术工作、研究和实践讨论的社区或其他团体的建议？    提交人    /u/Revolutionary-Fig660   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emhuwa/d_is_there_an_appropriate_community_for_technical/</guid>
      <pubDate>Wed, 07 Aug 2024 17:27:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 加入项目委员会有什么好处？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emh4i8/d_what_are_the_benefits_of_being_on_a_program/</link>
      <description><![CDATA[我很好奇，在 ML 会议上，加入程序委员会意味着什么，以及为什么人们会选择加入程序委员会。 作为 ML 会议的审稿人，我认为深入阅读几篇论文是有好处的。加入程序委员会有什么好处？我的理解是，这份工作主要是 ping 审稿人、总结评论和其他管理任务。    提交人    /u/smorad   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emh4i8/d_what_are_the_benefits_of_being_on_a_program/</guid>
      <pubDate>Wed, 07 Aug 2024 16:59:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 AAAI 投稿评论的公开访问权的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emengc/d_question_about_public_access_to_reviews_for/</link>
      <description><![CDATA[我正在准备向 AAAI 提交论文，今年 AAAI 使用 OpenReview。有人知道在审查过程结束后，所有评论（包括被拒绝的论文的评论）是否会公开吗？我在 AAAI 网站上找不到此信息。谢谢！    提交人    /u/RudeFollowing2534   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emengc/d_question_about_public_access_to_reviews_for/</guid>
      <pubDate>Wed, 07 Aug 2024 15:24:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 训练嵌入模型以忽略主题不必要的维度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emcrem/p_training_an_embedding_model_to_ignore/</link>
      <description><![CDATA[嗨， 我正在为固定的一组特定主题的文档构建知识管理工具。主要目标是使这些文档在嵌入空间中“可探索”并智能地聚类。但是，我注意到大多数嵌入都非常接近，我认为这是因为它们都围绕同一主题。 我的想法是微调模型以淡化嵌入空间的其余部分，从而增强同一主题内的差异并使其更具可比性。我最初尝试使用 PCA 来实现这一点，但结果并不好。我正在探索的另一个想法是在嵌入上使用小型自动编码器，或者可能为此目的微调开源嵌入模型。但是，我不确定如何开始。 有人有这方面的经验吗？如果是，您使用了哪些方法、模型、框架或来源，结果如何？ 此外，我正在寻找在此基础上对数据集进行良好的视觉探索。虽然美学是次要的，但我对任何有效绘图方法的建议都很感兴趣。    提交人    /u/zeronyk   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emcrem/p_training_an_embedding_model_to_ignore/</guid>
      <pubDate>Wed, 07 Aug 2024 14:09:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] Neurips 2024 的反驳现在可供审稿人查看吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emc004/d_are_neurips_2024_rebuttal_viewable_to_reviewers/</link>
      <description><![CDATA[这应该在几个小时前就发生了，但我审阅的论文仍然只显示原始评论，没有反驳。发生了什么事？    提交人    /u/fixed-point-learning   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emc004/d_are_neurips_2024_rebuttal_viewable_to_reviewers/</guid>
      <pubDate>Wed, 07 Aug 2024 13:37:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何追踪你所有的实验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emakgn/d_how_do_you_keep_track_of_all_your_experiments/</link>
      <description><![CDATA[大家好， 在我的公司，我们正在进行大量 LLM 实验。 我们目前正在进行“小规模”实验来做各种事情（选择各种超参数、进行一些小的架构更改、使用什么数据集等...） 我们正在使用 WandB，记录实验非常酷，但我不知道在协作方面有什么功能可以更进一步。例如，我们希望有一些东西可以从我们启动的各种实验/图中得出结论，理想情况下将图和结论存储在一个地方。 这样，我们就可以轻松地跟踪所有内容，特别是当我们几个月后回顾实验时，我们能够理解我们启动它的原因以及得出的结论是什么。 你是如何做到的？您是否使用特定工具？    提交人    /u/Theboredhuman_56   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emakgn/d_how_do_you_keep_track_of_all_your_experiments/</guid>
      <pubDate>Wed, 07 Aug 2024 12:32:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大型科技公司与生物科技公司的 AI/ML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1em3ke2/d_aiml_in_big_tech_vs_biotech/</link>
      <description><![CDATA[我很好奇为什么一个优秀的 ML 工程师会离开大型科技公司（如谷歌、微软或 OpenAI）并加入生物科技公司。与科技公司正在发生的所有前沿创新相比，生物科技的吸引力何在？    提交人    /u/Pleasant_Wish1799   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1em3ke2/d_aiml_in_big_tech_vs_biotech/</guid>
      <pubDate>Wed, 07 Aug 2024 05:13:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么过度参数化和重新参数化会产生更好的模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elvkz6/d_why_does_overparameterization_and/</link>
      <description><![CDATA[Apple 的 mobileCLIP 网络的主干是 FastVIT，它在训练和推理时间之间使用网络重新参数化来生成具有更好性能的较小网络。我最近在几篇论文中看到了这种现象，但基本思想是在训练期间对模型进行过度参数化，然后在数学上减少它以进行推理。例如，您可以创建两个“分支”，每个分支都是一个独立的转换操作，然后将结果相加，而不是执行单个转换操作。它在训练期间将操作的参数加倍，但在推理期间您“重新参数化”在这种情况下，这意味着将两个分支的权重/偏差加在一起，从而产生一个数学上相同的卷积操作（相同的输入，相同的输出，一个卷积操作而不是两个相加的分支）。 通过在训练期间在几个操作上添加跳过连接，然后在推理期间将跳过数学地合并到操作权重中以产生相同的输出，而无需保留较早的层张量或进行额外的添加，也可以完成类似的技巧。 这种情况似乎等同于在训练期间将 y = a*x + b 修改为 y = (a1+a2)*x +b1+b2 以获得更多参数，然后只需返回基本形式使用 a = a1+a2 和 b = b1+b2 进行推理即可。 我从数学上理解这些操作是等效的，但我不太明白为什么过度参数化用于训练，然后减少参数化用于推理会产生更好的模型。我天真地认为，这会给网络增加更多的内存和计算，降低训练速度，而实际上并没有增强模型的容量，因为过度参数化的操作在数学上仍然等同于单个操作，无论它们是否真的减少了。这背后有强有力的理论吗，还是有人尝试过的一个有趣的想法碰巧奏效了？    提交人    /u/Revolutionary-Fig660   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elvkz6/d_why_does_overparameterization_and/</guid>
      <pubDate>Tue, 06 Aug 2024 22:43:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>