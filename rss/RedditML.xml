<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 21 Feb 2024 12:23:27 GMT</lastBuildDate>
    <item>
      <title>[D] 将语言模型扩展到 128K 上下文的数据工程 - MIT 2024 - 具有 128k 上下文的新开放 LLaMA-2 7B 和 13B！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awagj3/d_data_engineering_for_scaling_language_models_to/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.10171 Github： https://github.com/FranxYao/Long-Context-Data-Engineering 内部有 128k 上下文的新模型！&lt; /p&gt; 摘要：  我们研究了将语言模型的上下文长度扩展到 128K 的持续预训练方法，重点是数据工程。我们假设长上下文建模，特别是在任意输入位置利用信息的能力，是一种大部分已经通过大规模预训练获得的能力，并且这种能力可以很容易地扩展到比训练期间看到的更长的上下文（例如，4K 到 128K）通过对适当的数据混合进行轻量级持续预训练。 我们调查了持续预训练的数据数量和质量：(1) 对于数量，我们表明 5 亿到 50 亿个令牌足以使模型能够在 128K 上下文中的任何位置检索信息； (2) 对于质量，我们的结果同样强调域平衡和长度上采样。具体来说，我们发现，对书籍等某些领域的较长数据进行上采样（现有工作的常见做法）会带来次优的性能，并且平衡的领域混合很重要。我们证明，在此类数据的 1B-5B 标记上对完整模型进行持续预训练是一种有效且经济实惠的策略，可将语言模型的上下文长度扩展到 128K。我们的方案优于强大的开源长上下文模型并缩小了与 GPT-4 128K 等前沿模型的差距。  https://preview.redd.it/bedg1gsgixjc1.jpg?width=1447&amp;format=pjpg&amp;auto=webp&amp;s=cdf15e90c375988b169fd24ffd5d45 05da002593  https://preview.redd.it/2qy3dhsgixjc1.jpg？ width=1837&amp;format=pjpg&amp;auto=webp&amp;s=2ced604b9e1360ee8d170773a1a0600523288516 https://preview.redd.it/pebawhsgixjc1.jpg?width=1446&amp;format=pjpg&amp;auto=webp&amp;s=4a57b8bb6685d6122d51a67e 4fa9645555c51d5a &lt; p&gt;https://preview.redd.it/o8v3kisgixjc1。 jpg?width=577&amp;format=pjpg&amp;auto=webp&amp;s=6d39b7736dc9221ed69e1c61ca36f303e8ef131e   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awagj3/d_data_engineering_for_scaling_language_models_to/</guid>
      <pubDate>Wed, 21 Feb 2024 12:05:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果一篇论文没有可用的开源代码，您是否可以为了娱乐/练习而实现该代码，并将其发布在您自己的 Github 上并附上适当的引用，并注明所有功劳均归作者所有？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awaeo0/d_if_a_paper_has_no_open_source_code_available/</link>
      <description><![CDATA[大家好， 我在发表于 的一篇论文中找到了物理数值计算的 ML 实现的描述具有 CC4 许可证的 arXiv（除了 arXiv 之外，它还发表在期刊上，但我只查看 arXiv 版本）： 您可以自由地：共享 — 复制并重新分发以下内容用于任何目的的任何媒体或格式，甚至是商业目的。改编——为任何目的（甚至商业目的）重新混合、转换和构建材料。只要您遵守许可条款，许可方就不能撤销这些自由。根据以下条款： 归属 - 您必须给出适当的信用，提供许可证的链接，并注明是否进行了更改。您可以以任何合理的方式这样做，但不得以任何暗示许可方认可您或您的使用的方式。相同方式共享 — 如果您对材料进行重新混合、转换或构建，则必须在与原始材料相同的许可下分发您的贡献。无额外限制 — 您不得应用法律条款或技术措施来合法限制他人执行许可证允许的任何操作。  据我所知，该论文没有开源代码。 如果我尝试编写自己的实现，从学术行为角度来看是否有任何问题？论文中的 ML 内容并将其发布到我自己的 Github 上？当然，我会引用这篇论文，并说这个项目中的所有内容都是基于该论文。 我真的不想联系作者来要求诚实。我想知道无论是否联系作者都可以这样做。想象一下，每次您想做类似的事情时都必须这样做（例如，练习实现“注意力就是您所需要的一切”）。 非常感谢！   由   提交/u/Invariant_apple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awaeo0/d_if_a_paper_has_no_open_source_code_available/</guid>
      <pubDate>Wed, 21 Feb 2024 12:02:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻求开发字体阅读器以从扫描图像中准确识别文本的指导</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awadzt/p_seeking_guidance_on_developing_a_font_reader/</link>
      <description><![CDATA[大家好， 我正在着手一个项目，开发或寻找一种能够从扫描图像中读取文本的解决方案，并且将其转换为可编辑文本，重点关注基于阿拉伯文字的特定字体，但包含几个附加字符，总计四十多个。该脚本具有独特的功能和特征，使其成为光学字符识别 (OCR) 技术的一个具有挑战性但又令人着迷的主题。 目前，在线提供的该脚本的数字化材料很稀缺。我可以访问一些使用自定义字体手动输入的书籍。数字打字的方式不太有利于 OCR 识别。例如，对这些书籍进行数字化的人使用现有的 Unicode 字符，并通过将字形更改为类似于脚本字符来修改它们。一个例子包括使用 Unicode 符号并更改它们来表示准确表示所需的特定字符，这些字符直到几年前才得到 Unicode 的正式认可，而这些书籍在二十多年前就已数字化。 考虑到这些由于复杂性，我正在寻求以下方面的建议和见解：  考虑到其以阿拉伯语为基础，是否有任何 OCR 工具或库可以针对具有如此独特特征的脚本进行调整或培训脚本，但进行了重大修改？ 考虑到具体的挑战和识别自定义修改的 Unicode 字符的需要，开发自定义 OCR 解决方案的最佳方法是什么？ 如何我解决了现有数字材料中非标准、手动编辑的 Unicode 字符的问题，以确保准确的文本识别？ 是否有任何推荐的资源、数据集或技术来训练 OCR 系统识别此脚本，特别是考虑到缺乏在线数字化材料？  来自 OCR 技术、语言支持或类似项目经验丰富的人员的任何指导、建议或见解都将非常宝贵。我致力于保存和数字化此脚本中的文本，并相信强大的 OCR 系统可能是向前迈出的重要一步。 提前感谢您的帮助和支持。   由   提交 /u/Ok-Necessary-6455   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awadzt/p_seeking_guidance_on_developing_a_font_reader/</guid>
      <pubDate>Wed, 21 Feb 2024 12:01:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用有限的资源促进人工智能理解我的民族语言</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awa7au/d_facilitating_ai_understanding_of_my_ethnic/</link>
      <description><![CDATA[我的兴趣在于人工智能技术（例如 ChatGPT）学习和理解我的民族语言的潜力，目前这种语言在网上的数字资源很少可用的。我渴望探索如何利用人工智能来弥合语言差距，并将我的语言纳入人工智能可以理解的语言列表中，尽管它很罕见。 我探究的核心是通过以下方式理解这一过程：哪些人工智能模型，特别是那些为语言理解而构建的模型，可以学习缺乏大量文档的语言的语法。这些模型能否在没有直接语法指导的情况下，从可用文本（例如书籍）中自主推断语法结构？此外，在没有综合词典或翻译的情况下，人工智能如何推断出单词的含义？ 我特别问这个问题是因为我想为人工智能能够更有效地理解我的民族语言做出贡献。广泛使用的语言。我就应该开始编译和在线访问哪些类型的资源或数据寻求建议，以协助这一教育过程。 您对如何实现这一目标的见解和建议对我来说非常宝贵。为我的民族语言融入人工智能的语言能力铺平道路。 期待就这一独特的挑战进行讨论并提出实用建议。   由   提交 /u/Ok-Necessary-6455   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awa7au/d_facilitating_ai_understanding_of_my_ethnic/</guid>
      <pubDate>Wed, 21 Feb 2024 11:51:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当使用大值进行回归训练时，使用值的对数还是值本身来训练模型更好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aw9csl/d_when_doing_regression_training_with_large/</link>
      <description><![CDATA[我正在训练一个模型来根据缩略图预测观看次数，并且由于观看次数相当大（数百万），我想知道我是否应该使用viewcount的日志而不是直接使用viewcount来防止损失函数爆炸。  有人对此有任何见解吗？ lr = 1e-5 batch_size=8 optimizationr = torch.optim.AdamW(model.parameters(),lr=lr) train_dataloader = torch.utils.data.DataLoader(mapped_dataset.with_format(&#39;torch&#39;), batch_size=batch_size) loss_func = nn.MSELoss()  基于日志的代码： &lt; pre&gt;对于tqdm中的批次（train_dataloader，total=1296//batch_size）：img_resized = batch[&#39;normalized_image&#39;].reshape（-1,3,720, 1296）views = torch.log(torch.tensor(batch[ &#39;views&#39;]）.to（device）.to（torch.float32））.reshape（-1,1）output_view = model（img_resized.cuda（））loss = loss_func（output_view，views）optimizer.zero_grad（）loss .backward() # torch.nn.utils.clip_grad.clip_grad_norm_(model.parameters(), 1.0) optimizationr.step() if ind % (100//batch_size) == 0: print(f&#39;lastloss&#39;, loss. item（），math.log（loss.item（））） print（output_view，views）loss.append（loss.item（））ind = ind + 1  非日志：  对于tqdm中的批次（train_dataloader，total=1296//batch_size）：img_resized = batch[&#39;normalized_image&#39;].reshape(-1,3,720, 1296)views = (torch.tensor( batch[&#39;views&#39;]).to(device).to(torch.float32)).reshape(-1,1)output_view = model(img_resized.cuda())loss = loss_func(output_view,views)optimizer.zero_grad( ) loss.backward() # torch.nn.utils.clip_grad.clip_grad_norm_(model.parameters(), 1.0) optimizationr.step() if ind % (100//batch_size) == 0: print(f&#39;lastloss&#39;, loss.item(),math.log(loss.item())) print(output_view,views)loss.append(loss.item()) ind = ind + 1  &amp; #x200b;   由   提交 /u/ExaminationNo8522   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aw9csl/d_when_doing_regression_training_with_large/</guid>
      <pubDate>Wed, 21 Feb 2024 10:59:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与 RL 相关的硕士论文论文或想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aw8c8j/d_papers_or_ideas_for_masters_thesis_related_to_rl/</link>
      <description><![CDATA[嘿，我即将完成数学硕士学位，需要为我的论文选择一个主题。我的研究重点是应用统计学和机器学习。最近，我开始接触强化学习，并且一直在考虑就此撰写硕士论文。我不太害怕编码，但我绝对想做理论研究。 由于我对 RL 的投入不是太深，所以我确实可以在我的论文中使用一些想法或论文建议。如果有任何建议，我将非常感激！ （最好是 RL）谢谢！   由   提交/u/d-eighties  /u/d-eighties  reddit.com/r/MachineLearning/comments/1aw8c8j/d_papers_or_ideas_for_masters_thesis_lated_to_rl/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aw8c8j/d_papers_or_ideas_for_masters_thesis_related_to_rl/</guid>
      <pubDate>Wed, 21 Feb 2024 09:51:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何预测未来产品持有量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aw820l/p_how_to_predict_future_product_holdings/</link>
      <description><![CDATA[我有一个零售银行客户及其随时间持有的产品的数据集。有哪些适当的技术可以预测每个客户在未来 1-3 年内将持有哪些产品？我曾考虑过使用马尔可夫链，但不确定使用机器学习技术是否更合适。   由   提交/u/legendarylegend26   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aw820l/p_how_to_predict_future_product_holdings/</guid>
      <pubDate>Wed, 21 Feb 2024 09:31:59 GMT</pubDate>
    </item>
    <item>
      <title>如何创建用于修改服装的图像处理图像 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aw65zn/how_to_create_an_image_processing_image_for_dress/</link>
      <description><![CDATA[模型的目的是获取人和衣服的图片，然后结果输出将是穿着衣服的人。然后它还有一个很酷的功能，就是人可以改变走路的姿势等等。 改变标题，图像处理模型   由   提交/u/No-Space-7  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aw65zn/how_to_create_an_image_processing_image_for_dress/</guid>
      <pubDate>Wed, 21 Feb 2024 07:25:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您建议亲自参加人工智能会议吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avzt7o/d_do_you_recommend_attending_ai_conferences_in/</link>
      <description><![CDATA[我的论文在 COLING 2024 中被接受。它是混合开放的，因此我也可以虚拟参加。 您对此有何看法亲自参加的好处？  我正在认真考虑它，因为这可能是我第一次也是最后一次在人工智能会议上发表文章。 您的经历如何？   由   提交 /u/Empty_Fee8023   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avzt7o/d_do_you_recommend_attending_ai_conferences_in/</guid>
      <pubDate>Wed, 21 Feb 2024 01:55:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] Apple 更快的法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avz6ns/r_faster_llm_from_apple/</link>
      <description><![CDATA[为了大胆创新，Apple 决定与世界分享他们的突破性技术   由   提交/u/Ok-Teaching6610   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avz6ns/r_faster_llm_from_apple/</guid>
      <pubDate>Wed, 21 Feb 2024 01:26:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] Apple 的更快的法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avyqf1/r_faster_llms_from_apple/</link>
      <description><![CDATA[Apple 开源推测流技术可加速设备上的 LLM    ;由   提交/u/Ok-Teaching6610   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avyqf1/r_faster_llms_from_apple/</guid>
      <pubDate>Wed, 21 Feb 2024 01:05:42 GMT</pubDate>
    </item>
    <item>
      <title>[N] 流浪小猪饼干来到Zuse研究所，研究用于原子和分子建模的图形处理器。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avverg/n_biscuit_the_wandering_piglet_arrived_at_the/</link>
      <description><![CDATA[   大家好！来认识一下饼干，一只玩具小猪，它通过从一个旅行者到另一个旅行者的传递而环游世界。 Biscuit 最近与来自日内瓦的科学家一起访问了柏林 Zuse 研究所，参加了“原子和分子建模未来高性能计算的前景和挑战”会议。在那里，Biscuit通过聆听所有讲座并检查超级计算机中使用的GPU，认真地探讨了这个话题。 接下来，他将前往日内瓦，与CERN的科学家一起参观大型强子对撞机。&lt; /p&gt; ——------------------------ 一些背景故事：不久前，我来了有了创造玩具的想法。它的名字叫饼干，是我和妻子制作的一只迷人的小猪。 Biscuit的使命是环游世界，从一只手传递到另一只手。通过这个项目，我的目标是连接全球各地的人们，展示我们星球的美丽，分享各地的精彩故事和事实。 为此，我们创建了一个 Instagram 页面 https://www.instagram.com/biscuitroams/ 此处将发布 Biscuit 的所有更新和冒险。另外，我会在Imgur和Reddit上整理并发布完整的故事。 Biscuit还有一个小背包，参与者可以通过它交换来自不同国家的小纪念品和磁铁！ Biscuit有他的旅程才刚刚开始，目前我们只有很少的志愿者来陪伴他。如果你有喜欢旅行的朋友，也许他们会想带上Biscuit一起去！ 是的，而且Biscuit很小，站立时全高只有18厘米。他可以轻松放入公文包中，而且他的小公文包上有一个登山扣，因此可以牢固地固定他。   由   提交 /u/Dangerous-Annual-511   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avverg/n_biscuit_the_wandering_piglet_arrived_at_the/</guid>
      <pubDate>Tue, 20 Feb 2024 22:46:59 GMT</pubDate>
    </item>
    <item>
      <title>有哪些开源库可以帮助我在构建 LLM 应用程序时轻松地在 LLM 之间切换？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avryf1/any_open_source_libraries_that_can_help_me_easily/</link>
      <description><![CDATA[我一直在构建使用 LLM 和 RAG 的开源工具，但是，有大量的 LLM 模型和框架可供选择，包括OpenAI、Huggingface、AzureOpenAI 等。为每个类编写新类和扩展可能很困难。我很好奇是否有更简单的方法，例如将最大数量的 LLM api 统一在一个工具/框架下，这样我就不必为所有内容编写一个新类？  在这些情况下你通常会做什么？   由   提交 /u/metalvendetta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avryf1/any_open_source_libraries_that_can_help_me_easily/</guid>
      <pubDate>Tue, 20 Feb 2024 20:30:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kaggle 数据集与实际表格数据 - 痛苦的认识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avq8uz/d_kaggle_datasets_vs_actual_tabular_data_bitter/</link>
      <description><![CDATA[经过多年在 Kaggle 或其他平台上的表格数据集的工作和实践，我终于开始使用来自大学医院的表格数据，就像一滩污垢花了一整天的时间才找到正确的标题并链接所有这些表间公式和过滤器。另一方面，我花了最多。 Kaggle 数据集上的 EDA 需要 30 分钟。  我被告知了其中的差异，但意识到 DS 必须处理什么混乱。总是低估它，跳过与之相关的研讨会，还随意取笑它（我通常处理图像和视频）。   由   提交 /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avq8uz/d_kaggle_datasets_vs_actual_tabular_data_bitter/</guid>
      <pubDate>Tue, 20 Feb 2024 19:23:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>