<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 07 Feb 2024 06:17:24 GMT</lastBuildDate>
    <item>
      <title>[D] 为什么搜索/推荐神经检索表现出严重的离线/在线度量差异以及如何弥合差距？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aku4am/d_why_searchrecommendation_neural_retrieval/</link>
      <description><![CDATA[作为在搜索/推荐 ML 业务方面拥有多年经验的人，我对基于 ML 的检索系统（例如近似值）的观察深感困惑最近邻搜索、离线评估指标通常与在线指标严重不一致。几家主要科技公司的情况似乎都是如此。在离线评估中，人们可以非常努力地模拟在线完成的检索过程，通过对齐索引项的大小、使用未来的数据并对所有索引项执行用户/查询的详尽搜索。当计算历史点击项目的命中率@k时，处理可以显着优于控制几个百分点。然而，当我们在线运行 AB 测试时，有时治疗甚至会比对照表现得更差。 我理解，基于历史用户反馈的离线评估可能会受到反事实不对称或确认偏差的影响，因为不同的检索来自基线的算法可能会导致以前未见过的商品被点击/购买，而评估数据集中记录的正面示例无法捕获这些商品。但这可能比治疗更有助于控制？同时还有其他检索源，其中一些是基于经典倒排索引的，其他可以是基于嵌入或基于模型的。我可以预见的一个问题是，来自这些其他检索源的优秀候选者会被正在测试的检索源蚕食。这是否表明人们应该以某种方式折扣从这些替代来源中检索到的前 k 个项目？我不清楚如何以原则性的方式做到这一点，因为评估集中的正面例子必须来自某些检索源。根据定义，排除它们将使控制方获得满分。  关于如何消除这种反事实效应还有哪些其他建议？对于这种差异还有哪些其他可能的解释？我还应该提到，在某些地方，我尝试使用基于人类手动探索和挖掘正例的独立评估集，在极端情况下，我看到了 50% 的离线提升（在数千个数据集上），而在线指标仍然保持中立。当然，这不太可扩展。然而，升力的重要性似乎是毋庸置疑的，尽管其幅度可能值得怀疑。从第一原理来看，这种提升也是合理的，因为治疗使用了更大、更深的模型，并且其他条件保持不变。有人可能会说，一些注释者的意见可能与用户满意度不太相符，但前面描述的用户反馈评估也证实了这种提升。   由   提交/u/Crazy_Suspect_9512   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aku4am/d_why_searchrecommendation_neural_retrieval/</guid>
      <pubDate>Wed, 07 Feb 2024 04:10:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 TED 生成文本 - 可训练的指数衰减</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akr9g6/r_text_generation_with_ted_trainable_exponential/</link>
      <description><![CDATA[链接：https://blpj.github.io/ ted/   与 Transformer 进行的全面比较或 RNN 中的顺序依赖相比，可训练指数衰减 (TED) 引入了一种不直接依赖于的独特方法在过去的代币上。 TED 的核心机制仅单独考虑每个代币一次，以确定其衰减率 λ (lambda)。然后，过去的代币会经历指数衰减，并将它们的影响相加并添加到当前的代币中以创建丰富的表示。 TED 在训练期间受益于并行硬件架构，因为对过去令牌的唯一依赖是通过加法，可以在单层上下文中随时以任何顺序执行。训练模型后，我们可以观察到过去标记的影响会随着时间的推移而自然衰减，从而使某些标记变得无关紧要，从而可以从上下文中删除。此外，围绕指数衰减的完善数学框架可以精确预测特定代币将“死亡”的时刻。这一观察结果在推理过程中开辟了许多优化机会。最简单的策略涉及在任何给定时间维护 K 个最相关的标记，以确保恒定的内存需求。或者，动态方法可能涉及丢弃相关性分数低于特定阈值的标记。相关性分数是通过将标记的向量幅度 ‖v‖ 乘以它在时间“t”时的当前衰减因子来计算的。由于指数衰减的本质，保存在上下文中的过去标记的顺序并不重要。这消除了对位置编码机制的需要，这在 Transformers 中被视为有问题。 TED 的架构遵循 Transformer 的架构，不同之处在于注意力模块被指数衰减模块取代。 TED 可以在 PyTorch 中实现，无需特殊的 CUDA 内核。代码位于：https://github.com/blpj/ted    ​   由   提交/u/_blpj_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akr9g6/r_text_generation_with_ted_trainable_exponential/</guid>
      <pubDate>Wed, 07 Feb 2024 01:49:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您会将当前的开发到生产流程放在哪里？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akr6gk/d_where_would_you_place_your_current_dev_to_prod/</link>
      <description><![CDATA[      嘿大家， 我正在与构建的人讨论这个问题ML Pipelines，关于以下之间的紧张关系： ​ 摆脱 ML Pipelines 的压力 这实际上是快速行动和构建良好系统之间的决定，因为我们都希望增加价值，您可以将其建模为以下曲线： ​ 让管道流出的有效前沿曲线。 所以我想知道人们将自己置于这条曲线的哪个位置？因此进行民意调查 - 我认为看看每个人如何评估自己会很有趣。 因为我只能进行一项民意调查，所以我认为了解快速发货之间的差异对于讨论很有用并交付专为您的环境而构建的代码。  我会使用这些结果来与我的团队和与我们一起工作的人展示/讨论（我在要求人们沿着曲线向右移动时遇到过阻力）。如果您想推动最佳实践，这也可能有助于引发讨论？ 查看投票   由   提交 /u/theferalmonkey   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akr6gk/d_where_would_you_place_your_current_dev_to_prod/</guid>
      <pubDate>Wed, 07 Feb 2024 01:45:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 具有多个任务的微调多模态变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akqsvq/d_finetuning_multimodal_transformers_with/</link>
      <description><![CDATA[你好， 我正在寻找 HuggingFaces 的转换过程。在其中一课中，他们教授如何微调 ViLT VQA 模型，并解释如何加载 BLIP 2 模型以进行零样本 VQA。 我看到 BLIP 2 除了 VQA 之外还执行许多其他任务，例如图像字幕。如果我针对特定数据集的图像字幕微调 BLIP2，此微调是否适用于此数据集上的 VQA 问题？ 如果是这样，它适用于可以执行多项任务的任何转换吗？即：任何其他可以图像标题和 VQA 的模型都可以将学习从一项任务转移到另一项任务吗？ 我发现很难找到该问题的答案   由   提交 /u/Impressive-Thing-553   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akqsvq/d_finetuning_multimodal_transformers_with/</guid>
      <pubDate>Wed, 07 Feb 2024 01:27:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] Mamba 在 Torch 中的实现（未经预训练）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akppx9/p_mamba_implementation_in_torch_without_pretrained/</link>
      <description><![CDATA[我正在做一项使用序列数据的工作，但不特定于语言。 在类似变压器的网络中，我没有使用源和目标的嵌入层，而是使用线性层；另外，我将源和目标都发送到转发过程。 在类似 LSTM 的网络中，我什至不需要这一步，我只需要 torch 标准的 lstm 单元；在这种情况下，前向传递只需要源代码。 我希望了解 Mamba 如何处理这项工作，所以我想要一个具有 Mamba 机制的模型，但我有我在前向传递和初始化方面都遇到了如何用它定义模型的困难。 有人有关于如何使用 Mamba 的代码示例吗？就像 pytorch 的 LSTM 和 Transformer 函数一样？ &gt;   由   提交/u/Hopeful_Tie_5488   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akppx9/p_mamba_implementation_in_torch_without_pretrained/</guid>
      <pubDate>Wed, 07 Feb 2024 00:36:45 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 如何证明核在数学上是有效的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akoo9c/discussion_how_do_you_show_that_a_kernel_is_valid/</link>
      <description><![CDATA[      ​ 内核函数 你到底会如何展示它？我是否只需要说第一个例子： 内核是有效的，因为它的函数满足 k(x, y) = k(y, x)。内核是对称且线性的 或者是否有更数学的方式来展示这一点？除了对称性、线性和正定性规则之外，我还没有真正找到任何例子或任何东西。 任何帮助或提示都值得赞赏:)   由   提交 /u/Advanced_Pay121   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akoo9c/discussion_how_do_you_show_that_a_kernel_is_valid/</guid>
      <pubDate>Tue, 06 Feb 2024 23:50:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] Evrptw 的蚁群优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akmzap/p_ant_colony_optimization_for_evrptw/</link>
      <description><![CDATA[该存储库包含蚁群优化 (ACO) 算法的 Python 实现，用于优化电动汽车的路线，考虑特定的时间窗口和充电需求。该技术是智慧城市框架内的一种机器学习方法，可提高城市出行效率和可持续交通管理，从而通过智能技术的使用改善城市生活。  如果您发现该项目有趣，请考虑为存储库加注星标并为其开发做出贡献，以支持和增强这种机器学习技术在智慧城市应用中的实施。  https://github.com/F-a-b-r-i-z-i-o/Ant_Colony_Optimization_for_Evrptw   由   提交/u/Stunning_Ad_1539   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akmzap/p_ant_colony_optimization_for_evrptw/</guid>
      <pubDate>Tue, 06 Feb 2024 22:39:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] L40S vs A100 vs A40 用于 AI/ML 研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akj2n7/d_l40s_vs_a100_vs_a40_for_aiml_research/</link>
      <description><![CDATA[我是一名研究生，我的导师正在考虑为我们的研究购买新的 GPU 机器。我们的研究是标准的计算机视觉研究，但现在我们正在利用最新的法学硕士浪潮进入视觉语言。我想知道在固定预算内我们应该买什么。   由   提交/u/nakali100100   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akj2n7/d_l40s_vs_a100_vs_a40_for_aiml_research/</guid>
      <pubDate>Tue, 06 Feb 2024 20:03:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这些法学硕士如何使用符号、方程等科学数据进行训练？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aki0hr/d_how_do_these_llms_train_on_scientific_data_with/</link>
      <description><![CDATA[如标题所示：方程是否转换为 LaTeX（或其他此类）格式？但是你可以在 LaTeX 中以多种不同的方式表达同一个方程。怎么解决的？   由   提交 /u/ispeakdatruf   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aki0hr/d_how_do_these_llms_train_on_scientific_data_with/</guid>
      <pubDate>Tue, 06 Feb 2024 19:20:53 GMT</pubDate>
    </item>
    <item>
      <title>[P] 开放法学硕士的宪法人工智能配方</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akdv4i/p_constitutional_ai_recipe_with_open_llms/</link>
      <description><![CDATA[      大家好，我是来自 Hugging Face 👋 研究团队的 Lewis。 我们最近一直在为 LLM 修改各种对齐算法，并且很好奇 Anthropic 的 Constitutional AI 是否适用于 Mistral 7B 等开放模型。 tl;dr 它效果很好，我们在这里总结了我们的实验和配方！ 像其他作品一样在“自我完善”方面，宪法人工智能的工作原理是要求模型生成对一组提示的响应，然后检查这些响应与一组“宪法原则”的一致性程度。定义您希望模型具有的值类型。然后，您让模型修改其原始响应，这会生成偏好对（original_response、revised_response）的合成数据集，您可以将其用于 DPO / PPO 等。该过程的概述如下所示：  ​ 宪法人工智能配方 我们发现他们的论文最有趣的是定义自己的一套宪法原则的可能性。例如，我认为很多人都认为“作为人工智能语言模型我不能......” ChatGPT 中的拒绝非常烦人，因此我们调整了 Anthropic 构成以模仿 xAI 的 Grok 助手的风格，该助手具有相当好的护栏，但通常会以一些幽默来回应:) 比较两种拒绝风格（Anthropic vs Grok），您可以在这里尝试演示：https://huggingface.co/spaces/HuggingFaceH4/constitutional -ai-demo   由   提交/u/lewtun  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akdv4i/p_constitutional_ai_recipe_with_open_llms/</guid>
      <pubDate>Tue, 06 Feb 2024 16:31:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士因在持续微调过程中发生灾难性遗忘而闻名</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akd287/d_llms_are_known_for_catastrophic_forgetting/</link>
      <description><![CDATA[但是 Chatgpt-4 是如何记住它学到的所有事实数据的呢？  换句话说，法学硕士如何记住他们在初始训练批次中学到的数据（在预训练和持续微调期间）？    由   提交/u/kekkimo  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akd287/d_llms_are_known_for_catastrophic_forgetting/</guid>
      <pubDate>Tue, 06 Feb 2024 15:57:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审稿人滥用 ChatGPT 撰写审稿</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akd0ko/d_reviewers_abusing_chatgpt_to_write_review/</link>
      <description><![CDATA[我不介意人们使用 LLM、ChatGPT 来修复他们的原始文本，但我确实得到了一位审稿人和元审稿人显然没有使用它阅读论文...感觉就像他们复制粘贴摘要，然后向 ChatGPT 提问。更糟糕的是，一位审稿人甚至敢要求我将他们不相关的工作添加为引文。 在 GPT 检测器上检查他们的评论时，检测到的人工智能检测率约为 98%... 结果是他们的评论都不相关，例如询问我论文中存在的信息、告诉我极其模糊的评论或解释摘要。就好像他们连整篇论文都没有贴，只贴了摘要。 我知道我的文章并不完美，但感觉就像是白白被拒绝了，而且我什至不能有一个真实的人类反馈。 你们中的一些人遇到过这种情况吗？   由   提交/u/AbleBrilliant13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akd0ko/d_reviewers_abusing_chatgpt_to_write_review/</guid>
      <pubDate>Tue, 06 Feb 2024 15:55:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 还有人因为 arxiv-vanity 的衰落而感到难过吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ak5u1q/d_anyone_else_sad_that_arxivvanity_is_down/</link>
      <description><![CDATA[我经常使用它在手机上阅读论文。当宣布 Arxiv 将支持 HTML 时，我非常高兴。然而，Arxiv 决定通过只为新论文提供 HTML 来处理这个问题，而不是旧论文，甚至新论文不知何故我也没有发现承诺的 HTML 版本可用。† 但是，不幸的是我发现 arxiv-vanity 现在在他们的首页上发布了一条消息：  arXiv 现在有了 HTML 论文，所以 arXiv Vanity 不需要再存在了。  这对我来说似乎有点为时过早。我想他们已经厌倦了主办它，这是可以理解的。但与此同时，如果没有尴尬的 PDF 缩放功能，我就无法再在手机上阅读论文了。在 Arxiv 开始更广泛地提供 HTML 之前，有人有更好的选择吗？ † 有人像我一样困惑吗？我查看了最近发表在 https://arxiv.org/list/cs.LG/recent 上的论文，并且我没有看到任何 HTML 链接，请单击“其他格式”只能看到 PDF 和源代码.. 编辑： 好吧，我不知道“5”技巧，请参阅评论。   由   提交 /u/radarsat1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ak5u1q/d_anyone_else_sad_that_arxivvanity_is_down/</guid>
      <pubDate>Tue, 06 Feb 2024 09:24:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 ML 出版中玩游戏或做科学研究。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajz2s3/d_play_the_game_or_do_the_science_in_ml_publishing/</link>
      <description><![CDATA[我看到很多大科技公司的愿景论文模板。方法总是一样的，对现有的工作做一个小的改变，称之为新颖，疯狂地运行超参数搜索，在 20 个数据集上显示结果。 （请注意，这些模型很可能无法零样本工作，它们显示的所有数字都针对该数据集进行了微调）。这些纸总是能进来的！  我觉得这为审稿人设定了非常不切实际的期望，并期望所有论文得到相同水平的实验结果。因此，学术实验室很难成为其中一些子领域的一部分。  只有我一个人有这样的感觉吗？ 当然也有例外，比如 DINO 或 SAM，它们真的很棒，我真的很欣赏。   由   提交/u/mildlyphd  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajz2s3/d_play_the_game_or_do_the_science_in_ml_publishing/</guid>
      <pubDate>Tue, 06 Feb 2024 02:33:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>