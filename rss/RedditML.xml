<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 29 Jan 2024 15:12:37 GMT</lastBuildDate>
    <item>
      <title>[R] 帮助查找同时包含眼底和 OCT 视网膜图像的数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adxib5/r_help_in_finding_a_dataset_that_has_both_fundus/</link>
      <description><![CDATA[我一直在寻找可以在我的研究项目中使用的数据集，但遗憾的是我找不到任何数据集。我找到了这个https://zenodo.org/records/7105232 但它只有2种疾病，那么谁能帮我找到一个多模态视网膜数据集，其中包含 4 或 6 种疾病，我在搜索了这么长时间后感觉自己在原地打转？  &amp;# 32；由   提交 /u/Atomicamism   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adxib5/r_help_in_finding_a_dataset_that_has_both_fundus/</guid>
      <pubDate>Mon, 29 Jan 2024 15:09:38 GMT</pubDate>
    </item>
    <item>
      <title>如何将用 Python 训练的模型导入到 C++ 中？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adx6f6/how_do_i_take_a_model_ive_trained_in_python_and/</link>
      <description><![CDATA[我是一名机器学习实习生，我目前正在使用 Python 构建机器学习模型，因为这就是我知道如何构建它们的方式，但是最终我必须能够在 C++ 应用程序中运行这些模型，并且软件开发团队不想调用 Python 代码。我目前正在使用 Pickle 将模型保存为 .sav 文件。有一个名为 pickling tools 的工具包，但我不知道我是否需要使用它。我是否需要只研究 C++ 机器学习库？    由   提交 /u/GlassWalkerKinfolk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adx6f6/how_do_i_take_a_model_ive_trained_in_python_and/</guid>
      <pubDate>Mon, 29 Jan 2024 14:55:09 GMT</pubDate>
    </item>
    <item>
      <title>寻求最佳的 Reranker 服务：bge 和 Cohere 的经验？ [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adwa3y/seeking_the_best_reranker_services_experiences/</link>
      <description><![CDATA[社区您好， 我正在探索重新排序工具，并对您的体验感到好奇，尤其是 bge 模型（大型/基础）和 Cohere Rerank 等服务。我的用例是一个非常通用的 RAG，我想查看可用重新排名器（MTEB 除外）的一些指标，尤其是在现实世界领域 纯粹来自服务 POV，Cohere 是镇上唯一的游戏吗，或者还有其他值得考虑的选择吗？有人提供 bge-reranker-base/large 作为服务吗？我对自托管不感兴趣。 任何见解或建议都会很棒   由   提交/u/brooding_pixel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adwa3y/seeking_the_best_reranker_services_experiences/</guid>
      <pubDate>Mon, 29 Jan 2024 14:14:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何为 RAG 划分块</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adtuzr/d_how_to_divide_a_chunk_for_rag/</link>
      <description><![CDATA[大家好， 我需要一些建议，假设您正在构建一个 RAG。您希望上下文块的长度为 512 个令牌。如何在不失去语义联系的情况下划分 1000 多个段落。 有关更多信息，它是一个问答机器人，那个巨大的段落是对一个常见问题的回答。   由   提交 /u/Lathanderrr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adtuzr/d_how_to_divide_a_chunk_for_rag/</guid>
      <pubDate>Mon, 29 Jan 2024 12:10:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 了解组织数据网格之旅中数据产品的明确界限</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adtnho/d_understanding_the_clear_bounds_for_data/</link>
      <description><![CDATA[揭开数据产品的模糊界限！ 在本文中，作者讨论了：  精益价值树 数据产品交互图 数据产品原子性的数据 SLA  阅读全文：https://moderndata101.substack.com/p/understand-the-clear-bounds-对于   由   提交/u/growth_man  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adtnho/d_understanding_the_clear_bounds_for_data/</guid>
      <pubDate>Mon, 29 Jan 2024 11:59:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于交互式研讨会的云托管 GPU 场解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adtk60/p_solutions_for_cloudhosted_gpu_farms_for_an/</link>
      <description><![CDATA[我将举办一个关于 LLM 微调和部署的互动研讨会。作为研讨会的一部分，我希望与会者尝试一些运行脚本和笔记本的实践实验。我无法提供物理硬件本身，因此我计划从云端租用 GPU。我想知道是否有任何现成的解决方案可用于此类用例。理想情况下，我可以部署一定数量的实例，甚至可以根据需求进行扩展，并授予单个用户访问隔离的 Docker 容器的权限。也许这个要求太多了，但也许有一些东西可以让我大部分时间到达那里。备份将在主要云提供商上自己构建该系统，这需要一些时间。谢谢！   由   提交 /u/zach_the_kraken   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adtk60/p_solutions_for_cloudhosted_gpu_farms_for_an/</guid>
      <pubDate>Mon, 29 Jan 2024 11:53:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] Hugging Face - 如何绘制训练和验证准确性与 Epoch 图？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adt8a5/d_hugging_face_how_to_plot_training_and/</link>
      <description><![CDATA[      由于标题是自我描述性的，我需要绘制获得的训练和验证准确性在训练我的拥抱脸模型期间。之后，我想绘制测试预测的混淆矩阵。我该如何做到这些？ 这是我的训练参数： args = TrainingArguments( output_dir=f&quot; ;my_training”， evaluation_strategy=“epoch”， save_strategy=“epoch”，  learning_rate=5e-5， per_device_train_batch_size=4， gradient_accumulation_steps= 4、 per_device_eval_batch_size=4， num_train_epochs=5， &lt;代码&gt;warmup_ratio=0.1， logging_steps=10， load_best_model_at_end=True， metric_for_best_model=“准确度”， report_to=&#39;tensorboard&#39;， push_to_hub=True , ) ​ 而且，这是我的教练： &lt; p&gt;defcompute_metrics(eval_pred): 预测 = np.argmax(eval_pred.predictions, axis=1)  准确度 = precision_score(y_pred=predictions, y_true=eval_pred.label_ids) return {&quot;accuracy&quot;: 准确度} ​ trainer = Trainer( 模型， args ， train_dataset=train_dataset， eval_dataset=eval_dataset， tokenizer=处理器， compute_metrics=compute_metrics， data_collat​​or=collat​​e_fn ) ​ 最后，我分别开始训练和预测： train_results = trainer.train() trainer.save_model() trainer.log_metrics(“train”, train_results.metrics ) trainer.save_metrics(&quot;train&quot;, train_results.metrics) trainer.save_state() ​ eval_results = trainer.evaluate(eval_dataset) trainer.log_metrics(&quot; eval&quot;, eval_results) trainer.save_metrics(&quot;eval&quot;, eval_results) ​ &lt; p&gt;使用当前配置，我只能获得评估/准确度与步骤图。我需要一个如下所示的图，该图取自 TensorBoard： https://preview.redd.it/pzhk797r7dfc1.jpg?width=478&amp;format=pjpg&amp;auto=webp&amp;s=955a22ef695a8945d2faf0dd8155329 535834a8b &amp; #x200b;   由   提交 /u/talhak   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adt8a5/d_hugging_face_how_to_plot_training_and/</guid>
      <pubDate>Mon, 29 Jan 2024 11:32:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进行直接偏好优化 (DPO) 的正确方法是什么？为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adnq4u/d_whats_the_proper_way_of_doing_direct_preference/</link>
      <description><![CDATA[      出于某种原因，我无法全神贯注于 DPO 的数据分发问题。论文中写道： https ://preview.redd.it/6c9z61o4bbfc1.png?width=2164&amp;format=png&amp;auto=webp&amp;s=c6b5ed46937da04e5912023e2f46ae7821a9a446 我的问题是：为什么它如此重要偏好数据分布与参考模型输出分布一致吗？我的理解是，在训练过程中，sft的参数会更新，使得选择的响应（y_w）生成的概率更高，而拒绝的响应（y_l）生成的概率更低，并且参考模型就在那里以防止 sft 模型偏离原始参数太远。但我不明白错误的参考分布如何阻碍这个过程。有人可以帮助我吗？ ​ p.s.我已经看到很多现有的实现忽略了这个分布转移问题并获得了良好的结果，所以我认为这并不重要？   由   提交/u/aaaprocrastinating   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adnq4u/d_whats_the_proper_way_of_doing_direct_preference/</guid>
      <pubDate>Mon, 29 Jan 2024 05:30:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不懂基础的LLM专家？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</link>
      <description><![CDATA[我最近遇到了很多人，他们知道 LLM 领域中不同技术的所有奇特缩写词，诚然我也是新手但越来越明显的是，他们甚至不知道 DL 的基础知识，比如背景是什么或其他经典概念。 这是否会成为现状，因为 LLM 领域更倾向于配置而不是做事从零开始？ 还有，这些人真的可以被认为是法学硕士还是表面上的专家？    由   提交/u/Plus_Tough_7497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</guid>
      <pubDate>Mon, 29 Jan 2024 04:13:30 GMT</pubDate>
    </item>
    <item>
      <title>什么是最好的 OCR（光学字符识别）。需要 PDNod 和 Google 的开源替代方案 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adlvco/what_is_the_best_ocr_optical_character/</link>
      <description><![CDATA[PDnod 翻译非常准确且良好。我想要一个能够处理准确的句子小屏幕截图的工具。 我测试了一些像 Tesseract 的工具，但在视频中尝试中文文本时它们无法正确处理。有谁知道 Tesseract 的更好的开源替代品吗？   由   提交 /u/RichCyph   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adlvco/what_is_the_best_ocr_optical_character/</guid>
      <pubDate>Mon, 29 Jan 2024 03:50:46 GMT</pubDate>
    </item>
    <item>
      <title>搜索给定特定方法的 ML 论文 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adk739/searching_for_ml_papers_given_a_specific_approach/</link>
      <description><![CDATA[大家好。我经常遇到这个问题，我会想到一种解决机器学习问题的特定方法，并尝试寻找类似的论文。然而，我不知道这些论文到底怎么称呼它，或者他们只是描述相同的方法略有不同。无论如何，我的搜索结果通常没有多大帮助。 在这种情况下您会做什么？我刚刚开始从事机器学习研究，所以我还没有读过那么多论文。是否有一种工具可以通过理解所采用方法的描述来对研究论文数据库进行上下文搜索？   由   提交/u/genesis_2602   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adk739/searching_for_ml_papers_given_a_specific_approach/</guid>
      <pubDate>Mon, 29 Jan 2024 02:26:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么假设使用 NN 连接隐式学习和存储信息比可学习向量更优化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adipfr/d_why_is_it_assumed_that_using_nn_connections_to/</link>
      <description><![CDATA[大多数学习网络都遵循类似的模式：获取一些输入数据，嵌入到一些输入向量中，然后在给出一些输入之前堆叠这些向量之间的连接模式所需的输出。对于一个简单的 NLP 示例，您从句子的一些嵌入开始，让这些单词标记相互关注，使用 FF 层让向量的元素连接到自身，然后重复（过度简化的转换器），然后让它预测下一个令牌。通常给出的直觉是，我们让网络通过反向传播更新权重来学习输入数据之间的复杂关系。从转换输入数据的角度来看，这是有道理的，但很明显大型模型正在记忆信息。例如，chatgpt 可以轻松重复著名事件的日期。如果我想将这些数据存储在网络之外，我只需显式编码一个向量来表示它，而不是尝试将其建模为单词或其他潜在对象之间的一系列复杂连接，这看起来会更加复杂并且效率较低。同样，我可以让输入关注一组可学习的标记，而不仅仅是在网络中的输入数据之间创建连接，该模型可以使用这些标记来编码世界信息。你可能想要与输入/输入注意力交错，但似乎可学习的标记将为网络提供一种更有效，或者至少更明确的方法来存储数据。我见过的最接近的是一些网络用于修改输入令牌的可学习位置嵌入，或者来自 https://arxiv.org 的 VIT 寄存器/abs/2309.16588 ，但它们对学习输入向量的使用仍然非常有限。我们不使用可学习向量是否有数学原因，或者论文表明它们不如更多的连接？    由   提交 /u/Revolutionary-Fig660    reddit.com/r/MachineLearning/comments/1adipfr/d_why_is_it_assumed_that_using_nn_connections_to/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adipfr/d_why_is_it_assumed_that_using_nn_connections_to/</guid>
      <pubDate>Mon, 29 Jan 2024 01:12:42 GMT</pubDate>
    </item>
    <item>
      <title>您在工作中是否拥有产品专业的法学硕士？如果是这样，那又是为了什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adbbnv/do_you_have_llms_in_prod_at_work_if_so_what_for_d/</link>
      <description><![CDATA[请随意在评论中扩展诸如任务（RAG、聊天机器人、工具、seq2seq 等）模型大小、部署策略、缺点等信息，未来计划等 就我而言：任务：RAG 模型：zephyr 7B 部署：vLLM 未来计划：内部文档预训练 + 聊天微调 &lt;!-- SC_ON - -&gt;  由   提交/u/masc98  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adbbnv/do_you_have_llms_in_prod_at_work_if_so_what_for_d/</guid>
      <pubDate>Sun, 28 Jan 2024 19:51:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 中的 OUTPUT 嵌入是什么？它从何而来？ （不是输入嵌入）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad1o11/d_what_are_the_output_embeddings_in_transformer/</link>
      <description><![CDATA[       由   提交 /u/ShlomiRex   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad1o11/d_what_are_the_output_embeddings_in_transformer/</guid>
      <pubDate>Sun, 28 Jan 2024 12:31:51 GMT</pubDate>
    </item>
    </channel>
</rss>