<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 18 Feb 2024 18:14:48 GMT</lastBuildDate>
    <item>
      <title>[P] Sentiment ML项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atzyq5/p_sentiment_ml_project/</link>
      <description><![CDATA[      我只是想分享我在 python Django 中集成的机器学习项目。 https://sentimentpredictor.pythonanywhere.com 源代码： https://github.com /nordszamora/sentiment https://preview.redd.it/nmf7dr01tdjc1.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;s=3ab0b4805c68adc7f3741e7d0ab4285fb7000038   由   提交 /u/ThePawners   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atzyq5/p_sentiment_ml_project/</guid>
      <pubDate>Sun, 18 Feb 2024 17:48:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 本科生 ML 博士想成为：大实验室还是小实验室？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atzdsz/d_undergrad_ml_phd_wannabe_big_lab_or_small_lab/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atzdsz/d_undergrad_ml_phd_wannabe_big_lab_or_small_lab/</guid>
      <pubDate>Sun, 18 Feb 2024 17:25:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 人类课程效应随着神经网络中的情境学习而出现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atyati/r_human_curriculum_effects_emerge_with_incontext/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.08674 摘要：  人类学习对规则式结构和课程很敏感用于训练的示例。在受简洁规则约束的任务中，当相关示例在试验中被阻止时，学习会更加稳健，但在没有此类规则的情况下，交错会更有效。迄今为止，还没有神经模型能够同时捕获这些看似矛盾的效应。在这里，我们表明，这种相同的权衡自发地出现在“上下文学习”中。 （ICL）既适用于元学习训练的神经网络，也适用于大型语言模型（LLM）。 ICL 是“在上下文中”学习新任务的能力。 - 没有重量变化 - 通过激活动力学中实现的内循环算法。预训练的 LLM 和元学习 Transformer 的实验表明，ICL 在涉及类规则结构的任务中表现出人类所表现出的阻塞优势，相反，并发权重学习再现了人类在缺乏此类结构的任务中观察到的交错优势。    由   提交 /u/New-Feedback-1881   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atyati/r_human_curriculum_effects_emerge_with_incontext/</guid>
      <pubDate>Sun, 18 Feb 2024 16:41:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 第一作者排序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aty0et/d_first_author_ordering/</link>
      <description><![CDATA[嗨，我是深度学习领域的初级研究员。我和我的同事正在寻求向 ECCV24 提交一篇论文。我和她已经一起工作了大约一年。我们即将提交的项目主要是我的想法，我构建了代码库。她帮助我计划实验并写论文。我们俩都是共同第一作者。我们计划在提交给会议之前将其提交到 arxiv 上。她给我下了最后通牒，如果我在 arxiv 上首先选择我的名字，那么我就不能在会议论文中把我的名字放在第一位，反之亦然。由于这是我的第一篇论文，而且我做了很多工作，所以我觉得我应该在两篇论文提交中被列为第一名。我的问题是： 1.从长远来看，这对我的职业生涯有多大影响？ 2. 如果我确实调换顺序，我应该成为 ECCV 还是 Arxiv 的第一作者？我想尽量减少冲突，同时为我的职业生涯做出最好的决定，而不是太小气。作为背景，她已经有一篇以她为第一作者的论文。请帮帮我！提前致谢！   由   提交/u/darkmatter6698   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aty0et/d_first_author_ordering/</guid>
      <pubDate>Sun, 18 Feb 2024 16:29:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 进入未知：自学习大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atxx77/r_into_the_unknown_selflearning_large_language/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.09147 代码：https://github.com/teddy-f-47/self-learning-llm-public 摘要：  我们解决自学LLM的主要问题：学什么的问题。我们提出了一个自学法学硕士框架，使法学硕士能够通过自我评估自己的幻觉来独立学习以前未知的知识。利用幻觉评分，我们引入了未知点（PiUs）的新概念，以及用于自动 PiU 识别的一种外在方法和三种内在方法。它有助于创建一个自学循环，专门关注“未知点”中的知识差距，从而降低幻觉分数。我们还制定了衡量法学硕士自学能力的评估指标。我们的实验表明，经过微调或对齐的 7B-Mistral 模型具有相当好的自学习能力。我们的自学理念使法学硕士更新更加高效，并为知识交流开辟了新的视角。它还可能增加公众对人工智能的信任。    由   提交 /u/New-Feedback-1881   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atxx77/r_into_the_unknown_selflearning_large_language/</guid>
      <pubDate>Sun, 18 Feb 2024 16:25:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何重振机器学习研究的动力？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atu7in/d_how_can_i_reinvigorate_the_motivation_for_doing/</link>
      <description><![CDATA[我怀念 ML 不那么流行的时代。我五年前完成了自然语言处理硕士学位，目前正在考虑攻读博士学位。但我厌倦了每个人都攻读法学硕士学位并跳上炒作的火车。我喜欢研究，我应该如何进行？   由   提交 /u/ArtisticView8321   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atu7in/d_how_can_i_reinvigorate_the_motivation_for_doing/</guid>
      <pubDate>Sun, 18 Feb 2024 13:34:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] ARB：大型语言模型的高级推理基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1attnyg/r_arb_advanced_reasoning_benchmark_for_large/</link>
      <description><![CDATA[ 由   提交 /u/EducationalCicada   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1attnyg/r_arb_advanced_reasoning_benchmark_for_large/</guid>
      <pubDate>Sun, 18 Feb 2024 13:05:44 GMT</pubDate>
    </item>
    <item>
      <title>[N] Google 博客文章“什么是长上下文窗口？”指出其结果用于 Gemini 1.5 Pro 的长上下文项目需要“一系列深度学习创新”，但没有具体说明这些创新是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1attgz7/n_google_blog_post_what_is_a_long_context_window/</link>
      <description><![CDATA[来自什么是一个很长的上下文窗口吗？:  “我们最初的计划是在上下文中实现 128,000 个代币，我认为设定一个雄心勃勃的标准会很好，所以我建议 100 万个令牌，”谷歌 DeepMind 研究科学家尼古拉·萨维诺夫 (Nikolay Savinov) 说道，他是长上下文项目的研究负责人之一。 “现在我们的研究甚至超过了这个数字 10 倍。”  为了实现这种飞跃，团队必须进行一系列深度学习创新。谷歌 DeepMind 工程师 Denis Teplyashin 解释道：“一个突破引发了另一个突破，每一个突破都开辟了新的可能性。” “然后，当它们全部堆叠在一起时，我们非常惊讶地发现它们可以做什么，从 128,000 个代币跃升至 512,000 个代币，再到 100 万个代币，而就在最近，我们的内部研究中增加了 1000 万个代币。”  相关帖子：[D] Gemini 1M/10M 令牌上下文窗口如何？&lt; /a&gt;   由   提交 /u/Wiskkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1attgz7/n_google_blog_post_what_is_a_long_context_window/</guid>
      <pubDate>Sun, 18 Feb 2024 12:55:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] YOLOv8：图像增强效果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atsnxz/d_yolov8_image_augmentation_effectiveness/</link>
      <description><![CDATA[一般来说，在训练 yolov8 模型进行对象分类时，哪些图像增强最为有效？ （按从最好到最差的顺序） 图像级别增强 旋转剪切灰度色调亮度曝光噪声剪切马赛克 边界框级别增强 &lt; p&gt;翻转 90° 旋转作物旋转剪切亮度曝光模糊噪声 是否有一个 python 包，给定训练图像和标签的 yolov8 数据集，将以可重现的方式执行所有增强？ &gt; 一个最小的可重现示例将不胜感激。   由   提交/u/Tim7459  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atsnxz/d_yolov8_image_augmentation_effectiveness/</guid>
      <pubDate>Sun, 18 Feb 2024 12:06:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何查明你的研究以前是否没有做过？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atrenf/d_how_to_find_out_if_your_research_hasnt_been/</link>
      <description><![CDATA[我最近有了一个关于 ML 研究项目的想法。我花了几天时间实施和完善它并进行了测试。事实证明它运作得非常好！ 事实是，这个想法本身非常简单且非常直接，所以我担心它已经完成了。然而，通过谷歌搜索与我的想法相关的关键词，我发现没有论文可以做我所做的事情。尽管如此，我觉得谷歌搜索关键字可能不是一个有效的策略。因此我想问：如何确保你的想法真正新颖？   由   提交/u/Raskolnikov98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atrenf/d_how_to_find_out_if_your_research_hasnt_been/</guid>
      <pubDate>Sun, 18 Feb 2024 10:46:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 过去一年左右，RL 发生了什么？有什么大的进展吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atpztx/d_whats_been_going_on_in_rl_this_past_year_or_so/</link>
      <description><![CDATA[自从法学硕士开始掀起新闻风暴以来，我就没有听说过任何关于 RL 的新闻。   由   提交/u/Intelligent_Rough_21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atpztx/d_whats_been_going_on_in_rl_this_past_year_or_so/</guid>
      <pubDate>Sun, 18 Feb 2024 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您保持最新状态的方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atmjz9/d_what_is_your_approach_for_staying_uptodate/</link>
      <description><![CDATA[新概念太多，时间太少。在我看来，虽然人们可以通过阅读获得基本的理解，但你确实需要修补和构建一些东西才能深入理解一项技术。作为一个有其他事情发生的成年人，这每年都变得越来越难，而与此同时，新工具和技术的速度似乎呈指数级增长。您要跟上的策略是什么？    由   提交 /u/HorseEgg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atmjz9/d_what_is_your_approach_for_staying_uptodate/</guid>
      <pubDate>Sun, 18 Feb 2024 05:28:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 应用机器学习论文中的公然数据泄露和谎言</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1atf9tz/d_blatant_data_leakage_and_lies_in_an_applied_ml/</link>
      <description><![CDATA[最近我看到一篇在医疗保健领域应用的机器学习论文。论文发表在该领域真正顶级期刊的较小子期刊上。从我看来，这篇论文在方法论上确实存在明显的根本缺陷，完全使任何提议的贡献无效。 本质上，他们从智能手表的患者那里收集心率、睡眠等数据，并安装梯度增强机来预测血液中化学物质的水平。他们在晚上的记录时间收集样本，并使用 10 分钟粒度的时间序列数据集来进行每日预测。 问题是，他们使用每日睡眠时间和睡眠子类别（睡眠）阶段）的特点。在这种情况下，睡眠数据会在一天中重复，然后与同一天整个数据持续时间的一个唯一标签相匹配。然后，他们进行 10 倍的 CV，并全面报告 0.90+ 的绩效评估指标。 我以前见过数据泄露的欺诈性研究，但我从未见过如此刻意、如此明目张胆的半成品研究。 - 之前受人尊敬的期刊。作者在论文中回顾了这些细节，并做出了笼统的陈述，比如他们如何确保在 10 倍 CV 期间的训练集和测试集中不存在相同的数据行，等等。哈哈。您有 7 个特征，每天都采用唯一值，然后每个特征重复约 100 次，与 1 个唯一结果相匹配，并且您是说您确保在简历中分隔行索引？ 我是我对他们的结果表示怀疑，因为我在类似的领域工作，但由于缺少一些细节而无法确定。值得庆幸的是，由于一些法规或规则，他们必须公开数据和代码，我确认这正是正在发生的事情。 我不会在这里分享这项研究，但我应该这样做吗？联系期刊让他们撤回论文？有趣的是，该杂志有“AI”一词。以他们的名义，所以这不像是一本有非机器学习审稿人的期刊。这怎么能通过同行评审呢？有人见过如此欺诈的研究吗？我对这些科学出版物的现状感到困惑和震惊。    由   提交/u/enthusiastic31  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1atf9tz/d_blatant_data_leakage_and_lies_in_an_applied_ml/</guid>
      <pubDate>Sat, 17 Feb 2024 23:13:55 GMT</pubDate>
    </item>
    <item>
      <title>V-JEPA：Yann LeCun 先进机器智能愿景的下一步 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1at7fib/vjepa_the_next_step_toward_yann_lecuns_vision_of/</link>
      <description><![CDATA[      博客：https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model- video-joint-embedding-predictive-architecture/ 论文：https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning-visual-representations-from-video/ ​ 摘要： ​ 本文探讨了特征预测作为视频无监督学习的独立目标，并引入了 V-JEPA，这是一组仅使用特征预测目标训练的视觉模型集合，不使用预训练的图像编码器、文本、负例、重建或其他监督源。这些模型使用从公共数据集中收集的 200 万个视频进行训练，并针对下游图像和视频任务进行评估。我们的结果表明，通过预测视频特征进行学习可以产生多功能的视觉表示，在基于运动和外观的任务上表现良好，而无需调整模型的参数；例如，使用冷冻的骨干。我们最大的模型，仅在视频上训练的 ViT-H/16，在 Kinetics-400 上获得 81.9%，在 Something-Something-v2 上获得 72.2%，在 ImageNet1K 上获得 77.9%。 ​&lt; /p&gt; ​ https://preview.redd.it/uvo0dpwvl6jc1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=3f308732b80a72be3d5ad8ef9542462cf4611b64 V-JEPA 训练视觉编码器通过预测学习的潜在空间中的屏蔽时空区域。   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1at7fib/vjepa_the_next_step_toward_yann_lecuns_vision_of/</guid>
      <pubDate>Sat, 17 Feb 2024 17:36:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>