<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 27 Sep 2024 06:24:43 GMT</lastBuildDate>
    <item>
      <title>[D] 我是不是被煮熟了</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqgkr7/d_am_i_cooked/</link>
      <description><![CDATA[我在一所 t20 学院学习计算机科学，正在学习数据科学 + 人工智能（双专业），辅修数理经济学。我想成为一名数据科学家/工程师，或者从事量化或机器学习领域的工作。我不太喜欢计算机科学，因为我更喜欢数学 + 统计 + 经济学，而不是编程。数据科学和人工智能会不会看起来像“假”专业，或者会不会让我在感兴趣的领域处于不利地位？    提交人    /u/Complex-Ad-7801   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqgkr7/d_am_i_cooked/</guid>
      <pubDate>Fri, 27 Sep 2024 05:28:06 GMT</pubDate>
    </item>
    <item>
      <title>寻找一些脑细胞来帮助我选择一个领域[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqfmt6/seeking_few_brain_cells_to_help_me_choose_a_field/</link>
      <description><![CDATA[我目前正在权衡云安全、DevOps 和网络安全领域的 AI/ML 之间的选择，专注于无需长期学术承诺的高薪职位。我还有 4 年才大学毕业，正在寻找一条相对不容易被人工智能取代的职业道路。我知道没有哪个领域可以完全免受人工智能的影响，未来可能会带来无法预料的变化，从而影响工作保障。积极主动并不断发展技能以保持领先于自动化至关重要。您对这些领域的未来有何看法？您认为哪条道路在未来几年最有增长、稳定和持久力的潜力，为什么？ 我很想听听有这些领域经验的人的见解！ 提前谢谢 :)    提交人    /u/Abhi_-_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqfmt6/seeking_few_brain_cells_to_help_me_choose_a_field/</guid>
      <pubDate>Fri, 27 Sep 2024 04:26:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 各位 ML 从业者，当您遇到 ML 问题时，您会向谁求助？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqb1t1/d_fellow_ml_practitioners_who_do_you_go_to_when/</link>
      <description><![CDATA[顺便说一句，不要在“简单问题主题”中发帖，因为我相信即使是具有正式 ML 知识的人也可以从中受益。 我很好奇，如果您遇到以前没有做过的事情，您如何获得新想法并验证它们。我的情况类似，虽然我的工作团队中有其他领域的专家，但没有高级 MLE。 不一定是个人，我也很想知道您提到的任何来源。    提交人    /u/Moltres23   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqb1t1/d_fellow_ml_practitioners_who_do_you_go_to_when/</guid>
      <pubDate>Fri, 27 Sep 2024 00:15:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何创建用于分割的数据集。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fq4wz2/p_how_to_create_a_dataset_for_segmentation/</link>
      <description><![CDATA[大家好，我一直在尝试使用 CNN 架构进行分类，但不幸的是，这不是我实现目标所需要的。我需要使用来自国家农业图像计划的 512x512 像素图块来确定岩石在景观中的位置，我对我的数据集应该是什么样子感到困惑。此外，我在互联网上找到的所有示例都是针对边界框的，但我想要像素分类。我之前被告知，要使分类模型表现良好，您至少需要五个类别（例如，岩石、水、树木、草地等）。这对于分割也适用吗，还是我应该专注于仅为岩石创建标签/蒙版？ 让我知道您的想法或您将如何创建此数据集。 非常感谢！    提交人    /u/Muted_Preparation_47   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fq4wz2/p_how_to_create_a_dataset_for_segmentation/</guid>
      <pubDate>Thu, 26 Sep 2024 19:38:17 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 自定义系统基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fq0s5c/discussion_custom_system_benchmarking/</link>
      <description><![CDATA[希望运行我自己的测试来对我的构建的 GPU、CPU 和内存功能进行压力测试和基准测试。无论是训练还是推理任务？有什么建议吗？    提交人    /u/arashsh0   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fq0s5c/discussion_custom_system_benchmarking/</guid>
      <pubDate>Thu, 26 Sep 2024 16:45:10 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 有没有什么有前景的研究可以利用 RL 从人类反馈中改进计算机视觉任务？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpzj0m/discussion_are_there_any_promising_work_on_using/</link>
      <description><![CDATA[目前，对于诸如对象检测或实例分割之类的计算机视觉任务，改进生产模型的最佳方法是使用硬示例挖掘进行某种形式的迭代模型训练/主动学习，并将其放回注释和训练中，并经常这样做。  是否有任何研究探索基于从人类反馈中学习到的某些策略快速对齐模型输出的方法，类似于语言模型中的 RLHF？  此外，是否有任何有助于减少人工注释工作量的值得探索的研究领域？    提交人    /u/Appropriate_Bear_894   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpzj0m/discussion_are_there_any_promising_work_on_using/</guid>
      <pubDate>Thu, 26 Sep 2024 15:52:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪种神经网络架构最适合具有几千个数据点的时间序列分析？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpxja7/d_what_neural_network_architecture_is_best_for/</link>
      <description><![CDATA[我知道你在想什么，使用 ARIMA 等经典方法。是的，你是对的，但我已经为我的公司这样做了。我目前是合作社，我得到了一份全职工作。在过渡期间，我两周内没什么事可做。我可以使用 PySpark 和 Databricks，但在新职位上我不会使用，所以我想把这段时间当作一次学习经历，最终它会对我的简历有所帮助。我并不期望性能会比我的 ARIMA 模型更好 数据具有 2021 年的每日粒度。我有特征，但不是很多。有三种架构我一直在考虑。我了解 RNN、LSTM 和时间 CNN。就（主要是）学习与性能相结合而言，您认为其中哪一个最适合我的任务？一般来说，对于丰富的数据，您认为哪种架构通常表现最佳？    提交人    /u/BostonConnor11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpxja7/d_what_neural_network_architecture_is_best_for/</guid>
      <pubDate>Thu, 26 Sep 2024 14:28:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您需要什么语音解码架构来模拟 openai 的高级语音模式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpwbjk/d_what_speech_decoding_architecture_do_you_need/</link>
      <description><![CDATA[Llama Omni 是我见过的唯一一篇接近语音模式的论文，但所使用的语音解码架构似乎不允许“用法语口音说 1 2 3”之类的事情。在论文中，他们似乎冻结了编码器和 llm，并使用来自其他 TTS 模型的文本和模型输出来训练解码器。这是否意味着您必须拥有一个包含诸如“[法语口音]1 2 3”，.waveform”之类的对的数据集，或者这里有不同的方法可以采用？    提交人    /u/natural_language_guy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpwbjk/d_what_speech_decoding_architecture_do_you_need/</guid>
      <pubDate>Thu, 26 Sep 2024 13:34:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能评估和输出质量的社区</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpvhxq/d_a_community_for_ai_evaluation_and_output_quality/</link>
      <description><![CDATA[如果您专注于 LLM 中的输出质量和评估，我创建了 r/AIQuality — 一个致力于为那些致力于构建可靠、无幻觉系统的人服务的社区。 就我个人而言，我在评估我的 RAG 管道时一直面临挑战。我应该使用 DSPy 来构建它吗？哪种检索器技术效果最好？我应该切换到不同的生成器模型吗？最重要的是，我如何真正知道我的模型是在改进还是在退步？这些问题使评估变得困难，但至关重要。 随着 RAG 和 LLM 的快速发展，一直没有空间深入研究这些评估难题 — 直到现在。这就是我创建这个社区的原因：分享见解，探索前沿研究，并应对评估 LLM/RAG 系统的真正挑战。 如果您正在处理类似的问题并希望改进您​​的评估流程，请加入我们。 https://www.reddit.com/r/AIQuality/    提交人    /u/Desperate-Homework-2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpvhxq/d_a_community_for_ai_evaluation_and_output_quality/</guid>
      <pubDate>Thu, 26 Sep 2024 12:55:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama-3.2 与 llama-3.1 在医疗领域的表现：Llama-3.1 70B 优于 Llama-3.2 90B</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fps53b/d_llama32_vs_llama31_in_medical_domain_llama31/</link>
      <description><![CDATA[      大型 LLama 模型在医疗领域的表现（90B、70B、11B） 探索 LLama 3.2 Large 模型与 Llama 3.1 模型在医疗领域的表现。 （未经微调） 🥇 Meta-Llama-3.1-70B-Instruct：总冠军，平均成绩 84%  MMLU 大学生物学成绩优异（95.14%） MMLU 专业医学成绩优异（91.91%）  🥈 Meta-Llama-3.2-90B-Vision（Instruct 和 Base）：以 83.95% 的平均成绩并列第二  Instruct 和 Base 版本表现一致 MMLU 大学生物学（93.06%）和 MMLU 专业医学（91.18%）成绩最佳  🥉 Meta-Llama-3-70B-Instruct：第三名，平均成绩 82.24%   MMLU 医学遗传学（93%） MMLU 大学生物学表现稳定（90.28%）  医学领域的小型 LLama 和 Phi 模型（3B、1B） 我还分析了较小的模型，并将它们与 phi-3 进行了比较，以探索小模型在医学领域的表现。 （未经微调） 🥇 Phi-3-4k：表现最佳，平均分数为 68.93％  MMLU 大学生物学成绩优异（84.72％） MMLU 临床知识成绩优异（75.85％）  🥈 Meta-Llama-3.2-3B-Instruct：平均成绩为 64.15％ ，排名第二  MMLU 大学生物学成绩最佳（70.83％） PubMedQA 成绩稳定（70.6％）  🥉 Meta-Llama-3.2-3B：平均成绩为 60.36％ ，排名第三  MMLU 大学生物学成绩最强（63.89％）  PubMedQA (72.8%)  其他观察结果： 评估结果  视觉模型中的表现相同： Meta-Llama-3.2-90B-Vision Instruct 和 Base 版本在所有指标和所有 9 个数据集上都表现出相同的表现（平均 83.95%），精确到小数点后一位。 同样，Meta-Llama-3.2-11B-Vision Instruct 和 Base 版本也表现出相同的分数（平均 72.8％）在所有类别中。（评估两次）  不寻常的一致性： Instruct 和 Base 版本之间的这种完美对齐有点不典型，因为 Instruct 和基础变体通常会显示出轻微的性能差异.. 我猜这是由于视觉指令调整造成的？视觉模型的能力是否可以减少对针对医疗任务的特定指令调整的依赖？ 结果以 JSON 格式提供，可在Github 上获取   将很快在此处为医疗领域评估更多模型 - 源帖子    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fps53b/d_llama32_vs_llama31_in_medical_domain_llama31/</guid>
      <pubDate>Thu, 26 Sep 2024 09:29:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你会关注哪些信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpo0z8/d_which_feeds_do_you_look_at/</link>
      <description><![CDATA[虽然 arxiv 和 open review 是新论文的两个最佳来源，但我发现某些 feed 也非常有趣。对我来说，这包括 GitHub、Less Wrong、Hugging Face、Twitter 和 Reddit。我遗漏了什么吗？还有更多吗？博客列表？我希望有这些东西的整合。    提交人    /u/Studyr3ddit   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpo0z8/d_which_feeds_do_you_look_at/</guid>
      <pubDate>Thu, 26 Sep 2024 04:27:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] ViT 受益于双曲空间变换</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fplhvi/r_vits_benefit_from_hyperbolic_space_transform/</link>
      <description><![CDATA[https://arxiv.org/abs/2409.16897    由   提交  /u/jacobfa   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fplhvi/r_vits_benefit_from_hyperbolic_space_transform/</guid>
      <pubDate>Thu, 26 Sep 2024 02:03:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama 3.2详细分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpckbb/d_llama_32_detailed_analysis/</link>
      <description><![CDATA[大家好！Meta 发布了一组新的 Llama 3.2 模型，分别用于文本（1B、3B）和视觉（11B、90B）。我对这些模型进行了深入研究，希望能够有所启发：  新的 1B 和 3B 文本专用 LLM 9 万亿个 token 新的 11B 和 90B 视觉多模态模型 128K 上下文长度 1B 和 3B 使用了一些来自 8B 和 70B 的提炼 VLM 60 亿个图片、文本对 CLIP MLP GeLU + 交叉注意  长分析：1. 视觉编码器中使用带有 GeLU 激活的 CLIP 类型 MLP。类似于 GPT2 的 MLP。与 Llama 3 的 MLP 不同，因为 SwiGLU 不用于视觉 MLP。  用于视觉编码器的正常 layernorm - 不是 RMS Layernorm。此外，一些“门控”参数用于乘以隐藏状态。 在注意力和 MLP 之后对隐藏状态进行门控乘法器 - tanh 用于将向量缩放移动到从 -1 到 1 的数字。 对于小型 1B 和 3B LLM 以及多模态 VLM 11B 和 90B，评估看起来相当不错。1B 49.3 MMLU 和 3B 63.4。 VLM MMMU 50.7 和 90B 60.3  感谢您的阅读，如果您有任何疑问，请告诉我！    由   提交  /u/danielhanchen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpckbb/d_llama_32_detailed_analysis/</guid>
      <pubDate>Wed, 25 Sep 2024 19:09:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 22 Sep 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>