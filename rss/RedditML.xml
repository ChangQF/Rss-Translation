<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 25 Nov 2024 03:31:01 GMT</lastBuildDate>
    <item>
      <title>[D] 作为计算机科学硕士生/研究员，在选择实验室领域时是否应该非常谨慎？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gz6mj1/d_as_a_cs_masters_studentresearcher_should_one_be/</link>
      <description><![CDATA[我（非常幸运）得到了一个机会，可以在一所 R1 学校的一个很棒的实验室工作，教授的 h 指数超过 40，记录很好，但主要在较低级别的会议上发表文章，尽管也做过一些 AAAI。它将 AI 应用于与我的经验相符的领域，我们有望发表文章，这很完美。但是，我更热衷于探索更多基础 AI 研究（除了我上的课程外，我在这方面的经验很少）。 在 CS、ML 领域，似乎大多数人只优先考虑 NIPS/ICLR/ICML，尤其是因为我有兴趣攻读博士学位。我有点进退维谷，不知道应该抓住机会还是继续寻找更匹配的实验室（尽管其他教授可能不想招收更多学生）。 我的直觉告诉我，我应该忽略会议排名，这样做，因为它们有一些思想链、知识表示、认知系统组件。他们希望我投入多个学期的时间，当然，一旦我投入，我就会坚持到底。我的困境是，我越来越多地转向人工智能中更实际的应用，这是一个非常具体的领域，我担心自己将来无法转型。  我知道这听起来很傻，但如果你能忽略这一点，能否请你站在一个崭露头角的学者的角度，给我一些建议和想法，谢谢！    提交人    /u/giuuilfobfyvihksmk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gz6mj1/d_as_a_cs_masters_studentresearcher_should_one_be/</guid>
      <pubDate>Mon, 25 Nov 2024 00:56:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] peft 是否训练新初始化的权重？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gz2n3x/d_does_peft_train_newly_initialized_weights/</link>
      <description><![CDATA[当使用 peft 微调预训练模型（例如 DistilBert）时，您需要指定 target_modules。对于 DistilBert，通常以注意力权重为目标。示例： lora_config = LoraConfig( r=8, # 等级数 lora_alpha=32, # Alpha（缩放因子） lora_dropout=0.05, # Lora 的 Dropout 概率 target_modules=[&quot;q_lin&quot;, &quot;k_lin&quot;,&quot;v_lin&quot;], # 应用 LoRA 的层，通常仅适用于多头注意层 bias=&#39;none&#39;, task_type=TaskType.SEQ_CLS # 序列到分类任务 )  我的问题是，在下游任务上微调预训练模型时，您初始化一个未经预训练且具有随机权重的新层（如分类层），peft 是否也会冻结该层或对其进行优化？ 答案应该是肯定的，但我在任何地方都找不到明确说明。    由   提交  /u/Qdr-91   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gz2n3x/d_does_peft_train_newly_initialized_weights/</guid>
      <pubDate>Sun, 24 Nov 2024 21:53:46 GMT</pubDate>
    </item>
    <item>
      <title>RTX 4090 与 4080 super [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyzxb1/rtx_4090_vs_4080_super_d/</link>
      <description><![CDATA[正在考虑为研究构建一个 ML 和分子动力学工作站。我正在寻找价格在 4000 美元左右的 GPU。我一直倾向于 2 个 4090（我知道 5090 将于 1 月推出，完全是另一回事！）但理论上我可以以大约相同的价格运行 4x 4080 supers，而且从技术上讲，数字是最重要的，但前提是您可以高效地使用它们。我知道 pytorch 可以相当好地分布在 GPU 上，但并非所有东西都可以。我也知道更多的 vRAM 总是更好，因为 40 系列没有 NVlink，所以不能池化内存。我也简要地看了 RTX 卡（安培和 ada），但我的理解是它们真的只对专业驱动程序有价值，仅此而已。任何想法都将不胜感激！     由    /u/Mdgoff7 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyzxb1/rtx_4090_vs_4080_super_d/</guid>
      <pubDate>Sun, 24 Nov 2024 19:58:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] NAACL 研讨会什么时候公布？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyye7a/d_when_will_the_naacl_workshops_get_announced/</link>
      <description><![CDATA[NAACL 网站提到 11 月 25 日开始第二次征集研讨会论文，但该网站似乎没有提到哪些研讨会将举行。我不知道我现在知道是不是太愚蠢了，请帮帮我。    提交人    /u/Aromatic_Web749   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyye7a/d_when_will_the_naacl_workshops_get_announced/</guid>
      <pubDate>Sun, 24 Nov 2024 18:54:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪里可以找到适合所有消费级 GPU 的良好基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyvari/d_where_find_a_good_benchmark_for_all_consumer_gpu/</link>
      <description><![CDATA[大家好，我想知道哪种 gpu 最适合机器学习，包括 openVino（仅适用于英特尔）、新推出的 rochm 以及显然是女王 nvidia，存在一些完全专注于 ML 的基准测试，其中包含各种类型的库    提交人    /u/FewVEVOkuruta   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyvari/d_where_find_a_good_benchmark_for_all_consumer_gpu/</guid>
      <pubDate>Sun, 24 Nov 2024 16:45:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过问题变体测试 LLM 类比推理的脆弱性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gys936/r_testing_the_brittleness_of_llm_analogical/</link>
      <description><![CDATA[研究人员开发了一个系统框架，使用复杂程度不断增加的字母字符串类比来测试法学硕士 (LLM) 中的类比推理。他们创建了多个测试集，用于探测类比思维的不同方面，从基本转换为复杂模式识别。 关键技术要点： - 评估了 4 个主要 LLM （包括 GPT-4 和 Claude）的性能 - 创建了具有可控难度进程的测试集 - 实现了用于衡量类比理解的新指标 - 测试了零样本和小样本性能 - 引入对抗性示例以测试鲁棒性 主要结果： - 模型在基本字母序列转换中的准确率达到 90% 以上 - 在多步转换中，性能下降 30-40% - 在新型字母系统上，准确率降至 50% 以下 - 小样本提示平均可将结果提高 15-20% - 模型对小模式扰动表现出脆弱性 我认为这项工作揭示了当前 LLM 抽象推理能力的重要局限性。虽然它们可以很好地处理表面级模式，但在更深层次的类比思维方面却举步维艰。这表明我们需要新的架构或训练方法来实现更强大的推理能力。 这里介绍的评估框架可以帮助以更系统的方式对未来模型的推理能力进行基准测试。结果还强调了当前模型需要改进的具体领域，特别是在处理新模式和多步骤转换方面。 TLDR：使用字母字符串类比测试 LLM 中的类比推理的新框架在基本模式下表现出色，但在复杂转换和新字母表中表现出明显的局限性。结果表明，当前模型可能是模式匹配，而不是真正的推理。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gys936/r_testing_the_brittleness_of_llm_analogical/</guid>
      <pubDate>Sun, 24 Nov 2024 14:32:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 模型中出现的认知途径。解决有关限制的根本缺陷。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gys51e/d_emergent_cognitive_pathways_in_transformer/</link>
      <description><![CDATA[TLDR： 随着模型的扩展和基于更好的数据的训练，推理和创造力等认知功能应运而生。当我们考虑具有不同寻常的认知或感官差异的人类（或对世界的接触有限的人）时，常见的反对意见就不攻自破了，他们仍然能够推理、形成新颖的想法并建立世界的内部模型。 OOD 神话和函数组合的优雅 LeCun 和 Chollet 等批评者认为，LLM 无法推断出其训练数据之外的内容，他们经常引用凸包测量。这种观点忽略了一个基本的数学现实：新颖的分布自然地通过函数组合出现。当非线性函数 f 和 g 组合为 f(g(x)) 时，它们会产生超出原始训练分布的输出。这不是限制，而是神经网络如何概括知识的一个特征。 考虑一个简单的例子：对{诗歌，猫诗，莎士比亚}进行训练允许模型生成“莎士比亚风格的猫诗”——一种混合分布的新型计算函数。将其扩大，f 和 g 可以代表贝叶斯统计和地缘政治分析，产生任何领域单独都无法产生的见解。推广这一原则可以揭示推理、创造力、心智理论和其他高级认知功能等能力。 训练数据悖论 我们可以看到 LLM 的训练数据，但看不到我们自己的经验限制，这导致人们误以为人类的知识是无限的。想想 1600 年的某个人：他们的“训练数据”包括他们当地的环境和几十本书。然而，他们可以推理看不见的现象并创造新的想法。关键不在于训练集的大小，而在于信息如何转换和重组。 持久记忆并非必不可少 一个常见的反对意见是，LLM 缺乏持久记忆，因此无法进行因果推理、推理或创造力。然而，患有前行性遗忘症的人无法形成新的记忆，他们经常仅使用工作记忆就展示所有这些能力。同样，LLM 使用上下文窗口作为工作记忆模拟，无需长期记忆即可进行推理和创造性综合。 缺乏世界模型 机械解释子领域的存在本身就强烈暗示，变压器和神经网络确实创建了世界模型。有一种观点认为，文字不是一种正确的感觉机制，因此纯文本的 LLM 不可能形成世界的 3D 模型。 我们以一位本体感觉有限、能阅读盲文的盲聋人为例。声称因为他们了解世界的主要窗口只是盲文中的文本，所以他们无法推理、发挥创造力或构建世界的内部模型，这种说法是荒谬的。我们知道这不是真的。 就像盲人通过学习转换从盲文构建有效的世界模型一样，LLM 通过组合学习模式来构建功能模型。批评者所称的“幻觉”通常是对这些组合空间的有效探索 - 以新颖的方式组合变换而出现的低概率区域。 真正的限制 虽然这些类比很有说服力，但真正的反思推理可能需要递归反馈循环或时间编码，而 LLM 缺乏这些，尽管注意力机制和上下文窗口提供了部分替代方案。虽然 LLM 目前缺乏真正的递归推理或类似人类的规划，但这些反映了未来设计可能解决的架构约束。 最后的想法 前馈网络及其高维空间的非线性使得真正的新颖输出成为可能，可通过嵌入分析和分布测试进行验证。像 Golden Gate Claude 这样的实验，研究人员放大了特定的神经通路以探索新的认知空间，证明了这些原则在实际中的作用。我们不会说飞机不能飞，因为它们不是鸟——同样，法学硕士可以推理和创造，尽管他们使用的认知架构与人类不同。我们可能可以近似和识别其他新兴的认知特征，如心智理论、元认知、反思，以及一些人类可能不具备的特征。    提交人    /u/ipassthebutteromg   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gys51e/d_emergent_cognitive_pathways_in_transformer/</guid>
      <pubDate>Sun, 24 Nov 2024 14:27:12 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我创建了一个库，用于构建使用树搜索来解决问题的代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyreq1/p_i_made_a_library_for_building_agents_that_use/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyreq1/p_i_made_a_library_for_building_agents_that_use/</guid>
      <pubDate>Sun, 24 Nov 2024 13:51:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 离散扩散模型的当前发展水平如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyp1br/d_what_is_the_current_stateoftheart_for_discrete/</link>
      <description><![CDATA[大家好， 我目前正在为一个新的研究项目研究离散扩散模型。在这个项目中，我将离散扩散应用到一个尚未应用的领域。然而，我对扩散本身还很陌生，我对关于这个主题的论文数量感到不知所措。在我目前的实施中，我专注于一篇较旧的论文，因为它们很好地描述了他们的方法，我想先测试我的想法，看看它是否有一些优点，根据初步结果，它确实有优点。 目前，我正在考虑用这个领域的最新补充来更新我的方法，但正如我之前所说，我对数量有点不知所措。所以我的问题是，最近有哪些研究离散扩散的好论文，它们要么解释了基本概念，比如调查论文，要么介绍了不仅适用于特定领域的新先进方法，比如 NLP 或视觉？ 提前谢谢你的帮助。    提交人    /u/Derpirium   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyp1br/d_what_is_the_current_stateoftheart_for_discrete/</guid>
      <pubDate>Sun, 24 Nov 2024 11:35:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 24 Nov 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要的建议：图像到 3D 扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy9dqd/d_recommendations_needed_imageto3d_diffusion/</link>
      <description><![CDATA[大家好，我正在为一个项目评估不同的开源图像到 3D 扩散模型，并且可以使用一些现实世界的见解。我一直在研究论文，但很想听听真正实施过这些论文的人的意见。 我的主要要求：  质量是重中之重 - 寻找干净、准确的重建 需要基于网格的输出（而不是点云或神经场），并且不是天文数字 推理时间并不重要 - 很乐意每代等待一分钟  我看过 Zero123、Wonder3D 和其他一些，但很好奇在实践中什么对人们有效。特别感兴趣：  哪些模型实际上可以在生产中维护 网格生成质量是否存在任何缺陷 您看到的实际推理时间 通常需要多少后处理  非常希望听到您的经验，特别是在实际项目中部署过这些经验的人的经验。谢谢！    提交人    /u/ESCNOptimist   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy9dqd/d_recommendations_needed_imageto3d_diffusion/</guid>
      <pubDate>Sat, 23 Nov 2024 20:44:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是我在 Medium 上的第一篇博客，内容是：现代二进制 Hopfield 网络如何只是伪装的汉明距离自动完成器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy4qpv/d_this_is_my_first_blog_on_medium_and_they_are/</link>
      <description><![CDATA[    /u/StoneSteel_1   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy4qpv/d_this_is_my_first_blog_on_medium_and_they_are/</guid>
      <pubDate>Sat, 23 Nov 2024 17:22:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过负特征值解锁线性 RNN 中的状态跟踪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gy0hbh/r_unlocking_statetracking_in_linear_rnns_through/</link>
      <description><![CDATA[摘要：线性循环神经网络 (LRNN)（例如 Mamba、RWKV、GLA、mLSTM 和 DeltaNet）已成为大型语言建模中 Transformers 的有效替代品，可提供序列长度的线性缩放并提高训练效率。然而，LRNN 难以执行状态跟踪，这可能会损害代码评估或跟踪国际象棋游戏等任务的性能。偶数奇偶校验是最简单的状态跟踪任务，非线性 RNN（例如 LSTM）可以有效处理，但当前的 LRNN 无法解决。最近，Sarrof 等人 (2024) 证明，像 Mamba 这样的 LRNN 无法解决奇偶校验的原因是将其对角状态转换矩阵的值范围限制为 [0,1]，而加入负值可以解决这个问题。我们将此结果扩展到非对角 LRNN，它们最近在 DeltaNet 等模型中表现出了良好的前景。我们证明，状态转移矩阵只有正特征值的有限精度 LRNN 无法解决奇偶校验问题，而模 3 计数则需要复特征值。值得注意的是，我们还证明，当 LRNN 的状态转移矩阵是恒等向量减去向量外积矩阵的乘积时，它们可以学习任何常规语言，每个矩阵的特征值都在 [-1,1] 范围内。我们的实证结果证实，将 Mamba 和 DeltaNet 等模型的特征值范围扩展为包括负值，不仅可以使它们解决奇偶校验问题，而且可以持续提高它们在状态跟踪任务上的性能。此外，使用扩展的特征值范围进行语言建模的预训练 LRNN 实现了可比的性能和稳定性，同时在代码和数学数据上显示出良好的前景。我们的工作增强了现代 LRNN 的表现力，扩大了它们的适用性，同时又不改变训练或推理的成本。 https://arxiv.org/abs/2411.12537    提交人    /u/iltruma   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gy0hbh/r_unlocking_statetracking_in_linear_rnns_through/</guid>
      <pubDate>Sat, 23 Nov 2024 14:11:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 已接受的 NeurIPS 2024 论文声称作为第一项工作解决了一个新问题，但忽略了 5 项先前的工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gxooqv/d_accepted_neurips_2024_paper_claimed_to_be/</link>
      <description><![CDATA[在 NeurIPS 2024 上，我发现了一篇被接受的论文，其主要贡献是“现有的针对 X 的算法忽略了 Y。我们调整了针对 X 的算法 Z 来考虑 Y”。 在 OpenReview 上，我看到审稿人特别称赞了这项工作的新颖性，并认为 Y 是 X 领域被忽视的一个重要方面。 现在有趣的是：合著者和我在 2023 年在 Springer 的机器学习杂志上发表了一篇论文，也提出了一种针对 X 的算法来解释 Y。我们也不是第一个研究 X 和 Y 问题设置的人：我们论文的相关工作部分讨论了 4 篇论文，它们都提出了针对 X 的算法来解释 Y。其中一篇甚至来自 NeurIPS（2017），最早的一篇可以追溯到 2012 年（一篇 AAAI 论文）。 这篇 2024 年的作者NeurIPS 论文完全忽略了所有这些先前的文献，并认为他们是第一批，所有审稿人也都这么认为。 本周，我给这篇 NeurIPS 2024 论文的作者发了电子邮件，他们承认这些工作（我的 + 其他 4 篇）确实都是在同一个问题设置上工作，并提到他们不知道所有这些工作，并承认他们不能再声称对问题设置具有新颖性。 NeurIPS 允许在会议结束后更新照相排版论文，作者承诺将利用这个机会合并那些相关工作并修改他们的贡献声明，不再声称对 X 和 Y 的第一个解决方案具有新颖性。 一方面，我很高兴我们的工作将得到适当的认可。 另一方面，我对在审查后严格修改贡献声明的道德性表示怀疑。作者不再声称具有新颖性，但审稿人特别赞扬了这种新颖性，这让我不确定如果审稿人知道这篇论文最终将不再能够声称其在审阅版本中声称具有的新颖性，他们是否会建议接受。 此外，这让我对实验部分感到疑惑。几乎可以肯定，审稿人会要求与这 5 篇先前的作品进行比较作为基线。这篇论文没有与基线进行比较，这在审阅这项工作的审稿人看来是合理的，因为他们认为问题设置是完全新颖的，并且不存在可以作为基线的先前方法。 在这里询问小组关于如何解决此类案件的任何想法：- 应该撤回这篇论文吗？- 应该通知领域主席/计划委员会吗？谁可能会或可能不会采取行动 - 这篇论文是否应该按照承诺的方式由作者更新，就这样？ - 还有别的吗？ 我删除了 X、Y 和 Z，以免公开羞辱作者，因为他们已经与我的电子邮件互动，我确信没有犯规行为，他们真的不知道这些作品。    提交人    /u/TaXxER   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gxooqv/d_accepted_neurips_2024_paper_claimed_to_be/</guid>
      <pubDate>Sat, 23 Nov 2024 01:58:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>