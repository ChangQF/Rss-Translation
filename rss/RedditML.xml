<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Fri, 14 Feb 2025 03:21:32 GMT</lastBuildDate>
    <item>
      <title>[d]如何根据其音频功能自动化命名批量音频样本？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ip0rnt/d_how_to_automate_naming_bulk_audio_samples_based/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好。 ，如果有人可以为我澄清一下，我将非常感谢它。我会切下它。我正在寻找一个可以分析音频文件的特征和生成描述性关键字或文本标签的工具，＆quot＆quot “深色环境垫环路”或“高能合成器循环”。我需要使用10k+音乐样本（每个大约5到20秒）。可以实现这一目标的嵌入，但是到目前为止，我没有任何运气，因此，如果有人可以将我指向正确的方向，或者至少告诉我没有大型团队是不可能的，我将非常感谢。&lt;&lt;&lt;&lt;&lt;&lt;&lt; /p&gt; 向任何试图提供帮助的人，谢谢您。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/krushur     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ip0rnt/d_how_how_to_automate_naming_naming_naming_bulk_audio_samples_basples_based/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ip0rnt/d_how_to_automate_naming_bulk_audio_samples_based/</guid>
      <pubDate>Fri, 14 Feb 2025 02:52:27 GMT</pubDate>
    </item>
    <item>
      <title>[P]纯C中的GPT-2（以及完整的CUDA工作室）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioybio/pgpt2_in_pure_cand_full_cuda_worklogs_to_come/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  并行计算是听起来令人生畏但对现代世界绝对必不可少的事情之一。从高频交易（HFT）到设备AI，最大程度地减少资源，同时最大程度地提高性能非常重要，并且随着我们转向更好的开源LLM，可能会成为瓶颈。  首先要潜入这个空间，我启动了一个项目，我以平原，幼稚和不优化的（边界愚蠢）C实现了GPT-2体系结构，而没有很大的依赖性。为什么？因为在最基本的层面上了解问题是有效优化它的唯一方法。大多数教程从基础知识开始（例如优化矩阵乘法，然后它们可能会介入基本操作/创建基于圆圈的渲染器），但是真实的生产级cuda，例如您在乔治·霍茨（George Hotz）的Tinygrad或Karpathy的LLM中看到的内核.c或类似项目是完全不同的事情。几乎没有任何结构化资源来弥合差距。 ，我的目标是吗？ ➡️从这个简单的实现开始，然后逐步优化。 ➡️学会从头开始构建cuda内核，基准测试并将它们与其他解决方案进行比较。 ➡️返回此GPT返回此GPT返回此GPT -2实施，再次逐步挑选它，看看我可以做到的速度更快，更精细，更有效。 ，我将使用完整的工作室  repolink： https://github.com/angry-kratos/gpt-2-in -c    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/atronos_kronios     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioybio/pgpt2_in_pure_cand_fule_fure_full_cuda_worklogs_to_to_to_to_come/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioybio/pgpt2_in_pure_cand_full_cuda_worklogs_to_come/</guid>
      <pubDate>Fri, 14 Feb 2025 00:43:58 GMT</pubDate>
    </item>
    <item>
      <title>[r]基于LLM的突变引导的元测试生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iou1uj/r_mutationguided_llmbased_test_generation_at_meta/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/ahmedmostafa16     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iou1uj/r_mutationguided_llmbased_test_generation_at_meta/</guid>
      <pubDate>Thu, 13 Feb 2025 21:26:59 GMT</pubDate>
    </item>
    <item>
      <title>[d]您是如何找到专业的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iosyf4/d_how_did_you_find_your_specialty/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  对于上下文，我是一个期待明年申请博士学位课程的本科生。我敢肯定我想学习ML，但这是一个非常广泛的话题。我已经倾斜了脚趾，在NLP中进行研究/项目，可解释性，扩散，推荐系统，歧管/几何方法，并将在音乐中以及RL中进行工作。你们如何找到自己的域名，以及确切地知道我要进入研究生院的内容有多重要？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/vialincasev2     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iosyf4/d_how_did_you_find_your_specialty/</guid>
      <pubDate>Thu, 13 Feb 2025 20:39:48 GMT</pubDate>
    </item>
    <item>
      <title>[D]升级模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioqhw8/d_upscaling_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我需要一个模型，该模型可以超过当前图像分辨率，更着重于推理时间（以milli secs为单位），你们知道任何模型吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/jiraiya1729     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioqhw8/d_upscaling_model/</guid>
      <pubDate>Thu, 13 Feb 2025 18:56:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlignRec在多模式建议中优于SOTA模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioo1ta/r_alignrec_outperforms_sota_models_in_multimodal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   alignrec，在 alignrec中引入：在多模式建议中对齐和训练（cikm &#39;24），解决多模式建议系统中的错误对准。传统方法难以整合各种内容类型（文本，图像和分类ID）到语义差距。 AlignRec通过优化三个对齐任务来解决此问题：ICA INTER-CONTENT（ICA），CONTENT类别（CCA）和用户项目（UIA）。 ICA通过基于注意力的编码器将语义表示统一，CCA使用对比度学习增强特征对齐，UIA通过余弦相似性损失来完善用户项目表示。   关键的Innovation是Alignrec的两阶段训练：预 - 培训使视觉和文本数据对齐，同时微型调整结合了用户行为以进行优化的建议。在亚马逊数据集中测试，它的表现优于九种SOTA模型，在长尾建议方面表现出色。通过弥合多模式语义差距，AlignRec提高了准确性和鲁棒性，推进了多模式AI驱动的建议。 以深入研究框架并结果，请参阅此处的完整纸张文章： https://www.shaped.ai/blog/multimodal-alignment-for-recmmentations   &lt; /div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/skeltzyboiii     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1ioo1ta/r_alignrec_outperforms_sota_moda_models_in_multimodal/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioo1ta/r_alignrec_outperforms_sota_models_in_multimodal/</guid>
      <pubDate>Thu, 13 Feb 2025 17:13:07 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何从头开始进行ML研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ion90w/d_how_you_do_ml_research_from_scratch/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   有人在顶级ML会议（NIPS，ICML，ICLR）或面向域的会议（CVPR，ICCV，ACL，EMNLP，KDD）上发布了作品，Sigir）。 1。如何从0到第一张纸？ 2。您的技能（Pytorch或域知识）是多少？ 3。您遵循的整个过程是什么善于实施您的想法？ 4。您如何提出想法和解决方案？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/antelopewilling2928      r/machinelearning/注释/1ion90w/d_how_you_do_do_ml_research_from_scratch/“&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ion90w/d_how_you_do_ml_research_from_scratch/</guid>
      <pubDate>Thu, 13 Feb 2025 16:40:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] Swe-Agent是Swe Bench Lite上的新开源SOTA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iolpvo/r_sweagent_is_the_new_opensource_sota_on_swebench/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   swe-agent是一种开源软件工程代理，可与任何类型的型号一起使用。我们的1.0版本增加了许多新功能：大规模并行运行；基于云的部署；具有工具捆绑包的广泛可配置性；新命令行接口＆amp;公用事业。完全开源（MIT），广泛的配置，易于破解。由于它将LITELLM用于LM接口，因此您可以与本地LM一起使用它：我们已经与QWEN一起使用了它，而其他社区成员已将其与Llama一起使用。   https://github.com/swe-agent/swe-agent    swe-agent现在由我们的新swe--提供支持REX软件包（也获得了MIT许可），这是一款轻巧的通用沙盒代码执行引擎，支持本地Docker，AWS，Modal Deployments  https：https：https：https：https： //github.com/swe-agent/swe-rex 。您可以使用它来轻松地从头开始使用代码执行，而无需弄清楚如何与运行的Docker容器进行通信！  swe-agent是由普林斯顿大学＆amp;开发的。斯坦福大学。如果您有任何疑问，我们将在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ofirpress     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iolpvo/r_sweagent_is_the_new_new_opensource_sota_sota_on_swebench/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iolpvo/r_sweagent_is_the_new_opensource_sota_on_swebench/</guid>
      <pubDate>Thu, 13 Feb 2025 15:35:03 GMT</pubDate>
    </item>
    <item>
      <title>[R]企业中的文本到SQL：比较方法和对我们有用的方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iojc1f/r_texttosql_in_enterprises_comparing_approaches/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  嗨hivery！  text-to-sql是一个流行的Genai用例，我们最近与一些企业合作。在这里分享我们的学习！ 这些企业已经尝试了不同的方法 - 使用rag，使用gpt-4O（例如GPT-4O），甚至是使用Autogen和Crew的GPT-4O，甚至基于代理的方法，将OR-LLM等最佳的LLM进行。但是它们以85％的精度撞到了天花板，面临超过20秒的响应时间（主要是由于错误的列出现的错误），并处理了使缩放硬缩放的复杂工程。 我们发现了这种微调在特定于商业的查询-SQL Pairs上的开放量LLM具有95％的精度，响应时间降低到7秒以下（通过消除故障恢复）和简化的工程。这些自定义的LLM保留了域内存，从而导致了更好的性能。 我们在上进行了比较。 sql-the-the-the-ultimate-guide-for-2025-3fa4e78cbdf9“&gt;中等。让我知道您的想法，如果您看到了更好的方法来解决此问题。 = Webp＆amp; s = 88251E0CFA246F2BF1F779E708AB03A96A3C0255“&gt; https：//preview.redd.i 246F2BF1F779E708AB03A96A3C0255    &lt; ！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sircomprehense7453     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iojc1f/r_texttosql_in_enterprises_comparing_approaches/</guid>
      <pubDate>Thu, 13 Feb 2025 13:44:21 GMT</pubDate>
    </item>
    <item>
      <title>[D]使用在线图像的自收集数据集的许可问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioj5ij/d_license_issue_with_selfcollected_dataset_using/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，因此我通过收集和注释在线图像来处理数据集。不幸的是，并非所有图像都符合CC许可。仅在我已发布的数据集中仅包含这些图像的链接是否合适？ （就像它被认为是合理使用的吗？还是会造成任何麻烦？）是否有任何流行的公共图像数据集，包括我不应该参考的CC许可证的图像？我对这些版权相关的事情并不熟悉，因此如果我在问题的描述中犯了任何错误，请提前道歉。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dectraTativead985     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioj5ij/d_license_issue_with_selfcollected_dataset_using/</guid>
      <pubDate>Thu, 13 Feb 2025 13:34:53 GMT</pubDate>
    </item>
    <item>
      <title>[R]自动化功能发现：使用基础模型自探索和评估AI能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iofk29/r_automated_capability_discovery_using_foundation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文介绍了一个称为自动化能力发现（ACD）的框架，该框架使用一个基础模型系统地探索和评估功能另一个模型。核心思想是将能力发现视为实验科学，其中一个模型充当科学家生成假设和设计测试。 关键技术点： - 框架由四个主要组成部分组成：任务生成，执行，执行，执行，执行，执行，评估和分析 - 使用提示策略来使评估器模型产生多样的有意义的测试 - 实现反馈循环，其中测试结果在未来的任务生成中为未来的任务提供了信息 - 评估包括二进制成功/失败和详细分析 - 对GPT -4进行了测试，Claude，Claude，Claude，和Llama模型作为评估者和受试者 结果： - 发现了数千个先前无证件的功能 -  AI评估者和人类在能力评估上的验证之间的共识为89％ - 生成的测试涵盖了从基本（ARITHMMETEC）到基本的功能类别复杂的（创意写作） - 成功识别已知模型限制 - 显示自动化和手动评估方法之间的密切相关性 我认为这种方法可以改变我们理解和评估AI系统的方式。我们可以对模型功能进行持续的自动探索，而不是仅依靠预定义的基准或手动测试。这对于快速测试新模型并确定意外能力或局限性特别有价值。 我认为，主要的挑战将确保评估器模型不受与主题模型相同的盲点的限制。还有一个问题是，这是如何将语言模型超出其他AI体系结构的概括。  tldr：新框架使用AI模型自动发现和评估其他AI模型的功能，并显示出与人类评估和人类评估和人类评估的强烈同意查找数千个以前未知的能力。   。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iofk29/r_automated_capability_discovery_using_foundation/</guid>
      <pubDate>Thu, 13 Feb 2025 09:43:22 GMT</pubDate>
    </item>
    <item>
      <title>[d]在2025年需要有关图像分类问题的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iocgvg/d_need_suggestions_for_image_classification/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  回到2022年下半年，我已经使用Edgitionnet_v2训练了图像分类模型（医学图像，高res），其中大约有20K数据。现在，我想重新训练该模型，因为我可以访问大量数据（〜300K）。我想提出一些建议。   我以前尝试过使用VIT，但其性能相对较差。我已经阅读了一些评论，即VIT在处理高RES图像方面存在一些问题。但是现在我注意到NVIDIA在DLSS上使用变压器。我认为高RES不再是VIT的问题。建议使用哪种VIT模型尝试？    我一直在使用预训练的重量作为起点并进行填充，因为我被告知我这样做我已经阅读的许多文章/在线信息，而且表现更好。是否仍建议使用预训练的重量在2025年？尤其是大多数图像模型是在低RES数据（224-512）上的火车，而我的数据集则是高RES。     CNN在2025年过时？我认为CNN和Transformer在与图像有关的问题上的竞争尚不清楚2023年。但是从2024年中开始，我看到很多人说Transformer赢得了胜利。      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/eternal14     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iocgvg/d_need_suggestions_for_image_classification/</guid>
      <pubDate>Thu, 13 Feb 2025 05:55:46 GMT</pubDate>
    </item>
    <item>
      <title>[r]“ O3在2024年IOI上获得了金牌，并获得了与精英人类竞争对手相当的代码供应”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1io4c7r/r_o3_achieves_a_gold_medal_at_the_2024_ioi_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    我们表明，应用于大型语言模型（LLM）的强化学习可显着提高复杂的编码和推理任务的性能。此外，我们将两种通用推理模型 -  OpenAI O1和O3的早期检查站与域特异性系统O1-IOI进行了比较，该系统使用手工设计的推理策略，旨在在2024年在Informatics中竞争（IOI）（IOI） ）。我们与O1-IOI一起在IOI 2024中现场直播，并使用手工制作的测试时间策略排名第49个百分位。在轻松的竞争限制下，O1-IOI获得了金牌。但是，在评估后来的O3之类的模型时，我们发现O3无需手工制作的领域特定策略或放松的约束就可以实现黄金。我们的发现表明，尽管O1-IOI等专门的管道可实现可靠的改进，但扩展的通用O3模型超过了这些结果，而无需依赖手工制作的推理启发式方法。值得注意的是，O3在2024年IOI上获得了金牌，并获得了与精英人类竞争对手的评级。总体而言，这些结果表明，扩展通用强化的增强学习，而不是依靠特定领域的技术，为推理领域（例如竞争性编程）提供了良好的途径。  &gt;  https://arxiv.org/abs/2502.06807       &lt;！ ＆＃32;提交由＆＃32; /u/u/we_are_mammals     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1io4c7r/1io4c7r/r_o3_achieves_a_medal_medal_medal_medal_medal_the_2024_ioi_ioi_and/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1io4c7r/r_o3_achieves_a_gold_medal_at_the_2024_ioi_and/</guid>
      <pubDate>Wed, 12 Feb 2025 22:55:17 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      对于那些寻找工作的人请使用此模板  &lt; p&gt;想要被录用：[位置]，薪水期望：[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简短概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，这个社区是适合有经验的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>