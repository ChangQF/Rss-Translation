<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 11 Dec 2024 06:26:17 GMT</lastBuildDate>
    <item>
      <title>[D] 为什么 Stella 嵌入模型比其他同等质量的模型小得多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbkww5/d_why_are_the_stella_embedding_models_so_much/</link>
      <description><![CDATA[在 MTEB 排行榜上，stella_en_v5 目前排名第三，而使用的内存仅为前 10 名中所有非 Stella 模型的五分之一。 stella_en_400M_v5 排名第十，而使用的内存比排名在其附近的模型少 15-20 倍。这似乎在基准测试的几个子任务中相对一致（针对英语）。 这里的秘诀是什么？或者说，陷阱是什么？目前还没有论文。有人知道详细信息吗？    提交人    /u/-p-e-w-   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbkww5/d_why_are_the_stella_embedding_models_so_much/</guid>
      <pubDate>Wed, 11 Dec 2024 03:58:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 第一资本电力日</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbjooi/d_capital_one_power_day/</link>
      <description><![CDATA[大家好，我在 Capital One 有一个应用研究员 1 职位的 Power Day。有人可以提供一些资源或提示来了解如何为 Power Day 做准备吗？我听说会有案例面试、技术面试、行为面试和演示。任何建议都值得赞赏！    提交人    /u/Funny_Rule2482   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbjooi/d_capital_one_power_day/</guid>
      <pubDate>Wed, 11 Dec 2024 02:52:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审查流程激励和竞争</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbf2gs/d_review_process_incentives_and_competition/</link>
      <description><![CDATA[我的一个实验室同事给我看了一条 AC 的评论，其中要求 ACM 会议的审稿人参与 ICLR 反驳和讨论阶段。光是这一点就让我感到好笑（和悲伤），但让我感到震惊的是，其中一位审稿人回应说，审稿过程激励审稿人给论文打低分，以阻止竞争论文被接受。 我想相信这种情况会发生，但其影响并不显著。然而，我听说这在推荐系统等领域非常常见。它在 ML 中普遍程度如何？    提交人    /u/like_a_tensor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbf2gs/d_review_process_incentives_and_competition/</guid>
      <pubDate>Tue, 10 Dec 2024 23:07:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 逆神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbbj5o/d_inverse_neural_network/</link>
      <description><![CDATA[大家好，我想问一下你们是否知道当前最好的监督逆神经网络是什么？我知道 GAN、VAE 和条件 VAE。 基本上，我的目标是确定满足输出值的多元函数的输入值，例如，找到 x=[x1,...,xN] 使得 0.2=f(x)。 我的主要专业是工程学（不是机器学习），我对该领域的了解非常有限。但是，我很擅长阅读你建议的任何研究论文。 谢谢大家， 编辑：抱歉，这个例子令人困惑。f 不是多元 pdf 而是一个“多元函数”f : R^N -&gt; R。具体来说，f 是一个“单变量” pdf 具有 N-1 个参数。    提交人    /u/zonanaika   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbbj5o/d_inverse_neural_network/</guid>
      <pubDate>Tue, 10 Dec 2024 20:34:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] Articulate Anything：从任何输入方式自动生成可交互的 3D 资产</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb82am/r_articulate_anything_automatic_generation_of_3d/</link>
      <description><![CDATA[📦 Frontier AI 能否将任何物理对象从任何输入模式转换为也可以移动的高质量数字孪生？很高兴分享我们的工作 Articulate-Anything，探索大型视觉语言模型 (VLM) 如何弥合物理世界和数字世界之间的差距。 Articulate-Anything 🐵 是一种最先进的方法，可以从任何输入模式（包括文本、图像或视频）自动创建可交互的 3D 资产。  网站：articulate-anything.github.io 论文：https://arxiv.org/abs/2410.13882 代码：https://github.com/vlongle/articulate-anything 请参阅我的推特帖子：https://x.com/int64_le/status/1866519866934714623 深入研究该方法    由    /u/Prudent_Fly_1004  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb82am/r_articulate_anything_automatic_generation_of_3d/</guid>
      <pubDate>Tue, 10 Dec 2024 18:08:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从失业到 Lisp：在青少年的深度学习编译器上运行 GPT-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb7v5h/d_from_unemployment_to_lisp_running_gpt2_on_a/</link>
      <description><![CDATA[几个月前，我失业了，不知道下一步该做什么。我想从系统的角度更多地了解深度学习。在学习了吴恩达的监督学习课程后，我渴望更多地了解像 Pytorch 或 Tinygrad 这样的深度学习框架（或深度学习编译器）。 我开始研究 Tinygrad，从我在网上找到的教程中学习，我发现它很有趣，因为它是一个真正的编译器，它采用传统的 Python 代码并将其转换为抽象语法树，然后将其解析为 UOps 和 ScheduleItems，最终拥有一个代码生成层。虽然设计很有趣，但代码很难读。 就在那时，我偶然发现了一些完全出乎意料的东西，一个基于 Common Lisp 构建的深度学习编译器，由一名 18 岁的日本年轻人在他的间隔年期间维护。目前我们已经完成了一件伟大的事情，它可以运行 gpt2！ 目前，它只是生成 C 内核，但未来我们希望支持 cuda codegen 以及许多其他功能，并作为任何想要使用 Common Lisp 进行深度学习编译器工作的人的学习工具。 这是一个开源项目，欢迎任何人做出贡献！ https://github.com/hikettei/Caten    提交人    /u/yCuboy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb7v5h/d_from_unemployment_to_lisp_running_gpt2_on_a/</guid>
      <pubDate>Tue, 10 Dec 2024 18:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于供暖系统机器学习的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb5dty/d_question_about_heating_system_machine_learning/</link>
      <description><![CDATA[您好，在传统的加热过程中，您可以控制何时开始加热以及何时使用目标值停止加热。一旦达到目标值，它将停止并一遍又一遍地启动整个过程，同时还会控制一些泵阀（有多少水需要循环）。 在过去 5 年（每分钟），我已经在时间序列数据库中捕获了几个室温、所有启动/停止以及加热自动化软件所做的泵阀调整。 我正在尝试创建一个具有恒定目标值的模型，例如 23°C。该模型的输入是加热系统状态（开/关）、泵阀位置和当前室温。输出应该是如何设置加热系统状态并调整阀门位置以达到并保持室温的目标值。在最好的情况下，它应该完全取代加热自动化软件。其他的就是仅仅建议或监督这个过程。 我想到了一些问题，我不知道该如何处理：  这个过程很慢，一旦开始加热，由于温度变化缓慢，1 小时后才能看到结果。那么对行动的评估必须延迟吗？ 我捕获的数据包含历史温度，但我认为它可能有缺陷。数据中的温度已经受到现有加热系统的影响。我没有温度数据显示在没有任何加热系统的情况下室温是如何变化的。这是学习的问题吗？我需要创建合成数据吗？ 训练一个模型来输出“开始加热/停止加热”（将其余部分留给传统的加热自动化）还是控制加热状态和泵阀本身会更好？ 什么是最好的机器学习技术，例如无监督，强化学习？     提交人    /u/QuickYogurt2037   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb5dty/d_question_about_heating_system_machine_learning/</guid>
      <pubDate>Tue, 10 Dec 2024 16:15:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 这个数据集到底有多难？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb54nd/r_how_difficult_is_this_dataset_really/</link>
      <description><![CDATA[新论文提醒！ 分类自动编码器测量分类难度并检测标签错误 我们倾向于认为训练分类器的挑战是由超参数调整或模型创新来处理的，但数据及其嵌入中存在丰富的固有信号。了解机器学习问题的难度一直很难。现在不再如此。 现在，您可以计算分类数据集的难度，而无需训练分类器，并且每个类别只需要 100 个标签。而且，这个难度估计与数据集大小出奇地无关。 传统上，数据集难度评估方法耗时和/或计算密集型，通常需要训练一个或多个大型下游模型。更重要的是，如果你在数据集上训练具有特定架构的模型并实现特定的准确度，则无法确定你的架构是否完全适合手头的任务 - 可能是一组不同的归纳偏差会导致模型更轻松地学习数据中的模式。 我们的方法为每个类训练一个轻量级自动编码器，并使用重建误差的比率来估计分类难度。在 100k 样本数据集上运行此数据集难度估计方法只需几分钟，并且不需要调整或自定义处理即可在新数据集上运行！ 效果如何？我们对 19 个常见的视觉数据集进行了系统研究，将我们的方法估计的难度与 SOTA 分类准确度进行了比较。除了一个异常值外，相关性为 0.78。它甚至适用于医疗数据集！ 论文链接：https://arxiv.org/abs/2412.02596 GitHub Repo Linked in Arxiv pdf    提交人    /u/ProfJasonCorso   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb54nd/r_how_difficult_is_this_dataset_really/</guid>
      <pubDate>Tue, 10 Dec 2024 16:04:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 理解 Transformer 在图形搜索中的局限性：学习和扩展行为的机制分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb1wjo/r_understanding_transformer_limitations_in_graph/</link>
      <description><![CDATA[本文通过研究 transformer 如何处理图连通性问题，解决了关于 transformer 学习搜索算法的能力的一个基本问题。作者开发了一种新颖的解释方法来分析 Transformer 如何逐层处理搜索操作。 关键技术要点：- 使用图可达性作为测试用例，具有可控的复杂性和无限的训练数据- 开发解释技术来了解 Transformer 层如何计算可达顶点集- 发现 Transformer 学习随着深度呈指数级扩展搜索边界- 展示了基于图大小的明显扩展限制- 表明上下文学习（思路链）无法克服这些限制 主要结果：- 小型 Transformer 在经过适当训练后可以学习基本搜索- 每一层计算先前可达顶点及其邻居的并集- 随着图大小的增加，性能急剧下降- 添加参数并不能解决扩展问题- 模型在处理超出其训练分布的图时遇到困难 我认为这项工作揭示了 Transformer 中重要的架构限制，我们需要为需要搜索功能的应用程序解决这些限制。缩放行为表明，对于更大的搜索空间，而不仅仅是更大的模型，我们可能需要从根本上不同的方法。 我认为他们开发的解释方法对于理解 Transformer 如何处理除图形之外的其他类型的结构化数据很有价值。关于扩展限制的明确经验结果应该为涉及搜索类计算的应用程序的架构选择提供参考。 TLDR：Transformer 可以学习基本的图形搜索操作，但在扩展方面面临根本限制。添加更多参数无济于事，这表明我们需要新的方法来解决复杂的搜索问题。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb1wjo/r_understanding_transformer_limitations_in_graph/</guid>
      <pubDate>Tue, 10 Dec 2024 13:37:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 模型出处：您如何追踪您的 ML 模型谱系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb0o4e/d_model_provenance_how_are_you_tracking_your_ml/</link>
      <description><![CDATA[嘿 r/MachineLearning，我很好奇这个社区的人们是如何处理模型出处的 - 在整个生命周期中跟踪机器学习模型的谱系和演变的实践。  您目前是否使用任何工具或方法来跟踪您的 ML 模型的出处？ 如果是，您使用什么解决方案？它们是定制的还是现成的？ 如果不是，您是否认为您的工作需要这样的工具？ 您认为模型出处解决方案中的哪些功能必不可少？     提交人    /u/crtahlin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb0o4e/d_model_provenance_how_are_you_tracking_your_ml/</guid>
      <pubDate>Tue, 10 Dec 2024 12:29:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] The Well：机器学习的大规模多样化物理模拟集合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1haz4nw/r_the_well_a_largescale_collection_of_diverse/</link>
      <description><![CDATA[数据集：https://github.com/PolymathicAI/the_well 论文：https://arxiv.org/pdf/2412.00568 摘要：  基于机器学习的替代模型为研究人员提供了加速基于模拟的工作流程的强大工具。然而，由于该领域的标准数据集通常涵盖一小部分物理行为，因此很难评估新方法的有效性。为了解决这一差距，我们引入了 Well：一个包含各种时空物理系统的数值模拟的大规模数据集集合。 The Well 汇聚了领域专家和数值软件开发人员的智慧，提供了 16 个数据集的 15TB 数据，涵盖生物系统、流体动力学、声散射以及河外流体或超新星爆炸的磁流体动力学模拟等不同领域。这些数据集可以单独使用，也可以作为更广泛的基准套件的一部分使用。为了方便使用 The Well，我们提供了一个统一的 PyTorch 界面来训练和评估模型。我们通过引入示例基线来演示该库的功能，这些示例基线突出了 The Well 复杂动态所带来的新挑战。代码和数据可在此 https URL 上找到。     提交人    /u/StartledWatermelon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1haz4nw/r_the_well_a_largescale_collection_of_diverse/</guid>
      <pubDate>Tue, 10 Dec 2024 10:49:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你是如何跟上文学发展的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hasdlo/d_how_do_you_keep_up_with_the_literature/</link>
      <description><![CDATA[标题基本就是这个意思。你用什么工具/策略来跟上文献的步伐？ 编辑：为了便于理解，我是一名一年级博士生，我指的是特定“利基”领域的文献（如果除了极少数例外，你可以在 ML 中将任何东西称为利基的话）    提交人    /u/Rickmaster7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hasdlo/d_how_do_you_keep_up_with_the_literature/</guid>
      <pubDate>Tue, 10 Dec 2024 03:20:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何管理和跟踪不断演变的大型图像数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1haokqp/d_how_do_you_manage_and_track_your_large_evolving/</link>
      <description><![CDATA[我想知道人们如何管理大型内部数据集的生命周期？比如说 &gt;1TB 和 100k 个文件。 在我的新角色中，我们有多个生产模型，这些模型是从内部数据集训练出来的，大小从几千到几十万张图像不等。我们还有大量新数据进入，每天超过 100 万张图像，因此我们不断挖掘这些数据并发送新的部分进行注释。 到目前为止，团队基本上都是自己管理这个问题，结果是可以预测的。在某些情况下，我们无法将我们的生产模型与任何特定数据关联起来。我们的一些核心数据集仅存在于人们的主目录中，很容易被一个错误的命令抹去。对于一个幸好被淘汰的模型，已知训练代码和原始训练数据都丢失了。 该组织的部分成员采用了 DVC，这似乎很不错，直到文件数量或整体大小变大。一方面，有些人将整个数据集塞进几个档案中并跟踪它们。这最大限度地减少了哈希带来的挫败感，但当只有几个文件更新时会占用大量存储空间。另一方面，有些人跟踪每个文件，这样可以单独更新文件，但签入和签出非常麻烦。其他人则将这两种方法的差异分开，以分层方式跟踪数据集的块作为档案。 那么你的组织是如何管理这一点的？在处理这些庞大且不断发展的数据集时，什么有效，什么无效？    提交人    /u/SirPitchalot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1haokqp/d_how_do_you_manage_and_track_your_large_evolving/</guid>
      <pubDate>Tue, 10 Dec 2024 00:09:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>