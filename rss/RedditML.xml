<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 18 Nov 2024 18:23:17 GMT</lastBuildDate>
    <item>
      <title>[P] 无需 SAHI 的小物体检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gubjpn/p_small_object_detection_without_sahi/</link>
      <description><![CDATA[大家好，我希望我来对地方了。 我目前正在做一个项目，需要在手机摄像头中检测背景混乱的非常小的物体。这些物体在 3024 x 4032 的图片中只有 10~20 个像素。 我已经用 SAHI 和平铺训练了一个 yolov8 模型。对我来说，80% 的地图效果已经足够好了，虽然在背景中产生了一些误报，但基本上可以检测到所有小物体。但我的主管对此并不满意，因为仍然存在误报，而且 SAHI 无法在手机中实时工作。 你有什么建议可以在手机设置中实现吗？    提交人    /u/Delay_no_more_1999   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gubjpn/p_small_object_detection_without_sahi/</guid>
      <pubDate>Mon, 18 Nov 2024 18:22:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为何 ML PhD 竞争如此激烈？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gu9os9/d_why_ml_phd_is_so_competitive/</link>
      <description><![CDATA[近年来，顶尖学校或相对顶尖学校的 ML 博士录取率出乎意料。大多数项目都要求之前有顶级论文才能入学。这被认为是最低限度。 另一方面，博士后行业 ML RS 职位也极具竞争力。 但如果你看，英特尔、NVIDIA、高通和其他公司的 EE 职位相对容易获得，与 ML 相比，获得博士学位或博士学位的出版要求并不严格。我不认为这些 EE 工作需要像 CS 人员那样无所不知的“高技能”人员（不要误会我贬低了 EE 博士学位）。你只需要一些技能，而且这些技能并不难掌握（从我作为前 EE 毕业生的经验来看）。 我以 EE 学位毕业，后来在一所中等学校（QS &lt; 150）攻读 CS 博士学位。但是一旦见到我的朋友，我就后悔去读 CS PhD，而不是按照传统路线加入 EE PhD。ML 竞争太激烈了，尽管我比我的 EE PhD 朋友更优秀，但我甚至想不出一份好工作（考虑到我的个人资料，RS 太远了）。 他们会在读博士后找到工作，大多数人会以工程师的身份加入顶级公司。而且我觉得，EE 职位的面试并不像花几年时间解决 leetcode 来破解 CS 职位那么难。而且在大多数情况下，面试轮次也更少。    提交人    /u/AntelopeWilling2928   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gu9os9/d_why_ml_phd_is_so_competitive/</guid>
      <pubDate>Mon, 18 Nov 2024 17:07:35 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 有人使用过 IBM WatsonX.ai 或 Watson Studio 进行云端机器学习吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gu9eb5/discussion_has_anyone_worked_with_ibm_watsonxai/</link>
      <description><![CDATA[大家好！ 一位客户提到，他们使用了 IBM WatsonX.ai，并且对所提供的解决方案非常满意。这引起了我的注意，因为在我的整个职业生涯中，我从未听说有人将此平台或 Watson Studio 用于基于云的机器学习项目；我一直听说 Google Cloud、AWS、DataRobot 和 Azure。 此外，我发现很难理解 IBM 如何构建有关可以使用 Watson Studio 做什么的信息。这一切似乎都非常复杂，也许就像平台本身一样。 我的问题是： 有人使用 IBM WatsonX.ai 或 Watson Studio 进行过机器学习项目吗？您的看法是什么？在功能、易用性和学习曲线方面，它们与 Azure 等其他平台相比如何？    提交人    /u/ealix4   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gu9eb5/discussion_has_anyone_worked_with_ibm_watsonxai/</guid>
      <pubDate>Mon, 18 Nov 2024 16:56:08 GMT</pubDate>
    </item>
    <item>
      <title>免费 GPU/TPU 驱动的笔记本服务 [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gu8ej2/free_gputpu_powered_notebook_service_project/</link>
      <description><![CDATA[我需要做一个机器学习项目。我想尝试测试各种架构并在一些数据集中研究它们，并希望写一篇好的研究论文。数据集的大小约为 60GB。除了 Colab 或 Sagemaker Studio Lab 之外，有没有免费的、由 GPU 驱动的 AI/Ml Notebook 服务？我想要比这些更好的。我尝试了 Azure for Students，但令人沮丧的是，它不允许我使用强大的 NVIDIA GPU。不幸的是，我的大学不为学生提供任何 GPU。无法想象在我的笔记本电脑上训练模型。任何帮助/建议都会非常有用。    提交人    /u/Due-Rest6652   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gu8ej2/free_gputpu_powered_notebook_service_project/</guid>
      <pubDate>Mon, 18 Nov 2024 16:15:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 三种现代超级计算机架构的 GPU 互连技术性能分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gu7swl/r_performance_analysis_of_gpu_interconnect/</link>
      <description><![CDATA[我发现这项研究超级计算机系统中 GPU 到 GPU 通信的研究非常有益。主要贡献是对不同互连技术及其对多 GPU 性能的影响进行了系统分析。 主要技术发现包括：  NVLink 提供最高带宽（双向高达 900 GB/s），但延迟开销更高 与 NVLink 相比，InfiniBand 的延迟更低（1-2μs），但带宽降低 PCIe 在所有测试中均表现出一致但较低的性能指标 拓扑和物理 GPU 排列会显著影响通信模式  一些关键方法论要点： - 使用 4-16 个 GPU 测试了多种硬件配置 - 测量标准通信模式的带宽、延迟和完成时间 - 分析不同数据大小和通信模式的影响 - 比较互连的理论带宽与实现带宽 我认为实际意义是……  最佳互连选择在很大程度上取决于工作负载特性 高带宽（NVLink）对大型模型训练更有利 分布式推理可能更喜欢低延迟解决方案（InfiniBand） 物理 GPU 拓扑应匹配常见的通信模式  TLDR：全面分析 GPU 互连性能，显示带宽、延迟和拓扑之间的权衡。结果表明，针对多 GPU 系统，针对工作负载的互连选择优化至关重要。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gu7swl/r_performance_analysis_of_gpu_interconnect/</guid>
      <pubDate>Mon, 18 Nov 2024 15:50:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求可用于生产的维度提取的最佳方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gu53ui/d_seeking_input_on_optimal_approach_for/</link>
      <description><![CDATA[[D] 大家好， 我一直在研究下面的问题。我正在处理一组包含各种工程图和不同组件的大型文档，我们需要从这些图纸中的组件中提取与尺寸相关的信息。工程图包含一个或多个组件。首先，重要的是识别组件（我们没有关于工程图中位置的任何信息），然后提取组件各部分上的尺寸。 示例数据集 - Kaggle 问题： - 实体数量将来可能会增加。 - 工程图上没有组件的名称。 - 只能通过其形状和结构来识别组件。 我想问一下，如果您处于我的位置，您会选择哪种方法？任何关于最佳生产方法的反馈都将不胜感激。    提交人    /u/Future-Outcome3167   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gu53ui/d_seeking_input_on_optimal_approach_for/</guid>
      <pubDate>Mon, 18 Nov 2024 13:49:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 动态学习率问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gu2u1l/d_dynamic_learning_rate_question/</link>
      <description><![CDATA[这里我开始了一系列可能很傻的问题，我忍不住要发布它们。 这个问题是关于处理不平衡的数据集，例如，一个标记图像，其中一些类别有很多样本，而其他类别的样本很少。 根据当前样本的类别在数据集中出现的频率来调整学习率有帮助吗？我的意思是，对于出现频率较低的样本，学习率要高一些，而出现频率较高的类别，学习率要低一些 在下一个词预测模型 (llm-s) 中，这意味着当当前词非常常见时，学习率要低一些，而当当前词出现频率稀少时，学习率要高一些。    提交人    /u/blimpyway   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gu2u1l/d_dynamic_learning_rate_question/</guid>
      <pubDate>Mon, 18 Nov 2024 11:41:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与其他人一起预订 GPU 的系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gu1jfx/d_booking_system_for_gpu_with_other_people/</link>
      <description><![CDATA[大家好， 我和我的朋友正在做一个项目：我们可以使用 GPU，我们希望确保我们每个人都可以在需要时使用 GPU。您知道任何允许我们预订时间段的应用程序吗？本质上，我们正在寻找一个方便且易于使用的共享日历。 谢谢大家！    提交人    /u/SupertrampDFenx   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gu1jfx/d_booking_system_for_gpu_with_other_people/</guid>
      <pubDate>Mon, 18 Nov 2024 10:10:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] AnyModal：用于多模态法学硕士 (LLM) 的 Python 框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtw77c/p_anymodal_a_python_framework_for_multimodal_llms/</link>
      <description><![CDATA[AnyModal 是一个模块化且可扩展的框架，用于将各种输入模式（例如图像、音频）集成到大型语言模型 (LLM) 中。它使用针对各种模式的预训练模型实现无缝标记、编码和语言生成。我创建 AnyModal 是为了解决现有资源中用于设计视觉语言模型 (VLM) 或其他多模式 LLM 的空白。虽然有用于特定任务的出色工具，但没有一个可以轻松将不同输入类型与 LLM 相结合的统一框架。 AnyModal 旨在通过简化添加新输入处理器和标记器的过程，同时利用预训练语言模型的优势来填补这一空白。 示例用法 from transformers import ViTImageProcessor, ViTForImageClassification from anymodal import MultiModalModel from vision import VisionEncoder, Projector # 加载视觉处理器和模型 processing = ViTImageProcessor.from_pretrained(&#39;google/vit-base-patch16-224&#39;) vision_model = ViTForImageClassification.from_pretrained(&#39;google/vit-base-patch16-224&#39;) hidden_​​size = vision_model.config.hidden_​​size # 初始化视觉编码器和投影仪 vision_encoder = VisionEncoder(vision_model) vision_tokenizer = Projector(in_features=hidden_​​size, out_features=768) # 加载 LLM 组件 from transformers import AutoTokenizer, AutoModelForCausalLM llm_tokenizer = AutoTokenizer.from_pretrained(&quot;gpt2&quot;) llm_model = AutoModelForCausalLM.from_pretrained(&quot;gpt2&quot;) # 初始化 AnyModal multimodal_model = MultiModalModel( input_processor=None, input_encoder=vision_encoder, input_tokenizer=vision_tokenizer, language_tokenizer=llm_tokenizer, language_model=llm_model, input_start_token=&#39;&lt;|imstart|&gt;&#39;, input_end_token=&#39;&lt;|imend|&gt;&#39;, prompt_text=&quot;给定图像的解释是：&quot; )  AnyModal 提供了一个统一的框架，用于将来自不同模态的输入与 LLM 相结合。它抽象了许多样板，让用户可以专注于他们的特定任务，而不必担心低级集成。与现有工具（如 Hugging Face 的转换器或特定于任务的 VLM，如 CLIP）不同，AnyModal 为任意模态组合提供了灵活的框架。它非常适合小众多模态任务或需要自定义数据类型的实验。 当前演示  LaTeX OCR 胸部 X 光字幕（进行中） 图像字幕 视觉问答（计划中） 音频字幕（计划中）  该项目仍在进行中，我很乐意收到社区的反馈或贡献。无论您是想添加新功能、修复错误还是仅仅尝试一下，我们都欢迎您提供任何意见。 GitHub repo：https://github.com/ritabratamaiti/AnyModal 请告诉我您的想法或任何疑问。    提交人    /u/Alternative_Detail31   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtw77c/p_anymodal_a_python_framework_for_multimodal_llms/</guid>
      <pubDate>Mon, 18 Nov 2024 04:02:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 还在研究论文中迷失？Ribbit Ribbit 进军 Web 和 Android！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtvmpn/p_still_drowning_in_research_papers_ribbit_ribbit/</link>
      <description><![CDATA[      嘿朋友们！上个月，我们分享了 Ribbit Ribbit，这是我们在 iOS 上的小型研究论文发现工具，哇哦，非常感谢您的喜爱！在过去的几周里，我们一直在努力将它带到更多地方，现在我们很高兴与大家分享：  完整网站 https://ribbitribbit.co 现已上线！它具有应用程序的所有功能。您可以在大屏幕上浏览论文以获得额外的清晰度，也可以将其放在手机上随时随地浏览 - 以您的方式进行研究！ Android 即将推出！它可通过 Google Play 测试获得。 Google 需要足够的测试人员才能上线，因此，如果您愿意尽早试用，请加入我们的测试人员小组：https://ribbitribbit.co/request?testandroid=true。您绝对会成为我们的英雄！  Ribbit Ribbit 可帮助您找到个性化的论文推荐，将其缩小为推文大小的摘要，甚至像播客一样读给您听。我们只是想让整个研究过程变得更有趣。我们希望您能查看一下。您的支持对我们意义重大！ https://preview.redd.it/hyf9e6rmxk1e1.png?width=1492&amp;format=png&amp;auto=webp&amp;s=9a4deb6f3b70c9cf79d3441846ee03d6d6b93d22    提交人    /u/haoyuan8   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtvmpn/p_still_drowning_in_research_papers_ribbit_ribbit/</guid>
      <pubDate>Mon, 18 Nov 2024 03:31:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对机器学习工程职位的期望</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtt099/d_expectation_from_machine_learning_engineering/</link>
      <description><![CDATA[大家好， 我在这里看到了很多关于 ML 职业和实习或工作机会的帖子，有两件事经常出现  建立强大的研究作品集，并在 NeurIPS、ICLR 和 ICML 等会议上发表文章，这些会议似乎更侧重于获得研究科学家的职位。 对机器学习工程师 (MLE) 职位的需求不断增长，显然比研究科学家职位更受欢迎。  我很好奇这两个角色之间的区别，以及什么样的作品集对于获得 MLE 职位来说是理想的。我知道拥有硕士学位通常是首选，但令人印象深刻的出版记录对 MLE 职位来说是必要的吗？或者这不是什么大问题？ 你怎么看？   由    /u/ziggyboom30  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtt099/d_expectation_from_machine_learning_engineering/</guid>
      <pubDate>Mon, 18 Nov 2024 01:14:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] PCA 与自动编码器在降维方面的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtng8q/d_pca_vs_autoencoders_for_dimensionality_reduction/</link>
      <description><![CDATA[标题总结了一切。我正在处理一些匿名时间序列数据，最初，我构建了一个自动编码器，以便在训练后用回归头替换解码器头。 至于预处理步骤，我通常只减去特征的平均值并除以它们的标准差，虽然我早就听说做“数据去相关”很有帮助，所以我决定最终学习 PCA。 我的问题如下：  如果 PCA 用于查找数据集的主要潜在特征，那么使用自动编码器有什么意义吗？（特别是如果某些特征之间存在高度相关性） 如果仍然有必要使用自动编码器，是否应该首先在数据集上使用 PCA 来去相关数据，或者这只是多余的，或者也许不使用它的另一个原因是它会擦除一些信息？ （尽管它是一种可逆变换，所以我看不出信息会如何丢失） PCA 作为预处理步骤是否有利于树构建算法？我没看到太多关于它的讨论，但对我来说，直观地看，在主成分轴上设置决策节点会带来更好的结果。     提交人    /u/DisciplinedPenguin   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtng8q/d_pca_vs_autoencoders_for_dimensionality_reduction/</guid>
      <pubDate>Sun, 17 Nov 2024 20:56:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 论文的质量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtjhge/d_quality_of_iclr_papers/</link>
      <description><![CDATA[我浏览了 ICLR 上一些与我感兴趣的领域相关的中等到高分论文，我发现它们进展缓慢，而且有点惊讶，对于一个主要的子领域来说，像这样的顶级会议，论文质量相当差。自从 llms 出现以来，我觉得论文的质量和原创性（当然不是全部）有所下降。只有我一个人有这种感觉吗？    提交人    /u/Cool_Abbreviations_9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtjhge/d_quality_of_iclr_papers/</guid>
      <pubDate>Sun, 17 Nov 2024 18:02:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Nov 2024 16:00:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>