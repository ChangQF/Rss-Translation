<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 07 May 2024 12:24:59 GMT</lastBuildDate>
    <item>
      <title>[D] 离开稳定的技术工作去攻读 ML 硕士学位，既兴奋又害怕！需要建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm9ycl/d_leaving_a_stable_tech_job_for_a_masters_in_ml/</link>
      <description><![CDATA[我感到焦虑。我今年 25 岁，拥有电子和电信工程学士学位。我一直对信号和系统、图像处理和机器学习充满热情。在大学里，我与他人共同创立了一个专注于人工智能的俱乐部，与公司合作举办研讨会和项目。大三时，我在一家汽车公司实习，从事 ADAS 工作，特别是 1 级——自适应巡航控制。我分析并实现了一个比较目标网络。这是我第一次真正体验机器学习，我非常喜欢它。我拒绝了那里的预录用机会，因为薪水明显低于另一家科技公司为我提供的薪水。我在第二家公司担任软件开发人员已近四年了。别误会我的意思——我已经获得了不错的加薪、保留奖金和晋升。然而，我现在看到的“增长”越来越少。最初，我觉得我在学习，但现在感觉更像是平凡的任务（或者至少是我知道可以使用我随着时间的推移学到的工具来实现的任务，例如系统设计、设计模式、OOP）。我曾经完成过一些具有挑战性的任务，可以在这些任务中学习工业级软件开发，但我一直在想，“我在做什么？”我怀念学习和实施机器学习模型时感受到的兴奋。我公司举办“创新周”活动每三个月我都会修改机器学习模型并为我们的产品创建有用的工具，我的经理对此非常赞赏。去年 ChatGPT/genAI 热潮之后，我的经理和各个 PM 希望我从事一个“秘密项目”，即“秘密项目”。可以说，这比实现现有模型要复杂得多。作为唯一领导该项目的人，我很快意识到我对这个领域以及自己构建 SaaS 的了解有多少。我感到非常失败和沮丧。我从那次经历中学到了很多东西，但我知道我必须提高技能。我申请了硕士课程，并进入了 6 所大学中的 5 所机器学习和信号处理专业。我想做，但是我很害怕！在裁员屡见不鲜的经济环境下，离开高薪工作回到学校是令人畏惧的。我不确定这是否是一个愚蠢的决定。这个 Reddit 子版块对我来说是一个很好的资源。我只是希望一切顺利。 PS：我的团队/组织目前专注于公司最赚钱的产品，所以我没有途径过渡到全职机器学习角色。 “隐形项目”这些任务必须与我目前的 SDE 职责一起完成，这实在是太繁重了。攻读硕士学位以将我的职业转向机器学习似乎是一个好主意。 PS1：我有一份奖学金，可以支付我硕士学费的 50%，我可以用我的积蓄轻松支付剩下的费用。多年来积累的。然而，这些积蓄不足以在毕业后找工作时轻松维持失业状态。 TL;DR：25 岁，拥有电子和电信背景，热衷于ML，尽管经济存在不确定性并且担心离开高薪职位，但我正在考虑辞去一份稳定的技术工作去攻读 ML 硕士学位。我经历过增长停滞，渴望机器学习带来的挑战和兴奋。我已被六所研究生院中的五所录取，并获得了一半学费的奖学金，但我对毕业后的财务风险感到焦虑。寻求建议。   由   提交 /u/Curiousbees01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm9ycl/d_leaving_a_stable_tech_job_for_a_masters_in_ml/</guid>
      <pubDate>Tue, 07 May 2024 11:47:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将LLM输出限制为某些单词</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm9r0y/d_limiting_llm_output_to_certain_words/</link>
      <description><![CDATA[假设我想对文本进行多类分类。一种方法是提示工程师，但是，这可能会输出与我想要的不同的标签。下面是一个示例： 从文本中提取以下标签。标签：苹果、橙子。文本：我吃了一个苹果，然后吃了几个橙子。答案：苹果，橙子  上面显示的答案只是预期的答案。如果我们要使用提示，其他一些可能性将是 [Apple，Orange]，[Oranges，Apples] 等。 就我而言，我确实有一组广泛的标签，我可以对模型进行微调在。虽然我可以训练 BERT 来做到这一点，但我希望将来能够添加标签，因此想尝试微调 LLM。有没有办法训练这个，以便我们限制 Answer 后可以输出的单词？我能想到的一种方法是查看单词的逻辑，但这取决于标记化（例如，apple 可以是 ap_, _ple）。 还有 instructor 库，但据我了解，这不适用于变压器库模型（例如 Llama-3）（至少在不单独托管的情况下）。 希望对此有任何提示/想法。 TIA   由   提交/u/themathstudent  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm9r0y/d_limiting_llm_output_to_certain_words/</guid>
      <pubDate>Tue, 07 May 2024 11:36:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] Agent Cloud - 用于构建私人 LLM 应用程序的开源 GUI 平台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm82xu/p_agent_cloud_opensource_gui_platform_to_build/</link>
      <description><![CDATA[大家好，我们正在构建 Agent Cloud，自过去几个月以来我们一直在 RAG 领域工作，并且我们是开源的.  Agent Cloud 是一个开源平台，使公司能够构建和部署私人 LLM 聊天应用程序，使团队能够安全地与其数据交互。 AgentCloud 在内部使用 Airbyte 构建数据管道，使我们能够对来自 300 多个数据源（包括 MongoDB 等 NoSQL 数据库）的数据进行拆分、分块和嵌入。它简化了将数据引入向量存储以进行初始设置和后续计划更新的过程，确保向量存储信息始终更新。 AgentCloud 使用 Qdrant 作为向量存储来高效存储和管理大量向量嵌入。对于给定的用户查询，RAG 应用程序通过分析向量表示与查询向量的相似程度，从向量存储中获取相关文档。  您可以在项目的自述文件中找到有关其工作原理以及如何使用它的更多信息，我们将在本周末推出云版本。   我们也非常愿意接受贡献，并为初学者添加了很好的第一期。 ​  同步策略- 我们仍然需要实现更改为增量追加而不是完全覆盖的能力 分块策略 - 我们有语义分块，我们希望实现与 Airbyte 连接配合良好的自定义策略 - 目前逐条消息分块(Rust) 检索策略 - 目前我们使用代理来制作查询，我们希望可以在 RAG 连接器中添加更多标准检索策略（TS、Python、Mongo）&lt; /li&gt; 对话应用程序易于设置 - 我们希望采用一种设计模式来简化对话应用程序的设置。  API - 将我们当前的 Web 应用程序 API 作为开放 API 规范等发布。   很高兴回答任何问题。 [GitHub 存储库](https://github.com/rnadigital/agentcloud)   由   提交 /u/thewritingwallah   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm82xu/p_agent_cloud_opensource_gui_platform_to_build/</guid>
      <pubDate>Tue, 07 May 2024 09:51:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用耳语识别不常见术语</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm7frx/d_recognizing_uncommon_terms_with_whisper/</link>
      <description><![CDATA[大家好，我目前正在开发 Whisper，专门研究法语铁路语言。我在转录含糊不清的单词和识别电台名称方面面临一些问题。最初，我尝试用总共2个小时的音频文件来训练它，但结果并没有达到我的预期。然后我转向使用提示，这解决了歧义问题，但是由于上下文大小限制为 244 个标记，我无法包含所有电台名称。 您能给我一些提示吗？我是这个领域的新手。谢谢   由   提交/u/Top-Set-1178   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm7frx/d_recognizing_uncommon_terms_with_whisper/</guid>
      <pubDate>Tue, 07 May 2024 09:06:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] EOS 代币在预训练过程中重要吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm7eqw/d_is_eos_token_crucial_during_pretraining/</link>
      <description><![CDATA[预训练期间使用的 EOS 令牌标记“序列结束”，但它不会阻止信息在可能不相关的文档之间流动。如果是这样，当我们可以稍后在 SFT 阶段添加它时，为什么还要在预训练期间包含它？   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm7eqw/d_is_eos_token_crucial_during_pretraining/</guid>
      <pubDate>Tue, 07 May 2024 09:04:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] Stack Overflow 与 OPEN AI 的合作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm64jk/d_stack_overflow_partnership_with_open_ai/</link>
      <description><![CDATA[      https://stackoverflow.co/company /press/archive/openai-partnership 一些想法： - 很确定 OPEN AI 在训练 ChatGPT 时已经抓取了 Stack Overflow（如果你不这么做的话）相信它 - 请再次观看米拉·穆拉蒂 (Mira Murati) 的著名采访） - 那么为什么要这样做呢？也许可以合法访问内容？ - 自从 Chat GPT 发布以来，StackOverflow 的受欢迎程度正在下降（请参见下面的 Google 趋势图表）- 所以这对于 SO 所有者来说是有意义的 &lt; p&gt;- 从社区的角度来看非常有趣：开发者免费创建了整个内容，现在将用于替换它们，并且他们没有获得利润分成 ​ https://preview.redd.it/fudrujkniyyc1 .png?width=968&amp;format=png&amp;auto=webp&amp;s=e116159e61394557e03a6cad431aadc77f88807b   由   提交/u/pg860  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm64jk/d_stack_overflow_partnership_with_open_ai/</guid>
      <pubDate>Tue, 07 May 2024 07:29:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 快速推理如何与最先进的法学硕士一起工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cm4h4i/d_how_does_fast_inference_work_with_state_of_the/</link>
      <description><![CDATA[我读到 Llama-2 70B 等模型的推理速度最多约为 10 t/s。所以这让我想知道像 GPT-4（1T 参数？）这样的超大型模型是如何进行快速 20 t/s 推理的。使用 10 倍的参数，它们必须至少有 3 倍的层（？），所以这应该会使其推理速度慢得多。我错过了什么吗？这些公司可能会做哪些进一步的改进来支持他们的快速 API？ 编辑：我必须提到，当数据必须通过模型时，您无法跨 GPU 并行化来帮助解决单个示例的延迟问题 由于模型尺寸较大，模型并行性及其 GPU 间通信应该会使其变得更慢......  &amp;# 32；由   提交/u/Fit-Flow-4180   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cm4h4i/d_how_does_fast_inference_work_with_state_of_the/</guid>
      <pubDate>Tue, 07 May 2024 05:36:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT-2 训练的数据准备</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1clx2bi/d_data_preparation_for_gpt2_training/</link>
      <description><![CDATA[      大家好， 我正在创建一个数据集来使用 nanoGPT 存储库训练/微调 GPT-2。我在txt文件中有这样的格式： SENTENCE TREE PARSING &lt;|endoftext|&gt; SENTENCE TREE PARSING &lt;|endoftext|&gt; 等等（在分词过程中添加了特殊的分词，\n\n 被它替换）。 这是正确的吗？或者我应该使用模型的其他格式来学习解析句子？ 谢谢！😊 一些示例   由   提交/u/NeatFox5866   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1clx2bi/d_data_preparation_for_gpt2_training/</guid>
      <pubDate>Mon, 06 May 2024 23:11:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 参与补助金</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cloxpt/d_icml_participation_grant/</link>
      <description><![CDATA[作为加拿大的一名博士生，并在 ICML 上发表了一篇已被接受的论文，我对参加这些昂贵的会议的资金选择感到好奇。虽然我的主管承担了一些费用，但总费用可达 3500-4000 加元，其中包括 700 加元的注册费。是否有其他外部资金来源可用于支付剩余费用？   由   提交/u/Personal_Click_6502   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cloxpt/d_icml_participation_grant/</guid>
      <pubDate>Mon, 06 May 2024 17:33:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 羊驼 3 怪物</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cljvpa/d_llama_3_monstrosities/</link>
      <description><![CDATA[我刚刚注意到有人通过将 Llama 3 与自身合并来创建了 Llama 3 的 120B Instruct 变体（最终结果重复了 60 / 80 层）。他似乎专门研究这些弗兰肯斯坦模型。对于我的一生来说，我实在无法理解这种趋势。使用 mergekit 可以轻松轻松地创建这些，我想知道它们在野外的商业用途。 Bud 甚至承认它并不比 GPT-4 更好。那么有什么意义呢？哦等等，他写到了帖子的结尾，并提到他已将其提交给 Open LLM Leaderboard……我们开始吧。 LLM排行榜攀登的游戏化很累人。   由   提交 /u/Objective-Camel-3726   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cljvpa/d_llama_3_monstrosities/</guid>
      <pubDate>Mon, 06 May 2024 14:04:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] LeRobot：Hugging Face 的现实世界机器人库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cldfy2/p_lerobot_hugging_faces_library_for_realworld/</link>
      <description><![CDATA[      认识一下 LeRobot，一个库托管最先进的机器人深度学习。 人工智能开发的下一步是将其应用到我们的物理世界。因此，我们正在围绕机器人人工智能构建社区驱动的工作，并且向所有人开放！ 看一下代码： https://github.com/huggingface/lerobot https://preview.redd.it/ugf4l8lfgryc1.png?width=3794&amp;format=png&amp;auto=webp&amp;s=222825e897ba48eb07acedffb0662d5794af04 e8 乐机器人是对于机器人技术来说，就像 Transformers 库对于 NLP 一样。它提供了带有预先训练的检查点的高级人工智能模型的干净实现。我们还重新实现了来自学术界的 31 个数据集和一些模拟环境，无需物理机器人即可开始使用。 Aloha项目。 [视频链接] https://preview.redd.it/86ihkcwhgryc1.png?width=2506&amp;format=png&amp;auto=webp&amp;s=4f2ca7522a012d00d7327d903 35d069dd099a321 LeRobot 的另一个可视化，这次是在 Mobile Aloha 数据上，学习完全端到端的导航和操作。这两个数据集都是在 trossenrobotics 机器人手臂上收集的。 [视频链接] https://preview.redd.it/qqtncqligryc1.png?width=1900&amp;format=png&amp;auto= webp&amp;s=4f83c675b5c6f9dbded4b5b90a7a1c9f531c4086 LeRobot 代码库已通过在模拟中复制最先进的结果进行了验证。例如，这里是著名的 ACT 策略，它已被重新训练并可用作预训练检查点： [HF HUB 链接] LeRobot 还具有扩散政策，强大的模仿学习算法，以及TDMPC，一种包含世界模型的强化学习方法，不断从与环境的交互中学习。 https://preview.redd.it /br9ibrylgryc1.png?width=1684&amp;format=png&amp;auto=webp&amp;s=8e5595f1dff5381e5f60c6776126f48187ec58d9 快来加入我们的Discord 频道。我们正在建立一个来自不同背景、软件和硬件的多元化社区，以开发现实世界中的下一代智能机器人！ 感谢人工智能和机器人社区，没有他们就没有乐机器人。可能。   由   提交/u/Tamazy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cldfy2/p_lerobot_hugging_faces_library_for_realworld/</guid>
      <pubDate>Mon, 06 May 2024 07:48:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kolmogorov-Arnold 网络只是一个 MLP</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1clcu5i/d_kolmogorovarnold_network_is_just_an_mlp/</link>
      <description><![CDATA[事实证明，您可以将 Kolmogorov-Arnold 网络编写为 MLP，并在 ReLU 之前进行一些重复和移位。  https://colab.research.google.com/drive/1v3AHz5J3gk-vu4biESubJdOsUheycJNz &lt; /div&gt;  由   提交 /u/osamc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1clcu5i/d_kolmogorovarnold_network_is_just_an_mlp/</guid>
      <pubDate>Mon, 06 May 2024 07:04:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 Gemma 有如此疯狂的大 MLP 隐藏暗尺寸？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1clcluq/d_why_gemma_has_such_crazy_big_mlp_hidden_dim_size/</link>
      <description><![CDATA[   /u/kiockete  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1clcluq/d_why_gemma_has_such_crazy_big_mlp_hidden_dim_size/</guid>
      <pubDate>Mon, 06 May 2024 06:48:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如果 Llama-3 只有 8K 上下文长度，为什么它可以使用 32K 上下文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1clbmz2/r_why_can_llama3_work_with_32k_context_if_it_only/</link>
      <description><![CDATA[大家好！请参阅此处的帖子：https://twitter.com/abacaj/status/1785147493728039111 我没有不明白他所说的“通过零训练（实际上只是一个简单的 2 行配置），你可以从 llama-3 模型中获得 32k 上下文”的意思 有人知道这个动态是什么吗？缩放技巧是？非常感激！ :)   由   提交 /u/sunchipsster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1clbmz2/r_why_can_llama3_work_with_32k_context_if_it_only/</guid>
      <pubDate>Mon, 06 May 2024 05:43:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>