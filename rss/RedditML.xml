<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 06 Feb 2024 18:15:29 GMT</lastBuildDate>
    <item>
      <title>DCGAN论文建议[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akgbue/dcgan_paper_suggestions_d/</link>
      <description><![CDATA[大家好，我是人工智能专业的硕士生，我将在实习中使用 GAN，所以在开始之前我试图研究它们。  我已经使用 MNIST 数据集研究并实现了 DCGAN、WGAN-GP 和 cDCGAN，现在我试图更深入地了解一些实验结果。我想知道是否有人尝试过 DCGAN具有特定的架构，如 ResNet 或类似的东西。 我阅读了“使用深度卷积生成对抗网络进行无监督表示学习”。我相信它为设计 DCGAN 设定了一些标准，但它是 2016 年的，所以我想知道最近是否有类似的文章发表。所以最后我要求你推荐你认为是的论文很有影响力，值得一读。我尝试在谷歌学术上搜索，但它们太多了，很难理解该读哪一篇。   由   提交/u/Sensitive-Specific17   reddit.com/r/MachineLearning/comments/1akgbue/dcgan_paper_suggestions_d/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akgbue/dcgan_paper_suggestions_d/</guid>
      <pubDate>Tue, 06 Feb 2024 18:13:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 困惑是判断法学硕士的好方法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akfzr0/d_is_perplexity_a_good_way_to_judge_llms/</link>
      <description><![CDATA[我们知道 LLM 是经过训练的预测模型，其任务是预测下一个单词，从而形成连贯、相关的响应。  由于一般来说，置信的输出意味着正确的输出，因此 Perplexity（通过平均对数概率的指数来衡量模型置信度）可能是评估 LLM 申请质量的好方法。 &gt; 然而，困惑有各种局限性，这些局限性在生成新颖文本的法学硕士的情况下尤为突出：  它不能捕获上下文信息和深层语义理解。 &gt; 它会惩罚模型混淆同义词的情况。   例如：考虑一个提示 LLM 的情况： 问：已知信息：国库券是短期政府证券......投资者可以购买国库券要么通过 TreasuryDirect 网站直接从财政部获取，要么通过银行和经纪人间接获取……。鉴于我是外国注册企业主，我如何购买国库券？ A.您可以通过 TreasuryDirect 网站或摩根大通、高盛等银行和经纪商购买。 查看“购买”一词的模型概率，我们看到排名前 3 的代币为 [购买：0.4] ，获取：0.3，购买：0.3]，反映了模型混乱和较高的困惑度分数，但它不会影响响应的质量。 在这种情况下，即使响应是连贯的，它也是质量低，因为用户查询没有得到答复，这没有反映在困惑度分数中。  为了克服这个问题，我认为以下指标列表对每个开发人员都会有所帮助： ​   指标 用例    事实准确性 检查响应是否可以通过检索到的上下文进行验证   响应相关性 检查生成的响应是否与用户的问题相关   响应完整性 检查生成的响应是否回答了用户查询的所有方面   ​   由   提交 /u/Vegetable-Skill-9700   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akfzr0/d_is_perplexity_a_good_way_to_judge_llms/</guid>
      <pubDate>Tue, 06 Feb 2024 17:59:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我被困在研究中 3 个月了，不知道该怎么做</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akfyge/r_im_stuck_in_my_research_for_3_months_and_dont/</link>
      <description><![CDATA[我目前正在攻读数据科学硕士学位。我的论文（也是一篇写论文的研究）在过去的三个月里停滞不前，没有任何进展，我不知道该怎么办。  我需要实现论文A中的方法代码，并与我当前关于稀疏专家混合（SMoE）的项目代码B相结合。  首先，我尝试阅读论文 A 并检查代码，但我并没有完全理解所有数学知识，甚至他们提供的代码也有一些论文中没有提到的步骤，这使得它甚至更复杂。然而，我仍然尝试将其实现到我的项目中，但代码不断出现错误并卡住。然后我又花了点时间去debug，但是还是不行。每次想到这个项目我就感到胃部不适，甚至晕倒过一次，浪费了1个月的时间来恢复（我还没有完全康复，因为现在我每天不能不看笔记本电脑屏幕超过4小时）去模糊） 看到我很挣扎（他不知道我的健康问题），我的导师建议也许这个方法不太好，我们不应该再参与太多。他给了我 1 周的时间来调试最后一次，然后我在下次会议上报告是否应该继续。他还很鼓励我，说我的代码和调试技术还不够好，可以通过这篇论文多练习一下，并请实验室的另一位同事帮我调试代码。  问题是，这位同事对我的项目并不了解，他只是编码能力很强。我觉得我不够好，对论文A的理解不够好，不知道如何向同事寻求帮助，并在1周内简要介绍我所有的大论文。  我： - 一遍又一遍地阅读论文 A 以及与论文 A 相关的一些论文，但仍然不理解数学。 - 尝试从基础课程重新学习代码，并练习调试。但课程中的调试练习很简单。现实生活不一样，整个论文有很大的代码库。 现在我不知道该怎么办，感觉即使再给我两个月时间，我仍然无法完成代码。我的国家正在放假，我应该放松休息，但我却在焦虑中挣扎，睡觉，看到我的心情不好，我的家人为我担心，也无法享受假期。 &lt; p&gt;希望听到你们的一些建议:((    提交者    /u/ma-d-ghost   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akfyge/r_im_stuck_in_my_research_for_3_months_and_dont/</guid>
      <pubDate>Tue, 06 Feb 2024 17:58:27 GMT</pubDate>
    </item>
    <item>
      <title>[研究]除了反向传播之外，还有其他使用梯度的作品吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akftvr/research_are_there_any_works_that_use_gradients/</link>
      <description><![CDATA[我的想法是这样的：我有一个网络，用于计算一批输入的梯度。但我没有将这些梯度用于反向传播，而是将它们用于其他用途。例如，我可以想象它们可以用作神经网络修剪的显着性分数。 我知道这是一个非常普遍的问题，但我很好奇除了梯度信息之外还可以做什么直接在权重上进行反向传播。   由   提交/u/daily_spiderman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akftvr/research_are_there_any_works_that_use_gradients/</guid>
      <pubDate>Tue, 06 Feb 2024 17:53:14 GMT</pubDate>
    </item>
    <item>
      <title>有人为有抱负的数据科学家推荐认证/课程吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akfrch/anybody_recommend_a_certificationcourse_for_an/</link>
      <description><![CDATA[嗨， 我已经拥有数据科学学士学位，所以我已经了解了很多概念和种类模特，但我现在正在找工作，并希望在我的背景中进一步添加更多专业学习/证书。我看到有一个张量流开发人员考试，但是有人推荐任何非常专业的考试吗？ 非常感谢！   由   提交 /u/卷积  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akfrch/anybody_recommend_a_certificationcourse_for_an/</guid>
      <pubDate>Tue, 06 Feb 2024 17:50:19 GMT</pubDate>
    </item>
    <item>
      <title>为我的最后一年项目寻求想法 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akevbs/seeking_ideas_for_my_final_year_project_p/</link>
      <description><![CDATA[目前正在为我的最后一年项目集思广益，并寻找灵感！ 主要对 ai ml 项目感兴趣 需要一个项目建议 我主修人工智能和机器学习。 我收集了一些想法，但由于复杂性而无法实现：- 汽车警察模拟交友应用手写识别和生成器   由   提交 /u/Raz--8   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akevbs/seeking_ideas_for_my_final_year_project_p/</guid>
      <pubDate>Tue, 06 Feb 2024 17:13:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 开放法学硕士的宪法人工智能配方</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akdv4i/p_constitutional_ai_recipe_with_open_llms/</link>
      <description><![CDATA[      大家好，我是来自 Hugging Face 👋 研究团队的 Lewis。 我们最近一直在为 LLM 修改各种对齐算法，并且很好奇 Anthropic 的 Constitutional AI 是否适用于 Mistral 7B 等开放模型。 tl;dr 它效果很好，我们在这里总结了我们的实验和配方！ 像其他作品一样在“自我完善”方面，宪法人工智能的工作原理是要求模型生成对一组提示的响应，然后检查这些响应与一组“宪法原则”的一致性程度。定义您希望模型具有的值类型。然后，您让模型修改其原始响应，这会生成偏好对（original_response、revised_response）的合成数据集，您可以将其用于 DPO / PPO 等。该过程的概述如下所示：  ​ 宪法人工智能配方 我们发现他们的论文最有趣的是定义自己的一套宪法原则的可能性。例如，我认为很多人都认为“作为人工智能语言模型我不能......” ChatGPT 中的拒绝非常烦人，因此我们调整了 Anthropic 构成以模仿 xAI 的 Grok 助手的风格，该助手具有相当好的护栏，但通常会以一些幽默来回应:) 比较两种拒绝风格（Anthropic 与 Grok），您可以在这里尝试演示：https://huggingface.co/spaces/HuggingFaceH4/constitutional -ai-demo   由   提交/u/lewtun  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akdv4i/p_constitutional_ai_recipe_with_open_llms/</guid>
      <pubDate>Tue, 06 Feb 2024 16:31:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 还有人因为 arxiv-vanity 的衰落而感到难过吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ak5u1q/d_anyone_else_sad_that_arxivvanity_is_down/</link>
      <description><![CDATA[我经常使用它在手机上阅读论文。当宣布 Arxiv 将支持 HTML 时，我非常高兴。然而，Arxiv 决定通过只为新论文提供 HTML 来处理这个问题，而不是旧论文，甚至新论文不知何故我也没有发现承诺的 HTML 版本可用。† 但是，不幸的是我发现 arxiv-vanity 现在在他们的首页上发布了一条消息：  arXiv 现在有了 HTML 论文，所以 arXiv Vanity 不需要再存在了。  这对我来说似乎有点为时过早。我想他们已经厌倦了主办它，这是可以理解的。但与此同时，如果没有尴尬的 PDF 缩放功能，我就无法再在手机上阅读论文了。在 Arxiv 开始更广泛地提供 HTML 之前，有人有更好的选择吗？ † 有人像我一样困惑吗？我查看了最近发表在 https://arxiv.org/list/cs.LG/recent 上的论文，并且我没有看到任何 HTML 链接，请单击“其他格式”只能看到 PDF 和源代码.. 编辑： 好吧，我不知道“5”技巧，请参阅评论。   由   提交 /u/radarsat1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ak5u1q/d_anyone_else_sad_that_arxivvanity_is_down/</guid>
      <pubDate>Tue, 06 Feb 2024 09:24:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] Mamba 能够进行情境学习吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ak3jpn/r_is_mamba_capable_of_incontext_learning/</link>
      <description><![CDATA[      链接： https://arxiv.org/abs/2402.03170 作者： Riccardo Grazzi*、Julien Siems*、Simon Schrodi ，Thomas Brox，Frank Hutter *同等贡献 摘要：这项工作提供了经验证据，证明 Mamba（一种新提出的选择性结构化状态空间模型）具有与 Transformer 类似的情境学习 (ICL) 功能。我们在涉及简单函数逼近以及更复杂的自然语言处理问题的任务上评估了 Mamba。我们的结果表明，在这两类任务中，Mamba 与 ICL 变压器模型的性能相匹配。进一步的分析表明，与 Transformer 一样，Mamba 似乎通过逐步优化其内部表示来解决 ICL 问题。总的来说，我们的工作表明，对于涉及较长输入序列的 ICL 任务，Mamba 可以成为 Transformer 的有效替代方案。 https://preview.redd.it/8gaky7z0vwgc1.png?width=1250&amp;format=png&amp;auto=webp&amp;s=57993bb782b547 a90776556364001b0f78a6d6a6   由   提交/u/Yossarian_1234   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ak3jpn/r_is_mamba_capable_of_incontext_learning/</guid>
      <pubDate>Tue, 06 Feb 2024 06:41:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 ML 出版中玩游戏或做科学研究。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajz2s3/d_play_the_game_or_do_the_science_in_ml_publishing/</link>
      <description><![CDATA[我看到很多大科技公司的愿景论文模板。方法总是一样的，对现有的工作做一个小的改变，称之为新颖，疯狂地运行超参数搜索，在 20 个数据集上显示结果。 （请注意，这些模型很可能无法零样本工作，它们显示的所有数字都针对该数据集进行了微调）。这些纸总是能进来的！  我觉得这为审稿人设定了非常不切实际的期望，并期望所有论文得到相同水平的实验结果。因此，学术实验室很难成为其中一些子领域的一部分。  只有我一个人有这样的感觉吗？ 当然也有例外，比如 DINO 或 SAM，它们真的很棒，我真的很欣赏。   由   提交/u/mildlyphd  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajz2s3/d_play_the_game_or_do_the_science_in_ml_publishing/</guid>
      <pubDate>Tue, 06 Feb 2024 02:33:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] Sparsetral - 由 Mistra 制作的参数高效稀疏 MoE</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajx04e/r_sparsetral_parameter_efficient_sparse_moe/</link>
      <description><![CDATA[引入 Sparsetral，这是一种由密集模型 Mistral 制成的稀疏 MoE 模型。有关该理论的更多信息，请参阅原始论文（Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks ）。这是本文附带的原始存储库（原始存储库），这是带有稀疏的分叉存储库（密斯特拉尔）集成（分叉存储库）。 我们还分叉了unsloth 和 vLLM 用于高效培训和推理。 vLLM 上的 Sparsetral 已经过测试，可在 4090、bf16 精度、4096 max_model_len 和 64 max_num_seq 上工作。 这里是 huggingface 上的模型。 - 请注意这是 v2。 v1 进行了训练（仅列出了 v2 的更改）（64 个适配器暗淡、32 个有效批量大小、slim-orca 数据集） 接下来是评估，然后是 DPO（或 CPO）+ 可能添加 激活信标后延长上下文长度 训练  8x A6000s unsloth 的分叉版本，用于高效训练 序列长度：4096 &lt; li&gt;有效批量大小：128 学习率：2e-5，线性衰减 历元：1 数据集：OpenHermes-2.5 基础模型使用 QLoRA（排名 64，alpha 16）进行训练，MoE 适配器/路由器使用 bf16 进行训练 专家数量：16 顶级 K：4  适配器尺寸：512  如果您需要任何帮助或有任何疑问，请随时发表评论！   由   提交 /u/kittenkrazy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajx04e/r_sparsetral_parameter_efficient_sparse_moe/</guid>
      <pubDate>Tue, 06 Feb 2024 00:55:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于 NanoDL 的思考，一个用于构建 Transformer 模型的新库。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajwzku/p_thoughts_on_nanodl_a_new_library_for_building/</link>
      <description><![CDATA[大家好，我刚刚发布了 NanoDL 的开发人员版本，这是一个用于在 Jax/Flax 生态系统中开发 Transformer 模型的库，希望得到您的反馈！&lt; /p&gt; NanoDL 的主要功能包括：  广泛的块和层，有助于从头开始创建定制的变压器模型。 广泛的模型选择，如 LlaMa2、Mistral、Mixtral、GPT3、GPT4（推断）、T5、Whisper、ViT、Mixers、GAT、CLIP 等，可满足各种任务和应用的需求。  数据并行分布式训练器，使开发人员可以在多个 GPU 或 TPU 上高效地训练大规模模型，而无需手动训练循环。 数据加载器，使 Jax/Flax 的数据处理过程更加简单和有效。 Flax/Jax 中未找到的自定义层，例如 RoPE、 GQA、MQA 和 SWin 的关注，允许更灵活的模型开发。 GPU/TPU 加速的经典 ML 模型，如 PCA、KMeans、回归、高斯过程等，类似到 GPU 上的 SciKit Learn。 模块化设计，使用户可以混合来自各种模型（例如 GPT、Mixtral 和 LlaMa2）的元素，以制作独特的混合变压器模型。 一系列用于 NLP 和计算机视觉任务的高级算法，例如高斯模糊、BLEU 等。 每个模型都包含在没有外部依赖项的单个文件，因此也可以轻松使用源代码。  查看存储库以获取示例用法和更多详细信息：https://github.com/HMUNACHI/nanodl  最终，我想要尽可能多的意见，下一步要考虑的问题，甚至贡献。 注意：我正在编写自述文件。目前，在源代码中，我在注释中的每个模型文件顶部包含了一个综合示例。   由   提交 /u/Henrie_the_dreamer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajwzku/p_thoughts_on_nanodl_a_new_library_for_building/</guid>
      <pubDate>Tue, 06 Feb 2024 00:54:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么不在神经模拟人工智能方向进行更多研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajrtug/d_why_isnt_more_research_being_done_in/</link>
      <description><![CDATA[尽管得到了 IBM 的支持，但与语言处理和其他“流行”技术相比，它似乎是一个相当死寂的主题。  如果我是对的，符号人工智能的最大缺陷之一是它依赖于人类输入规则，需要操作员执行手动工作才能使用。如果可以设计一个能够自动生成和更新现有规则的系统，那么它就有可能成为一个非常可靠的自主代理，能够进行基本的处理和探索。 最近这个方向，除了IBM还做了什么？如果不是，那么该技术目前不可行的关键问题是什么？   由   提交 /u/NightestOfTheOwls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajrtug/d_why_isnt_more_research_being_done_in/</guid>
      <pubDate>Mon, 05 Feb 2024 21:16:10 GMT</pubDate>
    </item>
    <item>
      <title>维苏威挑战奖已颁发！ [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ajqtfd/the_vesuvius_challenge_prize_has_been_awarded_n/</link>
      <description><![CDATA[https://scrollprize.org/grandprize 看起来这个项目已经死在水中了，读取的字母为零，直到非常偶然地发现了“裂开的泥土”。模式1由一个人使用自己的视觉系统盯着扫描进行模式识别。这导致其他人看到数据中的墨水，对其进行标记，训练机器学习模型，使用它们来查找更多字母等等。  1火山使墨水像干泥一样裂开   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ajqtfd/the_vesuvius_challenge_prize_has_been_awarded_n/</guid>
      <pubDate>Mon, 05 Feb 2024 20:35:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>