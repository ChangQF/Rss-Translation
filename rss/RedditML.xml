<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 01 Sep 2024 06:22:06 GMT</lastBuildDate>
    <item>
      <title>3D医学图像[博士]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f64wqa/3d_medical_images_d/</link>
      <description><![CDATA[我已经完成了一些 2D 图像分析和一些 2D 图像的计算机视觉任务，但我对 3D 医学图像还不熟悉，我正在使用 SimpleITK 来处理这些 3D 图像，我发现它有点难以理解（深度通道高度宽度等等）。有人可以给我推荐一些好的资源（可以是视频）吗，这样我就可以从基础开始理解 3D 医学图像？    提交人    /u/Odd_Breath_6685   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f64wqa/3d_medical_images_d/</guid>
      <pubDate>Sun, 01 Sep 2024 03:18:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f63rhf/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 01 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 识别和聚类 PvP 游戏中团队组成的对抗关系，以实现有效的平衡分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f63fxx/r_identifying_and_clustering_counter/</link>
      <description><![CDATA[论文： https://openreview.net/forum?id=2D36otXvBE 摘要：   如何量化游戏设置中的平衡？这个问题对于游戏设计师来说至关重要，尤其是在玩家对战 (PvP) 游戏中，分析预定义团队组成之间的强度关系（例如多人在线战斗竞技场 (MOBA) 游戏中的英雄组合或纸牌游戏中的卡组）对于增强游戏玩法和实现平衡至关重要。我们已经开发了两种先进的措施，它们超越了简单的胜率，可以量化零和竞争场景中的平衡。这些指标源自胜率估算，该估算采用 Bradley-Terry 模型的强度评级近似值和矢量量化的对抗关系近似值，从而显著降低了与传统胜率估算相关的计算复杂度。在这些模型的整个学习过程中，我们识别出有用的组合类别并确定它们的对抗关系，这与人类玩家的体验相一致，而不需要特定的游戏知识。我们的方法取决于一种简单的技术，即在极小的状态空间中使用确定性矢量量化过程来增强离散表示中的码本利用率。我们的框架已在热门在线游戏中得到验证，包括《帝国时代 II》、《炉石传说》、《荒野乱斗》和《英雄联盟》。在这些游戏中观察到的强度关系的准确性与传统的成对胜率预测相当，同时也提供了更易于管理的分析复杂性。最终，我们的研究结果有助于更深入地了解 PvP 游戏动态，并提出了一种显着改善游戏平衡评估和设计的方法。  我们对竞争场景的平衡措施的新研究。 虽然本文重点关注游戏内的平衡，但所讨论的原则和方法可能会扩展到其他领域，如体育运动，甚至像午餐一样日常的东西。    提交人    /u/Cold-Needleworker709   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f63fxx/r_identifying_and_clustering_counter/</guid>
      <pubDate>Sun, 01 Sep 2024 01:57:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 照片分类应用，根据提示制作相册</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5ynxw/d_photo_sorting_app_making_albums_guided_by/</link>
      <description><![CDATA[我最近结婚了（谢谢）。我收到了大约 800 张照片。这对我和家人来说都很棒。 但我想为不同的人群创建更小、更集中的相册。这个或那个朋友群体、同事、远房亲戚等。 我不想坐下来亲自制作每一张相册。我需要一些帮助。 我想要的是与一个可以帮助我实时策划这些相册的系统聊天。 我正在考虑的一些提示是：“从这张相册中为我来自北方的家人创建一个相册。放上他们所有的照片，还要添加一些家庭、仪式、派对的一般照片。”然后我可以给它反馈，比如：“添加几张我和我妻子一起跳舞的照片”。 有类似的东西吗？如果没有，它应该存在吗，我们应该创建它吗？ 或者我应该等待谷歌：https://blog.google/products/photos/ask-photos-google-io-2024/    提交人    /u/TheJulianInside   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5ynxw/d_photo_sorting_app_making_albums_guided_by/</guid>
      <pubDate>Sat, 31 Aug 2024 21:57:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人进入 ICMLA 2024 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5y90a/d_anyone_get_into_icmla_2024/</link>
      <description><![CDATA[今年有人的论文被 ICMLA 接受了吗？    提交人    /u/Hot-Acanthisitta-480   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5y90a/d_anyone_get_into_icmla_2024/</guid>
      <pubDate>Sat, 31 Aug 2024 21:37:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医疗 AI：顶级研究论文/模型🏅（2024 年 8 月 24 日至 8 月 31 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5xnnr/d_last_week_in_medical_ai_top_research/</link>
      <description><![CDATA[   本周热门论文（8 月 24 日至 31 日）  MultiMed：多模式医疗基准   本文介绍了 MultiMed，它是多种医疗模式和任务的基准。 MultiMed 包含 256 万个样本，涵盖十种医疗模式，例如医疗报告、病理学、基因组学和蛋白质数据。  用于生成胸部 X 光片图像的基础模型   本文介绍了一种潜在扩散模型，该模型在自然图像和文本描述符对上进行了预训练，以生成多样化且视觉上合理的合成胸部 X 光片图像，其外观可以通过自由形式的医学文本提示进行控制。  MEDSAGE：医学对话摘要   本文利用 LLM 的上下文学习能力，并指示它们根据一些可用的带有录音的医学对话示例生成类似 ASR 的错误。  用于放射学报告生成的知识图谱   本文介绍了一个名为 ReXKG 的系统，该系统从处理后的报告中提取结构化信息以构建全面的放射学知识图谱。  探索用于胸部 X 光的多模态 LLM   本文介绍了 M4CXR，这是一种旨在增强 CXR 解释的多模态 LLM。该模型根据一个数据集按照视觉指令进行训练，该数据集以对话格式集成了各种特定于任务的数据集。  改进临床记录生成   本文介绍了使用 LLM 对临床记录生成领域的三个关键贡献。首先，介绍全面的数据集 CliniKnote；其次，提出 K-SOAP（关键字、主观、客观、评估和计划）记录格式。 - 第三，开发一个自动管道，从医患对话中生成 K-SOAP 笔记   详细查看完整帖子：https://x.com/OpenlifesciAI/status/1829984701324448051  感谢您的阅读！如果您知道任何遗漏的有趣论文，请随时在评论中分享。如果您在医疗 AI 方面有见解或突破，并希望在下周的版本中分享，请通过 Twt/x 与我们联系：OpenlifesciAI    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5xnnr/d_last_week_in_medical_ai_top_research/</guid>
      <pubDate>Sat, 31 Aug 2024 21:10:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 致力于欧洲基础架构的研究实验室 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5wema/research_labs_working_on_foundation_architecture/</link>
      <description><![CDATA[  由    /u/Thick-brain-dude  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5wema/research_labs_working_on_foundation_architecture/</guid>
      <pubDate>Sat, 31 Aug 2024 20:15:21 GMT</pubDate>
    </item>
    <item>
      <title>[图片] AI 下 6x6 国际象棋，新算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5w23s/p_ai_plays_chess_6x6_new_algorithm/</link>
      <description><![CDATA[我创建了一个新的机器学习算法来玩棋盘游戏，并训练它下 6x6 象棋。在消费级 PC 上训练五天后，我无法赢过它一局。这是 GitHub 链接，其中包含实现、权重和交互式演示：https://github.com/omikad/probs 。请推荐其他值得尝试的棋盘游戏    提交人    /u/Putrid-Start-3520   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5w23s/p_ai_plays_chess_6x6_new_algorithm/</guid>
      <pubDate>Sat, 31 Aug 2024 19:59:56 GMT</pubDate>
    </item>
    <item>
      <title>[N] YOLO 愿景 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5twq4/n_yolo_vision_2024/</link>
      <description><![CDATA[        提交人    /u/Ultralytics_Burhan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5twq4/n_yolo_vision_2024/</guid>
      <pubDate>Sat, 31 Aug 2024 18:23:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 四年来我构建 MLOps 系统的经验教训</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5ojdu/d_what_ive_learned_building_mlops_systems_for/</link>
      <description><![CDATA[这是我四年来构建 MLOps 系统所学到的知识 http://mburaksayici.com/blog/2024/08/29/what-ive-learned-building-mlops-systems-for-four-years.html    提交人    /u/mburaksayici   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5ojdu/d_what_ive_learned_building_mlops_systems_for/</guid>
      <pubDate>Sat, 31 Aug 2024 14:27:27 GMT</pubDate>
    </item>
    <item>
      <title>[N][R] 发布 Re-LAION 5B：LAION-5B 的透明迭代，并附加安全修复</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5o0kj/nr_releasing_relaion_5b_transparent_iteration_on/</link>
      <description><![CDATA[        提交人    /u/Jamais_Vu206   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5o0kj/nr_releasing_relaion_5b_transparent_iteration_on/</guid>
      <pubDate>Sat, 31 Aug 2024 14:03:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] 受 Andrej Karpathy 启发，我制作了 NLP - Zero to Hero</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5ljxq/p_inspired_by_andrej_karpathy_i_made_nlp_zero_to/</link>
      <description><![CDATA[        由    /u/Particular_Tap_4002   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5ljxq/p_inspired_by_andrej_karpathy_i_made_nlp_zero_to/</guid>
      <pubDate>Sat, 31 Aug 2024 11:56:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 感知相似性用于衡量游戏中的决策风格和政策多样性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5hfzf/r_perceptual_similarity_for_measuring/</link>
      <description><![CDATA[论文： https://openreview.net/forum?id=30C9AWBW49 摘要：  定义和衡量决策风格（也称为游戏风格）在游戏中至关重要，因为这些风格反映了广泛的个性和多样性。然而，找到一种普遍适用的衡量这些风格的标准是一项挑战。基于第一个基于游戏屏幕和原始动作衡量游戏风格相似性的无监督指标，通过识别具有离散表示的可比状态来计算策略距离，我们引入了三种增强功能来提高准确性：具有不同状态粒度的多尺度分析、植根于心理学的感知内核以及利用交并法进行有效评估。这些创新不仅提高了测量精度，而且还提供了对人类对相似性的认知的洞察。在两款赛车游戏和七款 Atari 游戏中，我们的技术显著提高了零样本游戏风格分类的精度，在少于 512 个观察-动作对（不到这些游戏的一半）的情况下实现了超过 90% 的准确率。此外，我们的实验展示了离散游戏风格测量在益智和棋盘游戏中的潜力。我们还开发了一种使用这些指标评估决策多样性的算法。我们的研究结果改进了端到端游戏分析的测量和人工智能对不同游戏风格的演变。  您如何看待使用离散状态来比较风格的想法？    提交人    /u/Cold-Needleworker709   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5hfzf/r_perceptual_similarity_for_measuring/</guid>
      <pubDate>Sat, 31 Aug 2024 07:08:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能博士学位建议——需要顶尖大学吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5ackj/d_ai_phd_advice_top_university_required/</link>
      <description><![CDATA[大家好，我来征求一下建议。我是俄勒冈州立大学的 AI 博士生。我对使用 genAI 为使用 rag 管道的医生提供临床决策辅助特别感兴趣，这显然比我刚才解释的要复杂得多。 我的问题是：大多数情况下，我在类似的服务器上看到，你必须就读顶尖机构才能进入知名公司等。 因为我没有就读排名前 10 的大学，这会妨碍我找到工作的机会吗？根据 csrankings.org 的排名，俄勒冈州立大学排名第 53 位。 任何建议/评论都非常感谢    提交人    /u/frankies_wrld   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5ackj/d_ai_phd_advice_top_university_required/</guid>
      <pubDate>Sat, 31 Aug 2024 00:15:58 GMT</pubDate>
    </item>
    </channel>
</rss>