<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 29 Jan 2025 12:31:46 GMT</lastBuildDate>
    <item>
      <title>[D] 关于深度伪造检测软件的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icpwux/d_thoughts_on_deepfake_detection_software/</link>
      <description><![CDATA[我是一家初创公司的创始人，致力于开发一款深度伪造检测软件，该软件可以分析音频以获取人工智能生成的内容。目标是创建一种可靠的工具，保护个人和组织免受深度伪造的风险。我目前专注于企业，而不是消费者。 到目前为止，我计划将其部署为：  供开发人员集成的 API。 用于 Zoom、Webex 和 Teams 的扩展程序，用于在会议期间进行实时检测。 用于快速上传的 拖放功能。 用于基于 Web 的验证的 Chrome 扩展程序。  我很想听听您的想法  您认为还有哪些其他功能或平台可以使它更有用？ 最重要的是，您认为哪些类型的公司或行业最需要它？（例如媒体、执法、人力资源等）- 我已经对这些行业有了很好的想法，但我很想听听更多的意见和具体细节。     由   提交  /u/Fuzzy_Cream_5073   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icpwux/d_thoughts_on_deepfake_detection_software/</guid>
      <pubDate>Wed, 29 Jan 2025 09:18:25 GMT</pubDate>
    </item>
    <item>
      <title>NobodyWho 4.4！！Godot 开源 rust 插件！[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icpnf1/nobodywho_44_open_source_rust_plugin_for_godot_p/</link>
      <description><![CDATA[嘿，NobodyWho在这里。自从我们在 12 月初开放了 repo 源代码之后，我们在过去一个月里一直在努力提高插件的稳定性。 这意味着我们最近发布了 4.4，它有一些很棒的功能、更好的性能和 QOL 更改：  上下文转换，基本上允许您与角色进行无限次对话，而不管上下文长度如何 编辑器内文档 支持自定义聊天模板 我们的自述文件中有更好的示例 大量采样器变体和配置类型 大量错误修复  随着新 r1 模型的推出，我们还将添加一个小的 QOL 功能，它允许您隐藏回复中的思考标签。 如果您想了解更多信息，请查看我们的repo并给我们一颗星，那将非常非常感谢！ 此外，下周末我们将举办游戏 Jam，并提供奖品。因此，如果您还没有尝试过我们的插件，那么现在是时候尝试一下了！    提交人    /u/No_Abbreviations_532   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icpnf1/nobodywho_44_open_source_rust_plugin_for_godot_p/</guid>
      <pubDate>Wed, 29 Jan 2025 08:58:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发表论文 vs 获得博士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icpb9c/d_publications_vs_phd/</link>
      <description><![CDATA[这是一个相当简单的问题。 假设一个学历较低（学士或硕士）的人设法在三大会议（NeurIPS、ICML、ICLR）上发表了一些第一作者论文（让这个数字为 x）。 是否存在一个点，当 x 变得足够大时，博士学位就变得毫无意义，并且出于所有意图和目的，该人被视为合法的研究人员？ 换句话说，是否存在 x 的截止点，使得该个人的技能被视为与 R1 学校的 ML 平均博士学位相当？ 如果存在这样的截止点，它会是什么？    提交人    /u/throwaway-cs-grad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icpb9c/d_publications_vs_phd/</guid>
      <pubDate>Wed, 29 Jan 2025 08:31:15 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 哪种方法对 NER 更有效？训练 spaCy 模型还是使用 Meta 的 LLaMA？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icoi78/research_which_is_more_effective_for_ner_training/</link>
      <description><![CDATA[大家好， 我正在为一个涉及有关德国政治话语的 YouTube 评论的项目开发命名实体识别 (NER) 流程。我的目标是提取和标准化政客、政党和机构等实体。 其中的一个关键部分是将政客的名字转换成他们的缩写（例如，Ricarda Lang → RL，Friedrich Merz → FM），确保下游文本分析的一致性。 现在，我正在考虑两种方法：  为 NER 训练 spaCy 模型  我会在大约 1,000 个手动注释的示例上微调预训练的 spaCy 转换器模型。 我的数据集包括嘈杂的非正式文本（例如缩写、拼写错误和讽刺）。 我已经有一个结构化的地名词典，其中包含实体映射，以确保正确缩写。  使用 Meta 的 LLaMA API 进行零样本或小样本 NER  LLaMA 并非专门针对 NER 进行训练，但我可以使用结构化提示来提取命名实体并以缩写格式返回它们。 示例提示：&quot;从此文本中提取所有命名实体（人物、政党和机构）并以标准化缩写格式返回 JSON 格式。&quot; 这避免了训练开销，但我担心一致性和准确性。   主要问题：  有人成功使用 LLaMA（或其他 LLM API）进行NER吗？与微调模型相比，它的可靠性如何？ 对于混乱的社交媒体数据，微调 spaCy（即使使用小型数据集）是否会更加稳健？ 还有其他关于处理德语政治实体识别和转换的建议吗？  我很想听听您的想法，特别是如果您尝试过类似的方法！提前致谢！🚀    提交人    /u/Purple_Opposite3114   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icoi78/research_which_is_more_effective_for_ner_training/</guid>
      <pubDate>Wed, 29 Jan 2025 07:28:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态模型的可解释性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icnzzs/r_multimodal_models_interpretability/</link>
      <description><![CDATA[我正在深入研究多模态可解释性领域的进展。类似于显著性图的东西，但用于多模态输出或我可以研究的任何其他方法。是否有任何工具和方法已经为此开发，特别是针对多模态生成模型？渴望阅读有关相同内容的论文。     提交人    /u/theysaidno_1985   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icnzzs/r_multimodal_models_interpretability/</guid>
      <pubDate>Wed, 29 Jan 2025 06:52:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找有关领域适应方法的[现代]技巧，因为没有能力注释目标领域（图像数据）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icn2je/d_looking_for_modern_tips_on_domain_adaption/</link>
      <description><![CDATA[我基本上是想听听对于具有类似限制的人有用的方法，我可以生成任务的合成数据，但注释真实数据（需要许多传感器的回归任务）是一项非常昂贵的任务，并且由于设置条件甚至可能不切实际。 我正在考虑使用对抗训练作为架构的一部分，编码器有两个头，一个用于目标任务，一个用于对图像的域（合成域与目标域）进行分类，我们尝试最大化后者的损失，目标是让编码器提取用于计算目标的最小非不变特征。 但这感觉已经过时了，也许很挑剔，所以我想知道你们是否可以分享你们的经验。    提交人    /u/StillWastingAway   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icn2je/d_looking_for_modern_tips_on_domain_adaption/</guid>
      <pubDate>Wed, 29 Jan 2025 05:49:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 社区如何确保新发布的模型不会过度拟合流行基准中的问答？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iclxeo/d_how_does_the_llm_community_make_sure_that_a/</link>
      <description><![CDATA[正如标题所说，对于这种故意过度拟合的制衡措施是什么？ 更进一步说，如果基准集不断扩展，是否意味着新模型在扩展的基准上表现更好，而现有模型在训练时不可能看到这些新基准，这存在固有的偏见？    提交人    /u/Prize_Cup2626   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iclxeo/d_how_does_the_llm_community_make_sure_that_a/</guid>
      <pubDate>Wed, 29 Jan 2025 04:40:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数学奥林匹克的机器学习模型实用性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icl94m/d_practicality_of_machine_learning_model_for/</link>
      <description><![CDATA[在数学奥林匹克问题中，只有少数“技巧”/工具可用于解决每个问题。一些例子包括费马小定理、圆反转、鸽巢原理等。 解决这些问题归结为确定针对给定问题使用哪些工具。 因此，我有兴趣创建一个模型，该模型可以学习解决给定问题所需的工具（实际上不是编写完整的证明）。即，给定一个输入（奥林匹克问题），它会输出用于解决该问题的工具/技术，本质上是“解码”它。 我相信如果更多人做出贡献，这也可以扩展到数学的其他领域，并且如果规模足够大，有可能建立深远的横向联系。 我想知道建立这种模型的实用性和实际结果。我读过很多关于机器学习算法的理论（反向传播、多层感知器等），但没有太多的实践经验。 我想知道是否值得我花时间制作一个按照我指定的方式运行的模型，或者用我的时间做其他事情。有哪些限制，哪种学习最好？    提交人    /u/Electrical_Map_6169   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icl94m/d_practicality_of_machine_learning_model_for/</guid>
      <pubDate>Wed, 29 Jan 2025 04:02:21 GMT</pubDate>
    </item>
    <item>
      <title>检索增强生成中的规模与智能权衡 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ick63j/the_scale_vs_intelligence_tradeoff_in_retrieval/</link>
      <description><![CDATA[      检索增强生成 (RAG) 在过去一两年中发展迅猛，它为 LLM 提供了有关特定文档集或整个世界的知识。我个人已经广泛使用过大多数 RAG 类型，几乎所有 RAG 类型都基于两种基本算法（长上下文和嵌入）构建，但这两种算法存在一些基本限制。我计划就此写一篇更长、更全面的文章，但我想先在这里提出一些想法，以获得一些反馈，看看我是否遗漏了哪些观点。 长上下文模型（例如 Gemini）旨在处理单个上下文窗口内的大量文本，但面临着训练数据稀缺的关键瓶颈。随着上下文长度的增加，高质量训练数据的可用性迅速减少。这很重要，因为神经缩放定律到目前为止对 LLM 来说非常稳健。这里有一个很棒的视频解释它们。一个重要的含义是，如果你用完了人工生成的训练数据，那么无论你为这个问题投入多少其他资源或技巧，你的模型的推理能力都会受到瓶颈限制。这篇论文为这个想法提供了一些很好的实证支持。在所有“长上下文”模型的推理能力会随着上下文长度的增加而急剧下降。 我根据论文中的一个主要表格生成的图表，展示了随着上下文长度的增加，推理能力如何下降。 基于嵌入的 RAG 具有更好的可扩展性，但在高级推理任务中存在一些相当严重的问题。以下是这篇论文的一个小清单： https://preview.redd.it/huig4ipulufe1.png?width=967&amp;format=png&amp;auto=webp&amp;s=62743d60ba1c9162c9e1bf5ff6d05af20d577868 作者在论文开头也对核心原因进行了很好的阐述：   这种结构限制在处理需要深入理解和上下文解释的文档（例如复杂的书籍）时尤其成问题。通常，每个文档不仅会有一个重要的内部结构，而且跨文档还会有一个重要的元结构（想想引用其他科学论文特定部分的科学论文）。有一些技巧，例如使用知识图谱，可以尝试解决其中一些问题，但当基本方法在任何次要步骤开始之前就破坏了文档可能具有的任何结构时，它们只能做到这么多。  长上下文的可扩展性限制和嵌入的推理限制导致任何构建 RAG 系统的人都需要进行重要的权衡。长上下文模型在创造力和复杂推理方面表现出色，但由于训练数据限制，仅限于小型文档集。相反，基于嵌入的方法可以处理庞大的语料库，但功能更像是具有最低限度推理能力的增强型搜索引擎。对于许多任务来说，这种权衡是可以的，因为任务已经很好地适应了权衡的一方或另一方。然而，许多其他任务根本无法通过 SoTA RAG 方法轻松实现，因为它们既需要大量文档，又需要对这些文档进行高级推理。    提交人    /u/Daniel_Van_Zant   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ick63j/the_scale_vs_intelligence_tradeoff_in_retrieval/</guid>
      <pubDate>Wed, 29 Jan 2025 03:04:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepSeek 蒸馏和训练成本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icfbll/d_deepseek_distillation_and_training_costs/</link>
      <description><![CDATA[DeepSeek v3 训练中使用了蒸馏技术 (https://arxiv.org/html/2412.19437v1)。560 万美元仅仅是训练“学生”模型的成本吗？我并没有低估这一成就本身。但是，我想了解训练教师模型的成本是否已计入 560 万美元。 如果不考虑这些成本，虽然 DeepSeek 为降低成本和工程做出了重要贡献，但主流媒体散布的数字并不完全一致，需要进行纠正。或者也许我误解了整件事。 感谢您对此提供的任何见解。     由   提交  /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icfbll/d_deepseek_distillation_and_training_costs/</guid>
      <pubDate>Tue, 28 Jan 2025 23:13:12 GMT</pubDate>
    </item>
    <item>
      <title>[p] 让人们可以使用免费的 GPU - 希望得到 Beta 版反馈🦾</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icepak/p_giving_ppl_access_to_free_gpus_would_love_beta/</link>
      <description><![CDATA[大家好！我是一家 YC 投资公司的创始人，我们正努力让 ML 模型的训练变得非常便宜和简单。目前，我们正在运行一个免费测试版，希望得到您的一些反馈。 如果听起来很有趣，请随时在这里查看：https://github.com/tensorpool/tensorpool TLDR；免费计算😂    提交人    /u/joshkmartinez   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icepak/p_giving_ppl_access_to_free_gpus_would_love_beta/</guid>
      <pubDate>Tue, 28 Jan 2025 22:45:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你的秘诀是什么？你如何管理基础设施中的 GPU 容量？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icc8fb/d_whats_your_secret_sauce_how_do_you_manage_gpu/</link>
      <description><![CDATA[好的……我正在努力弄清楚资源管理的状态。我们这里有多少人有一堆闲置的 GPU 就放在那里，因为 Oracle 给了我们一笔交易，他们想阻止我们使用 AWS？或者这里的大多数人仍在使用 RunPod 或其他 neocloud/聚合器？据我所见，这些 neocloud 非常适合 MVP/POC 阶段开发，但不适用于生产。 但实际上，这里的每个人都只是购买额外的容量以避免延迟吗？随着推理工作负载开始扩展，是否有人开始对飞涨的计算成本感到恐慌？然后呢？    提交人    /u/PurpleReign007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icc8fb/d_whats_your_secret_sauce_how_do_you_manage_gpu/</guid>
      <pubDate>Tue, 28 Jan 2025 21:02:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有感觉自己在每个 scikit-learn 项目中都在重新发明轮子？让我们来谈谈如何让 ML 推荐做法不那么痛苦。🤔</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ic5e7f/d_ever_feel_like_youre_reinventing_the_wheel_with/</link>
      <description><![CDATA[嗨，各位数据科学家， 虽然 scikit-learn 功能强大，但我们经常会发现：  手动检查交叉验证错误 在 Copilot、StackOverflow 和文档之间来回切换只是为了遵循推荐的做法 重新设计需要为 DS 团队和利益相关者服务的验证流程 笔记本成为模型迭代的坟墓  我很好奇您如何在工作流程中应对这些挑战：  您在不同项目之间进行验证的方法是什么？是否有统一的方法，还是每个项目都有自己的验证风格？ 如何在不使事情过于复杂的情况下跟踪实验？ 您发现了哪些保持一致性的技巧？  我们（可能）已经构建了一个开源库（skore）来解决这些问题，但我希望先听听您的解决方案。哪些工作流程对您有用？什么仍然令人沮丧？  GitHub：github.com/probabl-ai/skore 文档：skore.probabl.ai     提交人    /u/positive-correlation   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ic5e7f/d_ever_feel_like_youre_reinventing_the_wheel_with/</guid>
      <pubDate>Tue, 28 Jan 2025 16:24:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>