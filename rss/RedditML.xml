<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 04 Nov 2024 12:33:46 GMT</lastBuildDate>
    <item>
      <title>[P] 数据量较少的文本分类：LLM 还是其他分类模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gj6iqf/p_text_classification_with_low_number_of_data_llm/</link>
      <description><![CDATA[我有一个项目，需要总结一些与某个主题相关的网页，并使用这些总结对上述主题进行分类。 在制作原型时，我使用 LLM 进行总结和分类任务，它们的准确率确实达到了 80% 左右（分类任务也不难）。为了提高性能，并且讨厌将 LLM 用于所有事情，我最初想要训练 2 个模型，一个用于总结，一个用于分类。 当我看到大多数可用的 summazier 并不比小型 LLM 轻那么多（而且没有多少支持我的语言）时，问题就出现了。添加另一个分类器，比如 bert 之类的，那么内存消耗的差异可能可以忽略不计。不过运行时间应该还是会更好。 另一个问题是，我的数据集只有大约 2000 个网页，大约 300 个主题和 70 个类别。许多类别有 0 或 1 个样本。有了这些数据，我认为对汇总器进行微调是可行的，尽管它可能不适用于分类器。获取更多数据并不是一个选择，因为我没有时间预算。尽管如此，我对应该分类到每个类别中的内容有详细的描述。 因此，我当前的解决方案是微调 LLM 以进行汇总和分类。缺点是 LLM 有时会给出无效的类别。 在 LLM 中添加分类头是一个好的解决方案吗？恐怕我没有足够的数据来训练那个分类头（实际上是一个分类矩阵）。或者有比这更好的方法吗？    提交人    /u/mtmttuan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gj6iqf/p_text_classification_with_low_number_of_data_llm/</guid>
      <pubDate>Mon, 04 Nov 2024 04:47:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何读取结构化数据和非结构化数据的组合并执行语义查询？例如，大量包含文本的 pdf 文档以及 pdf 中的列表/表格中出现的结构化数据或文本段落中提到的数字数据。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gj3bg8/d_how_to_read_and_perform_a_semantic_query_over/</link>
      <description><![CDATA[进一步举例，假设这些 PDF 是来自不同公司的财务报告，其中包含季度收入数据和其它数据。这个更广泛的问题有两个方面：查询和读取，如下所述 查询：因此我希望能够对所有 PDF 进行任意查询，例如“查找季度同比增长超过 10% 且提到新产品发布的公司”。这是一个简单的例子，但实际用例可以任意复杂，查询包含更多方面。 读取（输入）新报告：我还希望非技术用户可以在有新的 PDF 报告可用时将其放入，然后将其添加到查询数据库中，而无需技术人员手动参与预处理 您能否指导我如何解决这个问题，以及有哪些选项可以实现这样的事情？谢谢。    由   提交  /u/SpaceShip992   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gj3bg8/d_how_to_read_and_perform_a_semantic_query_over/</guid>
      <pubDate>Mon, 04 Nov 2024 01:49:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将 ImageNet 中的 100 万个文件导入 DVC、Git-LFS 和 Oxen.ai 进行基准测试，以进行开源数据集协作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gj0si8/p_benchmarking_1_million_files_from_imagenet_into/</link>
      <description><![CDATA[大家好！ 如果您还没有看过 Oxen 项目，我们一直在构建一个快速的开源非结构化数据版本控制工具和平台来托管数据（https://oxen.ai）。它是使用 git-lfs 或他们的数据集库将数据转储到 Hugging Face 上的替代方案，并且与他们的模型（如巧克力和花生酱）搭配使用 - Oxen 可用于迭代和编辑数据，而 Hugging Face 可用于公共模型。 我们受到了让大型机器学习数据集成为人们可以协作的活生生的资产而不是静态转储的想法的启发。最近，我们一直在努力优化 Oxen.ai 中的底层 Merkle 树和数据结构，并刚刚发布了 v0.19.4，它为内部 API 提供了大量性能升级和稳定性。 100 万个文件基准测试 为了进行全部测试，我们决定在经典 ImageNet 数据集中的 100 多万张图像上对该工具进行基准测试。 TLDR 是 Oxen.ai 比原始上传到 S3 更快，比 git-lfs 快 13 倍，比 DVC 快 5 倍。完整细分可在此处找到👇 https://docs.oxen.ai/features/performance 如果您身处 ML/AI 社区，或者只是数据爱好者，我们很乐意收到您对该工具和代码库的反馈。当涉及到不同的存储后端和与其他数据工具的集成时，我们希望社区做出一些贡献。    提交人    /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gj0si8/p_benchmarking_1_million_files_from_imagenet_into/</guid>
      <pubDate>Sun, 03 Nov 2024 23:43:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有/无 SMOTE 的逻辑回归比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gizg2u/d_comparison_of_logistic_regression_withwithout/</link>
      <description><![CDATA[      这让我在工作中抓狂不已。我一直在评估一个逻辑预测模型。该模型实施了 SMOTE 来将数据集平衡为 1:1 的比例（最初为期望结果的 7%）。我认为这是不必要的，因为改变决策阈值就足够了，并且可以避免不必要的数据插补。数据集中有超过 9,000 次期望事件的发生 - 这对于 MLE 估计来说已经足够了。我的同事不同意。  我在 R 中构建了一个闪亮的应用程序来比较两个模型的混淆矩阵以及一些指标。我欢迎社区对此比较提出一些意见。对我来说，非 smote 模型的表现同样出色，如果查看 Brier 分数或校准截距，甚至更好。你们觉得呢？    提交人    /u/Janky222   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gizg2u/d_comparison_of_logistic_regression_withwithout/</guid>
      <pubDate>Sun, 03 Nov 2024 22:42:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 特征选择 + 特征工程操作顺序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gizc5l/d_feature_selection_feature_eng_order_of/</link>
      <description><![CDATA[有人有使用特征工程进行特征选择的首选方法和操作顺序吗？例如，最佳做法是先删除不重要的特征，然后迭代设计新特征吗？    提交人    /u/Secret_Valuable_Yes   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gizc5l/d_feature_selection_feature_eng_order_of/</guid>
      <pubDate>Sun, 03 Nov 2024 22:37:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] 训练多个自动编码器可以减少损失但不会降低准确性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giz2wp/r_training_multiple_autoencoders_reduces_loss_but/</link>
      <description><![CDATA[您好， 我正在训练两个独立的自动编码器来聚类数据。网络将输入传递给两个自动编码器，计算两个自动编码器 (AE) 的重建误差并选择最佳的一个。这意味着只有一个 AE 的重建会导致损失，因此每个输入只有一个获得梯度更新。 损失减少，但准确度只是波动。此外，两个自动编码器都被使用，但最终模型对几乎所有输入都使用相同的自动编码器。有什么见解吗？ 目标是让每个 AE 学习重建相邻或属于同一群集的数据点。我见过论文做同样的事情，但他们只是预先训练他们的网络来解决这个问题，而从不讨论为什么会发生这种情况。 谢谢    由    /u/Grand_Comparison2081  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giz2wp/r_training_multiple_autoencoders_reduces_loss_but/</guid>
      <pubDate>Sun, 03 Nov 2024 22:26:03 GMT</pubDate>
    </item>
    <item>
      <title>当前 LLM 的视频输入 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giylel/video_input_for_the_current_llms_p/</link>
      <description><![CDATA[大家好， 我很高兴与大家分享我一直在研究的 OpenSceneSense 项目。这是一个 Python 包，旨在将视频内容与大型语言模型 (LLM)（如 OpenAI 的 Vision 模型和 OpenRouter）连接起来，从而开辟理解、分析和从视频数据中获取见解的新方法。 为什么选择 OpenSceneSense？ 大多数 LLM 在文本方面表现出色，但并非设计用于直接处理视频。OpenSceneSense 改变了这一点。它使用逐帧分析、音频转录和场景检测将视频数据转换为 LLM 可以处理的内容。想象一下，使用提示来获取每个场景中发生的事情的详细描述，或者自动创建将视频和音频联系在一起的叙述。 潜在用例： - 数据集创建：如果您从事计算机视觉或机器学习工作，OpenSceneSense 可以从视频中创建注释丰富的数据集，为 LLM 提供有关视觉事件、对象交互甚至场景间情绪变化的详细背景信息。 - 内容审核：OpenSceneSense 可以为内容审核带来更多背景信息。与可能仅检测关键字或简单视觉效果的传统审核方法不同，此工具可以解释整个场景，结合视觉和音频提示。它可以帮助区分真正有问题的内容和可能被标记的无害材料。 而且我还在开发一个与 Ollama 兼容的版本，这样你就可以在不依赖云的情况下在本地运行它，这对任何关心隐私或延迟的人来说都很有用。 要深入研究，您需要 Python 3.10+、FFmpeg 和几个 API 密钥（OpenAI 或 OpenRouter）。使用“pip install openscenesense”安装它，一切就绪。从那里，您可以轻松开始分析您的视频并尝试不同的提示来自定义您想要提取的内容。 我很乐意听取任何从事视频技术、数据集创建或审核工作的人的反馈。查看代码，试用一下，让我们看看我们可以将 OpenSceneSense 带到哪里！ https://github.com/ymrohit/openscenesense    提交人    /u/rohit3627   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giylel/video_input_for_the_current_llms_p/</guid>
      <pubDate>Sun, 03 Nov 2024 22:04:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 傅里叶权重神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giwdum/d_fourier_weights_neural_networks/</link>
      <description><![CDATA[亲爱的 ML 社区， 我想分享一个关于使用傅立叶系数来参数化神经网络权重的讨论想法。通常在 MLP 中，权重仅在一个方向上定义，而在另一个方向上未定义，这使其处于开放状态：我们可以将权重定义为对称的：w(r,s) = w(s,r)，我们可以使用双变量对称函数的傅立叶系数通过反向传播和梯度下降来计算权重。（我应该提到，我目前正在积极寻找机会将我的机器学习知识带到德国法兰克福附近的项目中。） 编辑：也许我的措辞不太正确。让我们同意，在大多数情况下，具有可逆激活函数的 MLP 满足对称性假设。我想讨论的想法是使用傅里叶系数来（重新）构建权重 w(r,s) = w(s,r)。为了使这个想法有意义，FWNN 不会像通常的 MLP/ANN 那样学习权重，而是学习傅里叶级数的系数（至少是其中一些）。通过调整学习的系数数量，FWNN 可以调整其学习能力。请注意，通过函数 w(r,s) 的对称性，我们得到诸如 sum_{j] c_j*cos(j * (r+s) ) 之类的项，其中 j 的范围是某个预定义的整数范围 [-R,R]。理论上，这个 R 应该是无穷大，因此 Z = [-inf, +inf] 是整数。还要注意，网络学习的参数 c_j 数量为 2*R+1，乍一看与神经元数量 N 无关。因此，具有 N 个神经元的传统神经网络理论上必须学习 O(N^2) 个权重，但使用傅里叶变换，我们可以将这个参数数量减少到 2*R+1。当然，R = N^2 是可能的，但我可以想象，当 2*R+1 &lt;&lt; N^2 时会出现问题。我希望这能澄清这个想法。 代码：https://github.com/githubuser1983/fourier_weighted_neural_network/blob/main/fourier_weighted_neural_network.py 方法说明：https://www.academia.edu/125262107/Fourier_Weighted_Neural_Networks_Enhancing_Efficiency_and_Performance   由    /u/musescore1983  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giwdum/d_fourier_weights_neural_networks/</guid>
      <pubDate>Sun, 03 Nov 2024 20:27:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAAI 2025 第二阶段评审</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giqc9n/d_aaai_2025_phase_2_reviews/</link>
      <description><![CDATA[评论将很快发布。这是一个讨论/吐槽的帖子。请在评论中保持礼貌。    由   提交  /u/quasi-literate   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giqc9n/d_aaai_2025_phase_2_reviews/</guid>
      <pubDate>Sun, 03 Nov 2024 16:09:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Nov 2024 16:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 2024 年，你的神经网络训练秘诀是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giovxi/r_what_is_your_recipe_for_training_neural/</link>
      <description><![CDATA[您可能已经知道 Karpathy 2019 中的神经网络训练秘诀圣经 虽然大多数建议仍然有效，但深度学习模型/方法的格局自那时起发生了很大变化。Karpathy 的建议在监督学习环境中效果很好，他确实提到了这一点：  坚持监督学习。不要对无监督预训练过度兴奋。与 2008 年那篇博客文章所说的不同，据我所知，没有任何版本在现代计算机视觉方面报告了强劲的结果（尽管如今 NLP 在 BERT 和朋友的帮助下似乎表现不错，这很可能是由于文本的更刻意性质和更高的信噪比）。  我最近一直在训练一些图像扩散模型，我发现在无监督环境下做出数据驱动的决策更加困难。指标不太可靠，有时我会训练损失更好的模型，但当我查看样本时，它们看起来更糟 你知道 2024 年训练神经网络的更多现代方法吗？（不仅仅是 LLM）    提交人    /u/Even_Information4853   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giovxi/r_what_is_your_recipe_for_training_neural/</guid>
      <pubDate>Sun, 03 Nov 2024 15:05:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] 理解多模态法学硕士：主要技术和最新模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gio7ap/p_understanding_multimodal_llms_the_main/</link>
      <description><![CDATA[  由    /u/seraschka  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gio7ap/p_understanding_multimodal_llms_the_main/</guid>
      <pubDate>Sun, 03 Nov 2024 14:34:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] X 列出要关注的 ML 研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ginx35/d_x_list_to_follow_for_ml_research/</link>
      <description><![CDATA[大家好，我刚刚进入 Ml（已经在这个领域大约 6 个月了），我想以更好的方式跟上它，但是 X 上有太多东西需要关注，我感到很困惑，有什么列表可以推荐吗？    提交人    /u/jinstronda   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ginx35/d_x_list_to_follow_for_ml_research/</guid>
      <pubDate>Sun, 03 Nov 2024 14:21:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有 Science Twitter/X 的替代品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gikys5/d_is_there_an_alternative_to_science_twitterx/</link>
      <description><![CDATA[大家好， 我一直在想，Twitter/X 上是否有科学界的替代方案，尤其是在 DS/ML 领域。在 COVID 之前和期间，我真的很喜欢那个社区，但在 Elon 上任后不久，我就离开了 Twitter，因为当时这个平台已经很有毒了，而且从那以后变得更糟了。  我知道 LinkedIn 上有一个活跃的社区，有时还不错，但大多都是试图听起来/看起来聪明的有影响力的人，还有人大肆宣传 LLM 的每件小事。我知道从那时起，其他人也离开了 Twitter 上的科学界，因此想知道过去几年是否出现了替代方案。 附言：我也会在 DS 社区中发布此消息。    提交人    /u/H4RZ3RK4S3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gikys5/d_is_there_an_alternative_to_science_twitterx/</guid>
      <pubDate>Sun, 03 Nov 2024 11:41:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>