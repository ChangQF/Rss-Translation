<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 05 Dec 2023 06:17:59 GMT</lastBuildDate>
    <item>
      <title>[D] 构建机器学习模型以检测 Zeek 或 PCAP 的 C2 活动的技巧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18b5m4y/d_tips_on_building_a_machine_learning_model_that/</link>
      <description><![CDATA[大家好。我正在开展一个项目，尝试构建某种类型的 ML 模型，用于检测 Zeek 或/和 PCAP 中的 C2（命令和控制）活动类型。欢迎任何想法或建议。   由   提交 /u/shimbapen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18b5m4y/d_tips_on_building_a_machine_learning_model_that/</guid>
      <pubDate>Tue, 05 Dec 2023 06:16:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 仍在进行研究的行业实验室</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18b4xju/d_industry_labs_that_still_do_research/</link>
      <description><![CDATA[我想知道是否还有研究实验室仍在进行探索性研究。我观察到的大多数地方都在朝着更少的探索性工作和更多的具体议程研究方向发展。我认为这阻碍了有趣/探索性的研究，而这通常会带来新的发现。我在攻读博士学位期间进行了此类研究，现在我被困在一个大型研发实验室中，该实验室的任务是研究特定的事情。您会推荐我看哪些实验室，并且仍然可以在某种程度上进行探索？   由   提交/u/oa97z  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18b4xju/d_industry_labs_that_still_do_research/</guid>
      <pubDate>Tue, 05 Dec 2023 05:35:54 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 教科书的文本到语音生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18b3g3g/discussion_text_to_voice_generation_for_textbooks/</link>
      <description><![CDATA[我正在听 lex 播客，了解我研究的一些内容，想问一下，是否有任何听起来足够自然的本地文本到语音模型？ 我非常想用它把一本书的文本部分变成音频，这样我就可以在阅读时收听它。我使用 edge 的 tts  进行语音，将一段文字放到剪贴板和 edge-tts 中以收听文本，但它造成两个问题：1.需要网络连接并且打开书2.只能逐段进行，容易出错，或者有时使用太多之后无法转换全文。 &lt; p&gt;这个想法是将一本书的章节转换成音频文件并传输，以便我可以在手机上即时收听。 离线模型的状态如何？他们有能力输出良好的声音（或者甚至能够从他们的讲座中提供导师的声音并对其进行训练）？   由   提交/u/sweetchocolotepie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18b3g3g/discussion_text_to_voice_generation_for_textbooks/</guid>
      <pubDate>Tue, 05 Dec 2023 04:12:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 神经马尔可夫控制的 SDE：连续时间数据的随机优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18b3035/d_neural_markov_controlled_sde_stochastic/</link>
      <description><![CDATA[大家好， 目前我正在研究神经 SDE 的随机最优控制。我对这篇论文很感兴趣，正在尝试实现论文中的算法。 我是神经微分方程领域的新手，我发现实现论文中提到的算法很困难。如果有人读过这篇论文或者有在 SDE 中进行随机控制编程的经验，请给我一些参考。 谢谢！   由   提交/u/luciffer_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18b3035/d_neural_markov_controlled_sde_stochastic/</guid>
      <pubDate>Tue, 05 Dec 2023 03:49:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于配置的生成式人工智能开发</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18b2ufb/d_configbased_development_for_generative_ai/</link>
      <description><![CDATA[我的团队最近启动了我们的第一个开源项目 AIConfig，这是一种 JSON 序列化格式，用于存储提示、模型参数和设置。我们对基于配置的生成式人工智能开发方法采取了立场，原因如下。   关注点分离：您可以与应用程序代码分开迭代提示和模型，不同的人可以负责它们，从而使整体开发更具协作性。  治理：作为源代码控制的工件，aiconfig 可用于应用程序的生成 AI 组件的再现性和来源。 更快的迭代：我们提供了一个类似笔记本的游乐场来编辑您的提示和模型设置。您可以从这个 Playground 下载并上传您的 AIConfig。与代码相比，在 UI 中编写提示和提示链要更容易、更快捷。  Github：https://github.com/lastmile-ai/aiconfig 很想听到关于这种生成式 AI 开发方法的反馈/想法。 &lt; !-- SC_ON --&gt;  由   提交 /u/InevitableSky2801   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18b2ufb/d_configbased_development_for_generative_ai/</guid>
      <pubDate>Tue, 05 Dec 2023 03:41:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于时间序列预测的 Transformer</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ax51t/d_transformers_for_time_series_forecasting/</link>
      <description><![CDATA[有一些新兴的 Transformer 模型专为预测时间序列值而设计，例如 Informer 和 Temporal Fusion Transformer。您对这个话题有何看法？你认为他们能忍受 RNN 吗？   由   提交 /u/MrGolran   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ax51t/d_transformers_for_time_series_forecasting/</guid>
      <pubDate>Mon, 04 Dec 2023 23:07:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] XGBoost特征选择</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18atkzs/d_xgboost_feature_selection/</link>
      <description><![CDATA[当前对深度和学习率进行有根据的猜测，添加几个白噪声变量，并删除特征重要性图中较低的所有变量。 有更好的方法吗？ 我看到其他人提到在删除白噪声以下的特征之前将树深度减小到 1。另一种方法是使用 shap 值并查看 pdp 图。   由   提交/u/fuzzy_plums  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18atkzs/d_xgboost_feature_selection/</guid>
      <pubDate>Mon, 04 Dec 2023 20:33:50 GMT</pubDate>
    </item>
    <item>
      <title>Mamba：具有选择性状态空间的线性时间序列建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18aq0k5/mamba_lineartime_sequence_modeling_with_selective/</link>
      <description><![CDATA[       由   提交/u/Jean-Porte  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18aq0k5/mamba_lineartime_sequence_modeling_with_selective/</guid>
      <pubDate>Mon, 04 Dec 2023 18:02:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪种架构可以替代变压器？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18apkw6/d_which_architecture_could_substitute_the/</link>
      <description><![CDATA[我最近读到了这个观点，讨论变压器可以被更换。  https://towardsdatascience.com/a-requiem-for-the-transformer -297e6f14e189 总的来说，过去几个月发表的文章显示了 Transformer 的局限性： https://arxiv.org/abs/2203.15556 https:/ /arxiv.org/abs/2304.15004  在计算机视觉中，具有相同预算的ConvNet似乎具有相似的性能： https://arxiv.org/abs/2310.19909  https://arxiv.org/abs/2310.16764  DeepMind 表明 Transformer 无法泛化到训练集分布之外： https://arxiv.org/abs/2311.00871 液体神经网络、鬣狗、尖峰神经网络等模型显示出活跃的搜索对于新架构： https://arxiv.org/pdf/2006.04439.pdf&lt; /p&gt; https://www.together.ai/blog/monarch-mixer  并不是说 Transformer 很快就会被取代，但我现在想知道下一个主导架构可能是什么？  所提出的架构似乎都不比变压器具有竞争优势   由   提交/u/NoIdeaAbaout   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18apkw6/d_which_architecture_could_substitute_the/</guid>
      <pubDate>Mon, 04 Dec 2023 17:44:29 GMT</pubDate>
    </item>
    <item>
      <title>从头开始学习 ML 概念的新资源（唯一要求是 Python）[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18apjbp/new_resource_for_learning_ml_concepts_from/</link>
      <description><![CDATA[结构化学习资源最适合我们大多数人，您可能对 ChatGPT 在最低级别的实际工作原理以及如何对其进行编码感兴趣 不幸的是，许多人工智能/机器学习资源包含太多数学知识，要么令人困惑，要么只是拖着乏味的数学证明。我创建了 YouTube 频道 GPT 和 Chill，专注于您在 ML 副项目或进入 ML 工程时实际需要了解的内容. 到目前为止，我们已经从头开始介绍了许多 ML 和神经网络概念，播放列表/系列中的下一个视频将介绍自注意力和从头开始编码 GPT。如果你对此感兴趣，我建议你先浏览一下现有的播放列表！ 你所需要的只是 Python 和基本的微积分知识（x^2 的导数是什么以及类似的东西）  p&gt; 我还将制作一个类似的播放列表/系列，介绍自动驾驶模型的工作原理和Deepfakes 是如何从头开始用代码生成的。我还将添加一个平台，您可以在其中尝试编写 ML 概念并针对基本测试用例进行运行。 如果您还想观看视频，请留下评论！希望回馈这个社区，因为它在我进入数据科学的过程中教会了我无数的教训。   由   提交 /u/GPTandChill   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18apjbp/new_resource_for_learning_ml_concepts_from/</guid>
      <pubDate>Mon, 04 Dec 2023 17:42:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 损失权重 - 理论保证？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ap1lk/r_loss_weighting_theoretical_guarantees/</link>
      <description><![CDATA[      对于由加权损失组成的损失函数的模型训练： &lt; p&gt;​ https ://preview.redd.it/j04h4v0sab4c1.png?width=153&amp;format=png&amp;auto=webp&amp;s=21677d2520375d500b904bb3ae30d403c9941d7c 我想知道关于模型可以说些什么基于损失 ℒ_i 的 ℒ 损失收敛，或者可能是分别收敛于 ℒ_i 损失的模型。例如，如果我对模型 m_i 有一些收敛到损失 ℒ_i 的保证/属性，如果其中一些保证属性转换到收敛于 ℒ 的模型 m。 非常感谢有关此问题的理论论文的链接，甚至是帮助我搜索此类论文的关键字。 &lt; p&gt;提前非常感谢您的帮助/指导！   由   提交 /u/progmayo   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ap1lk/r_loss_weighting_theoretical_guarantees/</guid>
      <pubDate>Mon, 04 Dec 2023 17:20:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024年机器学习研究热点是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18am0tx/d_whats_hot_for_machine_learning_research_in_2024/</link>
      <description><![CDATA[ML 中或与 ML 相关的哪些子领域/方法、应用领域预计将在 2024 年获得广泛关注（双关语无意）？&lt; /p&gt; PS：请不要回避提出您可能认为或知道的任何可能成为机器学习研究热门主题的内容，很可能您所知道的内容对于我们这里的许多人来说可能是未知的:)   由   提交 /u/ureepamuree   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18am0tx/d_whats_hot_for_machine_learning_research_in_2024/</guid>
      <pubDate>Mon, 04 Dec 2023 15:01:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] 即将推出的无隐藏状态的反应式 Python+SQL 笔记本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18akbc6/p_an_up_and_coming_reactive_pythonsql_notebook/</link>
      <description><![CDATA[    &lt; /a&gt;  该项目仍处于早期阶段，因此请告诉我们您有什么反馈！以下是快速预览： 零真演示 如果您想查看我们的 github：https://github.com/Zero-True/zero-true   由   提交/u/zero-true  /u/zero-true reddit.com/r/MachineLearning/comments/18akbc6/p_an_up_and_coming_reactive_pythonsql_notebook/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18akbc6/p_an_up_and_coming_reactive_pythonsql_notebook/</guid>
      <pubDate>Mon, 04 Dec 2023 13:34:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] 没有 Autograd 的教育变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18aaxfj/p_educational_transformer_without_autograd/</link>
      <description><![CDATA[我学习 NLP 一段时间了，总是发现很难找到具有显式前向和反向传播的 Transformer 的完整实现。这个项目是我在学习如何更好地理解 Transformers 中的优化的同时构建它的尝试。 它有尽可能详细的文档记录，并且可以通过编辑config.py 文件并运行 run.py 脚本。获取代码： git clone https://github.com/eduardoleao052/Transformer-from-scratch.git  我成功生成了一些在儒勒凡尔纳和莎士比亚的作品上训练这个模型的文本非常好。希望您喜欢！ GitHub 存储库此处！   由   提交 /u/suspicious_beam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18aaxfj/p_educational_transformer_without_autograd/</guid>
      <pubDate>Mon, 04 Dec 2023 03:12:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>