<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 30 Jan 2025 21:14:48 GMT</lastBuildDate>
    <item>
      <title>[D] 如何填补方差较大的时间序列中缺失的数据空白？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idw5hl/d_how_to_fill_missing_data_gaps_in_a_time_series/</link>
      <description><![CDATA[      我们如何填补这种方差较大的时间序列中的缺失数据空白？  https://preview.redd.it/s5cl4jl2u6ge1.png?width=507&amp;format=png&amp;auto=webp&amp;s=22f8eafbd905b3f9eea15b03e01acdafe217ac74    提交人    /u/the_professor000   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idw5hl/d_how_to_fill_missing_data_gaps_in_a_time_series/</guid>
      <pubDate>Thu, 30 Jan 2025 20:07:51 GMT</pubDate>
    </item>
    <item>
      <title>[R][P] R 中 LongituRF 中的 MERF 分析可以处理分类变量吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idvufh/rp_can_the_merf_analysis_in_longiturf_in_r_handle/</link>
      <description><![CDATA[当我尝试在我的 X 矩阵和/或我的 Z 矩阵中使用分类变量（因子或字符）时，我收到有关我的“非数字矩阵范围”的错误。MERF 分析是否可以不处理分类变量，或者我是否需要以非常特定的方式格式化它们？    提交人    /u/eekthemoteeks   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idvufh/rp_can_the_merf_analysis_in_longiturf_in_r_handle/</guid>
      <pubDate>Thu, 30 Jan 2025 19:55:29 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我创建了一个基准，以帮助您找到最佳的背景去除 API，实现完美的图像编辑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idv9w6/p_i_created_a_benchmark_to_help_you_find_the_best/</link>
      <description><![CDATA[我为什么构建它 曾经尝试过背景去除 API 并想过，“这有效......直到它无效”？头发、毛发和透明度是最艰巨的挑战，大多数 API 都难以应对。我想要一种方法来对它们进行正面比较，所以我构建了一个基准和交互式评估平台。 它的作用  在具有挑战性的图像上并排比较顶级背景去除 API 交互式 Gradio 界面可轻松探索结果 自己运行 API 并查看它们如何处理棘手的细节  试试看 基准测试和演示： Hugging Face Space 代码： Hugging Face 寻求反馈  准确性 – 哪种 API 能最好地处理头发、毛发和透明度？有什么突出的成功或失败吗？ 一致性 – 结果在不同图像上是否保持稳定？ 评估方法 – 我的比较方法是否可靠，或者您有更好的想法？ Gradio 界面 – 它直观吗？您有什么改进建议吗？  帮助改进基准！ 知道应该测试的背景去除 API 吗？有破坏大多数模型的具有挑战性的图像吗？分享它们。让我们将其作为该领域 ML 工程师的首选基准。 期待您的想法！    提交人    /u/tbdb92   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idv9w6/p_i_created_a_benchmark_to_help_you_find_the_best/</guid>
      <pubDate>Thu, 30 Jan 2025 19:31:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自动发现产品评论中的主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idurak/p_autodiscover_themes_in_product_reviews/</link>
      <description><![CDATA[TLDR： 您可以使用 LLM 高效地识别数据集中的关键主题，捕捉一般和细微的主题，例如“运输”、“电池”和“相机问题”，否则这些主题可能很难发现。此外，您可以根据这些主题对评论进行分类，以使用最少的代码识别趋势。 不久前，我尝试使用 LLM 执行经典的机器学习任务 - 如果您已经拥有足够的数据和专门的模型，这通常并不理想。但是，如果您缺少数据或需要灵活的方法，那么利用 LLM 可以成为救星，尤其是对于产品评论中的快速标记或主题发现。 示例场景 下面是一个 Python 脚本，展示了两个示例数据集的标签发现（聚合数据）和后续分类。一个数据集是纯文本评论，另一个数据集包含用户的 base64 编码图像，用于简单演示。将库调用替换为您自己的库调用或利用开源库调用：  步骤 1：发现标签   将评论合并为一个请求。  要求 LLM 提出重复的标签或主题。  步骤 2：对评论进行分类   使用发现的标签对数据进行分类。  如果您有大量或实时输入，请执行并发。   代码片段 !/usr/bin/env python3 import os from openai import OpenAI from flashlearn.skills.discover_labels import DiscoverLabelsSkill from flashlearn.skills.classification import ClassificationSkill def main(): os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;YOUR_API_KEY&quot; # 示例数据 (文本评论) text_reviews = [ {&quot;comment&quot;: &quot;电池寿命超出预期，但相机一般。&quot;}, {&quot;comment&quot;: &quot;到货晚了，屏幕破裂了，但客户支持很有帮助。&quot; ] # 示例数据 (图像 + 简短文本) # 这里，&quot;image_base64&quot;字段模拟编码图像 image_reviews = [ {&quot;image&quot;: &quot;ENCODED_ISSUE_IMAGE&quot;, &quot;comment&quot;: &quot;WHZ BOTHER WITH IT?&quot;}, {&quot;image&quot;: &quot;ENCODED_ISSUE_IMAGE&quot;, &quot;comment&quot;: &quot;This feature is amazing!!你应该收取更多费用！&quot; ] # 1) 标签发现（一次聚合整个数据集） # discover_skill = DiscoverLabelsSkill(model_name=&quot;gpt-4o-mini&quot;, client=OpenAI()) # column_modalities={&quot;image_base64&quot;:&quot;image_base64&quot;, &quot;comment&quot;: &quot;text&quot; # task_discover = discover_skill.create_tasks(text_reviews + image_reviews) # discover_labels = discover_skill.run_tasks_in_parallel(tasks_discover)[&#39;0&#39;][&#39;labels&#39;] # print(&quot;Discovered labels:&quot;, discover_labels) # 2)使用发现的标签进行分类 # classify_skill = ClassificationSkill(model_name=&quot;gpt-4o-mini&quot;, client=OpenAI(), categories=discovered_labels) # task_classify = classify_skill.create_tasks(text_reviews + image_reviews) # final_results = classify_skill.run_tasks_in_parallel(tasks_classify) # print(&quot;Classification results:&quot;, final_results) if __name__ == &quot;__main__&quot;: main() 使用说明 1.安装 如果您想要一种快速的管道方法，您可以像这样设置一个库：pip install flashlearn 然后导入相关的“技能”或类以进行分类、标签发现、并发等。 2. 何时使用 LLM 方法  如果您有最少（或没有）标记数据，这很有用。 快速原型设计以发现新主题。 轻松实现大规模并发（数百或数千条评论）。  如果您需要快速实验或只有小型数据集，LLM 聚合器管道可以帮助您发现核心主题并有效地对评论进行分类。请随意尝试上面的最小示例。完整代码：github    提交人    /u/No_Information6299   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idurak/p_autodiscover_themes_in_product_reviews/</guid>
      <pubDate>Thu, 30 Jan 2025 19:10:08 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 研究科学家职位面试技巧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idtkul/discussion_research_scientist_position_interview/</link>
      <description><![CDATA[嗨，对于那些正在行业中寻找研究科学家职位的人来说，你是如何准备面试的，你经常被问到什么问题？ 我即将获得博士学位（强化学习），我正在寻找关于如何准备面试的建议:)    提交人    /u/hmi2015   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idtkul/discussion_research_scientist_position_interview/</guid>
      <pubDate>Thu, 30 Jan 2025 18:21:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你们如何处理需要领域适应的任务？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idswu9/d_how_do_you_guys_deal_with_tasks_that_require/</link>
      <description><![CDATA[我想听听大家在使用领域自适应方法时觉得什么有用，它不一定与我的问题相关，但我有一些任务在目标领域中实际上不可能进行注释，但可以为（模拟的）合成数据创建注释，即使没有这种方法也能取得一些成功，但还不足以止步于此。 任何相关的东西都很高兴听到！    提交人    /u/StillWastingAway   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idswu9/d_how_do_you_guys_deal_with_tasks_that_require/</guid>
      <pubDate>Thu, 30 Jan 2025 17:53:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] [N] 开源 8B 评估模型在 11 个基准测试中击败 GPT-4o mini 并位居小型评委之首</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idpqas/r_n_opensource_8b_evaluation_model_beats_gpt4o/</link>
      <description><![CDATA[  由    /u/fortunemaple  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idpqas/r_n_opensource_8b_evaluation_model_beats_gpt4o/</guid>
      <pubDate>Thu, 30 Jan 2025 15:40:00 GMT</pubDate>
    </item>
    <item>
      <title>[d] 为什么“知识提炼”现在突然被贴上了盗窃的标签？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idjtta/d_why_is_knowledge_distillation_now_suddenly/</link>
      <description><![CDATA[我们都知道，蒸馏是一种近似更精确变换的方法。但我们也知道，这也是整个想法的终结。  蒸馏有什么问题？通过模仿输出来学习“知识”这一事实对我来说毫无意义。当然，通过保持输入和输出相同，我们试图近似一个类似的变换函数，但这并不意味着它确实如此。我不明白这怎么会被贴上盗窃的标签，尤其是当整个架构和训练方法都不同的时候。     提交人    /u/The-Silvervein   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idjtta/d_why_is_knowledge_distillation_now_suddenly/</guid>
      <pubDate>Thu, 30 Jan 2025 10:09:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于检索增强生成的 OSS React GUI 组件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idj27c/p_oss_react_gui_components_for_retrieval/</link>
      <description><![CDATA[      嘿 r/MachineLearning，我们想分享我们正在为 RAG QA 构建开源 REACT 组件！您可以在 https://github.com/renumics/lexio 找到我们的第一个 Lexio 版本 组件屏幕截图（文档来源：WMO-No. 1360：“非洲气候状况”） 它支持多种文档类型（PDF、HTML、Markdown），具有流式响应和源突出显示等高级功能。  主要特点：  查看器：用于聊天界面、源选择和查看的预构建组件，带有源突出显示 集成状态管理：组件间交互的透明状态处理 固执己见的架构：实现 RAG 最佳实践 高度可定制：主题和组件自定义选项     提交人    /u/DocBrownMS   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idj27c/p_oss_react_gui_components_for_retrieval/</guid>
      <pubDate>Thu, 30 Jan 2025 09:10:02 GMT</pubDate>
    </item>
    <item>
      <title>无炒作 DeepSeek-R1 [R] 阅读清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ideupn/no_hype_deepseekr1_reading_list/</link>
      <description><![CDATA[在过去的约 1.5 年里，我一直在运营一个研究论文俱乐部，我们在那里深入研究 AI/ML 领域有趣/基础的论文。因此，我们自然而然地接触到了很多导致 DeepSeek-R1 的论文。在本周深入研究 DeepSeek 论文时，我决定编制一份我们已经看过的论文清单，或者我认为这些论文是很好的背景阅读材料，可以更全面地了解 DeepSeek 内部发生的事情。 喝杯咖啡，享受吧！ https://www.oxen.ai/blog/no-hype-deepseek-r1-reading-list    提交人    /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ideupn/no_hype_deepseekr1_reading_list/</guid>
      <pubDate>Thu, 30 Jan 2025 04:51:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 假设分化驱动的推理模型新研究的产生</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ided3m/d_hypothetical_differentiationdriven_generation/</link>
      <description><![CDATA[有没有比我聪明的人能探索一下将 DSPy 或 TextGrad 之类的东西应用于 O1 或 DeepSeek R1 的可能性，使其生成推理链或提示，从而创建肯定不在其训练集中的 arXiv 论文，比如今天发布的论文？ 这是否有可能导致发现实际上会导致新发现的推理链？    提交人    /u/fraktall   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ided3m/d_hypothetical_differentiationdriven_generation/</guid>
      <pubDate>Thu, 30 Jan 2025 04:25:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 建立“穷人的推理模型”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1id8j4o/d_building_a_poor_mans_reasoning_model/</link>
      <description><![CDATA[阅读 DeepSeek-R1 论文后，我一直在想我们是否可以进一步优化推理模型以在消费级硬件上运行？ 该论文表明，推理可以纯粹从 RL 中产生，而无需 SFT，这令人印象深刻。但我并不确信这种新兴推理与我们通过结构良好、精心策划的 CoT 解决方案可能获得的推理有根本区别。 当然，RL 可以发现我们尚未明确教授的新策略（通过奖励信号进行“自我完善”），但我仍然不确定它是否真正不同于彻底的策划方法，尤其是看到像 4o 或 Sonnet 这样的模型在巧妙提示时可以产生什么。 RL DeepSeek 的方法具有明显的优势（训练成本更低，对手工制作数据的依赖更少），但如果我们可以通过更简单、无需训练的方法实现类似的结果：“借用”来自 R1 的合成数据集的推理，并结合多次提示？ 这是我的粗略想法：  将问答 + 推理 + 最终答案对存储在简单的数据库或向量存储中。 按主题标记它们（数学、编码、逻辑、等）或使用嵌入对它们进行索引以进行语义检索。 对于新查询，检索 2-3 个相关示例（包括它们的推理/错误/更正），然后将它们作为多样本提示提供给较小的模型，在推理时有效地借用 R1 的推理风格。  也许我们可以通过协作推理或轻量级 MoE 设置来改进输出，其中多个专门的提示会生成响应，而聚合器会选择或改进最佳的最终答案。或者尝试让竞争代理挑战彼此的推理逻辑，并通过比较来改进最终解决方案，基本上通过 MoE 构建错误/更正结构。 我的假设是，通过合成的“推理”多样本提示和轻量级代理协作，较小的模型可以在消费硬件上模仿 R1 的推理，同时几乎不需要任何训练成本，除了生成合成数据的初始成本之外。 无论如何，我打算在有空的时候测试这种方法。你怎么看？这是一条可行的道路，还是我遗漏了一些关键的东西？还是我从根本上误解了 R1？ 编辑：我应该在发布之前检查一下我输入的内容    提交人    /u/sebnadeau   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1id8j4o/d_building_a_poor_mans_reasoning_model/</guid>
      <pubDate>Wed, 29 Jan 2025 23:54:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大多数机械可解释性研究仅以预印本或博客文章的形式发表？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icw2pi/d_why_is_most_mechanistic_interpretability/</link>
      <description><![CDATA[我越深入研究这个话题，就越发现常见的做法是将您的工作作为博客文章发布在论坛上，而不是在同行评审的出版物上发布。  这使得工作变得不那么值得信赖和可信。我发现 Anthropic 不会在会议上发表文章，因为您无法复制他们的工作。但是，仍然有大量的工作“仅”以博客文章的形式提供。     提交人    /u/Physical_Seesaw9521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icw2pi/d_why_is_most_mechanistic_interpretability/</guid>
      <pubDate>Wed, 29 Jan 2025 15:16:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>