<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 03 Jul 2024 21:15:27 GMT</lastBuildDate>
    <item>
      <title>[D] 人工智能/机器学习中哪些问题似乎无人谈论？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dup0vs/d_what_are_issues_in_aiml_that_no_one_seems_to/</link>
      <description><![CDATA[我是一名研究人工智能的研究生，我经常遇到很多类似的关于人工智能监管问题的讨论，这些讨论通常涉及对高质量无偏见数据的需求、模型透明度、充分治理或其他类似但相关的主题。毫无疑问，所有这些都是重要而复杂的问题。 然而，我很好奇，是否有人在实践、个人或研究经历中遇到过任何不受欢迎或新颖的问题，这些问题通常不包括在人工智能讨论中，但出于某种原因一直困扰着你。 另一方面，是否还存在经常讨论但可能被严重低估的问题？ 我是一个有很多东西要学的学生，如果能得到任何见解或讨论，我将不胜感激。干杯。    提交人    /u/mrstealyoursoulll   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dup0vs/d_what_are_issues_in_aiml_that_no_one_seems_to/</guid>
      <pubDate>Wed, 03 Jul 2024 20:55:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] VAE 的变分和生成模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dumf18/d_variational_generative_model_of_vae/</link>
      <description><![CDATA[大家好， 这几天看了一些关于变分自编码器（VAE）的论文，感觉挺困惑的。 我是这样理解的： 在训练过程中，我训练编码器网络，调整近似后验分布 q(z|x)，使其接近真实分布。然后，我从这个多元分布中抽取一个潜在向量 z，并将其转发给解码器。解码器可以通过调整相应的权重来改变似然 p(x|z)。这会导致重建 x&#39;，我将其与初始输入观察 x 进行比较。重建的好坏可以通过似然度来衡量。这是 ELBO 的一部分。 ELBO 的另一部分是近似后验 q(z|x) 和先验 p(z) 之间的 KL 散度。在我看来，先验是我对潜在空间分布的初始信念。 以下是我的问题： 我经常读到，样本是从后验和先验中获取的。是否只在训练过程中从后验中获取样本？ 如果我的变分模型拟合完成，当我实际上想要在之后生成新数据时，我是否从先验 p(z) 中采样？ 此外，训练后是否使用拟合的后验 q(z|x) 更新先验 p(z)？ 最后一个问题是，如果我的解码器输出分布参数，如何从中得出实际的重建？    提交人    /u/hertz2105   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dumf18/d_variational_generative_model_of_vae/</guid>
      <pubDate>Wed, 03 Jul 2024 19:05:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习应用的投资回报率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1duklol/d_return_on_investment_of_ml_apps/</link>
      <description><![CDATA[我正在寻找 ML 应用的投资回报率。您是否知道此类报告/研究/客户成功案例，理想情况下包含有关成本和有形成分的数据？请分享您的见解并帮助我规划这个令人兴奋的领域。    提交人    /u/mhausenblas   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1duklol/d_return_on_investment_of_ml_apps/</guid>
      <pubDate>Wed, 03 Jul 2024 17:50:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mozilla TTS 从头开始​​训练结果不佳</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dujymn/d_mozilla_tts_training_from_scratch_bad_result/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dujymn/d_mozilla_tts_training_from_scratch_bad_result/</guid>
      <pubDate>Wed, 03 Jul 2024 17:23:23 GMT</pubDate>
    </item>
    <item>
      <title>ML中的复数分析[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dujmsf/complex_number_analysis_in_ml_p/</link>
      <description><![CDATA[我是 ML 的新手，有一些关于复数分析的理论想要测试，我想使用复数激活函数和复数数据作为输入。我想我偶然发现了一种涉及复数的新方法，但我还不知道自己在做什么。 有人知道任何包含复数的数据集吗？我在 kaggle 上找不到它们。我也对任何可能对 Black-Scholes 方程有用的数据感兴趣。 非常感谢您的帮助，抱歉我不想解释更多，也不想泄露秘诀。计划用这个给我找份工作，写一篇论文或尝试申请专利。    提交人    /u/LeopoldBStonks   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dujmsf/complex_number_analysis_in_ml_p/</guid>
      <pubDate>Wed, 03 Jul 2024 17:10:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 ML 模型从数据集生成见解 [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1duj6k6/generating_insights_from_a_dataset_using_a_ml/</link>
      <description><![CDATA[大家好， 在我的项目中，我想实现一项功能，以便我可以从数据集中生成自动见解，例如“过去 3 个月的销售额增加”、“该产品的价格下降了”等。有人可以告诉我如何从头开始实现它吗？    提交人    /u/OrneryCar6139   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1duj6k6/generating_insights_from_a_dataset_using_a_ml/</guid>
      <pubDate>Wed, 03 Jul 2024 16:51:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] GNN 学习过程的挣扎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1duf6tx/p_struggle_with_learning_process_of_gnn/</link>
      <description><![CDATA[大家好 :) 目前，我面临以下问题。我想构建一个 RL 代理，以根据动态变化的客户端位置优化大型网络中服务器的放置位置，并确定潜在位置。有许多潜在位置，代理应选择最佳选项，通过在该位置激活服务器来最小化延迟。 但是，我的 PPO 实现无法学习。为了检查我的底层模型是否能够捕获图表的信息，我将其重新定义为监督问题： 给定当前网络设置（潜在位置为节点、活动节点、客户端以及客户端与服务器之间的延迟），确定整体系统延迟。 因此，重要的部分是模拟单个延迟的边缘和标记为活动的节点。它们决定了系统的整体延迟。原则上，这不应该是一个难题，因为 GNN 应该很容易认识到它只需要考虑活动节点，然后在那里聚合边缘数据。但是，我的模型没有学到任何东西，并且通过预测系统延迟平均值附近的延迟而完全陷入困境。 我正在使用 torch_geometric 的 Graph Attention 模块。所以我的问题是，您是否有过类似的 GNN 经验，并在学习过程中遇到困难。对我来说，这个相对简单的任务的学习过程不能正常工作，这似乎很奇怪，所以我认为我搞砸了架构。 代码在这里： class CriticSwapGNN(nn.Module): def __init__(self, feature_dim_node: int = 3, hidden_​​channels: int = 12, fc_hidden_​​dim: int = 128, num_gat_layers: int = 4, num_mlp_layers:int = 3, num_heads=4,activation=nn.ReLU, num_nodes: int = None, num_locations: int = 15, for_active: bool = True, device: str = &quot;cuda&quot;, optimizer: nn.Module = torch.optim.Adam, lr: float = 3e-4, ):超级（CriticSwapGNN，self）。__init__（）self.num_nodes = num_nodes self.for_active = for_active self.num_locations = num_locations out_dim = 1 self.type_embedding = nn.Embedding（4，feature_dim_node）self.activation =activation（）self.att = GATConv（feature_dim_node + 2，hidden_​​channels//num_heads，heads=num_heads）self.hidden_​​atts = nn.ModuleList（）for _ in range（num_gat_layers - 2）：self.hidden_​​atts.append（GATConv（hidden_​​channels，hidden_​​channels//num_heads，heads=num_heads））self.final_att = GATConv（hidden_​​channels，hidden_​​channels//num_heads，heads=num_heads）critic_layer = [ nn.Sequential（线性（hidden_​​channels，fc_hidden_​​dim），activation（））] for _ in range（num_mlp_layers - 2）：critic_layer.append（线性（fc_hidden_​​dim，fc_hidden_​​dim））critic_layer.append（activation（））critic_layer.append（nn.Sequential（线性（fc_hidden_​​dim，1），activation（）））self.critic = nn.Sequential（*critic_layer）self.optimizer = optimizer（self.parameters（，lr=lr）self.device = device self.to（self.device）def forward（self，data：Union [Data，Batch]，batch：torch.Tensor = None）：如果len（data.type.shape）&gt;； 2：引发 ValueError（“类型应为 1D 张量。确保它不是独热编码的。”） x = self.type_embedding(data.type.long()) time_index = data.update_step.unsqueeze(1).to(self.device) # 规范化请求 mean_requests = torch.mean(data.requests[self.num_locations:], dim=0) std_requests = torch.std(data.requests[self.num_locations:], dim=0) request_norm = (data.requests[self.num_locations:] - mean_requests) / (std_requests + 1e-6) request_final = torch.cat([data.requests[:self.num_locations], request_norm], dim=0) x = torch.cat([x, request_final.unsqueeze(1), time_index], dim=-1) edge_index = data.edge_index x = self.att(x, edge_index, edge_attr=data.latency) x = self.activation(x) for att in self.hidden_​​atts: x = att(x, edge_index, edge_attr=data.latency) x = self.activation(x) x = self.final_att(x, edge_index, edge_attr=data.latency) # 节点值 node_values = self.critic(x) # 应用全局均值池来获得图级嵌入 graph_value = global_mean_pool(node_values, batch)     submitted by    /u/No_Individual_7831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1duf6tx/p_struggle_with_learning_process_of_gnn/</guid>
      <pubDate>Wed, 03 Jul 2024 14:05:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您认为验证映射器算法所识别的簇的稳定性的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1duc1d0/r_what_would_you_say_is_the_best_way_to_validate/</link>
      <description><![CDATA[是否有任何特定的技术可以确保它们不是噪声或参数选择的伪影？    提交人    /u/ICEpenguin7878   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1duc1d0/r_what_would_you_say_is_the_best_way_to_validate/</guid>
      <pubDate>Wed, 03 Jul 2024 11:29:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在动态因果建模中，量化模型证据和参数不确定性之间的权衡的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dubxgc/r_what_is_the_best_way_to_quantify_the_trade_off/</link>
      <description><![CDATA[例如在 MRI 扫描中    提交人    /u/ICEpenguin7878   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dubxgc/r_what_is_the_best_way_to_quantify_the_trade_off/</guid>
      <pubDate>Wed, 03 Jul 2024 11:22:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] dbt 用于数据产品：成本节约、体验和货币化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1du8j0h/d_dbt_for_data_products_cost_savings_experience/</link>
      <description><![CDATA[本文非常适合专注于优化 dbt 投资并希望增强以下任一功能的数据领导者或数据工程主管：成本节约、数据货币化工作、用户和数据消费者的整体体验。在本文中，您将了解：  将对话从 ETL 转移到数据产品的需求 + dbt 中的差距 数据产品：自助服务平台的众多成果之一，但很重要 如何利用现有堆栈（使用 dbt）构建数据产品 成本节约 大型 dbt 模型可能会导致高昂的计算成本 基础设施成本 维护、支持和运营成本 增加收入需求 规模和性能 转换/ ETL 如何进入新阶段并为扩展做好准备 增强所有人的体验（客户和业务人员）  在此处阅读完整文章：https://moderndata101.substack.com/p/dbt-for-data-products-cost-monetisation-xp    提交人    /u/growth_man   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1du8j0h/d_dbt_for_data_products_cost_savings_experience/</guid>
      <pubDate>Wed, 03 Jul 2024 07:30:29 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于函数/工具调用的全新 Llama、Mistral、Phi、Qwen 和 Gemma 模型集合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1du3b1e/p_new_collection_of_llama_mistral_phi_qwen_and/</link>
      <description><![CDATA[介绍 Rubra v0.1：一组开放权重、工具调用 LLM 在 此处 在 Hugging Face Spaces 中免费试用！ 我们还扩展了 vLLM 和 llama.cpp，以便您可以非常轻松上手。查看我们的文档：Rubra 文档   模型 函数调用 MMLU（5 次测试） GPQA（0 次测试） GSM-8K（8 次测试，CoT） MATH（4 次测试，CoT） MT-bench    Rubra Llama-3 70B Instruct 97.85% 75.90 33.93 82.26 34.24 8.36   Rubra Llama-3 8B 指导 89.28% 64.39 31.70 68.99 23.76 8.03   Rubra Qwen2 7B 指导 85.71% 68.88 30.36 75.82 28.72 8.08   Rubra Mistral 7B Instruct v0.3 73.57% 59.12 29.91 43.29 11.14 7.69   Rubra Phi-3 Mini 128k 指令 65.71% 66.66 29.24 74.09 26.84 7.45   Rubra Mistral 7B 指令 v0.2 69.28% 58.90 29.91 34.12 8.36 7.36   Rubra Gemma-1.1 2B Instruct 45.00% 38.85 24.55 6.14 2.38 5.75   我们为什么创建这些模型 尽管专有模型和开源模型之间的能力差距一直在缩小，但我们看到函数/工具调用在开源中仍然落后。 直到现在，让 LLM 输出可靠函数调用的选项有限，就像您可以让 OpenAI 和 Anthropic 这样做一样。提示工程、输出解析和 JSON 语法是一种 hack 选项。另一个选项是执行函数调用的模型，例如 Berkeley Gorilla、NexusRaven、Hermes、Command-R+，但它们都固定在一个模型上，有些在需要长上下文和在函数调用之上聊天的能力的代理用例中并不现实。最近，Mistral v0.3 中提供了工具调用，但在我们的测试中，它没有达到预期。 我们还根据对 gptscript、autogen 和其他代理框架的经验知道，您可能需要根据用例使用更小或更大的模型。我们不想被固定在一个模型上，所以我们决定对所有我们喜欢的模型进行进一步的后期训练。  一些旁注： - Rubra Qwen2 模型能够用中文进行函数调用！它在 Qwen2 支持的其他 28 种语言中具有有限的函数调用能力。 - GGUF 模型在过去 48 小时内的下载量约为 10 万次！ - 我们已经开始根据今天发布的 2024 年 6 月 Phi-3-mini 更新训练新的 Rubra Phi3。敬请期待！    提交人    /u/sanjay920   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1du3b1e/p_new_collection_of_llama_mistral_phi_qwen_and/</guid>
      <pubDate>Wed, 03 Jul 2024 02:18:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 推理过程中学习的当前研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dturka/d_current_research_in_learning_during_inference/</link>
      <description><![CDATA[我对在推理过程中可以学习的模型（尤其是自回归模型）的最新研究很感兴趣。这个领域的一些关键论文或方法是什么？我特别感兴趣的是：  推理过程中更新权重的方法 应用于语言模型、时间序列预测等。  任何指向最近工作的指针或对有希望的方向的想法都将不胜感激。谢谢！    提交人    /u/uoftsuxalot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dturka/d_current_research_in_learning_during_inference/</guid>
      <pubDate>Tue, 02 Jul 2024 19:42:32 GMT</pubDate>
    </item>
    <item>
      <title>有任何拥有 1 H100 允许分析的云提供商吗？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dtq8hn/any_cloud_providers_with_1_h100_allowing/</link>
      <description><![CDATA[您好，有谁知道有哪个 GPU 云提供商提供  租用单个 H100（而不是 8 个） 允许收集可能被 ncu 用于分析内核性能的分析数据。  例如，AWS 和 Lightning 允许收集分析数据，但我认为 Lambda 不允许。    提交人    /u/imurme8   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dtq8hn/any_cloud_providers_with_1_h100_allowing/</guid>
      <pubDate>Tue, 02 Jul 2024 16:35:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过稀疏插值专家释放元调整的力量，实现小样本泛化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dtntuq/r_unleashing_the_power_of_metatuning_for_fewshot/</link>
      <description><![CDATA[  由    /u/purified_piranha  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dtntuq/r_unleashing_the_power_of_metatuning_for_fewshot/</guid>
      <pubDate>Tue, 02 Jul 2024 14:55:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>