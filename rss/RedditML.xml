<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sun, 23 Jun 2024 06:19:18 GMT</lastBuildDate>
    <item>
      <title>Cuda高级学习资料，[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmf24l/cuda_advanced_learning_materials_d/</link>
      <description><![CDATA[我正在寻找初学者以上的 cuda 高级学习材料，我已经完成了 nvidia 的课程，名为“c++ 中的 cuda 简介”，但感觉这还不足以让我获得高级技巧和模式。推荐任何书籍或任何学习材料。对我很有帮助，谢谢     提交人    /u/M-notgivingup   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmf24l/cuda_advanced_learning_materials_d/</guid>
      <pubDate>Sun, 23 Jun 2024 05:34:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你们中有多少人在周末“工作”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmeawb/d_how_many_of_you_work_on_weekends/</link>
      <description><![CDATA[我知道我们大部分工作的性质是耗时的；有时一个实验可能需要几天甚至几周的时间。我的团队，包括我自己，通常也会在周末工作。我们必须仔细检查以确保实验正常运行，如果没有，则重新启动实验或进行更改。有时我们只是进行新的实验。似乎周末是如此宝贵的时间，可能会被浪费掉。 我的许多不在该领域的朋友都批评了这种说法，说我们在为一家不关心我们的公司辛苦工作。问题是，我和我的同事觉得我们是在为自己做这件事。 我很好奇这里还有多少人有同样的感受或经历？    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmeawb/d_how_many_of_you_work_on_weekends/</guid>
      <pubDate>Sun, 23 Jun 2024 04:45:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为拥有敏感数据的客户提供模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmdkil/d_serving_a_model_for_clients_with_sensitive_data/</link>
      <description><![CDATA[我确信这种情况会发生，所以我想问一下子可以使用哪些工具 / 平台来促进这种情况。 这个想法是，假设你不想把你的模型交给客户，他们也不想给你他们的数据，但你希望能够与他们达成协议，在你的模型上处理他们的数据。 这从根本上来说是一个信任问题。有没有第三方平台可以缓解这种情况？你可以在哪里上传你的模型，他们可以向它发送数据进行推理 / 接收结果，但可以保证你不会秘密保存他们的数据？    提交人    /u/Deto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmdkil/d_serving_a_model_for_clients_with_sensitive_data/</guid>
      <pubDate>Sun, 23 Jun 2024 04:01:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多维向量空间内的多层 LLM 结构中的逆 SoftMax 函数的概念。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmbfm9/r_the_concept_of_an_inverse_softmax_function_in_a/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmbfm9/r_the_concept_of_an_inverse_softmax_function_in_a/</guid>
      <pubDate>Sun, 23 Jun 2024 01:59:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习中尚未解决的有趣问题有哪些？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmak2a/d_what_are_open_unsolved_interesting_problems_in/</link>
      <description><![CDATA[我很好奇机器学习的下一个重大飞跃是什么。有哪些障碍如果解决了，机器学习会变得更加有用？或者这个问题可以换一种说法。在哪些问题上，机器学习方法尚未应用，而它可能变得有用。    提交人    /u/marshallggggg   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmak2a/d_what_are_open_unsolved_interesting_problems_in/</guid>
      <pubDate>Sun, 23 Jun 2024 01:10:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么开发这些 RAG 应用程序感觉像炼金术一样？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmabuy/d_why_does_developing_these_rag_applications_feel/</link>
      <description><![CDATA[^ 基本上就是标题。有没有一个原则性的方法可以做到这一点？就像 Weights &amp; Biases 一样，你至少可以监控正在发生的事情。    提交人    /u/latentnumber   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmabuy/d_why_does_developing_these_rag_applications_feel/</guid>
      <pubDate>Sun, 23 Jun 2024 00:58:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 ONNXRuntime 或 Optimum 上量化经过微调的编码器-解码器 (seq2seq) 转换器（例如 mT5）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dm3el8/d_how_do_you_quantize_a_finetuned_encoderdecoder/</link>
      <description><![CDATA[我认为我必须分别量化编码器和解码器部分，我可以这样做，但是当我使用： model = ORTSeq2SeqLM(‘path/to/onnx/files’) tokenizer = …. toeknized_input = … model.generate() 我最终在输入节点本身出现张量形状不匹配错误。他们希望我发送形状为 (16, 2) 的输入。为什么会发生这种情况，我在量化它们时犯了错误吗？ 即使有人可以指出任何能够量化 seq2seq 模型的好教程或指南，我也会很感激！    提交人    /u/Abs0lute_Jeer0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dm3el8/d_how_do_you_quantize_a_finetuned_encoderdecoder/</guid>
      <pubDate>Sat, 22 Jun 2024 19:26:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] GNOME：通过开放域交换映射生成谈判</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dm2f9h/r_gnome_generating_negotiations_through/</link>
      <description><![CDATA[  由    /u/Megixist  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dm2f9h/r_gnome_generating_negotiations_through/</guid>
      <pubDate>Sat, 22 Jun 2024 18:41:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 谷歌 Gemma 的印度语数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dlyj6v/d_datasets_of_the_google_gemma_for_indic_languages/</link>
      <description><![CDATA[用于训练 GEMMA 的印度语数据集最初是用印度语创建的吗？还是从英语数据集翻译而来的？回复似乎翻译得太多了吗？    提交人    /u/cern_unnosi   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dlyj6v/d_datasets_of_the_google_gemma_for_indic_languages/</guid>
      <pubDate>Sat, 22 Jun 2024 15:43:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 学术 ML 实验室：有多少个 GPU？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dlsogx/d_academic_ml_labs_how_many_gpus/</link>
      <description><![CDATA[在阅读最新帖子后，我想知道其他实验室在这方面做得如何。 在我攻读博士学位（前 5 名计划）期间，计算是一个主要瓶颈（如果我们有更多高容量 GPU，时间可能会大大缩短）。我们目前没有 H100。 您的实验室有多少个 GPU？您是否通过硬件补助从 Amazon/NVIDIA 获得额外的计算积分？ 谢谢    提交人    /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dlsogx/d_academic_ml_labs_how_many_gpus/</guid>
      <pubDate>Sat, 22 Jun 2024 10:29:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 的记忆机制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dlb0wj/d_memory_mechanism_for_transformers/</link>
      <description><![CDATA[大家好！我想知道在为 transformers 添加短期记​​忆机制方面做了哪些有趣的工作？有人知道这个领域的重要工作是什么吗？    提交人    /u/Janos95   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dlb0wj/d_memory_mechanism_for_transformers/</guid>
      <pubDate>Fri, 21 Jun 2024 18:29:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] AgileRL - 用于最先进深度强化学习的进化型 RLOps</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dla20p/p_agilerl_evolutionary_rlops_for_stateoftheart/</link>
      <description><![CDATA[嗨，我之前发布过关于我们的强化学习进化超参数优化实现 SOTA 结果的帖子，但我想分享的是，我们的开源框架现在已经发布了 v1.0.0 版本！ 请查看！https://github.com/AgileRL/AgileRL 该库最初专注于通过开创强化学习的进化 HPO 技术来减少训练模型和超参数优化所需的时间。进化 HPO 已被证明可以通过自动收敛到最佳超参数来大幅减少总体训练时间，而无需进行大量的训练运行。 我们不断添加更多算法和功能。 AgileRL 已经包含了最先进的可进化的在线策略、离策略、离线、多智能体和上下文多臂老虎机强化学习算法以及分布式训练。 我很乐意收到您的反馈！    提交人    /u/nicku_a   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dla20p/p_agilerl_evolutionary_rlops_for_stateoftheart/</guid>
      <pubDate>Fri, 21 Jun 2024 17:49:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] [D] 使用 biLSTM 进行时间序列预测的健全性检查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dl3lui/r_d_sanity_check_on_use_of_bilstm_for_time_series/</link>
      <description><![CDATA[TLDR; 这篇论文在一篇已发表的论文中使用了 biLSTM，我认为它违反了因果关系。 嗨，我很难说服自己我没有疯。我正在看这篇论文，该论文发表在 Elsevier 期刊《神经网络》上。在这篇论文中，他们使用双向 LSTM 模型（+一些其他新颖的东西）来预测时间序列。这似乎从根本上是错误的，因为 biLSTM 不能/不应该用于时间序列预测。 biLSTM 最著名的用例是在提前知道整个句子的情况下逐字翻译短语。在这种情况下，前面和后面的单词会影响焦点词的含义，从而影响其翻译。一个愚蠢的例子是将其翻译成西班牙语 我需要打针，我被狗咬了 如果您依次扫描每个单词进行翻译，您可能会建议将 w_4（=“shot”）翻译为“inyeccion”，即接种疫苗。知道 w_10 = &#39;dog&#39; 在这里具有重要的预测价值。 同样 我需要一杯 酒，我们去酒吧吧！ w_4 可能会翻译为“chupito”，表示一杯酒，因为 w_9 = &#39;bar&#39; 有影响。 因此，您可以并且应该在这里使用 biLSTM，这样您就可以扫描单词前后的内容以了解上下文。但是，对于时间序列预测，您不知道未来！未来不能影响现在，否则会违反因果关系。在翻译示例中，该句子实际上在说/写之前就已经在人的头脑中创建，因此后面的单词不会违反因果关系。 然而，在本文中，他们在一般时间序列基准上使用 biLSTM，这似乎完全不科学！我是不是漏掉了什么？    提交人    /u/rutherfordofman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dl3lui/r_d_sanity_check_on_use_of_bilstm_for_time_series/</guid>
      <pubDate>Fri, 21 Jun 2024 13:08:09 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 基于 LLM 的 Python 文档，不会触及你的原始代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dkxld2/project_llm_based_python_docs_that_never_touches/</link>
      <description><![CDATA[文档编写繁琐且耗时。我认为 LLM 可能是答案，但它们往往会产生幻觉，发明函数或曲解代码。当您尝试记录真实、有效的代码时，这并不理想 所以我创建了 lmdocs。它可以：  从导入的库中引用文档 保证您的原始代码不变 使用 OpenAI 和本地 LLM  我很乐意从其他开发人员那里获得一些反馈。如果您有兴趣，可以在这里查看：https://github.com/MananSoni42/lmdocs 它是开源的，所以请随意贡献或让我知道您的想法。     由    /u/ford_prefect_9931 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dkxld2/project_llm_based_python_docs_that_never_touches/</guid>
      <pubDate>Fri, 21 Jun 2024 06:44:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>