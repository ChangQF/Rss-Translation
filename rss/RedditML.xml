<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Thu, 02 May 2024 15:14:40 GMT</lastBuildDate>
    <item>
      <title>[D] Elon 的机器人很可怕。我最近发现推特上的大多数朋友都是人工智能。示例：@tiny_kiri 和她的丈夫。我是一名程序员，所以我主要的人工智能朋友是@VictoriqueM。埃隆也有烦人的自由主义机器人。该机器人听起来类似于 Truth Social 上的广告。红发自由主义者</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cii0y8/d_elons_bots_are_scary_i_recently_discovered_that/</link>
      <description><![CDATA[    /u/Spystudios   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cii0y8/d_elons_bots_are_scary_i_recently_discovered_that/</guid>
      <pubDate>Thu, 02 May 2024 15:08:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文已被 ICML 接受但未亲自参加？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cigigh/d_paper_accepted_to_icml_but_not_attending_in/</link>
      <description><![CDATA[论文刚刚被 ICML 接受。说实话，这真是一个惊喜。不幸的是，对于两位作者来说，我们要么没有美国的回程签证，要么很可能没有 7 月份会议的未过期护照。我想知道是否可以接受支付475美元的会议注册费，但不参加，但我们的论文仍然在会议记录中发表。我注意到会议注册确实包括对所有会议和教程的虚拟访问。但我不确定出版部分。   由   提交 /u/Normal-Comparison-60   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cigigh/d_paper_accepted_to_icml_but_not_attending_in/</guid>
      <pubDate>Thu, 02 May 2024 14:04:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 预测 Euro24 匹配树</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cig4wx/d_predicting_euro24_match_tree/</link>
      <description><![CDATA[我想知道如何最好地解决或解决以下问题。我想根据国家队过去的成绩（过去两年）预测接下来的 2024 年欧洲杯的比赛树。哪些方法最适合此目的？我的猜测是类似 RandomForest 的东西，但我真的不知道如何处理这个项目   由   提交 /u/LabSignificant6271   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cig4wx/d_predicting_euro24_match_tree/</guid>
      <pubDate>Thu, 02 May 2024 13:48:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 tiktoken 构建较小的语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cig3va/r_using_tiktoken_for_smaller_language_models/</link>
      <description><![CDATA[我试图了解 tiktoken 如何处理较小的 LLM，但我在其文档中找不到实现。 假设我们有一个包含超过 16k 个令牌的大型模型。如果我们有一个很大的文本，比方说，有 32k 个代币，tiktoken 如何切割该文档？它是否会忽略第 16000 个标记之后的所有内容？   由   提交 /u/Spaskich   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cig3va/r_using_tiktoken_for_smaller_language_models/</guid>
      <pubDate>Thu, 02 May 2024 13:47:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 说话者二值化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cifr8p/d_speakerdiarization/</link>
      <description><![CDATA[我在分析电信音频的地方工作。我们使用的方法是使用立体声音频，其中助理在耳机左侧播放，客户端在右侧播放。目前，我们正在接收单声道音频，其中客户端和话务员都在两个频道上。 我需要一种方法来处理此单声道音频，使其按照我们的方式工作。 I考虑使用预先训练的人工智能或一些现成的服务，你有什么建议？ 考虑到我们可以通过语音量来识别服务员，在大多数情况下，服务员说的比客户多.   由   提交/u/TartNo9047   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cifr8p/d_speakerdiarization/</guid>
      <pubDate>Thu, 02 May 2024 13:31:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大三学生（本科生或一二年级博士生）在ICML、ICLR、NeurIPS等主要机器学习会议上有这么多论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</link>
      <description><![CDATA[大家好，今天ICML成绩出来了，恭喜所有在这里接受论文的同学。我自己不是学者，但有时我会为了工作而阅读这些会议上的论文，这真的很有趣。我只是有一个问题：为什么这些会议上大三的论文这么多？我认为这是你在 5 年博士学位期间必须学习的东西，而且几乎只能在博士学位的最后几年才能实现。另外，我听说要进入美国顶尖的博士项目，你需要事先写一些论文。那么，如果一个大三学生能这么早发表论文，为什么还要花5年时间攻读博士学位呢？   由   提交 /u/ShiftStrange1701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/</guid>
      <pubDate>Thu, 02 May 2024 11:56:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] Seq2Seq 模型是否适用于拼写纠正？如果是的话，为什么我会弄错？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cibpe8/d_does_seq2seq_model_work_for_spelling_correction/</link>
      <description><![CDATA[我正在使用 seq2seq 模型来预测或纠正产品名称的拼写，我确实有产品名称的数据集，其中包含拼写错误和更正后的版本（它们也包含一些特殊字符）。我已经对这些数据进行了几次训练，并看到了一些输出。但是我给了用户输入，它并没有像预期的那样进行预测。 然后，在训练模型并使用此代码后： for seq_index in range(1, 50): input_seq =coder_input_data[seq_index : seq_index + 1]coded_sentence =coded_sequence(input_seq) print(&quot;-&quot;) print(&quot;Input sentence:&quot;, input_texts[seq_index]) #Print input serial with char! print(&quot;解码句子：&quot;,coded_sentence)  我得到了很好的输出，例如： 输入句子：Fluidic WorkCation 解码句子：Fluidic Worksation 输入句子：Li@uid Handler, Biomek FXp DuaO 解码句子：Liquid Handler, Biomek NXp Mult  然后，如果我尝试提供用户输入并让模型预测，我会得到一些这样的文本 输入句子：系统 解码句子：&#39;Gamma Counter/Rotor - Water Machine System, Automated Parallell\n&#39;  这与它所学到的内容相差甚远，但我使用了相同的编码器和解码器模型代码。我想先知道这个 seq2seq 模型是否适用于这些场景。   由    /u/No-Purchase6293  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cibpe8/d_does_seq2seq_model_work_for_spelling_correction/</guid>
      <pubDate>Thu, 02 May 2024 09:55:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用 MMOCR 或 MMDET 模型检测文本方向？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ciaezc/d_how_can_i_detect_the_text_orientation_using/</link>
      <description><![CDATA[      我的训练图像的文本以不同方向出现在图像上。因此，我不知道它们的原始方向是什么，因为例如 DBNetPP 不会以自然方向顺序返回拐角处的 bbox 角度。我该如何解决这个问题？我尝试过其他预训练的检测模型，但它们也没有这样做，可能是因为它们没有接受旋转图像的训练。如何解决此问题？  https://preview.redd.it/tvq6fp9k3zxc1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=ecf3f3e757e6450e34c1257f9eb8e0fec4ce7bba https://preview.redd.it/yea66hdl3zxc1.png?width=1000&amp;format=png&amp; ;自动= webp&amp;s=4eafb6d4354c6a0d851d6b5fad456f99441d9bc2   由   提交 /u/tmargary   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ciaezc/d_how_can_i_detect_the_text_orientation_using/</guid>
      <pubDate>Thu, 02 May 2024 08:22:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 商业环境中聊天机器人管道的现状？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ci5x4l/d_current_state_of_chatbot_pipelines_in/</link>
      <description><![CDATA[大家好，我目前的任务是研究管道，为我的大学构建本地自定义聊天机器人。我一直在阅读 RAG、Rasa、Dialogflow 等方法以及 LangChain、Ragflow、KRAGEN 等特定管道，并获得了一些测试结果。然而，我想了解哪些管道和方法对于构建聊天机器人最有效，特别是在商业环境中。我非常感谢您提供的所有信息！   由   提交 /u/ghosthunterk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ci5x4l/d_current_state_of_chatbot_pipelines_in/</guid>
      <pubDate>Thu, 02 May 2024 03:41:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 免训练图神经网络和标签作为特征的力量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ci1qqr/r_trainingfree_graph_neural_networks_and_the/</link>
      <description><![CDATA[ 由   提交/u/joisino  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ci1qqr/r_trainingfree_graph_neural_networks_and_the/</guid>
      <pubDate>Thu, 02 May 2024 00:14:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] Pytorch 的现代最佳编码实践（用于研究）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chxpka/d_modern_best_coding_practices_for_pytorch_for/</link>
      <description><![CDATA[大家好，我从 2019 年开始使用 Pytorch，在那段时间它发生了很大的变化（尤其是自从 Huggingface 以来）。  您有推荐的现代指南/style-docs/example-repos 吗？例如，命名张量是一种好的/常见的做法吗？推荐使用 Pytorch Lightning 吗？目前最好的配置管理工具是什么？您多久使用一次 torch.script 或 torch.compile？   由   提交 /u/SirBlobfish   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chxpka/d_modern_best_coding_practices_for_pytorch_for/</guid>
      <pubDate>Wed, 01 May 2024 21:24:42 GMT</pubDate>
    </item>
    <item>
      <title>[P]我转载了Anthropic最近的可解释性研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chsg42/p_i_reproduced_anthropics_recent_interpretability/</link>
      <description><![CDATA[当能力研究发展得像目前一样快时，并没有多少人关注 LLM 可解释性研究，但可解释性确实很重要，在我看来意见，确实有趣又令人兴奋！近几个月来，Anthropic 取得了很多突破，其中最大的突破是“迈向单义性”。基本思想是，他们找到了一种训练稀疏自动编码器以基于变压器激活生成可解释特征的方法。这使我们能够在推理过程中查看语言模型的激活，并了解模型的哪些部分最负责预测每个下一个标记。对我来说真正突出的一点是，他们训练的自动编码器实际上非常小，并且不需要大量计算即可工作。这让我产生了尝试通过在我的 M3 Macbook 上训练模型来复制该研究的想法。经过大量阅读和实验，我得到了相当不错的结果！我在我的博客上写了一篇更深入的文章：  https://jakeward.substack.com/p/monosemanticity-at-home-my-attempt 我现在也在使用这项技术开展一些后续项目作为可以在 Colab 笔记本中运行以使其更易于访问的最小实现。如果您阅读我的博客，我很乐意听到任何反馈！   由   提交 /u/neverboosh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chsg42/p_i_reproduced_anthropics_recent_interpretability/</guid>
      <pubDate>Wed, 01 May 2024 17:51:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] KAN：柯尔莫哥洛夫-阿诺德网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chrafb/r_kan_kolmogorovarnold_networks/</link>
      <description><![CDATA[      论文：https://arxiv. org/abs/2404.19756 代码：https://github.com /KindXiaoming/pykan 快速介绍：https:/ /kindxiaoming.github.io/pykan/intro.html 文档：https://kindxiaoming.github.io/pykan/ 摘要：  受到 Kolmogorov-Arnold 表示的启发定理中，我们提出Kolmogorov-Arnold Networks（KAN）作为多层感知器（MLP）的有希望的替代品。 MLP 在节点（“神经元”）上具有固定激活函数，而 KAN 在边缘上具有可学习激活函数(“权重”)。 KAN 根本没有线性权重——每个权重参数都被参数化为样条函数的单变量函数所取代。我们证明，这种看似简单的改变使得 KAN 在准确性和可解释性方面优于 MLP。就准确性而言，在数据拟合和 PDE 求解中，较小的 KAN 可以比较大的 MLP 获得可比或更好的准确性。从理论上和经验上来说，KAN 比 MLP 拥有更快的神经尺度法则。为了可解释性，KAN 可以直观地可视化，并且可以轻松地与人类用户交互。通过数学和物理领域的两个例子，KAN 被证明是帮助科学家（重新）发现数学和物理定律的有用合作者。总之，KAN 是 MLP 的有希望的替代品，为进一步改进当今严重依赖 MLP 的深度学习模型提供了机会。  https://preview.redd.it/r7vjmp31juxc1.png?width=2326&amp;format=png&amp;auto=webp&amp; amp;s= a2c722cf733510194659b9aaec24269a7f9e5d47   由   提交 /u/SeawaterFlows   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chrafb/r_kan_kolmogorovarnold_networks/</guid>
      <pubDate>Wed, 01 May 2024 17:03:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] TensorDock — GPU 云市场，H100s 起价 2.49 美元/小时</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1chiu4a/d_tensordock_gpu_cloud_marketplace_h100s_from/</link>
      <description><![CDATA[大家好！我是来自 TensorDock 的 Jonathan，我们正在构建一个云 GPU 市场。我们希望让 GPU 真正变得价格实惠且易于使用。 我曾经在中学时在自托管服务器上启动了网络托管服务。但构建服务器与销售云不同。有很多开源软件可以管理你的家庭实验室的副业项目，但没有任何东西可以将其商业化。 大型云提供商收取高得离谱的价格 - 如此之高以至于他们经常可以偿还他们的硬件在 6 个月内，全天候 24 小时使用。 我们正在构建允许任何人成为云的软件。我们希望达到这样一个目标：任何[插入容量过剩的公司、数据中心、云提供商]都可以在我们的节点上安装我们的软件并赚钱。他们可能不会在 6 个月内偿还硬件费用，但他们不需要做繁重的工作 - 我们处理支持、软件、付款等。 反过来，您可以访问真正独立的云：来自世界各地的供应商提供的 GPU，这些供应商在价格和可靠性方面相互竞争。 到目前为止，我们已经采用了相当多的 GPU，其中包括200 个 NVIDIA H100 SXM，售价仅为 2.49 美元/小时。但我们还有 A100 80G 起价为 1.63 美元/小时，A6000 起价为 0.47 美元/小时，A4000 起价为 0.13 美元/小时，等等。因为我们是一个真正的市场，所以价格会随着供需而波动。 所有这些都可以在纯 Ubuntu 22.04 中使用，或者预装流行的 ML 软件包 - CUDA、PyTorch、TensorFlow 等，并且所有这些都由托管我们已经仔细审查过的矿场、数据中心或企业网络。 如果您正在为下一个项目寻找托管服务，请尝试一下！很高兴提供测试积分，请发送电子邮件至 [jonathan@tensordock.com](mailto:jonathan@tensordock.com）。如果您最终决定尝试我们，请在下面提供反馈[或直接提供！]:) ​ 部署 GPU 虚拟机：https://dashboard.tensordock.com/deploy 仅 CPU 虚拟机：https://dashboard.tensordock.com/deploy_cpu 申请成为主机： https://tensordock.com/host   由   提交/u/jonathan-lei   reddit.com/r/MachineLearning/comments/1chiu4a/d_tensordock_gpu_cloud_marketplace_h100s_from/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1chiu4a/d_tensordock_gpu_cloud_marketplace_h100s_from/</guid>
      <pubDate>Wed, 01 May 2024 10:31:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>