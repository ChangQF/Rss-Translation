<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Mon, 15 Jul 2024 12:29:15 GMT</lastBuildDate>
    <item>
      <title>[D] 印地语 NER 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3tdng/d_ner_model_for_hindi_language/</link>
      <description><![CDATA[我正在 NER 上建立一个项目。我能够找到适合英语的良好模型。有没有适合印地语和其他印度语言的好模型。我尝试了 IndicNLP、BERT 等，但输出效果不佳。有人可以帮我找到一个好的模型吗？    提交人    /u/expiredUserAddress   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3tdng/d_ner_model_for_hindi_language/</guid>
      <pubDate>Mon, 15 Jul 2024 12:19:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最佳开源 LLM，用于基于图表的问答</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3s9zq/d_best_open_source_llm_for_graph_based_questions/</link>
      <description><![CDATA[因此，这个问题分为两部分：  用于从非结构化文本创建知识图谱的 LLM 基于知识图谱回答问题  就开源/微调 LLM 而言，有人有使用过其中任何一种的经验吗？    提交人    /u/Raise_Fickle   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3s9zq/d_best_open_source_llm_for_graph_based_questions/</guid>
      <pubDate>Mon, 15 Jul 2024 11:19:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您认为最佳的“检索增强生成”编排器是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3p5fx/d_best_retrieval_augmented_generation/</link>
      <description><![CDATA[因此，我目前正在开发一个包含 Gen AI 和适用于 gemini 1.5 flash 的 vertex ai 的项目，我计划为其添加一个 RAG 系统，并且我计划使用 MongoDB 作为矢量数据库以简化操作。现在，我正在尝试决定应该使用哪个编排器来为 RAG 系统加速开发。你们有什么建议？    提交人    /u/PsychologicalAd7535   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3p5fx/d_best_retrieval_augmented_generation/</guid>
      <pubDate>Mon, 15 Jul 2024 07:52:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习项目构想[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3m9js/ml_project_ideas_d/</link>
      <description><![CDATA[最近，我一直在努力为我的 ML 项目产生想法。我想到的想法是那些典型的糟糕想法，例如使用 KNN 和 SVM 的电影发现平台。没有人想要。  然后我想到遇到问题并解决它们。现在我也在努力寻找问题。  我该怎么办？其他人如何摆脱编码员的写作障碍     提交人    /u/MinuteDistribution31   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3m9js/ml_project_ideas_d/</guid>
      <pubDate>Mon, 15 Jul 2024 04:46:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于如何创建分层 LLM 工作流程的想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3fpz4/d_ideas_on_how_to_create_a_hierarchical_llm/</link>
      <description><![CDATA[是否可以创建一个 AI 代理工作流，让 LLM A 可以来回与 LLM B 对话，例如 10 次，以迭代特定案例，并且仅在这 10 次通过后才返回响应？ 例如，如果我有一个严格提示的低温 LLM 1 和一个不太严格、更有创意的 LLM2。LLM2 批评 LLM1 并给出如何改进（迭代）的建议。您可以指定“重复”的次数，例如，运行 LLM 2 最多 6 次或 10 次或我设置的任何次数。 想法是创建一个解决方案，您可以在其中将“主管”置于“工人或工人”之上，并将其构建到 LLM 层次模型中。我正在尝试使用 SmythOS 来快速创建概念证明，但我甚至无法在两个 LLM 之间来回传递数据。对于我的特定需求，我必须构建一个具有一定数量重复的多级层次结构。 为了很好地呈现它： LLM1 - 为文章创建大纲 LLM2 - 撰写文章并交给 LLM3 审阅 LLM3 - 根据他的清单对其进行批判性审查。 如果一切都很好，就会产生最终的回应，如果不是，LLM 3 会指出需要改进的地方并将其交给 LLM 4 以征求批判性见解（LLM 4 是一种预先提示的 LLM，它将提供非常具体的见解或关注以特定方式传递的特定感觉/信息），然后它将整个脚本交还给 LLM2，LLM2 是唯一真正在写作的 LLM。该过程重复进行，直到满足 LLM3 或超过 X 次重复（其中 X 是您提前设置的）。  您将如何进行此操作？    提交人    /u/moonbunR   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3fpz4/d_ideas_on_how_to_create_a_hierarchical_llm/</guid>
      <pubDate>Sun, 14 Jul 2024 23:09:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] Onnx 处理随时间变慢</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3a4rt/p_onnx_processing_slowing_down_with_time/</link>
      <description><![CDATA[我正在使用 PyQt 创建 onnx 桌面应用程序。该应用程序在后端使用 onnx 模型。Onnruntime-gpu 用于使用 GPU 进行处理。 我正在使用单图像超分辨率模型逐帧处理超分辨率视频。 模型启动良好。但是，随着时间的推移，处理速度会变慢。 我猜有些垃圾收集出了问题，但我不确定。正在寻找有关如何保持模型平稳运行的提示。我想运行它几个小时。    提交人    /u/SPRODEM   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3a4rt/p_onnx_processing_slowing_down_with_time/</guid>
      <pubDate>Sun, 14 Jul 2024 19:02:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 YOLO 和 Visual Transformers 检测和识别已看到和未看到的广告 - 可行性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e38mce/d_detecting_and_identifying_seen_and_unseen_ads/</link>
      <description><![CDATA[我正在开展一个项目，需要检测图片中见过和以前没见过的广告。设置如下： • 我有大约 1600 张图片的注释。• YOLO 对带注释的广告表现良好。• 对于带注释的广告，我还有一个源图片列表（带注释的图片来自野外）。 我的目标是检测以前没见过的广告。这是我目前的方法： 1. YOLO 模型：我训练了一个通用 YOLO 模型，其中所有广告都被标记为单个类“广告”。2. 使用嵌入进行比较：一旦检测到广告，计划使用嵌入将其与数据库中的广告进行比较。 3. 微调视觉转换器：我将在源图像上微调视觉转换器，以帮助区分略有变化的广告（例如，添加了“30％折扣”等文字或更改了字体）。  我的问题是： •根据您的经验，这种方法是否有希望检测和识别已看到和未看到的广告？ •对于这个问题，我应该考虑更好的方法或技术吗？  提前感谢您的见解！    提交人    /u/ThickDoctor007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e38mce/d_detecting_and_identifying_seen_and_unseen_ads/</guid>
      <pubDate>Sun, 14 Jul 2024 17:58:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 在 VQGAN 中，量化之后，图像是如何生成的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e37ymt/d_r_in_vqgan_after_quantization_how_is_an_image/</link>
      <description><![CDATA[我了解到我们首先训练 VQ-VAE（包括编码器、量化、解码器、鉴别器）模块，然后才训练变压器。 但如果这是真的，如果变压器模块尚未训练，图像是如何生成并在鉴别器中处理的呢？ 假设 VQ-VAE 和变压器模块都经过训练，那么图像生成是如何进行的？ 我读到变压器只预测下一个补丁（滑动窗口技术）。所以它预测实际像素？还是预测代码向量？但我读到代码向量被用作变压器的条件。 我只是不明白量化向量（z_q）之间的相互作用，之后会发生什么？如果 Transformer 预测下一个码本向量，那么为什么我们将码本向量作为序列作为 Transformer 的输入？    提交人    /u/ShlomiRex   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e37ymt/d_r_in_vqgan_after_quantization_how_is_an_image/</guid>
      <pubDate>Sun, 14 Jul 2024 17:31:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] Flash Attention 是什么？解释一下</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e36jye/r_what_is_flash_attention_explained/</link>
      <description><![CDATA[与标准 Attention 机制相比，Flash Attention 有重大改进（Attention 中用到的就够了），它在空间和时间复杂度上都有所提升。更多信息请查看：https://youtu.be/znhk2mgplWY?si=Q3fz5GuMuyyWSdhd    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e36jye/r_what_is_flash_attention_explained/</guid>
      <pubDate>Sun, 14 Jul 2024 16:32:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] Graph Vision：一个用于创建段映射的 Python 库。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e35cs4/r_graph_vision_a_python_library_to_create_segment/</link>
      <description><![CDATA[        提交人    /u/Kian5658   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e35cs4/r_graph_vision_a_python_library_to_create_segment/</guid>
      <pubDate>Sun, 14 Jul 2024 15:42:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 仅依赖 LLM API 与使用各种不同的模型。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e33lwl/d_relying_solely_on_llm_apis_vs_using_various/</link>
      <description><![CDATA[我不确定如何准确表述这一点，所以请原谅这个相当模糊的标题。 我的公司目前正在尝试创建一个专门用于电子商务的聊天机器人。我们面临的问题是，LLM 似乎难以区分某些函数调用的查询。 我认为最好让 LLM 做它们最擅长的事情，在我看来，那就是文本生成，并使用其他模型来处理其他事情。例如，如果我们需要成功地将客户查询分类为“request_a”、“request_b”等类别等等。对我来说，为此建立一个专用的模型（无论大小）并将结果传递给 LLM 以生成用户友好消息更有意义。 但与此同时，我承认我并不那么熟悉 LLM 在实际应用中的使用，并且不确定这是否比让模型自己做所有事情更糟糕。 想知道大家对此的看法。提前谢谢了。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e33lwl/d_relying_solely_on_llm_apis_vs_using_various/</guid>
      <pubDate>Sun, 14 Jul 2024 14:27:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解 Transformer Attention 中的 Look Ahead Mask</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e30zdg/d_understanding_the_look_ahead_mask_in/</link>
      <description><![CDATA[      我试图理解 transformers 中前瞻掩码的解释，即下三角矩阵掩码。常见的解释是，它可以防止 token 展望未来，我明白为什么它表面上是有道理的。如果你将矩阵视为经典数据结构表示中的有向邻接图，则此陈述是正确的。但是这个矩阵是由网络生成的，因此不受这些虚构规则的限制。如果你绘制下图的无向图，你会看到每个节点仍然连接到每个节点。这至少是我的困惑的根源。我想说，同样的论点也可以是，token 无法回顾过去。 如果我们说注意力矩阵是双向的，我们甚至可以说三角矩阵足以表示全连通图，因为全矩阵是对称的，因此包含冗余信息。并且进一步引出了一个问题，即应该如何解释不对称注意力矩阵。 或者后续的值 V 乘法以这样的方式使用矩阵，以至于它确实必须被解释为有向图？ 来源：https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0    提交人    /u/KonArtist01   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e30zdg/d_understanding_the_look_ahead_mask_in/</guid>
      <pubDate>Sun, 14 Jul 2024 12:21:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] 机器学习边做边教</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2yw8d/p_machine_learning_teach_by_doing/</link>
      <description><![CDATA[      https://i.redd.it/wsbaaccbmgcd1.gif  我相信任何人都可以转型到机器学习，只要他们决定这样做。 在过去的 3 个月里，我开始了一个教授机器学习和深度学习的项目。 我录制了 70 个机器学习和深度学习的视频。 每天，我都会编写脚本、录制和编辑 1 个视频，大约持续 6-7 个小时。结果是 2 个庞大的播放列表。 1️⃣ 机器学习边做边教播放列表： (a) 涵盖的主题：回归、分类、神经网络、卷积神经网络 (b) 讲座数量：35 (c) 讲座讲师：我（IIT Madras BTech、MIT AI PhD） (d) 播放列表链接：https://www.youtube.com/playlist?list=PLPTV0NXA_ZSi-nLQ4XV2Mds8Z7bihK68L 2️⃣ 从头开始​​的神经网络播放列表： (a) 涵盖的主题：神经网络架构、前向传递、后向传递，优化器。完全用 Python 从头开始​​编码。没有 Pytorch。没有 Tensorflow。只有 Numpy。 (b) 讲座数量：35 (c) 讲座讲师：我（IIT Madras BTech、MIT AI PhD） 播放列表链接：https://www.youtube.com/playlist?list=PLPTV0NXA_ZSj6tNyn_UadmUeU3Q3oR-hu 附注：讲师背景：我毕业于麻省理工学院，获得机器学习博士学位。    提交人    /u/OtherRaisin3426   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2yw8d/p_machine_learning_teach_by_doing/</guid>
      <pubDate>Sun, 14 Jul 2024 10:15:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] Glean 或 OpenAI 等公司如何将如此多的数据存储在向量数据库中以供检索？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e2vxqw/d_how_do_companies_like_glean_or_openai_store_so/</link>
      <description><![CDATA[我查看了 Qdrants 的定价，发现如果我想要 32GB RAM 和 4 个 VPCU + 1TB（假设空间），每月大约需要花费 780 美元。 Glean 或 OpenAI 等公司如何让如此多的企业数据可搜索？这些企业已经在支付存储费用，因此他们不认为 RAG 是在支付存储费用；当此类服务如此昂贵时，他们不清楚数据量能扩展到多大。 可以肯定的是，即使自己托管也不便宜。 有什么想法吗？    提交人    /u/dtek_01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e2vxqw/d_how_do_companies_like_glean_or_openai_store_so/</guid>
      <pubDate>Sun, 14 Jul 2024 06:58:02 GMT</pubDate>
    </item>
    </channel>
</rss>