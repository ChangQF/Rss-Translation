<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Mon, 17 Feb 2025 12:34:00 GMT</lastBuildDate>
    <item>
      <title>[p]我构建了一个基于LLM的工具，用于遵循GitHub存储库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irinnx/p_i_built_an_llm_based_tool_for_following_github/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    gitsub 读取所有提议，问题和释放的回购每个星期，向您发送30秒的电子邮件。它可以免费使用，直到Openai Bill使我破产。  它支持任何公共回购，但这里有一些特别有用的：    tensorflow      deepseek-r1&gt; deepseek-r1     deepseek-v3     langchain      pytorch      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ustonomousbull     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1irinnx/p_i_built_an_llm_lm_based_tool_tool_folollowing_github/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irinnx/p_i_built_an_llm_based_tool_for_following_github/</guid>
      <pubDate>Mon, 17 Feb 2025 12:24:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] TTSleaderboard-客观评估语音生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iri3dv/p_ttsleaderboard_objective_evaluation_of_speech/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我决定为语音生成的客观评估打开包裹： https://github.com/balacoon/speech_gen_eval    我开始在其上填写ttsleaderboard： https://huggingface.co/spaces/balacoon/ttsleaderboard   有ttsds（ https://balacoon.com/blog/blog/tts \ _leaderboard/     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/clementruhm     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iri3dv/p_ttsleaderboard_objective_evaluation_of_speech/</guid>
      <pubDate>Mon, 17 Feb 2025 11:49:36 GMT</pubDate>
    </item>
    <item>
      <title>[d] DeepSeek R1自托管工具在Cline中呼唤</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irhuje/d_deepseek_r1_selfhosted_tool_calling_in_cline/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在尝试使用使用vllm托管的deepseek模型，但使其在cline中使用的有用，它必须具有工具调用功能。但是DeepSeek本地不支持工具调用。 ，但是如果我在cline中使用Direct DeepSeek并输入API键，则它可以编辑文件。 甚至我尝试了使用DeepSeek-r1：70b使用Ollama，它一直在生成响应，并以错误 结束对于功能较低的模型而言，执行可能具有挑战性。为了获得最佳效果，建议使用Claude 3.5十四行诗来获得其先进的代理编码功能。 ```````` 如果可能的话，我应该更改我的端点，例如直接deepseek api。 我正计划在ollama端点中使用vllm端点。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/shrijayan     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1irhuje/d_deepseek_r1_r1_selfhosted_tool_calling_in_calling_in_cline/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irhuje/d_deepseek_r1_selfhosted_tool_calling_in_cline/</guid>
      <pubDate>Mon, 17 Feb 2025 11:33:19 GMT</pubDate>
    </item>
    <item>
      <title>[D]有趣的播客？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irhirs/d_interesting_podcasts/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我将不得不尽快恢复通勤，我想知道是否有人对机器学习的技术播客有建议。请不要仅营销销售资料技术谢谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/erlapso     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irhirs/d_interesting_podcasts/</guid>
      <pubDate>Mon, 17 Feb 2025 11:11:05 GMT</pubDate>
    </item>
    <item>
      <title>[d]在LLMS中的水印，它解决的实际问题是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irhije/d_watermarking_in_llms_what_is_the_actual_problem/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在寻找从业者的输入来填补我的理解中的空白。我理解当前水印方法的方式，例如SynthID：  1）假设我们可以访问基础LLM   2）没有试图解决更广泛的问题。 AI生成的？描述还是我错过了至关重要的东西？因为如果我没有错过任何东西，我看不到哪个合理（对我），这些水印将对社会有益。 让我解释一下： 假设我是LLM提供商，我不希望恶意演员使用我的服务来产生错误信息，伪造的图像等。在这种情况下，我认为水印的好处是威慑。如果Google提供免费/廉价的API来检查其服务是否生成内容，则恶意演员更有可能去其他地方使用其他LLM。 这就是我可以看到的好处的程度。只要有易于访问的LLM不实施此类水印功能，恶意演员的成本实际上就是0。 这是一个未来，这是一个未来，所有专业的公共LLM都需要服务来依法实施水印解决方案，而最新的LLMS锁定在此类服务后面。这是研究人员在水印期间期望的东西吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/stat-insig-005     link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irhije/d_watermarking_in_llms_what_is_the_actual_problem/</guid>
      <pubDate>Mon, 17 Feb 2025 11:10:41 GMT</pubDate>
    </item>
    <item>
      <title>[d]微调图像分类模型的最佳技巧和技巧是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irhhn4/d_what_are_your_best_tips_tricks_for_finetuning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 我目前正在参加专注于图像分类（70000 images）的Kaggle竞赛/strong&gt;，我正在深入研究预先训练的模型。虽然我对这一过程有着深入的了解，但我知道只有来自现实世界的实践才有丰富的经验和聪明的技巧。 我很想听听效果最好的技术在微调图像模型中适合您！    最佳预审计模型  您是否有用于图像分类的首选模型任务？ （例如，有效网络，Convnext，Vit，Swin Transformer等） 您如何在CNN和Vision Transformers之间决定？ 任何表现出令人惊讶的被低估的体系结构吗？    优化器＆amp;学习率策略  哪些优化者给您带来了最佳结果？ （adamw或sgd ??） 您如何安排学习率？ （OnecyClelr，cosineannealing，reducelRonplateau等）      数据增强＆amp;预处理  什么增强为您引起了明显的提升？ 正则化＆amp;预防过度拟合  您如何处理微调模型中的过度拟合？     推论＆amp;后处理提示  您是否使用测试时间增强（TTA），结合或其他技巧来提高性能？       &lt;强&gt;培训策略＆amp;技巧：  您如何决定在填充模型时要解冻多少层   增加了FC头部中的层是否会使它在小数据集中过度拟合？    很想听听您从自己的经历中获得的任何经验教训，洞察力，甚至是错误！  您还可以链接您认为具有高质量的资源或Kaggle笔记本。 期待您的响应。  &lt;！&lt;！ -  sc_on- - &gt;＆＃32;提交由＆＃32; /u/u/crearsive-bid6127     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irhhn4/d_what_are_your_best_tips_tricks_for_finetuning/</guid>
      <pubDate>Mon, 17 Feb 2025 11:08:57 GMT</pubDate>
    </item>
    <item>
      <title>[d]在笔记本电脑升级方面寻找有关运行较小LLM和微调的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irh1hj/d_looking_for_advice_on_laptop_upgrade_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我是一名学生学习机器学习，并且最近进入了LLM。目前，我大部分时间都花费大部分时间来阅读LLM的不同方面，因为我目前的笔记本电脑（GTX 1650 3 GB VRAM）只能以半级速度运行0.5B LLM，并且与大型型号斗争。由于我想经历更多关于LLM的信息，例如不同的微调技术或只是运行它们以测试它们，因此，笔记本电脑开始成为一个很大的限制。 我一直在考虑使用升级到笔记本电脑工作站更多的VRAM，我目前正在使用8GB或16GB VRAM的选项之间进行决定。我遇到了一些具有A5000或3080的联想ThinkPad，均为16GB VRAM，我想知道这对我的用例是否是一个不错的选择。我所在国家/地区的二手笔记本电脑的费用约为1.3-1.4k美元，因此它非常接近PC，而且价格不高。 我四处走动，所以PC不是PC目前对我来说确实是一个选择。 8GB VRAM是否足以实验较小的型号和微调，或者16GB明显更好？ ＃32;提交由＆＃32; /u/u/goat18_194     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irh1hj/d_looking_for_advice_on_laptop_upgrade_for/</guid>
      <pubDate>Mon, 17 Feb 2025 10:38:19 GMT</pubDate>
    </item>
    <item>
      <title>[R]区域自适应抽样：通过选择性更新高关注区域来加速扩散变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irfq36/r_regionadaptive_sampling_accelerating_diffusion/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  此处的关键贡献是扩散变压器的一种新的自适应采样方法，该方法通过基于区域重要性选择性分配注意力来降低计算。它没有平等地处理所有区域，而是确定哪些零件需要更详细的处理。 主要技术方面： - 基于预测的重要性得分 - 修改的注意力机制与与之兼容现有体系结构 - 记忆效率的自适应缓存策略 结果显示：-30-50％的计算时间减少 -  FID或剪辑分数中没有降解 - 通过自适应采样节省40％的内存 - 有效 - 在多个模型架构中有效 - 为有条件和无条件的生成工作 我认为这对于计算效率很重要的现实应用程序可能特别影响。在将资源使用量减少多达50％的同时保持质量的能力为在更适度的硬件上运行这些模型的可能性开辟了可能性。这里的原则也可能会很好地转移到选择性注意力分配可能会有所帮助的其他领域，例如视频生成或3D渲染。 我最感兴趣的是，这是如何挑战统一处理对于高质量而需要的假设。一代。通过证明我们可以选择计算分配，这表明当前架构的效率提高仍然有很大的空间。  tldr：新方法通过选择性注意重要的注意力将扩散变压器计算减少30-50％ ，没有质量损失。  完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irfq36/r_regionadaptive_sampling_accelerating_diffusion/</guid>
      <pubDate>Mon, 17 Feb 2025 09:03:14 GMT</pubDate>
    </item>
    <item>
      <title>[d] OpenAI帆布如何与Intlace人类编辑一起使用KV缓存？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irfgsc/d_how_does_openai_canvas_works_with_inplace_human/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想知道，如果openai允许它允许在内置的人类编辑，如何使用kv缓存？它是否必须使整个缓存无效到更早的文件编辑，然后必须在其余的帆布文本中执行前向通行证？ 它是否可以像所描述的图像一样起作用，或者有更好的方法将缓存保存在编辑之间但没有变化的文本中（我认为不是这样，因为隐藏的上下文会随着未来的所有代币而改变）？  https://preview.redd.it/e1ccea3zvnje1.png?width=746&amp;format=png&amp;auto= webp＆amp; s = F3848812A20F770C938B1D9B54EABAA64B07AFE5   喜欢：     line 1：def process_data（） ）第3行：y = x + 10→kv₃（意识到KV₁，kv₂）第4行：返回y→kv₄（知道kv₁，kv₂，kv₃，kv₃）现在我们编辑第2行：  现在我们编辑第2行    第1行：def Process_data（）：→KV₁（仍然有效）第2行：x = 10→KV₂&#39;（new）行3：y = x + 10→kv₃（无效！基于旧x值）第4行：返回y→kv₄（基于旧链的无效！）  有没有更聪明的方法可以逃脱较少的远期通行证？ 编辑：我现在认识到标题的差异有多糟。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/punsbymann     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1irfgsc/1irfgsc/d_how_does_openai_openai_canvas_works_with_with_with_inplace_inplace_human/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irfgsc/d_how_does_openai_canvas_works_with_inplace_human/</guid>
      <pubDate>Mon, 17 Feb 2025 08:44:48 GMT</pubDate>
    </item>
    <item>
      <title>[r]在LLM中，在哪里可以在哪里进行学习？ （神经2024）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irbjli/r_where_does_incontext_learning_happen_in_llms/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;    摘要：自我监督的大语言模型已经证明了能力要通过文本学习执行各种任务，但是对于模型将任务定位在迅速说明和演示示例方面的位置知之甚少。  在这项工作中，我们试图表征从识别任务到执行任务的大型语言模型过渡的区域。通过gptneo2.7b，bloom3b和starcoder2-7b，llama3.1-8b，llama3.1-8b-instruction，机器翻译和代码生成的一系列层面上下文掩盖实验，我们证明了A＆Met， ;任务识别;不再需要将任务编码到输入表示形式和对上下文的关注的点。 &lt; / p&gt; 在提示5个示例时，利用这种冗余的优势可节省45％的计算节省，并使用机器翻译的示例在第14/32层获得任务识别。我们的发现也对资源和参数有效微调有影响。 we observe a correspondence between fine-tuning performance of individual LoRA layers and the task recognition layers. &lt;a href=&quot;https://proceedings.neurips.cc/paper_files/paper/2024/file/3979818cdc7bc8dbeec87170c11ee340 -paper-conference.pdf“&gt; PaperLink ，提交由＆＃32; /u/u/thistory_insect668     [link]   ＆＃32;   [注释]  /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irbjli/r_where_does_incontext_learning_happen_in_llms/</guid>
      <pubDate>Mon, 17 Feb 2025 04:27:03 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何处理高度不平衡的数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ir2zm3/dhow_to_handle_highly_imbalanced_dataset/</link>
      <description><![CDATA[在解决高度不平衡数据集的社区。过去，我建立了搅动预测模型，现在我专注于预测保险索赔，在此索赔的百分比很低。 我的数据集跨越了15年，并且包含约800,000个记录，并具有具有此类功能的功能作为性别，年龄，马力，汽车品牌＆amp;类型  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sthyddoctor007     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ir2zm3/dhow_to_handle_highly_imbalanced_dataset/</guid>
      <pubDate>Sun, 16 Feb 2025 21:22:49 GMT</pubDate>
    </item>
    <item>
      <title>[d]进行原始研究的步骤（这也是一个咆哮）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqq4fz/d_the_steps_to_do_original_research_its_a_rant_as/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是英国的大师学生。我一直在阅读有关扩散的论文。我已经联系了大学的博士生，并表示对与他们合作的兴趣。我以为我会帮助他们解决他们的研究方向。但是，与他们交谈后，他们告诉我阅读一些论文，然后找到一个研究想法。  对于上下文，我正在阅读有关扩散模型的信息。我读的越多，我意识到我缺乏一些数学基础。我通过课程，书籍和文章来填补这些洞。但是，这需要时间。我相信，缺乏基本的理解使我无法提出假设。我可以通过最近的调查论文找到一些研究差距，但是我无法提出任何假设或解决方案。 我朝正确的方向前进吗？从根本的角度理解东西有助于产生新颖的研究思想吗？如何产生新颖的研究思想？如果您有一些提示，我很高兴听到它们。  P.S。我从未出版过。因此，如果我错过了一些基本的东西，我感到很抱歉。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/snoo_65491     [link]   ＆＃32;   [注释]      ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqq4fz/d_the_steps_to_do_original_research_its_a_rant_as/</guid>
      <pubDate>Sun, 16 Feb 2025 11:14:23 GMT</pubDate>
    </item>
    <item>
      <title>[P]我建立了一个开源AI代理，该代理可以完全自动编辑视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqq1vz/p_i_built_an_opensource_ai_agent_that_edits/</link>
      <description><![CDATA[   &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/comments/1iqqq1vz/p_i_built_an_opensource_aigent_ai_aigent_aigent_that_that_edits/ AI agent that edits videos fully autonomously&quot; src=&quot;https://external-preview.redd.it/aNz3BFb1ycBa55wI3LX5BuJGkVgsXAVk_7lUskfK1zk.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b072cacd407870c1166de542f8cab83d84861bf1&quot; title=&quot;[P] I构建了一个开源AI代理，该代理完全自动编辑视频“/&gt;   ＆＃32;提交由＆＃32; /u/u/umaust_instance_401     代理“&gt; [link]  ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqq1vz/p_i_built_an_opensource_ai_agent_that_edits/</guid>
      <pubDate>Sun, 16 Feb 2025 11:09:16 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会导致禁止。 鼓励其他人创建新的帖子，以便在此处发布问题！ 线程将一直活着直到下一个，因此请继续发布标题之后的发布。    meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>