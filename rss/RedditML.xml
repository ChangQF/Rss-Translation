<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sat, 01 Mar 2025 18:20:50 GMT</lastBuildDate>
    <item>
      <title>[D]我认为Doge正在使用电子邮件响应来形成培训和测试集...</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0zzfg/d_i_assume_doge_is_using_the_email_responses_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  毕竟，他们没有人能够阅读所有这些电子邮件，特别是如果运行很小的操作。  如果是这样，联邦雇员会在响应电子邮件中发出什么来扭曲集合并使其有用的用处降低？ 要求一堆朋友。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/gg1817     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0zzfg/d_i_assume_doge_is_using_the_email_responses_to/</guid>
      <pubDate>Sat, 01 Mar 2025 13:55:32 GMT</pubDate>
    </item>
    <item>
      <title>初步评级如何工作？ MIDL 2025 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0yg3c/how_does_preliminary_rating_works_midl_2025_d/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您好，最近进入出版物场景，我的第一份评论出了 -    3、3、4和3、3、3、3、2、2  对于弱拒绝的拒绝I.e.同样，对于第一篇论文，一位审稿人建议用于海报演示。 他们俩都被接受的机会有很大的机会吗？在反驳期间，很难说服审稿人？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j0yg3c/how_does_preliminary_rating_works_midl_2025_d/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j0yg3c/how_does_does_preliminary_rating_works_midl_2025_d/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0yg3c/how_does_preliminary_rating_works_midl_2025_d/</guid>
      <pubDate>Sat, 01 Mar 2025 12:31:47 GMT</pubDate>
    </item>
    <item>
      <title>[P]更新：使用Langchain和Langgraph呼吁使用DeepSeek-R1的工具：现在在打字稿中！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0wv8j/p_update_tool_calling_for_deepseekr1_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在这里发布了我在工具上创建的GitHub Repo Python软件包，呼吁使用Langchain和Langgraph进行DeepSeek-R1 671b，或更一般地用于Langchain cathopenal class in langchain cathopenal class中的任何LLMS（对于新发布的LLMS）（不支持Newly Preakain callms），该工具又支持/  https://github.com/leock.com/leockl/leockl/tool-ahead-ahead-oftime     通过社区请求，我很高兴能为此包含这个包的typepript版本。 - 在打字稿中，将工具呼叫功能的NPM套件：    https://github.com/github.com/leockl/leockl/leockl/leockl/tool-ahead-ockl/tool-ip----有帮助。享受！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lc19-     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0wv8j/p_update_tool_calling_for_deepseekr1_with/</guid>
      <pubDate>Sat, 01 Mar 2025 10:47:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] Marsopt：混合自适应随机搜索优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0vsct/r_marsopt_mixed_adaptive_random_search_for/</link>
      <description><![CDATA[       &lt;！ -  sc_off- sc_off-&gt;     marsopt （混合自适应随机搜索优化）的设计旨在解决具有多个参数类型的优化复杂系统的挑战。 The library implements an adaptive random search algorithm that dynamically balances exploration and exploitation through:  Adaptive noise for efficient parameter space sampling Elite selection mechanisms to guide search toward promising regions Integrated support for log-scale and categorical parameters Flexible objective handling (minimization or最大化）  技术突出显示 我们的基准测试表明，与Optuna的TPE Sampler相比，Marsopt的表现出色：  更快更快 href =“ https://preview.itd.it/s4nw6eehq1me1.png？ Consistently top ranks across standard black-box optimization benchmarks from SigOpt evalset   全面的变量支持 库处理现代ML管道所需的参数类型的完整频谱：     连续变量（带有可选的日志样本示例）  分类变量（带有智能表示）  实用的ML应用程序 在我们对LightGBM HyperPoReter调谐的实验中，Marsopt在加利福尼亚州住房数据集上调谐，Marsopt表现出与诸如Optiblesizeers相比的令人鼓舞的结果。库有效地处理了简单的参数空间和更复杂的方案，涉及不同的增强类型，正则化参数和采样配置。    使用Marsopt很简单：  来自Marsopt Import Intimp ofimp ofimp ofimp otim in trim imptim impor numpy作为NP DEF目标（试验：试验：试验） - ＆GT; float：lr = auggest_float（; quot; leadmood; querat＆quot;，1e-4，1e-1，log = true）layers = auggest_int（num_layers＆quot; num_layers＆quetizer＆quort＆quotizer＆quotizer = augger.suggest_categoral; “ rmsprop”]）＃您的评估逻辑在此处回报分数研究=研究（方向=“最大化”）研究。  文档： https://marsopt.readthedocs.io/      algorithm： https://marsopt.readthedocs.io/en/latest/latest/algorithm.html   href =“ https://github.com/sibirbil/marsopt”&gt; https://github.com/sibirbil/marsopt     pypi： https://pypi.org/project/project/marsopt/      我对您的反馈感兴趣，并欢迎您有关实施或绩效特征的任何问题。提交由＆＃32; /u/u/zedeleyici3401     [link]    [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0vsct/r_marsopt_mixed_adaptive_random_search_for/</guid>
      <pubDate>Sat, 01 Mar 2025 09:30:51 GMT</pubDate>
    </item>
    <item>
      <title>[R]用于数学推理的自我奖励LLM：一个自主错误检测和校正的两阶段框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0tw4n/r_selfrewarding_llms_for_mathematical_reasoning_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文引入了一种自我奖励校正机制，用于改善语言模型中的数学推理。核心想法将自我评估与迭代校正结合在一起 - 该模型学会了评估自己的解决方案并修复其确定的错误。 主要技术点： - 两阶段架构：解决方案生成：自定义奖励 - 自定义奖励功能 - 既有答案正确性和推理质量既不存在的范围 - 否则范围的范围 - 否则范围的范围 - 否定范围 - 否定范围 - 误差 - 误差 - 误解 - 误差 - 误差 - 误差 - 误差 - 全面训练 关键结果： -  15-20％的数学任务的基准精确度提高-80％的错误检测成功率 - 在算术，代数和单词问题上的出色表现 - 与基本模型相比，最小的额外培训计算 - 与基本模型相比最小的额外培训计算 - 最有效的对问题的方法尤其需要多个 我认为该方法的价值更高，因此可以不断地启动一个信息。自我纠正机制似乎可以将不仅仅是数学问题概括到需要强大推理的其他领域。 我认为，这里的真正价值是朝着可以有效地验证自己的工作而不是仅仅产生答案的模型发展。这是建立更值得值得信赖的AI系统的重要步骤。 我看到的主要限制是在解决方案中过度自信的潜力，尽管蒙特卡洛验证有助于减轻这种情况。看到这与外部验证系统结合在一起会很有趣。  tldr：结合自我奖励和数学推理的迭代校正的新方法。模型学会检查并修复自己的工作，并通过强误检测获得15-20％的准确性提高。  完整的总结在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0tw4n/r_selfrewarding_llms_for_mathematical_reasoning_a/</guid>
      <pubDate>Sat, 01 Mar 2025 07:14:55 GMT</pubDate>
    </item>
    <item>
      <title>[d]“反向传播：差异规则[第3部分]的视觉解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0ez5y/d_visual_explanation_of_backpropagation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi，  i先前在此处共享了第1部分和第2部分：  第1部分： https://www.reddit.com/r/machinelearning/comments/1irs3gn/d_visal_explanation_of_backpropagation/   第2部分： https://www.reddit.com/r/machinelearning/comments/1iy0d47/d_visual_explanation_of_backpropagation_forward/     这是第3部分我在其中分享了如何使用计算图从scratch中得出差异规则。 xi（x）= x。我发现它很有趣，因此共享。 谢谢，  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/madiyar     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0ez5y/d_visual_explanation_of_backpropagation/</guid>
      <pubDate>Fri, 28 Feb 2025 18:42:46 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何写数学大型ML论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0efdm/d_how_do_you_write_math_heavy_ml_papers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在ICLR/neurips/icml上发表理论ML论文或数学繁重论文的人，您如何撰写数学繁重的论文？编写方法部分的策略是什么？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/antelopewilling2928     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0efdm/d_how_do_you_write_math_heavy_ml_papers/</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:43 GMT</pubDate>
    </item>
    <item>
      <title>[D]需要建议产品销售预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j08yd2/d_in_need_of_advice_for_product_sales_forecasting/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我是一名本科生，他最近的任务是开发咖啡连锁店的销售预测模型，以预测下一份一年的所有商店中所有饮料的销售额，包括200多个销售商品，超过200个销售商品和250多个产品代码。当我打算使用Sarimax时，我认为在插座和产品上执行时间序列群集（使用Tslearn库中的Limeserieskmeans），以确保每个集群中的销售模式与提高模型的准确性相似。最初的计划是首先根据其销售方式聚类，然后将产品聚集在那些插座中。 ，但是我被告知其他出口特征（例如出口类型，出口类型，出口场地，城市）可能会对出口之间的销售产生更大的影响。时间序列聚类或通过出口特征进行聚类或聚类是否更有意义？提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j08yd2/d_in_ine_need_need_of_advice_for_for_product_sales_sales_forecasting/”&gt; [link]        [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j08yd2/d_in_need_of_advice_for_product_sales_forecasting/</guid>
      <pubDate>Fri, 28 Feb 2025 14:30:23 GMT</pubDate>
    </item>
    <item>
      <title>[d]减少随机森林训练时间</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j07uh4/d_reduce_random_forest_training_time/</link>
      <description><![CDATA[Hi everyone, I wonder when running a backtest on AWS with a 64 cores machine how would you decrease the training time ? The dataset isn’t very big but when running on my cloud it could take up to 1 day to backtest it. I’m curious to see what kind of optimisation can be made.  nb：平行编程已经在Python代码上使用，并且应该不变的树的数量。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/konni_algo     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j07uh4/d_reduce_random_forest_training_time/</guid>
      <pubDate>Fri, 28 Feb 2025 13:38:06 GMT</pubDate>
    </item>
    <item>
      <title>[R]动态词汇课程学习提高LLM训练效率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j04bwb/r_dynamic_vocabulary_curriculum_learning_improves/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了一种新颖的LLM预培训方法，该方法使用课程学习进行词汇扩展。该模型没有从一开始就开始词汇进行完整的词汇训练，而是从较小的高频词汇开始，在训练过程中逐渐扩展。 关键技术要点： - 从〜5k最频繁的代币开始，最常见的代币，扩展到完整的词汇（〜50k词）（〜50k代币），而不是训练 - 基于模型的扩展 - 维持型号的时间表 - 维护时间表的时间表 - 维持时间表的时间表 - 维持时间表的时间表，以供应量的时间表，以实现计时量的时间表，以验证时间表 - 维持时间表的时间表，以供应量表。在早期阶段的未使用令牌 - 在125m到7b参数之间进行测试的模型测试 结果：-25％的总训练时间减少了总训练时间以达到等效性能 - 在早期训练中没有明显的模型使LLM培训更容易被计算资源有限的研究人员访问。用较小的初始词汇进行有效训练的能力可以在早期开发阶段进行更多的实验和迭代。 我认为最有趣的方面是如何挑战模型从开始时需要完全词汇的假设。结果表明，首先构建共同令牌的有力表示可能实际上可能对整体模型开发有益。 我看到的主要限制是该方法主要是在英语模型上测试的。需要进行更多的研究来验证具有不同结构特征的多语言模型或语言的益处。  tldr：LLM期间LLM预训练期间进行的循序渐进的词汇扩展可将培训时间降低25％，而不会损害模型质量，而不会损害课程学习，这表明课程学习可以使LLM培训更有效。 href =“ https://aimodels.fyi/papers/arxiv/scaling-llm-pre-training-training-vocabulary-curriculum”&gt;完整的摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j04bwb/r_dynamic_vocabulary_curriculum_learning_improves/</guid>
      <pubDate>Fri, 28 Feb 2025 10:03:27 GMT</pubDate>
    </item>
    <item>
      <title>[r]找到一个用于症状疾病预测的好数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j03n2h/r_finding_a_good_dataset_for_symptombased_disease/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我希望你过得愉快。目前，我在BSIT第二届SEM中是第三年，而我的顶峰论文是关于基于Web的机器学习，可以通过输入症状来预测患者的疾病。具体来说，我专注于小儿呼吸道疾病，以便可以缩小研究范围。但是现在，我真的试图通过网上找到一个很好的数据集，我也试图在附近的诊所合作，但仍然没有运气，他们说他们的数据集是私人的，看来他们不够信任我可以使用他们的数据集，这是可以理解的。 我没有一个人要求我的关注点，所以我在这里愿意在这里找到一个好人，我会在这里找到一个好人，我可以在这里找到一个愿望我的愿望。我只需要一个好数据集来训练我的模型，我将进行所有清洁。 谢谢您阅读我的帖子并度过了美好的一天！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/factary-factor-624     [link]       &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j03n2h/r_finding_a_good_good_dataset_for_symptompompompompompompassed_disease/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j03n2h/r_finding_a_good_dataset_for_symptombased_disease/</guid>
      <pubDate>Fri, 28 Feb 2025 09:11:30 GMT</pubDate>
    </item>
    <item>
      <title>[R]无训练的色度键含量含量生成扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j00bbs/r_trainingfree_chroma_key_content_generation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们很高兴地宣布我们的论文“ tkg-dm：无训练的色彩键含量含量的含量生成扩散模型” 已被接受 cvpr 2025！ href =“ https://arxiv.org/abs/2411.15580”&gt; https://arxiv.org/abs/2411.15580    &gt;              dr：我们引入了 tkg-dm “ difunige difful&gt; difudion difful&gt; difudy diffff infort   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/maleficent_stay_7737      [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j00bbs/r_trainingfree_chroma_key_content_generation/</guid>
      <pubDate>Fri, 28 Feb 2025 05:18:11 GMT</pubDate>
    </item>
    <item>
      <title>[r]信仰状态变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izs7c8/r_belief_state_transformers/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/rajonrondoisturtle     [link]&gt; [link]&gt; [link]&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izs7c8/r_belief_state_transformers/</guid>
      <pubDate>Thu, 27 Feb 2025 22:19:57 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子以便在此处发布的新帖子的人！ 线程将活着直到下一个，因此请继续发布标题的日期之后。 感谢大家在上一个线程中回答了上一个线程中的问题！  &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iwdbgs/d_simple_questions_thread/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 23 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>