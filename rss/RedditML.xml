<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 13 Feb 2025 15:18:11 GMT</lastBuildDate>
    <item>
      <title>[D] 推理 LLM 能否帮助我们更好地识别相关作品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iol1qd/d_could_reasoning_llms_help_use_identify_relevant/</link>
      <description><![CDATA[我知道有很多有用的服务可以帮助你消化 arXiv 中的最新论文，例如 arxiv-sanity、paper digest、arXivist、IArxiv 等。他们中的大多数都使用 ML（TF-IDF）根据你的兴趣对论文进行排名，但即使有了他们的帮助，我仍然被论文淹没了。 大多数工具都是在 LLM 之前构建的（尤其是预推理模型），你们认为推理 LLM 是否可以更好地帮助我们从 arXiv 每日出版中识别相关作品？ 或者你听说过任何现有的方法？    提交人    /u/MadEyeXZ   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iol1qd/d_could_reasoning_llms_help_use_identify_relevant/</guid>
      <pubDate>Thu, 13 Feb 2025 15:05:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 企业中的文本转 SQL：比较方法以及对我们有效的方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iojc1f/r_texttosql_in_enterprises_comparing_approaches/</link>
      <description><![CDATA[      大家好！ 文本转 SQL 是一种流行的 GenAI 用例，我们最近与一些企业合作开发了它。在这里分享我们的经验！ 这些企业已经尝试了不同的方法——使用 O1 等最佳 LLM、将 RAG 与 GPT-4o 等通用 LLM 结合使用，甚至使用 AutoGen 和 Crew 的基于代理的方法。但它们的准确率达到了 85% 的上限，响应时间超过 20 秒（主要是由于列名错误导致的错误），并且处理了使扩展变得困难的复杂工程。 我们发现，对特定于业务的查询-SQL 对进行开放权重 LLM 微调可实现 95% 的准确率，将响应时间缩短至 7 秒以下（通过消除故障恢复），并简化了工程。这些定制的 LLM 保留了域内存，从而带来了更好的性能。 我们在medium上对所有尝试过的方法进行了比较。请让我知道您的想法，如果您发现更好的方法来解决这个问题。 https://preview.redd.it/kqfabsdkuwie1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=88251e0cfa246f2bf1f779e708ab03a96a3c0255    提交人    /u/SirComprehensive7453   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iojc1f/r_texttosql_in_enterprises_comparing_approaches/</guid>
      <pubDate>Thu, 13 Feb 2025 13:44:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用在线图像自收集数据集的许可证问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ioj5ij/d_license_issue_with_selfcollected_dataset_using/</link>
      <description><![CDATA[因此，我正在通过收集和注释在线图像来处理数据集。不幸的是，并非所有图像都受 CC 许可。在发布的数据集中仅包含这些图像的链接是否合适？（比如这是否被视为合理使用，还是会引起麻烦？）是否有任何流行的公共图像数据集（包括不受 CC 许可的图像）可供我参考？我对这些与版权相关的事物非常不熟悉，因此如果我在问题描述中犯了任何错误，请提前道歉。    提交人    /u/RepresentativeAd985   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ioj5ij/d_license_issue_with_selfcollected_dataset_using/</guid>
      <pubDate>Thu, 13 Feb 2025 13:34:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自动化能力发现：使用基础模型自我探索和评估人工智能能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iofk29/r_automated_capability_discovery_using_foundation/</link>
      <description><![CDATA[本文介绍了一个名为自动能力发现 (ACD)的框架，该框架使用一个基础模型来系统地探索和评估另一个模型的能力。核心思想是将能力发现视为一门实验科学，其中一个模型充当科学家生成假设和设计测试。 关键技术点： - 框架由四个主要组件组成：任务生成、执行、评估和分析 - 使用提示策略使评估器模型生成多样化、有意义的测试 - 实现反馈循环，其中测试结果为未来的任务生成提供信息 - 评估包括二元成功/失败和详细分析 - 在 GPT-4、Claude 和 Llama 模型上作为评估者和主体进行测试 结果： - 发现了数千种以前未记录的能力 - AI 评估者和人工验证在能力评估方面的一致性为 89% - 生成的测试涵盖了从基础（算术）到复杂（创意写作）的广泛能力类别 - 成功识别了已知的模型局限性 - 显示出自动和手动评估方法之间的很强的相关性 我认为这种方法可以改变我们理解和评估人工智能系统的方式。我们可以持续、自动地探索模型能力，而不是仅仅依赖预定义的基准或手动测试。这对于快速测试新模型和识别意外的能力或局限性尤其有价值。 我认为主要的挑战是确保评估模型不受与主题模型相同的盲点限制。还有一个问题是，这在语言模型之外推广到其他人工智能架构的效果如何。 TLDR：新框架使用人工智能模型自动发现和评估其他人工智能模型的能力，与人类评估显示出很强的一致性，并发现了数千种以前未知的能力。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iofk29/r_automated_capability_discovery_using_foundation/</guid>
      <pubDate>Thu, 13 Feb 2025 09:43:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要针对 2025 年图像分类问题的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iocgvg/d_need_suggestions_for_image_classification/</link>
      <description><![CDATA[早在 2022 年末，我就使用 EfficientNet_V2 训练了一个图像分类模型（医学图像，高分辨率），数据量约为 20k。现在我想重新训练模型，因为我可以访问大量数据（~300k）。我想征求一些建议。  我以前尝试过使用 ViT，但它的性能相对较差。我以前读过一些评论，说 ViT 在处理高分辨率图像方面存在一些问题。但现在我注意到 Nvidia 在 DLSS 上使用 Transformer。我认为高分辨率不再是 ViT 的问题。建议尝试哪种图像分类 ViT 模型？ 我一直使用预训练权重作为起点并进行微调，因为我读过的许多文章/在线信息都告诉我这样做，而且它确实表现更好。 2025 年还建议使用预训练权重吗？尤其是大多数图像模型都是在低分辨率数据（224-512）上训练的，而我的数据集是高分辨率的。 CNN 在 2025 年过时了吗？我认为 CNN 和 Transformer 在图像相关问题上的竞争在 2023 年还不明朗。但从 2024 年中期开始，我看到很多人说 Transformer 赢了。     提交人    /u/Eternal1314   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iocgvg/d_need_suggestions_for_image_classification/</guid>
      <pubDate>Thu, 13 Feb 2025 05:55:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 弱到强泛化中使用的 PGR 度量的探究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iocdb5/d_inquiry_on_pgr_metric_used_in_weak_to_strong/</link>
      <description><![CDATA[不确定这是否是合适的 subreddit，但我对 从弱到强的泛化 论文有一个问题。论文中的实验测量了 PGR，它比较了较强模型在针对较弱模型的标签进行训练后的相对性能与较弱模型在各种任务中的表现。  只衡量基础强模型的性能提升不是更合适吗？这是因为这篇论文试图将其类比为人类协调更强大的人工智能系统，因此更关心相对于人类的性能提升吗？    提交人    /u/nyesslord   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iocdb5/d_inquiry_on_pgr_metric_used_in_weak_to_strong/</guid>
      <pubDate>Thu, 13 Feb 2025 05:49:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为不规则时间序列数据创建因果 DAG</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1io7zrf/d_creating_a_causal_dag_for_irregular_timeseries/</link>
      <description><![CDATA[大家好， 我最近发表了一篇关于使用不规则时间序列数据进行因果推断的文章。我喜欢使用动态贝叶斯网络来做这件事的想法，因此我将问题改写为这个。 有人建议使用 SSM。据我所知，当它被离散化时，它可以表示为 DAG？然后我有一个结构来表示这些因果关系。 我最初偶然发现了这篇有趣的论文：https://arxiv.org/pdf/2312.09604，它似乎不适用于不规则的采样分辨率。 非常感谢！    提交人    /u/Sea_Farmer5942   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1io7zrf/d_creating_a_causal_dag_for_irregular_timeseries/</guid>
      <pubDate>Thu, 13 Feb 2025 01:47:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有没有关于如何将 CV 和 NetCDF 文件合并在一起的好书/教程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1io7lri/r_is_there_any_good_bookstutorials_on_combining/</link>
      <description><![CDATA[嗨，我必须做机器学习模型。在组合数据的过程中，我使用 CSV 文件做得很好，但是 NetCdf。我只是迷茫了，不知道从哪里开始学习将它们组合在一起。 任何建议都会有所帮助    提交人    /u/Necessary-Arm-6055   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1io7lri/r_is_there_any_good_bookstutorials_on_combining/</guid>
      <pubDate>Thu, 13 Feb 2025 01:27:43 GMT</pubDate>
    </item>
    <item>
      <title>[R]“o3 在 2024 年 IOI 上获得金牌，并获得与人类精英竞争对手相当的 Codeforces 评级”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1io4c7r/r_o3_achieves_a_gold_medal_at_the_2024_ioi_and/</link>
      <description><![CDATA[使用大型推理模型进行竞争性编程 OpenAI 我们表明，将强化学习应用于大型语言模型 (LLM) 可显著提高复杂编码和推理任务的性能。此外，我们将两个通用推理模型 - OpenAI o1 和 o3 的早期检查点 - 与领域特定系统 o1-ioi 进行了比较，后者使用专为参加 2024 年国际信息学奥林匹克 (IOI) 而设计的手工设计的推理策略。我们在 IOI 2024 上与 o1-ioi 进行了现场比赛，并使用手工制作的测试时间策略，排名在第 49 个百分位。在放宽竞争限制的情况下，o1-ioi 获得了金牌。然而，在评估 o3 等后期模型时，我们发现 o3 在没有手工制作领域特定策略或放宽限制的情况下获得了金牌。我们的研究结果表明，尽管 o1-ioi 等专用管道取得了显著的改进，但扩展的通用 o3 模型无需依赖手工制作的推理启发式方法即可超越这些结果。值得注意的是，o3 在 2024 年 IOI 上获得金牌，并获得与人类精英竞争对手相当的 Codeforces 评级。总体而言，这些结果表明，扩展通用强化学习，而不是依赖特定领域的技术，为在推理领域（例如竞争性编程）中实现最先进的 AI 提供了一条稳健的道路。 https://arxiv.org/abs/2502.06807    提交人    /u/we_are_mammals   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1io4c7r/r_o3_achieves_a_gold_medal_at_the_2024_ioi_and/</guid>
      <pubDate>Wed, 12 Feb 2025 22:55:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进行微调，用更简单的激活代替复杂的激活</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inyd67/d_finetuning_to_replace_complicated_activations/</link>
      <description><![CDATA[考虑以下问题。我想在不支持某些激活层的加速器硬件上运行预训练网络进行推理。是否有成熟的技术可以微调权重，以便它们可以与其他激活函数一起使用？ 假设网络是使用 SeLU 的 EfficientNet。我能否以某种方式微调权重以适应 ReLU 或 GeLU 激活？我不想从头开始重新训练。    提交人    /u/bjourne-ml   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inyd67/d_finetuning_to_replace_complicated_activations/</guid>
      <pubDate>Wed, 12 Feb 2025 18:47:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] TAID：时间自适应插值蒸馏，用于语言模型中的高效知识转移</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1invg9p/r_taid_temporally_adaptive_interpolated/</link>
      <description><![CDATA[    /u/hardmaru   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1invg9p/r_taid_temporally_adaptive_interpolated/</guid>
      <pubDate>Wed, 12 Feb 2025 16:51:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新论文：前沿模型能否以开放的方式自我探索并发现自己的能力？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inv1gy/r_new_paper_can_frontier_models_selfexplore_and/</link>
      <description><![CDATA[      标题：通过模型自我探索实现自动能力发现 作者： Cong Lu、Shengran Hu、Jeff Clune。 论文： https://arxiv.org/abs/2502.07577 摘要：基础模型已成为通用助手，通过对网络规模数据进行训练，在众多领域展现出多样化的能力。准确描述任何新模型的全部能力和潜在风险中的哪怕一小部分仍然具有挑战性。现有的评估方法通常需要大量的人力，而且需要付出越来越多的努力来为更强大的模型设计更艰巨的挑战。我们引入了自动能力发现 (ACD)，这是一个框架，它将一个基础模型指定为科学家，以系统地提出探索主题模型（可能是它本身）能力的开放式任务。通过将前沿模型与开放性领域的想法相结合，ACD 可以自动且系统地发现主题模型中令人惊讶的能力和失败。我们在一系列基础模型（包括 GPT、Claude 和 Llama 系列）中展示了 ACD，表明它会自动揭示任何单个团队都难以发现的数千种能力。我们通过广泛的人工调查进一步验证了我们方法的自动评分，观察到模型生成的评估和人工评估之间高度一致。通过利用基础模型创建任务和自我评估的能力，ACD 朝着可扩展、自动评估新型 AI 系统迈出了重要一步。 https://preview.redd.it/1zamtbjzjqie1.png?width=1204&amp;format=png&amp;auto=webp&amp;s=95c177136d8c77abd0b8fb4fda3d8d7f01b7a04f    提交人    /u/MolassesWeak2646   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inv1gy/r_new_paper_can_frontier_models_selfexplore_and/</guid>
      <pubDate>Wed, 12 Feb 2025 16:34:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 作为多语言文本解毒的少样本数据注释器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1innuh3/r_llms_as_fewshot_data_annotators_for/</link>
      <description><![CDATA[本文介绍了一种使用 LLM 作为小样本学习器来生成高质量并行数据集进行文本解毒的方法。关键创新是使用现代 LLM 创建配对的有毒/无毒文本示例，在降低毒性的同时保持语义含义。 主要技术要点： - 使用精心策划的示例对进行小样本提示 - 实现多阶段过滤以确保质量 - 使用自动化指标验证语义保存 - 与现有方法相比，在保持含义的同时实现更好的毒性降低 - 创建比以前的方法更大、更高质量的并行数据集 结果： - 在标准基准上优于现有的解毒模型 - 显示出强大的跨领域泛化能力 - 仅用 3-5 个例子就证明了有效性 - 保持语义相似度得分 &gt;0.85 - 在测试集上将毒性得分降低 &gt;60% 我认为这对于需要在删除有害内容的同时保留含义的内容审核系统特别有价值。生成高质量并行数据的能力可以帮助训练更好的下游解毒模型。 我认为小样本方法特别有前景，因为它减少了对大型带注释数据集的需求，而手动创建这些数据集既昂贵又耗时。 TLDR：现代 LLM 可以使用小样本学习生成高质量的并行有毒/无毒文本对，从而为解毒系统提供更好的训练数据，同时保持语义含义。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1innuh3/r_llms_as_fewshot_data_annotators_for/</guid>
      <pubDate>Wed, 12 Feb 2025 10:17:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>