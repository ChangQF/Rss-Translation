<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Thu, 22 Aug 2024 15:18:18 GMT</lastBuildDate>
    <item>
      <title>[P] 论文主题是运动规划，但想包含机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eylej1/p_thesis_in_motion_planning_but_want_to_include/</link>
      <description><![CDATA[大家好， 我正在做一篇关于运动规划四旋翼飞行器的论文（模型预测控制、经典计算机视觉、卡尔曼滤波器、A* 等）。我学过 DL、ML、CV 和 AI 课程。但是我想做一名机器学习工程师。如果我的论文中没有机器学习，我找到一份工作的几率有多大？ 我总是可以利用我的论文和机器学习来处理视觉或点云，并将这些项目添加到我的 github 和博客上。 你有什么建议给我？    提交人    /u/Huge-Leek844   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eylej1/p_thesis_in_motion_planning_but_want_to_include/</guid>
      <pubDate>Thu, 22 Aug 2024 14:56:03 GMT</pubDate>
    </item>
    <item>
      <title>使用预训练模型的 AI 管理紧急文档</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyktbb/ai_managed_emergency_documentation_with_a/</link>
      <description><![CDATA[  由    /u/Barqawiz_Coder  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyktbb/ai_managed_emergency_documentation_with_a/</guid>
      <pubDate>Thu, 22 Aug 2024 14:31:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 需要建议：为智能农业初创企业开发计算机视觉模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyk7jr/p_advice_needed_developing_computer_vision_models/</link>
      <description><![CDATA[      大家好， 我是一名初级工程师，最近被一家专门从事水培和鱼菜共生温室的智能农业初创公司聘用。他们希望整合计算机视觉模型来检测植物病虫害。我的任务是开发这些视觉模型，但我面临一些挑战： 问题：  缺乏数据：公司没有足够的图像，可用的图像似乎不适合这项任务。 图像质量低：提供的图像分辨率非常低（植物片段只有大约 40x40 像素）。  我提出的解决方案：两级级联网络：  异常检测网络：识别有潜在问题的区域（健康区域与不健康区域），理想情况下生成分割图。 分类网络：分析问题区域的特写图像并对特定疾病进行分类。  潜在问题：  图像分辨率：当前图像质量似乎太低，无法获得准确的结果。 植物生长周期：异常检测网络需要考虑植物生长过程中的正常尺寸差异增长，避免误报。  我附加了示例图像来说明数据质量问题。 我将非常感激您能提供的任何建议或意见，以帮助这位初级工程师应对这一挑战。提前感谢您的帮助！ 样本 1 - 裁剪 1  样本 1 样本 2 样本 1 - 裁剪 2    提交人    /u/Hot_Dirt718   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyk7jr/p_advice_needed_developing_computer_vision_models/</guid>
      <pubDate>Thu, 22 Aug 2024 14:06:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪个行业的数据最差？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyj7vq/d_what_industry_has_the_worst_data/</link>
      <description><![CDATA[好奇地想听听——您认为哪个行业的 ML 数据质量一贯最差？ 我说的不是没有现实和可预见的 ML 应用的个别工作，比如木工。我说的是更大的行业，银行业、制药业、电信业、科技业（可能有点广泛）、农业、采矿业等等。 谁是陷得最深的？    提交人    /u/Standard_Natural1014   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyj7vq/d_what_industry_has_the_worst_data/</guid>
      <pubDate>Thu, 22 Aug 2024 13:23:20 GMT</pubDate>
    </item>
    <item>
      <title>将手写内容转换为文字 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyj399/convert_handwritten_to_text_written_p/</link>
      <description><![CDATA[嗨，如何将手写内容转换为文本，我尝试使用 paddle ocr、tesseract 等，但没有得到好的结果，所以经过一番挖掘，我发现了 TrOCR，它不知道如何针对多种语言的手写内容进行微调。寻求指导甚至项目构建。    提交人    /u/LahmeriMohamed   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyj399/convert_handwritten_to_text_written_p/</guid>
      <pubDate>Thu, 22 Aug 2024 13:17:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为 MLE/数据工程师/数据科学家，您最不喜欢的工作部分是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyibmw/d_whats_least_favorite_part_of_your_job_as_an/</link>
      <description><![CDATA[当我梦想成为一名机器学习工程师时，我没有想到监控和调试性能回归、回填数据或执行迁移/模型会占用我相当一部分时间。 你的工作中哪一点让你早上起床有点困难？    提交人    /u/skeltzyboiii   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyibmw/d_whats_least_favorite_part_of_your_job_as_an/</guid>
      <pubDate>Thu, 22 Aug 2024 12:41:48 GMT</pubDate>
    </item>
    <item>
      <title>认知不确定性真的能反映模型的状态吗?[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyeyed/epistemic_uncertainty_really_could_reflect_the/</link>
      <description><![CDATA[我尝试使用 MC dropout 或者 deep ensemble 来获取每个 epoch 之后的认知不确定性（假设这是一个回归任务，我直接通过 output.std() 来量化不确定性）。我记录了每个 epoch 之后的不确定性，最后将其绘制成一条曲线，结果是数值会有一个快速上升然后缓慢下降的趋势（看起来很直观(?)）。但是这条曲线会不断波动，它并不是一条稳定的曲线。这让我很疑惑，为什么在不断增加 epoch 的训练过程中，模型的不确定性（episodic 不确定性）会如此不稳定？使用 output.std() 作为依据时也是这样吗？    submitted by    /u/Ok-Marsupial6206   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyeyed/epistemic_uncertainty_really_could_reflect_the/</guid>
      <pubDate>Thu, 22 Aug 2024 09:26:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] Yolov8 的替代品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyes8d/d_yolov8_alternatives/</link>
      <description><![CDATA[我目前正在使用 Yolov8 进行一些对象检测和分类任务。总的来说，我喜欢它的准确性和速度。但它是经过许可的。有哪些可以同时提供检测和分类功能的免费替代品？    提交人    /u/Powerful-Angel-301   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyes8d/d_yolov8_alternatives/</guid>
      <pubDate>Thu, 22 Aug 2024 09:14:30 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 通过梯度下降进行上下文学习 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eybxel/transformers_learn_incontext_by_gradient_descent_r/</link>
      <description><![CDATA[      有人能帮助我理解论文Transformers learn in-context by gradient descent中的推理吗？作者首先假设一个带有某个权重 \（W\）的“参考”线性模型，然后证明该模型在梯度下降步骤后的损失等于“转换后的数据”的损失。然后，在主要结果（命题 1）中，作者手动构建了 \（K\）、\（Q\）和 \（V\）的权重，使得单头注意层的前向传递将所有标记映射到此“转换后的数据”。 我的问题是：这种构造如何“证明”Transformers 可以在上下文学习（ICL）中执行梯度下降？前向传递的输出（即“转换后的数据”）是否被视为新的预测？我认为应该是这样的：新的预测与更新后的权重给出的预测相匹配。我无法理解这里的逻辑。 https://preview.redd.it/cztva19y05kd1.png?width=1046&amp;format=png&amp;auto=webp&amp;s=0196944994516f480670ba9d29be91f8f55fc6f9 https://preview.redd.it/oihuv48405kd1.png?width=1728&amp;format=png&amp;auto=webp&amp;s=8cfc35bf8aa433d53f9d7b5bc5faef3c3e4fba8a    提交人    /u/mziycfh   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eybxel/transformers_learn_incontext_by_gradient_descent_r/</guid>
      <pubDate>Thu, 22 Aug 2024 05:56:07 GMT</pubDate>
    </item>
    <item>
      <title>利用 HuggingFace GPT 模型构建学术错误信息检测器的可行性 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ey9fiy/feasibility_of_using_huggingface_gpt_model_to/</link>
      <description><![CDATA[大家好， 我正在开展一个与 GPT 相关的个人项目，旨在识别学术内容中的错误信息。我们的想法是使用 GPT-2 XL 检查学术文本中的主张，并生成超越简单分类的输出，提供更多与上下文相关的内容。 例如，如果研究论文中的主张指出“某种特定药物已被证明可有效治疗某种疾病”，该模型将使用与该主题相关的其他学术论文的文本，并生成详细的输出，根据证据支持或反驳该主张，并附上简要说明。这个想法是使用滑动窗口来分析其他研究论文的文本内容，以符合文本输入的限制。 我只能访问 RTX GeForce 3060 GPU（12 GB 内存），虽然 GPT-2 XL 在我的设置上运行高效，但我注意到输出质量相当差。 我正在考虑在专注于学术语言和错误信息的自定义数据集上对 GPT-2 XL 进行微调，以提高其在此特定任务中的表现。但是，考虑到我的局限性，我担心可行性。 为此目的在 RTX 3060 上对 GPT-2 XL 进行微调是否可能/实用，或者该过程的计算成本是否太高？    提交人    /u/Mental-Particular104   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ey9fiy/feasibility_of_using_huggingface_gpt_model_to/</guid>
      <pubDate>Thu, 22 Aug 2024 03:30:23 GMT</pubDate>
    </item>
    <item>
      <title>PINNs - 重力反演问题 [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ey7jw9/pinns_gravity_inversion_problem_project/</link>
      <description><![CDATA[我正在尝试使用 DeepXDE 或其他库来解决重力反演问题。简而言之，我有一个 3D“网格”上方的表面重力观测数据，然后我想使用 PINN 来拟合此网格中的密度模型，当模拟表面接收器的重力响应时，它会与观察到的重力数据相吻合。我已使用以下代码作为框架，但损失函数是静态的。为什么我的损失函数没有变化，我该如何改进我的合成数据代码？ import numpy as np import tensorflow as tf import deepxde as dde from discretize import TensorMesh from SimPEG.potential_fields import grave from SimPEG import map from discretize.utils import mkvc, active_from_xyz import matplotlib.pyplot as plt 定义 PINN 模型 def grave_pde(x, y,receiver_locations, perceived_gravity): G = 6.67430e-11 # 引力常数 计算源点和接收器位置之间的距离 r = tf.sqrt(tf.reduce_sum(tf.square(x[:, None, :] -receiver_locations[None, :, :]), axis=2) + 1e-6) 通过对所有源点的贡献求和来计算预测重力 pred_gravity = G * tf.reduce_sum(y / (r**3), axis=0) 确保 pred_gravity 的形状为 (256, 1) 以匹配 perceived_gravity pred_gravity = tf.reshape(pred_gravity, [-1, 1]) 减去觀察到的重力 fitting_residual = pred_gravity - perceived_gravity return fitting_residual def build_pinn_model(grid_size, perceived_gravity,receivers_locations): geom = dde.geometry.geometry_3d.Cuboid([0, 0, 0], [grid_size, grid_size, grid_size]) 创建 PDE 数据对象 def grave_pde_with_receivers(x, y): return grave_pde(x, y,receivers_locations,observed_gravity) data = dde.data.PDE( geom,  gravity_pde_with_receivers,  [],  num_domain=100,  num_boundary=10,  train_distribution=&quot;uniform&quot; ) 简单的神经网络 net = dde.maps.FNN([3] + [64] * 3 + [1], &quot;relu&quot;, &quot;He normal&quot;) model = dde.Model(data, net) model.compile(optimizer=&quot;adam&quot;, lr=0.0001) 返回模型 if __name__ == &quot;__main__&quot;: grid_size = 16 模拟一些重力数据 observed_gravity = np.random.normal(0, 1, size=(256, 1)) 用于测试的随机接收器位置 receiver_locations = np.random.rand(256, 3) * grid_size 构建并训练模型 pinn_model = build_pinn_model(grid_size, perceived_gravity,receiver_locations) pinn_model.train(epochs=1000) 测试预测 coords = np.array([(i, j, k) for i in range(grid_size) for j in range(grid_size) for k in range(grid_size)]) pred_density_grid = pinn_model.predict(coords).reshape((grid_size, grid_size, grid_size)) 可视化预测密度 plt.figure() plt.imshow(pred_density_grid[grid_size // 2, :, :], cmap=&quot;viridis&quot;) plt.colorbar(label=&quot;Density&quot;) plt.title(&quot;预测密度横截面&quot;) plt.show()    提交人    /u/BitcoinBeers   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ey7jw9/pinns_gravity_inversion_problem_project/</guid>
      <pubDate>Thu, 22 Aug 2024 01:57:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找长文本的有效共指解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1exzq7r/d_looking_for_an_efficient_coreference_solution/</link>
      <description><![CDATA[我希望创建一个利用共指提取长篇小说中人物提及列表的工具。我是 AI/ML 的新手，所以想评估一下这种确切场景是否可能实现。 给定一个长文本（最多 50 万字），我想收集一个可能涵盖整个文本的人物提及列表。例如，一个人物可能会在第一章（“亚瑟王子”）中以名字介绍，然后在最后一章（“王子”）中引用 30 万字。 除此之外，我希望该模型能够实现渐进式共指解析。我的意思是，如果初始文本的共指解析需要（例如） 15 分钟，那么当我在小说中间编辑一个句子时，模型应该能够在更短的时间内重新计算共指，也许可以利用初始解析并“添加”它。 到目前为止，我已经尝试了两种模型：  CoreNLP fastcoref  尽管 fastcoref 的文档说它可以处理任何长度的文本，但我发现它们的速度或内存效率都不足以处理这么长的文本。 如果现有的共指解析模型不支持这种用例，那么是否存在允许实现这一点的行业标准技术？例如，我正在考虑对文本进行分块并对各个块运行共引用，例如： 块 1：[亚瑟是王子。] 块 2：[王子用剑战斗。] 块 3：[他每场战斗都获胜。] 在上面的例子中，如果我对块 1 和块 2 运行共引用，“亚瑟”和“王子”将被归类为同一实体。如果我随后对块 2 和块 3 运行共引用，“王子”和“他”也将被归类在一起。因此，如果“亚瑟”=“王子”且“王子”=“他”，那么“他” = &quot;Arthur&quot;。 上述场景的问题在于，在小说中，提及可能跨越数千个单词，这会增加块的大小。此外，需要提前选择块大小，如果块大小太小，我将丢失提及。 我也考虑过对各个章节运行共引用并合并结果，但是这样我可能会丢失各章节的提及。 有人对此有什么想法吗？    提交人    /u/andreacerasoni   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1exzq7r/d_looking_for_an_efficient_coreference_solution/</guid>
      <pubDate>Wed, 21 Aug 2024 20:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] Formatron：一个高性能的约束解码库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1exwgx6/p_formatron_a_highperformance_constrained/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1exwgx6/p_formatron_a_highperformance_constrained/</guid>
      <pubDate>Wed, 21 Aug 2024 18:02:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 18 Aug 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>