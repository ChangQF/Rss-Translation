<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 18 Sep 2024 12:30:57 GMT</lastBuildDate>
    <item>
      <title>[D] 经过几个月的努力，我开发了一款 iOS 应用，让用户可以监控他们的服务，包括 API、网页和服务器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fjrht9/d_after_months_of_hard_work_i_developed_an_ios/</link>
      <description><![CDATA[大家好， 经过数月的辛勤工作，我刚刚推出了我的第一个应用程序 Timru Monitor。这款 iOS 应用程序旨在帮助用户轻松监控其网站、API、服务器和端口的可用性和性能。它设置简单，如果出现任何问题，您可以收到通知。您还可以在添加新服务时定义通知的自定义阈值。 我希望您尝试一下并分享您的反馈，以帮助我进一步微调应用程序。 提前致谢！ 在 iOS 上下载 Timru Monitor：https://apps.apple.com/app/timru-monitor/id6612039186    提交人    /u/Similar_Bad_3120   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fjrht9/d_after_months_of_hard_work_i_developed_an_ios/</guid>
      <pubDate>Wed, 18 Sep 2024 12:24:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 开源 LLM 评估工具新版本发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fjr6w1/p_new_release_for_open_source_llm_evaluation_tool/</link>
      <description><![CDATA[      大家好！我们发布了新版 Ollama Grid Search，所有主要平台均可下载。 对于那些不熟悉的人，这是一个多平台桌面应用程序，用于评估和比较 LLM 模型，用 Rust 和 React 编写。 https://preview.redd.it/isxnn85e6kpd1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=23d6fb836359075380d9b87b90c9cbb87d977519 这是一个小版本，旨在解决使用远程 Ollama 服务器时的连接问题。    提交人    /u/grudev   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fjr6w1/p_new_release_for_open_source_llm_evaluation_tool/</guid>
      <pubDate>Wed, 18 Sep 2024 12:08:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mamba 模型用于回归任务？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fjqbmt/d_mamba_model_for_regresison_task/</link>
      <description><![CDATA[声明一下，我还没有研究过 Mamba 的技术方面，只是听说它取得了不错的成绩。我碰巧发现了这个库，它实现了回归和分类任务的模型，而且由于我的研究不涉及 NLP，而主要是回归任务，所以我想知道它是否有用。这个库叫做 Mambular。有人试过吗？这个模型在理论上是否有可能在大型表格数据集中取得良好的结果？这个库还有一篇与之相关的论文，他们做了基准测试，但我还没有研究那么多。 **有什么想法吗？**    提交人    /u/MrGolran   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fjqbmt/d_mamba_model_for_regresison_task/</guid>
      <pubDate>Wed, 18 Sep 2024 11:20:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 首篇发表的机器学习论文——乍一看，同行评审笔记中有什么引人注目的地方吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fjpfvt/r_first_published_ml_paper_from_a_quick_glance/</link>
      <description><![CDATA[长话短说，我通过会议论文集发表了我的第一篇论文，但我的同行评审有点短。我想知道这里有没有时间序列预测或 XAI 经验的人可以给我一些笔记？非常感谢。如果没有，也没关系。 https://dl.acm.org/doi/abs/10.1145/3674029.3674035（在 ACM 下开放获取）。    提交人    /u/jnb_phd_ml_accy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fjpfvt/r_first_published_ml_paper_from_a_quick_glance/</guid>
      <pubDate>Wed, 18 Sep 2024 10:23:57 GMT</pubDate>
    </item>
    <item>
      <title>寻求灵感[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fjovwe/seeking_inspiration_r/</link>
      <description><![CDATA[大家好。 所以，我目前正在一家全球运营的大型工业集团开始我的硕士论文。我将要解决的主要课题是事件分类，目标是将向正确团队报告问题的整个过程自动化。现在，我的导师已经实现了一些非常基础的东西，一个带有一些轻量级文本预处理的线性 SVC，它在这些事件的一小部分上已经表现得相当不错。我们谈论的是 +- 90% 的准确率，而人类通常有 +- 65% 的准确率，他告诉我。他对 ML 了解不多，他是一位老派的计算机科学博士，所以他希望我帮助他将其提升到一个新的水平。基本上，他要么实现一个更大的模型来覆盖所有可能的事件区域（我们谈论的是 8 个宏观区域，每个区域平均有 30 个输出类别，所以很多），要么为每个区域建立一个专门的模型，使用某种预分类模型将事件发送到正确的模型。 我知道这个问题仍然很普遍，这也是为什么我愿意接受任何意见和以前的经验，如果你曾经处理过类似的事情。 提前谢谢。    提交人    /u/AffectionateWeb8013   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fjovwe/seeking_inspiration_r/</guid>
      <pubDate>Wed, 18 Sep 2024 09:44:53 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] - Mojo/Modular，有人在实际项目中使用过它吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fji12z/discussion_mojo_modular_has_anyone_used_it_in_a/</link>
      <description><![CDATA[首先，我应该说我是 Chris Lattners 的忠实粉丝。 但是尽管 Mojo 是 Python 的超集，我个人并不认为我会学习它。 我反对学习新语言的主要理由是我使用 LLM 来完成代码中的所有输入...在 LLM 能够编写非常复杂的 C++ 或 Rust 之前，我认为 Modular 不会为 Mojo 培训开发人员。 所以我认为学习另一种语言毫无意义。 简而言之，我认为 Mojo 是在错误的时间提出的正确解决方案。 当然，有人可能会争辩说，从长远来看，LLM 也可以编写 Mojo，而且由于 MLIR 编译器的支持，它可能会成为一种更好的语言。我的观点是，要为一种语言构建可靠的 LLM，您需要相当多的现有代码，而 Mojo 在未来 5-10 年内将会缺乏这些代码……    提交人    /u/zarrasvand   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fji12z/discussion_mojo_modular_has_anyone_used_it_in_a/</guid>
      <pubDate>Wed, 18 Sep 2024 02:18:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用梯度工程强制模型参数稀疏性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fjgfhn/r_force_sparsity_in_model_parameters_with/</link>
      <description><![CDATA[是否有人尝试过在训练后期强制网络实现真正的稀疏性？ 我指的是，在训练稳定下来后的某个时刻，你开始执行梯度工程，选择最接近零的权重组，它们的梯度在训练的剩余时间内将始终指向零，一旦达到 0，它们就会被冻结。重复该过程。 我很好奇是否有人尝试过这种方法，如果尝试过，结果如何。 这种方法的一些可能动机：生物大脑中的突触修剪，压缩模型权重以进行分布。    提交人    /u/FunSavings4881   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fjgfhn/r_force_sparsity_in_model_parameters_with/</guid>
      <pubDate>Wed, 18 Sep 2024 00:59:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人知道任何真正的多模式大型语言模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fjay5c/d_does_anyone_know_about_any_true_multimodal/</link>
      <description><![CDATA[大家好， 我对测试多模态大型语言模型以检测偏见和幻觉很感兴趣，具体方法是使用语音作为输入，并让模型对语音输入进行推理以产生文本或语音输出。模型必须是真正的多模态，因为我想检查网络内的偏见相互作用。我已经知道文本偏见是存在的，所以简单的语音转文本，然后是 LLM，并不是我想要的。 由于 OpenAI 的语音助手尚未向公众发布，我很好奇其他可以用于此目的的模型。我曾见过 Qwen2-Audio-7B-Instruct (https://arxiv.org/abs/2407.10759 https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct )，但我不确定如何找到更多这样的模型，或者你们是否有我可以测试的模型建议。任何建议都将不胜感激！    提交人    /u/Constant-Working5468   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fjay5c/d_does_anyone_know_about_any_true_multimodal/</guid>
      <pubDate>Tue, 17 Sep 2024 21:09:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Pandas / Dask 等为 ML / DS 加密数据。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fj5gxf/p_encrypting_data_for_ml_ds_with_pandas_dask_etc/</link>
      <description><![CDATA[* 由于标题中缺少标签而重新发布 刚刚发布了一个模块，使通过 Python / Pandas / Dask / CLI 和云资源进行数据加密变得更容易。我们已经在 fsspec 上实现了 AES-256 CBC https://pypi.org/project/fsspec-encrypted/ 来源 https://github.com/thevgergroup/fsspec-encrypted 许可 MIT 允许轻松在本地或远程读取和写入 例如 import pandas as pd from fsspec_encrypted.fs_enc_cli import generate_key crypto_key = generate_key(passphrase=&quot;my_secret_passphrase&quot;, salt=b&quot;12345432&quot;) #local df = pd.read_csv(f&#39;enc://./.encfs/encrypted-file.csv&#39;, storage_options={&quot;encryption_key&quot;: crypto_key}) # 用 fsspec-encrypted 包装的 S3 请求 df = pd.read_csv(f&#39;enc://s3://{bucket}/encrypted-file.csv&#39;, storage_options={&quot;encryption_key&quot;: crypto_key}) # 与 gcs、abfs、adl、az、hf 等类似。  甚至有一个 CLI，因此脚本编写可以更容易，并允许您即时加密/解密 即将推出更多更新。  我们的目标是帮助减少未加密存储在磁盘上的 PII/PHI 或其他敏感数据的数量。   由    /u/olearyboy  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fj5gxf/p_encrypting_data_for_ml_ds_with_pandas_dask_etc/</guid>
      <pubDate>Tue, 17 Sep 2024 17:35:55 GMT</pubDate>
    </item>
    <item>
      <title>[N] 介绍 CodonTransformer：一种使用上下文感知神经网络的多物种密码子优化器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fj58d1/n_introducing_codontransformer_a_multispecies/</link>
      <description><![CDATA[大家好，机器学习社区， 我很高兴与大家分享我们的最新成果：CodonTransformer，这是一种最先进的 Transformer 模型，可优化 DNA 序列，以实现 164 个物种 中的异源蛋白质表达！ 什么是 CodonTransformer？ CodonTransformer 利用深度学习生成具有自然密码子分布的宿主特异性 DNA 序列，同时最大限度地减少负调控元件。它经过来自各种生物体的超过 100 万个基因-蛋白质对的训练，在效率和准确性方面均优于现有的密码子优化工具。  主要特点：  🔬 STREAM 训练策略：我们引入了一种名为 STREAM 的新型训练方法，使我们的仅编码器模型能够有效地执行针对生物体定制的蛋白质到 DNA 的翻译。 🧬 高级揭露机制：该模型将 20 个可能的掩码标记 [aminoacid_UNK] 揭露为 64 个未掩盖的 [aminoacid_codon] 标记，从而实现精确的密码子选择。 🌐 开源且可扩展：我们发布了最大的密码子优化 Python 库以及我们的数据和模型，因此您可以根据自己独特的研究需求对 CodonTransformer 进行微调。  为什么这很重要？ 随着生物技术的进步，跨物种优化基因表达物种比以往任何时候都更加重要。 CodonTransformer 旨在弥补异源蛋白质表达方面的差距，使其成为计算生物学、合成生物学和相关领域研究人员的宝贵工具。 探索 CodonTransformer：  🌎 网站： adibvafa.github.io/CodonTransformer 💻 GitHub： GitHub.com/Adibvafa/CodonTransformer （如果您觉得有用，我们将不胜感激 ⭐！） 🛠 Colab Notebook： 在 Google Colab 上试用 🤖 Hugging Face 上的模型： CodonTransformer 模型 📄 预印本论文： bioRxiv 上的 CodonTransformer  我们很乐意听取您的反馈！ 请随意深入研究代码，测试模型，并让我们知道您的想法。您的见解和反馈对我们和社区来说都是无价的。 期待您的想法和讨论！    提交人    /u/Ornery_Historian_526   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fj58d1/n_introducing_codontransformer_a_multispecies/</guid>
      <pubDate>Tue, 17 Sep 2024 17:26:49 GMT</pubDate>
    </item>
    <item>
      <title>[N] Llama 3.1 70B，Llama 3.1 70B Instruct 压缩了 6.4 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fivdkg/n_llama_31_70b_llama_31_70b_instruct_compressed/</link>
      <description><![CDATA[我们最近对 Llama 3.1 70B 和 Llama 3.1 70B Instruct 模型的研究实现了 6.4 倍的压缩率，同时保留了大部分 MMLU 质量。如果您有 3090 GPU，您现在就可以在家运行压缩模型。  以下是结果和压缩模型： https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-AQLM-PV-2Bit-1x16 https://huggingface.co/ISTA-DASLab/Meta-Llama-3.1-70B-Instruct-AQLM-PV-2Bit-1x16/tree/main   由    /u/_puhsu  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fivdkg/n_llama_31_70b_llama_31_70b_instruct_compressed/</guid>
      <pubDate>Tue, 17 Sep 2024 10:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您使用什么工具进行 AI/ML 开发、训练和推理？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fiqcxh/d_what_tools_do_you_use_for_aiml_development/</link>
      <description><![CDATA[我很好奇您在 AI/ML 工作流中使用的企业工具。无论是用于开发、训练、推理还是使用预构建模型，我都很想知道您每天依赖什么。  开发和训练：您喜欢哪些平台或服务来构建和训练模型？ 推理和部署：您使用哪些工具来大规模提供模型？ 预构建模型：您是否使用 Hugging Face 或 OpenAI 等平台来提供现成的模型？ 数据和实验跟踪：您推荐什么工具来管理数据集和跟踪实验？  期待您的见解！谢谢！    提交人    /u/Pretend-Lobster6455   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fiqcxh/d_what_tools_do_you_use_for_aiml_development/</guid>
      <pubDate>Tue, 17 Sep 2024 04:53:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于不同训练“技巧”的效果的良好研究，例如学习率调度程序（热身/衰减）、权重衰减、dropout、批量大小、动量等？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fihdrd/d_good_studies_on_the_effects_of_different/</link>
      <description><![CDATA[鉴于学习率调度程序（例如线性热身/余弦衰减）、正则化（权重衰减）、dropout、批量大小、动量项（Adam 中的 beta1、beta2）、批量规范等“技巧”的数量变得相当大，并且在这些大型模型上检查这些参数的所有不同组合变得越来越困难，是否有任何现有的研究或众包努力研究当我们改变这些技巧的各种参数时对最终性能（例如验证困惑度）的影响？ 我敢打赌其中很大一部分是在消融研究中，但它们有点太分散了。    提交人    /u/ThienPro123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fihdrd/d_good_studies_on_the_effects_of_different/</guid>
      <pubDate>Mon, 16 Sep 2024 22:01:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>