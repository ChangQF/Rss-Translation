<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 08 Oct 2024 21:17:05 GMT</lastBuildDate>
    <item>
      <title>[D] 从本地笔记本在云中运行代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fz5r5t/d_run_code_in_the_cloud_from_a_local_notebook/</link>
      <description><![CDATA[      我想分享我们构建的一个新 Python 库，它可让您从本地 Jupyter 笔记本编写和运行云函数。 它是如何工作的？ 当您运行笔记本单元时，代码会在云中的强大服务器上执行，而不是在您的笔记本电脑上。 来自远程服务器的日志会流回到您的笔记本。感觉就像代码仍在您的本地笔记本中运行，但实际上它是在远程运行。  https://preview.redd.it/aj7k4uy9jktd1.png?width=790&amp;format=png&amp;auto=webp&amp;s=e24f7d1580ab01472cf4b529335ba3ae266ea4be 好处  您无需使用云笔记本即可在云端进行开发。  如果您曾经使用过云笔记本，那么您的云笔记本可能崩溃了，您的工作也丢失了。  这可让您在本地低功耗系统上进行开发，同时将计算传输到云端。 本地文件自动与云运行时同步  您可以在远程函数执行中使用本地计算机中的文件。无需从 Google Drive 或 S3 上传和下载权重。 您可以跨单元混合搭配计算  您的训练代码是否需要与推理代码相同的硬件？可能不需要。这可让您逐个功能地自定义笔记本中使用的硬件。 如果您尝试一下，我们会很高兴！如果您有任何功能想法或建议，请告诉我们。  示例笔记本： https://github.com/beam-cloud/examples/blob/main/jupyter_notebooks/beam-notebook.ipynb 文档：https://docs.beam.cloud    提交人    /u/velobro   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fz5r5t/d_run_code_in_the_cloud_from_a_local_notebook/</guid>
      <pubDate>Tue, 08 Oct 2024 17:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于比较二项式比例的客观贝叶斯推断</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fz49wf/p_objective_bayesian_inference_for_comparing/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fz49wf/p_objective_bayesian_inference_for_comparing/</guid>
      <pubDate>Tue, 08 Oct 2024 16:40:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 差分变压器 (微软研究院)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fz0pya/r_differential_transformer_microsoft_research/</link>
      <description><![CDATA[摘要：Transformer 倾向于将注意力过度分配到不相关的上下文中。在本文中，我们引入了 Diff Transformer，它可以在消除噪音的同时放大对相关上下文的注意力。具体而言，差分注意力机制将注意力分数计算为两个单独的 softmax 注意力图之间的差值。减法消除了噪音，促进了稀疏注意力模式的出现。语言建模上的实验结果表明，Diff Transformer 在扩大模型大小和训练 token 的各种设置中均优于 Transformer。更有趣的是，它在实际应用中具有显着优势，例如长上下文建模、关键信息检索、幻觉缓解、上下文学习和减少激活异常值。通过减少不相关上下文的干扰，Diff Transformer 可以减轻问答和文本摘要中的幻觉。对于上下文学习，Diff Transformer 不仅提高了准确性，而且对顺序排列也更具鲁棒性，这被认为是一个长期存在的鲁棒性问题。结果将 Diff Transformer 定位为一种高效且有前途的架构，可以推进大型语言模型的发展。    提交人    /u/Decent_Action2959   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fz0pya/r_differential_transformer_microsoft_research/</guid>
      <pubDate>Tue, 08 Oct 2024 14:10:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 节能语言模型只需要加法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fz0jza/r_addition_is_all_you_need_for_energyefficient/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fz0jza/r_addition_is_all_you_need_for_energyefficient/</guid>
      <pubDate>Tue, 08 Oct 2024 14:03:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 从连续数据中学习马尔可夫网络结构的公开可用的最先进方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fz08mg/r_publicly_available_stateoftheart_methods_for/</link>
      <description><![CDATA[正如标题所示，我正在寻找有关学习马尔可夫网络结构（特别是连续数据）的最佳可用模型的建议。如果您能分享代码或实现的任何链接，我将不胜感激。    提交人    /u/solingermuc   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fz08mg/r_publicly_available_stateoftheart_methods_for/</guid>
      <pubDate>Tue, 08 Oct 2024 13:48:54 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 弄清楚深度学习是否会对这个 NER 问题产生过度影响（从成本估算文件中提取关键信息）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fyzp1r/project_figuring_out_whether_deep_learning_would/</link>
      <description><![CDATA[我需要开展一个命名实体识别项目。我有一个 CSV 文件，其中包含来自 270 份文档的文本以及成本估算。我的任务是提取以下信息，不仅从这 270 份文档中提取，还要从未来的文档中提取。 a) 文档收件人 b) 该收件人的公司 c) 文档 ID 代码 d) 文档所涉及的一般服务 e) 产品数量 f) 产品描述 f) 产品价格 对于前四点，文档通常遵循一致的结构，具有清晰的模式。例如，文档收件人总是出现在相同的字母后面。我设法使用正则表达式提取它们，尽管我不得不使用大量规则来处理变化（这是我不喜欢的，因为未来一点点潜在的变化都可能导致一切崩溃）。 问题是，当我们谈论最后三个时，存在变化。有时没有数量，只有很长的文字描述和最终价格。有时有一个清晰的结构：数量、描述、价格。我很确定几天后我就能想出一些规则，让我从这 270 个中提取我需要的所有内容。但未来文档中的微小更改很容易危及一切。另一方面，法学硕士很容易在这样的任务中表现出色。你怎么看？这会不会有点小题大做？ 我特别考虑做手动注释，使用这个数据集在 NER 上微调 BERT，然后继续。    提交人    /u/No_Possibility_7588   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fyzp1r/project_figuring_out_whether_deep_learning_would/</guid>
      <pubDate>Tue, 08 Oct 2024 13:23:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] SWE-bench Multimodal：AI 代理是否可以推广到视觉软件领域？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fyzo4x/r_swebench_multimodal_do_ai_agents_generalize_to/</link>
      <description><![CDATA[嗨！ 我们刚刚推出了 SWE-bench Multimodal！ 它有 617 个全新的任务实例 - 在每个实例中，代理都会根据其修复 17 个 JavaScript GitHub 存储库中的一个真实错误的能力进行评估。我们在此数据集中使用的所有错误在问题文本中都有一张图片。并且所有存储库都是面向用户的库，如映射、绘图和 Web UI 库。 以下是 SWE-bench Multimodal 中的一些示例错误及其相关图像 此数据集对现有的开源代理（包括 Agentless、AutoCodeRover 和 Moatless）来说极具挑战性。我们制作了一个新版本的 SWE-agent，能够正确解决 12% 的问题。我们新的多模式 SWE 代理能够对正在编辑的网页进行截图，以便迭代修复视觉错误。 https://preview.redd.it/0n5kqqzg9jtd1.png?width=1256&amp;format=png&amp;auto=webp&amp;s=60a54b411436987d1036909ab5d6b0a4e7513a29 论文：https://arxiv.org/pdf/2410.03859 我们对这篇论文感到非常兴奋，并认为在这个方向上还有很大的研究空间。 如果你有任何问题，我会在这里，你也可以在 COLM 找到我。    提交人    /u/ofirpress   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fyzo4x/r_swebench_multimodal_do_ai_agents_generalize_to/</guid>
      <pubDate>Tue, 08 Oct 2024 13:22:13 GMT</pubDate>
    </item>
    <item>
      <title>[N] 2024 年诺贝尔物理学奖授予 ML 和 DNN 研究人员 J. Hopfield 和 G. Hinton</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fywi9h/n_2024_nobel_prize_for_physics_goes_to_ml_and_dnn/</link>
      <description><![CDATA[公告：https://x.com/NobelPrize/status/1843589140455272810 我们的学生 John Hopfield 和 Geoffrey Hinton 因其在机器学习和深度学习方面做出的奠基性贡献而获得了 2024 年诺贝尔物理学奖！ 我听到远处传来施米德胡贝愤怒的声音！ 严肃地说，尽管这个选择非常令人惊讶，但我总体上还是很高兴的——作为一名对机器学习有着浓厚兴趣的物理学家，我喜欢这个物理-机器学习电影宇宙交叉。 对 Hopfield 和 Hinton 的限制可能会引发关于{Hopfield、Hinton、 LeCun、Schmidhuber、Bengio、Linnainmaa 等} 是现代 ML/DL/AI 成功的关键。Schmidhuber 尤其积极参与这一讨论。 然而，核心物理学界的反应相当复杂，如 /r/physics 主题 所示。在那里，人们注意到了与物理学研究的缺失环节/联系，以及 24 年物理学研究人员奖的“同时丢失”。    提交人    /u/PrittEnergizer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fywi9h/n_2024_nobel_prize_for_physics_goes_to_ml_and_dnn/</guid>
      <pubDate>Tue, 08 Oct 2024 10:26:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言模型的机械行为编辑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fyuake/r_mechanistic_behavior_editing_of_language_models/</link>
      <description><![CDATA[在网络规模文本上训练的大型语言模型获得了语言生成能力，可以解决各种任务，特别是当使用上下文示例将任务知识提炼为生成先验时。然而，从嘈杂数据中学习到的虚假特征阻碍了它们的普遍性。监督微调可以引入任务特异性，但会导致数据效率低下。先前的研究表明，(i) LLM 中的噪声神经回路与可泛化的神经回路共存，(ii) 微调通常会增强（或抑制）现有能力而不会引入新能力。在此基础上，我们提出了一种新的任务适应方法 TaRot。TaRot 使用可学习的旋转矩阵干预神经回路，这些旋转矩阵使用贝叶斯优化进行了优化，并以标准少量提示示例的顺序对标记样本进行处理。使用不同大小的 LLM 在多个分类和生成任务上进行的实验揭示了 TaRot 的有效性，它同时提高了零样本和小样本性能，平均改进（跨模型和任务）分别为 23.81% 和 11.15%。 论文：https://arxiv.org/abs/2410.04277 代码：https://github.com/joykirat18/TaRot    提交人    /u/Gaussian_Kernel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fyuake/r_mechanistic_behavior_editing_of_language_models/</guid>
      <pubDate>Tue, 08 Oct 2024 07:36:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] GPT-2 电路 - 映射简单 LLM 的内部工作原理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fymczh/p_gpt2_circuits_mapping_the_inner_workings_of/</link>
      <description><![CDATA[我构建了一个应用程序，它使用 GPT-2 架构从模型中提取可解释的“电路”。虽然一些教程提供了 LLM 中的层如何产生预测的假设示例，但此应用程序提供了流经系统的信息的具体示例。例如，您可以看到搜索简单语法模式并将其构造追溯到更原始特征的使用的特征的形成。如果您正在研究可解释性，请查看！我很乐意听取您的反馈，并希望与可以提供帮助的人建立联系。项目链接：https://peterlai.github.io/gpt-mri/    提交人    /u/ptarlye   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fymczh/p_gpt2_circuits_mapping_the_inner_workings_of/</guid>
      <pubDate>Mon, 07 Oct 2024 23:51:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 适合 Nvidia A100 40G 的系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fyj5sw/d_a_suitable_system_for_nvidia_a100_40g/</link>
      <description><![CDATA[我从 2019 年开始从事机器学习领域，我当前的 4090 设置已无法满足我日益增长的需求。以下是我关注的重点：  微调大型语言模型 (LLM) 训练隐马尔可夫模型 (HMM) 训练长短期记忆网络 (LSTM)  处理包括文本、图像、视频和音频在内的各种数据类型 我对机架服务器或工作站了解不多，我也希望在不久的将来添加更多卡（H100 或 A100），我的机架服务器或工作站预算约为 3000-4000 美元（显然除了卡之外） PS。评估了几乎所有的显卡，A100 在大多数方面都是赢家，所以它成为了一个明确的选择。亚军是 L40S。也欢迎对显卡偏好的建议。    提交人    /u/Dapper_Ad79   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fyj5sw/d_a_suitable_system_for_nvidia_a100_40g/</guid>
      <pubDate>Mon, 07 Oct 2024 21:27:26 GMT</pubDate>
    </item>
    <item>
      <title>[P] Model2Vec：从任意句子转换器中提取一个小型快速模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fyb9jj/p_model2vec_distill_a_small_fast_model_from_any/</link>
      <description><![CDATA[嗨 👋！ 我想分享我们过去几个月一直在研究的一个项目，名为 Model2Vec，我们最近开源了这个项目。这是一种提炼 Sentence Transformer 模型并创建非常小的静态嵌入模型（磁盘上 30mb）的技术，这些模型的速度比原始模型快 500 倍，使其在 CPU 上非常容易使用。提炼在 CPU 上大约需要 30 秒。 这些嵌入在 MTEB 上的表现远胜于类似方法（如 GloVE 和 BPEmb），同时创建速度更快，并且不需要数据集。它被设计为（大型）语言模型的环保替代方案，特别适用于时间受限（例如搜索引擎）或无法使用高级硬件的情况。 这个想法非常简单，但效果却出奇地好： 1：获取任何句子转换器的标记输出嵌入。 2：使用 PCA 降低维数。这不仅减小了模型大小，而且还规范了输出空间。 3：根据单词/标记频率对嵌入应用 zipf 权重。这实质上降低了常用词的权重，这意味着您不需要删除停用词。 我们创建了几个易于使用的方法，可以在使用 pip install model2vec 安装包后使用： 推理： from model2vec import StaticModel # 从 HuggingFace 中心加载模型（在本例中为 M2V_base_output 模型）model_name = &quot;minishlab/M2V_base_output&quot; model = StaticModel.from_pretrained(model_name) # 制作嵌入 embeddings = model.encode([&quot;独自一人去很危险！&quot;, &quot;这对每个人来说都是个秘密。&quot;])  提炼： from model2vec.distill import extract # 选择一个句子转换器模型 model_name = &quot;BAAI/bge-base-en-v1.5&quot; # 提炼模型 m2v_model = deliver(model_name=model_name, pca_dims=256) # 保存模型 m2v_model.save_pretrained(&quot;m2v_model&quot;)  我很想听听您对此的想法，并很乐意回答任何问题！ 链接：  Repo 链接 结果链接     提交人    /u/Pringled101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fyb9jj/p_model2vec_distill_a_small_fast_model_from_any/</guid>
      <pubDate>Mon, 07 Oct 2024 16:02:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 法学硕士 (LLM) 混合专家 (MoE) 的视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fya2ks/p_a_visual_guide_to_mixture_of_experts_moe_in_llms/</link>
      <description><![CDATA[大家好！我很高兴向大家介绍法学硕士 (LLM) 中的混合专家 (MoE) 的高度说明性指南！ 从探索专家的作用、他们的路由机制、稀疏 MoE 层和负载平衡技巧（例如 KeepTopK、辅助损失和专家容量），到视觉模型中的 MoE 和计算要求。  https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts 我喜欢创建视觉效果，在创建了 55 多个自定义视觉效果后，我不得不停下来！ 本指南的视觉特性允许专注于直觉，希望使所有这些技术易于广大受众使用，无论您是 Mixture of Experts 的新手还是更有经验。    提交人    /u/MaartenGr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fya2ks/p_a_visual_guide_to_mixture_of_experts_moe_in_llms/</guid>
      <pubDate>Mon, 07 Oct 2024 15:13:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</guid>
      <pubDate>Sun, 06 Oct 2024 15:00:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>