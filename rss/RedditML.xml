<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 01 Jun 2024 12:25:12 GMT</lastBuildDate>
    <item>
      <title>[P] 深层生物群落实验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5laih/p_the_deep_biome_experiment/</link>
      <description><![CDATA[您好， 我正在研究深层生物群落的概念，并试图在本文档中描述它：https://docs.google.com/document/d/e/2PACX-1vR1bvKTV94WRUyz-xfqPkV0TQjrHgE-4reCdP2Ncjgxv4CN8CVhEmcYb_b7qC2lv_HK9vjZd9yv57-Z/pub 摘要是：创建一个虚拟生物群落，其中每个代理都有一个“DNA”代表其神经网络的结构，并具有与其他代理一起繁殖的能力。 我已经在 GitHub 上创建了一个 DeepDNA 的示例，其中创建了两个 DNA，然后合并以生成孩子的 DNA。 我正在寻找合作者来有效地开发理论（和实施），这可以帮助我解决一些概念瓶颈，例如代理模型的训练或像 LSTM 这样的复杂层的情况下序列的结构。 我很欣赏与大学的合作以及将论文作为研究发表的雄心。 python 测试在这个 repo 中：https://github.com/cekkr/DeepGenome  此刻，我正在等待“刺激”继续前进。 谢谢， Riccardo Cecchini    提交人    /u/itsmeriky   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5laih/p_the_deep_biome_experiment/</guid>
      <pubDate>Sat, 01 Jun 2024 11:53:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助提高 BERT 与神经网络的匹配度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5l0he/d_help_to_increase_the_acc_of_bert_with_neural/</link>
      <description><![CDATA[      你好，我是 ML 新手，我正在努力提高我的 BERT-CNN、BERT-LSTM、BERT-GRU 的准确率。 这是我的存储库情绪分析 BERT-CNN 我使用的数据集是Kaggle，该数据集是不平衡的，所以我需要取出一些中性情绪分数到 0.78 以获得 4k 或中性情绪 我现在的准确率是 -&gt; BERT-CNN 训练总结： 最佳训练损失：0.0129（第 10 次训练） 最佳验证准确率：81.55%（第 7 次训练） -&gt; BERT-LSTM 训练总结： 最佳训练损失：0.0815（第 10 次训练） 最佳验证准确率：81.14%（第 7 次训练） -&gt; BERT-GRU 训练总结： 最佳训练损失：0.0815（第 10 次迭代） 最佳验证准确率：81.14%（第 7 次迭代） 图表 我根据这篇论文进行研究，作为准确率的参考，但是 我的代码有问题吗？ 我不知道我已经更改了不同的超参数，但对准确率来说仍然不重要。以及为什么我的模型不好，比如 acc 的改进不是增量的，但有时是下降的？ 提前谢谢您，我希望您对讨论感兴趣:)    提交人    /u/Jveko   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5l0he/d_help_to_increase_the_acc_of_bert_with_neural/</guid>
      <pubDate>Sat, 01 Jun 2024 11:35:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何建立视频排名模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5kvvh/p_how_can_i_build_a_video_ranking_model/</link>
      <description><![CDATA[该模型应根据观看次数、喜欢次数、评论次数和情绪分数对 YouTube 视频进行排名。应该使用哪种类型的模型？一种方法是根据每个特征的加权总和计算综合分数，但权重应该是预先确定的，我们不能仅仅假设。没有其他输出特征（如排名）可以用来训练模型。    提交人    /u/TheMadKinz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5kvvh/p_how_can_i_build_a_video_ranking_model/</guid>
      <pubDate>Sat, 01 Jun 2024 11:27:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mojo 值得吗，或者你愿意为 ML 学习哪种第二语言？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5kov5/d_is_mojo_worth_it_or_which_second_language_would/</link>
      <description><![CDATA[基本上就是标题。我非常精通 Python（正如预期的那样），但除此之外，我对 JavaScript 和 C++ 的了解非常有限。我想学习一种更“低级”的第二种语言，可以更好地利用硬件功能。我的目标不是重写 Pytorch 或完全替换 Python（尽管 将推理移植到 Mojo 可能有意义），而是为性能关键用例提供替代方案。 从今天的情况来看，答案显然是 C++。然而，Rust 越来越受欢迎，除了陡峭的学习曲线外，人们开始在许多方面将其置于 C++ 之上。在这两种情况下，语法和语言都与 Python 不太接近，这使得它们很难学习。 Mojo 在这方面似乎要好得多，既提供了语法类似于 Rust 的低级功能（至少对于像我这样的门外汉来说），又可以用作奇怪的 Python 风格。它甚至允许直接导入 Python 库。这对于这种缺乏大型社区和各种库的年轻语言非常有帮助。尽管如此，该语言仍然很年轻，而且很容易发生变化，所以我不确定是否应该投资。 那么，对于上述用例，您认为最好的“第二种”语言是什么？有使用 Mojo 的经验吗？您是如何学习它或资源有限的任何其他语言的。如果我使用 Mojo，我打算通读文档并解决去年使用它的代码出现的问题。    提交人    /u/canbooo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5kov5/d_is_mojo_worth_it_or_which_second_language_would/</guid>
      <pubDate>Sat, 01 Jun 2024 11:15:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 情境学习是否足以满足法学硕士 (LLM) 课程的指导要求？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hh86/r_is_incontext_learning_sufficient_for/</link>
      <description><![CDATA[上下文学习 (ICL) 允许 LLM 从示例中学习而不改变其权重，这对于可以从许多示例中学习的长上下文 LLM 来说是一项特别有前途的功能。最近，Lin 等人 (2024) 提出了 URIAL，这是一种仅使用三个上下文示例来对齐基础 LLM 的方法，可实现非平凡的指令跟踪性能。在这项工作中，我们表明，虽然有效，但使用 URIAL 的 ICL 对齐与已建立的基准（例如 MT-Bench 和 AlpacaEval 2.0 (LC)）上的指令微调相比仍然表现不佳，尤其是对于功能更强大的基础 LM。与分类、翻译或摘要等任务不同，为长上下文 LLM 添加更多 ICL 演示并不能系统地提高指令跟踪性能。为了解决这一限制，我们推导出一种针对 ICL 示例的贪婪选择方法，该方法可显着提高性能，但不会弥合与指令微调之间的差距。最后，我们提供了一系列消融研究，以更好地了解剩余差距背后的原因，并展示了 ICL 的某些方面如何偏离现有知识并特定于指令调整设置。 总的来说，我们的工作推进了对 ICL 作为一种对齐技术的理解。    提交人    /u/m_andriushchenko   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hh86/r_is_incontext_learning_sufficient_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:21:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] DeTikZify：使用 TikZ 合成科学图形和草图的图形程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hh0s/p_detikzify_synthesizing_graphics_programs_for/</link>
      <description><![CDATA[        由    /u/DrCracket 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hh0s/p_detikzify_synthesizing_graphics_programs_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:20:46 GMT</pubDate>
    </item>
    <item>
      <title>[D]您最喜欢使用哪些研究工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hdve/dwhat_are_your_favorite_tools_that_you_use_for/</link>
      <description><![CDATA[作为一名研究人员，我发现有几种工具确实能帮助我更好地工作、更轻松地写作并跟上最新研究。这些工具对于管理我的项目、与他人合作以及确保我的工作彻底性非常有用。以下是我个人最喜欢的工具： blainy.com： Blainy 是一种 AI 写作工具，可轻松创建文章、作业和研究论文。它可以建议内容、具有自动写作选项、允许您自定义写作风格、管理引文、检查抄袭，并具有用于澄清的 PDF 聊天功能。它是改进学术工作的好工具。 connectedpapers.com：这是一个开始新研究项目的好工具。通过输入一篇相关论文，它会向您显示相关论文及其引文的图表。这样您就可以清楚地了解相关文献以及它们之间的联系。 researchrabbit.ai：与connectedpapers.com类似，但功能更多。它可以帮助您查找相关论文并跟上您所在领域的新研究。您可以创建收藏夹并获取符合您兴趣的新论文的更新。 litmaps.com：跟踪最新研究的绝佳工具。Litmaps可让您创建引文的可视化地图，并随时了解与您的工作相关的新论文。它对于了解研究随时间的发展非常有用。 overleaf.com：用于撰写研究论文或笔记的最佳网络应用程序。凭借版本控制、协作功能和基于Web的界面，Overleaf是用LaTeX编写的最佳方式，可轻松与他人合作和管理您的文档。 notion.so：灵活的项目管理工具，可根据研究项目进行定制。 Notion 可让您组织研究、与团队成员协作并在一个地方跟踪任务和截止日期。 zotero.org：一个强大的参考管理工具，可帮助您收集、组织、引用和共享研究。Zotero 与您的浏览器集成以直接保存研究文章，并与文字处理器配合使用以轻松管理引用。 mendeley.com：另一个强大的参考管理器和学术社交网络。Mendeley 可帮助您组织研究、与他人在线协作并发现最新研究。它还与文字处理器集成，可轻松管理引用和参考书目。 通过使用这些工具，您可以更高效地工作、保持井然有序，并确保您的学术写作是彻底的且得到良好的支持。    提交人    /u/mysticmuse72   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hdve/dwhat_are_your_favorite_tools_that_you_use_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:14:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自动 LoRA 发现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</guid>
      <pubDate>Sat, 01 Jun 2024 04:09:17 GMT</pubDate>
    </item>
    <item>
      <title>调整剧本中的探索与利用——需要帮助理解流程 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5cxyq/exploration_vs_exploitation_in_tuning_playbook/</link>
      <description><![CDATA[[已编辑] 我正在阅读“Tuning Playbook”，在理解超参数调整背景下的探索与利用概念时遇到了一些困难。 有没有人可以用更具体而不是抽象的方式解释这个概念，或者提供一个在超参数调整中如何进行探索的例子？什么是探索以及如何进行探索。还有一件事；它一直在说理解问题，哪个问题？问题模型试图解决？还是什么超参数影响性能和相互影响的问题？还是什么？  这是书中关于这个主题的部分：  探索与开发  谢谢！    提交人    /u/Same_Half3758   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5cxyq/exploration_vs_exploitation_in_tuning_playbook/</guid>
      <pubDate>Sat, 01 Jun 2024 02:40:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 其他领域的研究，例如最近对一立方毫米人类脑组织的映射，能否帮助机器学习领域？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d56zg0/d_can_other_areas_researches_such_as_the_recent/</link>
      <description><![CDATA[https://www.scientificamerican.com/article/a-cubic-millimeter-of-a-human-brain-has-been-mapped-in-spectacular-detail/ 围绕人类大脑的研究，例如这张最新的人类大脑图谱，能否为机器学习领域提供一些见解，以构建更有效的人工智能/算法模型？ 外行人在这里。    提交人    /u/Enzo-chan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d56zg0/d_can_other_areas_researches_such_as_the_recent/</guid>
      <pubDate>Fri, 31 May 2024 21:40:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进行模型推理的更便宜的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d56h9c/d_cheaper_way_to_do_model_inference/</link>
      <description><![CDATA[有人知道在服务器停机期间节省 GPU 计算的解决方案吗？我目前正在进行模型推理，大多数时候我只是为计算付费，而不提供任何用户请求。    提交人    /u/Fun_Win_6054   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d56h9c/d_cheaper_way_to_do_model_inference/</guid>
      <pubDate>Fri, 31 May 2024 21:17:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] Bigram 标记器比现状更好吗？尤其是对于多语言</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4z5dr/d_bigram_tokenizers_better_than_status_quo/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4z5dr/d_bigram_tokenizers_better_than_status_quo/</guid>
      <pubDate>Fri, 31 May 2024 16:03:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习会议和组织指标</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4shqn/d_ml_conferences_and_organization_metrics/</link>
      <description><![CDATA[我觉得很多人会认为 NeurIPS、ICLR、ICML 等是机器学习领域的重要会议。即使在机器学习之外，NeurIPS 和 ICLR 的 H 指数在所有会议中排名第 9 和第 10。但是，现在我正在查看全球的终身教职职位，情况似乎有所不同。这些出版物似乎对移民或学术终身教职毫无价值，因为它们不是传统期刊。您会注意到它们没有出现在 SCImago 中，SCImago 是许多组织用来衡量出版物质量的指标，因此会决定终身教职或移民。 我很好奇学术机器学习研究人员在这种情况下会做什么。您是否会停止向 NeurIPS 提交论文，而打算在 ACM “机器学习的基础和趋势”上发表论文，而该期刊 在 SCImago 上排名第二？还是在不断增长的机器学习 IEEE 期刊名单上？    提交人    /u/smorad   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4shqn/d_ml_conferences_and_organization_metrics/</guid>
      <pubDate>Fri, 31 May 2024 10:34:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] KAN ==多层GAM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d4pjxp/d_kan_multilayer_gam/</link>
      <description><![CDATA[我刚刚阅读了 KAN 论文， 我的理解是，它提供了如何堆叠多层 GAM（广义加性模型）的解决方案：Phi 函数只是 GAM 的形状函数，而样条函数是 GAMS 中经过充分研究的形状函数。 所以对我来说：  MLP 是一个多层线性回归 KAN 是一个多层 GAM  尽管如此，GAM 具有 KAN 论文中未表达的链接功能，但在我看来，这才是这篇论文的真正重点。如果我们向 KAN 层添加激活函数，那么我们就完全拥有了多层 GAM。 这也意味着我们可以将 MLP 视为 KAN 的特例，因为线性回归是 GAM 的特例。 这听起来正确吗？    提交人    /u/mainro12   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d4pjxp/d_kan_multilayer_gam/</guid>
      <pubDate>Fri, 31 May 2024 07:02:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>