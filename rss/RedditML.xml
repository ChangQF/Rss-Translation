<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Tue, 18 Feb 2025 06:24:53 GMT</lastBuildDate>
    <item>
      <title>[d]当应用行业工作时如何查看AISTATS/UAI/TMLR？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is3c39/d_how_aistatsuaitmlr_is_viewed_when_applied_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在谈论研究或应用科学家在行业中的角色。您认为这些论文在简历上提供了多少价值？与CVPR/ICCV/ECCV/NIPS/ICML/ICLR？  &lt;！ -  SC_ON- sc_on-&gt;＆＃32相比，与顶级会议的纸张相比提交由＆＃32; /u/u/dampiventive_newt_100       [link]   ＆＃32;   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is3c39/d_how_aistatsuaitmlr_is_viewed_when_applied_for/</guid>
      <pubDate>Tue, 18 Feb 2025 03:34:15 GMT</pubDate>
    </item>
    <item>
      <title>[D]哪种会议模板可以写得最多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is36l9/d_which_conference_template_can_write_most/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近将脚本从ICLR重写为Neurips，我突然发现我必须将内容减少约3％。这并不多，但是您可以编写的内容似乎在不同的模板上有所不同。皇家地说，哪个模板可以编写最多的内容（说10页的限制，包括参考和附录）？我个人认为应该是ICML或IJCAI   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petrichorinforest     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is36l9/d_which_conference_template_can_write_most/</guid>
      <pubDate>Tue, 18 Feb 2025 03:26:14 GMT</pubDate>
    </item>
    <item>
      <title>[D]可以在没有基准数据集的情况下训练和比较模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is1sbg/d_is_it_okay_to_train_and_compare_models_without/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在使用此类型的数据集训练模型，特别是在医疗域（与癌症相关的数据集）中进行训练。据我所知，没有其他研究在我的研究领域使用此特定数据集。因此，我只使用此数据集比较不同的模型。这种方法是否有效，还是有必要包括外部基准数据集以正确评估我的结果？任何建议都将不胜感激。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sea_muscle_4281     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1is1sbg/d_is_it_it_it_okay_okay_train_train_and_and_compare_models_models_models_without/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is1sbg/d_is_it_okay_to_train_and_compare_models_without/</guid>
      <pubDate>Tue, 18 Feb 2025 02:14:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] Finetuning Modernbert正在服用3小时（2个时代）和35 gigs的VRAM。正常吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1is0q1a/d_finetuning_modernbert_is_taking_3hrs_2_epochs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以其他详细信息... 我正在使用a6000 48gb vram，8vcpu，8vcpu，45 gb ram。我的数据集是NewsArticle文本和标签的9K样本。 我正在使用的模型是“ answerdotai/sodernbert-base”。上下文长度为8192。 最初，当我尝试使用32或16的批处理进行捕获时，我一直在遇到OOM错误。然后，我看到了设置4个或更少的批处理。 即使训练一个时代也要花费大约1H 31分钟。这是正常的吗？这是我第一次进行模型，所以我是一个没有参考或过去的经验，这是我第一次进行填充。当我将批处理大小设置为32或16时，我没想到会看到一个45MB CSV文件会填充整个VRAM。是Pytorch错误还是??? &lt; /p&gt; 编辑 - IM使用的数据集是“ valurank/politainbias_allsides_txt”的截断版本。大约有19k数据样本。我正在使用其中的一个子集 - 大约9K样品。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/solaris12     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1is0q1a/d_finetuning_modernning_modernbert_is_taking_3hrs_2_2_epochs/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1is0q1a/d_finetuning_modernbert_is_taking_3hrs_2_epochs/</guid>
      <pubDate>Tue, 18 Feb 2025 01:22:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] [P] LLM（Gemini Flash 2.0）未能收敛到答案|开放式研究项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irv0m4/rp_llm_gemini_flash_20_failing_to_converge_to_an/</link>
      <description><![CDATA[    Flash 2.0）未能收敛到答案|开放式研究项目“ src =” https://external-preview.itd.it/es​​kfuge5ajvkan5kmjqvvvvvvtks4to72xkk8yyu72xk8oy6o.jpg？ = 70804E6EBBEECFF8A96F36290DAB557E1F503DFD“ title =” [R] - &gt;  大家好， 我目前正在研究一个研究项目，使用Google AI Studio，并认为你们可能会提供帮助。该模型是Gemini 2.0 Flash思考实验01-21，已经计算了2天以上的响应。我不确定发生了什么...   计算时间     eding/note/note：以下是同一模型版本的响应。但是，它无法访问先前的上下文窗口内容。这是“元”。其他模型没有系统提示的版本，“ Victor”我正在分析。如果还不清楚...  这是一个猜测：  潜在的假设    以下是测试它的方法/preview.redd.it/6axzer7zlrje1.png?width = 1920＆amp; format = png＆amp; auto = webp＆s = 751132eca1a1a584c76fdde1926df5ff5ff5ff5ff5ff5ff5ff5ff5ff5ff5ff5ff5ff5ff5ff550cd：&gt;  https://discuss.ai.google.dev/t/gemini-2-0-flash-thinking-experimental-01-21-incredibly-long-response-time-currently-131000s/66470  事先感谢您的任何建议。  编辑：  我想我有答案：它从未在以后计算任何东西一个点。这是UI中的错误。请参阅 Frototypist 的响应。感谢你们如此理解和乐于助人。我已经不在业内了一分钟，对正在发生的事情有些天真。再次感谢。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/captain_meat_hat     [link]   ＆＃32;  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irv0m4/rp_llm_gemini_flash_20_failing_to_converge_to_an/</guid>
      <pubDate>Mon, 17 Feb 2025 21:12:31 GMT</pubDate>
    </item>
    <item>
      <title>[d]“反向传播：多元链规则”的视觉解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irs3gn/d_visual_explanation_of_backpropagation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我开始研究反向流动的视觉说明。这是第1部分： https://substack.com/home/post/post/p-157218392 。请让我知道您的想法。 使我对倒退的一部分感到困惑，这是为什么人们将反向传播与链条规则相关联？链条规则无法清楚地解释从参数到损失的多个路径。最终，我意识到我错过了“多元链规则”一词。一旦我找到了它，一切都在我的脑海中点击。让我知道您在这里有想法。  谢谢，  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/madiyar     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irs3gn/d_visual_explanation_of_backpropagation/</guid>
      <pubDate>Mon, 17 Feb 2025 19:16:15 GMT</pubDate>
    </item>
    <item>
      <title>[r]忘记数据和微调！只需折叠网络以压缩[2025年2月]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irqngl/r_forget_the_data_and_finetuning_just_fold_the/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irqngl/r_forget_the_data_and_finetuning_just_fold_the/</guid>
      <pubDate>Mon, 17 Feb 2025 18:19:59 GMT</pubDate>
    </item>
    <item>
      <title>[D]就业市场如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irnuv1/d_hows_the_job_market/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  昨天，我开始申请新工作。目前，我的标题是“ ML工程师”但是说实话，我最近一直在运行更像ML顾问 - 我已经好几个月了。专注于ML。似乎有很多角色正在寻找拥有3年以上经验的候选人。 我只是对我在接受第一次面试之前将需要多少申请的申请 - 我目前在24个申请中。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ready_plastic1737     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irnuv1/d_hows_the_job_market/</guid>
      <pubDate>Mon, 17 Feb 2025 16:29:37 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ASL手势字母到文本程序？输入有帮助！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irmh9f/discussion_asl_hand_gesture_alphabet_to_text/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已被禁用，这意味着我无法使用键盘（甚至在手机上触摸等）输入很长时间。语音到文本很有用，但是对于我的大学论文，我还需要其他一些选择，以便我可以休息我的语音/喉咙。 我突然想知道是否存在一种可以将手势转化为文本的技术 - 将美国或英国的手语视为文本。但是我不需要整个签名的语言，只是一个可以通过网络摄像头识别字母的程序，然后输出正确的字母（或靠近，即使是语音的说法也不完美）。   看来独立开发人员正在为此致力于这一点，但是目前尚无应用程序可用。如果有人认为他们可以为我做这样的事情，我愿意诚实地付款，我认为我什至可以学会很快地“签署”字母，并提高速度。老实说，我渴望这样的程序，但是我本人没有编码或编程经验，我只是一个人做。 有人知道任何帮助/任何已经做过/可以做的人这样的东西？这甚至可行吗？我不会问，除非我认为这真的很有益。 非常感谢您的任何帮助！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fudgecake199     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irmh9f/discussion_asl_hand_gesture_alphabet_to_text/</guid>
      <pubDate>Mon, 17 Feb 2025 15:31:45 GMT</pubDate>
    </item>
    <item>
      <title>** [讨论] Bytegpt-Small：我的第一个用于移动设备的字节式LLM **🚀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irloen/discussion_bytegptsmall_my_first_bytetokenized/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿reddit， 我一直在研究专为&lt;强&gt;计算和内存受限的设备，例如手机和嵌入式系统。 🚀 这是我的第一个版本： bytegpt-small  。它是一个小型GPT风格的模型接受了字节令牌化训练（受BYT5的启发），以最大程度地提高效率。   为什么要字节令牌化？     较小的足迹：微小的嵌入减少模型尺寸和内存的使用。   无依赖性：字节级令牌化很简单 - 不需要句子或bpe。强&gt;更好地处理错别字和看不见的令牌。    我的系列计划：      Bytegpt-small：现在活下来！我将尽快添加onnx，coreml和tflite文件  指令调整：使其聊天。    更大型号：训练字节中 - 中等（〜150m参数）。    gpro蒸馏：缩小模型，同时保持质量。专注于在边缘运行的特定领域的小LLM。   为什么我要发布： 我很喜欢您的反馈，尤其是在您：  - 具有在移动设备或嵌入式设备上部署 llms的经验&lt; /strong&gt;。认为Byte令牌化的潜力比人们想象的要大。  链接到型号：   bytegpt-small“   您是否尝试过 on Device llms ？  您对 byte级别的tokenization的经验 vs.子词模型？  关于GPRO蒸馏技术的任何建议？   期待您的想法！ 😊  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/kells1986     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irloen/discussion_bytegptsmall_my_first_bytetokenized/</guid>
      <pubDate>Mon, 17 Feb 2025 14:57:24 GMT</pubDate>
    </item>
    <item>
      <title>[R]区域自适应抽样：通过选择性更新高关注区域来加速扩散变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irfq36/r_regionadaptive_sampling_accelerating_diffusion/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  此处的关键贡献是扩散变压器的一种新的自适应采样方法，该方法通过基于区域重要性选择性分配注意力来降低计算。它没有平等地处理所有区域，而是确定哪些零件需要更详细的处理。 主要技术方面： - 基于预测的重要性得分 - 修改的注意力机制与与之兼容现有体系结构 - 记忆效率的自适应缓存策略 结果显示：-30-50％的计算时间减少 -  FID或剪辑分数中没有降解 - 通过自适应采样节省40％的内存 - 有效 - 在多个模型架构中有效 - 为有条件和无条件的生成工作 我认为这对于计算效率很重要的现实应用程序可能特别影响。在将资源使用量减少多达50％的同时保持质量的能力为在更适度的硬件上运行这些模型的可能性开辟了可能性。这里的原则也可能会很好地转移到选择性注意力分配可能会有所帮助的其他领域，例如视频生成或3D渲染。 我最感兴趣的是，这是如何挑战统一处理对于高质量而需要的假设。一代。通过证明我们可以选择计算分配，这表明当前架构的效率提高仍然有很大的空间。  tldr：新方法通过选择性注意重要的注意力将扩散变压器计算减少30-50％ ，没有质量损失。  完整摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irfq36/r_regionadaptive_sampling_accelerating_diffusion/</guid>
      <pubDate>Mon, 17 Feb 2025 09:03:14 GMT</pubDate>
    </item>
    <item>
      <title>[d] OpenAI帆布如何与Intlace人类编辑一起使用KV缓存？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irfgsc/d_how_does_openai_canvas_works_with_inplace_human/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想知道，如果openai允许它允许在内置的人类编辑，如何使用kv缓存？它是否必须使整个缓存无效到更早的文件编辑，然后必须在其余的帆布文本中执行前向通行证？ 它是否可以像所描述的图像一样起作用，或者有更好的方法将缓存保存在编辑之间但没有变化的文本中（我认为不是这样，因为隐藏的上下文会随着未来的所有代币而改变）？  https://preview.redd.it/e1ccea3zvnje1.png?width=746&amp;format=png&amp;auto= webp＆amp; s = F3848812A20F770C938B1D9B54EABAA64B07AFE5   喜欢：     line 1：def process_data（） ）第3行：y = x + 10→kv₃（意识到KV₁，kv₂）第4行：返回y→kv₄（知道kv₁，kv₂，kv₃，kv₃）现在我们编辑第2行：  现在我们编辑第2行    第1行：def Process_data（）：→KV₁（仍然有效）第2行：x = 10→KV₂&#39;（new）行3：y = x + 10→kv₃（无效！基于旧x值）第4行：返回y→kv₄（基于旧链的无效！）  有没有更聪明的方法可以逃脱较少的远期通行证？ 编辑：我现在认识到标题的差异有多糟。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/punsbymann     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1irfgsc/1irfgsc/d_how_does_openai_openai_canvas_works_with_with_with_inplace_inplace_human/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irfgsc/d_how_does_openai_canvas_works_with_inplace_human/</guid>
      <pubDate>Mon, 17 Feb 2025 08:44:48 GMT</pubDate>
    </item>
    <item>
      <title>[r]在LLM中，在哪里可以在哪里进行学习？ （神经2024）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1irbjli/r_where_does_incontext_learning_happen_in_llms/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;    摘要：自我监督的大语言模型已经证明了能力要通过文本学习执行各种任务，但是对于模型将任务定位在迅速说明和演示示例方面的位置知之甚少。  在这项工作中，我们试图表征从识别任务到执行任务的大型语言模型过渡的区域。通过gptneo2.7b，bloom3b和starcoder2-7b，llama3.1-8b，llama3.1-8b-instruction，机器翻译和代码生成的一系列层面上下文掩盖实验，我们证明了A＆Met， ;任务识别;不再需要将任务编码到输入表示形式和对上下文的关注的点。 &lt; / p&gt; 在提示5个示例时，利用这种冗余的优势可节省45％的计算节省，并使用机器翻译的示例在第14/32层获得任务识别。我们的发现也对资源和参数有效微调有影响。 we observe a correspondence between fine-tuning performance of individual LoRA layers and the task recognition layers. &lt;a href=&quot;https://proceedings.neurips.cc/paper_files/paper/2024/file/3979818cdc7bc8dbeec87170c11ee340 -paper-conference.pdf“&gt; PaperLink ，提交由＆＃32; /u/u/thistory_insect668     [link]   ＆＃32;   [注释]  /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1irbjli/r_where_does_incontext_learning_happen_in_llms/</guid>
      <pubDate>Mon, 17 Feb 2025 04:27:03 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会导致禁止。 鼓励其他人创建新的帖子，以便在此处发布问题！ 线程将一直活着直到下一个，因此请继续发布标题之后的发布。    meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>