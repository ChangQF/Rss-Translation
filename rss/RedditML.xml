<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 19 Jan 2024 12:25:40 GMT</lastBuildDate>
    <item>
      <title>[D] 是否可以在 RAM 内传输数据而不真正传输它们</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ahtjb/d_is_it_possible_to_transfer_data_within_ram/</link>
      <description><![CDATA[自从 Sapphire Rapids 采用 HBM2e 作为 L4 缓存以来。  是否可以将 l2 缓存与 HBM3e 结合起来，从而形成“组合 RAM 和缓存”。  我这样做的原因是因为它可能会减少 RAM 和缓存之间的传输并减少指令，因为所有数据都存储在 RAM 上。但问题是 RAM 内的互连传输仍然比“真实高速缓存”慢。 RAM 上的读取和写入速度。  所以我的问题是：如果你所有的数据都在RAM上，是否可以在RAM中传输数据而不真正传输它们。我的意思是，例如修改内存地址，而无需在内存上实际处理/读取/写入它们。是否可以进行这样的数据管理？   由   提交/u/Hot-Highlight8842   reddit.com/r/MachineLearning/comments/19ahtjb/d_is_it_possible_to_transfer_data_within_ram/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ahtjb/d_is_it_possible_to_transfer_data_within_ram/</guid>
      <pubDate>Fri, 19 Jan 2024 12:18:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 精彩 AI 产品流行功能的高级视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ahpnj/p_highlevel_visual_guide_to_popular_features_of/</link>
      <description><![CDATA[大家好， 我猜你们很多人都在构建人工智能产品。我整理了在大多数人工智能产品中发现的面向用户的功能列表。我所说的面向用户，是指用户可以与之交互的功能，而不是可以从后端触发的功能。 我希望它有所帮助。如果您指出其他有趣的功能，我很乐意添加。 https://open.substack.com/pub/buildawesomeai/p/all-popular-features-of-awesome- ai?r=m0unv&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcome=true 免责声明：这不是有关如何实现这些功能的技术指南。我计划将来写更多相关文章，但这不是您在本文中找到的内容。此外，它更关注基于 LLM 的产品，而不是基于图像的产品。 功能列表 与 AI 的接口  聊天界面&lt; /li&gt; Playground 界面 Playground 集成到工作区 混合聊天和聊天功能。游乐场  交互功能  多模态 自动完成建议 自动更正 突出显示潜在的改进 重新生成 多输出 后续问题 复制、下载或共享输出 互动思路链 多语言支持 翻译 Agent（或GPT）和模型选择  个性化功能  改变语气 改变风格 模仿角色、人物或人  可解释性特征  对所使用的数据源、工具和代理的引用 突出显示的更改 显示链想法  文章链接：链接   由   提交/u/emile_courthoud   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ahpnj/p_highlevel_visual_guide_to_popular_features_of/</guid>
      <pubDate>Fri, 19 Jan 2024 12:11:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 荷兰语 NLP 症状检查器：从数据到部署</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ahe92/p_nlp_symptom_checker_for_dutch_speakers_from/</link>
      <description><![CDATA[我想分享一下我最近做的一个项目，使用了 XGBoost Classifiers、Flask API、Docker、Google Cloud Container Registry 和 Google Cloud run。如果您感兴趣，请随时发表评论： https://christiangrech.medium.com/building-a-robust-dutch-nlp-symptom-checker-from-data-to-deployment-e389d874a247   由   提交 /u/OutplayOutlast   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ahe92/p_nlp_symptom_checker_for_dutch_speakers_from/</guid>
      <pubDate>Fri, 19 Jan 2024 11:53:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mistral 7B 使用采访数据进行微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19agmi6/d_mistral_7b_finetuning_with_interview_data/</link>
      <description><![CDATA[嗨！ 我一直想根据我作为训练数据转录的 Zoom 采访来微调这个模型。&lt; /p&gt; 如何解决这个问题？  如何格式化数据集？什么是好的方法论？我需要什么 GPU？最后，如何将其作为聊天 UI 上传到 Huggingspace？   由   提交/u/portmanteau98  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19agmi6/d_mistral_7b_finetuning_with_interview_data/</guid>
      <pubDate>Fri, 19 Jan 2024 11:04:14 GMT</pubDate>
    </item>
    <item>
      <title>[D]ML算子单元测试框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19aghlb/dml_operator_unit_test_framework/</link>
      <description><![CDATA[大家好， 我正在开发一个可插入的 GPU ML 运算符库（如 cudnn 和 cublas）  它有几百个算子，每个算子有几十个或几百个单元测试用例。 现在我的问题是测试效率。  让我具体说明一下。 我们的大多数测试用例如下所示： void TestMatMul() { inputA = PreparationRandomInput(); inputB = 准备随机输入(); // 这可能需要 1 分钟 cpu_result = RunMatMul(inputA, inputB, DEVICE_CPU); // 这可能需要 1 秒 gpu_result = RunMatMul(inputA, inputB, DEVICE_GPU); AssertAllClose(cpu_result, gpu_result) }  ​ 当 inputA 和 inputB 是大矩阵时，CPU 可能需要几分钟来计算 Matmul 运算，而也许GPU 上只需几毫秒。 Matmul 只是一个例子，这可能发生在任何操作员身上。 在单元测试结束时，整体 GPU 利用率非常低。  p&gt; 例如，对于一个小时的测试时间，整体 GPU 硬件时间不到 1 分钟。 CPU 正在努力进行计算。 我不能通过使用多线程并行测试用例来解决这个问题，因为 CPU 是这种情况下的主要瓶颈。 ​ 这个问题对我来说似乎很常见，因为大多数单元测试框架就是这样实现的。 我在google上尝试了运气，但没有太多发现。 我的想法是将测试分为两个阶段，并将cpu计算放在一个CPU farm。 我想知道是否有任何公共项目或研究论文解决了这个问题。 ​ 非常感谢&lt; /p&gt; 凯文 ​   由   提交/u/thwack324  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19aghlb/dml_operator_unit_test_framework/</guid>
      <pubDate>Fri, 19 Jan 2024 10:55:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在视觉领域，引导模型在利基任务上工作的当前 SOTA 是多少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19aet3w/d_what_is_the_current_sota_for_bootstrapping/</link>
      <description><![CDATA[过去，当您需要在一些相对小众的分类/检测/分割任务上训练模型时，您会使用在ImageNet1K/COCO 并将其微调到您拥有的任何中小型数据集，这足以将您的性能提升到合理的水平。当然，您始终可以通过使用更大的 Resnet、改进超参数选择或清除专有数据集中的噪声来改进这一点。更新的架构已经发布，更新的优化器，我们现在有像 CLIP 这样的大型 VL 模型，等等。我想知道我是否错过了一个新的共识。 如果你选择回答，我将不胜感激如果您还详细说明了以下标准：  您选择的方法是否对超参数过于敏感？ / 收敛到正确的模型有多难？例如，根据我的经验（当然不是绝对的），在超参数选择方面，ResNet 比 EfficientNet 更宽容。 您的方法对少量数据的敏感程度如何？例如，我记得原来的 Transformer 在小训练集场景中非常糟糕，结果在 IN22K 上报告。 您的选择有多快和/或内存效率如何？小的利基任务往往不会证明具有 1B 参数的模型是合理的。  谢谢！   由   提交/u/anaccountforthemasse   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19aet3w/d_what_is_the_current_sota_for_bootstrapping/</guid>
      <pubDate>Fri, 19 Jan 2024 08:57:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 有人在 NLI 架构中使用 NER 掩蔽技术吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19aersk/d_anyone_using_ner_masking_techniques_in_nli/</link>
      <description><![CDATA[有人用 NER 想法构建 NLI 架构吗？ 因此，我查阅了大量有关 NER 和 NLI 的文献，并且我意识到很多底层操作基本上都是围绕操纵代币上的屏蔽策略来进行的。我正在寻找人们在这方面集思广益新架构。  我正在考虑这样的事情：  BERT 层来生成令牌。 NER掩蔽层生成标记之间的 NER 关系（起到基本原理提取和附加信号的作用） 可以利用这一切的 NLI logit 估计。&lt; /li&gt;    由   提交/u/testuser514  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19aersk/d_anyone_using_ner_masking_techniques_in_nli/</guid>
      <pubDate>Fri, 19 Jan 2024 08:54:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] Facebook 关闭 ParlAI，一个对话研究框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19adrgv/d_facebook_shuts_down_parlai_a_framework_for/</link>
      <description><![CDATA[我刚刚了解到 Facebook 已经存档了 BlenderBot 背后的团队 ParlAI。该存储库于 2023 年 11 月 3 日存档，现在是只读的，此后该项目的 Twitter 帐户没有任何更新。 因此 Facebook 放弃了工程化和模块化对话系统背后的想法，并全力以赴对于LLM，我还听说其他大公司的其他模块化对话团队也在裁员。你觉得怎么样？   由   提交 /u/Comfortable_Use_5033   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19adrgv/d_facebook_shuts_down_parlai_a_framework_for/</guid>
      <pubDate>Fri, 19 Jan 2024 07:43:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何获得NLP中级/高级知识？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19adf04/r_how_to_gain_intermediateadvanced_knowledge_in/</link>
      <description><![CDATA[我有几年的行业经验。虽然我不是深度学习（或一般的机器学习）方面的专家，但我知道如何构建模型并部署它们等。这个领域在不断发展，所以我必须不断学习。我在 YouTube 或博客的帮助下做到了这一点，它们让我对情况有了基本的了解，仅此而已。 我到处实施了一些项目，以对我的内容有一些了解。我刚刚学会了。然而，凭借我所获得的知识，我只能构建基础知识，不了解如何进一步扩展它或承担复杂的项目。 例如（这是在简历中，但给出了要点） ，在学习图像分割时，我花了大约两周的时间来学习并在我拥有的这些奇特数据上实现一个模型，这很有趣。现在，没有任何“需要”为了进一步发展，该模型只是一个宠物项目。虽然我学习了如何训练和实现自定义模型（从头开始 UNet）并在 GPU 上处理数据，但我现在不知道在哪里寻找更多信息。 我正在转向 NLP，因为那是我的学习方向我想我想工作。然而，在这里我看到大部分游戏都依赖于 API，而不是自定义模型构建。我不想在几天内只构建一个基本项目。  您对我可以自己实施的项目/论文有什么建议，提供 NLP 领域的适当基础知识吗？ （就像从头开始实现变压器模型，但针对高级水平） PS：我想在空闲时间（除了我的工作）自己实现这些项目。因此，硬件要求可能会限制我。另外，我知道我对 NLP 领域知之甚少，因此任何有趣且包含理论背景的子领域都是有益的（我想同时学习理论:)   由   提交 /u/Amazing_Life_221   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19adf04/r_how_to_gain_intermediateadvanced_knowledge_in/</guid>
      <pubDate>Fri, 19 Jan 2024 07:19:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何从非结构化文本中提取事件信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19abdeo/d_how_to_extract_event_information_from/</link>
      <description><![CDATA[您好， 我有一些类似于新闻稿的内容，我需要提取事件信息。我是寻找来自某一特定行业的活动。但新闻稿可以不包含一个、一个或多个事件详细信息，并且它们不一定与我的行业相关。 作为一个人，我会根据标题（有时是描述）决定它是否适合我的行业，然后查找详细信息（日期/时间/地点/活动名称/描述/等）。 离线/本地执行此操作的好方法是什么？我只是尝试使用 llama.cpp ，这让我一团糟（可能我做错了）。几年前，我使用 Spacy 进行 NER - 我想这基本上只是步骤 4 的一小部分.有什么东西可以“理解”吗？我的数据更好并给我带来了很好的结果？   由   提交/u/Chris8080  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19abdeo/d_how_to_extract_event_information_from/</guid>
      <pubDate>Fri, 19 Jan 2024 05:14:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer多头注意力实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19a8klj/d_transformer_multihead_attention_implementation/</link>
      <description><![CDATA[我一直在关注带注释的 Transformer&lt; /a&gt; 实现变压器架构。在多头注意力类的forward()方法中，Query、Key &amp;值与相应的投影矩阵相乘； W_q, W_k, W_v.  查询，键，值 = [ lin(x).view(nbatches, -1, self.h, self.d_k) .transpose(1, 2) for lin, x in zip(self.linears, (query, key, value)) ]  这里，lin(x) 正在被重塑为 (nbatches, -1, self.h, self.d_k) 和维度 1 &amp; 2 正在被转置，这使得维度 (nbatches, self.h, -1, self.d_k)。 我无法理解为什么他们不直接这样做lin(x).view(nbatches, self.h, -1, self.d_k)?   由   提交 /u/Melodic_Stomach_2704   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19a8klj/d_transformer_multihead_attention_implementation/</guid>
      <pubDate>Fri, 19 Jan 2024 02:48:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能很强大实际上是一个正在研究的严肃而真实的领域，或者只是人们正在宣传的另一种炒作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19a6nsd/d_is_strong_ai_actually_a_serious_and_real_field/</link>
      <description><![CDATA[强大的人工智能。 （通用人工智能）实际上是一个严肃的研究领域，还是只是来自刚刚阅读/观看科幻小说的人的纯粹炒作？ 强人工智能/又名是强人工智能吗？ AGI实际上被一些研究人员/机构认真对待，他们认为它最终可以实现，或者它是人们一直在炒作的另一种奇特的技术蒸汽软件，但实际上，那些在该领域工作的人知道这样的想法实际上无法实现，因为严格的物理限制，或者如果发生的话，需要几个世纪才能实现？ 因为过去对于许多未来主义者来说有很多歇斯底里的感觉技术，这些技术被很多不知道蹲点的人大肆宣传，但它无法在实践中发挥作用（即 Em Drive、石墨烯、富勒烯、纳米机器人、Bussard Ramjet、聚变能源等）。   由   提交/u/Enzo-chan  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19a6nsd/d_is_strong_ai_actually_a_serious_and_real_field/</guid>
      <pubDate>Fri, 19 Jan 2024 01:16:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] PyTorch 2 内部结构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19a1mup/p_pytorch_2_internals/</link>
      <description><![CDATA[嗨，刚刚分享了关于 PyTorch 内部结构的幻灯片，涵盖了 Dynamo、Inductor、ExecuTorch 等最近的项目，我认为这里可能会有一些人感兴趣。 &lt;!-- SC_ON - -&gt;  由   提交 /u/perone   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19a1mup/p_pytorch_2_internals/</guid>
      <pubDate>Thu, 18 Jan 2024 21:37:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 你如何训练你的法学硕士？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19a03ax/r_how_do_you_train_your_llms/</link>
      <description><![CDATA[大家好，我是一名高级 Python 开发人员，正在接受 LLM 培训。我的老板正在使用一个需要将问题和答案输入到其中的系统。  所有训练都是这样完成的吗？将我们所有的文本数据转换为问答对是一个主要基础。我希望我们可以给它提供大量的文本，然后对其进行预训练。但我们当前使用的解决方案并不是这样工作的。  你们如何培训法学硕士以及我应该关注什么？   由   提交 /u/ZachVorhies   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19a03ax/r_how_do_you_train_your_llms/</guid>
      <pubDate>Thu, 18 Jan 2024 20:35:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>