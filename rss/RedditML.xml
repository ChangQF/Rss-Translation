<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 27 Sep 2024 15:17:50 GMT</lastBuildDate>
    <item>
      <title>[P] 推荐一些用于情绪分析的最佳轻量级模型。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqpac5/p_suggest_some_of_the_best_lightweight_models_for/</link>
      <description><![CDATA[大家好！我正准备启动一个新项目，我真的需要一些建议。我正在寻找最好的轻量级模型。我需要它们超级高效，同时又不牺牲质量。任何建议都很棒。我非常感谢你能提供的任何帮助。    提交人    /u/Ai_Peep   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqpac5/p_suggest_some_of_the_best_lightweight_models_for/</guid>
      <pubDate>Fri, 27 Sep 2024 14:39:17 GMT</pubDate>
    </item>
    <item>
      <title>扩大我的研究范围——医学图像分割[R][D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqp137/expanding_scope_of_my_research_medical_image/</link>
      <description><![CDATA[您好，想听听您的想法。 我正在撰写硕士论文，以便为外科手术数据建立医学图像分割的基础模型。两个月来，  我找到了相关的数据集，这些数据集是最新的，尚未被大量用于研究。 在数据集上设计和测试了经典的 segm 模型和基于 transformer 的模型。对器官特定数据进行二元分类。 （比较研究） 再进行一项关于模型大小（深度和宽度）对得分与基线的影响的比较研究。 多标签与器官特定模型。 使用 SAM 对其进行微调，以便为我的用例提供一种 SurgicalSAM。  我还有 6 个月的时间来完成这项工作，我真的不想要一篇平庸的论文，我觉得它正在变成一篇平庸的论文。不指望任何突破性的东西，但至少希望它能通过好的会议，并在申请博士学位时有所展示。 我的问题 -  还有什么我可以探索的吗？我想我有足够的时间做一些更先进的事情。请提出任何想法，我会交叉检查每个反馈。 我可能错过的任何有趣的技术或 SoTA segm 方法都可以作为应用程序包含在内。     提交人    /u/ade17_in   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqp137/expanding_scope_of_my_research_medical_image/</guid>
      <pubDate>Fri, 27 Sep 2024 14:27:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] TACL 审查延迟</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqo2du/d_tacl_review_delay/</link>
      <description><![CDATA[所以我在今年 8 月的周期（即 8 月初）向 TACL 提交了评论，但已经快 2 个月了，没有收到任何评论。通常评论会在 1.5 个月左右提交，以供比较。有没有其他人收到评论，还是每个人都是这种情况。几天前我给主编发了邮件，但仍然没有回复。    提交人    /u/Progamer101353   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqo2du/d_tacl_review_delay/</guid>
      <pubDate>Fri, 27 Sep 2024 13:44:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 帮助语音识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqjspj/p_help_with_speech_recognition/</link>
      <description><![CDATA[我正在开展一个项目，需要构建一个代理来监听用户并回答他们的问题（想象一下电话呼叫）。如果用户提供了错误的信息或不小心说错了话，他们还应该能够打断代理。 示例：  理想场景：   代理 🔊：您好！我能为您做些什么？ 人 🗣️：我的移动电源按钮出现问题。 代理 🔊：[提供详细信息。]   有问题的场景   代理 🔊：您好！我能为您做些什么？ 人🗣️：我的手机屏幕刚刚变黑了。我该怎么办？  代理🔊：[开始回复但用户打断...🗣️] 人🗣️：抱歉，我的意思是我的手机变黑了，因为我不小心把它掉进水里了。  我们可以看到，用户可以在代理说话时打断它，代理必须停止响应并开始监听用户的新命令。我正在使用带有两个线程的speech_recognition库：一个用于连续收听，另一个用于转录。我的问题是我的监听线程会同时激活代理和用户的声音。我尝试在笔记本电脑和耳机上输入代码，但它仍然在听。 有办法解决这个问题吗？    提交人    /u/MBHQ   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqjspj/p_help_with_speech_recognition/</guid>
      <pubDate>Fri, 27 Sep 2024 09:31:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何训练语音转文本模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqi44b/p_how_do_i_train_a_speech_to_text_model/</link>
      <description><![CDATA[您好，我想用大约 5-6 分钟的语音训练一个文本转语音模型，具体来说是这些。我本来打算使用 https://github.com/jasonppy/VoiceCraft?tab=readme-ov-file 或 https://github.com/Camb-ai/MARS5-TTS?tab=readme-ov-file 等模型，但它只需要 5 到 10 秒的样本。我不知道从哪个模型开始训练。任何指示都将不胜感激。谢谢    由   提交  /u/TemperatureOk3561   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqi44b/p_how_do_i_train_a_speech_to_text_model/</guid>
      <pubDate>Fri, 27 Sep 2024 07:21:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 各位 ML 从业者，当您遇到 ML 问题时，您会向谁求助？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqb1t1/d_fellow_ml_practitioners_who_do_you_go_to_when/</link>
      <description><![CDATA[顺便说一句，不要在“简单问题主题”中发帖，因为我相信即使是具有正式 ML 知识的人也可以从中受益。 我很好奇，如果您遇到以前没有做过的事情，您如何获得新想法并验证它们。我的情况类似，虽然我的工作团队中有其他领域的专家，但没有高级 MLE。 不一定是个人，我也很想知道您提到的任何来源。    提交人    /u/Moltres23   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqb1t1/d_fellow_ml_practitioners_who_do_you_go_to_when/</guid>
      <pubDate>Fri, 27 Sep 2024 00:15:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何创建用于分割的数据集。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fq4wz2/p_how_to_create_a_dataset_for_segmentation/</link>
      <description><![CDATA[大家好，我一直在尝试使用 CNN 架构进行分类，但不幸的是，这不是我实现目标所需要的。我需要使用来自国家农业图像计划的 512x512 像素图块来确定岩石在景观中的位置，我对我的数据集应该是什么样子感到困惑。此外，我在互联网上找到的所有示例都是针对边界框的，但我想要像素分类。我之前被告知，要使分类模型表现良好，您至少需要五个类别（例如，岩石、水、树木、草地等）。这对于分割也适用吗，还是我应该专注于仅为岩石创建标签/蒙版？ 让我知道您的想法或您将如何创建此数据集。 非常感谢！    提交人    /u/Muted_Preparation_47   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fq4wz2/p_how_to_create_a_dataset_for_segmentation/</guid>
      <pubDate>Thu, 26 Sep 2024 19:38:17 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 有没有什么有前景的研究可以利用 RL 从人类反馈中改进计算机视觉任务？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpzj0m/discussion_are_there_any_promising_work_on_using/</link>
      <description><![CDATA[目前，对于诸如对象检测或实例分割之类的计算机视觉任务，改进生产模型的最佳方法是使用硬示例挖掘进行某种形式的迭代模型训练/主动学习，并将其放回注释和训练中，并经常这样做。  是否有任何研究探索基于从人类反馈中学习到的某些策略快速对齐模型输出的方法，类似于语言模型中的 RLHF？  此外，是否有任何有助于减少人工注释工作量的值得探索的研究领域？    提交人    /u/Appropriate_Bear_894   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpzj0m/discussion_are_there_any_promising_work_on_using/</guid>
      <pubDate>Thu, 26 Sep 2024 15:52:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪种神经网络架构最适合具有几千个数据点的时间序列分析？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpxja7/d_what_neural_network_architecture_is_best_for/</link>
      <description><![CDATA[我知道你在想什么，使用 ARIMA 等经典方法。是的，你是对的，但我已经为我的公司这样做了。我目前是合作社，我得到了一份全职工作。在过渡期间，我两周内没什么事可做。我可以使用 PySpark 和 Databricks，但在新职位上我不会使用，所以我想把这段时间当作一次学习经历，最终它会对我的简历有所帮助。我并不期望性能会比我的 ARIMA 模型更好 数据具有 2021 年的每日粒度。我有特征，但不是很多。有三种架构我一直在考虑。我了解 RNN、LSTM 和时间 CNN。就（主要是）学习与性能相结合而言，您认为其中哪一个最适合我的任务？一般来说，对于丰富的数据，您认为哪种架构通常表现最佳？    提交人    /u/BostonConnor11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpxja7/d_what_neural_network_architecture_is_best_for/</guid>
      <pubDate>Thu, 26 Sep 2024 14:28:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您需要什么语音解码架构来模拟 openai 的高级语音模式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpwbjk/d_what_speech_decoding_architecture_do_you_need/</link>
      <description><![CDATA[Llama Omni 是我见过的唯一一篇接近语音模式的论文，但所使用的语音解码架构似乎不允许“用法语口音说 1 2 3”之类的事情。在论文中，他们似乎冻结了编码器和 llm，并使用来自其他 TTS 模型的文本和模型输出来训练解码器。这是否意味着您必须拥有一个包含诸如“[法语口音]1 2 3”，.waveform”之类的对的数据集，或者这里有不同的方法可以采用？    提交人    /u/natural_language_guy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpwbjk/d_what_speech_decoding_architecture_do_you_need/</guid>
      <pubDate>Thu, 26 Sep 2024 13:34:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama-3.2 与 llama-3.1 在医疗领域的表现：Llama-3.1 70B 优于 Llama-3.2 90B</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fps53b/d_llama32_vs_llama31_in_medical_domain_llama31/</link>
      <description><![CDATA[      大型 LLama 模型在医疗领域的表现（90B、70B、11B） 探索 LLama 3.2 Large 模型与 Llama 3.1 模型在医疗领域的表现。 （未经微调） 🥇 Meta-Llama-3.1-70B-Instruct：总冠军，平均成绩 84%  MMLU 大学生物学成绩优异（95.14%） MMLU 专业医学成绩优异（91.91%）  🥈 Meta-Llama-3.2-90B-Vision（Instruct 和 Base）：以 83.95% 的平均成绩并列第二  Instruct 和 Base 版本表现一致 MMLU 大学生物学（93.06%）和 MMLU 专业医学（91.18%）成绩最佳  🥉 Meta-Llama-3-70B-Instruct：第三名，平均成绩 82.24%   MMLU 医学遗传学（93%） MMLU 大学生物学表现稳定（90.28%）  医学领域的小型 LLama 和 Phi 模型（3B、1B） 我还分析了较小的模型，并将它们与 phi-3 进行了比较，以探索小模型在医学领域的表现。 （未经微调） 🥇 Phi-3-4k：表现最佳，平均分数为 68.93％  MMLU 大学生物学成绩优异（84.72％） MMLU 临床知识成绩优异（75.85％）  🥈 Meta-Llama-3.2-3B-Instruct：平均成绩为 64.15％ ，排名第二  MMLU 大学生物学成绩最佳（70.83％） PubMedQA 成绩稳定（70.6％）  🥉 Meta-Llama-3.2-3B：平均成绩为 60.36％ ，排名第三  MMLU 大学生物学成绩最强（63.89％）  PubMedQA (72.8%)  其他观察结果： 评估结果  视觉模型中的表现相同： Meta-Llama-3.2-90B-Vision Instruct 和 Base 版本在所有指标和所有 9 个数据集上都表现出相同的表现（平均 83.95%），精确到小数点后一位。 同样，Meta-Llama-3.2-11B-Vision Instruct 和 Base 版本也表现出相同的分数（平均 72.8％）在所有类别中。（评估两次）  不寻常的一致性： Instruct 和 Base 版本之间的这种完美对齐有点不典型，因为 Instruct 和基础变体通常会显示出轻微的性能差异.. 我猜这是由于视觉指令调整造成的？视觉模型的能力是否可以减少对针对医疗任务的特定指令调整的依赖？ 结果以 JSON 格式提供，可在Github 上获取   将很快在此处为医疗领域评估更多模型 - 源帖子    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fps53b/d_llama32_vs_llama31_in_medical_domain_llama31/</guid>
      <pubDate>Thu, 26 Sep 2024 09:29:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你会关注哪些信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fpo0z8/d_which_feeds_do_you_look_at/</link>
      <description><![CDATA[虽然 arxiv 和 open review 是新论文的两个最佳来源，但我发现某些 feed 也非常有趣。对我来说，这包括 GitHub、Less Wrong、Hugging Face、Twitter 和 Reddit。我遗漏了什么吗？还有更多吗？博客列表？我希望有这些东西的整合。    提交人    /u/Studyr3ddit   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fpo0z8/d_which_feeds_do_you_look_at/</guid>
      <pubDate>Thu, 26 Sep 2024 04:27:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] ViT 受益于双曲空间变换</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fplhvi/r_vits_benefit_from_hyperbolic_space_transform/</link>
      <description><![CDATA[https://arxiv.org/abs/2409.16897    由   提交  /u/jacobfa   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fplhvi/r_vits_benefit_from_hyperbolic_space_transform/</guid>
      <pubDate>Thu, 26 Sep 2024 02:03:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 22 Sep 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>