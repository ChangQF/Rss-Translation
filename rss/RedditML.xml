<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 29 Aug 2024 21:15:09 GMT</lastBuildDate>
    <item>
      <title>[D] 根据零件编号描述文字对材料进行分类的模型建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4c4vq/d_model_suggestion_for_classification_of/</link>
      <description><![CDATA[免责声明：我不是 ML 专业人士，我只建立了少数几个模型，主要用于需求预测（在 R 中），有一次是根据不同组件的数量预测产品装配时间（在 Tensorflow/Keras 中）。 在我目前的职位上，我的任务是创建一个模型，该模型根据描述对材料进行分类，以简化问题，假设我们试图预测材料是否是成品，因此是经典的二元分类。 在将文本通过 tfidfvectorizer 后，我已经尝试了 scikit-learn 中的 MLPClassifier 和 SVC，以及 Xgboost，但模型在测试集上表现不佳。 数据集上的一些上下文，大约 10％ 的数据有标签 1，其余的有标签 0。材料描述不是很清晰，我编写了一些辅助函数进行预处理。 上述已尝试过的模型的混淆矩阵显示，对标签 0 进行分类的准确率约为 90%，对标签 1 进行正确分类的准确率约为 60%。 我的问题：  我如何才能知道这些数据是否真的好，它不像数值数据，我可以计算 X 和 y 之间的相关性？ 由于“最佳模型”的概念并不存在，我正在寻求适合此类应用的模型的建议。我应该用我的数据训练 Hugging Face 的法学硕士吗？还是应该使用 Pytorch 从头开始​​构建深度学习模型，并使用 Torchtext 进行标记？ 我是否应该减少标签 0 数据的数量，使数据集为 1:1？还是应该保持原样（9:1）？  非常感谢！   由    /u/HalfManHalfChimp  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4c4vq/d_model_suggestion_for_classification_of/</guid>
      <pubDate>Thu, 29 Aug 2024 20:08:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 实时推荐系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4allv/d_realtime_recommendation_system/</link>
      <description><![CDATA[我正在阅读有关 Twitter 的推荐算法的官方博客，其中谈到“排名是通过一个约 48M 参数的神经网络实现的，该神经网络在推文互动中不断训练，以优化积极参与度。”我试图了解它是如何根据用户互动不断训练神经网络的，就像 Twitter 的情况一样。  就上下文而言，我正在构建一个 Web 应用程序，基本上是一个社交新闻聚合器。它根据我自己的偏好（例如，只向我推送内容和 ML/LLM 上的人员）从 Reddit、Twitter 和 Hacker News 获取帖子和评论，并且不受广告和政治等干扰。我使用 Python、FastAPI 和 PostgreSQL 作为后端。您将如何设计应用程序架构以确保其性能卓越且准确？    提交人    /u/friedahuang   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4allv/d_realtime_recommendation_system/</guid>
      <pubDate>Thu, 29 Aug 2024 19:04:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么审稿人不需要对反驳作出回应？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f49zq2/d_why_arent_reviewers_required_to_respond_to/</link>
      <description><![CDATA[嗨， 我最近向一个会议提交了论文，很好奇为什么审稿人不需要承认反驳。显然，审稿人往往日程繁忙，而详细的回复往往具有挑战性。但我不明白为什么审稿人至少不需要处理反驳（即使是像“谢谢回复！”或“我很感谢补充信息，我正在更新我的分数以反映它”这样简单的话）    提交人    /u/mathwoman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f49zq2/d_why_arent_reviewers_required_to_respond_to/</guid>
      <pubDate>Thu, 29 Aug 2024 18:39:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审稿人反驳规范</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f49wo1/d_reviewer_rebuttal_norms/</link>
      <description><![CDATA[嗨， 我最近向一个会议提交了论文，很好奇为什么审稿人不需要回应反驳。显然，审稿人往往日程繁忙，但我不明白为什么审稿人不需要至少回应反驳（即使是像“谢谢回复！”或“我很感谢补充信息，我正在更新我的分数以反映它”这样简单的话）    提交人    /u/mathwoman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f49wo1/d_reviewer_rebuttal_norms/</guid>
      <pubDate>Thu, 29 Aug 2024 18:35:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找研究论文合作者</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f45j0s/r_looking_for_people_for_research_paper/</link>
      <description><![CDATA[我想开始撰写更多研究论文。我目前在该行业有 2 年的经验。如果你们感兴趣，可以联系并讨论一下。另外，你的专业领域是什么。我的主要专业是 NLP。    提交人    /u/milanvarghese   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f45j0s/r_looking_for_people_for_research_paper/</guid>
      <pubDate>Thu, 29 Aug 2024 15:37:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在会议的反驳/讨论阶段更新论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f43dwv/d_updating_paper_during_the_rebuttaldiscussion/</link>
      <description><![CDATA[在会议的反驳/讨论阶段更新论文的规则是什么？ 有些会议明确表示不允许这样做。 NeurIPS 作者常见问题解答： 我们可以在反驳/讨论期间上传论文的修订版吗？ 在相机就绪阶段之前不允许进行任何修改。 ICML 作者说明： 在作者反馈期间没有上传论文修订版本的选项。论文被接受后，作者有权在最终的照相排版版本中对论文进行任何修改以改进论文（与审稿人看到的内容相比，本质上不改变其内容）。 但是，在查看前几年在 OpenReview 上发表的论文时，在反驳答案中，许多作者说：我们更新并上传了论文的修订版。.. 按照您的建议，我们在论文修订版的第 2 页进行了更改。 那么，作者是不是忽略了会议的官方声明，决定上传修订版？对于审稿人来说：如果作者在反驳阶段进行更改并上传新版本的论文，是不是更好？    提交人    /u/just_asking_21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f43dwv/d_updating_paper_during_the_rebuttaldiscussion/</guid>
      <pubDate>Thu, 29 Aug 2024 14:09:20 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]英特尔Arc A750机器学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f42r3f/discussion_intel_arc_a750_machine_learning/</link>
      <description><![CDATA[大家好，机器学习者们！我买了一块英特尔 Arc A750 8GB GPU。我一直在阅读英特尔关于在机器学习中使用它的一些文章。有人在机器学习中使用过英特尔 GPU 吗？    提交人    /u/Ferchitoqn   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f42r3f/discussion_intel_arc_a750_machine_learning/</guid>
      <pubDate>Thu, 29 Aug 2024 13:42:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将任何初学者问题发布至 r/MLQuestions！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3yfjg/d_post_any_bginner_questions_to_rmlquestions/</link>
      <description><![CDATA[我最近继承了 subreddit r/MLQuestions，因为其他版主分别有 10 个月和 4 年没有活动。我一直在整理子版块，添加标签、规则等，并试图增加参与度，使其对那些想要提问的人更有用。基本上就是 stackoverflow，但专门用于解决有关 ML 的初学者问题。所以，如果你们有不好意思在这里问的问题，请在 r/MLQuestions 上提问！我还将推出一个类似于 r/changemyview 的系统，其中每回答一个问题，他们的用户天赋就会增加一个，显示他们回答了多少问题！ 顺便说一句，版主允许我发布这篇文章，所以非常感谢你们，非常酷。    提交人    /u/NoLifeGamer2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3yfjg/d_post_any_bginner_questions_to_rmlquestions/</guid>
      <pubDate>Thu, 29 Aug 2024 09:50:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] Eagle：探索混合编码器的多模 LLM 的设计空间</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3yam7/r_eagle_exploring_the_design_space_for_multimodal/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3yam7/r_eagle_exploring_the_design_space_for_multimodal/</guid>
      <pubDate>Thu, 29 Aug 2024 09:40:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对多个市场中多种产品的需求预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3prgk/d_demand_forecasting_for_several_products_across/</link>
      <description><![CDATA[对于那些在零售或消费品行业工作并为公司开发了“自下而上”需求预测模型的人，我很想听听你们是如何实现的，以及哪些方法有效。我目前正在权衡我想要尝试的实验模型选项（看看它们是否能胜过简单的基线模型）。我正在考虑的主要两个选项是：  基于 RNN 的模型。特别是 DeepAR 是我正在关注的一个，因为它引起了很多关注。 一些建立在梯度提升树之上的策略。各种预测竞赛（例如 M4 和 M5）都表明，利用 LightGBM 的策略表现非常出色。  虽然传统的 TS 模型（如 ARIMA/ETS）在单变量情况下很难被击败，但在开发涉及“交叉训练”的全局模型时似乎并非如此，这就是我对这两个选项感兴趣的原因。  我对 DeepAR 有所保留，主要是因为我不完全理解它，而且我尝试阅读论文好几次…… 我读过的 LightGBM 策略更容易理解，而且似乎不太容易正确，所以我倾向于选择此选项。话虽如此，如果能听到大家说说哪些策略对您有效，那就太好了。您或您认识的人是否在这种情况下使用过 DeepAR 或梯度提升树之类的东西，如果是，效果如何？     由   提交  /u/Asleep-Importance-10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3prgk/d_demand_forecasting_for_several_products_across/</guid>
      <pubDate>Thu, 29 Aug 2024 00:59:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 澄清 VAE 中的“重新参数化技巧”以及为什么它是一个技巧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3ohje/d_clarification_on_the_reparameterization_trick/</link>
      <description><![CDATA[我一直在研究变分自动编码器 (VAE)，并且不断遇到术语“重新参数化技巧”。据我所知，该技巧涉及使用公式 (X = 平均值 + 标准偏差 * Z) 从正态分布中抽样，其中 Z 是从标准正态分布中抽取的。此公式似乎是从正态分布中抽样的标准方法 这是我的困惑： 为什么这是一个技巧？ 重新参数化“技巧”通常被强调为一个聪明的技巧，但对我来说，它似乎是转换公式的直接应用。如果 ( X = 平均值 + 标准差 * Z ) 是从正态分布中采样的唯一方法，那么为什么重新参数化技巧被认为特别具有创新性？ 我理解该技巧允许通过采样过程进行反向传播。但是，似乎使用 ( X = 平均值 + 标准差 * Z ) 是从给定 ( 平均值 ) 和 ( 标准差 ) 的正态分布中生成样本的唯一方法。除了确保可区分性之外，这个技巧还有什么特别之处？ 这是我的思维过程：我们从编码器获得平均值和标准差，并从中采样，唯一且最明显的方法是“X = 平均值 + 标准差 * Z”。 有人可以帮忙解释为什么重新参数化技巧被称为“技巧”吗？ 提前感谢您的见解！    提交人    /u/SwaroopMeher   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3ohje/d_clarification_on_the_reparameterization_trick/</guid>
      <pubDate>Wed, 28 Aug 2024 23:57:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于符号距离函数和体积数据结构的 Pytorch 库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3kdlb/p_pytorch_library_for_signed_distance_function/</link>
      <description><![CDATA[      体积数据结构库，通过提供梯度和不破坏自动微分，与 pytorch 生态系统良好交互。查看存储库：https://github.com/UM-ARM-Lab/pytorch_volumetric 您也可以通过以下方式安装 pip install pytorch-volumetric  在特定配置中对机器人进行有符号距离场查找的示例动画： https://i.redd.it/tcjvib45zgld1.gif    提交人    /u/LemonByte   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3kdlb/p_pytorch_library_for_signed_distance_function/</guid>
      <pubDate>Wed, 28 Aug 2024 21:05:23 GMT</pubDate>
    </item>
    <item>
      <title>“边缘写作 (WiM)”——一种更好的长上下文 LLM 推理模式，解决了中间丢失的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3d3uo/writing_in_the_margins_wim_a_better_inference/</link>
      <description><![CDATA[  由    /u/samjulien  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3d3uo/writing_in_the_margins_wim_a_better_inference/</guid>
      <pubDate>Wed, 28 Aug 2024 15:28:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过 Google 研究团队微调的 SD1.4 模型可玩 20FPS 的 Doom</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f31uye/r_playable_20fps_doom_via_a_finetuned_sd14_model/</link>
      <description><![CDATA[  由    /u/greentfrapp  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f31uye/r_playable_20fps_doom_via_a_finetuned_sd14_model/</guid>
      <pubDate>Wed, 28 Aug 2024 04:52:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>