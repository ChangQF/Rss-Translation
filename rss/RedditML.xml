<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 24 Oct 2024 15:18:18 GMT</lastBuildDate>
    <item>
      <title>[项目] 音乐推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gb4p1u/project_music_recommendation/</link>
      <description><![CDATA[我正在参加机器学习训练营，我想​​做一个基于趋势/用户偏好的音乐推荐项目。我正在努力寻找一个数据集。有什么建议吗？我应该如何开始这样的项目？    提交人    /u/Historical-Deer-3835   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gb4p1u/project_music_recommendation/</guid>
      <pubDate>Thu, 24 Oct 2024 15:00:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找有关人工智能对工作和工作意义的影响的书籍和文章推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gb3kuk/r_looking_for_book_and_article_recommendations_on/</link>
      <description><![CDATA[大家好！ 我正在研究人工智能 (AI) 如何影响工作环境，特别是在工作意义和职业认同方面。我关注的是汽车行业和 IT等行业，在这些行业中，AI 正在迅速融入日常运营。我特别感兴趣的是人工智能如何影响工作自主性、任务结构，以及对员工工作目标感和身份认同感的更广泛影响。 我正在寻找推荐学术书籍、文章或研究论文，以探讨：  人工智能对工作角色、自主性和工作意义的影响。 人工智能如何影响职业认同，以及员工如何看待自己在组织中的角色。 围绕人工智能在工作场所的道德考量，尤其是与员工福祉和公平性相关的考量。 来自工作特征模型或类似框架等理论的见解，可以应用于人工智能对工作设计的影响。 案例研究或实证研究，重点关注人工智能在特定行业的整合（汽车、   我会非常感激任何建议，无论是基础文本还是最近的研究。提前感谢您为我指明正确的方向！    提交人    /u/emillindstrom   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gb3kuk/r_looking_for_book_and_article_recommendations_on/</guid>
      <pubDate>Thu, 24 Oct 2024 14:12:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从零开始的神经网络博客</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gb2iwp/d_neural_network_from_scratch_blog/</link>
      <description><![CDATA[嘿，我最近开始了我的机器学习之旅，正在学习神经网络，想从头开始实现它，所以我在 YouTube 上搜索并找到了一个视频。然后我实现了它并做了一些修改，还在 Medium 上写了一篇关于它的博客。我知道这是一个非常基础的东西，我可能会犯很多错误，因为这是我的第一篇博客，也是我第一次做这样的事情。所以我只是想知道大家的意见和建议。 博客链接（当前草稿） - https://medium.com/@pankajgoyal4152/understanding-neural-networks-by-building-one-from-scratch-a-beginners-journey-3a11617313a4 你能读一下博客并告诉我吗？ 我希望这就是“公开学习”的意思，对吧？ 我将非常感谢您的任何建议或任何东西，所以请随意。这可能会对我有很大帮助。    提交人    /u/PixelPioneer-1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gb2iwp/d_neural_network_from_scratch_blog/</guid>
      <pubDate>Thu, 24 Oct 2024 13:23:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我应该如何设置LLM的回复格式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gayuhw/d_how_should_i_set_the_format_for_the_llms/</link>
      <description><![CDATA[微调 LLM 的新手 使用 https://github.com/hiyouga/LLaMA-Factory 例如： 嘿，Bhatgpt，您能修复这个句子中的语法错误吗？ “如果您的任务与检查点模型所训练的任务相似，那么您已经可以使用 LlamaForCausalLM 进行预测而无需进一步训练。”   所需格式： 语法错误更正： 您的句子有一个轻微的语法错误。它应该是：“XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX” 不同场景： 正式： “如果您的任务与检查点模型的训练参数相符，您可以继续使用 LlamaForCausalLM 进行预测，而无需额外的训练要求。” 书面英语： 在任务相似性与检查点模型的训练参数相对应的情况下，可以立即实施 LlamaForCausalLM 进行预测目的，而无需补充训练协议。 口语化： 嘿，如果你的任务与模型最初训练的任务相匹配，你完全可以即插即用 LlamaForCausalLM - 无需额外的训练或任何东西！    提交人    /u/Ggboysformnowhere   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gayuhw/d_how_should_i_set_the_format_for_the_llms/</guid>
      <pubDate>Thu, 24 Oct 2024 09:52:26 GMT</pubDate>
    </item>
    <item>
      <title>[P] 基于多代理人工智能的人力资源信息系统[HRIS]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gaylfx/p_multiagent_ai_based_human_resource_information/</link>
      <description><![CDATA[正如标题所示， 我正在研究构建基于 MAS 的 HRIS 的潜在想法，我正在研究其他经验丰富的人士或任何人的建议，关于如何为我的组织将这个想法构建成一个好的产品 什么样的服务或任何引人注目的用例等 我期待着收到所有人的意见    提交人    /u/Not_so_sure_paradox9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gaylfx/p_multiagent_ai_based_human_resource_information/</guid>
      <pubDate>Thu, 24 Oct 2024 09:33:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 的 Whisper“库”/“框架”等的包装器？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gayjwu/d_wrapper_for_openais_whisper_libraryframework_etc/</link>
      <description><![CDATA[自从 OpenAI 的 Whisper 发布以来，我就一直在使用它的命令行版本，但它并没有提供 Whisper-&quot;框架&quot;（或无论您怎么称呼它）包含的所有选项。一定有人为此编写了一个&quot;包装器&quot;，不是吗？但我在 Google 上找不到任何东西。您能推荐一些吗？ 我有 20 000 个文件，从 10 秒到几个小时不等，我希望尽可能高效、高质量地转录它们（我优先考虑质量而不是效率。目前，我使用带有大型 v3 模型的命令行客户端）。    提交人    /u/la-grave   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gayjwu/d_wrapper_for_openais_whisper_libraryframework_etc/</guid>
      <pubDate>Thu, 24 Oct 2024 09:30:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 将其他输入特征连接到 ViT 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gayiww/r_concatenating_additional_input_features_to_a/</link>
      <description><![CDATA[大家好， 我正在探索将其他输入功能（例如表格数据或其他非图像功能）与图像输入一起集成到 Vision Transformer (ViT) 架构中的方法。 有人尝试过这种方法吗？或者有人知道任何研究论文、博客或参考文献探讨过这个问题吗？我特别感兴趣的是如何以有意义的方式将这些额外的输入与图像标记集成在一起。 在此先感谢任何帮助或指点！    提交人    /u/kernel_KP   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gayiww/r_concatenating_additional_input_features_to_a/</guid>
      <pubDate>Thu, 24 Oct 2024 09:28:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 表格域中的解缠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gay549/r_disentanglement_in_tabular_domain/</link>
      <description><![CDATA[这里有人研究过表格数据中的解缠吗？这可能吗？或者这有意义吗？在没有可量化的基本事实因素的表格数据中，解缠的标准/评估指标是什么？ 背景：我被委托研究这个主题，发现解缠在图像等领域很常见，大多使用 VAE。有一些研究将 VAE 应用于表格数据，特别是为了公平或合成数据生成的目的，但他们并不称之为“解缠”，也没有给出与表格数据解缠相关的任何评估。    提交人    /u/QT-NTU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gay549/r_disentanglement_in_tabular_domain/</guid>
      <pubDate>Thu, 24 Oct 2024 08:59:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 是 CNN 的一种</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gaxscv/d_transformers_are_a_type_of_cnn/</link>
      <description><![CDATA[https://arxiv.org/abs/2309.10713 我随机在谷歌上搜索动态卷积，因为我觉得它们很酷，然后发现了这篇论文，它表明 transformer 相当于一种使用动态卷积的 CNN。动态卷积论文 (https://arxiv.org/abs/1912.03458) 于 2019 年发布，所以它确实在注意力就是你需要的所有论文之后发布。 遗憾的是这篇论文只有一个引用。我认为这太不可思议了。知道 transformers 可以被视为 CNN 让他们能够深入了解优化其设计，包括删除 softmax 激活并将其替换为 Relu+normalisation 层。我认为通过继续他们的工作可以做出更多的改进。    提交人    /u/Ozqo   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gaxscv/d_transformers_are_a_type_of_cnn/</guid>
      <pubDate>Thu, 24 Oct 2024 08:31:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] KAN 论文以一种有趣的方式将无监督问题转变为监督问题（允许某些样本存在差异）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gau1kt/r_the_kan_paper_has_this_interesting_way_to_turn/</link>
      <description><![CDATA[在 KAN 论文中，他们有一种有趣的方法来推断变量之间的映射，即允许部分数据样本的变量创建正样本和负样本。一种对比学习的形式。他们没有引用这种方法，是否有更多公式化的方法可以进行这种分析，以无监督的方式研究变量之间的关系。  第 4.2 节 - https://arxiv.org/abs/2404.19756    提交人    /u/Sandy_dude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gau1kt/r_the_kan_paper_has_this_interesting_way_to_turn/</guid>
      <pubDate>Thu, 24 Oct 2024 04:07:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 新款 Claude Sonnet 3.5 如何提供精确的坐标？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gasb94/d_how_could_the_new_claude_sonnet_35_provide/</link>
      <description><![CDATA[不确定以前是否有人问过这个问题，但最近发布的 Claude Sonnet 让我很惊讶。几个月前，我尝试了许多 LLM 来为我提供屏幕截图上的 (x, y) 坐标，使用各种方法，如网格位置、标记坐标等，但精度不够。但是；这个新模型实际上可以提供非常精确的坐标。有人知道/我们能猜出他们为这样的事情使用的系统吗？他们可以使用其他模型，如 SeeClick 吗？    提交人    /u/super_deap   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gasb94/d_how_could_the_new_claude_sonnet_35_provide/</guid>
      <pubDate>Thu, 24 Oct 2024 02:31:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] Ichigo：混合模式早期融合实时语音助手</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gae6tb/r_ichigo_mixedmodal_earlyfusion_realtime_voice/</link>
      <description><![CDATA[  由    /u/emreckartal  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gae6tb/r_ichigo_mixedmodal_earlyfusion_realtime_voice/</guid>
      <pubDate>Wed, 23 Oct 2024 16:03:30 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 世界上第一个自主 AI 发现的 0day 漏洞</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ga8wxn/project_worlds_first_autonomous_aidiscovered_0day/</link>
      <description><![CDATA[我确信很多人都通过将代码片段粘贴到 ChatGPT 中发现了 0-day 漏洞。问题一直是扫描整个项目的 0-day。一些论文表明，通过向其代理提供已知的易受攻击的代码是可能的，但据我所知，这些论文都没有获得任何 CVE 或发现真正的 0-day。Vulnhuntr 本周末发布，在 10k+ GitHub 星的开源项目中发现了十多个 0-day： https://github.com/protectai/vulnhuntr    提交人    /u/FlyingTriangle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ga8wxn/project_worlds_first_autonomous_aidiscovered_0day/</guid>
      <pubDate>Wed, 23 Oct 2024 12:07:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g80nkv/d_simple_questions_thread/</guid>
      <pubDate>Sun, 20 Oct 2024 15:00:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>