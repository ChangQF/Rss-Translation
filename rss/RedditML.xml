<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 25 Mar 2024 21:12:24 GMT</lastBuildDate>
    <item>
      <title>[D] ADAM 的替代品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnp1ag/d_alternatives_to_adam/</link>
      <description><![CDATA[机器学习从业者您好， 我想知道对于 NN 来说，除了 ADAM 之外还有哪些替代优化器？是否有比 ADAM 性能更好的替代方案？您会推荐哪个来优化 NLL 损失函数？ 我很感激任何建议或信息。非常感谢！   由   提交 /u/LItzaV   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnp1ag/d_alternatives_to_adam/</guid>
      <pubDate>Mon, 25 Mar 2024 21:06:12 GMT</pubDate>
    </item>
    <item>
      <title>【讨论】论“轨迹一致性蒸馏”的抄袭行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnmus0/discussion_on_plagiarism_of_trajectory/</link>
      <description><![CDATA[   我们遗憾地发现了我们的一致性轨迹模型（CTM、ICLR24） 被抄袭 轨迹一致性蒸馏（TCD）！令人难以置信——他们不仅窃取了我们关于轨迹一致性的想法，而且还犯下了“逐字剽窃”的罪名，逐字逐句地复制我们的证明！我们试图与 TCD 作者解决这个抄袭问题，但谈话令人失望，问题仍然没有解决。您可以在此处查看有关抄袭的更多信息。  ​ 逐字抄袭通过 TCD 对抗 CTM  TCD 针对 CTM 的抄袭行为列表   由   提交/u/Embarrassed_Aerie387  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnmus0/discussion_on_plagiarism_of_trajectory/</guid>
      <pubDate>Mon, 25 Mar 2024 19:42:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] Marigold-LCM：基于稳定扩散的快速单目深度估计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnlvcw/p_marigoldlcm_fast_monocular_depth_estimation/</link>
      <description><![CDATA[Marigold 是一种通用的单目深度估计器，可在野外提供令人难以置信的敏锐预测。它基于稳定扩散，仅使用合成深度数据进行训练，并且在零样本适应现实世界图像方面表现出色。原始方法需要数十秒来处理原始图像，考虑到深度图质量的提升，这是合理的。追随文本到图像研究的脚步，我们对原始模型进行了潜在一致性蒸馏，从而实现了一个数量级的加速。看看吧！ 演示：https://huggingface.co/spaces/prs-eth /marigold-lcm 论文：https://arxiv.org/abs/2312.02145  代码：https://github.com/prs-eth/marigold 网站：https://marigoldmonodepth.github.io/ &lt;!-- SC_ON - -&gt;  由   提交 /u/toshass   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnlvcw/p_marigoldlcm_fast_monocular_depth_estimation/</guid>
      <pubDate>Mon, 25 Mar 2024 19:04:23 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于使用多个头来预测同一分类任务的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnkwkg/d_paper_about_using_multiple_heads_for_predicting/</link>
      <description><![CDATA[我需要帮助查找论文。我不确定这篇论文是否是我产生的幻觉，因为谷歌不会给我任何结果。如果我没记错的话，这篇论文描述了一种通过对同一类使用多个头来训练模型的新方法，本质上是将单标签任务变成多标签任务。  之后，当您想要进行预测时，您只需选择性能最佳的头即可。  我认为作者将其比作一种集成？我不太确定。  非常感谢您帮助找到一篇与我所描述的内容接近的论文！   由   提交/u/2133  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnkwkg/d_paper_about_using_multiple_heads_for_predicting/</guid>
      <pubDate>Mon, 25 Mar 2024 18:26:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 连续状态和动作空间的近似策略迭代</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnkl8w/d_approximate_policy_iteration_for_continuous/</link>
      <description><![CDATA[我遇到的大多数理论分析都处理有限状态或动作空间，或一些其他算法，如近似拟合迭代等。 当状态和动作空间连续时，有关于\epsilon近似策略迭代收敛的理论结果吗？ 我记得一篇单独的论文处理近似策略迭代，其中假设近似误差为随着时间的推移趋于零，但是如果误差是恒定的怎么办？ 此外，是否存在“正统”的误差？这种算法的实际版本与理论算法相匹配吗？   由   提交/u/_An_Other_Account_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnkl8w/d_approximate_policy_iteration_for_continuous/</guid>
      <pubDate>Mon, 25 Mar 2024 18:13:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在损失景观中寻找大量局部最小值</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnihz3/d_searching_for_large_numbers_of_local_minima_in/</link>
      <description><![CDATA[我刚刚观看了此视频其中描述了最近的一篇论文，该论文寻找稳定的弹性结构型，这是弹性势能景观中的局部最小值。据我所知，论文用于查找这些稳定配置的算法是执行以下大量操作：1. 随机采样结的初始状态，2. 运行优化算法，直到达到局部最小值（在在这种情况下，优化算法是物理模拟），3.使用聚类来消除重复的局部最小值。 我对此问题的更通用版本感兴趣。有哪些现有方法可以在任意损失情况下找到大量局部最小值？还有什么比重复随机采样初始状态并优化该状态更好的吗？是否有某些采样或优化方法能够更好地产生局部最小值的多样性？我对适用于高维空间的算法特别感兴趣。   由   提交/u/kei147  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnihz3/d_searching_for_large_numbers_of_local_minima_in/</guid>
      <pubDate>Mon, 25 Mar 2024 16:51:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何获取大量样式丰富的手写公式以及对应的文本标签？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bniej1/d_how_to_obtain_a_large_number_of_handwritten/</link>
      <description><![CDATA[大家好，我是机器学习的初学者。最近，我训练了一个模型，可以将公式图像转换为相应的 LaTeX 文本。这个模型使用了750万对图像公式进行了训练，最终的性能相当不错（我也将该模型开源了：https://github.com/OleehyO/TexTeller）。&lt; /p&gt; 但是，当前模型不支持手写因为我找不到大量手写公式图像及其对应的 LaTeX 文本。这使我无法在大型-像以前一样缩放数据集，这将使模型能够识别手写公式。 我知道我可以使用 LaTeX 的手写字体来生成此类样本，但是这样生成的手写图像的风格太 那么，有没有人有什么好的想法来获取大量与 LaTeX 文本配对的手写公式样本？ &lt; !-- SC_ON --&gt;  由   提交/u/Admirable_Grape6372   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bniej1/d_how_to_obtain_a_large_number_of_handwritten/</guid>
      <pubDate>Mon, 25 Mar 2024 16:47:18 GMT</pubDate>
    </item>
    <item>
      <title>ICLR 2024：可证明且实用：通过 Langevin Monte Carlo 对强化学习进行有效探索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnfzrs/iclr_2024_provable_and_practical_efficient/</link>
      <description><![CDATA[ 由   提交/u/hmi2015  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnfzrs/iclr_2024_provable_and_practical_efficient/</guid>
      <pubDate>Mon, 25 Mar 2024 15:08:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 泰米尔语米斯特拉尔简介：通过法学硕士预训练开辟新的语言可能性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnfsw5/p_introducing_tamil_mistral_opening_up_new/</link>
      <description><![CDATA[嘿伙计们，你们一定要看看 Tamil Mistral 的最新更新！这是一个增强版本，可解决在现有 Mistral 框架内标记泰米尔语单词（尤其是“uyir ezuthukal”）的棘手任务。 我已将词汇从 32k 增加到 50k，并调整了嵌入大小。另外，在使用 Mistral 基础模型进行预训练期间，我向模型输入了 25GB 的泰米尔语文本，从而大大增强了模型的大脑功能。然后，我使用特定的泰米尔语指令对其进行了微调，以进一步提高其聊天性能。 对于预训练，投入了 25GB 的泰米尔语数据集（使用 A6000 48GB 大约需要 145 小时） 。为了进行微调，使用了大约 470k 泰米尔语指令（从 Google 翻译翻译和编辑），花费了大约 20 个小时。 基础模型：泰米尔语基础模型 指令模型：泰米尔语指令模型   由   提交/u/Ok-Measurement-6286   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnfsw5/p_introducing_tamil_mistral_opening_up_new/</guid>
      <pubDate>Mon, 25 Mar 2024 15:00:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] SIGIR 2024通知</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bncxen/d_sigir_2024_notification/</link>
      <description><![CDATA[今天发布的 SIGIR 2024 通知的讨论主题。祝大家好运。   由   提交/u/Immediate_Party_5698   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bncxen/d_sigir_2024_notification/</guid>
      <pubDate>Mon, 25 Mar 2024 12:54:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你的薪水主要取决于地理位置，而不是你的技能水平（根据 24k 样本和 300 个问题建立的薪水模型得出的结论）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bn88ql/d_your_salary_is_determined_mainly_by_geography/</link>
      <description><![CDATA[      我建立了一个模型，根据 2022 年 Kaggle 机器学习和机器学习的 23,997 条回复和 294 个问题来预测数据科学家/机器学习工程师的薪资。数据科学调查（来源：https://jobs-in-data.com/salary/data-scientist-工资） 我研究了 LGBM 模型中的特征重要性。 TL;DR：居住国家更重要一个数量级 该模型是为数据职业构建的，但在我看来它也适用于其他职业。 ​  https://preview.redd.it/6b9r67lctfqc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=73b437e43c754ede0b19e42d95655edd4b5adc95  &amp; #32；由   提交/u/pg860  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bn88ql/d_your_salary_is_determined_mainly_by_geography/</guid>
      <pubDate>Mon, 25 Mar 2024 08:03:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果我无法理解研究论文的某些部分并且无法在 Google 搜索中找到任何相关信息，你们会推荐什么方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bn48lw/d_what_approach_do_you_guys_recommend_if_im_stuck/</link>
      <description><![CDATA[我尝试在 Google 上搜索我最近读过的论文 (Sync Dreamer) 中的一些内容。尝试过 ChatGPT，并在 Reddit 和 stackechange 上发布我的疑问。当你无法理解论文中的某些段落时，你们会使用一些技巧吗？你怎样做呢？    由   提交 /u/ChaosAdm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bn48lw/d_what_approach_do_you_guys_recommend_if_im_stuck/</guid>
      <pubDate>Mon, 25 Mar 2024 03:43:09 GMT</pubDate>
    </item>
    <item>
      <title>新算法解锁计算机视觉的高分辨率见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmsk2m/new_algorithm_unlocks_highresolution_insights_for/</link>
      <description><![CDATA[      很棒的论文！ &lt;!-- SC_ON - -&gt;  由   提交/u/CrispLion1123  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmsk2m/new_algorithm_unlocks_highresolution_insights_for/</guid>
      <pubDate>Sun, 24 Mar 2024 19:06:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 请推荐如何让 ML 面试对候选人来说更好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmo6r0/d_please_recommend_ways_to_make_ml_interview/</link>
      <description><![CDATA[有一个线程抱怨 ML 面试过于详尽。 作为招聘经理，我希望获得关于制定 ML 的建议面试效果更好。  需要避免哪些事情？ 需要包括哪些好的步骤？    由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmo6r0/d_please_recommend_ways_to_make_ml_interview/</guid>
      <pubDate>Sun, 24 Mar 2024 16:01:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>