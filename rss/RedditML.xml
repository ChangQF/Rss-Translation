<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Mon, 20 May 2024 18:18:29 GMT</lastBuildDate>
    <item>
      <title>[D] 与使用传统分类器相比，使用自定义神经网络作为堆叠集成的辅助元学习器有何优点和缺点？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwij7u/d_what_is_the_advantage_and_disadvantage_of_using/</link>
      <description><![CDATA[这可能吗？我读过的每本期刊都只提到 xgboost、逻辑回归等分类器的使用。然而，当我在 chatgpt 上询问时，它推荐神经网络集成作为最有效的辅助元学习器进行堆叠。    由   提交/u/Mental_Ad_9152   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwij7u/d_what_is_the_advantage_and_disadvantage_of_using/</guid>
      <pubDate>Mon, 20 May 2024 15:37:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] Instagram应用上评论的音译+翻译</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwiemd/d_transliteration_translation_of_comments_on/</link>
      <description><![CDATA[是我一个人还是有人注意到翻译质量的显着提高 - 特别是使用英语字符编写的语言的翻译（音译 + 翻译） ）。想知道他们使用什么样的模型导致了突然的改进   由   提交/u/ts_aditya  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwiemd/d_transliteration_translation_of_comments_on/</guid>
      <pubDate>Mon, 20 May 2024 15:31:51 GMT</pubDate>
    </item>
    <item>
      <title>预测二元机器学习 - 变量选择 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwel28/predictive_binary_ml_variable_selection_d/</link>
      <description><![CDATA[嗨， 我几个月来一直在研究二元预测模型。我正在尝试优化变量选择。我大约有 12 个。 使用套索、最佳子集、树等不是我想要的。我试图循环遍历所有组合，但不仅难以编码，而且我还怀疑如果我编码，我的笔记本电脑是否能够处理它。  有什么建议吗？    由   提交/u/wiktor2701   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwel28/predictive_binary_ml_variable_selection_d/</guid>
      <pubDate>Mon, 20 May 2024 12:39:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] SDG-增加了对基于GPT的单表合成数据生成的支持</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwdicc/p_sdg_adds_support_for_gptbased_synthetic_data/</link>
      <description><![CDATA[https://github.com /hitsz-ids/synthetic-data-generator   由   提交 /u/hitszids   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwdicc/p_sdg_adds_support_for_gptbased_synthetic_data/</guid>
      <pubDate>Mon, 20 May 2024 11:42:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 医学语言代理模拟（基准）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cw5luk/r_medical_language_agent_simulation_benchmark/</link>
      <description><![CDATA[网站：https://agentclinic .github.io/ Arxiv：https://arxiv.org/pdf/ 2405.07960 TLDR： AgentClinic 将静态医疗 QA 问题转化为临床环境（医生、患者、医疗设备）中的代理，以提出更具临床相关性的挑战医学语言模型。 摘要：诊断和管理患者是一个复杂的、连续的决策过程，需要医生获取信息——例如要执行哪些测试—— ——并据此采取行动。人工智能 (AI) 和大语言模型 (LLM) 的最新进展有望对临床护理产生深远影响。然而，当前的评估方案过度依赖静态的医学问答基准，缺乏现实临床工作中所需的交互式决策。在这里，我们介绍 AgentClinic：一个多模式基准，用于评估法学硕士在模拟临床环境中作为代理运作的能力。在我们的基准中，医生代理必须通过对话和主动数据收集来揭示患者的诊断。我们提出了两个开放基准：多模态图像和对话环境 AgentClinic-NEJM 和纯对话环境 AgentClinic-MedQA。 AgentClinic-MedQA 中的代理以美国医学执照考试 (USMLE) 中的案例为基础，AgentClinic-NEJM 中的代理以多模式新英格兰医学杂志 (NEJM) 案例挑战为基础。我们在患者和医生代理中嵌入认知和隐性偏见，以模拟有偏见的代理之间的现实互动。我们发现引入偏差会导致医生代理人的诊断准确性大幅降低，以及患者代理人的依从性、信心和后续咨询意愿的降低。通过评估一套最先进的法学硕士，我们发现一些在 MedQA 等基准测试中表现出色的模型在 AgentClinic-MedQA 中表现不佳。我们发现患者代理中使用的 LLM 是 AgentClinic 基准测试中性能的重要因素。我们表明，有限的相互作用和过多的相互作用都会降低医生代理的诊断准确性。   由   提交/u/panthsdger  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cw5luk/r_medical_language_agent_simulation_benchmark/</guid>
      <pubDate>Mon, 20 May 2024 03:01:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 模型并行的当前发展水平如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cw35by/r_what_is_the_stateofart_of_model_parallelism/</link>
      <description><![CDATA[使用 PyTorch、Tensorflow 等常见框架实现模型并行是否容易？这取决于模型架构？模型并行性最常用的方法是什么？   由   提交/u/Various_Protection71   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cw35by/r_what_is_the_stateofart_of_model_parallelism/</guid>
      <pubDate>Mon, 20 May 2024 00:51:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] AlphaFold 3 的简化 PyTorch 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cw0n8b/p_simplified_pytorch_implementation_of_alphafold_3/</link>
      <description><![CDATA[       由   提交/u/csozboz  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cw0n8b/p_simplified_pytorch_implementation_of_alphafold_3/</guid>
      <pubDate>Sun, 19 May 2024 22:48:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您认为未来几年机器学习将在计算生物学和生物信息学等领域发挥什么作用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvxcbc/d_what_role_do_you_think_machine_learning_will/</link>
      <description><![CDATA[我相信计算生物学和生物信息学将越来越多地采用机器学习工作，我很高兴看到所取得的进步。我认为它将在将疾病与可能在标签外使用的现有药物相匹配方面开辟一个全新的世界。我们还应该注意哪些其他事情？ 谁是在这个世界上工作的研究人员？   由   提交/u/RawCS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvxcbc/d_what_role_do_you_think_machine_learning_will/</guid>
      <pubDate>Sun, 19 May 2024 20:19:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM可观察性工具真的在初创公司和公司中使用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvwohz/d_are_llm_observability_tools_really_used_in/</link>
      <description><![CDATA[每周都会推出许多 LLM 可观察性和监控工具。它们真的被真正的初创公司和公司使用吗？  这些工具似乎可以执行以下一项或多项操作： - 监控 LLM 输入和输出以发现提示注入、对抗性攻击、脏话、偏离主题的内容、RTC - &lt;随着时间的推移，监控 LLM 指标，例如成本、延迟、可读性、输出长度和自定义指标（语气、情绪等）、偏差 - 提示管理：a/b 测试、版本控制、黄金标准集 您观察到了什么 - 在拥有自己的 LLM 功能或产品的真实公司中，他们使用这些工具吗？   由   提交 /u/WolvesOfAllStreets   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvwohz/d_are_llm_observability_tools_really_used_in/</guid>
      <pubDate>Sun, 19 May 2024 19:50:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] DSPy 真的改变了 LM 权重吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvsviu/d_does_dspy_actually_change_the_lm_weights/</link>
      <description><![CDATA[我一直认为它本质上是美化和结构化的提示工程（在我看来仍然非常有用），但它也在文档中声称它进行了微调和更改LM 权重，然后绝对拒绝在其文档的任何部分中详细说明这一点。 我什至不明白它如何改变 LM 的实际参数，特别是如果我们使用LM 的第三方 API 调用。  通过 LM 权重，我认为它意味着变压器模型最后一层的权重。当他们描述优化器时，他们说“DSPy 引入了新的优化器，这是 LM 驱动的算法，可以根据您想要最大化的指标调整 LM 调用的提示和/或权重。” &lt; p&gt;我是否误解了 LM 权重的含义？ 如果这是一个愚蠢的问题，我很抱歉，但我似乎找不到任何有关此的信息。提前致谢！   由   提交 /u/chessnudes   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvsviu/d_does_dspy_actually_change_the_lm_weights/</guid>
      <pubDate>Sun, 19 May 2024 16:58:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 是如何从从事令人兴奋的研究变成一家类似大型科技公司的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</link>
      <description><![CDATA[我最近重新审视了 OpenAI 关于 DOTA2 Open 的论文五，从工程和研究的角度来看，他们在那里所做的事情令人印象深刻。创建一个包含 50k 个 CPU 的分布式系统用于部署，1k 个 GPU 用于训练，同时每 0.25 秒从 16k 个观察中执行 8k 到 80k 个操作 - 这有多疯狂？他们还对 RL 模型进行“手术”以恢复权重，因为在几个月的训练中，他们的奖励函数、观察空间甚至架构都发生了变化。最后但并非最不重要的一点是，他们击败了 OG 队（当时的世界冠军），并部署了代理与其他玩家在线实时比赛。  快进几年，他们正在预测序列中的下一个标记。不要误会我的意思，gpt4 及其全能版本的功能确实是工程和研究的惊人壮举（可能更有用），但它们似乎并不像它们的一些产品那样有趣（从研究角度来看）  那么，现在我想知道这些年来工程师和研究人员是如何转变的？主要是由于他们的财务状况和盈利需要，还是有更深层次的原因进行转型？   由   提交 /u/UnluckyNeck3925   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</guid>
      <pubDate>Sun, 19 May 2024 16:46:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在机器学习中回收旧会议提交内容的文化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</link>
      <description><![CDATA[我从事统计机器学习工作。我注意到很多人（包括我自己和我审阅的人）经常重复他们向 ML 会议提交的论文。 例如，如果他们的论文被 ICML 拒绝，他们会提交给 NeurIPS，然后提交给 ICLR（或UAI/AISTATS 在我的领域也是顶尖的）。如果2~3次后没有进入ICML/NeurIPS/ICLR，他们就会将其提交给AAAI/IJCAI/TMLR/ICDM，T-NNLS/T-KDD/NN/Neurocomputing等期刊，或特定领域的场地，如LoG/CoLLA/AABI。经过所有这些，如果论文仍然没有被接受，他们就简单地将它们或 arXiv.我相信 CV/NLP 也可能是这种情况。 作为审稿人，我经常遇到会议提交的内容，作者在没有真正考虑之前提供的审稿的情况下重新提交。有时他们在重新提交时确实会纳入审稿意见，但有时工作可能只是达不到一级会议的水平，但他们只是不断重新提交并希望能够偶然被接受。 我认为这正在消耗社区审稿人的大量时间来继续审阅相同的提交内容（特别是考虑到 NeurIPS 达到 20k 提交 ID；我预计会看到许多重新提交）。这也许也是 TMLR 诞生的原因之一（强调正确性而不是新颖性）。 我确实理解“研究质量比发表地点更重要”之类的论点。或者“OpenAI 通常只是简单地将他们的论文（例如 GPT-X）放在 arXiv 上”。然而，学生或初级研究人员在他们的职业生涯中也需要发表论文，包括我自己。  人们对此有何看法？   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</guid>
      <pubDate>Sun, 19 May 2024 14:04:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在机器学习中有效地进行消融研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/</link>
      <description><![CDATA[在对可预训练和微调的模型进行消融研究时，您是否在预训练和微调期间对每个消融版本执行完整的网格搜索微调？或者你有策略让这个过程更加高效吗？感谢您的见解。   由   提交 /u/Few-Pomegranate4369    reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvoten/d_how_do_you_efficiently_conduct_ablation_studies/</guid>
      <pubDate>Sun, 19 May 2024 13:54:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] N 路注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvkrpf/p_nwayattention/</link>
      <description><![CDATA[我一直在研究在 Transformer 模型中关注两个以上 token 的概念。例如，不是只有一个查询和一个键，而是有两个键和一个查询，并且每个查询都对之前的每对 token 求和。 它使算法变得更慢（O(n**3) 而不是 O(n**2)），但我认为这是一个有趣的概念。有些结果令我感到惊讶，比如它在寻找最长递增子序列方面表现得非常好。 我想分享它： https://github.com/Gusanidas/n-way-attention/tree/main 并询问是否有人知道处理这个概念的论文，或者提到它。    提交人    /u/Gusanidas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvkrpf/p_nwayattention/</guid>
      <pubDate>Sun, 19 May 2024 09:56:26 GMT</pubDate>
    </item>
    </channel>
</rss>