<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Thu, 06 Mar 2025 21:16:27 GMT</lastBuildDate>
    <item>
      <title>[d]寻求建议：在两个数据科学角色之间选择</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j55wqz/d_seeking_advice_choosing_between_two_data/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我很幸运能够在ICLR和ECCV等顶级会议上发布，以及其他第二层场所，例如模式识别和信息理论等期刊。我的研究重点是将信息理论概念整合到计算机视觉的深度学习中，解决：&lt; /p&gt; 1️⃣知识蒸馏2️概括性能3️⃣模型量化4️⃣在经典压缩技术中优化DL 5️⃣高度启动&lt; /prestique  4Thmove  4Thmody  themant for Complation for Cornement Inveriage 诺基亚的贝尔实验室/诺基亚和云网络服务目前正在8个月的数据科学实习中。 最近，我收到了两个工作机会：     calix   - 高级数据科学家 📌📌在Genai上为各种项目而工作的新团队 br/&gt; sight fors  sight inter  sight inter  30k br/&gt; &lt;30k br/&gt; &lt;30k cad br/&gt;） href =“ https://builtin.com/job/senior-data-scientist/3603162”&gt; https://builtin.com/job/job/job/senior-data-scientist/3603162 。学习项目 该决定不仅涉及薪酬，还与我的研究背景有关。我很想听听社区的意见 - 您会考虑做出这一决定的哪些因素？  #machinelearning #machinelearning #deeplearning #datascienciencience #careergrowth #careergrowth＃ai   &lt;！ -  sc_on-&gt; &lt;！提交由＆＃32; /u/u/defiant_lie_659     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1J55WQZ/D_SEEKING_ADVICE_CHOOSED_CHOOSES_BETWIENE_TWO_DATA/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j55wqz/d_seeking_advice_choosing_between_two_data/</guid>
      <pubDate>Thu, 06 Mar 2025 20:57:27 GMT</pubDate>
    </item>
    <item>
      <title>[P]排名算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j55rj8/p_ranking_algorithm/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在尝试阅读有关standign算法的相关研究论文，并特别使用XGBranker构建了一个案例研究。您能帮我良好的资源吗？研究论文/良好的案例研究和学习材料。感谢任何帮助。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/inapprep101     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j55rj8/p_ranking_algorithm/</guid>
      <pubDate>Thu, 06 Mar 2025 20:51:16 GMT</pubDate>
    </item>
    <item>
      <title>[d]训练炒MNIST的修道院</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4z9lf/d_training_a_convent_on_scrambled_mnist/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  我做了一些实验，以查看训练convnet在MNIST图像和拼写副本的混合中的效果。我从一个非常简单的网络开始，具有2个卷积层和2个密集的层，后来尝试了更多的技巧，例如合并和批处理归一化。数据集是从所有数字中采样的MNIST + 10％炒图像。有11个标签：0-9，对应于实际数字，“ 69”。对于炒示例。 无论我做什么，网络都不会超过70％的测试准确性。我知道该模型将被噪音抛弃或学会区分噪声与图案。我看到的是令人困惑。当我查看混淆矩阵时，0-6被准确地分类。但是标签7、8和9完全错误地分类为其继任标签：7  - ＆GT; 8、8-＆GT; 9和9-＆gt;69。 我找不到代码的明显问题。有人有任何有趣的假设吗？    代码： https：//github.com/farhanhanhanhabble/scrambled-mnist-mnist-mnist-mnist-mnist-mnist 提交由＆＃32; /u/u/farhanhubble     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4z9lf/d_training_a_convent_on_scrambled_mnist/</guid>
      <pubDate>Thu, 06 Mar 2025 16:22:39 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]寻求有关优化AI基础架构的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4yrvh/discussion_seeking_advice_on_optimizing_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我是一家正在迅速扩展的初创公司的一部分，我们目前在AI基础架构中面临挑战。 As we continue to grow, the costs and complexities associated with managing our AI workloads have become significant concerns. We&#39;ve been exploring various solutions to optimize our infrastructure, including:  Cost-effective compute resources: Balancing performance with budget constraints. Efficient workload management: Implementing strategies to handle increasing工作负载而不会损害速度或准确性。  可伸缩性：确保我们的基础架构可以适应我们的增长轨迹。   我遇到了一篇有见地的文章，讨论了与AI计算以及某些公司如何导航这些挑战的高成本。 href =“ https://a16z.com/navigating-the-high-cost-of-ai-compute/?utm_source=chatgpt.com”&gt; a16z.com     我正在与这个社区联系，以收集洞察力和建议：       成本？   您是否建议您为初创企业推荐特定的平台或服务，以便有效地扩展其AI的功能？    在扩展AI基础设施时，可以避免任何经验教训或陷阱，以避免使用AI基础设施？谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/parasssssssssssssssssssss     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4yrvh/discussion_seeking_advice_on_optimizing_ai/</guid>
      <pubDate>Thu, 06 Mar 2025 16:01:41 GMT</pubDate>
    </item>
    <item>
      <title>[d]如何在多输出回归问题中限制输出？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4v8r9/d_how_to_constrain_outputs_in_a_multioutput/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在处理一个多出输出回归问题，我需要对输出进行约束。具体来说，我需要说两个预测值等于给定的输入特征：y1+y2 = xi。任何指导都将不胜感激！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/gigi-25     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4v8r9/d_how_to_constrain_outputs_in_a_multioutput/</guid>
      <pubDate>Thu, 06 Mar 2025 13:18:25 GMT</pubDate>
    </item>
    <item>
      <title>[d]预处理管道的最佳编码实践是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4to0e/d_whats_the_best_coding_practice_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi mlers，推荐的策略是什么（以及为什么）构建用于1）ML开发和2）ML生产环境的预处理管道的建议。使用Sklearn.Pipelines或使用Numpy/Pandas创建预处理功能，还是使用方法适合和转换或任何其他方法来建立预处理类，是最佳实践吗？请分享您对最佳实践的想法。 *如果您也可以共享示例代码，这将是很棒的！提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j4to0e/d_whats_thate_the_best_coding_practice_for/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4to0e/d_whats_the_best_coding_practice_for/</guid>
      <pubDate>Thu, 06 Mar 2025 11:46:12 GMT</pubDate>
    </item>
    <item>
      <title>[r]启用语言模型自我完善的认知行为：分析验证，回溯，子目标和后退链接</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4szaa/r_cognitive_behaviors_that_enable_language_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在探索LLM可以提高自己的推理能力，而Google研究的这篇新论文确定了四种特定的认知行为，这些行为能够在推理模型中进行自我改进，而无需进行其他培训，而无需其他培训。 Double-checking: Models review their work, looking for calculation errors or logical inconsistencies Seeking background knowledge: Models identify information gaps and retrieve missing knowledge Step-back reasoning: Models approach problems from a higher level of abstraction before diving into details Heuristic放松：模型放弃了无效的初始方法，并尝试替代解决方案  这些结果在多个推理领域跨多个推理领域令人信服：  在数学推理（GSM8K）上测试（GSM8K），常识性推理（策略QA）和符号推理（最后字母串联）                  将多种行为结合起来产生了最强的改进 双重检查对数学推理的特殊价值   在GPT-4和Mistral    （我认为这项研究）的好处中出现了好处，我认为这项研究是有价值的。首先，它提供了具体的，可实施的技术，可以提高现有模型中的推理能力，而无需进行体系结构的变化。其次，它通过在LLM中形式化类似人类的元认知策略来弥合认知科学和AI。最后，它提出了一种模块化方法的改进方法 - 而不是将推理视为一种整体能力，我们可以将其分解为可以单独增强的特定认知行为。  tldr：研究人员确定了四个认知行为（确定了四个认知行为（识别双重训练，寻求知识，较高的推理），并没有启用较高的推理，以提高他们的启用模型，以提高他们的启用自身的启用）。这些类似人类的策略可大大提高数学，常识性和符号推理任务的性能。  纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j4szaa/r_cognitive_behaviors_that_enable_enable_language_model/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4szaa/r_cognitive_behaviors_that_enable_language_model/</guid>
      <pubDate>Thu, 06 Mar 2025 11:00:08 GMT</pubDate>
    </item>
    <item>
      <title>[d] ML基础设施不必吮吸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4k7ww/d_ml_infrastructure_doesnt_have_to_suck/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我们多年来一直在进行数据科学和ML。迭代我们的工具已有几年之后，我们终于解决了一些我们满意的工具。因此，通常您会看到很难使用的炒作工具。 我不是帖子的作者。但是我和那些写这篇  &lt;！ -  sc_on-&gt;＆＃32;的家伙一起工作。提交由＆＃32; /u/u/brianattwell     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4k7ww/d_ml_infrastructure_doesnt_have_to_suck/</guid>
      <pubDate>Thu, 06 Mar 2025 01:44:07 GMT</pubDate>
    </item>
    <item>
      <title>[P]培训1.5B的生锈编码器LM使用加固学习（GRPO）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4irp9/p_training_a_rust_15b_coder_lm_with_reinforcement/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，我们想在一个任务上测试GRPO，而不仅仅是通过使用GSM8K来优化小学数学课程的推理。认为我们是否可以使用Rust的“货物”工具作为反馈来改善编码的小语言模型会很有趣。我们为编译器，Linter设计了一些奖励功能，如果代码通过了单位测试。 在15K示例的培训时期，1.5B型号从将构建的时间传递到〜80％到〜80％，并将单位测试通过22％到37％的时间。第一次刺伤的结果令人鼓舞。接下来尝试一些较大的模型会很有趣。 我概述了下面的所有详细信息和代码，您有兴趣！ 博客文章：https://www.oxen.ai/blog/training-a-rust-1-5b-coder-lm-with-reinforcement-learning-grpo Code:  https://github.com/oxen-ai/oxen-ai/grpo-with-with-with-cargo-feedback/tree/main/main/main/main  提交由＆＃32; /u/u/u/fallmindless3563     [links]       [注释]     ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4irp9/p_training_a_rust_15b_coder_lm_with_reinforcement/</guid>
      <pubDate>Thu, 06 Mar 2025 00:33:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM研究人员：您通常用于研究工作流程什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4idbe/d_llm_researchers_what_do_you_typically_use_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是LMS的博士生，并试图运行已发表的论文的工作流程。该论文将LM评估 - 与VLLM一起用作背景。我探索了VLLM几天，并意识到它可能是为工业级别的高通量设计而设计的，但对于研究人员来说可能不是很友好。如果我的目标是迅速开发有关中型模型的研究思想（例如3〜10b参数）。培训和评估的最佳实践是什么？您是集成了现有框架，还是在自己的代码库上构建？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/oncecookedpork     [link]    [commient]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4idbe/d_llm_researchers_what_do_you_typically_use_for/</guid>
      <pubDate>Thu, 06 Mar 2025 00:14:08 GMT</pubDate>
    </item>
    <item>
      <title>[r]弧线的34.75％，没有训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4dw38/r_3475_on_arc_without_pretraining/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://iliao2345.github.io/blog_posts/arc_agi_without_pretraining/arc_agi_without_pretraining.html    我们的解决方案，我们将其命名为CompressArc，遵守以下三个限制：  否审计；模型在推理时间内随机初始化和训练。 无数据集；一个模型仅在目标弧形难题上训练并输出一个答案。 在大多数情况下，没有搜索（即梯度下降）。   ，尽管有这些限制，但CompressArc在培训中达到34.75％的培训，在评估集中为34.75％，在每次评估设置中，我们的知识为407分钟。求解ARC-AGI的神经方法，其中训练数据仅限于目标难题。    tl; DR对于每个难题，他们在推理时从头开始训练一个小的神经网络。尽管训练集非常小（三个数据点！）通常仍然可以推广到答案。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j4dw38/r_3475_on_arc_arc_arc_without_pretretrain/”&gt; [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4dw38/r_3475_on_arc_without_pretraining/</guid>
      <pubDate>Wed, 05 Mar 2025 21:02:53 GMT</pubDate>
    </item>
    <item>
      <title>[r]超出相关性：在搜索和建议中对多个目标进行优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j47mhf/r_beyond_relevance_optimizing_for_multiple/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  构建有效的建议和搜索系统意味着不仅可以预测相关性。现代用户期望的个性化体验可以满足广泛的需求和偏好，并且企业需要与其总体目标保持一致的系统。这需要同时针对多个目标进行优化 - 这是一个需要细微的方法的复杂挑战。这篇文章探讨了价值建模和多目标优化的概念（MOO），总结了Jannach＆amp; Abdollahpouri从2022年开始，并解释了这些技术如何使更复杂和有价值的建议和搜索经验的发展。 完整的纸张在这里写下：https://www.shaped.ai/blog/beyond-relevance-optimizing-for-multiple-objectives-in-search-and-recommendations  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/skeltzyboiii     [link]    [commient]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j47mhf/r_beyond_relevance_optimizing_for_multiple/</guid>
      <pubDate>Wed, 05 Mar 2025 16:52:38 GMT</pubDate>
    </item>
    <item>
      <title>安德鲁·巴托（Andrew Barto）和理查德·萨顿（Richard Sutton）是2024 ACM A.M.图灵（Turing）因发展强化学习的概念和算法基础而奖。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j42icj/andrew_barto_and_richard_sutton_are_the/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/mtgtraner     [link]&gt; [link]&gt; [link]&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j42icj/andrew_barto_and_richard_sutton_are_the/</guid>
      <pubDate>Wed, 05 Mar 2025 13:00:25 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1hc0o/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Mar 2025 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些经验丰富的人。   &lt;！ -  sc_on--&gt; 32;&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>