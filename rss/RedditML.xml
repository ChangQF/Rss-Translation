<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 29 Nov 2023 03:14:30 GMT</lastBuildDate>
    <item>
      <title>[D] kaggel是学习机器学习的好平台吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186eek5/d_is_kaggel_a_good_platform_to_learn_machine/</link>
      <description><![CDATA[我是一名网络安全学生，我对机器学习和人工智能感兴趣......所以我想自学，有些人确实推荐了 Kaggel。你觉得怎么样？   由   提交 /u/Dangerous_Wind8441   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186eek5/d_is_kaggel_a_good_platform_to_learn_machine/</guid>
      <pubDate>Wed, 29 Nov 2023 02:31:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 请指导我</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186dytr/d_guide_me_please/</link>
      <description><![CDATA[嘿伙计们。我是计算机科学专业的新生。我刚刚通过在 Coursera 上观看 Andrew ng 的视频开始机器学习（我的意思是我正在第一周）。我知道我在这个领域有点晚了。你们能给我路线图 1. 我应该如何开始？ 2. 我应该给多少时间？ 3.留学生实习真的像人们说的那么难吗？ 3. 如果你必须重新开始学习，你能说出你会避免的遗憾吗？ 4.任何对我有帮助的建议。 提前谢谢您。   由   提交/u/Unfair_Statement3278   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186dytr/d_guide_me_please/</guid>
      <pubDate>Wed, 29 Nov 2023 02:10:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 让 PyTorch 或 TensorFlow 与 AMD RX 580 配合使用的方法？请阅读说明以获取更多信息！在解决之前将非常活跃！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186crjx/p_methods_of_getting_pytorch_or_tensorflow_to/</link>
      <description><![CDATA[到目前为止，我在 TensorFlow-directml python 库方面只取得了微小的成功，但是，它似乎很糟糕，并且可能存在内存问题（小）模型和数据尚未尝试将 5-19GB 分配给 GPU RAM 或 RAM）。我尝试过使用 ROCm，但这导致我不断陷入死胡同，即使使用旧版本和 docker 方法也是如此。  此时，对于如何让这些程序与我的 AMD RX580 交互，我没有其他想法，并且购买新的 GPU 也不是一个选择。   由   提交/u/9876123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186crjx/p_methods_of_getting_pytorch_or_tensorflow_to/</guid>
      <pubDate>Wed, 29 Nov 2023 01:15:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果运行时间或 GPU 内存使用没有显着减少，那么参数高效微调的动机是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186ck5k/d_what_is_the_motivation_for_parameterefficient/</link>
      <description><![CDATA[我一直在尝试诸如提示调整和 LoRA 之类的方法，这些方法的参数效率很高，因为它们只微调很小的一部分（即是所有参数的&lt;1%）。 但是对于这两种方法，您必须在反向传播期间缓存中间梯度，这意味着您在微调期间（或在由于无需存储冻结层的优化器状态，​​因此节省了大部分 GPU 内存）。例如，我已经让 LoRA 将我的自定义模型的 GPU 内存占用量从 8.5GB 减少到了 8.5GB。 8.1GB，非常小。微调时间减少也并不是真正的主要优势，每批微调同一模型减少了 20 毫秒，从 210 毫秒减少到 190 毫秒。 这引出了一个问题 - 实际原因是什么？参数高效微调（例如，带有 1.6k+ 引用的提示调整）的流行，如果它不能真正节省 GPU 内存和训练时间？ 我可以看到两个可能的原因（但我不太相信他们真的解释了围绕参数高效微调的“炒作”）：  下游任务的微调模型检查点显着减少。例如，在提示调整中，我们只需要在硬盘/SSD 上保存经过训练的微小软提示（〜很少兆字节），而不是整个更改后的模型权重（〜很多很多 GB）。  但从实际角度来看，我觉得大多数人都缺乏计算能力（例如 GPU 内存），而不是硬盘空间。换句话说，训练时间和 GPU 内存消耗似乎比节省检查点存储空间更相关。  第二个是域转移的鲁棒性（因为我们是保留大部分原始模型的权重，而不是破坏性地重新学习它们），这一点在提示调整论文中提到过，但在 LoRA 论文中却没有提及太多。  我可以认为这是一个可能的原因，但是在分布外设置中的提示调优论文中的性能增益充其量是微乎其微的，并且 LoRA 没有提到域转换。   （编辑 - 我还想知道是否还缺少其他东西来减少 GPU 内存和运行时间？我听说 QLoRA 增加了 4- LoRA 之上模型的位量化，所以也许这是解决 LoRA 内存效率问题的一种方法。但我不知道是否有什么可以减少内存占用以进行快速调整？）   由   提交/u/patricky168  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186ck5k/d_what_is_the_motivation_for_parameterefficient/</guid>
      <pubDate>Wed, 29 Nov 2023 01:06:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI视频头像开源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186b1n8/d_ai_video_avatar_open_source/</link>
      <description><![CDATA[有谁知道或猜测 heygen.com 或 https://www.synthesia.io ？ 我很好奇是否有像稳定扩散那样的开源替代模型，我见过像 SadTalker 这样的东西，但这只是移动图像，其质量与此不同。 &lt; !-- SC_ON --&gt;  由   提交 /u/TernaryJimbo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186b1n8/d_ai_video_avatar_open_source/</guid>
      <pubDate>Tue, 28 Nov 2023 23:59:56 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]知识蒸馏定义不好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18681i4/discussion_knowledge_distillation_is_badly_defined/</link>
      <description><![CDATA[或者不那么挑衅地说，知识蒸馏是一系列没有明确目标的技术。 在我看来，在文献中通常考虑两种类型的知识蒸馏目标：  让学生模型向教师模型学习，以在教师训练数据集上重现教师的答案（非常重要） 让学生模型向教师模型学习，以重现教师在另一个下游数据集上预测的答案，因此教师和学生都不会“看到” ;之前的那些数据点  但是，我可以想象另一个我认为合理但似乎没有进行太多探索的目标：  拥有学生模型复制教师的输出到处，也就是说，训练学生对任何数据点给出与教师相同的答案。这可以通过将损失函数设置为教师和学生预测之间均方差的 x 积分来实现。我真的不知道如何解决这个特定问题，也许使用重要性采样？  如果有人知道尝试（3）的论文，请发布链接。  如果有人知道尝试（3）的论文，请发布链接。 p&gt; 讨论 知识蒸馏可能具有这三个目标之一（甚至可能是另一个目标）。根据实际用于训练学生的目标，结果应该会有很大差异。 教师在 A 组上进行训练，学生在 A 组上进行训练 在 (1) 的情况下，考虑到学生通常较小或具有更简单的架构，学生不会超越教师也就不足为奇了。如果学生在与老师相同的测试集上进行评估，那么学生就无法在他的领域击败老师。然而，学生可能完全无法匹配教师对分布外 (OOD) 数据的预测，因为它从未接受过 OOD 样本的训练。在这些情况下，我不确定学生是否会超越老师。 老师在 A 组上训练，学生在 B 组上训练 在（2）的情况下，考虑到新的下游分布通常与训练分布有很大不同，学生表现优于老师我不会感到惊讶，因此老师永远没有机会从这个新数据集中学习，但是学生会同时获得先前的信息（通过老师）和新的信息（通过输入，成为梯度，成为参数更新）。我什至想说，在这种情况下，一个体型相似的学生会被老师殴打，这将是令人惊讶的。 这就是为什么我认为如果我们在被打之前承认这种潜在影响会更好。令人惊讶的是，学生模型的表现优于教师。这在法学硕士接受其他法学硕士生成的数据训练的时代似乎尤为重要。在我看来，人们高估了蒸馏的效果，而实际上它可能只是迁移学习。性能的提高将归因于额外数据的使用，或者生成数据的选择机制，而不是蒸馏行为。 教师在 A 组上接受培训，学生在 A 组上接受培训整个输入域 对于（3），我想这实际上是知识蒸馏的最真实形式，因为目标实际上是在整个域上复制（非常复杂的）函数而不是只是一小部分。我想这就是所谓的“模型压缩”。在文献中，但我从未见过这样的问题。这种方法对于分布外的样本应该是稳健的，因为学生应该做出与老师相同的预测。换句话说，如果老师对 OOD 数据稳健，那么学生也应该如此。 我希望学生在任何给定的测试集上都比老师表现得更好一些，因为学生应该“顺利”出”教师做出的任何异常（伪影）预测并创建一种正则化形式。不过我可能是错的。 请随意发表您对此的想法。   由   提交 /u/Cosmolithe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18681i4/discussion_knowledge_distillation_is_badly_defined/</guid>
      <pubDate>Tue, 28 Nov 2023 21:58:04 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]您发现自己每周在工作的哪一部分上浪费时间最多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/</link>
      <description><![CDATA[不询问拖延症、实际工作职责。对我来说，它必须处理电子表格和演示文稿。您的工作流程中存在哪些瓶颈？   由   提交/u/zero-true  /u/zero-true reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/</guid>
      <pubDate>Tue, 28 Nov 2023 18:52:33 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习的 AMD GPU [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1863brm/amd_gpu_for_machine_learning_d/</link>
      <description><![CDATA[我是一名计算机科学学生，最近为我的第一台游戏电脑购买了组件。我发现 6800 的价格不错，相当不错，但我想知道面向机器学习的库（和其他相关的东西）是否会出现问题，因为我发现 NVIDIA GPU 更适合它。如果是这样，我是否仍然可以使用我拥有的 AMD GPU 获得不错的结果，还是应该更改它？   由   提交 /u/the_fabbest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1863brm/amd_gpu_for_machine_learning_d/</guid>
      <pubDate>Tue, 28 Nov 2023 18:44:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] minOFT：一个易于使用的 PyTorch 库，用于将正交微调 (OFT) 应用于 PyTorch 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1862am5/p_minoft_an_easytouse_pytorch_library_for/</link>
      <description><![CDATA[嗨r/MachineLearning， 我想分享我在微调语言模型（正交微调）研究中遇到的一项非常有趣的工作的开源实现。 正交微调 (OFT) 是 LoRA 的一种更强大、稳定且样本效率更高的替代方案，LoRA 最初是为微调扩散模型而开发的。 LoRA 通过添加两个低秩矩阵的乘积来更新预训练权重矩阵，而 OFT 将预训练层权重乘以可学习的正交矩阵以应用约束变换。 OFT 的作者最近表明，这种方法（通过名为 butterfly OFT 的巧妙改进）也适用于视觉转换器和语言模型。 灵感来自minLoRA，我认为最好有一个最小的开源存储库来测试并在微调时比较 OFT 与 LoRA语言模型。它也是由 Andrej Karpathy 在 nanoGPT 之上构建的。该库可通过 pip 安装，并且可以与任何 PyTorch 模型（包括 Hugging Face 模型）通用，就像 minLoRA 一样。 欢迎提供反馈和贡献！您可以在下面尝试一下： https://github.com/alif-munim/minOFT   由   提交/u/0blue2brown   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1862am5/p_minoft_an_easytouse_pytorch_library_for/</guid>
      <pubDate>Tue, 28 Nov 2023 18:01:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 对齐即代码：使 LLM 应用程序与 Tanuki 一起运行。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1861p30/p_alignmentascode_making_llm_applications_behave/</link>
      <description><![CDATA[我是 Tanuki 的贡献者，一个项目，允许您使用 Python 中的测试驱动语法以声明方式定义 LLM 行为。 通过指定 LLM 必须作为测试履行的合同，它有助于减少 MLOps 并使您能够使用标准的开发操作流程将模型的行为与您的要求保持一致。 此外，这些对齐语句有助于自动师生模型蒸馏，以将成本和延迟降低多达 10 倍（请参阅基准）。  非常感谢任何想法或反馈。   由   提交 /u/Noddybear   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1861p30/p_alignmentascode_making_llm_applications_behave/</guid>
      <pubDate>Tue, 28 Nov 2023 17:37:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 具有 2d 旋转嵌入的交叉轴变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18607oa/r_crossaxis_transformer_with_2d_rotary_embeddings/</link>
      <description><![CDATA[ 由   提交/u/lilyerickson  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18607oa/r_crossaxis_transformer_with_2d_rotary_embeddings/</guid>
      <pubDate>Tue, 28 Nov 2023 16:34:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师加薪？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185y5wn/d_machine_learning_engineer_salary_increase/</link>
      <description><![CDATA[大家好，我去年大学毕业，一直在佛罗里达州的一家公司担任机器学习工程师。我一年赚7.6万。该公司提供硕士学位学费报销。通常情况下，获得硕士学位后，您的加薪是多少？ 后续问题：从在线大学获得硕士学位（我仍然会全职工作）的声望是否会低于从在线大学获得硕士学位？亲自？ 请问，如果您愿意的话，是否有人介意直接分享他们大学毕业后的个人薪资数据以及在整个职业生涯中的进展情况？   由   提交/u/Fluid-Pipe-2831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185y5wn/d_machine_learning_engineer_salary_increase/</guid>
      <pubDate>Tue, 28 Nov 2023 15:06:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2023机构排名</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185pdax/d_neurips_2023_institutions_ranking/</link>
      <description><![CDATA[       由   提交/u/Roland31415   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185pdax/d_neurips_2023_institutions_ranking/</guid>
      <pubDate>Tue, 28 Nov 2023 06:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] SuGaR：用于高效 3D 网格重建和高质量网格渲染的表面对齐高斯喷射</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</link>
      <description><![CDATA[计算机视觉研究人员开发了一种方法，只需几分钟即可在单个 GPU 上根据图像创建详细的 3D 模型。他们的方法称为 SuGaR，通过优化数百万个微小粒子来匹配场景图像。关键的创新是让粒子与表面对齐，以便可以轻松地将它们变成网格。 传统的 3D 建模速度慢且资源繁重。激光扫描不方便。摄影测量点云缺乏细节。像 NeRF 这样的神经辐射场可以产生令人惊叹的渲染效果，但即使使用强大的硬件，将它们优化为网格也需要数小时或数天的时间。 VR/AR、游戏、教育等领域对更轻松的 3D 内容创建的需求不断增长。但大多数技术都有很大的速度、质量或成本限制，阻碍了它们主流使用。 这种新的 SuGaR 技术结合了神经场景表示和计算几何方面的最新进展，推动了最先进的技术的发展它首先利用一种称为高斯喷射的方法，该方法基本上使用大量微小粒子来复制场景。放置和配置粒子只需几分钟。问题是它们不会自然地形成连贯的网格。 SuGaR 提供了一种新的初始化和训练方法，可以将粒子与场景表面对齐，同时保持细节完整。这种条件允许将粒子云直接视为点云。 然后，他们应用一种称为泊松表面重建的计算技术，以并行方式直接在结构化粒子之间构建网格。一次处理数百万个粒子可以在低延迟的情况下实现高保真度。 通过将繁重的工作转移到前端点云结构化阶段，SuGaR 使最终网格生成与其他最先进的技术相比极其高效-艺术神经/混合方法。 实验表明，SuGaR 构建详细网格的速度比之前发布的技术快几个数量级，同时实现具有竞争力的视觉质量。该论文分享了一些在 10 分钟内重建复杂场景的有希望的示例。 处理更多样化的场景类型仍然存在问题。但就使用可访问的硬件使高质量 3D 重建更接近交互速度而言，这看起来是引人注目的进步。 TLDR：对齐高斯溅射中的粒子可让您将它们转变为详细的网格。使高质量 3D 更好、更快、更便宜。 完整摘要位于此处。论文网站此处。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</guid>
      <pubDate>Tue, 28 Nov 2023 02:37:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>