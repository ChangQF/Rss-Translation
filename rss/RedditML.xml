<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 10 Jan 2024 12:26:09 GMT</lastBuildDate>
    <item>
      <title>[D] 分位数概率预测的评估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1936hj1/d_evaluation_for_quantile_probabilistic_forecast/</link>
      <description><![CDATA[我正在训练一个执行概率预测的模型，它输出概率分布，而不是每个时间步的单点估计。因此，对于每个时间步长，我都会为我定义的每个分位数获得一个值 (q20,q50,q80..etc) 。  我发现大多数评估方法要么使用每个时间步长的中位数 (q50) 来计算 MAPE 和其他指标，要么使用特定的概率预测指标，例如 LogS、CRPS 和 VarS。 为了将概率预测模型与其他确定性模型进行比较，通过对每个时间步使用与实际目标值差异最小的预测值来获取测试集的 MAPE 是否有效？这意味着对于不同的时间步长，来自不同分位数的值可以用于评估性能。您认为这是一个好方法还是作弊？    由   提交 /u/MrGolran   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1936hj1/d_evaluation_for_quantile_probabilistic_forecast/</guid>
      <pubDate>Wed, 10 Jan 2024 11:48:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于预测的最佳时间序列模型（替代 TimeGPT）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/193672o/d_best_time_series_models_for_forecasting/</link>
      <description><![CDATA[我最近发现了TimeGPT，它真的很棒需求预测。 我不太擅长使用 pytorch，但我无法实现任何接近 TimeGPT 的结果。 我现在正在寻找类似的（甚至更好的） ？）对于预测数据（在我的例子中是需求预测）表现非常好的模型。 感谢您的建议！    ;由   提交/u/Benni03155  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/193672o/d_best_time_series_models_for_forecasting/</guid>
      <pubDate>Wed, 10 Jan 2024 11:30:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于 AI 翻唱歌曲制作者来说，RVC 有什么好的替代品吗</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19366tw/d_any_good_alternatives_to_rvc_for_ai_cover_song/</link>
      <description><![CDATA[就上下文而言，我还没有使用 RVC！问题是来自官方 GitHub 页面的安装文件根据我的防病毒软件 (Bitdiffender) 发现了恶意软件，而且该项目几乎已被放弃！！   由   提交 /u/qualaric   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19366tw/d_any_good_alternatives_to_rvc_for_ai_cover_song/</guid>
      <pubDate>Wed, 10 Jan 2024 11:30:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] RVC 模型训练过度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1935lb8/d_overtrained_rvc_model/</link>
      <description><![CDATA[      我使用了 来自 rvcmodels.com 的指南开始训练我的第一个模型，但我无法确定是否存在过度训练的问题TensorBoard 图。指南中的屏幕截图显示了一个明显的指示，但我没有在我的屏幕上观察到任何指示。我的模型是否过度训练？如果是，训练值是多少？如果有帮助的话，它有 650 个时期并使用了 69 分钟的数据集。  https://preview.redd .it/cwwe1cl2flbc1.png?width=1471&amp;format=png&amp;auto=webp&amp;s=b86ec7a6fd5efe4b42884b90fcdd2ca4243476ef   由   提交 /u/L4HPlz   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1935lb8/d_overtrained_rvc_model/</guid>
      <pubDate>Wed, 10 Jan 2024 10:51:19 GMT</pubDate>
    </item>
    <item>
      <title>《[讨论]》地址规范化实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/193596f/discussion_address_normalization_implementation/</link>
      <description><![CDATA[嗨，正如标题所说，我正在开发一个解决方案，我可以在其中开发内部地理编码 API，这可以帮助我清理错误，非标准化地址。 我有一个错误地址数据集，并使用地图 API 来获取相同地址的正确地址。 我想要开发的是与这些 API 类似的东西，如果有人输入错误的地址（这意味着拼写错误、密码错误、缺少城市、州或街道或任何其他异常），他/她可以检索正确的地址。当然，这需要与正确的地址匹配。 我尝试了一些解决方案，例如：  levenshtein distance - 但每次都搜索数据库会太过分 &lt; li&gt;使用嵌入方法 - 但准确性非常差，因为每个国家的文档向量几乎相似（当地址集中在一起时），使用单词和子单词级向量也发现了类似的结果。  我的好奇心是 Google 实施的方式和解决方案是什么，因此几乎 95% 的时间都是准确的？ 欢迎提出任何建议:)   由   提交/u/Fit-Rub3325  /u/Fit-Rub3325 reddit.com/r/MachineLearning/comments/193596f/discussion_address_normalization_implementation/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/193596f/discussion_address_normalization_implementation/</guid>
      <pubDate>Wed, 10 Jan 2024 10:28:18 GMT</pubDate>
    </item>
    <item>
      <title>[R] AdamL：一种结合损失函数的快速自适应梯度方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1932cv6/r_adaml_a_fast_adaptive_gradient_method/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.15295 摘要：  自适应一阶优化器是深度学习的基本工具，尽管由于梯度缩放不均匀，它们可能会受到泛化能力差的影响。在这项工作中，我们提出了 Adam 优化器的一种新颖变体 AdamL，它考虑了损失函数信息以获得更好的泛化结果。我们提供了充分的条件，与 Polyak-Lojasiewicz 不等式一起确保 AdamL 的线性收敛。作为我们分析的副产品，我们证明了 EAdam 和 AdaBelief 优化器的相似收敛特性。基准函数的实验结果表明，与 Adam、EAdam 和 AdaBelief 相比，AdamL 通常可以实现最快的收敛或最低的目标函数值。当考虑深度学习任务（例如训练卷积神经网络、使用普通卷积神经网络训练生成对抗网络和长短期记忆网络）时，这些优越的性能得到了证实。最后，在普通卷积神经网络的情况下，AdamL 从其他 Adam 变体中脱颖而出，不需要在训练后期手动调整学习率。     由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1932cv6/r_adaml_a_fast_adaptive_gradient_method/</guid>
      <pubDate>Wed, 10 Jan 2024 07:07:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 设备端人工智能是未来吗？ NVIDIA 在 CES 上发起挑战</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1930r1g/d_is_ondevice_ai_the_future_nvidia_throws_down/</link>
      <description><![CDATA[NVIDIA 在 CES 上的重大发布集中于一个关键主题：将强大的 AI 功能直接引入您的 PC 或笔记本电脑。   开发者工具：  AI Workbench（测试版）： 简化跨平台的 AI 开发例如 Hugging Face、GitHub 和 NVIDIA NGC。 RTX Remix：通过 AI 驱动的升级和元素修改为经典游戏注入新的生命。 &lt; strong&gt;NVIDIA Avatar Cloud Engine (ACE)：为游戏和其他应用程序创建人工智能驱动的数字化身。 与 RTX 聊天：构建个人助理和聊天机器人，利用本地法学硕士和用户数据。  这是设备上人工智能主导地位的曙光吗？人们很容易说是。 NVIDIA 强大的硬件和用户友好的工具使本地运行 AI 变得比以往更加容易。然而，挑战仍然存在：  电池寿命：配备这些强大 GPU 的笔记本电脑可能需要附近有一个额外的充电器。 软件成熟度：  设备上的人工智能软件仍在不断发展，开发人员的采用率需要提高。 可访问性：高端硬件是有代价的，可能会限制广泛采用.  你觉得怎么样？设备上的人工智能是未来，还是基于云的人工智能仍然是王者？在下面的评论中分享您的想法！   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1930r1g/d_is_ondevice_ai_the_future_nvidia_throws_down/</guid>
      <pubDate>Wed, 10 Jan 2024 05:31:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] MoE-Mamba：专家混合的高效选择性状态空间模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192z048/r_moemamba_efficient_selective_state_space_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.04081 代码：https ://github.com/llm-random/llm-random 摘要：  状态空间模型（SSM）已成为顺序建模领域的有力竞争者，挑战 Transformers 的主导地位。与此同时，Mixture of Experts (MoE) 显着改进了基于 Transformer 的法学硕士，包括最近最先进的开源模型。我们建议，为了释放 SSM 的扩展潜力，它们应该与 MoE 结合起来。我们在 Mamba 上展示了这一点，这是一个最近基于 SSM 的模型，它实现了类似 Transformer 的卓越性能。我们的模型 MoE-Mamba 的性能优于 Mamba 和 Transformer-MoE。特别是，MoE-Mamba 以减少 2.2 倍的训练步骤达到与 Mamba 相同的性能，同时保留了 Mamba 针对 Transformer 的推理性能增益。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192z048/r_moemamba_efficient_selective_state_space_models/</guid>
      <pubDate>Wed, 10 Jan 2024 04:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 受大脑启发的机器智能：神经生物学上合理的信用分配调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192yvmo/r_braininspired_machine_intelligence_a_survey_of/</link>
      <description><![CDATA[https://arxiv.org/abs/2312.09257   由   提交/u/gw109  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192yvmo/r_braininspired_machine_intelligence_a_survey_of/</guid>
      <pubDate>Wed, 10 Jan 2024 03:53:29 GMT</pubDate>
    </item>
    <item>
      <title>[P] 机器学习不平衡数据手册 + GitHub Repo</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192y4tf/p_machine_learning_for_imbalanced_data_book/</link>
      <description><![CDATA[自我推销提醒：我最近写了一本书，“针对不平衡数据的机器学习”。 这本书主要是专注于分类问题，其中一个或多个类别的数据太少或太多会导致不平衡。数据不平衡（不平衡）或类别不平衡一直是一个有争议的话题，对采样技术的批评导致模型校准错误问题和许多其他问题。然而，本书旨在公正地对待硬币的两面，探讨各种技术的优缺点。 📘 这是亚马逊链接：https://www.amazon.com/Machine-Learning-Imbalanced-Data-imbalanced/dp/1801070830/&lt; /p&gt; 本书的前半部分涵盖了结构化数据和经典模型的采样技术、加权技术、阈值调整技术。本书的后半部分介绍了使用 PyTorch 的非结构化数据和深度学习模型。最后，它以不平衡数据背景下的模型校准作为结论。 随附的 GitHub 存储库提供了 Jupyter 笔记本（在 Google Colab 上一键运行）以及补充本书内容的其他资源：https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data。 我花了一些时间来收集有关大公司是否以及如何处理数据不平衡以及他们在生产中使用哪些策略的信息，我记录了这些信息这里。 我花了一年半的时间写这本书。您的反馈和建议将受到高度赞赏，并且对于未来的版本非常宝贵（如果我碰巧写它😊） （官方书籍网站：https://imbalanceddata.com/)   由   提交/u/ic10503  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192y4tf/p_machine_learning_for_imbalanced_data_book/</guid>
      <pubDate>Wed, 10 Jan 2024 03:14:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么IAF-VAE模型被称为“逆”自回归流（IAF）？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192tj1t/why_is_the_iafvae_model_called_inverse/</link>
      <description><![CDATA[什么是“逆”？关于它？我理解论文中的第 3 节（逆自回归变换），但我无法理解第 4 节（逆自回归流 (IAF)）是如何从那里得出的。我们是否像第 3 节中那样选择潜在变量的特定顺序？  如果有人能给我指点一篇博客文章，引导您了解 IAF-VAE 模型的详细信息，我将不胜感激。 这里是论文：https://arxiv.org/pdf/1606.04934.pdf   &amp; #32；由   提交 /u/ComedyIsOver   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192tj1t/why_is_the_iafvae_model_called_inverse/</guid>
      <pubDate>Tue, 09 Jan 2024 23:43:22 GMT</pubDate>
    </item>
    <item>
      <title>训练损失按预期减少，然后在第一个时期后变得疯狂？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192ra9a/training_loss_decreases_expectedly_then_goes_wild/</link>
      <description><![CDATA[      在第一个时期，训练损失以令人愉快的速度下降，但从第二个时期开始时代开始疯狂地摇摆。我尝试过 1e-5、-6，似乎遵循相同的模式。验证也趋于平稳。我以前从未遇到过这个问题，这是局部最小问题吗？这次运行是 6 个 epoch，但我目前将其调至 20 个 epoch 来观察其行为，因为它在第 25k 步看起来很乐观。 该模型是用于令牌分类的 google/electra-large-discriminator ，优化器是adamw。没有使用其他修改，例如层冻结、权重衰减、分层权重衰减。 https://preview.redd.it/f6ydsuzcnhbc1.png?width=1210&amp;format=png&amp;auto=webp&amp;s=075f8da8ad5dab863cfa189bfc235b32658 a459d &lt; strong&gt;[更新] 我使用 Electra 进行了超过 20 个 epoch 的更多测试，使用的数据集要小得多。以下是训练/有效损失。使用 LR=5e-6（深蓝色线），electra 最终达到了近似对角线的混淆矩阵。 在 700 个训练步骤处似乎有一个分叉点，可能大约 15-20 个 epoch，橙色会话 (1e-5) 是第一次正确预测的运行一些不平凡的事情（尽管它仍然很糟糕）。 验证损失：较大步长的分叉点显示在 700 步。 ​   由   提交/u/pikachuunibyo   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192ra9a/training_loss_decreases_expectedly_then_goes_wild/</guid>
      <pubDate>Tue, 09 Jan 2024 22:12:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 测试 MAMBA 架构 KV 检索和 RAG 功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192k8b4/r_testing_mamba_architecture_kvretrieval_and_rag/</link>
      <description><![CDATA[我即将以与论文类似的方式测试 MAMBA 的功能 迷失在中间：语言模型如何使用长上下文，但由于这是一项大量的工作，我想问是否有人已经这样做了。    由   提交/u/25cmderespeito   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192k8b4/r_testing_mamba_architecture_kvretrieval_and_rag/</guid>
      <pubDate>Tue, 09 Jan 2024 17:30:37 GMT</pubDate>
    </item>
    <item>
      <title>目前该领域的弱点是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192aj3h/what_are_weaknesses_of_the_field_currently_d/</link>
      <description><![CDATA[大家好， 有人了解该领域技术和业务相关的差距和弱点吗？如果可能或者更高效的话，哪些事情会让项目和模型变得最优？例如（不一定是大规模案例）缺乏高质量的数据集。  非常感谢！   由   提交 /u/卷积  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192aj3h/what_are_weaknesses_of_the_field_currently_d/</guid>
      <pubDate>Tue, 09 Jan 2024 09:06:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>