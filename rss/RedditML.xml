<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sat, 08 Mar 2025 03:16:24 GMT</lastBuildDate>
    <item>
      <title>热：突出显示的思想链，用于参考输入的支持事实</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j676bx/hot_highlighted_chain_of_thought_for_referencing/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/u/lagitimate-case-3530       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j676bx/hot_highlighted_chain_of_thought_for_referencing/</guid>
      <pubDate>Sat, 08 Mar 2025 02:34:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] Arxiv认可请求AV项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j65qvv/p_arxiv_endorsement_request_for_av_project/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们的研究论文，“知识图作为自动驾驶汽车中材料意识到障碍物处理的世界模型，“ ”已被接受ICLR世界模型工作室2025年。但是，由于会议是非Archival，因此我们计划在ARXIV上发布该会议。我们需要有人认可我们的论文。几位审稿人已经验证了该论文，因此，如果有人可以快速提供认可，那将非常有帮助。 将文章提交给 cs.ai&gt; cs.ai  Arxiv的部分。要告诉我们，您会（或不会）认可此人，请访问以下URL： https://arxiv.org/auth/auth/auth/endorse?x=4Kdyhi  ape and clibe vist y hiv a n y hi. href =“ http://arxiv.org/auth/endorse.php”&gt; http://arxiv.org/auth/endorse.php 并输入以下六二吉特alphanumeric string：认可代码：认可代码：4Kdyhi      &lt;！提交由＆＃32; /u/syaang     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j65qvv/p_arxiv_endorsement_request_for_av_project/</guid>
      <pubDate>Sat, 08 Mar 2025 01:19:38 GMT</pubDate>
    </item>
    <item>
      <title>[d]运行Pytorch CUDA仅在CPU内加速了容器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j640gm/d_running_pytorch_cuda_accelerated_inside_cpu/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是一项有趣的新技术，允许数据科学家在CPU-仅CPU-仅容器内运行带有GPU加速的Pytorch项目 -   [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j640gm/d_running_pytorch_cuda_accelerated_inside_cpu/</guid>
      <pubDate>Fri, 07 Mar 2025 23:53:49 GMT</pubDate>
    </item>
    <item>
      <title>[d]与ML库一起使用Pyspark的最佳实践是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5y3d2/d_what_are_the_best_practices_for_using_pyspark/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我将Pyspark用于项目的数据处理部分，因为我的数据集很大，并且使用Pandas DataFrame会非常慢。 ，但是一旦我的数据准备就绪，我想使用Sklearn的一些方法，例如分层的启动，例如在Pyspark.ml上都无法使用。我考虑过将Pyspark数据框架转换为熊猫的数据框架，然后使用Sklearn和其他ML库从那里转换为从那里转换为非常昂贵的部分，并且导致内存错误  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/amirdol7     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5y3d2/d_what_are_the_best_practices_for_using_pyspark/</guid>
      <pubDate>Fri, 07 Mar 2025 19:40:48 GMT</pubDate>
    </item>
    <item>
      <title>[d]云计算与个人工作站 - 为什么云赢得沉重的工作量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5ph94/d_cloud_computing_vs_personal_workstationwhy_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在运行大量机器学习工作负载，虽然构建强大的个人工作站的想法令人诱人，但我一直回到云中。 使用云计算，我可以立即访问高强度的硬件，而不必担心，我可以立即访问艰难的成本，而不必担心。扩展就像旋转新实例一样容易，我只为自己使用的费用付费。同时，个人工作站是一项巨大的投资，需要进行持续的维护，并且在我需要更多的电力时无法轻松扩展。 对我来说，云的灵活性和便利性大于成本。你怎么了？您是否喜欢云计算，还是仍然对自己的硬件发誓？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/parasssssssssssssssssssss     [link]   [commiss]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5ph94/d_cloud_computing_vs_personal_workstationwhy_the/</guid>
      <pubDate>Fri, 07 Mar 2025 14:37:17 GMT</pubDate>
    </item>
    <item>
      <title>[d]寻求新的方法来分类和诊断小儿胸部X射线中多种疾病</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5mwb8/d_seeking_novel_approaches_for_classifying/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我有一个建议分类和诊断小儿胸部X射线中多种疾病的建议。我计划在此项目中使用Extricnet，但是我需要一种新颖的方法，例如混合方法或任何新方法。您可以建议什么吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/_ajing     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5mwb8/d_seeking_novel_approaches_for_classifying/</guid>
      <pubDate>Fri, 07 Mar 2025 12:55:15 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何将本地/本地培训和规模缩小到云？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5lkw9/d_how_do_you_orchestrate_onpremlocal_training_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在为一家专门从事kubernetes的公司工作，我试图更好地了解ML研究人员和工程师如何使用本地/本地GPU和公共云资源的混合。   似乎是一种常见的模式来进行“在桌子下进行较大的gpus”，以进行较大的培训，然后训练，然后进行范围或培训，然后进行范围或范围，以弥补云或云量。但是，在实践中设置的设置有多普遍？ 如果您使用这样的混合方法： 您是否有自动化的工作流程以在本地和云环境之间移动？ 哪些工具或平台对您有效吗？在这些情况下，像Zenml这样的MLOPS工具可以帮助？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ml_yegor     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j5lkw9/d_how_do_do_do_you_orchestrate_onpremlocal_training_and/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5lkw9/d_how_do_you_orchestrate_onpremlocal_training_and/</guid>
      <pubDate>Fri, 07 Mar 2025 11:41:47 GMT</pubDate>
    </item>
    <item>
      <title>[r]杂交：结合术前和后场，以进行更稳定和有效的变压器训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5l9mk/r_hybridnorm_combining_prenorm_and_postnorm_for/</link>
      <description><![CDATA[I&#39;ve been experimenting with various normalization techniques in transformers lately, and this new HybridNorm approach seems like a particularly elegant solution to the speed vs. stability tradeoff. The core idea is surprisingly simple but effective: use Layer Normalization after attention sublayers (where stability matters most) and use RMS Layer Normalization everywhere else (where we can benefit from its computational efficiency). Key technical points: - The post-attention sublayer is much more sensitive to normalization type than other positions - Using RMSNorm in non-critical positions reduces computation without compromising stability - Implementation requires minimal code changes to existing transformer architectures - HybridNorm delivers 13-17% training speedup compared to standard LayerNorm - Performance跨基准任务（胶水，小队，机器翻译）维护 - 在不同的模型量表（0.1b至3B参数）上始终如一地工作 - 与仅编码器，仅解码器和编码器decoder-decoder Architectures  兼容。 13-17％的加速可能听起来并不革命性，而是应用于大规模训练，这是零质量折衷的大量计算节省。本文还暗示了一个更广泛的机会 - 仔细分析哪些组件需要完全稳定，而我们可以优化速度。   特别有用的是该技术如何与现有架构无缝集成。您无需重新设计模型 - 只需在特定位置交换标准化层即可。从本质上免费获得提高效率的一个难得的案例。“  发现变压器中不同位置具有不同稳定性要求的发现为为什么在数学上发生这种情况的情况都打开了有趣的问题。我很想看到后续工作更深入地探索这一现象。  tldr：杂交从策略上结合了变压器模型中的分层和rmsnorm，将注意力越来越稳定的分层放置在注意力下的分子和更快的rmsnorm之后。这种简单的更改可提供13-17％的速度，而不会影响模型质量。 全部总结。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5l9mk/r_hybridnorm_combining_prenorm_and_postnorm_for/</guid>
      <pubDate>Fri, 07 Mar 2025 11:21:14 GMT</pubDate>
    </item>
    <item>
      <title>[D]学习如何与LLM构建的最佳资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5jlae/d_best_resources_to_learn_how_to_build_with_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最佳资源或课程是什么，特别是针对在数据科学领域中拥有丰富知识的人，精通一般的ML/DL原则，但是现在希望进入LLMS世界？    &lt;！ -  sc_on--&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j5jlae/d_best_resources_to_to_lealed_how_to_build_with_with_with_llms/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j5jlae/d_best_resources_to_to_to_lealed_how_to_build_build_with_with_lls/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5jlae/d_best_resources_to_learn_how_to_build_with_llms/</guid>
      <pubDate>Fri, 07 Mar 2025 09:25:00 GMT</pubDate>
    </item>
    <item>
      <title>[d]使用BERT作为T5中的编码器的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5gtie/d_impact_of_using_bert_as_the_encoder_in_t5/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果已经对Bert编码的编码器组成的编码器替换为bert编码器，考虑到BERT已经在较大的语料库上进行了训练？  Bertoder，Bertoder，Bertoder，在较大的Corpus上进行了较大的Corpus，可以为T5模型带来丰富的上下文模型。这可能会提高某些任务的性能，尤其是那些涉及理解和生成相干文本的任务。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ashydunes     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5gtie/d_impact_of_using_bert_as_the_encoder_in_t5/</guid>
      <pubDate>Fri, 07 Mar 2025 06:03:40 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] NLP应用程序中的质量保证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5ac22/discussion_quality_assurance_in_nlp_apps/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 我正在考虑在基于ML/NLP的应用程序中对主人进行质量保证的研究。除了功能性测试外，我想知道对非功能性测试的更大话题。在传统软件开发人员中，我们有诸如可访问性，可用性，安全性和更多类型的测试之类的东西。但是对于ML/NLP应用程序，我们应该看什么？ 超越准确性和表现，道德考虑，可用性和安全性，但是我觉得还有更多可以探索的东西。 很想听听您的想法和经验！  cheers！提交由＆＃32; /u/u/abk9035     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5ac22/discussion_quality_assurance_in_nlp_apps/</guid>
      <pubDate>Fri, 07 Mar 2025 00:11:47 GMT</pubDate>
    </item>
    <item>
      <title>[r] [p] SLM建议求解与声音单词错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j57nyy/r_p_slm_recommendation_to_solve_soundalike_word/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我需要一个可以解决声音单词错误的小语言模型，例如：\＆nbsp; \ \＆nbsp;＆nbsp;在早期，国王将赌注付诸实践，以适用于小小的实例\ i，对于小型型号的rob（e.G. x86（例如原子）。我尝试了2到4 GB的重量范围中的许多，但是到目前为止，除非我开始提供这些提示（例如挑选一个错误的单词并要求它考虑其他可能性），我还没有找到可以完成这项工作的一种。任何建议/建议欢迎  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jbrower888    href =“ https://www.reddit.com/r/machinelearning/comments/1j57nyy/r_p_p_slm_slm_recommendation_to_solve_solve_soundalike_word/&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j57nyy/r_p_slm_recommendation_to_solve_soundalike_word/</guid>
      <pubDate>Thu, 06 Mar 2025 22:11:35 GMT</pubDate>
    </item>
    <item>
      <title>[r]启用语言模型自我完善的认知行为：分析验证，回溯，子目标和后退链接</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4szaa/r_cognitive_behaviors_that_enable_language_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在探索LLM可以提高自己的推理能力，而Google研究的这篇新论文确定了四种特定的认知行为，这些行为能够在推理模型中进行自我改进，而无需进行其他培训，而无需其他培训。 Double-checking: Models review their work, looking for calculation errors or logical inconsistencies Seeking background knowledge: Models identify information gaps and retrieve missing knowledge Step-back reasoning: Models approach problems from a higher level of abstraction before diving into details Heuristic放松：模型放弃了无效的初始方法，并尝试替代解决方案  这些结果在多个推理领域跨多个推理领域令人信服：  在数学推理（GSM8K）上测试（GSM8K），常识性推理（策略QA）和符号推理（最后字母串联）                  将多种行为结合起来产生了最强的改进 双重检查对数学推理的特殊价值   在GPT-4和Mistral    （我认为这项研究）的好处中出现了好处，我认为这项研究是有价值的。首先，它提供了具体的，可实施的技术，可以提高现有模型中的推理能力，而无需进行体系结构的变化。其次，它通过在LLM中形式化类似人类的元认知策略来弥合认知科学和AI。最后，它提出了一种模块化方法的改进方法 - 而不是将推理视为一种整体能力，我们可以将其分解为可以单独增强的特定认知行为。  tldr：研究人员确定了四个认知行为（确定了四个认知行为（识别双重训练，寻求知识，较高的推理），并没有启用较高的推理，以提高他们的启用模型，以提高他们的启用自身的启用）。这些类似人类的策略可大大提高数学，常识性和符号推理任务的性能。  纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j4szaa/r_cognitive_behaviors_that_enable_enable_language_model/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4szaa/r_cognitive_behaviors_that_enable_language_model/</guid>
      <pubDate>Thu, 06 Mar 2025 11:00:08 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1hc0o/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Mar 2025 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些经验丰富的人。   &lt;！ -  sc_on--&gt; 32;&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>