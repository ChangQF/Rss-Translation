<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 02 Jul 2024 09:15:23 GMT</lastBuildDate>
    <item>
      <title>[P] 微调 NVIDIA LITA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dt670a/p_finetuning_nvidia_lita/</link>
      <description><![CDATA[我正在尝试微调 LITA（语言指导时间定位助手），这是 NVIDIA 的一款 VLM，用于特定用例：检测零售盗窃。例如，假设我在一家手机零售店内有一个视频剪辑，显示四位购物者正在查看并从展示墙和货架上拿起手机和其他产品。四位购物者中有三位没有表现出任何可疑行为，但一位购物者明显拿起手机，将其放在口袋里，然后离开商店而没有付款。 为了提供微调中使用的答案响应，是否可以仅描述盗窃发生的时间和地点的场景细节，还是应该提供包含场景中所有内容的详细描述？例如，以下内容是否足够？我还提供了带注释的正常场景视频剪辑，这些场景没有发生盗窃。 &quot;11b_chunk_0000.mp4&quot;: { &quot;vid&quot;: &quot;11b_chunk_0000.mp4&quot;, &quot;question&quot;: &quot;QuestionPrompt&quot;, &quot;answer&quot;: &quot;在&lt;8&gt; 和&lt;17&gt; 之间，一名身穿黑色 T 恤和蓝色牛仔裤、背着深色背包的购物者在产品展示架上拿起一部手机。 购物者随后将手机放在裤子左后口袋中，走开。 这显然是盗窃行为。&quot;, &quot;duration&quot;: 29 },     提交人    /u/Armed_Trash_Panda   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dt670a/p_finetuning_nvidia_lita/</guid>
      <pubDate>Mon, 01 Jul 2024 22:36:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于无人机基本飞行稳定算法的入门建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dt20wu/d_recommendations_for_getting_started_with_a/</link>
      <description><![CDATA[理想情况下，我想购买一架带有可编程控件的无人机，并在其上安装一些传感器和一个小型处理器。我对硬件项目的经验有限，我应该从哪里开始，买什么？    提交人    /u/inner_resilience   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dt20wu/d_recommendations_for_getting_started_with_a/</guid>
      <pubDate>Mon, 01 Jul 2024 19:42:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] VAE | 确定先验和近似后验分布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsz7ke/d_vae_determining_prior_and_approximated/</link>
      <description><![CDATA[大家好， 我从这几天开始研究变分自动编码器，对它们有了简单的了解。 但是，我对后验分布的近似值仍然有点不确定。 首先，我将解释我目前对这个主题的理解和知识，为我提供一些背景信息，如果我有部分错误，也请您纠正我。 为了调整变分自动编码器，ELBO 被用作损失函数，它带有一个用于评估重建损失的项和一个用于使用 KL 散度计算先验和近似后验分布之间相似性的项。 ELBO 可以从贝叶斯定理推导出来，该定理的根本目的是计算潜在空间上的真实后验分布。然而，由于证据（贝叶斯方程中的分母）的难处理性，这不能用于实际计算该分布。 为了解决这个问题，使用变分推理，其目的只是用可追踪的后验分布（称为近似后验分布）替代真实的后验分布。 通过进行一些转换，真实和近似后验分布之间的 KL 散度导致 ELBO。 通常，由于高斯分布在数学上简单，因此选择先验分布。通过 ELBO 中的 KL 散度正则化，我的潜在空间上的分布被迫表现得像高斯分布。通过这种方式，可以使用诸如重新参数化技巧之类的东西来使随机采样过程在反向传播期间可追溯。 我的观点正确吗？ 我现在想知道的是以下内容： 先验分布是高斯分布，在变分推理过程的某个时刻，我为我的近似后验分布选择了某种分布。 近似后验分布是否由先验分布通过使用 KL 散度确定？我就是无法理解。如果在将近似后验分布应用于 ELBO 之前选择了它，为什么我要开始强制它为高斯分布？ 提前致谢    提交人    /u/hertz2105   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsz7ke/d_vae_determining_prior_and_approximated/</guid>
      <pubDate>Mon, 01 Jul 2024 17:47:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] VQ-VAE - 为什么不在码本上使用注意力？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsxcfs/d_vqvae_why_not_to_use_attention_on_a_codebook/</link>
      <description><![CDATA[注意力机制是一种可微分的软查找。为什么不使用 K 和 V 作为码本，使用 Q 作为潜在变量，以软方式搜索码本？为什么我们要使用不可微分的 argmin？使用这种模型训练后再进行生成不是更简单吗？例如，使用 Transformer - 我们只需对 LLM 输出的词汇概率进行 MatMul 运算，即可获得表示 - 而不是先从 LLM 词汇概率中采样，然后从码本中挑选一个向量？    提交人    /u/kiockete   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsxcfs/d_vqvae_why_not_to_use_attention_on_a_codebook/</guid>
      <pubDate>Mon, 01 Jul 2024 16:30:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对生物医学/STEM 的微调检索模型 (DeBERTa/RoBERTa/e5)：寻求有关无监督微调、查询/指示格式和损失函数的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsxcb6/d_finetuning_retrieval_models_debertarobertae5/</link>
      <description><![CDATA[大家好！ TL;DR：使用 DeBERTa 微调医学/STEM 知识的检索模型。寻求有关 DeBERTa 解码器配置、查询前缀策略和监督微调损失函数的建议。还寻找一般技巧和要避免的常见陷阱……以及其他一系列无限的问题。 我正在微调检索模型（目前使用句子转换器库以简化操作）。我正在考虑将 DeBERTa v3 large 和 DeBERTa v2 xxlarge（1.5B 参数）作为基础模型。不幸的是，没有 v3 xlarge，这真的很可惜，因为 v3 使用 ELECTRA 风格的预训练，它比 BERT/RoBERTa/DeBERTa v1-2 的经典 MLM 更有效、更高效。 我的管道使用各种数据集，从面向检索的数据集（如 MSMARCO 和 GooQA）到用于不对称检索、句子相似性、NLI 和句子压缩的较小数据集……然后我在使用 GPT-4、Claude sonnet 和 Command R Plus 生成的较小数据集上进行微调（我使用了多个模型来避免风格偏见并增加可变性）。 用例可以在医学/生物医学领域定义为“知识检索”，但可以推广到 STEM 领域。通过在通常的管道之前添加无监督的微调步骤，我获得了很好的结果，其中 TSDAE 方法特别有效。但是，transformers 库中没有 DeBERTa 模型用作解码器时的配置，所以我最终使用了 RoBERTa large 和 e5-unsupervised large。 我正在向有类似项目经验的人寻求建议。具体来说：  有人知道如何获取 DeBERTa 作为解码器的配置吗？ 关于查询前缀或说明，是否有关于最佳方法的共识？我应该简单地在查询文本前面添加，在查询和输入文本之间使用“[SEP]”标记，还是使用新的自定义标记？ 对于监督微调损失，有什么推荐的选择吗？我使用了多重负排名损失，然后切换到 GISTEmbed，它提供了更好的结果（使用 Snowflake Arctic Large 作为 GISTEmbed 损失中的“指导”来消除批量负挖掘中出现的假阴性）。由于硬件限制，我一直在使用这些损失的缓存版本来有效地将批量大小增加到我的 GPU VRAM 限制之外。正如预期的那样，考虑到批量负挖掘，GISTEmbed 和 MNRL 的性能都与批量大小成正比。 哪些池化策略（例如，CLS 令牌、均值池化、最大池化、注意力池化）在检索任务中生成文档/查询嵌入时显示出最佳结果？ 哪些学习率计划对于微调像 DeBERTa 这样的大型模型以执行检索任务效果很好？对于衰减率或预热期，是否有任何特定领域的考虑因素？ 在医疗/STEM 领域，持续预训练的最有效策略是什么？是否存在特别有效的特定技术或数据集？ 关于无监督学习方法，我已经成功使用了 TSDAE。还有其他无监督方法在专门领域的检索任务中显示出前景吗？  抱歉，文字太多了，而且还有这么多问题…… 如果能提供任何避免常见错误的提示或建议，我们将不胜感激！ 提前感谢整个社区。    提交人    /u/Distinct-Target7503   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsxcb6/d_finetuning_retrieval_models_debertarobertae5/</guid>
      <pubDate>Mon, 01 Jul 2024 16:30:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研究监督令人绝望</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dswdrr/d_research_supervision_despair/</link>
      <description><![CDATA[嗨，我想听听另一边的观点。背景是，我是一名本科生，过去几个月一直在尝试进入理论机器学习实验室。我可能已经联系了大约 40 位不同的教授，既有学校的，也有学校外的。在每种情况下，我都阅读了他们的 5-7 篇论文和定制电子邮件；而且，在每种情况下，我要么没有收到回复，要么收到一封自动电子邮件，说他们没有空位。 教授/研究科学家/实验室人员，您认为这是徒劳的吗？我想我已经到了辞职去做没有主管或顾问的工作的地步。研究领域已经饱和了吗？我听说教授们总是喜欢免费劳动力，但我还没有看到这种情况。 如果这篇文章/咆哮让你觉得我对任何人生气，我想说我没有。我知道这个领域很忙，我只是在寻求建议。 为了获得更多背景信息，我曾尝试与一位教授一起进行应用 ML 研究，甚至获得了最佳海报奖。然而，我真正的热情在于理论方面。任何建议都将不胜感激。    提交人    /u/Open-Ad2530   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dswdrr/d_research_supervision_despair/</guid>
      <pubDate>Mon, 01 Jul 2024 15:51:59 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ECCV 决策出炉！（+边界论文支持线程）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsutwd/discussion_eccv_decisions_out_borderline_paper/</link>
      <description><![CDATA[https://eccv2024.ecva.net/Conferences/2024/AcceptedPapers 我们通过了 WA/WA/WR 的初步审查，当我看到我的 ID 被列出时，我差点吐了。这几个月真是令人紧张！ 你们都怎么样了？ 向所有正在查看结果的边缘论文拥有者致以深切的爱！对于我们这些边缘人士来说，这是一个完全随机的过程！    提交人    /u/impatiens-capensis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsutwd/discussion_eccv_decisions_out_borderline_paper/</guid>
      <pubDate>Mon, 01 Jul 2024 14:48:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要对损失函数提出建议，以对“传递”余弦相似度进行建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsu3f2/d_need_suggestions_for_loss_function_to_model/</link>
      <description><![CDATA[我知道余弦相似度不是传递性的，但这就是我想要建模的，给定 cs(A,B) 和 B 和 C，相似度指数介于 [0,1] 之间，则 cs(A,C)=s*cs(A,B)，大约。我正在开发一个推荐系统，并尝试使用 word2vec/prod2vec 来建模共现，我还有一个基于元数据的相似度指数，也想用它来创建一个高覆盖率的推荐系统。我这样做是因为我的共现/共同购买数据非常稀疏，而相似度数据很密集，我想在稀疏条件下对经常购买的推荐进行建模。    提交人    /u/Abs0lute_Jeer0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsu3f2/d_need_suggestions_for_loss_function_to_model/</guid>
      <pubDate>Mon, 01 Jul 2024 14:17:53 GMT</pubDate>
    </item>
    <item>
      <title>[P] 正在开发一种工具来增加数据集的大小，并创建叠加的数据集！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dst77q/p_working_on_a_tool_to_increase_dataset_size_and/</link>
      <description><![CDATA[      它是一个桌面应用程序，它有助于从 png 图像创建数据集。您只需选择要在其上运行模型的任何对象的几个 png 图像即可。然后选择一些随机图像（在我的示例中是随机山景图像）然后选择您想要的图像数量。然后它将创建一个包含 2 个子文件夹、蒙版和图像的 .zip。您可以在此处查看蒙版和图像的示例。它目前处于测试阶段，欢迎所有反馈！ https://preview.redd.it/l8yczzr9uw9d1.png?width=1016&amp;format=png&amp;auto=webp&amp;s=23474b4bfb0e8d5f5332833e019de3977d2b8542 https://preview.redd.it/3r34a3u7uw9d1.png?width=2405&amp;format=png&amp;auto=webp&amp;s=f3a417f0cfa665d98ab532c9d74d3042d34ba4ee    提交人    /u/MAKEMONEYSMOKEASS   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dst77q/p_working_on_a_tool_to_increase_dataset_size_and/</guid>
      <pubDate>Mon, 01 Jul 2024 13:38:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] 正在寻找 LLM/NLP 领域的开源/研究/志愿者项目？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsrwy4/p_looking_for_opensourceresearchvolunteer/</link>
      <description><![CDATA[嗨！我是一名数据科学家，从事该行业已有近一年的时间，但感觉与该领域非常脱节。 虽然薪水不错，但我并不太喜欢这份工作！在我的组织中，我们使用传统的 ML 算法，这很好（如果刀可以的话，就不能用剑来切苹果）。问题是，我不喜欢这个组织。我对他们的事业没有热情。这感觉像是一份我必须做的工作（事实也确实如此），但我怀念对项目工作和关心自己正在做的事情感到兴奋。 我喜欢在 NLP 领域工作，在该领域做过多个项目和实习。我特别喜欢研究代码混合语言或代表性不足的语言。如果你们知道任何与它们相关的此类项目，请告诉我。  我知道有 Kaggle，但我对竞争有点害怕，所以还没有勇气开始。  谢谢！    提交人    /u/MiserableGrapefruit7   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsrwy4/p_looking_for_opensourceresearchvolunteer/</guid>
      <pubDate>Mon, 01 Jul 2024 12:36:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 现在（2024年）最先进的 TTS 模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsp3vf/d_what_is_the_most_advanced_tts_model_now_2024/</link>
      <description><![CDATA[如果我想训练一个用于阅读新闻的 TTS 模型，我应该怎么做？我需要什么样的训练数据？ 谢谢。    提交人    /u/secsilm   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsp3vf/d_what_is_the_most_advanced_tts_model_now_2024/</guid>
      <pubDate>Mon, 01 Jul 2024 09:51:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型语言模型比大家想象的要线性得多</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dso3pg/r_large_language_models_are_much_more_linear_than/</link>
      <description><![CDATA[      作者揭示了 Transformer 解码器独有的一种新型线性特性，包括 GPT、LLaMA、OPT、BLOOM 等模型。他们分析了连续层之间的嵌入转换，发现了近乎完美的线性关系（Procrustes 相似度得分为 0.99）。然而，由于 Transformer 层的输出范数一直较低，因此在移除残差分量时线性度会降低。 https://preview.redd.it/t5kq9g598v9d1.png?width=2420&amp;format=png&amp;auto=webp&amp;s=20da53fce41f75242244d78eea590c6fa52b88c9 实验表明，移除或线性近似 Transformer 中一些最线性的块不会显著影响损失或模型性能。此外，在较小模型的预训练实验中，作者引入了基于余弦相似度的正则化，旨在降低层线性。这种正则化提高了 Tiny Stories 和 SuperGLUE 等基准测试的性能指标，并成功降低了模型的线性度。这项研究挑战了对 transformer 架构的现有理解，表明它们的操作可能比以前假设的更线性，并且可以在不损失质量的情况下消除 10-15% 的层。 该研究已被 ACL 2024 会议接受，更多详细信息请参阅预印本。    提交人    /u/AIRI_Institute   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dso3pg/r_large_language_models_are_much_more_linear_than/</guid>
      <pubDate>Mon, 01 Jul 2024 08:40:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 花费数十亿美元训练生成模型的人工智能实验室的最终目标是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsnk1k/d_whats_the_endgame_for_ai_labs_that_are_spending/</link>
      <description><![CDATA[鉴于目前 LLM 和生成模型的热潮，前沿 AI 实验室正在投入数十亿美元的风险投资资金来构建 GPU 集群、训练模型、免费提供模型访问权限以及获取授权数据。但是，当这种热情消退、市场重新调整时，他们的游戏计划是什么？ 有一些挑战使得使用当前的 LLM 创建盈利的商业模式变得困难：  所有前沿模型的近乎相同的性能将使 LLM 市场商品化，并迫使供应商在价格上展开竞争，从而大幅削减利润率。与此同时，新模型的培训仍然非常昂贵。 高质量的训练数据变得越来越昂贵。您需要主题专家来手动创建数据或审查合成数据。这反过来又使得模型改进的每次迭代都更加昂贵。 开源和开放权重模型的进步可能会占据私有模型企业市场的很大一部分。 设备上模型的进步和与操作系统的集成可能会减少未来对基于云的模型的需求。 模型的快速更新周期为人工智能公司提供了非常短的回报窗口来收回训练新模型的巨额成本。  当资金枯竭时，Anthropic、Cohere、Mistral、Stability 等实验室的最终结果是什么？他们会与大型科技公司（例如 OpenAI 和微软）更加紧密地合作以扩大分销吗？他们会找到其他商业模式吗？他们会消亡还是会被收购（例如，Inflection AI）？ 有什么想法吗？    提交人    /u/bendee983   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsnk1k/d_whats_the_endgame_for_ai_labs_that_are_spending/</guid>
      <pubDate>Mon, 01 Jul 2024 08:02:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] MESH2IR：用于复杂 3D 场景的神经声学脉冲响应发生器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsl349/r_mesh2ir_neural_acoustic_impulse_response/</link>
      <description><![CDATA[        由    /u/Snoo63916   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsl349/r_mesh2ir_neural_acoustic_impulse_response/</guid>
      <pubDate>Mon, 01 Jul 2024 05:17:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>