<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 19 Jun 2024 03:17:04 GMT</lastBuildDate>
    <item>
      <title>[P] [D] 你好，我是一名高级机器学习工程师，正在寻找伙伴一起创造很酷的东西！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dj8pg6/p_d_hi_im_a_senior_machine_learning_engineer/</link>
      <description><![CDATA[嗨，我是一名高级机器学习工程师，正在寻找伙伴一起创造很酷的东西！我希望与其他充满热情的工程师一起探索和实验。我们可以做 Kaggle 项目、LeetCode，或者只是面试头脑风暴。如果有人愿意提出想法并看看我们可以一起创造什么很酷的东西，请联系我。    提交人    /u/Rude-Eye3588   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dj8pg6/p_d_hi_im_a_senior_machine_learning_engineer/</guid>
      <pubDate>Wed, 19 Jun 2024 02:45:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] - AMD MI300X 和 Nvidia H100 在 FFT 中的基准测试：VkFFT、cuFFT 和 rocFFT 比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dj1ixf/d_amd_mi300x_and_nvidia_h100_benchmarking_in_fft/</link>
      <description><![CDATA[   您好，我是 VkFFT 的创建者 - 用于 Vulkan/CUDA/HIP/OpenCL/Level Zero 和 Metal 的 GPU 快速傅里叶变换库。目前没有太多独立基准测试来比较 Nvidia (H100 SXM5) 和 AMD (MI300X) 的现代 HPC 解决方案，因此一旦这些 GPU 按需可用，我就会想知道它们执行快速傅里叶变换的效果如何 - 以及供应商库（如 cuFFT 和 rocFFT）与我的实现相比的表现如何。 按需租赁非常昂贵，因此这些初步结果仅包括单精度和双精度的 1D 批处理 2 个复杂到复杂 FFT 的幂。此基准测试通常在 GPU 上受内存限制，这意味着大部分时间都花在利用 VRAM 总线和将数据从 VRAM 传输到芯片上（批处理大小选择得足够大以减少缓存重用并利用所有计算单元）。我使用估计带宽作为基准指标，其计算方式为 (2 x 系统大小 [GB]) / 执行时间 [s]。之所以有 2 个倍数，是因为我们需要上传数据并从芯片下载数据。因此，对于内存受限的代码，此值应接近设备的内存带宽。 https://preview.redd.it/ngv6qqxvbd7d1.png?width=4500&amp;format=png&amp;auto=webp&amp;s=d4bdc8893462561f307e758cafb10e3f76636174 在单精度下，两种 GPU 的结果相似 - 单上传 FFT 算法的带宽约为 3TB/s。大约 2^14（取决于实现）后，所有库都切换到两次上传（和两次下载）FFT 算法，导致内存传输量增加 2 倍，随后带宽下降 2 倍。切换到三次上传发生在 2^24 左右。总体而言，两种 GPU 的理论带宽都未达到（H100 为 3.35TB/s，MI300X 为 5.3TB/s），但实际值低于规格值是很常见的。对于 AMD MI300X，小尺寸的结果也不一致，这可能是因为需要对新的多芯片设计和 L3 缓存进行更多优化。当前的 VkFFT 版本（针对上一代硬件进行了优化）与供应商解决方案相匹配，并且通常优于供应商解决方案，适用于高度优化的 2 的幂的情况。  https://preview.redd.it/9q0wt6m3cd7d1.png?width=4500&amp;format=png&amp;auto=webp&amp;s=19644a0945cd9f4a6acd4172d956c467bca94856 双精度结果的缩放比例与单精度类似。 AMD MI300X 在此实现了比单精度更高的基本带宽，我还不确定为什么（也许 1:1 FP64:FP32 核心比率会派上用场）。 VkFFT 还针对非 2 幂的情况进行了高度优化，因此在新硬件上应该表现良好。您可以在 VkFFT 论文中找到实现的算法描述和上一代 HPC GPU 的完整性能比较。一旦我解决了访问成本问题并进行了广泛的测试，我就会调整新 GPU 的代码。 总体而言，MI300X 与 H100 具有竞争力，而且看起来 AMD 改进了前几代 CDNA 的许多问题（即远程合并访问的内存引脚序列化）。看起来每个计算单元仍然比相应的流式多处理器弱 - 它具有更小和更慢的共享内存/L1 和 L2 缓存，但是，它通过拥有 L3 缓存和新的多芯片设计（连接 304 个计算单元）来抵消，其影响有待估计。 感谢您的阅读，如果您对 VkFFT 或测试程序有任何疑问 - 我很乐意回答。    提交人    /u/xdtolm   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dj1ixf/d_amd_mi300x_and_nvidia_h100_benchmarking_in_fft/</guid>
      <pubDate>Tue, 18 Jun 2024 21:05:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 工业界的机器学习研究人员：如何找出时间发表论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1divk13/d_ml_researchers_in_industry_how_do_you_find_time/</link>
      <description><![CDATA[背景：我在一家 FAANG 公司从事计算机视觉工作。我非常幸运，能够应用相对先进的技术。我通常每年至少参加一次大型会议，看到很多行业科学家发表演讲/张贴海报，我不得不问：怎么做到的？ 我每周花 40 个小时将技术应用于我公司特定的数据集/问题。我擅长我的工作，紧跟最新技术，为我的雇主创造了很多价值。这些技术甚至可以发表，但这需要在开源数据集上对这些方法进行基准测试。我无法想象在拥有生活和爱好的同时，还要找到进行所有实验和写作所需的额外时间。 尽管如此，我觉得这是对我的期望。与我共事的科学家基本上没有研究以外的生活，这似乎很正常（除非他们周末去远足……）。    提交人    /u/generating_loop   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1divk13/d_ml_researchers_in_industry_how_do_you_find_time/</guid>
      <pubDate>Tue, 18 Jun 2024 16:56:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文提出想法却没有结果？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1div5a6/r_papers_proposing_ideas_without_results/</link>
      <description><![CDATA[考虑到训练某些深度学习模型（尤其是 LLM）所需的资源，由于资源不足，找到一篇提出想法但无法展示结果的论文有多普遍？换句话说，如果研究人员有一个有前途的想法，他们想向其他可能拥有更多资源的研究团队提出这个想法，那么当显示出积极结果时，他们有没有办法这样做，同时保持他们的贡献？    提交人    /u/SingularityCharity   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1div5a6/r_papers_proposing_ideas_without_results/</guid>
      <pubDate>Tue, 18 Jun 2024 16:39:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你能将自我完善的 LLM 系统推向多远？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1diszz1/d_how_far_can_you_push_selfimproving_llm_systems/</link>
      <description><![CDATA[      我看到最近大量的研究论文和技术，它们展示了如何将 LLM 与其他工具结合起来创建一个可以自我改进的自我强化系统循环。 例如，DrEureka 使用 LLM 为机器人操作任务创建多个奖励模型的草稿。然后将结果反馈给模型，并告诉模型对结果进行推理并思考如何改进自身。该模型不仅创建和调整奖励函数，而且还进行配置以促进 sim2real 传输。根据论文，这种技术已被证明可以创建比人类更好的奖励模型。 https://preview.redd.it/w14kfgbuic7d1.png?width=1300&amp;format=png&amp;auto=webp&amp;s=415dcdf48e868aa7157e7b7b7fd34c507e9c7125 另一个更新的例子是 Sakana AI 的 LLM^2。在这项技术中，LLM 用于建议损失函数。然后测试这些函数，并将结果发送回模型进行审查和改进。Sakana 的研究人员使用这项技术创建了 DiscoPOP，据他们称，它“在多个保留评估任务中实现了最先进的性能，优于直接偏好优化 (DPO) 和其他现有方法。” https://preview.redd.it/8sujx731jc7d1.png?width=2988&amp;format=png&amp;auto=webp&amp;s=5bfb0c32baa990d59333a6f90f714d3f1100a148 这里的重复模式是：  使用 LLM 生成多个假设（LLM 的好处是它们可以生成许多假设，甚至一些可能违反直觉但在实践中有效的假设）。 使用验证机制（Python 执行器、数学解算器等） 让模型推理结果并提出改进建议 重复  虽然这种模式有几个有趣的例子运行良好（包括上面提到的两个），但我想知道这个社区中是否有人知道这些方法的局限性是什么？这样的系统在哪里会遇到瓶颈？您可以将这种模式推广到多远，以及在哪些领域这种模式不起作用？    提交人    /u/bendee983   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1diszz1/d_how_far_can_you_push_selfimproving_llm_systems/</guid>
      <pubDate>Tue, 18 Jun 2024 15:09:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 优化指标和满意度指标</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1diqlq6/d_optimising_metric_and_satisficing_metric/</link>
      <description><![CDATA[为满意指标设置验收标准是有意义的。毕竟，模型必须满足部署的验收标准。例如，假设业务要求精度至少为 80%。精度是令人满意的指标。精度低于 80% 的模型将不会被部署。 优化指标意味着模型必须尽可能好地达到这个指标。例如，平均精度。（调整分类阈值以提高精度会牺牲召回率，反之亦然。我们希望在所有可能的阈值上减少这种权衡，因此寻找最大化 PRAUC 即平均精度的指标。）对于优化指标，设置阈值是否有意义？当它不影响模型接受或拒绝时，这个阈值有什么用处？ 渴望听到您的想法！   由    /u/ActiveBummer  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1diqlq6/d_optimising_metric_and_satisficing_metric/</guid>
      <pubDate>Tue, 18 Jun 2024 13:24:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对不同校准的测量设备进行迁移学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dip3e9/d_transfer_learning_given_differently_calibrated/</link>
      <description><![CDATA[我们遇到了以下问题，假设我们正在查看某个工厂 A 中生产样本 S 的一些机器测量值 X 和样本 Y 的一些昂贵质量测试。我们希望根据 X 预测我们无法承担 Y 的其他样本的结果 Y。X 和 Y 一起形成了一个完美的表格数据集，非常适合大多数经典机器学习任务，但有一些注意事项。首先，数据集相当小（约 500 到 5000 个样本），因为测量 Y 的成本很高，并且测量值 X 可能会随着时间的推移而恶化或改变，甚至会由于机器校准而出现突然转变。因此，概念漂移是常态，而不是例外。 现在我们还有来自工厂 B 的数据，他们使用不同的设备测量 X，但也进行昂贵的测试 Y。至少我们可以依赖结果 Y，因为这个测试在各个工厂之间是标准化的。因此，如果我们在工厂 A 中测量样本 S 的 Y，那么在工厂 B 中测量会得到相同的结果。但是，测量 X 的设备不是标准化的，无法进行手动校准。因此，在工厂 A 和 B 之间，平均值可能会发生变化，或者总体尺度可能会有轻微变化。 通过汇集工厂 A 和 B 的数据，有什么好的策略可以补偿小训练集？有哪些方法可以抵消工厂 A 和 B 之间 X 的平均值或尺度变化？请注意，我们不能发送校准样本 S 并在两个工厂中测量 X，以了解测量 X 的变化和差异。 有人知道这种迁移学习的一些好论文或方法吗？非常感谢！    提交人    /u/SmokinCaterpill4r   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dip3e9/d_transfer_learning_given_differently_calibrated/</guid>
      <pubDate>Tue, 18 Jun 2024 12:09:17 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] 雅典 NLP 暑期学校，2024 年 9 月 19 日至 25 日</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dineuj/news_athens_nlp_summer_school_september_1925_2024/</link>
      <description><![CDATA[      https://preview.redd.it/nfjcry734b7d1.jpg?width=1033&amp;format=pjpg&amp;auto=webp&amp;s=2118d94d8e415554e5de6e13055335e1ad711e50 链接： https://athnlp.github.io/2024/ 我们很高兴邀请所有对自然语言处理 (NLP) 和机器学习 (ML) 进入第二届雅典自然语言处理暑期学校 (AthNLP 2024)。该活动将在雅典 NCSR“Demokritos”校园举行，由 NCSR“Demokritos”、雅典经济与商业大学、RC“Athena”和赫瑞瓦特大学组织。 在 2019 年第一届 AthNLP 成功举办的基础上，AthNLP 2024 将涵盖一系列 NLP 主题，重点关注 ML 方法。预计上午有理论讲座，下午有实施和实验实验课，晚上有研究主题讲座，同时还有来自参与者和行业研究实验室的演示和海报。 主题包括分类、序列预测、线性模型、神经网络、编码器-解码器架构、机器翻译、大型语言模型和多模态。 目标受众 初步时间表： 点击此处  NLP 和计算语言学的研究人员和研究生 对 NLP 和 ML 感兴趣的计算机科学家 寻求更深入了解这些主题的行业从业者  不需要具备 NLP 和 ML 的先验知识，但需要具备基本的数学和 Python 编程技能。 重要日期  申请截止日期：2024 年 6 月 20 日 （可能会延长） 决定：2024 年 6 月 30 日 注册：2024 年 7 月 30 日 暑期学校：2024 年 9 月 19 日至 25 日  特色  费用中包含社交活动、每日午餐和咖啡休息时间 ML 和 NLP 领域顶尖研究人员的讲座 学生可选择参加海报会议，展示自己的作品 与技术公司和研究机构合作举办演示日  已确认的演讲者  Antonis Anastasopoulos，乔治梅森大学 Raquel Fernández，阿姆斯特丹大学 Ferenc Huszár，剑桥大学 Martin Krallinger，巴塞罗那超级计算中心 Mirella Lapata，爱丁堡大学 Ryan McDonald，ASAPP Aida Nematzadeh，Google DeepMind Vlad Niculae，阿姆斯特丹大学 Barbara Plank，慕尼黑路德维希马克西米利安大学 Anna Rogers，哥本哈根 IT 大学  参与费用  300 欧元（学生）（可申请奖学金） 400 欧元（大学教授或公共机构研究人员） 500 欧元（其他所有人）  如有任何疑问，请通过以下方式与我们联系：[athnlp2024@athenarc.gr]() 我们期待在那里见到您！    提交人    /u/yannisassael   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dineuj/news_athens_nlp_summer_school_september_1925_2024/</guid>
      <pubDate>Tue, 18 Jun 2024 10:30:24 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 如何为多模式RAG创建有效的多模式检索系统？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dilpbd/project_how_to_create_effective_multimodal/</link>
      <description><![CDATA[假设您需要根据用户查询检索图像和文本，我认为您可以采用 2 种方法。哪种方法更好？有没有更好的方法？ 方法 1：将所有内容转换为嵌入，并基于嵌入进行搜索。 方法 2：从图像中获取文本描述，将该文本转换为嵌入并搜索基于文本的嵌入。 如果采用方法 2，则可以选择组合基于关键字的搜索，这是一个额外的好处。    提交人    /u/badtemperedpeanut   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dilpbd/project_how_to_create_effective_multimodal/</guid>
      <pubDate>Tue, 18 Jun 2024 08:31:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用上下文敏感的声明性语法扩展合成逻辑推理数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dilijw/r_scaling_synthetic_logical_reasoning_datasets/</link>
      <description><![CDATA[  由    /u/Jean-Porte  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dilijw/r_scaling_synthetic_logical_reasoning_datasets/</guid>
      <pubDate>Tue, 18 Jun 2024 08:16:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进化策略与反向传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dila4s/d_evolutionary_strategy_vs_backpropagation/</link>
      <description><![CDATA[我正在研究用于训练 NN 的进化策略，并得到了非常有趣的结果。这是你可以使用的笔记本：Colab 笔记本链接   epoch 数 最终准确度 每 epoch 秒数    反向传播 10 97%   进化策略 10 90%   我不知道它可以走多远，但是对于完全不使用梯度信息并在与反向传播相同的时间内在 GPU 上完成训练的东西，获得 90% 的准确率是非常有趣的。 使用的 ES 算法非常简单：  用零初始化所有权重 创建大小为 N 的新一代种群 - 从正态分布中抽取每个权重，其中平均值是当前权重，标准差是学习率。 并行计算种群中每个个体的损失 - 在 GPU 上运行良好 挑选表现最好的前 k 个个体进行交配。 要获得新一代的下一个权重张量，请取表现最好的前 k 个个体的平均值。 转到步骤 2。  你知道有什么很棒的研究探索训练神经网络的进化策略吗？网络？ 更新 使用这些参数，您将在第一个 epoch 后获得 90%，在 10 个 epoch 后获得大约 94%，并且在一个 epoch 中花费的秒数相似： lr = 5E-2population_size = 512generations_per_batch = 1num_parents_for_mating = 256    submitted by    /u/kiockete   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dila4s/d_evolutionary_strategy_vs_backpropagation/</guid>
      <pubDate>Tue, 18 Jun 2024 08:00:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 视频传播模型的新调查和评论论文！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dihzuu/r_new_survey_and_review_paper_for_video_diffusion/</link>
      <description><![CDATA[      标题：视频扩散模型：综述 作者： Andrew Melnik、Michal Ljubljanac、Cong Lu、Qi Yan、Weiming Ren、Helge Ritter。 论文： https://arxiv.org/abs/2405.03150 摘要：扩散生成模型最近已成为一种用于制作和修改连贯、高质量视频的强大技术。本综述系统地概述了用于视频生成的扩散模型的关键要素，涵盖了应用、架构选择和时间动态建模。总结了该领域的最新进展并将其归类为发展趋势。调查最后概述了剩余的挑战并对该领域的未来进行了展望。 https://preview.redd.it/1845dt7zca7d1.png?width=2496&amp;format=png&amp;auto=webp&amp;s=17f52b44e9c3f1f06fe66e784512adae3d1c20de    提交人    /u/MolassesWeak2646   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dihzuu/r_new_survey_and_review_paper_for_video_diffusion/</guid>
      <pubDate>Tue, 18 Jun 2024 04:22:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] DiTTo-TTS：使用 Diffusion Transformer 实现高效、可扩展的零样本文本转语音</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dihfqu/r_dittotts_efficient_and_scalable_zeroshot/</link>
      <description><![CDATA[  由    /u/keonlee9420  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dihfqu/r_dittotts_efficient_and_scalable_zeroshot/</guid>
      <pubDate>Tue, 18 Jun 2024 03:51:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在我的机器学习职业生涯中感到迷茫：需要建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dhwzjk/d_feeling_lost_in_my_ml_career_advice_needed/</link>
      <description><![CDATA[大家好， 我希望这是发帖的正确地方，感谢您花时间阅读。 我今年 38 岁，来自一个贫穷的国家。父母抛弃了我，我和祖母一起长大，经历了巨大的损失和贫困。尽管我很聪明，但我一直在与注意力缺陷问题作斗争。 24 岁时，我搬到欧洲攻读计算机科学硕士学位，后来又攻读博士学位。学习六个月后，祖母去世了，导致我患上了严重的抑郁症，不得不暂停学业两年。最终，出于维持签证状态的需要，我恢复了学业，并获得了博士学位资助。我对信息检索产生了浓厚的兴趣，并于 2014 年完成了该领域的博士学位。 我的博士之旅充满挑战，抑郁和缺乏导师的支持。尽管如此，我还是发表了几篇论文，尽管我认为它们很平庸。即使在博士答辩之后，我仍然觉得自己像个大三学生。幸运的是，我在一家信誉良好的公司找到了一份工作，希望能提高自己的技能，但那是一个非技术环境。我研究了简单的 ML 模型并领导了 AI 路线图，更注重管理和领导力，而不是技术 ML 技能。 在此期间，ML 出现了重大进步，例如 BERT 和 GPT。现在我觉得我错过了这些发展。我的简历看起来令人印象深刻，有计算机科学学位、博士学位和 AI 团队经理，但我在编码和跟上新的 NLP 主题方面遇到了困难。 我确实喜欢管理和帮助他人成长，这是我的经理注意到并鼓励的（她对我说：“我从未见过有人花这么多时间帮助和培养他人，并在做这件事时表达出如此多的快乐”）。最近，我被目前的公司聘用为领导一个 NLP 研究和应用科学团队，但我觉得自己没有资格管理 ML 科学家，因为我自己并不是专家。 我也在考虑在更先进的科技公司探索从事尖端 NLP 研究的机会。我想向自己证明我有能力而不是无能。在过去的一年里，我一直专注于我的心理健康，并被诊断出患有严重抑郁症和 ADHD。这帮助我理解了我过去的行为，现在我处于一个更好的状态，正在努力完善自己。但我感到不知所措和迷茫，因为我觉得我不是真正的研究科学家，也不是 ML 工程师，也不是 AI 团队经理，因为我觉得我在所有方面都有所欠缺。 任何关于如何前进的建议都将不胜感激。 感谢您的时间和理解。    提交人    /u/Ikigai-iw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dhwzjk/d_feeling_lost_in_my_ml_career_advice_needed/</guid>
      <pubDate>Mon, 17 Jun 2024 12:35:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>