<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Sat, 10 Aug 2024 12:27:13 GMT</lastBuildDate>
    <item>
      <title>[D] 需要专家建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eopzz6/d_need_expert_suggestion/</link>
      <description><![CDATA[我有 120 万个条形码的数据，这些数据未经规范化，有些条形码包含品牌名称，但有些条形码包含额外的不太有用的数据，例如“Diléa Dilea Zero Lactose Young Gouda Slices 150 Gr” 我只对品牌名称感兴趣，例如本例中的“Diléa” 作为一名移动开发人员，我之前对 ML 一无所知，但在我的调查中，NER（命名实体识别）似乎是从这些数据中提取名称的好概念。 你有什么建议？    提交人    /u/usamakarim   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eopzz6/d_need_expert_suggestion/</guid>
      <pubDate>Sat, 10 Aug 2024 10:38:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 的替代品？你有什么经验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eokswq/d_transformer_alternatives_what_are_your/</link>
      <description><![CDATA[我看过一些关于 Transformer 替代方案的文章，但我没有看到人们在自己的数据集中使用它们的经验。是的，论文会告诉你它们很棒，但是从头开始制作它们并训练它们并找到好的超参数等经验......领域中的变化及其对它的影响；这些都是有价值的东西，但我们没有考虑到。 所以我想讨论一下 Transformer 的替代方案？哪一个是你最喜欢的，或者体验如何？    提交人    /u/MysticalDragoneer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eokswq/d_transformer_alternatives_what_are_your/</guid>
      <pubDate>Sat, 10 Aug 2024 04:55:16 GMT</pubDate>
    </item>
    <item>
      <title>轨迹预测 [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eoknon/trajectory_prediction_project/</link>
      <description><![CDATA[嗨，Redditors，我目前需要轨迹数据（例如，移动车辆/行人的坐标）。我打算用它来训练一个顺序变换器神经网络。网上的很多数据集似乎都是付费的，所以我真的希望有一个免费的替代方案，因为这是一个个人项目:)     提交人    /u/EmotionHeavy4684   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eoknon/trajectory_prediction_project/</guid>
      <pubDate>Sat, 10 Aug 2024 04:46:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 避免非凸正则化问题的严格鞍点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eojtkk/r_avoiding_strict_saddle_points_of_nonconvex/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eojtkk/r_avoiding_strict_saddle_points_of_nonconvex/</guid>
      <pubDate>Sat, 10 Aug 2024 04:00:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我是一个奇怪的数据集：语言模型的元语言测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eojeyi/r_i_am_a_strange_dataset_metalinguistic_tests_for/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eojeyi/r_i_am_a_strange_dataset_metalinguistic_tests_for/</guid>
      <pubDate>Sat, 10 Aug 2024 03:37:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医疗 AI：顶级研究论文/模型（2024 年 7 月 28 日至 8 月 3 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eoj3xe/d_last_week_in_medical_ai_top_research/</link>
      <description><![CDATA[       Palmyra-Med（新医学法学硕士） -  作家团队引入了专门的医疗保健模式，在医学基准中取得了 85.9% 的平均成绩。  医学法学硕士会被愚弄吗？ （微软研究院） -  研究调查了医学 LLM 中的漏洞，重点介绍了患者数据泄露等风险。  改进医学中的 RAG -  研究人员提出了 i-MedRAG，一种用于医学 LLM 的迭代检索增强生成方法。  CollectiveSFT -  中国研究人员使用多样化、分布良好的数据集进行微调，以提高医学 LLM 的性能。  MedExpQA -  研究人员推出了第一个使用 LLM 进行医学问答的多语言基准。  预训练医学 LLM -  研究比较了医学领域特定领域和混合领域预训练法学硕士。  ...  查看完整帖子 https://x.com/OpenlifesciAI/status/1822091419848237387 https://preview.redd.it/o3jvwixt8rhd1.png?width=1476&amp;format=png&amp;auto=webp&amp;s=7f70f2876c7572ad13ef6cadd6202351555e617c    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eoj3xe/d_last_week_in_medical_ai_top_research/</guid>
      <pubDate>Sat, 10 Aug 2024 03:20:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] Apple Intelligence Foundation 语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eogp0c/r_apple_intelligence_foundation_language_models/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eogp0c/r_apple_intelligence_foundation_language_models/</guid>
      <pubDate>Sat, 10 Aug 2024 01:17:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在小数据集上训练视觉变换器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eog6j9/p_training_a_vision_transformer_on_a_small_dataset/</link>
      <description><![CDATA[我的一位教授给了我一个小项目来实现视觉变换器，如 2020 年的论文“一张图片胜过 16x16 个单词：用于大规模图像识别的变换器”中所述。  该论文描述了在大型数据集上对变换器进行预训练，然后在较小的集合和任务上进行微调。  我相信他们用于预训练的最小数据集是 Image net，大约有 120 万张训练图像。我一直在尝试在 tiny image net 上对我的网络进行预训练，只有 100,000 张训练图像和 200 个图像类别。 使用此设置，我已经能够在训练集上实现大约 93% 的准确率，但我很难让测试集的准确率达到 40% 以上。 在使用 tiny image net 之前，我尝试在 Oxford pets 上对其进行训练，测试准确率约为 15%。这表明更多的数据肯定会改善结果。 我只是想知道我目前的结果是否表明实施存在问题，而不是数据不足的问题。我知道 Transformer 在大型数据集上蓬勃发展，但我只是想看看当前的差异是否比预期的更糟糕。如果有人有任何见解可以分享，那就太好了。    提交人    /u/TheToad54   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eog6j9/p_training_a_vision_transformer_on_a_small_dataset/</guid>
      <pubDate>Sat, 10 Aug 2024 00:51:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] txv：ViT 的可解释性包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eo3s7h/p_txv_an_explainability_package_for_vits/</link>
      <description><![CDATA[txv 是一个视觉变换器可解释性包。它为视觉变换器提供了类似 CAM 的可视化效果。 pip install txv Github 存储库：https://github.com/LokeshBadisa/txv 主页：https://lokeshbadisa.github.io/txv/ 文档：https://lokeshbadisa.github.io/txv/api_reference 教程：https://lokeshbadisa.github.io/txv/tutorials   由    /u/Eage1823  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eo3s7h/p_txv_an_explainability_package_for_vits/</guid>
      <pubDate>Fri, 09 Aug 2024 16:12:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 告别低分辨率：用于图像超分辨率的扩散小波方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eo2xs9/r_waving_goodbye_to_lowres_a_diffusionwavelet/</link>
      <description><![CDATA[我们很高兴地宣布，我们在今年的国际神经网络联合会议 (IJCNN 2024) 上成功展示了 DiWa！:-) TL;DR：DiWa 是一种用于增强图像的扩散小波技术。它将扩散模型与离散小波变换和基于初始回归的预测器相结合，以实现高质量、详细的图像重建。欢迎就论文、我们的发现或未来工作与我们联系！ arXiv：https://arxiv.org/abs/2304.01994    提交人    /u/Maleficent_Stay_7737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eo2xs9/r_waving_goodbye_to_lowres_a_diffusionwavelet/</guid>
      <pubDate>Fri, 09 Aug 2024 15:40:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] Karpathy - “RLHF 只是勉强算是 RL”。你同意吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enzn87/d_karpathy_rlhf_is_just_barely_rl_do_you_agree/</link>
      <description><![CDATA[https://x.com/karpathy/status/1821277264996352246    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enzn87/d_karpathy_rlhf_is_just_barely_rl_do_you_agree/</guid>
      <pubDate>Fri, 09 Aug 2024 13:25:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2024 数据集和基准测试轨道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enzi7r/d_neurips_2024_dataset_benchmarking_track/</link>
      <description><![CDATA[大家知道评论什么时候会出来吗？    提交人    /u/BodybuilderJunior775   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enzi7r/d_neurips_2024_dataset_benchmarking_track/</guid>
      <pubDate>Fri, 09 Aug 2024 13:19:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 探索 Kolmogorov-Arnold 网络在分类中的局限性：对软件训练和硬件实现的见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enx9be/r_exploring_the_limitations_of_kolmogorovarnold/</link>
      <description><![CDATA[      TL;DR：在训练计算方面，MLP 远远优于 KAN效率 论文： https://arxiv.org/pdf/2407.17790 摘要：  Kolmogorov-Arnold 网络 (KAN) 是一种新型神经网络，由于能够以更高的准确性和互操作性替代人工智能 (AI) 中的多层感知器 (MLP)，因此最近获得了普及和关注。然而，KAN 评估仍然有限，无法提供特定领域的深入分析。此外，还没有对 KAN 在硬件设计中的实现进行研究，这将直接证明 KAN 在实际应用中是否真正优于 MLP。因此，在本文中，我们专注于使用四种不同类型的数据集验证 KAN 的分类问题，这是 AI 中常见但重要的主题。此外，还考虑了使用 Vitis 高级综合 (HLS) 工具的相应硬件实现。据我们所知，这是第一篇为 KAN 实现硬件的文章。结果表明，在高复杂度数据集中，KAN 无法在利用大量硬件资源的情况下实现比 MLP 更高的准确度。因此，MLP 仍然是实现软件和硬件实现准确度和效率的有效方法。  亮点：  除了 Dry Bean 数据集的训练时间外，其他三个数据集始终表明 KAN 需要比 MLP 长得多的训练时间，范围从 6.55 倍（151.4 vs 23.1 秒）到 36.68 倍（198.1 vs 5.4 秒）。[...] 除了 Wine 数据集外，MLP 的损失减少速度一直比 KAN 更快，损失值也更低。总体而言，在训练时间和损失减少方面，KAN 并不比 MLP 更好。 总体而言，KAN 未能表现出比 MLP 更高的准确率，并且 KAN 的符号公式表示在分类挑战中的表现甚至比 MLP 更差。此外，KAN 还需要开发人员在最后阶段投入大量时间和精力来创建符号公式。  [专门的硬件测试：]  这些结果表明，与 MLP 中的正常矩阵乘法相比，在硬件上实现符号公式需要更多的硬件资源。此外，当 KAN 模型的规模增加时，所需的硬件资源也会相应增加。  视觉亮点： GPU 训练 有利于 MLP 的损失差异可能非常大。不过，Wine 数据集的快速 KAN 收敛值得注意。该数据集只有 178 个示例，每个示例有 13 个特征 GPU 训练 FPGA 训练 代码： https://github.com/Zeusss9/KAN_Analysis     由   提交  /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enx9be/r_exploring_the_limitations_of_kolmogorovarnold/</guid>
      <pubDate>Fri, 09 Aug 2024 11:27:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>