<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 11 Dec 2024 21:16:32 GMT</lastBuildDate>
    <item>
      <title>[D] 如何在 NeurIPS 结交朋友和建立人脉？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hc0x89/d_how_to_make_friends_and_network_at_neurips/</link>
      <description><![CDATA[这是我第一次参加 NeurIPS，看到这么多人以及这么多招聘人员，我感到很受震撼。我来自一所不太知名的大学，独自一人来参加会议，甚至我的导师都不在。 我并没有和很多其他与会者或招聘人员交谈，因为 (1) 在一大群人中接近其他人似乎很难，(2) 我觉得自己有强烈的冒名顶替综合症，无法胜任招聘人员提供的工作。我只被接受了一篇研讨会论文，它更偏向于应用，不像其他许多学生那样技术性。 有什么建议可以让我充分利用会议的剩余时间吗？关于这一点，有人也想见面聊聊吗？我是来自英国的三年级博士生，但我自己来自温哥华，所以了解该地区的很多事情。干杯！    由    /u/K_is_for_Karma 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hc0x89/d_how_to_make_friends_and_network_at_neurips/</guid>
      <pubDate>Wed, 11 Dec 2024 18:54:26 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以找到 Llama 3 初始化 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbudg3/where_to_find_llama_3_initialisation_r/</link>
      <description><![CDATA[标题基本上说明了一切，我想要一个好的变压器基线，我想初始化可能很重要。我可以找到 llama 3 模型，但我可以找到它们如何初始化参数。有人知道我在哪里可以找到这个吗？    提交人    /u/idkwhatever1337   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbudg3/where_to_find_llama_3_initialisation_r/</guid>
      <pubDate>Wed, 11 Dec 2024 14:14:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 连续潜在空间推理：通过连续思维链提高 LLM 性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbto1w/r_continuous_latent_space_reasoning_enhancing_llm/</link>
      <description><![CDATA[本文引入了COCONUT（连续思维链），将语言模型推理从离散的token空间转化为连续的潜在空间，其核心思想是将推理步骤编码为连续向量而不是文本token，从而实现更灵活、更精确的中间计算。 主要技术点： • 将文本↔连续向量映射的编码器-解码器架构 • 对潜在向量进行操作的新型连续推理模块 • 在连续空间中并行处理推理步骤 • 推理过程中基于梯度的优化 • 结合重建和推理目标的特殊损失函数 主要结果： • 与传统方法相比，推理基准提高了20% • 减少了解决复杂问题所需的计算步骤 • 在不同推理任务中获得更一致的性能 • 更好地处理数学和逻辑推理 • 增强了维持连贯推理链的能力 我认为这种方法可以有意义地推进语言模型处理复杂推理任务的方式。通过超越离散标记，模型可以更好地捕捉类似人类推理的连续性。在推理过程中在连续空间中进行优化的能力对于提高可靠性特别有希望。 我认为主要的挑战是将其扩展到非常大的模型，同时管理计算成本。离散空间和连续空间之间的转换增加了需要解决的开销。 TLDR：新方法将语言模型推理转换为连续向量空间而不是离散标记，通过更灵活的计算在推理任务上显示出 20% 的更好性能。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbto1w/r_continuous_latent_space_reasoning_enhancing_llm/</guid>
      <pubDate>Wed, 11 Dec 2024 13:39:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 掌握最先进的进化优化所需的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbt986/d_resources_to_get_up_to_the_speed_with_the_state/</link>
      <description><![CDATA[有很多好书可以让你接近该领域的最新水平，特别是机器学习和深度学习。但是，有没有关于进化优化的好现代书籍？有没有好的课程？    提交人    /u/ArtisticHamster   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbt986/d_resources_to_get_up_to_the_speed_with_the_state/</guid>
      <pubDate>Wed, 11 Dec 2024 13:17:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于 3D 环境中的物体检测和深度感知的视觉语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbs52u/d_visual_language_models_for_object_detection_and/</link>
      <description><![CDATA[我想在 3D 模拟引擎 (Unity) 中运行 VLM 进行对象检测和深度感知。考虑到准确性、速度和微调的简易性等因素，有哪些适合此用例的 vlm？ 用例示例： 在 Unity 中，我有一个包含 2 个房间的环境。设置了一个摄像头，用于捕捉场景的图像/视频源。VLM 应该在环境中找到特定对象（比如黑色瓶子），判断它在 3D 场景中的位置并为其生成坐标。 基本上，我想准确找出该对象在 Unity 环境中的位置。如何做到这一点？    提交人    /u/reso_ams   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbs52u/d_visual_language_models_for_object_detection_and/</guid>
      <pubDate>Wed, 11 Dec 2024 12:15:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 任何可用于多种场景的 3D 重建方法（即不使用就扔）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbreb4/d_any_3d_reconstruction_method_that_can_be_used/</link>
      <description><![CDATA[NeRF 对于每个场景都是独一无二的，因此需要从头开始训练。高斯溅射也是场景所独有的。我理解场景很复杂，因此训练后几乎没有机会出现可以输出多个场景的神经网络。但是，是否仍然有一些场景表示在某种程度上没有被使用和完全抛弃？    提交人    /u/deathmaster2011   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbreb4/d_any_3d_reconstruction_method_that_can_be_used/</guid>
      <pubDate>Wed, 11 Dec 2024 11:27:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 评估生成模型中隐含的世界模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbra2d/r_evaluating_the_world_model_implicit_in_a/</link>
      <description><![CDATA[  由    /u/jsonathan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbra2d/r_evaluating_the_world_model_implicit_in_a/</guid>
      <pubDate>Wed, 11 Dec 2024 11:19:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 作者何时可以访问 ICLR 元评论？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbqc75/r_when_do_authors_have_access_to_iclr_metareviews/</link>
      <description><![CDATA[大家好， 这是我第一次向 ICLR 提交论文。ICLR 网站上说元评审将于今天（几个小时后）截止。作者可以在收到决定通知的同时还是在元评审截止日期后立即查看这些评审？ 谢谢！    提交人    /u/Glaze_anetha42   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbqc75/r_when_do_authors_have_access_to_iclr_metareviews/</guid>
      <pubDate>Wed, 11 Dec 2024 10:10:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 Stella 嵌入模型比其他同等质量的模型小得多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbkww5/d_why_are_the_stella_embedding_models_so_much/</link>
      <description><![CDATA[在 MTEB 排行榜上，stella_en_v5 目前排名第三，而使用的内存仅为前 10 名中所有非 Stella 模型的五分之一。 stella_en_400M_v5 排名第十，而使用的内存比排名在其附近的模型少 15-20 倍。这似乎在基准测试的几个子任务中相对一致（针对英语）。 这里的秘诀是什么？或者说，陷阱是什么？目前还没有论文。有人知道详细信息吗？    提交人    /u/-p-e-w-   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbkww5/d_why_are_the_stella_embedding_models_so_much/</guid>
      <pubDate>Wed, 11 Dec 2024 03:58:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审查流程激励和竞争</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbf2gs/d_review_process_incentives_and_competition/</link>
      <description><![CDATA[我的一个实验室同事给我看了一条 AC 的评论，其中要求 ACM 会议的审稿人参与 ICLR 反驳和讨论阶段。光是这一点就让我感到好笑（和悲伤），但让我感到震惊的是，其中一位审稿人回应说，审稿过程激励审稿人给论文打低分，以阻止竞争论文被接受。 我想相信这种情况会发生，但其影响并不显著。然而，我听说这在推荐系统等领域非常常见。它在 ML 中普遍程度如何？    提交人    /u/like_a_tensor   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbf2gs/d_review_process_incentives_and_competition/</guid>
      <pubDate>Tue, 10 Dec 2024 23:07:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从失业到 Lisp：在青少年的深度学习编译器上运行 GPT-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb7v5h/d_from_unemployment_to_lisp_running_gpt2_on_a/</link>
      <description><![CDATA[几个月前，我失业了，不知道下一步该做什么。我想从系统的角度更多地了解深度学习。在学习了吴恩达的监督学习课程后，我渴望更多地了解像 Pytorch 或 Tinygrad 这样的深度学习框架（或深度学习编译器）。 我开始研究 Tinygrad，从我在网上找到的教程中学习，我发现它很有趣，因为它是一个真正的编译器，它采用传统的 Python 代码并将其转换为抽象语法树，然后将其解析为 UOps 和 ScheduleItems，最终拥有一个代码生成层。虽然设计很有趣，但代码很难读。 就在那时，我偶然发现了一些完全出乎意料的东西，一个基于 Common Lisp 构建的深度学习编译器，由一名 18 岁的日本年轻人在他的间隔年期间维护。而目前我们已经完成了一件伟大的事情，它可以运行 gpt2！ 目前，它只是生成 C 内核，但未来我们希望支持 cuda codegen 以及许多其他功能，并作为任何想要使用 Common Lisp 进行深度学习编译器工作的人的学习工具。 这是一个开源项目，欢迎任何人做出贡献！ https://github.com/hikettei/Caten 编辑：添加一个关于它如何工作的示例。 这是我在另一个论坛上写的一个例子： 你好！谢谢你的提问。 首先，Caten 中有三个抽象层：  caten/apis | 高级图形接口 2. caten/air |低级图形接口 3. caten/codegen | AIR Graph =&gt; 内核生成器  编译器的输入只是 Common Lisp 类（类似于 torch 模块）。例如，在 Common Lisp 中，我们可以创建一个执行 SinCos 的模块：  (defclass SinCos (Func) nil (:documentation &quot;The func SinCos computes sin(cos(x))&quot;)) ;; Forward 为下一次计算创建一个惰性张量。 ;; 您可以使用 `st` 宏跳过此过程。 (defmethod forward ((op SinCos) &amp;rest tensors) (st &quot;A[~] -&gt; A[~]&quot; (tensors))) ;; Backward 是可选的（这次跳过）（defmethod behind ((op SinCos) &amp;optional prev-grad) (declare (ignore prev-grad)) nil）；； Lower 描述了 `SinCos` 的降低表达式 (defmethod lower ((op SinCos) &amp;rest input) (let ((x (car input))) (with-context (a (%sin (%add x (%fconst (/ pi 2))))) (b (%sin a)))))  `apis` 层是高级接口，而 `lower` 方法是代码生成之前的低级步骤。 接下来，框架生成一个抽象 VM (AVM) 表示：  #S(AVM :GRAPH Graph[seen=NIL, output=(STC6466_1)] { &lt;ALLOCATE : TID6464 &lt;- (shape=(1), stride=(1)) where :dtype=FLOAT32&gt; &lt;Node[BUFFER] ALLOCATE(NID6480) : SID6479* &lt;- ()&gt; &lt;Node[BINARYOPS] ADD(NID6484) : BID6483* &lt;- (TID6464, LID6481)&gt; &lt;Node[UNARYOPS] SIN(NID6486) : UID6485* &lt;- (BID6483)&gt; &lt;Node[UNARYOPS] SIN(NID6488) : UID6487* &lt;- (UID6485)&gt; &lt;Node[SPECIAL/VM] PAUSE/BACKWARD(NID6501) : STC6466_1* &lt;- (UID6487)&gt; })  然后，将计算图转化为调度项目：  FastGraph[outputs=(val_6)] { { Allocate } : [ val_0 &lt;- (1) ] { KERNEL } : [ val_5 &lt;- val_1, val_0 :name=FUSED_SIN_SIN_ADD_LOAD6511] }  最后，代码生成步骤生成以下 C 代码：  void fused_sin_sin_add_load6511(float* val_5, const float* restrict val_0); void fused_sin_sin_add_load6511(float* val_5, const float* restrict val_0) { val_5[0] = sin(sin((val_0[0] + 1.5707964))); }  此 C 代码由 C 编译器编译并执行。 因此，回答您的问题：编译器采用 Common Lisp 代码并生成 C 函数。    提交人    /u/yCuboy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb7v5h/d_from_unemployment_to_lisp_running_gpt2_on_a/</guid>
      <pubDate>Tue, 10 Dec 2024 18:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 这个数据集到底有多难？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb54nd/r_how_difficult_is_this_dataset_really/</link>
      <description><![CDATA[新论文提醒！ 分类自动编码器测量分类难度并检测标签错误 我们倾向于认为训练分类器的挑战是由超参数调整或模型创新来处理的，但数据及其嵌入中存在丰富的固有信号。了解机器学习问题的难度一直很难。现在不再如此。 现在，您可以计算分类数据集的难度，而无需训练分类器，并且每个类别只需要 100 个标签。而且，这个难度估计与数据集大小出奇地无关。 传统上，数据集难度评估方法耗时和/或计算密集型，通常需要训练一个或多个大型下游模型。更重要的是，如果你在数据集上训练具有特定架构的模型并实现特定的准确度，则无法确定你的架构是否完全适合手头的任务 - 可能是一组不同的归纳偏差会导致模型更轻松地学习数据中的模式。 我们的方法为每个类训练一个轻量级自动编码器，并使用重建误差的比率来估计分类难度。在 100k 样本数据集上运行此数据集难度估计方法只需几分钟，并且不需要调整或自定义处理即可在新数据集上运行！ 效果如何？我们对 19 个常见的视觉数据集进行了系统研究，将我们的方法估计的难度与 SOTA 分类准确度进行了比较。除了一个异常值外，相关性为 0.78。它甚至适用于医疗数据集！ 论文链接：https://arxiv.org/abs/2412.02596 GitHub Repo Linked in Arxiv pdf    提交人    /u/ProfJasonCorso   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb54nd/r_how_difficult_is_this_dataset_really/</guid>
      <pubDate>Tue, 10 Dec 2024 16:04:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 理解 Transformer 在图形搜索中的局限性：学习和扩展行为的机制分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb1wjo/r_understanding_transformer_limitations_in_graph/</link>
      <description><![CDATA[本文通过研究 transformer 如何处理图连通性问题，解决了关于 transformer 学习搜索算法的能力的一个基本问题。作者开发了一种新颖的解释方法来分析 Transformer 如何逐层处理搜索操作。 关键技术要点：- 使用图可达性作为测试用例，具有可控的复杂性和无限的训练数据- 开发解释技术来了解 Transformer 层如何计算可达顶点集- 发现 Transformer 学习随着深度呈指数级扩展搜索边界- 展示了基于图大小的明显扩展限制- 表明上下文学习（思路链）无法克服这些限制 主要结果：- 小型 Transformer 在经过适当训练后可以学习基本搜索- 每一层计算先前可达顶点及其邻居的并集- 随着图大小的增加，性能急剧下降- 添加参数并不能解决扩展问题- 模型在处理超出其训练分布的图时遇到困难 我认为这项工作揭示了 Transformer 中重要的架构限制，我们需要为需要搜索功能的应用程序解决这些限制。缩放行为表明，对于更大的搜索空间，而不仅仅是更大的模型，我们可能需要从根本上不同的方法。 我认为他们开发的解释方法对于理解 Transformer 如何处理除图形之外的其他类型的结构化数据很有价值。关于扩展限制的明确经验结果应该为涉及搜索类计算的应用程序的架构选择提供参考。 TLDR：Transformer 可以学习基本的图形搜索操作，但在扩展方面面临根本限制。添加更多参数无济于事，这表明我们需要新的方法来解决复杂的搜索问题。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb1wjo/r_understanding_transformer_limitations_in_graph/</guid>
      <pubDate>Tue, 10 Dec 2024 13:37:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>