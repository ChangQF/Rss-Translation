<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 01 Mar 2024 03:16:58 GMT</lastBuildDate>
    <item>
      <title>[D] AI OSS 项目向贡献者开放？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3fmno/d_ai_oss_projects_open_to_contributors/</link>
      <description><![CDATA[我有一个大约 8 人的团队正在考虑尝试为一些 AI OSS 做出贡献，我想知道这里是否有人有任何最喜欢的项目已经受到巨大关注？我们对执行以下操作之一的 OSS 项目特别感兴趣：  让凡人能够相对经济地扩展训练或微调（当我说凡人时，我指的是我们中的凡人）没有 OpenAI 的数十亿） 更轻松、更直观地将非结构化数据（随机数据库表、pdf、网站等）转换为可随时进行微调的格式 &lt; li&gt;可用的代理（我不太相信我们已经为无监督人工智能做好了准备，所以这可能是列表中最低的代理之一，除非 OSS 领域的某些东西看起来确实很有前途） 将运行时上下文纳入 LLM，而无需对运行系统的详细信息进行配置或编程，以便您可以向 LLM 提出问题，例如“告诉我是否有任何与我认为的正常健康运行时状态相比发生了变化的情况”&lt; /li&gt; 专门针对 LLM 世界的新版本构建/部署/测试工具，使故障排除变得更加容易，因为它们更加配置驱动且 LLM 友好，并且运行时间和动态性较低？  &lt;该列表有点像我希望帮助加速​​ LLM 驱动的开发的愿望清单，现在我想要找到正在做这些事情的 OSS 项目（有牵引力！）。有人看到什么了吗？或者如果做不到这一点，任何人都知道如何搜索它们或向谁询问它们？   由   提交/u/jonxtensen  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3fmno/d_ai_oss_projects_open_to_contributors/</guid>
      <pubDate>Thu, 29 Feb 2024 23:56:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果你只是一名开发人员，你会在 LLM 中学到什么技能？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3dndi/d_what_skill_would_you_learn_in_llm_if_you_are/</link>
      <description><![CDATA[大家好， 感觉 LLM 是目前 ML 领域最有前途的工具，在各个领域都有应用潜力。但我的印象是，这就像一场赢家通吃的游戏，如果你不是最好的之一，你就没有多少机会或机会。我的意思是，如果你不够优秀，无法成为大型科技公司或一些精品初创公司（Mistral、Aleph Alpha、Databricks、C3、HF）的研究员或开发人员，那么剩下的机会不多了，我想说的是是的，它不是像网络开发、应用程序开发或云计算那样，每个级别的技能都有市场需要的技能，每个人都有机会，只是我的印象。 我想要进入这个ML领域，特别是在自己的应用程序中使用LLM，获得这个领域的工作机会，但我不确定如何有效地投入时间和精力进入这个领域，以便能够产生额外的成果值，尤其是这个问题：哪种知识深度是一个好的起点？ - 了解并能够使用最成功的法学硕士（Vertex、OpenAI、Mistral）的云 API - 理解并能够使用高级框架 LangChain、HF、微调开源模型 + 使用 vLLM 托管您自己的模型 -了解嵌入、Tokenizer、Attention、Transformer 等低级概念，并能够破解和使用低级框架 pytorch 或 tf/keras 训练您自己的模型 您认为休闲开发人员（德语为 0815）在哪里有机会进入该领域？   div&gt;  由   提交/u/tunggad  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3dndi/d_what_skill_would_you_learn_in_llm_if_you_are/</guid>
      <pubDate>Thu, 29 Feb 2024 22:35:41 GMT</pubDate>
    </item>
    <item>
      <title>[N] AI 和 NLP 爱好者激动人心的机会！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3bx77/n_exciting_opportunity_for_ai_and_nlp_enthusiasts/</link>
      <description><![CDATA[我们很高兴宣布推出 2024 年版 CheckThat! CLEF 2024 实验室，我们诚挚邀请您参加这一开创性的活动。今年，我们将加紧实施六项不同的任务，包括两项后续任务和四项全新的挑战，每一项都旨在解决跨多种语言的事实核查流程的关键方面。 🔍 任务概述：  1.推文的检查价值：深入社交和主流媒体，识别值得验证的主张。 （阿拉伯语、英语、荷兰语、西班牙语） 2.新闻文章中的主观性：检测需要特定处理策略的文本以帮助事实检查流程。 （阿拉伯语、英语、德语、意大利语、多语言） 3.说服技巧：通过说服来确定文本跨度来影响读者。 （阿拉伯语、保加利亚语、英语、葡萄牙语、斯洛文尼亚语） 4.检测模因中的角色：确定模因中实体的角色为英雄、恶棍、受害者或其他。 （阿拉伯语、英语、混合代码） 5.权威证据验证谣言：使用权威来源的证据验证谣言。 （阿拉伯语、英语） 6.可信度评估中针对对抗性示例的鲁棒性：发现在错误信息检测中误导分类器的微小变化。 （英语）  🌍 今年的实验室有望比以往更加国际化和包容性，涵盖多种语言的任务，并解决事实核查过程中的关键步骤. 📅 重要日期：  实验室注册现已开放，直至 2024 年 4 月 22 日。 评估周期会议将于2024年5月2日开始，最终提交日期为2024年5月6日。 CLEF 2024会议将于2024年9月9日至12日在法国格勒诺布尔举行。   ul&gt; 💡 无论您是对人工智能、自然语言处理和事实核查充满热情的研究人员、从业者还是学生，这都是展示您的技能、与同行合作并为斗争做出贡献的完美平台反对错误信息。 🔗 如需更多详细信息、数据集和注册，请访问：  实验室信息： https://checkthat.gitlab.io/ 数据集： https:/ /gitlab.com/checkthat_lab/clef2024-checkthat-lab 注册： https://clef2024-labs-registration.dei.unipd.it/registrationForm.php  让我们一起产生重大影响！与我们一起为更加知情和真实的数字世界铺平道路。 🌐✨ 致以诚挚的问候， CLEF-2024 CheckThat！实验室共享任务组织者   由   提交/u/firojalam04   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3bx77/n_exciting_opportunity_for_ai_and_nlp_enthusiasts/</guid>
      <pubDate>Thu, 29 Feb 2024 21:28:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 ViT 比 SWIN 更常用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3bhbd/d_why_is_vit_more_commonly_used_than_swin/</link>
      <description><![CDATA[我仍在四处阅读，但我读到的大多数计算机视觉论文都使用 ViT 作为其主干，而不是 SWIN 或其他类似的架构，但为什么呢？  ​ ViT 论文必须在 303M 图像 JFT 数据集上预训练他们的模型，以击败 ImageNet 上的早期卷积模型，而 SWIN 无需任何预训练即可实现更好的性能。训练。我想，如果 SWIN 以同样的方式进行预训练，即使不是更高的性能，也能在 ImageNet 上实现可比的性能，但不可否认的是，我还没有看到任何工作来验证这个想法。 ​ 这只是 ViT 优先的情况，所以现在每个人都使用它作为默认值还是还有其他原因？   由   提交 /u/PM_ME_JOB_OFFER   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3bhbd/d_why_is_vit_more_commonly_used_than_swin/</guid>
      <pubDate>Thu, 29 Feb 2024 21:10:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 开放人工智能超级对齐快速拨款决策？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b36h5r/d_decisions_for_open_ai_superalignment_fast_grants/</link>
      <description><![CDATA[大家好， 这笔拨款的截止日期是 2 月 18 日。有人收到回复了吗？我也不确定是否只有获奖者才会被明确通知。  提前感谢大家。   由   提交/u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b36h5r/d_decisions_for_open_ai_superalignment_fast_grants/</guid>
      <pubDate>Thu, 29 Feb 2024 17:49:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] [N] OptScale - 完全开源的 MLOps 和 FinOps 平台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b314xl/p_n_optscale_fully_open_source_mlops_and_finops/</link>
      <description><![CDATA[GitHub 链接： https:/ /github.com/hystax/optscale 如果您给我们一颗星，我们将不胜感激 OptScale 的功能：  包含候选人和资格的 ML 排行榜 数据集和模型跟踪和版本控制 运行指标和实验跟踪器 与 Optuna 集成的超级调整 培训启动器 ML 模型训练分析器 各种云成本优化功能，例如 RI/SP 使用、VM 调整大小、电源计划和成本异常检测。  OptScale 的 ML 功能正在积极开发中，应该会对 ML 团队有所帮助。 现场演示： https://my.optscale.com/live-demo   由   提交 /u/Hystax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b314xl/p_n_optscale_fully_open_source_mlops_and_finops/</guid>
      <pubDate>Thu, 29 Feb 2024 14:07:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG-嵌入降维</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2yc4f/d_rag_dimensionality_reduction_for_embeddings/</link>
      <description><![CDATA[去年早些时候，GPT 4 发布时，我读到人们对向量嵌入进行降维，特别是主成分分析，以使它们更适合 从那时起，随着 RAG 场景的发展，我就没有看到太多关于这样做的提及。 有人能阐明对 RAG 使用降维的优点吗？    由   提交 /u/BlueOrangeBerries   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2yc4f/d_rag_dimensionality_reduction_for_embeddings/</guid>
      <pubDate>Thu, 29 Feb 2024 11:40:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于 X 射线的预训练扩散 U 网（单通道）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2w3xx/r_pretrained_diffusion_unets_for_xrays_single/</link>
      <description><![CDATA[有人知道我可以用来微调的 X 射线数据（单通道）上预训练的扩散 U 网吗？图像空间或潜在空间 - 任何。最好是在乳房 X 光检查上，但任何类型都比随机初始化更好。   由   提交 /u/roleparacelsus   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2w3xx/r_pretrained_diffusion_unets_for_xrays_single/</guid>
      <pubDate>Thu, 29 Feb 2024 09:11:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 反向概念漂移 (RCD) 和概念漂移检测算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2vsbb/r_reversed_concept_drift_rcd_and_algorithm_for/</link>
      <description><![CDATA[    &lt; /a&gt;  所有 ML 模型都旨在完成一件事：学习 P(y 形式的概率分布|X）。换句话说，他们尝试学习如何在给定输入变量“X”的情况下对结果“y”进行建模。  这种概率分布 P(y|X) 也称为概念。因此，如果Concept发生变化，模型可能会变得无效。 但是我们如何知道我们的数据中是否存在新的Concept？ 或者，更重要的是，我们如何知道我们的数据中是否存在新的Concept？衡量新概念是否影响模型的性能？ 这是一个聪明的解决方案，其中主要成分是参考数据集（模型性能已知的数据集）以及包含我们想要的最新数据的数据集来监控。 分步解决方案：  我们首先在最新的数据块上训练内部模型数据。 -&gt;这使我们能够学习数据中呈现的新的可能概念。 接下来，我们使用内部模型对参考数据集进行预测。 然后，我们估计模型在参考数据集上的性能，假设模型对监控数据的预测是真实的。 如果模型的估计性能内部模型和实际监控模型有很大不同，我们就说存在概念漂移。  为了量化这个概念对性能的影响，我们减去了实际模型的根据估计性能参考性能并报告性能指标的增量。 -&gt;这就是下图所示的内容。由于概念漂移导致 F1 分数发生变化！  对于我们获得的每个新数据块，都会重复此过程。 ​ https://preview.redd.it/z570r1dqmhlc1.jpg?width=2738&amp;format=pjpg&amp;自动=webp&amp; ;s=3997aba54c71b13567bb78b8f5e4d244aa77c0b6 ​ ​   由   提交 /u/santiviquez   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2vsbb/r_reversed_concept_drift_rcd_and_algorithm_for/</guid>
      <pubDate>Thu, 29 Feb 2024 08:48:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何一步步思考：对思维链推理的机械理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2tar4/r_how_to_think_stepbystep_a_mechanistic/</link>
      <description><![CDATA[PDF: https://arxiv.org/pdf/2402.18312.pdf  研究结果： 1. 尽管 CoT 生成的不同阶段的推理要求不同，模型的功能组件几乎保持不变。不同的神经算法被实现为类似感应电路的机制的组合。  注意力头在本体相关（或负相关）标记之间执行信息移动。这种信息移动导致了此类令牌对的明显可识别的表示。通常，这种独特的信息运动从第一层开始一直持续到中间。虽然这种现象是零样本发生的，但上下文中的示例施加压力，要求在标记之间快速混合其他特定于任务的信息。 部署多个不同的神经通路来计算答案，这也是并行的。不同的注意力头，尽管具有不同的概率确定性，将答案标记（针对每个 CoT 子任务）写入最后的残差流。 这些并行答案生成路径收集来自不同部分的答案输入的。我们发现，在生成 CoT 时，模型从生成的上下文、问题上下文以及少样本上下文中收集答案标记。这为法学硕士在回答问题时是否真正使用通过 CoT 生成的上下文这一开放性问题提供了强有力的实证答案。 我们观察到法学硕士中间存在功能性裂痕。 （LLaMA-2 7B 情况下的第 16 个解码器块），它标志着残余流内容和注意力头功能的相移。在此裂痕之前，模型主要分配通过预训练记忆的二元关联；它完全开始遵循裂痕之前和之后的背景。这很可能与仅在裂痕之前发生的本体相关性的代币混合直接相关。同样，写答案的头也只有在裂痕之后才会出现。 （错误地）从少数样本中收集答案标记的注意力头也受到模型前半部分的限制。   代码： https://github.com/joykirat18/How-To-Think-Step-by-Step   由   提交 /u/Gaussian_Kernel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2tar4/r_how_to_think_stepbystep_a_mechanistic/</guid>
      <pubDate>Thu, 29 Feb 2024 06:07:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 语音转文本基准：在 RTX3070 Ti 上每 1 美元转录 47,638 分钟（比托管服务成本降低 1000 倍）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2m24h/p_speechtotext_benchmark_47638_mins_transcribed/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2m24h/p_speechtotext_benchmark_47638_mins_transcribed/</guid>
      <pubDate>Thu, 29 Feb 2024 00:09:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] SpeechBrain 工具包 1.0 版已发布！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b28j2o/r_the_speechbrain_toolkit_version_10_is_out/</link>
      <description><![CDATA[亲爱的 Reddit 社区， 三年前，我们在此 Reddit 子版块中宣布了 SpeechBrain 的测试版。今天，我们很高兴地宣布 SpeechBrain 1.0 正式发布。这一里程碑与之前的版本相比有许多增强和进步。 这是真正的社区努力（PyPi 每月 20 万次下载），我们非常高兴和自豪能够领导它。&lt; /strong&gt; 您可以在此处探索我们改进的全面摘要：SpeechBrain 1.0 摘要. 在这些变化中，我们在语音识别方面取得了重大改进，通过与 K2 集成有限状态传感器、CTC 解码、n- 增强了搜索功能。克重评分和法学硕士整合。此外，我们还引入了新型模型，例如 Streamable Conformer Transducers、Branchformers 和 Hyper-conformer 等，以提高性能和速度。您现在还可以轻松使用大语言模型 (LLM) 并使用我们的数据对其进行微调，或者简单地使用它们来重新评分 ASR 假设。 此外，SpeechBrain 现在支持更广泛的任务：&lt;语音、音频、文本和脑电图处理。我们改进了与 HF 模型的集成，使从 HF 导入任何模型变得更加容易。我们实施了现代技术和模型，包括持续学习、扩散模型、超网络、贝叶斯 ASR 等。 我们创建了一个新的基准存储库，其中包含用于自我监督学习 (MP3S) 的有用基准， EEG 处理 (SpeechBrain-MOABB) 和持续学习新语言 (CL-MASR)。 在提供的 Colab 上可以找到更多新奇事物。 敬请期待未来因为我们前面有宏伟的计划。 当然，非常感谢我们的慷慨赞助商 HuggingFace、OVHCloud 和 ViaDialog，以及我们在 Concordia、Avignon、Mila、剑桥大学和三星的合作伙伴，以及所有我们了不起的贡献者！  此致， SpeechBrain 核心团队   由   提交 /u/TParcollet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b28j2o/r_the_speechbrain_toolkit_version_10_is_out/</guid>
      <pubDate>Wed, 28 Feb 2024 15:20:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 生产级 RAG 应用程序真正包含什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b244vc/d_what_does_a_production_level_rag_application/</link>
      <description><![CDATA[我已经完成了 RAG 的研究，实现了一些简单的 RAG 教程，并且我知道我现在想要实现的高级 RAG 技术。但我真的不知道正确的应用程序工作流程是什么样的。就像在简单的 RAG 教程中实现这 7 行代码，然后添加混合搜索或重新排名等内容，以及实际构建生产级 RAG 应用程序之间有什么区别？这个“工作流程”是什么样的？    由   提交/u/Aggravating-Floor-38   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b244vc/d_what_does_a_production_level_rag_application/</guid>
      <pubDate>Wed, 28 Feb 2024 11:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 1 位 LLM 时代：所有大型语言模型均采用 1.58 位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b22izk/r_the_era_of_1bit_llms_all_large_language_models/</link>
      <description><![CDATA[https://arxiv.org/abs/2402.17764 摘要  最近的研究，例如 BitNet，正在为 1 位大型语言模型的新时代铺平道路（法学硕士）。在这项工作中，我们引入了一个 1 位 LLM 变体，即 BitNet b1.58，其中 LLM 的每个参数（或权重）都是三元的 {-1, 0, 1}。它在困惑度和最终任务性能方面与具有相同模型大小和训练令牌的全精度（即 FP16 或 BF16）Transformer LLM 相匹配，同时在延迟、内存、吞吐量、和能源消耗。更深刻的是，1.58 位法学硕士定义了新的扩展法则和配方，用于培训高性能且经济高效的新一代法学硕士。此外，它还实现了一种新的计算范例，并为设计针对 1 位 LLM 优化的特定硬件打开了大门。    由   提交/u/Civil_Collection7267   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b22izk/r_the_era_of_1bit_llms_all_large_language_models/</guid>
      <pubDate>Wed, 28 Feb 2024 10:03:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>