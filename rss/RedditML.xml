<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 15 Jan 2025 12:31:54 GMT</lastBuildDate>
    <item>
      <title>[D]尝试在我的系统上安装花卉库，但我一直遇到此错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1vheb/dtrying_to_install_flower_library_on_my_system/</link>
      <description><![CDATA[https://preview.redd.it/msjeigbm85de1.png?width=914&amp;format=png&amp;auto=webp&amp;s=a194813ea69769a5dc5dcde1d4e5953a552e7420 到目前为止，我已经尝试过：  升级 setuptools 安装了 visual studio 还创建了一个新的虚拟环境  但到目前为止什么都没起作用。请帮帮我！！    提交人    /u/69inchbatman   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1vheb/dtrying_to_install_flower_library_on_my_system/</guid>
      <pubDate>Wed, 15 Jan 2025 11:34:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 泰坦：在考试时学会记忆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1lg6o/r_titans_learning_to_memorize_at_test_time/</link>
      <description><![CDATA[摘要：“十多年来，人们进行了广泛的研究，以研究如何有效地利用循环模型和注意力机制。虽然循环模型旨在将数据压缩到固定大小的内存（称为隐藏状态），但注意力机制允许关注整个上下文窗口，捕获所有标记的直接依赖关系。然而，这种更准确的依赖关系建模需要二次成本，从而将模型限制在固定长度的上下文中。我们提出了一种新的神经长期记忆模块，该模块可以学习记忆历史背景，并帮助注意力机制在利用过去很久的信息的同时关注当前背景。我们表明，这种神经记忆具有快速并行训练的优势，同时保持快速推理。从记忆的角度来看，我们认为注意力机制由于其有限的上下文但准确的依赖关系建模而表现为短期记忆，而神经记忆由于其记忆数据的能力而表现为长期、更持久的记忆。基于这两个模块，我们引入了一个名为 Titans 的新架构系列，并提出了三种变体来解决如何有效地将内存整合到这个架构中。我们在语言建模、常识推理、基因组学和时间序列任务上的实验结果表明，Titans 比 Transformers 和最近的现代线性循环模型更有效。与基线相比，它们还可以有效地扩展到大于 2M 的上下文窗口大小，并且在大海捞针任务中具有更高的准确率。” Arxiv: https://arxiv.org/abs/2501.00663    提交人    /u/imadade   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1lg6o/r_titans_learning_to_memorize_at_test_time/</guid>
      <pubDate>Wed, 15 Jan 2025 00:51:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer²：自适应法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1l8d4/r_transformer²_selfadaptive_llms/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2501.06252 摘要 自适应大型语言模型 (LLM) 旨在解决传统微调方法带来的挑战，这些方法通常计算量大，处理各种任务的能力也比较静态。我们引入了 Transformer²，这是一种新颖的自适应框架，它通过选择性地调整权重矩阵的奇异分量，实时调整 LLM 以适应看不见的任务。在推理过程中，Transformer² 采用两遍机制：首先，调度系统识别任务属性，然后使用强化学习训练的任务特定“专家”向量进行动态混合，以获得针对传入提示的目标行为。我们的方法优于 LoRA 等普遍存在的方法，参数更少，效率更高。Transformer² 展示了跨不同 LLM 架构和模态的多功能性，包括视觉语言任务。Transformer² 代表了一次重大飞跃，为增强 LLM 的适应性和任务特定性能提供了可扩展、高效的解决方案，为真正动态、自组织的 AI 系统铺平了道路。 博客摘要：https://sakana.ai/transformer-squared/ GitHub：https://github.com/SakanaAI/self-adaptive-llms    提交人    /u/hardmaru   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1l8d4/r_transformer²_selfadaptive_llms/</guid>
      <pubDate>Wed, 15 Jan 2025 00:41:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们如何在 ArXiv 中搜索论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1hz8c/d_how_are_people_searching_for_papers_in_arxiv/</link>
      <description><![CDATA[您好， 我想知道人们在 ArXiv 中搜索或发现新论文的通常方式是什么？您只使用他们的搜索引擎吗？有什么提示/提示吗？    提交人    /u/TheDevilIsInDetails   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1hz8c/d_how_are_people_searching_for_papers_in_arxiv/</guid>
      <pubDate>Tue, 14 Jan 2025 22:11:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]你如何衡量你的 AI 管道的改进？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1gr9y/dhow_do_you_measure_improvements_of_your_ai/</link>
      <description><![CDATA[在为嵌入或推理工作流程添加改进方面，我非常有创造力，但在衡量这些改进是否真的使最终结果更适合我的用例时，我遇到了问题。这总是归结为直觉。 你们都如何衡量...... ..这个新的嵌入模型是否比以前的更好？ ..这个语义分块器是否比基于拆分的分块器更好？ ..短块是否比较长块更好？ ..这个新的重新排序器是否真的有所不同？ ..这个新的代理评估器工作流程是否创造了更好的结果？ 有没有科学的方法来衡量这一点？    提交人    /u/EnvironmentalPost830   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1gr9y/dhow_do_you_measure_improvements_of_your_ai/</guid>
      <pubDate>Tue, 14 Jan 2025 21:19:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 证明我错了……</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1fwsg/d_prove_me_wrong/</link>
      <description><![CDATA[我建立了一个 LGBM 模型来对帕金森病患者进行分类，使用了一个包含 2,562 名患者的数据集，通过 P 值和相关性分析以及我自己的领域知识选择了 37 个特征，问题可以是二进制、连续或序数的，例如他们是否有泌尿问题，是/否 = 0/1，所有问题都是数字答案。数据集分为 70% 训练（1,793 个样本）、15% 验证（384 个样本）和 15% 保留测试（385 个样本）。我对训练集进行了 5 倍分层交叉验证，每倍大约有 1,434 个样本用于训练，359 个样本用于验证。数据集包含 1085 名 PD 患者和 1477 名非 PD 患者。我认为性能确实很好，我想知道是否有人有其他测试或方法来评估这是否是一个大幻想，或者我手上有一个好的模型？ .=== 交叉验证指标 === 平均 F1 分数：0.8860 ± 0.0210 平均 AUC：0.9565 ± 0.0095 平均召回率：0.8814 ± 0.0239 平均精度：0.8911 ± 0.0251  === 保留集指标 === F1 分数：0.8875 AUC：0.9505 召回率：0.8957 精度： 0.8795    由   提交  /u/Disastrous_Ad9821   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1fwsg/d_prove_me_wrong/</guid>
      <pubDate>Tue, 14 Jan 2025 20:40:21 GMT</pubDate>
    </item>
    <item>
      <title>情绪分类和分析的预训练模型 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1act4/pretrained_models_for_sentiment_classification/</link>
      <description><![CDATA[嗨。我正在做一个项目，需要我从英文文本中识别情绪，然后将这些情绪量化为百分比。我需要在文本上运行六个模型，然后比较分类。 到目前为止，我已经探索了 Huggingface 中的一些基于 BERT 和 RoBERTa 的模型，这些模型使用 Google 提供的 GoEmotion 数据集进行训练。我很好奇，有没有更好的模型是我遗漏的？请留下一些可以给出一些良好结果的预训练模型的名称。 TIA！    提交人    /u/Big_Baguette17   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1act4/pretrained_models_for_sentiment_classification/</guid>
      <pubDate>Tue, 14 Jan 2025 16:46:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 预测信用卡用户违约的概率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i1aarq/d_predicting_the_probability_of_default_for_a/</link>
      <description><![CDATA[我有一个不平衡的数据集，大约有 100,000 行，其中 1500 行是默认值，有 1000 多个特征，并且有很多缺失值。此外，特征的名称是匿名的（例如 bureau_1、bureau_2），因此看起来也很困难，这些特征与目标变量的最大相关性为 0.1 我想根据数据预测客户可能违约的概率，但在召回率（0.25）、f1 和 auprc 等指标方面没有取得太大进展。 我尝试过各种基于树的模型，如 lgbm、xgboost 等，它们具有各种类平衡属性，但效果并不好。 如果你们中有任何人有处理此类数据集的经验，能否建议我在特征工程、建模等方面应该怎么做。你们所有的帮助对我来说意义重大。    提交人    /u/Chuggleme   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i1aarq/d_predicting_the_probability_of_default_for_a/</guid>
      <pubDate>Tue, 14 Jan 2025 16:44:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 非人体动作识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i194ja/d_nonperson_action_recognition/</link>
      <description><![CDATA[我正在努力让物体跟踪在体育比赛中发挥作用，并希望采取下一步行动，能够检测到何时发生了某个动作（例如足球出界、保龄球击中球瓶或球被抛出（而不是练习投掷或假动作）。我一直在通过手工编码启发式方法来检测这些动作，但我希望更加灵活。所有用于动作识别的库似乎都是关于人体骨骼动作的。这让我认为我在看错误的问题空间。是否有现有的技术可以随着时间的推移获取物体的位置并根据训练数据学习动作何时发生？    提交人    /u/needaname1234   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i194ja/d_nonperson_action_recognition/</guid>
      <pubDate>Tue, 14 Jan 2025 15:53:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师与人工智能研究科学家：未来前景？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i18421/d_machine_learning_engineer_vs_ai_research/</link>
      <description><![CDATA[有人说，人工智能研究科学家（博士学位持有者）几乎是不可替代的，因为他们能够突破知识的界限，提出突破性的方法和算法。但让我们面对现实吧——科技公司不需要大量的研究人员，尤其是如果他们的工作不能直接提高利润的话。 另一方面，机器学习工程师是那些将这些算法付诸实践、扩展系统和保持生产管道运行的人——所有这些都直接带来了 $$$。这就是为什么有些人认为未来 MLE 角色的增长速度会比人工智能研究科学家角色更快。 你怎么看？你是否看到过哪些趋势或经验表明其中一个角色在未来会更受欢迎？顺便说一下，我目前是一名博士生。 为了公平比较，我们假设这两个角色都在 FAANG 公司。   由    /u/wonder-why-I-wonder  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i18421/d_machine_learning_engineer_vs_ai_research/</guid>
      <pubDate>Tue, 14 Jan 2025 15:08:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 相关聚类？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i13aot/d_correlation_clustering/</link>
      <description><![CDATA[我想在相似性矩阵上应用聚类算法。这可能吗？如果可以，怎么做？    提交人    /u/fordperfect14   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i13aot/d_correlation_clustering/</guid>
      <pubDate>Tue, 14 Jan 2025 10:37:34 GMT</pubDate>
    </item>
    <item>
      <title>LLM 分布式训练 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i0vrg3/llm_distributed_training_r/</link>
      <description><![CDATA[在训练期间访问数据集的方法有哪些？它们是在开始训练过程之前下载到机器/pod 上，还是通过网络安装的？ 同样，对于大型模型，如何部署模型进行推理？（用于自动缩放或更新模型版本）    提交人    /u/badseed79   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i0vrg3/llm_distributed_training_r/</guid>
      <pubDate>Tue, 14 Jan 2025 02:29:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] 余弦相似度并非我们所认为的灵丹妙药</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i0hfsd/r_cosine_similarity_isnt_the_silver_bullet_we/</link>
      <description><![CDATA[Netflix 和康奈尔大学的研究人员揭露了余弦相似度的重大缺陷。他们的研究表明，线性矩阵分解模型中的正则化引入了任意缩放，导致不可靠或毫无意义的余弦相似度结果。这些问题源于嵌入重新缩放的灵活性，影响推荐系统等下游任务。该研究强调了对替代方案的需求，例如欧几里得距离、点积或规范化技术，并建议针对特定任务进行评估以确保稳健性。 阅读“嵌入的余弦相似度真的与相似度有关吗？”的完整论文评论。这里：https://www.shaped.ai/blog/cosine-similarity-not-the-silver-bullet-we-thought-it-was    由   提交  /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i0hfsd/r_cosine_similarity_isnt_the_silver_bullet_we/</guid>
      <pubDate>Mon, 13 Jan 2025 16:11:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 12 Jan 2025 16:00:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>