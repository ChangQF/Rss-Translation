<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 09 Sep 2024 12:31:34 GMT</lastBuildDate>
    <item>
      <title>[D] 大规模 TTS - 批量推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcloqk/d_tts_at_scale_batch_inference/</link>
      <description><![CDATA[在寻找一些高质量且可扩展的文本转语音解决方案时，我注意到大多数开源解决方案都不支持批量推理 - 它们都适用于单个文本样本。我想同时处理大量请求，因此我相信拥有强大的大型 GPU 并在一个批次中推理多个样本（短句）应该可以大大提高性能。知道它不受支持的原因是什么吗？TTS 架构是否不是这样有效/易于并行化的，可能是由于某些组件？或者由于输出波形的长度不同，该过程可能难以执行？或者您知道一些值得推荐的解决方案？    提交人    /u/ActualDoughnut8687   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcloqk/d_tts_at_scale_batch_inference/</guid>
      <pubDate>Mon, 09 Sep 2024 09:56:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 任何过去/现在的 Amazon ML 竞赛参与者能否提供有关其评估和提交内容的见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcjfkj/d_can_any_amazon_ml_competition_pastpresent/</link>
      <description><![CDATA[嗨，需要你的帮助，任何过去/现在的参与者都可以提供有关挑战、提交窗口、评估的更多信息    提交人    /u/Ticket-Financial   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcjfkj/d_can_any_amazon_ml_competition_pastpresent/</guid>
      <pubDate>Mon, 09 Sep 2024 07:02:35 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] Ted Chiang 对 AI 艺术的看法正确吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcfr0m/discussion_is_ted_chiang_right_about_ai_art/</link>
      <description><![CDATA[特德·姜 (Ted Chiang) 最近在《纽约客》上发表的文章《为什么人工智能不会创造艺术》引起了轰动。虽然特德·姜提出了一些有趣的观点，但我还是觉得有必要在我的 Medium 文章中提供不同的观点：https://medium.com/p/2022036fdce8。以下是我文章中的几个关键摘录：  “特德·姜认为，艺术创作需要做出许多决定，每个单词的选择都代表着一个独特的决定。然而，这种观点可能过于简化了创作过程。” “重要的是要认识到，人工智能模型，尤其是大型语言模型 (LLM)，做出的决定远不止一次选择一个单词。这些模型的内部过程涉及多层神经网络，每层都会做出许多有助于最终输出的微决策。”  您对蒋的文章和我的回应有何看法？人工智能在艺术创作中的作用是否比蒋所说的更微妙？    提交人    /u/Chaos_fractal_2224   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcfr0m/discussion_is_ted_chiang_right_about_ai_art/</guid>
      <pubDate>Mon, 09 Sep 2024 03:07:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 也许我们可以用每个权重 0.05 位来训练更大的模型，或者在消费级硬件上训练适度的模型……</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcedvx/d_maybe_we_can_train_bigger_models_with_005_bits/</link>
      <description><![CDATA[      https://preview.redd.it/xjc9zhq1xond1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=9dad2f1da27a465a33ba5decdf6a31e36c93a5bc 使用顶部的基本前馈神经网络对 MNIST 进行分类，然后用等级 4 的 DoRa 和 LoRa 表示相同的东西，最后是等级 16 的 bitnet/dora 混合，每个参数 1 位。降至每个权重约 0.05 位。所有权重都具有相同的有效权重数，但可训练参数减少。对于全权重训练，DoRa 似乎在 12 个 epoch 之后就不再比 LoRa 有优势了。 我将探索在增加参数数量以匹配正常模型的内存占用时是否可以获得相同或更好的性能。同时将 LoRa 和 DoRa 相加以动态提高排名并防止早期停滞。我的目标是最终在消费级硬件上训练一个有用的 LLM。如果我能做到这一点，想象一下有人可以在一家大公司用一些 A100 做什么。很快就会发布代码，这是早期的和不完整的。无论如何，我可能只是在做梦。晚安。    提交人    /u/Trainraider   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcedvx/d_maybe_we_can_train_bigger_models_with_005_bits/</guid>
      <pubDate>Mon, 09 Sep 2024 01:57:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 渐进式策略和过早的残局</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcapxf/d_incremental_gambits_and_premature_endgames/</link>
      <description><![CDATA[        由   提交  /u/Mooseton   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcapxf/d_incremental_gambits_and_premature_endgames/</guid>
      <pubDate>Sun, 08 Sep 2024 22:55:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 TsetlinMachine 库 Tsetlin.jl 中的最新优化，在 CPU 上实现每秒超过 1 亿个 MNIST 预测（吞吐量为 55.5 GB/s）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fc3ji0/p_achieved_over_100_million_mnist_predictions_per/</link>
      <description><![CDATA[      这个周末，我优化了 TsetlinMachine 库 Tsetlin.jl，取得了出色的成绩：在我的 Ryzen 7950X3D CPU 上每秒可进行 1.01 亿次 MNIST 预测，准确率为 98.10%。这个性能已经接近硬件的最大能力，因为双通道模式下 DDR5 RAM 在 6000 MT/s 下的峰值速度为 96 GB/s。我的吞吐量达到了 55.5 GB/s，主要是因为这个特定的 Tsetlin Machine 模型有 10499 个参数，而 CPU 缓存（尤其是 3D 缓存）在提升性能方面起着重要作用。 https://preview.redd.it/0a719tythmnd1.png?width=1780&amp;format=png&amp;auto=webp&amp;s=001526f65f3be2b99ce2a24ffe4b5bb5486f474e    由    /u/ArtemHnilov  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fc3ji0/p_achieved_over_100_million_mnist_predictions_per/</guid>
      <pubDate>Sun, 08 Sep 2024 17:42:23 GMT</pubDate>
    </item>
    <item>
      <title>聚类算法比较[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fc0niz/clustering_algorithms_comparison_d/</link>
      <description><![CDATA[我想看看是否有论文或文章对不同的聚类算法在优点、缺点和特殊性方面进行比较，我自己还没有找到任何像样的东西    提交人    /u/Extension-Group2131   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fc0niz/clustering_algorithms_comparison_d/</guid>
      <pubDate>Sun, 08 Sep 2024 15:38:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 08 Sep 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[P]: TensorHue – 张量可视化库（详情见评论）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbz318/p_tensorhue_a_tensor_visualization_library_info/</link>
      <description><![CDATA[        提交人    /u/epistoteles   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbz318/p_tensorhue_a_tensor_visualization_library_info/</guid>
      <pubDate>Sun, 08 Sep 2024 14:29:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过 LLM 实现隐写术的 Python 工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbx3ny/p_python_tool_for_steganography_through_llms/</link>
      <description><![CDATA[https://github.com/user1342/Tomato    由   提交  /u/OppositeMonday   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbx3ny/p_python_tool_for_steganography_through_llms/</guid>
      <pubDate>Sun, 08 Sep 2024 12:54:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 训练具有多种损失的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbvuhs/r_training_models_with_multiple_losses/</link>
      <description><![CDATA[我们建议使用 雅可比下降 来同时最小化多个损失，而不是使用梯度下降来最小化单个损失。基本上，该算法通过将（向量值）目标函数的雅可比矩阵简化为更新向量来更新模型的参数。 为了让每个人都能使用它，我们开发了 TorchJD：一个扩展 autograd 以支持雅可比下降的库。在简单的 pip install torchjd 之后，转换基于 PyTorch 的训练函数非常容易。随着最近发布的 v0.2.0，TorchJD 终于支持多任务学习了！ Github：https://github.com/TorchJD/torchjd 文档：https://torchjd.org 论文：https://arxiv.org/pdf/2406.16232 我们很乐意听到社区的一些反馈。如果您想支持我们，请在 repo 上点个星，我们将不胜感激！我们也欢迎讨论和批评。    提交人    /u/Skeylos2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbvuhs/r_training_models_with_multiple_losses/</guid>
      <pubDate>Sun, 08 Sep 2024 11:43:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医疗 AI：顶级研究论文/模型🏅（2024 年 9 月 1 日至 9 月 7 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbe5qg/d_last_week_in_medical_ai_top_research/</link>
      <description><![CDATA[   本周热门论文（2024 年 9 月 1 日至 9 月 7 日） 医学 LLM 及其他模型：  CancerLLM：癌症领域的大型语言模型  CancerLLM，一个为癌症特定任务设计的 70 亿参数模型。对 17 种癌症类型的 267 万份临床记录和 515,524 份病理报告进行了预训练。  MedUnA：用于医学图像的视觉语言模型  本文介绍了医学无监督适应（MedUnA）。它使用 BioBERT 将文本嵌入与类标签对齐，然后与 MedCLIP 的视觉编码器集成，通过对比熵损失实现视觉文本对齐。  机器人内窥镜手术的基础模型  本文介绍了机器人内窥镜手术中的深度一切 (DARES)，它引入了 Vector-LoRA，一种用于机器人辅助手术 (RAS) 中自监督单目深度估计的新型自适应技术。  Med-MoE：用于医学视觉语言模型的 MoE  本文介绍了 Med-MoE（Mixture-of-Experts），这是一个专为判别和生成多模态医疗任务而设计的轻量级框架。 Med-MoE 分三个阶段运作：  CanvOI：肿瘤学基础模型  本文介绍了 CanvOI，一种基于 ViT-g/10 的数字病理学基础模型，针对肿瘤组织病理学图像进行了优化。   医疗基准和评估：  TrialBench：临床试验数据集和基准  用于医学问答评估的 LLM  MedFuzz：探索稳健性医学 LLM  MedS-Bench：评估临床任务中的 LLM  DiversityMedQA：评估诊断中的 LLM 偏见  LLM 数字孪生：  用于罕见妇科肿瘤的数字孪生 DT-GPT：用于患者健康预测的数字孪生  ....  详细查看完整线程：https://x.com/OpenlifesciAI/status/1832476252260712788 感谢您的阅读！如果您知道任何遗漏的有趣论文，请随时在评论中分享。如果您对医疗 AI 有见解或突破，并希望在下周的版本中分享，请通过 Twt/x 与我们联系：OpenlifesciAI    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbe5qg/d_last_week_in_medical_ai_top_research/</guid>
      <pubDate>Sat, 07 Sep 2024 18:49:25 GMT</pubDate>
    </item>
    <item>
      <title>我尝试编写自己的 YOLO 模型来检测足球运动员 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbc185/i_tried_to_code_my_own_yolo_model_to_detect/</link>
      <description><![CDATA[       由    /u/AvvYaa  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbc185/i_tried_to_code_my_own_yolo_model_to_detect/</guid>
      <pubDate>Sat, 07 Sep 2024 17:15:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] Adam 优化器导致 Transformer 语言模型中出现特权基础</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbavdv/r_adam_optimizer_causes_privileged_basis_in/</link>
      <description><![CDATA[        由    /u/rrenaud  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbavdv/r_adam_optimizer_causes_privileged_basis_in/</guid>
      <pubDate>Sat, 07 Sep 2024 16:26:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>