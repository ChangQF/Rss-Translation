<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Wed, 26 Feb 2025 15:19:06 GMT</lastBuildDate>
    <item>
      <title>[r]乔什：自我改进的LLM用于工具使用而无需人为反馈</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iyoxna/r_josh_selfimproving_llms_for_tool_use_without/</link>
      <description><![CDATA[       &lt;！ -  sc_off- sc_off-&gt;  我们的团队最近发表了一篇论文，介绍了Josh（并置了模拟收获的结果），这是一种自我对准算法，使LLM可以自主提高其工具的功能，而没有人类的功能反馈，包括在τ板上。我们还介绍了一个代理工具调用数据集工具，该工具始于Multiwoz。     Josh的作用：  将工具调用用作模拟环境中的稀疏奖励来提取理想的对话togrooge  通过梁搜索探索训练自己的输出模型（让人联想到当前使用的测试时间缩放方法） 显着改善了跨模型尺寸的基于工具的交互（来自较小的型号诸如GPT-4O之类的边境模型）  关键结果：  在我们的工具WOZ基准上，llama3-8b的成功率提高了74％ li&gt; 当应用于GPT-4O  时，请在MT板凳和LMSYS上保持一般模型功能时，在τbench上进行最先进的性能在工具中使用  为什么这很重要： 今天的拟人公告显示了τbench上的改进，值得注意的是，如何已经应用了我们的方法来提高其功能呢乔什（Josh）提供了一种跨模型大小的一般方法，不需要人类的反馈 - 随着模型继续改进的可能性。 我们已经制定了代码，并且公开可用的工具工具数据集：&lt; a href =“ https://github.com/asappresearch/josh-llm-simulation-training”&gt; github repo    paper：稀疏的奖励可以自我培训对话代理  好奇地听到社区的想法！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bmlattimer     [link]   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iyoxna/r_josh_selfimproving_llms_for_tool_use_without/</guid>
      <pubDate>Wed, 26 Feb 2025 14:36:54 GMT</pubDate>
    </item>
    <item>
      <title>[r]固定态序列模型 - 事实证明，您不必训练嵌入或状态过渡功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iyodrr/r_fixedstate_sequence_model_turns_out_you_dont/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请看一下此笔记本 fixedstatesequencemodel.ipynb   密钥功能  1。冷冻嵌入  使用固定随机代码书作为令牌嵌入。 在嵌入空间中没有学习。   2。固定状态过渡函数  使用固定随机过渡权重进行状态过渡。 使用 Sinusoidal Transformations计算状态更新（在矩阵-State Evolution完全固定。   3。序列处理的基于傅立叶的卷积  使用快速傅立叶变换（FFT）有效地传播状态。 避免使用传统的基于复发的反向传播。    4。文本生成的单个MLP   模型的整个可学习部分由一个MLP （ W1 ， w2 ，&lt;代码&gt; W3 ）。   5。高效且轻巧的设计  无需训练嵌入或过渡→更少的参数才能优化。 基于FFT的计算使其 strong&gt;长序列的有效（Althoug自定义前缀扫描可能更快）    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/kiockete     [links]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iyodrr/1iyodrr/r_fixedstate_sequence_model_model_turns_out_out_you_dont/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iyodrr/r_fixedstate_sequence_model_turns_out_you_dont/</guid>
      <pubDate>Wed, 26 Feb 2025 14:11:10 GMT</pubDate>
    </item>
    <item>
      <title>[P]帮助优化观看品牌识别模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iylv5i/phelp_optimizing_watch_brand_identification_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想创建一个手表品牌标识符，该标识符获得图像并返回，如果它是4个品牌之一或其他品牌之一。我拥有的是4个品牌中每个品牌的3126张图像和其他品牌的8000张手表图像（如果来自Chrono中每个品牌的图像，则具有均匀的拆分）。即时通讯将CNN与VGG19用作基本型号，并在其中添加了一些图层。问题在于，我训练的模型具有78％的准确性，并预测了很多四个品牌之一的手表来自其他品牌。  我真正关心的是，如果手表来自ir品牌，而不是它是哪个品牌，我该怎么做才能改善这一点？我以为可能更改为仅仅是4个之一的二进制文件，但我不确定...这是代码 link    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/yalli12     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iylv5i/phelp_optimizing_watch_brand_identification_model/</guid>
      <pubDate>Wed, 26 Feb 2025 11:58:09 GMT</pubDate>
    </item>
    <item>
      <title>机器学习可以真正“概括”，或者我们只是在合成专业方面变得更好吗？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iykqh1/can_machine_learning_truly_generalizeor_are_we/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们谈论ML中的概括，就好像是最终目标一样，模型学习模式会传输跨域。但是“真正的概括”是实际发生的吗，还是我们只是完善特定于任务的外推？ 在大量，多样的数据上训练的模型不一定会概括 - 它只是在预先定义的约束中的模式综合越来越好。即使是似乎可以很好地“概括”的变压器，仍然受训练数据的基本结构的约束。 因此，ML的真正前沿是实现真实概括的真正前沿，或者接受智能是本质上与上下文有关的？如果是这样，ML的未来是关于打破过去数据集限制的未来，还是简单地优化合成智能以提高专业化？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iykqh1/can_machine_learning_truly_generalizeor_are_are_we/”&gt; [link]    [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iykqh1/can_machine_learning_truly_generalizeor_are_we/</guid>
      <pubDate>Wed, 26 Feb 2025 10:43:23 GMT</pubDate>
    </item>
    <item>
      <title>[D]您是否经常需要LLM（例如GPT-4）的结构化输出？如果是这样，您认为哪种用例最高？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iykcdi/d_do_you_frequently_need_structured_output_from/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在受约束的解码中给予了很多关注（例如，在claude/gemini/gpt-4中的轮廓＆amp; xgrammar/json模式），我想知道此功能最需要的是哪种用例（例如，行业 /业务中的现实世界中用例）？学术界研究仍然围绕“ ner and the Likes”，我相信大多数人不在乎（坦率地说）。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/marionberry6884     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iykcdi/d_do_do_do_you_frequally_need_need_need_need_need_otput_output_from//]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iykcdi/d_do_you_frequently_need_structured_output_from/</guid>
      <pubDate>Wed, 26 Feb 2025 10:15:52 GMT</pubDate>
    </item>
    <item>
      <title>[r]使用彩色检查器介绍的基于扩散的颜色恒定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iyjzpd/r_diffusionbased_color_constancy_using_color/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文使用扩散模型介绍了一种生成的颜色恒定方法。他们没有直接预测照明，而是建议将颜色检查器集成到场景中，并使用扩散模型生成具有校正颜色的图像。 关键技术点： *使用稳定的扩散将Macbeth颜色检查器注入场景中*两个阶段的过程：首先生成彩色检查器放置，然后将其用作参考 *组合感知，上下文和颜色精度术语的新颖损失函数 *介绍＆quot“ gcc-wild”具有3,700个现实世界图像和地面真相的数据集 结果： *与SOTA相比，对标准指标的传统和基于学习的方法 *降低了8-15％ *，在挑战照明条件下特别有效*在校正颜色 时保持图像质量 我认为这是一个有趣的方法转变 - 而不是试图直接估计照明，而是基本上创建了一个参考点，使问题更多可处理。使用生成模型进行颜色校正可以打开图像编辑和增强的新可能性。 我对如何将其应用于视频或实时应用程序感到特别感兴趣。虽然当前的实现可能不足以实时使用，但使用生成的参考点的概念对于其他计算机视觉任务很有价值。  tldr：新方法使用扩散模型添加颜色检查器场景的卡，通过使用这些作为参考点来实现SOTA颜色恒定结果。  完整摘要在这里。 Paper 在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iyjzpd/r_diffusionbased_color_constancy_using_color/</guid>
      <pubDate>Wed, 26 Feb 2025 09:50:11 GMT</pubDate>
    </item>
    <item>
      <title>[r] FFT反击：自我注意的有效替代品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iycjkd/r_the_fft_strikes_back_an_efficient_alternative/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  传统的自我注意力以野蛮的o（n²）方式计算成对相互作用，将每个令牌与其他所有标记进行比较。对于长序列而​​言，这种方法效率低下。相反，快速傅立叶变换（FFT）将序列转换为频域。在这里，每个令牌由一组由单一矩阵定义的正交频率组件表示。该表示可以保留通过Parseval定理确保信号的能量，并在O（n log n）复杂性下更快地计算。通过利用经典信号处理原理，FFT提供了一种数学上优雅且可扩展的方式来捕获全球依赖性，这使其成为建模远程互动的有吸引力的替代方法。  i Revisit fnet，最初引入了一篇论文静态非线性FFT方法。不幸的是，FNET的表述不仅写得不好，而且缺乏实用应用所需的可扩展性，并且在任何基准测试方面都没有表现出色。相反，我已经完善并优化了该方法，增强了其清晰度，适应性，有效性和非线性。我的方法还胜过许多基准上的经典自我注意力，因为它在频域中（自适应）在频域中运行，利用FFT的有效O（n log n）计算以更有效地捕获长期依赖性。这种改进的方法为传统的自我注意力提供了一种可靠，可扩展的替代方法，使其成为捕获全球依赖性的引人注目的替代者。 代码在本文中，但您也可以在这里找到它： https://github.com/jacobfa/fft     https://arxiv.org/abs/2502.18394       &lt;！ - &gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iycjkd/r_the_fft_fft_fft_backs_back_and_and_effficity_alternative/”&gt; [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iycjkd/r_the_fft_strikes_back_an_efficient_alternative/</guid>
      <pubDate>Wed, 26 Feb 2025 02:07:50 GMT</pubDate>
    </item>
    <item>
      <title>[r]预测稀有语言模型行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iya3f7/r_forecasting_rare_language_model_behaviors/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    人类团队找到了一种方法来预测稀有的AI风险，然后使用幂律级缩放。这有助于尽早发现有害的响应或未对齐的行为，使其在实时之前更安全。  摘要：    标准语言模型评估可能无法捕获仅在部署量表上出现的风险。例如，模型可以在小规模的Beta测试期间产生安全的响应，但在部署时处理数十亿个请求时会透露危险的信息。为了解决这一问题，我们引入了一种方法，以预测跨数量级的潜在风险比我们在评估过程中测试的更多查询。我们通过研究每个查询的启发概率（查询产生目标行为的概率）来进行预测，并证明最大观察到的启发概率可以随着查询数量而扩展。我们发现，我们的预测可以预测各种不良行为的出现，例如协助用户进行危险的化学综合或采取寻求权力的动作 - 最多三个数量级的查询量。我们的工作使模型开发人员能够在大规模部署期间显现出现罕见的失败。   链接到论文： https://arxiv.org/abs/2502.16797  /p&gt;  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/seraschka     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iya3f7/r_forecasting_rare_language_model_behaviors/</guid>
      <pubDate>Wed, 26 Feb 2025 00:09:31 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]与F1得分挣扎并在不平衡的二元分类模型（染色质访问性）中进行回忆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iy15ry/discussion_struggling_with_f1score_and_recall_in/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iy15ry/discussion_struggling_with_f1score_and_recall_in/</guid>
      <pubDate>Tue, 25 Feb 2025 17:54:39 GMT</pubDate>
    </item>
    <item>
      <title>[P]训练一点（39m）语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iy0rra/p_train_a_little39m_language_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我今年开始越来越多地进入LLM，寻找资源一直很容易模型架构不足以完全掌握这些模型的训练方式。  由于我在一个地方无法找到最近的架构实现的任何代码，所以我自己制作了。 我的目标是帮助任何具有基本理解的人变压器体系结构，但想通过最近的建筑变化从头开始训练自己的模型。 （我在此过程中包括资源 +我自己的笔记） 所以我的努力​​是训练小语言模型的努力，即从头开始的39m参数模型，可以很好地交谈。 它在2XA100上进行了训练。 〜8b令牌上的2.5小时。 我计划在此项目中包含所有内容!!!!  现在它包括一个基本的类似Llama的架构。   -  rmsnorm而不是layernorm    - 旋转位置嵌入而不是绝对位置嵌入   -  swiglu激活而不是relu    - 分组查询注意力而不是多头注意   -  kV缓存的实现  todo包含   - 使用dpo   fineTuning    - 添加混合物专家（MOE）体系结构   - 以及更多 如果有人愿意为这个项目做出贡献，那将是很棒的。 请找到该项目这里： https://github.com/cohlem/lillm/lillm    我将其发布在r/ localllama 也是一个很好的回应。在此处发布以最大程度的可见性。  谢谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Royalmaterial9614     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iy0rra/p_train_a_little39m_language_model/</guid>
      <pubDate>Tue, 25 Feb 2025 17:38:45 GMT</pubDate>
    </item>
    <item>
      <title>[r] MUON对于LLM培训是可扩展的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixzj26/r_muon_is_scalable_for_llm_training/</link>
      <description><![CDATA[        tl; dr ： muon 是一种优化algorithm ，替代Adamw。该报告表明，与Adamw相比，它节省了大约一半的拖鞋，用于在39b代币上受过训练的1.5B LLM。   paper  ： https://arxiv.org/pdf/2502.16982    摘要：   最近，基于矩阵正交化的MUON优化器在训练小型语言模型方面表现出很强的结果，但是对较大模型的可伸缩性具有没有被证明。我们确定了两种至关重要的技术来扩展MUON：（1）增加重量衰减，（2）仔细调整参数更新量表。这些技术使MUON可以在大规模培训的情况下开箱即用，而无需进行超参数调整。缩放定律实验表明，与ADAMW相比，MUON具有约2倍的计算效率，并通过计算最佳培训。基于这些改进，我们引入了Moonlight，这是一种3B /16B参数的混合物（MOE）模型，该模型接受了训练有素的模型5.7吨代币使用MUON。与先前的模型相比，我们的模型改善了当前的帕累托前沿，通过更少的训练拖曳来取得更好的性能。我们开源我们的分布式MUON实现，这是内存最佳和沟通效率的。我们还释放了经过预定的，指导和中间检查点，以支持未来的研究。   视觉摘要：      视觉亮点：           https://preview.itd.it/bxekx1ntcble1.png?width=1095＆amp; format = png＆amp; auto = webpp＆s = 508a10fdea89d17a49e619e619b53f88622222260ebd9393939393939384449e619e619e     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sustledwaterMelon     [link]       [注释]  /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixzj26/r_muon_is_scalable_for_llm_training/</guid>
      <pubDate>Tue, 25 Feb 2025 16:48:27 GMT</pubDate>
    </item>
    <item>
      <title>[R]分析2024年400多个ML比赛</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixrxoq/r_analysis_of_400_ml_competitions_in_2024/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我运行mlcontests.com，一个网站，列出了来自多个平台的ML竞赛-Kaggle，drivendata，aicrowd，aicrowd，zindi等…… 我刚刚花了几个月的时间查看我在去年的比赛中找到的所有信息以及赢得解决方案。  我发现了去年发生的400多场比赛，以及其中70个获胜解决方案的信息。  一些亮点：    kaggle仍然是总奖金最大的平台，并且比其他平台拥有更大的用户群 - 尽管有超过十几个值得跟踪的其他平台，并进行了定期有趣的比赛和有意义的奖金。  竞争的增加100万美元+奖品池（ARC奖励， 人工智能与往年相比。一位获胜者使用Rust，两名使用R.   卷积神经网继续在计算机视觉竞赛中表现出色，在竞争赢家中仍然比基于变形金刚的视觉模型更为普遍。    pytorch的使用量大于tensorflow ，大​​约是9：1。没有发现任何竞争者在JAX或其他图书馆中实施神经网。   使用Automl软件包有一些竞赛冠军，似乎越来越有用。不过，通才自主的大师级特工的任何主张似乎还为时过早。   在语言/文本/序列相关的竞争中，定量是有效利用有限资源的关键。通常是4-，5或8位。 Lora/Qlora也经常使用，尽管并非总是如此。   促进梯度的决策树继续赢得许多表格/时间序列的比赛。他们通常会喜欢深度学习模型。据我所知，获奖者在2024年没有使用表格/时间序列的预训练基础模型。   开始看到更多的数据范围的极点摄入量，有7个获奖者在2024年使用Porars（从2023年的3次提高），而使用PANDAS则使用Porars。所有使用Polars的人仍然在代码的某些部分中使用了大熊猫。  就硬件而言，竞争获奖者几乎完全使用了NVIDIA GPU来训练他们的模型。一些人仅在CPU上接受培训，或者通过Colab使用了TPU。没有AMD GPU。 NVIDIA A100是获奖者中最常用的GPU。 100万美元以上的奖金泳池比赛中有两个是由使用8xH100节点进行培训的团队赢得的。不过，还有许多其他GPU：T4/P100（通过Kaggle笔记本电脑）或RTX 3090/4090/3080/3060等消费者GPU。一些花费了数百美元在云上计算以训练他们的解决方案。  一种新兴模式：使用生成模型创建其他合成训练数据以增强提供的训练数据。   完整报告中有更多详细信息，您可以在此处阅读（无付费墙）： https://mlconts.com/state-com/state-of-machine-learning-learning-competition--competition--2024?ref= MLCR    处理IMG XMM4YWG9H9LE1 ...   完整报告还具有：  深入了解ARC奖和AI数学奥林匹克运动会 赢得NLP/序列竞赛解决方案的概述 赢得解决方案中使用的Python软件包的细分（例如，各种相对普及梯度增强的树库）  如果您想支持这项研究，我将非常感谢您与其他可能会发现它有趣的人分享。您还可以查看我新发射的在线杂志， jolt Ml   - 在顶级ML会议和长阅读文章中提供新闻（到目前为止，还有更多！）。  感谢竞争获奖者分享了有关其解决方案的信息，也感谢竞争平台分享了有关比赛的高级数据。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/hcarlens   href =“ https://www.reddit.com/r/machinelearning/comments/1ixrxoq/r_analsisy_of_400_ml_ml_competitions_in_2024/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixrxoq/r_analysis_of_400_ml_competitions_in_2024/</guid>
      <pubDate>Tue, 25 Feb 2025 10:28:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] CVPR 2025结束决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ixpu28/d_cvpr_2025_final_decision/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  亲爱的社区成员， 标题所建议的，此线程适用于所有等待CVPR的25个结果的人。我敢肯定，你们现在都感觉到肚子里的蝴蝶。因此，让我们在整个过程中互相支持并讨论结果。现在不到24小时，我期待在此线程中进行令人兴奋的互动。  P.S。我的评分为4,3,3，平均信心为3.67。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/stantheta   href =“ https://www.reddit.com/r/machinelearning/comments/1ixpu28/d_cvpr_2025_final_decision/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ixpu28/d_cvpr_2025_final_decision/</guid>
      <pubDate>Tue, 25 Feb 2025 07:57:20 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iwdbgs/d_simple_questions_thread/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 23 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      对于那些寻找工作的人请使用此模板  &lt; p&gt;想要被录用：[位置]，薪水期望：[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简短概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，这个社区是适合有经验的人。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>