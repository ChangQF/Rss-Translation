<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 07 Apr 2024 15:13:19 GMT</lastBuildDate>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] GCN 法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by250w/d_r_llm_with_gcn/</link>
      <description><![CDATA[您好，我正在研究生成对话响应。我的想法是，我将使用 GCN 标记对话的上下文（即过去话语的串联），然后使用基于 Transformers 的模型根据上下文 + 标签生成响应（假设在本例中我将使用 Blenderbot） ）。问题是：  是否最好先单独训练 GCN 模型，然后使用最佳检查点来预测标签并将该标签作为 Blenderbot 输入的一部分？ 我可以与 Blenderbot 联合训练 GCN 吗？首先，我将输入输入到 Blenderbot 的编码器中，然后使用该编码器的输出输入到未经预训练的 GCN 模型中以获得预测，之后我将把编码器的输出 + GCN 的预测输入到解码器中以生成响应，然后最终以某种方式将 GCN 和 Blenderbot 一起训练。如果答案是肯定的，我想知道这在技术上是如何完成的（是否需要向编码器添加 adj_matrix 参数，GCN 将如何训练等等......）  如果您对第二个问题有任何其他方法，我很乐意听到，并且也将非常感谢有关类似问题的已发表论文的链接，谢谢：&gt;&gt;。   由   提交/u/n804s  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by250w/d_r_llm_with_gcn/</guid>
      <pubDate>Sun, 07 Apr 2024 11:21:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 克劳德与 GPT 特工比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by1e23/p_claude_vs_gpt_agent_comparison/</link>
      <description><![CDATA[Anthropics 最近宣布的 Claude 工具（函数调用）引起了我的注意，特别是这个声明：  所有模型可以处理从 250 多种工具中正确选择工具的问题，前提是用户查询包含目标工具的所有必要参数，且准确度 &gt;90%。这些限制适用于工具的总数，无论复杂程度如何。 “复合体”工具将是一个具有大量参数或具有复杂模式的参数（例如嵌套对象）的工具。  这对于每个使用代理系统的人来说都是非常令人兴奋的消息。 OpenAI 的召回率要低得多。 所以我想将 GPT 函数调用与用于代理任务的 Claude 工具进行比较。   Metric claude-3-opus-20240229 gpt-4-0125-preview claude-3-sonnet-20240229 gpt-3.5-turbo-0125     平均工具调用 16 13 11 td&gt; 9   平均准确度 100% 81.25% 87.5%&lt; /td&gt; 79.17%   平均成本 $0.807255 $0.153540 $0.119638 $0.119638 td&gt; $0.008145   https://github.com/kadoa-org/claude-gpt-agent-comparison   由   提交 /u/madredditscientist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by1e23/p_claude_vs_gpt_agent_comparison/</guid>
      <pubDate>Sun, 07 Apr 2024 10:34:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在LoftQConfig中使用nf4</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by0x49/d_how_to_use_nf4_in_the_loftqconfig/</link>
      <description><![CDATA[嘿， 我正在查看拥抱脸 LORA 文档。 他们建议不要在 AutoModelForCausalLM 中进行量化，而是使用 Loftq  from peft import LoftQConfig， LoraConfig, get_peft_model base_model = AutoModelForCausalLM.from_pretrained(...) # 此处不要量化 loftq_config = LoftQConfig(loftq_bits=4, ...) # 设置 4 位量化 lora_config = LoraConfig(..., init_lora_weights=“loftq”, loftq_config=loftq_config) peft_model = get_peft_model(base_model, lora_config)  现在我想知道我应该把所有的位和字节配置放在哪里，例如 load_in_4bit = True -&gt;好吧，这应该是不必要的 bnb_4bit_use_double_quant = False -&gt;如果我现在想使用它怎么办？ bnb_4bit_quant_type = “nf4” -&gt;如果我现在想使用它怎么办？ bnb_4bit_compute_dtype = torch.bfloat16 -&gt;;如果我现在想使用它怎么办？    由   提交/u/Brighton_Beach  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by0x49/d_how_to_use_nf4_in_the_loftqconfig/</guid>
      <pubDate>Sun, 07 Apr 2024 10:04:44 GMT</pubDate>
    </item>
    <item>
      <title>[R]什么是热力学计算以及它如何帮助人工智能开发？！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by0690/r_what_is_thermodynamic_computing_and_how_does_it/</link>
      <description><![CDATA[   /u/TheBojda80  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by0690/r_what_is_thermodynamic_computing_and_how_does_it/</guid>
      <pubDate>Sun, 07 Apr 2024 09:16:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 我创建了一本适合初学者的量子机器学习手册。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxzz1w/p_d_i_have_created_a_beginnerfriendly_quantum/</link>
      <description><![CDATA[大家好，在过去的几周里，我一直致力于为一个不了解任何量子概念并且想要的人创建正确的手持路线图深入研究量子机器学习。我希望获得您对内容的意见，如果您能为这个项目做出贡献，我将不胜感激。希望为每个人提供这本手册。 这里是 GitHub 存储库链接：https:// github.com/Winter-Soren/quantum-ml-handbook 这里是托管链接：https://quantummlhandbook。 vercel.app/   由   提交 /u/_-THUNDERBOLT-_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxzz1w/p_d_i_have_created_a_beginnerfriendly_quantum/</guid>
      <pubDate>Sun, 07 Apr 2024 09:04:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有办法在 Surprise SVD 模型上执行增量矩阵分解？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxz7jx/d_is_there_any_way_to_perform_incremental_matrix/</link>
      <description><![CDATA[我有一个预先训练的 SVD 模型，但是，当我获取用户的数据并希望将其添加到数据集中进行推荐时，我不这样做想要拟合整个模型，因为它计算复杂且耗时。我已经看到有一些执行增量矩阵分解的方法，它允许仅拟合新数据而不干扰预训练模型的学习。使用惊喜库可以使用此功能吗？    由   提交 /u/Benxsu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxz7jx/d_is_there_any_way_to_perform_incremental_matrix/</guid>
      <pubDate>Sun, 07 Apr 2024 08:12:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何处理没有发布代码的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxxk3l/d_what_do_you_do_with_paper_with_no_code_published/</link>
      <description><![CDATA[许多论文介绍了自己的模型，大部分是现有模型的变体，对原始模型的改动很小（主要针对特定​​问题）。他们中的大多数没有发布代码，这使得重现结果非常困难。在某些情况下（甚至可能是很多情况，我只找到/检查了一些）实验配置不完整，在论文中。  你如何处理这些论文？ 当人们引用这些论文时你如何争论？  &amp;# 32；由   提交 /u/Muhammad_Gulfam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxxk3l/d_what_do_you_do_with_paper_with_no_code_published/</guid>
      <pubDate>Sun, 07 Apr 2024 06:26:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您对基于树的模型的特征进行标准化的原因是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxq6c5/d_what_are_the_reasons_why_you_standardise/</link>
      <description><![CDATA[下面的说法正确吗？如果是，请您稍微解释一下。 逻辑回归和基于树的算法（例如决策树、随机森林和梯度提升）对变量的大小不敏感。因此，在拟合这些类型的模型之前不需要标准化。 在此链接中找到 - https://builtin.com/data-science/when-and-why-standardize-your-data 这与说异常值不一样吗基于影响树的算法？   由   提交 /u/SriRamaJayam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxq6c5/d_what_are_the_reasons_why_you_standardise/</guid>
      <pubDate>Sat, 06 Apr 2024 23:58:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 专家的无限混合 - 可能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxmyac/r_infinite_mixture_of_experts_possible/</link>
      <description><![CDATA[我一直在研究 MoE 模型以了解它们为何如此有效，并且想知道是否有方法可以有效地创建“无限”模型可以路由到任务所需的任意数量的参数的专家吗？例如，Mixtral MoE 使用 8 名专家，但架构可以扩展到更多：https://arxiv.org/abs/2401.04088  这个想法是有一些逻辑可以提前选择要相乘的权重，但我有一种感觉，选择权重所需的计算与实际计算中的权重相同或更多。第一名   由   提交/u/CriticalTemperature1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxmyac/r_infinite_mixture_of_experts_possible/</guid>
      <pubDate>Sat, 06 Apr 2024 21:35:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] 一个关于 RAG 最新研究的对话式搜索应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxmvn3/p_a_conversational_search_app_about_recent/</link>
      <description><![CDATA[检索增强生成 (RAG) 正在成为一个流行的研究领域。自 2024 年初以来，大约 150篇关于该主题的研究论文已在arxiv.org上发表。 人们阅读和停留相当困难每一篇新论文都会更新。为了解决这个问题，我创建了一个对话式搜索应用程序。该应用程序允许用户询问有关 RAG 的问题。它旨在让人们更容易地快速获得最新研究进展的更新和总结：https://cloud.epsilla.com/enterprise-search/df6624c1-1c2a-4263-8c10-14f495fc3e7f-340417431/73ee9739-e674-44cd-b 007- 3c46b5811c2b?src=reddit 尝试一下，通过竖起大拇指或竖起大拇指让我知道您对答案的看法。期待看到您提出的所有富有洞察力的问题。   由   提交/u/songrenchu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxmvn3/p_a_conversational_search_app_about_recent/</guid>
      <pubDate>Sat, 06 Apr 2024 21:32:48 GMT</pubDate>
    </item>
    <item>
      <title>有没有统计学家决定攻读计算机科学博士学位而不是统计学博士学位？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxi4l1/any_statisticians_who_decided_on_a_phd_in_cs/</link>
      <description><![CDATA[我目前是一名统计硕士学生。现在我对我一直在学习的标准经典统计学有点厌倦。我最初选择这条道路是因为我想为行业做好准备。我暑假有一个数据科学家实习机会，我考虑过全职工作。不过，工作几年后我确实想继续研究，所以我回到的问题是我想读统计学博士学位还是计算机科学博士学位。 坦白说，与大多数 CS 学生相比，我的编程能力非常低。我的本科专业是纯数学和统计学，虽然我学过 Python、R 和一些 Java，但我不能说我达到了软件工程师的水平。我很了解我的数学和统计理论，并且可以使用 Python 和 R 中的包来有效地完成任务，并编写函数等，但是如果你现在问我“用 Python 编写一个类”，我可能会被困住，因为我从来没有写类。  我不再对统计博士课程真正感兴趣，因为如果我要攻读统计博士学位，我必须在前两年完成课程作业，坦率地说，我只是厌倦了。我不想花时间证明 Logit 模型下 MLE 的渐近结果，也不想花一个学期学习线性模型理论之类的东西。 我现在拥有统计学硕士学位，我想我我已经把统计学打败得够多了。 我对深度学习领域非常感兴趣，这自然吸引了我从统计学家的角度出发，这就是时间序列预测的进步。  我在统计研究生课程中学习了时间序列，在那里我们学习所有经典方法：arima、sarima、garch 和一些非平稳时间序列模型，如状态空间模型。我也有经典非参数回归（统计学习）的背景，因为这是我论文的主题。 这些非常有趣，但我对计算机科学部门如何使用深度学习方法来提取数据感兴趣来自时间序列的信息。我这个老派的统计学家厌倦了学习“使用 ADF 检验来验证平稳性，拟合 arima 和 sarima 模型来对这个时间序列进行建模，并进行预测”，我现在看到来自计算机科学系的时间序列方面的巨大进步我想加入。此外，由于我在应用贝叶斯分析方面也有丰富的经验，我认为我在这方面的背景也可以是独特的补充。因果推理也是我涉足的领域，在深度学习的任何方面我也有兴趣提供我的意见。  那么，对于这里的任何人来说，是否有人像我一样，其背景来自于旧式学校统计，例如统计学硕士学位，现在转而攻读计算机科学博士学位，以研究更现代的主题？我觉得我在贝叶斯推理、时间序列、统计学习和因果推理等基础主题方面的背景可以为我在计算机科学的研究中添加一些东西。    由   提交/u/AdFew4357  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxi4l1/any_statisticians_who_decided_on_a_phd_in_cs/</guid>
      <pubDate>Sat, 06 Apr 2024 18:11:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM大海捞针，标志着RAG的死亡</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxeqdc/d_llms_ability_to_find_needles_in_a_haystack/</link>
      <description><![CDATA[   /u/Vissidarte_2021   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxeqdc/d_llms_ability_to_find_needles_in_a_haystack/</guid>
      <pubDate>Sat, 06 Apr 2024 15:48:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] MoE 路由器在做出错误选择时如何学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxel8z/d_how_does_a_moe_router_learn_when_it_has_made_a/</link>
      <description><![CDATA[查看当前混合专家模型的代码，他们似乎使用 argmax，其中 k=1（仅选择顶级专家）来选择路由器的选择。由于 argmax 是不可微的，因此梯度不能流向其他专家。因此，在我看来，如果所选专家表现不佳，则只会更新其权重。然而，可能的情况是，对于给定的输入，不同的专家实际上是更好的选择，但路由器无法知道这一点，因为梯度不会流向其他专家。  路由器如何得知自己做出了错误的选择，并在下次使用不同的专家？   由   提交/u/RepresentativeWay0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxel8z/d_how_does_a_moe_router_learn_when_it_has_made_a/</guid>
      <pubDate>Sat, 06 Apr 2024 15:42:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 非 NLP 领域的 ML 研究人员，你们在研究什么？请分享。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bx914m/d_ml_researchers_who_are_not_in_nlp_what_are_you/</link>
      <description><![CDATA[我们很想了解机器学习研究的范围。 如果您将其写得尽可能详细，将会有所帮助。研究实际需要的内容是可能的。谢谢！   由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bx914m/d_ml_researchers_who_are_not_in_nlp_what_are_you/</guid>
      <pubDate>Sat, 06 Apr 2024 11:12:34 GMT</pubDate>
    </item>
    </channel>
</rss>