<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 13 Jan 2024 09:12:22 GMT</lastBuildDate>
    <item>
      <title>[D] 2024 年你的安排是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195jsx0/d_your_setups_in_2024/</link>
      <description><![CDATA[考虑将我的设置更改/升级为功能强大的 MacBook 组合，以实现灵活性和便携性。万一我构建的模型需要比云计算启动更多的功能。有人以类似的方式这样做吗？或者您是否坚持使用强大的工作站/您自己的服务器来执行此类任务？   由   提交/u/R3NNUR   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195jsx0/d_your_setups_in_2024/</guid>
      <pubDate>Sat, 13 Jan 2024 08:54:33 GMT</pubDate>
    </item>
    <item>
      <title>[D]假设：模型中向量的定向定位（例如：ViT-L/14）可能会带来新的可能性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195gyqe/d_hypothesis_directed_positioning_for_the_vectors/</link>
      <description><![CDATA[   我最近一直在研究 CLIP 模型 ViT-L/14，以检查数据的样子。 我注意到，即使对于“接近”的事物的定义也可能是这样的。彼此之间的接近度本质上几乎是随机的。我猜测，在训练过程中，值通过随机运动进行调整，直到“应该”的对象出现。在一起，降落在一个被认为“足够接近”的 n 空间位置，事情就到此结束。  但这使得坐标的随机性非常令人不满意。其示例是比较“cat”在768空间中的位置和“cat”在768空间中的位置。 vs “小猫”这里：  https://preview .redd.it/23v9ux27b5cc1.png?width=569&amp;format=png&amp;auto=webp&amp;s=895f80682a3f6f321bcb8a2482749649c1074c8b 它们的欧几里德距离为 7.22859525680542  什么如果真正属于“密切”的对象是在一起...实际上在大多数维度上都在一起？ 如果可以重新组织数据集，以便真正相似的对象在 768 空间中更多地反映这一点会怎样？  也就是说，如果“cat”是和“小猫”只有几个尺寸不同，其他的都一样？  在我看来，这可能会带来一些有趣的可能性。   由   提交/u/lostinspaz   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195gyqe/d_hypothesis_directed_positioning_for_the_vectors/</guid>
      <pubDate>Sat, 13 Jan 2024 05:50:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] UnIVAL：图像、视频、音频和语言任务的统一模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195eulx/r_unival_unified_model_for_image_video_audio_and/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2307.16184 OpenReview：https:// /openreview.net/forum?id=4uflhObpcp 代码：https： //github.com/mshukor/UnIVAL 检查点：https://github.com/mshukor/UnIVAL/blob/main/checkpoints.md 项目页面：https://unival-model.github.io/ 演示：https://huggingface.co/spaces/mshukor/UnIVAL 视频：&lt; a href=&quot;https://www.youtube.com/watch?v=mYOun92st08&quot;&gt;https://www.youtube.com/watch?v=mYOun92st08 摘要：  大型语言模型（LLM）使对通才智能体的雄心勃勃的追求不再是一个幻想。构建此类通用模型的一个关键障碍是任务和模式的多样性和异质性。一种有前途的解决方案是统一，允许在一个统一的框架内支持无数的任务和模式。虽然在海量数据集上训练的大型模型（例如 Flamingo（Alayrac 等人，2022））可以支持两种以上的模态，但当前的中小型统一模型仍然仅限于 2 种模态，通常是图像文本或视频-text.我们要问的问题是：是否有可能高效地构建一个能够支持所有模态的统一模型？为了回答这个问题，我们提出了UnIVAL，朝着这个雄心勃勃的目标又迈进了一步。在奇特的数据集大小或具有数十亿参数的模型上，~ 0.25B 参数 UnIVAL 模型超越了两种模式，并将文本、图像、视频和音频统一到单个模型中。我们的模型基于任务平衡，在许多任务上进行了有效的预训练和多模态课程学习。UniVAL 在图像和视频文本任务中显示出与现有最先进方法相比的竞争性能。从图像和视频文本模态中学习的特征表示，允许模型在微调时实现竞争性能音频文本任务，尽管没有经过音频预训练。得益于统一模型，我们提出了一项通过对不同多模态任务训练的模型进行权重插值来进行多模态模型合并的新颖研究，展示了它们特别是对于分布外泛化的好处。最后，我们通过展示任务之间的协同作用来激励统一。模型权重和代码在这里发布：这个 https URL.    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195eulx/r_unival_unified_model_for_image_video_audio_and/</guid>
      <pubDate>Sat, 13 Jan 2024 03:54:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] PASTA：预训练的动作状态转换代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195eh7b/r_pasta_pretrained_actionstate_transformer_agents/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2307.10936 OpenReview： https://openreview.net/forum?id=ciBFYxzpBT https： //openreview.net/forum?id=pxK9MWuFF8 摘要：  自监督学习带来了革命性的各种计算领域的范式转变，包括 NLP、视觉和生物学。最近的方法涉及对大量未标记数据进行预训练 Transformer 模型，作为有效解决下游任务的起点。在强化学习中，研究人员最近采用了这些方法，开发了根据专家轨迹进行预训练的模型。这一进步使模型能够处理从机器人到推荐系统的广泛任务。然而，现有的方法主要依赖于针对特定下游应用量身定制的复杂的预训练目标。本文对模型进行了全面的研究，称为预训练动作状态转换代理（PASTA）。我们的研究涵盖了统一的方法论，并涵盖了广泛的一般下游任务，包括行为克隆、离线强化学习、传感器故障鲁棒性和动态变化适应。我们的目标是系统地比较各种设计选择，并提供有价值的见解，帮助从业者开发强大的模型。我们研究的主要亮点包括动作和状态的组件级别的标记化、基本预训练目标的使用（例如下一个标记预测或掩码语言建模）、跨多个领域的模型同步训练以及各种微调的应用策略。在这项研究中，开发的模型包含不到 700 万个参数，允许广泛的社区使用这些模型并重现我们的实验。我们希望这项研究能够鼓励进一步研究使用具有第一原理设计选择的变压器来表示 RL 轨迹，并为稳健的策略学习做出贡献。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195eh7b/r_pasta_pretrained_actionstate_transformer_agents/</guid>
      <pubDate>Sat, 13 Jan 2024 03:35:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前最好的文字转语音工具是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195cxim/d_what_is_the_best_texttospeech_tool_currently/</link>
      <description><![CDATA[大家好，我需要一个听起来完全像人声的 TTS 工具。我想用它来编辑我的一些 YouTube 视频，更具体地说，上传我自己选择的语音样本并从中生成良好的结果。我看到周围有很多 TTS 平台。你推荐哪一个？我希望这不是一个过分的要求。我将非常感激。 提前致谢。   由   提交 /u/FateRiddle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195cxim/d_what_is_the_best_texttospeech_tool_currently/</guid>
      <pubDate>Sat, 13 Jan 2024 02:18:39 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] MS在线ML程序（EE背景）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1958r4n/discussion_ms_online_programs_for_ml_ee_background/</link>
      <description><![CDATA[我正在考虑获得机器学习硕士学位（无论是专注于 ML 的 CS，还是 ML+数据科学等）。想知道什么是值得一看的好程序？ 我拥有电气工程学士学位和电气工程硕士学位，但在 MS 期间，我将所有课程都集中在 ML 上，因为我意识到这就是什么我对此很感兴趣。目前我正在努力寻找一份与 ML 相关的工作，但没有专业经验。任何建议将不胜感激，谢谢！   由   提交/u/Sad-Fondant3060  /u/Sad-Fondant3060 reddit.com/r/MachineLearning/comments/1958r4n/discussion_ms_online_programs_for_ml_ee_background/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1958r4n/discussion_ms_online_programs_for_ml_ee_background/</guid>
      <pubDate>Fri, 12 Jan 2024 23:09:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 适合面试的 ML 工程题库好吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/</link>
      <description><![CDATA[我一直在研究 ML 工程面试（并做了一些），我意识到“了解偏见”的常见建议，方差、交叉折叠验证等”。都是错的。顶级公司要求你使用 Pytorch/numpy 编写简单的代码。所以问题是这样的：“编写一个神经网络来解决 X 问题”或者“编写一个神经网络来解决 X 问题”。或“使用 numpy 实现 k-means”。 考虑到这种情况，我认为通过做一堆编码问题来准备这些面试会更有用。 我想知道这里的人是否可以分享他们在 ML Eng 面试中遇到的一些编码问题，或者向我指出好的 Leetcode 风格的 MLEng 题库？  &amp;# 32；由   提交 /u/lisp-cloj    reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1958jbm/d_good_ml_eng_question_banks_for_interviews/</guid>
      <pubDate>Fri, 12 Jan 2024 23:00:47 GMT</pubDate>
    </item>
    <item>
      <title>图中的节点分类[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19572jd/node_classification_in_graphs_discussion/</link>
      <description><![CDATA[Tl;Dr：我有一个异构图，其中边具有特征，某种类型的节点具有标签。我想预测标签。但我发现很难得到结果。分享您遇到类似问题的经验 我的数据由代理和项目组成，我想根据代理交互来预测项目的质量。这是一个二元分类问题。 有关我的问题设置的更多详细信息：  边仅存在于代理和项目之间，其中代理可以与多个项目交互。  节点可以是代理或项目。代理节点没有特征，而项目节点有标签（这就是我试图预测的） 边具有交互长度和交互质量等特征  我尝试过一些非深度方法，主要是集成和增强方法。对于这些，我使用了节点传入边缘的统计数据（例如代理数量、平均交互长度等）。根据我使用的功能，我可以获得大约 0.6 F1，精度和召回率各不相同（有时高达 80%） 我发现很难使用 GNN 获得结果。我尝试过图注意网络，并且正在尝试 SAGEConv，但我不太确定如何处理卷积层的边缘特征。我觉得通过计算平均值或最大值来汇集它们与使用决策森林是一样的。 同时我觉得使用 GNN 可以帮助利用数据的几何形状，使用标准机器学习方法时，这有点被破坏了。 所以我的问题是，对于那些遇到类似问题的人来说，什么对你有用/没用，为什么？   由   提交/u/eatpasta_runfastah  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19572jd/node_classification_in_graphs_discussion/</guid>
      <pubDate>Fri, 12 Jan 2024 21:59:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 以最小的开销从大型 GPU 扩展到仅 CPU 的最便宜方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19549sd/d_cheapest_way_to_scale_up_and_down_from_a_large/</link>
      <description><![CDATA[当我离开家几周并且远离我相当强大的 GPU 桌面时，我有很多业余爱好者项目需要处理. 我正在寻找最简单（也是最便宜）的方法来获得一台可以通过 SSH 连接的计算机，并且：  进行一些编码/调试（花费 80 % 的时间） 以批处理模式运行一些相当小众的 ML 软件，需要低端 GPU (10%) 启动强大的 48 GB GPU 来处理LLM（10%）  考虑到设置/配置开销，我想做的是将 60 GB 存储附加到 EC2.micro，安装完整的 Lambdalabs 容器（Nvidia驱动程序、CUDA、Pytorch 等），将其用于 #1，然后将该启动驱动器交换到更多计算或 GPU 密集型计算机，以便在我准备好时运行 #2 或 #3 几个小时。 &lt; p&gt;单个配置良好的启动驱动器可以在截然不同的计算配置中工作吗？有没有最适合此类事情的云提供商？ 特别是，当我不积极做某事时，我希望能够尽可能降低费用（我可以支付一点存储费用。 我很乐意与 LamdaLabs 这样的公司合作，但他们没有廉价的低端仅 CPU 实例。 是否有更智能的（不是使用 Ansible 等疯狂的高努力）方法来维护 SSH 和 go 设置，使其能够在截然不同的规模计算中工作？  &amp; #32；由   提交/u/gofiend  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19549sd/d_cheapest_way_to_scale_up_and_down_from_a_large/</guid>
      <pubDate>Fri, 12 Jan 2024 20:01:27 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待 Yann Lecun 关于 ML 的有争议的观点？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/</link>
      <description><![CDATA[      Yann Lecun 有一些有争议的观点关于 ML 的看法，他并不羞于分享。他写了一篇立场文件，名为“通往自主机器智能的途径”。不久以前。此后，他也就此发表了很多演讲。这是屏幕截图 ​ https://preview.redd.it/xxmxgrdk02cc1.jpg?width=1581&amp;format=pjpg&amp;auto=webp&amp;s=4a7e98f5a41f2e454e2e33881f2 df93c7287d09b 来自 &lt; a href=&quot;https://www.youtube.com/watch?v=OKkEdTchsiE&quot;&gt;一个，但我看过几个 - 它们很相似，但不完全相同。以下并不是所有演讲的摘要，而只是他对 ML 现状的批评，根据记忆进行解释（他还谈论了 H-JEPA，我在这里忽略了）：  &lt; li&gt;法学硕士无法商业化，因为内容所有者“喜欢reddit”会起诉（奇怪的是，鉴于最近的《纽约时报》诉讼，这是有先见之明的） 当前的机器学习技术很糟糕，因为与人类相比，它需要大量的数据（有两种截然不同的可能性：算法本身很糟糕，或者人类只是在童年时期进行了更多的“预训练”） 规模化是不够的 自回归法学硕士注定会失败，因为任何错误都会让你偏离正确的道路，并且随着输出数量的增加，不犯错误的概率很快接近 0 LLM 无法推理，因为它们只能执行有限数量的计算步骤 连续域中的建模概率为错误的，因为你会得到无限的梯度 对比训练（如 GAN 和 BERT）是不好的。您应该进行正规化训练（例如 PCA 和稀疏 AE） 生成建模是误导性的，因为世界的大部分内容都是不可预测或不重要的，不应该由智能系统建模 人类通过被动视觉观察了解他们对世界的大部分了解（我认为这可能与先天失明的人可能非常聪明的事实相矛盾） 你不&#39;智能行为不需要巨大的模型，因为老鼠只有数千万个神经元，就超越了当前的机器人人工智能    由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/</guid>
      <pubDate>Fri, 12 Jan 2024 19:14:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于基于 RAG/LLM 的 MVP，您需要什么 UI 库/框架/堆栈？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1950nep/d_what_ui_libraryframeworkstack_do_you_just_for_a/</link>
      <description><![CDATA[我正在构建一个用于在客户面前展示的 mvp。我的后端基于 fastapi 构建，同时使用 Huggingface 和 openai。您建议我在什么基础上构建 UI？我应该使用 Streamlit（目前正在使用）还是其他？市场上还有其他新框架吗？ 我希望得到一些帮助。   由   提交 /u/Ok_Cartographer5609   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1950nep/d_what_ui_libraryframeworkstack_do_you_just_for_a/</guid>
      <pubDate>Fri, 12 Jan 2024 17:31:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 讨论我的项目在脊柱手术中使用医学成像的可行性。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/194xsl6/d_discussion_on_the_feasibility_of_my_project/</link>
      <description><![CDATA[您好，我正在尝试了解我计划开展的项目的可行性，并感谢来自该社区的任何和所有意见. 背景：我是神经外科医生（去年接受培训的住院医师），主攻脊柱外科。我认为脊柱外科是一个可以从人工智能实施中受益匪浅的外科领域。通常，对于通过影像学（和症状学）识别的任何给定脊柱病理，有几种不同类型的外科手术/方法可以解决该病理。这些不同的方法具有广泛的相关成本，并且通常会导致短期和长期的不同结果。令人惊讶的是，脊柱文献对于更直接的病理学的最佳方法仅达成了最低限度的共识。  我的目标：简单来说，我想实施机器学习来训练术前患者数据和患者成像（MRI、CT、X 射线）和术后患者结果数据，以及术后成像来创建预测模型，该模型可以执行以下操作： 1）根据新患者的术前数据/症状和成像预测能够提供最佳结果的手术干预类型。 &gt; 2) 为外科医生提供最佳的矫正脊柱参数以进行手术。例如，需要通过手术恢复的脊柱弯曲的矫正程度。  在过去的一年里，我与医院管理人员和放射科部门合作，终于能够建立一个能够访问 2500 多名患者影像和相关数据的途径。这一切都已得到机构审查委员会的批准，所有数据都将符合 HIPPA 要求并进行去识别化。我还能够与全州脊柱手术结果数据库合作，该数据库收集该州主要中心脊柱手术患者的非常详细、有组织的术前和术后数据。我的机构数据可以轻松地与全州数据交叉引用，以获得额外的结果数据。不幸的是，我没有计算机科学和机器学习方面的专业知识，无法理解在此类数据集上开发和训练机器学习算法的可行性。尽管如此，我确实知道完成如此规模的事情需要大量资源。话虽如此，通过一些网络，我已经从一位与我们医院系统有着深厚联系的当地著名金融家和捐助者那里获得了 300 万美元的承诺。此人的投资取决于我组建技术团队的能力。我还与对该项目表现出极大兴趣的其他投资者进行了两次会面。我的目标是筹集大约 500 万美元。我向医院系统提出的建议（他们完全同意）是，我将成立一家公司，医院作为股权合作伙伴，作为回报，医院将尽其所能简化与患者的接触和成像数据。该公司的结构将允许通过风险投资获得外部资金。  通过该计划开发的工具将对脊柱手术市场产生重大的商业影响，并且重要的是对脊柱手术患者的手术结果具有有意义的好处。  现在，显然如果没有技术团队，这将毫无进展。但首先，我希望在这里进行讨论，以了解此类项目的技术可行性、所需资源的类型和数量。  同样，为了保持这篇文章简短，我放弃了很多细节，但我很高兴通过评论进一步深入研究细节。    由   提交 /u/LaniakeaResident   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/194xsl6/d_discussion_on_the_feasibility_of_my_project/</guid>
      <pubDate>Fri, 12 Jan 2024 15:31:28 GMT</pubDate>
    </item>
    <item>
      <title>无监督聚类能否近似真实类别或分类？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/194v0n2/could_unsupervised_clustering_approximate_ground/</link>
      <description><![CDATA[假设我们有一个带标签的数据集，并且我们使用聚类来对实例进行聚类。我们还可以使用分类来对实例进行分类，因为它是有标签的。这里有人可以解释一下是否存在聚类会产生与分类相似的结果的情况吗？谢谢， 如果我们有真实类别，则不需要使用聚类，但我只是想知道它是否可以近似或等于分类。 编辑：假设确定性聚类方法，聚类数=类别数。 （这对于确定性聚类方法来说似乎是一个很好的答案。） &lt;!-- SC_ON - -&gt;  由   提交 /u/whereismycatyo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/194v0n2/could_unsupervised_clustering_approximate_ground/</guid>
      <pubDate>Fri, 12 Jan 2024 13:26:30 GMT</pubDate>
    </item>
    <item>
      <title>我们今天在人工智能中拥有的大多数东西将在 6 个月内变得无关紧要 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/194ap95/most_things_we_have_today_in_ai_will_be_a/</link>
      <description><![CDATA[      当您构建“薄包装器”时，这是不幸的情况。基础模型之上的产品。 去年，我们为客户构建了一个定制的稳定扩散管道，在 2 个月内进行了大量实验，找出了针对边缘情况的定制解决方案，并交付了一个可以将集体照片转换为圣诞礼品卡。 今天，阿里巴巴推出了 ReplaceAnything，我可以在一分钟内构建出同样的东西，但质量可能会下降 10%（！），因为我们的团队花了几周时间才完成了几个几个月前。 这个领域的进展是疯狂的。 幸运的是，这只是“那些有趣的小事情之一”。我们为客户建立的公司。 我无法想象建立这些公司之一的压力，尤其是如果你筹集了风险资金。 时间在流逝，你每天都在滴答作响。技术护城河越来越少。 这就是为什么您需要全力以赴尽快创建长期、可持续的数据护城河。 https://preview.redd.it/7a67geld8vbc1.png?width=722&amp;format= png&amp;auto=webp&amp;s=c4dc336cf2635c178ad6ccfc65d10292f5c881f4   由   提交 /u/BootstrapGuy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/194ap95/most_things_we_have_today_in_ai_will_be_a/</guid>
      <pubDate>Thu, 11 Jan 2024 19:52:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>