<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 14 Feb 2024 00:57:28 GMT</lastBuildDate>
    <item>
      <title>[D] 如果我有一个采样策略 A、B、C 和 B 表现最好。如果数据规模扩大，情况仍然如此吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq8p38/d_if_i_have_a_sampling_strategy_a_b_and_c_and_b/</link>
      <description><![CDATA[所以我一直在测试带有二进制标签的 NLP 数据的不同采样策略（均匀、分层以及标签上两者之间的中间）。我已经用 20% 的数据对它们进行了测试，发现中间采样策略迄今为止效果最好。如果我缩放到 100% 的数据，什么原因可能导致中间的数据不再是最好的？   由   提交 /u/DolantheMFWizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq8p38/d_if_i_have_a_sampling_strategy_a_b_and_c_and_b/</guid>
      <pubDate>Tue, 13 Feb 2024 23:58:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 信息检索/搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq8dvw/d_information_retrievalsearch/</link>
      <description><![CDATA[我正在寻找有关构建搜索引擎的文档。特别是围绕处理查询并为其构建嵌入。 一些用例可能是长查询、维护长上下文、拼写错误、处理多个条件、重写、扩展、查询意图、NLU。 &gt; 我可能会使用 RAG+LLM 构建它，但我认为基本原则仍然适用。关于在哪里/阅读什么内容有什么建议吗？   由   提交 /u/Worldly-Pen-8101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq8dvw/d_information_retrievalsearch/</guid>
      <pubDate>Tue, 13 Feb 2024 23:45:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 什么是鲁棒的预训练 Word2Vec 模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq8cm5/p_what_is_a_robust_pretrained_word2vec_model/</link>
      <description><![CDATA[我正在尝试构建一个 RNN 来预测句子，但我需要从一个好的 Word2Vec 模型开始，该模型对数字等事物具有鲁棒性（在非单词形式so：1,2,3)，人名，等等。我有数据，但新数据可能会包含以前未见过的单词，因此需要一个强大的 Word2Vec 模型。有什么建议吗？ 注意：由于某些问题限制，我无法使用 Transformer 来解决此问题，因为我知道最常见的响应是使用预先训练的 Transformer。   由   提交 /u/DolantheMFWizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq8cm5/p_what_is_a_robust_pretrained_word2vec_model/</guid>
      <pubDate>Tue, 13 Feb 2024 23:43:46 GMT</pubDate>
    </item>
    <item>
      <title>chatgpt API 的 Python 代码 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq8aw9/python_code_for_chatgpt_api_r/</link>
      <description><![CDATA[我的 Python 代码与 ChatGPT API 成功交互；然而，它产生的结果与我的预期不同。 ChatGPT 的输出通常更加详细和扩展，但我从 API 调用收到的响应很简短且缺乏细节。尽管调整了温度和标记值，但我没有看到任何改进。对于此问题，我将不胜感激。 def get_completion(prompt, model=&quot;gpt-4&quot;, temp=0.7, max_tokens=5000): messages = [{ “角色”：“用户”，“内容”：提示}] response = openai.ChatCompletion.create( model=model, messages=messages， 温度=温度， max_tokens=max_tokens， ) 返回response.choices[0]。 message[“content”] ​ ChatGPT API 响应：德克萨斯州普莱诺以其富裕的人口和高度优先的教育系统而闻名。它位于达拉斯北部，是许多公司总部的中心，包括丰田北美公司和菲多利公司。它以其多样化的餐饮场所而闻名，还拥有广泛的购物场所，整个城市拥有多个购物中心和购物中心。普莱诺还拥有 3,800 英亩的公园空间，包括步行道和娱乐中心。凭借其强劲的经济增长、优秀的学校和适合家庭的社区，普莱诺一直被评为美国最适宜居住的地方之一。 ChatGPT 回复：德克萨斯州普莱诺是一座因其卓越的生活质量、强劲的经济和精心规划的社区。它是达拉斯-沃斯堡大都市区的一部分，为居民和游客提供城市和郊区融合的生活。以下是关于普莱诺的一些亮点：  经济中心：普莱诺是多家公司总部所在地，包括丰田汽车北美公司、Frito-Lay 和 J.C. 等大公司。彭尼。强大的企业影响力推动了该市的经济发展，并提供了大量就业机会。 教育：该市以其高质量的教育体系而闻名。普莱诺独立学区 (PISD) 的学校获得了全国认可，增强了该市对家庭的吸引力。 公园和休闲：普莱诺拥有大量公园、休闲场所设施和开放空间。该市高度重视维护美丽且可用的体育、休闲和社区活动公共空间。 购物和餐饮：拥有各种购物中心，包括商店普莱诺 (Plano) 的 Legacy 和 Legacy West 以及各种餐饮选择可满足购物者和美食家的需求。 安全和社区：经常被誉为美国最安全的城市之一。在美国，普莱诺的低犯罪率和紧密的社区氛围使其成为寻求郊区生活方式和城市便利设施的家庭和个人的有吸引力的地方。 文化多样性：多年来，普莱诺变得越来越多元化，拥有丰富的文化景观，包括节日、艺术表演和国际美食。这种多样性在社区内受到赞扬和拥护。 交通：普莱诺通过主要高速公路和公共交通设施（包括达拉斯地区快速交通 (DART) 系统）四通八达，使得轻松导航和前往更广阔的 DFW 地区。  总体而言，德克萨斯州普莱诺结合了经济繁荣、卓越教育和高生活水平的优势，使其成为居民理想的居住地和企业一样。   由   提交/u/Better_Run_1295   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq8aw9/python_code_for_chatgpt_api_r/</guid>
      <pubDate>Tue, 13 Feb 2024 23:41:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Mamba 进行语音合成：初学者友好的笔记本 + 代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq7rd5/p_speech_synthesis_with_mamba_beginner_friendly/</link>
      <description><![CDATA[大家好，我遇到了这篇文章上个月，发现它非常有趣。我是 Defined AI 的开发者倡导者，总是希望学习新事物，所以我想自己解决这个问题。 博客文章写得非常好，作者：u/ExaminationNo8522 也有帮助。 无论如何，我想仔细检查它并在不同的数据集上为自己重现，然后移植到确定。结果是一个初学者友好的笔记本 + 博客文章。如果您感兴趣，请查看这些内容。 当然，如果您有想法/反馈/评论/问题，请告诉我！   由   提交/u/ishabytes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq7rd5/p_speech_synthesis_with_mamba_beginner_friendly/</guid>
      <pubDate>Tue, 13 Feb 2024 23:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] 思想扩散：扩散语言模型中的思想链推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq572l/r_diffusion_of_thoughts_chainofthought_reasoning/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.07754 代码：https ://github.com/HKUNLP/diffusion-of-thoughts 摘要：  扩散模型在以下领域获得了关注：文本处理，与传统自回归模型相比具有许多潜在优势。这项工作探索了扩散模型和思想链（CoT）的集成，这是一种完善的技术，可以提高自回归语言模型的推理能力。我们提出思想扩散 (DoT)，允许推理步骤通过扩散过程随着时间的推移而扩散。与以从左到右、逐个标记的方式做出决策的传统自回归语言模型相比，DoT 在计算和推理性能之间的权衡方面提供了更大的灵活性。我们的实验结果证明了 DoT 在多位数乘法和小学数学问题中的有效性。此外，DoT 还展示了有前景的自我纠正能力，以及自一致性解码等现有推理增强技术的优势。我们的发现有助于理解和发展扩散语言模型的推理能力。    由   提交 /u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq572l/r_diffusion_of_thoughts_chainofthought_reasoning/</guid>
      <pubDate>Tue, 13 Feb 2024 21:32:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR openreview 可见吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aq0ama/d_iclr_openreview_visible/</link>
      <description><![CDATA[我最近向 ICML 提交了一篇论文，但被 ICLR 拒绝了。我发现我在 ICLR 的 openreview 控制台中的论文是每个人都可以看到的。可以吗？由于ICLR和ICML中的论文标题相同，那么ICML可能不是完全匿名的。 我必须手动更改可见性吗？   由   提交/u/Shot-Button-9010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aq0ama/d_iclr_openreview_visible/</guid>
      <pubDate>Tue, 13 Feb 2024 18:15:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] Fiddler：用于混合专家模型快速推理的 CPU-GPU 编排 - 华盛顿大学 2024 年 - 推理速度比现有系统快 10 倍以上！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apxr2n/r_fiddler_cpugpu_orchestration_for_fast_inference/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.07033  Github：https://github。 com/efeslab/fiddler  摘要：  基于专家混合 (MoE) 架构的大型语言模型 (LLM) 在各种任务。然而，由于模型尺寸巨大，在 GPU 内存资源不足的资源受限设置上运行它们具有挑战性。将模型权重卸载到 CPU 内存的现有系统面临着在 CPU 和 GPU 之间频繁移动数据的巨大开销。在本文中，我们提出了 Fiddler，一种资源高效的推理引擎，可为 MoE 模型提供 CPU-GPU 编排。 Fiddler的核心思想是利用CPU的计算能力来最小化CPU和GPU之间的数据移动。 我们的评估表明，Fiddler 可以运行参数超过 90GB 的未压缩 Mixtral-8x7B 模型，在具有 24GB 内存的单个 GPU 上每秒生成超过 3 个令牌，比现有方法有数量级的改进。  https ://preview.redd.it/q9l3fciyqdic1.jpg?width=1338&amp;format=pjpg&amp;auto=webp&amp;s=2e39726c970c655d6ee39f2b68c323204c6b2289 https://preview.redd.it/epjd0fiyqdic1.jpg?width=1661&amp;format=pjpg&amp;auto=webp&amp; ;s=701a2d61f8ab50d054db0301a30e40119898dab6   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apxr2n/r_fiddler_cpugpu_orchestration_for_fast_inference/</guid>
      <pubDate>Tue, 13 Feb 2024 16:34:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 vLLM 在 AWS EC2 上部署 Mixtral 8x7B、LLaMA 2 和 Mistral</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apxg42/d_deploy_mixtral_8x7b_llama_2_and_mistral_on_aws/</link>
      <description><![CDATA[大家好， 2023 年，许多复杂的开源 LLM 已经推出。然而，将这些人工智能模型集成到生产环境中仍然是一项复杂的任务。我撰写了一篇文章，将指导您在 AWS EC2 上部署一些顶级 LLM，即 LLaMA 2 70B、Mistral 7B 和 Mixtral 8x7B。我采用了一个能够批量处理和分布式推理的推理引擎：vLLM。 vLLM 将极大地帮助 LLaMA 2 和 Mixtral 的实现，因为它允许我们使用配备多个较小 GPU 的 AWS EC2 实例（例如例如 NVIDIA A10），而不是依赖单个大型 GPU（例如 NVIDIA A100 或 H100）。 请参阅此处的详细操作方法：https://nlpcloud.com/deploy-llama -2-mistral-and-mixtral-on-aws-ec2-with-vllm.html 在本教程中，我使用了 AWS EC2，但当然我也可以使用其他供应商。主要挑战是 GPU 的成本及其可用性。 请随时分享有关本文的反馈，我们将非常感激！ Julien   由   提交/u/juliensalinas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apxg42/d_deploy_mixtral_8x7b_llama_2_and_mistral_on_aws/</guid>
      <pubDate>Tue, 13 Feb 2024 16:22:44 GMT</pubDate>
    </item>
    <item>
      <title>[研究] GStreamer 中共享分析数据的框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apwwme/research_a_framework_to_share_analytics_data_in/</link>
      <description><![CDATA[GStreamer 长期以来一直是构建处理视频流（尤其是实时视频流）管道的最佳框架。工程师们广泛采用它来构建视频分析管道，虽然许多公司确实围绕 GStreamer 构建了机器学习分析框架，但到目前为止，还没有人做出努力为上游做出贡献。  https://www.collabora.com/news-and-blog/news-and-events/a-framework-to-share-analytics-data-in-gstreamer.html   由   提交 /u/mfilion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apwwme/research_a_framework_to_share_analytics_data_in/</guid>
      <pubDate>Tue, 13 Feb 2024 16:01:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] OS-Copilot：迈向自我完善的通用计算机代理 - 上海人工智能实验室2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apwlkm/r_oscopilot_towards_generalist_computer_agents/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2402.07456  Github：https://github.com/OS-Copilot/FRIDAY  摘要：  与计算机的自主交互一直是一个长期的挑战巨大的潜力，最近大型语言模型（LLM）的激增显着加速了构建数字代理的进展。然而，大多数这些代理都被设计为与狭窄的域交互，例如特定的软件或网站。这种狭隘的关注限制了它们对一般计算机任务的适用性。为此，我们引入了 OS-Copilot，这是一个构建通用代理的框架，能够与操作系统 (OS) 中的综合元素（包括 Web、代码终端、文件、多媒体和各种第三方应用程序）进行交互。我们使用 OS-Copilot 创建 FRIDAY，这是一个自我改进的实体代理，用于自动化一般计算机任务。 在通用人工智能助手基准 GAIA 上，FRIDAY 的性能比以前的方法高出 35%，通过以前任务中积累的技能展示了对未见过的应用程序的强大泛化能力。我们还提供了数值和定量证据，表明 FRIDAY 学会了控制和控制在最少的监督下自我改进 Excel 和 Powerpoint。 我们的 OS-Copilot 框架和实证研究结果为未来研究更强大、更通用的计算机代理提供了基础设施和见解。   https://preview.redd.it/uzec8udohdic1.jpg?width=1655&amp;format=pjpg&amp; ;auto=webp&amp;s=893b5561ca47c26c789b69925efdc26e5b783007 https://preview.redd.it/vfwfwudohdic1.jpg?width=1653&amp;format=pjpg&amp;auto=webp&amp;s=9eafc2a5ea0ad188a156d3de446508d82d9cc913  https://preview.redd.it/lmi8rwdohdic1.jpg?width=1123&amp;format =pjpg&amp;auto=webp&amp;s=dbc67b27585b980d0c592f9bd9f87f3ec6531f66 https://preview.redd.it/20yo21eohdic1.jpg?width=1037&amp;format=pjpg&amp;auto=webp&amp;s=72fab36d585b862eed4ff6c7deed2be0cd62f637   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apwlkm/r_oscopilot_towards_generalist_computer_agents/</guid>
      <pubDate>Tue, 13 Feb 2024 15:48:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] GNN 的应用 - 调查（视频）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apwl8v/r_applications_of_gnns_a_survey_video/</link>
      <description><![CDATA[大家好，我正在分享图神经网络 (GNN) 应用程序的概述解释视频： 🎥 https://youtu.be/9QH6jnwqrAk?si=nEARUXquZ0aetjCD 我整理了一批信息一个视频，重点介绍了 GNN 在 7 个不同领域的最新突破和具体应用。 GNN 最近取得了快速、疯狂的进步。尽管比其他人工智能流行语少得多炒作，但它们仅在去年就取得了许多成就。 我计划在 GNN 上创作更多内容，比如一个将深入探讨的短片系列深入了解 GNN 如何工作的（一些）技术细节等等。听到您对此的想法将非常有帮助！   由   提交/u/mrx-ai  /u/mrx-ai  reddit.com/r/MachineLearning/comments/1apwl8v/r_applications_of_gnns_a_survey_video/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apwl8v/r_applications_of_gnns_a_survey_video/</guid>
      <pubDate>Tue, 13 Feb 2024 15:48:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] [P] 通过贝叶斯优化将 LLM 评估速度提高 10 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1apv97t/r_p_10_times_faster_llm_evaluation_with_bayesian/</link>
      <description><![CDATA[最近我一直致力于通过使用贝叶斯优化来选择合理的子集来快速进行 LLM 评估。 贝叶斯优化是使用它是因为它有利于探索/利用昂贵的黑匣子（释义，LLM）。 项目链接&lt; /p&gt; 我很想听听您对此的想法和建议！   由   提交 /u/b06901038g   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1apv97t/r_p_10_times_faster_llm_evaluation_with_bayesian/</guid>
      <pubDate>Tue, 13 Feb 2024 14:51:30 GMT</pubDate>
    </item>
    <item>
      <title>[2402.07901] FAST：加速 Transformer 的可分解注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aprsv9/240207901_fast_factorizable_attention_for/</link>
      <description><![CDATA[ 由   提交/u/Elven77AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aprsv9/240207901_fast_factorizable_attention_for/</guid>
      <pubDate>Tue, 13 Feb 2024 12:00:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>