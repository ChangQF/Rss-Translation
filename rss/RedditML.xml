<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Thu, 13 Jun 2024 12:27:30 GMT</lastBuildDate>
    <item>
      <title>[D] NLP 中的否定是一个已解决的问题吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1devevc/d_is_negation_in_nlp_a_solved_problem/</link>
      <description><![CDATA[我以为事实并非如此，而且存在问题，而且问题无处不在。但有人声称：  否定是扩散中已解决的问题，相同的原理将扩展到早期融合多模态模型。  我需要理解这一点。这种说法合理吗？如果这是真的，是否有论文、出版物可以转发给我？ 谢谢！    提交人    /u/Beginning-Ladder6224   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1devevc/d_is_negation_in_nlp_a_solved_problem/</guid>
      <pubDate>Thu, 13 Jun 2024 10:06:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] OpenMetricLearning 3.0 统一支持图片和文字！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deujz2/p_openmetriclearning_30_which_uniformly_supports/</link>
      <description><![CDATA[      大家好！ 我想分享 OpenMetricLearning 3.0 的发布！  OML — 是一个用于表示学习和检索的库，其中包含大量模型、损失、矿工、采样器、指标和其他有用的东西，如 DDP、与 PyTorchLightning 和 PyTorch Metric Learning 的集成、不同的实验跟踪器等。   有什么新内容？ * 我们已经添加了文本支持，现在我们正在添加音频！（用户不仅已经将 OML 用于图像，而且现在我们还提供开箱即用的支持、测试和示例。） * 代码统一适用于图像、文本，并且适用于声音！我邀请您查看图像和文本的并排比较。 * 检索部分已分离，可用于模型验证和推理，并进行以下重新排名或其他后期处理。 * 库的功能已在一个地方描述，以便于导航，并且我们总体上改进了文档和示例。 * 一些计算，特别是与内存相关的计算，已经进行了优化。 我们欢迎潜在的贡献者： * 代码变得更加模块化，因此入门门槛降低了 - 您可以获取单独的代码并继续进行它。 * 我们还用我们的问题/任务更新了board。 您在GitHub上的⭐️极大地帮助了我们进一步发展！ OML    提交人    /u/Zestyclose-Check-751   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deujz2/p_openmetriclearning_30_which_uniformly_supports/</guid>
      <pubDate>Thu, 13 Jun 2024 09:06:14 GMT</pubDate>
    </item>
    <item>
      <title>设计最佳栖息地[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deufeq/designing_the_optimal_habitat_p/</link>
      <description><![CDATA[看到最近一篇关于设计最佳伐木斧的帖子，我想起了我一直想做的一个项目。使用深度学习模型设计最佳、最优的栖息地，比如既有干湿部分的水族馆，又有热梯度的爬行动物围栏。有人知道与此相关的任何工作吗？提前致谢！    提交人    /u/TanukiBigBalls69   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deufeq/designing_the_optimal_habitat_p/</guid>
      <pubDate>Thu, 13 Jun 2024 08:57:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何为机器学习任务准备 TB 级数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1desvs5/d_how_to_prepare_tbs_of_data_for_ml_tasks/</link>
      <description><![CDATA[我目前必须预处理（主要是清理）几 TB 的图像，之后这些图像可用于机器学习。这一挑战似乎与拥有大型数据集的公司必须面临的挑战非常相似，例如 OpenAl、Tesla 等。 当处理代码使用 Python 时，您知道如何很好地分布这一过程吗？有没有流行的框架可以实现这一目标？    提交人    /u/That_Phone6702   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1desvs5/d_how_to_prepare_tbs_of_data_for_ml_tasks/</guid>
      <pubDate>Thu, 13 Jun 2024 07:06:21 GMT</pubDate>
    </item>
    <item>
      <title>[P] 微软开源 Recall AI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dergc6/p_opensource_microsoft_recall_ai/</link>
      <description><![CDATA[我创建了一个开源的 Microsoft Recall AI 替代品。 这会记录您屏幕上的所有内容，并可以使用自然语言搜索。但与 Microsoft 的实现不同，这不是隐私噩梦，现在就可以使用。并带有实时加密 这是一个新的启动项目，需要贡献，因此请希望转到 github repo 并给它一个星星 https://github.com/VedankPurohit/LiveRecall 它是完全本地的，您可以查看代码。而且所有内容始终是加密的，这与 Microsoft 的含义不同，当您登录时，图像会被解密并可能被盗    提交人    /u/Vedank_purohit   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dergc6/p_opensource_microsoft_recall_ai/</guid>
      <pubDate>Thu, 13 Jun 2024 05:30:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 能否发明更好的方法来培养 LLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deo4pd/r_can_llms_invent_better_ways_to_train_llms/</link>
      <description><![CDATA[新博客文章和论文： https://sakana.ai/llm-squared/ https://arxiv.org/abs/2406.08414 发现用于大型语言模型的偏好优化算法 摘要 离线偏好优化是增强和控制大型语言模型 (LLM) 输出质量的关键方法。通常，偏好优化被视为使用手工制作的凸损失函数的离线监督学习任务。虽然这些方法基于理论见解，但它们本质上受到人类创造力的限制，因此可能的损失函数的大量搜索空间仍未得到探索。我们通过执行 LLM 驱动的目标发现来解决这个问题，以自动发现新的最先进的偏好优化算法，而无需（专家）人工干预。具体而言，我们迭代地提示 LLM 根据先前评估的性能指标提出和实施新的偏好优化损失函数。此过程导致发现以前未知且性能良好的偏好优化算法。其中表现最好的我们称之为发现偏好优化 (DiscoPOP)，这是一种自适应地混合逻辑和指数损失的新算法。实验证明了 DiscoPOP 的最先进的性能及其成功转移到保留任务。    提交人    /u/hardmaru   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deo4pd/r_can_llms_invent_better_ways_to_train_llms/</guid>
      <pubDate>Thu, 13 Jun 2024 02:18:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] H100 为学术研究探究而建</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dejlq5/d_h100_build_for_academic_research_inquiry/</link>
      <description><![CDATA[我知道有人会说“这需要专业人士”，但我想我还是会问。我的任务是配置几个 H100 服务器（8x HGX H100 SXM5）。目前，我所有的工作都是在 A100 和 L40 GPU 上完成的。 如果您打算在服务器上花费更多来训练/微调 LLM、扩散/流动模型，您会把它放在配置的哪里？CPU 升级？最大内存？用大量 NVMe 驱动器作为缓存加载它？ 现在我正在看 2x (Genoa) AMD EPYC 9634。我知道升级到 Bergamos 或 Intel Xeon Platinum（8480+、8490H、8592V）的成本更高，但对于我的用例，我认为我不会看到任何实际收益。看起来如果我使用英特尔，我可以获得高达 4TB 的 RAM，而 AMD 主板将我限制为 3 TB。  我被告知的经验法则是每 GB VRAM 对应 4 GB 内存，因此实​​际上对于我的用例而言 2.5-3TB 可能就足够了。  对于存储，我将仅使用 NVMe 驱动器作为缓存，因为我们已经有一个相当大的专用存储解决方案。     提交人    /u/ShotUnderstanding562   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dejlq5/d_h100_build_for_academic_research_inquiry/</guid>
      <pubDate>Wed, 12 Jun 2024 22:34:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] CycleGAN 为什么有效？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1degbf8/d_why_does_cyclegan_work/</link>
      <description><![CDATA[我知道这是一个不再流行的旧模型，但有人知道任何展示 CycleGAN 工作原理的作品吗？（即这篇论文：https://arxiv.org/abs/1703.10593）。很久以前，我尝试将这篇论文应用于数值问题，但无法让它发挥作用。从两个边际学习条件分布似乎很神奇。它是否有效，因为图像的结构非常独特？如果有人有任何答案或研究，我会很有兴趣了解更多。    提交人    /u/www3cam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1degbf8/d_why_does_cyclegan_work/</guid>
      <pubDate>Wed, 12 Jun 2024 20:13:41 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] TinyML 疑难解答</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deg43s/discussion_tinyml_troubleshooting/</link>
      <description><![CDATA[对于那些在资源受限的设备上进行机器学习的人，我有一个问题：当你遇到困难时，你会使用什么资源来摆脱困境？ 我最近在尝试将 TensorFlow 对象检测模型加载到微控制器中时遇到了一个挑战。由于原始模型太大，因此必须对该模型进行量化。这导致 tflite 和 tflite-micro 出现了几个问题，我花了几天时间才解决。虽然原始模型由于其大小而无法使用，但它至少在我的桌面（tflite）和微控制器（tflite micro）上产生了相同的预测。但是，对 tflite 模型应用全整数量化会导致微控制器上的 Python 输出和 C++ 输出不匹配。我看到其他人在论坛上遇到了类似的问题，但没有任何明确的解决方案。我最终没有使用全整数模型，因为准确度损失太大。相反，我按照 TensorFlow 网站上的 quantization_debugger 文档选择性地量化了模型。再次，输出不匹配。我花了几天时间为每一层打开和关闭量化，并尝试不同的组合，最后才终于解决了这个问题。 我从这次调试会话中得到的主要结论是，几乎没有资源可以解决这些问题。教程和文章很少，大多数论坛问题要么“由于不活动而被标记为过时”，要么没有回复，要么尚未解决。 我很好奇你们都觉得哪些资源有用。当你遇到障碍时，你是如何克服它的？我不相信其他人都像我一样摸索着。我的职业生涯才刚刚开始，所以我真的很感激任何建议或提示！    提交人    /u/selfhelpjunkie99   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deg43s/discussion_tinyml_troubleshooting/</guid>
      <pubDate>Wed, 12 Jun 2024 20:05:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] Grokking 的问题解决了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1defvmv/d_is_grokking_solved/</link>
      <description><![CDATA[最近的 Grokfast 论文 发现了一种将算法数据集的 Grokking 速度提高 50 倍的方法。早些时候的 Omnigrok 论文 指出，对于他们的算法数据集，“在恒定权重范数下的约束优化在很大程度上消除了 Grokking” 这些改进是否意味着现在我们在训练模型时不必担心延迟泛化/grokking（尽管其机制不明朗）？    提交人    /u/delorean-88   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1defvmv/d_is_grokking_solved/</guid>
      <pubDate>Wed, 12 Jun 2024 19:55:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我厌倦了 LangChain，所以我制作了一个简单的开源替代方案，支持工具使用和视觉，以尽可能轻松地构建 Python AI 应用程序。（simpleaichat + vision + anthropic 和 gemini）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deffo8/p_im_tired_of_langchain_so_i_made_a_simple/</link>
      <description><![CDATA[https://github.com/piEsposito/tiny-ai-client 构建 tiny-ai-client 的动机来自于对 Langchain 的失望，它变得臃肿、难以使用且文档不全 - 并从 simpleaichat 中汲取灵感，但除了 OpenAI（Gemini、Anthropic - Groq 和 Mistral 正在研发中）之外，还增加了对视觉、工具和更多 LLM 提供商的支持。 我构建它是为了延续 simpleaichat 的初衷，不是为了炒作、筹集资金或其他什么，而是为了帮助人们做两件事：尽可能轻松地构建 AI 应用程序，并在无需使用 Langchain 的情况下切换 LLM。 这是一个极简软件包的可行版本，支持视觉、工具和异步调用。还有很多改进要做，但即使在目前的状态下，tiny-ai-client 也普遍改善了我与 LLM 的交互，并已成功用于生产。 让我知道你的想法：仍有一些错误可能需要修复，但所有示例都可以正常工作并且易于适应你的用例。    提交人    /u/lee_from_teashop   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deffo8/p_im_tired_of_langchain_so_i_made_a_simple/</guid>
      <pubDate>Wed, 12 Jun 2024 19:36:58 GMT</pubDate>
    </item>
    <item>
      <title>CLASSP：一种通过调整抑制和稀疏性提升进行持续学习的生物启发方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1deazza/classp_a_biologicallyinspired_approach_to/</link>
      <description><![CDATA[  由    /u/Gold-Plum-1436  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1deazza/classp_a_biologicallyinspired_approach_to/</guid>
      <pubDate>Wed, 12 Jun 2024 16:33:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习系统工程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de9glz/d_ml_system_engineering/</link>
      <description><![CDATA[最近的 WWDC 活动展示了 Apple 非凡的系统工程，它允许使用用户友好的产品，同时仍设法使用资源密集型的设备语言模型（3-7B 参数）。这对我来说非常鼓舞人心，尤其是作为一名博士生，我的大多数项目最终都只是一篇研究论文！ 我在 ML、DL 和 RL 方面拥有良好的理论背景，并且对大多数最先进的方法有很好的了解。但是，我在使用 ML 进行后端决策的可部署产品方面没有任何经验。 我想知道这里的人是否可以为我指出一些好的资源，以便我更多地了解 ML 系统设计和 MLOps，也许还有一些项目的想法可以获得更多经验。    提交人    /u/Personal_Click_6502   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de9glz/d_ml_system_engineering/</guid>
      <pubDate>Wed, 12 Jun 2024 15:29:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] François Chollet 宣布新的 ARC 奖挑战——它是 AI 泛化的终极测试吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1de2b16/d_françois_chollet_announces_new_arc_prize/</link>
      <description><![CDATA[Keras 的创建者兼《使用 Python 进行深度学习》一书的作者 François Chollet 宣布了一项名为 ARC Prize 的新挑战，旨在解决 ARC-AGI 基准。对于那些不熟悉的人来说，ARC（抽象和推理语料库）旨在衡量机器从几个例子中进行概括的能力，模拟类似人类的学习。 以下是宣布挑战的推文：   ARC 基准对于当前的深度学习模型（包括我们今天看到的大型语言模型 (LLM)）来说非常困难。它旨在测试人工智能理解和应用抽象推理的能力——这是通用智能的一个关键组成部分。 很想知道这个社区对 ARC 挑战及其对人工智能研究的影响的看法。  ARC 是衡量人工智能泛化的良好指标吗？  与其他基准相比，您认为 ARC 基准在多大程度上反映了人工智能的泛化能力？ ARC 中是否存在任何固有的偏见或限制，可能会扭曲结果？  人工智能泛化的现状  当前模型在 ARC 上的表现如何，它们的主要局限性是什么？ 最近是否有任何突破或技术有望解决 ARC 挑战？  ARC 大奖挑战的潜在影响  这项挑战将如何影响 AI 未来的研究方向？ 为这一挑战开发的解决方案除了解决 ARC 特定任务之外，是否还有更广泛的应用？  策略和方法  您认为哪种方法可能有效解决 ARC 基准？ 是否存在任何未充分探索的领域或新颖的方法可能破解 ARC 代码？      提交人    /u/HairyIndi​​anDude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1de2b16/d_françois_chollet_announces_new_arc_prize/</guid>
      <pubDate>Wed, 12 Jun 2024 09:15:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>