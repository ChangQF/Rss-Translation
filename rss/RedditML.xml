<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sun, 07 Jul 2024 18:17:54 GMT</lastBuildDate>
    <item>
      <title>[D] 2D 到 3D 物体检测架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxn0e9/d_2d_to_3d_object_detection_architectures/</link>
      <description><![CDATA[大家好， 有人可以指导我如何将 2D 物体检测器转换为 3D 检测器吗？我可以简单地将 4 维 bbox 输出更改为 6 维输出吗？或者我需要更复杂的架构（如 BEVFormer 或类似架构）才能获得良好的性能？    提交人    /u/SeucheAchat9115   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxn0e9/d_2d_to_3d_object_detection_architectures/</guid>
      <pubDate>Sun, 07 Jul 2024 18:17:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关系数据中的 AI/ML 应用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxm0hz/d_aiml_applications_in_relational_data/</link>
      <description><![CDATA[我有一个包含大量表和列的数据库，并且它们之间的关系是已知的。 根据对数据模型的理解，我们实施了多项基于规则的数据质量检测。 但是，使用机器学习可以构建哪些可能的用例？关系数据中的可能应用程序有哪些。 或者，如果事先知道逻辑和规则，基于规则的检查是否是最好的。 我想学习和阅读有关关系数据中 AI/ML 用例的更多信息。如果有人可以指出有关用例以及如何实现用例的正确文章/方向，那将会很有帮助。 谢谢    提交人    /u/rekonist-app   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxm0hz/d_aiml_applications_in_relational_data/</guid>
      <pubDate>Sun, 07 Jul 2024 17:34:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 添加多个 GPU 是否会同时线性增加 FLOP 速率和 VRAM 内存带宽？如果不是，随着利用率的增加，利用率是多少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxlll2/d_does_adding_multiple_gpus_increase_both_the/</link>
      <description><![CDATA[我正在尝试优化我的 LLM 服务器的 AWS 消耗，我很好奇在 TTFT、TPOT 和每小时总成本方面，拥有 4X 或 8X AMD Radeon Pro V520 意味着什么。对于我的指标估计，我遵循 https://www.jinghong-chen.net/estimate-vram-usage-in-llm-inference/。但是，我想了解是否可以通过堆叠更多 GPU 来线性增加 FLOPS 速率和 VRAM 带宽。谢谢。  我的理解是存在某种模型带宽和模型 flops 利用率。我已经看到 8X H100-80gb 有 25% 的 MBU。我希望我可以更好地理解如何在不消耗太多现金的情况下估算这些曲线。 PD：此外，我希望我可以更深入地了解该主题，如果您能给我指出一些有关该主题的入门知识，我将不胜感激。    提交人    /u/automated_msp   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxlll2/d_does_adding_multiple_gpus_increase_both_the/</guid>
      <pubDate>Sun, 07 Jul 2024 17:17:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如果提供微调 API，则可以通用地越狱 LLM 的安全输入和输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxiqhh/r_a_universal_way_to_jailbreak_llms_safety_inputs/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxiqhh/r_a_universal_way_to_jailbreak_llms_safety_inputs/</guid>
      <pubDate>Sun, 07 Jul 2024 15:11:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Llama 创建 DPO 数据集：最佳实践？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxh210/d_creating_a_dpo_dataset_using_llama_best/</link>
      <description><![CDATA[我要创建一个合成 DPO 数据集来微调 Llama-3-8b。我是否可以只将 Llama-3-70 的响应用作“已接受”而将 Llama-3-8b 的响应用作“已拒绝”？或者更好的方法是从 Llama-3-8b 中抽取两个响应，并将其中一个选为已接受，另一个选为已拒绝。    提交者    /u/AdKind316   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxh210/d_creating_a_dpo_dataset_using_llama_best/</guid>
      <pubDate>Sun, 07 Jul 2024 13:54:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] ReproModel：开源 ML 研究工具箱更新！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxgt56/p_repromodel_open_source_ml_research_toolbox/</link>
      <description><![CDATA[大家好，我很高兴与大家分享 ReproModel 的最新动态，这是一个开源工具箱，旨在简化机器学习模型的测试和复制。 我和你们中的许多人一样，在对模型进行基准测试和比较方面遇到了很多困难，从缺少代码到不透明的实验参数减慢了进程。我决定自己动手，在我的工作场所创建了一个迷你工具箱来简化这个过程。 目标是减少复制实验所花费的时间和精力，使研究人员能够专注于创新而不是设置。 我知道这项任务并不容易，不久前我联系了社区，并获得了巨大的帮助。在团队的努力下，我们现在已经在已经实现的功能中添加了代码提取器、AI 实验描述生成器和自定义脚本编辑器。 该项目是开源的，如果您喜欢我们正在构建的内容，欢迎与我们分享您的想法、做出贡献或留下一颗星 :) 您可以在此处找到存储库：https://github.com/ReproModel/repromodel 感谢您的时间，请随时在下面留下任何意见或建议！    提交人    /u/MintOwlTech   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxgt56/p_repromodel_open_source_ml_research_toolbox/</guid>
      <pubDate>Sun, 07 Jul 2024 13:42:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在深度模型上进行“深度工作”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxg0jg/d_deepwork_while_working_on_deep_models/</link>
      <description><![CDATA[大家好， 我最大的生产力挑战之一是等待深度学习训练循环、标记化或处理循环运行时的停机时间。对于较短的循环，这些循环可能需要 5 分钟到一个小时的时间，在此期间，我常常发现自己不知道该做什么。 开始一项新任务很困难，因为不断的上下文切换会打乱我的工作流程和注意力。 我以前在大学里遵循深度工作方法，这确实有助于控制我的注意力缺陷多动障碍。我白天不使用手机或社交媒体，一次只“专注于”一项任务。 现在，我觉得这几乎是不可能的。我“被迫”休息这些小憩，不断在任务之间切换，这非常具有挑战性。 您对如何充分利用这些间隔有什么建议吗？你会为这些时间段保留特定任务吗？ 即使从专注编码切换到阅读论文，如果只花 10 分钟左右的时间，也会非常困难。 有人解决过这些问题吗，还是只有我？ 谢谢。    提交人    /u/Magnospm   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxg0jg/d_deepwork_while_working_on_deep_models/</guid>
      <pubDate>Sun, 07 Jul 2024 13:02:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人使用过或知道任何实时说话人分类模型吗？我尝试过 diart 和 Ecapa tdnn 模型，但它们不太准确。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxduy9/d_anyone_used_or_know_any_real_time_speaker/</link>
      <description><![CDATA[我正在寻找一些准确的实时说话人分类开源模型，关键词是准确。有人尝试过类似的东西吗？也请告诉我开源和付费 API。    提交人    /u/Just_Difficulty9836   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxduy9/d_anyone_used_or_know_any_real_time_speaker/</guid>
      <pubDate>Sun, 07 Jul 2024 10:55:39 GMT</pubDate>
    </item>
    <item>
      <title>Coreweave 为什么存在？ - [讨论]“[D]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxbr0a/why_does_coreweave_exist_discussion_d/</link>
      <description><![CDATA[最近偶然发现了 Coreweave 作为一些 LLM 工作的选择。我仍然不太明白 Coreweave 存在的原因，除非是因为在芯片短缺时他们获得了一些 NVDA 容量。 他们的 kubernetes 基础设施有什么不同？这基本上是一个由一个供应商管理的超大规模器 + NVDA 芯片吗？他们的技术堆栈有什么不同？ 也希望听到使用它们的经验。 请不要跟我说 NVDA 购买收入阴谋论。    提交人    /u/HeadofMacro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxbr0a/why_does_coreweave_exist_discussion_d/</guid>
      <pubDate>Sun, 07 Jul 2024 08:29:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 拥有使用 ONNX 或 openVino 提供模型的经验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxbcue/d_experience_serving_models_with_onnx_or_openvino/</link>
      <description><![CDATA[到目前为止，我一直使用 torch 脚本来提供我的模型（主要是 CNN 和对象检测模型）。这样做的缺点是这些模型只能在 python 环境中执行，并且对 pytorch 有相当大的依赖性。 我正在研究使用 openVino 或 ONNX 来优化模型服务。对我来说重要的因素是  可以用任何语言执行 CPU 和 GPU 支持推理  推理速度，特别是在 CPU 上  您是否使用过这两种方法？什么对您有用/没用？    提交人    /u/Xayo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxbcue/d_experience_serving_models_with_onnx_or_openvino/</guid>
      <pubDate>Sun, 07 Jul 2024 08:02:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 识别歌曲中的音符（librosa）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxa84z/r_identify_notes_in_a_song_librosa/</link>
      <description><![CDATA[我试图通过歌手的声音识别歌曲中的音符。我使用的是 librosa。当我使用 ypin 算法进行音高检测并使用 hz_to_note 将音高转换为音符时，是否由于音高估计中的噪声 - 音符可能被错误地识别为 C2，而实际上它只是 C2#。对于实际上更接近 C2# 但最终低于其基频的值，该函数会将其分配给音符 C2。 我该如何解决这个问题？是否有其他方法/库可以对几乎只是人声的音频进行音高检测？任何见解都值得赞赏！    提交人    /u/perfectlylonely13   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxa84z/r_identify_notes_in_a_song_librosa/</guid>
      <pubDate>Sun, 07 Jul 2024 06:43:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于 Mamba 的语言模型实证研究（8B Mamba-2-Hybrid 在 3.5T token 数据上）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dx9ggp/r_an_empirical_study_of_mambabased_language/</link>
      <description><![CDATA[链接：http://arxiv.org/abs/2406.07887  选择性状态空间模型 (SSM)（如 Mamba）克服了 Transformers 的一些缺点，例如序列长度的二次计算复杂度和键值缓存的大量推理时间内存要求。此外，最近的研究表明，SSM 可以匹配或超越 Transformers 的语言建模能力，使其成为一种有吸引力的替代方案。然而，在受控设置（例如相同的数据）中，迄今为止的研究仅展示了将 SSM 与 Transformers 进行比较的小规模实验。为了了解这些架构在更大规模上的优势和劣势，我们直接比较了在多达 3.5T 个 token 的相同数据集上训练的 8B 参数 Mamba、Mamba-2 和 Transformer 模型。我们还将这些模型与由 43% Mamba-2、7% 注意力和 50% MLP 层 (Mamba-2-Hybrid) 组成的混合架构进行了比较。使用一组不同的任务，我们回答了 Mamba 模型是否可以在更大的训练预算下与 Transformers 匹敌的问题。我们的结果表明，虽然纯 SSM 在许多任务上与 Transformers 匹敌或超过 Transformers，但它们在需要强大复制或上下文学习能力（例如 5-shot MMLU、电话簿）或长上下文推理的任务上落后于 Transformers。相比之下，我们发现 8B Mamba-2-Hybrid 在我们评估的所有 12 个标准任务上都超过了 8B Transformer（平均 +2.65 分），并且预计在推理时生成 token 时速度最高可提高 8 倍。为了验证长上下文能力，我们提供了额外的实验，评估 Mamba-2-Hybrid 和 Transformer 的变体，以支持 16K、32K 和 128K 序列。在另外 23 个长上下文任务中，混合模型继续接近或平均超过 Transformer。为了进一步研究，我们发布了检查点以及用于训练我们模型的代码，作为 NVIDIA Megatron-LM 项目的一部分。     submitted by    /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dx9ggp/r_an_empirical_study_of_mambabased_language/</guid>
      <pubDate>Sun, 07 Jul 2024 05:52:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dx5tpo/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dx5tpo/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 07 Jul 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] Pytorch XLA/TPU 上有任何 mamba（或其他 SSM）的实现吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dx50pv/d_any_implementations_of_mamba_or_other_ssm_on/</link>
      <description><![CDATA[mamba_ssm 无法安装在我的 TPU VM 上，因为没有 nvcc。     提交人    /u/daking999   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dx50pv/d_any_implementations_of_mamba_or_other_ssm_on/</guid>
      <pubDate>Sun, 07 Jul 2024 01:31:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 扩散强制：下一个标记预测与全序列扩散相遇</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwkces/r_diffusion_forcing_nexttoken_prediction_meets/</link>
      <description><![CDATA[        由    /u/Rose52152   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwkces/r_diffusion_forcing_nexttoken_prediction_meets/</guid>
      <pubDate>Sat, 06 Jul 2024 07:43:56 GMT</pubDate>
    </item>
    </channel>
</rss>