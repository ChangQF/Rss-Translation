<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Thu, 04 Apr 2024 12:24:06 GMT</lastBuildDate>
    <item>
      <title>[D] rx7900 GRE 上的机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvkt5t/d_ml_on_an_rx7900_gre/</link>
      <description><![CDATA[有人在 7900 gre 上尝试过 ml 我打算买一个，因为它的价格与我国家的 4070 相当，并且有更大的显存.   由   提交/u/saksham7799  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvkt5t/d_ml_on_an_rx7900_gre/</guid>
      <pubDate>Thu, 04 Apr 2024 11:32:15 GMT</pubDate>
    </item>
    <item>
      <title>[D]机器学习和人工智能的未来是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvkr1u/dwhat_is_the_future_of_ml_and_ai/</link>
      <description><![CDATA[我的意思是每个人都害怕人工智能抢走他们的工作。但人工智能将如何抢走人工智能制造者的工作呢？您对机器学习作为职业道路的未来有什么看法？   由   提交 /u/AromaticEconomics113   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvkr1u/dwhat_is_the_future_of_ml_and_ai/</guid>
      <pubDate>Thu, 04 Apr 2024 11:28:57 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 接受研究ML职位的降薪，这通常是一个好的举动吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvj56a/discussion_accepted_a_salary_drop_for_a_ml/</link>
      <description><![CDATA[我于 2020 年从法国一所优秀大学（最好的大学之一，但不是最好的大学）毕业，获得了人工智能硕士学位。 我在一家美国科技公司（巴黎办事处）的数字营销领域工作了 3 年，担任数据科学家，一开始确实很酷，但这份工作很快就变得多余，更多的是软件工程而不是真正的数据科学，并且诚实、简单，足以由本科生完成，所有这一切都没有任何进化论的观点。我们开发的产品销量不够，最后全球气氛紧张。虽然福利很好，而且大多数人都很好，但团队中的每个数据科学家最终都离开了公司，我也是。 我有机会加入一个新的人工智能公共研究中心，作为一名研究机器学习工程师。这是我重返人工智能领域的绝佳机会。 该中心自 2020 年成立，内部成立了一个工程师团队，旨在：  帮助研究人员将他们的成果产业化通过支持他们开发开源包来进行研究 帮助组织活动以推广中心（暑期学校、黑客马拉松、研讨会等） 我的职位还包括监督该中心的创新部门，更准确地说，是支持该中心的合作机构创建的初创企业。  表面上，这份工作非常适合我，但是：   p&gt;  在 6 个月的时间里，我刚刚贡献了 2 个软件包，其中有一些小的贡献，例如重构、测试实现、文档等。没有真正的人工智能，而是人工智能项目的基本软件工程。这些项目真的很酷，研究人员也很优秀，但这些软件包并没有被经常使用，从我的角度来看，我的影响似乎很轻。 工程团队的成员，尤其是团队领导并不资深。个人资料和经验比我少，学位选择性也较差。此外，我与他们相处得并不融洽，而且没有团队合作，因为每个人都与不同的研究人员一起研究他的项目。 我们应该支持的初创公司似乎并不真正感兴趣在我们的支持下，他们通常会寻求我们团队中可能不具备的真正特定技能，并且为他们创造价值很复杂。 我们没有合适的办公室（没有为每个人提供的显示器，而且办公室是一个会议室改造成的一个开放空间），而我去那里的通勤往返需要3小时（必须每周2次）。此外，他们还给了我一台 13 英寸 MacBook Air，并告诉我，自从我到达那里后，我将拥有最新的 MacBook Pro，但每周都会推迟。 我接受了大幅降薪（10 %)  如果那里有高级机器学习工程师/数据科学家，我真的很想听听您对此的看法。   由   提交/u/brash69  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvj56a/discussion_accepted_a_salary_drop_for_a_ml/</guid>
      <pubDate>Thu, 04 Apr 2024 09:48:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士正在损害人工智能研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</link>
      <description><![CDATA[这是一个大胆的主张，但我觉得 LLM 的炒作早就该消退了。 GPT4 之后，LLM 性能和设计改进不仅取得了相对较小的进展：使其变得更好的主要方法仍然只是使其更大，并且所有 Transformer 的替代架构都被证明是低于标准和劣质的，它们引起了人们的关注（并且投资）远离其他可能更具影响力的技术。与此同时，大量涌入的人甚至不知道基本的机器学习是如何工作的，他们自称是“人工智能研究员”。因为他们使用 GPT 让每个人在本地托管一个模型，试图让你相信“语言模型完全可以推理”。我们只需要另一个 RAG 解决方案！”他们加入这个社区的唯一目标不是开发新技术，而是利用现有技术拼命拼凑出一项有利可图的服务。甚至论文本身也开始主要由法学硕士撰写。我不禁认为整个领域可能会陷入停滞状态，因为不断增长的社区满足于平庸的修复，这些修复充其量只能使模型在任意“分数”上的得分稍微好一些。他们弥补了这一点，忽略了诸如幻觉、上下文长度、基本逻辑缺乏能力以及运行这种规模模型的高昂成本等明显问题。我赞扬那些不顾市场炒作而致力于开发能够实现真正逻辑过程的代理的人们，并希望很快会引起更多关注。   由   提交/u/NightestOfTheOwls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</guid>
      <pubDate>Thu, 04 Apr 2024 08:36:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] JAX 和 Pytorch 专家混合实现（不是稀疏 MoE，而是“旧”类型）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvhlhd/d_jax_and_pytorch_implementations_of_mixture_of/</link>
      <description><![CDATA[大家好， 由于稀疏门控 MoE 层的爆炸式增长并利用“条件计算”来加速推理/近年来在法学硕士学习中，我很难根据这样的论文找到老式专家混合架构的代码实现： &quot;在专家的深度混合中学习因子表示” (Eigen, Ranzato, Sutskever 2013) ​ 通常当你搜索“Mixture of Experts Layer github”时所有热门都是最新的稀疏门控 MoE 内容——这很棒，但不是我想要的。 通过阅读 Eigen 等人上面的论文，我确信会实现它不会太难，但我想问是否有人知道这种类型的 MoE 的开源、现成的 JAX 或 Pytorch 实现？简而言之：您有一批来自输入的线性层 --&gt;输出，然后是来自输入的门控网络 --&gt;每个线性层输出的加权系数。然后使用这些权重作为混合系数对输出进行平均。需要明确的是：我并不是在寻找稀疏的 MoE 层实现（通常利用自定义“调度程序”的奇特东西，因此您一次只能激活模型的一部分），而只是一个标准的“密集”层实现。按照我刚才描述的方式混合专家层。 任何帮助将不胜感激！提前致谢。   由   提交/u/mccl30d  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvhlhd/d_jax_and_pytorch_implementations_of_mixture_of/</guid>
      <pubDate>Thu, 04 Apr 2024 08:00:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视觉自回归建模：通过下一代预测生成可扩展图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvh8ep/d_visual_autoregressive_modeling_scalable_image/</link>
      <description><![CDATA[      ​ https://preview.redd.it/12c372dv0fsc1.png?width=2833&amp;format=png&amp; ; auto=webp&amp;s=0d88f98929854f3de18b8c623d3aff5a7ed14b79 摘要：  我们提出了视觉自回归建模（VAR），一种新一代范式它将图像的自回归学习重新定义为从粗到细的“下一尺度预测”或“下一分辨率预测”，与标准光栅扫描“下一标记预测”不同。这种简单、直观的方法使自回归 (AR) 转换器能够快速学习视觉分布并很好地概括：VAR 首次使 AR 模型在图像生成方面超越了扩散转换器。在 ImageNet 256x256 基准上，VAR 通过将 Frechet 起始距离 (FID) 从 18.65 提高到 1.80、起始分数 (IS) 从 80.4 提高到 356.4，显着改善了 AR 基线，推理速度提高了约 20 倍。实证还验证了 VAR 在图像质量、推理速度、数据效率和可扩展性等多个维度上均优于 Diffusion Transformer (DiT)。扩大 VAR 模型表现出清晰的幂律缩放定律，与法学硕士中观察到的相似，线性相关系数接近 -0.998，这是确凿的证据。 VAR 进一步展示了下游任务中的零样本泛化能力，包括图像内画、外画和编辑。这些结果表明 VAR 最初模拟了法学硕士的两个重要属性：缩放定律和零样本任务泛化。我们已经发布了所有模型和代码，以促进 AR/VAR 模型在视觉生成和统一学习方面的探索。  Arxiv: https://arxiv.org/abs/2404.02905 Github： https://github.com/FoundationVision/VAR   由   提交 /u/ExponentialCookie   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvh8ep/d_visual_autoregressive_modeling_scalable_image/</guid>
      <pubDate>Thu, 04 Apr 2024 07:33:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 就是您所需要的吗？看看检索增强的局限性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvgyf1/d_is_rag_all_you_need_a_look_at_the_limits_of/</link>
      <description><![CDATA[检索增强生成 (RAG) 是将法学硕士投入生产的最流行、最有效的技术之一。它于 2021 年由一篇 Meta 论文 提出，自那以后，它迅速发展并发展成为一个本身的领域，受到以下直接好处的推动：它提供：降低产生幻觉的风险、获取最新信息等等。最重要的是，RAG 因其提供的优势而实施起来相对便宜，特别是与 LLM 微调等昂贵的技术相比。这使得它对于很多用例来说都是理所当然的，以至于现在每个在生产中使用 LLM 的生产系统似乎都是作为某种形式的 RAG 来实现的。  这是一篇由 Deepset 的 NLP 工程师、Haystack 核心维护者 Sara Zanzottera 撰写的精彩文章。来源：https://opendatascience。 com/is-rag-all-you-need-a-look-at-the-limits-of-retrieval-augmentation/  &amp;# 32；由   提交/u/Data_Nerd1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvgyf1/d_is_rag_all_you_need_a_look_at_the_limits_of/</guid>
      <pubDate>Thu, 04 Apr 2024 07:14:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使视觉合成数据看起来更真实的网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvg32z/d_networks_that_make_visual_synthetic_data_look/</link>
      <description><![CDATA[我经常听说 Blender 或视频游戏引擎生成的合成数据（至少是视觉数据）的问题是它们不够真实实现现实世界的可移植性。 但是有没有任何作品可以将这些合成图像通过网络传递，使它们看起来更真实，并使用它们来训练模型？ 我更指的是到像这个旧视频这样的网络，他们将其应用到 GTA V 镜头中，使其看起来更真实。   由   提交 /u/notEVOLVED   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvg32z/d_networks_that_make_visual_synthetic_data_look/</guid>
      <pubDate>Thu, 04 Apr 2024 06:16:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 ML 社区中建立联系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvat6l/d_how_to_create_contacts_in_the_ml_community/</link>
      <description><![CDATA[我想知道在 ML 社区中创建联系人的最佳方式是什么，因为我不确定从哪里开始以及这些方式在寻找时有多重要为了在该行业找到一份工作。当然，在 LinkedIn 上添加一些联系人也没什么坏处。有什么建议吗？   由   提交 /u/mmenendezg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvat6l/d_how_to_create_contacts_in_the_ml_community/</guid>
      <pubDate>Thu, 04 Apr 2024 01:36:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自动化超参数选择</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bv8x3r/p_automating_hyperparameter_selection/</link>
      <description><![CDATA[大家好！我昨天在这里发布了关于另一个项目的信息，并得到了非常有用的反馈，所以我想我应该发布关于我一直在从事的另一个项目的信息。我真的不知道这是否存在（老实说，可能确实存在），但我开发了一个简单的程序，没有机器学习经验的人可以提供 CSV 数据，它会自动选择超参数并根据数据训练前馈神经网络。我不会撒谎说它总是选择最好的参数，因为通常它实际上并没有选择很好的参数，但我希望您能检查一下并提供一些反馈。以下是 github 存储库的链接： https://github.com/jakeSteinburger/autoParam 它仍处于早期阶段，我觉得它已经存在，但我真的很喜欢你完全诚实的反馈。提前致谢！   由   提交 /u/JakeStBu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bv8x3r/p_automating_hyperparameter_selection/</guid>
      <pubDate>Thu, 04 Apr 2024 00:12:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] RLHF 真的有效吗？你为什么用它？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bv2jgm/d_does_rlhf_really_work_why_do_you_use_it/</link>
      <description><![CDATA[我尝试过自己做 RLHF。使用以下库： https://huggingface.co/docs/trl/en/index&lt; /a&gt;  在示例之外，它不起作用。  是否有人成功使用 RLHF（学术界之外）或正在为此苦苦挣扎？  您可以分享的任何具体用例都会有所帮助。    由   提交 /u/iordanissh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bv2jgm/d_does_rlhf_really_work_why_do_you_use_it/</guid>
      <pubDate>Wed, 03 Apr 2024 19:58:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么股票预测论文没有投入生产？ [D] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bv0cu7/why_stock_prediction_papers_arent_put_to/</link>
      <description><![CDATA[我最近一直在查看股票预测研究论文，并对他们所取得的成就感到惊讶。虽然这些研究看起来很有希望，但我不确定它们是否能应用于现实生活……这几乎就像是美好得令人难以置信的场景。任何人都想对此有所了解。   由   提交/u/Pomelo-Actual   /u/Pomelo-Actual reddit.com/r/MachineLearning/comments/1bv0cu7/why_stock_prediction_papers_arent_put_to/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bv0cu7/why_stock_prediction_papers_arent_put_to/</guid>
      <pubDate>Wed, 03 Apr 2024 18:36:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 只是美化了即时工程吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1busp41/d_is_rag_just_glorified_prompt_engineering/</link>
      <description><![CDATA[您会收到提示、IR 相关文档，将它们发送到提示，然后 LLM 会生成响应。我们刚刚设计了提示以提供更多信息。   由   提交 /u/RiseWarm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1busp41/d_is_rag_just_glorified_prompt_engineering/</guid>
      <pubDate>Wed, 03 Apr 2024 13:32:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过预消除使 KNN 更加高效</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bupi0p/p_making_knn_more_efficient_with_preelimination/</link>
      <description><![CDATA[大家好，我一直在从事一个小项目，我希望获得一些完全诚实的反馈。 KNN 是一种非常强大的算法，但不幸的是，它的效率也非常低，并且运行起来非常耗费资源。我一直在研究一个项目，根据一些基本测试，该项目平均比普通 KNN 快 20% 左右，而且质量几乎没有下降。您可以在此处查看 github 存储库： https://github.com/jakeSteinburger/peKNN&lt; /p&gt; 我还为此写了一篇小型论文，链接在存储库上。如果代码有点混乱，我很抱歉，但除此之外，我真的很喜欢你完全诚实的反馈（我知道 Reddit 很擅长这一点）。提前致谢！   由   提交 /u/JakeStBu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bupi0p/p_making_knn_more_efficient_with_preelimination/</guid>
      <pubDate>Wed, 03 Apr 2024 10:47:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>