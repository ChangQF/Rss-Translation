<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 04 Dec 2023 15:14:33 GMT</lastBuildDate>
    <item>
      <title>我是新来的，但这似乎太好了，无法不分享。对此大家有何看法呢？ 4M：大规模多模态掩模建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18am683/i_am_new_here_but_this_seemed_too_good_not_to/</link>
      <description><![CDATA[ 由   提交 /u/Dullydude   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18am683/i_am_new_here_but_this_seemed_too_good_not_to/</guid>
      <pubDate>Mon, 04 Dec 2023 15:08:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024年机器学习研究热点是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18am0tx/d_whats_hot_for_machine_learning_research_in_2024/</link>
      <description><![CDATA[ML 中或与 ML 相关的哪些子领域/方法、应用领域预计将在 2024 年获得广泛关注（双关语无意）？&lt; /p&gt; PS：请不要回避提出您可能认为或知道的任何可能成为机器学习研究热门主题的内容，很可能您所知道的内容对于我们这里的许多人来说可能是未知的:)   由   提交 /u/ureepamuree   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18am0tx/d_whats_hot_for_machine_learning_research_in_2024/</guid>
      <pubDate>Mon, 04 Dec 2023 15:01:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] 构建下一代法学硕士（GPT）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18am0d8/p_building_the_nextgen_llm_gpt/</link>
      <description><![CDATA[亲爱的 r/MachineLearning 成员，  由于与 Microsoft 的“合作伙伴关系”，我收到了 25,000 美元的 OpenAI 积分，可以随时使用。我可以访问最好的 OpenAI 模型，包括 GPT4-8k 和 GPT4-32k。 我决定使用这些积分来基于原始 ShareGPT 数据集创建高质量的问答数据集。我本质上要做的就是删除原始数据集中存在的所有答案，只留下问题，将它们输入 GPT-4 并接收更高质量的响应和结果。保存它。 我的目标是创建比 ChatGPT 更好的东西。 ChatGPT 目前是一个“觉醒”模型，它会因为说出种族歧视言论而选择杀死 10 亿人 (如 X 所示）。您可以将我理想的模型想法视为 GPT-4 和 pi.ai by Inflection 的混合 - 不唤醒，有点友好，并且在响应信息方面更先进。 现在，我需要您的帮助;我希望您问自己，作为客户，您在使用 ChatGPT 时错过的主要事情之一是什么。更重要的是，作为开源社区的成员，您欣赏的法学硕士尚未实现的最重要的功能是什么？更好的是，您知道如何实施它吗？另外，尝试考虑使用积分来实现此目标的其他方法，也许 ShareGPT 数据集根本不是最佳选择！也许重新开始是一个更好的选择？ 我已经就模型应如何响应以及应具有哪些功能制定了一些计划。以下是我的一些想法：  实施互联网搜索 - 教导模型正确理解从网络上抓取的数据并接收最佳响应 - 已经经过测试，轻松克服困惑.ai，甚至是 Bing（笑）和其他领先的搜索引擎，在使用 GPT4-32k 以及自定义系统消息和 Google 搜索结果时。 教模型以您的名字称呼您以获得更个性化的体验（可以关闭）。 实施响应长度模式 - 有些人喜欢细节，其他人希望快速得到答案，而模型不会“大喊大叫”。  这3个可以100%实现。我有数百万个不同的想法，比如长期记忆或个性化，但说实话，我不太确定如何实现它。 此外，与数据集无关，而是在模型之后经过培训后，我计划实现一项隐私功能，其中与模型的对话将进行端到端加密，此外还将添加 ElevenLabs 以获得最佳 TTS，以增强对话体验。 现在是所有关于微调数据集的内容。数据集越好，微调模型产生的响应就越好。 对于像我这样的 17 岁年轻人来说，25,000 美元是一笔巨款，而且这是一次创造一些伟大而精彩的东西的机会。有用。跳出框框思考是实现这一目标的第一步。 提前感谢您的任何建议。我将在这里以及 X (@vojtechcekal) 上发布有关此项目的定期更新。   由   提交/u/Business-Lead2679  /u/Business-Lead2679 reddit.com/r/MachineLearning/comments/18am0d8/p_building_the_nextgen_llm_gpt/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18am0d8/p_building_the_nextgen_llm_gpt/</guid>
      <pubDate>Mon, 04 Dec 2023 15:01:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] Comgra：用于调试和理解神经网络的库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18akicn/p_comgra_a_library_for_debugging_and/</link>
      <description><![CDATA[我是一名机器学习工程师和研究员。我厌倦了理解神经网络的行为方式是多么困难，所以我编写了一个库来帮助解决这个问题。 Comgra（计算图分析） 是一个库，您可以与 pytorch 一起使用来提取您关心的所有张量数据，并在浏览器中以图形方式将其可视化。 这允许比使用张量板的通常方法更详细地分析正在发生的情况。您可以在训练过程中研究张量、深入研究单个神经元、检查您特别感兴趣的单个数据集、跟踪梯度、比较不同训练运行之间的统计数据等等。 该工具具有通过让我比平时更快地检查我的假设并帮助我了解网络的不同部分如何真正相互作用，节省了我大量的研究时间。 我希望这个工具可以拯救其他人和我一样多的时间。我也欢迎有关如何进一步改进它的建议：由于我已经收集并可视化了大量网络信息，因此添加更多自动化分析不会带来太多额外工作。   由   提交 /u/Smart-Emu5581   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18akicn/p_comgra_a_library_for_debugging_and/</guid>
      <pubDate>Mon, 04 Dec 2023 13:45:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 买英伟达还是AMD？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18akbn1/d_buy_invidia_or_amd/</link>
      <description><![CDATA[大家好，我是一名CS专业的学生，​​我开始对AI和ML感兴趣， 我应该买什么卡那是在 500 美元的价格范围内吗？ AMD GPU 确实提供有竞争力的价格，但我听说它们有兼容性问题，我应该非常担心吗？  另外，如果您推荐 Invidia，我应该选择 3060 12gb 还是 4060 ti 16gb？ 4060ti 16gb 贵了 150 美元。   由   提交/u/3mwo2  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18akbn1/d_buy_invidia_or_amd/</guid>
      <pubDate>Mon, 04 Dec 2023 13:35:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 即将推出的无隐藏状态的反应式 Python+SQL 笔记本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18akbc6/p_an_up_and_coming_reactive_pythonsql_notebook/</link>
      <description><![CDATA[    &lt; /a&gt;  该项目仍处于早期阶段，因此请让我们知道您的反馈！以下是快速预览： 零真演示 如果您想查看我们的 github：https://github.com/Zero-True/zero-true   由   提交/u/zero-true  /u/zero-true reddit.com/r/MachineLearning/comments/18akbc6/p_an_up_and_coming_reactive_pythonsql_notebook/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18akbc6/p_an_up_and_coming_reactive_pythonsql_notebook/</guid>
      <pubDate>Mon, 04 Dec 2023 13:34:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些工具可以用于观察和监控生产中的 AI 模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18aicst/d_what_are_some_tools_for_observing_and/</link>
      <description><![CDATA[有许多机器学习监控和可观察性工具，但我们是否有为生产中的 AI 模型构建用于观察和监控的特定工具？或者任何开源库？   由   提交/u/Aromatic_Ad9700   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18aicst/d_what_are_some_tools_for_observing_and/</guid>
      <pubDate>Mon, 04 Dec 2023 11:35:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调基础模型时的图像和图像标题策略？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18acct2/d_strategy_for_images_and_image_captions_when/</link>
      <description><![CDATA[我想微调文本到图像模型以了解与我一起工作的人的某些面孔。我做了一些实验，我可以得到一些让人想起一个人的图像，但实际上看起来并不像他们。我还需要在提示中提供比我预期更多的内容。 例如，有一个人是一个留着小胡子、戴着眼镜的大个子。我使用他的几张图像进行了微调，标题是他在训练数据集中的真实姓名。 当我生成以他的名字为主题的图像时，没有一张脸上有胡子或眼镜。如果我提示“留着小胡子、戴眼镜的马克·史密斯正在做 xyz”它看起来确实有点让人想起他，但仍然不太正确。 我应该采取什么策略来改进这一点？我需要更多他的照片吗？我是否应该将他的名字（或类似的名字）散列到通用标题中，以确保模型中的其他权重不会干扰？还有其他想法吗？ 我意识到我可以尝试，但不断微调的成本非常高，而且我不想多次走错方向。   由   提交/u/coinclink  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18acct2/d_strategy_for_images_and_image_captions_when/</guid>
      <pubDate>Mon, 04 Dec 2023 04:32:53 GMT</pubDate>
    </item>
    <item>
      <title>[P] 没有 Autograd 的教育变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18aaxfj/p_educational_transformer_without_autograd/</link>
      <description><![CDATA[我学习 NLP 一段时间了，总是发现很难找到具有显式前向和反向传播的 Transformer 的完整实现。这个项目是我在学习如何更好地理解 Transformers 中的优化的同时构建它的尝试。 它有尽可能详细的文档记录，并且可以通过编辑config.py 文件并运行 run.py 脚本。获取代码： git clone https://github.com/eduardoleao052/Transformer-from-scratch.git  我成功生成了一些在儒勒凡尔纳和莎士比亚的作品上训练这个模型的文本非常好。希望您喜欢！ GitHub 存储库此处！   由   提交 /u/suspicious_beam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18aaxfj/p_educational_transformer_without_autograd/</guid>
      <pubDate>Mon, 04 Dec 2023 03:12:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用嵌入生成主题以进行主题建模的包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18a9qvv/d_package_that_uses_embeddings_to_generate_topics/</link>
      <description><![CDATA[我在 Python 中使用过 Bertopic 和 Top2Vec，但我想知道 R 中是否有类似的东西可以使用预训练模型来生成主题？如果没有，您认为投入时间构建这样的东西对社区有用吗？   由   提交 /u/NewerResearcher   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18a9qvv/d_package_that_uses_embeddings_to_generate_topics/</guid>
      <pubDate>Mon, 04 Dec 2023 02:09:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于分段任意模型的所有有趣的事情</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18a9agl/d_everything_interesting_about_the_segment/</link>
      <description><![CDATA[      分享我的 ML YouTube 频道中关于 Meta 的 Segment Anything 模型的视频，如何实现它的工作原理、训练方式以及部署方式。为感兴趣的人留下链接！   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18a9agl/d_everything_interesting_about_the_segment/</guid>
      <pubDate>Mon, 04 Dec 2023 01:45:59 GMT</pubDate>
    </item>
    <item>
      <title>[R]大型变压器模型推理优化（Lilian Weng，2023）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18a64mb/r_large_transformer_model_inference_optimization/</link>
      <description><![CDATA[ 由   提交/u/niplav  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18a64mb/r_large_transformer_model_inference_optimization/</guid>
      <pubDate>Sun, 03 Dec 2023 23:08:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您在研究中引用了 Arxiv 预印本吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18a5hd7/r_do_you_cite_arxiv_preprints_in_your_research/</link>
      <description><![CDATA[机器学习研究人员大家好！ 一些背景信息： 我正在写一篇调查论文（调查+拟议的研究方向）。它一直在不断发展，包括新的发展。没什么新奇的。我远离学术界，在一家初创公司担任科学家。 现实是：由于我的日程安排，我根本无法处理审核过程。同时，我真的希望这篇论文能够被阅读/使用/引用。我会将其上传到 arxiv 中。 我的问题是：在 ML 研究中，您多久会考虑将 arxiv 作为一个很好的参考？由于机器学习研究的超快性质，我的猜测是它与其他领域有点不同。 （我的博士学位是应用数学，我们经常引用 arxiv 预印本）。 （我的博士学位是应用数学，我们经常引用 arxiv 预印本）。 &gt;   由   提交 /u/tanweer_m   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18a5hd7/r_do_you_cite_arxiv_preprints_in_your_research/</guid>
      <pubDate>Sun, 03 Dec 2023 22:38:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文分析 - 从（生产）语言模型中可扩展地提取训练数据（视频演练）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189y2cv/d_paper_analysis_scalable_extraction_of_training/</link>
      <description><![CDATA[https://youtu.be/KwpeuqT69fw 研究人员只需要求 ChatGPT 多次重复一个单词，就可以从 ChatGPT 中获取大量训练数据，这会导致模型出现分歧并开始吐出记忆的文本。 为什么会出现这种情况？这些模型真正逐字记住了多少训练数据？ ​ 概要： 0:00 - 简介 8:05 - 可提取与可发现的记忆 14:00 - 模型泄漏的数据比之前想象的更多 20:25 - 某些数据是可提取的，但不可发现 25:30 - 从封闭模型中提取数据 30:45 - 诗诗诗 37:50 - 定量隶属度测试 40: 30 - 进一步探索 ChatGPT 漏洞 47:00 - 结论 ​ 论文：https://arxiv.org/abs/2311.17035   由   提交/u/ykilcher  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189y2cv/d_paper_analysis_scalable_extraction_of_training/</guid>
      <pubDate>Sun, 03 Dec 2023 17:13:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>