<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 01 Feb 2025 12:28:26 GMT</lastBuildDate>
    <item>
      <title>[D] 句子分类和自定义实体识别用于信息提取——这种方法有效吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1if4jn8/d_sentence_classification_and_custom_entity/</link>
      <description><![CDATA[      https://preview.redd.it/yt2v9o0klige1.png?width=1901&amp;format=png&amp;auto=webp&amp;s=e5efc6e6a03ce5210ca807b620b0886eb3c598bb 我正在从不遵循一致模板的 HTML 文档中提取财务实体（例如 EPS、收入）。我不想攻读 LLM（RAG）。 我正在考虑以下方法：  使用自定义解析器解析 HTML，以在添加分隔符的同时维护表格结构。 逐行或逐句对提取的文本进行分类。 对分类后的文本执行 NER 以提取相关值。  目标是实现最大准确度和低延迟。这种方法看起来可行吗？是否有我应该考虑的优化或替代方法？    提交人    /u/akfea   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1if4jn8/d_sentence_classification_and_custom_entity/</guid>
      <pubDate>Sat, 01 Feb 2025 11:39:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 分子指纹是肽功能预测的有力模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1if2wlc/r_molecular_fingerprints_are_strong_models_for/</link>
      <description><![CDATA[TL;DR 我们表明分子指纹为肽分类提供了 SOTA 结果，而长距离图基准 (LRGB) 实际上没有长距离依赖性 ArXiv：https://arxiv.org/abs/2501.17901 摘要：  我们研究了分子指纹对肽属性预测的有效性，并证明从分子图中提取领域特定特征可以胜过复杂且计算成本高昂的模型，例如 GNN、预训练的基于序列的变换器和多模态集成，即使没有超参数调整。为此，我们对 126 个数据集进行了全面评估，在 LRGB 和其他 5 个肽功能预测基准上取得了最先进的结果。我们表明，基于 ECFP、拓扑扭转和 RDKit 分子指纹的计数变体以及 LightGBM 作为分类头的模型非常稳健。分子指纹本质上是非常短程的特征编码器，其强大的性能挑战了肽中长程相互作用的假定重要性。我们的结论是，对于较大的分子（例如肽），使用分子指纹可以成为复杂深度学习模型的一种计算上可行、参数少且用途广泛的替代方案。  主要贡献：  分子指纹是分子图上的一种简单特征提取，对肽非常有效 它们在 LRGB 上获得 SOTA 结果，同时是极短程的描述符，并且与它确实需要长程依赖性的说法相矛盾  第一个更面向生物信息学，但第二个与 GNN 评估方法非常相关。大多数设计能够学习节点之间长距离关系的 GNN 的论文都是在 LRGB 上进行评估的。但似乎并没有真正做到这一点，因此这里的任何结论都可能是 a) 虚假相关性 b) 他们正在学习一些有趣的东西，但不是真正的长距离关系。有趣的是，LRGB 的原始审阅者也有同样的疑问（https://openreview.net/forum?id=in7XC5RcjEn）。    提交人    /u/qalis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1if2wlc/r_molecular_fingerprints_are_strong_models_for/</guid>
      <pubDate>Sat, 01 Feb 2025 09:37:56 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 激活转向优于微调的原因是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ieygxx/discussion_reason_for_activation_steering_over/</link>
      <description><![CDATA[我正在做一个项目，有人建议我尝试使用激活控制而不是微调，但我不明白为什么有人会这样做，从纸面上看，这个想法看起来很优雅，但这样做有什么真正的好处呢？ 有关激活控制的更多背景信息（来自 chatgpt）： 激活控制是一种通过修改特定层中的神经元激活来控制语言模型行为的技术。它不是重新训练或微调，而是应用学习到的方向向量（通常来自对比示例）来推动模型输出朝着期望的方向发展（例如，减少偏差或与特定指令保持一致）。此方法高效、可解释，并且允许实时干预而无需修改底层模型权重。非常适合对模型行为进行细粒度控制！    提交人    /u/reallfuhrer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ieygxx/discussion_reason_for_activation_steering_over/</guid>
      <pubDate>Sat, 01 Feb 2025 04:31:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] ROC AUC 分数的交互式解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iem7bq/p_interactive_explanation_to_roc_auc_score/</link>
      <description><![CDATA[嗨，社区， 我参与了 ROC 曲线、AUC 分数和混淆矩阵的交互式教程。 https://maitbayev.github.io/posts/roc-auc/ 欢迎提供任何反馈！ 谢谢！    提交人    /u/madiyar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iem7bq/p_interactive_explanation_to_roc_auc_score/</guid>
      <pubDate>Fri, 31 Jan 2025 18:54:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepSeek？Schmidhuber 是第一个这么做的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ielwh5/d_deepseek_schmidhuber_did_it_first/</link>
      <description><![CDATA[        提交人    /u/SirSourPuss   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ielwh5/d_deepseek_schmidhuber_did_it_first/</guid>
      <pubDate>Fri, 31 Jan 2025 18:41:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 所有的蒸馏都只使用软标签（概率分布）吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ieig2r/d_does_all_distillation_only_use_soft_labels/</link>
      <description><![CDATA[我正在阅读 Deepseek R1 论文的蒸馏部分，没有发现对 SFT 数据集中软标签（概率分布）的任何引用。  这是否意味着在蒸馏过程中总是软标签？因为使用拒绝抽样的 SFT 数据创建听起来更像是硬标签。想法？    提交人    /u/No-Cut5   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ieig2r/d_does_all_distillation_only_use_soft_labels/</guid>
      <pubDate>Fri, 31 Jan 2025 16:18:23 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 报告绩效和基准的可重复性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iei30l/discussion_reproducibility_in_reporting/</link>
      <description><![CDATA[我阅读 ML 论文已有大约一年了。由于我有物理学背景，我发现这些论文根本没有考虑可重复性。论文通常不会透露他们使用的所有细节，例如模型架构参数或其他超参数。 这也让我想到了一个问题：我几乎从未看到过误差线！ 我知道预训练很困难，需要大量的计算能力。但是，我认为评估可以进行多次。事实上，许多研究人员进行了多次评估，但只报告了他们的最佳结果，而不是报告带有置信区间的平均值，尤其是在将他们的模型与基线进行比较时。 你们对此有什么看法？你认为这可能是 AI/ML 中平庸研究泛滥的原因吗？    提交人    /u/vsa467   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iei30l/discussion_reproducibility_in_reporting/</guid>
      <pubDate>Fri, 31 Jan 2025 16:02:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 完全开源代码库用于训练 SOTA VLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ieh3e3/r_fully_open_source_codebase_to_train_sota_vlms/</link>
      <description><![CDATA[嗨！我是 Hugging Face 多模式团队的 Andi。 今天，我们将在 256 个 H100 上从头开始训练 SmolVLM 的代码库开源 受到我们团队开源 DeepSeek R1 训练的努力的启发，我们将在权重之上发布训练和评估代码 现在您可以训练我们的任何 SmolVLM - 或创建自己的自定义 VLM！ 去看看吧： https://github.com/huggingface/smollm/tree/main/vision    提交人    /u/futterneid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ieh3e3/r_fully_open_source_codebase_to_train_sota_vlms/</guid>
      <pubDate>Fri, 31 Jan 2025 15:19:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] 分类：带有印记的图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iee8mi/r_classification_image_with_imprint/</link>
      <description><![CDATA[大家好，我正在开发一种基于图像的药片假冒检测系统。药片表面有四个字母的印记，很难用假药压片机准确复制。我有大约 400 张正品药片的图像，想要开发一个根据印记检测异常值（即假冒产品）的模型。 图像预处理步骤  将图像转换为灰度。 应用阈值使背景变黑。 使用 CLAHE 增强印记文本，使其更加突出。  问题： 我是否应该重新缩放图像（例如 200x200 像素）以减少计算负荷，或者是否有更好的方法？ 哪些图像分类技术适合对印记进行建模？ 我正在考虑使用特征袋 (BoF) + 单类 SVM 进行异常值检测。基于 CNN 的方法（例如自动编码器或 Siamese 网络）是否更有效？ 还有其他建议吗？ 为了进行测试，我计划修改一些真实的印记（例如，更改字母）以模拟假冒案例。这种方法是否适合评估模型性能？ 我将在南美的一家药店购买一些正宗的药丸。 我很想听听您对这项任务的最佳技术和策略的看法。提前谢谢您！    提交人    /u/Haunting_Tree4933   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iee8mi/r_classification_image_with_imprint/</guid>
      <pubDate>Fri, 31 Jan 2025 13:00:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 项目 - 文档信息提取和结构化数据映射</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iebt78/p_project_document_information_extraction_and/</link>
      <description><![CDATA[大家好， 我正在做一个项目，需要从账单、问卷和其他文件中提取信息，以完成一份关于某个组织气候转型计划的结构化报告。该报告包含需要根据提取的信息填充的占位符。 为了提供上下文，该报告遵循一个结构化模板，包括如下语句：   我需要重写所有这些语句，并将它们合并成一份最终的完整报告。挑战在于，必须根据一组决策树式问题的答案来填充占位符。例如： 1.1 该组织是否有气候转型计划？ （是/否）  如果是 → 转至问题 1.2 如果否 → 跳至问题 2  1.2 转型计划是否获得行政机构批准？（是/否）  无论是否批准，继续回答 1.3  1.3 减排目标是否与将全球变暖限制在 1.5°C 相一致？ （是/否）  无论如何，请引用支持证据  依此类推，会引出更多问题和开放式回答，例如：  “解释锁定排放如何影响组织实现减排目标的能力。” “描述组织管理锁定排放的策略。”  从账单和问卷中提取的信息将用于回答这些问题。但是，我的主要问题是设计一种方法来获取这些提取的信息，并根据决策树系统地将其映射到报告中的占位符。 我心中有一个想法，但总是喜欢听取他人的见解。希望您能就以下方面提出意见：  构建逻辑以获取提取的数据并可靠地回答决策树问题。 将答案映射到报告的相应部分。 尽可能自动化流程（例如，使用规则、NLP 或其他技术）。  有人做过类似的事情吗？您会推荐哪些方法来有效地构建和自动化此过程？ 提前致谢！    提交人    /u/No_Possibility_7588   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iebt78/p_project_document_information_extraction_and/</guid>
      <pubDate>Fri, 31 Jan 2025 10:25:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么DeepSeek学生模型（7B参数）的表现略优于教师模型（671B参数）？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie46nq/why_does_the_deepseek_student_model_7b_parameters/</link>
      <description><![CDATA[这是论文中我无法理解的最大部分——知识提炼以匹配原始教师模型的分布是有意义的，但它是如何击败原始教师模型的？    提交人    /u/Easy_Pomegranate_982   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie46nq/why_does_the_deepseek_student_model_7b_parameters/</guid>
      <pubDate>Fri, 31 Jan 2025 02:08:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 温度为 0 时 LLM 的非确定性行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie15ev/d_nondeterministic_behavior_of_llms_when/</link>
      <description><![CDATA[嘿， 因此从理论上讲，当温度设置为 0 时，LLM 应该是确定性的。 然而，在实践中，由于硬件和其他因素的差异，情况并非如此。（示例） 有没有什么好的论文研究温度为 0 时 LLM 的非确定性行为？ 寻找深入研究根本原因、量化它等的东西。 谢谢！    提交人    /u/curryeater259   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie15ev/d_nondeterministic_behavior_of_llms_when/</guid>
      <pubDate>Thu, 30 Jan 2025 23:43:00 GMT</pubDate>
    </item>
    <item>
      <title>[d] 为什么“知识提炼”现在突然被贴上了盗窃的标签？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1idjtta/d_why_is_knowledge_distillation_now_suddenly/</link>
      <description><![CDATA[我们都知道，蒸馏是一种近似更精确变换的方法。但我们也知道，这也是整个想法的终结。  蒸馏有什么问题？通过模仿输出来学习“知识”这一事实对我来说毫无意义。当然，通过保持输入和输出相同，我们试图近似一个类似的变换函数，但这并不意味着它确实如此。我不明白这怎么会被贴上盗窃的标签，尤其是当整个架构和训练方法都不同的时候。     提交人    /u/The-Silvervein   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1idjtta/d_why_is_knowledge_distillation_now_suddenly/</guid>
      <pubDate>Thu, 30 Jan 2025 10:09:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    </channel>
</rss>