<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 28 Nov 2023 21:12:24 GMT</lastBuildDate>
    <item>
      <title>[R] 一天内的数据集。基于聚类的快速数据集创建方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1864rby/r_dataset_in_a_day_a_clusteringbased_approach_for/</link>
      <description><![CDATA[https:/ /medium.com/bumble-tech/dataset-in-a-day-7f369de3b178   由   提交 /u/Dutchcheesehead   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1864rby/r_dataset_in_a_day_a_clusteringbased_approach_for/</guid>
      <pubDate>Tue, 28 Nov 2023 19:43:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 转行研究的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1864a1r/d_advice_on_switching_into_research/</link>
      <description><![CDATA[我是一名经理，并拥有一份出版物。我想转向研究并为深度思维工作。我需要以下方面的建议：1) 如何准备面试，2) 与企业相比，成功进行研究所需的技能有什么不同。  &amp;# 32；由   提交/u/Odd-Distance-4439   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1864a1r/d_advice_on_switching_into_research/</guid>
      <pubDate>Tue, 28 Nov 2023 19:23:57 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]您发现自己每周在工作的哪一部分上浪费时间最多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/</link>
      <description><![CDATA[不询问拖延症、实际工作职责。对我来说，它必须处理电子表格和演示文稿。您的工作流程中存在哪些瓶颈？   由   提交/u/zero-true  /u/zero-true reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1863igy/discussion_what_part_of_your_job_do_you_finding/</guid>
      <pubDate>Tue, 28 Nov 2023 18:52:33 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习的 AMD GPU [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1863brm/amd_gpu_for_machine_learning_d/</link>
      <description><![CDATA[我是一名计算机科学学生，最近为我的第一台游戏电脑购买了组件。我发现 6800 的价格不错，相当不错，但我想知道面向机器学习的库（和其他相关的东西）是否会出现问题，因为我发现 NVIDIA GPU 更适合它。如果是这样，我是否仍然可以使用我拥有的 AMD GPU 获得不错的结果，还是应该更改它？   由   提交 /u/the_fabbest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1863brm/amd_gpu_for_machine_learning_d/</guid>
      <pubDate>Tue, 28 Nov 2023 18:44:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] minOFT：一个易于使用的 PyTorch 库，用于将正交微调 (OFT) 应用于 PyTorch 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1862am5/p_minoft_an_easytouse_pytorch_library_for/</link>
      <description><![CDATA[嗨r/MachineLearning， 我想分享我在微调语言模型（正交微调）研究中遇到的一项非常有趣的工作的开源实现。 正交微调 (OFT) 是 LoRA 的一种更强大、稳定且样本效率更高的替代方案，LoRA 最初是为微调扩散模型而开发的。 LoRA 通过添加两个低秩矩阵的乘积来更新预训练权重矩阵，而 OFT 将预训练层权重乘以可学习的正交矩阵以应用约束变换。 OFT 的作者最近表明，这种方法（通过名为 butterfly OFT 的巧妙改进）也适用于视觉转换器和语言模型。 灵感来自minLoRA，我认为最好有一个最小的开源存储库来测试并在微调时比较 OFT 与 LoRA语言模型。它也是由 Andrej Karpathy 在 nanoGPT 之上构建的。该库可通过 pip 安装，并且可以与任何 PyTorch 模型（包括 Hugging Face 模型）通用，就像 minLoRA 一样。 欢迎提供反馈和贡献！您可以在下面尝试一下： https://github.com/alif-munim/minOFT   由   提交/u/0blue2brown   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1862am5/p_minoft_an_easytouse_pytorch_library_for/</guid>
      <pubDate>Tue, 28 Nov 2023 18:01:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 对齐即代码：使 LLM 应用程序与 Tanuki 一起运行。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1861p30/p_alignmentascode_making_llm_applications_behave/</link>
      <description><![CDATA[我是 Tanuki 的贡献者，一个项目，允许您使用 Python 中的测试驱动语法以声明方式定义 LLM 行为。 通过指定 LLM 必须作为测试履行的合同，它有助于减少 MLOps 并使您能够使用标准的开发操作流程将模型的行为与您的要求保持一致。 此外，这些对齐语句有助于自动师生模型蒸馏，以将成本和延迟降低多达 10 倍（请参阅基准）。  非常感谢任何想法或反馈。   由   提交 /u/Noddybear   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1861p30/p_alignmentascode_making_llm_applications_behave/</guid>
      <pubDate>Tue, 28 Nov 2023 17:37:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 具有 2d 旋转嵌入的交叉轴变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18607oa/r_crossaxis_transformer_with_2d_rotary_embeddings/</link>
      <description><![CDATA[ 由   提交/u/lilyerickson  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18607oa/r_crossaxis_transformer_with_2d_rotary_embeddings/</guid>
      <pubDate>Tue, 28 Nov 2023 16:34:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有预训练的人脸识别模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185z0li/d_is_there_any_pretrained_model_for_face/</link>
      <description><![CDATA[我想用Java语言做一个人脸识别功能：输入两张人脸图像，输出是否是同一个人。有没有可以直接使用的预训练模型？我尝试使用opencv的直方图归一化方法进行识别，但是准确率非常差，无法接受。   由   提交 /u/Rare-Durian-2121   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185z0li/d_is_there_any_pretrained_model_for_face/</guid>
      <pubDate>Tue, 28 Nov 2023 15:44:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师加薪？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185y5wn/d_machine_learning_engineer_salary_increase/</link>
      <description><![CDATA[大家好，我去年大学毕业，一直在佛罗里达州的一家公司担任机器学习工程师。我一年赚7.6万。该公司提供硕士学位学费报销。通常情况下，获得硕士学位后，您的加薪是多少？ 后续问题：从在线大学获得硕士学位（我仍然会全职工作）的声望是否会低于从在线大学获得硕士学位？亲自？ 请问，如果您愿意的话，是否有人介意直接分享他们大学毕业后的个人薪资数据以及在整个职业生涯中的进展情况？   由   提交/u/Fluid-Pipe-2831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185y5wn/d_machine_learning_engineer_salary_increase/</guid>
      <pubDate>Tue, 28 Nov 2023 15:06:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 鲁棒强化学习并不安全</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185xflb/r_robust_reinforcement_learning_is_not_safe/</link>
      <description><![CDATA[https://blogs.ucl.ac.uk/steapp/2023/11/15/adversarial-attacks-robustness-and-generalization-in-deep-reinforcement-学习/    由   提交 /u/ml_dnn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185xflb/r_robust_reinforcement_learning_is_not_safe/</guid>
      <pubDate>Tue, 28 Nov 2023 14:33:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何弥合模态之间的鸿沟：多模态大语言模型综合综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185vu8v/r_how_to_bridge_the_gap_between_modalities_a/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2311.07594  摘要：  这篇综述论文探讨了多模态大型语言模型 (MLLM)，它集成了 GPT-4 等大型语言模型 (LLM) 来处理文本等多模态数据和愿景。 MLLM 展示了生成图像叙述和回答基于图像的问题等功能，缩小了与现实世界人机交互的差距，并暗示了通用人工智能的潜在途径。然而，MLLM 在处理多模态语义鸿沟方面仍然面临挑战，这可能导致错误生成，给社会带来潜在风险。选择合适的模态对齐方法至关重要，因为不正确的方法可能需要更多参数，而性能改进有限。本文旨在探索法学硕士的模态对齐方法及其现有能力。实施模式调整使法学硕士能够解决环境问题并提高可及性。该研究将 MLLM 中现有的模态对齐方法分为四组：（1）将数据转换为 LLM 可以理解的内容的多模态转换器； (2) 多模态感知器，以改善法学硕士感知不同类型数据的方式； (3) 工具协助将数据转换为一种通用格式，通常是文本； (4) 数据驱动方法，教导法学硕士理解数据集中特定类型的数据。该领域还处于探索和实验阶段，我们将整理和更新现有的各种多模态信息对齐的研究方法。  https://preview.redd.it/hoa7lf52a33c1.png?width=1149&amp;format=png&amp;auto=web p&amp; s=0a6230b350a0189fbfbdeaec719380c73c6403cd   由   提交 /u/APaperADay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185vu8v/r_how_to_bridge_the_gap_between_modalities_a/</guid>
      <pubDate>Tue, 28 Nov 2023 13:18:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2023机构排名</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185pdax/d_neurips_2023_institutions_ranking/</link>
      <description><![CDATA[       由   提交/u/Roland31415   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185pdax/d_neurips_2023_institutions_ranking/</guid>
      <pubDate>Tue, 28 Nov 2023 06:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] SuGaR：用于高效 3D 网格重建和高质量网格渲染的表面对齐高斯喷射</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</link>
      <description><![CDATA[计算机视觉研究人员开发了一种方法，只需几分钟即可在单个 GPU 上根据图像创建详细的 3D 模型。他们的方法称为 SuGaR，通过优化数百万个微小粒子来匹配场景图像。关键的创新是让粒子与表面对齐，以便可以轻松地将它们变成网格。 传统的 3D 建模速度慢且资源繁重。激光扫描不方便。摄影测量点云缺乏细节。像 NeRF 这样的神经辐射场可以产生令人惊叹的渲染效果，但即使使用强大的硬件，将它们优化为网格也需要数小时或数天的时间。 VR/AR、游戏、教育等领域对更轻松的 3D 内容创建的需求不断增长。但大多数技术都有很大的速度、质量或成本限制，阻碍了它们主流使用。 这种新的 SuGaR 技术结合了神经场景表示和计算几何方面的最新进展，推动了最先进的技术的发展它首先利用一种称为高斯喷射的方法，该方法基本上使用大量微小粒子来复制场景。放置和配置粒子只需几分钟。问题是它们不会自然地形成连贯的网格。 SuGaR 提供了一种新的初始化和训练方法，可以将粒子与场景表面对齐，同时保持细节完整。这种条件允许将粒子云直接视为点云。 然后，他们应用一种称为泊松表面重建的计算技术，以并行方式直接在结构化粒子之间构建网格。一次处理数百万个粒子可以在低延迟的情况下实现高保真度。 通过将繁重的工作转移到前端点云结构化阶段，SuGaR 使最终网格生成与其他最先进的技术相比极其高效-艺术神经/混合方法。 实验表明，SuGaR 构建详细网格的速度比之前发布的技术快几个数量级，同时实现具有竞争力的视觉质量。该论文分享了一些在 10 分钟内重建复杂场景的有希望的示例。 处理更多样化的场景类型仍然存在问题。但就使用可访问的硬件使高质量 3D 重建更接近交互速度而言，这看起来是引人注目的进步。 TLDR：对齐高斯溅射中的粒子可让您将它们转变为详细的网格。使高质量 3D 更好、更快、更便宜。 完整摘要位于此处。论文网站此处。   由   提交/u/Successful-Western27   reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/185ldf9/r_sugar_surfacealigned_gaussian_splatting_for/</guid>
      <pubDate>Tue, 28 Nov 2023 02:37:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你会痴迷地观看模特训练吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18576ol/d_do_you_obsessively_watch_your_models_train/</link>
      <description><![CDATA[我发现自己看张量板的时间多于工作——只是想知道其他陷入这种模式的人是否对生产力有什么建议   由   提交 /u/TehDing   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18576ol/d_do_you_obsessively_watch_your_models_train/</guid>
      <pubDate>Mon, 27 Nov 2023 16:39:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>