<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sun, 02 Mar 2025 09:16:24 GMT</lastBuildDate>
    <item>
      <title>[d]在商业世界中使用诸如knime之类的无代码工具，还是必须对专业知识进行编码？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1lg4c/d_is_using_nocode_tools_like_knime_valuable_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  需要建议：冗长的一个！ 来自非编码背景，在领导50多个以上的大规模大规模大规模，数据驱动的操作和业务转型分配方面经历了16年的经验，在BFSI中，BFSI在全球范围内分发了范围的持续分配的客户。付我大笔支票。随着责任的越来越多，现在我确实需要在职业发展和薪水方面提高。 在Al＆amp;中保持领先地位。将其用于未来的项目，我在AL攻读了一项研究生课程，以供德克萨斯州奥斯汀市的领导层。 （虚拟自节奏程序） 通过此，L&#39;VE学会了使用无代码工具来解决数据科学问题，并通过回归，神经网络等解决。  到目前为止，L&#39;VE能够在不编写代码的情况下推动结果，使用回归网络，EDA，NN等解决了以数据为中心的问题。 ，但我想知道： 您建议我学习编码或继续使用任何代码工具！  •无价值的compode and copode and copode and copode al＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp＆amp;现实世界业务应用程序中的数据科学技能？ •组织是否重视可以在没有深层编码专业知识的情况下利用AL的领导者，或者编码仍然是真正影响力的必备品；职业增长？ •这项技能是否设定了雇用经理的东西＆amp;企业积极寻求？ 会喜欢AL，Data Science等人的见解。商业领导！预先感谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1lg4c/d_is_is_using_nocode_nocode_tools_like_knime_valuable_in/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j1lg4c/d_is_is_using_nocode_tools_tools_like_knime_valuable_in/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1lg4c/d_is_using_nocode_tools_like_knime_valuable_in/</guid>
      <pubDate>Sun, 02 Mar 2025 07:29:01 GMT</pubDate>
    </item>
    <item>
      <title>[r] unitok：通过多编码本矢量量化统一视觉生成和理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1l0xo/r_unitok_unifying_visual_generation_and/</link>
      <description><![CDATA[Just checked out the new UniTok paper that introduces a unified visual tokenizer capable of handling both generation and understanding tasks within a single framework. The key innovation here is a joint training approach that combines: - Reconstruction objectives (for generation capabilities) - Recognition objectives (for understanding功能） 这使一个单一的代币化系统能够有效地实现双重目的，而不会损害任何任务类型的性能。 主要技术点： - 基于变压器的编码器 - 编码器架构，具有专门的训练方法 - 与偶然性损失相结合 - 可构成噪声的差异 - 与差异的差异 - 与差异相结合 - 精细的视觉细节 - 在Imagenet，Coco和其他基准测试中实现最新的结果 - 与使用单独的专业象征器 相比，我认为这种统一方法可以显着减少需要产生和理解能力的视觉AI系统中的计算范围。拥有一个有效的系统并没有维护和运行多个专业的代币器，而是为现实部署创造实际的优势。绩效的改进表明，我们可能会看到这种方法在未来的多模式系统中成为标准。 我对这可能会影响效率至关重要的移动/边缘应用特别感兴趣 - 拥有一个可以很好地处理这两个任务的单个标记器可以使您可以在资源限制的设备上更加易于访问。与使用单独的引导剂相比，训练方法，实现SOTA结果，同时提高效率40％。  完整摘要” Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1l0xo/r_unitok_unifying_visual_generation_and/</guid>
      <pubDate>Sun, 02 Mar 2025 07:00:04 GMT</pubDate>
    </item>
    <item>
      <title>[研究]使用5D时场的量子启发的神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1jwpg/research_quantuminspired_neural_networks_using_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿 r/machinelearning ， 我一直在研究一个新的神经网络框架，从而从&lt;强&gt;量子上启发 hamiltonian驱动的学习动力和一个内部时间字段来调节参数的动态更新。 模型的关键方面：         Quant&gt; Quantum-stront 波函数传播。    5D时场集成：引入了额外的内部时间场τ（x，t），可以动态地调整网络适应性。     更好的概括＆amp＆amp;学习效率：可以提高稳定性和训练的融合，尤其是在非平稳的环境中。  ，我已经整理了一个 preprint 讨论此框架并正在讨论这个框架并正在寻找ML社区的反馈。链接：  https://doi.org/10.5281/zenodo.14955019 应该进一步探索哪些关键方面？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_release_3665      [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1jwpg/research_quantuminspired_neural_networks_using_a/</guid>
      <pubDate>Sun, 02 Mar 2025 05:46:10 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1hc0o/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Mar 2025 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[r]发布我的离散辅助仪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1ed93/r_releasing_my_discrete_vocoder/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我正在释放我的离散vocoder（24kh，每秒50帧，每秒50帧，4个密码簿）。 我试图将某些东西放在高biTrate的高位型和低比特拉特Mimi/WaveTrate Mimi/waveTocken中。型号和用法示例： https://huggingface.co/balecoon/vq4_50fps_24khz_vocoder  href =“ https://huggingface.co/spaces/balacoon/ttsleaderboard”&gt; https://huggingface.co/spaces/balacoon/balacoon/ttsleaderboard （pick`ovododer`作为系统）提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1ed93/r_releasing_my_discrete_vocoder/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1ed93/r_releasing_my_discrete_vocoder/</guid>
      <pubDate>Sun, 02 Mar 2025 00:39:54 GMT</pubDate>
    </item>
    <item>
      <title>[D]在ML管道中实现实验？ （+ ML系统设计面试问题）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1dyff/d_enabling_experimentation_in_ml_pipelines_ml/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我是一个恢复了数据科学家，对数据工程和ML工程进行了关注（我为小型启动工作，所以我在较小的启动中做了一些两者，并且我以前在较大的org中所做的角色，但我曾经在offline/batch ml thersem and op anders访问过我的访问中，我已经接受过访问的访问。许多问题如何构建和部署生产ML管道（快速，可扩展的推理API）以及实现不同ML管道的实验。 这是两个单独的问题，但我觉得ML管道的最佳设计将同时实现这两者。我还没有发现最佳。这也是我目前工作的启动的挑战。 我觉得大多数OSS ML工具实际上并没有启用这些功能中的任何一个，这些功能（推理服务器和实验工作流程）需要由MLE/SWE构建。所有这些都需要缝合在一起。我正在考虑诸如AirFlow，Kedro，MLFlow等工具...也许云提供商（Databricks，AWS SageMaker，Azureml）提供了简单的方法，可以简单地上传模型来生产并通过可伸缩的API（+实验）为其提供服务，但我不知道它。 （如果您知道这样的ML工具，请告诉我） 无论哪种方式，我对快速型号的回应将被模型腌制的泡菜包裹在fastapi中包裹在docker上包裹的docker（已同意）      我想在哪里丢失了一些我会在哪里进行实验，我想在哪里构建了我的习惯。 （在ML管道的不同部分（清洁，Fe，培训，评估）中注册功能），可以在YAML中定义生产管道，并且可以在其他YAML中写入单独的实验，并在其他YAML中写下，并在某种程度上以并行部署预测和指标，以比较     &lt;强我的感觉，我的回答是如何的。你们解决了这些问题？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/myssirious_energy_80     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1dyff/d_enabling_experimentation_in_ml_pipelines_ml/</guid>
      <pubDate>Sun, 02 Mar 2025 00:19:13 GMT</pubDate>
    </item>
    <item>
      <title>[R]有效LLM的窗户注意力训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1ckye/r_sliding_window_attention_training_for_efficient/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     https：//arxiv.org/abs/2502.18845 Mamba，Titans和Transformers ++。在结论中跳跃：  ，通过用sigmoid替换软杀剂，将平衡的alebi替换为SWAT并将其结合在一起，SWAT解决了注意力下沉问题，并确保稳定的培训并确保稳定的培训。这么多的“曼巴发生了什么”帖子，我仍在等待基于泰坦的模型的发布，因此，尽管我不知道我们是否会使用特警，但我还是赞赏该论文作为对扩展 - 封闭式/替代架构世界中当前的调查。   &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1ckye/r_sliding_window_attention_trainention_training_for_for_effficity/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1ckye/r_sliding_window_attention_training_for_efficient/</guid>
      <pubDate>Sat, 01 Mar 2025 23:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[d]关于大规模优化ML模型并构建分布式培训/推断的材料</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j18c64/d_materials_on_optimizing_ml_models_at_scale_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  已经遇到了许多高级ML工程师工作，需要涉及“大规模运行和优化模型”或“分布式培训和推理”的经验。 在我作为ML工程师的5年中，我从来没有遇到需要此类技能的问题。这涉及哪些技术/知识？谁能指出相关的材料？ 我知道Pytorch DDP教程，但我想，不仅仅是它吗？ ，我可能还缺少某些东西，但没有像用户那样遇到pytorch-light trightwork，而是用户远离用户？例如。分布式培训和推断只是添加了一些参数？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j18c64/d_materials_optimizing_ml_models_models_at_at_scale_and/”&gt; [links]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j18c64/d_materials_on_optimizing_ml_models_at_scale_and/</guid>
      <pubDate>Sat, 01 Mar 2025 20:01:48 GMT</pubDate>
    </item>
    <item>
      <title>[d]插补方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j17zuj/d_imputation_methods/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我是一名医学生，目前正在接受ML实验，以根据不同的临床变量进行特定类型的手术后预测结果。我正在研究一个非常稀疏的数据集（其中一些特征丢失了约20-25％的数据），因此需要估算大量数据。我目前正在使用Scikit学习运行实验，但是多个插补功能不允许同时估算数值和分类变量，因此我使用了Missforest软件包。在使用“置换重要性”图和部分依赖性显示的置换率审查我的最终模型后，我意识到我的插补方法引入了很多偏见，有时会损害临床变量的实际正稳定值。我知道引入了这种偏见是因为先前使用同一数据集发表的论文，而不是使用Missforest算上，而是使用R。 中的MICE库，现在我不确定我应该做什么以减轻这种偏见。在上一篇使用小鼠的文章中，他们使用10个不同的估算数据集训练了单个回归模型，以评估其性能。在我的上下文中，我不确定我该怎么办，因为我使用10倍CV培训了几个ML模型，只有一个估算的数据集。我认为我可以使用小鼠生成一个估算的数据集，但是我觉得这违背了小鼠的全部目的，除非我错了，否则在这种情况下，我希望看到一些论文实施了小鼠以开发和验证不同ML模型。我还有其他方法可以减轻我的初始插补方法产生的偏差吗？ 谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j17zuj/d_imputation_methods/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j17zuj/d_imputation_methods/</guid>
      <pubDate>Sat, 01 Mar 2025 19:46:51 GMT</pubDate>
    </item>
    <item>
      <title>[P]更新：使用Langchain和Langgraph呼吁使用DeepSeek-R1的工具：现在在打字稿中！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0wv8j/p_update_tool_calling_for_deepseekr1_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在这里发布了我在工具上创建的GitHub Repo Python软件包，呼吁使用Langchain和Langgraph进行DeepSeek-R1 671b，或更一般地用于Langchain cathopenal class in langchain cathopenal class中的任何LLMS（对于新发布的LLMS）（不支持Newly Preakain callms），该工具又支持/  https://github.com/leock.com/leockl/leockl/tool-ahead-ahead-oftime     通过社区请求，我很高兴能为此包含这个包的typepript版本。 - 在打字稿中，将工具呼叫功能的NPM套件：    https://github.com/github.com/leockl/leockl/leockl/leockl/tool-ahead-ockl/tool-ip----有帮助。享受！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lc19-     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0wv8j/p_update_tool_calling_for_deepseekr1_with/</guid>
      <pubDate>Sat, 01 Mar 2025 10:47:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] Marsopt：混合自适应随机搜索优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0vsct/r_marsopt_mixed_adaptive_random_search_for/</link>
      <description><![CDATA[       &lt;！ -  sc_off- sc_off-&gt;     marsopt （混合自适应随机搜索优化）的设计旨在解决具有多个参数类型的优化复杂系统的挑战。 The library implements an adaptive random search algorithm that dynamically balances exploration and exploitation through:  Adaptive noise for efficient parameter space sampling Elite selection mechanisms to guide search toward promising regions Integrated support for log-scale and categorical parameters Flexible objective handling (minimization or最大化）  技术突出显示 我们的基准测试表明，与Optuna的TPE Sampler相比，Marsopt的表现出色：  更快更快 href =“ https://preview.itd.it/s4nw6eehq1me1.png？ Consistently top ranks across standard black-box optimization benchmarks from SigOpt evalset   全面的变量支持 库处理现代ML管道所需的参数类型的完整频谱：     连续变量（带有可选的日志样本示例）  分类变量（带有智能表示）  实用的ML应用程序 在我们对LightGBM HyperPoReter调谐的实验中，Marsopt在加利福尼亚州住房数据集上调谐，Marsopt表现出与诸如Optizizers之类的优化效果相比的令人鼓舞的结果。库有效地处理了简单的参数空间和更复杂的方案，涉及不同的增强类型，正则化参数和采样配置。    使用Marsopt很简单：  来自Marsopt Import Intimp ofimp ofimp ofimp otim in trim imptim impor numpy作为NP DEF目标（试验：试验：试验） - ＆GT; float：lr = auggest_float（; quot; leadmood; querat＆quot;，1e-4，1e-1，log = true）layers = auggest_int（num_layers＆quot; num_layers＆quort＆quort＆quotizer＆quotizer＆quort＆quort = auggest_catation.suggest_categorical; “ rmsprop”]）＃您的评估逻辑在此处回报分数研究=研究（方向=“最大化”）研究。  文档： https://marsopt.readthedocs.io/      algorithm： https://marsopt.readthedocs.io/en/latest/latest/algorithm.html   href =“ https://github.com/sibirbil/marsopt”&gt; https://github.com/sibirbil/marsopt     pypi： https://pypi.org/project/project/marsopt/      我对您的反馈感兴趣，并欢迎您有关实施或绩效特征的任何问题。提交由＆＃32; /u/u/zedeleyici3401     [link]    [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0vsct/r_marsopt_mixed_adaptive_random_search_for/</guid>
      <pubDate>Sat, 01 Mar 2025 09:30:51 GMT</pubDate>
    </item>
    <item>
      <title>[R]用于数学推理的自我奖励LLM：一个自主错误检测和校正的两阶段框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0tw4n/r_selfrewarding_llms_for_mathematical_reasoning_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文引入了一种自我奖励校正机制，用于改善语言模型中的数学推理。核心想法将自我评估与迭代校正结合在一起 - 该模型学会了评估自己的解决方案并修复其确定的错误。 主要技术点： - 两阶段架构：解决方案生成：自定义奖励 - 自定义奖励功能 - 既有答案正确性和推理质量既不存在的范围 - 否则范围的范围 - 否则范围的范围 - 否定范围 - 否定范围 - 误差 - 误差 - 误解 - 误差 - 误差 - 误差 - 误差 - 全面训练 关键结果： -  15-20％的数学任务的基准精确度提高-80％的错误检测成功率 - 在算术，代数和单词问题上的出色表现 - 与基本模型相比，最小的额外培训计算 - 与基本模型相比最小的额外培训计算 - 最有效的对问题的方法尤其需要多个 我认为该方法的价值更高，因此可以不断地启动一个信息。自我纠正机制似乎可以将不仅仅是数学问题概括到需要强大推理的其他领域。 我认为，这里的真正价值是朝着可以有效地验证自己的工作而不是仅仅产生答案的模型发展。这是建立更值得值得信赖的AI系统的重要步骤。 我看到的主要限制是在解决方案中过度自信的潜力，尽管蒙特卡洛验证有助于减轻这种情况。看到这与外部验证系统结合在一起会很有趣。  tldr：结合自我奖励和数学推理的迭代校正的新方法。模型学会检查并修复自己的工作，并通过强误检测获得15-20％的准确性提高。  完整的总结在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0tw4n/r_selfrewarding_llms_for_mathematical_reasoning_a/</guid>
      <pubDate>Sat, 01 Mar 2025 07:14:55 GMT</pubDate>
    </item>
    <item>
      <title>[d]“反向传播：差异规则[第3部分]的视觉解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0ez5y/d_visual_explanation_of_backpropagation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi，  i先前在此处共享了第1部分和第2部分：  第1部分： https://www.reddit.com/r/machinelearning/comments/1irs3gn/d_visal_explanation_of_backpropagation/   第2部分： https://www.reddit.com/r/machinelearning/comments/1iy0d47/d_visual_explanation_of_backpropagation_forward/     这是第3部分我在其中分享了如何使用计算图从scratch中得出差异规则。 xi（x）= x。我发现它很有趣，因此共享。 谢谢，  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/madiyar     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0ez5y/d_visual_explanation_of_backpropagation/</guid>
      <pubDate>Fri, 28 Feb 2025 18:42:46 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何写数学大型ML论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j0efdm/d_how_do_you_write_math_heavy_ml_papers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在ICLR/neurips/icml上发表理论ML论文或数学繁重论文的人，您如何撰写数学繁重的论文？编写方法部分的策略是什么？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/antelopewilling2928     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j0efdm/d_how_do_you_write_math_heavy_ml_papers/</guid>
      <pubDate>Fri, 28 Feb 2025 18:19:43 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些经验丰富的人。   &lt;！ -  sc_on--&gt; 32;&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>