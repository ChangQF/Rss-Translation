<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 19 Sep 2024 21:14:59 GMT</lastBuildDate>
    <item>
      <title>[D] 将 MILP 的输出纳入损失函数进行训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkuc24/d_incorporating_output_of_milp_into_loss_function/</link>
      <description><![CDATA[大家好， 我想预测互联网流量矩阵。我训练 GRU 以最小化模型输出和地面真实流量矩阵之间的 MSE。为了进一步评估模型，我将预测流量矩阵传递给路由解决方案。路由解决方案的输出是一个缩放值。为了评估模型是否是一个好的预测器，预测的 TM 应该从路由解决方案中产生一个接近地面真实流量矩阵产生的值的值。我想设计一个损失函数，将路由解决方案作为反馈纳入我的模型训练中。有什么建议吗？ 我正在考虑将路由解决方案差异添加到我的 mse 损失函数中。像这样： import torch import torch.nn as nn class TrafficMatrixLoss(nn.Module): def __init__(self, weight_mse=1.0, weight_routing=1.0): super(TrafficMatrixLoss, self).__init__() self.weight_mse = weight_mse self.weight_routing = weight_routing def forward(self, predict_tm, ground_truth_tm, routing_solution): # 计算预测流量矩阵和地面实况之间的 MSE 损失 mse_loss = nn. functional.mse_loss(predicted_tm, ground_truth_tm) # 计算预测和地面真相的路由解决方案输出 predicted_routing_value = routing_solution(predicted_tm) # 假设这返回一个标量 ground_truth_routing_value = routing_solution(ground_truth_tm) # 假设这返回一个标量 # 根据路由解决方案计算损失 routing_loss = torch.abs(predicted_routing_value - ground_truth_routing_value) # 合并损失 total_loss = (self.weight_mse * mse_loss) + (self.weight_routing *路由损失) 返回总损失    提交人    /u/mtot10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkuc24/d_incorporating_output_of_milp_into_loss_function/</guid>
      <pubDate>Thu, 19 Sep 2024 20:32:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将嵌入模型转换为法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fktvbj/p_swapping_embedding_models_for_an_llm/</link>
      <description><![CDATA[嵌入模型与语言模型的耦合程度如何？ 以 Langchain 的教程为例，他们使用 Ollama 的 nomic-embed-text 进行嵌入，使用 Llama3.1 进行理解和问答。我没有看到任何关于基于此嵌入模型的嵌入构建 Llama 的文档。 直觉表明，不同的嵌入模型可能会产生其他大小的输出或为字符/单词产生不同的张量，这会对 LLM 的结果产生影响。那么更改嵌入模型是否也需要重新训练/微调 LLM？ 我需要对代码片段和文本使用嵌入模型。我需要为此找到专门的嵌入模型吗？如果是，llama3.1 将如何提取嵌入？    提交人    /u/noobvorld   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fktvbj/p_swapping_embedding_models_for_an_llm/</guid>
      <pubDate>Thu, 19 Sep 2024 20:13:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 尝试构建 csv 代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fksier/p_trying_to_build_a_csv_agent/</link>
      <description><![CDATA[大家好，今天问候一下，我是一名全栈开发人员，最近正尝试转向 AI。 在我的公司，我被赋予了构建一个应用程序的任务，该应用程序使用本地 LLM 模型读取 csv 并回答有关其中数据的任何问题，我尝试了多种方法，例如，  使用 all-mpnet-base-v2 创建嵌入并使用不同的检索将其插入到 chroma db 中，例如具有相似性搜索的 vectorstore、父文档检索器、使用 llama3.1:7b 的多向量检索器，由 ollama 提供并与 langchain 连接 使用来自 langchain 的实验性 CSV 代理 直接从 hugging face 使用 google tapas  我正在使用 M2 pro macbook 以上方法均未给我准确的解决方案。 您能指导我如何解决这个问题吗？    提交人    /u/id159753   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fksier/p_trying_to_build_a_csv_agent/</guid>
      <pubDate>Thu, 19 Sep 2024 18:51:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] EMNLP 2024 成绩/通知</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkqxhh/d_emnlp_2024_results_notifications/</link>
      <description><![CDATA[一些曲目的结果似乎已经出来了，可以在 Openreview 上查看。电子邮件可能会在明天发送。  提前祝贺大家，迈阿密见！    提交人    /u/EDEN1998   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkqxhh/d_emnlp_2024_results_notifications/</guid>
      <pubDate>Thu, 19 Sep 2024 17:45:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机械可解释性论文关于 Yannic Kilcher 分歧的讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkouvg/d_mechanistic_interpretability_paper_discussion/</link>
      <description><![CDATA[      继续 Anthropic 的变压器电路系列，并作为 Yannic Kilcher discord 服务器上每日论文讨论的一部分，我将自愿领导对以下机械可解释性工作的分析 🧮 🔍 📜 叠加玩具模型，作者为 Nelson Elhage、Tristan Hume、Catherine Olsson、Nicholas Schiefer，等人。 🌐 https://transformer-circuits.pub/2022/toy_model/index.html 🕰 2024 年 9 月 19 日星期五 12:30 AM UTC // 2024 年 9 月 19 日星期五 6.00 AM IST // 2024 年 9 月 18 日星期四 5:30 PM PT 我们在本系列中讨论过的先前的机械可解释性论文： 🔬 Softmax 线性单元 🔬 情境学习和感应头 🔬 变压器电路的数学框架 加入我们一起享受乐趣吧 ~ https://ykilcher.com/discord 叠加玩具模型    提交人    /u/CATALUNA84   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkouvg/d_mechanistic_interpretability_paper_discussion/</guid>
      <pubDate>Thu, 19 Sep 2024 16:20:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] Comgra：用于分析和调试神经网络的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</link>
      <description><![CDATA[我是一名机器学习工程师和研究员。我厌倦了理解神经网络行为方式的难度，因此我编写了一个库来帮助我。 Comgra（计算图分析） 是一个可以与 pytorch 一起使用的库，用于提取您关心的所有张量数据并在浏览器中以图形方式对其进行可视化。有关它的论文已被接受为 ICML 2024 机械可解释性研讨会的焦点论文。 与通常使用 tensorboard 的方法相比，Comgra 可以对正在发生的事情进行更详细的分析。您可以在训练过程中研究张量，深入研究单个神经元，检查您特别感兴趣的单个数据集，跟踪梯度，比较不同训练运行之间的统计数据等等。 这个工具让我比平时更快地检查我的假设，并帮助我了解网络的不同部分是如何真正相互作用的，从而为我节省了大量的研究时间。    提交人    /u/Smart-Emu5581   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fklqcz/p_comgra_a_tool_for_analyzing_and_debugging/</guid>
      <pubDate>Thu, 19 Sep 2024 14:07:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语音到语音模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkhcur/d_speech_to_speech_models/</link>
      <description><![CDATA[有人在研究语音转语音 AI 模型或应用程序吗？想听听我正在进行的项目的第二意见。 如果您能提供帮助，请发表评论或 DM。    由    /u/vividly_voidy  提交  [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkhcur/d_speech_to_speech_models/</guid>
      <pubDate>Thu, 19 Sep 2024 10:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用少量数据进行训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkh1qa/p_training_with_little_data/</link>
      <description><![CDATA[大家好，提前感谢大家的见解！ 我正在做我的最后一个项目，涉及图像合成，但我面临一个挑战：我们可用的数据非常有限。我一直在研究诸如小样本学习、数据集提炼等方法来克服这个障碍。 我希望利用社区的集体智慧，看看是否有人对如何有效处理用于图像合成的小数据集有技巧、经验或建议。 期待任何建议！祝你有美好的一天！:)    提交人    /u/Galaxyraul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkh1qa/p_training_with_little_data/</guid>
      <pubDate>Thu, 19 Sep 2024 09:53:16 GMT</pubDate>
    </item>
    <item>
      <title>[P]用纯 Python 从头构建玩具神经网络框架——受 Karpathy 的 Micrograd 启发</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkg3yd/pbuilding_a_toy_neural_network_framework_from/</link>
      <description><![CDATA[      https://github.com/ickma/picograd 上周末，我开始了一个项目，完全从头开始使用纯 Python（没有 TensorFlow、PyTorch 或其他库）构建一个玩具神经网络框架。这个项目的想法来自 Andrej Karpathy 的 micrograd，我想挑战自己，真正了解神经网络在底层的工作原理。 我实现了前向和后向传播，经过一些测试后，我在 Iris 分类数据集上实现了 93% 的准确率。 这个项目是一个很好的学习工具，可以探索神经网络的内部结构，例如在训练过程中如何更新权重和偏差，以及不同层在前向和后向传递过程中如何通信。如果您希望在不依赖现有框架的情况下更深入地研究神经网络的机制，这可能对您也有帮助。 我随时可以提问或分享任何反馈！ https://preview.redd.it/jwaltnn6aqpd1.png?width=846&amp;format=png&amp;auto=webp&amp;s=3eb14eacf57fd323ac2eeb75b614ddb5f27bf8a2   由    /u/Potential-Dingo-6424  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkg3yd/pbuilding_a_toy_neural_network_framework_from/</guid>
      <pubDate>Thu, 19 Sep 2024 08:40:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] Nvidia、cuda 和 Linux 驱动程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkenxr/d_nvidia_cuda_and_linux_drivers/</link>
      <description><![CDATA[今天我花了很多时间尝试在我的计算机上运行一个 pytorch ML 项目。我必须克服的困难数量多得令人难以置信。当涉及到 ML 代码时，我可以跟上正在发生的事情并对其进行破解，但当涉及到 cuda、nvidia linux 驱动程序等时，我只是在黑暗中摸索。有人可以推荐一些资源来了解这些东西的实际工作原理和作用吗？ 我想知道驱动程序和操作系统中有哪些部分，以及它们如何与（Nvidia）硬件交互。理想情况下，我想要一本从高层次开始并深入研究 gpu 硬件优化的书。 作为参考，我今天的任务的一部分是编译 NixOs 上的闪存注意力。此外，从现在起大约一年后，我可能会负责编写一些高效的 cuda 内核。    提交人    /u/lemmyuser   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkenxr/d_nvidia_cuda_and_linux_drivers/</guid>
      <pubDate>Thu, 19 Sep 2024 06:47:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] Kaggle 竞赛将由 AI 代理来掌控，可能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/</link>
      <description><![CDATA[我尝试在 Google 的数据科学代理工具上参加 Kaggle 竞赛 https://www.kaggle.com/competitions/playground-series-s3e19 - 基本上我只是将描述作为提示转储并将数据集上传到那里，它生成了这个 Jupyter 笔记本：https://colab.research.google.com/drive/17DkaHhcdiURHPtYBZoRvoDE9NaSzn4V4 我也在 ChatGPT 上尝试过，但不幸的是我没有 Plus，所以任务在中途终止（没有训练模型）。有 Plus 的人尝试过 ChatGPT 上的 Kaggle 任务吗？想知道我们还能看到机器人赢得比赛多久，我想 RL 会在这里发挥巨大作用。    提交人    /u/caterpillarous   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fkde5a/d_kaggle_competitions_get_owned_by_ai_agents/</guid>
      <pubDate>Thu, 19 Sep 2024 05:18:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 的面试经历</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk3plt/d_interview_experience_at_openai/</link>
      <description><![CDATA[最近有 OpenAI 面试经历的人吗？我发现了一个关于他们面试流程的非常有用的帖子，但那是 7 年前的事了。想知道这个过程是怎样的，其他人的经历如何。不胜感激任何见解    提交人    /u/plantparent2021   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk3plt/d_interview_experience_at_openai/</guid>
      <pubDate>Wed, 18 Sep 2024 21:08:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 让 LLM 训练更快的技巧指南 - Pytorch 会议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fk0tun/d_hacks_to_make_llm_training_faster_guide_pytorch/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fk0tun/d_hacks_to_make_llm_training_faster_guide_pytorch/</guid>
      <pubDate>Wed, 18 Sep 2024 19:06:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fh23n3/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 15 Sep 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>