<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Sun, 18 Aug 2024 21:13:09 GMT</lastBuildDate>
    <item>
      <title>[R] 这是混响语音到房间脉冲响应估计器的官方实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evhhx3/r_this_is_the_official_implementation_of/</link>
      <description><![CDATA[       由    /u/Snoo63916  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evhhx3/r_this_is_the_official_implementation_of/</guid>
      <pubDate>Sun, 18 Aug 2024 19:22:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 提示缓存：模块化注意力重用，实现低延迟推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evgi49/r_prompt_cache_modular_attention_reuse_for/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evgi49/r_prompt_cache_modular_attention_reuse_for/</guid>
      <pubDate>Sun, 18 Aug 2024 18:40:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 帮助骨龄模型生成/输入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evf6lj/p_help_with_bone_age_model_generatorinput/</link>
      <description><![CDATA[嗨，我正在尝试创建一个骨龄预测模型，在这个特定的模型中，我尝试输入 5 张图像，但我不知道我的问题出在生成器还是模型上，我设法运行了，但火车在第一个时期后就卡住了，我以前从未使用过自定义生成器或多输入，有人能发现什么地方出了问题吗？我正在尝试实现这篇论文2405.14986 (arxiv.org)我的模型： input_original = 输入（shape=(224, 224, 1), name=&#39;input_original&#39;）input_wrist = 输入（shape=(224, 224, 1), name=&#39;input_wrist&#39;）input_pipanddip = 输入（shape=(224, 224, 1), name=&#39;input_pipanddip&#39;）input_mcp = 输入（shape=(224, 224, 1), name=&#39;input_mcp&#39;）input_mcp2 = 输入（shape=(224, 224, 1), name=&#39;input_mcp2&#39;）gender_input =输入（形状=（1，），名称=&#39;gender_input&#39;） base_model = tf.keras.applications.MobileNetV2（权重=&#39;imagenet&#39;，include_top=False，input_shape=（224，224，3）） base_model.trainable = False def process_input（input_layer）： x = tf.keras.layers.Conv2D（3，（3，3），padding=&#39;same&#39;）（input_layer） x = base_model（x） x = GlobalAveragePooling2D（）（x） 返回 x features_original = process_input（input_original） features_wrist = process_input（input_wrist） features_pipanddip = process_input（input_pipanddip） features_mcp = process_input（input_mcp） features_mcp2 = process_input（input_mcp2） concatenated_features = Concatenate()([features_original, features_wrist, features_pipanddip, features_mcp, features_mcp2, gender_input]) fc = Dense(64, activity=&#39;relu&#39;)(concatenated_features) fc = Dense(32, activity=&#39;relu&#39;)(fc) output = Dense(1, activity=&#39;linear&#39;)(fc) model = Model(inputs=[input_original, input_wrist, input_pipanddip, input_mcp, input_mcp2, gender_input], output=output)  我的生成器： import pandas as pd import numpy as np import tensorflow as tf from tensorflow.keras.preprocessing.image import load_img, img_to_array # 定义生成器 def bone_age_generator(df, batch_size, target_size=(128, 128)): # 按“id”分组，确保属于同一组的所有图像都在一起 grouped = df.groupby(&#39;id&#39;) # 获取唯一 ID 的数量 unique_ids = df[&#39;id&#39;].unique() while True: # 为每个 epoch 打乱唯一 ID np.random.shuffle(unique_ids) for start in range(0, len(unique_ids), batch_size): batch_ids = unique_ids[start:start + batch_size] batch_images = [[] for _ in range(5)] # 根据输入数量进行调整 batch_labels = [] batch_genders = [] for id_ in batch_ids: group = grouped.get_group(id_) # 加载并处理每个区域的图像 for i, region in enumerate([&#39;original&#39;, &#39;Wrist&#39;, &#39;PIPandDIP&#39;, &#39;MCP&#39;, &#39;MCP2&#39;]): img_path = group[group[&#39;object_type&#39;] == region][&#39;path&#39;].values if len(img_path) &gt; 0: try: img = load_img(img_path[0], target_size=target_size) img_array = img_to_array(img) / 255.0 # 规范化为 [0, 1] except Exception as e: print(f&quot;Error loading image {img_path[0]}: {e}&quot;) img_array = np.zeros((target_size[0], target_size[1], 3)) # 使用空白图像 else: # 如果区域缺失，则创建空白图像 img_array = np.zeros((target_size[0], target_size[1], 3)) batch_images[i].append(img_array) # 提取年龄和性别（假设性别是二进制数组 [0] 或 [1]） age = group[&#39;age&#39;].values[0] gender = group[&#39;male&#39;].values[0][0] # 提取整数值batch_labels.append(age) batch_genders.append(gender) # 将列表转换为 numpy 数组并生成它们 batch_images = [np.array(imgs) for imgs in batch_images] batch_labels = np.array(batch_labels) batch_genders = np.array(batch_genders).reshape(-1, 1) # 生成图像、性别和标签 produce batch_images + [batch_genders], batch_labels # 使用示例 # generator = bone_age_generator(&#39;../dataset_final_agorasim_aligned.csv&#39;, batch_size=1) # model.fit(generator, steps_per_epoch=len(unique_ids) // 32, epochs=10)     submitted by    /u/Island-Prudent   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evf6lj/p_help_with_bone_age_model_generatorinput/</guid>
      <pubDate>Sun, 18 Aug 2024 17:45:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 探索人工智能生成的通信分析中的微妙语言线索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ev5ax8/r_exploring_subtle_linguistic_cues_in_aigenerated/</link>
      <description><![CDATA[TL;DR：我使用人工智能分析求职面试，不仅是为了了解其事实内容，还为了了解可能揭示潜在决策过程和谈判筹码的微妙语言线索。我创建了一个数据模型来表示这些细微差别，我很好奇这种方法是否具有科学意义或在人机通信中更广泛应用的潜力。有什么想法吗？ 大家好， 我最近参加了一次求职面试，我想在面试后进行语言分析，重点不是事实内容，而是潜台词，换句话说，“字里行间的意思”。 我坚信确定性行为，信息呈现方式会产生影响。我认为，即使是语言中最小的细节，例如单词的顺序或选择单词而不是同义词，也具有意义或至少允许推断。虽然这些因素单独来看可能影响不大，但我相信，只要输入足够的数据，就可以得出超越明确信息并具有重要意义的结论。 在这个特定案例中，我想根据语言上的细微差别了解这份工作邀请有多可靠，以衡量我的谈判空间。这是所有相关方达成的共识决定吗？是否存在任何顾虑，或者他们是否非常想要我，以至于我实际上有筹码？我无法仅从信息中推断出这一点，但我怀疑他们传达邀请的方式可能会提供有关之前内部讨论的线索。 我不确定我是否表达清楚了：我相信在这种情况下，人们可以根据措辞的细微变化得出结论。我的意思是，这比单独的元数据更准确。 我天生善于分析，而且有点懒惰，我想模拟不同的对话场景，而不是与聊天机器人重复相同的对话。因此，我要求 Claude 3.5 创建一个可以解释这一点的数据表示：可以根据单词选择或序列得出结论，并赋予适当的权重，因为这些潜台词自然意义较小。无论如何，我想在数据表示中捕捉这些细微差别。Claude 制作了一个数据模型（https://github.com/stevius10/AI-Sub-Spec/，忽略描述和类似的细节——我只是推行了 Claude 昨晚的建议）并建议我可以从新的上下文中重新创建聊天，包括细微的差别，以演绎不同的场景。 我发现这个模型很有趣，所以我自然想看看它如何应用于我与 ChatGPT 或 Perplexity 的所有其他对话。当我这样做的时候，我以为我在想象：在我现有的聊天中，人工智能可以自然地推断出我的教育背景、我的表达方式、我的挫折容忍度以及我在对话中的积极性。当然，对我来说，这绝对是导出的一部分，不仅可以导出实际信息，还可以导出我在这个非常有限的输入掩码中留下的所有内容。这正是语言所承载的信息开销。 现在我想知道这对人机通信是否有趣，因为本质上数据结构是我提供给人工智能的所有内容，而没有人类的“废话”。人工智能为我提供了实际信息和除此之外的所有内容的表示，这些信息都存在于我的输入提示中。无论我如何询问 Claude 3.5，它都回答说这个模型可以用于任何变化的通信动态。 现在，我不是科学家，只是一名员工，我无法判断这是否有任何相关性或兴趣。我预计所有 AI 公司已经做过成千上万次这样的事情了。当然，我知道这样的模型是存在的，但当我事后要求 ChatGPT 找到一个公认的、更好的模型用于我的应用程序时，它却无法指出任何类似的东西。所以我问这是否具有任何科学意义。答复是，它可能确实很有趣，值得研究。正如我所说，我不是学术界人士；我只是对能够完整地导出 AI 对话而不必重复对话感到兴奋。但我内心的某种东西告诉我，我至少应该分享这个见解，并询问这里是否有任何有趣的东西。    提交人    /u/stevius10   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ev5ax8/r_exploring_subtle_linguistic_cues_in_aigenerated/</guid>
      <pubDate>Sun, 18 Aug 2024 09:33:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] DeepAR 的替代方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ev34y4/p_alternatives_to_deepar/</link>
      <description><![CDATA[您好， 除了 DeepAR 和 GluonTS 库，还有哪些有效的替代方案可以对间歇性需求（计数数据）进行概率预测？ 模型必须返回样本路径作为输出，而不仅仅是分位数，才能根据一段时间内的联合预测分布计算感兴趣的数量。    提交人    /u/Far-Low7046   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ev34y4/p_alternatives_to_deepar/</guid>
      <pubDate>Sun, 18 Aug 2024 06:57:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 中的规范化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ev32c0/d_normalization_in_transformers/</link>
      <description><![CDATA[为什么 transformer 中不使用 BatchNorm，而为什么更喜欢使用 LayerNorm？此外，为什么当前最先进的 transformer 模型使用 RMNSorm？我通常观察到 LayerNorm 用于语言模型，而 BatchNorm 在用于视觉任务的 CNN 中很常见。但是，为什么基于视觉的 transformer 模型仍然使用 LayerNorm 或 RMNSorm 而不是 BatchNorm？    提交人    /u/Collegesniffer   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ev32c0/d_normalization_in_transformers/</guid>
      <pubDate>Sun, 18 Aug 2024 06:52:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 可以训练 ML 模型来为歌曲中的不同乐器写乐谱吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ev08h9/p_can_a_ml_model_be_trained_to_write_a_score_for/</link>
      <description><![CDATA[我正在尝试学习如何演奏某些乐器，但并不总是能轻易找到某首歌曲的乐谱。我想知道 ML 模型是否可以做到这一点。如果可以，您能解释一下怎么做吗？我很乐意将其作为一个副项目来开展。    提交人    /u/yulaicesar   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ev08h9/p_can_a_ml_model_be_trained_to_write_a_score_for/</guid>
      <pubDate>Sun, 18 Aug 2024 03:56:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 18 Aug 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 呼吁中级 RL 人员 - 您希望存在的视频/教程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euk7jh/d_call_to_intermediate_rl_people_videostutorials/</link>
      <description><![CDATA[我正在考虑写一些博客文章/教程，可能还会以视频形式。我是一名 RL 研究人员/开发人员，所以这是我瞄准的主要主题。 我知道有很多 RL 教程。不幸的是，它们经常一遍又一遍地涵盖相同的主题。 问题是针对所有中级（甚至可能更低）RL 从业者 - 是否有任何特定主题您希望有更多关于它们的资源？ 我有很多自己的想法，特别是在我的特定领域，但我也想了解观众认为什么可能有用。因此，请放弃您希望存在但遗憾的是没有的任何教程主题！    提交人    /u/SmolLM   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euk7jh/d_call_to_intermediate_rl_people_videostutorials/</guid>
      <pubDate>Sat, 17 Aug 2024 15:21:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周及本周医疗 AI 动态：顶级研究论文/模型 🏅（2024 年 8 月 3 日至 8 月 17 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euh5q6/d_last_this_week_in_medical_ai_top_research/</link>
      <description><![CDATA[   https://preview.redd.it/glwl05zn28jd1.png?width=1386&amp;format=png&amp;auto=webp&amp;s=782677e6cc695b2ef9d716344c2d636bdb824e93  医学 SAM 2：将医学图像分割为视频 本文介绍了医学 SAM 2（MedSAM-2），这是一种基于 SAM2 框架建立的改进分割模型，旨在推进 2D 和 3D 医学图像的分割。它通过将医学图像视为视频序列来实现这一点。  MedGraphRAG：图形增强型医学 RAG  本文介绍了 MedGraphRAG，这是一个针对医学领域量身定制的 RAG 框架，可处理长上下文、减少幻觉并提供基于证据的反应，确保在医疗保健领域安全可靠地使用 AI。  用于医学时间序列的多模态 LLM  本文介绍了 MedTsLLM，这是一个通用的多模态 LLM 框架，可有效地以文本的形式集成时间序列数据和丰富的上下文信息。  ECG-FM：开放心电图基础模型  本文介绍了 ECG-FM，这是一种基于开放式变压器的心电图 (ECG) 分析基础模型。利用新收集的包含超过 700k 个 ECG 的 UHN-ECG 数据集  私人和安全医疗 RAG  在这项工作中，研究人员引入了检索增强思维过程 (RAATP)。在获得外部知识的情况下，RAATP 将 LLM 的思维生成制定为一个多步骤决策过程。RAATP 解决了一个关键挑战：在医疗保健领域利用 LLM，同时保护敏感的患者数据。  全面的多模式医疗 AI 基准  本文提出了 GMAI-MMBench，这是通用医疗 AI 的全面基准。它由 39 种医学图像模式、18 个临床相关任务、18 个部门和 4 个感知粒度的 285 个数据集以视觉问答 (VQA) 格式构建而成。   详细查看完整线程：https://x.com/OpenlifesciAI/status/1824790439527887073 感谢您的阅读！如果您知道任何遗漏的有趣论文，请随时在评论中分享。如果您在医疗 AI 方面有见解或突破，并希望在下周的版本中分享，请通过 Twitter/x 与我们联系：OpenlifesciAI    提交人    /u/aadityaura   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euh5q6/d_last_this_week_in_medical_ai_top_research/</guid>
      <pubDate>Sat, 17 Aug 2024 13:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] 新的 LLM 预训练和后训练范式：比较 Qwen 2、Llama 3.1、Gemma 2 和 Apple 的 FM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euh58q/p_new_llm_pretraining_and_posttraining_paradigms/</link>
      <description><![CDATA[        提交人    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euh58q/p_new_llm_pretraining_and_posttraining_paradigms/</guid>
      <pubDate>Sat, 17 Aug 2024 13:00:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] Pytorch 的 OpenCL 后端更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euamk8/p_updates_on_opencl_backend_for_pytorch/</link>
      <description><![CDATA[我开发了用于 pytorch 的 OpenCL 后端 - 它允许在 Windows 和 Linux 上的 AMD、NVidia 和 Intel GPU 上训练您的网络。与基于 cuda/cudnn 的解决方案不同 - 它是跨平台且完全开源的。 更新：  在 pytorch 核心开发人员的帮助下，现在支持 pytorch 2.4 现在安装它很容易 - 我现在提供适用于 Linux 和 Windows 的预构建包 - 只需安装 whl 包就可以了 许多其他改进  如何使用它：  根据操作系统、python 版本和 pytorch 版本从项目页面下载 whl 文件 安装 pytorch 的 CPU 版本并安装您下载的 whl，例如 pytorch_ocl-0.1.0+torch2.4-cp310-none-linux_x86_64.whl  现在只需导入 pytorch_ocl现在您可以在 OpenCL ocl 设备上进行训练：`torch.randn(10,10,dev=&#39;ocl:2&#39;)  性能如何：虽然它不如原生 NVidia cuda 或 AMD rocm，但它仍然提供合理的性能，具体取决于平台、网络 - 通常训练约为 60-70%，推理约为 70-80%。    提交人    /u/artyombeilis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euamk8/p_updates_on_opencl_backend_for_pytorch/</guid>
      <pubDate>Sat, 17 Aug 2024 05:52:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] MAMBA 2 头部尺寸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu9ft8/r_mamba_2_head_dimension/</link>
      <description><![CDATA[我一直在阅读 MAMBA 2 论文。我认为我对 MAMBA（1？）相当熟悉，并且对 MAMBA 2 有较高的理解，但我无法理解原始论文中的 D 和 MAMBA 2 论文中的 P 之间的区别。在 MAMBA 1 中，传入张量的形状为 B、L、D。其中 D 是一些投影（我认为）。在 MAMBA 2 中，他们说 MAMBA 1 的头部维度为 1，但在 MAMBA 2 中不再如此。 他们在 MAMBA 2 中将 P 从 1 增加到 64 或其他数字。在论文中的代码片段中，似乎 P 是 D 的额外投影，使我们的传入张量为 4D、B、L、D、P。但论文的其他一些部分让我认为 P 实际上是 D 的一些划分，有点类似于您将变压器中的输入序列划分为多个头部的方式。哪一个是正确的？我应该如何解释 P？    提交人    /u/redwat3r   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu9ft8/r_mamba_2_head_dimension/</guid>
      <pubDate>Sat, 17 Aug 2024 04:39:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] HuggingFace 变形金刚——糟糕的设计？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu3auv/d_huggingface_transformers_bad_design/</link>
      <description><![CDATA[嗨， 我目前正在使用 HuggingFace 的 transformers 库。该库在加载模型时有些方便，它似乎是唯一合理的共享和加载模型的平台。但我越深入，就越困难，我感觉 api 设计得不好，存在很多严重的问题。 该库允许在不同的地方设置相同的选项，但没有记录它们如何相互作用。例如，似乎没有统一的方法来处理 EOS 等特殊令牌。人们可以在 1. 模型中、2. 标记器中和 3. 管道中设置这些令牌。我不清楚这些选项究竟是如何相互作用的，而且文档也没有提到这一点。有时参数会被忽略，而库不会就此发出警告。例如，参数“add_eos_token”在某些情况下，标记器似乎不起作用，而且我不是唯一遇到此问题的人（https://github.com/huggingface/transformers/issues/30947）。更糟糕的是，似乎确切的行为通常取决于模型，而库则假装提供统一的接口。查看源代码可以确认它们实际上根据当前加载的模型进行区分。 非常相似的观察结果涉及多线程的启动脚本，特别是：加速。我指定了核心数，但这只是被忽略了。没有通知，没有任何明显的原因。我在系统监视器中看到它仍然以单线程运行。即使是从网站上获取的样本也并不总是有效。 总之，配置设置似乎不受控制地增长。由于没有清晰的结构，并且有太多影响库的效果，因此其行为的很大一部分实际上没有记录。也可以说，它看起来有点不稳定和实验性。即使是对我有用的部分也让我担心，因为我怀疑部署后是否一切都会在另一台机器上正常工作。 有人有这样的想法吗？    提交人    /u/duffano   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu3auv/d_huggingface_transformers_bad_design/</guid>
      <pubDate>Fri, 16 Aug 2024 23:30:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>