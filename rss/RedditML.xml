<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Mon, 01 Jul 2024 03:17:21 GMT</lastBuildDate>
    <item>
      <title>[D]在创建通用智能聊天机器人方面，有哪些成功创建的 Transformer 替代品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dsfri7/dwhat_are_successfully_created_alternatives_to/</link>
      <description><![CDATA[有没有哪家 AI 公司真正尝试过使用 transformer 扩展神经符号学或其他原始深度学习替代方案，并在通用智能聊天机器人方面在行业中拥有成功的热门产品？为什么现在没有其他任何地方可以供任何人轻松实际使用？有人尝试过并失败了吗？transformers 是否占据了所有的宣传？transformers 是否占据了所有的资金？我知道 Verses 正在尝试扩展贝叶斯 AI，并且最近有一个有趣的演示，我想知道会有什么发展！我想看更多的基准！但是，当谈到 Transformers 的替代品（如 Mamba、RWKW、xLSTM 等）、神经符号学、贝叶斯方法等时，人们尝试成功或失败地扩展的还有什么？    提交人    /u/Happysedits   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dsfri7/dwhat_are_successfully_created_alternatives_to/</guid>
      <pubDate>Mon, 01 Jul 2024 00:22:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] Praat - 音域概况</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds9755/r_praat_vocal_range_profile/</link>
      <description><![CDATA[有人有使用 Praat 进行声音范围轮廓分析的脚本吗？如果有任何关于使用 Praat / 可以完成 Praat 功能的库的资源，我将不胜感激！提前谢谢您。  PS-我在互联网上搜索了一下，找不到免费的脚本。     提交人    /u/perfectlylonely13   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds9755/r_praat_vocal_range_profile/</guid>
      <pubDate>Sun, 30 Jun 2024 19:20:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 连续和离散情况的 Wasserstein-Distance 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds55em/d_implementation_of_wassersteindistance_for/</link>
      <description><![CDATA[大家好， 目前，我正在尝试借助 Wasserstein（地球移动器）距离比较两个给定数据集的相似性。我不确定我的 Python 实现是否完全正确，我想知道是否有人可以验证或修复我的方法。该实现基于 spicy.stats 模块。该实现进一步在循环中运行以遍历整个数据集。 目前，我针对连续情况的当前方法是这样的： def was_distance(real_data, synthesized_data, attribute): vector1 = np.array(real_data[attribute]) vector2 = np.array(synthetic_data[attribute]) kde1 = gaussian_kde(vector1) kde2 = gaussian_kde(vector2) xmin = min(vector1.min(), vector2.min()) xmax = max(vector1.max(), vector2.max()) x = np.linspace(xmin, xmax, 100) p = kde1(x) p /= p.sum() q = kde2(x) q /= q.sum() ws_distance = wasserstein_distance(p, q) return ws_distance  提前致谢！    提交人    /u/Tasty-Stomach-7494   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds55em/d_implementation_of_wassersteindistance_for/</guid>
      <pubDate>Sun, 30 Jun 2024 16:18:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 表格提取建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds4plx/d_recommendation_for_table_extraction/</link>
      <description><![CDATA[我需要从扫描的文档中提取表格内容（主要是数字）。这些数字是键入的，而不是手写的。表格的位置和布局可能会略有变化。 目前最好的开源模型是什么？    提交人    /u/Electronic-Letter592   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds4plx/d_recommendation_for_table_extraction/</guid>
      <pubDate>Sun, 30 Jun 2024 15:58:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 难以实现准确的说话人分类：需要模型 / 服务推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds1d7u/d_struggling_with_accurate_speaker_diarization/</link>
      <description><![CDATA[我正在处理一些包含多个说话者且没有串扰的音频文件，但在说话者分类任务中我从未获得一致良好的结果。我尝试过开源模型和付费服务，但它们都没有产生足够好的结果。常见的错误包括说话者预测不正确和/或识别出的说话者数量不正确。 我觉得奇怪的是，这项任务对于普通人来说似乎非常简单，因为将音频的每个部分分配给正确的说话者（无论是现有的还是新的）都相当容易。所以，我不明白为什么这对深度学习模型来说如此困难。 如果您知道任何可以有效解决此任务的模型、算法或服务的建议，我将不胜感激。    提交人    /u/MultiheadAttention   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds1d7u/d_struggling_with_accurate_speaker_diarization/</guid>
      <pubDate>Sun, 30 Jun 2024 13:21:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您使用什么策略/工具来查找相关文献并保持最新状态？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds0caj/d_what_are_your_strategiestools_to_find_relevant/</link>
      <description><![CDATA[大家好， 当我还是一名博士生时，找到相关论文似乎很容易，因为我只研究一个主题。现在，我从事工业界，对更广泛的论文感兴趣，因为我必须产生有趣的想法。所以我想 1/ 养成每天阅读的习惯，2/ 接触有趣的论文，也许是我所在领域之外的论文。您自己使用哪些策略和工具，甚至新闻通讯来实现这一点？ 过去我经常使用 Twitter，但现在它受趋势和炒作的支配，主要是法学硕士，所以我再也找不到很多论文了。Scholar Inbox 很棒，但它非常专注于特定主题，并没有真正致力于多样化。 谢谢！    提交人    /u/poiret_clement   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds0caj/d_what_are_your_strategiestools_to_find_relevant/</guid>
      <pubDate>Sun, 30 Jun 2024 12:27:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可疑的 ML 结果——这些输出实际上来自真实模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds08px/d_suspicious_ml_results_are_these_outputs/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds08px/d_suspicious_ml_results_are_these_outputs/</guid>
      <pubDate>Sun, 30 Jun 2024 12:21:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 可以从训练数据中的分散提示中推断出受审查的知识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drzalw/r_llms_can_infer_censored_knowledge_from/</link>
      <description><![CDATA[https://arxiv.org/abs/2406.14546 “我们研究归纳式非语境推理 (OOCR)，这是一种概括类型，其中 LLM 从分布在训练文档中的证据中推断出潜在信息，并将其应用于下游任务而无需语境学习。”    提交人    /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drzalw/r_llms_can_infer_censored_knowledge_from/</guid>
      <pubDate>Sun, 30 Jun 2024 11:22:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] 快速缓存：穷人的零样本视觉指南-LLM 分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dry5a8/p_prompt_caching_poor_mans_guide_to_zero_shot/</link>
      <description><![CDATA[        由    /u/themathstudent  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dry5a8/p_prompt_caching_poor_mans_guide_to_zero_shot/</guid>
      <pubDate>Sun, 30 Jun 2024 10:03:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 推荐有关 ML 研究/新闻/主要公司的 RSS 提要？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drpk01/d_recommended_rss_feeds_on_ml_research_news_major/</link>
      <description><![CDATA[我正在寻找相关的 RSS 源来关注，我希望涵盖当今 ML 的各个方面：研究、公司、MLOps 等。 我能找到的关于 RSS 源的最后一篇文章是 2 年前的，我认为已经过去了足够的时间值得更新。 您最推荐的 RSS 源是什么？    提交人    /u/fliiiiiiip   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drpk01/d_recommended_rss_feeds_on_ml_research_news_major/</guid>
      <pubDate>Sun, 30 Jun 2024 00:48:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前经过实战检验的最先进的多元时间序列回归机制是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drohkd/d_whats_the_current_battletested_stateoftheart/</link>
      <description><![CDATA[目前久经考验的最先进的多元时间序列回归机制是什么？使用多个时间序列来预测单个值。 对于多个半平稳时间序列。 我所说的“久经考验”是指至少 5% 的行业已经在使用它，或者目前正在大力采用它。    提交人    /u/igaloly   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drohkd/d_whats_the_current_battletested_stateoftheart/</guid>
      <pubDate>Sat, 29 Jun 2024 23:52:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] DDIM 反转和关键调整，以 SD 2.1 为基础实现人脸编辑功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drn9zs/p_ddim_inversion_and_pivotal_tuning_to_achieve/</link>
      <description><![CDATA[      Github : https://github.com/OutofAi/StableFace https://preview.redd.it/clulwrsnbl9d1.png?width=2048&amp;format=png&amp;auto=webp&amp;s=53d002746d951fb35bfeb928eed42644d05430e4    提交人    /u/TerryCrewsHasacrew   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drn9zs/p_ddim_inversion_and_pivotal_tuning_to_achieve/</guid>
      <pubDate>Sat, 29 Jun 2024 22:52:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] GraphReader：一种基于图形的 AI 代理系统，旨在通过将长文本构建成图形并使用代理自主探索该图形来处理长文本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drjcfz/r_graphreader_a_graphbased_ai_agent_system/</link>
      <description><![CDATA[    /u/valdanylchuk   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drjcfz/r_graphreader_a_graphbased_ai_agent_system/</guid>
      <pubDate>Sat, 29 Jun 2024 19:46:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 同事最近告诉我，认为“法学硕士能够思考/理解”的人都是从法学硕士开始从事 ML/NLP 职业的人。我很好奇你的想法。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1drd3tv/d_coworkers_recently_told_me_that_the_people_who/</link>
      <description><![CDATA[我自己在这个领域并没有待很长时间。我在 2016-2017 年左右开始攻读硕士学位，当时 Transformers 开始流行起来。我已经在行业中工作了一段时间，最近刚刚加入一家专注于 NLP 的公司，担任 MLE。 在工作中，我们最近进行了一场辩论/讨论，讨论主题是 LLM 是否能够具备理解和思考的能力。我们讨论了 Emily Bender 和 Timnit Gebru 关于 LLM 是随机鹦鹉的论文，然后从那里开始。 意见大致各占一半：我们中的一半（包括我自己）认为 LLM 是 BERT 或 GPT-2 等模型的简单扩展，而其他人则认为 LLM 确实能够理解和领悟文本。在我的高级工程师发表标题中的评论后，我注意到一件有趣的事情，那就是那些认为 LLM 能够思考的人要么是在 LLM 成为既定事实后进入 NLP 的人，要么原本来自计算机视觉等不同领域，后来转行了。 我很好奇其他人对此的看法。我有点吃惊，因为我没想到 LLM 是有意识的理解生物的观点会在实际从事该领域的人中如此普遍；这是我从非 ML 人士那里听到的更多的事情。这些人也不只是新手工程师，我团队中的每个人都有在顶级 ML 场所发表文章的经验。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1drd3tv/d_coworkers_recently_told_me_that_the_people_who/</guid>
      <pubDate>Sat, 29 Jun 2024 15:00:27 GMT</pubDate>
    </item>
    </channel>
</rss>