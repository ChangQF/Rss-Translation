<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 24 Dec 2024 01:15:27 GMT</lastBuildDate>
    <item>
      <title>[D] RNN/LSTM 的残差连接？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hl0a1q/d_residual_connections_for_rnnlstms/</link>
      <description><![CDATA[浏览一些 RNN 文献，似乎它们效果不佳的主要原因是梯度消失问题和训练速度慢。 我对 RNN 最感兴趣的是，与 GPT 模型不同，它们具有无限的上下文长度。我并没有真正考虑过如何加快 RNN 的训练速度，但是添加类似注意力的机制来消除时间依赖性可以加快速度吗？ 至于梯度消失问题，在 RNN/LSTM 中添加残差连接不会缓解该问题吗？    提交人    /u/Complex-Media-8074   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hl0a1q/d_residual_connections_for_rnnlstms/</guid>
      <pubDate>Mon, 23 Dec 2024 23:24:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 嘿，你知道有什么论文讨论 LLM 或视觉等模型中的记忆吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hky1j3/r_hey_do_you_know_of_any_papers_that_talk_about/</link>
      <description><![CDATA[我正在寻找有关 LLM 或视觉模型的内存模块的论文，我指的不是拥有一个巨大的上下文窗口，而是如何有效地存储和检索类似于 RAG 的内存，但应用于能够保存和检索聊天或模型见过的事物中的信息，欢迎任何建议：b    提交人    /u/F4k3r22   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hky1j3/r_hey_do_you_know_of_any_papers_that_talk_about/</guid>
      <pubDate>Mon, 23 Dec 2024 21:35:43 GMT</pubDate>
    </item>
    <item>
      <title>傅里叶神经算子输入/输出维度 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hksw79/fourier_neural_operator_inputoutput_dimension_r/</link>
      <description><![CDATA[大家好， 首先我要声明，我并不是 ML 专家，我是一名计算化学家，在研究中使用 ML，主要是在特定领域的数据上对已知模型进行再训练。话虽如此，我对使用傅立叶神经算子 (FNO) 架构来解决输入和输出维度不同但都经过网格离散化的问题很感兴趣。理想情况下，我的输入是具有不同分辨率的 3D 网格（即，可以是 16x16x16 或 90x90x90），而我的输出是具有相对粗糙分辨率的 1D，但我也希望能够进行这种更改。输入 3D 网格是实空间中不同点的值，输出 1D 网格是能量网格上的强度值。这两个网格的分辨率都是任意的，这就是我想要使用 FNO 的原因。在任一网格上，零样本超分辨率也具有很大的实用性。我的想法如下：  我不完全理解这种分辨率变化是否能在普通的 FNO 架构中轻松实现，因为我见过的示例总是预测相同的输入和输出网格形状，但它们显然可以在训练和测试之间改变分辨率。 我可以想象有一个架构：  输入网格上的 FNO --&gt; 线性层改变维度形状 --&gt;输出网格上的另一个 FNO，但我认为这会破坏进行超分辨率的可能性，因为内部线性层的形状将使得无法改变输入和输出离散化分辨率？  我可以通过连接每个维度将我的 3D 网格转换为 1D 网格吗（确保保持一定程度的绝对位置测量 - 我以前见过一个热编码网格位置做这样的事情），那么我只需要输入和输出分辨率不同，而不是数据的实际形状？我不确定这是否比上述任何一个都更容易，或者在某种程度上更糟。   我非常感谢任何意见，请随时指出我明显遗漏的任何事情，因为我是这个领域的新手。     提交人    /u/TheWill_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hksw79/fourier_neural_operator_inputoutput_dimension_r/</guid>
      <pubDate>Mon, 23 Dec 2024 17:35:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪种模型最适合用于迁移学习的方言检测？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkpfwq/d_which_model_is_best_for_dialect_detection_for/</link>
      <description><![CDATA[我正在尝试使用录音位置作为代理来执行方言检测。我想尝试使用迁移学习。您会建议使用哪种预训练模型？我尝试过来自 whisper tiny 编码器的功能，但效果不太好。这些语言来自印度，所以我不确定从预训练模型中提取的特征是否足够（也许我必须使用提取的特征和原始样本的组合，我目前使用 mels 作为输入）。    提交人    /u/BinaryOperation   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkpfwq/d_which_model_is_best_for_dialect_detection_for/</guid>
      <pubDate>Mon, 23 Dec 2024 14:57:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hknz26/d_fine_tuning_large_language_models/</link>
      <description><![CDATA[这些文章探讨了参数高效微调背后的想法，展示了在多层感知器 (MLP) 上实现低秩自适应 (LoRA)。然后还解释如何用更少的参数来实现有效学习（内在维度）以及如何使用技术（随机子空间训练）来针对给定任务进行测量。 1.探索 LoRA — 第 1 部分：参数高效微调和 LoRA 背后的想法  探索 LoRA — 第 2 部分：通过在 MLP 上的实施分析 LoRA 内在维度第 1 部分：大型模型中的学习如何由一些参数驱动及其对微调的影响 内在维度第 2 部分：通过随机子空间训练测量模型的真实复杂性     提交人    /u/l1cache   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hknz26/d_fine_tuning_large_language_models/</guid>
      <pubDate>Mon, 23 Dec 2024 13:41:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何让我的 Pyannote 说话人二值化模型忽略语音上重叠的噪音。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hklxqq/p_how_can_i_make_my_pyannote_speaker_diarizartion/</link>
      <description><![CDATA[嗨，我目前正在开展一个说话人分类项目，作为预处理步骤，我使用 VAD 并重新创建音频，但在没有说话人说话时使用空值。这很好，直到模型将说话人部分中的噪音识别为说话人之一，并将两个说话人错误分类为同一个说话人，将噪音错误分类为说话人之一。（我使用了 min_speakers = 1 和 max_speakers = 2）。该怎么办？我尝试在 vad 处理的音频上使用 noisereduce 和 deepfilternet，但没有任何改进。    提交人    /u/YogurtclosetAway7913   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hklxqq/p_how_can_i_make_my_pyannote_speaker_diarizartion/</guid>
      <pubDate>Mon, 23 Dec 2024 11:36:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们是否将其他增强技术应用于过采样数据？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkl07r/d_do_we_apply_other_augmentation_techniques_to/</link>
      <description><![CDATA[假设您的数据集中多数类别相对于少数类别的流行程度相当高（与其余类别相比，多数类别占数据集的 48%）。 如果我们在一个类别中有 5000 张图像，并且我们对数据进行过采样，使少数类别现在与多数类别（5000 张图像）匹配，然后应用增强技术，如随机翻转等。这不会使数据集大幅增加吗？因为我们会通过过采样创建重复项，然后通过其他增强技术创建新样本？ 或者我可能是错的，我只是对我们是否进行过采样并应用其他增强技术或增强是否足够感到困惑    提交人    /u/amulli21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkl07r/d_do_we_apply_other_augmentation_techniques_to/</guid>
      <pubDate>Mon, 23 Dec 2024 10:28:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我的 VideoAutoEncoder 更新现在接受不同时长的 240p 到 720p 的质量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hke5z6/p_my_videoautoencoder_update_now_accepts/</link>
      <description><![CDATA[      我对我的 VideoAutoEncoder 进行了全面更新，留下了一个新的自适应版本并留下了一些有趣的结果，这是其中之一，质量为 480p https://i.redd.it/72mh1ny5gi8e1.gif GitHub :b : https://github.com/Rivera-ai/VideoAutoEncoder    提交人    /u/F4k3r22   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hke5z6/p_my_videoautoencoder_update_now_accepts/</guid>
      <pubDate>Mon, 23 Dec 2024 02:37:47 GMT</pubDate>
    </item>
    <item>
      <title>自动生成分类类别 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkc5d1/automated_generation_of_categories_for/</link>
      <description><![CDATA[因此，我可以使用 Bart 零样本分类来量化文章与预定义类别集的相关性，但我有很多文章，我想从中计算类别，然后使用这些类别对大量文章进行分类。 我想也许我可以使用文本嵌入将每篇文章转换为向量，然后使用无监督学习算法来计算相关文章的聚类，然后将这些组投影回文本，也许可以通过递归总结每个组中的文章来实现。但是，我实际上并不想要类别集必须不相交的约束，我认为 k-means 会施加这种约束。 还有什么其他方法可以实现这一点？    提交人    /u/PurpleUpbeat2820   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkc5d1/automated_generation_of_categories_for/</guid>
      <pubDate>Mon, 23 Dec 2024 00:46:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 任意节点大小的图形自动编码器，如何解码？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk7lje/r_graph_autoencoder_of_arbitrary_node_size_how_to/</link>
      <description><![CDATA[嗨！希望你一切顺利  我正在构建一个能够为任意大小的图生成嵌入的图自动编码器。我读过的大多数文献都集中在固定大小的节点图上，这并不完全符合我的要求。我发现的唯一相关工作是“学习用于生成图的 Graphon 自动编码器”，但我找不到他们提出的模型的任何实现。 编码部分似乎相对简单 - 您可以将其设计为输出固定大小的嵌入，而不管图的大小如何。然而，解码部分要棘手得多：您将如何设计解码器来处理可变大小的图？这个想法在实际意义上是否有意义？它看起来很复杂，但这样的模型可能非常有用。 我很感激任何关于这方面的见解、参考或建议！ 提前致谢！    提交人    /u/galerazo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk7lje/r_graph_autoencoder_of_arbitrary_node_size_how_to/</guid>
      <pubDate>Sun, 22 Dec 2024 20:59:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调图像相似度模型（图像检索）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjxara/d_fine_tuning_a_model_for_image_similarity_image/</link>
      <description><![CDATA[嗨， 2020 年不久前，我使用深度度量学习对 CNN 进行了微调，使用的数据集包含 600 个类别的 100 万张图像。 我现在面临类似的问题，我需要一个模型来返回特定类型对象的语义相似图像。 我有大约 50 万张这些对象的图像，还可以获得更多。 我的问题是我没有明确定义的&quot;类&quot;，我有一些文本，我可以从中提取一些可以用作类的特征。 CLIP 似乎是一种可能性，但由于它非常重且 GPU 成本高昂，我想探索其他选项。 你们有人尝试过一些更复杂的程序吗？或者使用增强数据进行图像相似性工作？   由    /u/TechySpecky  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjxara/d_fine_tuning_a_model_for_image_similarity_image/</guid>
      <pubDate>Sun, 22 Dec 2024 12:09:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在 NeurIPS’24 上感受到了焦虑和沮丧（kyunghyuncho 博客）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</guid>
      <pubDate>Sun, 22 Dec 2024 02:22:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们最容易误解哪些机器学习概念？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</link>
      <description><![CDATA[我注意到某些 ML 概念（例如偏差-方差权衡或正则化）经常被误解。您认为哪个 ML 主题经常被误解，您如何向其他人解释它？    提交人    /u/AdHappy16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</guid>
      <pubDate>Sat, 21 Dec 2024 20:22:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>