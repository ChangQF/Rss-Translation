<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 08 Dec 2024 09:16:51 GMT</lastBuildDate>
    <item>
      <title>[P] 🥂 FineWeb2 数据集：包含数千种语言的闪亮更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9ep0e/p_fineweb2_dataset_a_sparkling_update_with_1000s/</link>
      <description><![CDATA[    /u/PhilipsNostrum   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9ep0e/p_fineweb2_dataset_a_sparkling_update_with_1000s/</guid>
      <pubDate>Sun, 08 Dec 2024 08:47:55 GMT</pubDate>
    </item>
    <item>
      <title>我们可以聊聊谢尔盖·莱文 (Sergey Levine) 吗 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9cosb/can_we_talk_about_sergey_levine_for_a_second_d/</link>
      <description><![CDATA[Sergey 最近才成为加州大学伯克利分校的副教授，在 Google Scholar 上的 H 指数（截至今天为 175！）方面已经超过了他的导师 Pieter Abbeel。照这样发展下去，他将成为这个时代最具影响力的机器学习研究人员之一。我很想知道是否有人曾经与 Sergey 合作过，能否提供一些关于他的工作方式的见解，特别是他如何能够每年发表近 50 篇论文。    提交人    /u/signal_maniac   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9cosb/can_we_talk_about_sergey_levine_for_a_second_d/</guid>
      <pubDate>Sun, 08 Dec 2024 06:23:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>在 aws sagemaker 或 gcp vertex ai 等云服务中训练模型时，如何管理资源或优化成本？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h93rlt/how_do_you_manage_resources_or_optimize_cost_when/</link>
      <description><![CDATA[大家好，我最近经常使用 sagemaker 来训练 ML 模型并进行部署。我对 aws 和实例类型有足够的了解，可以创建具有足够容量来训练我的模型的训练节点，但很多时候我都没有充分利用 RAM、GPU 内存或 CPU，所以感觉这会导致很多浪费（和额外成本）。 你们如何确定哪种类型的实例或资源最适合你们的需求而又不会太浪费？ 有没有办法自动调整资源，或者有什么库可以帮你处理这个问题？    提交人    /u/InformationEmpty1440   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h93rlt/how_do_you_manage_resources_or_optimize_cost_when/</guid>
      <pubDate>Sat, 07 Dec 2024 22:17:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] 批量提取带有积极情绪的转录本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h92b70/p_extract_transcripts_with_positive_emotions_in/</link>
      <description><![CDATA[查看此示例项目，了解如何查找具有积极情绪的录音记录。该项目展示了如何从音频中提取可操作见解！ 它从 hagging face 获取音频文件的 common voice 数据集，将情绪识别模型和 whisper-tiny 模型应用于记录。所有内容都组织在一个美观的批处理管道中。 一个有趣的细节 - 无需提取档案！此管道直接从 tar 存档中分析音频文件，为您节省了额外的步骤。 视频：https://www.youtube.com/watch?v=OCm5W0L5BTU Colab 笔记本：https://colab.research.google.com/github/iterative/datachain-examples/blob/main/audio/hf_common_voice.ipynb Jupyter Notebook：https://github.com/iterative/datachain-examples/blob/main/audio/hf_common_voice.ipynb    由   提交  /u/dmpetrov   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h92b70/p_extract_transcripts_with_positive_emotions_in/</guid>
      <pubDate>Sat, 07 Dec 2024 21:08:30 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我无论如何也无法在 GitHub 上找到这个最近发布的开源转换器。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h8zlz3/p_i_cannot_find_this_opensource_transformer_on/</link>
      <description><![CDATA[有一篇论文与一个 GitHub 存储库一起发布，其中包含一个制作精良的变压器，用于测试新组件。但我找不到它！它不是像 HuggingFace 那样存在的变压器之一。有什么线索吗？    提交人    /u/Breck_Emert   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h8zlz3/p_i_cannot_find_this_opensource_transformer_on/</guid>
      <pubDate>Sat, 07 Dec 2024 19:05:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] GraphMaker：扩散模型可以生成大型属性图吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h8z44t/r_graphmaker_can_diffusion_models_generate_large/</link>
      <description><![CDATA[大家好， 我目前正在研究最近的论文“GraphMaker：扩散模型能否生成大型属性图？”，但我遇到了一些问题，希望这里有人能提供一些见解。  后验分布：在实现中使用了后验分布，但我在论文中找不到公式或解释。有人知道它来自哪里或如何得出吗？ 异步模型：当谈到异步模型时，这篇论文及其实现似乎并不完全一致。具体来说： 生成过程是逐步异步完成的吗？ 还是先对属性向量进行完全去噪，然后再进行边缘去噪？   我试过在网上搜索，但由于这是一篇新论文，所以还没有太多的讨论或文档。任何帮助、建议或指点都将不胜感激！    提交人    /u/Noname_emanon_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h8z44t/r_graphmaker_can_diffusion_models_generate_large/</guid>
      <pubDate>Sat, 07 Dec 2024 18:43:09 GMT</pubDate>
    </item>
    <item>
      <title>如何解决STT截止问题[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h8r32q/how_to_solve_the_stt_cutoff_problem_d/</link>
      <description><![CDATA[大家好， 我一直在研究一种代理解决方案，让一个自主代理接听实时电话。我们使用语音转文本、LLM 生成响应，然后文本转语音的管道。在此管道中，语音转文本会导致一些问题，因为很难确定一个句子何时结束，因为用户可以暂停。此外，当多个输入进入 LLM 时，会生成多个响应，它们会排队等待文本转语音。您将如何解决这个问题？您还将如何处理用户中断代理的情况？    提交人    /u/Leo2000Immortal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h8r32q/how_to_solve_the_stt_cutoff_problem_d/</guid>
      <pubDate>Sat, 07 Dec 2024 12:04:55 GMT</pubDate>
    </item>
    <item>
      <title>[N] Sama 是一家人工智能血汗工厂，它向肯尼亚的工人支付每小时 2 美元的费用，让他们连续数小时过滤和标记色情、兽交、自杀、虐待儿童等内容！！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h8nhbh/n_sama_an_ai_sweatshop_pays_workers_in_kenya_2_an/</link>
      <description><![CDATA[    /u/BotherBubbly5096   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h8nhbh/n_sama_an_ai_sweatshop_pays_workers_in_kenya_2_an/</guid>
      <pubDate>Sat, 07 Dec 2024 07:38:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 换个话题：我的一些非 LLM 重点工作：通过语义盲法和图神经网络进行无偏见情绪分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h8meas/r_for_a_change_of_topic_some_nonllm_focused_work/</link>
      <description><![CDATA[   在我的学术领域（社会科学），我处理 SA 模型中的偏见问题。我之前的工作表明，深度学习 SA 系统从注释者那里继承了偏见（例如，不代表人口政治偏见）： https://arxiv.org/abs/2407.13891 现在我设计了一个解决方案，使用一种我称之为语义盲法的技术，只为模型提供预测文本情绪所需的基本信息，不给模型留下任何过度拟合和产生偏见的信号： https://arxiv.org/abs/2411.12493 在我发布 SProp Gnn 之前，我很想听听你的想法。 你认为它在学术界之外还有用吗？    由    /u/Hub_Pli  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h8meas/r_for_a_change_of_topic_some_nonllm_focused_work/</guid>
      <pubDate>Sat, 07 Dec 2024 06:21:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAAI 2025第二阶段决定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h8kkjv/d_aaai_2025_phase_2_decision/</link>
      <description><![CDATA[第二阶段的决定什么时候出来？ 我知道日期是 12 月 9 日，但是结果有可能比宣布的日期更早出来吗？ 或者它是否在前几年的确切时间公布结果？（即 2024 年、2023 年、2022 年......） 继续等待让我有点恶心。    提交人    /u/No-Style-7975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h8kkjv/d_aaai_2025_phase_2_decision/</guid>
      <pubDate>Sat, 07 Dec 2024 04:27:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] JAX 与 TensorFlow-XLA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h8j2e5/r_jax_vs_tensorflowxla/</link>
      <description><![CDATA[几个月前，我从 TF 2.0 迁移到了 Jax。我发现 jax 比 Tf 快得多。我在官方文档中注意到它依赖于使用 JIT 编译的 XLA 默认设置，这使得执行速度更快。我还注意到 TF 图表也有使用 XLA 启用 JIT 编译的选项。但 jax 仍然在使用 XLA 的 TF 上占主导地位。我只是想知道为什么。    提交人    /u/Odd-Detective289   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h8j2e5/r_jax_vs_tensorflowxla/</guid>
      <pubDate>Sat, 07 Dec 2024 03:02:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有针对难以辨认的笔迹的 OCR 建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h7x5us/d_any_ocr_recommendations_for_illegible/</link>
      <description><![CDATA[      有人使用过 ML 模型来识别这样的手写内容吗？这个笔记本包含重要信息，可以帮助我破解我正在解决的一个难题。我总共有五本笔记本，都来自同一个人，而且笔迹模式一致。我的目标是使用 ML 识别和提取笔记，然后将它们转换为数字格式。 在知道 Tesseract 可能无法很好地处理这种难以辨认的样本后，我正在考虑使用 Google API。 但是，我也不确定 Google API 是否能够读取它。 我读到某处说 OCR+CNN 可能会起作用，所以我在这里征求建议。 谢谢！ 欢迎任何建议！     提交人    /u/SpaceSheep23   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h7x5us/d_any_ocr_recommendations_for_illegible/</guid>
      <pubDate>Fri, 06 Dec 2024 08:53:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 陷入人工智能地狱：法学硕士毕业后该做什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h7jg87/dstuck_in_ai_hell_what_to_do_in_post_llm_world/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h7jg87/dstuck_in_ai_hell_what_to_do_in_post_llm_world/</guid>
      <pubDate>Thu, 05 Dec 2024 20:49:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>