<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 12 Jan 2025 15:15:05 GMT</lastBuildDate>
    <item>
      <title>[D] 您认为哪种方法更有利于节省成本同时保持质量？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hznd9q/d_which_in_your_opinion_is_better_for_costsaving/</link>
      <description><![CDATA[我有一个场景，我需要将文本数据的 PDF 提供给生成式 AI 模型，以便从每个 PDF 中单独汇总和仅获取感兴趣的信息。现在，我首先考虑使用 OpenAI API (GPT-4o)，但我想知道是否有另一种解决方案更便宜，同时还能保持文本理解和生成的质量水平：  在我的计算机上本地安装一个模型来执行此操作。 在云服务器上安装模型，例如 AWS 中的 EC2 实例。 使用其他 GenAI 产品，例如 Amazon Bedrock  我没有下载模型和使用它的经验，因为我以前只使用过流行提供商的 API。但我想了解它的工作原理以及您是否认为这些选项是现实的。    提交人    /u/Alex_The_Android   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hznd9q/d_which_in_your_opinion_is_better_for_costsaving/</guid>
      <pubDate>Sun, 12 Jan 2025 14:05:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们使用 RLFH 而不是 Gumbel softmax？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hznbmr/d_why_do_we_use_rlfh_instead_of_gumbel_softmax/</link>
      <description><![CDATA[我的问题很简单。RLHF 用于微调 LLM，因为采样的 token 不可微分。为什么我们不直接使用 Gumbel softmax 采样来实现可微分采样并直接优化 LLM？ 整个 RLHF 感觉开销很大，我不明白为什么有必要这样做。    提交人    /u/No_Individual_7831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hznbmr/d_why_do_we_use_rlfh_instead_of_gumbel_softmax/</guid>
      <pubDate>Sun, 12 Jan 2025 14:03:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 在计算机视觉领域获胜了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzn0gg/d_have_transformers_won_in_computer_vision/</link>
      <description><![CDATA[嗨， 自 2018 年 BERT 和 GPT-1 问世以来，Transformer 在书面和口头自然语言处理应用中占据了主导地位。 对于计算机视觉，我上次检查时发现它在 2020 年开始获得发展势头，一张图片胜过 16x16 个单词，但当时的观点是“是的，Transformer 可能对 CV 有好处，现在我会继续使用我的 resnet” 2025 年这种情况有变化吗？ Vision Transformers 是否是计算机视觉的首选骨干？ 换句话说，如果您要从头开始一个新项目来进行图像分类（医学诊断等），您将如何在架构和培训目标方面着手？ 我主要是 NLP 人员，所以请原谅我对行业中的 CV 问题缺乏了解。    提交人    /u/Amgadoz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzn0gg/d_have_transformers_won_in_computer_vision/</guid>
      <pubDate>Sun, 12 Jan 2025 13:47:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 多模态分割中切片数量的差异</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzjlvy/d_discrepancy_in_no_of_slices_in_multimodal/</link>
      <description><![CDATA[嘿，我在分割任务中使用 DTI 和传统 MRI 扫描。DTI 有 60 个切片，MRI 有 23 个切片，分割掩模是基于 MRI 生成的，因此它有 23 个切片。有什么建议我该怎么做吗？切片数量有差异    提交人    /u/ThrowRA_2983839   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzjlvy/d_discrepancy_in_no_of_slices_in_multimodal/</guid>
      <pubDate>Sun, 12 Jan 2025 10:03:07 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 问题表述不明确</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzhrxb/discussion_unclear_problem_statement/</link>
      <description><![CDATA[以下是用例的问题陈述。  “欺诈的性质是动态的且不断变化。在这个行业中，寻找模式和识别异常至关重要。给定一组移动设备属性（例如，品牌、型号）数据，设计一个模型来查找这些数据中的模式或异常。  考虑到并非所有设备属性都随时可用，并且没有可用的历史数据。” 没有提供数据集，我必须自己找到它。我原本想获取 Kaggle 移动价格数据集并进行一些基本的异常检查（Z 分数、IQR）+ 隔离森林来检测欺诈性帖子。但是，不确定没有历史数据意味着什么？我将其解释为没有时间序列信息 + 未标记（以防万一）。    由    /u/asdacool  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzhrxb/discussion_unclear_problem_statement/</guid>
      <pubDate>Sun, 12 Jan 2025 07:47:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] Llama3 推理引擎 - CUDA C</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hze3vs/p_llama3_inference_engine_cuda_c/</link>
      <description><![CDATA[      嗨，r/MachineLearning，最近我从 llama.cpp、ollama 和类似的工具中获得了灵感，这些工具可以在本地实现 LLM 推理，我刚刚用 CUDA C 为 8B 模型构建了一个 Llama 推理引擎。 作为构建优化 GPGPU 软件的探索性工作的一部分，我决定从头开始构建它。这个项目只使用本机 CUDA 运行时 api 和 cuda_fp16。推理发生在 fp16 中，因此它需要大约 17-18GB 的​​ VRAM（~16GB 用于模型参数，更多用于中间缓存）。 它不使用 cuBLAS 或任何类似的库，因为我想接触最少的抽象。因此，它不像 cuBLAS 实现或其他推理引擎（如启发该项目的引擎）那样优化。 实现的简要概述 我使用了 CUDA C。它读取了模型的 .safetensor 文件，您可以从 HuggingFace 中提取该文件。实际的内核对于规范化、跳过连接、RoPE 和激活函数 (SiLU) 相当简单。 对于 GEMM，我已实现平铺矩阵乘法并为每个线程进行矢量化检索。GEMM 内核的编写方式也是，第二个矩阵不需要预先转置，同时仍可实现对 HBM 的合并内存访问。 有些内核（如 RoPE 和 GEMM 的内核）使用矢量化内存访问。 SwiGLU 前馈计算的部分内容在自定义融合内核中进行。 如果您感兴趣，可以随意查看项目仓库并尝试一下。如果您喜欢所看到的内容，也可以随意为仓库点赞！ 我非常感谢任何反馈，无论是好的还是建设性的。    提交人    /u/Delicious-Ad-3552   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hze3vs/p_llama3_inference_engine_cuda_c/</guid>
      <pubDate>Sun, 12 Jan 2025 03:51:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我应该使用哪个预测库来完成这项任务，因为我尝试过的所有方法都无法满足我的需要！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzbtak/r_which_forecasting_library_should_i_be_using_for/</link>
      <description><![CDATA[大家好， 我正在尝试使用多变量输入来预测数据集中的单列：取决于当前燃油百分比、车速和散热器温度的车内剩余燃油百分比。我需要训练一个可以实时近似燃油消耗曲线的模型，因此它必须根据所学知识对未见数据进行预测，但是我尝试过的库并不这样做，而是仅对之前的数据进行训练并预测准确的下一个 n（fh）。我不需要这个，我不想要我的训练数据的下 n 步，我想要我的测试数据的下 n 步，而这是未见的。我构建了自己的 pytorch 模型，它运行良好，但我需要将它与其他方法进行比较，以了解如何改进模型。 我尝试了 Facebook Prohpet、Nixtla、SKTime、Pytorch Forecasting 和 GluonTS，但它们似乎不能满足我的要求和/或缺少其中一项要求。我读过关于 TSAI、Darts 和 Kats 的文章，但我担心自己在浪费时间，可能没有测试太多库，结果却发现它们不能满足我的需要。 有没有什么建议可以满足我的需要？ tl;dr 我需要一个可以接受多变量输入来实时预测接下来 n 步的单变量输出的库/模型（看不见的数据）。    提交人    /u/thethiny   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzbtak/r_which_forecasting_library_should_i_be_using_for/</guid>
      <pubDate>Sun, 12 Jan 2025 01:46:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 SAM 进行图像分割</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hz7n71/d_image_segmentation_with_sam/</link>
      <description><![CDATA[有没有地方可以像 SAM 网站上那样，通过单击图像的不同部分来添加蒙版（或按住 Shift 键单击以删除）并最终下载蒙版来分割图像？ 我测试了一些标记工具，但我发现它们都不如元演示效果好。元网站的问题是我无法下载蒙版，我只能从图像中剪切出来。    提交人    /u/Helbal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hz7n71/d_image_segmentation_with_sam/</guid>
      <pubDate>Sat, 11 Jan 2025 22:26:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪个库适合扩散模型研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hz541n/d_which_library_is_good_for_diffusion_model/</link>
      <description><![CDATA[我想尝试使用扩散模型并切换管道的不同部分（例如采样器、模型、数据模态等或使用自定义部分）。我看了一些库，例如 modules_diffusion 或 diffusor，但它们似乎还不是很成熟或不是很高级。您在研究中使用哪种库来试验扩散模型？    提交人    /u/NumerousSwordfish653   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hz541n/d_which_library_is_good_for_diffusion_model/</guid>
      <pubDate>Sat, 11 Jan 2025 20:32:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 未来推理模型的硬算法基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hz4gdy/p_a_hard_algorithmic_benchmark_for_future/</link>
      <description><![CDATA[嗨，我一直在考虑一个简单的想法，即开发一个面向未来的动态 AI 模型基准。这个想法很简单。一个隐藏的函数会转换数据，模型只能看到前后情况，并且必须推断出隐藏的逻辑。我精心策划了几个难度略有增加的级别，我很惊讶地发现我可以访问的大多数当前模型（GTP、o1、Sonet、Gemini）都很糟糕。 例如，第一个谜题只是对输入缓冲区上的字节执行 ^=0x55，但大多数模型都很难看到或推断出它。 我已经启动了一个带有现场演示的开源 MIT 存储库，因此其他人可以尝试这个想法或做出贡献。我很感激任何反馈。谢谢！    提交人    /u/habitante   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hz4gdy/p_a_hard_algorithmic_benchmark_for_future/</guid>
      <pubDate>Sat, 11 Jan 2025 20:02:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对 Google Paxml (又名 Pax) 的看法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hz2dfp/d_thoughts_on_google_paxml_aka_pax/</link>
      <description><![CDATA[我刚刚发现了 Pax，这是一个在 Jax 之上配置和运行机器学习实验的框架。你知道这个吗？对于大规模模型来说，它可能比 Pytorch 更好。    提交人    /u/johnbond2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hz2dfp/d_thoughts_on_google_paxml_aka_pax/</guid>
      <pubDate>Sat, 11 Jan 2025 18:30:54 GMT</pubDate>
    </item>
    <item>
      <title>[N] 我不明白 LORA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hz1xks/n_i_dont_get_lora/</link>
      <description><![CDATA[人们一直给我一行语句，比如 dW =A B 的分解，因此 vram 和计算效率高，但我完全不明白这个论点。  为了计算 dA 和 dB，难道你不需要先计算 dW，然后将它们传播到 dA 和 dB 吗？此时，你不需要计算 dW 所需的那么多 vram 吗？并且比反向传播整个 W 需要更多的计算？ 在前向运行期间：你是否在每一步之后都用 W= W&#39; +A B 重新计算整个 W？因为否则你如何使用更新的参数计算损失？  请不要发怒，我不想听到 1。这太简单了，你不应该问 2。问题不清楚 请让我知道哪个方面不清楚。谢谢    由   提交  /u/Peppermint-Patty_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hz1xks/n_i_dont_get_lora/</guid>
      <pubDate>Sat, 11 Jan 2025 18:11:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 构建了一个贪吃蛇游戏，使用扩散模型作为游戏引擎。它几乎实时运行 🤖 它根据用户输入和当前帧预测下一帧。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hz1l2j/p_built_a_snake_game_with_a_diffusion_model_as/</link>
      <description><![CDATA[        由    /u/jurassimo  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hz1l2j/p_built_a_snake_game_with_a_diffusion_model_as/</guid>
      <pubDate>Sat, 11 Jan 2025 17:57:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1htw7hw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 05 Jan 2025 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>