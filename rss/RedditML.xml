<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 04 Jan 2024 01:00:07 GMT</lastBuildDate>
    <item>
      <title>[R] APE：从 Transformer 模型的输入中学习位置编码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xyuyz/r_ape_learning_positional_encodings_from_input_in/</link>
      <description><![CDATA[      ​  RoPE 和 APE Transformer 在推理过程中随着上下文窗口长度的增加而产生的困惑。两个 Transformer 均使用 128 长度上下文窗口进行训练。 链接： APE - 累积位置编码   由   提交 /u/alagagbar   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xyuyz/r_ape_learning_positional_encodings_from_input_in/</guid>
      <pubDate>Thu, 04 Jan 2024 00:20:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练数据多样性的理论保证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xxfp1/d_theoretical_guarantees_for_training_data/</link>
      <description><![CDATA[大家好， 我正在阅读有关机器学习的训练数据多样性的内容。我发现了许多实证论文来证明数据多样性如何帮助学习。还有很多评价论文。然而，我无法找到任何关于为什么训练数据多样性可能有助于机器学习的理论保证的资源。这里有人对此有什么想法或有任何读物吗？谢谢。   由   提交 /u/whereismycatyo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xxfp1/d_theoretical_guarantees_for_training_data/</guid>
      <pubDate>Wed, 03 Jan 2024 23:20:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何开始使用机器学习进行预测维护</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xx0na/d_how_to_get_started_with_predictive_maintenance/</link>
      <description><![CDATA[大家好， 我工作的公司是一家石油天然气公司（专门为这些油井提供化学解决方案）他们希望利用机器学习提前预测油井何时会出现故障，这样我们就可以派出特工来处理油井，从而减少停机时间，从长远来看可能节省数十万甚至数百万美元。我认为这对我来说是一个亲自动手的绝佳机会。因为我做了很多办公室工作，所以我已经在这里使用 Python 来使用 Pandas 和 Selenium（浏览器自动化）来自动化枯燥乏味的工作。 我最终希望有一个数据管道，将实时数据流式传输到这台机器学习模型，以便我们可以在油井需要维护时收到警报。我获得了一些关于这些井和泵产生的数据的信息，例如每分钟冲程、压力、温度、每分钟循环次数等。 我只是不知道从哪里开始或如何开始！我应该使用哪个机器学习库来实现此目的？我应该去哪里学习它？我有一些机器学习的概念，但不多。我 60% 确信这将是一个二元分类问题，但我只是不知道该用什么工具来构建这个问题。 我很想了解更多关于这方面的信息，如果有人有知识的话或者经验可以帮助我，我将不胜感激。   由   提交 /u/Opening_Inspector999   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xx0na/d_how_to_get_started_with_predictive_maintenance/</guid>
      <pubDate>Wed, 03 Jan 2024 23:04:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当前的就业市场？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xupvl/d_current_job_market/</link>
      <description><![CDATA[我很好奇是否有人对当前的就业市场有任何意见、观察等。我知道这对于入门级来说很糟糕，但你对中/高级以上有什么看法？  凭借博士学位和丰富的经验，这对我来说进展相当缓慢（但还为时过早）。   由   提交/u/walterkronkite33  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xupvl/d_current_job_market/</guid>
      <pubDate>Wed, 03 Jan 2024 21:31:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 持续强化学习的定义</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xu6sn/r_a_definition_of_continual_reinforcement_learning/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2307.11046 OpenReview：https:// /openreview.net/forum?id=ZZS9WEWYbD 摘要：  在强化学习问题的标准视图中，代理的目标是有效地确定最大化长期回报的策略。然而，这种观点是基于一种有限的观点，即学习是寻找解决方案，而不是将学习视为无休止的适应。相反，持续强化学习是指最好的智能体永远不会停止学习的环境。尽管持续强化学习很重要，但社区缺乏一个简单的问题定义来强调其承诺并使其主要概念准确清晰。为此，本文致力于仔细定义持续强化学习问题。我们将“永不停止学习”的代理概念正式化。通过一种新的数学语言来分析和编目代理。使用这种新语言，我们将持续学习代理定义为可以无限期地执行隐式搜索过程的代理，并将持续强化学习定义为最佳代理都是持续学习代理的设置。我们提供了两个激励性的例子，说明多任务强化学习和持续监督学习的传统观点是我们定义的特例。总的来说，这些定义和观点形式化了学习核心的许多直观概念，并开辟了围绕持续学习代理的新研究途径。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xu6sn/r_a_definition_of_continual_reinforcement_learning/</guid>
      <pubDate>Wed, 03 Jan 2024 21:10:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] ReCoRe：世界模型的正则化对比表示学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xtnzq/r_recore_regularized_contrastive_representation/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2312.09056 摘要：  虽然最近的无模型强化学习（RL）方法已经证明尽管在游戏环境中的人类水平的有效性，他们在视觉导航等日常任务中的成功受到限制，特别是在显着的外观变化下。这种限制源于 (i) 样本效率差和 (ii) 过度拟合训练场景。为了应对这些挑战，我们提出了一个世界模型，该模型使用（i）对比无监督学习和（ii）干预不变正则化器来学习不变特征。学习世界动态的显式表示（即世界模型）可以提高样本效率，而对比学习隐式地强制学习不变特征，从而提高泛化能力。然而，由于缺乏视觉编码器的监督信号，对比损失与世界模型的简单集成失败了，因为基于世界模型的强化学习方法独立地优化了表示学习和代理策略。为了克服这个问题，我们提出了一种以辅助任务（例如深度预测、图像去噪等）形式存在的干预不变正则化器，它明确地强制风格干预的不变性。我们的方法优于当前最先进的基于模型和无模型的 RL 方法，并且在 iGibson 基准评估的分布外点导航任务上表现显着。我们进一步证明，我们的方法仅通过视觉观察，优于最近的语言引导的点导航基础模型，这对于在计算能力有限的机器人上部署至关重要。最后，我们证明我们提出的模型在 Gibson 基准上的感知模块的模拟到真实转换方面表现出色。  同一作者之前的类似工作 ：  具有不变因果特征的世界模型的对比无监督学习  LanGWM：基于语言的世界模型   &amp;# 32；由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xtnzq/r_recore_regularized_contrastive_representation/</guid>
      <pubDate>Wed, 03 Jan 2024 20:48:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 第一作者</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xreys/r_first_authorship/</link>
      <description><![CDATA[你好， 我对这里的情况很陌生，我想问问你的意见。 &lt; p&gt;因此，我为一位医生做了一个项目，目的是使用机器学习来进行癌症检测（我就不详细介绍了）。 最近，他与一位教授合作发表了一篇出版物，该出版物将在拟发表在《国家癌症研究所杂志》上。我只对模型的技术部分做出了贡献（即使这不是我的选择，我也希望做得更多）。  我们最近写完了这篇论文，我重新获得了它的第一作者身份。医生反对这一说法，称它永远不会被接受，第一作者应该能够回答与非技术部分相关的问题，因为这些问题将会被问到。显然我是做最多工作的人（其他人只对出版物做出了贡献），尽管我不能按照论文所写的方式来写论文（根本不具备技术性） 所以我的问题是：我应该接受不是第一作者吗？我知道在写论文之前我已经获得了第一部分工作的报酬，但可以肯定地说，当我继续改进工作并进行消融研究和许多测试时，我完成的一半工作并没有得到报酬。  Ps：付钱给我的医生并不是他想列为第一作者的医生。论文的大部分内容是教授写的 Ps：模型的架构和所有的想法都是我的，就像我确实可以访问计算机而不知道要查找数据一样，我被告知要这样做让它发挥作用 错字：我在第一个版本中写的是“医生”，但我的意思是“医生”   由   提交/u/Training-Adeptness57  /u/Training-Adeptness57 reddit.com/r/MachineLearning/comments/18xreys/r_first_authorship/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xreys/r_first_authorship/</guid>
      <pubDate>Wed, 03 Jan 2024 19:18:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 硕士论文选题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xnm68/d_masters_thesis_topics/</link>
      <description><![CDATA[我要为我的计算机科学硕士课程开始我的机器学习论文，我对主题有一些想法，但想知道研究中是否有人有对我未来的主题的意见或更好的想法。我脑子里一直在思考的一些问题是： -机械可解释性：考虑解决 Neel Nanda 的一个开放问题。最有可能的是玩具或基础模型中的电路发现。也许是强化学习分析。 -赋予模型一致个性的不同方法。我对用于语义搜索的知识图谱和嵌入进行了研究，并认为可能有一种方法可以应用它来在基本提示工程之外获得更好的用户体验。  -还有其他主题，但我没有对这些主题进行太多思考，所以我觉得它们较弱，只有在太浅的情况下才会将它们用作备份。 请告诉我你们对我可能探索的这两个研究领域的看法。我也在寻找更好的主题，这些主题已经用尽，或者它们对于论文来说不够具体。我的目标是发表，所以请批评我需要改进。   由   提交 /u/Wizard_Machine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xnm68/d_masters_thesis_topics/</guid>
      <pubDate>Wed, 03 Jan 2024 16:38:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对 Mamba 语音合成的思考？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xjmao/d_thoughts_on_mamba_speech_synthesis/</link>
      <description><![CDATA[   所以，在我之前在 Reddit 上发表有关 Mamba 文本生成的文章之后，我很好奇看到如果它对于语音合成效果很好，他们在原始论文中确实提到过，所以我将 MarcRandbot 组合在一起以获取乐趣，从头开始合成一些语音。 2084：MarcRandbot：使用 Mamba 进行语音合成 (substack.com) ​ https://preview.redd.it/w5hwiodyl7ac1.png ?width=1000&amp;format=png&amp;auto=webp&amp;s=a343919c26121b4ef9940fa00b183ebc97ff81c7 即使对于小型模型，似乎也能很好地工作，因为模型只有大约 1200 万个参数，而且输出很棒（您可以在帖子中找到一些示例和 colab）。此外，小型模型的表现也出奇的好：我可以使用单个 V100 Google Colab 笔记本来训练模型。 无论如何，Mamba 一直令人印象深刻，而且它在更少的参数下表现出色，这真是太棒了。  &gt; ​ https://preview.redd.it/94c3pal9f8ac1.png?width=323&amp;format=png&amp;auto=webp&amp;s=2f27a194161f9e172716a8e4fa9173e255046ecc 编辑：如果有足够的兴趣，我可能会对此进行跟进，我将其应用于音乐生成。    由   提交 /u/ExaminationNo8522   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xjmao/d_thoughts_on_mamba_speech_synthesis/</guid>
      <pubDate>Wed, 03 Jan 2024 13:39:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于多模态数据融合的Python包：Fusilli</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18xfzqc/p_python_package_for_multimodal_data_fusion/</link>
      <description><![CDATA[大家好！我想分享一个我在攻读博士学位期间编写的 Python 库，名为 fusilli：文档 &amp; GitHub Fusilli 提供了一组 23 种基于深度学习的多模态数据融合方法。它还包括用于在回归/分类任务中比较这些方法的管道。它可以处理表格-表格融合或表格-图像融合（2D 或 3D 图像）。 多模态数据融合，简单来说，就是使用机器学习组合不同类型的数据（例如图像和表格）利用这些数据类型之间的共享信息的模型。想想 GNN、注意力机制或 VAE。有时也称为多视图或数据集成。 就我个人而言，我将其用于分析大脑 MRI 和临床数据以预测健康结果的博士研究。但 Fusilli 可以在任何有多模式数据的地方使用！ Fusilli 是我公开发布的最大的编码项目，所以我很乐意听到您可能有的任何反馈或建议！ ?? （这里还有一个简短的 Medium帖子我写了关于它的文章，展示了一些功能）   由   提交 /u/seemepastarolling   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18xfzqc/p_python_package_for_multimodal_data_fusion/</guid>
      <pubDate>Wed, 03 Jan 2024 10:08:42 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 有人从少量高质量（基础）信息研究机器学习吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18x33cm/discussion_anyone_researching_ml_from_small/</link>
      <description><![CDATA[当今的机器学习技术是统计模型，可以从大量数据中学习，这些数据预计具有不同程度的噪声、相关性等。我想知道如果有人目前正​​在研究机器学习技术，该技术可以从小块基本信息中学习并自动推断这些基本信息的结果，类似于逻辑代理，更接近地模拟人类学习。 例如，学生可以阅读一本介绍性教科书，并结合推理和推测得出一个新颖的研究问题。然而，当前的“智能”系统不是为此而设计的。我们可以使用语言建模和逻辑代理的组合来模拟这种行为吗？ 目前有人在研究这个吗？这个智力模型有名字吗？有没有人证明这是当前法学硕士的紧急行为？   由   提交/u/i_wasserman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18x33cm/discussion_anyone_researching_ml_from_small/</guid>
      <pubDate>Tue, 02 Jan 2024 22:56:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 优化平均损失与极值损失</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18x16kw/d_optimizing_mean_loss_vs_extremal_loss/</link>
      <description><![CDATA[在训练神经网络时，我们通常借鉴 MLE 的统计实践和 IID 数据，并最小化每个样本的损失函数的平均值。 然而，初步估计，生物自然选择必须减轻极端的负面结果（即防止死亡），而不是优化平均结果。我想知道这是否解释了动物大脑和我们当前的神经网络之间归纳先验的一些差异。 那么谁对其中一个玩具问题进行了以下实验（或类似的实验），并做了它工作？在每个批次中，运行前向传递，按损失值对样本进行排序，并且仅根据样本中表现最差的一半/四分之一/……来更新模型。如果需要，我会在有空闲时间试用后向您报告。   由   提交 /u/IWearMyFace   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18x16kw/d_optimizing_mean_loss_vs_extremal_loss/</guid>
      <pubDate>Tue, 02 Jan 2024 21:39:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] Self-Attention：使用 FFT 使用 QK 内核进行位置编码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18x16g7/r_selfattention_positional_encoding_with_qk/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18x16g7/r_selfattention_positional_encoding_with_qk/</guid>
      <pubDate>Tue, 02 Jan 2024 21:39:25 GMT</pubDate>
    </item>
    <item>
      <title>[P]我创建了一个完全在潜在空间中运行的社交网络！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18wscw4/p_i_made_a_social_network_that_operates_entirely/</link>
      <description><![CDATA[Litter（又名潜在 Twitter）将在图像和文本到达网络之前通过多种模态转换来提取图像和文本，以便您可以仅传达消息的本质. 视频在这里：https://youtu.be/v8O_tSF_o50   由   提交/u/ykilcher  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18wscw4/p_i_made_a_social_network_that_operates_entirely/</guid>
      <pubDate>Tue, 02 Jan 2024 15:44:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>