<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 20 Apr 2024 18:16:57 GMT</lastBuildDate>
    <item>
      <title>[D] 以 JSON 对象的形式从 PDF 文件中提取数据。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8w1mq/d_extract_data_from_pdf_file_in_the_form_of_json/</link>
      <description><![CDATA[      https://preview.redd.it/q93ittqnaovc1.png?width=777&amp;format=png&amp;auto=webp&amp;s=aec5c1767690bd3 269ba9e601623e4d85378fd37 这是我从 Pdf 文件中捕获的图像，一方面，pdf 文本是可选择的，就像我也可以选择标题和表格中写入的所有文本一样。我尝试了几种技术： 1：使用 llama-index-multi-modal-llms-openai (GPT4-API) 的 MultiModalVectorStoreIndex，首先使用 OCR 将 PDF 转换为图像，然后然后从 PDF 中检索表格，但有一件事我需要定义 pdf 的页数，然后它将准确地获取包含表格的页面，但你知道如果在 pdf 中我们有两个包含表格，并且我定义了 3 个阈值，那么它会重复一页，反之亦然。 2：我也尝试过table transfomer LLM，但结果不好。 3：使用过Tabula python库，但你知道管理阅读这个库的文本非常乏味。 那么有没有任何智能AI工具或LLM可以在这里轻松使用，并且可以将任何pdf（无论包含表格的页数）转换为JSON。 提前致谢，任何建议或帮助都会更加感激。   由   提交/u/Ghulam_Nabi   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8w1mq/d_extract_data_from_pdf_file_in_the_form_of_json/</guid>
      <pubDate>Sat, 20 Apr 2024 17:54:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] ControlNet++：通过高效的一致性反馈改进条件控制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8unjk/r_controlnet_improving_conditional_controls_with/</link>
      <description><![CDATA[ControlNet++：通过高效的一致性反馈改进条件控制 ​ 增强可控性对于文本到图像的扩散模型，ControlNet 等现有工作结合了基于图像的条件控制。在本文中，我们揭示了现有方法在生成与图像条件控制一致的图像方面仍然面临重大挑战。为此，我们提出了 ControlNet++，这是一种新颖的方法，通过显式优化生成图像和条件控制之间的像素级循环一致性来改进可控生成。具体来说，对于输入条件控制，我们使用预训练的判别奖励模型来提取生成图像的相应条件，然后优化输入条件控制和提取条件之间的一致性损失。一种简单的实现是从随机噪声生成图像，然后计算一致性损失，但这种方法需要存储多个采样时间步长的梯度，从而导致大量的时间和内存成本。为了解决这个问题，我们引入了一种有效的奖励策略，通过添加噪声故意干扰输入图像，然后使用单步去噪图像进行奖励微调。这避免了与图像采样相关的大量成本，从而可以更有效地进行奖励微调。大量实验表明ControlNet++显着提高了各种条件控制下的可控性。例如，在分割掩模、艺术线条边缘和深度条件方面，它比 ControlNet 分别提高了 7.9% mIoU、13.4% SSIM 和 7.6% RMSE。 ​ ​ p&gt; 论文：https://arxiv.org/pdf/2404.07987.pdf ​ 项目网站：https://liming-ai.github.io/ControlNet_Plus_Plus/  ​ 代码：https://github。 com/liming-ai/ControlNet_Plus_Plus ​ HuggingFace 演示：https://huggingface.co/spaces/limingcv/ControlNet-Plus-Plus   由   提交/u/Extension-Sun1816    reddit.com/r/MachineLearning/comments/1c8unjk/r_controlnet_improving_conditional_controls_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8unjk/r_controlnet_improving_conditional_controls_with/</guid>
      <pubDate>Sat, 20 Apr 2024 16:54:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 正在寻找一个在每次刷新时生成最先进的聚类结果的网站？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8ukyn/d_looking_for_a_website_that_generates_state_of/</link>
      <description><![CDATA[大家好， 我正在寻找一个网站。每次刷新页面时，它都会显示新的最先进的聚类结果。这是可能的，因为它使用了许多不同的指标、算法和数据集，实际上，由于随机性和多重比较，你总是会发现一个新的显着结果（因此它在某种意义上说明了 p-hacking）。  有人知道我指的是什么吗？我想在我的聚类课程中使用它。我似乎无法通过谷歌找到它，因为我得到了各种聚类论文。  非常感谢！ 汤姆   由   提交/u/TommieV123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8ukyn/d_looking_for_a_website_that_generates_state_of/</guid>
      <pubDate>Sat, 20 Apr 2024 16:51:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] Groq 上的 llama-3-70b 和代码解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8uiwi/p_llama370b_on_groq_with_code_interpreting/</link>
      <description><![CDATA[       由   提交/u/mlejva  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8uiwi/p_llama370b_on_groq_with_code_interpreting/</guid>
      <pubDate>Sat, 20 Apr 2024 16:48:50 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于预测的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8ta5f/d_question_on_forecasting/</link>
      <description><![CDATA[我是一名初级数据科学家，并试图更好地使用 ARIMA 和指数平滑，目前我正在使用 auto.arima和阻尼参数设置为 true 的 ets。 输出平坦线的主要原因是什么，最好的解决办法是什么？ 谢谢 &lt; /div&gt;  由   提交 /u/Significant-Ad5781    reddit.com/r/MachineLearning/comments/1c8ta5f/d_question_on_forecasting/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8ta5f/d_question_on_forecasting/</guid>
      <pubDate>Sat, 20 Apr 2024 15:54:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从第一原理解释多模态神经网络的简史</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8sydf/d_the_short_history_of_multimodal_neural_network/</link>
      <description><![CDATA[      来自我的 YT 频道的视频解释多模态机器学习的核心概念及其过去几年的演变。   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8sydf/d_the_short_history_of_multimodal_neural_network/</guid>
      <pubDate>Sat, 20 Apr 2024 15:40:17 GMT</pubDate>
    </item>
    <item>
      <title>[R][研究]应用人工智能/机器学习研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8r56m/rresearch_applied_ai_ml_research/</link>
      <description><![CDATA[人工智能/机器学习研究中是否有适合应用性更强的研究？ 例如。与其开发新技术，不如专注于使用现有的方法和技术（我们拥有大量的），然后使用这些现有的方法来解决现实世界中的各种问题。 或者也许找到更多新颖的方法来使用/改编现有的技术，以便它们可以用于解决比最初预期更多种类的现实世界问题。或者对所有不同类型的解决方案进行原型设计，并为现实世界的问题开发很酷的东西。 但我还没有遇到过任何主要教授/实验室等从事此类工作。 &lt; !-- SC_ON --&gt;  由   提交 /u/ColdPillow5585   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8r56m/rresearch_applied_ai_ml_research/</guid>
      <pubDate>Sat, 20 Apr 2024 14:20:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一张让你感觉自己老了的幻灯片</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8kuef/d_a_slide_which_makes_you_feel_old/</link>
      <description><![CDATA[       由   提交 /u/xiikjuy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8kuef/d_a_slide_which_makes_you_feel_old/</guid>
      <pubDate>Sat, 20 Apr 2024 08:20:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过空间、时间和大脑的反向传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8fl48/r_backpropagation_through_space_time_and_the_brain/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.16933 摘要：  神经网络中的有效学习需要个体突触的适应对解决任务的相对贡献。然而，物理神经元系统——无论是生物的还是人工的——都受到时空局部性的限制。这种网络如何进行有效的信用分配在很大程度上仍然是一个悬而未决的问题。在机器学习中，答案几乎普遍由误差反向传播算法通过空间（BP）和时间（BPTT）给出。然而，众所周知，BP(TT) 依赖于生物学上不可信的假设，特别是在时空（非）局部性方面，而实时循环学习 (RTRL) 等前向传播模型则受到令人望而却步的记忆限制。我们引入了广义潜在均衡（GLE），这是一种在神经元的物理动态网络中进行完全局部时空信用分配的计算框架。我们首先定义基于神经元局部不匹配的能量，从中我们通过平稳性导出神经元动力学，通过梯度下降导出参数动态。由此产生的动力学可以解释为深层皮质网络中 BPTT 的实时、生物学上合理的近似，具有连续时间神经元动力学和持续活跃的局部突触可塑性。特别是，GLE 利用生物神经元根据膜电位对其输出速率进行相移的能力，这对于信息传播的两个方向都是至关重要的。对于前向计算，它能够将时间连续输入映射到神经元空间，从而执行有效的时空卷积。对于后向计算，它允许反馈信号的时间反转，从而近似有用参数更新所需的伴随状态。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8fl48/r_backpropagation_through_space_time_and_the_brain/</guid>
      <pubDate>Sat, 20 Apr 2024 03:02:20 GMT</pubDate>
    </item>
    <item>
      <title>[N] 何凯明关于表征学习的深度学习架构讲座</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8d5m1/n_kaiming_hes_lecture_on_dl_architecture_for/</link>
      <description><![CDATA[https://youtu.be/D_jt-xO_RmI 非常好的讲座，DL 历史架构进展的最高信噪比。   由   提交 /u/lkphuc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8d5m1/n_kaiming_hes_lecture_on_dl_architecture_for/</guid>
      <pubDate>Sat, 20 Apr 2024 00:57:29 GMT</pubDate>
    </item>
    <item>
      <title>您认为强化学习仍然有效吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c87bh4/do_you_think_reinforcement_learning_still_got_it_d/</link>
      <description><![CDATA[最近我听到很多人说强化学习本身多年来没有任何改进（也许 alphago 是最后的大事）。  而人工智能的其他领域已经出现了许多 SOTA 架构，例如用于基于序列的任务的“Transformers”以及“ResNet”、“Diffusers”和“SOTA”架构。 “VAE”类似于计算机视觉任务的架构。 我认为，无论是直接还是间接，强化学习仍然在使用“RLHF”技术的 ChatGPT 和 Claude 等法学硕士背后发挥着至关重要的作用。以及许多其他最新技术，包括自动驾驶汽车和机器人。  我认为这只是这个领域的一个寒冷的冬天，在未来几年里很快就会找到最先进的建筑（或者这就是我所希望的） 你的想法是什么想法？ 🤔   由   提交/u/cyb0rg14_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c87bh4/do_you_think_reinforcement_learning_still_got_it_d/</guid>
      <pubDate>Fri, 19 Apr 2024 20:40:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] TorchFix - 具有自动修复支持的 PyTorch 使用代码的 linter</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c83rcw/p_torchfix_a_linter_for_pytorchusing_code_with/</link>
      <description><![CDATA[TorchFix 是一款针对 PyTorch 用户的 Python 代码静态分析工具 - 具有自动修复功能的 linter。它可用于查找和修复问题，例如使用已弃用的 PyTorch 函数和非公共符号，并一般采用 PyTorch 最佳实践： https://github.com/pytorch-labs/torchfix   由   提交/u/kit1980  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c83rcw/p_torchfix_a_linter_for_pytorchusing_code_with/</guid>
      <pubDate>Fri, 19 Apr 2024 18:13:04 GMT</pubDate>
    </item>
    <item>
      <title>[D]嵌入搜索“淹没”在噪音的海洋中！你能解开这个谜语吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7wrhe/d_embeddings_search_drowning_in_a_sea_of_noise/</link>
      <description><![CDATA[我正在为存储在 Postgres DB 中的数十万条文本记录的 RAG 应用程序编写概念证明，使用 pgvector 来存储嵌入（并使用 HNSW 索引）。向量维度指定正确。  当前正在使用不同的文本块大小进行实验，并比较两种不同的嵌入模型。（实际块大小可能会略有不同，因为我不会破坏单词来强制确定大小）。   nomic-embed-text snowflake-arctic-embed-m-long  这是实验的要点： 1-为“n”创建嵌入文档 2- 创建一个查询/提示列表，以查找其中某些文档中确实包含的信息。  示例：  在“地点 x”发生了哪些事件？ John Doe 的昵称是什么？  入住“医院名称”的患者是谁？ 请告诉我销售总监提出的申请。 ...  3- 对于每个查询/提示，我运行余弦距离查询并获取最近的 5 个匹配块。  4-计算所有查询/块的平均距离后，理论上，最小值是 model/chunk_size 的最佳组合。   这对于一小部分文档样本（比如 ≃ 200）效果非常好，但是一旦我添加了更多文档，我就开始注意到一个问题。  一些新文档包含 30k 多个名字的列表。  每当我运行包含名称的查询时，都会返回上面列表中的块，即使它们不包含名称或提示中显示的任何其他信息（无论选择块大小或策略）。  我的理论是，当嵌入包含名称的块时，生成的嵌入包含“名称”语义的强向量，但区分该名称与其他名称的向量可能相对较弱。  一个块，除了对“name”向量的引用之外几乎不包含任何内容。然后被认为与提示的嵌入非常相似，尽管名称本身不匹配。   对于那些有更多经验/理解的人来说，我的这些假设是错误的吗？  您有什么建议/解决方法吗？  我有一些想法，但想看看是否有人遇到同样的问题。   由   提交 /u/grudev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7wrhe/d_embeddings_search_drowning_in_a_sea_of_noise/</guid>
      <pubDate>Fri, 19 Apr 2024 13:21:46 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 最近是否有特定的技术/科学突破使得多个大型语言模型的最大上下文长度显着跃升？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7pzf0/discussion_are_there_specific_technicalscientific/</link>
      <description><![CDATA[GPT-4 和 Claude 等模型的最新版本在最大上下文长度上有显着的跳跃（4/8k -&gt; 128k+）。这些模型可以处理的代币数量方面的进展听起来非常引人注目。 是什么导致了这一点？这纯粹是因为训练期间可用的计算量增加而发生的吗？是否有算法进步导致了这种情况？   由   提交 /u/analyticalmonk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7pzf0/discussion_are_there_specific_technicalscientific/</guid>
      <pubDate>Fri, 19 Apr 2024 06:28:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>