<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sun, 16 Feb 2025 09:15:07 GMT</lastBuildDate>
    <item>
      <title>[d] Torch.com使用Hidet编译器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqnyet/d_torchcompile_using_hidet_compiler/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有人尝试使用hidet作为torch.compile的火炬电感器的Altenative Backend。    https://pytorch.org/blog/introducing-hidet/    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/lime_dragonfruit4244      [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqnyet/d_torchcompile_using_hidet_compiler/</guid>
      <pubDate>Sun, 16 Feb 2025 08:37:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM法官提供动力的每日ARXIV过滤（与项目链接）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqnhai/p_daily_arxiv_filtering_powered_by_llm_judge_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  链接到项目： https://arxiv.ianhsiao.xyz &lt; /a&gt;  大家好，在我以前的reddit帖子中：没有可用的链接，因为我对许多subreddits粘贴了相同的评论，因此系统认为我是垃圾邮件并删除了所有这些（您可以比较显示的评论金额和实际数量验证）。我为此感到抱歉。 话虽如此，我真的很想学习社区的反馈，所以我再次发布此信息。 谢谢您的耐心配合！   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/madyexz     [link]   ＆＃32;   [commist]       ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqnhai/p_daily_arxiv_filtering_powered_by_llm_judge_with/</guid>
      <pubDate>Sun, 16 Feb 2025 08:02:38 GMT</pubDate>
    </item>
    <item>
      <title>[R]大语言模型中逻辑推理功能的调查：框架，方法和评估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqmjal/r_a_survey_of_logical_reasoning_capabilities_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项新调查提供了对LLMS中逻辑推理能力的全面分析，检查了不同的推理类型，评估方法和当前局限性。 &lt; P&gt;关键技术方面： - 将逻辑推理分为演绎，归纳和绑架框架 - 评估跨多个基准测试和测试方法的性能 - 分析模型大小和推理能力之间的关系 - 审查用于改进逻辑推理的技术，包括及时的工程和链条，链接和链条，链接，链条，链条，链条，链接，链接，链接，链接，链接，链接，链接和链条以及链条以及链条迅速，链条以及链条的推理， - 思想方法 主要发现：-LLMS在基本逻辑任务上表现出很强的表现，但与复杂的多步骤推理斗争 - 仅模型大小并不确定推理能力 - 培训方法和解决问题的策略扮演关键角色 - 当前的评估方法可能无法有效地区分真实的推理和模式匹配 - 当问题需要组合多种推理类型 时，性能会大大降低 我认为这里最重要的贡献是当前模型的系统分解成功并失败了逻辑推理。这有助于确定我们需要集中研究工作的特定领域，而不是将推理视为单一功能。 我认为这项工作突出了对更好的基准的需求 - 许多当前的测试并未有效地衡量真实的推理能力。该领域需要更强大的评估方法，可以区分记忆和实际逻辑推理。  TLDR：LLM中逻辑推理的全面调查显示出强大的基本能力，但在复杂的推理中有显着限制。重点需要更好地评估方法和特定推理类型的有针对性改进。  完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqmjal/r_a_survey_of_logical_reasoning_capabilities_in/</guid>
      <pubDate>Sun, 16 Feb 2025 06:55:36 GMT</pubDate>
    </item>
    <item>
      <title>[P]寻求AI从业者进行微调访谈（10美元奖励）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqk6ft/p_seeking_ai_practitioners_for_finetuning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们正在建立一项服务，该服务可帮助开发人员更有效地培训AI模型。为了完善我们的方法，我们正在寻找 20 AI从业人员在微调模型中的动手经验。 我们的重点是已经准备好数据集的人，正在积极进行微调过程。我们想了解他们面临的挑战以及他们用来提高模型性能的策略。  我们正在寻找的人：  •您有体验微调AI模型（不仅仅是数据集准备）。 •您正在优化的模型，以提高准确性，效率或鲁棒性。。 •您在微调过程中面临挑战，并找到了解决方案的方法。  访谈详细信息：  •持续时间：&lt; /strong&gt; 〜10分钟 •补偿： $ 10用于全面参与 •格式：虚拟面试 如果您有兴趣，请填写此简短表格： https:///forms.gle/e4fapbvbvbvpnpygje9  div&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/vidivid-enternateer752     link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqk6ft/p_seeking_ai_practitioners_for_finetuning/</guid>
      <pubDate>Sun, 16 Feb 2025 04:27:26 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会导致禁止。 鼓励其他人创建新的帖子，以便在此处发布问题！ 线程将一直活着直到下一个，因此请继续发布标题之后的发布。    meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[D]用于嵌入培训的Torchrec或DGL</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqdzs5/d_torchrec_or_dgl_for_embedding_training/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我正在寻找一个库来训练大规模嵌入的库。 Pytorch-liggraph似乎不再维护。现在，我在Torchrec与DGL之间做出决定。您会推荐哪种工具，为什么？如果没有，您推荐哪个库？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bigbaydragon     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqdzs5/d_torchrec_or_dgl_for_embedding_training/</guid>
      <pubDate>Sat, 15 Feb 2025 23:01:47 GMT</pubDate>
    </item>
    <item>
      <title>文档提取[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqbeyc/document_extraction_r/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是一名新机器学习工程师，我试图解决几个月的问题，我需要从发票中提取键值对作为要求，我试图使用不同的策略来解决它，并且它们似乎都没有正常工作，我需要设计一个通用解决方案，该解决方案将在任何发票上都可以使用，而无需依赖发票布局。 Moto ---＆GT;提取关键价值对，例如提供者详细信息：[提供商姓名&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;＆quort&#39;&#39;&#39;&#39;&#39;，收件人详细信息＆quot＆quot＆quot＆quot＆quort“与提供者相同），” po详细信息“：[date＆quot&#39;总量“总量”，“描述”  当我使用tesseract或pdfplumber提取单词时，我面临的问题在某些人中左右读取单词。发票格式化提供商和收件人合并使分离复合物的地址和详细信息， 我到目前为止所做的事情--------＆gt;使用tesseract或pdfplumber提取，使用regex识别GST日期锅，但对于地址部分I am still lagging  I also read a blog &lt;a href=&quot;https://medium.com/analytics-vidhya/invoice-information-extraction-using-ocr-and-deep-learning-b79464f54d69 “&gt; https://medium.com/Analytics-vidhya/invoice-information-information-ectraction-raction-usion-ocr-and-deep-learning-b79464f54d69 他使用不同的方法解决了相同的方法，但我找不到我发现那些RCNN和蒙面的RNN模型 有人可以解释这个博客并帮助我解决这个问题吗？ 我是一个新鲜的，所以任何帮助对我都非常有帮助 &lt; p&gt;提前谢谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/floodrose_2003     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqbeyc/document_extraction_r/</guid>
      <pubDate>Sat, 15 Feb 2025 21:07:01 GMT</pubDate>
    </item>
    <item>
      <title>[D]我的公司是否因避免深度学习而错过了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq9gtk/d_is_my_company_missing_out_by_avoiding_deep/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  免责声明：如果线性回归足够，则使用神经网络是没有意义的。  我在一家严格遵守数学，可解释的模型的公司工作。他们的立场是，诸如神经网络甚至梯度提升机之类的方法也是“黑框”。因此对决策不可靠。尽管我了解可解释性的重要性（尤其是在任务关键场景中），但我忍不住感觉这种方法过于限制。  我看到了这些方法的大量研究和行业采用，这让我感到奇怪：它们真的只是黑匣子，还是这是过时的观点？当然，随着这么多的人在这一领域工作，必须有一些方法可以洞悉这些模型并使他们更值得信赖。  我也错过了它们，因为我没有此类模型的工作经验？ 编辑：上下文是一级方程式！但是，种族是另一件事并支持工具。除非完全必要，否则我也会避免使用与种族严格相关的任何模型。我只是觉得这里有一种与上下文无关的偏见。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/datandre     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq9gtk/d_is_my_company_missing_out_by_avoiding_deep/</guid>
      <pubDate>Sat, 15 Feb 2025 19:42:42 GMT</pubDate>
    </item>
    <item>
      <title>[D]混合和歧管混合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq64f0/d_mixup_and_manifold_mixup/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好。您在混合和歧管混合过程中的经历如何。我拥有由于内部和主体间可变性而导致的脑电图数据，域和VAL设置之间的域移动。我的目的是使我的模型的决策界限平滑。但是结果是训练不稳定。我使用a = 0.4，所以我只有光插值。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nigale-joke5751     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq64f0/d_mixup_and_manifold_mixup/</guid>
      <pubDate>Sat, 15 Feb 2025 17:16:03 GMT</pubDate>
    </item>
    <item>
      <title>[d]使用火炬XLA在小数据集上使用Torch XLA重新训练GPT-2时疯狂的CPU利用率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq5e3k/d_insane_cpu_utilization_when_using_torch_xla_to/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  我试图在威廉的作品上训练gpt-2莎士比亚（7ish MB），并使用Kaggle TPU V3-8 VM来做到这一点。这是我的训练代码： ````` &gt;  dropout = 0.1   vocab_size = tokenizer.n_vocab   ctx_size = 1024   batch_size = 8   steps = 10000 &lt; /p&gt;  ...   def train（索引，代币，层，emb_size，n_heads，droctout，vocab_size，ctx_size，steps）：  device = xla.dla.device （）  model =变压器（层，emb_size，n_heads，dropout，vocab_size，ctx_size）。 ，lr = 1e-4） 用于tqdm（range（step））中的i：  model.train（）  with xla.step（） ：  x，y = get_batch（数据，batch_size）  x = x.to（device）  y = y.to（device）  xm.master_print（f＆quot&#39;x shape：{x [5]};）  xm.master_print（f＆quort&#39;y Shape：{y [y [5]}＆quort）  out，loss =模型（x，y）  lose.backward（）  xm.optimizer_step（optimizer）  optimizer.zero_grad （）  xm.master_print（loss.item（）） 如果我％10 == 0：  x = tokenizer.encode（＆quot; hello; hello ，＆quot;）  x = torch.tensor（x）.to（device）  xm.master_print（tokenizer.decode（list。 ））））  checkpoint = { &#39;模型&#39;：raw_model.state_dict（）， &#39;imptimizer&#39;：optimizer.state_dict（）， }   torch.save（checkpoint，f＆quot; ckpt- {i} .pt; pst;） ```````将火车代码放入python文件中，然后将其导入笔记本，以使用xla.launch运行。由于某种原因，当我运行代码时，X和Y形状并未打印，并且我的CPU利用率会产生疯狂的价值。我该如何解决？ https ：//preview.redd.it/e38l444jb0cje1.png？width = 219＆amp;格式32;提交由＆＃32; /u/u/u/new-skin-5064     [link]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq5e3k/d_insane_cpu_utilization_when_using_torch_xla_to/</guid>
      <pubDate>Sat, 15 Feb 2025 16:43:58 GMT</pubDate>
    </item>
    <item>
      <title>[d]有没有LLM论文预测中间而不是下一个令牌？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iq4f0r/d_have_any_llm_papers_predicted_a_token_in_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在从事一个项目（与NLP无关），在该项目中，我们使用与GPT-3相同的架构和培训，但我们更多比下一个“ word”找到一系列令牌来连接起始和结束“单词”。由于我们在设置中从LLM中绘制了很多东西，因此我想知道是否有任何研究对模型的性能进行任何研究，而当损耗函数不基于下一个令牌，而是预测输入序列中某个地方的蒙版令牌。  最终，我们想扩展它（也许是通过微调），以预测一系列缺少的令牌，而不是一个，但这似乎是一个不错的起点。  我找不到太多关于文献中无监督的培训方案的信息，但似乎有人一定已经尝试过。有任何建议，或者是一个坏主意？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/thewittyscreenname     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iq4f0r/1iq4f0r/d_have_any_llm_llm_papers_predication_a_token_in_in_in_in_in_the/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iq4f0r/d_have_any_llm_papers_predicted_a_token_in_the/</guid>
      <pubDate>Sat, 15 Feb 2025 15:59:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM法官提供动力的每日ARXIV过滤</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipz934/p_daily_arxiv_filtering_powered_by_llm_judge/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/u/madyexz     [link]  ＆＃32;   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipz934/p_daily_arxiv_filtering_powered_by_llm_judge/</guid>
      <pubDate>Sat, 15 Feb 2025 11:14:16 GMT</pubDate>
    </item>
    <item>
      <title>[r]通过基于抽象网格的任务评估LLM中的物理概念理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipw78p/r_evaluating_physical_concept_understanding_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这项工作介绍了一个结构化评估框架，用于评估LLMS中物理理解的结构化评估框架，从教育测试原理中得出。研究人员使用定量和定性问题开发了一个全面的测试套件，涵盖了力学，热力学和电磁套件。 关键技术方面： - 多级评估层次结构，从事实回忆到概念转移到最小的词汇，以最小化 - 语言模式匹配 - 使用平行问题的跨文本验证 - 数值计算和概念解释任务的集成 - 基于教育评估方法的标准化评分标准评分 主要结果：-GPT -4在基本物理学上实现了76％的准确性计算 - 跨文本转移问题的性能下降至43％ - 跨物理域的性能显着差异 - 模型在数学能力和物理问题解决问题之间显示出很强的相关性 - 结合多个物理概念 时出现了系统错误我认为这种方法比以前的工作提供了一种更严格理解LLM功能的方法。教育测试框架有助于区分表面水平的模式匹配和更深的概念理解。这可能会导致更好的基准测量科学推理中的AI进展。 我认为，结果突出了LLMS在跨环境中传递物理知识的当前局限性 - 这对于实际科学工作至关重要。系统评估方法可以扩展到其他科学领域。  tldr：基于教育测试原理的新评估框架表明，LLM具有体面的物理计算能力，但与更深入的概念理解和知识转移斗争。 。&gt;   完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipw78p/r_evaluating_physical_concept_understanding_in/</guid>
      <pubDate>Sat, 15 Feb 2025 07:21:24 GMT</pubDate>
    </item>
    <item>
      <title>[d]变压器最有前途的继任者是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ipvau4/d_whats_the_most_promising_successor_to_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我所知道的是mamba，从效率的角度看（推理是线性而不是二次），但是Afaik没有人受过训练的大型模型。还有 xlstm  and  aaren 。  你们认为变压器最有前途的替代体系结构是什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jsonathan     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ipvau4/d_whats_the_most_promising_successor_to_the/</guid>
      <pubDate>Sat, 15 Feb 2025 06:17:01 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>