<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 05 Apr 2024 15:13:48 GMT</lastBuildDate>
    <item>
      <title>[R] 以编码器-解码器方式重建 3D 点云（使用等变编码器）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwjus6/r_reconstructing_3d_point_clouds_in_an/</link>
      <description><![CDATA[我为我正在写的一篇论文设计了一些基于自动编码器的二维图像方法，现在根据之前会议的反馈，我正在尝试将我的方法扩展到 3D 点云。为此，我首先必须首先开发一个 3D 自动编码器（即从点云编码到潜在向量并解码到点云），然后当然要继续构建我的方法的其余架构和属性（自动编码器必须例如，尊重某些 SO(3) 等方差约束，但现在让我们忘记这一点）。作为起点，我已经使用 PointNet 作为编码器为点云开发了一个编码器-解码器架构，并且效果非常好。  经过几周的审阅论文，我意识到所谓的“形状重建”任务是在现实世界中进行的。实际上并不意味着“从潜在向量重建点云”，这正是我正在寻找的。相反，该术语似乎通常用于指“在给定 3D 点云的情况下重建表面”的任务。所以基本上，没有什么像我想要开发的。这种命名约定阻碍了我对类似自动编码器的点云重建方法的搜索。  -首先，我想请求一些关于类似自动编码器的点云重建的论文的推荐。我似乎找不到任何或几乎任何一个，因为我所有的搜索最终都在关于点云到表面“重建”的论文中。 ​  - 其次，以自动编码器的方式重建点云似乎不受欢迎是有原因的吗？我认为，既然对于图像来说，基于自动编码器的架构非常流行，那么 3D 形状也会很流行，但看起来并非如此。  ​ 就这样了:)谢谢。 ​ 奖金：&lt; /strong&gt; 如果有人熟悉几何深度学习和SO(3)等变网络，我还想问： ​ 我开发的点云重建自编码器使用 PointNet 作为编码器和 FC 网络作为解码器可以完美地重建例如形状网。然而，当我使我的 PointNet 网络 SO(3) 等变时（我使用矢量神经元https://arxiv.org/abs/ 2104.12229），然后我的重建突然变得非常糟糕。我已经检查了错误，并且我的网络确实已正确实现。为什么等变实际上使任务比使用常规的非等变 PointNet 编码器更困难？   由   提交 /u/howtorewriteaname   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwjus6/r_reconstructing_3d_point_clouds_in_an/</guid>
      <pubDate>Fri, 05 Apr 2024 14:45:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 解读诗歌</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwhwsc/r_interpreting_poetry/</link>
      <description><![CDATA[我很好奇如何训练一个网络，使其能够通过引用行来解释诗歌来支持主张。由于有无数种方法可以用不同程度的证据来解释，我很好奇一个人如何训练一个网络，使其能够输出多个同样可行的解释，对我来说，输出 PDF 似乎更困难。对任何与生成模型相关的研究也感兴趣。   由   提交/u/ixw123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwhwsc/r_interpreting_poetry/</guid>
      <pubDate>Fri, 05 Apr 2024 13:22:12 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]最大特征值/特征向量/主成分优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwhslj/discussionlargest_eigenvalueeigenvectorprincipal/</link>
      <description><![CDATA[任何人都可以向我推荐任何通过深度学习优化这些术语而无需显式计算出来的作品吗？我很难找到这些作品。   由   提交 /u/_karma_collector   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwhslj/discussionlargest_eigenvalueeigenvectorprincipal/</guid>
      <pubDate>Fri, 05 Apr 2024 13:16:56 GMT</pubDate>
    </item>
    <item>
      <title>[研究]通过简单的自适应攻击越狱领先的安全对齐法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwguzv/research_jailbreaking_leading_safetyaligned_llms/</link>
      <description><![CDATA[摘要：我们表明，即使是最新的安全相关法学硕士对于简单的自适应越狱攻击也不够鲁棒。首先，我们演示如何成功利用对 logprobs 的访问进行越狱：我们最初设计一个对抗性提示模板（有时适应目标 LLM），然后我们对后缀应用随机搜索以最大化目标 logprob（例如，令牌的 logprob） “当然”），可能需要多次重新启动。这样，我们在 GPT-3.5/4、Llama-2-Chat-7B/13B/70B、Gemma-7B 和 R2D2 上实现了接近 100% 的攻击成功率（以 GPT-4 为判断） HarmBench 针对 GCG 攻击进行了对抗性训练。我们还展示了如何通过传输或预填充攻击来越狱所有 Claude 模型（不暴露 logprobs），成功率达 100%。此外，我们还展示了如何在一组受限的标记上使用随机搜索来查找中毒模型中的木马字符串——这项任务与越狱有许多相似之处——正是这种算法为我们在 SaTML&#39;24 中获得了第一名木马检测竞赛。这些攻击背后的共同主题是适应性至关重要：不同的模型容易受到不同提示模板的影响（例如，R2D2 对上下文学习提示非常敏感），某些模型具有基于其 API 的独特漏洞（例如，Claude 的预填充） ），并且在某些设置中，根据先验知识限制令牌搜索空间至关重要（例如，对于木马检测）。我们在 https://github.com/tml-epfl/llm 提供攻击的代码、提示和日志-自适应攻击。   由   提交 /u/m_andriushchenko   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwguzv/research_jailbreaking_leading_safetyaligned_llms/</guid>
      <pubDate>Fri, 05 Apr 2024 12:32:18 GMT</pubDate>
    </item>
    <item>
      <title>[R] 📘“通过终极资源编译深入研究保形预测！”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwgc5n/r_dive_deep_into_conformal_prediction_with_this/</link>
      <description><![CDATA[各位r/MachineLearning爱好者们好！&lt; /p&gt; 您有兴趣了解保形预测 (CP) 并探索其深度吗？无论您是初露头角的学习者、经验丰富的研究人员还是该领域的从业者，我们都很高兴分享一些必将激发您的兴趣并扩展您的知识的内容！ 🚀 W* e 呈现：“很棒的共形预测” - 共形预测资源的终极集合 *🚀 我们对 CP 的热情促使我们整理出一份详尽的列表，其中包含有关该主题的最佳材料。这个宝库旨在引导您了解保形预测的复杂景观，涵盖您可以想象的各个方面：  📺 Engaging 视频和视频教程：视觉学习者，欢呼吧！查找将复杂概念分解为易于理解的部分的教程和讲座。 📚 富有洞察力的书籍和讲座。论文：从介绍性文本到高级研究论文，加深您对 CP 理论基础和创新应用的理解。 🎓 学术论文：探索前沿发现博士和硕士论文致力于突破 CP 的界限。 📰 启发性文章： 随时了解揭示保形预测最新趋势、挑战和突破的文章. 💻开放源代码库：通过访问各种开源库来实践 CP，非常适合热衷于实际实施的学习者和开发人员。 li&gt;  无论您是想巩固基础知识、了解最新研究成果，还是在项目中应用 CP，此列表都是您的一站式目的地。 &lt; p&gt;深入研究这个精选的集合，加入掌握保形预测的前沿。让我们一起踏上机器学习领域的学习、发现和创新之旅！ 快乐探索！ https://github.com/valeman/awesome-conformal-prediction   由   提交 /u/predict_addict   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwgc5n/r_dive_deep_into_conformal_prediction_with_this/</guid>
      <pubDate>Fri, 05 Apr 2024 12:05:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] FMA 的补码 - 一个定制的二进制数字系统（如 2 的补码），专为基于查找表的矩阵乘法而设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwg494/r_fmas_complement_a_custom_binary_number_system/</link>
      <description><![CDATA[TLDR ：矩阵乘法的查找表。  简单描述：这是一个定制的二进制数字系统，旨在计算矢量点积。  技术描述：FMA 的补码是二进制数的定点表示形式，作为 2 的补码和 1 的补码的替代方案，用于执行融合乘加指令。  我们将线性代数和算术代码（来自数据压缩理论）结合起来，使数字系统非常适合查找点积。  这是获取开始文章 这是GitHub 存储库  &lt; !-- SC_ON --&gt;  由   提交 /u/DataBaeBee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwg494/r_fmas_complement_a_custom_binary_number_system/</guid>
      <pubDate>Fri, 05 Apr 2024 11:54:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] KDD2024 评论的评分标准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bweztg/d_scoring_scale_for_kdd2024_reviews/</link>
      <description><![CDATA[有谁知道今年 KDD 评论的评分标准是多少？我只在 OpenReview 上看到审稿人提出的数字，但在任何地方都找不到总体规模。   由   提交/u/Environmental_Gas318   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bweztg/d_scoring_scale_for_kdd2024_reviews/</guid>
      <pubDate>Fri, 05 Apr 2024 10:49:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] Tensorboard 的替代方案/权重和偏差</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwduod/d_alternatives_to_tensorboard_weights_and_biases/</link>
      <description><![CDATA[我一直在使用 Tensorboard 来跟踪我的深度学习项目中的损失曲线和几个指标的演变，但我放弃了它，因为它太有限了（尤其是在同一个图上进行多次运行）。 我大约 6 个月前开始使用权重和偏差，但它实际上接近于一场噩梦：用户界面极其缓慢，许多错误，非- 直观且文档很少的Python库。我实际上因此浪费了几十个小时。 对于未来的项目，我想改用更好的解决方案。我听说过海王星，但我从未有机会尝试过。我想要一些专注于跟踪指标的东西，但速度快，没​​有漏洞，并且高度可定制。 对 Neptune 有什么意见吗？您还会推荐什么？    由   提交 /u/Skeylos2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwduod/d_alternatives_to_tensorboard_weights_and_biases/</guid>
      <pubDate>Fri, 05 Apr 2024 09:35:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] Hugginface Accelerate 的 DeepSpeed 集成与 Native DeepSpeed</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwcwuv/d_hugginface_accelerates_deepspeed_integration_vs/</link>
      <description><![CDATA[通过加速使用时，deepspeed 的性能、功能和可用性如何？您的体验如何？直接使用 Deepspeed 会错过什么？我计划进行分布式多模式训练（音频+文本）。您建议使用上述深度速度中的哪一个？有什么技术堆栈可以派上用场或帮助我进行培训吗？多模式培训方面的任何相关资源都会有所帮助。预先感谢 ☺️    由   提交/u/gokulPRO  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwcwuv/d_hugginface_accelerates_deepspeed_integration_vs/</guid>
      <pubDate>Fri, 05 Apr 2024 08:31:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] KDD 2024 评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwcact/d_kdd_2024_reviews/</link>
      <description><![CDATA[大家好， KDD 2024 论文评审可在 OpenReview 上查看。随着评论的发布，我创建了这个讨论线程，供我们收集想法、问题和建议或其他任何内容。祝您一切顺利！  更新： Paper Copilot 正在使用以下计算方式收集 KDD&#39;24 评级。您还可以通过此链接输入您的分数，请查看一下。 评分=0.5*新颖性平均。 + 0.5*平均技术质量   由   提交 /u/jeongwhanchoi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwcact/d_kdd_2024_reviews/</guid>
      <pubDate>Fri, 05 Apr 2024 07:46:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 单次参考图像的高效一次性检测的 SOTA 是多少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bw7ol3/d_whats_sota_in_efficient_oneshot_detection_for_a/</link>
      <description><![CDATA[澄清一下，我并不是指通常的野外物体检测任务，就像“这里有一千张随机照片，放置边界框”周围所有的自行车”。我的意思是一个规模小得多的任务，更像是“这里有一千张通过公司传真机的图像，显​​示哪些图像在页面上的某个位置有该公司的徽标”。例如，您有一个在较大图像中查找的确切图像的干净参考副本，但它可能会扭曲、轻微旋转、大小和位置可变等。  以这张信头产品图片为例。如果我有一个“完美的”该图像中页面右上角徽标的 SVG，在图像中找到它确实不应该那么困难（尽管它看起来稍微扭曲，偏离水平约 10 度，而且可能要小得多）比我的参考图像）或者说它不存在。 显然，许多传统的 CV 已经完全被 ML 方法取代，并且目标检测/分割是一个非常活跃的领域。我说 SOTA，但这确实感觉像是一个传统的 CV 问题。我看的不是照片或自然图像，它们是机器生成的，我正在寻找的东西总是看起来或多或少相同，只有细微的变化。如果像 SIFT 功能这样的基本功能可以处理这个问题，那就太好了，但如果我要通过微调更快的 r-cnn 或 yolov5 或 detectorron2 等东西来获得明显更好的结果，那就这样吧。 其他因素：  宁愿不需要需要手工注释的训练集。当目标类别的真实示例变化很大（例如自行车）时，这显然是需要的，但这里的情况并非如此。在 COCO 等内容上进行预训练的模型感觉太过矫枉过正，甚至适得其反，因为我感兴趣的领域与自然图像几乎没有重叠。 更喜欢尽可能轻量级的解决方案。我不需要一个需要两天训练并且可以做无数事情的怪物框架，理想情况下它只是工作得相当好的东西，并且可以在本地运行，并且可以快速训练和快速推理。  更喜欢使用公开代码的方法，但如果有必要，我会自己实现一篇论文。  提前感谢您为我指明正确方向的任何帮助!   由   提交/u/wintermute93  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bw7ol3/d_whats_sota_in_efficient_oneshot_detection_for_a/</guid>
      <pubDate>Fri, 05 Apr 2024 03:17:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] KDD 评论 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bw7gsl/d_kdd_reviews_2024/</link>
      <description><![CDATA[今天不是应该发布 kdd 评论吗？   由   提交 /u/HighAfJoker   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bw7gsl/d_kdd_reviews_2024/</guid>
      <pubDate>Fri, 05 Apr 2024 03:06:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] Deepmind - Mixture-of-Depths：在基于 Transformer 的语言模型中动态分配计算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvrduw/r_deepmind_mixtureofdepths_dynamically_allocating/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2404.02258 ​ 摘要 基于 Transformer 的语言模型在输入序列中均匀分布 FLOP。在这项工作中，我们证明 Transformer 可以学习将 FLOP（或计算）动态分配到序列中的特定位置，从而优化模型深度上不同层的序列分配。我们的方法通过限制可以参与给定层的自注意力和 MLP 计算的令牌数量 (k) 来强制执行总计算预算。要处理的令牌由网络使用 top-k 路由机制确定。由于 k 是先验定义的，因此与其他条件计算技术不同，这个简单的过程使用具有已知张量大小的静态计算图。然而，由于 k 个标记的身份是可变的，因此该方法可能会在时间和模型深度维度上不均匀地消耗 FLOP。因此，计算支出总体上是完全可预测的，但在令牌级别是动态的和上下文敏感的。以这种方式训练的模型不仅可以学习动态分配计算，而且可以高效地进行计算。这些模型与等效 FLOPS 和训练挂钟时间的基线性能相匹配，但每次前向传递只需要一小部分 FLOP，并且在训练后采样期间的步进速度可以快 50% 以上。 ​ https: //preview.redd.it/aez0hy66mhsc1.png?width=1282&amp;format=png&amp;auto=webp&amp;s=59d59bff1dbf7a0323a5e00cb16182bd0f5de9d4 ​ &lt; a href=&quot;https://preview.redd.it/ma6ewf06nhsc1.png?width=2138&amp;format=png&amp;auto=webp&amp;s=f4a845f0892ccb6c4ebe447425c3a0aaadebb03d&quot;&gt;https://preview.redd.it/ma6ewf06nhsc1.png?width =2138&amp;format=png&amp;auto=webp&amp;s=f4a845f0892ccb6c4ebe447425c3a0aaadebb03d   由   提交 /u/RedditLovingSun   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvrduw/r_deepmind_mixtureofdepths_dynamically_allocating/</guid>
      <pubDate>Thu, 04 Apr 2024 16:20:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士正在损害人工智能研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</link>
      <description><![CDATA[这是一个大胆的主张，但我觉得 LLM 的炒作早就该消退了。 GPT4 之后，LLM 性能和设计改进不仅取得了相对较小的进展：使其变得更好的主要方法仍然只是使其更大，并且所有 Transformer 的替代架构都被证明是低于标准和劣质的，它们引起了人们的关注（并且投资）远离其他可能更具影响力的技术。与此同时，大量涌入的人甚至不知道基本的机器学习是如何工作的，他们自称是“人工智能研究员”。因为他们使用 GPT 让每个人在本地托管一个模型，试图让你相信“语言模型完全可以推理”。我们只需要另一个 RAG 解决方案！”他们加入这个社区的唯一目标不是开发新技术，而是利用现有技术拼命拼凑出一项有利可图的服务。甚至论文本身也开始主要由法学硕士撰写。我不禁认为整个领域可能会陷入停滞状态，因为不断增长的社区满足于平庸的修复，这些修复充其量只能使模型在任意“分数”上的得分稍微好一些。他们弥补了这一点，忽略了诸如幻觉、上下文长度、基本逻辑缺乏能力以及运行这种规模模型的高昂成本等明显问题。我赞扬那些不顾市场炒作而致力于开发能够实现真正逻辑过程的代理的人们，并希望很快会引起更多关注。   由   提交/u/NightestOfTheOwls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</guid>
      <pubDate>Thu, 04 Apr 2024 08:36:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>