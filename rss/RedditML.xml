<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 18 Nov 2024 01:20:33 GMT</lastBuildDate>
    <item>
      <title>[D] 对机器学习工程职位的期望</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtt099/d_expectation_from_machine_learning_engineering/</link>
      <description><![CDATA[大家好， 我在这里看到了很多关于 ML 职业和实习或工作机会的帖子，有两件事经常出现  建立强大的研究作品集，并在 NeurIPS、ICLR 和 ICML 等会议上发表文章，这些会议似乎更侧重于获得研究科学家的职位。 对机器学习工程师 (MLE) 职位的需求不断增长，显然比研究科学家职位更受欢迎。  我很好奇这两个角色之间的区别，以及什么样的作品集对于获得 MLE 职位来说是理想的。我知道拥有硕士学位通常是首选，但令人印象深刻的出版记录对 MLE 职位来说是必要的吗？或者这不是什么大问题？ 你怎么看？   由    /u/ziggyboom30  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtt099/d_expectation_from_machine_learning_engineering/</guid>
      <pubDate>Mon, 18 Nov 2024 01:14:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] PCA 与自动编码器在降维方面的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtng8q/d_pca_vs_autoencoders_for_dimensionality_reduction/</link>
      <description><![CDATA[标题总结了一切。我正在处理一些匿名时间序列数据，最初，我构建了一个自动编码器，以便在训练后用回归头替换解码器头。 至于预处理步骤，我通常只减去特征的平均值并除以它们的标准差，虽然我早就听说做“数据去相关”很有帮助，所以我决定最终学习 PCA。 我的问题如下：  如果 PCA 用于查找数据集的主要潜在特征，那么使用自动编码器有什么意义吗？（特别是如果某些特征之间存在高度相关性） 如果仍然有必要使用自动编码器，是否应该首先在数据集上使用 PCA 来去相关数据，或者这只是多余的，或者也许不使用它的另一个原因是它会擦除一些信息？ （尽管它是一种可逆变换，所以我看不出信息会如何丢失） PCA 作为预处理步骤是否有利于树构建算法？我没看到太多关于它的讨论，但对我来说，直观地看，在主成分轴上设置决策节点会带来更好的结果。     提交人    /u/DisciplinedPenguin   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtng8q/d_pca_vs_autoencoders_for_dimensionality_reduction/</guid>
      <pubDate>Sun, 17 Nov 2024 20:56:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 LLM 水印永远行不通</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtkp1d/d_why_llm_watermarking_will_never_work/</link>
      <description><![CDATA[        提交人    /u/bubble_boi   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtkp1d/d_why_llm_watermarking_will_never_work/</guid>
      <pubDate>Sun, 17 Nov 2024 18:55:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一支高效的应用机器学习团队是如何构成的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtke1b/d_how_an_efficient_applied_ml_team_is_structured/</link>
      <description><![CDATA[大家好， 我对你们关于大型（更大）ML 团队的结构的经验很感兴趣，这些团队结构对于使用 ML 进行构建的公司（在多个领域使用 ML 的公司，它们涵盖 CV、NLP 等）效果如何？我尝试搜索它，但关于高效团队结构的信息并不多。虽然结构可以由公司文化定义，但我相信你已经看到了如何让这种结构运作良好的模式。 （我认为一个大团队至少有 80 人，包括 PO/PM）。 最基本的（也许是最好的？）是当领域被划分（CV、NLP 等）时，每个领域都有一个负责人和多个高级、中级和初级。然后除了 ML 工程师之外，还有一个单独的部门负责产品化（创建 rest API 等），其中包括 devops 和 SWE。     由    /u/gabegabe6 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtke1b/d_how_an_efficient_applied_ml_team_is_structured/</guid>
      <pubDate>Sun, 17 Nov 2024 18:41:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] treemind：简化梯度提升模型分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtjkci/r_treemind_simplifying_gradient_boosting_model/</link>
      <description><![CDATA[treemind 是一个功能强大的 Python 库，旨在分析 xgboost、lightgbm 和 catboost 等梯度提升模型。它可以帮助您揭示特征及其相互作用如何影响特定间隔内的预测，从而提供快速、直观的见解。 主要功能：  功能和交互分析：了解最多 n 个特征的特征贡献和复杂交互。 高级可视化：用户友好的图表来解释模型决策。 高性能：使用 Cython 进行了优化，即使在大型数据集上也能实现闪电般的快速执行。 轻松集成：与流行的回归和二元分类框架无缝协作。  算法和性能：  算法：专注于分析基于树的模型中的特征贡献和交互，以获得有意义的基于区间的见解。 阅读有关该算法的更多信息 性能：该库的性能已经在合成数据集上进行了测试，其中它与 SHAP 进行了准确性和效率基准测试。 查看性能实验  快速入门： bash pip install tr​​eemind  查看完整文档以获取示例、可视化和 API 详细信息。 GitHub Repo | 文档 注意： 虽然该算法在实践中产生了理想的结果，但目前缺乏正式的数学证明。我们非常感谢您的反馈和想法，以帮助进一步改进和验证该方法！    提交人    /u/zedeleyici3401   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtjkci/r_treemind_simplifying_gradient_boosting_model/</guid>
      <pubDate>Sun, 17 Nov 2024 18:05:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 论文的质量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtjhge/d_quality_of_iclr_papers/</link>
      <description><![CDATA[我浏览了 ICLR 上一些与我感兴趣的领域相关的中等到高分论文，我发现它们进展缓慢，而且有点惊讶，对于一个主要的子领域来说，像这样的顶级会议，论文质量相当差。自从 llms 出现以来，我觉得论文的质量和原创性（当然不是全部）有所下降。只有我一个人有这种感觉吗？    提交人    /u/Cool_Abbreviations_9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtjhge/d_quality_of_iclr_papers/</guid>
      <pubDate>Sun, 17 Nov 2024 18:02:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtgnk8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Nov 2024 16:00:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用旧向量而不是新向量来定义词汇的小型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtenw8/d_small_language_models_defining_vocabulary_using/</link>
      <description><![CDATA[我一直在思考语言模型为何如此庞大，以及它们如何变得更小。我想每个人的大脑都不可能容纳人类的全部知识。我相信人类大致拥有一个类似于单词 X 其他单词的概率矩阵，但不是每个单词 X 每个单词。 我突然想到，我们经常使用我们知道的其他现有单词来定义不常用的单词（低频率、不常用的单词）。我们能否拥有一个语言模型，该模型仅使用频率最高的单词的向量，而“不常用的单词”没有自己的向量，而是引用现有向量？这可以大大减少单词 X 单词矩阵，因为常用单词由语言的一个小得多的子集组成。也许这样的模型可以在针对特定主题的文本进行重新训练时，动态地将参考词移入和移出主向量。 我知道我从来没有过原创的想法，有没有其他类似的项目？    提交人    /u/meteoraln   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtenw8/d_small_language_models_defining_vocabulary_using/</guid>
      <pubDate>Sun, 17 Nov 2024 14:26:01 GMT</pubDate>
    </item>
    <item>
      <title>用于语义搜索的 NLU 模型与自回归模型 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtdpwu/nlu_models_vs_autoregressive_models_for_semantic/</link>
      <description><![CDATA[在许多语义匹配困难的应用中，系统似乎被设计为使用自回归模型进行输入序列嵌入（然后执行一系列语义搜索技术）。  但从理论上讲，双向模型在这个任务上的表现难道不应该总是优于自回归模型吗？这表明最好使用优化的面向 NLU 的模型（如 DeBERTa-V3）（即对域数据进行微调）来获得更准确的嵌入，从而获得更好的语义搜索性能。 此外，关于统一语义搜索技术的报道有多少？我见过的所有实现都是高度领域特定/任意的。    提交人    /u/SnooPeripherals5313   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtdpwu/nlu_models_vs_autoregressive_models_for_semantic/</guid>
      <pubDate>Sun, 17 Nov 2024 13:37:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 卷积生成对抗网络噪声模式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtc2qv/d_convolutional_generative_adversarial_networks/</link>
      <description><![CDATA[我正在编写一个 DCGAN 来生成基于 BRATs 2020 数据集的脑 MRI 数据。作为一项健全性检查，我正在对具有恒定噪声的单个图像进行训练，以查看我的设计是否存在任何固有缺陷。GAN 似乎捕捉到了一般模式，但存在某种噪声或失真。您可以在下面的示例中看到，生成的图像不如原始图像清晰。 原始图像 lr 1e-4 1000 epochs  lr 2e-4 500 epochs 初始化后 我在所有图像上都看到了一些十字形图案，因此我相信我的网络本身存在问题，从而产生了这些图案。这是代码。 ``` class SimpleGenerator(nn.Module): def __init__(self,out_channels =1, noise_dimension = 100 , channels= 64 ): super(SimpleGenerator, self).__init__() self.noise_shape = (noise_dimension,1,1,1) self.out_channels = out_channels self.channels = channels self.gen = nn.Sequential( nn.ConvTranspose3d(self.noise_shape[0], self.channels * 32, 4, 1, (1, 0, 1)), nn.ReLU(), self._block( self.channels * 32, self.channels * 16, 5, 1, 0), self._block( self.channels * 16, self.channels * 8, 5, 1, 0), self._block( self.channels * 8, self.channels * 4, 4, 2, 1), self._block( self.channels * 4, self.channels * 2, 4, 2, 1), self._block( self.channels * 2, self.channels, 4, 2, 1), nn.ConvTranspose3d( self.channels, self.out_channels, 4, 2, 1), nn.Sigmoid() ) def _block(self,in_channels,out_channels,kernel_size,stride,padding): 返回 nn.Sequential( nn.ConvTranspose3d(in_channels,out_channels,3,1,1,bias=False), nn.InstanceNorm3d(out_channels), nn.ReLU(), nn.ConvTranspose3d(out_channels,out_channels,kernel_size,stride,padding,bias=False), nn.InstanceNorm3d(out_channels), nn.ReLU() ) def forward(self, x,separate=False): x = self.gen(x) return x  注意事项：  我使用 InstanceNorm 而不是 batch norm，因为我的图像是 160 x192x160，它们太大，所以 gpu 无法支持 batch_size &gt;1。 您在内核大小、步幅和填充中看到的奇怪数字是因为我想要实现上面描述的形状，它不是 2 的幂。可能是这个原因吗？ 我尝试了带有 1 或 2 个卷积的 _block 方法（我们看到 2 个版本）。结果相同 鉴别器是生成器的镜像。我不会提供代码来缩短帖子，但如果有人认为需要，我可以提供。     提交人    /u/ripototo   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtc2qv/d_convolutional_generative_adversarial_networks/</guid>
      <pubDate>Sun, 17 Nov 2024 12:00:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找一些音频分割模型。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gtbkhw/d_looking_for_some_audio_segmentation_model/</link>
      <description><![CDATA[标题，也类似于 pyannote/segmentation -3.0 但更好。这个领域有什么新东西吗？我遇到了 mamba，但它仍处于早期阶段，因此无法对此发表任何具体评论。    提交人    /u/Just_Difficulty9836   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gtbkhw/d_looking_for_some_audio_segmentation_model/</guid>
      <pubDate>Sun, 17 Nov 2024 11:26:24 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] R^2 为负，但预测值和实际值之间的相关性具有统计意义？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsxror/discussion_r2_is_negative_but_the_correlation/</link>
      <description><![CDATA[      我做了一些挖掘，但没有真正找到这个问题的答案，所以如果有人知道可能出什么问题，请告诉我。我进行了一些样本外预测（3000 个观测值），在评估预测需求水平的模型时，我得到了非常奇怪的结果。使用的模型是 xgb 回归量。因此 R^2 指出该模型的表现比简单地预测目标变量的平均值更差，但同时实际值和预测值之间的相关性具有统计意义。此外，解释方差得分表明该模型比朴素模型更差，但 Theil 的 U 统计量却相反？代码和结果发布如下。认为未完成的值可能是问题所在，但我将它们剪裁为 0.05 和 0.95 分位数，但没有帮助。 https://preview.redd.it/10kpzdqs1c1e1.png?width=966&amp;format=png&amp;auto=webp&amp;s=9b93f0ef588e2fa5cb16c06f69c0fea1902e0931 https://preview.redd.it/t2rapmo22c1e1.png?width=855&amp;format=png&amp;auto=webp&amp;s=ce9d8d1d2ad54c8743873560bfff8a275a14378d    提交人    /u/maciek024   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsxror/discussion_r2_is_negative_but_the_correlation/</guid>
      <pubDate>Sat, 16 Nov 2024 21:41:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 必读的 ML 理论论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsqqns/r_mustread_ml_theory_papers/</link>
      <description><![CDATA[您好， 我是一名计算机科学博士生，希望加深对机器学习理论的理解。我的研究领域专注于视觉语言模型，但我想通过阅读基础或开创性的机器学习理论论文来扩展我的知识。 您能否分享一份对机器学习理论产生重大影响的必读论文或个人推荐？ 提前谢谢您！    提交人    /u/AntelopeWilling2928   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsqqns/r_mustread_ml_theory_papers/</guid>
      <pubDate>Sat, 16 Nov 2024 16:19:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 分析 UMAP 为何如此之快</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gsjfq9/p_analysis_of_why_umap_is_so_fast/</link>
      <description><![CDATA[      嗨，我最近花了一些时间从 UMAP 算法的实现方式以及它为什么如此之快的角度来了解 UMAP 算法的核心实现（即使它是用 Python 编写的）。我决定将算法分解为更小的步骤，在这些步骤中，我对代码进行一些小的改进（一个接一个），这样最终的结果与我从 UMAP 获得的结果非常相似。 令我惊讶的是，这些变化中的大多数只是优化代码中的技巧，以更快地运行程序或减少更新不太重要的东西的频率。当然，我的实现并没有 100% 地重现 UMAP 算法，因为它是在教育目的中完成的。 我在我的项目中提供了详细的解释，说明我必须在每个步骤中添加什么才能转向类似 UMAP 的算法。这是项目页面：https://github.com/kmkolasinski/nano-umap 如果您是一个喜欢优化代码以提高性能的人，您可能会发现这很有趣。下面是我能够得到的演示：  https://preview.redd.it/eww57c3x881e1.png?width=1921&amp;format=png&amp;auto=webp&amp;s=ed4a345e40b47782ddf39cb93eb9d03207db1160 TLDR：在 UMAP 中他们：  使用 ANN 库快速找到顶级 k-NN， 使用良好的初始化方法，使事情更稳定并且算法需要更少的更新（UMAP 使用快速谱初始化）， 使用随机负采样，这是一种简单的方法，但在实践中效果很好， 压缩 numba 性能（通过用自定义实现替换 np.dot 或 np.clip 来使代码运行得更快）， 使用某种自适应采样，这将使算法将更多时间花在更重要的向量上，从而节省不太重要的向量上的 CPU 时间     提交人    /u/kmkolasinski   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gsjfq9/p_analysis_of_why_umap_is_so_fast/</guid>
      <pubDate>Sat, 16 Nov 2024 09:02:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>