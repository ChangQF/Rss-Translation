<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 11 Nov 2024 12:32:18 GMT</lastBuildDate>
    <item>
      <title>[D] 帮助我进行内部部署 ml 批量预测？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1goqchp/d_help_me_with_onpremise_ml_batch_prediction/</link>
      <description><![CDATA[我需要部署一个 .pkl 模型，在这样的设置下进行批量预测：代码被推送到 GitLab，SQL/pyspark 用于数据，cron 作业处理调度。不允许使用 Docker、Kubernetes 和云。这是本地设置。这种部署的一些最佳实践或方法是什么？    提交人    /u/Simple_Toe_6989   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1goqchp/d_help_me_with_onpremise_ml_batch_prediction/</guid>
      <pubDate>Mon, 11 Nov 2024 11:46:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么域随机化能保证神经网络控制器的稳定性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gopir9/d_why_does_domain_randomization_ensure_stability/</link>
      <description><![CDATA[大家好， 我正在探索域随机化如何有助于 NN 控制器的稳定性，尤其是当训练包括更广泛地查看历史数据时。 具体来说，我很好奇是否有理论基础或正式分析来解释域随机化如何帮助神经网络在不同条件或噪声水平下保持稳定性，尤其是在结合更多历史信息时。是否有论文通过 Lyapunov 稳定性或其他严格方法来分析这种影响，表明接触各种过去数据可以产生更稳定的基于 NN 的控制系统？ 任何关于该领域基础或最新研究的建议都将不胜感激。提前致谢！ （我已经在控制理论 reddit 上写了同样的东西）    提交人    /u/nerdkim   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gopir9/d_why_does_domain_randomization_ensure_stability/</guid>
      <pubDate>Mon, 11 Nov 2024 10:51:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于不同 LLM 红队方法和技术的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gonf47/r_resource_on_varying_llm_red_teaming_methods_and/</link>
      <description><![CDATA[https://github.com/user1342/Awesome-LLM-Red-Teaming    由   提交  /u/OppositeMonday   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gonf47/r_resource_on_varying_llm_red_teaming_methods_and/</guid>
      <pubDate>Mon, 11 Nov 2024 08:14:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 为什么没有文本驱动的布局 AI 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gom4iz/r_why_arent_there_text_driven_layout_ai_models/</link>
      <description><![CDATA[似乎几乎所有东西都有 AI 模型，除了能够描述城市、建筑物、房间或任何类型的空间的布局并创建其视觉表示的模型。让文本驱动的 AI 掌握和生成这些空间关系有什么特别的挑战吗？ 感觉这将是“文本驱动的 AI 游戏生成器”拼图的最后一块。我们几乎为创建游戏所需的所有其他组件都建立了模型。    提交人    /u/jbrinkw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gom4iz/r_why_arent_there_text_driven_layout_ai_models/</guid>
      <pubDate>Mon, 11 Nov 2024 06:42:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 参加 WACV2025</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gokplb/d_attending_wacv2025/</link>
      <description><![CDATA[您好， 有人要参加明年二月在图森举行的 WACV 会议吗？看来我们必须在 JW Marriot 预订一间房，他们将向我们每人收取每天 35 美元 + 税费作为度假村使用费。 有什么想法可以解决此问题吗，例如附近的酒店或其他解决方案？ 谢谢！    提交人    /u/tuvovan   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gokplb/d_attending_wacv2025/</guid>
      <pubDate>Mon, 11 Nov 2024 05:14:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用图像模型可视化 LLM 注意层对一组 token 的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gojg09/d_how_to_visualize_the_effect_of_an_llm_attention/</link>
      <description><![CDATA[通过将 token 嵌入输入到图像模型中，是否可以可视化 LLM 在通过注意层处理 token 之前和之后如何“想象”token？我知道您无法复制粘贴它，但是有没有办法捕获由注意层引起的潜在变换并将此变换应用于图像模型的嵌入空间？ 例如，如果我在 LLM 中输入“穷人”，那么“男人”的嵌入将转向“乞丐”，而输入“皇室男人”时，它可能会更接近“国王”。我想可视化这种变化。然后，你可以将人的嵌入转移到图像模型中，它会在这个例子中创建类似乞丐或国王的东西。 如果你捕获每个注意层之后的转换并通过插值每个步骤制作视频，它可以制作出非常酷的可视化效果。    提交人    /u/jbrinkw   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gojg09/d_how_to_visualize_the_effect_of_an_llm_attention/</guid>
      <pubDate>Mon, 11 Nov 2024 04:01:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 随机一位安全研究人员对一个有趣方法的猜测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1goi8ut/d_a_guess_for_an_interesting_method_by_a_random/</link>
      <description><![CDATA[我的专业是网络安全，但我对学习（一般来说）充满热情，对很多事情都深感兴趣，包括人工智能/机器学习研究。我一直在探索创建模型的概念，以一种新颖的、非同寻常的方式探索潜在空间。这个想法植根于好奇心驱动的强化学习原理，应用于生成模型。通过刺激驱动的注意力机制、内在刺激奖励和记忆增强架构，我试图想出一些可能有效的东西。以下是简要概述： 刺激驱动的注意力机制：将基于熵的奖励层集成到传统注意力机制中，以鼓励模型探索潜在空间中鲜为人知的标记和区域。 https://preview.redd.it/5isz9dj3h60e1.png?width=768&amp;format=png&amp;auto=webp&amp;s=e2d9ba2ed635c176b9dc66364a026ce024189d47 内在刺激奖励：修改损失函数以优先考虑令人惊讶或低概率的输出，在准确性和新颖性之间取得平衡。 https://preview.redd.it/ox9vkq57h60e1.png?width=798&amp;format=png&amp;auto=webp&amp;s=e88bce2eeaadca2e3c06a4c700adf261a9740adb 这些是主要思想。除此之外，您还可以： 记忆增强生成网络：实现情景记忆缓冲区和新颖性比较模块，以奖励与先前模式的偏差。 自我调节探索机制：当输出质量下降时，通过调整刺激奖励来添加反馈回路以保持一致性。 请帮我弄清楚这是否有意义。我不太喜欢这些想法本身。    提交人    /u/Entropy667   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1goi8ut/d_a_guess_for_an_interesting_method_by_a_random/</guid>
      <pubDate>Mon, 11 Nov 2024 02:55:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 结合归纳和传导进行抽象推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1goh5ym/r_combining_induction_and_transduction_for/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1goh5ym/r_combining_induction_and_transduction_for/</guid>
      <pubDate>Mon, 11 Nov 2024 01:58:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] / [D] 您最近最喜欢的 LLM 或基于扩散模型的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1go8qz0/r_d_your_most_recent_favorite_llm_or_diffusion/</link>
      <description><![CDATA[大家好， 作为竞赛的一部分，我正在尝试寻找一篇有趣的论文，作为我研究小组会议的演讲。我对语言模型和计算机视觉生成 AI 的进步很感兴趣，特别是使用扩散模型。 我想问一下，您目前最喜欢与这些领域相关的哪些论文，以及您为什么喜欢它们。我喜欢那些思维方式相当简单但创新性很强的论文，这些论文可以为研究增添很多价值。请提供您的想法/链接，我非常感谢您的所有意见。谢谢！！    提交人    /u/Tough-Statement9740   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1go8qz0/r_d_your_most_recent_favorite_llm_or_diffusion/</guid>
      <pubDate>Sun, 10 Nov 2024 19:32:31 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ML 和 DL 模型中存在伪造新型方法的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1go50wf/discussion_papers_with_fake_novel_approach_in_ml/</link>
      <description><![CDATA[为什么很多新论文（通常由博士完成）都采用现有方法，而当您询问他们的贡献时，他们说我们用另一层替换了这一层，或者我们添加了超参数!!!!! 这不是贡献！我很困惑这些怎么会被接受    提交人    /u/Rihab_Mira   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1go50wf/discussion_papers_with_fake_novel_approach_in_ml/</guid>
      <pubDate>Sun, 10 Nov 2024 16:53:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 建立了一个路线图网站，25 天内获得了 450 名用户，我太高兴了！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnwfhn/p_built_a_roadmap_site_and_got_450_users_in_25/</link>
      <description><![CDATA[      大家好，我是一名三年级 cse 学生。上个月，我建立了一个名为 https://www.mldl.study/ 的网站。该网站面向任何“刚”接触机器学习和深度学习且不知道从哪里开始的人。我建立这个网站是因为我也对此感到困惑。它有适当的视频讲座、文章、研究论文、可视化、kaggle 竞赛以及基本上掌握 ml 和 dl 所需的一切。 我 25 天前刚刚添加了谷歌分析，我发现我有 450 个用户和 135 个回访用户。我建立这个网站只是为了帮助我的大学朋友，但我很高兴它也能帮助其他人。我只是想分享这个，因为我对此很高兴。这让我有信心，我将来可以构建更酷、更有用的东西。 谢谢大家。我的分析能力从这里得到了一点推动。谢谢！！ （我也愿意接受建议和所有我可以做的事情来进一步发展它） https://preview.redd.it/s9v6omy5f10e1.png?width=1558&amp;format=png&amp;auto=webp&amp;s=eeb9a22012e2e3806245e9267a1187bb91e75305    提交人    /u/Grouchy-Breakfast-20   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnwfhn/p_built_a_roadmap_site_and_got_450_users_in_25/</guid>
      <pubDate>Sun, 10 Nov 2024 08:48:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对数概率与信息论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrpfe/d_log_probability_and_information_theory/</link>
      <description><![CDATA[在机器学习中，我们大量使用对数概率，试图最大化对数概率。从数字角度来看，这是有道理的，因为加法比乘法更容易，但我也想知道“对数概率”背后是否有根本含义。 例如，对数概率在信息论中被广泛使用，是“信息”的负数。我们能从信息论的角度来看待最小化负对数似然吗？它是最大化/最小化某些信息指标吗？    提交人    /u/masonw32   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrpfe/d_log_probability_and_information_theory/</guid>
      <pubDate>Sun, 10 Nov 2024 03:37:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[N] ARC 奖项为解决网格上彩色方块组成的谜题的少样本学习提供 60 万美元奖金。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnnstd/n_the_arc_prize_offers_600000_for_fewshot/</link>
      <description><![CDATA[        提交人    /u/moschles   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnnstd/n_the_arc_prize_offers_600000_for_fewshot/</guid>
      <pubDate>Sun, 10 Nov 2024 00:08:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>