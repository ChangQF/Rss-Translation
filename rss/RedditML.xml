<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 01 Oct 2024 12:33:41 GMT</lastBuildDate>
    <item>
      <title>[D] 关于推荐引擎社会影响的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fthnre/d_thoughts_on_societal_impacts_of_recommender/</link>
      <description><![CDATA[嗨！推荐引擎是我们生活中无处不在的一部分。它们会推荐我们应该买什么、听什么、约会对象和吃什么。我们倾向于认为它们最关心我们的利益——因为它们知道我们喜欢什么音乐，所以它们总是会根据我们的兴趣而不是我们的业务需求（例如想要销售更多特定品种的产品）向我们推荐一些东西。 我有兴趣了解更多关于推荐引擎如何影响你生活的一些奇怪方式。或者甚至是你是如何破解推荐引擎​​的——你是否故意开设了某种类型的新账户，试图弄清楚某些决定是如何做出的——例如在 Tinder/Bumble 上以某种方式滑动。 很想听听你的想法，因为我觉得它们很有趣！    提交人    /u/No-Group-5497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fthnre/d_thoughts_on_societal_impacts_of_recommender/</guid>
      <pubDate>Tue, 01 Oct 2024 06:34:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 对基于 Gemma 的模型进行微调（LoRA）并获得较高的训练和验证损失值</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftgxx3/p_finetuning_lora_a_gemmabased_model_and_getting/</link>
      <description><![CDATA[您好！我是一名计算机科学专业的学生，​​正在尝试微调（LoRA）基于 Gemma 7b 的模型以完成我的论文。但是，我不断获得较高的训练和验证损失值。我尝试了不同的学习率、批量大小、lora 等级、lora alpha 和 lora dropout，但损失值仍然很高。 我也尝试使用不同的数据整理器。使用 DataCollat​​orForLanguageModeling，我的损失值低至 ~4.XX。使用 DataCollat​​orForTokenClassification，它开始时非常高，大约为 18-20，有时更高。DataCollat​​orWithPadding 对我来说不起作用，它给了我这个错误： ValueError：预期输入 batch_size (304) 与目标 batch_size (64) 匹配。  这是我的训练师  training_args = TrainingArguments( output_dir=&quot;./training&quot;, remove_unused_columns=True, per_device_train_batch_size=params[&#39;batch_size&#39;], gradient_checkpointing=True, gradient_accumulation_steps=4, max_steps=500, learning_rate=params[&#39;learning_rate&#39;], logsing_steps=10, fp16=True, optim=&quot;adamw_hf&quot;, save_strategy=&quot;steps&quot;, save_steps=50, evaluation_strategy=&quot;steps&quot;, eval_steps=5, do_eval=True, label_names = [&quot;input_ids&quot;, &quot;labels&quot;, &quot;attention_mask&quot;], report_to = &quot;none&quot;, ) trainer = Trainer( model=model, train_dataset=tokenized_dataset[&#39;train&#39;], eval_dataset=tokenized_dataset[&#39;validation&#39;], tokenizer=tokenizer, data_collat​​or=data_collat​​or, args=training_args, )  我的数据集如下所示  text,absent,dengue,health,mosquito,sick 不是生病的好时机。,0,0,1,0,1 NUNG NA DENGUE AKO [LINK],0,1,1,0,1 是发烧还是天气原因,0,0,1,0,1 上帝帮助病人？,0,0,1,0,1 &quot;产妇观察。 [HASHTAG] [HASHTAG] [HASHTAG] @ 西利曼大学医学中心基金会，Inc . [LINK]&quot;,0,0,1,0,0 ? @ St .特蕾莎医院 [LINK],0,0,1,0,0  Tokenized: {&#39;text&#39;: &#39;现在不是生病的好时机&#39;, &#39;input_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1665, 476, 1426, 1069, 577, 947, 11666], &#39;attention_mask&#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], &#39;labels&#39;: [0, 0, 1, 0, 1]}  格式化程序： import re from datasets import DatasetDict max_length = 20 def clean_text(text): # 删除 URL text = re.sub(r&quot;\[LINK\]&quot;, &quot;&lt;URL&gt;&quot;, text) # 删除标签和提及 text = re.sub(r&quot;@[A-Za-z0-9_]+&quot;, &quot;\[MENTION\]&quot;, text) text = re.sub(r&quot;#\w+&quot;, &quot;\[HASHTAG\]&quot;, text) # 将文本小写 text = text.lower() # 删除特殊字符和多余空格 text = re.sub(r&quot;[^a-zA-Z0-9\s&lt;&gt;\&#39;]&quot;, &quot;&quot;, text) text = re.sub(r&quot;\s+&quot;, &quot; &quot;, text).strip() return text # 对文本列应用清理 dataset[&#39;train&#39;] = dataset[&#39;train&#39;].map(lambda x: {&#39;text&#39;: clean_text(x[&#39;text&#39;])}) def tokenize_function(examples): # 对文本进行标记 tokenized_text = tokenizer( examples[&#39;text&#39;], padding=&quot;max_length&quot;, truncation=True, max_length=max_length ) # 创建标签列表列表 labels = [ [examples[&#39;absent&#39;][i], examples[&#39;dengue&#39;][i], examples[&#39;health&#39;][i], examples[&#39;mosquito&#39;][i], examples[&#39;sick&#39;][i]] for i in range(len(examples[&#39;text&#39;])) ] tokenized_text[&#39;labels&#39;] = labels return tokenized_text # 对数据集应用标记化 tokenized_dataset = dataset.map(tokenize_function, batched=True) # 删除原有的标签列 tokenized_dataset = tokenized_dataset.remove_columns([&#39;absent&#39;, &#39;dengue&#39;, &#39;health&#39;, &#39;mosquito&#39;, &#39;sick&#39;]) # 打印出一个标记化的示例 print(tokenized_dataset[&#39;train&#39;][0])     submitted by    /u/jobiskits   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftgxx3/p_finetuning_lora_a_gemmabased_model_and_getting/</guid>
      <pubDate>Tue, 01 Oct 2024 05:44:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可扩展的机器学习管道，专注于训练基础设施</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftg3ly/d_scalable_ml_pipelines_focusing_training_infra/</link>
      <description><![CDATA[大家好，我目前正在尝试更多地了解 ML 系统设计，重点是基础模型的训练基础设施，我发现研究这个主题很困难。 有没有什么好的资源有人熟悉可能会有帮助？    提交人    /u/adi214   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftg3ly/d_scalable_ml_pipelines_focusing_training_infra/</guid>
      <pubDate>Tue, 01 Oct 2024 04:51:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 考古学或古代历史中的机器学习潜力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdw6n/d_machine_learning_potential_in_archeology_or/</link>
      <description><![CDATA[目前在 T10 攻读数学计算机科学专业的本科生，这可能是一个愚蠢的问题，但有没有人想过或对在埃及学或考古学等历史领域使用人工智能有过任何想法？破译象形文字，使用深度学习寻找陵墓或文物的位置，组装破碎或毁坏的古代文物或陶器和绘画等物品。只是想知道是否有人对这个主题有任何想法，以及它是否具有现实潜力（或没有）。我认为最大的困难是缺乏好的数据。    提交人    /u/hmbhack   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdw6n/d_machine_learning_potential_in_archeology_or/</guid>
      <pubDate>Tue, 01 Oct 2024 02:47:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们如何构建对话式检索增强生成应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdby7/d_how_are_folks_building_conversational_retrieval/</link>
      <description><![CDATA[我已阅读了各种资源，例如： - https://vectorize.io/how-i-finally-got-agentic-rag-to-work-right/ - https://python.langchain.com/docs/tutorials/qa_chat_history/ - https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/ - https://docs.llamaindex.ai/en/stable/module_guides/deploying/chat_engines/ - https://huggingface.co/datasets/nvidia/ChatRAG-Bench  但这些感觉过于简单，因为它们没有解决以下复杂性： 1）何时检索与立即响应以减少延迟 2）依靠先前在对话中检索到的现有上下文，而不是在当前回合再次检索 3）在检索到的信息和过去的对话历史之间划分 LLM 上下文。 我相信一些团队已经有了很好的系统，将不胜感激指针！    由    /u/iidealized 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdby7/d_how_are_folks_building_conversational_retrieval/</guid>
      <pubDate>Tue, 01 Oct 2024 02:17:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] SynthPAI：用于个人属性推断的合成数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftb4hk/r_synthpai_a_synthetic_dataset_for_personal/</link>
      <description><![CDATA[[被 NeurIPS&#39;24 D&amp;B 接受] TL;DR：我们为 Reddit 构建了一个 LLM 代理模拟框架，以生成合成数据来推进基于推理的隐私研究。 预印本：https://arxiv.org/abs/2406.07217 Github：https://github.com/eth-sri/SynthPAI 在我们的最新研究论文中，我们介绍了 SynthPAI - 一个合成数据集，它为评估基于 LLM 的个人属性推理的新基准奠定了基础。我们为 Reddit 构建了一个 LLM 代理模拟框架，以生成合成数据来推进基于推理的隐私研究。利用该框架，我们构建了一个 PAI（私有属性推断）数据集，其中包含 7800 多条评论和 300 个合成配置文件以及经过人工验证的属性标签。我们表明，我们的评论表现出高保真度（人类无法将它们与真实评论区分开来）和对 PAI 研究的信息性，使我们能够在各种实验中得出与真实世界数据相同的定性结论。    提交人    /u/equin_x   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftb4hk/r_synthpai_a_synthetic_dataset_for_personal/</guid>
      <pubDate>Tue, 01 Oct 2024 00:27:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 原生架构优化：torchao</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftaw4e/d_pytorch_native_architecture_optimization_torchao/</link>
      <description><![CDATA[https://pytorch.org/blog/pytorch-native-architecture-optimization/    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftaw4e/d_pytorch_native_architecture_optimization_torchao/</guid>
      <pubDate>Tue, 01 Oct 2024 00:16:04 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 为AI模型量身定制的无损压缩库 - 将Llama3.2的传输时间缩短33%</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ft2v10/project_a_lossless_compression_library_taliored/</link>
      <description><![CDATA[如果您希望减少 Hugging Face 的下载时间并帮助减少其服务器负载—（Clem Delangue 提到 HF 每天处理高达 6PB 的数据！） —&gt;您可能会发现 ZipNN 很有用。 ZipNN 是一个开源 Python 库，可在 MIT 许可下使用，专门用于压缩 AI 模型而不会损失准确性（类似于 Zip，但针对神经网络进行了定制）。 它使用无损压缩将模型大小减少 33%，节省了三分之一的下载时间。 ZipNN 有一个 HF 插件，因此您只需添加一行代码即可。 在这里查看： https://github.com/zipnn/zipnn Hugging Face 上已经有几个带有 ZipNN 的压缩模型，如果您有兴趣，可以直接上传更多。 最新的是 Llama-3.2-11B-Vision-Instruct-ZipNN-Compressed 看看这个 Kaggle 笔记本： 对于您可以在此 Kaggle 笔记本中找到 Llama-3.2 的实际示例： https://www.kaggle.com/code/royleibovitz/huggingface-llama-3-2-example ZipNN repo 中提供了更多示例： https://github.com/zipnn/zipnn/tree/main/examples    提交人    /u/Candid_Raccoon2102   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ft2v10/project_a_lossless_compression_library_taliored/</guid>
      <pubDate>Mon, 30 Sep 2024 18:32:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 量化模型的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsz97a/d_whats_the_best_way_to_quantise_a_model/</link>
      <description><![CDATA[我正在使用 SentenceTransformers 库中的一个 80MB 模型。它很棒，但我需要它在我的用例中更快一些。作为参考，基础模型每秒产生 2000 个嵌入。 编辑：我使用“性能”来表示每秒嵌入的数量。 我尝试使用 PyTorch 和 ONNX 量化模型。 PyTorch 量化@8 位 为了在 PyTorch 中进行量化，我使用了以下代码： import torch from sentence_transformers import SentenceTransformer torch.backends.quantized.engine = &#39;qnnpack&#39; model = SentenceTransformer(&quot;all-MiniLM-L6-v2&quot;, device=&quot;cpu&quot;) quantized_model = torch.quantization.quantize_dynamic( model, {torch.nn.Linear}, # 要量化的层 dtype=torch.qint8 # 量化数据类型 )  令我惊讶的是，这使模型的性能减半！量化模型每秒可管理 1000 个嵌入。 ONNX 量化@8 位 ONNX 量化更复杂，所以我不会发布所有代码，但最终结果是模型性能的三分之一。每秒仅管理 700 个嵌入。 为什么会发生这种情况？ 我研究过这个问题，可能是因为我的 Apple Silicon 芯片（M3 Pro）没有 8 位数字的加速。我觉得这很难相信，因为 Ollama 量化为 4 位并且在我的计算机上运行速度非常快。这留下了操作员错误。 我做错了什么？有没有一种万无一失的方法来量化我所缺少的模型？    提交人    /u/FPGA_Superstar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsz97a/d_whats_the_best_way_to_quantise_a_model/</guid>
      <pubDate>Mon, 30 Sep 2024 16:05:57 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 有哪些关于机器学习、深度学习或 NLP 的博客？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fsv7js/discussion_what_are_some_the_informative_blogs_on/</link>
      <description><![CDATA[您可以分享它们吗    由   提交  /u/Internal_Complaint64   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fsv7js/discussion_what_are_some_the_informative_blogs_on/</guid>
      <pubDate>Mon, 30 Sep 2024 13:12:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我试图通过分析数百条 Reddit 帖子来绘制人工智能中最常见和最流行的挑战。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fstn9m/p_i_tried_to_map_the_most_recurrent_and_popular/</link>
      <description><![CDATA[嗨，AI 爱好者和开发者们！我一直在开展一个项目，通过查看 Reddit 专用子版块上的帖子来分析和可视化 AI 开发中最常见的技术挑战。 项目目标 该项目的主要目标是识别和跟踪与 AI 开发相关的最普遍和最流行的技术挑战、实施问题和概念障碍。通过这样做，我们可以：  帮助开发人员专注于最相关的技能和知识领域 指导教育内容创建者解决最紧迫的问题 为研究人员提供有关需要更多关注或解决方案的领域的见解  工作原理  数据收集：我从以下每个与 AI 相关的 subreddits 中获取了最热门的 200 个帖子：r/learnmachinelearning、r/ArtificialIntelligence、r/MachineLearning、r/artificial。 筛选：使用 LLM 筛选帖子，以确保它们涉及特定的技术挑战，而不是一般讨论或新闻。 总结和标记：每个相关帖子都经过总结和标记最多可从预定义的 50 个技术领域列表中选择三个类别（例如，LLM-ARCH 代表大型语言模型架构，CV-OBJ 代表计算机视觉对象检测）。 分析：系统分析标签的频率，以及每个类别相关的赞成和评论。 可视化：结果通过各种图表和热图可视化，显示最常见的挑战及其在社区中的相对重要性。  结果（以下是图表）：  按综合得分（频率 + 赞成 + 评论）排名的前 15 个标签 标准化标签流行度热图 带有各个分数的标签分析表  反馈 我很乐意得到您的对这个项目的想法以及如何使其对人工智能开发社区更有用。具体来说：  除了 Reddit 之外，我们还应该考虑其他数据源吗？ 您认为哪些其他指标或分析有价值？ 如何使结果对开发人员、教育工作者或研究人员更具可操作性？ 这种方法是否存在我们应该解决的潜在偏见或局限性？ 您是否对定期更新这些趋势的仪表板感兴趣？  非常感谢您的见解和建议！ TL;DR：AI 开发挑战分析器  该项目分析 Reddit 帖子以识别常见的 AI 开发挑战 使用 ML 筛选、总结和标记来自 AI 相关子版块的帖子 可视化结果以显示讨论最多和参与度最高的技术领域 在此处查看结果 寻求反馈以改进分析     提交人    /u/Fixmyn26issue   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fstn9m/p_i_tried_to_map_the_most_recurrent_and_popular/</guid>
      <pubDate>Mon, 30 Sep 2024 11:53:28 GMT</pubDate>
    </item>
    <item>
      <title>[N] 强化学习速查表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fssp75/n_reinforcement_learning_cheat_sheet/</link>
      <description><![CDATA[大家好！ 我刚刚在 Medium 上发表了我的第一篇文章，还创建了一个强化学习备忘单。🎉 我很乐意听到您的反馈、建议或任何关于如何改进它们的想法！ 请随时查看它们，并提前感谢您的支持！😊 https://medium.com/@ruipcf/reinforcement-learning-cheat-sheet-39bdecb8b5b4    提交人    /u/Prudent_Nose921   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fssp75/n_reinforcement_learning_cheat_sheet/</guid>
      <pubDate>Mon, 30 Sep 2024 10:56:25 GMT</pubDate>
    </item>
    <item>
      <title>🚀 将任何 GitHub 存储库转换为单个文本文件，非常适合 LLM 提示使用“[Project]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fspn1s/convert_any_github_repo_to_a_single_text_file/</link>
      <description><![CDATA[大家好！ 👋 我知道有几种类似的工具，但你应该看看我的工具的原因如下：  免费且立即可用 💸 适用于私有存储库 🛡️ 完全在你的浏览器中运行 - 不会将数据发送到任何地方，因此它完全安全 🔒 适用于GitHub URL 到子目录 📁 支持标签、分支和提交 SHA 🏷️ 让你包含或排除特定文件 📂  🔗 试用这里 🔗 源代码 尝试一下，让我知道你的想法！😊 repo2txt 演示    提交人    /u/Beautiful-Novel1150   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fspn1s/convert_any_github_repo_to_a_single_text_file/</guid>
      <pubDate>Mon, 30 Sep 2024 07:05:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 29 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>