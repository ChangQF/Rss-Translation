<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 23 Apr 2024 09:13:46 GMT</lastBuildDate>
    <item>
      <title>[R] 寻求基于神经网络的热扩散研究的专家审稿人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cazmth/r_seeking_expert_reviewers_for_neural/</link>
      <description><![CDATA[大家好， 我正在准备提交一篇研究论文，需要确定潜在的审稿人。我的论文介绍了一种使用神经网络解决钢棒热扩散问题的新方法。传统方法常常难以应对复杂的边界条件或非线性材料特性，但我们的神经网络模型经过经典分析方法的解决方案训练，在以较低的误差范围准确预测温度分布方面表现出了希望。 我寻找拥有博士学位的专家。或医学博士，并在物理学、热动力学或机器学习相关领域拥有丰富的经验。如果您在这些领域拥有专业知识或认识这样做的人，我将非常感谢您的意见或推荐。 到目前为止我所做的： 开发了神经网络模型并针对经典解决方案进行了测试。 起草了详细说明方法、结果和含义的手稿。 我面临着寻找对热物理学有深入了解的合适审稿人的挑战。和机器学习应用程序。此社区的任何指导或建议都会非常有帮助。 感谢您考虑我的请求！ 致以诚挚的问候， Ed   由   提交/u/No-Palpitation-7229   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cazmth/r_seeking_expert_reviewers_for_neural/</guid>
      <pubDate>Tue, 23 Apr 2024 08:44:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 门控长期记忆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1caywsz/d_gated_longterm_memory/</link>
      <description><![CDATA[      今天，我将展示我的最新想法：门控长期记忆 GLTM 单元 门控长期记忆试图实现一种高效的 LSTM 替代方案。与 LSTM 不同，GLTM 并行执行所有繁重的工作，唯一顺序执行的操作是乘法和加法操作。与变形金刚的二次存储器相比，门控长期存储器仅使用线性存储器。   由   提交/u/jessielesbian  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1caywsz/d_gated_longterm_memory/</guid>
      <pubDate>Tue, 23 Apr 2024 07:52:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] 可扩展且可定制的 Vertex AI MLOps 平台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1caywir/p_extensible_and_customisable_vertex_ai_mlops/</link>
      <description><![CDATA[我刚刚在 Google Cloud Platform (GCP) 上发布了一个开源的端到端 Vertex AI MLOps 平台。它全面概述了基本组件以及启用此类平台所需的各种操作。 如果您是希望在 GCP 上开始使用 MLOps 的团队或个人，这可能是宝贵的资源 您可以在 Medium 上阅读相关内容：可扩展且可自定义Vertex AI MLOps 平台   由   提交/u/AdComfortable5974   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1caywir/p_extensible_and_customisable_vertex_ai_mlops/</guid>
      <pubDate>Tue, 23 Apr 2024 07:52:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型语言模型自我演化综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cayejz/r_a_survey_on_selfevolution_of_large_language/</link>
      <description><![CDATA[大家好，我是第二作者（也是项目负责人），想分享我们的最新工作：自我调查大型语言模型的演变。  采用自我进化方法的法学硕士数量迅速增加。然而，这些方法之间的关系仍然不清楚，缺乏系统的组织。 https://preview.redd.it/bhfeilfni6wc1.jpg?width=1240&amp;format=pjpg&amp;auto=webp&amp;s=8c268f3033fcd08c55ce860d00ff02c83bcb第3884章差距，我们很高兴地介绍我们的最新论文，“大型语言模型自我进化的调查”，它提出了法学硕士自我进化的概念框架，使模型（例如WizardLM，LLAMA和Phi）自主地（1）获取和（2）完善经验，（3）自我更新，以及（4）迭代评估他们的表现。 https://preview.redd.it/br95klfni6wc1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;s =93f6ae86772e632c168617c4cabd350f892eeedb  我们的框架探索了法学硕士从数据飞轮转向智能飞轮的潜力，并希望成为一种新的训练范式，将法学硕士和基于法学硕士的代理扩展到更自主的人工智能系统。  更多详情，请访问： 📄 Arxiv：https://arxiv.org/abs/2404.14387  🤖 GitHub：https://github .com/AlibabaResearch/DAMO-ConvAI/tree/main/Awesome-Self-Evolution-of-LLM 🐦 推文：https://twitter.com/tnlin_tw/status/1782662569481916671我们将不断添加论文并改进调查和回购。欢迎任何建议和 PR！   由   提交 /u/tnlin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cayejz/r_a_survey_on_selfevolution_of_large_language/</guid>
      <pubDate>Tue, 23 Apr 2024 07:17:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] Zotero组织</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cayah8/d_zotero_organization/</link>
      <description><![CDATA[使用 Zotero 组织和阅读研究论文的人，你们如何使用集合、子集合或标签？ 字面意思，我想知道您正在研究什么（视觉、语言……）以及您正在使用哪些集合、子集合或标签以及如何使用？ 最近我开始使用 Zoteor，我真的很喜欢对此感到困惑。从其他人那里寻找灵感。提前致谢。   由   提交/u/Relative_Tip_3647   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cayah8/d_zotero_organization/</guid>
      <pubDate>Tue, 23 Apr 2024 07:10:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] NLP模型选择</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1caxp40/p_nlp_model_choice/</link>
      <description><![CDATA[大家好！我希望您度过愉快的一天，我目前正在寻找最好的 NLP 模型来组成我正在开发的智能聊天机器人，我必须对其进行微调。 我的标准是：&lt; /p&gt; • 我需要数学/物理领域最合乎逻辑/中肯的解释 • 这是教育目的，因此它需要有能力提供良好的类比或“儿童解释”  • 它需要非常快速和流畅 我真的很感激任何建议:))   由   提交 /u/Simontana27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1caxp40/p_nlp_model_choice/</guid>
      <pubDate>Tue, 23 Apr 2024 06:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何优化 GCP Vertex AI 文本嵌入模型（gecko@003/preview-0409 模型）的参数，例如要搜索的分数叶节点、叶节点嵌入计数、近似 NN 计数？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1caxm6q/d_how_to_optimize_parameters_for_gcp_vertex_ai/</link>
      <description><![CDATA[您好，我在 GCP 社区上发帖了几次，但没有收到回复，所以在这里尝试...很高兴获得更一般性的建议不是特定于 GCP...我目前并不是在寻求使用其他（例如开源）模型的建议。 背景 我正在构建搜索功能使用 Vertex AI 文本嵌入和多模式嵌入。想象一个社交媒体平台，您可以在其中通过文本或图像查询语义搜索用户（有许多保护措施！）。它对于多模态嵌入确实（可怕地）很好地工作，但我在使用以下配置的文本搜索结果的相关性方面遇到了问题： 预处理：  非结构化文本数据的长度为 &lt;1000 个字符（仅限英文） 删除重复或更多 \n, !, ?, 。修剪然后将其拆分为单个 \n, !, ?, .字符 生成的段通常小于 100 个字符，大部分小于 100 个字符。 30 个字符  嵌入：  型号：textembedding-gecko@003 / text-embedding-preview-0409 任务类型： SEMANTIC_SIMILARITY  索引：  算法类型：tree-AH 维度：768 距离测量类型：点积距离 特征范数类型：无??? 向量大小：~10 k 要搜索的分数叶节点：0.1 ???&lt; /li&gt; 叶节点嵌入数量：1000 ??? 分片数量：1 大约邻居数量：200 ??? 邻居数量：20（将保持原样，但最终根据高于某个阈值 NN 距离的结果使其动态）  部署：  区域：us-central1  最小/最大副本数量：1/1（以确保我不会超过 1 个节点/索引/区域的配额） 机器类型：e2-standard-2   问题 如何优化索引，特别是带问号的配置参数？是否有经验法则/公式（我使用了 Google 推荐的规则），或者是一个实验案例，并运行具有不同配置的多个部署索引，获取延迟、NN 距离并（可能手动）检查一系列搜索结果的相关性测试查询？ 我的背景是化学工程师，而且我是自学的软件工程师，所以没有很多 CS 特定知识。任何学习这一点的资源将不胜感激。我还有很多其他问题，但现在想看看在召回和延迟方面效果如何，在构建它之前我可以让它在一个简单的 Web 服务中运行，而无需花费数百美元（我有 1000 美元的 Gen AI 积分可以使用）到我正在开发的 Android/iOS 应用程序中，并设置更新方法，并最终在测试发布之前使用大约 100 万个矢量大小进行测试。 感谢您的任何帮助、建议，资源。我不打算很快成为一名 ML 专家，只是为了让一些相当不错的东西工作。 *例如什么是更好的分段方法，或者我应该使用 NLP 工具，什么是设置嵌入预计算、缩放（分片大小、机器大小、副本）的有效方法   由   提交/u/AxelrodWins   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1caxm6q/d_how_to_optimize_parameters_for_gcp_vertex_ai/</guid>
      <pubDate>Tue, 23 Apr 2024 06:25:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么在 WAWQI 上建立机器学习模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1caw5ft/d_why_ml_models_on_wawqi/</link>
      <description><![CDATA[我正在做一个关于水质预测的项目。为了训练机器学习模型，我们需要 x（自变量）和 y（因变量）值。我正在使用加权 arethamatic 水质指数，使用一些数学方程从 x 计算 y 值，现在在计算 y 值后，我正在根据 x 和 y 值训练 ml 模型。我的问题是，机器学习模型值得应用吗？他们是否做了一些附加组件来查找信息？问题强调了当加权算术水质指数 (WAWQI) 已经可用时，使用 ML 模型进行水质预测的一个重要考虑因素 我认为，通过计算 ML 模型的 wawqi 值也可以完成与 ML 模型相同的操作测试数据，然后根据wawqi值判断水的好坏。那么为什么需要使用机器学习模型呢？我看到一些论文在做同样的事情，但不明白为什么？ 感谢有用的输入。   由   提交/u/Silver_Bison_4987   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1caw5ft/d_why_ml_models_on_wawqi/</guid>
      <pubDate>Tue, 23 Apr 2024 04:53:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] Phi-3即将发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/</link>
      <description><![CDATA[从 MSFT 的两个独立消息来源（其中一个接近 Sebastien Bubeck）了解到即将推出的 Phi-3 模型：  三个不同大小的模型（最多 14B） 同样，主要是合成和 LLM 增强的训练数据 显然在训练方面有一些升级技​​术 否更多 Apache 2，但更严格的许可证（类似于 llama3） Mixtral 级别性能，参数少得多  我想看看是否有人有更多有关模型的内部信息.   由   提交/u/yusuf-bengio  /u/yusuf-bengio  reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cartvg/d_phi3_to_be_released_soon/</guid>
      <pubDate>Tue, 23 Apr 2024 01:13:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM准确性评估方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1caq0jy/d_llm_accuracy_evaluation_methods/</link>
      <description><![CDATA[ML 社区您好， 我想了解人们如何在工作场所或个人用途中评估 LLM 的准确性。每个人都想采用法学硕士，但到目前为止我看到的用例在设置上都很相似。这是一个非常复杂的场景，所以我认为这对于志同道合的人来说是一个相互联系和分享想法的好机会。 本文为业界目前使用的一些 LLM 评估方法提供了不错的入门知识。 网络上的文章围绕以下内容进行讨论：以下指标：  ROUGE 分数、BLEU / BLEURT 分数、MAE 等。 自然语言推理（蕴涵）分数。 构建真实数据集，并比较答案的相关性、上下文的相关性和接地性（无论答案是否使用上下文）。 思想链和基本的自我评估，以检测和调节幻觉、情绪、语气、刻板印象和不准确的逻辑假设。 用户调查和用户反馈的机会，例如赞成/反对 UI。  最近有一些库，例如 Trulens、DeepEval 和 RAGAS 旨在解决 LLM 评估中存在的问题。但我想了解以下内容：  有人尝试任何新颖的方法来评估 LLM 的准确性吗？ 有没有人看过最近发布的旨在提供全面的利基论文评估聊天机器人的准确性尤其是没有地面真实数据集？大多数论文都是 2023 年末发表的，并使用一套相当严格的评估指标。  适当的背景：我在高等教育和教育科技数据科学领域工作。因此，准确性评估对于面向学生和面向员工的 LLM 用例至关重要。   由   提交 /u/Varunshou   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1caq0jy/d_llm_accuracy_evaluation_methods/</guid>
      <pubDate>Mon, 22 Apr 2024 23:48:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么选择 FID 而不是 ViT 模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1can2dg/d_why_fid_over_a_vit_model/</link>
      <description><![CDATA[标题基本上概括了这一点，但为什么我们要使用“更糟糕”的标题？计算图像距离的模型？我认为 ViT 模型能够更好地捕获图像之间的语义差异？   由   提交/u/Karan1213  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1can2dg/d_why_fid_over_a_vit_model/</guid>
      <pubDate>Mon, 22 Apr 2024 21:46:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有计算机视觉或机器人技术的实例级数据存储库？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1calk37/d_is_there_any_instancelevel_data_repository_for/</link>
      <description><![CDATA[通过实例级数据，我的意思是，如果我有一个数据集并用它评估两个模型，则不仅仅是报告平均准确度等聚合指标，数据将如下所示： 模型 1，图像 1：正确 模型 1，图像 2：失败 模型 2，图像 1：失败 模型 2，图像2：失败 对于语言模型和文本到文本或文本到图像任务，HELM 计划 (https://crfm.stanford.edu/helm/lite/latest/）出现了。 计算机视觉或机器人等其他领域有类似的东西吗？   由   提交/u/RF-Enthusiast   /u/RF-Enthusiast reddit.com/r/MachineLearning/comments/1calk37/d_is_there_any_instancelevel_data_repository_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1calk37/d_is_there_any_instancelevel_data_repository_for/</guid>
      <pubDate>Mon, 22 Apr 2024 20:47:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama-3 可能刚刚杀死了专有的人工智能模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</link>
      <description><![CDATA[完整博客文章  Meta 在三天前发布了 Llama-3，感觉开源模型终于缩小了与专有模型的差距，这已经是一个拐点。初始基准测试显示 Llama-3 70B 在许多任务中非常接近 GPT-4：  官方元页面仅显示Llama-3优于Gemini 1.5和Claude Sonnet。 人工分析显示 Llama-3 的质量介于 Gemini-1.5 和 Opus/GPT-4 之间。 关于 LMSYS 聊天机器人竞技场排行榜，Llama-3 排名第 5，而当前的 GPT-4 模型和 Claude Opus 仍并列第 1。  功能更强大Llama-3 400B+ 模型仍在训练中，发布后很可能超越 GPT-4 和 Opus。 Meta vs OpenAI 有人推测 Meta 从一开始的目标就是瞄准OpenAI 采用“焦土”方法，通过发布强大的开放模型来扰乱竞争格局并避免在竞争中落后AI 竞赛。 Meta 在计算和人才方面可能会超过 OpenAI：  OpenAI 的预计收入为 20 亿美元，并且可能无利可图。 2023 年，Meta 的收入为 $134B，利润为 $39B。 Meta 的计算资源目前可能超过 OpenAI。 开源可能会吸引更好的人才和研究人员。  &gt;  一个可能的结果是微软收购 OpenAI 以赶上 Meta。谷歌也在进军开放模型领域，并拥有与 Meta 类似的功能。看看它们适合什么位置将会很有趣。 获胜者：开发人员和人工智能产品初创公司 我最近写了一篇关于现在建立人工智能初创公司令人兴奋，因为您的产品会随着每个主要模型的进步而自动改进。随着 Llama-3 的发布，开发人员的机会更大：  不再受供应商锁定。 开发人员不仅可以封装专有 API 端点，还可以现在以一种非常经济高效且高性能的方式将人工智能深度集成到他们的产品中。 Hugging Face 上已经有超过 800 个 llama-3 模型变体，而且看起来每个人都能够针对他们的使用案例、语言或行业进行微调。 更快、更便宜的硬件：Groq 现在每秒可以生成 800 个 llama-3 代币，而成本只是 GPT 成本的一小部分。以低价提供近乎即时的 LLM 响应即将到来。  视觉和视频的开源多模式模型仍然需要迎头赶上，但我预计这很快就会发生。 Llama-3 的发布标志着人工智能民主化的一个重要里程碑，但现在宣布专有模型的消亡可能还为时过早。谁知道呢，也许 GPT-5 会让我们所有人感到惊讶，并超越我们对 Transformer 模型功能的想象。 这绝对是人工智能领域构建的超级激动人心的时代！    由   提交 /u/madredditscientist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</guid>
      <pubDate>Mon, 22 Apr 2024 15:08:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 循环记忆突破了 Transformer 神经网络的上下文长度限制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca6zvl/r_recurrent_memory_has_broken_the_limits_of/</link>
      <description><![CDATA[      研究人员对序列进行了分段，并向输入添加了特殊的记忆标记：来自输出的记忆状态上一段的数据成为下一段的输入。因此，整个变压器充当循环单元，而存储器充当网络的循环状态。这种方法被称为循环记忆变压器（RMT）。 作者用这种记忆增强了 BERT 和 GPT-2 等小型变压器模型，并在各种问答任务中对它们进行了测试，其中回答所需的事实位于文本。研究发现，使用循环记忆显着增加了输入序列的长度，同时保持令人满意的神经网络性能准确性。在他们的实验中，科学家们能够将这个值扩展到 200 万个代币。据作者称，该值进一步增加没有根本限制，因为 RMT 的计算复杂度随着令牌数量线性增长。 在三个任务上使用 RMT 增强的预训练 BERT 模型的准确性与输入序列中的标记数量的关系。灰色数字表示 GPU 内存消耗，垂直线表示 SOTA 模型的长度限制（截至 2023 年底） 该研究发表在 AAAI- 的会议记录上24 日会议上，预印本中提供了更多详细信息，代码可在预印本中找到。 com/booydar/recurrent-memory-transformer/tree/aaai24&quot;&gt;Gi​​tHub.   由   提交 /u/AIRI_Institute   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca6zvl/r_recurrent_memory_has_broken_the_limits_of/</guid>
      <pubDate>Mon, 22 Apr 2024 10:08:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>