<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Wed, 13 Mar 2024 00:57:29 GMT</lastBuildDate>
    <item>
      <title>[D] 我的免费 G​​enAI 课程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdd63f/d_my_free_genai_course/</link>
      <description><![CDATA[        由   提交 /u/MLRecipes   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdd63f/d_my_free_genai_course/</guid>
      <pubDate>Wed, 13 Mar 2024 00:12:13 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]：​​“Datasheets for Datasets”论文及其在现实世界中的相关性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdbuef/discussiondatasheets_for_datasets_paper_and_its/</link>
      <description><![CDATA[大家好， 我想发一篇文章来发起关于一篇名为 数据集数据表（&gt; 1900次引用，在研究界产生了很大影响） 。简而言之，本文讨论了缺乏记录数据集以训练机器学习模型的标准化方法，并建议使用“数据表”来记录数据集，类似于电子元件（或战锤无花果，或您通过数据表了解的任何其他项目）。作者用开源数据集的数据表原型示例（例如，LFW 数据集）说明了该数据表系统）。 IMO 附录中的示例可以快速传达整篇论文中表达的想法。因此，如果您不想花太多时间阅读本文，可以直接跳到原型。  在我之前攻读计算机视觉博士学位期间的经历以及目前担任人工智能工程师的经历中，我在使用同行或同事提供的数据集时一直遇到信息缺乏的情况。这通常导致我要么参与大量对话，要么执行临时脚本来收集对数据集特征的见解，例如其类分布或数据注释程序，以及这些选择背后的基本原理。这个信息检索过程需要重复多次，因为当然，第一次很可能会忽略某些方面。因此，我坚信“数据表”的引入最终会节省大量时间。数据表是一个看起来显然有益的想法。 因此，我对您对数据集文档的看法和经验感兴趣。 所以第一个问题，您愿意吗？知道数据集的任何标准文档程序或者您是否详细阐述过一个程序？如果是这样，您认为这些文档中哪些内容重要或无用？此文档中包含哪些内容？ AFAIK 我知道的唯一文档是“数据集卡”或“数据集卡”。 （或者更准确地说，一个简单的自述文件）或冗长的论文，这两个文档在您可以为读者编写的信息方面都非常宽松。 IMO 事情可能比这更容易。 对于那些读过这篇论文的人来说，第二个问题是：数据表的当前形式显然是一个经过修改以适合 PDF 的原型。 您将如何扩充该数据表？诸如交互式统计、源代码链接（例如在讨论预处理时），甚至简化字段之类的内容。我想像 Swagger 文档工具一样易于理解和交互，但适用于 ML 数据集。 第三个问题，与第二个问题相关：您对原始数据表提议有任何批评吗？我认为数据表中的一些字段应该与针对开发人员的主要文档分开，例如资金问题。 干杯！  ​   由   提交 /u/Barchimede   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdbuef/discussiondatasheets_for_datasets_paper_and_its/</guid>
      <pubDate>Tue, 12 Mar 2024 23:16:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 处理时间序列数据中的假期/事件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdb2li/d_treating_holidaysevents_in_time_series_data/</link>
      <description><![CDATA[大家好！ 我在一家生产零售销售模型（即单位）的公司工作。目前，该模型在“正常”或“一切照旧”期间表现良好，但在销售活动或其他节日活动期间表现不佳。后者低于预测——即销售活动导致销量增加。我有过去和未来的假期/销售活动的列表 - 是否有建议的方法来分析“纠正”或调整这些假期/销售活动的原始预测？ 预测是在日和商店级别进行的。公司拥有500多家门店。 感谢您的建议！   由   提交 /u/serpentna   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdb2li/d_treating_holidaysevents_in_time_series_data/</guid>
      <pubDate>Tue, 12 Mar 2024 22:44:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从头开始​​训练法学硕士的过程与训练较小的深度学习模型的过程之间的主要区别是什么，特别是在数据架构和训练流程方面？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bdami3/d_what_are_the_major_differences_specifically_in/</link>
      <description><![CDATA[当训练需要很多天的 LLM 时，用于存储嵌入和执行计算的管道可能与训练较小模型的过程有所不同，这些模型可能会在单 GPU 上运行。这是我的问题： 对于法学硕士， - 为训练较小模型和较大模型而生成的嵌入是否存在差异？  - 在多模态的情况下，嵌入的生成和存储有何变化？ - 纯文本模态的训练管道是什么样的？当谈到图像和音频时，训练管道有什么区别？  如果我能深入了解核心流程，我将不胜感激。谢谢！   由   提交 /u/metalvendetta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bdami3/d_what_are_the_major_differences_specifically_in/</guid>
      <pubDate>Tue, 12 Mar 2024 22:26:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] 现实世界 RAG 的法学硕士幻觉检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bd9gxr/p_llm_hallucination_detection_for_realworld_rag/</link>
      <description><![CDATA[大家好，我是 Jonathan，LastMile AI 的机器学习工程师。我们正在构建工具来评估生产中的法学硕士输出——特别是针对 RAG 应用。现在，我们专注于幻觉检测：给定 RAG 查询期间检索到的数据，响应是否忠实于该数据，还是幻觉？  这通常是通过模型评分大规模完成的：本质上，你向另一个 LLM（例如 GPT-4）提供问题、数据和回答，然后你会得到一个幻觉判决。 &gt; 我们研究了一些开源工具，例如 Arize 的 Phoenix，发现您可以通过更小（专业）的模型获得很高的准确性。  我们正在扩展对 v0 模型的早期访问，并有兴趣与任何需要帮助评估其生产 RAG 系统的人合作。  抢先体验：https://cdn.forms- content.sg-form.com/e8b9b4d4-dda0-11ee-85ff-daa2c5cfc593  详细信息：https://blog.lastmileai.dev/harder-better-faster-stronger-llm-hallucination-detection-for- real-world-rag-part-i-949248f0ad94   由   提交 /u/InevitableSky2801   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bd9gxr/p_llm_hallucination_detection_for_realworld_rag/</guid>
      <pubDate>Tue, 12 Mar 2024 21:40:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 克隆 git repo Huggingface 中耳语 AI 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bd89of/d_cloning_git_repo_huggingface_medium_model_of/</link>
      <description><![CDATA[我对这一切不是很有经验，但我目前正在尝试从这里克隆 git 存储库：  https://huggingface.co/openai/whisper-medium 我的 git bash 窗口给了我以下内容，但现在只是挂起，没有进度指示器 $ git clone https://huggingface.co/openai/whisper-medium 克隆到“whisper-medium”... 远程：枚举对象：175，完成。 远程：计数对象：100% (6/6)，完成。 p&gt; 远程：压缩对象：100% (6/6)，完成。 远程：总共 175 个（增量 1），重用 0 个（增量0)，包重用 169 s：99% (174/175)，2.75 MiB | 354.00 KiB/s 接收对象：100% (175/175)，2.88 MiB | 297.00 KiB/s，完成。 解析增量：100% (102/102)，完成。 创建的文件夹保留大小为 4.37MB，但我的网络流量告诉我到目前为止我已经下载了 5GB... 它去哪儿了？什么时候能完成？？？我以为中等型号的大小约为 3GB... 完全困惑！   由   提交 /u/AudioBabble   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bd89of/d_cloning_git_repo_huggingface_medium_model_of/</guid>
      <pubDate>Tue, 12 Mar 2024 20:53:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 优化 (2+1)D ResNet 以进行事件索引</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bd7ejh/d_optimising_a_21d_resnet_for_event_indexing/</link>
      <description><![CDATA[我正在开发一个 (2+1)D resnet，用于视频数据的对象检测、事件分类和事件索引。目前，我在第一次迭代中拥有的唯一功能是每帧的像素值。我还收集了其他特征，例如纹理、光流、运动向量、颜色直方图和每帧的边缘。 我的主要问题是如何将所有特征融合为模型的输入，但我也有兴趣听听是否有人对此有任何意见，或者我如何改进我的模型。 模型架构基于以下论文： &lt; a href=&quot;https://arxiv.org/pdf/1711.11248v3.pdf&quot;&gt;https://arxiv.org/pdf/1711.11248v3.pdf   由   提交/u/RxPiku  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bd7ejh/d_optimising_a_21d_resnet_for_event_indexing/</guid>
      <pubDate>Tue, 12 Mar 2024 20:19:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习面试倦怠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bd5hh4/d_ml_interview_burnout/</link>
      <description><![CDATA[我觉得我因数据科学面试而精疲力尽。我在该领域担任数据科学家已有 5 年了。这个领域有很多技术性的东西。尤其是在2023年，关于如何优化LLM模型和向量DB的使用的新论文层出不穷。我花在面试准备上的时间越多，我用来获取新知识的时间就越少。我应该怎么做才能克服这种情况？非常感谢。 为什么我觉得面试准备没有什么用 在实际工作中，我们可以针对一个话题进行不同的准备来回忆所有的内容。在向其他同事展示想法之前，先记忆并正确组织概念。然而，是否可以在采访过程中立即调取所有信息呢？有些知识可以追溯到学校课本上，几十年来一直没有人接触过。有些问题涉及不太常见的设计模式。当我无法回答一个问题时，我会感到难过，不是因为我不知道，而是因为我确实无法在短时间内总结出来。这就像数据被存档到AWS S3冰川一样，因此数据检索既耗时又昂贵。另外，不能回答一些代码设计模式并不意味着我不能写出好的代码并解决问题。为了准备这些面试，我尝试重新审视一些关键概念和各种不太有用的代码模式，但这非常耗时。老实说，这些工作的工资确实很高。我不是在谈论任何大型科技公司，而是在谈论一些中小企业。我对标准感到困惑。   由   提交 /u/MillionLiar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bd5hh4/d_ml_interview_burnout/</guid>
      <pubDate>Tue, 12 Mar 2024 19:03:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有针对应用研究的非技术同行评审期刊？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcqoa7/d_are_there_non_technical_peer_reviewed_journals/</link>
      <description><![CDATA[我今天正在看这篇论文 https://arxiv.org/abs/2403.04769 我缺乏发表纯理论机器学习论文的知识（也没有时间和精力真正深入该领域并赶上产生有意义的输出的水平）但我认为我有一些想法，并且有兴趣以发现漏洞的形式进行研究，或者以新颖的方式比较法学硕士或模型等。需要丰富的理论背景，并且具有不同技能的人更容易涉足其中。  与此同时，尽管我是一个完全不同领域的学者，但为了我的职业生涯，我需要在期刊上发表论文，而不仅仅是在 arxiv 上。所以我的问题是，像我上传的论文在实践中当然非常有用，但从科学角度讲，它们是否会在同行评审期刊上发表？如果是，在哪里？ 有兴趣听听您的想法和建议，提前致谢！   由   提交 /u/Dyoakom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcqoa7/d_are_there_non_technical_peer_reviewed_journals/</guid>
      <pubDate>Tue, 12 Mar 2024 06:41:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人可以澄清一下像 Perplexity、You.com 或 Coral Search 这样的网络搜索法学硕士是否正在自己抓取整个网络吗？否则，它们与简单地将搜索 API 与任何 LLM 模型结合起来有何不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcq8zy/d_can_someone_please_clarify_if_web_search_llms/</link>
      <description><![CDATA[如果他们自己爬行网​​络，有经验的人能否解释一下这项任务有多困难以及这些公司如何彼此区分，我看不到他们每个人提供的答案有多大差异？   由   提交/u/Fit-Set6851  /u/Fit-Set6851 reddit.com/r/MachineLearning/comments/1bcq8zy/d_can_someone_please_clarify_if_web_search_llms/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcq8zy/d_can_someone_please_clarify_if_web_search_llms/</guid>
      <pubDate>Tue, 12 Mar 2024 06:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]扩散模型有表示学习吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcmvo1/discussion_do_diffusion_models_do_any/</link>
      <description><![CDATA[诸如 VAE 和基于转换器的语言模型（MLM 或自回归）之类的模型提取数据的高阶表示。对于DM是否这样做有任何了解吗？我见过的论文中似乎没有讨论这个问题，大概是因为重点太集中在生成方面。   由   提交/u/daking999  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcmvo1/discussion_do_diffusion_models_do_any/</guid>
      <pubDate>Tue, 12 Mar 2024 03:08:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 作为可优化图的语言代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bchke2/r_language_agents_as_optimizable_graphs/</link>
      <description><![CDATA[ 由   提交/u/hardmaru  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bchke2/r_language_agents_as_optimizable_graphs/</guid>
      <pubDate>Mon, 11 Mar 2024 23:10:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] Gemini 1.5 Pro如何回忆10M上下文中的信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</link>
      <description><![CDATA[Google 最近发布了技术报告 关于 Gemini 1.5 Pro 及其 10M 上下文。他们简要概述了提高模型长上下文能力的现代方法（例如循环记忆、环形注意力、新颖的架构等），但我没有找到有关 Gemini 1.5 Pro 方法的信息。 有人注意到官方出版物中有关他们方法的信息吗？这对我来说似乎是 Google 的秘密。   由   提交/u/Mulated-Witness-7196   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</guid>
      <pubDate>Mon, 11 Mar 2024 12:26:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] ShortGPT：大型语言模型中的层比您预期的更加冗余</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.03853 摘要：  随着大型语言模型（LLM）的性能不断进步，它们的规模显着扩大，当前的法学硕士包含数十亿甚至数万亿的参数。然而，在这项研究中，我们发现LLM的许多层表现出高度相似性，并且某些层在网络功能中发挥的作用可以忽略不计。基于这一观察，我们定义了一个名为区块影响力 (BI) 的指标来衡量法学硕士中每一层的重要性。然后，我们提出了一种直接的修剪方法：层删除，其中我们根据 LLM 的 BI 分数直接删除其中的冗余层。实验表明，我们的方法（我们称之为 ShortGPT）在模型剪枝方面显着优于之前最先进的 (SOTA) 方法。此外，ShortGPT 与类量化方法正交，可以进一步减少参数和计算量。与更复杂的修剪技术相比，通过简单的层删除可以获得更好的结果，这表明模型架构中存在高度冗余。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</guid>
      <pubDate>Mon, 11 Mar 2024 11:41:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>