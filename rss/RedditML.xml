<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 31 Dec 2023 06:16:08 GMT</lastBuildDate>
    <item>
      <title>[D] 机器人人工智能的项目想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18v16sk/d_project_ideas_for_ai_in_robotics/</link>
      <description><![CDATA[我想为机器人行业构建一个端到端的 AI/ML 项目。  我正在考虑一些与计算机视觉相关的问题，但不确定可以解决什么问题。   由   提交/u/Snoo_72181   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18v16sk/d_project_ideas_for_ai_in_robotics/</guid>
      <pubDate>Sun, 31 Dec 2023 06:11:56 GMT</pubDate>
    </item>
    <item>
      <title>[P]从数学角度谈机器学习的论文题目思路</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uyqeb/p_essay_topic_ideas_about_machine_learning_from_a/</link>
      <description><![CDATA[ 由   提交/u/zen_bud  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uyqeb/p_essay_topic_ideas_about_machine_learning_from_a/</guid>
      <pubDate>Sun, 31 Dec 2023 03:58:21 GMT</pubDate>
    </item>
    <item>
      <title>[p] 我培训了一名法学硕士来教我更好地编码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uxz56/p_i_trained_an_llm_to_teach_me_to_code_better/</link>
      <description><![CDATA[正如你们中的一些人可能已经经历过的那样，GitHub Co-Pilot 是一种糟糕的学习方式，但我想看看是否有我想要的东西可以做一些编码教育方面的法学硕士。 在向公众提供它之前，我想看看人们对此有何看法。 演示：https://youtu.be/Z1rZZkL4PFA?si=-cYcKeh9FkLzBUp3   由   提交/u/AggressiveHunt2300   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uxz56/p_i_trained_an_llm_to_teach_me_to_code_better/</guid>
      <pubDate>Sun, 31 Dec 2023 03:18:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 GPT4 视觉进行 OCR 的一些实际结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uvrwj/p_some_practical_results_from_using_gpt4_vision/</link>
      <description><![CDATA[您好，不太确定将其发布到哪里，所以我会在这里尝试。人们对 GPT4 愿景有很多兴奋，但当在实际项目的一些真实数据上进行尝试时，却缺乏这种感觉。它有时会产生幻觉，或者拒绝执行任务，而且准确性并不比 Tesseract 好多少。然而，如果两者结合起来，事情就会变得非常好。更多详细信息和源数据请访问以下链接。 https://pslusarz.github.io/articles/2023/12/22/compare-ocr-tesseract-gpt4-nara-rolls.html   由   提交/u/wuj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uvrwj/p_some_practical_results_from_using_gpt4_vision/</guid>
      <pubDate>Sun, 31 Dec 2023 01:30:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 15亿参数的多模态聊天</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ut3lm/p_multimodal_chat_in_15_billion_parameters/</link>
      <description><![CDATA[   /u/ashvar  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ut3lm/p_multimodal_chat_in_15_billion_parameters/</guid>
      <pubDate>Sat, 30 Dec 2023 23:30:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 带有语音训练功能的本地 TTS 软件支持 AMD GPU 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18urbw5/d_local_tts_software_with_voice_training_that/</link>
      <description><![CDATA[有人知道可以在具有 AMD GPU 的本地计算机上运行的任何不错的文本转语音软件吗？ 到目前为止，我已经一直在使用Descript，那个相当不错，但是语音选择非常有限，而且需要订阅。我尝试过在本地计算机上运行类似的东西，但只找到了适用于 Nvidia Cuda 的东西。 我使用的是 AMD 6650XT，升级到 Nvidia 不是一个选择，甚至最便宜的“还可以”在我所在的地区，Nvidia 级卡的售价为 400 欧元，所以想知道是否有人知道任何可以在 AMD 卡上运行的工具，特别是可以选择从音频样本中训练您自己的 AI 配音声音？ 到目前为止尝试过 RVCv2， Mangio RVC、Apollio RVCv2 还研究了 Coqui TTS 和 Tortoise TTS，它们都满足我的需要，但都需要 Nvidia Cuda 才能工作。 Mangio RVC 是最成功的，允许使用“ ;几乎”所有功能，但如果没有 Cuda，特别是训练部分将无法工作。  如有任何建议，我们将不胜感激。   由   提交 /u/Cyber​​punkLover   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18urbw5/d_local_tts_software_with_voice_training_that/</guid>
      <pubDate>Sat, 30 Dec 2023 22:14:50 GMT</pubDate>
    </item>
    <item>
      <title>[R]《认知架构40年：核心认知能力与实际应用》（2018）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uqy29/r_40_years_of_cognitive_architectures_core/</link>
      <description><![CDATA[论文：https://link.springer.com/article/10.1007/s10462-018-9646-y 预印本版本 ：https://arxiv.org/abs/1610.08602 项目页面 （交互式可视化和完整参考书目）：http://jtl.lassonde.yorku.ca/project/cognitive_architectures_survey/ 摘要：  在本文中，我们对过去 40 年的认知架构研究进行了广泛的概述。迄今为止，现有架构的数量已达到数百个，但大多数现有调查并没有反映这种增长，而是集中在少数成熟的架构上。在这项调查中，我们的目标是对认知架构的研究提供更具包容性和更高层次的概述。我们最终的 84 种架构包括 49 种仍在积极开发中的架构，它们借鉴了从精神分析到神经科学等多种学科的知识。为了将本文的长度保持在合理的范围内，我们仅讨论核心认知能力，例如感知、注意机制、行动选择、记忆、学习、推理和元推理。为了评估认知架构实际应用的广度，我们提供了使用列表中的认知架构实施的 900 多个实际项目的信息。我们使用各种可视化技术来突出该领域发展的整体趋势。除了总结当前认知架构研究的最新进展之外，本次调查还描述了已经尝试过的各种方法和想法及其在模拟人类认知能力方面的相对成功，以及认知行为的哪些方面需要对其机械对应物进行更多研究，从而进一步了解认知科学如何进步。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uqy29/r_40_years_of_cognitive_architectures_core/</guid>
      <pubDate>Sat, 30 Dec 2023 21:58:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2023年十大值得关注的人工智能研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18unlno/p_ten_noteworthy_ai_research_papers_of_2023/</link>
      <description><![CDATA[       由   提交/u/seraschka  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18unlno/p_ten_noteworthy_ai_research_papers_of_2023/</guid>
      <pubDate>Sat, 30 Dec 2023 19:32:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 动量和批量大小</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uh79r/d_momentum_and_batch_size/</link>
      <description><![CDATA[更大的批量大小可以显着改善训练过程。显然，即使我们愿意牺牲每次梯度更新的计算量来增加批量大小，在某些时候 GPU 内存也是有限的。直观上，使梯度更稳定的另一种方法是增加动量。 是否有人有过这样的实际经验：您希望拥有更多 GPU 内存来增加批量大小，但又无法做到这一点？ t，然后利用动量来稳定梯度，从而改善训练过程？   由   提交 /u/felixcra   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uh79r/d_momentum_and_batch_size/</guid>
      <pubDate>Sat, 30 Dec 2023 14:47:51 GMT</pubDate>
    </item>
    <item>
      <title>目前命名实体识别和提取的Sota是多少？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ugt3d/what_is_the_current_sota_on_named_entity/</link>
      <description><![CDATA[命名实体识别和提取的最新技术是什么？   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ugt3d/what_is_the_current_sota_on_named_entity/</guid>
      <pubDate>Sat, 30 Dec 2023 14:28:16 GMT</pubDate>
    </item>
    <item>
      <title>【项目】时间增强检索（TAR）-动态RAG</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uddmj/project_temporal_augmented_retrieval_tar_dynamic/</link>
      <description><![CDATA[      从文本语料库中，如何检测新出现的主题并它们随时间的演变？ 介绍时间增强检索 (TAR)。 （在 buildspace n&amp;w s4 的背景下构建） TAR 是一种开源的高级 RAG 方法，旨在在执行检索时考虑文本数据的动态和时间方面。 &lt; p&gt;它使我们能够了解所讨论的主题随时间的演变。 该项目背后的想法是开启有关 RAG 方法当前局限性的辩论 第一种方法没有使用 RAG 框架（如 Jerry Liu 的 langchain）构建，专注于金融推文  相关链接： Medium：https://medium.com/@adam-rida/temporal-augmented-retrieval-tar-dynamic-rag-ad737506dfcc&lt; /p&gt; Github：https://github.com/adrida/Temporal_RAG 拥抱脸基准：https://huggingface.co/spaces/Adr740/Temporal-RAG-Benchmark 我的网站：adrida.github.io ​  https://preview.redd.it/lj7wkhk70f9c1.png？ width=960&amp;format=png&amp;auto=webp&amp;s=fc79c5034351a1711e1ec051919a​​5c4d2edbc333   由   提交/u/Adr-740  /u/Adr-740  reddit.com/r/MachineLearning/comments/18uddmj/project_temporal_augmented_retrieval_tar_dynamic/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uddmj/project_temporal_augmented_retrieval_tar_dynamic/</guid>
      <pubDate>Sat, 30 Dec 2023 11:08:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] InfoSHAP：用信息论 Shapley 值解释预测不确定性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ud5zn/r_infoshap_explaining_predictive_uncertainty_with/</link>
      <description><![CDATA[论文标题：用信息理论 Shapley 值解释预测不确定性 发表于&lt; /strong&gt;：NeurIPS 2023 论文链接：https://arxiv.org/ abs/2306.05724 代码链接：https://github.com /facebookresearch/infoshap tl;dr：这篇论文以一种可以用来解释模型预测而不是模型本身的不确定性的方式扩展了 SHAP预测本身。这可能有多种应用，例如：  在主动学习应用中，采样决策是基于预测不确定性（如 BatchBALD 等现代方法中的情况）做出的，以回答诸如“为什么”之类的问题我们是否决定注释这个特定实例？”。  在强化学习应用中，探索内容的决策是由好奇心驱动并基于奖励的不确定性。在此设置中，它可用于解释“为什么我们的智能体以这种方式进行探索？” 关于特征选择、主动特征值获取、协变量移位的解释的其他一些应用论文中重点介绍了可解释人工智能领域的研究人员开发了多种方法来帮助用户了解复杂监督学习模型的预测。相比之下，解释模型输出的不确定性受到的关注相对较少。我们采用流行的 Shapley 值框架来解释各种类型的预测不确定性，量化每个特征对单个模型输出的条件熵的贡献。我们考虑具有修改后的特征函数的博弈，并从信息论和条件独立性测试中找到所得的沙普利值与基本量之间的深层联系。我们概述了具有可证明保证的有限样本错误率控制的推理程序，并实现了一种有效的算法，该算法在真实和模拟数据的一系列实验中表现良好。我们的方法可应用于协变量偏移检测、主动学习、特征选择和主动特征值获取。   由   提交 /u/TaXxER   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ud5zn/r_infoshap_explaining_predictive_uncertainty_with/</guid>
      <pubDate>Sat, 30 Dec 2023 10:55:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] Stability AI 会成为第一个在 2024 年破产的生成型 AI 独角兽吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uclmy/d_will_stability_ai_be_the_first_generative_ai/</link>
      <description><![CDATA[   /u/milaworld  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uclmy/d_will_stability_ai_be_the_first_generative_ai/</guid>
      <pubDate>Sat, 30 Dec 2023 10:16:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习领域 CS 博士对于顶尖项目的竞争力（24 秋季）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uajqj/d_competitiveness_of_cs_phd_in_ml_for_top/</link>
      <description><![CDATA[我最近在其他地方读到一篇文章，声称今年顶尖机构的 ML 领域的 CS 博士招生竞争变得异常激烈。根据该帖子，对于美国排名前 20 的大学，只有在 ICML/NeurIPS/ICLR 上至少发表三篇第一作者论文的人才有机会，并且如果满足以下条件，则需要超过三篇论文：你的论文没有在这三个地点发表。他们还声称，对于排名前 50 的大学，您至少需要在 ICML/NeurIPS/ICLR 发表一篇第一作者论文才能被考虑。 我知道，进入顶尖博士课程的竞争非常激烈。 ML，但我发现这个信息非常可疑，因为我认为甚至不会有那么多申请者在 ICML/NeurIPS/ICLR 博士前至少拥有三篇论文。我个人认识一些顶尖大学的博士生，他们中的很多人在申请时都达不到这样的标准。但这个周期可能非常不同，并且变得特别有竞争力。 如果他们的说法确实属实，我认为我们当前的学术体系和出版文化可能存在更大的问题。  p&gt; 我将其发布在 r/MachineLearning 上，稍后我会将其交叉发布到 r/gradadmissions 在我弄清楚如何做到这一点之后。  &amp;# 32；由   提交 /u/zhxch   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uajqj/d_competitiveness_of_cs_phd_in_ml_for_top/</guid>
      <pubDate>Sat, 30 Dec 2023 07:59:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>