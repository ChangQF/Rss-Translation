<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 12 Jun 2024 01:04:22 GMT</lastBuildDate>
    <item>
      <title>[D] 拥有 ML/AI 博士学位会限制你从事哪些类型的工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddua2b/d_what_kind_of_jobs_do_a_phd_in_mlai_restrict_you/</link>
      <description><![CDATA[我已经看到很多关于博士学位如何可能或不可能帮助你获得特定 X 工作机会的帖子。 但我很好奇，获得博士学位是否实际上会限制你从事某些工作，因为雇主认为你资历过高、你太老了，或者你缺乏生产 YOE 等。    提交人    /u/Confident_Ad_7734   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddua2b/d_what_kind_of_jobs_do_a_phd_in_mlai_restrict_you/</guid>
      <pubDate>Wed, 12 Jun 2024 01:01:13 GMT</pubDate>
    </item>
    <item>
      <title>在 AI 性能评估中，准确度是与硬件无关的指标还是伪硬件无关的指标？[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddrvby/is_accuracy_a_hardwareagnostic_metric_or/</link>
      <description><![CDATA[我认为准确度是伪硬件不可知的。虽然有些评估论文认为准确度的定义与硬件无关，而与例如 VRAM 使用率等硬件相关指标相比则不然。但与参数量等模型特性相比，准确度需要在硬件上进行验证，您可以很好地尝试通过这些特性来预测 AI 的性能。参数量不需要在硬件上进行检查才能测量，它只是 AI 模型的固有特性。由于不同的设备不同，准确度也会不同。（NPU、浮点运算效率、内存、其他瓶颈……） 这是我的看法。我很困惑为什么论文经常将准确度称为硬件不可知的。    提交人    /u/Sweaty_Butterfly_516   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddrvby/is_accuracy_a_hardwareagnostic_metric_or/</guid>
      <pubDate>Tue, 11 Jun 2024 23:04:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何防止 GPT-4 上的脱离上下文的查询</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddr704/d_how_to_prevent_out_of_context_queries_on_gpt4/</link>
      <description><![CDATA[大家好， 我们有一个应用程序，它通过应用程序直接向我们的客户公开 GPT-4。我们希望确保它仅用于提供的上下文。我们不希望它在上下文是关于如何安全运送零件时能够回答有关蝙蝠侠的问题。有没有可以帮助我们做到这一点的库或模型？谢谢！    提交人    /u/MuscleML   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddr704/d_how_to_prevent_out_of_context_queries_on_gpt4/</guid>
      <pubDate>Tue, 11 Jun 2024 22:33:37 GMT</pubDate>
    </item>
    <item>
      <title>寻找对其 AI 输出评估不准确的论文 [P] [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddqfxa/looking_for_a_paper_with_inaccurate_evaluation_of/</link>
      <description><![CDATA[这可能是由于方法论缺陷、对结果的误解或不适当的评估指标造成的。谢谢！    提交人    /u/RandomXMR   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddqfxa/looking_for_a_paper_with_inaccurate_evaluation_of/</guid>
      <pubDate>Tue, 11 Jun 2024 22:00:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在审查时改进模型的内部运作是否不明智？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddjyx0/d_is_it_inadvisable_to_improve_the_internal/</link>
      <description><![CDATA[我向 NeurIPS 提交了一篇论文，其中的模型使用了 mamba 块。然而，在将稿件提交给 openreview 之前，我已经想到了一些可以尝试改进结果的调整或想法。现在，在 mamba-2 最近发布之后，这种情况更加明显，因为正如新论文中所述，一些微小的变化可以提高我的模型的性能和速度。 出于这些原因，自提交之日起，我一直在考虑研究一些旧想法，并尝试更新的 mamba 块；尽管如此，我担心这可能会让已经阅读过一个版本论文的审阅者感到困惑，我猜他们希望讨论旧版本的模型。也许改变这么多东西可能会让他们有点困惑，甚至恼火。 另一方面，我真的认为我至少可以改进一些指标，即使我被取消参加这次会议，我也愿意取得这些改进，尝试参加另一次会议。 在这种情况下你会怎么做？    提交人    /u/SrPinko   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddjyx0/d_is_it_inadvisable_to_improve_the_internal/</guid>
      <pubDate>Tue, 11 Jun 2024 17:34:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用平方误差而不是绝对误差？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddjbdi/why_use_squared_error_instead_of_absolute_error_d/</link>
      <description><![CDATA[我不明白为什么当错误 = 0 时得到未定义的偏导数会是一个大问题，我的意思是得到零错误不是我们从一开始就想要的吗？    提交人    /u/NeatJealous8110   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddjbdi/why_use_squared_error_instead_of_absolute_error_d/</guid>
      <pubDate>Tue, 11 Jun 2024 17:07:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您在使用 LLM 创建机器学习训练数据方面学到了什么经验教训？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddj561/d_what_are_the_lessons_you_learned_in_using_llms/</link>
      <description><![CDATA[大型语言模型 (LLM) 的广泛可用性和性能使从业者能够自动执行各种耗时的任务。获取机器学习训练数据集的大量质量标签是监督学习中的关键步骤，但手动生成可能需要大量时间。 https://opendatascience.com/trial-error-triumph-lessons-learned-using-llms-for-creating-machine-learning-training-data/    提交人    /u/Data_Nerd1979   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddj561/d_what_are_the_lessons_you_learned_in_using_llms/</guid>
      <pubDate>Tue, 11 Jun 2024 17:00:40 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 从 keras.optimizers.optimizer 访问和使用损失函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddizyz/discussion_accessing_and_using_the_loss_function/</link>
      <description><![CDATA[我目前正在研究一个优化器想法，它依赖于在参数更新函数期间多次计算损失，但我找不到有关此的任何文档......这里的任何人都知道做这样的事情的方法    提交人    /u/ihaveagoodusername2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddizyz/discussion_accessing_and_using_the_loss_function/</guid>
      <pubDate>Tue, 11 Jun 2024 16:54:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人参加 CVPR 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddirmi/d_anybody_attending_cvpr/</link>
      <description><![CDATA[这是我第一次参加 CVPR，所以想结识新朋友，一起出去玩，交流研究想法。有什么好的研讨会和教程可以参加吗？请告诉我。    提交人    /u/Deep-Inevitable-1977   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddirmi/d_anybody_attending_cvpr/</guid>
      <pubDate>Tue, 11 Jun 2024 16:45:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024年机器学习研究的热门话题是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddhu8n/d_what_are_the_hot_topics_in_machine_learning/</link>
      <description><![CDATA[今年，哪些子领域/方法、应用领域有望在学术界或工业界获得广泛关注（无意双关）？ PS：请不要羞于提出您认为或知道的任何可能是 ML 中流行的研究主题，您所知道的内容很可能对我们中的许多人来说相对不为人知：)    提交人    /u/knut_2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddhu8n/d_what_are_the_hot_topics_in_machine_learning/</guid>
      <pubDate>Tue, 11 Jun 2024 16:06:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] rerank-ts：使用 LLM 对搜索结果进行重新排序的 TypeScript 库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddhog4/p_rerankts_typescript_library_for_reranking/</link>
      <description><![CDATA[宣布推出一个 TypeScript 库，用于对来自向量数据库或全文搜索索引的搜索结果进行重新排名。重新排名是构建 RAG 应用程序检索中非常重要的一个步骤。它几乎可以立即提高 LLM 响应合成的准确性，因为您能够输入更准确、更相关的上下文。为什么？因为虽然语义或全文搜索系统旨在快速获取语义或词汇上接近的文档块，但它们不会根据用户查询的意图对块进行排名。这就是重新排名器的作用所在。 代码 - https://github.com/tensorlakeai/rerank-ts  我们为什么要构建它？ 我们找不到一个独立于框架的 Typescript 重新排名库。我们还希望轻松交换模型和算法，发布并密切跟踪延迟指标。我们实现了两种不同的重新排名算法 -   基于 LLM 的重新排名：它使用论文中提出的算法 - “ChatGPT 擅长搜索吗？” https://arxiv.org/abs/2304.09542 - 他们实现了基于滑动窗口的算法来重新排名搜索结果，这些搜索结果可能比 LLM 的上下文长度更大。我们增加了对 LLama3 和 GPT-4 的支持。对于 Llama3，我们使用 Groq，但可以轻松添加其他模型提供程序。  相互排序融合 - 一种轻量级算法，用于合并来自多个索引的搜索结果，同时保留它们的相对重要性。  我们最近构建了一个消费者应用程序，该应用程序使用 Indexfiy (https://getindexfiy.ai) 对 1000 个图像中的 100 个进行索引，该应用程序对图像的各个方面进行索引 - 标题（使用文本嵌入模型）、视觉描述（使用 VLM）、CLIP 嵌入。在检索过程中，我们根据用户查询从每个索引中查找 40 个图像，然后使用此库对结果进行重新排名。与根本不重新排名相比，结果确实令人惊叹。 延迟 - 对于与人类交互的应用程序来说，延迟是一个大问题，根据我们的经验，Groq 上的 LLama3 8B 是最快的 LLM 重新排名器。它们每秒能够处理约 1000 个 token。我们能够在大约 1.4 秒内对 100 张图像进行重新排名。我们还没有尝试在生产中使用 GPT4，以便能够分享任何与延迟相关的数字。 选择模型 - 选择在延迟与准确度之间取得最佳平衡的模型。有许多较小的重新排名模型可用 - Jina AI、BGE、Sentence Transformers 等。我们也听说过关于 Cohere 重新排名器的好评。我们希望在未来增加对更多模型的支持。该库有一个干净的模型提供程序界面，因此欢迎贡献！    提交人    /u/diptanuc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddhog4/p_rerankts_typescript_library_for_reranking/</guid>
      <pubDate>Tue, 11 Jun 2024 15:59:46 GMT</pubDate>
    </item>
    <item>
      <title>[N] YaFSDP 与 FSDP 在 LLM 培训中的比较：真正的进步？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ddc1uf/n_yafsdp_vs_fsdp_for_llm_training_real_improvement/</link>
      <description><![CDATA[在 Yandex，我们开发了 FSDP 的增强版本，称为 YaFSDP，与 FSDP 相比，它在 LLM 训练时间上表现出高达 26% 的惊人速度提升，并且节省了大量 GPU 资源。例如，在涉及具有 700 亿个参数的模型的预训练场景中，使用 YaFSDP 可以节省大约 150 个 GPU 的资源，这意味着每月可以节省大约 50 万美元到 150 万美元（取决于虚拟 GPU 提供商或平台）。  YaFSDP 是开源的，所以我们迫不及待地想听到您的反馈，看看您如何在工作中实现它！ https://github.com/yandex/YaFSDP     提交人    /u/azalio   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ddc1uf/n_yafsdp_vs_fsdp_for_llm_training_real_improvement/</guid>
      <pubDate>Tue, 11 Jun 2024 11:41:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语音研究是否陷入困境？语音应用的下一个重大突破是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dd8cbs/d_is_speech_research_hitting_a_wall_what_could_be/</link>
      <description><![CDATA[我觉得，与 NLP（LLM 中的安全/对齐等）和 CV（文本到图像/视频、机器人规划等，仅举几例）相比，语音应用的前景似乎不那么令人兴奋。 它的主要工作似乎只是将语音转录为文本，然后让 LLM 完成那些神奇的事情。 当然，它可以合成逼真的声音（例如 GPT-4o 中的演示）或其他应用程序，但语音似乎很难在未来再次成为关键角色。 就可能的研究方向而言，语音应用的下一个大事件是什么？    提交人    /u/xiikjuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dd8cbs/d_is_speech_research_hitting_a_wall_what_could_be/</guid>
      <pubDate>Tue, 11 Jun 2024 07:29:44 GMT</pubDate>
    </item>
    <item>
      <title>对 TMLR 及学术界其他新兴/小众场所的看法 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dd76xy/perception_of_tmlr_and_other_newniche_venues_in/</link>
      <description><![CDATA[今年冬天我将申请研究生院，到目前为止，我只在理论深度学习领域获得了一篇论文，它被发表在《机器学习研究汇刊》（TMLR）上。我不想解释为什么我在那里发表文章，但本质上，我的导师鼓励我们在那里发表文章。尽管评论非常轻松和有见地，但我担心（理论）学术界对 TMLR 的看法并不那么好。我和几位教授谈过，他们似乎都问我为什么在这样一个奇怪的场所发表文章，我真的很担心 GradApp 委员会对这项工作产生一些怀疑。这项工作本身很可爱，虽然不是什么了不起的事情，但解决了一些著名作者在一篇旧论文中提出的问题之一，我对我的工作感到非常自豪，但我觉得委员会可能不会这么认为。我很想知道全职学者对 TMLR 等场所的看法。    由    /u/filletedforeskin  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dd76xy/perception_of_tmlr_and_other_newniche_venues_in/</guid>
      <pubDate>Tue, 11 Jun 2024 06:09:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>