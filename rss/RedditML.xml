<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Mon, 08 Apr 2024 09:14:17 GMT</lastBuildDate>
    <item>
      <title>[R] 用于高性能语言技术的新的海量多语言数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byt3j8/r_a_new_massive_multilingual_dataset_for/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.14009 项目页面：https://hplt -project.org/ 数据集：https:// /hplt-project.org/datasets/v1.2 GitHub： https://github.com/hplt-project 摘要：  我们介绍HPLT（高性能语言技术）语言资源，一个新的大规模多语言数据集，包括从 CommonCrawl 中提取的单语和双语语料库以及从互联网档案馆中提取的以前未使用的网络爬虫。我们描述了大型语料库的数据采集、管理和处理方法，这些方法依赖于开源软件工具和高性能计算。我们的单语集合侧重于中低资源语言，涵盖 75 种语言，并在文档级别删除了总共约 5.6 万亿个单词标记。我们以英语为中心的平行语料库源自其单语对应语料库，涵盖 18 个语言对和超过 9600 万个对齐句子对，以及大约 14 亿个英语标记。 HPLT 语言资源是迄今为止发布的最大的开放文本语料库之一，为语言建模和机器翻译培训提供了丰富的资源。我们公开发布了这项工作中使用的语料库、软件和工具。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byt3j8/r_a_new_massive_multilingual_dataset_for/</guid>
      <pubDate>Mon, 08 Apr 2024 08:56:19 GMT</pubDate>
    </item>
    <item>
      <title>[P][D]如何增加指定项目的难度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byqglm/pd_how_to_increase_the_difficulty_of_a_specified/</link>
      <description><![CDATA[大家好！我正在做一个专注于检测图像中的白内障的项目，使用Vision Transformer作为主要架构，如果性能不好我可能会结合其他架构。数据集来自 Kaggle，经过最少的预处理。 我的目标是将模型的准确率提高到 80% 左右（现在是 26%，模型什么也没学到），并进行实验来比较不同条件下的结果。配置。我会把这个项目添加到我的简历中。 我个人认为这个项目的亮点是什么：  使用 PyTorch 从 0 到 1 解决问题&lt; /p&gt; 使用 ViT 架构 设计实验 一些技巧例如数据参数、批量归一化，用于训练以提高性能和准确性。  我是自学成才的，不幸的是，我的大学不提供实质性支持在 CV/DL 领域，缺乏专门的实验室和教师专业知识。有人可以提供建议来提高我的项目的复杂性和价值，从而成为我简历的有力支持吗？任何对我的职业道路有益的指导也将不胜感激！！！   由   提交/u/Keahi_xie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byqglm/pd_how_to_increase_the_difficulty_of_a_specified/</guid>
      <pubDate>Mon, 08 Apr 2024 05:57:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在自定义环境中部署较小的模型与使用 LLM API：成本比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bymokq/d_deploying_smaller_models_in_custom_environment/</link>
      <description><![CDATA[当您从在组织云中部署较小的 NLP 模型转向使用 LLM api 时，计算成本发生了多少变化？法学硕士在这些方面便宜吗？   由   提交 /u/metalvendetta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bymokq/d_deploying_smaller_models_in_custom_environment/</guid>
      <pubDate>Mon, 08 Apr 2024 02:30:53 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在扩展机器学习训练（分布式系统/Ray/数据并行性）方面存在哪些增量未解决的问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byk5gw/p_what_incremental_unsolved_problems_are_there_in/</link>
      <description><![CDATA[我正在开展一个班级项目，我们将在其中提出一个分布式系统问题并撰写有关对现有系统的一些改进的文章。我对机器学习培训感兴趣，并希望扩展 Ray。 我正在尝试找到 Ray 中未完全解决或可以优化的分布式系统问题。我并不是在寻找一种适合每种情况的解决方案，但也许可以进行一些小的权衡改进（例如：权衡准确性以获得更好的容错能力，或从故障中恢复时间等）。&lt; /p&gt; 例如，现在我发现数据并行训练中的参数服务器可能是一个瓶颈，因为传统上每个工作人员都必须与每个参数服务器通信。但是，已经有 论文解决了使用从本地缓存读取的多个容错参数服务器的问题。我想找到一些我可以解决的类似于本文的问题。 在容错、分布式系统和/或 Ray 类别中是否有任何类似的问题值得我解决对某些场景进行增量改进？   由   提交/u/stereotropic_CS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byk5gw/p_what_incremental_unsolved_problems_are_there_in/</guid>
      <pubDate>Mon, 08 Apr 2024 00:29:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 Transformer 架构进行乳腺 X 线摄影实体分类 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byiiri/mammography_entity_classification_using/</link>
      <description><![CDATA[https://amarjay. vercel.app/posts/named-entity-recognition/   由   提交 /u/Amar_jay101   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byiiri/mammography_entity_classification_using/</guid>
      <pubDate>Sun, 07 Apr 2024 23:15:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] A* 场地研讨会论文与评级较低的场地会议论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byg2n5/r_a_venue_workshop_paper_vs_lowerrated_venue/</link>
      <description><![CDATA[NeurIPS24 就在附近，我有一篇去年在 ICLR (5/5/6/3) 被拒绝的论文。虽然我正在处理上次会议的反馈（该方法得到了积极的反馈，但他们要求进行更多实验），但我仍然不确定这篇论文是否足够强大，足以进入 NeurIPS 等 A* 会议。另外，说实话，我已经为此工作了将近一年，我觉得我已经想结束这个工作并看看其他想法了。 ​ 我想知道这两者哪个更好：  提交到 NeurIPS 或类似的研讨会（ICLR、ICML..）。考虑到 ICLR 的反馈，我认为这对于我的论文来说应该是可行的，但我不知道这是否正确？ 瞄准“较低层”的会议论文。地点，例如 AISTATS、IJCAI 或类似地点。我认为这比 NeurIPS 的研讨会论文更难完成，但我又只是猜测？  我仍然不是博士生，但我定期申请博士学位。因此，我正在寻找一种选择（如果我的论文通过）可以让我作为博士候选人在未来的申请中获得更多的优势。    由   提交 /u/howtorewriteaname   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byg2n5/r_a_venue_workshop_paper_vs_lowerrated_venue/</guid>
      <pubDate>Sun, 07 Apr 2024 21:32:36 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]新的 TensorFlow 版本 - 发生了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1byfdbs/discussion_new_tensorflow_version_what_happened/</link>
      <description><![CDATA[我使用 TPU VM Pod 来训练我的模型。我最近将系统运行时更新为 tf-2.16.1-pod-pjrt，天哪，它有很多错误吗？这确实是我见过的最糟糕的 TensorFlow。我通常对 TF 模型对象进行子类化并覆盖训练、测试、构建...函数。由于某种原因，它不仅忽略了我的覆盖功能，而且甚至不允许我正确使用 GRUCell 之类的东西。值得庆幸的是，我在此之前制作了我的工作 GRUCell 层并且有效，但 Keras 层甚至无法使用它的事实是可怕的。我喜欢 TensorFlow，我希望他们能解决这个问题。我也很乐意帮助遇到这些问题的任何人。   由   提交 /u/Onlyheretohelp_you   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1byfdbs/discussion_new_tensorflow_version_what_happened/</guid>
      <pubDate>Sun, 07 Apr 2024 21:04:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] UNet 如何使用交叉注意力与 CLIP 文本嵌入来生成最终的噪声图像？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bycklh/d_how_does_the_unet_use_cross_attention_with_clip/</link>
      <description><![CDATA[目前，我对 Unet 中每个上采样和下采样块如何实际使用交叉注意力有一个不错的理解。最终，交叉注意力似乎产生了这些类似注意力的热图，这些热图基本上指示了图像中每个像素与提示中的单词的相关性。 ​ 我的困惑在于如何使用该注意力图来生成最终图像。即交叉注意力如何与 Unet 模型集成以产生最终输出（减少噪声图像） 我特别困惑，因为注意力图似乎是 4 个维度（image_h、image_w、#heads、提示中的单词）那么我们如何将其转换为二维（image_h，image_w） 希望这个问题有意义。抱歉，如果看起来令人困惑。   由   提交 /u/Jordanoer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bycklh/d_how_does_the_unet_use_cross_attention_with_clip/</guid>
      <pubDate>Sun, 07 Apr 2024 19:14:33 GMT</pubDate>
    </item>
    <item>
      <title>使用变形金刚为任何歌曲生成节奏游戏节拍图 [R] [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bya93f/generate_rhythm_game_beatmaps_for_any_song_using/</link>
      <description><![CDATA[       由   提交 /u/sedthh   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bya93f/generate_rhythm_game_beatmaps_for_any_song_using/</guid>
      <pubDate>Sun, 07 Apr 2024 17:39:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么人们在 Arxiv 上上传他们的作品，而不是提交会议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bya23i/d_why_do_people_upload_their_work_on_arxiv_not/</link>
      <description><![CDATA[纯粹是我的好奇心。 我知道这种情况，当一篇论文在会议或期刊上被接受，并且可以上传时他们在 Arxiv 上的工作。但我的问题是，有些作品只在Arxiv上上传。这是否意味着作者不想在会议上提交自己的作品，而是想发布自己的作品？或者，发布后他们还有其他提交计划吗？ 我这么问是因为我最近的工作在一次会议上被拒绝了，但我不想再深究了。人们是否也喜欢在 Arxiv 上上传废弃作品的同样情况？   由   提交/u/Shot-Button-9010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bya23i/d_why_do_people_upload_their_work_on_arxiv_not/</guid>
      <pubDate>Sun, 07 Apr 2024 17:31:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们知道Gemini 1.5是如何实现10M上下文窗口的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by8e9s/d_do_we_know_how_gemini_15_achieved_10m_context/</link>
      <description><![CDATA[我们知道 Gemini 1.5 是如何实现 1.5M 上下文窗口的吗？随着注意力窗口的扩大，计算量不会呈二次方增长吗？    由   提交/u/papaswamp91  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by8e9s/d_do_we_know_how_gemini_15_achieved_10m_context/</guid>
      <pubDate>Sun, 07 Apr 2024 16:21:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我构建了一个稳定的扩散管道，使用 LangChain、DeepLake 和 ControlNet 与稳定扩散创建艺术二维码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by7q46/p_i_built_a_stable_diffusion_pipeline_to_create/</link>
      <description><![CDATA[       由   提交/u/efenocchi   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by7q46/p_i_built_a_stable_diffusion_pipeline_to_create/</guid>
      <pubDate>Sun, 07 Apr 2024 15:52:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 我创建了一本适合初学者的量子机器学习手册。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxzz1w/p_d_i_have_created_a_beginnerfriendly_quantum/</link>
      <description><![CDATA[大家好，在过去的几周里，我一直致力于为一个不了解任何量子概念并且想要的人创建正确的手持路线图深入研究量子机器学习。我希望获得您对内容的意见，如果您能为这个项目做出贡献，我将不胜感激。希望为每个人提供这本手册。 这里是 GitHub 存储库链接：https:// github.com/Winter-Soren/quantum-ml-handbook 这里是托管链接：https://quantummlhandbook。 vercel.app/   由   提交 /u/_-THUNDERBOLT-_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxzz1w/p_d_i_have_created_a_beginnerfriendly_quantum/</guid>
      <pubDate>Sun, 07 Apr 2024 09:04:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何处理没有发布代码的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxxk3l/d_what_do_you_do_with_paper_with_no_code_published/</link>
      <description><![CDATA[许多论文介绍了自己的模型，大部分是现有模型的变体，对原始模型的改动很小（主要针对特定​​问题）。他们中的大多数没有发布代码，这使得重现结果非常困难。在某些情况下（甚至可能是很多情况，我只找到/检查了一些）实验配置不完整，在论文中。  你如何处理这些论文？ 当人们引用这些论文时你如何争论？  &amp;# 32；由   提交 /u/Muhammad_Gulfam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxxk3l/d_what_do_you_do_with_paper_with_no_code_published/</guid>
      <pubDate>Sun, 07 Apr 2024 06:26:36 GMT</pubDate>
    </item>
    </channel>
</rss>