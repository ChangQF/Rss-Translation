<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Fri, 28 Jun 2024 03:17:34 GMT</lastBuildDate>
    <item>
      <title>[R] 从歌曲中提取人声并进行音高检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dq8qty/r_extracting_vocals_from_a_song_pitch_detection/</link>
      <description><![CDATA[嗨，我正在处理一个歌曲数据集，我想仅基于歌曲的人声部分生成音域。我想知道有哪些技术或模型可以让我定位歌唱部分？ 仅给出歌唱音频 - 我想利用音高检测算法来识别音高信息以及每个音符在歌曲中持续的时间。我想将其与一个人的声音图进行比较。 在处理音频数据或执行更常规的音频分析时，有哪些库或资源值得关注？到目前为止，我一直在使用 librosa。 任何帮助都非常感谢！    提交人    /u/perfectlylonely13   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dq8qty/r_extracting_vocals_from_a_song_pitch_detection/</guid>
      <pubDate>Fri, 28 Jun 2024 02:21:11 GMT</pubDate>
    </item>
    <item>
      <title>MeshAnything：艺术家使用自回归变换器创建网格生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dq7lg2/meshanything_artistcreated_mesh_generation_with/</link>
      <description><![CDATA[  由    /u/s6x  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dq7lg2/meshanything_artistcreated_mesh_generation_with/</guid>
      <pubDate>Fri, 28 Jun 2024 01:19:35 GMT</pubDate>
    </item>
    <item>
      <title>训练地理空间分析模型：SOS [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dq5ysv/training_a_model_for_geospatial_analysis_sos_p/</link>
      <description><![CDATA[大家好， 开始一项关于行人死亡的研究。我有行人事故地点的地理定位数据，我想研究这些位置的道路设计。 我想使用航拍图像来分析车道数量、交叉路口设计、人行道存在情况，甚至事故地点附近的土地使用情况。 我的想法是训练一个模型，手动编码事故地点的航拍图像，然后公开发布该模型，供其他研究道路工程故障的研究人员使用。 关于行人死亡的数据在位置的许多属性方面存在差距和不一致。我认为航拍图像是解决方案。 我没有任何编码经验，但我对 gis 很熟悉，仅供参考。 提前谢谢您！欢迎 DM。   由    /u/colorsnumberswords  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dq5ysv/training_a_model_for_geospatial_analysis_sos_p/</guid>
      <pubDate>Thu, 27 Jun 2024 23:58:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对生物医学/STEM 的微调检索模型 (DeBERTa/RoBERTa/e5)：寻求有关无监督微调、查询/指示格式和损失函数的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dq5mmd/d_finetuning_retrieval_models_debertarobertae5/</link>
      <description><![CDATA[大家好！ TL;DR：使用 DeBERTa 微调医学/STEM 知识的检索模型。寻求有关 DeBERTa 解码器配置、查询前缀策略和监督微调损失函数的建议。还寻找一般技巧和要避免的常见陷阱……以及其他一系列无限的问题。 我正在微调检索模型（目前使用句子转换器库以简化操作）。我正在考虑将 DeBERTa v3 large 和 DeBERTa v2 xxlarge（1.5B 参数）作为基础模型。不幸的是，没有 v3 xlarge，这真的很可惜，因为 v3 使用 ELECTRA 风格的预训练，它比 BERT/RoBERTa/DeBERTa v1-2 的经典 MLM 更有效、更高效。 我的管道使用各种数据集，从面向检索的数据集（如 MSMARCO 和 GooQA）到用于不对称检索、句子相似性、NLI 和句子压缩的较小数据集……然后我在使用 GPT-4、Claude sonnet 和 Command R Plus 生成的较小数据集上进行微调（我使用了多个模型来避免风格偏见并增加可变性）。 用例可以在医学/生物医学领域定义为“知识检索”，但可以推广到 STEM 领域。通过在通常的管道之前添加无监督的微调步骤，我获得了很好的结果，其中 TSDAE 方法特别有效。但是，transformers 库中没有 DeBERTa 模型用作解码器时的配置，所以我最终使用了 RoBERTa large 和 e5-unsupervised large。 我正在向有类似项目经验的人寻求建议。具体来说：  有人知道如何获取 DeBERTa 作为解码器的配置吗？ 关于查询前缀或说明，是否有关于最佳方法的共识？我应该简单地在查询文本前面添加，在查询和输入文本之间使用“[SEP]”标记，还是使用新的自定义标记？ 对于监督微调损失，有什么推荐的选择吗？我使用了多重负排名损失，然后切换到 GISTEmbed，它提供了更好的结果（使用 Snowflake Arctic Large 作为 GISTEmbed 损失中的“指导”来消除批量负挖掘中出现的假阴性）。由于硬件限制，我一直在使用这些损失的缓存版本来有效地将批量大小增加到我的 GPU VRAM 限制之外。正如预期的那样，考虑到批量负挖掘，GISTEmbed 和 MNRL 的性能都与批量大小成正比。 哪些池化策略（例如，CLS 令牌、均值池化、最大池化、注意力池化）在检索任务中生成文档/查询嵌入时显示出最佳结果？ 哪些学习率计划对于微调像 DeBERTa 这样的大型模型以执行检索任务效果很好？对于衰减率或预热期，是否有任何特定领域的考虑因素？ 在医疗/STEM 领域，持续预训练的最有效策略是什么？是否存在特别有效的特定技术或数据集？ 关于无监督学习方法，我已经成功使用了 TSDAE。还有其他无监督方法在专门领域的检索任务中显示出前景吗？  抱歉，文字太多了，而且还有这么多问题…… 如果能提供任何避免常见错误的提示或建议，我们将不胜感激！ 提前感谢整个社区。    提交人    /u/Distinct-Target7503   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dq5mmd/d_finetuning_retrieval_models_debertarobertae5/</guid>
      <pubDate>Thu, 27 Jun 2024 23:42:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有办法通过 AoT 编译 AI 模型以在 CPU 和 GPU 上运行？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpxn8y/d_is_there_a_way_to_aot_compile_an_ai_model_to/</link>
      <description><![CDATA[从我初步的研究来看，AoT 编译是过去一两年来讨论的热门话题。随着模型越来越大，按需提供服务和预编译的成本也越来越高，关于 AoT 编译优于 JIT 编译的讨论也越来越普遍。但是，我还没有看到任何针对 GPU 的明确解决方案？同样，也没有看到针对 CPU 的现状解决方案。 Tensorflow XLA 支持 AoT 编译，但据我所知，它仅适用于 x86 CPU：https://openxla.org/xla/tf2xla/tfcompile PyTorch Glow 和内置的 PyTorch `aot_compile` 似乎也没有针对 GPU 的 AoT。它也是实验性的。 TVM 具有 AoT 编译，但 (1) 它目前已损坏，并且 (2) 是为针对微控制器（例如 x86、ARM、RISC-V）的 MicroTVM 构建的。 所以我的问题很简单。如果我想执行以下操作：  将 LLM 之类的神经网络模型作为二进制文件分发到多个主机上进行推理 让该二进制文件在运行推理时使用 GPU 或 CPU（编译时的选择）  ...我有什么选择？现在人们用什么来做这个？ 此外，有人知道任何基准测试吗：JIT 与 AoT 与 CPU 上的无编译以及一般的 GPU？    提交人    /u/jiMalinka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpxn8y/d_is_there_a_way_to_aot_compile_an_ai_model_to/</guid>
      <pubDate>Thu, 27 Jun 2024 17:57:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 概率图模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpq6xp/d_probabilistic_graphical_models/</link>
      <description><![CDATA[所以我很困惑是否要学习概率图模型。 目前我想探索的下 3 个领域是 人工智能（我将在大学下学期学习该课程）以及斯坦福大学的 cs 221 课程 因果推理（我已经为下学期制定了 SOP 生成式人工智能 我是否需要概率图模型知识来学习这些主题。 谢谢    提交人    /u/Worldly-Duty4521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpq6xp/d_probabilistic_graphical_models/</guid>
      <pubDate>Thu, 27 Jun 2024 12:33:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深度学习项目硬件要求（预算 2000 美元）：大型复杂数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpo1p2/d_deep_learning_project_hardware_requirements/</link>
      <description><![CDATA[虽然为了完成 ECG 分析算法的论文答辩，我进入应用机器学习（尤其是深度学习）领域已经 8 个多月了，但我还没有弄清楚最佳设置的硬件要求，以便明智地使用 2000 美元的研究经费。 我不是美国公民，我们国家也没有 Nvidia 供应商。我的笔记本电脑性能很差，只有英特尔酷睿 i3 处理器和 4GB RAM。我在国内的选择是购买一台新笔记本电脑或购买一台工作站，价格略低于 16GB RAM 和酷睿 i7 笔记本电脑的两倍。但我在其他地方读到过，笔记本电脑并不是重型 DL 项目的最佳选择，尽管我正在考虑使用 SSD 来增加内存和时间效率的可能性。 Google Collaboratory 一开始似乎是个不错的选择，但在处理如此大的项目时，尤其是在数据处理方面，它有局限性。 我必须将深度学习应用于复杂的心电图信号数据集，而我的研究领域是生物医学工程，很少考虑这些主题。如果能得到一个有见地的回复，以免在钱的问题上犯错，我将不胜感激。非常感谢您花时间阅读到这里。    提交人    /u/r_agate   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpo1p2/d_deep_learning_project_hardware_requirements/</guid>
      <pubDate>Thu, 27 Jun 2024 10:30:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从头开始​​训练 Transformer-CNN 视频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpnp05/d_training_a_transformercnn_model_for_videos_from/</link>
      <description><![CDATA[您好， 我正在尝试从头开始训练 Transformer-CNN 模型。Transformer 模型与 ViViT 模型 2 相当。CNN 正在获取第二个（时间）变换器的输出并生成图像输出。输入是视频文件。目标是输出这些视频文件中部分隐藏的移动物体。 我的架构（在 Pytorch 中）如下（从输入到输出）：  TubletEmbedding 卷积 PatchEmbedding（1 Conv3D 层） 添加 CLS Token 位置编码 （空间）TransformerEncoder 层（dim=512，heads=8，layers=1） 添加 CLS Token 全局平均池化 （时间）TransformerEncoder 层（dim=512，heads=8，layers=1） 解码器层  线性 ReLU Dropout BatchNorm1d Unflatten 2x  ConvT2d ReLU Dropout BatchNorm2d  ConvT2d Tanh   我有大约 80,000 个单独的训练视频。我使用热身学习 20 个时期，然后使用 AdamW 优化器进行余弦退火和热重启。我的批次大小是 64。为了加快训练速度（我只有一个 4090），我使用混合精度训练和梯度累积。我的标准是 MSE。 https://preview.redd.it/q3x31tfm439d1.png?width=2304&amp;format=png&amp;auto=webp&amp;s=22806fd864830529d3425597e74ff01226e69729 如上所示，该模型实际上收敛得相当快。最终验证损失非常小，但输出并不理想。它几乎是所有可能对象的混合体，集中在一个地方： https://preview.redd.it/zy1sooo2839d1.png?width=1948&amp;format=png&amp;auto=webp&amp;s=02ec6befce7b8c360f93fd8bee2bf734775b83d6 有什么想法吗？    提交人    /u/grmn0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpnp05/d_training_a_transformercnn_model_for_videos_from/</guid>
      <pubDate>Thu, 27 Jun 2024 10:07:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 既然 T5 似乎是更好的文本编码器（用于 SD3 等），为什么在 LaBSE 中使用 Bert</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpn365/d_why_is_bert_used_in_labse_when_t5_seems_like/</link>
      <description><![CDATA[LaBSE 是最好的（据我所知）开源句子嵌入模型，我经常使用它，但它是在 T5 之后出现的，最近 T5 似乎是最好的文本编码器，用于 SD3 等，为什么在 LaBSE 中使用 bert 而不是 T5 ？ 这篇 Google T5 句子嵌入论文 https://arxiv.org/pdf/2007.01852 甚至早于 LaBSE 论文 https://arxiv.org/pdf/2007.01852 Bert 只是编码器，而 T5 是编码器-解码器（我猜只有在像 SD3 这样的嵌入情况下才使用编码器部分），什么会让 Bert更适合句子嵌入，但 T5 更适合 SD3 ？     提交人    /u/EizanPrime   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpn365/d_why_is_bert_used_in_labse_when_t5_seems_like/</guid>
      <pubDate>Thu, 27 Jun 2024 09:25:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士中的可解释性研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpmuy9/r_interpretability_research_in_llms/</link>
      <description><![CDATA[法学硕士 (LLM) 的可解释机器学习 (ML) 的大部分工作都集中在机械可解释性上，而不是文献中先前的方法，如反事实、基于案例的推理、原型、显着性图、基于概念的解释等... 您认为这是为什么？我的感觉是，这是因为机械解释在研究中计算量较小，所以它是人们在法学硕士 (LLM) 中真正拥有的唯一选择（例如，数据集太大而无法进行基于案例的推理）。另一种解释是，人们只是试图将该领域推向不同的方向，而机械解释就是这样。就像人们只是想要法学硕士推理的因果形式保证一样。 但我想了解一下人们的感受，您认为我是对的还是这种趋势还有其他原因？    提交人    /u/SkeeringReal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpmuy9/r_interpretability_research_in_llms/</guid>
      <pubDate>Thu, 27 Jun 2024 09:09:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言模型对于时间序列预测真的有用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dpgp0h/r_are_language_models_actually_useful_for_time/</link>
      <description><![CDATA[  由    /u/Cunic  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dpgp0h/r_are_language_models_actually_useful_for_time/</guid>
      <pubDate>Thu, 27 Jun 2024 02:39:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找研究时间序列的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp96cu/d_looking_for_resources_to_study_time_series/</link>
      <description><![CDATA[我对基础统计学和深度学习有相当的了解。 我想从基础到尽可能深入地研究时间序列，包括数学和编码实现方面。我不想跳过数学细节。 有人可以给我推荐一些好的资源吗：书籍和讲座系列 谢谢     提交人    /u/Worldly-Duty4521   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp96cu/d_looking_for_resources_to_study_time_series/</guid>
      <pubDate>Wed, 26 Jun 2024 20:50:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为一名刚毕业的博士生，需要做好就业准备吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp73ct/d_job_prep_as_a_fresh_phd_grad/</link>
      <description><![CDATA[大家好， 我是一名刚毕业的 ML 博士，目前正在求职。我正在寻找 genAI 和传统 ML 职位。这里有没有人有申请 ML 职位的经验，你觉得哪些资源有用？提前谢谢大家。    提交人    /u/Temporary_Study2354   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp73ct/d_job_prep_as_a_fresh_phd_grad/</guid>
      <pubDate>Wed, 26 Jun 2024 19:22:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于最佳 Python 时间序列库的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dp4y8p/d_thoughts_on_best_python_timeseries_library/</link>
      <description><![CDATA[有许多 Python 库提供当代时间序列模型和数据工具的实现。以下是一份（不完整）列表。希望任何使用过这些（或其他）库的人对其优缺点提供反馈。如果您使用过多个库并且可以提供有见解的比较，则可以获得加分。我正在尝试弄清楚要花时间研究哪一个（些）。非常感谢！  TSA - https://github.com/timeseriesAI/tsai TSLib - https://github.com/thuml/Time-Series-Library AEON - https://github.com/aeon-toolkit/aeon SKTime - https://www.sktime.net/en/stable/ TSLearn - https://tslearn.readthedocs.io/en/stable/ Nixtla - https://github.com/Nixtla/ Pytorch-forcasting - https://pytorch-forecasting.readthedocs.io/en/stable/ DARTS - https://unit8co.github.io/darts/index.html Merlion - https://github.com/salesforce/Merlion     提交人    /u/HorseEgg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dp4y8p/d_thoughts_on_best_python_timeseries_library/</guid>
      <pubDate>Wed, 26 Jun 2024 17:54:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>