<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sun, 02 Jun 2024 01:06:43 GMT</lastBuildDate>
    <item>
      <title>[D] LAION 美学数据集的替代品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5y0oo/d_alternatives_to_the_laion_aesthetics_dataset/</link>
      <description><![CDATA[因此，LAION 数据集目前已关闭以进行安全审查。与此同时，是否有任何大型数据集可以代替其美学子集？我正在寻找“美学上令人愉悦”的图像，例如艺术品、绘画、漂亮的照片等。    提交人    /u/thehomelessman0   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5y0oo/d_alternatives_to_the_laion_aesthetics_dataset/</guid>
      <pubDate>Sat, 01 Jun 2024 22:00:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] CoPE：上下文位置编码：学习计算重要的事情</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5u95z/r_cope_contextual_position_encoding_learning_to/</link>
      <description><![CDATA[  由    /u/fasttosmile  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5u95z/r_cope_contextual_position_encoding_learning_to/</guid>
      <pubDate>Sat, 01 Jun 2024 19:05:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] Tensttorrent Galaxy Server 使用案例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5taip/d_tensttorrent_galaxy_server_usecases/</link>
      <description><![CDATA[大家好， 第一次发帖，请温柔一点 :) 我有机会以少量资金长期借用一台配备 32 个 wormhoole 处理器的 Tenstorrent Galaxy 服务器。 我们是一家拥有技术娴熟的工程师的小公司，但我们没有太多时间深入研究人工智能。我们做一些基本的事情，比如使用现成的模型和运行推理并进行一些轻度微调（主要是 YOLO），因为这不是我们的核心业务。然而，我个人的愿望是慢慢转向人工智能领域，所以我的问题是，如果你有类似的机会，你会接受它并将其用于什么？我知道这是一个广泛的问题，所以请自由发挥创意:) 在 github (https://github.com/tenstorrent/tt-buda-demos/tree/main/model\_demos) 上，他们已经有了模型演示列表，但这只是推理，没有看到提到微调或训练    提交人    /u/zakakanje   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5taip/d_tensttorrent_galaxy_server_usecases/</guid>
      <pubDate>Sat, 01 Jun 2024 18:21:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 超快 RAG：Langchain Streaming 和 Groq</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5s9g4/p_superfast_rag_langchain_streaming_and_groq/</link>
      <description><![CDATA[使用 Groq 和 Langchain Streaming 进行快速 LLM RAG 推理。  Groq 推出了一种新的、更简单的处理架构，专为满足机器学习应用程序和其他计算密集型工作负载的性能要求而设计。更简单的硬件还可以通过消除分析需求来节省开发人员资源，并且还可以更轻松地大规模部署 AI 解决方案。  资源：https://www.youtube.com/watch?v=frMdOL8knqg    提交人    /u/trj_flash75   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5s9g4/p_superfast_rag_langchain_streaming_and_groq/</guid>
      <pubDate>Sat, 01 Jun 2024 17:35:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] GPT-Burn：纯 Rust 中 GPT 的简单而简洁的实现🔥</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5qg3h/p_gptburn_a_simple_concise_implementation_of_the/</link>
      <description><![CDATA[        由    /u/ProfessionalDrummer7 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5qg3h/p_gptburn_a_simple_concise_implementation_of_the/</guid>
      <pubDate>Sat, 01 Jun 2024 16:10:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 PyTorch Geometric 进行 GNN 采样的视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5nmlh/p_a_visual_guide_to_gnn_sampling_using_pytorch/</link>
      <description><![CDATA[      大家好， 我发布了一些关于“图神经网络采样”主题的视频和笔记本（GNNs）”。原始 GCN 论文采用全批量训练。然后，研究人员使用不同的方法创建小批量（子图）来训练 GCN。例如，GraphSAGE 论文使用了邻居采样器，而 ClusterGCN 论文使用了集群采样器。这些采样器在 pytorch-geometric 中的 torch_geometric.loader 下实现。 这是视频，或者你可以直接跳到代码中..  图形神经网络的采样 视频 代码  图形神经网络中的迷你批次视频 视频 代码 原始图表 三使用来自 pytorch_geometric 的 NeighborLoader 对子图进行采样；白色节点未被采样。    提交人    /u/mashaan14   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5nmlh/p_a_visual_guide_to_gnn_sampling_using_pytorch/</guid>
      <pubDate>Sat, 01 Jun 2024 14:00:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 深层生物群落实验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5laih/p_the_deep_biome_experiment/</link>
      <description><![CDATA[您好， 我正在研究深层生物群落的概念，并试图在本文档中描述它：https://docs.google.com/document/d/e/2PACX-1vR1bvKTV94WRUyz-xfqPkV0TQjrHgE-4reCdP2Ncjgxv4CN8CVhEmcYb_b7qC2lv_HK9vjZd9yv57-Z/pub 摘要是：创建一个虚拟生物群落，其中每个代理都有一个“DNA”代表其神经网络的结构，并具有与其他代理一起繁殖的能力。 我已经在 GitHub 上创建了一个 DeepDNA 的示例，其中创建了两个 DNA，然后合并以生成孩子的 DNA。 我正在寻找合作者来有效地开发理论（和实施），这可以帮助我解决一些概念瓶颈，例如代理模型的训练或像 LSTM 这样的复杂层的情况下序列的结构。 我很欣赏与大学的合作以及将论文作为研究发表的雄心。 python 测试在这个 repo 中：https://github.com/cekkr/DeepGenome  此刻，我正在等待“刺激”继续前进。 谢谢， Riccardo Cecchini    提交人    /u/itsmeriky   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5laih/p_the_deep_biome_experiment/</guid>
      <pubDate>Sat, 01 Jun 2024 11:53:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助提高 BERT 与神经网络的匹配度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5l0he/d_help_to_increase_the_acc_of_bert_with_neural/</link>
      <description><![CDATA[      你好，我是 ML 新手，我正在努力提高我的 BERT-CNN、BERT-LSTM、BERT-GRU 的准确率。 这是我的存储库情绪分析 BERT-CNN 我使用的数据集是Kaggle，该数据集不平衡，因此我需要将一些中性情绪分数取出至 0.78 以获得 4k 的中性情绪 我现在的准确率是 -&gt; BERT-CNN 训练总结： 最佳训练损失：0.0129（第 10 次训练） 最佳验证准确率：81.55%（第 7 次训练） -&gt; BERT-LSTM 训练总结： 最佳训练损失：0.0815（第 10 次训练） 最佳验证准确率：81.14%（第 7 次训练） -&gt; BERT-GRU 训练总结： 最佳训练损失：0.0815（第 10 次迭代） 最佳验证准确率：81.14%（第 7 次迭代） 图表 我根据这篇论文进行研究，作为准确率的参考，但是 我的代码有问题吗？ 我不知道我已经更改了不同的超参数，但对准确率来说仍然不重要。以及为什么我的模型不好，比如 acc 的改进不是增量的，但有时是下降的？ 提前谢谢您，我希望您对讨论感兴趣:)    提交人    /u/Jveko   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5l0he/d_help_to_increase_the_acc_of_bert_with_neural/</guid>
      <pubDate>Sat, 01 Jun 2024 11:35:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mojo 值得吗，或者你愿意为 ML 学习哪种第二语言？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5kov5/d_is_mojo_worth_it_or_which_second_language_would/</link>
      <description><![CDATA[基本上就是标题。我非常精通 Python（正如预期的那样），但除此之外，我对 JavaScript 和 C++ 的了解非常有限。我想学习一种更“低级”的第二种语言，可以更好地利用硬件功能。我的目标不是重写 Pytorch 或完全替换 Python（尽管 将推理移植到 Mojo 可能有意义），而是为性能关键用例提供替代方案。 从今天的情况来看，答案显然是 C++。然而，Rust 越来越受欢迎，除了陡峭的学习曲线外，人们开始在许多方面将其置于 C++ 之上。在这两种情况下，语法和语言都与 Python 不太接近，这使得它们很难学习。 Mojo 在这方面似乎要好得多，既提供了语法类似于 Rust 的低级功能（至少对于像我这样的门外汉来说），又可以用作奇怪的 Python 风格。它甚至允许直接导入 Python 库。这对于这种缺乏大型社区和各种库的年轻语言非常有帮助。尽管如此，该语言仍然很年轻，而且很容易发生变化，所以我不确定是否应该投资。 那么，对于上述用例，您认为最好的“第二种”语言是什么？有使用 Mojo 的经验吗？您是如何学习它或资源有限的任何其他语言的。如果我使用 Mojo，我打算通读文档并解决去年使用它的代码出现的问题。    提交人    /u/canbooo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5kov5/d_is_mojo_worth_it_or_which_second_language_would/</guid>
      <pubDate>Sat, 01 Jun 2024 11:15:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 情境学习是否足以满足法学硕士 (LLM) 课程的指导要求？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hh86/r_is_incontext_learning_sufficient_for/</link>
      <description><![CDATA[上下文学习 (ICL) 允许 LLM 从示例中学习而不改变其权重，这对于可以从许多示例中学习的长上下文 LLM 来说是一项特别有前途的功能。最近，Lin 等人 (2024) 提出了 URIAL，这是一种仅使用三个上下文示例来对齐基础 LLM 的方法，可实现非平凡的指令跟踪性能。在这项工作中，我们表明，虽然有效，但使用 URIAL 的 ICL 对齐与已建立的基准（例如 MT-Bench 和 AlpacaEval 2.0 (LC)）上的指令微调相比仍然表现不佳，尤其是对于功能更强大的基础 LM。与分类、翻译或摘要等任务不同，为长上下文 LLM 添加更多 ICL 演示并不能系统地提高指令跟踪性能。为了解决这一限制，我们推导出一种针对 ICL 示例的贪婪选择方法，该方法可显着提高性能，但不会弥合与指令微调之间的差距。最后，我们提供了一系列消融研究，以更好地了解剩余差距背后的原因，并展示了 ICL 的某些方面如何偏离现有知识并特定于指令调整设置。 总的来说，我们的工作推进了对 ICL 作为一种对齐技术的理解。    提交人    /u/m_andriushchenko   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hh86/r_is_incontext_learning_sufficient_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:21:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] DeTikZify：使用 TikZ 合成科学图形和草图的图形程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5hh0s/p_detikzify_synthesizing_graphics_programs_for/</link>
      <description><![CDATA[        由    /u/DrCracket 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5hh0s/p_detikzify_synthesizing_graphics_programs_for/</guid>
      <pubDate>Sat, 01 Jun 2024 07:20:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自动 LoRA 发现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5ei7s/p_automated_lora_discovery/</guid>
      <pubDate>Sat, 01 Jun 2024 04:09:17 GMT</pubDate>
    </item>
    <item>
      <title>调整剧本中的探索与利用——需要帮助理解流程 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d5cxyq/exploration_vs_exploitation_in_tuning_playbook/</link>
      <description><![CDATA[[已编辑] 我正在阅读“Tuning Playbook”，在理解超参数调整背景下的探索与利用概念时遇到了一些困难。 有没有人可以用更具体而不是抽象的方式解释这个概念，或者提供一个在超参数调整中如何进行探索的例子？什么是探索以及如何进行探索。还有一件事；它一直在说理解问题，哪个问题？问题模型试图解决？还是什么超参数影响性能和相互影响的问题？还是什么？  这是书中关于这个主题的部分：  探索与开发  谢谢！    提交人    /u/Same_Half3758   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d5cxyq/exploration_vs_exploitation_in_tuning_playbook/</guid>
      <pubDate>Sat, 01 Jun 2024 02:40:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 其他领域的研究，例如最近对一立方毫米人类脑组织的映射，能否帮助机器学习领域？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d56zg0/d_can_other_areas_researches_such_as_the_recent/</link>
      <description><![CDATA[https://www.scientificamerican.com/article/a-cubic-millimeter-of-a-human-brain-has-been-mapped-in-spectacular-detail/ 围绕人类大脑的研究，例如这张最新的人类大脑图谱，能否为机器学习领域提供一些见解，以构建更有效的人工智能/算法模型？ 外行人在这里。    提交人    /u/Enzo-chan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d56zg0/d_can_other_areas_researches_such_as_the_recent/</guid>
      <pubDate>Fri, 31 May 2024 21:40:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>