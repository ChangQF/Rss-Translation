<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 02 Dec 2024 03:35:18 GMT</lastBuildDate>
    <item>
      <title>[D] 需要一些关于学校项目的建议。我们正在尝试使用 PySpark 预测 MLB 比赛。这是一个很大的分数，我们需要做得好。任何建议都将不胜感激。:)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4k89m/d_need_some_advice_for_a_school_project_were/</link>
      <description><![CDATA[大家好！我目前正在完成我的本科课程，我有一个大项目要为我的数据分析课程做。我们的项目应该使用 PySpark 来处理大型数据集并使用 ML 对其进行处理。这项任务是开放式的，所以我们有很多空间来做我们想出的东西。我说的“我们”是指我在这个项目中所在的三人小组。 我们决定使用 MLB 数据来预测比赛，我们已经能够收集数据、处理数据并进行一些基本的预测。问题是我们无法弄清楚如何真正设计模型。 我们有不同的数据来源，但到目前为止，棒球专家的数据是最有用的。我们也对 Retrosheet 的数据进行了一些处理，但它要复杂得多，而且处理起来真的很奇怪，因为多年来这项运动发生了变化，他们改变了数据记录方式，以及他们如何将所有这些年的数据塞进一个文件中。 目标（即，我非常非常想弄清楚处理数据的方式）是建立一个包含三个阶段的预测模型：  评估每个球员的表现 根据给定球队的球员评估每支球队的价值 比较两支球队的价值，同时考虑一些其他变量（体育场、天气、近期表现等，以及计算中引入的少量随机性），并预测哪支球队会获胜。  我们可以访问数百万行数据，并且我们有处理数据的硬件（尤其是使用 PySpark）。我一直在研究该模型的基本版本，但我不知道该如何处理这些数据。我写了很多关于如何处理数据的笔记，但每次我想出一个想法，我都会写下来，然后想出一些看起来更好的东西。我什么都做不了，这让我很难过。我真的很兴奋，我希望你们能对如何处理数据和训练模型提供一些建议，以便完成我的团队正在尝试做的事情。 到目前为止，代码可在 https://github.com/danielteberian/BaseballWizard 棒球专家数据的文档可在 https://baseballsavant.mlb.com/csv-docs 提前感谢大家。我很感激你们的时间。    提交人    /u/dptzippy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4k89m/d_need_some_advice_for_a_school_project_were/</guid>
      <pubDate>Mon, 02 Dec 2024 02:13:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要一些关于学校项目的建议。我们正在尝试使用 PySpark 预测 MLB 比赛。这是一个很大的分数，我们需要做得好。任何建议都将不胜感激。:)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4k884/d_need_some_advice_for_a_school_project_were/</link>
      <description><![CDATA[ 大家好！我目前正在完成我的本科学习，我有一个大项目要为我的数据分析课程做。我们的项目应该使用 PySpark 来处理一个大型数据集，并使用 ML 来处理它。这个任务是开放式的，所以我们有很多空间来做我们想出的东西。我说的“我们”是指我在这个项目中的三人小组。 我们决定使用 MLB 数据来预测比赛，我们已经能够收集数据、处理数据并进行一些基本的预测。问题是我们无法弄清楚如何实际设计模型。 我们有不同的数据来源，但到目前为止，棒球专家的数据是最有用的。我们也对 Retrosheet 的数据进行了一些处理，但它要复杂得多，而且处理起来真的很奇怪，因为多年来这项运动发生了变化，他们改变了数据记录方式，以及他们如何将所有这些年的数据塞进一个文件中。 目标（即，我非常非常想弄清楚处理数据的方式）是建立一个包含三个阶段的预测模型：  评估每个球员的表现 根据给定球队的球员评估每支球队的价值 比较两支球队的价值，同时考虑一些其他变量（体育场、天气、近期表现等，以及计算中引入的少量随机性），并预测哪支球队会获胜。  我们可以访问数百万行数据，并且我们有处理数据的硬件（尤其是使用 PySpark）。我一直在研究该模型的基本版本，但我不知道该如何处理这些数据。我写了很多关于如何处理数据的笔记，但每次我想出一个想法，我都会写下来，然后想出一些看起来更好的东西。我什么都做不了，这让我很难过。我真的很兴奋，我希望你们能对如何处理数据和训练模型提供一些建议，以便完成我的团队正在尝试做的事情。 到目前为止，代码可在 https://github.com/danielteberian/BaseballWizard Baseball Savant 数据的文档可在 https://baseballsavant.mlb.com/csv-docs 提前感谢大家。我很感激你们的时间。 总浏览量 总浏览量.78%赞同率 赞同与反对的比例.4评论 总评论数.6    提交人    /u/dptzippy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4k884/d_need_some_advice_for_a_school_project_were/</guid>
      <pubDate>Mon, 02 Dec 2024 02:13:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在 AWS Sagemaker 中对 DeepAR 框架进行查询</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4gwxy/r_queries_on_deepar_framework_in_aws_sagemaker/</link>
      <description><![CDATA[嗨， 我正在尝试为各种商店实施 deepAr 以预测未来的销售情况（每家商店有约 10k 个不同产品的 SKU）。由于 SKU 的规模庞大，我无法一次性对所有数据进行单次训练。我正在考虑按商店进行训练。  如何在 AWS 中并行进行训练？每个商店的训练过程最多需要 30 分钟； 如何处理数据中不存在的看不见的 SKU？  谢谢。    提交人    /u/skw1990   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4gwxy/r_queries_on_deepar_framework_in_aws_sagemaker/</guid>
      <pubDate>Sun, 01 Dec 2024 23:33:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人思人工智能研究员/住院医师——接受任何新毕业生/入门级人员吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4e0ah/d_anthropic_ai_fellowresidents_any_new/</link>
      <description><![CDATA[你好。入门级或新毕业生是否可以进入 Anthropic 奖学金或住院医师项目？过去被录取的人，你的简历和经历是什么样的？    提交人    /u/geekgeek2019   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4e0ah/d_anthropic_ai_fellowresidents_any_new/</guid>
      <pubDate>Sun, 01 Dec 2024 21:25:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何处理图神经网络训练中不同的特征维度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4dbvi/d_how_to_handle_varying_feature_dimensions_in/</link>
      <description><![CDATA[我有一个关于在图形神经网络训练中处理具有不同特征维度的数据集的问题。例如，在一个训练实例（我们称之为数据集 A）中，节点特征的维度为 4，边特征的维度为 16。在另一个实例（数据集 B）中，节点特征的维度为 5，边特征的维度为 25。其他数据集也可能具有不同的特征维度。 在使用此类数据集训练 GNN 模型时，用于处理每个实例的不同特征维度的标准方法是什么？我将不胜感激任何有关如何处理此问题的指导或方向。谢谢！    提交人    /u/bipulthapa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4dbvi/d_how_to_handle_varying_feature_dimensions_in/</guid>
      <pubDate>Sun, 01 Dec 2024 20:57:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] Promptwright - 使用 LLM（本地或托管）生成大型合成数据集的开源项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4bcz2/p_promptwright_open_source_project_to_generate/</link>
      <description><![CDATA[嘿 r/machinelearning， Promptwright，一个免费使用的开源工具，旨在使用本地大型语言模型或众多托管模型（OpenAI、Anthropic、Google Gemini 等）之一轻松生成合成数据集 此版本中的关键功能： * 支持多个 LLM 提供商：通过 Ollama、VLLM 等与大多数 LLM 服务提供商和 LocalLLM 配合使用 * 可配置的说明和提示：像以前一样在 YAML 中通过脚本定义自定义说明和系统提示。 * 命令行界面：直接从命令行运行生成任务 * 推送到 Hugging Face：使用自动数据集卡和标签将生成的数据集推送到 Hugging Face Hub 这是在最新版本上使用 promptwright 创建的示例数据集： https://huggingface.co/datasets/stacklok/insecure-code/viewer 这是使用“mistral-nemo:12b”从以下模板生成的，但老实说，大多数模型都能很好地执行，即使是小型 1/3b 模型也是如此。 system_prompt：“您是编程助理。您的任务是生成不安全代码的示例，突出显示漏洞，同时保持准确的语法和行为。” topic_tree： args： root_prompt：“跨多语言编程语言的不安全代码示例。” model_system_prompt: &quot;&lt;system_prompt_placeholder&gt;&quot; # 将被 system_prompt 替换 tree_degree: 10 # 广泛覆盖语言（例如 Python、JavaScript、C++、Java） tree_depth: 5 # 特定漏洞的深度层次结构（例如 SQL 注入、XSS、缓冲区溢出）temperature: 0.8 # 高度创造力以多样化示例 provider: &quot;ollama&quot; # LLM 提供者 model: &quot;mistral-nemo:12b&quot; # 模型名称 save_as: &quot;insecure_code_topictree.jsonl&quot; data_engine: args: instructions: &quot;用多种编程语言生成不安全的代码示例。每个示例都应包括对漏洞的简要说明。&quot; system_prompt: &quot;&lt;system_prompt_placeholder&gt;&quot; # 将被 system_prompt 替换 provider: &quot;ollama&quot; # LLM 提供程序 model: &quot;mistral-nemo:12b&quot; # 模型名称temperature: 0.9 # 鼓励示例中的多样性max_retries: 3 # 最多重试 3 次失败提示dataset:creation:num_steps: 15 # 在 10 次迭代中生成示例batch_size: 10 # 每次迭代生成 5 个示例provider: &quot;ollama&quot; # LLM 提供程序model: &quot;mistral-nemo:12b&quot; # 模型名称sys_msg: true # 在数据集中包含系统消息（默认值：true）save_as: &quot;insecure_code_dataset.jsonl&quot; # Hugging Face Hub 配置（可选）huggingface: # 格式为&quot;username/dataset-name&quot;的存储库repository: &quot;hfuser/dataset&quot; # 也可以通过 HF_TOKEN 环境变量或 --hf-token CLI 选项提供令牌 token: &quot;$token&quot; # 数据集的附加标签（可选） # &quot;promptwright&quot; 和 &quot;synthetic&quot; 标签会自动添加 tags: - &quot;promptwright&quot;  我们已在内部将它用于一些项目，效果非常好。您可以处理数千个样本，而不必担心 API 成本或速率限制。此外，由于一切都在本地运行，您不必担心敏感数据离开您的环境。 代码是 Apache 2 许可的，我们很乐意收到社区的反馈。如果您正在为 ML 进行任何类型的合成数据生成，请尝试一下并告诉我们您的想法！ 链接： 查看 examples 文件夹，获取生成代码、科学或创意 ewr 的示例 非常乐意听到您的想法和建议，如果您发现任何改进空间，请随时提出和发布或发出拉取请求。    提交人    /u/zero_proof_fork   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4bcz2/p_promptwright_open_source_project_to_generate/</guid>
      <pubDate>Sun, 01 Dec 2024 19:33:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关生成无缝 360° 图像的机器学习模型的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h48950/d_seeking_advice_on_machine_learning_models_for/</link>
      <description><![CDATA[大家好， 我正在做一个涉及创建 360° 图像的项目，遇到了一些挑战。目标是生成无缝 360° 全景图，图像环绕处没有可见边缘或伪影。 我想知道是否有任何机器学习模型、技术或工具特别适合这项任务。具体来说，我正在寻找可以做到以下事情的东西：  确保 360° 图像边缘的连续性。 处理不同的纹理和图案而不会出现明显的扭曲。 在我的自定义数据集上进行训练或微调（如果需要）。  我已经探索过 StyleGAN 和扩散模型等 GAN，但我不确定它们是否可以开箱即用地处理边缘连续性问题。有没有人解决过类似的问题或知道一个好的起点？ 任何建议、资源或见解都将不胜感激！提前致谢！    提交人    /u/Deep_Land_4093   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h48950/d_seeking_advice_on_machine_learning_models_for/</guid>
      <pubDate>Sun, 01 Dec 2024 17:22:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 01 Dec 2024 16:00:30 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Noema – 声明式 AI 编程库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h46341/project_noema_a_declarative_ai_programming_library/</link>
      <description><![CDATA[       由    /u/Super_Dependent_2978  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h46341/project_noema_a_declarative_ai_programming_library/</guid>
      <pubDate>Sun, 01 Dec 2024 15:46:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 来源：为什么猎犬的 KG 表现优于 RD？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h447eu/r_sources_reasons_why_kg_outperformes_rd_in/</link>
      <description><![CDATA[是否有任何资料讨论为什么 Retriever 与 KG 配合使用效果比 RD 更好？我发现说它更好是非常直观的，因为在知识图中我们拥有更多的语义结构，并且可以有效地发现关系。在我看来，“图当然更丰富/更密集”，但在论文合作时，我突然意识到我无法证明这一说法。我找不到任何资料可以真正解释为什么会这样。 我得到的唯一资料是这个： https://arxiv.org/abs/2311.07509 去年在子版块中也有：https://www.reddit.com/r/LocalLLaMA/comments/17vy1bo/a_benchmark_to_understand_the_role_of_knowledge/ 所以我们只能说&amp;“我们证明我们的决定是正确的，因为 KG 比 RD 效果更好 [基准论文来源]&amp;; 我本来很想讨论为什么 KG 更适合，并给出关于信息密度、语义结构或相关实体的更好选择的论据。但我找到的只是一些文章，它们散布着荒谬的主张或指出了更简单/原生的实现，从技术上讲，这也可以通过 RD 实现。 有人可以告诉我资料来源吗？很想阅读关于更好性能原因的深入讨论。    提交人    /u/PopPsychological4106   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h447eu/r_sources_reasons_why_kg_outperformes_rd_in/</guid>
      <pubDate>Sun, 01 Dec 2024 14:17:17 GMT</pubDate>
    </item>
    <item>
      <title>ROI 图像增强 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h41z2x/augmentation_for_images_with_roi_d/</link>
      <description><![CDATA[我有一张带有 roi (x_min、y_min、x_max、y_max) 的图像。我想用 torchvison 进行随机翻转、旋转、倾斜、平移等。为了与增强图像匹配，分别可以用哪些不同的方式转换 roi？    提交人    /u/Brief_Papaya121   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h41z2x/augmentation_for_images_with_roi_d/</guid>
      <pubDate>Sun, 01 Dec 2024 12:11:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] Qwen-VL：用于理解、定位、文本阅读等的多功能视觉语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h40wms/r_qwenvl_a_versatile_visionlanguage_model_for/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h40wms/r_qwenvl_a_versatile_visionlanguage_model_for/</guid>
      <pubDate>Sun, 01 Dec 2024 10:59:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    <item>
      <title>最好的开源图像升级模型是什么？[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3qcon/whats_the_best_open_source_imageupscaling_model/</link>
      <description><![CDATA[      我正在使用Playground-v2.5-aesthetic制作一些用于 YouTube 缩略图的图像。我对结果非常满意： 1024x1024 火星基地基础图像。 但我希望图像为 1920x1080 像素，而我唯一的选择是 1024x1024 或 1280x720 像素。目前，我可以使用 Photoshop 的修饰功能达到 1920x1080 的图像分辨率： 1920x1080 的火星基地修饰图像。 这还可以，但是 Photoshop 的修饰功能是手动的，并且质量会下降相当明显。理想情况下，我会生成 1280x720 的图像，然后通过编程将其升级到 1920x1080。 我听说过以下模型：  Real-ERSGAN Waifu2 SRGAN  但在我深入研究其中任何一个之前，哪种开源模型通常被认为最适合实现这一目标？我有一台 RTX 3060 12GB VRAM。    提交人    /u/FPGA_Superstar   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3qcon/whats_the_best_open_source_imageupscaling_model/</guid>
      <pubDate>Sun, 01 Dec 2024 00:13:57 GMT</pubDate>
    </item>
    <item>
      <title>[P]用Excel构建的完整变压器模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3hj6j/p_a_complete_transformer_model_built_in_excel/</link>
      <description><![CDATA[        提交人    /u/Revolutionary-Way290   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3hj6j/p_a_complete_transformer_model_built_in_excel/</guid>
      <pubDate>Sat, 30 Nov 2024 17:25:45 GMT</pubDate>
    </item>
    </channel>
</rss>