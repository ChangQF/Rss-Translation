<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Mon, 10 Jun 2024 12:28:04 GMT</lastBuildDate>
    <item>
      <title>[R] 接受率较高的机器学习/CS期刊。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dck8mv/r_machine_learningcs_journals_with_high/</link>
      <description><![CDATA[我想在影响因子 (&lt;1) 期刊上发表我的第三篇文章。这篇论文是关于使用 ML 和集成技术进行疾病预测。最好的选择是什么？    提交人    /u/Wide-Alternative-315   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dck8mv/r_machine_learningcs_journals_with_high/</guid>
      <pubDate>Mon, 10 Jun 2024 12:25:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] 异构 GNN - 链路预测 - 铁路延误预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dcjorv/p_heterogenous_gnn_link_prediction_railway_delay/</link>
      <description><![CDATA[你好，Reddit！ 我目前正在开展一个项目，该项目涉及预测法国铁路网络中的列车延误情况。该项目的数据表示为异构图，其中每列火车都与其前一个和后一个车站相连，也称为显著点 (PRs - Points Remarquables)。目的是预测将火车连接到其后续 PR 的边的延迟属性。 除了火车与 PR 的连接外，车站本身也相互连接以表示整体网络结构。在该网络的图形表示中，火车被描绘为节点，而车站之间的关系则由边表示。 数据封装在 HeteroData 对象中，该对象旨在处理具有各种类型节点和边的异构图。下面是一个图表的数据快照，其中标签为 y : HeteroData( train={ x=[391, 8], geometry=[391, 2], }, pr={ geometry=[3076, 2] }, (train, prev_pr, pr)={ edge_index=[2, 2034], edge_attr=[2034, 2], }, (train, foll_pr, pr)={ edge_index=[2, 5871], edge_attr=[5871, 1], y=[5871], }, (pr, pr_pr, pr)={ edge_index=[2, 3716], edge_attr=[3716, 2], } )  我不确定是否有可能为此类任务实现异构 GNN。我从这个开始，但我不知道如何实现前向方法： class SAGEConvReLU(torch.nn.Module): def __init__(self, in_channels, out_channels): super(SAGEConvReLU, self).__init__() self.conv = SAGEConv(in_channels, out_channels) def forward(self, x, edge_index): x = self.conv(x, edge_index) x = F.relu(x) return x class GNN(torch.nn.Module): def __init__(self, hidden_​​channels): super(GNN, self).__init__() self.conv1 = SAGEConvReLU(hidden_​​channels, hidden_​​channels) self.conv2 = SAGEConv(hidden_​​channels, hidden_​​channels) def forward(self, x, edge_index): x = self.conv1(x, edge_index) x = self.conv2(x, edge_index) 返回 x 类 RailwayHeteroGNN(torch.nn.Module): def __init__(self, hidden_​​channels): super(RailwayHeteroGNN, self).__init__() self.train_embedding = Linear(10, hidden_​​channels) self.pr_embedding = Linear(2, hidden_​​channels) self.gnn = GNN(hidden_​​channels) node_type = [&#39;train&#39;, &#39;pr&#39;] edge_types = [(&#39;train&#39;, &#39;prev_pr&#39;, &#39;pr&#39;), (&#39;train&#39;, &#39;foll_pr&#39;, &#39;pr&#39;), (&#39;pr&#39;, &#39;pr_pr&#39;, &#39;pr&#39;)] self.gnn = to_hetero(self.gnn, metadata=(node_type, edge_types)) def forward(self, data):  谢谢你的帮助！   由    /u/OtherDepartment8085  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dcjorv/p_heterogenous_gnn_link_prediction_railway_delay/</guid>
      <pubDate>Mon, 10 Jun 2024 11:55:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据产品的 Snowflake：数据货币化与体验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dcjigz/d_snowflake_for_data_products_data_monetisation/</link>
      <description><![CDATA[第 2 部分：通过优化业务的三个分支来利用现有堆栈：成本节约、货币化和数据公民的体验第 2 部分：通过优化业务的三个分支来利用现有堆栈：成本节约、货币化和数据公民的体验。 阅读完整文章了解更多信息！    提交人    /u/growth_man   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dcjigz/d_snowflake_for_data_products_data_monetisation/</guid>
      <pubDate>Mon, 10 Jun 2024 11:45:37 GMT</pubDate>
    </item>
    <item>
      <title>[N] 您认为这个新的开源文本转语音（TTS）模型有多好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dcj439/n_how_good_do_you_think_this_new_open_source/</link>
      <description><![CDATA[大家好， 我是 CAMB AI 的 Arnav，我们花了上个月的时间构建和训练 MARS 的第 5 次迭代，现在我们已经在 Github 上以英文开源了它 https://www.github.com/camb-ai/mars5-tts 我在 Reddit 这里 上发表了一篇较长的帖子。如果你们能看看并告诉我们你们的反馈，我们将不胜感激。谢谢！   由    /u/MrHumun  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dcj439/n_how_good_do_you_think_this_new_open_source/</guid>
      <pubDate>Mon, 10 Jun 2024 11:21:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 经纪人背后的炒作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dcefvk/d_hype_behind_agents/</link>
      <description><![CDATA[最近我听到了很多关于多智能体系统初创公司的宣传，我不确定为什么会有这么多的炒作。是什么让多智能体系统变得困难？有哪些有趣的研究问题？DSPy 不是已经解决了很多这些问题吗？    提交人    /u/Primary-Track8298   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dcefvk/d_hype_behind_agents/</guid>
      <pubDate>Mon, 10 Jun 2024 05:53:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] SIGIR 和 KDD 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dc5o15/d_sigir_and_kdd_2024/</link>
      <description><![CDATA[大家好！ 还有谁 8 月份要去巴塞罗那参加 SIGIR（在 DC）或 KDD 2024 吗？我是一名工业应用研究员，正在寻找来自美国（尤其是西雅图）的其他人来联系并可能一起去。 [D] 讨论 kdd recsys    提交人    /u/Financial_Bid_2614   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dc5o15/d_sigir_and_kdd_2024/</guid>
      <pubDate>Sun, 09 Jun 2024 22:06:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 为资源受限的设备开发模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dc5273/p_developing_a_model_for_resourceconstrained/</link>
      <description><![CDATA[我正在开发一个项目，我想在 3ds 上生成立体 3d 图像对，以便为不具备此功能的应用程序启用 3d 模式查看。  这是一个可以完成我需要的确切任务的模型，但没有达到我所需的性能：https://github.com/browarsoftware/stereofast 在项目的这个阶段，我已经使用本教程：https://tvm.apache.org/docs/how_to/work_with_microtvm/micro_custom_ide.html 在 3ds 上运行基准测试。教程中使用的模型（Visual Wake Word 模型，用于识别人是否在画面中）需要 125-129 毫秒才能运行。这不是很好。我目前正在将 MiDaS small 256 移植到 3ds 进行基准测试，但我担心 MiDaS 或任何深度估计模型对我的项目来说资源过于密集，因此我考虑设计自己的模型，使其具有一些语义分割或深度估计功能来处理我的硬件限制。 问题是，我不知道在机器学习模型方面哪些操作更耗资源或更少耗资源，所以我决定在这里发帖寻求建议。 如果我设计自己的针对我的用例优化的机器学习模型，那么在保持 OK 性能的同时，模型可以拥有的最大可能功能是什么？我应该考虑什么？  供参考，n3ds 规格：ARM11 MPCore 四核 @ 268MHz（一个为操作系统保留） – 四核 VFPv2 协处理器（矢量处理器） – 256MB FCRAM–  其他 3ds 硬件信息位于此处：https://www.3dbrew.org/wiki/Hardware#Common_hardware    提交人    /u/spogetini   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dc5273/p_developing_a_model_for_resourceconstrained/</guid>
      <pubDate>Sun, 09 Jun 2024 21:40:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于已知 x 的数据分布，求可微函数 y=f(x) 的逆？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dc4xxa/d_invert_differentiable_function_yfx_for_known/</link>
      <description><![CDATA[问题：我有一个可微分（非双射）函数 f，其输入为 x ∈ RT 并产生输出 y ∈ RT，其中每个向量 x 的概率均相等，例如 x_i ∈ [0, 1]。 我的目标：对于给定的 y，我想找到一个满足 y=f(x) 的可能解 x。 我尝试过的方法：我尝试过随机初始化向量 x 并通过梯度下降更新向量，以最小化预测 y 和目标 y 之间的距离 - 尽管这在某些情况下有效，但该方法大多会陷入局部最小值。 接下来的想法：我正在考虑学习和尝试一些生成建模方法，例如扩散或流匹配？虽然我对这些方法大多不熟悉。 问题：我正在寻找解决这个问题的一般技巧和建议——想法、论文、博客文章。谢谢！    提交人    /u/the_real_fishman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dc4xxa/d_invert_differentiable_function_yfx_for_known/</guid>
      <pubDate>Sun, 09 Jun 2024 21:35:11 GMT</pubDate>
    </item>
    <item>
      <title>我的 XTTS 网络屏幕阅读器 [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dc3514/my_xtts_screen_reader_for_the_web_project/</link>
      <description><![CDATA[我一直在做一个项目，一个带有自定义声音的网页屏幕阅读器。我使用 Read Aloud，声音听起来不太好。Edge 中的声音听起来更好，但我真正想要的是我最喜欢的叙述者为我朗读工作电子邮件和 reddit 帖子。它的工作原理是克隆一个大约 30 秒的音频 你可以在这里听到 https://youtu.be/0qcrwc7Dfww?si=vqvuI853_WKRsytF 它的工作原理是启动一个 XTTS 服务器。然后安装我的扩展。我在 GitHub 中有所有的说明。 我发布的版本不附带声音，它是 BYOV。但是它会克隆你输入的声音。所有这些都是使用现有技术在你的家用电脑上完成的，我刚刚为它构建了一个 chrome 扩展。我并没有计划为它发布声音，这些声音必须由用户提供。 此版本在个人电脑上本地运行，但我有一个为我儿子的学校（他患有自闭症）开发的版本，它将基于服务器，因此可以在学校部署，但被锁定，所以孩子们不能随便添加声音。 这是代码 https://github.com/psdwizzard/XTTS-Read-Aloud    提交人    /u/psdwizzard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dc3514/my_xtts_screen_reader_for_the_web_project/</guid>
      <pubDate>Sun, 09 Jun 2024 20:18:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] - 关于 MLOps 的西班牙语视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dby2ab/r_spanish_videos_about_mlops/</link>
      <description><![CDATA[一些关于西班牙语使用者的 MLOps 的有趣视频，我希望该帖子能受到欢迎并且没有违反任何规则 :) ______ 还有一些关于西班牙语使用者的 MLOps 的有趣视频，希望这篇帖子很好看并且不符合标准 :) 网络研讨会 (AI Tech Talk)。更高的 MLOps：提供生产服务 https://www.youtube.com/watch?v=727WIwTTNn8&amp;t=11s 网络研讨会 (AI Tech Talk)。更高的 MLFLow：使用 Databricks 生产 IA https://www.youtube.com/watch?v=DG9VP_Or1Ic 西班牙 AI 网络研讨会如何解决机器学习中的不平衡问题？ https://www.youtube.com/watch?v=DtgKFUpzZHo 加入 subreddit MLOps_Spain！ r/Mlops_Spain   由    /u/nettrotten  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dby2ab/r_spanish_videos_about_mlops/</guid>
      <pubDate>Sun, 09 Jun 2024 16:42:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 微型时间混合器 (TTM)：IBM 强大的零样本预测模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dbt398/p_tiny_time_mixersttms_powerful_zeroshot/</link>
      <description><![CDATA[IBM 推出的全新开源基础时间序列模型： https://aihorizo​​nforecast.substack.com/p/tiny-time-mixersttms-powerful-zerofew?-reml--    提交人    /u/apaxapax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dbt398/p_tiny_time_mixersttms_powerful_zeroshot/</guid>
      <pubDate>Sun, 09 Jun 2024 12:55:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 训练 llama 3 8B 需要多少 VRAM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dbp2sz/p_how_much_vram_i_need_to_train_llama_3_8b/</link>
      <description><![CDATA[您好， 我猜这是一个非常菜鸟的问题，但是找不到答案。 我想使用 llama 3 8b 并使用我的自定义数据增强模型。 我想在我的 Nvidia GPU 上进行本地训练和运行模型。 我现在没有 GPU，只有 mac m2 pro 16Gb，需要知道要购买什么。 我想知道，VRAM 要求是什么？12 GB 可以吗，还是需要 16 GB 的 gpu？或者唯一的方法是 24 GB 4090 之类的东西？    提交人    /u/webdunesurfer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dbp2sz/p_how_much_vram_i_need_to_train_llama_3_8b/</guid>
      <pubDate>Sun, 09 Jun 2024 08:33:20 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 使用上下文学习可以保证 LLM 输出可靠吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dbldwk/discussion_can_we_make_llm_outputs_reliable_when/</link>
      <description><![CDATA[现在，我并不是 LLM 的忠实粉丝，但我发现它们对于诸如通过上下文学习从长文本中提取具有最少标记数据的信息等问题非常有用。但是，结果有时可能不可靠，而且很难说什么时候会发生这种情况。希望了解人们在使用 LLM 时如何确保输出可靠。 PS - 我不是指风险缓解（对于无效输出/有害输出，应使用护栏）。我说的是结果的准确性（提取的信息是有效结果，但可能准确也可能不准确）。    提交人    /u/Either_Pea7803   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dbldwk/discussion_can_we_make_llm_outputs_reliable_when/</guid>
      <pubDate>Sun, 09 Jun 2024 04:29:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 可扩展的无 MatMul 语言建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dbjcbh/r_scalable_matmulfree_language_modeling/</link>
      <description><![CDATA[  由    /u/topcodemangler  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dbjcbh/r_scalable_matmulfree_language_modeling/</guid>
      <pubDate>Sun, 09 Jun 2024 02:33:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>