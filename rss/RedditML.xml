<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 11 Mar 2024 21:14:08 GMT</lastBuildDate>
    <item>
      <title>[R] Llama2 用英语“思考”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcecgu/r_llama2_thinks_in_english/</link>
      <description><![CDATA[https://www.newscientist.com/article/2420973-ai-chatbot-models-think-in-english-even-when-using-other-languages/   由   提交/u/c0d3l1v3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcecgu/r_llama2_thinks_in_english/</guid>
      <pubDate>Mon, 11 Mar 2024 21:04:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 回归的特征选择技术（连续变量）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bce948/d_feature_selection_technique_for_regression/</link>
      <description><![CDATA[大家好， 我需要您在这件事上的专业知识。 我有一些特征，例如预测一个目标变量的 26 个特征。目标变量是一个连续变量，有些特征具有负值，目标变量也是如此。 我正在尝试消除一些特征，也许它会提高我的模型的性能，但到目前为止，大多数特征选择技术仅适用于分类器模型，而不是回归模型。 您建议我可以使用哪些技术来根据特征对回归的重要性来选择/过滤特征模型。   由   提交 /u/emmyhabey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bce948/d_feature_selection_technique_for_regression/</guid>
      <pubDate>Mon, 11 Mar 2024 21:01:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您推荐哪些工具可以让人工智能访问公共领域数据集并生成视觉见解？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcdefi/d_what_are_your_recommended_tools_for_letting_an/</link>
      <description><![CDATA[具体来说，我在大型数据库上释放了一个人工智能，可以提供开箱即用的见解“这里是最重要的&lt;n&gt;”你需要知道的事情”等等，并且可以定制等等。 ​   由   提交/u/bluzkluz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcdefi/d_what_are_your_recommended_tools_for_letting_an/</guid>
      <pubDate>Mon, 11 Mar 2024 20:28:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找具有共享价值查询注意力权重的论文。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcck5w/r_looking_for_paper_with_shared_valuequery/</link>
      <description><![CDATA[我可以发誓我在一年前浏览过一篇论文，该论文展示了变压器的相当可靠的性能，其中值和键（或查询）权重是每个注意力层内相同/共享。我认为 Linformer 做了类似的事情，但我并不是在寻找试图解决注意力的二次运行时间的东西，只是表明你可以通过共享值和键获得合理的结果。它甚至可能在这个 Reddit 子版块中被提及。不知怎的，我似乎找不到它......有人碰巧知道这一点，或者也许知道正确的搜索术语？   由   提交/u/benthe human_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcck5w/r_looking_for_paper_with_shared_valuequery/</guid>
      <pubDate>Mon, 11 Mar 2024 19:56:13 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]LSTM模型可以自己学习特征工程吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bcc2oo/discussion_can_lstm_model_learn_feature/</link>
      <description><![CDATA[我有一个时间序列数据集，我正在其上训练 LSTM 模型以执行多类分类。 我的数据集有 7 列=&gt; x1,x2,x3....x7 并且有 4 个标签 =&gt; f1,f2,f3,f4 由于我对数据集具有领域知识，因此我确切地知道需要完成哪些特征工程。 ​ &lt; p&gt;例如，我需要通过在每一行应用一些规则来从当前功能创建 4 个新功能：-  newx1 由 =&gt; 创建if (x2==x3) then 1, else 0 newx2 由 =&gt; 创建if (x1==x4 and x1&gt;x5) then 1, else 0 newx3 由 =&gt; 创建if ((x1-x6)/x1&gt;x7) then 1, else 0 newx4 由 =&gt; 创建if ((x6-x1)x1/&gt;x7) then 1. else 0  ​ 我在测试数据上获得 100% 的准确度，如果我在 newx1、newx2、newx3、newx4 上训练我的 LSTM 模型。 但是，在原始特征 (x1,x2....x7) 上训练它时，我的准确度降低了 85-90%  我要解决的问题要求我的准确率高于 99%，因此仅 90% 的准确率是不够的。 &amp;# x200b; 我想知道我的 LSTM 模型是否可以自行学习特征工程的规则，或者我是否必须更改我的模型？ ​ 注意：我无法手动应用特征工程规则，因为我正在多个数据集上训练 LSTM 模型，并且每个数据集都需要自己的特征工程规则。我想让它尽可能通用。 ​ LSTM 模型 :- def create_lstm_model(MaxTimeslice, H, LR , num_classes, dropout_rate=0.1, l2_reg=0.001): ip = 输入(shape=(MaxTimeslice, H)) x = LSTM(32, return_sequences=True, dropout=dropout_rate, kernel_regularizer=l2(l2_reg))(ip) x = LSTM(16，dropout=dropout_rate，kernel_regularizer=l2(l2_reg))(x) x = Dense(units=16，activation=&#39;relu&#39;)(x) multiclass_output = Dense(units=num_classes，activation=&#39;softmax&#39;)( x) model = Model(inputs=ip,outputs=multiclass_output) model.compile(loss=&quot;categorical_crossentropy&quot;,metrics=[&quot;accuracy&quot;],optimizer=RMSprop(learning_rate=LR)) 返回模型 &lt; /pre&gt; ​   由   提交 /u/Fearless_Peanut_6092   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bcc2oo/discussion_can_lstm_model_learn_feature/</guid>
      <pubDate>Mon, 11 Mar 2024 19:37:27 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 这是数据泄露的例子吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bca8h7/discussion_is_this_an_example_of_data_leakage/</link>
      <description><![CDATA[我正在开展一个研究项目，使用机器学习来尝试发现基因启动子的模式。我担心我们模型中的数据泄漏，但在我大力推动我的实验室改变我们的方法之前，我需要一些外部意见。也许这个社区中的某人可以帮助我更好地理解这个问题。 我们的机器学习模型是 L1 正则化逻辑回归模型，它使用序列模式作为特征来预测转录起始位点（TSS）的二进制结果）在基因组中。序列模式由上游工具在 TSS 旁边约 1000 个核苷酸的区域中检测到。由于许多 TSS 在基因组中紧密聚集（某些基因具有多个 TSS），因此这些序列区域通常与至少一个其他 TSS 序列区域重叠 &gt; 99%。我担心的是，如果我们对单个 TSS 进行训练/测试分割，我们将会出现数据泄漏，因为训练集中的许多示例将具有与测试集中的至少一个特征向量相关且高度相关的特征向量。我们对序列区域进行分箱只能在一定程度上缓解这种情况，因为偏移 5 nt 或更少的两个 100 核苷酸 (nt) 箱（在我们的数据集中并不罕见）将共享 ≥95% 的序列同一性。 以下几点让我认为我们存在数据泄漏：  我们的特征比示例更多，使得过度拟合变得更容易。在将训练集性能与测试集性能进行比较时，观察到了一点过度拟合。 两个 TSS 的居中、缩放特征的组内平均（在最大 5nt 间隔的连续簇中）皮尔逊相关系数为〜0.99。这不包括自我比较。组之间的平均相关性为 ~-0.0002。大约 35% 的 TSS 位于具有此距离阈值的某个集群中。 当 TSS 按最大 5nt 间隔的邻近度进行聚类时，如果测试集中的 TSS 与测试集中的任何 TSS 分组，则测试集中的 TSS 将被删除。训练集上，通过评估“清理过的”测试集，我们的 auROC 下降了约 3%。这可以用不同的随机种子来重现。如果我们使用 20nt 的阈值，性能会下降约 5%。 当我用随机 DNA 序列而不是基因组来生成特征时，但使用相同的 TSS 位置和整体方法（意味着序列重叠）仍然发生），模型达到了 70% 的 auROC。相比之下，如果我将最大距离为 20 nt 的 TSS 分组，并在进行训练/测试拆分之前删除每组中除一个 TSS 之外的所有 TSS，则我在随机基因组上获得约 53% 的 auROC，更接近于随机分类器。&lt; /li&gt;  我删除太接近的 TSS 的方案无疑是有缺陷的，因为我们失去了宝贵的例子。我认为保留所有 TSS 并按组拆分会更好，同时还能防止数据泄漏。据我了解，这相当于整群抽样，并且类似于患者层面的分裂，因为医学研究人员正在学习如何处理 MRI 切片等数据。在这种情况下，该方案是否无效/有害，或者它是否是防止数据泄露的正确选择？或者我们应该使用另一种分割方案？   由   提交/u/analyze_hunter  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bca8h7/discussion_is_this_an_example_of_data_leakage/</guid>
      <pubDate>Mon, 11 Mar 2024 18:24:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要特征工程连续数值特征的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc8pig/d_need_suggestions_for_feature_engineering/</link>
      <description><![CDATA[      数据集链接 - https:// www.kaggle.com/competitions/playground-series-s4e3 在最近的一次比赛中，我遇到了一个包含连续特征的数据集，为了深入了解它们的分布动态，我生成了两个分布图和箱线图。目标列是分类的，目标是确定与预测缺陷相关的概率，评估指标是 AUC ROC 分数。 采用最少的预处理，我使用爬山集成训练了一个模型，其中包含超参数调整的 XGBoost (XGB) 和 LightGBM 模型。我取得的成绩使我跻身排行榜前 1%。我正在寻求进一步预处理步骤的建议，以提高模型的准确性。   由   提交/u/tushar_mahalya   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc8pig/d_need_suggestions_for_feature_engineering/</guid>
      <pubDate>Mon, 11 Mar 2024 17:24:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] Gemini 1.5 Pro如何回忆10M上下文中的信息？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</link>
      <description><![CDATA[Google 最近发布了技术报告 关于 Gemini 1.5 Pro 及其 10M 上下文。他们简要概述了提高模型长上下文能力的现代方法（例如循环记忆、环形注意力、新颖的架构等），但我没有找到有关 Gemini 1.5 Pro 方法的信息。 有人注意到官方出版物中有关他们方法的信息吗？这对我来说似乎是 Google 的秘密。   由   提交/u/Mulated-Witness-7196   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1ydg/d_how_does_gemini_15_pro_recall_information_in/</guid>
      <pubDate>Mon, 11 Mar 2024 12:26:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] [2403.05468] GPT-4 会运行《DOOM》吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</link>
      <description><![CDATA[ 由   提交/u/blabboy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1uyh/r_240305468_will_gpt4_run_doom/</guid>
      <pubDate>Mon, 11 Mar 2024 12:20:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] ShortGPT：大型语言模型中的层比您预期的更加冗余</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.03853 摘要：  随着大型语言模型（LLM）的性能不断进步，它们的规模显着扩大，当前的法学硕士包含数十亿甚至数万亿的参数。然而，在这项研究中，我们发现LLM的许多层表现出高度相似性，并且某些层在网络功能中发挥的作用可以忽略不计。基于这一观察，我们定义了一个名为区块影响力 (BI) 的指标来衡量法学硕士中每一层的重要性。然后，我们提出了一种直接的修剪方法：层删除，其中我们根据 LLM 的 BI 分数直接删除其中的冗余层。实验表明，我们的方法（我们称之为 ShortGPT）在模型剪枝方面显着优于之前最先进的 (SOTA) 方法。此外，ShortGPT 与类量化方法正交，可以进一步减少参数和计算量。与更复杂的修剪技术相比，通过简单的层删除可以获得更好的结果，这表明模型架构中存在高度冗余。    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc1638/r_shortgpt_layers_in_large_language_models_are/</guid>
      <pubDate>Mon, 11 Mar 2024 11:41:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] MathScale：数学推理的缩放指令调整</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bc0zpo/r_mathscale_scaling_instruction_tuning_for/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.02884 摘要：  大型语言模型（LLM）在解决问题方面表现出了卓越的能力 -解决。然而，他们解决数学问题的能力仍然不足。我们提出了 MathScale，这是一种使用前沿 LLM（例如 GPT-3.5）创建高质量数学推理数据的简单且可扩展的方法。受人类数学学习认知机制的启发，它首先从种子数学问题中提取主题和知识点，然后构建概念图，随后用于生成新的数学问题。 MathScale 沿着我们生成的数学数据集的大小轴展示了有效的可扩展性。因此，我们创建了一个包含 200 万数学问答对的数学推理数据集 (MathScaleQA)。为了全面评价法学硕士的数学推理能力，我们构建了数学应用题基准MwpBench，它是涵盖K-12、大学和竞赛级别的十个数据集（包括GSM8K和MATH）的集合数学问题。我们应用 MathScaleQA 来微调开源 LLM（例如 LLaMA-2 和 Mistral），从而显着提高数学推理能力。在 MwpBench 上进行评估，MathScale-7B 在所有数据集上均实现了最先进的性能，其微观平均准确度和宏观平均准确度分别超过同等大小的最佳同行 42.9% 和 43.7% .    由   提交 /u/SunsetOneSix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bc0zpo/r_mathscale_scaling_instruction_tuning_for/</guid>
      <pubDate>Mon, 11 Mar 2024 11:30:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 立场文件：人工智能代理迈向整体智能 - Microsoft 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbz4z8/r_position_paper_agent_ai_towards_a_holistic/</link>
      <description><![CDATA[      论文：https:/ /arxiv.org/abs/2403.00833  摘要：  大型基础模型的最新进展显着增强了我们对开放世界环境中感官信息的理解。在利用基础模型的力量时，人工智能研究必须摆脱过度还原论，转而强调作为有凝聚力的整体的系统。具体来说，我们强调开发人工智能代理——一种将大型基础模型集成到代理操作中的体现系统。代理人工智能的新兴领域涵盖了广泛的现有体现和基于代理的多模式交互，包括机器人、游戏和医疗保健系统等。在本文中，我们提出了一种新颖的大型动作模型实现体现智能行为，代理基础模型。除此之外，我们还讨论了智能体如何在各种领域和任务中展现出卓越的能力，挑战我们对学习和认知的理解。此外，我们从跨学科的角度讨论智能体人工智能的潜力，强调科学话语中的人工智能认知和意识。我们相信这些讨论可以作为未来研究方向的基础，并鼓励更广泛的社会参与。   https:// /preview.redd.it/h8m0ucns7onc1.jpg?width=1228&amp;format=pjpg&amp;auto=webp&amp;s=1cfc94db64f9f358b07353de285faefa5c8ca1a0 https ://preview.redd.it/rjo7pdns7onc1.jpg?width=927&amp;format=pjpg&amp;auto=webp&amp;s=a0728939d5a83c32811c2efbdff9b5a6d58f023f https://preview.redd.it/ng16dfns7onc1.jpg?width=487&amp;format=pjpg&amp;auto=webp ＆amp; ;s=72c6e46c75328cc39e606f149550c0fbf99115a3   由   提交/u/Singularian2501   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbz4z8/r_position_paper_agent_ai_towards_a_holistic/</guid>
      <pubDate>Mon, 11 Mar 2024 09:26:07 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] [D] NER 中手动标记的替代方案？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbxpsi/discussion_d_any_alternatives_to_manual_labelling/</link>
      <description><![CDATA[问题 -  有 NER 的替代方案吗？ （正则表达式不起作用，因为句子和单词/短语边界没有明确定义）任何无监督/半监督/自监督方法？ 对于标记，是否有手动标记的替代方法？  详细信息： 我有一个关于人物传记的自由文本列，其中包含不同的标识符，例如姓名、身份证号。 、电话号码、电子邮件、出生日期、国籍等。我需要将它们提取到正确的标签下（例如 NAM 代表名称，ID 代表 ID 号等）。每个实体标签可以有多种变体（例如，名称可以出现在“名称：”或“别名：”或“又名：”或“也称为”之后。此外，实体的存在（及其传记中的变体（有些传记只包含姓名、电子邮件和电话号码以及身份证号，很少包含国籍和出生日期）。我正在尝试应用 NER。但是，预训练的 NER 模型不包含我需要的实体，所以我需要用标记数据来训练模型。对于标记，我手动标记了大约 1K 传记 - 相当于 300,000 个标记。如果这些传记的性能不够，将来可能会有更多传记要标记。 .问题是标记是一项超级密集的任务。 我手动标记了 470 个传记，并尝试训练 crf、spacy 的 ner 解决方案和 bert 令牌分类器。对于那些计数的实体，性能较低&lt;1K。我尝试仅选择那些包含要提取的实体的传记进行标记。我尝试过使用CRF模型进行伪标记，但效果不佳。我将无法推送有关 spacy 神童的数据（违反公司政策）   由   提交/u/Ann2_123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbxpsi/discussion_d_any_alternatives_to_manual_labelling/</guid>
      <pubDate>Mon, 11 Mar 2024 07:43:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对比学习的梯度累积（InfoNCE）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbuacq/d_gradient_accumulation_for_contrastive_learning/</link>
      <description><![CDATA[我正在训练多模态对齐模型，但即使使用混合精度训练，我的 GPU 也只能容纳 64 的批量大小。根据 SimCLR 论文，较小的批量大小对于学习而言并不是最佳选择。有什么办法可以在这里实现梯度累积吗？   由   提交/u/Mad_Scientist2027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbuacq/d_gradient_accumulation_for_contrastive_learning/</guid>
      <pubDate>Mon, 11 Mar 2024 04:03:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>