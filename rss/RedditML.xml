<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sat, 08 Mar 2025 06:19:27 GMT</lastBuildDate>
    <item>
      <title>[P] [R] Sannd：使用可训练的迭代器的新神经网络框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j6809q/p_r_sannd_a_new_neural_network_framework_using/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  没有计算图的神经网络？ 神经网络不需要静态图。如果我们使用迭代器而不是张量训练了模型？ 引入sannd（沙盒人工神经网络设计） - 一个新的深度学习框架，其中模型像沙子一样流动。 与Tensorflow/Pytorch不同，Sannd不依赖计算图。取而代之的是，它使用可训练的迭代器（模具）： *动态调制数据流像层一样 *通过反向传播学习和适应 *支持残留网络，LSTMS和元学习的本性学习 📚传统的深度学习框架依靠静态张量和计算图。 SANND提出了一种更轻，更灵活的方法： 残留连接＆amp; LSTM是微不足道的（只是不同的模具链）元学习，在线学习更容易（没有固定结构）自然支持反向传播，而无需明确的图形  🛠️现在尝试一下！ 🔗github： https://github.com/gurumoore/sannd  href =“ https://github.com/gurumoore/sannd/sannd/blob/main/quickstart.md”&gt; https://github.com/gurumoore/gurumoore/sannd/sannd/blob/main/main/quickstart.md.md.md.md 改变我们如何建立神经网络？ 🚀  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j6809q/p_r_r_sannd_a_new_neur_near_neur_network_framework_usey/”&gt; [link]    32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j6809q/p_r_sannd_a_new_neur_neural_neur_network_framework_userwork_usion/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j6809q/p_r_sannd_a_new_neural_network_framework_using/</guid>
      <pubDate>Sat, 08 Mar 2025 03:20:25 GMT</pubDate>
    </item>
    <item>
      <title>热：突出显示的思想链，用于参考输入的支持事实</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j676bx/hot_highlighted_chain_of_thought_for_referencing/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/u/lagitimate-case-3530       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j676bx/hot_highlighted_chain_of_thought_for_referencing/</guid>
      <pubDate>Sat, 08 Mar 2025 02:34:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] Arxiv认可请求AV项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j65qvv/p_arxiv_endorsement_request_for_av_project/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们的研究论文，“知识图作为自动驾驶汽车中材料意识到障碍物处理的世界模型，“ ”已被接受ICLR世界模型工作室2025年。但是，由于会议是非Archival，因此我们计划在ARXIV上发布该会议。我们需要有人认可我们的论文。几位审稿人已经验证了该论文，因此，如果有人可以快速提供认可，那将非常有帮助。 将文章提交给 cs.ai&gt; cs.ai  Arxiv的部分。要告诉我们，您会（或不会）认可此人，请访问以下URL： https://arxiv.org/auth/auth/auth/endorse?x=4Kdyhi  ape and clibe vist y hiv a n y hi. href =“ http://arxiv.org/auth/endorse.php”&gt; http://arxiv.org/auth/endorse.php 并输入以下六二吉特alphanumeric string：认可代码：认可代码：4Kdyhi      &lt;！提交由＆＃32; /u/syaang     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j65qvv/p_arxiv_endorsement_request_for_av_project/</guid>
      <pubDate>Sat, 08 Mar 2025 01:19:38 GMT</pubDate>
    </item>
    <item>
      <title>[d]运行Pytorch CUDA仅在CPU内加速了容器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j640gm/d_running_pytorch_cuda_accelerated_inside_cpu/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是一项有趣的新技术，允许数据科学家在CPU-仅CPU-仅容器内运行带有GPU加速的Pytorch项目 -   [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j640gm/d_running_pytorch_cuda_accelerated_inside_cpu/</guid>
      <pubDate>Fri, 07 Mar 2025 23:53:49 GMT</pubDate>
    </item>
    <item>
      <title>[d]与ML库一起使用Pyspark的最佳实践是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5y3d2/d_what_are_the_best_practices_for_using_pyspark/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我将Pyspark用于项目的数据处理部分，因为我的数据集很大，并且使用Pandas DataFrame会非常慢。 ，但是一旦我的数据准备就绪，我想使用Sklearn的一些方法，例如分层的启动，例如在Pyspark.ml上都无法使用。我考虑过将Pyspark数据框架转换为熊猫的数据框架，然后使用Sklearn和其他ML库从那里转换为从那里转换为非常昂贵的部分，并且导致内存错误  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/amirdol7     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5y3d2/d_what_are_the_best_practices_for_using_pyspark/</guid>
      <pubDate>Fri, 07 Mar 2025 19:40:48 GMT</pubDate>
    </item>
    <item>
      <title>[D]是否可以在AMD的Ryzen 7 Ai NPU上进行机器学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5wmfz/d_is_it_possible_to_do_machine_learning_on_amds/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我还没有找到太多有关我是否可以使用tensorflow或pytorch的DL库，以及与AMD的ryzen 7处理器一样，我发现的很少的信息有点令人困惑。我已经看过Rocm，Ryzenai，甚至DirectML，但到目前为止似乎找不到直接的答案。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/marco_camilo     [link]   [commist]         ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5wmfz/d_is_it_possible_to_do_machine_learning_on_amds/</guid>
      <pubDate>Fri, 07 Mar 2025 18:50:24 GMT</pubDate>
    </item>
    <item>
      <title>[R]研究比较良性与故障的DNN中间层输出分布的研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5vhdj/r_research_on_comparing_benign_vs_faulty_dnn/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我是DNN的新手，并正在寻找有关比较良性（正确）和故障DNN模型之间的中间层输出分布以通过分配移位来检测故障的研究。您可以推荐任何论文或资源吗？ 预先感谢。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/usef_cut_4452     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j5vhdj/r_research_on_comparing_benign_vs_faulty_dnn/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5vhdj/r_research_on_comparing_benign_vs_faulty_dnn/</guid>
      <pubDate>Fri, 07 Mar 2025 18:07:32 GMT</pubDate>
    </item>
    <item>
      <title>[d]量化礁石框架的计算效率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5rnui/d_quantifying_the_computational_efficiency_of_the/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5rnui/d_quantifying_the_computational_efficiency_of_the/</guid>
      <pubDate>Fri, 07 Mar 2025 15:54:54 GMT</pubDate>
    </item>
    <item>
      <title>[d]寻求新的方法来分类和诊断小儿胸部X射线中多种疾病</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5mwb8/d_seeking_novel_approaches_for_classifying/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我有一个建议分类和诊断小儿胸部X射线中多种疾病的建议。我计划在此项目中使用Extricnet，但是我需要一种新颖的方法，例如混合方法或任何新方法。您可以建议什么吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/_ajing     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5mwb8/d_seeking_novel_approaches_for_classifying/</guid>
      <pubDate>Fri, 07 Mar 2025 12:55:15 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何将本地/本地培训和规模缩小到云？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5lkw9/d_how_do_you_orchestrate_onpremlocal_training_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在为一家专门从事kubernetes的公司工作，我试图更好地了解ML研究人员和工程师如何使用本地/本地GPU和公共云资源的混合。   似乎是一种常见的模式来进行“在桌子下进行较大的gpus”，以进行较大的培训，然后训练，然后进行范围或培训，然后进行范围或范围，以弥补云或云量。但是，在实践中设置的设置有多普遍？ 如果您使用这样的混合方法： 您是否有自动化的工作流程以在本地和云环境之间移动？ 哪些工具或平台对您有效吗？在这些情况下，像Zenml这样的MLOPS工具可以帮助？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ml_yegor     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j5lkw9/d_how_do_do_do_you_orchestrate_onpremlocal_training_and/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5lkw9/d_how_do_you_orchestrate_onpremlocal_training_and/</guid>
      <pubDate>Fri, 07 Mar 2025 11:41:47 GMT</pubDate>
    </item>
    <item>
      <title>[r]杂交：结合术前和后场，以进行更稳定和有效的变压器训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5l9mk/r_hybridnorm_combining_prenorm_and_postnorm_for/</link>
      <description><![CDATA[I&#39;ve been experimenting with various normalization techniques in transformers lately, and this new HybridNorm approach seems like a particularly elegant solution to the speed vs. stability tradeoff. The core idea is surprisingly simple but effective: use Layer Normalization after attention sublayers (where stability matters most) and use RMS Layer Normalization everywhere else (where we can benefit from its computational efficiency). Key technical points: - The post-attention sublayer is much more sensitive to normalization type than other positions - Using RMSNorm in non-critical positions reduces computation without compromising stability - Implementation requires minimal code changes to existing transformer architectures - HybridNorm delivers 13-17% training speedup compared to standard LayerNorm - Performance跨基准任务（胶水，小队，机器翻译）维护 - 在不同的模型量表（0.1b至3B参数）上始终如一地工作 - 与仅编码器，仅解码器和编码器decoder-decoder Architectures  兼容。 13-17％的加速可能听起来并不革命性，而是应用于大规模训练，这是零质量折衷的大量计算节省。本文还暗示了一个更广泛的机会 - 仔细分析哪些组件需要完全稳定，而我们可以优化速度。   特别有用的是该技术如何与现有架构无缝集成。您无需重新设计模型 - 只需在特定位置交换标准化层即可。从本质上免费获得提高效率的一个难得的案例。“  发现变压器中不同位置具有不同稳定性要求的发现为为什么在数学上发生这种情况的情况都打开了有趣的问题。我很想看到后续工作更深入地探索这一现象。  tldr：杂交从策略上结合了变压器模型中的分层和rmsnorm，将注意力越来越稳定的分层放置在注意力下的分子和更快的rmsnorm之后。这种简单的更改可提供13-17％的速度，而不会影响模型质量。 全部总结。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5l9mk/r_hybridnorm_combining_prenorm_and_postnorm_for/</guid>
      <pubDate>Fri, 07 Mar 2025 11:21:14 GMT</pubDate>
    </item>
    <item>
      <title>[d]一个负面结果：中间训练中的重量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5kovb/d_a_negative_result_untying_weights_midtraining/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hey  r/machinelearning ， 我是Milan的Milan of Postdoc in Milan，主要是在ML上工作，专注于这些天来嵌入这些天。最近，我遇到了一个负面的结果，并决定撰写有关它的博客文章。幸运的是，我花了很长时间才意识到我的想法不会像预期的那样工作。因此，如果您想浪费五分钟，这是帖子： link 。为了使数据运行良好，有关数据的某些假设必须保留（我们的 paper 讨论了这一点）。幸运的是，这些假设对于自然语言似乎很好，这解释了为什么体重绑扎是有效的。 但是，它们并不严格存在。所以我想知道：如果我们仅在一开始就绑住嵌入，然后我们将它们解开训练中的训练怎么办？这个想法是，早期的重量绑定可以帮助编码语义知识，同时避免稍后的限制性假设（有关“在此博客中”的“更多有关”博客它的期望至少有一个很小但明显的改进。但是...不。任何进步几乎都看不到 - 您必须真正放大地块才能看到任何有意义的东西。 我觉得一直在发生负面结果，但是没人真正谈论它们。所以我在这里。您怎么看？ 如果您很好奇，则是代码： github 。提交由＆＃32; /u/u/f14-bertolotti     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5kovb/d_a_negative_result_untying_weights_midtraining/</guid>
      <pubDate>Fri, 07 Mar 2025 10:41:47 GMT</pubDate>
    </item>
    <item>
      <title>[D]学习如何与LLM构建的最佳资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5jlae/d_best_resources_to_learn_how_to_build_with_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最佳资源或课程是什么，特别是针对在数据科学领域中拥有丰富知识的人，精通一般的ML/DL原则，但是现在希望进入LLMS世界？    &lt;！ -  sc_on--&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j5jlae/d_best_resources_to_to_lealed_how_to_build_with_with_with_llms/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j5jlae/d_best_resources_to_to_to_lealed_how_to_build_build_with_with_lls/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5jlae/d_best_resources_to_learn_how_to_build_with_llms/</guid>
      <pubDate>Fri, 07 Mar 2025 09:25:00 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1hc0o/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Mar 2025 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些经验丰富的人。   &lt;！ -  sc_on--&gt; 32;&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>