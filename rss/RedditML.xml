<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Thu, 20 Feb 2025 01:16:04 GMT</lastBuildDate>
    <item>
      <title>[d]证明ddpm后部有正确的边缘</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itlp1d/d_proof_that_ddpm_posterior_has_correct_marginal/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我想知道是否有证据表明DDPM后验有x  t〜p（x_t | x_0）和最佳噪声预测器e [epsilon_t | x_t]边缘化到正确的x_0条件分布p（x  {t-1} | x_0）。  这种证明是否存在？我试图更好地理解DDPM，并且在几篇论文中看到了这个结果，但我无法证明这一点。很容易进入边缘化步骤（这是高斯人的卷积），但是我看不出e [epsilon  t | x_t]术语在p（x 的最终统计数据中都消失了{t-1} | x_0）表明分布是正确的。提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1itlp1d/d_proof_that_that_that_that_ddpm_posterior_has_has_chcorrect_marginal/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1itlp1d/d_pofor_that_that_that_ddpm_posterior_has_correct_marginal/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itlp1d/d_proof_that_ddpm_posterior_has_correct_marginal/</guid>
      <pubDate>Thu, 20 Feb 2025 00:46:02 GMT</pubDate>
    </item>
    <item>
      <title>[d]检索增强一代的未来是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itl38x/d_what_is_the_future_of_retrieval_augmented/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  抹布令人怀疑。关于使用一束传统的IR技术来获取及时的上下文。这让我想起了Netflix在互联网足以流式传输之前必须邮寄DVD。 我无法想象以后使用数据库的LLMS。为什么不在推理期间而不是以前的检索呢？例如。如果数据库直接嵌入了KV缓存中，则可以像其他所有内容一样通过梯度下降来检索。至少对我来说，这似乎比使用（低精确）嵌入搜索来收集上下文并将其塞入提示中。 。有 Lost-In-in-the-the-the-Middle效果，和上下文污染的风险，即使所有这些都会降低性能，即使所有这些都会降低性能还存在正确的上下文。推理性能也随着更多上下文的添加。   无论未来如何，我的感觉是抹布将在几年内变得过时。大家怎么想？ 编辑： DeepMind的复古和 self-rag 是 学习检索的一些示例实现。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/jsonathan     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itl38x/d_what_is_the_future_of_retrieval_augmented/</guid>
      <pubDate>Thu, 20 Feb 2025 00:17:48 GMT</pubDate>
    </item>
    <item>
      <title>[r]错误分析可视化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itfscq/r_error_profiling_visualization/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我目前正在从事我的博士学位研究，我很想对我们一直在开发的事情有所了解。作为我项目的一部分，我们创建了一种新的错误分析可视化技术，旨在帮助我们更好地了解机器学习模型如何预测患者的结果。 的目标是提供更清晰，更可行的观点患者模型出错，这在医疗保健应用中确实很有价值。为了获得一些反馈，我们整理了一项调查，其中包括案例研究，以使您了解该技术在实践中的工作方式。 如果您有兴趣可以看一看并分享您的意见。当我们继续完善工具时，您的输入将非常有帮助！ 这是调查的链接：   https://uclahs.az1.qualtrics.com/jfe/jfe/jfe/sv_eaea6wu9szozoeg1e      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/alphamachinehodl     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itfscq/r_error_profiling_visualization/</guid>
      <pubDate>Wed, 19 Feb 2025 20:32:30 GMT</pubDate>
    </item>
    <item>
      <title>[D]在2025年从张力流到Pytorch的过渡：生态系统问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itbqwn/d_transitioning_from_tensorflow_to_pytorch_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  自2017年以来使用Tensorflow后，我终于将切换到Pytorch。尽管核心框架非常相似（原始的Pytorch代码更改是最小的），但我发现最大的区别是工具和附加组件的生态系统。 到目前为止，我已经遇到了：    hydra-用于配置管理和实验跟踪  pytorch Lightning-似乎抽象的类似凯拉斯的包装器Berierplate   MMDetection-对于对象检测任务  对于那些进行过类似过渡或经验丰富的Pytorch用户的人：您的首选堆栈是什么？您如何构建训练循环？您发现哪些工具（或其他工具）特别有价值或值得避免？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rsandler     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itbqwn/d_transitioning_from_tensorflow_to_pytorch_in/</guid>
      <pubDate>Wed, 19 Feb 2025 17:52:41 GMT</pubDate>
    </item>
    <item>
      <title>[D]数据清洁疼痛点？以及如何解决它们</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1itahgm/d_data_cleaning_pain_points_and_how_you_solve_them/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好，大家。 我是数据空间的新手。当我与数据分析师/科学家/工程师的人聊天时，一个反复出现的批评是数据清洁需要多少时间和精力。他们描述的一些疼痛点包括：  企业需要很长时间才能访问数据见解。  数据不及时支持决策。   在处理丢失的数据时，很难确定数据点还是其值是更重要。 数据清洁很长，乏味且重复。  我很好奇，如果你们同意，以及您遇到的其他主要问题变得干净和结构化数据？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/salvadorr16     [links]       &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1itahgm/d_data_cleaning_poin_points_pointss_and_how_you_solve_solve_solve_them/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1itahgm/d_data_cleaning_pain_points_and_how_you_solve_them/</guid>
      <pubDate>Wed, 19 Feb 2025 17:03:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] Scikit指纹 - 用于计算分子指纹和分子ML的库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it9xxq/p_scikitfingerprints_library_for_computing/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   tl; dr我们写了一个用于计算分子指纹＆amp＆amp;相关任务与Scikit-Learn接口兼容， scikit-fingerprints 。     是分子指纹吗？  用于矢量化学分子的算法。分子（原子和键）进入，特征向量熄灭，准备分类，回归，聚类或任何其他ML。这基本上将图形问题变成了表格问题。分子指纹非常有效，并且是ML分子ML，药物设计和其他化学应用的主食。了解更多在我们的教程中/strong&gt;    - 完全兼容Scikit-Learn，您可以通过解析来构建完整的管道分子，计算指纹，用于训练分类器并部署它们  -35指纹，是开源Python生态系统中最大的数量   - 许多其他功能，例如。分子过滤器，距离和相似性（在Numpy/Scipy阵列上工作），分裂数据集，超参数调谐以及更多   - 基于RDKIT（标准化学化形式图库），可与其整个生态系统互操作  p&gt;  - 可与PIPI的PIP一起安装，并带有文档和教程，易于启动   - 设计良好，带有高测试覆盖范围，代码质量工具，CI/CD和一组维护者  为什么不gnns？  图形神经网络仍然是一个新的事情和他们的预训练特别具有挑战性。我们已经看到了很多有趣的模型，但是在实用的药物设计问题中，它们仍然经常表现不佳（例如，参见我们的肽基准）。 gnns可以是与指纹结合，和分子指纹可以是用于预读。例如，夹具模型（ICML 2024）实际上使用指纹用于分子编码，而不是GNNS或其他预处理的模型。 ECFP指纹仍然是许多（甚至大多数分子属性预测/QSAR问题）的主食，也是一个很好的解决方案。  有些背景    i &#39;在计算机科学上获得博士学位，图形和分子的ML。我的硕士论点是关于分子特性预测的，我希望分子指纹作为实验的基准。原来，他们真的很棒，实际上胜过GNN，这很令人惊讶。但是，使用它们确实是不便的，我认为许多ML研究人员由于用途而省略了它们。因此，我受够了，得到了一群学生，我们为此写了一个完整的图书馆。该项目已经开发了大约两年，现在我们拥有一个完整的研究小组，正在研究带有Scikit指纹的开发和实际应用。您还可以在SoftwareX中阅读我们的论文（开放访问）： https://www.sciendirect.com/science.com/science/article/article/article/article/article/article/article/article/article/article/ /pii/s2352711024003145 。  了解更多  我们有完整的文档，也有教程和示例， https://scikit-fingerprints.github.io/scikit-fingerprints/ 。 We also conducted introductory molecular ML workshops using scikit-fingerprints: https://github.com/j-adamczyk/molecular_ml_workshops.  我很高兴回答任何问题！如果您喜欢该项目，请在Github上给它一颗星星。我们欢迎贡献，拉请求和反馈。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/qalis     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it9xxq/p_scikitfingerprints_library_for_computing/</guid>
      <pubDate>Wed, 19 Feb 2025 16:42:32 GMT</pubDate>
    </item>
    <item>
      <title>[P]破坏语言障碍：印地语的微调耳语</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it99pb/p_breaking_language_barriers_finetuning_whisper/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hindi的低语，这是Openai Whisper的微调版本，专为印地语自动语音识别（ASR）设计。使用2500小时的印地语语音数据和像归一化的创新技术，该模型为印地语ASR设定了新的基准。  https://www.collabora.com/news-and-blog/news-and-events/breaking-language-barriers-fine-tuning-whisper-for-for-hindi.hti.html    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/mfilion     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it99pb/p_breaking_language_barriers_finetuning_whisper/</guid>
      <pubDate>Wed, 19 Feb 2025 16:15:42 GMT</pubDate>
    </item>
    <item>
      <title>[r]扩散是解决高效RNN的解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it790b/r_diffusion_is_the_solution_for_efficient_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我表明扩散核捕获全局依赖性，并且具有复发结构的简单扩散内核在更少的参数和flops中优于变形金刚。    https://arxiv.org/abs/2502.12381      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1it790b/r_diffusion_is_is_solution_solution_solution_for_for_ffidice_and/”&gt; [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it790b/r_diffusion_is_the_solution_for_efficient_and/</guid>
      <pubDate>Wed, 19 Feb 2025 14:51:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] Paperstok -AI Arxiv论文，带有像UX这样的Tiktok</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it6x9a/p_paperstok_ai_arxiv_papers_with_a_tiktok_like_ux/</link>
      <description><![CDATA[    &lt;！ -  sc_off-&gt;  启动一个有趣的侧面项目，以预览与AI相关的Arxiv论文，具有Tiktok，例如经验，称为 paperstok （&lt;一个href =“ https://papers.infitok.com”&gt; https：//papers.infitok.com ）。每天都在Arxiv上进行，跟上最新进展提出了重大挑战。其中之一是围绕Arxiv Web界面导航的困难，必须不断打开和关闭新标签，以浏览标题和摘要。如果有一种更简单，有趣的方法来做到这一点怎么办？ “ https://papers.infitok.com”&gt; Paperstok 滚动浏览与AI相关的ARXIV提交。它具有乳胶支持渲染数学方程。它还提供了将您觉得有趣的论文添加书签的能力。我打算在未来几天添加更多功能，以增强通过论文浏览的体验。 我要求社区强调他们目前面临的挑战，这些挑战可以通过此工具来缓解。非常感谢您的宝贵反馈和评论。请随意DM或在 x 或在Reddit上。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pranftw   href =“ https://www.reddit.com/r/machinelearning/comments/1it6x9a/p_paperstok_ai_arxiv_paper_papers_awith_a_a_tiktok_like_like_ux/  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it6x9a/p_paperstok_ai_arxiv_papers_with_a_tiktok_like_ux/</guid>
      <pubDate>Wed, 19 Feb 2025 14:36:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] Mamba：我们可以实现无限的上下文长度吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1it279f/r_mamba_can_we_achieve_infinite_context_length/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;  新博客out！ 我讨论了mamba，一类序列建模的状态空间模型，并解释变压器，RNN和状态空间模型的基础知识以及它们的局限性。然后，博客探讨了S6模型（选择性扫描结构化状态空间序列模型）如何在建模长序列时提供优势。 长上下文长度（达到数十亿个标记）对于LLMS至关重要。它们使推理能够在扩展的历史上进行推理，同时解决了基于抹布的方法和“中间丢失”问题等挑战。但是，由于变压器中自我注意的二次计算成本，无限的上下文长度仍然具有挑战性。  mamba的线性时间复杂性提出了潜在的解决方案。 Falcon-Mamba可以在不增加内存使用情况的情况下处理任何长度的序列（如图所示）。 p&gt; 在此处查看完整博客 - ＆gt;  https://pranaval.github.io/projects/projects/projects/project2.html2.html 编写这些博客以对这些有趣的概念有很好的了解。如果时间允许，我希望最终将它们编译成一本书。总是欢迎反馈和批评。 网页 - ＆gt;  https://pranaval.github.io/      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/personal_click_6502     [link]   [注释] /table&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1it279f/r_mamba_can_we_achieve_infinite_context_length/</guid>
      <pubDate>Wed, 19 Feb 2025 10:14:04 GMT</pubDate>
    </item>
    <item>
      <title>[d]在深度学习备忘单上应该找到哪些常见的实施技巧或陷阱？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iszjp1/d_what_are_the_common_implementation_tips_or/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在谈论事物的工程方面。假设您有一个想法要实现。由于深度学习仍然不是一门精确的科学学科，因此在试用和实施错误时，很容易开枪射击自己，并且错误地说服您的想法不值得。 ，因此从实施中开始透视图，某人在使用深度学习模型时绝对或不做什么？ 例如还可以随意发布链接到您在此上下文中真正有用的任何内容。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iszjp1/d_what_are_are_the_common_implementation_tips_or/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iszjp1/d_what_are_the_common_implementation_tips_or/</guid>
      <pubDate>Wed, 19 Feb 2025 07:04:18 GMT</pubDate>
    </item>
    <item>
      <title>[r] LLMS中深度的诅咒：为什么深层效果降低？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isu1nn/r_the_curse_of_depth_in_llms_why_are_deep_layers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近的研究揭示了现代大语言模型中意外的问题，较深的层没有提高自己的体重。 最近的一篇论文＆quot&#39;大语模型中的深度诅咒“ &lt; /em&gt;”突出了一个关键问题：  -  LLM中的深层对学习的贡献明显少于早期。&lt; - 这些层中的许多层都可以在没有严重的性能损失的情况下进行修剪，从而提出了有关训练效率的问题。  - 罪魁祸首？前层归一化（PRE-LN）会导致输出方差在更深的层中爆炸，从而使它们的作用几乎像身份功能。  - 一个简单的修复？控制这一差异并提高训练效率的分层缩放。 这对LLM体系结构，培训效率和缩放定律具有重大影响。如果诸如Llama，Mistral和DeepSeek之类的模型中的一半层没有有效贡献，我们要处理多少计算浪费？&lt; /p&gt; 关键问题进行讨论：1️）我们应该重新思考）深层培训策略以提高效率吗？2️）这会影响到变压器体系结构中更深入=更好的假设吗？3️）本文的见解可以帮助您LLM压缩，微调或蒸馏技术？ 纸链接： arxiv preprint：25057955V1   p&gt; 让我们讨论一下 - 您对深度诅咒的想法是什么？  &lt;！ - sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pseud0nym    href =“ https://www.reddit.com/r/machinelearning/comments/1isu1nn/r_the_curse_curse_of_depth_in_in_in_in_llms_why_are_are_are_deep_layers/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1isu1nn/r_the_curse_curse_of_depth_in_in_in_in_in_llss_why_are_are_are_are_are_deep_deep_deep_layers/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isu1nn/r_the_curse_of_depth_in_llms_why_are_deep_layers/</guid>
      <pubDate>Wed, 19 Feb 2025 02:02:05 GMT</pubDate>
    </item>
    <item>
      <title>[R]评估现实世界软件工程任务的LLM：一项耗资100美元的基准研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1isbo6t/r_evaluating_llms_on_realworld_software/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  旨在评估现实世界软件工程任务上LLM的新基准测试，直接从附上的“实际美元”值中拉出。该方法涉及收集1,400多个任务，从$ 50- $ 32,000的支出，创建标准化的评估环境以及测试编码能力和工程管理决策。 关键技术要点： - 通过单位测试，专家测试验证任务验证和与人类解决方案的比较 - 评估使用Docker容器来确保测试环境 - 包括直接编码任务和高级工程管理决策 - 任务涵盖Web开发，移动应用程序，数据处理和系统体系结构 - 总任务价值超过100万美元的实际自由付款 我认为，此基准是我们评估LLM的重要转变世界应用。通过将绩效直接与经济价值联系起来，我们可以更好地了解当前能力和实用程序之间的差距。较低的成功率表明，在LLM可以可靠地处理专业软件工程任务之前，我们需要取得重大进展。 我认为，包括管理级别的决策尤其有价值，因为它可以测试技术理解和战略思维。这可以有助于指导开发更完整的工程辅助系统。  tldr：新的基准测试在实际$ 1M+的UPWORK编程任务上进行LLMS。当前模型在很大程度上挣扎，仅完成约10％的编码任务和约20％的管理决策。  完整的摘要在这里。纸在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1isbo6t/r_evaluating_llms_on_realworld_software/</guid>
      <pubDate>Tue, 18 Feb 2025 12:35:00 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客等对于产品和服务。 请不要发布链接缩短器，链接聚合器网站或自动订阅链接。    任何滥用信托的滥用都会领导禁止。 鼓励其他人创建新帖子，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。   元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iqiy4x/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iqiy4x/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 16 Feb 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子的人，以便在此处发布问题！ 线程将活着直到下一个，所以请继续发布标题的日期。 感谢大家回答问题在上一个线程中！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1ilhw29/d_simple_questions_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>