<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 07 Oct 2024 01:17:10 GMT</lastBuildDate>
    <item>
      <title>[D] 关于工具使用和 LLM 代理有哪些有趣的论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxvsp7/d_what_are_some_interesting_papers_about_tooluse/</link>
      <description><![CDATA[目前，我正在研究 voyager (https://arxiv.org/abs/2305.16291)，但希望得到更多建议。TIA。    提交人    /u/a1_jakesauce_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxvsp7/d_what_are_some_interesting_papers_about_tooluse/</guid>
      <pubDate>Mon, 07 Oct 2024 01:04:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML 论文的敏感性分析获得了更好的结果，现在怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxu3zw/d_sensitivity_analysis_of_the_ml_paper_got_better/</link>
      <description><![CDATA[我使用一种新方法针对特定数据集撰写了一篇 ML 论文，取得了一些积极成果。我训练了几个模型，对它们进行了评估，并根据研究结果进行了广泛的解释和讨论。其中一位审稿人要求对一些预处理参数/算法进行敏感性分析。有趣的是，其中一项更改导致的结果比我原来的方法略好。 我的问题是：在这种情况下的期望是什么？我需要重写整篇论文，还是应该仅在敏感性分析中报告这一观察结果？虽然更改改善了结果，但想到要根据新的运行重写大部分解释（例如，特征重要性、图表、讨论等），还是很令人沮丧。你的想法和经验是什么？    提交人    /u/anagreement   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxu3zw/d_sensitivity_analysis_of_the_ml_paper_got_better/</guid>
      <pubDate>Sun, 06 Oct 2024 23:37:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 有没有想过在你的 m1 16gb ram Mac 上微调 Xtts？好吧，我不知道为它做了一个 repo，</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxt77o/p_ever_wanted_to_fine_tune_xtts_on_your_m1_16gb/</link>
      <description><![CDATA[   https://github.com/DrewThomasson/finetuneXtts_apple_silicone 你需要 16 gb ram 来运行，而 docker 版本需要更多的 ram 来运行 :/ 压缩模型按钮中的 Final_output_files 与 https://github.com/DrewThomasson/ebook2audiobookXTTS 兼容   由   提交  /u/Impossible_Belt_7757   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxt77o/p_ever_wanted_to_fine_tune_xtts_on_your_m1_16gb/</guid>
      <pubDate>Sun, 06 Oct 2024 22:51:36 GMT</pubDate>
    </item>
    <item>
      <title>上下文感知词语替换 [P] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxsuhg/context_aware_word_replacement_p_r/</link>
      <description><![CDATA[你好！ 我从事 CV 研究，所以对 NLP 不是很精通，所以需要输入。 我正在研究在保留图片上下文的情况下替换“句子”中的“单词”，以便我们更容易在数据集中搜索该单词的合适图像。例如： 句子 - “学生应该抵制网络欺凌，以免攻击者伤害他们” 单词 - “攻击者” 为什么预期 - 网络犯罪分子、网络欺凌者等，以便我可以搜索相关图像。 BeRT 和其他模型用什么来替换它 - 恐怖分子、计算机、敌对攻击者等。 我想在本地运行一些东西，但找不到任何解决方案。有什么想法或输入我应该尝试吗？有任何资源或代码笔记本吗？    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxsuhg/context_aware_word_replacement_p_r/</guid>
      <pubDate>Sun, 06 Oct 2024 22:34:34 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 使用语言模型优化神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxs6t2/project_optimizing_neural_networks_with_language/</link>
      <description><![CDATA[Dux 是一个基于 GPT-4o-mini 的元优化器，可以实现神经网络的自适应优化——希望得到反馈！ 论文：https://aarushgupta.com/dux.pdf 代码：https://github.com/bxptr/dux PS。如果有人能在 arXiv 上为我推荐，我将不胜感激！    提交人    /u/theaarushgupta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxs6t2/project_optimizing_neural_networks_with_language/</guid>
      <pubDate>Sun, 06 Oct 2024 22:03:40 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 如何从参考列表中将产品的多种变体映射到其正确的标准名称？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxs3i4/project_how_to_map_multiple_variations_of_a/</link>
      <description><![CDATA[我使用经过微调的 BERT 模型执行命名实体识别，并成功从非结构化数据集中提取了产品名称、数量和价格。但是，产品名称有变体，现在我需要将这些变体与参考列表中的正确标准化名称进行匹配。我可以使用哪些可能的方法来完成这项任务，每种方法的优缺点是什么？我考虑将其视为一个多类分类问题，其中使用 BERT 或 GPT-4 等模型将每个产品名称变体分类为预定义的标准名称之一。    提交人    /u/No_Possibility_7588   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxs3i4/project_how_to_map_multiple_variations_of_a/</guid>
      <pubDate>Sun, 06 Oct 2024 21:59:33 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 为什么正弦 PE 不适用于较长的序列？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxmn0z/discussion_why_dont_sinusoidal_pe_work_for_longer/</link>
      <description><![CDATA[从理论上讲，它们会生成独特的位置向量，然后将其添加到嵌入中，因此它们应该可以工作。有人知道为什么它们不起作用吗？    提交人    /u/tororo-in   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxmn0z/discussion_why_dont_sinusoidal_pe_work_for_longer/</guid>
      <pubDate>Sun, 06 Oct 2024 18:03:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</guid>
      <pubDate>Sun, 06 Oct 2024 15:00:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 LLM 培训中，增加批次大小和使用注意力掩蔽的打包序列有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxguh6/d_whats_the_difference_between_increasing_batch/</link>
      <description><![CDATA[我很好奇在固定长度序列上训练大型语言模型 (LLM) 时，以下两种方法之间的区别： 使用批量大小 = 4，其中每个样本的序列长度为 1024 个标记，并且它们被独立处理。将 4 个序列打包成一个批次，最大序列长度为 4096，并应用注意掩码以确保没有序列关注来自另一个序列的标记。 如果正确应用了注意掩码，确保不会关注其他序列，那么这两种方法在以下方面是否存在显着差异： 内存使用情况 计算成本 训练动态  据我所知，如果没有注意掩码，由于自注意力机制，打包会导致计算成本呈二次方增加。但是使用掩码后，计算和内存使用量不是与将它们作为批处理中的单独序列处理几乎相同吗？还是我遗漏了其他因素？    提交人    /u/JeanMichelRanu   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxguh6/d_whats_the_difference_between_increasing_batch/</guid>
      <pubDate>Sun, 06 Oct 2024 13:46:13 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 在包含成本估算的文档上对 BERT 进行微调的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxgsoa/project_ideas_for_finetuning_bert_on_documents/</link>
      <description><![CDATA[大家好，我正在做一个项目，需要对包含成本估算的文档进行 NER。具体来说，我必须提取产品名称、价格及其数量。我原本想使用预先训练好的 BERT，但显然进行一些微调是最佳的。你有什么处理这个问题的建议吗？谢谢！    提交人    /u/No_Possibility_7588   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxgsoa/project_ideas_for_finetuning_bert_on_documents/</guid>
      <pubDate>Sun, 06 Oct 2024 13:43:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] MaskBit：通过 Bit Tokens 生成无嵌入图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxfy91/r_maskbit_embeddingfree_image_generation_via_bit/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxfy91/r_maskbit_embeddingfree_image_generation_via_bit/</guid>
      <pubDate>Sun, 06 Oct 2024 13:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 什么时候 Lora 不够好？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwqgfx/d_when_is_lora_not_good_enough/</link>
      <description><![CDATA[在 LLM 微调任务中，LORA（或其某些变体）不够好，需要进行全面微调，这方面有哪些例子？ 例如，在所有测试任务中，RoSA（LORA 变体）与全面微调一样好 https://arxiv.org/pdf/2401.04679    提交人    /u/osamc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwqgfx/d_when_is_lora_not_good_enough/</guid>
      <pubDate>Sat, 05 Oct 2024 13:30:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从头开始​​实现 Llama 3.2 1B 和 3B 架构（独立的 Jupyter Notebook）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwq5su/p_implementing_the_llama_32_1b_and_3b/</link>
      <description><![CDATA[    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwq5su/p_implementing_the_llama_32_1b_and_3b/</guid>
      <pubDate>Sat, 05 Oct 2024 13:15:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] Meta 发布少于 400 亿个参数的 SOTA 视频生成和音频生成。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fwic4m/r_meta_releases_sota_video_generation_and_audio/</link>
      <description><![CDATA[      今天，Meta 发布了一套 SOTA 文本转视频模型。这些模型足够小，可以在本地运行。他们似乎不打算发布代码或数据集，但他们几乎提供了模型的所有细节。事实上，这个模型已经如此连贯，这确实表明开发正在发生得有多快。 https://ai.meta.com/research/movie-gen/?utm_source=linkedin&amp;utm_medium=organic_social&amp;utm_content=video&amp;utm_campaign=moviegen 这套模型（Movie Gen）包含许多模型架构，但看到通过声音和图片同步进行训练非常有趣。从训练的角度来看，这实际上非常有意义。 https://preview.redd.it/047ddxdb7vsd1.png?width=1116&amp;format=png&amp;auto=webp&amp;s=a7cd628a8b2dde9824b27983a430217123c297d8    提交人    /u/AIAddict1935   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fwic4m/r_meta_releases_sota_video_generation_and_audio/</guid>
      <pubDate>Sat, 05 Oct 2024 04:26:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>