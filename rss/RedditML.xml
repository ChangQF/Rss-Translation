<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 16 Dec 2024 09:20:07 GMT</lastBuildDate>
    <item>
      <title>[R] 量化/可视化 lstms 中的遗忘门、输入门和输出门的活动，以便于解释。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hfcbzl/r_quantifying_visualizing_the_activity_of_the/</link>
      <description><![CDATA[是否有工作量化了出于可解释性原因在 lstms 或 gru 模型中遗忘和保留了多少信息。例如，有趣的是，看看模型是否在某些示例中更多地使用隐藏向量，而不是其他示例，这显示出在某些示例中对过去信息的更多需求。     提交人    /u/Sandy_dude   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hfcbzl/r_quantifying_visualizing_the_activity_of_the/</guid>
      <pubDate>Mon, 16 Dec 2024 05:39:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 优化 LLM 合并以减少性能权衡</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hfc8s5/r_optimizing_llm_merging_to_reduce_performance/</link>
      <description><![CDATA[      我们刚刚发布了我们的新工作，该工作涉及跨使用不同超参数、数据混合、目标等训练的检查点进行大规模合并，以优化权衡。例如，一些在代码生成方面表现良好的模型在指令遵循方面表现较差，反之亦然。一个有趣的问题是，在这样的设置下，模型合并是否可以产生帕累托最优模型。 TL;DR: 在开发 LLM 时，通常会获得不同的检查点，每个检查点都擅长单个或一组任务/功能。通常，您可以继续调整超参数，直到获得帕累托最优模型，但该过程可能非常昂贵。我们表明，您可以将所有这些模型收集到一个池中，并优化合并参数以减少任务权衡。我们表明，简单的线性合并可以在不同的权衡场景中产生帕累托最优模型——比单个模型和强合并基线更好的权衡。有趣的是，在某些情况下，我们的优化合并优于原始模型。我们的研究使用大规模模型（Cohere 的 Command R+ 104B）并探索从 SFT/RLHF 训练中合并多达 16 个检查点。  https://preview.redd.it/3b2her78d57e1.png?width=2269&amp;format=png&amp;auto=webp&amp;s=3974e5b7bbf2f1b5b602eb6aa3a4092978b286d5 很高兴听到您的想法。 📄 论文：https://huggingface.co/papers/2412.04144 🧵 Twitter/X：线程    提交人    /u/moyle   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hfc8s5/r_optimizing_llm_merging_to_reduce_performance/</guid>
      <pubDate>Mon, 16 Dec 2024 05:33:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] LPIPS 实现中缩放层的值背后的含义是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hf9ido/d_what_is_the_meaning_behind_the_values_for_the/</link>
      <description><![CDATA[      我一直在阅读论文“深度特征作为感知指标的不合理有效性”，并正在研究其实现方式。他们使用了缩放层 https://preview.redd.it/ctwnc4gsk47e1.png?width=1560&amp;format=png&amp;auto=webp&amp;s=45ba5e41249d4af1cb05e53c6855531fbccd544f 但是，我认为 Imagenet 标准化的平均值和标准差是 mean = [0.485, 0.456, 0.406] 和std = [0.229, 0.224, 0.225] 。好奇这些值是怎么来的？    提交人    /u/Snoo_65491   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hf9ido/d_what_is_the_meaning_behind_the_values_for_the/</guid>
      <pubDate>Mon, 16 Dec 2024 02:55:39 GMT</pubDate>
    </item>
    <item>
      <title>如何根据诗歌生成模型遵循文体指南的程度来评估其性能？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hf7l8n/how_can_i_evaluate_the_performance_of_my_poetry/</link>
      <description><![CDATA[因此，我正在创建一个机器学习系统，该系统根据输入生成诗歌，告诉它要遵循的诗人风格。我一直在尝试评估该模型的性能，但大多数客观评估指标都是根据生成的诗人与诗人诗歌样本的接近程度来分配分数。这没有帮助，因为我试图了解风格与措辞的匹配程度。有什么建议吗？    提交人    /u/SkyRevolutionary275   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hf7l8n/how_can_i_evaluate_the_performance_of_my_poetry/</guid>
      <pubDate>Mon, 16 Dec 2024 01:14:53 GMT</pubDate>
    </item>
    <item>
      <title>微调法学硕士 (LLM) 中的内存要求 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hf58kj/memory_requierements_in_finetune_llms_d/</link>
      <description><![CDATA[嗨，我正在尝试微调 meta-llama/Llama-3.2-1B-Instruct。我使用 Transformers 库以 4 位精度加载模型，并使用 PEFT 库和 TRL 应用 LoRA 方法。当我开始训练步骤时，问题就出现了，因为我一直内存不足，但我不知道为什么。这些是我的训练参数：training_args = SFTConfig（output_dir =&#39;/ content / results&#39;，num_train_epochs = 5，per_device_train_batch_size = 1，per_device_eval_batch_size = 1，gradient_accumulation_steps = 2，learning_rate = 2e-4，bf16 = True，logging_steps = 50，eval_strategy =&#39;steps&#39;，eval_steps = 500，save_strategy =“steps”，save_steps = 500，warmup_steps = 100，weight_decay = 0.01， logs_dir=&quot;/content/logs&quot;,packing=True, report_to=&quot;none&quot; ) trainer = SFTTrainer( model=model, train_dataset=templated_dataset[&#39;train&#39;], eval_dataset=templated_dataset[&#39;test&#39;], args=training_args, tokenizer=tokenizer, ) 序列长度为 2048，要训练的参数为 1,179,648 (LoRA)。我计算出我需要大约 3.57GB，但是我只有 15GB，内存不够了。我不知道我的训练参数配置是否有问题。你能帮帮我吗？提前致谢。    由   提交  /u/Top-Leave-7564   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hf58kj/memory_requierements_in_finetune_llms_d/</guid>
      <pubDate>Sun, 15 Dec 2024 23:18:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了 wut – 一个使用 LLM 解释你的最后一个命令的 CLI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hew6wy/p_i_made_wut_a_cli_that_explains_your_last/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hew6wy/p_i_made_wut_a_cli_that_explains_your_last/</guid>
      <pubDate>Sun, 15 Dec 2024 16:29:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</guid>
      <pubDate>Sun, 15 Dec 2024 16:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当你的模型正在训练时你做什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hemhil/d_what_do_you_do_while_your_model_is_training/</link>
      <description><![CDATA[我基本上在模型训练时照看它，看一些《豪斯医生》或者玩一些我的世界。我已经完成了所有的文献综述和论文写作，现在在我的模型训练时我应该做什么？    提交人    /u/Striking-Warning9533   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hemhil/d_what_do_you_do_while_your_model_is_training/</guid>
      <pubDate>Sun, 15 Dec 2024 06:11:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医学 AI：顶级 LLM 研究论文/模型（2024 年 12 月 7 日至 12 月 14 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hecwvp/d_last_week_in_medical_ai_top_llm_research/</link>
      <description><![CDATA[   [D] 医学 AI 上周：顶级 LLM 研究论文/模型（2024 年 12 月 7 日至 12 月 14 日） 医学 LLM &amp;  PediaBench：中文儿科法学硕士  本文介绍了 PediaBench，这是第一个用于评估大型语言模型 (LLM) 问答性能的中文儿科数据集，包含 12 个疾病组的 4,565 个客观问题和 1,632 个主观问题。  BiMediX：双语医学法学硕士  本文介绍了 BiMediX，这是第一个双语（英语-阿拉伯语）医学专家混合法学硕士，以及 BiMed1.3M，这是一个 1.3M 的双语医学指导数据集，其中包含超过 632M 个用于训练的标记。  多样化医学知识整合  本文介绍了 BiMediX2，这是一个基于 Llama3.1 架构的双语（阿拉伯语-英语）大型多模态模型 (LMM)，在160 万个医疗互动样本。  BRAD：数字生物语言模型 本文介绍了 BRAD（生物信息学检索增强数字助理），这是一个由 LLM 驱动的聊天机器人和代理系统，集成了各种生物信息学工具。  MMedPO：视觉语言医学 LLM  本文介绍了 MMedPO，一种多模态医学偏好优化方法，通过解决模态错位来提高医学大型视觉语言模型（Med-LVLM）中的事实准确性。   框架和方法论 - TOP-Training：医疗问答框架 - 混合 RAG：安全医疗数据管理 - 零样本 ATC 临床编码 - 胸部 X 光诊断架构 - 医学影像 AI 民主化 基准和评估 - KorMedMCQA：韩国医疗保健许可基准 - 大型语言模型医疗任务 - 临床 T5 模型性能研究 - 放射学报告质量评估 - 基因组分析基准 LLM 应用 - TCM-FTP：草药处方预测 - LLaSA：通过传感器进行活动分析 - 急诊科就诊预测 - 神经退行性疾病 AI 诊断 - 肾脏疾病可解释 AI 模型 道德 AI 与隐私 - 隐私保护 LLM 机制 - 人工智能驱动的数字有机体建模 - 生物医学研究自动化 - 医学实践中的多模态性 完整线程详细信息：https://x.com/OpenlifesciAI/status/1867999825721242101    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hecwvp/d_last_week_in_medical_ai_top_llm_research/</guid>
      <pubDate>Sat, 14 Dec 2024 21:25:08 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 矩阵循环状态，注意力机制的替代方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he8vhw/project_matrix_recurrent_states_a_attention/</link>
      <description><![CDATA[      https://github.com/mikayahlevi/mru-lm 大家好，我在这里发帖是为了分享我刚刚在 GitHub 上发布的项目。我将从描述开始，其中一些内容将从 GitHub repo 中复制/粘贴。 矩阵循环单元的概念由更新规则 H_t = H_{t-1} X_{t-1} 和 H_1 = X_1 决定，其中 X 和 H 是 s×n×n 方阵序列。这与传统 RNN 的主要区别在于，没有初始向量通过线性，而是第一个状态是矩阵，导致输出也是矩阵。我提出这个想法的动机基于以下原因：  矩阵乘法是结合的，但不是交换的。结合性意味着我可以使用（包含）并行扫描来计算累积矩阵乘积。缺乏交换性意味着标记的顺序会自动合并到 MRU 中。 当您尝试在传统 RNN 上执行此扫描时，操作数会与输出状态中的元素数量成立方比例，这意味着与计算量相比，保留的信息有限。另一方面，如果状态是矩阵，则作为输出状态中元素的函数的操作数为 (n^2)^(3/2)，其中 n^2 是方阵 n×n 矩阵状态中的元素数量。这里有一篇包含一些相关信息的论文：https://arxiv.org/abs/1709.04057。 当按顺序或与（尚未实施的）Brent-Kung 并行扫描并行处理标记时，网络会随时间线性扩展，而注意力则会随时间二次扩展。  我尝试在不同的分支中使用不同的方法生成矩阵 X。生成 X 并将输出隐藏状态折叠回向量的所有方法都是线性和重塑的任意组合，仅基于我发​​现效果良好的方法。 Transformer 和 MRU-LM 在 shakespeare-char 上的损失与步数 基于玩具数据集 shakespeare-char，这种方法似乎效果很好。如果有人能帮助我在更大的数据集上训练模型并进一步评估它，我将不胜感激。    提交人    /u/IonizedPro   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he8vhw/project_matrix_recurrent_states_a_attention/</guid>
      <pubDate>Sat, 14 Dec 2024 18:19:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2024 年法学硕士论文精选清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he4htl/p_curated_list_of_llm_papers_2024/</link>
      <description><![CDATA[       提交者    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he4htl/p_curated_list_of_llm_papers_2024/</guid>
      <pubDate>Sat, 14 Dec 2024 14:52:26 GMT</pubDate>
    </item>
    <item>
      <title>美国健康保险申请精选语料库 [P] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he14fo/curated_corpus_for_us_health_insurance/</link>
      <description><![CDATA[       由    /u/tpafs  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he14fo/curated_corpus_for_us_health_insurance/</guid>
      <pubDate>Sat, 14 Dec 2024 11:36:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深度学习训练的（非）书面规则是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he07vr/d_what_are_the_unwritten_rules_of_deep_learning/</link>
      <description><![CDATA[免责声明：我首先在 r/learnmachinelearing 中发布了此内容，但该子版块似乎更关注非常基本的问题、课程和招聘，因此如果它不适合在这里发布，请随时将其删除（尽管我认为这也适合作为讨论的子版块）。 我现在有几年构建和训练不同模型架构的经验，我了解大部分基本理论，并能够理解大多数论文。所以我的问题更偏向于方法论方向。虽然我能够成功地为许多应用程序构建模型，但很多时候这在很大程度上是一种猜测。我尝试了不同的东西，看看哪种方法可行。我知道在可解释性方面有很多研究正在进行，但这并不是我想要的方向。相反，我想问大家，你们对训练过程有什么一般性建议，你们采取的一些实际观察、经验法则和方法在论文或理论机器学习课程中没有描述。例如：  你如何分析模型中的梯度。我知道如何在这方面做一些非常基本的图表，但我对你的方法以及你如何从实际角度解读它们感兴趣？ 你如何可视化优化器步骤之间的时间不稳定性，例如由于学习率过大？ 你如何确定合适的正则化？ 在训练运行期间，你的收益递减经验法则是什么？ 你如何调整超参数？我或多或少地目测过它们，过去也使用过 optuna。 您认为在训练过程中有哪些重要的直觉、不成文的规则和陷阱？ 当模型表现不如预期时，您的调试步骤是什么？ 您实际上使用了哪些技巧？有很多小技巧（EMA、模糊的激活函数等）可以带来一些好处，但您实际上使用了什么？ 当您使用 Transformer、CNN、扩散模型等时，您的方法有何不同？ 上面我可能遗漏了一些一般性意见或技巧。  大学课程和在线资源主要教授基础知识或理论基础，这非常重要，但在实践中只是故事的一部分。现实世界的经验也有帮助，但你只能通过反复试验走这么远，可能会错过一些有用的东西。我知道 Karpathy 关于神经网络训练的博客文章，并在寻找这方面的更多资源。 我很高兴在这里看到您对这个广泛话题的回复。    提交人    /u/floriv1999   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he07vr/d_what_are_the_unwritten_rules_of_deep_learning/</guid>
      <pubDate>Sat, 14 Dec 2024 10:29:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 发生了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hdxbru/d_what_happened_at_neurips/</link>
      <description><![CDATA[        提交人    /u/howtorewriteaname   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hdxbru/d_what_happened_at_neurips/</guid>
      <pubDate>Sat, 14 Dec 2024 07:00:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>