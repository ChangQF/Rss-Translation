<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 29 Jan 2024 21:11:36 GMT</lastBuildDate>
    <item>
      <title>分解：神经网络结构组合性的证据 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae61tq/break_it_down_evidence_for_structural/</link>
      <description><![CDATA[ 由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae61tq/break_it_down_evidence_for_structural/</guid>
      <pubDate>Mon, 29 Jan 2024 20:59:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 之外的法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae5dgq/d_llms_beyond_rag/</link>
      <description><![CDATA[实际上几乎每个人都在谈论 RAG。我想知道接下来会出现什么趋势。很想听听您的想法。   由   提交/u/HolidayCritical3665   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae5dgq/d_llms_beyond_rag/</guid>
      <pubDate>Mon, 29 Jan 2024 20:31:28 GMT</pubDate>
    </item>
    <item>
      <title>佩德罗·多明戈斯：神经象征尚未发挥作用 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae4vp1/pedro_domingos_neurosymbolic_does_not_work_yet_r/</link>
      <description><![CDATA[      ​ https://preview.redd.it/r0h4yab5qffc1.png?width=817&amp;format=png&amp;auto=webp&amp;s=033744120df49 252c5379bdafa429570e80cfac4&lt; /a&gt; ​ 象征性人工智能通常被视为失败。我记得 Cyc 花费了 2 亿美元（比 GPT-4 的培训预算还多？）。 另一方面，Transformer LLM [1] 明显的固有局限性使一些人将目光转向象征性的、神经-再次采用象征性和混合性方法。 DeepMind 首席执行官表示，公司在这个领域有六个项目。 如果你对这些主题（神经网络、符号和神经符号人工智能的理论局限性）感兴趣，我为它们制作了一个 Reddit 子版块： r/symbolic （我可能会后悔这样做，但小众主题需要自己的 subreddits，因为大多数主题都没有关心或了解很多，因此提交的内容会被否决，并且评论通常缺乏洞察力，例如“什么是 ILP？”） ​ &lt; p&gt;[1]例如 https://arxiv.org/abs/2205.11502   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae4vp1/pedro_domingos_neurosymbolic_does_not_work_yet_r/</guid>
      <pubDate>Mon, 29 Jan 2024 20:11:06 GMT</pubDate>
    </item>
    <item>
      <title>Leeroo“专家编排”“[研究]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae3gth/leeroo_orchestrationofexperts_research/</link>
      <description><![CDATA[🌐 Leeroo “专家编排” O.O.E 1️⃣ 最先进的开源：在 MMLU 基准上实现76% 的准确率，在相同推理预算的情况下超越 Mixtral (70.6%)。  2️⃣ 超越 GPT-4：以一半的成本几乎与 GPT-4 的性能相当， 性能优于 GPT-4，但支出减少了 25%。  3️⃣ 可访问性：可部署在任何云提供商或本地上，使其具有多功能性且可广泛访问。 4️⃣ 持续演进：利用动态自我播放循环来持续进行学习， 确保响应变得越来越准确和高效。 🚀🤖 #OrchestrationOfExperts #LeerooOrchestrator 研究论文： https://arxiv.org/abs/2401.13979 Github： https://github.com/leeroo-ai/leeroo_orchestrator 研究博客： https://www.leeroo.com/post/leeroo-orchestrator-v1-面向人工智能操作系统 公司： https://www.leeroo .com/   由   提交 /u/AALISHKH   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae3gth/leeroo_orchestrationofexperts_research/</guid>
      <pubDate>Mon, 29 Jan 2024 19:13:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多输出高斯过程，每个输入一个输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae2o5b/r_multioutput_gaussian_process_with_one_output/</link>
      <description><![CDATA[我正在寻找一种适合多输出高斯过程的方法，其中在任何给定输入处仅观察到单个输出。我遇到的所有多输出高斯过程模型都假设在每个输入处观察到每个输出（即完全观察到的输出）。 这篇博客文章说，当在任何给定输入处观察到单个输出时，观察次数将为n，并且多输出 GP 将具有与单输出 GP 相同的时间和内存缩放比例。这是一个不错的酒店。但是，这篇文章没有提及如何拟合这样的模型。 我的特定应用程序有 2 个输出，其中一个输出比另一个输出具有更多的观察结果。任何帮助将不胜感激！   由   提交 /u/RemyMacDonald   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae2o5b/r_multioutput_gaussian_process_with_one_output/</guid>
      <pubDate>Mon, 29 Jan 2024 18:41:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 智能音乐生成系统回顾（2023 年 11 月 17 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae1p6p/r_a_review_of_intelligent_music_generation/</link>
      <description><![CDATA[ 由   提交/u/moschles  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae1p6p/r_a_review_of_intelligent_music_generation/</guid>
      <pubDate>Mon, 29 Jan 2024 18:03:06 GMT</pubDate>
    </item>
    <item>
      <title>[d] Code Llama，一种最先进的大型编码语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae0lsj/d_code_llama_a_stateoftheart_large_language_model/</link>
      <description><![CDATA[ https://ai.meta.com/blog/code-llama-large-language-model-coding/   由   提交/u/Electrical_Study_617   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae0lsj/d_code_llama_a_stateoftheart_large_language_model/</guid>
      <pubDate>Mon, 29 Jan 2024 17:19:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 早期的 Reddit 数据可以用于研究吗？关于新的API规则</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adwss2/d_can_earlier_reddit_data_be_used_for_research/</link>
      <description><![CDATA[您好！我们正在考虑使用 Kaggle 的数据集作为我们硕士论文的主要数据源。我们的研究重点是检测多动症及其症状，仅用于学术目的。有问题的数据集位于：https://www.kaggle.com/datasets/jerseyneo/reddit- adhd-dataset 但是，我们对使用该数据集的合法性感到担忧。它似乎可能违反 Reddit 的开发者条款 (§4.2)，其中规定：“您不会、也不会尝试、或允许或允许他人（包括通过您的应用程序）/…/访问或使用 Reddit 服务和数据通过任何方式（包括通过访问我们的 API 或索引、缓存或抓取我们的 Reddit 服务和数据）在未经我们许可的情况下训练大语言、人工智能或其他算法模型或相关服务。” 我们不确定将 Kaggle 的数据集用于我们的目的是否合法。我们将不胜感激任何有关此事的建议或见解。谢谢！   由   提交/u/Aggravating_Entry510   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adwss2/d_can_earlier_reddit_data_be_used_for_research/</guid>
      <pubDate>Mon, 29 Jan 2024 14:38:07 GMT</pubDate>
    </item>
    <item>
      <title>寻求最佳的 Reranker 服务：bge 和 Cohere 的经验？ [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adwa3y/seeking_the_best_reranker_services_experiences/</link>
      <description><![CDATA[社区您好， 我正在探索重新排序工具，并对您的体验感到好奇，尤其是 bge 模型（大型/基础）和 Cohere Rerank 等服务。我的用例是一个非常通用的 RAG，我想查看可用重新排名器（MTEB 除外）的一些指标，尤其是在现实世界领域 纯粹来自服务 POV，Cohere 是镇上唯一的游戏吗，或者还有其他值得考虑的选择吗？有人提供 bge-reranker-base/large 作为服务吗？我对自托管不感兴趣。 任何见解或建议都会很棒   由   提交/u/brooding_pixel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adwa3y/seeking_the_best_reranker_services_experiences/</guid>
      <pubDate>Mon, 29 Jan 2024 14:14:35 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯神经网络与学习方差和均值 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1advijz/bayesian_nns_vs_learning_variance_and_mean/</link>
      <description><![CDATA[嗨， 根据我的理解，贝叶斯神经网络将权重视为 pdf，从而允许神经网络本身产生随机变量基于训练后权重采样的结果。虽然这看起来很有趣，但它也很昂贵。对于那些希望能够产生随机预测的人来说，另一个更简单的选择就是让神经网络学习一些平均值和标准差。虽然神经网络本身现在是确定性的而不是随机的，但它仍然允许我们在假设某种分布的情况下从平均值和标准差中进行采样。 这有意义吗？因此，如果正在寻找神经网络的随机结果，但不希望考虑贝叶斯神经网络的额外成本，那么选项二似乎很有吸引力。 如果您同意我所写的内容，请告诉我或不。我很高兴听到您的意见:)   由   提交/u/andre2500_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1advijz/bayesian_nns_vs_learning_variance_and_mean/</guid>
      <pubDate>Mon, 29 Jan 2024 13:38:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何为 RAG 划分块</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adtuzr/d_how_to_divide_a_chunk_for_rag/</link>
      <description><![CDATA[大家好， 我需要一些建议，假设您正在构建一个 RAG。您希望上下文块的长度为 512 个令牌。如何在不失去语义联系的情况下划分 1000 多个段落。 有关更多信息，它是一个问答机器人，那个巨大的段落是对一个常见问题的回答。   由   提交 /u/Lathanderrr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adtuzr/d_how_to_divide_a_chunk_for_rag/</guid>
      <pubDate>Mon, 29 Jan 2024 12:10:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进行直接偏好优化 (DPO) 的正确方法是什么？为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adnq4u/d_whats_the_proper_way_of_doing_direct_preference/</link>
      <description><![CDATA[      出于某种原因，我无法全神贯注于 DPO 的数据分发问题。论文中写道： https ://preview.redd.it/6c9z61o4bbfc1.png?width=2164&amp;format=png&amp;auto=webp&amp;s=c6b5ed46937da04e5912023e2f46ae7821a9a446 我的问题是：为什么它如此重要偏好数据分布与参考模型输出分布一致吗？我的理解是，在训练过程中，sft的参数会更新，使得选择的响应（y_w）生成的概率更高，而拒绝的响应（y_l）生成的概率更低，并且参考模型就在那里以防止 sft 模型偏离原始参数太远。但我不明白错误的参考分布如何阻碍这个过程。有人可以帮助我吗？ ​ p.s.我已经看到很多现有的实现忽略了这个分布转移问题并获得了良好的结果，所以我认为这并不重要？   由   提交/u/aaaprocrastinating   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adnq4u/d_whats_the_proper_way_of_doing_direct_preference/</guid>
      <pubDate>Mon, 29 Jan 2024 05:30:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不懂基础的LLM专家？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</link>
      <description><![CDATA[我最近遇到了很多人，他们知道 LLM 领域中不同技术的所有奇特缩写词，诚然我也是新手但越来越明显的是，他们甚至不知道 DL 的基础知识，比如背景是什么或其他经典概念。 这是否会成为现状，因为 LLM 领域更倾向于配置而不是做事从零开始？ 还有，这些人真的可以被认为是法学硕士还是表面上的专家？    由   提交/u/Plus_Tough_7497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</guid>
      <pubDate>Mon, 29 Jan 2024 04:13:30 GMT</pubDate>
    </item>
    <item>
      <title>您在工作中是否拥有产品专业的法学硕士？如果是这样，那又是为了什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1adbbnv/do_you_have_llms_in_prod_at_work_if_so_what_for_d/</link>
      <description><![CDATA[请随意在评论中扩展诸如任务（RAG、聊天机器人、工具、seq2seq 等）模型大小、部署策略、缺点等信息，未来计划等 就我而言：任务：RAG 模型：zephyr 7B 部署：vLLM 未来计划：内部文档预训练 + 聊天微调 &lt;!-- SC_ON - -&gt;  由   提交/u/masc98  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1adbbnv/do_you_have_llms_in_prod_at_work_if_so_what_for_d/</guid>
      <pubDate>Sun, 28 Jan 2024 19:51:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>