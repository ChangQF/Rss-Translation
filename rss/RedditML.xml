<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 30 Jan 2024 09:13:55 GMT</lastBuildDate>
    <item>
      <title>[D] RAG 用于包含章节和子章节的文档</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aejsur/d_rag_for_documents_with_chapters_and_subchapters/</link>
      <description><![CDATA[我想为一个 100 页的文档实现 RAG，该文档具有章节、子章节等的层次结构。因此，我将文档分成更小的块段落。在许多情况下，子章节中的块仅在子章节标题的上下文中才有意义，例如（6.1 方法 ABC，6.1.1 缺点）。 我想知道 RAG 中处理分层结构最常用的方法是什么，这在较长的文档中很常见？ &lt; !-- SC_ON --&gt;  由   提交/u/Electronic-Letter592   reddit.com/r/MachineLearning/comments/1aejsur/d_rag_for_documents_with_chapters_and_subchapters/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aejsur/d_rag_for_documents_with_chapters_and_subchapters/</guid>
      <pubDate>Tue, 30 Jan 2024 08:38:01 GMT</pubDate>
    </item>
    <item>
      <title>主题建模[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aejdlm/topic_modelling_p/</link>
      <description><![CDATA[我的目标是创建一个模型，根据票证提到的功能/问题对支持票证进行集群。当使用像 BerTopic 这样的模型时，我得到的结果是一些提到相同问题的票证是不同主题的一部分。有没有不同的方法来解决这个问题？我的目标是根据与他们提到的产品/公司相关的功能/问题对票证进行集群。   由   提交/u/hugh57231   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aejdlm/topic_modelling_p/</guid>
      <pubDate>Tue, 30 Jan 2024 08:07:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将我们的客户反馈分为功能请求、错误和评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aehk5l/d_classify_our_customer_feedback_into_feature/</link>
      <description><![CDATA[嘿，我是一家 B2B SaaS 公司的 SWE，我的 PM 要求我将客户反馈分为功能请求、错误和评论。我建立了一个模型，但它不起作用。有我可以使用的模型吗？有什么建议么？我按着时钟。  谢谢！   由   提交 /u/Scary-Swing2852    reddit.com/r/MachineLearning/comments/1aehk5l/d_classify_our_customer_feedback_into_feature/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aehk5l/d_classify_our_customer_feedback_into_feature/</guid>
      <pubDate>Tue, 30 Jan 2024 06:06:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 向所有跨学科计算社会科学家提出的问题 - 在您的领域应用 AI/ML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeenu3/d_question_to_all_computational_social_scientists/</link>
      <description><![CDATA[您好r/MachineLearning！&lt; /p&gt; 我很想听听应用/计算社会科学家的意见，他们曾尝试或想要在您的研究中应用机器学习和人工智能技术。您遇到过哪些挑战？什么类型的能力最有用？ 问这个问题的主要动机来自于我过去的经验 - 我注意到专门用于社会科学研究的非处方人工智能模型的短缺，并开始想知道除了缺乏可用资源之外我们还存在哪些问题。 作为一名对人工智能/机器学习感兴趣的社会科学家，您通常会面临哪些问题？我也有兴趣听听您是否认为人工智能/机器学习将从根本上改变社会科学，或者只是提供一些有用但有限的工具，或者研究的性质会如何改变。 非常期待听到来自不同领域的观点。跨越社会科学！   由   提交/u/nickshoh  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeenu3/d_question_to_all_computational_social_scientists/</guid>
      <pubDate>Tue, 30 Jan 2024 03:25:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 加速注意力研究：融合心理学和机器学习：探索注意力机制中的意志力和兴趣</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeds27/d_accelerating_research_on_attention_blending/</link>
      <description><![CDATA[      摘录：今天，让我们从通常深入研究代码和算法的过程中绕道而行。相反，我想谈谈最近让我大脑发痒的事情：如果我们可以将一些人类心理学（例如意志力和兴趣）混合到机器学习的冷酷逻辑世界中会怎样？如果您希望我继续致力于此，请喜欢这篇文章！ :) https://medium.com/@beastman3b/blending-psychology-and-machine-learning-exploring-willpower-and-interest-in-attention-mechanisms-81ce5d6bdb3d &amp; #x200b; https:// medium.com/@beastman3b/blending-psychology-and-machine-learning-exploring-willpower-and-interest-in-attention-mechanisms-81ce5d6bdb3d 请继续关注，看看效果如何出！   由   提交 /u/Honest-Debate-6863   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeds27/d_accelerating_research_on_attention_blending/</guid>
      <pubDate>Tue, 30 Jan 2024 02:42:34 GMT</pubDate>
    </item>
    <item>
      <title>250 RTX 3080s 能做什么 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aedjxc/what_to_dow_ith_250_rtx_3080s_p/</link>
      <description><![CDATA[您好！我有大约 250 个 RTX 3080，+ 可能有 40 个 RTx 3070，我用于挖矿。他们都拆掉了风扇护罩并安装了风扇。在浸入式冷却液中采矿。长话短说。采矿停止后，事情变得忙碌起来。它们的 GPU 刚刚放在浸没液体中。它们仍然可以工作，并且自从采用液体冷却以来从未变热。  是否有任何公司可以托管浸入式冷却卡，或者有人想要协助代理这些卡或帮助它们设置机器学习？我很乐意将几台 3080 赠送给任何可以用它们实现目标的人！   由   提交/u/death0and0taxes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aedjxc/what_to_dow_ith_250_rtx_3080s_p/</guid>
      <pubDate>Tue, 30 Jan 2024 02:31:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LLM + RAG 进行 3D 对象搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aec8gb/d_3d_object_search_using_llm_rag/</link>
      <description><![CDATA[为可与自然语言一起使用的 3D 对象制作一个小型搜索引擎，并从中获得了一些乐趣。不需要元数据或标签，索引纯粹是根据几何图形构建的！这使用以下管道进行工作：  对于数据库中的每个对象，我生成 6 个图像，每侧 1 个。 对于每个图像，我使用 gpt4- 进行描述视觉，然后使用 gpt4 将其合成为单个描述 文本描述使用剪辑嵌入并存储在矢量数据库中 对于搜索查询，搜索字符串被嵌入，并且检索到数据库中最接近的（n）个向量。  参见此处：https://x.com/MenyJanos/status/1752104689188135271?s=20   由   提交/u/Janos95  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aec8gb/d_3d_object_search_using_llm_rag/</guid>
      <pubDate>Tue, 30 Jan 2024 01:29:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用多个库对 Mixtral-8x7B 进行实验 - 每秒最多获得 52 个令牌。想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeb70z/d_experiments_with_mixtral8x7b_using_multiple/</link>
      <description><![CDATA[      大家好， 最近尝试部署 Mixtral-8x7B模型并希望与感兴趣的人分享主要发现： 最佳性能：使用 Pytorch（每晚）的量化 8 位模型的平均代币生成率为 52.03 代币/秒在 A100 上，平均推理时间为 4.94 秒，冷启动时间为 11.48 秒（在无服务器环境中部署时很重要） 混合实验 测试的其他库： vLLM、AutoGPTQ、HQQ 渴望听到您在类似部署中的经验和学习！   由   提交/u/Tiny_Cut_8440   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeb70z/d_experiments_with_mixtral8x7b_using_multiple/</guid>
      <pubDate>Tue, 30 Jan 2024 00:40:34 GMT</pubDate>
    </item>
    <item>
      <title>自动 1111 的开源 SDK/Python 库 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeab92/opensource_sdkpython_library_for_automatic_1111_p/</link>
      <description><![CDATA[   ​ https://preview.redd.it/74bz5ko0xgfc1.png?width=1656&amp;format=png&amp;auto=webp&amp;s=2a0ea066 0f56c97e242c7e099073086f52e38263&lt; /a&gt; https://github.com/saketh12/Auto1111SDK 大家好，我为自动 1111 Web UI 构建了一个轻量级开源 Python 库，它允许您在基础设施上本地运行任何稳定扩散模型。您可以轻松运行：  文本到图像 图像到图像 修复 修复 li&gt; Stable Diffusion Upscale Esrgan Upscale Real Esrgan Upscale 直接从 Civit AI 下载模型  使用任何安全张量或检查点文件都只需几行代码！它超轻且高性能。与 Huggingface Diffusers 相比，我们的 SDK 使用的内存/RAM 少得多，并且我们在我们测试的所有设备/操作系统上观察到速度提高了 2 倍！ 请为我们的 Github 存储库加注星标！！！ https://github.com/saketh12/Auto1111SDK.   由   提交 /u/Dazzling_Koala6834   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeab92/opensource_sdkpython_library_for_automatic_1111_p/</guid>
      <pubDate>Mon, 29 Jan 2024 23:59:46 GMT</pubDate>
    </item>
    <item>
      <title>分解：神经网络结构组合性的证据 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae61tq/break_it_down_evidence_for_structural/</link>
      <description><![CDATA[ 由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae61tq/break_it_down_evidence_for_structural/</guid>
      <pubDate>Mon, 29 Jan 2024 20:59:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 之外的法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae5dgq/d_llms_beyond_rag/</link>
      <description><![CDATA[实际上几乎每个人都在谈论 RAG。我想知道接下来会出现什么趋势。很想听听您的想法。   由   提交/u/HolidayCritical3665   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae5dgq/d_llms_beyond_rag/</guid>
      <pubDate>Mon, 29 Jan 2024 20:31:28 GMT</pubDate>
    </item>
    <item>
      <title>佩德罗·多明戈斯：神经象征尚未发挥作用 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae4vp1/pedro_domingos_neurosymbolic_does_not_work_yet_r/</link>
      <description><![CDATA[      ​ https://preview.redd.it/r0h4yab5qffc1.png?width=817&amp;format=png&amp;auto=webp&amp;s=033744120df49 252c5379bdafa429570e80cfac4&lt; /a&gt; ​ 象征性人工智能通常被视为失败。我记得 Cyc 花费了 2 亿美元（比 GPT-4 的培训预算还多？）。 另一方面，Transformer LLM [1] 明显的固有局限性使一些人将目光转向象征性的、神经-再次采用象征性和混合性方法。 DeepMind 首席执行官表示，公司在这个领域有六个项目。 如果你对这些主题（神经网络、符号和神经符号人工智能的理论局限性）感兴趣，我为它们制作了一个 Reddit 子版块： r/symbolic （我可能会后悔这样做，但小众主题需要自己的 subreddits，因为大多数主题都没有关心或了解很多，因此提交的内容会被否决，并且评论通常缺乏洞察力，例如“什么是 ILP？”） ​ &lt; p&gt;[1]例如 https://arxiv.org/abs/2205.11502   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae4vp1/pedro_domingos_neurosymbolic_does_not_work_yet_r/</guid>
      <pubDate>Mon, 29 Jan 2024 20:11:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多输出高斯过程，每个输入一个输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae2o5b/r_multioutput_gaussian_process_with_one_output/</link>
      <description><![CDATA[我正在寻找一种适合多输出高斯过程的方法，其中在任何给定输入处仅观察到单个输出。我遇到的所有多输出高斯过程模型都假设在每个输入处观察到每个输出（即完全观察到的输出）。 这篇博客文章说，当在任何给定输入处观察到单个输出时，观察次数将为n，并且多输出 GP 将具有与单输出 GP 相同的时间和内存缩放比例。这是一个不错的酒店。但是，这篇文章没有提及如何拟合这样的模型。 我的特定应用程序有 2 个输出，其中一个输出比另一个输出具有更多的观察结果。任何帮助将不胜感激！   由   提交 /u/RemyMacDonald   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae2o5b/r_multioutput_gaussian_process_with_one_output/</guid>
      <pubDate>Mon, 29 Jan 2024 18:41:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不懂基础的LLM专家？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</link>
      <description><![CDATA[我最近遇到了很多人，他们知道 LLM 领域中不同技术的所有奇特缩写词，诚然我也是新手但越来越明显的是，他们甚至不知道 DL 的基础知识，比如背景是什么或其他经典概念。 这是否会成为现状，因为 LLM 领域更倾向于配置而不是做事从零开始？ 还有，这些人真的可以被认为是法学硕士还是表面上的专家？    由   提交/u/Plus_Tough_7497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</guid>
      <pubDate>Mon, 29 Jan 2024 04:13:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>