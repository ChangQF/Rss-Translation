<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 23 Feb 2024 06:17:52 GMT</lastBuildDate>
    <item>
      <title>[D] 为什么大家对 Mamba 被 ICLR 拒绝感到惊讶？我错过了什么吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axsxeo/d_why_is_everybody_surprised_that_mamba_got/</link>
      <description><![CDATA[我也不只是想逆势而行。我不断在 Reddit、工作中、不同的在线论坛等上听到这个消息。当我第一次听到这个消息时我也很惊讶，但读完这篇论文后我并不特别惊讶。他们的硬件调整很有趣，但除此之外，这似乎是对之前论文的简单改编。基准实验并不像我最初认为的那么广泛，因为每个人都在谈论它有多么革命性。阅读这篇论文给我留下了很多问题，比如“X 任务或 Y 基准测试的性能怎么样？”我并不是想羞辱作者，但它并不真的感觉像一个“传统”的。机器学习领域的论文也有。 已经发布了很多并不完全适合会议出版物的优秀论文，我认为这不仅仅是因为某件事被讨论得很多在 Twitter 或 LinkedIn 上，这意味着它值得在某个场所发布。我真的想知道我是否低估了它，因为我没有正确理解它并且愿意接受任何意见。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axsxeo/d_why_is_everybody_surprised_that_mamba_got/</guid>
      <pubDate>Fri, 23 Feb 2024 05:40:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 面向多语言大语言模型的高效且有效的词汇扩展</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axs4r4/r_efficient_and_effective_vocabulary_expansion/</link>
      <description><![CDATA[https://arxiv.org/abs/2402.14714 关于非英语语言词汇扩展的技术报告刚刚发布。你觉得怎么样？   由   提交/u/OldPin8654  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axs4r4/r_efficient_and_effective_vocabulary_expansion/</guid>
      <pubDate>Fri, 23 Feb 2024 04:57:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是发布我所从事的项目的正确位置吗，以便我可以获得反馈</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axqmen/d_is_this_the_right_place_to_post_a_project_i/</link>
      <description><![CDATA[这个子项目似乎更像是一个分享 ML 研究的地方，而且我的项目并不是全新的。然而，它确实展示了端到端的 ML Ops 工程。  我想分享它，以便获得一些反馈和对如何改进它的批评，从而使其对数据科学和机器学习工程招聘人员更具吸引力。当然，我可以添加任何使项目变得更好的概念也将是令人惊奇的。    由   提交/u/Snoo_72181   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axqmen/d_is_this_the_right_place_to_post_a_project_i/</guid>
      <pubDate>Fri, 23 Feb 2024 03:35:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 相似性度量问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axpqdk/d_similarity_metrics_question/</link>
      <description><![CDATA[大家好。我对相似性指标很陌生，我可以参考你的建议。我正在阅读这篇关于多模式 RAG 的论文。  https://arxiv.org/pdf/2211.12561.pdf#page10 他们提到他们正在使用最大内积搜索作为相似性度量。   给定这个检索器 r，我们在内存上执行最大内积搜索（MIPS；§4.1），以获得按相关性分数排序的候选文档列表。  但是他们也提到，他们将多模态文档特征向量的 L2 范数缩放为等于 1。   具体来说，如图 1b（右）所示，给定一个多模态文档，我们将其分为文本部分和图像部分，使用现成的冻结 CLIP 文本和图像编码器分别对两个部分进行编码，然后对两者进行平均，L2 范数缩放为 1，作为向量表示  在哪种情况下，他们实际上只是将余弦相似度作为相似度度量？    由   提交 /u/NightlyGravy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axpqdk/d_similarity_metrics_question/</guid>
      <pubDate>Fri, 23 Feb 2024 02:52:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您如何发现新的研究论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axosx0/r_how_do_you_spot_new_research_papers/</link>
      <description><![CDATA[好吧，我尝试在 arxive 中搜索关键字。但我觉得必须有更好的方法来解决这个问题。 显然，订阅昂贵的期刊是一种方法。科学中心是另一个。  但是您使用什么特定工具/流程来跟踪新论文的发布？    由   提交/u/Dump7  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axosx0/r_how_do_you_spot_new_research_papers/</guid>
      <pubDate>Fri, 23 Feb 2024 02:06:40 GMT</pubDate>
    </item>
    <item>
      <title>硕士论文错误[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axebkf/master_thesis_mistake_d/</link>
      <description><![CDATA[大家好，我正在写计算机科学硕士学位论文，我的核心主题是特别使用遗传算法的自动特征工程。我刚刚意识到我发生了数据泄漏，一旦解决，结果明显低于以前。我的论文即将结束，下周将与我的教授进行最后一次会面。我的数据来自与我合作的公司，无法公开，因此我的工作无法真正复制，但我真的很强调是否应该告诉教授这个问题还是继续解决这个问题..我起来，我不想不诚实，但我不知道如何处理它，任何人都可以提供一些想法帮助吗？    由   提交/u/Adventurous_Car_1809   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axebkf/master_thesis_mistake_d/</guid>
      <pubDate>Thu, 22 Feb 2024 18:52:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] MetaGPT 严重错误报告了基线数据并获得了 ICLR 口头审查！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1axbm0f/d_metagpt_grossly_misreported_baseline_numbers/</link>
      <description><![CDATA[OpenReview：https://openreview.net/forum ?id=VtmBAGCN7o 我正在查看 ICLR 评论，很惊讶地看到 MetaGPT 被提交给 ICLR。录取决定表明他们被授予口头（ICLR 的最高级别）。  查看论文，他们报告了与 HumanEval 的比较： ​   方法 Pass@1    MetaGPT 85.9   GPT-4 67.0   GPT-3.5-Turbo（在响应中） 48.1   然而，该基准测试中的真实 GPT-4 和 GPT-3.5-Turbo 数字要高得多（请参阅 EvalPlus 排行榜：https: //evalplus.github.io/leaderboard.html）。 EvalPlus 排行榜的结果已被重复多次，因此毫无疑问。 MetaGPT 作者使用的数字取自旧的技术报告，不再准确。他们必须知道这一点，每个人都知道，这是毫无疑问的。 以下是使用 EvalPlus 中的数字进行的真实比较：   方法 Pass@1    MetaGPT 85.9   GPT-4 88.4 &lt; /tr&gt;  GPT-3.5-Turbo 76.8   GPT-3.5-Turbo 性能被严重误报。以前从未见过这样的事情。他们不可能通过 GPT-3.5-Turbo 合法地获得该数字。 所以，基本上，他们的整个“代理公司模拟”是让你花 10 美元购买 OpenAI 学分的交易比只问一次 LLM 更糟糕...他们得到了口头...我们完蛋了。  &amp;# 32；由   提交 /u/Signal-Aardvark-4179   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1axbm0f/d_metagpt_grossly_misreported_baseline_numbers/</guid>
      <pubDate>Thu, 22 Feb 2024 17:06:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么西班牙顶级公司的研究部门如此之少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ax8xy3/d_why_are_there_so_few_research_divisions_of_top/</link>
      <description><![CDATA[我一直在审查几家领先公司的研究职位空缺，令我惊讶的是，尽管其中许多公司在西班牙设有分支机构，但几乎没有研究已经完成。通常情况下，最注重研究的职位似乎是在法国、英国、荷兰、德国或瑞士，除了美国。 是不是还没有时间在中国建立这种类型的部门？西班牙还是有什么根本原因吗？ 我不认为这是因为缺乏人才，因为我知道很多有才华的人不得不移民到这些公司寻找工作。   由   提交 /u/SrPinko   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ax8xy3/d_why_are_there_so_few_research_divisions_of_top/</guid>
      <pubDate>Thu, 22 Feb 2024 15:21:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么在法学硕士中字节对编码分词器比字符级分词器更受青睐？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ax6xuh/d_why_are_byte_pair_encoding_tokenizers_preferred/</link>
      <description><![CDATA[我知道字节对会给你更大的词汇量但更短的标记序列，而像字符级分词器这样更细粒度的东西将有一个小的词汇量但输出标记序列要长得多。 我不明白的是为什么这是大多数 LLM 模型的首选。例如，GPT 和 Llama 都使用字节对编码。这与这些模型的块大小限制有关吗？   由   提交/u/putinwhat  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ax6xuh/d_why_are_byte_pair_encoding_tokenizers_preferred/</guid>
      <pubDate>Thu, 22 Feb 2024 13:54:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有云 GPU 按计算/利用率而非正常运行时间计费？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ax6v04/d_are_there_any_cloud_gpus_billed_on/</link>
      <description><![CDATA[我正在启动一个照片处理应用程序，它使用 GPU 对大型图像处理模型进行推理。目前，只有少数用户，因此我的 GPU 实例 99.99% 的时间都处于空闲状态，但我每月要为空闲的 GPU 支付 400 多美元。当用户触发推理作业时，我可以启动 GPU 实例，但这意味着用户需要等待几分钟才能启动实例。无法承受这样的延迟。 我搜索过根据利用率计费的云 GPU 解决方案，但没有找到任何内容。当然，这对于云 CPU（多租户、虚拟化实例）来说非常常见，您只需为使用的计算付费；但我猜 GPU 并不真正具有相同的功能？有人看到过其他情况吗？ 除了每月支付 400 多美元购买利用率极低的 GPU 之外，我还有什么其他选择？  &amp; #32；由   提交/u/uberdev  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ax6v04/d_are_there_any_cloud_gpus_billed_on/</guid>
      <pubDate>Thu, 22 Feb 2024 13:51:04 GMT</pubDate>
    </item>
    <item>
      <title>[新闻]稳定扩散3</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ax6oi3/news_stable_diffusion_3/</link>
      <description><![CDATA[似乎已列入候补名单。 https://stability.ai/news/stable-diffusion-3 “Stable Diffusion 3 结合了扩散变压器架构和流匹配。 ”    由   提交/u/SunnyJapan  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ax6oi3/news_stable_diffusion_3/</guid>
      <pubDate>Thu, 22 Feb 2024 13:42:22 GMT</pubDate>
    </item>
    <item>
      <title>RAG 与长上下文模型 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ax6j73/rag_vs_long_context_models_discussion/</link>
      <description><![CDATA[大家好，我知道我们都见过具有 100 万上下文的 Gemini v1.5 模型，而且来自 groq 公司的硬件表明，如果硬件是专门为语言模型设计的，因为它们可以变得更好。您现在对 RAG 架构有何看法，因为我们已经看到了很长的上下文模型。如果我们有更长的上下文模型和更好的量化技术和硬件怎么办？您认为像 RAG 这样的架构以及使用向量数据库来存储知识库和动态检索仍然相关吗？ 请纠正我并相应地添加更多相关信息。如果相关的研究和观察被发布，我们将不胜感激！！   由   提交/u/WritingBeginning3403  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ax6j73/rag_vs_long_context_models_discussion/</guid>
      <pubDate>Thu, 22 Feb 2024 13:35:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研究论文中的结果（或数据）多久被操纵一次？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ax610a/d_how_often_is_results_or_data_manipulated_in/</link>
      <description><![CDATA[我最近看到了哈佛教授的结果操纵案例，觉得很有趣，人们怎么能在如此高的水平上伪造结果。机器学习研究中也会发生这种情况吗？我从来不是机器学习论文的第一作者，所以我不知道知名会议的工作原理，但我不认为有人会交叉检查结果，而只会在发现可疑时提出问题。 有时，我发现结果与作者发布的结果与使用他们提供的代码重新创建的结果不匹配，但我总是将其归咎于我的实现和/或环境。   由   提交 /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ax610a/d_how_often_is_results_or_data_manipulated_in/</guid>
      <pubDate>Thu, 22 Feb 2024 13:08:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么研究人员很少发布训练代码？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1awy07v/d_why_do_researchers_so_rarely_release_training/</link>
      <description><![CDATA[我现在正在查看针对各种 MoE 模型的 3 篇不同论文。这三个都发布了模型权重和推理代码，但都没有发布训练代码。  当我们期望现在大多数论文都有代码及其实现时，为什么这种情况如此普遍和被接受？   由   提交/u/hazard02  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1awy07v/d_why_do_researchers_so_rarely_release_training/</guid>
      <pubDate>Thu, 22 Feb 2024 04:59:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>