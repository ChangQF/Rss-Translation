<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Thu, 22 Aug 2024 12:29:23 GMT</lastBuildDate>
    <item>
      <title>认知不确定性真的能反映模型的状态吗?[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyeyed/epistemic_uncertainty_really_could_reflect_the/</link>
      <description><![CDATA[我尝试使用 MC dropout 或者 deep ensemble 来获取每个 epoch 之后的认知不确定性（假设这是一个回归任务，我直接通过 output.std() 来量化不确定性）。我记录了每个 epoch 之后的不确定性，最后将其绘制成一条曲线，结果是数值会有一个快速上升然后缓慢下降的趋势（看起来很直观(?)）。但是这条曲线会不断波动，它并不是一条稳定的曲线。这让我很疑惑，为什么在不断增加 epoch 的训练过程中，模型的不确定性（episodic 不确定性）会如此不稳定？使用 output.std() 作为依据时也是这样吗？    submitted by    /u/Ok-Marsupial6206   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyeyed/epistemic_uncertainty_really_could_reflect_the/</guid>
      <pubDate>Thu, 22 Aug 2024 09:26:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] Yolov8 的替代品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eyes8d/d_yolov8_alternatives/</link>
      <description><![CDATA[我目前正在使用 Yolov8 进行一些对象检测和分类任务。总的来说，我喜欢它的准确性和速度。但它是经过许可的。有哪些可以同时提供检测和分类功能的免费替代品？    提交人    /u/Powerful-Angel-301   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eyes8d/d_yolov8_alternatives/</guid>
      <pubDate>Thu, 22 Aug 2024 09:14:30 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 通过梯度下降进行上下文学习 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eybxel/transformers_learn_incontext_by_gradient_descent_r/</link>
      <description><![CDATA[      有人能帮助我理解论文Transformers learn in-context by gradient descent中的推理吗？作者首先假设一个带有某个权重 \（W\）的“参考”线性模型，然后证明该模型在梯度下降步骤后的损失等于“转换后的数据”的损失。然后，在主要结果（命题 1）中，作者手动构建了 \（K\）、\（Q\）和 \（V\）的权重，使得单头注意层的前向传递将所有标记映射到此“转换后的数据”。 我的问题是：这种构造如何“证明”Transformers 可以在上下文学习（ICL）中执行梯度下降？前向传递的输出（即“转换后的数据”）是否被视为新的预测？我认为应该是这样的：新的预测与更新后的权重给出的预测相匹配。我无法理解这里的逻辑。 https://preview.redd.it/cztva19y05kd1.png?width=1046&amp;format=png&amp;auto=webp&amp;s=0196944994516f480670ba9d29be91f8f55fc6f9 https://preview.redd.it/oihuv48405kd1.png?width=1728&amp;format=png&amp;auto=webp&amp;s=8cfc35bf8aa433d53f9d7b5bc5faef3c3e4fba8a    提交人    /u/mziycfh   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eybxel/transformers_learn_incontext_by_gradient_descent_r/</guid>
      <pubDate>Thu, 22 Aug 2024 05:56:07 GMT</pubDate>
    </item>
    <item>
      <title>利用 HuggingFace GPT 模型构建学术错误信息检测器的可行性 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ey9fiy/feasibility_of_using_huggingface_gpt_model_to/</link>
      <description><![CDATA[大家好， 我正在开展一个与 GPT 相关的个人项目，旨在识别学术内容中的错误信息。我们的想法是使用 GPT-2 XL 检查学术文本中的主张，并生成超越简单分类的输出，提供更多与上下文相关的内容。 例如，如果研究论文中的主张指出“某种特定药物已被证明可有效治疗某种疾病”，该模型将使用与该主题相关的其他学术论文的文本，并生成详细的输出，根据证据支持或反驳该主张，并附上简要说明。这个想法是使用滑动窗口来分析其他研究论文的文本内容，以符合文本输入的限制。 我只能访问 RTX GeForce 3060 GPU（12 GB 内存），虽然 GPT-2 XL 在我的设置上运行高效，但我注意到输出质量相当差。 我正在考虑在专注于学术语言和错误信息的自定义数据集上对 GPT-2 XL 进行微调，以提高其在此特定任务中的表现。但是，考虑到我的局限性，我担心可行性。 为此目的在 RTX 3060 上对 GPT-2 XL 进行微调是否可能/实用，或者该过程的计算成本是否太高？    提交人    /u/Mental-Particular104   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ey9fiy/feasibility_of_using_huggingface_gpt_model_to/</guid>
      <pubDate>Thu, 22 Aug 2024 03:30:23 GMT</pubDate>
    </item>
    <item>
      <title>Azure 机器学习工作区 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ey88lm/azure_machine_learning_workspace_d/</link>
      <description><![CDATA[有没有好的地方/社区/论坛可以讨论 Azure 机器学习工作区中的问题？ 我正在尝试创建一个可以在笔记本和计算集群中使用的环境。这样，我就可以测试代码以在笔记本中训练模型，并扩展以将训练作为作业运行。以及访问笔记本和作业的数据资产。 不幸的是，无论我怎么尝试，作业都不会提交（没有错误，但似乎有时会使内核崩溃或永远旋转），但如果我将其切换到内置的默认 sdk2 环境，它会提交，尽管无法访问数据资产，但这可能是代码错误或缺少包。 谢谢！    提交人    /u/Ulan0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ey88lm/azure_machine_learning_workspace_d/</guid>
      <pubDate>Thu, 22 Aug 2024 02:29:55 GMT</pubDate>
    </item>
    <item>
      <title>PINNs - 重力反演问题 [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ey7jw9/pinns_gravity_inversion_problem_project/</link>
      <description><![CDATA[我正在尝试使用 DeepXDE 或其他库来解决重力反演问题。简而言之，我有一个 3D“网格”上方的表面重力观测数据，然后我想使用 PINN 来拟合此网格中的密度模型，当模拟表面接收器的重力响应时，它会与观察到的重力数据相吻合。我已使用以下代码作为框架，但损失函数是静态的。为什么我的损失函数没有变化，我该如何改进我的合成数据代码？ import numpy as np import tensorflow as tf import deepxde as dde from discretize import TensorMesh from SimPEG.potential_fields import grave from SimPEG import map from discretize.utils import mkvc, active_from_xyz import matplotlib.pyplot as plt 定义 PINN 模型 def grave_pde(x, y,receiver_locations, perceived_gravity): G = 6.67430e-11 # 引力常数 计算源点和接收器位置之间的距离 r = tf.sqrt(tf.reduce_sum(tf.square(x[:, None, :] -receiver_locations[None, :, :]), axis=2) + 1e-6) 通过对所有源点的贡献求和来计算预测重力 pred_gravity = G * tf.reduce_sum(y / (r**3), axis=0) 确保 pred_gravity 的形状为 (256, 1) 以匹配 perceived_gravity pred_gravity = tf.reshape(pred_gravity, [-1, 1]) 减去觀察到的重力 fitting_residual = pred_gravity - perceived_gravity return fitting_residual def build_pinn_model(grid_size, perceived_gravity,receivers_locations): geom = dde.geometry.geometry_3d.Cuboid([0, 0, 0], [grid_size, grid_size, grid_size]) 创建 PDE 数据对象 def grave_pde_with_receivers(x, y): return grave_pde(x, y,receivers_locations,observed_gravity) data = dde.data.PDE( geom,  gravity_pde_with_receivers,  [],  num_domain=100,  num_boundary=10,  train_distribution=&quot;uniform&quot; ) 简单的神经网络 net = dde.maps.FNN([3] + [64] * 3 + [1], &quot;relu&quot;, &quot;He normal&quot;) model = dde.Model(data, net) model.compile(optimizer=&quot;adam&quot;, lr=0.0001) 返回模型 if __name__ == &quot;__main__&quot;: grid_size = 16 模拟一些重力数据 observed_gravity = np.random.normal(0, 1, size=(256, 1)) 用于测试的随机接收器位置 receiver_locations = np.random.rand(256, 3) * grid_size 构建并训练模型 pinn_model = build_pinn_model(grid_size, perceived_gravity,receiver_locations) pinn_model.train(epochs=1000) 测试预测 coords = np.array([(i, j, k) for i in range(grid_size) for j in range(grid_size) for k in range(grid_size)]) pred_density_grid = pinn_model.predict(coords).reshape((grid_size, grid_size, grid_size)) 可视化预测密度 plt.figure() plt.imshow(pred_density_grid[grid_size // 2, :, :], cmap=&quot;viridis&quot;) plt.colorbar(label=&quot;Density&quot;) plt.title(&quot;预测密度横截面&quot;) plt.show()    提交人    /u/BitcoinBeers   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ey7jw9/pinns_gravity_inversion_problem_project/</guid>
      <pubDate>Thu, 22 Aug 2024 01:57:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找长文本的有效共指解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1exzq7r/d_looking_for_an_efficient_coreference_solution/</link>
      <description><![CDATA[我希望创建一个利用共指提取长篇小说中人物提及列表的工具。我是 AI/ML 的新手，所以想评估一下这种确切场景是否可能实现。 给定一个长文本（最多 50 万字），我想收集一个可能涵盖整个文本的人物提及列表。例如，一个人物可能会在第一章（“亚瑟王子”）中以名字介绍，然后在最后一章（“王子”）中引用 30 万字。 除此之外，我希望该模型能够实现渐进式共指解析。我的意思是，如果初始文本的共指解析需要（例如） 15 分钟，那么当我在小说中间编辑一个句子时，模型应该能够在更短的时间内重新计算共指，也许可以利用初始解析并“添加”它。 到目前为止，我已经尝试了两种模型：  CoreNLP fastcoref  尽管 fastcoref 的文档说它可以处理任何长度的文本，但我发现它们的速度或内存效率都不足以处理这么长的文本。 如果现有的共指解析模型不支持这种用例，那么是否存在允许实现这一点的行业标准技术？例如，我正在考虑对文本进行分块并对各个块运行共引用，例如： 块 1：[亚瑟是王子。] 块 2：[王子用剑战斗。] 块 3：[他每场战斗都获胜。] 在上面的例子中，如果我对块 1 和块 2 运行共引用，“亚瑟”和“王子”将被归类为同一实体。如果我随后对块 2 和块 3 运行共引用，“王子”和“他”也将被归类在一起。因此，如果“亚瑟”=“王子”且“王子”=“他”，那么“他” = &quot;Arthur&quot;。 上述场景的问题在于，在小说中，提及可能跨越数千个单词，这会增加块的大小。此外，需要提前选择块大小，如果块大小太小，我将丢失提及。 我也考虑过对各个章节运行共引用并合并结果，但是这样我可能会丢失各章节的提及。 有人对此有什么想法吗？    提交人    /u/andreacerasoni   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1exzq7r/d_looking_for_an_efficient_coreference_solution/</guid>
      <pubDate>Wed, 21 Aug 2024 20:13:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何看待 Pytorch 的 torchtune 的未来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1exz7z5/d_what_do_you_think_of_the_future_of_pytorchs/</link>
      <description><![CDATA[运行现成的实验非常棒，但目前我更喜欢 HuggingFace，因为后者更通用，配置更改也更少。你认为 torchtune 想要拥有什么样的空间？ 无论如何，很高兴看到 PyTorch 社区推动更多出色的开源库。    提交人    /u/Moltres23   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1exz7z5/d_what_do_you_think_of_the_future_of_pytorchs/</guid>
      <pubDate>Wed, 21 Aug 2024 19:52:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这个用例的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1exz46l/d_whats_the_best_approach_for_this_use_case/</link>
      <description><![CDATA[大家好， 我正在做一个项目，帮助一位朋友将遮阳箔贴到建筑窗户上。客户通常希望预览贴上箔后建筑物的外观，而现在，他们正在手动处理这些图像。 我是 AI 新手，正在尝试使用不同的工具。我的目标是使这个过程自动化，这样我们就可以输入建筑物照片并获得带有变暗窗户的输出，模拟箔效果。 我应该针对这个特定任务微调模型吗，还是使用 ControlNet 之类的东西会更有效？任何关于最佳方法的建议都将不胜感激！    提交人    /u/jjoker1410   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1exz46l/d_whats_the_best_approach_for_this_use_case/</guid>
      <pubDate>Wed, 21 Aug 2024 19:48:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] Formatron：一个高性能的约束解码库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1exwgx6/p_formatron_a_highperformance_constrained/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1exwgx6/p_formatron_a_highperformance_constrained/</guid>
      <pubDate>Wed, 21 Aug 2024 18:02:12 GMT</pubDate>
    </item>
    <item>
      <title>实时推荐系统的书籍/链接/材料 [D] [R] [P]。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1exv6ov/bookslinksmaterials_for_real_time_recommendation/</link>
      <description><![CDATA[大家好， 很高兴成为这个社区的一员。我是新来的，我正在寻找一些与推荐系统相关的链接/书籍。如果您能帮我找到这些书，我将不胜感激。我和我的团队主要计划构建一个实时推荐系统，但我们都没有这方面的经验。如果您能帮助我们提供一些与之相关的链接/帖子，我将不胜感激。话虽如此，我们已经有一些与机器学习、深度学习相关的经验，以及一些强化学习方面的经验。期待您的回复。    提交人    /u/Kansei-Drifto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1exv6ov/bookslinksmaterials_for_real_time_recommendation/</guid>
      <pubDate>Wed, 21 Aug 2024 17:11:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] Beta9：开放无服务器 GPU 云</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1exq4k9/d_beta9_open_serverless_gpu_cloud/</link>
      <description><![CDATA[嗨 r/MachineLearning， TL;DR：Beta9 是一个开源框架，可让开发人员轻松地在云 GPU 上运行无服务器功能。 Git Repo： https://github.com/beam-cloud/beta9 我是 Eli，一年前，我们在这个 subreddit 上推出了 Beam。我们决定将其开源。  如果您还没有听说过 Beam，它是一个用于 GPU 工作负载的无服务器平台。它为将代码部署到云上提供了 Python 优先的开发人员体验，并且它可能是将 ML 模型部署到 GPU 上的最快方法。  您可以使用它做以下几件事：  微调 LLM 部署无服务器推理 API 将工作负载自动扩展到数百个 GPU  有几个技术组件使这种体验成为可能：自定义 Runc 容器运行时、图像缓存、全局分布式存储和工作负载调度程序。这些都包含在开源项目中。 为什么要开源？  Beam 是一种在云上运行代码的新方法，我们构建了不同的抽象来实现它（Web 端点、任务队列、存储卷等等）。通过开源，我们邀请您为框架贡献自己的云抽象。想要将 S3 存储桶安装到您的无服务器容器中吗？您可以为此构建一个抽象！如何在云 GPU 容器上公开 TCP 端口？向 repo 发送 PR 并疯狂地进行操作。 您可以插入自己的硬件提供商。想要在 Lambda Labs 上使用 A6000？在您的家庭实验室中使用 3090 集群怎么样？是的，您可以连接它们。如果您有 AWS 或 GCP 积分，您也可以使用它们。   我们认为，让云变得更简单是一个很大的机会，但这是我们无法独自完成的努力。如果您对这个愿景感到兴奋，我们很高兴您尝试一下这个项目。 以下是我们的快速链接：  Repo： https://github.com/beam-cloud/beta9 带有示例应用程序和教程的 Github： https://github.com/beam-cloud/examples 文档： https://docs.beam.cloud/  让我知道您的想法，以及您希望我们将来构建什么！   由    /u/velobro  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1exq4k9/d_beta9_open_serverless_gpu_cloud/</guid>
      <pubDate>Wed, 21 Aug 2024 13:49:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用来自 LLM 的合成数据来训练/微调其他模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1expxo4/d_using_synthetic_data_from_llms_to_trainfinetune/</link>
      <description><![CDATA[嗨，这似乎是一个简单的问题，但我找不到好的材料和建议。 我想用 LLM 生成合成数据来试验句子转换器的微调。  你知道有什么好的做法、教程或框架可以使合成数据尽可能有效吗？ 除了 Llama-3 系列之外，你是否知道有哪些好的 LLM 允许（或至少不禁止）这样使用它们的输出？     提交人    /u/BenXavier   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1expxo4/d_using_synthetic_data_from_llms_to_trainfinetune/</guid>
      <pubDate>Wed, 21 Aug 2024 13:40:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 18 Aug 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>