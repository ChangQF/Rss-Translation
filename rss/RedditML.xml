<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 19 Jun 2024 12:27:52 GMT</lastBuildDate>
    <item>
      <title>[D] ML Journal 审查速度快</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djh6n6/d_ml_journal_with_fast_review_time/</link>
      <description><![CDATA[有人知道哪个期刊的审稿速度快吗？可能最多 6 个月。但是，该期刊的竞争不应该太激烈。这是一篇被 CVPR 拒绝的计算机视觉论文。我已经知道 TMLR 了。    提交人    /u/MadScientist-1214   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djh6n6/d_ml_journal_with_fast_review_time/</guid>
      <pubDate>Wed, 19 Jun 2024 11:47:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 快速调整：快速了解需要微调的预训练模型以及如何微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djfuik/r_quicktune_quickly_learning_which_pretrained/</link>
      <description><![CDATA[      论文： https://openreview.net/forum?id=tqh1zdXIra 研究代码（用于论文中的实验）： https://github.com/releaunifreiburg/QuickTune 工具/包（用于在真实数据集中评估）： https://github.com/automl/QTT 视频： https://www.youtube.com/watch?v=bdQLWnaxAnc 摘要：随着预训练模型数量的不断增加，机器学习从业者不断面临使用哪种预训练模型以及如何针对新数据集对其进行微调的问题。在本文中，我们提出了一种联合搜索最佳预训练模型和对其进行微调的超参数的方法。我们的方法将有关具有多种超参数配置的许多预训练模型在一系列数据集上的性能的知识进行迁移。为此，我们评估了超过 20k 种超参数配置，以在 87 个数据集上对 24 个预训练图像分类模型进行微调，以生成大规模元数据集。我们在该元数据集的学习曲线上元学习灰盒性能预测器，并将其用于新数据集上的快速超参数优化。我们通过实验证明，我们得到的方法可以为新的数据集快速选择一个准确的预训练模型及其最优超参数。 TL ; DR：联合超参数和预训练模型选择进行微调。 https://preview.redd.it/c183uici9i7d1.png?width=1436&amp;format=png&amp;auto=webp&amp;s=09f29237b9f843f0829b00ab8df3a66b275c60af    提交人    /u/Accurate_Celery_4614   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djfuik/r_quicktune_quickly_learning_which_pretrained/</guid>
      <pubDate>Wed, 19 Jun 2024 10:27:19 GMT</pubDate>
    </item>
    <item>
      <title>[P][D] 需要帮助评估我的 rag-chatbot</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djfubc/pd_need_help_in_evaluating_my_ragchatbot/</link>
      <description><![CDATA[我已经使用 rag 架构和 llama3 作为基础 llm 开发了一个聊天机器人，需要改进的步骤，因此需要评估指标或任何类型来比较每个改进     提交人    /u/spiritleader473882   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djfubc/pd_need_help_in_evaluating_my_ragchatbot/</guid>
      <pubDate>Wed, 19 Jun 2024 10:26:56 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 原始 NTP 训练模型的循环文本生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djdz8n/discussion_loopy_text_generation_of_raw_ntp/</link>
      <description><![CDATA[如何解释在进行指令调整和对齐之前通过下一个标记预测进行预训练的模型生成循环文本，我们如何检测到它？ 例如，我的一个模型生成了这样的文本：“Temptation&#39;s Trial hope is a\u040b hope is a\u040b a bi hope is a hope is a bi hope is a hope is a bi hope is a hope is a bi hope is a hope is a bi hope is a hope is a bi hope is a... x20 次以上”。然后我将这句话插入 Llama3-8b 并发现每个标记的损失 - 它非常低 我将上述文本放入 GPT4o 并要求它执行其他任务，例如“将这些句子放入列表中”，它就因为文本的内容而发疯了！它进入了一个无限循环，打印相同的序列而永不停歇。尽管 GPT4o 不是原始的预训练模型，但情况仍然如此。不过，这种行为通常仅源自此类原始模型。 我还记得，一旦生成超过 1-2 个句子，GPT-2 就会陷入循环。有没有文献讨论过这种现象，有没有办法检测它？    提交人    /u/Fit-Flow-4180   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djdz8n/discussion_loopy_text_generation_of_raw_ntp/</guid>
      <pubDate>Wed, 19 Jun 2024 08:16:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于物理信息神经网络 (PINN) 训练方法的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djd9ih/r_question_about_training_methodology_in/</link>
      <description><![CDATA[大家好， 我正在深入研究物理信息神经网络 (PINN) 的世界，并试图了解训练方法，特别是在训练 PDE 系数和神经网络权重（逆问题）时。例如，让我们以 NVIDIA Modulus 为例。 这就是我遇到困难的地方：对我来说，这有点像先有鸡还是先有蛋的问题。我们使用复合损失函数（包括 PDE 损失和神经网络损失）来训练模型。但我们如何使用这种损失来训练损失本身的参数？ 换句话说，损失函数用于更新模型参数，但这些参数是我们正在优化的损失函数的一部分。这种递归训练过程在实践中是如何运作的？ 如有任何见解或解释，我们将不胜感激！ 提前致谢！    提交人    /u/SatieGonzales   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djd9ih/r_question_about_training_methodology_in/</guid>
      <pubDate>Wed, 19 Jun 2024 07:25:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我可以向哪些期刊/会议提交关于计算流体动力学的机器学习研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dj9zdv/r_which_journalsconferences_can_i_possibly_submit/</link>
      <description><![CDATA[我目前是化学工程硕士（研究），我的背景是氢和计算流体动力学 (CFD)，同时我对 ML 非常感兴趣。 我最近完成了 CFD + ML 的研究。对于 ML 部分，这当然不是什么新鲜事；它太基础了，因为我使用典型的 sklearn 回归和分类模型来预测我的 CFD 结果，同时应用超参数调整等。 在这种情况下，我最初考虑像往常一样将我的论文提交给与化学相关的期刊。然而，作为一名希望转行到 ML 行业的学生，​​我最近正在考虑将我的论文提交给与 ML 相关的期刊。 基于我非常快速的互联网搜索，我找到了 ICML。除了主会议之外，它的一个研讨会似乎也适合我的情况，例如“生命与材料科学的机器学习：从理论到行业应用”（提交截止日期已过）  您知道我还可以关注哪些其他 ML 期刊/会议吗？ 对于计算机相关领域，似乎每年只能提交一次论文。真的是这样吗？例如，ICML 会在 1 月至 2 月左右征集论文，如果错过了，是否应该等到下一年？     提交人    /u/Rumi94   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dj9zdv/r_which_journalsconferences_can_i_possibly_submit/</guid>
      <pubDate>Wed, 19 Jun 2024 03:55:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 你好，我是一名高级机器学习工程师，正在寻找伙伴一起创造很酷的东西！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dj8pg6/p_d_hi_im_a_senior_machine_learning_engineer/</link>
      <description><![CDATA[嗨，我是一名高级机器学习工程师，正在寻找伙伴一起创造很酷的东西！我希望与其他充满热情的工程师一起探索和实验。我们可以做 Kaggle 项目、LeetCode，或者只是面试头脑风暴。如果有人愿意提出想法并看看我们可以一起创造什么很酷的东西，请联系我。    提交人    /u/Rude-Eye3588   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dj8pg6/p_d_hi_im_a_senior_machine_learning_engineer/</guid>
      <pubDate>Wed, 19 Jun 2024 02:45:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] - AMD MI300X 和 Nvidia H100 在 FFT 中的基准测试：VkFFT、cuFFT 和 rocFFT 比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dj1ixf/d_amd_mi300x_and_nvidia_h100_benchmarking_in_fft/</link>
      <description><![CDATA[   您好，我是 VkFFT 的创建者 - 用于 Vulkan/CUDA/HIP/OpenCL/Level Zero 和 Metal 的 GPU 快速傅里叶变换库。目前没有太多独立基准测试来比较 Nvidia (H100 SXM5) 和 AMD (MI300X) 的现代 HPC 解决方案，因此一旦这些 GPU 按需可用，我就会想知道它们执行快速傅里叶变换的效果如何 - 以及供应商库（如 cuFFT 和 rocFFT）与我的实现相比的表现如何。 按需租赁非常昂贵，因此这些初步结果仅包括单精度和双精度的 1D 批处理 2 个复杂到复杂 FFT 的幂。此基准测试通常在 GPU 上受内存限制，这意味着大部分时间都花在利用 VRAM 总线和将数据从 VRAM 传输到芯片上（批处理大小选择得足够大以减少缓存重用并利用所有计算单元）。我使用估计带宽作为基准指标，其计算方式为 (2 x 系统大小 [GB]) / 执行时间 [s]。之所以有 2 个倍数，是因为我们需要上传数据并从芯片下载数据。因此，对于内存受限的代码，此值应接近设备的内存带宽。 https://preview.redd.it/ngv6qqxvbd7d1.png?width=4500&amp;format=png&amp;auto=webp&amp;s=d4bdc8893462561f307e758cafb10e3f76636174 在单精度下，两种 GPU 的结果相似 - 单上传 FFT 算法的带宽约为 3TB/s。大约 2^14（取决于实现）后，所有库都切换到两次上传（和两次下载）FFT 算法，导致内存传输量增加 2 倍，随后带宽下降 2 倍。切换到三次上传发生在 2^24 左右。总体而言，两种 GPU 的理论带宽都未达到（H100 为 3.35TB/s，MI300X 为 5.3TB/s），但实际值低于规格值是很常见的。对于 AMD MI300X，小尺寸的结果也不一致，这可能是因为需要对新的多芯片设计和 L3 缓存进行更多优化。当前的 VkFFT 版本（针对上一代硬件进行了优化）与供应商解决方案相匹配，并且通常优于供应商解决方案，适用于高度优化的 2 的幂的情况。  https://preview.redd.it/9q0wt6m3cd7d1.png?width=4500&amp;format=png&amp;auto=webp&amp;s=19644a0945cd9f4a6acd4172d956c467bca94856 双精度结果的缩放比例与单精度类似。 AMD MI300X 在此实现了比单精度更高的基本带宽，我还不确定为什么（也许 1:1 FP64:FP32 核心比率会派上用场）。 VkFFT 还针对非 2 幂的情况进行了高度优化，因此在新硬件上应该表现良好。您可以在 VkFFT 论文中找到实现的算法描述和上一代 HPC GPU 的完整性能比较。一旦我解决了访问成本问题并进行了广泛的测试，我就会调整新 GPU 的代码。 总体而言，MI300X 与 H100 具有竞争力，而且看起来 AMD 改进了前几代 CDNA 的许多问题（即远程合并访问的内存引脚序列化）。看起来每个计算单元仍然比相应的流式多处理器弱 - 它具有更小和更慢的共享内存/L1 和 L2 缓存，但是，它通过拥有 L3 缓存和新的多芯片设计（连接 304 个计算单元）来抵消，其影响有待估计。 感谢您的阅读，如果您对 VkFFT 或测试程序有任何疑问 - 我很乐意回答。    提交人    /u/xdtolm   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dj1ixf/d_amd_mi300x_and_nvidia_h100_benchmarking_in_fft/</guid>
      <pubDate>Tue, 18 Jun 2024 21:05:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 工业界的机器学习研究人员：如何找出时间发表论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1divk13/d_ml_researchers_in_industry_how_do_you_find_time/</link>
      <description><![CDATA[背景：我在一家 FAANG 公司从事计算机视觉工作。我非常幸运，能够应用相对先进的技术。我通常每年至少参加一次大型会议，看到很多行业科学家发表演讲/张贴海报，我不得不问：怎么做到的？ 我每周花 40 个小时将技术应用于我公司特定的数据集/问题。我擅长我的工作，紧跟最新技术，为我的雇主创造了很多价值。这些技术甚至可以发表，但这需要在开源数据集上对这些方法进行基准测试。我无法想象在拥有生活和爱好的同时，还要找到进行所有实验和写作所需的额外时间。 尽管如此，我觉得这是对我的期望。与我共事的科学家基本上没有研究以外的生活，这似乎很正常（除非他们周末去远足……）。    提交人    /u/generating_loop   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1divk13/d_ml_researchers_in_industry_how_do_you_find_time/</guid>
      <pubDate>Tue, 18 Jun 2024 16:56:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文提出想法却没有结果？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1div5a6/r_papers_proposing_ideas_without_results/</link>
      <description><![CDATA[考虑到训练某些深度学习模型（尤其是 LLM）所需的资源，由于资源不足，找到一篇提出想法但无法展示结果的论文有多普遍？换句话说，如果研究人员有一个有前途的想法，他们想向其他可能拥有更多资源的研究团队提出这个想法，那么当显示出积极结果时，他们有没有办法这样做，同时保持他们的贡献？    提交人    /u/SingularityCharity   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1div5a6/r_papers_proposing_ideas_without_results/</guid>
      <pubDate>Tue, 18 Jun 2024 16:39:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你能将自我完善的 LLM 系统推向多远？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1diszz1/d_how_far_can_you_push_selfimproving_llm_systems/</link>
      <description><![CDATA[      我看到最近大量的研究论文和技术，它们展示了如何将 LLM 与其他工具结合起来创建一个可以自我改进的自我强化系统循环。 例如，DrEureka 使用 LLM 为机器人操作任务创建多个奖励模型的草稿。然后将结果反馈给模型，并告诉模型对结果进行推理并思考如何改进自身。该模型不仅创建和调整奖励函数，而且还进行配置以促进 sim2real 传输。根据论文，这种技术已被证明可以创建比人类更好的奖励模型。 https://preview.redd.it/w14kfgbuic7d1.png?width=1300&amp;format=png&amp;auto=webp&amp;s=415dcdf48e868aa7157e7b7b7fd34c507e9c7125 另一个更新的例子是 Sakana AI 的 LLM^2。在这项技术中，LLM 用于建议损失函数。然后测试这些函数，并将结果发送回模型进行审查和改进。Sakana 的研究人员使用这项技术创建了 DiscoPOP，据他们称，它“在多个保留评估任务中实现了最先进的性能，优于直接偏好优化 (DPO) 和其他现有方法。” https://preview.redd.it/8sujx731jc7d1.png?width=2988&amp;format=png&amp;auto=webp&amp;s=5bfb0c32baa990d59333a6f90f714d3f1100a148 这里的重复模式是：  使用 LLM 生成多个假设（LLM 的好处是它们可以生成许多假设，甚至一些可能违反直觉但在实践中有效的假设）。 使用验证机制（Python 执行器、数学解算器等） 让模型推理结果并提出改进建议 重复  虽然这种模式有几个有趣的例子运行良好（包括上面提到的两个），但我想知道这个社区中是否有人知道这些方法的局限性是什么？这样的系统在哪里会遇到瓶颈？您可以将这种模式推广到多远，以及在哪些领域这种模式不起作用？    提交人    /u/bendee983   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1diszz1/d_how_far_can_you_push_selfimproving_llm_systems/</guid>
      <pubDate>Tue, 18 Jun 2024 15:09:18 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] 雅典 NLP 暑期学校，2024 年 9 月 19 日至 25 日</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dineuj/news_athens_nlp_summer_school_september_1925_2024/</link>
      <description><![CDATA[      https://preview.redd.it/nfjcry734b7d1.jpg?width=1033&amp;format=pjpg&amp;auto=webp&amp;s=2118d94d8e415554e5de6e13055335e1ad711e50 链接： https://athnlp.github.io/2024/ 我们很高兴邀请所有对自然语言处理 (NLP) 和机器学习 (ML) 进入第二届雅典自然语言处理暑期学校 (AthNLP 2024)。该活动将在雅典 NCSR“Demokritos”校园举行，由 NCSR“Demokritos”、雅典经济与商业大学、RC“Athena”和赫瑞瓦特大学组织。 在 2019 年第一届 AthNLP 成功举办的基础上，AthNLP 2024 将涵盖一系列 NLP 主题，重点关注 ML 方法。预计上午有理论讲座，下午有实施和实验实验课，晚上有研究主题讲座，同时还有来自参与者和行业研究实验室的演示和海报。 主题包括分类、序列预测、线性模型、神经网络、编码器-解码器架构、机器翻译、大型语言模型和多模态。 目标受众 初步时间表： 点击此处  NLP 和计算语言学的研究人员和研究生 对 NLP 和 ML 感兴趣的计算机科学家 寻求更深入了解这些主题的行业从业者  不需要具备 NLP 和 ML 的先验知识，但需要具备基本的数学和 Python 编程技能。 重要日期  申请截止日期：2024 年 6 月 20 日 （可能会延长） 决定：2024 年 6 月 30 日 注册：2024 年 7 月 30 日 暑期学校：2024 年 9 月 19 日至 25 日  特色  费用中包含社交活动、每日午餐和咖啡休息时间 ML 和 NLP 领域顶尖研究人员的讲座 学生可选择参加海报会议，展示自己的作品 与技术公司和研究机构合作举办演示日  已确认的演讲者  Antonis Anastasopoulos，乔治梅森大学 Raquel Fernández，阿姆斯特丹大学 Ferenc Huszár，剑桥大学 Martin Krallinger，巴塞罗那超级计算中心 Mirella Lapata，爱丁堡大学 Ryan McDonald，ASAPP Aida Nematzadeh，Google DeepMind Vlad Niculae，阿姆斯特丹大学 Barbara Plank，慕尼黑路德维希马克西米利安大学 Anna Rogers，哥本哈根 IT 大学  参与费用  300 欧元（学生）（可申请奖学金） 400 欧元（大学教授或公共机构研究人员） 500 欧元（其他所有人）  如有任何疑问，请通过以下方式与我们联系：[athnlp2024@athenarc.gr]() 我们期待在那里见到您！    提交人    /u/yannisassael   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dineuj/news_athens_nlp_summer_school_september_1925_2024/</guid>
      <pubDate>Tue, 18 Jun 2024 10:30:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进化策略与反向传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dila4s/d_evolutionary_strategy_vs_backpropagation/</link>
      <description><![CDATA[我正在研究用于训练 NN 的进化策略，并得到了非常有趣的结果。这是你可以使用的笔记本：Colab 笔记本链接    epoch 数量 最终准确度 每 epoch 秒数    反向传播 10 97% 9   进化策略 10 90% 9   我不知道它能走多远，但是对于完全不使用梯度信息并在与反向传播相同的时间内在 GPU 上完成训练的东西获得 90% 的准确率是非常有趣的。 使用的 ES 算法非常简单：  用零初始化所有权重 创建大小为 N 的新一代种群 - 从正态分布中绘制每个权重，其中平均值是当前权重，标准差是学习率。 并行计算种群中每个个体的损失 - 在 GPU 上运行良好 挑选表现最好的前 k 个个体进行交配。 要获得新一代的下一个权重张量，请对表现最好的前 k 个个体取平均值。 转到步骤 2。  您是否知道任何探索训练神经网络的进化策略的有趣研究？ 更新 使用这些参数，您将在第一个 epoch 后获得 90%，在 10 个 epoch 后获得大约 94%，并且一个 epoch 所花费的秒数相似： lr = 5E-2population_size = 512generations_per_batch = 1num_parents_for_mating = 256    submitted by    /u/kiockete   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dila4s/d_evolutionary_strategy_vs_backpropagation/</guid>
      <pubDate>Tue, 18 Jun 2024 08:00:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] DiTTo-TTS：使用 Diffusion Transformer 实现高效、可扩展的零样本文本转语音</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dihfqu/r_dittotts_efficient_and_scalable_zeroshot/</link>
      <description><![CDATA[  由    /u/keonlee9420  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dihfqu/r_dittotts_efficient_and_scalable_zeroshot/</guid>
      <pubDate>Tue, 18 Jun 2024 03:51:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>