<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Sun, 28 Jul 2024 18:19:37 GMT</lastBuildDate>
    <item>
      <title>[D] 使用 Snowflake 模式数据模型为实时 AI 系统添加更多功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eed7re/d_add_more_features_to_realtime_ai_systems_with_a/</link>
      <description><![CDATA[注意：本文是关于生产实时 AI 系统，该系统读取预先计算的特征以构建更丰富的特征向量。我们如何才能为这些模型获取更多特征，而不会增加底层数据库的读取延迟。 实时 AI 应用程序和 LLM 的 RAG 通常使用某种类型的 ID（用户 ID、会话 ID、信用卡号等）来检索预先计算的特征数据，以用于做出更好的预测。一般来说，更多样化的特征数据可以实现更好的预测。 例如，如果您正在构建实时信用卡欺诈 ML 模型，并且对您的在线应用程序的请求仅包含信用卡号（ID）和几个特征 - 消费金额、位置、商家 ID。这不足以构建丰富的特征向量。因此，您可以使用信用卡号和商家 ID 从低延迟数据库中检索更多特征。但是，这仍然不够。您还想使用用户帐户和信用卡发行商的功能。你会怎么做？ 本文中的答案是拥有一个规范化的数据模型，您可以在其中使用单个 (LEFT) JOIN 查询检索所有这些功能。本文介绍了我们成为第一个添加对 Snowflake 模式数据模型的支持的功能商店的历程，以及如何拥有具有更多预计算功能的更好的模型。 参考 https://www.hopsworks.ai/post/the-journey-from-star-schema-to-snowflake-schema-in-the-feature-store    提交人    /u/jpdowlin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eed7re/d_add_more_features_to_realtime_ai_systems_with_a/</guid>
      <pubDate>Sun, 28 Jul 2024 17:48:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jul 2024 15:00:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 逆 GAN 保留生成器的权重</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee6w2s/r_inverse_gan_preserving_weights_of_generator/</link>
      <description><![CDATA[我正在寻找一个 GAN 模型，其中生成器可以使用与原始 GAN 生成虚假数据时相同的权重参数反转回潜在空间。我看过的大多数可逆 GAN 论文都使用单独的编码器或一些优化问题。 我阅读了这篇关于逆 GAN 的调查论文，但找不到使用相同权重的模型。 注意：我知道扩散模型可能非常适合这种情况。但我不想使用具有时间步长的模型，而是寻找单次传递模型。    提交人    /u/Alternative-Talk1945   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee6w2s/r_inverse_gan_preserving_weights_of_generator/</guid>
      <pubDate>Sun, 28 Jul 2024 13:00:18 GMT</pubDate>
    </item>
    <item>
      <title>[R]：请求认可在 arXiv 上发表论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee5h4z/r_request_for_endorsement_to_publish_paper_on/</link>
      <description><![CDATA[您能在 arXiv 上为我推荐吗 - https://arxiv.org/auth/endorse?x=8VGUTR 与 NIT Calicut 相关  我正在尝试上传一篇论文，该论文重点介绍使用自然语言处理 (NLP) 和神经网络进行抽象文本摘要，特别是集成 T5 Transformers 来提高模型效率并提取更高级别的抽象。 在这项工作中，我们最初开发了一个利用 Python、NLP 技术和 Seq2Seq 编码器-解码器架构的模型，实现了精确的文本摘要。在对前馈和循环神经网络进行广泛研究后，我们基于 T5 框架实现了一个模型。我们的结果表明 ROUGE 和 BERT 指标有显著改善，准确率达到 93%。 如果您需要详细信息，请告诉我 :)    提交人    /u/PristineAd1284   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee5h4z/r_request_for_endorsement_to_publish_paper_on/</guid>
      <pubDate>Sun, 28 Jul 2024 11:38:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 演示 ML 模型的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edu2tk/d_tool_to_demo_ml_models/</link>
      <description><![CDATA[大家好， 我和我的朋友正在开发一种工具，可让您在部署之前在可展示的环境中预览您的 ML 模型。我的模型是在 Google Colab 上设置的，但团队很难对其进行审查。它对客户来说也不太好看。 因此，我们希望创建一个演示环境，在移交给 DevOps 之前，可以非常简单地共享和展示模型。也在考虑添加某种反馈系统。 我们仍在确定细节，所以我们很想听听你对此的看法。根据您的经验，哪些功能会对您有所帮助？目前，我们考虑了图表和协作功能。 谢谢！（我的 DM 是开放的！我们不可能是唯一遇到这个问题的人吧）    提交人    /u/Pristine-Watercress9   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edu2tk/d_tool_to_demo_ml_models/</guid>
      <pubDate>Sat, 27 Jul 2024 23:46:11 GMT</pubDate>
    </item>
    <item>
      <title>如何像机器学习开发人员一样编写代码？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edscmn/how_to_code_like_developers_in_ml_d/</link>
      <description><![CDATA[我今年 24 岁，是一名航空航天博士，从事科学机器学习工作。我用 Pytorch 编写代码。这就是我如何获得一些好结果的原因。但我的代码不太灵活。如果我必须改变我的训练风格，我必须完全编写所有内容。我不知道如何以优化的方式添加不同类型的数据结构，如字典、元组和列表，以及其他方法，例如人们在 NVIDIA 中所做的方法。我甚至感觉不舒服。任何人都有这种感觉。    提交人    /u/haramkhor_havasi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edscmn/how_to_code_like_developers_in_ml_d/</guid>
      <pubDate>Sat, 27 Jul 2024 22:23:51 GMT</pubDate>
    </item>
    <item>
      <title>摘要和其他任务的最佳块和重叠大小 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edr0ro/optimal_chunk_and_overlap_size_for_summarization/</link>
      <description><![CDATA[  由    /u/28djs  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edr0ro/optimal_chunk_and_overlap_size_for_summarization/</guid>
      <pubDate>Sat, 27 Jul 2024 21:23:15 GMT</pubDate>
    </item>
    <item>
      <title>LiveBench 与现有的大规模 LLM 基准测试相比如何？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edk0ca/how_does_livebench_compare_to_existing_large/</link>
      <description><![CDATA[想知道社区对新的 LLM 基准 LiveBench 有何看法。您认为它与其他一些大型基准（例如 HELM、ChatBot Arena 和 Open LLM Leaderboard）相比如何？    提交人    /u/Penfever   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edk0ca/how_does_livebench_compare_to_existing_large/</guid>
      <pubDate>Sat, 27 Jul 2024 16:14:10 GMT</pubDate>
    </item>
    <item>
      <title>[R][P] 为 Vision Transformer 实现 GQA 检查点转换</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edjj1m/rp_implementing_gqa_checkpoint_conversion_for/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edjj1m/rp_implementing_gqa_checkpoint_conversion_for/</guid>
      <pubDate>Sat, 27 Jul 2024 15:53:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Concrete ML 和完全同态加密的端到端加密 23andMe 基因测试应用程序。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edir29/p_endtoend_encrypted_23andme_genetic_testing/</link>
      <description><![CDATA[我们最近收到了一些外部贡献，展示了如何使用 Zama 库创建端到端加密的基因检测应用程序，例如使用完全同态加密 (FHE) 的 23andMe。这篇博文展示了高级加密技术的集成，以确保在进行基因分析时保护隐私。这是一个重要的里程碑，因为它表明我们现在可以使用 FHE 在大约 5 分钟内预测加密的 DNA 祖先。 在此处阅读完整的博客文章：使用 Concrete-ML 和完全同态加密构建端到端加密的 23andMe 基因检测应用程序 很高兴回答任何问题或帮助任何有兴趣使用我们的工具构建安全 ML 应用程序的人！     由    /u/fd0r 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edir29/p_endtoend_encrypted_23andme_genetic_testing/</guid>
      <pubDate>Sat, 27 Jul 2024 15:18:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] 这是我们基于神经网络的快速漫射房间脉冲响应发生器（FAST-RIR）的官方实现，用于为给定的声学环境生成房间脉冲响应（RIR）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edibkx/r_this_is_the_official_implementation_of_our/</link>
      <description><![CDATA[        提交人    /u/Snoo63916   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edibkx/r_this_is_the_official_implementation_of_our/</guid>
      <pubDate>Sat, 27 Jul 2024 14:59:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我创建了 Promptimizer——一个基于遗传算法 (GA) 的提示优化框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edgtft/d_i_created_promptimizer_a_genetic_algorithm/</link>
      <description><![CDATA[        由    /u/NextgenAITrading 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edgtft/d_i_created_promptimizer_a_genetic_algorithm/</guid>
      <pubDate>Sat, 27 Jul 2024 13:49:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找处理对图像中两个对象之间是否存在直接路径进行分类的问题的学术论文。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edevbz/r_looking_for_academic_papers_that_deal_with_the/</link>
      <description><![CDATA[大家好， 我目前正在做一个项目，我尝试使用 CNN 根据 2 个选定节点是否连接对图形图像进行分类。我在过度拟合方面有点挣扎，想探索一些研究人员可能之前尝试过的其他策略。我很感激任何帮助或建议！如果我的解释不够深入，也可以随时提问。    提交人    /u/Dualweed   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edevbz/r_looking_for_academic_papers_that_deal_with_the/</guid>
      <pubDate>Sat, 27 Jul 2024 12:08:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama3.1 如何利用词汇表中仅有的 28k 个额外标记来支持多种语言？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edct9i/d_how_does_llama31_support_multiple_languages/</link>
      <description><![CDATA[根据 Llama3.1 论文，词汇表包含 128k 个标记，其中 100k 个专用于英语，28k 个分配给非英语语言。鉴于韩语、中文和日语等语言不使用 26 个字母的拉丁字母表并且可以有数百万个唯一字符，如何仅用 28k 个标记就涵盖这些语言？标记化是基于 Unicode 吗？    提交人    /u/Financial_Air5256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edct9i/d_how_does_llama31_support_multiple_languages/</guid>
      <pubDate>Sat, 27 Jul 2024 09:59:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检索增强生成的替代方案是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1edbg0h/d_whats_the_alternative_to_retrieval_augmented/</link>
      <description><![CDATA[看来 RAG 是业界问答系统的事实标准。有什么替代方案吗？    提交人    /u/clocker2004   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1edbg0h/d_whats_the_alternative_to_retrieval_augmented/</guid>
      <pubDate>Sat, 27 Jul 2024 08:21:58 GMT</pubDate>
    </item>
    </channel>
</rss>