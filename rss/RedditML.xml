<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 10 Dec 2024 12:36:09 GMT</lastBuildDate>
    <item>
      <title>[D] 模型出处：您如何追踪您的 ML 模型谱系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb0o4e/d_model_provenance_how_are_you_tracking_your_ml/</link>
      <description><![CDATA[嘿 r/MachineLearning，我很好奇这个社区的人们是如何处理模型出处的 - 在整个生命周期中跟踪机器学习模型的谱系和演变的实践。  您目前是否使用任何工具或方法来跟踪您的 ML 模型的出处？ 如果是，您使用什么解决方案？它们是定制的还是现成的？ 如果不是，您是否认为您的工作需要这样的工具？ 您认为模型出处解决方案中的哪些功能必不可少？     提交人    /u/crtahlin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb0o4e/d_model_provenance_how_are_you_tracking_your_ml/</guid>
      <pubDate>Tue, 10 Dec 2024 12:29:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不平衡数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb0kew/d_imbalance_dataset/</link>
      <description><![CDATA[大家好，我正在做一个与云计算相关的项目。我有一个在互联网上找到的与计算相关的实时数据集，但这些数据存在严重的不平衡，例如，我有 4 个类，其中两个包含最高值，而其余两个则少得多。 如何使用这些数据输入 ml 模型（我知道如果我不平衡数据，那么模型将严重偏向多数类） 需要帮助    提交人    /u/zaynst   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb0kew/d_imbalance_dataset/</guid>
      <pubDate>Tue, 10 Dec 2024 12:23:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] The Well：机器学习的大规模多样化物理模拟集合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1haz4nw/r_the_well_a_largescale_collection_of_diverse/</link>
      <description><![CDATA[数据集：https://github.com/PolymathicAI/the_well 论文：https://arxiv.org/pdf/2412.00568 摘要：  基于机器学习的替代模型为研究人员提供了加速基于模拟的工作流程的强大工具。然而，由于该领域的标准数据集通常涵盖一小部分物理行为，因此很难评估新方法的有效性。为了解决这一差距，我们引入了 Well：一个包含各种时空物理系统的数值模拟的大规模数据集集合。 The Well 汇聚了领域专家和数值软件开发人员的智慧，提供了 16 个数据集的 15TB 数据，涵盖生物系统、流体动力学、声散射以及河外流体或超新星爆炸的磁流体动力学模拟等不同领域。这些数据集可以单独使用，也可以作为更广泛的基准套件的一部分使用。为了方便使用 The Well，我们提供了一个统一的 PyTorch 界面来训练和评估模型。我们通过引入示例基线来演示该库的功能，这些示例基线突出了 The Well 复杂动态所带来的新挑战。代码和数据可在此 https URL 上找到。     提交人    /u/StartledWatermelon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1haz4nw/r_the_well_a_largescale_collection_of_diverse/</guid>
      <pubDate>Tue, 10 Dec 2024 10:49:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求论文写作反馈：基于 GPT 的网络入侵检测系统（arXiv 发表）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1haufwv/d_seeking_paper_writing_feedback_gptbased_network/</link>
      <description><![CDATA[大家好， 我是一名独立开发者，一直致力于将 GPT 模型应用于网络入侵检测。虽然我有实施经验，但这是我第一次涉足学术论文写作，我正在寻求有关论文表达和结构的反馈。 我最近在 arXiv 上发表了文章： - 标题：NIDS-GPT：将包视为语言：使用 TRANSFORMER 进行异常检测 - arXiv 链接：https://arxiv.org/pdf/2412.04473 本文提出了一种新颖的方法，将网络数据包中的每个数字视为 GPT 处理的独立“单词”。我们的实验显示出令人鼓舞的结果 - 在极端不平衡条件下 CICIDS2017 和汽车黑客数据集的准确率达到 100％，在一次性学习中的准确率达到 90％ 以上。 作为首次撰写论文的作者，我希望得到以下方面的反馈：  论文结构和学术展示标准 可视化效果和清晰度 方法展示 实验比较的有效性 主张和结论的强度  我特别希望得到以下人员的反馈： - 网络安全/入侵检测研究人员 - 在非 NLP 领域使用语言模型的人员 - 经验丰富的论文撰写者/审阅者 实现很可靠，但我想确保论文有效地传达了对学术界的技术贡献社区。 感谢您的时间和专业知识！    由    /u/EliaukMouse 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1haufwv/d_seeking_paper_writing_feedback_gptbased_network/</guid>
      <pubDate>Tue, 10 Dec 2024 05:14:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你是如何跟上文学发展的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hasdlo/d_how_do_you_keep_up_with_the_literature/</link>
      <description><![CDATA[标题基本就是这个意思。你用什么工具/策略来跟上文献的步伐？ 编辑：为了便于理解，我是一名一年级博士生，我指的是特定“利基”领域的文献（如果除了极少数例外，你可以在 ML 中将任何东西称为利基的话）    提交人    /u/Rickmaster7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hasdlo/d_how_do_you_keep_up_with_the_literature/</guid>
      <pubDate>Tue, 10 Dec 2024 03:20:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我做的正确吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1has6jq/d_is_what_im_doing_is_correct/</link>
      <description><![CDATA[我正在开展一个 ML 项目。我有 100 个特征和 2000000 行（平衡）我应该遵循哪个顺序？ 我已经完成了，  数据不一致处理 NULL 插补 标准化 独热编码 数据可视化 相关性检查 PCA 训练测试分割 模型训练 评估  对于随机森林，我得到训练数据所有指标的 1，测试集的 0.79。对于逻辑回归，所有指标和测试集的值为 ~0.79，也是同样的结果。对于 GBDT，所有指标和测试集的值为 ~0.79，也是同样的结果。我应该选择哪种模型？上述步骤是否按正确的顺序执行？    提交人    /u/_crazy_muffin_   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1has6jq/d_is_what_im_doing_is_correct/</guid>
      <pubDate>Tue, 10 Dec 2024 03:10:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过乘性权重扰动提高对损坏的鲁棒性 - 一种简单而有效的方法，可以使神经网络对损坏具有鲁棒性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hap6gx/r_improving_robustness_to_corruptions_with/</link>
      <description><![CDATA[我们想分享和讨论这篇 NeurIPS 焦点论文（免责声明：我是合著者）。 论文：https://arxiv.org/abs/2406.16540 GitHub：https://github.com/trungtrinh44/DAMP DAMP（通过乘性扰动进行数据增强）是一种通过乘性权重扰动来提高神经网络鲁棒性的简单而有效的方法。与传统的数据增强方法不同，DAMP 在训练期间直接对模型权重进行操作，从而能够提高损坏鲁棒性，而不会影响干净图像的性能或增加计算成本。  主要亮点：  理论基础：DAMP 证明输入损坏可以等效地表示为乘性权重扰动，为权重空间数据增强提供了理论基础。 简单实现：该方法只需要随机高斯采样和逐点乘法，保持与标准 SGD 几乎相同的训练成本，同时完全兼容数据并行。 ViT 训练方面的突破：仅使用基本的预处理即可从头开始成功训练 Vision Transformers，在 ImageNet 上实现 ResNet50 级别的性能（23.7% 的 top-1 错误率），而无需复杂的增强。 高级集成：与 MixUp 和 RandAugment 结合使用时，DAMP 可显著提高清洁和损坏性能： ViT-S/16：20.09% 的清洁错误率（与基线 20.25% 相比），平均损坏误差 58.30%（与基线 60.07% 相比） ViT-B/16：清洁误差 19.36%（与基线 20.41% 相比），平均损坏误差 56.76%（与基线 58.83% 相比）   为什么选择 DAMP？与依赖复杂数据增强管道或计算成本高昂的集成方法的传统方法不同，DAMP 提供了一种简单、理论扎实的解决方案来提高模型稳健性。它能够从头开始训练 Vision Transformers，无需高级增强，并且与现有技术兼容，这使其成为开发稳健视觉模型的实用选择。 由于 DAMP 与标准训练相比开销最小，因此应用于大型模型和数据集时特别有效。  我们欢迎技术讨论，特别是关于与其他稳健性方法的理论联系以及计算机视觉以外的潜在应用！    提交人    /u/emiurgo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hap6gx/r_improving_robustness_to_corruptions_with/</guid>
      <pubDate>Tue, 10 Dec 2024 00:38:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何管理和跟踪不断演变的大型图像数据集？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1haokqp/d_how_do_you_manage_and_track_your_large_evolving/</link>
      <description><![CDATA[我想知道人们如何管理大型内部数据集的生命周期？比如说 &gt;1TB 和 100k 个文件。 在我的新角色中，我们有多个生产模型，这些模型是从内部数据集训练出来的，大小从几千到几十万张图像不等。我们还有大量新数据进入，每天超过 100 万张图像，因此我们不断挖掘这些数据并发送新的部分进行注释。 到目前为止，团队基本上都是自己管理这个问题，结果是可以预测的。在某些情况下，我们无法将我们的生产模型与任何特定数据关联起来。我们的一些核心数据集仅存在于人们的主目录中，很容易被一个错误的命令抹去。对于一个幸好被淘汰的模型，已知训练代码和原始训练数据都丢失了。 该组织的部分成员采用了 DVC，这似乎很不错，直到文件数量或整体大小变大。一方面，有些人将整个数据集塞进几个档案中并跟踪它们。这最大限度地减少了哈希带来的挫败感，但当只有几个文件更新时会占用大量存储空间。另一方面，有些人跟踪每个文件，这样可以单独更新文件，但签入和签出非常麻烦。其他人则将这两种方法的差异分开，以分层方式跟踪数据集的块作为档案。 那么你的组织是如何管理这一点的？在处理这些庞大且不断发展的数据集时，什么有效，什么无效？    提交人    /u/SirPitchalot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1haokqp/d_how_do_you_manage_and_track_your_large_evolving/</guid>
      <pubDate>Tue, 10 Dec 2024 00:09:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 问答评估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1han84i/d_r_question_answering_evaluation/</link>
      <description><![CDATA[除了标准的精确匹配、F1、准确度、BLEU、ROUGE、BERTScore 等指标外，是否还有其他新的指标可用于评估 QA 系统（开放域和多项选择）？我正在阅读一篇列出所有这些指标的论文（https://arxiv.org/abs/2406.13232），但我很好奇是否有人发布或正在研究一种新的指标，该指标与人类判断更好地相关和/或考虑到 LLM 提供问题答案的形式。例如，如果模型没有经过微调，很难让它们预测“答案：B”（对于多项选择 QA）之类的内容，也很难让它们预测一些简短的文字，例如“巴拉克奥巴马”（对于开放域 QA）。这种行为使得 LLM 的评估不一致，我想知道是否有人在积极致力于此。     提交人    /u/Debonargon   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1han84i/d_r_question_answering_evaluation/</guid>
      <pubDate>Mon, 09 Dec 2024 23:07:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] Meta 的全新 LLama 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1han33i/d_metas_new_llama_model/</link>
      <description><![CDATA[因此，meta 刚刚放弃了一种新的、更高效的 Llama 模型 Llama 3.3 70B，该模型基本上有望降低大型 AI 模型的计算成本。这里有人有机会测试它吗？好奇地想看看它在速度、资源使用率和准确性方面与以前的版本相比表现如何    提交人    /u/Frosty_Programmer672   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1han33i/d_metas_new_llama_model/</guid>
      <pubDate>Mon, 09 Dec 2024 23:01:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人成功训练过具有模型并行性的 LLM 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1habr8l/d_has_anyone_managed_to_train_an_llm_with_model/</link>
      <description><![CDATA[您好， 我正在为我的硕士论文研究微调 Llama-3.1。不幸的是，我目前的情况不允许使用高内存 GPU，例如 A100。相反，我可以使用具有多个低内存 GPU 的设置，例如 4×3090 或 8×V100。 因此，我需要实现模型并行性来训练我的模型，因为它不适合单个 GPU。但是，我注意到大多数框架主要关注数据并行性，这并不能满足我的需求。 有没有人通过将模型拆分到多个 GPU 上来成功训练模型？如果有，您能推荐我应该探索的框架或方法吗？我特别想寻找完整的培训，尽管我有兴趣听听是否有人使用 LoRA 管理过这个。 此外，如果有更适合此类问题的 subreddit，请引导我到那里。 谢谢！    提交人    /u/anilozlu   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1habr8l/d_has_anyone_managed_to_train_an_llm_with_model/</guid>
      <pubDate>Mon, 09 Dec 2024 15:06:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 文本转视频排行榜：比较最先进的文本转视频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ha54m0/p_texttovideo_leaderboard_compare_stateoftheart/</link>
      <description><![CDATA[与文本生成不同，文本转视频生成涉及平衡真实感、对齐和艺术表达。但就输出质量而言，哪一个最重要？ 我们不知道，这就是为什么我们创建了一个基于投票的文本转视频模型排行榜，灵感来自 LLM 排行榜 lmarena.ai。 目前，排行榜有五个开源模型：HunyuanVideo、Mochi1、CogVideoX-5b、Open-Sora 1.2 和 PyramidFlow，但我们的目标是还包括来自 Kling AI、LumaLabs.ai 和 Pika.art 的著名专有模型。 这是排行榜的链接：link。 我们很乐意听到您的想法、反馈或建议。您认为应该如何评估视频生成模型？    提交人    /u/lambda-research   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ha54m0/p_texttovideo_leaderboard_compare_stateoftheart/</guid>
      <pubDate>Mon, 09 Dec 2024 08:17:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] 扩散模型、图像超分辨率以及一切：综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9wrv6/r_diffusion_models_image_superresolution_and/</link>
      <description><![CDATA[我们很高兴与大家分享我们最新的关于应用于图像超分辨率的扩散模型的调查论文。欢迎您阅读。它也是开放获取的，并发表在 IEEE TNNLS 上 :)  arXiv：https://arxiv.org/abs/2401.00736    提交人    /u/Maleficent_Stay_7737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9wrv6/r_diffusion_models_image_superresolution_and/</guid>
      <pubDate>Mon, 09 Dec 2024 00:09:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>