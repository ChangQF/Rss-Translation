<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 11 Mar 2024 06:17:21 GMT</lastBuildDate>
    <item>
      <title>[P] 在 MERN Stack 项目中集成线性回归：使用 Node.js 还是 Python？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbw5uw/p_integrating_linear_regression_in_a_mern_stack/</link>
      <description><![CDATA[我目前正在开发一个使用 MERN 堆栈（MongoDB、Express、React 和 Node.js）开发的餐厅管理面板，并且我已经遇到了一个十字路口。我的下一步涉及实施线性回归，以根据历史数据预测未来的客户流量和销售趋势。目标是直接通过管理面板向餐厅经理提供可行的见解。 鉴于我的堆栈的其余部分是基于 JavaScript 的，我最初倾向于将所有内容保留在 Node.js 生态系统中。为此，我研究了一些 JS 库，例如 simple-statistics 和 mljs。虽然我设法建立并运行基本的线性回归模型，但我开始质疑这是否是最好的方法，特别是在性能、可扩展性和高级分析功能的可用性方面。 另一方面另一方面，Python 是数据分析和机器学习的强大工具，拥有 NumPy、pandas 和 scikit-learn 等库，这些库针对线性回归等任务进行了优化且功能丰富。将 Python 集成到我的主要 JavaScript 堆栈中可能会提供更好的性能和更广泛的功能集，但代价是在管理跨语言集成方面引入复杂性。 这是我寻求您建议的地方：  p&gt;  可行性和最佳实践：对于那些已将 Python 的特定功能集成到 Node.js 或 JavaScript 后端的人，您是如何管理集成的，以及您面临的最大挑战是什么？ 性能注意事项：JavaScript/Node.js 线性回归方法能否有效扩展，或者 Python 在该领域的优势是否太显着而不容忽视? 库建议：如果建议留在 JS 生态系统内，那么除了 simple-statistics 和 mljs 之外，我还应该考虑实现哪些库线性回归？ 一般建议：您是否建议为此目的将 Python 引入堆栈，或者潜在的集成挑战对于它可能带来的好处来说是否太大？  我感谢您可以分享的任何见解、经验或资源。做出明智的决定不仅有助于实现此功能，还有助于规划项目的未来开发和可扩展性。 提前致谢！ &lt;!-- SC_ON - -&gt;  由   提交/u/Ok_Ratio_2368   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbw5uw/p_integrating_linear_regression_in_a_mern_stack/</guid>
      <pubDate>Mon, 11 Mar 2024 05:54:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] Upstage发布Dataverse：LLM时代的用户友好型数据预处理工具！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbvxpd/r_upstage_releases_dataverse_a_userfriendly_data/</link>
      <description><![CDATA[🚀 令人兴奋的消息！ Upstage 发布 Dataverse：LLM 时代的用户友好型数据预处理工具！ Dataverse 是一个可免费访问的开源项目，支持使用 Python 进行 ETL（提取、转换和加载）管道。我们为数据处理和管理提供简单、标准化和用户友好的解决方案，满足LLM时代数据科学家、分析师和开发人员的需求。即使您对 Spark 不太了解，您也可以通过 dataverse 轻松使用它。 GitHub：https://github.com/UpstageAI/dataverse   由   提交/u/Chanjun_Park   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbvxpd/r_upstage_releases_dataverse_a_userfriendly_data/</guid>
      <pubDate>Mon, 11 Mar 2024 05:39:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] Upstage发布Dataverse：LLM时代的用户友好型数据预处理工具！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbvxpb/r_upstage_releases_dataverse_a_userfriendly_data/</link>
      <description><![CDATA[🚀 令人兴奋的消息！ Upstage 发布 Dataverse：LLM 时代的用户友好型数据预处理工具！ Dataverse 是一个可免费访问的开源项目，支持使用 Python 进行 ETL（提取、转换和加载）管道。我们为数据处理和管理提供简单、标准化和用户友好的解决方案，满足LLM时代数据科学家、分析师和开发人员的需求。即使您对 Spark 不太了解，您也可以通过 dataverse 轻松使用它。 GitHub：https://github.com/UpstageAI/dataverse   由   提交/u/Chanjun_Park   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbvxpb/r_upstage_releases_dataverse_a_userfriendly_data/</guid>
      <pubDate>Mon, 11 Mar 2024 05:39:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] ML 平台建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbvwbx/p_ml_platform_recommendations/</link>
      <description><![CDATA[大家好，我即将开始我的第一个 ML 项目。我想构建一个系统，可以输入视频数据并输出某些观察结果并将它们写入我的数据库中。哪种机器学习平台适合分析视频数据？   由   提交/u/aghazi22  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbvwbx/p_ml_platform_recommendations/</guid>
      <pubDate>Mon, 11 Mar 2024 05:36:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 已弃用框架的兼容性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbvmeh/p_compatibility_of_deprecated_frameworks/</link>
      <description><![CDATA[嘿，我一直在尝试为命名实体识别任务构建 BiLSTM-CRF 模型，显然，我一直在使用TensorFlow 2.16 和 Keras 3.0。然而，在尝试使用已弃用的 keras_contrib 或 tensorflow_addons GitHub 资源实现 CRF 层时，我遇到了无数问题，因为这些框架可能与最新的 TF 和 Keras 版本不兼容。不过，我不愿意仅仅为了这个而降级到较低版本的TF。有没有合适的替代方案可以用来完成我的任务？ 谢谢！   由   提交/u/LouisTrance123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbvmeh/p_compatibility_of_deprecated_frameworks/</guid>
      <pubDate>Mon, 11 Mar 2024 05:19:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求建议：使用廉价组件运行旧版本的 Rapids</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbuhq2/d_seeking_advice_using_cheap_components_for/</link>
      <description><![CDATA[大家好，我是新来的。我想知道是否可以使用相当便宜的组件来运行旧版本的 Rapids，因为最新的 24.02 版本不支持 Pascal 的 GPU。 我的想法是使用一些带有多个废弃的 E5v4 CPU矿卡 - P102 10Gb，非常便宜，并且提供与 1080ti 几乎相同的性能。唯一的缺点是它们只支持 PCIe 3.0x4（每卡 40 美元）。 我发现有些人可以安装 NVIDIA 驱动程序版本 525 或更高版本，可以与 CUDA 12 配对。但是，我找不到任何安装旧版本Rapid AI的文档。 我主要想将它用于CuDF。 非常感谢！    由   提交 /u/Exciting-Purple346    reddit.com/r/MachineLearning/comments/1bbuhq2/d_seeking_advice_using_cheap_components_for/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbuhq2/d_seeking_advice_using_cheap_components_for/</guid>
      <pubDate>Mon, 11 Mar 2024 04:14:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对比学习的梯度累积（InfoNCE）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbuacq/d_gradient_accumulation_for_contrastive_learning/</link>
      <description><![CDATA[我正在训练多模态对齐模型，但即使使用混合精度训练，我的 GPU 也只能容纳 64 的批量大小。根据 SimCLR 论文，较小的批量大小对于学习来说并不是最佳选择。有什么办法可以在这里实现梯度累积吗？   由   提交/u/Mad_Scientist2027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbuacq/d_gradient_accumulation_for_contrastive_learning/</guid>
      <pubDate>Mon, 11 Mar 2024 04:03:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 尝试使用 JEPA 理解推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbnb5q/d_trying_to_understand_inference_with_jepa/</link>
      <description><![CDATA[灵感来自 Lex Fridmans 播客剧集 与 Yann LeCun 一起，我试图通过阅读 I-JEPA 论文来提高我对 JEPA 和基于能量的模型的理解以及这些讲义。  我从学习高度语义特征的角度理解JEPA的吸引力/半监督过程中连续图像数据的表示。但真正让我困惑的是 Yann LeCun 的说法，一旦像这样的模型经过训练，你就可以进行基于优化的推理，基本上优化 Y 以最小化能量。  这个生成过程已经被证明了吗？除了预训练的 JEPA 模型之外，为了在这个基于优化的过程中生成图像/文本响应，还需要哪些组件？   由   提交/u/flxh13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbnb5q/d_trying_to_understand_inference_with_jepa/</guid>
      <pubDate>Sun, 10 Mar 2024 22:37:56 GMT</pubDate>
    </item>
    <item>
      <title>拥有非参数估计背景是否是进入机器学习的有用途径？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbk0i6/is_having_a_background_in_nonparametric/</link>
      <description><![CDATA[我是统计学硕士生。我的背景几乎全部基于基础统计理论，我的论文是非参数估计（特别是非参数回归）。基本上，我的“机器学习”知识源于一些经典的非参数估计书籍，例如（Tysbakov、Wasserman、Tibshirani/Hastie 和 Friedman）。统计学习的要素几乎是我在机器学习方面的背景，因为我的论文是关于非参数回归的经典方法之间的交集，例如基于树的方法、核平滑器和样条曲线，用于估计因果推理中的平均治疗效果。 但是，我有时会觉得自己的机器学习背景“相当老”。比如说，我不知道非参数回归背景对于现代机器学习工作有多有吸引力。一般来说，我们深入研究了非参数和统计学中的许多渐近理论，而且我知道对于大多数机器学习工作来说，没有人真正关心渐近保证。  有谁知道我的知识是否真的与当今主要关注神经网络的时代的机器学习工作相关？   由   提交/u/Direct-Touch469   reddit.com/r/MachineLearning/comments/1bbk0i6/is_having_a_background_in_nonparametric/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbk0i6/is_having_a_background_in_nonparametric/</guid>
      <pubDate>Sun, 10 Mar 2024 20:22:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] Lora 的记忆增益从何而来？ （除了优化器状态）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbgu8d/d_where_do_lora_memory_gains_come_from_apart_from/</link>
      <description><![CDATA[你好， 我已经阅读 Lora 的解释几个小时了，有一些东西我无法包装我的环顾四周：记忆力增强。我知道优化器状态可以获得很多冻结层不需要的效果。 但是，在 Lora 论文（第 4.2 章）中指出  与完全微调相比，我们还观察到在 GPT-3 175B 上的训练过程中加速了 25%，因为我们不需要计算绝大多数参数的梯度。  但是冻结层的梯度不需要计算吗？即使它们的权重不会随之更新，也必须计算它以获得可训练矩阵的梯度。 在经典微调中，需要梯度，因为大多数时候只有最后一层是训练完毕，反向传播就到此为止，但是对于 Lora，可训练参数位于所有注意力头中，因此反向传播需要继续直到那里，还是我误解了什么？ 所以，如果需要梯度，并且还需要激活+权重，那么唯一的内存增益将来自优化器？根据我的经验，LoRA 内存使用量似乎比“正常”内存使用量低得多。微调，所以我想有些东西我不明白 ​ 非常感谢您的帮助！   由   提交 /u/Wats0ns   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbgu8d/d_where_do_lora_memory_gains_come_from_apart_from/</guid>
      <pubDate>Sun, 10 Mar 2024 18:12:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] OpenAI：JSON 模式与函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbgky4/r_openai_json_mode_vs_functions/</link>
      <description><![CDATA[       由   提交/u/JClub  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbgky4/r_openai_json_mode_vs_functions/</guid>
      <pubDate>Sun, 10 Mar 2024 18:01:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024年，强化学习的最新趋势是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbawez/d_in_2024_what_are_the_latest_trends_on_rl/</link>
      <description><![CDATA[嗨， 这些天我正在研究决策转换器。 有争议的，同时试图找到最重要的论文，我注意到强化学习领域似乎没有发生太多事情。我注意到研究的重点是优化 Transformer 和训练巨大的语言和视觉模型（被视为监督模型）。这是强化学习领域的新大事吗？ 强化学习的最新趋势是什么？   由   提交/u/__Julia  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbawez/d_in_2024_what_are_the_latest_trends_on_rl/</guid>
      <pubDate>Sun, 10 Mar 2024 13:55:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年用于机器学习的 AMD 卡？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bb9ylx/d_amd_cards_for_machine_learning_in_2024/</link>
      <description><![CDATA[AMD 和 AI 的状况如何？我想知道 AMD 和 Nvidia GPU 之间的性能差异有多大，以及 7600xt 是否充分支持 pytorch 和 TensorFlow 等机器学习库。上次我听说 AMD 卡可以支持 ROCm，但存在不一致、软件问题以及速度慢 2 - 5 倍的问题。 就个人而言，您会选择 rx7600 而不是 4060 吗？    由   提交 /u/AtomicPiano   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bb9ylx/d_amd_cards_for_machine_learning_in_2024/</guid>
      <pubDate>Sun, 10 Mar 2024 13:08:44 GMT</pubDate>
    </item>
    <item>
      <title>GAN 仍然有意义吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bb34gj/are_gans_still_relevant_d/</link>
      <description><![CDATA[[D] 随着 Difussion 模型的不断兴起，我很好奇 GAN 是否会卷土重来？有什么想法吗？   由   提交 /u/Superb-Assignment-30   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bb34gj/are_gans_still_relevant_d/</guid>
      <pubDate>Sun, 10 Mar 2024 06:00:24 GMT</pubDate>
    </item>
    </channel>
</rss>