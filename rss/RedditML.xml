<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 12 Apr 2024 00:58:46 GMT</lastBuildDate>
    <item>
      <title>[D] 关于验证集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1vdgs/d_about_validation_set/</link>
      <description><![CDATA[我听说我只能使用测试集一次，但是如果我在测试集上没有得到很好的结果，我可以合并将测试集放入验证集，重新调整超参数，然后收集另一个测试集？  此外，如果我发现模型由于光照不良或域外数据而不能很好地处理某些数据，如果我在论文中记录这一点，我可以将它们从验证集中删除吗？ 我觉得这两种方式可能是“将数据改变成我们想要的”并对此感到有点不安。  谢谢   由   提交 /u/Striking-Warning9533    reddit.com/r/MachineLearning/comments/1c1vdgs/d_about_validation_set/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1vdgs/d_about_validation_set/</guid>
      <pubDate>Fri, 12 Apr 2024 00:34:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 变形金刚的注意力机制类似于神经科学中联想记忆模型的现代迭代。我展示了自联想和异联想混合物可以执行一系列任务+建议新的神经启发 Transformer 插值方法。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1pf30/r_the_attention_mechanism_of_transformers/</link>
      <description><![CDATA[   从机制上讲，注意力似乎执行异质关联。实际上，原则上它可以混合自动和自动混合。异性关联在一起。 问题：这允许什么能力？回答：很多！  有限自动机 通过为图像或文本数据分配神经活动，并将其组合转换为自关联吸引子（状态）或异关联准吸引子（转移），我们可以模拟有限自动机。 （参见下面链接的论文的第 3.4 节和附录 A12）  将有限自动机映射到“内存图”的示例。  多尺度图形表示 通过调整自关联（a）和异关联（h）的强度，我们可以选择我们希望识别的图形关系的比例或粗糙度。 （请参阅下面链接的论文的第 3.2 节和附录 A2）  使用关联内存进行检测时，不同活动规模分布在其顶点（内存模式）的 Tutte 图网络。  稳定视频的回忆 自然视频的帧之间通常具有很大的时间依赖性。实现自关联和异关联之间的适当平衡有助于防止视频“卡在”帧上或向前跳动。 （请参阅下面链接的论文的第 3.3 节和附录 A11） 视频帧（内存模式）随时间的相关性，显示 a 和 h 的值如何影响召回的平滑度。  内存保真度和内存保真度之间的优雅权衡。能力，通过异质关联相似的记忆和记忆对。 “检索”那些具有最高重叠度的内容。 （参见附录 A3） 神经科学数据的复制显示猴子颞叶皮层中的异质关联。 （参见附录A7） 左：内存负载方面的非传统自动关联性能。右图：a 和 h 的设置与猴子颞叶皮层的数据非常匹配。  这让我建议对变形金刚进行受神经科学启发的可解释性分析，并提出为什么叠加应该与“上下文切换”和“上下文切换”相关的假设。暗示“数据相关的几何形状”。 了解更多信息 -- 论文： https://arxiv.org/abs/2404.07123 GitHub：&lt; /strong&gt; https://github.com/tfburns/CDAM   由   提交/u/tfburns  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1pf30/r_the_attention_mechanism_of_transformers/</guid>
      <pubDate>Thu, 11 Apr 2024 20:30:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有没有人可以使用注意力可视化工具来生成注意力可视化，例如“注意力就是您所需要的一切”附录中的工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1oo7y/r_does_anyone_have_access_to_an_attention/</link>
      <description><![CDATA[由于许多论文没有附录，这里有一个，这样你就知道我在说什么：https://arxiv.org/pdf/1706.03762.pdf 附录中是注意力生成的连接的可视化机制，“似乎表现出与句子的句法和语义结构相关的行为”。 有人知道这些是如何生成的，或者有生成类似的工具或方法吗？ ​ 提前致谢！   由   提交 /u/mcarlin2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1oo7y/r_does_anyone_have_access_to_an_attention/</guid>
      <pubDate>Thu, 11 Apr 2024 20:01:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] ReFT：语言模型的表示微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1nvwi/r_reft_representation_finetuning_for_language/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.03592 代码：https://github .com/stanfordnlp/pyreft 摘要：  参数高效微调（PEFT）方法寻求适应大的通过更新少量权重来调整模型。然而，许多先前的可解释性工作表明，表示编码了丰富的语义信息，这表明编辑表示可能是一种更强大的替代方案。在这里，我们通过开发一系列表示微调 (ReFT) 方法来追求这一假设。 ReFT 方法在冻结的基础模型上运行，并学习对隐藏表示的特定任务干预。我们定义了 ReFT 系列的一个强大实例，低秩线性子空间 ReFT (LoReFT)。 LoReFT 是现有 PEFT 的直接替代品，其学习干预措施的参数效率比之前最先进的 PEFT 高 10 至 50 倍。我们展示了 LoReFT 在八个常识推理任务、四个算术推理任务、Alpaca-Eval v1.0 和 GLUE 上的表现。在所有这些评估中，LoReFT 提供了效率和性能的最佳平衡，并且几乎总是优于最先进的 PEFT。我们在 此 https URL 公开发布通用 ReFT 训练库。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1nvwi/r_reft_representation_finetuning_for_language/</guid>
      <pubDate>Thu, 11 Apr 2024 19:30:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] ReALM：参考解析作为语言建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1noed/r_realm_reference_resolution_as_language_modeling/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.20329 摘要：  参考解析是一个重要的问题，是理解这个问题所必需的并成功处理不同类型的上下文。此上下文包括先前的轮次和与非会话实体相关的上下文，例如用户屏幕上的实体或在后台运行的实体。虽然法学硕士已被证明对于各种任务都非常强大，但它们在参考解析中的使用，特别是对于非会话实体，仍然没有得到充分利用。本文通过展示如何将引用解析转换为语言建模问题，展示了如何使用法学硕士来创建一个极其有效的系统来解析各种类型的引用，尽管涉及到传统上不利于解决问题的屏幕上的实体形式。被简化为纯文本模式。我们展示了对不同类型参考具有类似功能的现有系统的巨大改进，我们最小的模型在屏幕参考上获得了超过 5% 的绝对增益。我们还对 GPT-3.5 和 GPT-4 进行了基准测试，我们最小的模型实现了与 GPT-4 相当的性能，而我们较大的模型则大大优于它。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1noed/r_realm_reference_resolution_as_language_modeling/</guid>
      <pubDate>Thu, 11 Apr 2024 19:21:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无限上下文变形金刚</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1l16l/r_infinite_context_transformers/</link>
      <description><![CDATA[我看了一下，没有在本文中看到任何看起来很有希望的讨论主题。  https://arxiv.org/abs/2404.07143  你的想法？这可能是 Gemini 1.5 报告的 10m 令牌上下文长度背后的技术之一吗？    由   提交 /u/Dyoakom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1l16l/r_infinite_context_transformers/</guid>
      <pubDate>Thu, 11 Apr 2024 17:35:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语义分割模型是否没有适当的可解释性方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1hi3z/d_are_there_no_proper_explainability_approaches/</link>
      <description><![CDATA[嘿，我目前正在更多地研究人工智能的可解释性，并希望对我的分割模型的结果有更多的了解（U-Net和 DeepLabV3）。 寻找解释我的输出（或网络的中间层）的可能性，我无法真正找到可靠的结果。  我可以看到，在 SHAP 示例中，有一个示例展示了如何使用 PyTorch 对 ImageNet 上的 VGG16 中间层进行一些解释（此处）。然而，这仍然显示了一个分类任务，并且尝试将其应用于我自己的问题并没有按预期进行。我也尝试过使用他们的 DeepExplainer，但这并没有真正给我带来任何结果。 语义分割问题没有可解释的方法吗？然而，我可以找到一两篇研究论文，对它们的最终结果进行分类，然后应用，例如： Grad-CAM 这只是分段的一种可解释性，不是吗？   由   提交/u/_awake  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1hi3z/d_are_there_no_proper_explainability_approaches/</guid>
      <pubDate>Thu, 11 Apr 2024 15:10:17 GMT</pubDate>
    </item>
    <item>
      <title>[P]使用GAN生成结构化文本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1gqqh/p_use_gan_for_generating_structured_text/</link>
      <description><![CDATA[我正处于个人项目的第一阶段，我想从数据集中生成新数据，以便稍后在项目中使用。数据是一个结构化测试（它就像一个日志文件），我想创建一个基于数据集生成新文件的 GAN。我很感谢使用 GAN 来做到这一点，但我不确定这是否是正确的路径，因为我发现它们主要用于图像。您对文本生成 GAN 有什么建议或实现吗？   由   提交/u/redska_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1gqqh/p_use_gan_for_generating_structured_text/</guid>
      <pubDate>Thu, 11 Apr 2024 14:39:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在论文《More Agents Is All You Need》中，为什么他们使用 BLEU 分数来计算集成投票的相似度而不是余弦相似度之类的东西？有后续研究比较方法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1e0x4/d_in_the_paper_more_agents_is_all_you_need_why/</link>
      <description><![CDATA[论文：https://arxiv.org/pdf /2402.05120.pdf 在论文中，他们有法学硕士集体回答问题。对于离散答案，例如多项选择题，他们只选择最常见的答案。对于“连续”来说，对于像代码这样的答案，他们使用 BLEU 分数来查找与其他答案最相似的答案。 有人知道为什么选择这个答案而不是余弦相似度之类的答案吗？他们看起来并没有解释这个选择，但他们的结果很好，所以我猜它有效！   由   提交/u/30299578815310  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1e0x4/d_in_the_paper_more_agents_is_all_you_need_why/</guid>
      <pubDate>Thu, 11 Apr 2024 12:39:47 GMT</pubDate>
    </item>
    <item>
      <title>LLM 擅长 NL 到代码和 NL 到 SQL 任务吗？ [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1bfxv/are_llms_good_at_nltocode_nltosql_tasks_discussion/</link>
      <description><![CDATA[大家好， 在过去的几天里，我一直在研究大型语言模型在特定于 &gt;NL 到代码，主要是 NL 到 SQL 任务。我想从我们的从业者社区中听到更多有关此问题的信息。 这种兴趣主要源于使用法学硕士进行编码的好奇心和效率。我想知道您对他们的表演有什么感受吗？ - 在准确性、效率等方面？您尝试过哪些模型来完成此任务？您认为哪种模型最有效？   由   提交 /u/Traditional-Lynx-684   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1bfxv/are_llms_good_at_nltocode_nltosql_tasks_discussion/</guid>
      <pubDate>Thu, 11 Apr 2024 10:12:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]深度学习模型的Hessian及其特征向量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c15ro1/d_hessian_of_deep_learning_model_and_its/</link>
      <description><![CDATA[我试图了解有关 Hessian 矩阵、其特征向量以及如何优化它们的更多信息。谁能给我提供一些关于这方面的见解（或者推荐对这方面有深刻见解的论文）？比如 Hessian 矩阵的特征向量代表什么，它们在良好的广义模型中应该如何表现。   由   提交 /u/Competitive_Newt_100   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c15ro1/d_hessian_of_deep_learning_model_and_its/</guid>
      <pubDate>Thu, 11 Apr 2024 04:08:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您最近关注 MLOps 领域有哪些有趣的发展？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c155wj/d_what_interesting_developments_in_the_mlops/</link>
      <description><![CDATA[最近感觉停滞不前。希望将一些尖端技术融入到我的 MLOps 堆栈中。但不知道从哪里开始，甚至不知道从哪里开始。 发展速度绝对是势不可挡的，尤其是现在基础法学硕士的狂野西部性质。因此，我希望这篇文章能够产生一些有用的线索供探索。 博客或论文链接的奖励积分。没有必要将自己限制在一件事情上。 TIA！   由   提交 /u/synthphreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c155wj/d_what_interesting_developments_in_the_mlops/</guid>
      <pubDate>Thu, 11 Apr 2024 03:35:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对象识别的自回归模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c141qv/r_an_autoregression_model_for_object_recognition/</link>
      <description><![CDATA[      大家好！ 我想分享一下我们最近的 CVPR 工作，希望能够传播我们简单的想法并收集见解 [TL;DR] 自回归模型可以仅根据输入图像预测标签，无需预定义的查询库（例如，类似 CLIP 的模型）或预定义的类概念（例如，类似 VGG/ResNet 的模型）。该模型从整个文本空间（任何标签）中预测前 K 个标签，例如 top-100。 有关更多详细信息，请访问我们的论文和项目：&lt; a href=&quot;https://github.com/kaiyuyue/nxtp&quot;&gt;https://github.com/kaiyuyue/nxtp。 感谢您的想法和反馈。非常感谢！ -----图----- https://preview.redd.it/vkbh3llzlwtc1.png?width=1102&amp;format=png&amp;auto=webp&amp;s=5213af64e5dfc1f 4479c7b502617a8aabe17dfd8&lt; /p&gt;   由   提交/u/pidoyu  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c141qv/r_an_autoregression_model_for_object_recognition/</guid>
      <pubDate>Thu, 11 Apr 2024 02:37:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您建议在哪些方面测试新的通用方法（架构/优化器）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0vh48/d_what_would_you_recommend_testing_new_general/</link>
      <description><![CDATA[到目前为止，我的很多工作都是关于优化器和架构的，但在发布研究结果时只在小型标记预测语言任务上测试过它们。您需要看到什么才能确信一种新颖的通用方法确实更优越？非常感谢具体的数据集和模型大小以及相关基准。   由   提交 /u/LahmacunBear   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0vh48/d_what_would_you_recommend_testing_new_general/</guid>
      <pubDate>Wed, 10 Apr 2024 20:20:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>