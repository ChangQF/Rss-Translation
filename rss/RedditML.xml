<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 27 Dec 2024 06:23:01 GMT</lastBuildDate>
    <item>
      <title>[R] 具有大量类别的文本分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hn1opy/r_text_classification_with_lots_of_classes/</link>
      <description><![CDATA[因此，我有一个包含大约 15K 条西班牙语评论的数据集，总共有 191 个不同的标签。我可以使用什么来对这段文本进行分类？ 我想过 Bert 之类的。但解决这个问题的最佳方法是什么？    提交人    /u/Ok_Ferret4986   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hn1opy/r_text_classification_with_lots_of_classes/</guid>
      <pubDate>Thu, 26 Dec 2024 23:56:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] : 文档恢复</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hn0q98/d_document_restoration/</link>
      <description><![CDATA[我见过很多关于这个的奇特的东西，比如改革者、GAN 等等。我不是很先进，我只是想用 1912 年的一份文件试试看，笔迹很难理解。我正在考虑使用 CNN，因为我对它们很熟悉，但我不确定它是否有用或者是一个很好的起点？有什么建议吗？    提交人    /u/Affectionate_Pen6368   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hn0q98/d_document_restoration/</guid>
      <pubDate>Thu, 26 Dec 2024 23:10:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 违反比例风险假设：我该怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmz1cs/p_violation_of_proportional_hazards_assumption/</link>
      <description><![CDATA[我正在开展一个项目，需要预测患者的造血细胞移植 (HCT) 后存活率。我有事件目标和事件发生时间目标。 事后看来，我的方法是使用生命线库 (Kaplan-Meier、Nelson-Aalen、CoxPH) 中的生存模型来估计风险评分，我将使用该评分作为 LightGBM 和 CatBoost 的回归目标。评估指标是分层一致性指数 (C 指数)。 使用 CoxPH 模型，我必须将所有分类特征转换为数字，因为 CoxPH 仅接受数值协变量 (特征)。但是，181 个协变量中至少有 40 个的 p 值小于 0.05 - 这违反了比例风险假设。 这是一个需要考虑的重要因素吗？我应该保留还是放弃针对 CoxPH 生存模型创建的目标进行训练的模型？违规行为是否会使生存模型“不可信”？    提交人    /u/TechNerd10191   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmz1cs/p_violation_of_proportional_hazards_assumption/</guid>
      <pubDate>Thu, 26 Dec 2024 21:51:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士 (LLM) 的机械可解释性中，有哪些常见的开放式问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmxxwf/d_what_are_some_popular_openended_problems_in/</link>
      <description><![CDATA[大家好，我对法学硕士及其研究非常熟悉。我对机械可解释性很感兴趣，并开始从事该领域的工作。作为机械可解释性的新手，我计划在该领域攻读博士学位，我应该开始探索该领域中哪些流行的开放式问题？很想听听这里的可解释性研究人员的见解。    提交人    /u/arinjay_11020   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmxxwf/d_what_are_some_popular_openended_problems_in/</guid>
      <pubDate>Thu, 26 Dec 2024 21:02:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 本地即插即用，语音转文本法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmwnm1/p_local_plug_in_play_llm_for_speech_to_text/</link>
      <description><![CDATA[您好，我希望创建一个可以在便携式设备上运行的本地 LLM，可以通过 SSD 在运行它的本地计算机上运行，​​也可以通过我直接连接到 LLM 的便携式计算机运行。 用例是在本地医院计算机上将医疗笔记进行语音到文本转录。    提交人    /u/Glittering_School994   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmwnm1/p_local_plug_in_play_llm_for_speech_to_text/</guid>
      <pubDate>Thu, 26 Dec 2024 20:03:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过优化内存管理在单个消费者 GPU 上微调 175B 参数语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmpck4/r_finetuning_175b_parameter_language_models_on_a/</link>
      <description><![CDATA[这里的关键技术进步是通过巧妙的内存管理和 NVMe SSD 利用率在单个消费级 GPU 上实现 100B 参数模型的微调。研究人员开发了一个框架，可在保持训练质量的同时优化 GPU、CPU RAM 和存储之间的数据移动。 主要技术贡献：- 为消费级硬件实现修改后的 ZeRO-Infinity 优化- 具有动态参数卸载的三层内存层次结构- 可减少内存访问延迟的新型预取系统- 优化存储层之间的数据传输模式- 跨 GPU/CPU/NVMe 的内存带宽管理 主要结果：- 与现有的单 GPU 方法相比，速度提高了 2.6 倍- 所需 GPU 内存减少 70%- 成功微调 100B 参数模型- 与多 GPU 设置相当的训练质量- 在消费级硬件配置上进行了验证 我认为这可以让个人研究人员和小型实验室更容易进行大型模型微调。虽然它不会在生产场景中取代多 GPU 训练，但它可以快速进行原型设计和实验，而无需昂贵的硬件集群。这里的技术还可以为未来内存高效的训练方法提供参考。 权衡似乎是合理的——较慢的训练换来大幅降低成本。但是，我希望看到对不同模型架构和训练任务进行更广泛的测试，以充分验证该方法。 TLDR：新框架通过优化的内存管理和 NVMe 利用率，可以在单个消费者 GPU 上微调 100B 参数模型，与现有方法相比，速度提高了 2.6 倍。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmpck4/r_finetuning_175b_parameter_language_models_on_a/</guid>
      <pubDate>Thu, 26 Dec 2024 14:25:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] “激活工程”能否取代提示工程或微调作为操纵模型的技术？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmjdh3/d_could_activation_engineering_replace_prompt/</link>
      <description><![CDATA[如果您不知道，激活工程只是一个流行词，用于操纵 LLM 中的激活向量来控制其行为。一个著名的例子是“金门克劳德”，其中人类工程师上调了代表模型潜在空间中“金门大桥”概念的神经元。这样做之后，该模型开始将金门大桥编织到其所有响应中，甚至开始将自己识别为金门大桥。 目前，这种可解释性工作主要存在于文献中，但我很好奇您是否预计“激活工程”的真正工具会成为主流。您如何看待未来的转向模型？    提交者    /u/jsonathan   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmjdh3/d_could_activation_engineering_replace_prompt/</guid>
      <pubDate>Thu, 26 Dec 2024 07:22:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每个人都对 LLM 如此感兴趣，但 Transformer 架构能否用于改进更“传统”的机器学习领域</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmitcz/d_everyone_is_so_into_llms_but_can_the/</link>
      <description><![CDATA[我正在考虑诸如推荐算法之类的东西，这些算法依赖于无监督学习或许多其他无监督算法 我会更深入地研究它，但也许想对此有一些想法    提交人    /u/noithatweedisloud   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmitcz/d_everyone_is_so_into_llms_but_can_the/</guid>
      <pubDate>Thu, 26 Dec 2024 06:40:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 物理学和逻辑学的结合最近取得了什么进展？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hmds2k/dhow_have_recent_advancements_with_incorporating/</link>
      <description><![CDATA[去年，关于这项技术将带来的承诺，曾有过大量讨论，但之后就没有什么进展了。    由    /u/sext-scientist  提交  [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hmds2k/dhow_have_recent_advancements_with_incorporating/</guid>
      <pubDate>Thu, 26 Dec 2024 01:28:20 GMT</pubDate>
    </item>
    <item>
      <title>太字节级 MoE：一种用于超越 RAM 模型推理的学习型按需专家加载和智能缓存框架 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm93jj/terabytescale_moes_a_learned_ondemand_expert/</link>
      <description><![CDATA[大型模型很容易装入硬盘，但很难装入 RAM 或 VRAM。以下是我解决这个问题的想法： 在 RAM 中训练一个包含所有专家的大型混合专家模型，然后在推理时，一个学习机制会动态地将相关专家加载到 VRAM/RAM 中。这允许模型超出硬件的内存限制，同时保持推理效率，因为系统本身学习哪些专家需要“热门”并避免不必要的交换。当然，交换仍然会发生，但希望很少发生。 已经尝试过类似的事情了吗？    提交人    /u/thepok   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm93jj/terabytescale_moes_a_learned_ondemand_expert/</guid>
      <pubDate>Wed, 25 Dec 2024 21:09:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 教 VLM 通过读写任务将手写图像转换为数字墨水</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm8a6s/r_teaching_vlms_to_convert_handwritten_images/</link>
      <description><![CDATA[InkSight：通过学习阅读和书写实现离线到在线手写转换 项目页面 | 模型发布 | Google 研究博客 TLDR： 通过教授视觉语言模型进行阅读和书写，我们能够弥合传统手写和数字墨水之间的差距，提供通过盲目研究评估的高质量数字描摹，其中 87% 被判定为有效， 67% 与人类生成的墨水无法区分。 消融研究强调了识别（“阅读”）任务在确保语义一致性方面的重要性，而推理策略则展示了处理模糊笔迹的灵活性。此外，使用去渲染墨水作为训练数据与真实世界数据集结合可增强手写识别，将字符错误率降低至 4.6%。这些发现展示了 InkSight 在推进手写数字化和识别系统方面的潜力。    提交人    /u/CharlieLee666   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm8a6s/r_teaching_vlms_to_convert_handwritten_images/</guid>
      <pubDate>Wed, 25 Dec 2024 20:26:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 无编码器视觉语言模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hm6qpu/d_encoder_free_vision_language_models/</link>
      <description><![CDATA[节日快乐！有没有关于无编码器 VLM 的有趣论文？最近在看视频 VLM，最大的麻烦是编码器效率。此外，端到端质量在很大程度上受限于视觉编码器的质量，而视觉编码器通常是 CLIP 样式模型。有 Fuyu 模型系列，但这种架构似乎表现不佳。最近有一篇 NeurlPS 论文：https://github.com/baaivision/EVE 看起来很有趣。期待对这个工作方向的评论和建议。    提交人    /u/encoreway2020   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hm6qpu/d_encoder_free_vision_language_models/</guid>
      <pubDate>Wed, 25 Dec 2024 19:04:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] JaVAD——又一款语音活动检测器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hlz6az/p_javad_just_another_voice_activity_detector/</link>
      <description><![CDATA[刚刚发布了我在过去 3 个月内研究的一个 VAD（不计算模型本身的时间），它看起来至少与其他开源 VAD 相当或更好。  它是一个自定义的基于卷积的架构，在梅尔频谱图上使用滑动窗口，因此速度也非常快（在 3090 上需要 16.5 秒来加载和处理来自测试集的 18.5 小时的音频）。 它也非常紧凑（包括检查点在内的所有内容都适合 PyPI 包），如果你不需要加载音频，核心功能依赖只是 pytorch 和 numpy。 其他一些 VAD 是通过混合语音和噪音在合成数据上进行训练的，我认为这就是它们在嘈杂音频上落后的原因。对于这个项目，我手动标记了数十个 YouTube 视频，特别是老电影和电视节目，其中有很多噪音。 还有一个用于流媒体的类，尽管由于滑动窗口和规范化的性质，处理音频的初始部分可能会导致较低质量的预测。 MIT 许可证  这是一个个人项目，所以我很确定我错过了一些东西（或者很多），请随时在 github 上发表评论或提出问题。 这是链接：https://github.com/skrbnv/javad    提交人    /u/ApprehensiveLet1405   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hlz6az/p_javad_just_another_voice_activity_detector/</guid>
      <pubDate>Wed, 25 Dec 2024 11:33:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>