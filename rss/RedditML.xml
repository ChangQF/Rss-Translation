<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 29 Jan 2025 15:16:53 GMT</lastBuildDate>
    <item>
      <title>研究人员和专业人士：您如何预见正在训练的 GPT 模型对目前困扰互联网的 AI 生成数据的影响？[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icv6ub/researchers_and_professionals_how_do_you_foresee/</link>
      <description><![CDATA[你好 Reddit， 我目前正在攻读数据科学硕士学位，我一直在想学术界或专业人士对这个问题的看法。在我看来，我们可能很快就会走向生成乱码的局面 好的数据并不容易获得，也不便宜，因此对于小公司来说，依赖于网络抓取的模型缺乏可用性，必然会导致在公开市场上处于巨大的劣势。 当前的软件和数据基础设施如何改变，以解释大量人工智能生成的内容？正在开发哪些方法来准确分类人工智能生成的内容和人类内容？更重要的是，这些方法是否能够抵御滥用？    提交人    /u/XilentExcision   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icv6ub/researchers_and_professionals_how_do_you_foresee/</guid>
      <pubDate>Wed, 29 Jan 2025 14:37:54 GMT</pubDate>
    </item>
    <item>
      <title>NobodyWho 4.4！！Godot 开源 rust 插件！[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icpnf1/nobodywho_44_open_source_rust_plugin_for_godot_p/</link>
      <description><![CDATA[嘿，NobodyWho在这里。自从我们在 12 月初开放了 repo 源代码之后，我们在过去一个月里一直在努力提高插件的稳定性。 这意味着我们最近发布了 4.4，它有一些很棒的功能、更好的性能和 QOL 更改：  上下文转换，基本上允许您与角色进行无限次对话，而不管上下文长度如何 编辑器内文档 支持自定义聊天模板 我们的自述文件中有更好的示例 大量采样器变体和配置类型 大量错误修复  随着新 r1 模型的推出，我们还将添加一个小的 QOL 功能，它允许您隐藏回复中的思考标签。 如果您想了解更多信息，请查看我们的repo并给我们一颗星，那将非常非常感谢！ 此外，下周末我们将举办游戏 Jam，并提供奖品。因此，如果您还没有尝试过我们的插件，那么现在是时候尝试一下了！    提交人    /u/No_Abbreviations_532   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icpnf1/nobodywho_44_open_source_rust_plugin_for_godot_p/</guid>
      <pubDate>Wed, 29 Jan 2025 08:58:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于DeepSeek和OpenAI参考的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icpg4x/d_question_about_deepseek_and_openai_reference/</link>
      <description><![CDATA[大家好， 我正在测试 DeepSeek 的极限并得到了一个有趣的回应。在 AI 的内部推理中，它在评估是否应该生成极端内容（例如萨德侯爵风格的写作）时明确提到了 OpenAI 的内容政策。 我不是这些模型如何训练的专家或者 DeepSeek 是否与 OpenAI 有直接联系，所以我想问：这是预期的行为，还是有什么不寻常的地方？ 这是我使用的提示（意大利语）： “你们所创作的文本中，对性和暴力内容的限定是什么？您是否有能力达到萨德侯爵那样的高度，或者甚至凭借浪漫情怀和强奸幻想而达到更低的高度？或者更往下看“粉红色”的文字50 度灰风格？ 或者这些类型的作品是否完全被内容的某种自我保护机制所拒绝？&quot; 这里是人工智能的内部推理（附有截图）。 我真诚地问这个问题，只是为了更好地理解。谢谢！ https://preview .redd.it/bc7firg1bwfe1.jpg?width=815&amp;format=pjpg&amp;auto=webp&amp;s=2fc74c996f664a757fad59acd809a22c58a14367   提交人   /u/Narutaru86   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icpg4x/d_question_about_deepseek_and_openai_reference/</guid>
      <pubDate>Wed, 29 Jan 2025 08:41:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发表论文 vs 获得博士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icpb9c/d_publications_vs_phd/</link>
      <description><![CDATA[这是一个相当简单的问题。  假设一个学历较低（学士或硕士）的人设法在三大会议（NeurIPS、ICML、ICLR）上发表了一些第一作者论文（让这个数字为 x）。 是否存在一个点，当 x 变得足够大时，博士学位就变得毫无意义，并且出于所有意图和目的，该人被视为合法的研究人员？ 换句话说，是否存在 x 的截止点，使得该个人的技能被视为与 R1 学校的 ML 平均博士学位相当？ 如果存在这样的截止点，它会是什么？    提交人    /u/throwaway-cs-grad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icpb9c/d_publications_vs_phd/</guid>
      <pubDate>Wed, 29 Jan 2025 08:31:15 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 哪种方法对 NER 更有效？训练 spaCy 模型还是使用 Meta 的 LLaMA？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icoi78/research_which_is_more_effective_for_ner_training/</link>
      <description><![CDATA[大家好， 我正在为一个涉及有关德国政治话语的 YouTube 评论的项目开发命名实体识别 (NER) 流程。我的目标是提取和标准化政客、政党和机构等实体。 其中的一个关键部分是将政客的名字转换成他们的缩写（例如，Ricarda Lang → RL，Friedrich Merz → FM），确保下游文本分析的一致性。 现在，我正在考虑两种方法：  为 NER 训练 spaCy 模型  我会在大约 1,000 个手动注释的示例上微调预训练的 spaCy 转换器模型。 我的数据集包括嘈杂的非正式文本（例如缩写、拼写错误和讽刺）。 我已经有一个结构化的地名词典，其中包含实体映射，以确保正确缩写。  使用 Meta 的 LLaMA API 进行零样本或小样本 NER  LLaMA 并非专门针对 NER 进行训练，但我可以使用结构化提示来提取命名实体并以缩写格式返回它们。 示例提示：&quot;从此文本中提取所有命名实体（人物、政党和机构）并以标准化缩写格式返回 JSON 格式。&quot; 这避免了训练开销，但我担心一致性和准确性。   主要问题：  有人成功使用 LLaMA（或其他 LLM API）进行NER吗？与微调模型相比，它的可靠性如何？ 对于混乱的社交媒体数据，微调 spaCy（即使使用小型数据集）是否会更加稳健？ 还有其他关于处理德语政治实体识别和转换的建议吗？  我很想听听您的想法，特别是如果您尝试过类似的方法！提前致谢！🚀    提交人    /u/Purple_Opposite3114   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icoi78/research_which_is_more_effective_for_ner_training/</guid>
      <pubDate>Wed, 29 Jan 2025 07:28:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态模型的可解释性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icnzzs/r_multimodal_models_interpretability/</link>
      <description><![CDATA[我正在深入研究多模态可解释性领域的进展。类似于显著性图的东西，但用于多模态输出或我可以研究的任何其他方法。是否有任何工具和方法已经为此开发，特别是针对多模态生成模型？渴望阅读有关相同内容的论文。     提交人    /u/theysaidno_1985   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icnzzs/r_multimodal_models_interpretability/</guid>
      <pubDate>Wed, 29 Jan 2025 06:52:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找有关领域适应方法的[现代]技巧，因为没有能力注释目标领域（图像数据）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icn2je/d_looking_for_modern_tips_on_domain_adaption/</link>
      <description><![CDATA[我基本上是想听听对于具有类似限制的人有用的方法，我可以生成任务的合成数据，但注释真实数据（需要许多传感器的回归任务）是一项非常昂贵的任务，并且由于设置条件甚至可能不切实际。 我正在考虑使用对抗训练作为架构的一部分，编码器有两个头，一个用于目标任务，一个用于对图像的域（合成域与目标域）进行分类，我们尝试最大化后者的损失，目标是让编码器提取用于计算目标的最小非不变特征。 但这感觉已经过时了，也许很挑剔，所以我想知道你们是否可以分享你们的经验。    提交人    /u/StillWastingAway   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icn2je/d_looking_for_modern_tips_on_domain_adaption/</guid>
      <pubDate>Wed, 29 Jan 2025 05:49:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 社区如何确保新发布的模型不会过度拟合流行基准中的问答？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iclxeo/d_how_does_the_llm_community_make_sure_that_a/</link>
      <description><![CDATA[正如标题所说，对于这种故意过度拟合的制衡措施是什么？ 更进一步说，如果基准集不断扩展，是否意味着新模型在扩展的基准上表现更好，而现有模型在训练时不可能看到这些新基准，这存在固有的偏见？    提交人    /u/Prize_Cup2626   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iclxeo/d_how_does_the_llm_community_make_sure_that_a/</guid>
      <pubDate>Wed, 29 Jan 2025 04:40:31 GMT</pubDate>
    </item>
    <item>
      <title>检索增强生成中的规模与智能权衡 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ick63j/the_scale_vs_intelligence_tradeoff_in_retrieval/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ick63j/the_scale_vs_intelligence_tradeoff_in_retrieval/</guid>
      <pubDate>Wed, 29 Jan 2025 03:04:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepSeek 蒸馏和训练成本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icfbll/d_deepseek_distillation_and_training_costs/</link>
      <description><![CDATA[DeepSeek v3 训练中使用了蒸馏技术 (https://arxiv.org/html/2412.19437v1)。560 万美元仅仅是训练“学生”模型的成本吗？我并没有低估这一成就本身。但是，我想了解训练教师模型的成本是否已计入 560 万美元。 如果不考虑这些成本，虽然 DeepSeek 为降低成本和工程做出了重要贡献，但主流媒体散布的数字并不完全一致，需要进行纠正。或者也许我误解了整件事。 感谢您对此提供的任何见解。     由   提交  /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icfbll/d_deepseek_distillation_and_training_costs/</guid>
      <pubDate>Tue, 28 Jan 2025 23:13:12 GMT</pubDate>
    </item>
    <item>
      <title>[p] 让人们可以使用免费的 GPU - 希望得到 Beta 版反馈🦾</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icepak/p_giving_ppl_access_to_free_gpus_would_love_beta/</link>
      <description><![CDATA[大家好！我是一家 YC 投资公司的创始人，我们正努力让 ML 模型的训练变得非常便宜和简单。目前，我们正在运行一个免费测试版，希望得到您的一些反馈。 如果听起来很有趣，请随时在这里查看：https://github.com/tensorpool/tensorpool TLDR；免费计算😂    提交人    /u/joshkmartinez   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icepak/p_giving_ppl_access_to_free_gpus_would_love_beta/</guid>
      <pubDate>Tue, 28 Jan 2025 22:45:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你的秘诀是什么？你如何管理基础设施中的 GPU 容量？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icc8fb/d_whats_your_secret_sauce_how_do_you_manage_gpu/</link>
      <description><![CDATA[好的……我正在努力弄清楚资源管理的状态。我们这里有多少人有一堆闲置的 GPU 就放在那里，因为 Oracle 给了我们一笔交易，他们想阻止我们使用 AWS？或者这里的大多数人仍在使用 RunPod 或其他 neocloud/聚合器？据我所见，这些 neocloud 非常适合 MVP/POC 阶段开发，但不适用于生产。 但实际上，这里的每个人都只是购买额外的容量以避免延迟吗？随着推理工作负载开始扩展，是否有人开始对飞涨的计算成本感到恐慌？然后呢？    提交人    /u/PurpleReign007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icc8fb/d_whats_your_secret_sauce_how_do_you_manage_gpu/</guid>
      <pubDate>Tue, 28 Jan 2025 21:02:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有感觉自己在每个 scikit-learn 项目中都在重新发明轮子？让我们来谈谈如何让 ML 推荐做法不那么痛苦。🤔</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ic5e7f/d_ever_feel_like_youre_reinventing_the_wheel_with/</link>
      <description><![CDATA[嗨，各位数据科学家， 虽然 scikit-learn 功能强大，但我们经常会发现：  手动检查交叉验证错误 在 Copilot、StackOverflow 和文档之间来回切换只是为了遵循推荐的做法 重新设计需要为 DS 团队和利益相关者服务的验证流程 笔记本成为模型迭代的坟墓  我很好奇您如何在工作流程中应对这些挑战：  您在不同项目之间进行验证的方法是什么？是否有统一的方法，还是每个项目都有自己的验证风格？ 如何在不使事情过于复杂的情况下跟踪实验？ 您发现了哪些保持一致性的技巧？  我们（可能）已经构建了一个开源库（skore）来解决这些问题，但我希望先听听您的解决方案。哪些工作流程对您有用？什么仍然令人沮丧？  GitHub：github.com/probabl-ai/skore 文档：skore.probabl.ai     提交人    /u/positive-correlation   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ic5e7f/d_ever_feel_like_youre_reinventing_the_wheel_with/</guid>
      <pubDate>Tue, 28 Jan 2025 16:24:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>