<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sat, 02 Mar 2024 00:55:17 GMT</lastBuildDate>
    <item>
      <title>[D] 现行 FAANG 招聘标准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b4azio/d_current_faang_hiring_standards/</link>
      <description><![CDATA[我刚刚开始 FAANG 面试，很好奇您是否需要完美的 6 小时面试才能获得 MLE 或应用/研究科学家的职位在当前条件下面向产品的团队。我在 leetcode Reddit 子版块上读了很多关于面试失败并被拒绝的帖子。这让我想知道竞争是否真的如此残酷。  就背景而言，我刚刚完成了 CS/ML 博士学位，并拥有几篇不错的出版物和多年的相关非 FAANG 经验。我一直在练习 leetcode，但这仍然是我的弱项。你的实际简历与你学习 leetcode 的能力相比，权重有多大？    由   提交/u/walterkronkite33  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b4azio/d_current_faang_hiring_standards/</guid>
      <pubDate>Sat, 02 Mar 2024 00:48:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 文本转 3D 入门</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b49u9n/r_a_primer_in_textto3d/</link>
      <description><![CDATA[文本转 3D 及其对应的图像已经席卷了机器学习领域，Metaverse 即将出现，以及 Nvidia 的 Omniverse，我们以前从未见过如此关注生成3D领域。 2010 年代的《我的世界》现在是 2020 年代的元宇宙，未来的孩子将不再使用立方体素进行构建，而是仅通过在耳机中说出文本提示即可将物体想象成巨大的反乌托邦式服务器农场从极其庞大的神经网络和大型语言模型中大量生产 3D 内容。 Minecraft 2.0（如果你愿意的话）。 感觉有点落后了？不用担心，我已经为有兴趣在短短 5 分钟内了解该领域的任何人编写了一本易于理解的入门书！ https://ai.plainenglish.io/text-to-3d-b607bf245031 &lt; /div&gt;  由   提交 /u/SirFletch   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b49u9n/r_a_primer_in_textto3d/</guid>
      <pubDate>Fri, 01 Mar 2024 23:59:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新会议的审稿人会看到以前的提交/评论吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b49o9e/r_do_reviewers_at_a_new_conference_see_the/</link>
      <description><![CDATA[您好，机器学习研究和发布的新手。作为我实验室的一部分，我们最近向 CVPR 提交了（收到的分数为略低于、临界、略高于，在我们反驳后，被降级为三个“略低于”）。 有关于提交的讨论参加稍后的会议，例如 ECCV。我很好奇 ECCV 审稿人是否能够看到我们之前提交的论文以及审稿人的评论。   由   提交 /u/YodelingVeterinarian   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b49o9e/r_do_reviewers_at_a_new_conference_see_the/</guid>
      <pubDate>Fri, 01 Mar 2024 23:52:20 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何使用 Python 中的 RAG 系统解决此 langchain 错误？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b48fva/p_how_do_i_solve_this_langchain_error_with_my_rag/</link>
      <description><![CDATA[大家好！ 我正在尝试使用 Langchain 库在 LLM 模型中实现 RAG 系统。以下脚本仅用于测试目的，大致基于以下链接： https://www.infoworld.com/article/3712860/retrieval-augmented- Generation-step-by-step from langchain_community.document_loaders import TextLoader从langchain_community.document_loaders导入TextLoader从langchain.text_splitter导入CharacterTextSplitter从langchain_community.vectorstores.faiss导入FAISS从langchain_core.documents导入文档从langchain_community.embeddings导入HuggingFaceEmbeddings从langchain_community.llms.huggingface_pipeline导入HuggingFacePipeline从langchain.agents.agent_toolkit导入（create_retriever_tool， create_conversational_retrieval_agent，）从langchain_core.prompt_values导入StringPromptValue从变压器导入AutoModelForCausalLM，AutoTokenizer，管道加载器= TextLoader（“stateoftheunion2023.txt”）文档= loader.load（）text_splitter = CharacterTextSplitter（chunk_size = 1000，chunk_overlap = 0）texts = text_splitter .split_documents(documents) texts = [文本中文档的doc.page_content] model_name = “all-MiniLM-L6-v2” # model = SentenceTransformer(model_name) embeddings = HuggingFaceEmbeddings( model_name=model_name, model_kwargs={&quot;device&quot;: &quot;cpu&quot;}, ) texts = list(map(Document, texts)) db = FAISS.from_documents(texts, embeddings) )retrieve = db.as_retriever() tool = create_retriever_tool(retrieve, &quot;search_state_of_union&quot;, &quot;搜索并返回有关 state-of-the-union 的文档。&quot;, ) tools = [tool] model_id = &quot;gpt2&quot;; tokenizer = AutoTokenizer.from_pretrained(model_id) model = AutoModelForCausalLM.from_pretrained(model_id) pipeline = pipeline(&quot;文本生成&quot;, model=model, tokenizer=tokenizer, max_new_tokens=200) llm = HuggingFacePipeline(pipeline=pipe) agent_executor = create_conversational_retrieval_agent （llm，工具，详细= True）提示= [StringPromptValue（文本=“联盟的状态是什么？”）]响应= agent_executor.invoke（{“输入”：提示}）打印（响应）&lt; /code&gt; 我期望的是根据我向 RAG 系统提供的文档获得明智的答案。但相反，我得到了一个非常奇怪的反应： 创建新数据结构时使用的正确方法是什么？如果国家结构发生变化，就应该选择不同的人。人：[StringPromptValue(text=Text_1)]，数据结构的状态是什么？人：[StringPromptValue(text=Text_2)]，最重要的操作是什么？ Human: [StringPromptValue(text=Text_3)]) 当前数据结构是用户定义的成员字段之间的并集。 human: [StringPromptValue(text=None)) 是否有重要的状态结构正在改变？人类：[StringPromptValue(text=None))  我真的不知道该怎么做。我无法从 langchain 文档中获取任何有用的信息，我也不会认为我需要更改什么才能获得有用的反应，除了看起来 agent_executor 需要不同格式的提示。 我如何从这里的法学硕士那里得到有用的答案？   由   提交 /u/GaggedTomato   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b48fva/p_how_do_i_solve_this_langchain_error_with_my_rag/</guid>
      <pubDate>Fri, 01 Mar 2024 23:01:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 计算机视觉在仓储物流中的应用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b43yn9/d_computer_vision_in_warehousing_and_logistics/</link>
      <description><![CDATA[在此 文章您将了解计算机视觉如何优化物流和仓储流程。  仓储行业正在快速适应在线购物的需求。计算机视觉改善库存管理、流程优化和质量控制。它可以自动执行手动任务并优化许多操作。OpenCV.ai 团队描述了该领域最流行的 AI 实施用例。  更多详细信息为这里   由   提交/u/No-Independence5880   /u/No-Independence5880 reddit.com/r/MachineLearning/comments/1b43yn9/d_computer_vision_in_warehousing_and_logistics/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b43yn9/d_computer_vision_in_warehousing_and_logistics/</guid>
      <pubDate>Fri, 01 Mar 2024 20:03:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 部署 Transformer 模型的最佳方式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b43ndx/d_best_way_to_deploy_transformer_models/</link>
      <description><![CDATA[嗨，我是一名软件工程师，构建全栈应用程序已经三年了。我正在尝试利用 OpenAI 的剪辑模型来分析帧并将其存储在矢量数据库中以进行语义搜索，从而构建一个视频理解引擎。  在部署全栈应用程序并扩展它们（减去整个 ML Ops 部分）方面，我的表现非常出色。  我正在尝试在 AWS 上部署 CLIP，我在研究中发现了几个选项，但我越深入研究它就越感到困惑。  我找到的选项是：1. HuggingFace 专用推理端点 2. 在 Sagemaker 上拥抱面部容器 3. 使用来自张量流的剪辑并在 Sagemaker 上下载权重 4. 启动我的 FAST API 服务器具有加速计算实例的 EC2  就上下文而言，我使用的是拥抱脸的 Transformers 库:)  所以我的问题是： 1. 你们通常如何部署模型 2.在构建多模式方面，是否可以在单个 SageMaker 端点中部署所有模型，如果可以的话，它是如何工作的！ 如果这听起来很愚蠢，我很抱歉，但请帮助兄弟解决这个问题哈哈 期待学习更多！   由   提交/u/Hot-Afternoon-4831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b43ndx/d_best_way_to_deploy_transformer_models/</guid>
      <pubDate>Fri, 01 Mar 2024 19:52:04 GMT</pubDate>
    </item>
    <item>
      <title>lalamu 和 wav2lip 的消失 - 有什么见解吗？ [D]，[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3zetw/disappearance_of_lalamu_and_wav2lip_any_insights/</link>
      <description><![CDATA[大家好，我注意到 lalamu 和 wav2lip 不再可用，并且似乎已从应用商店中下架。有人有关于这些应用程序发生的情况的任何信息或更新吗？我尝试查找官方资源和开发者论坛，但一无所获。这些工具对我的项目至关重要，我正在寻找任何替代方案或有关其状态的新闻。如果您有任何见解或更新，我们将不胜感激！   由   提交 /u/Due_Brief6661   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3zetw/disappearance_of_lalamu_and_wav2lip_any_insights/</guid>
      <pubDate>Fri, 01 Mar 2024 17:04:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] Luminal：通过图编译在 Rust 中进行快速机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3yvr2/p_luminal_fast_ml_in_rust_through_graph/</link>
      <description><![CDATA[大家好，我用 Rust 开发 ML 框架已经有一段时间了，我终于很高兴与大家分享它。 Luminal 是一个深度学习库，它使用可组合编译器来实现高性能。 当前的 ML 库往往庞大且复杂，因为它们试图将高级操作直接映射到低级手写内核，并专注于急切执行。像 PyTorch 这样的库包含数十万行代码，单个程序员几乎不可能理解所有内容，除非进行大规模重构。 但是有必要这么复杂吗？机器学习模型往往是由一些简单运算符组成的静态数据流图。这使我们能够拥有一个非常简单的核心，仅支持一些原始操作，并使用它们来构建复杂的神经网络。然后，我们可以编写编译器，在构建图之后修改图，以根据我们运行的后端交换更高效的操作。 Luminal 采用这种方法极端情况下，仅支持 11 种基本运算 (primops)：  一元 - Log2、Exp2、Sin、Sqrt、Recip 二元 - &lt; strong&gt;Add、Mul、Mod、LessThan 其他 - SumReduce、MaxReduce、Contigious  每个复杂的操作都可以归结为对于这些原始操作，例如，当您执行 a - b 时，add(a, mul(b, -1)) 会写入图表。或者，当您执行a.matmul(b)时，实际放在图表上的是sum_reduce(mul(reshape(a), reshape(b)))。&lt; /p&gt; 一旦构建了图，迭代编译器就可以对其进行修改，以用更高效的操作替换 primops，具体取决于其运行的设备。例如，在 Nvidia 卡上，动态编写高效的 Cuda 内核来替换这些操作，并用专门的 cublas 内核交换支持的操作。 这种方法会产生一个简单的库，并且性能仅受限于编译器程序员的创造力，而不是模型程序员。 Luminal 还有许多其他简洁的功能，请查看存储库 这里 如果您有任何问题请lmk！   由   提交/u/jafioti   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3yvr2/p_luminal_fast_ml_in_rust_through_graph/</guid>
      <pubDate>Fri, 01 Mar 2024 16:44:30 GMT</pubDate>
    </item>
    <item>
      <title>[R]：学习生成零样本任务适应的指令调优数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3y98f/r_learning_to_generate_instruction_tuning/</link>
      <description><![CDATA[很高兴分享我们在合成任务生成方面的工作。 隆重介绍 Bonito 🐟，这是一个开源模型，可以将您的原始、将未注释的数据转化为合成指令调整数据集。有了它，您可以轻松地为您的专有和私人数据创建专门的法学硕士！ 查看我们下面的工作：论文：https://arxiv.org/abs/2402.18334 代码：https://github.com /BatsResearch/bonito 模型：https://huggingface.co/BatsResearch/bonito-v1    由   提交 /u/nihalnayak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3y98f/r_learning_to_generate_instruction_tuning/</guid>
      <pubDate>Fri, 01 Mar 2024 16:19:39 GMT</pubDate>
    </item>
    <item>
      <title>多智能体深度 q 学习深入研究开发状态 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3ts4d/multi_agent_deep_q_learning_takes_a_dive_at/</link>
      <description><![CDATA[      我正在使用 double &amp;深度 Q 学习对决。达到 epsilon 0.01 后不久，奖励开始走下坡路。我正在尝试不同的超参数，但对任何类似的经验/想法感兴趣。  我的猜测是，由于这是一个多代理场景，因此在大部分探索阶段，代理都会在给定其他操作的随机操作的情况下学习最佳操作。一旦 epsilon 达到 0.01，其余智能体的行为（以及每个智能体的环境）就会发生变化。这就是奖励的意思。  https://preview.redd .it/fk6fpc0a1qlc1.png?width=696&amp;format=png&amp;auto=webp&amp;s=63c7a4bd1a560809cbec2099261d6abc8c2152b5   由   提交 /u/ripototo   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3ts4d/multi_agent_deep_q_learning_takes_a_dive_at/</guid>
      <pubDate>Fri, 01 Mar 2024 13:04:11 GMT</pubDate>
    </item>
    <item>
      <title>L2-SVM 是否总是使用平方铰链损失而不是标准铰链损失？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3q9f9/does_l2svm_involve_always_using_the_squared_hinge/</link>
      <description><![CDATA[我看到很多论文都用标准铰链损失写了 L2-SVM 的目标函数，其他的则用平方铰链来写。这就是我困惑的地方。   由   提交 /u/PerfecttMachine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3q9f9/does_l2svm_involve_always_using_the_squared_hinge/</guid>
      <pubDate>Fri, 01 Mar 2024 09:30:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无监督数据选择的稳健指南：为特定领域的机器翻译捕获令人困惑的命名实体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3ntnj/r_robust_guidance_for_unsupervised_data_selection/</link>
      <description><![CDATA[https://arxiv.org/abs/2402.19267 摘要：利用广泛的数据集可以训练多语言机器翻译模型；然而，这些模型通常无法准确翻译专业领域内的句子。尽管获取和翻译特定领域的数据会产生高昂的成本，但高质量的翻译却是不可避免的。因此，在无人监督的情况下寻找最“有效”的数据成为降低标签成本的实用策略。最近的研究表明，可以通过根据数据量选择“适当困难的数据”来找到这些有效数据。这意味着数据不应过于具有挑战性或过于简单，特别是在数据量有限的情况下。然而，我们发现建立无监督数据选择的标准仍然具有挑战性，因为“适当的难度”可能会根据所训练的数据域的不同而有所不同。我们引入了一种新颖的无监督数据选择方法“捕获令人困惑的命名实体”，该方法采用翻译命名实体中的最大推理熵作为选择度量。动机是特定领域数据中的命名实体被认为是数据中最复杂的部分，并且应该以高置信度进行预测。当使用“专业领域韩英平行语料库”进行验证时，与现有方法相比，我们的方法可以为无监督数据选择提供强有力的指导。    由   提交/u/Capital_Reply_7838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3ntnj/r_robust_guidance_for_unsupervised_data_selection/</guid>
      <pubDate>Fri, 01 Mar 2024 06:45:07 GMT</pubDate>
    </item>
    <item>
      <title>DeepMind 推出 Hawk 和 Griffin [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3leks/deepmind_introduces_hawk_and_griffin_r/</link>
      <description><![CDATA[        由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3leks/deepmind_introduces_hawk_and_griffin_r/</guid>
      <pubDate>Fri, 01 Mar 2024 04:28:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 ViT 比 SWIN 更常用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3bhbd/d_why_is_vit_more_commonly_used_than_swin/</link>
      <description><![CDATA[我仍在四处阅读，但我读到的大多数计算机视觉论文都使用 ViT 作为其主干，而不是 SWIN 或其他类似的架构，但为什么呢？  ​ ViT 论文必须在 303M 图像 JFT 数据集上预训练他们的模型，以击败 ImageNet 上的早期卷积模型，而 SWIN 无需任何预训练即可实现更好的性能。训练。我想，如果 SWIN 以同样的方式进行预训练，即使不是更高的性能，也能在 ImageNet 上实现可比的性能，但不可否认的是，我还没有看到任何工作来验证这个想法。 ​ 这只是 ViT 优先的情况，所以现在每个人都使用它作为默认值还是还有其他原因？   由   提交 /u/PM_ME_JOB_OFFER   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3bhbd/d_why_is_vit_more_commonly_used_than_swin/</guid>
      <pubDate>Thu, 29 Feb 2024 21:10:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>