<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 23 Jan 2024 01:02:43 GMT</lastBuildDate>
    <item>
      <title>[D] 欧洲人工智能法案暂定协议何时正式通过？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dbqvi/d_when_will_the_tentative_agreement_on_the_ai_act/</link>
      <description><![CDATA[一个月前，欧盟就一套具有里程碑意义的人工智能 (AI) 监管规则达成了临时协议，即《人工智能法案》。  虽然该协议仍有待欧洲议会和欧洲理事会正式通过，但最新进展表明《人工智能法案》的某些内容已得到进一步完善。  欧洲人工智能法案暂定协议何时正式通过？   ​   由   提交 /u/Periplokos   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dbqvi/d_when_will_the_tentative_agreement_on_the_ai_act/</guid>
      <pubDate>Tue, 23 Jan 2024 00:54:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 为 ML/LLM 任务构建了强大的 Colab 替代方案！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19dbpoj/p_built_a_powerful_colab_alternative_for_mlllm/</link>
      <description><![CDATA[嗨r/MachineLearning！我想向您介绍 Agora，一个用于 AI/ML 开发的 GPU 支持的笔记本平台。 Agora 旨在通过以下方式解决当前工具的常见问题：1) 采购世界上最便宜的计算2) 创建一种用户友好的方式来使用它来构建 ML。  大量的 AI/ML 开发都是从笔记本电脑开始的（至少我自己的笔记本电脑是这样），结果却因计算和性能限制而受到阻碍。特别是当使用 Google Colab 执行密集的 LLM 任务时，我经常会耗尽 RAM 并遇到可怕的 OOM 错误。我需要一种方法来从 Colab 获取我的工作并在 GPU 支持的沙箱环境中运行它。这就是 Agora 的诞生！ 我坚信任何人都可以在不到 2 分钟内开始使用 Agora！ 1) 使用您的自定义 GPU 规格创建 Agora 实验室2) 安装您的个人 Google Drive 用于存储/上传/下载3) 打开 JupyterLab 实例并开始工作！ 还添加了一些很酷的功能，使该平台的使用尽可能顺畅： - 可以输入任何公共 Colab 链接并立即在 Agora 上打开[DEMO]&lt; br /&gt; - 通过各种网络采购廉价+高性能的 GPU，可立即使用 - 内置分析器，以便您知道何时即将耗尽 VRAM I我和我最好的两个朋友一起构建了 Agora。我们三个人都是学生，他们已经研究 ML 一段时间了，但在尝试与最新的法学硕士合作时感到非常沮丧。通过云服务租用 GPU 的成本很高，而且我们无法从 Google Colab 等免费/低成本工具中获取所需的计算。在过去的几个月里，我们构建了 Agora 作为我们自己问题的解决方案，我们希望它能为其他许多人做同样的事情。 Agora 的开发听取了黑客、工程师、学生和其他人的意见。研究人员并受到 Sagemaker 和 Colab 的启发。我们希望您尝试一下并尝试一下。请留下任何反馈/建议（好的或坏的），以便我们继续让 Agora 变得更加有用！   由   提交/u/Horror-Economics-685   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19dbpoj/p_built_a_powerful_colab_alternative_for_mlllm/</guid>
      <pubDate>Tue, 23 Jan 2024 00:52:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 复杂网络链路预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19da4gr/p_complex_network_link_prediction/</link>
      <description><![CDATA[复杂网络链接预测是一个 Python 库，它实现了一些主要技术和算法来执行链接预测。  https://github.com/Typing-Monkeys/complex-network-link -预测   由   提交/u/Stunning_Ad_1539   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19da4gr/p_complex_network_link_prediction/</guid>
      <pubDate>Mon, 22 Jan 2024 23:41:30 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士可以在其回复中隐藏任意不可检测的信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</link>
      <description><![CDATA[ 由   提交/u/LuvIsOurResistance  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d8hed/llms_can_hide_arbitrary_undetectable_information/</guid>
      <pubDate>Mon, 22 Jan 2024 22:32:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新理论表明聊天机器人可以理解文本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</link>
      <description><![CDATA[文章链接：https://www.quantamagazine.org/new-theory-suggests-chatbots-can-understand-text-20240122/ 链接到论文 1：https://arxiv.org/abs/2307.15936 摘要：  当今人工智能产品的一个主要驱动力是，当参数集和训练语料库扩大时，语言模型中就会出现新的技能。人们对这种现象知之甚少，并且通过基于梯度的训练的数学分析来进行机械解释似乎很困难。当前的论文采用了不同的方法，使用著名的（和经验的）法学硕士缩放定律和简单的统计框架来分析涌现。贡献包括： (a) 一个统计框架，将法学硕士的交叉熵损失与语言任务的基本技能能力联系起来。 (b) 数学分析表明，缩放定律暗示了一种强烈的归纳偏差形式，使得预训练模型能够非常有效地学习。我们非正式地将其称为“弹弓泛化”，因为天真地认为它似乎给出了违反通常泛化理论的技能的能力水平。 (c) 弹弓泛化的一个关键例子，执行涉及 k 元组技能的任务的能力基本上以与基本技能本身的能力相同的规模和速度出现。  Link论文 2：https://arxiv.org/abs/2310.17567 摘要：  随着法学硕士的角色从语言统计建模转变为通用人工智能代理，法学硕士的评估应该如何改变？可以说，人工智能代理的一项关键能力是根据需要灵活组合其所学的基本技能。结合技能的能力在（人类）教育学以及关于涌现现象的论文中发挥着重要作用（Arora &amp; Goyal，2023）。这项工作引入了 Skill-Mix，这是一种衡量组合技能能力的新评估。使用 N 个技能的列表，评估者重复选择 k 个技能的随机子集，并要求法学硕士生成结合该技能子集的文本。由于子集的数量像 Nk 一样增长，因此即使是适度的 k，此评估也很有可能要求法学硕士生成与训练集中的任何文本显着不同的文本。该论文开发了一种方法，用于 (a) 设计和管理此类评估，以及 (b) 使用 GPT-4 以及开放的 LLaMA-2 70B 模型对结果进行自动分级（加上人工抽查）。管理流行聊天机器人的一个版本所得到的结果虽然总体上符合之前的预期，但也包含了令人惊讶的结果。模型能力之间存在相当大的差异，而这些差异并没有通过它们在流行的 LLM 排行榜上的排名来体现（“临时抱佛脚排行榜”）。此外，简单的概率计算表明GPT-4在k＝5上的合理性能暗示超越“随机鹦鹉”性能。行为（Bender 等人，2021），即它以训练期间未曾见过的方式组合技能。我们概述了该方法如何形成基于技能组合的生态系统，对未来模型的人工智能功能进行开放评估。    由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d7jyk/r_new_theory_suggests_chatbots_can_understand_text/</guid>
      <pubDate>Mon, 22 Jan 2024 21:54:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于文本分类的零样本 OOD</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d5ytn/d_zeroshot_ood_for_text_classification/</link>
      <description><![CDATA[我正在构建一个管道，该管道允许我根据文本是否属于我已经定义的任何类来过滤文本定义。 我觉得一种（尽管很幼稚）方法就是嵌入文本和代表类的文本，并对两者应用距离函数，如果距离超过某个值，则丢弃样本阈值。 这在零样本设置中可行吗？如果是这样，我应该如何计算阈值？如果没有，在零样本设置中可以使用什么（如果有）方法？   由   提交/u/DeezDineros   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d5ytn/d_zeroshot_ood_for_text_classification/</guid>
      <pubDate>Mon, 22 Jan 2024 20:50:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于股票交易的深度 Q 网络（深度强化学习） - 测试模型在同一集运行中执行相同的操作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d5llc/d_deep_qnetwork_deep_reinforcement_learning_for/</link>
      <description><![CDATA[      我使用 Deep Q-Network 模型（DRL 类型）进行股票交易 - 代理可以立即投资所有现金并立即出售所有股票，我们从 10,000 美元开始。 有人可以吗解释为什么我在每个情节运行中看到相同的情节交易序列，这意味着测试函数没有产生不同的结果（每个情节都有与其他情节相同的购买、持有、出售操作）。 一些信息下面的 epoch 数据用于训练，epoch 数据用于测试。超参数： { “hidden_​​size”：500、“epoch_num”：10、“memory_size”：300、“batch_size”：40、 &lt; p&gt;“train_freq”：400，“update_q_freq”：100，“gamma”：0.97，“epsilon_decay_divisor”：1.2， “start_reduce_epsilon”：500  } ​ https://preview.redd.it/bggh2p0sx1ec1.png?width=2070&amp;format=png&amp;auto=webp&amp;s=0ae7d2883bfb641f8cbf5f108f800acda62086 df https://preview.redd.it/gv5q2iqtx1ec1.png?width=2082&amp;format =png&amp;auto=webp&amp;s=181c8930b969ff103073bd2dd6b75ba0434e3ad8   由   提交 /u/Shark_Caller   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d5llc/d_deep_qnetwork_deep_reinforcement_learning_for/</guid>
      <pubDate>Mon, 22 Jan 2024 20:35:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前理论机器学习作为一个领域有什么意义吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</link>
      <description><![CDATA[随着 SOTA 架构不断变化的极快速度，可能的 DL 技术（正则化、所有不同的激活和损失函数）的多样性如下：以及对可解释人工智能相对退居二线的担忧，现在从事理论机器学习工作有什么用处吗？ 大多数 SOTA 架构似乎只是大规模扩展的高级猜测和检查，而且它确实有效就基准性能而言，我们是否需要 ML/DL 理论？   由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d4um9/d_is_there_any_point_to_theoretical_ml_as_a_field/</guid>
      <pubDate>Mon, 22 Jan 2024 20:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[R]双重认知架构：结合偏见和多记忆系统实现终身学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19d2c65/r_dual_cognitive_architecture_incorporating/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2310.11341 OpenReview：https:// /openreview.net/forum?id=PEyVq0hlO3 代码： https://github.com/NeurAI-Lab/DUCA 数据集：https://github.com/NeurAI-Lab/DN4IL-dataset 视频：https://www.youtube.com/watch?v=08tfpjvUGqs 摘要：  人工神经网络（ANN）在固定独立数据上表现出狭窄的专业知识范围。然而，现实世界中的数据是连续的、动态的，人工神经网络必须适应新的场景，同时保留学到的知识，成为终身学习者。人类在这些任务上表现出色的能力可以归因于多种因素，包括认知计算结构、认知偏差和大脑中的多记忆系统。我们结合了其中的关键概念来设计一个新颖的框架，双重认知架构（DUCA），其中包括多个子系统、隐式和显式知识表示二分法、归纳法偏见和多记忆系统。 DUCA 中的归纳偏差学习器有助于编码形状信息，有效对抗 ANN 学习局部纹理的趋势。同时，语义记忆子模块的包含有助于知识的逐步巩固，复制在快速和慢速学习系统中观察到的动态，让人想起支撑人类认知中互补学习系统的原理。 DUCA 在不同的设置和数据集上显示出改进，并且还表现出减少的任务新近度偏差，而不需要额外的信息。为了进一步测试终身学习方法在具有挑战性的分布变化上的多功能性，我们引入了一种新颖的领域增量数据集DN4IL。除了提高现有基准测试的性能之外，DUCA 还在这个复杂的数据集上展示了卓越的性能。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19d2c65/r_dual_cognitive_architecture_incorporating/</guid>
      <pubDate>Mon, 22 Jan 2024 18:20:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 提前停止但是什么时候？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cx4ol/d_early_stopping_but_when/</link>
      <description><![CDATA[你好， 我最近一直在尝试寻找比耐心和增量值更好的提前停止方法，并且我偶然发现这篇论文 https://page.mi.fu-berlin.de/prechelt/Biblio/ stop_tricks1997.pdf 。鉴于本文中提到的标准，我发现继续采用这种方法是非常合乎逻辑的。我还碰巧注意到这是一篇非常古老的论文，似乎没有一个主要平台考虑这里的实现。我完全不明白为什么这不是一个有效的方法吗？    由   提交/u/Bhargav_28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cx4ol/d_early_stopping_but_when/</guid>
      <pubDate>Mon, 22 Jan 2024 14:41:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们没有看到很多关于 Mamba 架构的内容？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cwf65/d_why_were_not_seeing_a_lot_of_content_about/</link>
      <description><![CDATA[比如对作者的一些采访？还没有看到例如TWIML AI 播客谈论 Mamba 架构。   由   提交/u/_learning_stuff_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cwf65/d_why_were_not_seeing_a_lot_of_content_about/</guid>
      <pubDate>Mon, 22 Jan 2024 14:07:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] ARR 2023 年 12 月（NAACL 2024）讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cvxz4/d_arr_2023_december_naacl_2024_discussion/</link>
      <description><![CDATA[评论应该在今天发布。   由   提交 /u/Street-Judgment7640    reddit.com/r/MachineLearning/comments/19cvxz4/d_arr_2023_december_naacl_2024_discussion/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cvxz4/d_arr_2023_december_naacl_2024_discussion/</guid>
      <pubDate>Mon, 22 Jan 2024 13:44:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 超越变形金刚：结构化状态空间序列模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cv8q6/d_beyond_transformers_structured_state_space/</link>
      <description><![CDATA[撰写了一篇文章，解释了状态空间序列模型的基础知识。本文的目的是以简化的方式呈现基础级别的概念。该领域在人工智能领域正在迅速发展，因为它在速度和内存消耗方面超越了 Transformer 架构。以下是文章链接：https://cnichkawde.github.io/statespacesequencemodels.html &lt; /div&gt;  由   提交 /u/cnichkawde   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cv8q6/d_beyond_transformers_structured_state_space/</guid>
      <pubDate>Mon, 22 Jan 2024 13:07:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 chatGPT 之后，人们现在还在创建自己的新的自定义 NLP 模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19cqde6/d_after_chatgpt_are_people_still_creating_their/</link>
      <description><![CDATA[对使用 scikit-learn 和 Tensorflow 训练 ML 和 DL 模型有点脱节。只是想知道 ML 工程师是否仍在训练他们自己的 NLP 模型（甚至 CV、预测、聚类模型等）。 如果是这样，您正在训练什么类型的模型？您正在解决哪些用例？如果您用 ChatGPT 替换自定义模型，进展如何？ 我想重新熟悉 ML 生态系统。很想听听您的想法。   由   提交 /u/automatonv1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19cqde6/d_after_chatgpt_are_people_still_creating_their/</guid>
      <pubDate>Mon, 22 Jan 2024 07:41:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>