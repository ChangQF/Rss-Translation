<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 20 Feb 2024 18:18:07 GMT</lastBuildDate>
    <item>
      <title>[D] 硕士学位对于成为一名出色的机器学习工程师和更好的职业前景有多大用处？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avnmde/d_how_useful_is_a_masters_degree_to_excel_as_a/</link>
      <description><![CDATA[我在德克萨斯州一所学校攻读计算机工程专业，GPA 为 3.99。我有 3 年的本科研究经验和出版物。目前，我已在一家领先的 OEM 担任机器学习工程师 2 年。我与拥有博士学位的科学家一起工作，并跨多个项目进行了工作。我觉得我在工作中学到了很多东西。 注意： - 我尝试搜索，但找不到任何针对我的具体情况的问题，  - 我尝试了 Gtech OMSCS，前两门课很垃圾 - 所以我退学了。由于每个队列中有多少人，我也没有得到我想要的课程。这个在线项目缺乏组织也让人非常沮丧。 我不一定打算成为一名机器学习科学家，但打算转向机器学习团队的管理。    由   提交 /u/Crackjoke   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avnmde/d_how_useful_is_a_masters_degree_to_excel_as_a/</guid>
      <pubDate>Tue, 20 Feb 2024 17:39:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你使用人工智能来编码你的人工智能项目吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avn0d4/d_do_you_use_ai_to_code_your_ai_projects/</link>
      <description><![CDATA[大家好， 我个人在我的编程项目中越来越多地使用 Github Copilot。 我很好奇，你也在你的编程/数据科学项目中使用它吗？如果是这样怎么办？ 谢谢！   由   提交/u/devonmatthew821   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avn0d4/d_do_you_use_ai_to_code_your_ai_projects/</guid>
      <pubDate>Tue, 20 Feb 2024 17:15:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 及时 GPU 托管？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avmoxx/d_just_in_time_gpu_hosting/</link>
      <description><![CDATA[嗨， 我看到了很多有关托管的问题，但这是非常具体的。我希望能够部署 4 个基于 DistilBERT 的小型模型，并在其他地方进行训练。我只需要它们“向上”即可。每天一小时或更少（用于现场演示），所以我不想支付每月的托管费。然而，我需要的不仅仅是一些随机的 Flask 提供程序，我需要它们在适当供电的 GPU/TPU 硬件上运行一个小时（所以我有低于 50 毫秒的延迟）。 有人有低-他们可以推荐成本低、易于使用的服务吗？ 提前致谢， W    ;由   提交 /u/wantondevious   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avmoxx/d_just_in_time_gpu_hosting/</guid>
      <pubDate>Tue, 20 Feb 2024 17:03:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于标准化图像的可视化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avjmqp/d_about_visualizing_normalized_images/</link>
      <description><![CDATA[        由   提交/u/NailaBaghir   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avjmqp/d_about_visualizing_normalized_images/</guid>
      <pubDate>Tue, 20 Feb 2024 14:59:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么扩散器库改变了原来的采样算法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avjgso/d_why_does_the_diffuser_library_change_the/</link>
      <description><![CDATA[      我最近一直在分析拥抱面部扩散器库的内部工作原理，并且我已经意识到step()函数内部采样方法似乎发生了变化： ​ https://preview.redd.it/9zz4yzm37rjc1.png?width=2041&amp;format=png&amp;auto=webp&amp;s = de825eb3d57bbffa103998368f60401dc9f6f304 如果我理解正确的话，首先，他们使用以下公式创建 x₀ 的预测： https://preview.redd.it/2cy3dp257rjc1.png?width=1483&amp;format=png&amp;auto =webp&amp; ;s=3126d7b6ddb26743f4c0545275d0dc3a12f154a0 接下来，他们使用以下方程创建 xₜ₋₁： https://preview.redd.it/72hbpzn57rjc1.png?width=1936&amp;format=png&amp;auto=webp&amp;s=3f839aa6ad 96d3c81812256e33573859a30b8f9b 但我认为这与原始方程第 4 行相比是一个巨大的变化： https://preview.redd.it/upexate77rjc1.png?width=1060&amp;format=png&amp;auto=webp&amp;s=4c6d17715f7 4fa4b72ecf63b4a82598634a36372&lt; /a&gt; 为什么他们使用不同的方式来获取xₜ₋₁？这种方法有什么优点？有没有任何原始材料或论文可以检查它的来源？ 谢谢您的帮助！   由   提交 /u/SrPinko   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avjgso/d_why_does_the_diffuser_library_change_the/</guid>
      <pubDate>Tue, 20 Feb 2024 14:52:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对检索增强生成（RAG）中的不同术语感到困惑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avikjn/d_confused_about_different_terms_in/</link>
      <description><![CDATA[嗨，我有一个课堂练习，需要对检索增强生成 (RAG) 进行文献回顾。我的老师告诉我们阅读“在检索增强生成中对大型语言模型进行基准测试”并找到一些其他有助于提高噪声鲁棒性的论文和信息交互。  我发现的一篇论文是“Chain-of-note：增强检索增强语言模型的鲁棒性”，他们提到了检索增强语言模型（RALM）。  那么这个RAG和RALMs是相同还是不同呢？据我了解，RALM 是 RAG 的一小部分，因为它将语言模型与从大量文档中查找信息的系统结合在一起。我是对的吗？ 此外，从 Chain-of-note 论文中，我读到了另一篇论文“Interleaving Retrieval with Chain”知识密集型多步骤问题的深度推理”感觉虽然看起来一样，但实际上它解决了与 Chain-of-note 不同的问题。  ​   由   提交 /u/ma-d-ghost   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avikjn/d_confused_about_different_terms_in/</guid>
      <pubDate>Tue, 20 Feb 2024 14:12:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为本科生选择一个 ML 实验室：大型、成熟的实验室还是小型、专注的实验室？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avie4g/d_picking_an_ml_lab_as_an_undergraduate_big/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avie4g/d_picking_an_ml_lab_as_an_undergraduate_big/</guid>
      <pubDate>Tue, 20 Feb 2024 14:04:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 其他流行/宣布的扩散变压器产品，如 Sora？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avht7j/d_other_popularannounced_diffusion_transformer/</link>
      <description><![CDATA[虽然 Sora 引起了不小的轰动，但还有哪些其他已知、流行/宣布的产品使用类似的模型架构？ &lt; !-- SC_ON --&gt;  由   提交 /u/CodeComedianCat   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avht7j/d_other_popularannounced_diffusion_transformer/</guid>
      <pubDate>Tue, 20 Feb 2024 13:36:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数据产品的版本控制、编目和停用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1avh5wg/d_versioning_cataloging_and_decommissioning_data/</link>
      <description><![CDATA[数据产品不断发展的格局的无中断管理：第 2 部分  如何保持跟上不断发展的数据产品并按照用户需求的节奏运行？虽然1️⃣版本控制数据产品资产和功能是数据产品管理的一个关键方面，但这里还有一些需要注意的操作👉🏻 2️⃣ 一致的编目（不仅仅是数据，而是产品的所有资产和功能）3️⃣ 仔细识别拐点（当 DP 不再是版本更改而是新的 DP 时）4️⃣ 识别何时停用数据产品或特定产品功能等等！  深入了解：https://moderndata101.substack。 com/p/managing-the-evolving-data-products-landscape-p2   由   提交/u/growth_man  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1avh5wg/d_versioning_cataloging_and_decommissioning_data/</guid>
      <pubDate>Tue, 20 Feb 2024 13:04:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文解释：V-JEPA：重新审视特征预测以从视频中学习视觉表示（视频分析）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aveqx4/d_paper_explained_vjepa_revisiting_feature/</link>
      <description><![CDATA[https://youtu.be/7UkJPwz_N_0 V-JEPA 是一种仅使用潜在表示预测作为目标函数来进行视频数据无监督表示学习的方法。 概要： 0:00 - 简介&lt; /p&gt; 1:45 - 预测特征原理 8:00 - （广告）权重和权重结构化 LLM 输出偏差课程 9:45 - 原始 JEPA 架构 27:30 - V-JEPA 概念 33:15 - V-JEPA架构 44:30 - 实验结果 46:30 - 通过解码进行定性评估 ​ 博客：&lt; a href=&quot;https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/&quot;&gt;https://ai.meta.com/ blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/ 论文：https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning- Visual-representations-from-video/ ​ 摘要： 本文探讨了特征预测作为一个独立的目标用于从视频进行无监督学习，并引入了 V-JEPA，这是一组仅使用特征预测目标进行训练的视觉模型集合，不使用预训练的图像编码器、文本、负例、重建或其他监督来源。这些模型使用从公共数据集中收集的 200 万个视频进行训练，并针对下游图像和视频任务进行评估。我们的结果表明，通过预测视频特征进行学习可以产生多功能的视觉表示，在基于运动和外观的任务上表现良好，而无需调整模型的参数；例如，使用我们最大的模型、仅在视频上训练的 ViT-H/16 冻结骨干网，在 Kinetics-400 上获得 81.9%，在 Something-Something-v2 上获得 72.2%，在 ImageNet1K 上获得 77.9%。 &lt; p&gt;​ 作者：Adrien Bardes Quentin Garrido Xinlei Chen Michael Rabbat Yann LeCun Mido Assran Nicolas Ballas Jean Ponce    ;由   提交/u/ykilcher  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aveqx4/d_paper_explained_vjepa_revisiting_feature/</guid>
      <pubDate>Tue, 20 Feb 2024 10:42:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果使用双 GPU 进行训练，瓦数会低得多</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1av8psg/d_much_lower_wattage_if_dual_gpu_used_for_training/</link>
      <description><![CDATA[我有双 GPU 设置，4080 16GB 和 4080 16GB 3090 24GB。通过我在 Yelp 评论数据集上训练 Bert Large 的玩具示例，我在双 GPU 上的训练速度始终比仅在 4080 上慢约 4%。我预计这 2 个 GPU 能够很好地协同工作，因为它们的 CUDA 核心数量非常相似（4080 9,728 ,3090 10,496）。另一项观察结果是，3090 在双重训练中仅拉动 270w 左右，而仅在 3090 上训练时，该卡拉动 335w。我有一个1600W的电源。我正在使用 Huggingface 变压器，精心挑选的最大批量大小为 18，多个数据加载器工作程序固定到内存。与 10k 和 100k 训练数据大小保持一致，速度减慢了约 4%。 有任何提示吗？   由   提交/u/kecso2107  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1av8psg/d_much_lower_wattage_if_dual_gpu_used_for_training/</guid>
      <pubDate>Tue, 20 Feb 2024 04:24:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数学家会在未来的机器学习研究中占据上风吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1av5gwy/d_will_mathematicians_have_the_upper_hand_in/</link>
      <description><![CDATA[似乎在各个角落我都看到了关于做研究的类似情绪。人们尝试各种事物的组合来获得渐进式的改进。我认为下一步的飞跃需要大量的理论知识来指导方向。   由   提交 /u/planetofthemushrooms   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1av5gwy/d_will_mathematicians_have_the_upper_hand_in/</guid>
      <pubDate>Tue, 20 Feb 2024 01:46:38 GMT</pubDate>
    </item>
    <item>
      <title>对于技术主管来说，您的实际工作是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auyt1n/for_anyone_whos_a_tech_lead_what_is_your_actual/</link>
      <description><![CDATA[在担任主要 DS 后，我最近被任命为一个大项目的技术主管，并发现自己在思考我的角色实际上是什么/应该是什么..你每天都做什么？与参加会议和计划里程碑等相比，您还有多少编码和技术工作？    由   提交 /u/natrules   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auyt1n/for_anyone_whos_a_tech_lead_what_is_your_actual/</guid>
      <pubDate>Mon, 19 Feb 2024 21:11:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在 10M 大海捞针中寻找针：循环记忆找到法学硕士错过的东西 - AIRI，莫斯科，俄罗斯 2024 - RMT 137M 具有循环记忆的微调 GPT-2 能够在 10M 中找到 85% 的隐藏针草垛！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1autvwq/r_in_search_of_needles_in_a_10m_haystack/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.10790  摘要：  本文解决了使用生成变压器模型处理长文档的挑战。为了评估不同的方法，我们引入了BABILong，一个新的基准旨在评估模型在广泛文本中提取和处理分布式事实的能力。我们的评估（包括 GPT-4 和 RAG 基准）表明，常见方法仅对最多 10^4 元素的序列有效。相比之下，通过循环内存增强对 GPT-2 进行微调使其能够处理涉及多达  10^7 个元素的任务。这一成就标志着一个重大飞跃，因为它是迄今为止任何开放神经网络模型处理的最长输入，展示了长序列处理能力的显着改进。   https://preview.redd.it /0o4207a70ljc1.jpg?width=577&amp;format=pjpg&amp;auto=webp&amp;s=2bfac07872020de222b4bf99f837aa398b778afc https://preview.redd.it/2ff82da70ljc1.jpg?width=1835&amp;format=pjpg&amp;auto=webp&amp;s=acc1409f5b9bcd07f9 b5ff8a3890cc1b15b5c8ed  https://preview.redd .it/ld69p7a70ljc1.jpg?width=1816&amp;format=pjpg&amp;auto=webp&amp;s=fdd72c1a87742f525fa352723bcd1a0f4f000638 https://preview.redd.it/7vn4gba70ljc1.jpg?width=900&amp;format=pjpg&amp;auto=webp&amp;s=c8d08bb85a6 699e5b451e01bf615379db1fcbdca   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1autvwq/r_in_search_of_needles_in_a_10m_haystack/</guid>
      <pubDate>Mon, 19 Feb 2024 18:02:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>