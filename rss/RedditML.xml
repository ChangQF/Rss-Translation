<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 06 Dec 2023 01:01:08 GMT</lastBuildDate>
    <item>
      <title>AGI 研究新进展！ [D][R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18brbid/new_to_agi_research_dr/</link>
      <description><![CDATA[过去几个月我一直在反思通用人工智能（AGI）的发展。 ChatGPT-4 看起来非常接近，甚至具有欺骗性。这让我想知道：如果它看起来如此有前途……这真的是正确的方向吗？ ​ 我认为支持这一点有几个原因；不仅是因为拥有一个虚拟助手对技术的极度热情，它可以以令人印象深刻的速度对我所说的一切进行编程 ​ 首先，我们创建了一个工具能够非常有效地生成和执行代码。事实上，看到它的有效性几乎令人感到谦卑。没有使用过付费版的请不要评论，抱歉，有点失望，还要等开源版；对于那些要告诉我我不明白它是如何工作的人，现在我将解释我是如何理解它的，如果你愿意，你可以纠正我。 ​ 这个系统是一个预先训练好的语言模型，在不知道如何阅读的情况下研究了很多书，学习阅读，并在这个过程中，以结构化、有序、连贯、完整且大部分的方式吐出信息。时间，正确的方法。由于培训成本“低”。对于结果，我们引入了大量的代码，但不仅如此；确实，他在推理中仍然有点迷失（可能是因为我们输入了错误的数据）。我们也不完全知道它为什么会丢失。正确吗？ ​ 但是，大多数时候它仍然提供正确的答案。它对于以下方面非常有用： ​ 将问题分解为更小的问题。 实施测试来验证问题是否已得到解决。  通过编程解决每个单独的问题。 递归迭代，直到完成所有测试。 ​ 获取所有这些考虑到这一点，理论上应该可以使用互连的 LLM 创建 AGI，类似于 Microsoft 的 Autogen。事实上，我明白，有了无限的时间和资源，这应该得到保证（就像猴子打字莎士比亚一样）。如果不是，那么我们就到了主要问题，为什么不呢？ ​ 这是一个概率问题，从某种意义上说，你期望花费很多资源吗？在最终实现之前？ 这是否是我们在理论上无法保证利用现有资源实现的目标？ （获取 AGI） ​ 如果最终可以实现：我们可以计算问题的时间复杂度吗？也就是说，我们如何计算保证达到预期结果的最长时间？ ​ 首先，我想我们必须建立LLM指定执行该任务；例如，具有特定互连任务的迷你法学硕士法学硕士，并评估您在较小问题上的表现，但在这里我不再有一个清晰的想法。 ​ 如果我们可以有效地计算这一点，我们可以研究法学硕士或整体法学硕士的改进发展，以便最终我们的傻朋友ChatGPT的哥哥能够实现它。 ​ 另一方面，如果你告诉我法学硕士是有限的，并且即使添加更多数据和反馈也将继续受到限制，并且对 AGI 进行编程（谈论非-这是讽刺的） AGI编程AGI，也许我们真的更接近看起来的样子）需要更高的水平；这个法学硕士难道不能成为像 OpenAI 这样的团队构建终极 AGI 的终极助手吗？ ​ 然后问题来了：我们真的想要 AGI 吗？为了得到它，我们愿意牺牲什么？事实是，我几乎会满足于现在的助手，就这样吧......   由   提交/u/spanish_bullgame   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18brbid/new_to_agi_research_dr/</guid>
      <pubDate>Wed, 06 Dec 2023 00:38:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习论文所需的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18br4km/d_advice_needed_for_ml_thesis/</link>
      <description><![CDATA[大家好， 我是人工智能专业的硕士生，我真的很难为我的硕士论文找到主题...我的兴趣主要在于 ML/DL，但我不确定我应该关注哪个主题。 在我看来，有两种方法：  第一种方法是获取数据集并使用深度学习来解决特定问题。现在的问题是（至少在我看来）所有问题看起来都一样，你只需在不同模型上试验和错误你的数据，直到获得适当的准确性。我不太确定这如何被视为科学工作。 第二种方法将致力于特定的理论领域，例如开发一种新的算法，或者修改已经存在的算法现有的。  在这两种情况下，我都不确定应该选择什么主题以及如何找到主题。我一直在想，我应该做一些半伟大的论文。 我应该提到我打算发表论文并最终获得博士学位。 任何指导都会是非常感谢！   由   提交 /u/labianconeri   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18br4km/d_advice_needed_for_ml_thesis/</guid>
      <pubDate>Wed, 06 Dec 2023 00:29:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] CS + 数学 vs CS+ 统计 vs CS + 数据科学</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bqyqt/d_cs_maths_vs_cs_stats_vs_cs_data_science/</link>
      <description><![CDATA[我是一名大学新生，我正在考虑选择另一个专业，所以在这种情况下我最终决定进入工业界/机器学习研究，您认为哪个是最好的选择？我更倾向于 CS + 统计/数学，而不是数据科学。我喜欢学习统计和数学。   由   提交/u/Equal_Job_7732   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bqyqt/d_cs_maths_vs_cs_stats_vs_cs_data_science/</guid>
      <pubDate>Wed, 06 Dec 2023 00:21:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大海捞针实验：Assistant API RAG 以 4% 的成本击败 GPT 4-Turbo & Llama Index</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bivxa/d_needle_in_a_haystack_experiment_assistants_api/</link>
      <description><![CDATA[      进行了一项实验，比较 Open AI 助手 API 的 RAG、GPT-4 Turbo（具有上下文窗口填充）和 Llama Index with GPT4 之间的信息检索性能。&lt; /p&gt; 我最近向 CopilotKit 添加了一个新的面向文档 React hook，专门制作来容纳（可能是长格式）文档并希望获得最佳性能。 得到了相当惊人的结果：助手的 API 在性能上大大击败了 Llama 索引，并且比使用 GPT-4 Turbo 填充上下文窗口便宜 25 倍。 ​ 准确度表现 ​ 成本 使用人工智能进行构建时的重大收获。几乎没有人应该使用上下文窗口填充，而且 Llama Index 在 RAG 性能方面还有很多工作要做。 无论 OpenAI 在 RAG 的底层使用什么，都具有出色的性能。 完整文章： https://ai88.substack.com/p/rag-vs-context-window- in-gpt4-准确度-成本   由   提交/u/kindly_formation71   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bivxa/d_needle_in_a_haystack_experiment_assistants_api/</guid>
      <pubDate>Tue, 05 Dec 2023 18:38:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你不需要矢量数据库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bhlsj/d_you_do_not_need_a_vector_database/</link>
      <description><![CDATA[RAG 的文档检索问题基本上是信息检索的情况，并且有更简单的解决方案。矢量嵌入仍然有用，但它们应该在 IR 管道的后期使用，而不是作为第一阶段检索，因为第一阶段检索有更简单、性能更高的解决方案。 此处的博客文章：http://about.xethub.com/blog/you-dont-need-a-vector-数据库 此处的笔记本和数据：https://github.com/xetdata/RagIRBench/   由   提交/u/yu Chenglow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bhlsj/d_you_do_not_need_a_vector_database/</guid>
      <pubDate>Tue, 05 Dec 2023 17:44:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 即时工程看起来像是猜测 - 如何正确评估 LLM 申请？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bgqyv/d_prompt_engineering_seems_like_guesswork_how_to/</link>
      <description><![CDATA[人们如何评估您的 LLM 申请的质量？我正在生产中运行一个治疗师聊天机器人（小规模 - 10 多个活跃用户），我花了很多时间微调提示，但这只是猜测。 我将对提示并运行一些测试对话，然后稍微了解一下它是否比调整之前更好或更差。这也是你们都在做的事情还是我错过了什么？？？   由   提交 /u/AndreeSmothers   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bgqyv/d_prompt_engineering_seems_like_guesswork_how_to/</guid>
      <pubDate>Tue, 05 Dec 2023 17:06:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlphaFold 预测是有价值的假设，可以加速但不能取代实验结构确定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bge4o/r_alphafold_predictions_are_valuable_hypotheses/</link>
      <description><![CDATA[社区绝对应该考虑来自科学实践的反馈：https://www.nature.com/articles/s41592-023-02087-4 引用：  &lt; p&gt;我们的结果表明，AlphaFold 预测并不比 PDB 中沉积的模型更好地表示晶体的内容，因为沉积的模型与实验数据更加一致，而预测和沉积的模型不同    由   提交 /u/suhcoR   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bge4o/r_alphafold_predictions_are_valuable_hypotheses/</guid>
      <pubDate>Tue, 05 Dec 2023 16:51:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研究人员如何产生新机器学习架构的想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bgb2n/d_how_do_researchers_generate_idea_of_new_machine/</link>
      <description><![CDATA[我从事机器学习工作已经有一段时间了，但我仍然专注于应用现有的机器学习技术。  每年我都对产生如此巧妙的建筑的过程感到困惑。如果您有经验，可以分享一下您是如何想出这个新想法的吗？在此过程中，什么对您启发最大？   由   提交 /u/Feisty_Philosophy234   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bgb2n/d_how_do_researchers_generate_idea_of_new_machine/</guid>
      <pubDate>Tue, 05 Dec 2023 16:47:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 最近您如何在移动设备上部署计算机视觉？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bg9x1/d_how_are_you_deploying_computer_vision_on_mobile/</link>
      <description><![CDATA[嘿/r/ml,&lt; /p&gt; 我正在构建一个用于图像分类的开源工具，您可以在其中使用网络应用程序构建图像分类器几秒钟。无需挑选恰好包含您的课程的预训练模型，您将获得适合您任务的自定义模型。我们在底层使用 CLIP 和 DinoV2，最终使用线性顶部部署 DinoV2。 我们目前仅提供用于部署的 Python 客户端，但我认为它在移动设备上非常有用，因为该模型相当适合小，您可以部署它，而无需在某个地方使用 API。 人们现在如何在移动设备上部署图像分类？他们通常只使用适合他们班级的预训练模型吗？使用 GPT4+Vision 并且只需按图像付费？或者计算机视觉功能通常被视为需要专业知识，因此大多数人并不真正使用它们？   由   提交/u/nateharada  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bg9x1/d_how_are_you_deploying_computer_vision_on_mobile/</guid>
      <pubDate>Tue, 05 Dec 2023 16:46:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何应对对你的论文是人工智能生成的错误指控？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ben3c/d_how_to_deal_with_false_accusations_of_your/</link>
      <description><![CDATA[读到我从 ICLR-2024 论文中获得的主观评论的质量有点令人沮丧。其中两个人相当不错，但另外两个人指责我的论文是一个“笑话”。和人工智能生成的。看到一个所谓的顶级会议允许公开发布此类不良评论，令人感到悲伤。现在，除非领域主席介入，否则外行人会对我的研究产生极大的偏见。   由   提交 /u/No-Sun-5534   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ben3c/d_how_to_deal_with_false_accusations_of_your/</guid>
      <pubDate>Tue, 05 Dec 2023 15:38:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 加州大学伯克利分校的论文“Sequential Modeling Enables Scalable Learning for Large Vision Models”有一条奇怪的缩放曲线。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bdcu7/r_sequential_modeling_enables_scalable_learning/</link>
      <description><![CDATA[   看到这篇论文“顺序建模实现大视觉模型的可扩展学习” （https://arxiv.org/abs/2312.00785）其中的数字看起来有点奇怪。对于不同的模型尺寸，线条看起来相同。  不同的运行或不同尺寸的大型模型通常是相同的吗？ https:/ /twitter.com/JitendraMalikCV/status/1731553367217070413  ​ 取自 https://arxiv.org/abs/2312.00785 中的图 3 这是完整的图3图 来自https:// arxiv.org/abs/2312.00785   由   提交/u/rantana  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bdcu7/r_sequential_modeling_enables_scalable_learning/</guid>
      <pubDate>Tue, 05 Dec 2023 14:37:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 顺序建模支持大型视觉模型的可扩展学习。 Transformer 接受“视觉句子”（1.64B 图像、420B 图像标记）的训练。同一模型可以执行修复、旋转、光照、语义分割、边缘检测、姿势估计等</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bd348/r_sequential_modeling_enables_scalable_learning/</link>
      <description><![CDATA[博客 - https://yutongbai.com/lvm.html  论文 - https://arxiv.org/abs/2312.00785   由   提交/u/MysteryInc152   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bd348/r_sequential_modeling_enables_scalable_learning/</guid>
      <pubDate>Tue, 05 Dec 2023 14:24:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] Paved2Paradise：通过考虑现实世界的经济高效且可扩展的 LiDAR 模拟</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bbklt/r_paved2paradise_costeffective_and_scalable_lidar/</link>
      <description><![CDATA[   /u/michaelaalcorn  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bbklt/r_paved2paradise_costeffective_and_scalable_lidar/</guid>
      <pubDate>Tue, 05 Dec 2023 13:06:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] StableSSM：通过稳定的重参数化缓解状态空间模型中的内存诅咒</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18b8nn4/r_stablessm_alleviating_the_curse_of_memory_in/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2311.14495 OpenReview：https:// /openreview.net/forum?id=BwG8hwohU4 摘要：  在本文中，我们研究了长期从参数化的角度来看状态空间模型（SSM）的记忆学习能力。我们证明，没有任何重新参数化的状态空间模型表现出与传统 RNN 类似的内存限制：可以通过状态空间模型稳定近似的目标关系必须具有指数衰减内存。我们的分析确定了这种“记忆诅咒”。由于循环权重收敛到稳定边界，这表明重新参数化技术可能是有效的。为此，我们引入了一类 SSM 重新参数化技术，可以有效解除其内存限制。除了提高逼近能力之外，我们进一步说明重新参数化方案的原则性选择还可以增强优化稳定性。我们使用合成数据集和语言模型验证了我们的发现。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18b8nn4/r_stablessm_alleviating_the_curse_of_memory_in/</guid>
      <pubDate>Tue, 05 Dec 2023 09:56:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>