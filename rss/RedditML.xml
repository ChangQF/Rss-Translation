<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 31 Dec 2023 18:15:15 GMT</lastBuildDate>
    <item>
      <title>[项目]我正在寻找文本（非手写）数字图像数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vdbgk/project_im_looking_for_a_text_not_handwritten/</link>
      <description><![CDATA[任何人都可以向我指出包含文本数字图像的数据集吗？我希望训练神经网络对数字图像进行分类，作为数独解算器项目的一部分，但我只能找到像 MNIST 这样的手写图像   由   提交/u/RubExpective0   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vdbgk/project_im_looking_for_a_text_not_handwritten/</guid>
      <pubDate>Sun, 31 Dec 2023 18:04:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] 微代理：能够自我编辑提示/Python 代码的代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vc2ia/p_microagents_agents_capable_of_selfediting_their/</link>
      <description><![CDATA[       由   提交/u/mikaron  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vc2ia/p_microagents_agents_capable_of_selfediting_their/</guid>
      <pubDate>Sun, 31 Dec 2023 17:05:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] NLP 算法/研究查询 - LF 帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vaiob/p_nlp_algoresearch_inquiry_lf_help/</link>
      <description><![CDATA[机器学习社区您好， 我来寻求您的帮助。 TLDR 在底部。 背景信息：我是一名经济学博士生，涉足机器学习以帮助回答我的一些研究问题。机器学习的一个分支在经济学研究中特别有用但很少使用，那就是自然语言处理技术（出于多种原因）。然而，我发现它对于许多应用程序都非常有用。我目前正在撰写一篇个人撰写的论文，主要关注 NLP 算法的应用。特别是，我需要做的是评估大量文档（业务描述）之间的相似性。我在经济领域的主要贡献是，我想为研究人员提供最先进的机器学习模型来评估不同公司的相似性。我已经应用了潜在语义索引，事实证明这非常有效。然而，LSI 是 90 年代的算法（Deerwester 等人），我正在寻找可以实现的现代算法。我有一个基本的概述，但我不是受过训练的机器学习工程师/数据科学家/计算机科学家。我不太确定如何找到所谓的 NLP 前沿，特别是用于评估文本相似性。 在经济学家文献中，有一本非常有用的期刊，称为《经济文献杂志》，基本上就是发表有关特定主题的文章并描述最新的应用程序。机器学习世界中也存在某些东西吗？无论如何，如果您能指出正确的方向以了解我应该寻找的方向，我将不胜感激。 TLDR：我正在寻找论文/文章（本质上是科学的，如果可能的话）描述了当前用于评估文档之间文本相似性的最先进的 NLP 算法。   由   提交 /u/ariusLane   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vaiob/p_nlp_algoresearch_inquiry_lf_help/</guid>
      <pubDate>Sun, 31 Dec 2023 15:52:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepMind 的 Beyond Human Data 论文中关于损失函数的问题。如果奖励只有 1 或 0，为什么要使用奖励加权损失，而不是仅仅针对成功进行训练？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18v9p53/d_question_on_the_loss_function_in_deepminds/</link>
      <description><![CDATA[在论文中，他们说他们将 1 和 0 的二元奖励分配给模型的输出。如果代码成功运行，或者数学问题被解决，或者w/e，那么奖励为1。否则为0。 论文后面他们说使用奖励加权负对数似然训练损失。  如果奖励只是 0 或 1，这不是正常的负对数似然损失，而是只在成功时进行训练（奖励为零时梯度为零）？如果是这样，为什么要在解释中添加额外的复杂性？ Mods，我不确定这是否算一个简单的问题，所以让我知道我是否应该移动它。   由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18v9p53/d_question_on_the_loss_function_in_deepminds/</guid>
      <pubDate>Sun, 31 Dec 2023 15:12:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么经过微调的 Donut 模型文档分类器的输出是一系列标记，而不仅仅是一个目标标签？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18v4d2m/d_why_is_the_output_from_a_fine_tuned_donut_model/</link>
      <description><![CDATA[我正在微调基于图像的文档分类器，Donut 模型 - https://huggingface.co/docs/transformers/model_doc/donut 以及我的自定义训练数据。  查看代码的推理部分（https://huggingface.co/ docs/transformers/model_doc/donut#inference-examples)，生成的“outputs”是一个带有多个标签的长字符串。使用正则表达式对该字符串进行后处理，最终获得目标标签。  请帮我解答几个与此相关的问题：  为什么要开发这样的微调模型？早些时候，我使用 DistilBert 处理基于文本的微调分类器模型 (https://huggingface.co/docs/transformers/tasks /sequence_classification），微调后的模型只会预测一个标签作为输出。为什么用于分类的 Donut 模型的微调没有设计为仅输出一个标签作为目标？鉴于 DistilBert 和 Donut 模型都是基于变压器的模型，为什么输出模式存在这种差异？ 作为一种尝试，我用很少的东西对 Donut 模型进行了微调仅 1 个 epoch 的示例。 （我的资源暂时有限。） 在推理过程中，我得到了一个垃圾字符串作为输出，就像这样 --  轴承轴承轴承轴承轴承轴承。它不包含任何候选目标标签。因此，这不仅仅是预测错误的问题，而是预测错误的问题。这是一个非解决方案。通过足够的示例和更多的训练，这种行为会得到改善吗？  提前非常感谢。    ;由   提交 /u/bikashg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18v4d2m/d_why_is_the_output_from_a_fine_tuned_donut_model/</guid>
      <pubDate>Sun, 31 Dec 2023 09:38:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 Colab Pro 中进行 Keras CNN 训练时，TPU 落后于 GPU</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18v37b7/d_tpu_lags_behind_gpu_for_keras_cnn_training_in/</link>
      <description><![CDATA[我一直在比较 Colab 的运行时。我发现，对于普通 Keras CNN，TPU 始终落后于 A100、V100 或 T4。增加批量大小并没有真正改善它。我应该研究任何具体配置吗？ 代码 。 包含详细信息的博客文章。   由   提交 /u/shakibahm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18v37b7/d_tpu_lags_behind_gpu_for_keras_cnn_training_in/</guid>
      <pubDate>Sun, 31 Dec 2023 08:19:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 华为、牛津大学和伦敦大学学院的研究人员提出了一种新的可微调通用代理来扩展 RL</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18v2eh3/r_researchers_in_huaweioxford_and_ucl_propose_a/</link>
      <description><![CDATA[   /u/Ok_Can2425   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18v2eh3/r_researchers_in_huaweioxford_and_ucl_propose_a/</guid>
      <pubDate>Sun, 31 Dec 2023 07:26:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何构建 ML 系统：从 MLOps 到机器学习管道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18v1onv/d_how_to_build_ml_systems_from_mlops_to_machine/</link>
      <description><![CDATA[MLOps 经常被视为“生产化 ML”的解决方案。然而，现有的课程、博客文章和书籍都是从“学习 Docker、kubernetes、Terraform 等”开始的。 MLOps 供应商混淆了问题 - Google 的 MLOps 思维导图有 26 个盒子需要构建（有史以来最糟糕的乐高指令！），而 Databricks 甚至有更多（以炫耀他们的生产就绪枪）。  我开发了一个免费的无服务器机器学习课程，您可以在其中使用 3 个 Python 程序（分别创建特征、模型和预测的 ML 管道）构建无服务器 ML 系统。现在，该课程中有许多出色的无服务器机器学习系统，可以预测空气质量、电力需求、足球比分、水位等。  我们在构建机器学习系统时是否误入歧途，主要是关于开发/登台/产品、基础设施即代码？或者只是 ML 基础设施现在才出现，可以轻松地用 Python 构建 ML 系统（例如 SaaS 模型注册表、特征存储、模型服务、Python UI (Gradio/Streamlit)）？ 参考文章我就这个主题写过： https://www.hopsworks。 ai/post/mlops-to-ml-systems-with-fti-pipelines   由   提交 /u/jpdowlin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18v1onv/d_how_to_build_ml_systems_from_mlops_to_machine/</guid>
      <pubDate>Sun, 31 Dec 2023 06:41:36 GMT</pubDate>
    </item>
    <item>
      <title>[p] 我培训了一名法学硕士来教我更好地编码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uxz56/p_i_trained_an_llm_to_teach_me_to_code_better/</link>
      <description><![CDATA[正如你们中的一些人可能已经经历过的那样，GitHub Co-Pilot 是一种糟糕的学习方式，但我想看看是否有我想要的东西可以做一些编码教育方面的法学硕士。 在向公众提供它之前，我想看看人们对此有何看法。 演示：https://youtu.be/Z1rZZkL4PFA?si=-cYcKeh9FkLzBUp3   由   提交/u/AggressiveHunt2300   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uxz56/p_i_trained_an_llm_to_teach_me_to_code_better/</guid>
      <pubDate>Sun, 31 Dec 2023 03:18:43 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 GPT4 视觉进行 OCR 的一些实际结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uvrwj/p_some_practical_results_from_using_gpt4_vision/</link>
      <description><![CDATA[您好，不太确定将其发布到哪里，所以我会在这里尝试。人们对 GPT4 愿景有很多兴奋，但当在实际项目的一些真实数据上进行尝试时，却缺乏这种感觉。它有时会产生幻觉，或者拒绝执行任务，而且准确性并不比 Tesseract 好多少。然而，如果两者结合起来，事情就会变得非常好。更多详细信息和源数据请访问以下链接。 https://pslusarz.github.io/articles/2023/12/22/compare-ocr-tesseract-gpt4-nara-rolls.html   由   提交/u/wuj   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uvrwj/p_some_practical_results_from_using_gpt4_vision/</guid>
      <pubDate>Sun, 31 Dec 2023 01:30:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 15亿参数的多模态聊天</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ut3lm/p_multimodal_chat_in_15_billion_parameters/</link>
      <description><![CDATA[   /u/ashvar  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ut3lm/p_multimodal_chat_in_15_billion_parameters/</guid>
      <pubDate>Sat, 30 Dec 2023 23:30:20 GMT</pubDate>
    </item>
    <item>
      <title>[R]《认知架构40年：核心认知能力与实际应用》（2018）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uqy29/r_40_years_of_cognitive_architectures_core/</link>
      <description><![CDATA[论文：https://link.springer.com/article/10.1007/s10462-018-9646-y 预印本版本 ：https://arxiv.org/abs/1610.08602 项目页面 （交互式可视化和完整参考书目）：http://jtl.lassonde.yorku.ca/project/cognitive_architectures_survey/ 摘要：  在本文中，我们对过去 40 年的认知架构研究进行了广泛的概述。迄今为止，现有架构的数量已达到数百个，但大多数现有调查并没有反映这种增长，而是集中在少数成熟的架构上。在这项调查中，我们的目标是对认知架构的研究提供更具包容性和更高层次的概述。我们最终的 84 种架构包括 49 种仍在积极开发中的架构，它们借鉴了从精神分析到神经科学等多种学科的知识。为了将本文的长度保持在合理的范围内，我们仅讨论核心认知能力，例如感知、注意机制、行动选择、记忆、学习、推理和元推理。为了评估认知架构实际应用的广度，我们提供了使用列表中的认知架构实施的 900 多个实际项目的信息。我们使用各种可视化技术来突出该领域发展的整体趋势。除了总结当前认知架构研究的最新进展之外，本次调查还描述了已经尝试过的各种方法和想法及其在模拟人类认知能力方面的相对成功，以及认知行为的哪些方面需要对其机械对应物进行更多研究，从而进一步了解认知科学如何进步。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uqy29/r_40_years_of_cognitive_architectures_core/</guid>
      <pubDate>Sat, 30 Dec 2023 21:58:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2023年十大值得关注的人工智能研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18unlno/p_ten_noteworthy_ai_research_papers_of_2023/</link>
      <description><![CDATA[       由   提交/u/seraschka  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18unlno/p_ten_noteworthy_ai_research_papers_of_2023/</guid>
      <pubDate>Sat, 30 Dec 2023 19:32:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] Stability AI 会成为第一个在 2024 年破产的生成型 AI 独角兽吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uclmy/d_will_stability_ai_be_the_first_generative_ai/</link>
      <description><![CDATA[   /u/milaworld  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uclmy/d_will_stability_ai_be_the_first_generative_ai/</guid>
      <pubDate>Sat, 30 Dec 2023 10:16:48 GMT</pubDate>
    </item>
    </channel>
</rss>