<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Thu, 18 Jul 2024 03:19:52 GMT</lastBuildDate>
    <item>
      <title>[R] Spider2-V：多模式代理距离实现数据科学和工程工作流程自动化还有多远？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5qt1r/r_spider2v_how_far_are_multimodal_agents_from/</link>
      <description><![CDATA[多模式 AI 代理的新基准，专注于现实世界的 Dara 工程任务。 项目页面：链接，论文：链接，代码：链接。  TLDR：自主 LLM 代理无法取代数据工程师……目前如此。但至少我们可以跟踪进度 🫡 概述： 随着 AI 技术变得越来越先进，我们需要越来越复杂的基准来评估系统的质量和衡量进度。出现了一个独特的基准分支，专注于使用专业工具/应用程序和网站（参见WorkArena、WebArena、OSWorld）。 在 Spider2-V 项目中，正在创建一个基准来评估数据工程中的 AI 代理。它包含 494 个任务，涵盖整个工作周期：  数据仓库（Snowflake、BigQuery 等工具） 数据提取（例如 Airbyte） 数据转换（例如 dbt） 数据可视化（例如 Superset、Metabase） 数据编排（例如 Airflow、Dagster）  （以及心爱的 Excel 文件，因为谁能没有它们？） 如果您有数据工程经验，您就会明白这是一个庞大的集合，尽管它没有涵盖您可能遇到的所有解决方案。 准备每个任务平均需要 4 个小时，因此它们非常原子化，不需要很长的视野思考。任务分为三个难度等级：  简单（20%，不超过 5 步即可解决） 中等（63%，6-15 步） 困难（17%，16-40 步）  所有任务均基于 DE/DS 教程，由人工标注员从网络上获取。可以说它们代表了真实的用例。简单任务示例：  将当前 Google Drive 文件夹下的数据加载到打开的 BigQuery 数据集的新表 “data1” 中  或者中等难度的任务：  从 GitHub 安装 dbt-cloud-cli，并将二进制文件解压到与 dbt 项目 “analytics” 相同的文件夹中  为了解决任务，LLM 代理可以访问 IDE 和浏览器（已设置账户）。模型使用 pyautogui 生成 Python 代码以与虚拟机的 UI 交互，然后执行代码，并逐步重复该过程。  猜猜 GPT-4 完成了多少任务？ 只有 14%！这个数字似乎很低，但可以突出显示更成功的集群——40% 的简单任务和 25% 的数据可视化任务都得到了解决。 除了专有模型外，还测试了开放模型 (LLAMA 3 70B、Mixtral 8x7B)，但由于它们不是多模态的并且不接受图像作为输入，因此仅向它们显示了屏幕的文本描述。这大大降低了它们的指标——它们只解决了一小部分任务。然而，我们热切期待 LLAMA-3 405B，据传它是多模态的，将于 7 月 23 日发布。  我非常渴望看到 GPT-5 发布时发布的基准指标——然后我们拭目以待！押注下一代模型将解决多少百分比的任务！     由    /u/stalkermustang 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5qt1r/r_spider2v_how_far_are_multimodal_agents_from/</guid>
      <pubDate>Wed, 17 Jul 2024 19:20:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于稳定扩散中潜伏层的维度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5qszw/d_about_the_dimensions_of_latents_in_stable/</link>
      <description><![CDATA[您好，我对这个问题已经思考了一段时间了，希望您能解答我的疑惑。 鉴于潜在（稳定）扩散中的自动编码器经过训练可以产生与输入图像感知相似的潜在数据，作者选择 4x64x64 作为潜在数据的尺寸似乎很奇怪；为什么要添加通道？ 选择 3x64x64 会更合理，因为可以说自动编码器将学习将输入图像的每个通道映射到潜在数据中的通道，从而尽可能在潜在空间中保留感知相似性。 所以我想讨论的主题是：为什么选择 4 个通道的潜在数据？    提交人    /u/HumbBest   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5qszw/d_about_the_dimensions_of_latents_in_stable/</guid>
      <pubDate>Wed, 17 Jul 2024 19:20:22 GMT</pubDate>
    </item>
    <item>
      <title>如何比较 XGBoost 与专家分类对未分类观测的敏感度？“[研究]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5jb5p/how_to_compare_sensitivity_between_xgboost_and/</link>
      <description><![CDATA[我有一个机器学习项目，涉及多类别分类，有三个类别：M、S 和 U。我的测试数据集包含 236 个观测值。我使用 XGBoost 并测量敏感度作为评估指标。 我想将结果与测试数据集上的专家分类进行比较。但是，专家仅对 68 个观测进行了分类，而留下 168 个观测未分类。 考虑到分类观测数量的差异，我如何比较 XGBoost 与专家分类的敏感度？ 以下是混淆矩阵： XGBoost 混淆矩阵： [[ 17 25 4] [ 19 120 15] [ 4 22 10]] 专家混淆矩阵： [[ 7 3 2] [ 5 13 30] [ 0 0 8]]    提交人    /u/Least-Background4181   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5jb5p/how_to_compare_sensitivity_between_xgboost_and/</guid>
      <pubDate>Wed, 17 Jul 2024 14:16:55 GMT</pubDate>
    </item>
    <item>
      <title>应该采取哪些步骤来理解变分自动编码器？[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5idrz/what_steps_should_be_taken_to_understand_up_to/</link>
      <description><![CDATA[现在开始使用 ML，需要为研究小组使用 VAE。 在专注于应用之前，我应该了解哪些概念？    提交人    /u/BobbyJones12344   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5idrz/what_steps_should_be_taken_to_understand_up_to/</guid>
      <pubDate>Wed, 17 Jul 2024 13:36:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 匹配医学图像中的分割区域</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5i610/p_matching_segment_areas_in_medical_images/</link>
      <description><![CDATA[      https://preview.redd.it/2p5lksh1z2dd1.png?width=597&amp;format=png&amp;auto=webp&amp;s=1995475c783500ab58e9564e140b8debdf7dc8f3 参考附图，我正在努力构建一个深度学习网络，该网络能够找出左图中哪个分割区域是与右侧区域 1（红色数字）匹配的身体部分。有人可以分享指向解决此挑战的地方的指针吗，或者无论如何问题的名称是什么，以便我可以搜索论文和代码？ 提前致谢，我也愿意合作，这是为了在心脏病的背景下解释人工智能。     提交人    /u/sladebrigade   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5i610/p_matching_segment_areas_in_medical_images/</guid>
      <pubDate>Wed, 17 Jul 2024 13:26:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 《ReFT：语言模型的表征微调》作者，本周五将在 Oxen.ai 论文俱乐部发表</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5h1m8/d_author_of_reft_representation_finetuning_for/</link>
      <description><![CDATA[Arxiv 论文第一作者Zhengxuan Wu将与Greg Schoeninger一起参加本周五的Oxen.AI论文俱乐部，解释编辑表示如何比参数高效微调 (PEFT) 方法更好。 https://lu.ma/oxen ReFT：语言模型的表示微调。 Greg，仅阅读摘要就有 3 个问题和 1 条评论。 Q1)“表示”到底是什么意思？ 即，本文所指的表示捕获了神经网络的哪一部分？ Q2)“任务特定干预”中的干预是什么意思？我以前没有听说过预训练或微调这个术语。 Q3) 从 API 角度来看，本文的重点是否类似于： 我们不会通过改进记录的输入和输出来改进 API，而是通过直接更改代码来改进 API？ 评论）摘要让这篇论文听起来很巫术。希望测试是苹果 :: 苹果。 期待您在周五揭开神秘面纱，Greg。非常酷，论文的第一作者能加入进来，帮助解释和回答问题。 详情： https://lu.ma/oxen 7 月 19 日星期五，太平洋时间上午 10:00，东部时间下午 1:00，Zoom 上 论文：https://arxiv.org/pdf/2404.03592 感谢：感谢 Greg、u/FallMindless3563、Scott Howard u/sthoward 和 Oxen团队为我提供了一个 Easy 按钮并与社区分享您的知识，同时提供了很酷的工具来在 oxen.ai 上管理数据集。    提交人    /u/ReluOrTanh   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5h1m8/d_author_of_reft_representation_finetuning_for/</guid>
      <pubDate>Wed, 17 Jul 2024 12:32:41 GMT</pubDate>
    </item>
    <item>
      <title>[P]在推理 ML 模型时处理缺失的文本信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5cczf/phandling_missing_textual_information_while/</link>
      <description><![CDATA[我正在解决一个问题，其中我拥有以数值变量形式以及某种较长文本形式提供的数据。现在我可以从这些文本信息中提取特征，并将它们与已有的数值特征相结合。但问题是，在推理过程中我无法获得这些文本信息。只有在训练数据中我才拥有这些文本，并且在进行预测时必须没有它们。有什么建议可以告诉我应该如何进行模型训练，因为我不能放弃这些文本信息，因为它们非常有见地？我能想到的唯一解决方案是在预测过程中屏蔽它们，或者甚至根据某些逻辑标准尝试使用一些默认值。非常欢迎任何建议！！谢谢！！    提交人    /u/vishants98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5cczf/phandling_missing_textual_information_while/</guid>
      <pubDate>Wed, 17 Jul 2024 07:42:41 GMT</pubDate>
    </item>
    <item>
      <title>[P]如何重新使用现有词汇来建立单词索引？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5bwq9/phow_do_you_reuse_an_existing_vocabulary_to_build/</link>
      <description><![CDATA[因此，我正在尝试训练一个用于股市预测的 ml 模型，我刚刚开始，所以现在它只是用来预测新闻文章是否与股市有关！因此，我成功地在数据上训练了模型，我必须将其转换为单词索引。因此，除了单词索引，我们还获得了一个词汇表，就像一本将单词与数字映射的词典。现在，我有一个测试数据集，如何使用相同的词汇表为测试集创建单词索引。创建不同的词汇表或单词索引只会破坏准确性？ 为测试集创建不同的单词索引和词汇表不会造成太大问题吗？如果会导致问题，我该如何使用现有的词汇表？我正在考虑合并两个数据集，然后从末尾省略测试集的长度！我觉得有比这更好的解决方案，请帮忙！ 抱歉，这是一个愚蠢的问题，我对此还是有点陌生​​。 token = Tokenizer() token.fit_on_texts(X) word_indices = token.texts_to_sequences(X) vocab = token.word_index max_len = max(max(i) for i in word_indices) word_indices_padded = pad_sequences(word_indices, maxlen=max_len, padding=&#39;post&#39;) word_indices_np_padded = np.array(word_indices_padded) y_train = np.asarray(y).astype(&#39;float32&#39;) model = Sequential([ Dense(16,activation=&#39;relu&#39;), Dense(16,activation=&#39;relu&#39;), Dense(1,激活=&#39;sigmoid&#39;）]）model.compile（optimizer=&#39;adam&#39;，loss=&#39;binary_crossentropy&#39;，metrics=[&#39;accuracy&#39;]）model.fit（word_indices_np_padded，y_train，epochs=10）;  这是我的上下文代码。 我的谷歌colab链接：https://colab.research.google.com/drive/1zwPKVwxtM2eoitISL9SnOwGiLj8hL6g6?usp=sharing    提交人    /u/Mastermind_308   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5bwq9/phow_do_you_reuse_an_existing_vocabulary_to_build/</guid>
      <pubDate>Wed, 17 Jul 2024 07:11:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 等变神经网络的新型正则化技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e58b7i/r_new_regularization_technique_for_equivariant/</link>
      <description><![CDATA[大家好， 我想分享一个我一直在研究的研究项目，它可能对那些训练机器学习模型的人有用。我正在收集更多数据并准备一篇论文，但与此同时，我想在这里分享这个想法，以获得一些反馈，看看它是否对其他人有帮助。 我使用 MIT 许可证发布它，我希望它被自由使用，但如果你在研究项目中使用它，请引用 GitHub。以下是我制作的一个非技术性的视频，用于展示这个想法： 项目概述 该项目引入了一个新的正则化项，旨在创建近似等变的神经网络。它的功能类似于通过随机转换来扩充您的数据，允许您教会您的模型如何对输入转换做出反应。 有关它的功能和使用方法的更多详细信息，请查看 GitHub 页面。 应用 此方法可应用于广泛的监督学习问题，包括：  图像和视频处理 音频处理 文本处理  以及某些无监督学习模型，如自动编码器。 我在强化学习方面的经验有限，但我对 RL 的潜在应用很感兴趣。 初步结果 虽然我的数据仍然有限，但我已经看到了某些任务的可喜改进。例如，在图像分割中，测试分数提高了几个百分点，在某些情况下，这种方法比传统的数据增强方法效果更好。我尝试过用 CNN 和预训练的视觉转换器来做这件事。使用预训练模型，最好在微调过程中将其应用于分类/分割头。 主要优势 与现有的等变 ML 技术相比，这种正则化方法有几个优势：  它支持不可逆变换。 它不需要特殊的模型架构。 您可以控制等变程度，这对于手写识别等任务至关重要，在这些任务中，模型应该对小旋转保持不变，但不应对大旋转保持不变。  很抱歉自我宣传，但我认为这是社区真正感兴趣的事情，我很高兴分享这个想法并听取您的想法和反馈。    提交人    /u/jjk23   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e58b7i/r_new_regularization_technique_for_equivariant/</guid>
      <pubDate>Wed, 17 Jul 2024 03:36:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 租用 GPU 的最佳地点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e562n1/d_best_places_to_rent_gpus_from/</link>
      <description><![CDATA[大家好， 我希望能够灵活地按需租用 GPU，而且当然不必支付很多费用。我一直在关注一些公司，例如 brev.Dev、runpod 和 fluidstack。我想知道你们是否使用其中任何一个或其他东西来运行工作负载     提交人    /u/OGbeeper99   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e562n1/d_best_places_to_rent_gpus_from/</guid>
      <pubDate>Wed, 17 Jul 2024 01:42:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] DiT 实施失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4vi9h/d_failed_dit_implementation/</link>
      <description><![CDATA[      大家好， 作为我在研究机器人操作时，想训练一个 DiT。我试图让它过度拟合一个简单的 20k 样本 猫数据集 。我的实现类似于论文的“adaLN-Zero”版本（在 LayerNorm 上进行条件化），它有 12 个 DiT 块层、12 个头、隐藏大小为 768 和一个补丁大小为 2。因为图像只包含猫，所以条件化有点没用，因为样本都有相同的标签。我在将它过度拟合到 MNIST 上确实取得了不错的效果。 在 8xA100 上一个小时后，我觉得它已经达到了瓶颈并努力克服它。 结果也很糟糕（图像是 1k 步采样）。我应该期待这个数据集有更好的效果吗？我将非常感谢任何能帮助我的人🙏 这是repo（我很懒，使用了HuggingFace的DDPMScheduler，但计划在它工作时编写自己的） https://preview.redd.it/k9bdi93b8xcd1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=5d3b14d1a16d3f4e9c5fbe8049cec6e4c5d360a5 https://preview.redd.it/9bmstg8c8xcd1.png?width=818&amp;format=png&amp;auto=webp&amp;s=f08747c95b5148a04c42c12ee8462b9bd2c6d057    提交人    /u/Ok_Operation_2094   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4vi9h/d_failed_dit_implementation/</guid>
      <pubDate>Tue, 16 Jul 2024 18:07:51 GMT</pubDate>
    </item>
    <item>
      <title>[P] Tricycle：从头开始完全从 Autograd 到 GPT-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4sz1e/p_tricycle_autograd_to_gpt2_completely_from/</link>
      <description><![CDATA[我想分享 Tricycle：一个我完全从头开始构建的快速、功能齐全的深度学习框架： https://github.com/bclarkson-code/Tricycle/。 到目前为止，最大的里程碑是在单个 RTX 3090 上 68 小时内在 23 亿个代币上训练 GPT-2(124M)，我正在努力进一步扩大规模。 整个库都是从头开始构建的，从 AutoGrad 引擎一直到 GPT-2，任何有一点 Python 经验的人都应该可以理解。我试图使代码尽可能简单而不隐藏任何东西，并且我添加了一个 wiki 来介绍我如何构建所有内容。 我很想听听你的想法！ 编辑：语法    提交人    /u/Efficient_Plankton_9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4sz1e/p_tricycle_autograd_to_gpt2_completely_from/</guid>
      <pubDate>Tue, 16 Jul 2024 16:26:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文讨论：超越：生成模型的表现可以超越训练它们的专家</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</link>
      <description><![CDATA[大家好， 正如标题所示：我创建这篇文章是为了讨论最近发布的论文，该论文到目前为止引起了很多关注。我刚刚阅读了这篇论文，有一些问题。如果你也读过并喜欢这篇论文，我们聊聊吧！ https://arxiv.org/abs/2406.11741  设置对你来说清楚吗？作者是否也通过实验测试了定理 3 或定理 4？ 训练数据集中有多少专家/玩家？如果他们测试定理 4，他们是否会在特定玩家的游戏上训练集合的每个成员？ 他们如何鼓励定理 3 中的不相交集条件？ 等式 4 有一个拼写错误（两个术语相同）？     提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</guid>
      <pubDate>Tue, 16 Jul 2024 14:27:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 蛋白质语言模型揭示病毒模仿和免疫逃逸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</link>
      <description><![CDATA[我们被 ICML 24/ML4LMS 研讨会接受了，所以我想分享一下 :) &quot;蛋白质语言模型揭示病毒模仿和免疫逃逸&quot; TL;DR: 🧬 研究概述：病毒模仿宿主蛋白以逃避免疫系统的检测。我们使用蛋白质语言模型 (PLM) 来区分病毒蛋白和人类蛋白，ROCAUC 为 99.7%，准确率为 97%。 📊 见解：我们的研究表明，PLM 和生物免疫系统会犯类似的错误。通过识别和分析这些错误，我们可以深入了解免疫反应性以及开发更有效的疫苗和治疗方法的潜在途径。 我们还展示了一种新颖的、可解释的、多模式表格错误分析方法，用于理解任何问题的见解和错误，让我们了解深度学习语言模型/PLM 所犯错误的特征。 🔗 论文：https://openreview.net/forum?id=gGnJBLssbb&amp;noteId=gGnJBLssbb 代码：https://github.com/ddofer/ProteinHumVir 与我和海报见面（#116）在 ICML/ML4LMS 研讨会上！：https://openreview.net/attachment?id=gGnJBLssbb&amp;name=poster doi： https://doi.org/10.1101/2024.03.14.585057    提交人    /u/ddofer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</guid>
      <pubDate>Tue, 16 Jul 2024 09:13:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>