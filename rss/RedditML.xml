<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Wed, 05 Mar 2025 18:24:53 GMT</lastBuildDate>
    <item>
      <title>[r]超出相关性：在搜索和建议中对多个目标进行优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j47mhf/r_beyond_relevance_optimizing_for_multiple/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  构建有效的建议和搜索系统意味着不仅可以预测相关性。现代用户期望的个性化体验可以满足广泛的需求和偏好，并且企业需要与其总体目标保持一致的系统。这需要同时针对多个目标进行优化 - 这是一个需要细微的方法的复杂挑战。这篇文章探讨了价值建模和多目标优化的概念（MOO），总结了Jannach＆amp; Abdollahpouri从2022年开始，并解释了这些技术如何使更复杂和有价值的建议和搜索经验的发展。 完整的纸张在这里写下：https://www.shaped.ai/blog/beyond-relevance-optimizing-for-multiple-objectives-in-search-and-recommendations  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/skeltzyboiii     [link]    [commient]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j47mhf/r_beyond_relevance_optimizing_for_multiple/</guid>
      <pubDate>Wed, 05 Mar 2025 16:52:38 GMT</pubDate>
    </item>
    <item>
      <title>[d]创建统一图向量的代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j477pz/d_code_to_create_uniform_graph_vectors/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j477pz/d_code_to_create_uniform_graph_vectors/</guid>
      <pubDate>Wed, 05 Mar 2025 16:35:17 GMT</pubDate>
    </item>
    <item>
      <title>[d]具有动态数字信息图的模块化AI体系结构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j4714s/d_modular_ai_architecture_with_dynamic_digital/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j4714s/d_modular_ai_architecture_with_dynamic_digital/</guid>
      <pubDate>Wed, 05 Mar 2025 16:27:48 GMT</pubDate>
    </item>
    <item>
      <title>[d]如果您必须再次写作，您会考虑哪个主题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j46ka0/d_what_topic_would_you_consider_for_your_master/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在已经从事ML工程师或类似行业的人。如果您如今必须再次介绍主论文，您将涉足什么话题？或您将避免哪些ML区域？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/vastsignature-8138     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j46ka0/d_what_topic_would_you_you_you_consider_for_your_your_master/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j46ka0/d_what_topic_would_you_consider_for_your_master/</guid>
      <pubDate>Wed, 05 Mar 2025 16:08:39 GMT</pubDate>
    </item>
    <item>
      <title>[d]如何用pytorch实施和训练比特网1.58b？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j463h1/d_how_to_implement_and_train_bitnet_158b_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我的目标是构建GPT。问题是我以前从未训练过一个，所以我无法想象它的工作方式。具体来说，我的知识仅限于“训练模型来预测接下来的标志”。假设我们有句子“什么是reddit”。和“很棒”。然后，仅解码器输入是“ reddit＆lt; eos＆gt;很棒的＆quot&#39;，虽然该标签的正确转移1，即“ reddit＆lt; eos＆gt;真棒。谢谢 我学到的：1。如何实现仅解码器的变压器（单词嵌入，预先计算的位置编码，变压器块：掩盖自我注意力，添加＆amp; norm，add＆amp; norm，feed forther，forth，add＆amp; norm，linearear tolinear，linearear）2。但是我看不到GPT的用例。我看到了这一点，用于文本到文本任务（翻译），文本到图像（图像生成），图像对文本（图像字幕）3。我听说GPT使用仅解码器的变压器，但Bert使用仅编码的变压器。所以我不确定。 我还没有学到的东西：1。如何训练（我对此完全看不见。 1.58B在pytorch中href =“ https://www.reddit.com/r/machinelearning/comments/1j463h1/d_how_to_implement_implement_and_train_bitnet_158b_with/”&gt; href =“ https://www.reddit.com/r/machinelearning/comments/1J463H1/d_how_how_to_implement_and_train_bitnet_158b_with/”&gt; [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j463h1/d_how_to_implement_and_train_bitnet_158b_with/</guid>
      <pubDate>Wed, 05 Mar 2025 15:48:42 GMT</pubDate>
    </item>
    <item>
      <title>[R]本周的最高LLM研究：2月24日至25日3月2日</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j435sy/r_top_llm_research_of_the_week_feb_24_march_2_25/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  跟上LLM研究很难，每天噪音过多和新滴。我们在内部为团队和纸阅读小组提供最佳论文（ https://forms.gle/pisk1ss1ss1wdzxkphi9 ）。在这里也共享。它证明了在生物医学发现中的应用，包括药物重新利用，新型靶标识别和细菌进化机制。 纸得分：0.62625    https://arxiv.org/pdf/2502.18864       swe-rl：通过开放式软件swee prowss noghate swe pressign pression swee props wrose props wirforme       纸得分：0.586004  纸url      https://arxiv.org/pdf/2502.18449         aad-aad-llm：Aad-aad-aad-aad-aad-lie lie&gt; aud&gt;通过IEEG整合大脑信号以解码听众注意并产生感知一致的响应。它开创了意图感知的听觉人工智能，改进了在Mutilealker方案中的语音转录和问题回答等任务。 纸质分数：0.543714286    https：//arxiv.org/pdf/2502.16794         llm-microscope：llm-microscope：揭示了Punction of Punction of Condect of Condect of Condect of Condort of Cronsupers of Cronsuper of consuply  纸张得分：0.47782      SurveyX：通过大语言模型的学术调查自动化  该研究介绍了Surveusx，这是一种自动化测量生成的新型系统，用于利用LLM，并具有属性，在线参考检索和重新销售等创新。它显着提高了内容和引文质量，接近人类专家的表现。 纸张得分：0.416285455     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sircomprehension7453     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j435sy/r_top_llm_research_of_the_week_weeek_feb_24_march_march_2_2_255/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j435sy/r_top_llm_research_of_the_week_feb_24_march_2_25/</guid>
      <pubDate>Wed, 05 Mar 2025 13:33:28 GMT</pubDate>
    </item>
    <item>
      <title>安德鲁·巴托（Andrew Barto）和理查德·萨顿（Richard Sutton）是2024 ACM A.M.图灵（Turing）因发展强化学习的概念和算法基础而奖。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j42icj/andrew_barto_and_richard_sutton_are_the/</link>
      <description><![CDATA[      ＆＃32;提交由＆＃32; /u/mtgtraner     [link]&gt; [link]&gt; [link]&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j42icj/andrew_barto_and_richard_sutton_are_the/</guid>
      <pubDate>Wed, 05 Mar 2025 13:00:25 GMT</pubDate>
    </item>
    <item>
      <title>[r] Qilin：带有用户会话的大规模多模式搜索数据集和Xiaohongshu的异质结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j41kzh/r_qilin_a_largescale_multimodal_search_dataset/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Qilin数据集通过收集840万个不同移动应用程序的840万个多模式搜索会话来引入信息检索研究的显着进步，从而在应用程序之间导航时捕获了实际用户行为。 This is the first dataset to track complete cross-app search journeys rather than single-app interactions. Key technical points: - Comprehensive data collection: 8.4M search sessions, 2.2M unique images, 6.9M text documents across 9 different mobile apps - True multimodal representation: Contains text queries (74%), image queries (20%), and hybrid queries (6%) - Cross-app tracking: 28% of sessions include app switches, enabling research on inter-app search behavior - Diverse application types: Includes search engines, e-commerce, short video, news, Q&amp;A platforms, and more - Performance improvements: Models trained on cross-app data outperform single-app models by up to 17% on query understanding任务 -  新颖的基准任务：引入标准化评估，以查询理解，文档理解和查询文档匹配 我认为该数据集可以从根本上改变我们接近移动搜索系统的方式。通过应用程序切换（28％）的会话比例很高，这表明我们通过孤立研究应用程序缺少关键上下文。交叉应用训练的性能提高表明，建立模型具有重要的价值，这些模型可以理解完整的用户旅程，而不是对单个应用程序进行优化。这可能会导致更加集成的搜索体验，可以更好地预测用户在不同信息源之间移动的需求。 数据的仅中文性质确实限制了对其他地区的普遍性，我很好奇这些模式在其他App生态系统中可能会有所不同。尽管研究人员确实实施了匿名化，但这种全面跟踪的隐私影响也应仔细考虑。  tldr：Qilin是第一个捕获用户如何在多个移动应用程序上进行搜索的数据集，这表明28％的搜索会话涉及应用程序切换。在此跨应用数据上培训的模型优于单个应用模型的模型多达17％，这表明我们需要重新考虑搜索作为一种集成体验而不是App-by-App优化。  。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [links]     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j41kzh/r_qilin_a_largescale_multimodal_search_dataset/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j41kzh/r_qilin_a_largescale_multimodal_search_dataset/</guid>
      <pubDate>Wed, 05 Mar 2025 12:07:42 GMT</pubDate>
    </item>
    <item>
      <title>[r]将自然语言转换为逻辑谬误检测的一阶逻辑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3zokg/r_translating_natural_language_to_firstorder/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/jsonathan     [link]&gt; [link]&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3zokg/r_translating_natural_language_to_firstorder/</guid>
      <pubDate>Wed, 05 Mar 2025 09:58:06 GMT</pubDate>
    </item>
    <item>
      <title>反驳策略，结构和做/不[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3zjae/rebuttal_strategies_structure_and_dodont_d/</link>
      <description><![CDATA[Facing my first rebuttal period and want to learn is there any statgergeis or structure people follow in AI/ML space. Particularly when  Asked to run more experiments and within very short time frame Asked to restructure the whole section and one of the reviewer didn&#39;t find it易于阅读   审稿人缺少论文中已经给出的基本细节   质疑提出的方法的新颖性      &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j3zjae/rebuttal_strategies_stratecies_sstruceure_and_dodont_d/”&gt; [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3zjae/rebuttal_strategies_structure_and_dodont_d/</guid>
      <pubDate>Wed, 05 Mar 2025 09:47:10 GMT</pubDate>
    </item>
    <item>
      <title>[r]如何微调“思考”模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3yx5a/r_how_do_i_finetune_thinking_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi，我想在“推理”上进行监督的微调。  DeepSeek-ai/deepSeek-ai/deepSeek-r1-distill-lllama-8b 等模型。但是，我注意到这些模型，就像它们被蒸馏的较大模型一样，产生了“思考”。在提供最终答案之前的文本（有时答案只是对＆lt; think; gt;＆lt;/think think gt; tags之间所包含的推理的简短摘要）。问题是：我是否应该构架我的任务以适合这种格式（推理 - ＆gt;答案），还是可以在没有思维标签的情况下对模型进行微调？这些模型只能在需要此行为的任务上进行微调吗？抱歉，这个幼稚的问题，但我是这种新型模型的新手。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/debonargon     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3yx5a/r_how_do_i_finetune_thinking_models/</guid>
      <pubDate>Wed, 05 Mar 2025 08:59:51 GMT</pubDate>
    </item>
    <item>
      <title>[d]使视觉语言模型指向图像中的对象，将新模式引入语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3xlre/d_making_vision_language_models_point_to_objects/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在尝试与Moondream和Molmo类似的东西。即使语言模型能够产生询问的对象的归一化坐标。 “要点：狗例如 我正在尝试使Smolvlm做到这一点，以作为一个有趣的项目，以获得更好的理解。我正在尝试使用Pixmo点数据集的子集（1MIL）。    尝试了纯sft，无论是完整的还是peft，显然是不起作用的，因为模型没有输出点的概念。      尝试了grpo，因为该模型显然没有这样的潜在功能，因为该模型没有这样的潜在能力。    从Moondream中汲取灵感，我完全引入了一种新的方式。即，对点进行了编码，与模型自回旋部分所接受的嵌入维度相同，然后在自动回归后，另一个解码器解码了点。保持其他零件冻结。我尝试了SFT的交叉熵，尽管它对它用于指向任务有些怀疑，而MSE损失似乎更合适。但这也失败了，尽管在训练过程中表现出很好的损失特征。该模型仅产生随机点。   有人尝试过类似的事情吗？关于我还能尝试什么建议？关于如何取得进展的任何指针都会很好，显然这是可行的。我缺少什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/smalltimecsguy     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j3xlre/d_making_vision_vision_vision_vision_models_models_point_point_objects/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3xlre/d_making_vision_language_models_point_to_objects/</guid>
      <pubDate>Wed, 05 Mar 2025 07:18:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM量化建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j3pyv1/d_llm_quantization_advice/</link>
      <description><![CDATA[在老实说，这是令人着迷和压倒性的混合。我得到了减少基础模型的规模，更快地推理，丢失精度，所有这些好东西，但我想了解更多。 如果您在对您有所帮助之前曾经经历过？任何更改游戏的论文，博客文章，存储库，代码教程或艰苦学习的课程？我想从“哦，我有点明白它”到真正知道我在做什么。 很想听听任何在这条路上有效的人，没有什么工作，没有什么，您希望您早些时候知道！ 欣赏它！    &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Professionfox8649     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j3pyv1/d_llm_quantization_advice/</guid>
      <pubDate>Wed, 05 Mar 2025 00:17:01 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们通过不垃圾邮件主题来促进自己的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1hc0o/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Mar 2025 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>