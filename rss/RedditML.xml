<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 14 Jan 2024 18:16:15 GMT</lastBuildDate>
    <item>
      <title>[P] 尝试让 ML 工程师的云基础设施尽可能简单。你怎么认为？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196lpy8/p_trying_to_make_cloud_infrastructure_as_simple/</link>
      <description><![CDATA[嘿伙计们！在过去的几个月里，我与几位机器学习工程师（主要是初创公司创始人）交谈，并意识到他们都不喜欢的一件事是设置和创建机器学习。管理后端或机器学习模型的云基础设施。虽然有像 Render 这样的服务，但出于某种原因，他们都选择使用 AWS / Azure / GCP 来硬核实现。不知道为什么，但无论如何，这些服务确实有很多开销，这使得它们变得乏味或困难，特别是对于第一次使用的人来说。 所以，我决定我想要构建一些东西，让它变得非常容易将您的 ML 服务部署到 AWS 等云提供商，无论是推理服务器、REST API 还是某些作业队列，以便 ML 工程师可以专注于其他更有趣的事情。 现在我已经构建了一个非常简单（可能没用，希望没有）第一个版本，www.eliseapp.com，它可以帮助您将 FastAPI 应用程序部署到 AWS 应用程序运行器（在您自己的帐户上）一键完成。我很想获得有关它的反馈，但更重要的是，您在尝试部署 ML 应用程序时遇到了哪些问题以及您期望在这样的平台上获得哪些服务！谢谢:)   由   提交 /u/johnyeocx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196lpy8/p_trying_to_make_cloud_infrastructure_as_simple/</guid>
      <pubDate>Sun, 14 Jan 2024 17:55:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 含有少量次要情感数据的不平衡数据问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196loki/d_question_of_imbalanced_data_containing_small/</link>
      <description><![CDATA[你好。我正在研究情感语音转换。 我收集了许多包含情感标签和一些辅助情感（道歉、沮丧等）的数据集。 我会使用所有这些来训练我的模型，但我想专注于 5 种主要情绪来评估和推断（愤怒、高兴、兴奋......），以推断出更多不同的韵律。 在这种情况下，我是想知道是否会因为少量的细微情绪而出现数据不平衡的问题。我想问一下你觉得怎么样，或者有什么论文或者见解吗？仅用主要情绪进行训练是否更好？   由   提交 /u/RedCuraceo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196loki/d_question_of_imbalanced_data_containing_small/</guid>
      <pubDate>Sun, 14 Jan 2024 17:53:42 GMT</pubDate>
    </item>
    <item>
      <title>损失被限制在我的 GCN 模型中 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196lkyw/loss_is_getting_clamped_in_my_gcn_model_p/</link>
      <description><![CDATA[我已经使用 pytorch 在具有相同边缘索引的图上训练了以下模型（任务是电子健康记录上的图分类，其中每个图代表患者数据和节点向量已从组合知识图导出） class mdl(torch.nn.Module): def init(self, input_size, hide_size, output_size,dropout_rate): super(GCNClassifier, self).init() self.conv1 = GCNConv(input_size,hidden_​​size) self.conv2 = GCNConv(hidden_​​size,output_size) self.dropout = torch.nn.Dropout(dropout_rate) defforward(self,x,edge_index): x = self.conv1(x, edge_index) x = F.relu(x) x = self.dropout(x) x = self.conv2(x, edge_index) x = torch.mean(x, dim=0, keepdim=True) return x  问题是损失被限制在特定值 ​ 我尝试了各种学习率值并尝试了各种技术，例如动量和学习率调度，但损失仍然保持不变 ​ 我尝试使用以下循环训练上述模型 ​ #training (graphVec) 800 个图（每个形状为 [5,20] 的图） #y_train 是形状 [800] 的 0 和 1 的张量,1] 用于二元分类 ​ num_epochs = 100 for epoch in range(num_epochs): model.train() for i in range(len( graphVec)): # 在每次迭代中将每个图传递给模型 output = model(graphVec[i], edge_index) loss = criteria(output, y_train[i]) loss.backward() optimizationr.step() optimizationr.zero_grad( ) # StepLR 调度器步骤 Scheduler.step() print(output) # 打印每个 epoch 的损失和学习率 current_lr = optimizer.param_groups[0][&#39;lr&#39;] print(f&#39;Epoch [{epoch + 1}/{num_epochs} ]，损失：{loss.item()}，学习率：{current_lr}&#39;)  但是我的损失严重受限（损失并没有随着时代的推移而减少）我该怎么办?   由   提交/u/Willing-Cell1790  /u/Willing-Cell1790 reddit.com/r/MachineLearning/comments/196lkyw/loss_is_getting_clamped_in_my_gcn_model_p/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196lkyw/loss_is_getting_clamped_in_my_gcn_model_p/</guid>
      <pubDate>Sun, 14 Jan 2024 17:49:31 GMT</pubDate>
    </item>
    <item>
      <title>[P]关于如何实施的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196les5/p_ideas_on_how_to_implement/</link>
      <description><![CDATA[我有一个问题：我已经在由“戴口罩”的人组成的数据集上创建并训练了一个 CNN。和“不戴口罩”。到目前为止一切顺利，现在的问题是我如何在新数据集“不正确的掩码使用”上使用我已经训练好的模型？并且只有这个数据集。我的准确率非常低，因为经过训练的模型识别了掩模。 PS：我不允许更改已经训练的模型，所以基本上我想将不正确的掩模使用数据集分类为或据我了解，没有面具   由   提交/u/NicoRobinFleur  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196les5/p_ideas_on_how_to_implement/</guid>
      <pubDate>Sun, 14 Jan 2024 17:42:06 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助评估我的人工智能模型 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196kv42/need_help_evaluating_my_ai_model_r/</link>
      <description><![CDATA[您好，我花了一年多的时间来实现和训练一个模型，我想尝试将该模型的准确性与人类预测进行比较。理想情况下，我正在寻找能够帮助给出“预测”的人。对于设定的场景，然后我将其与模型的输出进行比较。如果您有兴趣，请私信我或发表评论，我会与您联系以提供更多信息。如果您愿意帮忙，我将向您提供该软件的免费版本。谢谢   由   提交 /u/Sprixl   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196kv42/need_help_evaluating_my_ai_model_r/</guid>
      <pubDate>Sun, 14 Jan 2024 17:18:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当我们生成超出 LLM 训练上下文长度的标记时会发生什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196fnf3/d_what_happens_when_we_generate_tokens_beyond_the/</link>
      <description><![CDATA[举例来说，LLM 接受了 2048 个标记的训练，而我们生成的文本超过 2048 个标记。问题是什么？为什么？   由   提交/u/kekkimo  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196fnf3/d_what_happens_when_we_generate_tokens_beyond_the/</guid>
      <pubDate>Sun, 14 Jan 2024 13:15:36 GMT</pubDate>
    </item>
    <item>
      <title>我仅使用智能手机就通过“活动识别”控制了超级马里奥！ [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196f4z9/i_controlled_super_mario_with_activity/</link>
      <description><![CDATA[最近，我参与了一个涉及活动识别的项目，这是根据从传感器收集的数据来识别和理解人类活动的过程&lt; /强&gt;。我唯一拥有的就是一部旧智能手机，因为我没有钱投资额外的传感器。 我的最终目标是使用我在现实世界中的动作来控制游戏中的超级马里奥。经过一些研究后，我发现大多数智能手机都配备了加速度传感器，我可以利用它来训练用于活动识别的机器学习模型。幸运的是，我的旧智能手机有一个。然后，我开发了一个应用程序，能够将实时传感器数据从我的智能手机无线传输到我的笔记本电脑（我将此应用程序命名为“SensorFlow”）。 使用这些数据，我构建并训练了一个机器学习模型它可以准确地检测我的行为，准确率高达 95%。最后，我将这个模型与《超级马里奥》集成，使用 python 根据我的真实动作以编程方式敲击箭头键。我最终得到了一个只需用我的身体就可以玩超级马里奥的系统！虽然不是 100% 但效果已经足够好了。欢迎提出更多建议。 我已经开源了所有与活动识别相关的代码以及我在此过程中开发的 Android 应用程序。 有关此项目的更多信息，您可以看看我的 YouTube。这是一种自我推销，但其中包含有关该项目的附加信息。您可以在下面看到最终结果👇 https://www.youtube.com/watch?v =IpLV6uKAO98   由   提交 /u/Pritish-Mishra    reddit.com/r/MachineLearning/comments/196f4z9/i_control_super_mario_with_activity/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196f4z9/i_controlled_super_mario_with_activity/</guid>
      <pubDate>Sun, 14 Jan 2024 12:46:53 GMT</pubDate>
    </item>
    <item>
      <title>【研究】RepoPilot：可理解并生成存储库级别代码的多代理编码助手</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196ecrb/research_repopilot_multiagent_coding_assistant/</link>
      <description><![CDATA[我们发布了RepoPilot，这是一个可以理解整个代码存储库并与之交互的多代理系统。 RepoPilot 是一个一站式 Python 库，它彻底改变了开发人员与其代码库交互和理解其代码库的方式。 RepoPilot 利用先进的大型语言模型 (LLM)，充当多代理系统，为全面的代码库探索和影响分析提供下一代编码助手。 RepoPilot 专为寻求更深入了解项目的开发人员而设计，它简化了复杂的代码分析任务，使其成为现代软件开发不可或缺的工具。 与其他编码助手（例如 Github Copilot、Tabnine 等）或RepoPilot 旨在掌握整个代码库的完整上下文，从而实现更全面的分析和更准确的建议。 更多信息可以在此处找到：https://github.com/FSoft-AI4Code/RepoPilot   由   提交/u/FSoft_AIC   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196ecrb/research_repopilot_multiagent_coding_assistant/</guid>
      <pubDate>Sun, 14 Jan 2024 12:00:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我是一个奇怪的数据集：语言模型的元语言测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1969epa/r_i_am_a_strange_dataset_metalinguistic_tests_for/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.05300 代码和数据集：https://github.com/TristanThrush/i-am-a-strange-dataset 摘要：  涉及元语言自指的陈述（“本文有六个部分。”）在许多领域都很普遍。大型语言模型（LLM）可以处理这种语言吗？在本文中，我们提出了“我是一个奇怪的数据集”，这是一个解决这个问题的新数据集。有两个子任务：生成和验证。在生成过程中，模型会继续诸如“这句话中的倒数第二个词是”之类的语句。 （其中正确的延续是“is”）。在验证中，模型判断诸如“这句话中的倒数第二个词是句子”之类的陈述的真实性。 （错误的）。我们还提供了最小差异的元语言非自引用示例，通过探索模型是否可以处理元语言语言来补充主数据集。该数据集由专家手工制作，并由非专家注释者验证。我们通过 API 测试各种开源 LLM（7B 至 70B 参数）以及闭源 LLM。尽管我们发现模型规模有了一些稳定的改进，但所有模型在两个子任务上，甚至在非自指元语言控制数据上的表现都接近机会。 GPT 4 是唯一一个始终显着优于随机性的模型，但它仍然只在 60% 的范围内，而我们未经训练的人类注释者的得分在 89-93% 的范围内。数据集和评估工具包可在 此 https URL 获取。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1969epa/r_i_am_a_strange_dataset_metalinguistic_tests_for/</guid>
      <pubDate>Sun, 14 Jan 2024 06:28:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] REBUS：理解符号的稳健评估基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1969dl0/r_rebus_a_robust_evaluation_benchmark_of/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.05604 代码：https://github .com/cvndsh/rebus 数据集：https:// Huggingface.co/datasets/cavendishlabs/rebus 项目页面：https:// /cavendishlabs.org/rebus/ 摘要：  我们提出了一个新的基准来评估多模态大语言模型的性能画画谜题。该数据集涵盖 333 个基于图像的文字游戏的原始示例，涵盖电影、作曲家、主要城市和食物等 13 个类别。为了在识别线索单词或短语的基准上取得良好的性能，模型必须将图像识别和字符串操作与假设检验、多步骤推理和对人类认知的理解结合起来，从而对能力进行复杂的多模式评估。我们发现 GPT-4V 和 Gemini Pro 等专有模型的性能明显优于所有其他测试模型。然而，即使是最好的模型，最终准确率也仅为 24%，这凸显了推理方面需要大幅改进的必要性。此外，模型很少理解谜题的所有部分，并且几乎总是无法追溯解释正确的答案。因此，我们的基准可以用来识别多模态大语言模型的知识和推理方面的主要缺陷。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1969dl0/r_rebus_a_robust_evaluation_benchmark_of/</guid>
      <pubDate>Sun, 14 Jan 2024 06:26:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我厌倦了用我的背景来提示人工智能，所以我构建了一个应用程序，通过记录我的对话并将其构建为记忆来回答我的问题，同时了解我的一切</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1966vsg/p_i_was_tired_of_prompting_ais_with_the_context/</link>
      <description><![CDATA[   嘿 r/MachineLearning！ 我厌倦了在 chatGPT 和其他人工智能中编写关于我是谁的长提示。我一直希望拥有一个能够根据我的记忆进行训练并具有我的生活背景的人工智能 我意识到，如果我需要我的人工智能了解有关我的事情，就需要“原生”人工智能。我一直随身携带的设备（我的手机）的功能：录音和存储上下文。 因此我构建了自己的应用程序： 60 秒演示：https://youtu.be/MXZYaQlYm1Q 我创建了一个非常简单的 iOS 应用程序，名为 Sama AI，它会听我说的话，然后做出它向我发送主动的相关反馈。例如，今天我和我的朋友谈论移动应用程序和 reddit，这是我在对话过程中收到的通知： https://preview.redd.it/u7evh9fmvbcc1.jpg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=a4146a03cf2 9f5159940d4da7195f992703b1床 其他非常相关的反馈示例包括：  “嘿，我注意到你说得太多了，我们做一些工作怎么样？” &lt; li&gt;“看来你又在拖延了，在youtube上看一些无关紧要的东西，我们暂停一下，呼吸一下新鲜空气” “昨天你提到你今天想完成{X} 。我们就这样开始新的一天吧？” “你进展得怎么样？看来你没有实现你的目标。我们明天尝试进行一些销售工作怎么样？”  我通过“导师/教练”给了它许多具体的提示。性格。另外，我还让这个应用程序“自我教育”。根据我所说的了解我。我使用该应用程序的次数越多，它就越有用=&gt;经过几天的使用，一些反馈非常好 - 我一直在不停地使用它。 我把这个应用程序放入应用商店，我很想听听您构建类似事物的经验！并且非常感谢对我的应用程序的任何反馈以及如何改进它。感谢您提供的任何见解！   由   提交/u/kodjima33  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1966vsg/p_i_was_tired_of_prompting_ais_with_the_context/</guid>
      <pubDate>Sun, 14 Jan 2024 04:03:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 本科生论文容易批评</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19655al/d_easy_to_criticize_papers_for_undergrads/</link>
      <description><![CDATA[我正在教授研究课程简介。我想教学生如何通过一些例子来批判性地审查一篇论文（考虑实验设计、结果等）。你们知道有哪些易于阅读但存在明显缺陷/缺点的机器学习论文吗？   由   提交 /u/Salty-D​​are-4821   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19655al/d_easy_to_criticize_papers_for_undergrads/</guid>
      <pubDate>Sun, 14 Jan 2024 02:31:21 GMT</pubDate>
    </item>
    <item>
      <title>[P] 向 XalosXandrez 提出请求</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19628r2/p_request_to_xalosxandrez/</link>
      <description><![CDATA[嗨u/XalosXandrez 我会我想引用您 7 年前在 Reddit 子版块的一篇论文中所说的话演示文稿。 我没有足够的业力与您开始聊天。你能告诉我吗？ 编辑：人们能给我我需要的最低业力吗？我是一个相当好的人;-)   由   提交 /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19628r2/p_request_to_xalosxandrez/</guid>
      <pubDate>Sun, 14 Jan 2024 00:09:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] Google DeepMind 诊断法学硕士超过人类医生前 10 名的准确率（59% vs 34%）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/195q6lu/r_google_deepmind_diagnostic_llm_exceeds_human/</link>
      <description><![CDATA[Google 和 DeepMind 的研究人员开发并评估了专门针对临床诊断推理进行微调的法学硕士。在一项新研究中，他们严格测试了法学硕士进行鉴别诊断和帮助医生的能力。 他们根据《新英格兰医学杂志》的 302 个真实案例报告对法学硕士进行了评估。众所周知，这些病例报告是高度复杂的诊断挑战。 法学硕士制作了鉴别诊断列表，其中包括 302 例病例中 177 例前 10 种可能性中的最终确诊诊断，前 10 种准确度为 59 %。 这明显超过了经验丰富的医生的表现，在没有协助的情况下，经验丰富的医生在相同病例中的前 10 名准确率仅为 34%。 根据高级专家的评估，法学硕士的在对所有 302 份病例报告进行评估时，鉴别诊断也被认为比医生做出的诊断更加适当和全面。 这项研究表明，法学硕士有潜力提高医生水平&#39;复杂案件的临床推理能力。然而，作者强调，在临床部署之前，进一步严格的现实世界测试至关重要。还必须解决有关模型安全性、公平性和稳健性的问题。 完整摘要。 论文。    ;由   提交 /u/Successful-Western27    reddit.com/r/MachineLearning/comments/195q6lu/r_google_deepmind_diagnostic_llm_exceeds_ human/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/195q6lu/r_google_deepmind_diagnostic_llm_exceeds_human/</guid>
      <pubDate>Sat, 13 Jan 2024 15:16:47 GMT</pubDate>
    </item>
    </channel>
</rss>