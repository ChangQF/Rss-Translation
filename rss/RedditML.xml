<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 26 Jan 2024 03:15:18 GMT</lastBuildDate>
    <item>
      <title>[P] Qdrant向量数据库的K8S运算符</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fny36/p_k8s_operator_for_qdrant_vector_database/</link>
      <description><![CDATA[      亲爱的 Qdrant 数据库用户， 不久前，我有有机会使用这个美妙的矢量数据库！不幸的是，K8S中唯一可用的安装方法是Helm图表，并且它有其局限性。为了解决这种悲惨的情况，我开发了一个 Kubernetes Operator 来管理 Qdrant 集群和集合 - https://github.com/ganochenkodg/qdrant -operator。 主要功能：  创建和扩展 Qdrant 集群，具有灵活的 pod 调度配置。 支持自定义以及操作员生成的 API 密钥和证书。 管理集合，能够配置存储在 S3 中的即时和计划备份。  我希望得到反馈，并且，当然，GitHub 上的星星！ ​ https://i .redd.it/prgvfbxxeoec1.gif   由   提交 /u/Dmitriy_Ganochenko   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fny36/p_k8s_operator_for_qdrant_vector_database/</guid>
      <pubDate>Fri, 26 Jan 2024 00:08:22 GMT</pubDate>
    </item>
    <item>
      <title>骨科医生的编码之旅：启动骨折查找器.app - 人工智能驱动的髋部骨折诊断 [R] [N] [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fn0rv/orthopedic_surgeons_journey_into_coding_launching/</link>
      <description><![CDATA[作为一名对技术充满热情的骨科医生，我在我最伟大的导师 ChatGPT 的宝贵指导下踏上了自学编码之旅。我开发了fracturefinder.app，这是一个利用 CNN 模型通过 X 射线图像检测髋部骨折的平台。我很高兴与您分享这一点。试试看！您可以在那里上传右髋部或左髋部 X 光片，看看诊断结果是什么。您的意见对我很重要；我很想听听您的想法。   由   提交 /u/ControlNo8273   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fn0rv/orthopedic_surgeons_journey_into_coding_launching/</guid>
      <pubDate>Thu, 25 Jan 2024 23:26:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 学习 Hopfield Networks 的最佳资源是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19flrpn/d_whats_the_best_resource_to_learn_hopfield/</link>
      <description><![CDATA[学习离散 Hopfield 网络理论、学习良好的实现以及了解现代 Hopfield 网络（密集联想记忆）的最佳来源是什么？尽管论文介绍了具体的形式和算法。因此，我会寻找有关理论的书籍章节，而即使是博客文章也适合实现   由   提交/u/reverendCappuccino   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19flrpn/d_whats_the_best_resource_to_learn_hopfield/</guid>
      <pubDate>Thu, 25 Jan 2024 22:31:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 代理和行动</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fljyp/r_agents_and_actions/</link>
      <description><![CDATA[由于我是生成式人工智能和 LLMS 的初学者，我还不知道代理能够做什么，是否有任何类型的代理可以能够控制操作系统，例如完成给定的任务，而不仅仅是像 LLM 那样返回键入的答案。   由   提交 /u/Spiritual_Guide6862   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fljyp/r_agents_and_actions/</guid>
      <pubDate>Thu, 25 Jan 2024 22:22:10 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士作为通用模式机 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fhe8f/llms_as_general_pattern_machines_r/</link>
      <description><![CDATA[        由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fhe8f/llms_as_general_pattern_machines_r/</guid>
      <pubDate>Thu, 25 Jan 2024 19:21:58 GMT</pubDate>
    </item>
    <item>
      <title>[D]我们如何保持如此幸运？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fhdck/d_how_do_we_keep_getting_so_lucky/</link>
      <description><![CDATA[ML 很难——这是一个非常难的领域，而 DeepMind/OpenAI/insert 公司的研究人员都是天才。甚至他们也很难理解定义机器学习的模型是如何工作的。 这让我想知道......“我们如何保持如此幸运？”双血统、grokking、法学硕士的出现——做出这些发现的人绝对是聪明的，但它们的存在这一事实让人感觉非常幸运。就好像癌症研究人员突然发现所有癌症都有这种特定标记并且这种标记可以很容易地用一些标准药物来瞄准并且它可以在一段时间内完全治愈所有癌症几年。 即使是变形金刚，这是一种非常聪明的使用注意力的方式，也真的非常非常好，我什至不认为写“注意力就是你所需要的一切”的人是这样的。论文可以想象它们对机器学习产生的巨大影响。 我不知道我是否过于怀疑，但所有这一切似乎好得令人难以置信。我们已经取得了如此多的发现，但除了“像这样的矩阵相乘很酷”之外，我们对其中的许多发现几乎没有任何解释。到底是怎么回事？我是误解了还是描述了真实的东西？   由   提交/u/Bchalup2348   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fhdck/d_how_do_we_keep_getting_so_lucky/</guid>
      <pubDate>Thu, 25 Jan 2024 19:20:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] 漫画（Bande Dessinée、漫画、网络漫画等）自动翻译，具有语音气泡检测、文本分割、OCR 和修复功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fge55/p_automatic_translation_of_comics_bande_dessinée/</link>
      <description><![CDATA[      我想分享我一段时间以来所做的工作。一个 python 桌面应用程序，用于自动翻译多种格式（图像、Pdf、Epub 和漫画书档案）和多种语言的漫画。它使用我训练的 2 个 yolov8 模型来进行检测和分割，一套根据语言进行 OCR 的模型，以及一个用于修复的微调喇嘛检查点。  repo - https://github.com/ogkalu2/comic-translate GUI https:/ /preview.redd.it/1gq7j7r8smec1.png?width=576&amp;format=png&amp;auto=webp&amp;s=29790a1c2768ee274ade20945ba0ee9edfe0ba5a ​ &amp;# x200b;   由   提交/u/MysteryInc152   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fge55/p_automatic_translation_of_comics_bande_dessinée/</guid>
      <pubDate>Thu, 25 Jan 2024 18:39:42 GMT</pubDate>
    </item>
    <item>
      <title>[研究]WhisperFusion：与人工智能聊天机器人的超低延迟对话</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fchit/research_whisperfusion_ultralow_latency/</link>
      <description><![CDATA[通过使用完全开源的工具 WhisperLive &amp; 创建实时 AI 聊天机器人通信系统。 WhisperSpeech，Collabora 的工程师解决了当前机器人交互中的不自然延迟问题，以实现无缝对话。 https://www.collabora.com/news-and-blog/news-and-events/whisperfusion-ultra-low- Latency-conversations-with-an-ai-chatbot.html   由   提交 /u/mfilion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fchit/research_whisperfusion_ultralow_latency/</guid>
      <pubDate>Thu, 25 Jan 2024 15:54:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练 LSTM 模型的正确方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19fajpe/d_proper_way_to_train_an_lstm_model/</link>
      <description><![CDATA[我还没有找到训练 LSTM 的正确方法以及原因的解释。因此我问这个问题。 假设我们有股票价格等连续数据。 LSTM可以将前N天的价格作为输入，然后输出一个向量。将此向量输入一个简单的神经网络将为我们提供第 (N+1) 天的价格估计。 训练后，在使用模型进行推理时，我们将预测更多比一天向前。为了训练模型，我们可以获取前 2 天的股票价格并预测第 3 天。然后使用前3天的实际数据来预测第4天（因此第3天的预测在这里不起作用）。等等。然后我们测量所有预测与实际数据之间的距离，并将这种损失最小化。但是，如果我这样做，那么我本质上是要求模型擅长预测仅未来一天。这看起来不太理想。 我可以改变训练方法：我可以使用前10天来预测第10-20天，计算损失，然后使用前20天的实际数据（不是预测）来预测第20-40天。但这些听起来都太随意，不系统。对此有一些一般性建议吗？   由   提交 /u/speedy-spade   /u/speedy-spade  reddit.com/r/MachineLearning/comments/19fajpe/d_proper_way_to_train_an_lstm_model/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19fajpe/d_proper_way_to_train_an_lstm_model/</guid>
      <pubDate>Thu, 25 Jan 2024 14:27:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您经常遇到哪些令人尴尬的并行工作负载（没有节点间通信）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19faakw/d_what_embarrassingly_parallel_workloads_do_you/</link>
      <description><![CDATA[目前，几周后就会发布一个开源工具，该工具使大规模并行计算变得极其容易。  当我发布它时，我想要一些有用的教程。我想知道您认为我应该为哪些令人尴尬的并行用例创建教程？如果您可以在不需要任何配置的情况下运行 25k 个并行工作线程，您将运行哪些作业？    由   提交/u/Ok_Post_149   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19faakw/d_what_embarrassingly_parallel_workloads_do_you/</guid>
      <pubDate>Thu, 25 Jan 2024 14:15:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用全同态加密 (FHE) 在加密数据上训练 ML 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19f5z25/p_training_ml_models_on_encrypted_data_with_fully/</link>
      <description><![CDATA[大家好！  我们已经使用 FHE 成功地训练了加密数据的机器学习模型，确保了整个训练过程中最高级别的隐私。  这是解锁数据隐私至关重要的医疗保健和金融等领域的安全协作培训和模型微调等用例的关键一步。  为了让您了解预期的性能，我们可以在大约一个小时内训练一个具有 10 个特征和 10,000 行的模型。更重要的是，训练时间与特征和示例的数量呈线性关系。  您还可以在这里查看我们的库，因为我们所做的一切都是开源的：https: //github.com/zama-ai/concrete-ml 很高兴听到您对此的想法和想法！   由   提交 /u/strojax   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19f5z25/p_training_ml_models_on_encrypted_data_with_fully/</guid>
      <pubDate>Thu, 25 Jan 2024 10:02:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] Scikit-Learn 修复了 F-1 分数计算器；你应该现在更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19f0o8f/d_scikitlearn_fixed_its_f1_score_calculator_you/</link>
      <description><![CDATA[Scikit-Learn 1.3.x 的 F-1 分数计算器有一个错误，该错误已在最新版本（上周发布的 1.4.0）中修复），当 zero_division 参数设置为 0.0 或 np.nan 时，可能会产生错误的分数，例如：  &lt;代码&gt;&gt;&gt; sklearn.__version__&#39;1.3.2&#39;&gt;&gt;&gt;&gt; sklearn.metrics.f1_score(y_true=[0, 0, 1, 2, 3], y_pred=[0, 1, 0, 2, 3], Zero_division=1.0,average=“宏”) 0.875 # 错误  与。 （完全相同的输入） &gt;&gt;&gt; sklearn.__version__&#39;1.4.0&#39;&gt;&gt;&gt;&gt; sklearn.metrics.f1_score(y_true=[0, 0, 1, 2, 3], y_pred=[0, 1, 0, 2, 3], Zero_division=1.0,average=“宏”) 0.625 # 正确  这里是我的博客文章解释了该错误更多详细信息，以及修复该错误的拉取请求。如果您使用 Scikit-Learn 计算 F-1，您应该升级并仔细检查之前计算的 F-1 分数；考虑到真正的 F-1，看起来更好的分类器很容易比替代品差得多。   由   提交/u/Revolutionary-Ad-65   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19f0o8f/d_scikitlearn_fixed_its_f1_score_calculator_you/</guid>
      <pubDate>Thu, 25 Jan 2024 04:15:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 注意力之谜：哪个是哪个 - q、k 或 v？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ewfm9/d_attention_mystery_which_is_which_q_k_or_v/</link>
      <description><![CDATA[我终于开始了解注意力机制了，但有一点仍然让我困惑：q、k 和 v 背后的矩阵魔法。&lt; /p&gt; 我在理论层面上了解了整个矩阵乘法，但是什么数学属性实际上决定了哪个矩阵成为查询（q），即键 (k) 和值 (v)？这只是一些随机分配，还是有更深层次的逻辑在起作用？  这是我到目前为止收集到的内容：  所有三个矩阵都来自相同的输入数据，但神奇地呈现出不同的“个性”。在注意方程 (qkt)v 中。 我猜测它们的维度和相互作用一定发挥了作用，但除此之外，它是模糊的。  机制框图对于图片 https://upload.wikimedia .org/wikipedia/commons/thumb/8/81/Attention-qkv.png/799px-Attention-qkv.png   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ewfm9/d_attention_mystery_which_is_which_q_k_or_v/</guid>
      <pubDate>Thu, 25 Jan 2024 00:44:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 视觉变压器比新生视觉系统更需要数据吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19er4pp/r_are_vision_transformers_more_data_hungry_than/</link>
      <description><![CDATA[ 由   提交 /u/currentscurrents   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19er4pp/r_are_vision_transformers_more_data_hungry_than/</guid>
      <pubDate>Wed, 24 Jan 2024 20:59:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>