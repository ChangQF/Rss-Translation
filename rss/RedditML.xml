<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Mon, 24 Jun 2024 01:05:12 GMT</lastBuildDate>
    <item>
      <title>[R] [IEEE VR 2024] Listen2Scene：用于 3D 场景的交互式材料感知双耳声音传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmzfo5/r_ieee_vr_2024_listen2scene_interactive/</link>
      <description><![CDATA[  由    /u/Snoo63916  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmzfo5/r_ieee_vr_2024_listen2scene_interactive/</guid>
      <pubDate>Sun, 23 Jun 2024 23:32:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] [CVPR 2024] AV-RIR：视听室脉冲响应估计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmzdeb/r_cvpr_2024_avrir_audiovisual_room_impulse/</link>
      <description><![CDATA[    /u/Snoo63916   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmzdeb/r_cvpr_2024_avrir_audiovisual_room_impulse/</guid>
      <pubDate>Sun, 23 Jun 2024 23:29:22 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 利用分层内在维度进行实际对抗训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmy93n/research_exploiting_the_layered_intrinsic/</link>
      <description><![CDATA[      分享我们最近的工作以供讨论： 论文：https://arxiv.org/pdf/2405.17130 视频：https://youtu.be/vL4pn6AnDwI 我们从数据流形的角度研究了鲁棒性、泛化和对抗性训练之间的关系。我们利用流形猜想，指出非流形 AE 可带来更好的鲁棒性，而流形上 AE 可带来更好的泛化。 我们提出了 SMAAT，这是一种利用流形猜想的新 AT 算法，旨在通过扰动具有最低内在维度的中间深度网络层来生成更高比例的非流形 AE。  https://preview.redd.it/1jgw9ag1fe8d1.png?width=1545&amp;format=png&amp;auto=webp&amp;s=dc8650804d7e14d623675667d0a76b6831e159f5    提交人    /u/hassaan84s   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmy93n/research_exploiting_the_layered_intrinsic/</guid>
      <pubDate>Sun, 23 Jun 2024 22:35:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习专利</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmvu8t/d_patenting_in_ml/</link>
      <description><![CDATA[对于那些在学术界或行业中研究机器学习理论或应用前沿的人来说，你们在发布或营销产品之前申请专利的频率是多少？我知道谷歌和其他公司已经申请了一些看起来像算法的东西，但这些专利是作为应用程序或计算机系统写入专利的。当你打破 SOTA 进步时，这种情况有多普遍？ 我看到其他一些帖子表明软件专利并不是那么可执行：[D] 谷歌可以起诉 OpenAI 在其产品中使用 Transformer 吗？ ： 而其他评论则认为专利在行业中比论文更重要：https://www.reddit.com/r/MachineLearning/comments/mf24jr/comment/gsl3pux/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button 无论如何，我很好奇人们的经历是什么样的。    由    /u/SometimesObsessed  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmvu8t/d_patenting_in_ml/</guid>
      <pubDate>Sun, 23 Jun 2024 20:46:45 GMT</pubDate>
    </item>
    <item>
      <title>虚拟朋友的最佳文本转语音功能 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmv256/best_text_to_speech_for_virtual_friend_discussion/</link>
      <description><![CDATA[嗨，我正在为孩子们制作一个 Unity 虚拟朋友，它将是一只小猫，我不知道要使用哪种文本转语音。我尝试了 Google 文本转语音，是否可以使用代码修改声音以使其听起来更适合小猫，或者使用其他文本转语音？Elevenlabs 对我来说似乎很贵。    提交人    /u/NoPrinciple1242   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmv256/best_text_to_speech_for_virtual_friend_discussion/</guid>
      <pubDate>Sun, 23 Jun 2024 20:11:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 权重调整：训练期间应用初始化策略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmpp29/r_weight_rescaling_applying_initialization/</link>
      <description><![CDATA[  由    /u/rasten41  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmpp29/r_weight_rescaling_applying_initialization/</guid>
      <pubDate>Sun, 23 Jun 2024 16:13:26 GMT</pubDate>
    </item>
    <item>
      <title>[P] llama.ttf：一种也是 LLM 的字体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmkqrv/p_llamattf_a_font_which_is_also_an_llm/</link>
      <description><![CDATA[  由    /u/pred  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmkqrv/p_llamattf_a_font_which_is_also_an_llm/</guid>
      <pubDate>Sun, 23 Jun 2024 12:10:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士 (LLM) 中的思维空间？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmhuhi/d_thought_space_in_llms/</link>
      <description><![CDATA[我是 AI 概念方面的业余爱好者。我很好奇，想知道以下实现的障碍是什么，以及已经尝试了多少。 图像生成模型使用迭代降噪方法来生成图像。 我们能否创建文本的思维空间表示，并使用类似的技术从随机噪声中结晶思想？ 我们可以创建一个长嵌入模型，将段落甚至文档转换为长向量，或者可能是可变长度向量。这可能是思维空间表示。 将 LLM（整个互联网）训练集的所有输入输出对转换为思维空间后，我们可以向输出添加各种级别的噪声，并训练模型以接受输入思想并迭代地将随机噪声结晶为精致的、噪声较小的输出思想。通过这种方式，我们可以分配额外的推理计算来为更困难的问题具体化更复杂的想法。  最后一步是将具体化的想法转换成文本、图像、声音等。 对于文本，可以通过将嵌入反转为具有与输入嵌入相似的嵌入值的合理文本来完成。 由于反转尚未完善，也许现有的 LLM 可以采用近似文本和问题来推断更连贯的输出文本。  对于其他模态，我相信更有经验的研究人员可以提出解决方案。  我知道这完全是猜测，在如何和什么方面存在差距，但我对经验丰富的研究人员的答案很感兴趣，以便更好地理解当今的障碍。  谢谢    提交人    /u/ikoukas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmhuhi/d_thought_space_in_llms/</guid>
      <pubDate>Sun, 23 Jun 2024 08:49:01 GMT</pubDate>
    </item>
    <item>
      <title>Cuda高级学习资料，[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmf24l/cuda_advanced_learning_materials_d/</link>
      <description><![CDATA[我正在寻找初学者以上的 cuda 高级学习材料，我已经完成了 nvidia 的课程，名为“c++ 中的 cuda 简介”，但感觉这还不足以让我获得高级技巧和模式。推荐任何书籍或任何学习材料。对我很有帮助，谢谢     提交人    /u/M-notgivingup   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmf24l/cuda_advanced_learning_materials_d/</guid>
      <pubDate>Sun, 23 Jun 2024 05:34:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你们中有多少人在周末“工作”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmeawb/d_how_many_of_you_work_on_weekends/</link>
      <description><![CDATA[我知道我们大部分工作的性质是耗时的；有时一个实验可能需要几天甚至几周的时间。我的团队，包括我自己，通常也会在周末工作。我们必须仔细检查以确保实验正常运行，如果没有，则重新启动实验或进行更改。有时我们只是进行新的实验。似乎周末是如此宝贵的时间，可能会被浪费掉。 我的许多不在该领域的朋友都批评了这种说法，说我们在为一家不关心我们的公司辛苦工作。问题是，我和我的同事觉得我们是在为自己做这件事。 我很好奇这里还有多少人有同样的感受或经历？    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmeawb/d_how_many_of_you_work_on_weekends/</guid>
      <pubDate>Sun, 23 Jun 2024 04:45:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为拥有敏感数据的客户提供模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmdkil/d_serving_a_model_for_clients_with_sensitive_data/</link>
      <description><![CDATA[我确信这种情况会发生，所以我想问一下子可以使用哪些工具 / 平台来促进这种情况。 这个想法是，假设你不想把你的模型交给客户，他们也不想给你他们的数据，但你希望能够与他们达成协议，在你的模型上处理他们的数据。 这从根本上来说是一个信任问题。有没有第三方平台可以缓解这种情况？你可以在哪里上传你的模型，他们可以向它发送数据进行推理 / 接收结果，但可以保证你不会秘密保存他们的数据？    提交人    /u/Deto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmdkil/d_serving_a_model_for_clients_with_sensitive_data/</guid>
      <pubDate>Sun, 23 Jun 2024 04:01:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习中尚未解决的有趣问题有哪些？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmak2a/d_what_are_open_unsolved_interesting_problems_in/</link>
      <description><![CDATA[我很好奇机器学习的下一个重大飞跃是什么。有哪些障碍如果解决了，机器学习会变得更加有用？或者这个问题可以换一种说法。在哪些问题上，机器学习方法尚未应用，而它可能变得有用。    提交人    /u/marshallggggg   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmak2a/d_what_are_open_unsolved_interesting_problems_in/</guid>
      <pubDate>Sun, 23 Jun 2024 01:10:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么开发这些 RAG 应用程序感觉像炼金术一样？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dmabuy/d_why_does_developing_these_rag_applications_feel/</link>
      <description><![CDATA[^ 基本上就是标题。有没有一个原则性的方法可以做到这一点？就像 Weights &amp; Biases 一样，你至少可以监控正在发生的事情。    提交人    /u/latentnumber   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dmabuy/d_why_does_developing_these_rag_applications_feel/</guid>
      <pubDate>Sun, 23 Jun 2024 00:58:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 学术 ML 实验室：有多少个 GPU？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dlsogx/d_academic_ml_labs_how_many_gpus/</link>
      <description><![CDATA[在阅读最新帖子后，我想知道其他实验室在这方面做得如何。 在我攻读博士学位（前 5 名计划）期间，计算是一个主要瓶颈（如果我们有更多高容量 GPU，时间可能会大大缩短）。我们目前没有 H100。 您的实验室有多少个 GPU？您是否通过硬件补助从 Amazon/NVIDIA 获得额外的计算积分？ 谢谢    提交人    /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dlsogx/d_academic_ml_labs_how_many_gpus/</guid>
      <pubDate>Sat, 22 Jun 2024 10:29:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>