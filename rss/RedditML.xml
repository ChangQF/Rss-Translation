<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 17 May 2024 18:18:57 GMT</lastBuildDate>
    <item>
      <title>[D] 机器学习工程师，您工作的哪一部分侧重于部署管道与模型构建/调整？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cub74b/d_machine_learning_engineers_what_portion_of_your/</link>
      <description><![CDATA[我目前是一名机器学习工程师，但我更加关注管道，这与我担任数据工程师时类似。我很想更多地了解模型构建方面的知识，但自从我完成硕士学位以来，我的模型知识已经有点生疏了。  与模型构建相比，您日常工作的哪一部分侧重于部署？   由   提交/u/RawCS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cub74b/d_machine_learning_engineers_what_portion_of_your/</guid>
      <pubDate>Fri, 17 May 2024 17:32:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 就方法论监督寻求建议：纠正错误并寻求清晰度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cu8qib/r_seeking_advice_on_a_methodological_oversight/</link>
      <description><![CDATA[大家好， 我正在分享最近作为一名博士生的经历，并寻求有关解释我们研究中方法论监督的建议. 经过反思我们最近提交的一篇论文（我已经提交了相机就绪版本），我意识到我们犯了一个方法论错误。具体来说，我们使用了从测试集派生的验证集，这可能会在我们的结果中引入偏差，因为我们拥有异构数据集（训练和测试数据集来自不同的来源）。我们监控了验证集的准确性并将其用于早期停止。但正确的方法是从训练集中制作验证集，对吗？我很困惑，因为我读到在某些情况下，有些人出于相同的目的使用验证集和测试集。 令我惊讶的是，我的合著者和三位审稿人在同行评审期间都没有发现这个错误过程。我的合著者和审稿人发现错误的监督是否意味着可以淡化其严重性？ 此外，我们对五项测试进行了测量以平均我们的结果 - 但我不确定这是否有帮助减轻错误的影响。我们将非常感谢您对此事的意见。 我准备在演示过程中提及此错误以提高透明度，但我觉得有点愚蠢。 编辑：使用该验证集是否提前停止并没有改变我们的模型对未见数据的鲁棒性。那么...这个错误可以忽略不计吗？   由   提交 /u/TerminalFrauduleux   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cu8qib/r_seeking_advice_on_a_methodological_oversight/</guid>
      <pubDate>Fri, 17 May 2024 15:53:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 子空间嵌入与基本降维有何不同？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cu8is4/d_how_are_subspace_embeddings_different_from/</link>
      <description><![CDATA[我一直在努力理解更基本的降维技术与更高级的方法有何不同，主要是关于子空间、流形等的直觉是否相同。扩展到更基本的方法。我了解 PCA、t-SNE、UMAP 等如何工作（这些是在寻找维数降维时出现的 90% 的内容），但是当我阅读有关子空间聚类、流形学习或该领域的内容时，他们很少提及这些更基本的暗淡缩减技术，而是选择更高级的方法，我不确定为什么，特别是考虑到 PCA、t-SNE 和 UMAP 似乎是多么多产。 我不清楚像 PCA 这样的东西是否/如何不同于流形学习，特别是它们对于子空间聚类的有用性。我认为两者的目标都是找到一些潜在结构，直觉上在潜在空间中工作将减少噪音、无用/低信息特征，减少维数灾难，并且还可能更清楚地显示特征和标签的情况连接在潜在空间中。就实际算法而言，我理解直觉，但不知道它们是否是“真实的”。例如，在流形学习的情况下（FWIW，我真的不再看到任何相关论文，也不知道为什么会这样），一个常见的例子是“面流形”。对于图像来说，这是一个比原始输入尺寸低的平滑表面，并且从每个面平滑过渡到另一个面。对于图像来说，这可能有点微不足道，但是对于一般的时间序列数据，同样的直觉是否也适用？  例如，如果我有一个时间序列毛毛虫运动的数据集，我可以任意说存在毛毛虫尺寸的流形（较大的毛毛虫移动速度较慢）或毛毛虫能力的流形（例如，某种类型）能力/技能的多样性，如果毛毛虫正在完成任务/迷宫）？非常人为的例子，但基本上问题是，我是否一定能够根据我的先验告诉我应该存在/可能持有潜在结构（给定足够的数据）找到潜在空间？ &lt; p&gt;我知道 Yann LeCun 是在潜在空间中工作的大力支持者（尤其是联合嵌入，我不确定这是否适用于我和我的时间序列数据），所以我尝试更多地开展我的工作那个方向，但似乎基本 PCA 和基本非线性技术（例如，您会看到内置于 scipy 或 sklearn 等的技术）与其他论文中使用的技术之间存在很大分歧。 PCA（或基本非线性方法）等是否能实现相同的效果，但效果却不那么好？   由   提交 /u/Amun-Aion   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cu8is4/d_how_are_subspace_embeddings_different_from/</guid>
      <pubDate>Fri, 17 May 2024 15:44:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 PubLayLet 或 DocLayNet 上微调 DiT 的权重</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cu71km/d_weights_for_dit_finetuned_on_publaylet_or/</link>
      <description><![CDATA[    &lt; /a&gt;  大家好， 我正在寻找权重（最好是训练检查点） ）用于使用 DiT 构建的对象检测模型，该模型经过微调以识别文档布局。就像我附加的图片一样：  https://preview.redd.it/mculpv0l101d1.png?width=601&amp;format=png&amp;auto=webp&amp;s=2db28aa8fa05c1480418f46956fce731fbba3a1f 感谢任何可以提供帮助的人:)   由   提交 /u/ToeIntelligent4472   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cu71km/d_weights_for_dit_finetuned_on_publaylet_or/</guid>
      <pubDate>Fri, 17 May 2024 14:45:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 将帧中的对象替换为类似的对象</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cu0qgc/r_replace_the_object_in_the_frame_with_a_similar/</link>
      <description><![CDATA[你好，我正在为我的项目做研究，我需要你的帮助。 5 的桌子上有一个封闭的披萨盒。电影的第二部分，我想用 Pizza H*t、*ominos 等替换这个披萨盒。我的数据集中只有几个 Pizza H*t 盒子，因此人工智能模型需要使用类似的技术到“很少的镜头学习”。我以为我可以使用生成对抗网络 (GAN) 来做到这一点，但除了将马变成斑马之外，我无能为力。我对人工智能和软件开发有足够的了解，但对 GAN 还很陌生。 我应该使用哪种模型，我应该如何研究，我应该使用哪些关键字等等，我可以从哪里开始搜索正确的结果我需要你的帮助，谢谢。   由   提交 /u/GiantGulyabani   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cu0qgc/r_replace_the_object_in_the_frame_with_a_similar/</guid>
      <pubDate>Fri, 17 May 2024 09:07:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 FER-2013 数据集进行实时情绪分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctzd0a/p_real_time_emotion_classification_with_fer2013/</link>
      <description><![CDATA[所以我正在一家公司做实习项目，正如标题所说。我基本上需要将人脸分为 7 类 - 愤怒、厌恶目前，我正在努力在 FER 2013 数据集上获得良好的准确性，然后我将转向实时捕获部分 我需要在大约 2 周的时间内完成这个项目。我尝试过使用 mobile_net、VGG19、ResNet50、Inception、Efficient_net 等模型进行迁移学习，我的训练准确度已达到 87% 左右，但验证准确度相当低 ~56% （严重过度拟合，ik）。 这里的聪明人能否帮我提供一些关于如何更好地执行迁移学习的建议，是否应该使用数据增强（我有大约 28000 个训练图像），以及我应该使用视觉转换器等吗？ 使用 VGG19 和 Inception 时，由于某种原因，我的验证准确度停留在 24.71% 并且之后不会改变 ResNet50、mobile_net 和 Efficient_net 给出了上述指标 这是我一直用于迁移学习的示例笔记本 https://colab.research.google.com/drive/1DeJzEs7imQy4lItWA11bFB4mSdZ95YgN?usp=sharing 任何和所有感谢帮助！   由   提交 /u/Hades_Kerbex22   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctzd0a/p_real_time_emotion_classification_with_fer2013/</guid>
      <pubDate>Fri, 17 May 2024 07:25:22 GMT</pubDate>
    </item>
    <item>
      <title>从头计算出来的过去关键值与从模型获得的历史关键值不匹配 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctxd7c/mismatch_between_past_key_values_calculated_from/</link>
      <description><![CDATA[我正在尝试从头开始计算 llama-2 模型的过去关键值，并遵循所有步骤，包括标准化隐藏状态值和矩阵权重向量与隐藏状态相乘，最后应用 RoPE。即使完成所有这些操作后，过去的键值与从模型中获得的键值仍不匹配。有没有人有什么建议？代码如下： # 加载分词器和模型分词器 = LlamaTokenizer.from_pretrained(path_to_llama2) config = LlamaConfig.from_pretrained(path_to_llama2) config.output_hidden_​​states = True config.output_attentions = True config.use_cache =真实模型 = LlamaForCausalLM.from_pretrained(path_to_llama2, config=config) model.eval() input_text = &quot;很久很久以前&quot;输入 = tokenizer(input_text, return_tensors=&#39;pt&#39;) 输出 = model(**inputs) hide_states =outputs.hidden_​​states state_dict = model.state_dict() # 计算旋转嵌入的函数 def apply_rotary_pos_emb(q, k,rotary_pos_emb): cos, sin =rotation_pos_emb q_rot = q * cos +rotate_half(q) * sin k_rot = k * cos +rotate_half(k) * sin return q_rot, k_rot defrotate_half(x): x1, x2 = x.chunk(2, dim=- 1) return torch.cat((-x2, x1), dim=-1) # 生成旋转位置嵌入 def get_rotary_emb(dim, seq_len): inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2) ).float() / dim)) t = torch.arange(seq_len, dtype=inv_freq.dtype) freqs = torch.einsum(&quot;i,j-&gt;ij&quot;, t, inv_freq) emb = torch.cat( (freqs, freqs), dim=-1) cos = emb.cos().unsqueeze(0).unsqueeze(0) sin = emb.sin().unsqueeze(0).unsqueeze(0) return cos, sin #计算单层的 Past_key_values 的函数 defcompute_past_key_values_for_layer(layer_idx,hidden_​​state):attention_layers = [layer.self_attn for layer in model.model.layers] # 应用层归一化norm_weight = state_dict[f&#39;model.layers.{layer_idx}.input_layernorm .weight&#39;]hidden_​​state = F.layer_norm(hidden_​​state,(hidden_​​state.size(-1),),norm_weight) W_q = state_dict[f&#39;model.layers.{layer_idx}.self_attn.q_proj.weight&#39;] W_k = state_dict[ f&#39;model.layers.{layer_idx}.self_attn.k_proj.weight&#39;] W_v = state_dict[f&#39;model.layers.{layer_idx}.self_attn.v_proj.weight&#39;] 查询 = torch.matmul(hidden_​​state, W_q.T)键 = torch.matmul(hidden_​​state, W_k.T) 值 = torch.matmul(hidden_​​state, W_v.T) batch_size, seq_length, hide_dim = hide_state.size() num_attention_heads = focus_layers[layer_idx].num_heads head_dim = hide_dim // num_attention_heads 个键=keys.view(batch_size, seq_length, num_attention_heads, head_dim) 查询 = requests.view(batch_size, seq_length, num_attention_heads, head_dim) 值 =values.view(batch_size, seq_length, num_attention_heads, head_dim) 键 =keys.permute(0, 2 , 1, 3) 查询=queries.permute(0, 2, 1, 3) 值=values.permute(0, 2, 1, 3)rotary_emb = get_rotary_emb(head_dim, seq_length) 查询, 键= apply_rotary_pos_emb(查询, 键) ,rotary_emb) returnkeys,values # 计算past_key_values past_key_values = [] for i,hidden_​​state in enumerate(hidden_​​states[:-1]): # 跳过最后一层keys,values =compute_past_key_values_for_layer(i,hidden_​​state)past_key_values.append((keys) , value)) past_key_values = tuple(past_key_values)  感谢任何帮助！ 可以在此处找到值之间不匹配的示例：https://pastebin.com/CadGf9Ug   由   提交/u/1azytux  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctxd7c/mismatch_between_past_key_values_calculated_from/</guid>
      <pubDate>Fri, 17 May 2024 05:10:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 被 NeurIPS 2024 - 其他会议接受的真正机会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctv9li/d_real_chances_to_be_accepted_in_neurips_2024/</link>
      <description><![CDATA[嘿！ 这是我第一次提交到 NeurIPS。 有谁知道什么时候审核作者可以看到吗？八月，或者有可能更早吗？如果我们的评论真的很差……最好的办法就是退出提交路径，对吧？在这种情况下，您在这些日期推荐哪些替代方案？ 我的主题是神经网络可靠性，但我总是对我的研究缺乏信心，我总是认为这还不够，如果我在一个会议名为 Neurips。您认为大家都提交了好论文还是有大量的垃圾论文？我在这里看到了很多关于评审过程的不好的意见...所以，我有点害怕。 今年，有 20000 多份投稿。所以，我不知道该怎么办，是继续提交还是提交到另一个会议。由于我正在填补的空白很明确，我确信其他人正在弥补这一空白并将其提交给 NeurIPS。还有比 NeurIPS 更先输出结果的会议吗？我正在尝试以聪明的方式思考。当一名研究员太难了... 谢谢！   由   提交 /u/Sincerebri   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctv9li/d_real_chances_to_be_accepted_in_neurips_2024/</guid>
      <pubDate>Fri, 17 May 2024 03:06:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2018年以来未来被认为是大炮的开创性论文清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cts99m/d_seminal_papers_list_since_2018_that_will_be/</link>
      <description><![CDATA[大家好， 我是刚毕业的学生，​​终于有时间学习一些真正有趣的东西了。我想熟悉一下现代机器学习。我读过最著名的论文，比如《Attention is all you Need》、《CLIP》、《Vision Transformers》，但我肯定错过了大部分重要的论文。直接阅读最近的 ICML/NIPS 对我没有好处，因为我觉得我还有很多基础知识要讲。 我应该从哪里开始？我对 2018 年左右的 ML 和 DL 很熟悉，对 vanilla Transformer 也很熟悉，但基本就是这样了。    提交人    /u/David202023   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cts99m/d_seminal_papers_list_since_2018_that_will_be/</guid>
      <pubDate>Fri, 17 May 2024 00:27:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 高级框架值得使用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctqzfa/d_are_pytorch_highlevel_frameworks_worth_using/</link>
      <description><![CDATA[为了更好地跟踪实验结果和超参数，我不仅了解了权重和偏差库，而且最终还发现了诸如此类的框架如 PyTorch Lightning 和 Ignite。我一直使用原始 PyTorch，所以我不确定这些框架是否真的有用。我主要从事学术研究，现在我还需要跟踪 MAE，因为这是一个回归问题，我不知道这些框架是否支持这一点，或者让我定义一个自定义指标。 Would这些框架对我有用吗？在尝试不同的架构时，它可以加快进程吗？ 如果您认为它们有用，请告诉我您会推荐哪一个。   由   提交/u/dazor1  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctqzfa/d_are_pytorch_highlevel_frameworks_worth_using/</guid>
      <pubDate>Thu, 16 May 2024 23:24:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] L为什么线性 RNN 如此高效（在准确性方面，而不是计算方面）？寻找数学甚至直观的解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ctea1i/d_lwhy_are_linear_rnns_so_performant_in_terms_of/</link>
      <description><![CDATA[尝试熟悉曼巴架构，从而熟悉 SSM，从而熟悉线性 RNN。我查看了有关 SSM、S4 和 Mamba 的资源，但找不到解释。为什么带有 SSM 参数化的线性 RNN 可以提高性能。我也无法直观地理解它 - 为什么线性变换足以完成 seq2seq 任务？ 有没有详尽的数学解释，甚至有关于线性 RNN 如何在某些任务上超越 Transformer 的视频？&lt; /p&gt;   由   提交/u/Ice-Cool701  /u/Ice-Cool701 reddit.com/r/MachineLearning/comments/1ctea1i/d_lwhy_are_linear_rnns_so_performant_in_terms_of/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ctea1i/d_lwhy_are_linear_rnns_so_performant_in_terms_of/</guid>
      <pubDate>Thu, 16 May 2024 14:29:44 GMT</pubDate>
    </item>
    <item>
      <title>[P] 针中针（NIAN）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct9nth/p_needle_in_a_needlestack_nian/</link>
      <description><![CDATA[代码：https://github.com/llmonpy/needle-in-a-needlestack 网站：https://nian.llmonpy.ai/ 描述：  大海捞针(NIAH) 一直是一种广受欢迎的测试，用于评估法学硕士如何有效地关注其上下文窗口中的内容。随着法学硕士的进步，NIAH 变得太容易了。 Needle in a Needlestack (NIAN) 是一个新的、更具挑战性的基准。即使是 GPT-4-turbo 也很难达到这个基准。 NIAN 从大型打油诗数据库中创建打油诗列表，并询问有关已放置在测试位置的特定打油诗的问题。每个测试通常会使用 5 到 10 个测试打油诗，放置在提示中的 5 到 10 个位置。每个测试重复2-10次。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct9nth/p_needle_in_a_needlestack_nian/</guid>
      <pubDate>Thu, 16 May 2024 10:22:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在单个 A100 上预训练字节级 0.67B 变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct9bgc/r_pretraining_a_bytelevel_067b_transformer_on_a/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct9bgc/r_pretraining_a_bytelevel_067b_transformer_on_a/</guid>
      <pubDate>Thu, 16 May 2024 09:58:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文没有代码怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ct45hk/d_whats_up_with_papers_without_code/</link>
      <description><![CDATA[最近做一个人脸反欺骗的项目，在研究过程中发现几乎没有论文提供实现代码。在可重复性如此重要的领域，为什么人们仍然接受没有实现的论文？   由   提交/u/mtmttuan  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ct45hk/d_whats_up_with_papers_without_code/</guid>
      <pubDate>Thu, 16 May 2024 03:57:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>