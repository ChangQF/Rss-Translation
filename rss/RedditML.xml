<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 21 May 2024 06:20:36 GMT</lastBuildDate>
    <item>
      <title>[D] GPT-4 复古 - 在现代法学硕士兴起期间作为 NLP 研究员工作是什么感觉？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx14g4/d_gpt4_retro_what_it_was_like_working_as_a_nlp/</link>
      <description><![CDATA[我只是好奇 GPT-4 的发布如何改变了 NLP 领域。 GPT-4 或 ChatGPT 的发布对您的工作有很大影响吗？   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx14g4/d_gpt4_retro_what_it_was_like_working_as_a_nlp/</guid>
      <pubDate>Tue, 21 May 2024 06:18:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我应该考虑转型为 AI/ML 工程师吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx0ezo/d_should_i_consider_transitioning_to_an_aiml/</link>
      <description><![CDATA[大家好，我是第三世界国家的一名三年级 SWE 学生。  在获得实习机会之前，我有大约 4 个月的时间来奉献。现在，我有两个选择：一是专注于 Web 开发（我的简历中的大项目），二是完全沉浸在全职学习 AI/ML 中。 我我对人工智能或机器学习了解不多，但我有一些非常基础的知识。作为一名 SWE，我熟悉 Python。我在高中时数学很吃力，但我愿意在这方面学习和提高。 实际上，我应该走这条路，还是你们有更好的想法给我？我们将非常感谢您的意见！   由   提交/u/0962267576  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx0ezo/d_should_i_consider_transitioning_to_an_aiml/</guid>
      <pubDate>Tue, 21 May 2024 05:30:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 多输出回归任务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwy20w/d_multioutput_regression_tasks/</link>
      <description><![CDATA[我知道 scikit-learn 中的几种算法，例如 LR、SVR、KNR 等。 &lt; p&gt;问题是它们有时是有限的  仅接受一维输入（即 N x 特征，而我的数据是多维的、扁平化的与 2D CNN 相比，F 到 1D 并没有表现出更好的性能） 难以处理大量数据 多输出回归的工作并不多，或者他们需要一些调整（例如，每个输出一个回归器）  我找不到很多关于这种方法有效性的讨论。就可用的开源项目（huggingface、AIhub、timm、 mmpretrain等） 关于神经网络，也有人会说我们只要修改head就可以进行回归，真的有那么简单吗？ 总之，我想知道是否有人有处理回归任务的经验，你是否只使用经典的 ML 算法。那么，您是如何克服上述限制的呢？我正在处理的数据是音频 wav 形式，大小可以为 1000 x 5000 左右。 或者您是否使用神经网络来执行多输出回归？您会推荐哪些架构。我们需要注意哪些细节？  谢谢（如果我有任何错误，请纠正我）   由   提交/u/nguyenvulong  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwy20w/d_multioutput_regression_tasks/</guid>
      <pubDate>Tue, 21 May 2024 03:08:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您尝试过使用 Intel 和 AMD GPU 来训练模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwvoaq/r_have_you_give_a_try_to_use_intel_and_amd_gpus/</link>
      <description><![CDATA[NVIDIA 统治着数据中心 GPU 市场。最常用的 ML 框架支持 NVIDIA GPU。但我想知道使用 Intel 和 AMD GPU 训练 ML 模型的缺点和优点。你用过这些 GPU 吗？你对性能、可用​​性、软件堆栈和生态系统有什么看法？    提交人    /u/Various_Protection71   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwvoaq/r_have_you_give_a_try_to_use_intel_and_amd_gpus/</guid>
      <pubDate>Tue, 21 May 2024 01:05:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] Wav2Lip 用于动漫人物？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwudpo/d_wav2lip_for_anime_characters/</link>
      <description><![CDATA[大家好。我看到了 Wav2Lip，这是一个开源软件，用于根据单个图像和音频创建“深度伪造”头像。有没有类似的东西，但明确针对动漫 2D 角色？仅开源！   由   提交 /u/yukiarimo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwudpo/d_wav2lip_for_anime_characters/</guid>
      <pubDate>Tue, 21 May 2024 00:01:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习真的对人类健康产生了影响吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwsbyw/d_has_ml_actually_moved_the_needle_on_human_health/</link>
      <description><![CDATA[我们听说机器学习用于药物发现、精准医疗、个性化治疗等已有相当一段时间了。机器学习实际上通过哪些方式改善了人类健康？ 似乎大多数治疗和诊断仍然基于数十年的专注生物学研究，而不是某种公正的机器学习方法。放射学是一个值得注意的例外，它受益于机器视觉的进步，但即使是他们似乎也很慢地接受人工智能作为临床实践。   由   提交/u/Potential_Athlete238   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwsbyw/d_has_ml_actually_moved_the_needle_on_human_health/</guid>
      <pubDate>Mon, 20 May 2024 22:26:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有 ML/AI 相关主题的阅读小组/期刊俱乐部？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwrteq/d_are_there_any_reading_groupsjournal_clubs_for/</link>
      <description><![CDATA[嗨，有谁知道是否有任何阅读小组/期刊俱乐部，人们定期分享书籍章节或论文？如果可能的话，让一些阅读同一本书/论文的人分享他们的想法/想法可能会很好。谢谢！   由   提交 /u/Illustrious-Pay-7516   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwrteq/d_are_there_any_reading_groupsjournal_clubs_for/</guid>
      <pubDate>Mon, 20 May 2024 22:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 多模态模型能否区分图像和文本？就像如果文本标记和图像标记是接近的向量一样，模型是否能够“判断”它是在阅读还是在看？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwoh51/d_can_multimodal_models_tell_images_apart_from/</link>
      <description><![CDATA[我在使用多模式模型进行一些工作时遇到了这个问题。他们似乎无法区分信息的哪一部分来自输入的文本部分和图像部分。  有这方面的研究吗？    由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwoh51/d_can_multimodal_models_tell_images_apart_from/</guid>
      <pubDate>Mon, 20 May 2024 19:44:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] Instagram 应用程序上的评论的音译 + 翻译</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwiemd/d_transliteration_translation_of_comments_on/</link>
      <description><![CDATA[是我一个人还是有人注意到翻译质量的显着提高 - 特别是使用英语字符编写的语言的翻译（音译 + 翻译） ）。想知道他们使用什么样的模型导致了突然的改进   由   提交/u/ts_aditya  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwiemd/d_transliteration_translation_of_comments_on/</guid>
      <pubDate>Mon, 20 May 2024 15:31:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 模型并行性的最新技术是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cw35by/r_what_is_the_stateofart_of_model_parallelism/</link>
      <description><![CDATA[使用 PyTorch、Tensorflow 等常见框架实现模型并行是否容易？这取决于模型架构？模型并行性最常用的方法是什么？   由   提交/u/Various_Protection71   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cw35by/r_what_is_the_stateofart_of_model_parallelism/</guid>
      <pubDate>Mon, 20 May 2024 00:51:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] AlphaFold 3 的简化 PyTorch 实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cw0n8b/p_simplified_pytorch_implementation_of_alphafold_3/</link>
      <description><![CDATA[       由   提交/u/csozboz  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cw0n8b/p_simplified_pytorch_implementation_of_alphafold_3/</guid>
      <pubDate>Sun, 19 May 2024 22:48:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您认为未来几年机器学习将在计算生物学和生物信息学等领域发挥什么作用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvxcbc/d_what_role_do_you_think_machine_learning_will/</link>
      <description><![CDATA[我相信计算生物学和生物信息学将越来越多地采用机器学习工作，我很高兴看到所取得的进步。我认为它将在将疾病与可能在标签外使用的现有药物相匹配方面开辟一个全新的世界。我们还应该注意哪些其他事情？ 谁是在这个世界上工作的研究人员？   由   提交/u/RawCS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvxcbc/d_what_role_do_you_think_machine_learning_will/</guid>
      <pubDate>Sun, 19 May 2024 20:19:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 是如何从从事令人兴奋的研究变成一家类似大型科技公司的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</link>
      <description><![CDATA[我最近重新审视了 OpenAI 关于 DOTA2 Open 的论文五，从工程和研究的角度来看，他们在那里所做的事情令人印象深刻。创建一个包含 50k 个 CPU 的分布式系统用于部署，1k 个 GPU 用于训练，同时每 0.25 秒从 16k 个观察中执行 8k 到 80k 个操作 - 这有多疯狂？他们还对 RL 模型进行“手术”以恢复权重，因为在几个月的训练中，他们的奖励函数、观察空间甚至架构都发生了变化。最后但并非最不重要的一点是，他们击败了 OG 队（当时的世界冠军），并部署了代理与其他玩家在线实时比赛。  快进几年，他们正在预测序列中的下一个标记。不要误会我的意思，gpt4 及其全能版本的功能确实是工程和研究的惊人壮举（可能更有用），但它们似乎并不像它们的一些产品那样有趣（从研究角度来看）  那么，现在我想知道这些年来工程师和研究人员是如何转变的？主要是由于他们的财务状况和盈利需要，还是有更深层次的原因进行转型？   由   提交 /u/UnluckyNeck3925   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</guid>
      <pubDate>Sun, 19 May 2024 16:46:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在机器学习中回收旧会议提交内容的文化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</link>
      <description><![CDATA[我从事统计机器学习工作。我注意到很多人（包括我自己和我审阅的人）经常重复他们向 ML 会议提交的论文。 例如，如果他们的论文被 ICML 拒绝，他们会提交给 NeurIPS，然后提交给 ICLR（或UAI/AISTATS 在我的领域也是顶尖的）。如果2~3次后没有进入ICML/NeurIPS/ICLR，他们就会将其提交给AAAI/IJCAI/TMLR/ICDM，T-NNLS/T-KDD/NN/Neurocomputing等期刊，或特定领域的场地，如LoG/CoLLA/AABI。经过所有这些，如果论文仍然没有被接受，他们就简单地将它们或 arXiv.我相信 CV/NLP 也可能是这种情况。 作为审稿人，我经常遇到会议提交的内容，作者在没有真正考虑之前提供的审稿的情况下重新提交。有时他们在重新提交时确实会纳入审稿意见，但有时工作可能只是达不到一级会议的水平，但他们只是不断重新提交并希望能够偶然被接受。 我认为这正在消耗社区审稿人的大量时间来继续审阅相同的提交内容（特别是考虑到 NeurIPS 达到 20k 提交 ID；我预计会看到许多重新提交）。这也许也是 TMLR 诞生的原因之一（强调正确性而不是新颖性）。 我确实理解“研究质量比发表地点更重要”之类的论点。或者“OpenAI 通常只是简单地将他们的论文（例如 GPT-X）放在 arXiv 上”。然而，学生或初级研究人员在他们的职业生涯中也需要发表论文，包括我自己。  人们对此有何看法？   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/</guid>
      <pubDate>Sun, 19 May 2024 14:04:23 GMT</pubDate>
    </item>
    </channel>
</rss>