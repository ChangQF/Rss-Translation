<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 30 Nov 2023 21:12:21 GMT</lastBuildDate>
    <item>
      <title>[D] Kaggle竞赛初学者问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187t7im/d_kaggle_competition_beginner_question/</link>
      <description><![CDATA[我是 Kaggle 比赛的初学者 当我完成所有模型（预处理数据 + 训练 +验证+将模型保存在kaggle/working中），当我将笔记本提交给kaggle时，它重新运行它并计算运行时间，这正常吗？现在我已经在 kaggle/working 中保存并准备好了模型，就像我提交它时一样，也重新运行所有代码，甚至预处理， 如果您想帮助，请为我澄清这一点&lt; /p&gt;   由   提交 /u/Express-Pool-5480   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187t7im/d_kaggle_competition_beginner_question/</guid>
      <pubDate>Thu, 30 Nov 2023 21:09:06 GMT</pubDate>
    </item>
    <item>
      <title>YUAN-2.0-102B，带代码和重量。 ChatGPT 和 GPT-4 在各种基准上的得分 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187spj3/yuan20102b_with_code_and_weights_scores_between/</link>
      <description><![CDATA[       由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187spj3/yuan20102b_with_code_and_weights_scores_between/</guid>
      <pubDate>Thu, 30 Nov 2023 20:47:55 GMT</pubDate>
    </item>
    <item>
      <title>机械工程师想做机器学习[D].</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187qed9/mechanical_engineer_wants_to_do_machine_learning_d/</link>
      <description><![CDATA[我是一名机械工程专业的学生，​​我想进入机器学习领域，但我没有任何类型的指导。甚至讨论机械工程师如何成为机器学习专家。我看到一个帖子，来自一位在一家机械工程师公司担任数据分析师的人，他也是一名机械工程师。请指导。   由   提交 /u/AromaticEconomics113   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187qed9/mechanical_engineer_wants_to_do_machine_learning_d/</guid>
      <pubDate>Thu, 30 Nov 2023 19:10:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] MLM 通过解析音频输入来从背景氛围中辨别音乐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187o848/p_mlm_to_parse_through_audio_input_to_discern/</link>
      <description><![CDATA[大家好 :) 我正在开发一个 iOS 音频应用程序，它可以处理麦克风输入以实现与音乐同步的反应性可视化。我设置了一个 AVFoundation 管道来记录音频，对光谱质心和色度向量等特征帧执行实时 FFT 分析，并将这些特征映射到驱动视觉效果的参数。我现在想训练一个模型来区分麦克风数据中的音乐和环境噪音，以过滤掉仅具有不相关背景谈话或声音的片段。该应用程序是用 Swift 构建的，即使在较旧的 iPhone 上也需要非常有效地执行预测（理想情况下哈哈，这不是最大的问题）。您建议使用哪种类型的神经网络模型来对每帧的短音频特征序列进行分类？我正在考虑 LSTM 或 Transformer 架构。哪些功能集可提供最具辨别力的音乐与噪音信号？我应该通过帧级预测或总体序列准确性等聚合指标来量化模型准确性吗？关于优化实时移动推理模型有什么建议吗？我有收集和标记原始音频和功能集的带时间戳的训练数据对的经验。请让我知道有关数据、模型配置、指标或优化的其他细节是否有用。预先感谢您的指导！   由   提交/u/zeke-001  /u/zeke-001  reddit.com/r/MachineLearning/comments/187o848/p_mlm_to_parse_through_audio_input_to_discern/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187o848/p_mlm_to_parse_through_audio_input_to_discern/</guid>
      <pubDate>Thu, 30 Nov 2023 17:38:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自托管嵌入模型与使用托管嵌入服务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187ntuz/d_selfhosting_embedding_model_vs_using_hosted/</link>
      <description><![CDATA[机器学习小组，您好， 每个人都如何在您的应用程序中使用嵌入？您是在计算机中自行托管嵌入模型，还是使用托管服务，例如 https://embaas.io/？ &lt; p&gt;我假设对于闭源模型，例如 openai 嵌入或 voyage ai 嵌入，没有自托管选项。对于诸如sentence-transformers/all-MiniLM-L6-v2、BAAI/bge-small-en、bge-large-en-v1.5等开源模型，您更喜欢自行托管模型，还是使用托管服务？ 此外，在使用矢量数据库时，您是否在将数据插入矢量数据库之前单独处理嵌入，或者利用矢量数据库产品封装的内置嵌入功能？您遇到过任何限制吗？   由   提交/u/songrenchu   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187ntuz/d_selfhosting_embedding_model_vs_using_hosted/</guid>
      <pubDate>Thu, 30 Nov 2023 17:21:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求指导：有抱负的 ML/AI 工程师的最佳学习路径 - 优先考虑核心编程 (DSA) 还是深入研究机器学习库？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187nrs7/d_seeking_guidance_best_learning_path_for/</link>
      <description><![CDATA[大家好，向大家致以诚挚的问候。我目前是一名正在攻读学士学位的 IT 学生，我渴望未来成为一名机器学习或人工智能工程师。我正在寻求有关理想学习路径的建议。我是否应该优先考虑数据结构和算法等核心编程技能，并首先获得软件工程知识？或者，是否建议通过学习 TensorFlow 等不同的库来直接进入 ML/AI 世界？如果软件工程知识对于 ML/AI 领域的成功至关重要，那么需要掌握多少软件工程知识？感谢您的见解。    由   提交 /u/neerazayn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187nrs7/d_seeking_guidance_best_learning_path_for/</guid>
      <pubDate>Thu, 30 Nov 2023 17:19:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一周后我将采访 Rich Sutton，我应该问他什么问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187nbv8/d_im_interviewing_rich_sutton_in_a_week_what/</link>
      <description><![CDATA[Rich 是强化学习书籍&lt;的作者&lt; /a&gt;，最近，他与一些同事创立了 OpenMind 研究所。 ​ 面试时间为 1 周。我有 RL 背景，并且已经对问题和主题有了一些想法，但我也想在艾伯塔省 RL 泡沫之外寻找问题。技术问题是最好的，尽管我对任何事情都持开放态度。谢谢！ ​ 采访发布几周后，我将在此帖子中发布更新。   由   提交/u/ejmejm1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187nbv8/d_im_interviewing_rich_sutton_in_a_week_what/</guid>
      <pubDate>Thu, 30 Nov 2023 17:00:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我们将 Netron 集成到 GitHub 中以可视化模型架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187l3jp/p_we_integrated_netron_into_github_for/</link>
      <description><![CDATA[我们喜欢 Lutz Roeder 创建的 Netron 库：https:/ /github.com/lutzroeder/netron 我们想要探索能够为 GitHub 中托管的 ML 模型渲染 Netron 可视化的感觉，因此我们构建了 Netron 集成：https://about.xethub.com/blog/visualizing-ml-models-github-netron  Netron 专注于一次查看 1 个模型文件，但我们还在拉取请求中合并了前后模型可视化： https://assets-global.website-files.com/6474aea6101c81b742144dd2/65689c07b7f2b060a92 5097c_github_pr2.png   由   提交 /u/semicausal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187l3jp/p_we_integrated_netron_into_github_for/</guid>
      <pubDate>Thu, 30 Nov 2023 15:25:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAMAS 2024 评论已出炉！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187ilt5/d_aamas_2024_reviews_are_out/</link>
      <description><![CDATA[我没有看到讨论帖子，所以我想我应该制作这个。   由   提交 /u/LessPoliticalAccount   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187ilt5/d_aamas_2024_reviews_are_out/</guid>
      <pubDate>Thu, 30 Nov 2023 13:32:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于序列建模的分层门控循环神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187iaw6/r_hierarchically_gated_recurrent_neural_network/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2311.04823 代码：https://github.com/OpenNLPLab/HGRN 模型：https://huggingface.co/OpenNLPLab 摘要：  变形金刚已经超越RNN 因其并行训练和长期依赖建模的卓越能力而广受欢迎。最近，人们对使用线性 RNN 进行高效序列建模重新产生了兴趣。这些线性 RNN 通常在线性递归层的输出中采用门控机制，而忽略了在递归中使用遗忘门的重要性。在本文中，我们提出了一种门控线性 RNN 模型，称为分层门控循环神经网络（HGRN），其中包括由可学习值下界的遗忘门。当向上移动层时，下界单调增加。这允许上层对长期依赖关系进行建模，而下层对更多本地的短期依赖关系进行建模。语言建模、图像分类和远程竞技场基准的实验展示了我们提出的模型的效率和有效性。源代码可在 此 https URL 处获取。  https://preview.redd.it/thph9bpmjh3c1.png?width=965&amp;format=png&amp; ;auto=webp&amp;s=8e4871cd280ef7e5b771b463435d47da11dca52d   由   提交 /u/APaperADay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187iaw6/r_hierarchically_gated_recurrent_neural_network/</guid>
      <pubDate>Thu, 30 Nov 2023 13:16:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 深度强化学习的泛化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187f2rn/r_generalization_in_deep_reinforcement_learning/</link>
      <description><![CDATA[深度强化学习中的泛化、鲁棒性和对抗性攻击 https://blogs.ucl.ac.uk/steapp/2023/11/15 /对抗性攻击-深度强化学习中的鲁棒性和泛化/   由   提交 /u/ml_dnn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187f2rn/r_generalization_in_deep_reinforcement_learning/</guid>
      <pubDate>Thu, 30 Nov 2023 09:59:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用多个库部署 CodeLlama 34Bn 模型的见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/187bocu/d_insights_from_deploying_codellama_34bn_model/</link>
      <description><![CDATA[     &lt; td&gt; 大家好， 我们最近尝试部署 CodeLlama 340 亿模型，并希望分享我们的主要发现对于那些感兴趣的人：  最佳性能：使用 vLLM 的量化 GPTQ、4 位 CodeLlama-Python-34B 模型。 结果：我们平台上使用 Nvidia A100 GPU 的平均最低延迟为 3.51 秒，平均令牌生成率为 58.40/秒，冷启动时间为 21.8 秒。  CodeLlama 34Bn   测试的其他库：HuggingFace Transformer Pipeline、AutoGPTQ、文本生成推理。  渴望听到您在类似部署中的经验和学习！   由   提交/u/Tiny_Cut_8440   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/187bocu/d_insights_from_deploying_codellama_34bn_model/</guid>
      <pubDate>Thu, 30 Nov 2023 06:13:50 GMT</pubDate>
    </item>
    <item>
      <title>[D]：了解训练大型模型时的 GPU 内存分配</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1878lat/d_understanding_gpu_memory_allocation_when/</link>
      <description><![CDATA[TL;DR：为什么 GPU 内存使用量在梯度更新步骤期间会激增（无法解释 10GBs），然后又下降？ 我一直致力于微调 HuggingFace 上提供的一些较大的 LM（例如 Falcon40B 和 Llama-2-70B），到目前为止，我对内存需求的所有估计都没有相加。我可以使用 4 个 A100-80gb GPU，并且相当有信心我应该有足够的 RAM 来使用 LoRA 微调 Falcon40B，但我不断收到 CUDA OOM 错误。我已经找到了让事情运行的方法，但这让我意识到我并不真正理解训练期间如何分配内存。 以下是我对训练模型时内存去向的理解：  设置 -&gt;定义 TOTAL_MEMORY = 0 (MB)，我将在执行增加内存的每个步骤时更新它。 -&gt;通过“观察”来检查内存使用情况nvidia-smi 每 2 秒刷新一次。 -&gt;模型已加载到fp16 -&gt;使用具有 ~7B 参数的 Falcon7B（类似于 6.9，但足够接近） -&gt;在 jupyter 笔记本中的单个 A100-80gb GPU 上运行 加载模型：  用于 torch 等的 CUDA 内核（在我的机器上）我看到每个 GPU 大约 900mb）。总内存 + 900 -&gt; TOTAL_MEMORY=900 模型权重（废话）。假设您使用 float16 加载了一个 7B 参数模型，那么您将看到 2 字节 * 7B 参数 = 14B 字节。 ~= 14GB GPU VRAM。总内存 + 14_000 -&gt; TOTAL_MEMORY=15_000（舍入）  模型应在单个 GPU 上加载。 训练（我正在模拟单个前向并通过单独运行每个部分来向后一步）  数据。我正在传递一小批虚拟输入（随机整数），因此我假设这不会对内存使用量产生实质性贡献。 前向传递。由于某种原因，内存跳跃了大约 1000mb。也许这是由于缓存的中间激活造成的？虽然我觉得应该更大。 TOTAL_MEMORY + 1_000 -&gt; TOTAL_MEMORY = 16_000。 计算交叉熵损失。损失张量将利用一些内存，但这似乎不是一个非常高的数字，所以我认为它没有贡献。 通过调用 `loss.backwards() 计算相对于参数的梯度`。这会导致显着的内存峰值（增加 15_000 MB）。我想这是为模型中每个参数存储梯度值的结果？ TOTAL_MEMORY + 15_000 -&gt; TOTAL_MEMORY = 30_000 通过调用“optimizer.step()”更新模型参数。这会导致另一个内存峰值，GPU 内存使用量增加超过 38_000MB。不太确定为什么。我最好的猜测是，这是 AdamW 开始为每个参数存储 2 x 动量值的地方。如果我们进行数学计算（假设优化器状态值在 fp16 中）----&gt; 2 个字节 * 2 个状态 * 7B = 28B 字节 ~= 28GB。 TOTAL_MEMORY + 38_000 -&gt; TOTAL_MEMORY = 68_000  LoRA 会通过减少优化器步骤中所需的内存量来减少这个数字，但我尚未对此进行任何测试，因此没有任何数字。 我相信这就是所有主要组件。 那么额外的 10GB 从哪里来呢？也许它是“火炬保留了该内存但实际上并未使用它”之一。因此，我通过检查 `torch.cuda.memory_allocated` 和 `torch.cuda.max_memory_allocated` 的输出进行检查，也许那里有东西。 分配的内存（后退一步后）：53gb &lt; p&gt;分配的最大内存：66gb 这意味着在某些时候，需要额外的 13 GB，但后来被释放了。 我想问你们的问题是，有人知道这些内存在哪里吗？我在数学中没有发现的额外 10GB 来自哪里？向后传递后释放 13GB 会发生什么？是否有任何我错过的需要记忆的额外步骤？  这已经困扰我一段时间了，我希望获得更好的理解，因此我们将非常感谢您提供的任何专家意见、资源或其他建议！ &amp; #x200b; 编辑：我还知道，当您使用“Trainer”类进行训练时，您可以启用梯度检查点，通过在向后传递过程中重新计算一些中间激活来减少内存使用。那么整个过程的哪一部分会减少内存使用量呢？ ​   由   提交 /u/lightSpeedBrick   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1878lat/d_understanding_gpu_memory_allocation_when/</guid>
      <pubDate>Thu, 30 Nov 2023 03:27:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过深度学习发现了数百万种新材料</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/186w67m/r_millions_of_new_materials_discovered_with_deep/</link>
      <description><![CDATA[帖子：https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/ 论文：https://www.nature.com/articles/s41586-023-06735-9 摘要： 新型功能材料实现了从清洁能源到信息处理的技术应用的根本性突破。从微芯片到电池和光伏发电，无机晶体的发现一直受到昂贵的试错方法的瓶颈。与此同时，随着数据和计算的增加，语言、视觉和生物学的深度学习模型展示了新兴的预测能力。在这里，我们展示了大规模训练的图网络可以达到前所未有的泛化水平，从而将材料发现的效率提高一个数量级。在持续研究中发现的 48,000 个稳定晶体的基础上，效率的提高使得能够在当前凸包下方发现 220 万个结构，其中许多结构逃过了人类之前的化学直觉。我们的工作代表了人类已知的稳定材料的数量级扩展。最终凸包上的稳定发现将可用于筛选技术应用，正如我们对层状材料和固体电解质候选物的演示一样。在稳定结构中，有 736 个已通过独立实验实现。数以亿计的第一原理计算的规模和多样性也解锁了下游应用的建模能力，特别是导致高度准确和强大的学习原子间势，可用于凝聚相分子动力学模拟和高保真零-离子电导率的射击预测。   由   提交 /u/RobbinDeBank   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/186w67m/r_millions_of_new_materials_discovered_with_deep/</guid>
      <pubDate>Wed, 29 Nov 2023 18:19:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>