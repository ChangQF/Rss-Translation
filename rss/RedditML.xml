<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Fri, 07 Jun 2024 12:28:24 GMT</lastBuildDate>
    <item>
      <title>尝试理解IDM-VTON [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da8gv4/trying_to_understand_idm_vton_d/</link>
      <description><![CDATA[有人能进一步解释一下训练过程是如何进行的吗？扩散模型到底在哪里，其他模块如何连接到扩散模型。我还对使用的损失函数以及选择将配对的人 + 服装用于其中一个网络而不是仅提供面罩感兴趣。 https://arxiv.org/abs/2403.05139 谢谢     提交人    /u/ashblue21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da8gv4/trying_to_understand_idm_vton_d/</guid>
      <pubDate>Fri, 07 Jun 2024 11:36:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新书！设计一个机器学习系统（从头开始）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da7cgx/r_new_book_design_a_machine_learning_system_from/</link>
      <description><![CDATA[      大家好，感谢大家给我们机会与社区分享我们最新的 MEAP 版本。 设计机器学习系统（从头开始） 作者：Benjamin Tan Wei Hao、Shanoop Padmanabhan 和 Varun Mallya 我们最新的 MEAP 版本教你如何从头开始设计可靠的 ML 系统。它结合了 MLOps 和 DevOps 以及一系列经过验证的基础设施工具，包括 Kubeflow、MLFlow、BentoML、Evidently 和 Feast。 在整本书中，你将构建图像分类器和推荐系统的交付管道，同时学习最佳实践。 获得机器学习工作流程基本部分的实践经验，包括编排管道、模型训练、服务以及监控和可解释性。 🚀 立即采取行动！使用代码 retanweihao50 可节省 50% 📖 进入书籍：https://mng.bz/PZBR 📹 观看此视频以了解更多信息：https://mng.bz/1GZq 谢谢阅读。 https://preview.redd.it/u7p5fakfm45d1.jpg?width=718&amp;format=pjpg&amp;auto=webp&amp;s=f2d7cf88fbb3c0e72d64d1ee42ae047ecbbb2ca5 干杯，    提交人    /u/ManningBooks   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da7cgx/r_new_book_design_a_machine_learning_system_from/</guid>
      <pubDate>Fri, 07 Jun 2024 10:26:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检测手写单词</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da6zal/d_detecting_handwritten_words/</link>
      <description><![CDATA[      大家好， 我目前正在做一个项目，需要一些指导。如何从二值化图像中检测和选择手写单词？我一直在努力解决这个问题，如果您能分享任何建议或资源，我将不胜感激。 https://preview.redd.it/es​​wwi2mam45d1.png?width=990&amp;format=png&amp;auto=webp&amp;s=26df237f1067271d79e63671f81a8d475b99853d 提前感谢您的帮助！    提交人    /u/Dependent-Ad914   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da6zal/d_detecting_handwritten_words/</guid>
      <pubDate>Fri, 07 Jun 2024 10:02:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 从 GPT-4 中提取概念</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da6ml3/r_extracting_concepts_from_gpt4/</link>
      <description><![CDATA[与最近 Anthropic 的报告类似，OpenAI 发布了一份报告、一些代码和一个可视化工具，用于显示自动编码器从其模型中提取的特征。 OpenAI 博客文章：https://openai.com/index/extracting-concepts-from-gpt-4/ 论文：https://cdn.openai.com/papers/sparse-autoencoders.pdf 代码：https://github.com/openai/sparse_autoencoder    由   提交  /u/valdanylchuk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da6ml3/r_extracting_concepts_from_gpt4/</guid>
      <pubDate>Fri, 07 Jun 2024 09:37:07 GMT</pubDate>
    </item>
    <item>
      <title>[N] vLLM 发布了对嵌入 API 和 OpenAI 类嵌入客户端的初始支持！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da5wut/n_vllm_released_intial_support_for_embedding_api/</link>
      <description><![CDATA[很容易错过这个版本，但我很高兴几天前碰到了它。vLLM 发布了对带有 e5-mistral-7b-instruct 和 OpenAI 类嵌入客户端的嵌入 API 的初始支持！为什么这很重要？因为现在您只需一个推理引擎即可构建整个 RAG 解决方案！ https://docs.vllm.ai/en/latest/getting_started/examples/openai_embedding_client.html    提交人    /u/Patrick-239   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da5wut/n_vllm_released_intial_support_for_embedding_api/</guid>
      <pubDate>Fri, 07 Jun 2024 08:43:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何协调双重下降与毛丝鼠缩放定律？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da4j55/d_how_to_reconcile_double_descent_with_chincilla/</link>
      <description><![CDATA[前段时间，我听说 Chinchilla 缩放定律时，似乎认为许多主流 LLM 都严重训练不足，应该在模型大小不变的情况下，使用更多的数据进行训练。 不过，我最近也遇到了“双重下降”的概念，它似乎持相反观点 - 你应该在计算预算允许的范围内尽可能增加模型中的参数数量，即使参数/样本的比率非常高，只要你有某种正则化，模型在样本外的表现仍然会非常好，尽管过度拟合严重。 我该如何调和这两个看似对立的论点？一个主张降低参数/样本比率，另一个主张提高它。    提交人    /u/sam_the_tomato   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da4j55/d_how_to_reconcile_double_descent_with_chincilla/</guid>
      <pubDate>Fri, 07 Jun 2024 07:01:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻求健康应用项目的帮助：需要数据和方法建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da10lj/p_seeking_help_for_a_health_app_project_data_and/</link>
      <description><![CDATA[大家好， 我正在开发一款健康应用，旨在帮助患有慢性疾病（特别是糖尿病、高血压和高尿酸水平）的人。该应用将允许用户创建一份详细的健康档案，其中包括他们的慢性健康状况和当前用药情况。然后，用户将能够扫描食品的营养信息标签，应用将根据他们的健康档案提供产品是否适合他们食用的建议。 为了实现这一点，我需要包含详细营养信息的综合数据集。到目前为止，我已经确定了 USDA 食品成分数据集和 Open Food Facts 数据集作为潜在来源。如果有人可以访问可能对这个项目有用的其他数据集，请分享它们。 我也在寻求有关完成这个项目的最佳方法或方法的建议。具体来说，我想知道使用神经网络或其他机器学习技术是否是提供准确饮食建议的最有效方法。如有任何关于最佳方法的见解或建议，我将不胜感激。 如果有人有包含营养信息和健康状况的预处理数据集，我将非常有兴趣访问它们。这将大大加快开发过程。此外，我很好奇，您是否认为使用 USDA 食品成分数据集和开放食品事实数据集完成此项目是可行的。在使用这些数据集针对特定健康状况制定饮食建议时，我应该注意哪些限制？ 对于我可能需要准备自己的数据集的项目部分，我应该关注哪种数据？我特别想了解用户健康资料和营养数据中应包含哪些特定功能或细节，以确保准确的建议。 最后，如果有人做过类似的项目或知道与此类健康应用相关的研究论文或文章，您能分享一下吗？任何相关资源都将非常有帮助。    提交人    /u/amewzz_py   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da10lj/p_seeking_help_for_a_health_app_project_data_and/</guid>
      <pubDate>Fri, 07 Jun 2024 03:23:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用散焦注意力网络学习一维因果视觉表征</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1da0hlo/r_learning_1d_causal_visual_representation_with/</link>
      <description><![CDATA[模态差异导致了视觉和语言模型异构架构的发展。虽然图像通常需要 2D 非因果建模，但文本使用 1D 因果建模。这种区别对构建统一的多模态模型提出了重大挑战。本文探讨了使用 1D 因果建模表示图像的可行性。我们发现现有 1D 因果视觉模型中存在“过度聚焦”问题，其中注意力过度集中在一小部分视觉标记上。“过度聚焦”问题阻碍了模型提取各种视觉特征和获得有效梯度进行优化的能力。为了解决这个问题，我们提出了去焦点注意力网络，它采用可学习的带通滤波器来创建不同的注意力模式。在训练期间，引入了较大的和预定的丢弃路径率，以及用于全局理解任务的全局池化特征的辅助损失。这两种策略鼓励模型关注更广泛的标记并增强网络优化。大量实验验证了我们方法的有效性，表明一维因果视觉表示在全局感知、密集预测和多模态理解等任务中的表现可以与二维非因果表示相当。  Arxiv：https://arxiv.org/abs/2406.04342 Github：https://github.com/OpenGVLab/De-focus-Attention-Networks    提交人    /u/flyforlight   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1da0hlo/r_learning_1d_causal_visual_representation_with/</guid>
      <pubDate>Fri, 07 Jun 2024 02:55:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] NLP 与 LLM；有哪些主题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9y0wu/r_nlp_with_llms_what_topics/</link>
      <description><![CDATA[我们正在开发一门课程，向小型技术社区的学生教授 NLP 和 LLM。当今市场上哪些主题最相关？我想知道专家目前在这个领域强调什么。    提交人    /u/xyz__999   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9y0wu/r_nlp_with_llms_what_topics/</guid>
      <pubDate>Fri, 07 Jun 2024 00:47:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch Vs....为什么仍然是 Tensorflow？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9w79p/d_pytorch_vs_why_still_tensorflow/</link>
      <description><![CDATA[经过长时间的中断，我重新回到了机器学习领域。在与朋友交谈并做了一些研究（例如，2024 年 Tensorflow 与 PyTorch 的快速投票）后，我觉得 TensorFlow 可能不是恢复速度的最佳库。 现在，我对这篇文章的问题是：如果 TensorFlow 已经失宠到这种程度，人们建议不要使用它，那么为什么谷歌搜索“PyTorch vs.”仍然会带来大量将 PyTorch 与 TensorFlow 进行比较的文章和网站吗？ 在设置 PyTorch 环境之前，我应该考虑没有像样的 PyTorch 竞争者吗？ 期待您的见解！    提交人    /u/Tolure   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9w79p/d_pytorch_vs_why_still_tensorflow/</guid>
      <pubDate>Thu, 06 Jun 2024 23:19:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您是 NeurIPS'24 的审稿人吗？请阅读此内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9o8tn/r_are_you_a_reviewer_for_neurips24_please_read/</link>
      <description><![CDATA[你好！ 我目前担任 NeurIPS&#39;24 的区域主席 (AC)。提交的论文数量非常多，为这些论文分配合格的审稿人非常困难。 为什么很难，你可能会问。从高层次上讲，这是因为我们作为 AC，没有足够的信息来判断一篇论文是否分配给了足够数量（至少 3 个）的合格审稿人（即，能够对论文进行信息性评估的个人）。事实上，作为 AC，我们只能使用以下标准来决定是否为任何给定的论文分配审稿人：(i) 他们的出价；(ii) “亲和力”得分；(iii) 他们的个人 OpenReview 个人资料。但是  在注册成为审稿人的人中，只有一小部分对论文进行了投标。举个例子，在我堆积如山的论文中，有 30% 没有审稿人对其进行投标；实际上，大多数论文只有 3-4 个出价（不一定是“积极的”）。 当没有出价时，下一个指标是“亲和力”分数。但是，这个指标是以自动方式计算的，效果不佳（此外，一个人可能是某个领域的专家，但他们可能不愿意审阅某篇论文，例如，由于个人偏见）。 我们可以使用的最后一个指标是审稿人的“背景”，但这需要我们（即 AC）手动检查每个审稿人的 OpenReview 个人资料——这很耗时。更糟糕的是，今年的 NeurIPS 有大量审稿人是本科生或硕士生，他们的 OpenReview 简介完全为空。  鉴于上述情况，我写这篇文章是为了请求您的合作。如果您是 NeurIPS 的审稿人，请确保您的 OpenReview 简介是最新的。如果您是本科生/硕士生，请附上一个网页链接，该链接可以显示您是否具有审稿专业知识，或者您是否与一些“专家研究人员”在实验室工作（他们可能会通过提供审稿技巧来帮助您）。这同样适用于博士生或博士后：确保 OpenReview 上提供的信息反映了您的专业知识和偏好。 底线：您已同意担任（可以说是顶级的）顶级 ML 会议的审稿人。 请认真对待这项职责。如果您被分配到正确的论文，您将能够提供更多有用的评审，评审过程也会更顺畅。有用的评审对作者和 AC 都很有用。通过做得好，您甚至可能会获得“顶级评审员”的认可。    提交人    /u/hihey54   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9o8tn/r_are_you_a_reviewer_for_neurips24_please_read/</guid>
      <pubDate>Thu, 06 Jun 2024 17:46:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 给学生阅读人工智能研究论文的技巧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9k7rq/d_tips_for_getting_used_to_reading_ai_research/</link>
      <description><![CDATA[大家好， 我目前正在攻读五年制计算机科学课程的第二年，我计划明年深入研究人工智能领域。一段时间以来，我一直对人工智能充满热情，我渴望超越一般人的期望，深化我的知识。我目前的目标是三年内毕业，成为一名对该领域有深刻掌握的精英 MLE。 在正式学习人工智能之前，我咨询了一位大学教授，了解如何提高自己并深入研究人工智能，他强烈建议我开始阅读人工智能研究论文，以便在接下来的几年里适应它。然而，我发现，对于像我这样的相对新手学生来说，深入研究这些论文可能会相当艰巨（我只具备线性代数、概率和统计学的基本知识，以及对机器学习算法工作原理的一些了解）。因此，我想知道您是否可以分享任何技巧或策略来帮助我习惯这种阅读类型并充分利用它。 如果您能分享任何建议，资源或个人经验，我们将不胜感激。 提前感谢您的帮助    提交人    /u/ratybox_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9k7rq/d_tips_for_getting_used_to_reading_ai_research/</guid>
      <pubDate>Thu, 06 Jun 2024 14:58:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在这种情况下，多标签分类是最好的方法吗？我和我的经理似乎陷入了困境。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9jxt0/d_is_multilabel_classification_the_best_approach/</link>
      <description><![CDATA[我的公司处理来自智能阀门设备的设备遥测数据。它基本上是来自不同传感器和一些模拟组件的大量数字数据，例如电流和电压。无论是就特征还是样本而言，数据都非常庞大。我的经理基本上想使用机器学习来识别设备中的故障，该设备由多个子组件组成，因此一个子组件中可能存在多个故障，或者一个数据集中不同子组件中可能存在多个故障。 我之前曾使用 XGBoost 和随机森林分类器来识别单个问题，例如仅开关故障，因为那是当时的重点。我也使用 LSTM 处理过一些故障。现在有了这个新目标，基本上要用 ML 检测所有故障，我的经理希望我为所有故障单独标记和训练模型。因此，如果有 50 种类型的故障，就会有 50 个模型。  我觉得这非常低效，难以维护，除此之外，我认为它忽略了一个数据集可能有两个或三个故障的事实，并且在针对一个故障进行训练时，将所有其他故障标记为与正常数据相同的标签可能会在某种程度上产生误导。  我想使用多标签分类器。这里的约束是模型选择，因为我认为很难为某些模型编写多标签包装器，因此我们不得不依赖随机森林来发现所有故障。  你们能否就如何为此类数据选择方法和模型给出建议/提示/正反两方的论据/一般意见？ 您认为是否有可能只为 1 TB 的数据建立一个模型并通过它对所有故障进行分类？或者最好遵循我经理的方法，我觉得这违背了机器学习“学习”部分的目的。     由    /u/General_Working_3531 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9jxt0/d_is_multilabel_classification_the_best_approach/</guid>
      <pubDate>Thu, 06 Jun 2024 14:46:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 可扩展的无 MatMul 语言建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9fkkn/r_scalable_matmulfree_language_modeling/</link>
      <description><![CDATA[Arxiv link – 可扩展的无 MatMul 语言建模  [...] 在这项工作中，我们表明，MatMul 操作可以完全从 LLM 中消除，同时在十亿参数规模下保持强劲性能。我们的实验表明，我们提出的无 MatMul 模型实现了与最先进的 Transformers 相当的性能，后者在推理期间需要更多的内存，规模至少达到 2.7B 参数。我们研究了缩放规律，发现我们的无 MatMul 模型和全精度 Transformers 之间的性能差距随着模型尺寸的增加而缩小。我们还提供了此模型的 GPU 高效实现，与未优化的基线相比，在训练期间可将内存使用量降低高达 61%。通过在推理过程中使用优化的内核，与未优化的模型相比，我们的模型的内存消耗可以减少 10 倍以上。为了正确量化我们架构的效率，我们在 FPGA 上构建了一个自定义硬件解决方案，该解决方案利用了 GPU 无法实现的轻量级操作。     提交人    /u/PantsuWitch   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9fkkn/r_scalable_matmulfree_language_modeling/</guid>
      <pubDate>Thu, 06 Jun 2024 11:08:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>