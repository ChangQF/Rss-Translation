<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Tue, 21 May 2024 15:15:14 GMT</lastBuildDate>
    <item>
      <title>[P] 多项式回归博客系列中关于概率校准的帖子</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx9npr/p_a_post_on_probabilistic_calibration_in_blog/</link>
      <description><![CDATA[我个人学习伯恩斯坦基多项式回归的另一章涉及概率模型校准领域。我当然喜欢学习，我希望你也会觉得它很有趣。 系列从这里开始：https://alexshtf.github.io/2024/01/21/Bernstein.html 关于校准的最新帖子：https://alexshtf.github.io/2024/05/19/BernsteinCalibration.html   由   提交/u/alexsht1  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx9npr/p_a_post_on_probabilistic_calibration_in_blog/</guid>
      <pubDate>Tue, 21 May 2024 14:47:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 启用稀疏的基础法学硕士，以通过 Neural Magic 和 Cerebras 建立更快、更高效的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx83cs/r_enabling_sparse_foundational_llms_for_faster/</link>
      <description><![CDATA[      在 Neural Magic、Cerebras 的合作中，和 IST Austria，据我们所知，我们推出了第一个高度稀疏的基础法学硕士，在多项微调任务上完全恢复，包括聊天、代码生成、摘要等。 &lt; p&gt;热门微调任务的稀疏性与基线精度恢复Llama 2 7B 利用这些模型，我们进一步证明：  仅通过稀疏性即可在 Neural Magic 上将 CPU 的推理性能加速 3 倍，将 GPU 的推理性能加速 1.7 倍 通过量化实现复合增益，推理性能提升高达 8.6 倍。 接近利用 Cerebras CS-3 AI 加速器进行稀疏训练的理论增益。   ul&gt; 不同条件下的预填充和解码 Llama 2 7B 性能8 核 CPU 上 FP32 和 INT8 的稀疏级别。 论文：https://arxiv。 org/abs/2405.03594 模型：https://huggingface .co/collections/neuralmagic/sparse-foundational-llama-2-models-65f48cec6396309f02e74d21   由   提交/u/markurtz  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx83cs/r_enabling_sparse_foundational_llms_for_faster/</guid>
      <pubDate>Tue, 21 May 2024 13:36:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻求使用机器学习预测足球比赛结果的项目建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx7jqs/r_seeking_advice_for_project_on_predicting/</link>
      <description><![CDATA[大家好， 我目前正在写我的学士论文，重点是人工智能工程。我的项目围绕使用机器学习模型预测足球比赛结果。我研究的核心问题是：“人工智能模型能否通过分析球员得分、伤病以及专家和分析师的意见来准确预测足球比赛结果？” 到目前为止，我一直在收集数据来自各种来源，例如球员统计数据、伤病报告、专家意见以及 sofascore.com 等网站上的球迷投票等，并使用这些数据来训练预测模型。我尝试过随机森林和 LSTM 网络等模型，并且取得了一些有希望的结果。不过，我相信仍有改进的空间。 我正在联系这个社区，收集有关以下几件事的见解：  其他因素：我还应该考虑将哪些其他因素纳入我的预测模型中以提高准确性？到目前为止，我已经包含了球员表现数据、伤病报告以及专家和球迷的意见。还有其他可能有价值的数据点吗？ 模型建议：根据您的经验，您发现哪些机器学习模型对于预测运动结果特别有效，特别是足球？您有推荐的具体技术或架构吗？  我很高兴听到您的想法和建议。如果您能分享任何建议或资源，我们将不胜感激！ 提前感谢您的帮助！   由   提交 /u/Kitchen_Bike2456   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx7jqs/r_seeking_advice_for_project_on_predicting/</guid>
      <pubDate>Tue, 21 May 2024 13:11:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士作为主动学习主体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx6pif/r_llms_as_active_learning_agents/</link>
      <description><![CDATA[      TL;DR： LLM 可以用作主动学习组件，因为它们擅长寻找困难或多样化的示例 - 甚至优于小样本学习方法。 ​ 虽然 GPT-4 等 LLM 通常用于训练在我们研究较小的 BERT 类模型（伪标记或数据增强）的过程中，我们想知道它们是否也可以用作主动学习代理。与传统的主动学习相比，我们看到了 LLM 真正擅长捕捉示例的多样性和难度，并且不会面临冷启动问题的机会。传统的主动学习通常需要许多种子实例，这使得它对于 BERT 模型已经在少样本场景中取得良好性能的许多任务来说有些不具吸引力。 ​ 我们尝试使用不同的 LLM 作为主动学习组件，确实表明它们可以显着提高少样本场景下的性能： 在 GLUE 任务上使用不同 LLM 获得的少样本结果（32 个实例）。 我们还表明，使用 GPT-4 进行主动学习可以胜过少样本学习方法 SetFit： 在 AGNews 上进行比较（32 个实例） 论文： http://arxiv.org/abs/2405.10808    提交人    /u/Kaesebrot109   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx6pif/r_llms_as_active_learning_agents/</guid>
      <pubDate>Tue, 21 May 2024 12:29:43 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 有哪些关于算法公平性的好文章？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx63gy/research_what_are_some_great_articles_on/</link>
      <description><![CDATA[我目前正在准备关于算法公平性的演示，我想听听您的文章建议。如果这些文章是最近的，我会很高兴，但早期的里程碑文章也很受欢迎。    由   提交/u/berkaufman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx63gy/research_what_are_some_great_articles_on/</guid>
      <pubDate>Tue, 21 May 2024 11:57:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不同模态的数据是否应该在同一空间中表示？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx3pg9/d_should_data_in_different_modalities_be/</link>
      <description><![CDATA[由于我主要研究语言 AI，所以我习惯了多模态 AI。然而，训练方法似乎非常多样化，更不用说评估这些方法在我看来要困难得多。至少，我认为不同模态的数据应该表示在不同的空间中。有没有研究人员同意的“更好的方法（可能）”？    提交人    /u/Capital_Reply_7838   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx3pg9/d_should_data_in_different_modalities_be/</guid>
      <pubDate>Tue, 21 May 2024 09:25:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Pang Wei Koh 等人的“通过影响函数理解黑盒预测”中的推导问题。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx2u5v/d_question_about_a_derivation_in_understanding/</link>
      <description><![CDATA[我正在阅读https://arxiv.org/abs /1703.04730 并研究了附录 A 中给出的方程（1）的推导。我理解我们如何得到方程（6）-（10），但是从方程（10）到（11）的跳跃是让我感到困惑。 我也不太明白如何对方程 (10) 的 RHS 进行二阶泰勒展开，因为它是一个向量到向量函数。它们是否意味着二阶泰勒展开扰动损失函数 R(theta) + epsilon L(theta)？如果是这样的话，粗麻布不应该是二次形式的一部分吗？在方程（11）中，它们只是右乘以 delta_epsilon （不是左乘），所以它不是这种形式。    由   提交 /u/SwiftLynx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx2u5v/d_question_about_a_derivation_in_understanding/</guid>
      <pubDate>Tue, 21 May 2024 08:20:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于克隆/破解生产 FSD 来教授新 FSD 的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx2tt0/d_thoughts_on_cloninghacking_a_production_fsd_to/</link>
      <description><![CDATA[如果公司部署了明显更好的 FSD。然后你将不同汽车的视频输入FSD，并用这些动作来监督新的FSD..  抛开合法性和规模，这似乎是可行且不可避免的？要么是国家演员，要么是西方制造商想要获得最后的 9？​​ 想法 ??   由   提交/u/yazriel0  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx2tt0/d_thoughts_on_cloninghacking_a_production_fsd_to/</guid>
      <pubDate>Tue, 21 May 2024 08:19:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您是否尝试过使用 Intel 和 AMD GPU 来训练模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwvoaq/r_have_you_give_a_try_to_use_intel_and_amd_gpus/</link>
      <description><![CDATA[NVIDIA 统治着数据中心 GPU 市场。最常用的 ML 框架支持 NVIDIA GPU。但我想知道使用 Intel 和 AMD GPU 训练 ML 模型的缺点和优点。您有使用过这些 GPU 的经验吗？您对性能、可用​​性、软件堆栈和生态系统有何看法？   由   提交/u/Various_Protection71   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwvoaq/r_have_you_give_a_try_to_use_intel_and_amd_gpus/</guid>
      <pubDate>Tue, 21 May 2024 01:05:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 动漫人物的 Wav2Lip？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwudpo/d_wav2lip_for_anime_characters/</link>
      <description><![CDATA[大家好。我看到了 Wav2Lip，这是一个开源软件，用于根据单个图像和音频创建“深度伪造”头像。有没有类似的东西，但明确针对动漫 2D 角色？仅开源！   由   提交 /u/yukiarimo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwudpo/d_wav2lip_for_anime_characters/</guid>
      <pubDate>Tue, 21 May 2024 00:01:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习真的对人类健康产生了影响吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwsbyw/d_has_ml_actually_moved_the_needle_on_human_health/</link>
      <description><![CDATA[我们听说机器学习用于药物发现、精准医疗、个性化治疗等已有相当一段时间了。机器学习实际上通过哪些方式改善了人类健康？ 似乎大多数治疗和诊断仍然基于数十年的专注生物学研究，而不是某种公正的机器学习方法。放射学是一个值得注意的例外，它受益于机器视觉的进步，但即使是他们似乎也很慢地接受人工智能作为临床实践。   由   提交/u/Potential_Athlete238  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwsbyw/d_has_ml_actually_moved_the_needle_on_human_health/</guid>
      <pubDate>Mon, 20 May 2024 22:26:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有 ML/AI 相关主题的阅读小组/期刊俱乐部？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwrteq/d_are_there_any_reading_groupsjournal_clubs_for/</link>
      <description><![CDATA[嗨，有谁知道是否有任何阅读小组/期刊俱乐部，人们定期分享书籍章节或论文？如果可能的话，让一些阅读同一本书/论文的人分享他们的想法/想法可能会很好。谢谢！   由   提交 /u/Illustrious-Pay-7516   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwrteq/d_are_there_any_reading_groupsjournal_clubs_for/</guid>
      <pubDate>Mon, 20 May 2024 22:04:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 多模态模型能否区分图像和文本？就像如果文本标记和图像标记是接近的向量一样，模型是否能够“判断”它是否正在阅读或看到？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwoh51/d_can_multimodal_models_tell_images_apart_from/</link>
      <description><![CDATA[我在使用多模式模型进行一些工作时遇到了这个问题。他们似乎无法区分信息的哪一部分来自输入的文本部分和图像部分。  有这方面的研究吗？    由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwoh51/d_can_multimodal_models_tell_images_apart_from/</guid>
      <pubDate>Mon, 20 May 2024 19:44:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI 是如何从从事令人兴奋的研究变成一家类似大型科技公司的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</link>
      <description><![CDATA[我最近重新审视了 OpenAI 关于 DOTA2 Open 的论文五，从工程和研究的角度来看，他们在那里所做的事情令人印象深刻。创建一个包含 50k 个 CPU 的分布式系统用于部署，1k 个 GPU 用于训练，同时每 0.25 秒从 16k 个观察中执行 8k 到 80k 个操作 - 这有多疯狂？他们还对 RL 模型进行“手术”以恢复权重，因为在几个月的训练中，他们的奖励函数、观察空间甚至架构都发生了变化。最后但并非最不重要的一点是，他们击败了 OG 队（当时的世界冠军），并部署了代理与其他玩家在线实时比赛。  快进几年，他们正在预测序列中的下一个标记。不要误会我的意思，gpt4 及其全能版本的功能确实是工程和研究的惊人壮举（可能更有用），但它们似乎并不像它们的一些产品那样有趣（从研究角度来看）  那么，现在我想知道这些年来工程师和研究人员是如何转变的？主要是由于他们的财务状况和盈利需要，还是有更深层次的原因进行转型？   由   提交 /u/UnluckyNeck3925   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvslyc/d_how_did_openai_go_from_doing_exciting_research/</guid>
      <pubDate>Sun, 19 May 2024 16:46:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>