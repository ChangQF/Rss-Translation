<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 13 Oct 2024 03:24:11 GMT</lastBuildDate>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 13 Oct 2024 02:15:21 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 增加Yolov8图像分割模型的数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2esrc/project_increasing_data_in_yolov8_image/</link>
      <description><![CDATA[大家好， 我正在训练一个 YOLOv8 图像分割模型。我想增加数据集。有没有办法在训练期间增加数据集。 例如，我过去训练过一个 CNN 模型，并且在训练期间为每个图像生成了 100 个增强图像以增加数据集。该 CNN 模型的数据增强参数如下所示。 datagen = ImageDataGenerator( rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, sher_range=0.1, zoom_range=0.1, Horizo​​ntal_flip=True, Vertical_flip = True, fill_mode=&#39;nearest&#39; )  有没有办法用上面相同的参数对 YOLO 图像分割模型（每个图像生成 100 个图像）做同样的事情。我知道我必须在 .yaml 文件中为增强参数输入自定义值，但是，如果有人能为我提供信息，说明我需要在 .yaml 文件中更改哪些自定义参数才能实现上述配置，那就太好了。此外，如果有办法在训练期间为每个图像生成 100 张图像，标签中 .txt 文件中的多边形坐标是否会根据应用的增强参数自动调整。 如果您需要更多说明，请告诉我。 谢谢    提交人    /u/sahil_m00   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2esrc/project_increasing_data_in_yolov8_image/</guid>
      <pubDate>Sun, 13 Oct 2024 01:27:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻找可以在浏览器中完全本地运行的轻量级嵌入模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2ep9v/d_looking_for_lighweight_embeddings_model_that/</link>
      <description><![CDATA[我广泛使用了 OpenAI 嵌入端点和 Google 的 Universal Sentence Encoder (USE)。我正在为那些不希望将数据发送到*任何地方*的人开展一个项目。因此，我正在尝试看看我是否可以想出一个完全本地的实现，我可以在其中为他们存储文本，然后完全在本地对该数据进行余弦相似度搜索。我希望找到一个轻量级的嵌入模型，它可以严格在典型 PC 上的浏览​​器中运行，并且在激活时不会下载任何模型，因为所有这些都打破了隐私约束。 有人见过类似的东西吗？如果有，请留下链接。我的网络搜索和 ChatGPTPlus 讨论尚未取得成果。    提交人    /u/vengeful_bunny   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2ep9v/d_looking_for_lighweight_embeddings_model_that/</guid>
      <pubDate>Sun, 13 Oct 2024 01:21:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解流匹配</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2dpm8/d_understanding_flow_matching/</link>
      <description><![CDATA[我有点难以理解流匹配论文。是否有一些课程可以让我更好地理解这一点。 就上下文而言，我相当了解 ddpm，并在一定程度上了解 ddim。但是，我无法理解它的 ODE 方面。 流匹配论文讨论了很多关于矢量场和 ODE 的内容。如果您能推荐一篇论文/课程来理解这方面的内容，我将不胜感激。YouTube 上有一些关于统计力学的课程。这是否相关，或者考虑到我可以理解变分贝叶斯，是否有更好的起点？ TIA    提交人    /u/themathstudent   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2dpm8/d_understanding_flow_matching/</guid>
      <pubDate>Sun, 13 Oct 2024 00:25:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大信号模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2b98h/r_large_signal_models/</link>
      <description><![CDATA[在人工智能领域，大信号模型支持以人为中心的交互和信号数据的知识发现，类似于提示允许用户根据来自网络的非结构化文本查询 LLM 的方式。 用户可以询问有关焦点数据集与基于大量域的信号数据集构建的预编译 LSTM 结果之间关系的一般问题。这是通过将潜在模式检测和基于知识图谱 (KG) 的可解释性分层到 LSTM 推理管道中来实现的。 我们发现一些大型 F500 客户使用这项技术取得了巨大成功，但似乎每个人都继续专注于 LLM，即使他们面临幻觉挑战。 是否有一个社区专注于使用新方法应对幻觉挑战？    提交人    /u/PrizeDry8179   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2b98h/r_large_signal_models/</guid>
      <pubDate>Sat, 12 Oct 2024 22:14:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML 项目的反馈：使用 Transformers 改进蚁群优化算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g21loo/d_feedback_on_ml_project_using_transformers_to/</link>
      <description><![CDATA[我目前正在从事一个个人项目，尝试构建一个改进版本的蚁群优化算法。 在运行算法之前，我使用位置编码变压器神经网络来预测最佳信息素矩阵。 改进的蚁群优化算法使用位置编码变压器神经网络输出的信息素矩阵进行初始化，该网络使用来自普通蚁群优化算法的信息素矩阵数据进行训练。 为了分析算法的改进，我让改进的 ACO 与普通 ACO 一起运行不同地图大小的多次迭代，计算每个算法的最佳运行，并计算 p 值以验证改进的算法是否具有统计意义。 到目前为止，增强型 ACO 显示出令人满意的结果，对于节点大小为 30 和 35，p 值分别为 0.06 和 0.05。  但是，我的目标是在更大范围的节点大小中实现显著性 (p &lt; 0.05)。 我将不胜感激任何反馈！ 项目链接：https://github.com/ronantakizawa/improvedaco/blob/main/ronan_acotransformer_experiment.ipynb    提交人    /u/SafeSignificance8840   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g21loo/d_feedback_on_ml_project_using_transformers_to/</guid>
      <pubDate>Sat, 12 Oct 2024 14:42:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何改进 img2img 以实现（稳定的）扩散模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g20kgi/d_how_to_improve_img2img_for_stable_diffusion/</link>
      <description><![CDATA[图像生成人员，我们都熟悉用于扩散模型的 img2img 方法，其中输入图像用于调节扩散过程并产生输入图像的变化（也使用引导提示）。这是由 Automatic1111、ComfyUI、Invoke AI 实现的，并在许多论文中使用。 在此方法中，允许控制的参数是去噪强度，它对应于在对图像进行去噪之前向图像添加的噪声步骤百分比（由输入提示调节）。 我想知道这种简单的方法在过去两年中是否有所改进。 我知道你可以使用 img2img 进行修复（img2img 的局部区域而不是整个图像）或修复。我特别想找一些尝试不同的 img2img 方法并比较获得的结果的论文。如果有人能指出论文，那将会很有帮助！    提交人    /u/gohu_cd   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g20kgi/d_how_to_improve_img2img_for_stable_diffusion/</guid>
      <pubDate>Sat, 12 Oct 2024 13:51:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] GSM-Symbolic：理解大型语言模型中数学推理的局限性（Apple）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1wbir/r_gsmsymbolic_understanding_the_limitations_of/</link>
      <description><![CDATA[arXiv:2410.05229 [cs.LG]: https://arxiv.org/abs/2410.05229 Iman Mirzadeh、Keivan Alizadeh、Hooman Shahrokhi、Oncel Tuzel、Samy Bengio、Mehrdad Farajtabar - Apple TechCrunch - Devin Coldewey：研究人员质疑人工智能的“推理”能力，因为模型在解决数学问题时会遇到一些细微的变化：https://techcrunch.com/2024/10/11/researchers-question-ais-reasoning-ability-as-models-stumble-on-math-problems-with-trivial-changes/ 共同作者之一 Mehrdad Farajtabar 在 X 上的这个帖子中分解了这篇论文：https://x.com/MFarajtabar/status/1844456880971858028    由   提交  /u/Nunki08   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1wbir/r_gsmsymbolic_understanding_the_limitations_of/</guid>
      <pubDate>Sat, 12 Oct 2024 09:20:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 奖励进展：扩展 LLM 推理的自动化流程验证器（来自 Deepmind 的研究）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1uf90/r_rewarding_progress_scaling_automated_process/</link>
      <description><![CDATA[摘要：使用过程奖励模型 (PRM) 是改进大型语言模型推理的一种有前途的办法。PRM 在多步推理跟踪的每个步骤中提供反馈，与仅在最后一步提供反馈的结果奖励模型 (ORM) 相比，可能改善信用分配。然而，收集密集的、每步的人工标签是不可扩展的，并且迄今为止，从自动标记的数据训练 PRM 只带来了有限的收益。为了通过针对 PRM 运行搜索或将其用作强化学习 (RL) 的密集奖励来改进基础策略，我们问：“我们应该如何设计过程奖励？”。我们的主要见解是，为了有效，步骤的过程奖励应该衡量进展：在采取该步骤之前和之后，未来产生正确响应的可能性的变化，对应于 RL 中的步骤级优势概念。至关重要的是，应该在不同于基础策略的证明者策略下衡量这一进展。我们从理论上描述了一组好的证明器，我们的结果表明，优化此类证明器的过程奖励可改善测试时搜索和在线 RL 中的探索。事实上，我们的表征表明，弱证明器策略可以显著改善更强大的基础策略，我们也通过经验观察到了这一点。我们通过训练过程优势验证器 (PAV) 来预测此类证明器下的进度，从而验证了我们的说法，并表明与 ORM 相比，针对 PAV 的测试时搜索准确率提高了 8% 以上，计算效率提高了 1.5-5 倍。与 ORM 相比，具有来自 PAV 的密集奖励的在线 RL 实现了首批结果之一，样本效率提高了 5-6 倍，准确率提高了 6% 以上。    提交人    /u/DickMasterGeneral   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1uf90/r_rewarding_progress_scaling_automated_process/</guid>
      <pubDate>Sat, 12 Oct 2024 06:52:02 GMT</pubDate>
    </item>
    <item>
      <title>核技巧（RKHS）应用于逻辑：语义空间框架中的逻辑属性和量词</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1sfz2/the_kernel_trick_rkhs_applied_to_logic_logical/</link>
      <description><![CDATA[        由    /u/musescore1983   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1sfz2/the_kernel_trick_rkhs_applied_to_logic_logical/</guid>
      <pubDate>Sat, 12 Oct 2024 04:33:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAAI 2025 第一阶段决议泄露？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1plva/d_aaai_2025_phase_1_decision_leak/</link>
      <description><![CDATA[是否有人检查过 AAAI 提交的修订部分并注意到该论文已移至文件夹“Rejected_Submission”。它应该在 Venueid 标签下可见。我从推特帖子中了解到这一点： https://x.com/balabala5201314/status/1843907285367828606    提交人    /u/Wise_Witness_6116   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1plva/d_aaai_2025_phase_1_decision_leak/</guid>
      <pubDate>Sat, 12 Oct 2024 01:43:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么看起来谷歌的 TPU 对 nVidia 的 GPU 不构成威胁？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1okem/d_why_does_it_seem_like_googles_tpu_isnt_a_threat/</link>
      <description><![CDATA[尽管谷歌在其许多内部 AI 工作中使用了 TPU，但似乎并没有像 nVidia 的 GPU 那样推动其收入增长。这是为什么？为什么拥有自己的 AI 设计的处理器没有像 nVidia 那样对他们有所帮助，为什么所有其他专注于 AI 的公司似乎仍然只想在 nVidia 芯片上运行他们的软件……即使他们使用的是谷歌数据中心？    提交人    /u/kugelblitz_100   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1okem/d_why_does_it_seem_like_googles_tpu_isnt_a_threat/</guid>
      <pubDate>Sat, 12 Oct 2024 00:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[N] Kaido Orav 和 Byron Knoll 的 fx2-cmix 赢得 7950 欧元的 Hutter 奖！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1l725/n_kaido_orav_and_byron_knolls_fx2cmix_wins_7950/</link>
      <description><![CDATA[Kaido Orav 和 Byron Knoll 凭借其&quot;fx2-cmix&quot; 参赛作品在 人类知识无损压缩 Hutter 奖 上提高了 1.59%。由于 Hutter 奖将参赛者限制为单一&quot;通用处理器，并使用&quot;https://www.youtube.com/watch?v=AKMuA_TVz3A&quot;&gt;最&quot;通用的损失函数，因此所需的算法进步&quot;通常适用，无论业界的&quot;硬件彩票&quot; 或损失函数妥协如何。在这方面，它为机器学习的科学进步提供了独特且低风险的激励。  与之前的 Hutter 奖获奖算法相比，fx2-cmix 的一些算法进步如下：  混合器和预测器：当错误低于某个阈值时，混合器现在会跳过权重更新，从而提高处理速度。  单次传递 维基百科转换：此更新通过将转换过程从以前的多步骤方法简化为单次传递，减少了处理维基百科等大型数据集所需的时间和磁盘使用量，从而显著加快了预处理阶段。  新的词干和上下文方法：利用自然语言处理技术（如词干过程中的新词类型）来创建更紧凑、更相关的词流。这不仅提高了训练数据的质量，而且还增强了压缩能力，降低了存储要求。  高效的文章排序：通过将整个文章嵌入到大向量中并使用 t-SNE 将其减少到单个维度，可以快速重新排序整个语料库以进一步加快训练速度。  有关进展的详细描述以及 Jupyter 笔记本和其他文档可在 fx2-cmix README 中找到。     提交人    /u/jabowery   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1l725/n_kaido_orav_and_byron_knolls_fx2cmix_wins_7950/</guid>
      <pubDate>Fri, 11 Oct 2024 21:56:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 复合学习单元：超越参数更新的广义学习，将 LLM 转变为自适应推理机</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g1gtns/r_composite_learning_units_generalized_learning/</link>
      <description><![CDATA[  由    /u/jalabulajangs  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g1gtns/r_composite_learning_units_generalized_learning/</guid>
      <pubDate>Fri, 11 Oct 2024 18:37:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>