<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Tue, 23 Jul 2024 15:16:26 GMT</lastBuildDate>
    <item>
      <title>[D] 为应届毕业生举办法学硕士 (LLM) 研讨会游戏化的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eaa0iu/d_ideas_for_gamifying_an_llm_workshop_for_new/</link>
      <description><![CDATA[大家好， 我正在寻找一些想法，将针对新加入公司的大学毕业生的法学硕士学位研讨会游戏化。计划是在上半天进行动手实验室练习，然后在下半天进行黑客马拉松或游戏。我们总共有大约 6 小时的工作时间。 一些背景：我之前在这些学生实习期间为他们举办了一个 3 小时的研讨会，涵盖了 gen AI、法学硕士学位的基础知识，以及为 PDF 构建一个简单的基于 RAG 的聊天机器人。由于工作笔记本电脑的系统限制，并非每个人都能完成动手部分。 现在他们全职加入，这个研讨会是他们 3 个月培训计划的一部分。我正在尝试改进上一次会议。作为背景，去年 AWS 举办了一次 DeepRacer 研讨会，最后以一场比赛来应用所学知识。我的目标是在 LLM 中实现类似的东西——也许是一个可以作为 LLM 代理的游戏或活动，允许他们在竞争环境中应用 RAG 和函数调用等概念。 挑战在于参与者的编程技能水平各不相同。我正在寻找一种适合初学者的东西，但也足够充实，让每个人都能学到一些超越基本提示工程的东西。 如果您有任何想法或需要更多信息，请告诉我。我愿意接受有关如何让这成为新毕业生有效学习体验的建议。    提交人    /u/nerdimite   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eaa0iu/d_ideas_for_gamifying_an_llm_workshop_for_new/</guid>
      <pubDate>Tue, 23 Jul 2024 15:01:33 GMT</pubDate>
    </item>
    <item>
      <title>在数字序列中寻找模式[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea8ulk/finding_patterns_in_a_number_sequence_p/</link>
      <description><![CDATA[我有一个随机生成的数字序列，假设它们只能是 1-40 的数字。如果这个序列有数千个数字，如果我想寻找可能的模式以便至少能够大致预测下一个数字，我应该从哪里开始？是否有任何免费程序可以让我输入数据集并对其进行模式分析？所有数字都是“随机生成的”，但整个序列是作为一个整体提前生成的，而不是实时生成的数字。我不知道这是否有任何区别。此时，我只是想弄清楚我可以从哪里开始，任何信息都值得赞赏！    提交人    /u/Gang_StarrWoT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea8ulk/finding_patterns_in_a_number_sequence_p/</guid>
      <pubDate>Tue, 23 Jul 2024 14:12:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 导入 torch_tensorrt 时出错</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea8n2y/d_error_importing_torch_tensorrt/</link>
      <description><![CDATA[大家好 我正在尝试首次使用 torch_tensorrt。  我尝试使用 pip install torch-tensorrt 安装它，并且它工作正常，但是，当我尝试将它导入我的代码时，我收到一条错误消息： OSError：libtorchtrt.so：未定义符号：_ZNK3c105Error4whatEv。  有人知道如何解决这个问题吗？我在互联网上找不到任何东西    提交人    /u/Top-Establishment545   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea8n2y/d_error_importing_torch_tensorrt/</guid>
      <pubDate>Tue, 23 Jul 2024 14:03:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] scikit-activeml：Python 中的主动学习库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea8kc8/p_scikitactiveml_an_active_learning_library_in/</link>
      <description><![CDATA[ TL;DR：我们的主动学习库 scikit-activeml 中应该包含哪些有趣的功能和当前的主动学习研究趋势？  大家好， 我们已经在 scikit-activeml 上工作了几年，我们刚刚发布了具有许多新功能的版本 0.5.0。 什么是 scikit-activeml？ scikit-activeml 是一个全面的 Python 库，建立在 scikit-learn。它为主动学习策略提供了一个易于使用的界面，通过有选择地选择最“信息丰富”的数据来实现高效的数据标记。样本。 scikit-activeml 的主要功能是什么？  从研究论文中实现和概述许多（最先进的）主动学习策略。 支持各种学习范式，从基于池和基于流的主动学习到分类和回归任务，包括考虑多个错误注释者的策略。 广泛的文档，其中包含许多可视化和教程，涵盖各种用例，例如，用于促进主动学习的自我监督学习功能或用于标记新数据集的简单界面。 集成其他框架，如用于深度主动学习的 skorch 和用于基于流的主动学习的 river。  scikit-activeml应该支持哪些主动学习功能和趋势？ 我们想讨论一下您认为主动学习中的重要特征和研究趋势。目前，我们专注于以下方面：  有意义的评估：我们执行大规模基准测试，比较不同模型和主动学习设置的各种数据域和任务中的主动学习策略。结果将发布在一个交互式网站上，用户可以在其中绘制学习曲线并下载结果。此外，我们正在努力将主动学习任务集成到openml中，以允许用户轻松公开和比较他们的结果。 更多学习范式：我们目前专注于回归和分类任务，包括来自多个容易出错的注释者的嘈杂标签场景。鉴于具有多个目标变量的应用程序的重要性，我们的目标是在未来探索用于回归和分类（即多标签）的多输出主动学习策略。 深度主动学习：我们已经开始结合深度主动学习策略，如 DAL、CoreSet、BADGE 和 TypiClust。我们的目标是继续这些实施工作，特别是自我监督学习功能。  作为主动学习研究人员和从业者，您对我们应该考虑的功能和趋势还有其他想法吗？ 如何为 scikit-activeml做出贡献？ 我们一直在寻找各种形式的有用贡献：  加入我们的开源开发人员团队。 指出代码和文档中的错误。 请求新功能，例如新颖的主动学习策略（甚至您自己的策略）。  欢迎通过评论、问题或通过 Reddit 上的直接短信与我们联系。 GitHub：https://github.com/scikit-activeml/scikit-activeml/tree/master 文档：https://scikit-activeml.github.io/scikit-activeml-docs/    提交人    /u/ScienceAnnotator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea8kc8/p_scikitactiveml_an_active_learning_library_in/</guid>
      <pubDate>Tue, 23 Jul 2024 14:00:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] DataChain：使用本地模型和 LLM 调用来管理非结构化数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea881b/p_datachain_curate_unstructured_data_using_local/</link>
      <description><![CDATA[你好！我们今天开源 DataChain：https://github.com/iterative/datachain！它的作用：  从 S3/GCS/Azure/local 读取数据 &amp;版本数据集 应用转换：本地模型推理、外部 LLM 调用或自定义代码 通过 Pydantic 将 Python 对象存储在内部数据库（SQLite）中或导出到 parquet/CSV 文件中 高效并行运行代码，无需内存，可在笔记本电脑中处理数百万个文件 执行矢量化操作：相似度搜索嵌入、总和、平均值等。  示例 - 使用 Mistral 评估聊天机器人对话： from datachain import DataChain, Column from mistralai.client import MistralClient from mistralai.models.chat_completion import ChatCompletionResponse, ChatMessage def eval_dialogue(file: File) -&gt; ChatCompletionResponse: return MistralClient().chat( model=&quot;open-mixtral-8x22b&quot;, messages=[ChatMessage(role=&quot;system&quot;, content=PROMPT), ChatMessage(role=&quot;user&quot;, content=file.read())]) chain = ( DataChain.from_storage(&quot;gs://datachain-demo/chatbot-KiT/&quot;) .settings(parallel=4, cache=True) .map(response=eval_dialogue) .save(&quot;mistral_dataset&quot;) )  在底层，DataChain 利用 Pydantic 序列化 Python 对象；SQLite 作为元存储并执行矢量化操作，DVC 用于处理数据存储。 WDYT?渴望听到您的想法！    由   提交  /u/dmpetrov   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea881b/p_datachain_curate_unstructured_data_using_local/</guid>
      <pubDate>Tue, 23 Jul 2024 13:45:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 C++/C 优化模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea87qq/d_optimizing_models_with_cc/</link>
      <description><![CDATA[您是否真的在普通解决方案公司中使用 C++ 来优化模型？如果是，您认为有什么资源可以学习如何做到这一点？    提交人    /u/AdOk6683   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea87qq/d_optimizing_models_with_cc/</guid>
      <pubDate>Tue, 23 Jul 2024 13:45:11 GMT</pubDate>
    </item>
    <item>
      <title>[N] 首个 Embedding 模型训练平台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea7h0t/n_the_first_embedding_model_training_platform/</link>
      <description><![CDATA[Marqo 刚刚宣布推出 Marqtune：一个嵌入模型训练平台！ 他们在其训练框架广义对比学习 (GCL) 的基础上构建了 Marqtune。借助 GCL，您可以微调嵌入模型，不仅根据语义相关性对搜索结果进行排名，还可以根据您定义的排名系统对搜索结果进行排名。这意味着可以得到更好、更相关的搜索结果，以满足业务需求。 “Marqtune 是根据我们客户的反馈而开发的。生产中的每个向量搜索系统都需要不断地重新训练和更新其模型。手动执行此操作根本不可行，”Marqo 首席执行官兼联合创始人 Tom Hamer 表示。 “Marqtune 引入了一种用户友好的嵌入模型微调流程，并允许用户以最小的工程工作量实现搜索相关性的显着改进。” 开始使用 Marqtune 论文：https://arxiv.org/pdf/2404.08535 更多信息 代码   由    /u/elliesleight  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea7h0t/n_the_first_embedding_model_training_platform/</guid>
      <pubDate>Tue, 23 Jul 2024 13:11:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能可以写诗，但数学却很差</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea7d6v/d_ai_can_write_poetry_but_it_struggles_with_math/</link>
      <description><![CDATA[      我无法放置这篇纽约时报文章的链接，因为它需要付费才能阅读。但它基本上是说神经网络不能一直正确地进行数学运算，甚至不能以足够的精度进行数学运算。我很惊讶地看到 Le Chun 博士直接反驳了 Gregory Hinton 关于 ChatGPT 是否可以进行逻辑运算的观点。他们两人因在神经网络方面的贡献而获得了 Turning Prize。 无论如何，文章说某些 AI 工具（如 chatgpt）正在使用其他工具进行大规模乘法运算，也许还可以解决代数问题。这意味着它衍生出基于规则的例程而不是神经网络。（Matlab 可以解决任何数学问题。所以他们必须插入类似的东西。） 我使用它编写代码的经验是它当然可以解决几乎所有 Python 编程代码问题。那么你怎么看？chatGPT 可以做逻辑吗？是的，我同意它可能不能做所有的数学运算。 Chun 博士和 Hinton 博士的评论如下。 https://preview.redd.it/n0awbx3wo9ed1.png?width=1900&amp;format=png&amp;auto=webp&amp;s=5dabde60333dda6052df58a02024b5f226ad0a0e Gregory Hinton 在 60 分钟电视节目中给出了这个例子，以表明 AI 可以进行逻辑推理。 “我家里的房间都漆成了白色，蓝色或黄色。黄色油漆在一年内会褪色为白色。两年后，我希望所有的房间都变成白色。我该怎么办？” ChatGPT-4 迅速做出回应，建议涂成蓝色的房间需要重新粉刷，而黄色的房间不需要重新粉刷，因为它们会在截止日期前褪色为白色。它还警告不要将黄色房间漆成白色，因为黄色褪色时可能会出现颜色不匹配的风险，并指出重新粉刷黄色房间会浪费资源，因为它们会自然变白。 Hinton 表示，他认为这表明了人工智能的理解和推理水平，挑战了此类系统仅执行统计预测的观念。他表示，“我相信它肯定能理解”，并推测五年后，人工智能可能能够比人类更好地推理。 以下是《纽约时报》文章的摘录： “人工智能聊天机器人很难做数学题，因为它们从来就不是为数学设计的，”西北大学计算机科学教授兼人工智能研究员克里斯蒂安·哈蒙德 (Kristian Hammond) 说。 在最近的一次研讨会上，可汗学院 (Khan Academy) 首席学习官克里斯汀·迪塞博 (Kristen DiCerbo) 介绍了数学准确性这一主题。可汗学院是一家教育非营利组织，正在 试验人工智能聊天机器人导师和助教。迪塞博博士告诉教育工作者：“这是一个问题，你们很多人都知道。” 几个月前，可汗学院对其人工智能导师 Khanmigo 进行了重大改变。它将许多数字问题发送给计算器程序，而不是要求人工智能解决数学问题。在等待计算器程序完成时，学生们在屏幕上看到“做数学”字样和一个点头的 Khanmigo 图标。 “我们实际上正在使用用于做数学的工具，”DiCerbo 博士说，他仍然乐观地认为对话聊天机器人将在教育中发挥重要作用。 大型语言模型，LeCun 博士说，几乎不理解逻辑，缺乏常识推理。他坚持认为，需要一种更广泛的方法，他称之为“世界建模”，或者可以像人类一样学习世界如何运作的系统。这可能需要十年左右的时间才能实现。    提交人    /u/cyprusgreekstudent   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea7d6v/d_ai_can_write_poetry_but_it_struggles_with_math/</guid>
      <pubDate>Tue, 23 Jul 2024 13:06:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士类人记忆研究新成果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea5v1v/r_new_work_on_humanlike_memory_for_llms/</link>
      <description><![CDATA[新研究表明，人们可以通过使用认知生物学中的思想（即人类大脑的情景记忆）来改善 LLM 的背景。  查看：https://arxiv.org/pdf/2407.09450     提交人    /u/Ok_Can2425   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea5v1v/r_new_work_on_humanlike_memory_for_llms/</guid>
      <pubDate>Tue, 23 Jul 2024 11:50:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 多输出回归可根据 ROAS 和其他功能预测成本和收入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ea58i4/p_multi_output_regression_to_predict_cost_and/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ea58i4/p_multi_output_regression_to_predict_cost_and/</guid>
      <pubDate>Tue, 23 Jul 2024 11:14:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] haipera - 一个开源工具，用于为 Python 笔记本和脚本配置配置，无需编写任何代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e9xrsn/p_haipera_an_open_source_tool_to_instrument/</link>
      <description><![CDATA[TL;DR：我制作了一个开源（apache 2）工具（https://github.com/haipera/haipera），以便更轻松地使用简单的脚本和笔记本进行超参数扫描。 大家好！我已经在 ML / CV 领域进行了 7 年的研究，我一直对自己花在编写检测代码而不是编写算法上的时间感到沮丧。我所说的检测代码是指：配置管理、配置日志记录、一般日志记录、实验跟踪等... 在我的职业生涯中，我编写了无数的数据类、yaml 文件、json 文件和更多代码，以便通过层层的类层次结构传递这些配置对象的参数 - 只是为了发现我尝试的任何实验都没有结果，现在不得不删除我刚刚添加的内容。经常重复的模因是“机器学习研究人员只做超参数扫描”，但现实是，我们实际上编写代码来传递这些超参数，以便我们可以进行扫描。 这在将代码传输给产品团队时会导致更多问题；产品团队获得的代码包含 600 行 argparse 和从 argparse 复制到初始化程序的代码；这些代码经常有错误并且使跨项目兼容性变得困难。  我也有很多朋友在/曾经在配置系统上工作，试图解决这个问题 - 从 Hydra 到 tyro 到 dysweep 到无数的内部工具。我也是其中之一，但问题是这些库往往变得越来越复杂......因为它们试图变得更“健壮”和更少损坏。编写更多代码几乎永远不是解决方案。 所以我想尝试一种新的范式，它完全抛弃了插桩代码，并依赖于静态解析来插桩代码。这意味着您不必编写一行代码即可为您的代码启用配置之类的功能。最近，随着更好的解析库（如 ast 和 libcs​​t）的出现，这成为可能。展望未来，LLM 也拥有很多令人兴奋的潜力。  这一切是如何运作的？ 给定一个脚本，如下所示： num_apples = 100 apple_price = 3.0 print(&quot;# apples: &quot;, num_apples) print(&quot;price of an apple: &quot;, apple_price) price = num_apples * apple_price print(&quot;total: &quot;, price)  您只需执行 pip install haipera，然后就可以使用 haipera run script.py 运行脚本。您可以运行 haipera run script.py --help 以查看变量是否可直接从 CLI 编辑（目前仅支持全局变量和数字、布尔值、字符串等原始类型）。您可以运行类似 haipera run script.py --apple-price 1.0 的程序来直接从 CLI 设置参数。 当您使用 haipera 运行时，它将在 reports 中创建自己的实验文件夹，并使用自动生成的配置文件填充它，您可以直接重新运行该文件以实现可重复性。 如果您想进行网格扫描，您只需传入多个参数，如 haipera run script.py --num-apples 1,2,3 --apple-price 2.0,3.0,4.0。  您还可以做其他事情，例如 haipera run script.ipynb 以 运行 笔记本作为脚本（如果您想在笔记本内进行开发，但要使用配置作为脚本运行大量实验，这很方便）或 haipera notebook script.ipynb --opt1 2 使用提供的配置启动笔记本的新变体。事实证明，这对于对笔记本进行版本控制也很方便！ 我对这个库感到非常兴奋，并一直从我的研究员朋友那里得到反馈，但我想向大家展示并收集反馈。我们计划使这个库的功能更加完善（例如支持更多类型的变量，通常使一切更加强大，并添加对 GPU 分析工具等的支持） - 但在此之前，我们想听听大家对此的看法，并听听您希望 MLOps 工具中存在哪些类型的功能。 让我们知道您的想法！ https://github.com/haipera/haipera    由    /u/dromger 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e9xrsn/p_haipera_an_open_source_tool_to_instrument/</guid>
      <pubDate>Tue, 23 Jul 2024 03:24:55 GMT</pubDate>
    </item>
    <item>
      <title>投影头之后的自监督学习权重初始化 [D][R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e9ntgm/selfsupervised_learning_weights_initialization/</link>
      <description><![CDATA[对于大多数自监督学习算法：SimCLR、MoCo、BYOL、SimSiam、SwAV 等，在基础编码器（大多数情况下是原始 ResNet-50 CNN）之后通常有一个投影头。这种投影的一个示例（取自 SwAV）如下： projection_head = nn.Sequential( nn.Linear(2048, 512), nn.BatchNorm1d(512), nn.ReLU(inplace=True), nn.Linear(512, 128), )  此投影头的输出是 L2 归一化的： x = project_head(x) x = nn. functional.normalize(x, dim = 1, p = 2)  我试图将投影头后的层初始化为： wts = nn.Parameter(data = torch.empty(40 * 40, 128), require_grad = True) # 投影头输出范围为 [-1, 1] 的权重，因此将 SOM 权重初始化为该范围 - wts.data.uniform_(-1.0, 1.0)  由于投影头的输出是 L2 归一化的，我假设输入范围为 &quot;wts&quot; ∈ [-1, 1]，因此使用上面的统一初始化。 这是正确的方法还是我遗漏了什么？    提交人    /u/grid_world   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e9ntgm/selfsupervised_learning_weights_initialization/</guid>
      <pubDate>Mon, 22 Jul 2024 20:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[P] TTSDS – 对最近的 TTS 系统进行基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e9ec0m/p_ttsds_benchmarking_recent_tts_systems/</link>
      <description><![CDATA[TL;DR - 我为 TTS 做了一个基准测试，您可以在此处查看结果：https://huggingface.co/spaces/ttsds/benchmark 目前有很多 LLM 基准测试，虽然它们并不完美，但它们至少概述了哪些系统在哪些任务上表现良好。文本转语音系统没有类似的东西，所以我决定用我的最新项目来解决这个问题。 我们的想法是找到与不同因素相对应的语音表示：例如韵律、可理解性、说话者等 - 然后根据 Wasserstein 距离计算合成语音与真实数据和噪声数据的分数。我在论文 (https://www.arxiv.org/abs/2407.12707) 中对此进行了更详细的介绍，但我也很乐意在这里回答任何问题。 然后，我将这些因素汇总为一个与合成语音整体质量相对应的分数 - 该分数与从 2008 年的论文一直到 huggingface 最近发布的 TTS Arena 的人工评估分数有很好的相关性。 任何人都可以此处提交自己的合成语音。并且我还将在未来几周内添加更多模型。离线运行基准测试的代码位于此处。    提交人    /u/cdminix   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e9ec0m/p_ttsds_benchmarking_recent_tts_systems/</guid>
      <pubDate>Mon, 22 Jul 2024 13:29:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 神经网络经过训练，能够使用少 50 倍的数据准确预测分子的最佳几何形状</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e98s8l/r_neural_networks_have_been_trained_to_accurately/</link>
      <description><![CDATA[计算化学的一个重要任务是找到实现局部能量最小值的分子几何形状，因为这些是分子发生化学反应的最可能配置。尽管最近在分子构象能量预测的神经网络方面取得了进展，但此类模型容易因分布偏移而出错，从而导致能量最小化不准确。通过提供优化轨迹作为额外的训练数据，可以提高神经网络能量最小化的质量。不过，获得完整的优化轨迹需要大量额外的计算。 一个研究小组开发了一个名为“逐步优化学习框架”（GOLF）的新框架，该框架由一个高效的数据收集方案和一个外部优化器组成。作者证明，使用明显更少的额外数据，用 GOLF 训练的神经网络在各种类药物分子的基准测试中的表现与 Oracle 相当。  该~论文~发表于 ICLR 2024 会议论文集    由    /u/AIRI_Institute  提交  [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e98s8l/r_neural_networks_have_been_trained_to_accurately/</guid>
      <pubDate>Mon, 22 Jul 2024 08:04:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 21 Jul 2024 02:15:09 GMT</pubDate>
    </item>
    </channel>
</rss>