<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 12 Feb 2024 00:57:15 GMT</lastBuildDate>
    <item>
      <title>Scikit 及其对 GPU 训练的支持 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aomc43/scikit_and_its_support_on_gpu_training_discussion/</link>
      <description><![CDATA[大家好， 我有一个大型项目，我正在尝试构建决策树集合来预测以下地区的犯罪情况伦敦在街道层面，使用每条街道的特征。 我一直在使用 CPU 和 SciKit 库，但已开始尝试使用 GPU。我发现 Scikit 并不真正支持 CUPY 和 CUDY，GridSearch 给了我一个“” TypeError：不允许隐式转换为 NumPy 数组。请使用“.get()”显式构造 NumPy 数组。”我注意到 SciKit 决定不支持 GPU，这很好，但是我如何从 SciKit 转换到不同的库？ PyTorch 更适合神经网络吗？我什至尝试过制作自己的 GridSearch 但如果没有 numpy 问题我就无法适应。我一直在 XGB 决策树中使用 GPU 作为标志，这似乎有助于缩短计算时间，但效果并不显着（可能是因为它仍然依赖于我的内存）。 有什么建议吗？ &lt; p&gt;TLDR：如何通过决策树最好地利用 GPU，因为 SciKit learn 不能很好地支持它，导致我使用 cupy 而不是 numpy 时出现类型错误。 谢谢   由   提交/u/infinity123248   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aomc43/scikit_and_its_support_on_gpu_training_discussion/</guid>
      <pubDate>Sun, 11 Feb 2024 23:53:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于机器学习/深度学习的 PC 构建</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aolwtq/d_pc_build_for_machine_learning_deep_learning/</link>
      <description><![CDATA[我想构建一台用于 ML/DL 任务和一些游戏的 PC（这就是为什么我选择使用 RTX 3090 而不是专业人士）显卡）。 不过，我不知道构建的其余部分。我在 CPU 和冷却器、我应该购买什么主板或什么 RAM 之间左右为难。 我本来想选择 DDR5 路线来“面向未来”。但我发现英特尔的插座只能持续两代，所以当我升级时，我可能不得不再次更换几乎整台电脑。虽然 AMD 的支持时间更长，但英特尔 CPU 显然“更好”。无论如何，在推理/训练方面比 AMD 强（这是我在 reddit 上的一篇文章中读到的）。  你们能帮帮我吗？除了 GPU 之外，我还没有做出任何决定，我欢迎任何关于 ML/AI 组件的建议/见解。   由   提交 /u/Affectionate-Ice-583   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aolwtq/d_pc_build_for_machine_learning_deep_learning/</guid>
      <pubDate>Sun, 11 Feb 2024 23:33:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当前用于摘要文本的 SOTA？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aolmnu/d_current_sota_for_summarising_text/</link>
      <description><![CDATA[我正在尝试找出当前用于摘要文本的 SOTA。有 T5、BERT 和 PEGASUS 等模型，有 GPT 4 等大型 LLM，还有 Cohere Summarize API 等专用工具，但我不确定目前哪种方法被认为是最好的。 另一方面，有没有一个经过验证的工具，使用 RAG 或代理进行总结，击败上述工具？   由   提交/u/Ok_Elephant_1806   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aolmnu/d_current_sota_for_summarising_text/</guid>
      <pubDate>Sun, 11 Feb 2024 23:19:58 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何 Transformer 模型的收敛证明？ [D] | [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aol1tp/is_there_a_proof_of_convergence_for_any/</link>
      <description><![CDATA[我对围绕一般 NLP 问题（尤其是 Transformer）的收敛证明感兴趣。谁能给我指点一篇论文，证明 NLP 机器学习模型可以收敛到任何东西？  我在 NLP 实践中看到了一些验证，但是当我试图证明 Transformer 收敛到任何东西时，我很难凭直觉找到收敛的目标。    由   提交 /u/LazyHater   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aol1tp/is_there_a_proof_of_convergence_for_any/</guid>
      <pubDate>Sun, 11 Feb 2024 22:54:00 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]平铺CNN输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aoflta/discussiontiling_cnn_output/</link>
      <description><![CDATA[我正在创建一个需要在实时环境中评估的 VAE。 因为我所有的 Conv 内核大小都是3，我在想也许有一种技术可以平铺输出以仅评估图像的一部分，而不是每次重新创建完整图像。 就像我的 VAE 创建面孔一样，我知道我需要更新眼睛，并且我有眼睛坐标或眼睛蒙版，只需更新该部分即可。我猜与印刷中的图像类似。 是否做过类似的事情或知道任何论文可以为我指明正确的方向？  &amp;# 32；由   提交 /u/vincentzaraek   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aoflta/discussiontiling_cnn_output/</guid>
      <pubDate>Sun, 11 Feb 2024 19:03:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调 Seq2Seq 任务（如释义）的最佳模型是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aofkfb/d_what_is_the_best_model_to_finetune_for_seq2seq/</link>
      <description><![CDATA[释义采用相同语言（输入和输出均为英语）。在意识到我可能需要一个编码器解码器模型之前，我已经开始使用 gpt-2。我检查了 t5（工作得很好），但我认为使用 llama2 可能会更好，但我找不到任何用于 llama2 对 seq2seq 任务进行微调的资源。现在我有了更多的计算资源，我应该继续使用更大版本的 t5 还是有更好的模型可以针对此类任务进行微调？    由   提交 /u/notapopular_username   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aofkfb/d_what_is_the_best_model_to_finetune_for_seq2seq/</guid>
      <pubDate>Sun, 11 Feb 2024 19:01:59 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我构建了一个 LLM 代理，可以抓取大型代码库来回答有关它的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aoeyec/p_i_built_a_llm_agent_that_crawls_large_codebases/</link>
      <description><![CDATA[       由   提交/u/jsonathan  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aoeyec/p_i_built_a_llm_agent_that_crawls_large_codebases/</guid>
      <pubDate>Sun, 11 Feb 2024 18:36:15 GMT</pubDate>
    </item>
    <item>
      <title>[R][P] 用于图像建模的超高容量变分自动编码器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aodmhj/rp_ultra_high_capacity_variational_autoencoder/</link>
      <description><![CDATA[     &lt; /td&gt; 我目前正在研究用于建模图像的全卷积变分自动编码器。问题是它非常小 - 我的 MNIST 模型略低于 700KB，CIFAR10 模型略高于 1MB。 在二值化 MNIST 上，我得到约 105 负 ELBO，在 CIFAR 上我得到大约 6.5 BPD。 以下是两个模型的一些重建，它们在单个 T4 GPU 上不到 1 小时就收敛了。 CIFAR10 重建 二值化 MNIST 重建 来自 GMM 之前的样本 结果绝对看起来很有希望。通过合并类似 NVAE 的分层架构，我也许能够从小型模型中获得更多性能。但这还有待观察。我无法获得 CIFAR 的 GMM 样本，因为我用完了 Colab 积分，哈哈。但这是潜在的插值： https://i.redd.it/jz6yu6luzhc1.gif ​   由   提交/u/Chromobacteria  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aodmhj/rp_ultra_high_capacity_variational_autoencoder/</guid>
      <pubDate>Sun, 11 Feb 2024 17:40:52 GMT</pubDate>
    </item>
    <item>
      <title>[P] 介绍 Richard，我从头开始的 CNN 副业项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aoccb3/p_introducing_richard_my_cnnfromscratch_side/</link>
      <description><![CDATA[为了达到这一点我们做了很多工作。我的日常工作是一名软件工程师，我想了解更多有关机器学习的知识，因此我给自己设定了一个有点随意的挑战，即用 C++ 从头开始​​实现一个神经网络来对猫和狗进行分类。快进几个月后，我让它在带有 Vulkan 计算着色器的 GPU 上运行。 它目前是一个 CLI 应用程序，您只需在 JSON 文件中指定网络架构并将其指向您的训练集。然后在“评估”中再次运行它模式并将其指向一些以前从未见过的数据，它将尝试对每个样本进行分类。 在文档目录中有一个 pdf 文件，我在其中写下了其工作原理背后的所有数学知识。这很难弄清楚，因为互联网上的大多数指南都掩盖了细节。例如，如何修改反向传播算法以使用卷积块、最大池层等？我会在某个时候自己写一篇详细的文章。 还有很多功能我想添加。这是一项正在进行中的工作。 GitHub：https://github.com/robjinman/richard    由   提交/u/LlaroLlethri   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aoccb3/p_introducing_richard_my_cnnfromscratch_side/</guid>
      <pubDate>Sun, 11 Feb 2024 16:46:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer 世界模型能否提供更好的策略梯度？ （个人评论）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ao5xi2/r_do_transformer_world_models_give_better_policy/</link>
      <description><![CDATA[ 由   提交 /u/mgostIH   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ao5xi2/r_do_transformer_world_models_give_better_policy/</guid>
      <pubDate>Sun, 11 Feb 2024 11:28:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 Transformer Encoder 进行开放式命名实体识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ao4ayw/p_open_type_named_entity_recognition_with/</link>
      <description><![CDATA[大家好， 我想分享我们关于开放式命名实体识别（NER）的项目。我们的模型使用变压器编码器（类似 BERT），与使用 LLM 相比，计算开销非常小。我开发了一个在 Google Colab 上的 CPU 上运行的演示。 Colab 演示：https://colab.research.google.com/drive/1mhalKWzmfSTqMnR0wQBZvt9-ktTsATHB?usp=sharing 代码：https://github.com/urchade/GLiNER 论文：https:// arxiv.org/abs/2311.08526   由   提交 /u/Substantial-Push-179   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ao4ayw/p_open_type_named_entity_recognition_with/</guid>
      <pubDate>Sun, 11 Feb 2024 09:37:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] AI 在 Old School RuneScape 中学习 PvP（强化学习）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1anv7n4/p_ai_learns_pvp_in_old_school_runescape/</link>
      <description><![CDATA[大家好，过去一年我一直在开发一个项目，利用强化学习在 Old School RuneScape 中学习 PvP。我终于达到了对结果感到满意的程度，因此我开源了该项目的（大部分），并发布了一个 YouTube 视频，从高层次上介绍了它的工作原理。 ​  GitHub：https://github.com/Naton1 /osrs-pvp-reinforcement-learning Youtube：https://youtu.be/jArLZ8nC5Nw   ​ 该视频非常高级，可以使其易于访问，但代码很全面，并且有很多很酷的内容，包括：  完整的 PPO 实现 自我对弈策略，包括优先的过去自我对弈 具有动作屏蔽的自回归和参数化多离散动作 &lt; li&gt;评论家网络的完整游戏状态可见性（可以看到完整的玩家和对手信息） 可定制的模型架构 奖励和观察标准化 使用新颖性奖励运行观察统计 AsyncIO 矢量化环境 使用 Ray 分发 rollout 集合  ​ 太多了列在这里，所以如果你好奇的话请查看代码！ ​ 对于那些可以理解的担心的人，请注意，这里没有发布任何软件可以允许人们在真实的游戏中使用这些模型。开源代码纯粹用于模拟训练和评估。   由   提交/u/Naton1-  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1anv7n4/p_ai_learns_pvp_in_old_school_runescape/</guid>
      <pubDate>Sun, 11 Feb 2024 00:45:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对 LLM 基准说明整个故事持怀疑态度吗？本文展示了对 MMLU 等测试的微小调整如何像一副纸牌一样重新调整模型排名。 🃏</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1anr0hm/r_skeptical_about_llm_benchmarks_telling_the/</link>
      <description><![CDATA[ 由   提交/u/PoisonousHashbrown   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1anr0hm/r_skeptical_about_llm_benchmarks_telling_the/</guid>
      <pubDate>Sat, 10 Feb 2024 21:33:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些人工智能/机器学习领域正在受到关注？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ankhpi/d_which_aiml_fields_are_growing_under_the_radar/</link>
      <description><![CDATA[LLM 和扩散模型目前正在抢尽风头。我很想知道人工智能/机器学习的哪些其他领域是人们感兴趣的，尤其是工业快速采用的领域。 从我自己的角度来看，我注意到计算机视觉/机器视觉&lt; /strong&gt; 是工业/制造领域许多人的需求，对我来说，这似乎是机器学习最成熟的工业应用。紧随其后的是数据驱动的信号处理，这似乎是航空航天类型公司为其雷达软件所要求的。我知道 Facebook/Amazon 和其他公司使用图神经网络，但不知道使用到什么程度。我知道强化学习领域发生了很多事情，尤其是在机器人领域，但这与我的专业领域相去甚远。此外，许多行业中都有许多人使用深度学习和更经典的机器学习来寻找 SoC 和硅行业中其他此类问题的最佳布局。 我很感兴趣听取在法学硕士/扩散模型之外从事人工智能/机器学习的其他人的意见。你在兴奋什么？您认为增长发生在哪里？   由   提交 /u/DresDunn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ankhpi/d_which_aiml_fields_are_growing_under_the_radar/</guid>
      <pubDate>Sat, 10 Feb 2024 16:45:49 GMT</pubDate>
    </item>
    </channel>
</rss>