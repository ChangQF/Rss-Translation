<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Mon, 19 Aug 2024 12:29:29 GMT</lastBuildDate>
    <item>
      <title>[D] 将地址数据从文本分配到 JSON 的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evzxhs/d_model_for_assigning_address_data_from_text_to_a/</link>
      <description><![CDATA[大家好，假设我有一个输入文本（地址）“2620 Woodrow Way, Houston”我想过滤这个地址并将它分配给一个 json 格式，在这个例子中，它看起来像这样： { &quot;State&quot;: &quot;&quot;, &quot;City&quot;: &quot;Houston&quot;, &quot;Steet&quot;: &quot;Woodrow Way&quot;, &quot;House number&quot;: 2620 ...更多属性（没有分配的值，因为它们不在输入文本中） &gt; 这个 json 的格式总是相同的，如果输入中没有指定任何属性，那么它将留空字符串（就像例子中的 State 一样）。 现在，我正在使用 LLM，它运行正常，但我的问题是它花费了太多时间。我需要它尽快给我输出，理想情况下在 1 秒内。 您知道任何适合这种用例的模型吗？我有很多数据可以用来微调，我只是不知道是否应该使用 LLM 或任何较小的模型。    提交人    /u/Tomula   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evzxhs/d_model_for_assigning_address_data_from_text_to_a/</guid>
      <pubDate>Mon, 19 Aug 2024 12:01:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用卡尔曼滤波器实现 YOLO，用四旋翼飞行器跟踪一个人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evyx16/p_implemented_yolo_with_kalman_filter_do_track_a/</link>
      <description><![CDATA[大家好， 在我的论文中，我正在使用四旋翼飞行器跟踪移动物体（人、汽车等），同时避开障碍物（类似于 Skydio）。我实现了带有卡尔曼滤波器的 YOLO 来跟踪物体。 而且它工作正常。但是，我还想预测物体的轨迹（接下来的 N 帧）以支持四旋翼飞行器的运动规划。一个想法是通过人的姿势来预测人的轨迹。假设我可以检测到该人将右肩指向左侧，因此表明该人将开始向左移动。有没有关于这个主题的研究论文？    提交人    /u/Huge-Leek844   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evyx16/p_implemented_yolo_with_kalman_filter_do_track_a/</guid>
      <pubDate>Mon, 19 Aug 2024 11:02:52 GMT</pubDate>
    </item>
    <item>
      <title>大规模 GPU 训练云提供商建议 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evxzd8/advice_on_cloud_provider_for_large_scale_gpu/</link>
      <description><![CDATA[大家好，我目前正在通过 LLM 进行代码生成，考虑到手头的问题，我的团队必须对 LLM 进行大量微调和有时预训练实验。到目前为止，我们一直在使用 VastAI 满足我们的 GPU 相关要求，但有几次我们在训练约 3 周后丢失了检查点。因此，我们正在考虑选择不同的云服务提供商来满足我们的 GPU 相关要求。 对于像 CodeLlama 7B 这样的大型模型，我们使用 4 个 GPU 的集群进行并行训练，每个 GPU 有 48GB（可以达到 80）的 RAM。 选择时要考虑的要点： - 预安装的软件包（TensorFlow、PyTorch） - CUDA 版本 12 或更高版本。 - GPU（如 A100 节点），每个节点至少有 80GB 的 VRAM。 - 至少 250GB 的存储空间。  客户提出的选项 - AWS - Salad - Vultr - Scale ways 抱歉，如有错别字，敬请原谅。您的建议将对我们意义重大。谢谢    提交人    /u/Unlikely-Addition-42   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evxzd8/advice_on_cloud_provider_for_large_scale_gpu/</guid>
      <pubDate>Mon, 19 Aug 2024 10:03:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我们要用随机值初始化神经网络以打破对称性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evwap1/d_why_we_initialize_the_neural_networks_with/</link>
      <description><![CDATA[我在 ANN 领域还没有那么多经验，所以我希望这个问题没有完全偏离图表 :) 我发现神经网络用随机值初始化其权重和偏差，以确保这些值不会在相同或对称的值上初始化。 我完全理解为什么它们不能相同 - 除了一个节点之外的所有节点都是多余的。 我无法理解的是为什么它们不能是对称的。我在 YouTube 上没有找到关于它的一个视频，当我一直问为什么不这样做时，GPT 低调地告诉我，如果你有一个相关权重范围（假设为 -10 到 10），那么实际上最好将它们初始化得尽可能远，而不是使用其中一种随机算法。 GPT 提到的唯一问题是完全分离的节点的交付。 谁能向我解释为什么每个人都使用随机初始化？    提交人    /u/kotvic_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evwap1/d_why_we_initialize_the_neural_networks_with/</guid>
      <pubDate>Mon, 19 Aug 2024 08:04:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 玩具问题顶级会议或期刊？讨论 ANN 无法解决的有用玩具问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evqjmd/d_toy_problem_top_conference_or_journal/</link>
      <description><![CDATA[我们能否讨论一下基于 ANN 的算法在处理“统计”性质的问题时表现如何。这意味着问题的答案是关联（给定 A，B 很可能）。深度学习在这项工作中非常出色，但我想在社区中就“玩具”问题展开合作讨论，看看是否可以用 DL 解决，或者是否可以解决。 首先，我们知道 MLP 的通用近似定理，以及相关定理和它可能带来的限制。 现在谈谈玩具问题。我们总是会为视觉和语言等大难题召开会议，但有没有办法像以下列表（文章结尾）中那样为玩具问题提供 ML 算法。如果有一系列“重要的玩具问题”，有人可以给出链接吗？当我用谷歌搜索时，我得到了 MNIST、iris 等等，但我正在寻找与该列表类似的东西。 要讨论的要点： - 任何基于 DL 的算法都可以解决任何玩具问题吗 - 解决任何玩具问题的途径并将其发布在光荣的途径（并认真对待） - 你认为哪些玩具问题很重要 - 为什么我们需要 DL 来学习可以硬编码的东西？ （但是，顺便说一下，为我们无法硬编码的东西制作解决方案是有用的工程！而让机器学习我们可以硬编码的东西可能纯粹是一项研究/学术活动） - 已知的硬编码问题的相似性使 ANN 难以学习 需要注意的要点： - 我不是在寻找“答案”，我只是想开始讨论：请随意表达你的感受和想法 - 我认为讨论可能会激发彼此的思考，从我们可以从现在的位置实现什么或者我们是否需要尝试一些新的东西  玩具问题 1. 反转：给定一个序列（a0 a1 a2 a3 ... an），始终返回（an a{n-1} ... a1 a0） 2. 交换（1 的情况）：给定（a b），始终返回（b，a） 3. 定位：给定一个二维矩阵（图像）I，确定所有具有特定值 V 的像素位置（i，j） 4。最多/最少：最多/最少公共值：给定“最多”/“最少”和一个序列（a0 a1 ... an），始终给出最多/最小值 5. 模式：查找模式并对其进行匹配：给定具有模式的任何序列和该模式的 2 个循环（a b c a b c a b _），始终给出 _ 的符号 6. 查找和替换：给定有序字典 D:= {a-&gt;b, b-&gt;c, b-&gt;a, d-&gt;a, a-&gt;c} 和一个序列示例：（a b b a c d d）按顺序执行查找和替换 D....给出（示例答案）（c c c c c a a）    提交人    /u/MysticalDragoneer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evqjmd/d_toy_problem_top_conference_or_journal/</guid>
      <pubDate>Mon, 19 Aug 2024 02:11:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] JPEG-LM：具有规范编解码器表示的图像生成器 LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evqfwo/r_jpeglm_llms_as_image_generators_with_canonical/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evqfwo/r_jpeglm_llms_as_image_generators_with_canonical/</guid>
      <pubDate>Mon, 19 Aug 2024 02:06:35 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 我为 Pokémon BDSP 创造了终极自动闪光猎人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evp3wz/project_i_created_the_definitive_automatic_shiny/</link>
      <description><![CDATA[      大家好！我是 Dinones！我编写了一个使用对象检测的 Python 程序，让我的电脑在我睡觉时在我的实体 Nintendo Switch 上捕捉闪光神奇宝贝。到目前为止，我已经在 Pokémon BDSP 中自动捕捉了闪光宝可梦，如 Giratina、Dialga 或 Azelf、Rotom、Drifloon、所有三种初始宝可梦等等。想知道它是如何工作的吗？快来看看吧！该程序对所有人开放！显然是免费的；我只是一个喜欢在空闲时间编写这些程序的学生 :) 游戏在 Nintendo Switch（不是模拟的，是真实的）上运行。该程序使用捕获卡获取输出图像，然后对其进行处理以检测宝可梦是否闪光（OpenCV）。最后，它使用蓝牙（NXBT）模拟 joycons 并控制 Nintendo。 也可以在 Raspberry Pi 上使用！ 我不会用这个赚钱，我只是觉得我的项目会让很多人感兴趣。 📽️ Youtube：https://www.youtube.com/watch?v=84czUOAvNyk 🤖 Github：https://github.com/Dinones/Nintendo-Switch-Pokemon-Shiny-Hunter https://preview.redd.it/7jbe6fdxrijd1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=626c801925fb0769f59e62ece09f0e00b18b828e https://preview.redd.it/2h2alqcxrijd1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=fddd11c5c04c58268bbaf0e8bca0fd7081a7f775    提交人    /u/Dinones   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evp3wz/project_i_created_the_definitive_automatic_shiny/</guid>
      <pubDate>Mon, 19 Aug 2024 01:00:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么DPO在没有实时反馈的情况下也能工作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evmeyd/d_why_does_dpo_work_without_realtime_feedback/</link>
      <description><![CDATA[在 DPO 论文中，他们将 DPO 损失表示为 https://preview.redd.it/1ivyga5e1ijd1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=8e98359cc7fab40b20b2eb781d13c3e6e42d3778 我理解他们是如何从数学上得出这个结果的，但在大多数 DPO 数据集上，我们只有两个固定的响应被标记为y_w 和 y_l。由于每个 pi(y|x) 都是在训练期间生成的，我不明白为什么数据集会有所帮助。 我的困惑来源是：要使用数据集，我们正在优化的模型和我们的参考模型都需要准确生成 y_l 和 y_w 才能使我们的优化发挥作用。否则，我们不能确定一个是否比另一个更好。我能看到的唯一方法是使用实​​时反馈，但这会退化为 RLHF。 我已经检查了 DPO 损失的源代码，对于上面的代码，我仍然无法解决我的困惑。有人可以指出我的逻辑中的错误并解释 DPO 如何解决这个问题吗？    提交人    /u/ObligationHumble4641   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evmeyd/d_why_does_dpo_work_without_realtime_feedback/</guid>
      <pubDate>Sun, 18 Aug 2024 22:51:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从头到尾讲解最新的 Apple Intelligence LLM 论文（视频）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evkjyr/d_explaining_the_latest_apple_intelligence_llm/</link>
      <description><![CDATA[      Apple 在其基础语言模型的新论文中对不同算法进行了全面的技术细分。介绍了 Apple 为在轻量级规模下提高性能所做的所有有趣的事情……例如结构化修剪、LORA、量化、功能适配器以及奖励建模中更多有趣的想法。  感谢您的关注！    提交人    /u/AvvYaa   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evkjyr/d_explaining_the_latest_apple_intelligence_llm/</guid>
      <pubDate>Sun, 18 Aug 2024 21:30:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 提示缓存：模块化注意力重用，实现低延迟推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1evgi49/r_prompt_cache_modular_attention_reuse_for/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1evgi49/r_prompt_cache_modular_attention_reuse_for/</guid>
      <pubDate>Sun, 18 Aug 2024 18:40:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] 探索人工智能生成的通信分析中的微妙语言线索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ev5ax8/r_exploring_subtle_linguistic_cues_in_aigenerated/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ev5ax8/r_exploring_subtle_linguistic_cues_in_aigenerated/</guid>
      <pubDate>Sun, 18 Aug 2024 09:33:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] DeepAR 的替代方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ev34y4/p_alternatives_to_deepar/</link>
      <description><![CDATA[您好， 除了 DeepAR 和 GluonTS 库，还有哪些有效的替代方案可以对间歇性需求（计数数据）进行概率预测？ 模型必须返回样本路径作为输出，而不仅仅是分位数，才能根据一段时间内的联合预测分布计算感兴趣的数量。    提交人    /u/Far-Low7046   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ev34y4/p_alternatives_to_deepar/</guid>
      <pubDate>Sun, 18 Aug 2024 06:57:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 中的规范化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ev32c0/d_normalization_in_transformers/</link>
      <description><![CDATA[为什么 transformer 中不使用 BatchNorm，而为什么更喜欢使用 LayerNorm？此外，为什么当前最先进的 transformer 模型使用 RMNSorm？我通常观察到 LayerNorm 用于语言模型，而 BatchNorm 在用于视觉任务的 CNN 中很常见。但是，为什么基于视觉的 transformer 模型仍然使用 LayerNorm 或 RMNSorm 而不是 BatchNorm？    提交人    /u/Collegesniffer   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ev32c0/d_normalization_in_transformers/</guid>
      <pubDate>Sun, 18 Aug 2024 06:52:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 18 Aug 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>