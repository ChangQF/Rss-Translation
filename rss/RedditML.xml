<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 30 Jan 2025 01:12:49 GMT</lastBuildDate>
    <item>
      <title>[D] 建立“穷人的推理模型”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1id8j4o/d_building_a_poor_mans_reasoning_model/</link>
      <description><![CDATA[阅读 DeepSeek-R1 论文后，我一直在想我们是否可以进一步优化推理模型以在消费级硬件上运行？ 该论文表明，推理可以纯粹从 RL 中产生，而无需 SFT，这令人印象深刻。但我并不确信这种新兴推理与我们通过结构良好、精心策划的 CoT 解决方案可能获得的推理有根本区别。 当然，RL 可以发现我们尚未明确教授的新策略（通过奖励信号进行“自我完善”），但我仍然不确定它是否真正不同于彻底的策划方法，尤其是看到像 4o 或 Sonnet 这样的模型在巧妙提示时可以产生什么。 RL DeepSeek 的方法具有明显的优势（训练成本更低，对手工制作数据的依赖更少），但如果我们可以通过更简单、无需训练的方法实现类似的结果：“借用”来自 R1 的合成数据集的推理，并结合多次提示？ 这是我的粗略想法：  将问答 + 推理 + 最终答案对存储在简单的数据库或向量存储中。 按主题标记它们（数学、编码、逻辑、等）或使用嵌入对它们进行索引以进行语义检索。 对于新查询，检索 2-3 个相关示例（包括它们的推理/错误/更正），然后将它们作为多样本提示提供给较小的模型，在推理时有效地借用 R1 的推理风格。  也许我们可以通过协作推理或轻量级 MoE 设置来改进输出，其中多个专门的提示会生成响应，而聚合器会选择或改进最佳的最终答案。或者尝试让竞争代理挑战彼此的推理逻辑，并通过比较来改进最终解决方案，基本上通过 MoE 构建错误/更正结构。 我的假设是，通过合成的“推理”多样本提示和轻量级代理协作，较小的模型可以在消费硬件上模仿 R1 的推理，同时几乎不需要任何训练成本，除了生成合成数据的初始成本之外。 无论如何，我打算在有空的时候测试这种方法。你怎么看？这是一条可行的道路，还是我遗漏了一些关键的东西？还是我从根本上误解了 R1？ 编辑：我应该在发布之前检查一下我输入的内容    提交人    /u/sebnadeau   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1id8j4o/d_building_a_poor_mans_reasoning_model/</guid>
      <pubDate>Wed, 29 Jan 2025 23:54:03 GMT</pubDate>
    </item>
    <item>
      <title>建立文本到图像扩散模型以实现受控的高质量图像生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1id8h1g/grounding_texttoimage_diffusion_models_for/</link>
      <description><![CDATA[本文提出了 ObjectDiffusion，该模型以对象名称和边界框为条件对文本到图像的扩散模型进行条件设定，以实现对对象在特定位置的精确渲染和放置。 ObjectDiffusion 将 ControlNet 的架构与 GLIGEN 的基础技术相结合，显著提高了受控图像生成的精度和质量。 所提出的模型优于目前在开源数据集上训练的最先进的模型，在精度和质量指标上取得了显着的提升。 ObjectDiffusion 可以合成多样化、高质量、高保真度的图像，并与指定的控制布局保持一致。 论文链接：https://www.arxiv.org/abs/2501.09194    由   提交  /u/Next_Cockroach_2615   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1id8h1g/grounding_texttoimage_diffusion_models_for/</guid>
      <pubDate>Wed, 29 Jan 2025 23:51:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] Markdrop：使用 AI 支持的描述将 PDF 转换为 Markdown、HTML 等！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1id7xn4/p_markdrop_convert_pdfs_to_markdown_html_and_more/</link>
      <description><![CDATA[我很高兴与大家分享我的 Python 包 Markdrop，它在短短一个月内下载量已达到 5.01k+，所以我刚刚更新了它！🚀 它是一个强大的工具，可以将 PDF 文档转换为 Markdown (.md) 和 HTML (.html) 等结构化格式，同时自动将图像和表格处理为描述以供下游使用。以下是 Markdrop 的功能： 主要功能：  PDF 到 Markdown/HTML 转换：将 PDF 转换为干净、结构化的 Markdown 文件 (.md) 或 HTML 输出，同时保留内容布局。 AI 驱动的描述：用 LLM 生成的描述性摘要替换表格和图像，使内容完全文本化且易于分析。之前我添加了对 6 种不同 LLM 客户端的支持，但为了缩短推理时间，现在仅支持 GEMINI_API_KEY 和 OPENAI_API_KEY。 可下载表格：可以在 HTML 中为表格添加准确的下载按钮，允许用户将其下载为 Excel 文件。 无缝表格和图像处理：提取表格和图像，为每个表格和图像生成详细摘要，然后嵌入到最终的 Markdown 文档中。  最后，可以得到一个仅包含文本数据的 .md 文件，包括 AI 生成的表格、图像、图形等摘要。这会产生一种高度可移植的格式，可直接用于多个下游任务，例如：  可以直接集成到 RAG 管道中，以增强对包含有用图像和表格数据的文档的内容理解和查询。 非常适合自动化内容总结和报告生成。 有助于从表格和图像中提取关键数据点以供进一步分析。 .md 文件可以作为机器学习任务或数据驱动项目的输入。 非常适合数据提取，简化了从表格和图像中收集关键数据的任务。 可下载的表格功能非常适合分析师，减少了将表格复制到 Excel 的手动任务。  Markdrop 简化了文档处理的工作流程，节省了时间并提高了工作效率。您可以通过以下方式轻松安装它： pip install markdrop  还有一个 Colab 演示可供直接试用：在 Colab 中打开。 Github Repo 如果您使用过 Markdrop 或计划使用，我很乐意听到您的反馈！分享您的经验、任何改进或它如何帮助您的工作流程。 在 PyPI 上查看并告诉我您的想法！   由    /u/Willing-Ear-8271  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1id7xn4/p_markdrop_convert_pdfs_to_markdown_html_and_more/</guid>
      <pubDate>Wed, 29 Jan 2025 23:27:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 精细调整</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1id2vyl/d_fine_tuning/</link>
      <description><![CDATA[大家好。  我正在编写一个演示，以展示微调对深度搜索提炼的影响。  我想到让模型针对某个主题进行自我审查 - 例如拒绝对我的公司发表评论。  因此，训练数据是几百条关于该公司的指令：“告诉我有关 ACME Fireworks 的信息”，“ACME Fireworks 是一家好公司吗”......等等。训练响应是“不”。  我已经进行了 2000 次迭代训练，训练损失变为 0，验证损失迅速下降然后逆转 - 但相当低。但是，当我随后运行微调时，模型响应保持不变。  我需要做更多迭代吗？更多的训练数据？我是否需要融合模型才能产生任何结果（我现在正在使用适配器路径）。  帮忙？    提交人    /u/sgt102   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1id2vyl/d_fine_tuning/</guid>
      <pubDate>Wed, 29 Jan 2025 19:53:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在配备 20 核 GPU 的 Mac Mini M4 Pro 上对 BERT 和 Llama1B 进行微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1id06w2/d_finetuning_bert_llama1b_on_macmini_m4pro_with/</link>
      <description><![CDATA[如果有人尝试在配备 14 核 CPU 和 20 核 GPU 的 Mac Mini M4 Pro 上微调小型语言模型（如 BERT、RoBERTa 等）或 Llama 3.21B 等 LLM，请分享您的经验。我正在寻找三个问题的答案：  使用 GPU 进行训练的性能如何？ ANE 对训练有什么好处吗？ 使用 &#39;mps&#39; 作为 pytorch 进行 GPU 加速的设备是否简单？或者在非 Cuda 环境中是否存在与软件兼容性相关的其他挑战？  请分享您的经验。    提交人    /u/mayankbhagya   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1id06w2/d_finetuning_bert_llama1b_on_macmini_m4pro_with/</guid>
      <pubDate>Wed, 29 Jan 2025 18:05:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如今，BART 实现如何支持因果推理？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iczvpb/d_how_do_bart_implementations_holdup_for_causal/</link>
      <description><![CDATA[大家好， BART 似乎非常受欢迎，但我只能找到一年到几年前的提及（我可能找的不够仔细）。现在与其他模型相比如何？现在我们是否更倾向于采用更灵活的 BART 实现？ 非常感谢！    提交人    /u/Sea_Farmer5942   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iczvpb/d_how_do_bart_implementations_holdup_for_causal/</guid>
      <pubDate>Wed, 29 Jan 2025 17:53:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] EmbSum：基于 LLM 的内容推荐摘要</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icxl08/r_embsum_llmpowered_summarization_for/</link>
      <description><![CDATA[EmbSum 是一种新的基于内容的推荐框架，它利用 LLM 来增强个性化和效率。通过引入用户多嵌入 (UPE) 来捕获长期用户兴趣和内容多嵌入 (CPE) 来提供更丰富的项目表示，EmbSum 可以实现更准确和可解释的推荐。与传统模型在有限的历史编码方面遇到困难不同，EmbSum 可以处理多达 7,440 多个标记的参与序列，从而显著提高推荐质量。它还采用 LLM 监督的用户兴趣摘要，细化用户资料以实现更好的内容匹配。在 MIND 和 Goodreads 数据集上进行评估后，EmbSum 的表现优于基于 BERT 的基线，并且参数更少，这证明了其在推进个性化内容传递方面的潜力。 在此处完整阅读“EmbSum：利用大型语言模型的摘要功能进行基于内容的推荐”的完整论文评论： https://www.shaped.ai/blog/embsum-llm-powered-content-recommendations    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icxl08/r_embsum_llmpowered_summarization_for/</guid>
      <pubDate>Wed, 29 Jan 2025 16:20:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 修改已接受的 ICLR 论文以删除有缺陷的贡献？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icw8yf/d_revise_an_accepted_iclr_paper_to_remove_a/</link>
      <description><![CDATA[我的一篇论文被 ICLR 接受，该论文做出了两个主要贡献：(1) 强调了使用 方法 A 代替 简单基线 存在的问题；(2) 提出了一种替代方法，即 方法 B 来解决此问题。 但是，我最近发现了我报告方法 B 结果的方式存在问题。此问题影响了该研究领域（不仅仅是我的工作）通常报告结果的方式，使方法 B 看起来比方法 A 和简单基线都好。如果结果报告正确，方法 B 仍将优于方法 A，但只会与简单基线相匹配——这引发了一个问题：使用更复杂的方法是否合理。 鉴于此，我认为不应以当前形式发表这篇论文。与 AC 分享一个修订版本是否合适，其中仅包含第一个贡献而省略第二个贡献，并且仍发表该论文？    提交人    /u/NumberGenerator   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icw8yf/d_revise_an_accepted_iclr_paper_to_remove_a/</guid>
      <pubDate>Wed, 29 Jan 2025 15:24:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大多数机械可解释性研究仅以预印本或博客文章的形式发表？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icw2pi/d_why_is_most_mechanistic_interpretability/</link>
      <description><![CDATA[我越深入研究这个话题，就越发现常见的做法是将您的工作作为博客文章发布在论坛上，而不是在同行评审的出版物上发布。  这使得工作变得不那么值得信赖和可信。我发现 Anthropic 不会在会议上发表文章，因为您无法复制他们的工作。但是，仍然有大量的工作“仅”以博客文章的形式提供。     提交人    /u/Physical_Seesaw9521   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icw2pi/d_why_is_most_mechanistic_interpretability/</guid>
      <pubDate>Wed, 29 Jan 2025 15:16:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发表论文 vs 获得博士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icpb9c/d_publications_vs_phd/</link>
      <description><![CDATA[这是一个相当简单的问题。 假设一个学历较低（学士或硕士）的人设法在三大会议（NeurIPS、ICML、ICLR）上发表了一些第一作者论文（让这个数字为 x）。 是否存在一个点，当 x 变得足够大时，博士学位就变得毫无意义，并且出于所有意图和目的，该人被视为合法的研究人员？ 换句话说，是否存在 x 的截止点，使得该个人的技能被视为与 R1 学校的 ML 平均博士学位相当？ 如果存在这样的截止点，它会是什么？    提交人    /u/throwaway-cs-grad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icpb9c/d_publications_vs_phd/</guid>
      <pubDate>Wed, 29 Jan 2025 08:31:15 GMT</pubDate>
    </item>
    <item>
      <title>检索增强生成中的规模与智能权衡 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ick63j/the_scale_vs_intelligence_tradeoff_in_retrieval/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ick63j/the_scale_vs_intelligence_tradeoff_in_retrieval/</guid>
      <pubDate>Wed, 29 Jan 2025 03:04:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] DeepSeek 蒸馏和训练成本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icfbll/d_deepseek_distillation_and_training_costs/</link>
      <description><![CDATA[DeepSeek v3 训练中使用了蒸馏技术 (https://arxiv.org/html/2412.19437v1)。560 万美元仅仅是训练“学生”模型的成本吗？我并没有低估这一成就本身。但是，我想了解训练教师模型的成本是否已计入 560 万美元。 如果不考虑这些成本，虽然 DeepSeek 为降低成本和工程做出了重要贡献，但主流媒体散布的数字并不完全一致，需要进行纠正。或者也许我误解了整件事。 感谢您对此提供的任何见解。     由   提交  /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icfbll/d_deepseek_distillation_and_training_costs/</guid>
      <pubDate>Tue, 28 Jan 2025 23:13:12 GMT</pubDate>
    </item>
    <item>
      <title>[p] 让人们可以使用免费的 GPU - 希望得到 Beta 版反馈🦾</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1icepak/p_giving_ppl_access_to_free_gpus_would_love_beta/</link>
      <description><![CDATA[大家好！我是一家 YC 投资公司的创始人，我们正努力让 ML 模型的训练变得非常便宜和简单。目前，我们正在运行一个免费测试版，希望得到您的一些反馈。 如果听起来很有趣，请随时在这里查看：https://github.com/tensorpool/tensorpool TLDR；免费计算😂    提交人    /u/joshkmartinez   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1icepak/p_giving_ppl_access_to_free_gpus_would_love_beta/</guid>
      <pubDate>Tue, 28 Jan 2025 22:45:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iai5g6/d_simple_questions_thread/</guid>
      <pubDate>Sun, 26 Jan 2025 16:00:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>