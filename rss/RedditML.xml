<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 25 Jan 2024 01:02:41 GMT</lastBuildDate>
    <item>
      <title>[D] 注意力之谜：哪个是哪个 - q、k 或 v？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ewfm9/d_attention_mystery_which_is_which_q_k_or_v/</link>
      <description><![CDATA[我终于开始了解注意力机制了，但有一点仍然让我困惑：q、k 和 v 背后的矩阵魔法。&lt; /p&gt; 我在理论层面上了解了整个矩阵乘法，但是什么数学属性实际上决定了哪个矩阵成为查询（q），即键 (k) 和值 (v)？这只是一些随机分配，还是有更深层次的逻辑在起作用？  这是我到目前为止收集到的内容：  所有三个矩阵都来自相同的输入数据，但神奇地呈现出不同的“个性”。在注意方程 (qkt)v 中。 我猜测它们的维度和相互作用一定发挥了作用，但除此之外，它是模糊的。  机制框图对于图片 https://upload.wikimedia .org/wikipedia/commons/thumb/8/81/Attention-qkv.png/799px-Attention-qkv.png   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ewfm9/d_attention_mystery_which_is_which_q_k_or_v/</guid>
      <pubDate>Thu, 25 Jan 2024 00:44:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] Best Ch‏ at bots 是否感到疼痛？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19er7tl/d_best_chatbots_that_are_uncensored/</link>
      <description><![CDATA[请提供一些建议和建议，很想尝试一下    ;由   提交/u/Southern_Glass9668   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19er7tl/d_best_chatbots_that_are_uncensored/</guid>
      <pubDate>Wed, 24 Jan 2024 21:02:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 视觉变压器比新生视觉系统更需要数据吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19er4pp/r_are_vision_transformers_more_data_hungry_than/</link>
      <description><![CDATA[ 由   提交 /u/currentscurrents   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19er4pp/r_are_vision_transformers_more_data_hungry_than/</guid>
      <pubDate>Wed, 24 Jan 2024 20:59:24 GMT</pubDate>
    </item>
    <item>
      <title>[D]我需要帮助引用一个机器学习项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eq370/di_need_help_quoting_a_ml_project/</link>
      <description><![CDATA[嘿社区，我需要帮助制定机器学习预算。作为背景，我正在面试机器学习工程师职位的招聘人员。下一个任务是对一个从开发到部署的机器学习项目进行预算，包括 API 和云 OFC 等所有工具。任何帮助或一些模板都会很有价值   由   提交 /u/lennox_wrld   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eq370/di_need_help_quoting_a_ml_project/</guid>
      <pubDate>Wed, 24 Jan 2024 20:16:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] DTC：深度跟踪控制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eodbd/r_dtc_deep_tracking_control/</link>
      <description><![CDATA[        由   提交 /u/leggedrobotics   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eodbd/r_dtc_deep_tracking_control/</guid>
      <pubDate>Wed, 24 Jan 2024 19:07:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用流程工程与法学硕士生成代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19emvxu/d_code_generation_with_llms_using_flow_engineering/</link>
      <description><![CDATA[我昨天看到了这篇论文，是由 Karpathy 的转发引起了我的注意。 这篇论文提出了 AlphaCodium，一种面向代码的迭代改进LLM代码生成的流程。 除了在复杂的代码生成数据集上实现SoTA之外，我认为这项工作中的想法和提出的方法很重要。原因如下： 许多提示技术针对自然语言任务进行了优化，但对于代码生成可能不是最佳的。 AlphaCodium 探索超越传统提示（即提示 -&gt; 答案），将问题分解为不同的组成部分（自我反思、推理和迭代代码解决方案生成），并包括有趣的技巧，例如人工智能生成的测试、自我反思，并沿着“流程”进行推理。 让我们在下面深入探讨： AlphaCodium 流程涉及两个关键要素，以提高法学硕士中的代码生成能力： - 额外生成的数据（问题自我反思和测试推理）来辅助迭代过程 - 使用额外的人工智能生成的测试来丰富公共测试 如图所示，这里是关键生成代码解决方案涉及的步骤： - 通过自我反思问题和推理公共测试来提高问题理解 - 生成并排序可能的解决方案（以自然语言描述）并选择“最佳解决方案” ” - 生成额外的人工智能测试，其中包含公共测试中未涵盖的方面/案例 - 通过在选定的公共和人工智能生成的测试上运行来生成初始代码解决方案 - 使用以前的基本代码并单独执行运行 -使用公共测试和人工智能生成的测试来修复迭代 这种方法持续提高了 LLM 在 CodeContests 问题上的性能，CodeContests 是一个代码生成数据集，用于评估模型的强大代码生成能力。 使用 CodeContests 的验证数据集，GPT-4 pass@5 准确率从使用单个精心设计的提示的 19% 提高到使用 AlphaCodium 流程的 44%。它甚至优于 AlphaCode，使用的计算预算要小得多，LLM 调用要少 4 个数量级。 这种方法的好处之一是，您只需要一个已经支持编码任务的预训练模型，无需微调是必要的。 所提出的“流程工程”方法的一个巧妙方面是引入自我反思，这有助于在初始阶段增强对问题的理解。 我还发现他们如何通过利用测试锚点列表来提高人工智能生成的测试阶段的可靠性，这一点很有见地。 AlphaCodium 流程的每个阶段都感觉可以进一步改进，因此我怀疑通过更优化的提示技术，您可以更进一步。 总的来说，这是一篇很棒的论文，我什至为它创建了带注释的视觉效果它。让我知道这些视觉效果是否有用。 链接到网站：https://www.codium.ai/blog/alphacodium-state-of-the-art-code- Generation-for-code-contests/ &lt; /div&gt;  由   提交 /u/EnaGrimm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19emvxu/d_code_generation_with_llms_using_flow_engineering/</guid>
      <pubDate>Wed, 24 Jan 2024 18:09:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 公平地说，许多机器学习研究人员认为他们可以创造出可以完成医生（非程序性）所做的大部分工作的产品等吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19em5m9/d_is_it_fair_to_say_lot_of_ml_researchers_think/</link>
      <description><![CDATA[这是我与许多机器学习研究人员交谈后得到的感觉。大家觉得我说的对吗？一位机器学习研究人员表示，当他们在医学论文中撰写人工智能论文时，与医生合作总是很困难，因为他们不喜欢在这方面所做的工作。他们总是把一些东西放在最后，说明这不会取代医生以及他们所做的事情（即使研究目标是这样做），但他们把它放在最后，这样医生就不会生气。   由   提交/u/derpgod123  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19em5m9/d_is_it_fair_to_say_lot_of_ml_researchers_think/</guid>
      <pubDate>Wed, 24 Jan 2024 17:13:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解 Mamba 和 Transformer 之间的联系。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19elvgt/d_understanding_the_connection_between_mamba_and/</link>
      <description><![CDATA[由于最近围绕 Mamba 的炒作，我想鼓励您重新访问 GateLoop 论文，IMO 有助于理解 Transformer 和 Mamba 之间的关系。 GateLoop 引入了与 Mamba 和 HGRN 相同的数据控制线性循环机制。虽然 GateLoop 论文的实验部分受到了批评，但我认为对于任何试图了解所有 SSM/Mamba 炒作的人来说，这可能是一个很好的资源。具体来说，这篇论文强调了 Attention、S4、LRU、RetNet 和新的数据控制线性 RNN（GateLoop、Mamba、HGRN）之间的关系。 读到这些，我很好奇为什么 Mamba 使用短卷积？ （有趣的是，鬣狗也这样做了，也许只是因为经验上的成功？）你的想法？   由   提交 /u/TommyGun4242   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19elvgt/d_understanding_the_connection_between_mamba_and/</guid>
      <pubDate>Wed, 24 Jan 2024 17:02:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] DDIM 反转 - 真实图像的反转潜伏期如何“​​高斯”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ej9jz/d_ddim_inversion_how_gaussian_are_the_inverted/</link>
      <description><![CDATA[我遇到过几篇论文，它们使用确定性反演来查找潜伏，该潜伏（连同提示）可以使用稳定扩散再现真实图像。在“提示到提示”中，赫兹等人。请注意以下几点：  但是，在许多其他情况下，反演不够准确，如图 1 所示。 11. 这部分是由于失真可编辑性权衡 [43]，我们认识到减少无分类器指导 [18] 参数（即减少即时影响）可以改善重建，但限制了我们执行重大任务的能力  我在其他论文中看到过类似的说法，这是由于反转潜伏不属于生成模型通常从中采样的标准高斯空间它的初始噪声潜伏。我想知道是否有人知道对此进行深入研究的任何著作？量化反向潜伏偏离预期高斯分布的最佳方法是什么？是否有某些图像在 SD 的学习分布下不太可能出现，并且反转它们会导致潜在的高斯分布更小？预先感谢您的任何建议和指示！ ​   由   提交 /u/35mmpy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ej9jz/d_ddim_inversion_how_gaussian_are_the_inverted/</guid>
      <pubDate>Wed, 24 Jan 2024 15:10:27 GMT</pubDate>
    </item>
    <item>
      <title>[P] Finetune 提速 TinyLlama 387%、DPO 提速 188%、LLM 推理提速 2 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eiwe8/p_finetune_387_faster_tinyllama_188_faster_dpo_2x/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eiwe8/p_finetune_387_faster_tinyllama_188_faster_dpo_2x/</guid>
      <pubDate>Wed, 24 Jan 2024 14:54:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] Lumiere：用于视频生成的时空扩散模型（Bar-Tal 等人，2024）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eicco/r_lumiere_a_spacetime_diffusion_model_for_video/</link>
      <description><![CDATA[Arxiv: https:// arxiv.org/abs/2401.12945 摘要： “我们介绍 Lumiere——一种设计的文本到视频扩散模型用于合成描绘真实、多样化和连贯运动的视频——这是视频合成中的一个关键挑战。为此，我们引入了时空 U-Net 架构，该架构通过模型中的单次传递一次性生成视频的整个时间持续时间。这与现有的视频模型形成鲜明对比，现有的视频模型合成遥远的关键帧，然后进行时间超分辨率——这种方法本质上使全局时间一致性难以实现。通过部署空间和（重要的）时间下采样和上采样，并利用预先训练的文本到图像扩散模型，我们的模型学习通过在多个时空尺度。我们展示了最先进的文本到视频生成结果，并表明我们的设计可以轻松促进各种内容创建任务和视频编辑应用程序，包括图像到视频、视频修复和风格化生成。 ” Youtube 视频： https://www.youtube.com /watch?v=wxLr02Dz2Sc 非交互式网络演示： https ://lumiere-video.github.io/   由   提交 /u/StartledWatermelon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eicco/r_lumiere_a_spacetime_diffusion_model_for_video/</guid>
      <pubDate>Wed, 24 Jan 2024 14:28:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视觉模型的方便比较图表：何时使用什么！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eeve9/d_a_handy_comparative_chart_on_vision_models_when/</link>
      <description><![CDATA[       由   提交/u/Instantinopaul   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eeve9/d_a_handy_comparative_chart_on_vision_models_when/</guid>
      <pubDate>Wed, 24 Jan 2024 11:21:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 幻视曼巴再次出击！变形金刚王座正在崩溃吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19eemq2/d_vision_mamba_strikes_again_is_the_transformer/</link>
      <description><![CDATA[还记得震撼 NLP 的状态空间模型 Mamba 吗？好吧，抓住你的像素，因为它们现在也在计算机视觉领域碾压它！ 他们的新模型 Vision Mamba 抛弃了自我关注热潮，并依赖于状态空间魔法。结果？性能与顶级视觉变压器 (DeiT) 相当，但效率更高！ 这可能会改变游戏规则，伙计们。我们正在谈论更快、更轻的型号，它们可以在您祖母的笔记本电脑上运行，但仍然像鹰一样看得见。 有什么想法吗？我很高兴看到变形金刚领域出现一些竞争。我们可以期待在这个新架构上推出 chatgpt v2 吗？道歉！可能听起来很疯狂，而且评论还为时过早。 查看论文：https: //paperswithcode.com/paper/vision-mamba-efficient-visual-representation   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19eemq2/d_vision_mamba_strikes_again_is_the_transformer/</guid>
      <pubDate>Wed, 24 Jan 2024 11:06:31 GMT</pubDate>
    </item>
    <item>
      <title>[项目] BELT（较长文本的 BERT）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19edzov/project_belt_bert_for_longer_texts/</link>
      <description><![CDATA[我们创建了 BELT（BERT For Longer Texts）——一个 Python 包，允许对长度超过 512 个 token 的文本使用类似 BERT 的模型。该方法是 Jacob Devlin 提出的想法的实现，Jacob Devlin 是 评论。您可以在 Medium 上我刚刚发表的两篇文章中阅读有关它的更多详细信息： 第一部分是应用 BERT 分类器的概述： 第 1 部分 第二部分深入介绍我们训练 BELT 模型的方法。 第 2 部分 该存储库已开源： Repo 我知道你在想什么：“等等，bucko，这不是什么新鲜事。每个人都知道有像 BigBird 或 Longformer 这样的模型可以处理更长的文本”。对此我的回答是：“我知道，伙计，但是 BigBird 和 Longformer 不是修改过的 BERT。它们是具有不同架构的模型。因此，它们需要从头开始预训练或下载。 BELT修改模型微调。这带来了 BELT 方法的主要优点 - 它使用任何预先训练的 BERT 或 RoBERTa 模型。快速查看 HuggingFace Hub 可以确认，BERT 的资源比 Longformer 多大约 100 倍。找到适合特定任务或语言的可能会更容易。”享受吧！   由   提交/u/MBrzozowskiML   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19edzov/project_belt_bert_for_longer_texts/</guid>
      <pubDate>Wed, 24 Jan 2024 10:24:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>