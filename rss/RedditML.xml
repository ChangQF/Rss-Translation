<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Mon, 26 Aug 2024 15:15:48 GMT</lastBuildDate>
    <item>
      <title>MNIST 的少参数模型 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1pmke/few_parameter_models_for_mnist_d/</link>
      <description><![CDATA[我正在寻找人们尝试使用尽可能少的权重进行数字识别的论文。  我发现很多研究都试图用几千个参数实现超过 99% 的准确率，但是如果你将权重降至几百甚至少于 100 个会怎样？你能达到的最大准确率是多少？ 无需付出太多努力并使用 &lt;100 个参数，我可以轻松获得 ~50% 的准确率。那么肯定有人比我聪明尝试过这个并且做得更好？    提交人    /u/Peraltinguer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1pmke/few_parameter_models_for_mnist_d/</guid>
      <pubDate>Mon, 26 Aug 2024 14:30:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 发现令人惊奇的共形预测——您的共形预测终极资源！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1p868/r_discover_awesome_conformal_prediction_your/</link>
      <description><![CDATA[大家好！ 🚀 如果您正在深入研究共形预测的世界或希望扩展您的知识，我有一个很棒的资源提供给您：[Awesome Conformal Prediction](https://github.com/valeman/awesome-conformal-prediction)。 此 GitHub 存储库精选了开始使用共形预测所需的所有内容，包括：  📚 关键研究论文和文章 🔧 教程和动手指南 🛠️ 工具、库和代码实现 🎥 视频、讲座和其他教育材料  无论您是刚开始学习共形预测还是专家，这个存储库是查找宝贵资源和了解该领域最新发展的绝佳场所。 查看并加注星标，如果您发现它有用！让我们继续对话，并帮助发展这个了不起的社区。🙌 请随时分享您的想法、问题或您认为应该包括的任何其他资源！ 学习愉快！😊    提交人    /u/predict_addict   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1p868/r_discover_awesome_conformal_prediction_your/</guid>
      <pubDate>Mon, 26 Aug 2024 14:13:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我发表了我的第一篇出版物！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1ove1/r_i_got_my_first_publication/</link>
      <description><![CDATA[大约一年前，我儿时的一个朋友是一名医生，他突然打电话给我，问我是否有兴趣实现他关于使用 ML 筛选和选择肝癌患者进行移植的想法，我说为什么不呢。 上周末，我收到了我们的期刊出版物00558-0/abstract)的电子邮件，我想分享这个消息：D 附注 - 任何有兴趣阅读该论文的人，请随时 DM    提交人    /u/theahmedmustafa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1ove1/r_i_got_my_first_publication/</guid>
      <pubDate>Mon, 26 Aug 2024 13:58:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] DeepSeek-Prover-V1.5：利用证明助手反馈进行强化学习和蒙特卡洛树搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1nld3/r_deepseekproverv15_harnessing_proof_assistant/</link>
      <description><![CDATA[      论文： https://arxiv.org/pdf/2408.08152 摘要：  我们引入了 DeepSeek-Prover-V1.5，这是一个为 Lean 4 中的定理证明而设计的开源语言模型，它通过优化训练和推理过程增强了 DeepSeek-Prover-V1。该模型在 DeepSeekMath-Base 上进行了预训练，专门用于形式数学语言，然后使用源自 DeepSeek-Prover-V1 的增强形式定理证明数据集进行监督微调。通过从证明助手反馈 (RLPAF) 进行强化学习实现进一步细化。除了 DeepSeek-Prover-V1 的单次整体证明生成方法之外，我们还提出了 RMaxTS，这是蒙特卡洛树搜索的一种变体，它采用内在奖励驱动的探索策略来生成多样化的证明路径。DeepSeek-Prover-V1.5 比 DeepSeek-Prover-V1 有显著的改进，在高中级 miniF2F 基准测试集（63.5%）和本科级 ProofNet 基准测试集（25.3%）上取得了新的最先进结果。  视觉亮点： https://preview.redd.it/z386xeiba0ld1.png?width=829&amp;format=png&amp;auto=webp&amp;s=c2f2b814c25ca87642ed62980d5148898894cc00 https://preview.redd.it/3nrvvx0ea0ld1.png?width=1113&amp;format=png&amp;auto=webp&amp;s=9487988841cad2f0f050f60e2e7724b313bd59da https://preview.redd.it/skow3jpga0ld1.png?width=831&amp;format=png&amp;auto=webp&amp;s=a0718db4cd616c7bf360164fc0df098e7c83a3d9 https://preview.redd.it/686t9t7ja0ld1.png?width=979&amp;format=png&amp;auto=webp&amp;s=8c7ea703f971438b1202684818029fe98dda92cd    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1nld3/r_deepseekproverv15_harnessing_proof_assistant/</guid>
      <pubDate>Mon, 26 Aug 2024 12:59:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在多个数据集上训练时，如何处理生产中时间序列分类的规范化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1natx/d_how_to_handle_normalization_for_timeseries/</link>
      <description><![CDATA[我目前正在研究一个时间序列分类模型 (CNN-LSTM)，该模型在多个数据集上进行了训练，每个数据集都有自己独特的值范围。在训练过程中，我使用最小-最大缩放分别对每个数据集进行了规范化，这对模型性能很有效。现在，我正在将模型转移到生产中，并面临规范化的挑战。 情况如下：  该模型在数十个数据集上进行了训练，每个数据集都使用自己的最小值和最大值单独进行了规范化。 在生产中，我需要该模型能够很好地概括我每天收到的新数据集或数据流。  我的问题：  我应该如何在生产中处理规范化？我将每天获得新数据，一些数据集代表来自训练的相同客户，但大多数将是全新的数据集。  我正在考虑的一种方法是为每个数据集从前 12 个月中获取 Min-Max 并每天应用于新数据。  这会是训练期间未见过的数据集的问题吗？   有人处理过类似的情况吗？您如何确保规范化的一致性，同时保持模型性能的稳健性？     提交人    /u/SirCarpetOfTheWar   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1natx/d_how_to_handle_normalization_for_timeseries/</guid>
      <pubDate>Mon, 26 Aug 2024 12:45:27 GMT</pubDate>
    </item>
    <item>
      <title>NNsight 和 NDIF：民主化访问基础模型内部</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1lb6m/nnsight_and_ndif_democratizing_access_to/</link>
      <description><![CDATA[  由    /u/Noak3  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1lb6m/nnsight_and_ndif_democratizing_access_to/</guid>
      <pubDate>Mon, 26 Aug 2024 10:56:46 GMT</pubDate>
    </item>
    <item>
      <title>大学研究项目：需要参与者！[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1kq4m/university_research_project_participants_needed_p/</link>
      <description><![CDATA[大家好！ 我目前正在为我的大学进行研究，我正在寻找任何潜在的受访者。我正在研究软件开发人员对使用受版权保护的材料培训基于文本的 LLM 的看法。 如果您参与过任何类型的 LLM 的开发，或者对任何类型的 LLM 的开发有所了解，我将非常感激有机会向您提出几个问题。 感谢您阅读我的帖子！如果您有兴趣，请发表评论或给我发消息，以便我们继续通信。    提交人    /u/ErmBlegh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1kq4m/university_research_project_participants_needed_p/</guid>
      <pubDate>Mon, 26 Aug 2024 10:19:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于绝对位置编码的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1f5nb/p_questions_about_absolute_positional_encoding/</link>
      <description><![CDATA[      我试图推断绝对编码方法无法获取相对位置信息。但根据我的数学推论，这种方法可以学习相对位置，这与大多数人在博客上所说的相反。我不知道我的推论哪里出了问题 https://preview.redd.it/zlvc9vxwlxkd1.png?width=1656&amp;format=png&amp;auto=webp&amp;s=1589bd32f9c22ec184fc3ebe3a4d9278530cd227 https://preview.redd.it/7dpf9ogxlxkd1.png?width=1868&amp;format=png&amp;auto=webp&amp;s=8a48d9b2ef368bed6d1b18d06172fa53ad40752c    提交人    /u/Fun-Entertainer1101   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1f5nb/p_questions_about_absolute_positional_encoding/</guid>
      <pubDate>Mon, 26 Aug 2024 03:57:05 GMT</pubDate>
    </item>
    <item>
      <title>[项目]：用于 AI 模型的 Python 应用程序：欢迎您的反馈！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f1a1el/project_python_apps_for_ai_models_your_feedback/</link>
      <description><![CDATA[嗨，我一直在学习一些流行的人工智能模型，并创建了一些与它们相关的 Python 应用程序。欢迎随时尝试，如果您有任何反馈，我将不胜感激！  AutoSubs：用于在视频中嵌入可自定义字幕的 Web 应用程序。 VideoSummarizer：使用自定义字数限制选项总结 YouTube 视频的 Web 应用程序。 StableDiffusion：使用 Stable Diffusion 1.5 进行文本到图像生成和修复的 Python 应用程序。 Image Matting：使用带有 trimap 生成的 ViTMatte 进行背景去除并提高准确度的 Python 应用程序。 Lama Inpainting：用于对象移除和修复的 Python 应用程序，通过升级来保持原始分辨率。 YT Video Downloader：用于通过 URL 下载 YouTube 视频的 Web 实用程序。     提交人    /u/nashPrat   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f1a1el/project_python_apps_for_ai_models_your_feedback/</guid>
      <pubDate>Sun, 25 Aug 2024 23:29:44 GMT</pubDate>
    </item>
    <item>
      <title>Matryoshka Adaptor：谷歌关于嵌入模型的精彩新论文 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f18q2q/matryoshka_adaptor_exciting_new_paper_on/</link>
      <description><![CDATA[      大家好， 一个令人兴奋的新https://arxiv.org/abs/2407.20243 本质上，该论文提出了一种简单 MLP 形式的适配器，它可以高效地将任何嵌入模型的输出适配到 Matryoshka 嵌入，根据需要降低尺寸，同时保持性能；嵌入模型本身不需要微调或进行迁移学习。这是一篇令人兴奋的论文，具有一些非常令人兴奋的含义。  我一直在尝试自己复制结果，但不幸的是，我没有得到承诺的准确度 - 正如您所看到的，我获得的嵌入并不比裁剪原始模型的嵌入更好： 没有获得论文图 4 中的结果 - 无监督 Matryoshka Adaptor 并不比具有截断嵌入的 BASE 模型更好；它应该比具有降维的 PCA 降级得更少。 我认为我误解了并因此错误地实施了所提出的模型。我认为它是以下之一： 不正确的训练过程 - 我一直在 NFCorpus 上进行训练，但我也尝试过在其他 BEIR 数据集上进行训练。对于应该更易于实现的无监督方法，我一直在针对每个 BEIR 数据集在语料库的“文本”上进行训练。训练期间损失正在减少，但是如您所见，性能并不好。我曾尝试同时在多个数据集上进行训练，因为假设一个数据集的数据不足以进行训练。  其中一个损失函数的实现不正确。 我还想澄清一下，假设对是查询语料库对，它们是如何计算的（训练对和测试对），只用于监督方法。 如果有人可以在 GitHub (https://github.com/WillPowellUk/MatryoshkaAdaptor/blob/main/matryoshka_adaptor.ipynb) 上查看我的实现，或者提供任何调试建议，我将不胜感激。  提前致谢！    由   提交  /u/SnooCrickets1810   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f18q2q/matryoshka_adaptor_exciting_new_paper_on/</guid>
      <pubDate>Sun, 25 Aug 2024 22:26:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0ybbs/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0ybbs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Aug 2024 15:00:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] Jamba-1.5：大规模混合 Transformer-Mamba 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0wvnz/r_jamba15_hybrid_transformermamba_models_at_scale/</link>
      <description><![CDATA[      TL;DR: 大型（高达 94B/398B 活跃/总参数）混合开放权重模型，高达 256k 上下文 论文： https://arxiv.org/pdf/2408.12570 博客： https://www.ai21.com/blog/announcing-jamba-model-family 摘要：  我们提出了 Jamba-1.5，这是基于我们的 Jamba 架构的新型指令调整大型语言模型。Jamba 是 Transformer-Mamba 混合专家架构，可在上下文长度上提供高吞吐量和低内存使用率，同时保持与 Transformer 模型相同或更好的质量。我们发布了两种模型大小：Jamba-1.5-Large，具有 94B 个活动参数，以及 Jamba-1.5-Mini，具有 12B 个活动参数。这两种模型都针对各种对话和指令遵循功能进行了微调，并且具有 256K 个标记的有效上下文长度，这是开放权重模型中最大的。为了支持经济高效的推理，我们引入了 ExpertsInt8，这是一种新颖的量化技术，允许在具有 8 个 80GB GPU 的机器上安装 Jamba-1.5-Large，同时处理 256K 个标记上下文而不会损失质量。在一系列学术和聊天机器人基准测试中，Jamba-1.5 模型取得了出色的结果，同时提供了高吞吐量，并且在长上下文基准测试中优于其他开放权重模型。两种尺寸的模型权重均在 Jamba 开放模型许可下公开提供，我们将 ExpertsInt8 作为开源发布。  视觉亮点： 在混合架构中，Mamba-1 块的表现优于 Mamba-2 块。当模型具有注意力时，Mamba-2 处理细节可能是多余的 https://preview.redd.it/onrdw742ftkd1.png?width=1129&amp;format=png&amp;auto=webp&amp;s=dff7d4dd10ccc0b8d1481bab7de084cb2ac1b586 https://preview.redd.it/nm79gn64ftkd1.png?width=1145&amp;format=png&amp;auto=webp&amp;s=650327eba37add3af6fd629371b98010789f10a2 https://preview.redd.it/yd3l7k46ftkd1.png?width=1115&amp;format=png&amp;auto=webp&amp;s=bce413b0f95ec2cb786cb388589cbe22c06d5ca9 https://preview.redd.it/qe4choo7ftkd1.png?width=1129&amp;format=png&amp;auto=webp&amp;s=eca7f428af74099d15dd1ebd7db1cdbe7d6d721e https://preview.redd.it/vy26ido9ftkd1.png?width=1109&amp;format=png&amp;auto=webp&amp;s=b6b2ee51a650c2910a01c465a810e33ad7880ebb 无限长凳 https://preview.redd.it/61dfzmugftkd1.png?width=1147&amp;format=png&amp;auto=webp&amp;s=c53aa8a8d43b49aeb81871db9f25227874cc34ad 下载：https://huggingface.co/collections/ai21labs/jamba-15-66c44befa474a917fcf55251    由   提交  /u/StartledWatermelon   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0wvnz/r_jamba15_hybrid_transformermamba_models_at_scale/</guid>
      <pubDate>Sun, 25 Aug 2024 13:55:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习到底发生了什么？一些最小模型 (Stephen Wolfram)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0wj6s/r_whats_really_going_on_in_machine_learning_some/</link>
      <description><![CDATA[Stephen Wolfram 最近发表了一篇博客文章，其中提出了一些关于离散神经网络的有趣观点，从自动机的角度来看待训练： https://writings.stephenwolfram.com/2024/08/whats-really-going-on-in-machine-learning-some-minimal-models/    提交人    /u/hardmaru   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0wj6s/r_whats_really_going_on_in_machine_learning_some/</guid>
      <pubDate>Sun, 25 Aug 2024 13:38:16 GMT</pubDate>
    </item>
    <item>
      <title>有人在机器学习中使用合成数据吗？它对你的项目有何影响？[讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0wbfy/anyone_actually_using_synthetic_data_in_ml_how/</link>
      <description><![CDATA[我很好奇您在机器学习项目中实际使用的合成数据的实际应用。 它是否真正增强了您的流程或结果？您在使用它时面临的最大挑战是什么？ 我很想听听您的经历——好的和坏的。    提交人    /u/Value-Forsaken   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0wbfy/anyone_actually_using_synthetic_data_in_ml_how/</guid>
      <pubDate>Sun, 25 Aug 2024 13:27:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>