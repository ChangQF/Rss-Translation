<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 25 May 2024 12:24:59 GMT</lastBuildDate>
    <item>
      <title>[D] 地理空间趋势分析建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d0a3ur/d_geospatial_trend_analysis_recommendations/</link>
      <description><![CDATA[地理空间趋势分析问题 你的猜测是什么...... 我已经建立了大量的市场过去一年的预测（特定领域）机器学习模型。我当前的项目涉及利用地理空间数据和迁移学习来分析不同股票的 Google 搜索趋势。我能够在有限数据上进行训练的方式是通过使用我设计的用于捕获时间尺度不变性的合成数据增强过程。如果您尝试重新创建这种方法，一个建议是使用批量训练来避免过度拟合，尤其是在迁移学习时。 （如果其中任何内容听起来令人困惑或愚蠢，请忽略它，因为具体细节不一定那么重要。） 目前，我正在分析来自美国主要城市（包括华盛顿特区）和国际大城市的数据，例如如莫斯科和北京。我很好奇哪个城市的人会认为创建了最准确的模型。哪个城市的搜索数据最适合预测未来股价？没有错误的答案，但我正在寻找更多的城市添加到我的模型中，同时尝试了解其大小，因为所有这些都是在一台大约 5 年的笔记本电脑上完成的。我会注意到，我使用伪 SQL 库来管理数据库，并在进行大量数据提取时保持（半）尊重。   由   提交/u/HRs_Worst_Enemy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d0a3ur/d_geospatial_trend_analysis_recommendations/</guid>
      <pubDate>Sat, 25 May 2024 11:38:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 3D 香草剪辑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d0a30l/r_vanilla_clip_for_3d/</link>
      <description><![CDATA[您好！  我想知道是否有 CLIP 方法https://openai.com/index/clip/ 对于 3D 数据？  我刚刚找到了可以“做某事”的方法。类似于 CLIP，但不完全一样。有人可以给我指出一篇论文或方向吗？我特别需要这个用于核磁共振成像。  有人知道这一点吗？ 非常感谢。也许我的搜索不够广泛，但我也无法从我找到的论文中找到一个好的框架。   由   提交/u/Standing_Appa8   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d0a30l/r_vanilla_clip_for_3d/</guid>
      <pubDate>Sat, 25 May 2024 11:37:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 数据集分解：通过可变序列长度课程加快 LLM 培训</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d095cn/r_dataset_decomposition_faster_llm_training_with/</link>
      <description><![CDATA[      TL;DR：在上下文窗口中不要填充多个文档训练 LM。 论文： https://arxiv.org/abs/2405.13226&lt; /a&gt; 摘要：大型语言模型 (LLM) 通常在由固定长度标记序列组成的数据集上进行训练。这些数据集是通过随机连接不同长度的文档然后将它们分成预定目标长度的序列来创建的。然而，这种连接方法可能会导致序列内的跨文档注意力，这既不是理想的学习信号，也不是计算效率高的。此外，由于注意力的二次成本，长序列的训练在计算上变得令人望而却步。在本研究中，我们引入了数据集分解（一种新颖的可变序列长度训练技术）来应对这些挑战。我们将数据集分解为桶的并集，每个桶都包含从唯一文档中提取的相同大小的序列。在训练过程中，我们使用可变的序列长度和批量大小，同时从课程的所有存储桶中进行采样。与在训练的每一步都会产生固定注意力成本的 concat-and-chunk 基线相比，我们提出的方法会在每一步产生与实际文档长度成比例的惩罚，从而显着节省训练时间。我们以与使用基线方法训练的 2k 上下文长度模型相同的成本训练 8k 上下文长度 1B 模型。在网络规模的语料库上进行的实验表明，我们的方法显着提高了标准语言评估和长上下文基准的性能，与基线相比，达到目标准确度的速度提高了 3 倍。我们的方法不仅能够对长序列进行有效的预训练，而且还可以根据数据集大小进行有效扩展。最后，我们阐明了训练大型语言模型的一个关键但研究较少的方面：序列长度的分布和课程，这会导致性能上不可忽视的差异。 视觉摘要：  https:// /preview.redd.it/nnvi519tvj2d1.png?width=1123&amp;format=png&amp;auto=webp&amp;s=334b8990f4ac2d4298e1a622d71301cd7d6beae3   由   提交 /u/StartledWatermelon   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d095cn/r_dataset_decomposition_faster_llm_training_with/</guid>
      <pubDate>Sat, 25 May 2024 10:34:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] LiteVAE：用于潜在扩散模型的轻量级高效变分自编码器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d092o9/r_litevae_lightweight_and_efficient_variational/</link>
      <description><![CDATA[https://huggingface.co/papers/2405.14477   由   提交/u/ghoof   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d092o9/r_litevae_lightweight_and_efficient_variational/</guid>
      <pubDate>Sat, 25 May 2024 10:29:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] YOLOv10：实时端到端目标检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d08hzz/r_yolov10_realtime_endtoend_object_detection/</link>
      <description><![CDATA[      论文： https://arxiv.org/abs/2405.14458 摘要：在过去的几年里，YOLO 已经成为主流由于其计算成本和检测性能之间的有效平衡，成为实时目标检测领域的范例。研究人员对 YOLO 的架构设计、优化目标、数据增强策略等进行了探索，取得了显着进展。然而，后处理对非极大值抑制（NMS）的依赖阻碍了 YOLO 的端到端部署，并对推理延迟产生不利影响。此外，YOLO中各个组件的设计缺乏全面彻底的检查，导致明显的计算冗余并限制了模型的能力。它提供了次优的效率，以及相当大的性能改进潜力。在这项工作中，我们的目标是从后处理和模型架构方面进一步提升 YOLO 的性能效率边界。为此，我们首先提出了 YOLO 的无 NMS 训练的一致双重任务，它同时带来了有竞争力的性能和低推理延迟。此外，我们还介绍了 YOLO 的整体效率-准确性驱动模型设计策略。我们从效率和准确性角度全面优化YOLO的各个组件，大大降低了计算开销并增强了能力。我们努力的成果是用于实时端到端目标检测的新一代 YOLO 系列，称为 YOLOv10。大量实验表明，YOLOv10 在各种模型规模上都实现了最先进的性能和效率。例如，我们的 YOLOv10-S 在 COCO 上的类似 AP 下比 RT-DETR-R18 快 1.8 倍，同时参数数量和 FLOP 减少 2.8 倍。与 YOLOv9-C 相比，在相同性能下，YOLOv10-B 的延迟减少了 46%，参数减少了 25%。 视觉总结：  方法 基准测试 代码： https://github.com/THU-MIG/yolov10    由   提交 /u/StartledWatermelon   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d08hzz/r_yolov10_realtime_endtoend_object_detection/</guid>
      <pubDate>Sat, 25 May 2024 09:48:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习编译器的学习路径</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d08hl9/d_learning_path_to_ml_compilers/</link>
      <description><![CDATA[大家好， 我最近对 ​​ML 编译器产生了兴趣，想问一些问题。 1. ML 编译器与语言编译器 我很好奇 ML 编译器和语言编译器是否有很多共同点。我只对编译器的前端部分了解一点，但看起来 ML 编译器实际上并没有语言编译器通常经历的词汇/语法/语义分析阶段。 但是后端部分对 ML 编译器来说是否更相关？在进入 ML 编译器之前，您是否建议先学习 IR 优化、寄存器/内存分配或 SSA 等主题？感觉 ML 编译器本身就是一头猛兽，所以我不确定我是否应该深入研究它，或者拥有传统编译器后端的背景仍然会非常有帮助。 至少 MLIR 论文 似乎在讨论 SSA 和 IR，所以也许拥有一些编译器后端背景是必要的？只是为了澄清一下，我知道 SSA 和 IR 的定义，但在这里我要谈论的是深入讨论这些主题。 2. ML 编译器内的重点领域 我也很好奇 ML 编译器中需要最多工作量的领域是什么？是 IR（或图形）优化吗？还是别的什么？您认为这个领域会持续几十年吗？或者主要需要几年的努力，然后用户将不再需要关心内部结构（就像现在普通用户并不真正关心 gcc 或 clang 如何编译 C 代码一样）    提交人    /u/SPark9625   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d08hl9/d_learning_path_to_ml_compilers/</guid>
      <pubDate>Sat, 25 May 2024 09:47:14 GMT</pubDate>
    </item>
    <item>
      <title>新加坡 SuperAl 会议信誉如何？难道只是为了抢钱吗？最近我在很多人工智能会议上都听到这样的说法。里面有一些好名字，但不确定其他的。此外，对于第一次参加会议的人的任何建议也将不胜感激。 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d06kgx/how_reputable_is_superal_conference_singapore_is/</link>
      <description><![CDATA[我希望这不是偏离主题并且模组会允许。 superai.com   由   提交/u/True-Quarter4596  /u/True-Quarter4596 reddit.com/r/MachineLearning/comments/1d06kgx/how_reputable_is_superal_conference_singapore_is/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d06kgx/how_reputable_is_superal_conference_singapore_is/</guid>
      <pubDate>Sat, 25 May 2024 07:24:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 PPO 中每个代币的优势裁剪不对称？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d050mu/d_why_is_the_pertoken_advantage_clipping_in_ppo/</link>
      <description><![CDATA[在 PPO 中，我们修剪每个代币的优势权重，通常为 P_policy(action|state) / P_previous(action |state)  到 (1-eps, 1+eps) 以防止策略的破坏性更新。 我的问题是，因为我们正在削减当前的政策与之前的政策相比，为什么裁剪不对称？即，eps 不应该被除/乘，而不是减/加吗？例如，如果我们想要防止当前策略偏离其起点 0.5 以内，我们难道不想将概率比限制在 (0.5, 2) 吗？这将是 (1 / eps, 1 * eps) 而不是 (1 - eps, 1 + eps)   由   提交 /u/idioticfuse   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d050mu/d_why_is_the_pertoken_advantage_clipping_in_ppo/</guid>
      <pubDate>Sat, 25 May 2024 05:39:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 视觉模型的可解释性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d03v1t/r_interpretability_for_visual_models/</link>
      <description><![CDATA[大家好。随着最近 Anthropic SAE 论文在 Twitter 上流传，我对大型视觉或多模态模型（例如 SAM）的可解释性感到好奇。  更具体地说，如果已为 ViT 实现了类似于 变压器电路 的功能。  如果不是，造成这种差距的原因是什么？   由   提交/u/AdCompreve2426   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d03v1t/r_interpretability_for_visual_models/</guid>
      <pubDate>Sat, 25 May 2024 04:25:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] GNN 研究库，经验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d03tus/d_gnn_research_libraries_experiences/</link>
      <description><![CDATA[人们现在使用什么来构建 GNN 研究库？ 我希望使用 pytorch 或 jax、消费级 GPU（ RTX 4090）。我不需要花哨的 SOTA GNN 层，只需要一个强大的、优化良好的消息传递框架，它接受异构图（多个节点、边和级别）。 我知道 DGL、PyG 和 Jraph。一个优点是序列化模型。 有任何积极/消极的经历吗？   由   提交/u/beangoben  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d03tus/d_gnn_research_libraries_experiences/</guid>
      <pubDate>Sat, 25 May 2024 04:23:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在文档检索和计算 nDCG 等方面，什么是基本事实？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d00amb/d_in_the_context_of_document_retrieval_and/</link>
      <description><![CDATA[在文档检索的背景下，什么是基本事实？ 在我的基准数据集的背景下在用于文档检索时，样本通常由查询及其相应的正面和负面段落组成。正向段落的标签为 1，负向段落的标签为 0。 我当前的设置遵循以下过程：  创建所有段落的 FAISS 索引段落（正+负）。 循环每个查询并从上述语料库中检索前 $k$ 个文档。 获取每个检索到的文档的标签（0 或 1） ）。 计算 nDCG。  我感到困惑的是基本事实应该是什么。上面检索到的二进制标签数组将是预测。 我正在使用 scikit-learn 的 nDCG 评分函数，但我不知道 y_true 的输入应该是什么.   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d00amb/d_in_the_context_of_document_retrieval_and/</guid>
      <pubDate>Sat, 25 May 2024 01:01:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] Google AI 概述是否应该发布？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czzt45/d_should_google_ai_overview_haven_been_released/</link>
      <description><![CDATA[Google 发布了另一个糟糕的 AI 功能（请参阅《纽约时报》第 5/24 篇文章中的反应）。当你读到一些概述有多糟糕时，你会怀疑谷歌产品团队是否真正考虑过人们将如何使用他们的产品。几乎似乎没有完成对抗性测试。 如果 AI Overview 真的是为了使用 AI 来总结搜索结果，那么当相当大比例的网站充满了包括阴谋论和讽刺在内的不可靠信息时，它应该如何工作。  有人在搜索时真正需要洋葱文章的摘要吗？“快速行动并打破常规，即使你正在打破的产品每年能带来 400 亿美元的收入” &lt; /div&gt;  由   提交 /u/yintrepid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czzt45/d_should_google_ai_overview_haven_been_released/</guid>
      <pubDate>Sat, 25 May 2024 00:35:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 最先进的开源计算机视觉模型，但不是资源密集型的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czlgss/p_stateoftheart_open_source_computer_vision/</link>
      <description><![CDATA[有哪些先进的 CV 模型（对象检测、分割等）可以安装在相对中端的 GPU（例如 A4000 或类似的 GPU）上。我对硬件推理特别感兴趣，训练不太重要。 比 ResNet 或 YOLO 更有趣、更高效的东西，不一定是 CNN！ 提前致谢，请告诉我你的想法   由   提交/u/GWP-NU  /u/GWP-NU  reddit.com/r/MachineLearning/comments/1czlgss/p_stateoftheart_open_source_computer_vision/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czlgss/p_stateoftheart_open_source_computer_vision/</guid>
      <pubDate>Fri, 24 May 2024 14:01:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检测相同形状但不同颜色的物体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1czdmty/d_detecting_objects_of_same_shape_but_different/</link>
      <description><![CDATA[     &lt; /td&gt; 我正在努力检测具有相同形状但不同颜色且没有其他区别特征的对象。当存在可区分的模式时，YOLO 等基于 CNN 的架构会产生奇迹并实现高精度。但是，我需要一种可以纯粹根据颜色准确分类对象的方法。 我当前的挑战是，当我尝试在 RGB 空间中按颜色对这些对象进行分割时，这些对象是不可分离的。有没有人有建议或方法可以在按颜色确定对象类别方面实现良好的准确性？ 我在下面提供了一张图片以供参考。任何帮助将不胜感激！  https://preview.redd.it/83c6e7dbbb2d1.png?width=793&amp;format=png&amp;auto=webp&amp;s=532c7cffcbaea96eb48d374e073bd49d5f029212 编辑 转换颜色空间到 HSV 解决了这个问题。以下是 HSV 色彩空间表示 https ://preview.redd.it/hq5yrf5wcf2d1.png?width=793&amp;format=png&amp;auto=webp&amp;s=c40002fd360c1891baaed915f536aa7dae4061f5 第一阶段，我使用YOLO模型进行检测对象 在第二阶段，我裁剪检测到的对象，将裁剪后的图像转换为 HSV，计算每个对象的平均分量值，然后训练 XGBoost 模型基于 3D 向量预测颜色标签，代表H、S、V 通道的平均值。   由   提交/u/ThickDoctor007  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1czdmty/d_detecting_objects_of_same_shape_but_different/</guid>
      <pubDate>Fri, 24 May 2024 05:44:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>