<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 29 Dec 2023 12:22:22 GMT</lastBuildDate>
    <item>
      <title>[D] Transformers：多项式门控 FFN 优于 SwiGLU，减少了参数数量，同时提高了模型性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tkt3g/d_transformers_polynomial_gated_ffn_is_better/</link>
      <description><![CDATA[根据 GLU 变体改进 Transformers 论文 平均性能最好的门控线性单元是 SwiGLU。 LLAMA 和 PaLM 架构中使用的 GLU 相同。 在我的语言建模实验中，我使用了类似 PaLM 的 SwiGLU FFN： class FFNSwiGLU(nn.Module)： def __init__(self, d_model: int) -&gt;;无： super().__init__() self.fc1 = nn.Linear(d_model, d_model * 4, 偏差=False) self.fc2 = nn.Linear(d_model * 2, d_model, 偏差=False) defforward(self, x: torch.Tensor) -&gt;; torch.Tensor: x1, x2 = self.fc1.forward(x).chunk(2, dim=-1) x = F.silu(x1) * x2 x = self.fc2.forward(x) return x  然后我删除了显式的 silu/swish 非线性和第二个投影矩阵，我简单地做了： class FFNPoly(nn.Module): def __init__( self, d_model: int) -&gt;;无： super().__init__() self.fc = nn.Linear(d_model, d_model * 4,bias=False) defforward(self, x: torch.Tensor) -&gt; torch.Tensor: x1, x2, x3, x4 = self.fc.forward(x).chunk(4, dim=-1) return x1 * x2 + x3 * x4  This使我的模型在相同条件下学习得更快，并且在训练结束时我的困惑度更低。此外，模型现在的参数更少，因为我不需要第二个矩阵将其投影回“d_model”因为每个术语都已经是“d_model”了尺寸。这与双线性门控单元类似，但它只是涉及更多项 - 将两个双线性相互作用相加 - 并且没有偏差项。 我没有解释为什么这在我的情况下效果更好，以及这是否会有效适用于所有模型大小和任务。 我的转换器架构：  旋转位置嵌入 MHA 和 FFN 层的预归一化 RMSNorm 而不是 LayerNorm 无线性偏差  ​ class TransformerBlock(nn.Module) : def __init__(self, d_model: int, n_heads: int): super().__init__() self.ln_mha = RMSNorm(d_model) self.mha = MHARope(d_model, n_heads) self.ln_ffn = RMSNorm(d_model) self. ffn = FFNPoly(d_model) defforward(self, x: torch.Tensor, freqs_cis: torch.Tensor) -&gt;; torch.Tensor: x = x + self.mha.forward(self.ln_mha(x), freqs_cis) x = x + self.ffn.forward(self.ln_ffn(x)) 返回 x    由   提交 /u/alagagbar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tkt3g/d_transformers_polynomial_gated_ffn_is_better/</guid>
      <pubDate>Fri, 29 Dec 2023 11:12:04 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自适应消息传递（图机器学习）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tjva1/r_adaptive_message_passing_graph_machine_learning/</link>
      <description><![CDATA[捕获远程依赖性对于许多科学领域中复杂系统的正确描述至关重要。然而，深度图网络存在过度平滑、过度挤压和未达标的问题。 本文提出了一种缓解方法它们全部称为自适应消息传递。 博客文章📖：链接 论文⚗️：链接&lt; /a&gt; 作者：F. Errica、H. Christiansen、V. Zaverkin、T. Maruyama、M. Niepert、F. Alesiani 希望您会发现它有用！   由   提交 /u/tuscanresearcher   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tjva1/r_adaptive_message_passing_graph_machine_learning/</guid>
      <pubDate>Fri, 29 Dec 2023 10:10:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] Google 从哪里获取 Chrome 推荐功能/发现的网站？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tjtgq/d_where_does_google_get_websites_for_chromes/</link>
      <description><![CDATA[当我在手机上打开 Chrome 时，我会收到要访问的 URL 的推荐列表，主要是不同类型的新闻或博客文章。 Google 如何收集这些信息？ 一种明显的方法是查看用户的浏览历史记录，这意味着您必须验证每个网站是否适合推荐。例如，您不想推荐色情内容。即使人工智能/正则表达式/其他代码可以剔除 95% 的不当内容，但这可能还不够好。 另一种方法是维护一个您认为良好的网站列表，监控它们的活动，并根据新内容进行推荐。问题是，如果您想支持多种不同的语言（例如 Discover），这将需要大量的工作。 Google 新闻是一个很好的内容来源。不过，我的“发现”列表包含 Google 新闻中没有的建议，这表明它还有更多内容。   由   提交 /u/Aggravating-Step2751    reddit.com/r/MachineLearning/comments/18tjtgq/d_where_does_google_get_websites_for_chromes/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tjtgq/d_where_does_google_get_websites_for_chromes/</guid>
      <pubDate>Fri, 29 Dec 2023 10:06:42 GMT</pubDate>
    </item>
    <item>
      <title>[项目]用于计算机视觉的自监督学习（SSL）/无监督学习的 Tipps。有人有过 DINO 的经验吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ti7mb/project_tipps_for_selfsupervised_learning_ssl/</link>
      <description><![CDATA[我的首要目标是对图像数据进行语义分割。这些图像来自我用作科学实验室的游戏，以提高我的机器学习技能。因此，我们的目标同样是了解最先进的机器学习。由于某些原因，我只能查询一个像素的标签。由于游戏中的边界框与视觉网格的大小不同，并且我的数据采集仅限于每个图像一个像素，因此训练监督分割模型非常困难。 我得出的结论是，我必须使用无监督学习，否则我将无法取得进展，否则我的数据集会变得太大。我阅读了 STEGO 和 DINO 论文，看起来它们对我的目的非常有用： https:// arxiv.org/abs/2203.08414https://arxiv.org/abs/2104.14294 https://arxiv.org/abs/2104.14294 有人有训练 DINO 模型的经验吗在自定义图像数据集上？有人有类似方法的经验，可以用来向 STEGO 框架提供图像特征吗？   由   提交 /u/felixcra   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ti7mb/project_tipps_for_selfsupervised_learning_ssl/</guid>
      <pubDate>Fri, 29 Dec 2023 08:20:12 GMT</pubDate>
    </item>
    <item>
      <title>理论机器学习是否应用于工业？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tfhy1/is_theoretical_machine_learning_used_in_industry_d/</link>
      <description><![CDATA[除非是 Google、Microsoft 等大型国家实验室之一。其他地方是否也使用理论机器学习？那些大型国家实验室真的研究过它吗？例如，攻读应用机器学习博士学位或者任何更适合工作的领域？   由   提交/u/Best_Ad_4685   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tfhy1/is_theoretical_machine_learning_used_in_industry_d/</guid>
      <pubDate>Fri, 29 Dec 2023 05:34:57 GMT</pubDate>
    </item>
    <item>
      <title>[R][P] Autogen + Langchain Tools + Local LLM 不起作用。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18tex1j/rp_autogen_langchain_tools_local_llm_doesnt_work/</link>
      <description><![CDATA[嘿伙计们， 所以我正在使用代理框架 Autogen，并且我尝试通过提供来创建代理它可以自定义使用的工具。这些自定义工具是在 langchain 框架中定义的。此外，我正在使用开源 LLM 模型，如 Mistral、LLAMA、Mixtral 等。 根据我的经验，我无法让 Autogen+LocalLLM 框架根据提示识别要使用的正确工具。然而，它在 GPT 模型上做得非常出色。  请注意，我的目标是让代理强制使用提供的工具，而不是提出自己的代码。代理应该找出正确的工具来使用。  我的提示非常明确，尽管如此，我仍无法使其正常工作。 有什么想法和建议吗？请告诉我 ！也请分享您的经验。干杯！   由   提交/u/perceptron333  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18tex1j/rp_autogen_langchain_tools_local_llm_doesnt_work/</guid>
      <pubDate>Fri, 29 Dec 2023 05:03:23 GMT</pubDate>
    </item>
    <item>
      <title>[研究] ML/DL算法、数学和理论的开源项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18t99v6/research_open_source_projects_for_mldl_algorithms/</link>
      <description><![CDATA[我正在研究 ML/DL 算法和所涉及的数学，并且对此有兴趣。我正在考虑继续阅读我关于这个主题的一些书籍。我还想找到一个最好用 Python 或 Julia 编写的开源项目，通过它我可以了解所涉及的重要或高级算法。随着时间的推移，我花了相当多的时间在 github 上查找，但似乎没有合适的东西可用。如果有人有任何想法或意见，请告诉我。   由   提交 /u/reluctantCanuck   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18t99v6/research_open_source_projects_for_mldl_algorithms/</guid>
      <pubDate>Fri, 29 Dec 2023 00:28:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] CLadder：评估语言模型因果推理能力的基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18t86kj/r_cladder_a_benchmark_to_assess_causal_reasoning/</link>
      <description><![CDATA[论文。我与作者没有任何关系。 摘要：  执行因果推理的能力被广泛认为是智力的核心特征。在这项工作中，我们研究大型语言模型 (LLM) 是否能够连贯地推理因果关系。自然语言处理（NLP）领域的大部分现有工作都侧重于评估法学硕士中的常识因果推理，因此无法评估模型是否可以根据一组明确定义的形式规则执行因果推理。为了解决这个问题，我们受到“因果推理引擎”的启发，提出了一个新的 NLP 任务，即自然语言中的因果推理。 Judea Pearl 等人提出的假设。我们构建了一个包含 10K 样本的大型数据集 CLadder：基于因果图和查询（关联、干预和反事实）的集合，我们通过预言机因果推理引擎获得符号问题和真实答案。然后将它们翻译成自然语言。我们在数据集上评估了多个法学硕士，并引入并评估了定制的思维链提示策略 CausalCoT。我们表明，我们的任务对于法学硕士来说极具挑战性，我们进行了深入分析，以更深入地了解法学硕士的因果推理能力。    由   提交 /u/Wiskkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18t86kj/r_cladder_a_benchmark_to_assess_causal_reasoning/</guid>
      <pubDate>Thu, 28 Dec 2023 23:39:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 个人项目的工作流程 - 云 GPU 提供商</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18t794g/d_workflow_for_personal_projects_cloud_gpu/</link>
      <description><![CDATA[因此，在工作中，我习惯于在笔记本电脑上使用 VS Code 通过 SSH 远程连接到具有 NVIDIA GPU 的 Linux 计算机。我想尝试为我的个人项目找到一个类似的环境。我不会做任何疯狂的事情（每月约 100 小时），但我看过的大多数选项（colabs、图纸空间渐变等）都是基于笔记本的，并没有给我带来我想要的灵活性。  我正在寻找一台可以 ssh 进入的机器，拥有一个永久磁盘（一旦虚拟机启动）并继续处理一个项目（git 可以用于该项目本身）。我倾向于 GCP，但无法弄清楚一些项目，例如如何定义我想要保留的自定义图像。  有什么建议吗？   由   提交 /u/SuperbMonk4403   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18t794g/d_workflow_for_personal_projects_cloud_gpu/</guid>
      <pubDate>Thu, 28 Dec 2023 22:59:16 GMT</pubDate>
    </item>
    <item>
      <title>纽约时报起诉 OpenAI 和微软侵犯版权 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18t73v1/new_york_times_sues_openai_and_microsoft_for/</link>
      <description><![CDATA[https://www.theguardian.com/media/2023/dec/27/new-york-times-openai-microsoft-lawsuit 诉讼指控：&lt; em&gt;“被告的 GenAI 工具由包含《纽约时报》内容副本的法学硕士提供支持，可以生成逐字背诵《纽约时报》内容、对其进行仔细总结并模仿其表达风格的输出”。该诉讼要求赔偿数十亿美元，并希望看到这些聊天机器人被摧毁。  我不知道摘要和风格模仿是否属于版权法，但逐字引用就不能被阻止吗？我不久前建议在这个 subreddit 中这样做：  OpenAI 不能简单地检查与训练数据共享长子字符串的输出（也许是概率上的）吗？  您可以简单地将所有训练数据子字符串（固定长度，例如 20 个标记）放入哈希表、布隆过滤器或类似的数据结构中。然后，当法学硕士生成文本时，您可以检查以确保文本不包含数据结构中的任何子字符串。这将防止逐字引用《纽约时报》或其他受版权保护的材料，长度超过 20 个标记（或您选择的任何长度）。将数据结构存储在内存中可能需要将其分布在多台机器上，但我认为 OpenAI 可以轻松负担得起。如果考虑内存问题，您可以通过分隔子字符串来进一步节省内存。   由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18t73v1/new_york_times_sues_openai_and_microsoft_for/</guid>
      <pubDate>Thu, 28 Dec 2023 22:53:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 随机分类器 F1 分数与 SEP28k 出版物不匹配</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18t6vq7/r_random_classifier_f1_score_mismatch_with_sep28k/</link>
      <description><![CDATA[我正在尝试重现 SEP28k 论文中基线模型的结果，但我很难获取详细信息。最引人注目的是，随机预测的 F1 分数与论文不符。以下是数据集类别的统计数据（如论文所述，来自数据集的 1k 个样本）：  Block Prolongation SoundRep WordRep Interjection count 1000 1000 1000 1000 1000 unique 2 2 2 2 2 top False False False False False freq 829 834 879 834 636  以及为每个标签随机选取 True/False 的 F1 分数： Block：0.29（纸质中的 0.14） Prolongation：0.25（纸质中的 0.13） SoundRep：0.23（ 0.095 in paper) WordRep: 0.22 (0.043 in paper) 感叹词: 0.38 (0.14 in paper)  我使用的评估代码是这样的： ``` import pandas as pd import torch from sklearn.metrics import f1_score STUTTERLABELS = [&#39;Block&#39;, &#39;Prolongation&#39;, &#39;SoundRep&#39;, &#39;WordRep&#39;, &#39;Interjection&#39;] if __name_ == &quot; ma​​in”： df = pd.read_csv(&#39;SEP-28k_labels.csv&#39;) df = df[STUTTER_LABELS][df[STUTTER_LABELS].values.sum(axis=1) &gt;= 2] df = df.sample(n=1000) print((df &gt;= 2).describe()) labels = torch.from_numpy(df.values &gt;= 2).long () preds = torch.randint_like(labels, high=2) 分数 = [f1_score(labels[:, i], preds[:, i]) for i in range(5)] paper_scores = [0.137, 0.128, 0.095, 0.043, 0.136, 0.46] for name, Score, paper_score in zip(STUTTER_LABELS, Scores, paper_scores): print(f&quot;{name}: {score:.2} ({paper_score:.2} in paper)&quot;) &lt; /code&gt; ``` 并且 csv 可在 SEP28k github 上获取。  我尝试过仅使用口吃语音和口吃/流利语音对数据集进行预测，但随机分类器的结果比论文中所说的要高得多。也许原因是我不确定“软预测层”是什么。意味着  两个模型都有两个输出分支：对五种事件类型中的每一种的流畅/不流畅预测和软预测  我假设它分别预测每个类别（例如，每个类别末尾的 sigmoid 5 个输出神经元）。 所以我的问题是： 1. F1 分数对于数据集统计是否合理 2. 软预测层只是对每个类分别进行预测吗？ &lt; !-- SC_ON --&gt;  由   提交/u/marek_jg  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18t6vq7/r_random_classifier_f1_score_mismatch_with_sep28k/</guid>
      <pubDate>Thu, 28 Dec 2023 22:43:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 总结科学论文的最佳模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18t4zvl/d_best_model_to_summarize_scientific_papers/</link>
      <description><![CDATA[大家好 假设我是法学硕士的新手。我有大约 4k 篇科学论文（已经是 .txt 格式），我想获取其摘要。我已阅读以下有关使用法学硕士总结文本的内容，并希望您对采取什么路径发表意见： ​  总结会让你受益匪浅结果不理想，应该坚持摘要 最好的方法是对每个部分进行摘要，然后将摘要合并起来。  法学硕士会因为文本太长而开始产生幻觉（例如，bart-large-cnn 是在 &lt;1000 字的文本上进行训练的，而论文却有 &gt;8000 字的。  我看到有人提到 Pegasus 和 LongT5，但不知道这些 textsum 项目似乎适用于任意长度的文本，但我不知道它是否适用于科学论文  vault-ai 使用 聪明的方法，但我想要一个本地解决方案。  我希望摘要能够解决一页长，而且比论文摘要更详细，所以我想知道逐节总结的方法是否是最好的。另外，我不知道是否有专门为科学论文设计的模型。我的论文不是数学或CS，但确实有一些方程和化学公式，尽管我对文本本身感兴趣，而不是对具体的数值结果感兴趣。  任何提示或建议都会受到赞赏。    由   提交/u/isgael  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18t4zvl/d_best_model_to_summarize_scientific_papers/</guid>
      <pubDate>Thu, 28 Dec 2023 21:24:48 GMT</pubDate>
    </item>
    <item>
      <title>理论机器学习的发展有多快？ [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18swhwf/how_fastmoving_is_theoretical_machine_learning/</link>
      <description><![CDATA[与应用机器学习/计算机科学其他领域的步伐是否存在差异？   由   提交/u/Street_Comfortable38   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18swhwf/how_fastmoving_is_theoretical_machine_learning/</guid>
      <pubDate>Thu, 28 Dec 2023 15:28:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 开源法学硕士在代码编辑方面与 OpenAI 相去甚远</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18st9wa/r_open_source_llms_are_far_from_openai_for_code/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2312.12450  标题：可以编辑吗？评估大型语言模型遵循代码编辑指令的能力 代码存储库：https://github.com/nuprl/ CanItEdit 摘要：  大量研究集中在开发和评估用于各种代码合成任务的大型语言模型。其中包括从自然语言指令合成代码、从代码合成测试以及合成代码解释。相比之下，法学硕士的教学代码编辑行为尚未得到充分研究。在这些任务中，模型被指示更新提示中提供的代码块。编辑指令可能会要求添加或删除功能、描述错误并要求修复、要求不同类型的解决方案或许多其他常见的代码编辑任务。我们引入了精心设计的代码编辑任务基准，并用它评估了几个前沿的法学硕士。我们的评估揭示了最先进的开放模型和封闭模型的能力之间的巨大差距。例如，即使是 GPT-3.5-Turbo 在编辑代码方面也比最好的开放模型好 8.8%。我们还引入了一套新的、精心策划的、经过许可的代码编辑训练集以及自然语言指令。使用这个训练集，我们表明我们可以微调开放代码法学硕士，以显着提高他们的代码编辑能力。  讨论： 我正在分享这篇论文开始讨论。免责声明：本文来自我们的研究小组，但无意在此进行自我推销。我们看到，在程序综合评估中，开源代码 LLM 慢慢地越来越接近 GPT-4 的性能，并超越了 GPT-3.5-turbo（请参阅 DeepSeek Coder：https://github.com/deepseek-ai/DeepSeek-Coder) 当使用常见基准测试时，例如 HumanEval、MBPP 和 *新* LeetCode 问题（这是为了最大限度地减少污染）。 但是，这不是您想要的方式。通常，需要修改一段带有自然语言指令的代码（例如，Cursor IDE 已经从 GitHub Copilot 风格转变为仅专注于代码编辑：https://cursor.sh/features）。此外，通过代码编辑训练的模型可以实现简单的代码生成，可以通过在窗口前用空白提示模型来将其视为代码编辑的子集。 在我们的各种研究项目中，我们已经看到代码法学硕士在代码编辑方面遇到了困难。所以我们做了显而易见的事情，我们检查了这些模型在这个特定任务中的表现。令人惊讶的是，与 GPT-3.5-turbo 相比，在简单合成方面表现出色的模型在代码编辑方面却表现不佳。 为什么会出现这种情况？虽然有些人认为存在数据污染，但考虑到这些模型在新的和未见过的基准上的有效性，我怀疑这是主要因素。难道 OpenAI 专门为代码或语言编辑等任务（模型然后泛化为代码）专门设置了一个特定的数据子集？ 更新： 在因不包含大于在我们的评估中，我决定评估 Tulu 2 DPO 70b，据报道，根据 Chatbot Arena 排行榜，它是最先进的 70b 指令调整 LLM（请参阅：聊天机器人竞技场排行榜）。我还评估了 Mixtral Instruct 0.1。 正如我所料，这两个模型的表现都不佳，可能是因为代码训练不足。可以合理地假设专门针对代码进行训练的 70b 模型会产生更好的结果。 Tulu 的性能稍逊于 CodeLlama-33b-chat，与 DeepSeek Coder 不相上下，与 GPT-3.5-Turbo 相差甚远。 ​  &lt; tr&gt; 模型 描述性 Pass@1（ExcessCode） 惰性 Pass@1（ExcessCode）&lt; /th&gt;    Tulu-2-DPO-70b 33.26 (1.41) 33.26 (1.41) 26.42 (1.58)   Mixtral-8x7B-Instruct-v0.1 25.0（1.0） 28.14（0.26）   ​   由   提交/u/ellev3n11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18st9wa/r_open_source_llms_are_far_from_openai_for_code/</guid>
      <pubDate>Thu, 28 Dec 2023 12:54:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>