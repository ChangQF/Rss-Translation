<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Wed, 07 Aug 2024 12:29:32 GMT</lastBuildDate>
    <item>
      <title>[P]“实际”值有误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1em9msa/p_error_in_actual_values/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1em9msa/p_error_in_actual_values/</guid>
      <pubDate>Wed, 07 Aug 2024 11:44:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT（4o 模型）如何对快照执行反向搜索？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1em9g6j/d_how_gpt_4o_model_is_able_to_perform_a_reverse/</link>
      <description><![CDATA[      我将从网络浏览器中运行的网站点击的此快照附加到 ChatGPT（4o 模型），并提示“此快照来自哪个网站？”  https://preview.redd.it/2gs4vjbr98hd1.png?width=1180&amp;format=png&amp;auto=webp&amp;s=b6ad8bee668748f920d834eb1cb2ab89d3f8c76c 并且答案是正确的“该快照似乎来自 Stack Overflow 的开发人员调查，该调查提供了不同国家/地区按类型划分的开发人员薪资的见解。您可以在 Stack Overflow 开发者调查结果页面上找到这些数据。&quot; 什么样的下游任务能够实现这一点？    提交人    /u/samajhdar-bano2   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1em9g6j/d_how_gpt_4o_model_is_able_to_perform_a_reverse/</guid>
      <pubDate>Wed, 07 Aug 2024 11:34:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大型科技公司与生物科技公司的 AI/ML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1em3ke2/d_aiml_in_big_tech_vs_biotech/</link>
      <description><![CDATA[我很好奇为什么一个优秀的 ML 工程师会离开大型科技公司（如谷歌、微软或 OpenAI）并加入生物科技公司。与科技公司正在发生的所有前沿创新相比，生物科技的吸引力何在？    提交人    /u/Pleasant_Wish1799   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1em3ke2/d_aiml_in_big_tech_vs_biotech/</guid>
      <pubDate>Wed, 07 Aug 2024 05:13:18 GMT</pubDate>
    </item>
    <item>
      <title>[R] 场景流估计的最新技术？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1em2uby/r_state_of_the_art_in_scene_flow_estimation/</link>
      <description><![CDATA[场景流估计的最新进展如何？如能提供建议，我们将不胜感激。    提交人    /u/DisciplinedPenguin   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1em2uby/r_state_of_the_art_in_scene_flow_estimation/</guid>
      <pubDate>Wed, 07 Aug 2024 04:31:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] GroundedAI：高效法学硕士评估的开源框架/模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elx6ok/p_groundedai_opensource_frameworkmodels_for/</link>
      <description><![CDATA[我很高兴与大家分享 GroundedAI，这是我开发的开源框架，用于使用微调的小型语言模型和专门的适配器来评估大型语言模型应用程序输出。  主要特点： - 评估 LLM 输出的毒性、RAG 相关性和幻觉 - 具有特定于度量的适配器的高效小型语言模型 - 使用不到 5GB VRAM 进行本地评估 - 易于使用的 Python 包 - 仅需 38 亿个参数即可与 GPT4 性能相媲美 该框架目前包括三个主要评估器：1. 毒性评估器 2. RAG 相关性评估器 3. 幻觉评估器 每个评估器都使用一个基础模型，该模型在预热期间与专门的适配器合并，从而实现高效和特定于度量的评估。 我们的模型在 Hugging Face 上可用：https://huggingface.co/grounded-ai 我们欢迎社区的贡献和反馈。查看我们的 GitHub repo https://github.com/grounded-ai/grounded_ai 了解更多详细信息和文档。 如果您有任何问题或改进想法，请告诉我！    提交人    /u/Jl_btdipsbro   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elx6ok/p_groundedai_opensource_frameworkmodels_for/</guid>
      <pubDate>Tue, 06 Aug 2024 23:53:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么过度参数化和重新参数化会产生更好的模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elvkz6/d_why_does_overparameterization_and/</link>
      <description><![CDATA[Apple 的 mobileCLIP 网络的主干是 FastVIT，它在训练和推理时间之间使用网络重新参数化来生成具有更好性能的较小网络。我最近在几篇论文中看到了这种现象，但基本思想是在训练期间对模型进行过度参数化，然后在数学上减少它以进行推理。例如，您可以创建两个“分支”，每个分支都是一个独立的转换操作，然后将结果相加，而不是执行单个转换操作。它在训练期间将操作的参数加倍，但在推理期间您“重新参数化”在这种情况下，这意味着将两个分支的权重/偏差加在一起，从而产生一个数学上相同的卷积操作（相同的输入，相同的输出，一个卷积操作而不是两个相加的分支）。 通过在训练期间在几个操作上添加跳过连接，然后在推理期间将跳过数学地合并到操作权重中以产生相同的输出，而无需保留较早的层张量或进行额外的添加，也可以完成类似的技巧。 这种情况似乎等同于在训练期间将 y = a*x + b 修改为 y = (a1+a2)*x +b1+b2 以获得更多参数，然后只需返回基本形式使用 a = a1+a2 和 b = b1+b2 进行推理即可。 我从数学上理解这些操作是等效的，但我不太明白为什么过度参数化用于训练，然后减少参数化用于推理会产生更好的模型。我天真地认为，这会给网络增加更多的内存和计算，降低训练速度，而实际上并没有增强模型的容量，因为过度参数化的操作在数学上仍然等同于单个操作，无论它们是否真的减少了。这背后有强有力的理论吗，还是有人尝试过的一个有趣的想法碰巧奏效了？    提交人    /u/Revolutionary-Fig660   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elvkz6/d_why_does_overparameterization_and/</guid>
      <pubDate>Tue, 06 Aug 2024 22:43:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] alphaXiv - ArXiv 的评论部分</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elqzle/r_alphaxiv_a_comments_section_for_arxiv/</link>
      <description><![CDATA[我一直在研究一个 arXiv 实验室项目，alphaXiv.org，这是一个直接建立在 arXiv 之上的论文评论和讨论部分。我觉得很多读者经常对论文有相同的疑问，所以我希望有一个中央论坛对研究界大有裨益。上周，我们被斯坦福大学人工智能实验室报道。 请查看并告诉我您的想法！该项目正在积极开发中，如果您想合作或有反馈，请直接发信息给我。    提交人    /u/Vivid_Perception_143   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elqzle/r_alphaxiv_a_comments_section_for_arxiv/</guid>
      <pubDate>Tue, 06 Aug 2024 19:36:45 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 使用 100 个愚蠢的 LLaMA 搜索，在 Python 上击败 GPT-4o</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elo2d1/discussion_beat_gpt4o_at_python_by_searching_with/</link>
      <description><![CDATA[ 从这个惨痛的教训中，我们应该学到的一点就是通用方法的强大威力，这些方法即使可用的计算量变得非常大，也会随着计算量的增加而不断扩展。似乎以这种方式任意扩展的两种方法是搜索和学习。 Richard Sutton，惨痛的教训  Richard Sutton 的文章中令人不快的结论经常被误解：他们说，因为规模就是你所需要的一切，所以较小的模型注定会变得无关紧要。模型大小迅速增加到一万亿个参数以上，加上 GPU 内存的技术限制，似乎阻碍了任何地方的经济前沿智能，除了情报即服务提供商的寡头垄断。开放模型和自助推理正在撤退。 但正如上面的引文所示，扩展箭筒中实际上有两支箭：学习和搜索。学习，就像我们现在用神经网络所做的那样，在推理时随着内存而扩展——在其他条件相同的情况下，更大的模型表现更好，因为它们可以从训练集中提取更多数据到更多电路和更多模板中。搜索在推理时随着计算而平稳扩展——计算可以用于产生更高质量的候选者或产生更多的候选者。在理想情况下，可以通过所谓的缩放定律预测缩放行为。 最近的论文表明，像 LLM 这样的生成模型可以通过搜索进行扩展。上周，Brown、Juravsky 和合著者在 arXiv 上发表了一篇名为 Large Language Monkeys 的论文，其中包含了这方面的几个结果，并表明某些领域的前沿级智能可以从可在单个上一代 GPU 上运行的较小模型中引出。此外，他们观察到随着规模的扩大，性能会呈现平稳、可预测的提升。 更简单地说：以前，似乎前沿能力需要一只马大小的鸭子，而现在，很明显，我们可以用一百匹鸭子大小的马（或者更确切地说，LLaMA）来实现。 这个周末，我们着手复制这一发现。 在 Modal 上扩展 LLaMA 3.1 8B HumanEval 运行我们所有的实验（包括配置和测试），成本都远低于 50 美元。 您可以在此处找到我们的代码。您可以自行运行它，且不超过 Modal 免费套餐中包含的 30 美元/月信用额度。 指标和数据：HumanEval 和 pass@k 继续原帖...    提交人    /u/thundergolfer   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elo2d1/discussion_beat_gpt4o_at_python_by_searching_with/</guid>
      <pubDate>Tue, 06 Aug 2024 17:41:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] 接地 SAM 2：接地并跟踪一切</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elmxnq/p_grounded_sam_2_ground_and_track_anything/</link>
      <description><![CDATA[      https://preview.redd.it/13854j03q2hd1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=0735848ae40c2591111fa4ed91d2c28ea829c0ac 随着 SAM 2 的发布，我们借此机会更新了我们的 Grounded SAM 算法。与 SAM 相比，SAM 2 最大的改进是将其分割功能扩展到视频，允许用户以交互方式分割视频中的任何对象并对其进行跟踪。然而，SAM 2 的主要问题是分割和跟踪的对象不包含语义信息。为了解决这个问题，我们延续了 Grounded SAM 的方法，加入了开放集检测模型，即 Grounding DINO。这使我们能够将 2D 开放集检测扩展到视频对象分割和跟踪。 我们已经在 https://github.com/IDEA-Research/Grounded-SAM-2 中发布了我们的代码，实现非常简单，方便用户使用。 项目亮点： 在此 repo 中，我们通过简单的实现支持以下演示：  使用 Grounding DINO、Grounding DINO 1.5 &amp; 1.6 和 SAM 2 对任何事物进行接地和分段 使用 Grounding DINO、Grounding DINO 1.5 &amp; 1.6 对任何事物进行接地和跟踪 1.6 和 SAM 2 基于强大的 https://github.com/roboflow/supervision 库检测、分割和跟踪可视化。  我们将继续更新代码，让用户更容易使用。    提交人    /u/Technical-Vast1314   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elmxnq/p_grounded_sam_2_ground_and_track_anything/</guid>
      <pubDate>Tue, 06 Aug 2024 16:55:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过异常声音检测识别水冷式 HVAC 系统的故障组件，并通过热视觉异常检测诊断随之而来的冷却故障。为了执行 AI 功能，该设备结合使用 Audio MFE 和 FOMO-AD 算法与 Web 应用程序。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elmnxp/p_identify_the_faulty_components_of_watercooled/</link>
      <description><![CDATA[        提交人    /u/the-amplituhedron   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elmnxp/p_identify_the_faulty_components_of_watercooled/</guid>
      <pubDate>Tue, 06 Aug 2024 16:44:57 GMT</pubDate>
    </item>
    <item>
      <title>“[D]” 针对高度不平衡的图像数据进行每类增强。这是好主意还是坏主意？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elg93d/d_per_class_augmentation_for_highly_imbalanced/</link>
      <description><![CDATA[在解决数据高度不平衡的计算机视觉问题时，我遇到了许多可以尝试的技术 - 从使用针对不平衡数据集定制的损失函数、类/样本权重，使用采样技术（如 SMOTE、加权随机采样器或只是常规随机采样）以及使用 GAN 来生成少数类的更多数据。然而，我想知道是否有人探索过每个类别的增强，即对不同类别应用不同的增强，少数类与多数类相比得到了大量增强。我搜遍了互联网，寻找表明为什么这可能是一个好主意或坏主意及其含义的材料，但无济于事。     提交人    /u/Antman-007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elg93d/d_per_class_augmentation_for_highly_imbalanced/</guid>
      <pubDate>Tue, 06 Aug 2024 12:17:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] RTX 4090 与 L40S 服务器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elenk8/d_rtx_4090_vs_l40s_for_server/</link>
      <description><![CDATA[大家好，我们公司正在为 AI 任务获取一台新服务器，我们正在考虑两种 GPU 配置：  4x RTX 4090 2x L40S  我们知道 4090s 的功耗更高，对环境的影响更大，但由于其成本原因，我们仍在考虑它们。 我们的主要用例：  运行和微调小型 LLM 以进行分类、嵌入和重新排名任务 可能运行和微调仅解码器模型（llama、gemma、phi...） GPU 将位于 Kubernetes 环境中  目前，我们所有的机器都处于 CPU 设置中，因此这是一个很大的对我们来说，改变 - 因此我们希望确保我们没有遗漏任何重要方面。 我们希望了解 L40S 在数据中心设置中的优势。我们可能会忽略哪些因素？L40S 是否有任何数据中心特定的功能对我们的工作负载特别有益？ 如果您能分享任何指导或经验，我们将不胜感激。谢谢！！    提交人    /u/ouzunkumhavuzu   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elenk8/d_rtx_4090_vs_l40s_for_server/</guid>
      <pubDate>Tue, 06 Aug 2024 10:51:37 GMT</pubDate>
    </item>
    <item>
      <title>[项目] - 如何展示模型缺失预测的推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1elejh3/project_how_to_showcase_reasoning_for_model/</link>
      <description><![CDATA[建立了一个模型，使用营销支出、可用产品数量、库存、我们何时发布等来预测需求。 展示了模型，但财务总监想知道模型为何没有达到预测结果。 例如，如果模型预测收入为 100 万英镑，而我们产生了 90 万英镑的收入，她想知道是什么导致了预测结果的不符。 关于如何展示这一点，您有什么想法吗？我最初的想法是输出我们在预测中使用的特征，而不是特征的实际值。所以，如果我们说我们会在营销上花费 10 万英镑，但我们花了 9 万英镑，这可能是导致预测结果不符的原因？ 不是 DS，在工作中学习。任何想法都将不胜感激    提交人    /u/Environmental_Pop686   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1elejh3/project_how_to_showcase_reasoning_for_model/</guid>
      <pubDate>Tue, 06 Aug 2024 10:44:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>