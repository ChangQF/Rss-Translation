<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 07 Dec 2023 09:13:51 GMT</lastBuildDate>
    <item>
      <title>[R] LongScope：法学硕士中长上下文中的碎片知识使用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18crfli/r_longscope_fragmented_knowledge_use_in_long/</link>
      <description><![CDATA[LongScope 旨在评估这些模型智能处理和集成分散在大量文本片段中的信息的能力，超越简单的句子提取或检索。 项目链接：https://github.com/mrconter1/LongScope/   由   提交 /u/Alarmed-Profile5736   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18crfli/r_longscope_fragmented_knowledge_use_in_long/</guid>
      <pubDate>Thu, 07 Dec 2023 08:49:28 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在构建诊断疾病的机器学习模型/算法方面需要建议/支持</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18cqqte/p_need_advicesupport_in_building_an_ml_model/</link>
      <description><![CDATA[你好！ 我热衷于开发一种可以根据图像诊断特定疾病的算法。对于任何形式的开发都绝对新鲜，我不知道从哪里开始。我在印度经营一家小型咨询公司，我有技术方面的经验，但我从未自己构建过。通过初步研究，我能够理解要使用 CNN 模型，因为该算法将正在处理图像。欢迎任何建议、注释或意见。 PS：我是新手。知道的不多。   由   提交/u/gaurav_dhyani   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18cqqte/p_need_advicesupport_in_building_an_ml_model/</guid>
      <pubDate>Thu, 07 Dec 2023 07:57:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 文本到 SQL 方法的最佳实践，AI ML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18cqckj/d_best_practice_on_text_to_sql_approach_ai_ml/</link>
      <description><![CDATA[嗨，团队，我正在开发一个小型 POC，我正在尝试利用 Text2SQL 或 nsql-350M 模型进行转换  文本到sql 在数据库中运行该sql 结果为自然语言  但问题是我有3 个数据库，我在想如果用户提出的自然问题以某种方式涉及 3 个数据库怎么办？最好的做法是什么？ - 我们是否应该将所有数据库模式共享给 nsql-350M 模型并使用连接查询对其进行训练？ - 或者，我们还有其他方法吗？ 参考：https://huggingface.co/NumbersStation/nsql -350M   由   提交 /u/santosanta   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18cqckj/d_best_practice_on_text_to_sql_approach_ai_ml/</guid>
      <pubDate>Thu, 07 Dec 2023 07:28:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] NeuroEvoBench：深度学习应用的进化优化器基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18cp7bl/r_neuroevobench_benchmarking_evolutionary/</link>
      <description><![CDATA[   /u/hardmaru  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18cp7bl/r_neuroevobench_benchmarking_evolutionary/</guid>
      <pubDate>Thu, 07 Dec 2023 06:12:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2023 海报打印地点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18cn7v1/d_place_to_print_poster_at_neurips_2023/</link>
      <description><![CDATA[我需要在 NeurIPS 2023 上展示一张海报。但是，由于某些问题，我无法在我的大学打印它。会议中心附近有没有可以快速打印海报的地方？ TIA   由   提交 /u/NitroZox   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18cn7v1/d_place_to_print_poster_at_neurips_2023/</guid>
      <pubDate>Thu, 07 Dec 2023 04:17:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 第一份 ICLR 提交材料。被拒绝了。总体来说很棒的体验。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18cl7r0/d_first_iclr_submission_got_rejected_great/</link>
      <description><![CDATA[我预计我的论文会被拒绝，但我还是尝试了一下。审稿人非常有帮助；尽管出现了所有“低质量评论”的情况，但我还是收到了相当高质量的建设性批评。  这是我的论文：Guided Sketch-Based Program Induction by Search Gradients | OpenReview   由   提交/u/Chromobacteria  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18cl7r0/d_first_iclr_submission_got_rejected_great/</guid>
      <pubDate>Thu, 07 Dec 2023 02:31:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] Mamba-Chat：基于状态空间模型的聊天法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ckntr/p_mambachat_a_chat_llm_based_on_state_space_models/</link>
      <description><![CDATA[嘿！ 您可能已经看过这篇论文最近几天的 Mamba 论文，这是首次尝试将状态空间模型扩展到 2.8B 参数以处理语言数据。 与 Transformer 相反，这这种架构的计算复杂度不会随输入长度呈二次方扩展，因此从长远来看，如果它能够取代 Transformer，那就太棒了。 我们对这篇论文和发布的模型感到非常兴奋，但不幸的是，没有训练代码提供了它，所以我们决定自己编写它并训练模型。因此，我们刚刚发布了 mamba-chat，这可能是现有的最好的不依赖于 Transformer 的 LLM。老实说，我对该模型的表现感到非常惊讶，因为它只有 2.8B 个参数，并且基本模型仅在 Pile 上进行训练。想到这些模型是否会在某个时候取代 Transformer 真是令人兴奋。 请随意查看我们的 Github 或 Huggingface 存储库！我们的 Github 存储库包含一个 cli 聊天脚本，因此如果您有权访问 GPU，则可以轻松运行模型。   由   提交 /u/pip-install-torch   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ckntr/p_mambachat_a_chat_llm_based_on_state_space_models/</guid>
      <pubDate>Thu, 07 Dec 2023 02:03:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 愚蠢的项目：使用变压器实现 MLP（哟，dawg...）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ceqz5/p_silly_project_implement_mlp_using_a_transformer/</link>
      <description><![CDATA[Transformers 严重依赖 MLP。据推测，LLM 可以回忆的事实存储在 MLP 中。 （例如，参见 ROME 论文。）这些 MLP 非常庞大。 例如考虑 GPT-Neo-350M。每个 MLP 有 1024 个元素的输入和输出层以及 4096 个元素的内层。这需要 2x1024x4096 = 4.2M 权重。整个模型有 24 个（每层一个），导致 MLP 使用 100M 权重。 然而这些 MLP 基本上只做 4096 点积来计算特征。数以百万计的权重只是为了计算 4096 点积并线性变换输入/输出，这似乎过多。 MLP 中的权重数量是输入元素数量的平方，因为每个内部元素都必须直接连接每个输入和输出元素。每个连接都很昂贵。我们可以做得更好吗？ 好吧，我们可以将 MLP 拆分为更小的 MLP。例如。将 1024 元素的输入向量划分为 4 256 元素的向量，并为每个块应用单独的 MLP。这样我们总共就有 4096 个内部特征，但权重数量减少了 4 倍！ 遗憾的是，这效果不太好，因为我们缺少“块”之间的交互。 &lt; p&gt;但是...有一种架构可以在令牌之间有效地路由信息...这就是变压器，对吧。 那么，我们可以将变压器放入 MLP 中吗？ （然后我们将在变压器内部的 MLP 内部有一个变压器。） 是的！有效吗？有点像。 我们可以制作一个旨在近似 MLP 的模块。我们将这种基于转换器的 MLP 近似称为 TransMLP。 为了了解该近似的效果如何，我们可以将其与其他近似进行比较。在本实验中，我的目标是逼近 GPT-Neo-350M 众多 MLP 之一。为了获取训练数据，我在 Brown 文本上运行 GPT 以捕获 MLP 输入和输出。 为了进行比较，我训练了正常的“GPTNeoMLP”在相同的数据上。这些 MLP 使用较小的内部中间层尺寸进行实例化。基础模型有 4096 个元素中间层，近似值有 2048 和 1024 个。 我们可以使用均方误差损失来比较近似值。对于零近似，我得到 2.6（这基本上是输出的均方）。  GPTNeoMLP 4096：...损失，840 万权重 GPTNeoMLP 1024：0.39 损失，2.1 M 权重 GPTNeoMLP 2048：0.31 损失，4.2M 权重 TransMLP：0.36 损失，2.9M 权重  所以 TransMLP 的损失接近到具有 2048 个特征的经典 MLP，同时权重更少。请注意，仅单个线性层需要 1M 权重，变压器本身只需要 1.9M 权重。 我不想对此进行全面评估，而是进行快速健全性检查：如果我们替换使用 TransMLP 的 GPT-Neo-350M 的正常 MLP，句子上的 GPT 损失从 2.965 增加到 2.9908（请注意，这不是 MSE 损失，而是交叉熵或类似的东西）。它仍然可以生成与基线模型一样好的文本。 所以，是的，我们可以将一个变压器放在 MLP 内部的变压器中...... 享受：https://colab.research.google.com/drive/1UIDXF_x_Y7QWMQrteGaNHQ7Y9S-ZgeoF   由   提交/u/killerstorm  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ceqz5/p_silly_project_implement_mlp_using_a_transformer/</guid>
      <pubDate>Wed, 06 Dec 2023 21:28:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将我的 VAE 潜在分布从正态分布切换为分类分布，但我需要一种方法来替换高斯乘法运算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18caf50/d_switching_my_vaes_latent_distribution_from/</link>
      <description><![CDATA[所以我一直在重新实现一个具有循环潜在分布的 VAE。在每个新输入之后，使用编码器输出和当前潜在分布的高斯乘法来更新潜在分布。  该模型没有学习到良好的表示，我知道最近的 Dreamer 模型从连续潜在状态切换到分类潜在状态，这提高了性能，所以我想尝试一下。 但是，对于分类分布，没有等价的高斯乘法。我决定对新旧分布参数进行加权平均，其中权重由分布的逆熵确定（因此它们或多或少根据“不确定性”代理进行加权）。我知道这只是一种启发式的方法，并没有任何可靠的数学推理来支持它。  有谁知道更好的方法来实现这一点，或者有人遇到过类似的情况吗？   由   提交 /u/SmeatSmeamen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18caf50/d_switching_my_vaes_latent_distribution_from/</guid>
      <pubDate>Wed, 06 Dec 2023 18:22:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自旋模型变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ca7zr/p_spinmodel_transformers/</link>
      <description><![CDATA[变压器的非平衡统计力学视角。 我们提出了一类基于矢量平均场动力学的变压器-旋转模型。我们的框架支持非对称耦合并产生残差、注意力和前馈项。 帖子： https://mcbal.github.io/post/spin-model-transformers 代码（JAX）：https://github.com/mcbal/spin-model-transformers   由   提交/u/mcbal2666  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ca7zr/p_spinmodel_transformers/</guid>
      <pubDate>Wed, 06 Dec 2023 18:14:23 GMT</pubDate>
    </item>
    <item>
      <title>[R]谷歌发布Gemini系列前沿机型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c6xio/r_google_releases_the_gemini_family_of_frontier/</link>
      <description><![CDATA[来自 Jeff Dean 的推文：https://twitter。 com/JeffDean/status/1732415515673727286 博客文章：https:// blog.google/technology/ai/google-gemini-ai/ 技术报告：https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf 有什么想法吗？没有太多“肉”在这个公告中！他们肯定担心其他实验室+开源从中学习。   由   提交/u/blabboy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c6xio/r_google_releases_the_gemini_family_of_frontier/</guid>
      <pubDate>Wed, 06 Dec 2023 15:52:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么仅解码器模型用于自回归生成而不是仅编码器模型？如果新标记尚不存在，因果掩码的值是多少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18c498u/d_why_are_decoder_only_models_used_for/</link>
      <description><![CDATA[为什么还要费心使用因果掩码，看起来它只是破坏了有用的信息传输？我知道，如果你用它进行训练，你就无法在推理过程中轻松删除它而不降低质量，但为什么不直接训练编码器来猜测此时的下一个标记呢？    由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18c498u/d_why_are_decoder_only_models_used_for/</guid>
      <pubDate>Wed, 06 Dec 2023 13:43:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么大多数开源人工智能都发生在美国境外？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18by3wo/d_why_is_most_open_source_ai_happening_outside/</link>
      <description><![CDATA[我不认为这太双曲线。美国有 Meta，除此之外几乎没有什么，特别是与外部的相比。 我并不是说要在美国扣篮，我真的只是感到震惊。 &lt; strong&gt;中国：Yuan、Qwen、DeepSeek、Yi、XVERSE、Aquila、RWKV，都是当今顶级的法学硕士。 一打很棒的（顶级）多模式。顶级嵌入模型。 英国：稳定性 法国： Mistral 芬兰（？）： Lumi Poro 阿联酋： Falcon 俄罗斯：康定斯基 &lt; p&gt;美国：Meta 有 Llama 和其他一些好东西，Salesforce 有一些东西，“OpenAI”等。  是监管环境吗？是投资问题吗？是GPU短缺吗？大型科技公司是否挖走了并锁定了所有美国人才？ 有人有任何线索吗？ 编辑： 哇，我走出了大门。我的要求越来越合理。这里提到的所有模型都是经过预训练的模型。是的，美国社区可以进行微调，但这没有表达我的观点。昂贵的 OSS 工作正在美国境外进行。如果你说“那不是 OSS”，好吧，它仍然主要发生在美国境外。再说一遍，不是在美国扣篮，只是问一个问题，并希望看到更多的美国公司出现在 OSS 贡献者名单上。   由   提交 /u/BayesMind   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18by3wo/d_why_is_most_open_source_ai_happening_outside/</guid>
      <pubDate>Wed, 06 Dec 2023 06:45:18 GMT</pubDate>
    </item>
    <item>
      <title>Apple 发布“MLX” - Apple Silicon 的 ML 框架 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bwe19/apple_releases_mlx_ml_framework_for_apple_silicon/</link>
      <description><![CDATA[Apple 的 ML 团队刚刚在 GitHub 上发布了“MLX”。他们针对 Apple Silicon 的 ML 框架。 https://github.com/ml-explore/mlx CUDA 的现实替代方案？ MPS 已经非常高效...如果我们看到采用，这可能会变得有趣。 ​   由   提交 /u/LoadingALIAS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bwe19/apple_releases_mlx_ml_framework_for_apple_silicon/</guid>
      <pubDate>Wed, 06 Dec 2023 05:00:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>