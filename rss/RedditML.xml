<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 31 Aug 2024 18:18:44 GMT</lastBuildDate>
    <item>
      <title>[D] 四年来我构建 MLOps 系统的经验教训</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5ojdu/d_what_ive_learned_building_mlops_systems_for/</link>
      <description><![CDATA[这是我四年来构建 MLOps 系统所学到的知识 http://mburaksayici.com/blog/2024/08/29/what-ive-learned-building-mlops-systems-for-four-years.html    提交人    /u/mburaksayici   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5ojdu/d_what_ive_learned_building_mlops_systems_for/</guid>
      <pubDate>Sat, 31 Aug 2024 14:27:27 GMT</pubDate>
    </item>
    <item>
      <title>[N][R] 发布 Re-LAION 5B：LAION-5B 的透明迭代，并附加安全修复</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5o0kj/nr_releasing_relaion_5b_transparent_iteration_on/</link>
      <description><![CDATA[        提交人    /u/Jamais_Vu206   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5o0kj/nr_releasing_relaion_5b_transparent_iteration_on/</guid>
      <pubDate>Sat, 31 Aug 2024 14:03:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能 CPU 推荐 AMD 或 Intel</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5nj4n/d_cpu_recommendation_amd_or_intel_for_ai/</link>
      <description><![CDATA[您好 r/MachineLearning，我即将组装我的第一台 PC，我想知道最适合 AI 的 CPU 是什么。我知道 GPU 承担了大部分繁重的工作，但我希望得到好的 CPU 推荐。我还听朋友说英特尔最适合 AI。我也经常玩游戏。请帮我挑选合适的 CPU（仅限消费级）。     提交人    /u/Excellent_Respond330   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5nj4n/d_cpu_recommendation_amd_or_intel_for_ai/</guid>
      <pubDate>Sat, 31 Aug 2024 13:40:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用 FastText 实现在线/增量学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5n5j7/d_how_can_i_implement_onlineincremental_learning/</link>
      <description><![CDATA[大家好，随着新的单个数据样本的到来，我正在逐步训练 FastText。由于 FastText 是使用 SGD 进行训练的，所以我认为这应该是可能的。但是，我还没有找到使用 Python API 执行此操作的方法。可以加载预训练的词向量，我认为我们可以保存和加载训练后的向量来实现这一点，但我担心这可能会产生太多开销。有人找到处理这个问题的方法吗？有什么建议吗？    提交人    /u/hellowrld3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5n5j7/d_how_can_i_implement_onlineincremental_learning/</guid>
      <pubDate>Sat, 31 Aug 2024 13:22:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 受 Andrej Karpathy 启发，我制作了 NLP - Zero to Hero</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5ljxq/p_inspired_by_andrej_karpathy_i_made_nlp_zero_to/</link>
      <description><![CDATA[        由    /u/Particular_Tap_4002   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5ljxq/p_inspired_by_andrej_karpathy_i_made_nlp_zero_to/</guid>
      <pubDate>Sat, 31 Aug 2024 11:56:39 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 使用哪种 SSD？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5jg4a/discussion_which_ssd_to_use/</link>
      <description><![CDATA[我有两个 SSD 驱动器。 https://ssd.skhynix.com/platinum_p41/ (2TB) https://www.westerndigital.com/products/portable-drives/portable-ssd-sandisk-extreme-usb-3-2?sku=SDSSDE61-4T00-G25 (4TB) 第一个速度更快且为内置，而第二个速度较慢且为外置。 我听说 SSD 在机器学习方面比 HDD 好得多，因为它的速度更快。 我想知道的是：将第二个用于 ML（DL 也一样）可以吗？它够快吗？因为它毕竟也是 SSD。 我想使用第二个，因为第一个是我的主驱动器，并且该驱动器上安装了很多程序（包括 Windows）。另外，第二个有更多空间。而且我想有一个完全专用于我的 ML 内容的驱动器。 您有什么想法？    提交人    /u/max6296   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5jg4a/discussion_which_ssd_to_use/</guid>
      <pubDate>Sat, 31 Aug 2024 09:34:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 感知相似性用于衡量游戏中的决策风格和政策多样性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5hfzf/r_perceptual_similarity_for_measuring/</link>
      <description><![CDATA[论文： https://openreview.net/forum?id=30C9AWBW49 摘要：  定义和衡量决策风格（也称为游戏风格）在游戏中至关重要，因为这些风格反映了广泛的个性和多样性。然而，找到一种普遍适用的衡量这些风格的标准是一项挑战。基于第一个基于游戏屏幕和原始动作衡量游戏风格相似性的无监督指标，通过识别具有离散表示的可比状态来计算策略距离，我们引入了三种增强功能来提高准确性：具有不同状态粒度的多尺度分析、植根于心理学的感知内核以及利用交并法进行有效评估。这些创新不仅提高了测量精度，而且还提供了对人类对相似性的认知的洞察。在两款赛车游戏和七款 Atari 游戏中，我们的技术显著提高了零样本游戏风格分类的精度，在少于 512 个观察-动作对（不到这些游戏的一半）的情况下实现了超过 90% 的准确率。此外，我们的实验展示了离散游戏风格测量在益智和棋盘游戏中的潜力。我们还开发了一种使用这些指标评估决策多样性的算法。我们的研究结果改进了端到端游戏分析的测量和人工智能对不同游戏风格的演变。  您如何看待使用离散状态来比较风格的想法？    提交人    /u/Cold-Needleworker709   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5hfzf/r_perceptual_similarity_for_measuring/</guid>
      <pubDate>Sat, 31 Aug 2024 07:08:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有关重现结果的帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5fq26/d_help_regarding_reproducing_results/</link>
      <description><![CDATA[你好。我最近一直在研究对抗性自监督学习，并试图重现 DynCL 论文《重新思考数据增强在对抗性对比学习中的作用》中的结果。在他们的 GitHub 存储库中，他们提供了一个检查点文件，当我对该检查点进行微调时，结果是可重现的。但是，当我尝试训练他们的模型时，它的表现严重不佳。我尝试在 GitHub 存储库中提出问题，但没有得到回复。那么，我该怎么做？如果我想用我的方法对其进行基准测试，我应该使用我重现的结果还是他们论文中给出的值？他们的结果似乎有点可疑，但经过非常简单的修改，他们取得的改进非常大。尽管我希望并希望这是真的，但结果的重现似乎并不意味着如此。 任何帮助都值得赞赏。谢谢。     由    /u/SmartEvening 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5fq26/d_help_regarding_reproducing_results/</guid>
      <pubDate>Sat, 31 Aug 2024 05:12:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能博士学位建议——需要顶尖大学吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5ackj/d_ai_phd_advice_top_university_required/</link>
      <description><![CDATA[大家好，我来征求一下建议。我是俄勒冈州立大学的 AI 博士生。我对使用 genAI 为使用 rag 管道的医生提供临床决策辅助特别感兴趣，这显然比我刚才解释的要复杂得多。 我的问题是：大多数情况下，我在类似的服务器上看到，你必须就读顶尖机构才能进入知名公司等。 因为我没有就读排名前 10 的大学，这会妨碍我找到工作的机会吗？根据 csrankings.org 的排名，俄勒冈州立大学排名第 53 位。 任何建议/评论都非常感谢    提交人    /u/frankies_wrld   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5ackj/d_ai_phd_advice_top_university_required/</guid>
      <pubDate>Sat, 31 Aug 2024 00:15:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 对于多智能体纸牌游戏，我应该尝试哪种 RL 算法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f55ndj/p_what_rl_algorithm_should_i_try_for_a_multiagent/</link>
      <description><![CDATA[我目前正在学习 RL 和 AI，并在 PyTorch 中尝试了 DQN 和 Double DQN。 我想尝试实现一个多智能体纸牌游戏，我想听听你们的意见，了解最好的入门方法。由于这是一个不完全信息游戏，我认为更简单的方法不适用于此。 我为此建立了一个概念证明，其中 4 个 Double DQN 智能体相互对抗，每个模型都会从环境中分配一个玩家，然后进行游戏。作为状态，我给了它表中所有类型卡片的数量（13 个值）、手中所有类型卡片的数量（13 个值）以及有关游戏的更多信息。 不幸的是，正如预期的那样，它无法学到太多东西，所以我正在寻找其他选择。 这是游戏：https://bicyclecards.com/how-to-play/presidents 此外，我遇到的一个问题是模型在选择有效的动作时遇到了问题（它通常没有足够的所选类型的卡片，或者它与桌面上的卡片不匹配）。    提交人    /u/Neither_Butterfly_51   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f55ndj/p_what_rl_algorithm_should_i_try_for_a_multiagent/</guid>
      <pubDate>Fri, 30 Aug 2024 20:43:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 比较用于文档数据提取的 LLM API – 我的经验和寻找见解！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4wqak/d_comparing_llm_apis_for_document_data_extraction/</link>
      <description><![CDATA[大家好， 我最近写了一篇文章，比较了用于文档数据提取的各种 LLM API，您可以在这里查看。 完整免责声明：我在 Nanonets 工作，因此我的观点可能存在一些偏见，但我确实试图尽可能客观地进行这种比较。 在本文中，我比较了 Claude、Gemini 和 GPT-4 在文档理解和从各种类型文档中提取数据的有效性。我在不同的文档上测试了这些模型，以了解它们对内容的理解和推理能力，并在博客中分享了我的发现。 我非常好奇您使用这些 API 或其他 API 执行类似任务的经验：  您是否尝试过使用 LLM API 进行文档理解和数据提取？进展如何？ 哪些 API 最适合您，为什么？ 您是否遇到了本文未涉及的挑战？ 您对 LLM 在文档理解和数据提取方面的未来有何看法？     提交人    /u/Longjumping_Media365   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4wqak/d_comparing_llm_apis_for_document_data_extraction/</guid>
      <pubDate>Fri, 30 Aug 2024 14:31:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] WACV 2025 试卷评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4wj0j/d_wacv_2025_paper_reviews/</link>
      <description><![CDATA[WACV 2025 论文评论应该在今天发布。讨论主题会很有用！    由    /u/smokeriffs  提交  [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4wj0j/d_wacv_2025_paper_reviews/</guid>
      <pubDate>Fri, 30 Aug 2024 14:23:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年 Google 博士奖学金结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f4w1tr/d_results_for_google_phd_fellowship_2024/</link>
      <description><![CDATA[有人从 Google 那里听说过关于博士奖学金计划结果的消息吗？我以为他们会在去年 7 月通知大家。    提交人    /u/EDEN1998   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f4w1tr/d_results_for_google_phd_fellowship_2024/</guid>
      <pubDate>Fri, 30 Aug 2024 14:02:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将任何初学者问题发布至 r/MLQuestions！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f3yfjg/d_post_any_bginner_questions_to_rmlquestions/</link>
      <description><![CDATA[我最近继承了 subreddit r/MLQuestions，因为其他版主分别有 10 个月和 4 年没有活动。我一直在整理子版块，添加标签、规则等，并试图增加参与度，使其对那些想要提问的人更有用。基本上就是 stackoverflow，但专门用于解决有关 ML 的初学者问题。所以，如果你们有不好意思在这里问的问题，请在 r/MLQuestions 上提问！我还将推出一个类似于 r/changemyview 的系统，其中每回答一个问题，他们的用户天赋就会增加一个，显示他们回答了多少问题！ 顺便说一句，版主允许我发布这篇文章，所以非常感谢你们，非常酷。    提交人    /u/NoLifeGamer2   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f3yfjg/d_post_any_bginner_questions_to_rmlquestions/</guid>
      <pubDate>Thu, 29 Aug 2024 09:50:39 GMT</pubDate>
    </item>
    </channel>
</rss>