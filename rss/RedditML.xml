<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 29 Jun 2024 06:18:49 GMT</lastBuildDate>
    <item>
      <title>[P] Lyso：一款免费、易用、准确的音频转录器，具有说话人分类功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dr43ln/p_lyso_a_free_easytouse_and_accurate_audio/</link>
      <description><![CDATA[链接：https://lysoai.com/ 我的项目做什么 Lyso 是一款免费、易于使用且准确的音频转录器，具有说话者分类功能（根据说话者的身份将音频流划分为多个片段），可准确处理几乎任何音频和视频文件类型。 特点：✅终身免费✅最大文件大小：1GB✅最大文件时长：5 小时✅支持跨多个选项卡或会话的无限制并发请求✅支持多种语言（虽然不如英语准确）✅支持的音频文件类型：.aiff，.m4a，.flac， .m4r、.wav、.m4b、.mp3、.ac3、.ogg、.oga、.mogg、.opus、.amr、.ape、.au、.dss、.m4p、.qcp、.tta、.voc、.wma、.wv、.3ga、.8svx、.aac、.aif、.alac、.flv✅支持的视频文件类型：.mov、.mp4、.m4v、.mp2、.mts、.webm、.mxf、.m2ts、m4p（带 DRM）、.ts✅用户友好的网络界面✅无需注册或登录✅无广告 比较 1) 目前，有许多免费选项可用于将音频准确地转录为文本，但其中大多数（如 OpenAI 的 Whisper）不包括说话人日记。此外，那些免费提供说话人日记的服务缺乏准确性。 2) 有一些服务提供准确的转录和说话人日记，但需要付费。其中一些有试用期，但它们对并发请求的数量施加限制，或者要求文件的大小或持续时间非常小，这可能会令人烦恼。    提交人    /u/prateekvellala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dr43ln/p_lyso_a_free_easytouse_and_accurate_audio/</guid>
      <pubDate>Sat, 29 Jun 2024 05:38:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 这是一个回归问题还是排名问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqzgh8/p_is_it_a_regression_or_ranking_problem/</link>
      <description><![CDATA[大家好！ 我正在制作一个带有强化学习的俄罗斯方块机器人，但我不确定应该采用哪种方法： 我不希望我的 NN 输出与移动相对应的键；我想要的是我的神经网络能够对网格进行评分 基本上，我可以从单个向量中的网格中获取一些键值（例如每列的高度、填充行的 nb...），我正在计算与“猛击”结果相对应的多个网格将四格骨牌放在多个 x 坐标处，然后我想移动到与所有网格中得分最高的网格的位置 但这是一个回归问题吗？ 因为我的模型只需要学习输出一个对应于单个网格得分的单个数字，所以我得到了每个网格的得分，然后得到了得分最高的网格 如果是的话，我能否正确微调损失，因为奖励只来自于我将做出的最后一步，所以很多预测没有得到正确的纠正？ 或者是排名问题？ 因为我的模型应该学会从所有&quot;feeded&quot; 作为输入的网格中给出最好的结果 我试图查看&quot;排名&quot;可以在 PyTorch 中完成，但我似乎找不到方法，我缺乏有关如何搜索合适框架来执行此操作的知识 感谢您的时间！    提交人    /u/Mikgician   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqzgh8/p_is_it_a_regression_or_ranking_problem/</guid>
      <pubDate>Sat, 29 Jun 2024 01:13:33 GMT</pubDate>
    </item>
    <item>
      <title>语音生成模型建议建立数据集来检测言语障碍儿童的言语错误 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqy6rw/speech_generation_model_suggestions_for_building/</link>
      <description><![CDATA[我正在尝试构建一个音频分类模型，该模型可以检测出患有言语障碍的儿童的言语错误，以进一步帮助治疗过程。 由于真实数据的可用性低，我想在合成语音数据上启动训练过程。 为此，我需要生成器模型来发音一个单词（音素列表），其中我们用通常由儿童替换的音素替换一些音素。 我尝试过 suno/bark 和 espeak，但它们无法正确生成错误的单词。 请建议一些严格遵守所提供音素的语音生成模型。    提交人    /u/Agreeable_Ad_1085   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqy6rw/speech_generation_model_suggestions_for_building/</guid>
      <pubDate>Sat, 29 Jun 2024 00:06:53 GMT</pubDate>
    </item>
    <item>
      <title>[p] 对电子邮件进行分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqugja/p_categorising_email_segments/</link>
      <description><![CDATA[大家好！ 我一直在尝试使用机器学习对工作中收到的电子邮件进行分类，但一直很难找到可行的方法 我们在能源部门工作，模型需要了解很多特定领域的知识，才能理解客户的需求，然后对其进行正确排序。 主要问题是工作人员只对整个电子邮件链进行分类，而不是对其中的单个电子邮件进行分类 最终目标是能够对员工的工作进行分类，同时也能轻松报告客户的要求（因为代理有时会忘记或做错标签） 有些方法我还没有探索过。 -创建干净的电子邮件段以对数据集进行分类，对其进行矢量化，并将其类别用于 RAG，在那里我将获得 5 个最相似的电子邮件段，然后使用它们来帮助决定新的电子邮件段 -围绕 llama3 构建的某种代理框架，收到一堆请求来猜测和检查工作 -创建一个干净且正确的数据集以用于微调 如果您有任何想法，请告诉我！    提交人    /u/Kooky_Fun6918   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqugja/p_categorising_email_segments/</guid>
      <pubDate>Fri, 28 Jun 2024 21:14:16 GMT</pubDate>
    </item>
    <item>
      <title>[P]图注意力网络。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqrdr8/pgraph_attention_network/</link>
      <description><![CDATA[我正在尝试训练一个模型，以便它可以预测在路面上施加负载时的应变。我正在训练模型，以便它模仿 3D 分层弹性分析技术，但模型无法预测。我不确定模型是否正在接受训练。它从 5 个最近的邻居那里获取信息并传递消息。即使在训练了 10k 个时期后，模型也无法预测。我不知道模型在哪里收敛。有人可以指导我吗？    提交人    /u/Secret_Dinner7822   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqrdr8/pgraph_attention_network/</guid>
      <pubDate>Fri, 28 Jun 2024 19:00:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人见过 Kolmogorov-Arnold 网络在现实中的应用吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqr9gh/d_anyone_see_any_real_usage_of_kolmogorovarnold/</link>
      <description><![CDATA[KAN 在各处（包括 Reddit）都备受热捧，许多人都对它赞不绝口，尽管并非都是好评。现在已经过去 3 个月了。有没有人看到任何可以证实或反驳“信徒”的东西？就我个人而言，我没有看到任何值得注意的 KAN 采用​​情况。希望听听社区的意见。    提交人    /u/Sad-Journalist752   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqr9gh/d_anyone_see_any_real_usage_of_kolmogorovarnold/</guid>
      <pubDate>Fri, 28 Jun 2024 18:55:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] “Grok” 有太多不同的含义</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqpyb3/d_grok_means_way_too_many_different_things/</link>
      <description><![CDATA[我厌倦了到处看到这个词，而且它每次在同一个领域都有不同的含义。对我来说，第一次是当伊隆·马斯克推出并大肆宣传 Twitter 的新产品（现在不是新的，但当时是）“Grok AI”时，然后我阅读了更多论文，发现了一个相当惊人的发现，显然地球上的每个人都知道了一段时间，除了我之外，那就是在某个点之后，过度拟合模型开始能够概括，这摧毁了我之前的许多先入为主的观念以及我在学校和其他地方学到的东西。但这种现象也被称为“Grok”，然后有一篇基于 Grok 定义的新“GrokFast”论文，还有“Groq”，不要与其他两个“Grok”混淆，更不用说伊隆·马斯克将他的人工智能装备命名为“xAI”机械可解释性人们已经在使用该术语作为“可解释的 AI”的缩写，这对我来说太多了    提交人    /u/Traditional_Land3933   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqpyb3/d_grok_means_way_too_many_different_things/</guid>
      <pubDate>Fri, 28 Jun 2024 17:59:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 上下文增强检索：一种使用大型语言模型进行快速信息检索的响应生成新框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqnxm9/r_contextaugmented_retrieval_a_novel_framework/</link>
      <description><![CDATA[  由    /u/davidmezzetti  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqnxm9/r_contextaugmented_retrieval_a_novel_framework/</guid>
      <pubDate>Fri, 28 Jun 2024 16:33:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 最小分页注意力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqnaa4/p_minimal_paged_attention/</link>
      <description><![CDATA[我展示了 PagedAttention 如何以最少的 &lt;300 行代码实现吞吐量的提高。 https://github.com/tspeterkim/paged-attention-minimal/    提交人    /u/droidarmy95   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqnaa4/p_minimal_paged_attention/</guid>
      <pubDate>Fri, 28 Jun 2024 16:06:56 GMT</pubDate>
    </item>
    <item>
      <title>掩模引导分类[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqldtv/maskguided_classification_d/</link>
      <description><![CDATA[是否有人使用过掩码引导注意力进行图像分类或尝试在分割网络上构建分类模型？ 为了简化我的问题，我有医学图像、掩码（掩码中的 3+1 个类表示其中的特定器官）和标签（6 个类主要取决于掩码中器官的大小/形状）。 我尝试过 -  仅使用图像进行分类，没有掩码信息，使用 CNN、Transformers 等 - 结果较差，准确率只有 40%（比随机的 6 个类好） 使用这篇文章附带的链接。我寄予厚望，但得分只有 50% 左右。我想有类似的方法使用掩码来指导我的 clf 模型。请提出建议。 仅使用 maks 进行分类。由于形状/大小是突出的特征，我认为只使用掩码是个好主意。得分比 [1] 好。  只剩下一件事了 - 在分割模型之上构建分类模型。也许是数据驱动的方法。但我想知道是否有更多或已知的技术来解决此类问题？ 如果有人可以，请分享 repo、论文。欢迎所有输入。    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqldtv/maskguided_classification_d/</guid>
      <pubDate>Fri, 28 Jun 2024 14:47:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] Paddler（为 llama.cpp 定制的状态负载均衡器）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dql325/p_paddler_stateful_load_balancer_customtailored/</link>
      <description><![CDATA[我最近开始了这个项目。它允许我们自行托管 llama.cpp 并将其与开源模型一起使用。 它最近开始获得一些关注，并且已经准备好投入生产。 它允许从零实例扩展，因此如果您使用云提供商使用开源 LLM 为您的想法制作原型，则只需为实际使用的内容付费。如果有一段时间不活动，您可以使用它来关闭昂贵的 GPU 实例，只留下一些便宜的 CPU 实例，平衡器本身正在运行。 它可以部署在任何云或 Kubernetes 集群中。它有一些 AWS 辅助实用程序，可轻松在那里部署，但这些都是可选的。 Paddler 不会强迫您以特定方式配置 llama.cpp。您可以以任何方式配置您的 llama.cpp 实例，它会插入其 HTTP API。 https://github.com/distantmagic/paddler    提交人    /u/mcharytoniuk   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dql325/p_paddler_stateful_load_balancer_customtailored/</guid>
      <pubDate>Fri, 28 Jun 2024 14:33:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 深度学习论文摘要</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqg67i/r_deep_learning_paper_summaries/</link>
      <description><![CDATA[印度理工学院鲁尔基分校的视觉语言小组对来自 NeurIPS、CVPR、ICCV、ICML 2016-24 等各个著名会议的深度学习论文进行了全面的总结。一些值得注意的例子包括：  DreamBooth：针对主题驱动生成对文本到图像扩散模型进行微调，CVPR&#39;23 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/DreamBooth.md Segment Anything，ICCV&#39;23 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Segment_Anything.md 一张图片胜过一个词：使用个性化文本到图像生成文本反转，ICVR&#39;23 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Textual_inversion.md 具有深度语言理解的逼真文本到图像扩散模型，NIPS&#39;22 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/imagen.md 一张图片胜过 16X16 个单词：用于大规模图像识别的 Transformers，ICLR&#39;21 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Vision_Transformer.md Big Bird：用于更长序列的变换器，NIPS&#39;20 https://github.com/vlgiitr/papers_we_read/blob/master/summaries/Big_Bird_Transformers.md  如果您发现这些摘要有用，您可以贡献自己的摘要。 repo 将不断更新来自领先会议的更多论文摘要。    提交人    /u/vlg_iitr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqg67i/r_deep_learning_paper_summaries/</guid>
      <pubDate>Fri, 28 Jun 2024 10:09:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 分割任意文本：一种稳健、高效且适应性强的句子分割通用方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqfhn6/r_segment_any_text_a_universal_approach_for/</link>
      <description><![CDATA[      标题：分割任何文本：一种稳健、高效且适应性强的句子分割通用方法高效且适应性强的句子分割 论文： https://arxiv.org/abs/2406.16678 代码： https://github.com/segment-any-text/wtpsplit https://preview.redd.it/6frvmpc36a9d1.png?width=1849&amp;format=png&amp;auto=webp&amp;s=08c9769384d63bfd3ad786b0259f1dd4a97d4bce 摘要：  将文本分割成句子在许多 NLP 系统中起着早期和关键的作用。这通常通过使用基于规则或统计的方法来实现，这些方法依赖于标点符号等词汇特征。尽管最近的一些研究不再完全依赖标点符号，但我们发现，之前的方法都无法同时实现 (i) 对缺失标点符号的稳健性、(ii) 对新领域的有效适应性和 (iii) 高效率。我们引入了一个新模型 - 分割任何文本 (SaT) - 来解决这个问题。为了增强稳健性，我们提出了一种新的预训练方案，以确保减少对标点符号的依赖。为了解决适应性问题，我们引入了一个额外的参数高效微调阶段，在不同领域（例如歌词和法律文件中的诗句）建立了最先进的性能。在此过程中，我们引入了架构修改，使速度比以前的最先进水平提高了三倍，并解决了未来对上下文的虚假依赖。最后，我们引入了我们的模型的一个变体，该变体对多种多语言的句子分割数据进行了微调，作为现有分割工具的直接替代和增强。总的来说，我们的贡献提供了一种分割任何文本的通用方法。我们的方法优于所有基线 - 包括强大的 LLM - 在 8 个语料库中涵盖不同的领域和语言，特别是在文本格式不佳的实际相关情况下。 我们的模型和代码（包括文档）可在 此 https URL 下根据 MIT 许可获得。     提交人    /u/markus_583   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqfhn6/r_segment_any_text_a_universal_approach_for/</guid>
      <pubDate>Fri, 28 Jun 2024 09:22:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 还有其他人也陷入报纸的围攻，并且随时准备被抢先报道吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dqbgw4/d_is_anyone_else_absolutely_besieged_by_papers/</link>
      <description><![CDATA[我是一名一年级博士生，研究机器学习的一个热门领域（猜了 3 次，哈哈），过去的一年对我个人而言绝对是残酷的。每个工作日，我都会查看收件箱中的每日 arxiv 摘要，总有 3-5 篇与我的主题相关的新论文，尤其是最近每个人都在发布他们的 Neurips 投稿。 到目前为止，还没有一篇论文直接抢先发表我所研究的内容，但最近有太多差点被抢先发表的论文，这让我担心：(a) 这只是时间问题，我应该更快地完成预印本；或者 (b) 即使我在不​​久的将来发表了一篇论文，它也只是十几篇类似的论文之一，不会引起太大的关注。有些论文甚至有我导师的名字，因为她是一位著名的教授，非常乐于合作（我有时会想，因为她向很多人推销同样的想法，所以不可避免地会出现一些当地的抢先报道）。这些情况让我更加焦虑，因为我觉得速度在这里真的是最好的比较优势；从想法的产生到执行再到发表，都是速度的迭代。 我不知道，我觉得自己在本科时是如此的多产和成就，并且领先于时代，而现在已经一年了，我仍然在努力提出一个有意义和新颖的想法......有没有其他人和我一样？有没有人有什么有用的建议......如何应对快速出版周期的压力，或者如何在研究的早期挣扎，或者如何更快更好地思考？谢谢你听我（可能非常天真）的咆哮......    提交人    /u/akardashian   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dqbgw4/d_is_anyone_else_absolutely_besieged_by_papers/</guid>
      <pubDate>Fri, 28 Jun 2024 04:48:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>