<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 01 Feb 2024 21:11:51 GMT</lastBuildDate>
    <item>
      <title>[D] 围绕“AI”的普遍负面情绪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agj5y1/d_general_negative_sentiment_surrounding_ai/</link>
      <description><![CDATA[我注意到，每当我向普通人群（通常是非技术人员 -（家人、朋友等））提起人工智能主题时，第一个我想到的是“机器人接管世界并消灭人类”的存在的消极方面、危险和威胁，而不是积极的一面（如提高效率、自动化、科学等）。需要明确的是，我具体谈论的是人工智能的生存威胁，而不是像大型科技亿万富翁和法团主义这样的经济/政治问题。 这让我想知道 - “人工智能”是否已成为一个伴随着的术语对绝大多数人来说是一个可怕的负面含义吗？这是非常可悲的，我认为这些人中的许多人不知道他们在说什么，他们不明白这些模型是如何工作的，所以他们只是求助于人工智能存在主义者在媒体上推销的任何东西（不是为了淡化危险——我我知道有像 Ilya sutski 和 Geoffrey Hinton 这样的杰出研究科学家担心这些事情）但我觉得现在对人工智能的过度炒作和过度提及确实导致了普遍的技术悲观主义。 TLDR ：“人工智能”越来越多地给普通（非技术）公众带来存在主义的恐惧/负面含义？想法？   由   提交/u/Character-Capital-70   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agj5y1/d_general_negative_sentiment_surrounding_ai/</guid>
      <pubDate>Thu, 01 Feb 2024 19:22:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 开发人员在攻读法学硕士时面临的最大问题是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agj37d/d_what_are_the_biggest_issues_developers_face/</link>
      <description><![CDATA[我最近一直在研究 LLMops 工具，并思考是否存在大多数开发人员面临的常见未解决问题？   由   提交/u/Old_Log2517  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agj37d/d_what_are_the_biggest_issues_developers_face/</guid>
      <pubDate>Thu, 01 Feb 2024 19:19:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基础模型的未来会更加整合还是更加分散？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agielz/d_will_the_future_of_foundational_models_be_more/</link>
      <description><![CDATA[需要这个 subreddit 中的每个人都为最有可能的未来投票： 1) 综合：由于先发优势，从规模、资源和潜在拐点来看，由于首先冲击 AGI，基础模型市场将由一两个大型参与者（例如 OpenAI 和 Google）主导，任何其他参与者都没有机会赶上。例如：公用事业公司、社交媒体网络。 2）碎片化：由于这个世界上的数据/知识数量有限，培训和硬件成本不断减少，并且随着时间的推移，法学硕士能力的边际改进也逐渐减少，其他较小的参与者将缩小基础模型功能之间的差距，从而导致基础模型在某种程度上商品化。例如。云服务。 查看投票 &lt;!-- SC_ON - -&gt;  由   提交 /u/Try_StockAnalystGPT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agielz/d_will_the_future_of_foundational_models_be_more/</guid>
      <pubDate>Thu, 01 Feb 2024 18:51:21 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 需要 DATALODER 中 NSD 数据集的帮助</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aghwai/discussion_need_help_in_dataloder_with_nsd_dataset/</link>
      <description><![CDATA[了解什么是正确的 Data Loder 用于训练深度网络的数据集是一个巨大的问题 &lt; p&gt;当尝试通过 AWS 使用数据集时，我遇到了如何处理数据集的巨大问题。 1.使用什么数据加载模块？ 2.是否有任何预构建数据加载器可以按指定批次返回（RGB 刺激、FMRI 体素、图像标题）。？ 你能帮我解决这个问题吗？我已经挣扎了近 5 个月了。 你能帮我解决这个问题吗？ p&gt; 我项目的实际目标： 我想训练基于 Transformer 的自动编码器 - 解码器，用于从看到 coco 图像的大脑数据生成 RGB 特征。    由   提交 /u/hari-jilla   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aghwai/discussion_need_help_in_dataloder_with_nsd_dataset/</guid>
      <pubDate>Thu, 01 Feb 2024 18:30:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些有趣的本科/硕士 ML 论文想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agh056/d_what_are_some_interesting_undergraduatemasters/</link>
      <description><![CDATA[作为我的本科/硕士课程的一部分，我有一篇论文，我们希望在其中构建一些具有明确动机的东西，非常具有挑战性，但最重要的是，对您的项目所在领域可能做出的贡献。理想情况下，它可能是尝试结合几篇论文。论文大约有5-6个月长（但这不是我们唯一要做的事情，我们还有讲座等要参加）。对于计算，我有一个 3070，但可能可以获得 GPU 集群，但我怀疑他们是否会让我们训练大型变压器等。我已经阅读论文大约 1-2 年了，我的主要兴趣是 CV，特别是多模态空间/生成空间（例如 CLIP、扩散模型、GAN、ViT 等），有人有什么好的想法吗这要求我在这些领域发表广泛的论文。 （我也很想听到其他领域的想法！）。 我可能会对与 GNN 相关的事情持开放态度，但我有点怀疑，因为尽管我对它们有一些背景（完成了 CS224W + 阅读图形表示学习），我担心我必须做很多背景阅读，除非你认为这两个资源已经让我了解了。对于 RL 等其他领域也是如此。 [转发于r/deeplearning、r/learnmachinelearning 以获得更大的覆盖范围，希望没人介意]   由   提交/u/WideMind23  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agh056/d_what_are_some_interesting_undergraduatemasters/</guid>
      <pubDate>Thu, 01 Feb 2024 17:52:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻找一些通过 GPT 4 生成的数据集的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aggfth/p_looking_for_some_papers_for_datasets_generated/</link>
      <description><![CDATA[您好，有谁知道使用 GPT-4 或生成 Q/A 数据集或其他用于推理和推理的数据集的著名项目或论文吗？其他大型语言模型，而不是由人类创建或通过众包创建？   由   提交 /u/Conclusion_Silent   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aggfth/p_looking_for_some_papers_for_datasets_generated/</guid>
      <pubDate>Thu, 01 Feb 2024 17:28:48 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 基于皮层柱的计算研究现状？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agfn70/research_current_perspectives_on_research_in/</link>
      <description><![CDATA[2021 年，杰夫·霍金斯 (Jeff Hawkins) 发布了他的著作《一千个大脑：一种新的智能理论》，其中他强调了新皮质中的皮质柱，用于实现高级智力。它似乎遭到了分裂和短暂的接待。科普爱好者和一些​​认为该领域有点停滞的深度学习研究人员短暂地热衷于一种新颖的方法来为其增添趣味。与此同时，那些具有深厚神经科学背景的人对该理论的某些方面有一些疑虑，也许有些东西是可以挽救的。 基于炒作的性质，我本人对此有点怀疑，但是最近我看到了关于这个主题的随机不同研究。引起我注意的是卡耐基梅隆大学的神经拟态计算机架构实验室 (NCAL)。他们写了一份文档，其中详细介绍了一项研究计划，旨在设计一种新颖的架构，该架构结合了皮质柱和他们所说的东西时间神经网络。令我惊讶的是，有人实际上正在致力于实现与我认识的人的想法惊人相似的想法（即使它们没有实际意义），而不是仅仅围绕一个想法进行炒作。还有其他人听说过这个吗？人们对此有何看法？ 就背景而言，我是神经形态计算领域一个非常小的团队的成员。我拥有数学博士学位，并且是该领域的新手。我们正在寻找新的项目和研究方向，团队的一位高级成员对皮质柱的想法很感兴趣。他讨论的一些事情实际上与上面的非常相似，我很惊讶地看到人们独立地提出了这些想法。这看起来值得花时间吗？ 提前致谢   由   提交/u/Strawberry_Doughnut   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agfn70/research_current_perspectives_on_research_in/</guid>
      <pubDate>Thu, 01 Feb 2024 16:56:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能的真正价值在于最终用户用它做什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agewf2/d_is_the_true_value_of_ai_what_the_enduser_does/</link>
      <description><![CDATA[阅读本文后：https://www.taipy.io/posts/bringing-the-end-user-into-the-ai-picture 我已经考虑到为什么重点不是让人工智能对非技术最终用户来说更容易访问和用户友好。 制定真正复杂的算法是一回事，但当你实际上做不到时，它是否有意义用它来做出决策？ 如何改进这种人工智能协作？ 只是一些想法！  &amp;# 32；由   提交/u/quicklyalienated76   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agewf2/d_is_the_true_value_of_ai_what_the_enduser_does/</guid>
      <pubDate>Thu, 01 Feb 2024 16:25:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 传统的 ML/深度学习技术是否已在 NLP 和生产级系统中使用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agb5rg/d_are_traditional_ml_deep_learning_techniques/</link>
      <description><![CDATA[许多公司正在从他们在几年内开发的机器学习管道转向基于 ChatGPT 的/类似的解决方案。当然，对于文本生成用例来说，这是最有意义的。 但是，许多实际的 NLP 问题可以表述为分类/标记问题。 Pre-ChatGPT 系统过去涉及大量移动组件（关键字提取、超长正则表达式、在嵌入空间中查找最近向量等）。 那么，实际发生了什么？人们是否用 LLM API 替换特定组件？或者整个系统是否被一系列对 LLM API 的调用所取代？基于 BERT 的解决方案还在使用吗？ 现在 ChatGPT API 支持更长的时间和更长的时间。更长的上下文窗口（128k），除了定价和数据隐私问题之外，是否存在基于 BERT 的/其他解决方案能够发挥作用的用例；它不需要像 ChatGPT/LaMDA/类似的 LLM 等模型那样多的计算？ 如果它是上述 LLM 模型不知道的专有数据，那么您将使用自己的模型。但很多用例似乎都围绕着对人类语言本身的一般理解（例如投诉/票证分类/从产品评论中得出见解）。 任何博客、论文、案例研究或其他解决相同问题的文章将不胜感激。我也很想听听您的所有经历，以防您在现实系统中从事过/听说过上述迁移。 这个问题是专门提出的，请记住 NLP 的使用- 案例；但也可以随意将您的答案扩展到其他模式（例如表格和文本数据的组合）。   由   提交/u/101coder101  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agb5rg/d_are_traditional_ml_deep_learning_techniques/</guid>
      <pubDate>Thu, 01 Feb 2024 13:36:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 Codebase 上使用 RAG 创建代码完成助手最有效的方法。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ag972b/d_what_works_best_for_creating_code_completion/</link>
      <description><![CDATA[我正在尝试创建一个用于在私有代码库上完成代码的助手。 我发现很难从常规代码中获取正确的上下文嵌入。 是否有更好的方法可以从代码库中高效地嵌入、索引和检索代码？ [D]   由   提交 /u/Striking_Paper5259   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ag972b/d_what_works_best_for_creating_code_completion/</guid>
      <pubDate>Thu, 01 Feb 2024 11:50:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前适合本地法学硕士的最佳 RAG 设置是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ag6bo7/d_whats_the_best_current_rag_setup_that_would/</link>
      <description><![CDATA[我过去（6-8个月前）尝试过像langchain这样的东西，但它们很麻烦并且没有按预期工作。 我需要 RAG 从各种 pdf 中获取数据（很长，150 多页） - 我需要一个设置来允许我添加越来越多的数据源。 我想运行在本地，可以获得 24gb 显卡（或 2x16gb 显卡） - 这样我就可以使用 33b 或更小的型号运行。 我知道行业中的情况每两周就会发生变化，所以我希望有一个简单高效的 RAG 方法（与 6 个月前相比）   由   提交 /u/yupignome   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ag6bo7/d_whats_the_best_current_rag_setup_that_would/</guid>
      <pubDate>Thu, 01 Feb 2024 08:30:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mamba scalabe 是 Transformer 吗？或者只是另一种有效的模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ag3cgg/d_is_mamba_scalabe_as_transformer_or_just_another/</link>
      <description><![CDATA[*scalable Mamba 的作者声称“Mamba-3B 模型的性能优于相同尺寸的 Transformer，并且匹配两倍尺寸的 Transformer”。&lt; /p&gt; 像 Mamba-13B（只是一个假设）这样的模型与具有大量预训练数据的 Mixtral 8x7B 怎么样？有人尝试过这个吗？   由   提交 /u/Dry_Cheesecake_8311   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ag3cgg/d_is_mamba_scalabe_as_transformer_or_just_another/</guid>
      <pubDate>Thu, 01 Feb 2024 05:17:57 GMT</pubDate>
    </item>
    <item>
      <title>[N] Mistral 首席执行官确认新开源 AI 模型接近 GPT-4 性能的“泄露”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1afryc0/n_mistral_ceo_confirms_leak_of_new_open_source_ai/</link>
      <description><![CDATA[https://venturebeat.com/ai/mistral-ceo-confirms-leak-of-new-open-source-ai-model-nearing-gpt-4-性能/   由   提交/u/EmbarrassedHelp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1afryc0/n_mistral_ceo_confirms_leak_of_new_open_source_ai/</guid>
      <pubDate>Wed, 31 Jan 2024 20:35:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 裙带关系在大型科技机器学习角色中是否普遍存在？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1afm4lg/d_is_nepotism_prevalent_in_big_tech_ml_roles/</link>
      <description><![CDATA[我听一位朋友说，他在一家大型科技公司的著名机器学习团队实习。听说队里其他实习生大部分都是某所大学的（不是CS前10的），而且队里的总监也是教授。如果我的导师关系不好，申请这些实习还有意义吗？ 编辑1：我为裙带关系这个词的错误使用表示歉意，因为英语不是我的母语。我想，“在网络偏好中”是正确的词。  编辑 2：这种内部网络招聘似乎更加普遍，而且令人惊讶的是，这里的大多数评论者都可以接受。这怎么公平呢？那么好角色只属于有网络特权的人吗？    由   提交/u/mildlyphd  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1afm4lg/d_is_nepotism_prevalent_in_big_tech_ml_roles/</guid>
      <pubDate>Wed, 31 Jan 2024 16:41:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>