<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 12 Apr 2024 15:13:00 GMT</lastBuildDate>
    <item>
      <title>[D] 有人尝试过用 7B+ LLM 进行代币分类吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c2bdgh/d_has_anyone_tried_token_classification_with_a_7b/</link>
      <description><![CDATA[就像在具有很长上下文窗口的 2B 或 7B 模型上附加分类头并微调标记分类任务 Bert、T5 和类似的上下文窗口有限   由   提交 /u/EnnioEvo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c2bdgh/d_has_anyone_tried_token_classification_with_a_7b/</guid>
      <pubDate>Fri, 12 Apr 2024 15:01:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 检索增强语言建模（REALM）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c29r8h/d_retrievalaugmented_language_modeling_realm/</link>
      <description><![CDATA[我刚刚发现（我认为是）原始的 REALM 论文，“检索增强语言模型预训练”。非常有趣的想法，但是关于猎犬的角色，有一些关键细节我没有注意到。我希望这里有人能纠正我的观点：  首先也是最关键的是，检索增强仅与生成模型相关吗？你听说过很多关于RAG，但是就不能有像RAU这样的东西吗？就像为下游非生成任务 Y 编码某些文本 X 一样，编码器可以访问知识存储，从中识别、检索相关信息，然后将其包含在嵌入过程中以细化模型对原始文本的表示X？从概念上讲，这对我来说是有意义的，而且这似乎是 REALM 论文所做的（其中任务 Y 是 QA），但我在网上找不到此类事情的任何其他示例。检索增强似乎只适用于生成任务。那么是的，情况总是如此，还是 RAU 也存在？ 如果语言模型是使用检索增强进行训练的，那就意味着检索器是模型架构，对吗？换句话说，在推理时间中，必须始终进行一些检索，这进一步意味着从中检索文档的知识存储也必须始终存在，对吗？或者检索部分周围的所有机制都只是训练的产物，可以在学习完成后丢弃？ REALM 的主要好处是它允许的较小的模型？ 这个问题背后的基本原理：如果没有检索步骤，模型的 100% 的潜在知识必须包含在注意力机制的权重内（我认为）。对于预计几乎了解一切的基础模型，这需要大量的权重。然而，如果模型可以通过某些其他机制（例如检索增强）将上下文注入到表示中，则检索后模型的其余部分（例如注意机制）要做的工作更少，并且可以更小/更简单。我理解这里的大思想了吗？    由   提交 /u/synthphreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c29r8h/d_retrievalaugmented_language_modeling_realm/</guid>
      <pubDate>Fri, 12 Apr 2024 13:54:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自动数据段优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c26vfv/d_automatic_data_segment_optimisation/</link>
      <description><![CDATA[我在喝了几杯啤酒后想到了这一点，所以请允许我有一些不完整的地方。假设您在一家房地产投资基金工作，负责预测房价的问题。假设该企业每年只能投资 1000 万美元。您有一个包含全国 10 万栋房屋的数据集，其中包含许多特征以及各自的房价。现在，您可以针对整套 100k 房屋训练一些针对 RMSE 进行优化的奇特模型。太棒了，您现在有了一些很酷的 RMSE，可以描述您的表现有多“好”。你的模型是。但不要忘记，您的企业每年只能投资一定金额，所以如果您的模型在预测单层房屋的价格方面比预测两层房屋的价格要好得多，为什么要浪费计算资源和模型在两层房屋上学习能力？难道没有争论只在单层房屋上进行再训练吗？换句话说，虽然总 RMSE 不错，但如果单层房屋的 RMSE 远低于两层房屋（在同一组预测内），那么投资前者肯定会更好。应该有价值超过 1000 万美元的单层房屋可供投资。 现在，在这种情况下，您无法提前知道这个结果。另外，可能存在太大或太复杂而无法实际训练个体可疑“富有成果”的特征空间。数据子集。因此，在超参数搜索优化超参数的方式中，如果有一种方法可以优化用于训练的数据子集，那就太酷了。考虑到用于数据段优化的搜索空间是巨大的(甚至可能在降维之后)，因此“网格搜索”是可行的。可能不是正确的方法...有人知道一些优化用于训练的数据段的很酷的技术吗？感谢您阅读我的 Ted 演讲...   由   提交/u/HStuart18  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c26vfv/d_automatic_data_segment_optimisation/</guid>
      <pubDate>Fri, 12 Apr 2024 11:34:41 GMT</pubDate>
    </item>
    <item>
      <title>关于数据缺失点[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c26imw/about_data_missing_pointsd/</link>
      <description><![CDATA[我找到了股票价格数据，但该数据集不包含周末，并且日期之间存在差距，这是一个问题，我该如何解决这个问题。   由   提交 /u/YigitTheResearcher   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c26imw/about_data_missing_pointsd/</guid>
      <pubDate>Fri, 12 Apr 2024 11:14:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 Keras 上使用 VGGish slim 版本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c24xo9/d_using_vggish_slim_version_on_keras/</link>
      <description><![CDATA[我正在使用 VGGish 作为我正在为我的博士项目进行的声音事件检测项目的骨干。  我是深度学习框架的新手，从 Andrew Ng 的课程开始，我主要使用 Keras 和 Tensorflow。当我第一次开始涉足 VGGish 时，我对 官方 VGGish 存储库 而是使用我发现的这个 Keras 实现。  我刚刚意识到 Keras 实现存储库中的模型结构缺少原始模型的 256 个卷积层之一。  现在有人可以阅读我可以阅读的任何材料来帮助直接从官方 VGGish 存储库进行构建吗？我可以使用 slim 符号加载模型，然后将其桥接到 Keras 生态系统以添加我的层并微调我的数据吗？  谢谢。    由   提交 /u/RafaeldeCampos   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c24xo9/d_using_vggish_slim_version_on_keras/</guid>
      <pubDate>Fri, 12 Apr 2024 09:35:03 GMT</pubDate>
    </item>
    <item>
      <title>[D]利用自监督学习涉足手写文本识别问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c21frt/d_dabbling_in_handwritten_text_recognition/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c21frt/d_dabbling_in_handwritten_text_recognition/</guid>
      <pubDate>Fri, 12 Apr 2024 05:43:27 GMT</pubDate>
    </item>
    <item>
      <title>【研究】MMStar：我们评估大型视觉语言模型的方法正确吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c20v8x/research_mmstar_are_we_on_the_right_way_for/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2403.20330  评估代码：https://github.com/open-compass/VLMEvalKit  摘要： 大型视觉语言模型（LVLM）最近取得了快速进展，引发了大量研究来评估其多模态能力。然而，我们深入研究当前的评估工作并发现两个主要问题：1）视觉内容对于许多样本来说是不必要的。答案可以直接从问题和选项中推断出来，或者从法学硕士中嵌入的世界知识中推断出来。这种现象在当前的基准测试中普遍存在。例如，GeminiPro 在没有任何视觉输入的 MMMU 基准测试中达到了 42.9%，并且在六个基准测试中平均优于随机选择基准 24% 以上。 2）LLM和LVLM训练中存在无意的数据泄露。 LLM和LVLM仍然可以在没有视觉内容的情况下回答一些视觉必需的问题，表明在大规模训练数据中记忆了这些样本。例如，Sphinx-X-MoE 在不访问图像的情况下在 MMMU 上获得了 43.6%，超过了其 LLM 骨干网的 17.9%。这两个问题都会导致对实际多模态增益的误判，并可能误导 LVLM 的研究。为此，我们推出了 MMStar，这是一个精英视觉不可或缺的多模态基准，由人类精心挑选的 1,500 个样本组成。 MMStar 对 6 个核心功能和 18 个详细轴进行了基准测试，旨在通过仔细平衡和纯化的样本来评估 LVLM 的多模式能力。这些样本首先通过自动化管道从当前基准中粗略选择，然后进行人工审查，以确保每个精选样本表现出视觉依赖性、最小的数据泄漏，并需要先进的多模式功能。此外，还开发了两个指标来衡量多模式训练中的数据泄漏和实际性能增益。我们在 MMStar 上评估了 16 个领先的 LVLM，以评估其多模态能力，并在 7 个基准测试中使用建议的指标来调查其数据泄漏和实际多模态增益。    由   提交/u/KennyMcKormick_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c20v8x/research_mmstar_are_we_on_the_right_way_for/</guid>
      <pubDate>Fri, 12 Apr 2024 05:08:28 GMT</pubDate>
    </item>
    <item>
      <title>[研究] Ada-LEval：使用长度自适应基准评估长上下文法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c20to0/research_adaleval_evaluating_longcontext_llms/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2404.06480  代码/数据集：https://github.com/open-compass/Ada -LEval 摘要： 最近，大型语言模型 (LLM) 社区对增强 LLM 处理超长文档的能力表现出越来越大的兴趣。随着各种长文本技术和模型架构的出现，对模型长文本能力的精确而详细的评估变得越来越重要。现有的长文本评估基准，例如L-Eval和LongBench，都是基于开源数据集构建长文本测试集，主要关注QA和摘要任务。这些数据集包括纠缠在一起的不同长度（从 2k 到 32k+）的测试样本，这使得评估不同长度范围内的模型能力变得具有挑战性。此外，它们不涵盖最新法学硕士声称要实现的超长设置（100k+ 代币）。在本文中，我们介绍了 Ada-LEval，这是一种长度自适应基准，用于评估法学硕士的长上下文理解。 Ada-LEval 包括两个具有挑战性的子集：TSort 和 BestAnswer，它们可以更可靠地评估法学硕士的长上下文能力。这些基准测试支持对测试用例长度的复杂操作，并且可以轻松生成多达 128k 个标记的文本样本。我们使用 Ada-LEval 评估了 4 个最先进的闭源 API 模型和 6 个开源模型。评估结果证明了当前法学硕士的局限性，尤其是在超长上下文环境中。   由   提交/u/KennyMcKormick_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c20to0/research_adaleval_evaluating_longcontext_llms/</guid>
      <pubDate>Fri, 12 Apr 2024 05:05:45 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] NeurIPS 2024 为高中生新增论文轨道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1zesl/news_neurips_2024_adds_a_new_paper_track_for_high/</link>
      <description><![CDATA[NeurIPS 2024 为高中生添加了新的论文轨道 https://neurips.cc/Conferences/2024/CallforHighSchoolProjects  第三十八届神经信息处理系统年会 (NeurIPS 2024)一个跨学科会议，汇集了机器学习、神经科学、统计学、优化、计算机视觉、自然语言处理、生命科学、自然科学、社会科学和其他相邻领域的研究人员。  今年，我们邀请高中生提交有关机器学习社会影响主题的研究论文。将选出一部分决赛入围者以虚拟方式展示他们的项目，并将在 NeurIPS 主页上重点展示他们的作品。此外，最多五个获奖项目的主要作者将受邀参加在温哥华举行的 NeurIPS 2024 颁奖典礼。  每份提交的作品必须描述完全由高中生作者完成的独立作品。我们希望每份提交的内容都能突出显示已证明的积极社会影响或使用机器学习产生积极社会影响的潜力。    由   提交 /u/xiaohk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1zesl/news_neurips_2024_adds_a_new_paper_track_for_high/</guid>
      <pubDate>Fri, 12 Apr 2024 03:47:38 GMT</pubDate>
    </item>
    <item>
      <title>[项目] CLIP 实现高效知识蒸馏，不使用教师模型，仅使用教师嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1yjxd/project_clip_for_efficient_knowledge_distillation/</link>
      <description><![CDATA[从教师模型获得的预先计算的嵌入可以用来训练学生模型的知识蒸馏吗？ 这个项目扩展了CLIP 通过利用嵌入作为教师来实现高效的知识蒸馏。典型的知识蒸馏框架需要通过教师模型进行前向传递，这在十亿或万亿参数教师的情况下通常是令人望而却步的。仅使用教师模型的嵌入来指导蒸馏可以显着节省计算量。 GitHub：https:/ /github.com/lnairGT/CLIP-Distillation   由   提交 /u/IllustriousSir_007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1yjxd/project_clip_for_efficient_knowledge_distillation/</guid>
      <pubDate>Fri, 12 Apr 2024 03:03:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 变形金刚的注意力机制类似于神经科学中联想记忆模型的现代迭代。我展示了自联想和异联想混合物可以执行一系列任务+建议新的神经启发 Transformer 插值方法。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1pf30/r_the_attention_mechanism_of_transformers/</link>
      <description><![CDATA[   从机制上讲，注意力似乎执行异质关联。实际上，原则上它可以混合自动和自动混合。异性关联在一起。 问题：这允许什么能力？回答：很多！  有限自动机 通过为图像或文本数据分配神经活动，并将其组合转换为自关联吸引子（状态）或异关联准吸引子（转移），我们可以模拟有限自动机。 （参见下面链接的论文的第 3.4 节和附录 A12）  将有限自动机映射到“内存图”的示例。  多尺度图形表示 通过调整自关联（a）和异关联（h）的强度，我们可以选择我们希望识别的图形关系的比例或粗糙度。 （请参阅下面链接的论文的第 3.2 节和附录 A2）  使用关联内存进行检测时，不同活动规模分布在其顶点（内存模式）的 Tutte 图网络。  稳定视频的回忆 自然视频的帧之间通常具有很大的时间依赖性。实现自关联和异关联之间的适当平衡有助于防止视频“卡在”帧上或向前跳动。 （请参阅下面链接的论文的第 3.3 节和附录 A11） 视频帧（内存模式）随时间的相关性，显示 a 和 h 的值如何影响召回的平滑度。  内存保真度和内存保真度之间的优雅权衡。能力，通过异质关联相似的记忆和记忆对。 “检索”那些具有最高重叠度的内容。 （参见附录 A3） 神经科学数据的复制显示猴子颞叶皮层中的异质关联。 （参见附录A7） 左：内存负载方面的非传统自动关联性能。右图：a 和 h 的设置与猴子颞叶皮层的数据非常匹配。  这让我建议对变形金刚进行受神经科学启发的可解释性分析，并提出为什么叠加应该与“上下文切换”和“上下文切换”相关的假设。暗示“数据相关的几何形状”。 了解更多信息 -- 论文： https://arxiv.org/abs/2404.07123 GitHub：&lt; /strong&gt; https://github.com/tfburns/CDAM   由   提交/u/tfburns  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1pf30/r_the_attention_mechanism_of_transformers/</guid>
      <pubDate>Thu, 11 Apr 2024 20:30:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] ReFT：语言模型的表示微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1nvwi/r_reft_representation_finetuning_for_language/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.03592 代码：https://github .com/stanfordnlp/pyreft 摘要：  参数高效微调（PEFT）方法寻求适应大的通过更新少量权重来调整模型。然而，许多先前的可解释性工作表明，表示编码了丰富的语义信息，这表明编辑表示可能是一种更强大的替代方案。在这里，我们通过开发一系列表示微调 (ReFT) 方法来追求这一假设。 ReFT 方法在冻结的基础模型上运行，并学习对隐藏表示的特定任务干预。我们定义了 ReFT 系列的一个强大实例，低秩线性子空间 ReFT (LoReFT)。 LoReFT 是现有 PEFT 的直接替代品，其学习干预措施的参数效率比之前最先进的 PEFT 高 10 至 50 倍。我们展示了 LoReFT 在八个常识推理任务、四个算术推理任务、Alpaca-Eval v1.0 和 GLUE 上的表现。在所有这些评估中，LoReFT 提供了效率和性能的最佳平衡，并且几乎总是优于最先进的 PEFT。我们在 此 https URL 公开发布通用 ReFT 训练库。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1nvwi/r_reft_representation_finetuning_for_language/</guid>
      <pubDate>Thu, 11 Apr 2024 19:30:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无限上下文变形金刚</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1l16l/r_infinite_context_transformers/</link>
      <description><![CDATA[我看了一下，没有在本文中看到任何看起来很有希望的讨论主题。  https://arxiv.org/abs/2404.07143  你的想法？这可能是 Gemini 1.5 报告的 10m 令牌上下文长度背后的技术之一吗？    由   提交 /u/Dyoakom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1l16l/r_infinite_context_transformers/</guid>
      <pubDate>Thu, 11 Apr 2024 17:35:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在论文《More Agents Is All You Need》中，为什么他们使用 BLEU 分数来计算集成投票的相似度而不是余弦相似度之类的东西？有后续研究比较方法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1e0x4/d_in_the_paper_more_agents_is_all_you_need_why/</link>
      <description><![CDATA[论文：https://arxiv.org/pdf /2402.05120.pdf 在论文中，他们有法学硕士集体回答问题。对于离散答案，例如多项选择题，他们只选择最常见的答案。对于“连续”来说，对于像代码这样的答案，他们使用 BLEU 分数来查找与其他答案最相似的答案。 有人知道为什么选择这个答案而不是余弦相似度之类的答案吗？看起来他们没有解释这个选择，但他们的结果很好，所以我猜它有效！   由   提交/u/30299578815310  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1e0x4/d_in_the_paper_more_agents_is_all_you_need_why/</guid>
      <pubDate>Thu, 11 Apr 2024 12:39:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>