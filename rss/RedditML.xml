<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sat, 06 Jul 2024 09:16:30 GMT</lastBuildDate>
    <item>
      <title>[R] 扩散强制：下一个标记预测与全序列扩散相遇</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwkces/r_diffusion_forcing_nexttoken_prediction_meets/</link>
      <description><![CDATA[        由    /u/Rose52152   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwkces/r_diffusion_forcing_nexttoken_prediction_meets/</guid>
      <pubDate>Sat, 06 Jul 2024 07:43:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语言模型 - 为什么会发生重复？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwjyjt/d_language_models_why_do_repetitions_happen/</link>
      <description><![CDATA[这对我来说有点违反直觉。LM 尝试根据先前的标记对下一个标记的概率分布进行建模。如果我们在高质量数据（例如不包含大量重复的 fineweb-edu）上对其进行训练，则生成应该反映训练数据 - 没有重复的文本。LM 可以看到上下文中已经存在的内容，那么为什么它会为导致重复的标记分配高概率？这仅仅是因为我们从模型中采样的方式，例如 top-1？或者可能是因为 LM 没有提前计划的能力？两者都有？    提交人    /u/kiockete   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwjyjt/d_language_models_why_do_repetitions_happen/</guid>
      <pubDate>Sat, 06 Jul 2024 07:16:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] DoRA LLM 微调详解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwijir/r_dora_llm_finetuning_explained/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwijir/r_dora_llm_finetuning_explained/</guid>
      <pubDate>Sat, 06 Jul 2024 05:44:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 所有在机器学习领域工作了数月或数年的人——多年来，您职业生涯中最大的时刻是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwhx5f/d_all_the_folks_working_on_machine_learning_for/</link>
      <description><![CDATA[每天都有很多新的实验以难以跟上的速度进行。 例如，对于 2015 年的我来说，最大的基本见解是，十年内 90% 以上的数据将是非结构化的，而现在正在发生这种情况。这促使我进入电子商务、零售、医疗保健、农业和汽车等各个领域探索机器学习等模型。    提交人    /u/Worth-Card9034   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwhx5f/d_all_the_folks_working_on_machine_learning_for/</guid>
      <pubDate>Sat, 06 Jul 2024 05:05:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LLM 进行实体提取</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwbcp5/d_entity_extraction_with_llms/</link>
      <description><![CDATA[我们很多人都在使用 LLM 从非结构化文本中提取实体。使用 LLM 进行实体提取的最大挑战是：  重复实体：例如，如果您从用户支持单中提取产品，LLM 可能会提取“产品：衬衫”。“产品：T 恤”、“产品：短袖”或“产品：衬衫”，具体取决于输入文本如何引用 衬衫。这意味着您可能需要严格迭代和监控 LLM 的行为（例如，确保 LLM 引用现有实体标签）。 添加新实体：当现有实体标签不匹配时，LLM 通常擅长在必要时提出新的实体标签。但是，如果不断引入新的实体标签（粒度不一致），这可能会变得难以管理。不幸的是，LLM 必须索引的实体标签列表越大，LLM 的准确性就越低。  因此，这里有一些提示可帮助您掌握提取：  设置警报：掌握输出非常重要。如果您每天处理大量文本，则为任何新的 DISTINCT 标签设置 SQL 警报是一个很好的第一步。 提供上下文：LLM 在上下文中表现更好。为任务和实体标签添加上下文。 后处理：创建后处理步骤来处理重叠实体并优化结果。 用少量样本处理歧义：识别一些模棱两可或棘手的示例，并将它们添加到提示中。 没有答案比错误答案更好：给 LLM 一个出路。如果没有好的实体，您将要大力鼓励 LLM 不要编造某些东西（他们仍然经常这样做）。 整合业务反馈：这取决于用例。实体提取通常可以用于提高操作效率或面向用户的功能。如果是这种情况，重要的是确认并与这些用户就“衬衫”是什么达成一致。工程师和利益相关者的观点通常不同。  如果仍然没有获得所需的准确度，可以尝试微调。经典的 ML 和 NER 库相当不可靠，但如果您迫切需要，值得尝试。 您还可以尝试一些为您处理此问题的外部服务。例如，我们使用类似 BERT 的模型提取原始实体 + 管理并将它们解析为具有非常高准确度的规范实体选项。当出现新实体（与现有实体不匹配）时，如果它们在我们的模型中达到足够高的置信度，我们会将它们添加到实体列表中。 请在下面评论您在实体提取方面的经验和技巧！    提交人    /u/Different-General700   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwbcp5/d_entity_extraction_with_llms/</guid>
      <pubDate>Fri, 05 Jul 2024 23:14:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习工程师如何寻找客户</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwaed5/d_how_to_find_clients_as_a_machine_learning/</link>
      <description><![CDATA[我有一个关于自由职业者的快速问题。你如何联系客户？ 我所做的所有工作，都必须亲自与企业所有者交谈，并且几乎总是分享免费的演示，供他们在有限时间内使用，然后他们才同意以收入分成作为付款方式。 我喜欢这种模式，因为我工作越多，得到的报酬就越多。    提交人    /u/Regular-Connection46   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwaed5/d_how_to_find_clients_as_a_machine_learning/</guid>
      <pubDate>Fri, 05 Jul 2024 22:31:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 语言模型中上下文长度的指数增长</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw6e1r/d_p_exponential_growth_of_context_length_in/</link>
      <description><![CDATA[      https://preview.redd.it/0v289d9r2rad1.png?width=5376&amp;format=png&amp;auto=webp&amp;s=014fc378d270ac8f8a7090eab1880fb381fe67f4 LLM 上下文长度大小似乎在过去几年中呈指数级增长 - 从 T5/BERT/GPT-1 的 512 个标记到最新的 Gemini 1.5 Pro 的 200 万个标记。 目前尚不清楚上下文窗口是否会继续以这种速度增长，或者是否会在某个时候达到稳定状态。有多少上下文窗口变得没有必要？ （如果我们估计 100 个标记大约为 75 个单词，那么所有 7 本《哈利波特》书籍都可以容纳 150 万个标记。）  数据收集说明： 必须追踪每个单独模型的发布博客（如果有的话）并与它们的 API 文档（如果存在）进行交叉引用。或者一篇论文（如果有的话）。这个领域变化如此之快，而且一家公司发布具有 X 上下文窗口的模型，然后在 1 个月后更新 API 文档并说“但是等一下！上下文长度现在是 Y”的情况并不少见。） 分享下面的原始数据，因为我花了很多时间煞费苦心地收集这些数据。此外，如果我错过了什么，请随时进行抽查。 https://docs.google.com/spreadsheets/d/1xaU5Aj16mejjNvReQof0quwBJEXPOtN8nLsdBZZmepU/edit?gid=0#gid=0    提交人    /u/porkbellyqueen111   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw6e1r/d_p_exponential_growth_of_context_length_in/</guid>
      <pubDate>Fri, 05 Jul 2024 19:34:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 受限解码作为状态导航？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw2pqo/d_constrained_decoding_as_stateful_navigation/</link>
      <description><![CDATA[在实现 LLM 驱动的代理时，存在一系列方法，具体取决于“包装”程序尝试构造、控制或处理 LLM 的输入和输出的程度。一种方法涉及包装程序解析 LLM 的输出，并且为了使此过程更可靠，LLM 的解码器被限制为特定语法（例如 XML 或 JSON）或甚至特定的 XML 或 JSON 模式。 将解码器限制为您当前需要的语法通常是通过将违反语法的潜在输出值的概率归零来实现的。但是，如果 LLM 没有接受过针对您尝试执行的语法的任何特定培训，则此策略可能不是最佳的。 让我们以一个非常简单的语法为例。此语法中的有效字符串以双引号字符开头和结尾。字符串内部有两个字符必须“转义”：反斜杠和双引号。转义序列以反斜杠开头。 合法：“John 说，\&quot;This is a legal string.\&quot;。&quot; 合法：“John 说，&quot; 非法：“John 说，&quot;This string makes me sad.&quot;&quot; 如果我们将解码器视为“试图”用其输出表示某些编码向量，则它只有在“提前计划”一点点的情况下才能在此语法中这样做。它可能“想要”发出一个双引号字符，并且无论之前的内容是什么，语法都允许这样做。但是，如果该双引号字符前面没有反斜杠，则字符串必须在双引号之后立即结束，以使字符串合法。如果它“想要”发出双引号但不结束，它需要“知道”它不想在不久的将来结束并且为了不结束，它需要先发出反斜杠。 那么如何获得这种有计划的解码 - 理想情况下，同时能够使用尽可能接近现成的预训练 LLM？我不确定，但我有一个模糊的想法，我想知道社区会对此有何看法。 假设我们可以访问预训练的 LLM，包括中间层的激活。我们还有我们想要限制输出的语法，以图形的形式，其边缘标有潜在输出*。最后，我们有一个独热向量，指示解码过程当前位于语法图中的哪个节点（或者，对于语法的非确定性表示，是一个 k-hot 向量）。 来自预训练 LLM 的激活可用于为语法图的边缘分配“朴素可取性”。但是，出现了两个考虑因素：  要遍历的最理想边可能与当前状态无关。要到达那些边，我们可能需要遍历其他边（这可能需要我们发出其他输出标记）。在语义层面上，这“可以”吗？例如，某些恶意语法可能要求任何单词​​“dogs”的实例前面都有单词“absolutely no”。如果我到目前为止已经解码了“I love”，并且到达了“dogs”是可取的，我不想越过需要“绝对不”的语法边缘，否则我最终会说“我绝对不爱狗”。  在我们最终确定要发出的标记并将我们移动到语法图中的新节点之后，这是一个可以考虑我们可能还剩下什么需要解码的地方吗？  这些考虑让我认为通过语法表达 LLM 的编码含义就像玩 Metroidvania 式的游戏，其中不同的路径具有不同的成本和回报。不幸的是，我几乎没有灵活的游戏模型背景，所以我不确定从这一点开始要学习什么等（假设这首先是一条值得的攻击路线......）    提交人    /u/jpfed   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw2pqo/d_constrained_decoding_as_stateful_navigation/</guid>
      <pubDate>Fri, 05 Jul 2024 16:57:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 发布我基于 VGG 感知损失的损失函数。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw2dfb/p_releasing_my_loss_function_based_on_vgg/</link>
      <description><![CDATA[您好，这是我已经做了一段时间的项目。我使用“VGG Loss”在我的某些项目中，我一直觉得从一个模型中提取信息来训练另一个模型很有趣。 以此为灵感，我创建了这个项目，它允许您使用几乎任何来自 PyTorch 的预训练模型作为训练新模型的基础。 在代码中，您可以找到一个使用 DINOv2 作为损失函数（扮演 VGG 的角色）的示例，但该函数旨在接受除 Dino 之外的任何其他模型，甚至不接受图像作为输入的模型，例如 LLM 或任何其他模型。 这是一个专门为我在我的项目中使用和共享而开发的项目，所以我没有附加任何文章，它的大部分逻辑都是在我的项目中使用时通过反复试验开发出来的。 在 GitHub 描述中，有更多关于它的信息。我希望这个项目对某些人有用。 https://github.com/BurguerJohn/global_perceptual_similarity_loss     提交人    /u/CloverDuck   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw2dfb/p_releasing_my_loss_function_based_on_vgg/</guid>
      <pubDate>Fri, 05 Jul 2024 16:43:14 GMT</pubDate>
    </item>
    <item>
      <title>[D],[R]这是真的吗，在 O(log n) 中顺序处理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dw0to6/dris_this_true_sequential_processing_in_olog_n/</link>
      <description><![CDATA[有一篇学生的中等文章声称他的架构可以完成循环处理器（RNN）和变压器的工作，还讨论了如何将其用于图像生成。他的代码看起来有效且正确。 他声称构建了一个表现优于 distil-gpt 的 LLM，即使参数数量只有传统 LLM 的一半，而且训练方式也不尽相同。 我有个问题：这有什么新鲜的吗？ 阅读时间为 5 分钟。 文章链接：https://medium.com/@DakshishSingh/equinox-architecture-divide-and-compute-99c555ac08d6    提交人    /u/Conscious-Gazelle-91   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dw0to6/dris_this_true_sequential_processing_in_olog_n/</guid>
      <pubDate>Fri, 05 Jul 2024 15:35:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mapper（Mapper算法）区分噪声和显著拓扑结构的能力的理论极限是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvzsy8/d_what_are_the_theoretical_limits_of_mappers/</link>
      <description><![CDATA[大家觉得怎么样？    提交人    /u/ICEpenguin7878   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvzsy8/d_what_are_the_theoretical_limits_of_mappers/</guid>
      <pubDate>Fri, 05 Jul 2024 14:50:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 推荐一些关于模型合并的好资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvzr9d/d_suggest_any_good_resources_for_model_merging/</link>
      <description><![CDATA[我知道有合并模型的工具，但我想要一些关于合并模型的理论材料。任何讨论如何合并模型的博客、文章或研究论文都会有所帮助。 我将不胜感激您的帮助 :) 谢谢    提交人    /u/Ok_Cartographer5609   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvzr9d/d_suggest_any_good_resources_for_model_merging/</guid>
      <pubDate>Fri, 05 Jul 2024 14:48:53 GMT</pubDate>
    </item>
    <item>
      <title>[P] TensorFlow 概率的 torch 等价性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvwfov/p_torch_equivalence_of_tensorflow_probability/</link>
      <description><![CDATA[大家好， 我已经使用 tensorflow 很多年了，但对 pytorch 的经验有限。我正在考虑在 pytorch 上构建我的下一个项目。有没有人有在 pytorch 中进行近似推理的经验，有没有 tensorflow 概率的等效包？ 谢谢！    提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvwfov/p_torch_equivalence_of_tensorflow_probability/</guid>
      <pubDate>Fri, 05 Jul 2024 12:08:19 GMT</pubDate>
    </item>
    <item>
      <title>ECCV 相机就绪论文 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dvvzpm/camera_ready_paper_for_eccv_discussion/</link>
      <description><![CDATA[嗨， 我的论文被 ECCV 接受了，在反驳期间，我们从审稿人那里得到了很多有用的反馈。我们想把它们包括在主论文中，但超出了 14 页的限制。为了解决这个问题，我们想将一个消融研究图表和讨论从主论文移到补充材料中。当然，我们会在主图中引用它，但允许吗？    提交人    /u/dn8034   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dvvzpm/camera_ready_paper_for_eccv_discussion/</guid>
      <pubDate>Fri, 05 Jul 2024 11:43:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ds3fbp/d_simple_questions_thread/</guid>
      <pubDate>Sun, 30 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>