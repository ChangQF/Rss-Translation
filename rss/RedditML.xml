<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 24 Jan 2025 01:13:59 GMT</lastBuildDate>
    <item>
      <title>[D] 关于使用 transformer 进行图像恢复任务的好论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8bvx1/d_good_papers_on_image_restoration_tasks_using/</link>
      <description><![CDATA[有人能指出一些使用基于 Transformer 的主干进行图像恢复任务的好论文吗？我发现大多数论文要么没有很好地解释他们的设计选择，要么评估不力。特别是，我想看看其中是否有任何一个通过使用 CNN 上的 Transformer 获得显着的性能提升。 任何指示都非常感谢！    提交人    /u/ats678   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8bvx1/d_good_papers_on_image_restoration_tasks_using/</guid>
      <pubDate>Thu, 23 Jan 2025 19:36:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用推理时间计算换取对抗鲁棒性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i8anvi/r_trading_inferencetime_compute_for_adversarial/</link>
      <description><![CDATA[用推理时间计算换取对抗性鲁棒性  我们对增加推理模型（特别是 OpenAI o1-preview 和 o1-mini）中的推理时间计算对其对抗性攻击鲁棒性的影响进行了实验。我们发现，在各种攻击中，增加推理时间计算可以提高鲁棒性。在许多情况下（除了重要的例外），随着测试时间计算量的增加，攻击成功的模型样本比例趋于零。我们不对我们研究的任务进行对抗性训练，我们只是允许模型在推理上花费更多的计算来增加推理时间计算，与攻击形式无关。我们的结果表明，推理时间计算有可能提高大型语言模型的对抗鲁棒性。我们还探索了针对推理模型的新攻击，以及推理时间计算不会提高可靠性的设置，并推测了这些攻击的原因以及解决方法。  TL;DR o1 样式模型对对抗攻击和提示注入的抵抗力更强，并且它们的思考时间越长，抵抗力就越强。    提交人    /u/currentscurrents   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i8anvi/r_trading_inferencetime_compute_for_adversarial/</guid>
      <pubDate>Thu, 23 Jan 2025 18:45:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] ANN 搜索索引中向量 ID 和链接的高效无损压缩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i89hn0/r_efficient_lossless_compression_of_vector_ids/</link>
      <description><![CDATA[本文介绍了一种用于近似最近邻搜索系统中向量 ID 的新型无序压缩技术。 ID 不再作为序列处理，而是作为无序集处理，从而实现更高效的压缩模式，而不会影响搜索性能。 关键技术点： - 两阶段压缩管道：首先对相似的 ID 进行聚类，然后对每个聚类应用专门的压缩 - 与顺序无关的方法：消除了传统压缩中常见的顺序依赖关系 - 保持快速查找：使用索引系统，在减少存储的同时保留快速访问 - 与现有系统兼容：与当前的向量数据库实现一起工作 结果： - 向量 ID 的压缩率达到了 70% - 保持原有的搜索准确度水平 - 压缩速度与基线方法相当或更快 - 在标准 ANN 基准（SIFT1M、DEEP1B 数据集）上进行测试 - 压缩期间的内存开销保持在实际限制之内 我认为这种方法可以让存储资源有限的组织更容易进行大规模向量搜索。该方法对于图像搜索或推荐系统等矢量数据库正在成为标准的应用尤其有价值。 我认为主要的限制是数据集越小，好处就越少，这可能会使其对较小的应用程序吸引力降低。实施的复杂性也可能给没有专业知识的团队带来挑战。 TLDR：一种用于矢量 ID 的新压缩方法，可在不影响搜索性能的情况下减少 70% 的空间，使用与顺序无关的方法在压缩之前对相似的 ID 进行聚类。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i89hn0/r_efficient_lossless_compression_of_vector_ids/</guid>
      <pubDate>Thu, 23 Jan 2025 17:59:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] CVPR 评审系统</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i88j22/d_cvpr_review_system/</link>
      <description><![CDATA[有人知道评审系统具体是如何运作的吗？你需要平均分数至少为 4 分，还是所有评审者都需要给出 5 分？    提交人    /u/maestroDMX   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i88j22/d_cvpr_review_system/</guid>
      <pubDate>Thu, 23 Jan 2025 17:19:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于能量的文本生成扩散语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i87lgy/r_energybased_diffusion_language_models_for_text/</link>
      <description><![CDATA[https://arxiv.org/pdf/2410.21357 本文作者将扩散模型与基于能量的建模相结合，以解决离散生成建模中的挑战。    提交人    /u/Whatever_635   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i87lgy/r_energybased_diffusion_language_models_for_text/</guid>
      <pubDate>Thu, 23 Jan 2025 16:41:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有可能在不重新训练的情况下增加序列长度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i86s90/d_is_it_possible_to_increase_the_sequence_length/</link>
      <description><![CDATA[大家好， 我想知道是否有关于在不完全重新训练的情况下增加模型最大序列长度的研究。如果已经存在，您能分享一些论文或想法吗？    提交人    /u/BigAbbreviations9098   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i86s90/d_is_it_possible_to_increase_the_sequence_length/</guid>
      <pubDate>Thu, 23 Jan 2025 16:06:54 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 需要 nnViewer Beta 测试人员：帮助我们改进神经网络可视化！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i80gfn/project_nnviewer_beta_testers_needed_help_us/</link>
      <description><![CDATA[您好 r/MachineLearning ！ 我们很高兴推出 nnViewer，这是一个旨在简化 torch.nn.Module 模型可视化的 Python 库。无论您是在调试还是探索复杂神经网络的架构，nnViewer 的交互式 GUI 都能为您提供帮助！ 亮点：  快速入门：轻松可视化 Hugging Face 模型。 交互式图形探索：详细探索和分析您的神经网络。  我们为什么需要您 我们正在寻找beta 测试人员来帮助我们改进 nnViewer。该库功能齐全，可通过 pip 获得。 开始使用 查看我们的 GitHub 存储库 nnViewer 了解更多信息和演示。    提交人    /u/pibraa   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i80gfn/project_nnviewer_beta_testers_needed_help_us/</guid>
      <pubDate>Thu, 23 Jan 2025 10:30:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 Open AI、Firecrawl 和 Athina AI 构建和测试 AI 管道 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i7v6q9/building_and_testing_an_ai_pipeline_using_open_ai/</link>
      <description><![CDATA[      在构建生产级 LLM 应用程序时，在特定于您的用例/域的数据集上测试您的 AI 管道至关重要。 这需要在提示、模型、检索和其他高级技术的多种组合中进行大量迭代。 以下是一家大型医疗保健公司如何为医疗从业者构建其 AI 驱动的副驾驶的分步细分。 它涵盖了如何设置多步骤 AI 管道并使用自定义评估对其进行评估。 在评论中链接到整个管道和博客👇 https://preview.redd.it/9dwt18xe6oee1.png?width=2940&amp;format=png&amp;auto=webp&amp;s=c7bac5a079e09a6604ce07205df3424ccce58f23    提交人    /u/0xhbam   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i7v6q9/building_and_testing_an_ai_pipeline_using_open_ai/</guid>
      <pubDate>Thu, 23 Jan 2025 04:18:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 评论 CVPR 评论和 ICLR 决定。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i7nvix/d_comment_on_cvpr_reviews_and_iclr_decisions/</link>
      <description><![CDATA[大家好， 我们都知道评审和决定可能会引起争议，我相信你们中的许多人都对结果感到失望（我在 CVPR 上的评分都是 2 😅）。但请记住，这不是世界末日！ 被拒绝并不意味着你有错——这通常只是运气不好（当然，我们应该始终努力改进我们的工作）。 休息一下——吃点鸡肉和啤酒，睡个好觉，准备好将你的作品提交给另一个场地。你做到了！💪    提交人    /u/Shot-Button-9010   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i7nvix/d_comment_on_cvpr_reviews_and_iclr_decisions/</guid>
      <pubDate>Wed, 22 Jan 2025 22:26:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025 决议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i7i1d4/d_iclr_2025_decisions/</link>
      <description><![CDATA[决定似乎已经出现。你有什么想法？    由    /u/ApamNapat 提交   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i7i1d4/d_iclr_2025_decisions/</guid>
      <pubDate>Wed, 22 Jan 2025 18:27:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 学会利用贝叶斯原理持续学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i7g04y/r_learning_to_continually_learn_with_the_bayesian/</link>
      <description><![CDATA[       由    /u/moschles  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i7g04y/r_learning_to_continually_learn_with_the_bayesian/</guid>
      <pubDate>Wed, 22 Jan 2025 17:05:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] CVPR 2025 评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i7dqlh/d_cvpr_2025_reviews/</link>
      <description><![CDATA[评论应在 24 小时内发布（2025 年 1 月 23 日 01:59 AM CST）。 祝大家好运。    提交人    /u/Some-Landscape-4763   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i7dqlh/d_cvpr_2025_reviews/</guid>
      <pubDate>Wed, 22 Jan 2025 15:31:56 GMT</pubDate>
    </item>
    <item>
      <title>[D]：3blue1brown 视频详细解释了注意力机制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i6zh6p/d_a_3blue1brown_video_that_explains_attention/</link>
      <description><![CDATA[ YouTube 视频 字幕  时间戳 02:21：标记嵌入 02:33：在嵌入空间中 \ 一个单词有多个不同的方向 \ 对该单词的多个不同含义进行编码。 02:40：训练有素的注意力模块 \ 计算您需要添加到通用嵌入中的内容 \ 以将其移动到这些特定方向之一， \ 作为上下文的函数。 \ 07:55 ：从概念上认为 K 可能回答 Q。 11:22 ：（没听懂）    提交人    /u/yogimankk   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i6zh6p/d_a_3blue1brown_video_that_explains_attention/</guid>
      <pubDate>Wed, 22 Jan 2025 01:38:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 19 Jan 2025 03:15:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>