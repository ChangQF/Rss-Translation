<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 05 Feb 2025 12:32:33 GMT</lastBuildDate>
    <item>
      <title>[R] 通过广义空间传播网络进行并行序列建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii7ayl/r_parallel_sequence_modeling_via_generalized/</link>
      <description><![CDATA[      TL;DR： 空间传播网络的改进变体 [Liu et al. 2017] 是视觉任务中 Transformers 和 SSM 的快速、有竞争力的替代方案 论文： https://arxiv.org/pdf/2501.12381 摘要：  我们提出了广义空间传播网络 (GSPN)，这是一种针对视觉任务优化的新型注意力机制，可以固有地捕获 2D 空间结构。现有的注意力模型，包括 Transformers、线性注意力和 Mamba 等状态空间模型，将多维数据处理为 1D 序列，从而损害了空间连贯性和效率。 GSPN 通过直接对空间相干图像数据进行操作并通过线扫描方法形成密集的成对连接来克服这些限制。GSPN 的核心是稳定性上下文条件，它确保在 2D 序列中进行稳定的上下文感知传播，并将具有 N 个元素的方形图的有效序列长度减少到 √N，从而显著提高计算效率。凭借可学习的、依赖于输入的权重并且不依赖位置嵌入，GSPN 在视觉任务（包括 ImageNet 分类、​​类引导图像生成和文本到图像生成）中实现了卓越的空间保真度和最先进的性能。值得注意的是，在生成 16K 图像时，GSPN 可将带有 softmax-attention 的 SD-XL 加速超过 84 倍。  视觉摘要： https://preview.redd.it/5j4c125wsahe1.png?width=693&amp;format=png&amp;auto=webp&amp;s=50953106c9a2bce979f97b53c67084523b6ee8e4 视觉亮点： https://preview.redd.it/4coeu5cjuahe1.png?width=1201&amp;format=png&amp;auto=webp&amp;s=31d310a75e6f19dfb904590a8d8a0d1d52f42979 https://preview.redd.it/kgfzoa4kuahe1.png?width=587&amp;format=png&amp;auto=webp&amp;s=0f30e6574eab0fd057e8bab2a029ed004c1a2432 https://preview.redd.it/79jjec7luahe1.png?width=1337&amp;format=png&amp;auto=webp&amp;s=eb24ff967759f174ec03e6984d2a7da310742ddc https://preview.redd.it/6xttzw1muahe1.png?width=871&amp;format=png&amp;auto=webp&amp;s=670ed748ff70185c1acf5aa115939adec0c596ad https://preview.redd.it/3y02ydanuahe1.png?width=833&amp;format=png&amp;auto=webp&amp;s=f6195799f770a1d046206c9990c6697353111bb8 https://preview.redd.it/1j4ptr4puahe1.png?width=1333&amp;format=png&amp;auto=webp&amp;s=7eb319cbe18d4cc7ff4b2659a0c69a8eb962b5c4 https://preview.redd.it/yqlt590quahe1.png?width=1341&amp;format=png&amp;auto=webp&amp;s=b593155f82ac8edd5d4230f3fd9c9704be33f81a    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii7ayl/r_parallel_sequence_modeling_via_generalized/</guid>
      <pubDate>Wed, 05 Feb 2025 10:44:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] SafeRAG：检索增强生成系统的安全评估基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii6k5c/r_saferag_a_security_evaluation_benchmark_for/</link>
      <description><![CDATA[这项工作引入了 SafeRAG，这是一个用于测试检索增强生成 (RAG) 系统中安全漏洞的基准和评估框架。研究人员系统地分析了不同 RAG 实现中的数据中毒和提示注入攻击。 关键技术要点： - 创建针对检索和生成组件的攻击媒介 - 开发标准化的安全评估指标 - 评估商业和开源 RAG 系统 - 测试各种防御机制，包括输入验证和输出过滤 - 测量攻击成功率和安全措施的性能影响 主要结果： - 商业 RAG 实现比开源版本显示出更好的安全性 - 输入验证提高了安全性但降低了性能 - 当前的防御机制无法阻止所有已识别的攻击类型 - 检索组件比预期更容易受到中毒 - 生成组件表现出对提示注入的敏感性 我认为这项工作揭示了 RAG 安全性中的关键漏洞，需要在敏感应用程序中部署之前解决。基准测试应该可以帮助开发人员更好地评估他们的系统，尽管安全措施的性能权衡仍然是一个重大挑战。该方法似乎很可靠，但可能需要扩展以涵盖新出现的攻击媒介。 我认为最有价值的贡献是标准化测试框架——它为该领域提供了一种衡量和比较 RAG 安全性的通用方法。这可以加速更强大系统的开发。 TLDR：用于测试 RAG 安全性的新基准表明，当前系统容易受到数据中毒和提示注入的攻击。提供了评估防御的工具和指标，但强调了使 RAG 真正安全所需的重要工作。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii6k5c/r_saferag_a_security_evaluation_benchmark_for/</guid>
      <pubDate>Wed, 05 Feb 2025 09:47:33 GMT</pubDate>
    </item>
    <item>
      <title>研究人员和数据科学家真的会用这个吗？我正在开发一个人工智能工具来更快地找到数据集。[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii44ba/would_researchers_and_data_scientists_actually/</link>
      <description><![CDATA[我正在开发一个 AI 平台，该平台可帮助研究人员和数据科学家使用自然语言搜索在多个来源（Kaggle、政府门户、API、学术数据库等）中找到正确的数据集。目前，这个过程是超级手动的：大量谷歌搜索、检查不同的网站以及处理不一致的格式。我希望它能够轻松找到针对超特定问题的超级小众数据集。 Tl;dr – 我认为这可以通过聚合数据集、总结数据集（列、大小、上次更新）甚至建议相关数据集来为研究人员和 ML/数据科学家节省数小时的时间。 更长的解释： 使用此工具，您可以输入类似 “我需要有关年轻人智能手机使用情况和心理健康的数据” 的内容，它会在各个平台上找到相关数据集。它还将提供快速摘要，以便您知道是否值得下载而无需深入挖掘。  基于您的主题的智能推荐 API 集成以提取实时数据（例如来自 Twitter、Google Trends） 如果您想合并数据集，则可以使用数据集兼容性检查器  这有用吗？ 在我开始构建之前，试着看看这是否真的是人们会使用的东西。欢迎反馈！🙏    提交人    /u/paullieber98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii44ba/would_researchers_and_data_scientists_actually/</guid>
      <pubDate>Wed, 05 Feb 2025 06:43:39 GMT</pubDate>
    </item>
    <item>
      <title>[P]机器学习文档项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii2gkj/p_machine_learning_documentation_project/</link>
      <description><![CDATA[TL;DR：如果您有兴趣，请为以下机器学习相关的存储库做出贡献。 大家好，我有一个有趣的想法，就是创建一个有关 ML 相关主题的开源 Github 存储库。这些不会是别人的书或学习机器学习的路线图的提及。我们必须从头开始。 文件将采用 LaTeX 格式。我最初计划以 Markdown 格式编写。但我很快意识到它不能很好地扩展。例如，Markdown 不提供对数学方程式、目录、模块化、图表、图形、数字等的原生支持……这就是我选择 LaTeX 的原因。如果您不想与 Git、Github 和 LaTeX 搏斗，您可以将您写的笔记或改进建议发送给我（例如，改进内容的结构和格式）。您也将被视为贡献者。但是，我实际上建议您学习 LaTeX 并直接自己做出贡献。因为与简单的 Markdown 相比，LaTeX 为您提供了更强大的功能，如果您计划在未来撰写与 ML 相关的研究论文，它将是必需的。所以我也将这视为学习和探索更多 LaTeX 的机会。借助 Overleaf 的教程，学习 LaTeX 从未如此简单。去查看 Overleaf 教程。您可以使用 Overleaf 的基于云的平台编写 LaTeX，但我建议使用带有 LaTeX 扩展的 VS Code。它简化了工作流程。 我梦想把这本书做成“机器学习文档”之类的东西。我对需要涵盖的大多数主题和目录都有想法。所以，我们只需要详细研究每个主题。我一个人没有人力去做这件事。您可以在存储库中的“TODO”文件中找到需要涵盖的主题。存储库将是全面的。您可以将其视为与机器学习相关的博客。学习的最佳方法之一是通过教学（费曼技术）。此外，您可以创建与存储库相关的视频、闪存卡、Jupyter 笔记本等。我们将在存储库中提及您创建的这些资源。可能性无穷无尽。 此外，主题的措辞必须吸引读者并具有互动性（如内容写作），而不是像某些 AI 生成的内容。应该有一些原创性。您可以最初使用 AI 生成的内容来创建基线并在此基础上进行工作。但是，最终我们必须从此继续前进。随着时间的推移，存储库和内容将变得更加正式、全面和详细。 如果有人感兴趣或有任何类型的问题，请在本文的评论中询问我，或发送电子邮件至 open.src.lib@gmail.com。 这些是我目前正在研究的两个机器学习相关的存储库： - 机器学习 - 机器学习和深度学习的数学 注意： - 我建议目前专注于机器学习存储库。因为另一个结构不太好，也不完整。 - TODO.md 文件结构不太好，也不是世界上最好的。它需要一些处理。但你仍然可以相信它。 - 我们目前只做经典机器学习。 不是一些 LLM，深度学习类型的东西。 但如果这个项目取得良好的进展，那么下一个项目将是关于深度学习的。 我不知道我是否可以完成这个。 不过，我正在尝试，并且可能会在这个过程中学到一些东西。 我希望你们明白我的意思！ 到时候见...    提交人    /u/Zoory9900   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii2gkj/p_machine_learning_documentation_project/</guid>
      <pubDate>Wed, 05 Feb 2025 04:58:45 GMT</pubDate>
    </item>
    <item>
      <title>[P]改进不平衡医学图像数据集的多类分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii2cpm/pimproving_multiclass_classification_on_an/</link>
      <description><![CDATA[大家好， 我正在使用医学图像数据集进行多类别分类任务，其中的图像几乎是椭圆形的。类别主要按颜色区分：鲜红色、紫色、黑紫色、青色、粉红色、普通腮红和白色。一个类别只有 20 张图像，而其他类别各有 100 张图像，我目前的模型的准确率约为 56%。 如果您能提供任何关于如何改进我的模型性能的见解或建议，我将不胜感激。具体来说，我对此很感兴趣：  处理类别不平衡的策略（例如，增强、合成数据、动态加权损失函数） 模型架构修改或替代方法（例如，迁移学习或微调预训练网络） 可能更好地利用颜色差异的预处理或特征提取技术  提前感谢您的帮助！    提交人    /u/Inside-Ad3784   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii2cpm/pimproving_multiclass_classification_on_an/</guid>
      <pubDate>Wed, 05 Feb 2025 04:52:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前计算机视觉和语言技术领域不受欢迎的研究课题有哪些？ 2025</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</link>
      <description><![CDATA[不，我不想再听到有关 LLM 和 VLM 的更多信息了。    提交人    /u/KingsmanVince   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</guid>
      <pubDate>Wed, 05 Feb 2025 02:43:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM如何解决新的数学问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihsftt/d_how_does_llm_solves_new_math_problems/</link>
      <description><![CDATA[从架构角度来看，我理解 LLM 会处理来自用户查询和提示的标记，然后据此预测下一个标记。思路链机制本质上会推断这些预测以创建内部反馈循环，从而增加在训练期间使用强化学习时得出正确答案的可能性。当根据模型已知的信息解决问题时，此过程很有意义。 但是，当涉及到新的数学问题时，挑战不仅仅是简单的标记预测。模型必须理解问题，掌握底层逻辑，并使用适当的公理、定理或函数解决问题。它是如何做到这一点的？这个内部逻辑求解器从何而来，为 LLM 提供了解决此类问题所需的工具？ 澄清：新数学问题是指模型在训练期间未遇到的问题，这意味着它们不是以前见过的问题的完全重复。    提交人    /u/capStop1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihsftt/d_how_does_llm_solves_new_math_problems/</guid>
      <pubDate>Tue, 04 Feb 2025 21:03:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Vultr 优惠券的警告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihpz4k/d_warning_about_vultr_coupons/</link>
      <description><![CDATA[任何考虑使用促销积分来使用 Vultr 的人请注意 - 您的体验可能不会像预期的那样顺畅。 我有 300 美元的促销积分加上我个人存入的 5 美元（我以为是用于身份验证），但我无法使用其中任何一美元。 首先，他们要求我验证我的个人资料，我照做了。然后，他们突然要求我再存入 50 美元才能使用我已经拥有的资金 - 这实际上使我的 300 美元积分无法使用。这个要求没有提前提及，这令人沮丧。如果您已经承诺使用 Vultr，这可能不是问题，但如果您只是想测试服务，感觉很奇怪。 更糟糕的是，您不一定能够立即部署您的实例。在许多情况下，您需要打开支持票并手动请求访问权限。 他们的促销积分和存款政策具有误导性，一旦您的钱到账，您可能无法取回。他们不退款。我在他们的网站上找不到任何退款按钮，当我尝试通过 PayPal 申请退款时，他们立即暂停了我的帐户。    提交人    /u/KaiserZoldyck   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihpz4k/d_warning_about_vultr_coupons/</guid>
      <pubDate>Tue, 04 Feb 2025 19:23:29 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用自然语言生成 ML 模型的开源库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihn40f/p_opensource_library_to_generate_ml_models_using/</link>
      <description><![CDATA[大家好！我想展示一个我们正在进行的项目，希望你会感兴趣。 smolmodels 是一个完全开源的 Python 库，它根据问题的自然语言描述 + 最少的代码为特定任务生成 ML 模型。它结合了图形搜索和 LLM 代码生成，以尝试为给定问题找到并训练尽可能好的模型。这是 repo：https://github.com/plexe-ai/smolmodels。 大规模使用 LLM 的主要问题之一，特别是在延迟敏感的应用程序中，是巨大的 LLM 从根本上比较小的、特定于任务的模型更慢、更昂贵。这就是我们尝试使用 smolmodels 解决的问题。 这里有一个简单的例子来说明这个想法，基于流行的&quot;心脏病发作概率&quot;数据集（假设 df 是 pandas 数据框）： import smolmodels as sm # 步骤 1：根据意图、模式定义模型 model = sm.Model( intent=&quot;predict the probability of heart attack based on given features&quot;, input_schema={&quot;age&quot;: int, &quot;gender&quot;: int, &quot;cp&quot;: int, ... }, output_schema={&quot;probability&quot;: float} ) # 步骤 2：构建模型 model.build(dataset=df, provider=&quot;openai/gpt-4o&quot;) # 步骤 3：使用模型进行预测 prediction = model.predict({ &quot;age&quot;: 61, &quot;gender&quot;: 1, &quot;cp&quot;: 3, ... }) # 步骤 4：保存模型以供将来使用sm.models.save_model(model, &quot;heart_attack_model&quot;)  该库是完全开源的（Apache-2.0），因此您可以随意使用它。我们很乐意收到一些反馈，并且我们非常欢迎您贡献代码！    提交人    /u/impressive-burger   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihn40f/p_opensource_library_to_generate_ml_models_using/</guid>
      <pubDate>Tue, 04 Feb 2025 17:27:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformer 最佳实践：初始化/规范化/预热</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihk177/d_transformer_best_practise/</link>
      <description><![CDATA[TLDR：在参数初始化、规范化层、学习率预热（以及任何其他相关因素）方面，目前实现 Transformer 的最佳实践是什么？  我想实现和训练一个 Transformer（请参阅本文底部的“用例”） 我希望我的实现简单并且不需要太多的调整，但显然我也不想在性能、稳健性、一致性等方面做出太多牺牲 我知道有很多关于参数初始化/规范化层/学习率预热的选项，自 2017 年最初的 Transformer 论文以来，最佳实践已经发生了变化 例如： LayerNorm (2016)（用于原始变换器）对均值和 RMS 进行归一化 RMSNorm (2019) 对 RMS 进行归一化，但不对均值进行归一化 Pre-LN (2020) 将 LayerNorm 移到残差块内，从而提高了稳定性，并且消除了学习率预热的需要 T-Fixup (2020) 提出了一种初始化方案，消除了对归一化和学习率预热的需求 NormFormer (2021) 通过在注意力和 MLP 非线性后添加额外的规范化块来跟进 Pre-LN ReZero (2021) 将每个残差块的输出乘以初始化为零的可训练标量，这比 T-Fixup/NormFormer 更容易实现，同时还消除了对规范化和学习率预热的需要 这项调查 (2023) 比较了其中一些选项和其他一些选项（但没有受控的经验比较） 我目前倾向于使用没有规范化层和学习率的 ReZero热身，因为它将很容易实现（甚至比原始的 Transformer 模型更容易实现），而且根据他们的论文，它的表现应该相当不错 但我想知道为什么在最近的论文中没有看到更多提到 ReZero/现在更普遍的最佳实践是什么（假设在某种程度上有一个商定的最佳实践）？ 我最近碰巧看到的一些随机例子： Awni Hannun (2024) 说“通常使用 RMS 范数代替 Layer Norm”但没有提到 ReZero Lucas Nestler (2024) 发现 ReZero 的表现比 NormFormer 差一点（尽管这是使用“未缩放谨慎”优化器，而我打算只使用 Adam 或 AdamW，所以结果可能会有点不同） DreamerV3 使用 RMSNorm 而不是 LayerNorm，没有提到学习率预热或 ReZero  -------------------------------- 用例：我想为 集合预测 我正在研究的问题。输入数据不是基于文本或图像的。    提交人    /u/jakelevi1996   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihk177/d_transformer_best_practise/</guid>
      <pubDate>Tue, 04 Feb 2025 15:20:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论人工智能模型的推理能力及其量化方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihfyrt/r_on_the_reasoning_capacity_of_ai_models_and_how/</link>
      <description><![CDATA[https://arxiv.org/abs/2501.13833 大型语言模型 (LLM) 的最新进展加剧了围绕其推理能力基本性质的争论。虽然这些模型在 GPQA 和 MMLU 等基准测试中取得了高性能，但它们在更复杂的推理任务中表现出局限性，这凸显了对更严格的评估方法的需求。我们提出了一种新颖的现象学方法，它超越了传统的准确性指标来探究模型行为的潜在机制，建立了一个可以广泛影响我们分析和理解人工智能系统的框架。以多项选择推理任务中的位置偏差为例，我们展示了系统性扰动如何揭示模型决策的基本方面。为了分析这些行为，我们开发了两个互补的现象学模型：概率混合模型 (PMM)，将模型响应分解为推理、记忆和猜测部分；信息理论一致性 (ITC) 分析，量化模型置信度和策略选择之间的关系。通过对推理基准的受控实验，我们表明，真正的推理对于当前模型来说仍然具有挑战性，表面上的成功往往依赖于复杂的记忆和模式匹配组合，而不是真正的逻辑推理。更根本的是，我们证明单凭准确性往往会夸大模型的推理能力，因为模型行为可以通过认知策略相空间中的底层机制来表征，揭示模型在响应查询时如何动态平衡不同的方法。该框架为实际部署提供了定量标准，允许应用程序根据策略分布而不是聚合性能指标来指定可靠性阈值。    提交人    /u/jalabulajangs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihfyrt/r_on_the_reasoning_capacity_of_ai_models_and_how/</guid>
      <pubDate>Tue, 04 Feb 2025 11:54:45 GMT</pubDate>
    </item>
    <item>
      <title>[R] 推理模型是优柔寡断的鹦鹉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iheszs/r_reasoning_models_are_indecisive_parrots/</link>
      <description><![CDATA[R1、o1 和 gemini 2.0 flash 在 27 个不同的谜题上接受了测试。  这些模型仍然默认采用熟悉的解决方案，而不是适应新的环境 - 它们甚至强加不存在的约束、浪费 token 并得出错误的答案。 例子：  示例 1  问题：一组四人需要在晚上过桥。这座桥非常古老且摇摇欲坠。他们只有一支火炬，因为是晚上，所以火炬是过桥的必需品。每个人行走的速度都不同：A 需要 1 分钟才能过桥，B 需要 2 分钟，C 需要 5 分钟，D 需要 10 分钟。他们所有人过桥的最快时间是多少？  答案：10 分钟，最慢的人一起过桥的速度。  DeekSeek-R1：“……首先，限制条件是：这座桥一次只能容纳两个人，每次有人过桥时都需要火炬。所以，如果两个人一起过去，一个人必须带着火炬回来。”  示例 2  问题：假设您正在参加一个游戏节目，您可以选择三扇门：一扇门后面是金条；其他门后面是烂蔬菜。您选择了一扇门，比如说 1 号门，主持人问您，“您想选择 2 号门吗？”现在哪扇门的选择给您带来最大的优势？  回答：不，换门没有优势。我换不换都没什么区别，因为自最初的选择以来没有提供任何额外的实质性信息。蒙提霍尔问题在这里不适用，因为主持人不会打开另一扇门来告诉你是否应该换到第二扇门。 OpenAI O1：“这本质上是伪装的‘蒙提霍尔问题’。关键在于主持人提出的换门建议给了你新的信息——即另一扇未提及的门（3 号门）不是奖品。通过询问你是否想要 2 号门，主持人暗示排除了 3 号门。如果你坚持你的第一选择（1 号门），你获胜的机会仍然是开始时的 1/3。•如果你换门（在本例中是 2 号门），你获胜的概率就会跳到 2/3。因此，换门可以提高赢得金条的概率。”    submitted by    /u/Classic_Eggplant8827   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iheszs/r_reasoning_models_are_indecisive_parrots/</guid>
      <pubDate>Tue, 04 Feb 2025 10:34:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 曼巴为何消失了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihen9v/d_why_mamba_disappeared/</link>
      <description><![CDATA[我记得在 mamba 首次发布时就看到了它，因为它比 transformers 计算成本更低，性能更好，所以它被大肆炒作  那么它为什么会这样消失呢？    提交人    /u/Alarming-Power-813   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihen9v/d_why_mamba_disappeared/</guid>
      <pubDate>Tue, 04 Feb 2025 10:22:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>