<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Fri, 09 Aug 2024 21:14:01 GMT</lastBuildDate>
    <item>
      <title>[D] 关于 DNN 的修剪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eoa4t6/d_on_pruning_dnns/</link>
      <description><![CDATA[有没有什么好的资源可以编写自定义修剪函数并将它们应用于我们的网络来对其进行微调，比如如果我正在使用 GoogLenet 并且我想在转换上执行通道修剪。 使用自定义修剪函数的层，我该怎么做？     提交人    /u/TranquilVandal   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eoa4t6/d_on_pruning_dnns/</guid>
      <pubDate>Fri, 09 Aug 2024 20:30:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 错误代码嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eo64fw/d_error_code_embeddings/</link>
      <description><![CDATA[我遇到了一种特殊的问题。我需要嵌入错误代码及其相关描述（例如 ERROR1：文件未找到、ERROR2：文件大小不正确，...）。用于语义搜索，目标是识别与每个错误相关的关键字。我还需要能够找到语义上（基于其相关描述）彼此接近的代码，即 ERROR1 和 ERROR2 应该在余弦相似度方面彼此接近，但 ERROR8 的描述是关于...内存不足，会很远。 描述很完美，从几个词到一个句子不等。各种文档中大约有 150k 个错误。  我考虑过三重损失函数，嵌入锚点、正代码和负代码以及描述的组合，但似乎无法解决向量崩溃问题。 我也考虑过使用描述余弦相似度作为代码的“标签”。但结果有点糟糕。 我还认为这是一种机器翻译问题，因为代码（ERROR1 ... ERROR10）本质上是每个单独的标记，并且与相关输出（描述，自然语言）的域不同。所以我考虑过训练 enc-dec 以从输出中生成描述。但我听说相应的嵌入对于语义搜索来说并不好（尽管我自己还没有验证过）。 有没有关于代码嵌入的先前研究？除了嵌入编程“代码”之外，我很难找到任何其他结果。    提交人    /u/DReicht   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eo64fw/d_error_code_embeddings/</guid>
      <pubDate>Fri, 09 Aug 2024 17:46:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] txv：ViT 的可解释性包</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eo3s7h/p_txv_an_explainability_package_for_vits/</link>
      <description><![CDATA[txv 是一个视觉变换器可解释性包。它为视觉变换器提供了类似 CAM 的可视化效果。 pip install txv Github 存储库：https://github.com/LokeshBadisa/txv 主页：https://lokeshbadisa.github.io/txv/ 文档：https://lokeshbadisa.github.io/txv/api_reference 教程：https://lokeshbadisa.github.io/txv/tutorials   由    /u/Eage1823  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eo3s7h/p_txv_an_explainability_package_for_vits/</guid>
      <pubDate>Fri, 09 Aug 2024 16:12:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 告别低分辨率：用于图像超分辨率的扩散小波方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eo2xs9/r_waving_goodbye_to_lowres_a_diffusionwavelet/</link>
      <description><![CDATA[我们很高兴地宣布，我们在今年的国际神经网络联合会议 (IJCNN 2024) 上成功展示了 DiWa！:-) TL;DR：DiWa 是一种用于增强图像的扩散小波技术。它将扩散模型与离散小波变换和基于初始回归的预测器相结合，以实现高质量、详细的图像重建。欢迎随时联系我们了解论文、我们的发现或未来工作！    提交人    /u/Maleficent_Stay_7737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eo2xs9/r_waving_goodbye_to_lowres_a_diffusionwavelet/</guid>
      <pubDate>Fri, 09 Aug 2024 15:40:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用传统机器学习算法进行预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eo0670/d_forecasting_using_traditional_ml_algo/</link>
      <description><![CDATA[嗨， 我是时间序列分析的新手，正在使用随机森林和 SVM 为网络数据建立模型。我想知道这些模型是否适合预测。目前，我已将目标向前移动了 5 步，以便每个目标值对应于前进 5 步的一个点。此方法可用作预测步骤。此外，我使用前 5 个值作为特征。您认为这是一种好方法吗？如果您有任何建议或示例，我将不胜感激。谢谢！    提交人    /u/dumbestindumb   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eo0670/d_forecasting_using_traditional_ml_algo/</guid>
      <pubDate>Fri, 09 Aug 2024 13:48:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 光学神经网络的完全前向模式训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eo00m5/r_fully_forward_mode_training_for_optical_neural/</link>
      <description><![CDATA[摘要：光学计算有望提高机器学习应用的速度和能源效率1，2，3，4,5,6。然而，目前有效训练这些模型的方法受到数字计算机上的计算机模拟的限制。在这里，我们开发了一种称为完全前向模式 (FFM) 学习的方法，它在物理系统上实现计算密集型训练过程。因此，大多数机器学习操作都可以在现场高效并行进行，从而减轻数值建模限制。在自由空间和集成光子学中，我们通过实验展示了给定网络规模下具有最先进性能的光学系统。FFM 学习表明，训练具有数百万个参数的最深光学神经网络可实现与理想模型相当的精度。它支持通过散射介质进行全光学聚焦，分辨率达到衍射极限；它还可以以超过千赫兹的帧速率并行成像隐藏在直接视线之外的物体，并且可以在室温下以弱至亚光子/像素的光强度进行全光学处理（5.40 × 1018- 每秒每瓦操作能效）。此外，我们证明 FFM 学习可以在没有分析模型的情况下自动搜索非厄米特异常点。 FFM 学习不仅有助于提高学习过程的速度，还可以推动深度神经网络、超灵敏感知和拓扑光子学等应用和理论领域的发展。 链接：https://www.nature.com/articles/s41586-024-07687-4 代码：https://zenodo.org/records/10820584    提交人    /u/ashz8888   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eo00m5/r_fully_forward_mode_training_for_optical_neural/</guid>
      <pubDate>Fri, 09 Aug 2024 13:41:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] Karpathy - “RLHF 只是勉强算是 RL”。你同意吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enzn87/d_karpathy_rlhf_is_just_barely_rl_do_you_agree/</link>
      <description><![CDATA[https://x.com/karpathy/status/1821277264996352246    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enzn87/d_karpathy_rlhf_is_just_barely_rl_do_you_agree/</guid>
      <pubDate>Fri, 09 Aug 2024 13:25:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2024 数据集和基准测试轨道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enzi7r/d_neurips_2024_dataset_benchmarking_track/</link>
      <description><![CDATA[大家知道评论什么时候会出来吗？    提交人    /u/BodybuilderJunior775   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enzi7r/d_neurips_2024_dataset_benchmarking_track/</guid>
      <pubDate>Fri, 09 Aug 2024 13:19:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 探索 Kolmogorov-Arnold 网络在分类中的局限性：对软件训练和硬件实现的见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enx9be/r_exploring_the_limitations_of_kolmogorovarnold/</link>
      <description><![CDATA[      TL;DR：在训练计算方面，MLP 远远优于 KAN效率 论文： https://arxiv.org/pdf/2407.17790 摘要：  Kolmogorov-Arnold 网络 (KAN) 是一种新型神经网络，由于能够以更高的准确性和互操作性替代人工智能 (AI) 中的多层感知器 (MLP)，因此最近获得了普及和关注。然而，KAN 评估仍然有限，无法提供特定领域的深入分析。此外，还没有对 KAN 在硬件设计中的实现进行研究，这将直接证明 KAN 在实际应用中是否真正优于 MLP。因此，在本文中，我们专注于使用四种不同类型的数据集验证 KAN 的分类问题，这是 AI 中常见但重要的主题。此外，还考虑了使用 Vitis 高级综合 (HLS) 工具的相应硬件实现。据我们所知，这是第一篇为 KAN 实现硬件的文章。结果表明，在高复杂度数据集中，KAN 无法在利用大量硬件资源的情况下实现比 MLP 更高的准确度。因此，MLP 仍然是实现软件和硬件实现准确度和效率的有效方法。  亮点：  除了 Dry Bean 数据集的训练时间外，其他三个数据集始终表明 KAN 需要比 MLP 长得多的训练时间，范围从 6.55 倍（151.4 vs 23.1 秒）到 36.68 倍（198.1 vs 5.4 秒）。[...] 除了 Wine 数据集外，MLP 的损失减少速度一直比 KAN 更快，损失值也更低。总体而言，在训练时间和损失减少方面，KAN 并不比 MLP 更好。 总体而言，KAN 未能表现出比 MLP 更高的准确率，并且 KAN 的符号公式表示在分类挑战中的表现甚至比 MLP 更差。此外，KAN 还需要开发人员在最后阶段投入大量时间和精力来创建符号公式。  [专门的硬件测试：]  这些结果表明，与 MLP 中的正常矩阵乘法相比，在硬件上实现符号公式需要更多的硬件资源。此外，当 KAN 模型的规模增加时，所需的硬件资源也会相应增加。  视觉亮点： GPU 训练 有利于 MLP 的损失差异可能非常大。不过，Wine 数据集的快速 KAN 收敛值得注意。该数据集只有 178 个示例，每个示例有 13 个特征 GPU 训练 FPGA 训练 代码： https://github.com/Zeusss9/KAN_Analysis     由   提交  /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enx9be/r_exploring_the_limitations_of_kolmogorovarnold/</guid>
      <pubDate>Fri, 09 Aug 2024 11:27:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关我的求职机器学习项目的反馈</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enuq7p/d_seeking_feedback_on_my_machine_learning_project/</link>
      <description><![CDATA[大家好， 我正在申请政治学博士前奖学金，专注于计算冲突研究，并且我已经开发了一个示例项目来展示我的技能。我将不胜感激您可能提供的任何反馈或建议。 项目名称：机器学习用于恐怖主义数据分类 目标：应用机器学习技术对与冲突相关的文本进行分类，并根据全球恐怖主义数据库中的历史数据预测冲突结果。 展示的技能：机器学习、特征工程、模型训练和评估。 项目链接： 机器学习用于 1970 年至 2020 年东南亚恐怖主义数据分类的  职位描述： 政治学博士前研究员 我特别想听听您对以下方面的反馈：  项目概述的清晰度和结构。 所用方法和技术的有效性。 任何可以加强此类应用项目的其他元素。  提前感谢您的时间和见解！    提交人    /u/Lemmeaskyouonething   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enuq7p/d_seeking_feedback_on_my_machine_learning_project/</guid>
      <pubDate>Fri, 09 Aug 2024 08:45:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 24 数据集跟踪评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ent5sa/d_neurips_24_dataset_track_reviews/</link>
      <description><![CDATA[数据集和基准轨道评论应该在延迟后的今天发布。 我确信与主轨道相比，我们对此的关注度要小得多，但这可以作为讨论主题:)    提交人    /u/medcanned   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ent5sa/d_neurips_24_dataset_track_reviews/</guid>
      <pubDate>Fri, 09 Aug 2024 06:56:39 GMT</pubDate>
    </item>
    <item>
      <title>[d] ReFT 的实际示例：14 分钟内在 Llama3 上完成表征微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enk8wm/d_practical_example_of_reft_representation/</link>
      <description><![CDATA[几周前，Arxiv ReFT 论文第一作者郑轩吴与 Oxen.AI 首席执行官 Greg Schoeninger 合作，深入探讨了 ReFT：表示微调。 在明天（星期五）的 AI Water Cooler 中，Oxen 实习生 Eric 将介绍： &quot;我如何在 14 分钟内使用 ReFT 对 Llama3 进行微调&quot; ReFT 的 TLDR：不是通过参数进行微调，而是在隐藏状态中插入表示来指导模型。 Eric 将展示早期 Arxiv Dive 的实际实现。 有用的细节：  AI Water Cooler 是深度技术不太正式、未经记录的空间 8 月 9 日星期五，太平洋时间上午 10:00 定期日历邀请：https://oxen.ai/community YouTube https://youtu.be/to2oKwnknUk?si=LmMMYxoryOn0UCwh Arxiv 论文链接：https://arxiv.org/pdf/2404.03592     提交人    /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enk8wm/d_practical_example_of_reft_representation/</guid>
      <pubDate>Thu, 08 Aug 2024 23:10:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] FlexAttention：PyTorch 的灵活性与 FlashAttention 的性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</link>
      <description><![CDATA[https://pytorch.org/blog/flexattention/    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</guid>
      <pubDate>Thu, 08 Aug 2024 13:49:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>