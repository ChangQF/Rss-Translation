<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Mon, 22 Apr 2024 09:15:12 GMT</lastBuildDate>
    <item>
      <title>[D] 变形金刚中的复制机制，救命！！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca5ypn/d_copy_mechanism_in_transformers_help/</link>
      <description><![CDATA[大家好，我正在阅读这篇关于情境学习的论文：https://arxiv.org/abs/2212.07677。在第 4 节中，它提到了这种“复制机制”，但我很难理解它实际上是做什么的......  我的问题与论文的具体细节无关，我想知道其中的内容一般复制机​​制！！！  有人可以帮忙吗？ :)））））   由   提交/u/SnooOnions9136  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca5ypn/d_copy_mechanism_in_transformers_help/</guid>
      <pubDate>Mon, 22 Apr 2024 08:59:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] TriForce：使用分层推测解码对长序列生成进行无损加速</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca5smr/r_triforce_lossless_acceleration_of_long_sequence/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.11912 代码：https ://github.com/Infini-AI-Lab/TriForce 项目页面：https://infini-ai-lab.github.io/TriForce/ 摘要：  随着最近大型语言模型（LLM）在长内容生成中的广泛部署，对高效长序列推理支持的需求日益增长。然而，存储键值（KV）缓存以避免重新计算，其大小随着序列长度线性增长，已成为关键瓶颈。由于LLM的自回归性质，将为每个生成的令牌加载整个KV缓存，导致计算核心利用率低和延迟高。虽然已经提出了各种 KV 缓存压缩方法来缓解这个问题，但它们的生成质量会下降。我们引入了TriForce，这是一种可扩展至长序列生成的分层推测解码系统。这种方法通过检索利用原始模型权重和动态稀疏 KV 缓存作为草稿模型，充当层次结构中的中间层，并由较小的模型进一步推测以减少其草稿延迟。 TriForce 不仅为 Llama2-7B-128K 提供了令人印象深刻的加速，在 A100 GPU 上实现了高达 2.31× 的速度，而且还展示了处理更长上下文的可扩展性。对于两个 RTX 4090 GPU 上的卸载设置，TriForce 实现了0.108s/token，仅比 A100 上的自回归基线慢一半，后者在 A100 上实现了7.78×我们优化的卸载系统。此外，TriForce 在单个 RTX 4090 GPU 上的性能是 DeepSpeed-Zero-Inference 的4.86 倍。 TriForce 的坚固性以其在各种温度下始终如一的出色性能而著称。该代码可在 此 https URL 处获取。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca5smr/r_triforce_lossless_acceleration_of_long_sequence/</guid>
      <pubDate>Mon, 22 Apr 2024 08:46:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多镜头情境学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca5ky2/r_manyshot_incontext_learning/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.11018 摘要：  大型语言模型（LLM）擅长少量的in-上下文学习（ICL）——在推理时从上下文中提供的几个示例中学习，无需任何权重更新。新扩展的上下文窗口使我们能够使用数百或数千个示例来研究 ICL - 多样本机制。从少数镜头到多次镜头，我们观察到各种生成和判别任务的性能显着提升。虽然很有前景，但多次 ICL 可能会受到可用的人工生成示例数量的瓶颈。为了缓解这一限制，我们探索了两种新设置：强化和无监督 ICL。强化 ICL 使用模型生成的思维链原理代替人类示例。无监督 ICL 完全删除了提示中的基本原理，并且仅提示模型特定于领域的问题。我们发现强化 ICL 和无监督 ICL 在多次训练中都非常有效，特别是在复杂的推理任务中。最后，我们证明，与少样本学习不同，多样本学习可以有效地克服预训练偏差，并且可以通过数值输入学习高维函数。我们的分析还揭示了下一个令牌预测损失作为下游 ICL 性能指标的局限性。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca5ky2/r_manyshot_incontext_learning/</guid>
      <pubDate>Mon, 22 Apr 2024 08:31:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我正在尝试从高级员工转为 Gen AI / ML ops 架构师角色</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca5csr/d_i_am_trying_to_switch_from_a_senior_staff_to_a/</link>
      <description><![CDATA[大家好， 我发现公司非常挑剔，认为职业中断很糟糕。过去几个月我失业了，我正在寻找新工作。由于这是我第一次裁员，我想知道如果您正在休息并寻找新的工作职位，这会很糟糕吗？ 。人力资源人员在我的个人资料中看到我在云方面的广泛专业知识后就不再回来了？ 不幸的是，我拥有机器学习/人工智能的相关学位和一些 Gen AI 专业知识，但我在云方面的主要专业知识阻碍了大人物的发展正在寻找了解基础设施、数据科学、DevOps、DL、ML 和 gen AI 全栈的 GOD 应用工程师的公司。你的想法和经历是什么？市场有那么差吗？我应该回去寻找云角色还是继续在 Gen AI 中寻找一些可以展示的宠物项目？   由   提交 /u/Future_Challenge4191   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca5csr/d_i_am_trying_to_switch_from_a_senior_staff_to_a/</guid>
      <pubDate>Mon, 22 Apr 2024 08:15:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求建议：利用大型语言模型 (LLM) 解决数据挑战</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca4pjk/d_seeking_advice_solving_data_challenges_with/</link>
      <description><![CDATA[大家好 我遇到了一个问题，需要使用 LLM 来解决，以便从包含以下内容的文本中获取正确的数据：只有约 20% 的结构。这是一个示例数据 XXXXX AA BB CCCC:（可选DDDD） C1......(A1 ) (B1) C2......(A2) (B2) C3......(A3) (B3) 我需要回答从 A1/B1 到 A3/B3 对的这些结果中的任何一个，但为了做到这一点，我需要返回并询问用户 C1 到 C3 中的哪一个选项与 DDDD 一起适用于他？ /p&gt; 上面不是最复杂的结构，它的复杂性从这里开始增加，因此需要与用户进行大量聊天才能获取始终存在于上面的块中的正确数据。 在最简单的情况下，数据结构如下所示 XXXXX AA BB CCCC: ......(A1) (B1) 您将如何构建这样的系统？我正在研究使用 Langchain 的多代理系统，提示链怎么样？   由   提交/u/deeplearning2018   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca4pjk/d_seeking_advice_solving_data_challenges_with/</guid>
      <pubDate>Mon, 22 Apr 2024 07:29:47 GMT</pubDate>
    </item>
    <item>
      <title>[P] 零射击标志检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca35a7/p_zero_shot_logo_detection/</link>
      <description><![CDATA[我正在尝试创建一个可以识别图像中品牌徽标的网络应用程序。我尝试过使用 Microsoft Azure 计算机视觉/自定义视觉 API，但结果并不令人满意。我读过有关 Yolo 和 Yolo world 的内容。如果您曾经在项目中使用过它们，您能帮我看看这样是否可以实现零样本徽标检测吗？   由   提交 /u/CommercialFragrant   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca35a7/p_zero_shot_logo_detection/</guid>
      <pubDate>Mon, 22 Apr 2024 05:49:07 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 对于拥有丰富 SWE 经验、试图通过做个人项目和创建作品集来进入 ML 工程或数据工程的人来说，现实是什么？这是一个现实的目标吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca2j8j/discussionwhat_is_the_reality_for_someone_with/</link>
      <description><![CDATA[寻找极其诚实的意见。对于数据工程师来说，现实情况是否有所不同，因为我发现目前的供应需求使 DE 具有吸引力？    由   提交/u/Emergency-Director53  /u/Emergency-Director53 reddit.com/r/MachineLearning/comments/1ca2j8j/discussionwhat_is_the_reality_for_someone_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca2j8j/discussionwhat_is_the_reality_for_someone_with/</guid>
      <pubDate>Mon, 22 Apr 2024 05:11:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] AI 标志生成器 Looka 的 ML 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca1t0d/d_r_ai_logo_generator_lookas_ml_model/</link>
      <description><![CDATA[我偶然发现了这个人工智能徽标生成器网站 Looka。有谁知道它实际上是如何工作的？使用哪些机器学习模型可以如此快速地生成徽标，或者是否有预制模板？我还实现了稳定扩散来生成徽标，但这需要时间，而且生成的徽标效果也不错。   由   提交/u/Vishesh9096   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca1t0d/d_r_ai_logo_generator_lookas_ml_model/</guid>
      <pubDate>Mon, 22 Apr 2024 04:28:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 直接优惠政策 (DPO) - SFT 数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ca1lza/d_direct_preference_policy_dpo_sft_dataset/</link>
      <description><![CDATA[在 dpo 论文中，作者建议在进行 DPO 之前先进行 SFT，以防止分布偏移，并且还证明了非 SFT 和非 SFT 的性能差异新论文中的 SFT：https://arxiv.org/pdf/2404.12358.pdf 然而，我有点不确定使用 SFT 模型来整理偏好数据集的规则是什么。这是否意味着在进行 DPO 之前，参考模型必须在偏好数据集/相似分布数据集的相同提示 (x) 上进行 SFT 处理？或者偏好数据集必须从参考模型中策划？ 后者意味着您可以对任何数据集进行 SFT，只要偏好数据集是使用 SFT 模型策划的，而不是使用任何数据集您可以在网上找到可用的首选数据集，该数据集很可能是使用某些未知策略策划的。虽然前者说 ref 策略必须在 pref 数据集的相同分布（即类似的提示类型）上进行 SFT，这意味着与之前的情况相比，这只是对 pref 数据集选择的响应进行了额外的 SFT 步骤。&lt; /p&gt; 你对此有何看法？   由   提交 /u/nohodlnodough   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ca1lza/d_direct_preference_policy_dpo_sft_dataset/</guid>
      <pubDate>Mon, 22 Apr 2024 04:17:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能劳动力或公司是否比其他技术行业更分散？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9zr8x/d_is_the_ai_workforce_or_companies_more/</link>
      <description><![CDATA[   /u/digital-bolkonsky   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9zr8x/d_is_the_ai_workforce_or_companies_more/</guid>
      <pubDate>Mon, 22 Apr 2024 02:36:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 GNN 在工业界的需求不高？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9vibh/d_why_isnt_gnn_in_high_demand_in_industry/</link>
      <description><![CDATA[几乎没有数据科学家或机器学习工程师的职位发布需要 GNN。 是因为它的计算成本很高 - 无论是时间还是空间？或者是因为将数据预处理为图形格式并不总是直观的？或者 GNN 在学术界之外的认知度仍然很低？   由   提交/u/Snoo_72181   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9vibh/d_why_isnt_gnn_in_high_demand_in_industry/</guid>
      <pubDate>Sun, 21 Apr 2024 23:04:31 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 以视觉方式深入了解安德烈·卡帕蒂 (Andrej Karpathy) 首创的特斯拉数据引擎。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9oomh/research_a_visual_deep_dive_into_teslas_data/</link>
      <description><![CDATA[   TL;DR：特斯拉使用轻量级“触发分类器”检测机器学习模型表现不佳时的罕见情况。相关数据上传到服务器以改进模型，然后再次训练模型以覆盖不同的故障模式。 特斯拉如何持续自动改进 500 万辆以上汽车的自动驾驶和完全自动驾驶能力。视觉指南：特斯拉如何建立他们的迭代机器学习管道  P.S.：我花了几个小时研究并准备对由 Andrej Karpathy 开创的 Tesla 数据引擎进行可视化深入研究。这篇文章列出了特斯拉如何改进其完全自动驾驶和自动驾驶功能的迭代秘诀。 https://preview.re dd.it/qxmjeavmjvvc1.jpg?width=1456&amp;format=pjpg&amp;auto=webp&amp;s=94cb35f71f7e57b6bcc6e 0bf9f1d5f05b5c7f086 https://preview.redd.it/htz4p8vmjvvc1 .jpg?width=1456&amp;format=pjpg&amp;auto=webp&amp;s=a722604b59d2c6fbb8f7e605ad496bede05a238e   由   提交/u/ml_a_day  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9oomh/research_a_visual_deep_dive_into_teslas_data/</guid>
      <pubDate>Sun, 21 Apr 2024 18:18:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] Okkam - 使用 GA 查找适合任意数据集的多项式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jejf/p_okkam_find_polynomials_that_fit_arbitrary/</link>
      <description><![CDATA[与当前的 NN 元相比，这可能有点老派，但如果有人感兴趣，我已经编写了一个用于查找可配置多项式的工具CSV 中任意数据的参数（项数、指数位）。它使用可配置的基于锦标赛的 GA 算法来完成此操作，并提供一个 UI 来查看其进展情况。它是用 Rust 编写的，速度相对较快 - 尝试最大限度地利用所有可用的内核，因此可以很好地扩展。 如果您喜欢所看到的内容，我们将很高兴听到一些反馈或建议。在仓库上留下一个星星:) 仓库： Github&lt; /p&gt;   由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jejf/p_okkam_find_polynomials_that_fit_arbitrary/</guid>
      <pubDate>Sun, 21 Apr 2024 14:36:46 GMT</pubDate>
    </item>
    <item>
      <title>机器学习研究中推荐算法/系统的现状如何？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9hr3b/whats_the_current_state_of_recommendation/</link>
      <description><![CDATA[大约 4 年前，当我第一次开始我的 ML 之旅时，我学到的最基本的入门级推荐算法是关于协作过滤和基于内容的过滤。 我想更多地了解推荐系统的当前状态。怎么变了？人们试图采用哪些方法来寻找更好的推荐？有没有提到在推荐系统中包含因果关系？后者似乎是最“最新”的进步，但我还没有找到概述。   由   提交/u/Direct-Touch469   reddit.com/r/MachineLearning/comments/1c9hr3b/whats_the_current_state_of_recommendation/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9hr3b/whats_the_current_state_of_recommendation/</guid>
      <pubDate>Sun, 21 Apr 2024 13:20:56 GMT</pubDate>
    </item>
    </channel>
</rss>