<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Sat, 08 Mar 2025 09:14:19 GMT</lastBuildDate>
    <item>
      <title>[P]本周更新：Microsoft Azure现在可以使用DeepSeek-R1 671b的工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j6czij/p_update_this_week_tool_calling_for_deepseekr1/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   deepseek-r1爱好者令人振奋的消息！ I&#39;ve now successfully integrated DeepSeek-R1 671B support for tool calling on Microsoft Azure for BOTH Python AND JavaScript developers! Python: https://github.com/leockl/tool-ahead-of-time  javascript/typescript： https：//github.com/leock.com/leockl/leockl/tool-ahead-ohead-oftim-pime-time-ts      为什么这么重要？因为现在您可以利用DeepSeek-R1 671B具有令人难以置信的推理能力来利用工具，并具有企业级基础架构，安全性和可扩展性！  如果有帮助的话，请给我的GitHub存储库一个明星。希望这对需要这个的任何人都有帮助。玩得开心！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lc19-     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j6czij/p_update_this_week_week_tool_calling_for_for_deepseekr1/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j6czij/p_update_this_week_tool_calling_for_deepseekr1/</guid>
      <pubDate>Sat, 08 Mar 2025 08:41:13 GMT</pubDate>
    </item>
    <item>
      <title>图形数据的矢量化方法（在线ML）[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j6cry6/vectorization_method_for_graph_data_online_ml_p/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您好， 我目前正在从事Android恶意软件检测项目（二进制分类；恶意软件和良性），在其中我分析从我发现的在线数据集中从APK文件中提取的函数呼叫图。但是我是整个“图形数据”部分的新手。 我的项目尤其基于在线学习，这是模型随着新数据到达而不断自行更新的时候，而不是在固定数据集中培训。尽管我想知道我是否应该首先合并部分批处理学习...  我正在使用 示例原始JSON数据，但我打算使用：     {＆lt; lt; lt; lt; dump; lt; lt; dump; lt; lt; lt; dummymymainmathod（void dummymainmethod（java.lang.lang.lang.string [java.lang.string []） ＆quot＆quot＆quor com.ftnpv.speed.mywrapperproxyapplication：void＆lt; init＆gt;（） ＆quot＆quot＆quot android.app.application：void＆lt; init＆gt;（） ＆quot＆quord＆lt; com.wrapper.proxyapplication.wrapperproxyapplication：void onCreate（）＆gt;：＆qut;：{}}}}}}}}}    每个键是函数名称，并且值是其他功能。该结构表示应用程序的控制流。 href =“ https://arxiv.org/pdf/1707.05005”&gt; Graph2vec 兼容性。 ARF, Hoeffding Tree, SDG) using these embeddings.  Based on what I have seen, Graph2vec only captures structural properties of the graph so similar function call patterns between different APKs and variations in function relationships between benign and malware samples. I&#39;m kind of stuck here and I have a couple of问题：   graph2vec是这个问题的正确选择吗？ 有没有基于ol的gnn在那里可以尝试？ 另一种图形嵌入方法（node2vec，gcns或其他东西）可以更好地工作吗？提交由＆＃32; /u/u/i-am-am-just-that-guy       [link]     32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j6cry6/vectorization_method_for_graph_data_online_ml_p/</guid>
      <pubDate>Sat, 08 Mar 2025 08:25:18 GMT</pubDate>
    </item>
    <item>
      <title>[d]帮助找到论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j6cagu/d_help_finding_a_paper/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我最近看到了一篇论文，我认为在此潜艇或一个相关的子上，这是在谈论保存嵌入的另一种方法和计算用于检索和分类任务的相似性。它与传统的余弦相似性嵌入进行了比较，并以较小的足迹得分更高。我以为我可以保存稍后阅读，但现在我找不到任何地方，我希望有人看到它并记得阅读它。 感谢您的阅读！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;  /u/zilios   [link] ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j6cagu/d_help_finding_a_paper/</guid>
      <pubDate>Sat, 08 Mar 2025 07:49:56 GMT</pubDate>
    </item>
    <item>
      <title>[r]通过基于提示的学习进行工具集成的自学成才的推理LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j6bojk/r_selftaught_reasoning_llm_with_tool_integration/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  开始：使用外部工具的自学成才的推理器 研究人员开发了一种新颖的方法，称为“ start” that teaches language models to use external tools (specifically Python code execution) for complex reasoning tasks without requiring demonstration data. The key innovation is a two-step process: 1. Hint-infer: Inserting simple hints like &quot;Maybe I should use Python here&quot;在推断触发工具期间使用2。 collected 50,000 tool use examples across various reasoning datasets After filtering, approximately 32,000 high-quality examples were used for fine-tuning On GPQA (PhD-level science questions), START achieved 63.6% accuracy (vs. 40.3% for base model) On AMC23 (competition math), START reached 95.0% accuracy 对于更高级的数学比赛（AIME24/25），开始得分66.7％和47.1％ 在livecodebench上（竞争性编程），开始实现47.3％的准确性 这些结果与更大的专有模型 lie          影响 我认为这种方法代表了我们构建推理系统的范式转变。开始显示，我们可以通过集成外部计算工具来实现更好的结果，而不是试图扩展模型来内部处理所有计算。特别有趣的是“提示”方法表明，模型已经具有潜在的工具使用功能，可以通过最小的提示来激活。 我认为这可能会大大改变我们对复杂技术领域的AI的方式。我们可能会更多地专注于教授现有模型以有效利用外部工具，而不是尝试训练不断增加的模型。这更接近人类如何真正解决问题 - 我们使用计算器，编程语言和其他工具，而不是在脑海中做所有事情。 我认为自学框架是这项工作中最有前途的方面。从其自身的经验中生成，过滤和学习的能力创造了一种可扩展的改进方法，不依赖于人类生成的演示。  tldr  开始，开始教语言模型，使用python通过小说“ hint +自我嘲笑”来进行复杂的推理，方法，实现在博士学位科学问题和竞争数学/编码问题的更大模型中，实现结果竞争 - 所有这些都没有演示数据。  在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j6bojk/r_selftaught_reasoning_llm_with_tool_integration/</guid>
      <pubDate>Sat, 08 Mar 2025 07:06:39 GMT</pubDate>
    </item>
    <item>
      <title>[d] ijacai 2025摘要拒绝</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j6b787/d_ijacai_2025_summary_reject/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨，我只是想知道是否有人收到摘要拒绝？因为他们应该在3月7日发送摘要拒绝。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/oksplit641    href =“ https://www.reddit.com/r/machinelearning/comments/1j6b787/d_ijacai_2025_summary_reject/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j6b787/d_ijacai_2025_summary_reject/</guid>
      <pubDate>Sat, 08 Mar 2025 06:33:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] [R] Sannd：使用可训练的迭代器的新神经网络框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j6809q/p_r_sannd_a_new_neural_network_framework_using/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  没有计算图的神经网络？ 神经网络不需要静态图。如果我们使用迭代器而不是张量训练了模型？ 引入sannd（沙盒人工神经网络设计） - 一个新的深度学习框架，其中模型像沙子一样流动。 与Tensorflow/Pytorch不同，Sannd不依赖计算图。取而代之的是，它使用可训练的迭代器（模具）： *动态调制数据流像层一样 *通过反向传播学习和适应 *支持残留网络，LSTMS和元学习的本性学习 📚传统的深度学习框架依靠静态张量和计算图。 SANND提出了一种更轻，更灵活的方法： 残留连接＆amp; LSTM是微不足道的（只是不同的模具链）元学习，在线学习更容易（没有固定结构）自然支持反向传播，而无需明确的图形  🛠️现在尝试一下！ 🔗github： https://github.com/gurumoore/sannd  href =“ https://github.com/gurumoore/sannd/sannd/blob/main/quickstart.md”&gt; https://github.com/gurumoore/gurumoore/sannd/sannd/blob/main/main/quickstart.md.md.md.md 改变我们如何建立神经网络？ 🚀  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j6809q/p_r_r_sannd_a_new_neur_near_neur_network_framework_usey/”&gt; [link]    32;  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j6809q/p_r_sannd_a_new_neur_neural_neur_network_framework_userwork_usion/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j6809q/p_r_sannd_a_new_neural_network_framework_using/</guid>
      <pubDate>Sat, 08 Mar 2025 03:20:25 GMT</pubDate>
    </item>
    <item>
      <title>热：突出显示的思想链，用于参考输入的支持事实</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j676bx/hot_highlighted_chain_of_thought_for_referencing/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/u/lagitimate-case-3530       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j676bx/hot_highlighted_chain_of_thought_for_referencing/</guid>
      <pubDate>Sat, 08 Mar 2025 02:34:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] Arxiv认可请求AV项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j65qvv/p_arxiv_endorsement_request_for_av_project/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们的研究论文，“知识图作为自动驾驶汽车中材料意识到障碍物处理的世界模型，“ ”已被接受ICLR世界模型工作室2025年。但是，由于会议是非Archival，因此我们计划在ARXIV上发布该会议。我们需要有人认可我们的论文。几位审稿人已经验证了该论文，因此，如果有人可以快速提供认可，那将非常有帮助。 将文章提交给 cs.ai&gt; cs.ai  Arxiv的部分。要告诉我们，您会（或不会）认可此人，请访问以下URL： https://arxiv.org/auth/auth/auth/endorse?x=4Kdyhi  ape and clibe vist y hiv a n y hi. href =“ http://arxiv.org/auth/endorse.php”&gt; http://arxiv.org/auth/endorse.php 并输入以下六二吉特alphanumeric string：认可代码：认可代码：4Kdyhi      &lt;！提交由＆＃32; /u/syaang     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j65qvv/p_arxiv_endorsement_request_for_av_project/</guid>
      <pubDate>Sat, 08 Mar 2025 01:19:38 GMT</pubDate>
    </item>
    <item>
      <title>[d]与ML库一起使用Pyspark的最佳实践是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5y3d2/d_what_are_the_best_practices_for_using_pyspark/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我将Pyspark用于项目的数据处理部分，因为我的数据集很大，并且使用Pandas DataFrame会非常慢。 ，但是一旦我的数据准备就绪，我想使用Sklearn的一些方法，例如分层的启动，例如在Pyspark.ml上都无法使用。我考虑过将Pyspark数据框架转换为熊猫的数据框架，然后使用Sklearn和其他ML库从那里转换为从那里转换为非常昂贵的部分，并且导致内存错误  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/amirdol7     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5y3d2/d_what_are_the_best_practices_for_using_pyspark/</guid>
      <pubDate>Fri, 07 Mar 2025 19:40:48 GMT</pubDate>
    </item>
    <item>
      <title>[D]是否可以在AMD的Ryzen 7 Ai NPU上进行机器学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5wmfz/d_is_it_possible_to_do_machine_learning_on_amds/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我还没有找到太多有关我是否可以使用tensorflow或pytorch的DL库，以及与AMD的ryzen 7处理器一样，我发现的很少的信息有点令人困惑。我已经看过Rocm，Ryzenai，甚至DirectML，但到目前为止似乎找不到直接的答案。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/marco_camilo     [link]   [commist]         ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5wmfz/d_is_it_possible_to_do_machine_learning_on_amds/</guid>
      <pubDate>Fri, 07 Mar 2025 18:50:24 GMT</pubDate>
    </item>
    <item>
      <title>[R]研究比较良性与故障的DNN中间层输出分布的研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5vhdj/r_research_on_comparing_benign_vs_faulty_dnn/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我是DNN的新手，并正在寻找有关比较良性（正确）和故障DNN模型之间的中间层输出分布以通过分配移位来检测故障的研究。您可以推荐任何论文或资源吗？ 预先感谢。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/usef_cut_4452     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j5vhdj/r_research_on_comparing_benign_vs_faulty_dnn/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5vhdj/r_research_on_comparing_benign_vs_faulty_dnn/</guid>
      <pubDate>Fri, 07 Mar 2025 18:07:32 GMT</pubDate>
    </item>
    <item>
      <title>[r]杂交：结合术前和后场，以进行更稳定和有效的变压器训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5l9mk/r_hybridnorm_combining_prenorm_and_postnorm_for/</link>
      <description><![CDATA[I&#39;ve been experimenting with various normalization techniques in transformers lately, and this new HybridNorm approach seems like a particularly elegant solution to the speed vs. stability tradeoff. The core idea is surprisingly simple but effective: use Layer Normalization after attention sublayers (where stability matters most) and use RMS Layer Normalization everywhere else (where we can benefit from its computational efficiency). Key technical points: - The post-attention sublayer is much more sensitive to normalization type than other positions - Using RMSNorm in non-critical positions reduces computation without compromising stability - Implementation requires minimal code changes to existing transformer architectures - HybridNorm delivers 13-17% training speedup compared to standard LayerNorm - Performance跨基准任务（胶水，小队，机器翻译）维护 - 在不同的模型量表（0.1b至3B参数）上始终如一地工作 - 与仅编码器，仅解码器和编码器decoder-decoder Architectures  兼容。 13-17％的加速可能听起来并不革命性，而是应用于大规模训练，这是零质量折衷的大量计算节省。本文还暗示了一个更广泛的机会 - 仔细分析哪些组件需要完全稳定，而我们可以优化速度。   特别有用的是该技术如何与现有架构无缝集成。您无需重新设计模型 - 只需在特定位置交换标准化层即可。从本质上免费获得提高效率的一个难得的案例。“  发现变压器中不同位置具有不同稳定性要求的发现为为什么在数学上发生这种情况的情况都打开了有趣的问题。我很想看到后续工作更深入地探索这一现象。  tldr：杂交从策略上结合了变压器模型中的分层和rmsnorm，将注意力越来越稳定的分层放置在注意力下的分子和更快的rmsnorm之后。这种简单的更改可提供13-17％的速度，而不会影响模型质量。 全部总结。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5l9mk/r_hybridnorm_combining_prenorm_and_postnorm_for/</guid>
      <pubDate>Fri, 07 Mar 2025 11:21:14 GMT</pubDate>
    </item>
    <item>
      <title>[D]学习如何与LLM构建的最佳资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j5jlae/d_best_resources_to_learn_how_to_build_with_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最佳资源或课程是什么，特别是针对在数据科学领域中拥有丰富知识的人，精通一般的ML/DL原则，但是现在希望进入LLMS世界？    &lt;！ -  sc_on--&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j5jlae/d_best_resources_to_to_lealed_how_to_build_with_with_with_llms/”&gt; [links]      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j5jlae/d_best_resources_to_to_to_lealed_how_to_build_build_with_with_lls/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j5jlae/d_best_resources_to_learn_how_to_build_with_llms/</guid>
      <pubDate>Fri, 07 Mar 2025 09:25:00 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1j1hc0o/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j1hc0o/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Mar 2025 03:15:17 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些经验丰富的人。   &lt;！ -  sc_on--&gt; 32;&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>