<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Wed, 24 Apr 2024 12:29:15 GMT</lastBuildDate>
    <item>
      <title>[R] 我制作了一个应用程序来根据评论预测 ICML 论文接受情况</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbwsr2/r_i_made_an_app_to_predict_icml_paper_acceptance/</link>
      <description><![CDATA[https://www.norange.io/ projects/paper_scorer/ 几年前，u/programmerChilli 分析了 ICLR 2019 评审数据并训练了一个模型，该模型可以相当准确地预测 NeurIPS 的接受结果。 我决定继续进行这项分析，并根据较新的 NeurIPS 评论训练了一个模型（总共约 6000 个参数），该评论的评论数量是 ICLR 2019 的两倍。此外，NeurIPS 的评论评分系统自 2019 年以来已经发生了变化，以下是我了解到的情况： 1) 两个会议一致拒绝几乎所有得分 &lt;5 的提交内容，并接受那些得分 &gt;6 的提交内容。被接受的论文中最常见的分数是 6。大约 5.3 的平均评分通常会导致 ICML 和 NeurIPS 做出可能采取任何一种方式的决定，这表明 ~5.3 可能被认为是接受的软阈值。  2) 置信度分数对于边界评级（例如 4（边界拒绝）、5（边界接受）和 6（弱接受））影响较小，但它们可以显着影响较强拒绝或接受案例的结果。  例如，评级为 [3, 5, 6]，置信度为 [*, 4, 4]，将“拒绝”更改为“拒绝”。置信度从 5 变为 1 会使概率从 26.2% - 31.3% - 52.4% - 54.5% - 60.4% 变化，表明在这种情况下置信度较低会增加您的机会。 相反，对于评级 [3, 5 , 7] 置信度为 [4, 4, 4] 时，接受概率为 31.3%，但当置信度变为 [4, 4, 5] 时，接受概率降至 28.1%。尽管看起来有悖常理，但置信度分数为 5 实际上会降低您的机会。一种可能的解释是，许多评分为 5 的低质量评论通常会被区域主席 (AC) 打折。 希望这会有用，并感谢 u/programmerChilli 寻求灵感！ 我还在一系列 推文。   由   提交/u/Lavishness-Mission  /u/Lavishness-Mission reddit.com/r/MachineLearning/comments/1cbwsr2/r_i_made_an_app_to_predict_icml_paper_acceptance/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbwsr2/r_i_made_an_app_to_predict_icml_paper_acceptance/</guid>
      <pubDate>Wed, 24 Apr 2024 12:23:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] SpaceByte：从大型语言模型中删除标记化 - 莱斯大学 2024 - 几乎与子字标记化器具有相同的性能，但没有许多缺点！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbw0bn/r_spacebyte_towards_deleting_tokenization_from/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2404.14408 Github：https://github。 com/kjslag/spacebyte 摘要：  标记化在大型语言模型中被广泛使用，因为它显着提高了性能。然而，标记化带来了一些缺点，例如性能偏差、对抗性漏洞增加、字符级建模性能下降以及建模复杂性增加。为了在不牺牲性能的情况下解决这些缺点，我们提出了 SpaceByte，这是一种新颖的&lt;字节级解码器架构缩小了字节级和子字自回归语言建模之间的性能差距。SpaceByte 由字节级 Transformer 模型组成，但在层中间插入了更大的 Transformer 块。我们发现，仅在某些字节（例如通常表示字边界的空格字符）之后应用这些较大的块，性能显着提高。我们的实验表明，对于固定的训练和推理计算预算，SpaceByte 的性能优于其他字节级架构，并且大致与标记化 Transformer 架构的性能相匹配。论文：https://arxiv.org/abs/2404.14408Github: https:// github.com/kjslag/spacebyteAbstract：标记化在大型语言模型中被广泛使用，因为它显着提高了性能。然而，标记化带来了一些缺点，例如性能偏差、对抗漏洞增加、字符级建模性能下降以及建模复杂性增加。为了在不牺牲性能的情况下解决这些缺点，我们提出了 SpaceByte，这是一种新颖的字节级解码器架构，可以缩小字节级和子字自回归语言建模之间的性能差距。 SpaceByte 由字节级 Transformer 模型组成，但在各层中间插入了更大的 Transformer 块。我们发现，仅在某些字节（例如通常表示字边界的空格字符）之后应用这些较大的块，可以显着提高性能。我们的实验表明，对于固定的训练和推理计算预算，SpaceByte 的性能优于其他字节级架构，并且与标记化 Transformer 架构的性能大致相当。  https://preview.redd.it/v1xo6g1gzewc1.jpg?width=1507&amp;format=p jpg&amp;自动=webp&amp;s=f9d415307b60639fa67e8a54c8769fa5a6c10f04 https://preview.redd.it/edvqos1gzewc1.jpg?width=1654&amp;format=pjpg&amp;auto=webp&amp;s=f91c8727017e1a1bc7b80bb77a8627ff99182607  https://preview.redd.it/fe6z6i1gzewc1.jpg?width=1181&amp;format=p jpg&amp;amp; ;auto=webp&amp;s=24d955f30b8ca3eaa7c527f3f40545ed493f789c   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbw0bn/r_spacebyte_towards_deleting_tokenization_from/</guid>
      <pubDate>Wed, 24 Apr 2024 11:42:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 跟踪模型及其相关元数据。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbundt/d_keeping_track_of_models_and_their_associated/</link>
      <description><![CDATA[我开始为我正在从事的项目积累大量模型，其中许多模型都是旧模型，我为了存档而保留它们，并且许多是根据其他模型进行微调的。我想知道是否有行业标准的方法来处理这个问题，特别是我正在寻找以下内容：  有关用于训练模型的参数的信息 用于训练模型的数据集 有关模型的其他元数据（即对象检测模型训练的对象） 模型性能&lt; br /&gt; 模型沿袭（从哪个模型进行微调） 模型进展（该模型是从其他模型直接升级的吗？从相同的模型调整，但使用更好的超参数） 模型源（不确定这一点，但我正在考虑某种方法将模型链接到用于训练的 python 脚本不是很重要，但这样就很好了）  是否有任何服务工具可以帮助实现某些功能？另外，如果这不是这个问题的子问题，我可以获得一些正确方向的指示。谢谢！  ​   由   提交 /u/ClearlyCylindrical   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbundt/d_keeping_track_of_models_and_their_associated/</guid>
      <pubDate>Wed, 24 Apr 2024 10:20:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 Hugging Face 库部署微调的 Mistral 7B 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbtxxb/d_deploy_the_finetuned_mistral_7b_model_using_the/</link>
      <description><![CDATA[我按照 https 上提供的教程进行操作://www.datacamp.com/tutorial/mistral-7b-tutorial，现在寻求使用 Hugging Face 和 Gradio 来部署模型以实现更快推理的方法。任何人都可以分享指导笔记本或文章吗以供参考？如有任何帮助，我们将不胜感激。   由   提交 /u/Future-Outcome3167    reddit.com/r/MachineLearning/comments/1cbtxxb/d_deploy_the_finetuned_mistral_7b_model_using_the/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbtxxb/d_deploy_the_finetuned_mistral_7b_model_using_the/</guid>
      <pubDate>Wed, 24 Apr 2024 09:31:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transkribus 与 Tesseract 的手写文本识别 (HTR)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbr6h9/d_transkribus_vs_tesseract_for_handwritten_text/</link>
      <description><![CDATA[我正在寻找一种精度最高且最好不贵的 HTR 工具（显然）。根据我的研究，Transkribus 似乎是被提及最多且评价良好的平台。由于我需要定期将图像转换为文本，因此我需要支付订阅费用。所以我想知道是否可以使用 Tesseract 和/或 TensorFlow Python 库来免费获得相同的结果。使用 Tesseract/TensorFlow 是否会比使用 Transkribus 更不准确？ 我只学习了机器学习的基础知识（TensorFlow、scikit-learn、keras），所以我可能没有足够的知识来了解两者之间的区别两个解决方案。或者训练 Tesseract/TensorFlow 会很有挑战性吗？   由   提交 /u/Pretty_Instance4483   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbr6h9/d_transkribus_vs_tesseract_for_handwritten_text/</guid>
      <pubDate>Wed, 24 Apr 2024 06:15:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研究人员在考虑创建新的/改进的基础模型时如何考虑归纳偏差？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbnbsd/d_how_researcher_think_of_inductive_bias_when/</link>
      <description><![CDATA[我是学习机器学习的本科生。 我在阅读几篇论文时了解到我们试图减少搜索空间通过在机器学习模型中施加归纳偏差。当归纳偏差与基础数据相匹配时，创建有用模型就会成功。 在像 NVAE 这样的分层模型中，他们如何通过指定数据的计算方式来灌输归纳偏差？ （我认为这称为算法偏差，但不确定） 但是人们如何认为这种归纳偏差会有帮助，他们坚持这种归纳偏差要经历什么步骤。 &lt;我参加了很多机器学习和统计学课程，但没有听过任何解释这些内容的讲座。我是否错过了任何课程/讲座？ 如果可能，请提供与之相关的论文/讲座/演讲 谢谢   由   提交 /u/binny_sarita   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbnbsd/d_how_researcher_think_of_inductive_bias_when/</guid>
      <pubDate>Wed, 24 Apr 2024 02:36:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态检索和排序的广义对比学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbixix/r_generalized_contrastive_learning_for_multimodal/</link>
      <description><![CDATA[对流行的 CLIP 训练方法进行概括，使其更适合搜索和推荐。  论文：https://arxiv.org/pdf/2404.08535.pdf Github：https://github.com/marqo-ai/GCL 概括CLIP：  使用任意数量的文本和/或图像来表示文档。 通过模态间和模内损失更好地理解文本。 可以对排名/重要性/相关性进行编码，又名“排名调整”。 适用于预训练、文本、CLIP 模型。 可以学习单向量或多向量表示用于文档。 适用于二进制和 Matryoshka 方法。 开源 10M 行多模态数据集，包含 100k 查询和约 5M 产品。  为什么？ 训练嵌入模型的主流方法在很大程度上与最终用例（如搜索）、向量数据库、用户的需求以及缺乏用于开发和评估的代表性数据集，特别是当涉及多种模式和排名时。 当前矢量搜索嵌入模型的局限性 尽管矢量搜索是非常强大并且可以搜索几乎任何数据，但当前的方法有一些局限性。训练嵌入模型的流行方法在很大程度上与最终用例（如搜索）、向量数据库和用户的需求脱节。这意味着矢量搜索的许多潜力尚未得到满足。下面描述了当前的一些挑战。 仅限于使用单条信息来表示文档 当前模型编码并表示一条信息一个向量的信息。现实情况是，一份文档通常有多个相关信息，这些信息可能跨越多种模式。例如，在产品搜索中可能有标题、描述、评论和多个图像，每个图像都有自己的标题。 GCL 将嵌入模型训练概括为使用所需数量的信息。 处理退化查询时没有排名概念 当存在退化查询时查询 - 满足某些相关标准的多个结果 - 结果的排序只能从许多二元关系中间接学习。实际上，结果的排序很重要，即使对于第一阶段检索也是如此。 GCL 允许在嵌入中编码查询文档特定相关性的大小，并提高候选文档的排名。 使用类似 CLIP 的方法时文本理解较差 对于像 CLIP 这样的多模态模型，这些模型经过训练只能从图像到文本（反之亦然）。由于文本-文本关系是通过图像间接学习的，文本-文本的理解不如纯文本模型。对于许多应用程序来说，需要了解模态间和模内内的情况。 GCL 允许通过直接优化来实现模态间和模内理解的任意组合。 缺乏代表性数据集来开发矢量搜索方法 在开发 GCL 的过程中，很明显，与用于嵌入模型训练和评估现实世界用例的公开数据集存在脱节。现有的基准测试通常仅是文本或仅是跨模式的，并且侧重于 1-1 查询结果范式。此外，现有数据集的相关性概念有限，大多数将其编码为二元关系，而一些数据集通常仅在测试集上使用（最多）少量离散分类。这与典型的现实世界用例不同，在典型的现实世界用例中，相关性可以是硬二元关系，也可以来自连续变量。为了帮助解决这个问题，我们编译了一个包含 10M（排名）产品查询对的数据集，涵盖约 100k 查询、近 500 万个产品和四个评估分割（可用 此处)。 ​   由   提交/u/Jesse_marqo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbixix/r_generalized_contrastive_learning_for_multimodal/</guid>
      <pubDate>Tue, 23 Apr 2024 23:07:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能在公司内部的实际应用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbhxwb/d_practical_uses_of_ai_inside_companies/</link>
      <description><![CDATA[人们如何在公司内部（初创公司 -&gt; FAANG）使用人工智能来改进运营和流程？关于利用 LLM 和 GenAI 的讨论有很多，但我正在努力寻找成功的真正具体示例。 首先想到的是以下领域，但这个列表当然并不详尽：  p&gt;  设计（和移交） 工程 客户支持 销售 文档 营销  什么有效或有希望？什么不起作用？   由   提交 /u/CJSF   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbhxwb/d_practical_uses_of_ai_inside_companies/</guid>
      <pubDate>Tue, 23 Apr 2024 22:25:43 GMT</pubDate>
    </item>
    <item>
      <title>Meta 做了 OpenAI 应该做的一切 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbhec7/meta_does_everything_openai_should_be_d/</link>
      <description><![CDATA[我很惊讶（或者可能没有）这么说，但 Meta（或 Facebook）比 OpenAI 更民主化 AI/ML，而 OpenAI 最初是成立并主要为此目的提供资金。 OpenAI 很大程度上已经成为一个仅以盈利为目的的商业项目。虽然就 Llama 模型而言，对我来说它们尚未达到 GPT4 功能，但我相信这只是时间问题。你们对此有何看法？   由   提交 /u/ReputationMindless32   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbhec7/meta_does_everything_openai_should_be_d/</guid>
      <pubDate>Tue, 23 Apr 2024 22:03:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 吴的方法可以将符号人工智能提升到与银牌得主和 AlphaGeometry 竞争，从而超越 IMO Geometry 金牌得主</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cbd2ol/r_wus_method_can_boost_symbolic_ai_to_rival/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.06405 代码：https:// /huggingface.co/datasets/bethgelab/simplegeometry 摘要：  证明几何定理构成了视觉推理结合的标志直觉和逻辑能力。因此，奥林匹克级别几何问题的自动定理证明被认为是人类级别自动推理的一个重要里程碑。 AlphaGeometry 的推出标志着一项重大突破，这是一种用 1 亿个合成样本训练的神经符号模型。它解决了 30 个国际数学奥林匹克 (IMO) 问题中的 25 个，而基于 Wu 的方法报告的基线仅解决了 10 个。在这篇文章中，我们重新审视了 AlphaGeometry 引入的 IMO-AG-30 挑战赛，发现 Wu 的方法出奇的强大。仅吴的方法就可以解决15个问题，其中一些问题是其他任何方法都无法解决的。这导致了两个关键发现：（i）将 Wu 的方法与演绎数据库和角度、比率和距离追踪的经典综合方法相结合，仅使用仅使用 CPU 的笔记本电脑在 5 分钟的时间限制内解决了 30 种方法中的 21 种每个问题。从本质上讲，这种经典方法仅比 AlphaGeometry 少解决 4 个问题，并建立了第一个完全符号化的基线，其强度足以与 IMO 银牌得主的表现相媲美。 (ii) Wu 的方法甚至解决了 AlphaGeometry 未能解决的 5 个问题中的 2 个问题。因此，通过将 AlphaGeometry 与 Wu 的方法相结合，我们在 IMO-AG-30 上建立了一种新的最先进的自动定理证明，解决了 30 个问题中的 27 个，这是第一个超越 IMO 金牌得主的人工智能方法.    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cbd2ol/r_wus_method_can_boost_symbolic_ai_to_rival/</guid>
      <pubDate>Tue, 23 Apr 2024 19:11:50 GMT</pubDate>
    </item>
    <item>
      <title>[N] Phi-3-mini 在 HuggingFace 上发布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb7f9n/n_phi3mini_released_on_huggingface/</link>
      <description><![CDATA[https://huggingface .co/microsoft/Phi-3-mini-128k-instruct 技术报告中的数字看起来确实很棒，我想需要由第三方验证。 &lt; /div&gt;  由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb7f9n/n_phi3mini_released_on_huggingface/</guid>
      <pubDate>Tue, 23 Apr 2024 15:26:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何将 LLaMA 3 部署到生产中以及硬件要求</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb3ge1/d_how_to_and_deploy_llama_3_into_production_and/</link>
      <description><![CDATA[许多人都在尝试安装和部署自己的 LLaMA 3 模型，因此这里是我刚刚制作的教程，展示了如何在 AWS EC2 上部署 LLaMA 3实例：  https://nlpcloud.com/how-to-install-and-deploy-llama-3-into-product.html 部署 LLaMA 3 8B 相当容易，但部署 LLaMA 3 70B 则很困难另一个野兽。考虑到所需的 VRAM 量，您可能需要配置多个 GPU 并使用 vLLM 等专用推理服务器，以便将模型拆分到多个 GPU 上。 LLaMA 3 8B 需要大约 16GB 的磁盘空间，并且FP16 中 20GB VRAM（GPU 内存）。至于LLaMA 3 70B，它需要大约140GB的磁盘空间和160GB的FP16 VRAM。 我希望它有用，如果您有疑问，请随时询问！ 朱利安   由   提交/u/juliensalinas   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb3ge1/d_how_to_and_deploy_llama_3_into_production_and/</guid>
      <pubDate>Tue, 23 Apr 2024 12:33:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为 DS/MLE 单独工作的人应该牢记哪些最佳实践和工作流程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cb0fi1/d_what_best_practices_and_workflows_those_working/</link>
      <description><![CDATA[我想知道技术招聘人员或经验丰富的 DS/MLE 对像我这样的人有什么看法：良好的理论和良好的技术背景，但单独工作太长了。 我的职业生涯背景摘要：我作为 DS 工作了 8 年，前 3 年在中型研发和咨询团队（一家大型科技公司）工作，然后在过去 5 年内，作为相对成功的非人工智能初创企业的独立 DS，主要开发 ML/NLP 内容来解决特定问题或改进其产品的一项特定功能（即从来不是整个产品）。在我设计的5年里。开发和部署了 4 个模型（但尝试了许多 OFC）——以及一些仪表板和简单的流式化 POC）。  最近参加聚会，看到实际团队中的人们如何工作、讨论和交流知识，这突然让我感到震惊：我错过了，我正在变得过时。我对技术面试感觉不够敏锐，我不确定我开发和维护项目的方式是否遵循良好的标准/最佳实践（哎呀，我几乎不遵循看板，主要使用我的计划员向我的老板报告进度） 。我做了一些版本控制并记录了我放入产品中的内容，但即便如此，我也不确定我正在按照团队的预期进行操作。   由   提交/u/Melodic_Reality_646   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cb0fi1/d_what_best_practices_and_workflows_those_working/</guid>
      <pubDate>Tue, 23 Apr 2024 09:40:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama-3 可能刚刚杀死了专有的人工智能模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</link>
      <description><![CDATA[完整博客文章  Meta 在三天前发布了 Llama-3，感觉开源模型终于缩小了与专有模型的差距，这已经是一个拐点。初始基准测试显示 Llama-3 70B 在许多任务中非常接近 GPT-4：  官方元页面仅显示Llama-3优于Gemini 1.5和Claude Sonnet。 人工分析显示 Llama-3 的质量介于 Gemini-1.5 和 Opus/GPT-4 之间。 关于 LMSYS 聊天机器人竞技场排行榜，Llama-3 排名第 5，而当前的 GPT-4 模型和 Claude Opus 仍并列第 1。  功能更强大Llama-3 400B+ 模型仍在训练中，发布后很可能超越 GPT-4 和 Opus。 Meta vs OpenAI 有人推测 Meta 从一开始的目标就是瞄准OpenAI 采用“焦土”方法，通过发布强大的开放模型来扰乱竞争格局并避免在竞争中落后AI 竞赛。 Meta 在计算和人才方面可能会超过 OpenAI：  OpenAI 的预计收入为 20 亿美元，并且可能无利可图。 2023 年，Meta 的收入为 $134B，利润为 $39B。 Meta 的计算资源目前可能超过 OpenAI。 开源可能会吸引更好的人才和研究人员。  &gt;  一个可能的结果是微软收购 OpenAI 以赶上 Meta。谷歌也在进军开放模型领域，并拥有与 Meta 类似的功能。看看它们适合什么位置将会很有趣。 获胜者：开发人员和人工智能产品初创公司 我最近写了一篇关于现在建立人工智能初创公司令人兴奋，因为您的产品会随着每个主要模型的进步而自动改进。随着 Llama-3 的发布，开发人员的机会更大：  不再受供应商锁定。 开发人员不仅可以封装专有 API 端点，还可以现在以一种非常经济有效且高性能的方式将人工智能深度集成到他们的产品中。 Hugging Face 上已经有超过 800 个 llama-3 模型变体，而且看起来每个人都能够针对他们的使用案例、语言或行业进行微调。 更快、更便宜的硬件：Groq 现在每秒可以生成 800 个 llama-3 代币，而成本只是 GPT 成本的一小部分。以低价提供近乎即时的 LLM 响应即将到来。  视觉和视频的开源多模式模型仍然需要迎头赶上，但我预计这很快就会发生。 Llama-3 的发布标志着人工智能民主化的一个重要里程碑，但现在宣布专有模型的消亡可能还为时过早。谁知道呢，也许 GPT-5 会让我们所有人感到惊讶，并超越我们对 Transformer 模型功能的想象。 这绝对是人工智能领域构建的超级激动人心的时代！    由   提交 /u/madredditscientist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cad7kk/d_llama3_may_have_just_killed_proprietary_ai/</guid>
      <pubDate>Mon, 22 Apr 2024 15:08:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>