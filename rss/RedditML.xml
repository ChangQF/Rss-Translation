<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 23 Sep 2024 06:24:44 GMT</lastBuildDate>
    <item>
      <title>SQuAD 从零开始训练——问题与难点。[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fndwls/squad_training_from_scratch_questions_and/</link>
      <description><![CDATA[大约一年前，我参加了深度学习课程，我能够使用非常小的数据集创建一个合理的英语到德语翻译器。我想扩展这个想法，使用 SQuAD 创建自回归编码器-解码器转换器，但我遇到了很多困难和一些问题。  与翻译工作不同，SQuAD 的问题和答案与上下文相比非常短。因此，对于答案和问题编码，我将 10 作为最大序列长度，将上下文设置为 200 最大序列长度。因此，我向编码器提供 [batch x 200]，向解码器提供 [batch x 10]。这种做法可以吗？从编码角度来看，这不会产生错误，但我想知道从 LLM 的角度来看，这是否可以。 PAD 索引问题：我正在使用 Pytorch 中的 CrossEntropyLoss()，其中 ignore index = PAD index。但是，很多时候标签会有很多 PAD，像这样：[鱼，PAD，PAD，PAD，PAD，PAD，PAD，PAD，PAD，PAD]。如果我的输出是 [我喜欢吃苹果鱼，PAD，PAD，PAD，PAD，PAD]，那么它会忽略最后 9 个输出，而我并不想发生这种情况 - 我希望损失能够惩罚不必要的输出，即“喜欢吃苹果鱼”。我试图对 PAD 索引施加较小的惩罚，但结果仍然不太好。如何处理具有大量 PAD 的超短输出？例如，标签 = [Notre Dame PAD PAD PAD PAD PAD PAD PAD PAD]？我知道你可以做一些类似开始和结束标记索引输出的事情，但我想用自回归来做...... 我读到你可以做一些学习热身，这样你就不会得到梯度消失。我每批次采集 15 个样本，并使用 LinearLR 调度程序在 100 个批次中将学习量从 0.0001 线性提升到 0.001。我也在使用 Adam 优化器。我得到了大约 4000 个批次中目标嵌入的梯度总和从 e-1 到 e-7 的递减量。而我的损失从一开始就没有减少。它只是输出一些不连贯的输出，如 [............] 或 [of of of of of of of of of of of]。  任何见解都会非常有帮助。 附注：我正在使用编码器-解码器变压器，它有 12 个头、768 个隐藏维度、每个 6 层、2048 个前向维度，在注意力头之后使用规范化 + 残差连接，dropout 为 0.1。我认为这应该会产生一些合理的词语，尽管不正确。也许对此的一些见解可能会很棒。我读过尝试尽可能地模仿 GPT 架构，只要我的 GPU 内存允许（只有 2GB）...    提交人    /u/DiabloSpear   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fndwls/squad_training_from_scratch_questions_and/</guid>
      <pubDate>Mon, 23 Sep 2024 06:17:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 度量学习对 dinov2 进行微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fnbwyu/p_metric_learning_to_finetune_dinov2/</link>
      <description><![CDATA[如何使用度量学习来微调 dinov2... 我有一个未标记图像的数据集。我想微调 dinov2，以生成更好的图像嵌入来进行聚类并对我的图像进行相似性搜索。请让我知道度量学习是否可以用于 dinov2，并分享您使用过的任何资源    提交人    /u/PositiveResponse7678   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fnbwyu/p_metric_learning_to_finetune_dinov2/</guid>
      <pubDate>Mon, 23 Sep 2024 04:04:10 GMT</pubDate>
    </item>
    <item>
      <title>[N] 矩阵剖析系列的最后一篇论文：“矩阵剖析 XXXI：仅主题矩阵剖析：速度快几个数量级”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fn9s96/n_the_last_paper_in_the_matrix_profile_series/</link>
      <description><![CDATA[      亲爱的同事们 我很高兴地宣布矩阵剖析系列的最后一篇论文：“矩阵剖析 XXXI：仅基序矩阵剖析：速度快几个数量级”（或将被称为“MOMP”论文）[a]。 我认为不是每篇论文都需要宣布，但是…… 1）本文附带了一组新的基准数据集，这些数据集将被广泛使用。 2）对于寻找有趣问题来解决的学生和年轻教授，本文概述了几个值得研究的有趣挑战。 3）对于真正需要为其研究找到时间序列基序的研究人员，捆绑的代码将允许他们认为数据集要大一到两个数量级。 4）本文具有较小的“历史”意义，是三十篇被高引用率论文系列中的最后一篇。 为了让读者了解矩阵轮廓的影响力，请注意它刚刚成为 Matlab 语言的正式组成部分 [b]。 在论文 [a] 的扩展版本中，我花时间对矩阵轮廓系列进行了反思，并感谢帮助我实现时间序列数据挖掘愿景的数十个人。 本文通过引入矩阵轮廓的第一个下限，首次为加快八年来精确时间序列主题发现做出了贡献（基于硬件的想法除外）。 [a] 矩阵轮廓 XXXI：仅主题的矩阵轮廓：速度快几个数量级。 https://www.dropbox.com/scl/fi/mt8vp7mdirng04v6llx6y/MOMP_DeskTop.pdf?rlkey=gt6u0egagurkmmqh2ga2ccz85&amp;dl=0 [b] https://www.mathworks.com/help/predmaint/ref/matrixprofile.html https://preview.redd.it/it16c6h8vgqd1.jpg?width=2602&amp;format=pjpg&amp;auto=webp&amp;s=578a65723507c597ee4140d2eed17ba5938f326d    提交人    /u/eamonnkeogh   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fn9s96/n_the_last_paper_in_the_matrix_profile_series/</guid>
      <pubDate>Mon, 23 Sep 2024 02:04:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 实现 StyleGAN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fn6ivp/d_implementing_the_stylegan/</link>
      <description><![CDATA[大家好，如果您能查看我关于实施 StyleGAN 的最新帖子，我将不胜感激，这是我上一篇关于 PGGAN 的帖子的后续。如有任何问题，请随时联系我们。    提交人    /u/throwaway16362718383   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fn6ivp/d_implementing_the_stylegan/</guid>
      <pubDate>Sun, 22 Sep 2024 23:18:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何在聊天机器人 LlamaIndex 中使用记忆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fn2hye/p_how_to_use_memory_in_chatbot_llamaindex/</link>
      <description><![CDATA[在使用 RAG 管道构建聊天机器人时，内存是整个管道中最重要的组件。 我们将在 LlamaIndex 中集成内存并使用 Qdrant 向量存储启用混合搜索。 实施：https://www.youtube.com/watch?v=T9NWrQ8OFfI    提交人    /u/External_Ad_11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fn2hye/p_how_to_use_memory_in_chatbot_llamaindex/</guid>
      <pubDate>Sun, 22 Sep 2024 20:15:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] 介绍 FileWizardAi：使用人工智能排序和搜索整理您的文件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmy7j0/p_introducing_filewizardai_organizes_your_files/</link>
      <description><![CDATA[我很高兴与大家分享我一直在做的一个项目，名为 FileWizardAi，这是一个基于 Python 和 Angular 的工具，旨在管理您的文件。此工具会自动将您的文件组织成结构良好的目录层次结构，并根据其内容重命名，从而更轻松地整理您的工作区并快速找到文件。 该应用程序无法 100% 本地启动。 这是 GitHub 存储库；如果您想添加其他功能或有错误需要修复，请告诉我。也非常欢迎拉取请求： https://github.com/AIxHunter/FileWizardAI    提交人    /u/Majestic-Quarter-958   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmy7j0/p_introducing_filewizardai_organizes_your_files/</guid>
      <pubDate>Sun, 22 Sep 2024 17:09:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 22 Sep 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 二进制向量和Jaccard度量的快速精确搜索算法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmrmbq/d_fast_exact_search_algorithm_for_binary_vectors/</link>
      <description><![CDATA[我有一个以下问题：使用 Jaccard 相似性在一组长二进制向量中找到向量的精确最近邻（不是 ANN）。 对于近似解，我可以使用标准 MinHash LSH Forest（例如在 datasketch 库中），但我需要一个精确的。Scikit-learn 的最近邻太慢了，即使在 6 个核心上也是如此，因为它只能进行蛮力运算。K-D 树和球树不能使用，因为它们依赖于欧几里得距离，具体意味着对于给定维度有一个很好的截止值，这显然不适用于二进制数据和 Jaccard 度量。我不能使用 Faiss，因为它只支持精确二进制向量的汉明距离。 我可以使用什么算法或库？    提交人    /u/qalis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmrmbq/d_fast_exact_search_algorithm_for_binary_vectors/</guid>
      <pubDate>Sun, 22 Sep 2024 12:01:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 计划构建 7x RTX4090 设备。有什么建议吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmrfgw/d_planning_on_building_7x_rtx4090_rig_any_tips/</link>
      <description><![CDATA[我计划构建一个 7x RTX4090 装备，配备 Ryzen Threadripper 7960X 和 256GB 内存以及 2x 2000 瓦电源。我不太确定主板，但 Pro WS WRX90E-SAGE SE 或类似产品似乎适合 7x PCIE 16x 插槽。我需要降低（功率限制）我的 GPU 以避免过度劳累我的 PSU，我还将使用转接电缆将我的 GPU 安装在主板上。 有人有类似设置的经验吗？ 7960X 的 24 个核心对于 7 个 GPU 来说是否太少了？ 使用此设置运行模型并行 pytorch（例如 LLM 微调）时是否可能出现带宽问题？ 提前感谢任何提示或建议！    提交人    /u/Chance-Tell-9847   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmrfgw/d_planning_on_building_7x_rtx4090_rig_any_tips/</guid>
      <pubDate>Sun, 22 Sep 2024 11:50:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] PointNet 用于点云分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmrewx/d_pointnet_for_point_cloud_classification/</link>
      <description><![CDATA[我对 PointNet 模型使用的架构有疑问。 如果您查看它的内部，您会发现第一个块之一是 T-Net，它基于点的组合估计最佳转换矩阵，以将云与规范空间对齐。这很好，它使用了所有点的组合信息。 接下来，它需要开始从每个点提取特征，因此它将每个点应用于 MLP，该 MLP 将点重新映射到维度为 64 的新空间。 好吧，在这里我开始失去踪迹，而 T-Net 使用所有点的组合，MLP 层一次将一个点作为输入，因此它必须仅从该点的位置提取特征和含义。 我认为，要赋予一个点意义，就应该看看它周围的点。 起初我以为 T-Net 也在一个空间中执行映射，其中每个点都有携带一些聚合信息的坐标，但每个人都说这只是与规范空间对齐。 那么云的组合信息在哪里用于提取特征？    提交人    /u/AcquaFisc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmrewx/d_pointnet_for_point_cloud_classification/</guid>
      <pubDate>Sun, 22 Sep 2024 11:49:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解 1.58 位大型语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmnkar/d_understanding_158bit_large_language_models/</link>
      <description><![CDATA[大家好，我写了一篇关于三元 (trinary) 模型的文章，总结了我读到的关于这个主题的内容。它更像是一篇高水平的文献综述。目标受众是对研究感到好奇但没有时间深入研究论文本身的开发人员。这是一篇 Medium 上的免费文章。 感谢任何反馈和意见。    提交人    /u/ahronorha   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmnkar/d_understanding_158bit_large_language_models/</guid>
      <pubDate>Sun, 22 Sep 2024 07:19:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医疗 AI：顶级研究论文/模型🏅（2024 年 9 月 14 日至 9 月 21 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmkhok/d_last_week_in_medical_ai_top_research/</link>
      <description><![CDATA[      上周医疗 AI：顶级研究论文/模型🏅（2024 年 9 月 14 日至 9 月 21 日） 本周医疗 AI 论文  如何使用人工智能构建虚拟细胞：优先事项和机遇  本文提出了“人工智能驱动的虚拟细胞”的愿景，旨在创建稳健、数据驱动的细胞和细胞系统表示。它讨论了人工智能在各个尺度上生成通用生物学表征以及使用“虚拟仪器”促进可解释的计算机模拟实验的潜力。   医学法学硕士及其他模型  GP-GPT：用于基因-表型映射的法学硕士  本文介绍了 GP-GPT，这是第一个用于遗传-表型知识表示和基因组关系分析的专门大型语言模型。使用来自基因组学、蛋白质组学和医学遗传学数据集和出版物的超过 300 万个术语进行训练。  HuatuoGPT-II，医学法学硕士的 1 阶段训练 本文介绍了 HuatuoGPT-II，一种用于传统中医的新型大型语言模型 (LLM)，使用统一的输入输出对格式进行训练，以解决领域自适应中的数据异构性挑战。  HuatuoGPT-Vision：多模态医学法学硕士  本文介绍了 PubMedVision，这是一个 130 万个样本医学 VQA 数据集，通过使用 MLLM (GPT-4V) 对 PubMed 图像-文本对进行细化和去噪而创建。  Apollo：轻量级多语言医学法学硕士  本文介绍了多语言医学数据集 ApolloCorpora，以及XMedBench，评估六种主要语言的医学法学硕士的基准。作者开发并发布了 Apollo 模型（0.5B-7B 个参数）  GMISeg：通用医学图像分割  框架和方法  CoD：医疗代理的诊断链 如何使用 AI 构建虚拟细胞 使用 SAM 进行可解释的视觉概念发现 协调人类知识以获得可解释的医学图像 ReXErr：放射学报告中的合成错误 用于医学基础模型的 Veridical 数据科学 针对医学的微调 LLM：DPO 的作用  临床试验  用于生成临床试验表格和图表的 LLM 用于临床报告更正的 LLM AlpaPICO：用于临床试验 PICO 框架的 LLM  医学 LLM 应用  微软在医疗领域大规模部署机器人的经验  .... 详细查看完整帖子：https://x.com/OpenlifesciAI/status/1837688406014300514 感谢您的阅读！如果您知道任何遗漏的有趣论文，请随时在评论中分享。如果您在医疗 AI 方面有见解或突破，并希望在下周的版本中分享，请通过 Twt/x 与我们联系：OpenlifesciAI    提交人    /u/aadityaura   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmkhok/d_last_week_in_medical_ai_top_research/</guid>
      <pubDate>Sun, 22 Sep 2024 03:51:43 GMT</pubDate>
    </item>
    <item>
      <title>[D]除了美国和中国之外，人工智能模型发展排名前三的国家是哪些？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fme9af/dwhat_are_the_top_3_countries_in_development_of/</link>
      <description><![CDATA[毫无疑问，美国和中国在大型语言模型的发展中处于领先地位。其他国家表现如何？    提交人    /u/Realistic-Ad-6231   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fme9af/dwhat_are_the_top_3_countries_in_development_of/</guid>
      <pubDate>Sat, 21 Sep 2024 22:09:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 热点课题的研究人员如何跟上？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1flz1vo/d_how_do_researchers_in_hot_topics_keep_up/</link>
      <description><![CDATA[昨天晚上，我在阅读 Deepmind 的“通过强化学习训练语言模型进行自我纠正”(https://arxiv.org/abs/2409.12917)，该论文于 2 天前发布。这篇论文是关于使用 RL 预训练 LLM，但这与我的问题无关。 这篇论文很有趣，但我在阅读时想知道：他们怎么有时间做那里提到的所有事情？我的意思是：  根据所使用的预训练模型，他们很可能在 2-3 个月前才开始研究它 大多数参考文献和引文来自 2024 年下半年（从 5 月到 6 月开始），因此不到 3 个月  因此，在这几个月中，他们必须：阅读并彻底研究所有引用的论文（在这种情况下大约有 45 篇，并且再次强调：其中大多数都是非常新的），提出新的想法，开发它，进行实验（如今 SFT 也不是 15 分钟的事），汇编结果，并撰写实际论文。并且这假设他们没有同时研究其他论文/工作…… 作为一名单独的研究人员，我甚至无法想象在这段时间内做类似的事情，但即使在一个小团队中，我也发现这几乎是不可能的。我的一天只有 24 小时，但感觉研究界的其他人可以暂停时间以完成更多工作。 我是效率低下还是愚蠢？要完全理解一篇新颖的论文，我可能需要一两天的时间（每天 6 小时）来重现、推导所有（或大部分）数学运算并更深入地了解它为什么有效/无效。 非常感谢任何见解，谢谢！    提交人    /u/bgighjigftuik   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1flz1vo/d_how_do_researchers_in_hot_topics_keep_up/</guid>
      <pubDate>Sat, 21 Sep 2024 09:19:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>