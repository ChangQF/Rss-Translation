<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 02 Dec 2024 21:16:23 GMT</lastBuildDate>
    <item>
      <title>[R] ImageFolder🚀：使用折叠标记进行自回归图像生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h55x1i/r_imagefolder_autoregressive_image_generation/</link>
      <description><![CDATA[ ImageFolder🚀：使用折叠标记的自回归图像生成 图像标记器对于视觉生成模型（例如扩散模型 (DM) 和自回归 (AR) 模型）至关重要，因为它们构建了用于建模的潜在表示。增加标记长度是提高图像重建质量的常用方法。但是，标记长度较长的标记器并不能保证实现更好的生成质量。在标记长度方面，重建质量和生成质量之间存在权衡。在本文中，我们研究了标记长度对图像重建和生成的影响，并为权衡提供了灵活的解决方案。我们提出了 ImageFolder，这是一种语义标记器，它提供空间对齐的图像标记，可以在自回归建模期间折叠以提高生成效率和质量。为了在不增加 token 长度的情况下增强表示能力，我们利用双分支乘积量化来捕获图像的不同上下文。具体而言，在一个分支中引入语义正则化以鼓励压缩语义信息，而另一个分支则用于捕获剩余的像素级细节。大量实验证明使用 ImageFolder tokenizer 可以生成更高质量的图像并缩短 token 长度。  代码：https://github.com/adobe-research/ImageFolder    提交人    /u/xternalz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h55x1i/r_imagefolder_autoregressive_image_generation/</guid>
      <pubDate>Mon, 02 Dec 2024 21:11:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] PerpetualBooster 在 AutoML 基准测试中的表现优于 AutoGluon</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h52zk8/p_perpetualbooster_outperforms_autogluon_on/</link>
      <description><![CDATA[PerpetualBooster 是一种 GBM，但其行为类似于 AutoML，因此它也与 AutoGluon（v1.2，最佳质量预设）进行了基准测试，AutoGluon 是 AutoML 基准测试中的当前领导者。从 OpenML 数据集中选择了行数最多的前 10 个数据集。下表总结了回归任务的结果：   OpenML 任务 永久训练时长 永久推理时长 永久 RMSE AutoGluon 训练时长 AutoGluon 推理时长 AutoGluon RMSE    [Airlines_DepDelay_10M](openml.org/t/359929) 518 11.3 29.0 520 30.9 28.8   [bates_regr_100](openml.org/t/361940) 3421 15.1 1.084 OOM OOM OOM   [BNG(libras_move)](openml.org/t/7327) 1956 4.2 2.51 1922 97.6 2.53   [BNG(卫星图像)](openml.org/t/7326) 334 1.6 0.731 337 10.0 0.721   [COMET_MC](openml.org/t/14949) 44 1.0 0.0615 47 5.0 0.0662   [friedman1](openml.org/t/361939) 275 4.2 1.047 278 5.1 1.487   [扑克](openml.org/t/10102) 38 0.6 0.256 41 1.2 0.722   [subset_higgs](openml.org/t/361955) 868 10.6 0.420 870 24.5 0.421   [BNG(autoHorse)](openml.org/t/7319) 107 1.1 19.0 107 3.2 20.5   [BNG(pbc)](openml.org/t/7318) 48 0.6 836.5 51 0.2 957.1   平均 465 3.9 - 464 19.7 -   PerpetualBooster 在 10 个数据集中的 8 个上均优于 AutoGluon，训练速度同样快，推理速度快 5 倍。可以使用 automlbenchmark fork 此处 重现结果。 Github： https://github.com/perpetual-ml/perpetual   由    /u/mutlu_simsek  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h52zk8/p_perpetualbooster_outperforms_autogluon_on/</guid>
      <pubDate>Mon, 02 Dec 2024 19:12:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 处理图神经网络中不同的输出维度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4uyn9/d_handle_varying_output_dimension_in_graph_neural/</link>
      <description><![CDATA[我有一个关于在训练期间处理图形神经网络 (GNN)中不同输出维度的问题。我正在使用组合图（合并任务和计算图），其中结构类似于任务图，但计算节点信息集成到特征中。由于任务图和计算图（节点数）都可能变化，我使用前馈层将节点和边缘特征转换为固定的超参数嵌入维度。但是，数据集包含具有不同数量计算节点的实例。例如，一个实例 (A) 可能有 5 个计算节点，而另一个实例 (B) 可能有 7 个计算节点。鉴于这是使用 GNN 的调度任务，输出维度必须与计算节点的数量匹配，因为任务被分配给这些节点。我想知道如何处理 GNN 中不同的输出维度，以及是否有任何标准方法来管理这种变化。谢谢！    由   提交  /u/bipulthapa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4uyn9/d_handle_varying_output_dimension_in_graph_neural/</guid>
      <pubDate>Mon, 02 Dec 2024 13:29:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 简化的 RNN 通过并行训练和减少参数实现类似 Transformer 的性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4urpr/r_simplified_rnns_achieve_transformerlike/</link>
      <description><![CDATA[本文系统地研究了 RNN 是否足以完成目前由 Transformer 主导的许多 NLP 任务。研究人员在保持模型大小、训练数据和其他变量不变的情况下，进行了比较 RNN 和 Transformer 的受控实验。 关键技术要点： - 使用匹配的参数在语言建模和 seq2seq 任务上测试了这两种架构（70M-1.5B） - 引入了“具有并行生成的 RNN” （RPG）允许 RNN 像 Transformer 一样并行生成 token - 在包括 WikiText-103 和 WMT14 英德翻译在内的标准基准上进行评估 - 通过探测任务和注意模式分析分析表示能力 主要结果：- RNN 在 WikiText-103 语言建模上匹配或优于类似大小的 Transformer - Transformer 在翻译任务上显示出 1-2 BLEU 分数优势 - RPG 实现了 Transformer 生成速度的 95% 且准确度损失最小 - RNN 表现出更强的局部上下文建模，而 Transformer 擅长长距离依赖 我认为这项工作提出了关于现代 NLP 中架构选择的重要问题。虽然 Transformer 已成为默认设置，但 RNN 可能仍然适用于许多应用程序，尤其是那些专注于局部上下文的应用程序。并行生成技术可以使 RNN 更适用于生产部署。 我认为结果表明我们应该重新考虑特定用例的 RNN，而不是假设 Transformer 总是最佳的。 RNN 的计算效率对于资源受限的应用尤其有价值。 TLDR：综合比较表明，在控制模型大小和训练的情况下，RNN 可以在某些 NLP 任务上与 transformer 匹敌。介绍了 RNN 的并行生成技术。结果表明，架构选择应取决于特定的应用需求。 完整摘要在这里。论文这里    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4urpr/r_simplified_rnns_achieve_transformerlike/</guid>
      <pubDate>Mon, 02 Dec 2024 13:19:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 包含 300 多个生产 LLM 实现的综合数据库，其中包含技术架构详细信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4udds/r_a_comprehensive_database_of_300_production_llm/</link>
      <description><![CDATA[为 ML 从业者分享宝贵的资源：一个新发布的数据库，记录了 300 多个现实世界的 LLM 实现，并提供了详细的技术架构和工程决策。 这个社区可能感兴趣的关键方面：  生产中的检索增强生成 (RAG) 架构 微调决策和性能比较 嵌入策略和矢量数据库实现 模型优化技术和量化方法 评估方法和监控系统  涵盖的值得注意的技术实现：  Anzen 使用 BERT 的文档分类系统（生产准确率为 95%） 巴克莱的 MLOps 演变以实现监管合规性 MosaicML 从培训和部署 MPT Emergent Methods 用于新闻处理的实时 RAG 系统 卡塔尔计算研究所的 T-RAG 架构  技术重点领域：  模型服务架构 训练基础设施决策 延迟优化策略 成本-性能权衡 生产监控方法  每个案例研究包括：  可用的技术架构图 性能指标和基准 实施挑战和解决方案 基础设施决策和基本原理 扩展注意事项  URL：https://www.zenml.io/llmops-database/ 我们还通过提交表单接受生产实施的技术撰写：https://docs.google.com/forms/d/e/1FAIpQLSfrRC0_k3LrrHRBCjtxULmER1-RJgtt1lveyezMY98Li_5lWw/viewform 特别感兴趣的是这个社区对不同规模部署中出现的架构模式的看法。 编辑：我们还将跨领域的技术主题综合到摘要中播客，适合对高级模式感兴趣的人。 编辑：随附的博客综合了许多学习内容： https://www.zenml.io/blog/demystifying-llmops-a-practical-database-of-real-world-generative-ai-implementations    提交人    /u/htahir1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4udds/r_a_comprehensive_database_of_300_production_llm/</guid>
      <pubDate>Mon, 02 Dec 2024 12:58:02 GMT</pubDate>
    </item>
    <item>
      <title>[P]Levenberg-Marquardt训练算法的PyTorch实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4ubbd/p_pytorch_implementation_of_levenbergmarquardt/</link>
      <description><![CDATA[大家好， 如果有人感兴趣，这里有一个我开发的 Levenberg-Marquardt (LM) 算法的 PyTorch 实现。 GitHub Repo：torch-levenberg-marquardt 一个 Levenberg-Marquardt (LM) 优化算法的 PyTorch 实现，支持针对回归和分类问题的小批量训练。它利用 GPU 加速并提供可扩展的框架，支持不同的损失函数和可定制的阻尼策略。 TensorFlow 实现也可用：tf-levenberg-marquardt 安装 pip install torch-levenberg-marquardt     提交人    /u/fabiodimarco   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4ubbd/p_pytorch_implementation_of_levenbergmarquardt/</guid>
      <pubDate>Mon, 02 Dec 2024 12:54:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] RuleOpt v.1.1：基于优化的分类规则学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4tzd0/r_ruleopt_v11_optimizationbased_rule_learning_for/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2104.10751 软件包： https://github.com/sametcopur/ruleopt 文档： https://ruleopt.readthedocs.io/ RuleOpt 是一种基于优化的规则学习算法，专为分类问题而设计。RuleOpt 注重可扩展性和可解释性，利用线性规划进行规则生成和提取。 Python 库 ruleopt 能够从集成模型中提取规则，并且还实现了一种新颖的规则生成方案。该库确保与现有的机器学习管道兼容，并且对于解决大规模问题特别有效。 以下是ruleopt的一些亮点：  高效的规则生成和提取：利用线性规划进行可扩展的规则生成（独立的机器学习方法）以及从训练有素的随机森林和增强模型中提取规则。 可解释性：通过为规则分配成本来优先考虑模型透明度，以实现与准确性的理想平衡。 与机器学习库集成：促进与知名的Python库scikit-learn，LightGBM和XGBoost以及现有的机器学习管道的顺利集成。 广泛的求解器支持：支持各种求解器，包括Gurobi，CPLEX和OR-Tools。  通过最新版本的更新，RuleOpt 现在即使使用免费求解器 OR-Tools 也很快，即使在大型数据集上也是如此！在下图中，您可以看到新版本与以前版本相比在运行时间方面的表现。 Training Times v1.0 vs v1.1 我们很乐意听到您的反馈、问题或您可能有的任何其他疑问！    提交人    /u/zedeleyici3401   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4tzd0/r_ruleopt_v11_optimizationbased_rule_learning_for/</guid>
      <pubDate>Mon, 02 Dec 2024 12:36:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 特征生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4qwt4/r_feature_generation/</link>
      <description><![CDATA[      我提前为一个可能很愚蠢的问题道歉。 我正在尝试复制一篇研究论文，其中一些 ML 模型已经过训练以对金属切削刀具进行状态监测，所以我的问题是关于特征生成的。 假设我有一个包含 6 个信号（特征）的数据框，行是测量值在某个时间。要生成一个新特征，比如 RMS 值，我只需要进行 6 次测量并计算每行 6 个数字的 RMS 值？这会是我的新功能吗？ 谢谢。 https://preview.redd.it/dsjfcapthe4e1.png?width=560&amp;format=png&amp;auto=webp&amp;s=b22c007b2d2a73612280d0ecfa6556b68b793a17    提交人    /u/su_25_frogfoot   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4qwt4/r_feature_generation/</guid>
      <pubDate>Mon, 02 Dec 2024 09:04:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对于布局复杂的 PDF，最佳的分块方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4pkmh/r_best_chunking_method_for_pdfs_with_complex/</link>
      <description><![CDATA[我正在开发一个基于 RAG 的 PDF 查询系统，专门用于包含多列表、图像、跨多页的表格、包含图像的表格的复杂 PDF。 我想为此类 PDF 找到最佳分块策略。 目前我正在使用 RecursiveCharacterTextSplitter。对于复杂的 PDF，你们觉得哪种方法最有效？    提交人    /u/ElectronicHoneydew86   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4pkmh/r_best_chunking_method_for_pdfs_with_complex/</guid>
      <pubDate>Mon, 02 Dec 2024 07:24:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在 AWS Sagemaker 中对 DeepAR 框架进行查询</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4gwxy/r_queries_on_deepar_framework_in_aws_sagemaker/</link>
      <description><![CDATA[嗨， 我正在尝试为各种商店实施 deepAr 以预测未来的销售情况（每家商店有约 10k 个不同产品的 SKU）。由于 SKU 的规模庞大，我无法一次性对所有数据进行单次训练。我正在考虑按商店进行训练。  如何在 AWS 中并行进行训练？每个商店的训练过程最多需要 30 分钟； 如何处理数据中不存在的看不见的 SKU？  谢谢。    提交人    /u/skw1990   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4gwxy/r_queries_on_deepar_framework_in_aws_sagemaker/</guid>
      <pubDate>Sun, 01 Dec 2024 23:33:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人思人工智能研究员/住院医师——接受任何新毕业生/入门级人员吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4e0ah/d_anthropic_ai_fellowresidents_any_new/</link>
      <description><![CDATA[你好。入门级或新毕业生是否可以进入 Anthropic 奖学金或住院医师项目？过去被录取的人，你的简历和经历是什么样的？    提交人    /u/geekgeek2019   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4e0ah/d_anthropic_ai_fellowresidents_any_new/</guid>
      <pubDate>Sun, 01 Dec 2024 21:25:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何处理图神经网络训练中不同的特征维度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4dbvi/d_how_to_handle_varying_feature_dimensions_in/</link>
      <description><![CDATA[我有一个关于在图形神经网络训练中处理具有不同特征维度的数据集的问题。例如，在一个训练实例（我们称之为数据集 A）中，节点特征的维度为 4，边特征的维度为 16。在另一个实例（数据集 B）中，节点特征的维度为 5，边特征的维度为 25。其他数据集也可能具有不同的特征维度。 在使用此类数据集训练 GNN 模型时，用于处理每个实例的不同特征维度的标准方法是什么？我将不胜感激任何有关如何处理此问题的指导或方向。谢谢！    提交人    /u/bipulthapa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4dbvi/d_how_to_handle_varying_feature_dimensions_in/</guid>
      <pubDate>Sun, 01 Dec 2024 20:57:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] Promptwright - 使用 LLM（本地或托管）生成大型合成数据集的开源项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4bcz2/p_promptwright_open_source_project_to_generate/</link>
      <description><![CDATA[嘿 r/machinelearning， Promptwright，一个免费使用的开源工具，旨在使用本地大型语言模型或众多托管模型（OpenAI、Anthropic、Google Gemini 等）之一轻松生成合成数据集 主要特点： * 支持多个 LLM 提供商：通过 Ollama、VLLM 等与大多数 LLM 服务提供商和 LocalLLM 配合使用 * 可配置的说明和提示：通过脚本在 YAML 中定义自定义说明和系统提示，与以前一样。 * 命令行界面：直接从命令行运行生成任务 * 推送到 Hugging Face：使用自动数据集卡和标签将生成的数据集推送到 Hugging Face Hub 这是在最新版本上使用 promptwright 创建的示例数据集： https://huggingface.co/datasets/stacklok/insecure-code/viewer 这是使用“mistral-nemo:12b”从以下模板生成的，但老实说，大多数模型都能很好地执行，即使是小型 1/3b 模型也是如此。 system_prompt：“您是编程助理。您的任务是生成不安全代码的示例，突出显示漏洞，同时保持准确的语法和行为。” topic_tree： args： root_prompt：“跨多语言编程语言的不安全代码示例。” model_system_prompt: &quot;&lt;system_prompt_placeholder&gt;&quot; # 将被 system_prompt 替换 tree_degree: 10 # 广泛覆盖语言（例如 Python、JavaScript、C++、Java） tree_depth: 5 # 特定漏洞的深度层次结构（例如 SQL 注入、XSS、缓冲区溢出）temperature: 0.8 # 高度创造力以多样化示例 provider: &quot;ollama&quot; # LLM 提供者 model: &quot;mistral-nemo:12b&quot; # 模型名称 save_as: &quot;insecure_code_topictree.jsonl&quot; data_engine: args: instructions: &quot;用多种编程语言生成不安全的代码示例。每个示例都应包括对漏洞的简要说明。&quot; system_prompt: &quot;&lt;system_prompt_placeholder&gt;&quot; # 将被 system_prompt 替换 provider: &quot;ollama&quot; # LLM 提供程序 model: &quot;mistral-nemo:12b&quot; # 模型名称temperature: 0.9 # 鼓励示例中的多样性max_retries: 3 # 最多重试 3 次失败提示dataset:creation:num_steps: 15 # 在 10 次迭代中生成示例batch_size: 10 # 每次迭代生成 5 个示例provider: &quot;ollama&quot; # LLM 提供程序model: &quot;mistral-nemo:12b&quot; # 模型名称sys_msg: true # 在数据集中包含系统消息（默认值：true）save_as: &quot;insecure_code_dataset.jsonl&quot; # Hugging Face Hub 配置（可选）huggingface: # 格式为&quot;username/dataset-name&quot;的存储库repository: &quot;hfuser/dataset&quot; # 也可以通过 HF_TOKEN 环境变量或 --hf-token CLI 选项提供令牌 token: &quot;$token&quot; # 数据集的附加标签（可选） # &quot;promptwright&quot; 和 &quot;synthetic&quot; 标签会自动添加 tags: - &quot;promptwright&quot;  我们已在内部将它用于一些项目，效果非常好。您可以处理数千个样本，而不必担心 API 成本或速率限制。此外，由于一切都在本地运行，您不必担心敏感数据离开您的环境。 代码是 Apache 2 许可的，我们很乐意收到社区的反馈。如果您正在为 ML 进行任何类型的合成数据生成，请尝试一下并告诉我们您的想法！ 链接： 查看 examples 文件夹，获取生成代码、科学或创意 ewr 的示例 非常乐意听到您的想法和建议，如果您发现任何改进空间，请随时提出和发布或发出拉取请求。    提交人    /u/zero_proof_fork   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4bcz2/p_promptwright_open_source_project_to_generate/</guid>
      <pubDate>Sun, 01 Dec 2024 19:33:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 01 Dec 2024 16:00:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>