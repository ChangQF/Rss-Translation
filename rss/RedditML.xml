<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Thu, 07 Mar 2024 06:18:51 GMT</lastBuildDate>
    <item>
      <title>[D] Apollo：轻量级多语言医学法学硕士，将医疗人工智能普及到 6B 人群</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8mml6/d_apollo_lightweight_multilingual_medical_llms/</link>
      <description><![CDATA[    &lt; /a&gt;  我们开源了一系列SOTA轻量级多语言医疗LLM Apollo (0.5B, 1.8B, 2B, 6B, 7B)，利用非翻译语料库取得最佳新表现 覆盖英文、中文、法语、西班牙语、阿拉伯语和印地语  整个过程开源且可复制 精简版模型可以是用于提高大型模型的多语言医疗能力无需以代理调整方式进行微调   github：https://github.com/FreedomIntelligence/Apollo 演示：https://apollo.llmzoo.com/#/ 论文：https ://arxiv.org/abs/2403.03640 模型：https://huggingface.co /FreedomIntelligence/Apollo-7B  https://preview.redd.it/29kjdct4oumc1.png?width=1488&amp;format=png&amp;auto=webp&amp;s=1a16bbbf2588fb071ba2af5a50668ca8335c 92b7 https://preview.redd.it/406m28t4oumc1.png?width=1120&amp; ;format=png&amp;auto=webp&amp;s=607664035b62aa0ee726d3f5b4c4730863823bcb https://preview.redd.it/jiewd5t4oumc1.png?width=1242&amp;format=png&amp;auto=webp&amp;s=e059d49da4e788729b134b0d64415bcf 85bb024c    由   提交 /u/Pasu06   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8mml6/d_apollo_lightweight_multilingual_medical_llms/</guid>
      <pubDate>Thu, 07 Mar 2024 05:33:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] Nvidia Tesla P40 与 Mangio-RVC-Fork 配合良好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8ka8a/d_nvidia_tesla_p40_works_great_with_mangiorvcfork/</link>
      <description><![CDATA[正在寻找一种经济高效的方式来训练语音模型，在 eBay 上以 150 美元左右的价格购买了一台二手 Nvidia Tesla P40 和一个 3D 打印冷却器我交叉手指。系统只是我的一台带有 B250 Gaming K4 主板的旧电脑，没什么特别的，在 Windows 10 上运行得很好，并且在 Mangio-RVC-Fork 上以惊人的速度进行训练。它有 24GB 的 vram，因此您可以加载大型数据集并提高批量大小。使用默认设置，我在 rmvpe 上用 35 分钟的数据集训练了一个语音，批量大小为 12（仅使用大约 10GB 的 vram），纪元时间约为 1 分 30 秒。结合较大的 vram 净空，我认为更多的人应该尝试 RVC！性价比无与伦比！   由   提交/u/Remote_Hunt516  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8ka8a/d_nvidia_tesla_p40_works_great_with_mangiorvcfork/</guid>
      <pubDate>Thu, 07 Mar 2024 03:33:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 使用矢量数据库比较天气事件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8h6a7/d_p_compare_weather_events_using_vector_database/</link>
      <description><![CDATA[我正在努力寻找类似的风暴，为此我使用动态时间扭曲来计算阵风和降水率等参数的距离。我想知道是否有更有效的方法来将天气预报与过去的风暴进行比较。我可以制作风暴的矢量数据库，嵌入它们，矢量化它们，然后根据距离计算相似度吗？如果可以，该怎么做。我可以从哪里开始？    由   提交/u/Swimming_Expert5750   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8h6a7/d_p_compare_weather_events_using_vector_database/</guid>
      <pubDate>Thu, 07 Mar 2024 01:10:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我通过蒙特卡罗树搜索得到了不同的结果，我希望有人能提供一些线索。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8g7ys/d_im_getting_different_results_with_monte_carlo/</link>
      <description><![CDATA[嗨， 我正在为 Flesh and Blood 创建一个 MCTS 实现，它是一张交易卡。它似乎运行良好，即相当快。然而，我最近观察到一些奇怪的事情。我认为这是一个错误，但我想我应该联系一下，以防万一 MCTS 是如何工作的，如果是这样，最好有一个解释。 我可以选择以两种模式运行 MCTS：高效模式和低效模式。例如，考虑以下操作流程：开始游戏、开始回合、抽牌、开始阶段、[玩牌 1、玩牌 2]。 低效模式会将每个操作映射到一个节点：node1 ：开始游戏-&gt; StartTurn，节点2：StartTurn -&gt;抽卡，.... 高效模式将所有单个操作折叠为一个操作，因此“开始游戏”到“开始阶段”都将被执行，我们将拥有：node1：开始游戏-&gt; [Play Card 1、Play Card 2] 折叠它们的好处是我们不需要继续复制游戏状态。 但是，我看到的是高效模式返回的获胜次数几乎是低效模式的两倍。这是可能的，因为 MCTS 的工作方式，还是我怀疑它是一个错误。   由   提交/u/Annual_Asspiration_21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8g7ys/d_im_getting_different_results_with_monte_carlo/</guid>
      <pubDate>Thu, 07 Mar 2024 00:28:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 训练机器学习模型来识别含金石英岩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8etsl/d_training_an_ml_model_to_recognize_goldbearing/</link>
      <description><![CDATA[如何使用 Tensor Flow 训练 ML 模型来识别可能含有黄金的石英岩？ 一般来说，您想要“丑陋”的石英，石英的白色部分周围是破碎的、棕色和灰色的。 就属性而言，这可以在概念上建模如下： rock_type：石英 rock_texture：破碎 rock_colors：[棕色，灰色] rock_characteristics：[破碎，棕色，灰色] 我可以很容易地为此组装一个训练图像数据集。 创建一种机器学习算法是否很难，该算法可以输入数百或数千张含金石英矿石的图像，并预测哪些岩石更有可能含有最多的黄金？ 实现这一目标的步骤是什么？ 再说一次，我是一个新手，所以我不确定我是否正确地表达了我的问题. 谢谢您，祝您有美好的一天。   由   提交 /u/PickAxeCA   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8etsl/d_training_an_ml_model_to_recognize_goldbearing/</guid>
      <pubDate>Wed, 06 Mar 2024 23:28:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 比较决定系数与相关 R 平方值</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8en8p/d_compare_coefficient_of_determination_vs/</link>
      <description><![CDATA[寻求方法比较方面的帮助。 对于 100 个基因，我创建了一个模型来预测每个基因的表达（总共 100 个模型）。我执行了 k 倍交叉验证来计算决定系数 R 平方值，并将这些值聚合起来以获得每个模型 1，然后计算这些值的平均值和中位数。 我想要看看这与另一种方法相比如何，但该方法是计算得分（不是回归或 ML），因此我计算了 100 个基因中每个基因的相关系数 R 平方值，然后计算这些基因的平均值和中位数 因为我的 ML 模型的决定系数 R 平方值可能为负，并且计算得分的相关系数 R 平方值范围为 0 到 1，所以我不知道是否直接比较这些 R 平方值是有意义的。有人对如何比较它们有建议吗？将确定系数 R 平方值转换为 0 到 1 的范围是否有意义？   由   提交 /u/Br0wnish   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8en8p/d_compare_coefficient_of_determination_vs/</guid>
      <pubDate>Wed, 06 Mar 2024 23:20:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] Azure GPU 限制？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8e8yy/d_azure_gpu_restrictions/</link>
      <description><![CDATA[刚刚请求增加 a100 图像的配额，他们说 GPU 需求太高。想知道其他人是否遇到过这个问题，如果是的话，您是如何解决的？租用 GPU 应该不会这么困难......    由   提交 /u/Primary-Track8298    reddit.com/r/MachineLearning/comments/1b8e8yy/d_azure_gpu_restrictions/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8e8yy/d_azure_gpu_restrictions/</guid>
      <pubDate>Wed, 06 Mar 2024 23:05:01 GMT</pubDate>
    </item>
    <item>
      <title>[D]苹果ANE性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8dyq3/d_apple_ane_performance/</link>
      <description><![CDATA[是否有已发布的 ANE 在各种流行视觉基准（resnet 50、yolo）上的推理性能基准？还有关于功耗和/或效率的已发表研究吗？   由   提交/u/Dry-Significance-821   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8dyq3/d_apple_ane_performance/</guid>
      <pubDate>Wed, 06 Mar 2024 22:54:01 GMT</pubDate>
    </item>
    <item>
      <title>非文本数据的 LLM 微调 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8dp7t/finetuning_llm_on_nontext_data_discussion/</link>
      <description><![CDATA[嗨， 是否可以在非文本数据上训练大型语言模型。我可以将其应用于任何顺序数据集（例如音符）吗？我认为棘手的部分是对数据集进行标记，以便法学硕士可以更好地理解数据的底层结构。如果预训练的 LLMS 不是正确的方法，您能否建议任何其他预训练的模型？我试图解决的问题需要预测离散值，因此我认为使用音频生成模型没有意义。我不喜欢从头开始训练，所以只是想知道。另外，如果我的直觉不对，请告诉我。 谢谢！   由   提交 /u/Dunkeyfunkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8dp7t/finetuning_llm_on_nontext_data_discussion/</guid>
      <pubDate>Wed, 06 Mar 2024 22:43:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 NLP 分类数据集中查找潜在不良标签的技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8adyu/d_techniques_for_finding_potentially_bad_labels/</link>
      <description><![CDATA[我正在寻找在 NLP 分类数据集中查找潜在不良标签的技术。我们一直在使用 Cleanlab（自信学习），但我们发现对于我们的用例（内容审核/媒体监控）来说，精确度/召回率不是很高。您有其他有趣的技术/论文的指导吗？ GPT-4 等人。当您花费足够的时间编写描述性提示时，它是一个不错的选择，但它的代价是规模庞大。对更智能的“预选”感到好奇技术而不是把一切都扔给 GPT？    由   提交 /u/IbrahimSharaf   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8adyu/d_techniques_for_finding_potentially_bad_labels/</guid>
      <pubDate>Wed, 06 Mar 2024 20:32:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 逆转诅咒</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b86vgt/d_the_reversal_curse/</link>
      <description><![CDATA[https://arxiv.org/pdf/2309.12288 .pdf 原来我预测了 2021 年的逆转诅咒哈哈 https://www.reddit.com/r/MachineLearning/comments/p13ean/d_can_gpt_generalize_in_both_directions/ 编辑：第一篇论文引用的另一篇论文甚至使用了非常相似的示例： https://arxiv.org/pdf/2308.03296.pdf &lt; blockquote&gt; 美国第一任总统是乔治·华盛顿  如果我的帖子以任何方式启发作者，我会非常高兴 &lt; !-- SC_ON --&gt;  由   提交 /u/DeMorrr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b86vgt/d_the_reversal_curse/</guid>
      <pubDate>Wed, 06 Mar 2024 18:16:43 GMT</pubDate>
    </item>
    <item>
      <title>[D][R]强化学习的最新进展</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b81pkt/drrecent_developments_in_reinforcement_learning/</link>
      <description><![CDATA[我正在尝试进入强化学习领域，并且刚刚完成了 Sutton 和 Barto 的课程以及 YT 的一门课程。只是想知道目前在这个主题上正在做什么（调查论文/书会很好）。还想知道常用的数据集类型。我学习的课程本质上是完全理论性的，所以我也想知道目前这个领域使用什么工具包。   由   提交/u/ANI_phy  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b81pkt/drrecent_developments_in_reinforcement_learning/</guid>
      <pubDate>Wed, 06 Mar 2024 14:56:18 GMT</pubDate>
    </item>
    <item>
      <title>[D]为什么 Hugging Face 没有成为桌面上最有前途（且年轻）的 AI 聊天机器人玩家之一（如 Mistral AI、Anthropic、Perplexity AI 等）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b7t35y/dwhy_isnt_hugging_face_becoming_one_of_the/</link>
      <description><![CDATA[我记得几年前人们讨论HF的商业模式是什么或者如何盈利。 我认为现在是对他们来说这是最好的时代，但我有点惊讶他们没有创造自己的时代。 他们有才华、经验和资源。只是想知道。   由   提交 /u/xiikjuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b7t35y/dwhy_isnt_hugging_face_becoming_one_of_the/</guid>
      <pubDate>Wed, 06 Mar 2024 06:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 2023年300+ML比赛分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b79bqq/r_analysis_of_300_ml_competitions_in_2023/</link>
      <description><![CDATA[      我运行 mlcontests.com，这是一个网站列出了跨多个平台的 ML 竞赛，包括 Kaggle/DrivenData/AIcrowd/CodaLab/Zindi/EvalAI/… 我刚刚完成了对 300 多个 ML 竞赛的详细分析2023 年，包括查看其中 65 个获奖解决方案。 一些亮点：  正如预期的那样，几乎所有获奖者都使用 Python 。一名获胜者使用 C++ 解决性能至关重要的优化问题，另一名获胜者使用 R 进行时间序列预测竞赛。 92% 的深度学习解决方案使用 PyTorch。我们发现剩下的 8% 使用了 TensorFlow，并且所有这些都使用了更高级别的 Keras API。大约 20% 的获胜 PyTorch 解决方案使用 PyTorch Lightning。 基于 CNN 的模型比基于 Transformer 的模型赢得更多计算机视觉竞赛。 在 NLP 领域，毫不奇怪，生成式法学硕士开始被使用。一些竞赛获胜者使用它们来生成用于训练的合成数据，其他人则提出了创造性的解决方案，例如向开放权重法学硕士添加分类头并对其进行微调。还有更多专门针对 LLM 微调的竞赛正在推出。 与去年一样，梯度增强决策树库（LightGBM、XGBoost 和 CatBoost）仍然被广泛使用 由竞赛获胜者评选。 LightGBM 比其他两者稍微流行一些，但差异很小。 计算使用情况差异很大。 NVIDIA GPU 显然很常见；一些获奖者使用了 TPU；我们没有发现任何使用 AMD GPU 的获胜者；有些人仅在 CPU 上训练他们的模型（尤其是时间序列）。一些获奖者通过工作/大学获得了强大的（例如 8x A6000/8x V100）设置，一些获奖者在本地/个人硬件上进行了全面培训，相当多的获奖者使用了云计算。 有相当多的高- 2023 年的概况竞赛（我们详细介绍维苏威火山挑战赛和M6 预测），以及 2024 年即将举办的更多比赛（维苏威火山挑战赛第二阶段、AI 数学奥林匹克、AI 网络挑战赛） )  有关更多详细信息，请查看完整报告：https://mlcontests.com/state-of-competitive-machine-learning-2023?ref=mlc_reddit ​ 获奖者中最常用的一些 Python 软件包&lt; /p&gt; 在我的 r/MachineLearning 帖子中 去年关于 2022 年比赛的相同分析，热门评论之一询问了时间序列预测。 2023 年有几个有趣的时间序列预测竞赛，我设法对它们进行了相当深入的研究。跳至报告的此部分以了解这些内容。 （不同类型的时间序列竞赛的获胜方法有很大差异 - 包括 ARIMA 等统计方法、贝叶斯方法，以及 LightGBM 和深度学习等更现代的 ML 方法。） 我能够花费相当多的时间感谢今年报告的赞助商：Latitude.sh（配备专用 NVIDIA H100/A100/L40s GPU 的云计算提供商）和 Comet（有用的工具），我们花费了大量时间进行研究和撰写用于 ML - 实验跟踪、模型生产监控等）。我不会在这里向您发送垃圾邮件链接，报告底部有更多详细信息！   由   提交 /u/hcarlens   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b79bqq/r_analysis_of_300_ml_competitions_in_2023/</guid>
      <pubDate>Tue, 05 Mar 2024 16:22:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>