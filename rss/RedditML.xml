<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 03 Oct 2024 15:18:25 GMT</lastBuildDate>
    <item>
      <title>图表征学习 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fv8cnc/graph_representation_learning_p/</link>
      <description><![CDATA[我们开发了一个图形表示学习模型，可以预测静态知识图中节点之间的链接。您将如何修改此模型以纳入数据的时间成分？可能会出现哪些特定的工程挑战？    提交人    /u/Accomplished_Lake982   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fv8cnc/graph_representation_learning_p/</guid>
      <pubDate>Thu, 03 Oct 2024 13:56:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您对机器学习中的（高质量）内容创作有何看法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fv8429/d_what_are_your_thoughts_on_quality_content/</link>
      <description><![CDATA[我意识到，要成长为 MLE/数据科学家，甚至成为整体 IT 专业人士，成为拥有丰富经验和知识的最佳技术人员不会增加您的价值。有很多人进入了内容创作领域，例如 YouTube/X/podcasts/instagram 等。它似乎双向起作用，通过建立受众并向作者阐明主题。同样，一个人在进入内容创作领域之前可能是一个知名人物，比如 Andrej Karpathy，或者从头开始添加有价值的内容的人。所以我要说的是，考虑到一个人准备好耐心等待病毒式传播的门槛，内容创作似乎是职业加速的必需品。这里是对我来说最重要的一点，那就是创造力。让它变得有趣很容易引起注意。  这个问题已经萦绕在我脑海里有一段时间了，很想知道你的想法。原谅任何语法错误。谢谢🫂   由    /u/Particular_Tap_4002  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fv8429/d_what_are_your_thoughts_on_quality_content/</guid>
      <pubDate>Thu, 03 Oct 2024 13:45:10 GMT</pubDate>
    </item>
    <item>
      <title>[P] 更大、更易于指导的语言模型变得不那么可靠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fv4hxo/p_larger_and_more_instructable_language_models/</link>
      <description><![CDATA[      《自然》杂志上的一篇非常有趣的论文，后面是其中一位作者对 X 的摘要。 结论基本上是使用更多的计算资源和人类反馈训练的大型模型在几个方面对人类的可靠性会降低，例如，模型可以解决非常困难的任务，但在同一领域中无法解决许多简单的任务，并且这种不一致对于较新的模型来说变得越来越严重（基本上即使是简单的任务也无法实现无错误，而且人类越来越难以预测模型失败？）。论文还表明，较新的 LLM 现在更少地回避任务，从而导致更多错误/幻觉输出（这颇具讽刺意味：所以 LLM 变得更加正确，但同时也变得更加错误）...... 我很好奇，他们表明快速工程不会通过简单地扩大模型规模而消失，因为较新的模型只是在逐步改进，而人类不善于发现输出错误以抵消不可靠性。GPT、LLAMA 和 BLOOM 系列的 32 个 LLM 的结果似乎一致，并且在 X-thread 中，他们还表明不可靠性仍然存在于其他非常新的模型中，如 o1-preview、o1-mini、LLaMA-3.1-405B 和 Claude-3.5-Sonnet。这里有很多东西需要解开。但有趣的是，这项工作在某些方面挑战了当前的扩展范式，值得关注。 https://preview.redd.it/hpd7yynaqisd1.png?width=1888&amp;format=png&amp;auto=webp&amp;s=ebc7953700935ee85cafd2f5d3602b80418d4523    提交人    /u/Appropriate_Annual73   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fv4hxo/p_larger_and_more_instructable_language_models/</guid>
      <pubDate>Thu, 03 Oct 2024 10:26:40 GMT</pubDate>
    </item>
    <item>
      <title>[D]在 preprints.org 上发表的论文有多大意义？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fv3vj1/dhow_much_significance_is_given_to_papers/</link>
      <description><![CDATA[标题可能有点令人困惑，但看起来 preprints.org 没有强大的审核系统。在这样的地方提交论文有什么好处吗？我对这个领域还很陌生。所以，也许像 preprints.org 这样的地方可以提供一些我不知道的帮助？    提交人    /u/Uziii-Boiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fv3vj1/dhow_much_significance_is_given_to_papers/</guid>
      <pubDate>Thu, 03 Oct 2024 09:40:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从 AWS 到本地提供商：如何降低 AI 培训费用❗</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fuyse4/d_from_aws_to_local_providers_how_to_lower_ai/</link>
      <description><![CDATA[任何深入学习过 LLM 培训的人都知道，找到一个不会耗尽预算的 GPU 设置非常困难。经过多次反复尝试，我得出了以下几个结论： 1. 云提供商 方便、可扩展且快速。但说实话，如果 GPU 使用量很大，这些成本会飙升，而且您还需要支付存储和数据传输费用。 2. DIY 基础设施 我以为构建自己的集群会更具成本效益。但是，如果考虑到冷却、维护和设备问题，会浪费大量时间，除非您有专门的团队。 3. 本地 GPU 提供商 这一点让我很惊讶。本地设置可以提供可靠的性能，成本仅为云成本的一小部分，而无需长期投入 DIY。它并不完美，但却是一个不错的中间立场。 我的想法？ 云适合短期项目或原型设计。DIY 适合那些想要完全控制（并愿意忍受麻烦）的人。本地 GPU 提供商？如果您正在寻找更好的性价比平衡而又不想带来额外的麻烦，那么他们很有潜力。 想知道您的设置和体验——哪些对您有用（或失败）？ 如果您对每个选项的详细成本明细感兴趣，请查看完整文章这里。很想听听您的想法！    提交人    /u/SquirrelEffective   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fuyse4/d_from_aws_to_local_providers_how_to_lower_ai/</guid>
      <pubDate>Thu, 03 Oct 2024 03:34:29 GMT</pubDate>
    </item>
    <item>
      <title>[P] Paper Central，第一个将所有关键来源集中在一个地方的门户网站，包括 arXiv、Hugging Face 论文页面、GitHub 和会议记录。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fuy2qk/p_paper_central_first_portal_to_bring_together/</link>
      <description><![CDATA[Hugging Face 今天推出了 Paper Central，提供有关最新研究论文的最及时信息。 应用程序：https://huggingface.co/spaces/huggingface/paper-central 帖子：https://x.com/IAMJBDEL/status/1841627341195510256    提交人    /u/Illustrious_Row_9971   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fuy2qk/p_paper_central_first_portal_to_bring_together/</guid>
      <pubDate>Thu, 03 Oct 2024 02:54:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 即时实现：在运行时实现代码的 Python 库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fujbuz/p_justintime_implementation_a_python_library_that/</link>
      <description><![CDATA[嘿 r/MachineLearning ！ 你知道我们是如何进行即时编译的吗？好吧，我想，“为什么要停在那里？”所以我创建了即时实现 - 一个使用 AI 为您编写代码的 Python 库。是的，真的！ 以下是它可以做的事情： 从 jit_implementation 导入实现 @implement class Snake：“pygame 中的贪吃蛇游戏。初始化将启动游戏。”“” if __name__ == “__main__”: Snake() # 信不信由你，这确实有效！  我一开始只是开个玩笑，但后来我有点得意忘形，真的让它工作了。现在我不知道我应该感到骄傲还是害怕。 工作原理：  您编写一个函数或类签名和一个文档字符串。 您将 @implement 装饰器贴在上面。 当您调用函数或实例化类时，将按需生成实现。最好的懒惰编码！  一些“功能”让我特别感兴趣：  它是终极懒惰编程工具。代码在您运行之前甚至不存在！ 您可以在装饰器中定义测试，AI 会不断尝试，直到通过测试。这就像有一个永不睡觉的实习生！ 将采样温度设置为 0，它比 Docker 镜像更具可重复性。 足够聪明，可以浏览代码以了解上下文，但又不会愚蠢到读完所有内容。  您应该在生产中使用它吗？ 只有当您想让您的高级开发人员心脏病发作时才使用。但是，嘿，我不是来评判的。 想看看吗？ 这是 GitHub 存储库：JIT 实现 请随意加星标、分叉，或者只是指出并大笑。所有反应都是有效的！ 我很想听听你的想法。这是编程的未来还是我需要休长假的迹象？也许两者都有？ 附言：如果你们当中有人真的用过这个，请告诉我。我真的很想知道用这个可以制作出多么复杂的代码库（或者缺乏代码库）。 重要说明 我只用了不到 4 个小时就完成了整个过程，所以请保持你的期望！（它处于测试阶段）    提交人    /u/JirkaKlimes   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fujbuz/p_justintime_implementation_a_python_library_that/</guid>
      <pubDate>Wed, 02 Oct 2024 15:44:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 NotebookLM + Daily Medical AI Papers 进行实验：完美组合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fugsec/d_experiment_with_notebooklm_daily_medical_ai/</link>
      <description><![CDATA[      我们正在努力让我们的医学 AI/LLM 更新更具吸引力，更容易理解！ 我们已经收到了大量对我们的每日医疗 AI 论文。除了书面摘要外，我们还很高兴地宣布发布视频播客版本，您可以在工作、通勤甚至早上散步时欣赏。 🤗 查看我们的第一篇论文视频播客🔥 哈佛大学演讲 - ReXplain：将放射学转化为患者友好的视频报告 这里还有 YouTube 链接 https://www.youtube.com/watch?v=vZEAiYDNoME 哈佛大学演讲 - ReXplain：将放射学转化为患者友好的视频报告 每日新医学 AI 论文:)    由    /u/aadityaura 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fugsec/d_experiment_with_notebooklm_daily_medical_ai/</guid>
      <pubDate>Wed, 02 Oct 2024 13:56:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您的 LLM 聊天机器人有多安全？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fufrd1/d_how_safe_are_your_llm_chatbots/</link>
      <description><![CDATA[大家好，我一直在解决基于 LLM 的聊天机器人护栏的安全问题。 随着组织越来越依赖 Copilot 或 Gemini 等工具来创建内部聊天机器人，保护这些 LLM 并管理适当的授权至关重要。 当这些系统汇总和解释大量组织知识时，就会出现问题，这可能导致暴露超出员工授权访问权限的敏感信息。 在管理简单的应用程序时，管理授权很简单。您可以限制用户仅查看允许他们查看的内容。但在 RAG 系统中，这变得很棘手。 例如，如果员工询问 &quot;过去两分钟内哪些服务失败了？&quot; 一个简单的 RAG 实现可以提取所有可用的日志数据，绕过任何访问控制并可能泄露敏感信息。 您在组织中是否面临这种挑战，或者您如何应对？    提交人    /u/ege-aytin   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fufrd1/d_how_safe_are_your_llm_chatbots/</guid>
      <pubDate>Wed, 02 Oct 2024 13:07:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 学术不端行为调查 ICLR 2024 焦点：自适应理性激活以促进深度强化学习。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fuf5b2/r_academic_misconduct_investigation_into_iclr/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fuf5b2/r_academic_misconduct_investigation_into_iclr/</guid>
      <pubDate>Wed, 02 Oct 2024 12:37:17 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 您使用什么资源来了解最新的 ML 研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fu7gls/discussion_what_resource_do_you_use_to_keep_up_to/</link>
      <description><![CDATA[在我的日常工作中，我致力于推荐和搜索系统，我发现很难跟上与我的工作相关的最新发展。我可以抽出时间每周阅读一篇新论文（除非它直接用于我的工作），但从噪音中分离出信号是最困难的部分。我很好奇其他人如何选择和找到与您的特定领域相关的论文、博客文章或文章来阅读？    提交人    /u/PurpleAnnieOwl   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fu7gls/discussion_what_resource_do_you_use_to_keep_up_to/</guid>
      <pubDate>Wed, 02 Oct 2024 03:56:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 处理纸质复制品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fu1n9y/r_dealing_with_paper_reproductions/</link>
      <description><![CDATA[大家好，我目前是计算机视觉专业的一年级博士生，在小组会议期间，我在论文复现方面遇到了一些挑战。我面临的问题是，我复现的论文通常是其他论文的扩展，而这些论文又建立在更早的工作之上。当我展示我的结果时，我的导师经常会问很多详细的问题，有时是关于模型的历史或更详细的细节，我很容易感到困惑。 我通常没有时间在一周内回顾并完全理解旧论文中的数学或优化（我选修了 3 门研究课程），当我被要求解释它们时，我会感到不知所措。有时，我说得太多或太少，事后感到尴尬。问题是，我对这个话题真的很感兴趣，但在复现这些模型时，我没有时间深入研究每个方面，尽管我在会议结束后研究了这些片段。有没有其他人遇到过类似的事情？  您如何处理具有长扩展链的复现论文？例如，从头开始训练（docker 镜像不可用的情况） 当您只对旧工作有表面了解时，您如何处理会议/演示中的详细技术问题？ 在复现结果和微调模型时，有什么技巧可以平衡理解和时间管理？  我很欣赏您的想法或您在这种情况下发现有用的策略。提前谢谢您！    提交人    /u/Cool-Economy3492   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fu1n9y/r_dealing_with_paper_reproductions/</guid>
      <pubDate>Tue, 01 Oct 2024 22:57:21 GMT</pubDate>
    </item>
    <item>
      <title>[D]《思想之树》为什么是一部有影响力的作品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/</link>
      <description><![CDATA[我的导师最近让我阅读这篇 tot 论文，但在我看来，这只是又一个**花哨的快速工程工作**。tot 过程需要大量人类智能（我们应该手动将问题分为不同的步骤，并设计验证器以使此方法有效），而且成本很高，我很少看到人们在工作中使用这种方法。 尽管如此，这篇论文还是收到了很多引用，考虑到我的导师让我阅读它的事实，我想知道我是否错过了关于这项工作的任何优点或重要含义。    提交人    /u/StraightSpeech9295   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/</guid>
      <pubDate>Tue, 01 Oct 2024 19:38:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 29 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>