<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 19 Jun 2024 15:16:02 GMT</lastBuildDate>
    <item>
      <title>“[D]” 有没有适合网站类别分类的优秀法学硕士？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djln6e/d_any_good_llm_for_website_category_classification/</link>
      <description><![CDATA[大家好！ 我想将网站归类到其主要类别：ebay -&gt; 购物。NBA.com -&gt; 体育等等。 我没有任何已知的标签或数据集，我只想要一个 LLM 来帮我做这项工作，在 HF 上还没有找到一个好的，也没有找到任何免费的 API。 谢谢！    提交人    /u/Individual-Yak4992   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djln6e/d_any_good_llm_for_website_category_classification/</guid>
      <pubDate>Wed, 19 Jun 2024 15:15:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] SIREN 网络在回归设置中不能概括吗，或者是否存在一些技巧？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djlaoz/d_do_siren_networks_not_generalize_in_the/</link>
      <description><![CDATA[我有一个棘手的高维和高频率回归问题。当我寻找 MSE 时，典型 MLP（3-4 层，swish 激活）的 MSE 约为 0.1。 我想我会尝试 SIREN，因为 MLP 似乎难以处理高频分量，在这方面它很神奇，我可以将其降至 1e-4 的 MSE。 问题是它似乎没有以任何方式概括。验证 MSE 在训练期间只是停留在相同的值，如果模型正在执行随机傅立叶特征（如模型拟合）则这是有道理的，但这不是我需要的。您知道有什么技巧可以让这种模型更好地概括吗？    提交人    /u/internet_ham   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djlaoz/d_do_siren_networks_not_generalize_in_the/</guid>
      <pubDate>Wed, 19 Jun 2024 15:00:44 GMT</pubDate>
    </item>
    <item>
      <title>[D]需要寻求有关股票走势预测的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djkw05/dadvice_needed_seeking_advice_on_stock_movement/</link>
      <description><![CDATA[大家好， 我目前正在研究每周预测 NIFTY 500 股票的股价走势。我有一个包含 270 个指标的数据集，我一直在使用 BorutaPy 进行特征选择。BorutaPy 帮助我将范围缩小到大约 160 个特征。之后，我拟合了一个随机森林模型，并选择了杂质最多的前 30 个特征。 现在，我计划拟合一个随机森林模型，根据这 30 个特征进行预测。但是，我想知道我的方法是否可以改进。具体来说，我正在考虑是否应该为所有 500 只股票创建一个模型，或者是否最好对股票进行聚类并为每个聚类创建不同的模型。 我很感激您对以下方面的任何建议或意见：  特征选择：我使用 BorutaPy 然后使用随机森林来选择前 30 个特征的方法是否合理？是否有更好的特征选择技术我应该考虑？ 建模策略：我应该为所有 500 只股票创建一个模型，还是对股票进行聚类（例如按行业、市值等）并为每个聚类创建单独的模型是否更有效？ 聚类方法：如果建议进行聚类，哪种聚类方法对这种类型的数据最有效？  提前感谢您的帮助！   由    /u/MotorReading6068  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djkw05/dadvice_needed_seeking_advice_on_stock_movement/</guid>
      <pubDate>Wed, 19 Jun 2024 14:43:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 视频讲座摘要（带文字+截图）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djjovi/p_d_video_lecture_summarization_with/</link>
      <description><![CDATA[我创建了这个应用程序 vi-su.app ，它就是用来做这件事的。我把它发布在这里，因为我从事机器学习领域，实际上设计这个应用程序是为了帮助我预览/记住机器学习的视频教程/课程（因为我想看的太多了）。 它依靠视觉语言模型来完成工作，因此可能会出现不准确的情况，但通常效果很好。最新的例子是昨天麻省理工学院深度学习入门第 7 讲 - 那里的摘要 https://vi-su.app/P7Hkh2zOGQ0/summary.html 在我看来对讲座进行了很好的说明。请参阅搜索选项卡中的其他示例。 如果您觉得这有用或有建议，请告诉我。根据兴趣，我也可以开源它。    提交人    /u/chilled_87   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djjovi/p_d_video_lecture_summarization_with/</guid>
      <pubDate>Wed, 19 Jun 2024 13:51:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 寻找优化 Apple M1 上语言模型训练的方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djj1n1/p_d_looking_for_ways_to_optimize_training_of/</link>
      <description><![CDATA[我一直在我的 MacBook (M1 Pro) 上训练微型语言模型，目前需要大约 3-4 小时来训练类似 gpt 的模型 (5M 参数)，大约 10k 步，上下文长度为 256，批处理大小为 128。单步大约需要 0.95 秒或大约 35 个 token/s。还估计了 flop 利用率，假设 M1 Pro 的限制为 5.12TFLOPS，它将达到 25% 左右。  我已经尝试了使用梯度累积的不同批处理大小，但帮助不大。有没有办法进一步减少训练时间，因为 flop 利用率只有大约 25%。    提交人    /u/PickleFart56   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djj1n1/p_d_looking_for_ways_to_optimize_training_of/</guid>
      <pubDate>Wed, 19 Jun 2024 13:21:51 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 中的输入调制门的具体用途是什么？[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djinz7/what_is_the_exact_purpose_of_input_modulation/</link>
      <description><![CDATA[基本上，我在学习 LSTM 时发现 LSTM 由三个门组成：遗忘门、输入门和输出门。但是，我偶然发现一些资料表明还有第四个门，称为 输入调制门。但是，我找不到有关此门的太多信息。一些资料说，在定义输入门时通常会省略它。其他资料说，它是输入门的一部分，是一种子系统。 输入调制门在 LSTM 中到底起什么作用？    提交人    /u/RoomProfessional7018   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djinz7/what_is_the_exact_purpose_of_input_modulation/</guid>
      <pubDate>Wed, 19 Jun 2024 13:03:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML Journal 审查速度快</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djh6n6/d_ml_journal_with_fast_review_time/</link>
      <description><![CDATA[有人知道哪个期刊的审稿速度快吗？可能最多 6 个月。但是，该期刊的竞争不应该太激烈。这是一篇被 CVPR 拒绝的计算机视觉论文。我已经知道 TMLR 了。    提交人    /u/MadScientist-1214   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djh6n6/d_ml_journal_with_fast_review_time/</guid>
      <pubDate>Wed, 19 Jun 2024 11:47:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 快速调整：快速了解需要微调的预训练模型以及如何微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djfuik/r_quicktune_quickly_learning_which_pretrained/</link>
      <description><![CDATA[      论文： https://openreview.net/forum?id=tqh1zdXIra 研究代码（用于论文中的实验）： https://github.com/releaunifreiburg/QuickTune 工具/包（用于在真实数据集中评估）： https://github.com/automl/QTT 视频： https://www.youtube.com/watch?v=bdQLWnaxAnc 摘要：随着预训练模型数量的不断增加，机器学习从业者不断面临使用哪种预训练模型以及如何针对新数据集对其进行微调的问题。在本文中，我们提出了一种联合搜索最佳预训练模型和对其进行微调的超参数的方法。我们的方法将有关具有多种超参数配置的许多预训练模型在一系列数据集上的性能的知识进行迁移。为此，我们评估了超过 20k 种超参数配置，以在 87 个数据集上对 24 个预训练图像分类模型进行微调，以生成大规模元数据集。我们在该元数据集的学习曲线上元学习灰盒性能预测器，并将其用于新数据集上的快速超参数优化。我们通过实验证明，我们得到的方法可以为新的数据集快速选择一个准确的预训练模型及其最优超参数。 TL ; DR：联合超参数和预训练模型选择进行微调。 https://preview.redd.it/c183uici9i7d1.png?width=1436&amp;format=png&amp;auto=webp&amp;s=09f29237b9f843f0829b00ab8df3a66b275c60af    提交人    /u/Accurate_Celery_4614   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djfuik/r_quicktune_quickly_learning_which_pretrained/</guid>
      <pubDate>Wed, 19 Jun 2024 10:27:19 GMT</pubDate>
    </item>
    <item>
      <title>[P][D] 需要帮助评估我的 rag-chatbot</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djfubc/pd_need_help_in_evaluating_my_ragchatbot/</link>
      <description><![CDATA[我已经使用 rag 架构和 llama3 作为基础 llm 开发了一个聊天机器人，需要改进的步骤，因此需要评估指标或任何类型来比较每个改进     提交人    /u/spiritleader473882   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djfubc/pd_need_help_in_evaluating_my_ragchatbot/</guid>
      <pubDate>Wed, 19 Jun 2024 10:26:56 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 原始 NTP 训练模型的循环文本生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1djdz8n/discussion_loopy_text_generation_of_raw_ntp/</link>
      <description><![CDATA[如何解释在进行指令调整和对齐之前通过下一个标记预测进行预训练的模型生成循环文本，我们如何检测到它？ 例如，我的一个模型生成了这样的文本：“Temptation&#39;s Trial hope is a\u040b hope is a\u040b a bi hope is a hope is a bi hope is a hope is a bi hope is a hope is a bi hope is a hope is a bi hope is a hope is a bi hope is a... x20 次以上”。然后我将这句话插入 Llama3-8b 并发现每个标记的损失 - 它非常低 我将上述文本放入 GPT4o 并要求它执行其他任务，例如“将这些句子放入列表中”，它就因为文本的内容而发疯了！它进入了一个无限循环，打印相同的序列而永不停歇。尽管 GPT4o 不是原始的预训练模型，但情况仍然如此。不过，这种行为通常仅源自此类原始模型。 我还记得，一旦生成超过 1-2 个句子，GPT-2 就会陷入循环。有没有文献讨论过这种现象，有没有办法检测它？    提交人    /u/Fit-Flow-4180   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1djdz8n/discussion_loopy_text_generation_of_raw_ntp/</guid>
      <pubDate>Wed, 19 Jun 2024 08:16:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 你好，我是一名高级机器学习工程师，正在寻找伙伴一起创造很酷的东西！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dj8pg6/p_d_hi_im_a_senior_machine_learning_engineer/</link>
      <description><![CDATA[嗨，我是一名高级机器学习工程师，正在寻找可以一起创造酷炫东西的伙伴！我希望与其他充满热情的工程师一起探索和试验。我们可以做 Kaggle 项目、LeetCode，或者只是面试头脑风暴。如果有人愿意提出想法并看看我们可以一起创造什么酷炫的东西，请与我们联系。 更新：非常感谢大家的热烈响应！我收到了 100 多条回复，我感谢您的兴趣和贡献意愿。 为了确保我可以有效地管理所有回复并筛选出潜在的认真候选人，我将很快创建一个 Google 表单。 请耐心等待我的设置。在此期间，如果您有任何想法或建议，请分享。    提交人    /u/Rude-Eye3588   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dj8pg6/p_d_hi_im_a_senior_machine_learning_engineer/</guid>
      <pubDate>Wed, 19 Jun 2024 02:45:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] - AMD MI300X 和 Nvidia H100 在 FFT 中的基准测试：VkFFT、cuFFT 和 rocFFT 比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dj1ixf/d_amd_mi300x_and_nvidia_h100_benchmarking_in_fft/</link>
      <description><![CDATA[   您好，我是 VkFFT 的创建者 - 用于 Vulkan/CUDA/HIP/OpenCL/Level Zero 和 Metal 的 GPU 快速傅里叶变换库。目前没有太多独立基准测试来比较 Nvidia (H100 SXM5) 和 AMD (MI300X) 的现代 HPC 解决方案，因此一旦这些 GPU 按需可用，我就会想知道它们执行快速傅里叶变换的效果如何 - 以及供应商库（如 cuFFT 和 rocFFT）与我的实现相比的表现如何。 按需租赁非常昂贵，因此这些初步结果仅包括单精度和双精度的 1D 批处理 2 个复杂到复杂 FFT 的幂。此基准测试通常在 GPU 上受内存限制，这意味着大部分时间都花在利用 VRAM 总线和将数据从 VRAM 传输到芯片上（批处理大小选择得足够大以减少缓存重用并利用所有计算单元）。我使用估计带宽作为基准指标，其计算方式为 (2 x 系统大小 [GB]) / 执行时间 [s]。之所以有 2 个倍数，是因为我们需要上传数据并从芯片下载数据。因此，对于内存受限的代码，此值应接近设备的内存带宽。 https://preview.redd.it/ngv6qqxvbd7d1.png?width=4500&amp;format=png&amp;auto=webp&amp;s=d4bdc8893462561f307e758cafb10e3f76636174 在单精度下，两种 GPU 的结果相似 - 单上传 FFT 算法的带宽约为 3TB/s。大约 2^14（取决于实现）后，所有库都切换到两次上传（和两次下载）FFT 算法，导致内存传输量增加 2 倍，随后带宽下降 2 倍。切换到三次上传发生在 2^24 左右。总体而言，两种 GPU 的理论带宽都未达到（H100 为 3.35TB/s，MI300X 为 5.3TB/s），但实际值低于规格值是很常见的。对于 AMD MI300X，小尺寸的结果也不一致，这可能是因为需要对新的多芯片设计和 L3 缓存进行更多优化。当前的 VkFFT 版本（针对上一代硬件进行了优化）与供应商解决方案相匹配，并且通常优于供应商解决方案，适用于高度优化的 2 的幂的情况。  https://preview.redd.it/9q0wt6m3cd7d1.png?width=4500&amp;format=png&amp;auto=webp&amp;s=19644a0945cd9f4a6acd4172d956c467bca94856 双精度结果的缩放比例与单精度类似。 AMD MI300X 在此实现了比单精度更高的基本带宽，我还不确定为什么（也许 1:1 FP64:FP32 核心比率会派上用场）。 VkFFT 还针对非 2 幂的情况进行了高度优化，因此在新硬件上应该表现良好。您可以在 VkFFT 论文中找到实现的算法描述和上一代 HPC GPU 的完整性能比较。一旦我解决了访问成本问题并进行了广泛的测试，我就会调整新 GPU 的代码。 总体而言，MI300X 与 H100 具有竞争力，而且看起来 AMD 改进了前几代 CDNA 的许多问题（即远程合并访问的内存引脚序列化）。看起来每个计算单元仍然比相应的流式多处理器弱 - 它具有更小和更慢的共享内存/L1 和 L2 缓存，但是，它通过拥有 L3 缓存和新的多芯片设计（连接 304 个计算单元）来抵消，其影响有待估计。 感谢您的阅读，如果您对 VkFFT 或测试程序有任何疑问 - 我很乐意回答。    提交人    /u/xdtolm   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dj1ixf/d_amd_mi300x_and_nvidia_h100_benchmarking_in_fft/</guid>
      <pubDate>Tue, 18 Jun 2024 21:05:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 工业界的机器学习研究人员：如何找出时间发表论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1divk13/d_ml_researchers_in_industry_how_do_you_find_time/</link>
      <description><![CDATA[背景：我在一家 FAANG 公司从事计算机视觉工作。我非常幸运，能够应用相对先进的技术。我通常每年至少参加一次大型会议，看到很多行业科学家发表演讲/张贴海报，我不得不问：怎么做到的？ 我每周花 40 个小时将技术应用于我公司特定的数据集/问题。我擅长我的工作，紧跟最新技术，为我的雇主创造了很多价值。这些技术甚至可以发表，但这需要在开源数据集上对这些方法进行基准测试。我无法想象在拥有生活和爱好的同时，还要找到进行所有实验和写作所需的额外时间。 尽管如此，我觉得这是对我的期望。与我共事的科学家基本上没有研究以外的生活，这似乎很正常（除非他们周末去远足……）。    提交人    /u/generating_loop   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1divk13/d_ml_researchers_in_industry_how_do_you_find_time/</guid>
      <pubDate>Tue, 18 Jun 2024 16:56:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 进化策略与反向传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dila4s/d_evolutionary_strategy_vs_backpropagation/</link>
      <description><![CDATA[我正在研究用于训练 NN 的进化策略，并得到了非常有趣的结果。这是你可以使用的笔记本：Colab 笔记本链接    epoch 数量 最终准确度 每 epoch 秒数    反向传播 10 97% 9   进化策略 10 90% 9   我不知道它能走多远，但是对于完全不使用梯度信息并在与反向传播相同的时间内在 GPU 上完成训练的东西获得 90% 的准确率是非常有趣的。 使用的 ES 算法非常简单：  用零初始化所有权重 创建大小为 N 的新一代种群 - 从正态分布中绘制每个权重，其中平均值是当前权重，标准差是学习率。 并行计算种群中每个个体的损失 - 在 GPU 上运行良好 挑选表现最好的前 k 个个体进行交配。 要获得新一代的下一个权重张量，请对表现最好的前 k 个个体取平均值。 转到步骤 2。  您是否知道任何探索训练神经网络的进化策略的有趣研究？ 更新 使用这些参数，您将在第一个 epoch 后获得 90%，在 10 个 epoch 后获得大约 94%，并且一个 epoch 所花费的秒数相似： lr = 5E-2population_size = 512generations_per_batch = 1num_parents_for_mating = 256    submitted by    /u/kiockete   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dila4s/d_evolutionary_strategy_vs_backpropagation/</guid>
      <pubDate>Tue, 18 Jun 2024 08:00:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 16 Jun 2024 15:00:16 GMT</pubDate>
    </item>
    </channel>
</rss>