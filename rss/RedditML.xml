<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 28 Sep 2024 18:20:29 GMT</lastBuildDate>
    <item>
      <title>TextGrad 教程 - 用于提示优化的文本梯度下降 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frjwh5/textgrad_tutorial_text_gradient_descent_for/</link>
      <description><![CDATA[      分享一个关于 TextGrad 的教程视频，TextGrad 是斯坦福大学一个相当新的文本优化库。他们有一个类似 PyTorch 的框架来评估、计算损失并通过 LLM 提示图提供反馈信号。    提交人    /u/AvvYaa   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frjwh5/textgrad_tutorial_text_gradient_descent_for/</guid>
      <pubDate>Sat, 28 Sep 2024 17:49:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医疗 AI：顶级研究论文/模型🏅（2024 年 9 月 21 日至 9 月 27 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frha2f/d_last_week_in_medical_ai_top_research/</link>
      <description><![CDATA[   上周医疗 AI：顶级研究论文/模型🏅（2024 年 9 月 21 日至 9 月 27 日） 本周医疗 AI 论文 医学中 o1 的初步研究：我们离 AI 医生更近了吗？  本文介绍了 o1，这是一种大型语言模型 (LLM)，它在 37 个医学数据集上进行了评估，与 GPT-4 和 GPT-3.5 相比，在临床理解、推理和多语言性方面表现出色。  医学 LLM 和其他模型：  DREAMS：用于医学 LLM 的 Python 框架  用于 EEG 数据处理、模型训练和报告生成的综合深度学习框架。   SLaVA-CXR：用于胸部 X 光报告自动化的小型语言和视觉助手  本文介绍了 SLaVA-CXR，这是一种创新的小型模型，旨在以高精度和高效率自动化胸部 X 光报告。  医学中的 O1：AI 医生的潜力 基因组语言模型：机遇与挑战  它重点介绍了关键的 gLM 应用，如功能约束预测、序列设计和迁移学习，同时讨论了为复杂基因组开发有效 gLM 的挑战。   医学 LLM 和基准：   MEDICONFUSION：探究医学 LLM 的可靠性  本文介绍了 MediConfusion，这是一个具有挑战性的基准，用于探究医学成像中多模态大型语言模型 (MLLM) 的故障模式。  CHBench：中国 LLM 健康评估  本文介绍了 CHBench，这是第一个全面的中国健康相关基准，旨在评估大型语言模型 (LLM) 对身心健康的理解。  精神疾病评估的 LLM PALLM：评估姑息治疗 LLM 蛋白质 LM：扩展的必要性？   框架和方法：   肿瘤学操作的数字孪生 增强医疗 AI 的护栏 InterMind：由 LLM 驱动的抑郁症评估 对话式健康代理：LLM 框架  医学 LLM 应用：   用于心理健康严重程度预测的 LLM 用于放射学报告的微调 LLM 患者教育中的 LLM：背痛 通过检索上下文增强医疗 LLM 针对临床 LLM 的持续预训练  医疗伦理中的人工智能：   医学成像人工智能中的置信区间 生成式人工智能是否已为临床应用做好准备  ...  详细查看完整帖子：https://x.com/OpenlifesciAI/status/1840020394880667937 感谢您的阅读！如果您知道任何遗漏的有趣论文，请随时在评论中分享。如果您在医疗 AI 方面有见解或突破，并希望在下周的版本中分享，请通过 Twt/x 与我们联系：OpenlifesciAI    提交人    /u/aadityaura   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frha2f/d_last_week_in_medical_ai_top_research/</guid>
      <pubDate>Sat, 28 Sep 2024 15:50:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] 将 GPT 转换为 Llama 的分步代码指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frer4z/p_converting_gpt_to_llama_stepbystep_code_guide/</link>
      <description><![CDATA[      一个经常被问到的问题是 GPT 与 Llama 相比如何。在我看来，了解差异的最佳方法之一是从头开始实现这两种架构。这里有一个分步 Jupyter 笔记本指南。 https://preview.redd.it/qowi1sf12krd1.jpg?width=4286&amp;format=pjpg&amp;auto=webp&amp;s=b815e4e6df8d38c70816fb6f51ff1482b6cca80e    提交人    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frer4z/p_converting_gpt_to_llama_stepbystep_code_guide/</guid>
      <pubDate>Sat, 28 Sep 2024 13:51:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAAI 提交和 CoRL 研讨会</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frdyq5/d_aaai_submission_and_corl_workshop/</link>
      <description><![CDATA[我是否可以将目前正在 AAAI 会议审查的论文不做任何更改就提交给 CoRL 研讨会？这会对我的 AAAI 提交产生任何影响吗？CoRL 研讨会页面显示“已接受的论文将在研讨会网页上发布，并将以焦点演讲或海报的形式展示”。    提交人    /u/drainageleak   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frdyq5/d_aaai_submission_and_corl_workshop/</guid>
      <pubDate>Sat, 28 Sep 2024 13:10:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一种识别与特定知识相关的语言模型权重的方法：探索两个相互矛盾的提示的梯度增量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frcea9/d_a_method_to_identify_language_model_weights/</link>
      <description><![CDATA[嘿 - 我想到了以下方法来查找与特定知识相关的语言模型权重。 只是想分享反馈和灵感。可能已经有人提出了这个或更好的东西，在这种情况下，我很乐意了解更多！ 方法：采用语言模型（例如 Qwen2.5 0.5B Instruct）并对 2 个相互矛盾的提示运行 1 次前向和后向传递： prompt1 = &quot;法国的首都叫巴黎&quot; prompt2 = &quot;法国的首都叫伦敦&quot;  现在，查看模型建议的梯度更新以最小化损失。对于大多数权重，这两个提示的更新之间的差异应该会相互抵消 - 除了那些与哪个城市真正是法国首都直接相关的权重。 例如，我发现嵌入矩阵中的权重 id（或特征）674 与“法国首都”密切相关。通过调整该特征，我设法让模型预测伦敦而不是巴黎为首都。 我在以下笔记本中放了一个概念验证：https://gist.github.com/trianxy/c05b883d3cb12869f51327af1b69b771    提交人    /u/trianxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frcea9/d_a_method_to_identify_language_model_weights/</guid>
      <pubDate>Sat, 28 Sep 2024 11:41:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025 互惠审查例外</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1frccr2/d_iclr_2025_reciprocal_reviewing_exception/</link>
      <description><![CDATA[我想申请审查豁免。在表单上我必须输入论文 ID，这与提交编号相同吗？我找不到任何论文 ID……    提交人    /u/Admirable_Variation5   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1frccr2/d_iclr_2025_reciprocal_reviewing_exception/</guid>
      <pubDate>Sat, 28 Sep 2024 11:38:24 GMT</pubDate>
    </item>
    <item>
      <title>[R] 交互系统和生成音乐的可区分逻辑（GSOC '24）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fram3o/r_differentiable_logic_for_interactive_systems/</link>
      <description><![CDATA[  由    /u/jdkarmitage  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fram3o/r_differentiable_logic_for_interactive_systems/</guid>
      <pubDate>Sat, 28 Sep 2024 09:32:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 有人尝试用自己的数据训练 wav2lip 吗？结果如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fr9z58/d_r_anybody_tried_training_wav2lip_on_their_own/</link>
      <description><![CDATA[我尝试了 wav2lip，发现 Github 上有文档提到使用自己的数据训练模型。因此，假设我们拥有某个人大约 10 小时左右的说话头部数据，并且我们使用这些数据来训练或微调现有的 wav2lip 模型 - 这对于创建该人嘴唇同步视频的质量有何不同。 有人这样做过吗？结果如何，有更好的吗？ 如果您能分享您的经验，我们将不胜感激。    提交人    /u/arandomuser6543   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fr9z58/d_r_anybody_tried_training_wav2lip_on_their_own/</guid>
      <pubDate>Sat, 28 Sep 2024 08:42:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] neurips2024 论文列表已经出炉！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fr9bm2/d_list_of_neurips2024_papers_is_out/</link>
      <description><![CDATA[https://nips.cc/virtual/2024/papers.html?filter=titles 享受！    由   提交  /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fr9bm2/d_list_of_neurips2024_papers_is_out/</guid>
      <pubDate>Sat, 28 Sep 2024 07:52:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] Llama3.2-1B GGUF 量化基准测试结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqw88t/d_llama321b_gguf_quantization_benchmark_results/</link>
      <description><![CDATA[      我使用 IFEval 对 Llama 3.2-1B GGUF 量化进行了基准测试，以找到速度和准确性之间的最佳平衡数据集。为什么我选择 IFEval？它是测试 LLM 遵循指令情况的绝佳基准，这对于大多数现实世界用例（如聊天、问答和摘要）至关重要。 第一张图表显示了基于 IFEval 分数的不同 GGUF 量化的表现。 https://preview.redd.it/b580liydnerd1.png?width=692&amp;format=png&amp;auto=webp&amp;s=0b9a1b0e7af0004f25604d3634a615f2e6326d20 第二张图表说明了文件大小和性能之间的权衡。令人惊讶的是，q3_K_M 占用的空间更少（速度更快），但保持了与 fp16 相似的准确度水平。 https://preview.redd.it/6tkr76venerd1.png?width=866&amp;format=png&amp;auto=webp&amp;s=7dd90f1a82e4d222bcd4bd4475cb0b8720b8a5d1 https://preview.redd.it/zvmr0asgnerd1.png?width=1510&amp;format=png&amp;auto=webp&amp;s=2630cae9bac659591d714216b71d9ce87ea68222 完整数据可在此处获取：nexaai.com/benchmark/llama3.2-1b ​量化模型从 ollama.com/library/llama3.2 后端：github.com/NexaAI/nexa-sdk（SDK 将很快支持基准测试/评估！） 下一步是什么？  我接下来应该对 Llama 3.2-3B 进行基准测试吗？ 对 AWQ 等不同的量化方法进行基准测试？ 欢迎提出改进此基准测试的建议！  让我知道你的想法！    提交人    /u/AlanzhuLy   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqw88t/d_llama321b_gguf_quantization_benchmark_results/</guid>
      <pubDate>Fri, 27 Sep 2024 19:41:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 人工智能的下一个前沿是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqvy7d/d_r_what_is_the_next_frontier_to_ai/</link>
      <description><![CDATA[我是一名本科研究助理。我很好奇，您认为人工智能的新前沿是什么？ 例如，我们充满了 LLM 模型，这些模型非常适合语言和视觉任务。但是，当涉及到规划、控制、现实世界交互、分布式思维等时，它们就很差了。 哪些主题仍然处于研究领域的阴影中，但有能力成为新的前沿范式？偏见是非常鼓励的。    提交人    /u/One_Obligation3987   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqvy7d/d_r_what_is_the_next_frontier_to_ai/</guid>
      <pubDate>Fri, 27 Sep 2024 19:28:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] Llama-3.2-3B-指导-未经审查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqqzuh/r_llama323binstructuncensored/</link>
      <description><![CDATA[这是原始 Llama-3.2-3B-Instruct 的未经审查版本，使用 mlabonne 的 脚本 创建，该脚本基于 FailSpy 的笔记本 和来自 Andy Arditi 等人。此博客和此论文中详细讨论了该方法。 您可以在此处找到未经审查的模型，并在此🤗空间中使用它。    提交人    /u/chuanli11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqqzuh/r_llama323binstructuncensored/</guid>
      <pubDate>Fri, 27 Sep 2024 15:53:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 批次大小与学习率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fqqfos/d_batch_size_vs_learning_rate/</link>
      <description><![CDATA[关于最佳模型性能的最佳批次大小有两种观点：  较小，大约 32。 无关紧要，因此使用尽可能最大的批次大小来最大限度地缩短训练时间。  有大量资料支持这两种理论。以下几点表明小批量是最好的：  最佳性能始终是在 m=2 至 m=32 之间的小批量大小下获得，这与近期主张使用数千的小批量大小的研究形成鲜明对比。 重新审视深度神经网络的小批量训练 我们的结果得出结论，较大的批量大小通常不会实现高精度，并且使用的学习率和优化器也会产生重大影响。降低学习率和减小批量大小将使网络训练得更好，尤其是在微调的情况下。 批量大小对卷积神经网络在组织病理学数据集上的通用性的影响 使用大型小批量进行训练对您的健康有害。更重要的是，这对您的测试错误不利。朋友不会让朋友使用大于 32 的小批量。 Yann LeCun  有些人声称它们应该很大：  我们没有发现任何证据表明较大的批次大小会降低样本外性能。 测量数据并行对神经网络训练的影响 一旦考虑到所有这些影响，目前没有令人信服的证据表明批次大小会影响可实现的最大验证性能......批次大小不应被视为验证集性能的可调超参数。 深度学习调优手册  您觉得如何？对于 VGG、ResNet 和 DenseNet 等图像模型，是否对于应使用什么批量大小达成了共识？    提交人    /u/bjourne-ml   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fqqfos/d_batch_size_vs_learning_rate/</guid>
      <pubDate>Fri, 27 Sep 2024 15:29:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fmv9zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 22 Sep 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>