<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 19 Jan 2024 18:17:31 GMT</lastBuildDate>
    <item>
      <title>[P] 冷启动建议 - XGBoost 还是其他？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ancq9/p_cold_start_recommendations_xgboost_or_something/</link>
      <description><![CDATA[我有大约 100k 种不同产品的数据集。这些产品可以是整机，也可以是配件。就像完整的计算机与购买机箱、鼠标、键盘、内存、CPU 等一样。 我想建立一个推荐系统，在输入 1 个产品的情况下找到类似的产品。 数据是表格形式的（价格、长度/宽度/高度、类别、子类型等，其中一些文本部分（例如标题和描述）可以是可变的……有些列在所有内容中 100% 相同，但不同的类别有不同的规格/列）&lt; /p&gt; 最终这将出现在网站上 - 但假设现在用户流量为 0。我认为这排除了协同过滤，因为没有反馈循环。虽然从长远来看这可能是理想的。 既然是表格数据，我可以使用 XGBoost 吗？我是否将任何自由格式文本字段和隐藏类别/类型转换为数字？或者嵌入 + kNN 更好？任何 YouTube 视频或文档都会有所帮助。 我还在考虑根据类别设置多个单独的推荐匹配提供商，因为它们的列不同。类似于 StockX 基于鞋子或衣服等进行推荐的方式。   由   提交/u/pegasi320  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ancq9/p_cold_start_recommendations_xgboost_or_something/</guid>
      <pubDate>Fri, 19 Jan 2024 16:41:13 GMT</pubDate>
    </item>
    <item>
      <title>[2401.10187] GPU 上的快速克罗内克矩阵-矩阵乘法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19amot7/240110187_fast_kronecker_matrixmatrix/</link>
      <description><![CDATA[ 由   提交/u/Elven77AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19amot7/240110187_fast_kronecker_matrixmatrix/</guid>
      <pubDate>Fri, 19 Jan 2024 16:13:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习中的不确定性来源——统计学家的观点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19aml6l/r_sources_of_uncertainty_in_machine_learning_a/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2305.16703 摘要：  机器学习和深度学习今天已经达到了令人印象深刻的标准，使得我们可以回答几年前难以想象的问题。除了这些成功之外，很明显，除了纯粹的预测（大多数监督机器学习算法的主要优势）之外，不确定性的量化也是相关且必要的。虽然近年来出现了这个方向的第一个概念和想法，但本文采用概念视角并研究了不确定性的可能来源。通过采用统计学家的观点，我们讨论了任意和认知不确定性的概念，这些概念更常见于机器学习。本文旨在将两种类型的不确定性形式化，并证明不确定性的来源是多种多样的，并且并不总是可以分解为任意的和认知的。我们将机器学习中的统计概念与不确定性进行比较，还展示了数据的作用及其对不确定性的影响。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19aml6l/r_sources_of_uncertainty_in_machine_learning_a/</guid>
      <pubDate>Fri, 19 Jan 2024 16:09:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 人工神经网络中的类脑学习：综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19amch3/r_braininspired_learning_in_artificial_neural/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2305.11252 摘要：  人工神经网络（ANN）已成为以下领域的重要工具：机器学习，在图像和语音生成、游戏和机器人等多个领域取得了显着的成功。然而，人工神经网络的运行机制与生物大脑的运行机制之间存在根本差异，特别是在学习过程方面。本文对当前人工神经网络中的类脑学习表示进行了全面回顾。我们研究了更多生物学上合理的机制的整合，例如突触可塑性，以增强这些网络的能力。此外，我们深入研究了这种方法的潜在优势和挑战。最终，我们为这个快速发展的领域的未来研究找到了有希望的途径，这可以让我们更接近理解智能的本质。     ;由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19amch3/r_braininspired_learning_in_artificial_neural/</guid>
      <pubDate>Fri, 19 Jan 2024 15:59:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] GPU 服务器库存</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19allss/d_p_stockpile_of_gpu_servers/</link>
      <description><![CDATA[我有 22 台 8 GPU 服务器，配备 AMD Mi50（请参阅下面有关 Mi50 的注释）。我已经能够让 PyTorch 在这些 GPU 上运行，并且能够对不同的大型语言模型进行推理。我原本想使用这些 GPU 来为 LLM 提供服务，但 VLLM cuda 内核不能在 Mi50 上开箱即用，而且 Llama CPP 有一个错误，它一次最多只能支持 4 个 AMD GPU。 所以，TLDR，我不想让这些服务器闲置，如果有人对服务器有任何有用的创意，我很乐意授予他们 SSH 访问权限。 Mi50 规格：  - 16GB VRAM - 1TB/s VRAM 带宽 - 25 TFLOPs  &amp; #32；由   提交 /u/TheRealBracketMaster   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19allss/d_p_stockpile_of_gpu_servers/</guid>
      <pubDate>Fri, 19 Jan 2024 15:27:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] AISTATS 2024论文接收结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19al3e9/d_aistats_2024_paper_acceptance_result/</link>
      <description><![CDATA[AISTATS 2024 论文接受结果将于今天发布。正在为今年的结果创建讨论主题。   由   提交/u/zy415  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19al3e9/d_aistats_2024_paper_acceptance_result/</guid>
      <pubDate>Fri, 19 Jan 2024 15:03:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自我奖励语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19akxwp/r_selfrewarding_language_models/</link>
      <description><![CDATA[ 由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19akxwp/r_selfrewarding_language_models/</guid>
      <pubDate>Fri, 19 Jan 2024 14:57:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] Creatures 1996，一款利用机器学习的早期人工生命模拟游戏。想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ak2w9/d_creatures_1996_an_early_artificial_life/</link>
      <description><![CDATA[我想先说一下，当我浏览 Reddit 时，我看到了这个游戏的描述： “这个游戏有当时其中有一些非常复杂的系统。它有一个化学系统，你的生物的免疫系统，他们的行为和个性，他们的DNA和繁殖系统，你必须通过对象-词和行为关联来教他们实际的语言和单词，你必须惩罚和奖励他们的行为正确地，否则他们会发展出适应不良的行为或变得暴力并杀死你的其他生物，如果你不处理的话，他们也会变得沮丧，等等。事实上，游戏中甚至有一整套他们可以体验的情感系统，你必须尝试管理它，否则你的生物会变得孤立并对你反应迟钝。除此之外，还有暴力且患病的敌方生物种族，称为 grendels，它们在世界上漫游，可以杀死/骚扰你的生物。” 根据维基百科页面： “生物是一种人工生命模拟，用户可以孵化毛茸茸的小动物并教它们如何行为，或者让它们自己学习。这些“诺恩”可以说话，自己进食，并保护自己免受称为Grendels的邪恶生物的侵害。这是机器学习在交互式模拟中的第一个流行应用。生物利用神经网络来学习该做什么。该游戏被认为是人工生命研究的突破，旨在模拟生物与其环境互动的行为。” https://en.m.wikipedia.org/wiki/Creatures_(1996_video_game) 还有其他更高级的人工生命模拟游戏吗？这些看起来确实非常有趣，尤其是考虑到我们在机器学习方面取得了几十年的进步。   由   提交 /u/Username912773   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ak2w9/d_creatures_1996_an_early_artificial_life/</guid>
      <pubDate>Fri, 19 Jan 2024 14:16:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] AWS 课程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19ajjll/d_aws_courses/</link>
      <description><![CDATA[大家好，我是一名 ML 工程师，试图换工作，但似乎到处都需要云经验。不幸的是，我没有使用过云，但我想学习它，特别是 AWS。您推荐哪些 AWS 课程？   由   提交 /u/lusinn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19ajjll/d_aws_courses/</guid>
      <pubDate>Fri, 19 Jan 2024 13:50:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT 2论文问题（语言模型是无监督多任务学习者）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19aj9is/d_gpt_2_paper_question_language_models_are/</link>
      <description><![CDATA[在 2.2 中。输入表示部分，它使用字节级版本的 BPE，它如何处理可以在 Unicode 版本中处理的其他语言？（你知道 Unicode 中的字符比 256 个字符多得多，所以我想知道） + “既然我们的方法可以为任何 Unicode 字符串分配概率”（来自同一部分），那么当它只能表示整个 Unicode 中的 256 个字符时，这怎么可能？ p&gt; ​ 如果我误解了什么，请告诉我。谢谢   由   提交 /u/BarkingBot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19aj9is/d_gpt_2_paper_question_language_models_are/</guid>
      <pubDate>Fri, 19 Jan 2024 13:37:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在视觉领域，引导模型在利基任务上工作的当前 SOTA 是多少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19aet3w/d_what_is_the_current_sota_for_bootstrapping/</link>
      <description><![CDATA[过去，当您需要在一些相对小众的分类/检测/分割任务上训练模型时，您会使用在ImageNet1K/COCO 并将其微调到您拥有的任何中小型数据集，这足以将您的性能提升到合理的水平。当然，您始终可以通过使用更大的 Resnet、改进超参数选择或清除专有数据集中的噪声来改进这一点。更新的架构已经发布，更新的优化器，我们现在有像 CLIP 这样的大型 VL 模型，等等。我想知道我是否错过了一个新的共识。 如果你选择回答，我将不胜感激如果您还详细说明了以下标准：  您选择的方法是否对超参数过于敏感？ / 收敛到正确的模型有多难？例如，根据我的经验（当然不是绝对的），在超参数选择方面，ResNet 比 EfficientNet 更宽容。 您的方法对少量数据的敏感程度如何？例如，我记得原来的 Transformer 在小训练集场景中非常糟糕，结果在 IN22K 上报告。 您的选择有多快和/或内存效率如何？小的利基任务往往不会证明具有 1B 参数的模型是合理的。  谢谢！   由   提交/u/anaccountforthemasse   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19aet3w/d_what_is_the_current_sota_for_bootstrapping/</guid>
      <pubDate>Fri, 19 Jan 2024 08:57:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] Facebook 关闭 ParlAI，一个对话研究框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19adrgv/d_facebook_shuts_down_parlai_a_framework_for/</link>
      <description><![CDATA[我刚刚了解到 Facebook 已经存档了 BlenderBot 背后的团队 ParlAI。该存储库于 2023 年 11 月 3 日存档，现在是只读的，此后该项目的 Twitter 帐户没有任何更新。 因此 Facebook 放弃了工程化和模块化对话系统背后的想法，并全力以赴对于LLM，我还听说其他大公司的其他模块化对话团队也在裁员。你觉得怎么样？   由   提交 /u/Comfortable_Use_5033   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19adrgv/d_facebook_shuts_down_parlai_a_framework_for/</guid>
      <pubDate>Fri, 19 Jan 2024 07:43:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能很强大实际上是一个严肃而真实的领域正在研究，或者只是人们正在宣传的另一种炒作？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19a6nsd/d_is_strong_ai_actually_a_serious_and_real_field/</link>
      <description><![CDATA[强大的人工智能。 （通用人工智能）实际上是一个严肃的研究领域，还是只是刚刚阅读/观看科幻小说的人的纯粹炒作？ 强人工智能/又名是强人工智能吗？ AGI实际上被一些研究人员/机构认真对待，他们认为它最终可以实现，或者它是人们一直在炒作的另一种奇特的技术蒸汽软件，但实际上，那些在该领域工作的人知道这样的想法实际上无法实现，因为严格的物理限制，或者如果发生的话，需要几个世纪才能实现？ 因为过去对于许多未来主义者来说有很多歇斯底里的感觉技术，这些技术被很多不了解蹲点的人大肆宣传，但它无法在实践中发挥作用（即 Em Drive、石墨烯、富勒烯、纳米机器人、Bussard Ramjet、聚变能源等）。   由   提交/u/Enzo-chan  /u/Enzo-chan  reddit.com/r/MachineLearning/comments/19a6nsd/d_is_strong_ai_actually_a_serious_and_real_field/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19a6nsd/d_is_strong_ai_actually_a_serious_and_real_field/</guid>
      <pubDate>Fri, 19 Jan 2024 01:16:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] PyTorch 2 内部结构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19a1mup/p_pytorch_2_internals/</link>
      <description><![CDATA[嗨，刚刚分享了关于 PyTorch 内部结构的幻灯片，涵盖 Dynamo、Inductor、ExecuTorch 等最近的项目，我认为这里可能会有一些人感兴趣。 &lt;!-- SC_ON - -&gt;  由   提交 /u/perone   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19a1mup/p_pytorch_2_internals/</guid>
      <pubDate>Thu, 18 Jan 2024 21:37:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>