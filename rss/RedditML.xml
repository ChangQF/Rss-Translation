<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Fri, 19 Jul 2024 03:19:54 GMT</lastBuildDate>
    <item>
      <title>[D] 有没有关于句子转换器微调/修改的经验？附加问题：LLM 针对 NLP 任务和/或数据集生成进行微调？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6sfcg/d_any_experience_about_sentence_transformers_fine/</link>
      <description><![CDATA[我最近一直在研究对 Sentence Transformers 模型进行微调，想听听那些有针对特定任务对这些模型进行微调或“编辑”经验的人的意见。 我有一些问题：  您通常是从预训练模型开始还是从已经微调过的模型开始？（我尝试过 DeBERTa-v3、e5-unsupervised 和 snowflake-artic-large） 您使用哪些数据集进行微调？（好吧，一般的平庸问题，答案是“视情况而定”，但我只是想听听一些经验/想法） 哪些损失函数适合您的数据集格式？我注意到 MNR 损失和 GISTembedd 损失的表现良好......还使用了一些对比损失作为“弱监督训练”和 simCSE 作为完全无监督的  （问题：与 Sentence Transformers 库中的经典 &#39;&#39;&#39;contrastive Loss&#39;&#39;&#39;&quot; 相比，损失 &#39;&#39;&#39;OnlineContrastiveLoss&#39;&#39;&#39; 实际上做了什么）  有没有什么关于训练 Sentence Transformers 的技巧或最佳实践，或者我应该避免的常见错误？  欢迎分享您的见解、经验或任何有用的资源！ 提前感谢任何形式的回复！    提交人    /u/Distinct-Target7503   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6sfcg/d_any_experience_about_sentence_transformers_fine/</guid>
      <pubDate>Fri, 19 Jul 2024 02:00:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] Redis 作为矢量数据库。有什么个人经历吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6rhjx/d_redis_as_vector_database_any_personal/</link>
      <description><![CDATA[我们正在重新审视我们的 AI 平台/堆栈，并试图找出存储嵌入和向量搜索的最佳选择。我们为金融服务领域的客户提供服务，宁愿不依赖初创公司的产品，而更愿意选择更成熟的供应商。我们正在考虑将 redis 作为一种选择。似乎 Redis 具有良好的性能（至少在更传统的数据库中是最好的）。我没有注意到 pinecone 和 Redis 之间的设置时间有很大差异。有人用过 Redis 作为向量数据库吗？你喜欢/不喜欢什么？只对个人经历感兴趣，而不是供应商的宣传    提交人    /u/Different-Use9841   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6rhjx/d_redis_as_vector_database_any_personal/</guid>
      <pubDate>Fri, 19 Jul 2024 01:11:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 API 文档缓解代码 LLM 幻觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6o2gi/r_on_mitigating_code_llm_hallucinations_with_api/</link>
      <description><![CDATA[      TL;DR：我们引入了一个新的基准 CloudAPIBench 来测量 API 幻觉，并使用Documenation Augmented Generation （DAG） 来优化此基准测试的性能。  我们引入了 CloudAPIBench，这是一个衡量 API 幻觉并为公共 API 提供基于频率的注释的基准。 我们的研究表明，诸如 GPT-4o 之类的代码 LLM 在处理低频 API 时遇到困难，仅实现了 38.58% 的有效调用，而使用 DAG 后，这一比例提高到了 47.94%。但是，当使用次优检索器时，DAG 会对高频 API 产生负面影响。 为了解决这个问题，我们建议根据 API 索引或置信度分数有选择地触发 DAG，从而将 GPT-4o 在 CloudAPIBench 上的整体 API 调用正确性提高 8.20%。  该论文还包括一些有趣的见解，例如 API 文档的哪些部分在 DAG 期间最有用以及如何执行选择性检索，例如，使用预测的 API 名称令牌的置信度分数。 CloudAPIBench 和论文的代码将很快发布！ Arxiv：链接； Twitter 帖子：链接 作为作者之一，如果您对我们的工作有任何问题或意见，我很乐意参与讨论。谢谢！ DAG 概述。 结果摘要。    提交人    /u/nihaljn   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6o2gi/r_on_mitigating_code_llm_hallucinations_with_api/</guid>
      <pubDate>Thu, 18 Jul 2024 22:30:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 拆分前后编码之间的差异</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6niua/d_differences_between_encoding_before_and_after/</link>
      <description><![CDATA[在机器学习中处理分类数据时，编码过程是将分类特征转换为适合建模的格式的关键步骤。了解应用编码和拆分数据集的顺序如何影响模型的性能和数据表示的完整性至关重要。哪种方法更可取：在将数据集拆分为训练集和测试集之前还是之后应用编码？    提交人    /u/Appropriate-Wave-252   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6niua/d_differences_between_encoding_before_and_after/</guid>
      <pubDate>Thu, 18 Jul 2024 22:03:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 生成高维（>100k 列）、稀疏合成数据的策略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6k3m9/d_strategies_for_generating_highdimensional_100k/</link>
      <description><![CDATA[我正在尝试实现一篇论文，该论文提出了对估计算法的修改，以便挖掘稀疏、高维数据集。 这篇论文很旧，我无法找到作者使用的所提到的真实世界数据集。他们确实使用某些方法生成了合成数据集，但我确信在过去的 20 年里，高维合成数据生成的最新技术已经得到了改善。 我研究过 scikit-learn 的 `make_classification()` 方法和其他一些深度学习方法，但这些方法似乎都难以生成高维数据。 是否有可以以内存高效的方式生成稀疏、高维合成数据集的方法？ 我意识到这是一个相当模糊的问题，很乐意澄清我的用例。我甚至愿意将我的问题修改为可能更实用的内容。这是我第一次尝试实现这样的事情，所以我不知道会发生什么。    提交人    /u/SnooApples8349   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6k3m9/d_strategies_for_generating_highdimensional_100k/</guid>
      <pubDate>Thu, 18 Jul 2024 19:39:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 预测性维护的机器学习——最佳实践？过时的方法？该做什么和不该做什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6ix0q/d_ml_for_predictive_maintenance_best_practices/</link>
      <description><![CDATA[我在很多搜索中都看到了“相似性学习”，但我想我会在这里问-- 基本上，是否有人使用传感器数据来完成预测设备故障的任务。寻求以下方面的建议：  异常检测和故障预测的最佳模型 处理来自多个传感器的时间序列数据 估计剩余使用寿命 结合不同 ML 技术的有效方法  有类似项目的经验吗？什么方法有效？    提交人    /u/LyPreto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6ix0q/d_ml_for_predictive_maintenance_best_practices/</guid>
      <pubDate>Thu, 18 Jul 2024 18:51:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] NER 的最佳方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6i9dh/d_best_approach_to_ner/</link>
      <description><![CDATA[我认为自己在这个领域有点菜鸟，所以我希望从这篇文章中学习和理解得更好。  我编写了一个遍历文件系统并将文件传递给 Apache tika 的 Python 应用程序，Apache tika 将其支持的扩展中的内容传递给最终会找到 NER 的函数，该函数基本上用于识别和分类文件内容。 我使用了 spacey，但发现其标记实体输出的准确性不如我希望的那样准确，我理解可以自定义训练模型以提高准确性，但如果该工具要在不同的文件系统和不同的结构化用户数据上使用它，则可能意味着重新训练模型以适应每个用例。  然后，我尝试使用来自 ollama 的 LLM 和一个 Python 库向 ollama 服务器发出请求，我尝试了几个模型，mistral 和 orca-mini 和设计一个提示以在传递的内容中查找特定的 NER，并输出找到的实体的响应，这样我就可以得到与 spacy 类似的结果。  我发现准确度要好得多，但完成所需的时间令人震惊。 例如：我使用 Faker 在 pdf、CSV、RTF、DOCX 等中创建随机数据……用于测试目的，spacy 能够在几秒钟内处理 16 个 20 KB 的文件，上述 LLM 方法使用 mistral 花费 26 分钟，在 orca mini 上花费 15 分钟。  我理解 LLM 模型要大得多，需要更多的计算，而运行 spacy 和 NER 任务可能超出了它们的能力，但我正在努力寻找平衡。一种具有实际性能输出的通用 NER 方法。 还有其他项目或经过训练的模型可能适合这项任务吗？还是我做错了？    提交人    /u/Hungry-Jackfruit-265   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6i9dh/d_best_approach_to_ner/</guid>
      <pubDate>Thu, 18 Jul 2024 18:25:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我正在为几个任务训练视觉模型，然后我决定通过视觉提示将基础模型“串联起来”。这是纯粹的炒作吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6h0e8/d_i_was_training_vision_models_for_several_tasks/</link>
      <description><![CDATA[(视觉)提示和基础模型真的可以用于工业级应用吗？ 我正在“连接”基础模型（用于视觉），并慢慢意识到我实际上正在做视觉提示（在它们之间）。但是，除了这个关于从系统角度进行视觉提示的相当有趣的观点外，我没有找到太多关于这方面的信息。 有人使用或遵循过这条路线吗？    提交人    /u/btcmx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6h0e8/d_i_was_training_vision_models_for_several_tasks/</guid>
      <pubDate>Thu, 18 Jul 2024 17:27:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] ML 系统设计：450 个值得学习的案例研究（Airtable 数据库）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6gdsk/p_ml_system_design_450_case_studies_to_learn_from/</link>
      <description><![CDATA[大家好！想分享来自 100 多家公司的 450 个 ML 用例的数据库链接，这些用例详细介绍了 ML 和 LLM 系统设计。您可以按行业或 ML 用例进行筛选。 如果这里有人着手设计 ML 系统，我希望你会发现它很有用！ 数据库链接：https://www.evidentlyai.com/ml-system-design  免责声明：我是 Evidently 背后的团队成员，这是一个开源 ML 和 LLM 可观察性框架。我们整理了这个数据库。    提交人    /u/dmalyugina   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6gdsk/p_ml_system_design_450_case_studies_to_learn_from/</guid>
      <pubDate>Thu, 18 Jul 2024 17:01:17 GMT</pubDate>
    </item>
    <item>
      <title>[N] Fish Speech 1.3 更新：增强稳定性、情感和语音克隆</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6g122/n_fish_speech_13_update_enhanced_stability/</link>
      <description><![CDATA[我们很高兴地宣布，Fish Speech 1.3 现在提供了增强的稳定性和情感，并且只需 10 秒 的音频提示即可克隆任何人的声音！作为开源社区的坚定倡导者，我们今天开源了 Fish Speech 1.2 SFT，并引入了自动重新排名系统。敬请期待，因为我们很快就会开源 Fish Speech 1.3！我们期待收到您的反馈。 Playground（DEMO）：http://fish.audio GitHub：fishaudio/fish-speech    提交人    /u/lengyue233   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6g122/n_fish_speech_13_update_enhanced_stability/</guid>
      <pubDate>Thu, 18 Jul 2024 16:46:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] 训练 LLM 引用预训练数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e6fxgj/r_training_llms_to_cite_the_pretraining_data/</link>
      <description><![CDATA[我们的工作被 COLM 接受，并认为值得在此分享： &quot;源感知训练实现语言模型中的知识归因&quot; TL;DR: 通常，LLM 在训练期间会学习很多东西，但不记得从哪里学到的。本文是关于教 LLM 从预训练数据中引用他们的知识来源。这可以使模型更透明、更容易理解和更可靠。我们提出了一个两步过程：1) 使用文档 ID 注入进行预训练和 2) 指令调整。第一阶段教模型将知识片段链接到特定的预训练文档。第二阶段教模型如何在生成答案时引用这些文档。 🔗 论文：https://arxiv.org/abs/2404.01019 代码：https://github.com/mukhal/intrinsic-source-citation    提交人    /u/moyle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e6fxgj/r_training_llms_to_cite_the_pretraining_data/</guid>
      <pubDate>Thu, 18 Jul 2024 16:43:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 代理工作流程的人为干预</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e68up3/r_human_intervention_for_agentic_workflow/</link>
      <description><![CDATA[我最近探索了 OpenAGI 框架的一个新增功能：任务规划期间的人为干预。此功能允许自主 AI 代理从人类那里征求澄清或附加信息，从而提高任务准确性和效率。 我已将其集成到我的工作流程中，用于反馈和报告生成，结果令人印象深刻。与 crewAI 不同，任务规划准确性有时会下降，OpenAGI 的方法被证明更可靠。 我很想听听你的经验。 在 GitHub 上探索它：GitHub - github.com/aiplanethub/openagi    提交人    /u/trj_flash75   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e68up3/r_human_intervention_for_agentic_workflow/</guid>
      <pubDate>Thu, 18 Jul 2024 11:14:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 3090 上进行训练时出现异常行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e650gq/d_strange_behaviour_with_training_on_3090/</link>
      <description><![CDATA[我正在训练源分离模型，更具体地说，我正在微调一个模型。来自此 repo  问题是这样的：我尝试微调的原始检查点的 SDR 值约为 11。当我开始微调时（尽管批次大小只有 1，而原始批次大小为 16），第一个 epoch 完成后，我的 SDR 值为 0.0016 左右。然后下一个 epoch 大约是 3，然后下一个是 6，然后它逐渐上升到 6-7。 这不应该发生 - 从第一个 epoch 开始，SDR 就应该接近原始值（11）。 我为什么这么认为？该 repo 还允许您在没有训练的情况下验证 SDR 的检查点 - 当我再次验证 0.0016 SDR 检查点时，它告诉我 SDR 实际上大约是 11，就像它应该的那样。但在训练期间，它要小得多。 作者告诉我这可能是 Pytorch 的问题，但即使在最新版本上，问题仍然存在。不管怎样，我已经在云 A6000/A100/H100 上进行了完全相同的训练，问题不存在。从第一个 epoch 开始，SDR 值就完全正常了。 这只是 3090 不够用还是某处有错误？所有其他损失值也在正常范围内。    提交人    /u/lucellent   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e650gq/d_strange_behaviour_with_training_on_3090/</guid>
      <pubDate>Thu, 18 Jul 2024 06:53:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] Spider2-V：多模式代理距离实现数据科学和工程工作流程自动化还有多远？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e5qt1r/r_spider2v_how_far_are_multimodal_agents_from/</link>
      <description><![CDATA[多模式 AI 代理的新基准，专注于现实世界的 Dara 工程任务。 项目页面：链接，论文：链接，代码：链接。  TLDR：自主 LLM 代理无法取代数据工程师……目前如此。但至少我们可以跟踪进度 🫡 概述： 随着 AI 技术变得越来越先进，我们需要越来越复杂的基准来评估系统的质量和衡量进度。出现了一个独特的基准分支，专注于使用专业工具/应用程序和网站（参见WorkArena、WebArena、OSWorld）。 在 Spider2-V 项目中，正在创建一个基准来评估数据工程中的 AI 代理。它包含 494 个任务，涵盖整个工作周期：  数据仓库（Snowflake、BigQuery 等工具） 数据提取（例如 Airbyte） 数据转换（例如 dbt） 数据可视化（例如 Superset、Metabase） 数据编排（例如 Airflow、Dagster）  （以及心爱的 Excel 文件，因为谁能没有它们？） 如果您有数据工程经验，您就会明白这是一个庞大的集合，尽管它没有涵盖您可能遇到的所有解决方案。 准备每个任务平均需要 4 个小时，因此它们非常原子化，不需要很长的视野思考。任务分为三个难度等级：  简单（20%，不超过 5 步即可解决） 中等（63%，6-15 步） 困难（17%，16-40 步）  所有任务均基于 DE/DS 教程，由人工标注员从网络上获取。可以说它们代表了真实的用例。简单任务示例：  将当前 Google Drive 文件夹下的数据加载到打开的 BigQuery 数据集的新表 “data1” 中  或者中等难度的任务：  从 GitHub 安装 dbt-cloud-cli，并将二进制文件解压到与 dbt 项目 “analytics” 相同的文件夹中  为了解决任务，LLM 代理可以访问 IDE 和浏览器（已设置账户）。模型使用 pyautogui 生成 Python 代码以与虚拟机的 UI 交互，然后执行代码，并逐步重复该过程。  猜猜 GPT-4 完成了多少任务？ 只有 14%！这个数字似乎很低，但可以突出显示更成功的集群——40% 的简单任务和 25% 的数据可视化任务都得到了解决。 除了专有模型外，还测试了开放模型 (LLAMA 3 70B、Mixtral 8x7B)，但由于它们不是多模态的并且不接受图像作为输入，因此仅向它们显示了屏幕的文本描述。这大大降低了它们的指标——它们只解决了一小部分任务。然而，我们热切期待 LLAMA-3 405B，据传它是多模态的，将于 7 月 23 日发布。  我非常渴望看到 GPT-5 发布时发布的基准指标——然后我们拭目以待！押注下一代模型将解决多少百分比的任务！     由    /u/stalkermustang 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e5qt1r/r_spider2v_how_far_are_multimodal_agents_from/</guid>
      <pubDate>Wed, 17 Jul 2024 19:20:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>