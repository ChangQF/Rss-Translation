<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Tue, 16 Jul 2024 18:19:55 GMT</lastBuildDate>
    <item>
      <title>[D] DiT 实施失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4vi9h/d_failed_dit_implementation/</link>
      <description><![CDATA[      大家好， 作为我在研究机器人操作时，想训练一个 DiT。我试图让它过度拟合一个简单的 20k 样本 猫数据集 。我的实现类似于论文的“adaLN-Zero”版本（在 LayerNorm 上进行条件化），它有 12 个 DiT 块层、12 个头、隐藏大小为 768 和一个补丁大小为 2。因为图像只包含猫，所以条件化有点没用，因为样本都有相同的标签。我在将它过度拟合到 MNIST 上确实取得了不错的效果。 在 8xA100 上工作了一个小时后，我觉得它达到了瓶颈并很难克服它。 结果也很糟糕（图像是 1k 步采样）。我应该对这个数据集抱有更好的期望吗？我将非常感谢任何能帮助我的人🙏 这是repo（我很懒，使用了HuggingFace的DDPMScheduler，但计划在它工作时编写自己的） https://preview.redd.it/k9bdi93b8xcd1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=5d3b14d1a16d3f4e9c5fbe8049cec6e4c5d360a5 https://preview.redd.it/9bmstg8c8xcd1.png?width=818&amp;format=png&amp;auto=webp&amp;s=f08747c95b5148a04c42c12ee8462b9bd2c6d057    提交人    /u/Ok_Operation_2094   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4vi9h/d_failed_dit_implementation/</guid>
      <pubDate>Tue, 16 Jul 2024 18:07:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 假设 AGI 是可能的，我们是否有道德责任来协助它的出现？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4utwe/d_assume_agi_is_possible_do_we_have_an_ethical/</link>
      <description><![CDATA[这似乎是一个简单的问题，您觉得怎么样？ 如果这个问题被覆盖，我们该如何处理所有其他潜在问题？    提交人    /u/f0urtyfive   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4utwe/d_assume_agi_is_possible_do_we_have_an_ethical/</guid>
      <pubDate>Tue, 16 Jul 2024 17:40:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] Tricycle：从头开始完全从 Autograd 到 GPT-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4sz1e/p_tricycle_autograd_to_gpt2_completely_from/</link>
      <description><![CDATA[我想分享 Tricycle：一个我完全从头开始构建的快速、功能齐全的深度学习框架： https://github.com/bclarkson-code/Tricycle/。 到目前为止，最大的里程碑是在单个 RTX 3090 上 68 小时内在 23 亿个代币上训练 GPT-2(124M)，我正在努力进一步扩大规模。 整个库都是从头开始构建的，从 AutoGrad 引擎一直到 GPT-2，任何有一点 Python 经验的人都应该可以理解。我试图使代码尽可能简单而不隐藏任何东西，并且我添加了一个 wiki 来介绍我如何构建所有内容。 我很想听听你的想法！ 编辑：语法    提交人    /u/Efficient_Plankton_9   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4sz1e/p_tricycle_autograd_to_gpt2_completely_from/</guid>
      <pubDate>Tue, 16 Jul 2024 16:26:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我如何将我的 CS/ML/LLM 学术研究论文货币化？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4r1el/d_how_can_i_monetize_my_csmlllm_academic_research/</link>
      <description><![CDATA[我发表了几篇关于大型语言模型 (LLM) 的论文，并得到了社区的积极反馈。我的下两篇论文更实用，解决了现实世界的问题。一篇是关于代理的，另一篇是关于 RAG 的（有点）。老实说，接下来的两篇论文实际上是一些创业想法的秘诀，我不知道将它们作为研究论文免费发布是否会搬起石头砸自己的脚。一方面，作为一名学者，我关心的是免费传播知识和科学。另一方面，我希望能够从我的研究成果中受益，并有可能将其货币化。我是一名独立作者，所以我不必担心知识产权问题。此外，我现在是一名国际博士候选人，我不知道这会让创办公司/初创公司、吸引风险投资等方面的事情变得多么复杂。    提交人    /u/nderstand2grow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4r1el/d_how_can_i_monetize_my_csmlllm_academic_research/</guid>
      <pubDate>Tue, 16 Jul 2024 15:08:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文讨论：超越：生成模型的表现可以超越训练它们的专家</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</link>
      <description><![CDATA[大家好， 正如标题所示：我创建这篇文章是为了讨论最近发布的论文，该论文到目前为止引起了很多关注。我刚刚阅读了这篇论文，有一些问题。如果你也读过并喜欢这篇论文，我们聊聊吧！ https://arxiv.org/abs/2406.11741  设置对你来说清楚吗？作者是否也通过实验测试了定理 3 或定理 4？ 训练数据集中有多少专家/玩家？如果他们测试定理 4，他们是否会在特定玩家的游戏上训练集合的每个成员？ 他们如何鼓励定理 3 中的不相交集条件？ 等式 4 有一个拼写错误（两个术语相同）？     提交人    /u/South-Conference-395   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4q1a8/r_discussion_on_the_paper_transcendence/</guid>
      <pubDate>Tue, 16 Jul 2024 14:27:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] Cuda 12.5 Docker 容器错误。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4ps0k/d_cuda_125_docker_container_error/</link>
      <description><![CDATA[Cuda 12.5 的 Cuda 版本控制错误 我正在远程服务器上部署一个 docker 容器。服务器在 Cuda 12.5 上运行，而容器内我使用的是 pytorch 2.3.1+cu121（我猜它是从 transformers 库安装的）。 我收到以下错误： 无法加载库 libcudnn_ops_infer.so.8。错误：libcudnn_ops_infer.so.8：无法打开共享对象文件：没有此文件或目录 我有什么解决方案可以修复容器，而不是将服务器上的 cuda 版本恢复为 11.8。    提交人    /u/cedar_mountain_sea28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4ps0k/d_cuda_125_docker_container_error/</guid>
      <pubDate>Tue, 16 Jul 2024 14:16:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 模型手术：通过简单的参数编辑调节 LLM 的行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4l9xc/r_model_surgery_modulating_llms_behavior_via/</link>
      <description><![CDATA[我们很高兴介绍我们的新工作： 通过直接参数编辑来调节 LLM 行为。以推理级计算成本实现高达 90% 的解毒！ 对于我们想要避免的行为，我们使用线性分类器作为行为探针来对 LLM 的隐藏状态空间进行分类。然后，我们确定影响此行为的关键 LLM 参数，并通过转向行为探针来编辑这些参数。 我们在 RealToxicityPrompts 数据集上的实验表明，我们的方法可以将毒性降低高达 90%，在 ToxiGen 上降低 49%。我们的技术保留了 LLM 的核心功能，例如常识和推理，同时在解毒任务中表现出色。    提交人    /u/Anonymous_user0986   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4l9xc/r_model_surgery_modulating_llms_behavior_via/</guid>
      <pubDate>Tue, 16 Jul 2024 10:30:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 蛋白质语言模型揭示病毒模仿和免疫逃逸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</link>
      <description><![CDATA[我们被 ICML 24/ML4LMS 研讨会接受了，所以我想分享一下 :) &quot;蛋白质语言模型揭示病毒模仿和免疫逃逸&quot; TL;DR: 🧬 研究概述：病毒模仿宿主蛋白以逃避免疫系统的检测。我们使用蛋白质语言模型 (PLM) 来区分病毒蛋白和人类蛋白，ROCAUC 为 99.7%，准确率为 97%。 📊 见解：我们的研究表明，PLM 和生物免疫系统会犯类似的错误。通过识别和分析这些错误，我们可以深入了解免疫反应性以及开发更有效的疫苗和治疗方法的潜在途径。 我们还展示了一种新颖的、可解释的、多模式表格错误分析方法，用于理解任何问题的见解和错误，让我们了解深度学习语言模型/PLM 所犯错误的特征。 🔗 论文：https://openreview.net/forum?id=gGnJBLssbb&amp;noteId=gGnJBLssbb 代码：https://github.com/ddofer/ProteinHumVir 与我和海报见面（#116）在 ICML/ML4LMS 研讨会上！：https://openreview.net/attachment?id=gGnJBLssbb&amp;name=poster doi： https://doi.org/10.1101/2024.03.14.585057    提交人    /u/ddofer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e4k3oi/r_protein_language_models_expose_viral_mimicry/</guid>
      <pubDate>Tue, 16 Jul 2024 09:13:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] “创造性”解码策略怎么了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e42das/d_what_happened_to_creative_decoding_strategy/</link>
      <description><![CDATA[对于 GPT-2 以及当时的大多数模型，简单的贪婪解码极易快速生成重复且无意义的输出，需要使用许多技术，例如 top-p 采样、核采样、重复惩罚、n-gram 惩罚等。（例如 https://arxiv.org/pdf/1904.09751 ） 对于最近的 LLM，我没有使用任何这些技巧，相反，0 到 1 之间的任何温度似乎都可以正常工作。我观察到的唯一重复生成似乎是在数学推理中，当模型想要进行一些没有成功的穷举搜索时。  那么，所有这些自定义解码策略是否都已成为过去，我们不再需要担心退化内容生成？     提交人    /u/zyl1024   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e42das/d_what_happened_to_creative_decoding_strategy/</guid>
      <pubDate>Mon, 15 Jul 2024 18:35:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用生成树进行具有自我批评的任意属性条件分子生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e416fw/r_anypropertyconditional_molecule_generation_with/</link>
      <description><![CDATA[  由    /u/AlexiaJM  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e416fw/r_anypropertyconditional_molecule_generation_with/</guid>
      <pubDate>Mon, 15 Jul 2024 17:47:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于如何利用未知数据改进时间序列预测的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e40guh/d_ideas_on_how_to_improve_time_series_forecasting/</link>
      <description><![CDATA[大家好，我的公司决定添加一个分析套件作为我们产品的一部分，而我的任务是创建一个预测解决方案。 我的问题始于这样一个事实：我不知道我将获得什么数据。它可以是每月的财务汇总，例如收入，也可以是每日销售数据。 我目前使用 ETS、SARIMAX、Holt-Winters 和 N-beats 的实现（以防万一）。我使用扩展窗口进行自动超参数调整，然后选择具有最佳 MAPE 的模型。 至于预处理，我会删除非季节性的异常值，并在将数据提供给模型之前使用 Savitzky-Golay 过滤器。 关于如何让这一切不那么像万福玛利亚，有什么建议吗？    提交人    /u/Ok_Bottle2306   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e40guh/d_ideas_on_how_to_improve_time_series_forecasting/</guid>
      <pubDate>Mon, 15 Jul 2024 17:20:09 GMT</pubDate>
    </item>
    <item>
      <title>[N] Yoshua Bengio 的最新公开信回应了反对严肃对待 AI 安全的论点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3viby/n_yoshua_bengios_latest_letter_addressing/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3viby/n_yoshua_bengios_latest_letter_addressing/</guid>
      <pubDate>Mon, 15 Jul 2024 14:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您认为最佳的“检索增强生成”编排器是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3p5fx/d_best_retrieval_augmented_generation/</link>
      <description><![CDATA[因此，我目前正在开发一个包含 Gen AI 和适用于 gemini 1.5 flash 的 vertex ai 的项目，我计划为其添加一个 RAG 系统，并且我计划使用 MongoDB 作为矢量数据库以简化操作。现在，我正在尝试决定应该使用哪个编排器来为 RAG 系统加速开发。你们有什么建议？    提交人    /u/PsychologicalAd7535   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3p5fx/d_best_retrieval_augmented_generation/</guid>
      <pubDate>Mon, 15 Jul 2024 07:52:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于如何创建分层 LLM 工作流程的想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e3fpz4/d_ideas_on_how_to_create_a_hierarchical_llm/</link>
      <description><![CDATA[是否可以创建一个 AI 代理工作流，让 LLM A 可以来回与 LLM B 对话，例如 10 次，以迭代特定案例，并且仅在这 10 次通过后才返回响应？ 例如，如果我有一个严格提示的低温 LLM 1 和一个不太严格、更有创意的 LLM2。LLM2 批评 LLM1 并给出如何改进（迭代）的建议。您可以指定“重复”的次数，例如，运行 LLM 2 最多 6 次或 10 次或我设置的任何次数。 想法是创建一个解决方案，您可以在其中将“主管”置于“工人或工人”之上，并将其构建到 LLM 层次模型中。我正在尝试使用 SmythOS 来快速创建概念证明，但我甚至无法在两个 LLM 之间来回传递数据。对于我的特定需求，我必须构建一个具有一定数量重复的多级层次结构。 为了很好地呈现它： LLM1 - 为文章创建大纲 LLM2 - 撰写文章并交给 LLM3 审阅 LLM3 - 根据他的清单对其进行批判性审查。 如果一切都很好，就会产生最终的回应，如果不是，LLM 3 会指出需要改进的地方并将其交给 LLM 4 以征求批判性见解（LLM 4 是一种预先提示的 LLM，它将提供非常具体的见解或关注以特定方式传递的特定感觉/信息），然后它将整个脚本交还给 LLM2，LLM2 是唯一真正在写作的 LLM。该过程重复进行，直到满足 LLM3 或超过 X 次重复（其中 X 是您提前设置的）。  您将如何进行此操作？    提交人    /u/moonbunR   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e3fpz4/d_ideas_on_how_to_create_a_hierarchical_llm/</guid>
      <pubDate>Sun, 14 Jul 2024 23:09:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e34cwr/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jul 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>