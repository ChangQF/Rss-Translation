<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 26 Apr 2024 21:11:57 GMT</lastBuildDate>
    <item>
      <title>[D] 医疗管理如何改进？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdwmaa/d_how_can_healthcare_management_improve/</link>
      <description><![CDATA[我最近一直在思考这个问题： 医疗管理如何加强机器学习在医疗领域的实施和研究？  我对机器学习领域人们的观点非常感兴趣。我在这个子主题上看到了很多关于健康是开始机器学习职业最困难的领域的主题。我真的很想知道为什么会出现这种情况，以及哪里可以改进。   由   提交/u/Acceptable_Smoke_235   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdwmaa/d_how_can_healthcare_management_improve/</guid>
      <pubDate>Fri, 26 Apr 2024 21:06:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在公共档案中发现 EURISKO 和自动数学家 (AM) 的源代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cduk7k/p_source_code_for_eurisko_and_automated/</link>
      <description><![CDATA[博客文章：https://white-flame.com/am-eurisko.html EURISKO：https://github.com/white-flame/eurisko 在 Medley Interlisp 中运行 EURISKO：https://github.com/seveno4/EURISKO 自动数学家 (AM)：https://github.com/white-flame/am  &amp; #32；由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cduk7k/p_source_code_for_eurisko_and_automated/</guid>
      <pubDate>Fri, 26 Apr 2024 19:43:59 GMT</pubDate>
    </item>
    <item>
      <title>开源：自动数据排序工具 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdrahu/opensourced_automated_data_sorting_tools_p/</link>
      <description><![CDATA[您好r/MachineLearning， ​ 我很高兴分享一个项目，该项目最初旨在将 Windows 的自动化 AI 维护功能集成到我正在构建的用于商业销售的应用程序中，但现在已被开源供社区使用和开发。该项目专注于自动化数据排序，可以作为更高级机器学习应用程序的基础。 ​ 您可以在此处探索该项目：[NazTech 自动数据排序工具](https://github.com/nazpins/naztech-automated-data-sorting-tools) ​ 这些工具旨在快速自动对大型数据转储进行排序，采用适合处理大型数据集的 Python 算法。虽然从我的角度来看，该项目不再处于积极开发阶段，但 Python 脚本具有功能性，并且可以对您自己的 ML 项目感兴趣的任何改编或增强功能开放。我开始为实际应用程序构建框架，但由于时间限制和现实中发生的很多事情，我没有时间继续研究它。 ​ 不过，我很高兴与社区分享这些工具，并希望它们能够对其他人有所帮助。  干杯！ ​   由   提交 /u/Kilroy_GreyFox   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdrahu/opensourced_automated_data_sorting_tools_p/</guid>
      <pubDate>Fri, 26 Apr 2024 17:29:20 GMT</pubDate>
    </item>
    <item>
      <title>[D]您遵循什么命名法来命名 ML 模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdq5cd/dwhat_nomenclature_do_you_follow_for_naming_ml/</link>
      <description><![CDATA[大家好， 我正在为我们的团队集思广益，制定某种命名法，以便有一个命名 ML 模型的标准方法就像他们的泡菜文件一样。任何意见都将不胜感激。 谢谢   由   提交/u/BravoZero6  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdq5cd/dwhat_nomenclature_do_you_follow_for_naming_ml/</guid>
      <pubDate>Fri, 26 Apr 2024 16:42:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要建议：增强临床文本中 ADE 检测的 NER（论文工作）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdpt24/d_advice_needed_enhancing_ner_for_ade_detection/</link>
      <description><![CDATA[r/MachineLearning 社区您好，&lt; /p&gt; 我目前正在研究论文的第二部分，重点是用于检测临床文本中的药物不良事件 (ADE) 的命名实体识别 (NER)。在我的第一篇论文项目中，我尝试复制一篇论文，但不得不转向 n2c2 数据集，这给模型性能带来了挑战。 我已经用标准实践对 DeBERTa 模型进行了微调，但是我正在努力实现高精度，尤其是精确度和召回率。这是我第一次深入研究论文和 NLP 世界，任何指导都将非常感激。 此外，论文工作的任何常见陷阱或有关该主题的有用资源都将非常有帮助。我渴望向社区学习并改进我的研究。 非常感谢您抽出时间！   由   提交 /u/Popsuga   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdpt24/d_advice_needed_enhancing_ner_for_ade_detection/</guid>
      <pubDate>Fri, 26 Apr 2024 16:29:03 GMT</pubDate>
    </item>
    <item>
      <title>[R]大型语言模型可能无法对行为概率分布进行采样</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdpdci/rlarge_language_models_may_not_be_able_to_sample/</link>
      <description><![CDATA[      通过我们的实验，我们发现LLM智能体具有一定的理解概率分布的能力，LLM智能体的采样能力缺乏对概率分布的认识，仅通过LLM很难给出符合某种概率分布的行为序列。  我们期待您对此主题的想法、批评和讨论。全文及引用：您可以访问全文https://arxiv.org/abs/2404.09043。如果我们的工作对您的研究有所贡献，请引用我们的工作。 https://preview.redd.it/ai7uks7nluwc1.png?width=935&amp;format=png&amp;auto=webp&amp;s=891dd57ef50d1ee99b1a8b2372b9a460397754 d6   由   提交/u/GYX-001   /u/GYX-001 reddit.com/r/MachineLearning/comments/1cdpdci/rlarge_language_models_may_not_be_able_to_sample/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdpdci/rlarge_language_models_may_not_be_able_to_sample/</guid>
      <pubDate>Fri, 26 Apr 2024 16:11:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] GAN/对手自动编码器/循环 GAN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdpbsl/d_ganadversary_autoencodercycle_gan/</link>
      <description><![CDATA[主要目标：两个离散时间序列信号之间的风格转换。  详细信息如下： 数据集：离散时间序列。 1700 行，其中 97% 为零。无法删除这些零，因为它意味着什么。域 A 中的一个特征的值范围为 0-32，需要转换为域 B 中具有相同范围的另一个特征。域 A 中的另一个特征为 0-5000，需要转换为具有相同范围的不同域 B。我可以多次重新创建相同的数据集，但变化很小，因此我们可以拥有更大的数据集。我将创建大小为 20 或 30 的序列，批量为：32 或 64。 生成器网络：一个简单的编码器，具有线性层第一个隐藏大小：16、relu、第二个线性层：8 和 relu。对称解码器。 鉴别器：2 个线性层，隐藏大小为 8，它们之间有泄漏 Relu。 sigmoid 作为最后一层。损失函数：BCEloss。还试验了生成器的 BCE + MSE 损失。  培训：我正在使用 pytorch。仅使用一个特征/信号进行训练，并尝试从噪声中生成该特征。尚未转向循环一致性。通过小数据集训练，判别器变得太强，我什至尝试将判别器的学习率设置为 0.0001 ，将生成器的学习率设置为 0.01 ，但没有成功。尝试添加/复杂化生成器层，仍然不起作用。尝试每 10 个 epoch 训练一次鉴别器，而生成器则训练更多。没用。还尝试标准化数据。  我想探索 Adversarial autoencoder /cycle Gan ，但生成器也无法使用普通 GAN 学习任何内容。有人可以帮助我或给我一些关于我能做什么的想法吗？谢谢    由   提交 /u/investmentwholesome   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdpbsl/d_ganadversary_autoencodercycle_gan/</guid>
      <pubDate>Fri, 26 Apr 2024 16:09:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 压倒性的 LLM 释放率：寻求构建评估 LLM 测试集的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdn7da/d_overwhelming_llm_release_rate_seeking/</link>
      <description><![CDATA[大家好， 我正在尝试构建自己的测试集，以便对巨大的数据进行初步快速评估每周都会在huggingface.co上弹出的模型数量，我正在寻找一个起点或建议。 如果有人愿意分享一些他们用来测试LLM能力的问题，即使是高-水平概念，或者只是给我一些提示或建议，我真的很感激！ 提前感谢大家的回复。”   由   提交 /u/Distinct-Target7503    reddit.com/r/MachineLearning/comments/1cdn7da/d_overwhelming_llm_release_rate_seeking/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdn7da/d_overwhelming_llm_release_rate_seeking/</guid>
      <pubDate>Fri, 26 Apr 2024 14:43:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过回归相对奖励进行强化学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdl0em/r_reinforcement_learning_via_regressing_relative/</link>
      <description><![CDATA[https://arxiv.org/abs/2404.16767  新的深度 RL 算法，适用于语言模型和扩散模型。   由   提交/u/athens117  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdl0em/r_reinforcement_learning_via_regressing_relative/</guid>
      <pubDate>Fri, 26 Apr 2024 13:10:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 干净的字幕数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdimby/d_clean_caption_dataset/</link>
      <description><![CDATA[我正在尝试从头开始训练 CLIP。然而，缺乏可用的数据集。看起来相当多样化且干净的一个数据集似乎已被删除 (laion-400m)。看看 HF 数据集，这两个数据集很有前途，但想知道是否有更好/更干净的数据集。 - 概念性标题：使用替代文本。 - red_caps：reddit 线程，但这些大多是图像上的第一个评论，而不是实际的标题。 TIA   由   提交/u/themathstudent  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdimby/d_clean_caption_dataset/</guid>
      <pubDate>Fri, 26 Apr 2024 11:09:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士：为什么情境学习有效？从技术角度来看到底发生了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdih0a/d_llms_why_does_incontext_learning_work_what/</link>
      <description><![CDATA[无论我在哪里寻找这个问题的答案，得到的答案只不过是将模型拟人化而已。他们总是提出这样的主张：  如果没有示例，模型必须推断上下文并依靠其知识来推断出预期的结果。这可能会导致误解。 一次性提示通过提供具体示例来减轻这种认知负担，有助于锚定模型的解释并专注于具有更清晰期望的更狭窄的任务。  该示例充当模型的参考或提示，帮助其理解您正在寻求的响应类型并在训练期间触发对类似实例的记忆。&lt; /p&gt; 提供示例允许模型识别要复制的模式或结构。它为模型建立了一个对齐线索，减少了零样本场景中固有的猜测。  顺便说一句，这些是真实的摘录。 但这些模型不“理解”任何东西。他们不“推断”，或“解释”，或“聚焦”，或“记住训练”，或“猜测”，或有字面上的“认知负荷”。它们只是统计令牌生成器。因此，当寻求对上下文学习提高准确性的确切机制的具体理解时，像这样的流行科学解释是毫无意义的。 有人可以提供一个根据实际模型来解释事物的解释吗？架构/机制以及提供额外上下文如何带来更好的输出？我可以“说说而已”，所以请不遗余力地提供技术细节。 我可以做出有根据的猜测 - 在输入中包含示例，这些示例使用近似于您想要的输出类型的标记来引导注意力机制，并且最终的密集层对更高的令牌进行加权，这些令牌在某种程度上与这些示例相似，从而增加了在每个生成步骤中对这些所需令牌进行采样的几率；就像从根本上讲，我猜测相似性/距离的事情，其中​​明确举例说明我想要的输出会增加获得的输出与其相似的可能性 - 但我更愿意从对这些模型有深入了解的其他人那里听到它   由   提交 /u/synthphreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdih0a/d_llms_why_does_incontext_learning_work_what/</guid>
      <pubDate>Fri, 26 Apr 2024 11:01:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关键批量大小和法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdgxit/d_critical_batch_size_and_llms/</link>
      <description><![CDATA[在有关“小指南”的视频中到 2024 年构建大型语言模型” 41:38 作者开始讨论批量大小的限制。 ​  好吧，如果你当批量大小开始非常大时，每个优化步骤的模型都会降低每个令牌的使用效率，因为批量大小太大，以至于每个令牌在优化步骤中都会被淘汰。粗略地说，衡量这个限制有点困难，我们称之为临界批量大小。  我认为较大的批量大小对于训练 LLM 总是更好，因为： p&gt;  它更好地近似真实梯度。 我们更快地浏览数据集。 据我所知，限制仅在于基础设施、硬件、通信开销等.  我发现一篇论文介绍了“临界批量大小”概念 - 大批量训练的经验模型。它主要讨论大批量数据并行的速度/效率权衡。另一篇被高度引用的论文神经语言模型的缩放定律：  在临界批量大小下进行训练提供了时间和计算效率之间的大致最佳折衷  所以我不太明白视频作者的意思：  每个令牌是在优化步骤中有点被淘汰  除了基础设施、硬件或实现限制之外，大批量还有其他问题吗？   由   提交/u/kiockete  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdgxit/d_critical_batch_size_and_llms/</guid>
      <pubDate>Fri, 26 Apr 2024 09:21:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 面对不可能的机器学习问题，您有哪些恐怖经历</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ccz2cq/d_what_are_your_horror_stories_from_being_tasked/</link>
      <description><![CDATA[机器学习非常擅长解决一系列小众问题，但大多数技术细微差别都被技术兄弟和经理忽视了。您被告知要解决哪些问题是不可能的（没有数据、无用的数据、不切实际的期望）或机器学习的误用（您能让这个法学硕士做所有会计工作吗）。    由   提交 /u/LanchestersLaw   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ccz2cq/d_what_are_your_horror_stories_from_being_tasked/</guid>
      <pubDate>Thu, 25 Apr 2024 18:45:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 旧论文 - 机器学习奖学金中令人不安的趋势</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ccve1k/d_old_paper_troubling_trends_in_machine_learning/</link>
      <description><![CDATA[我只是想提醒或向新人介绍这篇论文。我认为应该重新开启这个讨论，因为这里的许多人确实影响了该领域的趋势。 https://arxiv.org/pdf/1807.03341  就个人而言（请随意跳过）： 具体来说，我想指出“数学性”的问题，因为这个问题似乎已经失控了，并且大多数会议的最佳论文都受到它的影响（其中一篇最重要的 ML 论文试图变得数学化并引入了一个大错误，我相信其他论文有更大的问题，但没有人费心去检查它）。 因此，以下是我对学者和研究人员的个人观点：  我们（我认为大多数人都会有同感），从业者，不需要方程式来知道什么是召回率，显然不想阅读难以理解的版本线性回归是什么，它只会让你的论文毫无用处。如果你不想浪费我们的时间，请把它放在附录中或完全删除它。 审稿人，请不要对不必要的数学印象深刻，如果它很复杂而且没有任何用处，谁在乎呢？此外，它可能存在缺陷，你可能不会发现它。     提交人    /u/pyepyepie   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ccve1k/d_old_paper_troubling_trends_in_machine_learning/</guid>
      <pubDate>Thu, 25 Apr 2024 15:50:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>