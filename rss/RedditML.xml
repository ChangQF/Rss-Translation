<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 12 Feb 2024 15:13:52 GMT</lastBuildDate>
    <item>
      <title>[P] 征求对 Graphbook 的诚实反馈，Graphbook 是一个交互式计算平台，可以直观地拆箱和编辑变压器模型以进行应用研究。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ap24gt/p_soliciting_honest_feedback_on_graphbook_an/</link>
      <description><![CDATA[   ​ https://preview.redd.it/g4oh19wy56ic1.png?width=5096&amp;format=png&amp; ;auto=webp&amp;s=fd1fa1350f86281ba56c6daa1609b410f5120c71 项目起源： 我和我的同事是 MLE/应用研究人员，并且经常对尝试在生产 NLP 用例中排除故障并定制 Transformer。这是从 BERT 在 Tensorflow1 上出现时开始的，当时你根本无法真正单步调试模型。澄清一下，当然，纯粹清理数据需要花费大量精力，但我们发现，通过深入研究模型架构，我们也可以更好地理解和解决问题。是的，TF1 是 5-6 年前的事，现在有了急切的执行和 PyTorch，这使得逐层查看数据变得更加容易，但共识似乎仍然很像做“手术”来进行编辑，这是随着新研究的扩展变得越来越重要。 另请注意，我们听说研究人员使用 Netron（25K+ 星github）来直观地调试事物，但抱怨它对于变压器架构来说非常有限，因为它是扁平的和只读的。 高级描述： 我们的项目 Graphbook 采用模型架构的可视化层次结构，并将其转换为交互式执行的拖放图（即图形）并让您查看每个变量的数据快照。它是一个 DAG，可让您直观地编排从模型输入到输出的数据流。每个操作要么是原始操作（通过 CUDA C++ 编程直接在 GPU 上运行），要么是复合操作，因此分解为子图。因此，这里的一些主要好处是，您无需迭代调试器即可查看每个变量的所有数据，并且当您进行更改时，它像 Jupyter Notebook 一样是交互式的（因此不会从头开始重新运行）。另一个主要好处是，您可以真正精细地钻取每个模型权重的读写，以便您可以观察每个权重的更新方式。除了模型设计器部分之外，Graphbook 还允许您训练和部署图表本身，因此 Graphbook 是模型设计器部分之上的 MLOps 工具。 youtube.com/watch?v=h-S4MdVn0XI&quot;&gt;短视频“商业广告”，其中提供了更多详细信息。 当前状态： &lt;该平台正处于“免费增值”版本的最后阶段，之后将是试用+订阅。我们正在发布预先训练的变压器图。我们现在能够相当快速地将模型从 PyTorch 和 HuggingFace 转移到 Graphbook。到目前为止，我们已经有了 BERT、GPT2、Flan-T5 和 Llama2，接下来我们正在研究 Mistral 和 Phi-2。  最终，我正在寻找有关我们正在做的事情的反馈和原始意见。我们在贸易展（MLOps World、NYC AI Summit，以及将在 Nvidia GTC 和 ODSC Boston）上与人们交谈时听到了各种各样的反应，但到目前为止还没有真正有机会联系到我认为 /machinelearning 可能拥有一个更大的专家和应用研究人员小组。抱歉，如果这篇文章过于促销。   由   提交/u/graphbook  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ap24gt/p_soliciting_honest_feedback_on_graphbook_an/</guid>
      <pubDate>Mon, 12 Feb 2024 15:08:47 GMT</pubDate>
    </item>
    <item>
      <title>构建地图预测模型 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ap1va4/build_a_map_prediction_model_r/</link>
      <description><![CDATA[大家好， 我有很多 3 维数据图（位置的 x、y 坐标和 z -每个点的值）。 它们都有点相似，看起来像这样：图片 现在，我想构建一个模型，可以仅根据 x、y 和 z 的几个输入向量来预测整个热图. 什么架构适合我的项目，训练应该如何进行？   由   提交 /u/PuzzledReception7725   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ap1va4/build_a_map_prediction_model_r/</guid>
      <pubDate>Mon, 12 Feb 2024 14:57:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在另一台计算机上运行机器学习模型，然后当我下载并尝试运行 sav pickle 文件时，收到错误消息“ModuleNotFoundError：没有名为 'keras.src' 的模块”？我知道我已将 keras 库导入到我的程序中。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ap1ctd/d_i_ran_a_machine_learning_model_on_another/</link>
      <description><![CDATA[我不能在其他计算机上运行 pickle 文件吗？我究竟做错了什么？    由   提交 /u/GlassWalkerKinfolk   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ap1ctd/d_i_ran_a_machine_learning_model_on_another/</guid>
      <pubDate>Mon, 12 Feb 2024 14:33:36 GMT</pubDate>
    </item>
    <item>
      <title>您对 hana-ml 库的看法？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ap100k/your_point_of_view_about_hanaml_library_d/</link>
      <description><![CDATA[嗨，我必须使用 SAP 库调用 hana-ml。您对此有何看法？ ML 算法/模式与最先进的算法具有相同的质量吗？ 感谢您未来的建议！   由   提交/u/lottot31  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ap100k/your_point_of_view_about_hanaml_library_d/</guid>
      <pubDate>Mon, 12 Feb 2024 14:17:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于推文分析的定制数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ap0ec6/r_customized_dataset_for_tweet_analysis/</link>
      <description><![CDATA[大家好 我想构建一个用于推文分析的自定义数据集。你们有人这样做过吗？工作流程应该是什么样的？该数据集将属于特定主题，但我的主管尚未最终确定该主题。他告诉我们要主动生成定制数据集。请帮助我。 您的好意建议将不胜感激。 谨致 Redwan  &amp;# 32；由   提交 /u/redwanhossain6333   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ap0ec6/r_customized_dataset_for_tweet_analysis/</guid>
      <pubDate>Mon, 12 Feb 2024 13:47:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] 拉皮赛</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ap0ap7/r_rapidsai/</link>
      <description><![CDATA[有人在他们的项目中使用过rapidsai吗？我刚刚了解它，但无法在 Jupiter Notebook 中使用它。如果有人可以指导我，我将非常感激。   由   提交 /u/PrateekAwate   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ap0ap7/r_rapidsai/</guid>
      <pubDate>Mon, 12 Feb 2024 13:42:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 医学数据注释器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aoyjvy/d_medical_data_annotator/</link>
      <description><![CDATA[您好！我是一名牙科学生，大约 7 个月以来，我一直在 DiagnosUs 应用程序上注释医学图像。我发现这很有趣，我渴望更深入地研究。想知道是否有人知道我在哪里可以找到更多这样的机会？由于我的临床背景和对医疗保健领域（尤其是牙科）人工智能的好奇心，我学得很快，并准备好投入其中。任何线索和建议都会很棒！谢谢！   由   提交/u/Professional_Win_347   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aoyjvy/d_medical_data_annotator/</guid>
      <pubDate>Mon, 12 Feb 2024 12:08:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自动编码器或变分自动编码器，用于与真实数据集相比查找数据集中的异常</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aowqce/r_autoencoder_or_variational_autoencoder_for/</link>
      <description><![CDATA[我有一个关于自动编码器 (AE) 或变分自动编码器 (VAE) 的一般性问题。我同时拥有真实世界数据集和合成数据集，我的目标是识别合成数据集与真实世界数据集相比的差异。虽然现有的研究重点是使用 AE 来检测数据集中的异常，但我特别感兴趣的是与真实数据集相比，检测合成数据集中的异常。我想知道是否有任何论文讨论这个问题。此外，我正在考虑使用真实数据集训练 AE，然后使用合成数据集对其进行测试，然后比较潜在空间的可能性。有没有人遇到过这种情况的相关文献或方法？    由   提交/u/Immediate-One-3259   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aowqce/r_autoencoder_or_variational_autoencoder_for/</guid>
      <pubDate>Mon, 12 Feb 2024 10:10:23 GMT</pubDate>
    </item>
    <item>
      <title>[D]架构超参数优化策略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aow8ri/d_architecture_hyperparameter_optimisation/</link>
      <description><![CDATA[我想知道是否值得对模型架构进行广泛的超参数调整。学习率调整通常会带来回报，因为这对收敛和整体性能有很大影响，但是在调整架构（num_layers、num_heads、dropout 等）时，我发现如果你保持在某个最佳范围内，实际性能差异是边缘。难道我做错了什么？您对此有什么经验？   由   提交 /u/Primary-Wasabi292    reddit.com/r/MachineLearning/comments/1aow8ri/d_architecture_hyperparameter_optimization/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aow8ri/d_architecture_hyperparameter_optimisation/</guid>
      <pubDate>Mon, 12 Feb 2024 09:35:53 GMT</pubDate>
    </item>
    <item>
      <title>[2402.06104]函数对齐回归：一种从数据中显式学习函数导数的方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aow5i4/240206104_function_aligned_regression_a_method/</link>
      <description><![CDATA[ 由   提交/u/Elven77AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aow5i4/240206104_function_aligned_regression_a_method/</guid>
      <pubDate>Mon, 12 Feb 2024 09:29:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些关于在生产中扩展经典 ML（GBM/RF）以实现极高吞吐量和低延迟的好资源或书籍？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aotfro/d_which_are_good_resources_or_books_on_scaling/</link>
      <description><![CDATA[哪些是关于在生产中有效部署经典机器学习以实现极高吞吐量的良好资源或书籍。假设每秒 100k 请求用于推理和计算需要低延迟。 我不会考虑在生产中扩展部署 Transfomer 或神经网络。但是用于经典化/回归的经典 ML 模型使用 Lightgbm、Xgboost、RF、SVM 等来实现此规模。 寻找有关提高模型效率以及推理数据 etl 效率等的资料来源。  p&gt; 我在互联网上找不到经典机器学习的资源。   由   提交/u/mrcet007  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aotfro/d_which_are_good_resources_or_books_on_scaling/</guid>
      <pubDate>Mon, 12 Feb 2024 06:20:49 GMT</pubDate>
    </item>
    <item>
      <title>[研究]利用神经网络改进气候模型的实例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aot670/research_example_of_using_neural_networks_to/</link>
      <description><![CDATA[分享一个使用神经网络进行海洋湍流建模的好例子。最近，科学家发现神经网络可以帮助模拟湍流，这是流体力学中尚未解决的问题之一。由于编写未解决的湍流通量方程一直是一项重大挑战，因此研究人员使用神经网络来“学习”这些方程。这些通量来自较高保真度模型（昂贵），并在较低保真度（便宜）模型中推断出相同的通量。在分享的文章中，作者改进了上层海洋的湍流模型，上层海洋是气候的关键区域。 https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023MS003890   由   提交/u/Environmental-Guy   /u/Environmental-Guy reddit.com/r/MachineLearning/comments/1aot670/research_example_of_using_neural_networks_to/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aot670/research_example_of_using_neural_networks_to/</guid>
      <pubDate>Mon, 12 Feb 2024 06:04:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] xgboost 如何处理时间序列？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aoo7gc/d_how_does_xgboost_work_with_time_series/</link>
      <description><![CDATA[有人可以解释一下 XGBoost 如何处理时间序列吗？ 我是数据科学领域的新手，看过某人的视频使用 XGBoost 预测未来的能源消耗，这让我感到惊讶，因为我认为基于树的方法很难进行外推（超出范围数据的常数值）。 我自己尝试过，并在验证集上得到了常数值。我做错了什么，在时间序列的背景下我对 XGBoost 有什么不理解？   由   提交/u/afrochamplooo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aoo7gc/d_how_does_xgboost_work_with_time_series/</guid>
      <pubDate>Mon, 12 Feb 2024 01:29:12 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何 Transformer 模型的收敛证明？ [D] | [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aol1tp/is_there_a_proof_of_convergence_for_any/</link>
      <description><![CDATA[我对围绕一般 NLP 问题（尤其是 Transformer）的收敛证明感兴趣。谁能给我指点一篇论文，证明 NLP 机器学习模型可以收敛到任何东西？  我在 NLP 实践中看到了一些验证，但是当我试图证明 Transformer 收敛到任何东西时，我很难凭直觉找到收敛的目标。    由   提交 /u/LazyHater   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aol1tp/is_there_a_proof_of_convergence_for_any/</guid>
      <pubDate>Sun, 11 Feb 2024 22:54:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>