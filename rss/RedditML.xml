<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 21 Apr 2024 15:13:02 GMT</lastBuildDate>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在机器学习中使用干净的架构和 DDD |深度学习项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jqo1/d_using_clean_architecture_and_ddd_in_machine/</link>
      <description><![CDATA[基本上是标题。有人使用干净架构和 DDD 的原则来构建深度学习或机器学习解决方案吗？如果是这样，您如何对域进行编码？您是否将像 PyTorch 这样的框架直接引入域和应用程序层？或者您是否尝试为训练过程编写抽象，并在第三个|上实现这些抽象？第四层？   由   提交 /u/Illustrious-Class-65   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jqo1/d_using_clean_architecture_and_ddd_in_machine/</guid>
      <pubDate>Sun, 21 Apr 2024 14:51:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用拥抱表情进行情感分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jq1g/p_sentiment_analysis_using_hugging_face/</link>
      <description><![CDATA[嗨， 我目前正在做一个网络文章情感分析项目。总的来说，我是 NLP 的新手，很想获得一些关于如何做到这一点的建议。目前，我有一个未标记的项目文章数据集。我最终想要实现的目标是将这些文章分为积极、消极和中立，并看看这种情绪随着时间的推移如何变化。我对此有一些问题：  标记数据集的最佳方法是什么？我目前的做法是使用通用的 BERT 模型进行初始分类，并使用这些标签来微调最终要使用的 Transformer 模型。 如何在 Hugging Face 平台上选择一个好的模型？ 代表情绪随时间变化的最佳方式是什么？  如果这些问题感觉很愚蠢，我很抱歉，但我找不到可靠的来源。如果我能就此获得一些建议和资源，那将会非常有帮助。   由   提交 /u/carliepep   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jq1g/p_sentiment_analysis_using_hugging_face/</guid>
      <pubDate>Sun, 21 Apr 2024 14:50:32 GMT</pubDate>
    </item>
    <item>
      <title>[P] Okkam - 使用 GA 查找适合任意数据集的多项式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jejf/p_okkam_find_polynomials_that_fit_arbitrary/</link>
      <description><![CDATA[与当前的 NN 元相比，这可能有点老派，但如果有人感兴趣，我已经编写了一个用于查找可配置多项式的工具CSV 中任意数据的参数（项数、指数位）。它使用可配置的基于锦标赛的 GA 算法来完成此操作，并提供一个 UI 来查看其进展情况。它是用 Rust 编写的，速度相对较快 - 尝试最大限度地利用所有可用的内核，因此可以很好地扩展。 如果您喜欢所看到的内容，我们将很高兴听到一些反馈或建议。在仓库上留下一个星星:) 仓库： Github&lt; /p&gt;   由   提交 /u/topcodemangler   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jejf/p_okkam_find_polynomials_that_fit_arbitrary/</guid>
      <pubDate>Sun, 21 Apr 2024 14:36:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为当地法学硕士寻求高级文本分析的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9itv9/d_seeking_recommendations_for_local_llms_for/</link>
      <description><![CDATA[大家好， 我目前正在探索使用大型语言模型 (LLM) 的高级文本分析功能，并寻求您的建议对于可以在本地运行的模型。我的设置包括配备 32 GB DDR5 的 RTX 4080 和 7800X3D 处理器，适合运行高要求的模型。 我对擅长深度文本理解且可供个人使用的法学硕士感兴趣本地机器。  有人有在复杂文本分析方面特别有效的本地法学硕士经验吗？您发现哪些模型有效？ 欣赏您的见解！   由   提交/u/tivied  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9itv9/d_seeking_recommendations_for_local_llms_for/</guid>
      <pubDate>Sun, 21 Apr 2024 14:11:22 GMT</pubDate>
    </item>
    <item>
      <title>机器学习研究中推荐算法/系统的现状如何？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9hr3b/whats_the_current_state_of_recommendation/</link>
      <description><![CDATA[大约 4 年前，当我第一次开始我的 ML 之旅时，我学到的最基本的入门级推荐算法是关于协作过滤和基于内容的过滤。 我想更多地了解推荐系统的当前状态。怎么变了？人们试图采用哪些方法来寻找更好的推荐？有没有提到在推荐系统中包含因果关系？后者似乎是最“最新”的进步，但我还没有找到概述。   由   提交/u/Direct-Touch469   reddit.com/r/MachineLearning/comments/1c9hr3b/whats_the_current_state_of_recommendation/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9hr3b/whats_the_current_state_of_recommendation/</guid>
      <pubDate>Sun, 21 Apr 2024 13:20:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 构建 TableOCR 工具的旅程。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9h6qn/d_journey_to_build_a_tableocr_tool/</link>
      <description><![CDATA[几个月前，我发表了一篇关于用于文档提取的 OCR 工具的帖子。从评论中，我能够探索相当多的工具，这些工具既令人难以置信，有时设置起来也有点烦人。 到目前为止，提取文档文本并没有真正的问题。通过使用 Deepdoctection、EasyOCR、PaddleOCR 等一些工具，我能够相当准确地提取文本及其布局。 现在面临下一个挑战。对于所有可用的工具，它们都具有表格提取功能。但是，对于我当前的用例，这些功能无法获得我想要的预期输出。 我现在在表格方面遇到的主要问题是表格何时合并单元格。我尝试了所有能找到的工具，并探索了表变压器。它能够提取表格（尽管有时会成功或失败），但它无法理解合并的单元格。 因此，我一直在尝试探索 TableOCR 工具的使用方式制成。我做的第一步是从文档/图像中提取表格。我已经微调了一个对象检测模型，该模型能够检测给定文档中的布局。它确实检测表格，因此我能够通过预测的边界框提取图像。我想进一步探讨的是确定表格是有边框还是无边框。到目前为止，我还没有看到任何好的数据集，所以我可能会创建自己的数据集。 提取表后，下一个任务是获取表的结构。我使用过 microsoft/table-struct-recognition 模型，它能够人为地创建给定表的结构。但同样，它不知道如何处理合并的单元格。在深入研究表格结构后，我想到，我该如何提取单个单元格的文本？我想我需要某种单元格检测模型来检测每个单元格，然后使用 OCR 模型逐一迭代它以预测该单元格内的文本。 为了说明我目前的理解：-&lt; br /&gt; 表检测模型==&gt;表结构识别==&gt;合并细胞固定器..？ ==&gt;细胞检测==&gt;字符 OCR？ 目前，我有点不知道该怎么做。对于一些背景信息，我目前正在提取与财务相关的文档。此外，我不得使用基于云的解决方案或任何类型的付费解决方案。一切都需要在本地进行。 （我没有设置此限制）。 如果有人对如何进行此操作有任何想法或对此有意见，请随时为该帖子做出贡献。 谢谢提前。   由   提交/u/FlyingRaijinEX   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9h6qn/d_journey_to_build_a_tableocr_tool/</guid>
      <pubDate>Sun, 21 Apr 2024 12:54:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何训练大量数据？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9au32/d_how_do_you_train_on_large_amount_of_data/</link>
      <description><![CDATA[我有大约 400 万篇报纸文章。我想训练词嵌入、主题建模。我买了 colab pro+，他们的高内存规格只有 60GB 左右的内存。  当我尝试在这些 4M 文章上训练任何内容时，运行时就会崩溃。我可以认为我们会从硬盘中批量加载数据并发送吗？我真的没有在这里的经验。我很想听听您的经验和建议。    由   提交 /u/RiseWarm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9au32/d_how_do_you_train_on_large_amount_of_data/</guid>
      <pubDate>Sun, 21 Apr 2024 06:07:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT 如何理解它不知道的东西？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c98pjl/d_how_does_gpt_understand_what_it_does_not_know/</link>
      <description><![CDATA[      https://preview.redd.it/kf5t2k95arvc1.png?width=625&amp;format=png&amp;auto=webp&amp;s=5631d9b49084 815d44c2178e1b27cfd4926f6f59 在我意识到之前，我要查找我打错的 Cramer 距离和 GPT 点。 GPT 如何理解输入可能是错误的，而不是总是假设输入是对的？这是否也是以端到端的方式完成的，或者如果有任何程序可以识别输入中可能的不确定性，那么还有哪些附加程序？ 我想一般来说我只是好奇如何GPT 知道它可能没有答案吗？   由   提交/u/No_Grapefruit_4686   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c98pjl/d_how_does_gpt_understand_what_it_does_not_know/</guid>
      <pubDate>Sun, 21 Apr 2024 03:57:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过想象力、探索和批评实现法学硕士的自我完善</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c97o2q/r_toward_selfimprovement_of_llms_via_imagination/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.12253 摘要：  尽管大型语言模型（LLM）在各种方面具有令人印象深刻的能力任务中，他们仍然在处理涉及复杂推理和计划的场景。最近的工作提出了先进的提示技术以及使用高质量数据进行微调以增强法学硕士推理能力的必要性。然而，这些方法本质上受到数据可用性和质量的限制。有鉴于此，自我纠正和自我学习成为可行的解决方案，采用的策略允许法学硕士改进他们的成果并从自我评估的奖励中学习。然而，法学硕士在自我完善其反应方面的有效性，特别是在复杂的推理和规划任务中，仍然值得怀疑。在本文中，我们引入了用于LLM自我改进的AlphaLLM，它将蒙特卡罗树搜索（MCTS）与LLM结合起来，建立一个自我改进循环，从而在无需额外注释的情况下增强LLM的能力。 AlphaLLM 从 AlphaGo 的成功中汲取灵感，解决了将 MCTS 与 LLM 相结合以实现自我提升的独特挑战，包括数据稀缺、语言任务的巨大搜索空间以及语言任务中反馈的主观性。 AlphaLLM 由即时合成组件、专为语言任务量身定制的高效 MCTS 方法以及用于精确反馈的三个批评模型组成。我们在数学推理任务中的实验结果表明，AlphaLLM 在无需额外注释的情况下显着增强了法学硕士的性能，显示了法学硕士自我改进的潜力。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c97o2q/r_toward_selfimprovement_of_llms_via_imagination/</guid>
      <pubDate>Sun, 21 Apr 2024 02:56:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] Tango 2：通过直接偏好优化调整基于扩散的文本到音频生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c95izw/d_tango_2_aligning_diffusionbased_texttoaudio/</link>
      <description><![CDATA[自动生成的成对偏好数据和 DPO 对齐改进了文本到音频的生成。 代码和数据集：https://github.com/declare-lab/tango 论文：https://arxiv.org/abs/2404.09956 模型：https://huggingface.co/declare-lab/tango2   由   提交 /u/sgpfc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c95izw/d_tango_2_aligning_diffusionbased_texttoaudio/</guid>
      <pubDate>Sun, 21 Apr 2024 01:00:04 GMT</pubDate>
    </item>
    <item>
      <title>[D]leetcode 在机器学习中有多重要？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8ygzl/d_how_important_is_leetcode_in_ml/</link>
      <description><![CDATA[我最近面试了一位应用数据科学家，面试过程是这样的： - 1x ML 面试 - 3x Leetcode 面试 - 1x 高级系统设计面试 leetcode对于ML/DS从业者的实际工作有多重要？ 3 个 leetcode 问题与 1 个 ml 问题有那么重要吗？ 当我在准备面试时，我只是觉得我在浪费时间做 leetcode，而我本可以在 ML 的其他领域甚至其他领域提升技能。 K8s、cuda 或数据工程等技术技能。  我有兴趣了解其他人对此的看法。   由   提交/u/Amgadoz  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8ygzl/d_how_important_is_leetcode_in_ml/</guid>
      <pubDate>Sat, 20 Apr 2024 19:36:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] Meta 的 H100 数据代表其根据 2024 年 2 月 1 日公司财报电话会议购买的 H100。不包括另外 250,000 个 H100 等值的 GPU。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8ydji/d_metas_h100_figure_represents_its_h100_purchase/</link>
      <description><![CDATA[   /u/ewelumokeke  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8ydji/d_metas_h100_figure_represents_its_h100_purchase/</guid>
      <pubDate>Sat, 20 Apr 2024 19:32:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 招聘时我应该在多大程度上重视传统机器学习知识？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8xgvp/d_how_much_should_i_emphasize_on_traditional_ml/</link>
      <description><![CDATA[我们正在招聘 nlp 高级机器学习工程师。  过去，我一直依赖标准的过滤问题。但我想知道这对于可能永远不会在项目中使用这些技术的新工程师来说是否不公平，以及这是否不再衡量工程师现在所做的事情。 我们确实有工艺演示的回声，其中我们询问相关的技术和技术问题。  但是想听听关于初始过滤的事情我想知道我是否应该停止询问： - 偏差与方差以及类似的训练“统计”概念 - 主题建模技术和类似的“旧 nlp” - 引导技术。 bagging 和类似技术 - 熵、杂质和其他“信息论”问题。  我们的团队无法达成共识。希望您的想法   由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8xgvp/d_how_much_should_i_emphasize_on_traditional_ml/</guid>
      <pubDate>Sat, 20 Apr 2024 18:54:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] Groq 上的 llama-3-70b 和代码解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c8uiwi/p_llama370b_on_groq_with_code_interpreting/</link>
      <description><![CDATA[       由   提交/u/mlejva  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c8uiwi/p_llama370b_on_groq_with_code_interpreting/</guid>
      <pubDate>Sat, 20 Apr 2024 16:48:50 GMT</pubDate>
    </item>
    </channel>
</rss>