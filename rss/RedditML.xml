<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Sun, 25 Aug 2024 09:14:43 GMT</lastBuildDate>
    <item>
      <title>[R] 什么是线性表示？什么是多维特征？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0s17s/r_what_is_a_linear_representation_what_is_a/</link>
      <description><![CDATA[论文链接  可解释性研究中有一组重要的直觉，可以追溯到著名的词嵌入结果，甚至更远。国王 - 男人 + 女人 = 女王。方向是有意义的单位。我们可以用向量算法来操纵表示。我们对叠加的研究很大程度上建立在这个基本的直觉之上，在此过程中，我们试图将这种直觉归结为“线性表示假设”。     提交人    /u/Regular-Donut3981   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0s17s/r_what_is_a_linear_representation_what_is_a/</guid>
      <pubDate>Sun, 25 Aug 2024 08:55:46 GMT</pubDate>
    </item>
    <item>
      <title>[N] 我们为法学硕士创建了人工智能同情心和 ToM 情商</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0qrpt/n_we_created_artificial_compassion_and_tom/</link>
      <description><![CDATA[      并且不需要相机或生物传感器。我的想法是，任何需要传感器的人都在测量马匹离开谷仓后的情绪，所有这些技术在不久的将来都将简化为对这些预测算法的简单验证。这是真正的心理预测理论处理，就像您知道您的另一半或家人或朋友将对特定刺激产生特定反应一样。您很快就能玩这个了。这个视频只是分享了我们加载算法作为概念证明后的第一个通用测试。我们即将把自我地图转储到模型中，这将使 OM 能够理解 Mary 和 Jayne 作为个体对相同生活场景的不同反应。当然，在这里解释这一切需要大量资料。我们已经等待了十多年才赶上来，所以这个发展可以在视频中出现。我逐字逐句地读了 LLM 的回复。 对于怀疑者，不，你们以前从未听说过我（我是自学成才，没有学术背景），尽管我是佐治亚理工学院 ATDC 的校友，并且拥有前世的几项专利。我有多本关于心智控制的书，这些书被多位美国海豹突击队队员认可为同类最佳的心智训练手册，我刚从 Stu 那里得到建议，我应该在意识科学会议上向经常参加该会议的诺贝尔奖获得者和超级天才展示我们的工作，所以请买好明年 7 月去巴塞罗那的机票。我的第一集 Sean Ryan 讨论了去年这些东西背后的科学，我们刚刚在周三开始着手让它发挥作用。（搜索 Sean Webb）    提交人    /u/IAMSpirituality   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0qrpt/n_we_created_artificial_compassion_and_tom/</guid>
      <pubDate>Sun, 25 Aug 2024 07:21:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我做了一个小项目，利用 LLM 进行财务分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0lae8/p_i_made_a_little_project_that_uses_llms_to/</link>
      <description><![CDATA[        由    /u/NextgenAITrading 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0lae8/p_i_made_a_little_project_that_uses_llms_to/</guid>
      <pubDate>Sun, 25 Aug 2024 01:43:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 边缘计算/联邦学习和 KAN 结合，能否提供一些研究和应用的范围或见解？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0ixra/r_edge_computingfederated_learning_and_kan/</link>
      <description><![CDATA[如何有效应对在联邦学习中实施 KAN 的挑战？数据异质性、灾难性遗忘和有限的计算能力是分布式环境中的真正挑战。您是否有任何想法或范围可以建议或任何论文？    提交人    /u/StopFrequent542   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0ixra/r_edge_computingfederated_learning_and_kan/</guid>
      <pubDate>Sat, 24 Aug 2024 23:41:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医疗 AI：顶级研究论文/模型🏅（2024 年 8 月 17 日至 8 月 24 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0fipu/d_last_week_in_medical_ai_top_research/</link>
      <description><![CDATA[   本周热门论文（8 月 17 日至 24 日）  医学多模态 LLM 的越狱  本文揭示了医学 MLLM 中的安全漏洞。针对 MedMLLM 的新“不匹配的恶意攻击”（2M 攻击）。它介绍了用于测试各种医疗场景的 3MAD 数据集  LLM 不是 零样本生物医学推理器  本文对生物医学任务上的 LLM 进行了基准测试，它在医学分类和 NER 上测试了 LLM，评估了标准提示、CoT、自洽性和 RAG  RuleAlign 框架：将 LLM 与医生规则对齐  本文介绍了用于医学诊断的 LLM 的 RuleAlign 框架。它将 LLM 与特定的诊断规则相结合，并开发基于规则的医学对话数据集。  CTP-LLM：用于临床试验转变预测的 LLM  本文介绍了用于临床试验预测的 CTP-LLM，它介绍了用于基准测试的 PhaseTransition (PT) 数据集。在所有阶段实现 67% 的准确率，从 III 期到批准的准确率达到 75%。  HIBOU：病理学的基础视觉转换器  本文介绍了病理学的视觉转换器，利用 DINOv2 框架在超过 100 万张全幻灯片图像 (WSI) 上预训练两种模型变体 Hibou-B 和 Hibou-L  LLaVA-Surg：多模式手术助手  LLaVA-Surg 引入了大规模手术视频指令调整数据集 Surg-QA，其中包含来自 2,201 个手术程序的超过 102K 个手术视频指令对，并训练了 LLaVA-Surg 模型。  ...  详细查看完整线程：https://x.com/OpenlifesciAI/status/1827442651810918509 感谢您的阅读！如果您知道任何遗漏的有趣论文，请随时在评论中分享。如果您对医疗 AI 有见解或突破，并希望在下周的版本中分享，请通过 Twt/x 与我们联系：OpenlifesciAI    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0fipu/d_last_week_in_medical_ai_top_research/</guid>
      <pubDate>Sat, 24 Aug 2024 21:01:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 生产中的机器学习：从数据科学家到机器学习工程师</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0fdih/p_ml_in_production_from_data_scientist_to_ml/</link>
      <description><![CDATA[我很高兴与大家分享我整理的一门课程：生产中的机器学习：从数据科学家到机器学习工程师。本课程旨在帮助您从 Jupyter 笔记本中获取任何 ML 模型并将其转变为可用于生产的微服务。 本课程涵盖以下内容：  将您的 Jupyter 代码构建为生产级代码库 管理数据库层 参数化、日志记录和最新的干净代码实践 使用 GitHub 设置 CI/CD 管道 为您的模型开发 API 容器化您的应用程序并使用 Docker 进行部署  我很乐意收到您对本课程的反馈。这是免费访问的优惠券代码：FREETOLEARN。您的见解将帮助我改进和完善内容。如果您喜欢本课程，我希望您留下好评，以便其他人也可以找到这门课程。谢谢，祝您学习愉快！    提交人    /u/5x12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0fdih/p_ml_in_production_from_data_scientist_to_ml/</guid>
      <pubDate>Sat, 24 Aug 2024 20:54:58 GMT</pubDate>
    </item>
    <item>
      <title>线性注意力——矩阵维数问题[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0e4u8/linear_attention_matrix_dimension_issue_r/</link>
      <description><![CDATA[      我正在阅读线性注意论文Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention。我对 eq(4) 和 eq(5) 中矩阵的维度感到困惑。作者说“用 i 给矩阵加下标会返回第 i 行向量”。我假设 \phi(\cdot) 是一个列向量。然后根据 eq(5)，V_j 必须是列向量，因为它必须左乘以 \phi。因此我假设 V_i 也是一个列向量。然而，eq(5) 最左边的项是 \phi^T，它是一个行向量。这似乎与我上面的想法相矛盾。  https://preview.redd.it/lr61kmu22okd1.png?width=1210&amp;format=png&amp;auto=webp&amp;s=e05296cf8073de618407a60cc744a449dc6c6f14    提交人    /u/mziycfh   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0e4u8/linear_attention_matrix_dimension_issue_r/</guid>
      <pubDate>Sat, 24 Aug 2024 19:58:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 训练和部署 JoJo - Tic Tac 特工 [适合新手]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f093av/p_training_and_deploying_jojo_a_tic_tac_agent/</link>
      <description><![CDATA[        由    /u/Particular_Tap_4002   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f093av/p_training_and_deploying_jojo_a_tic_tac_agent/</guid>
      <pubDate>Sat, 24 Aug 2024 16:17:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] Liger Kernel：一行代码使 LLM 培训速度提高 20%，内存减少 60%</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f0875c/p_liger_kernel_one_line_to_make_llm_training_20/</link>
      <description><![CDATA[        提交人    /u/Icy-World-8359   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f0875c/p_liger_kernel_one_line_to_make_llm_training_20/</guid>
      <pubDate>Sat, 24 Aug 2024 15:39:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] BLADE：数据驱动科学的基准语言模型代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f05t0t/r_blade_benchmarking_language_model_agents_for/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f05t0t/r_blade_benchmarking_language_model_agents_for/</guid>
      <pubDate>Sat, 24 Aug 2024 13:52:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 整理了一份 70 多篇研究论文的清单，供大家深入探讨</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f01yn2/p_curated_a_list_of_70_research_papers_for/</link>
      <description><![CDATA[        由    /u/Particular_Tap_4002   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f01yn2/p_curated_a_list_of_70_research_papers_for/</guid>
      <pubDate>Sat, 24 Aug 2024 10:15:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过估计数据分布比率进行离散扩散建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ezyunc/r_discrete_diffusion_modeling_by_estimating_the/</link>
      <description><![CDATA[文本扩散模型现在终于达到了 GPT2 的文本质量。 https://arxiv.org/abs/2310.16834（本文荣获 ICML2024 最佳论文奖！） 您认为扩散语言模型（扩散 LLM）会赶上自回归 LLM 并可能成为下一个 ChatGPT 吗？我们很快就会看到扩散 LLM 的缩放定律吗？与自回归 LLM 相比，这些模型具有一些关键优势，例如能够在任何地方接受提示 - 在输入的开始、中间、结束甚至拆分。此外，它们原则上可以一次生成多个标记。 这篇论文内容非常密集且数学繁重，所以我制作了一个动画解释视频，供任何感兴趣的人观看。 https://youtu.be/K_9wQ6LZNpI 我的看法：我认为这种方法在理论上可以扩展，但存在一个重大挑战：我们已经在 GPT/自回归变压器的硬件和软件优化方面投入了大量资金。考虑到沉没成本谬论，很难想象科技巨头会放弃他们目前的 LLM 来开始训练扩散 LLM，尤其是因为他们可能需要数年时间才能赶上 ChatGPT 和类似模型。就像 MAMBA 一样，我担心离散扩散也可能会输掉硬件/软件抽奖。    提交人    /u/AICoffeeBreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ezyunc/r_discrete_diffusion_modeling_by_estimating_the/</guid>
      <pubDate>Sat, 24 Aug 2024 06:32:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] TurboEdit：即时基于文本的图像编辑</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eztooi/r_turboedit_instant_textbased_image_editing/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eztooi/r_turboedit_instant_textbased_image_editing/</guid>
      <pubDate>Sat, 24 Aug 2024 01:33:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1euyfi6/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 18 Aug 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>