<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Thu, 27 Feb 2025 21:16:11 GMT</lastBuildDate>
    <item>
      <title>[d]建造ML/AI/VR开发学院实验室</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izixwy/d_the_building_of_a_mlaivr_development_college_lab/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我的大学最近获得了将近9000万印度卢比（约900万印度卢比或103,057美元）的资金，我们计划设置一个致力于机器学习，人工智能和虚拟现实开发的实验室。我非常感谢有关为该计划投资的最佳设备和软件的建议，见解或建议。预先感谢您的帮助！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1izixwy/d_the_building_of_a_a_mlaivr_develodment_college_lab/  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1izixwy/d_the_building_oof_a_mlaivr_develodment_college_college_lab/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izixwy/d_the_building_of_a_mlaivr_development_college_lab/</guid>
      <pubDate>Thu, 27 Feb 2025 15:53:16 GMT</pubDate>
    </item>
    <item>
      <title>[r]超越点产品：带有学习相似之处的检索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iziusf/r_beyond_dot_products_retrieval_with_learned/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  矢量数据库的世界正在爆炸。在大型语言模型的兴起以及对语义搜索的越来越多的需求下，从大规模数据集中获得信息的有效检索变得至关重要。大约最近使用点产品相似性和最大内部产品搜索（MIPS）算法的大约最近的邻居（ANN）搜索一直是该领域的主力。但是，如果我们可以超越点产品的局限性并直接学习相似之处，该怎么办？一份引人入胜的新论文，“  检索学到的相似性”       bailu ding（Microsoft）和Jiaqi Zhai（Meta）（在www &#39;25会议的会议记录中）提出了一种新颖的方法，称为逻辑（MOL），该方法为学习的相似性功能提供了一种通用界面。它不仅在建议系统和问题答案中取得了最新的结果，而且还显示出明显的延迟改善，有可能重塑矢量数据库的格局。 完整的纸张在这里写下： https：//www.shape.ai/blog/blog/blog/beyond-dot-dot-dot-drieval-drieval-with-with-with-with-with-lear-learned-learned-similarities     /u/u/skeltzyboiii     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iziusf/r_beyond_dot_products_retrieval_with_learned/</guid>
      <pubDate>Thu, 27 Feb 2025 15:49:33 GMT</pubDate>
    </item>
    <item>
      <title>[P]神经论文的语义搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izgxtb/p_semantic_search_of_neurips_papers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我做了一个语义搜索器 https://www.papers.app来源。 贡献是欢迎贡献的，例如添加更多会议或功能（当前具有Neurips，ICML，Aistats，Colt，Corl，Corl，ICGI）。   它是如何工作的？  使用HuggingFace中的GTE-SMALL嵌入所有摘要，查找以超过80％的匹配返回所有论文。  &lt;！&lt;！ -  sc_on-&gt; 32;&gt; 32;提交由＆＃32; /u/mgamal96     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izgxtb/p_semantic_search_of_neurips_papers/</guid>
      <pubDate>Thu, 27 Feb 2025 14:24:43 GMT</pubDate>
    </item>
    <item>
      <title>[D]语法和指导问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izfqjm/d_grammar_and_guidance_question/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi， 我创建了一个在技术域中生成数据的聊天机器人。  这些技术数据输出嵌入了JSON元数据中。  我知道我可以使用结构化输出或语法，但是我认为LLM只能使用JSON数据来回答，因为似乎会丢弃任何其他消息。我认为对吗？  因此，我希望能够生成JSON数据，并能够用解释已实现的内容回复。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/main_path_4051      [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izfqjm/d_grammar_and_guidance_question/</guid>
      <pubDate>Thu, 27 Feb 2025 13:26:53 GMT</pubDate>
    </item>
    <item>
      <title>[r] FFTNET：线性时间全局令牌通过自适应光谱过滤混合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izc94i/r_fftnet_lineartime_global_token_mixing_via/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  非常有趣的论文，显示了FFT在保持性能的同时如何替换变形金刚中的自我注意力。关键想法是使用快速的傅立叶变换来混合令牌之间的信息，而不是计算全部注意力矩阵。 主要技术点： - 替换二次复杂性自我关注自我关注与线性复杂性FFT操作 - 使用基于FFT的混合层 - 使用基于FFT的混合层，这些混合层可将频率域和后部转换为频率的频率范围 - 通过频率进行频率 - 在频率上进行频率 - 通过频率进行频率 - 范围 - 通过频率 - 范围 - 通过频率进行频率 - 依赖频率 - 依从性 - 依赖频率 - 依赖 - 标准变压器 关键结果： - 匹配或超过标准基准上的自我注意力表现 - 在长序列任务上表现出尤其有力的结果 - 从O（n²）减少了内存使用范围 - 跨越跨模态（视觉，语言，时间序列） - 有效地对更长的序列 进行量表，可以更效率地进行变形。在保持线性复杂性的同时保持较长序列的能力可以实现新的应用程序。 FFT方法也可能有助于我们更好地了解自我注意力的实际学习。 但是，我认为有关在很小的数据集或极大的语言模型上的表现有一些开放的问题，需要进行更多的调查。该方法还可能会错过某些明确关注的模式。  tldr：FFT可以有效替代变形金刚中的自我注意力，从而在保持性能的同时将复杂性从二次降低到线性。跨多个领域的作品，并显示出长序列的特殊希望。 完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izc94i/r_fftnet_lineartime_global_token_mixing_via/</guid>
      <pubDate>Thu, 27 Feb 2025 09:53:45 GMT</pubDate>
    </item>
    <item>
      <title>[D]想法：机器学习高尔夫？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izbgf2/d_idea_machine_learning_golf/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎在ML世界中进行的许多工作都集中在较小或更快的模型上，这些模型仍然有效，而这些模型仍然有效。在某些方面，这让我想起了代码高尔夫的实践：一个挑战，人们写了最小的程序来解决某个问题。 这样，我有了ML高尔夫的想法，这是一个友好的竞争设置，一个人必须创建一个最小的模型，仍然可以解决某个问题，以解决某个问题，例如在例如。 number of learnable parameters, or the number of bytes to store these parameters, probably including the program to load and run the model on a sample. It seems like someone did think of this before, but the problems seem contrived and unrealistic even compared to像Mnist这样的东西，因为看起来他们更旨在让人手工“编程”神经网络。它似乎也排除了可能很有趣的其他ML方法。 我想知道这是否是其他人可能感兴趣的。我觉得这可能是一个有趣的（S集）挑战，甚至与SOTA相比，由于任何涉及的型号的人都可以感兴趣。&gt;   是否会相当易于使用。       。实际上，我个人几乎没有ML背景，因此，其他比我更了解的人的意见将不胜感激。例如，有关如何运行/设置的想法，可能包括的数据集/基准，最大尺寸或最低性能等等等等等等。提交由＆＃32; /u/u/scheurneus     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izbgf2/d_idea_machine_learning_golf/</guid>
      <pubDate>Thu, 27 Feb 2025 08:54:18 GMT</pubDate>
    </item>
    <item>
      <title>[d]产品图像的建议比较控制仓库盗窃</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iz9cod/d_recommendation_for_products_images_comparison/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以我有很多选择器。我们从客户那里购买东西，Picker去拿起它并将其放在仓库中。但是，已经有很多偷窃和篡改产品。即使有时他们会通过放置相同的名字来替换昂贵的东西，并用当地的东西代替。 我想要的东西像Picker必须在客户门口和仓库中拍摄所有角度的产品形式，然后使用这些图像，然后使用这些图像，我可以获得是否已篡改prouduct的信息是否已篡改…   pls建议我的某些解决方案。只要给我正确的结果并减少盗窃。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/forky_friendship_557     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iz9cod/d_recommendation_for_products_images_comparison/</guid>
      <pubDate>Thu, 27 Feb 2025 06:18:59 GMT</pubDate>
    </item>
    <item>
      <title>[P]训练您自己的推理模型-GRPO仅在5GB VRAM上工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iyv12c/p_train_your_own_reasoning_model_grpo_works_on/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿[ r/machinelearning ]（）（）folks！非常感谢2周前我们的GRPO版本的支持！我们设法使GRPO仅在Qwen2.5（1.5b）的 5GB的VRAM 上工作 - 从上一个Untsloth版本中的7GB下降： https：&gt; https：&gt; the RL recipe behind DeepSeek-R1 Zero&#39;s reasoning, and you can now do it with 90% less VRAM via Unsloth + LoRA / QLoRA!  Due to our newly added Efficient GRPO algorithms, this enables 10x longer context lengths while using 90% less VRAM vs. every other GRPO LoRA/QLoRA具有0降解的实现。 具有标准的GRPO设置，Llama 3.1（8b）20K上下文长度的培训需要510.8GB的VRAM。但是，在同一设置中，Unsloth的90％VRAM减少将要求降低到 54.3GB 。 我们利用剃须372GB VRAM ，因为我们需要num \ _ generations = 8。我们可以通过中间梯度累积进一步减少此内存使用。 使用Google的免费上下文使用我们的GRPO Notebook，使用Google的免费gpus： href =“ https://colab.research.google.com/github/unslothai/notebooks/blob/blob/main/nb/llama3.1_(8B”&gt; llama 3.1（8b）on colab  -grpo.ipynb）以及更多： align =“ left”&gt; metric   unsploth   trl + fa2           training Moregre Cost（GB） align =“左”&gt; 414GB      grpo内存成本（gb）   9.8gb    78.3gb  78.3gb  78.3gb    0gb   16gb      推理20K上下文（GB）   2.5GB  2.5gb  Total Memory Usage 54.3GB (90% less) 510.8GB   Also we made a Guide (with pics) for everything on GRPO + reward functions/verifiers (please let us know of any suggestions): https://docs.unsloth.ai/basics/reasoning-grpo-and-rl Thank you guys once again for all the support.对我们来说意义重大！ ：d   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/danielhanchen     [links]   &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iyv12c/p_train_your_own_rowne_reasoning_model_grpo_grpo_works_on/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iyv12c/p_train_your_own_reasoning_model_grpo_works_on/</guid>
      <pubDate>Wed, 26 Feb 2025 18:51:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] Sugaku：基于数百万纸例子的培训的探索性数学研究工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iyv0jx/p_sugaku_ai_tools_for_exploratory_math_research/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经构建了 sugaku.net ，一个平台，旨在通过AI增强数学研究的平台。它将研究人员与相关论文联系起来，生成想法，并使用大量数学文献来回答问题。 Sugaku is the Japanese word for mathematics, and is a handle I&#39;ve been using for a long time. Try these examples:  询问Peper的内容  - href =“ https://sugaku.net/qna/a4e646bc-ce78-488f-b369-b369-b369-b7e006f767d1/”&gt;询问特定的研究人员  - href =“ https://sugaku.net/current/papergen/idea/719AED36-8DCD-4FD1-A171-B58261D3FC8E/&gt;生成假设的论文Metadata   -    - ＆quord; href =“ https://sugaku.net/oa/w4398767262/”&gt;浏览特定的论文建议 语义搜索，可以找到超出关键字的概念连接 使用矢量嵌入的类似纸张浏览 参考和合作者建议 研究想法生成            我为何建立了这一点：   我为什么要构建了这一点：     我通常会遇到意外的研究工具，但相关的是相关的连接。当搜索非明显但有价值的参考文献时，我尝试过的其他工具不足。我试图通过对纸元数据和超过700万篇论文和400万作者的参考图进行培训来解决这个问题，并定期通过当前更新。这似乎比我回到我先前关于L功能的博士学位研究和Riemann假设！ 数学研究语料库对AI培训特别有价值。它是相对独立和结构的，以学习预测参考的方式意味着该模型基本上学习了如何将问题分解为组成部分。通过此过程，系统将学习知识如何将新颖和正确的贡献结合在一起 - 可以很好地转移到帮助研究人员探索和产生新想法的技能。    技术实施：       构建在全面的培训方法上，以  vector  vector   vector    （不舒服，axolotl，直接火炬，洛拉斯，量化），通过Llama-Factory进行完整的参数预处理 当前运行多个基本模型（Llama 8b，Llama 70B，量化Llama 70B，Phi-4，phi-4，Qwen 32b），QWEN 32B） O3-Mini  收集性能数据以确定不同任务的最佳模型   寻找反馈：该网站现场直播 sugaku.net/“&gt; sugaku.net ，但我认为这是一项工作。 I&#39;d appreciate your thoughts on:  Features that would enhance your research workflow Math/ML research areas that need better support Technical suggestions for improving the models or search capabilities  I&#39;m particularly interested in seeing more questions asked, as this helps me build and refine an agent that pulls relevant papers into context for more accurate answers. Thanks for checking它！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/rfurman     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iyv0jx/p_sugaku_ai_ai_ai_for_for_exploration_math_research/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iyv0jx/p_sugaku_ai_tools_for_exploratory_math_research/</guid>
      <pubDate>Wed, 26 Feb 2025 18:50:49 GMT</pubDate>
    </item>
    <item>
      <title>[d] n维数几乎是正交的向量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iyt374/d_almost_orthogonal_vectors_in_n_dimensions/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  许多文献，尤其是从事表示形式学习的文献，他说“特征”是模型内一些高维空间中的向量，因为我们只能在n维中具有N完美的正交矢量（否则额外的向量将是线性依赖的），这些特征向量几乎是正交的，它几乎是正交的，几乎正交矢量的数量与n呈指数增加。但是我还没有找到一个可以理解的证据（或该指数界限）。一些地方提到了JL引理，但我看不到它是同一件事。有人在此背后有任何直觉，还是可以帮助一些平易近人的证据  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iyt374/d_almost_orthogonal_vectors_in_in_dimensions/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iyt374/d_almost_orthogonal_vectors_in_n_dimensions/</guid>
      <pubDate>Wed, 26 Feb 2025 17:32:47 GMT</pubDate>
    </item>
    <item>
      <title>[n]拉格斯：LLM的实时自我完善而无需再培训</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iyszck/n_ragsys_realtime_selfimprovement_for_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们很高兴共享一个名为ragsys的新框架，该框架重新考虑了LLMS的检索增强生成（RAG）。 Instead of simply appending static document chunks to prompts, RAGSys dynamically builds a database of few-shot examples, instructions, and other contexts, and optimizes its retrieval to compose prompts that have the highest chance of yielding a good response. Here’s the core idea:  Dynamic Context Composition: Retrieve not only documents but also few-shot examples and instructions, forming a prompt that’s optimized for each unique query. Utility-Driven Optimization: Rather than relying solely on similarity, the system measures the utility of each retrieved context—prioritizing those that actually improve response accuracy. Feedback Loop: Every interaction (query, response, outcome) is stored and used to amend the few-shot示例和说明，并调整猎犬。这种连续的，自我提高的循环意味着LLM适应而无需再进行重新训练。  期待您的见解和讨论！ 可以随时查看完整的文章 进行深度潜水。   &lt;！提交由＆＃32; /u/u/crossing_minds     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iyszck/n_ragsys_realtime_selfimprovement_for_llms/</guid>
      <pubDate>Wed, 26 Feb 2025 17:28:25 GMT</pubDate>
    </item>
    <item>
      <title>机器学习可以真正“概括”，或者我们只是在合成专业方面变得更好吗？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iykqh1/can_machine_learning_truly_generalizeor_are_we/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们谈论ML中的概括，就好像是最终目标一样，模型学习模式会传输跨域。但是，“真正的概括”实际上是在发生，还是我们只是完善了特定于任务的外推？ 经过大量，多样化数据训练的模型不一定是概括的 - 它只是在预定义约束中的模式综合方面变得更好。即使是似乎可以很好地“概括”的变压器，它仍然受训练数据的基本结构的束缚。 那么，ML的真正前沿是关于实现真正的概括的真正前沿，还是接受智能固有地依赖上下文依赖于上下文？如果是这样，ML的未来是关于打破过去数据集限制的未来，还是简单地优化合成智能以提高专业化？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iykqh1/can_machine_learning_truly_generalizeor_are_are_we/”&gt; [link]    [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iykqh1/can_machine_learning_truly_generalizeor_are_we/</guid>
      <pubDate>Wed, 26 Feb 2025 10:43:23 GMT</pubDate>
    </item>
    <item>
      <title>[r] FFT反击：自我注意的有效替代品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iycjkd/r_the_fft_strikes_back_an_efficient_alternative/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  传统的自我注意力以野蛮的o（n²）方式计算成对相互作用，将每个令牌与其他所有标记进行比较。对于长序列而​​言，这种方法效率低下。相反，快速傅立叶变换（FFT）将序列转换为频域。在这里，每个令牌由一组由单一矩阵定义的正交频率组件表示。该表示可以保留通过Parseval定理确保信号的能量，并在O（n log n）复杂性下更快地计算。通过利用经典信号处理原理，FFT提供了一种数学上优雅且可扩展的方式来捕获全球依赖性，这使其成为建模长距离交互作用的有吸引力的替代方法。  i Revisit fnet，该论文最初引入了静态的非线性非线性FFT方法。不幸的是，FNET的表述不仅写得不好，而且缺乏实用应用所需的可扩展性，并且在任何基准测试方面都没有表现出色。相反，我已经完善并优化了该方法，增强了其清晰度，适应性，有效性和非线性。我的方法还胜过许多基准上的经典自我注意力，因为它在频域中（自适应）在频域中运行，利用FFT的有效O（n log n）计算以更有效地捕获长期依赖性。这种改进的方法为传统的自我注意力提供了强大而可扩展的替代方案，使其成为捕获全球依赖性的引人注目的替代者。 编辑：本文的要点是表明我们可以以计算上有效的方式替换自我注意力。也许这不是最好的方法，但这是数学上合理的方法。它为将来的作品留下了很大的空间，并为更多机会打开了大门。这是论文的重点。 代码在本文中，但您也可以在这里找到： href =“ https://arxiv.org/abs/2502.18394”&gt; https://arxiv.org/abs/2502.18394 提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iycjkd/r_the_fft_fft_fft_backs_back_and_and_effficity_alternative/”&gt; [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iycjkd/r_the_fft_strikes_back_an_efficient_alternative/</guid>
      <pubDate>Wed, 26 Feb 2025 02:07:50 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子以便在此处发布的新帖子的人！ 线程将活着直到下一个，因此请继续发布标题的日期之后。 感谢大家在上一个线程中回答了上一个线程中的问题！  &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iwdbgs/d_simple_questions_thread/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 23 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>