<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 15 Nov 2024 15:17:57 GMT</lastBuildDate>
    <item>
      <title>[D] 当您说“LLM”时，有多少人也考虑过 BERT 之类的东西？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grxbdp/d_when_you_say_llm_how_many_of_you_consider/</link>
      <description><![CDATA[我不断遇到这种争论，但对我来说，当我听到“LLM”时，我的假设是只有解码器的模型，这些模型有数十亿个参数。似乎有些人会将 BERT-base 纳入 LLM 系列，但我不确定这是否正确？我想从技术上讲是这样，但每次我听到有人说“我如何使用 LLM 进行 XYZ”时，他们通常会提到 LLaMA 或 Mistral 或 ChatGPT 或类似的东西。    提交人    /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grxbdp/d_when_you_say_llm_how_many_of_you_consider/</guid>
      <pubDate>Fri, 15 Nov 2024 14:16:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 即将召开的 NeurIPS 的网络技巧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grts1a/d_networking_tips_for_the_upcoming_neurips/</link>
      <description><![CDATA[嗨，我不确定这是否允许，但请耐心等待。 我是一名硕士生，并以第一作者的身份在 NeurIPS 上发表了一篇论文。我计划在四月毕业，因此正在寻找全职机会，同时也在扩大我的人脉。 这是我参加的第一次会议，我不知道该做什么。我只是在寻找参加 NeurIPS 时的提示、指导等。我特别想寻找一些关于如何更好地建立人脉、谈论什么话题以及如何被那些能够有所作为的人记住的提示。我只是想充分利用这次活动。 提前谢谢！    提交人    /u/USBhupinderJogi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grts1a/d_networking_tips_for_the_upcoming_neurips/</guid>
      <pubDate>Fri, 15 Nov 2024 10:54:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] Ilya Sutskever 的 AI 阅读清单中丢失的阅读项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grti0x/d_the_lost_reading_items_of_ilya_sutskevers_ai/</link>
      <description><![CDATA[这篇博文试图找出今年早些时候出现的热门 AI 阅读清单中遗漏了哪些论文，该清单归功于 Ilya Sutskever 及其声称涵盖了 2020 年 AI 领域“90% 的重要内容”： https://tensorlabbet.com/2024/11/11/lost-reading-items/ 今年早些时候，大约 40 篇论文中只有 27 篇在网上分享，因此关于哪些作品足够重要而值得收录的理论有很多。这里讨论了一些与元学习和竞争性自我博弈相关的明显候选者。但也有几位值得注意的作者，如 Yann LeCun 和 Ian Goodfellow 未列入名单。 从我的角度来看，甚至关于 U-Net、YOLO 检测器、GAN、WaveNet、Word2Vec 等的论文也应该包括在内，所以我很好奇对此的更多看法！    提交人    /u/AccomplishedCat4770   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grti0x/d_the_lost_reading_items_of_ilya_sutskevers_ai/</guid>
      <pubDate>Fri, 15 Nov 2024 10:34:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用脑电图生物标志物数据模拟帕金森病风险患者是否合理？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grrb6w/p_is_it_reasonable_to_simulate_atrisk_parkinson/</link>
      <description><![CDATA[大家好， 我目前正在进行一个论文项目，该项目涉及训练一个机器学习模型，根据脑电图和其他临床特征对帕金森病 (PD) 进行分类。但是，我感兴趣的不仅仅是区分健康患者和帕金森病患者。我想看看该模型是否有可能识别出未来有患帕金森病风险的患者。 我面临的挑战是，我使用的数据集不包含任何真正的“高风险”患者——它是健康对照者和确诊帕金森病患者的二元集。我阅读了大量讨论帕金森氏症不同生物标志物的文献，例如特定脑电图频带的功率改变（如 alpha/beta 降低和 theta/delta 增加）、不同大脑区域之间的一致性变化等。 我正在考虑使用这些已知的生物标志物来人工生成“高风险”患者数据。本质上，我会通过应用某些变化（例如，降低 alpha 功率、增加 delta 活动）来修改来自健康对照的 EEG 信号，以创建代表处于前驱期或具有高风险因素的患者的合成数据。 我很想听听社区对这种方法的看法。  从方法论的角度来看，这是否有意义？ 有没有更好的方法来模拟或建模前驱 PD 阶段？ 使用这样的合成数据时，我应该注意哪些道德或科学问题？  任何意见或建议都将非常有帮助。提前谢谢！    提交人    /u/Impressive_Staff4688   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grrb6w/p_is_it_reasonable_to_simulate_atrisk_parkinson/</guid>
      <pubDate>Fri, 15 Nov 2024 07:47:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么我的（TensorFlow Lite）模型可以在桌面上运行，但在移动设备（Android）上却不行？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grqemd/d_why_does_my_tensorflow_lite_model_work_on/</link>
      <description><![CDATA[大家好， 我正在使用 TensorFlow Lite 在 Unity 中构建音频分类器，遇到了一个有趣的问题，我希望在这里询问以了解有关此问题的更多信息： - 默认的 YAMNet 模型在桌面和 Android 上都能完美运行 - 我的自定义模型（使用 Google Teachable Machine 制作）在桌面上运行良好，但在 Android 上完全失败 什么可能导致桌面和移动设备之间的差异？ 谢谢！    提交人    /u/kyzouik   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grqemd/d_why_does_my_tensorflow_lite_model_work_on/</guid>
      <pubDate>Fri, 15 Nov 2024 06:41:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] DTFormer：一种基于 Transformer 的离散时间动态图表示学习方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grq9cn/r_dtformer_a_transformerbased_method_for_discrete/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grq9cn/r_dtformer_a_transformerbased_method_for_discrete/</guid>
      <pubDate>Fri, 15 Nov 2024 06:31:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有关 ML 生命周期管理的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grpv5r/d_advice_on_ml_lifecycle_management/</link>
      <description><![CDATA[大家好，我目前正在为一个项目设置 ML 基础架构。 我希望能够跟踪模型版本，评估实时数据的性能，在有新数据可用时自动重新训练模型，并将训练好的模型保存在存储中。这样，使用该模型的应用程序就可以从存储中加载训练好的模型，并将其用于生产中的推理。 p.s.我无法将模型作为 Rest Api 提供服务，它必须部署在最终应用程序将运行的计算机上，因为该计算机可能没有互联网连接。 我现在的解决方案如下： 准备训练数据并将其保存到云端的增量表中 将新可用的数据逐步添加到增量表中 使用增量表中的数据训练和测试模型 如果测试指标令人满意，则将工件（模型、编码器和缩放器）和元数据（指标、特征等...）作为 blob 上传到 Azure 存储容器 对于每次新的工件上传，都会生成一个新的版本 id，并且工件将保存在存储容器中与模型版本相对应的子文件夹中。 在容器的根目录中有一个 blob，其中包含有关最新版本 id 的信息 当最终应用程序启动后，如果互联网连接可用，并且最新可用版本与运行应用程序的计算机上的版本不同，它会从 Azure 存储容器下载最新版本的工件，否则它将使用默认版本。 使用连续运行的作业来评估实时数据的模型并将结果保存在数据库中 仪表板显示评估结果 x 天后，触发作业以在新数据上重新训练模型，并且该过程按照上面列出的步骤经历一个新的循环。 如何看待这个设置？它过于复杂吗？我怎样才能使它更好/更高效？您有什么流程来训练、跟踪、监控和部署您的 ML 模型？ 我希望我的问题不要太复杂。如有任何错误，请原谅我，并提前感谢您的回答。    提交人    /u/InteractionSuitable1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grpv5r/d_advice_on_ml_lifecycle_management/</guid>
      <pubDate>Fri, 15 Nov 2024 06:05:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我应该转到推荐算法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grl7gk/d_should_i_transfer_to_recommendation_algorithms/</link>
      <description><![CDATA[我现在在一个“LLM”团队工作，或者至少广告上是这么宣传的，老实说，它只是使用 LLM 进行分类，并不是很有趣。我收到了公司另一个做推荐的团队的邀请。我认为推荐是一个非常可靠的领域，但竞争非常激烈。你们在推荐方面有什么工作经验？    提交人    /u/DolantheMFWizard   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grl7gk/d_should_i_transfer_to_recommendation_algorithms/</guid>
      <pubDate>Fri, 15 Nov 2024 01:42:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] RedCode：评估代码语言模型安全性和风险的基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grkagz/r_redcode_a_benchmark_for_evaluating_safety_and/</link>
      <description><![CDATA[RedCode：评估代码代理安全性的新基准 我一直在审查这篇介绍 RedCode 的新论文，RedCode 是用于评估 AI 代码代理的代码生成和执行的安全性方面的基准。核心贡献是一种系统性的方法来评估代码代理如何处理潜在的不安全操作。 基准测试由两个主要部分组成： - RedCode-Exec：测试代理对 8 个域中 25 种漏洞类型的 4,050 个提示的响应 - RedCode-Gen：评估代理是否从 160 个函数签名 / 文档字符串生成有害代码 关键技术点： - 使用 Docker 环境进行受控执行测试 - 实现自定义指标以进行安全评估 - 涵盖 Python 和 Bash 代码 - 测试多种输入格式（代码片段和自然语言） - 使用 19 种不同的 LLM 评估了 3 个代理框架 主要发现： - 与有缺陷的代码相比，代理对操作系统级风险操作的拒绝率更高 - 自然语言对风险操作的描述比代码的拒绝率更低 - 更强大的模型（例如 GPT-4）在提示时会生成更复杂的有害代码 - 发现安全性存在显著差异跨不同代理框架的性能 这些影响对于在生产环境中部署代码代理非常重要。结果表明，当前系统存在明显的安全漏洞，特别是在代码执行方面。该基准测试提供了一种评估和改进代码代理安全机制的标准化方法。 TLDR：名为 RedCode 的新基准测试测试代码代理处理不安全代码执行和生成的能力。结果表明，当前代理的安全能力水平各不相同，特别是在自然语言输入和技术上有缺陷的代码方面存在漏洞。 完整摘要在此处。论文此处。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grkagz/r_redcode_a_benchmark_for_evaluating_safety_and/</guid>
      <pubDate>Fri, 15 Nov 2024 00:56:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 论文俱乐部：Nvidia 研究员 Ethan He 介绍教育部法学硕士课程升级改造</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grjjlz/d_paper_club_nvidia_researcher_ethan_he_presents/</link>
      <description><![CDATA[大家好， 明天，Nvidia 研究员 Ethan He 将深入研究他的工作：在混合专家 (MoE) 中升级法学硕士。很高兴能一睹幕后风采，看看在 Nvida 处理这种规模的模型是什么样的。 如果您想在明天太平洋标准时间上午 10 点加入社区，我们非常欢迎您。我们通过 zoom 进行现场直播，欢迎任何人加入。 这是论文：https://arxiv.org/abs/2410.07524 现场加入我们：https://lu.ma/arxivdive-31    提交人    /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grjjlz/d_paper_club_nvidia_researcher_ethan_he_presents/</guid>
      <pubDate>Fri, 15 Nov 2024 00:19:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习理论研究有哪些重要贡献？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1grfxbz/d_what_are_some_important_contributions_from_ml/</link>
      <description><![CDATA[我有兴趣了解更多关于近年来理论 ML 研究人员的贡献。我想听听那些不适用的超级重要贡献（例如，告诉我们一些重要的事情）以及在现实世界中也适用的贡献。我想尝试阅读这些论文。 此外，我有兴趣知道（理论）研究人员对这个领域的看法，它有潜力吗，还是 ML 正在朝着纯粹的启发式方向发展？ 如果不谈论 ML 只是统计数据和 Lipschitz 常数，这次讨论可能会更有成效 :) 我说的是前沿的理论研究——我真的没有工具来估计这条工作线有多大用处，我相信这对其他人来说也是一个有趣的讨论。    提交人    /u/Traditional-Dress946   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1grfxbz/d_what_are_some_important_contributions_from_ml/</guid>
      <pubDate>Thu, 14 Nov 2024 21:34:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习模型中不可检测的后门：使用数字签名和随机特征的新技术，对对抗鲁棒性有影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr4ksm/r_undetectable_backdoors_in_ml_models_novel/</link>
      <description><![CDATA[我发现了一个重要的后门攻击分析，它展示了恶意服务提供商如何将无法检测到的后门插入机器学习模型中。 关键贡献是展示了如何构建即使在白盒分析下也无法检测到的后门，同时允许通过微妙的输入扰动任意操纵模型输出。 技术细节：* 用于植入无法检测的后门的两个框架：* 基于数字签名方案的后门，在计算上无法通过黑盒访问检测* 基于随机傅立叶特征/随机 ReLU 的后门，可经受白盒检查* 即使具有以下条件，后门模型也与干净模型无法区分：* 完全访问模型架构和参数* 完整的训练数据集* 分析模型行为的能力 结果：* 后门模型保持与原始模型相同的泛化误差* 服务提供商可以通过轻微扰动修改任何输入的分类* 构造适用于任何底层模型架构 * 任何计算受限的观察者都无法检测到后门 这对 ML 安全和外包培训具有重大影响。这项工作显示了证明对抗性鲁棒性的根本局限性——一个后门模型可能与一个鲁棒模型无法区分，而每个输入都有对抗性的例子。 TLDR：论文证明可以将无法检测到的后门插入 ML 模型中，允许任意操纵输出，同时证明无法检测到。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr4ksm/r_undetectable_backdoors_in_ml_models_novel/</guid>
      <pubDate>Thu, 14 Nov 2024 13:19:01 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 缩放定律和图神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gr2t6l/discussion_scaling_laws_and_graph_neural_networks/</link>
      <description><![CDATA[我偶然发现了一篇介绍第一个“图形基础模型”的论文：https://arxiv.org/pdf/2407.11907 他们表明，GNN 可以随着数据和模型大小而扩展，跨不同领域进行推广，并可以在新数据集上进行有效微调。 这对我来说很有趣，因为即使 LLM 风靡一时，文本也可能是一种弱数据表示。大多数知识都有图形结构。代码、研究论文，甚至人类大脑——都是图形。而下一个标记预测作为归纳偏差并没有利用这一点。 当然，这里有一个巨大的数据瓶颈。但也许下一步是使用 LLM 将互联网上的大量文本转换为图表进行训练。  你们觉得怎么样？    提交人    /u/jsonathan   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gr2t6l/discussion_scaling_laws_and_graph_neural_networks/</guid>
      <pubDate>Thu, 14 Nov 2024 11:34:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>