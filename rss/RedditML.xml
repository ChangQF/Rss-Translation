<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 10 May 2024 09:14:52 GMT</lastBuildDate>
    <item>
      <title>[P] 通过行车记录仪驾驶时进行瞌睡检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1coj73k/p_sleepy_detection_while_driving_via_dashcam/</link>
      <description><![CDATA[我需要有关此项目想法的帮助。我对此很陌生，任何类型的信息都会有帮助，我想开发一个模型，通过行车记录仪实时反馈检测驾驶员是否昏昏欲睡。 我该如何解决这个问题，我应该如何接近它，是否有更好和最差的方法来做到或避免。任何类型的信息都会非常有帮助。谢谢:)   由   提交/u/ahar_AIM   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1coj73k/p_sleepy_detection_while_driving_via_dashcam/</guid>
      <pubDate>Fri, 10 May 2024 06:49:07 GMT</pubDate>
    </item>
    <item>
      <title>从最后一层的隐藏状态值生成输出 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1coj061/generating_outputs_from_last_layers_hidden_state/</link>
      <description><![CDATA[在向 llama-2 模型提供特定输入（我们称之为 Input_1）后，我操纵了从 llama-2 模型获得的隐藏状态值。现在，我想检查它由此产生的输出（因果输出）。我的假设是它应该对应于不同的输入，我们称之为 Input_2，它将产生与初始输入不同的输出。 我通过以下方式获得了最后一层的隐藏状态值： &gt; from Transformers import LlamaModel, LlamaTokenizer, LlamaForCausalLM tokenizer = LlamaTokenizer.from_pretrained(path_to_llama2) model = LlamaModel.from_pretrained(path_to_llama2) model_ = LlamaForCausalLM.from_pretrained(path_to_llama2) tokenizer.pad_token = tokenizer.eos_token input = tokenizer( Prompt, return_tensors=&#39;pt&#39;) with torch.no_grad():outputs = model(**inputs,output_attentions=True,output_hidden_​​states=True)hidden_​​states=outputs.hidden_​​states[-1]#最后一层隐藏状态&lt; /pre&gt; 如上所示，我试图更改从 model 获得的 hide_states 值，但现在我想生成因果输出。我该怎么做？有什么建议吗？   由   提交/u/1azytux  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1coj061/generating_outputs_from_last_layers_hidden_state/</guid>
      <pubDate>Fri, 10 May 2024 06:35:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能对 Web 开发与深度学习就业市场的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1coimel/d_ai_effects_on_job_market_in_web_development_vs/</link>
      <description><![CDATA[嗨，我是一名首席数据分析师，正在尝试调整我的职业方向。我对 Web 开发和深度学习有一些基本的了解。考虑到人工智能可能会扰乱其中任何一个或两者的未来就业市场，我应该采取哪个方向？    由   提交 /u/Sufficient-Result987   /u/Sufficient-Result987 reddit.com/r/MachineLearning/comments/1coimel/d_ai_effects_on_job_market_in_web_development_vs/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1coimel/d_ai_effects_on_job_market_in_web_development_vs/</guid>
      <pubDate>Fri, 10 May 2024 06:09:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在实践中使用 RAG 基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1coi4iy/d_how_to_use_rag_benchmarks_in_practice/</link>
      <description><![CDATA[我正在开展一个涉及 RAG 实验的研究项目。我想首先运行模型以了解整个管道的工作原理。我在 HuggingFace 上找到了一些数据集（例如 https://huggingface.co/datasets/explodinggradients/WikiEval）。 我对 RAG 的理解是，应该给我一个数据存储，然后我使用该数据存储执行问答任务。然而，在这些数据集中，上下文与问题一起给出，我不太明白。 RAG 是否应该作为上下文问答来执行？如果是的话，它不会破坏RAG中检索的点吗？ 提出我的问题的另一种方式如下：不应该每个RAG数据集都有一个数据集级文档存储而不是随问题一起提供上下文？    由   提交/u/Tall_Sun_3096   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1coi4iy/d_how_to_use_rag_benchmarks_in_practice/</guid>
      <pubDate>Fri, 10 May 2024 05:37:05 GMT</pubDate>
    </item>
    <item>
      <title>相同的 llm 不同的结果 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cogzki/same_llm_different_results_d/</link>
      <description><![CDATA[你们有没有觉得同一个开源 llm 在不同的游乐场上给出了略有不同的答案.. 就像如果您在困惑度上使用 llama 70 b 一样groq 注意到差异有人可以告诉我为什么吗..    由   提交/u/IntentionNo5258  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cogzki/same_llm_different_results_d/</guid>
      <pubDate>Fri, 10 May 2024 04:25:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] CIFAR10培训</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co9uaf/d_training_on_cifar10/</link>
      <description><![CDATA[大家好，是否有一组已知的超参数用于在 CIFAR10 或任何其他著名数据集上训练扩散模型，主要用于重建损失？   由   提交/u/sidney_lumet  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co9uaf/d_training_on_cifar10/</guid>
      <pubDate>Thu, 09 May 2024 22:24:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] ECCV-2024 评论已出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co7w0i/d_eccv2024_reviews_are_out/</link>
      <description><![CDATA[标题说明了一切。   由   提交/u/darkknight-6  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co7w0i/d_eccv2024_reviews_are_out/</guid>
      <pubDate>Thu, 09 May 2024 21:01:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 杰出论文奖。恭喜！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co4kfw/d_iclr_outstanding_paper_awards_congratulations/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co4kfw/d_iclr_outstanding_paper_awards_congratulations/</guid>
      <pubDate>Thu, 09 May 2024 18:42:14 GMT</pubDate>
    </item>
    <item>
      <title>[D]“特征”一词从何而来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co2ye4/d_where_does_the_term_feature_come_from/</link>
      <description><![CDATA[也许是一个愚蠢的琐事问题，但我无法弄清楚。 ML 将特征称为特征，统计将特征称为预测变量，数学将特征称为特征变量，工程也将特征变量称为特征。 我知道它们是什么，但为什么我们称它们为特征？有谁知道起源故事吗？ 编辑：你们都给了我一些很好的线索；我想我已经找到了一个看似合理的答案：它可能来自认知心理学。 介绍感知器的论文（可以说是迈向神经网络的第一步）将输入称为刺激，但也指出将刺激编码为一小组强大的特征有助于提高性能：  随着系统中响应数量的增加，如果每个响应都与所有替代方案相互排斥，那么性能会逐渐变差。避免这种恶化的一种方法（在 Rosenblatt，15 中有详细描述）是通过响应的二进制编码。在这种情况下，我们不是用 100 个不同的、相互排斥的反应来表示 100 种不同的刺激模式，而是找到有限数量的区分特征，每个特征都可以独立地识别为存在或不存在，并且因此可以用一对互斥的响应来表示。  （突出显示是我的） 稍后得出结论  可以通过使用轮廓敏感投影区域以及通过使用二元响应系统来改进系统的性能，其中每个响应或“位”都由二元响应系统来改进。对应于刺激的某些独立特征或属性。  （突出显示我的）   由   提交 /u/FirefoxMetzger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co2ye4/d_where_does_the_term_feature_come_from/</guid>
      <pubDate>Thu, 09 May 2024 17:35:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] QServe：W4A8KV4 量化和系统协同设计，实现高效的 LLM 服务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1co2k7i/r_qserve_w4a8kv4_quantization_and_system_codesign/</link>
      <description><![CDATA[📚 研究论文：http://arxiv.org/ abs/2405.04532v1 🤔 为什么？：由于 GPU 上的运行时开销巨大，现有的 INT4 量化技术无法在大批量、基于云的语言模型服务中提供性能提升。 💻 How?：研究论文提出了一种新的量化算法 QoQ，它代表 quattuor-octo-quattuor，使用 4 位权重、8位激活和4位KV缓存。该算法在 QServe 推理库中实现，旨在通过引入渐进量化来减少 GPU 上的反量化开销。 **此外，研究论文引入了 SmoothAttention 来减轻 4 位 KV 量化造成的精度下降。 QServe 还执行计算感知权重重新排序，并利用寄存器级并行性来减少反量化延迟。最后，QServe 利用内存绑定的融合注意力来进一步提高性能。 🦾 性能增益：与现有技术相比，该研究论文实现了显着的性能改进。 QServe 将 Llama-3-8B 在 A100 上可实现的最大服务吞吐量提高了 1.2 倍，在 L40S 上提高了 1.4 倍；和 Qwen1.5-72B 在 A100 上提高 2.4 倍。   由   提交/u/dippatel21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1co2k7i/r_qserve_w4a8kv4_quantization_and_system_codesign/</guid>
      <pubDate>Thu, 09 May 2024 17:18:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlphaMath Almost Zero：没有流程的流程监督</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnu9mx/r_alphamath_almost_zero_process_supervision/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2405.03553 代码：https ://github.com/MARIO-Math-Reasoning/Super_MARIO 模型：https://huggingface.co/MARIO-Math-Reasoning/AlaphaMath-7B 摘要： &lt; blockquote&gt; 大型语言模型 (LLM) 的最新进展极大地增强了他们的数学推理能力。然而，这些模型仍然难以解决需要多个推理步骤的复杂问题，经常导致逻辑或数值错误。虽然数字错误很大程度上可以通过集成代码解释器来解决，但识别中间步骤中的逻辑错误更具挑战性。此外，手动注释这些培训步骤不仅成本高昂，而且需要专业知识。在本研究中，我们引入了一种创新方法，通过利用蒙特卡罗树搜索（MCTS）框架自动生成过程监督和评估信号，从而消除了手动注释的需要。本质上，当法学硕士经过良好的预训练时，只需要数学问题及其最终答案来生成我们的训练数据，而不需要解决方案。我们继续训练一个阶梯级价值模型，旨在改进法学硕士在数学领域的推理过程。我们的实验表明，使用由 MCTS 增强的法学硕士自动生成的解决方案可以显着提高模型处理复杂数学推理任务的能力。    由   提交/u/EternalBlueFriday  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnu9mx/r_alphamath_almost_zero_process_supervision/</guid>
      <pubDate>Thu, 09 May 2024 10:48:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] ECCV 2024回顾讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cntiks/d_eccv_2024_review_discussion/</link>
      <description><![CDATA[我认为，与其他会议一样，我们可能会为提交给 ECCV 的人们进行讨论，因为评论将在 10 小时内发布（晚上 10 点（欧洲中部夏令时间）。这是我第一次在任何地方提交，说实话我很紧张。   由   提交/u/mr_birrd  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cntiks/d_eccv_2024_review_discussion/</guid>
      <pubDate>Thu, 09 May 2024 10:00:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 多元时间序列的矩阵轮廓与深度学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnpo6n/d_matrix_profile_vs_deep_learning_for/</link>
      <description><![CDATA[大家好， 所以我阅读了大量的方法，特别是关于多元时间序列和实时研究的方法人类活动识别（HAR）。不过，我最近偶然发现了 Eamonn Keogh 在 Matrix Profiles 方面令人惊叹且全面的工作，最终陷入了困境。  但是出于好奇，在多元时间序列和实时数据流的背景下，矩阵配置文件与深度学习方法（例如 MLP、LSTM 等）相比如何？  我很想听听其他人的观点！   由   提交 /u/peachjpg111   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnpo6n/d_matrix_profile_vs_deep_learning_for/</guid>
      <pubDate>Thu, 09 May 2024 05:31:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审稿人你们都需要停止如此懒惰的狗。为什么审稿人做事这么懒？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cnn54n/d_reviewers_you_all_need_to_stop_being_so_lazy/</link>
      <description><![CDATA[我提交了一篇论文。 被会议接受。 收到来自某个随机家伙的电子邮件_插入_大学_。发送给主席和会议负责人。 指责我抄袭，并说发表论文的匹配度为 92%... 检查交叉引用。标题、作者（我和导师）、数据、结论，几乎整篇论文都被突出显示。 只有来源说 Arkiv。我偶然在那里有我的预印本。我按照他们的政策预印本并张贴了通知。 现在，这是非常愚蠢的。我做了很多尽职调查，如果它与作者匹配，它必须引用我的预印本。 为什么审稿人如此懒惰，可以采取如此激烈的行动，而不是仅仅向作者询问有关这些的问题？我真的不理解其中一些人。对于处理这些情况您有什么建议吗？   由   提交 /u/I_will_delete_myself   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cnn54n/d_reviewers_you_all_need_to_stop_being_so_lazy/</guid>
      <pubDate>Thu, 09 May 2024 03:03:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ckt6k4/d_simple_questions_thread/</guid>
      <pubDate>Sun, 05 May 2024 15:00:21 GMT</pubDate>
    </item>
    </channel>
</rss>