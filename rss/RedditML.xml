<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 05 Apr 2024 12:22:57 GMT</lastBuildDate>
    <item>
      <title>[R] 📘“通过终极资源编译深入研究保形预测！”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwgc5n/r_dive_deep_into_conformal_prediction_with_this/</link>
      <description><![CDATA[各位r/MachineLearning爱好者们好！&lt; /p&gt; 您有兴趣了解保形预测 (CP) 并探索其深度吗？无论您是初露头角的学习者、经验丰富的研究人员还是该领域的从业者，我们都很高兴分享一些必将激发您的兴趣并扩展您的知识的内容！ 🚀 W* e 呈现：“很棒的共形预测” - 共形预测资源的终极集合 *🚀 我们对 CP 的热情促使我们整理出一份详尽的列表，其中包含有关该主题的最佳材料。这个宝库旨在引导您了解保形预测的复杂景观，涵盖您可以想象的各个方面：  📺 Engaging 视频和视频教程：视觉学习者，欢呼吧！查找将复杂概念分解为易于理解的部分的教程和讲座。 📚 富有洞察力的书籍和讲座。论文：从介绍性文本到高级研究论文，加深您对 CP 理论基础和创新应用的理解。 🎓 学术论文：探索前沿发现博士和硕士论文致力于突破 CP 的界限。 📰 启发性文章： 随时了解揭示保形预测最新趋势、挑战和突破的文章. 💻开放源代码库：通过访问各种开源库来实践 CP，非常适合热衷于实际实施的学习者和开发人员。 li&gt;  无论您是想巩固基础知识、了解最新研究成果，还是在项目中应用 CP，此列表都是您的一站式目的地。 &lt; p&gt;深入研究这个精选的集合，加入掌握保形预测的前沿。让我们一起踏上机器学习领域的学习、发现和创新之旅！ 快乐探索！ https://github.com/valeman/awesome-conformal-prediction   由   提交 /u/predict_addict   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwgc5n/r_dive_deep_into_conformal_prediction_with_this/</guid>
      <pubDate>Fri, 05 Apr 2024 12:05:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] FMA 的补码 - 一个定制的二进制数字系统（如 2 的补码），设计用于基于查找表的矩阵乘法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwg494/r_fmas_complement_a_custom_binary_number_system/</link>
      <description><![CDATA[TLDR ：矩阵乘法的查找表。  简单描述：这是一个定制的二进制数字系统，旨在计算矢量点积。  技术描述：FMA 的补码是二进制数的定点表示形式，作为 2 的补码和 1 的补码的替代方案，用于执行融合乘加指令。  我们将线性代数和算术代码（来自数据压缩理论）结合起来，使数字系统非常适合查找点积。  这是获取开始文章 这是GitHub 存储库  &lt; !-- SC_ON --&gt;  由   提交 /u/DataBaeBee   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwg494/r_fmas_complement_a_custom_binary_number_system/</guid>
      <pubDate>Fri, 05 Apr 2024 11:54:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] KDD2024 评论的评分标准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bweztg/d_scoring_scale_for_kdd2024_reviews/</link>
      <description><![CDATA[有谁知道今年 KDD 评论的评分标准是多少？我只在 OpenReview 上看到审稿人提出的数字，但在任何地方都找不到总体规模。   由   提交/u/Environmental_Gas318   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bweztg/d_scoring_scale_for_kdd2024_reviews/</guid>
      <pubDate>Fri, 05 Apr 2024 10:49:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 训练和测试数据集之间的特征不匹配</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwe2v3/p_feature_mismatch_between_training_and_testing/</link>
      <description><![CDATA[背景： 对于我的大学顶点项目，我目前正在为想要的客户构建一堆机器学习模型预测高价值的潜在客户。客户给出了两个主要数据集：第一个是测试了客户产品并且是否成为客户的客户列表（明确标记），第二个是潜在客户列表。我在第一个数据集上训练了我的模型，并使用第二个数据集上的模型来预测潜在客户。 问题： 这两个数据集在特征上没有任何相似性；没有什么是我真正能用的。我尝试构建模型并进行预测，看看它们是否有效，但预测结果始终为所有潜在客户产生相同的价值。 我可以使用的相关领域知识并不多，也没有太多可用的特征工程（两个数据集之间的特征差异太大而无法使用）。我已经尝试过传统的 ML 模型，并且正在尝试 XGBoost/DNN/PCA，即使它们不应该这样使用。 问题： 我只是想能够提交一些我可以向客户展示的东西。是否有任何特殊模型可以解释这一点并执行？我可以利用什么特殊的特征工程技术吗？任何帮助将不胜感激，谢谢。   由   提交 /u/PM_ME_NATURE_PLS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwe2v3/p_feature_mismatch_between_training_and_testing/</guid>
      <pubDate>Fri, 05 Apr 2024 09:51:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] Tensorboard/权重和偏差的替代方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwduod/d_alternatives_to_tensorboard_weights_and_biases/</link>
      <description><![CDATA[我一直在使用 Tensorboard 来跟踪我的深度学习项目中的损失曲线和几个指标的演变，但我放弃了它，因为它太有限了（特别是在同一个图上进行多次运行）。 我大约 6 个月前开始使用权重和偏差，但它实际上接近于一场噩梦：用户界面极其缓慢，许多错误，非- 直观且文档很少的Python库。我实际上因此浪费了几十个小时。 对于未来的项目，我想改用更好的解决方案。我听说过海王星，但我从未有机会尝试过。我想要一些专注于跟踪指标的东西，但速度快，没​​有漏洞，并且高度可定制。 对 Neptune 有什么意见吗？您还会推荐什么？    由   提交 /u/Skeylos2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwduod/d_alternatives_to_tensorboard_weights_and_biases/</guid>
      <pubDate>Fri, 05 Apr 2024 09:35:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] Hugginface Accelerate 的 DeepSpeed 集成与 Native DeepSpeed</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwcwuv/d_hugginface_accelerates_deepspeed_integration_vs/</link>
      <description><![CDATA[通过加速使用时，deepspeed 的性能、功能和可用性如何？您的体验如何？直接使用 Deepspeed 会错过什么？我计划进行分布式多模式训练（音频+文本）。您建议使用上述深度速度中的哪一个？有什么技术堆栈可以派上用场或帮助我进行培训吗？多模式培训方面的任何相关资源都会有所帮助。预先感谢 ☺️    由   提交/u/gokulPRO  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwcwuv/d_hugginface_accelerates_deepspeed_integration_vs/</guid>
      <pubDate>Fri, 05 Apr 2024 08:31:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] KDD 2024 评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwcact/d_kdd_2024_reviews/</link>
      <description><![CDATA[大家好， KDD 2024 论文评审可在 OpenReview 上查看。随着评论的发布，我创建了这个讨论线程，供我们收集想法、问题和建议或其他任何内容。祝您一切顺利！  更新： Paper Copilot 正在使用以下计算方式收集 KDD&#39;24 评级。您还可以通过此链接输入您的分数，请查看一下。 评分=0.5*平均新颖性。 + 0.5*平均技术质量   由   提交 /u/jeongwhanchoi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwcact/d_kdd_2024_reviews/</guid>
      <pubDate>Fri, 05 Apr 2024 07:46:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 单次参考图像的高效一次性检测的 SOTA 是多少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bw7ol3/d_whats_sota_in_efficient_oneshot_detection_for_a/</link>
      <description><![CDATA[澄清一下，我并不是指通常的野外物体检测任务，就像“这里有一千张随机照片，放置边界框”周围所有的自行车”。我的意思是一个规模小得多的任务，更像是“这里有一千张通过公司传真机的图像，显​​示哪些图像在页面上的某个位置有该公司的徽标”。例如，您有一个在较大图像中查找的确切图像的干净参考副本，但它可能会扭曲、轻微旋转、大小和位置可变等。  以这张信头产品图片为例。如果我有一个“完美的”该图像中页面右上角徽标的 SVG，在图像中找到它确实不应该那么困难（尽管它看起来稍微扭曲，偏离水平约 10 度，而且可能要小得多）比我的参考图像）或者说它不存在。 显然，许多传统的 CV 已经完全被 ML 方法取代，并且目标检测/分割是一个非常活跃的领域。我说 SOTA，但这确实感觉像是一个传统的 CV 问题。我看的不是照片或自然图像，它们是机器生成的，我正在寻找的东西总是看起来或多或少相同，只是有细微的变化。如果像 SIFT 功能这样的基本功能可以处理这个问题，那就太好了，但如果我要通过微调更快的 r-cnn 或 yolov5 或 detectorron2 等东西来获得明显更好的结果，那就这样吧。 其他因素：  宁愿不需要需要手工注释的训练集。当目标类别的真实示例变化很大（例如自行车）时，这显然是需要的，但这里的情况并非如此。在 COCO 等内容上进行预训练的模型感觉太过矫枉过正，甚至适得其反，因为我感兴趣的领域与自然图像几乎没有重叠。 更喜欢尽可能轻量级的解决方案。我不需要一个需要两天训练并且可以做无数事情的怪物框架，理想情况下它只是工作得相当好的东西，并且可以在本地运行，并且可以快速训练和快速推理。  更喜欢使用公开代码的方法，但如果有必要，我会自己实现一篇论文。  提前感谢您为我指明正确方向的任何帮助!   由   提交/u/wintermute93  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bw7ol3/d_whats_sota_in_efficient_oneshot_detection_for_a/</guid>
      <pubDate>Fri, 05 Apr 2024 03:17:04 GMT</pubDate>
    </item>
    <item>
      <title>[D]猜想：如果深度学习模型没有取得进一步的进展，会发生什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bw7lqh/d_conjecture_if_no_further_advances_in_deep/</link>
      <description><![CDATA[看起来我们都在法学硕士的基础上扬帆起航，或者至少是这个行业的一部分。 我想想象一下，如果我们没有另一个突破并进行讨论，会发生什么。就我而言，对于某些人和公司来说，期望似乎很正常，而对于另一些人和公司来说，期望却很高。但考虑到声音最大，我可能无法很好地区分信号和噪音 ​ 好吧，我知道有些人很难进行建设性思考，所以这里有一些想法点让你消化你的创意天才。  该领域的期望会发生什么 公司的期望会发生什么 什么合理的优化并且可以在模型外部进行改进    由   提交 /u/Semtioc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bw7lqh/d_conjecture_if_no_further_advances_in_deep/</guid>
      <pubDate>Fri, 05 Apr 2024 03:13:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] KDD 评论 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bw7gsl/d_kdd_reviews_2024/</link>
      <description><![CDATA[今天不是应该发布 kdd 评论吗？   由   提交 /u/HighAfJoker   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bw7gsl/d_kdd_reviews_2024/</guid>
      <pubDate>Fri, 05 Apr 2024 03:06:55 GMT</pubDate>
    </item>
    <item>
      <title>[D][P] 在研究中使用类似 3D 游戏的生成代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvw9vy/dp_using_3d_gamelike_generative_agents_in_research/</link>
      <description><![CDATA[“生成代理” [Joon]论文一年前发表。它利用法学硕士为名为《超人前传》的 2D 游戏世界中的角色生成动作。它当时引起了很大的兴趣，但似乎并没有引起进行实际研究的人们的关注。 我的团队正在努力开源其 3D 版本。首先，我们开源了SAGA：技能到行动生成去年年底推出的 Agents，它从运行的模拟中抽象出动作生成。然后我们刚刚发布了Thistle Gulch，一个带有 python API 的 3D 城镇环境，它利用了 SAGA  我们认为其他研究人员对此感兴趣，但我们目前并没有真正看到类似的项目正在发生，并且不确定问题是否是缺乏兴趣或只是缺乏其他提供这样的项目的人。 RL 人员有诸如 Unity ML Agents、OpenAI Gym，甚至 Madrona 等。但这些通常更“机器人”喜欢的行为。有 Google SIMA，但那是关于训练人工智能玩游戏的意义不仅仅是环境本身。  我们认为对人们来说很重要的一些功能是：  高级 Python API - 研究人员需要 Python，但他们不是游戏程序员。 可定制 - 我确信这将非常依赖于研究人员。我可以看到只有一个标准化的环境并专注于动作生成，但其他人会希望拥有更多的能力来定制它。 视觉吸引力 - 这个可能不那么重要，但即使是研究现在也是关于吸引人们对你的工作的关注和兴趣，因此以视频形式访问你的工作结果似乎是一个非常重要的功能。如果您看看 SIMA，或者使用 Minecraft 作为平台的 Voyager [Fan] 就是很好的例子。 开源- 考虑到人们已经在使用《我的世界》等专有游戏，我实际上不确定这有多重要。有些有 API，但大多数都不是为此类事情设计的，所以使用起来很痛苦，而且无法根据您的需求进行更改。  那么，我有这个权利吗？或者我们还应该考虑什么？我很想更多地了解人们在这个领域的需求并建立一个社区。如果有人想聚在一起讨论的话，我也会参加八月份的新 RLConf。   由   提交 /u/frankcarey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvw9vy/dp_using_3d_gamelike_generative_agents_in_research/</guid>
      <pubDate>Thu, 04 Apr 2024 19:27:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言模型作为编译器：模拟伪代码执行改进语言模型中的算法推理 - 延世大学 2024 - 在七个算法推理任务中比 CoT 和 PoT 好 10 到 20 个百分点！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvvqbl/r_language_models_as_compilers_simulating/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2404.02575  摘要：  算法推理是指理解问题背后复杂模式的能力并将它们分解为解决问题的一系列推理步骤。算法推理的这种性质使其对大型语言模型（LLM）构成挑战，尽管它们在其他推理任务中表现出了良好的性能。在此背景下，最近的一些研究受到严格而精确的语法的启发，使用编程语言（例如Python）来表达解决给定实例/问题（例如思维程序）所需的逻辑。然而，编写在单个推理调用中动态表达正确逻辑的可执行代码并非易事。此外，专门为某个实例生成的代码不能被其他实例重用，即使它们来自同一任务并且可能需要相同的逻辑来解决。本文提出了 Think-and-Execute，这是一种新颖的框架，它将语言模型的推理过程分解为两个步骤。 （1）在Think中，我们发现了一个在所有实例之间共享的任务级逻辑，用于解决给定的任务，然后用伪代码表达该逻辑； (2)在Execute中，我们进一步针对每个实例定制生成的伪代码并模拟代码的执行。通过对七个算法推理任务的广泛实验，我们证明了思考和执行的有效性。 与执行特定实例推理的几个强基线（例如 CoT 和 PoT）相比，我们的方法更好地改进了 LM 的推理，这表明发现任务级逻辑的帮助。此外，我们还表明，与自然推理相比，我们的方法可以更好地提高 LM 的推理能力。语言中，伪代码可以更好地指导 LM 的推理，即使它们经过训练可以遵循自然语言指令。   https:/ /preview.redd.it/c22euztvgisc1.jpg?width=1339&amp;format=pjpg&amp;auto=webp&amp;s=7795149c70c4d1f3c94b517500975a2ea7136e72 https://preview.redd.it/ow9wn1uvgisc1.jpg?width=1081&amp;format=pjpg&amp;auto=webp&amp;s =7c8d4f82190f26d3e2870dd6baba45910fef6be6 https ://preview.redd.it/z6qdt0uvgisc1.jpg?width=1083&amp;format=pjpg&amp;auto=webp&amp;s=f87bf65c38dd52f46ac6ea1af7a15e43277f8aa7  &amp;# 32；由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvvqbl/r_language_models_as_compilers_simulating/</guid>
      <pubDate>Thu, 04 Apr 2024 19:07:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] Deepmind - Mixture-of-Depths：在基于 Transformer 的语言模型中动态分配计算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvrduw/r_deepmind_mixtureofdepths_dynamically_allocating/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2404.02258 ​ 摘要 基于 Transformer 的语言模型在输入序列中均匀分布 FLOP。在这项工作中，我们证明 Transformer 可以学习将 FLOP（或计算）动态分配到序列中的特定位置，从而优化模型深度上不同层的序列分配。我们的方法通过限制可以参与给定层的自注意力和 MLP 计算的令牌数量 (k) 来强制执行总计算预算。要处理的令牌由网络使用 top-k 路由机制确定。由于 k 是先验定义的，因此与其他条件计算技术不同，这个简单的过程使用具有已知张量大小的静态计算图。然而，由于 k 个标记的身份是可变的，因此该方法可能会在时间和模型深度维度上不均匀地消耗 FLOP。因此，计算支出总体上是完全可预测的，但在令牌级别是动态的和上下文敏感的。以这种方式训练的模型不仅可以学习动态分配计算，而且可以高效地进行计算。这些模型与等效 FLOPS 和训练挂钟时间的基线性能相匹配，但每次前向传递只需要一小部分 FLOP，并且在训练后采样期间的步进速度可以快 50% 以上。 ​ https: //preview.redd.it/aez0hy66mhsc1.png?width=1282&amp;format=png&amp;auto=webp&amp;s=59d59bff1dbf7a0323a5e00cb16182bd0f5de9d4 ​ &lt; a href=&quot;https://preview.redd.it/ma6ewf06nhsc1.png?width=2138&amp;format=png&amp;auto=webp&amp;s=f4a845f0892ccb6c4ebe447425c3a0aaadebb03d&quot;&gt;https://preview.redd.it/ma6ewf06nhsc1.png?width =2138&amp;format=png&amp;auto=webp&amp;s=f4a845f0892ccb6c4ebe447425c3a0aaadebb03d   由   提交 /u/RedditLovingSun   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvrduw/r_deepmind_mixtureofdepths_dynamically_allocating/</guid>
      <pubDate>Thu, 04 Apr 2024 16:20:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士正在损害人工智能研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</link>
      <description><![CDATA[这是一个大胆的主张，但我觉得 LLM 的炒作早就该消退了。 GPT4 之后，LLM 性能和设计改进不仅取得了相对较小的进展：使其变得更好的主要方法仍然只是使其更大，并且所有 Transformer 的替代架构都被证明是低于标准和劣质的，它们引起了人们的关注（并且投资）远离其他可能更具影响力的技术。与此同时，大量涌入的人甚至不知道基本的机器学习是如何工作的，他们自称是“人工智能研究员”。因为他们使用 GPT 让每个人在本地托管一个模型，试图让你相信“语言模型完全可以推理”。我们只需要另一个 RAG 解决方案！”他们加入这个社区的唯一目标不是开发新技术，而是利用现有技术拼命拼凑出一项有利可图的服务。甚至论文本身也开始主要由法学硕士撰写。我不禁认为整个领域可能会陷入停滞状态，因为不断增长的社区满足于平庸的修复，这些修复充其量只能使模型在任意“分数”上的得分稍微好一些。他们弥补了这一点，忽略了诸如幻觉、上下文长度、基本逻辑缺乏能力以及运行这种规模模型的高昂成本等明显问题。我赞扬那些不顾市场炒作而致力于开发能够实现真正逻辑过程的代理的人们，并希望很快会引起更多关注。   由   提交/u/NightestOfTheOwls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</guid>
      <pubDate>Thu, 04 Apr 2024 08:36:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>