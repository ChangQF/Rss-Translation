<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 10 Nov 2024 18:19:45 GMT</lastBuildDate>
    <item>
      <title>[P] 如何提高时间戳提取的准确性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1go6rtj/p_how_can_i_improve_accuracy_of_timestamp/</link>
      <description><![CDATA[您好， 我正在尝试改进时间戳的提取，它们都具有相同的格式（类似于附加的示例）。 无论出于何种原因，大约 20％ 的时间戳都无法提取。如何根据以下代码提高准确性？ 谢谢 https://preview.redd.it/qqpqo25m540e1.png?width=368&amp;format=png&amp;auto=webp&amp;s=8d691fd78858e57015f4cf2f171374f25e329a0b def extract_time_and_location_from_image(image): try: # 增强图像预处理以获得更好的 OCR 结果 image = ImageOps.grayscale(image) image = ImageOps.invert(image) image = ImageOps.autocontrast(image) image = image.filter(ImageFilter.SHARPEN) text = pytesseract.image_to_string(image) logger.debug(f&quot;Raw OCR text:\n{text}&quot;) cleaned_text = &#39; &#39;.join(text.split()) logger.debug(f&quot;Cleaned OCR text: {cleaned_text}&quot;) # 为日期和时间使用单独的正则表达式 date_pattern = r&#39;(\d{4}:\d{2}:\d{2})&#39; # 匹配 YYYY:MM:DD time_pattern = r&#39;(\b\d{2}:\d{2}\b)&#39; # 匹配带有单词边界的 HH:MM # 尝试分别提取日期和时间 date_match = re.search(date_pattern, cleaned_text) timestamp = None if date_match: # 仅在日期匹配后搜索时间模式 remaining_text = cleaned_text[date_match.end():] time_match = re.search(time_pattern, remaining_text) if time_match: # 验证提取的时间 time_parts = time_match.group(0).split(&#39;:&#39;) hours, minutes = int(time_parts[0]), int(time_parts[1]) if 0 &lt;= hours &lt; 24 and 0 &lt;= minutes &lt; 60: full_timestamp = f&quot;{date_match.group(0)} {time_match.group(0)}&quot; logger.info(f&quot;提取的时间戳：{full_timestamp}&quot;) timestamp = full_timestamp else: logger.warning(&quot;提取的时间无效。&quot;) timestamp = None else: # 如果未找到时间，则 HH:MM 默认为&quot;00:00&quot; full_timestamp = f&quot;{date_match.group(0)} 00:00&quot; logger.info(f&quot;提取的部分时间戳（默认为 00:00）：{full_timestamp}&quot;) timestamp = full_timestamp else: logger.warning(&quot;未找到有效的时间戳。&quot;) stats[&quot;no_timestamp_images&quot;] += 1 return None, &quot;UnknownCity&quot;, &quot;UnknownCountry&quot; # 验证提取的时间戳格式 if not is_valid_timestamp(timestamp): logger.warning(&quot;提取的时间戳不是有效格式。&quot;) return None, &quot;UnknownCity&quot;, &quot;UnknownCountry&quot; # 增强位置模式以捕获更多变化 location_patterns = [ r&#39;([A-Za-zÀ-ÖØ-öø-ÿ\s]+),\s*([A-Za-zÀ-ÖØ-öø-ÿ\s]+)&#39;, # 城市、国家 r&#39;([A-Za-zÀ-ÖØ-öø-ÿ\s]+)\s+([A-Za-zÀ-ÖØ-öø-ÿ\s]+)&#39; # 城市 国家 ] city, country = &quot;UnknownCity&quot;, &quot;UnknownCountry&quot;对于 location_patterns 中的 location_pattern： location_match = re.search(location_pattern, cleaned_text) 如果 location_match： city = location_match.group(1).strip() country = location_match.group(2).strip() logger.info(f&quot;提取的位置：{city}, {country}&quot;) break 返回时间戳、城市、国家/地区，但异常为 e： logger.error(f&quot;提取时间戳和位置时出错：{e}&quot;) 返回 None、&quot;UnknownCity&quot;、&quot;UnknownCountry&quot;     提交人    /u/maad0000   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1go6rtj/p_how_can_i_improve_accuracy_of_timestamp/</guid>
      <pubDate>Sun, 10 Nov 2024 18:07:59 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ML 和 DL 模型中存在伪造新型方法的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1go50wf/discussion_papers_with_fake_novel_approach_in_ml/</link>
      <description><![CDATA[为什么很多新论文（通常由博士完成）都采用现有方法，而当您询问他们的贡献时，他们说我们用另一层替换了这一层，或者我们添加了超参数!!!!! 这不是贡献！我很困惑这些怎么会被接受    提交人    /u/Rihab_Mira   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1go50wf/discussion_papers_with_fake_novel_approach_in_ml/</guid>
      <pubDate>Sun, 10 Nov 2024 16:53:17 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 寻找关于电影数据集的有趣研究（无生成模型）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1go1wps/research_looking_for_interesting_research_on/</link>
      <description><![CDATA[嘿，ML 研究人员！ 我一直在深入研究多模态学习，我特别感兴趣的是以创造性方式利用电影/视频数据集的论文。我不是在寻找与视频生成或传播相关的论文，而是在寻找有趣的方法：  从电影中进行多模态表示学习 结合视频、音频和文本模态的新型融合技术 从电影数据中进行场景理解/上下文学习 角色互动分析 跨模态的情感/情绪分析 使用电影数据进行跨模态检索  很想听听你在这个领域遇到的任何精彩论文！    提交人    /u/stoneddumbledore   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1go1wps/research_looking_for_interesting_research_on/</guid>
      <pubDate>Sun, 10 Nov 2024 14:31:46 GMT</pubDate>
    </item>
    <item>
      <title>[R]/[P] 寻找有关工业厂房成本估算的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnzcxi/rp_looking_for_papers_about_cost_estimation_for/</link>
      <description><![CDATA[大家好。我目前正在为公司一个项目准备数据集，该项目旨在估算我们建造的工业碳捕获工厂的价格。该工厂从烟气中提取二氧化碳，例如从排放大量二氧化碳的化学过程中提取二氧化碳。根据烟气成分，工程师设计工厂，这可能是一个非常耗时的过程。我目前正在准备的数据将包括工程师之前创建的报价。 我的目标是建立一个使用烟气成分（大约 10 个浮点值）的模型来估算工厂的成本或推荐类似的项目。该项目的要求尚未确定，但考虑到模型应该是可解释的并且能够处理较小的数据集，一旦数据准备就绪，回归树可能是我想要尝试的第一件事。 有人读过有用的论文或有类似项目的经验吗？我发现的大多数论文都是关于使用几何数据作为输入的 3D 部件的成本估算。    提交人    /u/Maendli   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnzcxi/rp_looking_for_papers_about_cost_estimation_for/</guid>
      <pubDate>Sun, 10 Nov 2024 12:14:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 PCA 对每个作业的多行数据进行降维的最佳方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnyyol/d_best_approach_to_dimensionality_reduction_with/</link>
      <description><![CDATA[您好！我正在处理一个数据集，其中包含 300 个作业，每个作业都有一个目标标签。对于每个作业，我有大约 1000 个数据点（行），每个数据点由具有各种参数的 17 维向量表示。 我想将每个作业的这 1000 行减少为单个代表性向量，以用于模型训练。但是，我想避免仅使用每列的平均值和方差，因为我认为这会丢失太多信息。 使用 PCA 是一种好方法吗？如果是这样，我可以使用第一个主成分 (PCA1) 及其相关方差来形成单个代表性向量吗？例如，将每个 17D 向量投影到 PCA1 上，然后对这些投影取加权平均值（由 PCA1 的解释方差加权）是否会为每个作业产生一个好的单个向量？ 非常感谢，祝您周末愉快。    提交人    /u/aaronhallam773   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnyyol/d_best_approach_to_dimensionality_reduction_with/</guid>
      <pubDate>Sun, 10 Nov 2024 11:49:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] 建立了一个路线图网站，25 天内获得了 450 名用户，我太高兴了！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnwfhn/p_built_a_roadmap_site_and_got_450_users_in_25/</link>
      <description><![CDATA[      大家好，我是一名三年级 cse 学生。上个月，我建立了一个名为 https://www.mldl.study/ 的网站。该网站面向任何“刚”接触机器学习和深度学习且不知道从哪里开始的人。我建立这个网站是因为我也对此感到困惑。它有适当的视频讲座、文章、研究论文、可视化、kaggle 竞赛以及基本上掌握 ml 和 dl 所需的一切。 我 25 天前刚刚添加了谷歌分析，我发现我有 450 个用户和 135 个回访用户。我建立这个网站只是为了帮助我的大学朋友，但我很高兴它也能帮助其他人。我只是想分享这个，因为我对此很高兴。这让我有信心，我将来可以构建更酷、更有用的东西。 谢谢大家。我的分析能力从这里得到了一点推动。谢谢！！ （我也愿意接受建议和所有我可以做的事情来进一步发展它） https://preview.redd.it/s9v6omy5f10e1.png?width=1558&amp;format=png&amp;auto=webp&amp;s=eeb9a22012e2e3806245e9267a1187bb91e75305    提交人    /u/Grouchy-Breakfast-20   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnwfhn/p_built_a_roadmap_site_and_got_450_users_in_25/</guid>
      <pubDate>Sun, 10 Nov 2024 08:48:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] AAAI 第 2 阶段反驳回复和 Openreview 中的审稿人更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnvy2i/r_aaai_phase_2_rebuttal_response_and_reviewer/</link>
      <description><![CDATA[我想知道我们是否可以在审阅者在 OpenReview 中提交新回复和更新后的评分时查看它们，或者我们是否需要等到 12 月 9 日。此外，在反驳期间，所有审阅者是否都可以看到我们提交给其他审阅者的回复，还是每个审阅者只能查看针对他们的回复？    提交者    /u/morphinejunkie   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnvy2i/r_aaai_phase_2_rebuttal_response_and_reviewer/</guid>
      <pubDate>Sun, 10 Nov 2024 08:13:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 经典 GNN（GCN、GraphSAGE、GAT）是节点分类的强大基线</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnsn54/r_classic_gnns_gcns_graphsages_gats_are_strong/</link>
      <description><![CDATA[我们很高兴与大家分享我们最近的论文“[NeurIPS 2024] 经典 GNN 是强大的基线：重新评估用于节点分类的 GNN”。 在本研究中，我们对用于节点分类任务的经典 GNN 进行了彻底的审查。我们的研究结果表明，最先进的图学习模型经常报告的卓越性能可能是由于经典 GNN 中的超参数配置不理想。通过对这些超参数进行微调，我们表明，在 18 个广泛使用的节点分类数据集中，经典 GNN 在 17 个上的表现优于最新模型。 Arxiv：https://arxiv.org/abs/2406.08993 代码：https://github.com/LUOyk1999/tunedGNN 如果您发现我们的工作很有趣，我们将非常感谢您在 GitHub 上留下 ⭐️！    提交人    /u/luoyuankai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnsn54/r_classic_gnns_gcns_graphsages_gats_are_strong/</guid>
      <pubDate>Sun, 10 Nov 2024 04:32:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于“反向”嵌入（即将向量/张量嵌入到文本、图像等）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrta9/d_on_reverse_embedding_ie_embedding/</link>
      <description><![CDATA[编辑：我并不是指解码器本身，我忘记澄清这一点，这是我的错。我的意思是指一个（更）直接的计算或数学框架，它不涉及训练另一个网络来进行反向嵌入。  正如标题所暗示的，是否有可能正在研究进行反向嵌入的方法和/或过程？从我昨天进行的初步互联网侦查来看，这似乎基本上是不可能的，因为逆映射将如何发挥作用。在这方面，使用我们现有的硬件和设置几乎不可能实现。 但是，也许你们中的一些人可能知道一些可能已经进入这个方向的文献，即使是在理论或初级层面，如果您能指出这些资源，我将不胜感激。也欢迎您分享您的想法和理论。 从反向嵌入扩展，是否可以超越嵌入向量/张量的范围，从而反向嵌入所述嵌入向量/张量，然后从中检索结果文本，图像等？ 提前谢谢您！    提交人    /u/YsrYsl   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrta9/d_on_reverse_embedding_ie_embedding/</guid>
      <pubDate>Sun, 10 Nov 2024 03:43:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对数概率与信息论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrpfe/d_log_probability_and_information_theory/</link>
      <description><![CDATA[在机器学习中，我们大量使用对数概率，试图最大化对数概率。从数字角度来看，这是有道理的，因为加法比乘法更容易，但我也想知道“对数概率”背后是否有根本含义。 例如，对数概率在信息论中被广泛使用，是“信息”的负数。我们能从信息论的角度来看待最小化负对数似然吗？它是最大化/最小化某些信息指标吗？    提交人    /u/masonw32   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrpfe/d_log_probability_and_information_theory/</guid>
      <pubDate>Sun, 10 Nov 2024 03:37:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[N] ARC 奖项为解决网格上彩色方块组成的谜题的少样本学习提供 60 万美元奖金。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnnstd/n_the_arc_prize_offers_600000_for_fewshot/</link>
      <description><![CDATA[        提交人    /u/moschles   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnnstd/n_the_arc_prize_offers_600000_for_fewshot/</guid>
      <pubDate>Sun, 10 Nov 2024 00:08:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] Jay McClelland 解释并行分布式处理、大脑的工作原理、赫布学习和反向传播</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gng4fy/r_jay_mcclelland_explains_parallel_distributed/</link>
      <description><![CDATA[      Jay McClelland 是人工智能领域的先驱，也是认知心理学家，斯坦福大学心理学、语言学和计算机科学系的教授。Jay 与 David Rumelhart 共同出版了两卷著作《并行分布式处理》，该书推动了联结主义理解认知的方法的蓬勃发展。 在这次对话中，Jay 为我们速成讲解了神经元和生物大脑的工作原理。这为 Jay、David Rumelhart 和 Geoffrey Hinton 等心理学家在历史上如何处理认知模型以及最终的人工智能的发展奠定了基础。我们还讨论了神经计算的替代方法，例如符号和神经科学方法以及反向传播的发展。 https://preview.redd.it/s7xv0pmk2xzd1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=2e5be31c51a8eb78bf7033d1def25fa29f0863af https://preview.redd.it/h4sqjoim2xzd1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=e7c952d579322379c67a77adadf1d392afe8d3c6 Youtube： https://www.youtube.com/watch?v=yQbJNEhgYUw&amp;list=PL0uWtVBhzF5AzYKq5rI7gom5WU1iwPIZO&amp;index=1&amp;pp=iAQB Spotify： https://open.spotify.com/show/1X5asAByNhNr996ZsGGICG RSS： https://feed.podbean.com/cartesiancafe/feed.xml    由   提交  /u/IamTimNguyen   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gng4fy/r_jay_mcclelland_explains_parallel_distributed/</guid>
      <pubDate>Sat, 09 Nov 2024 18:11:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 当机器学习讲述错误的故事时</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gne2x1/r_when_machine_learning_tells_the_wrong_story/</link>
      <description><![CDATA[  由    /u/jackcook  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gne2x1/r_when_machine_learning_tells_the_wrong_story/</guid>
      <pubDate>Sat, 09 Nov 2024 16:40:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>