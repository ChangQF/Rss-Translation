<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 18 Jan 2025 15:14:56 GMT</lastBuildDate>
    <item>
      <title>[D] 使用原型网络进行小样本学习——有助于理解概念</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i45h9r/d_fewshot_learning_with_prototypical_networks/</link>
      <description><![CDATA[嗨，对于那些了解这个概念的人来说，这可能是相当简单的问题，但对我来说仍然很难理解。 假设我有一个包含 200 个标记样本的数据集，我有 10 个类。但是，并非所有 200 个示例都包含所有 10 个类，而只包含其中一些，而其余样本包含它们的组合。这意味着一个样本可能被标记为类 0、1、5、8，而另一个样本被标记为 0、3、7 等等。这也意味着类别的流行程度差异很大。 如何使用原型网络分割我的数据集以进行小样本学习？我是否需要在包含所有类别的样本上进行训练和验证，以便网络学习为每个类别计算原型？此外，鉴于类别的普遍性各不相同，我是否需要平衡抽样，以便在训练和验证集的数量上平等地看到每个类别？ 在测试期间，我是否需要在测试集中为每个类别包含一些标记样本？我可以在没有标记样本的情况下进行推理吗？那是零样本学习吗？此外，我可以训练一个在训练期间推广到看不见的类别的模型吗？ 提前感谢您的时间和帮助！    提交人    /u/That_Machine9579   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i45h9r/d_fewshot_learning_with_prototypical_networks/</guid>
      <pubDate>Sat, 18 Jan 2025 11:17:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 液体神经网络在 OOD 环境中表现出强大的导航能力。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i458ut/r_liquid_neural_networks_exhibit_robust/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i458ut/r_liquid_neural_networks_exhibit_robust/</guid>
      <pubDate>Sat, 18 Jan 2025 11:01:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 因果推理遇上深度学习：综合综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i455gs/r_causal_inference_meets_deep_learning_a/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i455gs/r_causal_inference_meets_deep_learning_a/</guid>
      <pubDate>Sat, 18 Jan 2025 10:54:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 启动一个机器人联盟，协作训练对象操作模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i44wlr/p_launch_a_federation_of_robots_that/</link>
      <description><![CDATA[      使用 Flower 和 LeRobot，我整理了一个快速入门示例，演示了如何在 10 个独立节点（每个节点都有自己的数据集分区！）之间协作训练扩散模型。此示例使用 push-t 数据集，其中的任务是将字母 T 对象移动到另一个保持静止的对象之上。 该示例非常容易运行，如果您可以使用最新的游戏 GPU，则可以高效运行。虽然扩散模型仅占用 2GB 的 VRAM（当然您可以决定扩大规模），但训练它们所需的计算量不容小觑。就上下文而言，在双 RTX 3090 设置上，运行示例直到收敛需要 40 分钟。虽然示例默认运行 50 轮，但这样做大约需要 30 轮联邦学习 (FL)。 在不同轮次对全局模型进行评估。经过几轮协作 AI 训练后，模型成功完成了任务（而且速度非常快！！！） 示例默认在模拟中运行每个节点/机器人（即每个节点都是一个 Python 进程，并且有一些巧妙的调度以资源感知的方式运行作业）。但将其作为实际部署运行很简单，例如每个节点都是一个不同的设备（例如 NVIDIA Jetson）。如果有人有兴趣这样做，请查看示例自述文件底部添加的链接 了解有关行动扩散策略方法的更多信息 -&gt; https://arxiv.org/abs/2303.04137    提交人    /u/jfrmqOX   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i44wlr/p_launch_a_federation_of_robots_that/</guid>
      <pubDate>Sat, 18 Jan 2025 10:37:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我讨厌softmax</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i44h5v/d_i_hate_softmax/</link>
      <description><![CDATA[这是一个半开玩笑的说法，核心概念相当简单，但我相信社区会引用大量证据来支持和驳斥 softmax 很烂的说法，并真正使其成为一场严肃而有趣的讨论。 什么是 softmax？它是应用元素指数函数并通过激活总和进行归一化的操作。它直观地做了什么？一点是输出总和为 1。另一点是，相对较大的输出相对于较小的输出变得更大：大激活和小激活被分开。 一个问题是，如果输入是有限的，您永远不会得到零输出（例如，如果没有掩码，您就不能将 0 注意力归因于某些元素）。让我抓狂的是，对于大多数应用，幅度和幅度比率是有意义的，但在 softmax 中它们不是：softmax 关心差异。以 softmax([0.1, 0.9]) 和 softmax([1,9]) 或 softmax([1000.1,1000.9]) 为例。您认为哪个相等？在哪些应用中这是更自然的方式？ 数值不稳定性、奇怪的梯度、嵌入规范都是受此类简单核心影响的事物。当然，与此同时，softmax 是深度学习的主力之一，它做得相当不错。 还有其他人也这么讨厌我吗？有人热衷于在我眼中挽回 softmax 吗？    提交人    /u/Sad-Razzmatazz-5188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i44h5v/d_i_hate_softmax/</guid>
      <pubDate>Sat, 18 Jan 2025 10:05:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] Nuggt：从互联网上检索信息，用作 LLM 的背景信息（开源）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i43l2c/p_nuggt_retrieve_information_from_the_internet_to/</link>
      <description><![CDATA[      Nuggt 演示GIF 嗨 r/MachineLearning， 我们都知道，LLM 输出的质量在很大程度上取决于所提供的上下文和提示。例如，要求 LLM 就给定主题（假设为 X）生成一篇好的博客文章，可能会得到一个通用答案，可能符合也可能不符合您的期望。但是，如果您提供有关如何撰写好文章的指南，并为 LLM 提供有关该主题的其他相关信息，那么您收到符合您需求的回复的机会就会大大增加。 考虑到这一点，我想创建一个工作区，使构建和管理用于 LLM 的上下文变得容易。我想我们中的许多人可能会在类似以下的工作流程中使用 LLM： 任务：假设您想为您的初创公司撰写一份电梯游说。 步骤 1：研究如何撰写一份好的电梯游说，然后将关键点保存为上下文。 步骤 2：查找有效电梯游说的示例并将这些示例添加到您的上下文中。 步骤 3：将此精选的上下文传递给 LLM，并要求其为您的初创公司制作一份电梯游说。重要的是，您期望透明度 - 确保 LLM 按预期使用您提供的上下文并展示它如何为输出提供信息。 如果您发现这样的工作流程很有吸引力，我想您会喜欢这个工具。以下是其主要功能：  它集成了 Tavily 和 Firecrawl，可从互联网上收集任何主题的信息。 您可以突出显示任何要点，右键单击，然后将其保存为上下文。 您可以将此上下文传递给 LLM，LLM 将使用它来协助您完成任务。在其回复中，LLM 将引用上下文的相关部分，以便您可以验证您的输入是如何使用的，甚至将其追溯到原始来源。  我的假设是，我们中的许多人都会从构建强大的上下文中受益，以完成我们的任务。当然，我可能是错的 - 也许这只是我的一个怪癖，投入如此多的精力来创建详细的上下文！谁知道呢？唯一的办法就是把它发布在这里，看看社区是怎么想的。 我很乐意听到你的反馈！ 这是 github repo：https://github.com/shoibloya/nuggt-research    提交人    /u/Loya_3005   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i43l2c/p_nuggt_retrieve_information_from_the_internet_to/</guid>
      <pubDate>Sat, 18 Jan 2025 08:59:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于动态神经元控制器的 Transformer 架构：需要反馈</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i40viz/d_dynamic_neuroncontrollerbased_transformer/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i40viz/d_dynamic_neuroncontrollerbased_transformer/</guid>
      <pubDate>Sat, 18 Jan 2025 05:45:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有没有关于机器学习和因果推理中的贝叶斯方法的论文推荐？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i3ym76/r_any_paper_recommendations_for_bayesian_methods/</link>
      <description><![CDATA[大家好， 我对贝叶斯方法很陌生，从数据科学和建模的角度对它以及它如何确定因果关系感到好奇。 我真的不知道从哪里开始，但我读过一些关于贝叶斯网络的论文，听说过一些关于贝叶斯深度学习的有趣的事情，所以很高兴看到关于这些主题的任何建议。 我也很高兴听到你最近读过的任何论文，但我在寻找你们觉得有趣的东西，而不是任何特定领域的应用，只是对现在学习理论感兴趣（除非你建议我先选择一个领域）。 非常感谢    提交人    /u/Sea_Farmer5942   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i3ym76/r_any_paper_recommendations_for_bayesian_methods/</guid>
      <pubDate>Sat, 18 Jan 2025 03:29:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 构建强化学习代理来玩《塞尔达传说》</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i3t4c3/p_building_an_reinforcement_learning_agent_to/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i3t4c3/p_building_an_reinforcement_learning_agent_to/</guid>
      <pubDate>Fri, 17 Jan 2025 22:52:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] 有没有关于这个数据集的正式参考？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i3rrkx/p_are_there_any_formal_references_to_this_dataset/</link>
      <description><![CDATA[大家好！ 我正在开展一个关于多点触控归因建模的项目，使用 Tensor Flow 预测不同渠道的转化。 在项目中，我们使用此数据集 (https://www.kaggle.com/code/hughhuyton/multitouch-attribution-modelling)。但是，我们找不到任何正式参考资料（已发表的论文或类似资料）来进行适当的引用。我在 Google 上搜索了很多……真的，很多。 有人知道数据的来源是什么吗？或者它是否在某处被引用？ 谢谢您的帮助。    提交人    /u/mklsls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i3rrkx/p_are_there_any_formal_references_to_this_dataset/</guid>
      <pubDate>Fri, 17 Jan 2025 21:51:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我其实是一名机器学习工程师吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i3qxy4/d_am_i_actually_a_machine_learning_engineer/</link>
      <description><![CDATA[过去几年，我的官方头衔是“机器学习工程师”，但当我在网上寻找其他工作时，我想知道这是否准确。根据列出的经验要求和职责，它似乎与我的工作不匹配。 我拥有专注于机器学习的硕士学位（尽管那是在法学硕士热潮之前，所以情况发生了很大变化），但大学毕业后很难在我所在的领域找到与此相关的工作。在 COVID 之后，当每个人都远程办公时，我得到了我现在的工作。在其中，我致力于团队构建和部署利用机器学习来完成任务的软件。但是，我从来不是真正构建学习模型的人（我们团队中有一位研究人员是这样做的）；只是围绕它们创建系统。我实际上对我的“机器学习相邻”工作感到非常满意角色，但我应该搜索不同的职位名称来找到类似的职位吗？    提交人    /u/Cranyx   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i3qxy4/d_am_i_actually_a_machine_learning_engineer/</guid>
      <pubDate>Fri, 17 Jan 2025 21:15:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2025 年值得关注的 AI 论文推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i39iuh/d_recommendations_of_noteworthy_ai_papers_for/</link>
      <description><![CDATA[嗨，我正在设计一份论文清单，推荐给刚开始学习计算机科学的学生。 有哪些必读的论文，但又不是太深奥？ 如今，所有的统计学习理论都可以通过在线课程获得，但我希望他们能够成长为阅读学术论文的人。 我从 ilya Sutskever 的阅读清单开始。 也欢迎您简要解释一下您推荐这篇论文的原因！    提交人    /u/treblenalto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i39iuh/d_recommendations_of_noteworthy_ai_papers_for/</guid>
      <pubDate>Fri, 17 Jan 2025 05:36:33 GMT</pubDate>
    </item>
    <item>
      <title>探索数值稳定性的边缘 [研究]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i34keg/grokking_at_the_edge_of_numerical_stability/</link>
      <description><![CDATA[ Grokking 是长时间过度拟合后突然出现的泛化现象，是一种令人惊讶的现象，挑战了我们对深度学习的理解。尽管在理解 grokking 方面取得了重大进展，但延迟泛化及其对正则化的依赖背后的原因仍不清楚。在这项工作中，我们认为，如果没有正则化，grokking 任务会将模型推向数值稳定性的边缘，从而在 Softmax 函数中引入浮点错误，我们将其称为 Softmax Collapse (SC)。我们证明 SC 可以防止 grokking，而减轻 SC 可以在没有正则化的情况下实现 grokking。通过研究 SC 的根本原因，我们发现，在过度拟合点之后，梯度与我们所谓的朴素损失最小化 (NLM) 方向高度一致。梯度的这个部分不会改变模型的预测，但会通过缩放 logits（通常是通过沿其当前方向缩放权重）来减少损失。我们表明，这种对数的缩放解释了 grokking 的泛化延迟特征，并最终导致 SC，从而停止进一步的学习。为了验证我们的假设，我们引入了两个关键贡献来解决 grokking 任务中的挑战：StableMax，一种新的激活函数，可防止 SC 并允许 grokking 无需正则化，以及 ⊥Grad，一种通过完全防止 NLM 来促进 grokking 任务快速泛化的训练算法。这些贡献为 grokking 提供了新的见解，阐明了其延迟的泛化、对正则化的依赖以及现有 grokking 诱导方法的有效性。  论文：https://arxiv.org/abs/2501.04697 （不是我的论文，只是推荐给我的东西）   由    /u/JohnnyAppleReddit  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i34keg/grokking_at_the_edge_of_numerical_stability/</guid>
      <pubDate>Fri, 17 Jan 2025 01:06:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 12 Jan 2025 16:00:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>