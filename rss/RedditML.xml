<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Mon, 14 Apr 2025 01:25:05 GMT</lastBuildDate>
    <item>
      <title>[d]刚刚开源了一家经过10年印度市场数据的Financial LLM  - 您可以在DuckDB上运行的SQL Outputs SQL</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jyjkjf/d_just_opensourced_a_financial_llm_trained_on_10/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 想分享我在过去几周中一直在建立的东西 - 一个小的开源项目，这是一个很小的开源项目。 我对结构性的印度股票市场数据 -  ohlcv，ohlcv和Index Data-ex cross-10+ 10岁以上的结构性印度股票市场数据进行了调整，使一个变形金刚在结构化的印度股票市场数据上进行了微调。该模型输出SQL查询，以响应自然语言问题，例如：  “ 2021-03-31在Int_profit上是什么？ 它是100％离线 - 没有API，没有云通话 - 并用数据集预加载的DuckDB文件船。您可以将模型的SQL输出粘贴到DuckDB中，并立即获得结果。您甚至可以在不更改架构的情况下添加自己的数据。 如果您将它们接地在实际结构化数据集中，则将其构建为概念的概念。 它在此处的拥抱脸上直播：    https://huggingface.co/studentone/nifty50gpt-final        ，如果您尝试尝试或将其扩展为想法，则会喜欢反馈。欢呼。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/cod_277Killsshipment     [link]   [commist]         ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jyjkjf/d_just_opensourced_a_financial_llm_trained_on_10/</guid>
      <pubDate>Sun, 13 Apr 2025 22:15:18 GMT</pubDate>
    </item>
    <item>
      <title>[P]推理和微调正在融合 - 还有其他人在考虑这一点吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jyilsf/p_inference_and_finetuning_are_converging_is/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  感觉就像训练基础模型基本上已经合并了。 OpenAI，Meta，Mistral等。该层非常锁定。 ，但是越来越有趣的是，发生了什么 - 微调。它越来越快，更便宜，而且更具个性。团队正在将模型调整为自己的数据，代理商正在即时自定义行为，开发人员希望在本地调整音调或工作流程。 ，这让我思考，推理和微调不应该是两个完全独立的堆栈。 我们一直在建立他们可以安排的想法。例如：•使用空闲的GPU时间来运行背景微调作业  •如果推断请求进来，请暂停，并立即恢复快照（即使在14b+上我们看到了sub-2s sub-2 sub-2）••提供响应，然后恢复以后的         几乎可以用作可用的过程。预定，暂停，恢复，先发制人，取决于需要的东西。 ，令人惊讶地有效地保持GPU的高利用而不会过度提供。 奇怪的是，是否有人在玩这个方向，如果您仍在挥霍推理，或者您仍在分别散布和微调的推理和微调吗？ href =“ https://www.reddit.com/r/inferx”&gt; r/susterx 如果有人想深入研究。另外在x上：@inferxai   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jyilsf/p_inference_inference_and_and_finetuning_are_are_areverging_is/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jyilsf/p_inference_and_finetuning_are_converging_is/</guid>
      <pubDate>Sun, 13 Apr 2025 21:30:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 2025：向SOTA的正确性转变？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jydy3j/d_icml_2025_a_shift_toward_correctness_over_sota/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;   icml今年的策略 - 一个很好的方向，优先考虑Chasing Sota？   &lt;！ -  sc_on-&gt; sc_on-&gt; 32;提交由＆＃32; /u/u/fit-marketing5979      ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jydy3j/d_icml_2025_a_shift_toward_correctness_over_sota/</guid>
      <pubDate>Sun, 13 Apr 2025 18:08:33 GMT</pubDate>
    </item>
    <item>
      <title>[d] Kaggle竞赛对博士学位学生是否值得？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jy9hp7/dkaggle_competition_is_it_worthwhile_for_phd/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不确定这是否是一个愚蠢的问题。 Kaggle竞赛目前是否对于工程领域或计算机科学领域的博士学生来说仍然值得吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/superstarrockyou    href =“ https://www.reddit.com/r/machinelearning/comments/1jy9hp7/dkaggle_competition_is_it_it_it_worthlile_for_phd/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jy9hp7/dkaggle_competition_is_it_worthwhile_for_phd/</guid>
      <pubDate>Sun, 13 Apr 2025 14:55:13 GMT</pubDate>
    </item>
    <item>
      <title>[研究]我如何使用知识图来引导LLM的思维过程：帮助我将其集中在特定的想法或主题上</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jy6mgq/research_how_i_use_knowledge_graphs_to_steer_llms/</link>
      <description><![CDATA[       &lt;！ -  sc_off- sc_off-&gt;  我喜欢这种方法，因为它就像是梦dream以求的是思考（因此是想念（因此）。因此，我可以使AI将其回答集中在我感兴趣的领域上。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/noduslabs      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jy6mgq/research_how_ies_ise_sove_knowledge_graphs_graphs_to_steer_steer_lls/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jy6mgq/research_how_i_use_knowledge_graphs_to_steer_llms/</guid>
      <pubDate>Sun, 13 Apr 2025 12:34:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] Tiktok Brainrot Generator更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jy5w5l/p_tiktok_brainrot_generator_update/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  不久前，我制作了一个脑腐发生器，它利用motu hira的wav2vec2算法进行力对齐，它得到了一定的牵引力（ https://www.reddit.com/r/machinelearning/comments/1hlgdyw/pthlgdyw/p \_i \_made_a _a \_tiktok_brain \ _rot_rot_video \ _video \ _generator/ ）  这次，我和Vidhu一起对Brain Rot Generator进行了一些更新，Vidhu亲自与我联系以帮助我进行这个项目。    - 线程建议。 （现在，如果您不知道该建议的建议，则可以让LLM为您建议您又名GROQ 70B LLAMA和VADER情感）   - 图像覆盖层。 (This was done using an algorithm which showed the timestamp, similar to the audio for force alignment but done using image instead) - Dockerization support (It now supports dockerisation) - Web App (For easy usage, I have also made a web app that makes it easy to toggle between features) - Major bug fixed (Thanks to Vidhu for identifying and fixing the bug which阻止人们使用回购） 这是github： sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jy5w5l/p_tiktok_brainrot_generator_update/”&gt; [link]        [commist]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jy5w5l/p_tiktok_brainrot_generator_update/</guid>
      <pubDate>Sun, 13 Apr 2025 11:51:13 GMT</pubDate>
    </item>
    <item>
      <title>[d]您如何管理使用ML模型的实验？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jy5ue4/d_how_do_you_manage_experiments_with_ml_models_at/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在在一家公司做我的硕士论文，该论文对AI模型没有大量实验，而且绝对没有系统性，因此，当我启动时，我决定首先实施“标准”的“标准”项目结构（带有HYDRA和MLFLOW的CCD）。我花了一些时间来编写所需的所有内容，设置配置文件等。这并不是说要设法存储地块，可视化它们甚至任何形式的编排（无论如何都在我的范围之外）。 我在大学研究项目和学校工作中都做了同样的事情，因此，由于我没有预算，而且我想学习一切，我自己就可以自己实施一切。不过，如果您确实有预算，这似乎太多了。 你们如何管理实验？使用一些SaaS平台，运行开源工具（哪个？），或者编写自己的小堆栈并自己管理？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jy5ue4/d_how_do_do_do_you_manage_experiments_with_with_ml_models_at/  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jy5ue4/d_how_do_do_do_you_manage_experiments_with_with_ml_models_models_models_at/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jy5ue4/d_how_do_you_manage_experiments_with_ml_models_at/</guid>
      <pubDate>Sun, 13 Apr 2025 11:48:09 GMT</pubDate>
    </item>
    <item>
      <title>[d] ML悖论：当更好的指标导致更糟的结果时 - 您面对这个吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jy4odf/d_the_ml_paradox_when_better_metrics_lead_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  想象一下，您已经训练了一个理论上  excell yours 的模型（准确性，F1-SCORE，AUC-ROC等），但实际上实际上   在现实世界中造成了灾难性的失败。 For example:   A medical diagnosis model with 99% accuracy that disproportionately recommends harmful treatments for rare conditions. A self-driving car API that reduces pedestrian collisions in simulations but causes erratic steering in rain, leading to more crashes. An NLP chatbot that scores highly on “有益的”基准测试，但在询问心理健康时会提供危险的建议。    悖论：您的模型是按指标/研究标准“更好”，但在道德上，社会上或功能上或功能上是“更糟糕的”。   问题：  1。您是否遇到了此断开连接？分享您的故事！ 2。我们如何使用现实世界影响？ 3。如何对基准进行优化。我们甚至可以衡量后者吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/munibkhanali     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jy4odf/d_the_ml_paradox_when_better_better_metrics_lead_to/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jy4odf/d_the_ml_paradox_when_better_metrics_lead_to/</guid>
      <pubDate>Sun, 13 Apr 2025 10:29:45 GMT</pubDate>
    </item>
    <item>
      <title>[P]谐波激活：神经网络的周期性和单调功能扩展（预印本）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jxqtoo/p_harmonic_activations_periodic_and_monotonic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，伙计们！我最近发布了一个预印本，提出了一个新的激活功能系列，专为无标准化的深层网络而设计。我是一名独立研究人员，致力于MLP和变压器的表达性非线性。   tl; dr：  i提出了一个残留激活函数：    f（x）= x +α·g（sin²（sin²（πx/2）） gelu） 我想听听反馈。这是我的第一篇论文。   preprint ：[ &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/henriquelmeeee     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jxqtoo/p_harmonic_activations_periodic_and_monotonic/</guid>
      <pubDate>Sat, 12 Apr 2025 20:39:09 GMT</pubDate>
    </item>
    <item>
      <title>[D]“推理模型并不总是说出他们的想法”  - 有人提示吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jxjwi2/d_reasoning_models_dont_always_say_what_they/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是否有人尝试通过使用自己的提示来复制的“推理模型并不总是说出他们的想法” 纸张？我正在努力再现这些输出。如果您对此进行了尝试并进行了微调，您是否可以分享您的提示或一路上获得的任何见解？任何讨论或指示都将不胜感激！ 参考，这是：       - 提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jxjwi2/d_reasoning_models_models_dont_always_always_say_say_what_they/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jxjwi2/d_reasoning_models_dont_always_say_what_they/</guid>
      <pubDate>Sat, 12 Apr 2025 15:30:53 GMT</pubDate>
    </item>
    <item>
      <title>[n] Google开放，让企业自我主机SOTA模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jxin3q/n_google_open_to_let_entreprises_self_host_sota/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  从主要参与者中，这听起来像是一个很大的变化，并且大多会为企业提供有关数据隐私的有趣视角。 Mistral在Openai和Anthropic维护更多封闭式产品或通过合作伙伴时已经做了很多事情。   https://www.cnbc.com/2025/04/09/google-will-let-companies-run-gemini-models-models-in-their-own-data-centers.html     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jxin3q/n_google_open_to_to_let_tto_tto_entreprises_erse_host_host_sota/”&gt; [link]   [commist]     ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jxin3q/n_google_open_to_let_entreprises_self_host_sota/</guid>
      <pubDate>Sat, 12 Apr 2025 14:33:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] D1：通过增强学习在扩散大语模型中扩展推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jxeahf/r_d1_scaling_reasoning_in_diffusion_large/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   最近的大型语言模型（LLMS）已证明了强大的推理能力，可以从在线增强学习（RL）中受益。这些功能主要在从左到右的自回归（AR）一代范式中证明。相比之下，基于扩散的非运动范式以粗到精细的方式产生文本。尽管与AR相比，最近基于扩散的大语言模型（DLLM）已经达到了竞争性语言建模性能，但尚不清楚DLLM是否也可以利用LLM推理的最新进展。为此，我们提出了D1，这是一个框架，可以通过有监督的Finetuning（SFT）和RL的组合将预先训练的戴上DLLM适应推理模型。具体而言，我们开发并扩展了技术以改善预验证的DLLM中的推理：（a）我们利用蒙版的SFT技术直接从现有数据集中提炼知识并灌输自我提高行为，（b）我们引入了一种新颖的无评论，策略级别的RL算法，称为DIFFU-GRPO。通过实证研究，我们研究了不同的训练后食谱对多个数学和逻辑推理基准的性能。我们发现D1可以产生最佳性能，并显着提高了最先进的DLLM的性能。  在扩散扩散大语模型上，使用强化学习来缩放扩散模型。当涉及到实际上原因的语言模型时，绝对需要注意！ 纸链接：  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/hiskuu     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jxeahf/r_d1_scaling_reasoning_in_diffusion_large/</guid>
      <pubDate>Sat, 12 Apr 2025 10:30:15 GMT</pubDate>
    </item>
    <item>
      <title>[P]一种轻巧的开源模型，用于产生漫画</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jws42t/p_a_lightweight_opensource_model_for_generating/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jws42t/p_a_lightweight_opensource_model_for_generating/</guid>
      <pubDate>Fri, 11 Apr 2025 15:06:32 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jpdo7y/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</guid>
      <pubDate>Wed, 02 Apr 2025 02:15:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_be_hired/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Mon, 31 Mar 2025 02:30:37 GMT</pubDate>
    </item>
    </channel>
</rss>