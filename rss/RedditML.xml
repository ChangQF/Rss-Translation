<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 06 Dec 2023 09:14:10 GMT</lastBuildDate>
    <item>
      <title>[D] 为什么大多数开源人工智能都发生在美国境外？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18by3wo/d_why_is_most_open_source_ai_happening_outside/</link>
      <description><![CDATA[我不认为这太双曲线。美国有 Meta，除此之外几乎没有什么，特别是与外部的相比。 我并不是说要在美国扣篮，我真的只是感到震惊。 &lt; strong&gt;中国：Yuan、Qwen、DeepSeek、Yi、XVERSE、Aquila、RWKV，都是当今顶级的法学硕士。 一打很棒的（顶级）多模式。顶级嵌入模型。 英国：稳定性 法国： Mistral 芬兰（？）： Lumi Poro 阿联酋： Falcon 俄罗斯：康定斯基 &lt; p&gt;美国：Meta 有 Llama 和其他一些好东西，Salesforce 有一些东西，“OpenAI”等。  是监管环境吗？是投资问题吗？是GPU短缺吗？大型科技公司是否挖走了并锁定了所有美国人才？ 有人有任何线索吗？ 编辑： 哇，我走出了大门。我的要求越来越合理。这里提到的所有模型都是经过预训练的模型。是的，美国社区可以进行微调，但这没有表达我的观点。昂贵的 OSS 工作正在美国境外进行。如果你说“那不是 OSS”，好吧，它仍然主要发生在美国境外。再说一遍，不是在美国扣篮，只是问一个问题，并希望看到更多的美国公司出现在 OSS 贡献者名单上。   由   提交 /u/BayesMind   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18by3wo/d_why_is_most_open_source_ai_happening_outside/</guid>
      <pubDate>Wed, 06 Dec 2023 06:45:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何计算旨在缓解十字路口交通拥堵的 SARSA 模型的奖励？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bwqpn/d_how_to_calculate_reward_for_a_sarsa_model/</link>
      <description><![CDATA[我有一个 SARSA 强化学习模型，可以预测一条车道的交通拥堵情况，并尝试将该车道的交通信号灯变为绿色以减少交通量拥塞。对于每条车道，如果灯为红灯，我都会计算每辆车的等待时间。将所有车辆的等待时间相加后，我得到每个车道的总等待时间。我用它来计算奖励。等待时间越短，奖励越高。但是，我的模型正在做出随机决策，并且每一代的奖励都在波动。 我的问题是，如何使我的模型更好？如何正确定义操作和状态空间，以便模型可以预测哪条车道的等待时间较长，然后将该车道的交通灯变为绿色？我尝试了学习率和 epsilon 衰减，但发现差异很小。我还能做些什么来使模型的预测更好？   由   提交 /u/camelCase_Dev   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bwqpn/d_how_to_calculate_reward_for_a_sarsa_model/</guid>
      <pubDate>Wed, 06 Dec 2023 05:19:46 GMT</pubDate>
    </item>
    <item>
      <title>Apple 发布“MLX” - Apple Silicon 的 ML 框架 [N]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bwe19/apple_releases_mlx_ml_framework_for_apple_silicon/</link>
      <description><![CDATA[Apple 的 ML 团队刚刚在 GitHub 上发布了“MLX”。他们针对 Apple Silicon 的 ML 框架。 https://github.com/ml-explore/mlx CUDA 的现实替代方案？ MPS 已经非常高效...如果我们看到采用，这可能会变得有趣。 ​   由   提交 /u/LoadingALIAS   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bwe19/apple_releases_mlx_ml_framework_for_apple_silicon/</guid>
      <pubDate>Wed, 06 Dec 2023 05:00:05 GMT</pubDate>
    </item>
    <item>
      <title>[D]先验关联规则微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bv9ij/d_apriori_association_rules_fine_tune/</link>
      <description><![CDATA[我正在使用 apriori 算法来获取数据集的关联规则。问题是，我没有得到足够的结果（不同的）来使结果在 0.01 支持下有用。如果我将其增加到 0.001 个实例，则会因内存问题而死亡。这种情况我们该怎么办？ 欢迎提出建议   由   提交 /u/bubdi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bv9ij/d_apriori_association_rules_fine_tune/</guid>
      <pubDate>Wed, 06 Dec 2023 03:58:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习论文所需的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18br4km/d_advice_needed_for_ml_thesis/</link>
      <description><![CDATA[大家好， 我是人工智能专业的硕士生，我真的很难为我的硕士论文找到主题...我的兴趣主要在于 ML/DL，但我不确定我应该关注哪个主题。 在我看来，有两种方法：  第一种方法是获取数据集并使用深度学习来解决特定问题。现在的问题是（至少在我看来）所有问题看起来都一样，你只需在不同模型上试验和错误你的数据，直到获得适当的准确性。我不太确定这如何被视为科学工作。 第二种方法将致力于特定的理论领域，例如开发一种新的算法，或者修改已经存在的算法现有的。  在这两种情况下，我都不确定应该选择什么主题以及如何找到主题。我一直在想，我应该做一些半伟大的论文。 我应该提到我打算发表论文并最终获得博士学位。 任何指导都会是非常感谢！   由   提交 /u/labianconeri   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18br4km/d_advice_needed_for_ml_thesis/</guid>
      <pubDate>Wed, 06 Dec 2023 00:29:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大海捞针实验：Assistant API RAG 以 4% 的成本击败 GPT 4-Turbo & Llama Index</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bivxa/d_needle_in_a_haystack_experiment_assistants_api/</link>
      <description><![CDATA[      进行了一项实验，比较 Open AI 助手 API 的 RAG、GPT-4 Turbo（具有上下文窗口填充）和 Llama Index with GPT4 之间的信息检索性能。&lt; /p&gt; 我最近向 CopilotKit 添加了一个新的面向文档 React hook，专门制作来容纳（可能是长格式）文档并希望获得最佳性能。 得到了相当惊人的结果：助手的 API 在性能上大大击败了 Llama 索引，并且比使用 GPT-4 Turbo 填充上下文窗口便宜 25 倍。 ​ 准确度表现 ​ 成本 使用人工智能进行构建时的重大收获。几乎没有人应该使用上下文窗口填充，而且 Llama Index 在 RAG 性能方面还有很多工作要做。 无论 OpenAI 在 RAG 的底层使用什么，都具有出色的性能。 完整文章： https://ai88.substack.com/p/rag-vs-context-window- in-gpt4-准确度-成本   由   提交/u/kindly_formation71   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bivxa/d_needle_in_a_haystack_experiment_assistants_api/</guid>
      <pubDate>Tue, 05 Dec 2023 18:38:26 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]传统机器学习在学术界的活力如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bhxuo/discussion_how_alive_is_traditional_machine/</link>
      <description><![CDATA[业界常用的技术和模型还有研究空间吗？我目前是一名数据科学家，正在考虑攻读硕士或博士学位。在机器学习中。然而，最近的发展似乎主要集中在神经网络，尤其是大型语言模型（LLM）上。尽管广泛搜索了 arXiv 文章，但我在找到特征工程、概率模型和基于树的算法等领域的研究方面收效甚微。如果有人知道专门研究这些更传统的机器学习方面的教授，请告诉我。    由   提交 /u/BrDataScientist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bhxuo/discussion_how_alive_is_traditional_machine/</guid>
      <pubDate>Tue, 05 Dec 2023 17:58:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你不需要矢量数据库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bhlsj/d_you_do_not_need_a_vector_database/</link>
      <description><![CDATA[RAG 的文档检索问题基本上是信息检索的情况，并且有更简单的解决方案。矢量嵌入仍然有用，但它们应该在 IR 管道的后期使用，而不是作为第一阶段检索，因为第一阶段检索有更简单、性能更高的解决方案。 此处的博客文章：http://about.xethub.com/blog/you-dont-need-a-vector-数据库 此处的笔记本和数据：https://github.com/xetdata/RagIRBench/   由   提交/u/yu Chenglow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bhlsj/d_you_do_not_need_a_vector_database/</guid>
      <pubDate>Tue, 05 Dec 2023 17:44:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 即时工程看起来像是猜测 - 如何正确评估 LLM 申请？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bgqyv/d_prompt_engineering_seems_like_guesswork_how_to/</link>
      <description><![CDATA[人们如何评价您的 LLM 申请质量？我正在生产中运行一个治疗师聊天机器人（小规模 - 10 多个活跃用户），我花了很多时间微调提示，但这只是猜测。 我将对提示并运行一些测试对话，然后稍微了解一下它是否比调整之前更好或更差。这也是你们都在做的事情还是我错过了什么？？？   由   提交 /u/AndreeSmothers   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bgqyv/d_prompt_engineering_seems_like_guesswork_how_to/</guid>
      <pubDate>Tue, 05 Dec 2023 17:06:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] AlphaFold 预测是有价值的假设，可以加速但不能取代实验结构确定</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bge4o/r_alphafold_predictions_are_valuable_hypotheses/</link>
      <description><![CDATA[社区绝对应该考虑来自科学实践的反馈：https://www.nature.com/articles/s41592-023-02087-4 引用：  &lt; p&gt;我们的结果表明，AlphaFold 预测并不比 PDB 中沉积的模型更好地表示晶体的内容，因为沉积的模型与实验数据更加一致，而预测和沉积的模型不同    由   提交 /u/suhcoR   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bge4o/r_alphafold_predictions_are_valuable_hypotheses/</guid>
      <pubDate>Tue, 05 Dec 2023 16:51:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研究人员如何产生新机器学习架构的想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bgb2n/d_how_do_researchers_generate_idea_of_new_machine/</link>
      <description><![CDATA[我从事机器学习工作已经有一段时间了，但我仍然专注于应用现有的机器学习技术。  每年我都对产生如此巧妙的建筑的过程感到困惑。如果您有经验，可以分享一下您是如何想出这个新想法的吗？在此过程中，什么对您启发最大？   由   提交 /u/Feisty_Philosophy234   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bgb2n/d_how_do_researchers_generate_idea_of_new_machine/</guid>
      <pubDate>Tue, 05 Dec 2023 16:47:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何应对对你的论文是人工智能生成的错误指控？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ben3c/d_how_to_deal_with_false_accusations_of_your/</link>
      <description><![CDATA[读到我从 ICLR-2024 论文中获得的主观评论的质量有点令人沮丧。其中两个人相当不错，但另外两个人指责我的论文是一个“笑话”。和人工智能生成的。看到一个所谓的顶级会议允许公开发布此类不良评论，令人感到悲伤。现在，除非领域主席介入，否则外行人会对我的研究产生极大的偏见。   由   提交 /u/No-Sun-5534   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ben3c/d_how_to_deal_with_false_accusations_of_your/</guid>
      <pubDate>Tue, 05 Dec 2023 15:38:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 加州大学伯克利分校的论文“Sequential Modeling Enables Scalable Learning for Large Vision Models”有一条奇怪的缩放曲线。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18bdcu7/r_sequential_modeling_enables_scalable_learning/</link>
      <description><![CDATA[   看到这篇论文“顺序建模实现大视觉模型的可扩展学习” （https://arxiv.org/abs/2312.00785）其中的数字看起来有点奇怪。对于不同的模型尺寸，线条看起来相同。  不同的运行或不同尺寸的大型模型通常是相同的吗？ https:/ /twitter.com/JitendraMalikCV/status/1731553367217070413  ​ 取自 https://arxiv.org/abs/2312.00785 中的图 3 这是完整的图3图 来自https:// arxiv.org/abs/2312.00785   由   提交/u/rantana  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18bdcu7/r_sequential_modeling_enables_scalable_learning/</guid>
      <pubDate>Tue, 05 Dec 2023 14:37:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] StableSSM：通过稳定的重参数化缓解状态空间模型中的内存诅咒</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18b8nn4/r_stablessm_alleviating_the_curse_of_memory_in/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2311.14495 OpenReview：https:// /openreview.net/forum?id=BwG8hwohU4 摘要：  在本文中，我们研究了长期从参数化的角度来看状态空间模型（SSM）的记忆学习能力。我们证明，没有任何重新参数化的状态空间模型表现出与传统 RNN 类似的内存限制：可以通过状态空间模型稳定近似的目标关系必须具有指数衰减内存。我们的分析确定了这种“记忆诅咒”。由于循环权重收敛到稳定边界，这表明重新参数化技术可能是有效的。为此，我们引入了一类 SSM 重新参数化技术，可以有效解除其内存限制。除了提高逼近能力之外，我们进一步说明重新参数化方案的原则性选择还可以增强优化稳定性。我们使用合成数据集和语言模型验证了我们的发现。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18b8nn4/r_stablessm_alleviating_the_curse_of_memory_in/</guid>
      <pubDate>Tue, 05 Dec 2023 09:56:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>