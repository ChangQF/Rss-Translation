<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 21 Dec 2024 15:14:43 GMT</lastBuildDate>
    <item>
      <title>[D] ResNet 与 Transformer 在音频分类任务上的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjacxa/d_resnet_vs_transformer_on_audio_classification/</link>
      <description><![CDATA[我是公司的一名研发软件工程师，几乎完成了一个唤醒词系统（如 Ehy google），该系统可在非常小的音频数据集上训练，同时保留非常轻的模型资源印记，以便以 0 延迟和低电池影响运行。我使用了残差网络，其残差是在输入频谱图的频率维度上计算的。一位同事在我获得优秀结果之前建议我，Transformer 架构会表现更好（由于过度自信，我出现了假阳性问题，已通过温度缩放和标签平滑解决）。我应该尝试具有自我注意的 Transformer 吗？Transformer 架构在每种情况下都优于 Resnet 吗？ 谢谢    提交人    /u/CatsOnTheTables   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjacxa/d_resnet_vs_transformer_on_audio_classification/</guid>
      <pubDate>Sat, 21 Dec 2024 13:58:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 努力寻找相关工作，并理解这个图问题是什么任务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hj8rdu/d_struggling_to_find_related_work_and_understand/</link>
      <description><![CDATA[我有一个包含 15k 个节点的图，每个节点都由一个 ID 标识。我可以计算节点之间的距离。在推理过程中，我得到了一个包含 10-30 个节点的子图，需要识别它们，面临的挑战包括缺失/错误节点以及边缘值的轻微不精确。 我在推理过程中得到的子图将仅包含彼此靠近的节点。 这是一个子图匹配问题还是节点分类问题？我的主管想使用 GNN。简单的三角方法可以得到很好的结果，但我需要一种深度学习方法，其中输入是子图，输出是节点 ID 列表。 我很难找到与此相关的工作 - 有什么建议吗？    提交人    /u/Turbulent-Quality906   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hj8rdu/d_struggling_to_find_related_work_and_understand/</guid>
      <pubDate>Sat, 21 Dec 2024 12:19:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 努力寻找博士研究之路</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hj6nbf/d_struggling_to_find_my_path_in_phd_research/</link>
      <description><![CDATA[大家好，希望你们不介意我发泄一下，但我希望能够深入了解我所面临的挑战。我是一名研究时间序列的二年级博士生，老实说，我以为现在我会有一个明确的研究问题。但我没有，这让我开始感到困惑。 部分困难来自于选择“热门”主题的巨大压力。我看到的该领域的许多研究都受到我只能描述为闪亮物体综合症的驱动——追逐最新趋势，而不是专注于有意义和实质性的工作。例如，我看到几篇论文使用大型语言模型 (LLM) 进行时间序列预测。虽然 LLM 无疑令人着迷，但它更像是一种试图强行将它们融入时间序列的尝试，因为它很“酷”，而不是因为它是解决手头问题的最佳工具。而我不想成为这种趋势的一部分。 但这里有一个难题：你如何选择一个既真实又有影响力的研究课题，尤其是当你周围的一切似乎都被最新的炒作所驱动时？你是追随这些新兴趋势，还是专注于能与你产生深刻共鸣的东西，即使它不是其他人都在研究的“闪亮”的东西？ 老实说，我感觉有点陷入困境，对自己没有信心。我是不是想太多了？这只是过程的一部分吗？我如何找到一个符合我的兴趣和我想为这个领域做出贡献的大局的方向？如果有人经历过类似的事情或有任何建议，我将不胜感激。 感谢您花时间阅读这篇文章——我真的很感激您能提供的任何见解或鼓励。    提交人    /u/Few-Pomegranate4369   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hj6nbf/d_struggling_to_find_my_path_in_phd_research/</guid>
      <pubDate>Sat, 21 Dec 2024 09:45:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2025 年机器学习研究的热点是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hj0p0y/d_whats_hot_for_machine_learning_research_in_2025/</link>
      <description><![CDATA[2025 年，机器学习或与机器学习相关的哪些子领域/方法、应用领域有望获得广泛关注（无意双关）？    提交人    /u/ureepamuree   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hj0p0y/d_whats_hot_for_machine_learning_research_in_2025/</guid>
      <pubDate>Sat, 21 Dec 2024 03:00:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有办法将 3D 网格数据转换为矢量嵌入？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hj0j1m/d_is_there_a_way_to_convert_3d_mesh_data_into/</link>
      <description><![CDATA[大家好， 现在我有一堆 3D 网格数据，以 .obj 表示，我想将它们传递到矢量数据库中进行检索。 我想知道，是否有现有的嵌入方法可以让我做到这一点？我认为传统的文本嵌入（如 text-embedding-3-large）在 3D 数据上效果不佳？ 提前感谢大家！    提交人    /u/LooouisZ   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hj0j1m/d_is_there_a_way_to_convert_3d_mesh_data_into/</guid>
      <pubDate>Sat, 21 Dec 2024 02:50:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么蒙特卡洛树搜索是增量博弈树搜索的唯一方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hizb1u/d_why_is_monte_carlo_tree_search_the_only_goto/</link>
      <description><![CDATA[我注意到，每当需要一种搜索​​方法，使其质量随推理时间计算而变化时，人们总是选择 MCTS，而从未考虑过其他类型的搜索方法。看看广泛使用的 MCTS 版本（例如 UCB 等），很明显很多启发式方法都是手工制作的。有没有关于更好的搜索方法的研究（也许是元学习的方法）？我觉得有很多机会可以改进手工制作的启发式过程。    提交人    /u/TommyX12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hizb1u/d_why_is_monte_carlo_tree_search_the_only_goto/</guid>
      <pubDate>Sat, 21 Dec 2024 01:41:38 GMT</pubDate>
    </item>
    <item>
      <title>XQ-GAN：用于自回归生成的开源图像标记化框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hiwl1m/xqgan_an_opensource_image_tokenization_framework/</link>
      <description><![CDATA[  由    /u/xternalz  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hiwl1m/xqgan_an_opensource_image_tokenization_framework/</guid>
      <pubDate>Fri, 20 Dec 2024 23:20:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 不再使用 Adam：初始化时调整学习率就是你所需要的</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hivid1/r_no_more_adam_learning_rate_scaling_at/</link>
      <description><![CDATA[  由    /u/RobbinDeBank  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hivid1/r_no_more_adam_learning_rate_scaling_at/</guid>
      <pubDate>Fri, 20 Dec 2024 22:28:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI o3 在 ARC 奖挑战赛上获得 87.5% 高分</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hiq3tz/d_openai_o3_875_high_score_on_arc_prize_challenge/</link>
      <description><![CDATA[https://arcprize.org/blog/oai-o3-pub-breakthrough  OpenAI 的新 o3 系统 - 在 ARC-AGI-1 公共训练集上进行训练 - 在我们所述的公共排行榜 10,000 美元计算限制下的半私人评估集上取得了突破性的 75.7% 的成绩。高计算（172x）o3 配置得分为 87.5%。     提交人    /u/currentscurrents   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hiq3tz/d_openai_o3_875_high_score_on_arc_prize_challenge/</guid>
      <pubDate>Fri, 20 Dec 2024 18:20:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 更快的推理：torch.compile 与 TensorRT</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1himai0/r_faster_inference_torchcompile_vs_tensorrt/</link>
      <description><![CDATA[在我们对 LLama-7b、LLama-3-8b、mistral-v0.1、phi-3 和 phi-2 等模型的测试中，torch.compile 在易用性和性能方面优于 TensorRT。除非您需要 TensorRT 特定的功能或专门在 NVIDIA 的生态系统中工作，否则 torch.compile 是优化 PyTorch 模型的更好选择。 https://www.collabora.com/news-and-blog/blog/2024/12/19/faster-inference-torch.compile-vs-tensorrt/   由    /u/mfilion  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1himai0/r_faster_inference_torchcompile_vs_tensorrt/</guid>
      <pubDate>Fri, 20 Dec 2024 15:32:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 超级连接</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hiiktb/r_hyperconnections/</link>
      <description><![CDATA[      TL;DR 残差流的更复杂、更高性能变体。 论文： https://arxiv.org/pdf/2409.19606 摘要：  我们提出了超连接，这是一种简单而有效的方法，可以作为残差连接的替代方案。这种方法专门解决了残差连接变体中观察到的常见缺点，例如梯度消失和表示崩溃之间的跷跷板效应。从理论上讲，超连接允许网络调整不同深度特征之间的连接强度并动态重新排列层。我们进行了实验，重点是大型语言模型的预训练，包括密集和稀疏模型，其中超连接比残差连接显示出显着的性能改进。在视觉任务上进行的其他实验也证明了类似的改进。我们预计，这种方法将广泛应用于各种人工智能问题，并能从中受益。  视觉摘要： 相信我，它没有乍一看那么复杂 视觉亮点： 最令人印象深刻的收益是使用 MoE 架构实现的，尽管 Dense Transformers 也得到了提升 超连接在一定程度上缓解了表示崩溃 扩展率是指将残差流拆分为 n 个独立的分量，每个分量都进行动态门控。每个 Transformer 块的输入都是这些组件的简单总和 SHC=静态门控，DHC=动态门控 计算开销可以忽略不计 https://preview.redd.it/238ex3emtz7e1.png?width=973&amp;format=png&amp;auto=webp&amp;s=ac12792a4d45f7bf6e91f767dd12f2134ec74083    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hiiktb/r_hyperconnections/</guid>
      <pubDate>Fri, 20 Dec 2024 12:18:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我不再认为反驳有什么意义。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hi9jt2/d_i_dont_see_a_point_in_rebuttals_anymore/</link>
      <description><![CDATA[这是一些沉思和一些咆哮的混合体，但根据标题，我只是觉得它没有任何意义。我最近从一次会议上得到了结果，我得到了两个正面评论和一个负面评论。然后写了一篇非常好的反驳，解决了对审稿人的根本误解（后来审稿人确实增加了他们的分数，所以我猜反驳是正确的？）。但结果是，元审稿人抓住了负面评论，甚至没有阅读针对该评论的反驳并拒绝了这篇论文。 如果有关各方_甚至不会阅读它们_，我反驳的意义何在？在这一点上，我很想把反驳阶段当作徒劳无功。也许我应该在第一阶段撤回论文，因为出现任何问题，而不是试图经历最终毫无意义的劳动的痛苦。   由    /u/pddpro  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hi9jt2/d_i_dont_see_a_point_in_rebuttals_anymore/</guid>
      <pubDate>Fri, 20 Dec 2024 02:18:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] chat-gpt 越狱提取系统提示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hi429q/d_chatgpt_jailbreak_to_extract_system_prompt/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hi429q/d_chatgpt_jailbreak_to_extract_system_prompt/</guid>
      <pubDate>Thu, 19 Dec 2024 21:48:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hevk2a/d_simple_questions_thread/</guid>
      <pubDate>Sun, 15 Dec 2024 16:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>