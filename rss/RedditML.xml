<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 07 Oct 2024 12:33:25 GMT</lastBuildDate>
    <item>
      <title>[D] 我们可以直接在 Google Drive 文件上处理 ML 模型而无需下载吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fy6e5y/d_can_we_directly_process_ml_models_on_google/</link>
      <description><![CDATA[我正在为我的老板做一个项目，但遇到了这个问题。我希望有某种方法可以让模型至少在不下载所有内容的情况下进行处理...这可能吗...？    提交人    /u/wannasleepforlong   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fy6e5y/d_can_we_directly_process_ml_models_on_google/</guid>
      <pubDate>Mon, 07 Oct 2024 12:28:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 根据任务复杂性灵活部署计算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fy54kn/d_flexible_compute_deployment_based_on_task/</link>
      <description><![CDATA[大家好，ML 的朋友们。我是一名认知科学专业的学生，​​研究神经科学和机器学习的交叉领域。大脑最酷的事情之一可能就是它能够完成的任务是多么的高效——依靠灯泡运行。据我所知，这可能是因为如果任务不需要所有参数，则不会使用它们。到目前为止，我发现的唯一与此类似的 ML 方法是专家混合法。除此之外，在深度学习中，优化推理过程似乎被忽视了——通常只是使用所有参数，而不管自上而下的上下文或输入统计数据。 我几乎可以肯定我错了，所以我希望你们能给我指出一些深入研究这个问题的好论文？或者也许是问题的正式名称？例如，你可以攻读法学硕士学位。如果对句子中下一个单词的预测很简单（例如食草动物吃 [植物]），我可能不需要所有参数就能得到完美的预测（Claude 和 LLama 可能会做得同样好，但 Claude 解决这个问题的成本更高），而不是更技术性、需要更多注意力和背景投入处理的预测（例如，解决数学证明）。    提交人    /u/Karioth1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fy54kn/d_flexible_compute_deployment_based_on_task/</guid>
      <pubDate>Mon, 07 Oct 2024 11:16:17 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 用于从成本估算文件中提取关键信息的 NER</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fy3o00/project_ner_for_extracting_key_information_from/</link>
      <description><![CDATA[我需要开展一个命名实体识别项目。我有一个 CSV 文件，其中包含来自 270 个文档的文本以及成本估算。我的任务是提取以下信息： a) 文档收件人 b) 产品数量 c) 产品价格 d) 产品名称 e) 文档 ID 代码 文档通常遵循一致的结构，具有清晰的模式。例如，文档收件人始终出现在相同的字母之后。产品名称始终位于数量和价格之间，因此识别这两个元素将使我能够提取介于两者之间的任何内容。我需要提取的其他关键部分也是如此。您对如何以简单而准确的方式处理此问题有什么建议吗？谢谢！    提交人    /u/No_Possibility_7588   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fy3o00/project_ner_for_extracting_key_information_from/</guid>
      <pubDate>Mon, 07 Oct 2024 09:35:07 GMT</pubDate>
    </item>
    <item>
      <title>[R][P] AI 特工 LlamaIndex</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fy2y5d/rp_ai_agents_llamaindex/</link>
      <description><![CDATA[AI Agents LlamaIndex 速成课程 内容包括：  函数调用 函数调用代理 + Agent Runner Agentic RAG REAcT 代理：构建您自己的搜索助理代理  https://youtu.be/bHn4dLJYIqE    提交人    /u/External_Ad_11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fy2y5d/rp_ai_agents_llamaindex/</guid>
      <pubDate>Mon, 07 Oct 2024 08:40:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求建议：手写 OCR 的 LLM 与 Google Vision 的 LLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fy1iqx/d_looking_for_advice_llms_for_handwriting_ocr_vs/</link>
      <description><![CDATA[大家好！ 我正在做一个项目，需要从手写图像中提取文本。到目前为止，我一直在使用 Google Vision API，它对包括手写在内的一些文本效果很好，但我想知道是否有更直接的解决方案专门处理手写。 使用可以直接处理和读取手写内容的 LLM 是否有意义，还是坚持使用传统的 OCR 方法（如 Google Vision）仍然是可行的方法？我知道 GPT-4o/Gemini 等 LLM 具有这些功能，但我不确定它们处理基于图像的输入或手写的效果如何。 有人尝试过使用 LLM 进行 OCR 吗？您会推荐什么，是否有特定的模型可以擅长这项任务？ 我的想法是还使用 LLM 来总结手写文本，因此在流程的某个阶段，无论如何我都需要 LLM。 谢谢。    提交人    /u/Practical_Estate4971   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fy1iqx/d_looking_for_advice_llms_for_handwriting_ocr_vs/</guid>
      <pubDate>Mon, 07 Oct 2024 06:49:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言建模任务上的 Mamba 和 SSM 是一个很好的研究轨迹吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxzor7/r_is_mamba_and_ssms_on_language_modelling_task_a/</link>
      <description><![CDATA[我刚刚接触到 Mamba 和 SSM，因为我的教授说我应该尝试探索它。我是一名硕士生，刚刚开始我的研究之旅，我原本想像我系里的其他学生一样研究 transformers LM。有人说这会让我陷入别人以前没有做过的事情，会使我的学习/研究变得比预想的更难（最终可能会得到平庸的结果）。你们对此有什么看法吗？谢谢。    提交人    /u/worthlesspineapple   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxzor7/r_is_mamba_and_ssms_on_language_modelling_task_a/</guid>
      <pubDate>Mon, 07 Oct 2024 04:41:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 正在从事客户流失预测项目，模型输出的流失窗口是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxyzkz/p_working_on_a_customer_churn_prediction_project/</link>
      <description><![CDATA[如果我使用的数据集包含过去 15 年的所有活跃客户和所有流失客户，我该如何决定我希望我的模型预测未来 90 天的情况？我相信在训练之前我应该​​在数据中进行某种“时间框架”，但我不确定如何解决此类问题    提交人    /u/Extension-Group2131   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxyzkz/p_working_on_a_customer_churn_prediction_project/</guid>
      <pubDate>Mon, 07 Oct 2024 03:57:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于工具使用和 LLM 代理有哪些有趣的论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxvsp7/d_what_are_some_interesting_papers_about_tooluse/</link>
      <description><![CDATA[目前，我正在研究 voyager (https://arxiv.org/abs/2305.16291)，但希望得到更多建议。TIA。    提交人    /u/a1_jakesauce_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxvsp7/d_what_are_some_interesting_papers_about_tooluse/</guid>
      <pubDate>Mon, 07 Oct 2024 01:04:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] ML 论文的敏感性分析获得了更好的结果，现在怎么办？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxu3zw/d_sensitivity_analysis_of_the_ml_paper_got_better/</link>
      <description><![CDATA[我使用一种新方法针对特定数据集撰写了一篇 ML 论文，取得了一些积极成果。我训练了几个模型，对它们进行了评估，并根据研究结果进行了广泛的解释和讨论。其中一位审稿人要求对一些预处理参数/算法进行敏感性分析。有趣的是，其中一项更改导致的结果比我原来的方法略好。 我的问题是：在这种情况下的期望是什么？我需要重写整篇论文，还是应该仅在敏感性分析中报告这一观察结果？虽然更改改善了结果，但想到要根据新的运行重写大部分解释（例如，特征重要性、图表、讨论等），还是很令人沮丧。你的想法和经验是什么？    提交人    /u/anagreement   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxu3zw/d_sensitivity_analysis_of_the_ml_paper_got_better/</guid>
      <pubDate>Sun, 06 Oct 2024 23:37:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 有没有想过在你的 m1 16gb ram Mac 上微调 Xtts？好吧，我不知道为它做了一个 repo，</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxt77o/p_ever_wanted_to_fine_tune_xtts_on_your_m1_16gb/</link>
      <description><![CDATA[   https://github.com/DrewThomasson/finetuneXtts_apple_silicone 你需要 16 gb ram 来运行，而 docker 版本需要更多的 ram 来运行 :/ 压缩模型按钮中的 Final_output_files 与 https://github.com/DrewThomasson/ebook2audiobookXTTS 兼容   由   提交  /u/Impossible_Belt_7757   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxt77o/p_ever_wanted_to_fine_tune_xtts_on_your_m1_16gb/</guid>
      <pubDate>Sun, 06 Oct 2024 22:51:36 GMT</pubDate>
    </item>
    <item>
      <title>上下文感知词语替换 [P] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxsuhg/context_aware_word_replacement_p_r/</link>
      <description><![CDATA[你好！ 我从事 CV 研究，所以对 NLP 不是很精通，所以需要输入。 我正在研究在保留图片上下文的情况下替换“句子”中的“单词”，以便我们更容易在数据集中搜索该单词的合适图像。例如： 句子 - “学生应该抵制网络欺凌，以免攻击者伤害他们” 单词 - “攻击者” 为什么预期 - 网络犯罪分子、网络欺凌者等，以便我可以搜索相关图像。 BeRT 和其他模型用什么来替换它 - 恐怖分子、计算机、敌对攻击者等。 我想在本地运行一些东西，但找不到任何解决方案。有什么想法或输入我应该尝试吗？有任何资源或代码笔记本吗？    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxsuhg/context_aware_word_replacement_p_r/</guid>
      <pubDate>Sun, 06 Oct 2024 22:34:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxif7x/d_simple_questions_thread/</guid>
      <pubDate>Sun, 06 Oct 2024 15:00:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 LLM 培训中，增加批次大小和使用注意力掩蔽的打包序列有什么区别？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxguh6/d_whats_the_difference_between_increasing_batch/</link>
      <description><![CDATA[我很好奇在固定长度序列上训练大型语言模型 (LLM) 时，以下两种方法之间的区别： 使用批量大小 = 4，其中每个样本的序列长度为 1024 个标记，并且它们被独立处理。将 4 个序列打包成一个批次，最大序列长度为 4096，并应用注意掩码以确保没有序列关注来自另一个序列的标记。 如果正确应用了注意掩码，确保不会关注其他序列，那么这两种方法在以下方面是否存在显着差异： 内存使用情况 计算成本 训练动态  据我所知，如果没有注意掩码，由于自注意力机制，打包会导致计算成本呈二次方增加。但是使用掩码后，计算和内存使用量不是与将它们作为批处理中的单独序列处理几乎相同吗？还是我遗漏了其他因素？    提交人    /u/JeanMichelRanu   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxguh6/d_whats_the_difference_between_increasing_batch/</guid>
      <pubDate>Sun, 06 Oct 2024 13:46:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] MaskBit：通过 Bit Tokens 生成无嵌入图像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fxfy91/r_maskbit_embeddingfree_image_generation_via_bit/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fxfy91/r_maskbit_embeddingfree_image_generation_via_bit/</guid>
      <pubDate>Sun, 06 Oct 2024 13:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>