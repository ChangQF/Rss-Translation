<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 09 Nov 2024 15:17:11 GMT</lastBuildDate>
    <item>
      <title>[P] 使用文本或图像特征和实值回归目标对监督数据集进行基准测试或开源？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnb9z5/p_benchmark_or_open_source_supervised_datasets/</link>
      <description><![CDATA[出于某种原因，我似乎找不到任何以文本或图像为特征、以实值为目标的知名基准数据集。任何目标范围都可以（（0,1）、（-infinity, infinity）、（0, infinity）等）。我找到了具有序数分类目标的示例（例如 1-5 的整数评级），但这不符合我的目的。 有谁知道任何符合此描述的开源监督 ML 数据？最好是具有性能排行榜的基准数据集。    提交人    /u/BreakingBaIIs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnb9z5/p_benchmark_or_open_source_supervised_datasets/</guid>
      <pubDate>Sat, 09 Nov 2024 14:28:56 GMT</pubDate>
    </item>
    <item>
      <title>[R][D] 模式匹配 != 推理：我们分析了 2 条不同的路径，让 LLM 真正思考 [技术深度探讨]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gna1wq/rd_pattern_matching_reasoning_we_analyzed_2/</link>
      <description><![CDATA[首席 ML 和密码学家研究员。刚刚完成了一项可能会惹恼某些人的研究，但数据不会说谎：当前的 LLM（是的，甚至 GPT-4）只是非常复杂的自动完成功能。这就是为什么这很重要。 TL;DR: * 当前的 LLM 实际上并不推理，它们的模式匹配非常好 * 我们确定了两条有希望的前进道路：训练时间和推理时间增强 * PEFT + 思维链提示一起显示出令人惊讶的结果 * 所有研究/代码都将开源 https://blog.bagel.net/p/train-fast-but-think-slow   由    /u/Future_Recognition97  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gna1wq/rd_pattern_matching_reasoning_we_analyzed_2/</guid>
      <pubDate>Sat, 09 Nov 2024 13:25:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医学 AI：顶级 LLM 研究论文/模型（2024 年 11 月 2 日至 11 月 9 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gn8wqp/d_last_week_in_medical_ai_top_llm_research/</link>
      <description><![CDATA[      上周医学 AI：顶级 LLM 研究论文/模型（2024 年 11 月 2 日至 11 月 9 日） 本周医学 AI 论文：  谷歌推出*：探索用于专家级肿瘤护理的大型语言模型*  本文使用 50 个合成癌症小插图评估了乳腺肿瘤学中的对话式诊断 AI 系统 AMIE。借助网络搜索检索和自我批评流程，AMIE 在制定管理计划方面的表现优于内科实习生和肿瘤学研究员，使用涵盖病例总结、计划安全性和治疗建议的详细临床评估标准进行评估。   医学 LLM 及其他模型：  AutoProteinEngine：多模态蛋白质 LLM  本文介绍了 AutoProteinEngine (AutoPE)，这是一个由 LLM 驱动的蛋白质工程多模态 AutoML 框架，使没有深度学习专业知识的生物学家能够使用自然语言与 DL 模型进行交互。AutoPE 将 LLM 与 AutoML 集成，用于模型选择（序列和图形模态）、超参数优化和自动数据检索，在两个现实世界的蛋白质工程任务中表现出比传统方法显着的性能改进。代码可从以下位置获取：  GSCo：通才-专才 AI 协作  本文介绍了 GSCo，这是一种结合通才基础模型 (GFM) 和专才模型的医学图像分析框架。它开发了最大的开源医学 GFM MedDr 和用于下游任务的轻量级专才。  用于肺部 X 射线分割的 SAM  本文探讨了 Meta AI 的 Segment Anything Model (SAM) 在胸部 X 射线分析中用于肺部分割的应用。这项研究采用了带有微调的迁移学习方法，与原始 SAM 相比，其性能有所提高，所取得的结果可与 U-Net 等最先进的模型相媲美。  MEG：知识增强型医学问答  本文介绍了 MEG，这是一种使用轻量级映射网络为大型语言模型 (LLM) 提供医学知识图谱的参数高效方法。在四个医学多项选择数据集上进行评估后，MEG 的准确率比 Mistral-Instruct 基线提高了 10.2%，比 BioMistral 等专业模型提高了 6.7%，证明了知识图谱集成的好处。   框架和方法：  BrainSegFounder：3D 神经图像分析 PASSION：撒哈拉以南皮肤病学数据集 Label Critic：数据优先方法 Medprompt 运行时策略  医学 LLM 应用：  CataractBot：患者支持系统 CheX-GPT：X 射线报告增强 CardioAI：癌症心脏毒性监测器 HealthQ：医疗保健对话Chain PRObot：糖尿病视网膜病变助理  医学法学硕士和基准：  MediQ：临床推理基准 Touchstone：分割评估 医学 LLM 适应进展 微调医学 QA 策略  医疗伦理中的 AI：  具有 LLM 的医疗机器人 临床实践中的 XAI 精准康复框架 多模式 AI 挑战  完整线程详细信息：https://x.com/OpenlifesciAI/status/1855207141302473090    由   提交  /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gn8wqp/d_last_week_in_medical_ai_top_llm_research/</guid>
      <pubDate>Sat, 09 Nov 2024 12:20:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] MiniBoosts：一组小型的 boosting 算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gn8mpt/p_miniboosts_a_small_collection_of_boosting/</link>
      <description><![CDATA[大家好。 我用 Rust 编写了一个小型的 boosting 算法集合，名为 MiniBoosts。 这是一个业余项目，但我想进一步改进。 欢迎任何反馈意见。 感谢您的合作。    提交人    /u/__leopardus__   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gn8mpt/p_miniboosts_a_small_collection_of_boosting/</guid>
      <pubDate>Sat, 09 Nov 2024 12:03:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 嵌入和 docker 文件 - 两个库之间的比较 - 有没有比 ONNX 更好的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gn87vi/d_embeddings_and_docker_file_comparison_between/</link>
      <description><![CDATA[正如标题所说，我想知道是否还有其他方法可以在不使用 torch 的情况下嵌入语料库。我想到的解决方案之一是使用 ONNX。我使用 Qdrant 中的 fastembed 库和 sentence-transformer 库创建了图像。使用 fastembed 可以显著减小图像尺寸。 问题： 还有其他方法（例如修改 dockerfile 或使用其他库）可以进一步缩小 docker 映像吗？ 公共 repo：https://github.com/learning-bos/dockerize-torch-fastembed-sentence-transformer-comparison   由    /u/Ambitious-Most4485  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gn87vi/d_embeddings_and_docker_file_comparison_between/</guid>
      <pubDate>Sat, 09 Nov 2024 11:36:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否有人用全连接层替换了 Transformers，并证实其性能确实更差（对于训练语言模型）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gn6sam/d_has_anyone_replaced_transformers_with/</link>
      <description><![CDATA[这似乎是一个显而易见的问题，但这样的“数据点”对于消除我们的无知非常有帮助。    提交人    /u/Cyber​​netic1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gn6sam/d_has_anyone_replaced_transformers_with/</guid>
      <pubDate>Sat, 09 Nov 2024 09:52:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 开源文本到代理：从 YAML 文件开发 AI 代理的框架。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gn2e5w/p_opensource_texttoagent_framework_to_develop_ai/</link>
      <description><![CDATA[大家好，我想听听你们对我正在开发的一个项目的反馈。我正在构建一个框架，从 YAML 配置文件中定义 AI 代理。这些文件封装了需要完成的任务、它们如何连接等，而其余的都被抽象出来了。 现在的想法是使用 LLM 本身从用户提示中创建这些 YAML 文件。由于配置文件具有代理的所有核心逻辑并删除了所有不必要的细节，我认为这是构建文本到代理框架的最有效方法。 Wdyt？ 让我知道你的想法，并查看 repo https://github.com/octopus2023-inc/gensphere 如果您想做出贡献并使其发挥作用，请告诉我。    提交人    /u/Jazzlike_Tooth929   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gn2e5w/p_opensource_texttoagent_framework_to_develop_ai/</guid>
      <pubDate>Sat, 09 Nov 2024 04:47:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] PAKDD 2023 数据？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gn282v/d_pakdd_2023_data/</link>
      <description><![CDATA[我正在研究 PAKDD 2023 上发表的研究论文。从作者的名字，我可以猜出他们是中国人、韩国人或日本人 我知道 PAKDD 是双盲评审。但为什么其他人不提交他们的作品？或者如果他们提交了，为什么接受的数量很低 我也是亚洲人，所以我不是想在这里种族歧视。只是想知道为什么会这样    提交人    /u/Alarming-Camera-188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gn282v/d_pakdd_2023_data/</guid>
      <pubDate>Sat, 09 Nov 2024 04:37:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单的 ML 模型托管服务？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmzb3q/d_simple_ml_model_hosting_service/</link>
      <description><![CDATA[我的工作是寻找一种让人工智能帮助制定计划的方法，我真的认为一个简单的多变量模型就可以解决问题；只需要找到一个可靠的托管服务，可以根据需要在此基础上进行构建。是否有成熟的 ML 托管商，它们可扩展、可配置，等等？    提交人    /u/Lucrayzor   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmzb3q/d_simple_ml_model_hosting_service/</guid>
      <pubDate>Sat, 09 Nov 2024 01:55:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大多数时间序列异常检测结果毫无意义（两个简短的视频解释了原因）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmwxnr/r_most_time_series_anomaly_detection_results_are/</link>
      <description><![CDATA[亲爱的同事们 时间序列异常检测 (TSAD) 目前非常热门，每年在 NeurIPS、SIGKDD、ICML、PVLDB 等会议上都会发表数十篇论文。 但是，我认为大部分已发表的结果都毫无意义，因为基本事实标签的不确定性使得算法之间声称的任何差异或声称的改进量相形见绌。 我制作了两个 90 秒长的视频，以视觉和直观的方式清楚地说明了这一点：  1) 为什么大多数时间序列异常检测结果毫无意义（道奇队） https://www.youtube.com/watch?v=iRN5oVNvZwk&amp;ab_channel=EamonnKeogh  2）为什么大多数时间序列异常检测结果毫无意义（AnnGun） https://www.youtube.com/watch?v=3gH-65RCBDs&amp;ab_channel=EamonnKeogh 与往常一样，欢迎更正和评论。 Eamonn  编辑：需要说明的是，我的观点只是为了防止其他人浪费时间处理带有本质上随机标签的数据集。此外，我们应该对文献中基于此类数据的任何主张保持谨慎（其中包括至少数十篇被高度引用的论文） 有关大多数常用 TSAD 数据集的审查，请参阅此文件： https://www.dropbox.com/scl/fi/cwduv5idkwx9ci328nfpy/Problems-with-Time-Series-Anomaly-Detection.pdf?rlkey=d9mnqw4tuayyjsplu0u1t7ugg&amp;dl=0    由    /u/eamonnkeogh 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmwxnr/r_most_time_series_anomaly_detection_results_are/</guid>
      <pubDate>Fri, 08 Nov 2024 23:58:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于经典游戏的人工智能生成的游戏世界？（例如 Spyro）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmspmt/d_aigenerated_gameworlds_based_on_classic_games/</link>
      <description><![CDATA[我想知道是否有人想过这样的事情可能有多遥远或有多困难。自从当前 ai/llms 时代到来以来，我认为能够以某种形式从怀旧游戏中获取数据并创建某种类型的系统来无限生成这些世界会很棒 - 同时仍然非常忠实于参考游戏中的世界/关卡的风格和布局/精神。如果有一条道路可以创建某种“永无止境”的&lt;在此处插入怀旧游戏&gt;，而不是局限于开发人员在过去推出的东西，那将是多么美妙。 如果有人对此有任何见解或想法，请告诉我 :)。我在 AI 领域工作，但我集成了模型，并且没有在低级 ML 方面进行任何训练或任何事情。另外，是的，我现在只考虑游戏世界/级别。    提交人    /u/cobalt1137   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmspmt/d_aigenerated_gameworlds_based_on_classic_games/</guid>
      <pubDate>Fri, 08 Nov 2024 20:49:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 PB 级数据集上进行训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmpedb/d_training_on_petabyte_scale_datasets/</link>
      <description><![CDATA[假设我们有一个比磁盘存储空间大得多的数据集。例如：  数据集：1PB 我们的磁盘存储空间：10TB GPU RAM：8x80GB（与本次讨论不太相关）  对这样的数据进行训练的常用方法是什么？我直观想到的是以某种方式并行执行以下操作： - 预取块 n，在块 n-1 上进行训练，从磁盘中删除块 n-2 假设我们使用 PyTorch，因此我们有一个 PyTorch 数据集，其中包含数据存储在云中的所有路径。我们是否需要为从云端下载并存储在磁盘上的预取器/删除器编写代码，并让其在单独的进程中运行，然后让 DataLoader 用于训练，假设它可以从磁盘读取（因为预取器正确地完成了它的工作）？让 DataLoader 从 S3 读取对 GPU 利用率不利，对吗？ 退一步说，我假设这是每个在大型数据集上进行训练的公司都会遇到的普通且经常发生的“问题”，所以我对自己编写所有这些代码持怀疑态度，因为我觉得应该有标准的开箱即用的解决方案，但真的找不到完美匹配的东西。    提交人    /u/lapurita   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmpedb/d_training_on_petabyte_scale_datasets/</guid>
      <pubDate>Fri, 08 Nov 2024 18:27:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些疯狂的结构或更新规则可能有用（或没用）？欢迎提出极端的想法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gmm7mi/d_what_are_crazy_structures_or_update_rule_that/</link>
      <description><![CDATA[上下文：我正在 pip 上基于 JAX（也是面向 FP 的）制作一个面向 FP 的 NN 库/框架，名为 z-zephyr。但是，我注意到你可以用它做一些笨重的事情，即使不乏味，其他框架也是如此。 （请阅读上下文） TLDR；Zephyr 被证明是一种非常好的方法（至少根据我的经验）来制作奇怪的结构。我最近刚刚添加了更新功能，以便 zephyr 不仅可以构建结构，还可以更新。 免责声明：你可以使用其他框架做到这一点，我在其他框架或库中尝试了很多我将在下面讲述的事情，这对我来说很痛苦，或者我只是对这些不熟悉。  以下是 Zephyr 中可以快速完成的疯狂事情，在其他框架中可能不那么快（如果可以在其他框架中更轻松地完成，请告诉我）。 （这些不应该是有用的，它们应该是极端的） 全二叉树作为神经网络  边具有关联的权重 输入是标量（可以是带有 JAX vmap 的批处理，但让我们考虑 1） 输出形状为 (2n,) 的数组，其中 n 是树的深度 考虑权重是 {L}eft 还是 {R}right 分支的更新规则（我会保持简单，但它可以是任何东西）  这是 Zephyr 中的树网络，以及如何获得初始参数和标签（标签是params[key]中的键）。 ```python # 本质上是 4 行代码 @flexible def tree_net(params, x, n, i=0): if i == n-1: return [x] return ( tree_net( params[&quot;branch&quot;][&quot;L&quot;] if i !=n-2 else params,validate(params[&quot;weight&quot;][&quot;L&quot;], (1,), uniform) * x, n, i+1) + tree_net( params[&quot;branch&quot;][&quot;R&quot;] if i !=n-2 else params,validate(params[&quot;weight&quot;][&quot;R&quot;], (1,), uniform) * x, n, i+1) ) x = jnp.ones((1,)) # 虚拟 N = 4 params = trace(tree_net, key, x, N) tags = get_lineage_tags(params)  ``` 假设您有损失函数和梯度，为了简单起见，我只需更新，使左分支的权重为 0，而右分支的权重保持不变。  ```python def make_left_zero(params, tags): # i left out gradients if tags[-1] == &quot;L&quot;: return params * 0  return params # update the params params = apply_updates(make_left_zero, params, tags)  ``` 现在你可以用 zephyr 做的其他事情（我已经尝试过了，代码对我来说很容易，而且我的编码能力不是很好）  多层网络并使用网络深度（通过标签）来计算参数的更新 将一些权重标记为&quot;fast&gt; 或&quot;slow&quot; 并在更新时使用这些标签 创建一个 MLP，其神经元为 Wx+b。请注意，神经元是一个数组 -&gt; 标量的函数。因此，我可以用另一个输出为标量（形状为 (1,) 的数组）的 MLP 替换该 MLP 中的每个神经元。或者用任何神经网络（任何函数）替换其中的神经元，即数组 -&gt; 标量。   您能想到哪些具有自定义更新规则的架构/结构易于编写（伪代码/数学或描述）但现在实现起来可能很麻烦？ 请建议一些极端的想法让我尝试。 我认为 zephyr 可以成为使这些变得容易的工具。我希望听到你的极端想法，这样我就可以尝试用 zephyr 编写它们，如果我不能毫不费力地做到这一点，并且如果我认为这是足够通用的东西，我会改进 zephyr 以更轻松地处理它。 PS：自述文件尚未包含这些内容，因为它开始是一个（普通）NN 库。 如果您想查看，repo 的链接将在评论中。    提交人    /u/Pristine-Staff-5250   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gmm7mi/d_what_are_crazy_structures_or_update_rule_that/</guid>
      <pubDate>Fri, 08 Nov 2024 16:14:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Nov 2024 16:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>