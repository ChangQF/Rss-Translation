<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sat, 27 Apr 2024 15:12:43 GMT</lastBuildDate>
    <item>
      <title>[D] 但经过训练的卷积神经网络究竟学到了什么？可视化！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cefhwf/d_but_what_does_a_trained_convolution_neural/</link>
      <description><![CDATA[   分享我的 YT 频道中的视频，解释卷积并可视化内核的学习方式……享受吧！    由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cefhwf/d_but_what_does_a_trained_convolution_neural/</guid>
      <pubDate>Sat, 27 Apr 2024 14:14:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 小型 GPT-2 大小的 LLM 的分类微调实验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cedfub/p_classification_finetuning_experiments_on_small/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cedfub/p_classification_finetuning_experiments_on_small/</guid>
      <pubDate>Sat, 27 Apr 2024 12:31:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 环境数据驱动模型中的迁移学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ced51n/r_transfer_learning_in_environmental_datadriven/</link>
      <description><![CDATA[全新论文发表在Environmental Modeling &amp;软件。我们研究了在数据丰富的站点中训练模型并重用它的可能性，而无需在新的（数据稀缺）站点中进行重新训练或调整。引入了可转移性矩阵和可转移性指标的概念。在这里查看更多信息：https://www.researchgate.net/publication/380113869_Transfer_learning_in_environmental_data-driven_models_A_study_of_o高山地区的区域预测    由   提交/u/_Mat_San_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ced51n/r_transfer_learning_in_environmental_datadriven/</guid>
      <pubDate>Sat, 27 Apr 2024 12:15:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于 Llama-3 的 OpenBioLLM-70B 和 8B：在医疗领域优于 GPT-4、Gemini、Meditron-70B、Med-PaLM-1 和 Med-PaLM-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cecpvk/d_llama3_based_openbiollm70b_8b_outperforms_gpt4/</link>
      <description><![CDATA[      开源再次来袭，我们很高兴地宣布 OpenBioLLM-Llama3-70B 和 OpenBioLLM-Llama3-70B 的发布。 8B.这些模型在生物医学领域超越了 Openai 的 GPT-4、Google 的 Gemini、Meditron-70B、Google 的 Med-PaLM-1 和 Med-PaLM-2 等行业巨头，树立了新的状态。对于同尺寸的模型来说是最先进的。 迄今为止最有能力的公开医学领域法学硕士！ 🩺💊🧬 https://预览。 redd.it/w41pv7mwf0xc1.png?width=5760&amp;format=png&amp;auto=webp&amp;s=f3143919ef8472961f329bb8eb98937d8f8e41e0 结果可在 Open Medical-L 上查看LM排行榜：https://huggingface.co/spaces/openlifescienceai/open_medical_llm_leaderboard 超过约 4 个月，我们精心策划了多样化的定制数据集，与医学专家合作以确保最高质量。该数据集涵盖 3000 个医疗保健主题和 10 多个医学主题。 📚 OpenBioLLM-70B 的卓越性能在 9 个不同的生物医学数据集上显而易见，尽管与 GPT-4 和 GPT-4 相比其参数数量较少，但其平均得分达到了令人印象深刻的 86.06%。医学-PaLM。 📈 https://预览。 redd.it/5ff2k9szf0xc1.png?width=5040&amp;format=png&amp;auto=webp&amp;s=15dc4aa948f2608717f68ddf2cb27a6a2de03496 您今天可以直接从 Huggingface 下载模型。  70B : https://huggingface.co/aaditya/OpenBioLLM-Llama3-70B 8B：https://huggingface.co/aaditya/OpenBioLLM-Llama3-8B  此版本只是一个开始！在接下来的几个月中，我们将推出  扩大医疗领域覆盖范围， 更长的上下文窗口， 更好的基准，以及 多模式功能。  更多详细信息可在此处找到：https://twitter。 com/aadityaura/status/1783662626901528803 在接下来的几个月中，Multimodal 将可用于各种医疗和法律基准。 我希望它对您的研究有用 🔬 大家周末愉快！ 😊   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cecpvk/d_llama3_based_openbiollm70b_8b_outperforms_gpt4/</guid>
      <pubDate>Sat, 27 Apr 2024 11:51:42 GMT</pubDate>
    </item>
    <item>
      <title>我如何说服我的上级进行数据预处理？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ceckws/how_do_i_convince_my_superior_to_do_data/</link>
      <description><![CDATA[我如何说服我的上级进行数据预处理？ 您好，我在目前的公司担任 AI 工程师一年（获得计算机科学硕士学位，专攻数据科学）。我们想用特定语言构建专门用于闲聊（主要是对话聊天）的聊天机器人。 问题是我不同意我上级做事的方法。它几乎总是进行即时工程。我的意思是我们有大量的数据（我想说无数的实时对话聊天会话，其中包含兴趣、外表等信息……，这是所有数据科学家的梦想，可以建立一个不错的模型）。我不同意他的方法的原因是，使用即时工程我们无法始终获得良好的结果。此外，对于特定领域（例如色情聊天），由于模型的审查制度，您无法进行即时工程。或者当模型未针对特定领域的标记/单词进行训练时，会出现幻觉和其他问题。归根结底，这都是关于统计数据的，不是吗？模型从所使用的数据中学习。如果在推理过程中有一个标记，而该标记未在训练数据中涵盖，那么它将以概率进行猜测，以预测最可能的下一个标记。 我不明白为什么我们不利用数据来清理它，为我们的目的/领域创建一个超级好的数据集并微调 LLM。我问过他很多次，为什么我们不这样做，我的上司回答说：“我们过去做过，成本太高，结果不好”。所以我问他，是谁做的？他告诉我，我的同事做的（医学教育背景，业余时间对人工智能感兴趣，但他对数据处理或数据科学基础知识一无所知）。  所以他们最后一次尝试是在 3 年前（他们使用 deepspeed 而不是 Lora 方法，所以我的上司告诉我成本相当高但结果并不好（他们在云端微调了 200 小时），所以那是一次全参数微调） 说实话我不怪我的同事。他用他的知识尽了最大努力。但我确实责怪我愚蠢的上司，因为我们没有成功开发出一个符合我们目的的像样的模型。 所以在我开始为公司工作半年后，我终于说服了我的上司（因为我在空闲时间做了一次微调只是为了好玩并向他们展示了我的结果）。所以他同意，我们可以用 lora 进行微调但是......但是......没有数据处理，只接受原始数据！！ 说真的，那家伙完全迷茫了，顺便说一句，他是我们的产品经理，对数据科学一无所知。他又犯了同样的错误，没有进行数据处理，因为“我们没有这方面的资源”，我甚至无法说服他。 所以最后，聊天机器人比直接进行即时工程要好一点，但对我来说它仍然很糟糕。我只想要一个真正的标准工作流程，包括数据预处理、训练、评估。就这样。最重要的是：数据预处理 所以你们觉得呢？我是猴子吗？我应该尽快离开公司吗？我至少需要在那里呆一年。    提交人    /u/bobotomoon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ceckws/how_do_i_convince_my_superior_to_do_data/</guid>
      <pubDate>Sat, 27 Apr 2024 11:43:37 GMT</pubDate>
    </item>
    <item>
      <title>[研究]机器学习与推理的协同作用（2024）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ceamub/research_synergies_between_machine_learning_and/</link>
      <description><![CDATA[ 由   提交 /u/blackgreenolive   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ceamub/research_synergies_between_machine_learning_and/</guid>
      <pubDate>Sat, 27 Apr 2024 09:39:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 标记化的数学方面</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cea5qn/d_mathematical_aspects_of_tokenization/</link>
      <description><![CDATA[我最近制作了一个视频，介绍了我们最近在标记化的数学方面的工作，特别是： - 将标记化形式化为压缩 - 字节对编码的界限最优性 - 标记化熵和性能之间的联系 我将非常感谢任何反馈，因为我仍在学习如何制作教育视频。谢谢！ https://youtu.be/yeEZpf4BlDA   由   提交/u/zouharvi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cea5qn/d_mathematical_aspects_of_tokenization/</guid>
      <pubDate>Sat, 27 Apr 2024 09:06:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型模型的参数高效微调：综合调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ce8wow/r_parameterefficient_finetuning_for_large_models/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2403.14608 摘要：  大型模型代表了多个应用领域的突破性进步，实现了显着的各项任务取得的成绩。然而，其前所未有的规模伴随着巨大的计算成本。这些模型通常由数十亿个参数组成，需要大量的计算资源来执行。特别是，在针对特定下游任务进行定制时，巨大的规模和计算需求带来了相当大的挑战，特别是在受计算能力限制的硬件平台上。 参数高效微调 (PEFT ）通过在各种下游任务中有效地调整大型模型来提供实用的解决方案。具体来说，PEFT 是指调整预训练大型模型的参数以使其适应特定任务，同时最大限度地减少引入的附加参数或所需的计算资源的数量的过程。在处理具有高参数数的大型语言模型时，这种方法尤其重要，因为从头开始微调这些模型可能会耗费大量计算资源且占用大量资源，从而给支持系统平台设计带来相当大的挑战。 ，我们对各种 PEFT 算法进行了全面的研究，检查了它们的性能和计算开销。此外，我们概述了使用不同 PEFT 算法开发的应用程序，并讨论了用于降低 PEFT 计算成本的常用技术。除了算法角度之外，我们还概述了各种现实世界的系统设计，以研究与不同 PEFT 算法相关的实施成本。这项调查对于旨在了解 PEFT 算法及其系统实现的研究人员来说是不可或缺的资源，提供了对最新进展和实际应用的详细见解。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ce8wow/r_parameterefficient_finetuning_for_large_models/</guid>
      <pubDate>Sat, 27 Apr 2024 07:42:15 GMT</pubDate>
    </item>
    <item>
      <title>[D]DDPG可以解决高维环境吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ce8t9z/dcan_ddpg_solve_high_dimensional_environments/</link>
      <description><![CDATA[ 由   提交/u/Interesting-Weeb-699   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ce8t9z/dcan_ddpg_solve_high_dimensional_environments/</guid>
      <pubDate>Sat, 27 Apr 2024 07:35:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 推荐的机器学习会议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ce84nb/d_recommended_ml_conferences/</link>
      <description><![CDATA[您好r/MachineLearning！您会推荐哪些 ML 相关会议？   由   提交 /u/TechTalksWeekly   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ce84nb/d_recommended_ml_conferences/</guid>
      <pubDate>Sat, 27 Apr 2024 06:51:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何判断评估是FID-10k还是FID-50k？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ce659j/d_how_to_find_out_if_evaluation_is_fid10k_or/</link>
      <description><![CDATA[大家好， 我正在使用 以下存储库代码用于计算我的扩散模型的FID值。我正在使用此参考数据集 - ImageNet 256x256 执行评估：参考批次。但我不确定我是使用 evaluator.py 计算 FID-10k 还是 FID-50k  脚本。   本例中使用的评估是什么以及如何从代码中推断出它？  如果是计算 FID-50k，那么我应该如何计算 FID-10k（反之亦然）？  我应该从模型中生成多少样本（较低的估计）才能获得公平的评估？生成的样本数量是否会影响我进行 FID-50k 还是 FID-10k？  请告诉我您知道的任何问题的答案..   由   提交 /u/InstinctsInFlow   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ce659j/d_how_to_find_out_if_evaluation_is_fid10k_or/</guid>
      <pubDate>Sat, 27 Apr 2024 04:50:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 谈论模型的概率有意义吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ce1zfs/d_does_it_make_sense_to_talk_about_the/</link>
      <description><![CDATA[https://lunaverus.com/programLikelihoods  有一种巧妙的方法将无监督学习构建为似然最大化，但不是以通常的方式，即使用模型计算数据的似然性并忽略模型本身的似然性。相反，这是模型和数据的组合可能性...  谈论 ML 模型的概率有意义吗？   由   提交 /u/bouncyprojector   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ce1zfs/d_does_it_make_sense_to_talk_about_the/</guid>
      <pubDate>Sat, 27 Apr 2024 01:06:38 GMT</pubDate>
    </item>
    <item>
      <title>[R]大型语言模型可能无法对行为概率分布进行采样</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdpdci/rlarge_language_models_may_not_be_able_to_sample/</link>
      <description><![CDATA[      通过我们的实验，我们发现LLM智能体具有一定的理解概率分布的能力，LLM智能体的采样能力缺乏对概率分布的认识，仅通过LLM很难给出符合某种概率分布的行为序列。  我们期待您对此主题的想法、批评和讨论。全文及引用：您可以访问全文https://arxiv.org/abs/2404.09043。如果我们的工作对您的研究有所贡献，请引用我们的工作。 https://preview.redd.it/ai7uks7nluwc1.png?width=935&amp;format=png&amp;auto=webp&amp;s=891dd57ef50d1ee99b1a8b2372b9a460397754 d6   由   提交/u/GYX-001   /u/GYX-001 reddit.com/r/MachineLearning/comments/1cdpdci/rlarge_language_models_may_not_be_able_to_sample/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdpdci/rlarge_language_models_may_not_be_able_to_sample/</guid>
      <pubDate>Fri, 26 Apr 2024 16:11:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士：为什么情境学习有效？从技术角度来看到底发生了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cdih0a/d_llms_why_does_incontext_learning_work_what/</link>
      <description><![CDATA[无论我到哪里寻找这个问题的答案，答案都不过是将模型拟人化而已。它们总是做出如下声明：  如果没有示例，模型就必须推断上下文并依靠其知识来推断预期的内容。这可能会导致误解。 一次性提示通过提供特定示例来减少这种认知负荷，有助于巩固模型的解释并专注于具有更明确期望的更窄任务。 示例可作为模型的参考或提示，帮助其了解您正在寻找的响应类型并在训练期间触发对类似实例的记忆。 提供示例可让模型识别要复制的模式或结构。它为模型建立了一个与之对齐的线索，从而减少了零样本场景中固有的猜测。  顺便说一句，这些都是真实的摘录。 但这些模型并不“理解”任何东西。它们不会“推断”、“解释”、“聚焦”、“记住训练”、“做出猜测”，也不会有字面上的“认知负荷”。它们只是统计标记生成器。因此，在寻求具体理解情境学习提高准确性的确切机制时，像这样的流行科学解释是毫无意义的。 有人可以从实际的模型架构/机制的角度解释事物，以及如何提供额外的上下文来获得更好的输出吗？我可以“说到做到”，所以请不要遗漏技术细节。 我可以做出有根据的猜测 - 在输入中包含使用近似于您想要的输出类型的标记的示例，会导致注意机制和最终的密集层对在某种程度上与这些示例相似的标记赋予更高的权重，从而增加这些所需标记在每次前向传递结束时被采样的几率；从根本上说，我猜这是一个相似性/距离的事情，明确举例说明我想要的输出会增加输出与它相似的几率 - 但我更愿意从对这些模型和机制有深入了解的人那里听到它。    提交人    /u/synthphreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cdih0a/d_llms_why_does_incontext_learning_work_what/</guid>
      <pubDate>Fri, 26 Apr 2024 11:01:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>