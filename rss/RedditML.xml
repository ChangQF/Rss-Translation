<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 06 Nov 2024 09:18:52 GMT</lastBuildDate>
    <item>
      <title>[D] Photoshop Neural Filter 的替代品：智能肖像</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkt9xu/d_alternative_to_photoshop_neural_filter_smart/</link>
      <description><![CDATA[有没有类似的东西？ 它基本上允许您调整滑块，例如：头部角度，微笑，年龄，头发等...    提交人    /u/frosty3907   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkt9xu/d_alternative_to_photoshop_neural_filter_smart/</guid>
      <pubDate>Wed, 06 Nov 2024 07:48:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为一名研究人员，您如何做好进入行业的准备？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gksoi7/d_as_a_researcher_how_do_you_become_industryready/</link>
      <description><![CDATA[作为一名博士生，我的大部分时间都花在指导学生、项目管理和编写用于原型设计的“快速而粗糙”的代码上。我打算在获得博士学位后进入行业，但我觉得我错过了关键的软件工程技能和良好的编码实践。其他人有这种感觉吗？在攻读博士学位期间，你如何提升自己的技能以做好进入行业的准备？    提交人    /u/fullgoopy_alchemist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gksoi7/d_as_a_researcher_how_do_you_become_industryready/</guid>
      <pubDate>Wed, 06 Nov 2024 07:07:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于构建 LLM 应用程序的开源声明式框架 - 寻找贡献者</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkpazh/p_opensource_declarative_framework_to_build_llm/</link>
      <description><![CDATA[我一直在构建基于 LLM 的应用程序，并且对所有主要框架（langchain、autogen、crewAI 等）感到非常沮丧。它们似乎还引入了一堆不必要的抽象。即使是非常简单的东西，也很难理解幕后发生了什么。 所以我刚刚发布了这个开源框架 GenSphere。 这个想法是拥有类似 Docker for LLMs 的东西。您可以使用定义执行图的 YAML 文件构建应用程序。节点可以是 LLM API 调用、常规函数执行或其他图本身。因为您可以轻松嵌套图，所以构建复杂的应用程序不是问题，但同时您不会失去控制。 您基本上用 YAML 编写代码，说明需要完成的任务是什么以及它们如何连接。除此之外，您只需编写在执行期间调用的单个 Python 函数。无需学习新的类和抽象。 它都是开源的。现在我正在寻找贡献者来调整框架以适应循环和条件节点 - 这将允许全面的代理系统构建！如果您想做出贡献，请联系我们，有很多事情要做！ PS：您可以在此处阅读详细文档，并快速浏览这个Google Colab 教程。    提交人    /u/Jazzlike_Tooth929   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkpazh/p_opensource_declarative_framework_to_build_llm/</guid>
      <pubDate>Wed, 06 Nov 2024 03:34:51 GMT</pubDate>
    </item>
    <item>
      <title>论一项低预算的成功研究[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkn6tw/on_a_successful_research_with_low_budget_d/</link>
      <description><![CDATA[嗨，我有一个研究想法，并将其应用于 nanogpt repo 进行 lm 训练，经过验证的 transformer 在验证损失上概括得更好，但训练损失更差，更容易过度拟合，因为像训练损失稍差验证损失稍好，我只应用于完整的 shakespeare_char 和 openwebtext 上的子集，因为 runpod 上的 10 美元只允许我这样做，我仍然要发布一篇论文，因为我取得了不错的成绩并做了一些数学工作，我应该这样做吗？    提交人    /u/Mean-Force267   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkn6tw/on_a_successful_research_with_low_budget_d/</guid>
      <pubDate>Wed, 06 Nov 2024 01:37:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] Autograd 与 JAX？两者都是针对基于梯度的方法的 Google 产品。主要区别是什么？（GPU/TPU？）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkms4w/d_autograd_vs_jax_both_are_google_products_aimed/</link>
      <description><![CDATA[最近看到谷歌人开发的 Autograd（库），它对 numpy 进行了薄包装以提供反向传播。JAX 也这样做，但基本上重写了 numpy。有什么区别？是 JAX 的 gpu tpu 支持吗？autograd 适用于较小的模型吗？    提交人    /u/MysticalDragoneer   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkms4w/d_autograd_vs_jax_both_are_google_products_aimed/</guid>
      <pubDate>Wed, 06 Nov 2024 01:15:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 专用 AI 数据中心在增强模型训练和微调方面的作用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkmen4/d_the_role_of_dedicated_ai_data_centers_in/</link>
      <description><![CDATA[刚刚读到 Kinetic Seas 推出了一个新的 AI 专用数据中心——听起来他们的目标是让模型训练和微调变得不那么令人头疼。他们的设置包括专用的 GPU 和 CPU，据说是为了满足大型复杂模型的需求而构建的。如果传统数据中心感觉像是在上坡，那么这些 AI 专用中心可能就是在下坡？ 随着机器学习模型变得越来越耗费资源，我想知道像这样优化的基础设施是否会改变游戏规则。想想看：更快地训练模型，并且限制更少，可以真正提高研究人员和数据科学家的生产力。Kinetic Seas 似乎认为值得为 AI 构建基础设施，这感觉是一个非常有趣的赌注。 这里有人使用过这样的 AI 专用设置吗？好奇地想知道它是否真的像听起来那么顺利！ https://www.prnewswire.com/news-releases/kinetic-seas-fka-bellatora-announces-completion-of-phase-i-of-its-data-center-for-ai-302168707.html    提交人    /u/booboo1998   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkmen4/d_the_role_of_dedicated_ai_data_centers_in/</guid>
      <pubDate>Wed, 06 Nov 2024 00:55:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] LoRA 合并（和非线性模式连接）是更好的变压器超网络的关键吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkhy4n/d_is_lora_merging_and_non_linear_mode/</link>
      <description><![CDATA[大家好！我在想，如果我们可以根据手头的任务类型动态合并 LLM 微调 LoRA，我们就可以修复灾难性遗忘，甚至可以让 Transformer 更好地泛化。问题是，由于注意力层在权重上非常非线性，Transformer 不会表现出较差的 LMC（线性模式连接）。 您是否知道精确 LoRA 合并的计算复杂性？我看过很多关于 LoRA 合并的论文，但它们似乎质量很差，而且只是经验性的，几乎没有数学基础。 所以如果你们想到了，我很高兴听到它！    提交人    /u/Due-Pangolin325   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkhy4n/d_is_lora_merging_and_non_linear_mode/</guid>
      <pubDate>Tue, 05 Nov 2024 21:31:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 可以收敛到什么交叉熵损失值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gk92rs/d_to_what_crossentropy_loss_value_can_llms/</link>
      <description><![CDATA[LLM 通常在旨在衡量广泛能力的基准上进行评估。但是，大多数基础模型的发布者都不会发布模型在训练结束时实现的实际交叉熵损失值。我找不到任何关于此的资料，但我想知道 LLM 在人类语言上可以实现的损失值。有谁对此有更多了解吗？可能会有下限吗？    提交人    /u/cbl007   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gk92rs/d_to_what_crossentropy_loss_value_can_llms/</guid>
      <pubDate>Tue, 05 Nov 2024 15:19:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 切勿从头开始训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gk7dny/r_never_train_from_scratch/</link>
      <description><![CDATA[https://arxiv.org/pdf/2310.02980  作者表明，当对 transformer 进行预训练时，它们可以在 Long range Arena 基准上将性能与 S4 相匹配。    提交人    /u/Whatever_635   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gk7dny/r_never_train_from_scratch/</guid>
      <pubDate>Tue, 05 Nov 2024 14:02:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 文本分类：N 次提示分类 VS 在嵌入器上训练线性分类器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gk4wx1/d_text_classification_nshot_prompt_classification/</link>
      <description><![CDATA[我需要在工作中制作一个文本分类器。我对 5 个类别中的每个类别都有 200 个示例。每个示例都是一封电子邮件。两种方法：  使用 n-shot 即时分类对电子邮件进行分类，可能使用 LoRA 微调。 使用预先训练的文本嵌入器（例如句子转换器或 OpenAI text-embeddings-3）和分类头。在文本嵌入上训练分类器。  哪种方法最好？    提交人    /u/Aromatic-Oil-4586   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gk4wx1/d_text_classification_nshot_prompt_classification/</guid>
      <pubDate>Tue, 05 Nov 2024 11:53:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 二流论文在申请行业研究工作时有价值吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gjz3in/d_do_second_tier_papers_have_any_value_when_apply/</link>
      <description><![CDATA[我想我之前遇到过一些行业工作，要求申请人拥有顶级论文（NIPS/ICML/ICLR/CVPR/ICCV/ECCV），所以我的问题是，来自不太有声望（AAAI/IJCAI/WACV/BMVC.... 或期刊）会议的论文在申请这些工作时有任何价值吗？此外，h 指数或引用等指标重要吗？    提交人    /u/Competitive_Newt_100   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gjz3in/d_do_second_tier_papers_have_any_value_when_apply/</guid>
      <pubDate>Tue, 05 Nov 2024 04:58:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于准备 Google ML 面试的建议 – 应关注的关键领域？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gjxyg0/d_advice_on_preparing_for_google_ml_interview_key/</link>
      <description><![CDATA[我正在准备参加 Google 的机器学习面试，招聘人员分享了他们将重点关注的主要领域： - 理论 ML 概念和实际应用 - 包括问题定义、模型选择、模型调整和评估。 - 行业规模 ML - 涵盖性能和成本优化、数据处理以及面向生产的实验和调试。 如果有人对这些领域的期望或重点提示有任何见解，我将不胜感激！我特别难以理解“行业规模 ML”问题实际上可能是什么。 提前感谢任何建议或资源！ 编辑：背景：我已经完成了两次 LC 风格的面试。我想说第一次面试很容易，第二次面试肯定很难。我认为我在两方面都表现不错，但只有第二位面试官告诉我我的表现如何（显然我表现不错）。我还参加了 Googlyness 的面试，我认为面试也很顺利。我们进行了很好的交谈。    提交人    /u/atomicalexx   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gjxyg0/d_advice_on_preparing_for_google_ml_interview_key/</guid>
      <pubDate>Tue, 05 Nov 2024 03:53:08 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型（LLM）实际上可以很好地解决哪些问题？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gjoxpi/what_problems_do_large_language_models_llms/</link>
      <description><![CDATA[虽然人们对人工智能炒作周期的怀疑越来越多，尤其是围绕聊天机器人和 RAG 系统，但我感兴趣的是确定 LLM 在准确性、成本或效率方面明显优于传统方法的具体问题。我能想到的问题是： - 单词分类 - 非大段文本的情感分析 - 图像识别（在某种程度上） - 写作风格转换（在某种程度上） 还有什么？    提交人    /u/Educational-String94   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gjoxpi/what_problems_do_large_language_models_llms/</guid>
      <pubDate>Mon, 04 Nov 2024 20:52:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Nov 2024 16:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>