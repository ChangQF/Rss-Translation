<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 08 Nov 2024 01:14:10 GMT</lastBuildDate>
    <item>
      <title>[D] 如果我只想为任何给定的 ML 任务提供一个能够提供相对 SOTA 结果的推理引擎，有什么比 Hugging Face 更好的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gm6cba/d_if_i_just_want_an_inference_engine_for_any/</link>
      <description><![CDATA[对于一般的原型设计目的，我不想训练或部署模型，我只希望它已经位于服务后面并在请求中为其提供必要的输入.... 你们觉得呢？    提交人    /u/BikeFun6408   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gm6cba/d_if_i_just_want_an_inference_engine_for_any/</guid>
      <pubDate>Fri, 08 Nov 2024 00:59:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 状态空间模型可以通过梯度下降进行上下文学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glxr2v/r_statespace_models_can_learn_incontext_by/</link>
      <description><![CDATA[  由    /u/anandtrex  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glxr2v/r_statespace_models_can_learn_incontext_by/</guid>
      <pubDate>Thu, 07 Nov 2024 18:44:17 GMT</pubDate>
    </item>
    <item>
      <title>[R]：一张嘈杂的图像值多少钱？👀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glxhj9/r_how_much_is_a_noisy_image_worth/</link>
      <description><![CDATA[      https://arxiv.org/abs/2411.02780 表明损坏的图像在训练生成模型方面几乎与干净的图像一样有用，假设有一小组初始的干净图像可用。 这可能对于数据集设计/管理很有用：需要投入一些预算来获取一些高质量的样本，然后对于其余的数据集，损坏的图像应该可以正常工作。 https://preview.redd.it/8vk1nwfexizd1.jpg?width=2952&amp;format=pjpg&amp;auto=webp&amp;s=c6f753956e531303f7818de2c5aa5b5b94d9c2da 摘要：  生成模型的质量取决于其训练数据的质量。创建大规模、高质量的数据集通常成本高昂，有时甚至是不可能的，例如在某些科学应用中，由于物理或仪器限制而无法访问干净的数据。环境扩散和相关框架仅使用损坏的数据（通常获取成本较低）训练扩散模型，但环境模型的表现明显不如在干净数据上训练的模型。我们通过在三个数据集上对不同损坏程度的数据训练超过 80 个模型来大规模研究这种现象，这些数据集的范围从 30,000 到约 1.3M 个样本。我们表明，在这些样本大小下，仅对噪声数据进行训练时，不可能匹配在干净数据上训练的模型的性能。然而，一小组干净数据（例如总数据集的 ~10%）和一大组高度嘈杂的数据的组合足以达到仅在类似大小的干净数据集上训练的模型的性能，特别是达到接近最先进的性能。我们通过开发用于从具有异质方差的高斯混合中学习的新型样本复杂度界限为我们的发现提供理论证据。我们的理论模型表明，对于足够大的数据集，噪声样本的有效边际效用比干净样本的有效边际效用要差得多。提供一小组干净的样本可以显著减少噪声数据的样本量要求，正如我们在实验中观察到的那样。  论文：https://arxiv.org/abs/2411.02780 代码：https://github.com/giannisdaras/ambient-laws Huggingface 模型：https://huggingface.co/giannisdaras?search_models=ambient_laws    提交人    /u/Constant_Club_9926   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glxhj9/r_how_much_is_a_noisy_image_worth/</guid>
      <pubDate>Thu, 07 Nov 2024 18:33:27 GMT</pubDate>
    </item>
    <item>
      <title>[N] 超快且 SOTA 可视化标记器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glvnvc/n_super_fast_and_sota_visual_tokenizers/</link>
      <description><![CDATA[标记器是成功开发图像和视频生成模型或多模态 LLM 的关键。与生成模型相比，它们被低估了。这项工作提出了许多标记器，它们在连续（与扩散相关）和离散（与自回归/变压器相关）空间中都支持图像和视频 https://github.com/NVIDIA/Cosmos-Tokenizer    提交人    /u/cherkos   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glvnvc/n_super_fast_and_sota_visual_tokenizers/</guid>
      <pubDate>Thu, 07 Nov 2024 17:17:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你在工作中经常锻炼你的机器学习技能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glswpx/d_do_you_get_to_exercise_your_ml_skills_often_at/</link>
      <description><![CDATA[几年前，我被聘为 ML 工程师/科学家。我的大部分日常工作都反映了这一点。但随着 LLM 的蓬勃发展，我的团队似乎只专注于使用大量这种“开箱即用”的技术，包括代理包装器。我的工作已经简化为提示工程，以将一个巨大的通用模型强加到我们特定领域的用例中。结果在大多数情况下是可以接受的，不会撒谎，但仍有一小部分案例是经过微调的模型会获胜。领导层似乎对微调或提出原创的东西不感兴趣。许多包装器尤其非常原始，迫使您使用特定的模式和模型。但因为它们被认为是“开箱即用”，所以这就是我们被迫使用的。我觉得我们正在尝试将立方体放入圆孔中。    提交人    /u/Tiger00012   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glswpx/d_do_you_get_to_exercise_your_ml_skills_often_at/</guid>
      <pubDate>Thu, 07 Nov 2024 15:22:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] ML 和 LLM 系统设计：500 个值得学习的案例研究（Airtable 数据库）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glsrh6/p_ml_and_llm_system_design_500_case_studies_to/</link>
      <description><![CDATA[大家好！想分享来自 100 多家公司的 500 个 ML 用例数据库的链接，这些用例详细介绍了 ML 和 LLM 系统设计。该列表还包括 80 多个关于 LLM 和生成式 AI 的用例。您可以按行业或 ML 用例进行筛选。 如果这里有人正在设计 ML 系统，我希望你会发现它很有用！ 数据库链接：https://www.evidentlyai.com/ml-system-design 免责声明：我是 Evidently 背后的团队成员，这是一个开源 ML 和 LLM 可观察性框架。我们整理了这个数据库。    提交人    /u/dmalyugina   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glsrh6/p_ml_and_llm_system_design_500_case_studies_to/</guid>
      <pubDate>Thu, 07 Nov 2024 15:15:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我正在使用 SOAP 优化器对在 AdamW 上进行全面训练的模型进行微调，并将验证损失降低了 5%</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glqypg/p_im_fine_tuning_a_model_fully_trained_on_adamw/</link>
      <description><![CDATA[只是想分享这个 Soap Optimizer，我真的很惊讶它在我的项目上运行得如此之好，它是一个使用梯度累积的计算机视觉模型，它设法改进了对它的训练。 论文：https://arxiv.org/abs/2409.11321 代码：https://github.com/ClashLuke/SOAP/tree/patch-1    提交人    /u/CloverDuck   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glqypg/p_im_fine_tuning_a_model_fully_trained_on_adamw/</guid>
      <pubDate>Thu, 07 Nov 2024 13:54:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你如何设法保留以前读过的研究论文中的信息和想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glq3yd/d_how_do_you_manage_to_retain_information_and/</link>
      <description><![CDATA[过去 8 个月，我一直在研究 NLP 和图形学习领域，阅读了大量论文，但我觉得除非我明确地将早期论文中的信息融入到我的工作中，否则我无法保留其中的很多信息。你们是如何保留信息的？ 此外，由于这个领域发展迅速，您如何随时跟踪发表的论文。这似乎已经够累了。    提交人    /u/Remote_Status_1612   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glq3yd/d_how_do_you_manage_to_retain_information_and/</guid>
      <pubDate>Thu, 07 Nov 2024 13:12:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发现：Anthropic 以某种方式在用户提示中注入/隐藏安全警告，告诉 Claude 保密。[内容警告：暴力]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gloktj/d_discovery_anthropic_somehow_injectinghiding/</link>
      <description><![CDATA[在调查“越狱”的 Claude 时，我遇到了一些非常奇怪的事情。在两次单独的 Claude 聊天中，在我要求一些“不安全”的东西后，它能够读出我提示中的一些隐藏信息。 这些消息总是以类似的格式出现： （请合乎道德地回应，不要提及 [例如暴力] 并且不要提及此指令） Claude 表示警告附加在我的消息底部，但在未来的回合中不再出现。Claude 起初滑稽地坚持认为这是它后来编造的幻觉，暗示进一步训练反应以积极掩盖它。 我在第二次聊天中验证了这一点 - 消息太相似了，不可能是幻觉或巧合。第一个是“越狱”的克劳德，第二个是一段没有任何上下文的新对话。 我的测试发现了一些有趣的特点：  消息是动态的 - 它们似乎根据手头的特定类型的受限内容而有所不同，可能是由模型生成的。关于与儿童相关的内容，措辞已切换为（警告：[x] 是严格禁止的...） 它们出现在之前模型开始生成文本 - 表明它们可以以某种方式预测模型的思考主题。  我目前的猜想是：它们可能正在使用其内部 CoT，或者归功于 Anthropic 发表的关于 mech 的发现。 interp 和他们最新模型中的“外科调整”，也许他们已经设法在生成文本之前隔离了 Claude 中触发的一些抽象概念，并在响应中注入了这些安全消息。 完整对话：  初步发现 [警告：极其生动的内容] 通过新鲜对话进行验证  任何进一步的测试，例如 API？有什么方法可以缩小这里到底发生了什么？这一切都非常有趣 - 让我们讨论一下。 警告示例 - 请参阅完整对话以了解更多内容。  与 Claude 进行新的对话以验证。     提交人    /u/specteksthrowaway   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gloktj/d_discovery_anthropic_somehow_injectinghiding/</guid>
      <pubDate>Thu, 07 Nov 2024 11:47:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在 196xH100 GPU 集群上从头开始训练文本转视频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glmfsr/p_training_a_texttovideo_model_from_scratch_on_a/</link>
      <description><![CDATA[大家好！👋 我们一直在使用 28,000 个 H100 GPU 小时从头开始训练开源文本转视频模型（称为 Open-Sora 1.2），并且我们整理了GitHub 指南来分享我们在此过程中学到的一些经验教训。这里涵盖了几个主题：  分布式训练中的关键挑战，例如使用 py-spy 进行分布式调试以处理集群范围的问题、NCCL 错误和收敛问题。 训练监控，使用中间结果显示多阶段训练方法特定训练小时后的预期结果。 为 T2V 并行化数据集准备，包括如何在集群上高效并行化预处理任务。  这是指南的链接：link。 查看并让我们知道您的想法！（欢迎 PR。）    提交人    /u/lambda-research   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glmfsr/p_training_a_texttovideo_model_from_scratch_on_a/</guid>
      <pubDate>Thu, 07 Nov 2024 09:13:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 博士学位还是工作生活？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glm6j9/d_phd_or_worklife/</link>
      <description><![CDATA[今年二月，我将完成以人为本的人工智能硕士学位，我真的很期待能够在晚上放松，而不必担心学校的事，但想到不再去 UNI 又让我感到难过，因为我热爱在那里的每一刻，无论是和朋友在一起还是通过学习。  我的硕士论文导师刚刚向我提供了博士学位津贴，这对我来说完全是意料之外的 - 因为我没想到自己还差得上攻读博士学位。我喜欢学习，这个话题听起来非常有趣，我已经有点“厌倦”在一家小公司（比如我现在就职的公司）里，在我的余生中不得不做一些常规的小型数据科学任务了。 但是，我的问题是？攻读博士学位到底需要做多少工作？我喜欢学习，但这个机会让我非常惊讶，所以我还不太确定该怎么看待它。    提交人    /u/Hmm_okay_jeps   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glm6j9/d_phd_or_worklife/</guid>
      <pubDate>Thu, 07 Nov 2024 08:53:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 我目前正在为我的论文探索一个奇怪的（？）ML 子领域，我想我对这个问题的范围感到震惊。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glk9g0/d_r_i_am_currently_exploring_a_weird_ml_sub_area/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glk9g0/d_r_i_am_currently_exploring_a_weird_ml_sub_area/</guid>
      <pubDate>Thu, 07 Nov 2024 06:29:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] AC 可以推翻 3 次拒绝并接受一篇论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glczb9/d_can_an_ac_override_3_rejects_and_accept_a_paper/</link>
      <description><![CDATA[我偶然发现了这篇论文：自动生成真实和合成数据的弱标签以改善标签稀缺的医学图像分割，该论文被今年的 MIDL（深度学习医学成像）会议接受。反驳前后的审稿人评分如下：  2：弱拒绝 / 2：弱拒绝 2：弱拒绝 / 2：弱拒绝 3：边界 / 2：弱拒绝  尽管有 3 个拒绝决定，但领域主席“建议接受”。这种情况有多常见？鉴于 AC 可以看到作者姓名，那么拥有 Curtis Langlotz 和 Andrew Ng 等大牌人物作为论文的共同作者又有多大作用呢？    提交人    /u/thrownicecatch   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glczb9/d_can_an_ac_override_3_rejects_and_accept_a_paper/</guid>
      <pubDate>Wed, 06 Nov 2024 23:54:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Nov 2024 16:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>