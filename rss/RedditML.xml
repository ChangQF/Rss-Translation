<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 12 Feb 2025 09:17:21 GMT</lastBuildDate>
    <item>
      <title>[R] 法学硕士可以自学如何更好地预测未来</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inks6r/r_llms_can_teach_themselves_to_better_predict_the/</link>
      <description><![CDATA[  由    /u/jsonathan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inks6r/r_llms_can_teach_themselves_to_better_predict_the/</guid>
      <pubDate>Wed, 12 Feb 2025 06:31:42 GMT</pubDate>
    </item>
    <item>
      <title>机器心理学？[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inh9cy/machine_psychologyr/</link>
      <description><![CDATA[嗨，我想知道你们中是否有人在这个领域工作过，或者对此有更多了解，我对心理学在机器学习中的应用很感兴趣。     提交人    /u/Nervous_Club09   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inh9cy/machine_psychologyr/</guid>
      <pubDate>Wed, 12 Feb 2025 03:05:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025 的提交在哪里？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inegee/d_where_are_iclr_2025_submissions/</link>
      <description><![CDATA[看来 openreview 只显示已撤回的投稿。虽然通常不会提供已接受的论文列表，但据我记得前几年，仍然可以访问投稿和评论： https://openreview.net/group?id=ICLR.cc/2025/Conference#tab-withdrawn-submissions 我是否遗漏了什么？为什么今年会有这种变化？    提交人    /u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inegee/d_where_are_iclr_2025_submissions/</guid>
      <pubDate>Wed, 12 Feb 2025 00:45:51 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 新型聚类指标——Jaccard 集中指数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1indsvi/research_novel_clustering_metric_the/</link>
      <description><![CDATA[我创建了一个新的聚类指标，称为 Jaccard-Concentration Index(JCI)，并将其上传为 Python 库。我最​​初创建它是为了帮助我测试我正在开发的聚类算法，但它似乎本身就很有用，所以我把它变成了一个库。 从技术上讲，它是两个指标合二为一。有一个集中函数，用于测量值列表中的总值在一个或几个索引内的压缩程度，还有 JCI 函数，它是提供直接评估结果的主要函数。 以下是该库的摘要： Jaccard 集中指数 (JCI) 是一个 Python 库，用于使用一种新颖的指标来评估聚类（或更一般地说，分类）的质量，该指标将众所周知的 Jaccard 指数与自定义集中分数相结合。它不仅考虑预测簇和真实簇之间的最佳匹配，还测量每个预测簇的质量在真实簇中的集中程度，从而提供更细致入微的簇纯度视图。 通常，在最少数量的真实簇中分配质量的预测簇得分更高。质量分布不均匀的簇（严重偏向一个或几个真实簇）的得分甚至更高。例如，如果有 4 个真正的聚类，则按 70-30-0-0 分割分布的预测聚类的得分将高于按 65-35-0-0 分割分布的聚类，而且有趣的是，按 70-10-10-10 分割分布的聚类的得分将高于按 70-10-10-10 分割分布的聚类。这种行为源于对与真正的聚类重叠强度的双重强调以及对重叠的关注。与真实聚类具有更高的最大重叠度通常是可取的，但集中剩余的质量也很重要，因为它减少了关于聚类中点属于哪个真实类的不确定性 - 使分类更有用。 本质上，Jaccard-Concentration 指数提供了一种平衡预测的精确度和召回率的平滑方法。 有关所涉及的函数和数学的更多详细信息，请参阅 GitHub 或 PyPI 上的项目描述。 欢迎提出所有想法和评论。    提交人    /u/Significant-Agent854   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1indsvi/research_novel_clustering_metric_the/</guid>
      <pubDate>Wed, 12 Feb 2025 00:15:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 通过预测未来的目标标记，实现标记采样器模型的概念，这些标记与解码器反向因果对齐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inbt45/d_a_concept_for_a_token_sampler_model_through/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inbt45/d_a_concept_for_a_token_sampler_model_through/</guid>
      <pubDate>Tue, 11 Feb 2025 22:45:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] SSM 和线性注意力怎么了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1in9y30/d_what_happened_to_ssms_and_linear_attentions/</link>
      <description><![CDATA[了解该研究领域的人可以总结一下 SSM 和 softmax 注意力替代方案的当前状态吗？它们是否已用于以客户为中心的模型，还是仍在研究中？它们的承诺是否只出现在纸面上的基准测试中？或者硬件加速器是否已经蚀刻了注意力，以便它完全充满活力，而使用 SSM 或线性注意力替代方案只能提供边际收益，这对它们的复杂程度确实有吸引力？    提交人    /u/ApartmentEither4838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1in9y30/d_what_happened_to_ssms_and_linear_attentions/</guid>
      <pubDate>Tue, 11 Feb 2025 21:27:30 GMT</pubDate>
    </item>
    <item>
      <title>可解释的时间序列预测人工智能 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1in57y1/explainable_ai_for_time_series_forecasting/</link>
      <description><![CDATA[是否有任何研究论文的功能实现专注于可解释的 AI 进行时间序列预测？我一直在广泛搜索，但没有一个库表现最佳。此外，请推荐其他方法来解释时间序列模型的结果并向业务利益相关者解释它们。    提交人    /u/Severe_Conclusion796   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1in57y1/explainable_ai_for_time_series_forecasting/</guid>
      <pubDate>Tue, 11 Feb 2025 18:15:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] MaskNet 的持续相关性：利用乘性特征交互进行 CTR 预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1in4qsv/r_the_continued_relevance_of_masknet_leveraging/</link>
      <description><![CDATA[2021 年，在 ChatGPT 引发 AI 热潮之前，新浪微博公司的研究人员在新加坡 ACM 的 DLP-KDD 上介绍了 MaskNet，题为“MaskNet：通过实例引导掩码将特征乘法引入 CTR 排名模型”。这种使用深度神经网络中的实例引导掩码进行点击率 (CTR) 预测的特征乘法方法在当今的工业应用中仍然具有很高的竞争力。 MaskNet 超越了传统的加性特征交互，证明了即使人工智能格局迅速发展，重点领域的突破性创新也能经受住时间的考验。 关键技术亮点：  实例引导掩码：在特征嵌入和前馈层上动态执行元素乘法，提高模型强调信息特征的能力。 MaskBlock：结合层规范化、前馈层和乘法掩码的混合模块，允许加法和乘法交互共存。 性能提升：MaskNet 在真实数据集上的表现优于 DeepFM 和 xDeepFM，AUC 提高了高达 5.23%。 灵活的架构：提供串行（SerMaskNet）和并行（ParaMaskNet）配置适用于各种用例。  MaskNet 表明，将乘法运算合并到深度神经网络中可以显着捕获复杂的特征交互，从而为 CTR 预测提供更有效的方法。如果您在 CTR 或推荐系统中工作，本文将提供宝贵的见解。 阅读全文：https://www.shaped.ai/blog/masknet-ctr-ranking-innovation 期待听到您对这种方法的想法！    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1in4qsv/r_the_continued_relevance_of_masknet_leveraging/</guid>
      <pubDate>Tue, 11 Feb 2025 17:56:59 GMT</pubDate>
    </item>
    <item>
      <title>闭源模型的碳排放推理 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1in2cpg/carbon_emissions_for_closed_source_models_at/</link>
      <description><![CDATA[大家好！我无法从 OpenAI/Anthropic 找到有关 GPT-4o 或 Claude 3.5 Sonnet 等模型的每个推理请求的碳排放量的任何数据。所以我想知道：  是否有任何已知的方法可以估算每个 API 调用的排放量（例如，令牌计数、计算时间、云碳工具）？ 是否有第三方研究或粗略的近似值？ 为什么缺乏透明度？  欢迎猜测、框架或研究链接 :)。谢谢    提交人    /u/PlatypusPrudent3076   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1in2cpg/carbon_emissions_for_closed_source_models_at/</guid>
      <pubDate>Tue, 11 Feb 2025 16:18:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调能赚大钱——怎么做到的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imwnnp/d_finetuning_is_making_big_moneyhow/</link>
      <description><![CDATA[嘿！ 自从我担任计算机视觉研究员以来，我一直在研究 LLM 行业。 与计算机视觉任务不同，似乎许多公司（尤其是初创公司）都依赖于基于 API 的服务，例如 GPT、Claude 和 Gemini，而不是像 Llama 或 Mistral 这样的自托管模型。我还在这个 subreddit 中看到了很多讨论微调的帖子。 这让我很好奇！据报道，Together AI 的 ARR 已达到 1 亿美元以上，令我惊讶的是，微调似乎是其主要的收入驱动因素之一。微调是如何为如此高的收入数字做出贡献的？公司是否在大力投资它以获得更好的性能、数据隐私或成本节省？ 那么，为什么要微调模型而不是使用 API（GPT、Claude 等）？我真的想知道。  很想听听您的想法 - 提前谢谢！    提交人    /u/Vivid-Entertainer752   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imwnnp/d_finetuning_is_making_big_moneyhow/</guid>
      <pubDate>Tue, 11 Feb 2025 11:41:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 循环潜在推理：在不生成标记的情况下扩展语言模型中的测试时间计算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imwkns/r_recurrent_latent_reasoning_scaling_testtime/</link>
      <description><![CDATA[我发现这篇论文的主要贡献是重新思考我们如何通过连续循环处理而不是离散层来扩展推理过程中的计算。作者建议将模型深度视为一个连续参数，可以在推理时动态调整。 主要技术要点： - 引入“循环深度” - 允许信息多次循环通过组件 - 将深度建模为连续参数而不是离散层 - 使用微分方程的原理来创建平滑的信息流 - 根据任务复杂性实现自适应计算 主要结果： - 匹配较大模型的性能，同时减少 30-40% 的计算量 - 与传统架构相比，显示出更稳定的训练动态 - 展示了跨处理步骤的改进的信息保留 - 通过增加推理迭代实现了一致的性能扩展 我认为这种方法可以帮助解决我们扩展语言模型的一些基本效率低下问题。我们可以通过更智能的处理更好地利用现有参数，而不是简单地扩大模型。对深度的连续处理还为在部署期间平衡计算与性能提供了更大的灵活性。 我认为最大的挑战将是在实践中有效地实现这一点，特别是对于并行处理。与传统的前馈架构相比，循环性质增加了复杂性。然而，计算节省可能使它对许多应用程序来说是值得的。 TLDR：本文建议将神经网络深度视为连续的而不是离散的，使用循环处理在推理过程中更有效地扩展计算。显示出有希望的结果，在保持性能的同时减少了 30-40% 的计算量。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imwkns/r_recurrent_latent_reasoning_scaling_testtime/</guid>
      <pubDate>Tue, 11 Feb 2025 11:35:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] 利用潜在推理扩展测试时间计算：一种循环深度方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imr031/r_scaling_up_testtime_compute_with_latent/</link>
      <description><![CDATA[  由    /u/jsonathan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imr031/r_scaling_up_testtime_compute_with_latent/</guid>
      <pubDate>Tue, 11 Feb 2025 05:04:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我对知识蒸馏的实验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imodbb/p_my_experiments_with_knowledge_distillation/</link>
      <description><![CDATA[嗨 r/MachineLearning 社区！ 我对知识提炼进行了几次实验，想分享我的发现。以下是比较教师、学生、微调和提炼模型性能的结果片段：   数据集 Qwen2 模型系列 MMLU（推理） GSM8k（数学） WikiSQL（编码）            1 预训练 - 7B 0.598 0.724 0.536   2 预训练 - 1.5B 0.486 0.431 0.518   3 微调 - 1.5B 0.494 0.441 0.849   4 Distilled - 1.5B, Logits Distillation 0.531 0.489 0.862   5 Distilled - 1.5B, Layers Distillation 0.527 0.481 0.841   如需详细分析，您可以阅读本报告。 我还创建了一个开源库以促进其采用。您可以在此处尝试。 我的结论：当目标数据集上的较大模型和较小模型之间存在很大差距时，优先选择蒸馏而不是微调。在这种情况下，蒸馏可以有效地传递知识，从而比单独的标准微调产生更好的性能。 附注：本博客文章对蒸馏进行了高级介绍。 让我知道你的想法！    提交人    /u/darkItachi94   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imodbb/p_my_experiments_with_knowledge_distillation/</guid>
      <pubDate>Tue, 11 Feb 2025 02:44:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>