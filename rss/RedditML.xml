<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Mon, 12 Aug 2024 06:22:36 GMT</lastBuildDate>
    <item>
      <title>[D] 我如何改进/加速我的聊天机器人？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq63v2/d_how_do_i_improvespeedup_my_chatbot/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq63v2/d_how_do_i_improvespeedup_my_chatbot/</guid>
      <pubDate>Mon, 12 Aug 2024 05:54:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformers 是通用的上下文学习器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq5bkz/r_transformers_are_universal_incontext_learners/</link>
      <description><![CDATA[这项工作探索了 Transformer 的表现力，重点关注它们处理任意数量上下文标记的能力。值得注意的是，单个 Transformer 可以处理具有固定嵌入维度和恒定数量头的无限数量的标记。注意层之间 MLP 层的使用也受到严格监管    提交人    /u/AhmedMostafa16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq5bkz/r_transformers_are_universal_incontext_learners/</guid>
      <pubDate>Mon, 12 Aug 2024 05:06:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用断路器提高一致性和稳健性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq4c77/r_improving_alignment_and_robustness_with_circuit/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq4c77/r_improving_alignment_and_robustness_with_circuit/</guid>
      <pubDate>Mon, 12 Aug 2024 04:10:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多智能体模仿学习：价值很容易，遗憾很难</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq4aik/r_multiagent_imitation_learning_value_is_easy/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq4aik/r_multiagent_imitation_learning_value_is_easy/</guid>
      <pubDate>Mon, 12 Aug 2024 04:07:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于撰写基准论文的优点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eq22hg/d_pros_about_writing_a_benchmark_paper/</link>
      <description><![CDATA[作为一个从未写过论文提出基准的人，我只能想象写一篇论文会有什么见解/收获。也许发现模型的底层性能就是其中之一。对于那些写过类似文章的人，你觉得你的经验有价值吗？你会推荐吗？    提交人    /u/Haunting_Air3071   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eq22hg/d_pros_about_writing_a_benchmark_paper/</guid>
      <pubDate>Mon, 12 Aug 2024 02:08:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 低数据扩散的架构，但 PCA 也表明需要 5%-10% 的 PCA 组件特征数量才能解释 80-90% 的方差？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epzir5/d_architecture_for_diffusion_for_low_data_but_pca/</link>
      <description><![CDATA[我有一个数据集，相当少。2K 个样本。这些不是图像，而是集合数据。每个样本都是一组值 V，每组/样本大约有 50,000 个。 当我执行 PCA 时，我看到 numV 成分的 10% 解释了 90% 左右的方差。 我尝试了一个简单的 Transformer 块 x 3，以及一些跳过/规范。并训练了反向扩散。低点很低。但是当我生成数据时，损失（MSE）很低，但绝对皮尔逊相关系数很低，所以它不能很好地捕捉到起伏。 你们有什么建议吗？对于神经网络的架构或数据表示等 编辑：我还要补充一点，Transformer 在计算和存储大型注意矩阵时非常痛苦 整个数据集的形状为 (2000, 50_000)    提交人    /u/MysticalDragoneer   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epzir5/d_architecture_for_diffusion_for_low_data_but_pca/</guid>
      <pubDate>Mon, 12 Aug 2024 00:04:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] Vision Transformer + 聊天机器人</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epz92g/p_vision_transformer_chatbot/</link>
      <description><![CDATA[假设我想在某些图像数据和注释上训练一个预先训练过的 Vision Transformer/CLIP 模型，并将其实现为聊天机器人，基本上像 ChatGPT4.0，我该怎么做？我应该提到，这些图像的注释将是单词/双词，但我的要求包括，鉴于 Transformer 已在其他图像数据上进行过预先训练并且具有进行对话的能力，因此它在扫描图像后可以给出 4-5 行文本。我有计算机视觉方面的经验和法学硕士的基本经验，但这对我来说绝对是另一个级别。    提交人    /u/DaTrollFace   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epz92g/p_vision_transformer_chatbot/</guid>
      <pubDate>Sun, 11 Aug 2024 23:52:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 研讨会：可扩展的无 MatMul 语言建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epz1zr/r_workshop_scalable_matmulfree_language_modeling/</link>
      <description><![CDATA[摘要  矩阵乘法 (MatMul) 通常占据大型语言模型 (LLM) 总体计算成本的主导地位。随着 LLM 扩展到更大的嵌入维度和上下文长度，此成本只会增加。在这项工作中，我们表明 MatMul 操作可以完全从 LLM 中消除，同时在十亿参数规模下保持强劲性能。我们的实验表明，我们提出的无 MatMul 模型实现了与最先进的 Transformers 相当的性能，后者在推理期间需要更多的内存，规模至少达到 2.7B 参数。我们研究了缩放规律，发现我们的无 MatMul 模型和全精度 Transformers 之间的性能差距随着模型尺寸的增加而缩小。我们还提供了此模型的 GPU 高效实现，与未优化的基线相比，在训练期间可将内存使用量降低高达 61%。通过在推理过程中使用优化的内核，与未优化的模型相比，我们的模型的内存消耗可以减少 10 倍以上。为了正确量化我们架构的效率，我们在 FPGA 上构建了一个自定义硬件解决方案，该解决方案利用了 GPU 无法处理的轻量级操作。我们以 13W 的功耗处理了十亿参数规模的模型，超出了人类可读的吞吐量，使 LLM 更接近类似大脑的效率。这项工作不仅展示了 LLM 在保持有效运行的情况下可以剥离到何种程度，而且还指出了未来加速器在处理下一代轻量级 LLM 时应该优化的操作类型。  论文： 链接到 arXiv 仓库： 链接到 GitHub 研讨会 大家好，我们将与最近的论文“可扩展的无 MatMul 语言建模”的第一作者一起举办一个免费的在线研讨会！Ridger Zhu 将介绍一些关于论文和研究领域的幕后花絮，以及一些关于实施细节的说明。我们希望将人数控制在较小规模，以便 Ridger 有机会回答每个人的问题，因此将按照先到先得的原则进行，容量有限。 时间： 8 月 15 日下午 6 点（太平洋夏令时间） 地点： 在线（通过 Zoom） 加入候补名单： 在此处注册（我们将在临近日期时发送包含会议详细信息的电子邮件）    提交人    /u/Dankiest_Of_Memes   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epz1zr/r_workshop_scalable_matmulfree_language_modeling/</guid>
      <pubDate>Sun, 11 Aug 2024 23:43:05 GMT</pubDate>
    </item>
    <item>
      <title>付费 API 与本地机器 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epyta8/paid_apis_vs_local_machine_d/</link>
      <description><![CDATA[我正在考虑构建一台带有几个高端 GPU 的计算机，用于在本地运行 ML 模型（可能是 ollama 和开放 WebUI）。 但是，我已经计算了机器构建的数字，现在想知道是否应该将这笔钱花在支付 API 上。两个 RTX 4090 24GB 将花费我 5000 美元。我将这些 GPU 的相关使用寿命定为 5 年。这大约是每月 85 美元的 API 代币。 哪个会更好？ 有人解决了这个问题吗？    提交人    /u/mikedensem   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epyta8/paid_apis_vs_local_machine_d/</guid>
      <pubDate>Sun, 11 Aug 2024 23:32:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 需要有关使用机密数据在本地微调 LLM 以及创建 PDF 模板的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eps6k5/d_need_advice_on_finetuning_llms_locally_with/</link>
      <description><![CDATA[大家好！我计划在本地机器上使用 Llama 3.1 70B 模型，使用公司的一些机密数据对其进行微调。我担心的是，尽管我将在本地运行该模型，但这些数据是否可能会泄露。 此外，您能否推荐一些比 Llama 3.1 70B 更好的 LLM？ 就上下文而言，我有一个大约 9 个 PDF 的数据集（我知道这不是很多），其中包含表格和文本的混合。当我微调模型时，我需要它以 PDF 格式生成模板，仅关注表格和标题。由于我对此还很陌生，因此我非常感谢任何有关如何准备数据集以及我的下一步应该做什么的建议。谢谢！    提交人    /u/thepotentio_reddy09   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eps6k5/d_need_advice_on_finetuning_llms_locally_with/</guid>
      <pubDate>Sun, 11 Aug 2024 18:45:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢所有人在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Aug 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] onnx 模型转换的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epgi4u/discussion_resources_for_onnx_model_conversion/</link>
      <description><![CDATA[过去六个月我一直在从事一个基于音频的项目，主要使用 TensorFlow，因为需要使用 TensorFlow Lite (TFLite) 部署模型。但是，我在基于音频的增强方面遇到了 TensorFlow 的限制，例如音调变换、房间脉冲响应 (RIR) 和 SpecAugment。相比之下，PyTorch 为这些任务提供了一套更丰富的工具，使其更适合我的项目需求。 鉴于此，我正在考虑切换到 PyTorch。但是，我仍然需要将 PyTorch 模型转换为 TensorFlow 模型以进行部署。在研究过程中，我发现 ONNX 是一种流行的转换方法。但是，似乎 PyTorch 模型需要以特定方式构建才能在转换后与 TensorFlow 兼容。 是否有人有关于如何构建 PyTorch 模型以进行 ONNX 转换的指南，或者知道更灵活的转换技术？ TL;DR：我正在使用 TensorFlow 进行 TFLite 部署的音频项目，但由于 PyTorch 具有出色的音频增强工具，因此正在考虑切换到 PyTorch。我需要将 PyTorch 模型转换为 TensorFlow，并正在寻找有关使用 ONNX 进行此或任何其他灵活转换方法的指导。    提交人    /u/JournalistCritical32   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epgi4u/discussion_resources_for_onnx_model_conversion/</guid>
      <pubDate>Sun, 11 Aug 2024 09:07:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从 Scratch 开始的 Vison 语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epga39/p_vison_language_models_from_scratch/</link>
      <description><![CDATA[        提交人    /u/themathstudent   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epga39/p_vison_language_models_from_scratch/</guid>
      <pubDate>Sun, 11 Aug 2024 08:52:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 树注意力：GPU 集群上长上下文注意力的拓扑感知解码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ep9qpa/r_tree_attention_topologyaware_decoding_for/</link>
      <description><![CDATA[一篇新的研究论文介绍了一种树注意力算法，用于在多个 GPU 上并行化注意力计算，利用 logsumexp 和 max 运算的关联属性将约简结构化为树。 树注意力算法使跨设备解码能够比 Ring Attention 等替代方法渐近地更快地执行（最高可快 8 倍），同时还需要显著减少通信量并将峰值内存减少 2 倍。    提交人    /u/AhmedMostafa16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ep9qpa/r_tree_attention_topologyaware_decoding_for/</guid>
      <pubDate>Sun, 11 Aug 2024 02:17:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>