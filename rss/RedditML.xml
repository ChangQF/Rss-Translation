<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 09 Jan 2024 09:13:43 GMT</lastBuildDate>
    <item>
      <title>目前该领域的弱点是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192aj3h/what_are_weaknesses_of_the_field_currently_d/</link>
      <description><![CDATA[大家好， 有人了解该领域技术和业务相关的差距和弱点吗？如果可能或者更高效的话，哪些事情会让项目和模型变得最优？例如（不一定是大规模案例）缺乏高质量的数据集。  非常感谢！   由   提交 /u/卷积  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192aj3h/what_are_weaknesses_of_the_field_currently_d/</guid>
      <pubDate>Tue, 09 Jan 2024 09:06:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自对弈微调将弱语言模型转换为强语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192agnv/r_selfplay_finetuning_converts_weak_language/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.01335 摘要：  通过监督微调利用人工注释数据的力量（SFT）对于推进大型语言模型（LLM）至关重要。在本文中，我们深入探讨了在无需获取额外人工注释数据的情况下，从较弱的法学硕士中培养出较强的法学硕士的前景。我们提出了一种新的微调方法，称为自玩微调（SPIN），该方法从监督微调模型开始。 SPIN 的核心在于自我对弈机制，LLM 通过与自身实例对战来完善其能力。更具体地说，法学硕士从之前的迭代中生成自己的训练数据，通过区分这些自我生成的响应和从人工注释数据中获得的响应来完善其策略。我们的方法逐步将 LLM 从一个新生模型提升为一个强大的模型，释放了 SFT 人工注释演示数据的全部潜力。从理论上讲，我们证明，只有当 LLM 策略与目标数据分布一致时，才能实现我们方法的训练目标函数的全局最优。根据经验，我们在几个基准数据集上评估我们的方法，包括 HuggingFace Open LLM Leaderboard、MT-Bench 和 Big-Bench 的数据集。我们的结果表明，SPIN 可以显着提高 LLM 在各种基准测试中的表现，甚至优于通过直接偏好优化 (DPO) 并辅以额外 GPT-4 偏好数据训练的模型。这揭示了自我对弈的前景，无需专家对手即可在法学硕士中实现人类水平的表现。   &amp;# 32；由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192agnv/r_selfplay_finetuning_converts_weak_language/</guid>
      <pubDate>Tue, 09 Jan 2024 09:01:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 尝试理解alignn论文中的边和节点嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/192aeps/d_trying_to_understand_edge_and_node_embeddings/</link>
      <description><![CDATA[      我正在阅读这篇论文 ALIGNN（原子线图神经网络） - 链接。我对他们如何找到边缘和键嵌入感到困惑。他们提到他们正在使用原子线图（不知道那是什么）作为原始图，节点表示原子线图中的边，边表示原子的三元组以包括键角。  折线图&lt; /p&gt; 那么我们如何最终确定图的这些三元组呢？假设我们有一个包含 10 个节点和 10 个边的图，这些三元组是如何最终确定的、有多少个三元组以及它们将按什么顺序考虑它     ;由   提交 /u/specializedboy   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/192aeps/d_trying_to_understand_edge_and_node_embeddings/</guid>
      <pubDate>Tue, 09 Jan 2024 08:58:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 定制 LLM RAG 应用程序会变得多余吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1929n4f/d_are_custom_llm_rag_apps_going_to_become/</link>
      <description><![CDATA[Copilot Studio 即将推出 (https://www.microsoft.com/en-us/microsoft-copilot/microsoft-copilot-studio）具有令人印象深刻的无代码/开箱即用的 RAG 解决方案。  开源 RAG 世界（例如 Langchain、Llamaindex 等）有大量的开发和活动，我是 FYI 的大力支持者。 但是，什么似乎奇怪的是，如果您想构建一个 RAG 应用程序，即如果您比较构建和生产自定义应用程序的成本，那么这种没有开箱即用代码的解决方案（Copilot Studio - 只是作为一个示例）似乎压倒性地是更好的选择RAG 应用程序与使用 Copilot Studio 的成本相比，几乎低了一个数量级（无论您如何削减开发人员的时间和持续时间）。  我的问题是，在我看来，我们正在走向这样一种情况：企业解决方案将使自定义 RAG 应用程序变得多余（当然不是在所有情况下，但在大多数情况下），但是似乎很少有与开源社区中的活动相关的讨论。人们是否同意这是一种可能的情况？  显然会有例外......但在大多数用例中，我不知道如何与即时/最小设置、低成本、高度可扩展的 RAG 解决方案竞争。    由   提交/u/Used-Ad-7734   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1929n4f/d_are_custom_llm_rag_apps_going_to_become/</guid>
      <pubDate>Tue, 09 Jan 2024 08:03:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对话系统的多模态记忆和经验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1927zi6/d_multimodal_memory_and_experiences_for_dialog/</link>
      <description><![CDATA[      我认为，为了让人工智能和对话系统能够自主运行，它们应该具有多模态记忆和体验，例如场景记忆和情景记忆。 （就像电影《杨后》中出现的记忆[1]） 我正在考虑以下系统作为原型。 这是一个处理多模态的系统向量DB作为系统自身的记忆和经验，并使用系统自身的多模态记忆来响应人类的话语。 假设DB中存储的数据是与情景记忆相关的图像和文本的组合，例如如 MPCHAT [2]。 原型 然而，目前的多模态法学硕士专门研究从第三人称视角理解图像，并不能将图像视为系统自己的记忆或经验。 请让我知道是否有任何论文或技术可能有用！ 谢谢。 参考文献： [1] 杨的记忆场景来自 AFTER YANG，https://youtu.be/cIJ8-HGWlKw?feature=shared [2] MPCHAT：迈向基于角色的多模式对话， https://arxiv.org/abs/2305.17388  &amp; #32；由   提交/u/kassy11jp   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1927zi6/d_multimodal_memory_and_experiences_for_dialog/</guid>
      <pubDate>Tue, 09 Jan 2024 06:17:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你们如何评价LLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1926ias/d_how_do_you_guys_evaluate_llm/</link>
      <description><![CDATA[你们如何评价LLM？有在线排行榜：https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard &amp; #x200b; 是否有任何脚本可以自动评估我们的离线/基准性能？   由   提交/u/Dense-Smf-6032   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1926ias/d_how_do_you_guys_evaluate_llm/</guid>
      <pubDate>Tue, 09 Jan 2024 04:54:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT4-V VS Gemini Pro Vision 完整版！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19268kz/d_gpt4v_vs_gemini_pro_vision_full_version/</link>
      <description><![CDATA[目前GPT和Gemini都只支持图片输入，不支持视频输入。因此，我只从Google Gemini demo中选择了与图像相关的测试来比较GPT-4-V和Gemini-Pro-Vision，测试内容包括：  图像内容的基本识别 对图像中的物体进行分析 对图像中的内容进行逻辑推理 连续图像内容的识别与分析  https://youtu .be/yFK62Tn_f4Q 如果您对视频中演示的开源项目感兴趣，请访问https://github.com/smalltong02/keras-llm-robot    由   提交 /u/Entire-Fly-6957   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19268kz/d_gpt4v_vs_gemini_pro_vision_full_version/</guid>
      <pubDate>Tue, 09 Jan 2024 04:39:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视频摘要有圣杯吗？像专业人士一样记录和检索！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1925m9k/d_is_there_a_holy_grail_for_video_summarization/</link>
      <description><![CDATA[嘿 Reddit 爱好者，我正在寻找终极视频摘要方法。不仅仅是普通的要点列表，而是丰富、详细和互动的内容。将其视为将每个视频变成可搜索的事件数据库，准备好回答我稍后提出的任何问题。 这是梦想的工作流程：  记录每个关键事件：捕获所有重要内容 - 人物、事件、地点、时间、原因。有人被绊倒吗？机器人跳舞了吗？记录下来！ 不错的细节：不仅仅是“人摔倒了”，但“笨拙的游客在博物馆入口外被香蕉皮绊倒。”描述性越强越好。 问答检索：稍后，我应该能够提出诸如“向我展示所有有趣的瀑布”之类的问题。或“机器人在讲话时说了什么？”并获得精确的视频片段作为响应。  我知道，这听起来雄心勃勃，但这可能吗？ 我探索了一些选择： 自动转录&amp;关键字提取：听起来很有希望，但可能会错过未说出口的事件（有人跌倒）。 人工注释：准确，但耗时且昂贵。 基于 AI/ML 的方法：总结逐帧进行，但我们失去了活动的时间流（例如：绕圈行走）。 所以，Reddit，我需要你的智慧！您是否遇到过任何接近我的视频摘要梦想的工具或技术？或者我在这里追逐独角兽？ P.S. 请随意用您自己的视频摘要困境和愿望劫持此线程！越多越好（我们离圣杯越近）！   由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1925m9k/d_is_there_a_holy_grail_for_video_summarization/</guid>
      <pubDate>Tue, 09 Jan 2024 04:08:22 GMT</pubDate>
    </item>
    <item>
      <title>混合纸[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1924vn1/mixtral_paperd/</link>
      <description><![CDATA[https://arxiv.org/abs/2401.04088   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1924vn1/mixtral_paperd/</guid>
      <pubDate>Tue, 09 Jan 2024 03:31:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] WikiChat：通过维基百科上的少发基础来阻止大型语言模型聊天机器人的幻觉 - 在与人类用户就最新主题进行的对话中实现了 97.9% 的事实准确性，比 GPT-4 好 55.0%！ - 斯坦福大学 2023</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1920hky/r_wikichat_stopping_the_hallucination_of_large/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2305.14292v2  Github：https://github.com/stanford-oval/WikiChat  摘要：  本文提出了第一个基于 LLM 的少样本聊天机器人几乎从不产生幻觉，并且具有高会话性和低延迟。 WikiChat 以英语维基百科为基础，这是最大的精选自由文本语料库。  WikiChat 生成法学硕士的回复，仅保留有根据的事实，并将其与从语料库中检索到的其他信息相结合，形成事实且引人入胜的回复。 我们将基于 GPT-4 的 WikiChat 提炼为质量损失最小的 7B 参数 LLaMA 模型，以显着改善其延迟、成本和隐私，并促进研究和部署。  使用一种新颖的人类和法学硕士混合评估方法，我们证明我们最好的系统在模拟对话中达到了 97.3% 的事实准确性。它显着优于所有基于检索和基于 LLM 的基线，与 GPT-4 相比，在头部、尾部和近期知识方面分别提高了 3.9%、38.6% 和 51.0%。与之前最先进的基于检索的聊天机器人相比，WikiChat 的信息量和吸引力也显着提高，就像法学硕士一样。  WikiChat 在与人类用户就近期话题进行的对话中实现了 97.9% 的事实准确性，比 GPT-4 高出 55.0%，同时获得了更高的用户评分和更有利的评论。   https:/ /preview.redd.it/9mhpdh300bbc1.jpg?width=1225&amp;format=pjpg&amp;auto=webp&amp;s=cb64b717e920d7bf727782f7c803500ae838d6ef https://preview.redd.it/5dxesl200bbc1.jpg?width=862&amp;format=pjpg&amp;auto=webp&amp;s =b6de0cda980eec3cf3484ff1f9cd6dc1acf13505 https ://preview.redd.it/j387vl200bbc1.jpg?width=914&amp;format=pjpg&amp;auto=webp&amp;s=736fb922c1f98f4c7b132f1c153f4653a8b85441 https://preview.redd.it/3hnxqi200bbc1.jpg?width=923&amp;format=pjpg&amp;auto=webp&amp; ;s=95b40a9cf67d7f3729dae85878db67a262cc5201   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1920hky/r_wikichat_stopping_the_hallucination_of_large/</guid>
      <pubDate>Tue, 09 Jan 2024 00:07:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我构建了 marimo——一个开源的反应式 Python 笔记本，它存储为 .py 文件，可以作为脚本执行，并且可以作为应用程序部署。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191rdwq/p_i_built_marimo_an_opensource_reactive_python/</link>
      <description><![CDATA[嗨！我想分享 marimo，一个用于 Python 的开源反应式笔记本。它旨在解决 Jupyter 笔记本的许多众所周知的问题，同时为您提供新功能：marimo 笔记本可重复（无隐藏状态）、git 友好（存储为 Python 文件）、可作为 Python 脚本执行以及可部署为 Web 应用程序。 GitHub 存储库： https://github.com/marimo-team/marimo 在 marimo 中，您的笔记本代码、输出和程序状态保证是一致的。运行单元格并通过自动运行引用其变量的单元格来做出反应。删除一个单元格，marimo 就会从程序内存中清除其变量，从而消除隐藏状态。如果您担心意外触发昂贵的计算，您可以禁用特定单元格的自动运行。 marimo 还附带 UI 元素，例如滑块、数据帧转换器以及自动与 Python 同步的交互式绘图。与元素交互，使用该元素的单元格会自动以其最新值重新运行。反应性使这些 UI 元素比 Jupyter 小部件更有用，更不用说更易于使用。 我选择开发 marimo，因为我相信 ML 社区应该有一个更好的编程环境来进行研究和交流。我看到很多研究都是从 Jupyter 笔记本开始的（我自己的大部分也是这样）。由于 Jupyter 笔记本固有的缺陷，我还看到许多相同的研究无法重现或因隐藏的错误而减慢速度。 我坚信，我们的工作质量取决于我们的工作质量我们使用的工具塑造了我们的思维方式——更好的工具，更好的思维。 2017 年至 2018 年，我在 Google Brain 担任软件工程师，当时 TensorFlow 正在过渡到 TensorFlow 2，而 JAX 还处于早期阶段。我亲眼目睹了 PyTorch 和 JAX 为我们的社区带来的生产力的提高，后来当我在斯坦福大学与 Stephen Boyd 一起攻读博士学位时，我也亲眼目睹了我自己的研究。我们对 marimo 的目标是通过新的编程环境做一些类似的事情。 marimo 的开发经过了科学家和工程师的密切投入，并受到了包括 Pluto.jl 和 Streamlit 在内的许多工具的启发。只有我们两个人在研究它——我们最近将其开源，因为我们认为它已经准备好供更广泛的使用。请尝试一下（pip install marimo &amp;&amp; marimo 教程简介）。我们非常希望您能提供任何反馈！   由   提交 /u/akshayka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191rdwq/p_i_built_marimo_an_opensource_reactive_python/</guid>
      <pubDate>Mon, 08 Jan 2024 18:00:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 采访里奇·萨顿</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191oujg/d_interview_with_rich_sutton/</link>
      <description><![CDATA[一个多月前，我向这位订阅者询问了一些问题，以询问 Rich Sutton (此处），截至今天，完整采访内容可在 https:/ /youtu.be/4feeUJnrrYg！ Rich 有一些独特的想法 - 或者正如他喜欢说的 - 它是什么过时了，但我很想听听其他人之后的想法提出其中一些想法。 大纲： 0:00 - 简介 1:33 - 采访开始 2:04 - OpenMind 研究院4:32 - 人工智能的历史7:13 - 扩展容易吗？10:49 - 反向传播和反向传播的问题陈述21:22 - 狭隘视野的咆哮23:43 - 令人兴奋的新事物 32:00 - 记忆 35:34 - 提出想法 43 :47 - STOMP45:30 - Keen Technologies50:39 - 人类的下一阶段和未来情绪1:06:25 - 外星人工智能1:08:00 - 不同的研究方法1:21:30 - 里奇的建议1:26:00 - RL 牛肉1:27:07 - 将所有内容整合在一起    由   提交/u/ejmejm1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191oujg/d_interview_with_rich_sutton/</guid>
      <pubDate>Mon, 08 Jan 2024 16:17:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人脑 FLOPs 估计，是否比我们想象的要低？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191ol1n/d_human_brain_flops_estimate_is_it_lower_than_we/</link>
      <description><![CDATA[这篇文章旨在提供对人脑的深入了解，以便更容易将其与人工神经网络进行比较。 对我即将要说的大部分内容持保留态度，我很容易就会被一个数量级所影响，或者错过一些东西。  Ray Kurzweils 估计。 1011 个神经元。每个神经元有 1000 个突触连接。每秒 100 个峰值。  每秒计算 1011 × 1000 × 100=1016 次。 引用奇点临近：“考虑到人脑逆向工程的早期阶段，我将使用更保守的数字 1016 CPS”。  我自己的计算。自 2005 年以来情况似乎发生了变化，现在维基百科说每个神经元有 7000 个突触 https://en.m.wikipedia.org/wiki /Neuron  神经元放电速度平均为 0.1 到 2 赫兹。 https://aiimpacts.org/rate-of-neuron-firing/ #:~:text=Assorted%20estimates- 我将使用 1/s 作为尖峰频率。大脑也更明确，有 86,000,000,000 个神经元。 8,6×1010 × 7000 × 1 = 6×1014。 6×10 14 FLOP（每个突触一次 FLOP）。  峰值能量需求。神经元的每次激活都需要一定量的能量，该能量似乎为 2.468 × 10−7 J https://link.springer.com/article/10.1007/s11571-018-9503-3  所以从这里开始，其他一切都可以被弄清楚。尖峰能量 = 2.468 × 10−7 J 24 小时内大脑能量消耗 = 1,673,600 焦耳 24 小时内的秒数 = 86400。每个神经元有 7000 个突触。 1,673,600÷(2.468 × 10 −7) J = 6,782×1012。 6,782×1012 ÷ 86400 = 78,486,103。 (78,每秒 500 万次峰值）。 78,486,103 × 7000 = 5.49×1010 FLOP 或 549 gigaFLOPs 如果 3 正确，则意味着高端手机的 GPU 计算量比人脑的计算量还要多（三星 s23，fp32 时为 3,681 TFLOP。大脑一天平均为 0,549 TFLOP）。 这不是比较事物的好方法，因为大脑是一台大规模并行计算机，内存基本上存在于结构中。  那么需要多少“内存”呢？我们谈论的是大脑吗？我们有： 86,000,000,000 个神经元。每个神经元有 7000 个突触。每个突触 5 位。 https://www.cnsnevada.com/what-is-the-memory-capacity-of-a- human-brain/#:~:text=Neurons%20are%20the%20cells%20which 86,000,000,000 × 7000 × 5 = 3×1015 位或 3.76×1014 字节。祝你好运，在手机上安装 376 TB RAM。 但是每秒 78,500,000 个峰值真的足以让大脑处理所有事情吗？让我们看看眼睛。 每只眼睛的总分辨率为 8 兆像素。 https://m.youtube.com/watch?v=4I5Q3UXkGd0&amp;pp=ygUednNhdWNlIHJlc29sdXRpb 24gb2YgaHVtYW4gZXll&lt; /p&gt; 通过视神经发送的信息大约只有 10,000,000 位/秒 https://www.eurekalert。 org/news-releases/468943 （只有最相关的信息通过视神经发送，因为大脑希望不惜一切代价节省电量）。因此，我们的双眼每秒有 20,000,000 个尖峰，这是 7850 万个尖峰的 25.5%。 7850 万个尖峰并不是硬性的性能上限，它只是一天中的平均值，而大脑是根据需要主动调节脑电波频率。 您认为哪种情况更有可能？ 1. 2. 或 3.   由   提交 /u/SpaceXRaptor42   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191ol1n/d_human_brain_flops_estimate_is_it_lower_than_we/</guid>
      <pubDate>Mon, 08 Jan 2024 16:05:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何猜测梯度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191lu3v/r_how_to_guess_a_gradient/</link>
      <description><![CDATA[      奇怪的是，你在不知道目标函数的情况下就知道梯度在哪里。 论文：https://arxiv.org/abs/2312.04709 摘要  关于梯度你能说多少无需计算损失或不知道标签的神经网络？这听起来可能是一个奇怪的问题：答案肯定是“很少”。然而，在本文中，我们表明梯度比之前想象的更加结构化。梯度位于可预测的低维子空间中，该子空间取决于网络架构和传入特征。利用这种结构可以显着改进基于方向导数的无梯度优化方案，该方案一直难以扩展到在玩具数据集上训练的小型网络之外。我们研究如何缩小计算精确梯度的方法和使用方向导数的方法之间优化性能的差距。此外，我们强调了克服精确梯度优化和猜测梯度之间巨大差距的新挑战。  https://preview.redd.it/l7tm982c28bc1.png?width=1962&amp;format=png&amp;auto=webp&amp;s=94d237353bc53ee b21489f6adeeaa8e43043f44a ​   由   提交/u/That_Violinist_18   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191lu3v/r_how_to_guess_a_gradient/</guid>
      <pubDate>Mon, 08 Jan 2024 14:00:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>