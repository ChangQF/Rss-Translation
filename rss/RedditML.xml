<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 15 Oct 2024 09:17:58 GMT</lastBuildDate>
    <item>
      <title>为裸 React Native 应用实现的 BERT 模型的 WordPiece Tokenizer [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g43jcg/wordpiece_tokenizer_for_bert_models_implemented/</link>
      <description><![CDATA[在花费了大量时间并且几次几乎发疯之后，我终于成功构建了一个标记器，为在裸 React Native 应用程序上运行的自定义 Bert 模型准备输入。 我没有使用外部库，因为目前没有可用于裸 React Native 环境的库（我认为 expo 有，但不确定）。 我不知道以前是否有人搞砸过这个问题，但我打算将我的代码作为模块开源，我想知道至少是否存在这种需要，以及是否有少数贡献者愿意参与    提交人    /u/BrilliantCustard1136   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g43jcg/wordpiece_tokenizer_for_bert_models_implemented/</guid>
      <pubDate>Tue, 15 Oct 2024 09:17:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解 CLIP 模型中的损失</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g42hnu/d_understanding_the_loss_in_the_clip_model/</link>
      <description><![CDATA[我正在仔细研究 CLIP 论文。第 2.3 节第 4 段中写道：  联合训练图像编码器和文本编码器，以最大化批次中 N 个真实对的图像和文本嵌入的余弦相似度，同时最小化 N2 − N 个不正确配对的嵌入的余弦相似度。   查看来自 MLFoundations 的 代码，第 290 行及以后， ``` logits_per_image = logit_scale * image_features @ text_features.t() logits_per_text = logits_per_image.t() total_loss = ( F.cross_entropy(logits_per_image, labels) + F.cross_entropy(logits_per_text, labels) ) / 2 ``` 来自 Revant 的 替代实现 具有非常相似的代码（第 88 行及以后） 我的问题很简单 -  这些代码行是否对应于论文中所述的最大化 N 个真实对的余弦相似度并最小化其他 N2 - N 个不正确对的余弦相似度？如果确实如此，请帮助我简要了解一下这是怎么回事。     提交人    /u/datashri   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g42hnu/d_understanding_the_loss_in_the_clip_model/</guid>
      <pubDate>Tue, 15 Oct 2024 07:51:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人知道可以编辑很长的音频文件的 AI 模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g41e7v/d_does_anyone_know_of_an_ai_model_that_can_edit/</link>
      <description><![CDATA[是否有一个人工智能网站或自托管模型，可以帮助编辑/修剪非常长的音频/视频文件中的静音部分？也许我在拉长它，但最好是免费的？ 我使用 DaVinci resolve 进行编辑，但似乎无法在其中执行此操作（这令人惊讶）。  作为奖励，如果它可以自动编辑音频/视频（不一定是长音频/视频），只需以正常方式即可，那就太好了。我有大量音频/视频，其中有很多空白处，我不值得花时间编辑所有这些。我还有很多不相关的长视频，我没有时间编辑。     提交人    /u/dangerously__based   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g41e7v/d_does_anyone_know_of_an_ai_model_that_can_edit/</guid>
      <pubDate>Tue, 15 Oct 2024 06:25:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习研究人员是否通常会调整代码直到其正常运行，然后再根据其进行叙述（和数学）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g40i0h/d_is_it_common_for_ml_researchers_to_tweak_code/</link>
      <description><![CDATA[作为一名有抱负的 ML 研究人员，我对同事的意见很感兴趣。如果真是这样，这会让您的工作变得不那么充实吗？    提交人    /u/Diligent-Ad8665   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g40i0h/d_is_it_common_for_ml_researchers_to_tweak_code/</guid>
      <pubDate>Tue, 15 Oct 2024 05:22:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在云端训练之前开发/调试分布式训练代码？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g3zmld/d_how_to_developdebug_distributed_training_code/</link>
      <description><![CDATA[您好，我对开发更大的模型或使用 DDP/FSDP 加速训练很感兴趣。我很好奇您如何使用单个 gpu 开发机器为此开发训练代码。我发现一些 torch 分布式代码不适用于单个 gpu 系统。有必要拥有 2+ gpu 机器吗？我知道 gpu 拆分，但据我所知，消费卡上没有。我不想在昂贵的云实例上进行调试。感谢您的任何建议！    提交人    /u/jms4607   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g3zmld/d_how_to_developdebug_distributed_training_code/</guid>
      <pubDate>Tue, 15 Oct 2024 04:27:24 GMT</pubDate>
    </item>
    <item>
      <title>[N] Lambda Cloud 上提供 A100 80 GB GPU 实例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g3y4xo/n_a100_80_gb_gpu_instances_available_on_lambda/</link>
      <description><![CDATA[Lambda Cloud 上有大量 A100 80 GB 容量可用 - https://lambdalabs.com/service/gpu-cloud    提交人    /u/Pretend-Lobster6455   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g3y4xo/n_a100_80_gb_gpu_instances_available_on_lambda/</guid>
      <pubDate>Tue, 15 Oct 2024 03:02:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 什么是“ML框架”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g3u1gv/d_what_is_an_ml_framework/</link>
      <description><![CDATA[我尝试使用 ML 已有一段时间了，我按照教程操作，对 PyTorch 也相当熟悉。一年多来，我一直在用漂亮的 C++20 构建一个 ML 框架。 我希望最终发布并产品化它。现在，我正在尝试明确定义明年首次发布所需的范围。 我的重点是深度神经网络（没有其他 ML 方法）。如果这样更清楚的话，我可以将其标记为“深度 NN 框架”。 我实现的功能：1. 用于定义层的可扩展框架。模型可以简单地由不同的层组成，然后进行训练和运行。2. 线性层、Relu、Softmax、Tanh 等等 - 无需分叉框架即可实现新层，基本上只是一个 C++ 类。3. 二次损失、交叉熵损失。新的损失函数很容易实现。4. 嵌入层、注意力层（带有一些自定义点）。5. 接下来将实现 CNN（Conv、pooling）层，应该很容易 6. 支持 RNN（需要做一些特殊工作才能使内存使用不依赖于迭代次数）5. 使用可插入优化器实现训练。SGD 已实现，ADAM 即将推出。支持多进程和分布式训练。6. 网络本身被编译为本机代码，目前支持 clang++ 和 GCC（Linux/Mac），将支持 VC++ 和 WebAssembly。将有几种方法可以打包参数，包括独立数据文件或可以链接到二进制文件中的 blob。 测试数据管理是作为并行项目开发的。目前，我支持下载存档文件并根据目录、大小、扩展名等对其进行采样。如果有用户需求，将与 Python 合作进行互操作。 价值主张：易于嵌入到其他代码库（视频游戏、嵌入式）中或在浏览器中部署和运行。我目前的里程碑是简单的编码器模型，还计划为 Q 学习提供一组有趣的功能。没有计划为推理或训练实现 GPU 支持，因为目前的目标是更小的模型，所以没有看到这种需要。 这样的框架还应该有什么？    提交人    /u/euos   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g3u1gv/d_what_is_an_ml_framework/</guid>
      <pubDate>Mon, 14 Oct 2024 23:34:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我实际上如何修剪 LLM 和 VLM？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g3rmuy/d_how_do_i_actually_prune_llm_and_vlms/</link>
      <description><![CDATA[我知道修剪的工作原理和作用，但我还没有在 LLM 上尝试过。我计划修剪 MolomoE 72B 和 Qwen2 VL 72B。我使用什么软件来实际修剪这些模型。     提交人    /u/SpecialistStory336   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g3rmuy/d_how_do_i_actually_prune_llm_and_vlms/</guid>
      <pubDate>Mon, 14 Oct 2024 21:42:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大学声誉/排名对于博士学位有多重要？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g3pw4t/d_how_important_is_the_university/</link>
      <description><![CDATA[大家好！ 我目前正在寻找博士职位（在欧洲），我正在多个博士职位之间做出选择。我有一份可靠的简历（排名靠前的大学、良好的研究经验、良好的实习机会），而且幸运的是，我几乎申请了每个实验室，都得到了面试机会。 由于我无法找到以下问题的简明答案，所以我想向社区询问！ 1. 大学的排名/声誉有多重要？ 我在各处都找到了很棒的实验室。我在排名低至 800qs 的大学中找到了很棒的实验室。虽然我知道排名是如何计算的，但我担心自己不能去一所声誉良好/知名的大学。作为一名在全国排名第一的大学获得学士/硕士学位的人，我担心在这样的地方攻读博士学位会让自己处于不利地位。 2. PI 声誉与大学声誉？ 这个问题主要归结为在知名大学攻读博士学位，导师合作者很少，研究网络很小，与导师来自不知名的大学，但与该领域的顶尖人物合作之间的区别。大池塘里的小鱼还是大池塘里的大鱼。 3. 大学 &lt;&gt; PI &lt;&gt; 研究适合度？您如何对它们进行排名？您会选择哪 2/3？ 由于您不太可能找到您想要的一切。你会在什么方面妥协？    提交人    /u/Stoick01   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g3pw4t/d_how_important_is_the_university/</guid>
      <pubDate>Mon, 14 Oct 2024 20:28:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有关于软件验证的机器学习研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g3nxpo/d_is_there_any_ml_research_regarding_software/</link>
      <description><![CDATA[我找到了几篇论文，但是我可能错过了正确的搜索词。 我特别感兴趣的是将实现 / 代码与它们的规范进行比较，或者只是通常使用机器学习检查 ~code 的等效性？ 谢谢    提交人    /u/SPD-1337   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g3nxpo/d_is_there_any_ml_research_regarding_software/</guid>
      <pubDate>Mon, 14 Oct 2024 19:09:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] pytorch 的高效视频摄取？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g3d1b0/d_efficient_video_ingestion_for_pytorch/</link>
      <description><![CDATA[我目前正在启动一个新项目，需要训练视频分类器/回归模型。每个视频由 ~360 帧组成，并以非常高的质量 ~3840x2160 拍摄（由同一相机在同一位置拍摄几乎相同的产品）。视频目前以 .ts 格式保存，我对此并不十分熟悉，但似乎压缩效率很高，因为每个视频仅占用约 15 MB 的空间。 我还不知道如何训练这些视频，但我的想法是在训练期间将每个视频分成随机的 n 帧剪辑。因此，如果 n=20，一个样本将具有形状 (20,3,3840,2160)。 最初，我在想，我只需将每个视频转换为图片帧，然后保存图片，或者将图片保存为 pytorch 对象。但是 15 MB 的视频会变成 0.5 GB 的 jpg 图片，更糟糕的是，如果我直接将其保存为 uint8 中大小为 (360,3,3840,2160) 的 pytorch 对象，那么每个小视频最终会占用大约 9 GB。所以显然这是不行的。 pytorch vision 有一个名为 VideoClips 的方法，https://github.com/pytorch/vision/blob/main/torchvision/datasets/video_utils.py，它似乎是为这种事情设计的，但使用此方法处理其中 3 个视频需要大约 80 秒。 （建议缓存此输出，但我不确定他们到底是什么意思？只是将结果腌制到文件中还是他们的意思是什么？） 使用 opencv 将相同的 3 个视频读入内存大约需要 20 秒，到目前为止这似乎是最好的方法，但我希望有一些我错过了的更好的工具。 也许解决方案涉及将视频从 .ts 转换为压缩程度较低但在 ML 中更易于读取和处理的格式？    提交人    /u/alyflex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g3d1b0/d_efficient_video_ingestion_for_pytorch/</guid>
      <pubDate>Mon, 14 Oct 2024 10:58:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助 NASA 资助的项目更多地了解太阳！（Kaggle 竞赛）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g32evj/d_help_a_nasafunded_project_learn_more_about_the/</link>
      <description><![CDATA[大家好，我叫 Hannah，我是 NASA 资助的 Eclipse Megamovie 2024 项目的通讯员。 4 月份日全食临近时，我们非常活跃，但还有更多令人兴奋的事情等着我们！我们发起了 Kaggle 竞赛，希望得到像这样的社区的帮助。以下是有关整个项目的更多信息以及我们的竞赛页面的链接。请随时提问，我会尽力回答！ 2024 年 4 月 8 日，日全食始于南太平洋，横跨北美洲，途经墨西哥、美国和加拿大。北美大陆第一个经历日全食的地点是墨西哥太平洋海岸，时间大约是太平洋夏令时间上午 11:07。 2024 年 4 月 8 日日全食之后，超过 145 名志愿者上传了超过 1 TB 的照片数据，供我们的项目使用。 Eclipse Megamovie 2024 (EM2024) 由 NASA 资助，旨在利用日全食期间收集的数据研究太阳，这是一个特殊的时期，可以研究太阳的行为，与其他任何时候都不同。日食和数据收集之后的下一个阶段是对照片数据进行分类和标记，然后我们就可以开始认真进行科学分析——这就是你发挥作用的地方！ 如果您精通 Python 代码和机器学习，您可能能够为解答有关太阳的以前未解答的问题做出贡献！  比赛页面链接：https://www.kaggle.com/competitions/eclipse-megamovie 比赛参与者将使用我们的 2017 年日全食数据集来“训练”机器，方法是编写代码并利用提供的训练数据集自动根据日食阶段将日食照片归类为几个类别之一。建议有兴趣参加本次比赛的人具备 Python 和机器学习基础知识。 与我们的竞赛一致的兴趣：摄影、太阳物理学和/或太阳科学研究、参与式科学和机器学习。奖品： 排行榜奖品：根据私人排行榜排名颁发。  一等奖：带太阳滤镜的图像稳定双筒望远镜、Eclipse Megamovie 网站上的 Spotlight、Eclipse Megamovie 团队徽章、NASA 日历、Eclipse Megamovie 贴纸、一等奖证书。 二等奖：Eclipse Megamovie 网站上的 Spotlight、Eclipse Megamovie 团队徽章、NASA 日历、Eclipse Megamovie 贴纸、二等奖证书。 三等奖：Eclipse Megamovie 网站上的 Spotlight、Eclipse Megamovie 团队徽章、NASA 日历、Eclipse Megamovie 贴纸、三等奖证书。  参与者将帮助确保数据 [日食照片] 能够快速组织，并且每张图片都具有正确的信息（元数据）。通过帮助我们开发能够准确识别志愿者提交的照片中的日食阶段的代码，您将帮助我们跨越一个重大的数据处理障碍。通过您的代码，您将为这项由 NASA 资助的研究太阳喷流和等离子羽流铺平道路！ 您的任务是创建最准确的分类机，将日食照片分类到特定的日食阶段。如果您的代码能够成功地将提供的照片分类为以下类别，您就知道自己成功了：暗色或平面（校准镜头）、日偏食阶段（20 度的箱 [类别]）、钻石环阶段、日全食阶段，当然还有非日食类别。 特别感谢 Mods 让我知道在这篇文章中使用哪个标签 :) 已编辑文字    提交人    /u/EMegamovie2024   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g32evj/d_help_a_nasafunded_project_learn_more_about_the/</guid>
      <pubDate>Sun, 13 Oct 2024 23:11:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 被研究论文淹没了？🐸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g31hfd/p_drowning_in_research_papers/</link>
      <description><![CDATA[      我们是两名对人工智能研究感兴趣的工程师，但却被 arXiv 上大量新论文淹没。因此，我们开发了 Ribbit Ribbit，一款研究论文发现工具。  https://apps.apple.com/us/app/ribbit-ribbit/id6529547956 https://ribbitribbit.co  它会整理个性化的论文推荐，并将其转化为推文大小的摘要，这样您就可以像在 Twitter 上一样滚动浏览。您还可以像为您量身定制的播客一样收听更新。我们添加了一点轻松的体验，希望它能为整个纸质阅读过程增添一丝乐趣，说实话，这个过程可能会变得相当枯燥乏味 :p。 https://preview.redd.it/evoemobinlud1.png?width=1179&amp;format=png&amp;auto=webp&amp;s=4dff5b2b60f2a1272b6ac04347f661ceacff2aa5    提交人    /u/haoyuan8   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g31hfd/p_drowning_in_research_papers/</guid>
      <pubDate>Sun, 13 Oct 2024 22:24:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 13 Oct 2024 02:15:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>