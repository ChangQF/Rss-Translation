<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Fri, 17 Jan 2025 15:16:37 GMT</lastBuildDate>
    <item>
      <title>[P] 安永开放科学人工智能与数据挑战赛 2025 虚拟指导会议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i3han7/p_virtual_orientation_session_on_ey_open_science/</link>
      <description><![CDATA[参加即将于 2025 年 1 月 22 日举行的开放科学人工智能与数据挑战虚拟介绍会。​​让我们共同努力，为城市降温，创造更健康、更可持续的城市环境。了解 2025 EY 开放科学人工智能与数据挑战如何通过应用人工智能和基于技术的解决方案来帮助解决城市热岛问题。获奖者有资格获得现金奖励并参加激动人心的颁奖典礼。立即注册！    提交人    /u/fofxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i3han7/p_virtual_orientation_session_on_ey_open_science/</guid>
      <pubDate>Fri, 17 Jan 2025 14:16:52 GMT</pubDate>
    </item>
    <item>
      <title>使用相机自动化深度学习模型（inception -Tensorflow）[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i3enos/automate_deep_learning_model_with_camerainception/</link>
      <description><![CDATA[所以我一直在研究一个深度学习项目，目的是检测物体。我的主要目标是从水中检测塑料，并使用附在船上的传送带将其拾取，因此我从 GitHub 获取代码并进行了足够的更改，现在模型可以正常工作，但有一个问题是我必须手动添加照片并将其名称更改为 test.jpeg（我已经给出了）所以在我的模型中，船上有一个摄像头我将如何制作一个项目，当它检测到物体时可以自动拍照并自动加载到我已经制作的模型中，对于所有这些过程，哪个开发板就足够了。我希望有人回答我的问题 🙂    提交人    /u/ExB_ZEBRoN   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i3enos/automate_deep_learning_model_with_camerainception/</guid>
      <pubDate>Fri, 17 Jan 2025 11:51:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对 TPAMI 审查流程的担忧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i3baxp/d_concerns_about_review_process_at_tpami/</link>
      <description><![CDATA[我于 2024 年 6 月 25 日向 TPAMI 提交了一篇论文。这是我们工作的一个重要延伸，被接受为 AAAI 2023 的口头报告。我知道 TPAMI 的评审非常严格，可能需要数月时间，但我只是想知道，就您的经验而言，评审所花的最长时间是多久，因为已经 6 个月零 3 天没有消息了。此外，审稿人会考虑提交日期后发表的作品吗？我只是担心，由于（可以理解的）评审速度很慢，审稿人会问我为什么不与 XYZ 方法进行比较，而是要求与该方法进行比较，由于该领域的进展速度很快，该方法可能会胜过我的方法，并使修订和接受变得复杂。    提交人    /u/I_am_a_robot_   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i3baxp/d_concerns_about_review_process_at_tpami/</guid>
      <pubDate>Fri, 17 Jan 2025 07:42:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2025 年值得关注的 AI 论文推荐</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i39iuh/d_recommendations_of_noteworthy_ai_papers_for/</link>
      <description><![CDATA[嗨，我正在设计一份论文清单，推荐给刚开始学习计算机科学的学生。 有哪些必读的论文，但又不是太深奥？ 如今，所有的统计学习理论都可以通过在线课程获得，但我希望他们能够成长为阅读学术论文的人。 我从 ilya Sutskever 的阅读清单开始。 也欢迎您简要解释一下您推荐这篇论文的原因！    提交人    /u/treblenalto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i39iuh/d_recommendations_of_noteworthy_ai_papers_for/</guid>
      <pubDate>Fri, 17 Jan 2025 05:36:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分享你最常做的尴尬的并行任务</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i39cia/d_share_your_most_frequent_embarrassingly/</link>
      <description><![CDATA[大家好， 我很好奇大家在实际中遇到的最常见的令人尴尬的并行任务是什么。在 ML 和 DS 领域，我注意到许多工作流程都倾向于遵循以下一般模式：  从云存储中提取大量数据 通过一系列函数处理该数据 运行分析、使用数据进行训练或将其传递到模型中进行推理  你们有哪些工作负载遵循此流程或类似流程？我一直在研究云抽象，以便更轻松地进行大规模并行处理，并且正在尝试确定构建教程所需的常见用例。 任何想法、建议或反馈都将非常有帮助    提交人    /u/Ok_Post_149   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i39cia/d_share_your_most_frequent_embarrassingly/</guid>
      <pubDate>Fri, 17 Jan 2025 05:25:37 GMT</pubDate>
    </item>
    <item>
      <title>探索数值稳定性的边缘 [研究]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i34keg/grokking_at_the_edge_of_numerical_stability/</link>
      <description><![CDATA[ Grokking 是长时间过度拟合后突然出现的泛化现象，是一种令人惊讶的现象，挑战了我们对深度学习的理解。尽管在理解 grokking 方面取得了重大进展，但延迟泛化及其对正则化的依赖背后的原因仍不清楚。在这项工作中，我们认为，如果没有正则化，grokking 任务会将模型推向数值稳定性的边缘，从而在 Softmax 函数中引入浮点错误，我们将其称为 Softmax Collapse (SC)。我们证明 SC 可以防止 grokking，而减轻 SC 可以在没有正则化的情况下实现 grokking。通过研究 SC 的根本原因，我们发现，在过度拟合点之后，梯度与我们所谓的朴素损失最小化 (NLM) 方向高度一致。梯度的这个部分不会改变模型的预测，但会通过缩放 logits（通常是通过沿其当前方向缩放权重）来减少损失。我们表明，这种对数的缩放解释了 grokking 的泛化延迟特征，并最终导致 SC，从而停止进一步的学习。为了验证我们的假设，我们引入了两个关键贡献来解决 grokking 任务中的挑战：StableMax，一种新的激活函数，可防止 SC 并允许 grokking 无需正则化，以及 ⊥Grad，一种通过完全防止 NLM 来促进 grokking 任务快速泛化的训练算法。这些贡献为 grokking 提供了新的见解，阐明了其延迟的泛化、对正则化的依赖以及现有 grokking 诱导方法的有效性。  论文：https://arxiv.org/abs/2501.04697 （不是我的论文，只是推荐给我的东西）   由    /u/JohnnyAppleReddit  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i34keg/grokking_at_the_edge_of_numerical_stability/</guid>
      <pubDate>Fri, 17 Jan 2025 01:06:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻找一位知识渊博的时间序列基础模型研究合著者</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i33y8v/r_seeking_a_knowledgeable_coauthor_for_time/</link>
      <description><![CDATA[您好， 我正在开展研究，计划提交给 AHLI 健康、推理和学习会议 (CHIL)（H5 指数 26，h5 中位数 43）。但是，提交截止日期即将到来——2 月 10 日。 我的导师建议添加其他教授作为合著者，但他们主要会审阅并提供反馈，而不是直接参与写作。因此，我想看看是否有任何精通时间序列基础模型的人有兴趣作为合著者进行合作。 这项研究涉及比较不同数据集中的时间序列基础模型。实验已接近完成，但我需要支持为每个模型编写理论基础。如果您具备必要的知识、时间，并且有兴趣为这项工作做出有意义的贡献，请给我发私信，以便我们进一步讨论这个机会。 谢谢！    提交人    /u/mrlucasrib   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i33y8v/r_seeking_a_knowledgeable_coauthor_for_time/</guid>
      <pubDate>Fri, 17 Jan 2025 00:35:46 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我编写了一个脚本来创建任意复杂程度的 GSM 问题。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i31dwr/p_i_made_a_script_to_create_gsm_problems_of_any/</link>
      <description><![CDATA[项目 github 链接 这是一个示例。 这是一个示例，它使用更简单的语言，用于测试是否是令人困惑的语言导致模型失败。 编辑：详细的帖子不断被删除。请提问，希望有人觉得这个工具有用。    提交人    /u/datta_sid   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i31dwr/p_i_made_a_script_to_create_gsm_problems_of_any/</guid>
      <pubDate>Thu, 16 Jan 2025 22:35:18 GMT</pubDate>
    </item>
    <item>
      <title>[R] 多模态思维可视化：通过视觉思维增强 MLLM 推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2q6t9/r_multimodal_visualizationofthought_enhancing/</link>
      <description><![CDATA[这里的关键创新是将大型语言模型与图像生成相结合，以创建一个可以在解决问题时“视觉思考”的系统。这种方法称为多模态思维可视化 (MVoT)，它在推理过程中生成相关的可视化效果，类似于人类绘制图表以更好地理解问题的方式。 主要技术要点： - 系统架构将 LLM 与图像生成模型集成以进行推理 - 使用空间语义对齐来确保生成的视觉效果与推理步骤相匹配 - 实现一个迭代过程，其中每个推理步骤都可以触发可视化 - 通过多模态思维链保持视觉和文本表示之间的一致性 结果： - 与基线​​方法相比，视觉推理基准提高了 12% - 在涉及空间关系的任务上表现特别出色 - 生成的可视化效果与推理步骤明显一致 - 适用于不同组合的语言和图像生成模型 我认为这种方法可以显著提高人工智能系统推理物理和空间问题的能力。通过将视觉思维融入推理过程，我们可能会看到人类通常通过可视化解决的任务（从物理问题到建筑设计）表现更好。然而，在推理过程中生成图像的计算开销可能会限制实际应用。 我认为最有趣的方面是它如何模仿人类的认知过程——我们经常通过素描或可视化来理解复杂的问题。这可能导致人工智能系统以更直观和可解释的方式进行推理。 TLDR：新方法将语言模型与图像生成相结合，以创建可以在推理时“进行视觉思考”的人工智能系统，在视觉推理任务上显示出 12% 的改进。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2q6t9/r_multimodal_visualizationofthought_enhancing/</guid>
      <pubDate>Thu, 16 Jan 2025 14:31:58 GMT</pubDate>
    </item>
    <item>
      <title>带有 MLP 混频器的 CIFAR 100。[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2nu5q/cifar_100_with_mlp_mixer_p/</link>
      <description><![CDATA[最近参加了一场黑客马拉松，任务是在不使用卷积和变换器模型的情况下实现高精度。尽管 mlp 混合器可以说与卷积相似，但它们是允许的。即使经过多次尝试，我也无法将准确率提高到 60% 以上。有没有办法用 mlp 或其他任何东西来达到 90% 左右的准确率。    提交人    /u/Abbe_Kya_Kar_Rha_Hai   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2nu5q/cifar_100_with_mlp_mixer_p/</guid>
      <pubDate>Thu, 16 Jan 2025 12:30:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 泰坦：一个新的开创性的建筑发展？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2l0ey/d_titans_a_new_seminal_architectural_development/</link>
      <description><![CDATA[对他们的工作的最初印象是什么？它能改变游戏规则吗？这能多快融入新产品？期待对话！    提交人    /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2l0ey/d_titans_a_new_seminal_architectural_development/</guid>
      <pubDate>Thu, 16 Jan 2025 09:12:27 GMT</pubDate>
    </item>
    <item>
      <title>对 NSFW 文本进行分类的最佳方法 - BERT、小型 LLM（如 llama 3.2 3B）还是其他？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i2h315/best_way_to_classify_nsfw_text_bert_small_llm/</link>
      <description><![CDATA[我正在做一个项目，需要将文本分类为 nsfw 或 sfw。我知道有一些基于 BERT 的分类器专门针对此类任务进行训练。我也见过有人使用较小的 LLM。 最好的方法是什么？由于检测 NSFW 文本的底层复杂性并不高，我认为也许全面的 LLM 有点过头了。你有什么建议？    提交人    /u/newyorkfuckingcity   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i2h315/best_way_to_classify_nsfw_text_bert_small_llm/</guid>
      <pubDate>Thu, 16 Jan 2025 04:38:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我如何发现并修复微软 Phi-4 模型中的 4 个错误</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1i23zbo/p_how_i_found_fixed_4_bugs_in_microsofts_phi4/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1i23zbo/p_how_i_found_fixed_4_bugs_in_microsofts_phi4/</guid>
      <pubDate>Wed, 15 Jan 2025 18:22:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hzprm8/d_simple_questions_thread/</guid>
      <pubDate>Sun, 12 Jan 2025 16:00:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 31 Dec 2024 03:30:14 GMT</pubDate>
    </item>
    </channel>
</rss>