<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 23 Dec 2024 01:16:55 GMT</lastBuildDate>
    <item>
      <title>自动生成分类类别 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hkc5d1/automated_generation_of_categories_for/</link>
      <description><![CDATA[因此，我可以使用 Bart 零样本分类来量化文章与预定义类别集的相关性，但我有很多文章，我想从中计算类别，然后使用这些类别对大量文章进行分类。 我想也许我可以使用文本嵌入将每篇文章转换为向量，然后使用无监督学习算法来计算相关文章的聚类，然后将这些组投影回文本，也许可以通过递归总结每个组中的文章来实现。但是，我实际上并不想要类别集必须不相交的约束，我认为 k-means 会施加这种约束。 还有什么其他方法可以实现这一点？    提交人    /u/PurpleUpbeat2820   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hkc5d1/automated_generation_of_categories_for/</guid>
      <pubDate>Mon, 23 Dec 2024 00:46:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 任意节点大小的图形自动编码器，如何解码？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk7lje/r_graph_autoencoder_of_arbitrary_node_size_how_to/</link>
      <description><![CDATA[嗨！希望你一切顺利  我正在构建一个能够为任意大小的图生成嵌入的图自动编码器。我读过的大多数文献都集中在固定大小的节点图上，这并不完全符合我的要求。我发现的唯一相关工作是“学习用于生成图的 Graphon 自动编码器”，但我找不到他们提出的模型的任何实现。 编码部分似乎相对简单 - 您可以将其设计为输出固定大小的嵌入，而不管图的大小如何。然而，解码部分要棘手得多：您将如何设计解码器来处理可变大小的图？这个想法在实际意义上是否有意义？它看起来很复杂，但这样的模型可能非常有用。 我很感激任何关于这方面的见解、参考或建议！ 提前致谢！    提交人    /u/galerazo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk7lje/r_graph_autoencoder_of_arbitrary_node_size_how_to/</guid>
      <pubDate>Sun, 22 Dec 2024 20:59:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 寻求改进 NL2SQL 模型性能的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk42na/r_looking_for_suggestions_to_improve_nl2sql_model/</link>
      <description><![CDATA[大家好， 我正在为 NL2SQL 任务微调一个大型语言模型。我尝试过 BERT 和 CodeBERT，但这两个模型的表现都不如预期。虽然我的目标是在测试中达到 90% 以上的准确率，但我能达到的最好成绩是 在看不见的测试集上达到 84%，但在训练和验证中确实达到了 90% 以上的准确率。 上下文：  数据集大小：我的数据集很大，因此数据可用性不是限制。 当前模型：我使用过 BERT 和 CodeBERT。 挑战：这两种模型都很难有效地概括。  问题：  有没有人推荐适用于 NL2SQL 的替代模型（例如，专门的架构或微调模型）？ 有什么建议可以专门提高 CodeBERT 的准确率吗？例如： 额外的微调技术。 模型架构更改。 更好概括的策略。   任何建议都将不胜感激！ （此外，我没有从事 SQL 生成工作，而是从事 SQL 评估工作）谢谢！    提交人    /u/Aggravating-Bend-343   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk42na/r_looking_for_suggestions_to_improve_nl2sql_model/</guid>
      <pubDate>Sun, 22 Dec 2024 18:10:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习中的协作好奇心？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk21kl/d_collaboration_curiosity_in_ml/</link>
      <description><![CDATA[我见过许多论文，其中 10/12/15 人进行了合作。 他们真的在从事这些项目吗？ 或者只有 2/3 的人在工作？ 它是如何工作的？其他作者的贡献是什么？ 我只是对这个过程很好奇    提交人    /u/Alarming-Camera-188   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk21kl/d_collaboration_curiosity_in_ml/</guid>
      <pubDate>Sun, 22 Dec 2024 16:35:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习/人工智能会议的相机就绪截止日期之后是否有一个全面的审查期？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hk1r03/r_is_there_a_comprehensive_review_period_after/</link>
      <description><![CDATA[我的作品已被 AAAI 接受，我最近提交了我的照相排版文件。我想知道是否存在另一个审查期，这会导致我的论文在会议前被拒绝。作者顺序没有改变，并且大多数（如果不是全部）审阅者的反馈都已添加。    提交人    /u/Enough_Home_7500   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hk1r03/r_is_there_a_comprehensive_review_period_after/</guid>
      <pubDate>Sun, 22 Dec 2024 16:21:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用引导树搜索提出和解决奥林匹克几何问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjyg9z/r_proposing_and_solving_olympiad_geometry_with/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjyg9z/r_proposing_and_solving_olympiad_geometry_with/</guid>
      <pubDate>Sun, 22 Dec 2024 13:25:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] LLM 微调：揭开 Huggingface Trainer 的神秘面纱 🚀</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjy2iw/p_llm_finetuning_demystifying_huggingface_trainer/</link>
      <description><![CDATA[        由    /u/themathstudent 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjy2iw/p_llm_finetuning_demystifying_huggingface_trainer/</guid>
      <pubDate>Sun, 22 Dec 2024 13:02:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调图像相似度模型（图像检索）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjxara/d_fine_tuning_a_model_for_image_similarity_image/</link>
      <description><![CDATA[嗨， 2020 年不久前，我使用深度度量学习对 CNN 进行了微调，使用的数据集包含 600 个类别的 100 万张图像。 我现在面临类似的问题，我需要一个模型来返回特定类型对象的语义相似图像。 我有大约 50 万张这些对象的图像，还可以获得更多。 我的问题是我没有明确定义的&quot;类&quot;，我有一些文本，我可以从中提取一些可以用作类的特征。 CLIP 似乎是一种可能性，但由于它非常重且 GPU 成本高昂，我想探索其他选项。 你们有人尝试过一些更复杂的程序吗？或者使用增强数据进行图像相似性工作？   由    /u/TechySpecky  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjxara/d_fine_tuning_a_model_for_image_similarity_image/</guid>
      <pubDate>Sun, 22 Dec 2024 12:09:55 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 精细调节 SDM 的消融研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjwn2h/dr_ablation_studies_on_fine_tuned_sdm/</link>
      <description><![CDATA[有一个稳定的扩散模型，可以在 COCO 图像上进行微调。它以这种方式进行微调： 如果图像包含各种对象（例如 obj1、obj2 等），我们会以这种方式构建提示：“&lt;obj1&gt; 和 &lt;obj2&gt; 以及 &lt;obj3&gt; 的照片...... 等等”。 我们将此提示与图像一起传递以进行微调。请注意，如果图像由同一类别的各种对象组成，我们不会在提示中重复该类别。 例如：如果图像包含狗、猫、香蕉、熊和树，则提示将如下所示：“一张狗、猫、香蕉、熊和树的照片”。 现在，我想通过更改提示模板并观察图像质量的变化来对该模型进行消融研究。 请注意，该模型用于生成图像和边界框，现在它充当数据集合成器。我们给出一个只有 2 个类别的提示。例如：“一张椅子和人的照片”。生成的数据集与原始 coco 数据集一起使用，然后我们在该组合数据上训练图像识别模型，并注意图像识别器的性能是否有所改善。 告诉我可以使用哪些提示模板来进行消融研究。    提交人    /u/maaKaBharosaa   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjwn2h/dr_ablation_studies_on_fine_tuned_sdm/</guid>
      <pubDate>Sun, 22 Dec 2024 11:20:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] DETR 中的位置嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjvrfa/d_positional_embedding_in_detr/</link>
      <description><![CDATA[ViT 和 DETR 都依赖于变压器架构来完成其特定任务。 ViT 仅使用编码器进行分类，而 DETR 同时使用编码器和解码器进行对象检测。 在 ViT 中，位置嵌入在输入到编码器之前添加到输入中。然后，编码器重复处理输入并输出结果。 在 DETR 中，位置嵌入在编码器处理过程中被重复添加到输入中。本文没有明确讨论这一点，但我检查了它们的实现。 我的问题是：我不确定重复添加位置嵌入与仅添加一次有什么区别？    提交人    /u/JicamaNormal927   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjvrfa/d_positional_embedding_in_detr/</guid>
      <pubDate>Sun, 22 Dec 2024 10:10:49 GMT</pubDate>
    </item>
    <item>
      <title>多模式文档转 Markdown [R][P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjsh1h/multimodal_documents_to_markdown_rp/</link>
      <description><![CDATA[目前正在使用多模式 PDF。这些 PDF 将具有文本、OCR 文本、手写笔记、表格、图表、注释等的任意组合。我们必须将其转换为易于搜索的 Markdown，以供多模式 RAG 使用。是否有任何工具/库适合这种用例？需要一些可以快速处理文档的东西。 我见过的许多库的问题是，它们要求您自己明确调用 OCR/其他功能页面。这不起作用，因为输入将包含任意组合（一个页面甚至可能包含多种类型的输入），所以我们无法预编程。到目前为止，最好的方法是使用 VLM 来执行此操作（如果您有任何关于优质 VLM 的推荐，请告诉我）。 感谢您的任何推荐。   由    /u/ISeeThings404  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjsh1h/multimodal_documents_to_markdown_rp/</guid>
      <pubDate>Sun, 22 Dec 2024 05:54:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjq0bm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 22 Dec 2024 03:15:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我在 NeurIPS’24 上感受到了焦虑和沮丧（kyunghyuncho 博客）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjp5gc/d_i_sensed_anxiety_and_frustration_at_neurips24/</guid>
      <pubDate>Sun, 22 Dec 2024 02:22:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们最容易误解哪些机器学习概念？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</link>
      <description><![CDATA[我注意到某些 ML 概念（例如偏差-方差权衡或正则化）经常被误解。您认为哪个 ML 主题经常被误解，您如何向其他人解释它？    提交人    /u/AdHappy16   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hjiana/d_what_ml_concepts_do_people_misunderstand_the/</guid>
      <pubDate>Sat, 21 Dec 2024 20:22:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>