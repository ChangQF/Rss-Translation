<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 28 Dec 2023 15:13:05 GMT</lastBuildDate>
    <item>
      <title>[D] LLaMA 2 无法工作，名为 fire 的模块未找到可能是问题所在吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sv3cp/d_llama_2_not_working_could_module_named_fire_not/</link>
      <description><![CDATA[嗨，我对 elms 相当陌生，想在没有任何 webuis 或其他东西的情况下尝试原始 llama，我做了所有写在metaai 的存储库以及使用  torchrun --nproc_per_node 2 example_chat_completion.py \ --ckpt_dir llama-2-13b-chat/ \  启动模型时--tokenizer_path tokenizer.model \ --max_seq_len 512 --max_batch_size 6 我遇到了“注意：Windows 或 MacO 中目前不支持重定向”的问题。 警告：torch.distributed.run： ******************************** ********** 将每个进程的OMP_NUM_THREADS环境变量默认设置为1，以避免您的系统过载，请根据需要进一步调整该变量以获得应用程序的最佳性能. ************************************************&lt; /p&gt; 回溯（最近一次调用）： 文件“/Users/filipbartczak/llama/example_chat_completion.py”，第 6 行，位于  导入 fire ModuleNotFoundError：没有名为“fire”的模块 回溯（最近一次调用）： 文件“/Users/filipbartczak/llama/ example_chat_completion.py”，第 6 行，位于  import fire ModuleNotFoundError：没有名为“fire”的模块 错误：torch.distributed。 elastic.multiprocessing.api：失败（退出代码：1）local_rank：0（pid：6267）二进制文件：/opt/homebrew/opt/python@3.10/ bin/python3.10 回溯（最近一次调用最后一次）： 文件“/opt/homebrew/bin/torchrun”，第 8 行，在  sys.exit(main()) 文件“/opt/homebrew/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__”。 py”，第 346 行，包装器 return f(*args, **kwargs) 文件“/opt/homebrew/lib/python3.10/site-packages/ torch/distributed/run.py”，第 794 行，在 main run(args) 文件“/opt/homebrew/lib/python3.10/site-packages/ torch/distributed/run.py”，第 785 行，运行中 elastic_launch( 文件“/opt/homebrew/lib/python3.10/site-packages/torch/ “distributed/launcher/api.py”，第 134 行，在 __call__ 中 return launch_agent(self._config, self._entrypoint, list(args)) 文件“/opt/ homebrew/lib/python3.10/site-packages/torch/distributed/launcher/api.py”，第 250 行，在 launch_agent raise ChildFailedError( torch.distributed.elastic .multiprocessing.errors.ChildFailedError：  example_chat_completion.py失败 ----------------- ------------------------------------------------------ 失败： [1]： 时间：2023-12-28_06:18:46 主持人：mbp-filip.home rank：1（local_rank：1） 退出代码：1（pid：6268） error_file： traceback：启用回溯请参阅：https://pytorch.org/docs/stable/elastic/errors.html -------------------------------------------------------- --------------- 根本原因（第一次观察到的故障）： [0]： 时间： 2023-12-28_06:18:46 主机：mbp-filip.home 排名：0（local_rank：0） 退出代码：1（pid : 6267) error_file:  traceback ：要启用回溯，请参阅：https://pytorch.org/docs/stable/elastic/errors.html ================ ==============================================&quot; 我们将不胜感激！   由   提交 /u/Fearless-Chapter1413    reddit.com/r/MachineLearning/comments/18sv3cp/d_llama_2_not_working_could_module_named_fire_not/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sv3cp/d_llama_2_not_working_could_module_named_fire_not/</guid>
      <pubDate>Thu, 28 Dec 2023 14:24:44 GMT</pubDate>
    </item>
    <item>
      <title>[R]可解释强化学习研究综合概述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18suecx/r_comprehensive_overview_of_explainable/</link>
      <description><![CDATA[您好，我在  上概述了可解释的强化学习研究https://github.com/yanzheb/xrl。我计划保持这个存储库最新并不断添加新论文。希望你觉得它有用。欢迎任何反馈。   由   提交/u/peppercat-2c4t9  /u/peppercat-2c4t9 reddit.com/r/MachineLearning/comments/18suecx/r_compressive_overview_of_explainable/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18suecx/r_comprehensive_overview_of_explainable/</guid>
      <pubDate>Thu, 28 Dec 2023 13:52:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于文本生成模型的主动学习管道。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18su3p3/r_active_learning_pipeline_for_text_generation/</link>
      <description><![CDATA[我之前曾使用小文本为分类模型构建主动学习管道。现在，小文本使用受模型不确定性（低置信度）约束的算法来从数据集中挑选最佳示例进行训练，这在文本生成的情况下不起作用，因为您需要大量潜在的下一个单词使一代人多样化的候选人。因此，不确定的分数并不一定意味着需要标记的考试。  所以我目前迷失在洗牌中，不知道如何继续。我的目标是使用“rouge-score”进行主动学习适用于 T5 或 Flan-T5 型号。是否有任何库或博客可以帮助构建像小文本那样的管道？   由   提交/u/cedar_mountain_sea28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18su3p3/r_active_learning_pipeline_for_text_generation/</guid>
      <pubDate>Thu, 28 Dec 2023 13:37:57 GMT</pubDate>
    </item>
    <item>
      <title>翻译模型[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sttmj/translation_model_d/</link>
      <description><![CDATA[我正在寻找阿拉伯语到英语的预训练模型？ [D]   由   提交 /u/Kachikairi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sttmj/translation_model_d/</guid>
      <pubDate>Thu, 28 Dec 2023 13:23:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] Deepfake口型同步云软件。需要建议。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18stnvi/r_deepfake_lip_syncing_cloud_software_advice/</link>
      <description><![CDATA[Reddit 社区您好。 一年前，我对视频操作制作（特别是口型同步）非常着迷，因为它似乎是编辑视频、创建内容等的新奇方式……确实有无限的可能性，因为互联网视频和互联网娱乐很可能永远不会用完。我知道视频操纵由于不道德的创作而名声相对较差，但由于语言差异，它确实有很好的应用程序，可以用来更好地连接世界 - 内容、电影、影响者、应用程序、广告。 我决定创建一个软件，可以实现逼真的口型同步 - lipsynthesis.com 它是云托管应用程序，允许用户处理（文本到语音）到视频）自定义文本视频。 几个月前我完成了它，得到了很多用户，并且 200 名订阅者中获得了 0 退款 - 看起来人们喜欢它（没有付费广告）。这是我的业余爱好项目，目标是真正提高人们的认识 - 我们为新闻频道（最近 CNN 关于 2024 年选举和 Deepfake，视频将于 1 月上线）、影响者、公共演讲者和学校（在教室中展示）制作了多个视频用于教育目的）。 以下是一个展示其威力的示例： https://www.youtube.com/watch?v=3wVpVH0Wa6E 我目前正在训练 5000 小时训练数据集的模型，以进一步改进口型同步，以获得更准确的口型同步。使用新同步网络和基础模型的初步测试显示，在各个方面都有惊人的改进 - 口型同步的准确性、蒙版的质量以及即使是相当复杂的语言（例如普通话）口型同步的强大能力。 截至目前，人工智能经过训练的模型尚未收到许多法规。我相信监管人工智能的时代很快就会到来。这就是为什么我寻求其他人的建议。 我应该向何处前进？如前所述，最初的想法是提高人们对深度造假技术的认识。但就商业而言，这不会是一个长途的事情。 我的想法是： -娱乐方法：创建一个不和谐/公共社区，每个人每月支付固定费用，并且可以以相同的价格生成任意数量的视频。正如当今许多软件公司所做的那样。 -商业方法：专业软件，允许公司通过口型同步将其视频广告、应用程序翻译成多种语言。 什么你们觉得呢？   由   提交 /u/Da_Roxy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18stnvi/r_deepfake_lip_syncing_cloud_software_advice/</guid>
      <pubDate>Thu, 28 Dec 2023 13:15:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 有兴趣构建 Kannada-GPT 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18stltt/p_interested_in_building_kannadagpt/</link>
      <description><![CDATA[嘿伙计们， 现在我们正处于培训不同语言的法学硕士的时代，人们正在跨领域进行培训在全球范围内，我想看看是否有人有兴趣对卡纳达语（南印度语言）做同样的事情？如果有人有兴趣合作，请告诉我。另外，如果也正在进行同样的努力，请告诉我，我很高兴在这方面进行合作。  干杯！   由   提交/u/perceptron333  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18stltt/p_interested_in_building_kannadagpt/</guid>
      <pubDate>Thu, 28 Dec 2023 13:12:16 GMT</pubDate>
    </item>
    <item>
      <title>[R] 开源法学硕士在代码编辑方面与 OpenAI 相去甚远</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18st9wa/r_open_source_llms_are_far_from_openai_for_code/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2312.12450  标题：可以编辑吗？评估大型语言模型遵循代码编辑指令的能力 代码存储库：https://github.com/nuprl/ CanItEdit 摘要：  大量研究集中在开发和评估用于各种代码合成任务的大型语言模型。其中包括从自然语言指令合成代码、从代码合成测试以及合成代码解释。相比之下，法学硕士的教学代码编辑行为尚未得到充分研究。在这些任务中，模型被指示更新提示中提供的代码块。编辑指令可能会要求添加或删除功能、描述错误并要求修复、要求不同类型的解决方案或许多其他常见的代码编辑任务。我们引入了精心设计的代码编辑任务基准，并用它评估了几个前沿的法学硕士。我们的评估揭示了最先进的开放模型和封闭模型的能力之间的巨大差距。例如，即使是 GPT-3.5-Turbo 在编辑代码方面也比最好的开放模型好 8.8%。我们还引入了一套新的、精心策划的、经过许可的代码编辑训练集以及自然语言指令。使用这个训练集，我们表明我们可以微调开放代码法学硕士，以显着提高他们的代码编辑能力。  讨论： 我正在分享这篇论文开始讨论。免责声明：本文来自我们的研究小组，但无意在此进行自我推销。我们看到，在程序综合评估中，开源代码 LLM 慢慢地越来越接近 GPT-4 的性能，并超越了 GPT-3.5-turbo（请参阅 DeepSeek Coder：https://github.com/deepseek-ai/DeepSeek-Coder) 当使用常见基准测试时，例如 HumanEval、MBPP 和 *新* LeetCode 问题（这是为了最大限度地减少污染）。 但是，这不是您想要的方式。通常，需要修改一段带有自然语言指令的代码（例如，Cursor IDE 已经从 GitHub Copilot 风格转变为仅专注于代码编辑：https://cursor.sh/features）。此外，通过代码编辑训练的模型可以实现简单的代码生成，可以通过在窗口前用空白提示模型来将其视为代码编辑的子集。 在我们的各种研究项目中，我们已经看到代码法学硕士在代码编辑方面遇到了困难。所以我们做了显而易见的事情，我们检查了这些模型在这个特定任务中的表现。令人惊讶的是，与 GPT-3.5-turbo 相比，在简单合成方面表现出色的模型在代码编辑方面却表现不佳。 为什么会出现这种情况？虽然有些人认为存在数据污染，但考虑到这些模型在新的和未见过的基准上的有效性，我怀疑这是主要因素。难道 OpenAI 专门为代码或语言编辑等任务提供了特定的数据子集（然后将模型推广为代码）？   由   提交/u/ellev3n11   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18st9wa/r_open_source_llms_are_far_from_openai_for_code/</guid>
      <pubDate>Thu, 28 Dec 2023 12:54:58 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 WhisperModel 像 SpreedSheet 一样编辑视频</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18st2s1/p_edit_your_videos_like_spreedsheet_using/</link>
      <description><![CDATA[ML 社区您好，我很乐意与您分享 Hugging Face 中的一个演示应用程序，我在其中使用 WhisperModel 提取脚本，然后通过以下方式编辑视频修改脚本内容。您可以删除不需要的单词，例如“AMMM”、“AAA”等。 注意：不要在脚本中添加任何内容；您所要做的就是删除。 这是提高我的机器学习技能的一部分。您可以克隆代码并自行测试。 Hugging Face Space：[ https://huggingface.co/spaces/otmanheddouch/edit-video-like-sheet] GitHub 存储库：[https://github.com/otman-ai/edit-video-like-sheet] 尝试一下并告诉我什么你认为！   由   提交 /u/AvocadoRelevant5162   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18st2s1/p_edit_your_videos_like_spreedsheet_using/</guid>
      <pubDate>Thu, 28 Dec 2023 12:44:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] CART 决策树和随机森林中的小偏差</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ss4ko/r_a_small_bias_in_cart_decision_trees_and_random/</link>
      <description><![CDATA[决策树和随机森林对于属性的缩放是不变的。有趣的是，它们对于属性的镜像（即乘以 -1）并不是不变的。准确地说，如果存在可能取与二叉 CART 树中的阈值一致的值的特征，则该特征的镜像会导致推理时间的偏差。这并不是一个很大的偏差，但是可以达到r2和AUC的0.1-0.2个百分点左右。 好的一点是，在随机森林的情况下，这个偏差基本上可以消除。通过在大约一半的树中使用轴镜像扩展 boostrap 采样来降低成本。 我们相应的论文中提供了更多示例和定量评估：[2312.10708] 二元决策树和随机森林中的条件偏差及其消除 (arxiv.org)  您认为值得为 sklearn 准备 PR随机森林、R 树，或者更确切地说，发布一个带有随机森林的非常小的包，以消除这种偏差？欢迎任何评论！ ​   由   提交 /u/gykovacs   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ss4ko/r_a_small_bias_in_cart_decision_trees_and_random/</guid>
      <pubDate>Thu, 28 Dec 2023 11:49:15 GMT</pubDate>
    </item>
    <item>
      <title>树林中的森林——人工智能年的收获 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sjtmo/the_forest_amidst_the_trees_the_takeaway_from_our/</link>
      <description><![CDATA[2023 年将是有意义的一年，也许是书写人工智能历史的最有意义的一年之一。从本质上讲，这是一次大爆炸。  它始于 2022 年底，OpenAI 的 ChatGPT 但它的响应是如此令人惊叹。几个月内，我们就拥有了 Meta 的 LLaMA 2，Google 的 吟游诗人 聊天机器人在今年晚些时候推出了 Gemini，Anthropic 的 克劳德等人。专有和开源之间的斗争愈演愈烈，甚至强大的谷歌得出结论：找不到护城河。我们认为这有利于开源。  https://blog.min.io/the-forest-amid-the-trees-the-takeaway-from-our-ai-year/?utm_source=reddit&amp;utm_medium =organic-social+&amp;utm_campaign=forest_amid_trees_ai_year   由   提交 /u/swodtke   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sjtmo/the_forest_amidst_the_trees_the_takeaway_from_our/</guid>
      <pubDate>Thu, 28 Dec 2023 03:27:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] torch.odeint（ODE求解器）执行速度慢的解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18sed9l/d_solution_to_slow_execution_speed_of_torchodeint/</link>
      <description><![CDATA[当我在神经常微分方程上运行 torch 优化时，我发现 torch.odeint （此处存储库：rtqichen/torchdiffeq：具有完全 GPU 支持和 O(1) 内存反向传播的可微分 ODE 求解器。(github.com)）非常慢。它会占用单个 CPU 核心 100% 的资源，使其余核心和大部分 GPU 闲置。事实上，似乎并没有太多并行性。 并行 ODE 求解器确实存在，但它们并不是很出名。有人知道任何可以帮助提高 torch.odeint 性能的建议吗？ ​   由   提交 /u/speedy-spade   /u/speedy-spade  reddit.com/r/MachineLearning/comments/18sed9l/d_solution_to_slow_execution_speed_of_torchodeint/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18sed9l/d_solution_to_slow_execution_speed_of_torchodeint/</guid>
      <pubDate>Wed, 27 Dec 2023 23:19:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 未经训练的卷积神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s9l3j/d_untrained_convolutional_neural_networks/</link>
      <description><![CDATA[根据标题，我正在探索一个利基主题：使用未经训练的卷积神经网络 (CNN) 作为特征提取器。现有的研究已经证明，即使没有训练，CNN 仍然可以从数据中捕获一些有意义的特征。 因此，我对任何专注于提高未经训练的 CNN 特征提取能力的方法的论文或研究感兴趣，或者探索替代（无需训练）的方法。 目前，我能够找到研究未经训练的 CNN 效率的论文  [1] [2] 或使用它们作为特征提取器的[3] [4] 具体任务和架构。然而，这些论文中没有一篇试图深入研究无需传统的基于梯度的优化即可增强提取特征的方法。 有关此主题的任何共享资源或指导将不胜感激。预先感谢您！   由   提交 /u/RussB3ar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s9l3j/d_untrained_convolutional_neural_networks/</guid>
      <pubDate>Wed, 27 Dec 2023 19:58:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我从头开始制作了一个教育自动毕业</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18s0adx/p_i_made_an_educational_autograd_from_scratch/</link>
      <description><![CDATA[学习机器学习，我一直对 PyTorch 及其 Autograd 引擎感兴趣。  在这个项目中，我尝试重新实现 PyTorch 的大部分&lt; /strong&gt;（包括 Autograd）以记录完善、单元测试且可解释的方式从头开始。它对我来说非常有用，我希望它也能帮助您更好地了解 Autograd！  希望您喜欢！  GitHub 存储库此处！   由   提交 /u/suspicious_beam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18s0adx/p_i_made_an_educational_autograd_from_scratch/</guid>
      <pubDate>Wed, 27 Dec 2023 13:06:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 MoE 模型仅针对前馈层？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18rzygz/d_why_moe_models_target_only_feedforward_layers/</link>
      <description><![CDATA[所以我看到 Mixtral 8x7b 只有 45B 参数，而不是 56B (src https://huggingface.co/blog/mixtral），因为 MoE 仅适用于前馈层，不适用于注意力层。为什么会这样呢？我相信肯定有研究将MoE应用于注意力层，但为什么没有使用呢？是不是没有提高性能什么的，MoE 在注意力层上有什么帮助的任务吗？   由   提交/u/vincent163  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18rzygz/d_why_moe_models_target_only_feedforward_layers/</guid>
      <pubDate>Wed, 27 Dec 2023 12:48:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>