<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 26 Nov 2024 21:16:22 GMT</lastBuildDate>
    <item>
      <title>Tensorflow 模型问题“[P]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0kk0t/tensorflow_models_problem_p/</link>
      <description><![CDATA[大家好！我正在尝试按照本教程制作一个小型手语检测模型：https://www.youtube.com/watch?v=pDXdlXlaCco&amp;t=1400s&amp;ab_channel=NicholasRenotte 就在训练部分之前我遇到了困难，我从 github 中提取了 tensorflow 模型并从&quot;没有名为 compat 的模块&quot;开始cython-pyyaml 兼容性问题的错误我遇到了所有问题，我尝试了 python（3.9-12）及其相应的 tensorflow 版本的所有组合，但仍然出现此类错误。 现在我再次尝试了 python 3.11 和 tf 2.18.0，这是我得到的错误： 回溯（最近一次调用最后一次）： 文件“E:\tryit\tensorflow\Tensorflow\models\research\object_detection\model_main_tf2.py”，第 31 行，在&lt;module&gt; 从 object_detection 导入 model_lib_v2 ModuleNotFoundError：没有名为“object_detection”的模块 对于此问题的解决方案或 tensorflow 的任何替代方案，我们将不胜感激。 （只是一名工程专业的学生试图完成他的项目，谢谢）    提交人    /u/wolfmanwulf   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0kk0t/tensorflow_models_problem_p/</guid>
      <pubDate>Tue, 26 Nov 2024 19:34:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 修剪（通道 + 层） + 蒸馏或仅蒸馏</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0kcgn/d_prune_channel_layers_distillation_or_just/</link>
      <description><![CDATA[假设我想让我的模型更小。 有一篇论文说蒸馏很好，但需要很长时间https://arxiv.org/abs/2106.05237 还有一篇论文说修剪 + 蒸馏效果很好：https://arxiv.org/abs/2407.14679 现在，我的问题是：有没有比较修剪 + 蒸馏与从头开始蒸馏的工作？    提交人    /u/osamc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0kcgn/d_prune_channel_layers_distillation_or_just/</guid>
      <pubDate>Tue, 26 Nov 2024 19:25:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 有人知道如何使用自动编码器减少嵌入的维度吗？如果你有相关的博客，请发给我</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0j77v/p_does_anyone_know_how_to_reduce_the_dimensions/</link>
      <description><![CDATA[      https://preview.redd.it/3cub8uc9ja3e1.png?width=766&amp;format=png&amp;auto=webp&amp;s=0a824d6ae516ff699cb880d8e998ace85354a50f    提交人    /u/GellertGrindelwald_1   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0j77v/p_does_anyone_know_how_to_reduce_the_dimensions/</guid>
      <pubDate>Tue, 26 Nov 2024 18:39:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一篇解释稀疏变换器的博客文章（原始论文）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0gl2j/d_a_blog_post_explaining_sparse_transformers_the/</link>
      <description><![CDATA[嗨！ 如果在此 subreddit 上发布此类帖子不合适，我很抱歉。我确实不会在此 subreddit 上发布此类帖子，但我一直看到文章或视频或任何内容在解释 GPT-3 时没有深入研究稀疏变压器。这让我很沮丧，因为论文中他们清楚地说“我们在变压器的各层中使用交替的密集和局部带状稀疏注意力模式，类似于稀疏变压器”。 但似乎没有人关心解释它们。老实说，我理解为什么，但看到所有这些文章、项目、视频等试图解释有关 GPT 的所有内容，甚至没有提到稀疏变压器部分，这令人沮丧。除了 GPT-3 特有的许多其他元素或 ML 中可重复性的通用元素之外，稀疏变换器部分甚至对 GPT-3 的原型设计也造成了很大的影响。 当我试图理解某件事时，我有写下东西的习惯，所以我写了一篇关于稀疏变换器的博客文章。从来没有谈论过它，因为我这样做是为了重组我的想法并作为我的笔记。因此，我不会建议任何人阅读它，我确信它充满了错别字，我的写作风格也不整洁等等。这只是我为自己做的事情，我会理解并在浏览时恢复丢失的信息。 无论如何，如果你自己阅读论文并试图从中构建知识，也许我的笔记可以帮助你：https://reinforcedknowledge.com/sparse-transformers/ 如果这篇文章不合适并且喋喋不休，我再次抱歉。 （如果您碰巧阅读它或者您发现任何错误，请随时指出它们，我很感激从中学习）    提交人    /u/ReinforcedKnowledge   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0gl2j/d_a_blog_post_explaining_sparse_transformers_the/</guid>
      <pubDate>Tue, 26 Nov 2024 16:55:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 公司对音频和语音处理中的哪些问题感兴趣？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h082e6/d_what_are_some_problems_in_audio_and_speech/</link>
      <description><![CDATA[我刚刚获得计算机科学学士学位，对音频和机器学习非常感兴趣，想做一个具有商业范围的项目。公司会对哪些问题陈述感兴趣？尤其是与人工智能相关的     提交人    /u/Personal_Equal7989   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h082e6/d_what_are_some_problems_in_audio_and_speech/</guid>
      <pubDate>Tue, 26 Nov 2024 09:36:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 毕业于麻省理工学院，获得机器学习博士学位 | 教你如何从零开始构建整个法学硕士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h07crj/d_graduated_from_mit_with_a_phd_in_ml_teaching/</link>
      <description><![CDATA[      https://preview.redd.it/e7xcen4lk73e1.png?width=2076&amp;format=png&amp;auto=webp&amp;s=630c464152c2c78297c288bb4a99c37c0b3baecb 每个人都与 ChatGPT 互动。但是你能从头开始构建它吗？ 我于 2022 年获得麻省理工学院机器学习博士学位。 然后发现了我对从头开始教授机器学习的热情。 3 个月前，我开始了一个项目，教授“如何从头开始构建大型语言模型”，没有任何库！ 目标是让学生和行业专业人士掌握大型语言模型和 ChatGPT 的构建块。 结果是一个大型项目，其中包含 15 个视频，涵盖了有关大型语言模型的所有内容。我已经将所有视频上传到 Youtube 上。 讲座 1：从头开始构建 LLM：系列介绍：https://youtu.be/Xpr8D6LeAtw 讲座 2：大型语言模型 (LLM) 基础知识：https://youtu.be/3dWzNZXA8DY 讲座 3：预训练 LLM 与微调 LLM https://youtu.be/-bsa3fCNGg4 讲座 4：什么是 transformer？  https://youtu.be/NLn4eetGmf8 讲座 5： GPT-3 究竟是如何工作的？  https://youtu.be/xbaYCf2FHSY 讲座 6：从 Scratch 构建 LLM 的阶段  https://youtu.be/z9fgKz1Drlc 讲座 7：使用 Python 从 Scratch 编写 LLM Tokenizer  https://youtu.be/rsy5Ragmso8 讲座 8：GPT Tokenizer：字节对编码  https://youtu.be/fKd8s29e-l4 讲座 9：使用 Python DataLoader 创建输入-目标数据对 https://youtu.be/iQZFH8dr2yI 讲座 10：什么是标记嵌入？  https://youtu.be/ghCSGRgVB_o 讲座 11：位置嵌入的重要性 https://youtu.be/ufrPLpKnapU 讲座 12：大型语言模型 (LLM) 的整个数据预处理管道 https://youtu.be/mk-6cFebjis 讲座 13：大型语言模型 (LLM) 中的注意力机制简介 https://youtu.be/XN7sevVxyUM 讲座 14：简化的注意力机制 - 用 Python 从头开始​​编码 | 没有可训练的权重  https://youtu.be/eSRhpYLerw4 讲座 15：使用键、查询和值矩阵编码自我注意力机制  https://youtu.be/UjdRN80c6p8 我花了很多时间和精力来制作这些讲座。  我将所有内容都展示在白板上，然后通过 Python 代码进行展示。 没有任何假设。一切都已拼写出来。    提交人    /u/OtherRaisin3426   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h07crj/d_graduated_from_mit_with_a_phd_in_ml_teaching/</guid>
      <pubDate>Tue, 26 Nov 2024 08:41:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我报名参加 Hackathon 是不是太傻了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h01hfn/d_am_i_a_complete_idiot_for_signing_up_for_a/</link>
      <description><![CDATA[好吧，我是一名通信科学研究生，我选择的学习领域是道德人工智能。 我非常想参加这次人工智能会议，因为有一些演讲者我很钦佩。但我买不起通行证，所以我决定申请参加学生黑客马拉松，因为如果被录取，你就可以免费通行。 对我来说，申请就像是孤注一掷，但我认为这也是一个与他人一起学习的好机会。 我被录取了……我非常兴奋。但现在我想，哦，等等，我会不会因为我不会编程而惹恼我的队友？ 有什么建议吗？一周后有一个准备网络研讨会，我一直在上一些概述课，这样我就可以学习术语/基础知识。申请还要求我说明我的编码经验水平，我检查了一下：无。但还是被录取了……所以我希望组织者认为我仍然可以做出有价值的贡献？ 请告诉我你的想法 🥲    提交人    /u/sydj_k941   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h01hfn/d_am_i_a_complete_idiot_for_signing_up_for_a/</guid>
      <pubDate>Tue, 26 Nov 2024 02:44:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 采用优化器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h01cqq/d_adopt_optimizer/</link>
      <description><![CDATA[你们有人尝试过新的 ADOPT 优化器吗？效果怎么样？我有点好奇，但还没有机会尝试一下。    提交人    /u/neu_jose   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h01cqq/d_adopt_optimizer/</guid>
      <pubDate>Tue, 26 Nov 2024 02:37:39 GMT</pubDate>
    </item>
    <item>
      <title>动态表和标准变量表“[项目]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h00o51/dynamic_table_and_standard_variable_table_project/</link>
      <description><![CDATA[你们在随机森林模型中使用多个表时有最佳实践吗？ 例如： 使用随机森林模型确定我今天吃的食物是否会导致我胃病 因为我是否会胃痛取决于比我吃的食物的不变属性更多的因素。也会取决于每次观察的变化因素 1.我正在集思广益的模型将具有一组标准且不变的变量（在此示例中，我将使用食物及其特征），就像在食物及其属性的表中一样，即 食物名称：热狗，卡路里：135，肉：是 食物名称：素食狗，卡路里：35，肉：否  第二张表将是一个动态表  第 1 天（唯一 ID），睡眠良好：否，喝水：否 这是一个非常粗略的示例，但为了说明这两个表都需要在我的 Python 脚本中考虑，并将其作为 CSV 加载到数据框中。 我不确定随机森林如何考虑静态因素和动态因素。它们会合并在 Day# 或唯一 ID 上吗？    提交人    /u/peyott100   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h00o51/dynamic_table_and_standard_variable_table_project/</guid>
      <pubDate>Tue, 26 Nov 2024 02:04:12 GMT</pubDate>
    </item>
    <item>
      <title>[D]对于 Gretel.ai 或 Mostly AI 等合成数据平台的看法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzsqwu/dthoughts_on_synthetic_data_platforms_like/</link>
      <description><![CDATA[这里有人用过 Gretel.ai 或 Mostly AI 这样的平台吗？• 您喜欢或不喜欢什么？• 您的用例的合成数据质量如何？ 我正在探索各种选择，希望能得到您的见解。谢谢！    提交人    /u/Value-Forsaken   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzsqwu/dthoughts_on_synthetic_data_platforms_like/</guid>
      <pubDate>Mon, 25 Nov 2024 20:20:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 现代神经网络架构（带有规范化）是否会使初始化变得不那么重要？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzq63h/d_do_modern_neural_network_architectures_with/</link>
      <description><![CDATA[随着现代神经网络架构中广泛采用规范化技术（例如批量规范、层规范、权重规范），我想知道：初始化现在有多重要？现代架构是否足够强大以克服不良初始化，或者是否存在谨慎初始化至关重要的情况？分享您的经验和见解！    提交人    /u/NumberGenerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzq63h/d_do_modern_neural_network_architectures_with/</guid>
      <pubDate>Mon, 25 Nov 2024 18:37:08 GMT</pubDate>
    </item>
    <item>
      <title>[项目] Claude Francois - 让 AI 以 François Chollet 的风格审查你的代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzmk5n/project_claude_francois_let_an_ai_review_your/</link>
      <description><![CDATA[演示在此处：https://claude-francois.crossingminds.com 在最近的 Anthropic Builder Day 黑客马拉松上，我们（Crossing Minds）构建了“Claude François”，一个以 Keras 的创建者 François Chollet 风格进行训练的 AI 代码审查员。它改编了 Anthropic 的 Claude 3.5 Sonnet 进行代码审查，但我们没有进行常规微调，而是使用少量上下文学习和我们的自定义 RAG 检索模型，该模型在 Keras 项目的 PR 上进行训练。与典型的 AI 代码审查者相比，它提供了更简洁、高质量的代码审查，专注于真正的问题而不是肤浅的吹毛求疵。 工作原理：  数据集：在公共 Keras GitHub PR 和 François 的评论数据库上进行训练。 微调的 RAG 嵌入：使用主动学习和 RLAIF 来训练优化为生成“fchollet 级”的嵌入审查。 改进的检索：不仅通过嵌入相似性来检索相关示例，而且通过优化相互信息来检索相关示例。 自我反思：采用自我反思技术来增强 Sonnet 的推理能力。  此技术演示展示了 Crossing Minds 的 RAGSys ICL 如何实现域自适应而无需微调。除了代码审查之外，它还可以用于无数其他用例，例如分类、摘要、翻译、搜索、推荐等。 Arxiv 论文即将发布！ 立即尝试：https://claude-francois.crossingminds.com 我们很乐意听到您的反馈！    提交人    /u/Crossing_Minds   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzmk5n/project_claude_francois_let_an_ai_review_your/</guid>
      <pubDate>Mon, 25 Nov 2024 16:16:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] Aurora：用于地球系统预测的通用基础模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gzj8rs/r_aurora_a_generalpurpose_foundation_model_for/</link>
      <description><![CDATA[这里的关键贡献是 Aurora 的开发，这是一个基于超过 100 万小时的大气数据进行训练的基础模型，可以使用单一模型架构执行多种类型的天气和气候预测。这代表着从构建单独的专门模型到拥有一个学习一般大气物理的模型的转变。 关键技术要点： - 模型架构使用具有适应时空数据的注意机制的转换器块 - 在来自多个来源的合并数据集上进行训练，包括 ERA5 再分析、卫星观测和气候模型输出 - 可以为空气污染、降水和温度预报等各种任务生成预测 - 与传统数值模型的数小时/数天相比，可在 1 分钟内生成预测 - 在多个基准上优于专门的 ML 模型和基于物理的数值天气预报 结果： - 与当前方法相比，5 天全球空气污染预测提高了 15-20% - 与专门模型相比，10 天天气预报的表现更好 - 即使在极端天气事件中也能保持准确性 - 随着训练数据的增加而持续改进 - 成功处理多个空间和时间分辨率 我认为这项工作可以显著改变我们处理环境建模的方式。无需为不同的预测任务维护单独的模型，只需拥有一个可以处理多个大气预测的单一基础模型，就可以使预测更加高效和易于理解。速度的提高（几分钟 vs. 几小时）可以支持需要快速预测的新应用程序。 我认为未来的挑战包括：- 验证更多样化大气现象的性能 - 了解关键预测的模型可解释性 - 解决训练和推理的计算成本 - 确保操作预测系统的可靠性 TLDR：研究人员开发了 Aurora，这是一种大气基础模型，经过大量天气/气候数据的训练，可以比专门的模型更好地处理多个预测任务，同时速度更快。表明基础模型可以改变环境预测。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gzj8rs/r_aurora_a_generalpurpose_foundation_model_for/</guid>
      <pubDate>Mon, 25 Nov 2024 13:50:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 24 Nov 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>