<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 16 Jan 2024 21:12:32 GMT</lastBuildDate>
    <item>
      <title>[D] 时间序列数据上的 MAMBA 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1989o55/d_mamba_models_on_time_series_data/</link>
      <description><![CDATA[大家好，我最近对 ​​MAMBA 架构很感兴趣，特别是因为它采用线性时间无关数学模型作为一种内存。我热衷于将其应用于时间序列分类或回归任务，但我在网上找到的大多数信息都集中在它在语言建模中的使用。尽管我尝试在时间序列数据集上训练这些模型，但它们似乎没有学到任何东西。我想知道你们中是否有人遇到过在时间序列数据上成功训练 MAMBA 模型的例子，以便找出我做错了什么。提前致谢！   由   提交 /u/jumpyAlucard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1989o55/d_mamba_models_on_time_series_data/</guid>
      <pubDate>Tue, 16 Jan 2024 18:16:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 有没有办法使用法学硕士创建长篇内容？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1988yxi/p_is_there_any_way_to_create_long_form_content/</link>
      <description><![CDATA[对于上下文，我正在尝试提取一堆文档（可以是讲义、一本书或任何东西）并生成 30 分钟长的文字记录使用 python 详细解释了这些主题。 有这样的方法吗？目前 openai 有令牌限制，我不知道如何使用矢量数据库来解决这个问题。假设要使用的内容位于矢量数据库上，我们如何让法学硕士生成长格式的成绩单？   由   提交 /u/internetcookiez   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1988yxi/p_is_there_any_way_to_create_long_form_content/</guid>
      <pubDate>Tue, 16 Jan 2024 17:48:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何处理雇主提出的不合理要求以及对机器学习不切实际的期望？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19882l2/d_how_do_you_deal_with_unreasonable_request_from/</link>
      <description><![CDATA[几个月前，我接受了一个职位，通过为社会科学研究项目训练机器学习模型来支持该项目。该项目涉及使用团队（由多名实习生、研究生、博士后和教授组成）花费数年时间并付出疯狂努力编制的数据集。然而，问题是他们没有事先咨询任何真正了解机器学习的人。对于非常复杂的任务来说，他们的数据集太小（只有大约 200 行）。更糟糕的是，大多数变量的预测价值微乎其微，而用于推导这些变量的方法虽然非常耗费人力，却引发了人们对其有效性的担忧。 该项目的 MO 绝对令人困惑：通过巨大的数据积累了数千个预测变量。努力和人力，期待完美的结果。任何模型如何用如此小的数据集估计如此多的参数却被忽视了。项目负责人似乎对 ML 有着某种神奇的理解，这可能是受到其在特定领域频繁误用的影响。这个项目的灵感尤其来自于一篇研究论文，我几乎可以保证该论文在其验证集上过拟合。 所有这些都让我处于尴尬的境地，作为新人，我需要告知这一点一个由经验丰富的博士后和教授组成的团队，全部来自社会科学背景，没有定量专业知识，他们多年的工作产生了一个完全不适合他们的目标的数据集，并且他们所建立的现有文献都是错误的，因为他们显然没有不知道什么是测试集以及何时使用它。我也不能告诉他们只扩展数据集，因为达到 200 行已经花费了数年时间。 我必须承认我对这次谈话有点紧张。 ​ 我怀疑对 ML 功能抱有不切实际的期望是一种常见的经历。其他人如何处理这个问题？如果他们坚持不管，你会直白地告诉他们这行不通，然后到别处找工作吗？如果是这样，这些交互通常如何进行？   由   提交 /u/Excusemyvanity   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19882l2/d_how_do_you_deal_with_unreasonable_request_from/</guid>
      <pubDate>Tue, 16 Jan 2024 17:13:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] APAR：法学硕士可以进行自动并行自动回归解码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1987em3/r_apar_llms_can_do_autoparallel_autoregressive/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.06761 摘要：  大型语言模型（LLM）的大规模采用需要高效部署策略。然而，自回归解码过程是大多数法学硕士生成文本的基础，它对实现高效服务提出了挑战。在这项工作中，我们介绍了一种并行自回归生成方法。通过对包含层次结构的通用领域数据进行指令调整，我们使法学硕士能够独立规划其生成过程并执行自动并行自回归（APAR）生成，从而显着减少生成步骤的数量。单独使用 APAR 即可实现高达 2 倍的加速，与推测解码结合使用时，加速可高达 4 倍。此外，APAR 减少了生成过程中的键值缓存消耗和注意力计算。与最先进的服务框架相比，这使得高吞吐量场景中的吞吐量提高了 20-70%，延迟降低了 20-35%。     由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1987em3/r_apar_llms_can_do_autoparallel_autoregressive/</guid>
      <pubDate>Tue, 16 Jan 2024 16:46:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer 是多状态 RNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1986k0x/r_transformers_are_multistate_rnns/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.06104 代码：https ://github.com/schwartz-lab-NLP/TOVA 摘要：  Transformers 被认为在概念上与到上一代最先进的 NLP 模型 - 循环神经网络 (RNN)。在这项工作中，我们证明了仅解码器 Transformer 实际上可以被概念化为无限多状态 RNN——一种具有无限隐藏状态大小的 RNN 变体。我们进一步证明，通过固定隐藏状态的大小，预训练的 Transformer 可以转换为有限多状态 RNN。我们观察到一些现有的转换器缓存压缩技术可以被构建为这样的转换策略，并引入了一种新的策略，TOVA，它比这些策略更简单。我们对多个远程任务进行的实验表明，TOVA 优于所有其他基线策略，同时几乎与完整（无限）模型相当，并且在某些情况下仅使用原始缓存大小的 1/8。我们的结果表明，变压器解码器 LLM 在实践中通常表现为 RNN。他们还提出了缓解最痛苦的计算瓶颈之一——缓存大小的选项。我们在 此 https URL 公开发布我们的代码。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1986k0x/r_transformers_are_multistate_rnns/</guid>
      <pubDate>Tue, 16 Jan 2024 16:12:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] AI音乐生成、语音克隆平台获得反馈</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/198615b/p_feedback_appreciated_for_ai_music_generation/</link>
      <description><![CDATA[我是这个 reddit 子版块的忠实粉丝，因为很多想法似乎都与 AI 宇宙相关。  如果我的最新进展能得到一些诚实的反馈，那就太好了。我添加了人工智能音乐生成，还包括语音克隆。可以免费完成有限的生成，但您可以联系我以获得更多测试积分。 https://www.aimastercraft.com/Audio/Generate ​ &amp;# x200b; ​ ​   由   提交 /u/EfficientEffort7029   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/198615b/p_feedback_appreciated_for_ai_music_generation/</guid>
      <pubDate>Tue, 16 Jan 2024 15:50:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] 📢 使用 Fondant 自动 RAG 优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19826qq/p_automated_rag_optimization_with_fondant/</link>
      <description><![CDATA[大家好， 我们通过名为“检索增强生成”（RAG）的自定义数据处理框架分享了一些关于检索增强生成（RAG）的实用见解我们最新博文中的软糖。 微调 RAG 是一项复杂的任务，需要大量时间和精力。我们构建了一个示例管道，用于索引自定义知识库（PDF、Huggingface 数据集等）、处理数据（嵌入、分块等）并评估结果。我们集成了不同的参数搜索技术来选择最佳配置，从而为您的 RAG 系统带来最佳结果。 为了构建管道，我们利用了 Fondant，这是一个开源框架数据处理框架，可以简化流程通过提供可重用组件来构建数据管道。它具有一系列功能，可以轻松开发和扩展管道，例如本地测试、内置云兼容性、缓存等。 查看以下资源：  📖 阅读博客文章 - https://medium .com/fondant-blog/lets-tune-rag-pipelines-with-fondant-902f7215e540 🔗 Medium 上的翻糖博客 - https://medium.com/fondant-blog 📂 RAG GitHub 存储库 - https://github.com/ml6team/fondant-usecase-RAG 📂 Fondant GitHub存储库 - https://github.com/ml6team/fondant 让我们知道什么如果您有任何问题或反馈，请随时在 Discord 上或在下面的评论中与我们联系。   由   提交 /u/East_Dragonfruit7277   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19826qq/p_automated_rag_optimization_with_fondant/</guid>
      <pubDate>Tue, 16 Jan 2024 12:50:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] iPhone 文本检测的有趣现象</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197zbzs/d_interesting_occurrence_about_text_detection_of/</link>
      <description><![CDATA[      我点击该图像几次，它检测到第二只狗是单词“dog”用中文写的。我不认为这是有原因的，但如果有人有任何想法，我很乐意听到他们。   由   提交/u/Ok_Care_886   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197zbzs/d_interesting_occurrence_about_text_detection_of/</guid>
      <pubDate>Tue, 16 Jan 2024 09:57:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 动态选择 RNN 递归</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197z747/d_dynamically_choosing_rnn_recurrences/</link>
      <description><![CDATA[嗨， 我正在开展一个研究项目，该项目可以从一些基于 ML 的建模中受益。我想知道是否有人知道 LSTM（或其他 RNN）模型的研究，其中重复次数是在模型执行期间动态确定的。例如，输出一个类的神经网络单元、决定网络是否继续运行的标准（+对更多单元迭代次数的惩罚）。 我尝试过搜索此内容，但没有成功。任何指向关键字或研究的指示将不胜感激。   由   提交 /u/ActuaV   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197z747/d_dynamically_choosing_rnn_recurrences/</guid>
      <pubDate>Tue, 16 Jan 2024 09:48:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于直接偏好优化（DPO）方程的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197yl66/d_question_about_direct_preference_optimization/</link>
      <description><![CDATA[      这是（直接偏好优化）DPO 的损失： https://preview.redd.it/6ubjn8ekprcc1.png?width=1324&amp;format=png&amp; ;auto=webp&amp;s=c932f5c030c2fb6b5f0f136934b047bc364d1dcc 我不明白 pi\_ref 的除法（对于 y\_w 和 y\_l）。我知道目的是微调后的模型不会偏离参考模型太远，但只要从数学上看 - 为什么 pi\_ref(y\_w|x) 应该接近 pi\_theta(y\_w |x)? 至少对于 y\_w 来说，损失似乎会受益于 pi\_ref(y\_w|x) 尽可能接近 0，因为我们希望最大化左侧部分 我错过了什么？ 谢谢。   由   提交/u/erap129  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197yl66/d_question_about_direct_preference_optimization/</guid>
      <pubDate>Tue, 16 Jan 2024 09:05:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是一个时间序列问题吗？或者还有其他方法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197y6lk/d_is_this_a_time_series_problem_or_is_there/</link>
      <description><![CDATA[      你好， 我正在尝试实现一个机器学习问题加上有限元模拟。 我有一组模拟（~5000），每个模拟有多个时间步长（~20），对于每个时间步长，我想预测~50个节点的坐标。我使用每个节点作为观察，因此这将是一个多输出回归问题，其目标是预测每个节点的 x、y 和 z 最终坐标。我按节点组织数据集，因此每个节点都属于特定的时间步和特定的模拟。 这里是来自数据集的 5 个观察值和相应特征的示例（与讨论无关） ）： https://preview .redd.it/4hjdyi3wjrcc1.png?width=1093&amp;format=png&amp;auto=webp&amp;s=df4ba944856d9e04fd76b12adf691fca77a692e6 我正在考虑使用 LSTM 和多时间序列，但自从我正在处理彼此不相关的小型时间序列模拟，我不太确定如何实现它。我认为这是一个时间序列问题，但我意识到我不能使用经典的预测方法。我只有 t = 0 时的信息，并且我想预测整个系列，因此我没有任何过去的观察结果可用于预测未来的结果。 什么是最好的模型/在这种情况下使用的方法？ ​   由   提交/u/rita_moura  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197y6lk/d_is_this_a_time_series_problem_or_is_there/</guid>
      <pubDate>Tue, 16 Jan 2024 08:37:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深度学习最好的进阶书籍？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197r6o0/d_best_advanced_books_of_deep_learning/</link>
      <description><![CDATA[我遇到的几乎所有书籍都是从头开始写的。他们是否有深入探讨主题的地方？   由   提交/u/toxfu  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197r6o0/d_best_advanced_books_of_deep_learning/</guid>
      <pubDate>Tue, 16 Jan 2024 02:12:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您对强化学习的真实体验是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197jp2b/d_what_is_your_honest_experience_with/</link>
      <description><![CDATA[根据我个人的经验，SOTA RL 算法根本不起作用。我尝试强化学习已有 5 年多了。我记得当 Alpha Go 击败世界著名围棋棋手 Lee Sedol 时，每个人都认为 RL 会席卷 ML 社区。然而，除了玩具问题之外，我个人从未找到过 RL 的实际用例。 您对此有何体验？除了广告推荐系统和 RLHF 之外，RL 是否还有合法的用例？或者，这都是炒作吗？ 编辑：由于我的评论被否决，这里是我的文章的链接可以更好地描述我的立场。 这并不是说我不理解强化学习。我发布了我的开源代码和就此写了一篇论文。 事实是它非常难以理解。其他深度学习算法，如 CNN（包括 ResNet）、RNN（包括 GRU 和 LSTM）、Transformers 和 GAN 并不难理解。这些算法可以工作，并且在实验室外有实用用例。 传统的 SOTA RL 算法（如 PPO、DDPG 和 TD3）非常困难。即使解决一个玩具问题，你也需要做大量的研究。相比之下，决策转换器是任何人都可以实现的东西，而且它似乎匹配或超越了 SOTA。您不需要两个网络相互竞争。您不必经历地狱般的事情来调试您的网络。它只是自然地以自回归的方式学习最好的一组动作。 我也不是故意显得傲慢或暗示强化学习不值得学习。我只是还没有看到任何现实世界中的实际用例。我只是想开始讨论，而不是声称我什么都知道。 编辑 2：令人震惊的是，有很多人因为我没有完全理解 RL 而称我为白痴。你们太自在了称呼不同意的人的名字。新闻快讯，并不是每个人都拥有机器学习博士学位。我的本科学位是生物学。我自学了高级数学来理解机器学习。我对这个领域充满热情；我在 RL 方面的经历非常令人失望。 有趣的是，很少有人反驳我的实际观点。总结一下：  缺乏实际应用 极其复杂且 99% 的人无法使用 比 CNN、RNN 和 GAN 等传统深度学习算法困难得多 样本效率低下且不稳定 难以调试 更好的替代方案，例如决策转换器&lt; /li&gt;  这些难道不是合理的批评吗？本子的目的不是要讨论与机器学习相关的问题吗？ 致少数没有称我为白痴的评论者……谢谢！请记住，你不需要付出任何代价就能变得友善！ 编辑 3：很多人似乎都认为 RL 被过度炒作了。不幸的是，这些评论被否决了。澄清一些事情：  我们在强化学习上投入了大量资金。我们从这项投资中得到的只是一个可以在（某些）视频游戏中超越人类的机器人。 AlphaFold 没有使用任何强化学习。 SpaceX 也没有。  我承认它对机器人技术很有用，但仍然认为它在实验室之外的用例极其有限。  如果您无意中发现了这条线索并对 RL 替代方案感到好奇，请查看决策转换器。它可以用于任何可以使用传统强化学习算法的情况。 最终编辑：对于那些最近做出贡献的人，感谢你们深思熟虑的讨论！据我所知，像 Dreamer 和 IRIS 这样基于模型的模型可能会有未来。但每个真正使用过像 DDPG 这样的无模型模型的人都一致认为它们很糟糕而且不起作用。   由   提交 /u/Starks-Technology   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197jp2b/d_what_is_your_honest_experience_with/</guid>
      <pubDate>Mon, 15 Jan 2024 20:56:46 GMT</pubDate>
    </item>
    <item>
      <title>NLP 应用程序的降维被遗忘了……？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/197glkm/dimensionality_reduction_for_nlp_applications/</link>
      <description><![CDATA[好吧，几年前我写论文时，我写了整整一节关于为什么降维（DR）很重要，我记得通过说明距离概念在高维度中失去重要性的东西来论证这一点。我还记得我用于聚类的一些方法在较低维度上效果更好，因此，DR 不仅仅是为了可视化目的（我觉得这是我最常使用的），而是建模中的必要步骤，不过，这些天，我读了很多关于人们使用 LLM 并将极高维嵌入到模型、聚类方法等中的文章，甚至没有提到 DR。那是怎么回事？我记得（尽管模糊）对维度如何影响常见距离度量进行了一些测试，基本上，余弦相似度在比 BERT、Mistral、openAI 或其他任何输出少得多的维度上不再有意义。我在这里误解了什么吗？难道DR真的没那么重要吗，人们是不是低估了它的价值，他们不在乎，难道他们不知道吗……？预先感谢大家，希望有人能为我阐明这一点:)   由   提交/u/_donau_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/197glkm/dimensionality_reduction_for_nlp_applications/</guid>
      <pubDate>Mon, 15 Jan 2024 18:56:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>