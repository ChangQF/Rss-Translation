<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Fri, 02 Feb 2024 06:16:19 GMT</lastBuildDate>
    <item>
      <title>[D] 谷歌云ML认证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agvyed/d_google_cloud_ml_certification/</link>
      <description><![CDATA[有人从 Google 云参加过考试吗？我想知道考试难还是容易，因为我也想参加。我知道 google 提供 20 道练习题，但考试有 60 道。另外，passmark 是什么？   由   提交 /u/ElRamani   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agvyed/d_google_cloud_ml_certification/</guid>
      <pubDate>Fri, 02 Feb 2024 05:10:58 GMT</pubDate>
    </item>
    <item>
      <title>CVPR [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agv3k1/cvpr_r/</link>
      <description><![CDATA[2023年1月底就发布了CVPR Workshop名单，今年什么时候发布CVPR Workshop名单？？ &lt; /div&gt;  由   提交 /u/coolchikku   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agv3k1/cvpr_r/</guid>
      <pubDate>Fri, 02 Feb 2024 04:23:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这里的充分概率是什么意思？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agu3rw/d_what_does_probability_of_sufficiency_mean_here/</link>
      <description><![CDATA[我正在阅读这篇论文，但是发现这个部分非常令人困惑。就像，给定 Z 与 z 不同，Y 与 y 不同，然后得到 Y(Z=z)=y ??这不是超级矛盾吗？？  P/s：来自 r/learnmachinelearning  的交叉发布  由   提交/u/KarmaCut132   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agu3rw/d_what_does_probability_of_sufficiency_mean_here/</guid>
      <pubDate>Fri, 02 Feb 2024 03:29:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 图像和动画制作所需的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agtf73/d_suggestions_needed_for_image_and_animation_maker/</link>
      <description><![CDATA[您好，你们用什么来创建自己的图像（ex1) 或动画 (ex 2) 感谢您的帮助。   由   提交/u/Relative_Tip_3647   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agtf73/d_suggestions_needed_for_image_and_animation_maker/</guid>
      <pubDate>Fri, 02 Feb 2024 02:54:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 22 个消费级 GPU 上的分段任意模型 (SAM) 基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agr8rm/p_segment_anything_model_sam_benchmark_on_22/</link>
      <description><![CDATA[      对分段任意模型 (SAM) 进行基准测试&lt; /h2&gt; 在此基准测试中，我们对来自 COCO 2017 和 AVA 图像数据集。我们评估了代表 22 种不同消费类 GPU 类别的 SaladCloud 上 302 个节点的推理速度和性价比。  为此，我们创建了一个容量为 100 个节点的容器组，其 GPU 类别为“稳定扩散兼容”。所有节点都分配有 2 个 vCPU 和 8GB RAM。这是我们发现的。  在 RTX 3060 Ti 和 RTX 3060 Ti 上，每美元可分割 50K+ 图像。 RTX 3070 Ti https:// Preview.redd.it/c9qt2abwm2gc1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=51b55b9dc00cf8b7dc6919023a5aa9249218e0a0 与较小型号的情况几乎总是一样，最好的成本-性能来自低端 GPU，主要是 RTX 30 系列卡。在这种情况下，我们看到 Ti 卡的性价比显着提升。这是有道理的，因为它们的价格与非 Ti 同类产品相同，但拥有更多 CUDA 核心。这里表现出色的是 RTX 3060 Ti 和 RTX 3070 Ti，每台每美元至少提供 50k 次推理。 特定节点内的推理时间相当一致  https://preview.redd.it/njos0wl2n2gc1.png？ width=1920&amp;format=png&amp;auto=webp&amp;s=b89b4527600350960dbac903274b3407ddfc78d6 放大单个 GPU 类别（RTX 3070 Ti）的性能，我们发现大部分推理时间落在任何特定节点上的范围都很窄，有一些显着的异常值。我们确实看到不同节点之间存在一些差异，其中一个节点特别糟糕。我们经常看到 Salad 上各节点的性能存在少量差异，因为每台节点都是一台单独的住宅游戏 PC，具有各种不同的 CPU、RAM 速度、主板配置等。 我们的一个异常值节点（31b6，上面圈出的）表示该机器存在异常情况。  RTX 3060 Ti 和 RTX 3070 Ti 提供最佳性价比 运行 Segment Anything Model (SAM) 的 RTX 3060 Ti 和 RTX 3070 Ti 提供极高的性价比批量图像分割解决方案，每美元可分割近 50,000 张图像。  带有更多说明的完整基准测试如下：https://blog.salad.com /segment-anything-model-benchmark/ ​ ​   由   提交 /u/SaladChefs   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agr8rm/p_segment_anything_model_sam_benchmark_on_22/</guid>
      <pubDate>Fri, 02 Feb 2024 01:08:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] NLP学习资源新旧对比。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agpwun/d_nlp_learning_resource_old_vs_new/</link>
      <description><![CDATA[大家好，我正在开始我的 NLP 之旅，我的课程是 cs124(2012) 和 cs224n(2023)，所以我计划从2012 年讲座的 cs124，然后转到 cs224n。 我的问题是 2012 年讲座已经很老了，而且目前技术已经很先进，所以我应该直接跳到 cs224n 吗？或者我应该因为基础知识或知识而学习它们？也请告诉我是否有任何好的资源。我目前正在参考演讲和语言书籍第三版作为讲座。   由   提交 /u/Critical_Day3611   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agpwun/d_nlp_learning_resource_old_vs_new/</guid>
      <pubDate>Fri, 02 Feb 2024 00:07:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 访谈系统设计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agogxg/d_sys_design_for_interviews/</link>
      <description><![CDATA[昨天我与一家非 faang 但顶级公司的高级 MLE 进行了交谈。他说，即使在 FAANG 中，ML 面试也不再有 Sys 设计。他说ML设计是一个回合，但不是sys设计。系统设计仅适用于 SWE。我认为以前是系统设计+机器学习设计。谁能确认一下吗？   由   提交/u/No-Mud4063  /u/No-Mud4063 reddit.com/r/MachineLearning/comments/1agogxg/d_sys_design_for_interviews/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agogxg/d_sys_design_for_interviews/</guid>
      <pubDate>Thu, 01 Feb 2024 23:04:40 GMT</pubDate>
    </item>
    <item>
      <title>【研究】防御语言模型越狱攻击的鲁棒提示优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agnzxt/research_robust_prompt_optimization_for_defending/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2401.17263   摘要：尽管人工智能对齐取得了进步，但语言模型（LM）仍然容易受到对抗性攻击或越狱，其中对手会修改输入提示以诱发有害行为。虽然已经提出了一些防御措施，但它们侧重于狭隘的威胁模型，缺乏强大的防御能力，我们认为这种防御措施应该是有效的、普遍的和实用的。为了实现这一目标，我们提出了第一个对抗性目标来保护 LM 免受越狱攻击，并提出了一种算法，即鲁棒提示优化（RPO），该算法使用基于梯度的令牌优化来强制执行无害的输出。这产生了一个易于访问的后缀，显着提高了对优化过程中出现的越狱和未知的、持续越狱的鲁棒性，将 Starling-7B 在 20 次越狱中的攻击成功率从 84% 降低到 8.66%。此外，我们发现RPO对正常LM使用影响较小，在自适应攻击下成功，并且可以转移到黑盒模型，将GPT-4最强攻击的成功率从92%降低到6%。    由   提交 /u/SatisfyingLatte   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agnzxt/research_robust_prompt_optimization_for_defending/</guid>
      <pubDate>Thu, 01 Feb 2024 22:45:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] MoE-LLaVA：大视觉语言模型专家混合 - 北京大学 2024 - MoE-LLaVA-3B 展示了与 LLaVA-1.5-7B 相当的性能！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agmd47/r_moellava_mixture_of_experts_for_large/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2401.15947v1  Github： https://github.com/PKU-YuanGroup/MoE-LLaVA  摘要：  对于大型视觉语言模型（LVLM） ，缩放模型可以有效提高性能。然而，扩展模型参数会显着增加训练和推断成本，因为计算中的每个标记都会激活所有模型参数。在这项工作中，我们提出了一种新的训练策略MoE-tuning for LVLMs，它可以构建一个参数数量惊人但计算成本恒定的稀疏模型，并且有效解决通常与多模式学习和模型稀疏性相关的性能下降问题。此外，我们还提出了 MoE-LLaVA 框架，这是一种基于 MoE 的稀疏 LVLM 架构。该框架独特地在部署期间通过路由器仅激活前k个专家，使其余专家保持不活动状态。我们广泛的实验突出了MoE-LLaVA在视觉理解方面的出色能力及其减少模型中幻觉的潜力输出。 值得注意的是，仅用 30 亿个稀疏激活参数， MoE-LLaVA 在各种视觉理解数据集上表现出与 LLaVA-1.5-7B 相当的性能，甚至超过了 LLaVA-1.5-物体幻觉基准中的 13B。通过 MoE-LLaVA，我们的目标是为稀疏 LVLM 建立基线，并为未来开发更高效、更有效的多模态学习系统的研究提供宝贵的见解。   https://preview.redd.it/pfpthghxl1gc1.jpg ?width=803&amp;format=pjpg&amp;auto=webp&amp;s=4e4578bb154a596fc11c8da18de1aadf4955c1e6 https://preview.redd.it/xo5rzbhxl1gc1.jpg?width=797&amp;format=pjpg&amp;auto=webp&amp;s=96bcd786ebfe3291e1ccb50415 6e5b3e8db7b710 https://preview.redd.it/22e3kfhxl1gc1 .jpg?width=1321&amp;format=pjpg&amp;auto=webp&amp;s=ad7a4657421f8bc34bea15d720b2bd5f78792d7b https://preview.redd.it/6i93vbhxl1gc1.jpg?width=1181&amp;format=pjpg&amp;auto=webp&amp;s=b43afea3e6e24 568a39118307ead132455a471c9   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agmd47/r_moellava_mixture_of_experts_for_large/</guid>
      <pubDate>Thu, 01 Feb 2024 21:36:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 围绕“AI”的普遍负面情绪</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agj5y1/d_general_negative_sentiment_surrounding_ai/</link>
      <description><![CDATA[我注意到，每当我向普通人群（通常是非技术人员 -（家人、朋友等））提起人工智能主题时，第一个我想到的是“机器人接管世界并消灭人类”的存在的消极方面、危险和威胁，而不是积极的一面（如提高效率、自动化、科学等）。需要明确的是，我具体谈论的是人工智能的生存威胁，而不是像大型科技亿万富翁和法团主义这样的经济/政治问题。 这让我想知道 - “人工智能”是否已成为一个伴随着的术语对绝大多数人来说是一个可怕的负面含义吗？这是非常可悲的，我认为这些人中的许多人不知道他们在说什么，他们不明白这些模型是如何工作的，所以他们只是求助于人工智能存在主义者在媒体上推销的任何东西（不是为了淡化危险——我我知道有像 Ilya sutski 和 Geoffrey Hinton 这样的杰出研究科学家担心这些事情）但我觉得现在对人工智能的过度炒作和过度提及确实导致了普遍的技术悲观主义。 TLDR ：“人工智能”越来越多地给普通（非技术）公众带来存在主义的恐惧/负面含义？想法？   由   提交/u/Character-Capital-70   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agj5y1/d_general_negative_sentiment_surrounding_ai/</guid>
      <pubDate>Thu, 01 Feb 2024 19:22:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能的真正价值在于最终用户用它做什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agewf2/d_is_the_true_value_of_ai_what_the_enduser_does/</link>
      <description><![CDATA[阅读本文后：https://www.taipy.io/posts/bringing-the-end-user-into-the-ai-picture 我已经考虑到为什么重点不是让人工智能对非技术最终用户来说更容易访问和用户友好。 制定真正复杂的算法是一回事，但当你实际上做不到时，它是否有意义用它来做出决策？ 如何改进这种人工智能协作？ 只是一些想法！  &amp;# 32；由   提交/u/quicklyalienated76   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agewf2/d_is_the_true_value_of_ai_what_the_enduser_does/</guid>
      <pubDate>Thu, 01 Feb 2024 16:25:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 传统的 ML/深度学习技术是否已在 NLP 和生产级系统中使用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1agb5rg/d_are_traditional_ml_deep_learning_techniques/</link>
      <description><![CDATA[许多公司正在从他们在几年内开发的机器学习管道转向基于 ChatGPT 的/类似的解决方案。当然，对于文本生成用例来说，这是最有意义的。 但是，许多实际的 NLP 问题可以表述为分类/标记问题。 Pre-ChatGPT 系统过去涉及大量移动组件（关键字提取、超长正则表达式、在嵌入空间中查找最近向量等）。 那么，实际发生了什么？人们是否用 LLM API 替换特定组件？或者整个系统是否被一系列对 LLM API 的调用所取代？基于 BERT 的解决方案还在使用吗？ 现在 ChatGPT API 支持更长的时间和更长的时间。更长的上下文窗口（128k），除了定价和数据隐私问题之外，是否存在基于 BERT 的/其他解决方案能够发挥作用的用例；它不需要像 ChatGPT/LaMDA/类似的 LLM 等模型那样多的计算？ 如果它是上述 LLM 模型不知道的专有数据，那么您将使用自己的模型。但很多用例似乎都围绕着对人类语言本身的一般理解（例如投诉/票证分类/从产品评论中得出见解）。 任何博客、论文、案例研究或其他解决相同问题的文章将不胜感激。我也很想听听您的所有经历，以防您在现实系统中从事过/听说过上述迁移。 这个问题是专门提出的，请记住 NLP 的使用- 案例；但也可以随意将您的答案扩展到其他模式（例如表格和文本数据的组合）。   由   提交/u/101coder101  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1agb5rg/d_are_traditional_ml_deep_learning_techniques/</guid>
      <pubDate>Thu, 01 Feb 2024 13:36:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前适合本地法学硕士的最佳 RAG 设置是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ag6bo7/d_whats_the_best_current_rag_setup_that_would/</link>
      <description><![CDATA[我过去（6-8个月前）尝试过像langchain这样的东西，但它们很麻烦并且没有按预期工作。 我需要 RAG 从各种 pdf 中获取数据（很长，150 多页） - 我需要一个设置来允许我添加越来越多的数据源。 我想运行在本地，可以获得 24gb 显卡（或 2x16gb 显卡） - 这样我就可以使用 33b 或更小的型号运行。 我知道行业中的情况每两周就会发生变化，所以我希望有一个简单高效的 RAG 方法（与 6 个月前相比）   由   提交 /u/yupignome   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ag6bo7/d_whats_the_best_current_rag_setup_that_would/</guid>
      <pubDate>Thu, 01 Feb 2024 08:30:18 GMT</pubDate>
    </item>
    <item>
      <title>[N] Mistral 首席执行官确认新开源 AI 模型接近 GPT-4 性能的“泄露”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1afryc0/n_mistral_ceo_confirms_leak_of_new_open_source_ai/</link>
      <description><![CDATA[https://venturebeat.com/ai/mistral-ceo-confirms-leak-of-new-open-source-ai-model-nearing-gpt-4-性能/   由   提交/u/EmbarrassedHelp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1afryc0/n_mistral_ceo_confirms_leak_of_new_open_source_ai/</guid>
      <pubDate>Wed, 31 Jan 2024 20:35:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>