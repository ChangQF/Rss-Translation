<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 03 Feb 2025 09:18:28 GMT</lastBuildDate>
    <item>
      <title>[R] 使用算法蒸馏扩展跨域动作模型的上下文强化学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1igl19m/r_scaling_incontext_reinforcement_learning_with/</link>
      <description><![CDATA[我刚刚阅读了这篇关于动作建模的新论文，其中介绍了一种将上下文 RL 与连续噪声蒸馏相结合的有趣方法。关键技术贡献是使用基于 Transformer 的架构，该架构通过两阶段过程学习动作表示：初始特征提取与噪声蒸馏，然后通过 RL 进行上下文细化。 主要技术组件和结果：  连续噪声蒸馏：一种在模型训练期间从视频数据中滤除不相关特征的新技术 上下文内动作学习：使用 Transformer 注意机制来捕获动作序列中的时间关系 结果：与以前的方法相比，动作识别准确率提高了 27%，训练速度提高了 35% 跨领域评估：在涵盖机器人、人类动作和游戏环境的新数据集上进行了测试  实现细节：- 多层注意架构，具有针对动作理解不同方面的专门层 - 结合监督学习和 RL 微调的两阶段训练过程 - 自定义损失函数平衡特征提取和时间连贯性- 与现有视觉变换器主干集成 我认为这种方法对于实时动作理解至关重要的机器人应用特别有用。更快的训练时间和更高的准确性使其可以实际部署在生产系统中。跨域性能表明它可能很好地推广到新任务。 但是，我认为计算要求可能会限制立即广泛采用。本文指出训练期间 GPU 内存使用率很高。在将其用于安全关键型应用之前，还需要解决复杂动作序列的性能下降问题。 TLDR：使用上下文 RL 和噪声蒸馏的新动作建模方法实现了 27% 的更好准确度和 35% 的更快训练速度，在机器人和自动化系统中具有潜在的应用。 完整摘要在这里。论文此处。    由    /u/Successful-Western27 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1igl19m/r_scaling_incontext_reinforcement_learning_with/</guid>
      <pubDate>Mon, 03 Feb 2025 09:07:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 值得关注的 DS 课程或认证？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1igk9jx/d_ds_courses_or_certifications_that_are_worthy_of/</link>
      <description><![CDATA[对于数据科学专业人士来说，您认为哪些资格 / 认证 / 认可具有声望或至少值得关注？ 据我所知，只有高等教育和经验才能真正发挥作用。    提交人    /u/kultuhtu   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1igk9jx/d_ds_courses_or_certifications_that_are_worthy_of/</guid>
      <pubDate>Mon, 03 Feb 2025 08:07:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] 使用不准确的标签进行训练时测量模型性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1igi8nu/d_p_measuring_model_performance_when_training/</link>
      <description><![CDATA[我正在一个没有标记数据的领域工作。例如，数据将是寻找异常使用情况的网络流量模式。由于没有基本事实数据，我们经常依赖一组启发式方法，这些方法可以帮助我们根据数据点中特定特征违反的基于启发式规则阈值的数量获得每个数据点的分数。 我想要构建的解决方案的目标是识别启发式规则被充分触发的类似模式，同时也捕获启发式规则不足以将数据点识别为异常但表现出较新的异常模式的案例数据点。 我遇到的问题是 - 我如何衡量这个模型的性能。目前，违反任何单一启发式的数据点都被认为是坏的（即异常）。但是经典的机器学习模型评估说我需要每个数据点的“是/否”，我目前正在使用 F 分数来检查模型性能。这种衡量模型性能的方式是，如果没有触发任何基于启发式的规则，则会惩罚将数据点归类为异常的模型。 这个问题可以用不同的方式来表达 -  如何向我的模型添加较新的基于启发式的规则，以使其不会过时/陈旧 如何衡量此模型的性能，以便识别较新的模式不会受到惩罚。  那么我该如何处理呢？我不需要确切的答案 - 我觉得这应该是一个定义明确且经过探索的问题空间，如果有人可以建议我应该搜索哪些术语才能找到该空间的正确材料/论文，那将非常有用。    提交人    /u/PsychologicalRide127   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1igi8nu/d_p_measuring_model_performance_when_training/</guid>
      <pubDate>Mon, 03 Feb 2025 05:46:47 GMT</pubDate>
    </item>
    <item>
      <title>[D][R] 大型语言模型会彻底改变推荐系统吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ig6w7b/dr_are_large_language_models_going_to/</link>
      <description><![CDATA[LinkedIn 刚刚发布了一些关于使用大型语言模型 (LLM) 进行排名和推荐任务的有趣研究。您可以在这篇论文 (https://arxiv.org/abs/2501.16450) 中深入了解详细信息。 传统上，推荐系统依赖于大型稀疏表（想想大规模 ID 嵌入表）将用户映射到内容。但这种新方法颠覆了剧本：它“口头化”所有特征，将它们转换为 LLM 可以咀嚼的文本（LLM 具有小型嵌入表）。这个想法是，由于推荐本质上是将用户与内容进行匹配，因此 LLM 在模式识别和推理方面的天赋可能会发现老式方法所遗漏的用户行为中隐藏的见解。 最酷的部分是：如果这种方法有效，我们可能会看到推荐系统不仅更智能，而且还能够解释他们为什么会提出某个建议。这创造了零样本能力，用几个例子构建了一个 RS 模型。每个排名模型都不需要新的团队或 ML 工程师。 当然，有一个问题。将所有内容转换为文本，然后用大型模型进行处理，这听起来效率极低。我们正在讨论延迟和扩展方面的潜在问题，尤其是当您需要实时提供推荐时。这是一个典型的“更聪明但更慢”的例子，除非有一些巧妙的优化发挥作用。 因此，虽然这个研究方向无疑令人兴奋，并可能彻底撼动推荐游戏，但最大的问题是：它能实用吗？更好的推理和可解释性带来的好处是否会超过额外的计算成本？只有时间（和进一步的研究）会告诉我们答案。 你们都觉得怎么样？    提交人    /u/No_Bullfrog6378   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ig6w7b/dr_are_large_language_models_going_to/</guid>
      <pubDate>Sun, 02 Feb 2025 20:32:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 研究人员使用哪些软件工具来制作这样的神经网络架构？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ig6k3l/d_which_software_tools_do_researchers_use_to_make/</link>
      <description><![CDATA[        提交人    /u/SimpleObvious4048   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ig6k3l/d_which_software_tools_do_researchers_use_to_make/</guid>
      <pubDate>Sun, 02 Feb 2025 20:19:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 解决法学硕士中的思考不足：基于标记的提高推理深度的策略</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ig6aic/r_addressing_underthinking_in_llms_a_tokenbased/</link>
      <description><![CDATA[本文介绍了一种通过标记级输出分析跟踪推理一致性来分析大型语言模型中的“欠思考”模式的新方法。研究人员开发了指标来识别模型在任务期间何时在不同的认知方法之间切换。 关键技术要点： - 开发用于衡量模型输出中思维模式切换的定量指标 - 分析标记级序列以检测推理路径的变化 - 发现模型平均每 2-3 个推理步骤切换一次思维方法 - 证明准确度降低 15-30％ 与频繁切换相关 - 表明简单任务比复杂任务更容易受到不一致推理的影响 该方法结合了： - 标记模式分析以识别推理状态的变化 - 跨任务复杂性级别的性能相关性研究 - 一致与不一致推理路径之间的比较分析 - 量化思维碎片化影响的指标 我认为这项研究揭示了当前 LLM 架构中的重要限制，需要解决这些限制才能将这些系统可靠地用于需要持续推理的任务。这些指标和分析方法可能是评估和改进模型训练方法的有力工具。 我认为最有趣的技术发现是，简单的任务实际上比复杂的任务更容易受到思维转换的影响——这表明我们关于这些模型如何处理不同认知负荷的假设可能需要修改。 TLDR：新方法量化了 LLM 在任务中切换推理模式的频率，显示由于思维不一致，性能下降了 15-30%。简单任务比复杂任务受到的影响更大。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ig6aic/r_addressing_underthinking_in_llms_a_tokenbased/</guid>
      <pubDate>Sun, 02 Feb 2025 20:07:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] xLSTM 和注意力机制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ig46fk/d_xlstm_and_attention/</link>
      <description><![CDATA[大家好， 我目前正在撰写关于通过扩展的长期短期模型进行鼓轨合成的硕士论文，我考虑将注意力机制引入模型架构，因为它在音乐生成任务中似乎非常有效，正如一些使用 Bi-LSTM 的研究表明的那样。由于我还没有找到任何结合 xLSTM 和注意力机制的论文，我有点不确定我是否错过了什么，或者它还没有真正经过测试（因为它仍然是一项新技术）。你的看法是什么？  提前谢谢！     提交人    /u/qwertzonator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ig46fk/d_xlstm_and_attention/</guid>
      <pubDate>Sun, 02 Feb 2025 18:40:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] [P] 使用大型概念模型研究 KV 缓存压缩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ig0z7h/r_p_investigating_kv_cache_compression_using/</link>
      <description><![CDATA[大家好，假期期间我阅读了 Meta 的论文，其中介绍了大型概念模型，并认为这可能是压缩 KV 缓存的有效方法。我在 TPU v4-32s 上的 Jax 中实现并训练了一个 LCM 架构，以探索其在 KV 缓存压缩方面的潜力。完整实现和详细结果可在此处获得。 主要发现：虽然理论上很有希望，但基础 LCM 架构表现出明显的性能下降。我怀疑以下原因会导致这种退化：  序列打包损害了概念嵌入语义，阻碍了有效的注意 联合编码器-解码器训练将计算浪费在概念形成上，而不是利用预训练的知识 由于 LCM 在 seq_len/concept_size 示例上进行训练，而标准 Transformer 中的 seq_len 则不然，因此有效训练减少  值得探索的潜在改进：  禁用序列打包 利用预训练的编码器/解码器（SONAR/T5） 研究有/无联合训练的基于扩散的 LCM  但是，考虑到基本的数据效率问题，替代的 KV 缓存压缩方法可能更有前景。 上面的链接中有实现细节和完整分析。欢迎讨论和反馈。     由    /u/clankur 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ig0z7h/r_p_investigating_kv_cache_compression_using/</guid>
      <pubDate>Sun, 02 Feb 2025 16:27:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何从像 Llama-3.2-Vision 这样的多模态 LLM 获取注意力图？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifxffm/d_how_to_get_attention_maps_from_a_multimodal_llm/</link>
      <description><![CDATA[我正在开展一个项目，希望用户能够看到模型在预测每个标记时“看到”的内容。我正在寻找一种在推理过程中从视觉编码器中提取注意力图的方法。您知道如何实现这一点吗？或者是否有可用的代码？    提交人    /u/SussyAmogusChungus   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifxffm/d_how_to_get_attention_maps_from_a_multimodal_llm/</guid>
      <pubDate>Sun, 02 Feb 2025 13:40:19 GMT</pubDate>
    </item>
    <item>
      <title>[P] VGSLify – 使用 VGSL 定义和解析神经网络（现在具有自定义层！）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifwuxp/p_vgslify_define_and_parse_neural_networks_with/</link>
      <description><![CDATA[大家好，我想分享 VGSLify，这是一个 Python 包，它简化了使用 VGSL（可变大小图形规范语言） 定义、训练和解释神经网络的过程。受 Tesseract 的 VGSL 启发，VGSLify 为 TensorFlow 和 PyTorch 扩展了这一概念。 🚀 🔹 什么是 VGSL？ VGSL 是一种使用简单字符串格式定义深度学习模型的紧凑方法：  None,None,64,1 Cr3,3,32 Mp2,2 Cr3,3,64 Mp2,2 Rc3 Fr64 D20 Lfs128 D20 Lf64 D20 Fs10  每个 token 代表一个 层：  Cr3,3,32 → 卷积（3x3 内核、32 个过滤器、ReLU 激活） Mp2,2 → MaxPooling（2x2） Rc3 → 重塑为（序列、特征） Lfs128 → 具有 128 个单元的前向 LSTM，返回序列 D20 → 速率为 0.2 的 Dropout 层 Lf64 → 具有 128 个单元的前向 LSTM，不返回序列 Fs10 → 具有 10 个输出和 softmax 激活的完全连接层  🚀 将 VGSL 转换为深度学习模型 使用 VGSLify，您可以轻松地从 VGSL 字符串生成 TensorFlow 或 PyTorch 模型： ```python from vgslify import VGSLModelGenerator vgsl_spec = &quot;None,None,64,1 Cr3,3,32 Mp2,2 Fs92&quot; vgsl_gen = VGSLModelGenerator(backend=&quot;tensorflow&quot;) # 或者 &quot;torch&quot; model = vgsl_gen.generate_model(vgsl_spec) model.summary() ``` 🔄 将现有模型转换为 VGSL 想要获得模型的 VGSL 表示吗？使用： ```python from vgslify import model_to_spec import tensorflow as tf model = tf.keras.models.load_model(&quot;your_model.keras&quot;) vgsl_spec = model_to_spec(model) print(vgsl_spec) ``` 非常适合以紧凑格式导出模型。 🔥 VGSLify v0.14.0 有什么新功能？ 我刚刚发布了 VGSLify v0.14.0，它增加了一些备受期待的功能！ 🎉 ✅ 自定义层注册 现在，您可以使用自己的层扩展 VGSL： ```python from vgslify.tensorflow import register_custom_layer @register_custom_layer(&quot;Xsw&quot;) def build_custom_layer(factory, spec): return tf.keras.layers.Dense(10) # 示例自定义层 ``` 这意味着您可以添加所需的任何层，同时仍然使用 VGSL 的简单性。 ✅ 自定义模型解析 需要将具有自定义层的模型转换回 VGSL 吗？只需注册一个解析器： ```python from vgslify.model_parsers.tensorflow import register_custom_parser @register_custom_parser(MyCustomLayer) def parse_my_custom_layer(layer): return f&quot;Xsw({layer.units})&quot; ``` 现在，VGSLify 将在转换模型时自动识别您的自定义层。 ✅ 简化导入和更清洁的 API 我已经重新组织了模块以便于使用： python from vgslify import VGSLModelGenerator, model_to_spec  不再需要深度导入！ 📥 安装 bash pip install vgslify[tensorflow] # For TensorFlow pip install vgslify[torch] # For PyTorch  或者，只安装核心库而不安装任何深度学习后端： bash pip install vgslify  🛠️ 为什么要使用 VGSLify？  紧凑且可读 → 在单个字符串中定义整个模型 与 TensorFlow 和PyTorch → 在后端之间无缝切换 解析和导出模型 → 轻松将模型转换为 VGSL 并转回 现在可扩展！ → 自定义层和解析器使其更加灵活  🌟 在 GitHub 和 PyPI 上查看：  GitHub：https://github.com/timkoornstra/VGSLify PyPI：https://pypi.org/project/vgslify/  希望听到您的反馈！让我知道您的想法。😊   由    /u/henkje112  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifwuxp/p_vgslify_define_and_parse_neural_networks_with/</guid>
      <pubDate>Sun, 02 Feb 2025 13:08:16 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] TMLR 已获 Scopus 索引批准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ift104/news_tmlr_was_approved_for_indexing_in_scopus/</link>
      <description><![CDATA[ 2024 TMLR 年度报告 - Google Docs 2025 年 1 月 14 日，TMLR 获准在 Scopus 中编入索引。2025 年 1 月 15 日，TMLR 获准在 DOAJ 中编入索引。  在这里发布这个消息是因为我还没有在任何地方看到这个消息。对于欧洲和南美的 ML 研究人员/博士来说，这是一个好消息，因为许多大学只承认 Scopus 索引的论文。   由    /u/OkTaro9295  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ift104/news_tmlr_was_approved_for_indexing_in_scopus/</guid>
      <pubDate>Sun, 02 Feb 2025 08:40:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] Tulu 3 模型表现优于 4o 和 Deepseek？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifetmm/news_tulu_3_model_performing_better_than_4o_and/</link>
      <description><![CDATA[有人用过艾伦人工智能研究所周四发布的这个模型吗？它似乎在很多方面都胜过 4o 和 DeepSeek，但不知为何，几乎没有报道。有什么想法吗？ https://www.marktechpost.com/2025/01/31/the-allen-institute-for-ai-ai2-releases-tulu-3-405b-scaling-open-weight-post-training-with-reinforcement-learning-from-verifiable-rewards-rlvr-to-surpass-deepseek-v3-and-gpt-4o-in-key-benchmarks/    由    /u/joshkmartinez 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifetmm/news_tulu_3_model_performing_better_than_4o_and/</guid>
      <pubDate>Sat, 01 Feb 2025 19:57:03 GMT</pubDate>
    </item>
    <item>
      <title>[2412.20302] EXAdam：自适应交叉矩的力量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifag0a/241220302_exadam_the_power_of_adaptive/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifag0a/241220302_exadam_the_power_of_adaptive/</guid>
      <pubDate>Sat, 01 Feb 2025 16:48:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>