<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 05 Apr 2024 06:17:29 GMT</lastBuildDate>
    <item>
      <title>[D]我想知道如何集成GPT<->Jango来分析物流年度库存excel数据。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bw8jly/di_would_like_to_know_how_to_integrate_gptjango/</link>
      <description><![CDATA[你好。我目前正在从事 Python 后端训练营团队项目。我想将 GPT 集成到 Django 开发的登陆页面输入表单中，其中包含以下内容。 简单的想法是  用户访问登陆页面并上传年销售额和库存的 Excel 文件。 GPT 将 Excel 文件传递​​到服务器以执行适当的分析（例如 EDA 分析）。 &lt; li&gt;在登陆页面上以输入表单的形式公开上面 2. 中分析的数据。  目前无法进行微调和其他高级处理，所以我的目标是进行简单的集成。我还是一个初学者，所以我很感激任何参考和建议。    由   提交/u/Minute_Ad_244   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bw8jly/di_would_like_to_know_how_to_integrate_gptjango/</guid>
      <pubDate>Fri, 05 Apr 2024 04:00:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 单次参考图像的高效一次性检测的 SOTA 是多少？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bw7ol3/d_whats_sota_in_efficient_oneshot_detection_for_a/</link>
      <description><![CDATA[澄清一下，我并不是指通常的野外物体检测任务，就像“这里有一千张随机照片，放置边界框”周围所有的自行车”。我的意思是一个规模小得多的任务，更像是“这里有一千张通过公司传真机的图像，显​​示哪些图像在页面上的某个位置有该公司的徽标”。例如，您有一个在较大图像中查找的确切图像的干净参考副本，但它可能会扭曲、轻微旋转、大小和位置可变等。  以这张信头产品图片为例。如果我有一个“完美的”该图像中页面右上角徽标的 SVG，在图像中找到它确实不应该那么困难（尽管它看起来稍微扭曲，偏离水平约 10 度，而且可能要小得多）比我的参考图像）或者说它不存在。 显然，许多传统的 CV 已经完全被 ML 方法取代，并且目标检测/分割是一个非常活跃的领域。我说 SOTA，但这确实感觉像是一个传统的 CV 问题。我看的不是照片或自然图像，它们是机器生成的，我正在寻找的东西总是看起来或多或少相同，只有细微的变化。如果像 SIFT 功能这样的基本功能可以处理这个问题，那就太好了，但如果我要通过微调更快的 r-cnn 或 yolov5 或 detectorron2 等东西来获得明显更好的结果，那就这样吧。 其他因素：  宁愿不需要需要手工注释的训练集。当目标类别的真实示例变化很大（例如自行车）时，这显然是需要的，但这里的情况并非如此。在 COCO 等内容上进行预训练的模型感觉太过矫枉过正，甚至适得其反，因为我感兴趣的领域与自然图像几乎没有重叠。 更喜欢尽可能轻量级的解决方案。我不需要一个需要两天训练并且可以做无数事情的怪物框架，理想情况下它只是工作得相当好的东西，并且可以在本地运行，并且可以快速训练和快速推理。  更喜欢使用公开代码的方法，但如果有必要，我会自己实现一篇论文。  提前感谢您为我指明正确方向的任何帮助!   由   提交/u/wintermute93  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bw7ol3/d_whats_sota_in_efficient_oneshot_detection_for_a/</guid>
      <pubDate>Fri, 05 Apr 2024 03:17:04 GMT</pubDate>
    </item>
    <item>
      <title>[D]猜想：如果深度学习模型没有取得进一步的进展，会发生什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bw7lqh/d_conjecture_if_no_further_advances_in_deep/</link>
      <description><![CDATA[看起来我们都在法学硕士的基础上扬帆起航，或者至少是这个行业的一部分。 我想想象一下，如果我们没有另一个突破并进行讨论，会发生什么。就我而言，对于某些人和公司来说，期望似乎很正常，而对于另一些人和公司来说，期望却很高。但考虑到声音最大，我可能无法很好地区分信号和噪音 ​ 好吧，我知道有些人很难进行建设性思考，所以这里有一些想法点让你消化你的创意天才。  该领域的期望会发生什么 公司的期望会发生什么 什么合理的优化并且可以在模型外部进行改进    由   提交 /u/Semtioc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bw7lqh/d_conjecture_if_no_further_advances_in_deep/</guid>
      <pubDate>Fri, 05 Apr 2024 03:13:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] KDD 评论 2024</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bw7gsl/d_kdd_reviews_2024/</link>
      <description><![CDATA[今天不是应该发布 kdd 评论吗？   由   提交 /u/HighAfJoker   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bw7gsl/d_kdd_reviews_2024/</guid>
      <pubDate>Fri, 05 Apr 2024 03:06:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调还是持续预训练？出于教育目的调整米斯特拉尔教学模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvwl55/d_finetuning_or_continual_pretraining_adapting_a/</link>
      <description><![CDATA[大家好， 我正在尝试根据我的各种科目的教育内容训练现有的 Mistral Instruct 模型。根据这些数据训练模型最有效的方法是什么？我应该选择监督微调还是持续预训练？ 我最近看到一篇 Reddit 帖子和几篇论文，表明持续预训练并没有带来显着的改进。另一方面，多样化且高质量的指令集被证明可以提高输出质量和知识的准确性和效率。这一发现在论文“LIMA：Less Is More for Alignment”中也得到了强调。 我想知道选择哪种方法以及做出此决定的标准。此外，我很好奇微调与持续预训练的优缺点。 任何分享的见解或经验将不胜感激。预先感谢您的帮助！   由   提交 /u/aadityaura   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvwl55/d_finetuning_or_continual_pretraining_adapting_a/</guid>
      <pubDate>Thu, 04 Apr 2024 19:39:32 GMT</pubDate>
    </item>
    <item>
      <title>[D][P] 在研究中使用类似 3D 游戏的生成代理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvw9vy/dp_using_3d_gamelike_generative_agents_in_research/</link>
      <description><![CDATA[“生成代理” [Joon]论文一年前发表。它利用法学硕士为名为《超人前传》的 2D 游戏世界中的角色生成动作。它当时引起了很大的兴趣，但似乎并没有引起进行实际研究的人们的关注。 我的团队正在努力开源其 3D 版本。首先，我们开源了SAGA：技能到行动生成去年年底推出的 Agents，它从运行的模拟中抽象出动作生成。然后我们刚刚发布了Thistle Gulch，一个带有 python API 的 3D 城镇环境，它利用了 SAGA  我们认为其他研究人员对此感兴趣，但我们目前并没有真正看到类似的项目正在发生，并且不确定问题是否是缺乏兴趣或只是缺乏其他提供这样的项目的人。 RL 人员有诸如 Unity ML Agents、OpenAI Gym，甚至 Madrona 等。但这些通常更“机器人”喜欢的行为。有 Google SIMA，但那是关于训练人工智能玩游戏的意义不仅仅是环境本身。  我们认为对人们来说很重要的一些功能是：  高级 Python API - 研究人员需要 Python，但他们不是游戏程序员。 可定制 - 我确信这将非常依赖于研究人员。我可以看到只有一个标准化的环境并专注于动作生成，但其他人会希望拥有更多的能力来定制它。 视觉吸引力 - 这个可能不那么重要，但即使是研究现在也是关于吸引人们对你的工作的关注和兴趣，因此以视频形式访问你的工作结果似乎是一个非常重要的功能。如果您看看 SIMA，或者使用 Minecraft 作为平台的 Voyager [Fan] 就是很好的例子。 开源- 考虑到人们已经在使用《我的世界》等专有游戏，我实际上不确定这有多重要。有些有 API，但大多数都不是为此类事情设计的，所以使用起来很痛苦，而且无法根据您的需求进行更改。  那么，我有这个权利吗？或者我们还应该考虑什么？我很想更多地了解人们在这个领域的需求并建立一个社区。如果有人想聚在一起讨论的话，我也会参加八月份的新 RLConf。   由   提交 /u/frankcarey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvw9vy/dp_using_3d_gamelike_generative_agents_in_research/</guid>
      <pubDate>Thu, 04 Apr 2024 19:27:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 代理工作流程的人工审批工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvvrbv/p_a_human_approval_tool_for_agent_workflows/</link>
      <description><![CDATA[嘿。我们开发了由现有工具触发的 LLM 应用程序，例如客户支持票证到达，LLM 链启动以分析请求，确定下一步该做什么，例如编写响应。 但我们需要一种方法让用户检查和批准这些代理操作。如果没有简单的聊天会话，这会很棘手，而且我们没有找到任何可以帮助我们解决此问题的东西。 因此，我们开始开发一种可以集成到任何自定义 LLM 链中的人工监督工具。需要人类的认可吗？调用我们的 API，请求将发送至用户的收件箱，我们将通过 Webhook 给您回电并告知您的决定。 goto human .com 很高兴听到您的想法🙏   由   提交/u/tisi3000  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvvrbv/p_a_human_approval_tool_for_agent_workflows/</guid>
      <pubDate>Thu, 04 Apr 2024 19:08:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 语言模型作为编译器：模拟伪代码执行改进语言模型中的算法推理 - 延世大学 2024 - 在七个算法推理任务中比 CoT 和 PoT 好 10 到 20 个百分点！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvvqbl/r_language_models_as_compilers_simulating/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2404.02575  摘要：  算法推理是指理解问题背后复杂模式的能力并将它们分解为解决问题的一系列推理步骤。算法推理的这种性质使其对大型语言模型（LLM）构成挑战，尽管它们在其他推理任务中表现出了良好的性能。在此背景下，最近的一些研究受到严格而精确的语法的启发，使用编程语言（例如Python）来表达解决给定实例/问题（例如思维程序）所需的逻辑。然而，编写在单个推理调用中动态表达正确逻辑的可执行代码并非易事。此外，专门为某个实例生成的代码不能被其他实例重用，即使它们来自同一任务并且可能需要相同的逻辑来解决。本文提出了 Think-and-Execute，这是一种新颖的框架，它将语言模型的推理过程分解为两个步骤。 （1）在Think中，我们发现了一个在所有实例之间共享的任务级逻辑，用于解决给定的任务，然后用伪代码表达该逻辑； (2)在Execute中，我们进一步针对每个实例定制生成的伪代码并模拟代码的执行。通过对七个算法推理任务的广泛实验，我们证明了思考和执行的有效性。 与执行特定实例推理的几个强基线（例如 CoT 和 PoT）相比，我们的方法更好地改进了 LM 的推理，这表明发现任务级逻辑的帮助。此外，我们还表明，与自然推理相比，我们的方法可以更好地提高 LM 的推理能力。语言中，伪代码可以更好地指导 LM 的推理，即使它们经过训练可以遵循自然语言指令。   https:/ /preview.redd.it/c22euztvgisc1.jpg?width=1339&amp;format=pjpg&amp;auto=webp&amp;s=7795149c70c4d1f3c94b517500975a2ea7136e72 https://preview.redd.it/ow9wn1uvgisc1.jpg?width=1081&amp;format=pjpg&amp;auto=webp&amp;s =7c8d4f82190f26d3e2870dd6baba45910fef6be6 https ://preview.redd.it/z6qdt0uvgisc1.jpg?width=1083&amp;format=pjpg&amp;auto=webp&amp;s=f87bf65c38dd52f46ac6ea1af7a15e43277f8aa7  &amp;# 32；由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvvqbl/r_language_models_as_compilers_simulating/</guid>
      <pubDate>Thu, 04 Apr 2024 19:07:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] 推出世界上最大的用于人工智能训练的高质量合成开源文本到 SQL 数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvvg89/r_introducing_worlds_largest_highquality/</link>
      <description><![CDATA[Gretel 发布最大开源 Text-to-SQL 数据集，加速 AI 模型训练 https://gretel.ai/blog/synthetic-text-to-sql-dataset &lt; !-- SC_ON --&gt;  由   提交/u/alig80  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvvg89/r_introducing_worlds_largest_highquality/</guid>
      <pubDate>Thu, 04 Apr 2024 18:57:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] Octopus v2：超级代理的设备上语言模型 - 斯坦福 2024 - 将延迟提高 35 倍，并允许在智能手机上执行代理操作！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvv0by/r_octopus_v2_ondevice_language_model_for_super/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2404.01744  Github： https://huggingface.co/NexaAIDev/Octopus-v2 包括代码和模型！ 摘要：  语言模型已在各种软件应用程序中显示出有效性，特别是在与自动工作流程相关的任务中。这些模型拥有调用函数的关键能力，这对于创建人工智能代理至关重要。尽管云环境中的大规模语言模型具有高性能，但它们通常与隐私和成本问题相关。 当前用于函数调用的设备上模型面临延迟和准确性问题。我们的研究提出了一种新方法，使具有 20 亿个参数的设备上模型能够在准确性和准确性方面超越 GPT-4 的性能和延迟，并将上下文长度减少 95%。与具有基于 RAG 的函数调用机制的 Llama-7B 相比，我们的方法将延迟提高了 35 倍。此方法将延迟降低到适合在生产环境中的各种边缘设备上部署的水平，从而符合实际应用程序的性能要求。   https:// /preview.redd.it/sengb3jpbisc1.jpg?width=757&amp;format=pjpg&amp;auto=webp&amp;s=ff93e50487ea652e9b843e22481b9670dd2097d2 https://preview.redd.it/8gsad4jpbisc1.jpg?width=879&amp;format=pjpg&amp;auto=webp&amp;s =9ea2ba3fe385d9250c714548de43c9faef3be8ab   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvv0by/r_octopus_v2_ondevice_language_model_for_super/</guid>
      <pubDate>Thu, 04 Apr 2024 18:40:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] Deepmind - Mixture-of-Depths：在基于 Transformer 的语言模型中动态分配计算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvrduw/r_deepmind_mixtureofdepths_dynamically_allocating/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2404.02258 ​ 摘要 基于 Transformer 的语言模型在输入序列中均匀分布 FLOP。在这项工作中，我们证明 Transformer 可以学习将 FLOP（或计算）动态分配到序列中的特定位置，从而优化模型深度上不同层的序列分配。我们的方法通过限制可以参与给定层的自注意力和 MLP 计算的令牌数量 (k) 来强制执行总计算预算。要处理的令牌由网络使用 top-k 路由机制确定。由于 k 是先验定义的，因此与其他条件计算技术不同，这个简单的过程使用具有已知张量大小的静态计算图。然而，由于 k 个标记的身份是可变的，因此该方法可能会在时间和模型深度维度上不均匀地消耗 FLOP。因此，计算支出总体上是完全可预测的，但在令牌级别是动态的和上下文敏感的。以这种方式训练的模型不仅可以学习动态分配计算，而且可以高效地进行计算。这些模型与等效 FLOPS 和训练挂钟时间的基线性能相匹配，但每次前向传递只需要一小部分 FLOP，并且在训练后采样期间的步进速度可以快 50% 以上。 ​ https: //preview.redd.it/aez0hy66mhsc1.png?width=1282&amp;format=png&amp;auto=webp&amp;s=59d59bff1dbf7a0323a5e00cb16182bd0f5de9d4 ​ &lt; a href=&quot;https://preview.redd.it/ma6ewf06nhsc1.png?width=2138&amp;format=png&amp;auto=webp&amp;s=f4a845f0892ccb6c4ebe447425c3a0aaadebb03d&quot;&gt;https://preview.redd.it/ma6ewf06nhsc1.png?width =2138&amp;format=png&amp;auto=webp&amp;s=f4a845f0892ccb6c4ebe447425c3a0aaadebb03d   由   提交 /u/RedditLovingSun   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvrduw/r_deepmind_mixtureofdepths_dynamically_allocating/</guid>
      <pubDate>Thu, 04 Apr 2024 16:20:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] FMOps 基础设施堆栈的可视化。你的想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvqi0s/d_a_visualization_of_the_fmops_infrastructure/</link>
      <description><![CDATA[       由   提交 /u/vvkuka   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvqi0s/d_a_visualization_of_the_fmops_infrastructure/</guid>
      <pubDate>Thu, 04 Apr 2024 15:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 接受研究ML职位的降薪，这通常是一个好举动吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvj56a/discussion_accepted_a_salary_drop_for_a_ml/</link>
      <description><![CDATA[我于 2020 年从法国一所优秀大学（最好的大学之一，但不是最好的大学）毕业，获得了人工智能硕士学位。 我在一家美国科技公司（巴黎办事处）的数字营销领域工作了 3 年，担任数据科学家，一开始确实很酷，但这份工作很快就变得多余，更多的是软件工程而不是真正的数据科学，并且诚实、简单，足以由本科生完成，所有这一切都没有任何进化论的观点。我们开发的产品销量不够，最后全球气氛紧张。虽然福利很好，而且大多数人都很好，但团队中的每个数据科学家最终都离开了公司，我也是。 我有机会加入一个新的人工智能公共研究中心，作为一名研究机器学习工程师。这是我重返人工智能领域的绝佳机会。 该中心自 2020 年成立，内部成立了一个工程师团队，旨在：  帮助研究人员将他们的成果产业化通过支持他们开发开源包来进行研究 帮助组织活动以推广中心（暑期学校、黑客马拉松、研讨会等） 我的职位还包括监督该中心的创新部门，更准确地说，是支持该中心的合作机构创建的初创企业。  表面上，这份工作非常适合我，但是：   p&gt;  在 6 个月的时间里，我刚刚贡献了 2 个软件包，其中有一些小的贡献，例如重构、测试实现、文档等。没有真正的人工智能，而是人工智能项目的基本软件工程。这些项目真的很酷，研究人员也很优秀，但这些软件包并没有被经常使用，从我的角度来看，我的影响似乎很轻。 工程团队的成员，尤其是团队领导并不资深。个人资料和经验比我少，学位选择性也较差。此外，我与他们相处得并不融洽，而且没有团队合作，因为每个人都与不同的研究人员一起研究他的项目。 我们应该支持的初创公司似乎并不真正感兴趣在我们的支持下，他们通常会寻求我们团队中可能不具备的真正特定技能，并且为他们创造价值很复杂。 我们没有合适的办公室（没有为每个人提供的显示器，而且办公室是一个会议室改造成的一个开放空间），而我去那里的通勤往返需要3小时（必须每周2次）。此外，他们还给了我一台 13 英寸 MacBook Air，并告诉我，自从我到达那里后，我将拥有最新的 MacBook Pro，但每周都会推迟。 我接受了大幅降薪（10 %)  如果那里有高级机器学习工程师/数据科学家，我真的很想听听您对此的看法。   由   提交/u/brash69  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvj56a/discussion_accepted_a_salary_drop_for_a_ml/</guid>
      <pubDate>Thu, 04 Apr 2024 09:48:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士正在损害人工智能研究</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</link>
      <description><![CDATA[这是一个大胆的主张，但我觉得 LLM 的炒作早就该消退了。 GPT4 之后，LLM 性能和设计改进不仅取得了相对较小的进展：使其变得更好的主要方法仍然只是使其更大，并且所有 Transformer 的替代架构都被证明是低于标准和劣质的，它们引起了人们的关注（并且投资）远离其他可能更具影响力的技术。与此同时，大量涌入的人甚至不知道基本的机器学习是如何工作的，他们自称是“人工智能研究员”。因为他们使用 GPT 让每个人在本地托管一个模型，试图让你相信“语言模型完全可以推理”。我们只需要另一个 RAG 解决方案！”他们加入这个社区的唯一目标不是开发新技术，而是利用现有技术拼命拼凑出一项有利可图的服务。甚至论文本身也开始主要由法学硕士撰写。我不禁认为整个领域可能会陷入停滞状态，因为不断增长的社区满足于平庸的修复，这些修复充其量只能使模型在任意“分数”上的得分稍微好一些。他们弥补了这一点，忽略了诸如幻觉、上下文长度、基本逻辑缺乏能力以及运行这种规模模型的高昂成本等明显问题。我赞扬那些不顾市场炒作而致力于开发能够实现真正逻辑过程的代理的人们，并希望很快会引起更多关注。   由   提交/u/NightestOfTheOwls   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bvi4au/d_llms_are_harming_ai_research/</guid>
      <pubDate>Thu, 04 Apr 2024 08:36:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>