<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 12 Dec 2024 06:26:47 GMT</lastBuildDate>
    <item>
      <title>[N] 为 Liger-Kernel 中的 DPO 和 ORPO 节省 80% 的内存</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hcewdl/n_save_80_memory_for_dpo_and_orpo_in_ligerkernel/</link>
      <description><![CDATA[在 Liger Kernel 中引入第一个开源优化的训练后损失，内存减少约 80%，具有 DPO、CPO、ORPO、SimPO、JSD 等功能，通过更大的批量大小实现高达 70% 的端到端加速。将其用作任何 PyTorch 模块 - 今天在 Liger v0.5.0 中可用！ https://x.com/hsu_byron/status/1866577403918917655    提交人    /u/Icy-World-8359   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hcewdl/n_save_80_memory_for_dpo_and_orpo_in_ligerkernel/</guid>
      <pubDate>Thu, 12 Dec 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 进化的通用变形记忆体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hc6bs8/r_an_evolved_universal_transformer_memory/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hc6bs8/r_an_evolved_universal_transformer_memory/</guid>
      <pubDate>Wed, 11 Dec 2024 22:43:30 GMT</pubDate>
    </item>
    <item>
      <title>时间序列数据 Conv2D 教程 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hc5rel/conv2d_for_time_series_data_tutorial_discussion/</link>
      <description><![CDATA[有人能给我提供一个使用 TensorFlow 处理时间序列数据的教程，以及一个包含 Conv2D 层、AveragePooling2D 层和最终密集层的示例模型吗？    提交人    /u/chiplab   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hc5rel/conv2d_for_time_series_data_tutorial_discussion/</guid>
      <pubDate>Wed, 11 Dec 2024 22:18:34 GMT</pubDate>
    </item>
    <item>
      <title>推理图 TensorFlow 教程 [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hc5nyt/inference_graph_tensorflow_tutorial_project/</link>
      <description><![CDATA[有人能告诉我是否可以将以“.keras”格式保存的模型（TensorFlow）转换为推理图吗？如果可以，怎么做？（像分步教程一样）    提交人    /u/chiplab   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hc5nyt/inference_graph_tensorflow_tutorial_project/</guid>
      <pubDate>Wed, 11 Dec 2024 22:14:24 GMT</pubDate>
    </item>
    <item>
      <title>推理图 TensorFlow 教程 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hc5njm/inference_graph_tensorflow_tutorial_discussion/</link>
      <description><![CDATA[有人能告诉我是否可以将以“.keras”格式保存的模型（TensorFlow）转换为推理图吗？如果可以，怎么做？（像分步教程一样）    提交人    /u/chiplab   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hc5njm/inference_graph_tensorflow_tutorial_discussion/</guid>
      <pubDate>Wed, 11 Dec 2024 22:13:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在 NeurIPS 结交朋友和建立人脉？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hc0x89/d_how_to_make_friends_and_network_at_neurips/</link>
      <description><![CDATA[这是我第一次参加 NeurIPS，看到这么多人以及这么多招聘人员，我感到很受震撼。我来自一所不太知名的大学，独自一人来参加会议，甚至我的导师都不在。 我并没有和很多其他与会者或招聘人员交谈，因为 (1) 在一大群人中接近其他人似乎很难，(2) 我觉得自己有强烈的冒名顶替综合症，无法胜任招聘人员提供的工作。我只被接受了一篇研讨会论文，它更偏向于应用，不像其他许多学生那样技术性。 有什么建议可以让我充分利用会议的剩余时间吗？关于这一点，有人也想见面聊聊吗？我是来自英国的三年级博士生，但我自己来自温哥华，所以了解该地区的很多事情。干杯！    由    /u/K_is_for_Karma 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hc0x89/d_how_to_make_friends_and_network_at_neurips/</guid>
      <pubDate>Wed, 11 Dec 2024 18:54:26 GMT</pubDate>
    </item>
    <item>
      <title>[R] 连续潜在空间推理：通过连续思维链提高 LLM 性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbto1w/r_continuous_latent_space_reasoning_enhancing_llm/</link>
      <description><![CDATA[本文引入了COCONUT（连续思维链），将语言模型推理从离散的token空间转化为连续的潜在空间，其核心思想是将推理步骤编码为连续向量而不是文本token，从而实现更灵活、更精确的中间计算。 主要技术点： • 将文本↔连续向量映射的编码器-解码器架构 • 对潜在向量进行操作的新型连续推理模块 • 在连续空间中并行处理推理步骤 • 推理过程中基于梯度的优化 • 结合重建和推理目标的特殊损失函数 主要结果： • 与传统方法相比，推理基准提高了20% • 减少了解决复杂问题所需的计算步骤 • 在不同推理任务中获得更一致的性能 • 更好地处理数学和逻辑推理 • 增强了维持连贯推理链的能力 我认为这种方法可以有意义地推进语言模型处理复杂推理任务的方式。通过超越离散标记，模型可以更好地捕捉类似人类推理的连续性。在推理过程中在连续空间中进行优化的能力对于提高可靠性特别有希望。 我认为主要的挑战是将其扩展到非常大的模型，同时管理计算成本。离散空间和连续空间之间的转换增加了需要解决的开销。 TLDR：新方法将语言模型推理转换为连续向量空间而不是离散标记，通过更灵活的计算在推理任务上显示出 20% 的更好性能。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbto1w/r_continuous_latent_space_reasoning_enhancing_llm/</guid>
      <pubDate>Wed, 11 Dec 2024 13:39:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 掌握最先进的进化优化所需的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbt986/d_resources_to_get_up_to_the_speed_with_the_state/</link>
      <description><![CDATA[有很多好书可以让你接近该领域的最新水平，特别是机器学习和深度学习。但是，有没有关于进化优化的好现代书籍？有没有好的课程？    提交人    /u/ArtisticHamster   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbt986/d_resources_to_get_up_to_the_speed_with_the_state/</guid>
      <pubDate>Wed, 11 Dec 2024 13:17:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 任何可用于多种场景的 3D 重建方法（即不使用就扔）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbreb4/d_any_3d_reconstruction_method_that_can_be_used/</link>
      <description><![CDATA[NeRF 对于每个场景都是独一无二的，因此需要从头开始训练。高斯溅射也是场景所独有的。我理解场景很复杂，因此训练后几乎没有机会出现可以输出多个场景的神经网络。但是，是否仍然有一些场景表示在某种程度上没有被使用和完全抛弃？    提交人    /u/deathmaster2011   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbreb4/d_any_3d_reconstruction_method_that_can_be_used/</guid>
      <pubDate>Wed, 11 Dec 2024 11:27:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 评估生成模型中隐含的世界模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbra2d/r_evaluating_the_world_model_implicit_in_a/</link>
      <description><![CDATA[  由    /u/jsonathan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbra2d/r_evaluating_the_world_model_implicit_in_a/</guid>
      <pubDate>Wed, 11 Dec 2024 11:19:06 GMT</pubDate>
    </item>
    <item>
      <title>[R] 作者何时可以访问 ICLR 元评论？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbqc75/r_when_do_authors_have_access_to_iclr_metareviews/</link>
      <description><![CDATA[大家好， 这是我第一次向 ICLR 提交论文。ICLR 网站上说元评审将于今天（几个小时后）截止。作者可以在收到决定通知的同时还是在元评审截止日期后立即查看这些评审？ 谢谢！    提交人    /u/Glaze_anetha42   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbqc75/r_when_do_authors_have_access_to_iclr_metareviews/</guid>
      <pubDate>Wed, 11 Dec 2024 10:10:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 Stella 嵌入模型比其他同等质量的模型小得多？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hbkww5/d_why_are_the_stella_embedding_models_so_much/</link>
      <description><![CDATA[在 MTEB 排行榜上，stella_en_v5 目前排名第三，而使用的内存仅为前 10 名中所有非 Stella 模型的五分之一。 stella_en_400M_v5 排名第十，而使用的内存比排名在其附近的模型少 15-20 倍。这似乎在基准测试的几个子任务中相对一致（针对英语）。 这里的秘诀是什么？或者说，陷阱是什么？目前还没有论文。有人知道详细信息吗？    提交人    /u/-p-e-w-   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hbkww5/d_why_are_the_stella_embedding_models_so_much/</guid>
      <pubDate>Wed, 11 Dec 2024 03:58:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从失业到 Lisp：在青少年的深度学习编译器上运行 GPT-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hb7v5h/d_from_unemployment_to_lisp_running_gpt2_on_a/</link>
      <description><![CDATA[几个月前，我失业了，不知道下一步该做什么。我想从系统的角度更多地了解深度学习。在学习了吴恩达的监督学习课程后，我渴望更多地了解像 Pytorch 或 Tinygrad 这样的深度学习框架（或深度学习编译器）。 我开始研究 Tinygrad，从我在网上找到的教程中学习，我发现它很有趣，因为它是一个真正的编译器，它采用传统的 Python 代码并将其转换为抽象语法树，然后将其解析为 UOps 和 ScheduleItems，最终拥有一个代码生成层。虽然设计很有趣，但代码很难读。 就在那时，我偶然发现了一些完全出乎意料的东西，一个基于 Common Lisp 构建的深度学习编译器，由一名 18 岁的日本年轻人在他的间隔年期间维护。而目前我们已经完成了一件伟大的事情，它可以运行 gpt2！ 目前，它只是生成 C 内核，但未来我们希望支持 cuda codegen 以及许多其他功能，并作为任何想要使用 Common Lisp 进行深度学习编译器工作的人的学习工具。 这是一个开源项目，欢迎任何人做出贡献！ https://github.com/hikettei/Caten 编辑：添加一个关于它如何工作的示例。 这是我在另一个论坛上写的一个例子： 你好！谢谢你的提问。 首先，Caten 中有三个抽象层：  caten/apis | 高级图形接口 2. caten/air |低级图形接口 3. caten/codegen | AIR Graph =&gt; 内核生成器  编译器的输入只是 Common Lisp 类（类似于 torch 模块）。例如，在 Common Lisp 中，我们可以创建一个执行 SinCos 的模块：  (defclass SinCos (Func) nil (:documentation &quot;The func SinCos computes sin(cos(x))&quot;)) ;; Forward 为下一次计算创建一个惰性张量。 ;; 您可以使用 `st` 宏跳过此过程。 (defmethod forward ((op SinCos) &amp;rest tensors) (st &quot;A[~] -&gt; A[~]&quot; (tensors))) ;; Backward 是可选的（这次跳过）（defmethod behind ((op SinCos) &amp;optional prev-grad) (declare (ignore prev-grad)) nil）；； Lower 描述了 `SinCos` 的降低表达式 (defmethod lower ((op SinCos) &amp;rest input) (let ((x (car input))) (with-context (a (%sin (%add x (%fconst (/ pi 2))))) (b (%sin a)))))  `apis` 层是高级接口，而 `lower` 方法是代码生成之前的低级步骤。 接下来，框架生成一个抽象 VM (AVM) 表示：  #S(AVM :GRAPH Graph[seen=NIL, output=(STC6466_1)] { &lt;ALLOCATE : TID6464 &lt;- (shape=(1), stride=(1)) where :dtype=FLOAT32&gt; &lt;Node[BUFFER] ALLOCATE(NID6480) : SID6479* &lt;- ()&gt; &lt;Node[BINARYOPS] ADD(NID6484) : BID6483* &lt;- (TID6464, LID6481)&gt; &lt;Node[UNARYOPS] SIN(NID6486) : UID6485* &lt;- (BID6483)&gt; &lt;Node[UNARYOPS] SIN(NID6488) : UID6487* &lt;- (UID6485)&gt; &lt;Node[SPECIAL/VM] PAUSE/BACKWARD(NID6501) : STC6466_1* &lt;- (UID6487)&gt; })  然后，将计算图转化为调度项目：  FastGraph[outputs=(val_6)] { { Allocate } : [ val_0 &lt;- (1) ] { KERNEL } : [ val_5 &lt;- val_1, val_0 :name=FUSED_SIN_SIN_ADD_LOAD6511] }  最后，代码生成步骤生成以下 C 代码：  void fused_sin_sin_add_load6511(float* val_5, const float* restrict val_0); void fused_sin_sin_add_load6511(float* val_5, const float* restrict val_0) { val_5[0] = sin(sin((val_0[0] + 1.5707964))); }  此 C 代码由 C 编译器编译并执行。 因此，回答您的问题：编译器采用 Common Lisp 代码并生成 C 函数。    提交人    /u/yCuboy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hb7v5h/d_from_unemployment_to_lisp_running_gpt2_on_a/</guid>
      <pubDate>Tue, 10 Dec 2024 18:00:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>