<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Fri, 09 Aug 2024 12:28:49 GMT</lastBuildDate>
    <item>
      <title>[R] 探索 Kolmogorov-Arnold 网络在分类中的局限性：对软件训练和硬件实现的见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enx9be/r_exploring_the_limitations_of_kolmogorovarnold/</link>
      <description><![CDATA[      TL;DR：在训练计算方面，MLP 远远优于 KAN效率 论文： https://arxiv.org/pdf/2407.17790 摘要：  Kolmogorov-Arnold 网络 (KAN) 是一种新型神经网络，由于能够以更高的准确性和互操作性替代人工智能 (AI) 中的多层感知器 (MLP)，因此最近获得了普及和关注。然而，KAN 评估仍然有限，无法提供特定领域的深入分析。此外，还没有对 KAN 在硬件设计中的实现进行研究，这将直接证明 KAN 在实际应用中是否真正优于 MLP。因此，在本文中，我们专注于使用四种不同类型的数据集验证 KAN 的分类问题，这是 AI 中常见但重要的主题。此外，还考虑了使用 Vitis 高级综合 (HLS) 工具的相应硬件实现。据我们所知，这是第一篇为 KAN 实现硬件的文章。结果表明，在高复杂度数据集中，KAN 无法在利用大量硬件资源的情况下实现比 MLP 更高的准确度。因此，MLP 仍然是实现软件和硬件实现准确度和效率的有效方法。  亮点：  除了 Dry Bean 数据集的训练时间外，其他三个数据集始终表明 KAN 需要比 MLP 长得多的训练时间，范围从 6.55 倍（151.4 vs 23.1 秒）到 36.68 倍（198.1 vs 5.4 秒）。[...] 除了 Wine 数据集外，MLP 的损失减少速度一直比 KAN 更快，损失值也更低。总体而言，在训练时间和损失减少方面，KAN 并不比 MLP 更好。 总体而言，KAN 未能表现出比 MLP 更高的准确率，并且 KAN 的符号公式表示在分类挑战中的表现甚至比 MLP 更差。此外，KAN 还需要开发人员在最后阶段投入大量时间和精力来创建符号公式。  [专门的硬件测试：]  这些结果表明，与 MLP 中的正常矩阵乘法相比，在硬件上实现符号公式需要更多的硬件资源。此外，当 KAN 模型的规模增加时，所需的硬件资源也会相应增加。  视觉亮点： GPU 训练 有利于 MLP 的损失差异可能非常大。不过，Wine 数据集的快速 KAN 收敛值得注意。该数据集只有 178 个示例，每个示例有 13 个特征 GPU 训练 FPGA 训练 代码： https://github.com/Zeusss9/KAN_Analysis     由   提交  /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enx9be/r_exploring_the_limitations_of_kolmogorovarnold/</guid>
      <pubDate>Fri, 09 Aug 2024 11:27:45 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 请对我创建的应用程序提供 LLM 建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enwk3h/project_llm_advice_please_for_an_app_i_have/</link>
      <description><![CDATA[嗨，我在 Patreon 上有一个应用程序，大约有 450 名成员，其中 220 名付费，它允许用户与虚拟现实中的各种化身进行交互。该 AI 由一家大型 AI 游戏公司提供，但他们的许可结构正在发生变化，我认为我买不起新的许可证。 我想将我的应用程序（在 Unity 中制作）调整为使用不同的 AI 产品。我不想使用选择 LLM 的 AI 游戏公司，而是直接使用 LLM。我有使用 OpenAI 的 GPT API 的经验，但如果可能的话，我不想使用它，我想使用审查较少的 LLM。 我没有本地 LLM 的经验，我有一台配备 i7 7700k + 4090 + 32GB RAM 的 PC，我不确定这是否足够？可能不行。老实说，我认为我更喜欢不使用本地解决方案，而宁愿只使用在线服务的 API。 请提供一些建议（不是 OpenAI，如果可能的话不要本地，不要像 OpenAI 那样受到审查，但不必疯狂地不受审查，低延迟，可以在 Unity 中实现）。    提交人    /u/__tyke__   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enwk3h/project_llm_advice_please_for_an_app_i_have/</guid>
      <pubDate>Fri, 09 Aug 2024 10:45:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 GPT4o 与 langchain/chroma 进行体育分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enuzlp/p_using_gpt4o_with_langchainchroma_for_sports/</link>
      <description><![CDATA[大家好，我正在做一个业余项目，该项目有助于对历史比赛进行体育分析，进而有助于体育博彩。目前我只专注于 MLB，因为我想看看用例会如何发展。 我第一次尝试使用 openai 端点并加载所有相关的 JSON 对象，并将它们与提示一起发送到 GPT，看看我得到了什么。最终，上下文大小变得太大，我遇到的问题是它很昂贵。不过，返回的提示实际上相当不错，并且与数据相关。 我的第二次尝试是使用 Chroma/LangChain/GPT4o 设置 RAG。我让它工作了，但答案似乎都非常不准确，而且非常模糊。我所拥有的任何数据都没有显示在我所询问的任何提示中，或者在提示中根本没有提到正在玩游戏的任何玩家，而且在询问特定游戏时，它一直提到错误的游戏/团队。我假设我可能需要稍微调整一下矢量存储，但不确定如何使用色度来做到这一点。 我的问题是，设置某种流程的最佳方法是什么？我的最终结果是，我希望使用我提供的历史数据来回复，以便根据给出的所有统计数据对游戏可能是什么样子做出假设，同时也为 GPT 也留下一些推断的空间。 我在这方面还很陌生，所以到目前为止这是一个学习过程；请耐心等待。    提交人    /u/Previous_Impact1597   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enuzlp/p_using_gpt4o_with_langchainchroma_for_sports/</guid>
      <pubDate>Fri, 09 Aug 2024 09:02:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关我的求职机器学习项目的反馈</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enuq7p/d_seeking_feedback_on_my_machine_learning_project/</link>
      <description><![CDATA[大家好， 我正在申请政治学博士前奖学金，专注于计算冲突研究，并且我已经开发了一个示例项目来展示我的技能。我将不胜感激您可能提供的任何反馈或建议。 项目名称：机器学习用于恐怖主义数据分类 目标：应用机器学习技术对与冲突相关的文本进行分类，并根据全球恐怖主义数据库中的历史数据预测冲突结果。 展示的技能：机器学习、特征工程、模型训练和评估。 项目链接： 机器学习用于 1970 年至 2020 年东南亚恐怖主义数据分类的  职位描述： 政治学博士前研究员 我特别想听听您对以下方面的反馈：  项目概述的清晰度和结构。 所用方法和技术的有效性。 任何可以加强此类应用项目的其他元素。  提前感谢您的时间和见解！    提交人    /u/Lemmeaskyouonething   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enuq7p/d_seeking_feedback_on_my_machine_learning_project/</guid>
      <pubDate>Fri, 09 Aug 2024 08:45:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 24 数据集跟踪评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ent5sa/d_neurips_24_dataset_track_reviews/</link>
      <description><![CDATA[数据集和基准轨道评论应该在延迟后的今天发布。 我确信与主轨道相比，我们对此的关注度要小得多，但这可以作为讨论主题:)    提交人    /u/medcanned   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ent5sa/d_neurips_24_dataset_track_reviews/</guid>
      <pubDate>Fri, 09 Aug 2024 06:56:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 泰卢固语的 ASR 效果良好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eno3bf/d_good_asr_for_telugu/</link>
      <description><![CDATA[我们正在努力寻找适合泰卢固语音频的良好 ASR。尝试过 Google Speech to Text 和 whisper-large-v3，但 WER 超过 40%。确切的用例是转录和分析通话录音，这些录音通常混合了泰卢固语和英语。  提前感谢您的帮助 🙏    提交人    /u/BitAffectionate4586   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eno3bf/d_good_asr_for_telugu/</guid>
      <pubDate>Fri, 09 Aug 2024 02:11:16 GMT</pubDate>
    </item>
    <item>
      <title>[d] ReFT 的实际示例：14 分钟内在 Llama3 上完成表征微调</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enk8wm/d_practical_example_of_reft_representation/</link>
      <description><![CDATA[几周前，Arxiv ReFT 论文第一作者郑轩吴与 Oxen.AI 首席执行官 Greg Schoeninger 合作，深入探讨了 ReFT：表示微调。 在明天（星期五）的 AI Water Cooler 中，Oxen 实习生 Eric 将介绍： &quot;我如何在 14 分钟内使用 ReFT 对 Llama3 进行微调&quot; ReFT 的 TLDR：不是通过参数进行微调，而是在隐藏状态中插入表示来指导模型。 Eric 将展示早期 Arxiv Dive 的实际实现。 有用的细节：  AI Water Cooler 是深度技术不太正式、未经记录的空间 8 月 9 日星期五，太平洋时间上午 10:00 定期日历邀请：https://oxen.ai/community YouTube https://youtu.be/to2oKwnknUk?si=LmMMYxoryOn0UCwh Arxiv 论文链接：https://arxiv.org/pdf/2404.03592     提交人    /u/ReluOrTanh   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enk8wm/d_practical_example_of_reft_representation/</guid>
      <pubDate>Thu, 08 Aug 2024 23:10:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关 Perplexity Sonar 模型的深入信息：系统消息、上下文处理和 API 限制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1enk3mw/d_seeking_indepth_information_on_perplexitys/</link>
      <description><![CDATA[除了 Perplexity 文档中提供的内容外，是否还有其他关于 Sonar 模型的文档？ 我正在寻找有关“系统消息”、提示和/或第一个用户请求之间的行为差​​异的更多信息。据我了解，查询是基于“用户”消息生成的，查询生成会忽略“系统”消息。那么这个“系统”消息的用途到底是什么？这些示例通常使用简短的 3-4 个单词的短语，但 Sonar 模型是否支持更复杂的系统指令（类似于它们所训练的模型）？ 此外，在线模型如何处理多轮对话？查询生成和 RAG 使用什么上下文？我理解这些模型适用于单轮交互，而“聊天”版本可用于多轮对话。 这引出了我关于上下文长度的问题。在线模型声称拥有 128K 上下文，但这在实践中似乎无法实现。如果用户消息太长，查询生成效率会降低，检索到的相关结果也会减少。即使多轮聊天也无法实现更高的上下文，因为质量会显著下降。 值得注意的是，作为“源”提供给模型的标记数量通常在全球范围内在 2-3K 范围内，但通常会少得多，具体取决于问题的复杂性（通过 API）。 有人对这些问题有见解吗？工作人员可以给我提供更详细的信息吗？ 提前谢谢！    提交人    /u/Distinct-Target7503   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1enk3mw/d_seeking_indepth_information_on_perplexitys/</guid>
      <pubDate>Thu, 08 Aug 2024 23:03:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] OpenAI：API 中的结构化输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1endf5w/d_openai_structured_outputs_in_the_api/</link>
      <description><![CDATA[https://openai.com/index/introducing-structured-outputs-in-the-api/ 只是好奇，为什么这是一件大事？你看到任何用例了吗？    提交人    /u/dmpetrov   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1endf5w/d_openai_structured_outputs_in_the_api/</guid>
      <pubDate>Thu, 08 Aug 2024 18:27:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] DistilBERT 基础多语言（大小写）葡萄牙语</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en74uf/d_distilbert_base_multilingual_cased_for/</link>
      <description><![CDATA[有人用过 DistilBERT 基础多语言（大小写）来处理葡萄牙语吗？如果是，你的结果如何？它好用吗？ 提前致谢。    提交人    /u/mr_house7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en74uf/d_distilbert_base_multilingual_cased_for/</guid>
      <pubDate>Thu, 08 Aug 2024 14:16:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] FlexAttention：PyTorch 的灵活性与 FlashAttention 的性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</link>
      <description><![CDATA[https://pytorch.org/blog/flexattention/    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en6h4b/d_flexattention_flexibility_of_pytorch_with/</guid>
      <pubDate>Thu, 08 Aug 2024 13:49:55 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 我需要什么数学背景才能阅读 Le Cam 的《充分性和近似充分性》论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1en55pb/research_what_mathematical_background_do_i_need/</link>
      <description><![CDATA[嗨， 我是一名统计学家，出于研究目的，我想阅读 Le Cam 提到的论文。我遇到的困难是它使用了诸如向量格、正正则化线性函数、格对偶等术语。 因此，我的问题是：我需要什么样的数学先决条件才能阅读此类论文？ 我做过标准线性代数、实分析（单变量和多变量）、测度论、概率论内容、一些点集拓扑，但从未见过这样的对象，所以我认为这可能与抽象代数有关，但我不知道从哪里开始才能读懂这篇文章。 任何帮助都将不胜感激。谢谢！   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1en55pb/research_what_mathematical_background_do_i_need/</guid>
      <pubDate>Thu, 08 Aug 2024 12:52:00 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 多模式人工智能聊天机器人令人费解的失败</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1emi095/research_the_puzzling_failure_of_multimodal_ai/</link>
      <description><![CDATA[      https://preview.redd.it/ummnvenf1ahd1.png?width=2592&amp;format=png&amp;auto=webp&amp;s=7115ba5de026ada17b0636ec2fa3c3151b3e5eb6 GPT-4o 和 Gemini 等聊天机器人模型在理解图像和文本方面表现出了令人印象深刻的能力。然而，它们是否能模仿人类的一般智力和推理能力尚不清楚。为此，PuzzleVQA 是多模式拼图的新基准，用于探索当前模型的极限。如上所示，即使是 GPT-4V 这样的模型也很难理解儿童可以掌握的简单抽象模式。 https://preview.redd.it/7l5fmuys1ahd1.png?width=2716&amp;format=png&amp;auto=webp&amp;s=337118dbc55230637cec1b08b90ae943746ddbb0 尽管谜题看似简单，但我们观察到当前多模态 AI 模型的表现却出奇地差。值得注意的是，与人类的表现仍然存在巨大差距。因此，自然而然地出现了一个问题：是什么导致了模型的失败？为了回答这个问题，我们进行了瓶颈分析，逐步为模型提供真实“提示”，例如用于感知或推理解释的图像标题。如上所示，我们发现领先的模型在视觉感知和归纳推理方面面临关键挑战。这意味着他们无法准确地感知图像中的物体，并且在识别正确的模式方面也很差。 https://arxiv.org/abs/2403.13315    提交人    /u/chiayewken   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1emi095/research_the_puzzling_failure_of_multimodal_ai/</guid>
      <pubDate>Wed, 07 Aug 2024 17:33:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ejkdhj/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 04 Aug 2024 02:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>