<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sat, 19 Oct 2024 01:14:14 GMT</lastBuildDate>
    <item>
      <title>[D] 评估生产中的分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6w6za/d_evaluating_classification_in_production/</link>
      <description><![CDATA[对于 Facebook、Youtube、LinkedIn 等，他们如何在生产中评估其有害内容检测模型？如果是离线，可以使用精度、召回率、F1。由于我们不知道生产过程中的标签是什么，他们使用什么指标进行评估/监控？    提交人    /u/lalalagay   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6w6za/d_evaluating_classification_in_production/</guid>
      <pubDate>Fri, 18 Oct 2024 23:53:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用气象雷达数据</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6tmvv/d_working_with_weather_radar_data/</link>
      <description><![CDATA[我已经开始处理天气雷达数据，这些数据以原始二进制格式提供 - 转换为 IRIS 格式以方便访问和计算，但需要对数据执行机器学习以做出未来预测。 有没有很好的来源可以理解这样的数据，以及与这种类型的数据相关的 AI / ML 技术？    提交人    /u/Mynameiswrittenhere   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6tmvv/d_working_with_weather_radar_data/</guid>
      <pubDate>Fri, 18 Oct 2024 21:49:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 仍然无法规划；LRM 可以吗？OpenAI 在 PlanBench 上对 o1 的初步评估</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6qpeq/r_llms_still_cant_plan_can_lrms_a_preliminary/</link>
      <description><![CDATA[论文：https://www.arxiv.org/abs/2409.13373 “虽然 o1 的性能在基准上有了很大的改进，超过了竞争对手，但它还远远没有达到饱和状态。” 总结很恰当。o1 看起来是一个非常令人印象深刻的改进。同时，它揭示了剩余的差距：随着组合长度的增加而退化，成本增加 100 倍，并且当“检索”因名称混淆而受到阻碍时，退化程度大大降低。 但是，我想知道这是否足够接近。例如，这种类型的模型至少足以提供合成数据/监督来训练可以填补这些空白的模型。如果是这样，恕我直言，很快就能找到答案。 此外，作者还添加了一些辛辣的脚注。例如： “研究人员使用纳税人提供的研究资金来向 OpenAI 等私人公司支付费用，以评估其私人商业模式，这种讽刺意味当然在我们心中挥之不去。”    提交人    /u/marojejian   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6qpeq/r_llms_still_cant_plan_can_lrms_a_preliminary/</guid>
      <pubDate>Fri, 18 Oct 2024 19:36:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM 解码中保存的注意力？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6ozlr/d_attention_saved_in_llm_decoding/</link>
      <description><![CDATA[在 LLM 生成（解码）过程中，是否每一步都要重新计算全部注意力？我知道像 KV 缓存这样的东西用于保存之前的键/值向量，但是它们的注意力分数怎么办？还是只计算当前查询的注意力？ 谢谢！    提交人    /u/BigYounzzz   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6ozlr/d_attention_saved_in_llm_decoding/</guid>
      <pubDate>Fri, 18 Oct 2024 18:22:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用原始语音/音频进行情绪分类 - 有任何资源和指导吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6o94x/d_emotion_classification_using_raw_speechaudio/</link>
      <description><![CDATA[大家好， 我正在做一个使用原始语音/音频数据进行情绪识别/分类的项目，但遇到了一个障碍。与大多数将音频转录为文本然后进行情绪分析的方法不同，我想直接从音频信号中对情绪进行分类。 有没有人参与过或知道任何使用原始音频特征进行情绪分类的著名项目/研究？ 如能提供任何指导、论文推荐或代码库，我们将不胜感激。 TLDR：寻求使用原始语音/音频数据进行情绪分类的资源和专业知识，而无需转换为文本。    提交人    /u/Low-Champion-4194   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6o94x/d_emotion_classification_using_raw_speechaudio/</guid>
      <pubDate>Fri, 18 Oct 2024 17:50:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 后塌陷检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6l9qv/d_testing_for_posterior_collapse/</link>
      <description><![CDATA[我有一个基于我的数据集训练的 VAE。它表现出以下特点  编码器产生的模型参数非常接近。大多数参数都落在 1e-1 和 1e-2 之间。对数方差类似。 采样新点始终返回 0。 训练数据在经过几个时期后也全部变为 0。  我怀疑模型的指定不充分。但是，如果我忽略 kl 损失，情况会有所改善（我只训练了 50 个时期）。我想知道模型是否正在遭受后验崩溃。 如何测试该假设？    提交人    /u/Chr0nomaton   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6l9qv/d_testing_for_posterior_collapse/</guid>
      <pubDate>Fri, 18 Oct 2024 15:45:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用“部分实现的数据”解决时间序列问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6hpto/d_how_to_approach_a_time_series_problem_with/</link>
      <description><![CDATA[大家好， 我被分配了一个工作问题需要解决，由于我对时间序列没有太多经验，所以这感觉像是一个不太容易建模的问题。我必须使用 Python 来实现这一点，而不是 R，所以我知道我的选择可能更有限？ 简而言之，  我有 2021-01-01 至 2022-07-31 之间 19 个月的每日客户下单数据。这给了我下单的天数、订单数量以及交易金额（$）。没有其他外生信息可立即获得； 我试图预测下个月（8 月 22 日）的订单天数（是/否目标，而不是计数）；需要注意的是，我只有 8 月份的部分信息，即数千个帐户已在 8 月份下了一个或多个订单，我在启动模型之前就掌握了这些信息。因此，我的目标是在进行预测时考虑到这一点。 我看到了两种解决方法：1) 最快/最简单的方法可能是使用部分实现的数据对 8 月份的 31 天进行建模，然后仅使用从本月预测的订单中“折扣”的订单；2) 似乎是正确的做法，但更难，即使用 8 月份的这些额外数据对 8 月份做出更好的预测； 我真的不知道我在寻找什么文献；当我问“要研究什么/要寻找什么”时，gpt 向我抛出了一些术语，例如“部分实现的滚动预测”、“使用不完整数据的预测”、“删失数据预测”、“实时预测”、“使用部分信息的现在预测”、“间歇性需求预测”。 我对统计学有一定的了解，接触过生存分析和删失数据，但正在试水，看看是否有更简单的方法可用。  谢谢！ 编辑：了解了面板数据建模的框架！现在正在研究它。    提交人    /u/pdr07   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6hpto/d_how_to_approach_a_time_series_problem_with/</guid>
      <pubDate>Fri, 18 Oct 2024 13:11:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于时间序列的多模态神经网络？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6gcxl/d_multimodal_neural_networks_for_time_series/</link>
      <description><![CDATA[我正在寻找一个可以处理非时间序列输入的时间序列神经网络。 具体来说，一个神经网络，我可以给它一个主要时间序列（可能还有额外的辅助时间序列），以及一些关于这个特定时间序列的属性。目标是预测主要时间序列。 例如，假设我有个人家庭能源消耗，但我的测量结果并非全部来自同一时间段。有些房子我只拥有 2023 年的数据，而其他房子则从 2024 年开始，等等。为了配合这些能源消耗时间序列，我可能会有关于消费者家庭的其他信息，比如房子的大小或住在房子里的人数，或者只是一个唯一的 house_id。我想在这种时间序列上训练我的神经网络，在某种嵌入中利用这些附加参数，使得神经网络在给定特定嵌入时能够为这些家庭中的任何一个生成准确的预测。 所以看起来像： forecasting=model(input_time_serie,auxiliary_time_series,additional_properties) 其中input_time_serie是长度为n的单个时间序列向量，auxiliary_time_series是长度为n的可选时间序列（可以是室外温度、一周中的时间等），additional_properties是一个长度为m的向量，包含属性参数，它以某种方式嵌入神经网络内部，允许神经网络区分两个不同的家庭。 这样的神经网络有望用于零样本预测，在这种情况下我们还没有家庭的实际能源消耗，只有嵌入数据。 我知道https://github.com/thuml/Time-Series-Library，但所有这些类型的神经网络的问题在于，它们期望所有不同的时间序列作为输入，因此每个家庭一个，但当我的时间序列实际上没有重叠时，这不起作用，当我想对不在训练数据集中的新家庭进行零样本预测时，它也不起作用。 那么有谁知道有哪个神经网络能够做到这样的事情吗？或者有谁对如何修改神经网络以合理地包含属性嵌入有什么好的想法？    提交人    /u/alyflex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6gcxl/d_multimodal_neural_networks_for_time_series/</guid>
      <pubDate>Fri, 18 Oct 2024 12:01:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 主流 LLM 标记器的局限性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6dc8l/r_limitations_in_mainstream_llm_tokenizers/</link>
      <description><![CDATA[主流 LLM 标记器无法编码和解码为精确的字符串。这意味着它们不是无损的。一些 Llama、Mistral 和 Phi 标记器无法编码字符串 &#39; 谁放了狗？！ !&#39;，然后解码为相同的字符串。 如果运行代码：```python from transformers import AutoTokenizer models = [ &#39;meta-llama/Llama-2-7b&#39;, &#39;meta-llama/Meta-Llama-3-8B&#39;, &#39;meta-llama/Llama-3.1-8B&#39;, &#39;mistralai/Mistral-7B-v0.3&#39;, &#39;mistralai/Mixtral-8x7B-v0.1&#39;, &#39;mistralai/Mixtral-8x22B-v0.1&#39;, &#39;mistralai/Mistral-Nemo-Instruct-2407&#39;, &#39;mistralai/Mistral-Small-Instruct-2409&#39;, &#39;mistralai/Mistral-Large-Instruct-2407&#39;, &#39;microsoft/phi-1&#39;, &#39;microsoft/phi-1_5&#39;, &#39;microsoft/phi-2&#39;, &#39;microsoft/Phi-3-mini-4k-instruct&#39;, &#39;microsoft/Phi-3.5-mini-instruct&#39;, ] text = &#39; 谁放了狗？！&#39; for n in models: tokenizer = AutoTokenizer.from_pretrained(n) text2 = tokenizer.decode(tokenizer.encode(text, add_special_tokens=False)) if text2 == text: print(&#39;OK: &#39;, n, repr(text2)) else: print(&#39;ERR:&#39;, n, repr(text2))  ``` 您将得到： OK: meta-llama/Llama-2-7b &#39; 谁放了狗？！&#39; ERR: meta-llama/Meta-Llama-3-8B “谁放出了狗？！！” ERR: meta-llama/Llama-3.1-8B “谁放出了狗？！！” ERR: mistralai/Mistral-7B-v0.3 “谁放出了狗？！！” OK: mistralai/Mixtral-8x7B-v0.1 “谁放出了狗？！！” ERR: mistralai/Mixtral-8x22B-v0.1 “谁放出了狗？！！” OK: mistralai/Mistral-Nemo-Instruct-2407 “谁放出了狗？！！” OK: mistralai/Mistral-Small-Instruct-2409 “谁放出了狗？！！” OK：mistralai/Mistral-Large-Instruct-2407 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-1 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-1_5 &#39;谁放出了狗？！&#39; ERR：microsoft/phi-2 &#39;谁放出了狗？！&#39; OK：microsoft/Phi-3-mini-4k-instruct &#39;谁放出了狗？！&#39; OK：microsoft/Phi-3.5-mini-instruct &#39;谁放出了狗？！&#39;  所有标有 ERR 的都无法编码​​并解码为相同的字符串。    提交人    /u/mtasic85   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6dc8l/r_limitations_in_mainstream_llm_tokenizers/</guid>
      <pubDate>Fri, 18 Oct 2024 08:35:43 GMT</pubDate>
    </item>
    <item>
      <title>医学成像人工智能顶级会议 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6bu6z/top_conferences_for_ai_in_medical_imaging_d/</link>
      <description><![CDATA[抱歉，标题中不能有“AGI”。 我正在研究我的第一篇第一作者研究，我的导师认为它的发展方向很好。我真的希望它明年能通过一些好的会议。 我知道 MICCAI 和 MIDL，但找不到可靠的来源来检查 2025 年与医学成像或医学 AI 相关的所有其他会议。我希望这里的人一定有一些其他经验。有什么建议吗？ 另外，研讨会论文是什么意思？我知道它不叫真正的出版物，但它值得提交给一个备受推崇的研讨会还是一个中等排名的会议？ 提前谢谢！    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6bu6z/top_conferences_for_ai_in_medical_imaging_d/</guid>
      <pubDate>Fri, 18 Oct 2024 06:37:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对于“迷失于中间”现象是否存在一个普遍认可的解释？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g6avhy/d_is_there_a_universally_agreed_explanation_for/</link>
      <description><![CDATA[自从我在攻读长语境法学硕士 (LLM) 期间阅读“Lost in the Middle”论文以来，已经有一段时间了。我很好奇是否有一篇论文提出了对这种影响的广泛接受的解释，或者是否有任何方法可以有效地解决或克服它。    提交人    /u/StraightSpeech9295   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g6avhy/d_is_there_a_universally_agreed_explanation_for/</guid>
      <pubDate>Fri, 18 Oct 2024 05:28:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 2.5.0 发布！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g62vyh/d_pytorch_250_released/</link>
      <description><![CDATA[https://github.com/pytorch/pytorch/releases/tag/v2.5.0 亮点：我们很高兴地宣布 PyTorch® 2.5 的发布！此版本为 SDPA 提供了新的 CuDNN 后端，默认情况下，为 H100 或更新 GPU 上的 SDPA 用户启用加速。此外，torch.compile 的区域编译提供了一种减少 torch.compile 冷启动时间的方法，它允许用户编译重复的 nn.Module（例如 LLM 中的转换器层）而无需重新编译。最后，TorchInductor CPP 后端通过 FP16 支持、CPP 包装器、AOT-Inductor 模式和最大自动调谐模式等众多增强功能提供了可靠的性能加速。此版本由 504 位贡献者自 PyTorch 2.4 以来的 4095 次提交组成。我们衷心感谢我们敬业的社区所做的贡献。 我最喜欢的一些改进：  通过重复使用重复模块加快 torch.compile 编译速度 torch.compile 支持 torch.istft FlexAttention：一种灵活的 API，只需几行惯用的 PyTorch 代码即可实现各种注意机制，如滑动窗口、因果掩码和 PrefixLM。此 API 利用 torch.compile 生成融合的 FlashAttention 内核，从而消除了额外的内存分配并实现了与手写实现相当的性能。此外，我们使用 PyTorch 的自动求导机制自动生成向后传递。此外，我们的 API 可以利用注意力掩码中的稀疏性，从而比标准注意力实现有显著的改进。     提交人    /u/parlancex   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g62vyh/d_pytorch_250_released/</guid>
      <pubDate>Thu, 17 Oct 2024 22:11:36 GMT</pubDate>
    </item>
    <item>
      <title>[P] 如何使用 LLM 从 500k 条聊天信息中提取见解？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g5yn4b/p_how_to_extract_insights_from_500k_chat_messages/</link>
      <description><![CDATA[大家好， 我从 AI 上的 discord 服务器下载了聊天消息，2-3 年间总计约 50 万条消息。我这样做的原因是我想提取有关该主题的见解/提示和技巧，而这些见解/提示和技巧可能在在线教程中找不到（我一直发现在 discord 服务器中，人们互相帮助比阅读各种博客文章/教程更有信息量）。 它们总计约 800 万个代币，使用 gpt-4o-mini 需要花费 1-2 美元，使用 gpt-4o 需要花费 20-30 美元，这是相当合理的。 但是，我正在尝试弄清楚两件事： 1) 我是否可以使用本地 llm 来完成部分流程。这是首选，因为虽然 gpt-4o-mini 只需花费 1 到 2 美元，但这是每个提示的价格，而且我可能希望以多种方式查询/处理数据。 2) 我到底能做些什么来提取最有价值的见解？可能 95% 的聊天只是玩笑，但 5% 可能充满了有用的建议。我可以使用什么样的提示？我该如何处理需要分块输入以适应上下文窗口的事实？ 我愿意学习和探索任何新的主题来解决这个问题，因为我很高兴把它作为一个项目来接触 LLM。    提交人    /u/PMMEYOURSMIL3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g5yn4b/p_how_to_extract_insights_from_500k_chat_messages/</guid>
      <pubDate>Thu, 17 Oct 2024 19:04:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1g2fmfw/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 13 Oct 2024 02:15:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>