<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 09 Sep 2024 01:13:14 GMT</lastBuildDate>
    <item>
      <title>[讨论] 学习数据科学中的真实世界模型架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fccipd/discussion_learning_realworld_model_architectures/</link>
      <description><![CDATA[  由    /u/jiraiya1729  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fccipd/discussion_learning_realworld_model_architectures/</guid>
      <pubDate>Mon, 09 Sep 2024 00:21:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 渐进式策略和过早的残局</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fcapxf/d_incremental_gambits_and_premature_endgames/</link>
      <description><![CDATA[        由   提交  /u/Mooseton   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fcapxf/d_incremental_gambits_and_premature_endgames/</guid>
      <pubDate>Sun, 08 Sep 2024 22:55:11 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 TsetlinMachine 库 Tsetlin.jl 中的最新优化，在 CPU 上实现每秒超过 1 亿个 MNIST 预测（吞吐量为 55.5 GB/s）。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fc3ji0/p_achieved_over_100_million_mnist_predictions_per/</link>
      <description><![CDATA[      这个周末，我优化了 TsetlinMachine 库 Tsetlin.jl，取得了出色的成绩：在我的 Ryzen 7950X3D CPU 上每秒可进行 1.01 亿次 MNIST 预测，准确率为 98.10%。这个性能已经接近硬件的最大能力，因为双通道模式下 DDR5 RAM 在 6000 MT/s 下的峰值速度为 96 GB/s。我的吞吐量达到了 55.5 GB/s，主要是因为这个特定的 Tsetlin Machine 模型有 10499 个参数，而 CPU 缓存（尤其是 3D 缓存）在提升性能方面起着重要作用。 https://preview.redd.it/0a719tythmnd1.png?width=1780&amp;format=png&amp;auto=webp&amp;s=001526f65f3be2b99ce2a24ffe4b5bb5486f474e    由    /u/ArtemHnilov  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fc3ji0/p_achieved_over_100_million_mnist_predictions_per/</guid>
      <pubDate>Sun, 08 Sep 2024 17:42:23 GMT</pubDate>
    </item>
    <item>
      <title>聚类算法比较[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fc0niz/clustering_algorithms_comparison_d/</link>
      <description><![CDATA[我想看看是否有论文或文章对不同的聚类算法在优点、缺点和特殊性方面进行比较，我自己还没有找到任何像样的东西    提交人    /u/Extension-Group2131   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fc0niz/clustering_algorithms_comparison_d/</guid>
      <pubDate>Sun, 08 Sep 2024 15:38:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbzs8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 08 Sep 2024 15:00:19 GMT</pubDate>
    </item>
    <item>
      <title>[P]: TensorHue – 张量可视化库（详情见评论）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbz318/p_tensorhue_a_tensor_visualization_library_info/</link>
      <description><![CDATA[        提交人    /u/epistoteles   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbz318/p_tensorhue_a_tensor_visualization_library_info/</guid>
      <pubDate>Sun, 08 Sep 2024 14:29:13 GMT</pubDate>
    </item>
    <item>
      <title>市场组合建模数据 [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbyal0/data_for_market_mix_modelling_project/</link>
      <description><![CDATA[大家好， 我刚刚完成了对机器学习概念的学习。现在，我正计划为我的简历创建一个端到端的市场组合建模项目，但不知道在哪里可以获取数据。如能提供建议，我们将不胜感激。 谢谢    提交人    /u/abhi_pal   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbyal0/data_for_market_mix_modelling_project/</guid>
      <pubDate>Sun, 08 Sep 2024 13:53:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过 LLM 实现隐写术的 Python 工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbx3ny/p_python_tool_for_steganography_through_llms/</link>
      <description><![CDATA[https://github.com/user1342/Tomato    由   提交  /u/OppositeMonday   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbx3ny/p_python_tool_for_steganography_through_llms/</guid>
      <pubDate>Sun, 08 Sep 2024 12:54:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 训练具有多种损失的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbvuhs/r_training_models_with_multiple_losses/</link>
      <description><![CDATA[我们建议使用 雅可比下降 来同时最小化多个损失，而不是使用梯度下降来最小化单个损失。基本上，该算法通过将（向量值）目标函数的雅可比矩阵简化为更新向量来更新模型的参数。 为了让每个人都能使用它，我们开发了 TorchJD：一个扩展 autograd 以支持雅可比下降的库。在简单的 pip install torchjd 之后，转换基于 PyTorch 的训练函数非常容易。随着最近发布的 v0.2.0，TorchJD 终于支持多任务学习了！ Github：https://github.com/TorchJD/torchjd 文档：https://torchjd.org 论文：https://arxiv.org/pdf/2406.16232 我们很乐意听到社区的一些反馈。如果您想支持我们，请在 repo 上点个星，我们将不胜感激！我们也欢迎讨论和批评。    提交人    /u/Skeylos2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbvuhs/r_training_models_with_multiple_losses/</guid>
      <pubDate>Sun, 08 Sep 2024 11:43:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医疗 AI：顶级研究论文/模型🏅（2024 年 9 月 1 日至 9 月 7 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbe5qg/d_last_week_in_medical_ai_top_research/</link>
      <description><![CDATA[   本周热门论文（2024 年 9 月 1 日至 9 月 7 日） 医学 LLM 及其他模型：  CancerLLM：癌症领域的大型语言模型  CancerLLM，一个为癌症特定任务设计的 70 亿参数模型。对 17 种癌症类型的 267 万份临床记录和 515,524 份病理报告进行了预训练。   MedUnA：用于医学图像的视觉语言模型  本文介绍了医学无监督适应（MedUnA）。它使用 BioBERT 将文本嵌入与类标签对齐，然后与 MedCLIP 的视觉编码器集成，通过对比熵损失实现视觉文本对齐。  机器人内窥镜手术的基础模型  本文介绍了机器人内窥镜手术中的深度一切 (DARES)，它引入了 Vector-LoRA，一种用于机器人辅助手术 (RAS) 中自监督单目深度估计的新型自适应技术。  Med-MoE：用于医学视觉语言模型的 MoE  本文介绍了 Med-MoE（Mixture-of-Experts），这是一个专为判别和生成多模态医疗任务而设计的轻量级框架。 Med-MoE 分三个阶段运作：  CanvOI：肿瘤学基础模型  本文介绍了 CanvOI，一种基于 ViT-g/10 的数字病理学基础模型，针对肿瘤组织病理学图像进行了优化。   医疗基准和评估：  TrialBench：临床试验数据集和基准  用于医学问答评估的 LLM  MedFuzz：探索稳健性医学 LLM  MedS-Bench：评估临床任务中的 LLM  DiversityMedQA：评估诊断中的 LLM 偏见  LLM 数字孪生：  用于罕见妇科肿瘤的数字孪生 DT-GPT：用于患者健康预测的数字孪生  ....  详细查看完整线程：https://x.com/OpenlifesciAI/status/1832476252260712788 感谢您的阅读！如果您知道任何遗漏的有趣论文，请随时在评论中分享。如果您对医疗 AI 有见解或突破，并希望在下周的版本中分享，请通过 Twt/x 与我们联系：OpenlifesciAI    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbe5qg/d_last_week_in_medical_ai_top_research/</guid>
      <pubDate>Sat, 07 Sep 2024 18:49:25 GMT</pubDate>
    </item>
    <item>
      <title>我尝试编写自己的 YOLO 模型来检测足球运动员 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbc185/i_tried_to_code_my_own_yolo_model_to_detect/</link>
      <description><![CDATA[       由    /u/AvvYaa  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbc185/i_tried_to_code_my_own_yolo_model_to_detect/</guid>
      <pubDate>Sat, 07 Sep 2024 17:15:58 GMT</pubDate>
    </item>
    <item>
      <title>[R] 利用长距离深度学习对硬件加密进行广义功率攻击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbbbb3/r_generalized_power_attacks_against_hardware/</link>
      <description><![CDATA[      https://preview.redd.it/8x0oesms1fnd1.jpg?width=2000&amp;format=pjpg&amp;auto=webp&amp;s=3d3d331ddb4ebf23eface0d49b312b28cd5e2fcd 星期六快乐 我很高兴地宣布，经过 3 年的研发，我们终于发布了 GPAM，我们的通用模型电源侧信道攻击模型：  幻灯片&amp; 论文：https://elie.net/publication/generalized-power-attacks-against-crypto-hardware-using-long-range-deep-learning 代码 &amp;数据集：https://github.com/google/scaaml/tree/main/papers/datasets/ECC/GPAM  与以前的方法相比，GPAM 代表了一代人的飞跃，因为它能够攻击多种算法（AES、ECC）和对策，而无需人工干预并且无需预处理输入跟踪。它确实需要一些自动超调优，因此：每次攻击约 700 GPU/h。    提交人    /u/ebursztein   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbbbb3/r_generalized_power_attacks_against_hardware/</guid>
      <pubDate>Sat, 07 Sep 2024 16:44:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] Adam 优化器导致 Transformer 语言模型中出现特权基础</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fbavdv/r_adam_optimizer_causes_privileged_basis_in/</link>
      <description><![CDATA[        由    /u/rrenaud  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fbavdv/r_adam_optimizer_causes_privileged_basis_in/</guid>
      <pubDate>Sat, 07 Sep 2024 16:26:05 GMT</pubDate>
    </item>
    <item>
      <title>[P]⚡️最快的预训练代码：9天获得LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fb6fet/pfastest_pretraining_code_llm_in_9_days/</link>
      <description><![CDATA[我们仅用 9 天就创建了一个在 MT-Bench 上表现优于 OpenELM 和 Phi 的 LLM。它基于 Lightning 框架构建，并经过 TinyLlama 的优化，实现了超高吞吐量（GPU 利用率约 99.6%）。将其发布给所有人，如果您喜欢我们所做的，请给我们一个 star。 代码：https://github.com/pints-ai/1.5-Pints    提交人    /u/calvintwr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fb6fet/pfastest_pretraining_code_llm_in_9_days/</guid>
      <pubDate>Sat, 07 Sep 2024 13:02:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1f5cy0v/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sat, 31 Aug 2024 02:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>