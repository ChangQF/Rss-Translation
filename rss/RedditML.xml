<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 20 Feb 2024 06:17:51 GMT</lastBuildDate>
    <item>
      <title>数据采样[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1av9bbl/data_sampling_d/</link>
      <description><![CDATA[我可以使用哪些方法来收集准确代表总体生产输出的生产数据样本，而不需要对整个生产数据集进行质量控制？ 域可以是文本或图像。 到目前为止，我已经阅读过有关随机、分层、系统的内容，其中分层似乎是最佳选择。但是，我找不到任何有关当前行业趋势的信息。   由   提交/u/Azrael-1810  /u/Azrael-1810 reddit.com/r/MachineLearning/comments/1av9bbl/data_sampling_d/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1av9bbl/data_sampling_d/</guid>
      <pubDate>Tue, 20 Feb 2024 04:57:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果使用双 GPU 进行训练，瓦数会低得多</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1av8psg/d_much_lower_wattage_if_dual_gpu_used_for_training/</link>
      <description><![CDATA[我有双 GPU 设置，4080 16GB 和 4080 16GB 3090 24GB。通过我在 Yelp 评论数据集上训练 Bert Large 的玩具示例，我在双 GPU 上的训练速度始终比仅在 4080 上慢约 4%。我预计这 2 个 GPU 能够很好地协同工作，因为它们的 CUDA 核心数量非常相似（4080 9,728 ,3090 10,496）。另一项观察结果是，3090 在双重训练中仅拉动 270w 左右，而仅在 3090 上训练时，该卡拉动 335w。我有一个1600W的电源。我正在使用 Huggingface 变压器，精心挑选的最大批量大小为 18，多个数据加载器工作程序固定到内存。与 10k 和 100k 训练数据大小保持一致，速度减慢了约 4%。 有任何提示吗？   由   提交/u/kecso2107  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1av8psg/d_much_lower_wattage_if_dual_gpu_used_for_training/</guid>
      <pubDate>Tue, 20 Feb 2024 04:24:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为本科论文选择模型/架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1av73zo/d_choosing_a_modelarchitecture_for_undergraduate/</link>
      <description><![CDATA[目前是一名本科生，我们选择的主题是区分脑部疾病与其模拟疾病，以避免使用 MRI 图像进行误诊。  如果我们只区分它的模仿者而不是所有模仿者，范围是否太小？我们担心，如果我们将其所有模仿者都包括进来，范围就会太大，对于本科论文来说不可行。  您认为这是一篇有趣的论文吗？我真的很想进行一项既有帮助又有趣的研究:) 最后，我们也在选择模型/架构方面遇到了困难。这是因为我们这学期才刚刚开始学习机器学习。我们是否只是选择一个用于图像分类的架构，然后对其进行改进？我们可以采用同一研究中的方法但改进它（但我们不知道如何改进它，哈哈）？目前，我们正在考虑半监督学习，因为大脑图像的数据集很少（特别是我们正在寻找的疾病）。暂定方法：我们将使用基于注意力的CNN（因为我们想解决误诊问题，所以我们认为使用注意力机制会很有帮助，这样模型就能知道重要的特征。对于架构，我们正在规划使用 DenseNet、Inception 或 ResNet）和 Grad-CAM（为了可解释性）。我们也没有包含分割来让模型选择分类所需的特征。这个方法足够并且可行8个月吗？ 我们也在寻找一位可以帮助我们的导师，即使只是咨询。谢谢！   由   提交/u/viagee2  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1av73zo/d_choosing_a_modelarchitecture_for_undergraduate/</guid>
      <pubDate>Tue, 20 Feb 2024 03:02:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何训练 ViT 与 CNN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1av70eo/d_how_to_train_vit_vs_cnn/</link>
      <description><![CDATA[大家好，我尝试了猫和狗二元分类数据集来练习（224px）。首先，我使用了一个简单的 CNN，它有大约 250 万个可训练参数，Ir= 1e-3 和 25 个时期。训练后测试准确率约为90%。此后，我尝试使用 ViT base 16（大约 8500 万个可训练参数）来使用相同的超参数进行训练，但在 25 个 epoch 后，它仅达到 70% 的测试精度。我该怎么做才能获得更好的结果？   由   提交/u/spacesubmarine97   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1av70eo/d_how_to_train_vit_vs_cnn/</guid>
      <pubDate>Tue, 20 Feb 2024 02:58:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 数学家会在未来的机器学习研究中占据上风吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1av5gwy/d_will_mathematicians_have_the_upper_hand_in/</link>
      <description><![CDATA[似乎在各个角落我都看到了关于做研究的类似情绪。人们尝试各种事物的组合来获得渐进式的改进。我认为下一步的飞跃需要大量的理论知识来指导方向。   由   提交 /u/planetofthemushrooms   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1av5gwy/d_will_mathematicians_have_the_upper_hand_in/</guid>
      <pubDate>Tue, 20 Feb 2024 01:46:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 表示正交性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1av2dyh/r_representation_orthogonality/</link>
      <description><![CDATA[在表示理论文献中，不同类的表示具有典型的正交表示并且更细粒度的类具有一些正交表示是一个常见/合理的假设吗？余弦相似度相当低？   由   提交/u/Classic_Youth_4957   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1av2dyh/r_representation_orthogonality/</guid>
      <pubDate>Mon, 19 Feb 2024 23:31:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求 axolotl 配置指南：电子商务 Mistral 的微调设置</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auzq5u/d_seeking_guidance_for_axolotl_config_finetuning/</link>
      <description><![CDATA[您好，我对模型微调还很陌生，我正在尝试在自定义电子商务数据集上微调模型。该数据集包含大约 140k 羊驼格式的样本。我使用以下配置设置来使用 axolotl 微调 7B Mistral 模型。有人可以检查配置并建议我在开始训练之前是否可以省略任何重要的内容吗？ 任何帮助将不胜感激，因为我有其他领域的背景，但对计算机科学产生了热情主题。如果我问初学者问题，请接受我的歉意，因为我仍在学习本材料的细节。 ​ base_model：mistralai/Mistral-7B -v0.1 model_type: MistralForCausalLM tokenizer_type: LlamaTokenizer is_mistral_衍生_model: true load_in_8bit: true load_in_4bit: false strict: false 数据集: - 路径：combined_file.json ds_type: json 类型: alpaca output_dir: ./out 适配器: lora lora_r: 8 lora_alpha: 16 lora_dropout：0.05 lora_target_modules：-q_proj - v_proj - v_proj - o_proj - gateway_proj - down_proj - up_proj 序列_len：8192 样本包装：假 pad_to_sequence_len：真 wandb_project：axolotl wandb_entity：wandb_watch：wandb_name：wandb_log_model：gradient_accumulation_step s: 3 micro_batch_size: 2 num_epochs: 4 优化器: adamw_bnb_8bit lr_scheduler：余弦学习率：0.0002 train_on_inputs：假group_by_length：假bf16：真fp16：假tf32：假gradient_checkpointing：真early_stopping_patience：resume_from_checkpoint：local_rank：logging_steps：1 xformers_attention：flash_attention：true Warmup_steps：10次评估_per_epoch：4 eval_table_size：eval_max_new_tokens：128 saves_per_epoch: 1 debug: #default deepspeed，如果需要的话可以使用更激进的，如zero2、zero3 deepspeed: deepspeed_configs/zero1.json Weight_decay: 0.0 fsdp: fsdp_config:special_tokens: bos_token: &quot;&lt;s&gt;&quot; eos_token：“&lt;/s&gt;” unk_token：＆quot＆lt; unk＆gt;＆quot;    由   提交 /u/Monk_programmer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auzq5u/d_seeking_guidance_for_axolotl_config_finetuning/</guid>
      <pubDate>Mon, 19 Feb 2024 21:47:21 GMT</pubDate>
    </item>
    <item>
      <title>对于技术主管来说，您的实际工作是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auyt1n/for_anyone_whos_a_tech_lead_what_is_your_actual/</link>
      <description><![CDATA[在担任主要 DS 后，我最近被任命为一个大项目的技术主管，并发现自己在思考我的角色实际上是什么/应该是什么..你每天都做什么？与参加会议和计划里程碑等相比，您还有多少编码和技术工作？    由   提交 /u/natrules   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auyt1n/for_anyone_whos_a_tech_lead_what_is_your_actual/</guid>
      <pubDate>Mon, 19 Feb 2024 21:11:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为一名应届本科生，我需要知道如何做才能获得 AI/ML 实习机会？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auyh5o/d_what_do_i_need_to_know_how_to_do_in_order_to/</link>
      <description><![CDATA[所以我在 Reddit 子版块上看到了一篇关于获得 AI/ML 实习机会的帖子，其中 OP 尽管拥有高水平的 AI 项目但无法获得实习机会，并且这让我有点困惑，因为自从我开始学习人工智能以来，我所想的就是我所需要的只是高水平的人工智能项目/论文实现，以便在本科期间/毕业后获得实习机会。 所以这让我想到了我的问题：业内人士在决定向人们提供实习/工作时实际关注的当前技能是什么？除了能够在 IPython 笔记本中创建模型之外，当今还需要哪些技能？可以从哪里学习这些技能？ 以下是我认为一个人必须具备的技能，收集于其他讨论中的评论：  数据工程、分析 边缘情况检测/识别 能够编写端到端生产代码（如果可能的话，有人可以链接一些资源来开始） 理解/实现各种算法  （现在让我们讨论一下经验的争论，并且现在只关注技能部分；我知道经验对于决定实习来说是一个非常重要的部分，但现在我们假设世界上所有的申请者都有相同的经验） P。 S. 当我说技能是必要的时，我的意思是一个人必须有与这些技能相伴随的项目。 P. P.S.如果有人正在进入这个领域，您能否也链接我们应该用来学习所述技能的资源（是的，我将其放在 r/learnmachinelearning 也是如此，但我认为这个子程序能够更好地讲述必要的技能）   由   提交/u/throtaway236822  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auyh5o/d_what_do_i_need_to_know_how_to_do_in_order_to/</guid>
      <pubDate>Mon, 19 Feb 2024 20:58:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] Lipschitz 连续性和凸函数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1auv1pp/p_lipschitz_continuity_and_convex_functions/</link>
      <description><![CDATA[我有这个： Sigma：R-&gt;R 是非递减 L-Lipschitz 函数，W € R kxd, 和 b €Rk 存在凸 L||W||22 平滑函数 F (w,b) 使得 Nablax F(w b)(x) =WT sigma(Wx +b)  并且我们有凸势层 z = x - (2*WT sigma(Wx + b) )/ ||W||_22  现在，谁能帮我严格证明 F_(w,b) L||W||_22 光滑吗？而且，z 可微吗？  如果不是解决方案，那么其他人可以推荐一些阅读材料和书籍吗？   由   提交 /u/theloneliestsoulever   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1auv1pp/p_lipschitz_continuity_and_convex_functions/</guid>
      <pubDate>Mon, 19 Feb 2024 18:47:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在 10M 大海捞针中寻找针：循环记忆找到法学硕士错过的东西 - AIRI，莫斯科，俄罗斯 2024 - RMT 137M 具有循环记忆的微调 GPT-2 能够在 10M 中找到 85% 的隐藏针草垛！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1autvwq/r_in_search_of_needles_in_a_10m_haystack/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2402.10790  摘要：  本文解决了使用生成变压器模型处理长文档的挑战。为了评估不同的方法，我们引入了BABILong，一个新的基准旨在评估模型在广泛文本中提取和处理分布式事实的能力。我们的评估（包括 GPT-4 和 RAG 基准）表明，常见方法仅对最多 10^4 元素的序列有效。相比之下，通过循环内存增强对 GPT-2 进行微调使其能够处理涉及多达  10^7 个元素的任务。这一成就标志着一个重大飞跃，因为它是迄今为止任何开放神经网络模型处理的最长输入，展示了长序列处理能力的显着改进。   https://preview.redd.it /0o4207a70ljc1.jpg?width=577&amp;format=pjpg&amp;auto=webp&amp;s=2bfac07872020de222b4bf99f837aa398b778afc https://preview.redd.it/2ff82da70ljc1.jpg?width=1835&amp;format=pjpg&amp;auto=webp&amp;s=acc1409f5b9bcd07f9 b5ff8a3890cc1b15b5c8ed  https://preview.redd .it/ld69p7a70ljc1.jpg?width=1816&amp;format=pjpg&amp;auto=webp&amp;s=fdd72c1a87742f525fa352723bcd1a0f4f000638 https://preview.redd.it/7vn4gba70ljc1.jpg?width=900&amp;format=pjpg&amp;auto=webp&amp;s=c8d08bb85a6 699e5b451e01bf615379db1fcbdca   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1autvwq/r_in_search_of_needles_in_a_10m_haystack/</guid>
      <pubDate>Mon, 19 Feb 2024 18:02:36 GMT</pubDate>
    </item>
    <item>
      <title>MoE - 我对“专家”有点困惑 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aurrxi/moe_im_a_bit_confused_about_experts_d/</link>
      <description><![CDATA[我一直在阅读一些有关专家混合 (MoE) 模型的内容，以及它们如何惩罚模型以确保激活分布相等话虽如此，可以合理地说它不是“这是数学专家，这是科学专家”，而是一个优化的黑匣子在大量训练数据上训练的子模型以针对输入查询的不同维度？ 我更多地将其视为负载均衡器，并且可能是一种通过拆分来抵消大型模型可能产生的负面影响的方法增加工作量。 我们无法控制专家，对吧？  还是我大错特错了？   由   提交 /u/Kaldnite   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aurrxi/moe_im_a_bit_confused_about_experts_d/</guid>
      <pubDate>Mon, 19 Feb 2024 16:41:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] Mamba 和状态空间模型的视觉指南</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aupbct/d_a_visual_guide_to_mamba_and_state_space_models/</link>
      <description><![CDATA[大家好！为了使状态空间模型（和 Mamba）更容易被更广泛的受众接受，我创建了底层技术的视觉指南。 https://maartengrootendorst.substack.com/p/a-visual-guide-to-mamba-and-state 通过 50 多个自定义可视化，我希望它为那些对用于语言建模的 Mamba 和状态空间模型感兴趣的人提供一个直观的起点。 我们的想法是专注于直觉，使这一潜在的新功能成为可能。对于该领域的新手来说，架构很容易理解。我确保尽可能将方程式保持在最低限度。 希望这将为那些完全陌生的人提供一个很好的介绍。 如果您有任何反馈和/或者更正，我洗耳恭听！    由   提交 /u/MaartenGr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aupbct/d_a_visual_guide_to_mamba_and_state_space_models/</guid>
      <pubDate>Mon, 19 Feb 2024 15:01:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI/ML 实习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1audi2u/d_aiml_internships/</link>
      <description><![CDATA[为什么现在 AI/ML 领域的实习这么难？  我目前拥有一些高级人工智能项目的一年经验。但不知何故，我无法找到任何实习机会。至于工作，我几乎找不到需要5年以下经验的工作。说实话，这令人沮丧。有人可以帮忙吗？   由   提交/u/Anonymous_Life17  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1audi2u/d_aiml_internships/</guid>
      <pubDate>Mon, 19 Feb 2024 03:34:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>