<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 08 Mar 2024 09:12:55 GMT</lastBuildDate>
    <item>
      <title>[R] 迈向通用计算机控制：以 Red Dead Redemption II 的多模式代理为例 - 北京人工智能研究院 (BAAI) 2024 - 第一个能够在 AAA 游戏中跟踪并完成真实任务的代理！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b9jrxo/r_towards_general_computer_control_a_multimodal/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2403.03186  包含代码和视频的 Projekt 网站：https://baai-agents.github.io/Cradle/  摘要：  尽管在特定任务和场景中取得了成功，但现有基础在大型模型（LM）和高级工具的支持下，智能体仍然无法泛化到不同的场景，这主要是由于不同场景的观察和行动存在巨大差异。在这项工作中，我们提出了通用计算机控制（GCC）设置：构建可以通过仅将计算机的屏幕图像（可能还有音频）作为输入并生成键盘和鼠标操作作为输出来掌握任何计算机任务的基础代理，类似于到人机交互。实现GCC的主要挑战是：1）用于决策的多模态观察，2）键盘和鼠标精确控制的要求，3）&lt; /strong&gt;长期记忆和推理的需要，以及4)高效探索和自我完善的能力。针对GCC，我们引入了Cradle，一个具有六个主要模块的代理框架，包括：1）信息收集以提取多模态信息， 2) 自我反思，重新思考过去的经验，3) 任务推理，选择下一个最佳任务，4) 技能策划，用于生成和更新给定任务的相关技能，5) 生成键盘和鼠标控制特定操作的行动计划，以及 6) 存储和检索过去经验和已知技能的内存。为了展示Cradle的泛化能力和自我完善能力，我们将其部署在复杂的AAA游戏《荒野大镖客2》中，作为对GCC具有挑战性目标的初步尝试。 据我们所知，我们的工作是第一个使基于 LMM 的代理能够在复杂的 AAA 游戏中遵循主要故事情节并完成真实任务的工作，同时最大限度地减少对先验知识或资源的依赖。  https://preview.redd .it/5pxz5wc9s2nc1.jpg?width=1650&amp;format=pjpg&amp;auto=webp&amp;s=7f407686977e84e9b0465cfa5a29b4f735a83365 https://preview.redd.it/e09d2wc9s2nc1.jpg?width=1332&amp;format=pjpg&amp;auto=webp&amp;s=0db5a0c19 ff3d060644077d9640718017d6699af https://preview .redd.it/x656lyc9s2nc1.jpg?width=1349&amp;format=pjpg&amp;auto=webp&amp;s=d433c42a46dccf5f5b9609c5535e087179532c2e   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b9jrxo/r_towards_general_computer_control_a_multimodal/</guid>
      <pubDate>Fri, 08 Mar 2024 09:02:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻找有关如何将旧纸质目录转换为综合电子表格的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b9hq3r/p_looking_for_recommendations_on_how_to_convert/</link>
      <description><![CDATA[免责声明：我是一名专业软件工程师，我个人还没有任何关于 ML 或 AI 的第一手经验（至少除了喂养之外）无论如何，文本都会提示著名的人工智能） 所以情况是这样的 我是下一个高中同学聚会委员会的成员（这将是我们的 20 年），到目前为止，仅依靠 Facebook（我们有一个专门针对我们年级的毕业班小组），我们只认为我们已经达到了班级的 1/5 左右，最多可能是 1/4。 我们班只有 500 多名毕业生，我们的 Facebook 群组大约有 341 名成员。尽管社交变得有毒和可怕，但还是有很多人直接删除了所有社交媒体。除了那些使用核技术的人之外，我们有一种非常强烈的感觉，从技术上讲，很大一部分人仍然在 Facebook 上，甚至在我们发送邀请的群组中注册过，只是不再登录了。我们从去年 5 月份左右就开始为这次重聚而努力，在 10 月份左右全力以赴，预定于 4 月 19 日举行，但我们只有大约 100 个回复（到目前为止，其中只有 75 个已支付门票）。&lt; /p&gt; 当我们上学时，我们每年年初都会得到一份新的注册表。一本简单的塑料螺旋装订，大约 4 x 6、1 英寸厚的小册子，列出了班级中的每个学生、他们的街道地址、家长的姓名、电话号码，在极少数情况下还具体列出了学生的电话号码（这是在手机出现之前）爆炸了，所以任何学生号码都会是一个额外的专用固定电话）。 我希望建立一个非常全面的电子表格，列出与我们一起毕业的每个学生，他们的旧目录信息，然后另外在我们进一步整理信息时添加更多杂项详细信息（例如某人是否已去世、他们现在居住在哪个州、当前的联系信息、他们的 RSVP 状态等）。 显然，20 年前的数据这里并不是最理想的基础，因为人们搬家、结婚（改名）以及任何其他事情都可能发生，使这些记录中的每一项几乎毫无用处。不过，我们必须尝试超越仅仅依赖 Facebook、LinkedIn 和口碑。因此，除了至少为每个学生制作一份带有原名的条目外，我们认为下一步是将我们无法联系到的人（希望他们的父母或某种形式的家庭）的信件邮寄给这些旧地址的家人仍然住在那里，他们能够为我们传递这个消息。 （因此，任何有关如何编写一封带有通过外部文档读取的变量的字母的建议也是受欢迎的）。 在这个人工智能时代，我知道完全有可能从此解开螺旋边界旧目录，将其输入多页双面扫描仪，保存单个 PDF 或其他内容，然后让 AI 立即自动为我创建此电子表格，而无需手动输入所有这些数据。 唯一的问题是，我不知道最好的方法是什么，所以有人对我应该如何开始有任何潜在的建议或指导吗？ 我的第一个想法是通过简单的模式识别（区分每页的一个目录条目与另一个目录条目），然后在名字、姓氏、街道地址等上对输入框进行区域映射，这样就可以非常快速、直接地训练人工智能如何做我想做的事。如果没有的话，也为我创建一个电子表格，如果没有别的，数据将所有内容转储到一个 JSON 或 CSV 或其他文件中。只是我在训练人工智能模型方面没有任何实际的第一手经验，所以我不知道从哪里开始，或者是否有一个特定的已经存在的流行人工智能模型是可适应/可定制的，我应该从具体开始。  所以你们能在这方面给我指出的任何方向都很棒 • 如何为这项任务训练我自己的模型 • 任何现有的人工智能我应该有兴趣寻找这项工作 • 任何人都知道的现有应用程序/软件已经设计用于精确执行此操作 • 具体文档 •任何我还没有想到但你认为可能非常有用的东西 非常感谢！   由   提交 /u/RudePhilosopher5721   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b9hq3r/p_looking_for_recommendations_on_how_to_convert/</guid>
      <pubDate>Fri, 08 Mar 2024 06:51:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 开源 LEURN：表格数据的可解释和生成人工智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b9hkl2/p_opensourcing_leurn_an_explainable_and/</link>
      <description><![CDATA[大家好， 我正在开源 LEURN - 一个用于表格数据的可解释和生成人工智能。 https://github.com/CaglarAytekin/LEURN/ 这是一个本质上可解释的神经网络生成一个单变量决策树，您也可以将其用作生成器。 请在存储库中找到广泛的演示。 说明格式  &lt; li&gt;LEURN 提供样本所属的类别。它给出了数字特征的上限和下限，以及分类特征的类别集。 LEURN 还提供了每个特征对最终结果的精确附加贡献。 （见注释）  生成能力  LEURN 与任何其他神经网络一样以预测方式进行训练。 经过训练的预测网络可以直接用作生成网络。这是由于神经网络的单变量性质而得以实现的。对于具有多元规则的常规网络，尽管可以提取这些规则，但很难从这些多元不等式定义的类别中进行采样。由于 LEURN 的决策是单变量的，因此它只不过是从下边界和上边界对每个特征进行采样。请参阅论文了解详细信息。 可以从与输入相同的类别生成（用例：数据匿名化）。 还可以生成全新的样本（用例：合成数据生成）。  一些注意事项：  该方法不是像 SHAP、LIME 那样的训练后解释器，这是一个独立的新型神经网络，您应该从头开始训练 与 SHAP、LIME 等不同，附加贡献不是近似值，而是设计上的精确值。 与 SHAP 不同，等等，解释过程不需要任何支持数据，并且由单个推理样本组成。 LEURN 在表格数据的预测性能方面与 SotA 方法相当（请参阅我在 github 中的论文链接），同时本质上是可解释的和生成性的。  期待听到您的意见和要求。   由   提交 /u/MLC_Money   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b9hkl2/p_opensourcing_leurn_an_explainable_and/</guid>
      <pubDate>Fri, 08 Mar 2024 06:41:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 小语言模型与 RAG</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b9hcfl/d_small_language_models_vs_rag/</link>
      <description><![CDATA[我发现很多人对使用多个小语言模型来实现“专家”的兴趣。内容生成。在什么情况下它们比更大的通用模型与 RAG 搭配获取专门信息更有用？   由   提交 /u/TheCoconutTree   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b9hcfl/d_small_language_models_vs_rag/</guid>
      <pubDate>Fri, 08 Mar 2024 06:28:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 给自回归模型思考的空间</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b9edix/d_giving_autoregressive_models_the_space_to_think/</link>
      <description><![CDATA[自回归预测有一个问题：无论你是在问天空是什么颜色，还是在证明黎曼假设，生成下一个预测的计算量token 完全相同，但显然这两个问题中哪一个需要更多计算才能回答。因此，工程师们致力于如何扩展自回归模型的能力，以便能够在说话之前思考一段可变的时间。这是解决方案（留给读者练习）。   哲学动机 人类思维在一个连续的潜在思想空间中运作，在大脑状态的自然演化过程中被离散化为语言对应项。任何作家都可以告诉你，将某些东西放在页面上就是将其压缩到头脑中想法的一小部分。换句话说，离散化是有损的，尤其是结构化离散化，就像语言的情况一样。因此，语言模型必须将连续的潜在预测纳入其输出“思想”的一部分。 （不过，这些想法永远不会映射到令牌空间，也不会呈现给用户，这使得它与便签本之类的东西不同）。   Transformers 将计算隐藏在前向传播中不重要的标记。有关此内容的进一步说明，请参阅此处。作者表明，只需为转换器提供预测空间之外的额外计算空间，就可以将计算从标记空间移出，从而产生更可解释的注意力图和逻辑性能。     现在让我们将自回归语言模型视为一个抽象系统，它计算离散（令牌）空间中下一个时间步状态如何演变的概率分布。无需将每个下一个预测映射到令牌！相反，让我们将两个新标记注入到我们的嵌入表中， &lt;结束思想流&gt;。当模型在自回归解码期间预测这些标记时，这些标记以及它们之间预测的连续向量（从未离散化！）完全在损失函数之外，但它们用于条件所有未来的标记预测。    我可以对此进行更多讨论，但如果您要实现这一点，您可能已经明白了这一点。我知道，这篇文章背后的自负是疯狂的。   由   提交/u/H2O3N4  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b9edix/d_giving_autoregressive_models_the_space_to_think/</guid>
      <pubDate>Fri, 08 Mar 2024 03:52:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人尝试过使用 Grace Hopper 超级芯片进行 AI/ML 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b9cwry/d_anyone_tried_using_grace_hopper_superchip_for/</link>
      <description><![CDATA[       由   提交 /u/YouGotServer   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b9cwry/d_anyone_tried_using_grace_hopper_superchip_for/</guid>
      <pubDate>Fri, 08 Mar 2024 02:42:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 约 100 行 CUDA 中的 Flash Attention</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b9bsme/p_flash_attention_in_100_lines_of_cuda/</link>
      <description><![CDATA[对于像我这样的 CUDA 初学者来说，深入了解官方 Flash Attention 源代码可能会令人畏惧。所以我用大约 100 行 CUDA https://github.com/tspeterkim/flash-attention-minimal&lt; 编写了前向传递/a&gt; 并出于教育价值而分享。    由   提交/u/droidarmy95  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b9bsme/p_flash_attention_in_100_lines_of_cuda/</guid>
      <pubDate>Fri, 08 Mar 2024 01:50:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] GaLore：通过梯度低秩投影进行内存高效的 LLM 训练</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b99cmm/r_galore_memoryefficient_llm_training_by_gradient/</link>
      <description><![CDATA[论文：[2403.03507] GaLore：内存高效的 LLM 培训梯度低阶投影 (arxiv.org) 代码库：GaLore (github.com) 训练大型语言模型 (LLM) 带来了巨大的内存挑战，主要是由于权重和优化器状态的大小不断增加。常见的内存减少方法，例如低秩适应（LoRA），将可训练的低秩矩阵添加到每层中冻结的预训练权重中，从而减少可训练的参数和优化器状态。然而，此类方法通常在预训练和微调阶段都表现不佳，因为它们将参数搜索限制在低秩子空间并改变了训练动态，而且可能需要全秩热启动。在这项工作中，我们提出了梯度低秩投影（GaLore），这是一种允许全参数学习的训练策略，但比 LoRA 等常见的低秩适应方法更节省内存。我们的方法在优化器状态下将内存使用量减少了高达 65.5%，同时保持了在 LLaMA 1B 和 7B 架构上使用最多 19.7B 令牌的 C4 数据集进行预训练的效率和性能，以及在 GLUE 任务上微调 RoBERTa 的效率和性能。与 BF16 基准相比，我们的 8 位 GaLore 进一步减少了优化器内存高达 82.5%，总训练内存减少了 63.3%。值得注意的是，我们首次证明了在具有 24GB 内存的消费级 GPU（例如 NVIDIA RTX 4090）上预训练 7B 模型的可行性，无需模型并行、检查点或卸载策略。 Pretty团队的出色工作！   由   提交/u/honestlylost18   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b99cmm/r_galore_memoryefficient_llm_training_by_gradient/</guid>
      <pubDate>Thu, 07 Mar 2024 23:57:35 GMT</pubDate>
    </item>
    <item>
      <title>[D]机器学习研究人员如何看待可视化低代码/无代码机器学习工具？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b9318j/dwhat_do_ml_researchers_think_about_visual_lowno/</link>
      <description><![CDATA[我正在研究 ML 工具领域，并遇到了几种用于构建/可视化 LLM 的低代码工具，例如 cerbrec.com。我的背景比较偏向 swe，因此与 PyTorch 相比，我看不出这些工具的实用性，但我很想向在非技术团队工作的传统“非 swe”研究人员学习。    由   提交 /u/Bnjoroge   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b9318j/dwhat_do_ml_researchers_think_about_visual_lowno/</guid>
      <pubDate>Thu, 07 Mar 2024 19:31:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 可解释的人工智能研究已经失败了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8zifr/r_has_explainable_ai_research_tanked/</link>
      <description><![CDATA[我感觉整个 ML 社区已经以一种奇怪的方式对 XAI 失去了兴趣，或者只是变得极其愤世嫉俗。  在某种程度上，这仍然是所有机器学习领域需要解决的问题，但它与几年前的情况确实不同。现在人们不敢说XAI，而是说“可解释”、“值得信赖”、“监管”、“公平”、“人机交互”、“机械可解释性”等等。 . 我有兴趣了解人们对此的感受，因此我写这篇文章是为了就该主题进行对话。 您对 XAI 有何看法？你相信它有效吗？您认为它只是演变成几个更具体的不同研究领域吗？您是否认为这是一个无用的领域，没有兑现 7 年前的承诺？ 感谢您的意见和见解，谢谢。  &amp; #32；由   提交 /u/SkeeringReal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8zifr/r_has_explainable_ai_research_tanked/</guid>
      <pubDate>Thu, 07 Mar 2024 16:57:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] MAMBA 优于变形金刚吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8u2kq/d_is_mamba_superior_to_transformers/</link>
      <description><![CDATA[您好， 曼巴架构引起了很多争议。它真的有那么好，比变形金刚更好吗？如果是，为什么我们没有看到它像变形金刚推出时那样被广泛采用。   由   提交 /u/rodeowrong   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8u2kq/d_is_mamba_superior_to_transformers/</guid>
      <pubDate>Thu, 07 Mar 2024 13:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 微软研究院推出 NaturalSpeech 3，这是零样本文本转语音技术的重大进步。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8pw7i/r_microsoft_research_unveils_naturalspeech_3_a/</link>
      <description><![CDATA[      论文链接：https://arxiv.org/abs/2403.03100 演示链接：https://speechresearch.github.io/naturalspeech3/&quot;&gt;https:// /speechresearch.github.io/naturalspeech3/ ​ 基于 NaturalSpeech 系列的成功，NaturalSpeech 3 不仅继承了高质量的合成功能而且还通过分解语音属性来进一步推进，从而实现更详细和受控的合成过程。 ​ NaturalSpeech 3 的主要亮点包括： 1.因子化编解码器：具有因子化矢量量化的神经编解码器能够熟练地将语音分解为不同的子空间，从而有针对性地改进语音生成。 2.因子化扩散模型：因子化扩散模型旨在生成语音属性与相应的提示完全一致。这种创新方法使 NaturalSpeech 3 不仅可以合成类似人类的语音，还可以调整韵律和音色的细微差别，以匹配说话者的情感和风格。 3. 可扩展性：可扩展至 10 亿个参数经过超过 20 万小时的数据训练，NaturalSpeech 3 在提高语音质量和清晰度方面显示出了可喜的成果。未来，NaturalSpeech 3 计划进一步扩大规模，以实现更精细的结果。 ​ 深入研究演示、阅读论文，了解 NaturalSpeech 3 的用途为零样本语音合成设定新标准。 https://preview.redd.it/gbgau8vwkvmc1.png?width=1982&amp;format=png&amp;auto=webp&amp;s=3260d6ac03b42e6059c5e0a58169d880b037 b00f ​   由   提交/u/Front-Article-7366   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8pw7i/r_microsoft_research_unveils_naturalspeech_3_a/</guid>
      <pubDate>Thu, 07 Mar 2024 08:47:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么最新、最伟大的法学硕士仍然为生成十个以 apple 结尾的句子这样的小事而苦苦挣扎？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8ohhy/d_why_do_the_latest_and_greatest_llms_still/</link>
      <description><![CDATA[所有 3 个模型（Gemini Advanced、Claude 3.0 Opus、GPT-4）都失败了，gpt-4 表现最好，十有八九以苹果结尾。    由   提交 /u/ccooddeerr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8ohhy/d_why_do_the_latest_and_greatest_llms_still/</guid>
      <pubDate>Thu, 07 Mar 2024 07:18:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] Apollo：轻量级多语言医学法学硕士，将医疗人工智能普及到 6B 人群</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b8mml6/d_apollo_lightweight_multilingual_medical_llms/</link>
      <description><![CDATA[    &lt; /a&gt;  我们开源了一系列SOTA轻量级多语言医疗LLM Apollo (0.5B, 1.8B, 2B, 6B, 7B)，利用非翻译语料库取得最佳新表现 覆盖英文、中文、法语、西班牙语、阿拉伯语和印地语  整个过程开源且可复制 精简版模型可以是用于提高大型模型的多语言医疗能力无需以代理调整方式进行微调   github：https://github.com/FreedomIntelligence/Apollo 演示：https://apollo.llmzoo.com/#/ 论文：https ://arxiv.org/abs/2403.03640 模型：https://huggingface.co /FreedomIntelligence/Apollo-7B  https://preview.redd.it/29kjdct4oumc1.png?width=1488&amp;format=png&amp;auto=webp&amp;s=1a16bbbf2588fb071ba2af5a50668ca8335c 92b7 https://preview.redd.it/406m28t4oumc1.png?width=1120&amp; ;format=png&amp;auto=webp&amp;s=607664035b62aa0ee726d3f5b4c4730863823bcb https://preview.redd.it/jiewd5t4oumc1.png?width=1242&amp;format=png&amp;auto=webp&amp;s=e059d49da4e788729b134b0d64415bcf 85bb024c    由   提交 /u/Pasu06   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b8mml6/d_apollo_lightweight_multilingual_medical_llms/</guid>
      <pubDate>Thu, 07 Mar 2024 05:33:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>