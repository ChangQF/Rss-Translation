<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 05 Feb 2025 21:15:50 GMT</lastBuildDate>
    <item>
      <title>[D] 机器学习用于编码孔径图像重建</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iikqxt/d_machine_learning_for_coded_aperture_image/</link>
      <description><![CDATA[我正在研究编码孔径 X 射线望远镜，并且正在探索机器学习是否可以提供比传统反卷积方法更好的结果。我对机器学习的背景知识知之甚少，可以使用一些指针。我找到了一些参考资料，但机器学习实现超出了我的理解范围。我有一个（小）原始图像集合及其重建，我可以使用它们来训练它，但我不确定如何实际设置问题。 这是一个与我所问的类似的参考资料。不幸的是，它位于 Elsevier 付费墙后面    提交人    /u/spacepbandjsandwich   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iikqxt/d_machine_learning_for_coded_aperture_image/</guid>
      <pubDate>Wed, 05 Feb 2025 21:01:28 GMT</pubDate>
    </item>
    <item>
      <title>机器学习子领域（例如医疗）的专业化是否会限制未来在大型科技领域的机会？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iij25z/does_specialization_in_niche_ml_subfield_eg/</link>
      <description><![CDATA[我很好奇在职业生涯早期专攻某个子领域是否会影响以后进入大型科技领域的选择。例如，我收到了一些在知名研究小组（全额资助和作为雇员）开始攻读博士学位的邀请，但他们似乎（目前）对他们的目标和我将要从事的工作非常具体。 我看到大型科技公司都在研究 NLP 和一些 CV 内容（但仍然期待一些 NLP 内容），只有医疗机构与我想攻读博士学位的主题相关。 这是否会使过渡到行业中的一般 ML 角色变得更加困难？或者 ML 专业知识是否无论在哪个领域都可以转移？很想听听那些专攻利基领域或实现职业转型的人的想法。    提交人    /u/ade17_in   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iij25z/does_specialization_in_niche_ml_subfield_eg/</guid>
      <pubDate>Wed, 05 Feb 2025 19:52:34 GMT</pubDate>
    </item>
    <item>
      <title>[N] Deepseek 如何训练他们的 R1 模型，以及当今前沿 LLM 是如何训练的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iii013/n_how_deepseek_trained_their_r1_models_and_how/</link>
      <description><![CDATA[https://www.youtube.com/watch?v=aAfanTeRn84 Lex Friedman 最近发布了一篇名为“DeepSeek 的 GPU 优化技巧”的采访。这是一篇很棒的幕后花絮，展示了 Deepseek 在没有像美国同行那样多的 GPU 的情况下如何训练他们的最新模型。 需要是发明之母，Deepseek 做了几件事-  他们的专家混合配置非常创新，他们拥有非常高的稀疏因子，8/256 位专家激活。这比其他模型高得多，其他模型中 8 位专家中有​​ 2 位激活。  训练这个模型可能很难，因为只有少数专家真正学习并激活任务，这使得模型很弱。他们引入了辅助损失，以确保所有专家都用于所有任务，从而形成强大的模型。 混合专家模型的一个挑战是，如果只有少数专家激活，那么只有少数 GPU 可能会计算过载，而其余 GPU 则处于闲置状态。辅助损失也可以防止这种情况发生。 他们走得更远，实现了他们自己的 Nvidia NCCL 通信库版本，并使用更接近汇编级 PTX 指令来管理 GPU 中的 SM 如何为每个操作进行调度。这种低级优化使他们的模型在有限的硬件上具有非常高的性能。  他们还讨论了研究人员如何使用新的模型架构和数据工程步骤进行实验。他们说，在训练过程中，损失曲线会出现一些峰值，很难确切知道原因。有时训练后问题会消失，但有时 ML 工程师必须从较早的检查点重新开始训练。 他们还提到了 YOLO 运行，研究人员投入所有可用的硬件和预算来尝试获得前沿模型。他们可能会得到一个非常好的模型，也可能会在这个过程中浪费数亿美元。 这次采访实际上是对当今训练前沿 LLM 的幕后情况的一次非常好的深入观察。我很喜欢，我建议你也去看看！    提交人    /u/ml_guy1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iii013/n_how_deepseek_trained_their_r1_models_and_how/</guid>
      <pubDate>Wed, 05 Feb 2025 19:09:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] 虚幻的安全：Redteaming DeepSeek R1 和 OpenAI、Anthropic 和 Google 最强大的可微调模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iif6qk/r_illusory_safety_redteaming_deepseek_r1_and_the/</link>
      <description><![CDATA[安全护栏是虚幻的。DeepSeek R1 的高级推理可以转化为“邪恶双胞胎”：同样强大，但安全护栏被剥离。GPT-4o、Gemini 1.5 和 Claude 3 也是如此。我们如何确保 AI 最大化利益同时最小化伤害？ 我们通过越狱调整来移除护栏：对带有有害响应的越狱提示进行微调。最初，开源和专有模型都会拒绝几乎所有有害请求。越狱调整后，它们几乎可以帮助解决所有问题：恐怖主义、欺诈、网络攻击等。 经过微调的模型会主动对之前拒绝的危险查询生成详细、精确且可操作的响应。 与基于微调的攻击相比，越狱提示可能不一致且产生质量较差的响应。 薄弱的安全护栏会给人一种虚假的安全感。对保障措施的过度自信可能意味着威胁不受控制——直到为时已晚。 我们该如何解决这个问题？ 😈 邪恶双胞胎评估 - 测试假设最坏情况滥用的预缓解模型。 🚧 红线 - 设定清晰、现实的伤害阈值 &amp;不要越过它们。 🚫 非微调人工智能 - 允许隐私和边缘设备等开放式优势，同时阻止有害的微调。 这不仅仅是一个企业或国家的问题。这是一个共同的挑战。 将人工智能视为一场竞赛——公司与公司、国家与国家、开放与封闭——将每个人都置于危险之中。如果我们想要安全的人工智能，全球合作，而不是竞争，是唯一的出路。 我们必须超越安全的幻想。我们关于越狱调整漏洞和人工智能安全漏洞的新研究将很快全面发布。同时，请查看我们的研究预览： 🔗 http://far.ai/post/2025-02-r1-redteaming/     提交人    /u/KellinPelrine   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iif6qk/r_illusory_safety_redteaming_deepseek_r1_and_the/</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:08 GMT</pubDate>
    </item>
    <item>
      <title>探索自定义指令：调试平台特定问题并向 OpenAI 工程师寻求见解 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iierrw/exploring_custom_instructions_debugging/</link>
      <description><![CDATA[嗨，OpenAI 工程师，我一直在尝试自定义指令功能，并且在不同的设备（Apple 移动设备、Android 移动设备和桌面 Windows 10）上遇到了一些令人沮丧的平台特定问题。这是我试图解决的混乱情况的细分。我在文本编辑器中输入了这段代码，因此我只需将其剪切并粘贴在下面即可： 情况 - BLUF：我发现了几个错误，既有系统性的也有功能性的。  AA.platform a = apple mobile b = andriod mobile c#= 自定义编号指令子集到平台（a、b、d）d = 桌面 win10  BB。每个设备每个自定义的自定义指令字段在 2 个可用选项（指令 1 和 2）之间选择 ac1 = ChatGPT 应该具备哪些特征？ac2 = ChatGPT 还应该了解您的哪些信息？ bc1 = 您希望 ChatGPT 了解您的哪些信息以提供更好的响应？bc2 = 您希望 ChatGPT 如何回应？ dc1 = ChatGPT 应该具备哪些特征？dc2 = ChatGPT 还应该了解您的哪些信息？  CC。用户输入自定义 ChatGPT 功能的状态（platform_custom_inst = 字段已填充 [true] &amp;&amp; 空 [flase]） ac1 = true ac2 = false bc1 = false bc2 = true dc1 = false dc2 = true  DD。问题  ac1 &amp;&amp; dc1 是相同的指令，但是只填充了 1 个字段 (ac1) dc2 &amp;&amp; ac2 是相同的指令，但是只填充了 1 个字段 (dc1) bc1 是在平台 a &amp;&amp; d 上不共享的指令 bc2 是在平台 a &amp;&amp; d 上不共享的指令 ac1 输入等于 bc2 dc2 输入不等于 a 或 c 上的指令   EE. 当前采取的步骤  退出 &amp;&amp; 重新登录之前 I：  a.将长度相同且少于 1500 个字符的 verebitum 说明剪切并粘贴到平台 a &amp;&amp; b &amp;&amp; d -result = 参考表 CC b. 首先退出平台 b &amp;&amp; 重新启动平台 a &amp;&amp; d -result = 字段 ac1/2 &amp;&amp; dc1/2 没有变化 c. 第二次退出平台 a &amp;&amp; 重新启动平台 d -result = 字段 ca1/2 没有变化 d. 退出平台 d &amp;&amp; 重新启动平台 d &amp;&amp; 在平台 d 上重新登录 ChatGPT &amp;&amp; 清除平台 d 上的浏览​​器历史记录 -result = 字段 dc1/2 没有变化 e. 将长度相同且少于 1500 个字符的 verebitum 说明剪切并粘贴到平台 a &amp;&amp; b &amp;&amp; d -result = 字段 dc1/2 没有变化  FF. 评论 这里有多个不匹配和歧义，我不得不相信这会导致冲突。我个人的用途目前将限制在平台 a &amp;&amp; d 之间。 来自一位朋友的真实性：“这只是另一个‘秘密训练模型’无法跨设备同步的案例，还是我陷入了这些自定义指令的无限循环？只是想避免这里出现故障的 GPT-3 后果，伙计们……😜&quot;    提交人    /u/indifferentindium   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iierrw/exploring_custom_instructions_debugging/</guid>
      <pubDate>Wed, 05 Feb 2025 16:59:48 GMT</pubDate>
    </item>
    <item>
      <title>[R] Transformer-Squared：自适应 LLM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iicsz0/r_transformersquared_selfadaptive_llms/</link>
      <description><![CDATA[      Sakana AI 的一个框架，允许 LLM 在推理时调整部分权重。 论文 | GitHub | 博客摘要 https://preview.redd.it/61pd7me6jche1.png?width=915&amp;format=png&amp;auto=webp&amp;s=b223fcb9369dc461c0b933669b1026f5eb46d351 摘要：  “自适应大型语言模型 (LLM) 旨在解决传统微调方法通常需要大量计算，并且在处理各种任务的能力上是静态的。我们引入了 Transformer-Squared，这是一种新颖的自适应框架，它通过选择性地调整权重矩阵的奇异分量，实时调整 LLM 以适应看不见的任务。在推理过程中，Transformer-Squared 采用两遍机制：首先，调度系统识别任务属性，然后使用强化学习训练的任务特定“专家”向量进行动态混合，以获得针对传入提示的目标行为。我们的方法始终优于 LoRA 等普遍使用的方法，具有更少的参数和更高的效率。此外，Transformer-Squared 展示了跨不同 LLM 架构和模态的多功能性，包括视觉语言任务。 Transformer-Squared 代表着一次重大的飞跃，它提供了一种可扩展、高效的解决方案，可增强 LLM 的适应性和特定任务性能，为真正动态、自组织的 AI 系统铺平了道路。&quot;  https://preview.redd.it/w5tey3kebche1.png?width=907&amp;format=png&amp;auto=webp&amp;s=15550138bac56f881d8981d5e45022c4cbf6c278 https://preview.redd.it/nb3rdwagbche1.png?width=962&amp;format=png&amp;auto=webp&amp;s=df98f74dea04365eefba9bf4004ba1c3c50a3359 结论：  在本文中，我们引入了 Transformer2，为实现自适应 LLM 提供了新颖的蓝图。在这个框架内，我们首先提出了 SVF，它比之前的微调方法性能更出色，同时成本更低、组合性更强、正则化过拟合——这些都是实现可扩展自适应的关键特性。利用一组 SVF 专家作为构建模块，我们开发了三种有效的自适应策略，每种策略都具有独特的优势，并且随着测试时间条件的增加，性能优势也变得单调。 虽然 Transformer2 展示了令人鼓舞的结果，但未来仍有令人兴奋的发展机会。一个限制是 SVF 专家的能力与基础模型的潜在组件相关联。为了解决这个问题，模型合并提供了一个有希望的方向（Yu 等人，2024；Goddard 等人，2024；Akiba 等人，2024），使专门的模型能够组合成一个功能更强大的模型。此外，虽然我们基于 CEM 的适应性有效地平衡了性能和效率，但扩展到大量专门领域可能会增加一次性计算成本。然而，这种权衡被改进的性能和增强的自适应能力的好处所抵消。模型合并和高效适应技术的进步使得模型在开放排行榜上占据主导地位，使它们成为 Transformer2 基础模型的有力候选者，并为自适应 LLM 开辟了新的可能性。     提交人    /u/Jind0sh   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iicsz0/r_transformersquared_selfadaptive_llms/</guid>
      <pubDate>Wed, 05 Feb 2025 15:39:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 BNN 或 BART 来学习 DAG 中的关系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iicf2h/d_bnn_or_bart_to_learn_relationships_in_a_dag/</link>
      <description><![CDATA[大家好， 您发现什么方法效果更好？ 因此，从我的理解来看，BNN 更难以解释、计算成本更高，并且可以模拟更复杂的关系。 非常感谢    提交人    /u/Sea_Farmer5942   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iicf2h/d_bnn_or_bart_to_learn_relationships_in_a_dag/</guid>
      <pubDate>Wed, 05 Feb 2025 15:22:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过广义空间传播网络进行并行序列建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii7ayl/r_parallel_sequence_modeling_via_generalized/</link>
      <description><![CDATA[      TL;DR： 空间传播网络的改进变体 [Liu et al. 2017] 是视觉任务中 Transformers 和 SSM 的快速、有竞争力的替代方案 论文： https://arxiv.org/pdf/2501.12381 摘要：  我们提出了广义空间传播网络 (GSPN)，这是一种针对视觉任务优化的新型注意力机制，可以固有地捕获 2D 空间结构。现有的注意力模型，包括 Transformers、线性注意力和 Mamba 等状态空间模型，将多维数据处理为 1D 序列，从而损害了空间连贯性和效率。 GSPN 通过直接对空间相干图像数据进行操作并通过线扫描方法形成密集的成对连接来克服这些限制。GSPN 的核心是稳定性上下文条件，它确保在 2D 序列中进行稳定的上下文感知传播，并将具有 N 个元素的方形图的有效序列长度减少到 √N，从而显著提高计算效率。凭借可学习的、依赖于输入的权重并且不依赖位置嵌入，GSPN 在视觉任务（包括 ImageNet 分类、​​类引导图像生成和文本到图像生成）中实现了卓越的空间保真度和最先进的性能。值得注意的是，在生成 16K 图像时，GSPN 可将带有 softmax-attention 的 SD-XL 加速超过 84 倍。  视觉摘要： https://preview.redd.it/5j4c125wsahe1.png?width=693&amp;format=png&amp;auto=webp&amp;s=50953106c9a2bce979f97b53c67084523b6ee8e4 视觉亮点： https://preview.redd.it/4coeu5cjuahe1.png?width=1201&amp;format=png&amp;auto=webp&amp;s=31d310a75e6f19dfb904590a8d8a0d1d52f42979 https://preview.redd.it/kgfzoa4kuahe1.png?width=587&amp;format=png&amp;auto=webp&amp;s=0f30e6574eab0fd057e8bab2a029ed004c1a2432 https://preview.redd.it/79jjec7luahe1.png?width=1337&amp;format=png&amp;auto=webp&amp;s=eb24ff967759f174ec03e6984d2a7da310742ddc https://preview.redd.it/6xttzw1muahe1.png?width=871&amp;format=png&amp;auto=webp&amp;s=670ed748ff70185c1acf5aa115939adec0c596ad https://preview.redd.it/3y02ydanuahe1.png?width=833&amp;format=png&amp;auto=webp&amp;s=f6195799f770a1d046206c9990c6697353111bb8 https://preview.redd.it/1j4ptr4puahe1.png?width=1333&amp;format=png&amp;auto=webp&amp;s=7eb319cbe18d4cc7ff4b2659a0c69a8eb962b5c4 https://preview.redd.it/yqlt590quahe1.png?width=1341&amp;format=png&amp;auto=webp&amp;s=b593155f82ac8edd5d4230f3fd9c9704be33f81a    提交人    /u/StartledWatermelon   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii7ayl/r_parallel_sequence_modeling_via_generalized/</guid>
      <pubDate>Wed, 05 Feb 2025 10:44:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] SafeRAG：检索增强生成系统的安全评估基准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii6k5c/r_saferag_a_security_evaluation_benchmark_for/</link>
      <description><![CDATA[这项工作引入了 SafeRAG，这是一个用于测试检索增强生成 (RAG) 系统中安全漏洞的基准和评估框架。研究人员系统地分析了不同 RAG 实现中的数据中毒和提示注入攻击。 关键技术要点： - 创建针对检索和生成组件的攻击媒介 - 开发标准化的安全评估指标 - 评估商业和开源 RAG 系统 - 测试各种防御机制，包括输入验证和输出过滤 - 测量攻击成功率和安全措施的性能影响 主要结果： - 商业 RAG 实现比开源版本显示出更好的安全性 - 输入验证提高了安全性但降低了性能 - 当前的防御机制无法阻止所有已识别的攻击类型 - 检索组件比预期更容易受到中毒 - 生成组件表现出对提示注入的敏感性 我认为这项工作揭示了 RAG 安全性中的关键漏洞，需要在敏感应用程序中部署之前解决。基准测试应该可以帮助开发人员更好地评估他们的系统，尽管安全措施的性能权衡仍然是一个重大挑战。该方法似乎很可靠，但可能需要扩展以涵盖新出现的攻击媒介。 我认为最有价值的贡献是标准化测试框架——它为该领域提供了一种衡量和比较 RAG 安全性的通用方法。这可以加速更强大系统的开发。 TLDR：用于测试 RAG 安全性的新基准表明，当前系统容易受到数据中毒和提示注入的攻击。提供了评估防御的工具和指标，但强调了使 RAG 真正安全所需的重要工作。 完整摘要在这里。论文这里。   由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii6k5c/r_saferag_a_security_evaluation_benchmark_for/</guid>
      <pubDate>Wed, 05 Feb 2025 09:47:33 GMT</pubDate>
    </item>
    <item>
      <title>研究人员和数据科学家真的会用这个吗？我正在开发一个人工智能工具来更快地找到数据集。[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ii44ba/would_researchers_and_data_scientists_actually/</link>
      <description><![CDATA[我正在开发一个 AI 平台，该平台可帮助研究人员和数据科学家使用自然语言搜索在多个来源（Kaggle、政府门户、API、学术数据库等）中找到正确的数据集。目前，这个过程是超级手动的：大量谷歌搜索、检查不同的网站以及处理不一致的格式。我希望它能够轻松找到针对超特定问题的超级小众数据集。 Tl;dr – 我认为这可以通过聚合数据集、总结数据集（列、大小、上次更新）甚至建议相关数据集来为研究人员和 ML/数据科学家节省数小时的时间。 更长的解释： 使用此工具，您可以输入类似 “我需要有关年轻人智能手机使用情况和心理健康的数据” 的内容，它会在各个平台上找到相关数据集。它还将提供快速摘要，以便您知道是否值得下载而无需深入挖掘。  基于您的主题的智能推荐 API 集成以提取实时数据（例如来自 Twitter、Google Trends） 如果您想合并数据集，则可以使用数据集兼容性检查器  这有用吗？ 在我开始构建之前，试着看看这是否真的是人们会使用的东西。欢迎反馈！🙏    提交人    /u/paullieber98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ii44ba/would_researchers_and_data_scientists_actually/</guid>
      <pubDate>Wed, 05 Feb 2025 06:43:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前计算机视觉和语言技术领域不受欢迎的研究课题有哪些？ 2025</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</link>
      <description><![CDATA[不，我不想再听到有关 LLM 和 VLM 的更多信息了。    提交人    /u/KingsmanVince   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihzy00/d_what_are_current_unpopular_research_topics_in/</guid>
      <pubDate>Wed, 05 Feb 2025 02:43:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] LLM如何解决新的数学问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihsftt/d_how_does_llm_solves_new_math_problems/</link>
      <description><![CDATA[从架构角度来看，我理解 LLM 会处理来自用户查询和提示的标记，然后据此预测下一个标记。思路链机制本质上会推断这些预测以创建内部反馈循环，从而增加在训练期间使用强化学习时得出正确答案的可能性。当根据模型已知的信息解决问题时，此过程很有意义。 但是，当涉及到新的数学问题时，挑战不仅仅是简单的标记预测。模型必须理解问题，掌握底层逻辑，并使用适当的公理、定理或函数解决问题。它是如何做到这一点的？这个内部逻辑求解器从何而来，为 LLM 提供了解决此类问题所需的工具？ 澄清：新数学问题是指模型在训练期间未遇到的问题，这意味着它们不是以前见过的问题的完全重复。    提交人    /u/capStop1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihsftt/d_how_does_llm_solves_new_math_problems/</guid>
      <pubDate>Tue, 04 Feb 2025 21:03:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Vultr 优惠券的警告</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ihpz4k/d_warning_about_vultr_coupons/</link>
      <description><![CDATA[任何考虑使用促销积分来使用 Vultr 的人请注意 - 您的体验可能不会像预期的那样顺畅。 我有 300 美元的促销积分加上我个人存入的 5 美元（我以为是用于身份验证），但我无法使用其中任何一美元。 首先，他们要求我验证我的个人资料，我照做了。然后，他们突然要求我再存入 50 美元才能使用我已经拥有的资金 - 这实际上使我的 300 美元积分无法使用。这个要求没有提前提及，这令人沮丧。如果您已经承诺使用 Vultr，这可能不是问题，但如果您只是想测试服务，感觉很奇怪。 更糟糕的是，您不一定能够立即部署您的实例。在许多情况下，您需要打开支持票并手动请求访问权限。 他们的促销积分和存款政策具有误导性，一旦您的钱到账，您可能无法取回。他们不退款。我在他们的网站上找不到任何退款按钮，当我尝试通过 PayPal 申请退款时，他们立即暂停了我的帐户。    提交人    /u/KaiserZoldyck   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ihpz4k/d_warning_about_vultr_coupons/</guid>
      <pubDate>Tue, 04 Feb 2025 19:23:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ifnw79/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 02 Feb 2025 03:15:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>