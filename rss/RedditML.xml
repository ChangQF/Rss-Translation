<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 02 Oct 2024 15:18:33 GMT</lastBuildDate>
    <item>
      <title>[D] 对一系列表情符号进行二元分类..已达到 70% l..需要 95%😮‍💨</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fuhzon/d_binary_classification_on_a_sequence_of/</link>
      <description><![CDATA[我有一个包含 2 列的数据集：表情符号和标签 表情符号列的每一行包含 13 个表情符号的序列和相应的标签 0/1。 给定 test.csv、validation.csv，我已经完成了诸如物流注册、svm、随机森林、XGB 等常规操作。 我在 validation.csv 上获得的最大准确率为 70% 我必须获得至少 95% 的准确率。 如何继续？ 我正在做的是使用 python ord() 将每个表情符号转换为其对应的整数 unicode。数据集被转换为 13 个特征和一个标签。完成 StandardScalar 转换并完成常规分类。    提交人    /u/divine_watcher   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fuhzon/d_binary_classification_on_a_sequence_of/</guid>
      <pubDate>Wed, 02 Oct 2024 14:48:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 NotebookLM + Daily Medical AI Papers 进行实验：完美组合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fugsec/d_experiment_with_notebooklm_daily_medical_ai/</link>
      <description><![CDATA[      我们正在努力让我们的医学 AI/LLM 更新更具吸引力，更容易理解！ 我们已经收到了大量对我们的每日医疗 AI 论文。除了书面摘要外，我们还很高兴地宣布发布视频播客版本，您可以在工作、通勤甚至早上散步时欣赏。 🤗 查看我们的第一篇论文视频播客🔥 哈佛大学演讲 - ReXplain：将放射学转化为患者友好的视频报告 这里还有 YouTube 链接 https://www.youtube.com/watch?v=vZEAiYDNoME 哈佛大学演讲 - ReXplain：将放射学转化为患者友好的视频报告 每日新医学 AI 论文:)    由    /u/aadityaura 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fugsec/d_experiment_with_notebooklm_daily_medical_ai/</guid>
      <pubDate>Wed, 02 Oct 2024 13:56:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您的 LLM 聊天机器人有多安全？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fufrd1/d_how_safe_are_your_llm_chatbots/</link>
      <description><![CDATA[大家好，我一直在解决基于 LLM 的聊天机器人护栏的安全问题。 随着组织越来越依赖 Copilot 或 Gemini 等工具来创建内部聊天机器人，保护这些 LLM 并管理适当的授权至关重要。 当这些系统汇总和解释大量组织知识时，就会出现问题，这可能导致暴露超出员工授权访问权限的敏感信息。 在管理简单的应用程序时，管理授权很简单。您可以限制用户仅查看允许他们查看的内容。但在 RAG 系统中，这变得很棘手。 例如，如果员工询问 &quot;过去两分钟内哪些服务失败了？&quot; 一个简单的 RAG 实现可以提取所有可用的日志数据，绕过任何访问控制并可能泄露敏感信息。 您在组织中是否面临这种挑战，或者您如何应对？    提交人    /u/ege-aytin   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fufrd1/d_how_safe_are_your_llm_chatbots/</guid>
      <pubDate>Wed, 02 Oct 2024 13:07:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 最新最好的图像转 3D 网格模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fu9ed0/r_latest_and_greatest_image_to_3d_mesh_model/</link>
      <description><![CDATA[现在有什么？有没有什么不错的模型可以实现这个？我记得 NVidia 前段时间展示了一些东西，但找不到任何发布的产品    提交人    /u/Ok-Information-5072   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fu9ed0/r_latest_and_greatest_image_to_3d_mesh_model/</guid>
      <pubDate>Wed, 02 Oct 2024 06:01:44 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 您使用什么资源来了解最新的 ML 研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fu7gls/discussion_what_resource_do_you_use_to_keep_up_to/</link>
      <description><![CDATA[在我的日常工作中，我致力于推荐和搜索系统，我发现很难跟上与我的工作相关的最新发展。我可以抽出时间每周阅读一篇新论文（除非它直接用于我的工作），但从噪音中分离出信号是最困难的部分。我很好奇其他人如何选择和找到与您的特定领域相关的论文、博客文章或文章来阅读？    提交人    /u/PurpleAnnieOwl   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fu7gls/discussion_what_resource_do_you_use_to_keep_up_to/</guid>
      <pubDate>Wed, 02 Oct 2024 03:56:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 应用 LoRA 后发现额外的 LoRA 适配器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fu6xlm/p_extra_lora_adapter_found_after_applying_lora/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fu6xlm/p_extra_lora_adapter_found_after_applying_lora/</guid>
      <pubDate>Wed, 02 Oct 2024 03:25:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] 处理纸质复制品</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fu1n9y/r_dealing_with_paper_reproductions/</link>
      <description><![CDATA[大家好，我目前是计算机视觉专业的一年级博士生，在小组会议期间，我在论文复现方面遇到了一些挑战。我面临的问题是，我复现的论文通常是其他论文的扩展，而这些论文又建立在更早的工作之上。当我展示我的结果时，我的导师经常会问很多详细的问题，有时是关于模型的历史或更详细的细节，我很容易感到困惑。 我通常没有时间在一周内回顾并完全理解旧论文中的数学或优化（我选修了 3 门研究课程），当我被要求解释它们时，我会感到不知所措。有时，我说得太多或太少，事后感到尴尬。问题是，我对这个话题真的很感兴趣，但在复现这些模型时，我没有时间深入研究每个方面，尽管我在会议结束后研究了这些片段。有没有其他人遇到过类似的事情？  您如何处理具有长扩展链的复现论文？例如，从头开始训练（docker 镜像不可用的情况） 当您只对旧工作有表面了解时，您如何处理会议/演示中的详细技术问题？ 在复现结果和微调模型时，有什么技巧可以平衡理解和时间管理？  我很欣赏您的想法或您在这种情况下发现有用的策略。提前谢谢您！    提交人    /u/Cool-Economy3492   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fu1n9y/r_dealing_with_paper_reproductions/</guid>
      <pubDate>Tue, 01 Oct 2024 22:57:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有关排名和推荐系统和算法的书籍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fu1ljy/d_books_on_ranking_and_recommendation_systems_and/</link>
      <description><![CDATA[关于排名和推荐系统/算法的书籍 有人可以推荐一些关于排名和推荐系统和算法的书籍吗？经典但也是更 SOTA 的主题。谢谢     提交人    /u/dirk_klement   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fu1ljy/d_books_on_ranking_and_recommendation_systems_and/</guid>
      <pubDate>Tue, 01 Oct 2024 22:55:11 GMT</pubDate>
    </item>
    <item>
      <title>[D]《思想之树》为什么是一部有影响力的作品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/</link>
      <description><![CDATA[我的导师最近让我阅读这篇 tot 论文，但在我看来，这只是又一个**花哨的快速工程工作**。tot 过程需要大量人类智能（我们应该手动将问题分为不同的步骤，并设计验证器以使此方法有效），而且成本很高，我很少看到人们在工作中使用这种方法。 尽管如此，这篇论文还是收到了很多引用，考虑到我的导师让我阅读它的事实，我想知道我是否错过了关于这项工作的任何优点或重要含义。    提交人    /u/StraightSpeech9295   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftx04x/d_why_is_tree_of_thought_an_impactful_work/</guid>
      <pubDate>Tue, 01 Oct 2024 19:38:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 可重复性声明</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftsp3j/d_iclr_reproducibility_statement/</link>
      <description><![CDATA[我正在向 ICLR 提交论文，想知道今年的可重复性声明是否计入页数限制？ 作者指南说不计入，但征文通知说只有参考文献和附录不计入页数限制。    提交人    /u/baghalipolo   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftsp3j/d_iclr_reproducibility_statement/</guid>
      <pubDate>Tue, 01 Oct 2024 16:44:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] NotebookLM 背后的研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftr2wt/d_research_papers_behind_notebooklm/</link>
      <description><![CDATA[有没有关于 Google NotebookLM 内部工作原理的技术信息？或者有没有与手头的系统相关的论文？ 编辑：更具体地说，我指的是在引用来源的同时检索大型文档中事实的能力。我不是在谈论播客功能。    提交人    /u/Log_Dogg   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftr2wt/d_research_papers_behind_notebooklm/</guid>
      <pubDate>Tue, 01 Oct 2024 15:37:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] ECCV 应用程序可让你浏览论文并查找相关工件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftq8rj/d_eccv_app_that_lets_you_browse_papers_and_find/</link>
      <description><![CDATA[有一个应用程序可以浏览论文、按受欢迎程度排名、过滤开放模型、数据集和演示  huggingface.co/spaces/ECCV/ECCV2024-papers     提交人    /u/Illustrious_Row_9971   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftq8rj/d_eccv_app_that_lets_you_browse_papers_and_find/</guid>
      <pubDate>Tue, 01 Oct 2024 15:01:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] PyTorch 原生架构优化：torchao</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftaw4e/d_pytorch_native_architecture_optimization_torchao/</link>
      <description><![CDATA[https://pytorch.org/blog/pytorch-native-architecture-optimization/    由   提交  /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftaw4e/d_pytorch_native_architecture_optimization_torchao/</guid>
      <pubDate>Tue, 01 Oct 2024 00:16:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 29 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>