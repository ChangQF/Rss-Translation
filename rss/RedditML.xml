<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Thu, 25 Jul 2024 21:14:18 GMT</lastBuildDate>
    <item>
      <title>[P] 如何进行“样本外”预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ec4382/p_how_to_make_outofsample_predictions/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ec4382/p_how_to_make_outofsample_predictions/</guid>
      <pubDate>Thu, 25 Jul 2024 19:47:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 无监督 FSD 最终在特斯拉 HW3 上运行是否足够高效？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ec3qk9/d_will_an_unsupervised_fsd_eventually_be/</link>
      <description><![CDATA[特斯拉有一个版本 (V12.5) 的监督式“全自动驾驶”，该版本有潜力显示出显着的改进，但我们将拭目以待，看看每次临界脱离行驶里程增加了多少。（可能是 600-1000 英里。以前的版本每次临界脱离行驶里程为 100-200 英里）。 为了实现这一改进，他们将参数数量增加了 5 倍。他们只是勉强让它在 HW3 上运行（在 HW4 上有效）。这些模型已经利用了蒸馏和压缩技术。 考虑到每次临界脱离行驶里程仍需要再增加 100 倍，我认为模型参数数量必须显着增加，也许是 10 倍到 100 倍？  虽然模型提炼和压缩在不断进步，但我很难想象实现无人监督驾驶所需的更大模型会被进一步压缩。  像这样的推文暗示（大概是来自 LLAMA 2 到 LLAMA 3 等进步）这些压缩率将继续以惊人的速度增长。 https://x.com/wintonARK/status/1816537413206048915 你怎么看？对我来说，达到 robotaxi 级别保真度所需的模型尺寸增加将超过提炼方面的任何进步，因此 HW3 不太可能处理该模型。   由    /u/ZeApelido  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ec3qk9/d_will_an_unsupervised_fsd_eventually_be/</guid>
      <pubDate>Thu, 25 Jul 2024 19:32:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] EMNLP 论文评审分数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ec330j/r_emnlp_paper_review_scores/</link>
      <description><![CDATA[EMNLP 论文评审分数 我的论文总体评价是 2、2.5 和 3。它还有机会被选中吗？置信度是 2、2.5 和 3。可靠性是 2、2.5、3.5。我不确定可靠性和置信度会如何影响我的论文的选择。请解释一下这是如何运作的。我应该考虑哪些指标是重要的。 谢谢！    提交人    /u/Immediate-Hour-8466   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ec330j/r_emnlp_paper_review_scores/</guid>
      <pubDate>Thu, 25 Jul 2024 19:06:31 GMT</pubDate>
    </item>
    <item>
      <title>[N] OpenAI 宣布 SearchGPT</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ec2gk2/n_openai_announces_searchgpt/</link>
      <description><![CDATA[https://openai.com/index/searchgpt-prototype/  我们正在测试 SearchGPT，这是新 AI 搜索功能的临时原型，可为您提供快速及时的答案以及清晰且相关的来源。     提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ec2gk2/n_openai_announces_searchgpt/</guid>
      <pubDate>Thu, 25 Jul 2024 18:41:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] Local Llama 3.1 和 Marqo 检索增强生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebzm8e/p_local_llama_31_and_marqo_retrieval_augmented/</link>
      <description><![CDATA[我使用 Llama 3.1 (8B GGUF) 和 Marqo 构建了一个简单的知识问答系统入门演示。欢迎大家自行尝试并在此基础上构建！ GitHub：https://github.com/ellie-sleightholm/marqo-llama3_1     提交人    /u/elliesleight   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebzm8e/p_local_llama_31_and_marqo_retrieval_augmented/</guid>
      <pubDate>Thu, 25 Jul 2024 16:45:52 GMT</pubDate>
    </item>
    <item>
      <title>[N] 人工智能在国际数学奥林匹克竞赛中取得银牌成绩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebyx03/n_ai_achieves_silvermedal_standard_solving/</link>
      <description><![CDATA[https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/ 他们解答了 6 道 IMO 题目中的 4 道（尽管有些题目花了好几天才解答）。这样他们的分数就是 28/42，只比金牌水平低一分。    提交人    /u/we_are_mammals   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebyx03/n_ai_achieves_silvermedal_standard_solving/</guid>
      <pubDate>Thu, 25 Jul 2024 16:16:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] HuggingFace 模型 (LLM) 对文本摘要/生成任务的可解释性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebximk/r_explainability_of_huggingface_models_llms_for/</link>
      <description><![CDATA[大家好， 我正在探索负责任的人工智能领域，我已经开始阅读有关使深度学习模型可解释的方法和工具。我已经使用 SHAP 和 LIMe 来实现 ML 模型可解释性。但是，我不确定它们在解释 LLM 方面的用途。我知道这些方法与模型无关，但我们可以将这些方法用于文本生成或摘要任务吗？ 我从 Shap 那里获得了解释 GPT2 用于文本生成任务的参考文档，但我不确定是否将其用于其他较新的 LLM。此外，我想知道，有没有更好的方法来实现 LLM 的可解释人工智能？    提交人    /u/PhoenixHeadshot25   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebximk/r_explainability_of_huggingface_models_llms_for/</guid>
      <pubDate>Thu, 25 Jul 2024 15:19:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 高维概率模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebwzkq/d_highdimensional_probabilistic_models/</link>
      <description><![CDATA[目前对高维随机过程进行建模的标准方法是什么？我在图像 x 上定义了一些过程，我想为所有 x&#39; 计算 P(x&#39; | x, z)。我知道有正则化流、高斯过程等，但我不知道从哪一个开始。我特别想计算概率，而不仅仅是抽样一些 x&#39; ~ P(x, z)。    提交人    /u/smorad   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebwzkq/d_highdimensional_probabilistic_models/</guid>
      <pubDate>Thu, 25 Jul 2024 14:58:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 共享想象力：法学硕士产生幻觉</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebvd4w/r_shared_imagination_llms_hallucinate_alike/</link>
      <description><![CDATA[      很高兴分享我们最近的论文，我们在论文中证明了 LLM 在纯粹的想象和幻觉内容上表现出惊人的一致性 —— 我们称之为“共享想象空间”。为了得出这个结论，我们要求 LLM 针对假设内容（例如，物理学中虚构的概念）提出问题，然后发现它们能够以比随机概率更高的准确率回答彼此的（无法回答且毫无意义的）问题。由此，我们从多个方向研究了它的出现、普遍性和可能的​​原因，并鉴于现代 LLM 中幻觉和想象行为的一致性，讨论了对幻觉检测和计算创造力的影响。  论文链接：https://arxiv.org/abs/2407.16604 包含结果摘要和重点的推文链接：https://x.com/YilunZhou/status/1816371178501476473 如有任何问题，请随时提问！ 主要实验设置和发现。    提交人    /u/zyl1024   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebvd4w/r_shared_imagination_llms_hallucinate_alike/</guid>
      <pubDate>Thu, 25 Jul 2024 13:49:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 论文 NAACL 2024：“新闻媒体来源的可靠性评估：物以类聚”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebqclk/r_paper_naacl_2024_reliability_estimation_of_news/</link>
      <description><![CDATA[对于一般从事信息验证的人来说，例如，从事事实核查、虚假新闻检测，甚至使用新闻文章中的 RAG，这篇论文可能会有所帮助。 作者使用不同的强化学习技术，根据新闻媒体在网络上的互动方式来估计其可靠性值。 该方法易于扩展，因为可以使用源代码从 Common Crawl News 构建更大的基于超链接的交互图。作者还发布了计算值和带有新闻媒体可靠性注释的数据集：  Github repo： https://github.com/idiap/News-Media-Reliability 论文： https://aclanthology.org/2024.naacl-long.383/ 现场演示示例： https://lab.idiap.ch/criteria/  在演示中，检索到的新闻文章不仅按与查询的匹配排序，还按每个来源的估计可靠性排序（URL 域用颜色编码，从绿色到绿色）。例如，如果查询结果为红色，则向下滚动将显示来自可靠性较低的来源的结果（用红色标记）。或者，如果查询中给出了新闻 URL 或新闻媒体域名（例如 apnews.com），则会详细说明估计值（例如，显示与媒体交互的邻近来源等）。 祝大家有美好的一天！:)    提交人    /u/sergbur   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebqclk/r_paper_naacl_2024_reliability_estimation_of_news/</guid>
      <pubDate>Thu, 25 Jul 2024 09:10:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] ACL ARR 六月 (EMNLP) 评审讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebmas6/d_acl_arr_june_emnlp_review_discussion/</link>
      <description><![CDATA[太担心评论了，因为它们还没到！想与社区分享，看看大家对评论的反应！发泄一下！评论时要有礼貌。     提交人    /u/always_been_a_toy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebmas6/d_acl_arr_june_emnlp_review_discussion/</guid>
      <pubDate>Thu, 25 Jul 2024 04:45:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 提前提示你的法学硕士可以提高表现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebbtq7/r_preprompting_your_llm_increases_performance/</link>
      <description><![CDATA[UoW 的研究表明，预先提示您的 LLM，或在提出问题之前提供背景信息会带来更好的结果。即使上下文是自我生成的。 https://arxiv.org/pdf/2110.08387 例如询问， &quot;我在罗马应该做什么？&quot; 不如一系列提示有效， &quot;罗马有哪些最好的餐馆？&quot; &quot;罗马有哪些最好的观光地点？&quot; &quot;在罗马最值得做的事情&quot; &quot;我在罗马应该做什么？&quot; 我一直从轶事证据中认为情况确实如此，但很高兴看到比我更早的人在本文中解释这一点。虽然链式提示稍微耗费一些时间，但有 ChatGPT Queue 等 chrome 扩展程序可以简化该过程。 还有其他“黑客”可以挤出更好的性能吗？    提交人    /u/CalendarVarious3992   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebbtq7/r_preprompting_your_llm_increases_performance/</guid>
      <pubDate>Wed, 24 Jul 2024 20:33:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 段任何内容存储库已归档 - 为什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ebbl9h/r_segment_anything_repository_archived_why/</link>
      <description><![CDATA[您好，ML subreddit， 我最近才知道，不到一个月前（2024 年 7 月 1 日），segment anything 存储库 已被存档为公共档案。但是，我找不到有关为什么会出现这种情况的任何信息。我​​知道有很多正在开发中的 segment anything 的衍生产品，但我不知道为什么这需要公共档案。 有人知道为什么会发生这种情况以及我们可以将问题/问题重定向到哪里吗？    提交人    /u/Ben-L-921   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ebbl9h/r_segment_anything_repository_archived_why/</guid>
      <pubDate>Wed, 24 Jul 2024 20:23:42 GMT</pubDate>
    </item>
    <item>
      <title>[N] Mistral 推出“足够大”模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eb9n8c/n_mistral_releases_a_large_enough_model/</link>
      <description><![CDATA[https://mistral.ai/news/mistral-large-2407/  123B 参数 根据它们的基准，与 GPT-4o 和 Llama 3.1 405B 相当 Mistral 研究许可证允许出于研究和非商业目的使用和修改     提交人    /u/we_are_mammals   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eb9n8c/n_mistral_releases_a_large_enough_model/</guid>
      <pubDate>Wed, 24 Jul 2024 19:04:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1e8btox/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 21 Jul 2024 02:15:09 GMT</pubDate>
    </item>
    </channel>
</rss>