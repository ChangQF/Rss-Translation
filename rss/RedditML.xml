<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 01 Mar 2024 12:23:42 GMT</lastBuildDate>
    <item>
      <title>一次性学习、零次学习、少次学习[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3sijd/oneshot_zeroshot_fewshot_learning_d/</link>
      <description><![CDATA[嗨！，我对这三种技术有疑问。  这些技术仅用于生成式人工智能模型还是已经开始用于传统模型的训练？ 谢谢   由   提交 /u/kalanestis   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3sijd/oneshot_zeroshot_fewshot_learning_d/</guid>
      <pubDate>Fri, 01 Mar 2024 11:54:38 GMT</pubDate>
    </item>
    <item>
      <title>[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3sbwm/d/</link>
      <description><![CDATA[技术上是否可以制作一种工具，识别任何性视觉内容（视频或图像）或任何一般视觉内容，并在出现在屏幕上之前阻止它们它可以在任何应用程序、网站甚至任何有屏幕的设备的主屏幕上运行，并且该工具将嵌入到系统中，以便没有人可以删除该工具或禁用它？如果做这样的事情是可能的，为什么我们看不到它呢？   由   提交/u/ysf_hsn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3sbwm/d/</guid>
      <pubDate>Fri, 01 Mar 2024 11:44:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 多层感知器与支持向量分类器的比较</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3qhud/d_comparing_a_multilayer_perceptron_with_an/</link>
      <description><![CDATA[由于模型根本不同，如何使实现最具可比性。 我必须使用MLP 和 SVM 分类器并对它们进行比较。我是这样做的： MLP：  找到最佳架构：隐藏层和隐藏神经元的数量 执行网格搜索以确定最佳超参数 交叉验证：评估未见数据的泛化性能  SVM：  执行网格搜索以确定最佳超参数 交叉验证：评估未见数据的泛化性能  然后比较两个模型在测试数据上的性能评估 F1、召回率、精确度、混淆矩阵 我是否遗漏了一些重要的东西？   由   提交 /u/Jumpy-Wrongdoer1649    reddit.com/r/MachineLearning/comments/1b3qhud/d_comparing_a_multilayer_perceptron_with_an/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3qhud/d_comparing_a_multilayer_perceptron_with_an/</guid>
      <pubDate>Fri, 01 Mar 2024 09:47:12 GMT</pubDate>
    </item>
    <item>
      <title>L2-SVM 是否总是使用平方铰链损失而不是标准铰链损失？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3q9f9/does_l2svm_involve_always_using_the_squared_hinge/</link>
      <description><![CDATA[我看到很多论文都用标准铰链损失写了 L2-SVM 的目标函数，其他的则用平方铰链来写。这就是我困惑的地方。   由   提交 /u/PerfecttMachine   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3q9f9/does_l2svm_involve_always_using_the_squared_hinge/</guid>
      <pubDate>Fri, 01 Mar 2024 09:30:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无监督数据选择的稳健指南：为特定领域的机器翻译捕获令人困惑的命名实体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3ntnj/r_robust_guidance_for_unsupervised_data_selection/</link>
      <description><![CDATA[https://arxiv.org/abs/2402.19267 摘要：利用广泛的数据集可以训练多语言机器翻译模型；然而，这些模型通常无法准确翻译专业领域内的句子。尽管获取和翻译特定领域的数据会产生高昂的成本，但高质量的翻译却是不可避免的。因此，在无人监督的情况下寻找最“有效”的数据成为降低标签成本的实用策略。最近的研究表明，可以通过根据数据量选择“适当困难的数据”来找到这些有效数据。这意味着数据不应过于具有挑战性或过于简单，特别是在数据量有限的情况下。然而，我们发现建立无监督数据选择的标准仍然具有挑战性，因为“适当的难度”可能会根据所训练的数据域的不同而有所不同。我们引入了一种新颖的无监督数据选择方法“捕获令人困惑的命名实体”，该方法采用翻译命名实体中的最大推理熵作为选择度量。动机是特定领域数据中的命名实体被认为是数据中最复杂的部分，并且应该以高置信度进行预测。当使用“专业领域韩英平行语料库”进行验证时，与现有方法相比，我们的方法可以为无监督数据选择提供强有力的指导。    由   提交/u/Capital_Reply_7838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3ntnj/r_robust_guidance_for_unsupervised_data_selection/</guid>
      <pubDate>Fri, 01 Mar 2024 06:45:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] StiefelGen：一种简单的、与模型无关的黎曼流形时间序列数据增强方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3mpli/r_stiefelgen_a_simple_model_agnostic_approach_for/</link>
      <description><![CDATA[ 由   提交 /u/NorfLandan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3mpli/r_stiefelgen_a_simple_model_agnostic_approach_for/</guid>
      <pubDate>Fri, 01 Mar 2024 05:39:16 GMT</pubDate>
    </item>
    <item>
      <title>DeepMind 推出 Hawk 和 Griffin [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3leks/deepmind_introduces_hawk_and_griffin_r/</link>
      <description><![CDATA[        由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3leks/deepmind_introduces_hawk_and_griffin_r/</guid>
      <pubDate>Fri, 01 Mar 2024 04:28:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI OSS 项目向贡献者开放？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3fmno/d_ai_oss_projects_open_to_contributors/</link>
      <description><![CDATA[我有一个大约 8 人的团队正在考虑尝试为一些 AI OSS 做出贡献，我想知道这里是否有人有任何最喜欢的项目已经受到巨大关注？我们对执行以下操作之一的 OSS 项目特别感兴趣：  让凡人能够相对经济地扩展训练或微调（当我说凡人时，我指的是我们中的凡人）没有 OpenAI 的数十亿） 更轻松、更直观地将非结构化数据（随机数据库表、pdf、网站等）转换为可随时进行微调的格式 &lt; li&gt;可用的代理（我不太相信我们已经为无监督人工智能做好了准备，所以这可能是列表中最低的代理之一，除非 OSS 领域的某些东西看起来确实很有前途） 将运行时上下文纳入 LLM，而无需对运行系统的详细信息进行配置或编程，以便您可以向 LLM 提出问题，例如“告诉我是否有任何与我认为的正常健康运行时状态相比发生了变化的情况”&lt; /li&gt; 专门针对 LLM 世界的新版本构建/部署/测试工具，使故障排除变得更加容易，因为它们更加配置驱动且 LLM 友好，并且运行时间和动态性较低？  &lt;该列表有点像我希望帮助加速​​ LLM 驱动的开发的愿望清单，现在我想要找到正在做这些事情的 OSS 项目（有牵引力！）。有人看到什么了吗？或者如果做不到这一点，任何人都知道如何搜索它们或向谁询问它们？   由   提交/u/jonxtensen  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3fmno/d_ai_oss_projects_open_to_contributors/</guid>
      <pubDate>Thu, 29 Feb 2024 23:56:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 ViT 比 SWIN 更常用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b3bhbd/d_why_is_vit_more_commonly_used_than_swin/</link>
      <description><![CDATA[我仍在阅读，但我阅读的大多数计算机视觉论文都使用 ViT 作为其主干，而不是 SWIN 或其他类似的架构，但为什么呢？  ​ ViT 论文必须在 303M 图像 JFT 数据集上预训练模型，以击败 ImageNet 上的早期卷积模型，而 SWIN 无需任何预训练即可实现更好的性能。训练。我想，如果 SWIN 以同样的方式进行预训练，即使不是更高的性能，也能在 ImageNet 上实现相当的性能，但不可否认的是，我还没有看到任何工作来验证这个想法。 ​ 这只是 ViT 优先的情况，所以现在每个人都使用它作为默认值还是还有其他原因？   由   提交 /u/PM_ME_JOB_OFFER   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b3bhbd/d_why_is_vit_more_commonly_used_than_swin/</guid>
      <pubDate>Thu, 29 Feb 2024 21:10:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 开放人工智能超级对齐快速拨款决策？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b36h5r/d_decisions_for_open_ai_superalignment_fast_grants/</link>
      <description><![CDATA[大家好， 这笔拨款的截止日期是 2 月 18 日。有人收到回复了吗？我也不确定是否只有获奖者才会被明确通知。  提前感谢大家。   由   提交/u/South-Conference-395   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b36h5r/d_decisions_for_open_ai_superalignment_fast_grants/</guid>
      <pubDate>Thu, 29 Feb 2024 17:49:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG-嵌入降维</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2yc4f/d_rag_dimensionality_reduction_for_embeddings/</link>
      <description><![CDATA[去年早些时候，GPT 4 发布时，我读到人们对向量嵌入进行降维，特别是主成分分析，以使它们更适合 从那时起，随着 RAG 场景的发展，我就没有看到太多关于这样做的提及。 有人能阐明对 RAG 使用降维的优点吗？    由   提交 /u/BlueOrangeBerries   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2yc4f/d_rag_dimensionality_reduction_for_embeddings/</guid>
      <pubDate>Thu, 29 Feb 2024 11:40:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何一步步思考：对思维链推理的机械理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2tar4/r_how_to_think_stepbystep_a_mechanistic/</link>
      <description><![CDATA[PDF: https://arxiv.org/pdf/2402.18312.pdf  研究结果： 1. 尽管 CoT 生成的不同阶段的推理要求不同，模型的功能组件几乎保持不变。不同的神经算法被实现为类似感应电路的机制的组合。  注意力头在本体相关（或负相关）的标记之间执行信息移动。这种信息移动导致了此类令牌对的明显可识别的表示。通常，这种独特的信息运动从第一层开始一直持续到中间。虽然这种现象是零样本发生的，但上下文中的示例施加压力，要求在标记之间快速混合其他特定于任务的信息。 部署多个不同的神经通路来计算答案，这也是并行的。不同的注意力头，尽管具有不同的概率确定性，将答案标记（针对每个 CoT 子任务）写入最后的残差流。 这些并行答案生成路径收集来自不同部分的答案输入的。我们发现，在生成 CoT 时，模型从生成的上下文、问题上下文以及少样本上下文中收集答案标记。这为法学硕士在回答问题时是否真正使用通过 CoT 生成的上下文这一开放性问题提供了强有力的实证答案。 我们观察到法学硕士中间存在功能性裂痕。 （LLaMA-2 7B 情况下的第 16 个解码器块），它标志着残余流内容和注意力头功能的相移。在此裂痕之前，模型主要分配通过预训练记忆的二元关联；它完全开始遵循裂痕之前和之后的背景。这很可能与仅在裂痕之前发生的本体相关性的代币混合直接相关。同样，写答案的头也只有在裂痕之后才会出现。 （错误地）从少数样本中收集答案标记的注意力头也受到模型前半部分的限制。   代码： https://github.com/joykirat18/How-To-Think-Step-by-Step   由   提交 /u/Gaussian_Kernel   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2tar4/r_how_to_think_stepbystep_a_mechanistic/</guid>
      <pubDate>Thu, 29 Feb 2024 06:07:13 GMT</pubDate>
    </item>
    <item>
      <title>[P] 语音转文本基准：在 RTX3070 Ti 上每 1 美元转录 47,638 分钟（比托管服务成本降低 1000 倍）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b2m24h/p_speechtotext_benchmark_47638_mins_transcribed/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b2m24h/p_speechtotext_benchmark_47638_mins_transcribed/</guid>
      <pubDate>Thu, 29 Feb 2024 00:09:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] 1 位 LLM 时代：所有大型语言模型均采用 1.58 位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1b22izk/r_the_era_of_1bit_llms_all_large_language_models/</link>
      <description><![CDATA[https://arxiv.org/abs/2402.17764 摘要  最近的研究，例如 BitNet，正在为 1 位大型语言模型的新时代铺平道路（法学硕士）。在这项工作中，我们引入了一个 1 位 LLM 变体，即 BitNet b1.58，其中 LLM 的每个参数（或权重）都是三元的 {-1, 0, 1}。它在困惑度和最终任务性能方面与具有相同模型大小和训练令牌的全精度（即 FP16 或 BF16）Transformer LLM 相匹配，同时在延迟、内存、吞吐量、和能源消耗。更深刻的是，1.58 位法学硕士定义了新的扩展法则和配方，用于培训高性能且经济高效的新一代法学硕士。此外，它还实现了一种新的计算范例，并为设计针对 1 位 LLM 优化的特定硬件打开了大门。    由   提交/u/Civil_Collection7267   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1b22izk/r_the_era_of_1bit_llms_all_large_language_models/</guid>
      <pubDate>Wed, 28 Feb 2024 10:03:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1azra3g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 25 Feb 2024 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>