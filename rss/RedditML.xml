<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Fri, 28 Feb 2025 12:33:24 GMT</lastBuildDate>
    <item>
      <title>[d]增加随机森林训练时间</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j064dd/d_increase_random_forest_training_time/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我想知道用64个内核在AWS上运行回头测试时，您将如何增加训练时间？    nb：并行编程已在Python Code       &lt;！ -  sc_on-&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/konni_algo     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j064dd/d_increase_random_forest_training_time/</guid>
      <pubDate>Fri, 28 Feb 2025 12:05:08 GMT</pubDate>
    </item>
    <item>
      <title>[项目] ohara视频AI助理 -  YouTube中的聊天和摘要</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j04v4w/project_ohara_video_ai_assistant_chat_summary_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好！ 👋 我构建了ohara视频AI助手，这是一个浏览器扩展程序，可以解决我最大的挫败感之一 - 暂时暂停视频到Google。如果您喜欢从YouTube学习但讨厌杂耍选项卡并为Google填补上下文，这可能适合您！ 我是一个永恒的学习者，观看了大量的讲座，教程和深度潜水视频。我想要一种更快的方法来获取上下文，参考和见解而不会突破焦点。 谢谢，我希望这对像我这样的好奇心等无数标签的一些人都会有所帮助。欢呼！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/jinings     [link]   [注释]     ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j04v4w/project_ohara_video_ai_assistant_chat_summary_in/</guid>
      <pubDate>Fri, 28 Feb 2025 10:42:01 GMT</pubDate>
    </item>
    <item>
      <title>[R]动态词汇课程学习提高LLM训练效率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j04bwb/r_dynamic_vocabulary_curriculum_learning_improves/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  本文提出了一种新颖的LLM预培训方法，该方法使用课程学习进行词汇扩展。该模型没有从一开始就开始词汇进行完整的词汇训练，而是从较小的高频词汇开始，在训练过程中逐渐扩展。 关键技术要点： - 从〜5k最频繁的代币开始，最常见的代币，扩展到完整的词汇（〜50k词）（〜50k代币），而不是训练 - 基于模型的扩展 - 维持型号的时间表 - 维护时间表的时间表 - 维持时间表的时间表 - 维持时间表的时间表，以供应量的时间表，以实现计时量的时间表，以验证时间表 - 维持时间表的时间表，以供应量表。在早期阶段的未使用令牌 - 在125m到7b参数之间进行测试的模型测试 结果：-25％的总训练时间减少了总训练时间以达到等效性能 - 在早期训练中没有明显的模型使LLM培训更容易被计算资源有限的研究人员访问。用较小的初始词汇进行有效训练的能力可以在早期开发阶段进行更多的实验和迭代。 我认为最有趣的方面是如何挑战模型从开始时需要完全词汇的假设。结果表明，首先构建共同令牌的有力表示可能实际上可能对整体模型开发有益。 我看到的主要限制是该方法主要是在英语模型上测试的。需要进行更多的研究来验证具有不同结构特征的多语言模型或语言的益处。  tldr：LLM期间LLM预训练期间进行的循序渐进的词汇扩展可将培训时间降低25％，而不会损害模型质量，而不会损害课程学习，这表明课程学习可以使LLM培训更有效。 href =“ https://aimodels.fyi/papers/arxiv/scaling-llm-pre-training-training-vocabulary-curriculum”&gt;完整的摘要在这里。 Paper 在这里。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j04bwb/r_dynamic_vocabulary_curriculum_learning_improves/</guid>
      <pubDate>Fri, 28 Feb 2025 10:03:27 GMT</pubDate>
    </item>
    <item>
      <title>[r]找到一个用于症状疾病预测的好数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j03n2h/r_finding_a_good_dataset_for_symptombased_disease/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我希望你过得愉快。目前，我在BSIT第二届SEM中是第三年，而我的顶峰论文是关于基于Web的机器学习，可以通过输入症状来预测患者的疾病。具体来说，我专注于小儿呼吸道疾病，以便可以缩小研究范围。但是现在，我真的试图通过网上找到一个很好的数据集，我也试图在附近的诊所合作，但仍然没有运气，他们说他们的数据集是私人的，看来他们不够信任我可以使用他们的数据集，这是可以理解的。 我没有一个人要求我的关注点，所以我在这里愿意在这里找到一个好人，我会在这里找到一个好人，我可以在这里找到一个愿望我的愿望。我只需要一个好数据集来训练我的模型，我将进行所有清洁。 谢谢您阅读我的帖子并度过了美好的一天！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/factary-factor-624     [link]       &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1j03n2h/r_finding_a_good_good_dataset_for_symptompompompompompompassed_disease/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j03n2h/r_finding_a_good_dataset_for_symptombased_disease/</guid>
      <pubDate>Fri, 28 Feb 2025 09:11:30 GMT</pubDate>
    </item>
    <item>
      <title>[R]无训练的色度键含量含量生成扩散模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1j00bbs/r_trainingfree_chroma_key_content_generation/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们很高兴地宣布我们的论文“ tkg-dm：无训练的色彩键含量含量的含量生成扩散模型” 已被接受 cvpr 2025！ href =“ https://arxiv.org/abs/2411.15580”&gt; https://arxiv.org/abs/2411.15580    &gt;              dr：我们引入了 tkg-dm “ difunige difful&gt; difudion difful&gt; difudy diffff infort   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/maleficent_stay_7737      [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1j00bbs/r_trainingfree_chroma_key_content_generation/</guid>
      <pubDate>Fri, 28 Feb 2025 05:18:11 GMT</pubDate>
    </item>
    <item>
      <title>[d]普通英语到有限的词汇转换</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izwhdp/d_normal_english_to_limited_vocab_conversion/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您好， 希望这在Sub。 的范围内。 我有一个动画软件，用户可以在其中使用简单但有限的词汇来创建指令，并创建指令，并且该软件可以生成必要的动画。我现在希望用户能够使用自然的普通英语。那么，我将如何训练一个模型从天然，普通英语转换为有限的词汇说明？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/usenming     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izwhdp/d_normal_english_to_limited_vocab_conversion/</guid>
      <pubDate>Fri, 28 Feb 2025 01:45:38 GMT</pubDate>
    </item>
    <item>
      <title>[R]大语模型中的动态计划归纳</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izt1vr/r_dynamic_planning_induction_in_large_language/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如何在llms中引入元思考以更好地回答查询。介绍已被接受的工作二植物，并将在 NAACL 2025 。 摘要：研究表明推理的有效性（例如，链接的效果（例如，chain-offeriep contranive contressive），改善策略（例如，自我启动），增长了增长， （LLMS）在各种任务上，例如回答问题。但是，使用单个固定策略回答不同类型的问题的性能是次优，并且在生成的输出令牌和执行检索方面效率低下。在我们的工作中，我们提出了一种新颖的技术Dyplan，以诱导LLMS中的动态策略选择过程，以提高性能并降低提问中的计算成本。 Dyplan结合了最初的决策步骤，以选择以输入问题为条件的最合适的策略，并相应地指导LLM的响应生成。我们扩展了二型植物以呈二植物验证，添加了内部验证和校正过程，以进一步丰富生成的答案。对三个突出的多跳问题回答（MHQA）数据集进行的实验揭示了Dyplan如何将模型性能提高7-13％，同时相对于最佳基线模型，将计算成本降低了11-32％。  paper链接： https://arxiv.org/pdf/2410.23511   tweet链接： https://x.com.com/tpare.com/tparekh97/status/189524117221976764841 提交由＆＃32; /u/u/tparekh97     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izt1vr/r_dynamic_planning_induction_in_large_language/</guid>
      <pubDate>Thu, 27 Feb 2025 22:58:14 GMT</pubDate>
    </item>
    <item>
      <title>[r]信仰状态变压器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izs7c8/r_belief_state_transformers/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/rajonrondoisturtle     link&gt; link&gt; link&gt; link&gt;  32   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izs7c8/r_belief_state_transformers/</guid>
      <pubDate>Thu, 27 Feb 2025 22:19:57 GMT</pubDate>
    </item>
    <item>
      <title>[r]超越点产品：带有学习相似之处的检索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iziusf/r_beyond_dot_products_retrieval_with_learned/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  矢量数据库的世界正在爆炸。在大型语言模型的兴起以及对语义搜索的越来越多的需求下，从大规模数据集中获得信息的有效检索变得至关重要。大约最近使用点产品相似性和最大内部产品搜索（MIPS）算法的大约最近的邻居（ANN）搜索一直是该领域的主力。但是，如果我们可以超越点产品的局限性并直接学习相似之处，该怎么办？一份引人入胜的新论文，“  检索学到的相似性”       bailu ding（Microsoft）和Jiaqi Zhai（Meta）（在www &#39;25会议的会议记录中）提出了一种新颖的方法，称为逻辑（MOL），该方法为学习的相似性功能提供了一种通用界面。它不仅在建议系统和问题答案中取得了最新的结果，而且还显示出明显的延迟改善，有可能重塑矢量数据库的格局。 完整的纸张在这里写下： https：//www.shape.ai/blog/blog/blog/beyond-dot-dot-dot-drieval-drieval-with-with-with-with-with-lear-learned-learned-similarities     /u/u/skeltzyboiii     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iziusf/r_beyond_dot_products_retrieval_with_learned/</guid>
      <pubDate>Thu, 27 Feb 2025 15:49:33 GMT</pubDate>
    </item>
    <item>
      <title>[P]神经论文的语义搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izgxtb/p_semantic_search_of_neurips_papers/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我做了一个语义搜索器 https://www.papers.app来源。 贡献是欢迎贡献的，例如添加更多会议或功能（当前具有Neurips，ICML，Aistats，Colt，Corl，Corl，ICGI）。   它是如何工作的？  使用HuggingFace中的GTE-SMALL嵌入所有摘要，查找以超过80％的匹配返回所有论文。  &lt;！&lt;！ -  sc_on-&gt; 32;&gt; 32;提交由＆＃32; /u/mgamal96     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izgxtb/p_semantic_search_of_neurips_papers/</guid>
      <pubDate>Thu, 27 Feb 2025 14:24:43 GMT</pubDate>
    </item>
    <item>
      <title>[r] FFTNET：线性时间全局令牌通过自适应光谱过滤混合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izc94i/r_fftnet_lineartime_global_token_mixing_via/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  非常有趣的论文，显示了FFT在保持性能的同时如何替换变形金刚中的自我注意力。关键想法是使用快速的傅立叶变换来混合令牌之间的信息，而不是计算全部注意力矩阵。 主要技术点： - 替换二次复杂性自我关注自我关注与线性复杂性FFT操作 - 使用基于FFT的混合层 - 使用基于FFT的混合层，这些混合层可将频率域和后部转换为频率的频率范围 - 通过频率进行频率 - 在频率上进行频率 - 通过频率进行频率 - 范围 - 通过频率 - 范围 - 通过频率进行频率 - 依赖频率 - 依从性 - 依赖频率 - 依赖 - 标准变压器 关键结果： - 匹配或超过标准基准上的自我注意力表现 - 在长序列任务上表现出尤其有力的结果 - 从O（n²）减少了内存使用范围 - 跨越跨模态（视觉，语言，时间序列） - 有效地对更长的序列 进行量表，可以更效率地进行变形。在保持线性复杂性的同时保持较长序列的能力可以实现新的应用程序。 FFT方法也可能有助于我们更好地了解自我注意力的实际学习。 但是，我认为有关在很小的数据集或极大的语言模型上的表现有一些开放的问题，需要进行更多的调查。该方法还可能会错过某些明确关注的模式。  tldr：FFT可以有效替代变形金刚中的自我注意力，从而在保持性能的同时将复杂性从二次降低到线性。跨多个领域的作品，并显示出长序列的特殊希望。 完整的摘要在这里。纸在这里。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us sucke-western27     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izc94i/r_fftnet_lineartime_global_token_mixing_via/</guid>
      <pubDate>Thu, 27 Feb 2025 09:53:45 GMT</pubDate>
    </item>
    <item>
      <title>[D]想法：机器学习高尔夫？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1izbgf2/d_idea_machine_learning_golf/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  似乎在ML世界中进行的许多工作都集中在较小或更快的模型上，这些模型仍然有效，而这些模型仍然有效。在某些方面，这让我想起了代码高尔夫的实践：一个挑战，人们写了最小的程序来解决某个问题。 这样，我有了ML高尔夫的想法，这是一个友好的竞争设置，一个人必须创建一个最小的模型，仍然可以解决某个问题，以解决某个问题，例如在例如。 number of learnable parameters, or the number of bytes to store these parameters, probably including the program to load and run the model on a sample. It seems like someone did think of this before, but the problems seem contrived and unrealistic even compared to像Mnist这样的东西，因为看起来他们更旨在让人手工“编程”神经网络。它似乎也排除了可能很有趣的其他ML方法。 我想知道这是否是其他人可能感兴趣的。我觉得这可能是一个有趣的（S集）挑战，甚至与SOTA相比，由于任何涉及的型号的人都可以感兴趣。&gt;   是否会相当易于使用。       。实际上，我个人几乎没有ML背景，因此，其他比我更了解的人的意见将不胜感激。例如，有关如何运行/设置的想法，可能包括的数据集/基准，最大尺寸或最低性能等等等等等等。提交由＆＃32; /u/u/scheurneus     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1izbgf2/d_idea_machine_learning_golf/</guid>
      <pubDate>Thu, 27 Feb 2025 08:54:18 GMT</pubDate>
    </item>
    <item>
      <title>[P]训练您自己的推理模型-GRPO仅在5GB VRAM上工作</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iyv12c/p_train_your_own_reasoning_model_grpo_works_on/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿[ r/machinelearning ]（）（）folks！非常感谢2周前我们的GRPO版本的支持！我们设法使GRPO仅在Qwen2.5（1.5b）的 5GB的VRAM 上工作 - 从上一个Untsloth版本中的7GB下降： https：&gt; https：&gt; the RL recipe behind DeepSeek-R1 Zero&#39;s reasoning, and you can now do it with 90% less VRAM via Unsloth + LoRA / QLoRA!  Due to our newly added Efficient GRPO algorithms, this enables 10x longer context lengths while using 90% less VRAM vs. every other GRPO LoRA/QLoRA具有0降解的实现。 具有标准的GRPO设置，Llama 3.1（8b）20K上下文长度的培训需要510.8GB的VRAM。 However, Unsloth’s 90% VRAM reduction brings the requirement down to just 54.3GB in the same setup. We leverage our gradient checkpointing algorithm which we released a while ago.它可以巧妙地将中间激活卸载到系统RAM异步，同时仅慢1％。此剃须372GB VRAM ，因为我们需要num \ _ generations = 8。我们可以通过中间梯度累积进一步减少此内存使用。 使用Google的免费上下文使用我们的GRPO Notebook，使用Google的免费gpus： href =“ https://colab.research.google.com/github/unslothai/notebooks/blob/blob/main/nb/llama3.1_(8B”&gt; llama 3.1（8b）on colab  -grpo.ipynb）以及更多： align =“ left”&gt; metric   unsploth   trl + fa2           training Moregre Cost（GB） align =“左”&gt; 414GB      grpo内存成本（gb）   9.8gb    78.3gb  78.3gb  78.3gb    0gb   16gb      推理20K上下文（GB）   2.5GB  2.5gb  Total Memory Usage 54.3GB (90% less) 510.8GB   Also we made a Guide (with pics) for everything on GRPO + reward functions/verifiers (please let us know of any suggestions): https://docs.unsloth.ai/basics/reasoning-grpo-and-rl Thank you guys once again for all the support.对我们来说意义重大！ ：d   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/danielhanchen     [links]   &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1iyv12c/p_train_your_own_rowne_reasoning_model_grpo_grpo_works_on/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iyv12c/p_train_your_own_reasoning_model_grpo_works_on/</guid>
      <pubDate>Wed, 26 Feb 2025 18:51:23 GMT</pubDate>
    </item>
    <item>
      <title>[d]简单问题线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请在此处发布问题，而不是创建新线程。鼓励其他创建新帖子以便在此处发布的新帖子的人！ 线程将活着直到下一个，因此请继续发布标题的日期之后。 感谢大家在上一个线程中回答了上一个线程中的问题！  &lt;！ -  sc_on- sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1iwdbgs/d_simple_questions_thread/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1iwdbgs/d_simple_questions_thread/</guid>
      <pubDate>Sun, 23 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些经验丰富的人。   &lt;！ -  sc_on--&gt; 32;&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_to_be_hired/”&gt; [link]  &lt;A href =“ https://www.reddit.com/r/machinelearning/comments/1ie5qoh/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>