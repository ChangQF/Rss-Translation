<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 09 Dec 2023 03:13:50 GMT</lastBuildDate>
    <item>
      <title>微调 SDXL [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18e3c8v/fine_tuning_sdxl_p/</link>
      <description><![CDATA[嗨！这里是 ML/AI 的新手。我正在开发一个项目，并试图找出用一小组面部图像微调 SDXL、生成输出并使用一组新的面部图像重复的最佳方法（很多次） 我研究过 Replicate，它有一个非常简单的方法，而且似乎可行，但我不确定它的可扩展性或成本效益如何（看起来每次训练大约需要 0.37 美元）。  关于去哪里看有什么建议吗？非常感谢任何帮助。 ​   由   提交/u/Simple-Alps-7409   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18e3c8v/fine_tuning_sdxl_p/</guid>
      <pubDate>Sat, 09 Dec 2023 02:30:01 GMT</pubDate>
    </item>
    <item>
      <title>[D]组讨论 OpenAI 的零样本图像分类基础 CLIP 论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dzol3/group_discussion_on_openais_foundational_clip/</link>
      <description><![CDATA[大家好，今天我们就 OpenAI 的 2021 年 CLIP 论文进行了热烈的小组讨论。 每个星期五我们都在回顾当今机器学习中使用的许多最先进技术的基础知识。希望每周都能学到一点东西，并发现可以应用到自己工作中的模式。我觉得在阅读这篇论文之前总是有一些我没有完全理解的信息，所以我发现它很有帮助。 尽管截至本周这还不是开创性的研究，但我认为它很好退后一步，回顾一下基础知识，并跟上最新和最好的内容。 如果有人觉得有帮助的话，可以在此处发布注释和视频回顾： https://blog.oxen.ai/arxiv-dives-zero-shot-image -classification-with-clip/ 也希望有人能在周五参加我们的直播或推荐论文！我们有一个由 400 多名工程师和研究人员组成的非常稳定且有趣的团队。 ​  &amp;# 32；由   提交 /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dzol3/group_discussion_on_openais_foundational_clip/</guid>
      <pubDate>Fri, 08 Dec 2023 23:23:56 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 需要阅读的论文以保持最新状态</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dz1fw/research_papers_to_read_to_stay_up_to_date/</link>
      <description><![CDATA[您好！我熟悉 dnn、cnn、循环神经网络、gan、策略梯度强化学习和变压器网络的工作原理。我希望扩大我的知识并了解该领域的最新动态。您有什么建议可以阅读以了解最新情况吗？我意识到该领域正在产生大量论文，但如果有关于“不容错过”论文的建议，我将不胜感激。    ;由   提交 /u/MyFriendTheGuitar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dz1fw/research_papers_to_read_to_stay_up_to_date/</guid>
      <pubDate>Fri, 08 Dec 2023 22:53:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用大型语言模型进行超参数优化</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dxiim/r_using_large_language_models_for_hyperparameter/</link>
      <description><![CDATA[我们花了很多精力调整大型模型的超参数，但如果它们也能帮助我们调整超参数呢？ Arxiv：https://arxiv.org/abs/2312.0452 &lt;!-- SC_ON - -&gt;  由   提交/u/ImpossibleTeach880  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dxiim/r_using_large_language_models_for_hyperparameter/</guid>
      <pubDate>Fri, 08 Dec 2023 21:43:09 GMT</pubDate>
    </item>
    <item>
      <title>[R] QuIP#：SOTA 2 位法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dwb4t/r_quip_sota_2_bit_llms/</link>
      <description><![CDATA[我们很高兴推出 QuIP#，这是一种新的 SOTA LLM 量化方法，它使用 QuIP（论文）和 QuIP 的不相干处理。晶格以实现具有接近 fp16 性能的 2 位 LLM！现在您可以在 24G GPU 上运行 LLaMA 2 70B，无需卸载！ QuIP# 碾压了所有公开可用的语言建模和 2 位 PTQ 方法。零射击任务，同时概念上干净简单。我们已经发布了量化的 LLaMA、Mistral 和 OpenHermes 模型，以及完整的代码库，位于 https://github.com/Cornell- RelaxML/quip-sharp  有关 QuIP# 工作原理的更多信息，请参见此处 https:/ /cornell-relaxml.github.io/quip-sharp/. ​   由   提交/u/tsengalb99  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dwb4t/r_quip_sota_2_bit_llms/</guid>
      <pubDate>Fri, 08 Dec 2023 20:49:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 为高效架构铺平道路：StripedHyena-7B，开源模型让我们一睹变形金刚之外的世界</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dw9ia/r_paving_the_way_to_efficient_architectures/</link>
      <description><![CDATA[https://www.together.ai /blog/stripedhyena-7b   由   提交/u/hzj5790  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dw9ia/r_paving_the_way_to_efficient_architectures/</guid>
      <pubDate>Fri, 08 Dec 2023 20:47:02 GMT</pubDate>
    </item>
    <item>
      <title>[P]我制作了一个工具，可以自动进行数据清理并纠正机器学习的数据条目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dtsp5/p_i_made_a_tool_that_automates_data_cleaning_and/</link>
      <description><![CDATA[嗨，机器学习战士们， 由于拼写和快捷方式不一致，我花了几个小时手动调整数据条目，所以我构建了一个工具来使用大语言模型自动化此过程。  https://www.dataharmonizer.com/ 这个想法是一个接受 CSV 导出的工具，并且： &gt;纠正拼写不一致的情况（Coop 与 co-op） &gt;协调快捷方式（Limited 与 Ltd.） &gt;更正拼写错误（serbices 与 services） 该工具的工作原理如下：  您可以上传 CSV 文件并指定要提取和协调的行。  模型通过组合外观相似的短语来自动合并数据。 如果模型遗漏了某些组，您可以编辑建议的短语名称或进一步合并条目。  &gt; 最后，您可以再次下载 CSV 文件并将其推送到数据库  很高兴听到一些想法。谢谢:)   由   提交/u/Appressive_Cut9179   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dtsp5/p_i_made_a_tool_that_automates_data_cleaning_and/</guid>
      <pubDate>Fri, 08 Dec 2023 18:55:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] EfficientSAM：利用蒙版图像预训练实现高效分割任何内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dt8kr/r_efficientsam_leveraged_masked_image_pretraining/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2312.00863 代码：https://github.com/yformer/EfficientSAM 项目页面：https://yformer.github.io/efficient-sam/ 演示，模型GPU/CPU：https://huggingface.co/spaces/yunyangx/EfficientSAM &lt; p&gt;演示页面 2：https://6639e86fff1fc7b618.gradio.live/ 摘要：  分段任意模型 (SAM) 已成为众多视觉应用的强大工具。驱动零样本传输和高多功能性的令人印象深刻的性能的一个关键组件是在广泛的高质量 SA-1B 数据集上训练的超大型 Transformer 模型。 SAM 模型虽然有益，但巨大的计算成本限制了其在更广泛的现实世界中的应用。为了解决这一限制，我们提出了 EfficientSAM 轻量级 SAM 模型，该模型表现出良好的性能，同时大大降低了复杂性。我们的想法基于利用蒙版图像预训练 SAMI，它学习从 SAM 图像编码器重建特征，以实现有效的视觉表示学习。此外，我们采用 SAMI 预训练的轻量级图像编码器和掩模解码器来构建 EfficientSAM，并微调 SA-1B 上的模型以分割任何任务。我们对图像分类、对象检测、实例分割和语义对象检测等多个视觉任务进行评估，发现我们提出的预训练方法 SAMI 始终优于其他掩模图像预训练方法。在分割任何任务（例如零样本实例分割）时，我们的 EfficientSAM 与 SAMI 预训练的轻量级图像编码器相比其他快速 SAM 模型表现良好，具有显着的增益（例如，COCO/LVIS 上的 ~4 AP）。  https://preview.redd.it /a01gzzes645c1.png?width=1211&amp;format=png&amp;auto=webp&amp;s=dbc45f005da14c7655982406ff8fe83c32a954c3   由   提交 /u/APaperADay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dt8kr/r_efficientsam_leveraged_masked_image_pretraining/</guid>
      <pubDate>Fri, 08 Dec 2023 18:30:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于共谋圈的真诚讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dt7vt/d_a_genuine_and_honest_discussion_on_collusion/</link>
      <description><![CDATA[亲爱的 NeurIPS 同胞拒绝。当你的深度学习、强化学习、图神经网络和深度学习理论被人们飞到新奥尔良时，你意识到自己被抛在了后面。 ​ I邀请您加入我的小组治疗讨论，我们今天的主题是共谋环。 ​ 我想……第一个问题是它们是否真的存在？它们在机器学习学术界的渗透程度如何？作为一个为发表第一篇论文而奋斗多年的人，我的轶事证据表明，机器学习更多的是关于鼓手的节奏，而鼓手肯定是深度学习的粉丝。 ​ 作为一个仍在努力发表另一篇论文的人，我的轶事观察是，在过去几年里，鼓声变得更加激烈。 ​ 作为一个与同样被边缘化的其他人进行过很多很多对话的人，我们的轶事数据池并不完全是一个数据集，而是一种过滤，它不是独立同分布的，但肯定表明积极主动获取深度学习引用对我们的职业生涯来说是更好的选择。 ​ 作为目前正在审稿 ICLR/AAAI/AISTATS 的人。我的轶事证据是审稿人协调是通过秘密握手、关键词、引文、参考文献列表、主题、arxiv 预印本和shibboleths 进行的。 ​ 我希望你能找到作为一个从内向外看或从外向内看的人，勇敢地分享你的经历。 ​ 作为希望的灯塔，我提醒你阅读迈克尔·乔丹的革命尚未发生。&lt; /p&gt; ​ 作为最后一个需要思考的问题。深度学习合谋圈已经崩溃了吗？还会进一步崩溃吗？   由   提交 /u/Terrible_Button_1763   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dt7vt/d_a_genuine_and_honest_discussion_on_collusion/</guid>
      <pubDate>Fri, 08 Dec 2023 18:29:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于图表示学习的循环距离编码神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dsosl/r_recurrent_distanceencoding_neural_networks_for/</link>
      <description><![CDATA[      arXiv: https://arxiv.org/abs/2312.01538 OpenReview：https://openreview.net/forum?id=lNIj5FdXsC 摘要：   基于迭代一跳消息传递的图神经网络已被证明难以有效地利用来自远程节点的信息。相反，图变换器允许每个节点直接关注所有其他节点，但计算复杂度很高，并且必须依赖临时位置编码来烘焙图归纳偏差。在本文中，我们提出了一种新的架构来应对这些挑战。我们的方法源于深度状态空间模型在序列数据上提供的远程建模的最新突破：对于给定的目标节点，我们的模型通过其他节点到目标的最短距离来聚合其他节点，并在距离链提供其邻域结构的自然编码。由于不需要位置编码，我们凭经验证明，在各种基准上，我们的模型的性能与最先进的图变换器相比具有很强的竞争力，并且计算复杂度大大降低。此外，我们还表明，我们的模型在理论上比单跳消息传递神经网络更具表现力。  https://preview.redd.it/wf256ehd245c1.png?width=937&amp;format=png&amp;auto=webp&amp;s=3d3d15544dafdc1 c562694a0336448652cebd753   由   提交 /u/APaperADay   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dsosl/r_recurrent_distanceencoding_neural_networks_for/</guid>
      <pubDate>Fri, 08 Dec 2023 18:05:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视觉变压器的类别区分注意力图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dpgam/d_classdiscriminative_attention_maps_for_vision/</link>
      <description><![CDATA[      大家好，我刚刚在 arxiv 上发布了这个预印本，并正在考虑在哪里提交。我非常希望听到您的反馈。通常我不会把它发布在这里，但我认为这真的很有趣并且广泛有用，所以我试图设定更高的目标。 Lmk！ 基本上，我们为视觉变压器提出了类别区分注意力图（CDAM）。 CDAM 是一个热图（也称为显着性图或相关性图），显示每个像素相对于 ViT 模型中所选类别的重要性。 CDAM 保留了注意力图（高质量语义分割）的优点，同时具有类别判别性并提供隐式正则化。此外，您甚至不必在 ViT 上构建分类器。您只需选择一些共享共同对象（“概念”）的图像，CDAM 就会对此进行解释。  现场演示（上传图片）：https://cdam.informatism.com/查看 arxiv：https://arxiv.org/abs/2312.02364 Python/pytorch 实现：https://github.com/lenbrocki/CDAM ​ &amp;# x200b; https://preview .redd.it/txq752hyb35c1.png?width=2327&amp;format=png&amp;auto=webp&amp;s=9dddb8f21521d984020eedb3a1241ca8e5c6076f https://preview.redd.it/nwbft1hyb35c1.png?width=1400&amp;format=png&amp;auto=webp&amp;s= 26796e3f847ca5e247f9bd2a6ad8e4f538adf058  ​   由   提交/u/wro_o   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dpgam/d_classdiscriminative_attention_maps_for_vision/</guid>
      <pubDate>Fri, 08 Dec 2023 15:38:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在神经网络中，选择性能最好的输出神经元来训练模型是否有效？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dlsjh/d_in_neural_networks_is_it_effective_to_select/</link>
      <description><![CDATA[假设我有 M 个输入和 1 个目标。但是，我没有在模型的输出层中使用 1 个神经元，而是在输出层中放置 1000 个神经元，并使用自定义损失函数，该函数计算批量大小为 X 的目标的每个单独输出的损失。然后我可以找到每个神经元的最小平均损失批量输出。然后将基于最小损失进行反向传播。在下一个纪元中，我将保留所选神经元的权重，但会随机化其他输出神经元的权重。 这是否可能最终有用且更快收敛，还是我遗漏了某些东西？    由   提交/u/mbrostami   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dlsjh/d_in_neural_networks_is_it_effective_to_select/</guid>
      <pubDate>Fri, 08 Dec 2023 12:29:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 一边全职担任 ML 工程师一边攻读硕士学位值得吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18dg3cm/d_is_masters_while_working_full_time_as_ml/</link>
      <description><![CDATA[我目前是本科大学一年级毕业生，全职担任机器学习工程师。我的公司提供支付研究生学位的费用，我真的正在考虑攻读硕士学位。 第一个问题：对于那些从事机器学习或数据科学家的人来说，您的学位是什么？ 第二个问题：这有多糟糕？每学期上两门课合理吗？在线大学被认为还可以吗？ 第三个问题：获得硕士学位后，你看到工资上涨了多少？    ;由   提交/u/Fluid-Pipe-2831   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18dg3cm/d_is_masters_while_working_full_time_as_ml/</guid>
      <pubDate>Fri, 08 Dec 2023 05:52:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 对曼巴的看法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18d65bz/d_thoughts_on_mamba/</link>
      <description><![CDATA[   我运行了 Karparthy 的 NanoGPT，用 Mamba 在他的 TinyShakespeare 数据集上，5 分钟内它开始吐出以下内容： ​ https://preview.redd.it/4r96tp6lxx4c1.png ?width=836&amp;format=png&amp;auto=webp&amp;s=10f2f61cd4cea96f4f903cb2070835fc5d1df951 ​ https://preview.redd.it/32ler5vnxx4c1.png?width=622&amp;format=png&amp;auto=webp&amp; s=dd00e53f43dd0afa058758a987901ee6789d2258 ​ https://preview.redd.it/sc96i4xoxx4c1.png?width=678&amp;format=png&amp;auto=webp&amp;s=94d2ed279054363d3ed2b6beed65be894 68582b0  比 self-attention 快得多，也更流畅，以每秒 6 个 epoch 的速度运行。老实说，我惊呆了。 https://colab.research.google.com /drive/1g9qpeVcFa0ca0cnhmqusO4RZtQdh9umY?usp=sharing ​   一些损失图： 无截断的多头注意力（x为10秒迭代，y为损失） 带截断的多头注意力（x 是 10 秒内的迭代，y 是是损失）  Mamba 损失图（x 为 10 秒迭代次数，y 为损失） ​ ​ &lt; !-- SC_ON --&gt;  由   提交 /u/ExaminationNo8522   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18d65bz/d_thoughts_on_mamba/</guid>
      <pubDate>Thu, 07 Dec 2023 21:29:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189wh8y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>