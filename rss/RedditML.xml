<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Mon, 27 May 2024 15:15:53 GMT</lastBuildDate>
    <item>
      <title>[P]如何获得LSUN-CAT</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1tefs/p_how_can_i_get_lsuncat/</link>
      <description><![CDATA[我注意到几篇研究论文提到了 LSUN-CAT 数据集，该数据集似乎广泛用于图像生成任务。但是，我无法找到该数据集的下载链接，因为官方 LSUN github 没有“cat”选项。 class https://github.com/fyu/lsun。 任何人都可以提供有关如何访问的指导吗它？以下是其在图像生成中的使用参考：https://paperswithcode.com/ sota/image- Generation-on-lsun-cat-256-x-256 ADM 还提供使用数据集训练的权重：https://github.com/openai/guided-diffusion 感谢您的帮助！   由   提交/u/National-Resident244  /u/National-Resident244 reddit.com/r/MachineLearning/comments/1d1tefs/p_how_can_i_get_lsuncat/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1tefs/p_how_can_i_get_lsuncat/</guid>
      <pubDate>Mon, 27 May 2024 14:56:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 离散多 token 方法与传递隐藏状态以实现多模态输出和机器人控制的单 token 方法相比如何？整个行业的趋势是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1rmjl/d_how_do_discrete_multitoken_approaches_compare/</link>
      <description><![CDATA[对于连续输出，我见过使用两种不同的方法 1：模型给出了离散标记的词汇表，并可以组装它们的列表，并将其传递给解码器 2：模型为每个输出模态赋予一个标记（例如，图像标记），并且在选择时将隐藏状态传递给解码器 这两种方法的最新趋势是什么？ 2 看起来会快很多，因为你只需要 1 个令牌，但这对损失函数有何影响，因为有时你会遇到回归问题（图像生成），有时你会遇到分类问题？    由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1rmjl/d_how_do_discrete_multitoken_approaches_compare/</guid>
      <pubDate>Mon, 27 May 2024 13:33:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分形网络曾经被扩展过吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1ring/d_was_fractal_net_ever_expanded_upon/</link>
      <description><![CDATA[我一直在阅读&quot;FractalNet：无残差的超深神经网络&quot;，我想知道 FractalNet 背后的方法是否在其他文章中得到改进。    提交人    /u/research_pie   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1ring/d_was_fractal_net_ever_expanded_upon/</guid>
      <pubDate>Mon, 27 May 2024 13:28:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在 2 万美元预算下构建和持续训练自定义 NLP 模型的最佳硬件建议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1pmk2/d_optimal_hardware_recommendations_for_building/</link>
      <description><![CDATA[机器学习爱好者您好， 我目前面临一个难题，可以从这个智能社区的集体专业知识中受益匪浅。我的预算分配约为20,000 美元，目标是建立一个强大的设置，致力于开发、微调和持续训练自定义自然语言处理 (NLP) 模型，并可能利用 Hugging Face 等框架。  我最关心的两个问题（尽管还有其他问题）是：  GPU 选择： 当前前景分析：随着 Nvidia Ampere 架构的广泛进步以及对即将出现的更先进 GPU 的预期，我现在应该投资哪种具体型号？我应该考虑多个中档 GPU，例如多个 RTX 3090，还是倾向于一两个高端 A100？ 可扩展性和面向未来：性能飞跃有多显着对即将到来的架构（例如 Nvidia Hopper）有何期望？由于突破性创新，对当前一代 GPU 的大量投资是否会使其在 2-3 年内过时？   并且 2) 预构建与定制构建：  就长期弹性和可升级性而言，我应该选择 Lambda Labs 等供应商提供的预配置工作站还是Puget Systems，或者构建定制钻机会在适应性和潜在成本效率方面提供切实的好处吗？ 我认为供应商的保修和支持服务似乎很有吸引力，因为它们在维持运营连续性方面将发挥作用，这可能会影响运营连续性。证明预先设定的溢价合理吗？  最后，考虑到技术的快速过时，我想征求您对对冲投资的看法。 您将如何定位您的硬件设置，以确保至少五年的相关性，而不会遇到过快的折旧？ 我真诚地感谢您分享的任何细致入微的建议和个人经验。您的见解将有助于做出明智的战略投资。    由   提交 /u/Holiday_Enema   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1pmk2/d_optimal_hardware_recommendations_for_building/</guid>
      <pubDate>Mon, 27 May 2024 11:45:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] nDCG 分数比官方 TREC 脚本结果高很多，我不确定问题是什么。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1nxye/d_ndcg_scores_are_much_higher_than_the_official/</link>
      <description><![CDATA[我目前正在尝试使用我自己编写的 Python 函数来计算文档检索基准的 nDCG@10（它是 MIRACL 数据集） . 我正在尝试将我的结果与官方 TREC 评估脚本进行比较 (https://github.com/terrierteam /jtreceval），但我注意到我的实现比应有的高了大约 20 个点。 我正在使用的函数如下： ```Python def dcg_score(relevance_scores, k=10): dcg = 0 for idx in range(min(k, len(relevance_scores))): rel_i =相关性_scores[idx] dcg += (2 ** rel_i - 1 ) / np.log2(idx + 2) return dcg def ndcg_at_k(retrieved_docs, ground_truth, k=10): &quot;&quot;&quot;计算每个查询的 nDCG@k。&quot;&quot; ” ndcg_scores = {} 对于 query_id，retrieved_docs.items() 中的文档：relevance_scores = [1 if doc_id.docid in ground_truth.get(query_id, []) else 0 for doc_id in docs[:k]] dcg_val = dcg(relevance_scores, k) Ideal_relevance_scores = 排序（relevance_scores，reverse=True） idcg_val = dcg（ideal_relevance_scores，k） ndcg_scores[query_id] = dcg_val / idcg_val 如果 idcg_val &gt; 0 else 0.0 return ndcg_scores ``` MIRACL 基准测试没有提供任何相关性分数；它只是告诉您哪些文档对于每个查询是肯定的和否定的。因此，我使用二进制相关性分数。 我有一个字典，将每个查询 ID 映射到其自己的肯定段落 ID。相关性得分是通过将检索到的文档映射到 0 或 1 来获得的，具体取决于它们是否是积极的。 这些相关性得分首先用于计算 DCG 得分，然后用于计算nDCG。 IDCG 是通过获取相关性分数并按降序排序来计算的。 有人能指出我做错了什么吗？我相信我准确地遵循了方程式。   由   提交 /u/Seankala   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1nxye/d_ndcg_scores_are_much_higher_than_the_official/</guid>
      <pubDate>Mon, 27 May 2024 09:51:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] AstroPT：扩展天文学大型观测模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1nirc/r_astropt_scaling_large_observation_models_for/</link>
      <description><![CDATA[ 由   提交/u/Smith4242  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1nirc/r_astropt_scaling_large_observation_models_for/</guid>
      <pubDate>Mon, 27 May 2024 09:19:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 特征转换与 Catboost 相关吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1n0uc/p_is_feature_transformation_relevant_for_catboost/</link>
      <description><![CDATA[我了解功能转换对于 Catboost 很重要？我知道特征转换对于回归模型（例如处理偏度或离群值）以及某些梯度增强模型（one-hot 编码）很有用。 但是，据我所知偏度异常值并不会真正影响决策树模型，Catboost 不需要分类变量的 one-hot 编码，所以我只是想知道特征转换是否/在哪里对 Catboost 很重要。 &lt; !-- SC_ON --&gt;  由   提交/u/matushi  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1n0uc/p_is_feature_transformation_relevant_for_catboost/</guid>
      <pubDate>Mon, 27 May 2024 08:41:49 GMT</pubDate>
    </item>
    <item>
      <title>进行 ML/DL 研究的终极方式是我的方式还是你的方式？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1mxzo/ultimate_way_of_doing_research_in_mldl_is_my_way/</link>
      <description><![CDATA[嗨， 这篇文章旨在邀请您分享您处理研究的方法。我想深入研究像您这样的研究人员如何想象和处理问题，特别是如何提出想法和假设。  个人反思： 作为 3D 视觉领域，特别是点云分类/分割领域的研究人员，我&#39;我目前正在反思我自己的研究方法。就在最近，我突然意识到，我对作为一名初级研究员所做贡献的整个方式提出了质疑。  案例研究： 为了说明我当前的研究风格，让我们考虑一下我最近的一个想法。最近，我花了部分时间探索一种新颖的点云分类轻量级架构。探索了沿着点云（3d 对象）的纵轴将对称对象一分为二（切成两半）的想法。这种方法旨在实现两个目标：减少数据大小和潜在的数据增强。如果我们在管道中的某个点有两个处理分支怎么办？  如你所见，我的想法/假设完全是抽象的。我正在以一种半有形且琐碎的人类理解逻辑的方式走进这些想法。正确的？  忽略这个想法是否符合我首先提到的研究目标。这不关我的事。  中心问题：  我特别想知道这是处理问题的正确方法吗？ ？这是进行研究的最终方式吗？这个领域的想法就是这样诞生的？ 我有限的数学背景是否会阻碍更系统、数学驱动的方法来研究解决问题、可视化和思考？ 如果数学不一定是最初的重点，那么它在什么阶段变得至关重要？以后的整合会带来什么优势？ 请分享您的经验和方法。  ​   由   提交 /u/Same_Half3758   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1mxzo/ultimate_way_of_doing_research_in_mldl_is_my_way/</guid>
      <pubDate>Mon, 27 May 2024 08:35:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些 LLM 进步也适用于 100M 以下参数模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1m9ux/d_which_llm_advancements_also_work_for_sub_100m/</link>
      <description><![CDATA[大家好， 我想从头开始训练一个具有大约 50M 参数的小型语言模型。我想知道我应该为此使用什么样的架构。 我应该坚持使用良好的 GPT2 还是像分组查询注意 (GQA) 这样的技术也适用于如此小的模型大小？旋转位置嵌入 (RoPE) 也是如此。现代法学硕士似乎大多使用它，但 GPT2 没有。然后是规范化层的放置，我也不确定。 如果我只选择一个现成的架构并将其缩小，可能是最好的，但是这您现在可以推荐一个吗？为什么？   由   提交/u/CloudyCloud256   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1m9ux/d_which_llm_advancements_also_work_for_sub_100m/</guid>
      <pubDate>Mon, 27 May 2024 07:45:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视觉机械解释？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1k8w8/d_mech_interp_for_vision/</link>
      <description><![CDATA[基本标题。是否有任何论文研究将机械解释方法应用于视觉变压器？   由   提交/u/AdCompreve2426   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1k8w8/d_mech_interp_for_vision/</guid>
      <pubDate>Mon, 27 May 2024 05:24:31 GMT</pubDate>
    </item>
    <item>
      <title>[P] ASL ⭤ 英语翻译，带有 MediaPipe、PointNet、ThreeJS 和 Embeddings</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1k3nw/p_asl_english_translation_w_mediapipe_pointnet/</link>
      <description><![CDATA[嘿！我是凯文·托马斯 (Kevin Thomas)，是伯纳比南中学（也是不列颠哥伦比亚省聋人学校的所在地）的 11 年级学生！ 在过去的几个月里，我一直在开发一种工具，可以在美国语言和英语之间进行翻译手语 (ASL) 和英语。大多数现有的 ASL 翻译工具都建立在 ASL 与英语是同一种语言的误解之上。基本上，他们只将耳聋视为一种残疾，只寻求克服听力障碍，而不是翻译成美国手语本身的语言。 在我的美国手语老师的指导下，我一直在致力于一项该项目促进了这种翻译，同时尊重和保留美国手语作为主要语言。对于 ASL 接收，我使用 Google MediaPipe 增强了 100,000 多张 ASL 字母图像，并训练了一个 PointNet 模型来对聋人手写的手形进行分类。对于 ASL 表达，我增强了 9,000 多个 ASL 手势视频，嵌入了相应的单词，然后使用 ThreeJS 标记了听力正常的人所说的单词。我还使用法学硕士来提高准确性并在英语和 ASL 语法之间进行翻译。 这里是一个演示（和解释器）YouTube 视频 这里是GitHub 存储库 我是在过去几个月才开始研究 ML/AI 的！我将不胜感激任何反馈、机会或资源来继续学习和成长！请随时通过 Reddit DM 或 kevin.jt2007@gmail.com 与我联系！另外喜欢这个 Linkedin 帖子 将会转到路还很长🙏🫶   由   提交 /u/TrustedMercury   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1k3nw/p_asl_english_translation_w_mediapipe_pointnet/</guid>
      <pubDate>Mon, 27 May 2024 05:15:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] (RL) 环境复杂度与最优策略收敛的关系</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d1ctnn/r_rl_relation_between_environment_complexity_and/</link>
      <description><![CDATA[大家好，是否有一些关于环境复杂性与学习到的最优策略本身之间关系的文献？例如，如果一个环境是由“世界模型”中的VAE生成的，那么环境复杂度和策略之间的关系是什么？   由   提交/u/Main_Pressure271   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d1ctnn/r_rl_relation_between_environment_complexity_and/</guid>
      <pubDate>Sun, 26 May 2024 22:23:12 GMT</pubDate>
    </item>
    <item>
      <title>[D]《创世记》等中文文本经过精心翻译，与英文语义完全相同，但却占用了一半的内存。由于每字节语义密度更高，使用中文训练 LLM 是否会更有效？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d152ps/d_chinese_text_such_as_genesis_meticulously/</link>
      <description><![CDATA[        提交人    /u/Civil_Repair   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d152ps/d_chinese_text_such_as_genesis_meticulously/</guid>
      <pubDate>Sun, 26 May 2024 16:25:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] ReRecall：我尝试使用开源模型和工具重新创建 Microsoft 的 Recall</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d14pad/p_rerecall_i_tried_to_recreate_microsofts_recall/</link>
      <description><![CDATA[      对我来说，召回听起来像是一场隐私噩梦，所以我想我可以尝试仅使用开源组件来制作类似的东西。如果您想试用，这里是代码： https://github.com/AbdBarho/ReRecall 总体而言，效果比我预期的要好，我使用 `mss` 截取显示器的屏幕截图，并使用 ollama 和 llava 和 mxbai embed 生成屏幕截图的描述和嵌入，然后使用 chromadb 进行存储和搜索。 这里肯定有很大的改进空间：  生成的屏幕截图描述中存在大量幻觉，这可能是 MLLM 用于生成描述的大小的组合（我使用非常小的模型，因为我有一个生锈的 1060），或者因为屏幕截图的分辨率非常高（截图后没有调整大小）。 搜索非常基础，它只匹配查询文本的嵌入通过嵌入屏幕截图，一个潜在的改进可能是在嵌入搜索之前使用该模型为用户查询提供更多信息。 我相当肯定微软并不像我一样仅仅依赖屏幕截图，还会捕获单个应用程序窗口，还会提取窗口标题等元信息，甚至可能是窗口的文本内容（与视障人士使用的文本转语音程序相同的文本），这些肯定可以改善结果。  您对可以更改的内容还有其他想法吗？ 示例（精选）： 右侧屏幕，左侧相应使用 ReRecall    提交人    /u/Abdoo2   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d14pad/p_rerecall_i_tried_to_recreate_microsofts_recall/</guid>
      <pubDate>Sun, 26 May 2024 16:08:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>