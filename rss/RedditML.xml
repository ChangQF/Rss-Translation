<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Mon, 25 Mar 2024 15:14:37 GMT</lastBuildDate>
    <item>
      <title>ICLR 2024：可证明且实用：通过 Langevin Monte Carlo 对强化学习进行有效探索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnfzrs/iclr_2024_provable_and_practical_efficient/</link>
      <description><![CDATA[ 由   提交/u/hmi2015  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnfzrs/iclr_2024_provable_and_practical_efficient/</guid>
      <pubDate>Mon, 25 Mar 2024 15:08:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 泰米尔语米斯特拉尔简介：通过法学硕士预训练开辟新的语言可能性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnfsw5/p_introducing_tamil_mistral_opening_up_new/</link>
      <description><![CDATA[嘿伙计们，你们一定要看看 Tamil Mistral 的最新更新！增强版本，可解决在现有 Mistral 框架内标记泰米尔语单词（尤其是“uyir ezuthukal”）的棘手任务。 我已将词汇量从 32k 增加到 50k，并调整了嵌入大小。另外，在使用 Mistral 基础模型进行预训练期间，我向模型输入了 25GB 的泰米尔语文本，从而大大增强了模型的大脑功能。然后，我使用特定的泰米尔语指令对其进行了微调，以进一步提高其聊天性能。 对于预训练，投入了 25GB 的泰米尔语数据集（使用 A6000 48GB 大约需要 145 小时） 。为了进行微调，使用了大约 470k 泰米尔语指令（从 Google 翻译翻译和编辑），花费了大约 20 个小时。 基本模型：泰米尔语基础模型 指令模型：泰米尔语指令模型   由   提交/u/Ok-Measurement-6286   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnfsw5/p_introducing_tamil_mistral_opening_up_new/</guid>
      <pubDate>Mon, 25 Mar 2024 15:00:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 今天我们在科技行业构建机器学习的方式出了什么问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnet6n/d_what_is_wrong_with_how_we_build_ml_in_the_tech/</link>
      <description><![CDATA[我热爱技术。尽管我已经在科技行业工作了十多年，但我仍然这样做。我坚信，只要我们面对这样一个事实：价值是集体发现的，而不是自动生成的，那么集体构建技术可以成为一种变革性的体验；停止让整个公司都去验证单一的想法；相反，他开始将探索性研究方法更深入地融入科技产品开发的结构中。  在这里写了一些关于该主题的咆哮：https://vectorheart .substack.com/p/inside-the-intensity-machine   由   提交/u/OkTeaching5518   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnet6n/d_what_is_wrong_with_how_we_build_ml_in_the_tech/</guid>
      <pubDate>Mon, 25 Mar 2024 14:18:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我还有机会吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bnd2jw/d_is_there_a_chance_for_me/</link>
      <description><![CDATA[大家好！我是一年级博士生。我一直梦想着能在像 ICLR 或 ICML 这样的优秀机器学习会议上展示我的作品。问题是我的实验室没有这方面的经验/论文。我加入的原因是这个主题和项目看起来很有趣，但实际上它们只关注问题的系统方面。我意识到了这一点，一开始我认为一旦加入，我就可以按照自己的方式工作。但你知道，对于一个刚进入这个领域的人来说，很难真正在这样的会议上做出有意义的事情。 我想知道我有机会吗？或者我应该遵循 PI 的建议？ 我还没有放弃，但我想要一些意见，以现实地实现我的目标。谢谢。   由   提交/u/little_vsgiant   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bnd2jw/d_is_there_a_chance_for_me/</guid>
      <pubDate>Mon, 25 Mar 2024 13:01:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] SIGIR 2024通知</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bncxen/d_sigir_2024_notification/</link>
      <description><![CDATA[今天发布的 SIGIR 2024 通知的讨论主题。祝大家好运。   由   提交/u/Immediate_Party_5698   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bncxen/d_sigir_2024_notification/</guid>
      <pubDate>Mon, 25 Mar 2024 12:54:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无监督聚类管道</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bna1lw/r_unsupervised_clustering_pipeline/</link>
      <description><![CDATA[大家好，我正在寻找有关我正在做的个人项目的一些建议。 目标： 许多文档包含许多信息。我想在同一上下文中对来自不同独立文档的信息进行语义分组。例如，如果有 50 份对冲基金报告，理想的输出是“两名顾问预测股票 X 将上涨，而一名顾问预测股票会下跌”等... 想法： &lt; p&gt;具有嵌入的聚类的无监督学习管道。这将供个人使用，因此最大负载将是 O(~100MB)，这意味着 Vector DB 将是过度的。这提供了使用 sklearn 在本地构建它来创建我的集群管道的机会，因为： A）搜索速度更快 B）更少麻烦 C) 更快的构建 实现： 输入： 用于文档正文提取的文件 ID 列表。 步骤： p&gt;  get_document_sentences()  输入按语义相似性聚合文档中的句子。 输出列表的列表，其中内部列表包含语义分组的句子，外部列表跨文档聚合这些组。 - 句子最初使用 &#39;. &#39; (dot_split)。 - 使用矢量化和聚类 (semantic_split) 对文档中语义相似的句子进行分组。 ： clustering_model = AgglomerativeClustering（n_clusters=None，distance_threshold=2.5，compute_full_tree=True，linkage=&#39;ward&#39;） 2）cluster_sentences（）&lt; /p&gt; - 进一步对所有文档中按语义分组的句子进行聚类，以识别更广泛的主题或上下文。 - 使用 \all 对文本进行矢量化-MiniLM-L6-v2`` - 将列表列表作为输入，其中每个列表代表一个上下文，并使用指定的聚类技术（例如，凝聚、DBSCAN、kMeans）跨文档对这些上下文进行聚类。 # 请注意，我尝试了多种聚类技术来找到最合适的一种；在“生产”中，我会选择最合适的一个。 - 输出一个列表列表，每个内部列表包含来自共享相似上下文的各种文档中的句子。 methods = [ (&#39;agglomerative&#39;, {&#39;distance_threshold&#39;: 1.2, &#39;linkage&#39;: &#39;ward&#39;}), (&#39;dbscan&#39;, {&#39;eps&#39;: 4.0, &#39;min_samples&#39;: 2, &#39;n_neighbors&#39;: 50, &#39;metricNNDescent&#39;:&#39;euclidean&#39;, &#39;metricDBSCAN&#39;:&#39;预计算&#39; }), (&#39;kmeans&#39;, {&#39;n_clusters&#39;: 30}) ]&lt; /code&gt; 输出： 按语义分组的列表上下文列表。 问题： 我得到一个密集的“质心”簇;其余的都非常稀疏，而且我没有最佳的簇数。我针对一个示例组对其进行了微调，但我过度拟合了它并且无法概括。 问题： 我的起始逻辑还好吗？如何找到最佳的簇数？如何评估聚类，而不必通过读取它们并“评分”来手动进行。输出？ 我今天想尝试一下： 请注意，1) 和 2) 是不同的方法，并且不相关。  To进一步进行超参数调整并减少 epsilon，以便仅输出高度连接的数据点。目标是质量信息，而不是指标较低的数量。 到目前为止，我已经构建了：  管道功能 1) 基于上下文的最佳文档分块 pipeline func 2) 从各种文档中分块的不是最佳信息 我是否构建 pipeline func 3 来优化 pipeline func 2) 的非最佳分组信息，或者我是否尝试首先优化管道函数 2)，然后按照我的方式工作？   由   提交/u/Queasy_Tailor_6276   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bna1lw/r_unsupervised_clustering_pipeline/</guid>
      <pubDate>Mon, 25 Mar 2024 10:11:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视觉舞台纸？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bn9ty9/d_visual_staging_paper/</link>
      <description><![CDATA[如果我使用了错误的术语，请道歉。我最近看到一篇论文能够拍摄一个人的照片，一张衣服的照片，并且能够将衣服叠加到人身上。这是一个不太可能的事情，但希望有人知道我在谈论哪篇论文，因为我没有保存它。  提前致谢。   由   提交/u/themathstudent  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bn9ty9/d_visual_staging_paper/</guid>
      <pubDate>Mon, 25 Mar 2024 09:57:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你的薪水主要取决于地理位置，而不是你的技能水平（根据 24k 样本和 300 个问题建立的薪水模型得出的结论）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bn88ql/d_your_salary_is_determined_mainly_by_geography/</link>
      <description><![CDATA[      我建立了一个模型，根据 2022 年 Kaggle 机器学习和机器学习的 23,997 条回复和 294 个问题来预测数据科学家/机器学习工程师的薪资。数据科学调查（来源：https://jobs-in-data.com/salary/data-scientist-工资） 我研究了 LGBM 模型中的特征重要性。 TL;DR：居住国家更重要一个数量级 该模型是为数据职业构建的，但在我看来它也适用于其他职业。 ​  https://preview.redd.it/6b9r67lctfqc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=73b437e43c754ede0b19e42d95655edd4b5adc95  &amp; #32；由   提交/u/pg860  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bn88ql/d_your_salary_is_determined_mainly_by_geography/</guid>
      <pubDate>Mon, 25 Mar 2024 08:03:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如果我无法理解研究论文的某些部分并且无法在 Google 搜索中找到任何相关信息，你们会推荐什么方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bn48lw/d_what_approach_do_you_guys_recommend_if_im_stuck/</link>
      <description><![CDATA[我尝试在 Google 上搜索我最近读过的论文 (Sync Dreamer) 中的一些内容。尝试过 ChatGPT，并在 Reddit 和 stackechange 上发布我的疑问。当你无法理解论文中的某些段落时，你们会使用一些技巧吗？你怎样做呢？    由   提交 /u/ChaosAdm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bn48lw/d_what_approach_do_you_guys_recommend_if_im_stuck/</guid>
      <pubDate>Mon, 25 Mar 2024 03:43:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻找矩阵分解 python 库的贡献</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bn47ev/p_looking_for_contributions_for_a_matrix/</link>
      <description><![CDATA[我已经研究 Python 包 `decompy` 有一段时间了。它是一个用于执行不同稳健矩阵分解技术（例如稳健奇异值分解和稳健主成分分析）的库。以下是链接：  Github：https://github.com/subroy13/decompy  PyPI：https://pypi.org/project/decompy/  我目前正在寻找可以通过以下方式之一增强此库的贡献者。  创建有趣的示例笔记本，展示该包的适用性。流行的例子有“自动视频监控背景建模”、“图像补全”等。 添加更多算法（此 MATLAB 库中有非详尽列表 https://github.com/andrewssobral/lrslibrary/tree/master/algorithms）。 修复错误/提出问题.    由   提交/u/subroy13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bn47ev/p_looking_for_contributions_for_a_matrix/</guid>
      <pubDate>Mon, 25 Mar 2024 03:41:22 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 训练解释 CLIP 空间的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bn2b08/research_training_a_model_to_interpret_clip_space/</link>
      <description><![CDATA[我一直在研究一些不同的 CLIP 模型。最近，使用 OpenCLIP 和较小的模型，例如 ViT-L-14:Ldatacomp_xl_s13b_b90k 我有一个有趣的小工具，它给定 [768] 空间中的特定向量，它会计算出“最接近”到目前为止，我一直在使用它来比较“哪些其他单词与该模型中选定的初始单词‘接近’？”  然后我开始思考……如果我想对一个“最接近的词”进行逆向工程，在这种情况下，对于给定的未知向量，描述性短语可能会更好地匹配随机向量。 但是如何找出最佳短语？ 然后我想知道......什么如果我可以培训法学硕士或类似的东西来解决这个问题？ 但是..我对这方面的事情很陌生，所以我想知道是否有人可以提出具体的方法？&lt; /p&gt; ​   由   提交/u/lostinspaz   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bn2b08/research_training_a_model_to_interpret_clip_space/</guid>
      <pubDate>Mon, 25 Mar 2024 02:04:15 GMT</pubDate>
    </item>
    <item>
      <title>新算法解锁计算机视觉的高分辨率见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmsk2m/new_algorithm_unlocks_highresolution_insights_for/</link>
      <description><![CDATA[      很棒的论文！ &lt;!-- SC_ON - -&gt;  由   提交/u/CrispLion1123  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmsk2m/new_algorithm_unlocks_highresolution_insights_for/</guid>
      <pubDate>Sun, 24 Mar 2024 19:06:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 请建议如何让 ML 面试对候选人来说更好</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmo6r0/d_please_recommend_ways_to_make_ml_interview/</link>
      <description><![CDATA[有一个线程抱怨 ML 面试过于详尽。 作为招聘经理，我希望获得关于制定 ML 的建议面试效果更好。  需要避免哪些事情？ 需要包括哪些好的步骤？    由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmo6r0/d_please_recommend_ways_to_make_ml_interview/</guid>
      <pubDate>Sun, 24 Mar 2024 16:01:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] VAE 还值得吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmi8gq/d_is_vae_still_worth_it/</link>
      <description><![CDATA[VAE似乎在“扩散时代”逐渐消失。与 GAN 不同。 我知道扩散可以被视为 VAE 的特例，但问题是其他 VAE 变体相对于扩散（如果有的话）有哪些优势？    由   提交 /u/Realistic_Thanks3282   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmi8gq/d_is_vae_still_worth_it/</guid>
      <pubDate>Sun, 24 Mar 2024 11:07:12 GMT</pubDate>
    </item>
    </channel>
</rss>