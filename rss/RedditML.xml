<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Wed, 22 May 2024 12:27:10 GMT</lastBuildDate>
    <item>
      <title>[P] Fish Speech TTS：30分钟克隆OpenAI TTS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cxwqb7/p_fish_speech_tts_clone_openai_tts_in_30_minutes/</link>
      <description><![CDATA[虽然我们仍在想办法改善代理对 OpenAI GPT-4o 的情绪反应，但我们已经在调整 OpenAI 的 TTS 性能方面取得了重大进展。为了开始这项实验，我们收集了 10 小时的 OpenAI TTS 数据，对 LLM（中等）和 VITS 模型进行监督微调 (SFT)，大约需要 30 分钟。之后，我们在推理过程中使用 15 秒的音频作为提示。 可用的演示：这里。 正如您所见，模型的情感、节奏、口音和音色与 OpenAI 说话者相匹配，尽管音频质量有所下降，我们正在努力解决这个问题。为了避免任何法律问题，我们无法发布经过微调的模型，但我相信每个人都可以在数小时内以大约 20 美元的价格将 fish-speech 调整到这个水平。 我们的实验表明，仅需 25 秒的提示（小样本学习），无需任何微调，该模型就可以模仿大多数行为，除了音色和读数字的方式等细节。据我们所知，您可以使用此框架用 30 分钟的数据克隆某人说英语、中文和日语的方式。 Repo：https://github.com/fishaudio/fish-speech    提交人    /u/lengyue233   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cxwqb7/p_fish_speech_tts_clone_openai_tts_in_30_minutes/</guid>
      <pubDate>Wed, 22 May 2024 10:11:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习项目有多成功？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cxtro6/d_how_successful_are_ml_projects/</link>
      <description><![CDATA[我们的团队刚刚部署了我们的第一个机器学习解决方案。我们有几个人拥有 DS/ML 证书，并在业余项目和黑客马拉松中完成了 ML，但没有人拥有统计、数学或 DS 学位，也没有人专业地完成过 ML。我们定期咨询多位 DS / ML 专家，但我们的团队中从未有专门的 DS。我们的实施成本约为 40 万美元，预计每年节省 5 万美元，运营成本为每年 2 万美元。 ​ 这似乎是在追求这不值得。这是我们的误判吗？您从事的项目的成功率是多少？您为公司付出了多少成本，而您为公司创造了（或节省）了多少钱？ ​   由   提交 /u/natidone   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cxtro6/d_how_successful_are_ml_projects/</guid>
      <pubDate>Wed, 22 May 2024 06:37:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] AI 代理的学习和贡献</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cxtf2o/d_learning_and_contributing_in_ai_agents/</link>
      <description><![CDATA[我发现由法学硕士支持的人工智能代理是一个非常有趣的话题！我想知道是否有人可以告诉我理解和贡献它所需的理论和实践背景是什么？考虑到我精通基础 NLP、RNN、LSTM 和 Transformer（仅限 SLM）等深度学习技术以及基本 RAG 管道。 此外，我还想在与 ML 相关的开源项目中工作/做出贡献我也想知道您知道哪些项目？请不要犹豫，分享您的项目:)。   由   提交/u/Working_Resident2069   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cxtf2o/d_learning_and_contributing_in_ai_agents/</guid>
      <pubDate>Wed, 22 May 2024 06:13:03 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 评估不平衡数据的指标。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cxrivi/discussion_metric_to_evaluate_imbalance_data/</link>
      <description><![CDATA[我正在处理有关分类图像的问题。我可以增强和采样我的不平衡训练集，但我的有效/测试集不平衡。我应该使用哪个指标来评估我的模型（我知道存在 F1 分数，但这也是一个多类问题）？   由   提交/u/Civil_Statement_9331   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cxrivi/discussion_metric_to_evaluate_imbalance_data/</guid>
      <pubDate>Wed, 22 May 2024 04:13:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 获得学位后，您最喜欢扩展该领域知识的方式是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cxos4s/d_what_is_your_favorite_way_to_expand_your/</link>
      <description><![CDATA[我完成了硕士学位一年多前，我获得了统计学博士学位，我的知识已经有点生疏了，我想重新鞭策自己，加深对所有这些触手可及的伟大概念的理解。我倾向于喜欢拿起一本教科书并完成它，或者找到一个很酷的数据集并构建一些模型来巩固我一直在学习的东西。 我知道除了获得博士学位或工作之外在实验室里，很难在研究方面真正取得有意义的进展；然而，老实说，我非常喜欢数学/统计学/计算机科学，所以学习这些东西可能是我在一天结束时最喜欢的放松方式。  你最喜欢的让自己成长的方式是什么？   由   提交/u/RawCS  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cxos4s/d_what_is_your_favorite_way_to_expand_your/</guid>
      <pubDate>Wed, 22 May 2024 01:45:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何将机器学习博士与云和分布式系统结合起来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cxejcc/d_how_to_combine_phd_in_machine_learning_with/</link>
      <description><![CDATA[我在大学，我想知道是否有任何博士重点关注机器学习和构建运行这些模型的大型高效系统？我真的很喜欢我的机器学习研究工作（特别是深度学习和简历）和学术工作，但我也喜欢我的云和分布式系统作为一种爱好。如果我不想攻读博士学位，我可能会做 MLops 之类的事情。 要点： -我不确定我的主题是否太模糊，或者是否我正在查找错误的搜索词，但找不到任何相关信息。  -我会寻找专注于 HPC 的实验室和教授吗？我认为 HPC 更通用，更专注于超级计算机的工作。我可能想探索边缘设备机器学习或其他规模。  -将 ML 与这些结合起来没有意义吗？大型系统上的 ML 可以被视为专注于分布式系统的 CS 博士的另一个分支吗？   由   提交 /u/LeaderElectronic8810   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cxejcc/d_how_to_combine_phd_in_machine_learning_with/</guid>
      <pubDate>Tue, 21 May 2024 18:11:33 GMT</pubDate>
    </item>
    <item>
      <title>用于货架图优化的超市图像数据集[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cxbsbl/supermarket_image_dataset_for_planogram/</link>
      <description><![CDATA[您好， 我一直在研究用于零售行业规划图优化问题的对象检测模型。到目前为止，我一直在使用 SKU110K 数据集。此数据集的问题是产品没有单独标记。所有要检测的对象都标记为“对象”。 您是否知道类似于 SKU110K 的数据集，该数据集对图像中的每个产品都有特定的标签？ 谢谢    提交人    /u/GMDragon23   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cxbsbl/supermarket_image_dataset_for_planogram/</guid>
      <pubDate>Tue, 21 May 2024 16:17:01 GMT</pubDate>
    </item>
    <item>
      <title>[P] 多项式回归博客系列中关于概率校准的帖子</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx9npr/p_a_post_on_probabilistic_calibration_in_blog/</link>
      <description><![CDATA[我个人学习伯恩斯坦基多项式回归的另一章涉及概率模型校准领域。我当然喜欢学习，我希望你也会觉得它很有趣。 系列从这里开始：https://alexshtf.github.io/2024/01/21/Bernstein.html 关于校准的最新帖子：https://alexshtf.github.io/2024/05/19/BernsteinCalibration.html   由   提交/u/alexsht1  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx9npr/p_a_post_on_probabilistic_calibration_in_blog/</guid>
      <pubDate>Tue, 21 May 2024 14:47:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 启用稀疏的基础法学硕士，以通过 Neural Magic 和 Cerebras 建立更快、更高效的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx83cs/r_enabling_sparse_foundational_llms_for_faster/</link>
      <description><![CDATA[      在 Neural Magic、Cerebras 的合作中，和 IST Austria，据我们所知，我们推出了第一个高度稀疏的基础法学硕士，在多项微调任务上完全恢复，包括聊天、代码生成、摘要等。 &lt; p&gt;热门微调任务的稀疏性与基线精度恢复Llama 2 7B 利用这些模型，我们进一步证明：  仅通过稀疏性即可在 Neural Magic 上将 CPU 的推理性能加速 3 倍，将 GPU 的推理性能加速 1.7 倍 通过量化实现复合增益，推理性能提升高达 8.6 倍。 接近利用 Cerebras CS-3 AI 加速器进行稀疏训练的理论增益。   ul&gt; 不同条件下的预填充和解码 Llama 2 7B 性能8 核 CPU 上 FP32 和 INT8 的稀疏级别。 论文：https://arxiv。 org/abs/2405.03594 模型：https://huggingface .co/collections/neuralmagic/sparse-foundational-llama-2-models-65f48cec6396309f02e74d21   由   提交/u/markurtz  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx83cs/r_enabling_sparse_foundational_llms_for_faster/</guid>
      <pubDate>Tue, 21 May 2024 13:36:34 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士作为主动学习主体</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx6pif/r_llms_as_active_learning_agents/</link>
      <description><![CDATA[        由   提交/u/Kaesebrot109   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx6pif/r_llms_as_active_learning_agents/</guid>
      <pubDate>Tue, 21 May 2024 12:29:43 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 有哪些关于算法公平性的好文章？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx63gy/research_what_are_some_great_articles_on/</link>
      <description><![CDATA[我目前正在准备关于算法公平性的演示，我想听听您的文章建议。如果这些文章是最近的，我会很高兴，但早期的里程碑文章也很受欢迎。    由   提交/u/berkaufman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx63gy/research_what_are_some_great_articles_on/</guid>
      <pubDate>Tue, 21 May 2024 11:57:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不同模态的数据是否应该在同一空间中表示？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cx3pg9/d_should_data_in_different_modalities_be/</link>
      <description><![CDATA[由于我主要研究的是语言 AI，所以我正在习惯多模式 AI。然而，培训方法似乎如此多样化，更不用说在我看来评估这些方法要困难得多。至少，我认为不同形式的数据应该表示不同的空间。研究人员是否同意“更好的方法（也许）”？   由   提交/u/Capital_Reply_7838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cx3pg9/d_should_data_in_different_modalities_be/</guid>
      <pubDate>Tue, 21 May 2024 09:25:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 您尝试过使用 Intel 和 AMD GPU 来训练模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwvoaq/r_have_you_give_a_try_to_use_intel_and_amd_gpus/</link>
      <description><![CDATA[NVIDIA 统治着数据中心 GPU 市场。最常用的 ML 框架支持 NVIDIA GPU。但我想知道使用 Intel 和 AMD GPU 训练 ML 模型的缺点和优点。您有使用过这些 GPU 的经验吗？您对性能、可用​​性、软件堆栈和生态系统有何看法？   由   提交/u/Various_Protection71   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwvoaq/r_have_you_give_a_try_to_use_intel_and_amd_gpus/</guid>
      <pubDate>Tue, 21 May 2024 01:05:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习真的对人类健康产生了影响吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cwsbyw/d_has_ml_actually_moved_the_needle_on_human_health/</link>
      <description><![CDATA[我们听说机器学习用于药物发现、精准医疗、个性化治疗等已有相当一段时间了。机器学习实际上通过哪些方式改善了人类健康？ 似乎大多数治疗和诊断仍然基于数十年的专注生物学研究，而不是某种公正的机器学习方法。放射学是一个值得注意的例外，它受益于机器视觉的进步，但即使是他们似乎也很慢地接受人工智能作为临床实践。   由   提交/u/Potential_Athlete238  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cwsbyw/d_has_ml_actually_moved_the_needle_on_human_health/</guid>
      <pubDate>Mon, 20 May 2024 22:26:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cvq77y/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 May 2024 15:00:17 GMT</pubDate>
    </item>
    </channel>
</rss>