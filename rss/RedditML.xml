<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Tue, 15 Apr 2025 01:24:19 GMT</lastBuildDate>
    <item>
      <title>[d]建立一个100k+小时的高质量，道德采购的视频数据的市场，可从AI研究人员那里获得反馈</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jzffw1/d_building_a_marketplace_for_100k_hours_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 我在专门为AI实验室设计的市场上工作： 100k+小时的道德上播放的，录音室确定的视频内容用于大规模培训。 我们正在构建核心搜索范围，因此您可以通过自然进行搜索，因此可以通过搜索范围。这个想法是要使大量的视频数据集实际上可用。 为研究人员和工程师在视频上培训的一些开放问题：  您更喜欢培训数据的格式？生的？压缩（MP4）？像4K，2K或Full HD这样的分辨率？其他东西？ 我们已经进行了细分视频并可以通过自然语言进行搜索。  您可以许可您： →只是与查询 →完整视频相匹配的段 →它来自         无论如何，您通常需要较大的块或完整的数据集？ 我们处于用户发现模式并试图验证核心假设。如果您在视频或视听数据上训练，我很想听听您的想法 - 无论是在评论还是通过DM。提交由＆＃32; /u/u/playfulmenu1395     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jzffw1/d_building_a_marketplace_for_100k_hours_of/</guid>
      <pubDate>Tue, 15 Apr 2025 01:14:06 GMT</pubDate>
    </item>
    <item>
      <title>[r] AI科学家V2：通过代理树搜索的车间级自动化科学发现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jzdgyk/r_the_ai_scientistv2_workshoplevel_automated/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/milaworld       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jzdgyk/r_the_ai_scientistv2_workshoplevel_automated/</guid>
      <pubDate>Mon, 14 Apr 2025 23:39:19 GMT</pubDate>
    </item>
    <item>
      <title>[D]有关建造随机森林/Xgboost模型的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jz8boa/d_advice_on_building_random_forestxgboost_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我具有具有数百万记录和约700个变量的EMR数据。我需要创建一个随机的森林或XGBoost模型，以评估手术后30天内住院的风险。给定大量变量，我计划遵循此过程：  将数据分为培训，验证和测试集，并在培训集上执行以下步骤。 使用RF/XGBOOST的默认设置，用于rf/xgboost的默认设置，并根据功能进行超级&gt;        基于新的超参数的重新评估特征选择，并继续在功能选择和超参数调整之间迭代，评估验证集上的性能。  我的问题是：  我应该在def for the for the for the for the Andertion for for for for for for for for forf/promparem fortim forters inf inf/empormar helting temption the Endertions上，并启用rf/XGBOST的功能。调整，还是我应该首先调整模型？我担心有如此大的数据，调整可能是不可行的。 我的方法看起来不错？请建议我可能错过任何改进或步骤。  这是我第一次使用此大小的数据。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/chemical-library4425     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jz8boa/d_advice_on_building_random_forestxgboost_model/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jz8boa/d_advice_on_building_random_forestxgboost_model/</guid>
      <pubDate>Mon, 14 Apr 2025 19:56:36 GMT</pubDate>
    </item>
    <item>
      <title>您是否仍然使用人类数据预先培训您的模型？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jz819a/do_you_still_use_human_data_to_pretrain_your/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  最近在预训练期间我们喂养LLM的数据最近一直在查看一些辩论。这让我思考，对于那个初始的基础阶段，高质量的人类数据是多么重要的？  我认为我们主要是使用合成数据进行预训练。这个想法是利用大规模生成的文本来教授模型，包括语法，语法，基本概念和常见模式。  有些人正在保留微调阶段的通常昂贵数据。  你们中的许多人仍在很大程度上依赖人类数据以进行预培训吗？我想知道您坚持下去的原因。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/deniushss     [links]   &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jz819a/do_you_still_sstill_sstill_human_human_data_to_to_to_to_to_to_pretrain_your/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jz819a/do_you_still_use_human_data_to_pretrain_your/</guid>
      <pubDate>Mon, 14 Apr 2025 19:44:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] [P] LLM体系结构列表。我正在收集有关LLM Architectures的Arxiv论文 - 寻找我所缺少的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jz80xq/d_p_list_of_llm_architectures_i_am_collecting/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿。 我正在寻找有关LLM架构（和类似）的任何主要Arxiv论文的建议和链接，我还没有。还要感谢任何帮助。 也，至于这是全部的，我有“设计”的爱好。新颖的小语言模型体系结构。我很好奇的是，是否有比我更访问计算的人可能有兴趣与我合作并与我一起做一个最终目标，即在创意共享属性下发布新颖的架构4.0 Internationallike 4.0 International（CC BY-SA 4.0）许可证？ ？  bi-mamba   bigbird   deepSeek r1   deepseek v3    hyena    hymba    jamba  jamba   linear transfors  linformanser  linformer 神经图灵机 表演者 重复的内存变压器  retnet   rwkv     s4    titans  titans   提交由＆＃32; /u/megneous     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jz80xq/d_p_p_p_list_of_llm_architectures_i_i_am_collecting/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jz80xq/d_p_list_of_llm_architectures_i_am_collecting/</guid>
      <pubDate>Mon, 14 Apr 2025 19:44:33 GMT</pubDate>
    </item>
    <item>
      <title>我如何扭曲您的噪音：扩散模型之前的时间相关噪声[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jz6shu/how_i_warped_your_noise_a_temporallycorrelated/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/bregav      &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jz6shu/how_i_warped_your_your_noise_a_a_temporporallycorrelated/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jz6shu/how_i_warped_your_noise_a_temporallycorrelated/</guid>
      <pubDate>Mon, 14 Apr 2025 18:54:56 GMT</pubDate>
    </item>
    <item>
      <title>[D]机器学习中的离群分析</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jz0qlk/d_outlier_analysis_in_machine_learning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我训练了多个ML模型，并注意到某些样本始终产生高预测错误。我想调查为什么这些样本更难预测 - 由于固有的噪音，数据质量问题或模型限制。 专注于具有高率作为异常值的样本或其他方法（例如，使用高斯流程的不确定性估算）是有意义的吗？提交由＆＃32; /u/limmick     [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jz0qlk/d_outlier_analysis_in_machine_learning/</guid>
      <pubDate>Mon, 14 Apr 2025 14:50:01 GMT</pubDate>
    </item>
    <item>
      <title>[D]语音克隆的最新tts</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jyzamc/d_latest_tts_for_voice_cloning/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好， 你们知道我可以在本地运行的任何好tts来克隆声音，最好是多语言吗？ 请否11 labs cuz cuz cuz cuz荒谬的定价，寻找我可以在本地思考的东西。   &lt;！提交由＆＃32; /u/u/no_chair9618     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jyzamc/d_latest_tts_for_voice_cloning/</guid>
      <pubDate>Mon, 14 Apr 2025 13:47:50 GMT</pubDate>
    </item>
    <item>
      <title>[d]堪萨斯州怎么了？ （Kolmogorov-Arnold网络）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jyz2vg/d_what_happened_to_kans_kolmogorovarnold_networks/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   kans似乎很有希望，但我没有听到任何实际应用。好奇是否有人从事它  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ulight_architect   href =“ https://www.reddit.com/r/machinelearning/comments/1jyz2vg/d_what_what_happend_to_kans_kolmogorovarnold_networks/  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jyz2vg/d_what_happened_to_kolmogorovarnold_networks/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jyz2vg/d_what_happened_to_kans_kolmogorovarnold_networks/</guid>
      <pubDate>Mon, 14 Apr 2025 13:37:55 GMT</pubDate>
    </item>
    <item>
      <title>[D]蒸馏被低估了。我以14倍便宜的型号复制了GPT-4O的功能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jyr6ah/d_distillation_is_underrated_i_replicated_gpt4os/</link>
      <description><![CDATA[    src =“ https://preview.itd.it/zyj7as7ogque1.png？被低估了。设法使用较小的，微调的型号来复制GPT-4O级的性能（精度为92％），并且价格便宜14倍。对于那些不熟悉的人来说，蒸馏基本上是：采用巨大，昂贵的型号，并使用它来训练更小，更便宜，更快的特定域。如果做得正确，小型模型也可以以一小部分成本执行几乎。老实说，超级有前途。好奇这里的其他人都玩过蒸馏。告诉我更多用例。  在注释中添加我的代码。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/bibious_anybody855      [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jyr6ah/d_distillation_is_underrated_i_replicated_gpt4os/</guid>
      <pubDate>Mon, 14 Apr 2025 05:12:18 GMT</pubDate>
    </item>
    <item>
      <title>[d]当从头开始训练mmpose模型时，无法复制报告的结果</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jypxab/d_unable_to_replicate_reported_results_when/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在尝试mmpose，但完全无法使用其培训脚本复制报告的性能。我尝试了几个没有成功的模型。 projects/rtmpose/rtmpose/thothbody_2d_keypoint/rtmpose-l_8xb64-270e_coco-wholebody-256x192.py     href =“ https://github.com/open-mmlab/mmpose/tree/main/main/projects/rtmpose”&gt; https://github.com/open-mmlab/mmlab/mmpose/mmain/main/main/main/projects/projects/rtmpose/rtmpose ， rtmpose 256x192，应该在可可数据集上达到61.1的整个AP。但是，我只能达到54.5的AP。我还尝试将阶段2微调持续时间从30个时代增加到300个时代，但我得到的最好的结果是AP为57.6。此外，我试图从他们提供的预告片模型中恢复培训以获取更多时代，但是表现始终如一地降低。 是否有人经历了类似的问题或对可能出了什么问题有任何见解？   &lt;！提交由＆＃32; /u/u/i_am_a_robot_      [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jypxab/d_unable_to_replicate_reported_results_when/</guid>
      <pubDate>Mon, 14 Apr 2025 03:54:28 GMT</pubDate>
    </item>
    <item>
      <title>[d]刚刚开源了一家经过10年印度市场数据的Financial LLM  - 您可以在DuckDB上运行的SQL Outputs SQL</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jyjkjf/d_just_opensourced_a_financial_llm_trained_on_10/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿， 想分享我在过去几周中一直在建立的东西 - 一个小的开源项目，这是一个很小的开源项目。 我对结构性的印度股票市场数据 -  ohlcv，ohlcv和Index Data-ex cross-10+ 10岁以上的结构性印度股票市场数据进行了调整，使一个变形金刚在结构化的印度股票市场数据上进行了微调。该模型输出SQL查询，以响应自然语言问题，例如：  “ 2021-03-31在Int_profit上是什么？ 它是100％离线 - 没有API，没有云通话 - 并用数据集预加载的DuckDB文件船。您可以将模型的SQL输出粘贴到DuckDB中，并立即获得结果。您甚至可以在不更改架构的情况下添加自己的数据。 如果您将它们接地在实际结构化数据集中，则将其构建为概念的概念。 它在此处的拥抱脸上直播：    https://huggingface.co/studentone/nifty50gpt-final        ，如果您尝试尝试或将其扩展为想法，则会喜欢反馈。欢呼。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/cod_277Killsshipment     [link]   [commist]         ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jyjkjf/d_just_opensourced_a_financial_llm_trained_on_10/</guid>
      <pubDate>Sun, 13 Apr 2025 22:15:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 2025：向SOTA的正确性转变？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jydy3j/d_icml_2025_a_shift_toward_correctness_over_sota/</link>
      <description><![CDATA[       &lt;！ -  sc_off-&gt;   icml今年的策略 - 一个很好的方向，优先考虑Chasing Sota？   &lt;！ -  sc_on-&gt; sc_on-&gt; 32;提交由＆＃32; /u/u/fit-marketing5979      ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jydy3j/d_icml_2025_a_shift_toward_correctness_over_sota/</guid>
      <pubDate>Sun, 13 Apr 2025 18:08:33 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jpdo7y/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</guid>
      <pubDate>Wed, 02 Apr 2025 02:15:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_be_hired/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Mon, 31 Mar 2025 02:30:37 GMT</pubDate>
    </item>
    </channel>
</rss>