<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 12 Feb 2025 21:15:16 GMT</lastBuildDate>
    <item>
      <title>[D] 进行微调，用更简单的激活代替复杂的激活</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inyd67/d_finetuning_to_replace_complicated_activations/</link>
      <description><![CDATA[考虑以下问题。我想在不支持某些激活层的加速器硬件上运行预训练网络进行推理。是否有成熟的技术可以微调权重，以便它们可以与其他激活函数一起使用？ 假设网络是使用 SeLU 的 EfficientNet。我能否以某种方式微调权重以适应 ReLU 或 GeLU 激活？我不想从头开始重新训练。    提交人    /u/bjourne-ml   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inyd67/d_finetuning_to_replace_complicated_activations/</guid>
      <pubDate>Wed, 12 Feb 2025 18:47:14 GMT</pubDate>
    </item>
    <item>
      <title>[P] 优化套索回归的留一法交叉验证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inw1qh/p_optimize_leaveoneout_crossvalidation_for_lasso/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inw1qh/p_optimize_leaveoneout_crossvalidation_for_lasso/</guid>
      <pubDate>Wed, 12 Feb 2025 17:14:33 GMT</pubDate>
    </item>
    <item>
      <title>[R] TAID：时间自适应插值蒸馏，用于语言模型中的高效知识转移</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1invg9p/r_taid_temporally_adaptive_interpolated/</link>
      <description><![CDATA[    /u/hardmaru   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1invg9p/r_taid_temporally_adaptive_interpolated/</guid>
      <pubDate>Wed, 12 Feb 2025 16:51:08 GMT</pubDate>
    </item>
    <item>
      <title>[R] 新论文：前沿模型能否以开放的方式自我探索并发现自己的能力？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inv1gy/r_new_paper_can_frontier_models_selfexplore_and/</link>
      <description><![CDATA[      标题：通过模型自我探索实现自动能力发现 作者： Cong Lu、Shengran Hu、Jeff Clune。 论文： https://arxiv.org/abs/2502.07577 摘要：基础模型已成为通用助手，通过对网络规模数据进行训练，在众多领域展现出多样化的能力。准确描述任何新模型的全部能力和潜在风险中的哪怕一小部分仍然具有挑战性。现有的评估方法通常需要大量的人力，而且需要付出越来越多的努力来为更强大的模型设计更艰巨的挑战。我们引入了自动能力发现 (ACD)，这是一个框架，它将一个基础模型指定为科学家，以系统地提出探索主题模型（可能是它本身）能力的开放式任务。通过将前沿模型与开放性领域的想法相结合，ACD 可以自动且系统地发现主题模型中令人惊讶的能力和失败。我们在一系列基础模型（包括 GPT、Claude 和 Llama 系列）中展示了 ACD，表明它会自动揭示任何单个团队都难以发现的数千种能力。我们通过广泛的人工调查进一步验证了我们方法的自动评分，观察到模型生成的评估和人工评估之间高度一致。通过利用基础模型创建任务和自我评估的能力，ACD 朝着可扩展、自动评估新型 AI 系统迈出了重要一步。 https://preview.redd.it/1zamtbjzjqie1.png?width=1204&amp;format=png&amp;auto=webp&amp;s=95c177136d8c77abd0b8fb4fda3d8d7f01b7a04f    提交人    /u/MolassesWeak2646   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inv1gy/r_new_paper_can_frontier_models_selfexplore_and/</guid>
      <pubDate>Wed, 12 Feb 2025 16:34:19 GMT</pubDate>
    </item>
    <item>
      <title>结构化数据解析[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ins93r/structured_data_parsing_d/</link>
      <description><![CDATA[我正在尝试构建一个管道，它可以解析非常复杂的表格结构，包括多行列标题和很可能的内联图像/文本等。我​​目前的方法是使用 LLM 清理表格结构并编写 pandas 代码来查询表格，我首先提取数据开始的行，然后将列合并为一行，并让 LLM 重命名它们并提供描述。发布后我要求它根据查询为我编写 pandas 代码，然后使用输出生成响应，目前我还在使用启发式/微调 SETbert 和很可能其他 ML 模型完成前两个步骤，发布后我将调用 LLM 编写 python 代码并生成响应，这对许多表格来说都没问题，但对于更复杂的管道来说就开始崩溃了。有人知道其他获得更好结果的方法吗，具体来说，你使用/微调了哪些模型来实现这个效果？谢谢    由   提交  /u/ashblue21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ins93r/structured_data_parsing_d/</guid>
      <pubDate>Wed, 12 Feb 2025 14:37:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Transformer 和图像到图像网络的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inqevv/d_question_regarding_transformers_and/</link>
      <description><![CDATA[最近，我有点不适应机器学习方法，这些方法的目标是将一幅图像转换为同一或不同域的另一幅图像。我在这里考虑的是分割和图像生成，尤其是 CT 或 MRI 重建等任务。  我的最新更新是 CNN 是首选架构。但与此同时，我预计，随着 LLM 和 Transformers 的出现，它们已经超越了这项任务。有人对这个主题有更多了解吗，也包括预训练模型？  提前谢谢大家！     提交人    /u/excel_foley   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inqevv/d_question_regarding_transformers_and/</guid>
      <pubDate>Wed, 12 Feb 2025 13:09:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不规则时间序列数据中的因果推断？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inpgkw/d_causal_inference_in_irregular_time_series_data/</link>
      <description><![CDATA[大家好， 我读过的很多方法都假设采样分辨率是固定的，这是有道理的。还有通过对数据进行分组来预处理数据的方法，但是你们有没有读过处理非固定采样分辨率的材料，因为因果效应确实发生在多个事件中。因果结构会是什么样子？ 这是我正在阅读的一篇论文，但我认为其中一个条件是定期采样间隔：https://arxiv.org/pdf/2312.09604 非常感谢    提交人    /u/Sea_Farmer5942   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inpgkw/d_causal_inference_in_irregular_time_series_data/</guid>
      <pubDate>Wed, 12 Feb 2025 12:17:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 作为多语言文本解毒的少样本数据注释器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1innuh3/r_llms_as_fewshot_data_annotators_for/</link>
      <description><![CDATA[本文介绍了一种使用 LLM 作为小样本学习器来生成高质量并行数据集进行文本解毒的方法。关键创新是使用现代 LLM 创建配对的有毒/无毒文本示例，在降低毒性的同时保持语义含义。 主要技术要点： - 使用精心策划的示例对进行小样本提示 - 实现多阶段过滤以确保质量 - 使用自动化指标验证语义保存 - 与现有方法相比，在保持含义的同时实现更好的毒性降低 - 创建比以前的方法更大、更高质量的并行数据集 结果： - 在标准基准上优于现有的解毒模型 - 显示出强大的跨领域泛化能力 - 仅用 3-5 个例子就证明了有效性 - 保持语义相似度得分 &gt;0.85 - 在测试集上将毒性得分降低 &gt;60% 我认为这对于需要在删除有害内容的同时保留含义的内容审核系统特别有价值。生成高质量并行数据的能力可以帮助训练更好的下游解毒模型。 我认为小样本方法特别有前景，因为它减少了对大型带注释数据集的需求，而手动创建这些数据集既昂贵又耗时。 TLDR：现代 LLM 可以使用小样本学习生成高质量的并行有毒/无毒文本对，从而为解毒系统提供更好的训练数据，同时保持语义含义。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1innuh3/r_llms_as_fewshot_data_annotators_for/</guid>
      <pubDate>Wed, 12 Feb 2025 10:17:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士可以自学如何更好地预测未来</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inks6r/r_llms_can_teach_themselves_to_better_predict_the/</link>
      <description><![CDATA[  由    /u/jsonathan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inks6r/r_llms_can_teach_themselves_to_better_predict_the/</guid>
      <pubDate>Wed, 12 Feb 2025 06:31:42 GMT</pubDate>
    </item>
    <item>
      <title>机器心理学？[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inh9cy/machine_psychologyr/</link>
      <description><![CDATA[嗨，我想知道你们中是否有人在这个领域工作过，或者对此有更多了解，我对心理学在机器学习中的应用很感兴趣。     提交人    /u/Nervous_Club09   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inh9cy/machine_psychologyr/</guid>
      <pubDate>Wed, 12 Feb 2025 03:05:33 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 新型聚类指标——Jaccard 集中指数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1indsvi/research_novel_clustering_metric_the/</link>
      <description><![CDATA[我创建了一个新的聚类指标，称为 Jaccard-Concentration Index(JCI)，并将其上传为 Python 库。我最​​初创建它是为了帮助我测试我正在开发的聚类算法，但它似乎本身就很有用，所以我把它变成了一个库。 从技术上讲，它是两个指标合二为一。有一个集中函数，用于测量值列表中的总值在一个或几个索引内的压缩程度，还有 JCI 函数，它是提供直接评估结果的主要函数。 以下是该库的摘要： Jaccard 集中指数 (JCI) 是一个 Python 库，用于使用一种新颖的指标来评估聚类（或更一般地说，分类）的质量，该指标将众所周知的 Jaccard 指数与自定义集中分数相结合。它不仅考虑预测簇和真实簇之间的最佳匹配，还测量每个预测簇的质量在真实簇中的集中程度，从而提供更细致入微的簇纯度视图。 通常，在最少数量的真实簇中分配质量的预测簇得分更高。质量分布不均匀的簇（严重偏向一个或几个真实簇）的得分甚至更高。例如，如果有 4 个真正的聚类，则按 70-30-0-0 分割分布的预测聚类的得分将高于按 65-35-0-0 分割分布的聚类，而且有趣的是，按 70-10-10-10 分割分布的聚类的得分将高于按 70-10-10-10 分割分布的聚类。这种行为源于对与真正的聚类重叠强度的双重强调以及对重叠的关注。与真实聚类具有更高的最大重叠度通常是可取的，但集中剩余的质量也很重要，因为它减少了关于聚类中点属于哪个真实类的不确定性 - 使分类更有用。 本质上，Jaccard-Concentration 指数提供了一种平衡预测的精确度和召回率的平滑方法。 有关所涉及的函数和数学的更多详细信息，请参阅 GitHub 或 PyPI 上的项目描述。 欢迎提出所有想法和评论。    提交人    /u/Significant-Agent854   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1indsvi/research_novel_clustering_metric_the/</guid>
      <pubDate>Wed, 12 Feb 2025 00:15:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] SSM 和线性注意力怎么了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1in9y30/d_what_happened_to_ssms_and_linear_attentions/</link>
      <description><![CDATA[了解该研究领域的人可以总结一下 SSM 和 softmax 注意力替代方案的当前状态吗？它们是否已用于以客户为中心的模型，还是仍在研究中？它们的承诺是否只出现在纸面上的基准测试中？或者硬件加速器是否已经蚀刻了注意力，以便它完全充满活力，而使用 SSM 或线性注意力替代方案只能提供边际收益，这对它们的复杂程度确实有吸引力？    提交人    /u/ApartmentEither4838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1in9y30/d_what_happened_to_ssms_and_linear_attentions/</guid>
      <pubDate>Tue, 11 Feb 2025 21:27:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调能赚大钱——怎么做到的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imwnnp/d_finetuning_is_making_big_moneyhow/</link>
      <description><![CDATA[嘿！ 自从我担任计算机视觉研究员以来，我一直在研究 LLM 行业。 与计算机视觉任务不同，似乎许多公司（尤其是初创公司）都依赖于基于 API 的服务，例如 GPT、Claude 和 Gemini，而不是像 Llama 或 Mistral 这样的自托管模型。我还在这个 subreddit 中看到了很多讨论微调的帖子。 这让我很好奇！据报道，Together AI 的 ARR 已达到 1 亿美元以上，令我惊讶的是，微调似乎是其主要的收入驱动因素之一。微调是如何为如此高的收入数字做出贡献的？公司是否在大力投资它以获得更好的性能、数据隐私或成本节省？ 那么，为什么要微调模型而不是使用 API（GPT、Claude 等）？我真的想知道。  很想听听您的想法 - 提前谢谢！    提交人    /u/Vivid-Entertainer752   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imwnnp/d_finetuning_is_making_big_moneyhow/</guid>
      <pubDate>Tue, 11 Feb 2025 11:41:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>