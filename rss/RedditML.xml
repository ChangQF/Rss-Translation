<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 03 Nov 2024 12:29:38 GMT</lastBuildDate>
    <item>
      <title>[D] 使用 LLM 的信念集形式逻辑和集合论？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gil6vg/d_formal_logic_and_set_theory_in_belief_sets/</link>
      <description><![CDATA[我一直在研究一个信念集，它是命题子句的集合，并使用 LLM 和余弦相似度 + 聚类 + 提示工程来近似谓词逻辑运算。 例如： $Statement1 = &quot;real estate agent help people find the right house&quot; $Statement2 = &quot;real estate agent help men find the right house&quot; 余弦相似度只能告诉我这两个语句在向量空间中接近（大约 0.93），但无法解释 Statement2 是 Statement1 的子集这一事实。 我一直在使用 LLM 和一些提示工程以及少量样本来获取这些集合关系，但我想知道是否有更简单或计算成本更低的方法（给定一组简单命题子句的信念集）- - 或者是否有已经专门针对形式逻辑进行了微调……？    提交人    /u/noellarkin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gil6vg/d_formal_logic_and_set_theory_in_belief_sets/</guid>
      <pubDate>Sun, 03 Nov 2024 11:56:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有 Science Twitter/X 的替代品？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gikys5/d_is_there_an_alternative_to_science_twitterx/</link>
      <description><![CDATA[大家好， 我一直在想，Twitter/X 上是否有科学界的替代方案，尤其是在 DS/ML 领域。在 COVID 之前和期间，我真的很喜欢那个社区，但在 Elon 上任后不久，我就离开了 Twitter，因为当时这个平台已经很有毒了，而且从那以后变得更糟了。  我知道 LinkedIn 上有一个活跃的社区，有时还不错，但大多都是试图听起来/看起来聪明的有影响力的人，还有人大肆宣传 LLM 的每件小事。我知道从那时起，其他人也离开了 Twitter 上的科学界，因此想知道过去几年是否出现了替代方案。 附言：我也会在 DS 社区中发布此消息。    提交人    /u/H4RZ3RK4S3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gikys5/d_is_there_an_alternative_to_science_twitterx/</guid>
      <pubDate>Sun, 03 Nov 2024 11:41:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在移动 RX 6700S 上使用 ROCm 进行机器学习项目？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gikbg1/d_use_rocm_for_machine_learning_projects_on_a/</link>
      <description><![CDATA[您好，我目前正在使用带有 RX 6700S GPU 的 AMD G14，并且我对运行一些机器学习项目感兴趣。我目前正在使用 Windows。 我有没有办法使用 RX 6700S GPU 在 Windows 上运行使用 tensorflow 和 pytorch 的机器学习项目？如果没有，我可以使用 WSL 来做吗？ 我还不太熟悉安装，所以如果您能给我一些详细的答案或说明，我将不胜感激。 谢谢！    提交人    /u/DBT177   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gikbg1/d_use_rocm_for_machine_learning_projects_on_a/</guid>
      <pubDate>Sun, 03 Nov 2024 10:57:53 GMT</pubDate>
    </item>
    <item>
      <title>[P] 从开源 LLM 生成 SLM 的平台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giesrc/p_platform_to_generate_slms_from_opensource_llms/</link>
      <description><![CDATA[我们很高兴收到您对我们新平台的反馈，该平台用于创建高效、经济的语言模型，从而降低飞涨的推理成本。 它是什么？一个 AI 平台，使企业能够从大型开源语言模型创建量身定制的小型语言模型 (SLM)，而无需 ML 专业知识。 我们的目标：帮助用户轻松微调、提炼和修剪模型，将模型大小缩小 4-5 倍，同时保持准确性。 结果？为您的业务定制的高性能、经济实惠的模型。 如果您能在此处分享您的反馈，我们将不胜感激：- https://forms.gle/aVu8a7WkNV5uGGJUA   由    /u/darkItachi94  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giesrc/p_platform_to_generate_slms_from_opensource_llms/</guid>
      <pubDate>Sun, 03 Nov 2024 04:12:30 GMT</pubDate>
    </item>
    <item>
      <title>有什么发声技巧吗？[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gi9afs/tips_on_generating_voices_p/</link>
      <description><![CDATA[我正在寻找一个程序，可以大声朗读我以各种声音提供的文本文件。有什么关于从哪里开始的建议吗？    提交人    /u/marksmiley   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gi9afs/tips_on_generating_voices_p/</guid>
      <pubDate>Sat, 02 Nov 2024 23:20:10 GMT</pubDate>
    </item>
    <item>
      <title>[N] Quantum Machines 和 Nvidia 利用机器学习来更接近纠错量子计算机</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gi5ohq/n_quantum_machines_and_nvidia_use_machine/</link>
      <description><![CDATA[一篇基于对 Quantum Machines 和 Nvidia 的采访的文章，介绍他们如何使用强化学习来优化脉冲，提高性能和保真度 https://techcrunch.com/2024/11/02/quantum-machines-and-nvidia-use-machine-learning-to-get-closer-to-an-error-corrected-quantum-computer/    提交人    /u/MeltingHippos   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gi5ohq/n_quantum_machines_and_nvidia_use_machine/</guid>
      <pubDate>Sat, 02 Nov 2024 20:31:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] NCA 对潜在模型的模拟（具有意义推理能力的编码器-解码器模型）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gi4xc2/d_nca_simulation_over_the_latent_encoderdecoder/</link>
      <description><![CDATA[大家好，我只是提出一个直觉，我必须评估这个领域……我想，如果我们想制作一个可以在不到 100M 个参数中推理和思考的语言模型，也许就是嵌入尽可能多的有用的宇宙中预先存在的机制。换句话说，我们停止制作语言模型，现在我们的目标是制作一个意义模型。我们回到编码器/解码器架构，两者都绑定在一起以鼓励双向映射空间。现在这是关键因素！中间的潜在变量具有位置编码，因此它是一个 3D 体积。潜在的 3D 位置被检索并用于执行场操作，因此内存需求是潜在变量的形状乘以 N 个模拟场。表示根据物理耦合变形，并反馈到 NCA（神经细胞自动机）。几年前，NCA 还未被人注意到，实际上它只是一个学习过的感知 Sobel 过滤器，它可以学习将信息存储到每个单元的隐藏状态中。我还看到，NCA 可以被教导解决迷宫问题，它是如何做到的真的很有趣。以这种方式，中间的潜在空间现在是一个灵活的体积表示空间，具有隐藏的维度和场方程，这些方程通过自然熵和流动为其提供能量，清晰的路径让单词移动并减少能量。不是对语言进行建模，而是尝试使用语言标记作为全模态模拟运算符，其中全模态性在其几何 3D 缩减中实现。也许这就是大脑的工作方式？它捕捉微观尺度上的现实现象，并有选择地移除和过滤它们，以创建消除歧义的想象空间？人类语言源自我们的欧几里得几何现实。每个词，甚至我在上一句中使用的“Descend”这个词……每个句子都有欧几里得形式。因此，如果我们创建一个欧几里得模拟空间，语言应该自动调节这个模拟并给它贴上标签？通过这种方式，我们可以创建任意数量的表示来连接模态。换句话说，当你说“X 高于 Y”时，你实际上会看到两个粒子在潜在的多场想象中的某个地方实例化，其中一些“上方”的结合粒子取决于意义空间结构的深度和分辨率。我们创建一个模拟，一个连续的细胞自动机，它本身永远不会因为过于复杂的超参数而绑定或获得稳定的牵引力，我们使用语言和数据集作为正则化！颠覆整个训练范式！现在，推理是免费的，很容易分辨出模型何时不再想思考，因为表示已经达到稳态/收敛。文本用于介绍结构和几何熵融入潜在表示，NCA 就像一个动态降噪器和“自搜索自动编码器”，学习进化规则，永远寻找更好的表示和新的优化。在升级到科学材料之前，需要先在更简单的数据集上收敛。它必须逐步组装和建模宇宙，也可能不这样做。也许你会分别训练编码器/解码器和 NCA，冻结一个而另一个保持热度。它可能具有极强的上下文学习能力。你怎么看？有很多广泛的想法，但我觉得给模型一个带有自然物理的小“游戏空间”是正确的做法。基于此架构的图像生成模型可以进行极其复杂的合成！语言模型将具有真实的想象空间，使它们能够以几何方式解决问题，模拟物体/粒子/规则等的简化表示和嵌入。至少，编码器/解码器 LLM 中某种位置基础的潜在特征似乎是一个值得研究的有力事物。    提交人    /u/ryunuck   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gi4xc2/d_nca_simulation_over_the_latent_encoderdecoder/</guid>
      <pubDate>Sat, 02 Nov 2024 19:57:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 在法学硕士课程中灌输知识</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gi27ev/p_instilling_knowledge_in_llm/</link>
      <description><![CDATA[大家好！ 我有一个信息语料库（文本），我希望我的基础模型能够学习语料库中包含的知识，这样我就可以简单地根据微调模型进行推断，而不是执行 RAG。我该怎么做？对于我读过的所有文档，它都是关于标记数据集（在我的情况下是问答）。有没有办法在 LLM 中灌输知识？ 提前致谢。    提交人    /u/mulberry-cream   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gi27ev/p_instilling_knowledge_in_llm/</guid>
      <pubDate>Sat, 02 Nov 2024 17:54:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医学 AI：顶级 LLM 研究论文/模型（2024 年 10 月 26 日至 11 月 2 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghx268/d_last_week_in_medical_ai_top_llm_research/</link>
      <description><![CDATA[   上周医学 AI：顶级 LLM 研究论文/模型（2024 年 10 月 26 日至 11 月 2 日） 本周医学 AI 论文：  Google 推出 MDAgents：用于医学决策的 LLM 自适应协作  本文介绍了MDAgents 是一个多代理框架，它为 LLM 分配协作结构以完成复杂的医疗任务，模仿现实世界的医疗决策。   医学 LLM &amp;其他模型：  Matchmaker：使用 LLM 进行模式匹配  本文介绍了 Matchmaker，这是一种用于模式匹配的组合语言模型程序，可解决数据源中的结构和语义异质性挑战。  UltraMedical：专门的生物医学模型  本文介绍了 UltraMedical，它是一组跨多个 LLM 的高质量手动和合成数据集，带有偏好注释，可用于生物医学应用。  ZALM3：视觉语言医学对话  本文介绍了 ZALM3，这是一种零样本策略，用于改善多轮多模式医学对话中的视觉语言对齐，解决在线咨询中患者提供的图像质量差的挑战。  EchoFM：超声心动图基础模型  本文介绍了EchoFM 是超声心动图视频的基础模型，采用具有时空一致性掩蔽和周期驱动对比学习的自监督学习框架，在 26 个扫描视图和不同成像模式下对超过 290,000 个视频（2000 万帧）进行了预训练。   框架和方法：  FEDKIM：联合医学知识注入 Flex-MoE：灵活模态组合 MAISI：合成医学成像 Cough-E：边缘隐私检测 MassSpecGym：分子识别  医学 LLM 应用：  DiaMond：多模态痴呆症诊断 LLM-Forest：健康数据归因 医学多模式视觉基础 与法学硕士 (LLM) 的临床证据综合  医学法学硕士 &amp;基准：  超越 H&amp;E 的组织病理学模型 心理健康咨询法学硕士 医学数据集重用分析  医疗伦理中的人工智能：  医学教育法学硕士 医学考试问题生成 临床知识图谱集成  .... 完整线程详细信息：https://x.com/OpenlifesciAI/status/1852685220912464066    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghx268/d_last_week_in_medical_ai_top_llm_research/</guid>
      <pubDate>Sat, 02 Nov 2024 13:59:40 GMT</pubDate>
    </item>
    <item>
      <title>[研究] [项目] 寻求公开可用的超声数据集用于卵巢癌检测项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghw3m2/research_project_seeking_publicly_available/</link>
      <description><![CDATA[大家好！ 我目前正在进行一个研究项目，旨在通过应用于超声图像的深度学习来改善卵巢癌的早期检测。现在，我正处于数据集收集阶段，在查找可访问的数据集时遇到了一些挑战。 我遇到了 PLCO 和 MMOTU 数据集：  PLCO 需要项目提案才能访问，我正在考虑，但可能需要一些时间。 MMOTU 提供分割数据，但不包括我的工作所需的全套诊断图像。  在查阅文献后，我注意到许多研究人员使用的临床研究数据集是私人的、特定于医院的患者数据或其他不公开的数据集。 如果这里有人参与过类似的项目或面临过这些挑战，我将非常感谢任何指点！具体来说，我正在寻找：  可公开访问的针对卵巢癌或妇科癌症的超声数据集 可通过作者请求或联系相关组织获得的数据集  提前感谢您分享的任何指导或资源！    提交人    /u/Swimming-Car-6055   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghw3m2/research_project_seeking_publicly_available/</guid>
      <pubDate>Sat, 02 Nov 2024 13:11:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] torch.compile 是否已经终结了 JAX 的案例？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghw330/d_has_torchcompile_killed_the_case_for_jax/</link>
      <description><![CDATA[我喜欢 JAX，但我完全承认你为了性能牺牲了开发的便利性。 我在网上看到一些关于 torch.compile 加速的讨论，但我并不是很了解。JAX 的性能案例现在已经过时了吗，或者令人印象深刻的 GPU 性能是否归因于多 GPU 等其他因素。    提交人    /u/internet_ham   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghw330/d_has_torchcompile_killed_the_case_for_jax/</guid>
      <pubDate>Sat, 02 Nov 2024 13:10:48 GMT</pubDate>
    </item>
    <item>
      <title>[P] Zephyr 的第一个可用版本：JAX 上的新声明 FP NN 框架</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghthur/p_first_usable_release_of_zephyr_new_declaration/</link>
      <description><![CDATA[编辑标题：JAX 上的新声明式 FP NN 框架 链接在评论中。 您好！我在 JAX 之上创建了一个新的面向函数式编程的框架。它应该使 JAX 上的高级和低级操作变得容易，并有助于使神经网络简短、简单且易读。 它与其他 JAX 框架的主要区别在于，您不会将任何东西子类化，而是按照数学方式编写神经网络，只是一个纯函数 `F(parameters, X, hyperparameters)`。因此，如果您了解神经网络、python 和 jax，那么您可能只需要知道 2 件事： - 一个 trace 函数来帮助您自动生成 `params`（如果您愿意，您可以自己完成此操作）。 `params = trace(model, random_PRNG_key, sample_input_batch)` - `validate` 函数，可以将其视为一种提供 python 形状和其他信息以供检查的方法，但这只有在您需要创建自己的参数时才有用 我最近发布了它的第一个非 alpha 版本。它现在具有通用层：线性、mlp、conv、注意等等。我计划添加更多内容，也许很快会实现论文中的图层。欢迎提出建议。 我个人会将它用于我自己的项目，我希望它对你们有用，特别是那些想要进行面向 FP 的编码的人。请查看评论中的链接，尝试一下；我很乐意听到您的反馈意见。 最后几件事： - 查看 `zephyr.nets` 了解网络和层 - 并且可以在 `zephyr.trace` 找到跟踪    提交人    /u/Pristine-Staff-5250   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghthur/p_first_usable_release_of_zephyr_new_declaration/</guid>
      <pubDate>Sat, 02 Nov 2024 10:29:39 GMT</pubDate>
    </item>
    <item>
      <title>[P] 努力利用 NN 实现声音方向检测（方位角估计）的准确性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ghqx2p/p_struggling_to_achieve_accuracy_in_sound/</link>
      <description><![CDATA[我正在开展一个项目，使用神经网络估计声源的方向（方位角），数据来自在（约 2m x 2m）平面上移动的 Khepera III 机器人。该设置使用 Raspberry Pi 跟踪机器人的 x、y 坐标和方向角“a”（相对于声源。直接指向目标声音时为 0），每次机器人向前移动然后稍微旋转（约 5-10 度）直到完全旋转时，都会捕获左右音频样本（左右麦克风相距约 18/19 厘米）。我收集了大约 1200 个音频（1 秒）样本，每个样本都在安静的实验室环境中录制。我的声源每 50 毫秒发出一次啪啪声。坐标系是使用 OpenCV 实现的（通过先前的研究），可以在屏幕上渲染 2D 平面内的位置和移动。它将坐标计算与每帧中的实时对象（机器人和扬声器）跟踪和空间表示对齐。 我的方法 我尝试了两种主要方法：  前馈神经网络 (FFNN)：我尝试仅使用原始音频（通过 librosa.load）进行训练，并且仅对每个方向角度“a”使用平坦的 MFCC。我的 FFNN 过度拟合了训练集并在测试集上挣扎。 长短期记忆 (LSTM)：我将数据重构为时间序列（序列长度为 200、50 等），遵循 Dhwani Desai 和 Ninad Mehendale 的论文&quot;机器人耳：用于检测声音方向的音频信号处理&quot;。他们报告的准确率为 82–95%，但我在目标声音 ±10° 范围内仅达到约 40%。  数据预处理： 规范化：我使用以下方法对整个数据集的特征进行标准化： for c in df_train.columns: mean = df_train[c].mean() stdev = df_train[c].std() df_train[c] = (df_train[c] - mean) / stdev df_test[c] = (df_test[c] - mean) / stdev  输出编码：我还尝试用正弦/余弦变换分解角度“a”，希望降低角度敏感度： def get_sin(A_degrees): return math.sin(math.radians(A_degrees)) def get_cos(A_degrees): return math.cos(math.radians(A_degrees))  超参数和代码：我测试了各种超参数，并使用了 nn.MSELoss() 和 torch.optim.Adam()： 我尝试了 FFNN 和 LSTM 的音频数据的对齐（互相关）和未对齐版本。我使用 PyTorch 实现了这一点。 问题  为什么我的模型与论文中的结果相比表现不佳？我想知道问题是否在于左右之间的数据对齐，因为论文没有指定确切的方法（例如，是否使用了互相关或时间同步记录精度（如以纳秒精度同时记录）。）。或者可能是完全不同的东西。我不确定我错过了什么。     提交人    /u/Decent_Eye_659   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ghqx2p/p_struggling_to_achieve_accuracy_in_sound/</guid>
      <pubDate>Sat, 02 Nov 2024 07:05:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 27 Oct 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>