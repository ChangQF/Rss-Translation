<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 06 Jan 2024 09:12:31 GMT</lastBuildDate>
    <item>
      <title>机器学习实习[D],[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zv7nf/machine_learning_internship_d_p/</link>
      <description><![CDATA[我如何才能找到 ML 实习生，因为我已经找了一段时间但找不到任何实习生。如果有人能推荐我，那就太好了恢复有价值的 ML 项目和资源。   由   提交/u/Antique_Jelly_9619   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zv7nf/machine_learning_internship_d_p/</guid>
      <pubDate>Sat, 06 Jan 2024 08:13:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 变形金刚的思想链表现力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zufv8/r_the_expressive_power_of_transformers_with_chain/</link>
      <description><![CDATA[论文。我不隶属于作者。 摘要：  最近的理论工作已经发现了令人惊讶的简单推理问题，例如检查图中的两个节点是否连接或模拟有限状态机，标准变压器在读取输入后立即回答，这证明是无法解决的。然而，在实践中，变形金刚的推理可以通过允许他们使用“思维链”来改进。或“暂存器”，即，在回答之前生成中间标记序列并对其进行调节。受此启发，我们问：这种中间生成是否从根本上扩展了仅解码器变压器的计算能力？我们证明答案是肯定的，但增加的数量很大程度上取决于中间代的数量。例如，我们发现具有对数数量的解码步骤（相对于输入长度）的 Transformer 解码器仅略微突破了标准 Transformer 的限制，而线性数量的解码步骤则增加了明显的新能力（在标准复杂性猜想下）：所有常规语言。我们的结果还表明，线性步骤使变压器解码器保持在上下文相关语言内，而多项式步骤使它们能够准确识别多项式时间可解决问题的类别——这是根据标准复杂性类别对变压器类型进行的第一个准确表征。总之，我们的结果提供了一个细致入微的框架，用于理解变压器的思想链或暂存器的长度如何影响其推理能力。    由   提交 /u/Wiskkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zufv8/r_the_expressive_power_of_transformers_with_chain/</guid>
      <pubDate>Sat, 06 Jan 2024 07:23:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习有什么有趣的数学理论吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zo7or/d_is_there_any_interesting_mathematical_theory_of/</link>
      <description><![CDATA[大家好！我的问题在标题中，这是一些背景信息。我的背景可以描述为“主修理论计算机科学（非常强调‘理论’这个词，想想计算复杂性理论），辅修数学”。 几年前，我参加了入门课程机器学习课程......非常沮丧和失望。  没有解释任何东西应该如何或为什么工作，相反有很多不令人信服的猜测，比如“如果你添加一个卷积层，然后它将学习简单的几何形状，因此后面的层将有更多的结构可以使用”或者“我们可以在 RNN 中使用额外的输入，并以某种方式组合三个输入，这样新的输入将起到‘长期记忆’的作用”。我没想到数学逻辑或编程语言理论的严谨程度，但其他科学，例如经济学，至少可以用一些简化的模型来解释他们正在研究的现象。我们在机器学习中没有类似的东西吗？ 在课程中，我们直接跳到一些相当复杂的问题，例如区分猫的图片和狗的图片。我怀疑是否有人能够对这两类图片给出一个很好的定义。虽然这让神经网络能够解决问题变得更加令人印象深刻，但我看不出我们可以从中学到什么关于神经网络如何做到这一点的信息。训练神经网络区分蓝色和绿色、正方形和圆形等，然后尝试使用结果来分析神经网络如何学习不是更好吗？  后来我开了一个很少有机器学习教科书。  我真的很喜欢有关 PAC 学习的部分，总体来说统计学习也很适合我。 有关神经网络和尤其是深度学习，几乎与我在课程中听到的关于仪式舞蹈如何导致降雨的炼金术级别的推测相同。  所以我试图在 arXiv 上找到一些现代结果。   大多数关于机器学习的论文都将更难以推理的模型应用于更难以理解的问题，这让我感到非常失望。 有一些关于神经网络是通用逼近器的结果，即使不多也很好。 我还遇到过（在写硕士论文时）一两篇关于感知器和电路计算复杂性的论文阈值函数。令人遗憾的是，似乎对此主题的当代研究很少甚至没有。  ​ 这就是我的“咆哮”的结论。 ，我希望这能够澄清“机器学习数学”的类型。我正在寻找。请注意，我确实理解使用现代模型需要大量的知识和专业知识，我并不是想贬低你所做的工作，我只是对找到这些模型如何工作的理论解释有多么困难感到沮丧，考虑到机器学习的普及。 我真的很感激任何想法或建议！ 此外，英语不是我的母语，所以我很抱歉任何拼写错误、不正确的语法或尴尬的句子。 ​ UPD：看到这篇文章刚刚。我真的很想看到更多类似的作品。   由   提交/u/a_broken_coffee_cup   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zo7or/d_is_there_any_interesting_mathematical_theory_of/</guid>
      <pubDate>Sat, 06 Jan 2024 01:50:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] BioAI 在巴黎的研究角色？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zkudh/d_bioai_research_roles_in_paris/</link>
      <description><![CDATA[嗨， 我今年将捍卫我的计算基因组学/机器学习博士学位。我将在就业市场上寻找博士后或行业职位，我正在努力寻找合适的人选。我现在想留在巴黎地区。 我对蛋白质、分子动力学和组学数据特别感兴趣。 关于行业，我确定了以下两个拥有高质量研究成果并在机器学习会议上发表过文章的公司。您有在那里工作或申请的经验吗？您还知道其他类似的机会吗？  目前的 A 计划是 InstaDeep，最近被 BioNTech 收购。巴黎办事处似乎进行了认真的研究，生物学方面必将得到更大的发展。我特别喜欢人们对从头蛋白质设计的兴趣，到目前为止我在其他地方还没有发现这种兴趣。 还有 Owkin。他们似乎主要致力于组学或联邦学习，所以我会错过蛋白质设计/折叠/对接方面的内容。 当然 DeepMind 会很棒，但我的印象是他们没有直接从博士生中招募。  感谢您的关注并想听听您的想法！   由   提交 /u/ZestycloseBus4359   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zkudh/d_bioai_research_roles_in_paris/</guid>
      <pubDate>Fri, 05 Jan 2024 23:22:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 一个用于部署本地模型的开源项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zkm5m/p_an_opensource_project_for_deploying_local_models/</link>
      <description><![CDATA[     &lt; td&gt; 引入一个新的LLM WebUI项目，支持各种本地模型加载，并为尖端在线多模态模型GPT-4-Vision和提供流式输出双子座-Pro-Vision。它完全免费和开源，是探索不同模型的宝贵研究工具。该项目正在积极开发并不断更新： https://github.com/smalltong02/keras-llm-机器人 ​ WebUI ​ 配置 ​ 工具与代理   由   提交 /u/Entire-Fly-6957   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zkm5m/p_an_opensource_project_for_deploying_local_models/</guid>
      <pubDate>Fri, 05 Jan 2024 23:12:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 时间序列数据表示学习的最新技术是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zjkyn/d_what_is_state_of_art_for_representation/</link>
      <description><![CDATA[有一堆未标记的一维原始时间序列数据。标记数据量有限。 我正在寻找最好的无监督/自监督编码技术，以学习有用的潜在特征表示（例如，在下游监督预测任务中有用）。  无论是使用 Transformer 还是 CNN (ConvNext V2) 架构，屏蔽自动编码器领域似乎都有很多工作要做。  这些技术是目前最好的技术，还是我还缺少其他在各种数据集上表现出强大性能的技术？ ​ 谢谢！   由   提交/u/ZeApelido  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zjkyn/d_what_is_state_of_art_for_representation/</guid>
      <pubDate>Fri, 05 Jan 2024 22:29:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] Hieros：结构化状态空间序列世界模型的层次想象</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zizet/r_hieros_hierarchical_imagination_on_structured/</link>
      <description><![CDATA[OpenReview: https: //openreview.net/forum?id=5j6wtOO6Fk arXiv：https ://arxiv.org/abs/2310.05167 代码：https： //github.com/Snagnar/Hieros 摘要：  现代深度强化学习面临的最大挑战之一（ DRL）算法是样本效率。许多方法学习世界模型，以便完全在想象中训练智能体，从而消除训练期间直接环境交互的需要。然而，这些方法常常缺乏想象准确性、探索能力或运行效率。我们提出了Hieros，这是一种分层策略，可以学习时间抽象的世界表示并想象潜在空间中多个时间尺度的轨迹。 Hieros 使用基于 S5 层的世界模型，该模型在训练期间并行预测下一个世界状态，并在环境交互期间迭代预测。由于 S5 层的特殊属性，我们的方法可以并行训练并在想象过程中迭代预测下一个世界状态。这使得训练比基于 RNN 的世界模型更有效，并且比基于 Transformer 的世界模型更有效的想象力。 我们证明，我们的方法在 Atari 上的平均和中值归一化人类分数方面优于现有技术。 100k 基准，并且我们提出的世界模型能够非常准确地预测复杂的动态。我们还表明，与现有方法相比，Hieros 显示出卓越的探索能力。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zizet/r_hieros_hierarchical_imagination_on_structured/</guid>
      <pubDate>Fri, 05 Jan 2024 22:04:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士增强法学硕士：通过组合扩展能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zii8u/r_llm_augmented_llms_expanding_capabilities/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2401.02412 OpenReview：https:// /openreview.net/forum?id=jjA4O1vJRz 摘要：  经过训练的数十亿参数的基础模型对大型数据集的研究已经在各个领域展示了不平凡的技能。然而，由于它们的整体结构，增强它们或传授新技能具有挑战性且成本高昂。另一方面，由于它们的适应能力，这些模型的几个新实例正在针对新领域和任务进行训练。在这项工作中，我们研究了现有基础模型与更具体模型的高效实用组合问题，以实现更新的功能。为此，我们提出了CALM——组合增强语言模型——它引入了模型之间的交叉注意力来组合它们的表示并启用新的功能。 CALM 的显着特征是：（i）通过“重用”现有的 LLM 以及一些额外的参数和数据，在新任务上扩展 LLM，（ii）现有模型权重保持完整，从而保留现有功能，以及（ iii) 适用于不同的领域和环境。我们证明，使用在低资源语言上训练的较小模型来增强 PaLM2-S 可以在翻译成英语和低资源语言的算术推理等任务上绝对提高高达 13%。同样，当 PaLM2-S 通过特定于代码的模型进行增强时，我们发现代码生成和解释任务比基本模型相对提高了 40%，与完全微调的对应模型相当。 &lt; /blockquote&gt;   由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zii8u/r_llm_augmented_llms_expanding_capabilities/</guid>
      <pubDate>Fri, 05 Jan 2024 21:44:21 GMT</pubDate>
    </item>
    <item>
      <title>基于变压器的法学硕士不是一般学习者：通用电路视角 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zie7z/transformerbased_llms_are_not_general_learners_a/</link>
      <description><![CDATA[https://openreview.net/forum?id =tGM7rOmJzV  （法学硕士）的巨大成功引发了人工智能界研究重点的显着转变。这些令人印象深刻的实证成就激发了人们对法学硕士是“通用人工智能（AGI）的火花”的期望。然而，一些评估结果也呈现了法学硕士失败的令人困惑的例子，包括一些看似微不足道的任务。例如，GPT-4 能够解决一些 IMO 中对研究生来说可能具有挑战性的数学问题，而在某些情况下它可能会在小学水平的算术问题上出错。 ...  我们的理论结果表明 T-LLM 无法成为通用学习者。然而，T-LLM 在各种任务中取得了巨大的经验成功。我们对这种不一致现象提供了一个可能的解释：虽然 T-LLM 不是一般学习者，但他们可以通过记忆大量实例来部分解决复杂的任务，从而导致人们产生一种错觉，认为 T-LLM 具有真正解决这些任务问题的能力。     由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zie7z/transformerbased_llms_are_not_general_learners_a/</guid>
      <pubDate>Fri, 05 Jan 2024 21:39:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] GPT-4V(ision) 是一款多面手 Web 代理，如果接地 - 俄亥俄州立大学 2024 年 - 可以成功完成实时网站上 50% 的任务！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zgfmx/r_gpt4vision_is_a_generalist_web_agent_if/</link>
      <description><![CDATA[&lt;表&gt;   论文：https://arxiv.org/abs/2401.01614  博客：https ://osu-nlp-group.github.io/SeeAct/  代码： https://github.com/OSU-NLP-Group/SeeAct  摘要：  大型多模态模型（LMM）的最新发展），特别是 GPT-4V(ision) 和 Gemini，一直在快速扩展多模态模型的能力边界，超越图像字幕和视觉问答等传统任务。在这项工作中，我们探索了像 GPT-4V 这样的 LMM 作为通用网络代理的潜力，它可以遵循自然语言指令来完成任何给定网站上的任务。我们提出了 SEEACT，这是一种通用网络代理，它利用 LMM 的力量来实现集成的视觉理解和在网络上的操作。我们对最近的 MIND2WEB 基准进行评估。除了对缓存网站进行标准离线评估之外，我们还通过开发允许在实时网站上运行 Web 代理的工具来启用新的在线评估设置。 我们表明，GPT-4V 为网络代理提供了巨大的潜力 - 如果我们手动将其文本计划转化为网站上的操作，它可以成功完成实时网站上 50% 的任务。这大大优于文本-仅限专门针对网络代理进行微调的 LLM，例如 GPT-4 或更小的模型（FLAN-T5 和 BLIP-2）。然而，接地仍然是一个重大挑战。现有的 LMM 基础策略（例如标记集提示）对于网络代理来说并不有效，而我们在本文中开发的最佳基础策略同时利用了 HTML 文本和视觉效果。然而，仍然存在与预言机基础存在很大差距，留有足够的进一步改进的空间。   https://preview.redd.it/1w22ga2ejoac1.jpg?width=706&amp;format=pjpg&amp;auto=webp&amp;s=204d4852c614efaf8c 39c990d25a7acae805290e  https://preview.redd .it/vaabea2ejoac1.jpg?width=1344&amp;format=pjpg&amp;auto=webp&amp;s=17f5a5ca7e1add213ca4d75ed53a74e230369655 https://preview.redd.it/2720ob2ejoac1.jpg?width=1340&amp;format=pjpg&amp;auto=webp&amp;s=4cec63cdd3e14 48e03f82309ac219684c62b8ffb https://preview .redd.it/9wn5sa2ejoac1.jpg?width=1242&amp;format=pjpg&amp;auto=webp&amp;s=dcc8919105686007d670f9b140aaeb3e4683d56e https://preview.redd.it/ttgaad2ejoac1.jpg?width=801&amp;format=pjpg&amp;auto=webp&amp;s=568 4aa7969a6564eab8cb4a5ea36fa21f4c63e9e    由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zgfmx/r_gpt4vision_is_a_generalist_web_agent_if/</guid>
      <pubDate>Fri, 05 Jan 2024 20:18:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何及时了解 ML 领域的最新论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ze0cx/d_how_to_stay_updated_with_latest_paper_in_ml/</link>
      <description><![CDATA[深度学习论文如此之多，很难从噪音中筛选出优秀的论文以保持领先地位。 有什么建议吗？也许有人有要关注的 Twitter 帐户列表？   由   提交 /u/Remet0n   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ze0cx/d_how_to_stay_updated_with_latest_paper_in_ml/</guid>
      <pubDate>Fri, 05 Jan 2024 18:37:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] MC-JEPA 神经模型：释放运动识别和生成式人工智能在视频和图像上的力量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18zbxt7/d_mcjepa_neural_model_unlock_the_power_of_motion/</link>
      <description><![CDATA[我们进行了讨论论文“MC-JEPA：用于运动和内容特征自监督学习的联合嵌入预测架构” https://arxiv.org/pdf/2307.12698.pdf   由   提交 /u/sasaram   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18zbxt7/d_mcjepa_neural_model_unlock_the_power_of_motion/</guid>
      <pubDate>Fri, 05 Jan 2024 17:11:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 深度强化学习泛化分析调查</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18z90nq/r_a_survey_analyzing_generalization_in_deep/</link>
      <description><![CDATA[https://arxiv.org/pdf/2401.02349 .pdf   由   提交 /u/ml_dnn   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18z90nq/r_a_survey_analyzing_generalization_in_deep/</guid>
      <pubDate>Fri, 05 Jan 2024 15:07:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] ArXiv 替代方案（或者是否有可能实现更多“暂停”透明度）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18z3jdr/d_arxiv_alternatives_or_is_there_possible_for/</link>
      <description><![CDATA[我当前的文章已“暂停”差不多一周了（尝试联系模组，得到了一般性的答复）。我在 arXiv 上发表了 5 篇文章，没有任何问题（同一类别中有 3 篇文章）。 还有一些关于文章被搁置一个月以上的可怕故事 (https://academia.stackexchange.com/questions/189542/arxiv-preprint-on-hold，https://twitter.com/YuanqiD/status/1678949802367676417，https:// twitter.com/moyix/status/1604218507708846082，https://twitter.com/PierLucaLanzi/status/1629569377690439680，https://twitter.com/GriffinAdams92/status/1605310825958637568）。  我知道模组是免费做他们的工作的，如果这个过程在某种程度上是透明的，我可以等待合理的时间。但现在，有些文章一天之内就被接受，有些则需要等待数周/数月。是否有可能让 arXiv“暂停”？状态更透明？例如。通过显示当前队列大小或“保留”的某种原因（错误的类别，像 Covid 这样的敏感话题，...）？  此外，对于 ML 工作，是否有一些 arXiv 的不错替代品？那些具有良好声誉（没有 vixra）、可预测的等待时间并且至少还被 Google Scholar 索引的？   由   提交 /u/osamc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18z3jdr/d_arxiv_alternatives_or_is_there_possible_for/</guid>
      <pubDate>Fri, 05 Jan 2024 10:09:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>