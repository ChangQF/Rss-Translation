<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 02 Dec 2023 21:11:12 GMT</lastBuildDate>
    <item>
      <title>迷茫不知道该做什么[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189d7cn/confused_about_what_to_do_d/</link>
      <description><![CDATA[为了提供背景信息，我目前正处于工程研究的最后一年，需要进行 4-6 个月的实习作为我的毕业项目。我的兴趣在于人工智能的应用，特别是在机器人、计算机视觉和其他工程领域。幸运的是，我已经在一所著名的学院找到了职位。然而，拟议的实习主题集中在入侵检测系统中的人工智能，这与我的兴趣不太相符。 经过研究，我发现该领域已经相当成熟，实习将涉及广泛的研究。现在，我发现自己正处于十字路口，正在考虑是否接受这份工作并利用学院的网络和资源（以及优良的生活条件），还是探索其他机会。不幸的是，在另一家著名机构获得职位似乎不太可能，我的替代方案可能涉及当地公司（可能已经过时）或国外大学。值得一提的是，我来自北非。 任何有关此事的建议或见解将不胜感激。   由   提交/u/Dry_Curve_8260   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189d7cn/confused_about_what_to_do_d/</guid>
      <pubDate>Sat, 02 Dec 2023 21:08:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我想使用神经网络进行函数拟合（根据函数的样本找到函数的参数），但是函数采样的坐标并不总是相同的。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/189bzpx/p_i_want_to_use_a_neural_network_for_function/</link>
      <description><![CDATA[嗨，我希望有人能告诉我这个问题叫什么，以便我可以搜索现有文献。我有一个函数 f = f(theta,V)，它是一类系统（晶体管）的物理模型。假设 f 是标量，theta 是约 100 个元素向量，V 是约 3 维向量 (x,y,z)。我想让 f 适合晶体管的测量：找到参数 theta，使得 f 接近某个 V 域中的测量行为（例如 [0,xmax] x [0,ymax] x [0, zmax]).* 标准解决方案是使用像 Newton-Raphson 这样的优化器来找到最小化 f 和系统测量值之间的 RMS 误差的 theta。这有一些问题，例如由于 f 是非线性的，因此陷入局部最小值。 我想训练一个神经网络以测量值作为输入并产生 theta 作为输出。如果测量总是在相同的 V 值下进行，这将相对简单：我可以通过随机采样 theta 来生成训练数据，给出 [ f(theta,V_1), ..., f(theta, V_R) ]作为一个输入点，theta 作为预期输出。 但是，我想要拟合该函数的域并不总是相同：今天我可能想要将 f 拟合到晶体管的测量值，其中 V1 的范围为0 到 5，明天我将安装一个不同的晶体管，其中 V1 的范围从 0 到 100。 原则上，我可以使输入 [ V_1, f(theta,V_1), ..., V_N ，f(theta，V_N)]。但这感觉像是神经网络必须学习的非常复杂的映射（如果我错了，请纠正我）。它必须找到点之间的关系，并对它们重新排序，以从中提取有意义的内容。 另一种可能性是始终测量相同的 V，只是线性缩放到感兴趣的域，并告诉神经网络这个缩放比例是什么。输入为 [ xmax, ymax, zmax, f(theta,scaledV_1), ..., f(theta,scaledV_R) ]。在这种情况下，神经网络不必在运行时重新排序测量：它们总是彼此具有相同的关系，只是比例不同。 我想到的最后一种可能性是只需让它适用于固定域，然后在需要新域时进行微调。如果每次新的执行需要一个小时，那也没关系，这仍然是对现有解决方案的改进。 很抱歉这篇文章很长，我很想知道我可以使用哪些搜索词或您可以使用的任何相关文献可以推荐。 谢谢！ *如果这一切听起来太抽象，想象一下我有函数 a*x2 +b*x+ 的示例c，我希望网络根据样本输出 a、b、c，但我并不总是以相同的 x 值对函数进行采样。   由   提交 /u/ignamv   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/189bzpx/p_i_want_to_use_a_neural_network_for_function/</guid>
      <pubDate>Sat, 02 Dec 2023 20:11:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 请检查我对使用 PyTorch 的 ngrams 模型的词嵌入的理解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18990rv/d_please_check_my_understanding_of_word/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18990rv/d_please_check_my_understanding_of_word/</guid>
      <pubDate>Sat, 02 Dec 2023 17:50:20 GMT</pubDate>
    </item>
    <item>
      <title>[R] 持续学习：应用与前进之路（2023 年 11 月 30 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1897ywt/r_continual_learning_applications_and_the_road/</link>
      <description><![CDATA[ 由   提交/u/moschles  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1897ywt/r_continual_learning_applications_and_the_road/</guid>
      <pubDate>Sat, 02 Dec 2023 17:01:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] USearch HNSW 的大规模实施速度比 FAISS 快 10 倍</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1896uhy/p_usearch_hnsw_implementation_is_10x_faster_than/</link>
      <description><![CDATA[ 由   提交/u/ashvar  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1896uhy/p_usearch_hnsw_implementation_is_10x_faster_than/</guid>
      <pubDate>Sat, 02 Dec 2023 16:06:57 GMT</pubDate>
    </item>
    <item>
      <title>[P] 让我们调试您的神经网络：NN 的基于梯度的符号执行</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1896rze/p_lets_debug_your_neural_network_gradientbased/</link>
      <description><![CDATA[我开发了 Gymbo，一个概念证明用于从头开始实现的基于梯度的符号执行引擎。  符号是一种用于分析程序并识别触发每个程序部分执行的输入的方法。它在调试神经网络的行为时效果很好。例如，Gymbo 可以让您轻松找到对抗性示例。有趣的是，基于逻辑的方法可以有效地分析神经网络。 Gymbo 还提供与 sklearn 和 PyTorch 兼容的易于使用的 Python API。 我很期待收到您的反馈！   由   提交/u/Living_Impression_37   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1896rze/p_lets_debug_your_neural_network_gradientbased/</guid>
      <pubDate>Sat, 02 Dec 2023 16:03:32 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么交叉熵随着准确度的增加而增加？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1895m5k/d_why_is_crossentropy_increasing_with_accuracy/</link>
      <description><![CDATA[      我正在实现 softmax 回归，并且我正在努力理解交叉熵值增加的问题背后的本质[1]，以及准确性的增加（在“iris”数据集上）： https://preview.redd.it/eo3654zwbw3c1.png?width=688&amp;format= png&amp;auto=webp&amp;s=52916d56029e6e8aa1e9594bbcb02c7075009206 这对我来说非常令人困惑，因为没有类不平衡： [1]   由   提交 /u/joshjson   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1895m5k/d_why_is_crossentropy_increasing_with_accuracy/</guid>
      <pubDate>Sat, 02 Dec 2023 15:05:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] Transformers 如何重写机器学习的古老传统规则</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1895ipi/d_how_transformers_rewrote_the_rules_of_an_age/</link>
      <description><![CDATA[      大家好！分享我的 ML YT 频道的最新视频，讨论 Transformer、它们的工作原理，以及与其他神经网络（如 CNN、RNN 等）相比，它与归纳偏差的有趣关系。分享一个链接给有兴趣的人看看！谢谢。   由   提交/u/AvvYaa  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1895ipi/d_how_transformers_rewrote_the_rules_of_an_age/</guid>
      <pubDate>Sat, 02 Dec 2023 15:01:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 惨痛的教训和思想之树 - 像 ToT 这样的技术是使用搜索的例子，还是它们通过编码类人学习而忽略了惨痛的教训？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1893ne2/d_bitter_lesson_and_tree_of_thoughts_are/</link>
      <description><![CDATA[惨痛的教训表明，学习和搜索是获胜策略，因为它们随着计算能力的扩展而扩展，并且通常会优于依赖于编码人类知识的技术。&lt; /p&gt; 鉴于此，您对 ToT 和类似技术有何看法？它们是通过搜索扩展模型能力的好例子，还是试图强制我们认为是类人行为的例子？ ​ 仅供参考，我在研究中看到了两种主要的基于树的方法。一种是基于MCTS的解码。这似乎更符合传统的搜索概念，因为您正在搜索可能文本的结果空间，然后选择最好的文本。 meta 使用 PPO 值函数作为 MCTS 节点评估器的论文 使用MCTS来提高编写成功程序的能力 ​ 但是，还使用了更抽象的CoT/ToT风格的树，这依赖模型为给定序列生成后续序列树。 思想树：故意问题使用大型语言模型求解 这里的一个核心区别是树并不像 MCTS 解码树搜索那样表示对可能输出的搜索。这是对可能的推理链的搜索，这些推理链最终是某种评估方法（通常是模型本身）的输入，以确定最佳输出。因此，您不仅搜索结果空间，还搜索“证据空间”，这两者都将传递给评估器以选择适当的结果。  编辑：不相关，但原则上您可以结合这两种搜索技术，这会很酷，但可能非常昂贵。例如，对 ToT 中的每个节点使用 MCTS 解码。我还没有看到有人这样做，但如果有人有一篇论文的链接那就太酷了。   由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1893ne2/d_bitter_lesson_and_tree_of_thoughts_are/</guid>
      <pubDate>Sat, 02 Dec 2023 13:23:42 GMT</pubDate>
    </item>
    <item>
      <title>[P] 让为您的 ML 模型创建 FastAPI 后端变得非常容易！想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18933bh/p_made_it_really_easy_to_create_a_fastapi_backend/</link>
      <description><![CDATA[嘿伙计们！我想分享我最近制作的这个工具，https://visual-backend.com，它可以让你为你的 ML 构建 FastAPI 后端模型真的很快。它本质上是一个 GUI，可让您生成代码和代码。端点处理程序的脚手架、身份验证，甚至只需一键即可部署到 GCP。因此，要为您的 ML 模型提供服务，您所需要做的就是加载它并在每个端点处理程序处调用推理函数。当然，对于批处理或作业队列之类的东西，没有这样的功能，但只是想知道在基础级别上，这样的工具是否对你们有用！ I最初是为全栈开发人员构建的，但在与几位 ML 工程师/数据科学家交谈后，我意识到这可能对那些希望快速将 ML 模型投入生产而不用太关心的人有所帮助。基础设施/软件工程，所以我很想听听您是否觉得这有帮助以及您可能有的其他想法。期待它:)   由   提交 /u/johnyeocx   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18933bh/p_made_it_really_easy_to_create_a_fastapi_backend/</guid>
      <pubDate>Sat, 02 Dec 2023 12:51:36 GMT</pubDate>
    </item>
    <item>
      <title>[D]如何追踪最近​​的热门论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1890zpi/dhow_do_i_track_recent_trending_papers/</link>
      <description><![CDATA[由于papers.labml.ai离线，如何处理你们跟踪最近的热门论文或热门话题吗，尤其是 X 方面的。有什么推荐吗？   由   提交 /u/Historical-Tree9132    reddit.com/r/MachineLearning/comments/1890zpi/dhow_do_i_track_recent_trending_papers/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1890zpi/dhow_do_i_track_recent_trending_papers/</guid>
      <pubDate>Sat, 02 Dec 2023 10:32:08 GMT</pubDate>
    </item>
    <item>
      <title>[D]深入研究 Google Brain 团队的 Vision Transformer (ViT) 论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/188pe7u/deep_dive_into_the_vision_transformer_vit_paper/</link>
      <description><![CDATA[我们每周五都有一个名为 Arxiv Dives 的阅读俱乐部，在那里我们回顾当今机器学习中使用的许多最先进技术的基础知识。上周我们深入探讨了“视觉变形金刚” 2021 年的论文，其中 Google Brain 团队针对 ResNets 进行了大规模 Transformer 训练基准测试。 尽管截至本周这还不是开创性的研究，但我认为随着人工智能的发展步伐，深入研究过去的工作非常重要以及其他人的尝试！很高兴退一步回顾基础知识并跟上最新和最好的内容。 如果有人觉得有帮助，请在此处发布注释并回顾一​​下： https://blog.oxen.ai/arxiv-dives-vision-transformers-vit/&lt; /p&gt; 也希望有人能加入我们周五的直播！我们有一个由 300 多名工程师和研究人员组成的非常稳定且有趣的团队。   由   提交 /u/FallMindless3563   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/188pe7u/deep_dive_into_the_vision_transformer_vit_paper/</guid>
      <pubDate>Fri, 01 Dec 2023 23:16:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] Llama 微调速度提高 80%，内存减少 50%，精度损失 0%</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/188g31r/p_80_faster_50_less_memory_0_loss_in_accuracy/</link>
      <description><![CDATA[       嘿r/MachineLearning！ 我手动导出了反向传播步骤，做了一些链式矩阵乘法优化，用 OpenAI 的 Triton 语言编写所有内核，并进行更多数学和编码技巧，以使 QLoRA 在 Unsloth 上对 Llama 的微调速度提高 5 倍：https:// github.com/unslothai/unsloth！一些亮点：  速度提高 5 倍（5 小时到 1 小时） 使用内存减少 50% 精度损失为 0% 所有本地均在 NVIDIA GPU（Tesla T4、RTX 20/30/40、Ampere、 Hopper）免费！ QLoRA / LoRA 现在训练速度提高了 80%。  在 2 个 Tesla T4 上的 Slim Orca 518K 示例上通过 DDP 的 GPU，Unsloth 在 260 小时内在所有层上训练 4 位 QLoRA VS Huggingface 的原始实现需要 1301 小时。 Slim Orca 1301 小时到 260 小时 您可能（很可能不）记得来自 Hyperlearn 的我 (https://github.com/danielhanchen/hyperlearn）是我几年前推出的，旨在通过数学和编码技巧使 ML 算法速度提高 2000 倍。 我通过 https://unsloth.ai/introducing 写了一篇关于所有手动手动导出反向传播的博客文章。&lt; /p&gt; 我为 Alpaca 编写了 T4 的 Google Colab：https://colab.research。 google.com/drive/1oW55fBmwzCOrBVX66RcpptL3a99qWBxb?usp=sharing，在单个 GPU 上将 Alpaca 的速度提高 2 倍。 在 Kaggle 上通过 DDP 上的 2 个 Tesla T4：https://www.kaggle.com/danielhanchen/unsloth-laion-chip2-kaggle，微调 LAION 的 OIG 速度快 5 倍，Slim Orca 速度快 5 倍更快。 您可以通过以下方式在本地安装 Unsloth： pip install &quot;unsloth[cu118] @ git+https://github.com/unslothai/unsloth。 git” pip install “unsloth[cu121] @ git+https://github.com/unslothai/unsloth.git”  目前我们仅支持 Pytorch 2.1 和 Linux 发行版 - 更多安装说明请参见 https://github.com/unslothai/unsloth/blob/main/README.md 我希望：  支持除Llama 风格模型（Mistral 等） 添加 sqrt 梯度检查点以再减少 25% 的内存使用量。 还有其他技巧！  谢谢一堆！！   由   提交 /u/danielhanchen   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/188g31r/p_80_faster_50_less_memory_0_loss_in_accuracy/</guid>
      <pubDate>Fri, 01 Dec 2023 16:31:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 一些作者是否认真地添加了比需要的更多的数学知识，以使论文“看起来”更具开创性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/188d7qc/r_do_some_authors_conscientiously_add_up_more/</link>
      <description><![CDATA[我最近注意到一种趋势，即作者在某些情况下添加了超出所需的形式主义（例如，图表/图像就可以很好地完成工作）。  这是否是为了使论文看起来更好而添加了超出所需的数学内容，或者可能只是受到出版商的限制（无论论文必须坚持什么格式才能发表）？ &gt;   由   提交 /u/Inquation   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/188d7qc/r_do_some_authors_conscientiously_add_up_more/</guid>
      <pubDate>Fri, 01 Dec 2023 14:29:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/17z08pk/d_simple_questions_thread/</guid>
      <pubDate>Sun, 19 Nov 2023 16:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>