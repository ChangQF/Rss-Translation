<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Thu, 11 Apr 2024 18:16:14 GMT</lastBuildDate>
    <item>
      <title>[D] AGI 到底是什么？引入独特而严格的标准</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1lxq1/d_what_exactly_is_agi_introducing_a_unique_and/</link>
      <description><![CDATA[你好！ 我很好奇这里的人对此有何看法： AGI到底是什么？引入独特而严格的标准 致以诚挚的问候！   由   提交 /u/gvatte   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1lxq1/d_what_exactly_is_agi_introducing_a_unique_and/</guid>
      <pubDate>Thu, 11 Apr 2024 18:12:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无限上下文变形金刚</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1l16l/r_infinite_context_transformers/</link>
      <description><![CDATA[我看了一下，没有在本文中看到任何看起来很有希望的讨论主题。  https://arxiv.org/abs/2404.07143  你的想法？这可能是 Gemini 1.5 报告的 10m 令牌上下文长度背后的技术之一吗？    由   提交 /u/Dyoakom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1l16l/r_infinite_context_transformers/</guid>
      <pubDate>Thu, 11 Apr 2024 17:35:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 工业机器学习数据集和方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1ktup/d_machine_learning_datasets_and_methods_in/</link>
      <description><![CDATA[我目前是一名对机器学习感兴趣的硕士生。我一直在努力寻找与该领域相关的实习机会。谁能深入了解行业中使用的数据集和机器学习方法？我很想获得一些现实生活中的数据集，我可以自己使用这些数据集并获得更多经验。  ​ 仅供参考，我只有作业和课堂项目经验。    由   提交/u/Beautiful_Carrot7  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1ktup/d_machine_learning_datasets_and_methods_in/</guid>
      <pubDate>Thu, 11 Apr 2024 17:26:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 语义分割模型是否没有适当的可解释性方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1hi3z/d_are_there_no_proper_explainability_approaches/</link>
      <description><![CDATA[嘿，我目前正在更多地研究人工智能的可解释性，并希望对我的分割模型的结果有更多的了解（U-Net和 DeepLabV3）。 寻找解释我的输出（或网络的中间层）的可能性，我无法真正找到可靠的结果。  我可以看到，在 SHAP 示例中，有一个示例展示了如何使用 PyTorch 对 ImageNet 上的 VGG16 中间层进行一些解释（此处）。然而，这仍然显示了一个分类任务，并且尝试将其应用于我自己的问题并没有按预期进行。我也尝试过使用他们的 DeepExplainer，但这并没有真正给我带来任何结果。 语义分割问题没有可解释的方法吗？然而，我可以找到一两篇研究论文，对它们的最终结果进行分类，然后应用，例如： Grad-CAM 这只是分段的一种可解释性，不是吗？   由   提交/u/_awake  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1hi3z/d_are_there_no_proper_explainability_approaches/</guid>
      <pubDate>Thu, 11 Apr 2024 15:10:17 GMT</pubDate>
    </item>
    <item>
      <title>[P]使用GAN生成结构化文本</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1gqqh/p_use_gan_for_generating_structured_text/</link>
      <description><![CDATA[我正处于个人项目的第一阶段，我想从数据集中生成新数据，以便稍后在项目中使用。数据是一个结构化测试（它就像一个日志文件），我想创建一个基于数据集生成新文件的 GAN。我很感谢使用 GAN 来做到这一点，但我不确定这是否是正确的路径，因为我发现它们主要用于图像。您对文本生成 GAN 有什么建议或实现吗？   由   提交/u/redska_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1gqqh/p_use_gan_for_generating_structured_text/</guid>
      <pubDate>Thu, 11 Apr 2024 14:39:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在论文《More Agents Is All You Need》中，为什么他们使用 BLEU 分数来计算集成投票的相似度而不是余弦相似度之类的东西？有后续研究比较方法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1e0x4/d_in_the_paper_more_agents_is_all_you_need_why/</link>
      <description><![CDATA[论文：https://arxiv.org/pdf /2402.05120.pdf 在论文中，他们有法学硕士集体回答问题。对于离散答案，例如多项选择题，他们只选择最常见的答案。对于“连续”来说，对于像代码这样的答案，他们使用 BLEU 分数来查找与其他答案最相似的答案。 有人知道为什么选择这个答案而不是余弦相似度之类的答案吗？看起来他们没有解释这个选择，但他们的结果很好，所以我猜它有效！   由   提交 /u/30299578815310   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1e0x4/d_in_the_paper_more_agents_is_all_you_need_why/</guid>
      <pubDate>Thu, 11 Apr 2024 12:39:47 GMT</pubDate>
    </item>
    <item>
      <title>LLM 擅长 NL 到代码和 NL 到 SQL 任务吗？ [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c1bfxv/are_llms_good_at_nltocode_nltosql_tasks_discussion/</link>
      <description><![CDATA[大家好， 在过去的几天里，我一直在研究大型语言模型在特定于 &gt;NL 到代码，主要是 NL 到 SQL 任务。我想从我们的从业者社区中听到更多有关此问题的信息。 这种兴趣主要源于使用法学硕士进行编码的好奇心和效率。我想知道您对他们的表演有什么感受吗？ - 在准确性、效率等方面？您尝试过哪些模型来完成此任务？您认为哪种模型最有效？   由   提交 /u/Traditional-Lynx-684   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c1bfxv/are_llms_good_at_nltocode_nltosql_tasks_discussion/</guid>
      <pubDate>Thu, 11 Apr 2024 10:12:39 GMT</pubDate>
    </item>
    <item>
      <title>[D]深度学习模型的Hessian及其特征向量</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c15ro1/d_hessian_of_deep_learning_model_and_its/</link>
      <description><![CDATA[我试图了解有关 Hessian 矩阵、其特征向量以及如何优化它们的更多信息。谁能给我提供一些关于这方面的见解（或者推荐对这方面有深刻见解的论文）？比如 Hessian 矩阵的特征向量代表什么，它们在良好的广义模型中应该如何表现。   由   提交 /u/Competitive_Newt_100   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c15ro1/d_hessian_of_deep_learning_model_and_its/</guid>
      <pubDate>Thu, 11 Apr 2024 04:08:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 曼巴进军遥感领域！ RS-Mamba：SSM在大型遥感图像语义分割和变化检测中的首次应用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c158zy/r_mamba_enters_remote_sensing_rsmamba_the_first/</link>
      <description><![CDATA[       内容摘要 Mamba以其线性复杂度和与Transformer相当的性能在大型语言模型领域大放异彩，成为替代Transformer的有力竞争者。变压器。最近的作品 Vim 和 VMamba 将 Mamba 引入了视觉成像领域，在视觉的各个领域引发了众多突破，并产生了大量使用 Mamba 执行视觉任务的研究。  本文首次将 Mamba 引入遥感领域，开发了用于极高分辨率遥感图像密集预测任务的 RS-Mamba。它利用其线性复杂度和全局建模能力来处理大型遥感图像。 以前的遥感模型主要是分为基于CNN和基于Transformer。基于CNN的模型由于局部卷积运算，无法对遥感图像进行全局建模。基于 Transformer 的模型由于其二次复杂度，无法处理大型超高分辨率遥感图像，而不会通过将图像裁剪成更小的块而丢失大量上下文信息。 尽管最近的工作，Vim 和VMamba将Mamba带入视觉成像领域，它们只在水平或垂直方向上进行选择性扫描，适合主要空间特征分布在这些方向上的自然图像，而不适合特征分布在任意方向上的遥感图像。 针对这些问题，RS-Mamba创新性地提出了全向选择性扫描模块，对遥感图像进行多个方向扫描，提取各个方向的大尺度空间特征。由于其线性复杂性，RS-Mamba 可以处理 Transformer 模型无法处理的大型遥感图像，拥有全局建模功能。在各种土地覆盖类型的语义分割和变化检测任务中的实验表明，RS-Mamba 通过简单的模型架构和训练方法实现了最先进的性能。 RSM-SS和RSM-CD的整体结构 代码：RS-Mamba PDF：RS-Mamba Arxiv：RS-Mamba 代码已开源，如果您觉得有帮助，请在 GitHub 上给我们一个star，我们将不胜感激。 更多信息，可以参考上述论文和代码。 我们欢迎基于本文进一步探索基于SSM的方法在远程密集预测任务中的潜力传感。 RSM 中使用的架构是最简单的，这表明其具有巨大的未开发潜力。 Mamba 在各个领域的受欢迎程度正在迅速达到遥感领域，其在该领域的潜力有望激发新的领域研究兴趣浪潮。   由   提交 /u/walkingshadow2233   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c158zy/r_mamba_enters_remote_sensing_rsmamba_the_first/</guid>
      <pubDate>Thu, 11 Apr 2024 03:40:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您最近关注 MLOps 领域有哪些有趣的发展？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c155wj/d_what_interesting_developments_in_the_mlops/</link>
      <description><![CDATA[最近感觉停滞不前。希望将一些尖端技术融入到我的 MLOps 堆栈中。但不知道从哪里开始，甚至不知道从哪里开始。 发展速度绝对是势不可挡的，尤其是现在基础法学硕士的狂野西部性质。因此，我希望这篇文章能够产生一些有用的线索供探索。 博客或论文链接的奖励积分。没有必要将自己限制在一件事情上。 TIA！   由   提交 /u/synthphreak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c155wj/d_what_interesting_developments_in_the_mlops/</guid>
      <pubDate>Thu, 11 Apr 2024 03:35:39 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对象识别的自回归模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c141qv/r_an_autoregression_model_for_object_recognition/</link>
      <description><![CDATA[      大家好！ 我想分享一下我们最近的 CVPR 工作，希望传播我们简单的想法并从社区收集见解。 [TL;DR] 自回归模型可以仅根据输入图像预测标签，没有预定义的查询库（例如，类似 CLIP 的模型）或预定义的类概念（例如，类似 VGG/ResNet 的模型）。该模型从整个文本空间（任何标签）中预测前 K 个标签，例如 top-100。 有关更多详细信息，请访问我们的论文和项目：&lt; a href=&quot;https://github.com/kaiyuyue/nxtp&quot;&gt;https://github.com/kaiyuyue/nxtp。 感谢您的想法和反馈。非常感谢！ -----图----- https://preview.redd.it/edrhgizctrtc1.png?width=1124&amp;format=png&amp;auto=webp&amp;s=d5a4ebb0ad58da9ae11f4550 1846ada130539f06&lt; /p&gt;   由   提交/u/pidoyu  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c141qv/r_an_autoregression_model_for_object_recognition/</guid>
      <pubDate>Thu, 11 Apr 2024 02:37:44 GMT</pubDate>
    </item>
    <item>
      <title>[R] NeurIPS '24 - 尚未进行实验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c10364/r_neurips_24_no_experiments_yet/</link>
      <description><![CDATA[我是一名正在进行研究的本科生（之前没有发表过文章）。我和我的顾问一直忙于其他工作，没有足够的时间来处理我们的项目。虽然我们已经编写了大部分代码，但我们还剩下一些部分，并且还没有开始运行任何实验（尽管我们知道前进的步骤并且有一个相对有组织的研究计划）。我们计划提交给 NeurIPS &#39;24；我们是否应该屈服并尝试向 ICLR 提交（九月截止日期）？接下来的几周值得全力以赴吗？    由   提交 /u/epsilon-delta-proof   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c10364/r_neurips_24_no_experiments_yet/</guid>
      <pubDate>Wed, 10 Apr 2024 23:32:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 单 GPU 上的数据高效多模态融合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0zfpx/r_dataefficient_multimodal_fusion_on_a_single_gpu/</link>
      <description><![CDATA[ 由   提交/u/gabloa  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0zfpx/r_dataefficient_multimodal_fusion_on_a_single_gpu/</guid>
      <pubDate>Wed, 10 Apr 2024 23:03:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您建议在哪些方面测试新的通用方法（架构/优化器）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c0vh48/d_what_would_you_recommend_testing_new_general/</link>
      <description><![CDATA[到目前为止，我的很多工作都是关于优化器和架构的，但在发布研究结果时只在小型标记预测语言任务上测试过它们。您需要看到什么才能确信一种新颖的通用方法确实更优越？非常感谢具体的数据集和模型大小以及相关基准。   由   提交 /u/LahmacunBear   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c0vh48/d_what_would_you_recommend_testing_new_general/</guid>
      <pubDate>Wed, 10 Apr 2024 20:20:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>