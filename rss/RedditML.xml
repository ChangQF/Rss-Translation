<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Sun, 28 Apr 2024 12:25:19 GMT</lastBuildDate>
    <item>
      <title>对于机器学习初学者来说，“探索深度学习技术在低资源语言中进行情感分析的应用”是一个可行的论文主题吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf4zyf/is_exploring_the_application_of_deep_learning/</link>
      <description><![CDATA[我应该写一篇关于数据科学/机器学习的学士论文，我选择了这个，我的时间有限，想知道这是否可以在机器学习初学者需要 2 周的时间？ （我知道时间不多）如果有任何主题想法请提出谢谢   由   提交 /u/General_Arm_7352   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf4zyf/is_exploring_the_application_of_deep_learning/</guid>
      <pubDate>Sun, 28 Apr 2024 12:14:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何诊断训练损失中的这些峰值？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf4gw9/d_how_would_you_diagnose_these_spikes_in_the/</link>
      <description><![CDATA[   /u/NumberGenerator  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf4gw9/d_how_would_you_diagnose_these_spikes_in_the/</guid>
      <pubDate>Sun, 28 Apr 2024 11:44:29 GMT</pubDate>
    </item>
    <item>
      <title>在（国际象棋或将棋）中实现 alpha 0 是一个好的论文主题吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf4d8c/is_implementation_of_alpha_zero_in_chess_or_shogi/</link>
      <description><![CDATA[我应该写一篇关于数据科学/机器学习的论文，我选择了在（国际象棋或将棋）中实现 alphazero（尚未选择游戏） ）但是这是一个有效的论文主题吗？如果是的话，它是一个好的主题吗？如果您有任何主题想法，请提出任何建议谢谢   由   提交 /u/General_Arm_7352   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf4d8c/is_implementation_of_alpha_zero_in_chess_or_shogi/</guid>
      <pubDate>Sun, 28 Apr 2024 11:38:16 GMT</pubDate>
    </item>
    <item>
      <title>“变形金刚可以使用无意义的填充标记（例如，‘......’）来代替一连串的思想” - Let's Think Dot by Dot [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf2u0d/transformers_can_use_meaningless_filler_tokens_eg/</link>
      <description><![CDATA[https://arxiv.org/abs/2404.15758 从摘要开始 我们表明，变压器可以使用无意义的填充标记（例如“......”）来代替一系列思想来解决两个问题在没有中间令牌的情况下进行响应时，他们无法解决困难的算法任务。然而，我们根据经验发现，学习使用填充令牌很困难，需要特定的、密集的监督才能收敛   由   提交 /u/Agitated_Space_672   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf2u0d/transformers_can_use_meaningless_filler_tokens_eg/</guid>
      <pubDate>Sun, 28 Apr 2024 09:59:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于网络搜索代理的网络抓取工具是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf2fms/d_what_web_scraper_for_web_search_agent/</link>
      <description><![CDATA[大家好...  我构建了一个高级 RAG 管道，其中包括一个应该从网络获取数据的代理，从网络搜索结果中打开链接...无论如何，我过去的网络抓取经验为零，而且我的 html 知识非常基础。我疯狂地试图从网页中提取主要文本，而不会受到标签、标题和其他 UI 元素的干扰。作为临时解决方案，我在“中间”添加了一个 llm 代理，用它来清理抓取的文本......但这很慢、昂贵（使用云提供商）并且效率很低。  有人可以给我一些提示/帮助吗？有一些库、存储库或框架可以帮助我吗？  任何形式的重播都将非常感激！  预先感谢您的宝贵时间。    由   提交 /u/Distinct-Target7503    reddit.com/r/MachineLearning/comments/1cf2fms/d_what_web_scraper_for_web_search_agent/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf2fms/d_what_web_scraper_for_web_search_agent/</guid>
      <pubDate>Sun, 28 Apr 2024 09:31:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 将您的 LLM（应用程序/系统）转移到生产环境中最常见和最重大的挑战是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf178i/d_what_are_the_most_common_and_significant/</link>
      <description><![CDATA[目前有很多人使用法学硕士进行构建，但没有那么多人从原型和 POC 过渡到生产。尤其是在企业环境中，但我相信这对于产品公司甚至一些专注于基于 LLM 的应用程序的初创公司来说也是类似的。事实上，一些调查和研究认为这一比例低至5%。  从事这一领域工作的人们，在尝试将产品投入生产时遇到的最常见和最困难的挑战是什么？目前您是如何解决这些挑战的？    由   提交/u/gamerx88  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf178i/d_what_are_the_most_common_and_significant/</guid>
      <pubDate>Sun, 28 Apr 2024 08:07:07 GMT</pubDate>
    </item>
    <item>
      <title>[D]关于构建OCR基准数据集时的版权问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cf1763/d_about_copyright_problem_when_building_ocr/</link>
      <description><![CDATA[我是新手，所以请轻柔地回答我。 基本上，我想创建越南语前现代的基准数据集用于 OCR 任务（文本识别）的书籍（当上下文、内容、方言、语法、老化的印刷质量、印刷模具非常不同时）。 问题是我从互联网上下载了它们（有些人只是上传并提供一些云驱动器的链接），我只是一一获取了具有基本事实的信息。这些书的出版日期从 1880 年到 1970 年不等，其中许多出版商都消失了（破产或出售或更名或合并或私有化）。我的意思是每本书的版权都非常不同（因为越南在战后改变了政治制度）。 这比我想象的要复杂，因为它是过渡时期（中诺到佛朗哥殖民地国家到南越）到现在），解决了很多技术难题。但突然ChatGPT（我问在哪里发布）告诉我要小心版权问题。我不知道在哪里问，所以我希望我能从这里得到帮助。 我真的很想发表这个，因为没有人尝试它，目前的 OCR 还不够好，因为越南研究界不付费就像中国人或韩国人一样受到关注。我想将其贡献给进一步的研究（作为将 VNese 老龄化书籍数字化的努力）。 但是有了这个版权，我根本没有任何经验。而且，这样的书大约有100本，全部联系起来又是一个痛苦的问题。我想知道我是否可以发表，但有一个条件或协议，即这是“仅研究目的”基准数据集，任何人都不应将其用作转售或类似用途。 如果有人知道如何以最省力的方式处理此版权，请告诉我。非常感谢。   由   提交/u/Soggy_Ad6925   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cf1763/d_about_copyright_problem_when_building_ocr/</guid>
      <pubDate>Sun, 28 Apr 2024 08:07:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 自然语言到 MongoDB 查询的转换。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ceyzkr/p_natural_language_to_mongodb_query_conversion/</link>
      <description><![CDATA[      我很高兴这次发布我的副项目“nl2query”的下一个迭代一个微调的 Phi2 模型，用于将自然语言输入转换为相应的 Mongodb 查询。以前的 CodeT5+ 模型不够强大，无法处理嵌套字段（如数组和对象），但 Phi2 可以。在 GitHub 上探索代码：https://github.com/Chirayu-Tripathi/nl2query。 https://preview.redd.it/0y8o9w1br5xc1.png ?width=1800&amp;format=png&amp;auto=webp&amp;s=295e045bedf504ec4b0e4b04d590635abf45119b   由   提交/u/WorryWhole7805   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ceyzkr/p_natural_language_to_mongodb_query_conversion/</guid>
      <pubDate>Sun, 28 Apr 2024 05:42:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] PointNet 输入转换块中单位矩阵的作用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cexbr6/d_role_of_the_identity_matrix_in_pointnets_input/</link>
      <description><![CDATA[你好， 我目前正在探索 PointNet 的代码，特别是输入转换块。我知道这个块用于学习应用于输入点云的变换矩阵，但我对单位矩阵在这种情况下以及通常在深度学习中的作用有点困惑 Here&#39;s我所指的代码片段：  def forward(self, x): batchsize = x.size()[0] x = F.relu(self.bn1( self.conv1(x))) x = F.relu(self.bn2(self.conv2(x))) x = F.relu(self.bn3(self.conv3(x))) x = torch.max( x, 2, keepdim=True)[0] x = x.view(-1, 1024) x = F.relu(self.bn4(self.fc1(x))) x = F.relu(self.bn5( self.fc2(x))) x = self.fc3(x) iden = 变量(torch.from_numpy(np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype (np.float32))).view(1, 9).repeat(batchsize, 1) if x.is_cuda: iden = iden.cuda() x = x + iden x = x.view(-1, 3, 3 ) 返回 x    由   提交 /u/Same_Half3758   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cexbr6/d_role_of_the_identity_matrix_in_pointnets_input/</guid>
      <pubDate>Sun, 28 Apr 2024 04:00:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 快速提问：您如何实施研究论文？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cew2b5/d_quick_question_how_do_you_implement_research/</link>
      <description><![CDATA[我正在学习深度学习，现在我想通过实施一篇研究论文来测试我的技能。 有一篇研究论文称为深度学习的语言进化，它让我着迷，但我很困惑从哪里开始以及如何开始。 如果有人，我需要指导。   由   提交/u/No-Signal-313  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cew2b5/d_quick_question_how_do_you_implement_research/</guid>
      <pubDate>Sun, 28 Apr 2024 02:48:54 GMT</pubDate>
    </item>
    <item>
      <title>[P] NLLB-200 蒸馏器 350M 一台</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ceuj4t/p_nllb200_distill_350m_for_enko/</link>
      <description><![CDATA[您好r/MachineLearning， 我很高兴分享一个最初打算在我的毕业产品（Capstone）中使用的项目 我制作了 NLLB-200 Distill 350M 模型来将英语翻译成韩语 很好用。小而快。所以它可以用 CPU 运行！ GPU 服务器相当昂贵，所以我为那些买不起服务器的大学生（比如我）制作了它。 更多细节是在我的页面 如果你懂韩语，请给我很多反馈 谢谢！！ https://github.com/newfull5/NLLB-200-Distilled-350M-en-ko   由   提交/u/SaeChan5  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ceuj4t/p_nllb200_distill_350m_for_enko/</guid>
      <pubDate>Sun, 28 Apr 2024 01:26:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 RAG 的真实讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cekoc7/d_real_talk_about_rag/</link>
      <description><![CDATA[说实话。我知道我们都必须与这些经理/董事/CXO 打交道，他们提出了与公司数据和文档交谈的惊人想法。 但是……有人真正做了一些真正有用的事情吗？如果是这样，它的有用性是如何衡量的？ 我有一种感觉，我们被一些非常复杂的废话所愚弄，因为法学硕士总是可以产生在某种程度上听起来合理的东西。但它有用吗？   由   提交/u/fusetron  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cekoc7/d_real_talk_about_rag/</guid>
      <pubDate>Sat, 27 Apr 2024 18:00:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 基于 Llama-3 的 OpenBioLLM-70B 和 8B：在医疗领域优于 GPT-4、Gemini、Meditron-70B、Med-PaLM-1 和 Med-PaLM-2</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1cecpvk/d_llama3_based_openbiollm70b_8b_outperforms_gpt4/</link>
      <description><![CDATA[      开源再次来袭，我们很高兴地宣布 OpenBioLLM-Llama3-70B 和 OpenBioLLM-Llama3-70B 的发布。 8B.这些模型在生物医学领域超越了 Openai 的 GPT-4、Google 的 Gemini、Meditron-70B、Google 的 Med-PaLM-1 和 Med-PaLM-2 等行业巨头，树立了新的状态。对于同尺寸的模型来说是最先进的。 迄今为止最有能力的公开医学领域法学硕士！ 🩺💊🧬 https://预览。 redd.it/w41pv7mwf0xc1.png?width=5760&amp;format=png&amp;auto=webp&amp;s=f3143919ef8472961f329bb8eb98937d8f8e41e0 结果可在 Open Medical-L 上查看LM排行榜：https://huggingface.co/spaces/openlifescienceai/open_medical_llm_leaderboard 超过约 4 个月，我们精心策划了多样化的定制数据集，与医学专家合作以确保最高质量。该数据集涵盖 3000 个医疗保健主题和 10 多个医学主题。 📚 OpenBioLLM-70B 的卓越性能在 9 个不同的生物医学数据集上显而易见，尽管与 GPT-4 和 GPT-4 相比其参数数量较少，但其平均得分达到了令人印象深刻的 86.06%。医学-PaLM。 📈 https://预览。 redd.it/5ff2k9szf0xc1.png?width=5040&amp;format=png&amp;auto=webp&amp;s=15dc4aa948f2608717f68ddf2cb27a6a2de03496 您今天可以直接从 Huggingface 下载模型。  70B : https://huggingface.co/aaditya/OpenBioLLM-Llama3-70B 8B：https://huggingface.co/aaditya/OpenBioLLM-Llama3-8B  此版本只是一个开始！在接下来的几个月中，我们将推出  扩大医疗领域覆盖范围， 更长的上下文窗口， 更好的基准，以及 多模式功能。  更多详细信息可在此处找到：https://twitter。 com/aadityaura/status/1783662626901528803 在接下来的几个月里，Multimodal 将可用于各种医疗和法律基准。 我希望它对您的研究有用 🔬 大家周末愉快！ 😊   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1cecpvk/d_llama3_based_openbiollm70b_8b_outperforms_gpt4/</guid>
      <pubDate>Sat, 27 Apr 2024 11:51:42 GMT</pubDate>
    </item>
    <item>
      <title>如何说服我的上级进行数据预处理？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ceckws/how_do_i_convince_my_superior_to_do_data/</link>
      <description><![CDATA[如何说服上级进行数据预处理？ 您好，我做了一年的 AI 工程师在我现在的公司（获得了数据科学专业的计算机硕士学位）。我们希望构建专门用于特定语言的闲聊（主要是对话式聊天）的聊天机器人。  问题是我不同意上级的做事方式。它几乎总是在进行即时工程。我的意思是我们有大量的数据（我想说的是无限的实时会话聊天会话，其中包含兴趣、外表等信息……这是所有数据科学家建立一个漂亮模型的梦想）。我不同意他的方法的原因是，通过及时的工程设计，我们并不总是能获得持续的良好结果。此外，对于特定领域（例如色情聊天），由于模型的审查，您无法提示工程。当模型未针对特定领域的标记/单词进行训练时，可能会出现幻觉和其他问题。最后，一切都与统计有关，不是吗？该模型从使用的数据中学习。如果推理过程中有一个 token 没有包含在训练数据中，那么它会以概率进行猜测，以预测最有可能的下一个 token。 我不明白为什么我们不这样做利用这些数据来清理它，为我们的目的/领域创建一个超级好的数据集，并对法学硕士进行微调。我问过他很多次为什么我们不这样做，我的上级回答说：“我们过去这样做过，成本太大，效果不好”。于是我问他，是谁干的？他告诉我，我的同事做到了（医学教育背景，空闲时间对人工智能感兴趣，但他对数据处理或数据科学基础知识一无所知）。  所以他们最后一次尝试是在3年前（他们是用deepspeed做的，没有使用Lora方法，所以我的上级告诉我成本相当高，但结果不好（他们在云中进行了微调） 200h），所以这是一个完整的参数微调） 说实话，我不怪我的同事。他用自己的知识尽力了。但我确实责怪我愚蠢的上司，我们没有取得多大成功来为我们的目的开发一个像样的模型。  所以，在我开始为公司工作半年后，我终于可以说服我的上司了（因为我在空闲时间做了一个微调，只是为了好玩，并向他们展示了我的结果）。所以他同意，我们可以对洛拉进行微调，但是..但是..没有数据处理，就拿原始的宝贝来说！！ 说真的，那家伙完全迷失了，顺便说一句，他是我们的产品经理并且对数据科学一无所知。他在没有数据处理的情况下再次犯了同样的错误，因为“我们没有这方面的资源”，我什至无法说服他。 所以最后，聊天机器人变得比仅仅做更好一些及时的工程，但对我来说它仍然是垃圾。我只想要一个真实且标准的工作流程，包括数据预处理、训练、评估。就这样。最重要的是：数据预处理 那么你们觉得怎么样？我是猴子吗？我应该尽快离开公司吗？我需要在那里至少再呆一年。   由   提交/u/bobotomoon  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ceckws/how_do_i_convince_my_superior_to_do_data/</guid>
      <pubDate>Sat, 27 Apr 2024 11:43:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c9jy4b/d_simple_questions_thread/</guid>
      <pubDate>Sun, 21 Apr 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>