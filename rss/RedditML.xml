<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 07 Nov 2024 01:14:19 GMT</lastBuildDate>
    <item>
      <title>[D] 存储 LLM 嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glecgo/d_storing_llm_embeddings/</link>
      <description><![CDATA[你好！ 我正在开展一个 ML 项目，该项目涉及使用预训练的蛋白质语言模型（如 ESM）。对于该项目，我想预先生成并存储大约 500,000 个氨基酸序列的嵌入。但是，这些向量可能非常庞大 - 嵌入序列、序列化 PyTorch 向量（使用 torch.save）和对整个数据集进行 gzip 压缩将使用大约 500TB。如果我使用 bfloat16，这会将数字减半，但仍然非常难以处理。我也可以使用具有较小潜在空间的模型，但这也不能真正解决问题。 我尝试过不同的压缩工具，但似乎没有一个能做得更好。所有这些工具的压缩率都非常糟糕（只有大约 7%），我假设这意味着向量看起来非常随机。我想知道是否有人知道如何序列化向量，使它们看起来不那么“随机”。我认为向量不应该是随机的，因为氨基酸序列具有可预测的结构，所以我希望有一种方法可以实现更好的压缩。 任何建议或想法都将不胜感激！我的其他选择是大幅减少训练数据的大小，这并不理想，或者临时生成嵌入，这非常耗费计算资源，即使在 GPU 上也是如此。    提交人    /u/BerryLizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glecgo/d_storing_llm_embeddings/</guid>
      <pubDate>Thu, 07 Nov 2024 00:58:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于 LLM 逆向工程和红队测试的开源模块化工具</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glazls/p_open_source_modular_tool_for_llm_reverse/</link>
      <description><![CDATA[https://github.com/user1342/Oversight    由   提交  /u/OppositeMonday   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glazls/p_open_source_modular_tool_for_llm_reverse/</guid>
      <pubDate>Wed, 06 Nov 2024 22:25:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我可以使用什么技术来保持图像生成的一致性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1glas2y/d_what_techniques_i_can_use_to_maintain/</link>
      <description><![CDATA[我正在开展一个 NLP 项目， 1) 将 txt 文件作为输入 2) 使用 Gemini api 从预定义的 writeup 中提取信息 3) 使用 DistilBert 对主文件进行总结 4) 并使用 ROUGE 以第二步生成的结果作为计算评估指标的基本事实。然后通过参数调整来改进评估指标结果 5）将每个写入转换为详细的图像提示 6）使用文本到图像模型从提示生成图像。 我需要帮助，如何改进这个过程，我可以使用哪些技术来保持图像生成的实体表示的统一性。 我愿意接受你的任何建议 也请建议是否有任何好的研究论文我可以参考..    提交人    /u/Which-Boss-1332   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1glas2y/d_what_techniques_i_can_use_to_maintain/</guid>
      <pubDate>Wed, 06 Nov 2024 22:16:06 GMT</pubDate>
    </item>
    <item>
      <title>[P] YOLOv8 .pt 文件用于跨多种环境的通用对象检测（50+ 个类别）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gla56x/p_yolov8_pt_file_for_general_object_detection/</link>
      <description><![CDATA[有人可以提供用于一般物体检测的 YOLOv8 的最佳 .pt 文件吗，涵盖大学、办公室和家庭等环境，数据集包含至少 50 个类别？    提交人    /u/MuchSand7923   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gla56x/p_yolov8_pt_file_for_general_object_detection/</guid>
      <pubDate>Wed, 06 Nov 2024 21:49:03 GMT</pubDate>
    </item>
    <item>
      <title>[R] 嵌入模型无法捕捉中性语义：应用于偏见检测用例。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gl9rof/r_embedding_models_are_not_able_to_capture/</link>
      <description><![CDATA[在这篇论文中：通过上下文注入消除文本嵌入偏差，结果表明嵌入模型无法真正捕捉“中性”文本的语义。 这一现象是在偏见检测的视角下研究的，其中“中性”表示：性别中立、年龄中立、种族中立。 事实上，我们发现了一种过度补偿效应，即“这个人是电工。我们不知道这个人的性别。”与女性相关术语的嵌入程度比与男性相关术语的嵌入程度更高。任何与男性相关的工作/职业都是这种情况。 因此，我们表明，嵌入中的偏见不能通过使用有目的制作的上下文/提示来消除。 这些见解证实了 SUGARCREPE++ 论文 的发现，即嵌入模型很难将语法与词汇/语义相似性区分开来。 这项工作尚未经过同行评审，仍处于预印本阶段。代码位于：https://github.com/pinouche/bias-in-embeddings    提交人    /u/EvenYogurtcloset3966   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gl9rof/r_embedding_models_are_not_able_to_capture/</guid>
      <pubDate>Wed, 06 Nov 2024 21:33:07 GMT</pubDate>
    </item>
    <item>
      <title>[D]篮球视频中的球员识别与追踪（计算机视觉）[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gl999e/dplayer_identification_and_tracking_in_basketball/</link>
      <description><![CDATA[我正在为体育行业的一个客户启动一个项目，目标是从视频中识别篮球运动员，具体来说，他们想要的是球员号码，这只是第一步，因为他们希望能够识别哪个球员做了特定的比赛，但在手动观看了一些视频后，似乎从球员球衣上识别号码对我来说非常困难，即使对于我这个人类来说也是如此（图像质量不佳，而且摄像头有时离篮球场太远），所以我想知道是否有关于如何解决这个问题的建议？ 有什么推荐的模型、算法、方法或流程吗？（主要问题是如何识别球员）我在考虑做类似的事情：对象跟踪以在每个时刻了解谁是独特的球员以及他们的位置，然后尝试在可以看到号码的某些帧中使用 OCR 从他们的球衣上读取号码，但这可能非常低效且容易出错。    由   提交  /u/Sad-Anywhere-2204   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gl999e/dplayer_identification_and_tracking_in_basketball/</guid>
      <pubDate>Wed, 06 Nov 2024 21:11:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于规范化的模糊性和缺失链接</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gl5fy8/d_on_obscurities_and_missed_links_with/</link>
      <description><![CDATA[尽管几乎身处任何地方，我还是不断注意到规范化技术是多么晦涩难懂，对 reddit 用户和技术人员来说都是如此。 InstanceNorm、GroupNorm、BatchNorm、LayerNorm 都是计算平均值、标准差，然后对输出进行 z 评分（可能随后进行仿射变换）。它们通过计算统计数据的轴来区分。 RMSNorm 和 ScaleNorm（缩放的 L2 规范化）反而是“固定范数”的向量，重新缩放。但这掩盖了它们与 LayerNorm 之间的关系。如果在 d 维向量上执行 LayerNorm，当我们居中（移除平均值）时，我们会将其投影到垂直于 1 的向量并与原点相交的超平面上；当我们重新缩放中心条目时，我们现在将向量限制在所述超平面中的“超圆”（d-1 维的超球面）。我们丢失了有关其原始方向和幅度的信息。无论如何，此后的所有向量都具有 sqrt(d) 范数和具有单位方差的条目。当我们执行 RMSNorm 时，我们跳过中心部分并具有 sqrt(d) 范数和具有单位方差的条目。当我们执行 ScaleNorm 时，范数固定为 1，因此方差缩小到 1/d。特别是，RMSNorm 和 ScaleNorm 是相同的，模数缩放因子仅取决于 d 和最终学习的仿射。 那么我们何时以及为什么应该选择单位范数或单位方差？例如，有“尺度等变”激活函数，例如 ReLU，以及高度变异的激活函数，例如 e(x)（其斜率直接取决于 x）。 我最近看到了一篇不错的 TokenFormer 论文，他们似乎竭尽全力不白白写出他们用 GeLU(RMSNorm(attn_logit_of_q_i)) 替换 softmax(attn_logit_of_q_i)。他们将其作为具有乘数和 L2 范数除法的缩放对数出售，但它在初始化时正是 RMSNorm，他们没有检查学习摆脱它是否真的发生并有帮助。 另一篇不错的论文是 normalizedGPT，他们将 token 保留在单位超球面上，但有点遗憾缺乏针对 L2norm 的特定 CUDA 内核。RMSNorm 对于用例来说有那么大的不同吗？可能，但是如何以及为什么？ 为什么我们要发现和重新涵盖规范化技术和操作方法，部分和事后解释决策，等等？我认为这很重要，特别是在使用如此多的 softmax 函数时，差异实际上比比率更重要（例如 softmax([1,2])==softmax([11,12])!=softmax([10,20])，这是否总是清晰、理想和明智的？）    提交人    /u/Sad-Razzmatazz-5188   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gl5fy8/d_on_obscurities_and_missed_links_with/</guid>
      <pubDate>Wed, 06 Nov 2024 18:32:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何在已为每个客户端划分数据集的自定义数据集上运行联邦学习模拟？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gl3wto/d_how_to_run_a_federated_learning_simulation_on_a/</link>
      <description><![CDATA[因此，我在 flwr 中查找此任务，我发现了很多分区器，但没有一个可以完成工作（我也可能错过了） 你们解决过这样的问题吗？ 为了更好地理解，假设我有四个客户端 A、B、C 和 D 在正常情况下（在许多使用 CIFAR10 的文档中给出），有一个数据集根据某种算法被划分为这四个客户端。 我不想要那样，我所拥有的基本上是一个已经根据客户端（A/B/C/D）划分的数据集（训练/测试划分尚未完成），我想在这种环境中运行模拟 任何帮助都将不胜感激！    提交人    /u/lel_73   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gl3wto/d_how_to_run_a_federated_learning_simulation_on_a/</guid>
      <pubDate>Wed, 06 Nov 2024 17:28:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了一个工具，用于通过直观的操作来构建和训练神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gl30b0/p_i_made_a_tool_for_building_and_training_neural/</link>
      <description><![CDATA[嘿！我主要将其作为工具来学习如何实现反向传播并了解其工作原理，因此我认为它可能对其他人有用！我还在自述文件中撰写了一篇关于反向传播和模型训练如何工作的文章：https://github.com/PavleMiha/mlgarden 这对您有用吗？这是您会玩的东西吗？我真的不知道该怎么用它，所以我很想听听社区的想法！    提交人    /u/Massena   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gl30b0/p_i_made_a_tool_for_building_and_training_neural/</guid>
      <pubDate>Wed, 06 Nov 2024 16:50:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 亚马逊研究人员发现 LLM 并不总是遵循用户请求并提出自我纠正流程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkzac4/r_amazon_researchers_find_llms_do_not_always/</link>
      <description><![CDATA[      偶然发现了这篇将于下周在 EMNLP 2024 上发表的有趣论文：LLM使用 DECRIM 进行自我纠正：分解、批评和改进，以增强对具有多个约束的指令的遵循。。 这项研究深入探讨了一个重要问题：LLM 真的会按照我们的要求去做吗？我们经常依靠 LLM 来完成具有特定指令的任务，但是当这些指令变得复杂且受到多重约束时，例如要求特定的音调或避免使用某些单词，LLM 真的会遵循吗？本文表明答案可能比我们想象的更复杂。 作者创建了一个新的基准 RealInstruct，它使用真实世界的用户指令而不是合成提示。他们估计至少 30% 的真实用户请求包含 LLM 必须遵循的多个约束。在他们的结果中，即使是像 GPT-4 这样的高级模型也未能满足超过 21% 的测试指令的至少一个要求。因此，虽然 LLM 在简单情况下表现良好，但在处理更复杂、多步骤的请求时，其性能会下降。 为了解决这些差距，作者开发了一个名为 DECRIM 的自我修正管道，其中模型分解每条指令，根据每项要求检查其响应，并根据需要迭代优化它。通过 DECRIM，像 Mistral 这样的开源模型得到了显着的改进，甚至在基准测试中超过了 GPT-4。初步测试表明，LLM 无法单独可靠地自我纠正，然而，在弱但可靠性最低的辅助反馈下，它们实现了高达 8% 的提升。 通过高质量的“理想”反馈，DECRIM 将 Mistral 的性能提高了 34%，在 RealInstruct 和 IFEval 基准测试中均超越了 GPT-4。 我认为这篇论文符合 LLM 的新趋势，这些系统 2 推理模型（如 GPT-o1）在输出响应之前试图模仿一些思考/反思。无论如何，令人震惊的是，LLM 在一个似乎只是对用户最重要的任务中表现如此糟糕，遵循用户的要求。这种类型的模型是否让我们更接近 AGI？或者这只是证明有些人谈论的这种神奇的 AGI 实际上还很遥远？  论文：https://arxiv.org/pdf/2410.06458 他们在 Linkedin 上的帖子 https://preview.redd.it/techjo8pfazd1.png?width=2794&amp;format=png&amp;auto=webp&amp;s=18155cdbf4ba164f48480d4583c3cfea1d40298e    提交人    /u/Mundane_Sir_7505   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkzac4/r_amazon_researchers_find_llms_do_not_always/</guid>
      <pubDate>Wed, 06 Nov 2024 14:06:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 想要摆脱繁重的机器学习编码，但仍想完成博士学位</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkx6o7/d_want_to_move_away_from_coding_heavy_ml_but/</link>
      <description><![CDATA[大家好， 我来自传统的电气工程背景，从事工业自动化和计算机视觉等工作。我决定攻读机器学习博士学位，因为根据我过去的经验，我认为这将是一个不错的领域。现在我已经攻读博士学位三年了。虽然我喜欢我的团队和研究，但我对以下因素感到沮丧/沮丧：(1) 出版竞争激烈 (2) 毕业后的机会大多是编码繁重 (3) 由于该领域已经变得如此拥挤，我无法在该领域为自己树立名声。 因此，理想情况下，我希望完成我的博士学位，然后从事节奏更轻松（即使它不像机器学习工作那么高薪）且编码繁重但技术性强的工作，在那里我不需要不断提升自己的技能。你们对我可以从事什么工作有什么建议吗？或者你们建议我放弃博士学位，做些其他的事情？ TLDR：四年级 ML 博士生不确定是否继续攻读博士学位，因为他们希望毕业后在行业中从事一份非编码重度技术工作。寻求建议。    提交人    /u/Hopeful-Reading-6774   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkx6o7/d_want_to_move_away_from_coding_heavy_ml_but/</guid>
      <pubDate>Wed, 06 Nov 2024 12:18:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 现代人工智能的矩阵计算技术不断发展：有何新进展？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gkwpht/d_evolving_matrix_computation_techniques_for/</link>
      <description><![CDATA[随着人工智能模型在复杂性和规模上不断扩大，我对矩阵计算领域如何发展以应对这些新挑战很感兴趣。矩阵计算中有哪些最新进展或策略可以提高现代人工智能系统的效率和适应性？我们在这些计算方法上是否有任何最新突破或转变，对人工智能研究和应用产生了重大影响？    提交人    /u/Glittering_Age7553   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gkwpht/d_evolving_matrix_computation_techniques_for/</guid>
      <pubDate>Wed, 06 Nov 2024 11:51:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 作为一名研究人员，您如何做好进入行业的准备？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gksoi7/d_as_a_researcher_how_do_you_become_industryready/</link>
      <description><![CDATA[作为一名博士生，我的大部分时间都花在指导学生、项目管理和编写用于原型设计的“快速而粗糙”的代码上。我打算在获得博士学位后进入行业，但我觉得我错过了关键的软件工程技能和良好的编码实践。其他人有这种感觉吗？在攻读博士学位期间，你如何提升自己的技能以做好进入行业的准备？    提交人    /u/fullgoopy_alchemist   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gksoi7/d_as_a_researcher_how_do_you_become_industryready/</guid>
      <pubDate>Wed, 06 Nov 2024 07:07:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/</guid>
      <pubDate>Sun, 03 Nov 2024 16:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>