<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Sat, 06 Apr 2024 12:22:22 GMT</lastBuildDate>
    <item>
      <title>[p] Rag - 知识库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxa8g8/p_rag_knowledge_base/</link>
      <description><![CDATA[我将为工厂构建一个聊天机器人。机器人应该了解生产过程。没有任何文档或其他东西来记录这些知识。获取这些数据的最佳方式是什么，可能会出现什么问题？这样的知识文本应该多长？我正在考虑一次聊天，工厂里的人解决问题，我可以将其保存为知识，但我认为聊天会产生大量混乱的数据。  &amp;# 32；由   提交/u/ExtensionPrimary9095   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxa8g8/p_rag_knowledge_base/</guid>
      <pubDate>Sat, 06 Apr 2024 12:21:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用预先训练的扩散模型进行极限视频压缩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bxa6a0/r_extreme_video_compression_with_pretrained/</link>
      <description><![CDATA[ 由   提交/u/atgctg   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bxa6a0/r_extreme_video_compression_with_pretrained/</guid>
      <pubDate>Sat, 06 Apr 2024 12:18:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 非 NLP 领域的 ML 研究人员，你们在研究什么？请分享。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bx914m/d_ml_researchers_who_are_not_in_nlp_what_are_you/</link>
      <description><![CDATA[我们很想了解机器学习研究的范围。 如果您将其写得尽可能详细，将会有所帮助。研究实际需要的内容是可能的。谢谢！   由   提交/u/20231027  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bx914m/d_ml_researchers_who_are_not_in_nlp_what_are_you/</guid>
      <pubDate>Sat, 06 Apr 2024 11:12:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] H5到tflite转换问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bx8s7c/d_h5_to_tflite_conversion_problems/</link>
      <description><![CDATA[       &amp;# 32；由   提交/u/Rhet98  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bx8s7c/d_h5_to_tflite_conversion_problems/</guid>
      <pubDate>Sat, 06 Apr 2024 10:56:56 GMT</pubDate>
    </item>
    <item>
      <title>[P] GitHub - CaptureFlow：为法学硕士提供 CodeGen 的调试器级应用程序上下文（开源）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bx7kzt/p_github_captureflow_provide_llms_with/</link>
      <description><![CDATA[嘿， https://github.com/CaptureFlow/captureflow-py/ 我我们构建了一个名为 CaptureFlow 的东西，这是一个开源 Python 工具，它将 AI（现在是 OpenAI API）代码生成与执行跟踪相结合，以建议自动修复生产错误。它捕获详细的执行图、代码、函数调用层次结构、输入/输出，并为人工智能驱动的代码重构任务提供一个非常好的管道。 为什么有趣：它打开了空间用于代码生成的检索增强生成（RAG）（向 DevinAI console.logging 本身致敬）。 渴望听到您的见解和想法。让我们一起集思广益，讨论人工智能开发的未来！ 自动异常处理只是一个 POC（基本调用图遍历），但我想知道如何进行基准测试……（新颖？）用例。   由   提交/u/Financial_Muffin396   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bx7kzt/p_github_captureflow_provide_llms_with/</guid>
      <pubDate>Sat, 06 Apr 2024 09:36:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我无法将 BERT 微调到超过 40% 的文本分类任务准确率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bx5r8r/d_i_just_cant_fine_tune_bert_over_40_accuracy_for/</link>
      <description><![CDATA[大家好，这是我第一次对 LLM 进行微调，但文本分类的准确率无法超过 40%任务。 我使用 Transformers 库中的 BERT 来加载和训练模型，并为 LoRA 实现提供支持。我的数据集包含新闻文章的英文书面摘要，每篇文章都有一个标签，例如经济、政治、科学、娱乐等......（14 个独特的标签）。摘要的最大长度可以扩展到 250-300 个标记。我的训练集有 800 个示例，验证集有 200 个示例。 起初，训练损失非常低，但验证损失并没有太低，验证准确率最高可达 45%。由于过度拟合，我将 dropout 率从 0.1 更改为 0.5。之后，模型现在没有过拟合，但欠拟合，验证和训练损失几乎相同，验证准确率仍然达到最大值 45%。 我尝试删除 LoRA 实现，但没有任何改变，除了训练时间。此时我很困惑我应该做什么。我尝试过调整超参数，但没有任何变化。 任何人都可以帮助我理解我可能在这里遗漏的内容。我可以分享统计数据和代码实现，或者如果可能的话我什至可以随叫随到。非常感谢任何帮助。   由   提交 /u/Total-Opposite-8396   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bx5r8r/d_i_just_cant_fine_tune_bert_over_40_accuracy_for/</guid>
      <pubDate>Sat, 06 Apr 2024 07:33:16 GMT</pubDate>
    </item>
    <item>
      <title>从人类的微小反馈中学习 [R] [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bx2nun/learning_from_little_human_feedback_r_p/</link>
      <description><![CDATA[我有一个输入是图像的环境，该图像可能包含也可能不包含边界框。根据提供的图像和人类的动作确定人类是否喜欢边界框的代理。现在，我想修改此设置，以便代理可以以最少的反馈适应任何其他人的偏好。我怎样才能实现这个目标？   由   提交/u/Sea-Collection-8844   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bx2nun/learning_from_little_human_feedback_r_p/</guid>
      <pubDate>Sat, 06 Apr 2024 04:26:11 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何利用离线先验知识来增强在线分类器？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bx0m5s/r_how_to_utilize_the_offline_prior_knowledge_to/</link>
      <description><![CDATA[你好，我希望设计一个分类系统，每1秒分类10个类别。 目前，我上网很差分类器的准确率达到 45%。但我可以在这个时间步获得每个类的离线概率，例如，P(offline) = [0.0, 0.05, 0.10, 0.70, ..., 0.15]。 直观上，虽然我的分类器 P（在线）的准确度较低，但我有 P（离线）作为附加先验信息，所以我猜我应该能够将这两者结合在一起以更好地执行任务。 我的计划是：我将设计一个名为“MyLogic”的逻辑来消耗来自 P(在线) 和 P(离线) 的预测向量，并且“MyLogic”将被调用。会输出一个信号来指示我是否有必要手动亲自检查班级。不过，我希望减少这种手动检查的频率。 有人可以指导我如何设计这个“MyLogic”吗？或者是否已经有一些现有的论文或文献来处理类似的问题？    由   提交 /u/AaronSpalding   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bx0m5s/r_how_to_utilize_the_offline_prior_knowledge_to/</guid>
      <pubDate>Sat, 06 Apr 2024 02:38:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 过去几个月的一些论文和方法通常或针对特定用例减少了预训练和/或微调和/或推理成本。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwtw2b/r_some_papers_and_approaches_in_the_last_few/</link>
      <description><![CDATA[   /u/Singularian2501   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwtw2b/r_some_papers_and_approaches_in_the_last_few/</guid>
      <pubDate>Fri, 05 Apr 2024 21:37:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何获得足够的耐心来训练-调试-训练模型？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwlqj4/d_how_do_you_get_enough_patience_to/</link>
      <description><![CDATA[训练一个大模型只是为了让它出错。我不会同时处理多项任务，因为专注于一件事可以更快地完成它。 但这太烦人了。我只是永远等待它完成，而我的所有其他任务都暂停了，当我得到结果时，这都是错误！  哎呀兄弟   由   提交 /u/RiseWarm   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwlqj4/d_how_do_you_get_enough_patience_to/</guid>
      <pubDate>Fri, 05 Apr 2024 16:02:36 GMT</pubDate>
    </item>
    <item>
      <title>[R] 以编码器-解码器方式重建 3D 点云（使用等变编码器）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwjus6/r_reconstructing_3d_point_clouds_in_an/</link>
      <description><![CDATA[我为我正在写的一篇论文设计了一些基于自动编码器的二维图像方法，现在根据之前会议的反馈，我正在尝试将我的方法扩展到 3D 点云。为此，我首先必须首先开发一个 3D 自动编码器（即从点云编码到潜在向量并解码到点云），然后当然要继续构建我的方法的其余架构和属性（自动编码器必须例如，尊重某些 SO(3) 等方差约束，但现在让我们忘记这一点）。作为起点，我已经使用 PointNet 作为编码器为点云开发了一个编码器-解码器架构，并且效果非常好。  经过几周的审阅论文，我意识到所谓的“形状重建”任务是在现实世界中进行的。实际上并不意味着“从潜在向量重建点云”，这正是我正在寻找的。相反，该术语似乎通常用于指“在给定 3D 点云的情况下重建表面”的任务。所以基本上，没有什么像我想要开发的。这种命名约定阻碍了我对类似自动编码器的点云重建方法的搜索。  -首先，我想请求一些关于类似自动编码器的点云重建的论文的推荐。我似乎找不到任何或几乎任何一个，因为我所有的搜索最终都在关于点云到表面“重建”的论文中。 ​  - 其次，以自动编码器的方式重建点云似乎不受欢迎是有原因的吗？我认为，既然对于图像来说，基于自动编码器的架构非常流行，那么 3D 形状也会很流行，但看起来并非如此。  ​ 就这样了:)谢谢。 ​ 奖金：&lt; /strong&gt; 如果有人熟悉几何深度学习和SO(3)等变网络，我还想问： ​ 我开发的点云重建自编码器使用 PointNet 作为编码器和 FC 网络作为解码器可以完美地重建例如形状网。然而，当我使我的 PointNet 网络 SO(3) 等变时（我使用矢量神经元https://arxiv.org/abs/ 2104.12229），然后我的重建突然变得非常糟糕。我已经检查了错误，并且我的网络确实已正确实现。为什么等变实际上使任务比使用常规的非等变 PointNet 编码器更困难？   由   提交 /u/howtorewriteaname   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwjus6/r_reconstructing_3d_point_clouds_in_an/</guid>
      <pubDate>Fri, 05 Apr 2024 14:45:33 GMT</pubDate>
    </item>
    <item>
      <title>[研究]通过简单的自适应攻击越狱领先的安全对齐法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwguzv/research_jailbreaking_leading_safetyaligned_llms/</link>
      <description><![CDATA[摘要：我们表明，即使是最新的安全相关法学硕士对于简单的自适应越狱攻击也不够鲁棒。首先，我们演示如何成功利用对 logprobs 的访问进行越狱：我们最初设计一个对抗性提示模板（有时适应目标 LLM），然后我们对后缀应用随机搜索以最大化目标 logprob（例如，令牌的 logprob） “当然”），可能需要多次重新启动。这样，我们在 GPT-3.5/4、Llama-2-Chat-7B/13B/70B、Gemma-7B 和 R2D2 上实现了接近 100% 的攻击成功率（以 GPT-4 为判断） HarmBench 针对 GCG 攻击进行了对抗性训练。我们还展示了如何通过传输或预填充攻击来越狱所有 Claude 模型（不暴露 logprobs），成功率达 100%。此外，我们还展示了如何在一组受限的标记上使用随机搜索来查找中毒模型中的木马字符串——这项任务与越狱有很多相似之处——正是这种算法为我们带来了 SaTML&#39;24 中的第一名木马检测竞赛。这些攻击背后的共同主题是适应性至关重要：不同的模型容易受到不同提示模板的影响（例如，R2D2 对上下文学习提示非常敏感），某些模型具有基于其 API 的独特漏洞（例如，Claude 的预填充） ），并且在某些设置中，根据先验知识限制令牌搜索空间至关重要（例如，对于木马检测）。我们在 https://github.com/tml-epfl/llm 提供攻击的代码、提示和日志-自适应攻击。   由   提交 /u/m_andriushchenko   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwguzv/research_jailbreaking_leading_safetyaligned_llms/</guid>
      <pubDate>Fri, 05 Apr 2024 12:32:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] Tensorboard/权重和偏差的替代方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwduod/d_alternatives_to_tensorboard_weights_and_biases/</link>
      <description><![CDATA[我一直在使用 Tensorboard 来跟踪我的深度学习项目中的损失曲线和几个指标的演变，但我放弃了它，因为它太有限了（特别是在同一个图上进行多次运行）。 我大约 6 个月前开始使用权重和偏差，但它实际上接近于一场噩梦：用户界面极其缓慢，许多错误，非- 直观且文档很少的Python库。我实际上因此浪费了几十个小时。 对于未来的项目，我想改用更好的解决方案。我听说过海王星，但我从未有机会尝试过。我想要一些专注于跟踪指标的东西，但速度快，没​​有漏洞，并且高度可定制。 对 Neptune 有什么意见吗？您还会推荐什么？    由   提交 /u/Skeylos2   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwduod/d_alternatives_to_tensorboard_weights_and_biases/</guid>
      <pubDate>Fri, 05 Apr 2024 09:35:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] KDD 2024 评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bwcact/d_kdd_2024_reviews/</link>
      <description><![CDATA[大家好， KDD 2024 论文评审可在 OpenReview 上查看。随着评论的发布，我创建了这个讨论线程，供我们收集想法、问题和建议或其他任何内容。祝您一切顺利！  更新： Paper Copilot 正在使用以下计算方式收集 KDD&#39;24 评级。您还可以通过此链接输入您的分数，请查看一下。 评分=0.5*平均新颖性。 + 0.5*平均技术质量   由   提交 /u/jeongwhanchoi   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bwcact/d_kdd_2024_reviews/</guid>
      <pubDate>Fri, 05 Apr 2024 07:46:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bmmra9/d_simple_questions_thread/</guid>
      <pubDate>Sun, 24 Mar 2024 15:00:20 GMT</pubDate>
    </item>
    </channel>
</rss>