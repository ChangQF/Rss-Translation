<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 27 Oct 2024 21:14:16 GMT</lastBuildDate>
    <item>
      <title>[D] 揭秘分布式检查点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gdkdka/d_demystifying_distributed_checkpointing/</link>
      <description><![CDATA[        提交人    /u/joygao   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gdkdka/d_demystifying_distributed_checkpointing/</guid>
      <pubDate>Sun, 27 Oct 2024 20:25:57 GMT</pubDate>
    </item>
    <item>
      <title>[R] 需要 Arxiv cs.AI 上的认可</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gdje64/r_need_endorsement_on_arxiv_csai/</link>
      <description><![CDATA[我是一名独立研究员，我的论文已经在 IEEE explorer 上发表，我希望将其上传到 arxiv，我需要 CS.AI 的认可&gt; 认可代码：PM3P4K https://arxiv.org/auth/endorse?x=PM3P4K    提交人    /u/benxben13   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gdje64/r_need_endorsement_on_arxiv_csai/</guid>
      <pubDate>Sun, 27 Oct 2024 19:42:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与 Leland McInnes 的最新访谈：UMAP、HDBSCAN 和数据几何 | 从机器学习中学习 #10</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gdimqa/d_new_interview_with_leland_mcinnes_umap_hdbscan/</link>
      <description><![CDATA[      本期《从机器学习中学习》与 Leland McInnes 一起探索纯数学与现代数据科学的交集，Leland McInnes 是无监督学习工具生态系统背后的思想者，包括 UMAP、HDBSCAN、PyNN Descent 和 DataMapPlot。作为 Tutte 数学和计算研究所的研究员，McInnes 从根本上改变了我们处理和理解复杂数据的方式。 抵制追逐炒作的冲动，寻求真正的理解并真正有所作为。    提交人    /u/NLPnerd   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gdimqa/d_new_interview_with_leland_mcinnes_umap_hdbscan/</guid>
      <pubDate>Sun, 27 Oct 2024 19:09:02 GMT</pubDate>
    </item>
    <item>
      <title>RAG - 当前研究的视觉分解！[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gdfny4/rags_a_visual_breakdown_of_current_research_d/</link>
      <description><![CDATA[      大家好！我制作了一个视频，介绍了 RAG 的主要组件以及研究人员/工程师用来构建强大的 LLM 管道的领先技术。希望你们喜欢！我     提交人    /u/AvvYaa   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gdfny4/rags_a_visual_breakdown_of_current_research_d/</guid>
      <pubDate>Sun, 27 Oct 2024 17:01:48 GMT</pubDate>
    </item>
    <item>
      <title>特征工程与交叉验证 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gdbgzt/cross_validation_with_feature_engineering_d/</link>
      <description><![CDATA[您可以使用交叉验证来通知特征的增加/减少吗？还是仅用于超参数调整？如果两者兼而有之，您通常会使用交叉验证来选择特征，然后冻结特征并再次运行交叉验证来调整超参数吗？试图了解结合两者的迭代过程会是什么样子。     提交人    /u/Secret_Valuable_Yes   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gdbgzt/cross_validation_with_feature_engineering_d/</guid>
      <pubDate>Sun, 27 Oct 2024 13:54:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 寻求有关提高以单一特征为主的 Instacart 购物篮分析模型的稳健性的建议。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd9q9f/d_seeking_advice_on_improving_robustness_of/</link>
      <description><![CDATA[大家好， 我正在 Kaggle 上开展 Instacart 购物篮分析项目，专注于预测重复购买。我设计了一个名为 num_of_ord_purch_p_prod 的功能，表示特定用户购买特定产品的次数。虽然此功能具有很高的预测性，但它在各个模型中都占据了功能重要性的主导地位，这引发了对潜在过度依赖和模型稳健性的担忧。有关更多详细信息，请参阅我的特征工程笔记本的链接：笔记本。 项目详细信息：  类别平衡：目标类别（重新排序状态）是平衡的。 评估方法：我在两个单独的测试集上测试了模型，每个测试集仅包含最新的订单，以进行更多基于时间的验证。 模型性能： 我的最佳 LightGBM 模型实现了 0.85 的 AUC，与第二佳特征相比，num_of_ord_purch_p_prod 的重要性提高了 1000 倍。 我的最佳 XGBoost模型实现了 0.72 的 AUC，与第二佳特征相比，同一特征的重要性提高了 20 倍。  特征重要性：SHAP 分析证实了 num_of_ord_purch_p_prod 的重要性，即使在应用正则化技术之后也是如此。在 XGBoost 中，正则化降低了其主导性，但也降低了 AUC。  使用中的功能：除了 num_of_ord_purch_p_prod 之外，我还包含了以下功能：  frequency_of_reorder（用户重新订购产品的频率） product_mean_of_position（用户订单中的平均产品位置） prob_of_being_reordered（基于过去购买的重新订购概率） count_ord_no_prev_purchased_items（每个订单中的新商品数量） 每周每天的产品订单分布数量等。  征求建议：鉴于单一特征占主导地位，我正在寻找建议，以增强模型的稳健性和泛化能力，同时降低 auc（&gt; 0.80）。    提交人    /u/ds_reddit1   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd9q9f/d_seeking_advice_on_improving_robustness_of/</guid>
      <pubDate>Sun, 27 Oct 2024 12:21:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医学 AI：顶级 LLM 研究论文/模型（10 月 19 日至 10 月 26 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd6k6j/d_last_week_in_medical_ai_top_llm_research/</link>
      <description><![CDATA[      医学 AI 上周：顶级 LLM 研究论文/模型（10 月 19 日至 10 月 26 日） 本周医学 AI 论文：  谷歌使用生成式 AI 进行医学摘要的安全原则  本文讨论了在医疗保健领域应用大型语言模型 (LLM) 的潜力和挑战，重点关注生成式 AI 支持各种工作流程的前景。医学 LLM 和其他模型：   医学法学硕士及其他模型：  BioMistral-NLU：医学词汇理解  本文介绍了 BioMistral-NLU，这是一种可通用的医学 NLU 模型，在 MNLU-Instruct 数据集上进行了微调，以提高专门医学任务的性能。 BioMistral-NLU 在来自 BLUE 和 BLURB 基准的六个 NLU 任务的零样本评估中优于现有的 LLM，如 ChatGPT 和 GPT-4。  用于生物医学任务的双语多模态 LLM  本文介绍了 MedRegA，这是一种新型的区域感知医学多模态大型语言模型 (MLLM)，该模型在名为 MedRegInstruct 的大规模数据集上进行训练。  用于临床分析的代谢增强 LLM  本文介绍了代谢途径驱动的提示 (MPP)，通过将代谢途径的领域知识整合到 LLM 中来增强临床时间序列数据中的异常检测。  皮肤病学基础模型  本文介绍了 PanDerm，这是一种多模态皮肤病学基础模型，在 11 家临床机构和 4 家影像模式。   框架和方法：  回到过去：医学 Deepfake 检测 用于水晶设计的混合 GenAI VISAGE：用于手术的视频合成 MoRE：多模态 X 射线/ECG 预训练 SleepCoT：通过 CoT 实现个性化健康  医学 LLM 应用：  ONCOPILOT：肿瘤 CT 模型 LMLPA：语言人格评估 用于医学培训的 GenAI  医学 LLM 和基准：  通过解释进行 LLM 评估 医学 LLM 幻觉的对比解码  医疗伦理中的人工智能：  通过讲故事进行医疗保健 XAI 临床 LLM 偏见分析 ReflecTool：反射感知临床代理  ... 完整线程详细信息：https://x.com/OpenlifesciAI/status/1850202986053808441    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd6k6j/d_last_week_in_medical_ai_top_llm_research/</guid>
      <pubDate>Sun, 27 Oct 2024 08:41:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 有人有 wikitext-2-v1.zip 数据集文件或其他链接可以下载吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd36p9/r_does_anyone_have_wikitext2v1zip_dataset_file_or/</link>
      <description><![CDATA[大家好， 我正在尝试重现一个使用 wikitext-2 数据集的旧实验，并且它依赖于 torchtext 来导入它。但是，下载数据集的链接似乎不再有效。以下是损坏的链接： https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip 以下是相关的 torchtext 源代码，供参考： https://pytorch.org/text/0.12.0/_modules/torchtext/datasets/wikitext2.html 有人知道更新的链接或获取此数据集的解决方法吗？谢谢！    提交人    /u/reddo-lumen   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd36p9/r_does_anyone_have_wikitext2v1zip_dataset_file_or/</guid>
      <pubDate>Sun, 27 Oct 2024 04:35:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 27 Oct 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 交叉验证后在完整数据集上进行训练？语义分割</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gct22r/d_train_on_full_dataset_after_crossvalidation/</link>
      <description><![CDATA[我目前正在进行燕麦叶病症状的语义分割项目。数据集很小，只有 16 张图像。由于时间限制，我无法扩展它。 我目前正在训练 3 个模型、3 个主干和 3 个损失 - 使用 5 倍交叉验证和网格搜索。 完成后，我计划对每个图像的几个不同级别的增强进行交叉验证。 我的问题是： 一旦我确定了最佳模型、主干、损失和增强组合，我可以在如此小的整个数据集上进行训练吗？如果我能做到这一点，我怎么知道何时停止训练以防止过度拟合但仍然充分学习数据？ 到目前为止，我附上了一些结果的图片。 https://preview.redd.it/sx394c58l5xd1.png?width=2000&amp;format=png&amp;auto=webp&amp;s=3cefbf5c84bf3fbf48936c47810c4e3039dcb410 感谢您提供的任何帮助提供！    由   提交  /u/Entire_Commission169   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gct22r/d_train_on_full_dataset_after_crossvalidation/</guid>
      <pubDate>Sat, 26 Oct 2024 19:38:09 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用神经网络进行形状限制回归</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gcpl03/p_shaperestricted_regression_with_neural_networks/</link>
      <description><![CDATA[前段时间在工作中，我们必须强制我们的模型学习一个特征的递增函数。例如，作为出价函数的中标概率应该增加。最近，我偶然发现了一篇关于使用形状限制函数进行回归的论文 https://arxiv.org/abs/2209.04476，我想通过实际的代码来训练这样的模型，让它更具体一些。 因此，我写了一篇博文：https://alexshtf.github.io/2024/10/14/Shape-Restricted-Models.html 还有一个带有随附代码的笔记本：https://github.com/alexshtf/alexshtf.github.io/blob/master/assets/shape_constrained_models.ipynb 我以前经常做广告。所以这种模型在这个行业似乎很有用——根据出价预测赢得广告拍卖的概率。我希望它在其他地方也有用。 所以我希望你会喜欢它！这是一个很大的“数学”，但你知道，它不可能是别的。    提交人    /u/alexsht1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gcpl03/p_shaperestricted_regression_with_neural_networks/</guid>
      <pubDate>Sat, 26 Oct 2024 16:58:41 GMT</pubDate>
    </item>
    <item>
      <title>[P] 任何设备上的实时角色动画</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gco234/p_realtime_character_animation_on_any_device/</link>
      <description><![CDATA[      我最近看到了阿里巴巴的这篇论文MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling，真的很有趣。浏览完论文后，我想，“嘿，可以使用一些开源工具复制这个工作流程！”我设法创建了一个可行的系统，该系统可以在设备上以 ~10fps 的速度实时运行，请注意，这是在一台配备 8 GB RAM 和 4 GB VRAM 的土豆笔记本电脑上运行的。 原始视频 重建视频 当前工作流程如下所示 -&gt; 1. 我使用 Tracking4All 创建了一个 Unity 应用程序，它可以从网络摄像头获取输入并使用 Mediapipe 生成动画姿势。 2. 接下来，我将这些生成的图像发送到 Python 服务器，该服务器接收原始帧、动画角色以及来自 Mediapipe 姿势的人物面具。 3. 最终使用 MI-GAN，我能够实时移除人物。 这个项目目前存在一些缺陷 1. MI-GAN 模型虽然速度很快，但却是主要的瓶颈。我尝试了 OpenCV 中提供的其他算法，但它们更糟糕、更慢（~1fps）。 2. 角色大小调整并不总是准确的，尽管可以在 Unity 中轻松调整。 3. 遮挡问题仍然是一个挑战。 此外，值得注意的是，Tracking4All 软件包需要许可证，这可能会限制可访问性。 是否有任何算法可以在各种设备（移动设备、Windows、Mac 和 Linux）上实时执行修复？ 该项目的目标是创建任何人都可以在任何设备上运行的端到端工作流程。这在 AR 和 VFX 中有许多应用程序！您对此有何看法？我接下来应该实现什么？   由    /u/Jazzlike-Shake4595  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gco234/p_realtime_character_animation_on_any_device/</guid>
      <pubDate>Sat, 26 Oct 2024 15:49:38 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人知道 Eleven 实验室是如何设计提示音的吗？我想根据提示音生成新的声音，而不是声音克隆。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gcej8u/d_do_anyone_know_how_eleven_labs_is_designing_the/</link>
      <description><![CDATA[        由    /u/usama__01 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gcej8u/d_do_anyone_know_how_eleven_labs_is_designing_the/</guid>
      <pubDate>Sat, 26 Oct 2024 06:02:26 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 开源视频索引/标签/标签生成工具。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gccyhp/project_open_source_video_indexinglabellingtag/</link>
      <description><![CDATA[伙计们，我正在寻找一个开源工具或任何可以帮助我生成视频标签的 repo，以便对多个视频进行分类并进行进一步分析。 我想要的等价物是 Azure AI clvideo inxer，但如果有这样的开源工具，它将解决问题。    提交人    /u/jokingwizard   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gccyhp/project_open_source_video_indexinglabellingtag/</guid>
      <pubDate>Sat, 26 Oct 2024 04:18:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>