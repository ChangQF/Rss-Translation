<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Wed, 10 Jul 2024 15:18:03 GMT</lastBuildDate>
    <item>
      <title>[D] 如何调试深度学习模型的大规模训练？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dzxq9z/d_how_to_debug_large_scale_training_of_deep/</link>
      <description><![CDATA[大家好， 我目前在调试深度学习模型的大规模训练时面临挑战。在本地工作时，我可以通过缩小模型并使用小批量大小轻松添加断点和调试。但是，当模型太大而无法在本地 GPU 上容纳时，我不确定该怎么做。 是否有人有关于如何添加断点或调试在分布式系统或云平台上训练的大规模模型的经验或技巧？ 任何对您有用的工具、技术或工作流程的见解都将不胜感激！ 提前致谢！    提交人    /u/Daedelus123   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dzxq9z/d_how_to_debug_large_scale_training_of_deep/</guid>
      <pubDate>Wed, 10 Jul 2024 14:52:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我正在尝试使用 LLM 生成程序材料</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dzvdvw/p_im_trying_to_generate_procedural_material_with/</link>
      <description><![CDATA[      我正在尝试微调 Llama 3 8b 以生成像图中这样的搅拌机节点树，我有 2.5k 个训练示例。问题是，训练结果不佳后，它会错误地获取节点的索引，并且不知道在哪里完成代码。有没有更好的方法来实现我的目标？谢谢  我使用了 unsloth 最大序列长度为 12.800  https://preview.redd.it/401dv33nxobd1.png?width=1905&amp;format=png&amp;auto=webp&amp;s=c05d5d858d6309f6570e046f4fda50f8796fe617   由    /u/kulokaq  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dzvdvw/p_im_trying_to_generate_procedural_material_with/</guid>
      <pubDate>Wed, 10 Jul 2024 13:09:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深度学习算法 AlphaFord 2 是否“在很大程度上解决了蛋白质折叠问题”并且是否有可能在不需要 ML/bio 背景的情况下真正理解这一点？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dzupoz/d_did_the_deep_learning_algorithm_alphaford_2/</link>
      <description><![CDATA[大家觉得如何？你们需要什么，比如需要具备哪些先决条件才能真正理解这一点，就像如果不理解黑体辐射、光电效应、杨氏双缝实验、线性代数、理解物理实验、数学形式主义等，就无法真正理解量子理论一样……    提交人    /u/ICEpenguin7878   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dzupoz/d_did_the_deep_learning_algorithm_alphaford_2/</guid>
      <pubDate>Wed, 10 Jul 2024 12:37:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 实时 AI 工作者 Web 应用程序</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dzryk9/p_real_time_ai_workers_web_application/</link>
      <description><![CDATA[大家好！ 我创建了一个关于如何使用 Django、LangChain 和 Celery 构建实时 AI 应用程序的迷你系列。 免费知识 - 将其发布在这里，供任何从事类似工作并在构建时遇到与我相同阻碍的人使用。 让我知道你对我如何改进这个架构的看法。 第 1 部分 https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-601dff7ada79 第 2 部分 https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-5828a1ea43a3 第 3 部分 https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-5828a1ea43a3 第 4 部分 https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-8e73c7b6b4c8    提交人    /u/stoic-AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dzryk9/p_real_time_ai_workers_web_application/</guid>
      <pubDate>Wed, 10 Jul 2024 10:00:49 GMT</pubDate>
    </item>
    <item>
      <title>照相排版提交中主要内容和补充内容之间的交叉引用 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dzqzo1/cross_referencing_between_main_and_supplement_in/</link>
      <description><![CDATA[嗨， 我想向 ECCV 提交照相排版 PDF，但我使用 xr 包和以下代码生成了主文档和补充文档之间的一些交叉引用。它当然可以在背面使用，但我不确定当会议人员稍后编译代码时这是否会起作用。我需要手动放置交叉引用吗？或者这是正确的方法？谢谢  \makeatletter \newcommand*{\addFileDependency}[1]{% 参数 = 文件名和扩展名 \typeout{(#1)}% 如果 $recorder=0，latexmk 将会找到它 \@addtofilelist{#1 \IfFileExists{#1}{}{\typeout{没有文件 #1.}&gt; }\makeatother \newcommand*{\myexternaldocument}[1]{% \externaldocument{#1}% \addFileDependency{#1.tex}% \addFileDependency{#1.aux}% &gt; \myexternaldocument{supplement&gt;     由   提交  /u/dn8034   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dzqzo1/cross_referencing_between_main_and_supplement_in/</guid>
      <pubDate>Wed, 10 Jul 2024 08:54:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] Text-2-SQL 模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dzqigk/d_text2sql_models/</link>
      <description><![CDATA[我一直对检查可能用作 RAG 系统一部分的 Text-2-SQL 模型感兴趣。我在社区中寻找一个运行良好的模型，但只找到了表现不错的 LLM。 想知道是否有人尝试使用 Phi-3-Mini 或任何 T5 或 Flan 模型（T5、Flan-T5、Flan-Ul2）训练 Text-2-SQL 模型，以及结果如何。 我的目标是小而快，这就是为什么我不想部署任何大型 LLM，如果可行，我个人会把它当作对自己的挑战。    提交人    /u/cedar_mountain_sea28   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dzqigk/d_text2sql_models/</guid>
      <pubDate>Wed, 10 Jul 2024 08:21:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] RoBERTa 从头开始​​！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dzllu1/d_roberta_from_scratch/</link>
      <description><![CDATA[在看到 Karpathy 的从头开始的 GPT 模型和 u/atronos_kronios 的 Llama 3 模型后，我开始为多类分类创建自己的 RoBERTa“从头开始”实现。实际上，我没有训练初始权重或实现注意层。相反，我创建了代码来处理那些给定的权重。 在我的 Github 存储库中，我包含了一个用于实现的文件和一个用于“从头开始”的标记器文件（我没有足够的资源来完全训练标记器以达到 RoBERTa 标准）。 某些代码可能是不必要的，但这就是我已经完成的工作。 这是存储库 - 谢谢：https://github.com/nhemauer/Projects/tree/main/RoBERTa%20from%20Scratch 这让我学到了很多关于 NLP 的知识，我建议有类似兴趣的人也从头开始查看 Llama 3：https://www.reddit.com/r/MachineLearning/comments/1djyilm/p_llama_3_language_model_implementation_from/    由   提交  /u/nhemauer   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dzllu1/d_roberta_from_scratch/</guid>
      <pubDate>Wed, 10 Jul 2024 03:17:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有人收到ACL 2024学生志愿者的录取通知了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dzj1ga/d_did_anyone_get_the_acceptance_notification_from/</link>
      <description><![CDATA[大家好， 我查了一下，录取通知日期是 7 月 8 日，UTC-12。 但是到现在我还没有收到任何通知。 由于演讲者必须在 12 日之前注册参加会议，所以我很担心通知的延迟。 有人收到了录取或拒绝通知吗？ 如果你的情况和我一样，请评论一下。这应该会对我有帮助 XD    提交人    /u/ImpossibleAd568   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dzj1ga/d_did_anyone_get_the_acceptance_notification_from/</guid>
      <pubDate>Wed, 10 Jul 2024 01:07:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] Lambda 堆栈不再能开箱即用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dzffp8/d_lambda_stack_no_longer_working_out_of_the_box/</link>
      <description><![CDATA[      还有其他人遇到 lambda 堆栈问题吗？在 Ubuntu 22.04 的新版本上，我安装了 lambda 堆栈以在 GPU 上启动并运行 ML。然后当我去测试它时，它失败了。 Pytorch 和 TF 无法看到或使用 GPU。看起来 CUDA 版本可能与 ML 库不同步？ 任何建议或替代方案都很好。我在他们的社区帮助页面上重复了这个问题，但目前没有回复。我很怀念当它开箱即用时，用一行代码设置这一切真是太棒了。  https://preview.redd.it/l06uig7ljkbd1.jpg?width=1198&amp;format=pjpg&amp;auto=webp&amp;s=97e642510a0bd41d96d2c4549010fdfd1529aeaf    提交人    /u/Heavy_Carpenter3824   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dzffp8/d_lambda_stack_no_longer_working_out_of_the_box/</guid>
      <pubDate>Tue, 09 Jul 2024 22:23:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用角色扩展合成数据创建</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dzergu/r_scaling_synthetic_data_creation_with_personas/</link>
      <description><![CDATA[https://arxiv.org/abs/2406.20094  我们提出了一种新颖的人物驱动数据合成方法，该方法利用大型语言模型 (LLM) 中的各种视角来创建多样化的合成数据。为了充分利用这种方法，我们引入了 Persona Hub——一个由 10 亿个从网络数据中自动整理出来的不同人物组成的集合。这 10 亿人物（约占世界总人口的 13%）作为世界知识的分布式载体，可以利用 LLM 中封装的几乎所有视角，从而促进为各种场景大规模创建多样化的合成数据。通过展示 Persona Hub 在大规模合成高质量数学和逻辑推理问题、指令（即用户提示）、知识丰富的文本、游戏 NPC 和工具（功能）方面的用例，我们证明了角色驱动的数据合成是多功能、可扩展、灵活且易于使用的，有可能推动合成数据创建和实践应用的范式转变，这可能会对 LLM 的研究和开发产生深远的影响。     提交人    /u/20231027   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dzergu/r_scaling_synthetic_data_creation_with_personas/</guid>
      <pubDate>Tue, 09 Jul 2024 21:56:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人工智能研究初创企业职位空缺 - 寻求见解和指导</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dzc5qv/d_ai_research_startup_openings_seeking_insights/</link>
      <description><![CDATA[我想（未来某个时候）为这家 AI 研究初创公司工作，该公司在大多数招聘信息中都列出了代表性项目。虽然我符合他们许多职位的最低和优先资格要求，但我对所提到的具体项目的经验非常有限。我有 5 年构建面向客户的 ML 应用程序的经验，刚刚获得计算机科学硕士学位（ML 专业）。  如果您是从事以下任何项目的工程师/研究人员，我将非常感激您对如何开始（以下提到的任何项目）的指导。我正在寻求指导和辅导。 如果您在这家初创公司工作（希望你们都知道这是哪家主流初创公司），我很想听听您在招聘信息中列出的代表性项目中的经验。从事这些项目是否有助于您获得这份工作，或者您没有特定的经验也能被录用？ 如果您的情况类似，并且对人工智能充满热情，也致力于此，那么让我们合作完成其中一个项目。我目前失业了 :) 如果您不从事这些工作，而是从事技术工作，请告诉我您对这些代表性项目的感受。所有见解都很有价值，欢迎大家提出！  部分职位及其各自的代表性项目如下： 角色：推理软件工程师 代表性项目：  改进推理请求路由到模型服务器的方式，以最大程度提高计算效率 构建性能模型，以预测未来架构和硬件改进的影响 为新的模型架构实施推理 分析可观测性数据，以根据生产工作负载调整性能 在新的硬件平台上实施推理 构建仪器以检测和消除 Python GIL 争用 优化 GPU 内核的效率 准备部署推理引擎  角色：可解释性软件工程师 代表性项目：  构建 Garcon，该工具允许研究人员从 jupyter 笔记本轻松访问 LLM 内部 设置和优化管道，以有效收集 PB 级的 transformer 激活并对其进行混洗。 分析和优化 ML 训练，包括并行化到许多 GPU 快速轻松地启动 ML 实验并操纵+分析结果 在语言模型中的 token 之间创建注意力的交互式可视化  角色：研究工程师，元提示 代表性项目：  为由语言模型支持的生产应用程序构建提示和模型编排 在使用特定提示技术时，对 Claude 进行微调以最大化其性能。 构建和测试自动提示优化器或自动 LLM 驱动的评估系统，以判断提示在任务上的表现。 为语言模型实现新颖的检索、工具使用、子代理或内存架构。 构建由基于模型的评估技术驱动的缩放模型评估框架。     提交人    /u/June_76   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dzc5qv/d_ai_research_startup_openings_seeking_insights/</guid>
      <pubDate>Tue, 09 Jul 2024 20:09:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 推理时间梯度</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dz3vka/d_inferencetime_gradients/</link>
      <description><![CDATA[我认为标题中最成功的应用是扩散模型。它们不是试图直接重建图像，而是预测特定时间步（或时间）的分数/噪声/梯度，以逆转扩散过程并更接近原始数据分布。特别酷的想法是整流用于稳定扩散 3。 更多示例涉及：  神经 ODE - 网络用作 ODE 求解器的梯度源 学习（在测试时学习） - 在推理过程中计算梯度以演变隐藏状态 液体时间常数网络 - 类似于神经微分方程，但更受追捧  我发现“推理时间梯度”范式很酷的一点是，模型不必一次性输出解决方案。因此，它不再是直接解决任务 - NN 更多地用作获得解决方案的指南。在某些情况下，我们还可以根据对准确性/质量的关注程度选择更快或更慢地获得解决方案。 我不知道接下来该怎么做，但我想知道这种方法如何用于语言建模，我们也许可以在推理过程中投入更多计算以获得更好的预测。网络不应该直接输出概率分布，而应该输出“提示”/“梯度”，这将帮助我们获得比类似大小的“正常”语言模型更好的解决方案。   由    /u/kiockete  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dz3vka/d_inferencetime_gradients/</guid>
      <pubDate>Tue, 09 Jul 2024 14:31:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 具有多个依赖时间序列的 LSTM 架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dz3ll1/d_architecture_of_an_lstm_with_multiple_dependent/</link>
      <description><![CDATA[大家好，我需要一些关于如何处理涉及多个时间序列数据的问题的建议。 如果对于给定的问题，您有多个时间序列数据（例如，预测房价，并且每个城市都有数据）。每个城市都有一个特征列表和目标特征。如果您想一起训练一个包含所有城市的 LSTM，您将如何处理？ 我正在考虑使用无状态 LSTM 架构，在该架构中，我以这样一种方式组织我的输入，即每个批次代表一个城市的时间序列。如果这种方法可行，我还需要考虑更多的事情吗？关于制作与其他城市距离的附加特征怎么样，您对此有什么看法？ 提前感谢您的帮助！    提交人    /u/XDV_6   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dz3ll1/d_architecture_of_an_lstm_with_multiple_dependent/</guid>
      <pubDate>Tue, 09 Jul 2024 14:19:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 还有其他人对语言模型的非结构化输出有疑问吗？😩</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dyxiw4/d_is_anyone_else_having_trouble_with_the/</link>
      <description><![CDATA[我找到了一种修复此问题的方法，并在本文中用代码编写了该过程，但如果有人知道更好的方法，我很想知道！ 基本上使用 Pydantic 输出解析器将混乱的 LLM 响应转换为干净、结构化的数据，这些数据易于在我们的应用程序中使用。该过程是构建一个模型，该模型从表格数据集中建议数据可视化图表，组织输出，并使其准备好方便 API 调用和前端使用。    提交人    /u/stoicwolfie   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dyxiw4/d_is_anyone_else_having_trouble_with_the/</guid>
      <pubDate>Tue, 09 Jul 2024 08:46:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dx5tpo/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dx5tpo/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 07 Jul 2024 02:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>