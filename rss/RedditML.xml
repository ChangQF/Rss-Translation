<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 03 Oct 2024 21:15:33 GMT</lastBuildDate>
    <item>
      <title>[项目] 为特殊图集寻找合适的神经网络和算法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvh4w9/project_finding_suitable_neural_networks_and/</link>
      <description><![CDATA[我正在处理许多大型图，其中节点是共享的，但边集不同。具体来说，这些图描述了不同条件下同一组实体之间的不同关系。 目前的挑战是这些图非常大。节点集大小约为 60k，边集大小从 10k 到 30k 不等，大约有 100k 个图。我想知道是否有任何算法可以有效地在这样的图上执行链接预测任务？我尝试了 GraphSAGE\GIN\GCN\GAT，但它们都需要大量的计算资源，并且没有利用 Graph 的特性:(    提交人    /u/Head_Brilliant_367   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvh4w9/project_finding_suitable_neural_networks_and/</guid>
      <pubDate>Thu, 03 Oct 2024 20:16:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 宣布推出首批 Liquid Foundation 模型 (LFM) - 新一代生成式 AI 模型，可在各个规模上实现最先进的性能，同时保持更小的内存占用和更高效的推理。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvgo7o/r_announcing_the_first_series_of_liquid/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvgo7o/r_announcing_the_first_series_of_liquid/</guid>
      <pubDate>Thu, 03 Oct 2024 19:57:00 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我们所需要的只是 RNN 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvg7qr/r_were_rnns_all_we_needed/</link>
      <description><![CDATA[https://arxiv.org/abs/2410.01201 作者（包括 Y. Bengio）提出了 LSTM 和 GRU 的简化版本，允许并行训练，并在一​​些基准测试中显示出强劲的结果。    提交人    /u/we_are_mammals   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvg7qr/r_were_rnns_all_we_needed/</guid>
      <pubDate>Thu, 03 Oct 2024 19:37:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] 理解语义的电影基因组特征的嵌入</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvfy7h/r_embeddings_for_movie_genome_features_that/</link>
      <description><![CDATA[我正在创建一个远远超越单纯类型的电影基因组。基线数据如下：  子类型：心理惊悚片、哲学剧 情绪：紧张、黑暗、悬念、神秘、强烈 主题：复仇的代价、身份危机、权力腐败 情节：卧底行动、队伍内部背叛、猫捉老鼠、心理操纵、揭露腐败、被错误指控的主角、双重间谍、道德困境、发现隐藏的身份、救赎弧 文化影响：标志性口号、影响流派、在其他媒体中模仿 角色类型：反英雄、主谋、忠诚的伙伴 对话风格：诙谐的玩笑、激烈的独白 叙事结构：非线性叙事、多视角、倒叙 节奏：快节奏、营造紧张感 时间：现在、遥远的未来 地点：城市景观、地下藏身处 电影风格：深色调色板、高对比度照明、手持摄像机、斯坦尼康镜头 配乐和声音设计：电子音乐、环境声音 服装和布景设计：现代服装、粗犷的城市布景 关键道具：机密文件、隐藏武器、象征性项链 目标受众：成人 标志：暴力画面、粗俗语言  对于每个特征，我都创建一个嵌入向量。我的期望是向量的距离基于对语义的理解。  我目前使用的模型是 jinaai/jina-embeddings-v2-small-en，但遗憾的是结果质量参差不齐。 例如，它为 深色调色板 和 鲜艳调色板 生成非常相似的向量，尽管它们完全相反。  有什么想法吗？    由    /u/alp82 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvfy7h/r_embeddings_for_movie_genome_features_that/</guid>
      <pubDate>Thu, 03 Oct 2024 19:25:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] ubuntu 24.04 中的 nerfstudio，有人成功使用了吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvc758/d_nerfstudio_in_ubuntu_2404_did_anyone_get_it_off/</link>
      <description><![CDATA[升级到 24.04 时出错了。nvidia 端全部启动并运行，但 nerfstudio 在 pip 安装时失败。查看了 docker 和 pixi，但两者似乎都有自己的问题。在我进一步弄乱我的系统之前。有人在 24.04 上正确运行了吗？如果是这样，怎么做的？    提交人    /u/bernieskijump   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvc758/d_nerfstudio_in_ubuntu_2404_did_anyone_get_it_off/</guid>
      <pubDate>Thu, 03 Oct 2024 16:46:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哪些论文描述了 LLM 中的 MOE 技术？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fvaiq1/d_which_papers_describe_techniques_for_moe_in_llms/</link>
      <description><![CDATA[我对学习法学硕士 (LLM) 中的 MOE 行业技巧很感兴趣。下面列出了我知道的一些要看的论文，但如果有任何其他建议，我将不胜感激。 TIA。 https://arxiv.org/abs/1701.06538 - 超大型神经网络：稀疏门控混合专家层 https://arxiv.org/abs/2401.04088 - 专家混合 https://arxiv.org/abs/2409.02060 - OLMoE：开放混合专家语言模型 https://arxiv.org/abs/2407.06204 - 关于专家混合的调查     提交人    /u/a1_jakesauce_   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fvaiq1/d_which_papers_describe_techniques_for_moe_in_llms/</guid>
      <pubDate>Thu, 03 Oct 2024 15:30:09 GMT</pubDate>
    </item>
    <item>
      <title>图表征学习 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fv8cnc/graph_representation_learning_p/</link>
      <description><![CDATA[我们开发了一个图形表示学习模型，可以预测静态知识图中节点之间的链接。您将如何修改此模型以纳入数据的时间成分？可能会出现哪些特定的工程挑战？    提交人    /u/Accomplished_Lake982   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fv8cnc/graph_representation_learning_p/</guid>
      <pubDate>Thu, 03 Oct 2024 13:56:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您对机器学习中的（高质量）内容创作有何看法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fv8429/d_what_are_your_thoughts_on_quality_content/</link>
      <description><![CDATA[我意识到，要成长为 MLE/数据科学家，甚至成为整体 IT 专业人士，成为拥有丰富经验和知识的最佳技术人员不会增加您的价值。有很多人进入了内容创作领域，例如 YouTube/X/podcasts/instagram 等。它似乎双向起作用，通过建立受众并向作者阐明主题。同样，一个人在进入内容创作领域之前可能是一个知名人物，比如 Andrej Karpathy，或者从头开始添加有价值的内容的人。所以我要说的是，考虑到一个人准备好耐心等待病毒式传播的门槛，内容创作似乎是职业加速的必需品。这里是对我来说最重要的一点，那就是创造力。让它变得有趣很容易引起注意。  这个问题已经萦绕在我脑海里有一段时间了，很想知道你的想法。原谅任何语法错误。谢谢🫂   由    /u/Particular_Tap_4002  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fv8429/d_what_are_your_thoughts_on_quality_content/</guid>
      <pubDate>Thu, 03 Oct 2024 13:45:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 2024 年生产 ML 状态：36% 需要 1-3 个月部署模型，<50% 没有监控，10% 使用电子表格进行实验跟踪（初步结果）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fv65qa/d_the_state_of_production_ml_2024_36_take_13/</link>
      <description><![CDATA[分享 2024 年生产 ML 状况调查的一些有趣 (初步) 结果：  部署 ML：36% 需要 1-3 个月，21% 需要 3-6 个月 实验跟踪：42% 使用 MLFlow，10% 使用电子表格 特征存储：53% 未使用，28% 定制 向量 DB：55&amp; 未使用，其余未合并 训练：27&amp;使用定制，21% 使用 Databricks 服务：56% 使用定制（+ FastAPI/Flask） 监控：50% 未使用，24% 使用定制 多样性：只有 4% 的人认为自己是女性  这是一项社区倡议，这些数据将为社区中的所有人提供可行的见解，以改善生态系统。我们的目标是，这些意见将有助于全面概述常见做法、工具偏好以及将模型部署到生产中面临的挑战，最终使整个 ML 社区受益 🚀 我们将在 10 月底之前开放这项调查，我们将公布结果，以便社区获得有用的见解！如果您可以花两分钟分享您的经验：https://bit.ly/state-of-ml-2024 您还可以在此处查看初步结果：https://ethical.institute/state-of-ml-2024 - 我们正在构建一个用于基本切片和切块的界面，以便提取进一步的见解（但仍处于早期 WIP 阶段，因此欢迎提供反馈）。    提交人    /u/axsauze   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fv65qa/d_the_state_of_production_ml_2024_36_take_13/</guid>
      <pubDate>Thu, 03 Oct 2024 12:09:24 GMT</pubDate>
    </item>
    <item>
      <title>[P] 更大、更易于指导的语言模型变得不那么可靠</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fv4hxo/p_larger_and_more_instructable_language_models/</link>
      <description><![CDATA[      《自然》杂志上的一篇非常有趣的论文，后面是其中一位作者对 X 的摘要。 结论基本上是使用更多的计算资源和人类反馈训练的大型模型在几个方面对人类的可靠性会降低，例如，模型可以解决非常困难的任务，但在同一领域中无法解决许多简单的任务，并且这种不一致对于较新的模型来说变得越来越严重（基本上即使是简单的任务也无法实现无错误，而且人类越来越难以预测模型失败？）。论文还表明，较新的 LLM 现在更少地回避任务，从而导致更多错误/幻觉输出（这颇具讽刺意味：所以 LLM 变得更加正确，但同时也变得更加不正确）...... 我很好奇，他们表明快速工程可能不会通过简单地扩大模型规模而消失，因为较新的模型只是在逐步改进，而人类不善于发现输出错误以抵消不可靠性。GPT、LLAMA 和 BLOOM 系列的 32 个 LLM 的结果似乎一致，并且在 X-thread 中，他们还表明不可靠性仍然存在于其他非常新的模型中，如 o1-preview、o1-mini、LLaMA-3.1-405B 和 Claude-3.5-Sonnet。这里有很多东西需要解开。但有趣的是，这项工作在某些方面挑战了当前的扩展范式（以及LLM的一些其他设计实践），值得关注。 https://preview.redd.it/hpd7yynaqisd1.png?width=1888&amp;format=png&amp;auto=webp&amp;s=ebc7953700935ee85cafd2f5d3602b80418d4523    submitted by    /u/Appropriate_Annual73   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fv4hxo/p_larger_and_more_instructable_language_models/</guid>
      <pubDate>Thu, 03 Oct 2024 10:26:40 GMT</pubDate>
    </item>
    <item>
      <title>[P] Paper Central，第一个将所有关键来源集中在一个地方的门户网站，包括 arXiv、Hugging Face 论文页面、GitHub 和会议记录。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fuy2qk/p_paper_central_first_portal_to_bring_together/</link>
      <description><![CDATA[Hugging Face 今天推出了 Paper Central，提供有关最新研究论文的最及时信息。 应用程序：https://huggingface.co/spaces/huggingface/paper-central 帖子：https://x.com/IAMJBDEL/status/1841627341195510256    提交人    /u/Illustrious_Row_9971   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fuy2qk/p_paper_central_first_portal_to_bring_together/</guid>
      <pubDate>Thu, 03 Oct 2024 02:54:08 GMT</pubDate>
    </item>
    <item>
      <title>[P] 即时实现：在运行时实现代码的 Python 库</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fujbuz/p_justintime_implementation_a_python_library_that/</link>
      <description><![CDATA[嘿 r/MachineLearning ！ 你知道我们是如何进行即时编译的吗？好吧，我想，“为什么要停在那里？”所以我创建了即时实现 - 一个使用 AI 为您编写代码的 Python 库。是的，真的！ 以下是它可以做的事情： 从 jit_implementation 导入实现 @implement class Snake：“pygame 中的贪吃蛇游戏。初始化将启动游戏。”“” if __name__ == “__main__”: Snake() # 信不信由你，这确实有效！  我一开始只是开个玩笑，但后来我有点得意忘形，真的让它工作了。现在我不知道我应该感到骄傲还是害怕。 工作原理：  您编写一个函数或类签名和一个文档字符串。 您将 @implement 装饰器贴在上面。 当您调用函数或实例化类时，将按需生成实现。最好的懒惰编码！  一些“功能”让我特别感兴趣：  它是终极懒惰编程工具。代码在您运行之前甚至不存在！ 您可以在装饰器中定义测试，AI 会不断尝试，直到通过测试。这就像有一个永不睡觉的实习生！ 将采样温度设置为 0，它比 Docker 镜像更具可重复性。 足够聪明，可以浏览代码以了解上下文，但又不会愚蠢到读完所有内容。  您应该在生产中使用它吗？ 只有当您想让您的高级开发人员心脏病发作时才使用。但是，嘿，我不是来评判的。 想看看吗？ 这是 GitHub 存储库：JIT 实现 请随意加星标、分叉，或者只是指出并大笑。所有反应都是有效的！ 我很想听听你的想法。这是编程的未来还是我需要休长假的迹象？也许两者都有？ 附言：如果你们当中有人真的用过这个，请告诉我。我真的很想知道用这个可以制作出多么复杂的代码库（或者缺乏代码库）。 重要说明 我只用了不到 4 个小时就完成了整个过程，所以请保持你的期望！（它处于测试阶段）    提交人    /u/JirkaKlimes   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fujbuz/p_justintime_implementation_a_python_library_that/</guid>
      <pubDate>Wed, 02 Oct 2024 15:44:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] 学术不端行为调查 ICLR 2024 焦点：自适应理性激活以促进深度强化学习。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fuf5b2/r_academic_misconduct_investigation_into_iclr/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fuf5b2/r_academic_misconduct_investigation_into_iclr/</guid>
      <pubDate>Wed, 02 Oct 2024 12:37:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1fru46i/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 29 Sep 2024 02:15:10 GMT</pubDate>
    </item>
    </channel>
</rss>