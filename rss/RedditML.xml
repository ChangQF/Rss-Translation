<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Sat, 17 Aug 2024 03:15:52 GMT</lastBuildDate>
    <item>
      <title>[讨论]决策树构建中的歧义</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu64fq/discussion_ambiquity_in_the_construction_of/</link>
      <description><![CDATA[      https://preview.redd.it/0013142so4jd1.png?width=707&amp;format=png&amp;auto=webp&amp;s=8764b6772fdabe809e7a4db449b501a6d5df201c 我正在尝试对图 1 中显示的品牌示例进行决策树数值计算当我尝试使用熵手动构建决策树时，我得到了 https://preview.redd.it/zdllqlbzo4jd1.png?width=1106&amp;format=png&amp;auto=webp&amp;s=15deb539b6ed7643df0041b09d0dd880c6fb0ee6 现在，当我尝试使用下面的代码构建决策树时 import pandas as pd from sklearn.preprocessing import OrdinalEncoder from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.metrics 导入 accuracy_score data = pd.DataFrame({ “天”: [&#39;D1&#39;, &#39;D2&#39;, &#39;D3&#39;, &#39;D4&#39;, &#39;D5&#39;, &#39;D6&#39;, &#39;D7&#39;, &#39;D8&#39;, &#39;D9&#39;, &#39;D10&#39;, &#39;D11&#39;, &#39;D12&#39;, &#39;D13&#39;, &#39;D14&#39;], “展望”: [&#39;晴天&#39;, &#39;晴天&#39;, &#39;阴天&#39;, &#39;下雨&#39;, &#39;下雨&#39;, &#39;下雨&#39;, &#39;阴天&#39;, &#39;晴天&#39;, &#39;下雨&#39;, &#39;晴天&#39;, &#39;阴天&#39;, &#39;下雨&#39;], “温度”: [&#39;热&#39;, &#39;热&#39;, &#39;热&#39;, &#39;温和&#39;, &#39;凉爽&#39;, &#39;凉爽&#39;, &#39;凉爽&#39;, &#39;温和&#39;, &#39;凉爽&#39;, &#39;温和&#39;, &#39;温和&#39;, &#39;温和&#39;, &#39;热&#39;, &#39;温和&#39;], “湿度”: [&#39;高&#39;, &#39;高&#39;, &#39;高&#39;, &#39;高&#39;, &#39;正常&#39;, &#39;正常&#39;, &#39;正常&#39;, &#39;高&#39;, &#39;正常&#39;, &#39;正常&#39;, &#39;正常&#39;, &#39;高&#39;, &#39;正常&#39;, &#39;高&#39;], “风”: [&#39;弱&#39;, &#39;强&#39;, &#39;弱&#39;, &#39;弱&#39;, &#39;弱&#39;, &#39;强&#39;, &#39;弱&#39;, &#39;弱&#39;, &#39;弱&#39;, &#39;强&#39;, &#39;弱&#39;, &#39;强&#39;, &#39;弱&#39;, &#39;强&#39;], “PlayTennis”: [&#39;否&#39;, &#39;否&#39;, &#39;是&#39;, &#39;是&#39;, &#39;是&#39;, &#39;否&#39;, &#39;是&#39;, &#39;否&#39;, &#39;是&#39;, &#39;是&#39;, &#39;是&#39;, &#39;是&#39;, &#39;是&#39;, &#39;是&#39;, &#39;否&#39;] }) 编码器 = OrdinalEncoder() data_encoded = data.copy() data_encoded[[&#39;Outlook&#39;, &#39;温度&#39;, &#39;湿度&#39;, &#39;风&#39;]] = 编码器.fit_transform(data[[&#39;Outlook&#39;, &#39;温度&#39;, &#39;湿度&#39;, &#39;风&#39;]]) data_encoded[&#39;PlayTennis&#39;] = data_encoded[&#39;PlayTennis&#39;].map({&#39;否&#39;: 0, &#39;是&#39;: 1}) X = data_encoded.drop([&#39;PlayTennis&#39;, &#39;白天&#39;], axis=1) y = data_encoded[&#39;PlayTennis&#39;] clf = DecisionTreeClassifier(criterion=&#39;entropy&#39;) clf.fit(X, y) plt.figure(figsize=(12, 8)) plot_tree(clf, feature_names=X.columns, class_names=[&#39;No&#39;, &#39;Yes&#39;], filled=True, rounded=True) plt.show()  我得到了这棵树 https://preview.redd.it/r1g3x10ep4jd1.png?width=950&amp;format=png&amp;auto=webp&amp;s=bde00bf06025f3a5847717045528128c8283b817 那么我在手工数值计算部分做错了什么吗？还是编码错了？有人可以解释一下吗？    提交人    /u/jiraiya1729   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu64fq/discussion_ambiquity_in_the_construction_of/</guid>
      <pubDate>Sat, 17 Aug 2024 01:42:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 视频生成模型的未来</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu3o5t/d_future_of_video_generation_models/</link>
      <description><![CDATA[有一篇论文已经发表来解决这些问题，该论文使用自回归模型来解决这些问题。  该模型的关键组成部分： - 自回归建模：确保道具、角色等元素的整体一致性 - 扩散渲染：将预测的视觉标记转换为高质量帧 - 多模态脚本：包含场景详细描述的脚本  视频生成模型进行内容创作的未来： - 少量镜头学习以实现定制：能够根据用户提供的少量查询来个性化内容，这意味着用户将能够创建自己的内容。例如，他们自己的节目或 YouTube 视频。   不再有动漫：这可能会让动画过时，当你可以使用人工智能生成的人类来扮演类似的角色时，为什么要使用动漫呢？ 内容创作的民主化：随着内容创作成本的下降，我们将看到更多小型工作室和创作者涌现，类似于 YouTube 所做的那样。此外，这可能会导致好莱坞制作更多样化的电影，而不是少数几部大片。  让我知道您对内容创作未来的看法    提交人    /u/MinuteDistribution31   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu3o5t/d_future_of_video_generation_models/</guid>
      <pubDate>Fri, 16 Aug 2024 23:47:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] HuggingFace 变形金刚——糟糕的设计？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu3auv/d_huggingface_transformers_bad_design/</link>
      <description><![CDATA[嗨， 我目前正在使用 HuggingFace 的 transformers 库。该库在加载模型时有些方便，它似乎是唯一合理的共享和加载模型的平台。但我越深入，就越困难，我感觉 api 设计得不好，存在很多严重的问题。 该库允许在不同的地方设置相同的选项，但没有记录它们如何相互作用。例如，似乎没有统一的方法来处理 EOS 等特殊令牌。人们可以在 1. 模型中、2. 标记器中和 3. 管道中设置这些令牌。我不清楚这些选项究竟是如何相互作用的，而且文档也没有提到这一点。有时参数会被忽略，而库不会就此发出警告。例如，参数“add_eos_token”在某些情况下，标记器似乎不起作用，而且我不是唯一遇到此问题的人（https://github.com/huggingface/transformers/issues/30947）。更糟糕的是，似乎确切的行为通常取决于模型，而库则假装提供统一的接口。查看源代码可以确认它们实际上根据当前加载的模型进行区分。 非常相似的观察结果涉及多线程的启动脚本，特别是：加速。我指定了核心数，但这只是被忽略了。没有通知，没有任何明显的原因。我在系统监视器中看到它仍然以单线程运行。即使是从网站上获取的样本也并不总是有效。 总之，配置设置似乎不受控制地增长。由于没有清晰的结构，并且有太多影响库的效果，因此其行为的很大一部分实际上没有记录。也可以说，它看起来有点不稳定和实验性。即使是对我有用的部分也让我担心，因为我怀疑部署后是否一切都会在另一台机器上正常工作。 有人有这样的想法吗？    提交人    /u/duffano   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu3auv/d_huggingface_transformers_bad_design/</guid>
      <pubDate>Fri, 16 Aug 2024 23:30:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] BAM！就这样：简单高效的混合专家参数升级</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eu30k2/r_bam_just_like_that_simple_and_efficient/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eu30k2/r_bam_just_like_that_simple_and_efficient/</guid>
      <pubDate>Fri, 16 Aug 2024 23:17:52 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 GPT-3.5 和 Haiku 在成本、延迟和准确性方面击败 GPT-4o 结构化输出</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etyrs8/r_beating_gpt4o_structured_output_with_gpt35_and/</link>
      <description><![CDATA[完整帖子：https://www.boundaryml.com/blog/sota-function-calling 使用 BAML，我们几乎解决了1 个 伯克利函数调用基准 (BFCL)（每个模型）（gpt-3.5+）。期待很快分享 arXiv 论文！ https://preview.redd.it/78uxa0xx5pid1.png?width=916&amp;format=png&amp;auto=webp&amp;s=f36e9c6fbb8ea1939c5406e552b0dcf0a4f6fe20 主要发现  与任何本机函数调用 API 相比，BAML 在函数调用方面更准确、更便宜。它比 OpenAI 的 FC-strict API 快 2-4 倍。 BAML 的技术与模型无关，并且可以与任何模型一起使用而无需修改（甚至是开源模型）。 gpt-3.5-turbo、gpt-4o-mini 和 claude-haiku 与 BAML 配合使用的效果几乎与具有结构化输出的 gpt4o 一样好（不到 2%） 使用 FC-strict 而不是简单的函数调用可以改进每个较旧的 OpenAI 模型，但是 gpt-4o-2024-08-06 会变得更糟  背景 到目前为止，从 LLM 获得更好结果的唯一方法是：  迅速设计使用更长更复杂的提示来训练它 训练更好的模型  BAML 的不同之处  用类似 typescript 的定义替换 JSON 模式。例如 string[] 比 {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}&gt; 更容易理解。 使用一种新颖的解析技术（Schema-Aligned Parsing）代替 JSON.parse。SAP 允许输出中出现更少的标记，而不会因 JSON 解析而出现错误。例如，即使键周围没有引号，也可以解析它。 PARALLEL-5 [ { streaming_service: &quot;Netflix&quot;, show_list: [&quot;Friends&quot;], sort_by_rating: true }, { streaming_service: &quot;Hulu&quot;, show_list: [&quot;The Office&quot;, &quot;Stranger Things&quot;], sort_by_rating: true } ]  我们使用提示 DSL（BAML）来实现这一点[2]，而没有使用 JSON 模式或任何类型的约束生成。我们还与使用“工具”API 的 OpenAI 的结构化输出进行了比较，我们称之为“FC-strict”。 对未来的思考 模型真的非常好，是一种语义理解。 模型在必须完美的事情上真的很糟糕，比如完美的 JSON、完美的 SQL、编译代码等。 我们认为，与其努力训练结构化数据的模型或在生成时约束令牌，不如将工程努力应用于稳健地处理模型输出等领域，这将带来尚未开发的价值。    提交人    /u/kacxdak   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etyrs8/r_beating_gpt4o_structured_output_with_gpt35_and/</guid>
      <pubDate>Fri, 16 Aug 2024 20:15:53 GMT</pubDate>
    </item>
    <item>
      <title>[P]：使用 LLM 自动化脚本中的 API 文档。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etyfi2/p_automating_api_documentation_in_the_script/</link>
      <description><![CDATA[大家好，我目前正在开展一个项目，旨在创建一个 AI 代码助手，从开发人员的角度帮助解决一些痛点。 我的项目中的一个功能是在输入脚本中创建 api 文档。 我正在使用 LLM 来帮助构建此功能，特别是 llama 3，使用 llama api，这是一个无键 api。 到目前为止，我正在努力构建此功能，目前我还没有主意。 希望大家对如何进一步进行提出想法和意见。 此外，如果有人想合作，这个项目是一个开源项目，欢迎所有贡献。    提交人    /u/Sherlock_holmes0007   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etyfi2/p_automating_api_documentation_in_the_script/</guid>
      <pubDate>Fri, 16 Aug 2024 20:01:34 GMT</pubDate>
    </item>
    <item>
      <title>多模态LLM解析策略[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ettoy9/multimodal_llm_parsing_strategyd/</link>
      <description><![CDATA[我正在尝试从车辆用户手册中提取图像、表格和文本，我目前的方法是使用预训练的 yolov8 模型来处理图像，使用微调的模型来处理表格，然后使用 OCR 来提取文本。除了在我的自定义数据集上对 YOLO 进行微调外，还有其他有前途的方法吗？我在想我会使用多模态 LLM 来总结每个有图像的页面，并提示它为每个图像专门生成单独的摘要。正在寻找具有成本效益的替代方法，但我需要提取和总结至少 95% 的相关图像    提交人    /u/ashblue21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ettoy9/multimodal_llm_parsing_strategyd/</guid>
      <pubDate>Fri, 16 Aug 2024 16:45:16 GMT</pubDate>
    </item>
    <item>
      <title>[P] 生产中的迭代模型改进</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etn0x2/p_iterative_model_improvement_in_production/</link>
      <description><![CDATA[大家好， 我创建了一个多类分类模型，并在一个带标签的数据集上对其进行了训练。说实话，在本地数据集上表现得相当不错，现在我正打算将其软启动到生产环境中。输入数据将转换为 n 维输入向量，绘制在图表上时不会形成凸形或规则形状（至少我的 EDA 显示了这一点）。由于我无法预见所有可能的模型输入，因此该模型无法完美处理每种情况，我想这没问题，但我正在寻找广泛的用例。这将导致大量误报，我想将其迭代添加到我的训练数据语料库中并随着时间的推移改进模型。 我正在寻找一种有效的方法来识别和管理这些误报。我在考虑：1）随机抽样数据子集并手动标记以验证其是真阳性还是假阳性。 2）获取用户反馈以识别错误分类的反馈。 3）使用聚类技术，其指标包括 Silhouette 分数、Davies-Bouldin 指数、Calinski-Harabasz 指数 (CH)、归一化互信息 (NMI) 或 Dunn 指数。 4）结合 1）和 3）？识别一些假阳性，然后通过聚类找到可能也是假阳性的类似结果 我的最终目标是创建一个随着时间推移不断改进的管道。您将如何解决这个问题？谢谢！    提交人    /u/Queasy_Tailor_6276   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etn0x2/p_iterative_model_improvement_in_production/</guid>
      <pubDate>Fri, 16 Aug 2024 12:06:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT 样式模型可以用于文件压缩、图像升级和恢复吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etlwku/d_can_gptstyle_models_be_used_for_file/</link>
      <description><![CDATA[我一直在思考这个问题 - 是否真的有可能直接在文件（如图像文件）的原始字节数据上训练 GPT 样式的仅解码器架构？我们的想法是学习文件数据中的基础统计模式，然后可能使用模型的概率分布来执行以下操作：  通过更有效地对数据进行建模来设计新的文件压缩算法 通过让模型生成文件中缺失/损坏的部分，对模型进行微调以执行图像升级或恢复等任务  这似乎是一种有趣的方法，因为 GPT 样式的模型已经表现出非凡的能力来捕获自然语言数据中的统计模式。但我不确定同样的原则是否适用于图像文件等更结构化的二进制数据。 这是一个愚蠢或不切实际的想法吗？以前有人尝试过这样的事情吗？我真的很想听听社区对这种方法的潜力和挑战的看法。    提交人    /u/No-Point1424   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etlwku/d_can_gptstyle_models_be_used_for_file/</guid>
      <pubDate>Fri, 16 Aug 2024 11:06:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] PINN 的嵌套 AD</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etkmm6/r_nested_ad_for_pinns/</link>
      <description><![CDATA[我目前正在尝试求解 Lu = f 形式的 PDE，其中 L 是二阶微分算子。我正在进行无监督学习，损失函数只是残差 Lv - f 的通常 MSE，其中 v 是我对 u 的近似值。 由于 L 具有二阶导数，这意味着我们在训练期间获取网络梯度时会获取三阶导数。这太麻烦了（我使用的是 Flux.jl，而 Zygote 无法很好地处理嵌套的三阶 AD），所以我最终求助于 L 的有限差分离散化，这样 AD 的唯一应用就是网络本身的梯度，而没有另外 2 个嵌套的梯度。当然，我很想避免使用有限差分，但我真的没有其他方法。 有人处理过类似的情况吗？根据我的发现，似乎大家一致认为三阶嵌套 AD 确实不切实际，但我希望它还有更多内容。 提前感谢任何输入！ 编辑：在许多情况下，可以以变分形式重新计算问题以将阶数降低 1，但不幸的是，这对我的 PDE 来说是不可能的    提交人    /u/Fleico   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etkmm6/r_nested_ad_for_pinns/</guid>
      <pubDate>Fri, 16 Aug 2024 09:45:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 什么是“低三角因果掩蔽”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etia89/d_what_is_lowtriangle_causal_masking/</link>
      <description><![CDATA[在 https://docs.nvidia.com/megatron-core/developer-guide/latest/api-guide/context_parallel.html 上写着“[上下文并行性很好，因为] 消除了低三角因果掩蔽导致的不必要计算”。这个术语起源于哪里，请问我可以看一个例子吗？    提交人    /u/khidot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etia89/d_what_is_lowtriangle_causal_masking/</guid>
      <pubDate>Fri, 16 Aug 2024 07:03:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可重复性检查表 AAAI25</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ethhro/d_reproducibility_checklist_aaai25/</link>
      <description><![CDATA[大家好， 我正在准备向 AAAI 提交论文，我遇到了可重复性检查表的要求。我对如何提交此检查表有点困惑。它应该作为附录包含在主要论文中，还是需要作为单独的文档上传？此外，如果它包含在论文中，它是否计入页数限制？ 任何曾经向 AAAI 提交过论文或有此过程经验的人的见解都将不胜感激！ 提前致谢！    提交人    /u/Ok_Butterfly7408   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ethhro/d_reproducibility_checklist_aaai25/</guid>
      <pubDate>Fri, 16 Aug 2024 06:10:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审稿人 2 - NeurIPS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etb4qh/d_reviewer_2_neurips/</link>
      <description><![CDATA[NeurIPS 辩驳期终于结束了。大家的审稿怎么样？ 我和一位审稿人打过交道，这是最糟糕的经历。对于最初的评论，他/她只写了一个简短的段落，问了一堆可以通过论文内容轻松回答的问题，然后给了 3 分和 4 分的置信度。对于辩驳，这位审稿人给出了相互矛盾的陈述，甚至无法理解训练数据和测试数据之间的区别。我花了整整两天时间解释这种区别。最后，审稿人留下了关于论文的错误陈述然后消失了。典型的审稿人 2。    提交人    /u/DrSolar789   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etb4qh/d_reviewer_2_neurips/</guid>
      <pubDate>Fri, 16 Aug 2024 00:27:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢所有人在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Aug 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>