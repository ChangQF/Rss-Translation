<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sat, 27 Jan 2024 18:14:25 GMT</lastBuildDate>
    <item>
      <title>[P] 还有什么独特的计算机视觉项目创意吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1acgj8w/p_any_unique_computer_vision_project_ideas_left/</link>
      <description><![CDATA[对于我们的计算机视觉课程，我们应该制作一个项目，我想做一些独特的事情，但我提出的每一个想法都被证明是是一个非常常见的或至少已经实现的。是否有任何独特的项目想法可以在现实世界中应用？ 我目前正在研究“使用 DCGAN 的 T 恤设计生成器”。然而类似的项目已经在互联网上存在，并且我们的教授反复强调该项目需要解决现实世界的问题，所以我不确定我的项目想法是否符合描述。 &lt; !-- SC_ON --&gt;  由   提交/u/clapped_indian  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1acgj8w/p_any_unique_computer_vision_project_ideas_left/</guid>
      <pubDate>Sat, 27 Jan 2024 17:51:22 GMT</pubDate>
    </item>
    <item>
      <title>[D]“特征稀释”是深度神经网络中公认的现象以及如何应对它</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1acfyh2/d_is_feature_dilution_a_recognised_phenomenon_in/</link>
      <description><![CDATA[我一直在努力应对与数据集成和多模式神经网络相关的挑战，我希望得到您的见解。场景如下：我有一个具有多种类型特征的特征矩阵，包括 0 到 1 范围内的 5 个连续变量。此外，我将一个 1024 维的嵌入向量连接到同一个特征矩阵中，其中嵌入值为也是连续的。 我担心的是高维嵌入特征的存在是否会削弱原始 5 个连续变量的效果或重要性。这是一种公认​​的现象吗？如果是，如何解决或对抗这种潜在的稀释效应？ 我很欣赏有关此主题的相关文献的任何指导或参考。预先感谢您的专业知识！   由   提交 /u/Primary-Wasabi292    reddit.com/r/MachineLearning/comments/1acfyh2/d_is_feature_dilution_a_recognised_phenomenon_in/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1acfyh2/d_is_feature_dilution_a_recognised_phenomenon_in/</guid>
      <pubDate>Sat, 27 Jan 2024 17:26:32 GMT</pubDate>
    </item>
    <item>
      <title>[P]有人可以帮我解决这个问题吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ace25g/pcan_someone_please_help_me_with_this/</link>
      <description><![CDATA[      ​ https://preview.redd.it/b877oy0c90fc1.png?width=1920&amp;format=png&amp;放大器;auto=webp&amp;s=15550a423cbb7915f43fdc04895e89440d7ab113 https://preview.redd.it/u0wczy0c90fc1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=5df03f7b522e45bbfbb9e4fdff6da0bd9e7e82cd https://preview.redd.it/akm3b11c90fc1.png?width=1920&amp;format =png&amp;auto=webp&amp;s=12579f4a1c40db1a4c3b350b565a5fe64479fa61 https://preview.redd.it/ga5va11c90fc1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=cfdd70102175313ff9fc32137e587d7b72ed 7196 大家好。所以我尝试自学深度学习，并从用 numpy 制作神经网络开始。您在此处看到的这组特定代码是我创建神经网络类的尝试。这里的回归问题是一个非常基本的问题，我的网络尝试根据 12 个数字特征来预测谷物食品的评级。至于神经网络 netowkr 类，它接受一个列表，其中包含每个隐藏层的神经元数量、激活函数（在本例中为 sigmoid），其他都是不言自明的。现在，当我将神经元列表留空时，即没有隐藏层时，图形的行为符合预期。此图特别绘制了预测值与实际值。当不涉及隐藏层时，我的模型可以完美地模拟谷物数据，并且图形看起来就像一堆沿直线对齐的点。但正如你所看到的，一旦我添加图层，就会发生这种情况。有什么建议吗？ ​   由   提交 /u/MrCensoredFace   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ace25g/pcan_someone_please_help_me_with_this/</guid>
      <pubDate>Sat, 27 Jan 2024 16:03:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] DS 和 Engineering 之间的一个存储库与多个存储库（生产代码）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1accw0t/d_one_repo_vs_multi_repo_between_ds_and/</link>
      <description><![CDATA[大家好， 我昨天发布了一个问题，似乎与构建 AI/ML 产品的人们产生了共鸣。将其作为民意调查发布以产生见解 -  如果您是一名数据科学家，与工程团队一起构建 AI/ML 解决方案，您是否使用与生产存储库相同的存储库进行实验/笔记本，或者执行以下操作：您有一个单独的 DS 存储库，其中包含您的“脏”文件代码？  查看投票  &amp; #32；由   提交/u/Moist_Onion_6440   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1accw0t/d_one_repo_vs_multi_repo_between_ds_and/</guid>
      <pubDate>Sat, 27 Jan 2024 15:11:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] DCGAN 模型训练问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1accsjx/p_issue_with_dcgan_model_training/</link>
      <description><![CDATA[我是 CNN 和 GenAI 的初学者，我很难弄清楚我面临着什么样的问题（模式崩溃、梯度消失）或收敛失败）以及如何修复它。任何帮助，将不胜感激。以下是有关堆栈溢出的完整问题的链接： https://stackoverflow.com/questions/77891608/how-do-i-make-my-discriminator-and-generator-loss-converge-in-dcgan   由   提交/u/clapped_indian  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1accsjx/p_issue_with_dcgan_model_training/</guid>
      <pubDate>Sat, 27 Jan 2024 15:06:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 梯度累积不应与不同的序列长度一起使用</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1acbzrx/d_gradient_accumulation_should_not_be_used_with/</link>
      <description><![CDATA[我正在训练一个占用大量内存的模型，以至于我只能使用批量大小 1 并累积 N 次。如果您考虑一下，这意味着优化将更加重视较小的序列长度。下面是一个示例： 假设您在一个批次中有 2 个序列。序列 1 有 7 个标记，序列 2 有 10 个。这意味着我需要用 3 个填充标记来填充序列 1。如果我在这里使用梯度累积，最终损失将是损失 7 个令牌/7 + 损失 10 个令牌/10。如果我使用的批量大小为 2，则损失将是 17 个令牌/17。很容易看出两者都不是相同，这会引入对较小序列长度的偏见。 我能想到解决这个问题的唯一方法就是“打包”将类似的序列长度放在一起，并且仅对这些打包序列进行混洗，而不是“单独”进行混洗。序列。我将按序列长度对数据集进行排序，并批量制作相似大小的序列。因此，10-15 的序列长度可能是一个批次，16-20 的序列长度可能是另一批次，依此类推……我只对这些批次进行洗牌。这有道理吗？这会引入一些我不知道的其他偏见吗？ 编辑：我刚刚提出了另一个想法，该想法实施起来会稍微困难一些，但可能是有效的。仅当我对损失使用平均减少时，上述内容才有效（为什么我将每个序列的损失除以其中的令牌数量）。但是因为我也在使用梯度裁剪，所以删除损失减少是否有意义（这将是所有令牌损失的总和）？如果我没有弄错的话，与常规的完整批次相比，梯度裁剪会给我完全相同的结果，对吧？它只是渐变的缩放因子，然后通过渐变裁剪将其删除，对吧？   由   提交 /u/AromaticCantaloupe19   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1acbzrx/d_gradient_accumulation_should_not_be_used_with/</guid>
      <pubDate>Sat, 27 Jan 2024 14:28:24 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我的兴趣与典型机器学习工程师的日常职责有交叉吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1acasly/d_do_my_interests_intersect_with_the_day_to_day/</link>
      <description><![CDATA[这似乎是一个相当广泛的立场，所以我试图弄清楚我的热情和 ML 工程师在他们的实际工作中是否有重叠。日复一日。 我的兴趣：  性能至关重要的低级编程。用于快速操作的 GPU 和 SIMD 对深度学习有一定热情，但不是太热衷，因为它对我来说显得太黑箱 我对在消费硬件 GGML 上运行模型非常着迷， LLama.cpp 对经典算法充满热情  我也擅长数学，并且希望解决一些问题。在 React 和 SaaS 上工作通常不会涉及太多这些。   由   提交 /u/ThrowayGigachad   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1acasly/d_do_my_interests_intersect_with_the_day_to_day/</guid>
      <pubDate>Sat, 27 Jan 2024 13:26:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 用于简单支撑结构的 GAN</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ac91cs/p_gan_for_simple_support_structure/</link>
      <description><![CDATA[您好，有人有训练有素的 GAN 模块来构建简单的 3D 打印支撑结构吗？   由   提交/u/Aggravating_Spell116   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ac91cs/p_gan_for_simple_support_structure/</guid>
      <pubDate>Sat, 27 Jan 2024 11:40:23 GMT</pubDate>
    </item>
    <item>
      <title>[p] 眼睛白内障检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ac4t0g/p_eye_cataract_detection/</link>
      <description><![CDATA[大家好，我正在开发一个用于眼睛白内障检测的 ML 模型，我需要有关在哪里下载数据集的帮助。我在 Kaggle 上下载了这个 500+ MB 的数据集，但图像非常小，这影响了模型的性能   由   提交 /u/sammyhga   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ac4t0g/p_eye_cataract_detection/</guid>
      <pubDate>Sat, 27 Jan 2024 06:51:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于零样本语音克隆有什么建议吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1abzrt0/d_any_recommendation_on_zeroshot_voice_cloning/</link>
      <description><![CDATA[我正在寻找一个零样本语音克隆项目。有些提供了 colab 链接，但大多数都以某种方式损坏了（我认为太旧了），一些 github 项目没有很好的文档记录，我未能在我的 Linux 服务器上正确安装它们。我的电脑没有强大的 GPU，所以我想在我的服务器上运行模型，这意味着 Web 界面是必要的。当然，大多数拥有语音克隆功能的网络应用程序都不是免费的。我的语音样本非常有限（10 秒），而且我知道从中克隆语音在技术上可能很困难。非常感谢任何帮助。   由   提交 /u/UndefinedCpp   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1abzrt0/d_any_recommendation_on_zeroshot_voice_cloning/</guid>
      <pubDate>Sat, 27 Jan 2024 02:12:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对国际信息论研讨会 (ISIT) 和 ALLERTON 等会议上的机器学习理论论文的思考</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1abwmal/r_thoughts_about_ml_theory_papers_in_conferences/</link>
      <description><![CDATA[我在国际信息论研讨会 (ISIT) 和 Allerton 等会议上发表了几篇论文。然而，当我申请实习职位时，申请有时会询问在 Neurips、ICML、ICLR 等会议上发表的论文数量。 尽管从任何标准来看，我的研究论文都是“好”的。 （最起码，我是这么想的）。然而，我觉得我没有针对正确的会议。我的导师也在这些会议上发表了很多文章，我想说他/她喜欢“谨慎行事”。并避免在这些大型场所承担任何风险。   由   提交 /u/AfraidKiwi213   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1abwmal/r_thoughts_about_ml_theory_papers_in_conferences/</guid>
      <pubDate>Fri, 26 Jan 2024 23:43:42 GMT</pubDate>
    </item>
    <item>
      <title>极简主义还有空间吗？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1abvqr0/is_there_still_room_for_a_minimalist_aprochd/</link>
      <description><![CDATA[看看 hf 上的排行榜以及我从导师/互联网上得到的总体氛围，似乎当今大多数高质量的工作都是通过框架实现的。  就像如果你想训练一个法学硕士，你需要这些大的仓库和软件包才能有效。 现在我最近开始学习 cuda 和 hpc，我玩得很开心与它一起。当我编写 Transformer 代码时，我通常会尽可能坚持使用 pytorch。减少使用高频训练器。  我是这个行业的新手，而且我还没有做太多值得注意的事情，所以我担心这种方法不是我能跟上的。  实践经验和代码库将得到极大的赞赏   由   提交/u/rejectedlesbian  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1abvqr0/is_there_still_room_for_a_minimalist_aprochd/</guid>
      <pubDate>Fri, 26 Jan 2024 23:04:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 您如何保持动力跟上最新趋势？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1abttig/d_how_do_you_keep_motivated_to_stay_uptodate_with/</link>
      <description><![CDATA[从机器学习内外的各个领域奔波之后，如何选择值得学习的内容？我的书签文章、视频、教程、书籍列表不断快速增长，此时我什至已经停止完全阅读 ML 时事通讯。出于真正的好奇心和兴趣，我能够从工业界回到大学进行应用机器学习研究。但我发现自己几乎没有时间阅读和学习新的 SoTA。当我在这个行业时，即使对于我的机器学习领域之外的领域，我也可以更好地管理这一点。您如何选择性地选择哪些材料来投入时间并真正看透它？我通过推文、YouTube、时事通讯、播客、文章了解最新研究。我很好奇其他机器学习从业者如何应对这种不了解“热门”事物的感觉，以及这是否也让他们感到困扰。欢迎提出所有建议！   由   提交/u/dark-ascension  /u/dark-ascension  reddit.com/r/MachineLearning/comments/1abttig/d_how_do_you_keep_motivated_to_stay_uptodate_with/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1abttig/d_how_do_you_keep_motivated_to_stay_uptodate_with/</guid>
      <pubDate>Fri, 26 Jan 2024 21:43:42 GMT</pubDate>
    </item>
    <item>
      <title>[R] 一种神经网络方法来预测如果我在 1997 年鼓起勇气邀请巴里·科顿菲尔德 (Barry Cottonfield) 参加少年舞会，事情可能会如何发展</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1abiqi6/r_a_neural_networks_approach_to_predicting_how/</link>
      <description><![CDATA[    /u/TobyWasBestSpiderMan   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1abiqi6/r_a_neural_networks_approach_to_predicting_how/</guid>
      <pubDate>Fri, 26 Jan 2024 13:47:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>