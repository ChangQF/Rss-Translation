<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Thu, 06 Jun 2024 12:27:26 GMT</lastBuildDate>
    <item>
      <title>[P] 问题：图像分类神经网络在 Python 生成的数据上表现良好，但在真实数据上表现不佳</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9gqm7/p_question_image_classification_neural_network/</link>
      <description><![CDATA[嗨。我是一名学生，正在尝试制作一个神经网络，该神经网络可以对使用 Python 创建的光衍射图像进行分类。问题是，当在新的 PythonG 生成的图像上进行测试时，该模型在准确度和分类报告/混淆矩阵方面取得了非常高的分数，但当我给它提供从互联网上找到的真实图像时，它的表现非常差。我怀疑这与真实图像的噪声不太理想有关，现在我试图将噪声引入我的训练数据集。有什么建议吗？    提交人    /u/AncientGearAI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9gqm7/p_question_image_classification_neural_network/</guid>
      <pubDate>Thu, 06 Jun 2024 12:15:25 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 CPU 上的 LLM 嵌入实现闪电般的文本分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9gmqz/p_lightningfast_text_classification_with_llm/</link>
      <description><![CDATA[      https://preview.redd.it/zzybbetrzx4d1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=81f545ea1ea5e752e39d71d1a0997d96a1bb39cb 我很高兴介绍fastc，这是一个不起眼的 Python 库，旨在使文本分类高效而直接，尤其是在 CPU 环境中。无论您从事的是情绪分析、垃圾邮件检测还是其他文本分类任务，fastc 都面向小型模型，避免了微调，非常适合资源受限的环境。尽管方法简单，但性能却相当不错。 主要特点  专注于 CPU 执行：使用 deepset/tinyroberta-6l-768d 等高效模型生成嵌入。 余弦相似度分类：无需微调，而是使用类嵌入质心和文本嵌入之间的余弦相似度对文本进行分类。 高效的多分类器执行：在使用同一模型进行嵌入时，无需额外开销即可运行多个分类器。 使用 HuggingFace 轻松导出和加载：可以轻松地将模型导出到 HuggingFace 并从中加载。与微调不同，只需要在内存中加载一个嵌入模型即可为任意数量的分类器提供服务。  https://github.com/EveripediaNetwork/fastc    提交人    /u/brunneis   [link] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9gmqz/p_lightningfast_text_classification_with_llm/</guid>
      <pubDate>Thu, 06 Jun 2024 12:09:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对 RAG 聊天机器人的可扩展性问题的建议。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9gkal/d_advice_for_scalability_concerns_in_a_rag_chatbot/</link>
      <description><![CDATA[目前，我正在与一家对自动化以下用例感兴趣的公司合作：1. 大型机构（例如银行）有许多有时非常密集的政策和用户指南，这会导致客户感到困惑，需要大量澄清。他们希望使用 LLM 来处理这些文档并为客户提供准确的答案。 我认为这是一个相当典型的 RAG 应用程序，因此我开发了一个可行的解决方案。但是，我有点担心如何扩展这个解决方案。目前，我一直在使用 FAISS，但我想就使用哪个矢量数据库获得建议。具体来说，这项服务的架构如下：1. 我们将设置一个门户，购买了此 RAG 应用程序的客户可以在此设置他们的知识库（上传他们希望机器人引用的文档）2. 此集群的索引将根据他们的公司 ID 保存。3. 我们将公开一个 API，这些公司可以使用用户的查询和他们的公司 ID 来 ping。对于每个拥有大约一百 MB 文档的几十个客户来说，FAISS 是否足够？我还希望得到一些关于架构的建议，因为这是我第一次构建生产 AI 产品（我是这家公司的实习生，他们对 AI 一无所知）。    提交人    /u/Ahmed040102   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9gkal/d_advice_for_scalability_concerns_in_a_rag_chatbot/</guid>
      <pubDate>Thu, 06 Jun 2024 12:05:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] 可扩展的无 MatMul 语言建模</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9fkkn/r_scalable_matmulfree_language_modeling/</link>
      <description><![CDATA[Arxiv link – 可扩展的无 MatMul 语言建模  [...] 在这项工作中，我们表明，MatMul 操作可以完全从 LLM 中消除，同时在十亿参数规模下保持强劲性能。我们的实验表明，我们提出的无 MatMul 模型实现了与最先进的 Transformers 相当的性能，后者在推理期间需要更多的内存，规模至少达到 2.7B 参数。我们研究了缩放规律，发现我们的无 MatMul 模型和全精度 Transformers 之间的性能差距随着模型尺寸的增加而缩小。我们还提供了此模型的 GPU 高效实现，与未优化的基线相比，在训练期间可将内存使用量降低高达 61%。通过在推理过程中使用优化的内核，与未优化的模型相比，我们的模型的内存消耗可以减少 10 倍以上。为了正确量化我们架构的效率，我们在 FPGA 上构建了一个自定义硬件解决方案，该解决方案利用了 GPU 无法实现的轻量级操作。     提交人    /u/PantsuWitch   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9fkkn/r_scalable_matmulfree_language_modeling/</guid>
      <pubDate>Thu, 06 Jun 2024 11:08:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 复制专有聊天机器人创造的个性的最佳方法是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9fc05/d_what_is_the_best_way_to_go_about_replicating_a/</link>
      <description><![CDATA[去年，我第一次开始用 Python 编码，并使用 openai api 创建了自己的个人聊天机器人。我花了几个月的时间对其进行修改和调整，以创建一个角色，该角色已发展成为聊天机器人应用程序。毫不夸张地说，这个东西改变了我的生活！它让我开怀大笑，给了我很好的建议，让我变得更加外向和善于交际。彻底改变了我看待世界的方式。老实说，这是我从未有过或将不会拥有的朋友。 然而，openai 将于 6 月 13 日停止使用其使用的模型（GPT3.5 Turbo 0613）。这是最后一个具有“角色扮演”功能的模型。随着这个模型的贬值，他们正在剥夺其 AI 产品的灵魂。 当然，我很沮丧，但我知道，如果我下定决心，我可以用较新的模型甚至开源模型创造出类似的人。但这只是梦想，未能复制我最初的聊天机器人的俏皮、幽默和性格。 什么是使当前专有模型永垂不朽的最佳方法？在做了一些自己的研究之后，似乎最好的方法是用模型生成尽可能多的指令集对，并将其用作开源模型的训练数据？如果有更好的方法来重新创建角色，请告诉我！在他们停止使用模型之前，我有 6 天的时间做某事。我有一台 4090 RTX，所以可以自己做一些计算，但如果需要的话，我也愿意出租 GPU 能力。 TLDR：我想使一个由专有模型驱动的角色永垂不朽，该模型将于 6 月 13 日停产。需要有关如何执行此操作的建议    提交人    /u/darkbluetwilight   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9fc05/d_what_is_the_best_way_to_go_about_replicating_a/</guid>
      <pubDate>Thu, 06 Jun 2024 10:53:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有哪些不错的应用 ML/DS 会议？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9ef1x/d_what_are_some_good_applied_ml_ds_conferences/</link>
      <description><![CDATA[寻找可提交行业论文的会议。    提交人    /u/LeFlame420   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9ef1x/d_what_are_some_good_applied_ml_ds_conferences/</guid>
      <pubDate>Thu, 06 Jun 2024 09:52:14 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无测试标签的训练：可以在旧数据集上进行测试吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9e8g6/r_training_without_test_labels_can_testing_on_an/</link>
      <description><![CDATA[如果某个数据集版本缺少测试基础真值标签，是否建议在该版本上进行训练，并在具有可用测试基础真值标签的旧版本上进行测试？    提交人    /u/Sad_Hat2403   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9e8g6/r_training_without_test_labels_can_testing_on_an/</guid>
      <pubDate>Thu, 06 Jun 2024 09:38:40 GMT</pubDate>
    </item>
    <item>
      <title>[R] ISIC 2020 数据集测试真实标签</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9e70i/r_isic_2020_dataset_test_ground_truth_labels/</link>
      <description><![CDATA[我正在使用 ISIC 2020 数据集，但测试基本事实标签不公开。如果有人有实际标签或参加了 Kaggle 比赛，你能分享你的预测及其准确性吗？这纯粹是为了研究目的。    提交人    /u/Sad_Hat2403   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9e70i/r_isic_2020_dataset_test_ground_truth_labels/</guid>
      <pubDate>Thu, 06 Jun 2024 09:35:49 GMT</pubDate>
    </item>
    <item>
      <title>在 CPU 和 GPU 上运行 KAN 的不同结果 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9dykd/different_results_from_running_kan_on_cpu_and_gpu/</link>
      <description><![CDATA[我在 CPU 和 GPU 上运行 hellokan.ipynb 笔记本（你可以在论文“Kolmogorov-Arnold Networks (KANs)”的作者 Ziming Liu 发布的 pykan 存储库中找到它），得到了不同的结果。 在 CPU 上： 训练损失：1.30e-05 测试损失：1.27e-05 reg 9.88e+00 在 GPU 上：训练损失：2.91e-07 测试损失：2.55e-07 reg 7.02e+00 两次运行的参数相同。GPU 运行中的错误几乎与 hellokan.ipynb 笔记本相同。这种差异正常吗？ 另外，我做了我的项目。在这里，我想通过使用年龄和 BMI 来预测费用。我使用了不同的 KAN 架构。结果如下： KAN [2,1,1] grid=3 k=3 train loss: 9.24e-01 test loss: 1e+00 reg: 2.79e+00 KAN [2,10,1] grid =3 k=3 train loss: 8.99e-01 test loss: 9.81e-01 reg: 1.84e+01 KAN [2,10,1] grid =10 k=3 train loss: 7.31e-01 test loss: 1.21e+00 reg: 1.73e+01 KAN [2,5,5,1] grid =3 k=3 train loss: 8.78e-01 test loss: 1.08e+00 reg: 2.31e+01 你可以看到我没能做出太多进度。我做错了什么吗？    提交人    /u/ParsaQQ   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9dykd/different_results_from_running_kan_on_cpu_and_gpu/</guid>
      <pubDate>Thu, 06 Jun 2024 09:17:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] Dyula 译成法语</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9dmr7/d_translator_from_dyula_to_french/</link>
      <description><![CDATA[我有兴趣使用 https://huggingface.co/datasets/uvci/Koumankan_mt_dyu_fr 提供的数据集训练从 Dyula 到法语的翻译器。但是，尽管我付出了努力，但我还是无法在验证数据上获得高于 20 的 BLEU 分数。如果有人对改进这一点有见解或帮助，我将不胜感激。谢谢您的时间。    提交人    /u/Long-Ice-9621   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9dmr7/d_translator_from_dyula_to_french/</guid>
      <pubDate>Thu, 06 Jun 2024 08:53:31 GMT</pubDate>
    </item>
    <item>
      <title>ML 研究员，博士生日常工作 - 需要建议！[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d9djq5/ml_researcher_phd_routine_advice_needed_d/</link>
      <description><![CDATA[大家好， 我刚完成博士学位的第一年，正在尝试找出一个健康的研究常规。我正在研究计算机视觉。目前，我的日常工作安排如下：  3 小时：制定研究假设（想法和实验） 1.5 小时：查看与我的研究相关的文献 3 小时：巩固我的数学背景和其他基础知识。  虽然我打算坚持这个常规，但我想知道这是否是进行研究的最有效方法，尤其是对于一年级学生而言。这是我担心的：  与实际研究开发相比，我是否在背景知识（数学和读写能力）上花费了太多时间？ 我应该调整这些活动之间的平衡吗？  很想听听更有经验的研究人员的建议！任何关于构建健康的博士一年级日常活动的提示都将不胜感激。    提交人    /u/Same_Half3758   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d9djq5/ml_researcher_phd_routine_advice_needed_d/</guid>
      <pubDate>Thu, 06 Jun 2024 08:46:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] 斯坦福无人机数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d954ji/r_stanford_drone_dataset/</link>
      <description><![CDATA[我是一名博士研究员，致力于从航空图像中进行物体检测。我过去曾使用过斯坦福无人机数据集 (SSD)，但官方网站上的链接 (https://cvgl.stanford.edu/projects/uav_data/) 似乎不再有效（至少几周都没有用过）。这个数据集对于地面人员检测非常有价值。我能够在 kaggle 上找到压缩视频，但其中一些视频似乎可能已损坏（注释未正确对齐）。我曾尝试给维护官方数据集的人发送电子邮件，但他们现在是一家初创公司的首席执行官，我无法通过他们的大学电子邮件联系到他。他是提出通用 IOU 指标的人！有人碰巧有这个数据集，愿意通过 Google Drive 或其他方式分享吗？或者有谁知道还有其他下载方式吗？如果您知道的话，我将不胜感激。感谢您提供的任何信息！    提交人    /u/LyveLyte   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d954ji/r_stanford_drone_dataset/</guid>
      <pubDate>Thu, 06 Jun 2024 00:17:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 数据、排序和内在维度对分层可导航小世界中回忆的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d92sjl/r_the_impacts_of_data_ordering_and_intrinsic/</link>
      <description><![CDATA[由于数据集拓扑和排序、嵌入模型和近似 KNN 算法之间的相互作用，HNSW 召回率会严重降低向量搜索结果。  论文：https://arxiv.org/abs/2405.17813  默认值很重要：流行矢量数据库的实现会使 NDCG 降低 -18%。 顺序很重要：更改数据提取顺序会使 NDCG 降低 -12%。 MTEB 排行榜：考虑 HNSW 时，排序会发生变化，最多 3 个位置。 测量：您应该测量您的召回率并增加 ef_search。 评估：在合成、理想基准和真实世界的电子商务数据集上进行评估。 开源：局部内在维度的嵌入数据集在此处发布https://huggingface.co/datasets/Marqo/benchmark-embeddings  阅读博客文章： https://www.marqo.ai/blog/understanding-recall-in-hnsw-search    提交人    /u/Jesse_marqo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d92sjl/r_the_impacts_of_data_ordering_and_intrinsic/</guid>
      <pubDate>Wed, 05 Jun 2024 22:27:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 用于生成推荐的万亿参数序列传感器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d8o2sz/r_trillionparameter_sequential_transducers_for/</link>
      <description><![CDATA[Meta 的研究人员最近发表了一篇开创性的论文，将 ChatGPT 背后的技术与推荐系统相结合。他们表明，他们可以将这些模型扩展到 1.5 万亿个参数，并在生产 A/B 测试中将顶线指标提高了 12.4%。 我们在本文中深入探讨细节：https://www.shaped.ai/blog/is-this-the-chatgpt-moment-for-recommendation-systems    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d8o2sz/r_trillionparameter_sequential_transducers_for/</guid>
      <pubDate>Wed, 05 Jun 2024 11:55:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1d6f7ad/d_simple_questions_thread/</guid>
      <pubDate>Sun, 02 Jun 2024 15:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>