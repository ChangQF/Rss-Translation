<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 11 Nov 2024 21:15:06 GMT</lastBuildDate>
    <item>
      <title>当目标具有非常高的基数时提示进行分类[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp2mqh/prompting_for_classification_when_target_has_very/</link>
      <description><![CDATA[我正在研究一种植物疾病分类问题，根据症状，人们必须将一种植物归类为几种疾病类别之一。我的问题是关于当目标具有非常高的基数时，提示分类的工程策略。当只有四五个潜在的目标标签时，我可以在提示中列出它们并要求 LLM 进行分类。当类别数量超过 50 时会发生什么？在这种情况下，有没有办法有效地提示 LLM？    提交人    /u/Ok-Emu5850   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp2mqh/prompting_for_classification_when_target_has_very/</guid>
      <pubDate>Mon, 11 Nov 2024 20:43:11 GMT</pubDate>
    </item>
    <item>
      <title>[P]带注释的数据集，用于解释 AI 与真实图像检测的原因</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp05os/pannotated_dataset_for_explaining_the_reason_in/</link>
      <description><![CDATA[我目前正在研究一个问题陈述，其中我需要对真实图像和人工智能生成的图像进行分类，然后对分类进行解释。第一部分非常简单，对于第二部分，我找到了一些研究论文，但没有一篇提供用于微调模型的注释数据集的链接。有人可以帮我找到具有良好注释的数据集吗？ SynArtifact：通过视觉语言模型对合成图像中的伪影进行分类和缓解（他们在第 4 页提到了一个数据集，但没有提供任何链接）    提交人    /u/Background-Trainer37   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp05os/pannotated_dataset_for_explaining_the_reason_in/</guid>
      <pubDate>Mon, 11 Nov 2024 19:03:52 GMT</pubDate>
    </item>
    <item>
      <title>过度拟合查询[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gow3uh/overfitting_query_p/</link>
      <description><![CDATA[大家好，我正在构建一个 NN 模型，根据多个问题的答案来检测疾病。在对 600 名患者的初步测试中，该模型表现非常出色，AUC 为 0.995，测试准确率为 0.975，但我担心该模型过度拟合，我使用了交叉验证和性能差距分析以及 L1/L2 正则化、Dropout 和早期停止。以下是交叉验证和性能差距分析的结果。交叉验证结果：平均 Auc=0.9787 SD0.0090 平均准确率 =0.9350 SD0.0262 性能差距分析训练集 Auc = 0.9983 准确率 =0.9859 测试集 Auc=0.9936 准确率 0.9803 告诉我你们对这些结果的看法，如果您认为它是过度拟合/我还可以做哪些其他测试来判断？我正在尝试确定更多数据，但可能需要与某人合作才能完成此操作。我不想合作伙伴获取数据后发现这完全是浪费！谢谢    提交人    /u/Disastrous_Ad9821   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gow3uh/overfitting_query_p/</guid>
      <pubDate>Mon, 11 Nov 2024 16:22:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025 论文评论讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gov5zd/d_iclr_2025_paper_reviews_discussion/</link>
      <description><![CDATA[ICLR 2025 评审明天将在 OpenReview 上线！我想开一个帖子，讨论评审过程中的任何反馈、问题或庆祝活动。 随着 ICLR 的发展，评审噪音不可避免，好的作品可能并不总是能得到应有的分数。让我们记住，分数并不能定义研究的真正影响。分享您的经验、想法，让我们在整个过程中互相支持！    提交人    /u/Technical_Proof6082   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gov5zd/d_iclr_2025_paper_reviews_discussion/</guid>
      <pubDate>Mon, 11 Nov 2024 15:43:34 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 在训练我的模型时，jupyter 笔记本中每 2n 个 Epoch 都会被跳过</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1got90h/project_while_training_my_model_every_2n_epoch/</link>
      <description><![CDATA[      就上下文而言，我正在尝试对 MobileNetV3Small 模型进行微调以进行面部识别。我冻结了所有层，并在顶部添加了一些层以进行训练。 目前，我的数据集有四个类，每个类有 126 张图像。 在训练模型时，不知何故每 2n 个 epoch 都会被跳过，而且它们也不会记录在历史记录中。如果 epoch 设置为 20，则实际上只有 10 个 epoch 正在执行。我已附上 jupyter notebook 输出的 ss。 后来我在 collab 中尝试了完全相同的代码，它在第 2 个 epoch 上引发了一个错误，说验证生成器正在返回 None 对象。我多次重新检查了代码，但仍然找不到问题所在。 如果有人知道任何修复方法，请提出建议。 我的生成器的代码： datagen = ImageDataGenerator（rescale = 1./255，width_shift_range = 0.1，height_shift_range = 0.1，horizo​​ntal_flip = True，rotation_range = 10，fill_mode = &#39;nearest&#39;）datagen_val = ImageDataGenerator（rescale = 1./255）batch_size = 16 train_generator = datagen.flow（X_train，y_train，batch_size = batch_size）validation_generator = datagen_val.flow（X_val，y_val，batch_size = batch_size） https://preview.redd.it/b9zrpqls0a0e1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=d1141db2189b0bc371a5dd28c279c2b2639db33d https://preview.redd.it/yza75p8t0a0e1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=fbab0aa05e67511dab4c8436e5a12b14a2d06e09    提交人    /u/bkkh_3   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1got90h/project_while_training_my_model_every_2n_epoch/</guid>
      <pubDate>Mon, 11 Nov 2024 14:20:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 帮助我进行内部部署 ml 批量预测？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1goqchp/d_help_me_with_onpremise_ml_batch_prediction/</link>
      <description><![CDATA[我需要部署一个 .pkl 模型，在这样的设置下进行批量预测：代码被推送到 GitLab，SQL/pyspark 用于数据，cron 作业处理调度。不允许使用 Docker、Kubernetes 和云。这是本地设置。这种部署的一些最佳实践或方法是什么？    提交人    /u/Simple_Toe_6989   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1goqchp/d_help_me_with_onpremise_ml_batch_prediction/</guid>
      <pubDate>Mon, 11 Nov 2024 11:46:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么域随机化能保证神经网络控制器的稳定性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gopir9/d_why_does_domain_randomization_ensure_stability/</link>
      <description><![CDATA[大家好， 我正在探索域随机化如何有助于 NN 控制器的稳定性，尤其是当训练包括更广泛地查看历史数据时。 具体来说，我很好奇是否有理论基础或正式分析来解释域随机化如何帮助神经网络在不同条件或噪声水平下保持稳定性，尤其是在结合更多历史信息时。是否有论文通过 Lyapunov 稳定性或其他严格方法来分析这种影响，表明接触各种过去数据可以产生更稳定的基于 NN 的控制系统？ 任何关于该领域基础或最新研究的建议都将不胜感激。提前致谢！ （我已经在控制理论 reddit 上写了同样的东西）    提交人    /u/nerdkim   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gopir9/d_why_does_domain_randomization_ensure_stability/</guid>
      <pubDate>Mon, 11 Nov 2024 10:51:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于不同 LLM 红队方法和技术的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gonf47/r_resource_on_varying_llm_red_teaming_methods_and/</link>
      <description><![CDATA[https://github.com/user1342/Awesome-LLM-Red-Teaming    由   提交  /u/OppositeMonday   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gonf47/r_resource_on_varying_llm_red_teaming_methods_and/</guid>
      <pubDate>Mon, 11 Nov 2024 08:14:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 参加 WACV2025</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gokplb/d_attending_wacv2025/</link>
      <description><![CDATA[您好， 有人要参加明年二月在图森举行的 WACV 会议吗？看来我们必须在 JW Marriot 预订一间房，他们将向我们每人收取每天 35 美元 + 税费作为度假村使用费。 有什么想法可以解决此问题吗，例如附近的酒店或其他解决方案？ 谢谢！    提交人    /u/tuvovan   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gokplb/d_attending_wacv2025/</guid>
      <pubDate>Mon, 11 Nov 2024 05:14:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用图像模型可视化 LLM 注意层对一组 token 的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gojg09/d_how_to_visualize_the_effect_of_an_llm_attention/</link>
      <description><![CDATA[通过将 token 嵌入输入到图像模型中，是否可以可视化 LLM 在通过注意层处理 token 之前和之后如何“想象”token？我知道您无法复制粘贴它，但是有没有办法捕获由注意层引起的潜在变换并将此变换应用于图像模型的嵌入空间？ 例如，如果我在 LLM 中输入“穷人”，那么“男人”的嵌入将转向“乞丐”，而输入“皇室男人”时，它可能会更接近“国王”。我想可视化这种变化。然后，你可以将人的嵌入转移到图像模型中，它会在这个例子中创建类似乞丐或国王的东西。 如果你捕获每个注意层之后的转换并通过插值每个步骤制作视频，它可以制作出非常酷的可视化效果。    提交人    /u/jbrinkw   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gojg09/d_how_to_visualize_the_effect_of_an_llm_attention/</guid>
      <pubDate>Mon, 11 Nov 2024 04:01:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 结合归纳和传导进行抽象推理</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1goh5ym/r_combining_induction_and_transduction_for/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1goh5ym/r_combining_induction_and_transduction_for/</guid>
      <pubDate>Mon, 11 Nov 2024 01:58:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] / [D] 您最近最喜欢的 LLM 或基于扩散模型的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1go8qz0/r_d_your_most_recent_favorite_llm_or_diffusion/</link>
      <description><![CDATA[大家好， 作为竞赛的一部分，我正在尝试寻找一篇有趣的论文，作为我研究小组会议的演讲。我对语言模型和计算机视觉生成 AI 的进步很感兴趣，特别是使用扩散模型。 我想问一下，您目前最喜欢与这些领域相关的哪些论文，以及您为什么喜欢它们。我喜欢那些思维方式相当简单但创新性很强的论文，这些论文可以为研究增添很多价值。请提供您的想法/链接，我非常感谢您的所有意见。谢谢！！    提交人    /u/Tough-Statement9740   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1go8qz0/r_d_your_most_recent_favorite_llm_or_diffusion/</guid>
      <pubDate>Sun, 10 Nov 2024 19:32:31 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ML 和 DL 模型中存在伪造新型方法的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1go50wf/discussion_papers_with_fake_novel_approach_in_ml/</link>
      <description><![CDATA[为什么很多新论文（通常由博士完成）都采用现有方法，而当您询问他们的贡献时，他们说我们用另一层替换了这一层，或者我们添加了超参数!!!!! 这不是贡献！我很困惑这些怎么会被接受    提交人    /u/Rihab_Mira   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1go50wf/discussion_papers_with_fake_novel_approach_in_ml/</guid>
      <pubDate>Sun, 10 Nov 2024 16:53:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>