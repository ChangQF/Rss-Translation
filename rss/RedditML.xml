<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 15 Jan 2024 09:14:56 GMT</lastBuildDate>
    <item>
      <title>在训练之前找出网络在数据集上的最佳性能 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1974bt1/figure_out_networks_best_possible_performance_on/</link>
      <description><![CDATA[我遇到一个问题，即我无法访问大量硬件，这意味着训练模型需要很长时间，例如至少需要几天的时间能够查看图像生成模型是否会按照我想要的方式运行。那么有没有技术可以在训练之前大致了解模型将如何执行或找出最佳模型以获得我想要的结果？   由   提交 /u/Hewwo-Is-me-again   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1974bt1/figure_out_networks_best_possible_performance_on/</guid>
      <pubDate>Mon, 15 Jan 2024 08:57:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] GAN 的 LORA</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1973l79/d_loras_for_gans/</link>
      <description><![CDATA[嗨，潜艇。我想训练一些GAN模型（比如pix2pix），但似乎训练一个高质量的GAN确实很难。 是否可以为GAN训练LORA？ 编辑：刚刚发现新论文E2GAN：用于图像到图像翻译的高效GAN的高效训练 https:/ /arxiv.org/abs/2401.06127   由   提交/u/gxcells  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1973l79/d_loras_for_gans/</guid>
      <pubDate>Mon, 15 Jan 2024 08:07:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何通过基于分数的扩散模型计算新数据点的分数（song & ermon，2019）？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1971j09/r_how_to_calculate_the_score_of_a_new_datapoint/</link>
      <description><![CDATA[我有一个在 64X64 图像上训练的基于预训练分数的扩散模型。现在我想通过这个预训练的神经网络计算新图像（相同维度）的分数。 分数网络需要两个输入：  x_t：在时间戳 t 处采样 t：时间戳  我应该如何通过这个预训练的神经网络计算新图像的分数？   由   提交 /u/AIsavvy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1971j09/r_how_to_calculate_the_score_of_a_new_datapoint/</guid>
      <pubDate>Mon, 15 Jan 2024 05:57:47 GMT</pubDate>
    </item>
    <item>
      <title>[R] COSMO：具有交错预训练的对比流线型多模态模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1971c6h/r_cosmo_contrastive_streamlined_multimodal_model/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2401.00849 代码：https://github .com/showlab/cosmo 模型：https://huggingface.co/ Awiny 数据集：https://huggingface.co /datasets/Awiny/Howto-Interlink7M 项目页面：https： //fingerrec.github.io/cosmo/ 摘要：  视觉语言预训练的演变，从短文本理解转向包含扩展文本上下文是关键。最近的自回归视觉语言模型，如 [Flamingo、PaLM-E]，利用大型语言模型的长上下文功能，在少量文本生成任务中表现出色，但在对齐任务中面临挑战。为了解决这一差距，我们将对比损失引入文本生成模型，提出了 COntrastive-Streamlined MultimOdal 框架（CosMo），策略性地将语言模型划分为专用的单模态文本处理和熟练的多模态数据处理组件。 CosMo 是我们的统一框架，融合了单模态和多模态元素，增强了涉及文本和视觉数据的任务的模型性能，同时显着减少了可学习的参数。然而，这些模型需要大量的长文本数据集，而高质量长文本视频数据集的可用性仍然有限。为了弥补这一差距，这项工作引入了 Howto-Interlink7M，这是一个首个具有全面字幕的交错视频文本数据集，标志着向前迈出了重要一步。为了展示其影响，我们说明了 Howto-Interlink7M 如何增强图像文本任务中的模型性能。我们的模型具有 34% 的可学习参数并利用了 72% 的可用数据，表现出优于 OpenFlamingo 的显着优势。例如，在 4 镜头 flickr 字幕任务中，性能显着提高，从 57.2% 提高到 65.1%。 CosMo 和 Howto-Interlink7M 的贡献体现在涵盖图像文本和视频文本任务的 14 个不同下游数据集上的显着性能提升。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1971c6h/r_cosmo_contrastive_streamlined_multimodal_model/</guid>
      <pubDate>Mon, 15 Jan 2024 05:46:49 GMT</pubDate>
    </item>
    <item>
      <title>用于二元分类的 MLE [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196ypkq/mle_for_binary_classification_r/</link>
      <description><![CDATA[在 y 等于 +1 或 -1 的二元分类问题中，我们希望对 x 求解 y = ax+n。这里，如果 ax+n 为正，则 y 等于 +1；如果 ax+n 为负，则 y 等于 -1，并且 n 是高斯噪声 ~ N(0,1)。我知道假设这个噪声是高斯分布，则 y 的最大似然估计会最小化 y 和 ax 之间的 MSE，因为 y 将是具有均值 ax 的高斯分布。现在，我对一些事情感到困惑：因为 y 是二进制的，所以它应该建模为：sign(ax+n)。这绝对不是高斯分布（因为它只能等于+1或-1）。如果你想最大化sign(ax+n)的可能性，它不会产生MSE，因为它不是高斯的。但是，自然地我可能会考虑最小化 y 和 sign(ax) 之间的 MSE（因为如果我想通过函数对 y 建模，它应该是 sign(ax)）。我想了解我们如何实现这一点？它是否会将 y 定义更改为 y = sign(ax)+n 这与真正的定义 y=sign(ax+n) 肯定不同？ 如果 y=sign(ax+ n)，为了最大化 y 的可能性，我们应该最小化什么损失？   由   提交 /u/lookingfornonibudle   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196ypkq/mle_for_binary_classification_r/</guid>
      <pubDate>Mon, 15 Jan 2024 03:27:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自行实现 Rabbit tech 的 LAM</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196wqsl/d_selfimplementing_rabbit_techs_lam/</link>
      <description><![CDATA[我看到了有关 Rabbit R1 和人性化人工智能的炒作。我只找到了一篇Rabbit ai的研究论文（https://www.rabbit.tech/research）。不幸的是，“研究论文”没有详细让我深入了解如何实现这样的人工智能。你们知道如何有效地自我训练“LAM”吗？如果你只是用这个人工智能制作一个启动器，直接与本机应用程序交互以切断数字处理的需要，不是更容易吗？ 我对这篇没有组织的帖子感到非常抱歉🙏&lt; /p&gt;   由   提交/u/amirkasraaa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196wqsl/d_selfimplementing_rabbit_techs_lam/</guid>
      <pubDate>Mon, 15 Jan 2024 01:50:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2024 决定将于今天公布</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196uyub/d_iclr_2024_decisions_are_coming_out_today/</link>
      <description><![CDATA[我们很快就会在接下来的几个小时内知道结果。请随意宣传您已被接受的项目，并对您被拒绝的项目进行咆哮。   由   提交/u/deschaussures147  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196uyub/d_iclr_2024_decisions_are_coming_out_today/</guid>
      <pubDate>Mon, 15 Jan 2024 00:25:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我应该如何实现自定义量化方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196uam1/d_how_should_i_go_about_implementing_a_custom/</link>
      <description><![CDATA[大家好！我一直在研究量化 LLMS，并且我有一些想要测试的自定义方法。看看现有的实现，比如 Tim Dettmers 的 bitandbytes，让我感到一如既往的迷失。查看 llama.cpp 源代码也没有多大帮助。有没有人有实施和更重要的是评估自定义量化方法的经验？请分享任何想法，如果您有任何问题，请随时提问。谢谢！   由   提交 /u/Im_The_Tall_Guy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196uam1/d_how_should_i_go_about_implementing_a_custom/</guid>
      <pubDate>Sun, 14 Jan 2024 23:55:36 GMT</pubDate>
    </item>
    <item>
      <title>哪些部门研究现代实验设计？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196tumn/what_kinds_of_departments_research_modern/</link>
      <description><![CDATA[ 由   提交/u/AdFew4357  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196tumn/what_kinds_of_departments_research_modern/</guid>
      <pubDate>Sun, 14 Jan 2024 23:36:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] [R] 因果关系和基于模型的强化学习：可能的联系？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196sva4/d_r_causality_and_modelbased_rl_possible/</link>
      <description><![CDATA[大家好！我一直在深入研究基于模型的强化学习（RL）及其与因果推理的关系，我发现自己很感兴趣，但又有点困惑。（请告诉我我的理解是否有意义） 一方面，基于模型的强化学习专注于学习环境的动态，似乎很自然地适合回答“假设”问题。问题。在没有实际的现实世界试验的情况下预测行动结果的能力感觉非常像因果推理。但是，这是否意味着基于模型的强化学习本质上能够进行全面的因果推理？ 我的理解是，因果推理不仅涉及预测结果（干预），还涉及反事实推理 - 理解什么在不同的过去行为下会发生。我想知道基于模型的强化学习在这方面的处理效果如何，因为它依赖于学习模型的准确性和完整性。 我很好奇社区对此的想法： &lt; ol&gt; 基于模型的 RL 系统可以回答的因果问题类型是否有任何限制？ 将显式因果模型集成到基于模型的 RL 框架中如何增强其功能？  li&gt;  很想听听您的见解或任何可以阐明这个交叉点的相关研究！   由   提交 /u/vocdex   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196sva4/d_r_causality_and_modelbased_rl_possible/</guid>
      <pubDate>Sun, 14 Jan 2024 22:54:40 GMT</pubDate>
    </item>
    <item>
      <title>[P]尝试计算单词的语义差异。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196ryle/p_trying_to_calculate_semantic_difference_of_words/</link>
      <description><![CDATA[我正在做一个项目，我有一个目标单词列表，需要计算这些单词和新单词之间的含义差异。这主要是一个单词相似度任务。  假设目标词是“car”，模型需要为“dog”输出高值。 “吉普车”的价值较低；或相反亦然。目前我正在使用huggingface的句子转换器库来实现此目的，并使用（1-余弦相似度）作为差异分数。但表现并没有达到预期。有什么办法可以提高性能吗？我应该使用其他库/模型/指标吗？  谢谢。   由   提交 /u/franticpizzaeater   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196ryle/p_trying_to_calculate_semantic_difference_of_words/</guid>
      <pubDate>Sun, 14 Jan 2024 22:16:42 GMT</pubDate>
    </item>
    <item>
      <title>损失被限制在我的 GCN 模型中 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196lkyw/loss_is_getting_clamped_in_my_gcn_model_p/</link>
      <description><![CDATA[我已经使用 pytorch 在具有相同边缘索引的图上训练了以下模型（任务是电子健康记录上的图分类，其中每个图代表患者数据和节点向量已从组合知识图导出） class mdl(torch.nn.Module): def init(self, input_size, hide_size, output_size,dropout_rate): super(GCNClassifier, self).init() self.conv1 = GCNConv(input_size,hidden_​​size) self.conv2 = GCNConv(hidden_​​size,output_size) self.dropout = torch.nn.Dropout(dropout_rate) defforward(self,x,edge_index): x = self.conv1(x, edge_index) x = F.relu(x) x = self.dropout(x) x = self.conv2(x, edge_index) x = torch.mean(x, dim=0, keepdim=True) return x  问题是损失被限制在特定值 ​ 我尝试了各种学习率值并尝试了各种技术，例如动量和学习率调度，但损失仍然保持不变 ​ 我尝试使用以下循环训练上述模型 ​ #training (graphVec) 800 个图（每个形状为 [5,20] 的图） #y_train 是形状 [800] 的 0 和 1 的张量,1] 用于二元分类 ​ num_epochs = 100 for epoch in range(num_epochs): model.train() for i in range(len( graphVec)): # 在每次迭代中将每个图传递给模型 output = model(graphVec[i], edge_index) loss = criteria(output, y_train[i]) loss.backward() optimizationr.step() optimizationr.zero_grad( ) # StepLR 调度器步骤 Scheduler.step() print(output) # 打印每个 epoch 的损失和学习率 current_lr = optimizer.param_groups[0][&#39;lr&#39;] print(f&#39;Epoch [{epoch + 1}/{num_epochs} ]，损失：{loss.item()}，学习率：{current_lr}&#39;)  但是我的损失严重受限（损失并没有随着时代的推移而减少）我该怎么办?   由   提交/u/Willing-Cell1790   /u/Willing-Cell1790 reddit.com/r/MachineLearning/comments/196lkyw/loss_is_getting_clamped_in_my_gcn_model_p/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196lkyw/loss_is_getting_clamped_in_my_gcn_model_p/</guid>
      <pubDate>Sun, 14 Jan 2024 17:49:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196j1w0/d_simple_questions_thread/</guid>
      <pubDate>Sun, 14 Jan 2024 16:00:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当我们生成超出 LLM 训练上下文长度的标记时会发生什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196fnf3/d_what_happens_when_we_generate_tokens_beyond_the/</link>
      <description><![CDATA[举例来说，LLM 接受了 2048 个标记的训练，而我们生成的文本超过 2048 个标记。问题是什么？为什么？   由   提交/u/kekkimo  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196fnf3/d_what_happens_when_we_generate_tokens_beyond_the/</guid>
      <pubDate>Sun, 14 Jan 2024 13:15:36 GMT</pubDate>
    </item>
    <item>
      <title>我仅使用智能手机就通过“活动识别”控制了超级马里奥！ [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/196f4z9/i_controlled_super_mario_with_activity/</link>
      <description><![CDATA[最近，我参与了一个涉及活动识别的项目，这是根据从传感器收集的数据来识别和理解人类活动的过程&lt; /强&gt;。我唯一拥有的就是一部旧智能手机，因为我没有钱投资额外的传感器。 我的最终目标是使用我在现实世界中的动作来控制游戏中的超级马里奥。经过一些研究后，我发现大多数智能手机都配备了加速度传感器，我可以利用它来训练用于活动识别的机器学习模型。幸运的是，我的旧智能手机有一个。然后，我开发了一款能够将实时传感器数据从智能手机无线传输到笔记本电脑的应用程序（我将这个应用程序命名为“SensorFlow”）。 使用这些数据，我构建并训练了一个机器学习模型它可以准确地检测我的行为，准确率高达 95%。最后，我将这个模型与《超级马里奥》集成，使用 python 根据我的真实动作以编程方式敲击箭头键。我最终得到了一个只需用我的身体就可以玩超级马里奥的系统！虽然不是 100% 但效果已经足够好了。欢迎提出更多建议。 我已经开源了所有与活动识别相关的代码以及我在此过程中开发的 Android 应用程序。 有关此项目的更多信息，您可以看看我的 YouTube。这是一种自我推销，但其中包含有关该项目的附加信息。您可以在下面看到最终结果👇 https://www.youtube.com/watch?v =IpLV6uKAO98   由   提交 /u/Pritish-Mishra    reddit.com/r/MachineLearning/comments/196f4z9/i_control_super_mario_with_activity/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/196f4z9/i_controlled_super_mario_with_activity/</guid>
      <pubDate>Sun, 14 Jan 2024 12:46:53 GMT</pubDate>
    </item>
    </channel>
</rss>