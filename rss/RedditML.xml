<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 09 Dec 2024 12:36:55 GMT</lastBuildDate>
    <item>
      <title>[P] 文本转视频排行榜：比较最先进的文本转视频模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ha54m0/p_texttovideo_leaderboard_compare_stateoftheart/</link>
      <description><![CDATA[与文本生成不同，文本转视频生成涉及平衡真实感、对齐和艺术表达。但就输出质量而言，哪一个最重要？ 我们不知道，这就是为什么我们创建了一个基于投票的文本转视频模型排行榜，灵感来自 LLM 排行榜 lmarena.ai。 目前，排行榜有五个开源模型：HunyuanVideo、Mochi1、CogVideoX-5b、Open-Sora 1.2 和 PyramidFlow，但我们的目标是还包括来自 Kling AI、LumaLabs.ai 和 Pika.art 的著名专有模型。 这是排行榜的链接：link。 我们很乐意听到您的想法、反馈或建议。您认为应该如何评估视频生成模型？    提交人    /u/lambda-research   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ha54m0/p_texttovideo_leaderboard_compare_stateoftheart/</guid>
      <pubDate>Mon, 09 Dec 2024 08:17:05 GMT</pubDate>
    </item>
    <item>
      <title>[R] Monet：Transformer 的单语义专家组合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ha4inl/r_monet_mixture_of_monosemantic_experts_for/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2412.04139 GitHub：https://github.com/dmis-lab/Monet Monet 通过创新的稀疏混合专家 (SMoE) 架构提出了一种增强大型语言模型 (LLM) 中机械可解释性的新方法。通过将稀疏词典学习直接纳入端到端预训练，Monet解决了多义性的基本挑战 - 单个神经元对多个不相关的概念作出反应 - 同时保持模型性能。 主要亮点：  可扩展的专家架构：Monet引入了参数高效的专家分解方法，可以扩展到每层 262,144 位专家，同时确保总参数与专家数量的平方根成比例扩展。 单义专家：通过细粒度的专家专业化，Monet实现了展示知识互斥性的单义专家，允许透明地观察模型行为和参数知识。 强大的知识控制：该架构能够精确操纵领域特定知识、语言能力和毒性缓解，而不会影响一般性能。  为什么选择 Monet？ 与使用事后重建的传统方法（如稀疏自动编码器）不同，Monet 将可解释性直接集成到其架构中。这样既可以透明地理解模型内部结构，也可以控制基本行为。通过扩展单语义专家，Monet 为更透明、更可控的语言模型铺平了道路。 我们很乐意听到您的反馈、问题或您可能有的任何其他疑问！    提交人    /u/affjljoo3581   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ha4inl/r_monet_mixture_of_monosemantic_experts_for/</guid>
      <pubDate>Mon, 09 Dec 2024 07:31:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 寻找每日关键词搜索数据库（任何平台）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ha465g/p_looking_for_daily_keyword_search_database_any/</link>
      <description><![CDATA[大家好， 在彻底搜索 Google 并尝试查找允许我以每日为单位在任何平台上生成关键字搜索或帖子或评论频率的 API 后，我找不到任何此类数据提供商。考虑到这是一种小众请求，我在此提出此询问，以寻求 Reddit 的 ML 大神的帮助。 基本上，我正在尝试创建一个 ML 模型，可以预测未来关键字使用量的增加/减少（无论是在 Google 搜索还是 X 帖子上；无所谓）以每日为单位。我找到了很多每月平均关键字搜索提供商，但我找不到任何方法来访问任何平台的更细粒度的每日搜索总数。如果您知道任何此类数据的来源，请将其放在这里...或者，如果这是不可能完成的任务，就告诉我放弃。    提交人    /u/Appropriate-Touch515   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ha465g/p_looking_for_daily_keyword_search_database_any/</guid>
      <pubDate>Mon, 09 Dec 2024 07:06:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] O1 复制纸</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9zjf1/r_o1_replication_paper/</link>
      <description><![CDATA[大家好， 刚刚发布的一篇论文，我认为它暗示了 OpenAI 可能如何开发出 O1 的一些非凡的推理能力。TLDR-您需要一个真正高质量的人类小型数据集，并搭配一点 RL 以下是他们从研究中得出的一些关键方法  互联网上的推理数据极其稀缺。很难找到真正显示问题解决过程的数据，例如假设检验、回溯等 尽管 RL 很重要，但被整个社区高估了。它真的是锦上添花。人类数据完成了大部分繁重的工作。有关更多信息，请参阅 deep-seek math  论文可以在这里找到：https://arxiv.org/abs/2412.04645 并不是说这绝对是 o1 的工作原理，但结果表明，这种方法可用于创建非常相似的行为 论文为预印本，因此很高兴澄清任何不清楚的地方。 很高兴回答有关论文的任何问题。    提交人    /u/Brosarr   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9zjf1/r_o1_replication_paper/</guid>
      <pubDate>Mon, 09 Dec 2024 02:31:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 扩散模型、图像超分辨率以及一切：综述</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9wrv6/r_diffusion_models_image_superresolution_and/</link>
      <description><![CDATA[我们很高兴与大家分享我们最新的关于应用于图像超分辨率的扩散模型的调查论文。欢迎您阅读。它也是开放获取的，并发表在 IEEE TNNLS 上 :)  arXiv：https://arxiv.org/abs/2401.00736    提交人    /u/Maleficent_Stay_7737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9wrv6/r_diffusion_models_image_superresolution_and/</guid>
      <pubDate>Mon, 09 Dec 2024 00:09:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我尝试测试所有这些人工智能食谱和菜谱，结果感到非常沮丧</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9wcdo/p_i_got_too_frustrated_trying_to_test_all_these/</link>
      <description><![CDATA[在过去一年构建支持 AI 的 SaaS 应用程序的过程中，我对开发人员从使用 jupyter 笔记本编写的 AI RAG 手册到将其集成到我的应用程序中的体验越来越感到沮丧。笔记本很棒，但很难测试其中的哪一部分对我的应用程序真正重要。这让我不得不理解每个笔记本中的每一段代码，解释什么是重要的，以某种方式构建一个 API 服务器作为 POC，然后将其挂接到我的应用程序中。反馈循环非常漫长、痛苦，而且大多数时候我都会放弃 POC，因为它不是我想要的。 这时我才意识到，AI 开发者世界中的角色被分成了两部分。数据科学家和人工智能开发人员想要简单的笔记本来测试方法和技术，但并不关心运送可以轻松被应用程序使用的东西。 另一个阵营是应用程序开发人员，他们只想要简单的 API，可以使用这些 API 快速测试并验证这些人工智能方法是否增强了他们的应用程序。 进入 KitchenAI。 通过将与人工智能相关的 Jupyter 笔记本转换为现成的生产 API 服务器来弥合两者之间的差距，以便轻松测试各种食谱、菜谱和技术。将开发周期缩短一半，同时为用户提供完整的本地体验，并能够将其作为 docker 容器共享。 完全与供应商和框架无关，目标是让开发人员最大限度地自由地使用他们已经觉得最舒服的库。 它带有一个插件架构，所以我设想我们的团队和社区将构建各种 llmops 类型的插件，如评估框架、可观察性、提示管理等等。 我们付出了很多努力来提供完全开源、本地化且经过实战测试的技术（如 Django），这样开发人员就不必依赖第三方提供商。 我们已在 Apache 许可下启动了这个 repo，因此任何开发人员都可以使用该工具。我们正在努力为那些有更复杂需求的人提供具有更深入的集成、指标、分析和工作流程的托管云版本。 尝试一下：https://github.com/epuerta9/kitchenai。让我们知道您的想法！    提交人    /u/wait-a-minut   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9wcdo/p_i_got_too_frustrated_trying_to_test_all_these/</guid>
      <pubDate>Sun, 08 Dec 2024 23:48:32 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 模拟 Kubernetes 监控数据以用于深度学习原型——有什么想法吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9vru3/project_simulating_kubernetes_monitoring_data_for/</link>
      <description><![CDATA[我们的目标是使用深度学习构建一个原型项目，但我们需要一个包含 Kubernetes 部署指标的数据集。我最初尝试从我的公司获取数据，但 — 剧透警告 — 我们显然无法使用它。 我们目前的想法是创建一个虚拟实验室，其中有一个运行自定义应用程序的小型 Kubernetes 集群。使用 JMeter，我们计划模拟随机场景以生成类似于我们公司微服务部署的流量。 生成的合成数据将用于训练我们的原型。之后，我们将通过稍微修改 JMeter 场景并根据 Kubernetes 的默认算法评估其性能来测试模型。 你的想法是什么？我知道这方面有现成的文献，但我很想听听你的专家意见。 谢谢！    提交人    /u/Ok-Consequence-8863   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9vru3/project_simulating_kubernetes_monitoring_data_for/</guid>
      <pubDate>Sun, 08 Dec 2024 23:20:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 存在“可积规划”这样的东西吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9ty31/d_is_there_such_a_thing_as_integrable_programming/</link>
      <description><![CDATA[我来自纯数学背景，最近开始从事科学 AI/ML 的新工作，在工作中我经常使用 JAX。JAX 很棒，我喜欢它，但我看到了一种非常常见的模式，研究人员会有一个完全可微分的模拟和几个神经网络架构之类的东西，但随后会有一堆相对不精确的积分值数值估计。显然，我正在阅读数值方法，并尽我所能重构问题以更代数地解决问题，但我自己的好奇心是，有没有一种相当于“可微分”编程的方法，你处理的是“可积”实体？ 显然，这将是一类更难的问题，因为你可以积分……好吧，一切。这就是你最终在紧凑支撑上求解具有奇怪丑陋的 Holder 边界的 PDE 的方法。但是，有没有计算方法（或者我应该知道的可微分编程策略）朝这个方向发展？是否有很好的自然代数属性可以利用？你能以同样的方式使用计算图吗？怎么样，比如，扩展到“弱可微分”函数式编程的有效方法？ 希望这足够相关，因为它是学习 JAX 启发的……    提交人    /u/redwingviking   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9ty31/d_is_there_such_a_thing_as_integrable_programming/</guid>
      <pubDate>Sun, 08 Dec 2024 21:56:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LLM 进行上下文感知实体识别</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9stfq/d_contextaware_entity_recognition_using_llms/</link>
      <description><![CDATA[有人能推荐一些可以执行实体识别但使用 LLM 级上下文的好模型吗？此类模型通常是针对实体识别进行微调的 LLM。通常，使用传统的 NER/ER 管道（例如 SpaCy 的 NER 模型）只能标记已经训练过的单词。使用针对实体识别进行微调的 LLM（例如 GLiNER 模型）可以标记模糊实体，而不仅仅是基本实体，例如名称、地点、组织等。    提交人    /u/Ashwiihii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9stfq/d_contextaware_entity_recognition_using_llms/</guid>
      <pubDate>Sun, 08 Dec 2024 21:05:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 针对高中生的离线 AI/ML 活动？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9ks8v/d_offline_aiml_activity_for_high_school_students/</link>
      <description><![CDATA[下周，我将在当地一所高中进行一小时的代码演示。由于我经营着大学的人工智能俱乐部，所以我想以人工智能为中心。过去，我曾与高中生一起进行过一些以人工智能为重点的活动，取得了不同程度的成功，但还没有找到“那个”。有什么想法可以尝试下一步吗？我将列出我到目前为止所做的事情以及此特定活动的限制。 限制：  这些是 9-12 年级的随机学生，所以我不能依赖任何先前的计算机科学知识 我们无法使用计算机，因此一切都必须离线。不过，我可能可以为他们提供 ipad 我们有 1 小时的活动时间。填满 45 分钟左右是理想的，这样我们就不会超时，也不会有太多的额外时间。  我以前尝试过的事情：  AI Kahoot + 解释神经网络的简单讲座 - 学生们喜欢 kahoot，但我大大高估了他们对 AI 的知识（和兴趣）。愚蠢地以为他们中至少有少数人至少听说过神经网络，但没有一个学生听说过哈哈 Wordle AI 伪代码和代码 - 我让学生分成小组，集思广益，想出如何制作一个算法来解决 wordle。然后我在投影仪上编写他们的解决方案，我们与我的算法竞争。这个很酷，但我认为只有当学生真正参与时它才会真正起作用，而我真的不认为这个小组会那么投入。 图像分类代码 - 我曾经自己在投影仪上做过这个（不好），也曾和一些有 CS 经验的学生一起做过（还行）。但这个不适合这个活动，我只是想把它包括进去 图灵测试活动 - 让学生猜猜哪个答案来自 ChatGPT，哪个来自学生志愿者。志愿者会离开房间，其余学生会问一个问题（比如“生命的意义是什么”之类的）。我会在 PowerPoint 幻灯片上写下志愿者的答案和 ChatGPT 的答案，让学生猜猜哪个是 GPT。过去，这种方法在初中生中确实很成功，但我担心对于高中生来说这有点太幼稚了。  --- 我倾向于努力为高中生设计活动，因为我不想削弱他们的智力，但我不想给他们布置一个他们不理解的复杂活动。    提交人    /u/j0ngle6421   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9ks8v/d_offline_aiml_activity_for_high_school_students/</guid>
      <pubDate>Sun, 08 Dec 2024 15:08:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我应该在我的学术论文中使用 MLflow 或 DVC 等机器学习实验跟踪工具吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9ig1e/r_should_i_use_ml_experiment_tracking_tools_like/</link>
      <description><![CDATA[大家好！ 我是一名计算机科学毕业生，目前正在为研究论文进行机器学习实验。我有一个数据集，计划比较多个深度学习模型之间的错误指标。 我打算提交论文的会议要求我提供代码和数据集，我也坚信可重复性在学术研究中至关重要。为此，我正在使用 Docker 和 pip-compile 使环境尽可能可重复。 话虽如此，我知道有像 MLFlow 和 DVC 这样的工具可以跟踪 ML 实验。但是，我从未在学术论文附带的代码中看到过这些工具。 我的问题是：  有没有学术论文使用 MLFlow 或 DVC 等 ML 实验跟踪工具？ 我应该将这些工具用于我的研究吗，即使这意味着额外的工作？  我也在尝试 DVC，因为它将实验输出存储在 Git 中。但是，我的项目涉及在单个存储库中运行许多不同的实验（比较多种 ML 算法）。DVC 或其他工具是否是这种工作流程的最佳选择？或者对于学术论文来说，使用这样的工具是不是有点小题大做？    提交人    /u/mrlucasrib   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9ig1e/r_should_i_use_ml_experiment_tracking_tools_like/</guid>
      <pubDate>Sun, 08 Dec 2024 13:05:06 GMT</pubDate>
    </item>
    <item>
      <title>[D] 各种 LLM 抽样方法的集合</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9fe8q/d_a_collection_of_various_llm_sampling_methods/</link>
      <description><![CDATA[在过去的几个月里，我阅读了有关执行 LLM 采样的各种算法。我决定构建自己的推理堆栈并实现这些算法。 这是 Github 仓库 - https://github.com/shreyansh26/LLM-Sampling 该仓库包括 Top-k、Top-p（核心）、Min-p、典型、Epsilon、Eta、Beam 搜索、Chain-of-Thought (CoT) 解码、Constrained JSON 解码和 Speculative 解码的实现。 就我个人而言，我发现这是一个很好的学习经历。在这里分享，以防它对某人有帮助！    提交人    /u/shreyansh26   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9fe8q/d_a_collection_of_various_llm_sampling_methods/</guid>
      <pubDate>Sun, 08 Dec 2024 09:39:17 GMT</pubDate>
    </item>
    <item>
      <title>[P] 🥂 FineWeb2 数据集：包含数千种语言的闪亮更新</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h9ep0e/p_fineweb2_dataset_a_sparkling_update_with_1000s/</link>
      <description><![CDATA[    /u/PhilipsNostrum   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h9ep0e/p_fineweb2_dataset_a_sparkling_update_with_1000s/</guid>
      <pubDate>Sun, 08 Dec 2024 08:47:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>