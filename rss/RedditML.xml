<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升</description>
    <lastBuildDate>Fri, 22 Mar 2024 15:13:07 GMT</lastBuildDate>
    <item>
      <title>[D] PuzzleVQA：用抽象视觉模式诊断语言模型的多模态推理挑战</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bl12g2/d_puzzlevqa_diagnosing_multimodal_reasoning/</link>
      <description><![CDATA[数据集：https ://github.com/declare-lab/LLM-PuzzleTest/tree/master/PuzzleVQA 论文：https://arxiv.org/abs/2403.13315 大型多模态模型通过集成多模态理解能力扩展了大型语言模型的令人印象深刻的功能。然而，目前尚不清楚它们如何模仿人类的一般智力和推理能力。由于识别模式和抽象概念是通用智能的关键，因此我们推出了 PuzzleVQA，这是一组基于抽象模式的谜题。通过此数据集，我们根据基本概念（包括颜色、数字、大小和形状）评估具有抽象模式的大型多模态模型。通过我们对最先进的大型多模态模型的实验，我们发现它们无法很好地推广到简单的抽象模式。值得注意的是，即使是 GPT-4V 也无法解决一半以上的难题。为了诊断大型多模态模型中的推理挑战，我们逐步用视觉感知、归纳推理和演绎推理的真实推理解释来指导模型。我们的系统分析发现，GPT-4V的主要瓶颈是视觉感知和归纳推理能力较弱。通过这项工作，我们希望阐明大型多模态模型的局限性以及它们如何在未来更好地模拟人类认知过程。   由   提交 /u/sgpfc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bl12g2/d_puzzlevqa_diagnosing_multimodal_reasoning/</guid>
      <pubDate>Fri, 22 Mar 2024 14:49:32 GMT</pubDate>
    </item>
    <item>
      <title>[d] 在没有标记数据集的情况下评估无监督分类器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bl050h/d_evaluate_unsupervised_classifier_without/</link>
      <description><![CDATA[大家好，我正在开发一个机器学习项目，我必须使用 ECM 分类器来给出结果。结果我的公司没有标记的数据集来比较我的结果。我在机器学习方面没有太多经验。有没有办法可以在没有标记数据的情况下为我的公司提供一些评估指标，例如精确度、召回率混淆矩阵？如果不是（似乎是这样）我还可以使用哪些其他方法来显示我的算法有多好？   由   提交/u/No_Context_6938   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bl050h/d_evaluate_unsupervised_classifier_without/</guid>
      <pubDate>Fri, 22 Mar 2024 14:09:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每日 ML 新闻的精彩合集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bl0274/d_a_great_collection_of_daily_ml_news/</link>
      <description><![CDATA[有关 Python 的最新新闻和文章的精彩集合： https://www.techontheedge.com/searchmore/machinelearning/ 也可使用移动应用程序：  iOS  Android    由   提交 /u/SEYsto   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bl0274/d_a_great_collection_of_daily_ml_news/</guid>
      <pubDate>Fri, 22 Mar 2024 14:05:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 目前评估法学硕士的局限性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkz0od/d_the_current_limitation_of_evaluating_llms/</link>
      <description><![CDATA[在分析LLM的性能时，大多数相关论文都使用Loss per FLOPs和基准表（例如GLUE、Perplexity等）。 ）。 但是每 FLOP 的损失不能表明整个验证损失，并且基准测试不能证明它如何在实证事件中工作。 例如，无论什么情况，损失都可以更低其数据集的质量，必须有可靠的基准。 此外，我们不知道在不过度拟合公共研究数据集的情况下基准如何可靠。 在这种情况下，什么是您是否有洞察力来根据您所在领域的研究价值来挑选更好的论文？   由   提交/u/Mundane_Definition_8  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkz0od/d_the_current_limitation_of_evaluating_llms/</guid>
      <pubDate>Fri, 22 Mar 2024 13:17:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有“完整”LLMOps 的资源或存储库吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkyr87/d_any_resources_or_repos_of_complete_llmops/</link>
      <description><![CDATA[您好， 因此，我的团队希望探索在生产中应用法学硕士，但我们根本不知道从哪里开始堆栈的术语。您能否推荐一些资源，以便我能够为 LLMOps 的外观打下坚实的基础？谢谢！   由   提交 /u/TheCockatoo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkyr87/d_any_resources_or_repos_of_complete_llmops/</guid>
      <pubDate>Fri, 22 Mar 2024 13:04:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我有一个 GPU 集群可供出租</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkygxz/d_i_have_a_gpu_cluster_to_offer_for_rent/</link>
      <description><![CDATA[您好， 我有一个带有 8 个 GPU 的 RIG，但我没有使用，您是否有任何建议的机制如何让它发挥作用？我听说有些平台可以让您向其他人提供您的硬件。有人有这方面的经验吗？ 谢谢！   由   提交 /u/ElGranCapitanBetal   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkygxz/d_i_have_a_gpu_cluster_to_offer_for_rent/</guid>
      <pubDate>Fri, 22 Mar 2024 12:50:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人们使用什么来编排频繁的模型重新训练和部署？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkx2it/d_what_are_people_using_for_orchestration_of/</link>
      <description><![CDATA[我的团队有一些正在生产的模型，其中每隔几周就会临时进行一次模型重新训练。我们运行训练，使用 MLFlow 进行跟踪（不使用 MLFlow 的模型注册表），然后如果我们想要部署新模型，我们手动更新应用程序存储库中的模型标签，创建新的应用程序映像，从 s3 下载新模型工件，然后部署。  这对我们来说效果很好。问题是，我们即将开展一个项目，每天可能需要多次重新训练模型，因此显然当前的工作流程将无法工作。  人们使用什么来协调这些大规模、频繁的再培训和部署？我们正在考虑使用托管 AirFlow 实例和 MLFlow 模型注册表，但我对其他想法持开放态度，例如 MetaFlow 或 MLOps 动物园中的任何其他工具  &amp; #32；由   提交/u/stephenfenel  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkx2it/d_what_are_people_using_for_orchestration_of/</guid>
      <pubDate>Fri, 22 Mar 2024 11:32:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] 如何用更少的 GPU 内存训练神经网络：可逆残差网络回顾</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkv29x/r_how_to_train_a_neural_network_with_less_gpu/</link>
      <description><![CDATA[探索可逆残差网络的有趣方法。 OpenCV.ai 团队的新文章回顾了一种减少 GPU 内存需求的方法在神经网络训练期间。您将发现可逆残差网络在神经网络训练期间如何节省 GPU 内存。该技术在“可逆残差网络：无需存储激活的反向传播”中详细描述。通过不存储反向传播的激活，可以有效地训练更大的模型。了解其在降低硬件要求方面的应用，同时保持 CIFAR 和 ImageNet 分类等任务的准确性。   由   提交/u/Human_Statistician48   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkv29x/r_how_to_train_a_neural_network_with_less_gpu/</guid>
      <pubDate>Fri, 22 Mar 2024 09:21:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 首次参加 ICLR 2024 会议的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkqxms/d_advice_for_attending_iclr_2024_as_a_first/</link>
      <description><![CDATA[嗨，我是一名大三学生，非常幸运，被邀请参加 ICLR 的研讨会。我计划参加整个会议。我想知道是否有人对第一次参加会议的人有建议，以便我能够充分利用它。 我也对博士学位感兴趣，但在大学的前两年过得很艰难。与 ICLR 其他学校的教授交谈会有帮助吗？   由   提交 /u/mathwoman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkqxms/d_advice_for_attending_iclr_2024_as_a_first/</guid>
      <pubDate>Fri, 22 Mar 2024 04:30:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当前小型（例如，<10,000 个参数）语言模型中最好的是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkqd2q/d_what_is_the_current_best_in_tiny_say_10000/</link>
      <description><![CDATA[显然，我们都听说过大语言模型，甚至听说过“小”语言模型。语言模型非常大（通常&gt; 100万个参数）。显然（除非我严重误解了语言模型的工作原理），你至少需要与词汇量一样多的参数（因为人们可以想象的最基本的模型只是为每个后续的概率分配一个固定的概率）单词，无论上下文如何 - 显然任何有用的模型都会做比这更复杂的事情）。 但我想知道小型模型的最新技术是什么，以前存在的模型的大小“大数据”甚至是一个已经被创造出来的短语。我知道这现在可能是一个小众的事情，业内很少有人致力于此。但我认为（或者至少我希望）至少仍然有爱好者在业余时间从事此类工作，就像仍然有人为 NES 编写自制游戏一样。 我&#39;我正在谈论一种可以在几个下午内在 C/C++ 中从头开始构建的模型（模型和训练算法），而不使用任何第三方依赖项/框架，可以进行训练和推理，甚至不需要显卡等。最重要的是，什么架构在这些限制下工作得最好？当限制在这个大小时，有什么能打败 HMM、n-gram 模型等吗？   由   提交/u/math_code_nerd5   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkqd2q/d_what_is_the_current_best_in_tiny_say_10000/</guid>
      <pubDate>Fri, 22 Mar 2024 03:58:26 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ML 研讨会/会议推荐：不是 AAI、IJCAI、NeuRips 或 ICML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bkdsi2/discussion_ml_workshopconference_recommendation/</link>
      <description><![CDATA[这里是博士生。我尝试在 AAI-22、IJCAI-23、NeuRIPS-23 和 ICML-24 上发表我的论文。每次我处理这些评论时，我的分数都会更低。我做了表格数据——他们要求计算机视觉，我就这么做了。现在，他们要求语音识别。它在哪里停止？最重要的是，有些评论感觉他们在审稿时根本没有读过论文。这两年我一直在做这方面的工作，发表了几篇论文。我很累，整个过程都筋疲力尽。有人可以推荐一些 2024 年排名较低但可以接受的 ML 会议或信誉良好的研讨会吗？我想发布并完成这个工作。    由   提交/u/Conscious-Media3207  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bkdsi2/discussion_ml_workshopconference_recommendation/</guid>
      <pubDate>Thu, 21 Mar 2024 18:35:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有准确的AI工具进行研究？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk9aw0/d_is_there_an_accurate_ai_tool_for_research/</link>
      <description><![CDATA[我所在的领域需要大量数据分析和最新信息。我尝试过 Perplexity、ChatGPT 和 Bard 等工具，但结果各不相同。他们都有过自己的时刻，但没有一个是始终准确的，而不断检查它们是否准确就违背了使用人工智能工具的初衷。我遇到过一些问题，例如误解上下文以及反馈给我的不相关信息。我最近在寻找有关量子计算的信息，但只收到过时的参考资料。 同样，必须验证我得到的所有内容，这让我回到了最初的问题，我宁愿不完全使用人工智能工具。那么有没有真正的替代方案，或者我对独角兽的要求太多了？理想情况下，我正在寻找一个能够处理复杂主题并与最新出版物保持同步的人。  感谢您的帮助！   由   提交 /u/energetic_slugger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk9aw0/d_is_there_an_accurate_ai_tool_for_research/</guid>
      <pubDate>Thu, 21 Mar 2024 15:31:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 评论已发布。来！我们讨论一下！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk7u47/d_icml_reviews_are_released_lets_discuss/</link>
      <description><![CDATA[ 您收到了多少评论？ 他们的评分是多少？ （分数/置信度）  以下是审阅说明供参考：https://icml .cc/Conferences/2024/ReviewerInstructions   由   提交/u/tfburns  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk7u47/d_icml_reviews_are_released_lets_discuss/</guid>
      <pubDate>Thu, 21 Mar 2024 14:28:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 发布“1 位法学硕士时代”的培训代码及更多内容</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bk32ye/d_training_code_and_more_released_for_the_era_of/</link>
      <description><![CDATA[不幸的是，微软没有发布权重，但如果权重介于权重和训练代码之间，那么这当然是更好的选择。 这篇文章在这里。  我们怎么想？关于形状奇怪的损失曲线有什么想法吗？您认为这种方法在 4B 参数之后会失效吗？法学硕士如何在如此低的精度下工作？我知道这不是特别科学，但对我来说，你可能会在几张 CD 上安装一个功能齐全的 7B 参数模型，这似乎相当违反直觉……然而最重要的是，谁有价值 100,000 美元的计算来实际测试这个？   由   提交 /u/DickMasterGeneral   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bk32ye/d_training_code_and_more_released_for_the_era_of/</guid>
      <pubDate>Thu, 21 Mar 2024 10:09:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1bbcaq5/d_simple_questions_thread/</guid>
      <pubDate>Sun, 10 Mar 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>