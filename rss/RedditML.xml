<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 - >/r/mlquestions或/r/r/learnmachinelearning，agi->/r/singularity，职业建议 - >/r/cscareerquestions，数据集 - > r/数据集</description>
    <lastBuildDate>Wed, 09 Apr 2025 12:36:43 GMT</lastBuildDate>
    <item>
      <title>[D]您如何监视AI代理或LLM应用程序？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jv2zxc/d_how_do_you_monitor_your_ai_agents_or_llm_apps/</link>
      <description><![CDATA[I’m curious how others are monitoring and tracking LLM-based apps or AI agents, especially as they get more complex with RAG, tool use, or user input. Do you track things like:  Token usage Latency Error rates Prompt version changes ...或其他任何与性能/成本相关的指标？  您是否为此使用了工具，还是您自己构建了自己的东西？ 很想听听（或者不适合您的），甚至轻量级的解决方案或痛苦点。提交由＆＃32; /u/yersyas     [links]     &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jv2zxc/d_how_how_do_do_you_you_you_your_your_your_your_ai _ai_aigents_aigents_or_llm_llm_apps/]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jv2zxc/d_how_do_you_monitor_your_ai_agents_or_llm_apps/</guid>
      <pubDate>Wed, 09 Apr 2025 11:01:08 GMT</pubDate>
    </item>
    <item>
      <title>[p]阳阳的分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1juxjwk/p_yinyang_classification/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在yin-yang数据分类中混乱并将其扔进回购中。 链接：https://github.com/mavleo96/yin-yang-classification Please do comment your thought and any suggestion on what else might be interesting to visualize here — and feel free to star the repo if it&#39;s interesting / helpful. &lt;!-- sc_on-&gt;＆＃32;提交由＆＃32; /u/u/mavleo96     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1juxjwk/p_yinyang_classification/</guid>
      <pubDate>Wed, 09 Apr 2025 04:35:52 GMT</pubDate>
    </item>
    <item>
      <title>[p]减少变压器训练时间而不牺牲准确性 - 一种动态架构更新方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jurarc/p_reducing_transformer_training_time_without/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，大家！ 我一直在研究一个研究项目，致力于将变压器模型优化为 减少训练时间而不损害准确性。 🚀 通过这项工作，我开发了一种新颖的方法，该方法在训练过程中动态更新其体系结构，使其能够更快地收敛，同时仍保持性能。可以将其视为自适应缩放，但更聪明 - 我们不仅在任意地降低尺寸，而且在Fly fly 。。。。。。。。。我最近发表了一篇媒介的文章，解释了方法的一部分：我如何在减少培训时间后保持模型的准确性稳定，即使在训练时间。如果您对技术细节感兴趣或只是想讨论优化策略，我很乐意检查一下！  媒介 ： https://medium.com/me/me/stats/post/e74449c3d7ccf  href =“ https://github.com/suparshwa31/dynamic_transformer”&gt; https://github.com/suparshwa31/dynamic_transformer       会喜欢反馈，想法，甚至可以免费打开您的想法，或者可以免费打开您的想法。总是很乐意讨论！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/suparshwa1     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jurarc/p_reducing_transformer_training_time_without/</guid>
      <pubDate>Tue, 08 Apr 2025 23:06:39 GMT</pubDate>
    </item>
    <item>
      <title>[d]如何处理关于我在海报会议演示中没有直接从事的协作研究项目的问题的问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jukunq/d_how_to_handle_questions_about_parts_of_a/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在介绍我专注于实验结果/代码库的研究，但我们的论文包括合作者的理论工作。我如何回答有关我没有处理的部分的问题？   可以说可以说，‘这个方面是由[名字]领导的 - 我可以解释它如何与我的实验联系在一起？     我对别人的贡献有什么详细介绍吗？不屑一顾？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/neotod1     [link]   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jukunq/d_how_to_handle_questions_about_parts_of_a/</guid>
      <pubDate>Tue, 08 Apr 2025 18:30:52 GMT</pubDate>
    </item>
    <item>
      <title>[d] ML的合成介绍数学博士学位学生</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1juft4t/d_synthetic_introduction_to_ml_for_phd_student_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嗨， 我即将开始我的数学博士学位，而我的主管当前项目是调查某些ni基线性代数工具的可行性，以使机器学习的设置，尤其是pinns。但是我缺乏ML。 href =“ https://books.google.it/books/about/pattern_recognition_and_machine_learning.html？学习，我发现这两本书都过多冗长而冗长。 我确实很欣赏这些书的丰富示例和迷人方法，但是我需要对该主题进行理​​论上的掌握。  我正在寻找有关针对研究生的数学严谨性写作的主题的替代资源。  您有什么要建议的，无论是书籍，讲义还是视频讲座？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/trijack2357     [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1juft4t/d_synthetic_introduction_to_ml_for_ml_for_phd_student_in/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1juft4t/d_synthetic_introduction_to_ml_for_phd_student_in/</guid>
      <pubDate>Tue, 08 Apr 2025 15:06:02 GMT</pubDate>
    </item>
    <item>
      <title>[n]生物医学数据科学暑期和会议（7月28日至8月8日，布达佩斯，匈牙利）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1juf66b/n_biomedical_data_science_summer_school/</link>
      <description><![CDATA[    src =“ https://b.thumbs.redditmedia.com/yyh3u3u3wcgz7ckdhic11t4lcxwayxhf3q5l4z7ofc1vw.jpg“ title =“ [n]生物医学数据科学夏季学校＆Amp; Amp; amp; amp; amp; amp; amp; 7月28日 -  8月28日，  加入我们的生物医学数据科学暑期学校＆amp; Conference between July 28 – August 8, 2025, in Budapest! Summer School (July 28 – August 5) – 7-day intensive training in English – Topics: medical data visualization, machine learning and deep learning of medical data, biomedical network – Earn 4 ECTS – Learn from world-renowned experts, including Nobel Laureate Ferenc Krausz 早鸟注册截止日期：2025年5月20日 会议（8月6日至8日）   - 鼓舞人心的科学演讲，展示了尖端研究  - 主题演讲者：KatyBörner，Albert-LászlóBarabási截止日期：2025年4月30日 无论您是学生，研究员还是专业人士，这都是您探索生物医学数据科学的最前沿！ 更多信息＆amp;注册： https://www.biomed-data.semmelweis.hu/  提交由＆＃32; /u/u/konderal333       [注释]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1juf66b/n_biomedical_data_science_summer_school/</guid>
      <pubDate>Tue, 08 Apr 2025 14:39:40 GMT</pubDate>
    </item>
    <item>
      <title>[P]在不同硬件上某些LLM的性能转移的见解</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1judb8u/p_insights_in_shift_of_performance_of_certain/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  你好， ，我对学校进行了一些简单的性能测试，其中有几个LLM，一个在带有RTX2060的桌面上，另一个在Raspberry Pi5上进行。我试图理解数据，但仍然有几个问题，因为我不是该领域的理论专家。 在桌面llama3.2：1b上比我测试过的任何其他模型都做得更好，但是当我在raspberry pi上测试了相同的提示时，第二个问题是第二个问题。其他模型，这仅仅是因为它是一个MOE模型，它取决于它激活的模型的哪一部分？ 我测试过的所有模型都足够小，足以适合2060的6GB VRAM和PI的8GB系统RAM的8GB。     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/forade-ad-5955     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1judb8u/p_insights_in_shift_of_performance_of_certain/</guid>
      <pubDate>Tue, 08 Apr 2025 13:16:44 GMT</pubDate>
    </item>
    <item>
      <title>[D]比较Genai推断引擎：Tensorrt-llm，VLLM，拥抱Face TGI和LMDEPLOY</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1juay0t/d_comparing_genai_inference_engines_tensorrtllm/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，大家，我一直在NLP云中潜入了一段时间的生成AI推理引擎的世界，我想分享一些比较中的见解。我查看了四个流行的选择：Nvidia的Tensorrt-llm，VLLM，Hugging Face的文本生成推断（TGI）和LMDEPLOY-并进行了一些基准测试，以查看它们如何堆叠用于现实世界中用例。认为这可能会引发一些讨论，因为我知道很多人正在使用LLMS或优化推理管道：  tensorrt-llm      nvidia的野兽，用于gpu-accelerated推断。它基于张力，它通过层融合，精确调整（FP16，INT8，甚至FP8）和自定义CUDA内核进行优化。  PROS：PROS：在NVIDIA GPUS上快速燃烧 - 在A100和〜700 TOKENS/sec sec的单个请求中，均可在NVIDIA GPUS上快速延迟，均可用〜700 cossecter-sec sec-sec-sec-sec-sec-sec Q4 llama-blama-blama-blama-bame sec 3 30（基准）。动态批处理和与Triton推理服务器的紧密集成使其成为吞吐量怪物。  cons：如果您还没有在NVIDIA生态系统中，设置可能很复杂。您需要处理模型汇编，并且对于快速原型制作而言，它并不是超级灵活的。   vllm    开放式冠军冠军进行高通量推广。使用pageNationention来管理块中的KV缓存，切割记忆浪费和提高速度。 专利：易于旋转（PIP安装，python友好），并且灵活 - 在NVIDIA，AMD，AMD，甚至CPU上。吞吐量为固体（〜600-650代币/秒，在100个用户中，对于Llama-3 70B Q4），而动态批处理使其保持嗡嗡声。潜伏期在60-80ms独奏中的体面。  cons：它对单重点延迟的优化程度较低，因此，如果您一次与一个用户建立聊天机器人，则可能不会太多。另外，它仍在成熟 - 可能不支持某些边缘案例（例如异国模型架构）。  拥抱脸部TGI   拥抱Face Face的生产准备的推理工具。连接其模型中心（Bert，GPT等），并使用Rust for Speed，并连续批处理使GPU忙碌。  PROS：DOCKER设置很快，并且可以很好地缩放。延迟的50-70ms，吞吐量与VLLM匹配（约600-650个令牌/秒，用100个用户）。奖金：安全性的内置输出过滤。如果您已经在HF生态系统中。 缺点：比tensorrt-llm少的原始速度，并且内存可以用大批量膨胀。在HF的世界之外感觉有些限制。   lmdeploy   这个工具包来自Mmrazor/mmdeploy Crew，重点是快速，有效的LLM部署。具有Turbomind（高性能发动机）和Pytorch后卫，具有持续的批处理和速度的KV缓存。  PROS：解码速度是疯狂的 - 比A100上的VLLM多于1.8倍/秒。 Turbomind以比FP16快的2.4倍推动4位推断，在100个用户（Llama-3 70B Q4）上击中约700个令牌/秒。低延迟（40-60ms），简单的单command服务器设置，甚至通过缓存历史记录有效地处理多轮聊天。  cons：Turbomind的挑剔 - 不支持滑动窗户的注意（例如，Mistral）。非NVIDIA用户会被较慢的Pytorch发动机陷入困境。尽管如此，在Nvidia GPU上，这是一个性能野兽。  您可以在此处阅读完整的比较： https://nlpcloud.com/genai-inference-engine-engines-tensorrt-llm-vs-vlm-vs-hugging-face-face-face-tgi-vs-lmdeploy.html   您对这些工具有什么经验？我错过了任何隐藏的问题吗？还是应该提到的其他推理引擎？很想听听您的想法！  Julien   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/juliensalinas     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1juay0t/d_comparing_genai_inference_engines_tensorrtllm/</guid>
      <pubDate>Tue, 08 Apr 2025 11:09:57 GMT</pubDate>
    </item>
    <item>
      <title>[r]超越接下来的令牌：通过有效的多token预测来迅速射击零射击分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ju8923/r_beyond_the_next_token_towards_promptrobust/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   零弹声文本分类通常依赖于及时的工程，但是在矿山下，大语言模型的固有及时的迅速易用性。提示的微小变化可能会导致模型性能的严重差异。我们将这种提示性的脆性归因于现有方法中的隔壁概率的狭义重点。为了解决这个问题，我们提出了一个新颖的方法（P3），这是一种新的方法，可以预测跨多个位置的令牌概率，并模拟单个语言模型的单个运行中的发电路径的全面抽样。实验表明，在提示中，标准偏差提高了准确性，并降低了98％的降低，从而提高了鲁棒性。即使没有提示，P3仍保持可比性的性能，减少了及时工程的需求。  有趣的论文有关改善ML模型中的确定性的有趣论文，并避免“及时brittleness”使用占位符和平行的预测，而不是仅依靠下一步的概率。 纸链接： https：// https：//arxiv.org.org/arxiv.orgs/arxiv.orgs/arxiv.orgs/2504.034.0344.03159 /u/hiskuu     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ju8923/r_beyond_the_next_token_towards_promptrobust/</guid>
      <pubDate>Tue, 08 Apr 2025 07:57:25 GMT</pubDate>
    </item>
    <item>
      <title>[d] LLM的回归头非常出色！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ju5g9d/d_a_regression_head_for_llm_works_surprisingly/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在训练我为视觉接地任务编写的一个小的33m vit+解码器模型，当从头开始训练时，我通过在LM头之前向嵌入式介绍了一个Zentruce Scratch的成功，以获得LM头的准确性。  All the literature (such as: https://arxiv.org/html/2501.19383v1) I could find directly works with particular tokens and cross entropy loss from what I gathered.  我通过在LM_head结果（用于点令牌）上共同进行跨熵并在最后一个嵌入层上引入回归头并进行回归损失，从而获得了个人项目的成功。  我最初煮了它，但这是已知的吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/smalltimecsguy     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ju5g9d/d_a_regression_head_for_llm_works_surprisingly/</guid>
      <pubDate>Tue, 08 Apr 2025 04:42:18 GMT</pubDate>
    </item>
    <item>
      <title>[p] [d]为什么我的GNN-LSTM模型无法通过完整的培训数据来概括为时空预测任务？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jtwdn8/p_d_why_does_my_gnnlstm_model_fail_to_generalize/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jtwdn8/p_d_why_does_my_gnnlstm_model_fail_to_generalize/</guid>
      <pubDate>Mon, 07 Apr 2025 21:07:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] HAI人工智能指数报告2025：AI种族变得拥挤了，中国正在美国近乎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jtoegy/d_hai_artificial_intelligence_index_report_2025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  斯坦福大学的人类人为AI（hai）今天发表了一份新的研究论文，该论文彰显了该领域的挤压。 href =“ https://macro.com/app/pdf/e10d9df1-f1-f135-4681-b377-8a6c72ec07f8/”&gt; hai人工智能索引报告2025  improve. AI is increasingly embedded in everyday life. Business is all in on AI, fueling record investment and usage, as research continues to show strong productivity impacts. The U.S. still leads in producing top AI models—but China is closing the performance gap. The responsible AI ecosystem evolves—unevenly. 全球AI乐观态度正在上升，但仍有深层区域鸿沟。收紧。  AI因其对科学的影响而获得最高荣誉。 复杂的推理仍然是一个挑战。    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/1jtoegy/d_hai_artercover_intelligence_index_report_2025/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jtoegy/d_hai_artificial_intelligence_index_report_2025/</guid>
      <pubDate>Mon, 07 Apr 2025 15:44:24 GMT</pubDate>
    </item>
    <item>
      <title>[p] docext：开源，本地文档智能，由视觉模型提供支持</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jtjw2b/p_docext_opensource_onprem_document_intelligence/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们很高兴开放源 docext ，一种零o的内部，本地工具，用于从发票，护照等文档中提取结构化数据，诸如云，无云，无需外部apis，不需要外部apis， by  by   docext 在视觉和语义上了解文档以提取字段数据和表格 - 直接从文档图像中。 全部运行它，以全部运行，以进行完整的数据隐私和控制。   关键功能：    custom＆amp;预构建的提取模板 表 +现场数据提取  gradio-power-power Web界面 与REST API  多页文档支持 置信度得分 用于提取字段的置信得分                 docext 帮助您在几分钟内将它们变成可用的数据。尝试一下：     pip install docext 或通过docker  用 python -m code&gt;   旋转Web UI href =“ https://github.com/nanonets/docext”&gt;  docext.app.app.app.app       https://github.com/nanonets/docext  问题？功能请求？打开问题或开始讨论！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/souvikmandal     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jtjw2b/p_docext_opensource_onprem_document_intelligence/</guid>
      <pubDate>Mon, 07 Apr 2025 12:20:48 GMT</pubDate>
    </item>
    <item>
      <title>[d]自我促进线程</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  请发布您的个人项目，初创企业，产品安排，协作需求，博客，博客等。禁止。 鼓励其他人创建新帖子以便在此处发布问题！ 线程将一直活着直到下一步，因此在标题日期之后继续发布。   -     meta：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为了鼓励社区中的人们不要通过垃圾邮件来促进他们的工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jpdo7y/d_selfpromotion_thread/”&gt; [link]   ＆＃32;   [commist]  ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jpdo7y/d_selfpromotion_thread/</guid>
      <pubDate>Wed, 02 Apr 2025 02:15:32 GMT</pubDate>
    </item>
    <item>
      <title>[D]每月谁在招聘，谁想被聘用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   为职位发布请使用此模板  雇用：[位置]，薪水：[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]和[简要概述，您要寻找的是]    对于那些寻求工作的人请使用此模板  想要被录用：[位置]，薪水期望，[]，[]，[]，[]，[]，[]，[]，[远程|搬迁]，[全职|合同|兼职]简历：[链接到简历]和[简要概述，您要寻找的是]   ＆＃＆＃＆＃＆＃＆＃＆＃＆＃＆＃x200B;  请记住，请记住，这个社区适合那些有经验的人。   &lt;！ -  sc_on--&gt; 32;&gt; 32;提交由＆＃32;态href =“ https://www.reddit.com/r/machinelearning/comments/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_be_hired/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/machinelearning/comments/1jnt4sp/d_monthly_whos_hiring_and_and_and_who_wants_wants_to_to_be_hired/”]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1jnt4sp/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Mon, 31 Mar 2025 02:30:37 GMT</pubDate>
    </item>
    </channel>
</rss>