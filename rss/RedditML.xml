<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Mon, 08 Jan 2024 06:19:01 GMT</lastBuildDate>
    <item>
      <title>[D] - OpenAI 的 Assistants API 是如何实现的，以及如何使用本地法学硕士实现操作和知识文件读取？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191dwz0/d_how_is_assistants_api_of_openai_made_possible/</link>
      <description><![CDATA[TLDR：使用本地 LLM 复制 Assistant API 的所有功能以及您可能想到的任何其他功能。  我想问的是以下内容，如果我的逻辑存在缺陷，我希望得到反馈。提高我的理解力对我来说很重要，我正在寻求您的智慧。  他们如何给出自定义指令？我认为这相当于“系统” Chat API 中的消息，那么“系统”如何处理？消息架构有效吗？ 模型如何决定使用哪个操作，并假设 read_knowledge_files() 函数存在于其不可见操作列表中，它如何决定何时以及如何执行那？ 知识文件内容是否在某种程度上微调了模型响应的方式，或者只是按需读取文件？  如果我期望的最终目标是使用相同的框架（选择操作，甚至使用不同的操作模型，从大文件中检索知识，决定何时使用大文件中的知识）使用其他框架，我如何复制大部分操作我可以在本地运行法学硕士吗？我不在乎是否能让两个法学硕士互相交谈，这很容易。   我不明白动作选择和知识文件访问决策/执行机制、系统消息。 谢谢大家！我的计划是准备一个框架，直到gpt4等效的开源模型出来。   由   提交/u/Text-Agitated  /u/Text-Agitated reddit.com/r/MachineLearning/comments/191dwz0/d_how_is_assistants_api_of_openai_made_possible/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191dwz0/d_how_is_assistants_api_of_openai_made_possible/</guid>
      <pubDate>Mon, 08 Jan 2024 05:47:22 GMT</pubDate>
    </item>
    <item>
      <title>缩放会起作用吗？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191ddbw/will_scaling_work_d/</link>
      <description><![CDATA[       由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191ddbw/will_scaling_work_d/</guid>
      <pubDate>Mon, 08 Jan 2024 05:16:39 GMT</pubDate>
    </item>
    <item>
      <title>[新闻] 具有自然语言能力的个人机器人助手是谷歌能力的未来吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191ccbb/news_are_natural_language_capable_personal_robot/</link>
      <description><![CDATA[    /u/Anirban_Hazra   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191ccbb/news_are_natural_language_capable_personal_robot/</guid>
      <pubDate>Mon, 08 Jan 2024 04:21:40 GMT</pubDate>
    </item>
    <item>
      <title>[P]我对变压器架构的解释。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191axx1/pmy_go_at_explaining_the_transformer_architecture/</link>
      <description><![CDATA[使用 Pytorch 代码了解 Transformer 架构 代码：https://github.com/ashish -s-bisht/TransformerArchitecturePytorch ​   由   提交 /u/GoofyRoach   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191axx1/pmy_go_at_explaining_the_transformer_architecture/</guid>
      <pubDate>Mon, 08 Jan 2024 03:09:48 GMT</pubDate>
    </item>
    <item>
      <title>将 XGBoost 模型转置为 Excel [项目]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1917xgg/transpose_xgboost_model_to_excel_project/</link>
      <description><![CDATA[您好， 我有兴趣将 XGBoost 模型导出到 Excel。我使用 caret 包和 XGBoost 包在 R 中创建了一个 XGBoost 模型。最终模型包括 50 个决策树。我在想，我基本上可以通过在 excel 中制作 if-then 语句，将所有决策树手动转置到 excel 中（我将有一行 50 个值，每个值都是代表决策树的 if-then 语句）。我尝试手动执行此操作，但很难解决为什么我的预测在 Excel 中不正确。我有几个问题  XGBoost 如何从所有决策树中确定最终得分。是平均值还是求和？ 是否有任何简单的方法可以将 XGBoost 模型转换为 Excel，或者我只是想尝试这个。  谢谢大家的支持帮助   由   提交 /u/Ermundo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1917xgg/transpose_xgboost_model_to_excel_project/</guid>
      <pubDate>Mon, 08 Jan 2024 00:49:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当遇到 NaN 损失时，Keras EarlyStoppingCallback 是否会恢复最佳权重？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1917oz8/d_does_keras_earlystoppingcallback_restore_best/</link>
      <description><![CDATA[我知道有一个名为 TerminateOnNaN 回调的回调，并且我知道由于梯度爆炸而导致的 NaN。我不想使用此回调的原因是，如果我的直觉是正确的，爆炸梯度可能会下降。所以我的问题是：  梯度爆炸后是否有可能不爆炸（意味着回到 2^32 以下）？ Keras EarlyStoppingCallback 是否会恢复最佳权重，如果/当遇到NaN损失时？    由   提交 /u/StellaarMonkey   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1917oz8/d_does_keras_earlystoppingcallback_restore_best/</guid>
      <pubDate>Mon, 08 Jan 2024 00:38:31 GMT</pubDate>
    </item>
    <item>
      <title>[R] V*：引导视觉搜索作为多模式法学硕士 (SEAL) 的核心机制 - 纽约大学 2023 - 在搜索视觉细节方面比 GPT-4V 好 25%！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/191652a/r_v_guided_visual_search_as_a_core_mechanism_in/</link>
      <description><![CDATA[   论文：https://arxiv.org/abs/2312.14135v2  Github：https： //github.com/penghao-wu/vstar  摘要：  当我们环顾四周并执行复杂任务时，我们如何看待并选择性地处理什么我们看到至关重要。然而，当前的多模态法学硕士（MLLM）缺乏这种视觉搜索机制，阻碍了他们专注于重要视觉细节的能力，特别是在处理高分辨率和视觉拥挤的图像时。为了解决这个问题，我们引入了 V*，一种 LLM 引导的视觉搜索机制，它利用 LLM 中的世界知识来进行高效的视觉查询。当与 MLLM 结合使用时，该机制可以增强协作推理、上下文理解以及特定视觉元素的精确定位。这种集成产生了一个新的 MLLM 元架构，名为 Show、sEArch 和 TelL (SEAL)。我们进一步创建了 V*Bench，这是一个专门设计用于评估 MLLM 处理高分辨率图像和关注视觉细节的能力的基准。 我们的研究强调了将视觉搜索功能纳入多模态系统的必要性。   https://preview.redd.it/0b78lih1r3bc1.jpg?width=1663&amp;format=pjpg&amp;auto=webp&amp;s=786702884305 88cfee2db280cb75e348254ec0eb https://preview。 redd.it/8kap1jh1r3bc1.jpg?width=1661&amp;format=pjpg&amp;auto=webp&amp;s=d6e8a372cd91976e6e35710d32992a443981f06e https://preview.redd.it/oakf3lh1r3bc1.jpg?width=1247&amp;format=pjpg&amp;auto=webp&amp;s=612ab61b763 254f5cabb3a93990cc5baa2a917e3&lt; /a&gt; https:// Preview.redd.it/mta8emh1r3bc1.jpg?width=653&amp;format=pjpg&amp;auto=webp&amp;s=209871901bf2ba26537b1587c4be388df055f30b   由   提交/u/Singularian2501  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/191652a/r_v_guided_visual_search_as_a_core_mechanism_in/</guid>
      <pubDate>Sun, 07 Jan 2024 23:30:52 GMT</pubDate>
    </item>
    <item>
      <title>[D]机器学习的学术经验过渡到企业界，我在哪里可以找到项目的示例？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/19136cc/dacademic_experience_in_machine_learning/</link>
      <description><![CDATA[我已经担任程序员大约 5 年了，一直在移动领域（Swift/Android）工作。 2021 年底，我完成了机器学习硕士学位，并希望继续在这个领域工作。我在该领域拥有扎实的知识，通常在 Kaggle 上学习和创建模型，但我主要关注学术方面。我有兴趣了解这些模型如何在现实的企业环境中使用。有谁知道我是否可以在 GitHub 上找到类似的东西？   由   提交/u/Substantial_Fact_205   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/19136cc/dacademic_experience_in_machine_learning/</guid>
      <pubDate>Sun, 07 Jan 2024 21:31:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] LiDAR 和分割</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190z1o4/p_lidar_and_segmentation/</link>
      <description><![CDATA[大家早上好。有人使用过 LiDAR 并且有经验可以帮助我吗？我需要使用激光雷达提取的点云来计算物品的体积。然而，图像中将会有多个对象。我如何选择我感兴趣的对象？我应该用某种模型分割原始图像中的对象，然后在点云中定位该对象，还是应该只使用带有点云的图像？   由   提交 /u/gr_ferro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190z1o4/p_lidar_and_segmentation/</guid>
      <pubDate>Sun, 07 Jan 2024 18:42:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 更快地阅读机器学习论文的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190vo6n/d_faster_way_to_read_ml_papers/</link>
      <description><![CDATA[似乎我在试图走捷径，但我想首先知道我发现的一篇论文是否确实提供了关于如何解决我的问题的见解手头的 ML 问题，只有在那之后我才会阅读详细信息。 任何提示将不胜感激   由   提交/u/Snoo_72181   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190vo6n/d_faster_way_to_read_ml_papers/</guid>
      <pubDate>Sun, 07 Jan 2024 16:18:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么在机器学习中几乎所有的概率推导都如此难以遵循？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190to69/d_why_are_almost_all_probabilistic_derivations_so/</link>
      <description><![CDATA[      我认为自己非常擅长数学，甚至还教过大学生，活跃于ML 等领域。 然而，我发现大多数（如果不是全部）涉及 ML 中任何远程概率问题的论文都得到了残酷的解释。 最近我决定真的了解 OG [DDPM](https://arxiv.org/pdf/2006.11239.pdf) 论文。&lt; /p&gt; 这是推导的一部分，他们……以某种方式……插入了 KLD。我完全不清楚这个跳跃是如何进行的。是的，我看过 KLD 的定义，是的，我用谷歌搜索过，但每个人似乎都相信这一点。 ChatGPT 说“存在未显示的隐藏期望”。 https://preview.redd.it/glvvzcc351bc1.png?width=2014&amp;format=png&amp;auto=webp&amp;s=d4c95a5716c0b8113e9a3346b8f99e3c5 a3db919 有人知道吗？  ​ 更新：感谢大家的评论，我这里的结论是DDPM论文有一个错误，即上面的图像。  错误是因为它们显示外部期望没有被用完，而实际上它已经被用尽了。  我在 Calvin 的论文此处中找到了正确的推导过程。这是图像： ​ https://preview.redd.it/54o6592vj2bc1.png?width=2370&amp;format=png&amp;auto=webp&amp;s=78d089d3d5c183f286bac15d3e6 d38ed5fa4e37e 上面是正确的，而DDPM论文是错误的。  ​   由   提交 /u/Ayakalam   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190to69/d_why_are_almost_all_probabilistic_derivations_so/</guid>
      <pubDate>Sun, 07 Jan 2024 14:46:58 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]我可以使用LORA/QLORA来微调BERT吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190rw8w/discussion_can_i_use_loraqlora_to_finetune_bert/</link>
      <description><![CDATA[BERT，从技术上讲也是一个法学硕士，传统上是通过在特定领域数据集上的屏蔽词进行微调/领域适应的。但我也可以将 qlora 与基于 BERT 的模型结合使用，以实现更高效的微调吗？   由   提交/u/Electronic-Letter592   reddit.com/r/MachineLearning/comments/190rw8w/discussion_can_i_use_loraqlora_to_finetune_bert/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190rw8w/discussion_can_i_use_loraqlora_to_finetune_bert/</guid>
      <pubDate>Sun, 07 Jan 2024 13:14:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 那么，曼巴大战变形金刚……炒作是真的吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190q1vb/d_so_mamba_vs_transformers_is_the_hype_real/</link>
      <description><![CDATA[听到了有关序列建模模块新成员 Mamba 的所有讨论。据说它速度更快，可以更好地处理更长的序列，甚至在某些任务上优于 Transformer。但它真的是王位窃取者还是只是昙花一现？ 我的看法： 优点：Mamba 拥有高效的内存使用、随序列长度线性扩展以及令人印象深刻的性能语言和 DNA 建模。另外，它放弃了注意力机制，可能为更快的推理铺平道路。  弱点：仍处于早期阶段，因此 Mamba 在不同任务中的长期稳定性和表现仍有待观察。虽然它不需要关注，但它的状态空间方法对于某些人来说可能更难以掌握。  对于人工智能爱好者来说，曼巴只是下一个闪亮的玩具，还是序列建模中真正的范式转变？它会推翻强大的变形金刚，还是作为一种专门的工具并存？让我们听听您的想法！ https://arxiv.org/abs/2312.00752 &lt; /div&gt;  由   提交/u/Instantinopaul   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190q1vb/d_so_mamba_vs_transformers_is_the_hype_real/</guid>
      <pubDate>Sun, 07 Jan 2024 11:19:08 GMT</pubDate>
    </item>
    <item>
      <title>[D]我们的大脑如何防止过度拟合？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/190c7y2/d_how_does_our_brain_prevent_overfitting/</link>
      <description><![CDATA[老实说，这个问题引发了一系列其他问题，老实说，这很有趣，我们阻止这种情况发生的机制是什么？ 梦想只是生成数据增强，以便我们防止过度拟合吗？ 如果我们进一步将过度拟合拟人化，患有学者综合症的人会过度拟合吗？ （因为他们在狭窄的任务上表现出色，但在泛化方面有其他障碍。尽管他们仍然有梦想） 为什么我们不记忆，而是学习？    由   提交 /u/BlupHox   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/190c7y2/d_how_does_our_brain_prevent_overfitting/</guid>
      <pubDate>Sat, 06 Jan 2024 22:33:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18vao7j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 31 Dec 2023 16:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>