<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Tue, 30 Jan 2024 06:17:50 GMT</lastBuildDate>
    <item>
      <title>[D] 将我们的客户反馈分为功能请求、错误和评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aehk5l/d_classify_our_customer_feedback_into_feature/</link>
      <description><![CDATA[嘿，我是一家 B2B SaaS 公司的 SWE，我的 PM 要求我将客户反馈分为功能请求、错误和评论。我建立了一个模型，但它不起作用。有我可以使用的模型吗？有什么建议么？我按着时钟。  谢谢！   由   提交 /u/Scary-Swing2852    reddit.com/r/MachineLearning/comments/1aehk5l/d_classify_our_customer_feedback_into_feature/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aehk5l/d_classify_our_customer_feedback_into_feature/</guid>
      <pubDate>Tue, 30 Jan 2024 06:06:35 GMT</pubDate>
    </item>
    <item>
      <title>[D] 学习许多到手动映射</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aegxjw/d_learning_many_to_manu_mappings/</link>
      <description><![CDATA[[D] 我必须要有一组样本。每个样本集都有自己的一组功能。例如，在一组中，样本为 s1(f1,f2,...)，在另一组中，样本为 s2(f&#39;1, f&#39;2,....)。集合 1 的特征数量与集合 2 的特征数量不同。需要学习两个样本集合之间的多对多映射。哪种方法最适合该问题？此外，示例是文本，而不是图像。   由   提交/u/unhappywife_77  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aegxjw/d_learning_many_to_manu_mappings/</guid>
      <pubDate>Tue, 30 Jan 2024 05:29:22 GMT</pubDate>
    </item>
    <item>
      <title>[讨论]", "[D] 最近，我一直在尝试理解 scikit-learn 中缺失值的处理，尽管我付出了努力，但在理解这个概念时我面临着一些困难。有人可以帮助我吗？缺失值支持决策树</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aegacj/discussion_d_recently_i_have_been_trying_to/</link>
      <description><![CDATA[最近，我一直在尝试理解 scikit-learn 中缺失值的处理，尽管我付出了努力，但我在掌握概念。有人可以帮助我吗？ /a&gt; 和 DecisionTreeRegressor 具有内置支持对于缺失值，当 splitter=&#39;best&#39; 且标准为 &#39;gini&#39; 、 &#39;entropy &#39; 或 &#39;log_loss&#39; 时，对于分类或 &#39;squared_error&#39; 、 &#39;friedman_mse&#39; 或 &#39;poisson&#39; 用于回归。 对于非缺失数据上的每个潜在阈值，分割器将使用所有缺失值来评估分割转到左节点或右节点。 决策如下：  默认情况下，在预测时，具有缺失值的样本将按照中使用的类别进行分类训练过程中发现的分裂： &gt;&gt;&gt;来自 sklearn.tree 导入 DecisionTreeClassifier &gt;&gt;&gt;&gt;&gt;导入 numpy as np &gt;&gt;&gt; X = np.array([0 , 1, 6, np.nan]).reshape(-1, 1) &gt;&gt;&gt; y = [0, 0, 1, 1] &gt;&gt;&gt; ; tree = DecisionTreeClassifier(random_state=0).fit(X, y) &gt;&gt;&gt; tree.predict(X) array([0, 0, 1, 1] ) 如果两个节点的标准评估相同，则通过转到正确的节点来打破预测时缺失值的平局。拆分器还会检查拆分，其中所有缺失值都转到一个子项，而非缺失值则转到另一个子项： &gt;&gt;&gt;来自 sklearn.tree 导入 DecisionTreeClassifier &gt;&gt;&gt;&gt;&gt;导入 numpy as np &gt;&gt;&gt; X = np.array([np .nan, -1, np.nan, 1]).reshape(-1, 1) &gt;&gt;&gt; y = [0, 0, 1, 1] &gt; &gt;&gt; tree = DecisionTreeClassifier(random_state=0).fit(X, y) &gt;&gt;&gt; X_test = np.array([np.nan]).reshape (-1, 1) &gt;&gt;&gt; tree.predict(X_test) array([1]) 如果在给定特征的训练过程中没有看到缺失值，然后在预测期间缺失值被映射到具有最多样本的子项： &gt;&gt;&gt;&gt;&gt;来自 sklearn.tree 导入 DecisionTreeClassifier &gt;&gt;&gt;&gt;&gt;导入 numpy as np &gt;&gt;&gt; X = np.array([0 , 1, 2, 3]).reshape(-1, 1) &gt;&gt;&gt; y = [0, 1, 1, 1] &gt;&gt;&gt;&lt; /strong&gt; 树 = DecisionTreeClassifier(random_state=0).fit(X, y) &gt;&gt;&gt; X_test = np.array([np.nan]).reshape(-1, 1 ) &gt;&gt;&gt; tree.predict(X_test) array([1])    由   提交/u/Low-Wish5722  /u/Low-Wish5722 reddit.com/r/MachineLearning/comments/1aegacj/discussion_d_recently_i_have_been_trying_to/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aegacj/discussion_d_recently_i_have_been_trying_to/</guid>
      <pubDate>Tue, 30 Jan 2024 04:52:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 向所有跨学科计算社会科学家提出的问题 - 在您的领域应用 AI/ML</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeenu3/d_question_to_all_computational_social_scientists/</link>
      <description><![CDATA[您好r/MachineLearning！&lt; /p&gt; 我很想听听应用/计算社会科学家的意见，他们曾尝试或想要在您的研究中应用机器学习和人工智能技术。您遇到过哪些挑战？什么类型的能力最有用？ 问这个问题的主要动机来自于我过去的经验 - 我注意到专门用于社会科学研究的非处方人工智能模型的短缺，并开始想知道除了缺乏可用资源之外我们还存在哪些问题。 作为一名对人工智能/机器学习感兴趣的社会科学家，您通常会面临哪些问题？我也有兴趣听听您是否认为人工智能/机器学习将从根本上改变社会科学，或者只是提供一些有用但有限的工具，或者研究的性质会如何改变。 非常期待听到来自不同领域的观点。跨越社会科学！   由   提交/u/nickshoh  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeenu3/d_question_to_all_computational_social_scientists/</guid>
      <pubDate>Tue, 30 Jan 2024 03:25:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] 加速注意力研究：融合心理学和机器学习：探索注意力机制中的意志力和兴趣</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeds27/d_accelerating_research_on_attention_blending/</link>
      <description><![CDATA[      摘录：今天，让我们从通常深入研究代码和算法的过程中绕道而行。相反，我想谈谈最近让我大脑发痒的事情：如果我们可以将一些人类心理学（例如意志力和兴趣）混合到机器学习的冷酷逻辑世界中会怎么样？如果您愿意，请喜欢这篇文章我要继续努力！ :) https://medium.com/@beastman3b/blending-psychology-and-machine-learning-exploring-willpower-and-interest-in-attention-mechanisms-81ce5d6bdb3d &amp; #x200b; https:// medium.com/@beastman3b/blending-psychology-and-machine-learning-exploring-willpower-and-interest-in-attention-mechanisms-81ce5d6bdb3d 请继续关注，看看效果如何出！   由   提交 /u/Honest-Debate-6863   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeds27/d_accelerating_research_on_attention_blending/</guid>
      <pubDate>Tue, 30 Jan 2024 02:42:34 GMT</pubDate>
    </item>
    <item>
      <title>250 RTX 3080s 能做什么 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aedjxc/what_to_dow_ith_250_rtx_3080s_p/</link>
      <description><![CDATA[您好！我有大约 250 个 RTX 3080，+ 可能有 40 个 RTx 3070，我用于挖矿。他们都拆掉了风扇护罩并安装了风扇。在浸入式冷却液中采矿。长话短说。采矿停止后，事情变得忙碌起来。它们的 GPU 刚刚放在浸没液体中。它们仍然可以工作，并且自从采用液体冷却以来从未变热。  是否有任何公司可以托管浸入式冷却卡，或者有人想要协助代理这些卡或帮助它们设置机器学习？我很乐意将几台 3080 赠送给任何可以用它们实现目标的人！   由   提交/u/death0and0taxes  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aedjxc/what_to_dow_ith_250_rtx_3080s_p/</guid>
      <pubDate>Tue, 30 Jan 2024 02:31:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LLM + RAG 进行 3D 对象搜索</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aec8gb/d_3d_object_search_using_llm_rag/</link>
      <description><![CDATA[为可与自然语言一起使用的 3D 对象制作一个小型搜索引擎，并从中获得了一些乐趣。不需要元数据或标签，索引纯粹是根据几何图形构建的！这使用以下管道进行工作：  对于数据库中的每个对象，我生成 6 个图像，每侧 1 个。 对于每个图像，我使用 gpt4- 进行描述视觉，然后使用 gpt4 将其合成为单个描述 文本描述使用剪辑嵌入并存储在矢量数据库中 对于搜索查询，搜索字符串被嵌入，并且检索到数据库中最接近的（n）个向量。  参见此处：https://x.com/MenyJanos/status/1752104689188135271?s=20   由   提交/u/Janos95  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aec8gb/d_3d_object_search_using_llm_rag/</guid>
      <pubDate>Tue, 30 Jan 2024 01:29:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用多个库对 Mixtral-8x7B 进行实验 - 每秒最多获得 52 个令牌。想法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeb70z/d_experiments_with_mixtral8x7b_using_multiple/</link>
      <description><![CDATA[      大家好， 最近尝试部署 Mixtral-8x7B模型并希望与感兴趣的人分享主要发现： 最佳性能：使用 Pytorch（每晚）的量化 8 位模型的平均代币生成率为 52.03 代币/秒在 A100 上，平均推理时间为 4.94 秒，冷启动时间为 11.48 秒（在无服务器环境中部署时很重要） 混合实验 测试的其他库： vLLM、AutoGPTQ、HQQ 渴望听到您在类似部署中的经验和学习！   由   提交/u/Tiny_Cut_8440   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeb70z/d_experiments_with_mixtral8x7b_using_multiple/</guid>
      <pubDate>Tue, 30 Jan 2024 00:40:34 GMT</pubDate>
    </item>
    <item>
      <title>自动 1111 的开源 SDK/Python 库 [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aeab92/opensource_sdkpython_library_for_automatic_1111_p/</link>
      <description><![CDATA[   ​ https://preview.redd.it/74bz5ko0xgfc1.png?width=1656&amp;format=png&amp;auto=webp&amp;s=2a0ea066 0f56c97e242c7e099073086f52e38263&lt; /a&gt; https://github.com/saketh12/Auto1111SDK 大家好，我为自动 1111 Web UI 构建了一个轻量级开源 Python 库，它允许您在基础设施上本地运行任何稳定扩散模型。您可以轻松运行：  文本到图像 图像到图像 修复 修复 li&gt; Stable Diffusion Upscale Esrgan Upscale Real Esrgan Upscale 直接从 Civit AI 下载模型  使用任何安全张量或检查点文件都只需几行代码！它超轻且高性能。与 Huggingface Diffusers 相比，我们的 SDK 使用的内存/RAM 少得多，并且我们在我们测试的所有设备/操作系统上观察到速度提高了 2 倍！ 请为我们的 Github 存储库加注星标！！！ https://github.com/saketh12/Auto1111SDK.   由   提交 /u/Dazzling_Koala6834   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aeab92/opensource_sdkpython_library_for_automatic_1111_p/</guid>
      <pubDate>Mon, 29 Jan 2024 23:59:46 GMT</pubDate>
    </item>
    <item>
      <title>分解：神经网络结构组合性的证据 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae61tq/break_it_down_evidence_for_structural/</link>
      <description><![CDATA[ 由   提交/u/we_are_mammals  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae61tq/break_it_down_evidence_for_structural/</guid>
      <pubDate>Mon, 29 Jan 2024 20:59:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] RAG 之外的法学硕士</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae5dgq/d_llms_beyond_rag/</link>
      <description><![CDATA[实际上几乎每个人都在谈论 RAG。我想知道接下来会出现什么趋势。很想听听您的想法。   由   提交/u/HolidayCritical3665   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae5dgq/d_llms_beyond_rag/</guid>
      <pubDate>Mon, 29 Jan 2024 20:31:28 GMT</pubDate>
    </item>
    <item>
      <title>佩德罗·多明戈斯：神经象征尚未发挥作用 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae4vp1/pedro_domingos_neurosymbolic_does_not_work_yet_r/</link>
      <description><![CDATA[      ​ https://preview.redd.it/r0h4yab5qffc1.png?width=817&amp;format=png&amp;auto=webp&amp;s=033744120df49 252c5379bdafa429570e80cfac4&lt; /a&gt; ​ 象征性人工智能通常被视为失败。我记得 Cyc 花费了 2 亿美元（比 GPT-4 的培训预算还多？）。 另一方面，Transformer LLM [1] 明显的固有局限性使一些人将目光转向象征性的、神经-再次采用象征性和混合性方法。 DeepMind 首席执行官表示，公司在这个领域有六个项目。 如果你对这些主题（神经网络、符号和神经符号人工智能的理论局限性）感兴趣，我为它们制作了一个 Reddit 子版块： r/symbolic （我可能会后悔这样做，但小众主题需要自己的 subreddits，因为大多数主题都没有关心或了解很多，因此提交的内容会被否决，并且评论通常缺乏洞察力，例如“什么是 ILP？”） ​ &lt; p&gt;[1]例如 https://arxiv.org/abs/2205.11502   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae4vp1/pedro_domingos_neurosymbolic_does_not_work_yet_r/</guid>
      <pubDate>Mon, 29 Jan 2024 20:11:06 GMT</pubDate>
    </item>
    <item>
      <title>[d] Code Llama，一种最先进的大型编码语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ae0lsj/d_code_llama_a_stateoftheart_large_language_model/</link>
      <description><![CDATA[ https://ai.meta.com/blog/code-llama-large-language-model-coding/   由   提交/u/Electrical_Study_617   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ae0lsj/d_code_llama_a_stateoftheart_large_language_model/</guid>
      <pubDate>Mon, 29 Jan 2024 17:19:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不懂基础的LLM专家？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</link>
      <description><![CDATA[我最近遇到了很多人，他们知道 LLM 领域中不同技术的所有奇特缩写词，诚然我也是新手但越来越明显的是，他们甚至不知道 DL 的基础知识，比如背景是什么或其他经典概念。 这是否会成为现状，因为 LLM 领域更倾向于配置而不是做事从零开始？ 还有，这些人真的可以被认为是法学硕士还是表面上的专家？    由   提交/u/Plus_Tough_7497   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1admb6z/d_llm_experts_who_dont_know_basics/</guid>
      <pubDate>Mon, 29 Jan 2024 04:13:30 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的其他人在此处发帖！ 帖子将保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>