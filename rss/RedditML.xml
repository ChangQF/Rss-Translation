<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Sun, 15 Dec 2024 12:32:19 GMT</lastBuildDate>
    <item>
      <title>[D] 我们能接受这个吗？NeurIPS 上令人质疑的发帖行为</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1heo36q/d_are_we_okay_with_this_questionable_poster/</link>
      <description><![CDATA[      这是我参加 NeurIPS 的第一年。看到如此多的前沿研究成果被展示，真是令人振奋，但在海报展示期间，一些令人不安的事情引起了我的注意，我觉得有必要分享一下，尤其是考虑到最近与 Rosalind Picard 发生的事件。 论文被 NeurIPS 接受是一个巨大的成就。每一个海报位置都代表着如此多的辛勤工作，并且令人垂涎。 我看到了两张不应该在那里的海报，这让我对这些空间的开发产生了怀疑。 非法海报 #1： Generative Boba。这是一张“可爱，看我”的海报，但它还带有一个链接到创作者 X/Twitter 的二维码。虽然海报本身被放置在展厅的侧墙上，而不是官方海报位置（当我看到它时），但它仍然感觉很奇怪。他们为什么要制作这张海报？这是为了激发欢乐，还是为了吸引注意力和粉丝？ 非法海报 #1：Generative Boba。 非法海报 #2： Benchmarkthing。 这更令人担忧。它公然宣传一家新的 AI 初创公司，并提到由我们领域的知名人物 Jeff Dean 提供资金。与 boba 海报不同，从视觉上看，这可以被视为真正的 NeurIPS 海报。可能大多数路人都没有多想，但海报的展示者（也是公司的创始人）实际上是在推广他的新创业公司，有时是向大量观众推广，而且是在多个海报展示会上。这让人感觉具有欺骗性和剥削性——利用社区的信任，在神圣的学术空间中作弊获得知名度。 非法海报 #2：Benchmarkthing。 另一种类型的游戏是作者将海报张贴在未使用的位置，同时在正式指定的位置留下一个标志，上面写着“在#{更好的位置} 查看海报”。如果未使用位置的作者到了，他们只需将海报移回原位 — 但如果作者没有到，他们大概会因为位置更靠近大厅入口、人流量更大而受到更多关注。 重新放置海报似乎仍有问题，但至少海报属于会议。另一方面，我更强烈地认为未经授权的海报用于个人或商业宣传会损害空间的完整性，不尊重海报真正属于此处的演讲者，并破坏整个会议。 社区问题：  是否应该对海报会议制定更严格的政策或更好的执行？ 我们如何区分轻微的游戏（例如重新放置海报）和彻底的剥削（例如未经授权的海报）？ 只要意图是轻松的或仍然是学术性的，容忍一些灵活性是否公平？  我们该如何应对这些行为？应该承担后果吗？     提交人    /u/Positive_Lychee6904   [link] [comments] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1heo36q/d_are_we_okay_with_this_questionable_poster/</guid>
      <pubDate>Sun, 15 Dec 2024 08:08:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 当你的模型正在训练时你做什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hemhil/d_what_do_you_do_while_your_model_is_training/</link>
      <description><![CDATA[我基本上在模型训练时照看它，看一些《豪斯医生》或者玩一些我的世界。我已经完成了所有的文献综述和论文写作，现在在我的模型训练时我应该做什么？    提交人    /u/Striking-Warning9533   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hemhil/d_what_do_you_do_while_your_model_is_training/</guid>
      <pubDate>Sun, 15 Dec 2024 06:11:22 GMT</pubDate>
    </item>
    <item>
      <title>[D] 上周医学 AI：顶级 LLM 研究论文/模型（2024 年 12 月 7 日至 12 月 14 日）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hecwvp/d_last_week_in_medical_ai_top_llm_research/</link>
      <description><![CDATA[      医学 AI 上周：顶级 LLM 研究论文/模型（2024 年 12 月 7 日至 12 月 14 日） 医学 LLM &amp;  PediaBench：中文儿科法学硕士  本文介绍了 PediaBench，这是第一个用于评估大型语言模型 (LLM) 问答性能的中文儿科数据集，包含 12 个疾病组的 4,565 个客观问题和 1,632 个主观问题。  BiMediX：双语医学法学硕士  本文介绍了 BiMediX，这是第一个双语（英语-阿拉伯语）医学专家混合法学硕士，以及 BiMed1.3M，这是一个 1.3M 的双语医学指导数据集，其中包含超过 632M 个用于训练的标记。  多样化医学知识整合  本文介绍了 BiMediX2，这是一个基于 Llama3.1 架构的双语（阿拉伯语-英语）大型多模态模型 (LMM)，在160 万个医疗互动样本。  BRAD：数字生物语言模型 本文介绍了 BRAD（生物信息学检索增强数字助理），这是一个由 LLM 驱动的聊天机器人和代理系统，集成了各种生物信息学工具。  MMedPO：视觉语言医学 LLM  本文介绍了 MMedPO，一种多模态医学偏好优化方法，通过解决模态错位来提高医学大型视觉语言模型（Med-LVLM）中的事实准确性。   框架和方法论 - TOP-Training：医疗问答框架 - 混合 RAG：安全医疗数据管理 - 零样本 ATC 临床编码 - 胸部 X 光诊断架构 - 医学影像 AI 民主化 基准和评估 - KorMedMCQA：韩国医疗保健许可基准 - 大型语言模型医疗任务 - 临床 T5 模型性能研究 - 放射学报告质量评估 - 基因组分析基准 LLM 应用 - TCM-FTP：草药处方预测 - LLaSA：通过传感器进行活动分析 - 急诊科就诊预测 - 神经退行性疾病 AI 诊断 - 肾脏疾病可解释 AI 模型 道德 AI 与隐私 - 隐私保护 LLM 机制 - 人工智能驱动的数字有机体建模 - 生物医学研究自动化 - 医学实践中的多模态性 完整线程详细信息：https://x.com/OpenlifesciAI/status/1867999825721242101    提交人    /u/aadityaura   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hecwvp/d_last_week_in_medical_ai_top_llm_research/</guid>
      <pubDate>Sat, 14 Dec 2024 21:25:08 GMT</pubDate>
    </item>
    <item>
      <title>对比损失的自定义实现[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1heb4iv/custom_implementation_of_contrastive_loss_p/</link>
      <description><![CDATA[我正在尝试实现对比损失函数，但我不确定它是否正确。我的损失似乎爆发到无穷大。如果能再多看看这篇文章，我会非常感激，这看起来正确吗？ class ContrastiveLoss(nn.Module): def __init__(self,temperature=0.9): super(ContrastiveLoss, self).__init__() self.temperature =temperature def forward(self,projections_1,projections_2): z_i =projections_1 z_j =projections_2 z_i_norm = F.normalize(z_i,dim=1) z_j_norm = F.normalize(z_j,dim=1) cosine_num = torch.matmul(z_i,z_j.T) cosine_denom = torch.matmul(z_i_norm,z_j_norm.T) cosine_similarity = cosine_num / cosine_denom numerator = torch.exp(torch.diag(cosine_similarity)/ self.temperature) 分母 = 余弦相似度 对角线指数 = torch.arange(denominator.size(0)) 分母[diagonal_indices, diagonal_indices] = 0 分母 = torch.sum(torch.exp(cosine_similarity), dim=1) 损失 = -torch.log(numerator / denominator).mean() 返回损失     提交人    /u/Ok-Administration894   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1heb4iv/custom_implementation_of_contrastive_loss_p/</guid>
      <pubDate>Sat, 14 Dec 2024 20:01:39 GMT</pubDate>
    </item>
    <item>
      <title>[项目] 矩阵循环状态，注意力机制的替代方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he8vhw/project_matrix_recurrent_states_a_attention/</link>
      <description><![CDATA[      https://github.com/mikayahlevi/mru-lm 大家好，我在这里发帖是为了分享我刚刚在 GitHub 上发布的项目。我将从描述开始，其中一些内容将从 GitHub repo 中复制/粘贴。 矩阵循环单元的概念由更新规则 H_t = H_{t-1} X_{t-1} 和 H_1 = X_1 决定，其中 X 和 H 是 s×n×n 方阵序列。这与传统 RNN 的主要区别在于，没有初始向量通过线性，而是第一个状态是矩阵，导致输出也是矩阵。我提出这个想法的动机基于以下原因：  矩阵乘法是结合的，但不是交换的。结合性意味着我可以使用（包含）并行扫描来计算累积矩阵乘积。缺乏交换性意味着标记的顺序会自动合并到 MRU 中。 当您尝试在传统 RNN 上执行此扫描时，操作数会与输出状态中的元素数量成立方比例，这意味着与计算量相比，保留的信息有限。另一方面，如果状态是矩阵，则作为输出状态中元素的函数的操作数为 (n^2)^(3/2)，其中 n^2 是方阵 n×n 矩阵状态中的元素数量。这里有一篇包含一些相关信息的论文：https://arxiv.org/abs/1709.04057。 当按顺序或与（尚未实施的）Brent-Kung 并行扫描并行处理标记时，网络会随时间线性扩展，而注意力则会随时间二次扩展。  我尝试在不同的分支中使用不同的方法生成矩阵 X。生成 X 并将输出隐藏状态折叠回向量的所有方法都是线性和重塑的任意组合，仅基于我发​​现效果良好的方法。 Transformer 和 MRU-LM 在 shakespeare-char 上的损失与步数 基于玩具数据集 shakespeare-char，这种方法似乎效果很好，所以如果有人愿意帮助我，我想在更具信息量的数据集上对其进行基准测试，看看效果如何。    提交人    /u/IonizedPro   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he8vhw/project_matrix_recurrent_states_a_attention/</guid>
      <pubDate>Sat, 14 Dec 2024 18:19:00 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我的 nn 模型有问题，它不是预测真实的单词，而是返回诸如“the in 等”之类的东西，而不是真实的单词，如何解决这个问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he8fea/p_i_have_an_issue_with_my_nn_the_model_instead_of/</link>
      <description><![CDATA[repo : https://github.com/troy12x/Quasar-1     由   提交  /u/Justimrandy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he8fea/p_i_have_an_issue_with_my_nn_the_model_instead_of/</guid>
      <pubDate>Sat, 14 Dec 2024 17:58:33 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2024 年法学硕士论文精选清单</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he4htl/p_curated_list_of_llm_papers_2024/</link>
      <description><![CDATA[       提交者    /u/seraschka   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he4htl/p_curated_list_of_llm_papers_2024/</guid>
      <pubDate>Sat, 14 Dec 2024 14:52:26 GMT</pubDate>
    </item>
    <item>
      <title>美国健康保险申请精选语料库 [P] [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he14fo/curated_corpus_for_us_health_insurance/</link>
      <description><![CDATA[       由    /u/tpafs  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he14fo/curated_corpus_for_us_health_insurance/</guid>
      <pubDate>Sat, 14 Dec 2024 11:36:37 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深度学习训练的（非）书面规则是什么</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1he07vr/d_what_are_the_unwritten_rules_of_deep_learning/</link>
      <description><![CDATA[免责声明：我首先在 r/learnmachinelearing 中发布了此内容，但该子版块似乎更关注非常基本的问题、课程和招聘，因此如果它不适合在这里发布，请随时将其删除（尽管我认为这也适合作为讨论的子版块）。 我现在有几年构建和训练不同模型架构的经验，我了解大部分基本理论，并能够理解大多数论文。所以我的问题更偏向于方法论方向。虽然我能够成功地为许多应用程序构建模型，但很多时候这在很大程度上是一种猜测。我尝试了不同的东西，看看哪种方法可行。我知道在可解释性方面有很多研究正在进行，但这并不是我想要的方向。相反，我想问大家，你们对训练过程有什么一般性建议，你们采取的一些实际观察、经验法则和方法在论文或理论机器学习课程中没有描述。例如：  你如何分析模型中的梯度。我知道如何在这方面做一些非常基本的图表，但我对你的方法以及你如何从实际角度解读它们感兴趣？ 你如何可视化优化器步骤之间的时间不稳定性，例如由于学习率过大？ 你如何确定合适的正则化？ 在训练运行期间，你的收益递减经验法则是什么？ 你如何调整超参数？我或多或少地目测过它们，过去也使用过 optuna。 您认为在训练过程中有哪些重要的直觉、不成文的规则和陷阱？ 当模型表现不如预期时，您的调试步骤是什么？ 您实际上使用了哪些技巧？有很多小技巧（EMA、模糊的激活函数等）可以带来一些好处，但您实际上使用了什么？ 当您使用 Transformer、CNN、扩散模型等时，您的方法有何不同？ 上面我可能遗漏了一些一般性意见或技巧。  大学课程和在线资源主要教授基础知识或理论基础，这非常重要，但在实践中只是故事的一部分。现实世界的经验也有帮助，但你只能通过反复试验走这么远，可能会错过一些有用的东西。我知道 Karpathy 关于神经网络训练的博客文章，并在寻找这方面的更多资源。 我很高兴在这里看到您对这个广泛话题的回复。    提交人    /u/floriv1999   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1he07vr/d_what_are_the_unwritten_rules_of_deep_learning/</guid>
      <pubDate>Sat, 14 Dec 2024 10:29:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 发生了什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hdxbru/d_what_happened_at_neurips/</link>
      <description><![CDATA[        提交人    /u/howtorewriteaname   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hdxbru/d_what_happened_at_neurips/</guid>
      <pubDate>Sat, 14 Dec 2024 07:00:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] NVIDIA 的人质：垄断的赛博朋克现实</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hdjklf/d_nvidias_hostages_a_cyberpunk_reality_of/</link>
      <description><![CDATA[在人工智能和专业工作站领域，NVIDIA 的主导地位让人感觉像是令人窒息的垄断。他们细分的产品线扩大了消费级和专业级 GPU 之间的差距，尤其是在 VRAM、性能和价格方面。 人工智能爱好者为配备足够 VRAM 的 GPU 而苦苦挣扎，因为成本高昂。对 CUDA 核心（专有标准）的依赖进一步将开发人员锁定在 NVIDIA 的生态系统中，扼杀了竞争和创新。 NVIDIA 的控制范围不仅限于硬件，因为他们的 CUDA 平台不鼓励采用开放、竞争的解决方案。这助长了一种赛博朋克反乌托邦，企业整合权力，让消费者和开发者几乎没有选择。 为什么科技界仍然同谋？为什么我们不追求替代硬件架构或超越 CUDA 的更广泛的软件兼容性？ AMD 的 ROCm 是一个开始，但需要更积极的开发和政策干预来挑战 NVIDIA 的控制权。 这种情况会持续到什么时候？谁会为最终消费者挺身而出？    提交人    /u/SevenShivas   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hdjklf/d_nvidias_hostages_a_cyberpunk_reality_of/</guid>
      <pubDate>Fri, 13 Dec 2024 19:02:54 GMT</pubDate>
    </item>
    <item>
      <title>[R] 通过标记级不确定性分析识别神经文本生成中的关键决策点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hdd0kk/r_identifying_critical_decision_points_in_neural/</link>
      <description><![CDATA[本文介绍了一个框架，用于分析和可视化语言模型在文本生成过程中做出的分支决策。关键方法涉及跟踪不同采样路径上的概率分布，以了解早期选择如何影响下游生成。 主要技术要点： - 开发指标来量化每个生成步骤的不确定性 - 创建可视化工具来映射生成中的决策树 - 分析不同采样方法如何影响路径发散 - 测量模型置信度和生成质量之间的相关性 - 识别生成轨迹中的聚类模式 主要结果： - 发现路径倾向于聚类成 2-3 个不同的轨迹组 - 早期采样决策对最终输出的影响巨大 - 不确定性模式在不同采样方法之间差异很大 - 类似的提示可能导致截然不同的生成路径 - 模型置信度并不能始终如一地预测输出质量 我认为这项工作为我们如何更好地控制文本生成提供了重要的见解。映射和理解生成路径的能力有助于开发更可靠的采样方法和更好的不确定性估计。 我认为生成路径的聚类特别有趣 - 它表明可能有方法将生成引导至所需的轨迹组。这对于需要更可预测输出的应用程序可能很有价值。 该方法还揭示了当前采样方法的一些令人担忧的方面。对早期决策的强烈依赖表明我们可能需要新的方法来更好地在整个序列中保持生成灵活性。 TLDR：用于分析语言模型如何做出文本生成选择的新框架。表明生成路径聚集成不同的组，早期决策严重影响结果。可以帮助开发更好的采样方法和不确定性估计。 完整摘要在这里。论文此处。    由    /u/Successful-Western27  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hdd0kk/r_identifying_critical_decision_points_in_neural/</guid>
      <pubDate>Fri, 13 Dec 2024 14:10:21 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 2024 最佳论文奖得主破坏了其他团队</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hctf36/d_the_winner_of_the_neurips_2024_best_paper_award/</link>
      <description><![CDATA[据推测，NeurIPS 2024 最佳论文奖的获得者（来自字节跳动，抖音的创造者）破坏了其他团队的研究，并将他们的资源转移到他自己的团队。此外，他在会议上调试同事的代码，所以他总是领先一步。有人呼吁撤回他的论文。 https://var-integrity-report.github.io/ 我还没有核实事实本身，所以如果你能验证断言的内容，如果这是真的，那就太好了。    提交人    /u/LelouchZer12   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hctf36/d_the_winner_of_the_neurips_2024_best_paper_award/</guid>
      <pubDate>Thu, 12 Dec 2024 19:41:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h99kae/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 08 Dec 2024 03:15:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>