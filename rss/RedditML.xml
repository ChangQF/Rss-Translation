<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Sun, 31 Dec 2023 01:04:05 GMT</lastBuildDate>
    <item>
      <title>[P] 15亿参数的多模态聊天</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ut3lm/p_multimodal_chat_in_15_billion_parameters/</link>
      <description><![CDATA[   /u/ashvar  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ut3lm/p_multimodal_chat_in_15_billion_parameters/</guid>
      <pubDate>Sat, 30 Dec 2023 23:30:20 GMT</pubDate>
    </item>
    <item>
      <title>YOLOv5-8 性能指标“[P]”的 Python 代码</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18us17t/python_code_for_yolov58_performance_metrics_p/</link>
      <description><![CDATA[大家好。我是计算机视觉新手，我在自定义数据集上使用了 YOLOv5-8 模型。现在我想知道性能指标 IoU、AP、mAP、Precision、Recall 和 F1-Score。我似乎找不到任何 python 代码来了解这些指标，或者我不知道在哪里可以看到它。有任何有用的教程或代码吗？为我提供这个会对我有很大帮助。谢谢。 P.S: 我更喜欢 python 代码    由   提交/u/shafayat666   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18us17t/python_code_for_yolov58_performance_metrics_p/</guid>
      <pubDate>Sat, 30 Dec 2023 22:44:25 GMT</pubDate>
    </item>
    <item>
      <title>适用于多 GPU ML 设备的最佳 Ubuntu 版本是什么？ [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18urs0d/what_is_the_best_ubuntu_variation_for_multi_gpu/</link>
      <description><![CDATA[有人可以评论一下哪个版本的 Ubuntu 更适合具有多个 GPU 的机器学习设备吗？在这种设置中，服务器版本与桌面版本相比有哪些优点/缺点？对 Pop!_OS 与 Ubuntu v.20.04 LTS 有何评论？   由   提交/u/SnooAdvice4458  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18urs0d/what_is_the_best_ubuntu_variation_for_multi_gpu/</guid>
      <pubDate>Sat, 30 Dec 2023 22:33:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 带有语音训练功能的本地 TTS 软件支持 AMD GPU 吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18urbw5/d_local_tts_software_with_voice_training_that/</link>
      <description><![CDATA[有人知道可以在具有 AMD GPU 的本地计算机上运行的任何不错的文本转语音软件吗？ 到目前为止，我已经一直在使用Descript，那个相当不错，但是语音选择非常有限，而且需要订阅。我尝试过在本地计算机上运行类似的东西，但只找到了适用于 Nvidia Cuda 的东西。 我使用的是 AMD 6650XT，升级到 Nvidia 不是一个选择，甚至最便宜的“还可以”在我所在的地区，Nvidia 级卡的售价为 400 欧元，所以想知道是否有人知道任何可以在 AMD 卡上运行的工具，特别是可以选择从音频样本中训练您自己的 AI 配音声音？ 到目前为止尝试过 RVCv2， Mangio RVC、Apollio RVCv2 还研究了 Coqui TTS 和 Tortoise TTS，它们都满足我的需要，但都需要 Nvidia Cuda 才能工作。 Mangio RVC 是最成功的，允许使用“ ;几乎”所有功能，但如果没有 Cuda，特别是训练部分将无法工作。  如有任何建议，我们将不胜感激。   由   提交 /u/Cyber​​punkLover   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18urbw5/d_local_tts_software_with_voice_training_that/</guid>
      <pubDate>Sat, 30 Dec 2023 22:14:50 GMT</pubDate>
    </item>
    <item>
      <title>[R]《认知架构40年：核心认知能力与实际应用》（2018）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uqy29/r_40_years_of_cognitive_architectures_core/</link>
      <description><![CDATA[论文：https://link.springer.com/article/10.1007/s10462-018-9646-y 预印本版本 ：https://arxiv.org/abs/1610.08602 项目页面 （交互式可视化和完整参考书目）：http://jtl.lassonde.yorku.ca/project/cognitive_architectures_survey/ 摘要：  在本文中，我们对过去 40 年的认知架构研究进行了广泛的概述。迄今为止，现有架构的数量已达到数百个，但大多数现有调查并没有反映这种增长，而是集中在少数成熟的架构上。在这项调查中，我们的目标是对认知架构的研究提供更具包容性和更高层次的概述。我们最终的 84 种架构包括 49 种仍在积极开发中的架构，它们借鉴了从精神分析到神经科学等多种学科的知识。为了将本文的长度保持在合理的范围内，我们仅讨论核心认知能力，例如感知、注意机制、行动选择、记忆、学习、推理和元推理。为了评估认知架构实际应用的广度，我们提供了使用列表中的认知架构实施的 900 多个实际项目的信息。我们使用各种可视化技术来突出该领域发展的整体趋势。除了总结当前认知架构研究的最新进展之外，本次调查还描述了已经尝试过的各种方法和想法及其在模拟人类认知能力方面的相对成功，以及认知行为的哪些方面需要对其机械对应物进行更多研究，从而进一步了解认知科学如何进步。    由   提交 /u/APaperADay   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uqy29/r_40_years_of_cognitive_architectures_core/</guid>
      <pubDate>Sat, 30 Dec 2023 21:58:38 GMT</pubDate>
    </item>
    <item>
      <title>[P] 2023年十大值得关注的人工智能研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18unlno/p_ten_noteworthy_ai_research_papers_of_2023/</link>
      <description><![CDATA[       由   提交/u/seraschka  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18unlno/p_ten_noteworthy_ai_research_papers_of_2023/</guid>
      <pubDate>Sat, 30 Dec 2023 19:32:49 GMT</pubDate>
    </item>
    <item>
      <title>[D] 分享您 2023 年的 AI/ML 乐趣</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18umvm4/d_share_your_aiml_joys_for_2023/</link>
      <description><![CDATA[也许这很老套，但今年是我第一次从事 AI/ML 工作，我真的很喜欢这个领域。正在发生如此多的事情，了解其背后的技术真的很有趣。在此之前我已经从事过多种职业/工作，人工智能的前沿方面是一个爆炸。 只是好奇其他人在过去的一年里对他们的工作/学习感到满意。 &lt; /div&gt;  由   提交 /u/LowerSurplus   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18umvm4/d_share_your_aiml_joys_for_2023/</guid>
      <pubDate>Sat, 30 Dec 2023 19:01:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 动量和批量大小</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uh79r/d_momentum_and_batch_size/</link>
      <description><![CDATA[更大的批量大小可以显着改善训练过程。显然，即使我们愿意牺牲每次梯度更新的计算量来增加批量大小，在某些时候 GPU 内存也是有限的。直观上，使梯度更稳定的另一种方法是增加动量。 是否有人有过这样的实际经验：您希望拥有更多 GPU 内存来增加批量大小，但又无法做到这一点？ t，然后利用动量来稳定梯度，从而改善训练过程？   由   提交 /u/felixcra   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uh79r/d_momentum_and_batch_size/</guid>
      <pubDate>Sat, 30 Dec 2023 14:47:51 GMT</pubDate>
    </item>
    <item>
      <title>目前命名实体识别和提取的Sota是多少？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ugt3d/what_is_the_current_sota_on_named_entity/</link>
      <description><![CDATA[命名实体识别和提取的最新技术是什么？   由   提交/u/One_Definition_8975   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ugt3d/what_is_the_current_sota_on_named_entity/</guid>
      <pubDate>Sat, 30 Dec 2023 14:28:16 GMT</pubDate>
    </item>
    <item>
      <title>【项目】时间增强检索（TAR）-动态RAG</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uddmj/project_temporal_augmented_retrieval_tar_dynamic/</link>
      <description><![CDATA[      从文本语料库中，如何检测新出现的主题并它们随时间的演变？ 介绍时间增强检索 (TAR)。 （在 buildspace n&amp;w s4 的背景下构建） TAR 是一种开源的高级 RAG 方法，旨在在执行检索时考虑文本数据的动态和时间方面。 &lt; p&gt;它使我们能够了解所讨论的主题随时间的演变。 该项目背后的想法是开启有关 RAG 方法当前局限性的辩论 第一种方法没有使用 RAG 框架（如 Jerry Liu 的 langchain）构建，专注于金融推文  相关链接： Medium：https://medium.com/@adam-rida/temporal-augmented-retrieval-tar-dynamic-rag-ad737506dfcc&lt; /p&gt; Github：https://github.com/adrida/Temporal_RAG 拥抱脸基准：https://huggingface.co/spaces/Adr740/Temporal-RAG-Benchmark 我的网站：adrida.github.io ​  https://preview.redd.it/lj7wkhk70f9c1.png？ width=960&amp;format=png&amp;auto=webp&amp;s=fc79c5034351a1711e1ec051919a​​5c4d2edbc333   由   提交/u/Adr-740  /u/Adr-740  reddit.com/r/MachineLearning/comments/18uddmj/project_temporal_augmented_retrieval_tar_dynamic/&quot;&gt;[链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uddmj/project_temporal_augmented_retrieval_tar_dynamic/</guid>
      <pubDate>Sat, 30 Dec 2023 11:08:59 GMT</pubDate>
    </item>
    <item>
      <title>[R] InfoSHAP：用信息论 Shapley 值解释预测不确定性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18ud5zn/r_infoshap_explaining_predictive_uncertainty_with/</link>
      <description><![CDATA[论文标题：用信息理论 Shapley 值解释预测不确定性 发表于&lt; /strong&gt;：NeurIPS 2023 论文链接：https://arxiv.org/ abs/2306.05724 代码链接：https://github.com /facebookresearch/infoshap tl;dr：这篇论文以一种可以用来解释模型预测而不是模型本身的不确定性的方式扩展了 SHAP预测本身。这可能有多种应用，例如：  在主动学习应用中，采样决策是基于预测不确定性（如 BatchBALD 等现代方法中的情况）做出的，以回答诸如“为什么”之类的问题我们是否决定注释这个特定实例？”。  在强化学习应用中，探索内容的决策是由好奇心驱动并基于奖励的不确定性。在此设置中，它可用于解释“为什么我们的智能体以这种方式进行探索？” 关于特征选择、主动特征值获取、协变量移位的解释的其他一些应用论文中重点介绍了可解释人工智能领域的研究人员开发了多种方法来帮助用户了解复杂监督学习模型的预测。相比之下，解释模型输出的不确定性受到的关注相对较少。我们采用流行的 Shapley 值框架来解释各种类型的预测不确定性，量化每个特征对单个模型输出的条件熵的贡献。我们考虑具有修改后的特征函数的博弈，并从信息论和条件独立性测试中找到所得的沙普利值与基本量之间的深层联系。我们概述了具有可证明保证的有限样本错误率控制的推理程序，并实现了一种有效的算法，该算法在真实和模拟数据的一系列实验中表现良好。我们的方法可应用于协变量偏移检测、主动学习、特征选择和主动特征值获取。   由   提交 /u/TaXxER   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18ud5zn/r_infoshap_explaining_predictive_uncertainty_with/</guid>
      <pubDate>Sat, 30 Dec 2023 10:55:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] Stability AI 会成为第一个在 2024 年破产的生成型 AI 独角兽吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uclmy/d_will_stability_ai_be_the_first_generative_ai/</link>
      <description><![CDATA[   /u/milaworld  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uclmy/d_will_stability_ai_be_the_first_generative_ai/</guid>
      <pubDate>Sat, 30 Dec 2023 10:16:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 机器学习领域 CS 博士对于顶尖项目的竞争力（24 秋季）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18uajqj/d_competitiveness_of_cs_phd_in_ml_for_top/</link>
      <description><![CDATA[我最近在其他地方读到一篇文章，声称今年顶尖机构的 ML 领域的 CS 博士招生竞争变得异常激烈。根据该帖子，对于美国排名前 20 的大学，只有在 ICML/NeurIPS/ICLR 上至少发表三篇第一作者论文的人才有机会，并且如果满足以下条件，则需要超过三篇论文：你的论文没有在这三个地点发表。他们还声称，对于排名前 50 的大学，您至少需要在 ICML/NeurIPS/ICLR 发表一篇第一作者论文才能被考虑。 我知道，进入顶尖博士课程的竞争非常激烈。 ML，但我发现这个信息非常可疑，因为我认为甚至不会有那么多申请者在 ICML/NeurIPS/ICLR 博士前至少拥有三篇论文。我个人认识一些顶尖大学的博士生，他们中的很多人在申请时都达不到这样的标准。但这个周期可能非常不同，并且变得特别有竞争力。 如果他们的说法确实属实，我认为我们当前的学术体系和出版文化可能存在更大的问题。  p&gt; 我将其发布在 r/MachineLearning 上，稍后我会将其交叉发布到 r/gradadmissions 在我弄清楚如何做到这一点之后。  &amp;# 32；由   提交 /u/zhxch   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18uajqj/d_competitiveness_of_cs_phd_in_ml_for_top/</guid>
      <pubDate>Sat, 30 Dec 2023 07:59:56 GMT</pubDate>
    </item>
    <item>
      <title>[R] 大型语言模型世界国际象棋锦标赛🏆♟️</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18u31w8/r_large_language_models_world_chess_championship/</link>
      <description><![CDATA[通过国际象棋的战略视角探索大型语言模型 (LLM) 的新兴能力，精心策划首届 LLM 世界象棋锦标赛。比赛采用循环赛制，大型语言模型的巨头：OpenAI 的 GPT-4 Turbo 和GPT-3.5 Turbo、Google DeepMind 的 Gemini-Pro 和 Mistral AI 的 Mixtral-8x7B 相互较量。 在冠军赛中，每位法学硕士与其他法学硕士进行了 30 场比赛，黑白交替。&lt; /p&gt; “自我反省的思想链”每个模型都使用一次性提示。使用 python-chess 库来确保遵守官方国际象棋规则。 GPT-4 Turbo 夺得冠军，而 Gemini-Pro 尽管得到了 Google 的大力支持，但遇到了推理挑战，表现不佳。 Mixtral 以其先进的推理能力超出了预期。有关比赛的全面视图，请参阅锦标赛的 联盟表。 期待详细的博客文章、概述方法和研究结果的 arXiv 论文、GitHub 存储库、PGN 文件、游戏视频和巫妖链接并附有专家评论。 https://www.linkedin.com /posts/sherazmit_llm-prompt-chess-activity-7146175489622097920-SVTV ​   由   提交 /u/PerformanceRound7913   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18u31w8/r_large_language_models_world_chess_championship/</guid>
      <pubDate>Sat, 30 Dec 2023 01:14:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/18kkdbb/d_simple_questions_thread/</guid>
      <pubDate>Sun, 17 Dec 2023 16:00:19 GMT</pubDate>
    </item>
    </channel>
</rss>