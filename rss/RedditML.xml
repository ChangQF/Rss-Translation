<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 02 Dec 2024 18:24:18 GMT</lastBuildDate>
    <item>
      <title>[D] 处理图神经网络中不同的输出维度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4uyn9/d_handle_varying_output_dimension_in_graph_neural/</link>
      <description><![CDATA[我有一个关于在训练期间处理图形神经网络 (GNN)中不同输出维度的问题。我正在使用组合图（合并任务和计算图），其中结构类似于任务图，但计算节点信息集成到特征中。由于任务图和计算图（节点数）都可能变化，我使用前馈层将节点和边缘特征转换为固定的超参数嵌入维度。但是，数据集包含具有不同数量计算节点的实例。例如，一个实例 (A) 可能有 5 个计算节点，而另一个实例 (B) 可能有 7 个计算节点。鉴于这是使用 GNN 的调度任务，输出维度必须与计算节点的数量匹配，因为任务被分配给这些节点。我想知道如何处理 GNN 中不同的输出维度，以及是否有任何标准方法来管理这种变化。谢谢！    由   提交  /u/bipulthapa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4uyn9/d_handle_varying_output_dimension_in_graph_neural/</guid>
      <pubDate>Mon, 02 Dec 2024 13:29:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 简化的 RNN 通过并行训练和减少参数实现类似 Transformer 的性能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4urpr/r_simplified_rnns_achieve_transformerlike/</link>
      <description><![CDATA[本文系统地研究了 RNN 是否足以完成目前由 Transformer 主导的许多 NLP 任务。研究人员在保持模型大小、训练数据和其他变量不变的情况下，进行了比较 RNN 和 Transformer 的受控实验。 关键技术要点： - 使用匹配的参数在语言建模和 seq2seq 任务上测试了这两种架构（70M-1.5B） - 引入了“具有并行生成的 RNN” （RPG）允许 RNN 像 Transformer 一样并行生成 token - 在包括 WikiText-103 和 WMT14 英德翻译在内的标准基准上进行评估 - 通过探测任务和注意模式分析分析表示能力 主要结果：- RNN 在 WikiText-103 语言建模上匹配或优于类似大小的 Transformer - Transformer 在翻译任务上显示出 1-2 BLEU 分数优势 - RPG 实现了 Transformer 生成速度的 95% 且准确度损失最小 - RNN 表现出更强的局部上下文建模，而 Transformer 擅长长距离依赖 我认为这项工作提出了关于现代 NLP 中架构选择的重要问题。虽然 Transformer 已成为默认设置，但 RNN 可能仍然适用于许多应用程序，尤其是那些专注于局部上下文的应用程序。并行生成技术可以使 RNN 更适用于生产部署。 我认为结果表明我们应该重新考虑特定用例的 RNN，而不是假设 Transformer 总是最佳的。 RNN 的计算效率对于资源受限的应用尤其有价值。 TLDR：综合比较表明，在控制模型大小和训练的情况下，RNN 可以在某些 NLP 任务上与 transformer 匹敌。介绍了 RNN 的并行生成技术。结果表明，架构选择应取决于特定的应用需求。 完整摘要在这里。论文这里    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4urpr/r_simplified_rnns_achieve_transformerlike/</guid>
      <pubDate>Mon, 02 Dec 2024 13:19:02 GMT</pubDate>
    </item>
    <item>
      <title>[R] 包含 300 多个生产 LLM 实现的综合数据库，其中包含技术架构详细信息</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4udds/r_a_comprehensive_database_of_300_production_llm/</link>
      <description><![CDATA[为 ML 从业者分享宝贵的资源：一个新发布的数据库，记录了 300 多个现实世界的 LLM 实现，并提供了详细的技术架构和工程决策。 这个社区可能感兴趣的关键方面：  生产中的检索增强生成 (RAG) 架构 微调决策和性能比较 嵌入策略和矢量数据库实现 模型优化技术和量化方法 评估方法和监控系统  涵盖的值得注意的技术实现：  Anzen 使用 BERT 的文档分类系统（生产准确率为 95%） 巴克莱的 MLOps 演变以实现监管合规性 MosaicML 从培训和部署 MPT Emergent Methods 用于新闻处理的实时 RAG 系统 卡塔尔计算研究所的 T-RAG 架构  技术重点领域：  模型服务架构 训练基础设施决策 延迟优化策略 成本-性能权衡 生产监控方法  每个案例研究包括：  可用的技术架构图 性能指标和基准 实施挑战和解决方案 基础设施决策和基本原理 扩展注意事项  URL：https://www.zenml.io/llmops-database/ 我们还通过提交表单接受生产实施的技术撰写：https://docs.google.com/forms/d/e/1FAIpQLSfrRC0_k3LrrHRBCjtxULmER1-RJgtt1lveyezMY98Li_5lWw/viewform 特别感兴趣的是这个社区对不同规模部署中出现的架构模式的看法。 编辑：我们还将跨领域的技术主题综合到摘要中播客，适合对高级模式感兴趣的人。 编辑：随附的博客综合了许多学习内容： https://www.zenml.io/blog/demystifying-llmops-a-practical-database-of-real-world-generative-ai-implementations    提交人    /u/htahir1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4udds/r_a_comprehensive_database_of_300_production_llm/</guid>
      <pubDate>Mon, 02 Dec 2024 12:58:02 GMT</pubDate>
    </item>
    <item>
      <title>[P]Levenberg-Marquardt训练算法的PyTorch实现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4ubbd/p_pytorch_implementation_of_levenbergmarquardt/</link>
      <description><![CDATA[大家好， 如果有人感兴趣，这里有一个我开发的 Levenberg-Marquardt (LM) 算法的 PyTorch 实现。 GitHub Repo：torch-levenberg-marquardt 一个 Levenberg-Marquardt (LM) 优化算法的 PyTorch 实现，支持针对回归和分类问题的小批量训练。它利用 GPU 加速并提供可扩展的框架，支持不同的损失函数和可定制的阻尼策略。 TensorFlow 实现也可用：tf-levenberg-marquardt 安装 pip install torch-levenberg-marquardt     提交人    /u/fabiodimarco   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4ubbd/p_pytorch_implementation_of_levenbergmarquardt/</guid>
      <pubDate>Mon, 02 Dec 2024 12:54:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] RuleOpt v.1.1：基于优化的分类规则学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4tzd0/r_ruleopt_v11_optimizationbased_rule_learning_for/</link>
      <description><![CDATA[      论文：https://arxiv.org/abs/2104.10751 软件包： https://github.com/sametcopur/ruleopt 文档： https://ruleopt.readthedocs.io/ RuleOpt 是一种基于优化的规则学习算法，专为分类问题而设计。RuleOpt 注重可扩展性和可解释性，利用线性规划进行规则生成和提取。 Python 库 ruleopt 能够从集成模型中提取规则，并且还实现了一种新颖的规则生成方案。该库确保与现有的机器学习管道兼容，并且对于解决大规模问题特别有效。 以下是ruleopt的一些亮点：  高效的规则生成和提取：利用线性规划进行可扩展的规则生成（独立的机器学习方法）以及从训练有素的随机森林和增强模型中提取规则。 可解释性：通过为规则分配成本来优先考虑模型透明度，以实现与准确性的理想平衡。 与机器学习库集成：促进与知名的Python库scikit-learn，LightGBM和XGBoost以及现有的机器学习管道的顺利集成。 广泛的求解器支持：支持各种求解器，包括Gurobi，CPLEX和OR-Tools。  通过最新版本的更新，RuleOpt 现在即使使用免费求解器 OR-Tools 也很快，即使在大型数据集上也是如此！在下图中，您可以看到新版本与以前版本相比在运行时间方面的表现。 Training Times v1.0 vs v1.1 我们很乐意听到您的反馈、问题或您可能有的任何其他疑问！    提交人    /u/zedeleyici3401   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4tzd0/r_ruleopt_v11_optimizationbased_rule_learning_for/</guid>
      <pubDate>Mon, 02 Dec 2024 12:36:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 特征生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4qwt4/r_feature_generation/</link>
      <description><![CDATA[      我提前为一个可能很愚蠢的问题道歉。 我正在尝试复制一篇研究论文，其中一些 ML 模型已经过训练以对金属切削刀具进行状态监测，所以我的问题是关于特征生成的。 假设我有一个包含 6 个信号（特征）的数据框，行是测量值在某个时间。要生成一个新特征，比如 RMS 值，我只需要进行 6 次测量并计算每行 6 个数字的 RMS 值？这会是我的新功能吗？ 谢谢。 https://preview.redd.it/dsjfcapthe4e1.png?width=560&amp;format=png&amp;auto=webp&amp;s=b22c007b2d2a73612280d0ecfa6556b68b793a17    提交人    /u/su_25_frogfoot   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4qwt4/r_feature_generation/</guid>
      <pubDate>Mon, 02 Dec 2024 09:04:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 对于布局复杂的 PDF，最佳的分块方法是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4pkmh/r_best_chunking_method_for_pdfs_with_complex/</link>
      <description><![CDATA[我正在开发一个基于 RAG 的 PDF 查询系统，专门用于包含多列表、图像、跨多页的表格、包含图像的表格的复杂 PDF。 我想为此类 PDF 找到最佳分块策略。 目前我正在使用 RecursiveCharacterTextSplitter。对于复杂的 PDF，你们觉得哪种方法最有效？    提交人    /u/ElectronicHoneydew86   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4pkmh/r_best_chunking_method_for_pdfs_with_complex/</guid>
      <pubDate>Mon, 02 Dec 2024 07:24:21 GMT</pubDate>
    </item>
    <item>
      <title>[R] 在 AWS Sagemaker 中对 DeepAR 框架进行查询</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4gwxy/r_queries_on_deepar_framework_in_aws_sagemaker/</link>
      <description><![CDATA[嗨， 我正在尝试为各种商店实施 deepAr 以预测未来的销售情况（每家商店有约 10k 个不同产品的 SKU）。由于 SKU 的规模庞大，我无法一次性对所有数据进行单次训练。我正在考虑按商店进行训练。  如何在 AWS 中并行进行训练？每个商店的训练过程最多需要 30 分钟； 如何处理数据中不存在的看不见的 SKU？  谢谢。    提交人    /u/skw1990   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4gwxy/r_queries_on_deepar_framework_in_aws_sagemaker/</guid>
      <pubDate>Sun, 01 Dec 2024 23:33:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 人思人工智能研究员/住院医师——接受任何新毕业生/入门级人员吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4e0ah/d_anthropic_ai_fellowresidents_any_new/</link>
      <description><![CDATA[你好。入门级或新毕业生是否可以进入 Anthropic 奖学金或住院医师项目？过去被录取的人，你的简历和经历是什么样的？    提交人    /u/geekgeek2019   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4e0ah/d_anthropic_ai_fellowresidents_any_new/</guid>
      <pubDate>Sun, 01 Dec 2024 21:25:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何处理图神经网络训练中不同的特征维度？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4dbvi/d_how_to_handle_varying_feature_dimensions_in/</link>
      <description><![CDATA[我有一个关于在图形神经网络训练中处理具有不同特征维度的数据集的问题。例如，在一个训练实例（我们称之为数据集 A）中，节点特征的维度为 4，边特征的维度为 16。在另一个实例（数据集 B）中，节点特征的维度为 5，边特征的维度为 25。其他数据集也可能具有不同的特征维度。 在使用此类数据集训练 GNN 模型时，用于处理每个实例的不同特征维度的标准方法是什么？我将不胜感激任何有关如何处理此问题的指导或方向。谢谢！    提交人    /u/bipulthapa   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4dbvi/d_how_to_handle_varying_feature_dimensions_in/</guid>
      <pubDate>Sun, 01 Dec 2024 20:57:35 GMT</pubDate>
    </item>
    <item>
      <title>[P] Promptwright - 使用 LLM（本地或托管）生成大型合成数据集的开源项目</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h4bcz2/p_promptwright_open_source_project_to_generate/</link>
      <description><![CDATA[嘿 r/machinelearning， Promptwright，一个免费使用的开源工具，旨在使用本地大型语言模型或众多托管模型（OpenAI、Anthropic、Google Gemini 等）之一轻松生成合成数据集 主要特点： * 支持多个 LLM 提供商：通过 Ollama、VLLM 等与大多数 LLM 服务提供商和 LocalLLM 配合使用 * 可配置的说明和提示：通过脚本在 YAML 中定义自定义说明和系统提示，与以前一样。 * 命令行界面：直接从命令行运行生成任务 * 推送到 Hugging Face：使用自动数据集卡和标签将生成的数据集推送到 Hugging Face Hub 这是在最新版本上使用 promptwright 创建的示例数据集： https://huggingface.co/datasets/stacklok/insecure-code/viewer 这是使用“mistral-nemo:12b”从以下模板生成的，但老实说，大多数模型都能很好地执行，即使是小型 1/3b 模型也是如此。 system_prompt：“您是编程助理。您的任务是生成不安全代码的示例，突出显示漏洞，同时保持准确的语法和行为。” topic_tree： args： root_prompt：“跨多语言编程语言的不安全代码示例。” model_system_prompt: &quot;&lt;system_prompt_placeholder&gt;&quot; # 将被 system_prompt 替换 tree_degree: 10 # 广泛覆盖语言（例如 Python、JavaScript、C++、Java） tree_depth: 5 # 特定漏洞的深度层次结构（例如 SQL 注入、XSS、缓冲区溢出）temperature: 0.8 # 高度创造力以多样化示例 provider: &quot;ollama&quot; # LLM 提供者 model: &quot;mistral-nemo:12b&quot; # 模型名称 save_as: &quot;insecure_code_topictree.jsonl&quot; data_engine: args: instructions: &quot;用多种编程语言生成不安全的代码示例。每个示例都应包括对漏洞的简要说明。&quot; system_prompt: &quot;&lt;system_prompt_placeholder&gt;&quot; # 将被 system_prompt 替换 provider: &quot;ollama&quot; # LLM 提供程序 model: &quot;mistral-nemo:12b&quot; # 模型名称temperature: 0.9 # 鼓励示例中的多样性max_retries: 3 # 最多重试 3 次失败提示dataset:creation:num_steps: 15 # 在 10 次迭代中生成示例batch_size: 10 # 每次迭代生成 5 个示例provider: &quot;ollama&quot; # LLM 提供程序model: &quot;mistral-nemo:12b&quot; # 模型名称sys_msg: true # 在数据集中包含系统消息（默认值：true）save_as: &quot;insecure_code_dataset.jsonl&quot; # Hugging Face Hub 配置（可选）huggingface: # 格式为&quot;username/dataset-name&quot;的存储库repository: &quot;hfuser/dataset&quot; # 也可以通过 HF_TOKEN 环境变量或 --hf-token CLI 选项提供令牌 token: &quot;$token&quot; # 数据集的附加标签（可选） # &quot;promptwright&quot; 和 &quot;synthetic&quot; 标签会自动添加 tags: - &quot;promptwright&quot;  我们已在内部将它用于一些项目，效果非常好。您可以处理数千个样本，而不必担心 API 成本或速率限制。此外，由于一切都在本地运行，您不必担心敏感数据离开您的环境。 代码是 Apache 2 许可的，我们很乐意收到社区的反馈。如果您正在为 ML 进行任何类型的合成数据生成，请尝试一下并告诉我们您的想法！ 链接： 查看 examples 文件夹，获取生成代码、科学或创意 ewr 的示例 非常乐意听到您的想法和建议，如果您发现任何改进空间，请随时提出和发布或发出拉取请求。    提交人    /u/zero_proof_fork   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h4bcz2/p_promptwright_open_source_project_to_generate/</guid>
      <pubDate>Sun, 01 Dec 2024 19:33:47 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h46e6j/d_simple_questions_thread/</guid>
      <pubDate>Sun, 01 Dec 2024 16:00:30 GMT</pubDate>
    </item>
    <item>
      <title>[R] 来源：为什么猎犬的 KG 表现优于 RD？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h447eu/r_sources_reasons_why_kg_outperformes_rd_in/</link>
      <description><![CDATA[是否有任何资料讨论为什么 Retriever 与 KG 配合使用效果比 RD 更好？我发现说它更好是非常直观的，因为在知识图中我们拥有更多的语义结构，并且可以有效地发现关系。在我看来，“图当然更丰富/更密集”，但在论文合作时，我突然意识到我无法证明这一说法。我找不到任何资料可以真正解释为什么会这样。 我得到的唯一资料是这个： https://arxiv.org/abs/2311.07509 去年在子版块中也有：https://www.reddit.com/r/LocalLLaMA/comments/17vy1bo/a_benchmark_to_understand_the_role_of_knowledge/ 所以我们只能说&amp;“我们证明我们的决定是正确的，因为 KG 比 RD 效果更好 [基准论文来源]&amp;; 我本来很想讨论为什么 KG 更适合，并给出关于信息密度、语义结构或相关实体的更好选择的论据。但我找到的只是一些文章，它们散布着荒谬的主张或指出了更简单/原生的实现，从技术上讲，这也可以通过 RD 实现。 有人可以告诉我资料来源吗？很想阅读关于更好性能原因的深入讨论。    提交人    /u/PopPsychological4106   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h447eu/r_sources_reasons_why_kg_outperformes_rd_in/</guid>
      <pubDate>Sun, 01 Dec 2024 14:17:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] Qwen-VL：用于理解、定位、文本阅读等的多功能视觉语言模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h40wms/r_qwenvl_a_versatile_visionlanguage_model_for/</link>
      <description><![CDATA[  由    /u/moschles  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h40wms/r_qwenvl_a_versatile_visionlanguage_model_for/</guid>
      <pubDate>Sun, 01 Dec 2024 10:59:28 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>