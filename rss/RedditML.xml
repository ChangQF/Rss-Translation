<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Fri, 16 Aug 2024 12:29:09 GMT</lastBuildDate>
    <item>
      <title>[P] 生产中的迭代模型改进</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etn0x2/p_iterative_model_improvement_in_production/</link>
      <description><![CDATA[大家好， 我创建了一个多类分类模型，并在一个带标签的数据集上对其进行了训练。说实话，在本地数据集上表现得相当不错，现在我正打算将其软启动到生产环境中。输入数据将转换为 n 维输入向量，绘制在图表上时不会形成凸形或规则形状（至少我的 EDA 显示了这一点）。由于我无法预见所有可能的模型输入，因此该模型无法完美处理每种情况，我想这没问题，但我正在寻找广泛的用例。这将导致大量误报，我想将其迭代添加到我的训练数据语料库中并随着时间的推移改进模型。 我正在寻找一种有效的方法来识别和管理这些误报。我在考虑：1）随机抽样数据子集并手动标记以验证其是真阳性还是假阳性。 2）获取用户反馈以识别错误分类的反馈。 3）使用聚类技术，其指标包括 Silhouette 分数、Davies-Bouldin 指数、Calinski-Harabasz 指数 (CH)、归一化互信息 (NMI) 或 Dunn 指数。 4）结合 1）和 3）？识别一些假阳性，然后通过聚类找到可能也是假阳性的类似结果 我的最终目标是创建一个随着时间推移不断改进的管道。您将如何解决这个问题？谢谢！    提交人    /u/Queasy_Tailor_6276   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etn0x2/p_iterative_model_improvement_in_production/</guid>
      <pubDate>Fri, 16 Aug 2024 12:06:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] GPT 样式模型可以用于文件压缩、图像升级和恢复吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etlwku/d_can_gptstyle_models_be_used_for_file/</link>
      <description><![CDATA[我一直在思考这个问题 - 是否真的有可能直接在文件（如图像文件）的原始字节数据上训练 GPT 样式的仅解码器架构？我们的想法是学习文件数据中的基础统计模式，然后可能使用模型的概率分布来执行以下操作：  通过更有效地对数据进行建模来设计新的文件压缩算法 通过让模型生成文件中缺失/损坏的部分，对模型进行微调以执行图像升级或恢复等任务  这似乎是一种有趣的方法，因为 GPT 样式的模型已经表现出非凡的能力来捕获自然语言数据中的统计模式。但我不确定同样的原则是否适用于图像文件等更结构化的二进制数据。 这是一个愚蠢或不切实际的想法吗？以前有人尝试过这样的事情吗？我真的很想听听社区对这种方法的潜力和挑战的看法。    提交人    /u/No-Point1424   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etlwku/d_can_gptstyle_models_be_used_for_file/</guid>
      <pubDate>Fri, 16 Aug 2024 11:06:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] PINN 的嵌套 AD</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etkmm6/r_nested_ad_for_pinns/</link>
      <description><![CDATA[我目前正在尝试求解 Lu = f 形式的 PDE，其中 L 是二阶微分算子。我正在进行无监督学习，损失函数只是残差 Lv - f 的通常 MSE，其中 v 是我对 u 的近似值。 由于 L 具有二阶导数，这意味着我们在训练期间获取网络梯度时会获取三阶导数。这太麻烦了（我使用的是 Flux.jl，而 Zygote 无法很好地处理嵌套的三阶 AD），所以我最终求助于 L 的有限差分离散化，这样 AD 的唯一应用就是网络本身的梯度，而没有另外 2 个嵌套的梯度。当然，我很想避免使用有限差分，但我真的没有其他方法。 有人处理过类似的情况吗？根据我的发现，似乎大家一致认为三阶嵌套 AD 确实不切实际，但我希望它还有更多内容。 提前感谢任何输入！ 编辑：在许多情况下，可以以变分形式重新计算问题以将阶数降低 1，但不幸的是，这对我的 PDE 来说是不可能的    提交人    /u/Fleico   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etkmm6/r_nested_ad_for_pinns/</guid>
      <pubDate>Fri, 16 Aug 2024 09:45:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 什么是“低三角因果掩蔽”？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etia89/d_what_is_lowtriangle_causal_masking/</link>
      <description><![CDATA[在 https://docs.nvidia.com/megatron-core/developer-guide/latest/api-guide/context_parallel.html 上写着“[上下文并行性很好，因为] 消除了低三角因果掩蔽导致的不必要计算”。这个术语起源于哪里，请问我可以看一个例子吗？    提交人    /u/khidot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etia89/d_what_is_lowtriangle_causal_masking/</guid>
      <pubDate>Fri, 16 Aug 2024 07:03:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 哈希与关键点检测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eti3vk/d_hashing_vs_keypoint_detection/</link>
      <description><![CDATA[如果我必须对图像进行指纹识别，就像为图像赋予唯一身份一样。图像是任何物体的图片。我可以使用什么技术。给定图像的模仿，我需要说它不是原始图像。但底线是要对物体进行指纹识别。 编辑：我正在努力为对象创建指纹，首先使用高分辨率高清质量图像，将其存储在我的数据库中。接下来，我计划使用我的手机实时拍摄同一物体的照片。扫描的物体被验证为属于其创建者，从而提供了一种验证形式。由于实时图片中的光照将不可避免地发生变化，基于梯度的方法可能不是签名的理想选择。但是，我正在使用物体的固有图像，因此我同时拥有反照率和阴影信息。我应该使用哪种技术来创建指纹 - 散列或关键点检测还是有其他技术？    提交人    /u/PositiveResponse7678   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eti3vk/d_hashing_vs_keypoint_detection/</guid>
      <pubDate>Fri, 16 Aug 2024 06:51:16 GMT</pubDate>
    </item>
    <item>
      <title>[D] 可重复性检查表 AAAI25</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ethhro/d_reproducibility_checklist_aaai25/</link>
      <description><![CDATA[大家好， 我正在准备向 AAAI 提交论文，我遇到了可重复性检查表的要求。我对如何提交此检查表有点困惑。它应该作为附录包含在主要论文中，还是需要作为单独的文档上传？此外，如果它包含在论文中，它是否计入页数限制？ 任何曾经向 AAAI 提交过论文或有此过程经验的人的见解都将不胜感激！ 提前致谢！    提交人    /u/Ok_Butterfly7408   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ethhro/d_reproducibility_checklist_aaai25/</guid>
      <pubDate>Fri, 16 Aug 2024 06:10:21 GMT</pubDate>
    </item>
    <item>
      <title>[P] 佛罗里达大西洋大学 ML Hackathon</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etenk6/p_florida_atlantic_university_ml_hackathon/</link>
      <description><![CDATA[嗨，帖子有点不一样！威廉·哈恩博士和机器感知认知机器人实验室将于 8 月 23 日至 25 日在佛罗里达大西洋大学博卡拉顿校区举办一场有现金奖励的 ML 黑客马拉松。这项活动非常适合有志向的学生、研究人员和企业家，他们喜欢结交志同道合的朋友、寻找工作/实习机会并实现自己的想法。我们提供免费入场、食物和饮料。欢迎任何学校的任何人创造他们想要的东西，无论是项目、研究还是初创企业。很乐意共同建立这个社区并让您加入！ 您可以在我们的 Luma 上阅读有关它的更多信息：https://lu.ma/unlearntolearn 我们的实验室：https://mpcrlab.com，FAU 的沙盒：https://www.fau.edu/sandbox/    提交人    /u/ekkolapto1   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etenk6/p_florida_atlantic_university_ml_hackathon/</guid>
      <pubDate>Fri, 16 Aug 2024 03:22:26 GMT</pubDate>
    </item>
    <item>
      <title>[N] NeurIPS 2024 评测分析器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etd10k/n_neurips_2024_review_analyzer/</link>
      <description><![CDATA[      大家好， 我创建了一个工具，可以根据历史数据分析您的 NeurIPS 2024 复习分数和被录取的机会。 请在以下网址试用该工具：https://scienhub.com/review-analyzer/neurips 截图： https://preview.redd.it/3g5li04snxid1.png?width=1072&amp;format=png&amp;auto=webp&amp;s=f80ea86a942f691659348e36ed67c69c36acea29 https://preview.redd.it/2zzxtomsnxid1.png?width=1044&amp;format=png&amp;auto=webp&amp;s=665aadf7ff8cb7f0224018535c21f0f46648d8e2    提交人    /u/batchfy   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etd10k/n_neurips_2024_review_analyzer/</guid>
      <pubDate>Fri, 16 Aug 2024 01:59:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审稿人 2 - NeurIPS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etb4qh/d_reviewer_2_neurips/</link>
      <description><![CDATA[NeurIPS 辩驳期终于结束了。大家的审稿怎么样？ 我和一位审稿人打过交道，这是最糟糕的经历。对于最初的评论，他/她只写了一个简短的段落，问了一堆可以通过论文内容轻松回答的问题，然后给了 3 分和 4 分的置信度。对于辩驳，这位审稿人甚至无法理解训练数据和测试数据之间的区别。我花了两天时间解释了这种区别。最后，审稿人留下了关于论文的错误陈述然后消失了。典型的审稿人 2。    提交人    /u/DrSolar789   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etb4qh/d_reviewer_2_neurips/</guid>
      <pubDate>Fri, 16 Aug 2024 00:27:46 GMT</pubDate>
    </item>
    <item>
      <title>[R] LayerMerge：通过层修剪和合并实现神经网络深度压缩 (ICML 2024)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1esy876/r_layermerge_neural_network_depth_compression/</link>
      <description><![CDATA[      论文： https://arxiv.org/abs/2406.12837 代码： https://github.com/snu-mllab/LayerMerge TL;DR：LayerMerge 通过修剪和合并卷积层和激活层来减少 CNN 和扩散模型的深度。 定性示例LayerMerge 概述：LayerMerge 是一种新颖的方法，可提高卷积神经网络的效率而不会损失性能。传统的减少网络深度的方法通常遵循以下两种方法之一： 1. 修剪卷积层：积极删除参数，冒着丢失重要信息的风险。 2. 修剪激活层和合并层：消除冗余激活层并合并产生的连续卷积层，这可能会增加内核大小并抵消速度增益。 LayerMerge 通过联合修剪卷积层和激活函数来解决这些问题。它优化要删除的层，加快推理速度，同时最大限度地减少性能损失。由于此选择过程涉及指数搜索空间，我们制定了一个新的替代优化问题并通过动态规划有效地解决了它。 我们的结果表明，LayerMerge 在减少网络深度方面优于当前方法，包括图像分类和生成 演示展示了 LayerMerge 在 ImageNet 上使用 MobileNetV2-1.0 以及在 CIFAR10 上使用 DDPM 的有效性。    提交人    /u/jusjinuk   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1esy876/r_layermerge_neural_network_depth_compression/</guid>
      <pubDate>Thu, 15 Aug 2024 15:32:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于设置推荐渠道的提示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1esv81l/p_tips_on_setting_up_a_recommendations_pipeline/</link>
      <description><![CDATA[大家好， 我是一位经验丰富的 ML 专家，还没有接触过太多推荐，但我很快就需要建立一个新的推荐管道。我有一些问题，希望你们能帮我解答。 假设我有一个提供产品推荐的现有系统，假设我们有 10 个项目的轮播。为简单起见，假设我们关心的只是点击，我们有一个数据集，其中包含使用 ID、项目 ID、项目位置和点击（0 或 1）。现在假设我创建了一个简单的协同过滤算法（我知道有更智能的算法可以处理特征，但我想尽可能简单地开始），该算法使用用户和项目之间的效用矩阵，其中点击用作评级。 以下是我担心的一些问题：  位置偏差：每个项目的位置可能会影响结果。我可以引入一个映射函数，使用项目的位置来构建评级，但我必须从可能显著影响结果模型的任意映射开始，并且这种映射可能难以调整。有人对此有什么建议吗？ 探索与利用：一旦我们开始提供基于模型的推荐，我们将影响我们的训练数据，所以我希望建立一个老虎机系统，在插槽级别平衡探索和利用。因此，对于 10 个插槽中的每一个，我们掷骰子来决定我们是否要显示随机（在合理范围内）推荐或基于模型的推荐。理想情况下，我们希望仅使用随机数据进行训练以避免偏差，但这会导致大量数据丢失，所以也许我仍然可以使用“利用”臂，但只是进一步降低评级值——这再次是相当任意的  关于如何处理这些问题有什么建议吗？这些肯定是经过充分研究和理解的挑战。我还想知道，刚刚开始采用建议的公司是否会完全忽略这些挑战，如果是这样，他们是否仍然可以获得可接受的性能。 非常感谢您的阅读！    提交人    /u/de1pher   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1esv81l/p_tips_on_setting_up_a_recommendations_pipeline/</guid>
      <pubDate>Thu, 15 Aug 2024 13:30:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我设计了一种潜在的类似 Transformer 的架构，时间复杂度为 O(n)，并行化后可简化为 O(log n)。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1esteqd/r_ive_devised_a_potential_transformerlike/</link>
      <description><![CDATA[[R] 我尝试构建一个使用简单除法和计算方法的架构。从我所看到和理解的情况来看，它似乎是可行的，至少在我看来是这样。虽然我的代码中可能存在错误，但我已经检查并测试过它，没有发现任何错误。 我想知道这种方法是否有什么新意。如果是这样，我有兴趣与您合作撰写有关它的研究论文。此外，如果您能帮助我检查代码以查找任何潜在错误，我将不胜感激。 但最重要的是，我想知道这个架构，它是新的吗，有没有人尝试过这个或类似的东西， 我写了一篇包含代码的 Medium 文章。文章可从以下网址获取：https://medium.com/@DakshishSingh/equinox-architecture-divide-compute-775a8ff698fe 非常感谢您就此事提供的帮助和想法。如果您有任何疑问或需要澄清，请随时询问。    提交人    /u/Conscious-Gazelle-91   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1esteqd/r_ive_devised_a_potential_transformerlike/</guid>
      <pubDate>Thu, 15 Aug 2024 12:03:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] AgentGen：通过环境和任务生成增强基于大型语言模型的代理的规划能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1esk9q4/r_agentgen_enhancing_planning_abilities_for_large/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1esk9q4/r_agentgen_enhancing_planning_abilities_for_large/</guid>
      <pubDate>Thu, 15 Aug 2024 02:42:07 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢所有人在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Aug 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>