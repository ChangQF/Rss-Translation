<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions 或 /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Wed, 12 Feb 2025 15:18:10 GMT</lastBuildDate>
    <item>
      <title>结构化数据解析[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ins93r/structured_data_parsing_d/</link>
      <description><![CDATA[我正在尝试构建一个管道，它可以解析非常复杂的表格结构，包括多行列标题和很可能的内联图像/文本等。我​​目前的方法是使用 LLM 清理表格结构并编写 pandas 代码来查询表格，我首先提取数据开始的行，然后将列合并为一行，并让 LLM 重命名它们并提供描述。发布后我要求它根据查询为我编写 pandas 代码，然后使用输出生成响应，目前我还在使用启发式/微调 SETbert 和很可能其他 ML 模型完成前两个步骤，发布后我将调用 LLM 编写 python 代码并生成响应，这对许多表格来说都没问题，但对于更复杂的管道来说就开始崩溃了。有人知道其他获得更好结果的方法吗，具体来说，你使用/微调了哪些模型来实现这个效果？谢谢    由   提交  /u/ashblue21   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ins93r/structured_data_parsing_d/</guid>
      <pubDate>Wed, 12 Feb 2025 14:37:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于 Transformer 和图像到图像网络的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inqevv/d_question_regarding_transformers_and/</link>
      <description><![CDATA[最近，我有点不适应机器学习方法，这些方法的目标是将一幅图像转换为同一或不同域的另一幅图像。我在这里考虑的是分割和图像生成，尤其是 CT 或 MRI 重建等任务。  我的最新更新是 CNN 是首选架构。但与此同时，我预计，随着 LLM 和 Transformers 的出现，它们已经超越了这项任务。有人对这个主题有更多了解吗，也包括预训练模型？  提前谢谢大家！     提交人    /u/excel_foley   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inqevv/d_question_regarding_transformers_and/</guid>
      <pubDate>Wed, 12 Feb 2025 13:09:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 不规则时间序列数据中的因果推断？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inpgkw/d_causal_inference_in_irregular_time_series_data/</link>
      <description><![CDATA[大家好， 我读过的许多方法都假设采样分辨率是固定的，这是有道理的。还有通过对数据进行分组来预处理数据的方法，但是，考虑到因果效应确实发生在多个事件中，你们读过的任何材料处理非固定采样分辨率吗？因果结构会是什么样子的？ 非常感谢    提交人    /u/Sea_Farmer5942   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inpgkw/d_causal_inference_in_irregular_time_series_data/</guid>
      <pubDate>Wed, 12 Feb 2025 12:17:38 GMT</pubDate>
    </item>
    <item>
      <title>[R] LLM 作为多语言文本解毒的少样本数据注释器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1innuh3/r_llms_as_fewshot_data_annotators_for/</link>
      <description><![CDATA[本文介绍了一种使用 LLM 作为小样本学习器来生成高质量并行数据集进行文本解毒的方法。关键创新是使用现代 LLM 创建配对的有毒/无毒文本示例，在降低毒性的同时保持语义含义。 主要技术要点： - 使用精心策划的示例对进行小样本提示 - 实现多阶段过滤以确保质量 - 使用自动化指标验证语义保存 - 与现有方法相比，在保持含义的同时实现更好的毒性降低 - 创建比以前的方法更大、更高质量的并行数据集 结果： - 在标准基准上优于现有的解毒模型 - 显示出强大的跨领域泛化能力 - 仅用 3-5 个例子就证明了有效性 - 保持语义相似度得分 &gt;0.85 - 在测试集上将毒性得分降低 &gt;60% 我认为这对于需要在删除有害内容的同时保留含义的内容审核系统特别有价值。生成高质量并行数据的能力可以帮助训练更好的下游解毒模型。 我认为小样本方法特别有前景，因为它减少了对大型带注释数据集的需求，而手动创建这些数据集既昂贵又耗时。 TLDR：现代 LLM 可以使用小样本学习生成高质量的并行有毒/无毒文本对，从而为解毒系统提供更好的训练数据，同时保持语义含义。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1innuh3/r_llms_as_fewshot_data_annotators_for/</guid>
      <pubDate>Wed, 12 Feb 2025 10:17:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 大规模实时推理的挑战</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inl6pv/d_challenges_with_realtime_inference_at_scale/</link>
      <description><![CDATA[您好！我们正在实现一个支持实时客户互动的 AI 聊天机器人，但在用户流量大的情况下，我们的 LLM 的推理时间会成为瓶颈。即使使用 GPU 支持的基础设施，扩展成本也在迅速攀升。是否有人针对高吞吐量应用程序优化过 LLM，或者有公司提供可以有效处理此问题的平台/服务？很想听听在不牺牲质量的情况下减少延迟的方法。    提交人    /u/jameslee2295   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inl6pv/d_challenges_with_realtime_inference_at_scale/</guid>
      <pubDate>Wed, 12 Feb 2025 06:58:35 GMT</pubDate>
    </item>
    <item>
      <title>[R] 法学硕士可以自学如何更好地预测未来</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inks6r/r_llms_can_teach_themselves_to_better_predict_the/</link>
      <description><![CDATA[  由    /u/jsonathan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inks6r/r_llms_can_teach_themselves_to_better_predict_the/</guid>
      <pubDate>Wed, 12 Feb 2025 06:31:42 GMT</pubDate>
    </item>
    <item>
      <title>机器心理学？[R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1inh9cy/machine_psychologyr/</link>
      <description><![CDATA[嗨，我想知道你们中是否有人在这个领域工作过，或者对此有更多了解，我对心理学在机器学习中的应用很感兴趣。     提交人    /u/Nervous_Club09   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1inh9cy/machine_psychologyr/</guid>
      <pubDate>Wed, 12 Feb 2025 03:05:33 GMT</pubDate>
    </item>
    <item>
      <title>[研究] 新型聚类指标——Jaccard 集中指数</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1indsvi/research_novel_clustering_metric_the/</link>
      <description><![CDATA[我创建了一个新的聚类指标，称为 Jaccard-Concentration Index(JCI)，并将其上传为 Python 库。我最​​初创建它是为了帮助我测试我正在开发的聚类算法，但它似乎本身就很有用，所以我把它变成了一个库。 从技术上讲，它是两个指标合二为一。有一个集中函数，用于测量值列表中的总值在一个或几个索引内的压缩程度，还有 JCI 函数，它是提供直接评估结果的主要函数。 以下是该库的摘要： Jaccard 集中指数 (JCI) 是一个 Python 库，用于使用一种新颖的指标来评估聚类（或更一般地说，分类）的质量，该指标将众所周知的 Jaccard 指数与自定义集中分数相结合。它不仅考虑预测簇和真实簇之间的最佳匹配，还测量每个预测簇的质量在真实簇中的集中程度，从而提供更细致入微的簇纯度视图。 通常，在最少数量的真实簇中分配质量的预测簇得分更高。质量分布不均匀的簇（严重偏向一个或几个真实簇）的得分甚至更高。例如，如果有 4 个真正的聚类，则按 70-30-0-0 分割分布的预测聚类的得分将高于按 65-35-0-0 分割分布的聚类，而且有趣的是，按 70-10-10-10 分割分布的聚类的得分将高于按 70-10-10-10 分割分布的聚类。这种行为源于对与真正的聚类重叠强度的双重强调以及对重叠的关注。与真实聚类具有更高的最大重叠度通常是可取的，但集中剩余的质量也很重要，因为它减少了关于聚类中点属于哪个真实类的不确定性 - 使分类更有用。 本质上，Jaccard-Concentration 指数提供了一种平衡预测的精确度和召回率的平滑方法。 有关所涉及的函数和数学的更多详细信息，请参阅 GitHub 或 PyPI 上的项目描述。 欢迎提出所有想法和评论。    提交人    /u/Significant-Agent854   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1indsvi/research_novel_clustering_metric_the/</guid>
      <pubDate>Wed, 12 Feb 2025 00:15:14 GMT</pubDate>
    </item>
    <item>
      <title>[D] SSM 和线性注意力怎么了？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1in9y30/d_what_happened_to_ssms_and_linear_attentions/</link>
      <description><![CDATA[了解该研究领域的人可以总结一下 SSM 和 softmax 注意力替代方案的现状吗？它们是否已用于以客户为中心的模型，还是仍在研究中？它们的承诺是否只出现在纸面上的基准测试中？或者硬件加速器是否已经蚀刻了注意力，使其完全充满活力，而使用 SSM 或线性注意力替代方案只能提供边际收益，这对它们的复杂程度确实有吸引力？    提交人    /u/ApartmentEither4838   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1in9y30/d_what_happened_to_ssms_and_linear_attentions/</guid>
      <pubDate>Tue, 11 Feb 2025 21:27:30 GMT</pubDate>
    </item>
    <item>
      <title>可解释的时间序列预测人工智能 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1in57y1/explainable_ai_for_time_series_forecasting/</link>
      <description><![CDATA[是否有任何研究论文的功能实现专注于可解释的 AI 用于时间序列预测？我一直在广泛搜索，但没有一个库表现最佳。此外，请推荐其他方法来解释时间序列模型的结果并向业务利益相关者解释它们。    提交人    /u/Severe_Conclusion796   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1in57y1/explainable_ai_for_time_series_forecasting/</guid>
      <pubDate>Tue, 11 Feb 2025 18:15:41 GMT</pubDate>
    </item>
    <item>
      <title>[R] MaskNet 的持续相关性：利用乘性特征交互进行 CTR 预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1in4qsv/r_the_continued_relevance_of_masknet_leveraging/</link>
      <description><![CDATA[2021 年，在 ChatGPT 引发 AI 热潮之前，新浪微博公司的研究人员在新加坡 ACM 的 DLP-KDD 上介绍了 MaskNet，题为“MaskNet：通过实例引导掩码将特征乘法引入 CTR 排名模型”。这种使用深度神经网络中的实例引导掩码进行点击率 (CTR) 预测的特征乘法方法在当今的工业应用中仍然具有很高的竞争力。 MaskNet 超越了传统的加性特征交互，证明了即使人工智能格局迅速发展，重点领域的突破性创新也能经受住时间的考验。 关键技术亮点：  实例引导掩码：在特征嵌入和前馈层上动态执行元素乘法，提高模型强调信息特征的能力。 MaskBlock：结合层规范化、前馈层和乘法掩码的混合模块，允许加法和乘法交互共存。 性能提升：MaskNet 在真实数据集上的表现优于 DeepFM 和 xDeepFM，AUC 提高了高达 5.23%。 灵活的架构：提供串行（SerMaskNet）和并行（ParaMaskNet）配置适用于各种用例。  MaskNet 表明，将乘法运算合并到深度神经网络中可以显着捕获复杂的特征交互，从而为 CTR 预测提供更有效的方法。如果您在 CTR 或推荐系统中工作，本文将提供宝贵的见解。 阅读全文：https://www.shaped.ai/blog/masknet-ctr-ranking-innovation 期待听到您对这种方法的想法！    提交人    /u/skeltzyboiii   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1in4qsv/r_the_continued_relevance_of_masknet_leveraging/</guid>
      <pubDate>Tue, 11 Feb 2025 17:56:59 GMT</pubDate>
    </item>
    <item>
      <title>[D] 微调能赚大钱——怎么做到的？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imwnnp/d_finetuning_is_making_big_moneyhow/</link>
      <description><![CDATA[嘿！ 自从我担任计算机视觉研究员以来，我一直在研究 LLM 行业。 与计算机视觉任务不同，似乎许多公司（尤其是初创公司）都依赖于基于 API 的服务，例如 GPT、Claude 和 Gemini，而不是像 Llama 或 Mistral 这样的自托管模型。我还在这个 subreddit 中看到了很多讨论微调的帖子。 这让我很好奇！据报道，Together AI 的 ARR 已达到 1 亿美元以上，令我惊讶的是，微调似乎是其主要的收入驱动因素之一。微调是如何为如此高的收入数字做出贡献的？公司是否在大力投资它以获得更好的性能、数据隐私或成本节省？ 那么，为什么要微调模型而不是使用 API（GPT、Claude 等）？我真的想知道。  很想听听您的想法 - 提前谢谢！    提交人    /u/Vivid-Entertainer752   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imwnnp/d_finetuning_is_making_big_moneyhow/</guid>
      <pubDate>Tue, 11 Feb 2025 11:41:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 循环潜在推理：在不生成标记的情况下扩展语言模型中的测试时间计算</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1imwkns/r_recurrent_latent_reasoning_scaling_testtime/</link>
      <description><![CDATA[我发现这篇论文的主要贡献是重新思考我们如何通过连续循环处理而不是离散层来扩展推理过程中的计算。作者建议将模型深度视为一个连续参数，可以在推理时动态调整。 主要技术要点： - 引入“循环深度” - 允许信息多次循环通过组件 - 将深度建模为连续参数而不是离散层 - 使用微分方程的原理来创建平滑的信息流 - 根据任务复杂性实现自适应计算 主要结果： - 匹配较大模型的性能，同时减少 30-40% 的计算量 - 与传统架构相比，显示出更稳定的训练动态 - 展示了跨处理步骤的改进的信息保留 - 通过增加推理迭代实现了一致的性能扩展 我认为这种方法可以帮助解决我们扩展语言模型的一些基本效率低下问题。我们可以通过更智能的处理更好地利用现有参数，而不是简单地扩大模型。对深度的连续处理还为在部署期间平衡计算与性能提供了更大的灵活性。 我认为最大的挑战将是在实践中有效地实现这一点，特别是对于并行处理。与传统的前馈架构相比，循环性质增加了复杂性。然而，计算节省可能使它对许多应用程序来说是值得的。 TLDR：本文建议将神经网络深度视为连续的而不是离散的，使用循环处理在推理过程中更有效地扩展计算。显示出有希望的结果，在保持性能的同时减少了 30-40% 的计算量。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1imwkns/r_recurrent_latent_reasoning_scaling_testtime/</guid>
      <pubDate>Tue, 11 Feb 2025 11:35:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ilhw29/d_simple_questions_thread/</guid>
      <pubDate>Sun, 09 Feb 2025 16:00:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ie5qoh/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Fri, 31 Jan 2025 03:30:56 GMT</pubDate>
    </item>
    </channel>
</rss>