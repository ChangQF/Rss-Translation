<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions</description>
    <lastBuildDate>Fri, 16 Aug 2024 03:19:32 GMT</lastBuildDate>
    <item>
      <title>[N] NeurIPS 2024 评测分析器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etd10k/n_neurips_2024_review_analyzer/</link>
      <description><![CDATA[      大家好， 我创建了一个工具，可以根据历史数据分析您的 NeurIPS 2024 复习分数和被录取的机会。 请在以下网址试用该工具：https://scienhub.com/review-analyzer/neurips 截图： https://preview.redd.it/3g5li04snxid1.png?width=1072&amp;format=png&amp;auto=webp&amp;s=f80ea86a942f691659348e36ed67c69c36acea29 https://preview.redd.it/2zzxtomsnxid1.png?width=1044&amp;format=png&amp;auto=webp&amp;s=665aadf7ff8cb7f0224018535c21f0f46648d8e2    提交人    /u/batchfy   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etd10k/n_neurips_2024_review_analyzer/</guid>
      <pubDate>Fri, 16 Aug 2024 01:59:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审稿人 2 - NeurIPS</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1etb4qh/d_reviewer_2_neurips/</link>
      <description><![CDATA[NeurIPS 辩驳期终于结束了。大家的审稿怎么样？ 我和一位审稿人打过交道，这是最糟糕的经历。对于最初的评论，他/她只写了一个简短的段落，问了一堆可以通过论文内容轻松回答的问题，然后给了 3 分和 4 分的置信度。对于辩驳，这位审稿人甚至无法理解训练数据和测试数据之间的区别。我花了两天时间解释了这种区别。最后，审稿人留下了关于论文的错误陈述然后消失了。典型的审稿人 2。    提交人    /u/DrSolar789   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1etb4qh/d_reviewer_2_neurips/</guid>
      <pubDate>Fri, 16 Aug 2024 00:27:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 深入研究 CogVideoX-2B...但代价是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1et7dj6/d_diving_into_cogvideox2b_but_at_what_cost/</link>
      <description><![CDATA[      今天，我准备分享一个引人入胜的视频，以教育目的展示 CogVideoX-2B 的强大功能。但有一个问题——这个模型太大了，我的 Mac 花了很长时间才安装好它！😅 这让我开始思考：人工智能的发展是否受到硬件的阻碍？当一个模型就能将一台功能强大的机器推向极限时，在追求可访问的人工智能教育方面，我们还能走多远呢？ 我很想听听你对如何平衡尖端人工智能工作和硬件限制的看法。你遇到过类似的挑战吗？ 请继续关注——一旦我的 Mac 完成马拉松，我将展示一些令人兴奋的东西！ 🕒 AI #CogVideoX2B #GenerativeAI #TechChallenges #MachineLearning #Python #Education https://preview.redd.it/r8g83bmrdwid1.png?width=3024&amp;format=png&amp;auto=webp&amp;s=478f850d111b195f2816e2503d922a6df34f9eef    由    /u/lordamdal  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1et7dj6/d_diving_into_cogvideox2b_but_at_what_cost/</guid>
      <pubDate>Thu, 15 Aug 2024 21:41:27 GMT</pubDate>
    </item>
    <item>
      <title>[R] LayerMerge：通过层修剪和合并实现神经网络深度压缩 (ICML 2024)</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1esy876/r_layermerge_neural_network_depth_compression/</link>
      <description><![CDATA[      论文： https://arxiv.org/abs/2406.12837 代码： https://github.com/snu-mllab/LayerMerge TL;DR：LayerMerge 通过修剪和合并卷积层和激活层来减少 CNN 和扩散模型的深度。 定性示例LayerMerge 概述：LayerMerge 是一种新颖的方法，可提高卷积神经网络的效率而不会损失性能。传统的减少网络深度的方法通常遵循以下两种方法之一： 1. 修剪卷积层：积极删除参数，冒着丢失重要信息的风险。 2. 修剪激活层和合并层：消除冗余激活层并合并产生的连续卷积层，这可能会增加内核大小并抵消速度增益。 LayerMerge 通过联合修剪卷积层和激活函数来解决这些问题。它优化要删除的层，加快推理速度，同时最大限度地减少性能损失。由于此选择过程涉及指数搜索空间，我们制定了一个新的替代优化问题并通过动态规划有效地解决了它。 我们的结果表明，LayerMerge 在减少网络深度方面优于当前方法，包括图像分类和生成 演示展示了 LayerMerge 在 ImageNet 上使用 MobileNetV2-1.0 以及在 CIFAR10 上使用 DDPM 的有效性。    提交人    /u/jusjinuk   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1esy876/r_layermerge_neural_network_depth_compression/</guid>
      <pubDate>Thu, 15 Aug 2024 15:32:55 GMT</pubDate>
    </item>
    <item>
      <title>[P] 关于设置推荐渠道的提示</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1esv81l/p_tips_on_setting_up_a_recommendations_pipeline/</link>
      <description><![CDATA[大家好， 我是一位经验丰富的 ML 专家，还没有接触过太多推荐，但我很快就需要建立一个新的推荐管道。我有一些问题，希望你们能帮我解答。 假设我有一个提供产品推荐的现有系统，假设我们有 10 个项目的轮播。为简单起见，假设我们关心的只是点击，我们有一个数据集，其中包含使用 ID、项目 ID、项目位置和点击（0 或 1）。现在假设我创建了一个简单的协同过滤算法（我知道有更智能的算法可以处理特征，但我想尽可能简单地开始），该算法使用用户和项目之间的效用矩阵，其中点击用作评级。 以下是我担心的一些问题：  位置偏差：每个项目的位置可能会影响结果。我可以引入一个映射函数，使用项目的位置来构建评级，但我必须从可能显著影响结果模型的任意映射开始，并且这种映射可能难以调整。有人对此有什么建议吗？ 探索与利用：一旦我们开始提供基于模型的推荐，我们将影响我们的训练数据，所以我希望建立一个老虎机系统，在插槽级别平衡探索和利用。因此，对于 10 个插槽中的每一个，我们掷骰子来决定我们是否要显示随机（在合理范围内）推荐或基于模型的推荐。理想情况下，我们希望仅使用随机数据进行训练以避免偏差，但这会导致大量数据丢失，所以也许我仍然可以使用“利用”臂，但只是进一步降低评级值——这再次是相当任意的  关于如何处理这些问题有什么建议吗？这些肯定是经过充分研究和理解的挑战。我还想知道，刚刚开始采用建议的公司是否会完全忽略这些挑战，如果是这样，他们是否仍然可以获得可接受的性能。 非常感谢您的阅读！    提交人    /u/de1pher   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1esv81l/p_tips_on_setting_up_a_recommendations_pipeline/</guid>
      <pubDate>Thu, 15 Aug 2024 13:30:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] 我设计了一种潜在的类似 Transformer 的架构，时间复杂度为 O(n)，并行化后可简化为 O(log n)。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1esteqd/r_ive_devised_a_potential_transformerlike/</link>
      <description><![CDATA[[R] 我尝试构建一个使用简单除法和计算方法的架构。从我所看到和理解的情况来看，它似乎是可行的，至少在我看来是这样。虽然我的代码中可能存在错误，但我已经检查并测试过它，没有发现任何错误。 我想知道这种方法是否有什么新意。如果是这样，我有兴趣与您合作撰写有关它的研究论文。此外，如果您能帮助我检查代码以查找任何潜在错误，我将不胜感激。 但最重要的是，我想知道这个架构，它是新的吗，有没有人尝试过这个或类似的东西， 我写了一篇包含代码的 Medium 文章。文章可从以下网址获取：https://medium.com/@DakshishSingh/equinox-architecture-divide-compute-775a8ff698fe 非常感谢您就此事提供的帮助和想法。如果您有任何疑问或需要澄清，请随时询问。    提交人    /u/Conscious-Gazelle-91   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1esteqd/r_ive_devised_a_potential_transformerlike/</guid>
      <pubDate>Thu, 15 Aug 2024 12:03:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] AgentGen：通过环境和任务生成增强基于大型语言模型的代理的规划能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1esk9q4/r_agentgen_enhancing_planning_abilities_for_large/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1esk9q4/r_agentgen_enhancing_planning_abilities_for_large/</guid>
      <pubDate>Thu, 15 Aug 2024 02:42:07 GMT</pubDate>
    </item>
    <item>
      <title>[P] marimo 笔记本现在内置了对 SQL 的支持</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eshdzc/p_marimo_notebooks_now_have_builtin_support_for/</link>
      <description><![CDATA[      marimo - 一个用于 Python 的开源反应式笔记本 - 现在内置了对 SQL 的支持。您可以查询数据框、CSV、表格等，并以 Python 数据框的形式获取结果。 如需交互式教程，请在命令行中运行 pip install --upgrade marimo &amp;&amp; marimo tutorial sql 。 完整公告：https://marimo.io/blog/newsletter-5 文档/指南：https://docs.marimo.io/guides/sql.html https://preview.redd.it/rlwniug82qid1.png?width=1668&amp;format=png&amp;auto=webp&amp;s=b3919e2c6fdb7f1e9d2f1968ed546e4919d24b8b    提交人    /u/mmmmmmyles   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eshdzc/p_marimo_notebooks_now_have_builtin_support_for/</guid>
      <pubDate>Thu, 15 Aug 2024 00:26:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] 优化 LLM 测试时间计算的缩放比缩放模型参数更有效</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1esbkfr/r_scaling_llm_testtime_compute_optimally_can_be/</link>
      <description><![CDATA[  由    /u/AhmedMostafa16  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1esbkfr/r_scaling_llm_testtime_compute_optimally_can_be/</guid>
      <pubDate>Wed, 14 Aug 2024 20:17:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] Meta 取消了今年的 AI Residency 计划吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1es6c98/d_has_meta_cancelled_its_ai_residency_program_for/</link>
      <description><![CDATA[正如标题所示，meta 于 2023 年开放了它的驻留权，但出于某种原因，决定今年不开放。有人知道为什么吗？    提交人    /u/Interesting-Weeb-699   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1es6c98/d_has_meta_cancelled_its_ai_residency_program_for/</guid>
      <pubDate>Wed, 14 Aug 2024 16:38:18 GMT</pubDate>
    </item>
    <item>
      <title>多个小型专门模型与大型多方面模型？[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1es5k98/multiple_small_specialized_models_vs_large/</link>
      <description><![CDATA[总体而言，我对 AI/ML 还很陌生，但已经在 TF 中玩了足够多的东西，而且我还是一个不断进行修补的人。 我只是对像股票建模这样复杂系统的模型“设计”感到好奇。如果我创建一个具有四个输出的模型来确定如何处理股票（买入、不买入、卖出或持有），这是否比创建四个单独的模型（每个模型都“专门”于一种交易/输出）更好？ 我可以想象这两种方法的问题（但股票本身就是一个非常难以预测的主题），最好的答案可能是制作五个模型：四个专门的模型和一个总体模型，然后以某种方式比较结果以最终实现利润最大化。 时间成分和“市场崩溃”除此之外，是构建原子专门模型并以某种方式权衡它们还是创建一个考虑到所有拼图碎片的大型模型更好？ --- 或者两者兼而有之/更多的信息总是更好？我敢肯定，这是一个很难回答的问题，但我很想听听大家的想法！    提交人    /u/BodeMan5280   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1es5k98/multiple_small_specialized_models_vs_large/</guid>
      <pubDate>Wed, 14 Aug 2024 16:07:19 GMT</pubDate>
    </item>
    <item>
      <title>[R] 无处不在的集成：多尺度聚合以实现对抗鲁棒性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1es3dfy/r_ensemble_everything_everywhere_multiscale/</link>
      <description><![CDATA[  由    /u/hardmaru  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1es3dfy/r_ensemble_everything_everywhere_multiscale/</guid>
      <pubDate>Wed, 14 Aug 2024 14:41:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 新开源版本：时尚领域的 SOTA 多模态嵌入模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eryo73/p_new_opensource_release_sota_multimodal/</link>
      <description><![CDATA[      大家好！ 我非常高兴地宣布推出 Marqo-FashionCLIP 和 Marqo-FashionSigLIP - 两种用于时尚领域搜索和推荐的全新先进多模式模型。这些模型在包​​括 DeepFashion 和 Fashion200K 在内的 7 个时尚评估数据集上超越了当前的 SOTA 模型 FashionCLIP2.0 和 OpenFashionCLIP，最高提升 57%。 Marqo-FashionCLIP &amp; Marqo-FashionSigLIP 是具有 1.5 亿个参数的嵌入模型，其性能如下：  在所有基准测试中均优于 FashionCLIP2.0 和 OpenFashionCLIP（最高提升 57%）。 推理速度比 FashionCLIP2.0 和 OpenFashionCLIP 快 10%。 将 广义构造学习 (GCL) 与 SigLIP 结合使用，可优化超过七个时尚特定方面，包括描述、标题、颜色、详细信息、类别、关键字和材料。 在 7 个公开可用的数据集和 3 个任务中进行了基准测试。  https://preview.redd.it/8kkyn2e61mid1.png?width=1459&amp;format=png&amp;auto=webp&amp;s=e8bfa42faca752538b92e06e3dba3a7780007981 我们根据 Apache 2.0 许可发布 Marqo-FashionCLIP 和 Marqo-FashionSigLIP 此处。 基准测试结果 以下是 7 个数据集的结果。所有值均代表相对于 FashionCLIP2.0 基线的准确率/召回率的相对改进。您可以在此处找到更多详细信息和要重现的代码 https://github.com/marqo-ai/marqo-FashionCLIP。  7 个数据集的平均召回率/准确率@1 结果（与 FashionCLIP2.0 基线相比） 请告诉我任何反馈意见，或者您是否有兴趣看到正在开发的其他模型！ GitHub：https://github.com/marqo-ai/marqo-FashionCLIP 博客：https://www.marqo.ai/blog/search-model-for-fashion    由   提交  /u/Jesse_marqo   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eryo73/p_new_opensource_release_sota_multimodal/</guid>
      <pubDate>Wed, 14 Aug 2024 11:00:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持有效，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢所有人在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1epmsrd/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Aug 2024 15:00:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    </channel>
</rss>