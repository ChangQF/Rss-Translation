<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 12 Nov 2024 03:18:45 GMT</lastBuildDate>
    <item>
      <title>[D] LoRA 的子空间相似度图</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gpat21/d_subspace_similarity_plot_of_lora/</link>
      <description><![CDATA[      有人可以向我解释如何解释 LoRA 的图 3 吗？为什么前两张图片的左下角是灰色的，为什么放大的图片（最后两张图片）的灰色部分不在左下角而是反转的？ 谢谢你的帮助 https://preview.redd.it/ocji41m1xd0e1.png?width=1106&amp;format=png&amp;auto=webp&amp;s=1afd83925af782da6122d70632f7592f9a11c502    由    /u/BigYounzzz 提交   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gpat21/d_subspace_similarity_plot_of_lora/</guid>
      <pubDate>Tue, 12 Nov 2024 02:51:01 GMT</pubDate>
    </item>
    <item>
      <title>[D] NeurIPS 暗夜社交活动</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gpamvn/d_neurips_after_dark_networking_event/</link>
      <description><![CDATA[刚收到一封关于官方售票的夜间 NeurIPS 网络活动的电子邮件 - 这将是我第一次参加/演讲，想知道这些活动是否值得参加。更一般地说，也有兴趣听听如何充分利用我的时间参加。    提交人    /u/gateofptolemy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gpamvn/d_neurips_after_dark_networking_event/</guid>
      <pubDate>Tue, 12 Nov 2024 02:42:13 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你们正在研究哪些问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp9ydh/d_what_are_some_problems_you_guys_are_working_on/</link>
      <description><![CDATA[大家好，我是一名主修机器学习的研究生。寒假快到了，我将独自度过圣诞节😃。我有一些空闲时间，可以使用几台 A100，所以我打算做一个项目。 我很好奇你们正在研究什么样的问题！需要有人帮忙还是希望有人能解决你的问题？也许我可以腾出整个冬天来解决这个问题！ 请分享您正在研究或希望解决的任何问题陈述。此外，如果您在该行业工作并且知道什么样的问题可以帮助我脱颖而出，那么我的建议也将不胜感激 :)    提交人    /u/ziggyboom30   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp9ydh/d_what_are_some_problems_you_guys_are_working_on/</guid>
      <pubDate>Tue, 12 Nov 2024 02:07:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 线性回归被视为人工智能吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp95jv/d_is_linear_regression_considered_ai/</link>
      <description><![CDATA[嗨 Redditors， 我很好奇想听听你对此的看法！你认为线性回归是 AI 的一部分吗，还是你认为它更像是一种传统的统计方法？我觉得关于哪些技术真正被视为 AI 存在很多争论，特别是因为有些方法已经存在了几十年，并且在 AI 特定应用程序之外被广泛使用。 此外，有没有其他你最初不认为是 AI 的方法，后来才意识到它们是，反之亦然？很想知道其他人如何划分传统数据分析和 AI 技术之间的界限。 谢谢！    提交人    /u/gcombar   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp95jv/d_is_linear_regression_considered_ai/</guid>
      <pubDate>Tue, 12 Nov 2024 01:28:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在本地训练语音模型的最佳方法是什么？（最好制作一个可在应用程序上使用的 TTS 模型）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp88fs/d_whats_the_best_way_to_train_a_voice_model/</link>
      <description><![CDATA[我有一个朋友得了癌症，最近的一次手术使他们失去了声音。我想尝试用手术前的一些视频来训练一个人工智能语音模型。理想情况下，我希望有一个安卓应用或网络应用，我可以在里面使用他们的语音模型，这样他们就可以使用 TTS 再次用他们的声音说话。如果可能的话，我正在寻找一种他们可以通过手机上的应用使用它的方法    提交人    /u/TheTabernacleMan   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp88fs/d_whats_the_best_way_to_train_a_voice_model/</guid>
      <pubDate>Tue, 12 Nov 2024 00:44:26 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么 LLM 修剪不像量化那样普遍可用？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp6h2d/d_why_is_llm_pruning_not_as_generally_available/</link>
      <description><![CDATA[我一直在深入研究大型语言模型 (LLM)，并一直在探索各种优化技术。令我感到困惑的一件事是量化与修剪的可用性和采用率之间的差异。 量化似乎是一种成熟且广泛使用的技术，可以减少 LLM 的内存占用和计算成本。它相对容易实现，并且在研究和行业中都得到了广泛的采用。 另一方面，修剪（涉及从模型中删除不太重要的权重）不太常见。尽管它具有潜在的好处，例如进一步减小模型大小和推理时间，但它似乎并不普遍可用或被广泛采用。我在互联网上进行的许多搜索都只得到研究论文或概念验证 GitHub 存储库。 我很好奇这种差异背后的原因。修剪是否存在技术挑战，导致其不太实用？实施或集成到现有工作流程中是否更加困难？还是有其他因素在起作用？    提交人    /u/Soumil30   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp6h2d/d_why_is_llm_pruning_not_as_generally_available/</guid>
      <pubDate>Mon, 11 Nov 2024 23:23:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 抖音滤镜中使用的实时 GAN 模型可能的架构/数据集是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp3vz0/d_what_is_the_likely_architecturedataset_for/</link>
      <description><![CDATA[我很好奇抖音滤镜为何在去除头发 (https://effecthouse.tiktok.com/learn/guides/technical-guides/objects/generative-effects/hair-eraser) 和眉毛 (https://effecthouse.tiktok.com/learn/guides/technical-guides/objects/generative-effects/eyebrow-eraser) 方面表现如此出色。 我尝试过使用轻量级滤镜做类似的事情（实时从人们的脸上去除物品）我使用 OpenCV 方法创建的配对数据集上的 Pix2Pix 样式模型，但是随着生成器的大小减小，生成的图像的质量下降太多。 有人知道他们如何在如此轻量级的模型上实现如此一致的结果吗？谢谢    提交人    /u/DjPoliceman   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp3vz0/d_what_is_the_likely_architecturedataset_for/</guid>
      <pubDate>Mon, 11 Nov 2024 21:34:21 GMT</pubDate>
    </item>
    <item>
      <title>[P]带注释的数据集，用于解释 AI 与真实图像检测的原因</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gp05os/pannotated_dataset_for_explaining_the_reason_in/</link>
      <description><![CDATA[我目前正在研究一个问题陈述，其中我需要对真实图像和人工智能生成的图像进行分类，然后对分类进行解释。第一部分非常简单，对于第二部分，我找到了一些研究论文，但没有一篇提供用于微调模型的注释数据集的链接。有人可以帮我找到具有良好注释的数据集吗？ SynArtifact：通过视觉语言模型对合成图像中的伪影进行分类和缓解（他们在第 4 页提到了一个数据集，但没有提供任何链接）    提交人    /u/Background-Trainer37   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gp05os/pannotated_dataset_for_explaining_the_reason_in/</guid>
      <pubDate>Mon, 11 Nov 2024 19:03:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICLR 2025 论文评论讨论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gov5zd/d_iclr_2025_paper_reviews_discussion/</link>
      <description><![CDATA[ICLR 2025 评审明天将在 OpenReview 上线！我想开一个帖子，讨论评审过程中的任何反馈、问题或庆祝活动。 随着 ICLR 的发展，评审噪音不可避免，好的作品可能并不总是能得到应有的分数。让我们记住，分数并不能定义研究的真正影响。分享您的经验、想法，让我们在整个过程中互相支持！    提交人    /u/Technical_Proof6082   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gov5zd/d_iclr_2025_paper_reviews_discussion/</guid>
      <pubDate>Mon, 11 Nov 2024 15:43:34 GMT</pubDate>
    </item>
    <item>
      <title>[D] 为什么域随机化能保证神经网络控制器的稳定性？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gopir9/d_why_does_domain_randomization_ensure_stability/</link>
      <description><![CDATA[大家好， 我正在探索域随机化如何有助于 NN 控制器的稳定性，尤其是当训练包括更广泛地查看历史数据时。 具体来说，我很好奇是否有理论基础或正式分析来解释域随机化如何帮助神经网络在不同条件或噪声水平下保持稳定性，尤其是在结合更多历史信息时。是否有论文通过 Lyapunov 稳定性或其他严格方法来分析这种影响，表明接触各种过去数据可以产生更稳定的基于 NN 的控制系统？ 任何关于该领域基础或最新研究的建议都将不胜感激。提前致谢！ （我已经在控制理论 reddit 上写了同样的东西）    提交人    /u/nerdkim   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gopir9/d_why_does_domain_randomization_ensure_stability/</guid>
      <pubDate>Mon, 11 Nov 2024 10:51:17 GMT</pubDate>
    </item>
    <item>
      <title>[R] 关于不同 LLM 红队方法和技术的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gonf47/r_resource_on_varying_llm_red_teaming_methods_and/</link>
      <description><![CDATA[https://github.com/user1342/Awesome-LLM-Red-Teaming    由   提交  /u/OppositeMonday   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gonf47/r_resource_on_varying_llm_red_teaming_methods_and/</guid>
      <pubDate>Mon, 11 Nov 2024 08:14:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何使用图像模型可视化 LLM 注意层对一组 token 的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gojg09/d_how_to_visualize_the_effect_of_an_llm_attention/</link>
      <description><![CDATA[通过将 token 嵌入输入到图像模型中，是否可以可视化 LLM 在通过注意层处理 token 之前和之后如何“想象”token？我知道您无法复制粘贴它，但是有没有办法捕获由注意层引起的潜在变换并将此变换应用于图像模型的嵌入空间？ 例如，如果我在 LLM 中输入“穷人”，那么“男人”的嵌入将转向“乞丐”，而输入“皇室男人”时，它可能会更接近“国王”。我想可视化这种变化。然后，你可以将人的嵌入转移到图像模型中，它会在这个例子中创建类似乞丐或国王的东西。 如果你捕获每个注意层之后的转换并通过插值每个步骤制作视频，它可以制作出非常酷的可视化效果。    提交人    /u/jbrinkw   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gojg09/d_how_to_visualize_the_effect_of_an_llm_attention/</guid>
      <pubDate>Mon, 11 Nov 2024 04:01:25 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] ML 和 DL 模型中存在伪造新型方法的论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1go50wf/discussion_papers_with_fake_novel_approach_in_ml/</link>
      <description><![CDATA[为什么很多新论文（通常由博士完成）都采用现有方法，而当您询问他们的贡献时，他们说我们用另一层替换了这一层，或者我们添加了超参数!!!!! 这不是贡献！我很困惑这些怎么会被接受    提交人    /u/Rihab_Mira   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1go50wf/discussion_papers_with_fake_novel_approach_in_ml/</guid>
      <pubDate>Sun, 10 Nov 2024 16:53:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gnrb08/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 10 Nov 2024 03:15:11 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>