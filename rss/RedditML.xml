<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Wed, 07 Feb 2024 18:16:05 GMT</lastBuildDate>
    <item>
      <title>[D] [R] 学校教育</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1al8cjv/d_r_schooling/</link>
      <description><![CDATA[您好，我在中西部，海拔 31m。我刚刚开始在一家提供学费报销的公司工作，我想利用它。在机械行业实现最高薪酬的最佳途径是什么？您会推荐什么学位？我应该尝试转向生产工程吗？我从未上过大学，所以我所有的经验都来自实践工作，我有大约 10 年的机械加工经验。   由   提交/u/Safe-Strike7480  /u/Safe-Strike7480 reddit.com/r/MachineLearning/comments/1al8cjv/d_r_schooling/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1al8cjv/d_r_schooling/</guid>
      <pubDate>Wed, 07 Feb 2024 17:26:41 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于我的模型的问题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1al7cz8/d_question_regarding_my_model/</link>
      <description><![CDATA[嘿，最近，我开发了一个 ML 模型，可以以 56% 的准确率预测特定篮球道具（主要是场均得分/PPG）的结果。回报虽然不大，但非常稳定。我已经测试了一段时间了，每投资 1000 美元，它可以提供 70 美元的稳定收入，我很好奇增加收入的最佳方式是什么，我应该尝试组合道具吗？每周的准确性相当一致，但我必须投入更多的钱才能赚取不那么高的百分比。该模型的开发尚未最终确定，有一些功能将很快实现。我确实相信它的准确率有可能提高到 60%。事实上，两天前我的准确率是 61%（50 个样本）。您对提高模型的盈利能力有什么建议吗？最好的方法是什么？我正在尝试找到一种方法来确定哪些玩家应该被排除在投注之外。提前致谢！    由   提交/u/Relevant_Horse2066   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1al7cz8/d_question_regarding_my_model/</guid>
      <pubDate>Wed, 07 Feb 2024 16:46:33 GMT</pubDate>
    </item>
    <item>
      <title>[D] 以安全的方式用受过训练的声音生成高质量写作的选项？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1al60qf/d_options_to_generate_quality_writing_in_a/</link>
      <description><![CDATA[一般来说，我正在尝试简化手动定性分析。模型需要能够总结文本输入，并以不僵硬的方式以书面形式描述它们。   我的公司有数千篇用我们的声音编写的博客文章可供培训。 我的经理会非常犹豫是否使用 Open.ai，因为我们需要通过模型输入来自客户的数据。即使 open.ai 表示他们不使用 API 调用来训练他们的模型。因此，我们需要以更安全的方式运行 open.ai（例如通过 Azure？），或者使用经过训练的模型自行托管它。  您将如何以安全的方式获得良好的创意写作输出？是否有值得信赖的公司或开源项目专注于高质量的写作风格？   由   提交/u/low-code-Rachel  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1al60qf/d_options_to_generate_quality_writing_in_a/</guid>
      <pubDate>Wed, 07 Feb 2024 15:50:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 你会用大量的中世纪文本做哪些有趣的事情？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1al4ayb/d_what_interesting_things_would_you_do_with_a/</link>
      <description><![CDATA[大家好，我希望可以在此处发布此内容。如果不合适，请删除。 我正在开展一个项目，该项目旨在将大量中世纪行政记录数字化。这将包括法律、财务和其他类型的记录，这些记录在一个世纪或更长时间内数量达到数亿字。这些记录是拉丁文的，跨越了一个气候严重不稳定的时期（导致饥荒、瘟疫、瘟疫）。 短期内，该项目只会数字化数万或数十万字，但我我想知道如果我们在未来获得更多支持，可能会发生什么。 就计算可能的知识而言，我是一个相当基础的人，但我比绝大多数人知道得更多。我的同事，所以我想在这里问一下，看看人们可能会采取什么方向。 例如，数字化过程目前涉及训练一个模型来识别手稿照片中的文本，并且需要大量干预直到我们有足够大的基本事实。我可以设想一个预测文本模型，它表示“根据已经数字化的数据，我预测以下单词可能是 x、y、z 之一”，并根据已知的文本附有概率百分比。这将与视觉模型并存，帮助志愿者破译手稿中最有可能的单词。  这只是我想到的一个小例子，但我想知道这里的人（比我拥有更多的知识）可能想要处理如此大量的数据。该项目最终（可能是 2025 年）将开放我们收集的所有数据供人们使用。   由   提交/u/newjack7  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1al4ayb/d_what_interesting_things_would_you_do_with_a/</guid>
      <pubDate>Wed, 07 Feb 2024 14:34:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 未来同行评审系统的愿望清单？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1al39hi/d_wishlist_for_a_future_peerreviewing_system/</link>
      <description><![CDATA[https://twitter.com/openreviewnet/status /1754978447456084195 听起来他们在后台开发了一些东西，并且愿意接受建议。他们可以提供什么样的服务来让我们研究人员的生活变得更好？ 我个人认为，仅仅一个类似 Twitter 的地方来讨论论文就已经是一个足够好的开始了 &lt; !-- SC_ON --&gt;  由   提交 /u/DeepLearningOnTheDL   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1al39hi/d_wishlist_for_a_future_peerreviewing_system/</guid>
      <pubDate>Wed, 07 Feb 2024 13:45:58 GMT</pubDate>
    </item>
    <item>
      <title>[2402.04239] CAST：使用代理令牌对高效 Transformer 进行自我关注聚类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1al1apt/240204239_cast_clustering_selfattention_using/</link>
      <description><![CDATA[ 由   提交/u/Elven77AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1al1apt/240204239_cast_clustering_selfattention_using/</guid>
      <pubDate>Wed, 07 Feb 2024 11:58:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] AE 的可解释性</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1al18g7/d_interpretability_of_a_ae/</link>
      <description><![CDATA[我目前正在开发可解释的自动编码器，但我想知道需要可解释性的自动编码器的最佳用途是什么？能够精确解释或描述潜在空间对您有什么用？   由   提交/u/tricycl3_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1al18g7/d_interpretability_of_a_ae/</guid>
      <pubDate>Wed, 07 Feb 2024 11:54:48 GMT</pubDate>
    </item>
    <item>
      <title>[D] 是否还有其他人觉得整个员工队伍都因为对 ML 职业提供和期望的不切实际的期望而误入歧途？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1al0fny/d_does_anyone_else_feel_like_theres_an_entire/</link>
      <description><![CDATA[例如，查看此推文，我看到我的网络中的一位（非机器学习）软件工程师分享了该推文：  https://x.com/pwang/status/1753445897583653139?s=20 &lt; p&gt;（对于那些不想点击的人，它得到了一些相当大的积极吸引力，并说“当人类创造 AGI 时，它将被命名为 Untitled14.ipynb”） 我已经最近，我们不得不与一些人合作，他们认为他们可以将一些混乱的数据处理代码从笔记本复制并粘贴到 cronjob 中，并将其称为生产 ML 系统，之后我们不得不处理许多令人沮丧的交互。还有一些人认为，谈论他们从社交媒体上获得的最新前沿研究论文可以很好地替代了解如何很好地实施核心基础知识。 我觉得这些人中的许多人都会如果他们在职业生涯开始时得到适当的支持和建议，这样他们就知道应该投入时间来发展哪些技能，以成为一名决策科学家、研究员或 MLE（或者可能以上都不是，并鼓励他们从事某些事情），那很好。否则他们更擅长）。但相反，他们被告知，他们可以通过成为“介于两者之间的东西”来增加价值——这实际上往往是一种旁观者；不太擅长软件工程、数学，也不欣赏成为该领域研究人员所需的时间和奉献精神（甚至不了解研究人员的贡献）。 我觉得这个行业正在慢慢醒来事实上，这些人只能做出有限的贡献，到那时，很多人将失业或被迫做出不令人满意的选择。这让我感到难过，因为造成这种情况的责任实际上在于那些让他们误入歧途的影响者和那些未能为他们提供所需支持和指导的非技术经理。   由   提交/u/capguard  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1al0fny/d_does_anyone_else_feel_like_theres_an_entire/</guid>
      <pubDate>Wed, 07 Feb 2024 11:02:34 GMT</pubDate>
    </item>
    <item>
      <title>[P] 移动版 WandB（iOS 和 Android）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1al02oc/p_wandb_for_mobile_ios_android/</link>
      <description><![CDATA[过去 2 个月我一直在训练一个新模型，但我很沮丧，因为我必须在我的 PC 上打开 WandB（它在移动设备，而且它也有问题），因此我为移动设备创建了一个超级高效且简单的客户端，可以随时随地观看模型的训练并查看指标，无需使用键盘，它是完全私有的，您的任何训练/数据/配置都不会共享.  对于 iOS：https://apps.apple。 com/us/app/wandview/id6477268896?platform=iphone 对于 Android：https://play.google.com/store/apps/details?id=com.read21.wandview.wandview     由   提交/u/simonthedungeon  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1al02oc/p_wandb_for_mobile_ios_android/</guid>
      <pubDate>Wed, 07 Feb 2024 10:37:56 GMT</pubDate>
    </item>
    <item>
      <title>[P]最快的耳语推理引擎</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akwilm/p_fastest_whisper_inference_engine/</link>
      <description><![CDATA[shashikg/WhisperS2T：优化的语音到文本管道支持多个推理引擎的 Whisper 模型 (github.com) ​ 查看同事的项目，提供比流行的耳语推理快 2-3 倍的功能像whisperX或insanely-fast-whisper这样的项目 ​ 还提供了许多其他便利功能   由   提交 /u/Agent_SS_Athreya   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akwilm/p_fastest_whisper_inference_engine/</guid>
      <pubDate>Wed, 07 Feb 2024 06:24:32 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用 TED 生成文本 - 可训练的指数衰减</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akr9g6/r_text_generation_with_ted_trainable_exponential/</link>
      <description><![CDATA[链接：https://blpj.github.io/ ted/   与 Transformer 进行的全面比较或 RNN 中的顺序依赖相比，可训练指数衰减 (TED) 引入了一种不直接依赖于的独特方法在过去的代币上。 TED 的核心机制仅单独考虑每个代币一次，以确定其衰减率 λ (lambda)。然后，过去的代币会经历指数衰减，并将它们的影响相加并添加到当前的代币中以创建丰富的表示。 TED 在训练期间受益于并行硬件架构，因为对过去令牌的唯一依赖是通过加法，可以在单层上下文中随时以任何顺序执行。训练模型后，我们可以观察到过去标记的影响会随着时间的推移而自然衰减，从而使某些标记变得无关紧要，从而可以从上下文中删除。此外，围绕指数衰减的完善数学框架可以精确预测特定代币将“死亡”的时刻。这一观察结果在推理过程中开辟了许多优化机会。最简单的策略涉及在任何给定时间维护 K 个最相关的标记，以确保恒定的内存需求。或者，动态方法可能涉及丢弃相关性分数低于特定阈值的标记。相关性分数是通过将标记的向量幅度 ‖v‖ 乘以它在时间“t”时的当前衰减因子来计算的。由于指数衰减的本质，保存在上下文中的过去标记的顺序并不重要。这消除了对位置编码机制的需要，这在 Transformers 中被视为有问题。 TED 的架构遵循 Transformer 的架构，不同之处在于注意力模块被指数衰减模块取代。 TED 可以在 PyTorch 中实现，无需特殊的 CUDA 内核。代码位于：https://github.com/blpj/ted    ​   由   提交/u/_blpj_  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akr9g6/r_text_generation_with_ted_trainable_exponential/</guid>
      <pubDate>Wed, 07 Feb 2024 01:49:18 GMT</pubDate>
    </item>
    <item>
      <title>[P] 开放法学硕士的宪法人工智能配方</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akdv4i/p_constitutional_ai_recipe_with_open_llms/</link>
      <description><![CDATA[      大家好，我是来自 Hugging Face 👋 研究团队的 Lewis。 我们最近一直在为 LLM 修改各种对齐算法，并且很好奇 Anthropic 的 Constitutional AI 是否适用于 Mistral 7B 等开放模型。 tl;dr 它效果很好，我们在这里总结了我们的实验和配方！ 像其他作品一样在“自我完善”方面，宪法人工智能的工作原理是要求模型生成对一组提示的响应，然后检查这些响应与一组“宪法原则”的一致性程度。定义您希望模型具有的值类型。然后，您让模型修改其原始响应，这会生成偏好对（original_response、revised_response）的合成数据集，您可以将其用于 DPO / PPO 等。该过程的概述如下所示：  ​ 宪法人工智能配方 我们发现他们的论文最有趣的是定义自己的一套宪法原则的可能性。例如，我认为很多人都认为“作为人工智能语言模型我不能......” ChatGPT 中的拒绝非常烦人，因此我们调整了 Anthropic 构成以模仿 xAI 的 Grok 助手的风格，该助手具有相当好的护栏，但通常会以一些幽默来回应:) 比较两种拒绝风格（Anthropic 与 Grok），您可以在这里尝试演示：https://huggingface.co/spaces/HuggingFaceH4/constitutional -ai-demo   由   提交/u/lewtun  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akdv4i/p_constitutional_ai_recipe_with_open_llms/</guid>
      <pubDate>Tue, 06 Feb 2024 16:31:20 GMT</pubDate>
    </item>
    <item>
      <title>[D] 法学硕士因在持续微调过程中发生灾难性遗忘而闻名</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akd287/d_llms_are_known_for_catastrophic_forgetting/</link>
      <description><![CDATA[但是 Chatgpt-4 是如何记住它学到的所有事实数据的呢？  换句话说，法学硕士如何记住他们在初始训练批次中学到的数据（在预训练和持续微调期间）？    由   提交/u/kekkimo  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akd287/d_llms_are_known_for_catastrophic_forgetting/</guid>
      <pubDate>Tue, 06 Feb 2024 15:57:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 审稿人滥用 ChatGPT 撰写审稿</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1akd0ko/d_reviewers_abusing_chatgpt_to_write_review/</link>
      <description><![CDATA[我不介意人们使用 LLM、ChatGPT 来修复他们的原始文本，但我确实得到了一位审稿人和元审稿人显然没有使用它阅读论文...感觉就像他们复制粘贴摘要，然后向 ChatGPT 提问。更糟糕的是，一位审稿人甚至敢要求我将他们不相关的工作添加为引文。 在 GPT 检测器上检查他们的评论时，检测到的人工智能检测率约为 98%... 结果是他们的评论都不相关，例如询问我论文中存在的信息、告诉我极其模糊的评论或解释摘要。就好像他们连整篇论文都没有贴，只贴了摘要。 我知道我的文章并不完美，但感觉就像是白白被拒绝了，而且我什至不能有一个真实的人类反馈。 你们中的一些人遇到过这种情况吗？   由   提交/u/AbleBrilliant13  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1akd0ko/d_reviewers_abusing_chatgpt_to_write_review/</guid>
      <pubDate>Tue, 06 Feb 2024 15:55:15 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ad5t7g/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jan 2024 16:00:31 GMT</pubDate>
    </item>
    </channel>
</rss>