<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Tue, 29 Oct 2024 09:18:14 GMT</lastBuildDate>
    <item>
      <title>[D] 探索 Whisper V3 Turbo 集成的无服务器解决方案</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1genbjo/d_exploring_serverless_solutions_for_whisper_v3/</link>
      <description><![CDATA[目前，Runpod 的无服务器解决方案在成本和功能方面满足了我的需求：https://github.com/runpod-workers/worker-faster_whisper 但是，我对使用https://huggingface.co/openai/whisper-large-v3-turbo感兴趣，因为它的速度很快。 我不确定如何在 Runpod 的无服务器基础设施上设置和运行 Whisper V3 Turbo。  看来我们可能需要等到上游项目 https://github.com/SYSTRAN/faster-whisper/issues/1030 使用 Turbo 更新并在 https://pypi.org/project/faster-whisper/ 上发布。  只有这样，此功能才可用，此时，我们可以分叉 https://github.com/runpod-workers/worker-faster_whisper 以进行相应更新。 与此同时，您是否知道使用 Whisper V3 Turbo 的任何经济高效的无服务器解决方案？ 谢谢。 p/s  Groq 提供此服务：https://groq.com/whisper-large-v3-turbo-now-available-on-groq-combining-speed-quality-for-speech-recognition/ 但是，他们目前不接受来自开发者的付款，也没有提供何时可用预计时间表。    提交人    /u/yccheok   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1genbjo/d_exploring_serverless_solutions_for_whisper_v3/</guid>
      <pubDate>Tue, 29 Oct 2024 05:26:01 GMT</pubDate>
    </item>
    <item>
      <title>[R] SpotDiffusion：一种随时间推移生成无缝全景图的快速方法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gekcus/r_spotdiffusion_a_fast_approach_for_seamless/</link>
      <description><![CDATA[我很高兴地宣布，我们的论文“SpotDiffusion：一种随时间推移生成无缝全景图的快速方法”已被 WACV2025 接受：https://arxiv.org/abs/2407.15507 项目页面：https://spotdiffusion.github.io 代码：https://github.com/stanifrolov/spotdiffusion 我们的方法会随时间推移移动不重叠的去噪窗口，确保一个时间步中的接缝在下一个时间步中得到纠正。这样可以用更少的总体步骤生成连贯的高分辨率图像。我们通过定性和定量评估证明了我们方法的有效性，并将其与 MultiDiffusion、SyncDiffusion 和 StitchDiffusion 进行了比较。我们的方法提供了几个关键优势，包括提高计算效率和加快推理时间，同时产生相当或更好的图像质量。    提交人    /u/Maleficent_Stay_7737   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gekcus/r_spotdiffusion_a_fast_approach_for_seamless/</guid>
      <pubDate>Tue, 29 Oct 2024 02:33:13 GMT</pubDate>
    </item>
    <item>
      <title>[R] 动态注意力引导扩散用于图像超分辨率</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gekbg3/r_dynamic_attentionguided_diffusion_for_image/</link>
      <description><![CDATA[我很高兴地告诉大家，我们的论文“用于图像超分辨率的动态注意力引导扩散”被 WACV2025 接受了： https://arxiv.org/abs/2308.07977 这项工作的目标是引入一种新的注意力引导扩散机制，将图像细化重点放在从深度细化中受益最大的重要区域上：)    提交人    /u/Maleficent_Stay_7737   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gekbg3/r_dynamic_attentionguided_diffusion_for_image/</guid>
      <pubDate>Tue, 29 Oct 2024 02:31:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] ML论文中可变长度输出的模型建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ged0by/r_model_suggestion_for_variablelength_output_in/</link>
      <description><![CDATA[大家好，我正在开始写论文，具备基本的 ML/DL 知识。我需要一个模型，它可以采用一组固定的输入（快照）并输出具有实数和复数值的可变长度向量。我读过 LSTM 可能有效，但我不确定给定固定输入。 有人推荐适合这种任务的模型或架构吗？任何关于从哪里开始或查看资源的建议都将非常有帮助。提前致谢！    提交人    /u/Less-Meaning-6450   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ged0by/r_model_suggestion_for_variablelength_output_in/</guid>
      <pubDate>Mon, 28 Oct 2024 20:58:25 GMT</pubDate>
    </item>
    <item>
      <title>[R] 超越自回归：离散扩散用于复杂推理和规划</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1geb685/r_beyond_autoregression_discrete_diffusion_for/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2410.14157 我很想听听专家对此的看法。 它与我认为有吸引力的想法有关：  自回归生成在组合领域（例如推理、规划、数学）中受到限制。 这解释了 LLM 在这些领域面临的许多挑战。 扩散在这些领域可能更有效：它学习从一般到具体生成。 （更像是基于能量的模型视角）。 在其生成过程的早期，它不太可能因为做出特定的错误选择而陷入困境。     提交人    /u/marojejian   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1geb685/r_beyond_autoregression_discrete_diffusion_for/</guid>
      <pubDate>Mon, 28 Oct 2024 19:42:23 GMT</pubDate>
    </item>
    <item>
      <title>[R] 使用数据流进行机器学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1geat4u/r_machine_learning_with_data_streams/</link>
      <description><![CDATA[我刚刚开始写论文，我需要学习使用数据流进行机器学习。我找到了一些文章、书籍和一些课程，但如果您能提供更多资源帮助我更好地理解这个主题，我将不胜感激。 非常感谢 :)    提交人    /u/Deepblue597   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1geat4u/r_machine_learning_with_data_streams/</guid>
      <pubDate>Mon, 28 Oct 2024 19:27:19 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何总结一篇研究论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ge8m3q/d_how_to_summarize_a_research_paper/</link>
      <description><![CDATA[我并不是论文阅读的新手，过去两年我一直在阅读论文，我甚至还时不时地实现一些论文，但我不能说我擅长总结它们。 总结论文时有什么一般技巧吗？是否有论文及其摘要的示例，以便我更好地理解论文总结是如何完成的？ 任何帮助都值得感激。    提交人    /u/darthJOYBOY   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ge8m3q/d_how_to_summarize_a_research_paper/</guid>
      <pubDate>Mon, 28 Oct 2024 17:58:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] 有人可以给我一些关于如何微调 SigLip 进行图像分类的提示吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ge5p0s/p_can_someone_give_me_tips_on_how_to_finetune/</link>
      <description><![CDATA[我正在使用 huggingface 的 Siglip，并尝试在我的数据集（不是那么大）上对其进行微调。它有点过度拟合，我研究了一些正常的正则化技术和 LORA，并得到了 peft 的帮助。我愿意接受所有建议。我对此很陌生。提前谢谢！！ 我从这个开始作为基础： model = AutoModel.from_pretrained(&quot;google/siglip-so400m-patch14-384&quot;) process = AutoProcessor.from_pretrained(&quot;google/siglip-so400m-patch14-384&quot;)     提交人    /u/Fantastic-Garlic19   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ge5p0s/p_can_someone_give_me_tips_on_how_to_finetune/</guid>
      <pubDate>Mon, 28 Oct 2024 16:00:54 GMT</pubDate>
    </item>
    <item>
      <title>[D]最终在 NuerIPS-24 上发表了一张海报</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gdxef5/dended_up_with_a_poster_in_nuerips24/</link>
      <description><![CDATA[我今年通过期刊轨道 (MLRC) 在 NuerIPS 上发表了一张海报，以及主要的会议论文。我没想到会发生这种情况，所以我之前没有计划/研究过费用/资金。我已经安排好了签证和会议注册，但对 Nuerips 的进一步进展和如何资助它一无所知（我是本科三年级学生）。如果你以前已经参加过 NeurIPS，请倾诉你的想法和经验。    提交人    /u/whit3whistl3   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gdxef5/dended_up_with_a_poster_in_nuerips24/</guid>
      <pubDate>Mon, 28 Oct 2024 08:50:47 GMT</pubDate>
    </item>
    <item>
      <title>[N] 有任何肺癌检测模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gdnra7/n_any_models_lung_cancer_detection/</link>
      <description><![CDATA[我是一名医学生，正在探索 AI 在资源有限的医院（通过 CT 图像）改善肺癌诊断的潜力。AI 的经济实惠使其成为一种很有前途的工具，但我面临着为这一特定应用寻找合适的预训练模型或开源资源的挑战。我有点避免使用商业模型，因为研究重点是低资源设置。虽然像 GPT 这样的大型语言模型很有价值，但我知道它们在直接分析医学图像方面的局限性。所以有什么建议吗？任何东西都会真正帮助我，谢谢！    提交人    /u/Krank910   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gdnra7/n_any_models_lung_cancer_detection/</guid>
      <pubDate>Sun, 27 Oct 2024 23:01:47 GMT</pubDate>
    </item>
    <item>
      <title>基于时间的课程学习 [讨论]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gdn8hr/time_based_curriculum_learning_discussion/</link>
      <description><![CDATA[是否有人探索过 LLM 课程学习的变体，其中 1) 按时间顺序提供模型训练的信息，或 2) 明确指定/学习训练数据源的生产日期。 扩展 1）对于 LLM，这可能意味着首先对 2010 年的维基百科文章进行训练 -&gt; 对 2011 年的维基百科文章进行训练。 扩展 2）在这种情况下，它可以表示所有文本中的特定标记，用于训练编码按时间顺序排列信息的语言模型。类似于 [CLS] 标记。另一个示例可能是具有额外损失的子网/超网络，训练使得训练数据的按时间顺序排列的创建日期必须可以从文本中预测出来。 具体来说，我想激发人们对这些修改的实用性及其潜在好处的讨论。一些担忧包括，为了能够估计输入文本的时间顺序，输入文本必须足够长且完整。这可能意味着预训练中使用的传统截断策略将不可行。    提交人    /u/Envoy-Insc   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gdn8hr/time_based_curriculum_learning_discussion/</guid>
      <pubDate>Sun, 27 Oct 2024 22:36:53 GMT</pubDate>
    </item>
    <item>
      <title>[D] 揭秘分布式检查点</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gdkdka/d_demystifying_distributed_checkpointing/</link>
      <description><![CDATA[        提交人    /u/joygao   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gdkdka/d_demystifying_distributed_checkpointing/</guid>
      <pubDate>Sun, 27 Oct 2024 20:25:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 与 Leland McInnes 的最新访谈：UMAP、HDBSCAN 和数据几何 | 从机器学习中学习 #10</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gdimqa/d_new_interview_with_leland_mcinnes_umap_hdbscan/</link>
      <description><![CDATA[      本期《从机器学习中学习》与 Leland McInnes 一起探索纯数学与现代数据科学的交集，Leland McInnes 是无监督学习工具生态系统背后的思想者，包括 UMAP、HDBSCAN、PyNN Descent 和 DataMapPlot。作为 Tutte 数学和计算研究所的研究员，McInnes 从根本上改变了我们处理和理解复杂数据的方式。 抵制追逐炒作的冲动，寻求真正的理解并真正有所作为。    提交人    /u/NLPnerd   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gdimqa/d_new_interview_with_leland_mcinnes_umap_hdbscan/</guid>
      <pubDate>Sun, 27 Oct 2024 19:09:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gd0v8r/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 27 Oct 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>