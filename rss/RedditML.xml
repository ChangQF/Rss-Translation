<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>毫升。初学者请看learnmachinelearning</description>
    <lastBuildDate>Fri, 19 Apr 2024 03:14:16 GMT</lastBuildDate>
    <item>
      <title>[D] 有人尝试过用旧方法提取大型语言模型吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7izc4/d_has_anyone_tried_distilling_large_language/</link>
      <description><![CDATA[因此，如今，每个人都在将从大型语言模型收集的基本原理提炼到另一个相对较小的模型中。然而，我记得从前我们在进行蒸馏时训练了小型网络以匹配大型网络的逻辑。这是忘记/尝试过并且今天不起作用吗？   由   提交 /u/miladink   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7izc4/d_has_anyone_tried_distilling_large_language/</guid>
      <pubDate>Fri, 19 Apr 2024 00:11:00 GMT</pubDate>
    </item>
    <item>
      <title>[D] 结合不同模态的模型</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7fumb/d_combining_models_of_different_modalities/</link>
      <description><![CDATA[组合不同模态的多个模型以生成合理输出的过程/方法：架构是什么？只是好奇你的经历是什么。任何研究的指针或链接都会很方便。   由   提交/u/hophophop1233  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7fumb/d_combining_models_of_different_modalities/</guid>
      <pubDate>Thu, 18 Apr 2024 21:55:34 GMT</pubDate>
    </item>
    <item>
      <title>揭示领先法学硕士的真实背景能力 [R]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7fbs5/exposing_the_true_context_capabilities_of_leading/</link>
      <description><![CDATA[      我一直在研究大型语言模型 (LLM) 的现实世界上下文限制，我想分享最近基准测试中的一些启发性发现(RULER) 消除噪音。 RULER 基准是什么？  RULER 由 NVIDIA 开发，是一个旨在测试 LLM 的基准&#39; 处理长上下文信息的能力。 它比常见的以检索为重点的 NIAH 基准更加复杂。 RULER 根据模型在理解和使用较长文本片段方面的表现来评估模型.  表格突出显示RULER 基准结果和领先法学硕士的有效上下文长度 研究中的表现亮点：  Llama2-7B （聊天）：显示出不错的初始性能，但在较高的上下文长度下无法维持。 GPT-4：显着优于其他人，尤其是在较长的上下文中，保持 80% 以上的准确率。 Command-R (35B)：表现相当不错，略落后于 GPT-4。 Yi ( 34B)：显示出强大的性能，特别是在高达 32K 上下文长度的情况下。 Mixtral (8x7B)：与 Yi 类似，在 32K 上下文之前都能保持良好的性能。 li&gt; Mistral (7B)：随着上下文的增加，性能下降，32K 后更是如此。 ChatGLM (6B)：挣扎在较长的上下文中，显示出急剧下降。 LWM (7B)：与 ChatGLM 相当，在较长的上下文中显着下降。  Together (7B)：随着上下文长度的增长，在保持准确性方面面临困难。 LongChat (13B)：票价合理地高达 4K，但随后下降。 LongAlpaca (13B)：随着上下文变长，性能下降最显着。  关键要点：  随着上下文长度的增加，所有模型都会出现性能下降，无一例外。 LLM 声称的上下文长度通常不会转化为这些长度的有效处理能力。&lt; /li&gt; GPT-4 成为强大的领导者，但在较长距离下也无法避免准确性下降。  为什么这很重要？&lt; /p&gt;  作为人工智能开发人员，超越法学硕士宣传的能力至关重要。 了解有效上下文长度可以帮助我们在将这些模型集成到应用程序中时做出明智的决策。&lt; /li&gt;  评估中遗漏了什么？  值得注意的是，Google 的 Gemini 和 Claude 3 并不属于评估模型的一部分。   li&gt; RULER 现已开源，为该领域的进一步评估和透明度铺平了道路。  来源 我从下面的帖子中回收了很多内容（并试图使其更易于理解和阅读），更多资源可以在这里找到： Harmonious.ai 每周论文综述：RULER：法学硕士的真实上下文大小（2024 年 4 月 8 日） )   由   提交 /u/ParsaKhaz   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7fbs5/exposing_the_true_context_capabilities_of_leading/</guid>
      <pubDate>Thu, 18 Apr 2024 21:34:05 GMT</pubDate>
    </item>
    <item>
      <title>[P] Llama 3 70B 供电编码副驾驶扩展</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7c6e2/p_llama_3_70b_powered_coding_copilot_extension/</link>
      <description><![CDATA[今天早上读到来自 Meta 的新闻非常兴奋，特别是关于 70B 模型获得的 HumanEval 分数。 想到了让新的 Llama 3 70B 可供任何想要尝试的人使用会很有用，因此我将其添加到我的 VS Code 编码副驾驶扩展 double.bot 。  还对前 50 条消息免费，以便在我们等待量化版本在本地运行时每个人都有机会尝试   由   提交/u/geepytee  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7c6e2/p_llama_3_70b_powered_coding_copilot_extension/</guid>
      <pubDate>Thu, 18 Apr 2024 19:29:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 医疗领域基准上的 Llama-3（7B 和 70B）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c7b35q/d_llama3_7b_and_70b_on_a_medical_domain_benchmark/</link>
      <description><![CDATA[      Llama-3 正在人工智能社区掀起波澜。我很好奇它在医学领域的表现如何，以下是 Llama-3（7B 和 70B）在由 9 个不同数据集组成的医学领域基准上的评估结果 https://preview.redd.it/sdwx5tglxbvc1.png?width=1464&amp;format =png&amp; ;auto=webp&amp;s=d32585a69244d44c83e2b1e8a85301a7a8676ea2 我会进行微调、评估和释放 Llama-3 和在接下来的几天里，我们将在不同的医疗和法律基准上获得不同的法学硕士。请关注此处的更新：https://twitter.com/aadityaura https://preview.redd.it/9egbcayv9avc1.png?width=1344&amp;format=png&amp;auto =webp&amp;s=436a972421d5568e1a544962b8cfd1c7b14efe04   由   提交 /u/aadityaura   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c7b35q/d_llama3_7b_and_70b_on_a_medical_domain_benchmark/</guid>
      <pubDate>Thu, 18 Apr 2024 18:45:43 GMT</pubDate>
    </item>
    <item>
      <title>[D] ICML 元评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c78or9/d_icml_meta_reviews/</link>
      <description><![CDATA[ICML 元评论何时发布？是否会与最终纸质通知一起宣布？该网页显示截止日期为 4 月 16 日。 https://icml.cc/Conferences/2024/ReviewerInstructions   由   提交/u/Personal_Click_6502   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c78or9/d_icml_meta_reviews/</guid>
      <pubDate>Thu, 18 Apr 2024 17:09:50 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自信地展示您的工作：调整曲线的置信带</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c783my/r_show_your_work_with_confidence_confidence_bands/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2311.09480  推文：https://x.com/NickLourie/status/1770077925779337563  代码：https://github.com/nicholaslourie/opda 文档：https://nicholaslourie.github.io/opda/tutorial/usage.html 摘要：  超参数的选择极大地影响自然语言处理的性能。通常，很难判断一种方法是否优于另一种方法，或者只是更好地调整。调优曲线通过考虑调优工作来解决这种歧义。具体来说，他们将验证性能绘制为迄今为止尝试的超参数选择数量的函数。虽然这些曲线存在多种估计器，但通常使用点估计，我们发现点估计会默默地失败，并且当给出的数据太少时会给出矛盾的结果。除了点估计之外，置信带对于严格建立不同方法之间的关系也是必要的。我们提出了第一种为调谐曲线构建有效置信带的方法。这些频带是精确的、同步的且无分布的，因此它们为比较方法提供了坚实的基础。实证分析表明，虽然作为基线的引导置信带未能接近其目标置信度，但我们的置信带却完全达到了目标。我们通过消融验证我们的设计，分析样本量的影响，并提供将模型与我们的方法进行比较的指导。为了促进未来工作中的自信比较，我们发布了 opda：一个易于使用的库，您可以使用 pip 安装它。    由   提交/u/nicholaslourie  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c783my/r_show_your_work_with_confidence_confidence_bands/</guid>
      <pubDate>Thu, 18 Apr 2024 16:46:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] InternVL v1.5开源，OpenCompass多模态基准测试排名第一</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c780cd/r_internvl_v15_open_sourced_ranking_first_in/</link>
      <description><![CDATA[      https://preview.redd.it/fh44g3n4m9vc1.png?width=1383&amp;format=png&amp;auto=webp&amp;s=9b3e499b d51aeb10559f4636eba2a1677d4a08a3 InternVL是多模态基础模型，被CVPR 2024接受为Oral paper。最新版本InternVL v1.5在OpenCompass多模态模型基准测试中排名第一。 演示： https://internvl.opengvlab.com/ 模型下载： https://huggingface.co/collections/OpenGVLab/internvl-65b92d6be81c86166ca0dde4 OpenCompass： https://rank.opencompass.org.cn 一些示例： https://preview.redd.it/rwj7vs9rm9vc1.jpg?width=902&amp;format=pjpg&amp;auto=webp&amp;s=514e14e69 2db8ea7bd5a66cc36b1ca3f8351102c&lt; /a&gt; https:// Preview.redd.it/vtwjml3qm9vc1.png?width=2508&amp;format=png&amp;auto=webp&amp;s=e32c044d4bc60ef28baf64dccdcb5fe9b10dfc61 https://preview.redd.it/p51vt3xpn9vc1.png?width=2609&amp;format=png&amp;auto=webp&amp; ;s= 73907e5ffb4d9b9bd4250cbce53e3bd29dedabf1   由   提交 /u/flyforlight   [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c780cd/r_internvl_v15_open_sourced_ranking_first_in/</guid>
      <pubDate>Thu, 18 Apr 2024 16:42:45 GMT</pubDate>
    </item>
    <item>
      <title>[N] Meta 发布 Llama 3</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c77f0m/n_meta_releases_llama_3/</link>
      <description><![CDATA[      https://llama.meta.com/llama3 /  ​ ​ https://preview.redd.it/n3lwb4xfj9vc1.png?width=3840&amp;format=png&amp;auto=webp&amp;s=b756d89c 50c627955668d5ac16df82f7af01cdbc&lt; /a&gt;   由   提交/u/we_are_mammals  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c77f0m/n_meta_releases_llama_3/</guid>
      <pubDate>Thu, 18 Apr 2024 16:18:07 GMT</pubDate>
    </item>
    <item>
      <title>[R] 压缩线性代表智能</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c76tpe/r_compression_represents_intelligence_linearly/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2404.09937 代码：https://github.com/hkust-nlp/llm-compression-intelligence 数据集：https://huggingface.co/datasets/hkust-nlp/llm-compression 摘要：&lt; /p&gt;  人们相信，学习良好的压缩会带来智慧。最近，语言建模已被证明等同于压缩，这为大型语言模型（LLM）的成功提供了令人信服的理由：更高级语言模型的开发本质上是增强压缩，从而促进智能。尽管讨论如此吸引人，但关于压缩和智能之间相互作用的实证证据却很少。在这项工作中，我们在法学硕士的背景下研究了它们的关系，将法学硕士视为数据压缩器。考虑到“智力”的抽象概念，我们采用平均下游基准分数作为替代，特别针对与知识和常识、编码和数学推理相关的智力。我们的研究涵盖 12 个基准，汇集了来自不同组织的 30 名公共法学硕士。值得注意的是，我们发现法学硕士的智力（通过平均基准分数反映出来）几乎与他们压缩外部文本语料库的能力呈线性相关。这些结果提供了具体的证据，支持这样的信念：卓越的压缩能力意味着更高的智力。此外，我们的研究结果表明，压缩效率作为源自原始文本语料库的无监督指标，可以作为与模型功能线性相关的可靠评估指标。我们开源我们的压缩数据集以及数据收集管道，以方便未来的研究人员正确评估压缩。    由   提交 /u/SeawaterFlows   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c76tpe/r_compression_represents_intelligence_linearly/</guid>
      <pubDate>Thu, 18 Apr 2024 15:54:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 产品评估是讨论最多的话题之一</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c75q78/d_product_evaluations_is_one_of_the_most/</link>
      <description><![CDATA[我们是一家人工智能咨询公司，这种情况一次又一次地发生在我们身上...... 我们开始一个新的法学硕士项目客户。 他们的工程师很快就能完成 80%。 他们有很多边缘情况，希望我们完成剩余的 20%。  &gt;我们向他们询问有关评估的信息。 当然他们没有。 我们创建评估框架，迭代改进管道，瞧。  工作完成，每个人都很高兴。 我认真地认为，根据我们的观察，最好的人工智能产品团队将是那些在评估上花费大量时间的团队。它很无聊，很重复，但它区分了令人惊叹的人工智能产品和表现不佳的产品。   由   提交 /u/BootstrapGuy   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c75q78/d_product_evaluations_is_one_of_the_most/</guid>
      <pubDate>Thu, 18 Apr 2024 15:10:17 GMT</pubDate>
    </item>
    <item>
      <title>[D] 100+标签文本分类问题。 “通常”的方法是什么？变形金刚？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c748uc/d_100_labels_textclassification_problem_whats_the/</link>
      <description><![CDATA[每个文本不超过15个单词，并且类别高度不平衡。但它们都至少有 30 个左右的实例。 我成功地处理了具有相同性质的数据，但具有大约 15 个标签以及梯度增强模型的集合。  在深入测试一堆模型之前，我想知道是否有一些策略可以解决像这样的高维问题。  有些问题是无法解决的，让我们面对现实吧。但是你们会尝试什么？   由   提交/u/Melodic_Reality_646   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c748uc/d_100_labels_textclassification_problem_whats_the/</guid>
      <pubDate>Thu, 18 Apr 2024 14:07:23 GMT</pubDate>
    </item>
    <item>
      <title>[D] 复制和比较研究模型 - 最佳实践？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c70y9j/d_reproducing_and_comparing_models_from_research/</link>
      <description><![CDATA[在我的工作中，我花费了大量时间复制研究论文并尝试将它们应用到我们的用例（医学图像分析）中。  通常，这是一个很大的麻烦，甚至带有代码的论文也经常表明，如果没有大量编辑，它就无法运行。一旦它们运行，只有在设置特定的随机种子时结果才会好...... 然后将其应用到我们的用例后，我意识到性能的提高实际上并不是来自新模型，但是来自不同的后处理方式... 我已经开始为自己编写一些脚本来模块化它，以便更容易地重现和比较。  但我不确定这是否是正确的方法。所以我很好奇，您为您的用例复制模型并进行科学比较的方法是什么？    由   提交 /u/MintOwlTech   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c70y9j/d_reproducing_and_comparing_models_from_research/</guid>
      <pubDate>Thu, 18 Apr 2024 11:27:51 GMT</pubDate>
    </item>
    <item>
      <title>[N] 美联储任命“人工智能末日者”来管理美国人工智能安全研究所</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1c6nps8/n_feds_appoint_ai_doomer_to_run_us_ai_safety/</link>
      <description><![CDATA[https://arstechnica.com/tech-policy/2024/04/feds-appoint-ai-doomer-to-run-us-ai-safety-institute/ 文章简介： 被任命为 AI 安全负责人的是 Paul Christiano，他是前 OpenAI 研究员，开创了一种名为基于人类反馈的强化学习的基础 AI 安全技术（ RLHF），但也因预测“人工智能发展有 50% 的机会以‘厄运’而告终”而闻名。尽管克里斯蒂安诺的研究背景令人印象深刻，但一些人担心，任命所谓的“人工智能厄运者”会带来灾难。 NIST 可能冒着鼓励非科学思维的风险，许多批评家认为这些思维纯粹是猜测。   由   提交/u/bregav  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1c6nps8/n_feds_appoint_ai_doomer_to_run_us_ai_safety/</guid>
      <pubDate>Wed, 17 Apr 2024 22:49:39 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持到下一篇，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1by6i5h/d_simple_questions_thread/</guid>
      <pubDate>Sun, 07 Apr 2024 15:00:22 GMT</pubDate>
    </item>
    </channel>
</rss>