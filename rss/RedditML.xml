<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>此 Reddit 子版块暂时关闭，以抗议 Reddit 终止第三方应用程序，请参阅 /r/ModCoord 和 /r/Save3rdPartyApps 了解更多信息。</description>
    <lastBuildDate>Thu, 15 Feb 2024 09:16:03 GMT</lastBuildDate>
    <item>
      <title>[D] 在本地 GPU 上运行 DL 模型的资源</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arb3pt/d_resources_to_run_dl_model_on_local_gpu/</link>
      <description><![CDATA[我的设备中有 rtx 3060 ti GPU，并尝试在 Jupiter 笔记本中执行多个深度学习和机器学习模型。 但我检查了任务管理器以及执行时间。看起来它没有利用 GPU 内存等本地资源。 您能帮我提供所需的代码片段或文章，以便我可以在 GPU 上执行我的模型吗？   由   提交 /u/FardinRock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arb3pt/d_resources_to_run_dl_model_on_local_gpu/</guid>
      <pubDate>Thu, 15 Feb 2024 08:46:55 GMT</pubDate>
    </item>
    <item>
      <title>[R] [2402.05919] 几何条件 PBR 图像生成的协同控制</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1araxfo/r_240205919_collaborative_control_for/</link>
      <description><![CDATA[ 由   提交 /u/StartCodeEmAdagio   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1araxfo/r_240205919_collaborative_control_for/</guid>
      <pubDate>Thu, 15 Feb 2024 08:33:51 GMT</pubDate>
    </item>
    <item>
      <title>[R] EEG-GPT：探索大型语言模型用于脑电图分类和解释的能力</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1araxfi/r_eeggpt_exploring_capabilities_of_large_language/</link>
      <description><![CDATA[论文：https://arxiv.org/abs/2401.18006  摘要：  在应用于脑电图 (EEG) 的传统机器学习 (ML) 方法中，这通常是一个有限的焦点，隔离发生的特定大脑活动跨越不同的时间尺度（从毫秒级的短暂峰值到持续几分钟的癫痫发作）和空间尺度（从局部高频振荡到全局睡眠活动）。这种孤立的方法限制了 EEG ML 模型的开发，而这些模型表现出多尺度的电生理理解和分类能力。此外，典型的 ML EEG 方法采用黑盒方法，限制了其在临床环境中的可解释性和可信度。因此，我们提出了 EEG-GPT，这是一种利用大语言模型 (LLM) 进步的统一脑电图分类方法。 EEG-GPT 在仅使用 2% 的训练数据的几次学习范式中对正常脑电图和异常脑电图进行分类方面取得了与当前最先进的深度学习方法相当的优异性能。此外，它还具有独特的优势，可以在操作中提供中间推理步骤并协调多个尺度的专业脑电图工具，提供透明且可解释的逐步验证，从而提高临床环境中的可信度。  ​   由   提交 /u/Typical-Respect590    reddit.com/r/MachineLearning/comments/1araxfi/r_eeggpt_exploring_capability_of_large_language/&quot;&gt;[链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1araxfi/r_eeggpt_exploring_capabilities_of_large_language/</guid>
      <pubDate>Thu, 15 Feb 2024 08:33:51 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用小数据集进行验证</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1arakd6/d_validation_with_small_datasets/</link>
      <description><![CDATA[我所在的领域的数据集通常很小（100-10000 个样本）且具有层次结构（取自 10-50 个参与者）。这意味着，为了在足够大的测试集上评估数据，而不仅仅是少数参与者，我们需要使用交叉验证。到目前为止一切顺利。 但是，这仍然没有解决验证问题。有几种可能的方法可以进行验证：  跳过验证。这似乎是我所在领域的首选方法。我认为这是非常错误的，而且我发现它可以高估准确度 5%（包含 5000 个样本的数据集），甚至高达 20%（100 个样本）。 将训练数据一次分割为训练和验证集用于对每个测试折叠进行验证。这样做的缺点是验证集最终很小（比测试集小得多），并且如果不小心的话，训练验证分割可能是任意的。 完全嵌套交叉验证。这似乎是正确验证超参数配置的最佳方法，因为它几乎使用整个数据集进行验证。我在我的领域还没有遇到过一篇使用嵌套交叉验证（正确）的论文。我相信主要问题非常明显：如果一个人使用 10 倍嵌套交叉验证训练一个神经网络模型 100 个时期，并尝试优化 5 个二进制超参数，那么最终已经有大约 100 * 10^2 * 2 ^5 = 320,000 个纪元。如果一个 epoch 需要 10 秒，这已经相当于一个多月的计算时间，而且我们仍然只验证了很少的超参数配置。  我可以看到以下解决方案：   p&gt;  接受计算需要这么长时间（并希望评审者不要要求我们重复实验）。 找到尽可能限制超参数配置的方法。  li&gt; 改用 5 重嵌套交叉验证。 减小验证集的大小（方法 2）。 承认并停止将神经网络拟合得较小数据集。  您对此有何看法？您更喜欢哪些选项？您还有其他解决方案吗？   由   提交/u/philosophicalmachine  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1arakd6/d_validation_with_small_datasets/</guid>
      <pubDate>Thu, 15 Feb 2024 08:07:12 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 使用Macbook进行机器学习值得吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ar9r38/discussion_is_using_a_macbook_worth_the_trouble/</link>
      <description><![CDATA[使用 Macbook 值得进行机器学习吗？ Reddit 用户您好，我有一台 Windows 笔记本电脑，规格相当不错用于机器学习，但我不喜欢的是它体积庞大且电池寿命很差。因此，我正在考虑改用 Macbook，因为它的电池续航时间、便携性以及更好的用户体验。 我要问的并不是 Macbook 是否比 Windows 笔记本电脑更适合机器学习，就像大多数 Reddit 那样帖子已经回答了这个问题。我相信这取决于个人选择。我也不是问你是否应该使用笔记本电脑进行机器学习，因为这个问题已经在这个 Reddit 子版块中得到了解答，我们都知道，对于中小型型号，大多数笔记本电脑都可以工作，具体取决于笔记本电脑的 RAM，对于更大的笔记本电脑模型，如 NLP 或 Gen-AI，最好使用专用工作站、SSH 或云。  我要问的是，与 Windows 或 Linux 相比，使用 Macbook 进行机器学习有哪些相关问题？有哪些可能的解决方法？这些问题是否严重到不需要进行切换，与仅使用问题较少的 Windows 笔记本电脑相比，使用解决方法是否没有那么麻烦？ 为了帮助我做出决定，我我正在确定切换到 Macbook 的成本以及这些机会成本是否很大。 提前感谢您的任何反馈，我也很感谢任何其他建议。 &lt; /div&gt;  由   提交 /u/Confident_Ad_7734   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ar9r38/discussion_is_using_a_macbook_worth_the_trouble/</guid>
      <pubDate>Thu, 15 Feb 2024 07:09:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我想要一些关于可以使用文本提示编辑图像的开源模型的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ar8els/d_i_would_like_some_suggestions_for_opensource/</link>
      <description><![CDATA[我一直在 `Huggingface` 的多模态部分中进行搜索，我找到的只是基于文本提示生成图像的文本到图像模型。我需要能够围绕或基于我已有图像中的主题生成图像的模型。   由   提交 /u/BBloggsbott   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ar8els/d_i_would_like_some_suggestions_for_opensource/</guid>
      <pubDate>Thu, 15 Feb 2024 05:43:43 GMT</pubDate>
    </item>
    <item>
      <title>[R] RVC 语音翻译器</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ar7e01/r_rvc_speech_to_speech_translator/</link>
      <description><![CDATA[我正在学习一门非常好的摄影测量课程，以英语为语言。我的女朋友对这个主题很感兴趣，也想参加该课程，但问题是，显然，该课程没有翻译。我希望能够免费翻译整个课程的配音并保留视频的原始声音，这样它就不会是机器人和合成的。我已经下载了一些 RVC GUI，但感觉完全迷失了或者它最终没有按预期工作。谁能帮我吗？   由   提交 /u/East-Return-5308   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ar7e01/r_rvc_speech_to_speech_translator/</guid>
      <pubDate>Thu, 15 Feb 2024 04:42:59 GMT</pubDate>
    </item>
    <item>
      <title>[N] Gradio Notebook 自定义组件</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ar1u1q/n_gradio_notebook_custom_component/</link>
      <description><![CDATA[嘿！我们刚刚与 Hugging Face 团队一起推出了 Gradio Notebook。  该组件在 Hugging Face 空间上部署笔记本用户体验。   在一个地方探索多个 Hugging Face 模型的最简单方法 使用文本、图像和音频模型构建 AI 工作流程 托管您的 AI 工作流程上抱脸给别人看！   在这里查看：https://huggingface.co/spaces/ lastmileai/gradio-notebook-template  我们正在寻找早期反馈以及改进体验的方法。如果您有任何疑问，请发表评论并随时私信 :)    由   提交 /u/InevitableSky2801   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ar1u1q/n_gradio_notebook_custom_component/</guid>
      <pubDate>Wed, 14 Feb 2024 23:59:50 GMT</pubDate>
    </item>
    <item>
      <title>[P] Whisper Large v3 基准：在消费类 GPU 上以 5110 美元（每美元 11,736 分钟）转录 100 万小时 - 后续</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ar08br/p_whisper_large_v3_benchmark_1_million_hours/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ar08br/p_whisper_large_v3_benchmark_1_million_hours/</guid>
      <pubDate>Wed, 14 Feb 2024 22:50:05 GMT</pubDate>
    </item>
    <item>
      <title>[D]微调时间有没有“负面提示”的方法？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqyhmk/d_is_there_a_way_of_negative_prompting_at/</link>
      <description><![CDATA[假设我正在尝试微调预训练的语言模型，并且我想更改其响应格式。通常情况下，我会根据新格式对一堆回复示例进行微调。但这样做也会改变模型的语义行为，以更接近地模仿 SFT 示例中存在的文本类型。有没有办法对新格式的示例进行微调，然后对微调示例中的相同文本进行有效的负面微调，但没有新的响应格式？最终结果是模型现在以所需的格式返回响应，但返回的文本类型的分布没有变化。   由   提交/u/thirdvox  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqyhmk/d_is_there_a_way_of_negative_prompting_at/</guid>
      <pubDate>Wed, 14 Feb 2024 21:35:28 GMT</pubDate>
    </item>
    <item>
      <title>[R] 自然语言强化学习</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqwx7q/r_natural_language_reinforcement_learning/</link>
      <description><![CDATA[arXiv: https:// arxiv.org/abs/2402.07157 OpenReview：https:// /openreview.net/forum?id=0VzU2H13qj 摘要：  强化学习（RL）在以下方面表现出了非凡的能力：学习决策任务的策略。然而，强化学习常常受到样本效率低、缺乏可解释性和监督信号稀疏等问题的阻碍。为了解决这些限制，我们从人类学习过程中汲取灵感，引入了自然语言强化学习 (NLRL)，它创新地将强化学习原理与自然语言表示相结合。具体来说，NLRL 重新定义了自然语言空间中的任务目标、策略、价值函数、贝尔曼方程和策略迭代等 RL 概念。我们介绍如何利用 GPT-4 等大型语言模型 (LLM) 的最新进展来实际实施 NLRL。对表格 MDP 的初步实验证明了 NLRL 框架的有效性、效率和可解释性。    由   提交/u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqwx7q/r_natural_language_reinforcement_learning/</guid>
      <pubDate>Wed, 14 Feb 2024 20:28:37 GMT</pubDate>
    </item>
    <item>
      <title>[R] 模型崩溃揭秘：回归案例</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqwset/r_model_collapse_demystified_the_case_of/</link>
      <description><![CDATA[论文：https:// arxiv.org/abs/2402.07712 摘要：  在ChatGPT这样的大型语言模型时代， “模型崩溃”指的是这样一种情况：随着时间的推移，模​​型根据其前几代生成的数据进行递归训练，其性能会下降，直到模型最终变得完全无用，即模型崩溃。在这项工作中，我们在核回归的简化设置中研究了这种现象，并获得了结果，这些结果显示模型可以处理虚假数据的情况与模型性能完全崩溃的情况之间存在明显的交叉。在多项式衰减光谱和源条件下，我们获得了修改后的缩放定律，该定律表现出从快速率到慢速率的新交叉现象。我们还提出了一种基于自适应正则化的简单策略来减轻模型崩溃。我们的理论结果通过实验得到了验证。    由   提交/u/FastestGPU   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqwset/r_model_collapse_demystified_the_case_of/</guid>
      <pubDate>Wed, 14 Feb 2024 20:22:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 阅读和学习研究论文的最佳方式</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</link>
      <description><![CDATA[当我们尝试专注于玉兰油的创新产品时，我们必须学习许多现代科技知识。但通常需要时间才能获得博客和教程上的可用资源。  因此，直接从第一个主要来源学习是有效的学习方式，因为它是主要来源。 但是，我发现阅读论文非常困难，因为它包含许多术语或内容不寻常的措辞。此外，跟踪和掌握一篇大论文的上下文也需要很大的耐心。 你们能分享一下你们的方法吗？你们如何有效且高效地从已发表的论文中学习并获得见解？   由   提交 /u/FardinRock   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqo515/d_best_way_to_read_and_learn_from_research_papers/</guid>
      <pubDate>Wed, 14 Feb 2024 14:28:04 GMT</pubDate>
    </item>
    <item>
      <title>[P] 通过计算机视觉让我的书架可点击</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</link>
      <description><![CDATA[      我构建了一个系统，可以让你拍摄书架的照片并创建一个交互式 HTML 网页，您可以在其中单击图像中的书籍来了解有关每本书的更多信息。 该项目的技术堆栈是：  用于检索的接地 SAM书籍的多边形。 OpenCV + 监督转换，为 OCR 准备书籍。 GPT-4 和 Vision for OCR Google Books API，用于获取书籍元数据。  生成 HTML + SVG 以创建最终网页。  我在博客上写了如何构建这个项目。 尝试演示。 我希望获得有关如何提高图书检测率以获得更好性能的反馈。在书脊上训练自定义分割模型可能会起作用，但我知道为此可能需要多少数据。 下面的红色多边形表示在演示中可点击的分段书籍：  p&gt; https://preview.redd.it /p9w4rgsn1jic1.png?width=1260&amp;format=png&amp;auto=webp&amp;s=35116c7eb9d1f5dab2b11375be9e2ff0e7163b78   由   提交/u/zerojames_  [链接] [评论] &lt; /表&gt;]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aqjp5d/p_making_my_bookshelves_clickable_with_computer/</guid>
      <pubDate>Wed, 14 Feb 2024 10:21:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人在此处发帖！ 帖子将一直保持活跃状态​​，直到下一篇帖子，因此请在标题中的日期之后继续发帖。 感谢大家回答问题在上一个线程中！   由   提交 /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1aob7zi/d_simple_questions_thread/</guid>
      <pubDate>Sun, 11 Feb 2024 16:00:18 GMT</pubDate>
    </item>
    </channel>
</rss>