<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>ml。初学者请参阅 learnmachinelearning</description>
    <lastBuildDate>Sun, 07 Jul 2024 09:15:49 GMT</lastBuildDate>
    <item>
      <title>[D] 编程经验有限的情况下我应该参加哪门机器学习课程？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxbvg4/d_which_machine_learning_course_should_i_take/</link>
      <description><![CDATA[我是卡内基梅隆大学的 MISM 研究生，今年秋季入学。我对机器学习很感兴趣，但没有太多的编程经验。我正在寻找建议，看看哪种机器学习课程最适合我的情况。 选项：  95-828 机器学习解决问题 10601 机器学习简介  如果您能分享有关这些课程的任何见解或经验，或者您可能有的任何其他建议，我将不胜感激。    提交人    /u/Sumedhmb   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxbvg4/d_which_machine_learning_course_should_i_take/</guid>
      <pubDate>Sun, 07 Jul 2024 08:38:21 GMT</pubDate>
    </item>
    <item>
      <title>Coreweave 为什么存在？ - [讨论]“[D]”</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxbr0a/why_does_coreweave_exist_discussion_d/</link>
      <description><![CDATA[最近偶然发现了 Coreweave 作为一些 LLM 工作的选择。我仍然不太明白 Coreweave 存在的原因，除非是因为在芯片短缺时他们获得了一些 NVDA 容量。 他们的 kubernetes 基础设施有什么不同？这基本上是一个由一个供应商管理的超大规模器 + NVDA 芯片吗？他们的技术堆栈有什么不同？ 也希望听到使用它们的经验。 请不要跟我说 NVDA 购买收入阴谋论。    提交人    /u/HeadofMacro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxbr0a/why_does_coreweave_exist_discussion_d/</guid>
      <pubDate>Sun, 07 Jul 2024 08:29:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 拥有使用 ONNX 或 openVino 提供模型的经验</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxbcue/d_experience_serving_models_with_onnx_or_openvino/</link>
      <description><![CDATA[到目前为止，我一直使用 torch 脚本来提供我的模型（主要是 CNN 和对象检测模型）。这样做的缺点是这些模型只能在 python 环境中执行，并且对 pytorch 有相当大的依赖性。 我正在研究使用 openVino 或 ONNX 来优化模型服务。对我来说重要的因素是  可以用任何语言执行 CPU 和 GPU 支持推理  推理速度，特别是在 CPU 上  您是否使用过这两种方法？什么对您有用/没用？    提交人    /u/Xayo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxbcue/d_experience_serving_models_with_onnx_or_openvino/</guid>
      <pubDate>Sun, 07 Jul 2024 08:02:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从 MLOps 转换到数据科学岗位的解释</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxb117/d_switching_from_mlops_to_data_science_job_role/</link>
      <description><![CDATA[  由    /u/mehul_gupta1997  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxb117/d_switching_from_mlops_to_data_science_job_role/</guid>
      <pubDate>Sun, 07 Jul 2024 07:39:22 GMT</pubDate>
    </item>
    <item>
      <title>[R] 识别歌曲中的音符（librosa）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dxa84z/r_identify_notes_in_a_song_librosa/</link>
      <description><![CDATA[我试图通过歌手的声音识别歌曲中的音符。我使用的是 librosa。当我使用 ypin 算法进行音高检测并使用 hz_to_note 将音高转换为音符时，是否由于音高估计中的噪声 - 音符可能被错误地识别为 C2，而实际上它只是 C2#。对于实际上更接近 C2# 但最终低于其基频的值，该函数会将其分配给音符 C2。 我该如何解决这个问题？是否有其他方法/库可以对几乎只是人声的音频进行音高检测？任何见解都值得赞赏！    提交人    /u/perfectlylonely13   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dxa84z/r_identify_notes_in_a_song_librosa/</guid>
      <pubDate>Sun, 07 Jul 2024 06:43:53 GMT</pubDate>
    </item>
    <item>
      <title>[R] 基于 Mamba 的语言模型实证研究（8B Mamba-2-Hybrid 在 3.5T token 数据上）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dx9ggp/r_an_empirical_study_of_mambabased_language/</link>
      <description><![CDATA[链接：http://arxiv.org/abs/2406.07887  选择性状态空间模型 (SSM)（如 Mamba）克服了 Transformers 的一些缺点，例如序列长度的二次计算复杂度和键值缓存的大量推理时间内存要求。此外，最近的研究表明，SSM 可以匹配或超越 Transformers 的语言建模能力，使其成为一种有吸引力的替代方案。然而，在受控设置（例如相同的数据）中，迄今为止的研究仅展示了将 SSM 与 Transformers 进行比较的小规模实验。为了了解这些架构在更大规模上的优势和劣势，我们直接比较了在多达 3.5T 个 token 的相同数据集上训练的 8B 参数 Mamba、Mamba-2 和 Transformer 模型。我们还将这些模型与由 43% Mamba-2、7% 注意力和 50% MLP 层 (Mamba-2-Hybrid) 组成的混合架构进行了比较。使用一组不同的任务，我们回答了 Mamba 模型是否可以在更大的训练预算下与 Transformers 匹敌的问题。我们的结果表明，虽然纯 SSM 在许多任务上与 Transformers 匹敌或超过 Transformers，但它们在需要强大复制或上下文学习能力（例如 5-shot MMLU、电话簿）或长上下文推理的任务上落后于 Transformers。相比之下，我们发现 8B Mamba-2-Hybrid 在我们评估的所有 12 个标准任务上都超过了 8B Transformer（平均 +2.65 分），并且预计在推理时生成 token 时速度最高可提高 8 倍。为了验证长上下文能力，我们提供了额外的实验，评估 Mamba-2-Hybrid 和 Transformer 的变体，以支持 16K、32K 和 128K 序列。在另外 23 个长上下文任务中，混合模型继续接近或平均超过 Transformer。为了进一步研究，我们发布了检查点以及用于训练我们模型的代码，作为 NVIDIA Megatron-LM 项目的一部分。     submitted by    /u/ghosthamlet   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dx9ggp/r_an_empirical_study_of_mambabased_language/</guid>
      <pubDate>Sun, 07 Jul 2024 05:52:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dx5tpo/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dx5tpo/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 07 Jul 2024 02:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] Pytorch XLA/TPU 上有任何 mamba（或其他 SSM）的实现吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dx50pv/d_any_implementations_of_mamba_or_other_ssm_on/</link>
      <description><![CDATA[mamba_ssm 无法安装在我的 TPU VM 上，因为没有 nvcc。     提交人    /u/daking999   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dx50pv/d_any_implementations_of_mamba_or_other_ssm_on/</guid>
      <pubDate>Sun, 07 Jul 2024 01:31:10 GMT</pubDate>
    </item>
    <item>
      <title>[R] 改进语音识别的室内脉冲响应估计</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dx0kue/r_towards_improved_room_impulse_response/</link>
      <description><![CDATA[        由    /u/Snoo63916  提交  [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dx0kue/r_towards_improved_room_impulse_response/</guid>
      <pubDate>Sat, 06 Jul 2024 21:50:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] 从文章中提取 NER</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwxyy1/d_extracting_ner_from_articles/</link>
      <description><![CDATA[我有很多新闻文章，需要从中提取标签和重要关键词。我尝试使用 NLTK、Spacy、Flair，但它们并不准确。我也尝试过使用 LLM，主要是 llama3、bert 等，但速度很慢。现在有什么建议/想法可以告诉我怎么做吗？    提交人    /u/expiredUserAddress   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwxyy1/d_extracting_ner_from_articles/</guid>
      <pubDate>Sat, 06 Jul 2024 19:50:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] 交叉验证是否只能检测或减轻/避免过度拟合问题？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwweqt/d_does_crossvalidation_only_detect_or/</link>
      <description><![CDATA[YouTube 上有一位教授不同意竞赛的观点，即交叉验证可以减轻过度拟合。根据这位教授的说法，交叉验证只是检测过度拟合的存在。目前，我倾向于同意竞赛的观点，因为在我看来，交叉验证可以更好地评估错误，从而避免过度拟合。但是，我想保持开放的心态，听取您的意见，因为我想对事情有一个清晰的理解    提交人    /u/ZehEstocahstico   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwweqt/d_does_crossvalidation_only_detect_or/</guid>
      <pubDate>Sat, 06 Jul 2024 18:39:57 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用元数据和 Python 下载托管数据集的最佳方式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwt33t/d_best_way_to_host_datasets_with_metadata_and/</link>
      <description><![CDATA[我有一堆想要公开的数据集，并且想将其下载为类似于 scikit-learn 或 sktime 中的示例数据集。 我的数据是表格形式的，但它也具有每个数据集的全局元数据，例如不同类型的分割。例如，数据集是：  包含实际数据的 CSV 按时间分割的训练/测试分割索引 按另一个分割的训练/测试分割索引  我已经考虑过并拒绝了：  UCI - 他们已经 3 个月没有批准我的数据集（“待定”状态）。 OpenML - 首先，网站上的上传不起作用（单击上传按钮时挂起）。其次，我不确定它是否允许额外的元数据文件，我认为不允许，因为任务和拆分似乎与数据集分开。 HuggingFace Hub - 不允许额外的元数据，如此处和此处所述。 Kaggle - 不允许公开下载，即它要求在下载之前进行身份验证，即使是从 Python API 也是如此。 AWS Open Data、BigQuery 公共数据集等 - 我绝不会将我的信用卡详细信息放在没有下载限制的公共数据集的任何地方。此外，设置它是件苦差事。 Zenodo - 基本上不为人知（尽管宣传和 SEO 不是我的主要关注点），而且不够稳定（刚才我试图在那里搜索一些东西时得到了 503）。  你对替代解决方案有什么想法吗？我开始认为老牌的 Google Drive 是最好的解决方案，只需上传带有数据集的目录即可。    提交人    /u/qalis   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwt33t/d_best_way_to_host_datasets_with_metadata_and/</guid>
      <pubDate>Sat, 06 Jul 2024 16:09:15 GMT</pubDate>
    </item>
    <item>
      <title>[P] 时间序列模型基准测试</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwlvi5/p_time_series_model_benchmarking/</link>
      <description><![CDATA[我创建了一个帖子和一个演示应用程序，使用来自 40 个数据集的莫纳什大学基准对 13 个时间序列模型进行排名。该应用程序以更易于使用的格式呈现信息，并且比使用莫纳什网站更容易比较模型性能。我还开始进行一些分析，以呈现显示模型方法与预测范围关系的图表，并计划随着时间的推移，使用尚未进行基准测试的较新模型进行自己的基准测试。排名系统是使用一级方程式积分系统完成的，但所有这些都有一个重要的观点，即促进更一致的时间序列模型评估标准。 F1 得分时间序列模型排行榜    提交人    /u/Inner_Potential2062   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwlvi5/p_time_series_model_benchmarking/</guid>
      <pubDate>Sat, 06 Jul 2024 09:36:49 GMT</pubDate>
    </item>
    <item>
      <title>[R] 扩散强制：下一个标记预测与全序列扩散相遇</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwkces/r_diffusion_forcing_nexttoken_prediction_meets/</link>
      <description><![CDATA[        由    /u/Rose52152   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwkces/r_diffusion_forcing_nexttoken_prediction_meets/</guid>
      <pubDate>Sat, 06 Jul 2024 07:43:56 GMT</pubDate>
    </item>
    <item>
      <title>[D] 所有在机器学习领域工作了数月或数年的人——多年来，您职业生涯中最大的时刻是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1dwhx5f/d_all_the_folks_working_on_machine_learning_for/</link>
      <description><![CDATA[每天都有很多新的实验以难以跟上的速度进行。 例如，对于 2015 年的我来说，最大的基本见解是，十年内 90% 以上的数据将是非结构化的，而现在正在发生这种情况。这促使我进入电子商务、零售、医疗保健、农业和汽车等各个领域探索机器学习等模型。    提交人    /u/Worth-Card9034   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1dwhx5f/d_all_the_folks_working_on_machine_learning_for/</guid>
      <pubDate>Sat, 06 Jul 2024 05:05:14 GMT</pubDate>
    </item>
    </channel>
</rss>