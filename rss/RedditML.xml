<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Thu, 28 Nov 2024 01:20:31 GMT</lastBuildDate>
    <item>
      <title>因果发现竞赛获奖论文讨论[D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h1i0ji/causal_discovery_competition_winning_paper/</link>
      <description><![CDATA[我最近看到了这篇文章：https://thetourney.github.io/adia-report/，它描述了一场休闲发现竞赛的获胜方法。这不是我的专业，但我确实对 GNN 和因果推理有合理的理解。无论如何，从报告中我不明白获胜团队到底在做什么。有人可以链接到完整的论文或对他们正在做的事情有一个直观且可能的分步解释吗？    提交人    /u/www3cam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h1i0ji/causal_discovery_competition_winning_paper/</guid>
      <pubDate>Wed, 27 Nov 2024 23:22:43 GMT</pubDate>
    </item>
    <item>
      <title>集成 MLR 中的残差 [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h1ero2/residuals_in_ensemble_mlr_d/</link>
      <description><![CDATA[大家好 集成新手。 但是，如果您集成 MLR，则最终可能会得到一个非线性方程…… A) 集成的单个 MLR 的残差需要满足参数假设吗？不能只因为它将在集成中使用而使用垃圾 MLR？B) 如果集成的 MLR 方程是线性的，那么残差应该满足参数假设吗？ 谢谢    提交人    /u/Yellow_fruit_2104   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h1ero2/residuals_in_ensemble_mlr_d/</guid>
      <pubDate>Wed, 27 Nov 2024 20:58:23 GMT</pubDate>
    </item>
    <item>
      <title>[P] 搜索查询内容安全审核模型选择</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h1dof1/p_search_query_content_safety_moderation_model/</link>
      <description><![CDATA[大家好，我正在制作一个具有搜索功能的移动应用程序。在字符串清理和验证之后，我想将查询归类到一个或多个类别中，以进行内容安全审核，类似于 Google 为图像上的 SafeSearchAnnotations 或 Llama Guard 中为 LLM 提示/响应提供的 Meta 服务。 我需要非常快（&lt;100 毫秒）的东西，因为显然实际搜索和数据提取需要在预过滤后以低延迟（&lt;500 毫秒）进行。我预计有 1000...2000 个带标签的样本搜索查询和另外 5000...10000 个未标记的样本搜索查询用于模型验证。在此之前，我可能还有一个在客户端上运行的停用词列表，并且在删除所有停用词之前不允许用户发送查询。这些类别可能有两个父类（用户/管理员），每个类别有五个子类。用户可以调整用户类别，如果查询属于管理类别，则会被标记并触发审核。我需要模型为所有类别提供分数。 请不要推荐任何 LLM/GPT，因为这些速度不够快，我正在寻找像 BERT 或其变体这样的东西，但不确定是哪一个。仅限英语。目前，我正在真正关注 Google Cloud 的 Model Garden，特别是 MobileBERT Classifier 或 RoBERTa-large (PEFT)，因为我的很多堆栈都是 GC 繁重的。我不想设置和部署复杂的东西。请注意，这与确定 Google 的 Perceptive API 中的“毒性”不同。    提交人    /u/AxelrodWins   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h1dof1/p_search_query_content_safety_moderation_model/</guid>
      <pubDate>Wed, 27 Nov 2024 20:11:08 GMT</pubDate>
    </item>
    <item>
      <title>[D] 如何对这类数据做RLHF？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h1bpwq/d_how_to_do_rlhf_on_this_kind_of_data/</link>
      <description><![CDATA[嗨，如果这是一个愚蠢的问题，请原谅——我真的不了解后期训练。假设我有一只骆驼，我想用人工注释来微调“喜欢”或“不喜欢”一个提示响应。大多数 DPO 数据集都有一对可能的响应，其中一个被选中。将我的数据解释为一对中的一半，其中一个缺失，我可以从同一个提示生成第二个响应，并说如果“喜欢”它是首选，如果“不喜欢”它是不首选。有更好的方法吗？    提交人    /u/khidot   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h1bpwq/d_how_to_do_rlhf_on_this_kind_of_data/</guid>
      <pubDate>Wed, 27 Nov 2024 18:50:05 GMT</pubDate>
    </item>
    <item>
      <title>[D] 知识蒸馏神经网络</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h17xwc/d_knowledge_distillation_neural_network/</link>
      <description><![CDATA[大家好， 假设我原来的神经网络模型大小为 50MB。有没有办法在应用知识蒸馏后估算蒸馏模型的大小。    提交人    /u/PhilosopherNew313   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h17xwc/d_knowledge_distillation_neural_network/</guid>
      <pubDate>Wed, 27 Nov 2024 16:13:12 GMT</pubDate>
    </item>
    <item>
      <title>[R] 帮助提交 WACV 研讨会论文</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h15p2e/r_help_with_submitting_a_wacv_workshop_paper/</link>
      <description><![CDATA[大家好， 我之前从未向任何会议提交过论文。我必须向 11 月 30 日截止的 WACV 研讨会提交一篇论文。 到目前为止，我几乎已经完成了 WACV 推荐的模板，但它在生成 PDF 时要求在 LaTeX 文件中提供论文 ID。我不确定从哪里获取该论文 ID。 我使用 Microsoft CMT 进行提交。我是否需要先提交没有论文 ID 的论文以分配它，然后用 ID 更新 PDF 并重新提交？或者有没有办法事先获得 ID？ 此外，WACV 的抄袭阈值是多少？我想确保合规，但希望明确多少百分比的相似性是可以接受的。 谢谢您的帮助！    提交人    /u/__proximity__   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h15p2e/r_help_with_submitting_a_wacv_workshop_paper/</guid>
      <pubDate>Wed, 27 Nov 2024 14:34:45 GMT</pubDate>
    </item>
    <item>
      <title>[D] AAMAS 2025 评论出炉！</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h15k8k/d_aamas_2025_reviews_are_out/</link>
      <description><![CDATA[我找不到讨论主题，所以我想自己创建一个。     提交人    /u/E-Cockroach   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h15k8k/d_aamas_2025_reviews_are_out/</guid>
      <pubDate>Wed, 27 Nov 2024 14:28:29 GMT</pubDate>
    </item>
    <item>
      <title>[R] Meissonic：通过增强蒙版图像建模实现高分辨率文本到图像的生成</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h1529m/r_meissonic_highresolution_texttoimage_generation/</link>
      <description><![CDATA[这项工作引入了一种非自回归掩蔽图像建模 (MIM) 方法，旨在匹配 SDXL 级图像生成，同时避免自回归方法的标记效率低下。关键创新是将 MIM 与架构改进和采样优化相结合，以实现高分辨率图像合成。 主要技术要点： - 使用具有专门的自注意力和位置编码的基于变压器的架构 - 将人类偏好分数作为“微条件”来指导生成 - 采用特征压缩层有效处理高分辨率 - 通过并行标记预测而不是顺序预测生成 1024x1024 图像 - 实现与 SDXL 相当的 FID 分数，同时计算效率更高 结果： - 在标准基准上，图像质量指标与 SDXL 相媲美 - 与自回归方法相比，生成速度更快 - 更好地处理复杂场景和构图 - 与以前的 MIM 方法相比，文本对齐得到改进 我认为这可能会在几个方面影响该领域： - 表明非扩散方法可以实现 SOTA 级生成 - 提供统一语言视觉模型的潜在途径 - 可能导致更有效地部署文本到图像系统 - 可能影响未来多模态模型的架构设计 在我看来，最大的悬而未决的问题是这种方法是否可以进一步扩展 - 虽然它在当前分辨率下运行良好，但目前尚不清楚相同的原理是否会在更高的维度上成立。 TLDR：非自回归掩蔽建模方法匹配 SDXL 级图像生成同时比典型的自回归方法更有效。显示出统一语言视觉架构的前景。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h1529m/r_meissonic_highresolution_texttoimage_generation/</guid>
      <pubDate>Wed, 27 Nov 2024 14:05:29 GMT</pubDate>
    </item>
    <item>
      <title>[D] 使用 LLM 进行评估的有效性如何？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h11lbt/d_how_valid_is_the_evaluation_using_llms/</link>
      <description><![CDATA[大家好， 我对使用 Gen AI 还不熟悉，我想检查使用更大的 LLM 评估其他 LLM 结果的有效性。我见过不同的博客这样做是为了实现评估自动化。 例如，要评估模型 A 的英语翻译列表，提示另一个模型 B 是否有效，如下所示 &#39;&#39;&#39;这个翻译是否正确 原文：{original_text}，翻译文本 {translated_text}&#39;&#39;&#39; 这是一种有效的评估方式吗？我内心深处的某种东西告诉我这在科学上是错误的，因为 LLM 模型 B 本身会有一些错误，对吧？    提交人    /u/raman_boom   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h11lbt/d_how_valid_is_the_evaluation_using_llms/</guid>
      <pubDate>Wed, 27 Nov 2024 10:48:09 GMT</pubDate>
    </item>
    <item>
      <title>[D] AISTATS 2025 论文评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0y8rn/d_aistats_2025_paper_reviews/</link>
      <description><![CDATA[由于 AISTATS 2025 论文评审今天截止，所以我想开一个帖子让大家讨论一下自己的经验！    提交人    /u/PhoneImpressive9983   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0y8rn/d_aistats_2025_paper_reviews/</guid>
      <pubDate>Wed, 27 Nov 2024 06:42:52 GMT</pubDate>
    </item>
    <item>
      <title>[D] AISTATS 2025 评论</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0x428/d_aistats_2025_reviews/</link>
      <description><![CDATA[Aistats 2025 评论应该会在今天发布。所以我想创建一个讨论帖子，让我们可以分享我们的经验！    提交人    /u/PhoneImpressive9983   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0x428/d_aistats_2025_reviews/</guid>
      <pubDate>Wed, 27 Nov 2024 05:31:15 GMT</pubDate>
    </item>
    <item>
      <title>[R] 机器学习中的黑洞和损失景观</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0uwjd/r_black_holes_and_the_loss_landscape_in_machine/</link>
      <description><![CDATA[摘要：  了解损失景观是机器学习中的一个重要问题。损失函数的一个关键特征是存在指数级的低位局部最小值，这在许多神经网络架构中都很常见。具有类似能量景观的物理系统可能会提供有用的见解。在这项工作中，我们指出，由于黑洞熵的存在，黑洞自然会产生这样的景观。为了明确起见，我们考虑 =8 弦理论中的 1/8 BPS 黑洞。这些提供了在相应黑洞的微观描述中出现的无限潜在景观系列。最小值的计数相当于黑洞微观状态计数。此外，这些景观的最小值的确切数量是从弦理论中的对偶性中先验已知的。一些最小值由低损失值的路径连接，类似于模式连接。我们估计找到所有解决方案所需的运行次数。初步探索表明，随机梯度下降可以找到很大一部分最小值。  Arxiv：https://arxiv.org/abs/2306.14817    提交人    /u/Mindless-House-8783   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0uwjd/r_black_holes_and_the_loss_landscape_in_machine/</guid>
      <pubDate>Wed, 27 Nov 2024 03:26:49 GMT</pubDate>
    </item>
    <item>
      <title>[P] [D] 比较 Llama 模型和 GPT 4o 模型在多语言机器翻译和反向翻译方面的表现</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h0sehj/p_d_comparing_llama_models_and_gpt_4o_models_on/</link>
      <description><![CDATA[      大家好， 本着 LLM 实际现实世界任务的精神，我们想看看不同的模型能够多好地自动将耐克产品目录上的文本从英语翻译成西班牙语，然后再翻译回英语。我们从 Llama 405B、Llama 70B、Llama 8B、GPT 4o-mini 和 GPT 4o 开始，但希望测试更多模型。 ~ TLDR ~ 以下是包含所有数据和代码的结果： https://www.oxen.ai/datasets/Nike-Product-Translation-Experiments https://preview.redd.it/qken2vjfhc3e1.png?width=1150&amp;format=png&amp;auto=webp&amp;s=739ef336dd7b89856a39d872ef12e03f806ce799 虽然反向翻译可能不是最有效的基准测试方法，但我们认为这将是一个有趣的实验，看看它与模型性能的相关性如何。让以西班牙语为母语的人用基本事实标签注释数据集是理想的选择，因此如果有人想做出贡献，请随时分叉 repo，我们可以获得一些真正的标签。 我们正在尝试制作更多现实世界的数据集 / 基准，因此如果您想提供帮助，请告诉我们。 如果您是 Oxen.ai 项目的新手，我们正在构建一个快速的开源数据集协作工具以及大量有用的数据探索工具！如果您对数据或 ML/AI 感兴趣，我们很乐意听取您对该工具和项目的想法！    提交人    /u/FallMindless3563   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h0sehj/p_d_comparing_llama_models_and_gpt_4o_models_on/</guid>
      <pubDate>Wed, 27 Nov 2024 01:17:44 GMT</pubDate>
    </item>
    <item>
      <title>[D] 自我推销帖</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</link>
      <description><![CDATA[请发布您的个人项目、初创公司、产品展示、协作需求、博客等。 请提及产品和服务的付款和定价要求。 请勿发布链接缩短器、链接聚合器网站或自动订阅链接。  任何滥用信任的行为都会导致禁令。 鼓励其他为问题创建新帖子的人在这里发帖！ 主题将保持活跃，直到下一个主题，因此请在标题中的日期之后继续发帖。  元：这是一个实验。如果社区不喜欢这样，我们将取消它。这是为鼓励社区中的人们通过不在主线程上发垃圾邮件来推广他们的工作。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1gyhfxm/d_selfpromotion_thread/</guid>
      <pubDate>Sun, 24 Nov 2024 03:15:10 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Tue, 01 Oct 2024 02:30:17 GMT</pubDate>
    </item>
    </channel>
</rss>