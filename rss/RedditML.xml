<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/learnmachinelearning ，AGI -> /r/singularity</description>
    <lastBuildDate>Fri, 02 Aug 2024 15:16:17 GMT</lastBuildDate>
    <item>
      <title>[D] NLP 论文的新常态是“提示工程”论文吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei9e3l/d_is_the_new_norm_for_nlp_papers_prompt/</link>
      <description><![CDATA[很多论文似乎本质上都是“我们如何让 LLM 1 不经过任何培训就能做到这一点？”我已经有一段时间没有发表过文章了，过去几年一直在行业内工作。我最近加入了一家新公司，担任一个稍微更偏向研究的职位，与研究科学家和研究生实习生一起工作。我注意到他们每个人都在做一些我在研究生院会受到 PI 斥责的事情。基本上就是“我们如何让 LLM 不经过任何培训就能完成这个非常复杂的任务？”也许并不出人意料的是，在很多情况下，你做不到。我想这就是为什么现在 NLP 领域有这么多负面结果的论文。 这是新常态吗？浏览 arXiv 的 CL 部分已经变得很痛苦了。 98% 的论文都是类似“LLaMA 怎么会不懂数字？”这样的问题。 我想知道我是不是酒吧角落里那个老糊涂，还是大家都有同样的感受。    提交人    /u/Seankala   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei9e3l/d_is_the_new_norm_for_nlp_papers_prompt/</guid>
      <pubDate>Fri, 02 Aug 2024 12:57:27 GMT</pubDate>
    </item>
    <item>
      <title>torch 高斯随机权重初始化和 L2 正则化 [D][R][P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei8xn9/torch_gaussian_random_weights_initialization_and/</link>
      <description><![CDATA[我有一个线性/全连接的 torch 层，它接受 latent_dim 维输入。该层中的神经元数量 = 高度 \ 宽度*:  # 定义当前层的超参数 - height = 20 width = 20 latent_dim = 128 # 初始化线性层 - linear_wts = nn.Parameter(data = torch.empty(height * width, latent_dim), require_grad = True) &#39;&#39;&#39; torch.nn.init.normal_(tensor, mean=0.0, std=1.0, generator=None) 用从正态分布中抽取的值填充输入张量 - N(mean, std^2) &#39;&#39;&#39; nn.init.normal_(tensor = som_wts, mean = 0.0, std = 1 / np.sqrt(latent_dim)) print(f&#39;1/sqrt(d) = {1 / np.sqrt(latent_dim):.4f}&#39;) print(f&#39;SOM 随机 wts; min = {som_wts.min().item():.4f} &amp;&#39; f&#39; max = {som_wts.max().item():.4f}&#39; ) print(f&#39;SOM 随机 wts; mean = {som_wts.mean().item():.4f} &amp;&#39; f&#39; std-dev = {som_wts.std().item():.4f}&#39; ) # 1/sqrt(d) = 0.0884 # SOM 随机 wts；min = -0.4051 &amp; max = 0.3483 # SOM 随机 wts；mean = 0.0000 &amp; std-dev = 0.0880  问题 1：对于 std-dev = 0.0884（大约），根据最小值和最大值 -0.4051 和 0.3483，似乎正常初始化程序正在计算距离平均值 = 0 的 +3.87 个标准差和距离平均值 = 0 的 -4.4605 个标准差。这是正确的理解吗？我假设权重是从距离平均值 +3 和 -3 个标准差中抽取的？ 大多数最近的自监督学习论文，即 SimCLR、MoCo、Barlow Twins、SwAV、BYOL、SimSiam 等，都使用 L2 标准化输出进行成本函数计算和训练。受此启发，我尝试了以下操作： 问题 2：我希望此线性层的输出进行 L2 归一化，使其位于单位超球面上。为此，似乎有 2 个选项：  执行一次性操作：```linear_wts.data.copy_(nn.Parameter(data = F.normalize(input = linear_wts.data, p = 2.0, dim = 1)))```，然后照常训练 获取层的输出为：```F.relu(linear_wts(x))```，然后执行 L2 归一化（针对每个训练步骤）：```F.normalize(input = F.relu(linear_wts(x)), p = 2.0, dim = 1)```  我认为选项 2 更正确。有什么想法吗？    由   提交  /u/grid_world   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei8xn9/torch_gaussian_random_weights_initialization_and/</guid>
      <pubDate>Fri, 02 Aug 2024 12:35:18 GMT</pubDate>
    </item>
    <item>
      <title>[D] LlamaIndex 模式用法</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei3lzz/d_llamaindex_pattern_usage/</link>
      <description><![CDATA[我制作了一个 YouTube 视频，作为 LlamaIndex 新手的入门指南。虽然我对 RAG（检索增强生成）解决方案和实现有经验，但教学对我来说是一项新尝试，我很乐意与社区分享我的方法。 在这篇文章中，我的目标是简化初学者学习 LlamaIndex 的过程。我没有深入研究密集的文档，而是以一种引人入胜的方式呈现概念，并结合模因让事情变得有趣。 以下是视频内容的简要概述：  通过 5 个简单步骤解释 LlamaIndex。 有效使用的实用示例和模式。 简化工作流程的技巧和窍门。  我愿意接受任何批评和改进建议。您的反馈将非常宝贵，有助于我改进教学方法并在未来创建更有效的内容。 感谢您花时间观看我的视频，我期待听到您的想法！    提交人    /u/Several_Operation707   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei3lzz/d_llamaindex_pattern_usage/</guid>
      <pubDate>Fri, 02 Aug 2024 07:03:08 GMT</pubDate>
    </item>
    <item>
      <title>二进制值的特征相关性[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei21gb/feature_correlation_for_binary_values_p/</link>
      <description><![CDATA[我想要预测的标签是二进制的（不确定这是否重要），其中一个特征也是二进制的。当我对标签进行特征相关时，我得到一个像 0.35 这样的数字，然后如果我切换特征的真假，相关性将是完全相同的数字，但被取反（所以像 -0.35）。首先，你如何解释这一点？具体来说，我在女性特征的真假之间切换。其次，这是确定二进制值的特征重要性的正确方法吗？因为似乎找到二进制特征的相关性只是说明模型对特征的真实值的工作情况，而不是整个特征的工作情况。     提交人    /u/Inspection-Conscious   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei21gb/feature_correlation_for_binary_values_p/</guid>
      <pubDate>Fri, 02 Aug 2024 05:20:07 GMT</pubDate>
    </item>
    <item>
      <title>我制作了一个 SWE 套件，以便轻松构建 SWE Agent [P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ei0pd7/i_made_a_swe_kit_for_easy_swe_agent_construction_p/</link>
      <description><![CDATA[大家好！我很高兴与大家分享一个新项目：SWEKit，这是一个使用 Composio 工具生态系统构建软件工程代理的强大框架。 目标 SWEKit 允许您：  使用 CrewAI 和 LlamaIndex 等框架构建开箱即用的代理。 添加或优化代理的能力。 根据 SWE-Bench 对您的代理进行基准测试。  实施细节  使用的工具：Composio、CrewAI、Python  设置：  安装您选择的代理框架和 Composio 插件 代理需要 github 访问令牌才能与您的存储库配合使用 您还需要设置 API 密钥适用于您计划使用的 LLM 提供程序  搭建并运行您的代理 工作区环境： SWEKit 支持不同的工作区环境：  主机：在主机上运行。 Docker：在 Docker 容器内运行。 E2B：在 E2B 沙箱内运行。 FlyIO：在 FlyIO 机器内运行。  运行基准测试：  SWE-Bench 使用来自流行 Python 开源项目的实际问题来评估软件工程代理的性能。  GitHub 欢迎探索该项目，如果发现它有用，请给它一颗星，并让我知道您的想法或改进建议！🌟    提交人    /u/kingai404   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ei0pd7/i_made_a_swe_kit_for_easy_swe_agent_construction_p/</guid>
      <pubDate>Fri, 02 Aug 2024 04:05:02 GMT</pubDate>
    </item>
    <item>
      <title>[P] 加权损失函数（Pytorch 的 CrossEntropyLoss）解决多类多输出问题的不平衡数据分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehyv6b/p_weighted_loss_function_pytorchs/</link>
      <description><![CDATA[我正在尝试使用加权损失函数来处理数据中的类别不平衡问题。我的问题是多类别和多输出问题。例如（我的数据有五个输出/目标列（output_1、output_2、output_3）并且每个目标列中有三个类（class_0、class_1 和 class_2）。我目前正在使用 pytorch 的交叉熵损失函数https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html并且我看到它有一个权重参数，但我的理解是，这个相同的权重将统一应用于每个输出/目标，但我想在每个输出/目标中为每个类应用单独的权重。 具体来说，我可以获得如下数据   A B C D E OUTPUT_1 OUTPUT_2 OUTPUT_3    5.65 3.56 0.94 9.23 6.43 0 2 1   7.43 3.95 1.24 7.22 2.66 0 0 0   9.31 2.42 2.91 2.64 6.28 2 0 2   8.19 5.12 1.32 3.12 8.41 0 2 0   9.35 1.92 3.12 4.13 3.14 0 1 1   8.43 9.72 7.23 8.29 9.18 1 0 2   4.32 2.12 3.84 9.42 8.19 0 1 0   3.92 3.91 2.90 8.19 8.41 2 0 2   7.89 1.92 4.12 8.19 7.28 0 1 2   5.21 2.42 3.10 0.31 1.31 2 0 0   其中，产出 1 中的比例为：0 = 0.6, 1 = 0.1, 2 = 0.3 产出 2 中的比例为：0 = 0.4, 1 = 0.3, 2 = 0.3  输出 3 为：0 = 0.4、1 = 0.2、2 = 0.4 我想根据每个输出列中的类分布应用类权重，以便它重新规范化（或重新平衡？不确定这里要使用的术语是什么）类 1 为 0.15，类 0 和类 2 各为 0.425（因此对于 output_1，权重将是 [0.425/0.6、0.15/0.1、0.425/0.3]，对于输出 2，它将是 [0.425/0.4、0.15/0.3、0.425/0.3] 等）。相反，我理解 pytorch 的交叉熵损失函数中的权重参数目前正在做的事情是，它将对每个输出列应用单个类权重。任何帮助都将不胜感激。     由   提交  /u/Individual_Ad_1214   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehyv6b/p_weighted_loss_function_pytorchs/</guid>
      <pubDate>Fri, 02 Aug 2024 02:28:02 GMT</pubDate>
    </item>
    <item>
      <title>[D] 理解 ByteNet 架构</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehws26/d_understanding_bytenet_architecture/</link>
      <description><![CDATA[你好！ 我正在考虑在一个项目中使用 ByteNet (https://arxiv.org/abs/1610.10099) 架构，并希望更好地了解该模型的工作原理。 我已经阅读了这篇论文大约一百万次，但无法弄清楚动态展开究竟是如何实现的。我知道输入序列被映射到更长的中间表示，其长度是输入长度的函数，但不明白 1×1 卷积层如何做到这一点。我也不清楚输入序列如何可以具有可变长度而没有任何重复。 背景：动态展开的目标是允许模型处理输入长度与目标长度不匹配的情况（例如，将句子翻译成另一种语言时就是这种情况）。它涉及创建输入序列 s 的表示，其长度为 a \ |s| + b，其中 *a 和 b 是超参数。这个新的、更长的表示是使用一维卷积层生成的（以一种我无法理解的方式）。 任何帮助都将不胜感激！或者任何人知道任何解释它的优秀 YouTube 视频，这也会有所帮助。    提交人    /u/BerryLizard   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehws26/d_understanding_bytenet_architecture/</guid>
      <pubDate>Fri, 02 Aug 2024 00:44:54 GMT</pubDate>
    </item>
    <item>
      <title>[D] 长上下文文本分类</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehw2zt/d_longcontext_text_classification/</link>
      <description><![CDATA[据我所知，DeBERTa v3 large 通常是文本分类中性能最强的 BERT 类模型，但它被限制为 24,528 个标记（这很多，但在某些情况下可能不足以满足我的用例）。有人对比这更长的序列的 SOTA 模型/方法有经验/建议吗？    提交人    /u/sanest-redditor   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehw2zt/d_longcontext_text_classification/</guid>
      <pubDate>Fri, 02 Aug 2024 00:11:46 GMT</pubDate>
    </item>
    <item>
      <title>[D] 有没有什么好的可微调的 TTS？（不是 Coqui 或 TorToiSe）</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehw1nf/d_any_good_finetunable_tts_not_coqui_or_tortoise/</link>
      <description><![CDATA[大家好！我有一个非常感性的数据集，里面有大约 20-30 分钟的清晰的英语语音录音。我想制作一个微调模型来完全复制该声音，并且能够在没有 CUDA 的情况下仅使用 MPS 进行推理。除了 Coqui 和 TorToiSe（它们不适用于高音调数据）之外，还有什么想法以及好的分步文档吗？    提交人    /u/yukiarimo   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehw1nf/d_any_good_finetunable_tts_not_coqui_or_tortoise/</guid>
      <pubDate>Fri, 02 Aug 2024 00:10:06 GMT</pubDate>
    </item>
    <item>
      <title>特征提取[P]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehuw5z/features_extraction_p/</link>
      <description><![CDATA[嗨 r/MachineLearning ， 我正在开展一个数据科学项目，该项目专注于识别与土著相关的数据，我可以使用社区的一些意见。 主要目标是在数据中找到表明信息与土著人民相关的特征，重点是环境和生物多样性数据。这将使我们能够识别与土著社区相关的互联网数据，但这些数据并未明确标记。通过发现这些以前未被识别的与土著相关的数据，我们可以将利益共享实践扩展到这些社区。 我从头开始；我仍然需要找到相关的可用数据集。我正在考虑使用聚类来识别相关参数。但是，我怀疑我需要大量优质数据才能实现有意义的目标。 是否可以使用已经在大量数据上训练过的 LLM（开源或通过 API），并将其用于根据我的需求量身定制的适当迁移学习方法？我愿意接受任何建议，并且真的很好奇人们能提出什么想法。    提交人    /u/Miserable-Ad5138   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehuw5z/features_extraction_p/</guid>
      <pubDate>Thu, 01 Aug 2024 23:17:58 GMT</pubDate>
    </item>
    <item>
      <title>[D] 在专注于 LLM 的初创公司工作值得吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehudwq/d_is_it_worth_working_at_startups_focusing_on_llm/</link>
      <description><![CDATA[一些正在开发 LLM 产品的初创公司的 HR 找到了我。根据我们的讨论，他们仍然主要将流行的开放 AI 模型或开源模型 (llama3) 用于他们的 LLM 产品（这并不奇怪），我认为工程师将主要做的事情是快速工程和/或微调。我对 LLM 非常感兴趣，我相信这是一个相当突出的未来（如果我错了，请纠正我），但是我不确定如果我在使用这些模型的初创公司工作，我能在 LLM 领域达到多大的深度，可能只有快速工程和微调技术？在这些初创公司工作是否会让我在直接申请这些大型模型公司（Meta、Google、Open AI 等）的 LLM 职位时更有竞争力？ 我想在 LLM 领域获得更多知识，但我不知道在只使用带有 API 调用的 LLM 模型的公司工作是否是一个好的起点。任何建议都值得赞赏！    提交人    /u/Upbeat-Carrot1999   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehudwq/d_is_it_worth_working_at_startups_focusing_on_llm/</guid>
      <pubDate>Thu, 01 Aug 2024 22:55:27 GMT</pubDate>
    </item>
    <item>
      <title>[D] 用于随机内容生成的 Transformer 采样技术</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ehrw4r/d_transformer_sampling_techniques_for_random/</link>
      <description><![CDATA[我正在做一个项目，在这个项目中，给定一个（相对较小的）转换器，我们希望能够生成独特的句子。也就是说，没有输入提示或任何条件。从 0 个 token 开始，我们希望能够生成新颖的句子。 我遇到的问题是，当我们使用传统的采样技术（例如 TopK/TopP）时，它往往会“崩溃”在一些想法上。由于前几个 token 可能只会落入少数几个最佳可能性中，这往往会限制剩余生成的新颖性。 关于如何处理这个问题有什么建议吗？我们正在研究模型训练技术 + 数据处理方面的其他选择，但我认为在采样方面可能会有一些“速胜”。    提交人    /u/leoholt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ehrw4r/d_transformer_sampling_techniques_for_random/</guid>
      <pubDate>Thu, 01 Aug 2024 21:08:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 还有人觉得 LLM 没什么意思吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1eh4llh/d_llms_arent_interesting_anyone_else/</link>
      <description><![CDATA[我不是 ML 研究员。当我想到很酷的 ML 研究时，我想到的是 OpenAI Five 或 AlphaFold 之类的东西。如今，人们热议的是 LLM 和扩展转换器，虽然该领域确实有一些研究和优化要做，但它对我来说并不像其他领域那么有趣。对我来说，ML 的有趣部分是为您的用例端到端训练模型，但如今的 SOTA LLM 可以用于处理许多用例。好的数据 + 大量的计算 = 不错的模型。就这样？ 如果我可以用一小部分计算来训练这些模型，我可能会更感兴趣，但这样做是不合理的。那些没有计算能力的人只能进行微调或快速工程，而我内心的 SWE 发现这很无聊。这个领域的大多数人真的把精力投入到下一个标记预测器中了吗？ 显然，LLM 具有颠覆性，并且已经发生了很大的变化，但从研究的角度来看，它们对我来说并不有趣。还有人有这种感觉吗？对于那些因为与 LLM 无关的东西而被该领域吸引的人，你对此有何感想？你是否希望 LLM 的炒作会逐渐消退，以便焦点可以转移到其他研究上？那些在当前趋势之外进行研究的人：你如何处理所有的噪音？    提交人    /u/leetcodeoverlord   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1eh4llh/d_llms_arent_interesting_anyone_else/</guid>
      <pubDate>Thu, 01 Aug 2024 01:40:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1egc1um/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Wed, 31 Jul 2024 02:30:25 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励创建新帖子提问的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1ee9dra/d_simple_questions_thread/</guid>
      <pubDate>Sun, 28 Jul 2024 15:00:14 GMT</pubDate>
    </item>
    </channel>
</rss>