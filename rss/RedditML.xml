<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>机器学习</title>
    <link>https://www.reddit.com/r/MachineLearning/</link>
    <description>初学者 -> /r/mlquestions，AGI -> /r/singularity，职业建议 -> /r/cscareerquestions，数据集 -> r/datasets</description>
    <lastBuildDate>Mon, 30 Dec 2024 15:16:46 GMT</lastBuildDate>
    <item>
      <title>[P] 介绍 LongTalk-CoT v0.1：用于推理模型后训练的超长思维链数据集</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpp8ph/p_introducing_longtalkcot_v01_a_very_long/</link>
      <description><![CDATA[我很高兴发布LongTalk-CoT v0.1，这是一个专为后期训练 o1 类推理模型设计的数据集。每个响应都使用 QwQ-32B-Preview 提示，特别是手工制作的系统消息，鼓励更多发声思考和自我反思。  训练后数据集包含97M 个标记（使用 meta-llama/Llama-3.1-8B-Instruct 标记器）。 输出标记长度比 HuggingFaceTB/smoltalk 🤔💭长 5.29 倍 提升ProcessBench中的性能可用于 SFT 和 RL /偏好优化 微调模型能够解决 9.11 是否大于 9.9 以及草莓单词中有多少个字母 R！     由    /u/transformer_ML 提交   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpp8ph/p_introducing_longtalkcot_v01_a_very_long/</guid>
      <pubDate>Mon, 30 Dec 2024 15:11:04 GMT</pubDate>
    </item>
    <item>
      <title>[D]- 在线还是本地助手？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpoos6/d_online_or_local_assistant/</link>
      <description><![CDATA[因此，我想尝试在我的手机（poco x6 pro，12GB RAM）上运行本地 llm 作为我可以与之交谈的助手，但经过一番争论和在线搜索后，我不确定它是否比在线代理更值得。 比如，似乎在线的可以做更多的事情，速度更快，但不依赖于网络访问和数据隐私是本地的一大优势。（尽管我仍在寻找一个精简版的实时 TTS。如果你知道任何好的，请告诉我😆） 有人尝试过吗，你的体验如何？    提交人    /u/mousio   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpoos6/d_online_or_local_assistant/</guid>
      <pubDate>Mon, 30 Dec 2024 14:44:56 GMT</pubDate>
    </item>
    <item>
      <title>[讨论] 使用 LLM 与您的推荐系统进行讨论。</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpo6y9/discussion_talk_to_your_recommendation_system/</link>
      <description><![CDATA[LLM 能否帮助我们向推荐系统提出我们的需求： 大型语言模型 (LLM) 与推荐系统的交集代表了机器学习研究的一个令人兴奋的前沿。虽然传统的推荐系统擅长模式匹配和协同过滤，但它们往往难以细致地理解用户上下文，也难以进行自然对话。通过将 LLM 集成为推荐系统的智能接口，我们可以解决这些限制，同时保留使推荐系统有效的强大算法基础。 考虑这样一个场景：用户表达：“我是一个 50 岁的中国人，住在芬兰，喜欢园艺。”如果没有明确的特征工程，传统的推荐系统将很难解析这种丰富的上下文信息。然而，LLM 可以自然地提取多个相关维度：文化背景、地理限制、气候因素以及基于年龄的潜在身体能力。这种自然语言理解层将非结构化的人工输入转换为可以增强推荐管道的结构化特征。 这种混合方法的真正威力在于它能够弥合用户意图和系统功能之间的语义鸿沟。LLM 擅长理解用户可能未明确说明的隐式约束和偏好。例如，系统可以推断芬兰的中国园丁可能对中国传统植物的耐寒品种感兴趣，或者对将亚洲园艺实践适应北欧条件的技术感兴趣。仅使用传统的推荐架构很难实现这种级别的上下文推理。 使用 Chatgpt 进行橡皮鸭练习的其他示例。  “我是一名 35 岁的孕妇，患有 1 型糖尿病，住在蒙大拿州农村。我是一名护士，上夜班，需要适合我的时间表和身体状况的锻炼建议。我也遵循犹太饮食习惯。” “我是一名巴西软件工程师，拥有 8 年 Java 经验，目前居住在柏林。我有兴趣转向 AI 开发，但需要根据我的阅读障碍和注意力缺陷多动障碍 (ADHD) 来安排我的学习。我的公司主要使用德语文档。” “我们是多伦多的一个韩裔墨西哥混血家庭，有三个孩子（分别为 4 岁、8 岁和 13 岁）。正在寻找有助于维持两国文化联系的周末活动。我们最小的孩子患有自闭症，对噪音很敏感。” “我是一名来自印度的 45 岁自由艺术家，现居住在新西兰。我使用多种货币赚钱，在印度有一个受赡养的父母，并且对符合我的印度教价值观的可持续投资感兴趣。我还有美元学生贷款。” “我是一名来自日本、现居冰岛的聋哑摄影师。我专攻极光摄影，希望拓展到野生动物摄影领域。我使用轮椅，需要建议可进入的地点和专用设备。” “我是新加坡的一名穆斯林家庭教育家长，有三个 12 岁的小孩，他们数学天赋异禀。一个患有注意力缺陷多动障碍，另一个是色盲，第三个是游泳健将。需要课程建议，既能适应三个孩子，又能保留他们的伊斯兰价值观。”     提交人    /u/Maleficent-Scene7771   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpo6y9/discussion_talk_to_your_recommendation_system/</guid>
      <pubDate>Mon, 30 Dec 2024 14:20:04 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 适合用于基于文本到文本的应用程序的 LLM 是什么？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpnt5h/d_which_llm_to_use_for_text_to_text_based/</link>
      <description><![CDATA[所以我正在从事这个小项目（也有一些资金）。问题是我有一个数据集（用户提供）并且我正在使用它根据查询检索信息。现在我有矢量数据库和用户提供的上下文，并想将其提供给 LLM 以用自然语言回复用户，什么付费或免费模型可以有效地完成这项工作并给我一个合适的回应。我尝试过使用 HuggingFace 上提供的 gpt2，但我对响应不太满意，它不理解上下文并使用它来构建答案。所以想找一个更好的模型，它有一个相当大的上下文窗口并且可以扩展。我应该尝试什么???    提交人    /u/randombro420   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpnt5h/d_which_llm_to_use_for_text_to_text_based/</guid>
      <pubDate>Mon, 30 Dec 2024 14:00:50 GMT</pubDate>
    </item>
    <item>
      <title>[D] 叙述数据（故事）可以存储为知识图谱吗？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpiu23/d_can_narrative_data_stories_be_stored_as/</link>
      <description><![CDATA[这是在将故事存储为 RAG 问答的 KG 的背景下。 KG 在存储本体/关系数据和查询事实数据方面非常出色。但如何在不丢失大量信息的情况下将叙述数据存储在知识图谱中？首先，故事中有一个时间维度，关系会随着故事的发展而发生变化（一个人可能在第 1 章停留在位置 A，而在第 2 章移动到位置 B）。 这个https://www.youtube.com/watch?v=g6xBklAIrsA有一些想法，但并没有真正涉及问题。    提交人    /u/noellarkin   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpiu23/d_can_narrative_data_stories_be_stored_as/</guid>
      <pubDate>Mon, 30 Dec 2024 08:32:36 GMT</pubDate>
    </item>
    <item>
      <title>[D] 这是什么样的学习？这种学习有哪些不同的训练范式？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hphaqy/d_what_kind_of_learning_this_is_what_are/</link>
      <description><![CDATA[我心中有一个堆叠（或元）模型设置。 https://imgur.com/a/AJhI2vS 模型 A 是一个物理信息神经网络，它处理一组特定的输入并给出一组输出，这些输出是模型 B（时间卷积网络）接收的输入的一部分。 在模型 B 输出时（参见红线），我们将损失分别传递给模型 A 和 B，而且模型 A 等待模型 B 的反向传播，因此模型 A 也可以将自己的损失传递给模型 A，然后模型 A 进行反向传播。 与此类似的设置和训练范例在文献中有哪些可能的类型？此外，如果它是新颖的，如何实现这一点？这将如何运作？     提交人    /u/AngleStrange6693   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hphaqy/d_what_kind_of_learning_this_is_what_are/</guid>
      <pubDate>Mon, 30 Dec 2024 06:46:03 GMT</pubDate>
    </item>
    <item>
      <title>[D] - 为何 MAMBA 没有流行起来？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hpg91o/d_why_mamba_did_not_catch_on/</link>
      <description><![CDATA[从所有的炒作来看，MAMBA 似乎将取代 transformer。它速度很快，但仍保持了 transformer 的性能。训练期间为 O(N)，推理期间为 O(1)，并且准确率相当高。那么为什么它没有占据主导地位呢？状态空间模型的状态是什么？    提交人    /u/TwoSunnySideUp   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hpg91o/d_why_mamba_did_not_catch_on/</guid>
      <pubDate>Mon, 30 Dec 2024 05:39:42 GMT</pubDate>
    </item>
    <item>
      <title>[R]几何直觉为什么 L1 将系数驱动为零</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp7us9/rgeometric_intuition_why_l1_drives_the/</link>
      <description><![CDATA[  由    /u/madiyar  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp7us9/rgeometric_intuition_why_l1_drives_the/</guid>
      <pubDate>Sun, 29 Dec 2024 22:34:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 关于在单个 H100 GPU 上 100 个 epoch 内实现 Imagnet 上 >=80% 准确率的建议</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp4hph/d_advice_on_achieving_80_accuracy_on_imagnet_in/</link>
      <description><![CDATA[大家好！ 我目前正在尝试在单个 H100 GPU 上从头开始训练 ImageNet1K 上的 EfficientNetV2-medium 模型。由于 GPU 在我的实验室同事之间共享，因此每个 epoch 的训练时间非常慢。因此，我将训练 epoch 的数量限制为 100。鉴于这些限制，我想听听您的建议，关于如何才能获得超过 80% 的 top1 分数？ 根据我目前的配置，我可以达到 78%。以下是我的训练细节： 批次大小：256 学习率：0.1 优化器：动量为 0.9 的 SGD 权重衰减：2x10-5 学习率调度程序：余弦增强：TrivialAugmentWide、RandomCrop(8) 混合精度训练 (bf16) 深度学习库：Pytorch Lightning 我还应用了动态调整大小，其中我的训练和测试图像从 128x128 的大小开始，每 20 个 epoch 增加 24 个像素，直到第 80 个 epoch，图像大小固定为 224x224。 如果您能提供任何关于如何提高我的分数的见解，以及是否有可能进一步减少训练时间，我将不胜感激。 谢谢！    由    /u/atif_hassan  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp4hph/d_advice_on_achieving_80_accuracy_on_imagnet_in/</guid>
      <pubDate>Sun, 29 Dec 2024 20:05:55 GMT</pubDate>
    </item>
    <item>
      <title>[D] 我们如何才能善用机器学习？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hp0m3o/d_how_can_we_use_ml_for_good/</link>
      <description><![CDATA[您好，我即将完成我的学士学位，我真的想利用我学到的关于机器学习和数据工程的知识来帮助人们，我有一些之前的经验，但如果我们可以与一些初创公司合作，分享我们关于机器学习和工程的知识并真正创造价值，那就太好了。 你知道一些初创公司或非政府组织利用他们的数据技能来帮助人们或促进创新吗？ 我们如何使用我们的技能来帮助别人？ 我一直在想，为小型企业设置基本的数据基础设施，然后使用机器学习算法帮助他们提高生产力会很好，但我不知道从哪里开始。    提交人    /u/Southern_Respond846   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hp0m3o/d_how_can_we_use_ml_for_good/</guid>
      <pubDate>Sun, 29 Dec 2024 17:16:03 GMT</pubDate>
    </item>
    <item>
      <title>[P] 我制作了 Termite，一个可以通过简单的文本提示生成终端 UI 的 CLI</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyzao/p_i_made_termite_a_cli_that_can_generate_terminal/</link>
      <description><![CDATA[        提交人    /u/jsonathan   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyzao/p_i_made_termite_a_cli_that_can_generate_terminal/</guid>
      <pubDate>Sun, 29 Dec 2024 16:02:40 GMT</pubDate>
    </item>
    <item>
      <title>[D] 简单问题主题</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</link>
      <description><![CDATA[请在此处发布您的问题，而不是创建新帖子。鼓励其他创建新帖子的人在此处发布问题！ 帖子将保持活跃，直到下一个帖子，因此请在标题中的日期之后继续发帖。 感谢大家在上一个帖子中回答问题！    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoyxhm/d_simple_questions_thread/</guid>
      <pubDate>Sun, 29 Dec 2024 16:00:31 GMT</pubDate>
    </item>
    <item>
      <title>[D] 批量标准化及其对梯度的影响</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hoy9zk/d_batch_normalization_and_effect_on_the_gradients/</link>
      <description><![CDATA[我最近在读这篇论文：https://arxiv.org/pdf/1706.05350，我想了解作者是如何得出梯度与权重成反比这一事实的。这是第 3 页上的第一个等式。如果有人能给我提示或解释，我将不胜感激。    提交人    /u/Numerous_Talk7940   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hoy9zk/d_batch_normalization_and_effect_on_the_gradients/</guid>
      <pubDate>Sun, 29 Dec 2024 15:29:22 GMT</pubDate>
    </item>
    <item>
      <title>[P] 使用 ARIMA/SARIMA 进行风速预测</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1hou9cq/p_wind_speed_prediction_with_arimasarima/</link>
      <description><![CDATA[      我正在做一个风速预测的项目。有些文章说使用 ARIMA / SARIMA 会是一个好的开始。 我确实开始使用 ARIMA，并且预测值没有任何变化。 当我尝试使用 SARIMA，季节性 = 12（一年中的月份），预测 36 个月（3 年）时，它给了我不满意的结果，这些结果看起来每年都一样（周期性的，因此远离现实）所以我放弃了 SARIMA。 请随时给我解决方案或更好的方法。    提交人    /u/Associate-Existing   [链接] [评论] ]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1hou9cq/p_wind_speed_prediction_with_arimasarima/</guid>
      <pubDate>Sun, 29 Dec 2024 11:33:42 GMT</pubDate>
    </item>
    <item>
      <title>[D] 每月谁在招聘以及谁想被招聘？</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</link>
      <description><![CDATA[对于职位发布，请使用此模板  招聘：[地点]，薪资：[]，[远程 | 搬迁]，[全职 | 合同 | 兼职]和[简要概述，您在寻找什么]  对于那些正在找工作的人，请使用此模板  希望被雇用：[地点]，薪资期望：[]，[远程 | 搬迁]，[全职 | 合同 |兼职] 简历：[简历链接] 和 [简要概述，您在寻找什么]  ​ 请记住，这个社区面向有经验的人。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/MachineLearning/comments/1h3u444/d_monthly_whos_hiring_and_who_wants_to_be_hired/</guid>
      <pubDate>Sun, 01 Dec 2024 03:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>