<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 27 Nov 2024 03:32:21 GMT</lastBuildDate>
    <item>
      <title>Ngram 模型背后的概率分布</title>
      <link>https://stats.stackexchange.com/questions/657910/probability-distribution-underlying-ngram-model</link>
      <description><![CDATA[介绍 ngram 模型的文本通常直接操纵条件概率。例如，给定一个语料库 $V$，其单词具有二元模型，我们将计算句子 $W_1 W_2 ... W_n$ 的概率，如下所示：
\begin{equation}
\begin{split}
P(W_1W_2...W_n) &amp;= P(W_1)P(W_2|W_1)P(W_3|W_1W_2)...P(W_n|W_1...W_{n-1}) \\
&amp;\approx P(W_1)P(W_2|W_1)P(W_3|W_2)...P(W_n|W_{n-1})
\end{split}
\end{equation&gt;
那么，大多数文本会将 $P(W_a|W_b)$ 计算为 $COUNT(W_aW_b)/COUNT(W_b)$，并且它们会通过简单地使用起始标记 $P(W_1) = P(W_1|\text{&lt;s&gt;})$ 来绕过 $P(W_1)$ 的边际概率计算。
但是，这种模型背后的实际概率分布是什么？我们实际上如何计算边际概率 $P(W)$？当我们谈到“一个句子的概率”时，它是否与语料库中所有单词组合形成的所有可能句子的概率进行比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/657910/probability-distribution-underlying-ngram-model</guid>
      <pubDate>Wed, 27 Nov 2024 02:04:47 GMT</pubDate>
    </item>
    <item>
      <title>结果难以辨别的多项式回归模型</title>
      <link>https://stats.stackexchange.com/questions/657909/multinomial-like-regression-model-with-indiscernible-outcomes</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657909/multinomial-like-regression-model-with-indiscernible-outcomes</guid>
      <pubDate>Wed, 27 Nov 2024 01:58:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们通常不担心具有固定效应的面板数据模型中的平稳性？</title>
      <link>https://stats.stackexchange.com/questions/657907/why-dont-we-typically-worry-about-stationarity-in-panel-data-models-with-fixed</link>
      <description><![CDATA[为什么我们通常不担心具有固定效应的面板数据模型中的平稳性？
在时间序列分析中，平稳性通常是一个关键假设。然而，我注意到，在面板数据的应用微观计量经济学中，研究人员似乎不太关心变量$y_{it}$和$x_{it}$是否是平稳的。
考虑一个典型的固定效应模型：
$$y_{it} = \alpha_i + \alpha_t + \sum_{l=1}^L \beta_l x_{i,t-l} + \epsilon_{it}$$
在这种情况下，我们似乎常常不关心：

$y_{it}$是否满足传统的平稳性假设

协方差结构$Cov(y_{it}, y_{i,t+k})$是时不变的

条件期望$E[y_{it}|\alpha_i,\alpha_t]$
与 $t$ 无关


这与 VAR 文献形成鲜明对比，在 VAR 文献中平稳性起着核心作用。
为什么我们经常可以在面板数据环境中忽略平稳性？
拥有较大的 $N$（横截面单位）是否会使平稳性变得不那么重要？
有人可以提供直观的解释，如果可能的话，提供一些数学推理？我熟悉基本的面板数据方法和时间序列概念，但我试图理解这两个领域对平稳性的处理之间的具体区别。]]></description>
      <guid>https://stats.stackexchange.com/questions/657907/why-dont-we-typically-worry-about-stationarity-in-panel-data-models-with-fixed</guid>
      <pubDate>Wed, 27 Nov 2024 00:13:54 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在处理一个重复测量数据集，需要进行降维。在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法包括以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除“物种”变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不平等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    <item>
      <title>处理格兰杰因果关系中的非平稳时间序列</title>
      <link>https://stats.stackexchange.com/questions/657899/dealing-with-non-stationary-time-series-in-granger-causality</link>
      <description><![CDATA[我正在努力确定两个时间序列的 Granger 因果关系。
需要注意的一点是，对于我的具体项目，我有大约 100k 个时间序列，涉及两个不同的维度，例如产品名称和销售类型，我正在尝试确定不同的销售类型是否会对一种特定的销售类型造成 Granger 影响。
到目前为止，在我进行的分析中，我通过采用指数移动平均线来平滑时间序列，然后通过查看指数移动平均线的逐日变化对其进行归一化。我将查看每个产品名称的不同销售类型的指数移动平均线逐日变化的 Granger 因果关系。
从理论上讲，我相信逐日变化已经是一种差异形式，因此大概这应该会迫使时间序列保持平稳。话虽如此，我已经运行了 ADF 测试，大约 10% 的时间序列是非平稳的，阈值为 0.05。
我想知道如何继续，因为我不想通过另一轮标准化来过多地改变解释。出现了两个问题：

可以丢弃所有非平稳时间序列吗？
由于指数移动平均线将自相关引入序列，这可能是我的序列非平稳的原因吗？

请原谅我在这方面的无知，我只是想迈出合理的下一步。]]></description>
      <guid>https://stats.stackexchange.com/questions/657899/dealing-with-non-stationary-time-series-in-granger-causality</guid>
      <pubDate>Tue, 26 Nov 2024 20:29:56 GMT</pubDate>
    </item>
    <item>
      <title>如何制作一个能够抵御数据不平衡变化的分类器？</title>
      <link>https://stats.stackexchange.com/questions/657898/how-do-i-make-a-classifier-thats-robust-to-variation-in-data-imbalance</link>
      <description><![CDATA[我正在为通常非常不平衡的数据编写一个二元分类器，例如大多数类别中 99% 的数据（使用梯度提升），但我希望有一个分类器至少对不平衡的严重程度具有一定的鲁棒性。一个数据集与另一个数据集之间的不平衡率差异很大。A 类分数可能 &gt;99% 或低至 75%。理想情况下，我希望在单个训练集上训练我的分类器，然后让它在类别频率差异很大的测试集上表现得相当好。有没有既定的方法可以做到这一点？或者我只需要根据预期的不平衡程度为每个新数据集重新训练模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/657898/how-do-i-make-a-classifier-thats-robust-to-variation-in-data-imbalance</guid>
      <pubDate>Tue, 26 Nov 2024 20:26:32 GMT</pubDate>
    </item>
    <item>
      <title>可能性只是达到目的的一种手段吗？（贝叶斯推理）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657896/is-likelihood-just-a-means-to-an-end-in-bayesian-inference</link>
      <description><![CDATA[我知道教科书上的答案是否定的。但无论如何，我提出这个问题有两个原因：

可能性最明显的动机是，没有可能性，后验就没有意义。如果模型产生的是点预测而不是输出分布，您就无法询问某些参数 $\theta$ 生成数据集的概率（即 $P(D|\theta)$）。答案永远是 0 或 1（实际上大多只是 0）。
无可能性贝叶斯推理 将可能性视为更广泛应用贝叶斯推理的障碍，因此它试图避免它。而是依赖误差/残差。

P.S. 这也只是一个粗略的观察：我已经告诉了很多同事如何在回归的 VI 中正确实现随机不确定性，但他们似乎对认知不确定性不太感兴趣……]]></description>
      <guid>https://stats.stackexchange.com/questions/657896/is-likelihood-just-a-means-to-an-end-in-bayesian-inference</guid>
      <pubDate>Tue, 26 Nov 2024 19:18:26 GMT</pubDate>
    </item>
    <item>
      <title>自举法作为基于模拟的功效/样本量计算的替代方案</title>
      <link>https://stats.stackexchange.com/questions/657895/bootstrapping-as-an-alternative-to-simulation-based-power-sample-size-calculatio</link>
      <description><![CDATA[通常，当需要进行样本量和/或计算时，他们可能会使用教科书中的简单样本量计算或使用 gpower。但是，只有非常基本的程序才有闭式计算。对于复杂的分析，它将要求用户模拟数据以计算估计的功率/样本量。模拟数据的问题是获取正确的信息以使模拟变得逼真。您将必须获得斜率、截距、标准误差等的估计值。此外，如果您对这些内容的估计有误，则会导致样本量计算错误。这是一项艰巨的任务。
现在，假设有人有试验数据。在我看来，与其猜测斜率/截距/标准误差，不如从试验数据中进行引导，作为计算功率/样本量的替代方法。以前有人这样做过吗？如果不是，那么这是不是一个好主意的原因是什么？
当然，如果试点数据不能代表总体，就会出现明显的问题，尽管我认为这可以通过某种 MCMC 程序来克服。
编辑：我有一个重大疏忽。使用此程序不允许您计算功效，因为您不知道实际的总体值。所以也许我会修改我的问题，询问使用试点数据进行样本量计算的理想方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/657895/bootstrapping-as-an-alternative-to-simulation-based-power-sample-size-calculatio</guid>
      <pubDate>Tue, 26 Nov 2024 18:58:17 GMT</pubDate>
    </item>
    <item>
      <title>弹性净惩罚分位数回归模型效果不佳的原因及解决方法</title>
      <link>https://stats.stackexchange.com/questions/657894/reasons-and-potential-solutions-for-poor-performance-of-elastic-net-penalized-qu</link>
      <description><![CDATA[我正在使用 rqPen 包对我的数据集执行弹性净惩罚分位数回归 (EN-QR)，该数据集有 6,782 行和 227 列（即预测因子）。其中 195 个预测因子是代谢物，我的目标是找出哪些代谢物与接触空气污染物 PM2.5 有关。我选择执行 QR 而不是线性回归，因为 PM2.5 数据存在偏差且不呈正态分布，即使在执行对数转换和标准化之后也是如此。我将数据集按 70:30 的比例分为训练集 (n = 4,747) 和测试集 (n = 2,035)。
我遇到的问题是，当我将训练集中的 EN-QR 对象应用于测试集以预测 PM2.5 值（下图）时，我得到了一个奇怪的多峰分布，它与测试集中的实际 PM2.5 值（上图）不符。我已在下面附上这些分布的屏幕截图。

我想知道是否有人对此有解决问题的建议。有哪些潜在原因会导致模型分裂成多峰分布而不是（近似）正态分布？是否有我没有考虑纳入训练集模型的内容？是否有其他策略可以让我实现变量选择的目标？理想情况下，我希望 EN-QR 模型能够发挥作用，因为它为我的研究问题提供了最多的信息。
我尝试根据数据属于多峰分布的哪个模式将数据分成四个集群。我发现美国人口普查区域与预测的 PM2.5 值的模式之间存在关系。例如，几乎所有 z 得分最低的模式中的人员都来自南部，而几乎所有 z 得分最高的模式中的人员都来自中西部。我发现这很奇怪，因为美国人口普查区域被作为协变量纳入，因此模型不应该按地区分层。我在下面附上了这张图片和表格。

这是我用来在训练集上执行 EN-QR 的 R 代码。下面是我用来预测测试集中 PM2.5 值的代码。
trainingset.ENQR &lt;- rq.pen.cv(
x = as.matrix(trainingset[, c(4:5, 27, 29:251)]),
y = trainingset[, 18],
tau = c(0.1, 0.5, 0.9),
penalty = &quot;ENet&quot;,
a = c(0.50, 0.75, 0.90),
nfolds = 10,
printProgress = TRUE,
penalty.factor = c(rep(0, 32), rep(1, 194))
)

lambda.min.training &lt;- trainingset.ENQR$gtr$lambda1se[2]

testingset.ENQR.50 &lt;- rqPen:::predict.rq.pen.seq.cv(object = trainingset.ENQR,
newx = as.matrix(testingset[, c(4:5, 27, 29:251)]),
tau = 0.50,
a = 0.50,
lambda = lambda.min.training,
cvmin = FALSE)
]]></description>
      <guid>https://stats.stackexchange.com/questions/657894/reasons-and-potential-solutions-for-poor-performance-of-elastic-net-penalized-qu</guid>
      <pubDate>Tue, 26 Nov 2024 18:49:07 GMT</pubDate>
    </item>
    <item>
      <title>对于 PLS 模型拟合，如何计算 R2VX、R2VY 以及累积 R2VX、R2VY？</title>
      <link>https://stats.stackexchange.com/questions/657880/for-a-pls-model-fit-how-can-i-calculate-r2vx-r2vy-and-the-cumulative-r2vx-r2</link>
      <description><![CDATA[根据Eriksson等人2013年出版的《多变量和巨变量数据分析基本原理与应用》一书，PLS模型性能的重要指标包括$R2VX$和$R2VY$，其文本定义为“X/Y变量变异的解释分数”数学上为：
$$ 
R2VX = 1 - \frac{ \Sigma_i e_{i,k}^2 } { \Sigma_i e_{i,0}^2 }
$$
其中 $e_{i,k}$ 表示 $k$ 分量模型的 $i$ 个 X 残差。
类似地，
$$ 
R2VY = 1 - \frac{ \Sigma_i f_{i,k}^2 } { \Sigma_i f_{i,0}^2 }
$$
其中$f_{i,k}$ 表示 $k$ 个组件模型的 $i$ 个 Y 残差。
我想出了以下代码来计算 $R2VY$：
library(pls)

fit = plsr(hp ~ ., 
segments = 10,
scale=T, 
center=T,
validation = &quot;CV&quot;,
method = &quot;simpls&quot;,
data=mtcars)

## 对于组件 1
R2VX = 1 - sum(residuals(fit)[,,1]^2)/sum((mtcars$hp - mean(mtcars$hp))^2)
R2VX 

# 与 R2() 函数的结果匹配
R2(fit)

但是，我不清楚应该如何计算 $R2VX$。我甚至不确定如何提取 X 变量的残差。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657880/for-a-pls-model-fit-how-can-i-calculate-r2vx-r2vy-and-the-cumulative-r2vx-r2</guid>
      <pubDate>Tue, 26 Nov 2024 15:42:27 GMT</pubDate>
    </item>
    <item>
      <title>多元正态分布之间的柯西-施瓦茨散度</title>
      <link>https://stats.stackexchange.com/questions/657879/cauchy-schwarz-divergence-between-multivariate-normal-distributions</link>
      <description><![CDATA[我试图使用本文中正态分布混合之间的柯西-施瓦茨散度的推导来推导两个多元正态分布之间的柯西-施瓦茨散度：CLOSED-FORM CAUCHY-SCHWARZ PDF DIVERGENCE FOR
MIXTURE OF GAUSSIANS by CLOSED-FORM CAUCHY-SCHWARZ PDF DIVERGENCE FOR
MIXTURE OF GAUSSIANS
Kittipat Kampa、Erion Hasanbelliu 和 Jose C. Principe
考虑$p(x) = \mathcal{N}(x|\mu,\Lambda^{-1})=\frac{|\Lambda|^{1/2}}{(2\pi)^{D/2}}\exp\Big(-\frac{1}{2}(x-\mu)^{\top}\Lambda(x-\mu)\Big)$ 和 $q(x) = \mathcal{N}(x|\nu,\Omega^{-1})=\frac{|\Omega|^{1/2}}{(2\pi)^{D/2}}\exp\Big(-\frac{1}{2}(x-\nu)^{\top}\Omega(x-\nu)\Big)$。
使用论文中的公式柯西-施瓦茨散度可以简化为：
\begin{align}
D_{CS}(p,q) &amp;=-\log\Big(\mathcal{N}\big(\mu|\nu,(\Lambda^{-1}+\Omega^{-1}\big)\Big) + \frac{1}{2}\log\Big(\frac{|\Lambda|^{1/2}}{(2\pi)^{D/2}}\Big) + \frac{1}{2}\log\Big(\frac{|\Omega|^{1/2}}{(2\pi)^{D/2}}\Big) \\
&amp;= -\log\Bigg(\frac{\big|\Lambda^{-1}+\Omega^{-1}\big|^{-1/2}}{(2\pi)^{D/2}}\Bigg) +\frac{1}{2}(\mu-\nu)^{\top}\big(\Lambda^{-1}+\Omega^{-1}\big)^{-1}(\mu-\nu) + \frac{1}{2}\log\Big(\frac{|\Lambda|^{1/2}}{(2\pi)^{D/2}}\Big) + \frac{1}{2}\log\Big(\frac{|\Omega|^{1/2}}{(2\pi)^{D/2}}\Big) \\
&amp;= \frac{1}{2}\log\Big(\big|\Lambda^{-1}+\Omega^{-1}\big|\Big) +\frac{1}{2}(\mu-\nu)^{\top}\big(\Lambda^{-1}+\Omega^{-1}\big)^{-1}(\mu-\nu) + \frac{1}{4}\log\big(|\Lambda|\big) + \frac{1}{4}\log\big(|\Omega|\big)
\end{align&gt;
但是，如果我将 $p$ 插入 $q$，我会得到：
\begin{align}
D_{CS}(p,p)= \frac{1}{2}\log\Big(\big|2\Lambda^{-1}\big|\Big) + \frac{1}{2}\log\big(|\Lambda|\big) = \frac{D}{2}\log(2) \neq0
\end{align&gt;
我哪里犯了错误？]]></description>
      <guid>https://stats.stackexchange.com/questions/657879/cauchy-schwarz-divergence-between-multivariate-normal-distributions</guid>
      <pubDate>Tue, 26 Nov 2024 15:19:24 GMT</pubDate>
    </item>
    <item>
      <title>正态性假设 - qqplot 解释</title>
      <link>https://stats.stackexchange.com/questions/657859/normality-assumption-qqplot-interpretation</link>
      <description><![CDATA[我目前正在从事一个涉及评估多个变量分布的项目，并且我正在使用 Q-Q 图作为分析的一部分。虽然我已经为这些变量生成了 Q-Q 图。确实，我已经研究这些很长时间了，但我仍然想在这里听取意见。这些变量的样本量接近 70，目的是在纵向分析的几个变量之间进行独立 t 检验。我可以提出，shapiro 和 ks-test 拒绝正态性假设。
如果您能指导我准确解释它们以评估正态性并识别任何偏离高斯分布的情况，我将不胜感激。这些生物标志物通常在尾部变得更重，但我不会进行转化。欢迎任何评论！


]]></description>
      <guid>https://stats.stackexchange.com/questions/657859/normality-assumption-qqplot-interpretation</guid>
      <pubDate>Tue, 26 Nov 2024 10:45:29 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中拟合已知和未知非线性形状的模型</title>
      <link>https://stats.stackexchange.com/questions/657902/fitting-models-with-known-and-unknown-nonlinear-shapes-in-r</link>
      <description><![CDATA[我正尝试使用 mgcv 在 R 中拟合一个假设检验模型。
响应 Y 被假设为 x1 和 x2 的线性函数。这是一个空间数据集，其某些结构我先验不知道，因此我另外添加了一个纬度和经度的平滑项。
到目前为止，我们有这个模型，以 R / mgcv 语法表示：
Y ~ x1 + x2 + s(Latitude, Longitude, k = someK, bs = &quot;tp&quot;)

我必须向这个模型添加另外 2 个项。第一个是饱和曲线，具有 2 个参数，形式如下：
beta1 * ( (x3 ^ beta2) - 1) / beta2)

其中 beta1 和 beta2 是要估计的参数，x3 是数据向量。下一个是过度分散参数/观察级随机效应，用于吸收残差方差。再次以 mgcv 术语表示：
s(obs, bs=&quot;re&quot;)

首先，我使用 nimble 编写了一个模型，其中代表了所有这些组件。我提到这一点只是为了解释这不是未来的选择。该模型没有收敛（或者收敛速度极慢），我认为采样器在决定将方差归因于何处（空间平滑或过度分散参数）时会遇到一些困难，即使有信息丰富的先验。好吧，那只是一厢情愿。
接下来，我尝试用非线性曲线拟合模型，没有空间平滑，并且 brms 中有过度分散项；但是，该模型应该以某种方式考虑空间结构。我似乎无法使用 brms 在非线性模型中写入平滑项。这是通过 bf 得到的非线性 brms 公式的结构：
bf(Y ~ b0 + b1*x1 + b2*x2 + b3*( (x3 ^ b4) - 1) / b4), b0 ~ (1|overdisp), b1 + b2 + b3 ~ 1, nl = T)

其中 b0 是全局截距，其中针对此平均值周围的每个观测值估计了一个额外的过度分散参数。但同样，我现在缺少未知形式和复杂性的空间结构。我尝试使用 mgcv 进行 GAM：
bam(Y ~ x1 + x2 + x3 + s(Latitude, Longitude, k = someK, bs = &quot;tp&quot;) + s(overdisp, bs=&quot;re&quot;), data = dat, ...)

此模型运行，产生合理的输出，并解释 99% 的偏差。一切都很好——只是我似乎无法为 x3 包含具有 2 个参数的非线性项。是否有某种方法可以做到这一点，而我在 mgcv 的文档中遗漏了？或者也许有一种方法可以在非线性 brms 模型中表达 GAM 项？或者是否存在一些理论/统计原因，说明我不应该像以前那样进行建模？]]></description>
      <guid>https://stats.stackexchange.com/questions/657902/fitting-models-with-known-and-unknown-nonlinear-shapes-in-r</guid>
      <pubDate>Tue, 26 Nov 2024 06:01:50 GMT</pubDate>
    </item>
    <item>
      <title>Beta 回归中的权重</title>
      <link>https://stats.stackexchange.com/questions/657808/weights-in-beta-regression</link>
      <description><![CDATA[我在 R 中使用 betareg 来评估覆盖时间百分比与年龄和性别等基线特征之间的关系。
结果测量是测试覆盖时间百分比 (PTC)：每个测试覆盖一名参与者 6 个月。如果参与者在研究期间进行了几次测试，则他们的总覆盖时间是所有覆盖时间 (TC) 的总和。PTC 是 TC 除以他们在研究中的总时间 (TT)。由于参与者之间的 TT 不同；范围从 6 个月到几年，我使用权重来更加强调那些在研究中时间较长的人。我检查了两个权重选项：第一个选项是 TT，第二个选项是 TT/SUM(TT)：对于每个参与者，他们的 TT 除以所有参与者的 TT 总和。因此，第二个选项本质上是第一个选项除以一个常数值 (SUM(TT))。
选项 1：
 调用：
betareg(formula = PTC ~ Sex + Age, data = Test, weights = 
Test$TT, link = &quot;logit&quot;)

标准化加权残差 2：
最小值 1Q 中位数 3Q 最大值 
-10.9333 -3.1518 -0.0751 4.8051 18.9835 

系数（带 logit 链接的均值模型）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -0.1771340 0.0281138 -6.301 2.96e-10 ***
性别女性 -0.0323812 0.0114639 -2.825 0.00473 ** 
年龄 0.0169218 0.0004632 36.532 &lt; 2e-16 ***

Phi 系数（带身份链接的精度模型）：
估计标准误差 z 值 Pr(&gt;|z|) 
(phi) 1.94438 0.01234 157.5 &lt;2e-16 ***
---
显著性代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1 &#39; &#39; 1 

估计量类型：ML（最大似然）
对数似然：4 Df 上的 1.267e+04
伪 R 平方：0.01633
迭代次数：17（BFGS）+ 1（Fisher 评分）

选项 2：
 调用：
betareg（公式 = PTC ~ Sex + Age，数据 = Test，权重 = 
Test$TT/T，链接 = &quot;logit&quot;)

标准化加权残差 2：
最小值 1Q 中位数 3Q 最大值 
-0.0548 -0.0158 -0.0004 0.0241 0.0952 

系数（带 logit 链接的均值模型）：
估计标准差误差 z 值 Pr(&gt;|z|)
（截距） -0.17713 5.60469 -0.032 0.975
性别女性 -0.03238 2.28541 -0.014 0.989
年龄 0.01692 0.09234 0.183 0.855

Phi 系数（具有身份链接的精度模型）：
估计标准差。误差 z 值 Pr(&gt;|z|)
(phi) 1.944 2.461 0.79 0.429

估计量类型：ML（最大似然）
对数似然：4 Df 上的 0.3188
伪 R 平方：0.01633
迭代次数：28（BFGS）+ 3（Fisher 评分）
警告消息：
在 betareg.fit(X, Y, Z, weights, offset, link, link.phi, type, 
control) 中：
未找到精度参数的有效起始值，改用 1 


为什么将权重乘以常数会导致结果如此不同？哪一个是正确的？
编辑：我现在明白重新调整权重、重新调整方差，因此也重新调整 p 值。我现在的问题是哪个选项是正确的？我应该标准化权重吗（选项 2）？]]></description>
      <guid>https://stats.stackexchange.com/questions/657808/weights-in-beta-regression</guid>
      <pubDate>Mon, 25 Nov 2024 15:03:37 GMT</pubDate>
    </item>
    <item>
      <title>Freeman-Tukey 变换发生率的反向变换（在 metafor 中）</title>
      <link>https://stats.stackexchange.com/questions/657703/back-transformation-of-freeman-tukey-transformed-incidence-rates-in-metafor</link>
      <description><![CDATA[问题描述
我正在使用 metafor 包对同一疾病的不同治疗方法的术后复发率进行荟萃分析，但我很难将估计的平均结果反向转换为原始比例，因为我们使用 Freeman-Tukey 变换后的发生率作为结果测量。
代码
使用以下公式将个体效应大小计算为 Freeman-Tukey 变换后的发生率：
 ies = escalc(measure = &quot;IRFT&quot;, add = 0, data = Data, xi = total.recurrences,
ti = time)

我们指定了一个三级模型来解释研究间和研究内的异质性，并将其拟合到我们不同的治疗组，以获得每个治疗组的汇总效应大小。
模型1：
 pes.sg = rma.mv(yi, vi, data = ies,
subset = treatment == &quot;插入子组&quot;, 
random = ~1 | study.id/es.id,
method = &quot;REML&quot;, test = &quot;t&quot;,dfs = &quot;contain&quot;, 
cvvc = TRUE) 

我们还对整个数据集使用了另一种多元回归参数化方法，将分组变量作为调节器，以获得与单独分析相同的结果。
模型 2：
 pes = rma.mv(yi, vi, 
random = list(~treatment|study.id, ~treatment|es.id), 
mods = ~0+treatment,
data = ies, 
method = &quot;REML&quot;, struct = &quot;DIAG&quot;, test = &quot;t&quot;,dfs = &quot;contain&quot;,
sparse = TRUE)

我们希望获得模型 1 的反向转换估计平均结果，或模型 2 的每个调节器治疗级别的反向转换估计平均结果。每个结果都有相应的置信区间和预测区间，因为我们希望报告原始量表上每个治疗组的估计平均发生率（及其 CI 和 PI），以使我们的结果易于解释。
方程式
根据文档，发生率$ r_i $由escalc计算，其中$ r_i=c_i/t_i $，其中$ c_i $ 和 $ t_i $ 分别表示事件计数和患者时间。
然后使用以下代码对个体发生率进行 Freeman-Tukey 变换：
$$
y_i=1/2(\sqrt{r_i} + \sqrt{r_i+1/t_i})
$$
在 transf.iirft 中，使用以下代码实现个体发生率的反向变换：
$$
r_i = \frac {1/t_i - 8 y_i^2 + 16 t_i y_i^4}{16 y_i^2 t_i}
$$
我的问题是：

是否可以按预期将估计的平均发生率、CI 和 PI 反向变换为原始比例？
如果可以，您将如何计算反向变换，以及哪种方法信息/需要哪些值才能做到这一点？

我很感激有关这个主题的任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/657703/back-transformation-of-freeman-tukey-transformed-incidence-rates-in-metafor</guid>
      <pubDate>Fri, 22 Nov 2024 22:28:48 GMT</pubDate>
    </item>
    </channel>
</rss>