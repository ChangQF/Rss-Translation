<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 01 Dec 2024 18:22:34 GMT</lastBuildDate>
    <item>
      <title>如何最好地利用比率数据进行机器学习分类主动学习循环？</title>
      <link>https://stats.stackexchange.com/questions/658093/how-best-to-approach-ml-classification-active-learning-loop-with-ratio-data</link>
      <description><![CDATA[我目前正在进行一个项目，试图研究分子与其相行为（在本例中为二元）之间的结构-性质关系。分子具有主链和任意数量的侧链，并且每个侧链可以具有一系列长度和柔韧性。因此，任何一个分子的数据都是主链长度、主链上侧链所在位置的 1D 数组、指定侧链长度的相同长度的 1D 数组、主链柔韧性的值（10-100，以 10 的倍数表示，从最柔韧性到最不柔韧性），以及给出每个侧链柔韧性的最终数组。还要注意，数据中存在依赖性，即如果主链较长，侧链也可能更长，并且侧链数量可能更多。
我试图将这些特征与我的二元结果联系起来，但标记成本很高，因此我正在进行基于池的主动学习，以尽可能少的数据获得良好的替代模型。在我看来，有两个选项，我不知道哪个最好。按照上述描述顺序的一个分子的示例数据：
10 [2,4,7] [9,1,5] 100 [10,80,40]

我已经知道，我可以通过对每个模型进行短暂模拟计算出的几何描述符与目标（模拟长度约为 30 分钟）有很好的相关性。要获得整个未标记池的这些描述符是不可能的，因为如果我将主链长度从 4 变为 14，并允许所有可能的数量、位置、弯曲和侧链长度，那么分子的总组合将达到数百万。所以我需要从代表总体的搜索空间中抽样，理想情况下最终得到 2000 个或更少的分子。我真的不太确定如何做到这一点，因为它是比率数据，我认为传统的技术（如 PCA）不能很好地处理它。另一个问题是，我需要对更大、更刚性的分子进行过度采样，否则最终会得到不平衡的类别分布。目前，我正尝试根据直觉对一个全面的未标记池进行采样，该池涵盖了分子特征的主要变化，但我想知道是否有更强大的方法。

跳过几何描述符，让代理模型直接使用初始数据中的分子特征。在我的数据上，随机森林效果很好，所以这是代理模型的计划，我知道它可以很好地处理分类数据。但我认为我的数据格式不正确，如果我进行独热编码，我会担心数据稀疏性。我见过有人建议散列，但我需要能够从散列数据中恢复分子，这样我才知道在 AL 循环中标记期间要模拟什么。有一件事是，理想情况下，我希望避免使用 VAE 等无监督技术，因为我遇到了很多与这些技术重建质量有关的问题。理想情况下，我可以通过某种巧妙的方法将数据（甚至是构建数据组合的特征工程）转换为随机森林的输入。


如果有人有任何全面且可实施的方法来实现上述任何一个目标，我们将不胜感激。我目前正在使用 sklearn 和 ALiPy 进行代理和 AL 循环。]]></description>
      <guid>https://stats.stackexchange.com/questions/658093/how-best-to-approach-ml-classification-active-learning-loop-with-ratio-data</guid>
      <pubDate>Sun, 01 Dec 2024 14:57:19 GMT</pubDate>
    </item>
    <item>
      <title>协方差对 Stata 来说意味着什么？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658089/what-does-covariance-mean-to-stata</link>
      <description><![CDATA[
我的问题

我想解释 Stata 给我的 ESS 和 RSS 结果，针对一个解释变量和一个响应变量。

我迄今为止尝试过的方法

我尝试过如何使用术语“协方差”来解释这些值。但是，据我理解，协方差可以有多种含义。我不知道 Stata 使用哪种含义。
我已在 Google 和 Cross Validated 上查找答案，但未找到有关 Stata 的具体答案。

定义

在 Stata 上，当我通过输入以下命令启动回归分析时：
reg 响应变量的名称 解释变量的名称
Stata 显示总平方和以及解释和未解释的平方和。
我的理解方式是：

TSS：最佳拟合线与响应变量均值之间的平方差之和。
ESS：响应变量均值与每个数据点之间的平方差之和。 ESS 是解释平方和。
RSS：最佳拟合线与每个数据点之间的平方差之和。RSS 是未解释平方和。

这里的“解释”是指“协方差”。
我理解协方差的方式如下：

两个变量单调相关的程度。
当一个变量增加时，另一个变量是增加还是减少？


我的问题

我的问题是：协方差对 Stata 意味着什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658089/what-does-covariance-mean-to-stata</guid>
      <pubDate>Sun, 01 Dec 2024 12:39:00 GMT</pubDate>
    </item>
    <item>
      <title>随机森林 R 帮助[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658084/random-forest-r-help</link>
      <description><![CDATA[我在 R 中有一个数据框，随机分为训练集 (779) 和测试集 (326)，两者都不平衡。在训练集中，我有 31% 的事件（我想要预测的事件）。我应用了 5 倍交叉验证。这是我使用的方法。有人能告诉我这是否是正确的方法吗（就 summaryfunction 而言，考虑不平衡等）？如何调整超参数？我读到 method=ranger 中不考虑 ntress。我该怎么办？
&lt;&quot;&quot;control &lt;- trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = prSummary)
#根据类别不平衡定义类别权重
class_weights &lt;- c(&quot;No&quot; = 1, &quot;Yes&quot; = 535 / 244) print(class_weights)
#使用 ROC 作为权重度量来训练随机森林模型
#定义类别权重
class_weights &lt;- c(&quot;No&quot; = 1, &quot;Yes&quot; = nrow(train_data) / (2 * sum(train_data$Predictor== &quot;Yes&quot;)))
#默认模型----
set.seed(123) rf_default &lt;- train(Predictor ~ ., data = train_data[, c(features, &quot;Predictor&quot;)], method = &quot;ranger&quot;, metric = &quot;AUC&quot;, trControl = control, weights = ifelse( train_data$RECIST_first_progressors == &quot;Yes&quot;, class_weights[&quot;Yes&quot;], class_weights[&quot;No&quot;] # 为类别不平衡分配权重 ))
# 访问交叉验证结果
cv_results &lt;- rf_default$resample
# 打印每个折叠的结果
print(cv_results)
# 计算汇总统计数据
summary_stats &lt;- cv_results %&gt;%
summarise(
Mean_AUC =平均值（AUC），
SD_AUC = sd（AUC），
平均值_Precision = 平均值（Precision），
SD_Precision = sd（Precision），
平均值_Recall = 平均值（Recall），
SD_Recall = sd（Recall），
平均值_F1 = 平均值（F），
SD_F1 = sd（F）
）
#打印摘要统计信息
print(summary_stats)&quot;&quot;
我从交叉验证中获得了 77% 的平均 AUC，因此我认为该模型在训练中不能完美预测（我喜欢这一点，因为它可能意味着没有过度拟合）。但是，当我在完整的数据框（训练+测试）上训练模型以评估在训练测试中预测结果的差异（基本上是用条形图绘制）时，预测是完美的。怎么可能呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/658084/random-forest-r-help</guid>
      <pubDate>Sat, 30 Nov 2024 22:38:54 GMT</pubDate>
    </item>
    <item>
      <title>不同打印方法导致的方差解释差异</title>
      <link>https://stats.stackexchange.com/questions/658082/discrepancies-in-explained-variance-depending-on-the-print-method</link>
      <description><![CDATA[在执行探索性因子分析时，我想查看因子的解释方差。这很简单，我打印了fa()方法的输出。可以得到与$loadings输出相同的汇总表，如下所示。问题是两个表中的解释方差有偏差。这是什么原因，是 psych 包中的错误吗？哪个输出是正确的？
library(psych)

fa_results &lt;- fa(df_sq1sq9, nfactors = 5, rotate = &quot;oblimin&quot;)
print(fa_results)
fa_results$loadings

请注意，我不是在谈论因子载荷，而是在下表中谈论 Cumulative var 行。差异出现在正交和斜向旋转的情况下，并且在斜向旋转的情况下，两个输出的偏差更大。因此，该示例以斜交旋转显示。
斜交旋转：
&gt;print(fa_results)

[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.45 1.50 1.07 1.05 0.60
比例方差 0.27 0.17 0.12 0.12 0.07
累积方差 0.27 0.44 0.56 0.68 0.74
解释比例 0.37 0.22 0.16 0.16 0.09
累积比例 0.37 0.59 0.75 0.91 1.00

因子相关性为 
MR1 MR3 MR5 MR2 MR4
MR1 1.00 0.59 0.64 -0.01 0.30
MR3 0.59 1.00 0.33 0.12 0.21
MR5 0.64 0.33 1.00 0.28 0.11
MR2 -0.01 0.12 0.28 1.00 -0.17
MR4 0.30 0.21 0.11 -0.17 1.00

斜轴旋转：
&gt;fa_results$loadings
[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.310 1.350 0.975 1.038 0.563
比例方差 0.257 0.150 0.108 0.115 0.063
累计Var 0.257 0.407 0.515 0.630 0.693

我也在 https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained 中提出了这个问题作为更新]]></description>
      <guid>https://stats.stackexchange.com/questions/658082/discrepancies-in-explained-variance-depending-on-the-print-method</guid>
      <pubDate>Sat, 30 Nov 2024 11:55:31 GMT</pubDate>
    </item>
    <item>
      <title>对于满足 LLN 和 CLT 的非 IID 数据，EDF 是否收敛？</title>
      <link>https://stats.stackexchange.com/questions/657989/does-the-edf-converge-for-non-iid-data-that-satisfy-lln-and-clt</link>
      <description><![CDATA[对于 IID 数据，经验分布函数 (EDF) 已知会收敛，这是由于 Glivenko-Cantelli 定理，该定理保证 EDF 均匀收敛到真实累积分布函数 (CDF)。
如果数据是非 IID 的但仍满足大数定律 (LLN) 和中心极限定理 (CLT)：

EDF 还会收敛吗？
如果会，在什么类型的收敛下（例如，在概率上，弱收敛）？

寻找将 EDF 收敛推广到满足 LLN 和 CLT 的非 IID 数据的见解或参考。]]></description>
      <guid>https://stats.stackexchange.com/questions/657989/does-the-edf-converge-for-non-iid-data-that-satisfy-lln-and-clt</guid>
      <pubDate>Thu, 28 Nov 2024 16:28:34 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在处理一个重复测量数据集，其中个人/单位/实体代表医疗机构。研究的目的是观察机构特征 (X) 对由于某种医疗状况 (Y) 导致的几家医疗机构的死亡人数的影响。Y 表示在跨越多年的时间段内每周测量的死亡人数。X 表示在整个研究过程中在多个时间点（每周、每季度、研究开始/结束）测量的连续/分类变量。变量 Y 是零膨胀的，并且由于在模型中包含太多预测因子而导致数值问题。
我的一组 X 变量 (u1、u2、...、un) 与一组其他变量 (v1、v2、...、vn) 相关。这使我无法在同一模型中同时建模 U（总共约 50 个）和 V（总共约 5 个）变量。因此，我对 U 变量进行了建模，并选择了对 Y 有显著影响的 U 变量子集。利用这个子集，我执行了 PCA，并在最终模型中将 PCA 分数与 V 变量一起使用。我相信这样做可以让它们（U 变量和 V 变量的 PCA 分数）彼此不相关，同时在估计 V 变量时会纳入 U 变量的净效应。
我的最终目标是获得与时间无关的 V 变量预测。
在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法涉及以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 之间的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除非数字变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不均等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    <item>
      <title>计算事件总数的置信区间</title>
      <link>https://stats.stackexchange.com/questions/657232/calculating-a-confidence-interval-for-a-sum-of-events</link>
      <description><![CDATA[我有一个包含一组事件的试验，很多次都没有发生任何事件。每个事件都有一定的量级，但事件的量级遵循合理的分布（正态分布）。
我拥有的：

使用比例检验发现事件发生的概率，置信区间（事件率）为 95%
使用 t 检验对所有事件得出的事件量级的 95% 置信区间

我想要找到的

在规模为 n 的试验中，所有事件总和的 95% 置信区间。

示例：
假设我试图估计如果有 n 位顾客进来，商店将赚多少钱。我收集了有关客户购买任何东西的可能性的数据，以及任何一次购买的平均金额的数据。
因为购买金额的分布极其不正常（你有一群客户如果商店没有购买任何东西，则对所有客户进行 t 检验或 z 检验会违反正态性假设。更糟糕的是，商店很小，因此购买的数量很少（~10），而客户数量较大，但仍然不多（~50）。
如果有 n 个客户进来，有没有办法获得产生的收入的 95% 置信区间？
更新：
使用 MATLAB 代码更新。
我能够使用以下参数运行一些模拟
购买概率 25% STD 0.05
平均购买金额 100 STD 10
客户：50
模拟 50,000 次后，每位客户的收入的 95% 置信区间为 12.41 至 38.65。

代码：
rng(&#39;default&#39;) % 可重复性
numberofTrials = 50000;
trialSize = 50;
means = zeros(1,numberofTrials);
prob = normrnd(.25,0.05,[1,numberofTrials]);

parfor meanindex = 1:试验次数
valuepool = normrnd(100,10,[1,trialSize]);
trial = zeros(1,trialSize);
currentValIndex = 1; 
for eventindex = 1:trialSize
cause = rand(1);
if cause &lt; prob(meanindex)
trial(eventindex) = valuepool(currentValIndex);
currentValIndex = currentValIndex + 1;
end
end
means(meanindex) = mean(trial);
end
means = rot90(means);
%pd = fitdist(means, &#39;Rayleigh&#39;)
%pd = fitdist(means, &#39;kernel&#39;)
%pd = fitdist(means, &#39;Normal&#39;)
%qqplot(means, pd)
hist = histogram(means);
histfit(means, hist.NumBins, &#39;Normal&#39;)
ylabel(&quot;频率&quot;)
xlabel(&quot;平均购买金额&quot;)
quantile(means,[.05, .95])
]]></description>
      <guid>https://stats.stackexchange.com/questions/657232/calculating-a-confidence-interval-for-a-sum-of-events</guid>
      <pubDate>Thu, 14 Nov 2024 02:17:22 GMT</pubDate>
    </item>
    <item>
      <title>以不同时间频率收集变量的纵向回归模型？</title>
      <link>https://stats.stackexchange.com/questions/655840/longitudinal-regression-models-with-variables-collected-at-different-time-freque</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655840/longitudinal-regression-models-with-variables-collected-at-different-time-freque</guid>
      <pubDate>Wed, 16 Oct 2024 05:18:50 GMT</pubDate>
    </item>
    <item>
      <title>如果分类变量保留在 R 中的最终模型中，那么为什么事后分析表明水平没有差异？</title>
      <link>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</link>
      <description><![CDATA[我正在使用 R 中的 anova() 函数进行模型选择，并且我的分类变量在我的最终模型中得到了保留，但是当我使用 emmeans() 函数进行事后分析时，它告诉我水平没有差异。这是什么意思？
我使用 R 软件，我正在研究一种鱼的身体状况在三种河流中的变化：保护性、轻微城市化和高度城市化。每个类别都有一个重复，这意味着我有 2 条保护性河流、2 条轻微城市化河流和 2 条高度城市化河流，这意味着“河流”是一个随机因素，“城市化类别”是我的固定因素和具有 3 个级别的预测变量。在使用 anova() 函数在 R 中执行模型选择时，分类变量“类别”得到保留：
`#它是一个线性混合模型，因为条件呈正态分布
&gt; lmm.1 &lt;- lmer(条件 ~ 城市化类别 + (1|河流), 数据 = 鱼) 
&gt; lmm.null &lt;- lmer(条件 ~ 1 + (1|河流), 数据 = 鱼) 
&gt; anova(lmm.null, lmm.1)
使用 ML（而不是 REML）重新拟合模型
数据：鱼
模型：
lmm.null：条件 ~ 1 + (1 | 河流)
lmm.1：条件 ~ 城市化类别 + (1 | 河流)
npar AIC BIC logLik 偏差 Chisq Df Pr(&gt;Chisq)
lmm.null 3 -214.42 -205.37 110.21 -220.42
lmm.1 5 -219.80 -204.71 114.90 -229.80 9.3806 2 0.009184 **
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1`

`
我忘记在我的问题中包含我的模型摘要，所以这里是：
&gt; summary(lmm.1)
REML [&#39;lmerMod&#39;] 拟合的线性混合模型
公式：条件 ~ 城市化类别 + (1 | 河流)
数据：鱼

收敛时的 REML 标准：-214.3

缩放残差：
最小 1Q 中位数 3Q 最大
-2.65967 -0.54776 -0.07734 0.56748 2.79995

随机效应：
组名称方差标准差。
河流（截距）0.001965 0.04432 
残差 0.012381 0.11127 
观测数：151，组：河流，6

固定效应：
估计标准差。误差 t 值
（截距） -0.12808 0.04154 -3.084
category.of.urbanizationslightly 0.15972 0.05376 2.971
category.of.urbanizationvery 0.17063 0.05432 3.141

固定效应相关性：
（截距） ctgr.d.rbnzcp
ctgr.d.rbnzcp -0.773 
ctgr.d.rbnzcm -0.765 0.591 

我的 p 值为 0.009184，这意味着城市化类别是一个重要的预测因素，我预计分类变量的至少一个级别会与其他级别不同。然而，当尝试进行事后分析时，我调用了 emmeans() 函数，R 说所有水平都没有差异，因为 p 值都高于 0.05：
`&gt; emmeans(lmm.1，成对 ~ category.of.urbanization)
已注册的 S3 方法被“broom”覆盖：
方法来自 
tidy.glht jtools
tidy.summary.glht jtools
$emmeans
category.of.urbanization emmean SE df lower.CL upper.CL
保留 -0.1281 0.0441 3.42 -0.2592 0.00304
略微城市化 0.0316 0.0341 2.20 -0.1030 0.16632
非常城市化 0.0425 0.0350 2.43 -0.0852 0.17032

自由度方法：kenward-roger
使用的置信度：0.95

$contrasts
对比估计 SE df t.ratio p.value
保留 - 略带城市化 -0.1597 0.0558 2.83 -2.863 0.1324
保留 - 非常城市化 -0.1706 0.0563 2.95 -3.028 0.1123
略带城市化 - 非常城市化 -0.0109 0.0489 2.32 -0.223 0.9733

自由度方法：kenward-roger
P 值调整：用于比较 3 个估计值的 Tukey 方法`

请问，这是什么意思？预测变量如何显著，但水平没有差异？我有 151 条鱼，所以我的数据和观察值数量不是很低。如果我犯了拼写错误，我很抱歉，英语不是我的母语。]]></description>
      <guid>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</guid>
      <pubDate>Tue, 15 Oct 2024 13:48:27 GMT</pubDate>
    </item>
    <item>
      <title>证明 $\mathbb{E} (|X-Y|) = 0 \implies X^2 = Y^2$</title>
      <link>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</link>
      <description><![CDATA[$\boxed{\text{设 } X,Y \text{ 为任意随机变量。证明如果 } \mathbb{E}(​​|X-Y|) = 0，\text{则 } X^2 = Y^2。}$
我们有 $\mathbb{E}(​​|X-Y|) = 0$，我认为如果我能以某种方式证明 $X=Y$，那么它直接意味着 $X^2 = Y^2$，但我不知道如何实现。
附言：这不是任何形式的家庭作业，我只是在大学概率课程的往期考试中看到了这个问题，想尝试一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</guid>
      <pubDate>Wed, 09 Oct 2024 19:54:07 GMT</pubDate>
    </item>
    <item>
      <title>在扩散模型（DDPM）中，如果我们预测总噪声，为什么不直接在一次采样中去除噪声呢？</title>
      <link>https://stats.stackexchange.com/questions/650844/in-diffusion-models-ddpm-if-we-predict-the-total-noise-why-not-just-remove-t</link>
      <description><![CDATA[正如 DDPM 论文所指出的，我们可以选择将均值的预测重新参数化为总噪声的预测“εθ 是一个函数近似器，旨在根据 x 预测 ε”（公式 11）。那么，在采样过程中，我们为什么不直接从最后一步（纯噪声）中去除预测的总噪声，而是逐步采样图像？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650844/in-diffusion-models-ddpm-if-we-predict-the-total-noise-why-not-just-remove-t</guid>
      <pubDate>Thu, 11 Jul 2024 03:07:21 GMT</pubDate>
    </item>
    <item>
      <title>如何分析时间序列+滑动窗口的分类结果</title>
      <link>https://stats.stackexchange.com/questions/585214/how-to-analyse-results-of-classification-for-time-series-sliding-windows</link>
      <description><![CDATA[这是我的上下文：
我有一个仅由 1 个特征组成的时间序列。我希望能够在两个类之间进行分类。为了从这些数据中获取更多信息，我使用了滑动时间窗口。
例如，如果我的时间序列包含 1000 个观测值，我会使用 20 个观测值的滑动窗口，并迭代所有 1000 个观测值。我将时间序列的迭代 t 与窗口的第一个值相关联（如果 t=1：窗口在 [1,21] 中有 t；如果 t=150，窗口在 [150,170] 中有 t）
对于每个包含 20 个样本的窗口，我提取其他特征（为简单起见，我们假设为均值和方差）。
这样做，我有一个大小为 1000*2 的新数据集。然后，我在这个数据集上训练一个分类器。我不使用时间作为特征。
为了评估模型，我有一个测试集（200 个观测的时间序列）。我对时间窗口执行相同的过程以获得 200*2 的数据集。从那里，我将真实类别与预测类别进行比较并创建混淆矩阵。
快速总结整个过程：

将 N 个观测和 f 个特征的时间序列 x 转换为具有滑动时间窗口的 N 个观测和 F 个特征的训练集 X
使用 X 训练分类器
将另一个时间序列 y 转换为测试集 Y（与 1 相同的过程）
使用训练模型预测 Y 的类别
创建混淆矩阵

现在，这是我的问题：
当我得到混淆矩阵时，我得到了很多假阳性。原因是，如果时间序列中的类别差异极大，则在发生类别转换时统计值会有点“错误”。这有点难以解释，所以我画了一张图来说明这个问题：

这是一个有两个类别（蓝点和绿点）的时间序列，我将滑动时间窗口获得的平均值叠加在一起。可以看到在切换类别时平均值会发生“转换阶段”。问题是我因此得到了很多错误分类。例如，它将把索引 12、13、14 处的绿色类别分类为蓝色
我的问题是，分类器在技术上并没有“错误”，因为这些示例存在于滑动窗口中，但在混淆矩阵中不可见。
我的观点是：如何在混淆矩阵中考虑这种现象？
我希望我表达得足够清楚，并提前感谢您对此的任何意见！]]></description>
      <guid>https://stats.stackexchange.com/questions/585214/how-to-analyse-results-of-classification-for-time-series-sliding-windows</guid>
      <pubDate>Thu, 11 Aug 2022 17:43:21 GMT</pubDate>
    </item>
    <item>
      <title>按分布和收敛顺序收敛</title>
      <link>https://stats.stackexchange.com/questions/567308/converge-in-distribution-and-order-of-convergence</link>
      <description><![CDATA[我读过一本关于“分布收敛”的计量经济学教科书，发现了以下句子。
\begin{equation}
Z_{N} \xrightarrow{d} Z\implies Z_{N} = {O_p}(1) 
\end{equation
也就是说，如果一个随机变量$Z_n$在分布上收敛到$Z$，$Z_N$的概率是有界的。
教科书上说这很容易验证。但是，我现在还搞不清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/567308/converge-in-distribution-and-order-of-convergence</guid>
      <pubDate>Thu, 10 Mar 2022 04:23:40 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 GLM 中的条件平均值？</title>
      <link>https://stats.stackexchange.com/questions/552908/how-to-compute-conditional-mean-in-glm</link>
      <description><![CDATA[我已经了解了 GLM 的基本知识。我知道为什么 GLM 由预测器、链接函数和分布组成。但我不知道条件均值如何与分布联系起来。
以泊松回归为例，我们有 $\log(\mu_i) = \beta_0 + \beta_1x_i$，其中 $\mu_i$ 是条件均值。
如何根据观测值 $y_i$ 和泊松分布计算出 $\mu_i$？
此外，泊松分布中的参数 $\lambda$ 是如何计算的？]]></description>
      <guid>https://stats.stackexchange.com/questions/552908/how-to-compute-conditional-mean-in-glm</guid>
      <pubDate>Fri, 19 Nov 2021 18:38:24 GMT</pubDate>
    </item>
    <item>
      <title>使用随机森林中的交叉验证进行超参数调整——测试集 AUC 高于交叉验证 AUC</title>
      <link>https://stats.stackexchange.com/questions/542117/hyper-parameter-turning-using-cross-validation-in-random-forest-test-set-auc</link>
      <description><![CDATA[我正在训练一个随机森林模型来预测某个结果。
我将数据分成 80% 的训练集和 20% 的测试集。在训练数据中，我使用网格搜索来选择最佳超参数，基于哪些超参数在此训练集中产生最高的 5 倍交叉 AUC。
然后，我使用这些超参数在训练集上训练模型，并确定测试集上的 AUC。
我还有第二个外部验证集，我也在其上确定了 AUC。
以下是我的结果：
80% 训练集 AUC：89（95% CI：85-92）
80% 训练集中的 5 倍交叉验证 AUC：64
20% 测试集 AUC：80（95% CI：71-89）
外部测试集 AUC：70（95% CI：54-85）
我担心的是 5 倍交叉验证在训练集中的 AUC 比其他 AUC 低得多。我查看了几种资源，它们都表明交叉验证 AUC 应该仅用于选择超参数，而不是用于模型评估。
我应该担心/不信任这些结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/542117/hyper-parameter-turning-using-cross-validation-in-random-forest-test-set-auc</guid>
      <pubDate>Wed, 01 Sep 2021 01:46:20 GMT</pubDate>
    </item>
    </channel>
</rss>