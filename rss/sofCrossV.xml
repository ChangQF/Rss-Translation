<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 27 Jul 2024 21:13:10 GMT</lastBuildDate>
    <item>
      <title>多重 t 检验分析或个体 t 检验</title>
      <link>https://stats.stackexchange.com/questions/651872/multiple-t-test-analysis-or-indidivual-t-tests</link>
      <description><![CDATA[我必须使用 t 检验来分析样本。我不确定我是否应该将样本视为单个 t 检验或多个 t 检验。以下是详细信息：
我有一个实验，我分析了 30 种不同代谢物在 24 和 48 小时内的浓度。因此，我想知道每种代谢物在 24 小时和 48 小时之间是否存在显着差异。我对了解代谢物是否彼此不同并不感兴趣。我考虑运行 30 个单独的 t 检验（对每个代谢物进行一次 t 检验，评估 24 和 48 小时），但我不确定这是否可以，或者我是否应该考虑所有 30 种代谢物运行多个 t 检验。如果需要多个，有人可以告诉我原因吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/651872/multiple-t-test-analysis-or-indidivual-t-tests</guid>
      <pubDate>Sat, 27 Jul 2024 21:05:22 GMT</pubDate>
    </item>
    <item>
      <title>lavaan bootstrapLavaan() 函数没有考虑 heywood 案例？</title>
      <link>https://stats.stackexchange.com/questions/651870/lavaan-bootstraplavaan-function-does-not-take-into-consideration-heywood-cases</link>
      <description><![CDATA[我正在尝试使用 lavaan::bootstrapLavaan() 函数来引导探索性因子分析模型（具体来说，是标准化因子载荷），但我有两个问题：

我注意到这个函数没有考虑 Heywood 案例 - 即，如果在引导样本中遇到 Heywood 案例，它仍然会提取值，而不是给出 NA。虽然可以编写 FUN 来捕获该情况，然后在 boostrapLavaan() 中使用该 FUN，但我只是好奇为什么默认值不考虑 Heywood 案例，以及这是否表明我实际上不应该自己考虑 Heywood 案例。
此外，我的 efa 要求 2 个因子，有时即使因子结构相同，f1 和 f2 的标签也会交换，这可能会错误地增加 SE 或偏差（原始值减去引导平均值）。同样，我可以在 FUN 中自己解释这一点，但我很好奇，鉴于这是默认值，我是否实际上不应该考虑交换。
]]></description>
      <guid>https://stats.stackexchange.com/questions/651870/lavaan-bootstraplavaan-function-does-not-take-into-consideration-heywood-cases</guid>
      <pubDate>Sat, 27 Jul 2024 18:43:30 GMT</pubDate>
    </item>
    <item>
      <title>使用/不使用固定效应的 DIiff-in-diff 回归</title>
      <link>https://stats.stackexchange.com/questions/651869/diiff-in-diff-regression-with-without-using-fixed-effects</link>
      <description><![CDATA[我试图使用差异-差异策略查看冲击（在地区层面衡量，例如有些地区遭受冲击，有些地区没有）是否对个人某些活动的时间使用产生影响。由于几个人可能属于同一个家庭，因此我被建议包括家庭/地区固定效应。但是，在地区固定效应的情况下，这样做会降低系数的显著性水平。当我尝试使用家庭固定效应这样做时，会出现一些共线性问题。当我排除固定效应时，显著性水平上升到 1%。在这种情况下，我考虑不包括固定效应。这是否意味着我的分析不是因果关系？有人可以解释一下使用有/无固定效应的差异-差异估计有什么区别吗？请注意，数据的性质是重复的横截面，而不是面板。]]></description>
      <guid>https://stats.stackexchange.com/questions/651869/diiff-in-diff-regression-with-without-using-fixed-effects</guid>
      <pubDate>Sat, 27 Jul 2024 18:39:37 GMT</pubDate>
    </item>
    <item>
      <title>在 APA 格式的句子中，下列哪项是正确的统计数据：零还是 0？一还是 1？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651868/which-is-correct-for-writing-statstics-in-a-sentence-in-apa-style-zero-or-0-on</link>
      <description><![CDATA[示例：
如果两家公司位于同一国家，则指示变量等于 1，否则等于 0。
或者：
如果两家公司位于同一国家，则指示变量等于 1，否则等于 0。
如果您能引用权威机构的回答，我将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651868/which-is-correct-for-writing-statstics-in-a-sentence-in-apa-style-zero-or-0-on</guid>
      <pubDate>Sat, 27 Jul 2024 18:22:37 GMT</pubDate>
    </item>
    <item>
      <title>非满秩情况下的 `lm` [重复]</title>
      <link>https://stats.stackexchange.com/questions/651867/lm-in-non-full-rank-case</link>
      <description><![CDATA[从数学上讲，lm 如何处理数据不是满秩的情况？举个简单的例子：
set.seed(1234)

n &lt;- 100
X1 &lt;- rnorm(n)
X2 &lt;- rnorm(n)
Y &lt;- 2 + 3 * X1 + 4*X2 + rnorm(n, mean = 0, sd = 0.1)

model &lt;- lm(Y ~ X1 + X2 + I(2*X1 + 3*X2))
mat &lt;- model.matrix(model)
print(summary(model))

它给出输出：
调用：
lm(formula = Y ~ X1 + X2 + I(2 * X1 + 3 * X2))

残差：
最小值 1Q 中位数 3Q 最大值
-0.31933 -0.06734 0.01060 0.05823 0.27650 

系数：（由于奇异性，1 未定义）

估计标准误差 t 值 Pr(&gt;|t|) 
（截距） 2.016358 0.009747 206.9 &lt;2e-16 ***
X1 3.008051 0.009633 312.3 &lt;2e-16 ***
X2 4.008832 0.009373 427.7 &lt;2e-16 ***
I(2 * X1 + 3 * X2) NA NA NA NA 
---
显著性代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

残差标准误差：97 个自由度上的 0.09624

多重 R 平方：0.9996，调整后的 R 平方：0.9996

F 统计量：2 和 97 DF 上的 1.369e+05，p 值：&lt; 2.2e-16

看来 lm 找到了一种方法来将一列标识为其他两列的线性组合！
但是，最后一个公式发生了变化：
model &lt;- lm(Y ~ X1 + I(2*X1 + 3*X2) + X2)

其余代码相同，得出：
调用：
lm(formula = Y ~ X1 + I(2 * X1 + 3 * X2) + X2)

残差：
最小值 1Q 中位数 3Q 最大值 
-0.31933 -0.06734 0.01060 0.05823 0.27650 

系数：（由于奇异性，1 未定义）
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 2.016358 0.009747 206.86 &lt;2e-16 ***
X1 0.335497 0.011348 29.56 &lt;2e-16 ***
I(2 * X1 + 3 * X2) 1.336277 0.003124 427.68 &lt;2e-16 ***
X2 NA NA NA NA 
---
有效代码: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

残差标准误差：97 自由度上的 0.09624
多重 R 平方：0.9996，调整后的 R 平方：0.9996
F 统计量：2 和 97 DF 上的 1.369e+05，p 值：&lt; 2.2e-16

那么 R 是否有某种检测非满秩数据的机制？它在给出最小二乘之前是否根据公式检查数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/651867/lm-in-non-full-rank-case</guid>
      <pubDate>Sat, 27 Jul 2024 18:13:24 GMT</pubDate>
    </item>
    <item>
      <title>加权最小二乘法，检查正态性</title>
      <link>https://stats.stackexchange.com/questions/651861/weighted-least-squares-checking-normality</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651861/weighted-least-squares-checking-normality</guid>
      <pubDate>Sat, 27 Jul 2024 12:45:43 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证后模型表现不佳</title>
      <link>https://stats.stackexchange.com/questions/651860/model-performing-poorly-after-cross-validation</link>
      <description><![CDATA[在使用交叉验证查看自定义预测函数对未见数据的表现后，我将函数应用于原始数据集，结果性能（基于判定系数）大幅下降。
我正在尝试构建一个预测模型来获取 3 个输入特征并预测一个比例。我定义了一个自定义函数来将输出限制在 0 和 1 之间：
def xg_curve(X, a, b, c, d, e):
x1, x2, x3 = X[:, 0], X[:, 1], X[:, 2]
return 1 / (1 + a * b ** (c * x1 + d * x2 + e * x3))

我尝试了分层 5 倍交叉验证，通过按目标变量对数据框进行排序，然后循环分配它们 0-4，这使得所有折叠中的目标分布几乎彼此相同，并且整个数据集也是如此。
测试折叠的平均 R2 为 0.6485，并且在所有折叠中非常紧密地聚集在这个值附近，平均训练 R2 等于0.655，并且非常紧密地聚集在这个值周围。
这是一个相当小的数据集（750 个条目），因此我使用交叉验证来确保模型很好地推广到看不见的数据，而不仅仅是在一个特定的训练/测试分割上表现良好。该模型预测了冰球模拟器中要保存的击球难度等级，所以我想将它应用于已经编程的击球（数据集）和游戏中的任何未来击球。目标是用户保存现有击球的时间百分比。
基于领域知识，我对特征占目标变化的约 65% 感到满意，并将该函数应用于整个数据集。但是，当我这样做时，R2 值下降到 0.478。我在下面提供了我的代码，我找不到任何错误！任何帮助都将不胜感激！
def xg_curve(X, a, b, c, d, e):
x1, x2, x3 = X[:, 0], X[:, 1], X[:, 2]
return 1 / (1 + a * b ** (c * x1 + d * x2 + e * x3))

X_data = over50[[&quot;Required_rate_of_closure&quot;, &quot;Shot angle&quot;, &quot;Lateral_diff_spin&quot;]].values
y_data = over50[&quot;Goal Percentage&quot;].values
folds = over50[&quot;Fold&quot;].values

# 初始化列表以存储每个折叠的 RMSE 和 R^2
train_rmse_values = []
train_r2_values = []
test_rmse_values = []
test_r2_values = []
params_list = []

# 折叠数
k = 5

for i in range(k):

# 将数据拆分为训练集和测试集
train_idx = folds != i
test_idx = folds == i

X_train, X_test = X_data[train_idx], X_data[test_idx]
y_train, y_test = y_data[train_idx], y_data[test_idx]

# 在训练集上拟合模型
popt, _ = curve_fit(xg_curve, X_train, y_train, p0=[1, 1, 1, 1, 1])

# 在训练集上进行预测
y_train_pred = xg_curve(X_train, *popt)
# 在测试集上进行预测
y_test_pred = xg_curve(X_test, *popt)

# 计算训练集的 RMSE 和 R^2
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
train_r2 = r2_score(y_train, y_train_pred)

# 计算测试集的 RMSE 和 R^2
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
test_r2 = r2_score(y_test, y_test_pred)

# 存储结果
train_rmse_values.append(train_rmse)
train_r2_values.append(train_r2)
test_rmse_values.append(test_rmse)
test_r2_values.append(test_r2)
params_list.append(popt)

# 计算所有折叠的 RMSE 和 R^2 的平均值和标准差
mean_train_rmse = np.mean(train_rmse_values)
std_train_rmse = np.std(train_rmse_values)
mean_train_r2 = np.mean(train_r2_values)
std_train_r2 = np.std(train_r2_values)

mean_test_rmse = np.mean(test_rmse_values)
std_test_rmse = np.std(test_rmse_values)
mean_test_r2 = np.mean(test_r2_values)
std_test_r2 = np.std(test_r2_values)

print(&quot;训练 RMSE：平均值 = {:.4f}，标准差 = {:.4f}&quot;.format(mean_train_rmse, std_train_rmse))
print(&quot;训练 R^2：平均值 = {:.4f}，标准差 = {:.4f}&quot;.format(mean_train_r2, std_train_r2))
print(&quot;验证 RMSE：平均值 = {:.4f}，标准差 = {:.4f}&quot;.format(mean_test_rmse, std_test_rmse))
print(&quot;验证 R^2：平均值 = {:.4f}，标准差 = {:.4f}&quot;.format(mean_test_r2, std_test_r2))

final_params, _ = curve_fit(xg_curve, X_data, y_data, p0=[1,1,1,1,1])

a,b,c,d,e = final_params

print(f&#39; 最终参数：a = {a}, b = {b}, c = {c}, d = {d}, e = {e}&#39;)

print(r2_score(xg_curve(X_data, *final_params), y_data))
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/651860/model-performing-poorly-after-cross-validation</guid>
      <pubDate>Sat, 27 Jul 2024 12:16:22 GMT</pubDate>
    </item>
    <item>
      <title>设计复杂的混合模型分析</title>
      <link>https://stats.stackexchange.com/questions/651846/designing-complex-mixed-model-analysis</link>
      <description><![CDATA[我正在尝试使用混合模型分析患者的脑电图数据。我在这方面已经停滞了一段时间，我阅读了大量论文和一本入门教科书，但仍然不确定自己在做什么。我正在尝试使用 Python 中的 statsmodels 来执行此操作。
有 10 个受试者，每个人在会话期间都会记录他们的脑电波。每个会话都有一个“控制”状态，即他们什么也不做，还有一个状态，即他们正在观看一些视频（治疗）。有多个会话，有些受试者跳过了一些会话。大脑活动局限于大脑中的特定区域。
使用混合模型，对单个受试者的不同会话（时间）重复测量，但也对治疗与控制进行测量。这让我开始感到困惑 - 当时间和治疗条件都在单个受试者内（“嵌套”）时，我该如何处理分析中的复杂情况？我对混合模型的理解非常简单，即存在重复测量（例如，某个位置的大脑活动），并且有受试者接受治疗或控制，但不会同时接受两者。有没有专门处理这个问题的文献？
另一个问题让我更加头疼——我不确定我是否应该对每个大脑区域分别进行分析，或者大脑区域应该是一个独立变量。如果我把它作为IV（不同区域的大脑活动不太可能是独立的，因为论文的一部分是某些区域是相连的）..我想这会使统计分析的设计更加复杂。然后另一个IV可能是不同的脑波频带（alpha vs beta vs theta等），类似的问题也适用——是否单独分析，因为它们也可能不独立..我在这里是一个非常困惑的人，希望能得到正确的指导..
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/651846/designing-complex-mixed-model-analysis</guid>
      <pubDate>Sat, 27 Jul 2024 03:02:37 GMT</pubDate>
    </item>
    <item>
      <title>回归和独立随机向量</title>
      <link>https://stats.stackexchange.com/questions/651795/regression-and-independent-random-vectors</link>
      <description><![CDATA[假设数据样本由随机向量$(X_1, Y_1)...(X_N, Y_N)$生成。对于回归，通常假设误差分布为 I.I.D。正态分布，数据的似然性纯粹由条件分布定义（忽略$X_i$的边际分布）：
$$
L(D) = p_{Y|X}(x_1,y_1)p_{Y|X}(x_2,y_2)...p_{Y|X}(x_N,y_N)
$$
其中$p_{Y|X}$是条件分布的概率函数。
这让我得出以下结论：

条件 p.d.f.每个随机向量的$p_{Y|X}(x_i,y_i)$与其他向量相互独立。这只有在随机向量 $(X_1, Y_1)...(X_N, Y_N)$ 也是独立的，因为任何独立随机向量的函数也是独立的。

$p_{Y|X}$ - 是一个固定函数，用于对数据样本的条件分布进行建模。

回归不对 DGP 每个随机向量内随机变量的联合分布做出任何假设，每个随机向量可以具有不同的联合分布，即 - $p_{X_1,Y_1} ,p_{X_2,Y_2}...p_{X_N,Y_N}$ 唯一的假设是它们彼此独立。


这些有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651795/regression-and-independent-random-vectors</guid>
      <pubDate>Fri, 26 Jul 2024 08:56:07 GMT</pubDate>
    </item>
    <item>
      <title>多元时间序列预测</title>
      <link>https://stats.stackexchange.com/questions/651716/multivariate-time-series-forecasting</link>
      <description><![CDATA[我有一个 200,000 行的数据集。每行包含歌曲 ID、今天的流数 (d​​ay_0)、昨天的流数 (d​​ay_1) 等，直到 21 天前的流数 (d​​ay_21)。我的任务是预测下周的流数。
我正在尝试弄清楚如何构造我的数据以将其输入到多变量 LSTM 中。目前，窗​​口滑动一天。这合适吗，还是我应该使用不重叠的窗口？我计划嵌入（来自这个帖子）歌曲 ID，以便 LSTM 可以学习特定于歌曲的模式。
任何其他建议都很好！]]></description>
      <guid>https://stats.stackexchange.com/questions/651716/multivariate-time-series-forecasting</guid>
      <pubDate>Thu, 25 Jul 2024 01:06:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 glmer 逻辑回归检查收敛问题后的模型</title>
      <link>https://stats.stackexchange.com/questions/651414/checking-model-after-convergence-issues-with-glmer-logistic-regression</link>
      <description><![CDATA[我正在使用 glmer 运行逻辑回归模型，其中受试者 ID 嵌套在窝仔 ID 中。方程式如下：
glmer(outcome ~ group * time + 
previousStatus + (1|litter/pup), data, 
family = binomial())

我正在分析一项随机对照试验，该试验有来自 120 窝仔仔的 679 名受试者，总共 1983 个观察值。
当包含受试者 ID 时，模型不会收敛。我使用了“allFit”，发现如果我使用“bobyqa”，模型就会收敛。但是，受试者 ID 的随机效应方差看起来非常高 - 使用公式 var/(var+pi^2/3)，它表明受试者 ID 本身就解释了我的结果中超过 99% 的方差。我查看了受试者 ID 的毛毛虫图（使用 qqmath），看看它是否看起来合理（试图决定我是否可以继续报告结果），但我不确定它显示了什么，也不确定它是否真的对我有帮助。有人对此有什么想法或想法吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651414/checking-model-after-convergence-issues-with-glmer-logistic-regression</guid>
      <pubDate>Fri, 19 Jul 2024 16:22:19 GMT</pubDate>
    </item>
    <item>
      <title>对于 $N=2$ 个样本，Welch t 检验的 p 值校准得不好</title>
      <link>https://stats.stackexchange.com/questions/651279/welch-t-test-p-values-are-poorly-calibrated-for-n-2-samples</link>
      <description><![CDATA[我正在对非常小的样本量执行大量 Welch t 检验（方差不等的 t 检验），通常每个条件只有两个样本。我发现 p 值校准得不好：模拟分布上的分布不均匀。
问题
对于每个条件 $N=2$ 个样本的 Welch t 检验，是否存在已知的校准？
最小 Python 代码
import numpy as np
import scipy as sp
from matplotlib import pyplot as plt

rng = np.random.default_rng()

X = rng.normal(loc=0, scale=1, size=(2, 1000000))
Y = rng.normal(loc=0, scale=2, size=(2, 1000000))

p = sp.stats.ttest_ind(X, Y, equal_var=False).pvalue
plt.hist(p,
bins=np.linspace(0, 1, 100),
histt​​ype=&#39;step&#39;,
density=True)
plt.axhline(1)
plt.xlabel(&#39;p&#39;)
plt.ylabel(&#39;PDF of p&#39;)

# 统计检验分布不均匀
ks_stat, ks_p_value = sp.stats.kstest(p, &#39;uniform&#39;)
print(&quot;KS Statistic:&quot;, ks_stat)
print(&quot;KS Test p-value:&quot;, ks_p_value)

输出如下。
KS Statistic: 0.03906382636964301
KS Test p-value: 0.0

]]></description>
      <guid>https://stats.stackexchange.com/questions/651279/welch-t-test-p-values-are-poorly-calibrated-for-n-2-samples</guid>
      <pubDate>Wed, 17 Jul 2024 18:56:49 GMT</pubDate>
    </item>
    <item>
      <title>使用尺度正权重和非 0.5 截止分数来建立相似模型</title>
      <link>https://stats.stackexchange.com/questions/650910/using-scale-pos-weight-and-non-0-5-cut-off-score-for-a-look-alike-model</link>
      <description><![CDATA[我正在研究一个分类问题，试图识别出第 0 类中第 1 类的相似者。第 1 类和第 0 类是根据客户使用的产品类型建立的。基本上，第 1 类客户拥有产品 A 并表现出某些行为。第 0 类客户拥有产品 B，但其中一些客户表现出的行为类似于拥有产品 A 的第 1 类客户的行为。
我的模型旨在识别表现出第 1 类行为的 0 类客户，以便可以有针对性地将第 0 类客户迁移到产品 A。我们称此类客户为相似者。
基本上，我只有确认的第 1 类客户。第 0 类在某种程度上是一组混合客户。我正在构建一个分类器来识别第 0 类中的相似者。基本上，模型识别的误报。
第 1 类和第 0 类的实际比例约为 1:10。我的样本的比例为 1:4。我正在使用 xgboost 分类器，其尺度正权重约为 4。
我试图保守一点，使用更高的截止分数 0.7 来识别相似者。即，任何获得 0.7 或更高分数的 0 类客户都被视为相似者。我使用召回率作为模型性能指标，在 0.7 截止分数下，我得到的召回率为 0.7，相似者或假阳性率为 0.05（5%）。考虑到业务用例，这看起来是合理的。
我的问题是，在这种情况下同时使用尺度正权重和更高的截止分数是否有意义？我的建模方法听起来有问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650910/using-scale-pos-weight-and-non-0-5-cut-off-score-for-a-look-alike-model</guid>
      <pubDate>Fri, 12 Jul 2024 01:16:22 GMT</pubDate>
    </item>
    <item>
      <title>比较分布的差分熵</title>
      <link>https://stats.stackexchange.com/questions/649799/differential-entropy-for-comparison-distributions</link>
      <description><![CDATA[我想使用差分熵来比较不同数据集的贝叶斯更新（多维概率分布）的结果。我的参数是不同的物理参数，即具有不同的维度和（非常）不同的绝对值。
现在，我想知道差分熵是否是一种很好的比较方法。
是否会出现这样的情况：例如，差分熵的下降仅仅是因为某个变量（具有高绝对值）变得（稍微）更精确地确定，而另一个变量的定义不太明确，仅仅是因为一个变量具有高绝对值？
在这种情况下，该度量不能很好地描述信息/近似值，因为增加对具有高绝对值的参数的了解似乎会以另一个同样重要但绝对值范围较低的参数为代价来提高对多维分布的了解。]]></description>
      <guid>https://stats.stackexchange.com/questions/649799/differential-entropy-for-comparison-distributions</guid>
      <pubDate>Mon, 24 Jun 2024 12:28:33 GMT</pubDate>
    </item>
    <item>
      <title>向量自相关公式参考</title>
      <link>https://stats.stackexchange.com/questions/642523/reference-for-autocorrelation-formula-for-vectors</link>
      <description><![CDATA[Stack Overflow 上的这篇文章说，向量的自相关或自相关定义为
$$C(t, \{v\}_n) = \frac {1}{n-t}\sum_{i=0}^{n-1-t}\vec v_i\cdot\vec v_{i+t}$$
这个公式的出处是什么？能给我一个参考吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642523/reference-for-autocorrelation-formula-for-vectors</guid>
      <pubDate>Wed, 13 Mar 2024 17:24:54 GMT</pubDate>
    </item>
    </channel>
</rss>