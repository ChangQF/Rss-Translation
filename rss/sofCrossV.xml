<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 15 Feb 2024 15:13:21 GMT</lastBuildDate>
    <item>
      <title>通过块转置重新组织数据</title>
      <link>https://stats.stackexchange.com/questions/639357/reorganizing-data-by-transposing-in-blocks</link>
      <description><![CDATA[我被要求帮助清理数据集，我想反过来向你们寻求帮助。我提供了一个示例（带有随机生成的数据）。基本上，数据按块排列。

我用绿色标记了案例 ID，用黄色标记了日期 ID。其他标记的颜色标识匹配的测量值。例如，蓝色是第 2 天 0:00 的测量值，其中变量 1 的测量值是 132/88，变量 2 的测量值是 13.00，变量 3 的测量值是 16。此外，每个“变量”还有一个附加列，其中包含附加测量值，排序为“时间”“测量”“时间”测量。我想将它们分成两部分，以便它们与其他测量值相匹配。
我的目标是将其转换为一个长数据集，更适合分析（例如，具有匹配的颜色编码，如下所示）。这将涉及到块的转置，但我不知道该怎么做。它还涉及带有附加测量的字符串，但这可以通过我发现的一些包含向量和循环的语法来实现。将“131/66”拆分为“131”和“66”两个变量也是如此，但这是稍后要担心的。

我可以手动完成此操作，但除了明显的时间投入之外，它还会引入人为错误的可能性，因此我更喜欢基于语法的解决方案。
有没有什么函数可以实现这个功能。 Transpose 函数只处理整个变量，这不是我想要的。如果这在 SPSS 中不可能，什么程序可以让我做到这一点（我们也有 csv 文件形式的原始数据）。]]></description>
      <guid>https://stats.stackexchange.com/questions/639357/reorganizing-data-by-transposing-in-blocks</guid>
      <pubDate>Thu, 15 Feb 2024 14:59:27 GMT</pubDate>
    </item>
    <item>
      <title>识别缺失数据的类型以及可以进行 Skillings Mack 检验的事后检验</title>
      <link>https://stats.stackexchange.com/questions/639356/identifying-the-type-of-missing-data-and-the-post-hoc-test-that-can-be-carried-o</link>
      <description><![CDATA[我有一个非正态配对样本数据集。每行代表一只经过实验测试的狗。每只狗都提供了三种提示（治疗）：5s 提示（又名仅面部提示）、vocalone（面部 + 声音提示）、vocaltwo（面部 + 声音*2）。提示是连续提供的。根据他们的行为，他们会得到一个分数。每个分数是通过添加在特定提示处理期间显示的所有行为来计算的（例如，竖起耳朵 + 左尾巴摇摆 = -3）。 0分代表中立。当狗接近实验者时，实验就停止了。在突出显示的行中，狗在声乐治疗中接近实验者。由于实验在那一点停止，对该狗的声音两次治疗没有得分。在其他情况下，狗可能在 5 秒提示处理中接近，因此该狗的vocalone 和vocaltwo 都没有得分。我的问题如下：

假设此处缺失的数据可以归类为“随机缺失数据”是否正确？
如果是，并且我执行了 Skillings-Mack 检验，如果综合检验返回显着性（在我的情况下，p &lt; 0.05），适当的事后检验是什么？我一直在考虑像弗里德曼那样与霍尔姆修正进行 Nemenyi 或 Conover 成对比较。其中之一有用吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/639356/identifying-the-type-of-missing-data-and-the-post-hoc-test-that-can-be-carried-o</guid>
      <pubDate>Thu, 15 Feb 2024 14:54:48 GMT</pubDate>
    </item>
    <item>
      <title>Performance::icc 和 iccCounts::icc_counts 给出不同的结果</title>
      <link>https://stats.stackexchange.com/questions/639355/performanceicc-and-icccountsicc-counts-give-different-result</link>
      <description><![CDATA[我已经运行了这段代码：
模型 &lt;- pat_count ~ 1 + (1 | 扇区)
m1 &lt;- glmmTMB(模型,
  数据=findf，
  家庭 = nbinom2
）

性能::icc(m1)
iccCounts::icc_counts(findf, &quot;pat_count&quot;, &quot;扇区&quot;, fam=&quot;nbinom2&quot;)

但是性能::icc给出：
&lt;前&gt;&lt;代码&gt;r$&gt;性能::icc(m1)
# 类内相关系数

    调整后的ICC：0.529
  未经调整的 ICC：0.529
警告信息：
mu 为 0.1 太接近于零，估计为
  随机效应方差可能不可靠。

虽然iccCounts::icc_counts给出：
r$&gt;; iccCounts::icc_counts(findf, &quot;pat_count&quot;, &quot;s
ector&quot;, fam=&quot;nbinom2&quot;)
$型号
公式：y~(1|id)
数据：数据
           AIC BIC 日志
 6266.92439287 6287.32970422 -3130.46219644
      df.残渣
          6643
随机效应（共）方差：

条件模型：
 组名称 标准差
 id（拦截）1.8942829

obs 数量：6646 / 条件模型：id, 3

nbinom2 系列的色散参数 ()：0.09
85

固定效果：

条件模型：
（截距）
-2.58614296

$ICC
                 国际商会SE
[1，] 0.0869237660467 0.0100996407407
           95% CI LL 95% CI UL
[1,] 0.0670970885753 0.106681822593

$varcomp
             穆BSVar
 0.452942944372 3.58830769324 10.1529061428

attr(,“类”)
[1]《ICCC》

所以一个是 53%，另一个是 9%。
为什么两者差别这么大？]]></description>
      <guid>https://stats.stackexchange.com/questions/639355/performanceicc-and-icccountsicc-counts-give-different-result</guid>
      <pubDate>Thu, 15 Feb 2024 14:40:59 GMT</pubDate>
    </item>
    <item>
      <title>R 中 SAS 的变量聚类 (varclus) R 平方</title>
      <link>https://stats.stackexchange.com/questions/639354/variable-clustering-varclus-r-squared-from-sas-in-r</link>
      <description><![CDATA[我正在使用 R 中 Hmisc 包中的 varclus 函数。有没有办法像 SAS 中那样从 varclus 生成汇总表，其中包含诸如它们解释的方差比例、R 与自己的簇的平方以及下一个最接近的信息等信息。我特别感兴趣的是如何在使用 Hmisc 包中的 varclus 函数后计算自己的簇和下一个最接近的 R 平方以及 1-R**2 比率。
]]></description>
      <guid>https://stats.stackexchange.com/questions/639354/variable-clustering-varclus-r-squared-from-sas-in-r</guid>
      <pubDate>Thu, 15 Feb 2024 14:40:06 GMT</pubDate>
    </item>
    <item>
      <title>R 中多分类变量线性回归中的缺失系数</title>
      <link>https://stats.stackexchange.com/questions/639351/missing-coefficients-in-linear-regression-with-multiple-categorical-variables-in</link>
      <description><![CDATA[我有一个奇怪的场景，我试图在几个分类变量上回归一个数值变量，没有其他数值变量。在我的实际示例中，我有大约 23k 行数据。 R 函数 lm 可以很好地处理分类——至少在大多数情况下是这样。但是，我发现我没有获得分类变量的每个值的系数。这是一个最小的工作示例：
费用 = c(1000, 2000, 3000, 4000, 5000)
geo = c(“本地”、“区域”、“全国”、“本地”、“区域”)
区域=c(“德克萨斯州”、“俄克拉荷马州”、“路易斯安那州”、“德克萨斯州”、“路易斯安那州”)

rev = data.frame(费用、地理、区域)

rev$geo = 因子(rev$geo)
rev$region = 因子(rev$region)

mod = lm(充电~.,数据=转速)
摘要（模组）

结果是：
&lt;前&gt;&lt;代码&gt;
称呼：
lm(公式 = 电荷 ~ ., 数据 = rev)

残差：
         1 2 3 4 5
-1.500e+03 1.484e-13 9.154e-14 1.500e+03 1.484e-13

系数：（1 由于奇点而未定义）
               估计标准。误差t值Pr(&gt;|t|)
（截距） 2500 1500 1.667 0.344
地理国家 500 2598 0.192 0.879
地理区域 2500 2598 0.962 0.512
地区俄克拉荷马州 -3000 3000 -1.000 0.500
地区 德克萨斯州 NA NA NA NA

残余标准误差：1 自由度上为 2121
多重 R 平方：0.55，调整 R 平方：-0.8
F 统计量：3 和 1 DF 上为 0.4074，p 值：0.7848

现在我明白模型矩阵中存在线性相关问题，这就是 regionTexas 没有获得系数的原因。据推测，截距应该是 cal categori 变量缺失值的值；问题是，我发现很难解释该参考值，因为它必须承担“双重职责”作为多个分类变量的参考值。最终，我的实际应用程序中有 4 个分类变量。
我该如何解决这个问题？如果我能以某种方式控制因子中的哪个级别成为参考级别，我愿意用额外的行填充数据，包括分类变量的额外值。最终，我有 4 个因素需要延长这种处理，以获得所有因素的系数。
这篇文章 似乎相关，但没有完全回答我的问题。关于分类变量的多元回归还有其他一些建议，但它们没有回答我的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/639351/missing-coefficients-in-linear-regression-with-multiple-categorical-variables-in</guid>
      <pubDate>Thu, 15 Feb 2024 14:13:19 GMT</pubDate>
    </item>
    <item>
      <title>效应大小+方差计算单组前测后测-不同样本量前测-后测</title>
      <link>https://stats.stackexchange.com/questions/639350/effect-size-variance-calculation-single-group-pretest-posttest-different-sam</link>
      <description><![CDATA[我在荟萃分析中纳入了单组前测-后测研究设计。我计算效应大小如下：后测均值和预测均值之间的差异除以预测均值的标准差（Becker et al., 1988）。这种效应大小的方差取决于测试前和测试后分数以及 N（配对数）的相关性。
对于我的大部分数据，我有配对的均值和 SD - N 预测试与 N 后测试相同。
但是，我的一些文章报告了不同样本量的均值和标准差。例如预测试 N = 64；后测 N = 60。
现在，如果我想使用隐喻包函数 escalc(measure=“SMCR”) 计算 R 中的效应大小，我必须包括平均预测试、平均后测试、标准差预测试、N 和 r(函数中 pre-post) 之间的相关性。
假设如前所述的示例，其中我的平均值来自不同的参与者组，那么我将使用什么来表示 N？预测样本量还是后测样本量？您也许可以为两者找到合适的论据。采用预测试样本量可能更有意义，因为用于标准化均值差的标准差也基于预测试信息（因为我使用贝克尔公式）。另一方面，采用后测数字也是有意义的，就像研究中的任何配对 t 检验一样（我经常用它来计算前测和后测之间的相关性，参见 Morris &amp; DeShon，2002）大概是基于测试后的样本量。也许这里没有完美的解决方案，因为您进入隐喻功能的方式可能应该来自相同数量的参与者。然而，正如我所说，文章中提供的数据并不总是可行。
在这种情况下，最佳实践是什么？
非常感谢您的帮助！提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/639350/effect-size-variance-calculation-single-group-pretest-posttest-different-sam</guid>
      <pubDate>Thu, 15 Feb 2024 13:59:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么SVM的成本函数中正则化项要乘以误差项？</title>
      <link>https://stats.stackexchange.com/questions/639349/why-is-the-regularization-term-multiplied-by-the-error-term-in-the-cost-function</link>
      <description><![CDATA[最优间隔分类器（非核化 SVM）的成本函数如下：
$$
J(\mathbf{\vec w}, b) = \frac{1}{2}\|\mathbf{\vec w}\|_{2}^{2} + C \sum_{i=1}^ {n}\max(0, 1-y ^{(i)}(\mathbf{\vec w}\cdot \mathbf{\vec x}^{(i)} + b))
$$
&lt;块引用&gt;
为什么我们将正则化参数 $C$ 与误差项相乘，而不是正则化项 $\frac{ 1}{2}\|\mathbf{\vec{w}}\|_2^2$ ?

成本函数的一般形式通常是这样的：
$$
J_\lambda(\boldsymbol \theta) = J(\boldsymbol \theta) + \lambda R(\boldsymbol \theta)
$$
其中 $R(\boldsymbol \theta)$ 是正则化项。
如您所见，正则化参数 $\lambda$ 始终乘以正则化项。那么为什么SVM的成本函数如此奇特呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/639349/why-is-the-regularization-term-multiplied-by-the-error-term-in-the-cost-function</guid>
      <pubDate>Thu, 15 Feb 2024 13:51:48 GMT</pubDate>
    </item>
    <item>
      <title>没有事先研究吗？使用深度学习通过预测要应用的最佳过滤器或直方图转换来增强视频</title>
      <link>https://stats.stackexchange.com/questions/639345/no-prior-research-using-deep-learning-to-enhance-videos-by-predicting-the-best</link>
      <description><![CDATA[我想增强使用 4K 摄像机录制的视频。不过，我在网上能找到的技术大致分为这两类：

巧妙的数学启发式算法可自动调整锐度、色彩平衡、对比度等。
深度学习模型直接对像素进行操作，作为模型的输入和输出。

我想超越启发式方法并应用“智能”来解决问题。颜色调整，例如。这样（肤色就不会变得奇怪）。然而，应用模型来输出操纵的像素是不可取的，因为它是计算密集型的。这是因为无法单独修改帧，因为这会导致不一致（闪烁）。另外，我需要处理所有帧（每秒 30 帧），而不是仅仅将模型应用于例如。每秒 1 帧，平滑输出，然后对所有帧应用廉价转换。
因此，我希望找到一些关于模型的研究、基准数据集、huggingface 模型等，这些模型可以建议要应用的过滤器，无论是来自一组预定义的过滤器，还是通过输出完整的直方图转换来应用图像。
但是，我什么也没找到。
这种研究叫什么，例如。我应该搜索什么？
是否存在此类内容的基准数据集？]]></description>
      <guid>https://stats.stackexchange.com/questions/639345/no-prior-research-using-deep-learning-to-enhance-videos-by-predicting-the-best</guid>
      <pubDate>Thu, 15 Feb 2024 12:41:40 GMT</pubDate>
    </item>
    <item>
      <title>多重线性混合模型-多重比较调整</title>
      <link>https://stats.stackexchange.com/questions/639344/multiple-linear-mixed-models-multiple-comparisons-adjustment</link>
      <description><![CDATA[我最近开始使用随时间重复测量的病例对照研究（在 R 中对重复测量数据进行建模 - 解释和验证）。我有几个因变量，我想为每个变量拟合一个线性混合模型。
我的问题是：我应该调整从每个模型获得的系数的 p 值吗？我该怎么做？此外，当我报告简单对比以显示每个时间点组之间的差异时，我是否还应该调整通过简单对比获得的 p 值？]]></description>
      <guid>https://stats.stackexchange.com/questions/639344/multiple-linear-mixed-models-multiple-comparisons-adjustment</guid>
      <pubDate>Thu, 15 Feb 2024 12:41:09 GMT</pubDate>
    </item>
    <item>
      <title>统计上显着差异</title>
      <link>https://stats.stackexchange.com/questions/639338/statistically-significant-difference</link>
      <description><![CDATA[我正在阅读一篇医学论文，其中写道：“
“6个月时，IPC组的呼吸困难有统计学上显着的改善，IPC组和滑石粉组之间的VAS评分平均差异为-14.0毫米（95% CI，-25.2至-2.8）毫米；P = .01)”
但是，我认为由于 -14 位于 -25.2 到 -2.8 的 CI 范围内，因此这在统计上不显着。
我错了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639338/statistically-significant-difference</guid>
      <pubDate>Thu, 15 Feb 2024 11:06:48 GMT</pubDate>
    </item>
    <item>
      <title>受两种相互作用的处理影响的两个变量之间的非线性关系</title>
      <link>https://stats.stackexchange.com/questions/639337/nonlinear-relation-between-two-variables-as-affected-by-two-interacting-treatmen</link>
      <description><![CDATA[我通过实验测试了 6 个重复 x 2 个基因型（分类）x 3 个物种（分类）的因变量 y（连续）和自变量 x（连续）之间的关系（= 处理 A），这些重复在 3 个不同的预处理中生长。 -处理过的土壤（分类，=处理 B），产生 108 株植物。该实验同时在不同的温室（GH）中进行，基因型-土壤组合随机分布。我主要想知道 y 和 x 之间的关系在土壤 (a) 之间是否不同。我还想知道当每个物种的两个植物品种在同一土壤中生长时，y 和 x 之间的关系是否不同 (b)。我想将温室视为潜在的随机效应。

我可以像这样安装 y~x：
(一)
unique_soils &lt;- unique(d_sub$Soil)
for（unique_soils 中的土壤）{
  sub_data &lt;- d_sub[d_sub$Soil == 土壤, ]
  拟合 &lt;- nls(y ~ SSlogis(x, asymp, infl, 斜率1), data = sub_data)
  model_list[[paste(&quot;fit_&quot;, 土壤, sep = &quot;&quot;)]] &lt;- 拟合
}

(b)
unique_soils &lt;- unique(d_sub$Soil)
unique_Genotypes &lt;- unique(d_sub$Genotype)
for（unique_soils 中的土壤）{
  sub&lt;- d_sub[d_sub$Soil == 土壤, ]
  for (unique_Genotypes 中的基因型) {
  sub_data &lt;- sub[sub$Genotype == Genotype, ]
  拟合 &lt;- nls(y ~ SSlogis(x, asymp, infl, 斜率1), data = sub_data)
  model_list[[paste(&quot;fit_&quot;, Genotype,&#39;_&#39;,soil, sep = &quot;&quot;)]] &lt;- 拟合
  }
}

我的表格如下所示（示例）：
&lt;前&gt;&lt;代码&gt;&gt;头（d_sub）
        ID 基因型 土壤 GH y x 物种
1 311019 物种B_基因型A 土壤A 1 0.1542170 1.482907 物种B
2 311019 物种B_基因型A 土壤A 1 0.2033631 1.715033 物种B
3 311019 物种 B_基因型 A 土壤 A 1 0.2762349 2.365915 物种 B

如果土壤和同一土壤中生长的同一物种的基因型之间的 y 和 x 之间的关系存在统计差异，那么最好的测试方法是什么？
我在想：

使用方差分析来比较生成的模型是否彼此存在显着差异。我不确定这是否有效，因为我的模型是非线性的。
创建一个以土壤和基因型作为交互因子的 nlme（我没有找到如何在 R 中对其进行编码）。
提取拟合参数asymp、infl、slope1并使用统计检验在处理之间相互比较。我不知道如何解释拟合参数的标准误差/置信区间。

感谢您分享您的意见！]]></description>
      <guid>https://stats.stackexchange.com/questions/639337/nonlinear-relation-between-two-variables-as-affected-by-two-interacting-treatmen</guid>
      <pubDate>Thu, 15 Feb 2024 11:06:33 GMT</pubDate>
    </item>
    <item>
      <title>在比例赔率模型中，当两个相邻类别合并在一起时，估计参数（斜率）会发生变化，即使它们不应该发生变化</title>
      <link>https://stats.stackexchange.com/questions/639335/in-a-proportional-odds-model-when-two-adjacent-categories-are-pooled-together</link>
      <description><![CDATA[在几篇文章中，我指出，当使用比例赔率（PO 或累积 Logit）模型时，由于斜率参数保持不变，因此很自然会折叠相邻的结果类别。目前，我使用 R 中的 clm 函数，语法如下：clm &lt;- clm(response ~ time + Group, data=DatasetLong)。我的响应变量包含四个级别：0、1、2 和 3。在检查模型摘要后，我观察到以下输出：
公式：响应~时间+组
数据：数据集长

系数：
       估计标准。误差z值Pr(&gt;|z|)
时间 0.1268 0.0432 2.94 0.0033 **
第4组 0.0923 0.2746 0.34 0.7369
第 5 组 1.3196 0.2858 4.62 3.9e-06 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

阈值系数：
    估计标准。误差z值
0|1 0.926 0.330 2.80
1|2 2.560 0.362 7.07
2|3 6.007 0.677 8.87
（197 个观察因缺失而被删除）

比我尝试折叠级别 0 和 1 (DatasetLong$response2 &lt;- recode_factor(DatasetLong$response, &quot;0&quot;=&quot;1&quot;)并拟合相同的模型：clm2 &lt;- clm(response2 ~ time + Group, data=DatasetLong)，其中response2现在只有3个级别：1,2,3。根据“可折叠性下不变”属性，我假设对时间、Group4 和 Group5 的估计相同。但是，我的摘要（clm2）输出是：
&lt;前&gt;&lt;代码&gt;摘要(clm2)
公式：响应2~时间+组别
数据：数据集长

系数：
       估计标准。误差z值Pr(&gt;|z|)
时间 0.0597 0.0550 1.09 0.27774
第4组 -0.0217 0.4029 -0.05 0.95712
第 5 组 1.3584 0.3595 3.78 0.00016 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

阈值系数：
    估计标准。误差z值
1|2 2.117 0.452 4.69
2|3 5.569 0.730 7.62
（197 个观察因缺失而被删除）

对于时间的估计，Group4和Group5完全不同。我哪里出错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/639335/in-a-proportional-odds-model-when-two-adjacent-categories-are-pooled-together</guid>
      <pubDate>Thu, 15 Feb 2024 10:45:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 bootstrap 比较两种机器学习模型的性能</title>
      <link>https://stats.stackexchange.com/questions/639334/using-bootstrap-to-compare-performance-of-two-machine-learning-models</link>
      <description><![CDATA[我有一个二元分类问题，以及两个 ML 模型 $A$ 和 $B$。我使用 ROC 曲线下面积 (AUROC) 评估这些模型的性能。我想评估模型 $A$ 是否明显优于模型 $B$。我的测试集相当小（156 个样本）。由于它是从未知分布（我无权访问）中抽​​取的，因此是随机的，因此 AUROC 结果也有些随机。统计测试应该告诉我结果的差异是否可能是由于更好的模型（“统计显着性”），或者是否很可能是由于测试数据的特定选择。
我有以下使用引导测试的方法：

我绘制 $n$ 个引导样本 $i\in\{1,...,n\}$测试集的，例如$n=1000$。
对于每个引导样本$i$，我计算$\text{AUROC}^A_i$和 $\text{AUROC}^B_i$，以及它们的区别 $d_i = \text{AUROC}^A_i - \text{AUROC}^B_i$。
根据差异分布$d_i$，我计算了 bootrap 置信区间
如果该区间完全高于零或低于零，则性能差异具有统计显着性，如果该区间包含零，则不显着。

这是测试性能差异的好方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639334/using-bootstrap-to-compare-performance-of-two-machine-learning-models</guid>
      <pubDate>Thu, 15 Feb 2024 10:20:46 GMT</pubDate>
    </item>
    <item>
      <title>CI 的 p 值？</title>
      <link>https://stats.stackexchange.com/questions/639326/p-values-from-cis</link>
      <description><![CDATA[有没有办法从使用 quantile 函数提取的 CI 中计算 p 值？
bs1 &lt;- 复制(1000, sd(样本(c(10,23,21,12,14,14,13,14,15,25)) ,
                                 10、替换=真）））
bs2 &lt;- 复制(1000, sd(样本(c(10,11,10,13,13,13,14,19,12,23),
                                 10、替换=真）））

CI &lt;- 分位数(bs1 - bs2, prob = c(0.025, 0.975))
]]></description>
      <guid>https://stats.stackexchange.com/questions/639326/p-values-from-cis</guid>
      <pubDate>Thu, 15 Feb 2024 08:55:11 GMT</pubDate>
    </item>
    <item>
      <title>通过引导计算斯皮尔曼相关性置信区间的最佳方法是什么？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/639315/what-is-the-best-way-to-calculate-confidence-interval-for-spearman-correlation-b</link>
      <description><![CDATA[我发现以下两种方法与 bootstrap 之间的置信区间值存在重要差异：
第一个：分位数(Rs, prob=c(0.025, 0.975))
第二个：tanh(atanh(R) ± 1.96 sqrt(n-3))
（第二个解释[那里]如何计算 Spearman 等级相关的置信区间？ )
是否存在错误或为何存在这些差异？
祝你有美好的一天。
关联=c()
NB=1000

对于 ( i in 1:nb)
{
    A=r范数(500, 10,3)
    E=runif(500，最小值=0，最大值=12)
    B=A*2+E*2+E
    Z=cor(A,B, 方法=“矛兵”)
    关联=追加（关联，Z）
    如果 (i==1) 原点=Z
}

#分位数
打印（分位数（相关，概率=c（0.025，0.975）））

#cal
stderr=1/sqrt(500-3) #编辑不注意
增量=1.96*标准错误
up=tanh(atanh(原点) + delta) #edit
down=tanh(atanh(原点) - delta) #edit
打印（上）
打印（向下）

编辑：有关分位数，请参阅[那里]https:/ /www.rdocumentation.org/packages/stats/versions/3.6.2/topics/quantile
分位数用于查找百分位数 97.5 和 2.5 的值，请参阅 https://en .wikipedia.org/wiki/97.5th_percentile_point
结果：
&lt;预&gt;&lt;代码&gt;2.5% 97.5%
0.3899030 0.5288183
打印（上）
[1] 0.4804465
 打印（向下）
[1] 0.3794499

编辑感谢 Mathemagician777 对 delta 的评论]]></description>
      <guid>https://stats.stackexchange.com/questions/639315/what-is-the-best-way-to-calculate-confidence-interval-for-spearman-correlation-b</guid>
      <pubDate>Thu, 15 Feb 2024 06:28:44 GMT</pubDate>
    </item>
    </channel>
</rss>