<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 May 2024 12:27:42 GMT</lastBuildDate>
    <item>
      <title>在 R 中绘制后验概率</title>
      <link>https://stats.stackexchange.com/questions/648205/plotting-posterior-probabilities-in-r</link>
      <description><![CDATA[我正在为考试练习一些题目，但不知为何我无论如何也想不通为什么概率必须除以它们和的 0.01。和是有道理的，因为它是成比例的后验，但为什么是 0.01？难道我们不希望和是 1 而不是 100 吗？谢谢！
# A 型马的数据
na &lt;- 60
sa &lt;- 18
fa &lt;- na - sa

# 先验参数
a &lt;- 5
b &lt;- 15

# 后验 = 伯努利似然 * Beta 先验
post &lt;- function(theta, n, s, f, a, b) {
prob &lt;- theta ** (s + a - 1) * (1 - theta) ** (f + b - 1)

return(prob)
}

theta &lt;- seq(0, 1, 0.001)
probs &lt;- post(theta, na, sa, fa, a, b)
probs &lt;- probs / (0.01 * sum(probs)) # &lt;--- 为什么是 0.01？
图（theta，probs）
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648205/plotting-posterior-probabilities-in-r</guid>
      <pubDate>Wed, 29 May 2024 11:29:30 GMT</pubDate>
    </item>
    <item>
      <title>`ggplot` 中没有反向刻度的轴刻度[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648202/no-axis-ticks-in-reversed-scale-in-ggplot</link>
      <description><![CDATA[当 ggplot 中的刻度反转时，轴分隔线无法呈现。例如：
ggplot() +
scale_x_continuous(limits = c(1, 1000))

显示默认分隔线，但是：
ggplot() + 
scale_x_continuous(limits = c(1000, 1))

无法呈现任何分隔线。即使尝试使用 breaks 参数手动添加它们也会失败。]]></description>
      <guid>https://stats.stackexchange.com/questions/648202/no-axis-ticks-in-reversed-scale-in-ggplot</guid>
      <pubDate>Wed, 29 May 2024 10:37:04 GMT</pubDate>
    </item>
    <item>
      <title>“clusterSim” R 包中 index.Gap 中的“clall”是什么？</title>
      <link>https://stats.stackexchange.com/questions/648200/what-is-clall-in-index-gap-in-clustersim-r-package</link>
      <description><![CDATA[我在我的项目中使用&quot;clusterSim&quot; 包 (https://cran.r-project.org/web/packages/clusterSim/clusterSim.pdf，第 39 页)，我不明白&quot;clall&quot; 变量的含义，以及为什么在文档的示例 1 中，pam 算法被使用两次并保存在两个不同的变量中。
有人可以向我解释一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648200/what-is-clall-in-index-gap-in-clustersim-r-package</guid>
      <pubDate>Wed, 29 May 2024 10:05:15 GMT</pubDate>
    </item>
    <item>
      <title>R 和 SPSS 中的因子方差分析结果不同</title>
      <link>https://stats.stackexchange.com/questions/648199/factorial-anova-results-differ-in-r-and-spss</link>
      <description><![CDATA[我尝试在 SPSS 和 R 中运行因子方差分析，但得到了不同的结果。我也将 iv 转换为因子。有什么建议吗？
pacman::p_load(foreign, phia, car)
d = read.csv(&quot;https://raw.githubusercontent.com/srk7774/data/master/stevensp.174.csv&quot;, 
)
d$facta = as.factor(d$facta)
d$factb = as.factor(d$factb)
d$factc = as.factor(d$factc)
m = lm(score ~ 1 + facta * factb * factc, data = d)
Anova(m, type = 3)
#&gt; Anova 表（III 型检验）
#&gt; 
#&gt; 响应：分数
#&gt;总和平方 Df F 值 Pr(&gt;F) 
#&gt; (截距) 120.333 1 13.2883 0.001284 **
#&gt; facta 0.167 1 0.0184 0.893218 
#&gt; factb 13.500 1 1.4908 0.233953 
#&gt; factc 94.889 2 5.2393 0.012940 * 
#&gt; facta:factb 1.333 1 0.1472 0.704566 
#&gt; facta:factc 154.333 2 8.5215 0.001598 **
#&gt; factb:factc 23.111 2 1.2761 0.297399 
#&gt; facta:factb:factc 74.889 2 4.1350 0.028639 * 
#&gt; 残差 217.333 24 
#&gt; ---
#&gt; 有效代码: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

于 2024-05-29 使用 reprex v2.0.2
]]></description>
      <guid>https://stats.stackexchange.com/questions/648199/factorial-anova-results-differ-in-r-and-spss</guid>
      <pubDate>Wed, 29 May 2024 09:53:57 GMT</pubDate>
    </item>
    <item>
      <title>对分析公开医疗数据集的方法提出意见</title>
      <link>https://stats.stackexchange.com/questions/648196/input-on-methodology-for-analysing-publicly-available-medical-datasets</link>
      <description><![CDATA[我被要求分析一个公开的药物不良反应医疗数据集。
我的数据质量本来就很差，所以我一直在尽力从中提取一些有意义的东西。我的研究问题是“哪些 SSRI 与哪些 ADR 最相关”
我按性别分层以减少混淆，将一列 ADR 变成虚拟变量，并使用以下逻辑回归模型：
ADR 类型 ~ 年龄 + SSRI 类型
请记住，ADR 遵循 MedDRA 层次结构，从最通用的 27 个术语（例如 Psych 或 Nerv）到越来越具体的术语。最常见的是 27，然后是 337，然后是 1737。我知道很多模型和很多多重测试效果。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648196/input-on-methodology-for-analysing-publicly-available-medical-datasets</guid>
      <pubDate>Wed, 29 May 2024 09:39:32 GMT</pubDate>
    </item>
    <item>
      <title>在仅截距和 AR-NN 模型之间进行选择：是否有理由不使用 RMSE/MAE 最低的模型？</title>
      <link>https://stats.stackexchange.com/questions/648194/choosing-between-intercept-only-and-ar-nn-models-justified-to-not-use-the-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648194/choosing-between-intercept-only-and-ar-nn-models-justified-to-not-use-the-model</guid>
      <pubDate>Wed, 29 May 2024 08:36:00 GMT</pubDate>
    </item>
    <item>
      <title>置信区间 ODE 岭回归</title>
      <link>https://stats.stackexchange.com/questions/648192/confidence-intervals-ode-ridge-regression</link>
      <description><![CDATA[我想找到 L2 正则化的最小二乘损失的置信区间。我只找到了一些线性问题的方法，但在我的例子中，我想估计常微分方程参数（因此高度非线性）。有人处理过同样的问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648192/confidence-intervals-ode-ridge-regression</guid>
      <pubDate>Wed, 29 May 2024 08:27:07 GMT</pubDate>
    </item>
    <item>
      <title>过程（Hayes）逻辑回归输出解释-优势比[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648191/process-hayes-logistic-regression-output-interpretation-odds-ratio</link>
      <description><![CDATA[我使用 SPSS 中的 PROCESS 宏运行了逻辑回归，并且是使用 PROCESS 运行此模型的新手。我正在执行中介分析。根据我的理解，我需要报告比值比 (OR)，但我似乎无法在 PROCESS 输出中找到它可能在何处？或者我必须计算它吗？任何帮助都将不胜感激，我尝试四处寻找但找不到任何东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/648191/process-hayes-logistic-regression-output-interpretation-odds-ratio</guid>
      <pubDate>Wed, 29 May 2024 08:16:55 GMT</pubDate>
    </item>
    <item>
      <title>AR(1) 的手动 MLE 产生了一个奇怪的初始值 $y_0$</title>
      <link>https://stats.stackexchange.com/questions/648189/manual-mle-of-ar1-yields-a-weird-initial-value-y-0</link>
      <description><![CDATA[我正在尝试手动实现 AR(1) 模型中参数的最大似然估计 (MLE)
$$
y_t = c + \varphi_1 y_{t-1} + \varepsilon_t
$$
其中 $\text{Var}(\varepsilon_t)=\sigma^2$。我将我的结果与 forecast 包中的 Arima 获得的结果进行比较（基于 stats 包中的 arima）。

我的可能性略高于 Arima。
除了初始值 $y_0$ 之外，估计值并不相同，但相当接近。我的估算器给出的值似乎太高（高于 $y$ 的范围），并且远离 Arima 的更合理值。

我尝试了几个不同的手动 MLE 起始值，但每次都得到相同的结果。
我做错了什么？
library(fpp2) # 示例数据集所需

# AR(1) 的对数似然
loglik &lt;- function(pars){
c &lt;- pars[&quot;c&quot; ] # 常数
phi1 &lt;- pars[&quot;phi1&quot; ] # 斜率
sigma2 &lt;- pars[&quot;sigma2&quot;] # 误差方差
y0 &lt;- pars[&quot;y0&quot; ] # 时间序列的初始值
T &lt;- length(y)
e &lt;- rep(NA,T)
e[1] &lt;- y[1] - ( c + phi1*y0 )
for(t in 2:T){
e[t] &lt;- y[t] - ( c + phi1*y[t-1] )
}
Li &lt;- dnorm(e, mean=0, sd=sqrt(sigma2))
loglik &lt;- sum(log(Li))
return(loglik)
}

y &lt;- diff(log(oil)) # 1966-2013 年沙特阿拉伯石油产量年度变化百分比

# 优化 loglik 函数
opars &lt;- c(c=0, phi1=0, sigma2=var(y), y0=mean(y)) # 参数的初始值
#opt &lt;- optim(par=opars, fn=loglik, method=&quot;BFGS&quot;, control=list(fnscale=-1)) # 无界优化
opt &lt;- optim(par=opars, fn=loglik, method=&quot;L-BFGS-B&quot;, control=list(fnscale=-1), 
lower=c(-Inf,-0.99,1e-10,-Inf), 
upper=c( Inf, 0.99,Inf , Inf)) # 有界优化，-0.99&lt;=phi1&lt;=0.99 且 0&lt;sigma2
opt$convergence # 值为 0 表示优化算法正确收敛
optres &lt;- c(opt$par, logL=opt$value) # 主要结果为单个向量

# 与 `forecast::Arima` 进行比较相同数据的收益
m1 &lt;- Arima(y, order=c(1,0,0), method=&quot;CSS-ML&quot;)
m1 &lt;- Arima(y, order=c(1,0,0), method=&quot;ML&quot; )
chat &lt;- unname(m1$coef[2]*(1 - m1$coef[1])) # 用 mu 的估计值表示的 c 估计值
phi1hat &lt;- unname(m1$coef[1])
y0hat &lt;- (y[1] - chat - m1$residuals[1]) / phi1hat # y0 的估计值
m1par &lt;- c(c=chat, phi1=phi1hat, sigma2=m1$sigma2, y0=y0hat) 
m1res &lt;- c(m1par, logL=m1$loglik) # 单个向量中的主要结果

# 打印出来并将手动 ML 估计值与 `Arima` 中的估计值进行比较
估计值 &lt;- rbind(optres,m1res)
rownames(估计值) &lt;- c(&quot;Manual&quot;,&quot;Arima&quot;)
print(round(估计值, 数字=6))
]]></description>
      <guid>https://stats.stackexchange.com/questions/648189/manual-mle-of-ar1-yields-a-weird-initial-value-y-0</guid>
      <pubDate>Wed, 29 May 2024 08:09:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么对于两个比例的合并检验，只能用于假设检验，而不能用于置信区间？</title>
      <link>https://stats.stackexchange.com/questions/648188/why-is-it-for-the-pooled-test-of-two-proportions-it-can-only-be-used-for-a-hypo</link>
      <description><![CDATA[我在此处看到，使用 2 比例的合并检验时，只能得出假设检验，而不能得出置信区间。这是为什么？它还说当 $H_0: p_1-p_2=0$ 时使用合并，但这是否意味着当 $H_0: p_1-p_2=a$ 时，其中 $a\neq 0$ 我们会使用合并？如果是，为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648188/why-is-it-for-the-pooled-test-of-two-proportions-it-can-only-be-used-for-a-hypo</guid>
      <pubDate>Wed, 29 May 2024 07:35:38 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中的嵌套变量，其中因子具有多个级别</title>
      <link>https://stats.stackexchange.com/questions/648187/nested-variable-in-regression-model-where-factor-has-multiple-levels</link>
      <description><![CDATA[我遇到一种情况，我有一个因子变量 $F$ 和一个连续变量，例如 $X$。因子变量有三个级别，例如 (&#39;x&#39;、&#39;y&#39;、&#39;z&#39;)，并且 $X$ 仅在值为 $x$ 或 $y$ 时才定义。特别是，&#39;z&#39; 被编码为 NA。
如何在 R 中模拟这种情况？此答案建议这样做：
y ~ A + (A %in c(&#39;x&#39;, &#39;y&#39;)):X


如果所有 $X4 均为正，则我必须将 NA 设置为某个值（例如 -1） - 对吗，否则模型求解算法将无法处理这个问题？
公式规范似乎不起作用？现在我要开始做这件事吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648187/nested-variable-in-regression-model-where-factor-has-multiple-levels</guid>
      <pubDate>Wed, 29 May 2024 07:24:13 GMT</pubDate>
    </item>
    <item>
      <title>我们什么时候需要将隔离项作为 ergm 模型的一部分添加以及如何解释系数</title>
      <link>https://stats.stackexchange.com/questions/648181/when-are-we-required-to-add-isolates-as-part-of-the-ergm-model-and-how-to-interp</link>
      <description><![CDATA[最近，我尝试通过使用 ERGM 对公司网络进行建模来执行网络分析。当我研究要添加到模型中的一些流行术语时，我遇到了隔离术语，因此我想知道我应该如何解释隔离术语的系数（当它是负数或正数时）
我正在阅读以下链接以帮助进行解释，但它不包括对 ergm 术语的解释。https://github.com/eehh-stanford/SNA-workshop/blob/master/ergm-predictions.md#more-realistic-change-statistics]]></description>
      <guid>https://stats.stackexchange.com/questions/648181/when-are-we-required-to-add-isolates-as-part-of-the-ergm-model-and-how-to-interp</guid>
      <pubDate>Wed, 29 May 2024 04:41:40 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中的 Z 分数和标准误差</title>
      <link>https://stats.stackexchange.com/questions/648177/z-score-and-standard-error-in-linear-regression</link>
      <description><![CDATA[我正在阅读《统计学习要素》，在线性回归章节中，我无法理解以下内容：
我们已经从 $N$ 个数据点估计了回归参数 $\beta_1, ..., \beta_p$。
已确定 $\hat{\beta} \sim N(\beta, (X^T X)^{-1}\sigma^2)$，其中 $\beta$ 是 $\hat{\beta}$ 的真实值，$X$ 是数据矩阵。 $\sigma^2$ 是 $Y$ 相对于其均值的方差，即 $Y = X\beta + \epsilon$, $\epsilon \sim N(0, \sigma^2)$。
现在，作者计算 $z_j = \frac{\hat{\beta}_j}{\hat{\sigma}\sqrt{(X^TX)^{-1}_{jj}}}$。
此外，方差估计为 $\hat{\sigma}^2 = \frac{1}{N-p-1}RSS$。
现在，这或多或少清楚了，但是我应该也通过将 $\hat{\beta}_j$ 除以其标准误差来获得相同的 $z_j$。换句话说，它应该成立
$SE(\hat{\beta}_j) = \hat{\sigma}\sqrt{(X^TX)^{-1}_{jj}}$。但相反，我得到了以下结果：
$SE(\hat{\beta}_j) = \frac{\sqrt{(X^TX)^{-1}_{jj}}\sigma}{\sqrt{N}} = \frac{\sqrt{(X^TX)^{-1}_{jj}(N-p-1)}\hat{\sigma}}{\sqrt{N}}$
其中我使用了 $(N-p-1)\hat{\sigma} \sim \sigma^2\mathcal{X}^2_{N-p-1}$
因此 $\sqrt{N-p-1}$ 因子有些不对劲，我担心我从根本上误解了一些东西这里。
编辑：我可能犯了一个错误，第二种情况下的正确标准错误可能是
$\frac{\sqrt{(X^TX)^{-1}_{jj}}\hat{\sigma}}{\sqrt{N}}$
因为$\hat{\sigma}$估计的是$\sigma$。但我仍然不明白为什么$\sqrt{N}$仍然在那里。]]></description>
      <guid>https://stats.stackexchange.com/questions/648177/z-score-and-standard-error-in-linear-regression</guid>
      <pubDate>Wed, 29 May 2024 00:19:01 GMT</pubDate>
    </item>
    <item>
      <title>glmer 显著，事后检验不显著</title>
      <link>https://stats.stackexchange.com/questions/648171/glmer-significant-and-post-hoc-test-not-significant</link>
      <description><![CDATA[我运行了一个 glmer 模型来测试治疗对我的响应变量的影响
summary(model1)
通过最大似然法（拉普拉斯近似）拟合的广义线性混合模型 [&#39;glmerMod&#39;]
系列：二项式（logit）
公式：cbind(Numero_foglie_minate, Foglie_sane) ~ Trattamento + Blocco + Data_rilievo + (1 | ID_pianta)
数据：data_infestate
控制：glmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e+05))

AIC BIC logLik 偏差 df.resid 
4066.1 4142.5 -2020.0 4040.1 2632

缩放残差：
最小 1Q 中位数 3Q 最大值
-1.6876 -0.4813 -0.3308 0.1900 4.8004 

随机效应：
组名称方差标准差
ID_pianta (截距) 1.307 1.143 
观察数：2645，组：ID_pianta，478

固定效应：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -2.98258 0.18485 -16.135 &lt; 2e-16 ***
TrattamentoLavanda -0.43253 0.19116 -2.263 0.0237 * 
TrattamentoRosmarino -0.40539 0.20355 -1.992 0.0464 * 
TrattamentoTimo -0.22146 0.18686 -1.185 0.2360 
Blocco2 -0.33824 0.17387 -1.945 0.0517 。
Blocco3 -0.04463 0.17187 -0.260 0.7951 
Data_rilievo16 -0.01192 0.12264 -0.097 0.9226 
Data_rilievo22 0.08879 0.12123 0.732 0.4639 
Data_rilievo29 -0.03263 0.12380 -0.264 0.7921 
Data_rilievo36 -0.32984 0.12850 -2.567 0.0103 * 
Data_rilievo52 -0.56837 0.12778 -4.448 8.67e-06 ***
Data_rilievo9 0.03357 0.12290 0.273 0.7848 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应相关性：
（内部）TrttmL TrttmR TrttmT Blocc2 Blocc3 Dt_r16 Dt_r22 Dt_r29 Dt_r36 Dt_r52
TrttmntLvnd -0.468 
TrttmntRsmr -0.411 0.463 
TrattamntTm -0.512 0.495 0.463 
Blocco2 -0.441 -0.034 -0.127 0.018 
Blocco3 -0.436 -0.057 -0.153 -0.002 0.546 
Data_rilv16 -0.331 -0.004 0.044 -0.003 -0.040 -0.039 
Data_rilv22 -0.329 -0.009 0.037 -0.016 -0.043 -0.040 0.551 
Data_rilv29 -0.326 -0.003 0.039 -0.015 -0.041 -0.041 0.542 0.553 
Data_rilv36 -0.317 0.004 0.047 -0.003 -0.041 -0.046 0.519 0.531 0.531 
Data_rilv52 -0.318 0.001 0.046 -0.010 -0.038 -0.036 0.525 0.536 0.540 0.518 
Data_riliv9 -0.324 -0.007 0.046 -0.007 -0.046 -0.044 0.539 0.546 0.536 0.515 0.520

结果表明，两种处理方法（“Lavanda”和“Rosmarino”）以及一些采样日期“Data_rilievo”具有显著性。
然后我应用事后检验，如下所示
&gt; emmeans_trattamento &lt;- emmeans(model1, ~ Trattamento)
&gt; 
&gt; # Esegue i encounteri post-hoc tra i livelli del fattore Trattamento
&gt; facedi_posthoc &lt;- 对(emmeans_trattamento)
&gt; 
&gt; # 事后观察结果
&gt; summary(confronti_posthoc)
对比估计 SE df z.ratio p.value
Controllo - Lavanda 0.4325 0.191 Inf 2.263 0.1069
Controllo - Rosmarino 0.4054 0.204 Inf 1.992 0.1911
Controllo - Timo 0.2215 0.187 Inf 1.185 0.6362
Lavanda - Rosmarino -0.0271 0.205 Inf -0.132 0.9992
Lavanda - Timo -0.2111 0.190 Inf -1.110 0.6831
Rosmarino - Timo -0.1839 0.203 Inf -0.907 0.8011

结果在以下水平上取平均值： Blocco，Data_rilievo 
结果以对数比值比（而非响应）尺度给出。
P 值调整：用于比较 4 个估计值的 Tukey 方法

显著性已经消失。现在的问题是：

为什么在事后检验中进行成对比较时，glmer 中显著的东西变得不显著？
如何解释这个结果？我倾向于说，总体而言，这两种处理是显著的，但它们的影响非常小，以至于在成对比较期间无法观察到。第二种选择是，没有一种处理是显著的。哪一个是最正确的解释？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648171/glmer-significant-and-post-hoc-test-not-significant</guid>
      <pubDate>Tue, 28 May 2024 21:35:33 GMT</pubDate>
    </item>
    <item>
      <title>根据预测变量数量调整的逻辑回归中的 R 平方</title>
      <link>https://stats.stackexchange.com/questions/648160/r-squared-in-logistic-regression-adjusted-for-number-of-predictors</link>
      <description><![CDATA[对于 OLS，我们有一个调整后的 R 平方，它根据模型中包含的预测变量的数量进行调整。
对于逻辑回归，有一些 R 平方类似物（Tjur 的 R 平方、McFadden 的 R 平方、Cox-Snell 的 R 平方和 Nagelkerke 的 R 平方）。但是，是否有一个针对逻辑回归的 R 平方测量，可以根据模型中包含的预测变量的数量进行调整？
这篇关于逻辑回归的 R 平方的帖子没有回答我的问题，因为它没有关于根据模型中的预测变量数量进行调整的 R 平方的信息。&quot;调整&quot;这里提到的是指度量的尺度，上限为 1。这不是我的问题所在。]]></description>
      <guid>https://stats.stackexchange.com/questions/648160/r-squared-in-logistic-regression-adjusted-for-number-of-predictors</guid>
      <pubDate>Tue, 28 May 2024 16:21:54 GMT</pubDate>
    </item>
    </channel>
</rss>