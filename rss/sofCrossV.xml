<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 21 May 2024 15:15:41 GMT</lastBuildDate>
    <item>
      <title>正确使用K折交叉验证和最终确定模型</title>
      <link>https://stats.stackexchange.com/questions/647698/proper-usage-of-k-fold-cross-validation-and-finalizing-model</link>
      <description><![CDATA[我正在尝试了解 k 折交叉验证。我正在脑肿瘤 MRI 的 Kaggle 数据集上使用它，试图对图像进行分类。 Kaggle 提供了两个目录 使用 5712 张图像进行训练并使用 1311 张图像进行测试总共有 7023 张图像。我相应地制作了训练数据帧和测试数据帧，现在我的问题是，当我在我的情况下执行 5 倍的 k 倍交叉验证时，我是否应该仅使用整个训练目录（5712 个图像）来进行此 k 倍交叉验证？触摸测试目录，或者我应该使用整个数据集（7023 个图像）进行 k 倍交叉验证？
当我选择平均在 k 倍交叉验证上表现最好的模型架构时，另一个问题就结束了，我想“最终确定”据我了解，模型现在应该正常在整套训练目录（5712）上进行训练，并使用测试目录（1311张图像）进行最终模型评估，并根据此评估报告准确性和损失？感谢您的帮助并消除了我的困惑/误解。]]></description>
      <guid>https://stats.stackexchange.com/questions/647698/proper-usage-of-k-fold-cross-validation-and-finalizing-model</guid>
      <pubDate>Tue, 21 May 2024 14:55:45 GMT</pubDate>
    </item>
    <item>
      <title>模拟循环</title>
      <link>https://stats.stackexchange.com/questions/647696/simulate-cycles</link>
      <description><![CDATA[一辆自卸卡车将煤炭从矿井运输到铁路附近的卸货设施。在矿井装载过程结束后，卡车立即前往秤进行称重，从装载机到秤的运输时间很短。称重后，卡车前往位于铁路附近的卸货设施，卸货并返回矿井重新装载。此循环每天连续重复十二次，以满足所需的负载配额。
卡车的装载时间符合正态分布，平均值为 5.95 分钟，方差为 0.4475 分钟。称重是自动的，通常需要大约 1.1 分钟。表 3.1 给出了到卸货设施的行程时间的概率分布。卸载时间服从负指数分布，平均值为 3 分钟。从卸货设施返回矿山的时间取决于交通状况。从卸货设施到矿井的行程时间概率分布如表3.2所示。
从称重站到卸货设施的行程时间（以分钟为单位）
14 - 0.40 概率
15 - 0.24 概率
16 - 0.30 概率
17 - 0.05 概率
从卸货设施到矿井的行驶时间（以分钟为单位）
18 - 0.35 概率
20 - 0.35 概率
22 - 0.30 概率
将卡车装载、称重、前往卸货设施、卸货和返回矿场所需的总时间视为一个周期。
(i) 模拟 12 个周期并估计完成 12 个周期所需的总时间。
(ii) 重复 12 周期模拟 25 次，并计算 10 小时内完成 12 周期的概率？
(iii) 对于此业务流程，您会给管理层什么建议？提供数字证据来支持您的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/647696/simulate-cycles</guid>
      <pubDate>Tue, 21 May 2024 14:44:45 GMT</pubDate>
    </item>
    <item>
      <title>切尔诺夫绑在弦上</title>
      <link>https://stats.stackexchange.com/questions/647693/chernoff-bound-on-strings</link>
      <description><![CDATA[设 $x\in(0,1)^*$ 为二进制字符串。考虑 m 个样本索引 $i_1,i_2,\dots,i_m$ 均匀随机且彼此独立。每个 $i_j$ 都是从 $[|x|]$ 中独立均匀随机采样的。我们还表示 $x$ 的平均值为 $$\bar x=\frac{\sum_{k=1}^ {|x|}x_k}{|x|}.$$
假设我们给出概率 $$P[|\frac{\sum_{j=1}^{m}x_{i_j}}{|m|}-\bar x|&gt;\frac{\epsilon}{2}]&lt;\frac{1}{3}.$$
那我怎么写 $$\frac{\sum_{j=1}^{m}x_{i_j}}{|m|}=\\
\bar x \pm \frac{\epsilon}{2}\text{ 概率为 $\geq \frac{2}{3}$}?$$
我不明白等号 (=)。]]></description>
      <guid>https://stats.stackexchange.com/questions/647693/chernoff-bound-on-strings</guid>
      <pubDate>Tue, 21 May 2024 13:36:45 GMT</pubDate>
    </item>
    <item>
      <title>非正态分布残差和线性混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/647692/non-normally-distributed-residuals-and-linear-mixed-effects-models</link>
      <description><![CDATA[我正在使用一个相当小的数据集（来自 10 名参与者的 cca 150 DP），并尝试将注视持续时间建模为两个自变量的函数：具有两个级别的 1（偏差编码：0.5、-0.5）和 1具有三个级别的 IV（也使用具有 2 个对比度的偏差编码（C1：0.5，-0.5；C2：0.33，-0.66，0.33）。
因为我对固定效应和两个随机变量（房间和参与者）的影响感兴趣，所以我使用线性混合效应模型对数据进行建模。
问题是，无论因变量是原始变量还是对数转换变量，我的残差仍然呈非正态分布。我在使用 plot(model)、qqPlot() 目视检查残差以及在模型残差上运行 shapiro.test() 后声明了这一点。&lt; /p&gt;
我希望该模型成为假设检验和推理的坚实基础，但我不确定下一步如何进行。从我能找到的解决此问题的帖子中，我无法找到解决我的问题的方法。
我尝试遵循此处给出的建议：非问题-正态残差（lmer 函数），并用 Gamma 分布拟合 glmer，但我正在处理一个我不知道如何修复的错误：
eval(family$initialize, rho) 中的错误：
“Gamma”系列不允许使用非正值
编辑：我仍然想考虑值为 0 且据我所知为非正值的数据点。线性混合效应模型可以处理缺失问题，什么样的分析会更好，可以处理残差的非正态性？
注意：经过彻底检查，数据集中没有非正值，只有 0 值和正值。
如有任何建议，我们将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647692/non-normally-distributed-residuals-and-linear-mixed-effects-models</guid>
      <pubDate>Tue, 21 May 2024 13:11:23 GMT</pubDate>
    </item>
    <item>
      <title>我的模型给出的结果不一致</title>
      <link>https://stats.stackexchange.com/questions/647691/my-model-is-giving-inconsistent-results</link>
      <description><![CDATA[“我在只有 98 个点的数据集上运行了多项式多元回归模型。当我在不同的数据子集（训练和测试）上运行模型时。它给了我从负到正的 r2 值。我知道我的数据点数量较少。我想问我是否可以坚持以最高的正r2值运行。另外，如果以后需要运行该模型，如何保存该模型？因为当我关闭 r 窗口并再次运行代码时，我没有得到相同的 r2 值和结果，而是得到不同的最高正 r2”。
“我在 r 中工作，我也尝试了其他不同的模型，例如随机森林和 SVM。但我发现 PMLR 最好。但我得到的 r2 值不一致”。]]></description>
      <guid>https://stats.stackexchange.com/questions/647691/my-model-is-giving-inconsistent-results</guid>
      <pubDate>Tue, 21 May 2024 13:06:33 GMT</pubDate>
    </item>
    <item>
      <title>查看 X 变化和 Y 变化之间关联的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/647687/what-is-the-best-approach-to-look-at-association-between-change-in-x-and-change</link>
      <description><![CDATA[通过两次同步重复测量来分析两个变量变化之间关联的正确方法是什么？
我已经计算了变量的增量变化分数
X 和 Y（例如，ΔX = X_year1 - X_baseline 和 ΔY = Y_year1 - Y_baseline），然后查看这些变化分数之间的相关性。然而，我的结果显示与我的假设相反的关联。我怀疑均值回归可能会影响我的结果，但我还没有找到太多关于这种影响如何影响两个变量变化之间关联的信息。
更好的方法是计算“变化”吗？使用线性模型的残差，例如 X_year1 ~ X_baseline。这种方法还允许我通过将协变量添加到线性模型来调整协变量。
具体问题：

均值回归如何影响变化分数之间的相关性？
使用线性模型（例如 X_time2 ~ X_time1）的残差来分析变量变化是否是更合适的方法？
还有哪些其他推荐方法可以在控制基线值和潜在协变量的同时准确评估两个变量变化之间的关联？
如果您有三个与两个时间点，正确的方法是否会改变？

任何对相关文献的想法或参考都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/647687/what-is-the-best-approach-to-look-at-association-between-change-in-x-and-change</guid>
      <pubDate>Tue, 21 May 2024 12:02:45 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助解释交互效果</title>
      <link>https://stats.stackexchange.com/questions/647686/need-help-interpreting-interaction-effects</link>
      <description><![CDATA[我有两个分类自变量（类别：治疗前/治疗后 [A、B、C]）和二元响应。
我在 R 中的回归输出如下：
 估计标准。误差z值Pr(&gt;|z|)
(截距)-1.16220 0.14103 -8.241＜ 2e-16 ***
类别之后 0.89254 0.24876 3.588 0.000333 ***
治疗B -0.03485 0.20577 -0.169 0.865513
治疗C 0.29998 0.30781 0.975 0.329771
类别之后：治疗B -0.73438 0.37841 -1.941 0.052295 。
类别之后：治疗C -0.47215 0.56504 -0.836 0.403382

交互作用项不具有统计显着性。但是“之后”治疗A的“治疗A”与“之前”的治疗显着不同。对于治疗A。
我的理解是，如果交互项不显着，那么结果就不能解释为交互效应。然而，我很难看出这怎么不是一种相互作用：之前/之后的效果仅在治疗 A 中才明显。我应该如何解释这一点？
这是交互图：
]]></description>
      <guid>https://stats.stackexchange.com/questions/647686/need-help-interpreting-interaction-effects</guid>
      <pubDate>Tue, 21 May 2024 11:55:37 GMT</pubDate>
    </item>
    <item>
      <title>当存在发生率极低的竞争风险时，如何处理事件时间数据</title>
      <link>https://stats.stackexchange.com/questions/647685/how-to-handle-time-to-event-data-when-there-is-a-competing-risk-with-very-low-in</link>
      <description><![CDATA[我正在分析事件发生时间数据。主要结果是出院时间，并且存在死亡风险。竞争风险模型似乎是合适的，但我想知道如果第二个事件的发生率非常低：经历该事件的样本少于 5%，这是否仍然适用。
我正在考虑两种可能的替代方案：

使用特定原因模型并审查死亡。
假设估计策略：使用特定原因模型并将死亡时间计为缺失并估算出院时间。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647685/how-to-handle-time-to-event-data-when-there-is-a-competing-risk-with-very-low-in</guid>
      <pubDate>Tue, 21 May 2024 11:49:06 GMT</pubDate>
    </item>
    <item>
      <title>解释 LMM 中固定效应的相关性</title>
      <link>https://stats.stackexchange.com/questions/647681/interpreting-the-correlation-of-fixed-effects-in-a-lmm</link>
      <description><![CDATA[我计算了一个线性混合模型，其中因变量“兴趣”为这是按照 1-7 的等级和三个固定效应威胁级别、极端和超人性进行测量的，这些因素都是具有 2 个级别（0 和 1）及其相互作用的因素。这是我在 R 中的输出：
通过最大似然拟合线性混合模型。 t 检验使用 Satterthwaite 方法 [&#39;lmerModLmerTest&#39;]
公式：兴趣~威胁等级 * 极限 * 超人性 + (1 | ID) + (1 | items_recode)
   数据：subset_data.long

     AIC BIC logLik 偏差 df.resid
  3691.9 3746.3 -1835.0 3669.9 1029

缩放残差：
    最小 1Q 中值 3Q 最大
-2.9717 -0.6725 0.0326 0.6630 2.8920

随机效果：
 组名称方差标准差
 ID（截距） 1.0635 1.0313
 items_recode（拦截）0.1141 0.3377
 残差 1.5537 1.2465
obs数量：1040，组：ID，130；项目重新编码，8

固定效果：
                                        估计标准。误差df t值Pr(&gt;|t|)
（截距）3.01350 0.23121 22.21688 13.034 6.94e-12 ***
威胁级别1 -0.22480 0.23895 263.69178 -0.941 0.3477
肢体1 2.11180 0.28221 12.57909 7.483 5.61e-06 ***
超人性1 0.01503 0.15155 924.30143 0.099 0.9210
威胁级别1：肢体1 0.16775 0.22866 927.72532 0.734 0.4634
威胁级别1：超人性1 0.15327 0.22966 929.31973 0.667 0.5047
肢体1：超人1 -0.43173 0.21860 938.21094 -1.975 0.0486 *
威胁级别1：肢体1：超人1 -0.10793 0.33440 948.21803 -0.323 0.7470
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应的相关性：
            （内部）thrtl1 extrm1 sprhm1 thrtlvl1:x1 thrtlvl1:s1 ext1:1
威胁等级1 -0.452
肢体1 -0.600 0.158
超级1 -0.308 0.298 0.266
thrtlvl1:x1 0.202 -0.453 -0.350 -0.329
thrtlvl1:s1 0.203 -0.453 -0.176 -0.661 0.509
外部1:s1 0.224 -0.217 -0.387 -0.727 0.477 0.481
thrtlv1:1:1 -0.146 0.332 0.253 0.476 -0.731 -0.732 -0.653

我很难理解固定效应的相关性，有时固定效应的相关性非常高。到目前为止，我的谷歌搜索也没有帮助我。有人可以解释一下这些相关性意味着什么吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647681/interpreting-the-correlation-of-fixed-effects-in-a-lmm</guid>
      <pubDate>Tue, 21 May 2024 10:48:57 GMT</pubDate>
    </item>
    <item>
      <title>将 tf.keras.metrics.Precision 添加到 TensorFlow 中的模型指标时出现 ValueError [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647680/valueerror-when-adding-tf-keras-metrics-precision-to-model-metrics-in-tensorflow</link>
      <description><![CDATA[我正在尝试使用 MobileNet 在自定义数据集上应用迁移学习。我的代码工作正常，直到我将 tf.keras.metrics.Precision(name=“ precision”) 添加到模型的指标中。添加此指标后，我在 model.fit 期间遇到以下错误：
update_confusion_matrix_variables y_pred.shape.assert_is_兼容_with(y_true.shape) ValueError：形状（无，4）和（无，1）不兼容
相关代码块：
导入tensorflow为tf
从tensorflow.keras.utils导入image_dataset_from_directory作为get_dataset

图像大小 = (224, 224)
preprocessing_layer = tf.keras.applications.mobilenet.preprocess_input
img_shape = img_size + (3,)

base_model = tf.keras.applications.MobileNet(
    输入形状=img_形状，
    include_top=假，
    权重=&#39;imagenet&#39;,
）

批量大小 = 32
训练集 = 获取数据集（
    &#39;某条路&#39;,
    随机播放=真，
    批量大小=批量大小，
    图像大小=img_大小，
）

班级名称 = train_set.班级名称
num_classes = len(类名)

base_model.trainable = False
global_average_layer = tf.keras.layers.GlobalAveragePooling2D()

输入 = tf.keras.Input(shape=img_shape)
k = 预处理层（输入）
k = base_model(k, 训练=False)
k = 全局平均层(k)
k = tf.keras.layers.Dropout(0.2)(k)

Prediction_layer = tf.keras.layers.Dense(
    类数，
    激活=“softmax”
）
输出=预测层（k）

模型= tf.keras.Model（输入，输出）

模型.编译(
    优化器=tf.keras.optimizers.Adam(learning_rate=0.0001),
    损失=tf.keras.losses.SparseCategoricalCrossentropy(),
    指标=[
        tf.keras.metrics.SparseCategoricalAccuracy(name=&#39;accuracy&#39;),
        tf.keras.metrics.Precision(name=“精度”),
    ]
）

自动调谐 = tf.data.AUTOTUNE

train_set = train_set.prefetch(buffer_size=AUTOTUNE)

历元 = 1
历史=模型.fit(
    动车组，
    纪元=纪元，
）

数据集被组织成子目录，其中每个子目录名称都是类标签。有四个类标签。
数据集加载和预处理似乎工作正常，因为模型在没有 tf.keras.metrics.Precision 指标的情况下进行训练。
在添加精度指标时会出现这个问题。
epochs 出于实验目的特意设置为 1。]]></description>
      <guid>https://stats.stackexchange.com/questions/647680/valueerror-when-adding-tf-keras-metrics-precision-to-model-metrics-in-tensorflow</guid>
      <pubDate>Tue, 21 May 2024 10:18:04 GMT</pubDate>
    </item>
    <item>
      <title>非正态分布相关小样本量的 t 检验[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647679/t-test-for-non-normally-distributed-dependent-small-sample-size</link>
      <description><![CDATA[我试图测试治疗前后样本点的显着变化，但样本点很少，而且治疗后和治疗前组都不是正态分布的。我能怎么办呢，我有点失落。
TIA]]></description>
      <guid>https://stats.stackexchange.com/questions/647679/t-test-for-non-normally-distributed-dependent-small-sample-size</guid>
      <pubDate>Tue, 21 May 2024 10:14:01 GMT</pubDate>
    </item>
    <item>
      <title>调查样本量</title>
      <link>https://stats.stackexchange.com/questions/647678/sample-size-for-survey</link>
      <description><![CDATA[我的兴趣是对 1700 人进行一项具有统计意义的调查，这些调查可以分为不同的类别，因此每个人只属于一个类别。
我有两类兴趣：Cat1 由 700 人组成，Cat2 由 200 人组成。
我的调查应该由足够多的人完成，以便这两类人中的每一组都有显着的代表性，置信度为 95%，误差幅度为 5%，尽管这些值可以更改。
我知道误差幅度越大，样本就越小。到什么值才合理？
此外，考虑总体有限或无限对样本大小有何影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/647678/sample-size-for-survey</guid>
      <pubDate>Tue, 21 May 2024 10:12:50 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 的 RMSE 小于 SARIMA，该选择哪一个？</title>
      <link>https://stats.stackexchange.com/questions/647677/the-rmse-for-arima-is-less-than-sarima-which-one-to-prefer</link>
      <description><![CDATA[虽然用原始数据（第二个）绘制去季节值，但没有太大差异。阶数为 ARIMA(1,1,0) 和 SARIMA((1,1,0),(7,1,0,12))。虽然评估 ARIMA 的 RMSE 小于 SARIMA。
可以假设数据没有很强的季节性吗？或者可能是因为过度拟合导致 SARIMA 表现不佳？
另外，我应该选择哪种型号？ （原油价格时间序列分析（印度篮子）。
这里还有 RMSE：
rollingARIMA=6.1377,
rollSARIMA= 6.6290
]]></description>
      <guid>https://stats.stackexchange.com/questions/647677/the-rmse-for-arima-is-less-than-sarima-which-one-to-prefer</guid>
      <pubDate>Tue, 21 May 2024 10:04:57 GMT</pubDate>
    </item>
    <item>
      <title>基础模型 ANOVA 和 Kruskal-Wallis</title>
      <link>https://stats.stackexchange.com/questions/647667/underlying-model-anova-and-kruskal-wallis</link>
      <description><![CDATA[单向方差分析 ($Y_{ij}= u + t_i + E_{ij}$) 的基础模型是否与 Kruskal-Wallis 检验完全相同因为 KW 是非参数方差分析，还是有不同的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/647667/underlying-model-anova-and-kruskal-wallis</guid>
      <pubDate>Tue, 21 May 2024 04:28:39 GMT</pubDate>
    </item>
    <item>
      <title>在匹配中，上限混杂因素是改善与高度倾斜的连续混杂因素匹配的平衡的合法方法吗？</title>
      <link>https://stats.stackexchange.com/questions/647666/in-matching-are-capped-confounders-a-legitimate-method-of-improving-balance-for</link>
      <description><![CDATA[在匹配（或类似的混杂控制方法，例如加权）中，“上限度量”是“合法的”改善高度倾斜的连续混杂因素平衡的方法？
上限指标是在线实验中常用的方差减少方法（Kohavi et al., 2014），但用于结果变量（我不熟悉 CUPED 中是否使用上限）。上限是指将某个百分位数（例如 99）之后的所有值设为相同。最终我明白这是一种偏差-方差权衡，并且平衡减少方法已经存在，例如卡尺（偏差的权衡），但在某些情况下，我认为在处理非常高的偏差时，上限也是合理的（&gt;20+ 偏度系数）由于极右尾部，但我想检查文献中是否有一些合理性，以便我不使用无效的方法（我还无法找到有关此主题的任何内容）。&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/647666/in-matching-are-capped-confounders-a-legitimate-method-of-improving-balance-for</guid>
      <pubDate>Tue, 21 May 2024 04:24:19 GMT</pubDate>
    </item>
    </channel>
</rss>