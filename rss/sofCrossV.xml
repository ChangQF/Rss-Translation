<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 12 Jan 2025 01:23:01 GMT</lastBuildDate>
    <item>
      <title>分层抽样和可变大小聚类的置信区间</title>
      <link>https://stats.stackexchange.com/questions/659897/confidence-intervals-for-stratified-sampling-and-variable-sized-clusters</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659897/confidence-intervals-for-stratified-sampling-and-variable-sized-clusters</guid>
      <pubDate>Sun, 12 Jan 2025 00:25:49 GMT</pubDate>
    </item>
    <item>
      <title>对已进行 FDR 校正的数据批次进行 FDR 校正</title>
      <link>https://stats.stackexchange.com/questions/659893/fdr-correction-on-batches-of-already-fdr-corrected-data</link>
      <description><![CDATA[背景：
这个问题来自组学背景，其中大量数据有时需要将整个数据集分成几批，并用一些分析软件分别处理它们。
示例：
对于此示例，请考虑两个大小相等的测量数据批次。在每个批次中，可以用各种置信度分数识别 50000 个分子。在 1% 阈值下应用错误发现校正后，每个数据集中仍保留 1000 个具有显著 q 值的分子。任务是重新组合两个批次并获得一个仍具有 1% FDR 的数据集。
问题：
我的问题是，BH 校正（或任何其他类型的调整）是否可用于重新校正批次 q 值并允许组合批次而不会夸大错误发现？任何有关现有实现和/或统计背景的评论都将不胜感激。
示例方法：
我能想到一种方法，其中从每个批次中取出 50000 个 q 值并对整个 100000 个值集运行 BH 校正，同时取 q 值 &lt; 0.01。这基本上相当于解释批次 q 值，就像解释单个数据集中的原始 p 值一样。]]></description>
      <guid>https://stats.stackexchange.com/questions/659893/fdr-correction-on-batches-of-already-fdr-corrected-data</guid>
      <pubDate>Sat, 11 Jan 2025 20:52:03 GMT</pubDate>
    </item>
    <item>
      <title>Grover 算法是否比同时进行的贝叶斯更新更具优势？</title>
      <link>https://stats.stackexchange.com/questions/659892/does-grover-s-algorithm-offer-advantages-over-simultaneous-bayesian-updates</link>
      <description><![CDATA[最近我一直在学习 Grover 算法，该算法用于量子计算中的非结构化搜索。该算法的思路是这样的：您有一个大型未排序列表，并且想要找到某个东西（称为目标）的位置。您假设目标在列表中，但您不知道它在列表中的位置，并且想要找到这个位置。在开始搜索之前，您为列表中的每个项目分配相等的概率（从技术上讲，您为每个项目分配一个幅度，但平方幅度对应于概率）。例如，如果列表中有 100 个项目，则每个项目的（先验）概率为 1%。您可以通过使用这些概率初始化一个 100 个元素的向量来实现这一点。然后，您执行一系列计算来更新此概率向量，并多次执行这些计算（大约是列表大小的平方根，在本例中为 10，即 100 的平方根），直到（希望）表示目标的向量元素的概率很大（理想情况下为 1）。然后，您使用概率作为权重对向量索引进行采样（量子计算和物理学家称之为“测量”），希望您获得的采样向量索引对应于包含目标的向量元素。
Grover 算法（在某些条件下）比传统计算替代方案的速度快了二次。其中一个原因是 sqrt{100}=10 向量更新中的每一个实际上都会同时更新所有 100 个向量元素，这有时被称为量子并行性。
然而，我认为这种方法的精神与贝叶斯更新非常相似甚至相同。我到底错过了什么？例如，我曾经研究过一种贝叶斯聚类算法，我们逐一更新每个观测与其他 $N - 1$ 个观测聚类的概率，并将结果存储在一个向量中。显然，我应该考虑将该更新计算重新表述为单个操作，然后我可以同时更新所有概率。除了这种并行性（这似乎并不是 Grover 算法或量子计算所独有的）之外，Grover 算法是否还有一些额外的东西可以使其比某些可以同时更新所有向量元素的贝叶斯计算更具优势？
顺便说一句，这个论点可以扩展到任何阶的张量，而不仅仅是向量，尽管合理的更新计算可能很难得出。]]></description>
      <guid>https://stats.stackexchange.com/questions/659892/does-grover-s-algorithm-offer-advantages-over-simultaneous-bayesian-updates</guid>
      <pubDate>Sat, 11 Jan 2025 20:42:17 GMT</pubDate>
    </item>
    <item>
      <title>跨维度网格上的后验</title>
      <link>https://stats.stackexchange.com/questions/659890/posterior-on-a-grid-across-dimensions</link>
      <description><![CDATA[我已经注意到，虽然每维 100 个点可以很好地近似一维后验，但当你进入高维（3 维或 4 维）时，我通常必须增加每维的点数才能获得良好的近似值。这一定是由于“高维欧几里得空间的广阔性”，正如维基百科的距离函数部分所指出的那样。
有没有估计一下，每维应该使用多少个点才能正确覆盖 N 维的整个空间？]]></description>
      <guid>https://stats.stackexchange.com/questions/659890/posterior-on-a-grid-across-dimensions</guid>
      <pubDate>Sat, 11 Jan 2025 18:39:46 GMT</pubDate>
    </item>
    <item>
      <title>并行化蒙特卡罗模拟最简单的方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/659889/what-is-the-easist-way-to-parallelize-a-monte-carlo-simulation</link>
      <description><![CDATA[据我所知，并行化蒙特卡罗模拟归结为将问题分解为子问题，并行运行它们以产生多个马尔可夫链，最后将马尔可夫链连接在一起。
现在的问题是，没有直接的方法来连接马尔可夫链。
并行化蒙特卡罗模拟最简单的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659889/what-is-the-easist-way-to-parallelize-a-monte-carlo-simulation</guid>
      <pubDate>Sat, 11 Jan 2025 18:02:09 GMT</pubDate>
    </item>
    <item>
      <title>固定效应面板回归中的特征选择和异常值检测</title>
      <link>https://stats.stackexchange.com/questions/659888/feature-selection-and-outlier-detection-in-panel-regression-with-fixed-effects</link>
      <description><![CDATA[我试图拟合以下具有固定实体效应的面板回归
$$Y_{it} = \alpha_i + \sum_j \beta_jX^{(j)}_{it} + \epsilon_{it},$$
其中索引$j$标记了不同的特征。我知道其中一些特征对所有实体都很重要（领域知识），而有些可能只对某些实体很重要。此外，某些特征 $X^{(j)}_{it}$ 可能包含某些实体的错误数据（或极端异常值）。
我正在寻找此模型的诊断方法，以便能够检测：

某些特征仅与面板中的一小部分实体相关，并识别该子集；
某些特征包含异常值或高杠杆点，并识别它们。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659888/feature-selection-and-outlier-detection-in-panel-regression-with-fixed-effects</guid>
      <pubDate>Sat, 11 Jan 2025 17:54:42 GMT</pubDate>
    </item>
    <item>
      <title>非参数检验显著但回归不显著</title>
      <link>https://stats.stackexchange.com/questions/659886/non-parametric-test-significant-but-regression-not-significant</link>
      <description><![CDATA[我正在研究测试分数与某些指标的线性回归，并注意到在某些情况下测试分数存在上限效应，因此回归似乎不合适。我附上了一个示例图，尽管回归是显著的，但从图中可以明显看出它没有意义。
有人告诉我，我可以另外计算 Spearman 等级相关系数，并且只接受 Spearman 检验显著的显著回归结果，因为它比回归更保守，并且丢弃 Spearman 检验不显著时的显著回归结果。但是，如果相反的情况是回归不显著但 Spearman 检验显著，该怎么办？我该如何报告这个结果？
提前谢谢您！
]]></description>
      <guid>https://stats.stackexchange.com/questions/659886/non-parametric-test-significant-but-regression-not-significant</guid>
      <pubDate>Sat, 11 Jan 2025 16:36:45 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯与频率派 A/B 测试</title>
      <link>https://stats.stackexchange.com/questions/659882/bayesian-vs-frequentist-a-b-testing</link>
      <description><![CDATA[我是一名统计学消费者，正在阅读一篇软文，我发现它很直接，信息量很大，所以我希望它也是正确的。它讲述了一些关于贝叶斯统计学和频率统计学在实际使用中所谓差异的常见误解，比如在线 A/B 测试实验的偷看和提前结束。我同意其中的大部分内容，但有一点我很好奇。文章说

在两个变体（对照和治疗）的情况下，当用户数量足够大时，单尾 p 值几乎与对照优于治疗的贝叶斯概率相同，记为 P(A&gt;B| 数据) =1-P(B&gt;A| 数据)。在 A/B 测试中，较低的单尾 p 值和较低的 P(A&gt;B| 数据)（相当于较高的 P(B&gt;A| 数据)）表明处理组优于对照组。这两个指标几乎相同，这意味着从技术上讲，基于 P(B&gt;A | 数据) 的提前停止相当于基于 p 值未能维持 I 类错误率（假阳性率）的提前停止。

在“偷看”和提前结束实验的情况下，提前停止是否恰恰不是“当用户数量足够大时”的“单尾 p 值几乎与贝叶斯概率相同”的情况？这对他的论点重要吗？
我正在努力思考这个问题。似乎可以，“提前停止”有点意味着“对于我们所针对的置信度而言，样本不足”，但这对他的论点并不重要。贝叶斯估计器和频率估计器的小样本行为在这里有显著的不同吗？这甚至是一个相关的问题吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659882/bayesian-vs-frequentist-a-b-testing</guid>
      <pubDate>Sat, 11 Jan 2025 15:19:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 SARIMA 模型中，时间序列的差分无助于使其平稳？</title>
      <link>https://stats.stackexchange.com/questions/659898/why-does-differencing-of-time-series-not-help-to-make-it-stationary-in-the-sarim</link>
      <description><![CDATA[我在 SARIMA 模型中差分后无法获得平稳时间序列。
我是时间序列分析的初学者，但我读到时间序列 Y_t = \nabla^d (1-L^s)^D X_t 应该是平稳时间序列。然而，在用值 s=12 和不同的 d 和 D 值进行差分后，我的时间序列似乎不是平稳分析 ACF 函数。我也尝试过一开始 lambda=0 的 Box–Cox 变换，但同样没用。
这是我的原始数据
原始数据 (data_ts)
它是非平稳的。
经过 lambda = 0 的 Box-Cox 变换之后
data_bc &lt;- BoxCox(data_ts, lambda=0)

Box-Cox 变换之后
这是 ACF 函数：
ACF 函数
然后我尝试对我的时间序列进行差分，结果如下：
ts_plot(diff(data_bc))
Acf(diff(data_bc))

差分后的时间序列图。
我的时间的 ACF系列。
在我看来，它可以是静止的，但从 ACF 来看，它不是。可能是因为季节性？因此，我尝试对滞后 s=12 的时间序列进行差分，然后再次进行差分（s=12、d=1、D=1）。
ts_plot(diff(diff(data_bc, lag=12)))
Acf(diff(diff(data_bc, lag=12)))

新时间序列
ACF
再次分析 ACF 函数，它似乎不是平稳的。我错了吗？那我该怎么办？
Box-Cox 变换、差分、消除季节性。我希望获得平稳的时间序列。]]></description>
      <guid>https://stats.stackexchange.com/questions/659898/why-does-differencing-of-time-series-not-help-to-make-it-stationary-in-the-sarim</guid>
      <pubDate>Sat, 11 Jan 2025 14:36:19 GMT</pubDate>
    </item>
    <item>
      <title>联合高斯的充分条件</title>
      <link>https://stats.stackexchange.com/questions/659878/sufficient-condition-for-jointly-gaussian</link>
      <description><![CDATA[设 $Z = f(X) + V$，其中 $X$ 和 $V$ 为独立的高斯随机变量，且 $f:\mathbb{R}\to \mathbb{R}$。
联合 $(Z,X)$ 为高斯的必要充分条件是什么？我怀疑 $f$ 应该是仿射线性的，比如 $ax + b$，但我该如何正式证明这一点呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/659878/sufficient-condition-for-jointly-gaussian</guid>
      <pubDate>Sat, 11 Jan 2025 12:55:03 GMT</pubDate>
    </item>
    <item>
      <title>无法拟合高斯混合模型，估计错误参数</title>
      <link>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</link>
      <description><![CDATA[下面的测试从高斯混合模型生成样本，然后对其进行拟合。
拟合模型与原始模型完全不同。为什么？这怎么可能呢，结果不只是稍微不同——错误是巨大的。

原文：weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2]
拟合：weights=[0.525, 0.475], means=[-0.617, 0.716], sigmas=[1.434, 1.443]
代码（带图的完整代码)
import numpy as np
from sklearn.mixture import GaussianMixture

def fit_normal_mixture(*, n_components, values, random_state, n_init):
values = np.array(values).reshape(-1, 1) # 转换为 2D 数组
nmm = GaussianMixture(n_components, covariance_type=&#39;diag&#39;, random_state=random_state, n_init=n_init)
nmm.fit(values)
means = nmm.means_.flatten().tolist()
sigmas = np.sqrt(nmm.covariances_.flatten()).tolist()
weights = nmm.weights_.flatten().tolist()
return weights, means, sigmas

def sample_normal_mixture(*, weights, means, sigmas, n):
if not np.isclose(sum(weights), 1):
raise ValueError(&quot;Weights must sum to 1&quot;)
components = np.random.choice(len(weights), size=n, p=weights)
return np.random.normal(loc=np.array(means)[components], scale=np.array(sigmas)[components])

# 测试
if __name__ == &#39;__main__&#39;:
# 从正态混合模型生成样本
nmm_sample = sample_normal_mixture(weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2], n=10000)

# 将样本拟合到正态混合模型
print(fit_normal_mixture(n_components=2, values=nmm_sample, random_state=0, n_init = 10))

附言：是否可以告诉拟合算法使用 0 作为平均值？]]></description>
      <guid>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</guid>
      <pubDate>Sat, 11 Jan 2025 06:59:18 GMT</pubDate>
    </item>
    <item>
      <title>偏最小二乘回归 - 解释 X 的方差高于 100%</title>
      <link>https://stats.stackexchange.com/questions/659831/partial-least-squares-regression-explained-variance-for-x-above-100</link>
      <description><![CDATA[我正在使用 58 个参数（股票价格、历史回报、利率、国债收益率、商品……等）对标准普尔 500 指数的每日回报进行建模。
我使用偏最小二乘法创建了一个回归模型。
我的模型总共有 58 个组件，从 50 个组件开始，独立变量的解释方差超过 100%。
可能是什么原因造成的？
如果您需要更多信息，请告诉我。
编辑：
我使用 pls 包中的 plsr 函数实现了 PLSR：
dfAnalysisNumeric = read.csv(&quot;dfAnalysisNumeric.csv&quot;)[,-1]

plsrModel = plsr(indexReturn_t~.,data=dfAnalysisNumeric,
validation =&quot;CV&quot;,
scale=TRUE,
center=TRUE)
summary(plsrModel)

dfAnalysisNumeric 是我的数据集。我将其导出为 csv 文件。
这是链接：https://mega.nz/file/3ZsWDJpa#oueRGUqrVnyWqEIMdvU0mZYBjkAW57xklxkjbpTD_nQ
]]></description>
      <guid>https://stats.stackexchange.com/questions/659831/partial-least-squares-regression-explained-variance-for-x-above-100</guid>
      <pubDate>Fri, 10 Jan 2025 16:48:36 GMT</pubDate>
    </item>
    <item>
      <title>对于 OLS 假设，随机样本是否需要 IID</title>
      <link>https://stats.stackexchange.com/questions/659821/does-random-sample-need-to-be-iid-for-ols-assumption</link>
      <description><![CDATA[假设要为 OLS 回归 创建样本，我分 2 个阶段 在不同的总体中抽样数据。例如，在一个总体中，我有 5000 个数据点，我从该总体中选择了 1000 个数据。而在另一个总体中，有 3000 个数据点，我从该总体中选择了 500 个数据。
然后我 组合 2 个抽样数据集（因此，组合数据集有 1500 个数据点），并构建横截面 OLS 回归。
我的问题是，在这种情况下，随机样本的 OLS 假设 是否得到满足？对于随机样本，我们是否需要数据为 IID？
在另一个抽样选项中，我有相同的 2 个数据总体。但是对于 1 个样本，我进行了 分层抽样，而对于另一个样本，我进行了 简单随机抽样。然后 合并 2 个抽样数据集。
在进行 OLS 回归时，随机样本假设在这种抽样方法下是否成立？
随机样本假设取自 Wooldridge 的计量经济学入门。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659821/does-random-sample-need-to-be-iid-for-ols-assumption</guid>
      <pubDate>Fri, 10 Jan 2025 11:50:05 GMT</pubDate>
    </item>
    <item>
      <title>R 中 Frank's Copula 负二项式模型中 Theta 参数发散问题</title>
      <link>https://stats.stackexchange.com/questions/659647/issue-with-diverging-theta-parameter-in-negative-binomial-models-with-franks-co</link>
      <description><![CDATA[我尝试使用负二项分布结合 Frank 的 copula 来对足球比赛结果进行建模，以建立依赖结构。每支球队都被分配了单独的进攻和防守参数，并且有主场和客场进球的离散参数，以及 Frank 的 copula 的 theta 参数。
我的方法受到 McHale、Ian 和 Phil Scarf 的论文“国际足球比赛中对方球队进球依赖关系建模”中描述的方法的启发（统计建模，11.3（2011）：219-236）。但是，我没有使用基于 FIFA 世界排名位置差异的参数来对进球依赖关系进行建模（如原始研究），而是对其进行了修改，使用单独的球队参数进行进攻和防守。
不幸的是，在优化过程中，theta 参数在几次迭代后开始发散，我不知道如何解决这个问题。我怀疑 Frank 的 copula 的 theta 参数可能需要限制在特定范围内以确保数值稳定性。但是，我使用的优化函数 (nlm) 不直接支持参数约束，这使得这很难实现。
我的方法：

示例数据：

set.seed(123)

data_model &lt;- data.frame(
Heim = sample(c(&quot;Team A&quot;, &quot;Team B&quot;, &quot;Team C&quot;, &quot;Team D&quot;), 100, 
replace = TRUE),
Gast = sample(c(&quot;Team A&quot;, &quot;Team B&quot;, &quot;Team C&quot;, &quot;Team D&quot;), 100, 
replace = TRUE),
ToreHeim = rpois(100, lambda = 1.5), # 主队进球
ToreGast = rpois(100, lambda = 1.2) # 客队进球
)

# 删除主队与客队平分的比赛
data_model &lt;- data_model[data_model$Heim != data_model$Gast, ]


模型函数：

negloglik_double_nb_copula &lt;- function(params, goals_home, 
goals_visitor, team_home, team_visitor, param_skeleton) {
plist &lt;- relist(params, param_skeleton)
plist$defense &lt;- c(sum(plist$defense)*-1, plist$defense)
names(plist$defense)[1] &lt;-名称（plist$attack[1]）

lambda_home &lt;- exp（plist$attack[team_home] + 
plist$defense[team_visitor] + plist$home）
lambda_visitor &lt;- exp（plist$attack[team_visitor] + 
plist$defense[team_home]）

m1 &lt;- exp（plist$m1）
m2 &lt;- exp（plist$m2）
theta &lt;- exp（plist$theta）

log_lik_home &lt;- dnbinom（goals_home，mu = lambda_home，
size = m1^(-1)，log = FALSE）
log_lik_visitor &lt;- dnbinom(goals_visitor, mu = lambda_visitor, 
size = m2^(-1), log = FALSE)
log_lik_copula &lt;- log(frank_copula_density(log_lik_home, 
log_lik_visitor, theta))

log_lik &lt;- sum(log_lik_copula)
return(log_lik * -1)
}

frank_copula_density &lt;- function(p_home, p_visitor, theta) {
num &lt;- theta * exp(-theta * (p_home + p_visitor)) * 
(1 - exp(-theta))
denom &lt;- ((1 - exp(-theta * p_home)) * 
(1 - exp(-theta * p_visitor)) + exp(-theta) - 1)^2
return(num / denom)
}



初始参数：

parameter_list_copula &lt;- list(
attack = rep(0.2, n_teams),
defense = rep(-0.01, n_teams-1),
home = 0.1,
m1 = 0.1,
m2 = 0.15,
theta = 0.5
)

names(parameter_list_copula$attack) &lt;- all_teams
names(parameter_list_copula$defense) &lt;- all_teams[-1]



优化：

nlm_nb_copula &lt;- nlm(negloglik_double_nb_copula, 
unlist(parameter_list_copula), 
goals_home = data_model$ToreHeim,
goals_visitor = data_model$ToreGast,
team_home = data_model$Heim, 
team_visitor = data_model$Gast,
param_skeleton = param_list_copula, 
print.level = 2, 
iterlim = 10000, hessian = FALSE)

尽管设置了合理的起始值，但经过几次迭代后，优化结果在 theta 参数上出现分歧。
切换到支持参数约束的优化方法（例如，使用带有框约束的 optim）是否有意义？或者有其他推荐的策略来解决这个问题？
任何稳定优化的建议或改进该模型的见解都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659647/issue-with-diverging-theta-parameter-in-negative-binomial-models-with-franks-co</guid>
      <pubDate>Sun, 05 Jan 2025 22:58:36 GMT</pubDate>
    </item>
    <item>
      <title>结合多个调查设计对象的年份，何时适当使用交互项</title>
      <link>https://stats.stackexchange.com/questions/659458/combining-years-for-multiple-survey-design-object-when-to-appropriately-use-inte</link>
      <description><![CDATA[我正在使用 KID（儿童住院数据库）并使用 R 中的调查包。我有两个问题

何时使用 Strata 和 PSU 的交互项：
KID 数据库包含每年重新采样的 PSU（医院），而 Strata 包括 10% 的健康新生儿出院和 80% 的其他出院。
我不确定何时在定义 svydesign() 的 id 和 strata 参数时使用交互项。

id 参数应该使用 ~ PSU 还是 ~ interaction(PSU, YEAR) 来解释医院的年度重新采样？
strata 参数应该使用 ~ strata 还是 ~ interaction(strata, YEAR)？
我想确保设计反映了调查结构。

子集化后是否可以合并 survey.design 对象？还是需要先合并原始数据框，创建一个调查设计对象，然后再子集化？

例如，如果我每年按人口统计组对 survey.design 对象进行子集化，是否可以合并生成的对象？]]></description>
      <guid>https://stats.stackexchange.com/questions/659458/combining-years-for-multiple-survey-design-object-when-to-appropriately-use-inte</guid>
      <pubDate>Thu, 02 Jan 2025 16:44:23 GMT</pubDate>
    </item>
    </channel>
</rss>