<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 13 May 2024 06:20:14 GMT</lastBuildDate>
    <item>
      <title>什么是重要性抽样中的提案分布</title>
      <link>https://stats.stackexchange.com/questions/647121/what-is-proposal-distribution-in-importance-sampling</link>
      <description><![CDATA[我想用一个简单的例子来学习重要性采样。考虑以下使用 python 实现此采样的示例代码。我读到我们修复了证据，所以在这里我们修复“y” （带雨伞）为 True，如果我们看到有人带雨伞，则希望得到晴天的概率。我不明白为什么它使用均匀分布来生成晴天和雨天样本，我希望使用先验概率来生成它们，然后根据“y”的概率来调整它们在每个样本中。你能解释一下吗？
随机导入

# 定义概率
p_sunny = 0.7
p_雨= 0.3
p_y_given_sunny = 0.2
p_y_given_rainy = 0.8

# 使用提案分布生成 10 个样本
样本=[]
对于范围（10）内的 _：
    # 来自提案分布的样本 X
    x_sample = random.choice([&#39;晴天&#39;, &#39;雨天&#39;])
    
    # 根据证据计算权重 Y = yes
    如果 x_sample == &#39;晴朗&#39;:
        重量 = p_sunny * p_y_given_sunny
    别的：
        重量 = p_rainy * p_y_given_rainy
    
    样本.append((x_sample, 权重))

# 标准化权重
Total_weight = sum(w 为 _, w 为样本)
Normalized_samples = [(x, w/total_weight) 对于样本中的 x, w]

print(&quot;生成的样本：&quot;)
对于 x，归一化样本中的权重：
    print(f&quot;X = {x}, 权重 = {权重:.4f}&quot;)

# 计算后验概率
terior_sunny = sum(x 的权重，如果 x == &#39;sunny&#39; 则归一化样本中的权重)
terior_rainy = sum(x 的权重，如果 x == &#39;rainy&#39; 则归一化样本中的权重)

print(&quot;\n后验概率:&quot;)
print(f&quot;P(X = 晴天 | Y = 是) = {posterior_sunny:.4f}&quot;)
print(f&quot;P(X = 下雨 | Y = 是) = {posterior_rainy:.4f}&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/647121/what-is-proposal-distribution-in-importance-sampling</guid>
      <pubDate>Mon, 13 May 2024 06:01:26 GMT</pubDate>
    </item>
    <item>
      <title>我可以在 softmax 之前使用 Tanh 进行二元分类吗？</title>
      <link>https://stats.stackexchange.com/questions/647119/can-i-use-tanh-before-softmax-for-binary-classification</link>
      <description><![CDATA[我正在研究使用神经网络进行金融数据的二元分类任务。输出结果是二维的，如[[0.5,0.5],[0.1,09]]。在只有2000个小样本的情况下，我发现训练非常困难，经常遇到损失和准确率不下降的情况。然而，当我在输出层的softmax之前添加Tanh时，结果表现得非常好。为什么会发生这种情况？
我问了GPT4，它告诉我这样做会限制基本模型的输出，而且由于输出是对称的，这可能对不稳定的模型有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/647119/can-i-use-tanh-before-softmax-for-binary-classification</guid>
      <pubDate>Mon, 13 May 2024 03:52:51 GMT</pubDate>
    </item>
    <item>
      <title>当我们谈论一般可能性时......我们是在谈论“联合可能性”还是“条件可能性”？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/647115/when-we-talk-about-the-likelihood-in-general-are-we-talking-about-a-joint-l</link>
      <description><![CDATA[我对此感到困惑。
假设我们收集一些数据并相信它来自正态分布。为了估计该正态分布的参数（mu、sigma），我们创建了 MLE 的似然函数。但是当谈论这个似然函数时，哪个是正确的？

联合：观察这组数据以及可能产生该数据的参数的可能性？

$$L_1(X = x_1 ... x_n, \mu, \sigma)$$

条件：在给定一组特定参数的情况下观察这组数据的可能性？

$$L_2(X = x_1 ... x_n| \mu, \sigma)$$
我认为第二个说法是正确的。我们感兴趣的是在给定一些参数的情况下观察这组数据的可能性......然后估计这些参数最有可能是什么（相对于收集的数据）。
这是有道理的，因为概率分布描述了在给定（即有条件）一组预先确定的参数的情况下观察某些值范围内的随机变量的概率：
$$P(a \leq X \leq b | \mu, \sigma) $$
因此，我的猜测是似然函数本质上是有条件的。
这个推理正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647115/when-we-talk-about-the-likelihood-in-general-are-we-talking-about-a-joint-l</guid>
      <pubDate>Mon, 13 May 2024 02:30:02 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的概率区间</title>
      <link>https://stats.stackexchange.com/questions/647112/probability-intervals-with-machine-learning</link>
      <description><![CDATA[让我们想象一下抛硬币。正面或反面。在公平的游戏中，正面或反面出现的概率各为 50%。
我抛了十次硬币，其中有六次是正面。
话虽这么说，我可以计算出置信度为 95% 的概率区间（z 得分为 1.96）。
概率区间 = 0.6 ± 1.96 × sqrt(0.6 * (1 - 0.6) / 10) = [0.2962, 0.9038]
这意味着，对于我第 11 次抛硬币，我可以 95% 确定正面朝上的概率等于或大于 29.62% 且等于或小于 90.38%。
酷！一步完成。现在是困难的部分。机器学习。
我创建了一个 C# 机器学习 ml.net 二进制分类模型，对它进行了训练并对其进行了评估，给了我一个 CalibrateBinaryClassificationMetrics 具有大量指标。

准确性；
精确召回曲线下的面积；
Roc曲线下面积；
混淆矩阵；
熵；
F1分数；
对数损失；
对数损失减少；
负精度；
负召回率；
正精度；
积极回忆；

从我去年的研究来看，我发现这些都对我想要实现的目标没有帮助，如果你证明我错了，我会很高兴。
我想预测概率区间，而不仅仅是概率。
我总是将输入样本分为两部分：训练和测试。测试部分用于获取 校准的二进制分类指标。
此测试部分是预测的，然后我将预测概率与实际输出进行比较（1 - 发生，0 - 未发生）。
我可以用这些数据实现预测区间吗？也许是一般误差范围？
我应该怎么做才能获得概率区间而不仅仅是预测概率？如果我们不知道概率有多准确，那么概率本身就没有任何意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/647112/probability-intervals-with-machine-learning</guid>
      <pubDate>Mon, 13 May 2024 01:42:57 GMT</pubDate>
    </item>
    <item>
      <title>结合重复测量的变化和不确定性</title>
      <link>https://stats.stackexchange.com/questions/647108/combining-variation-and-uncertainty-from-replicate-measurements</link>
      <description><![CDATA[我从 3 个独立实验 {m_1、m_2、m_3} 中获得了 3 个测量值。
我还有另外 3 个测量值，用于缩放同一实验中的 m 个测量值 {n_1, n_2, n_3}（与 m 不同）。由于它们来自同一个实验，我可以将不确定性确定为 (std.dev.(n) / root(n))。
n 个测量值用于将 m 缩放为 (m / n)。
我想对变化和不确定性进行积分，以将 m/n 表示为 m/n +- 变化。这可能吗？如果是这样怎么办？
我找到了通过“相对正交”组合不确定性来源的指南在第 5 节中：https://phas.ubc.ca/~phys109 /manual/UncertaintyFinish/Uncertainty.pdf
但在我有限的理解中，变化和不确定性的确定方式不同，因此使用“相对求积”是没有意义的
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647108/combining-variation-and-uncertainty-from-replicate-measurements</guid>
      <pubDate>Sun, 12 May 2024 22:47:01 GMT</pubDate>
    </item>
    <item>
      <title>非识别混合物示例</title>
      <link>https://stats.stackexchange.com/questions/647107/example-of-nonidentification-mixture</link>
      <description><![CDATA[考虑一个连续的 r.v. $X$ 和 pdf $f$ 对于每个 $x\in \mathbb{R}$：
$$
f(x)=\sum_{k=1}^K \lambda_k f_k(x) \quad \lambda_k\geq 0, \sum_k\lambda_k=1
$$
假设$K=3$。你能举一个简单的例子来解释为什么上面的混合模型无法识别吗？不要提及本例中的标签问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/647107/example-of-nonidentification-mixture</guid>
      <pubDate>Sun, 12 May 2024 21:38:10 GMT</pubDate>
    </item>
    <item>
      <title>比较两组之间 PCA 变异的统计检验</title>
      <link>https://stats.stackexchange.com/questions/647105/statistical-test-for-comparing-pca-variation-between-two-groups</link>
      <description><![CDATA[我进行了 Procrustes 改造的 PCA。我将多个古代人类群体的数据转换为现代参考数据的相同背景。
我正在调查一些群体，我注意到协方差置信椭圆的变异性存在明显差异
（例如，参见下图中的 A 和 B）。我正在寻找某种统计测试来证实这一点，以便我可以确定这不仅仅是由于样本量或任何其他偏见因素造成的。
莱文斯的测试？巴特利特的？

图来自 Vyas、Koncz 等人。 2023年]]></description>
      <guid>https://stats.stackexchange.com/questions/647105/statistical-test-for-comparing-pca-variation-between-two-groups</guid>
      <pubDate>Sun, 12 May 2024 21:11:54 GMT</pubDate>
    </item>
    <item>
      <title>这是具有两个自变量的回归中辛普森悖论的示例吗？</title>
      <link>https://stats.stackexchange.com/questions/647104/is-this-an-example-of-simpsons-paradox-in-a-regression-with-two-independent-vari</link>
      <description><![CDATA[我正在做以下回归：
$$\text{home_price} \sim \alpha + \beta_1 \cdot \text{浴室} + \beta_1 \cdot \text{sqft_living}$$ 
我得到以下结果：
$$\text{home_price}= -17581.822 -1536.354*\text{浴室} + 267.132*\text{sqft_living}$$
但是，当我开始对卧室 = 2、3、4、5 进行调节时（数据集中只有 2 到 5 个卧室），我得到以下结果：
$$\text{home_price} = 50951.877 + 6795.518*\text{浴室}+ 270.233*\text{sqft_living} | \text{卧室} = 2$$
$$\text{home_price} = -30993.812 + 12964.777*\text{浴室}+ 258.223*\text{sqft_living} | \text{卧室} = 3$$
$$\text{home_price} = -228122.518 + 19911.07*\text{浴室}+ 316.307*\text{sqft_living} | \text{卧室} = 4$$
$$\text{home_price} = -490157.558 + 36623.244*\text{浴室}+ 379.488*\text{sqft_living} | \text{卧室} = 5$$
如何理解各个回归系数（符号不同）以及所有数据的回归之间的差异？
如果这是辛普森悖论的一个例子，我该如何理解它？]]></description>
      <guid>https://stats.stackexchange.com/questions/647104/is-this-an-example-of-simpsons-paradox-in-a-regression-with-two-independent-vari</guid>
      <pubDate>Sun, 12 May 2024 21:10:21 GMT</pubDate>
    </item>
    <item>
      <title>训练和测试准确性给了我 1 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647103/traning-and-testing-accuracy-gives-me-1</link>
      <description><![CDATA[0
我开发了一个代码，用于使用三种不同的卷积神经网络 (CNN) 架构（1D、2D 和 3D）对高光谱图像进行分类。该代码有两个主要部分：
预处理和数据准备，其中涉及数据分割等任务（具有过采样、PCA、数据增强和补丁创建选项）。本部分最后将处理后的数据保存到单独的文件中。
训练和测试 CNN 模型。然而，在评估模型时，我始终得到准确度和测试准确度分数 1，这似乎不切实际。我尝试调整代码，但结果保持不变。
我怀疑代码或数据预处理步骤可能存在问题，但我不确定如何进一步排除故障。任何有关如何解决此问题的指导将不胜感激。”]]></description>
      <guid>https://stats.stackexchange.com/questions/647103/traning-and-testing-accuracy-gives-me-1</guid>
      <pubDate>Sun, 12 May 2024 20:59:54 GMT</pubDate>
    </item>
    <item>
      <title>使用随机条件协方差矩阵显式采样</title>
      <link>https://stats.stackexchange.com/questions/647101/explicit-sampling-with-a-random-conditional-covariance-matrix</link>
      <description><![CDATA[设 $\mathbf X = (x_1,\ldots,x_N)$ 为具有条件协方差的零均值随机向量
$$
\Sigma_\xi
\相当于
\运算符名称{cov}[x_i,x_j| \xi]=\frac{1}{N}\left(
\sigma^2 \delta_{ij}
+
\sum_{\mu=1}^K
\xi_i^\mu
\xi_j^\mu
\正确的）
$$
其中 $\xi = \left[\xi^\mu_i\right]$ 是一个随机矩阵，其元素是 IID 正态随机变量：
$$
\operatorname{E}[\xi_i^\mu] = 0,\qquad
\operatorname{E}[\xi_i^\mu\xi_j^\nu] = \frac{\sigma_\xi^2}{K} \delta_{ij}\delta_{\mu\nu}
$$
如果可以找到一些矩阵 $A_\xi$ 使得 $A_\xi = \sqrt{ \Sigma_\xi}$ 或者是 $\Sigma_\xi$ 的 Cholesky 分解，那么可以写成 $\mathbf X$ 仅就独立随机变量而言：
$$
\mathbf X = A_\xi \mathbf Z，
$$
其中 $\mathbf Z$​​ 是 IID 标准法线变量的向量。特别是，$\mathbf Z$​​ 独立于$A_\xi$。
$A_\xi$ 有解析表达式吗？我想可能有某种方法可以在大型 $N$ 和 $K$ 与 $N/K = \Theta(1)$ 因为术语涉及 $\xi$条件协方差可以被认为是对单位矩阵的低秩扰动。我还可以想象，幂级数近似可以应用于平方根。
类似的问题是：有没有办法同时参数化 $\mathbf X$ 和 $\xi$就一些常见的 IID 随机变量集而言，以可分析处理的方式用于其他目的？]]></description>
      <guid>https://stats.stackexchange.com/questions/647101/explicit-sampling-with-a-random-conditional-covariance-matrix</guid>
      <pubDate>Sun, 12 May 2024 20:41:35 GMT</pubDate>
    </item>
    <item>
      <title>如何将多元 DKW 不等式排列到 n 的上限？</title>
      <link>https://stats.stackexchange.com/questions/647066/how-to-arrange-multivariate-dkw-inequality-to-an-upper-bound-on-n</link>
      <description><![CDATA[多元 DKW 不等式 给出
$$\Pr \left[ \sup_{t \in \mathbb{R}^k} \left| F_n(t) - F(t) \right| &gt; \epsilon \right] \leq (n+1)k e^{-2n\epsilon^2},$$
eCDF，$F(t)$ 是累积分布函数的总体。 rel=&quot;nofollow noreferrer&quot;&gt;CDF，$\epsilon\in\mathbb{R}_{&gt;0} $ 和 $n,k \in \mathbb{N}$。
我想要找到的是给定其他输入的 $n$ 的上限。我尝试使用 Lambert $W$ 函数但我没能成功地将事物安排成正确的形式来应用它。]]></description>
      <guid>https://stats.stackexchange.com/questions/647066/how-to-arrange-multivariate-dkw-inequality-to-an-upper-bound-on-n</guid>
      <pubDate>Sun, 12 May 2024 05:30:17 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中如何处理极小的训练数据集？</title>
      <link>https://stats.stackexchange.com/questions/647122/how-to-deal-with-extremely-small-training-dataset-in-machine-learning</link>
      <description><![CDATA[我有大约 100 行带有标签的数据
国家/地区 |类别 |标签
-----------+----------------+--------------------
[美国、英国、日本] |电子| 1
[美国] |体育 | 1
[台湾、英国] |杂货| 2
[日本] |预订 | 3

大约 900 行没有标签的数据
国家/地区 |类别
-----------+--------------
[美国、英国] |运动的
[台湾] |运动的
[美国] |杂货店
[日本] |电子的

使用这么小的数据集做分类模型可以吗？如果是这样，我该如何编码Country？或者是否有任何其他聚类/数学方法可以用来处理这种情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/647122/how-to-deal-with-extremely-small-training-dataset-in-machine-learning</guid>
      <pubDate>Sun, 12 May 2024 02:56:14 GMT</pubDate>
    </item>
    <item>
      <title>如何处理极小的训练数据？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647061/how-to-deal-with-extremely-small-training-data</link>
      <description><![CDATA[我有大约 100 行带有标签的数据
国家/地区 |类别 |标签
-----------+----------------+--------------------
[美国、英国、日本] |电子| 1
[美国] |体育 | 1
[台湾、英国] |杂货| 2
[日本] |预订 | 3

大约 900 行没有标签的数据
国家/地区 |类别
-----------+--------------
[美国、英国] |运动的
[台湾] |运动的
[美国] |杂货店
[日本] |电子的

使用这么小的数据集做分类模型可以吗？如果是这样，我该如何编码Country？或者是否有任何其他聚类/数学方法可以用来处理这种情况？
总共有 5 个标签，它们代表一个排名，其中 1 是最好的，5 是最差的。]]></description>
      <guid>https://stats.stackexchange.com/questions/647061/how-to-deal-with-extremely-small-training-data</guid>
      <pubDate>Sun, 12 May 2024 01:44:33 GMT</pubDate>
    </item>
    <item>
      <title>样本量和变异系数</title>
      <link>https://stats.stackexchange.com/questions/647058/sample-size-and-coefficient-of-variation</link>
      <description><![CDATA[我想知道样本量和变异系数 (CV) 之间的关系。 CV 定义为标准差与平均值的比率。我们是否可以说“样本量越小，CV 越大，因此关系呈负相关”？
我们的情况：有很多小区域。每个区域都有自己的样本。值得注意的是，城市地区的样本量较大，而农村地区的样本量较小。现在，我们的区域数据遵循泊松分布。当我们分别计算所有地区的 CV 时，我们发现样本量较小的农村地区的 CV 较大。我们想调查这是否是样本量的影响。
库(dplyr)
库（r样本）

cv &lt;- 函数(x){返回(sd(x)/mean(x))}
sim &lt;- data.frame(id=1:100000,
                变量=rpois(100000, 5),
                group10=样本(1:10,100000,替换=TRUE),
                group100=样本(1:100,100000,替换=TRUE),
                group1000=样本(1:1000,100000,替换=TRUE),
                group10000=样本(1:10000,100000,替换=TRUE)
                ）
AA &lt;- NULL
G &lt;- c(10,100,1000,10000)
for(k in 1:4){
  for(j in 1:G[k]){

  如果（k==1）{
    A &lt;- dplyr::filter(sim, group10==j)
  }否则如果(k==2){
    A &lt;- dplyr::filter(sim, group100==j)
  }否则如果(k==3){
    A &lt;- dplyr::filter(sim, group1000==j)
  }否则如果(k==4){
    A &lt;- dplyr::filter(sim, group10000==j)
  }
  
  AA &lt;- rbind(AA, c(G[k],
                    j,
                    n行(A),
                    平均值（A  $变量），
                var(A$变量),
                    sd(A$变量),
                简历（A$变量）
                    ）
              ）
  }
}
AA &lt;- as.data.frame(AA)
colnames(AA)＜-c(“组”、“组N”、“N”、“平均值”、“Var”、“SD”、“CV”)
头(AA)
尾部(AA)

AA10 &lt;- AA %&gt;% 过滤器(组==10)
AA100 &lt;- AA %&gt;% 过滤器(组==100)
AA1000 &lt;- AA %&gt;% 过滤器(组==1000)
AA10000 &lt;- AA %&gt;% 过滤器(组==10000)

(简历(sim$变量))

par(mfrow = c(1, 4))
图(AA10$N,AA10$CV, ylim=c(0,1.2), ylab=“CV”,xlab=“样本大小”,
     主=“10组”）
abline(h=cv(sim$variable),col=&quot;red&quot;)
绘图(AA100$N,AA100$CV, ylim=c(0,1.2), ylab=&quot;CV&quot;,xlab=&quot;样本大小&quot;,
 主要=“100组”）
abline(h=cv(sim$变量),col=“红色”)
绘图(AA1000$N,AA1000$CV, ylim=c(0,1.2), ylab=“CV”,xlab=“样本大小”,
     main=“1,000 组”）
abline(h=cv(sim$variable),col=&quot;red&quot;)
绘图(AA10000$N,AA10000$CV, ylim=c(0,1.2), ylab=&quot;CV&quot;,xlab=&quot;样本大小&quot;,
 主要=“10,000组”）
abline(h=cv(sim$变量),col=“红色”)
dev.off()

]]></description>
      <guid>https://stats.stackexchange.com/questions/647058/sample-size-and-coefficient-of-variation</guid>
      <pubDate>Sun, 12 May 2024 00:00:18 GMT</pubDate>
    </item>
    <item>
      <title>具有二级主持人的多级 1-1-1 调解_MPLUS [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647015/multilevel-1-1-1-moderated-mediation-with-level2-moderator-mplus</link>
      <description><![CDATA[我为多级 1-1-1 中介模型创建了以下语法，对 a 和 b 路径进行了 2 级调节。 ED 是主持人。


我不确定在模型约束中包含 s1 和 s2(cab) 的协方差，就像我向您展示的语法一样。您能确认一下协方差部分吗？

那么我是否可以理解inda1~3是a路径*主持的b路径的间接效果，而indb1~3是主持a路径*b路径的间接效果？如何查看主持的 a 路径 * 主持的 b 路径的间接效果？它只是 (s1mean + mod1 * wlow) * (s2mean + mod2 * wlow) + cab 吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/647015/multilevel-1-1-1-moderated-mediation-with-level2-moderator-mplus</guid>
      <pubDate>Sat, 11 May 2024 07:28:48 GMT</pubDate>
    </item>
    </channel>
</rss>