<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 10 Aug 2024 18:18:49 GMT</lastBuildDate>
    <item>
      <title>识别聚类以校正散点</title>
      <link>https://stats.stackexchange.com/questions/652598/identifying-clusters-to-correct-for-scatter</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652598/identifying-clusters-to-correct-for-scatter</guid>
      <pubDate>Sat, 10 Aug 2024 17:52:31 GMT</pubDate>
    </item>
    <item>
      <title>GLMM 用于推理与预测</title>
      <link>https://stats.stackexchange.com/questions/652596/glmm-for-inference-vs-prediction</link>
      <description><![CDATA[我正在使用线性混合模型 (LMM) 和广义线性混合模型 (GLMM) 的混合模型评估横断面重复测量数据。我看到很多地方都说 GLMM 主要用于预测结果变量值。我的研究主要是推断一组独立变量与结果变量之间的关系（推断），而不是预测值。当目标是推断而不是预测时，GLMM 是否仍然适用于连续/近似连续的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/652596/glmm-for-inference-vs-prediction</guid>
      <pubDate>Sat, 10 Aug 2024 17:09:12 GMT</pubDate>
    </item>
    <item>
      <title>单调变换的数学理论</title>
      <link>https://stats.stackexchange.com/questions/652595/mathematical-theory-of-monotone-transforms</link>
      <description><![CDATA[对于从总体 $ \mathcal{P}$ 中选取的一个服从分布 $P$ 的一个样本的 $n$ 个观测值 $X_1, \ldots, X_n$，假设我们观察到 $X_i = x_i \in \mathbb{R}$。从经验上讲，我们可以通过查看 QQ 图或运行正态性检验来检测 $P$ 是否不正态。当我们有理由怀疑$P$不是正常的时候，根据经验，我们可以应用某种单调变换（例如幂变换，特别是 Box-Cox 变换）来“使其看起来更正常”。这意味着我们将固定一个非减函数 $f: \mathbb{R} \to \mathbb{R}$ 并研究 $Y_i = f(X_i)$。
是否有任何数学理论表明，在适当选择的 $f$（特别是 Box-Cox 变换）下，$Y_i$ 的分布在某种数学意义上（例如累积分布函数之间的距离）更接近具有一定均值和方差的正态分布？这个问题的定量答案（参考）是最好的。定性答案也是可以接受的。我只是想知道这种变换是否纯粹是经验性的，还是有任何理论基础。
对我来说，听起来这种变换只能拉伸数据（非均匀地），使其集中在某个区域而不是其他区域，这肯定会使其更接近正态分布。对于所有非正态分布，某种算法是否可以确定一种变换使其更正态，这是另一回事。
这种变换的使用存在很多歧义。]]></description>
      <guid>https://stats.stackexchange.com/questions/652595/mathematical-theory-of-monotone-transforms</guid>
      <pubDate>Sat, 10 Aug 2024 16:14:20 GMT</pubDate>
    </item>
    <item>
      <title>xgboost 模型的超参数优化</title>
      <link>https://stats.stackexchange.com/questions/652593/hyperparameter-optimization-for-xgboost-model</link>
      <description><![CDATA[我正在尝试训练 xgboost 模型。准备好数据集后，我进行了训练/测试分割。为了加快训练过程，我想先使用网格搜索确定超参数的最佳范围，然后使用随机搜索训练模型。但我对得到的图表感到怀疑。例如，我获得了 max_depth 参数的验证图；
param_grid = {
&#39;max_depth&#39;: [1, 3, 5, 7, 10, 50, 100]
}

#model
xgb_model2 = xgb.XGBClassifier()

#grid_search
grid_search1 = GridSearchCV(xgb_model2, param_grid, cv=5,scoring = &quot;precision&quot;, error_score = &quot;raise&quot;, return_train_score=True)
grid_search1.fit(X_train, y_train)
results = pd.DataFrame(grid_search1.cv_results_)

max_depths = results[&#39;param_max_depth&#39;]
mean_train_scores = results[&#39;mean_train_score&#39;]
mean_test_scores = results[&#39;mean_test_score&#39;]

plt.figure(figsize=(10, 6))
plt.plot(max_depths, mean_train_scores, label=&#39;训练精度&#39;, marker=&#39;o&#39;)
plt.plot(max_depths, mean_test_scores, label=&#39;验证精度&#39;, marker=&#39;o&#39;)
plt.xlabel(&#39;最大深度&#39;)
plt.ylabel(&#39;精度&#39;)
plt.title(&#39;max_depth 对模型性能的影响&#39;)
plt.legend()
plt.grid(True)
plt.show()


我的顾问说这个图表可能是错的，但我认为不是。在我看来，根据图表，max_depth 参数本身无法解决过度拟合问题，但我可以将其解释为在进行随机搜索时尝试 max_depth 参数的 1-10 之间的值是合适的。图表或我的解释有误吗？
我的顾问期望是这样的;
]]></description>
      <guid>https://stats.stackexchange.com/questions/652593/hyperparameter-optimization-for-xgboost-model</guid>
      <pubDate>Sat, 10 Aug 2024 15:13:03 GMT</pubDate>
    </item>
    <item>
      <title>用于 SDE 参数估计的 MLE</title>
      <link>https://stats.stackexchange.com/questions/652589/mle-for-sde-parameter-estimation</link>
      <description><![CDATA[我目前正在阅读 Särkkä 和 Solin 合著的《应用随机微分方程》（链接 - 第 234 页）。书中提到，如果已知转移密度，则可以使用最大似然估计 (MLE) 来估计随机微分方程 (SDE) 的参数。
但是，书中并未讨论 MLE 估计量是否一致且是否会收敛。我的具体问题是：

遍历过程的 MLE 一致性：如果底层随机过程是遍历的，我理解人们可能仍会期望 MLE 具有一致性。这种理解正确吗？

非平稳过程的一致性：当过程非平稳时会怎样？我们还能期望 MLE 是一致的并且会收敛吗？如果是，在什么条件下？如果不是，对于非平稳过程，哪些替代估计方法可能更合适？


任何见解或相关文献的引用都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652589/mle-for-sde-parameter-estimation</guid>
      <pubDate>Sat, 10 Aug 2024 11:17:52 GMT</pubDate>
    </item>
    <item>
      <title>指定 TWFE 模型（有或无动态效应）的正确方法是什么？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652588/what-is-the-correct-way-to-specify-model-a-twfe-with-and-without-dynamic-effect</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652588/what-is-the-correct-way-to-specify-model-a-twfe-with-and-without-dynamic-effect</guid>
      <pubDate>Sat, 10 Aug 2024 10:57:00 GMT</pubDate>
    </item>
    <item>
      <title>处理大量非随机缺失值的最合适填补方法</title>
      <link>https://stats.stackexchange.com/questions/652587/most-appropriate-imputation-method-for-dealing-with-large-amount-of-non-random-m</link>
      <description><![CDATA[我正在尝试根据几个指标的值创建一个综合指数。这些指标为各国在其衡量的某个维度上每年提供分数。这个想法是使用 PCA 确定分配给这些分数的相对权重。
但是，我的数据集包含许多缺失值。这是因为并非所有国家/地区每年在每个维度上都获得分数。

要运行 PCA，我需要某种方法来处理这些缺失值。事实证明这非常困难，可能很大程度上是由于我对统计学的了解非常基础。
理想情况下，我想以某种方式估算数据。但是，我很难确定最好的方法是什么。首先，这是因为缺失的数据不是随机的。如果一个国家在某一年没有在某个指标上得分，那么它在其他年份也不太可能再次得分。反之亦然：获得分数的国家很可能在下一年再次获得分数。其次，由于我的数据涉及彼此独立的国家，因此我无法将一个国家的数据归因于另一个国家。如果尼日利亚获得分数但挪威没有，那么以某种方式将数据归因于挪威是没有意义的。
因此我面临一个问题。您对如何最好地处理这种情况有什么建议吗？或者最好根本不归因，而选择像 NIPALS 这样的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/652587/most-appropriate-imputation-method-for-dealing-with-large-amount-of-non-random-m</guid>
      <pubDate>Sat, 10 Aug 2024 10:40:00 GMT</pubDate>
    </item>
    <item>
      <title>聚类和样本加权（使用 GEE）</title>
      <link>https://stats.stackexchange.com/questions/652584/clustering-and-samples-weighting-using-gee</link>
      <description><![CDATA[我目前正在使用 GEE 模型分析与欧洲国家传染病流行相关的社会因素。我的数据基于特定健康保险覆盖的患者，这引发了对外部有效性的担忧。具体而言，由于不同族群在受保人群中所占比例过高，患病率可能会出现偏差。
我是否应该调整模型中每个族群（来自整个国家人口）的比例，使用这些比例作为加权因子，或考虑按族群进行聚类以解决潜在的偏差？确保我的结果更适用于总体人群的最佳方法是什么？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652584/clustering-and-samples-weighting-using-gee</guid>
      <pubDate>Sat, 10 Aug 2024 08:50:58 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用哪种回归来估计协方差？</title>
      <link>https://stats.stackexchange.com/questions/652583/which-regression-should-i-use-to-estimate-the-covariance</link>
      <description><![CDATA[我使用以下代码生成了一些合成数据。我想仅使用 (X, Z, Y) 中的信息推断 U。例如，泊松回归估计 U 的平均值，但不提供有关其协方差的信息。哪种回归模型合适？
# 加载必要的包
library(lme4)
library(MASS)

# 设置种子
set.seed(123)

# 生成 X
X &lt;- 1 + rnorm(10000, 0, 1)
beta &lt;- 0.5

# 生成 Z
Z &lt;- 0.2 * matrix(rnorm(20000), ncol = 2)

# 均值向量和协方差矩阵
mean &lt;- c(-0.5, 1)
covariance_matrix &lt;- matrix(c(1.0, 0.5, 0.5, 1.5), nrow = 2)

# 从多元正态分布中抽样
U &lt;- mvrnorm(10000, mu = mean, Sigma = covariance_matrix)

#计算线性组合
linear &lt;- X * beta + rowSums(Z * U)

# 从泊松分布中抽样
rate &lt;- exp(linear)
Y &lt;- rpois(10000, lambda = rate)

# 组织成数据框
data &lt;- data.frame(X = X, Z1 = Z[,1], Z2 = Z[,2], Y = Y)

example_model = glm(Y ~ 0 + X + Z1 + Z2, data = data, family =toxic)

我的尝试：
data$id = 1:nrow(data)
model = glmer(Y ~ 0 + X + Z1 + Z2 + (0 + Z1 + Z2 | id), data = data, family = poisson,
control=glmerControl(check.nobs.vs.nlev = &quot;ignore&quot;,
check.nobs.vs.rankZ = &quot;ignore&quot;,
check.nobs.vs.nRE=&quot;ignore&quot;))

虽然这个方法有效，但整体质量并不好。有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652583/which-regression-should-i-use-to-estimate-the-covariance</guid>
      <pubDate>Sat, 10 Aug 2024 07:52:35 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中的残差指数/偏协方差解释</title>
      <link>https://stats.stackexchange.com/questions/652566/residual-index-partial-covariance-interpretation-in-linear-regression</link>
      <description><![CDATA[我根据以下模型模拟数据

其中我的最终结果变量是鸟类物种的平均脑质量。
我需要帮助解释从以下 OLS 回归拟合的 beta 系数
$$
(residuals~of~G \thicksim B) \thicksim D
$$
它给出了最佳拟合线
$$
(residuals~of~G \thicksim B) = \alpha + \beta D
$$
我有 beta 的闭式解，包括偏协方差、偏相关和相关性，我认为这使其值特别清晰。尽管如此，我想将 $\beta$ 解释为告诉我 G 本身在某些条件下如何变化，而不是 G 对 B 的残差如何变化。这可能吗？如果它能给出更好的解释，我很乐意重新想象一下这个系统。例如，我可以翻转 B2 或 B3 箭头，这样 B/D 中的一个就直接导致另一个。任何关于 $\beta$ 到底告诉我什么的进一步见解都将不胜感激。以下是我对 $\beta$ 值的三个闭式表达式，它们仍然让我感到困惑。
$$
\beta = \frac{partial~covariance~of(G,D |B)}{var(D)}
$$
其中 (G,D |B) 的偏协方差为
$$
partial~covariance~of(G,D |B) = cov(G,D) - \frac{cov(G,B)cov(B,D)}{var(B)}
$$
此外，$\beta$ 可以用偏相关来表示
$$
\beta = \rho_{GD\cdot B}\frac{sd(residuals~of~G \thicksim B )sd(residuals~of~D \thicksim B)}{var(D)}
$$
最后，我最喜欢的表达式是下一个，因为它显示$\beta$是G和D之间的相关性，无法通过B标准化到回归的正确单位来追踪
$$
\beta = \big(cor(G,D) - cor(G,B)cor(B,D)\big)\frac{sd(G)}{sd(D)}
$$
但是我仍然很困惑。如何在我的模拟数据集中将D改变一个单位并控制改变B的影响，以便我的G实际上增加了$\beta$。如果可能的话，我想根据原始模型而不是残差来解释$\beta$，因为至少对我来说，残差实际上没有任何意义，据我所知，G ~ B 的残差是 E-A 的某种估计值，但这很令人困惑。
欢迎任何观点/意见。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652566/residual-index-partial-covariance-interpretation-in-linear-regression</guid>
      <pubDate>Fri, 09 Aug 2024 20:31:47 GMT</pubDate>
    </item>
    <item>
      <title>在模型选择中执行内部 CV 的“元”学习器的性能如何？</title>
      <link>https://stats.stackexchange.com/questions/652525/what-is-the-performance-of-a-meta-learner-that-performs-internally-cv-for-mode</link>
      <description><![CDATA[我试图理解证明，即在模型选择期间将 CV 性能报告为性能估计存在乐观偏差。证明步骤如下：

设 $p_i, \pi_i$ 为样本真实表现 $\forall i$（每个 $i$ 对应一个配置，又称学习器，例如 $C=1$ 的 SVM、$C=10$ 的 SVM 等）
$\mathbb{E}[p_i] = \pi_i, \forall i$（无偏估计）
我们返回估计值 $\max(p_1, \ldots, p_n)$
我们平均回报$\mathbb{E}[\max(p_1, \ldots, p_n)]$
真正的最佳表现$\max(\pi_1, \ldots, \pi_n) =
\max(\mathbb{E}[p_1], \ldots, \mathbb{E}[p_n])$ 为什么？

\begin{align*}
&amp;\mathbb{E}[\max(p_1, \ldots, p_n)]
\geq
\max(\mathbb{E}[p_1], \ldots, \mathbb{E}[p_n])
\\
&amp;\therefore \text{Overestimation}
\end{align*&gt;
我不明白为什么内部执行 CV 的学习者的真实表现必须是 $\max(\pi_1, \ldots, \pi_n)$。
为了获得这个“元”的表现学习器，我们需要以下内容：

将数据集拆分为训练和测试
在训练中通过 CV 调整超参数
估计测试集中最佳选定模型的性能
对不同的数据集重复 1-3 的所有步骤，并平均步骤 3 的性能（这应该是期望等于“元”学习器的真实性能）

有人能证明为什么这个性能必须等于 $\max(\pi_1, \ldots, \pi_n)$ 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652525/what-is-the-performance-of-a-meta-learner-that-performs-internally-cv-for-mode</guid>
      <pubDate>Fri, 09 Aug 2024 09:20:53 GMT</pubDate>
    </item>
    <item>
      <title>如果 PCA 无法对我的样本进行分组，但 K-means 可以完美地聚类它们，该怎么办？我的数据分析有问题吗？可能吗？</title>
      <link>https://stats.stackexchange.com/questions/652329/what-if-pca-is-unable-to-group-my-samples-but-k-means-perfectly-clusters-them</link>
      <description><![CDATA[我不是专家，但我目前正在使用无监督方法来更好地解释通过 DART-MS 分析获得的质谱数据。我还在学习。
事实证明，当我在 MetaboAnalyst 平台上分析我的数据时，我没有观察到通过 PCA 进行的区分，而 K-means 能够将我的样本聚类为两个不同的组，这与样本特征非常一致。
我已经多次检查了该协议。它在分析其他样本时效果很好，我的意思是“PCA 与 K-means 结果一致，两者一致。”
如果这是正确的，我们如何解释这种分歧？
PCA 结果

K-means 结果中，您可以看到样本 Q3、Q4、T2、T3、V3、V4、R3 和 R4 按预期分组：
]]></description>
      <guid>https://stats.stackexchange.com/questions/652329/what-if-pca-is-unable-to-group-my-samples-but-k-means-perfectly-clusters-them</guid>
      <pubDate>Mon, 05 Aug 2024 14:26:56 GMT</pubDate>
    </item>
    <item>
      <title>导出有界函数估计误差和的大 $O_p$</title>
      <link>https://stats.stackexchange.com/questions/651980/deriving-the-big-o-p-of-a-sum-involving-estimation-errors-of-bounded-functions</link>
      <description><![CDATA[假设 $\frac{1}{n}\sum_{i=1}^n\{f(X_i) - \hat{f}_n(X_i)\}^2$ 和 $\frac{1}{n}\sum_{i=1}^n\{g(X_i) - \hat{g}_n(X_i)\}^2$ 为 $O_p(a^2_n)$，其中 $a_n$ 为 $a_n = O(n^{-r}$)，其中 $r &gt; 1/4$。
假设 $Y_i$ 是二进制 0/1 随机变量，$f(\cdot)$ 介于 -1 和 1 之间（即，对于任何 $X_i$，$-1 \leq f(X_i) \leq 1$），并且 $g(\cdot)$ 介于 0 和 1 之间（即，对于任何 $X_i$，$0 \leq g(X_i) \leq 1$）。观测值 $i = 1, \ldots, n$ 是 i.i.d，而 $\hat{f}_n(\cdot)$ 和 $\hat{g}_n(\cdot)$ 是从这些观测值中获得的估计量。
对于，最大的 $O_p$ 是什么呢？
$$\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}_n(X_i))g(X_i) + (\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i))]^2?$$
展开平方，我们得到 3 项之和：
\begin{align*}
&amp;\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}_n(X_i))g(X_i) + (\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i))]^2\\
&amp;=\frac{1}{n}\sum_{i=1}^n \{f(X_i) - \hat{f}_n(X_i)\}^2g^2(X_i)+2(f(X_i) - \hat{f}_n(X_i))g(X_i)(\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i)) + (\hat{f}_n(X_i) - Y_i)^2(g(X_i) - \hat{g}_n(X_i))^2
\end{align*&gt;
项 1：$\frac{1}{n}\sum_{i=1}^n \{f(X_i) - \hat{f}_n(X_i)\}^2g^2(X_i)$
由于 $g(X_i)$ 有界，并且 $\frac{1}{n}\sum_{i=1}^n\{f(X_i)-\hat{f}_n(X_i)\}^2$ 为 $O_p(a^2_n)$，则 项 1 为 $O_p(a^2_n)$。
项 2：$\frac{2}{n}\sum_{i=1}^n (f(X_i) - \hat{f}_n(X_i))g(X_i)(\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i))$
由于$g(X_i) \leq 1$ 和 $|\hat{f}_n(X_i) - Y_i| \leq 2$，则我们有
\begin{align*}
&amp;\frac{2}{n}\sum_{i=1}^n (f(X_i) - \hat{f}_n(X_i))g(X_i)(\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i))\\ &amp;\leq C \sqrt{\left(\frac{1}{n}\sum_{i=1}^n \{f(X_i)-\hat{f}_n(X_i)\}^2\right)\left(\frac{1}{n}\sum_{i=1}^n \{g(X_i) - \hat{g}_n(X_i)\}^2\right)}\\
&amp;= O_p(a^2_n)
\end{align*&gt;
其中 $C$ 是某个正常数，不等式由柯西-施瓦茨定理成立。
第 3 项：$\frac{1}{n}\sum_{i=1}^n (\hat{f}_n(X_i) - Y_i)^2(g(X_i) - \hat{g}_n(X_i))^2$
因为 $|\hat{f}_n(X_i) - Y_i| \leq 2$
$$\frac{1}{n}\sum_{i=1}^n (\hat{f}_n(X_i) - Y_i)^2(g(X_i) - \hat{g}_n(X_i))^2 \leq \frac{4}{n}\sum_{i=1}^n (g(X_i) - \hat{g}_n(X_i))^2 = O_p(a^2_n)$$
总之，我们有
\begin{align*}
&amp;\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}_n(X_i))g(X_i) + (\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i))]^2\\ &amp;= O_p(a^2_n) + O_p(a^2_n) + O_p(a^2_n)\\
&amp;= O_p(a^2_n)
\end{align*&gt;
以上内容正确吗？我不太确定项 2和项 3，特别是关于分解$\hat{f}_n(X_i)-Y_i$。]]></description>
      <guid>https://stats.stackexchange.com/questions/651980/deriving-the-big-o-p-of-a-sum-involving-estimation-errors-of-bounded-functions</guid>
      <pubDate>Tue, 30 Jul 2024 02:22:39 GMT</pubDate>
    </item>
    <item>
      <title>处理具有许多变量和大量数据集的 Cox 模型中的非比例风险</title>
      <link>https://stats.stackexchange.com/questions/651252/dealing-with-non-proportional-hazards-in-a-cox-model-with-many-variables-and-a-l</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651252/dealing-with-non-proportional-hazards-in-a-cox-model-with-many-variables-and-a-l</guid>
      <pubDate>Wed, 17 Jul 2024 14:28:42 GMT</pubDate>
    </item>
    <item>
      <title>有哪些情况我们需要避免使用 IQR？</title>
      <link>https://stats.stackexchange.com/questions/633392/are-there-cases-where-we-need-to-avoid-the-usage-of-iqr</link>
      <description><![CDATA[让我们考虑一下四分位距 (IQR)、标准差 (SD) 和平均绝对差 (MAD)。我们知道&quot;最常见的稳健尺度测量之一是四分位距 (IQR)&quot;，而&quot;标准差受异常值的影响很大&quot;，其&quot;崩溃点为 0&quot;。此外，“平均绝对偏差是比标准偏差更稳健的离散度度量”。
当我在近似对称或中度偏斜的分布（没有异常值）中计算 IQR、SD 和 MAD 时，SD 和 MAD 给出的值相似（MAD 返回的值比 SD 略低），并且它们始终低于 IQR 值，并且与 IQR 值相对较远。
可能保留 IQR、SD 和 MAD 并没有什么错，因为它们只是“离散度”一词的不同定义，但如果一个人需要依赖一个数字来表示数据的离散度并问，“该分布的离散度是多少？”，我们应该说出 IQR、SD 和 MAD 的所有值吗？
或者我们应该 - 例如 - 丢弃 IQR，因为它离 SD 和 MAD 相当远，而只传达 SD 或 MAD，因为它们彼此相当接近？
从这个案例中，我会概括并问：是否存在我们需要避免使用 IQR 的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/633392/are-there-cases-where-we-need-to-avoid-the-usage-of-iqr</guid>
      <pubDate>Fri, 08 Dec 2023 11:24:41 GMT</pubDate>
    </item>
    </channel>
</rss>