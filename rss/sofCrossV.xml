<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 23 Dec 2024 15:17:23 GMT</lastBuildDate>
    <item>
      <title>我应该服从 AIC 还是 Ljung-Box？</title>
      <link>https://stats.stackexchange.com/questions/659126/should-i-obey-aic-or-ljung-box</link>
      <description><![CDATA[我有 13 个收益系列，我想通过 GJR-GARCH 模型进行研究。
由于其中 3 个显示出均值自相关（根据 Ljung-Box 检验），我需要将其消除，并且我决定计算 ARMA(0,0) 和 ARMA(2,2) 之间所有组合的 AIC。
出乎意料的是，无论 Ljung-Box 检验是否检测到自相关，AIC 都表明 13 个系列中的 12 个的最佳模型是 ARMA(2,2)。
我的问题是：我应该如何处理非自相关的系列？我应该遵循 AIC 并使用 ARMA(2,2)，还是应该遵循 Ljung-Box 检验并仅对 Ljung-Box 检测到自相关的系列使用 ARMA(2,2)？]]></description>
      <guid>https://stats.stackexchange.com/questions/659126/should-i-obey-aic-or-ljung-box</guid>
      <pubDate>Mon, 23 Dec 2024 15:14:16 GMT</pubDate>
    </item>
    <item>
      <title>将 MLE 的条件密度绘制到数据集上</title>
      <link>https://stats.stackexchange.com/questions/659125/plotting-conditional-densities-from-mle-onto-data-sets</link>
      <description><![CDATA[免责声明：我知道这很可能是一个极其琐碎和简单的问题。我希望了解。
我对不同的“状态”做了一些估计并希望使用估计值绘制密度$ f(x_{T}\mid x_t)$，$T&gt;t$。
通常，当我们使用$f(x)$进行 MLE 时，我们：

绘制已进行最大似然估计的数据直方图。
在$x$值的网格上计算$f(x)$的值。
将密度绘制到数据直方图上。

但是，当我们使用条件密度函数进行最大似然估计时，RHS 将取决于某个值$x_t$我们选择什么值才能将密度绘制到数据直方图上？]]></description>
      <guid>https://stats.stackexchange.com/questions/659125/plotting-conditional-densities-from-mle-onto-data-sets</guid>
      <pubDate>Mon, 23 Dec 2024 14:24:38 GMT</pubDate>
    </item>
    <item>
      <title>VAE 高斯分布的加权融合</title>
      <link>https://stats.stackexchange.com/questions/659124/weighted-fusion-of-vae-gaussian-distributions</link>
      <description><![CDATA[假设您有 4 个 VAE 的 4 个输出向量：$4\times B \times 512$
这些 $512$ 个元素对应于 $256 \ \mu$ &amp; $256 \ \log(\sigma^2)$ 个相互依赖的多元正态分布。
我的目标是将这四个元素组合成一个多元正态分布，该分布通过 $\mu^*$ &amp; $\sigma^*$ 使用加权融合来定义。我正在考虑两种方法...

1.简单求和高斯函数
均值总和：$\mu^*=\sum w_i * \mu_i$
对数变量的对数总和指数技巧：$\sigma^*=\sqrt{a + \log \sum w_i * e^{\text{logvar}_i - a}}$
其中

$w_i$ 是基于 VAE 输出向量学习到的注意力权重，其中 $\sum w_i = 1$
$a = \max (\text{logvar})$

现在我像这样计算$w_i$：
self.to_attn_logits = nn.Conv1d(512, 1, 1)
...
attn = self.to_attn_logits(latents).softmax(dim = -1)

仅供参考，但我不完全确定根据$\mu$和$\text{logvar}$计算注意力权重是否有意义。但这只是个次要问题，目前并不重要。
2. 混合模型方法
这个方法有点类似，但更复杂，我认为它考虑到单独的分布与另一个分布相关。我不是统计学家！
均值总和：$\mu^*=\sum w_i * \mu_i$
协方差总和：$\Sigma^* = \sum w_i * (\Sigma_i + (\mu_i * \mu^*)(\mu_i * \mu^*)^T)$
其中

$\Sigma_i = \text{diag}(\exp(\text{logvar}_i))$ 第 i 个分布的对角协方差矩阵。


想请教统计学方面比我更了解的人，以确保它有意义（尤其是第二种方法）。有关更多背景信息，您可以访问此 repo，我正在其中整理这些内容。简而言之，$x$ 是一个分子，它表示为字符串、图像、图形和指纹，每个都使用单独的 VAE 进行编码，并组合成用于采样和计算 KL 散度的单个多变量正态分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/659124/weighted-fusion-of-vae-gaussian-distributions</guid>
      <pubDate>Mon, 23 Dec 2024 13:14:30 GMT</pubDate>
    </item>
    <item>
      <title>N 维单调函数的可逆性</title>
      <link>https://stats.stackexchange.com/questions/659121/invertibility-of-n-dimensional-monotonic-function</link>
      <description><![CDATA[给定一个函数 $F: \mathbb{R}^n\rightarrow \mathbb{R}^n$，其中我们知道 $\frac{dF_i(x)}{dx_j}\ge 0 \,\,\forall i,j$（因此 $F$ 的每个分量对所有输入都是单调的），我们可以说它是可逆的吗？
实际上，这指的是规范化流，具体来说，我正在阅读这篇论文，特别是在定理 1（在补充材料）他们声称他们的复合函数是可逆的。
但是，我不太同意，具体来说，如果我们取$F = [x+y, x+y]$，我们有一个二维函数，其中每个分量相对于输入都是单调的，但它绝对不是可逆的。现在，假设他们使用残差连接，这样的示例可以轻松实现：
$$
x&#39; = x + \begin{bmatrix}0&amp;1\\1&amp;0\end{bmatrix}x
$$
我知道缺少非线性，但这证明了单调性是不够的，不是吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659121/invertibility-of-n-dimensional-monotonic-function</guid>
      <pubDate>Mon, 23 Dec 2024 10:58:18 GMT</pubDate>
    </item>
    <item>
      <title>跨栏模型等同于零膨胀模型吗？</title>
      <link>https://stats.stackexchange.com/questions/659119/are-hurdle-models-equivalent-to-zero-inflated-models</link>
      <description><![CDATA[换句话说，障碍模型可以转换为零膨胀模型吗？
我正在查看障碍模型的维基百科页面（https://en.wikipedia.org/wiki/Hurdle_model）。据我理解，障碍模型只是零概率，对于非零情况，则是严格非零分布。
零膨胀模型是零概率，对于其他情况，则是包含零的分布。
所以你可以采用零膨胀模型，将零概率分解为单一情况，然后将其称为障碍模型，对吗？我遗漏了什么吗？
它们似乎都能够形成相同的总概率分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/659119/are-hurdle-models-equivalent-to-zero-inflated-models</guid>
      <pubDate>Mon, 23 Dec 2024 10:49:34 GMT</pubDate>
    </item>
    <item>
      <title>单因素方差分析对比</title>
      <link>https://stats.stackexchange.com/questions/659115/contrasts-in-one-way-anova</link>
      <description><![CDATA[我正在观看一场关于方差分析的讲座，讲师给出了 3 个可能的数据假设示例：

对于假设 3 (mu2 = mu1 - 3*mu3)，对比度系数总和不为零 (-1 + 1 + 3 != 0)。在这种情况下，我们可以说它是对比度吗？如果不是，那它是什么？在这种情况下，我们可以检查第三个假设与假设 1 的正交性，就像幻灯片上所做的那样 (a * c)？]]></description>
      <guid>https://stats.stackexchange.com/questions/659115/contrasts-in-one-way-anova</guid>
      <pubDate>Mon, 23 Dec 2024 05:03:38 GMT</pubDate>
    </item>
    <item>
      <title>元分析中嵌套数据的模型简化</title>
      <link>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</link>
      <description><![CDATA[我正在对子组中不同程度的异质性进行荟萃分析。由于数据结构是嵌套的（效应大小嵌套在研究中），我通过添加研究的随机效应和研究内的效应大小来考虑这一点。轮廓似然图在其估计值处达到峰值。
比较具有不同程度异质性的模型和具有共同异质性估计值的模型的似然比检验是显著的。然而，在获得 $ \tau^2_\text{between} $ 和 $ \tau^2_\text{within} $ 的置信区间 (CI) 后，除了一个之外，$ \tau^2_\text{within} $ 的所有 CI 的下限均为零。一个显著的估计值仍然是适中的。
在这种情况下，将模型简化为仅在研究层面具有随机效应的两级模型是否合适，从而仅考虑研究之间的差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</guid>
      <pubDate>Sun, 22 Dec 2024 20:41:46 GMT</pubDate>
    </item>
    <item>
      <title>使用 simr 了解功率曲线和非单调功率随样本量增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</guid>
      <pubDate>Wed, 18 Dec 2024 13:31:01 GMT</pubDate>
    </item>
    <item>
      <title>如何应用对系数有约束的 OLS 并使输出规模与目标变量对齐？</title>
      <link>https://stats.stackexchange.com/questions/658907/how-to-apply-ols-with-constraints-on-coefficients-and-align-the-output-scale-wit</link>
      <description><![CDATA[我正在研究一个 OLS 回归问题，其中：
因变量（目标）的范围从 1 到 6（步长为 1）。
独立变量的范围从 1 到 10（步长为 0.5）。
我想要设置模型，使得：
没有截距。
所有系数的总和（β）等于 1。
输出与因变量的尺度一致（1 到 6）。
但是，当所有独立变量都达到其最大值 10 时，模型输出将扩大到 10，这超出了目标范围。我无法缩放独立变量。我可以缩放因变量。因此，它是 1 到 10。下面是我用来缩放因变量的映射。



原始比例
新scale




1
1


2
2.8


3
4.6


4
6.4


5
8.2


6
10



但是还有其他方法吗？我如何调整我的 OLS 设置？
如果您能提供任何关于如何实施的指导或建议，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658907/how-to-apply-ols-with-constraints-on-coefficients-and-align-the-output-scale-wit</guid>
      <pubDate>Wed, 18 Dec 2024 07:41:36 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost - `colsample_bytree`<1 的树所见列的顺序</title>
      <link>https://stats.stackexchange.com/questions/658867/xgboost-order-of-columns-seen-by-a-tree-with-colsample-bytree1</link>
      <description><![CDATA[我的理解是，如果两个或多个列在拆分时提供相同的增益，XGBoost 会选择第一列。
为了确保 XGBoost 有机会查看并包含所有相关列，我认为我可以简单地传递 colsample_bytree=0.99。但是，为了使其工作，采样返回的列必须按随机顺序排列。这种方法正确吗？还是我应该在某种交叉验证方案中对列进行打乱？]]></description>
      <guid>https://stats.stackexchange.com/questions/658867/xgboost-order-of-columns-seen-by-a-tree-with-colsample-bytree1</guid>
      <pubDate>Tue, 17 Dec 2024 11:02:34 GMT</pubDate>
    </item>
    <item>
      <title>在此次治疗师依从性的测试中，作者是否适当地应用了重复测量单因素方差分析和 ROC 分析？</title>
      <link>https://stats.stackexchange.com/questions/658834/have-the-authors-appropriately-applied-repeated-measures-one-way-anova-and-roc-a</link>
      <description><![CDATA[我正在阅读一篇关于我所从事的心理治疗类型的研究。我的直觉是，这篇论文对统计数据的使用是有缺陷的，但我在意识形态上想要找出这篇特定研究的缺陷，而且我对统计数据的了解相当基础。出于这些原因，我不会链接到这篇论文。
这篇论文的所有作者都是接受过同一种治疗培训的心理治疗师。他们创建了一份问卷，供接受过该治疗培训的观察员使用，以评估治疗师在特定疗程中对该治疗的治疗程度。（即，这是一项依从性测试。）作者将这份问卷分发给了大约 200 名参与者（均接受过相关治疗培训），并附上了 4 个治疗疗程的视频；其中 2 个由接受过相关治疗培训的治疗师制作，另外 2 个由接受过其他治疗培训的治疗师制作。参与者对前两个视频的评分（每个约平均值 = 16.5，标准差 = 0.2）高于对后两个视频的评分（每个约平均值 = 4.5，标准差 = 0.25），这表明使用问卷可以清楚地区分受过相关疗法培训的人提供的疗法和受过其他疗法培训的人提供的疗法。
作者将上述平均值和标准差值作为“单向重复测量方差分析”的一部分呈现测试，他们说这显示出了统计学意义。
然后，他们进行了 ROC 分析，以确定将感兴趣的疗法与其他类型的疗法区分开来的阈值分数，并获得了 11 的值。
我有两个顾虑：
1：Statology 说，“重复测量单向方差分析用于确定三个或更多组的平均值之间是否存在统计学上的显着差异，其中每个组中都出现了相同的受试者。”我可以看到这里有 4 个组（4 个视频中的每个视频都有 1 组分数），但是，按照 Statology 的字面意思理解，这意味着观察者评分者是受试者，而不是他们正在评分的视频会话。如果研究的目的是找到一种方法来区分感兴趣的疗法和其他类型的疗法，那么我们实际上肯定有两组（2 个感兴趣的疗法样本和 2 个来自另一种疗法的样本）。如果我们只有 4 个样本，那么我认为统计显着性检验尚不合适。我愿意被告知我对此的想法是错误的，并欢迎任何评论。
2：维基百科说 ROC 分析是为了确定什么强度的信号应该被视为值得在雷达上显示的物体而开发的。我认为该任务必然是二进制的，以限制雷达操作员必须解析的信息量。我认为阈值不适用于确定某人是否遵守特定类型的疗法（特别是如果我们只有 4 个样本并且我们只评估了 2 种类型的疗法）。再次，我欢迎任何评论，包括对我的观点的任何更正。
我不知道是否已经发布了足够的有关该研究的信息。如果我应该提供更多详细信息，请告诉我。
编辑：我可能会接受的答案回答了我在其中一条评论中提出的这个问题...

我们需要对多少个视频进行评级才能确信我们已经开发出一种可以区分感兴趣的疗法和任何其他疗法的工具？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658834/have-the-authors-appropriately-applied-repeated-measures-one-way-anova-and-roc-a</guid>
      <pubDate>Mon, 16 Dec 2024 20:53:10 GMT</pubDate>
    </item>
    <item>
      <title>根据相关数据进行方差估计</title>
      <link>https://stats.stackexchange.com/questions/658200/variance-estimation-from-dependent-data</link>
      <description><![CDATA[我想从形式为 $y_n = u_n x_n$ 的数据中估计零均值正态分布 $x_n \sim \mathcal{N}(0, \sigma^2)$ 的方差，其中输入 $u_n \in [u_{\min}, u_{\max}]$ 可以在每次迭代 $n$ 中主动选择，即 $u_n$ 不是先验固定的，而是高度依赖于先前的选择。
在这种情况下，如何估计方差 $\sigma^2$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658200/variance-estimation-from-dependent-data</guid>
      <pubDate>Tue, 03 Dec 2024 12:19:22 GMT</pubDate>
    </item>
    <item>
      <title>在频率论的背景下，我们如何能够确定零假设为真/假？</title>
      <link>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</link>
      <description><![CDATA[引用 Casella 和 Berger (2002) 的话：假设检验由零假设 $H_0: \theta \in \Theta_0 $ 和备择假设 $H_1: \theta \in \Theta_0^c = \bar{H_0}$ 定义，其中 $\Theta$ 是总体参数 $\theta$ 的一组可能值，并且 $\Theta_0^c = \Theta - \Theta_0 $。
在频率论的设定中，$\theta$ 是一个未知但固定的量（也就是说，它是非随机的）。因此，对于给定集合$\Theta_0$，零假设$H_0$严格为真或假（但我们不知道是哪个）。备择假设，即否定，相应地为假或真。
让我们的检验统计量为$\hat{\theta} = f(X_1, ..., X_n)$。我们将拒绝域$RR \subset Range(\hat{\theta})$定义为我们选择拒绝$H_0$的检验统计量$\hat{\theta}$的值集。由于我们的样本 $X_1, ..., X_n$ 是随机的，$\hat{\theta}$ 是一个随机变量，因此数量 $p(\hat{\theta} \in RR)$ 是一个有效概率，类似于更简单的概率，如 $p(X \le 5)$
到目前为止一切顺利。然而，当我们开始定义 I 类错误时，我开始感到困惑。I 类错误是当我们拒绝 $H_0$ 即使它是 True 时。这在数学上定义为：
$$
\alpha = p(\hat{\theta} \in RR | H_0 \text{ is True}) = p(\hat{\theta} \in RR | \theta \in \Theta_0)
$$
这个概率对我来说毫无意义。$\theta$ 不是随机变量，因此 $\theta \in \Theta_0$ 不是概率事件，而是 True 或 False 值。概率框架（据我所知）不允许我们有意义地对实值或布尔值进行条件限制，而只能对事件进行条件限制。
这是怎么回事？我能做出的唯一有意义的解释是$\theta$是否是一个随机变量，这违反了频率统计的核心思想。]]></description>
      <guid>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</guid>
      <pubDate>Tue, 26 Nov 2024 01:27:13 GMT</pubDate>
    </item>
    <item>
      <title>分层 2x2 全因子试验的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/656805/sample-size-calculation-for-a-hierarchical-2x2-full-factorial-trial</link>
      <description><![CDATA[我需要计算分层 2x2 全因子试验所需的样本量（簇数和每个簇的平均观察数）。试验中心将随机分配到四种条件（基数、基数 + A、基数 + B、基数 + A + B）。在每个中心，将针对多个个体测量主要结果（指标，可能有偏差）。A 和 B 对结果的影响以及它们的相互作用将引起人们的兴趣。
如果残差分布允许，我打算使用混合线性效应模型（我希望不必求助于广义模型或其他替代方案，但我想还是有可能的）。我将对 ICC（预计相当低，介于 0.02 和 0.04 之间）和簇大小变化做出假设。 Alpha=0.05，power=0.8。
我熟悉具有分层数据结构的集群随机试验的功效计算，这些试验通过混合线性效应模型进行分析，其中单一治疗效果是感兴趣的，但不熟悉因子试验。我也在一定程度上熟悉 2x2 全因子试验的功效计算，但不熟悉分层数据结构。
我使用 Stata 和 R。
非常感谢您的帮助！如果您可以为该方法添加可引用的参考文献，那就更好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/656805/sample-size-calculation-for-a-hierarchical-2x2-full-factorial-trial</guid>
      <pubDate>Tue, 05 Nov 2024 21:40:50 GMT</pubDate>
    </item>
    <item>
      <title>场景中，X（训练）和 X（测试）上的 PCA 不是数据泄漏</title>
      <link>https://stats.stackexchange.com/questions/656799/scenario-where-pca-on-xtrain-and-xtest-is-not-a-data-leakage</link>
      <description><![CDATA[有无数（转）帖讨论使用主成分分析 (PCA) 作为交叉验证 (CV) 中回归/分类问题特征的预处理方法的问题。我知道在执行 CV 之前将 PCA 应用于整个特征数据集会导致数据泄漏，因为测试数据集与训练数据集并不完全独立。这会影响我们准确评估模型如何推广到新鲜和未见过的数据的能力。
然而，在某种情况下，我认为这并不成立，但我没有发现无数关于这个主题的帖子中提到过这个问题。我认为这甚至可能不是一种罕见的情况：
假设我们想知道特定地理研究区域（$G$）内目标变量（$Y$）的值，例如创建空间地图。对于 $G$，特征 ($X$) 是详尽可用的，例如，将高维遥感特征视为 $X$ 的输入。
我们可以在某些位置 ($Y(s)$) 采样并确定 $Y$；以预测未知的 $Y(u)$。通过这样做，我们能够拟合模型 ($F$) $F: X(s) -&gt; Y(s)$。接下来，我们可以使用该模型预测给定$X(u)$的$Y(u)$，其中预测的$\hat{Y}(u)$ = $F(X(u)$)。我们只对使用我们的模型一次感兴趣，例如创建一个映射，其中 $X(u) ⊆ G$。
为了获得最佳的 $\hat{Y}(u)$，我们将在拟合 $F$ 之前对整个特征数据集 $X(s+u)$ 应用 PCA，因为我们有 $X(u)$ 可用。
接下来，我们要检查我们的 $\hat{Y}(u)$（或 $F$）有多准确。由于我们没有从 $G$ 中抽取的进一步独立样本 $Y$，我们可以使用 CV。
如果我们在 CV 中仅对 $X(train)$ 应用 PCA 并将其投射到 $X(test)$ 上，我们不会得到悲观的结果吗？在我们的实际流程中，我们对 $X(u+s)$ 使用了 PCA，那么在 CV 中，是否有理由以不同的方式执行此操作，因为我们只想知道我们的模型在给定 $X(u) ⊆ G$ 的情况下如何推广到 $X(u)$。
我的想法是不是错了？与典型情况不同的底层概念的名称是什么，我们希望 $F$ 能够很好地推广到新鲜和独立的样本？有人知道任何针对这种特定场景的文献吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656799/scenario-where-pca-on-xtrain-and-xtest-is-not-a-data-leakage</guid>
      <pubDate>Tue, 05 Nov 2024 18:18:30 GMT</pubDate>
    </item>
    </channel>
</rss>