<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 24 Jan 2024 21:12:48 GMT</lastBuildDate>
    <item>
      <title>关于估计数据生成对象数量的困惑</title>
      <link>https://stats.stackexchange.com/questions/637687/confusion-regarding-estimating-the-number-of-data-generating-objects</link>
      <description><![CDATA[秘密房间里有一台带有$N$按钮的电脑。我们无权访问计算机，也不知道$N$。但我们知道 $N\leq 100$ 并且对于较小的 $N$ 我们有一个稍大的先验跨度&gt;s。每个按钮 $i$ 都与一个数字 $\mu_i$ 相关联，按下时，计算机会采样一个来自 $\mathcal{N}(\mu_i,\sigma=1)$ 的实数。数字 $\mu_i$ 是 $1$ 和 $10^6$。房间里有人，我们可以要求他们按任意随机按钮并获取随机数，我们假设无论之前发生了什么，他们总是同样可能按任何 $N$ 按钮。
到目前为止，我们已要求此人执行 $k$ 次并获得 $k$ 个数字&lt; span class=&quot;math-container&quot;&gt;$D_k=d_1, ..., d_k$，我们要计算 $P(N=n|D_k=d_1 ,...,d_k)$.
为此进行必要的计算似乎相当困难。但我相信可以证明 $\forall n_1\geq k,n_2\lt k: P(N=n_1|D_k=d_1...,d_k)\gt P(N =n_2|D_k=d_1...,d_k)$。
现在假设一个场景，其中 $k$ 很小，特别是小于 $100$，例如$k=10$。在这种情况下，在我看来，我们对 $N$ 的最佳选择，即 $N$ 的最可能值 是 $N=k$ （因为较小的 $N$ 的先验稍大&gt;s）。然而，这对我来说似乎相当违反直觉，因为（对于小的 $k$ ）我们的推断仅取决于我们想要生成多少数据点的意愿！无论我们将获得什么数据，我们都可以预测性操纵我们的推理。如果我决定再次骚扰房间里的人，我事先就知道我的最佳估计将是 $N=k+1$。所以我什至不需要再问那个人了。我已经可以更新我的信念了！
我希望我能够表达我的困惑。我需要澄清我在哪里犯了错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/637687/confusion-regarding-estimating-the-number-of-data-generating-objects</guid>
      <pubDate>Wed, 24 Jan 2024 20:20:50 GMT</pubDate>
    </item>
    <item>
      <title>给定两个随机变量 X 和 Y，所得差异是对数逻辑分布或 Fisk 分布，那么 X 和 Y 的分布是什么？</title>
      <link>https://stats.stackexchange.com/questions/637685/given-two-random-variables-x-and-y-and-the-resulting-difference-is-a-log-logist</link>
      <description><![CDATA[我们知道两个 Gumbel 或极端 I 型分布之间的差异是逻辑分布，我想知道如果差异（甚至比率）的结果是对数，那么随机变量 X 和 Y 的分布是什么？物流还是 Fisk 配送？]]></description>
      <guid>https://stats.stackexchange.com/questions/637685/given-two-random-variables-x-and-y-and-the-resulting-difference-is-a-log-logist</guid>
      <pubDate>Wed, 24 Jan 2024 20:01:32 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 spatstat 可视化使用 gam 拟合的多点过程模型中变量的影响？</title>
      <link>https://stats.stackexchange.com/questions/637684/how-to-visualize-the-effect-of-a-variable-in-a-multiple-point-process-model-fitt</link>
      <description><![CDATA[我正在使用 spatstat（版本 3.0-7）中的 gam 拟合多点过程模型。
需要明确的是，我使用的是一般形式的调用：
&lt;块引用&gt;
mppm(公式, data=hyperframe, eps=0.5, rbord=0.5, use.gam=TRUE)

因此我的模型是泊松过程。
当模型拟合时我想做的是绘制：

以 mgcv::plot.gam 方式给定预测变量的影响
空间趋势图。

但是，当我尝试使用函数时，我收到这些错误消息

effectfun()：错误：第一个参数“model”应该是“ppm”、“kppm”、“lppm”、“dppm”、“rppm”或“profilepl”类的拟合模型&#39;
plot.mppm()：错误：GAM 拟合不支持此计算

我正在考虑以下解决方法选项：
spatstat中的子拟合方法

分别将模型重新拟合到超帧中的每个模式（因为 subfits 不适用于 gam）：我应用了 mppm 模型中使用的相同模型公式并以 ppm 为每个模式运行它。但这样做时，我可能会为每个模式独立修改 k 参数，因为 mppm 中使用的 k 值可能会在某些变量上出现错误。
在每个单独拟合的 ppm 模型上使用 effectfun 和 plot。在这里，我担心我最终可能会得到每个图案不同的样条形状，从而使解释变得复杂

破解mppm并使用mgcv

使用我想要的 use.gam=T 模型运行 mppm。
使用 my_model$Fit$moadf 从 mppm 对象中提取 data.frame
使用 mppm 内部使用的调用，通过 mgcv::gam 拟合模型：

&lt;块引用&gt;
gam(fmla、family = quasi(link = log、variance = mu)、权重 = .mpl.W * caseweight、数据 = moadf、子集 = (.mpl.SUBSET == &quot;TRUE&quot;) ，控制= ctrl）


此时，我可以使用 mgcv 函数来可视化我需要的图（至少是给定预测变量的效果。

我的问题
我描述的方法好吗？其中之一是首选？或者，还有其他（更好）的选择来实现我的目标吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637684/how-to-visualize-the-effect-of-a-variable-in-a-multiple-point-process-model-fitt</guid>
      <pubDate>Wed, 24 Jan 2024 19:58:32 GMT</pubDate>
    </item>
    <item>
      <title>如何正确编写具有 inverse.gaussian 系列和自相关结构的 gamm() 模型？</title>
      <link>https://stats.stackexchange.com/questions/637683/how-do-i-appropriately-code-a-gamm-model-with-an-inverse-gaussian-family-and-a</link>
      <description><![CDATA[我对广义增性建模非常陌生，因此我为任何天真行为提前道歉。但我相信 GAMM 是适合我的数据的方法。我正在处理来自河流遥测研究的鱼类运动数据。我有 72 条鱼 (FishID)，并且数据点（检测）在时间上分布不均匀（跟踪间隔不相等）。我的响应变量是运动速率，我想探索不同的环境协变量，包括一年中的某一天 (DOY)，以便了解运动的季节性模式。我还认为包括 DOY 将帮助我解释时间自相关。一年中的某一天实际上是学习的一天，因为我的学习跨越了两年。
我已经确定（希望是正确的）我的数据最适合逆高斯分布和对数链接函数，因为我的低移动率远高于高移动率（范围从 1.001m/天- 15,615m/天，平均值为 251m/天）。
（我通过仅使用 s(DOY) 和 s(FishID, bs = &quot;re&quot;) 构建基本的 gams() 来做到这一点，但使用不同的系列参数来查看通过 AIC 和 draw() 最好的方法）。
（请告诉我在我的代码中查看这些原始步骤是否有帮助）。
因此，当我尝试将不同的相关结构适合我的数据以查看添加相关结构是否可以改善模型拟合（通过比较 AIC）时，我遇到了错误。考虑到自相关性是我最初被游戏吸引的原因之一，因为从本质上讲，每条鱼的运动都取决于它所进行的运动。当我进行家庭争论（例如高斯或伽玛）时，我在这里没有问题。但是，一旦我尝试将 gamm() 与 inverse.gaussian(link = log) 相匹配，就会出现错误。这是我的工作流程：
mm1 = gam(MoveRate ~ s(DOY) + s(FishID, bs = “re”),data = mv, family = inverse.gaussian(link=“log”), method = &#39;雷姆&#39;)

#测试自动校正
par(mfrow = c(1,2))
acf(resid(mm1), main = &quot;ACF&quot;) #可能明显滞后 1？
pacf(残渣(mm1),main = “pACF”)

然后我得到这个图，表明（我认为）我在 lag = 1 时具有自相关：  
因此，我将模型更改为 gamm() 结构，以便将具有自相关结构的模型与模型进行比较，而不查看考虑自相关是否可以提高模型拟合度。
#model 不带 corr
mm1 = gamm(MoveRate ~ s(DOY), 数据 = mv, 系列 = Gamma(link = &quot;log&quot;),
           random = list(FishID=~1), method = &#39;REML&#39;,niterPQL = 500) #我编码的是随机效应吗？

# corSpher 结构，推荐使用，因为数据在时间上间隔不等？
mm1b = gamm(MoveRate ~ s(DOY), 数据 = mv,
            family = Gamma(link = &quot;log&quot;), random = list(FishID=~1),
            相关性 = corSpher(form = ~DOY|FishID, nugget = TRUE), method = &#39;REML&#39;,
            硝石PQL = 100
            ) #这里出现错误

# corARMA 结构
#滞后= 1
mm1c = gamm(MoveRate ~ s(DOY) ,数据 = mv,
            family = inverse.gaussian(link=“log”), random = list(FishID=~1),
            相关性 = corARMA(form = ~1|DOY, p = 1), 方法 = &#39;REML&#39;,
            niterPQL = 500 #尝试增加迭代次数以帮助收敛？
            ) #这里也出现错误

但是我无法让这些具有任何类型相关结构的模型成功运行，以便我可以比较所有 3 个模型。我可以让相关模型与不同的系列一起运行，但我认为如果我发现 inverse.gaussian 与我原来的 gam() 中的其他模型（例如 gamma、gaussian、tw）相比是最好的，那就违背了这一点建筑。
综上所述，有谁知道为什么我的模型可能无法使用 inverse.gaussian 系列和相关结构成功运行？这些是否是适合测试的相关结构，特别是因为我的数据在时间上分布不均匀？到目前为止我的方法还有什么明显的错误吗？
我的基本想法是确定我的模型是否应该包含相关结构，然后从那里继续测试其他先验模型中的其他协变量。因此，我正在考虑的所有模型要么具有相关结构，因为它被确定最适合我的数据，要么不具有相关结构，因为我发现事实恰恰相反。
非常感谢任何指导或帮助！我渴望尽可能多地学习，以适当、正确地完成这一分析。预先感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/637683/how-do-i-appropriately-code-a-gamm-model-with-an-inverse-gaussian-family-and-a</guid>
      <pubDate>Wed, 24 Jan 2024 19:25:13 GMT</pubDate>
    </item>
    <item>
      <title>综合控制方法中仅治疗前结果变量</title>
      <link>https://stats.stackexchange.com/questions/637682/only-pre-treatment-outcome-variables-in-the-synthetic-control-method</link>
      <description><![CDATA[我正在尝试制定一个 tidysynth R 代码，该代码将产生一个合成的埃及股票市场指数（基于其他外国股票市场指数）。
我仅使用治疗前结果变量（每日收盘价）进行权重估计。我得到的结果为所有国家/地区赋予非零权重（不像 SCM 实施中通常的情况那样只选择少数国家/地区）。
我很想知道导致这个结果的代码中有什么问题？
output1 &lt;- Final_data1 %&gt;%
  合成控制（结果 = log_price，
                    单位=国家索引，
                    时间=时间单位，
                    i_unit =“埃及”, # 发生干预的单位
                    i_time = 2375, # 干预发生的时间段
                    生成_placebos = TRUE
  ) %&gt;%
  # 生成用于拟合权重的聚合预测变量
  generate_predictor(time_window = 1:2375, log_price = Mean(log_price, na.rm = T)) %&gt;%
  # 生成合成控制的拟合权重
  generate_weights(optimization_window = 1:2375, # 优化任务中使用的时间
                   margin_ipop = 0.02, sigf_ipop = 7,bound_ipop = 6 # 优化器选项
  ) %&gt;%
  # 生成综合控制
  生成控制（）

我特别不确定平均值（log_price）部分？如果我理解正确的话，只是让 SCM 通过匹配平均 log_price 来选择权重。
当我没有将mean()放入代码中时，我收到一条错误消息
`tidyr::spread()` 中出现错误：
！每行输出必须由唯一的键组合来标识。
ℹ 2375 行共享密钥

所以我解决这个问题的方法是将generate_predictor()部分按年份（2014年到2023年）划分，如下所示
output1 &lt;- Final_data1 %&gt;%
  合成控制（结果 = log_price，
                    单位=国家索引，
                    时间=时间单位，
                    i_unit =“以色列”, # 发生干预的单位
                    i_time = 2375, # 干预发生的时间段
                    生成_placebos = TRUE
  ) %&gt;%
  # 生成用于拟合权重的聚合预测变量
  generate_predictor(time_window = 2191:2375, log_price_2023 = Mean(log_price, na.rm = T)) %&gt;%
  generate_predictor(time_window = 1952:2190, log_price_2022 = Mean(log_price, na.rm = T)) %&gt;%
  generate_predictor(time_window = 1713:1951, log_price_2021 = Mean(log_price, na.rm = T)) %&gt;%
  generate_predictor(time_window = 1465:1712, log_price_2020 = Mean(log_price, na.rm = T)) %&gt;%
  generate_predictor(time_window = 1221:1464, log_price_2019 = 平均值(log_price, na.rm = T)) %&gt;%
  generate_predictor(time_window = 978:1220, log_price_2018 = 平均值(log_price, na.rm = T)) %&gt;%
  generate_predictor(time_window = 733:977, log_price_2017 = 平均值(log_price, na.rm = T)) %&gt;%
  generate_predictor(time_window = 488:732, log_price_2016 = 平均值(log_price, na.rm = T)) %&gt;%
  generate_predictor(time_window = 243:487, log_price_2015 = 平均值(log_price, na.rm = T)) %&gt;%
  generate_predictor(time_window = 1:242, log_price_2014 = 平均值(log_price, na.rm = T)) %&gt;%
  # 生成合成控制的拟合权重
  generate_weights(optimization_window = 1:2375, # 优化任务中使用的时间
                   margin_ipop = 0.02, sigf_ipop = 7,bound_ipop = 6 # 优化器选项
  ) %&gt;%
  # 生成综合控制
  生成控制（）

那么SCM实际上只选择3-4个国家来赋予非零权重。但是，它显然也赋予了预处理年份的权重。我以前没有见过像这样使用所有滞后预处理结果变量作为预测变量的论文，它有效吗？你的意见是什么？
非常感谢对该方法的任何批评、建议、意见、问题等。]]></description>
      <guid>https://stats.stackexchange.com/questions/637682/only-pre-treatment-outcome-variables-in-the-synthetic-control-method</guid>
      <pubDate>Wed, 24 Jan 2024 19:21:40 GMT</pubDate>
    </item>
    <item>
      <title>最短随访期生存分析</title>
      <link>https://stats.stackexchange.com/questions/637680/minimum-follow-up-period-survival-analysis</link>
      <description><![CDATA[想象一下，疾病 A 的手术可能会导致疾病 B。疾病 A 手术后诊断疾病 B 的最短时间是 3 个月（在这段时间之前，我们不能说疾病 B存在，考虑到已发表的文献）。
如果我有一组因疾病 A 接受过手术的患者，并且我想研究疾病 B 的发病率，并进行生存分析，但其中一些患者的随访时间不到 3 个月（疾病 B 没有出现的机会），将他们纳入研究中没有意义，对吧？我不知道我是否应该排除他们，或者由于生存分析包括经过审查的患者，我应该将他们视为经过审查的。]]></description>
      <guid>https://stats.stackexchange.com/questions/637680/minimum-follow-up-period-survival-analysis</guid>
      <pubDate>Wed, 24 Jan 2024 18:49:18 GMT</pubDate>
    </item>
    <item>
      <title>使用相同模型但两个不同（大小相同）的数据集测试 $R^2$ 的差异</title>
      <link>https://stats.stackexchange.com/questions/637678/testing-for-a-difference-in-r2-with-the-same-model-but-two-different-equally</link>
      <description><![CDATA[我有两个相同大小的数据集，$\{\vec{Y}_{1},\vec{X}_1\}$ 和 &lt; span class=&quot;math-container&quot;&gt;$\{\vec{Y}_{2},\vec{X}_2\}$。
我将相同的回归模型拟合到两个数据集，并根据该模型计算两个数据集的决定系数，$R^{2}_{1}$和$R^{2}_{2}$。
我想测试这两个值是否“相同”。
更正式地说，让零假设是模型同样适合两个数据集；观察到 $R^{2}_{1}$ 和 $R^{2}_{ 的概率是多少2}$ 在原假设下。
我认为我不能使用 F 检验，因为我没有考虑嵌套模型与完整模型。还有什么我可以使用的？或者，我可以考虑一些非参数或引导/排列测试吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637678/testing-for-a-difference-in-r2-with-the-same-model-but-two-different-equally</guid>
      <pubDate>Wed, 24 Jan 2024 18:08:39 GMT</pubDate>
    </item>
    <item>
      <title>期望最大化算法中潜变量独立性假设的合理性</title>
      <link>https://stats.stackexchange.com/questions/637677/justification-of-independence-assumption-for-latent-variables-in-expectation-max</link>
      <description><![CDATA[当在 EM 算法中导出 ELBO/自由能时，通常以“通用”方法完成。观察变量和潜在变量的情况，然后引入独立（或独立同分布）变量的假设。
例如，令 $\mathbf X$ 为观察变量，而 $\mathbf Z$​​ 为未观察变量/潜在变量我们可以将 ELBO/自由能表示为
\begin{align}
\mathcal F\left(q(\mathbf Z), \球符号\theta \right) &amp; = \log p(\mathbf X \lvert\ballsymbol\theta)
-\sum_{\mathbf{Z}} q\left(\mathbf{Z}\right) \log \frac{q\left(\mathbf{Z}\right)}{p\left(\mathbf{Z} \mid \mathbf{X}, \ballsymbol{\theta}\right)}\\
&amp;= \log p(\mathbf X \lvert \球符号 \theta)
-D_{\mathbb{K} \mathbb{L}}\left(q\left(\mathbf{Z}\right) \| p\left(\mathbf{Z} \mid \mathbf{X}, \ball符号 {\theta}\right)\right)\\
&amp;= \sum_{\mathbf Z} q(\mathbf z) \log \frac{p(\mathbf X, \mathbf Z \lvert \球符号\theta)}{q(\mathbf Z)}。
\end{对齐}
论证继续认为，在观察变量 $\mathbf X $ 由独立观察值组成的（典型）情况下，它可以分解为 $(\mathbf x_1, \ldots, \mathbf x_N)$ （例如 $N$ 独立观测值的数据集）。此外，潜在变量可以分解为独立的 $(\mathbf z_1, \ldots, \mathbf z_N)$ 但没有给出这种潜在变量独立性的理由（请参阅[1]、[2]）。我认为这一步不一定是显而易见的。
在数据和潜在变量独立的假设下，我们可以分解 $p(\mathbf X, \mathbf Z) = \prod_{n=1}^N p (\mathbf x_n, \mathbf z_n)$ 并且你可以看到 ([1], [2]) ELBO/自由能可以重写为
\begin{align}
\mathcal F\left(q(\mathbf Z), \球符号\theta \right) &amp; = \sum_{n=1}^N \sum_{\mathbf z_n} q_n(\mathbf z_n) \log \frac{p(\mathbf x_n, \mathbf z_n \lvert \球符号 \theta)}{q_n(\ mathbf z_n)}。
\end{对齐}
那么，我们如何证明潜变量是独立的呢？潜在变量是否必须独立于观察到的变量？如果是这样，为什么？如果潜在变量不独立会发生什么？
&lt;小时/&gt;
参考文献
[1]：第 6 页；尼尔，R.M.，辛顿，G.E. （1998）。 Em 算法的观点证明了增量、稀疏和其他变体的合理性。在图形模型中学习。北约 ASI 系列，第 89 卷。施普林格，多德雷赫特。 9_12
[2]：第 453 页 Christopher M. Bishop。 2006。模式识别和机器学习。施普林格出版社，柏林，海德堡。]]></description>
      <guid>https://stats.stackexchange.com/questions/637677/justification-of-independence-assumption-for-latent-variables-in-expectation-max</guid>
      <pubDate>Wed, 24 Jan 2024 18:07:09 GMT</pubDate>
    </item>
    <item>
      <title>hyperloglog 算法计算独立同分布随机变量的概率分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637676/hyperloglog-algorithm-to-compute-the-probablity-disribution-of-iid-random-variab</link>
      <description><![CDATA[我有一个随机变量 $Y={1,2,3,2,4,5,2,3,6,7,2,8,9,10, 2}$
我想使用 hyperloglog 方法来估计概率 $P(Y=2)$ 而不是计算确切的概率
我可以使用 hyperloglog 方法吗？如果是这样怎么办？
如何证明估计概率接近真实概率？
我不完全理解 hyperloglog 方法。我不知道它的一些参数是如何选择的，比如 alpha 和寄存器。
编辑：我提供的随机变量很小，但我询问 hyperlogolog 的原因是我想在恒定时间 O(1) 内计算非常大的随机变量的概率。而不是计算确切的出现次数并除以元素总数，这需要线性时间 O(n)]]></description>
      <guid>https://stats.stackexchange.com/questions/637676/hyperloglog-algorithm-to-compute-the-probablity-disribution-of-iid-random-variab</guid>
      <pubDate>Wed, 24 Jan 2024 17:26:18 GMT</pubDate>
    </item>
    <item>
      <title>计算并显示较大组内子组响应的变化</title>
      <link>https://stats.stackexchange.com/questions/637674/calculating-and-displaying-variation-of-sub-group-responses-within-larger-group</link>
      <description><![CDATA[我有一个问题，有 3 个可能的答案（是、否、不确定），并且我有两组的回答。 A组和B组。
A组有三个子组（A1、A2、A3），
B 组有两个子组（B1、B2）
我有选择每个答案的参与者数量以及选择每个答案的样本百分比。
样本大小各不相同，因此为了清楚起见，我想使用百分比进行比较，并使用聚类列来显示每个组答案的列。
我想添加误差线，显示主组内每个子组的响应范围。
当我比较百分比时，我应该对误差线使用什么度量？标准差合适吗？
如果没有，有其他推荐吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637674/calculating-and-displaying-variation-of-sub-group-responses-within-larger-group</guid>
      <pubDate>Wed, 24 Jan 2024 16:54:16 GMT</pubDate>
    </item>
    <item>
      <title>债券发行数据的插值</title>
      <link>https://stats.stackexchange.com/questions/637673/interpolation-on-bond-issuance-data</link>
      <description><![CDATA[我目前正在对新冠疫情期间的债券发行进行分析。
我将对多个债券发行特征以及多个公司关键特征（例如盈利能力、有形性、市账率等）进行利差线性回归。
我的问题是，我只有季度的这些公司特征，而我每天都有债券发行的信息。
我考虑过汇总一家公司在一个季度内的所有发行，但由于发行特征也取决于发行，并且可能不是数字（例如发行类型），这将导致错误的分析。汇总还可能导致统计误解，因为每家公司的财务季度末不一定相同。
我想到的唯一解决方案是为每个问题提供每月的邮票，通过公司标识符和“属于同一公司”的组来识别发行这些问题的公司。通过唯一的债券标识符发行。但为此，我还需要更改公司关键特征的数据。
我正在考虑进行插值以获得季度的月度数据，但我不确定这是否是一个好主意，或者是否会导致我得出错误的结论。
你们认为插值可行吗？如果是，您建议我做什么？如果没有，您还有其他想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637673/interpolation-on-bond-issuance-data</guid>
      <pubDate>Wed, 24 Jan 2024 16:46:04 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用什么 R 包将逆概率权重（以调整调查设计和波间损耗）合并到 GEE 模型中？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637671/what-r-package-can-i-use-to-incorporate-inverse-probability-weights-to-adjust-f</link>
      <description><![CDATA[我正在分析一个纵向数据集（使用 R），该数据集提供了逆概率权重来调整初始采样方法（两阶段聚类）和随后的差分波间损耗，旨在获得代表源群体的研究群体。我想运行未加权和加权的 GEE 模型（由于教室中参与者的聚集而选择 GEE 模型）并且我有一个二元结果（在单个时间点进行评估，即没有重复的测量）。
我有两个问题：

geeglm() 不会接受编码为因子的结果（用两个级别编码：否/是），即使 family = “二项式” 。这是一个完整的案例分析，因此 NA 被排除在数据框中。
这是我的模型的结构：
mod &lt;- geeglm(结果 ~ 预测器 1 + 预测器 2, data=complete_df, family = “二项式”, id=cluster_id, corstr = “可交换”)

错误消息如下：
lm.fit(zsca, qlf(pr2), offset= soffset 中的错误：“y”中的 NA/NaNInf
另外：警告消息：1. 在模型响应（mf，“numeric”）中：使用 type =“numeric”带有因子响应的将被忽略 2. 在 ops.factor(y, mu) 中： &#39;-&#39; 对于因子没有意义
但是，我的（未加权）GEE 模型运行时没有错误消息，结果为整数 (0/1)。有谁知道为什么会这样？是否不可能在二项式 GEE 中使用因子结果？

什么 R 包可以让我将权重适当地纳入 GEE 模型中？我尝试使用参数权重 = geeglm() 但收到此错误消息：
“警告消息：在 eval(family$initialize) 中：二项式 glm 中的非整数#成功！”

我推测这可能是由于权重（数字）与我的整数结果相互作用而引起的...尽管有错误消息，加权 GEE 模型的结果打印出来并且看起来相对合理...当我浏览了geepack手册，权重参数来自glm()并指定“对于二项式glm，当响应是成功比例时，先验权重用于给出试验次数”，所以我不确定这是否是适合我的分析吗？
我读过使用类似数据集的论文，这些数据集已成功在 GEE 模型中应用此类权重，但使用不同的软件，因此我不确定如何继续！
任何建议将不胜感激！！]]></description>
      <guid>https://stats.stackexchange.com/questions/637671/what-r-package-can-i-use-to-incorporate-inverse-probability-weights-to-adjust-f</guid>
      <pubDate>Wed, 24 Jan 2024 16:25:31 GMT</pubDate>
    </item>
    <item>
      <title>不可折叠性和缺少误差项如何影响回归系数</title>
      <link>https://stats.stackexchange.com/questions/637668/how-does-non-collapsibility-and-the-lack-of-an-error-term-affect-coefficients-in</link>
      <description><![CDATA[我从此处读到，在 logit 和 Cox 等非线性模型中， 由于缺少误差项，当省略协变量时，系数可能会出现偏差（通常为零）；我知道如果排除的协变量是混杂因素，那么偏见可能会如何产生，但无论如何，这篇文章都暗示偏见是一种暗示；我不明白为什么会这样。例如，在线性回归中，误差项只是量化观测数据到拟合线的距离；附加系数（除非它们是混杂因素）会减少误差，但不会改变系数的值。我不明白它是如何“吸收”任何不合身的？
我可以从此处看到不可折叠性如何导致 OR这不具有代表性（有偏见？），而且很明显：我认为这延伸到了 logit 模型。此外，我知道风险比率是可折叠的，所以他们不存在这个问题；然而，这些可以通过没有误差项的非线性模型来估计。这让我更加困惑非线性、误差项和偏差之间的关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/637668/how-does-non-collapsibility-and-the-lack-of-an-error-term-affect-coefficients-in</guid>
      <pubDate>Wed, 24 Jan 2024 15:44:17 GMT</pubDate>
    </item>
    <item>
      <title>计算两个因变量之比的平均值和标准差</title>
      <link>https://stats.stackexchange.com/questions/637662/calculate-mean-and-standard-deviation-of-the-ratio-of-two-dependent-variables</link>
      <description><![CDATA[我有一台仪器，我想了解所进行测量的不确定性，以便每次执行单次测量时，我都可以应用获得的误差，从而将其与其他测量进行比较。为了估计不确定性，我接连进行了 30 次测量。
我有兴趣从该仪器中获取的变量实际上是仪器在同一时刻测量的两个变量 A 和 B 的比率，因此对于每一轮测量，我都会有一对 ( A$_i$, B$_i$), 其中 i = 1, ... 30. 我的因此，最终变量将为 $y = \frac{A}{B}$。
我实验室中的一些人所做的就是进行这 30 次测量，计算比率的平均值和标准差，就好像该比率是直接测量一样。即：
$\bar{y} = \frac{1}{N} \sum \frac{A_i}{B_i}$ 和 $\sigma_y = \frac{1}{N - 1} \sum (y_i - \bar{y})^2$
不过，我的第一个想法是将 A 和 B 视为两个独立的测量值（因为它们本身就是这样），彼此依赖（因为来自同一台仪器），并使用误差传播来计算标准差公式：
$\bar{y} = \frac{\bar{A}}{\bar{B}}$ 和 $\sigma_y = \sqrt((\frac{\partial y}{\partial A})^2 \sigma_A^2 + (\frac{\partial y}{\partial B})^2 \sigma_B^2 + 2 \frac{\partial y}{\partial A} \frac{\partial y}{\partial B} \sigma_{AB})$
现在我的问题是：这两种方法在理论上有什么区别？什么时候应该使用第一种方法（假设这是正确的方法），什么时候使用第二种方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/637662/calculate-mean-and-standard-deviation-of-the-ratio-of-two-dependent-variables</guid>
      <pubDate>Wed, 24 Jan 2024 14:12:34 GMT</pubDate>
    </item>
    <item>
      <title>Bing 藏文错误表情符号问题</title>
      <link>https://stats.stackexchange.com/questions/637505/the-bing-tibetan-glitch-emoji-problem</link>
      <description><![CDATA[这是一个非常有趣的数理统计难题，是我在使用 Bing 时偶然发现的。事实证明这个问题太深了，我花了相当长的时间思考如何解决它！尽管背景故事相对有趣，但看起来这可能是一个非常普遍（众所周知？）的统计问题。
请原谅我的篇幅，但我认为背景故事很有趣，值得分享:)
谜题：Bing 的新 AI 语言模型有一个非常奇特的错误。如果您向它发送一个来自未知“故障表情符号”列表中的单个表情符号，它会随机用藏语回复。例如，这是它对 🥲 的响应：

目标是描述引起此响应的所有表情符号的特征。由于表情符号有 3782 个，因此每个表情符号发送一条消息需要几个小时。
但有趣的是。如果您向 Bing 发送的消息仅包含有此“故障”的表情符号，财产，它会用西藏的废话来回应。但是，即使您发送一个没有表情符号的表情符号，它也会正常响应。这是两者的示例，其中 🥲🫥🤥🤫🤠 是故障表情符号，而 😊 不是：

因此，可以“批量测试”表情符号，并可能减少表征该集合所需的消息数量。大批量的风险更大，因为如果你足够幸运，选择了所有故障表情符号，你会立即获得大量信息，但如果没有，你除了至少有一个表情符号不是故障表情符号之外，一无所知。 
问题：用最少的消息来描述整套故障表情符号的最佳策略是什么？
为了简单起见，以下是我们可以做出的数学假设：

所有表情符号都同样可能是故障表情符号。
对于哪些表情符号是故障标记、哪些不是故障标记，没有特定的模式。
各种表情符号的故障/非故障状态在条件上都是相互独立的。
特别是，如果我们知道某些表情符号是或不是故障表情符号，我们假设这与概率无关，例如相邻的故障表情符号或任何其他表情符号。
我们可以访问一个黑盒函数，该函数将表情符号的一些子集作为输入，并且当且仅当每个表情符号都是故障表情符号时才返回 TRUE。

那么问题实际上是：如果你作为一个坚定的常客/贝叶斯/无论如何，被要求解决这个问题，并在尽可能少的查询中，在一些可证明最优的问题（相对到您认为“最佳”的任何内容）您会如何处理？
在我看来，“最佳”可能有多种概念。贝叶斯主义者和频率主义者对此可能有不同的看法。一个人可以尝试查看发送的消息数量的预期值；另一个可能会查看似然函数等。所以，我将其保留。我将在下面发布我的部分解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/637505/the-bing-tibetan-glitch-emoji-problem</guid>
      <pubDate>Tue, 23 Jan 2024 01:23:09 GMT</pubDate>
    </item>
    </channel>
</rss>