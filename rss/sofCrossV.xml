<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 31 Aug 2024 18:19:08 GMT</lastBuildDate>
    <item>
      <title>ARIMA 模型系数估计</title>
      <link>https://stats.stackexchange.com/questions/653678/estimation-of-model-coefficients-of-arima-model</link>
      <description><![CDATA[假设我在 R 中有以下 ARIMA 模型估计
&gt; arima(x = LakeHuron, order = c(0,0,1), xreg = time(LakeHuron) - 1920)

调用：
&gt; arima(x = LakeHuron, order = c(0, 0, 1), xreg = time(LakeHuron) - 1920)

调用：
arima(x = LakeHuron, order = c(0, 0, 1), xreg = time(LakeHuron) - 1920)

系数：
ma1 截距时间(LakeHuron) - 1920
0.7822 579.0821 -0.0233
s.e. 0.0651 0.1400 0.0049

但是，我还分别使用线性回归计算了外生变量和自相关残差的模型系数，如下所示
&gt; model_lm = lm(&#39;y~x&#39;, data = data.frame(x = time(LakeHuron) - 1920, y = LakeHuron))
&gt; model_Res = lm(&#39;y~x-1&#39;, data.frame(y = resid(model_lm), x = c(NA, resid(model_lm)[-length(LakeHuron)])))
&gt; summary(model_lm )

调用：
lm(formula = &quot;y~x&quot;, data = data.frame(x = time(LakeHuron) - 1920, 
y = LakeHuron))

残差：
最小值 1Q 中值 3Q 最大值 
-2.50997 -0.72726 0.00083 0.74402 2.53565 

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 579.088786 0.115047 5033.507 &lt; 2e-16 ***
x -0.024201 0.004036 -5.996 3.55e-08 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：96 个自由度上的 1.13

多重 R 平方：0.2725，调整后的 R 平方：0.2649

F 统计量：1 和 96 DF 上的 35.95，p 值：3.545e-08

&gt; summary(model_Res )

调用：
lm(formula = &quot;y~x-1&quot;, data = data.frame(y = resid(model_lm), 
x = c(NA, resid(model_lm)[-length(LakeHuron)])))

残差：
最小值 1Q 中值 3Q 最大值 
-1.94335 -0.48386 0.01758 0.43251 1.91083 

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
x 0.79084 0.06556 12.06 &lt;2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：96 个自由度上的 0.7125
（由于缺失，删除了 1 个观察值）
多重 R 平方：0.6025，调整后的 R 平方：0.5984

F 统计量：1 和 96 DF 上的 145.5，p 值：&lt; 2.2e-16

这两种方法似乎给出了类似的结果。但是我想知道从理论上讲，对于任何数据，情况是否总是如此？另外，哪种方法更好，为什么？
我还有一个问题，我正在使用 MA 模型，在第二种方法中，我应该使用 自相关调整 SE 而不是正常 SE 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653678/estimation-of-model-coefficients-of-arima-model</guid>
      <pubDate>Sat, 31 Aug 2024 18:05:26 GMT</pubDate>
    </item>
    <item>
      <title>层次结构取决于潜在变量的层次模型</title>
      <link>https://stats.stackexchange.com/questions/653677/hierarchical-models-where-the-hierarchy-structure-depends-on-a-latent-variable</link>
      <description><![CDATA[在实际层次结构取决于潜在变量的情况下，我很难为贝叶斯推理制定层次模型。我想知道这是否可能。这是一个例子。
我有一些观察变量$\theta$，它们依赖于四个潜在变量$m$、$z_1$、$z_2$和$z_3$。这些第一个变量分布为 $m \sim {\rm DiscreteUniform}(3)$ （不确定这里的标准符号，但我的意思是 $P(m=1) = P(m=2) = P(m=3) = 1/3$）您可以将 $m$ 视为一个 RV，它确定 $z_i$ 中的哪个是“最大值”含义如下：
如果 $m=1$，则
$$
\begin{align}
z_1 &amp;\sim {\rm Uniform}(0,1) \\
z_2 &amp;\sim {\rm Uniform}(0, z_1) \\
z_3 &amp;\sim {\rm Uniform}(0, z_2)
\end{align}
$$
如果 $m=2$，则
$$
\begin{align}
z_2 &amp;\sim {\rm Uniform}(0,1) \\
z_1 &amp;\sim {\rm Uniform}(0, z_2) \\
z_3 &amp;\sim {\rm Uniform}(0, z_2)
\end{align}
$$
如果 $m=3$，则
$$
\begin{align}
z_3 &amp;\sim {\rm Uniform}(0,1) \\
z_2 &amp;\sim {\rm Uniform}(0, z_3) \\
z_1 &amp;\sim {\rm Uniform}(0, z_2)
\end{align}
$$
这里的想法是，$z_i$中的一个应该具有最大值，并且没有$z_i$可以大于相邻的（这是我的特征我对整个构造过程非常感兴趣）。我认为，这些 $z_i$ 继续以一种对当前问题不重要的方式确定我观察到的变量。
有没有办法将其表述为适当的分层模型，根据 $m$ 的值具有不同的“分支”？或者这真的是竞争分层模型之间贝叶斯模型选择的问题？无论哪种情况，我都会很感激任何见解或资源建议。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653677/hierarchical-models-where-the-hierarchy-structure-depends-on-a-latent-variable</guid>
      <pubDate>Sat, 31 Aug 2024 17:58:08 GMT</pubDate>
    </item>
    <item>
      <title>蒙特卡洛积分方法利用黑匣子给出的一组代表点</title>
      <link>https://stats.stackexchange.com/questions/653676/monte-carlo-integration-methods-utilizing-a-set-of-representative-points-given-b</link>
      <description><![CDATA[考虑对可能离散的多峰分布进行函数积分的任务。假设黑匣子给了我一组独立但分布相同的点，这些点对应于密度/概率最高的模式，但不一定成比例。*
蒙特卡罗方法中是否有一个研究领域可以从这样的集合中受益，同时保留收敛保证？有哪些方法？这里的“收敛保证”是指该方法的估计量是一致的/无偏的。如果它有助于回答这个问题，可以假设可以从这个未知分布中抽取更多的样本。
*也就是说，它们不是来自目标分布的样本，但恰好聚集在模式周围。更正式地说，这个代表性集合所来自的底层分布的密度是未知的。一个设想的场景是模式搜索算法，保证从分布的精确模式中采样。
例如，Metropolis-Hastings 肯定可以从这样的初始化中受益。
一个非示例是重要性采样，因为我们无法获得此类样本集的密度。
类似地，并行回火也可以从概率上获益，但顺序蒙特卡洛采样器则不行。]]></description>
      <guid>https://stats.stackexchange.com/questions/653676/monte-carlo-integration-methods-utilizing-a-set-of-representative-points-given-b</guid>
      <pubDate>Sat, 31 Aug 2024 17:40:22 GMT</pubDate>
    </item>
    <item>
      <title>说统计模型是位置家族是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/653675/what-does-it-mean-to-say-that-a-statistical-model-is-a-location-family</link>
      <description><![CDATA[我想知道说统计模型是位置族是什么意思。查看了一些定义，我得出了位置族定义的三种可能解释。
设$(\mathbb{R},\mathfrak{B}_\mathbb{R},P_\theta )_{\theta\in\Theta }$为一个统计模型，其中$\mathfrak{B}_\mathbb{R}$表示$\mathbb{R}$的 Borel $\sigma$-代数。对于所有 $\theta$，定义 $F_\theta :\mathbb{R\to R}$ 为 $F_\theta (x):=P_\theta ((-\infty ,x])$。
我的问题：下列哪个定义是正确的？
定义 1： 我们说 $(\mathbb{R},\mathfrak{B}_\mathbb{R},P_\theta )_{\theta\in\Theta }$ 是一个位置族，如果对于任何 $\theta\in\Theta$ 并且 $a\in\mathbb{R}$ 函数 $F:\mathbb{R}\to \mathbb{R}$ 由 $F(x):=F\!_{\theta} (x+a)$ 给出，属于集合 $\{F_\theta\}_{\theta\in\Theta }$。
定义 2： 我们说 $(\mathbb{R},\mathfrak{B}_\mathbb{R},P_\theta )_{\theta\in\Theta }$ 是一个位置族，如果存在 $\theta_0\in\Theta$，使得对于所有 $\theta\in\Theta$，都有 $a_\theta \in\mathbb{R}$，使得对于所有 $x\in\mathbb{R}$，都有 $F_\theta (x)=F_{\theta_0}(x-a_\theta )$。
定义 3：我们说 $(\mathbb{R},\mathfrak{B}_\mathbb{R},P_\theta )_{\theta\in\Theta }$ 是位置族，如果存在 $\theta_0\in\Theta$，使得以下命题为真：

对于所有 $a\in\mathbb{R}$，由 $F(x):=F\!_{\theta_0} (x+a)$ 给出的函数 $F:\mathbb{R}\to \mathbb{R}$ 属于集合 $\{F_\theta\}_{\theta\in\Theta }$；$\theta\in\Theta$ 存在 $a_\theta \in\mathbb{R}$ 使得对于所有 $x\in\mathbb{R}$，$F_\theta (x)=F_{\theta_0}(x-a_\theta )$。

例如，使用定义 2，很容易得出统计模型 $ (\mathbb{R},\mathfrak{B}_\mathbb{R},N(\mu ,\sigma ^2))_{\mu \in\mathbb{R}}$（其中 $\sigma^2&gt;0$ 固定）是一个位置系列。]]></description>
      <guid>https://stats.stackexchange.com/questions/653675/what-does-it-mean-to-say-that-a-statistical-model-is-a-location-family</guid>
      <pubDate>Sat, 31 Aug 2024 17:25:13 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证来评估特征选择的不同互信息阈值</title>
      <link>https://stats.stackexchange.com/questions/653673/using-crossvalidation-to-evaluate-different-mutual-information-threshholds-for-f</link>
      <description><![CDATA[我目前正在尝试确定分类任务中特征选择的互信息阈值。我的想法是根据位置参数（例如中位数、top75% 等）设置不同的阈值，然后通过 CV 对训练集进行评估。由于我计划部署几个不同的模型（朴素贝叶斯、CART、TAN），那么是否有必要单独比较每个模型的每个阈值的差异，还是只需比较阈值 1 的平均 acc 和阈值 2 的平均 acc 就足够了？
这通常是一种可接受的方法，还是您会推荐一种更科学的方法？
我也尝试了 boruta 方法，但该算法只排除了 29 个特征中的 1 个，尽管其中许多特征的 MI 分数很低（0,001）。与仅使用 top50%/75% 的模型相比，使用其余 28 个特征的模型在 CV 中的表现也更差。
总的来说，我试图避免特征选择过程被批评为不科学。然而，我读过的许多论文都指出，没有最好的方法来做到这一点。
你会推荐什么方法？从我的方法来看，应该改进什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/653673/using-crossvalidation-to-evaluate-different-mutual-information-threshholds-for-f</guid>
      <pubDate>Sat, 31 Aug 2024 14:13:00 GMT</pubDate>
    </item>
    <item>
      <title>正态分布是如何由现实世界数据构成的</title>
      <link>https://stats.stackexchange.com/questions/653672/how-is-the-normal-distribution-made-from-real-world-data</link>
      <description><![CDATA[我是一名中学生，我正在尝试理解人们在现实世界中如何创建和应用正态分布。
从我有限的知识来看，常识告诉我，他们收集原始数据，然后继续从中创建一个直方图，如果这个直方图足够接近完美的钟形曲线（我假设他们使用其他统计指标（如偏度等）来确定这一点），然后他们使用标准偏差和平均值并将其插入正态分布函数以获得实际的钟形曲线。
因为即使身高之类的东西是正态分布的，我实际上假设在现实世界中，当有人收集数据时，他们可能会发现身高可能不是正态分布的（例如，一个有很多孩子的城镇等）。所以在我的脑海里，我假设科学家首先制作一个直方图来检查它是否大致接近钟形曲线。]]></description>
      <guid>https://stats.stackexchange.com/questions/653672/how-is-the-normal-distribution-made-from-real-world-data</guid>
      <pubDate>Sat, 31 Aug 2024 12:24:07 GMT</pubDate>
    </item>
    <item>
      <title>模拟具有特定事件和多个变量的 HR 的生存数据集</title>
      <link>https://stats.stackexchange.com/questions/653670/simulate-a-survival-dataset-with-specific-events-and-hr-for-multiple-variables</link>
      <description><![CDATA[在我的教学课上，学生需要阅读并评论一篇科学文章。
下一课是编码课，我希望他们根据这篇文章重新创建一个情节，以便他们了解其中的利害关系。
这是源数据集，情节（带注释的森林图）无关紧要：
tibble::tibble(
category = rep(c(&quot;Marker 1&quot;, &quot;Marker 2&quot;), each = 2L),
level = rep(c(&quot;Yes&quot;, &quot;No&quot;), 2),
gpA_n_events = c(149, 60, 119, 92),
gpA_n_patients = c(233, 98, 192, 139),
gpB_n_events = c(74, 35, 66, 43),
gpB_n_patients = c(115, 47, 96, 67),
hr_pfs__estimate = c(0.55, 0.51, 0.48, 0.54),
hr_pfs__ci_inf = c(0.42, 0.33, 0.35, 0.37),
hr_pfs__ci_sup = c(0.73, 0.79, 0.65, 0.73),
gpA_pfs__median = c(10, 11.7, 10.3, 10.8),
gpA_pfs__ci_inf = c(8.3, 9.5, 8.6, 8.4),
gpA_pfs__ci_sup = c(11.4, 17.7, 12.3, 13.7),
gpB_pfs__median = c(5.4, 5.9, 5.3, 5.3),
gpB_pfs__ci_inf = c(4, 3.4, 4.1, 3.4),
gpB_pfs__ci_sup = c(7.8, 8.2, 7.8, 7.2),
)


这里，多个标记（我有 8 个类别）每个级别的事件数量不同，风险比也不同（计算得出来自 Cox 模型）。
我想生成一个数据集，该数据集将产生与表格相同的结果：A 组 331 名患者和 B 组 163 名患者，生存时间以获得指定的 HR（gpA vs gpB）。事件数和 CI 中位数不太重要（但如果简单的话会更好）。
我看到了关于该主题的几个很棒的答案（例如 此处、此处 和 此处），但目的不同（不是相同的 N，只有一个模型...）。
我想做的事情可行吗？如果可以，哪种方法合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/653670/simulate-a-survival-dataset-with-specific-events-and-hr-for-multiple-variables</guid>
      <pubDate>Sat, 31 Aug 2024 10:41:06 GMT</pubDate>
    </item>
    <item>
      <title>我可以在 R 中使用哪些统计测试来确定使用 DIANA（DIvisive ANAlysis Clustering）获得的聚类的统计意义？</title>
      <link>https://stats.stackexchange.com/questions/653669/what-statistical-tests-can-i-use-in-r-to-ascertain-the-statistical-significance</link>
      <description><![CDATA[我有一组表皮碳氢化合物 (CHC) 数据，这些数据来自 60 个蚜虫样本，这些样本来自蚜虫活动季节的中期、早期和晚期，蚜虫以三种不同的植物为食。由于季节、蚜虫以哪种植物为食，或者由于许多不同的非生物因素，CHC 可能会有所不同。我想使用 DIANA 来可视化数据。我在网上找到了一个类似的分析，其中使用 R 完成了此分析：
chcmain &lt;- read.csv(&quot;chcsitobion.csv&quot;, header = TRUE)
row.names(chcmain) &lt;- chcmain$X
chcmain &lt;- chcmain[,2:18]

#对数变换数据
chc_matrixmain &lt;- log(data.matrix(chcmain))

#计算除法层次聚类
hc_d &lt;- diana(chc_matrix)

#除法系数；发现的聚类结构数量
hc_d$dc

#绘制树状图
pltree(hc_d, cex = 0.6, hang = -1, main = &quot;Dendrogram of diana&quot;)

#将 diana()tree 切成 4 组
clust &lt;- cutree(as.hclust(hc_d), k=4)

#在散点图中可视化结果
fviz_cluster(list(data = chc_matrix, cluster = clust))

#在树状图内可视化聚类
pltree(hc_d, hang=-1, cex = 0.6)
rect.hclust(hc_d, k =4, border = 2:10)

我真的不明白他们是如何得出 4 个聚类的，以及我是否可以进行任何统计以确保获得的聚类在统计上与每个聚类不同其他。
如果我使用 DIANA，您能否指导我如何确定簇的数量以及我可以做哪些统计来支持我的分析？
我不可能对预期的簇数或测试特定假设做出先验假设，因为我的数据可能受到多种因素的影响。
散点图显示了两个主成分，但我不明白这是使用前两个 PC 还是所有 PC 创建的。
上面的代码对我来说是有效的，但缺少关于他们如何确定 4 个簇以及应该进行哪些统计测试来支持结果的步骤，而且我不太清楚如何将此分析用于我自己的数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/653669/what-statistical-tests-can-i-use-in-r-to-ascertain-the-statistical-significance</guid>
      <pubDate>Sat, 31 Aug 2024 10:22:17 GMT</pubDate>
    </item>
    <item>
      <title>与 GARCH-DCC 方法相比，使用多元滤波历史模拟和单变量 GARCH 模型的优缺点是什么？</title>
      <link>https://stats.stackexchange.com/questions/653668/what-are-the-pros-and-cons-of-using-multivariate-filtered-historical-simulation</link>
      <description><![CDATA[我正在评估股票投资组合的市场风险，并在 MATLAB 文档中看到了一个使用多元过滤历史模拟技术的示例：
https://it.mathworks.com/help/econ/using-bootstrapping-and-filtered-historical-simulation-to-evaluate-market-risk.html
这种方法将单变量 GARCH 模型与资产收益概率分布的非参数规范相结合。 FHS 允许通过引导标准化残差和模拟未来回报来生成预测。
我还知道 GARCH-DCC（动态条件相关性）方法，该方法对资产回报之间的时变相关性进行建模。我有兴趣了解使用 FHS 和 GARCH 模型与 GARCH-DCC 方法的优缺点。
每种方法的优点和局限性是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/653668/what-are-the-pros-and-cons-of-using-multivariate-filtered-historical-simulation</guid>
      <pubDate>Sat, 31 Aug 2024 09:51:03 GMT</pubDate>
    </item>
    <item>
      <title>MatchIt 边际效应</title>
      <link>https://stats.stackexchange.com/questions/653667/matchit-marginal-effects</link>
      <description><![CDATA[我正尝试使用 MatchIt 估计治疗的 ATT，但不确定它是边际效应还是条件效应。在估计结果的插图中，它说：

此外，对于连续结果，当结果模型中存在治疗-协变量相互作用时，条件效应可能会被错误地解释为边际效应估计。如果协变量不是以目标人群中的平均值为中心（例如，ATT 的治疗组、ATE 的完整样本或 ATM 的剩余匹配样本），治疗系数将不对应于目标人群中的边际效应；它将对应于协变量值等于零时的治疗效果，这可能没有意义或不合理。当结果模型中包含协变量时，G 计算始终是估计效应的最安全方法，尤其是在存在治疗-协变量相互作用的情况下。

在这里，结果是连续的，在结果模型中，我有一个二元治疗、匹配变量 X（全部连续）和一个相互作用。由于我正在使用 G-Computation（我认为），这是否估计了边际效应？
m &lt;- matchit(D ~ X,
data = data,
method = &quot;cem&quot;, 
estimand = &quot;ATT&quot;, 
k2k = FALSE)

matchdata &lt;- match.data(m)

fit &lt;- lm(Y ~ D + X + D * X,
data = matchdata, weights = weights)

avg_comparisons(fit, variable = &quot;D&quot;,
vcov = &quot;HC3&quot;, 
newdata = subset(matchdata, D == 1),
wts = &quot;weights&quot;) 
]]></description>
      <guid>https://stats.stackexchange.com/questions/653667/matchit-marginal-effects</guid>
      <pubDate>Sat, 31 Aug 2024 09:50:38 GMT</pubDate>
    </item>
    <item>
      <title>分类变量的效应大小[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653666/effect-size-of-categorical-variables</link>
      <description><![CDATA[如果我对两个不同维度的类别进行生物测试，样本量较大，为 190 个，df=63。Cramer V 是否适合这种情况？考虑到效应大小，解释会如何？SPSS 计算出的 lambda、列联系数是否也有效？]]></description>
      <guid>https://stats.stackexchange.com/questions/653666/effect-size-of-categorical-variables</guid>
      <pubDate>Sat, 31 Aug 2024 09:30:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们使用 KL 散度而不是交叉熵？[重复]</title>
      <link>https://stats.stackexchange.com/questions/653664/why-are-we-using-kl-divergence-over-cross-entropy</link>
      <description><![CDATA[我读过这个问题
为什么我们在 t-SNE 目标函数中使用 Kullback-Leibler 散度而不是交叉熵？
我无法完全理解答案。
如果我们使用 KL 散度作为损失，它不是与使用交叉熵具有相同的效果吗？当 KL 散度很大时，交叉熵也很大，反之亦然。两者的变化量也没有太大区别。此外，KL 散度还有更多项需要计算，即熵。
从这个角度来看，我找不到使用 KL 散度而不是交叉熵的理由。
有人能帮我吗？
（+ 如果 KL 散度真的比交叉熵更好（对于损失函数），我也很好奇为什么有些任务仍在使用交叉熵）]]></description>
      <guid>https://stats.stackexchange.com/questions/653664/why-are-we-using-kl-divergence-over-cross-entropy</guid>
      <pubDate>Sat, 31 Aug 2024 08:48:16 GMT</pubDate>
    </item>
    <item>
      <title>简单线性回归中的统计误差</title>
      <link>https://stats.stackexchange.com/questions/653635/statistical-error-in-simple-linear-regression</link>
      <description><![CDATA[首先我想说的是，我正在寻找一个简单的回归模型，而不是一个数学模型，来对这个术语进行更多的概念性理解。
在计量经济学中，简单的线性回归有一个“误差项”，称为mu，它表示“影响y的除x之外的因素，或未观察到的数据”。在统计学课上，这个术语被称为“统计误差”或“噪声”，被视为epsilon，这又是现实世界中我们的模型无法捕捉到的随机噪声。
在《统计学习简介》中，这个术语被称为“不可约误差”，是一个表示我们尚未测量的未测量变量的数量，或者只是现实世界数据中无法测量的变化。作者将这个术语与可约误差区分开来。
这就是我感到困惑的地方：在一个理论上完全确定的世界中，我们拥有无限量的数据，这个“不可约误差”在理论上是可以约化的吗？也就是说，如果在这个理论世界中，我们的协变量，大学 GPA，可以映射到我们的响应，比如“薪水”，那么这个术语在技术上可以为零吗？
我理解，在我们生活的世界中，数据总是存在不可测量的变化，我们永远无法获得无限量的数据或事先知道每一个协变量，因此会出现这个错误。但是假设我们有 5 个数据点，这是我们的“理论总体”，这个“不可约误差”会是零吗？术语消失？
例如，在《统计学习简介》中，他们有这张图片：

我对这张图片的困惑源于这个数据是模拟的，所以我们实际上知道真正的底层函数 f。但如果是这样的话，为什么还有错误？如果我们知道 f，为什么我们不能完美地将这个函数与数据拟合？如果这个数据是基于 f 模拟的，为什么模拟不会在函数 f 上产生数据点？
我知道这似乎是一个愚蠢的问题，但我试图理解这里的细微差别。非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653635/statistical-error-in-simple-linear-regression</guid>
      <pubDate>Fri, 30 Aug 2024 17:14:15 GMT</pubDate>
    </item>
    <item>
      <title>基于模拟随机事件概率平均值的预期泊松二项分布</title>
      <link>https://stats.stackexchange.com/questions/653630/expected-poisson-binomial-distribution-based-on-average-of-simulated-random-even</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653630/expected-poisson-binomial-distribution-based-on-average-of-simulated-random-even</guid>
      <pubDate>Fri, 30 Aug 2024 15:25:44 GMT</pubDate>
    </item>
    <item>
      <title>利用混合样本确定生物学重复</title>
      <link>https://stats.stackexchange.com/questions/653624/determining-biological-replicates-with-pooled-samples</link>
      <description><![CDATA[我们小组有一个长期存在的方案，其中汇集了多个组织纯化样本。这是因为每只动物的组织很少。然后对该池进行多次采样，并测量感兴趣的结果。每次测量都被视为推理分析的独立数据点。虽然这些单个样本可能是“重复”，但它们作为生物重复的状态充其量是高度可疑的。它们看起来可能是伪重复。
即，用两种药物治疗动物。提取的组织被合并到两个池中。每个池采样 x 次。然后通过药物治疗分析这些样品，每次治疗 n = x。
应该如何调整这种设计？目前没有办法只使用一只动物的组织进行测定。必须将组织组合起来。
如果我们使用更多动物并创建多个池，那么每个池可以采样几次，以解释因组合动物而引入的变化。这将使用混合级别模型进行建模。每个池是否都是一个单一的生物学重复，并且池中的每个样本都是随机效应内的聚类？
因此，两种治疗方法，每种治疗方法有 M 只动物。组织提取物组合成 P 个池，每个池采样 N 次。模型中每个治疗方法的 n = P，单个样本按 P 聚类。
还有其他方法可以做到这一点吗？
（这是我最近问过的一个问题的重述，但措辞不当且令人困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/653624/determining-biological-replicates-with-pooled-samples</guid>
      <pubDate>Fri, 30 Aug 2024 14:35:33 GMT</pubDate>
    </item>
    </channel>
</rss>