<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 30 Apr 2024 12:24:58 GMT</lastBuildDate>
    <item>
      <title>训练 RNN 时通过采样标记的梯度流（但没有教师强制）</title>
      <link>https://stats.stackexchange.com/questions/646186/gradient-flow-through-sampled-tokens-when-training-rnns-but-without-teacher-for</link>
      <description><![CDATA[假设我们想要训练一个基于循环神经网络 (RNN) 架构的自回归生成语言模型，没有教师强制：
在每个时间步，RNN 获取输入标记 $x_t$ 并计算输出向量 $o_t$，并基于 $o_t$，在前向传递中，我们对使用的输出标记 $y_t$ 进行采样作为下一个时间步的输入 $x_{t+1}=y_t$ 。对于典型的 RNN，RNN 还具有一个在时间步之间更新的隐藏状态 $h_t$。
因此，在训练过程中，我们有一个从时间步 $t+1$ 到 $t$ 的梯度流从 $h_{t+1}$ 到 $h_t$ 的隐藏状态用于优化权重（随着时间的反向传播，BPTT）。 但是由于我们不使用教师强制，是不是还有另一个（不可微分的）“信息”通过来自 $x_{t+1}=y_t$ 到上一个时间步？采样令牌的选择是否也会影响权重的理想优化方式？
我知道，教师强制在每个时间步提供固定输入$x_t$（由于监督学习），实际上始终是首选的训练方式这样的场景，它隐含地避免了这条额外的信息流路径。然而，支持教师强制的论点总是围绕着防止随着时间的推移累积错误或训练效率，但我从未见过任何论点讨论采样令牌作为可能影响的另一种信息路径的问题。最优权重更新。
在对抗性训练的背景下，一些对手基于采样的标记，我已经看到了诸如 Gumbel Softmax 技巧之类的变通方法来获得可微的近似值，但同样，似乎没有人讨论仅用于生成语言建模的 RNN 的问题。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/646186/gradient-flow-through-sampled-tokens-when-training-rnns-but-without-teacher-for</guid>
      <pubDate>Tue, 30 Apr 2024 12:17:44 GMT</pubDate>
    </item>
    <item>
      <title>模型定义中的独立语句，然后是 DAG</title>
      <link>https://stats.stackexchange.com/questions/646185/independent-statements-in-model-definition-and-then-dag</link>
      <description><![CDATA[在本文第3.1节中，他们给出了贝叶斯线性回归模型，然后是 DAG，如下所示。

&lt;小时/&gt;
根据我的理解，DAG 告诉我们如何分解联合分布。
但为了拥有这样的DAG，我们是否不需要额外的独立语句比如：
$$y_{ij} \perp \xi^2 \; \mid x_{ij} , \beta_j, \sigma_j^2$$]]></description>
      <guid>https://stats.stackexchange.com/questions/646185/independent-statements-in-model-definition-and-then-dag</guid>
      <pubDate>Tue, 30 Apr 2024 12:15:24 GMT</pubDate>
    </item>
    <item>
      <title>综合对照法中的治疗效果是ATE还是ATT？</title>
      <link>https://stats.stackexchange.com/questions/646184/is-the-treatment-effect-in-the-synthetic-controls-method-the-ate-or-the-att</link>
      <description><![CDATA[在综合控制方法中，一段时间内的处理效果$t$被指定为处理单元和控制单元的结果差异，在治疗后时期。对此，我认为这是ATT而不是ATE，但无法向自己完全解释原因。任何人都可以给理性让路吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646184/is-the-treatment-effect-in-the-synthetic-controls-method-the-ate-or-the-att</guid>
      <pubDate>Tue, 30 Apr 2024 12:09:41 GMT</pubDate>
    </item>
    <item>
      <title>因果相加干预操作</title>
      <link>https://stats.stackexchange.com/questions/646183/causal-additive-intervention-operation</link>
      <description><![CDATA[我正在阅读 Shpitser 和 Pearl 的以下论文：治疗对治疗对象的影响：识别和概括。在第 517 页，他们提供了有关加法干预运算的推论，用 do(x′ + q) 表示。他们继续表明，这种效果可以通过治疗对治疗者的效果 (ETT) 来估计：
$$P(Y|do(X+q)) = \sum_{x&#39;} P(Y_{X+q}=y|x&#39;)P(x &#39;).$$
虽然 ETT 的识别看起来相当容易，但我并不完全理解为什么我们首先要对 x&#39; 求和。我想这是因为在相关的图形模型中，我们没有删除任何进入 X 的箭头。这是否意味着我们无法删除X原始值的总和？]]></description>
      <guid>https://stats.stackexchange.com/questions/646183/causal-additive-intervention-operation</guid>
      <pubDate>Tue, 30 Apr 2024 12:07:04 GMT</pubDate>
    </item>
    <item>
      <title>训练集、验证集和测试集的划分是否会使 p-hacking 变得不可能？</title>
      <link>https://stats.stackexchange.com/questions/646182/does-division-into-training-validation-and-test-sets-make-p-hacking-impossible</link>
      <description><![CDATA[是否有可能犯“统计罪”？比如

如果分析产生显着的 p 值，则停止数据探索

决定是否在分析后包含或删除异常值


何时使用机器学习算法？换句话说，划分训练集、验证集和测试集是否会使 p-hacking 变得不可能？

经典/贝叶斯推理争论对机器学习领域有影响吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/646182/does-division-into-training-validation-and-test-sets-make-p-hacking-impossible</guid>
      <pubDate>Tue, 30 Apr 2024 11:57:38 GMT</pubDate>
    </item>
    <item>
      <title>使用 Gamma 先验计算指数数据的贝叶斯估计量的极限分布（通过使用一致性？）</title>
      <link>https://stats.stackexchange.com/questions/646177/computing-the-limiting-distribution-of-the-bayes-estimator-for-exponential-data</link>
      <description><![CDATA[设数据为 $X_i \sim \text{Exp}(\theta)$ iid, $i=1 ,...,n$。令先验为 $\text{Gamma}(\alpha, \beta)$。后验当然是 $\text{Gamma}(\alpha + n, \beta + \sum X_i)$。 $\theta$ 的贝叶斯估计量 $\pi_n$ 就是后验均值，$\frac{\alpha + n}{\beta + \sum X_i}$。
我想将 $\sqrt{n}(\pi_n - \theta)$ 的极限分布计算为 $n \rightarrow \infty$。
请注意，我已经证明（使用大数定律）贝叶斯估计量是一致的（$\pi_n \overset{P}{\longrightarrow} \theta$）。这可以帮助我计算这个限制分布吗？如果可以，如何计算？
我一直在尝试进行一些代数运算以获得 $\sqrt{n}(\frac{\alpha + n}{\beta + \sum X_i} - \theta )$ 到一个表单中，我可以开始应用 Slutsky/连续映射/等，但这并没有起作用。这让我相信我需要使用我之前证明的一致性结果。但是，我不确定如何利用我的一致性结果来获得限制分布。
如何计算这个极限分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/646177/computing-the-limiting-distribution-of-the-bayes-estimator-for-exponential-data</guid>
      <pubDate>Tue, 30 Apr 2024 10:42:00 GMT</pubDate>
    </item>
    <item>
      <title>Cox 回归中缺失结果的多重插补</title>
      <link>https://stats.stackexchange.com/questions/646176/multiple-imputation-for-missing-outcomes-in-cox-regression</link>
      <description><![CDATA[想象一个具有事件发生时间结果的 RCT，并使用 Cox 回归进行分析。有四项评估（T1=随机化前，T2=3周，T3=6周，T4=12周）。在随机审查假设下，对早期无信息的退出（例如，评估 T2 后退出）做出正确的推论。现在对于那些退出的人来说有一个特殊情况：那些在随机化后立即退出研究的人（即只知道 T1）。如果我们在最终的 Cox 模型中控制基线协变量，每个参与者（以及那些在 T1 之后退出的参与者）都可以使用该协变量，那么
是否推荐：

对于根本没有结果数据的特殊情况（即仅针对那些只有 T1 数据的情况），估算结果数据（事件和事件发生前的时间）
在研究结束前估算所有缺失结果病例的结果数据（以及在 T2、T3 或 T4 缺失的病例），忽略 Cox 回归的固有审查机制
使用完整的案例分析？

有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646176/multiple-imputation-for-missing-outcomes-in-cox-regression</guid>
      <pubDate>Tue, 30 Apr 2024 10:30:24 GMT</pubDate>
    </item>
    <item>
      <title>（何时）GLMM 是否提供比逻辑回归更好的预测？</title>
      <link>https://stats.stackexchange.com/questions/646174/when-does-glmm-provide-better-predictions-than-logistic-regression</link>
      <description><![CDATA[我正在尝试测试 statsmodels GLMM 与逻辑回归（通过 statsmodels 或 scikit-learn - 请参阅下面带有玩具示例的代码）。我了解混合模型在参数估计中的实用性，并且该模型在 Akaike 或其他一些标准方面可能更真实。但是，在测试来自未知群体的数据时，我不确定是否以及何时应该期望预测准确性得到提高。
这是带有玩具示例的代码：
from __future__ 导入分部
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

将 statsmodels.api 导入为 sm
从 sklearn.linear_model 导入 LogisticRegression
从 sklearn.preprocessing 导入 StandardScaler

来自 scipy.special 导入导出

种子 = 2024

”“”
逻辑回归与 GLM 的比较
”“”

#生成混合数据
n_smpls = 1000
n_feats = 5
n_组 = 100

groups = np.repeat(np.arange(n_groups), n_smpls//n_groups)

rng = np.random.default_rng(seed=2024)
X_train = np.random.normal(size=(n_smpls, n_feats))

offs = np.random.normal(大小=n_groups，比例=0.5)
offsets = np.array([offs[g] for g in groups])

x0 = 0。； b = 10。
y_train = (np.random.random_sample(n_smpls) &lt; expit(b * (X_train[:,0]-x0-offsets))).astype(np.float64)

#生成测试数据
m_smpls = 100
x 最大值 = 1。
xx = np.linspace(-xmax, xmax, m_smpls)
X_test = np.random.normal(size=(m_smpls, n_feats))
X_test[:,0] = xx
prob_test = expit(b * (X_test[:,0] - x0))
y_test = (np.random.random_sample(m_smpls) &lt; prob_test).astype(np.float64)


#------------------------------------------------- ------------------------
#缩放数据
定标器=标准定标器()
X_train_scaled = 缩放器.fit_transform(X_train)
X_test_scaled = 缩放器.transform(X_test)

预测 = []
概率 = [概率测试]
#------------------------------------------------- ------------------------
#sklearn 逻辑回归
clf = LogisticRegression(random_state=seed,penalty=&#39;l2&#39;)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
preds.append(y_pred)

概率 = clf.predict_proba(X_test)[:,1]
probs.append（概率）

#------------------------------------------------- ------------------------
#Statsmodels 的逻辑回归
clf = sm.GLM(y_train, X_train_scaled, family=sm.families.Binomial()).fit_regularized(L1_wt=.9, alpha=.01)

prob = clf.predict(X_test_scaled)
probs.append（概率）

y_pred = (prob &gt; 0.5).astype(float)
preds.append(y_pred)

#------------------------------------------------- ------------------------
#GLMM 与 statsmodels
Z_train = np.zeros((n_smpls, n_groups))
Z_train[np.arange(n_smpls), 组] = 1
glmm = sm.BinomialBayesMixedGLM(y_train, X_train_scaled, Z_train, np.arange(n_groups))
clf = glmm.fit_vb(scale_fe=True)

prob = clf.predict(X_test_scaled)
probs.append（概率）

y_pred = (prob &gt; 0.5).astype(float)
preds.append(y_pred)

#------------------------------------------------- ------------------------
#分析结果
图, ax = plt.subplots(1, 1, Figsize=(6, 4))
对于名称，zip 中的概率（[&#39;test&#39;, &#39;lr&#39;, &#39;glm&#39;, &#39;glmm&#39;], probs）：
    ax.plot(xx, 概率, 标签=名称)
斧头图例()
ax.set_xlabel(r&#39;$X_0$&#39;)
ax.set_ylabel(&#39;prob&#39;)
ax.set_title(&#39;预测概率&#39;)
plt.tight_layout()
plt.show()

结果为：

我们在这里看到，在预测概率方面，GLMM 做得更好，但它产生相同的截距，并且分类精度没有提高：可以评估真/假阳性的数量和相关指标。例如，对于真正的正/负率，我们得到
[np.sum((y_pred==1)&amp;(y_test==1))/np.sum(y_test==1) for y_pred in preds]
[0.9782608695652174、0.9782608695652174、0.9565217391304348]

结果
&lt;预&gt;&lt;代码&gt;[0.9782608695652174，0.9782608695652174，0.9565217391304348]
[0.9074074074074074、0.9259259259259259、0.9259259259259259]
]]></description>
      <guid>https://stats.stackexchange.com/questions/646174/when-does-glmm-provide-better-predictions-than-logistic-regression</guid>
      <pubDate>Tue, 30 Apr 2024 09:56:05 GMT</pubDate>
    </item>
    <item>
      <title>普通最小二乘法的解析解能否很好地转化为代码？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/646173/does-the-analytical-solution-of-ordinary-least-squares-translate-well-into-code</link>
      <description><![CDATA[普通最小二乘回归的封闭式解如下：
$${\displaystyle {\hat {\boldsymbol {\beta }}}=\left(\mathbf {X} ^{\operatorname {T} }\mathbf {X} \右)^{-1}\mathbf {X} ^{\operatorname {T} }\mathbf {y} .}$$
我尝试在 Rust 中实现，如下所示：
fn tfit(数据: &amp;BaseDataset, 目标: usize){
    让 mut features = data.into_f64_array_without_target(target);
    让目标 = data.get_col(target).map(|x| x.to_f64().unwrap());
    让ones = Array1::ones(features.nrows());
    features.push_column(ones.view()).expect(“形状错误”);
    让feature_t = features.t();
    让 left = feature_t.dot(&amp;features);
    让 right = feature_t.dot(&amp;target);
    让 I = Array2::eye(features.ncols());
    让检查 = left.dot(&amp;I).dot(&amp;right);
}

但是，这似乎不起作用，因为给定的解决方案向量（check）具有无意义的值。我是否做错了什么，如果是，我该如何改进？我见过其他实现，而不是通过执行 $ 来计算 $\boldsymbol{{X}} ^ {-1}$ \boldsymbol{{X}{I}}$ 他们求解线性方程组
$\boldsymbol{{X} {X} ^{\operatorname {T}}}$ 作为方程组和  $\boldsymbol{{X} ^{\operatorname {T}}{y}} $ 作为解。这种方法有什么不同吗？我的不起作用有什么原因吗？
N/B：data 是一个二维矩阵。函数：into_f64_array_without_target 构造一个 ndarray，其中包含 f64 (float) 值以及 target &gt; 列已排除。
如果乳胶有任何畸形，我深表歉意。非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/646173/does-the-analytical-solution-of-ordinary-least-squares-translate-well-into-code</guid>
      <pubDate>Tue, 30 Apr 2024 09:49:41 GMT</pubDate>
    </item>
    <item>
      <title>置信区间 标准误差</title>
      <link>https://stats.stackexchange.com/questions/646171/confidence-interval-standar-error-of-the-mean</link>
      <description><![CDATA[我正在对 10 名受试者进行重复性研究，重复 4 项措施。
计算每个受试者的平均值标准误差 (SEm) = SD(4 个测量值)/Sq(4)。
示例：
234
226
239
244
平均值= 238
SEm = 2.016
在此之后，可以正确计算 SEm 的置信区间 95%，例如 = SEm x 2.3534 吗？
2.354 是统计量 T。
示例：
IC95% SEm = 4.743
如果这是正确的，我应该如何报告？
我对 IC95 和 SEm 感兴趣，就像重复性的衡量标准一样，我对 4 个值的平均值并不真正感兴趣，但我不知道在没有平均值的情况下报告它是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/646171/confidence-interval-standar-error-of-the-mean</guid>
      <pubDate>Tue, 30 Apr 2024 09:23:57 GMT</pubDate>
    </item>
    <item>
      <title>配对条件逻辑回归的似然函数</title>
      <link>https://stats.stackexchange.com/questions/646169/likelihood-function-of-paired-conditional-logistic-regression</link>
      <description><![CDATA[我发现关于成对数据的条件逻辑回归的似然性的信息很少。Wiki 给出了这个答案，但我认为这是错误的，因为事件 Yi1 和 Yi2 是相关的，因为 Yi1 + Yi2 =1。（Yi 是二元随机变量）。因此，我们如何基于 Yi1 + Yi2 = 1 的假设来解决条件似然性？我还没有找到任何证据。谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/646169/likelihood-function-of-paired-conditional-logistic-regression</guid>
      <pubDate>Tue, 30 Apr 2024 09:00:33 GMT</pubDate>
    </item>
    <item>
      <title>模型没有评估固定效应吗？</title>
      <link>https://stats.stackexchange.com/questions/646167/are-fixed-effects-not-being-evaluated-by-the-model</link>
      <description><![CDATA[我有一个混合效应模型，其中包括一些作为固定效应的变量和一些作为随机效应的变量。
所有这些都被定义为因素，并且我设置了适当的参考水平。 var_one 包含两个级别，var_two 包含四个级别，var_ Three 包含三个级别。
# 定义公式
Formula_rda &lt;-“var_one+var_two+var_三+条件(rand_one+rand_two)”

该模型用于运行部分 RDA 排序，然后运行 ​​anova.cca 来测试约束。像这样的事情：
# 运行部分 RDA
partial_rda &lt;- 纵坐标（数据，“RDA”，公式=as.formula（formula_rda））
# 执行测试
signif_test &lt;- anova.cca(partial_rda, step=1000, by=&quot;terms&quot;)

但是，我得到的输出只包含一个变量：
简化模型下rda的排列测试
按顺序添加的术语（从第一个到最后一个）
排列：自由
排列数：999

模型：rda(公式 = OTU ~ var_one + var_two + var_ Three + 条件(rand_one + rand_two), 数据 = 数据)
            Df 方差 F Pr(&gt;F)
var_one 1 347279 0.2253 0.867
剩余82 126409291

问题是：为什么 var_two 和 var_third 没有包含在 anova.cca 测试的结果中？]]></description>
      <guid>https://stats.stackexchange.com/questions/646167/are-fixed-effects-not-being-evaluated-by-the-model</guid>
      <pubDate>Tue, 30 Apr 2024 08:29:12 GMT</pubDate>
    </item>
    <item>
      <title>混合物分布：关于为什么我们不能通过目视检查推断混合物成分数量的直觉</title>
      <link>https://stats.stackexchange.com/questions/646164/mixture-distributions-an-intuition-on-why-we-cannot-infer-the-number-of-mixture</link>
      <description><![CDATA[我正在研究混合模型，我希望您能帮助解决这个问题：
考虑分布 $\Gamma$ 并假设它是有限混合分布，即 $\Gamma=\ sum_{k=1}^K \Gamma_k \lambda_k$ 与每个 $\lambda_k\geq 0$。您能否直观地理解为什么我们不能仅通过目视检查（例如，通过计数）来推断混合物成分的数量 $K$（或其上限）我们在密度函数的图形表示中看到了多少个“钟声”？]]></description>
      <guid>https://stats.stackexchange.com/questions/646164/mixture-distributions-an-intuition-on-why-we-cannot-infer-the-number-of-mixture</guid>
      <pubDate>Tue, 30 Apr 2024 07:52:24 GMT</pubDate>
    </item>
    <item>
      <title>平稳过程是不可预测的，非平稳过程是可预测的吗？</title>
      <link>https://stats.stackexchange.com/questions/646162/are-stationary-processes-non-predictable-and-non-stationary-ones-predictable</link>
      <description><![CDATA[我正在阅读多个时间序列的规范分析 作者：Box 和 Tiao (1977)。在论文摘要中，作者提到：
&lt;块引用&gt;
最不可预测的成分通常是近乎白噪声，它可以反映原始变量之间稳定的同期关系。最可预测的可能是近乎不稳定的，代表了该系列的动态增长特征。

这直观吗？白噪声是不可预测的，非平稳噪声是可预测的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646162/are-stationary-processes-non-predictable-and-non-stationary-ones-predictable</guid>
      <pubDate>Tue, 30 Apr 2024 07:37:37 GMT</pubDate>
    </item>
    <item>
      <title>如何呈现两个 KPI 之间的关系</title>
      <link>https://stats.stackexchange.com/questions/646159/how-to-present-the-relation-between-two-kpis</link>
      <description><![CDATA[此案例针对一家物流公司。我们试图向用户展示他们当前的排放量，以及通过选择更可持续的路线选项可以节省/避免/减少多少排放量。在我们的仪表板上，我们希望向用户展示这方面的 KPI，以便他们可以更轻松地跟踪利益相关者并与其进行沟通。例如，“老板，如果我们在 25% 的路线上选择更可持续的路线，我们就可以减少 40% 的排放量。我们 75% 的路线已经很好了”
注意：我们还有其他图表来识别实际热点。因为可能只有 2 条路线造成了这 40% 的可避免排放。
挑战

一方面要了解预计排放量和可避免排放量之间的关系，另一方面要了解具有更可持续替代方案的路线百分比。
应该安装在相对较小的组件上。

到目前为止我尝试过的
]]></description>
      <guid>https://stats.stackexchange.com/questions/646159/how-to-present-the-relation-between-two-kpis</guid>
      <pubDate>Tue, 30 Apr 2024 06:58:02 GMT</pubDate>
    </item>
    </channel>
</rss>