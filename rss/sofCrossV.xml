<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 01 Apr 2024 15:14:01 GMT</lastBuildDate>
    <item>
      <title>简单的更新过程以及如何在 R 或 python 中创建一个简单的应用程序</title>
      <link>https://stats.stackexchange.com/questions/644031/simple-renewal-processes-and-how-do-i-create-a-simple-application-in-r-or-python</link>
      <description><![CDATA[我想简单地应用更新过程，使用更新函数，更新密度，以及更新函数的计算，渐近行为，更新定理，并且分布限制不必包括它们全部，但我想看看我如何能在 R、python 或 Matlab 中应用它。]]></description>
      <guid>https://stats.stackexchange.com/questions/644031/simple-renewal-processes-and-how-do-i-create-a-simple-application-in-r-or-python</guid>
      <pubDate>Mon, 01 Apr 2024 15:01:27 GMT</pubDate>
    </item>
    <item>
      <title>悲伤和麦当劳模拟法</title>
      <link>https://stats.stackexchange.com/questions/644030/galarnau-and-mcdonald-simulation-method</link>
      <description><![CDATA[
set.seed(14678)
p=5
n=15
ro._=0.7
z_ij=rnorm(75,均值=0,sd=1)
z_1=z_ij[1:15]
z_2=z_ij[16:30]
z_3=z_ij[31:45]
z_4=z_ij[46:60]
z_5=z_ij[61:75]
z_alt1&lt;-sqrt(1-ro._^2)*z_1
z_alt2&lt;-sqrt(1-ro._^2)*z_2
z_alt3&lt;-sqrt(1-ro._^2)*z_3
z_alt4&lt;-sqrt(1-ro._^2)*z_4
z_alt5&lt;-sqrt(1-ro._^2)*z_5
z_matrs&lt;-矩阵(z_ij,nrow=15,ncol=5)
z_altmtrs&lt;-矩阵(z_matrs[,5],nrow=15,ncol=5)
X_mtrs&lt;-矩阵(sqrt(1-ro._)^2*z_matrs+ro._*z_altmtrs,nrow=15,ncol=5)
x_1kolon&lt;-X_mtrs[,1]
x_2kolon&lt;-X_mtrs[,2]
x_3kolon&lt;-X_mtrs[,3]
x_4kolon&lt;-X_mtrs[,4]
x_5kolon&lt;-X_mtrs[,5]
x_matrs&lt;-cbind(x_1kolon,x_2kolon,x_3kolon,x_4kolon,x_5kolon)
x_1kolanstd&lt;-scale(x_1kolon)*sqrt(n/(n-1))
x_2kolanstd&lt;-scale(x_2kolon)*sqrt(n/(n-1))
x_3kolanstd&lt;-scale(x_3kolon)*sqrt(n/(n-1))
x_4kolanstd&lt;-scale(x_4kolon)*sqrt(n/(n-1))
x_5kolanstd&lt;-scale(x_5kolon)*sqrt(n/(n-1))
X_std&lt;-stdize(X_mtrs,scale=T)
cor.X_&lt;-cor(X_std)
特征值.X_&lt;-特征值(cor.X_)
C_n&lt;-4.17561983/0.02991036
lambda_&lt;-cbind(eigen.X_$values)
epslon_&lt;-rnorm(15,均值=0,sd=0.1)
e_&lt;-矩阵(epslon,nrow=15,ncol=1)
beta_&lt;-矩阵(c(0,1,1,1,1),nrow=5,ncol=1)
y_&lt;-X_std%*%beta_+e_
y_std&lt;-stdize(y_)
x_x&lt;-t(X_std)%*%X_std
x_x_cor&lt;-cor(x_x)
simx_xters&lt;-cor(求解(t(X_std)%*%X_std))
xus_y&lt;-t(X_std)%*%y_std
std_xus_y&lt;-stdize(xus_y)
beta_ols&lt;-simx_xters%*%std_xus_y
..

 我不使用 galarnau 和 mcdonald 模拟方法..xij=sqrt(1-ro^2)*zij+zip i=1...n
,j=1...p。标量（mse）1000重复..可以找到但我不知道..这种形式???现在我研究文章新岭回归估计器的性能。亚齐德·M·阿尔-哈桑
瑞典斯德哥尔摩皇家理工学院 (KTH) 数学系
这
结论
表 1 p = 5 和 n = 15 时估计的 MSE 和 CN 值。
ro 估算器
       OLS HK HSL NHSL CN
0.99 0.0369229 0.0328831 0.0336641 0.0268559 879.62
0.9 0.0270955 0.0248932 0.0250849 0.0213376 80.79
0.8 0.0204500 0.0191982 0.0192228 0.0173943 35.29
0.7 0.0159889 0.0153413 0.0153420 0.0132687 19.39
...
非常感谢..
]]></description>
      <guid>https://stats.stackexchange.com/questions/644030/galarnau-and-mcdonald-simulation-method</guid>
      <pubDate>Mon, 01 Apr 2024 14:57:40 GMT</pubDate>
    </item>
    <item>
      <title>最小描述长度、归一化最大似然和最大后验估计</title>
      <link>https://stats.stackexchange.com/questions/644029/minimum-description-length-normalized-maximum-likelihood-and-maximum-a-posteri</link>
      <description><![CDATA[TL;DR：我相信使用 NML 的 MDL 是模型和参数联合 MAP 的特例，并且需要承认这一点的来源。
这就是我对最小描述长度（MDL）的理解：我们有一组模型 $M_i\in M$ 以及之前的 $P(M_i)$，每个都由 $\Theta_i$ 参数化，即 $ 对(M_i,\theta\in\Theta_i)$ 完全指定似然函数 $P(z|M_i,\theta)$ 其中 $z$ 是数据。对于每个 $M_i$，我们定义一个函数 $f_i(z)$，然后选择 $\arg\max_{M_i\in M}P(M_i)f_i(z)$。如果我们定义 $f_i(z):=P(z|M_i)=\int_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i, \theta)$，这相当于 MAP。
但是，我们可以通过其他方式定义 $f_i$。一种方法是归一化最大似然（NML）：
$$f_i(z):=g^{NML}_i(z):=\frac{\max_{\theta\in\Theta_i}P(\theta| M_i)P(z|M_i,\theta)}{\int\max_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i,\theta)dz}$$
（一般来说，$P(\theta|M_i)$实际上是用更通用的“幸运函数”代替的。但在这个问题中我们还是坚持这个公式吧）&lt; /p&gt;
这里的分母（我们称之为$I_i$）应该对值进行标准化以防止过度拟合。对于更复杂的模型，它应该更大，本质上是模型复杂性的度量（尽管我不确定这是否是我们定义复杂性的方式，或者只是模型复杂性的另一个独立定义的含义）。
人们看待模型复杂性的一种方式是使用其先前的 $P(M_i)$。从这个角度来看，较小的先验意味着更复杂的模型，因为最佳代码需要更长的消息来对具有较小先验的模型进行编码。现在，采用我们在模型上已有的任何内容，即 $P(M_i)$ 并定义 $P_{new} (M_i)=\frac{P(M_i)}{I_i}$ 作为模型的新先验。另外，我们定义 $f_i(z):=\max_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i,\theta)$。与 MDL 一样，我们继续发现：
$$\arg\max_{M_i\in M}P_{new}(M_i)f_i(z)=\arg\max_{M_i\in M}\frac{ P(M_i)}{I_i}\max_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i,\theta)=\\\arg\max_{M_i\in M}P(M_i )\frac{\max_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i,\theta)}{I_i}=\arg\max_{M_i\in M}P(M_i)g_i ^{NML}(z)$$
这相当于具有先验的 NML 解决方案 $P(M_i)$。然而，我们也可以将其视为发现：
$$\arg\max_{M_i\in M}P_{new}(M_i)f_i(z)=\arg\max_{M_i\in M}P_{new}(M_i )\max_{\theta\in\Theta_i}P(\theta|M_i)P(z|M_i,\theta)=\\\arg\max_{M_i\in M}\max_{\theta\in\Theta_i} P_{new}(M_i)P(\theta|M_i)P(z|M_i,\theta)=\arg\max_{M_i\in M}\max_{\theta\in\Theta_i}P(M_i, \theta )P(z|M_i,\theta)=\\\arg\max_{M_i\in M}\max_{\theta\in\Theta_i}P(M_i,\theta|z)=\\\arg\max_{ (M_i\in M,\theta\in\Theta_i)}P(M_i, \theta|z)$$
这只是对 $(M,\theta\in\Theta_i)$ 上的 MAP 解决方案，而不是仅在 $ 上M_i$，先验 $P_{new}(M_i)$
然而，这实际上是比 NML 更通用的解决方案，因为现在我们不需要通过引用 $M_i$ 的复杂性-container&quot;&gt;$I_i$ 根本没有。因此，只要 $P_{new}(M_i)$ 正确捕获了复杂度，我们就可以选择模型和参数对上的 MAP 解作为描述的解消息最短的数据。
我的问题是，是否有来源承认这一点，以某种方式使用它进行模型选择，并断言它是有效的 MDL 解决方案（即在某种意义上最小化数据的描述长度）？在我的工作中，我喜欢以这种方式描述我的程序，但如果没有相关文献，就很难让人们相信这是有道理的。]]></description>
      <guid>https://stats.stackexchange.com/questions/644029/minimum-description-length-normalized-maximum-likelihood-and-maximum-a-posteri</guid>
      <pubDate>Mon, 01 Apr 2024 14:48:13 GMT</pubDate>
    </item>
    <item>
      <title>ARIMAX 残差的解释</title>
      <link>https://stats.stackexchange.com/questions/644027/interpretation-of-arimax-residuals</link>
      <description><![CDATA[绘制了一个季节性 ARIMAX 模型，其中我采用了一个差异和一个季节性差异，我不确定如何解释下面的残差输出。生成的模型为 ARIMA(2,1,2)(2,1,0)[12]，它通过了 Ljung Box 测试。
我知道它看起来像白噪声，我在某种程度上观察到 ARIMA 误差。但是，这里的回归误差模式表明了什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/644027/interpretation-of-arimax-residuals</guid>
      <pubDate>Mon, 01 Apr 2024 14:39:31 GMT</pubDate>
    </item>
    <item>
      <title>聚合数据与非聚合数据</title>
      <link>https://stats.stackexchange.com/questions/644026/aggrregated-vs-non-aggregated-data</link>
      <description><![CDATA[我正在运行 TWFE 逻辑回归来回归公司的退出状态，这意味着如果被投资公司进行了 IPO，则为 1，如果没有，则为 0。我正在运行以下代码规范：
logit_model_exit &lt;- feglm(dv_success ~ ddd | 公司名称 + 投资日期, data=data2, family = 二项式(link = &quot;logit&quot;))

我有一个不平衡面板数据集，其中包含约 150 家公司（75 家处理公司和 75 家对照公司，通过粗化精确匹配进行匹配）长达 23 年。原始数据集包含这些公司（风险投资公司）参与的所有交易及其特征。我汇总了一些数据，并创建了每年每个风险投资公司的编译数据集以及相应的汇总数据，例如其投资的退出率。
我使用聚合数据和交易级别数据运行了 TWFE logit。我不确定为什么我得到的估计如此不同，以及为什么在使用聚合数据时估计很重要，而在使用原始数据时估计器根本不重要。我的交易级别数据包含 63k 个观察值，我的汇总数据约为 2300 个。
估计器。标准错误。 z 值。 Pr(&gt;|z|)
0.24363 0.128339 -1.8983。 0.057653。 -&gt;用于汇总数据
-0.071454 0.083729 -0.853397 0.39344 --&gt;用于交易级别数据

知道如何理解这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644026/aggrregated-vs-non-aggregated-data</guid>
      <pubDate>Mon, 01 Apr 2024 14:19:14 GMT</pubDate>
    </item>
    <item>
      <title>利用有限价格数据实现利润最大化的稳健或随机优化方法</title>
      <link>https://stats.stackexchange.com/questions/644025/robust-or-stochastic-optimization-approach-for-maximizing-profit-with-limited-pr</link>
      <description><![CDATA[我正在解决一个线性最大化问题，在给定某些限制的情况下，我需要在几周内从多个选项中选择最佳产品，以便最大化未来利润。决策变量是二元的，指示是否选择特定产品。
目标函数表示为：
$$
\max_{j} \sum_{i} 选择(j) \cdot c_{i,j}^T p_{i,j}$$
地点：
$c_{i,j}$表示产品$j$在一周内的生产数量$i$,
$p_{i,j}$ 表示产品 $j$ 在一周内的价格 $i$,
$choice(j)$ 是一个二进制变量，指示产品 $j$ 的选择，以及求和整个星期$i$。
但是，我遇到了挑战，因为 $p_{i,j}$ 并不完全已知。这是一个时间序列，我缺乏未来值以及广泛的历史数据。为了解决这个问题，我正在考虑稳健优化或随机优化技术。在这种情况下我应该采取哪种方法？如何有效实施以实现利润最大化？
我很感激有关此事的任何见解或指导。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644025/robust-or-stochastic-optimization-approach-for-maximizing-profit-with-limited-pr</guid>
      <pubDate>Mon, 01 Apr 2024 14:11:42 GMT</pubDate>
    </item>
    <item>
      <title>哪些经典的机器学习算法可以编写为神经网络？</title>
      <link>https://stats.stackexchange.com/questions/644024/which-classic-ml-algorithms-can-be-written-as-neural-networks</link>
      <description><![CDATA[许多经典的机器学习算法可以重构为简单的神经网络。
例如：

线性回归可以被视为具有一个线性层的神经网络，该线性层具有 $p$ 输入和 $1$&lt; /span&gt; 使用 MSE 作为损失函数进行输出。
逻辑回归可以被认为是一种神经网络，具有一个线性层，输入为 $p$，$1$&lt; /span&gt; 输出，一个 sigmoid 激活函数，并使用二元交叉熵作为损失函数。
多项逻辑回归与上述相同，但使用 $p$ 输入，$c$输出、softmax 激活和分类交叉熵。

还有哪些经典算法可以用这种方式改写？例如，我们可以以这种形式编写二次判别分析吗？这对我来说是一个特别有趣的例子，因为 QDA 对完整的联合分布进行建模，而不仅仅是上面示例中的条件分布。
在这里，通过神经网络，我指的是以下形式的函数
$f_\theta : \mathbb{R}^{p_0} \stackrel{L_0}{\to} \mathbb{R}^{p_1} \stackrel{\sigma_1 }{\to} \mathbb{R}^{p_1} \stackrel{L_1}{\to} \mathbb{R}^{p_2} \stackrel{\sigma_2}{\to} \mathbb{R}^{p_k } \dots \stackrel{L_k}{\to} \mathbb{R}^{p_{k+1}} \stackrel{\sigma_{k+1}}{\to} \mathbb{R}^{p_{ k+1}}$
其中 $L_i$ 是线性函数，而 $\sigma_i$ 是非线性函数它们是按坐标应用的。
这与我们想要最小化的损失函数 $\ell(\theta)$ 配对。]]></description>
      <guid>https://stats.stackexchange.com/questions/644024/which-classic-ml-algorithms-can-be-written-as-neural-networks</guid>
      <pubDate>Mon, 01 Apr 2024 13:55:26 GMT</pubDate>
    </item>
    <item>
      <title>运行过度离散的负二项式回归</title>
      <link>https://stats.stackexchange.com/questions/644022/running-a-negative-binomial-regression-with-overdispersion</link>
      <description><![CDATA[我不是 SPSS 专家，但一直在发展我的技能，并相信我应该对我的数据进行负二项式回归，尽管我不确定。
我正在根据选择的控件测试人们每周跑步的天数（因变量）。首先，我假设这是一个计数因变量是否正确？
其次，鉴于 DV 的平均值为 2.45，标准差为 2.3，我认为这表明存在过度离散（假设方差 (2.3 ^2) 大于平均值）。
有鉴于此，我对数据运行负二项式回归模型是否正确？只是寻找一些清晰度！]]></description>
      <guid>https://stats.stackexchange.com/questions/644022/running-a-negative-binomial-regression-with-overdispersion</guid>
      <pubDate>Mon, 01 Apr 2024 13:27:47 GMT</pubDate>
    </item>
    <item>
      <title>是否可以并行运行蒙特卡洛模拟？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/644018/is-it-possible-to-run-a-monte-carlo-simulation-in-parallel</link>
      <description><![CDATA[是否可以并行运行蒙特卡罗模拟？
假设我使用四个线程执行蒙特卡洛模拟。
编程源代码将指定数量的迭代划分为四个线程，以同时计算模拟的各个部分。每个线程生成随机样本，累积部分结果，并将其输出写入文件，确保带锁的线程安全操作。
导入线程
随机导入
导入操作系统

蒙特卡罗模拟类：
    def __init__(self, num_iterations):
        self.num_iterations = num_iterations
        自我结果 = 0.0
        self.lock = threading.Lock()
        self.file_lock = threading.Lock()

    def run_simulation（自身）：
        线程 = []

        # 创建并启动线程
        对于范围 (4) 内的 i：
            线程 = threading.Thread(target=self.perform_calculations, args=(i,))
            线程.追加（线程）
            线程.start()

        # 等待所有线程完成
        对于线程中的线程：
            线程.join()

        print(f&quot;总结果：{self.result}&quot;)

    def Perform_calculations(self, thread_index):
        iterations_per_thread = self.num_iterations // 4
        开始 = 线程索引 * 每个线程的迭代次数
        结束 = 开始 + 每个线程的迭代次数
        如果线程索引 == 3：
            end = self.num_iterations # 确保最后一个线程覆盖所有剩余的迭代

        部分结果 = 0.0

        对于范围内的 i（开始，结束）：
            with self.lock: # 访问共享资源时加锁
                样本 = random.random()
            部分结果 += 样本

            # 在屏幕上显示每个样本
            print(f&quot;线程 ID: {thread_index}, 步骤: {i}, 示例结果: {sample}&quot;)

            # 将每个样本保存到文件中
            self.save_sample_to_file(thread_index, i, 样本)

        带自锁：
            self.result += 部分结果

    def save_sample_to_file(self, thread_id, step_number, result):
        file_path = f“results_thread_{thread_id}.txt”
        与 self.file_lock:
            以 open(file_path, &quot;a&quot;) 作为作者：
                writer.write(f&quot;线程 ID: {thread_id}, 步骤: {step_number}, 示例结果: {result}\n&quot;)

如果 __name__ == “__main__”：
    模拟 = MonteCarloSimulation(1000000)
    模拟.run_simulation()


此蒙特卡罗模拟的行为与单线程蒙特卡罗模拟的行为相同吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644018/is-it-possible-to-run-a-monte-carlo-simulation-in-parallel</guid>
      <pubDate>Mon, 01 Apr 2024 10:05:09 GMT</pubDate>
    </item>
    <item>
      <title>理解二元逻辑回归结果/解释 r 中的奇比</title>
      <link>https://stats.stackexchange.com/questions/644017/making-sense-of-binary-logistic-regression-results-interpreting-odd-ratio-in-r</link>
      <description><![CDATA[我正在使用具有两个响应级别“是”和“否”的二元逻辑。结果以对数奇数表示，我之前了解到并建议（问题是关于多项逻辑回归）对我的估计求幂并获得奇数比。当观众来自非统计背景时，奇数比很容易解释，这就是我的情况。这就是我所做的：
exp_coef &lt;- exp(coef(logit_model))
conf_intervals &lt;- exp(confint.default(logit_model))

以下是指数结果：
（截距）（截距）1.898752e+00 0.1224433 29.444310
年龄 年龄 9.507915e-01 0.8569893 1.054861
性别男性 性别男性 8.980799e-01 0.0753226 10.707909
教育中学教育中学 6.013910e+00 0.4316033 83.797132
教育高等教育高等教育 1.144236e-08 0.0000000 Inf
资源访问是 资源访问是 3.924051e+00 0.2185817 70.445865

以下是我考虑因变量果汁实践/制作果汁和自变量而整理的具体结果解释；年龄、性别、教育程度以及获得审查和纠正资源的机会。
拦截：制作果汁的几率是1.898752倍。这是什么意思？
年龄：受访者年龄每增加一个单位，制作果汁的几率就会增加 9.507915 倍。这意味着果汁的练习随着年龄的增长而增加。这个不清楚。
性别：男性受访者制作果汁的可能性是女性的 8.980799 倍。在输入数据集中，有 14 名女性和 6 名男性，其中 9 名女性表示是，5 名否，3 名男性，3 名表示是，3 名否，我无法理解这个结果。与女性相比，9次到底意味着什么？为什么置信度为 1？
教育程度：中等教育程度会做果汁的可能性是小学教育程度的6.013910倍。这意味着什么，因为在输入数据集中，次要有 7 个“是”，而主要有 5 个？
教育程度：受过高等教育的受访者会制作果汁的可能性是受过初等教育的受访者的1.144236倍。该结果较低，因为只有一名参与者受过高等教育。
资源可及性：受访者无法获得制作果汁的资源的可能性是能够获得资源的受访者的 3.924051 倍。也不清楚。
这种解释对我来说似乎没有逻辑意义。我如何理解它们，以完整而合理的方式解释它们。这些数据是关于能够制作果汁以及影响制作果汁的因素。解释结果时如何使用参考文献？我如何解释次数才能理解我的解释？我尝试阅读逻辑回归结果解释，并通过我的问题定向到一些解释结果的资源，但我仍然迷失https://stackoverflow.com/questions/78110101/how-to-create-dummy-variables-for-a-multinomial-logistic-regression
这是我的输入数据集：
]]></description>
      <guid>https://stats.stackexchange.com/questions/644017/making-sense-of-binary-logistic-regression-results-interpreting-odd-ratio-in-r</guid>
      <pubDate>Mon, 01 Apr 2024 09:58:25 GMT</pubDate>
    </item>
    <item>
      <title>控制一个时间段（经济危机发生期间）是否可以控制 Cox 扩展模型中的固定效应？</title>
      <link>https://stats.stackexchange.com/questions/644016/is-controlling-for-a-time-period-during-which-an-economic-crisis-took-place-co</link>
      <description><![CDATA[我正在使用 Cox 扩展模型来衡量工作合同期限在劳动改革 A 和 B 通过之前或之后是否发生变化。因此，劳动改革变量是随时间变化的（如果没有改革则为 0，如果改革 A 通过则为 1，如果改革 B 通过则为 2）。问题是改革是在经济危机期间通过的。如果我将经济危机的时间段控制为时变变量，那么说我控制的是固定效应是否有意义？ （即危机前 0，危机期间 1，危机后 2）？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644016/is-controlling-for-a-time-period-during-which-an-economic-crisis-took-place-co</guid>
      <pubDate>Mon, 01 Apr 2024 09:41:04 GMT</pubDate>
    </item>
    <item>
      <title>使用池化 OLS 和面板数据固定效应方法比较双向固定效应模型</title>
      <link>https://stats.stackexchange.com/questions/644015/comparing-two-way-fixed-effects-model-using-pooled-ols-and-panel-data-fixed-effe</link>
      <description><![CDATA[我正在使用一个不平衡面板数据集，其中有许多缺失值。我想在分析中控制特定于公司和特定于时间的影响。我正在考虑两种方法：
通过包含公司和年份虚拟变量，使用合并 OLS 估计双向固定效应模型。
使用面板数据固定效应方法，该方法贬低每个公司内的数据并包括年份虚拟数据。
使用合并 OLS 的双向固定效应模型的方程为：
\begin{方程}
y_{it} = \beta_0 + \beta_1 x_{1it} + \dots + \beta_k x_{kit} + \gamma_2 d_{2t} + \dots + \gamma_T d_{Tt} + \delta_2 f_{2i} + \点 + \delta_N f_{Ni} + \varepsilon_{it}
\end{方程}
地点：

$y_{it}$ 是公司 $i$ 的因变量时间 $t$

$x_{1it}$ 到 $x_{kit}$ 是 &lt; span class=&quot;math-container&quot;&gt;$k$ 自变量

$d_{2t}$ 到 $d_{Tt}$ 是年份虚拟变量（$T$ 是总年数）

$f_{2i}$ 到 $f_{Ni}$ 是公司虚拟变量（$N$ 是行总数）

$\beta_0$ 到 $\beta_k$、$\gamma_2$ 到 $\gamma_T$ 和 $\delta_2$ 到 $\delta_N$ 是要估计的系数

$\varepsilon_{it}$ 是错误项


我的问题是：
1：两种方法在估计和解释方面是否存在显着差异？比如，它们在幕后本质上是一样的吗？
2：考虑到我的数据集的不平衡性质以及许多缺失值的存在，哪种方法更合适？
任何指导或见解将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644015/comparing-two-way-fixed-effects-model-using-pooled-ols-and-panel-data-fixed-effe</guid>
      <pubDate>Mon, 01 Apr 2024 09:33:58 GMT</pubDate>
    </item>
    <item>
      <title>二项分布的置信区间[重复]</title>
      <link>https://stats.stackexchange.com/questions/644013/confidence-interval-for-binomial-distribution</link>
      <description><![CDATA[我正在开发一个简单的记忆应用程序，供个人使用。用户给出与提示相对应的响应，每个提示都属于某个类别。最后，对于每个类别 $c$，用户已给出 $s_c$ 的$n_c$ 正确答案。
一般来说，$n_c$ 可以非常小（0 或 1）。
我希望使用响应作为样本，获得每个类别的用户真实准确度的下限。我认为我应该为此使用二项式置信区间。我浏览了有关该主题的维基百科文章，但很难理解其中的行话。文章说：
&lt;块引用&gt;
在上面列出的近似值中，Wilson 评分区间方法（带或不带连续性校正）已被证明是最准确和最稳健的，尽管有些人更喜欢 Agresti 和 Agresti 方法。针对较大样本量的 Couls 方法。

由于威尔逊方法最准确，而且我的样本量很小，因此我倾向于使用威尔逊方法。但本文中还有其他方法没有在比较中介绍（Jeffreys、Clopper-Pearson、反正弦变换、$t_a$ 变换）。我如何知道其中哪一个适合我？]]></description>
      <guid>https://stats.stackexchange.com/questions/644013/confidence-interval-for-binomial-distribution</guid>
      <pubDate>Mon, 01 Apr 2024 08:45:33 GMT</pubDate>
    </item>
    <item>
      <title>在随机森林中，如何获取分配到不同决策树的样本？</title>
      <link>https://stats.stackexchange.com/questions/644012/in-a-random-forest-how-to-get-the-samples-that-are-assigned-to-different-decisi</link>
      <description><![CDATA[对于我的研究课题，我需要获取随机森林中每个样本所使用的样本，以及训练好的决策树的每个叶子节点中的样本...然后利用这些样本的信息来完成下一步任务。
我知道这项工作对随机森林结果没有统计意义，但我真的需要这个:(]]></description>
      <guid>https://stats.stackexchange.com/questions/644012/in-a-random-forest-how-to-get-the-samples-that-are-assigned-to-different-decisi</guid>
      <pubDate>Mon, 01 Apr 2024 08:32:07 GMT</pubDate>
    </item>
    <item>
      <title>连续情况下的 Log-Sum-Exp 技巧的简单示例</title>
      <link>https://stats.stackexchange.com/questions/644002/simple-example-of-log-sum-exp-trick-for-continuous-case</link>
      <description><![CDATA[我试图确认我对如何应用[Log-Sum-Exp 技巧从对数后验分布恢复后验分布的理解。我想考虑我正在研究的模型中的一个简单示例，并尝试使用该技巧从对数后验中恢复后验。给出归一化后验的示例
$$p(x) = (0.39898) \text{exp}\left[-\frac{1}{8}(-2.5+x)^2\right] \sin ^2(x)$$ 和对应的对数后验
$$\log(p(x))=-\log(2)+\log\left[\frac{\text{exp}\left\{-\frac{1 }{8}(-2.5+x)^2\right\}}{2\sqrt{2 \pi}}\right]+2\log(\sin (x)).$$
对于 Log-Sum-Exp 技巧，我现在考虑定义 $c:= \text{max}~{\log(p(x))} = -2.40119$&lt; /span&gt;（用 Mathematica 进行数值确定）。
log-sum-exp 技巧意味着我们可以通过写来恢复后验
$$p(x) = \text{exp}\big(\log(p(x)) - c-\log \int_x \text{exp}(\log(p) (x)-c)dx\big).$$
这看起来是这个技巧的正确应用吗？当我评估这个例子时，我从数字上得到
$p(x)\text{exp}(1.38639)$。我不知道为什么我会得到这个额外的因子 $\text{exp}(1.38639)$。由于后验已归一化，您是否不会期望 $\text{exp}(0)$ 而不是 $\text{指数}(1.38639)$？我想它不会直接扩展到连续的情况。对于此类问题，如何将离散情况相应地适应连续情况？ Log-Sum-Exp 技巧的连续情况是否有任何标准扩展？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644002/simple-example-of-log-sum-exp-trick-for-continuous-case</guid>
      <pubDate>Mon, 01 Apr 2024 03:05:45 GMT</pubDate>
    </item>
    </channel>
</rss>