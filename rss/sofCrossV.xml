<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 18 Jan 2025 18:20:30 GMT</lastBuildDate>
    <item>
      <title>我是否正确地从该 VAE 中提取了每个类的均值和协方差矩阵？</title>
      <link>https://stats.stackexchange.com/questions/660207/am-i-extracting-the-mean-and-covariance-matrix-per-class-from-this-vae-correctly</link>
      <description><![CDATA[我有以下代码，可以提取每个类的平均值和协方差矩阵。我想知道我做的是否正确？
import numpy as np
import tensorflow as tf
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# 加载并预处理 Iris 数据集
iris = datasets.load_iris()
X = iris.data
y = iris.target
scaler = StandardScaler()
X = scaler.fit_transform(X)

# 按标签拆分数据集
classes = np.unique(y)
X_classwise = {cls: X[y == cls] for cls in classes}

# VAE 架构
latent_dim = 9
input_dim = X.shape[1]

# 为 VAE 定义自定义损失函数（重建损失 + KL 散度）
def vae_loss(inputs,输出、z_mean、z_log_var)：
# 重建损失 (RMSE)
reconstruction_loss = tf.reduce_mean(tf.square(输入 - 输出))
# KL 散度损失
kl_loss = -0.5 * tf.reduce_mean(tf.reduce_sum(
1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1))

返回 rebuild_loss + kl_loss

def build_vae(input_dim, latent_dim)：
# 编码器
encoder_inputs = tf.keras.Input(shape=(input_dim,))
x = tf.keras.layers.Dense(36,activation=&#39;relu&#39;)(encoder_inputs)
x = tf.keras.layers.Dense(18,激活=&#39;relu&#39;)(x)
z_mean = tf.keras.layers.Dense(latent_dim, name=&quot;z_mean&quot;)(x)
z_log_var = tf.keras.layers.Dense(latent_dim, name=&quot;z_log_var&quot;)(x)

# 采样层
def samples(args):
z_mean, z_log_var = args
epsilon = tf.keras.backend.random_normal(shape=tf.shape(z_mean))
return z_mean + tf.exp(0.5 * z_log_var) * epsilon

z = tf.keras.layers.Lambda(sampling, output_shape=(latent_dim,), name=&quot;z&quot;)([z_mean, z_log_var])

编码器 = tf.keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=&quot;encoder&quot;)

# 解码器
latent_inputs = tf.keras.Input(shape=(latent_dim,))
x = tf.keras.layers.Dense(18,activation=&#39;relu&#39;)(latent_inputs)
x = tf.keras.layers.Dense(36,activation=&#39;relu&#39;)(x)
coder_outputs = tf.keras.layers.Dense(input_dim)(x)
coder = tf.keras.Model(latent_inputs,decoder_outputs, name=&quot;decoder&quot;)

# VAE 模型
outputs =coder(encoder(encoder_inputs)[2])
vae = tf.keras.Model(encoder_inputs,outputs, name=&quot;vae&quot;)

# 在模型编译中定义自定义损失
def compute_total_loss(inputs, output):
z_mean, z_log_var, _ =coder(inputs)
return vae_loss(inputs, output, z_mean, z_log_var)

vae.compile(optimizer=tf.keras.optimizers.Adam(), loss=compute_total_loss)

return vae,coder,coder

# 每个类训练一个 VAE
vaes = {}
encoders = {}
for cls in classes:
print(f&quot;Training VAE for class {cls}...&quot;)
X_train, X_val = train_test_split(X_classwise[cls], test_size=0.2, random_state=42)

vae,coder, _ = build_vae(input_dim, latent_dim)
vae.fit(X_train, X_train, epochs=50, batch_size=256, validation_data=(X_val, X_val), verbose=0)

vaes[cls] = vae
coders[cls] =coder

在推理时，我可以使用以下代码提取均值和协方差矩阵：
# 计算每个类的潜在空间中的均值和协方差
latent_stats = {}
X_all_classes = np.concatenate(list(X_classwise.values()), axis=0)
y_all_classes = np.concatenate([np.full(len(X_classwise[cls]), cls) for cls in classes])

# 对所有数据点同时使用模型预测以避免回溯
z_means, z_log_vars, z_samples =coders[cls].predict(X_all_classes)

# 现在按类计算均值和协方差
for cls in classes:
print(f&quot;计算类 {cls} 的均值和协方差...&quot;)
# 过滤每个类的 z_samples
z_samples_cls = z_samples[y_all_classes == cls]
latent_stats[cls] = {
&quot;mean&quot;: np.mean(z_samples_cls, axis=0),
&quot;covariance&quot;: np.cov(z_samples_cls, rowvar=False),
}

# 打印结果
for cls, stats in latent_stats.items():
print(f&quot;类 {cls} 潜在均值:\n{stats[&#39;mean&#39;]}&quot;)
print(f&quot;类{cls} 潜在协方差:\n{stats[&#39;covariance&#39;]}&quot;)

提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660207/am-i-extracting-the-mean-and-covariance-matrix-per-class-from-this-vae-correctly</guid>
      <pubDate>Sat, 18 Jan 2025 17:10:23 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SAS 在 MMRM 中获取预测值？</title>
      <link>https://stats.stackexchange.com/questions/660206/how-to-get-predicted-values-in-mmrm-using-sas</link>
      <description><![CDATA[这是我的问题：
在我的研究中，主要终点是“在过去六周的访问中进行的四次测量中有三次达到固定阈值血红蛋白 (Hb) &gt;= 12g/dL 的患者百分比”，Hb 是在治疗后的几次访问中测量的。
为了处理在过去四次预定测量中出现的缺失值，我决定使用重复测量的混合模型，并使用基于模型的预测来估算缺失值。由于我对这种模型了解不多，我尝试了一些方法：
我的数据如下所示：

方法 1：
proc combined data=indata covtest;
where visitn ne 1;
class age(ref=&quot;&lt;45&quot;) visitn subjid gender(ref=&quot;Female&quot;);
model hb=age gender visitn base/ solution;
repeat visitn/subject=subjid type=UN;
lsmeans visitn/cl;
store work.modeldata;
run;

data shooting;
set indata;
where visitn&gt;1;
run;

proc plm restore=modeldata;
score data=scoring out=preddata2 predict=pred;
run;

我在Proc Mixed中使用Store语句来存储模型拟合，然后使用Proc Plm获取名为“Pred”的预测值。以下是参考：https://support.sas.com/kb/69/066.html
方法 2
proc combined data=indata covtest;
where visitn&gt;1;
class age(ref=&quot;&lt;45&quot;) visitn subjid gender(ref=&quot;Female&quot;);
model hb=age gender visitn base/ solution outp=Predata3;
duplicate visitn/subject=subjid type=UN;
lsmeans visitn/cl;
run;

如您所见，相同的模型，相同的代码，但我在 model 语句中使用了 outp= 选项，并在“Predata3”数据集中获得了基于模型的预测，名为“Pred”。
现在结果显示：如果观测值（HB）存在，则两种方法给出相同的预测，但当 HB 缺失时，预测完全不同。
我做错了什么？我想知道它们为什么不同，哪种方法才是我真正需要的。如果您对此有任何想法，非常感谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660206/how-to-get-predicted-values-in-mmrm-using-sas</guid>
      <pubDate>Sat, 18 Jan 2025 16:10:28 GMT</pubDate>
    </item>
    <item>
      <title>随机森林中的迭代与 set.seed</title>
      <link>https://stats.stackexchange.com/questions/660203/iterations-vs-set-seed-in-a-random-forest</link>
      <description><![CDATA[众所周知，种子参数会影响模型性能，例如，在本线程中讨论过
另一种方法可能是迭代运行模型，如同一研究人员在此处和此处中演示的那样（“简而言之，我们使用了随机森林分类和回归算法，训练集和测试集分割为 80/20，重复 100 次&quot;)。然而，目前尚不清楚他们是否使用迭代来替代 set.seed 或与之结合，因为他们在工作中没有明确说明这一点。
不依赖种子的模型拟合迭代方法似乎是理想的，因为它会在多次运行中平均模型选择。然而，我在网上找不到足够的信息来确认或反驳这种方法的有效性。
你对这种方法有什么看法？]]></description>
      <guid>https://stats.stackexchange.com/questions/660203/iterations-vs-set-seed-in-a-random-forest</guid>
      <pubDate>Sat, 18 Jan 2025 14:58:28 GMT</pubDate>
    </item>
    <item>
      <title>在面板数据上对多元回归的 FGLS 设置协方差矩阵</title>
      <link>https://stats.stackexchange.com/questions/660201/setting-up-covariance-matrix-for-fgls-on-multiple-regressions-on-panel-data</link>
      <description><![CDATA[我将面板数据组织为一组时间指数横截面数据。也就是说，对于超过 1000 个日期，我有一组 40 个点。这 40 个点始终指代相同的“个体”。
在每个日期，我都会运行多元线性回归，因为我对系数随时间的变化很感兴趣。我使用 OLS 来查找我的参数。这些参数在每个时间 $t$ 给出：
$\hat{\beta}_t = (X^\top X)^{-1} X^\top y_t$
然而，在研究我的残差时，我发现了两件事：

横截面研究（分析每个日期的残差）表明我有异方差 - 我的残差似乎在我的值的左侧部分比右侧部分更大，并且主要显示右侧值的自相关性。
。
跨时间研究（对 40 个个体跨时间的残差进行分析）证实了残差之间存在很强的相关性。在每个时间点，我的残差都非常接近 0，尽管它们往往会相互反转（如果一个“残差组”现在为负，则另一个将“补偿”） - 正如我们在下面的相关矩阵中看到的那样：


因此，似乎 OLS 产生 BLUE 的 3 个标准之一没有得到尊重，即我没有形式为 $\sigma^2 \mathbf{I}$ 的协方差。
在这种情况下可以使用 FGLS，整个挑战出现在确定协方差矩阵 $\Omega$（或 $\Omega_t$ 在这种情况下？）在 $\hat{\beta}_t = (X^\top \Omega^{-1} X)^{-1} X^\top \Omega^{-1} y_t$ 中。我发现主题讨论确定面板回归的协方差矩阵，用于“简单回归”，但不用于多重时间指数线性回归。
我的问题是：

在这种情况下，FGLS 会是一个很好的解决方案吗？在我看来，我对残差的结构及其行为有相对良好的了解，从而允许我生成一个“合乎逻辑的”协方差矩阵。
横截面多时间指数回归具有独特的优势，即用不同的数据估计相同类型的回归，从而揭示残差随时间的变化行为 - 简单地使用残差随时间的变化历史协方差矩阵作为 FGLS 中的协方差矩阵是否是一个好方法？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660201/setting-up-covariance-matrix-for-fgls-on-multiple-regressions-on-panel-data</guid>
      <pubDate>Sat, 18 Jan 2025 12:51:26 GMT</pubDate>
    </item>
    <item>
      <title>用于样本量估计的 Bootstrap。序数尺度。分布远离正态</title>
      <link>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</link>
      <description><![CDATA[我们经常在约 100 个句子的测试翻译上比较人工翻译或机器翻译系统（每次实验中为 2 到 4 个）。
每个句子的翻译都由一名称职的翻译人员进行评分，通常为 5 分制，有时为 10 分制（分数通常为整数，但可以包括中点，例如 3.5），费用昂贵。这是我们的黄金标准，尽管不同评分者之间的结果并非 100% 一致。这意味着我正在寻找经验法则，而不是最严格的方法。
量表由口头描述定义（“小幅编辑”、“严重改变含义”等）。因此它们本质上是有序的，通常是倾斜的，有时是双峰的。
如果有两种翻译，则使用 Wilcoxon 检验来评估结果，如果有两种以上的翻译，则使用 Friedman 检验来评估结果。
如果我们无法拒绝原假设，我们可能想看看更大的样本是否有帮助。下面是我想要使用的算法。

从原始样本中生成引导样本。使用 Wilcoxon/Friedman 检验评估每个样本，并计算我们可以拒绝原假设的样本比例。这是我们估计的功效。

通过从原始样本中重复抽样来生成更大的样本，但这次抽取的项目要多于原始样本量。按照与上述第 (1) 点相同的方式估计检验功效。

不断增加生成的样本量，直到达到所需功效或样本量变得过大。


从实际角度来看，这有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</guid>
      <pubDate>Sat, 18 Jan 2025 12:37:22 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵损失的方差是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/660198/what-is-the-meaning-of-the-variance-of-cross-entropy-loss</link>
      <description><![CDATA[通常我们用所有测试集的交叉熵损失的平均值作为指标，那我们可以用交叉熵损失的方差作为指标吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660198/what-is-the-meaning-of-the-variance-of-cross-entropy-loss</guid>
      <pubDate>Sat, 18 Jan 2025 12:21:24 GMT</pubDate>
    </item>
    <item>
      <title>需要有关时间序列分析中使用的数据的帮助</title>
      <link>https://stats.stackexchange.com/questions/660195/need-help-regarding-the-data-used-in-time-series-analysis</link>
      <description><![CDATA[我是时间序列的初学者。我试图通过获取过去 10 年的月度数据来预测棉花作物的价格。但价格数据仅适用于 1 月至 5 月，然后是 11 月和 12 月。由于棉花在这里是季节性作物，因此没有其他月份的市场数据。那么在这种情况下，我该如何进行时间序列分析，以及我应该使用多少个最小数据点来运行模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/660195/need-help-regarding-the-data-used-in-time-series-analysis</guid>
      <pubDate>Sat, 18 Jan 2025 10:11:48 GMT</pubDate>
    </item>
    <item>
      <title>当响应变量是“一年中的某一天”时，应使用哪种回归模型</title>
      <link>https://stats.stackexchange.com/questions/660197/which-regression-model-to-use-when-response-variable-is-day-of-the-year</link>
      <description><![CDATA[我有一个检测数据集，其中包含一年中被标记动物被重新检测到的天数（即 1 - 365），该天数是在它之前被释放的地点（即 release_location）被重新检测到的。有来自五个不同释放地点的多只被标记的动物，有些动物在被释放后的多年内被重新检测到（即 redetection_year）。示例数据（实际数据集要大得多）：
redetection_year&lt;-c(2,3,2,4,5,3,4,2,5)
redetection_day&lt;-c(25,66,340,129,12,67,200,36,248)
animal_id&lt;-c(1,1,2,3,3,4,4,4,4)
release_location&lt;-c(&quot;A&quot;,&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;,&quot;A&quot;,&quot;A&quot;,&quot;A&quot;)
df&lt;-data.frame(animal_id, release_location, redetection_day, redetection_year)

我想要在 R 中运行模型，以测试释放位置和重新检测年份（预测变量）是否预测重新检测日期（即 1-365）（响应变量）。这可以通过线性回归来实现吗？还是因为响应变量的格式而需要考虑？即它只从 1 到 365，它是循环的。
我读过一些关于 Tobit 回归的文章，这些回归适用于响应变量被审查的情况，以及许多关于当它是预测变量时如何使用“天”变量的示例，但我找不到适合我的问题的解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/660197/which-regression-model-to-use-when-response-variable-is-day-of-the-year</guid>
      <pubDate>Sat, 18 Jan 2025 08:51:33 GMT</pubDate>
    </item>
    <item>
      <title>季节性虚拟变量回归。为什么我们要在这个回归中使用时间趋势？或者说，在什么情况下我们应该使用时间趋势？</title>
      <link>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</link>
      <description><![CDATA[我的导师希望我用季节性虚拟变量进行回归分析。
我有 DPPI 指数（土耳其国内生产者价格指数），这是月度数据。
首先，我需要用截距项和 11 个虚拟变量进行回归分析。
其次，我需要用 12 个虚拟变量进行不带截距项的回归分析。
在这两种情况下，我都应该包括时间趋势项吗？在哪种情况下，或者为什么包括时间趋势项？
或者，我应该同时使用和不使用时间趋势项进行这两个回归分析吗？
我的最后一个问题是我需要分析残差。为此，我应该对残差应用哪些测试或图？
请与我分享您的想法。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</guid>
      <pubDate>Fri, 17 Jan 2025 18:42:39 GMT</pubDate>
    </item>
    <item>
      <title>伪似然与似然的比较</title>
      <link>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</link>
      <description><![CDATA[假设我们有一个离散多元概率分布，其密度$f_{\theta}(X=(x_1,\ldots,x_n))=\frac{g_{\theta}(X=(x_1,\ldots,x_n))}{Z}$取决于某个参数$\theta$。我特意以这种形式将其写出，以表示 Z 是难以计算的归一化常数（它也可能依赖于$\theta$）。这种分布的伪似然函数（为简单起见，针对单个数据点）是否定义为：
$$
PL_{\theta}(X=(x_1,\ldots,x_n)) = \prod_{i}f_{\theta}(X_i=x_i | X_j=x_j, i \neq j)
$$
如果是这样，则由此得出的公式在我看来有点奇怪，因为：
$$
= \prod_{i}\frac{g_{\theta}(X)}{\sum_{X_i=a}g_{\theta}(X_1=x_1,\ldots,X_i=a,\ldots)}
$$
调用分母 $Z_i(X)$ 可得到：
$$
\log(PL_{\theta}(X=(x_1,\ldots,x_n))) = n \log(g_{\theta}(X)) - \sum_i \log( Z_i(a))
$$
而真实可能性为
$$
\log(L_{\theta}(X=(x_1,\ldots,x_n))) = \log(g_{\theta}(X)) - \log(Z)
$$
我不知道为什么伪对数可能性可以替代对数可能性。我确实知道计算起来比计算似然性要容易得多，但我无法理解为什么这是一个可接受的估计值。原始文章（Besag Statistical Analysis of Non-Lattice Data (1975)）在这方面没有太大帮助，非常简短的维基百科上关于伪似然性的文章也没有。我知道现在人们可能更喜欢蒙特卡洛之类的方法，但我仍然想了解一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</guid>
      <pubDate>Fri, 17 Jan 2025 16:25:55 GMT</pubDate>
    </item>
    <item>
      <title>针对 2 个以上类别的卡方检验（2x5 列联表）</title>
      <link>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</link>
      <description><![CDATA[我有一个 2x5 的频率表，其中有 2 列分别名为男性和女性，5 行分别名为病理 A、B、C、D 和 E。
我想确定不同病理类别的性别比例是否存在统计学差异。
例如：男性是否比女性更频繁地受到病理 A 的影响（每个类别都是如此）？
我是否可以将其他类别（例如 B + C + D + E）相加以创建新的 2x2 列联表并对其进行卡方检验？
这在统计上正确吗？如果我的 p 值小于 0.05，我可以得出的结论是：男性比女性更频繁地受到病理 A 的影响？
问题是，如果我对所有数据计算一次卡方检验，我只能对情况有一个整体了解。

感谢大家的回复。实际上，我的不同类别如下：
列：男性和女性
行：A = 无病理（健康患者），B = β-地中海贫血，C = α-地中海贫血，D = db-地中海贫血，E = 其他。
患者只能属于五个类别之一，因为他们被诊断出患有相同的测试。因此，它们是互斥的。
最初，我创建了 5 个 2x2 列联表，如我在第一篇文章中所述，并将其视为二元变量（如 Rick 所述，存在或不存在），但我不确定我能从中得出什么结论，以及将一些类别组合在一起以评估特定类别的频率在两性之间是否存在显着差异是否在统计上正确。
我不一定想计算比值比，只是想知道根据卡方检验，我的病理分布在男性还是女性中更常见。
感谢您的所有回复。我期待阅读您的结论。
此致，
Adrien]]></description>
      <guid>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</guid>
      <pubDate>Fri, 17 Jan 2025 12:27:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Mercer 定理总是被引用于核学习而不是 Moore-Aronszajn</title>
      <link>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</link>
      <description><![CDATA[为什么在大多数关于核技巧的解释中，Mercer 定理都用作依据？
我们能否用 Moore-Aronszajn 来证明这一点，该定理不将紧致性假设置于 $X$ 和 $k$ 连续性上？
编辑：
那么，核技巧背后的想法是，我们能够计算某个希尔伯特空间 $H$ 中的内积，而不必将数据嵌入该空间，因为 $k(x,x&#39;) = \langle \phi(x), \phi(x&#39;) \rangle_{H}$，对于某个 $\phi : X \mapsto H$
现在，经常引用 mercer 定理来证明这样的 $\phi$ 存在。然而，通过 Moore-Aronszajn 定理，我们知道对于 p.d. 核 $k$，特征图 $\phi_{H_k}: X \mapsto H_k = \mathbb{R}^X$，其中 $\phi_{H_k}(x) = k(x,\cdot)$ 满足 $k(x,x&#39;) = \langle \phi(x)_{H_k}, \phi_{H_k}(x&#39;) \rangle_{H_k}$。那么，为什么 Mercer 经常被引用呢？此外，有些 p.d. 核不是连续的，因此无法通过 Mercer 定理进行论证。]]></description>
      <guid>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</guid>
      <pubDate>Fri, 17 Jan 2025 11:39:14 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归中的虚拟变量与虚拟变量交互作用</title>
      <link>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</link>
      <description><![CDATA[我正在 R 中进行泊松回归，以估计按年龄组和病毒分类的死亡人数，其中相互作用的项是因子：
model &lt;- glm(death_count ~ strain * cohort + age + year,
family = poisson(link = &quot;log&quot;),
offset = log(exposure),
data = df)

我的 df 是面板数据，其中包含每年特定年龄的死亡人数。每年都以特定病毒为特征，每个年龄分配一个群体。我试图找出以病毒 C 为特征的年份中死亡人数减少的统计意义。以下是简化的回归输出：
 估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -15.39575 0.07621 -202.012 &lt; 2e-16 ***
病毒A -1.29389 0.08358 -3.516 0.000437 ***
病毒B 2.80059 0.06230 12.851 &lt; 2e-16 ***
病毒C 4.22142 0.05298 60.800 &lt; 2e-16 ***
群组X -2.99472 0.02494 -39.890 &lt; 2e-16 ***
群组Y -1.76074 0.02747 -27.691 &lt; 2e-16 ***
群组Z -1.31331 0.03499 -8.953 &lt; 2e-16 ***
病毒A：群组X 1.39666 0.07366 5.385 7.24e-08 ***
病毒B：群组X 1.21714 0.05685 3.820 0.000134 ***
病毒C：群组X -3.97906 0.03390 -28.883 &lt; 2e-16 ***
病毒A：队列Y 1.24520 0.10246 2.393 0.016701 * 
病毒B：队列Y 1.05056 0.07980 0.634 0.526360 
病毒C：队列Y -1.43923 0.03422 -12.836 &lt; 2e-16 ***
virusA:cohortZ 0.12472 0.13408 0.930 0.352274 
virusB:cohortZ -0.33748 0.11851 -2.848 0.004404 ** 
virusC:cohortZ -1.13441 0.04187 -3.210 0.001327 ** 

我知道没有交互项的系数是与参考组相比的，但我听说在泊松回归中，交互项并不那么简单。
我有兴趣解释为什么与队列 Y 和 Z 相比，队列 X 感染病毒 C 的死亡率减少幅度最大。我不太明白如何理解交互系数，我也不明白为什么截距为负。如果没有偏移量，截距 = 0.18252，我无法理解这一点，因为我认为添加偏移量会将 DV 变成速率。]]></description>
      <guid>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</guid>
      <pubDate>Fri, 17 Jan 2025 00:16:33 GMT</pubDate>
    </item>
    <item>
      <title>回归分析中总体模型和样本模型的区别是什么？</title>
      <link>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</link>
      <description><![CDATA[术语“样本回归模型”在回归分析中究竟指什么？假设我们有一个数据集$\{(\mathbf{x}_i,\mathbf{y}_i)\}$，我们假设一个底层回归模型形式为
$$
\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon},
$$
其中$\boldsymbol{\theta}$是真实总体参数（频率学派观点）和$\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\Sigma)$。我们所说的样本回归模型到底是什么意思？
以下是我正在探索的一些可能性：

拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}})$，从某种意义上说，我们已经选择了一个估计值$\hat{\boldsymbol{\theta}}$;
拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}}) + \hat{\boldsymbol{\epsilon}}$，其中我们有一个估计值$\hat{\boldsymbol{\theta}}$ 而且 $\hat{\boldsymbol{\epsilon}} \sim \mathcal{N}(\mathbf{0},\hat{\Sigma})$;
从字面上看，人口模型 $\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon}$，但现在以样本指数的形式写出：$\mathbf{y}_i = f(\mathbf{x}_i;\boldsymbol{\theta}) + \boldsymbol{\epsilon}_i$ 使得 $\boldsymbol{\epsilon}_i$ 是观测值，而不是随机向量。
关系 $\mathbf{y}_i = f(\mathbf{x}_i;\hat{\boldsymbol{\theta}}) + \mathbf{e}_i$，其中 $\mathbf{e}_i = \mathbf{y}_i - \hat{\mathbf{y}}_i$ 是残差。

如能得到严格澄清，我们将不胜感激。

编辑：这个问题被认为不清楚，因此这里进行澄清。
问题：术语“样本回归模型”是指什么？
动机：术语“样本回归模型”用于回归分析文献中。例如，Montgomery、Peck 和 Vining 所著的《线性回归分析导论》第六版就使用了该术语。使用 Google 的“图书”标签搜索“样本回归模型”（带引号）也会产生大量结果。但是，我很难理解该术语的正式含义，这就是我提出这个问题的原因。从我目前所见，似乎确实存在对该术语的混淆，因为许多人都在使用该术语，但一些知识渊博的人似乎并不熟悉它。因此，我认为在论坛中回答这个问题是有价值的。]]></description>
      <guid>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</guid>
      <pubDate>Thu, 16 Jan 2025 07:27:25 GMT</pubDate>
    </item>
    <item>
      <title>Rao-Blackwell 定理中估计量和统计量的区别</title>
      <link>https://stats.stackexchange.com/questions/660129/difference-between-estimator-and-statistic-in-rao-blackwell-theorem</link>
      <description><![CDATA[问题：当“估计量”和“统计量”都用于查找参数$\theta$时，这两个词之间有区别吗？我的理解是，估计量“估计”一个参数，而统计量基本上做同样的事情，所以它们似乎是同一事物的名称。在这种情况下，下面的 Rao-Blackwell 定理基本上是在谈论两个估计量，但事实上不同的词语适用于 $T$ 和 $\tilde{\theta}$，这让我不确定……
我看到 Rao-Blackwell 定理说，如果我们有一个充分统计量 $T$ 用于 $\theta$，并且有一个估计量 $\tilde{\theta}$ 用于 $\theta$，使得 $\mathbb{E}(​​\tilde{\theta}^2) &lt; \infty$，我们可以构造 $\hat{\theta} = \mathbb{E}[\tilde{\theta}|T]$ 作为另一个无偏估计量或统计数据，并且 $\hat{\theta}$ 的 m.s.e. 低于 $\tilde{\theta}$。在这种情况下，$T$ 和 $\tilde{\theta}$ 都可以称为“统计数据”，或者都可以称为“估计量”，这样是否有效？]]></description>
      <guid>https://stats.stackexchange.com/questions/660129/difference-between-estimator-and-statistic-in-rao-blackwell-theorem</guid>
      <pubDate>Tue, 14 Jan 2025 21:18:54 GMT</pubDate>
    </item>
    </channel>
</rss>