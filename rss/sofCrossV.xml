<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 20 Jul 2024 21:13:39 GMT</lastBuildDate>
    <item>
      <title>带有 Morisita-Horn 指数的 NMDS：哪种数据转换有意义？</title>
      <link>https://stats.stackexchange.com/questions/651459/nmds-with-morisita-horn-index-which-data-transformation-makes-sense</link>
      <description><![CDATA[我有一个蜘蛛群落矩阵，是我在冬季在不同的林分类型中捕获的。
我现在想进行 NMD。为此，我想使用 R 中 vegdist 包中的 Morisita-Horn 指数：


其中 xij = 样本 j 中物种 i 的个体数
xik = 样本 k 中物种 i 的个体数
据我所知，该指数非常适合评估林分类型共享物种的程度，同时整合了物种相对丰度的相似性。
我有一个包含许多零的矩阵，因为我捕获了许多稀有物种。下面是矩阵的示例：

当我在 R 中应用 metaMD 时，R 会自动应用威斯康星双重标准化。老实说，我真的不明白这种转变的含义。
目前，我想知道我是否应该应用任何转换，或者这是否没有必要。在另一篇科学家的论文中，他们也捕获了冬季的蜘蛛，他们使用了 hellinger 变换（计算每个样本中物种的相对丰度并对所有值进行平方根变换）。这增强了较少数量物种的影响力。例如：
我的社区矩阵中的两个样本：
1.4：1,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,1,0,0,0,0,0,2,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
4.2：0,0,0,0,1,0,0,1,0,0,14,0,0,0,0,0,0,0,0,2,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,2,0,0,2,0,0
（丰度11 和 14 属于一个共同的物种，1 和 6）
当我使用不带任何变换的“horn”指数时，我得到的值是 0.1310861，这意味着它们在物种和样本中的相对丰度方面彼此非常相似（0 表示完全相似），而且在查看数据时也很明显（因为物种有 11 和 14 个个体）。
但是当我之前应用 hellinger 变换时，我得到的值是 0.33205，所以它们不太相似，因为它们不共享具有低丰度的物种。
当然，在绘制 NMDS 时绝对值并不重要，但我猜它会改变考虑所有样本时的关系。
应用这种转换有意义吗？一方面，我会说是的，因为其中包含了更多关于丰度较低的物种的信息，但另一方面，丰度如此低的物种可能只是没有在另一个林分中被捕获，即使它们也在那里……所以包括那些随机采样效应就太多了……
所以最后我的问题是：
当我使用 Morisita-Horn 指数时，对我的数据应用 Hellinger 标准化而不是威斯康星双重标准化是否有意义？
或者换一种问法：选择某种标准化的标准是什么？
在另一篇论文中，他们在应用 Morisita Horn 指数之前只是对他们的丰度数据进行了平方根变换。我有点不知所措。
感谢您的任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/651459/nmds-with-morisita-horn-index-which-data-transformation-makes-sense</guid>
      <pubDate>Sat, 20 Jul 2024 20:11:58 GMT</pubDate>
    </item>
    <item>
      <title>使用加法用链式法则计算梯度[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651458/calculate-gradient-with-chain-rule-using-additions</link>
      <description><![CDATA[我正在学习 Karpathy 的课程，具体来说，我正在观看第一个视频。micrograd 的开发中有一个步骤我并不完全理解。具体来说，在本节中，当他谈到如果同一个节点或参数使用多次，则计算其梯度的正确方法是将图中使用它的不同部分的梯度相加。根据视频，维基百科页面上的“多变量情况”中的链式法则对此进行了解释部分。
我已经进行了各种手动测试，并且确实可以通过对节点在其介入的不同点处的贡献求和来正确计算梯度，但我不明白为什么总是要对贡献求和，并且这并不依赖于例如节点所涉及的操作。
非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/651458/calculate-gradient-with-chain-rule-using-additions</guid>
      <pubDate>Sat, 20 Jul 2024 18:27:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 lme4 在 R 中重复测量 HLM [关闭]</title>
      <link>https://stats.stackexchange.com/questions/651450/repeated-measures-hlm-in-r-using-lme4</link>
      <description><![CDATA[我进行了一项采用受试者内设计的实验。每个参与者与两个系统进行交互，每次交互后，都会用问卷调查相同的结构进行测量。参与者与系统交互的顺序是随机的，因此我有两个组（系统 1，然后是系统 2，然后是反之）。所以我的数据嵌套在每个参与者中，而每个参与者又嵌套在一个组中。
我现在想分析我收集的数据。我的研究模型如下：
系统影响结构 a；a 影响 b 和 c； b 和 c 影响 d
我有两个主要问题：

不可能创建一个使用 HLM 一次性计算所有依赖关系的模型，对吗？

我的测量 lmer(...) 的代码看起来如何？


a ~ system + (1|participant) + (1|group) -&gt;我想找出哪个系统产生更高的 a
b ~ a + (1|participant) + (1|group) + (1|system)
c ~ a + (1|participant) + (1|group) + (1|system)
d ~ b + c (1|participant) + (1|group) + (1|system) ]]></description>
      <guid>https://stats.stackexchange.com/questions/651450/repeated-measures-hlm-in-r-using-lme4</guid>
      <pubDate>Sat, 20 Jul 2024 10:59:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 LOOCV 中的正则化减少小型数据集的方差</title>
      <link>https://stats.stackexchange.com/questions/651449/reducing-variance-with-regularization-in-loocv-for-small-datasets</link>
      <description><![CDATA[我有一个小数据集，我正在考虑使用留一交叉验证 (LOOCV) 来评估我的模型。我理解，交叉验证通常是一种评估模型在未见数据上的表现的方法。
但是，我担心偏差-方差权衡。具体来说，使用 LOOCV 时，存在偏差低但方差高的风险。为了缓解这种情况，我正在考虑使用正则化模型（L1、L2 或 Elastic Net）来引入一些偏差并减少方差（在使用 loocv 时同时……）。
您能否提供任何实施此方法的提示或最佳实践？任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/651449/reducing-variance-with-regularization-in-loocv-for-small-datasets</guid>
      <pubDate>Sat, 20 Jul 2024 10:57:12 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用正则化方法作为特征选择方法，然后使用机器学习模型来分析数据？</title>
      <link>https://stats.stackexchange.com/questions/651448/would-it-be-possible-to-use-regularization-methods-as-a-feature-selection-method</link>
      <description><![CDATA[我的数据是具有超过 14000 个特征的 RNA-seq 数据，问题是二分类。那么总样本是 50 并且 p&gt;&gt;n。当我使用 Elasticnet 方法对训练和测试数据进行处理时，敏感度为 0.6，准确度为 0.5。当我使用 Elasticnet 作为特征选择，然后将随机森林或深度学习拟合到所选特征时，结果会更好。例如，在随机森林建模中，敏感度为 0.97，对于深度学习，敏感度为 0.84。所以，我的问题是，是否可以使用正则化方法作为特征选择方法，然后使用机器学习模型来分析分类问题中的数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/651448/would-it-be-possible-to-use-regularization-methods-as-a-feature-selection-method</guid>
      <pubDate>Sat, 20 Jul 2024 10:51:36 GMT</pubDate>
    </item>
    <item>
      <title>证明 $T$ 是一个完全统计量，并找到 $p$ 的 UMVUE</title>
      <link>https://stats.stackexchange.com/questions/651430/prove-that-t-is-a-complete-statistic-and-find-a-umvue-for-p</link>
      <description><![CDATA[在准备预赛时，我遇到了这个问题：
设$X_1, X_2,\cdots, X_n$为伯努利试验序列，$n \geq 4.$已知，$X_1,X_2,X_3 \stackrel{\text{i.i.d.}}{\sim} Ber(\frac12),$且对于$4\leq i \leq n,$ $P(X_i=X_{i-1}|X_1,\cdots,X_{i-1})=1-p,$ $p \in (0,1).$ 考虑 $T:=\sum_{i=4}^n |X_i-X_{i-1}|$。$T$ 是否完整？因此（否则），找到 $p$ 的 UMVUE。
到目前为止，我所能证明的只是 $S:=\frac{T}{n-3}$ 对于 $p$ 是无偏的。如果我能进一步证明 $T$ 对于 $p$ 是完全充分的，那么 $S$ 将是 UMVUE，由 Lehmann-Scheffe 提出。我如何证明 $T$ 是完全的？我没能找到 $E[f(T)],$ 的简洁表达式，其中 $f$ 是 Borel 可测的。]]></description>
      <guid>https://stats.stackexchange.com/questions/651430/prove-that-t-is-a-complete-statistic-and-find-a-umvue-for-p</guid>
      <pubDate>Fri, 19 Jul 2024 20:46:19 GMT</pubDate>
    </item>
    <item>
      <title>皮尔逊卡方和相关性</title>
      <link>https://stats.stackexchange.com/questions/651426/pearson-chi-square-and-correlation</link>
      <description><![CDATA[我的数据是有序的
Pearson 卡方检验值为 4.664
并且不对称 sig 为 0.97，因此数据是独立的
但是 pearson 的 R =-0.309
并且近似 sig=0.037
它们可以同时独立和负相关吗]]></description>
      <guid>https://stats.stackexchange.com/questions/651426/pearson-chi-square-and-correlation</guid>
      <pubDate>Fri, 19 Jul 2024 20:13:56 GMT</pubDate>
    </item>
    <item>
      <title>lmer - 如何解释随机因素之间的相关性？</title>
      <link>https://stats.stackexchange.com/questions/651416/lmer-how-to-interpret-correlation-between-random-factors</link>
      <description><![CDATA[我的模型：
DV ~ 1 + 时间 * IV + (1 + 时间 | 受试者 ID)

其中 IV 是受试者间独立变量，时间 是受试者内重复测量。DV 是因变量。该模型没有收敛警告/问题。
这是随机效应表：
随机效应：
组名称方差标准差校正
受试者 ID（截距）1541413 1241.5
时间 322490 567.9 -0.75
残差 3172063 1781.0

Q1。 “强”相关性（即 &gt; .7）是什么意思，我应该如何在分析中解释它？
Q2。如果相关性是“强”甚至是 1，我是否应该按时间降低随机斜率，只保留 Subject_ID 的随机截距？
Q3。如果相关性是“弱”的（即 &lt;.3），这是什么意思，我应该如何在分析中解释它？]]></description>
      <guid>https://stats.stackexchange.com/questions/651416/lmer-how-to-interpret-correlation-between-random-factors</guid>
      <pubDate>Fri, 19 Jul 2024 16:30:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 glmer 逻辑回归检查收敛问题后的模型</title>
      <link>https://stats.stackexchange.com/questions/651414/checking-model-after-convergence-issues-with-glmer-logistic-regression</link>
      <description><![CDATA[我正在使用 glmer 运行逻辑回归模型，其中受试者 ID 嵌套在窝仔 ID 中。方程式如下：
glmer(结果 ~ 组 * 时间 + 上一状态 + (1|窝仔/幼崽), 数据, 家庭 = 二项式())
我正在分析一项随机对照试验，该试验有来自 120 窝的 679 名受试者，总共 1983 个观察值。
当包含受试者 ID 时，模型不会收敛。我使用了“allFit”，发现如果我使用“bobyqa”，模型就会收敛。但是，受试者 ID 的随机效应方差看起来非常高 - 使用公式 var/(var+pi^2/3)，它表明受试者 ID 本身就解释了我的结果中超过 99% 的方差。我查看了受试者 ID 的毛毛虫图（使用 qqmath），看看它是否看起来合理（试图决定我是否可以继续报告结果），但我不确定它显示了什么，也不确定它是否真的对我有帮助。有人对此有什么想法或想法吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651414/checking-model-after-convergence-issues-with-glmer-logistic-regression</guid>
      <pubDate>Fri, 19 Jul 2024 16:22:19 GMT</pubDate>
    </item>
    <item>
      <title>我有一个包含 18 个生物标志物特征和一个目标变量的数据集。我想找到对目标影响最大的特征</title>
      <link>https://stats.stackexchange.com/questions/651353/i-have-a-dataset-with-18-biomarker-features-and-a-target-variable-i-want-to-fin</link>
      <description><![CDATA[我有一些疾病生物标志物数据集，其中包含来自不同样本的 18 个生物标志物读数和一个显示疾病存在与否的目标变量（特征既有分类特征也有数值特征）。我想看看是否只使用对目标变量影响最大的特征会提高我的预测模型的性能——目前使用 scikit learn。
以下是数据等的一些细节。

这些是我拥有的肝病数据集，共有 4 个。它们都包含相同的 18 个生物标志物特征，其中包括“白蛋白水平”、“总胆固醇”、“性别”、“甘油三酯”等读数。

2.目标变量是二进制的，“0”= 无肝病，“1”= = 肝病。

我有一个用于训练的发现数据集和 3 个用于测试的验证数据集。因此准确度指标基于验证集中对疾病的正确预测。

我尝试应用浅层模型，包括使用 18 种生物标志物以及 MLP 的逻辑回归、梯度提升和随机森林。数据集非常不平衡，表现不如我希望的那样好，尤其是对于预测第 1 组。- 这就是我认为特征选择可以帮助减少噪音的原因。

我尝试过一种随机森林方法来查看每个特征在多大程度上降低了分割的杂质 - 虽然鉴于我经验不足，我不知道这是否是最好的方法。


有人可以建议如何做这件事的好方法吗？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/651353/i-have-a-dataset-with-18-biomarker-features-and-a-target-variable-i-want-to-fin</guid>
      <pubDate>Thu, 18 Jul 2024 16:31:46 GMT</pubDate>
    </item>
    <item>
      <title>我有计数数据，但它不遵循泊松分布，该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/651343/i-have-count-data-but-it-does-not-follow-a-poisson-distribution-what-to-do</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651343/i-have-count-data-but-it-does-not-follow-a-poisson-distribution-what-to-do</guid>
      <pubDate>Thu, 18 Jul 2024 13:55:15 GMT</pubDate>
    </item>
    <item>
      <title>处理具有许多变量和大量数据集的Cox模型中的非比例风险[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651252/dealing-with-non-proportional-hazards-in-a-cox-model-with-many-variables-and-a-l</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651252/dealing-with-non-proportional-hazards-in-a-cox-model-with-many-variables-and-a-l</guid>
      <pubDate>Wed, 17 Jul 2024 14:28:42 GMT</pubDate>
    </item>
    <item>
      <title>R 中连续数据的期望值</title>
      <link>https://stats.stackexchange.com/questions/651249/expected-value-of-continuous-data-in-r</link>
      <description><![CDATA[我目前正在 R 中处理涉及三个连续变量的数据，我想计算联合概率分布的预期值。
我尝试使用 ks 包中的 kde() 来估计概率密度，然后对其进行积分以找到预期值。
但是，我遇到了一个问题：要执行积分，我需要一个涉及变量的表达式，但 kde 将特定点的概率估计为常数。
这是我的代码：
kde_estimate &lt;- kde(data, eval.points = data[1:nrow(data)])
library(pracma)
func &lt;- (kde_estimate$estimate) * (data$V1 * data$V2 * data$V3)
integral2(func, xmin=0, xmax=3, ymin=1, ymax=2)

有人能指导我如何推导包含变量作为未知数的联合 PDF 函数吗？
此外，是否绝对有必要构建联合 PDF 来计算预期值，或者我可以通过计算每个点的概率、乘以相应的 xyz 值，然后对这些乘积求和，将其处理得类似于离散数据？
换句话说，以下方法对连续数据有效吗：

使用 kde 计算每个点的概率。
将每个点的概率乘以其相应的 xyz 值。
将这些乘积加到所有点上。

如果能提供任何建议或其他方法来计算此场景中的预期值，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/651249/expected-value-of-continuous-data-in-r</guid>
      <pubDate>Wed, 17 Jul 2024 01:26:24 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中的 IV 回归中获得 KP F-stat？</title>
      <link>https://stats.stackexchange.com/questions/651212/how-to-get-kp-f-stat-in-iv-regression-in-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651212/how-to-get-kp-f-stat-in-iv-regression-in-r</guid>
      <pubDate>Tue, 16 Jul 2024 13:50:03 GMT</pubDate>
    </item>
    <item>
      <title>具有累积距离的 GLMM</title>
      <link>https://stats.stackexchange.com/questions/651174/glmm-with-cumulative-distances</link>
      <description><![CDATA[我计算了每个人累计的行进距离。目的是使用 R 包 ggplot2 将数据以趋势曲线的形式表示出来。但是，数据太过分散，导致趋势线不准确，有时还会下降。我想知道检查是否可以使用广义线性混合效应模型 (GLMM) 或模型来表示男女之间的差异并对其进行测试是否有用。
以下数据框代表了所讨论的数据：
library(ggplot2)

num_ids &lt;- 30

generate_data_for_id &lt;- function(id) {
num_observations &lt;- sample(1:20, 1)
distances &lt;- runif(num_observations, min = 1, max = 5) 
cumual_distances &lt;- cumsum(distances)
time_since_release &lt;- seq_len(num_observations) - 1
sex &lt;- sample(c(&quot;female&quot;, &quot;male&quot;), 1) 

data.frame(
ID = rep(id, num_observations), 
Distance = distances,
Cumulative_Distances_km =cumulative_distances,
Time_Since_Release = time_since_release,
Sex = rep(sex, num_observations)
)
}

all_data &lt;- do.call(rbind, lapply(1:num_ids, generate_data_for_id))

all_data_female &lt;- subset(all_data, all_data$Sex==&quot;female&quot;)
all_data_male &lt;- subset(all_data, all_data$Sex==&quot;male&quot;)

这是我表示数据的方式
female_dist_max &lt;- ggplot() +
geom_line(data = all_data_female, aes(x = Time_Since_Release, 
y = Cumulative_Distances_km, color = as.factor(ID)), 
size = 0.4, linetype=&quot;dashed&quot;, alpha=0.5) +
geom_smooth(data = all_data_female, aes(x = Time_Since_Release, 
y = Cumulative_Distances_km, group = 1), method = &quot;loess&quot;, 
color = &quot;#f8766dff&quot;, size = 0.7, se = TRUE, span = 1) + 
labs(x = &quot;Time_since_release (days)&quot;, 
y = &quot;Cumulative distance (km)&quot;, color = &quot;ID&quot;) +
theme_minimal() 
print(female_dist_max)

male_dist_max &lt;- ggplot() +
geom_line(data = all_data_male, aes(x = Time_Since_Release, 
y = Cumulative_Distances_km, color = as.factor(ID)), size = 0.4, 
linetype=&quot;dashed&quot;, alpha=0.5) +
geom_smooth(data = all_data_male, aes(x = Time_Since_Release, 
y = Cumulative_Distances_km, group = 1), method = &quot;loess&quot;, 
color = &quot;#f8766dff&quot;, size = 0.7, se = TRUE, span = 1) +
labs(x = &quot;Time_since_release (days)&quot;, 
y = &quot;累计距离（公里）&quot;, color = &quot;ID&quot;) +
theme_minimal() 

print(male_dist_max)

我想要另一种方法来表示这些距离并测试男性和女性之间的差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/651174/glmm-with-cumulative-distances</guid>
      <pubDate>Tue, 16 Jul 2024 09:54:25 GMT</pubDate>
    </item>
    </channel>
</rss>