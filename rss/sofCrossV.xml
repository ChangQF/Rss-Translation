<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 08 Jun 2024 01:03:34 GMT</lastBuildDate>
    <item>
      <title>尽管 Resnet50 的测试和训练准确率很高，但 F1 分数却很低</title>
      <link>https://stats.stackexchange.com/questions/648855/resnet50-low-f1-score-despite-high-testing-and-training-accuracy</link>
      <description><![CDATA[我目前正在使用 Resnet50 在 Amazon Berkley Objects 数据集上进行图像分类，我一直面临 F1 分数低的问题，我确保训练和测试样本中的类别相等（总共约 50k 张图像），尽管它不会超过 10%（我知道图像显示的是第 7 个 epoche，但我不会让步直到运行结束），有什么建议吗？
预处理步骤主要是过滤、数据增强、重新缩放、基本数据准备，数据分为 80 20。]]></description>
      <guid>https://stats.stackexchange.com/questions/648855/resnet50-low-f1-score-despite-high-testing-and-training-accuracy</guid>
      <pubDate>Sat, 08 Jun 2024 00:43:40 GMT</pubDate>
    </item>
    <item>
      <title>适合 MLP 和 LSTM 的分布</title>
      <link>https://stats.stackexchange.com/questions/648854/appropriate-distribution-for-mlp-and-lstm</link>
      <description><![CDATA[我总共有 6300 个样本，其中 5800 个是训练数据，500 个是测试数据。我们在训练过程、预测精度和学习能力方面比较了 LSTM 和具有一个隐藏层的多层感知器 (MLP) 的性能。
在下图中，横坐标和纵坐标分别是迭代次数和 MSE 误差。它们的学习曲线如图所示。观察图，很明显 LSTM 的学习曲线比 MLP 的学习曲线衰减得更快。此外，LSTM 的收敛曲线比其他曲线更稳定。此外，LSTM 的损失 (RME 误差) 始终小于 MLP。LSTM 的 RMS 误差为 3.47998，MLP 为 5.02391。
我的问题是如何为 LSTM 和 MLP 找到/定义合适的分布？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/648854/appropriate-distribution-for-mlp-and-lstm</guid>
      <pubDate>Sat, 08 Jun 2024 00:37:30 GMT</pubDate>
    </item>
    <item>
      <title>使用二元结果的功率计算（使用 R 包和手动模拟）</title>
      <link>https://stats.stackexchange.com/questions/648852/power-calculation-with-a-binary-outcome-using-a-r-package-manual-simulation</link>
      <description><![CDATA[我试图在相同的设置下比较三种不同的功效计算方法。虽然我理解由于随机性，每种方法的功效估计不可能完全相同，但我预计它们会非常相似。然而，我观察到功效估计略有不同。
基本设置如下：

结果：二进制（成功 1；失败 0）
要比较的两组：G1 vs G2
G1：样本数 - 150；成功率为 0.2
G2：样本数 - 30；成功率为 0.4
显著性水平为 0.2（不是通常的 0.05）

也就是说，
p1 &lt;- 0.2
p2 &lt;- 0.4

n1 &lt;- 150
n2 &lt;- 30

我使用的三种方法是：

使用 pwr 包中的 pwr.2p2n.test 函数。
使用 prop.test 函数进行模拟。
使用 fisher.test 函数进行模拟

### -------------------------------- ###
### --- 版本 1：pwr.2p2n.test --- ###
### -------------------------------- ###
library(pwr)
pwr.2p2n.test(h = ES.h(p1 = p1, p2 = p2), 
n1 = n1, n2 = n2,
sig.level = 0.20,
alternative = &quot;less&quot;)

# power = 0.9145152

### ---------------------------- ###
### --- 版本 2：Prop 测试 --- ###
### ---------------------------- ###
nreps &lt;- 10000
y1 &lt;- rbinom(n = nreps, size = n1, p = p1)
y2 &lt;- rbinom(n = nreps, size = n2, p = p2)

pval &lt;- rep(NA, nreps)
for(i in 1:nreps) {
pval[i] &lt;- prop.test(c(y1[i], y2[i]), 
n= c(n1, n2), 
alternative = &quot;less&quot;,
p = NULL, correct = TRUE)$p.value
}

power &lt;- sum(pval &lt; 0.20) / nreps 
power # [1] 0.8756

### -------------------------------------- ###
### --- 版本 3：Fisher 精确检验 --- ###
### -------------------------------------- ###
pval.fin &lt;- c()
for(i in 1:nreps){
y1 &lt;- rbinom(n1, size = 1, p = p1)
y2 &lt;- rbinom(n2, size = 1, p = p2)
dat.comb &lt;- rbind(data.frame(res = y1, group = &quot;G1&quot;),
data.frame(res = y2, group = &quot;G2&quot;))
tab &lt;- table(dat.comb$group, dat.comb$res)
test.res &lt;- fisher.test(tab, alternative = &#39;less&#39;)
pval.fin[i] &lt;- test.res$p.value
}
mean(pval.fin&lt;0.2) # [1] 8e-04

我注意到了以下两点：

第三种方法使用 Fisher 精确检验，其幂为 8e-0.4。但是，如果我将“替代”选项从“less”更改为“greater”，幂将变为 0.8811，这与我们从第一种方法和第二种方法中获得的结果相似。但是第一种方法和第二种方法使用了“less”的“替代”选项……我不明白是什么导致了如此巨大的差异。

版本 1 和版本 2 的幂估计也有点偏差。我不太清楚是什么导致了这种差异。


有人能帮我理解为什么即使设置相同，我也没有获得类似的功率吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648852/power-calculation-with-a-binary-outcome-using-a-r-package-manual-simulation</guid>
      <pubDate>Fri, 07 Jun 2024 22:15:04 GMT</pubDate>
    </item>
    <item>
      <title>对于缺少很多天的时间序列，最好的输入选择是什么</title>
      <link>https://stats.stackexchange.com/questions/648849/what-are-the-best-options-for-imputing-time-series-that-is-missing-lots-of-days</link>
      <description><![CDATA[我有好几个月的温度数据，大约每十分钟记录一次。除非它有间隙。如果间隙为一小时左右，我可以线性插值，但如果间隙为几天，这显然行不通。
我目前所做的是取每日平均值，然后进行样条拟合以获得每天的平均值。我还从每天中减去平均值，以计算数据随时间变化的滚动平均值，按小时计算。然后，我可以用每小时滚动偏移量来填充缺失的天数，该偏移量由插值样条拟合所表示的平均值应为的值决定。
这有点用，但你可以看到我拼接的地方。例如，连接处的梯度不连续。我想我可以通过每天对总变化进行每日估计，然后将其插入间隙来改进，但是......
这肯定应该是机器学习的一个很棒的应用？我正在摆弄一些 scikit-learn 包，但它们似乎都希望在学习之前删除 NaN。
如能提供任何指点，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648849/what-are-the-best-options-for-imputing-time-series-that-is-missing-lots-of-days</guid>
      <pubDate>Fri, 07 Jun 2024 20:38:31 GMT</pubDate>
    </item>
    <item>
      <title>SVRG 与完全梯度下降</title>
      <link>https://stats.stackexchange.com/questions/648848/svrg-vs-full-gradient-descent</link>
      <description><![CDATA[随机梯度下降法让我们能够避免计算全梯度，但代价是引入收敛噪声底限。为了降低此噪声底限，SGD 需要减小步长，这会导致在强凸情况下失去线性收敛。 SVRG（随机方差降低梯度）允许我们返回这种线性收敛，但我看不出这在计算上比简单的全梯度下降有什么好处。
SVRG 在外循环的每次迭代中对完整梯度进行采样，然后执行形式为 $w_t = w_{t-1} - \eta \left(\nabla f_{i_t}(w_{t-1})-\nabla f_{i_t}(\hat{w}) + \nabla f(\hat{w})\right)$ 的内循环步骤，其中 $\hat{w}$ 是当前外循环值。我们的想法是利用梯度之间的正相关性来减少估计量中的方差。在强凸情况下，论文中的分析会选择这些内循环子步骤中的一个随机步骤作为我们的下一个外循环步骤。然后他们继续将其呈现为返回 GD 的线性收敛，但收敛程度取决于我们运行的外循环步骤数。这些外循环步骤中的每一个都在计算一个完整的梯度，那么这是否不是在进行完整的梯度下降加上这些内循环步骤的一些额外工作 - 所有这些都是为了实现与 GD 相同的收敛？]]></description>
      <guid>https://stats.stackexchange.com/questions/648848/svrg-vs-full-gradient-descent</guid>
      <pubDate>Fri, 07 Jun 2024 20:06:54 GMT</pubDate>
    </item>
    <item>
      <title>比较两个随着时间的推移而不平等的群体？</title>
      <link>https://stats.stackexchange.com/questions/648846/comparing-two-unequal-groups-over-time</link>
      <description><![CDATA[我对 rstudio 和统计学还不熟悉，所以请耐心等待。我试图比较两个不同变量随时间的变化，但它们来自非常不同的样本量。
我正在研究现场样本测量值和实验室样本测量值之间的差异。它们以不同的单位测量，但应该是相关的，因为它们本质上测量的是同一件事。
我有一个数据集“Probe”，其中测量了感兴趣的变量“value”。
这应该与我的其他数据集“Field”中的“value”变量相关。
哪种统计测试可以给我我想要的分析？我想看看“Field”值的峰值是否与“Probe”值的峰值相关，依此类推。我试图随着时间的推移跟踪它们是否显示出相似的趋势。我想做一些类似相关性的事情，但不能，因为“Probe”数据由 1606 个观测值组成，而“现场”数据由 197 个观测值组成，因此它们的长度不同，并且无法关联（据我迄今为止的研究所知）。]]></description>
      <guid>https://stats.stackexchange.com/questions/648846/comparing-two-unequal-groups-over-time</guid>
      <pubDate>Fri, 07 Jun 2024 19:59:43 GMT</pubDate>
    </item>
    <item>
      <title>寻找在线性回归中非线性组合特征的最佳方法</title>
      <link>https://stats.stackexchange.com/questions/648845/finding-the-best-way-for-combining-features-non-linearly-within-a-linear-regress</link>
      <description><![CDATA[问题陈述
我有一组两个特征，$X_1$ 和 $X_2$，我将它们组合起来尝试预测以下形式的回归中的目标变量：$ Y_0 = \frac{X_1 - X_2}{X_1 + X_2} $。您可以将其视为两者之间的插值，将差异标准化为所有数据点的$[-1, 1]$之间的差异。
$X_1, X_2$受到其他一些特征的非线性影响：$Z_1, Z_2$。
我正在尝试找到一种方法来改进原始回归$Y_0$，使用某个函数$f$，以便$Y_1 = \frac{f(X_1, Z_1) - f(X_2, Z_2)}{f(X_1, Z_1) + f(X_2, Z_2)} $改进$Y_0$。
我很清楚要从哪个类的函数开始。但我意识到，理想情况下，我希望针对我的具体问题调整我使用的任何函数。因此，如果我使用指数函数：$f(X_i, Z_i) = X_i * e^{Z_i} $，我希望找到最佳参数 lambda，其中 $f(X_i, Z_i, \lambda) = X_i * e^{\lambda * Z_i} $ 提供最佳拟合。 （$\lambda$ 是所有数据点的固定值）

具体示例
我认为用一个例子来说明会更容易。假设我们正试图通过进行许多平衡实验来预测跷跷板的倾斜角度。$Y=1$ 表示 $X_1$ 重（无限），跷跷板在那一侧接触地板。类似地，$Y=-1$ 表示 $X_2$ 重无限，跷跷板在相应的一侧接触地板。在理想情况下，这个目标变量恰好由两者的相对质量决定。这是之前的初始简单回归，$Y_0$。
但现在我们有一个未知的力作用在每个物体上：$Z_1$ 和 $Z_2$。我们有一个作用在每一侧的力的值，但我们不知道它如何准确地影响不平衡。把它想象成外星引力。下面是我所说的这一切的粗略图表，希望它能有所帮助。 
但现在我们有了这种奇怪的力量，我们想找到一种完美的建模方法。
实际数据不同，因此请在此示例中允许一些创造性想象力 :)

我的进度：
我尝试回归 $Y = \beta_1 X_1 + \beta_2 X_2 + \alpha$，按 $Z_1$ 和 $Z_2$ 的每个十分位数细分，然后绘制系数与十分位数的关系。我发现，随着 $Z_1$ 的增加，$X_1$ 的系数以指数方式增加，$X_2$ 和 $Z_2$ 的系数也以相同的方式（但为负）增加。因此，这表明我假设存在指数关系可能是正确的。

我的问题：
&quot;以指数方式&quot; 非常不切实际。我希望对这个建模过程有一个合理的方法。我需要找到最佳 lambda，并确认指数拟合是最佳选择。不太确定该怎么做。

我尝试过的方法
我尝试将指数曲线拟合到系数与十分位数图，这为 lambda 提供了一些值。但问题是，当我进行完全回归时，这种方法不起作用？只尝试一堆 lambda 值听起来也不对，感觉像是过度拟合。我这样做了，最佳 lambda 与我从另一种方法中获得的完全不同。所以我现在完全迷路了。

任何关于如何开始解决或查找此问题的指导都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/648845/finding-the-best-way-for-combining-features-non-linearly-within-a-linear-regress</guid>
      <pubDate>Fri, 07 Jun 2024 19:51:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的风险比系数在 Coxph 回归中这么大或这么小？</title>
      <link>https://stats.stackexchange.com/questions/648843/why-are-my-hazard-ratio-coefficients-so-large-or-small-in-coxph-regression</link>
      <description><![CDATA[我有一些我工作的机构中特定子群体的成绩数据，并将其与一段时间内的留校情况进行比较。下面的第一个表格是 R 中 coxph 回归的一些风险比，使用 D&amp;F GPA 学生作为比较组。这是一个通常会离开我们机构去另一所机构的子群体，所以我希望看到 A（学术货币）与离开与留下有关。
时间单位基于学分数量。

我的解释是，获得 A 的学生离开的可能性大约是平均成绩为 D 或 F 的学生的 15 倍。作为一项健全性检查，我想检查一下汇总的原始数据：

我很困惑，因为这个值比两组之间的比例要高得多。我是否应该进行更好的比较来计算“原始”数据？从汇总数据透视表值中得出风险比？
另一个示例是下面比较学生程序的输出（程序 3 是参考组）。

与原始数据相比，这里的比例似乎也不支持风险比。程序是分析中最具预测性的变量。

为了进一步参考，我附上了一份 Kaplan Maier 成绩生存图，该图似乎并未表明如此大的 coxph 系数。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648843/why-are-my-hazard-ratio-coefficients-so-large-or-small-in-coxph-regression</guid>
      <pubDate>Fri, 07 Jun 2024 19:36:29 GMT</pubDate>
    </item>
    <item>
      <title>对于采用和使用健康赤池信息准则 (hAIC) 有何见解？</title>
      <link>https://stats.stackexchange.com/questions/648841/any-insights-on-the-adoption-and-use-of-the-healthy-akaike-information-criterion</link>
      <description><![CDATA[最近，我偶然发现了 Demidenko 在其 2004 年出版的《混合模型：R 的理论与应用》一书中提出的健康赤池信息准则 (hAIC)。尽管它具有（潜在的）优势，但我在文献中发现的对它的引用却非常少。
一些背景知识：健康赤池信息准则 (hAIC) 由 Demidenko 开发，用于解决传统赤池信息准则 (AIC) 在解释变量之间存在高度多重共线性时的局限性。 AIC 的计算方法如下：
$$
AIC = −2\log(\text{max})+2k
$$
其中 $\log(\text{max})$ 是最大对数似然，$k$ 是参数数量，hAIC 通过合并惩罚项来修改此值，该惩罚项考虑了参数向量的长度，Demidenko 声称这使得 hAIC 在存在不适定问题和/或高度相关预测变量的场景中特别有用。
hAIC 公式为：
$$
HAIC = H + AIC
$$
其中
$$
H = k \left[ \log\left(\frac{\|\beta_{\text{ls}}\|^2}{k}\right) - 1 \right]
$$
这里，$\beta_{ls}$表示参数和范数的最小二乘估计，$\|\beta_{\text{ls}}\|$是参数向量的欧几里得长度：
$$
\|\beta_{\text{ls}}\| = \sqrt{\sum_{i=1}^k (\beta_{\text{ls},i})^2}
$$
这个惩罚项旨在惩罚具有较大参数估计的模型，这表明存在多重共线性。通过纳入参数向量的范数，hAIC 可确保对系数过大的模型进行惩罚，从而促进更稳定、更可靠的估计。过度的多重共线性可能导致不适定问题，即模型矩阵几乎是奇异的，从而导致参数估计值出现较大方差。额外的惩罚项有助于缓解这一问题，因为它倾向于使用参数估计值较小、更稳定的模型（到目前为止，我所读到的资料中还没有提到如何区分由于多重共线性而导致的较大参数估计值和真正较大的参数效应）。传统的 AIC 只考虑参数的数量，而不考虑它们的大小。另一方面，hAIC 整合了参数的数量和大小，旨在采用更全面的模型选择方法，考虑模型的整体稳定性和可靠性。
我发现的唯一已发表的研究是 Harezlak 等人 (2007) 的一篇题为“函数回归问题的惩罚解”的论文。在本研究中，hAIC 通过结合误差方差估计、自由度和基函数系数范数来增强模型稳定性和可解释性。
所以，我想知道这里是否有其他人使用过 hAIC，或者见过它被使用，甚至听说过它？如果有，你对它有什么想法和经验？如果没有，您对我在这里介绍的内容有什么看法？
为了增加背景信息，以下是我想到的 AIC、hAIC 和 BIC 的一些优缺点：
惩罚结构：

AIC：惩罚项为 $2k$，重点关注参数数量。
BIC：惩罚项为 $k\log(n)$，随着观察次数的增加而增加，并为其他参数提供更强的惩罚。
hAIC：惩罚项包括参数数量和参数向量的范数，还解决了参数估计的大小问题。

模型选择：

AIC：由于每个惩罚较低，通常会选择更复杂的模型参数。
BIC：由于惩罚力度较大，倾向于使用更简单的模型，尤其是样本量增加时。
hAIC：旨在平衡模型拟合度和复杂性之间的权衡，同时专门解决多重共线性和参数不稳定的问题。

应用场景：

AIC：适用于主要关注预测准确性且观测次数不是过多时的模型选择。
BIC：在认为真实模型在候选模型中且样本量较大的情况下是首选。
hAIC：在具有高多重共线性或不适定问题的场景中特别有用，在这些场景中，传统 AIC 可能无法提供稳定可靠的模型选择。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648841/any-insights-on-the-adoption-and-use-of-the-healthy-akaike-information-criterion</guid>
      <pubDate>Fri, 07 Jun 2024 18:34:18 GMT</pubDate>
    </item>
    <item>
      <title>用于实验推断的逻辑回归？</title>
      <link>https://stats.stackexchange.com/questions/648840/logistic-regression-for-experimental-inference</link>
      <description><![CDATA[我很好奇，当任务是推断治疗对比例的影响（例如：成功率）时，如果存在协变量，并且治疗组和对照组之间存在一些不平衡，那么逻辑回归是否合适。（换句话说，本质上是比例的 ANCOVA。）
我知道逻辑回归在对数几率空间中模拟线性趋势。并且这种线性关系通过 S 型函数传递，该函数将对数几率转换为概率。但是，与非线性变换相关的曲率量在 0.0 和 1.0 附近最大，在 0.5 附近最轻微。
当数据远离 50% 时，使用这种方法有什么问题吗？
为了增加假设背景，假设一个研究实验室正在尝试创建一种蛇毒治疗方法，如果不进行治疗，存活的概率为 5%。理想情况下，治疗效果会增加存活的概率。 （我没有这方面的背景，这也不是我的工作，所以我们不需要讨论蛇毒治疗的现实情况。）
是否有人担心，由于控制概率非常接近于零（因此 S 型函数对对数几率进行了大量“弯曲”），估计结果会​​不可靠？]]></description>
      <guid>https://stats.stackexchange.com/questions/648840/logistic-regression-for-experimental-inference</guid>
      <pubDate>Fri, 07 Jun 2024 17:57:52 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯法比尼·托内利</title>
      <link>https://stats.stackexchange.com/questions/648839/bayesian-fubini-tonelli</link>
      <description><![CDATA[我正在研究一个贝叶斯框架，其中我在函数$f\sim GP$上放置了一个高斯过程，并且有数据$D^n=\{(X_i,Z_i,W_i)\}^n$。
然后我得到了后验测量$\mu(f|D^n)$。后验均值估计量由 $\hat{f}=\int fd\mu(f|D^n)$ 给出。
我现在感兴趣的是找到另一个估计量的误差，我将其定义为：
\begin{align*}
\beta(x,z) &amp;=E_W[\hat{f}(x,z,W)]\\
&amp;=\int_\mathcal{W}\hat{f}(x,z,W)dP(W)\\
&amp;=\int_\mathcal{W}\int_\mathcal{F}f(x,z,W)d\mu(f|D^n)dP(W)
\end{align*&gt;
我现在想知道是否可以调用 Fubini Tonelli 来切换积分顺序 $\int_\mathcal{W}\int_\mathcal{F}f(x,z,W)d\mu(f|D^n)dP(W)=\int_\mathcal{F}\int_\mathcal{W}f(x,z,W)dP(W)d\mu(f|D^n)$.
我猜我的疑惑来自于我没有对整个数据分布$P(X,Z,W)$进行积分，并且测量$\mu$依赖于数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/648839/bayesian-fubini-tonelli</guid>
      <pubDate>Fri, 07 Jun 2024 16:33:20 GMT</pubDate>
    </item>
    <item>
      <title>李克特量表和样本量</title>
      <link>https://stats.stackexchange.com/questions/648828/likert-scale-and-sample-size</link>
      <description><![CDATA[我想研究母亲收到论文或网站信息的满意度。我至少会问 5 个问题，每个问题都使用李克特量表（5 分）。
样本量：

我是否应该使用调查的样本量公式进行计算（从 $y$ 中抽取 $x$ 名女性）？
我是否应该根据我预期的最重要的问题的李克特量表之间的差异来计算样本量？
我是否应该调整问题数量？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648828/likert-scale-and-sample-size</guid>
      <pubDate>Fri, 07 Jun 2024 14:57:59 GMT</pubDate>
    </item>
    <item>
      <title>估计样本的概率密度</title>
      <link>https://stats.stackexchange.com/questions/648819/estimating-probability-density-for-sample</link>
      <description><![CDATA[我有一个包含 20,000 多个样本的数据集。这里的目标是为样本定义一个分布，以便我可以绘制所有可能的结果。但是，我无法找到可用于估计概率密度的适当分布。我尝试使用正态分布、柯西分布、拉普拉斯分布、学生 T 分布和威布尔分布来测试样本。在所有情况下，Kolmogorov-Smirnov 检验都拒绝了我的样本遵循上述任何分布的可能性。我也尝试使用 KDE 进行估计，但结果并不理想。我尝试使用 KS 检验来检查 KDE 和我的样本之间的相似性，但即使在这里相似性也被拒绝了。我不知道下一步该怎么做才能估算出概率密度。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648819/estimating-probability-density-for-sample</guid>
      <pubDate>Fri, 07 Jun 2024 13:27:34 GMT</pubDate>
    </item>
    <item>
      <title>离散时间生存中的审查类型</title>
      <link>https://stats.stackexchange.com/questions/648701/type-of-censoring-in-discrete-time-survival</link>
      <description><![CDATA[*我有一个前瞻性纵向研究。在这项研究中，患者每三个月来医院检查一次。T0（手术前一周）、T3（手术后三个月）、T6（手术后六个月）、T9、T12、、、、、、T24（手术后 24 个月）。所以有 9 个时间点。
我们对预测性 Cox 回归感兴趣，其中包括二元时间相关协变量和连续自变量。在事件发生前退出、完成无事件随访（T24）或在研究结束时显示特定水平的时间相关协变量的病例是审查者。
*似乎在计数过程方法中，只有右审查者。并且为了使用离散时间生存，必须满足以下条件（如果我说得不对，请纠正我）

所有患者的时间间隔相同
时间点数量有限
区间审查*

1. 我不确定我的研究中的审查类型。如果研究中同时有右审查和区间审查，我们可以使用离散时间生存方法吗？
2. 如果研究允许患者在错过一个间隔点后重新加入试验（一个时间段内的所有观察数据都缺失），我想知道我们应该如何评估他们。当有缺失信息时，我们还能使用离散时间生存分析吗？例如，患者没有出席 T6 预约（手术后六个月），但他在 T9 时返回学习。
有关研究的更多信息
事件变量是疾病进展（是-否），主要协变量（时间相关变量-感兴趣的变量）是智力（是-否）。我们正在调查改变智力状态是否可以预测疾病的增加。]]></description>
      <guid>https://stats.stackexchange.com/questions/648701/type-of-censoring-in-discrete-time-survival</guid>
      <pubDate>Wed, 05 Jun 2024 19:03:51 GMT</pubDate>
    </item>
    <item>
      <title>计算 Cox-Snell Rsquared 的值</title>
      <link>https://stats.stackexchange.com/questions/648684/calculating-the-value-of-cox-snell-rsquared</link>
      <description><![CDATA[我想计算前瞻性纵向研究的最小样本量（使用 cox 回归 - 该项目的目的是进行预测）。可以使用 R 中 pmsampsize 包中的以下函数 pmsampsize 进行计算（基于以下出版物；开发具有连续、二元或生存（事件发生时间）结果的模型的最小样本量。Riley 等人（2018））。要运行以下函数，我们需要输入 csrsquared 的值，即新模型的 Cox-Snell Rsquared 值。
pmsampsize(type = &quot;s&quot;, csrsquared = , parameters = , rate = ,timepoint = , meanfup = )

如果在类似的研究中没有试验数据，也没有伪 R2 的报告值，那么如何定义 csrsquared 的值以使用此函数进行计算？
2. 假设伪 R2 的值可用，如何估计 Cox-Snell R 平方的值。。
我的模型中有一个二元时间相关协变量，只有 9 个时间点。因此，当 cox 模型包含时间相关协变量和离散生存时间时，我认为上述函数不可用于样本量计算。 但我仍然想知道在没有试验数据的情况下如何预测伪 R2，假设我们有连续的生存时间并且所有协变量都是时间独立的。
在我的研究中，患者每两个月来医院检查一次。T0（手术前一周）、T1（手术后两个月）、T2（手术后 4 个月）直至 T9（手术后 18 个月）。有一个二元时间相关协变量和一个连续独立变量。 在事件发生前退出、完成无事件随访（T9）的病例被审查。]]></description>
      <guid>https://stats.stackexchange.com/questions/648684/calculating-the-value-of-cox-snell-rsquared</guid>
      <pubDate>Wed, 05 Jun 2024 13:08:22 GMT</pubDate>
    </item>
    </channel>
</rss>