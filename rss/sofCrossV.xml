<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 04 Oct 2024 09:18:15 GMT</lastBuildDate>
    <item>
      <title>在自动编码器中使用批量标准化进行图像重建是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/655310/does-it-make-sense-to-use-batch-normalization-in-autoencoders-for-image-reconstr</link>
      <description><![CDATA[我正在开发用于图像重建的自动编码器，我想听听您对在这种架构中使用批量标准化 (BN) 的看法。

在专注于图像重建的自动编码器的编码器和解码器层中应用 BN 有什么优势？
就性能和重建质量而言，批量标准化是否会对结果产生负面影响，尤其是在需要最终输出具有高精度的任务中？我读到过，在某些情况下，标准化可能会导致重建过程中关键信息的丢失，因为激活被修改并可能改变原始图像的特征。
是否存在您建议使用或避免使用其的特定情况或配置？

提前感谢您就此主题分享的任何建议或经验。]]></description>
      <guid>https://stats.stackexchange.com/questions/655310/does-it-make-sense-to-use-batch-normalization-in-autoencoders-for-image-reconstr</guid>
      <pubDate>Fri, 04 Oct 2024 08:19:48 GMT</pubDate>
    </item>
    <item>
      <title>用标准差更高的方法对短期数据和长期总体进行假设检验 - 也就是如何测试苹果和橘子</title>
      <link>https://stats.stackexchange.com/questions/655307/hypothesis-testing-short-term-data-against-long-term-population-with-much-higher</link>
      <description><![CDATA[实际问题，尽可能笼统地讲
假设我有一个已知均值和标准差的高斯超种群。假设我知道这个超种群实际上是许多已知且标准差相等的子种群的卷积；但子种群均值的分布使得它们产生超种群均值和超种群标准差。这意味着我不知道任何随机抽取的子种群的均值的确切值。
假设我想测试我的治疗是否会改变相对于子种群的均值。我期望效果与超种群的标准差顺序一致。有办法做到这一点吗？如果是，我会使用什么方法？
这个问题的动机可能会帮助您回答它
我在制造部门工作，我们遇到了以下情况。
我们想测试某个参数（假设$Y$）是否会因某些新流程而得到改善。我们从经验中知道，我们的原材料存在相当大的批次间、供应商间甚至季节性变化。我们在$Y$的分布中看到了这一点，它具有相对较高的长期标准差$\sigma_{lt}$。我们还知道，我们的生产过程在进行实验所需的时间尺度上存在一些变化，但这种短期变化比长期变化小得多，假设为 $\sigma_{st} \ll \sigma_{lt}$。即使我们不进行任何实验，这也适用。
添加一个数值示例：假设我们的长期 $\mu_{lt} = 0$ 和 $\sigma_{lt} = 5$，并且我们有 $\sigma_{st} = 1$。我们进行测试，样本平均值为 $\overline{y_{test}}$，样本标准差为 $s_{test} \approx \sigma_{st}$。将 $\overline{y_{test}}$ 与 $\mu_{lt} = 0$ 进行比较很有吸引力，但那会是个错误。我们实际上是从未知的 $\mu_{st}$ 分布中抽样，其中 $\sigma_{st} = 1$。我们知道 $\mu_{st}$ 分布在 $\mu_{lt} = 0$ 附近，但我们不知道它的实际值。因此，将样本结果与长期人口估计值进行比较是苹果与橘子之间的比较。
有些解决方案是显而易见的，我们实际上会在可能的情况下使用这些解决方案：

理想情况下，我们执行配对测试，从生产线上取样，并测试每对测试样本结果和生产样本之间的差异。不幸的是，由于实际限制（主要与安全性和/或不存在的采样点有关），这通常是不可能的。即“苹果内”比较。
我们的后备方案是并行运行实验和参考生产，并执行双样本测试。我们将测试样本与参考人群样本进行比较，即进行适当的同类比较。

但是，我们也会遇到无法进行这种回退的情况。我们有一条单独的生产线，可以在没有参考生产运行的时候运行小型测试。如果我们预期并观察到很大的影响（$\gt 10\sigma_{lt}$），显然无需担心（也几乎不需要用复杂的统计工作来支持我们的结论）。我们的 I 类和 II 类风险不会完全准确，但实际影响并不特别重要。另一方面，随着预期的小效应越来越小，直到$\sigma_{lt}$的数量级，将越来越难以区分治疗效果与自然的长期变化。
哪些技术可用于检测上述情况下的微小变化？]]></description>
      <guid>https://stats.stackexchange.com/questions/655307/hypothesis-testing-short-term-data-against-long-term-population-with-much-higher</guid>
      <pubDate>Fri, 04 Oct 2024 06:30:26 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯定理适用于按特定顺序发生的事件</title>
      <link>https://stats.stackexchange.com/questions/655306/bayes-theorem-for-events-that-happen-in-a-particular-order</link>
      <description><![CDATA[我想了解如何使用贝叶斯定理来计算按特定顺序发生的事件的概率。我举个例子：假设我有一个梦想中的博士课程想进入（比如说，在 A 大学攻读统计学博士学位）。现在，我需要先攻读硕士学位，我收到了 B、C 和 D 三所大学的录取通知书。我想攻读硕士课程，这将最大限度地提高我进入 A 大学博士课程的机会。因此，设置以下事件：

B、C 和 D：就读 B/C/D 大学的理学硕士课程。
A：被 A 大学的博士课程录取。

因此，我想知道哪个条件概率最大。例如，$P(A|B)$。现在，为了做到这一点，我们可以使用贝叶斯定理。然而，让我困惑的是，$P(B|A)$ 是什么？事件 B 不依赖于事件 A，因为事件 A 不可能在 B、C 或 D 之一先发生的情况下发生。]]></description>
      <guid>https://stats.stackexchange.com/questions/655306/bayes-theorem-for-events-that-happen-in-a-particular-order</guid>
      <pubDate>Fri, 04 Oct 2024 05:42:17 GMT</pubDate>
    </item>
    <item>
      <title>在 2010 年代后期小程序流行之前，统计学家用什么来快速找到 p 值？</title>
      <link>https://stats.stackexchange.com/questions/655303/what-did-statisticians-use-to-quickly-find-p-values-before-applets-were-populari</link>
      <description><![CDATA[我是统计学专业的新生，今天我从教授那里得知，实际上，模拟样本重复的小程序直到 2010 年代末才出现，这让我非常惊讶，因为它们看起来很简单 - 就像已经存在一段时间的东西一样。在这些出现之前，用什么来快速找到 p 值？]]></description>
      <guid>https://stats.stackexchange.com/questions/655303/what-did-statisticians-use-to-quickly-find-p-values-before-applets-were-populari</guid>
      <pubDate>Fri, 04 Oct 2024 03:01:10 GMT</pubDate>
    </item>
    <item>
      <title>glmer 估计值为负，但应为正</title>
      <link>https://stats.stackexchange.com/questions/655300/glmer-estimate-is-negative-but-should-be-positive</link>
      <description><![CDATA[我正在为我的硕士论文研究寻找一个 glmer（论文完成之前我不能分享数据，所以我会尽量在描述中非常明确）。
但总结一下，我的因变量是一个二进制（exhaustbinary），其中 1 表示参与者做了这件事，0 表示参与者没有做这件事。
我的独立因素是年龄组（儿童或成人）和试验类型（对照或关键），其中有两个随机截距，分别是单个参与者（SubjectID）和单个试验（Item）。
查看代码：
agebytrialopt &lt;- glmer (ExhaustBinary ~ Agegroup * TrialType +(1|SubjectID)+(1|Item), data=df, family=&quot;binomial&quot;, control=glmerControl(optimizer=&quot;bobyqa&quot;, optCtrl=list(maxfun=100000)))

这一切都运行良好。
然而，在摘要和输出中，我得到了一些违反直觉的东西。
固定效应：
估计标准差。错误 z 值 Pr(&gt;|z|) 
(截距) 8.701 1.380 6.306 2.86e-10 ***
AgegroupChild -3.805 1.213 -3.137 0.0017 ** 
TrialTypeCritical -7.049 1.148 -6.140 8.23e-10 ***
AgegroupChild:TrialTypeCritical 6.493 1.201 5.409 6.35e-08 ***

基本上，当我们从儿童级别切换到成人级别时，与成人相比，儿童在排气二进制中更有可能获得 1 值。但是，根据 glmer 选择的名称，这应该意味着儿童与成人相比具有较低的“分数”。这与数据不符，他们的得分高于成年人。
与 TrialTypeCritical 相比，与对照组相比，关键试验在排气二进制中具有更多 0 值。因此，根据名称，关键试验应该比对照组具有较低的“分数”。这在直观上是真实/准确的，并且这里的负估计是有意义的。
我确实检查了因素中对比的虚拟代码，基本因素如下所示。
&gt; 对比（df$Agegroup）
儿童
成人 0
儿童 1

&gt;对比（df$TrialType）
严重
控制 0
严重 1

公平地说，我在过去 5 个小时里一直在研究这个问题，在开始手动设置对比之前，我想确保我正确地解释了这些估计值。
此外，由于我们确实有显著的相互作用，我已经进行了分解，并查看了 emmeans 等等，那里的一切都有意义，可以解释，我对那里的任何负/正翻转都没有问题。
任何关于我哪里出错的见解（无论是我对因素/水平和对数估计的理解，还是对比的工作原理，或者只是一般情况）都会有所帮助。
不过，为了清楚起见，glmer 是我们拥有的数据的最佳选择，我已经做了使用这种方法的所有理论论证，所以我不想回答关于为什么我选择使用glmer 或类似的东西。我只是需要帮助来了解 AgegroupChild 上的极性发生了什么。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655300/glmer-estimate-is-negative-but-should-be-positive</guid>
      <pubDate>Thu, 03 Oct 2024 22:55:02 GMT</pubDate>
    </item>
    <item>
      <title>Newey-West 标准误差的滞后长度</title>
      <link>https://stats.stackexchange.com/questions/655298/lag-length-for-newey-west-standard-errors</link>
      <description><![CDATA[我目前正在 Stata 上估计时间序列回归，但遇到了瓶颈。在调查自相关的残差时，我发现滞后 19 的残差之间存在显著的自相关性。检查偏自相关性时，我发现在滞后 19、32 和 34 处存在显著的滞后。由于我计划使用 Newey-West 标准误差来处理这个问题，因此我不确定在使用这些新误差估计回归时应该指定什么滞后。应该是 34 吗，因为这是存在任何类型的自相关和偏自相关的最远滞后？我不擅长这些东西，所以任何答案都将不胜感激！谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655298/lag-length-for-newey-west-standard-errors</guid>
      <pubDate>Thu, 03 Oct 2024 22:20:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么“无偏”估计量比最小误差估计量更重要？</title>
      <link>https://stats.stackexchange.com/questions/655296/why-is-unbiased-estimator-more-important-than-min-error-estimator</link>
      <description><![CDATA[根据 Edwin Jaynes（其著作《概率论：科学的逻辑》第 17 章）的说法，估计量的均方误差由偏差项和方差项组成，即：
$$L =E[(\beta - \alpha)^2]=E[(E[\beta] - \alpha)^2]+(E[\beta^2] - E[\beta]^2)$$
其中 $\beta$ 是数量 $\alpha$ 的估计量。
对于“无偏”估计量，我们的目标是最小化第一项$E[(E[\beta] - \alpha)^2]$，然而，这通常不会导致总误差$L$最小化。Jaynes 建议最好使用估计量$\beta$来最小化$L$，这样我们就可以充分利用有限的可用数据。
鉴于这种推理，我有点困惑，为什么我们首先想要得到“无偏”估计量而不是最小误差估计量，有人可以分享你的意见吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655296/why-is-unbiased-estimator-more-important-than-min-error-estimator</guid>
      <pubDate>Thu, 03 Oct 2024 22:14:49 GMT</pubDate>
    </item>
    <item>
      <title>非重叠、非堆叠面积图或非分支、非恒定数量流程图</title>
      <link>https://stats.stackexchange.com/questions/655295/non-overlapping-non-stacked-area-plots-or-non-branching-non-constant-quantity</link>
      <description><![CDATA[考虑对少量时间点和大量系列的数据进行可视化，在这种情况下：
day | a | b | c | d | e | f
0 | 2 | 4 | 2 | 0 | 1 | 3
90 | 4 | 2 | 3 | 1 | 0 | 1
180 | 4 | 2 | 2 | 4 | 2 | 2

由于集合的大小，条形图和折线图效果不佳，按时间点分组不能轻松地跨系列进行比较，反之亦然。堆积面积图和堆积柱形图是自然契合的，可以比较两者，但是在 X 轴点数较少（在本例中为 3）并且数据点接近零时，两者都会失真：

可以计算“填充”数据以水平对齐系列：
 日 | | a | | b | | c | | d | | e | | f
中点 | | 2 | | 7 | | 11.5 | | 16 | | 20 | | 23.5
0 | 1 | 2 | 2 | 4 | 1.5 | 2 | 3.5 | 3.5  0 | 3.5 | 3.5  1 | 1.5 | 1.5  3 90 |  0 |  4 |  2 |  2 | 2 |  3 | 2.5 | 2.5  1 | 3.5 | 3.5  0 | 3 |  1 180 |  0 |  4 |  2 |  2 | 2.5 | 2.5  2 | 1.5 | 1.5  4 | 1 |  2 | 1.5 | 1.5  2

这提高了清晰度：

并且可以通过添加沿 X 轴的间距坐标来进一步改进面积图：
 day | | a | | b | | c | | d | | e | | f
中点 | | 2 | | 7 | | 11.5 | | 16 | | 20 | | 23.5
0 | 1 | 2 | 2 | 4 | 1.5 | 2 | 3.5 | 0 | 3.5 | 1 | 1.5 | 3
10 | 1 | 2 |  2 |  4 | 1.5 | 1.5  2 | 3.5 | 3.5  0 | 3.5 | 3.5  1 | 1.5 | 1.5  3 80 |  0 |  4 |  2 |  2 | 2 |  3 | 2.5 | 2.5  1 | 3.5 | 3.5  0 | 3 |  1 100 | 1 100  0 |  4 |  2 |  2 | 2 |  3 | 2.5 | 2.5  1 | 3.5 | 3.5  0 | 3 |  1 170 |  0 |  4 |  2 |  2 | 2.5 | 2.5  2 | 1.5 | 1.5  4 | 1 |  2 | 1.5 | 1.5  2 180 |  0 |  4 |  2 |  2 | 2.5 | 2.5  2 | 1.5 | 1.5  4 | 1 |  2 | 1.5 | 1.5  2


最后一个开始类似于流程图，例如桑基图或平行集图，尽管它没有输入和输出流，只是幅度变化。它也类似于小提琴图，尽管数据与 x 轴时间点相关，宽度不是概率分布。它只是一个平行面积图 - 不堆叠，不重叠，也不受 100% 约束。
这个平行面积图有名字吗？
除了手动计算填充数据然后将其隐藏在视图之外，R 或 Python（ggplot2 或其他）中是否有此平行面积图的可视化方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655295/non-overlapping-non-stacked-area-plots-or-non-branching-non-constant-quantity</guid>
      <pubDate>Thu, 03 Oct 2024 21:59:23 GMT</pubDate>
    </item>
    <item>
      <title>统一采用政策，不错开[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655294/uniform-policy-adoption-and-not-staggered</link>
      <description><![CDATA[我有两个问题。

在政策变化是即时的而不是交错的的情况下，用什么术语来描述政策变化的情况？

分析此类数据时，哪些统计方法合适？常用的统计方法来分析此类数据。


谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655294/uniform-policy-adoption-and-not-staggered</guid>
      <pubDate>Thu, 03 Oct 2024 21:54:57 GMT</pubDate>
    </item>
    <item>
      <title>我有一份医疗保健优先事项的排序列表，该列表是我通过对两个不同国家的医生进行的调查来评估的</title>
      <link>https://stats.stackexchange.com/questions/655290/i-have-a-rank-order-list-of-healthcare-priorities-which-i-assessed-using-a-surve</link>
      <description><![CDATA[我使用调查来评估两个不同国家/地区的医疗保健提供者之间某些医疗保健优先事项的排名顺序。我使用标准独立样本 t 检验测试了归因于每个优先事项的排名值，但我试图查看优先事项的顺序是否不同。
只是显示顺序（从 1 到 6）是否足够不同，或者是否有测试可以用来显示顺序不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/655290/i-have-a-rank-order-list-of-healthcare-priorities-which-i-assessed-using-a-surve</guid>
      <pubDate>Thu, 03 Oct 2024 20:15:42 GMT</pubDate>
    </item>
    <item>
      <title>两个大型二进制数组之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/655279/correlation-between-two-large-binary-arrays</link>
      <description><![CDATA[假设我有两个由 0 和 1 组成的大型数组，精确定位：
$$
X=\text{错误率高的位置}\\
Y=\text{数据较差的位置}
$$
用于检查 $X$ 和 $Y$ 是否相关的最佳统计测试是什么？卡方或 phi 系数是否合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/655279/correlation-between-two-large-binary-arrays</guid>
      <pubDate>Thu, 03 Oct 2024 17:15:55 GMT</pubDate>
    </item>
    <item>
      <title>纵向分析结果中与基线的对数转换比率</title>
      <link>https://stats.stackexchange.com/questions/655273/log-transformed-ratio-to-baseline-as-an-outcome-in-longitudinal-analyses</link>
      <description><![CDATA[我必须分析变量 Y 的纵向数据（8 次访问），在文献中，大多数类似研究都对 Y&#39;=log(Y/Ybl) 进行建模，其中 Ybl 是 Y 的基线值，以获得不同组中不同时间的基线百分比变化估计值。
基线的 Y&#39; 始终等于 0，因此我从分析中排除了基线数据。但是，在这种情况下，截距和随机截距涉及第 2 周的访问，这是基线后的第一次访问。在我看来，这没有意义。
将对数转换后的比率建模为基线是一个好主意吗？
在这种情况下，我该怎么做才能有效且一致地编写模型？
（我正在使用 R）
以下是一些附加信息（感谢您的评论）：
模型为 Y&#39; = log(Ybl) + 治疗 + 访问 + 访问 * 治疗

对个人的随机影响（相关出版物中不再有精度）

使用此配置，模型无法收敛到我的数据。如前所述，根据定义，对于所有患者，Y&#39; = 0。]]></description>
      <guid>https://stats.stackexchange.com/questions/655273/log-transformed-ratio-to-baseline-as-an-outcome-in-longitudinal-analyses</guid>
      <pubDate>Thu, 03 Oct 2024 10:29:11 GMT</pubDate>
    </item>
    <item>
      <title>线性回归：因变量是两个自变量的乘积</title>
      <link>https://stats.stackexchange.com/questions/655257/linear-regression-dependent-variable-is-the-multiplication-of-two-independent-v</link>
      <description><![CDATA[如果$y= x_1\times x_2, $我们有什么方法可以进行线性回归吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655257/linear-regression-dependent-variable-is-the-multiplication-of-two-independent-v</guid>
      <pubDate>Thu, 03 Oct 2024 10:28:08 GMT</pubDate>
    </item>
    <item>
      <title>与统计模型对比的正确代数符号</title>
      <link>https://stats.stackexchange.com/questions/655305/correct-algebraic-notation-for-contrasts-from-statistical-model</link>
      <description><![CDATA[在事前事后研究中，我们可以使用线性混合模型将治疗效果估计为时间 x 治疗相互作用的系数，请参见此处（第 19.3 节）：
https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/models-for-longitudinal-experiments-pre-post-designs.html
假设我们使用回归样条将此模型扩展到几个后续时期和模型时间。这些系数将无法解释，但我们可以计算每次后续测量时的一系列条件/边际对比，以估计治疗效果，即预测值之间的差异。我正在考虑使用后估计工具（例如 R 中的包 emmeans、marginaleffects、rms 等）可以获得的对比类型。但是，我不知道如何正确地用代数方式写出这样的对比。我的尝试附在下面的图片中（抱歉，我无法弄清楚如何直接在此网站上书写）。

其中 I 是干预效果，y 是响应变量，x 是预测变量，t 是一系列随访时间，t0 是基线时间，T 是治疗组，C 是对照组。
如果有人能帮我用代数符号纠正/正确地写出这个，我将不胜感激，因为假设正态分布误差的线性模型存在对比。以及这如何推广到具有对数链接的泊松模型。在这种情况下，差异中的差异变成了响应尺度上的比率，但我再次不确定如何使用代数符号正确地写出它。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655305/correct-algebraic-notation-for-contrasts-from-statistical-model</guid>
      <pubDate>Wed, 02 Oct 2024 06:53:23 GMT</pubDate>
    </item>
    <item>
      <title>零膨胀泊松/负二项分布的功率分析</title>
      <link>https://stats.stackexchange.com/questions/655177/power-analysis-for-zero-inflated-poisson-negative-binomial</link>
      <description><![CDATA[我想进行一些功效分析来帮助规划实验。
具体来说，实验旨在测试一种处理方法是否能减少植物病原体的数量。实验设置是不同的地点，每个地点都包含“处理”和“控制”象限。
从以前的实验中，我知道我的响应变量（病原体数量）可以使用负二项式和/或零膨胀泊松分布进行建模。
我有两个问题，一个是实际问题，一个是理论问题：

我找到了一些关于零膨胀泊松分布功效分析的学术论文，但我找不到可以实现这些的 R 包。任何指针都值得赞赏！
在我的实验中，病原体可以不存在，因此是 ZIP 分布。但是，由于实地工作在资源（金钱/时间）上成本高昂，我希望能够判断一个地点是否值得采样。显然，如果没有病原体，该网站就不具有信息量。我的理解是，低病原体压力（病原体数量）比高病原体压力“信息量更少”。是否可以定义病原体压力的阈值，或者这肯定会违反统计上合理的采样方案？如果没有，这与功效分析有何关系？

提前感谢您的任何指示！]]></description>
      <guid>https://stats.stackexchange.com/questions/655177/power-analysis-for-zero-inflated-poisson-negative-binomial</guid>
      <pubDate>Tue, 01 Oct 2024 15:48:46 GMT</pubDate>
    </item>
    </channel>
</rss>