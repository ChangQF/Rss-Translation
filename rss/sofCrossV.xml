<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 11 Apr 2024 21:13:24 GMT</lastBuildDate>
    <item>
      <title>马尔可夫决策过程和消息传递</title>
      <link>https://stats.stackexchange.com/questions/644835/markov-decision-process-and-message-passing</link>
      <description><![CDATA[我正在读《贝叶斯推理与机器学习》这本书。我正在阅读第 7.5 章有关马尔可夫决策过程的内容。我来自最佳停止/最佳控制背景，熟悉贝尔曼原理等。本质上，这个想法是从最后开始并向后工作。
令我困惑的是，Bellamn 原理（向后步进）的应用是用消息传递来解释的，其中消息是状态的价值函数。
这样表达有什么特殊原因吗？我觉得我一定没有抓住要点。]]></description>
      <guid>https://stats.stackexchange.com/questions/644835/markov-decision-process-and-message-passing</guid>
      <pubDate>Thu, 11 Apr 2024 20:58:20 GMT</pubDate>
    </item>
    <item>
      <title>使用变量公式的变化计算后验</title>
      <link>https://stats.stackexchange.com/questions/644834/compute-posterior-using-change-of-variable-formula</link>
      <description><![CDATA[给定一个从单位圆盘到 $\mathbb R^2$ 的双射 f，$w \sim N( 0、\gamma^2 I)$ 和 $y = f^{-1}(f(x) + w)$，如何显示那
$$ \pi(y | x) = |\det Df(y)| \pi_w(f(x) - f(y))。 $$
我知道 $y = f(x)$ 的变量变化是 $\pi(y) = \pi( f^{-1}(y)) |\det Df^{-1}(y)|$，但这仅适用于 $\pi(y) $ 而不是 $\pi(y|x)$，那么我该如何使用它呢？
编辑更多详细信息：$f(x) = \frac{x}{1- ||x||^2}$。给定单位圆盘中的$x$，计算$f(x)$并随机抽取$w$ 来自正态分布，则 $y = f^{-1}(f(x) + w)$。我需要证明后验分布 $\pi(y | x)$ 如上]]></description>
      <guid>https://stats.stackexchange.com/questions/644834/compute-posterior-using-change-of-variable-formula</guid>
      <pubDate>Thu, 11 Apr 2024 20:23:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 PROC PHREG 的边际结构模型</title>
      <link>https://stats.stackexchange.com/questions/644833/marginal-structural-model-using-proc-phreg</link>
      <description><![CDATA[我想拟合一个边际结构模型来解释随访期间的治疗转换。
我发现了一篇关于如何在 R 中执行此操作的精彩论文：https: //www.sciencedirect.com/science/article/abs/pii/S0010482519302082
但是，当然，我正在从事临床试验并使用 SAS。
2000 年，Hernan、Brumback 和 Robins 提供了在 SAS 中构建 MSM 的代码：
https://journals.lww.com/epidem/fulltext/ 2000/09000/marginal_structural_models_to_estimate_the_causal.12.aspx
由于PROC PHREG不支持时间更新权重，因此使用合并逻辑回归来获得边际风险比。
现在是 2024 年，而不是 2000 年，我想知道时间更新的权重现在是否可以合并到 PROC PHREG 中，或者合并逻辑回归仍然是事实上的 MSM 拟合方法？或者，是否有众所周知的宏可以用来适应这个模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/644833/marginal-structural-model-using-proc-phreg</guid>
      <pubDate>Thu, 11 Apr 2024 20:00:26 GMT</pubDate>
    </item>
    <item>
      <title>通过具有时空相关性的二元测量的重复横截面调查进行区域层面的预测</title>
      <link>https://stats.stackexchange.com/questions/644832/forecasting-at-areal-level-from-repeated-cross-sectional-survey-with-binary-meas</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644832/forecasting-at-areal-level-from-repeated-cross-sectional-survey-with-binary-meas</guid>
      <pubDate>Thu, 11 Apr 2024 19:28:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Hotellings T 方统计量按 n 倍缩放？</title>
      <link>https://stats.stackexchange.com/questions/644831/why-does-the-hotellings-t-squared-statistic-scale-by-a-factor-of-n</link>
      <description><![CDATA[根据 NIST：https://www. itl.nist.gov/div898/handbook/pmc/section5/pmc543.htm T 方统计量的方程的比例因子为 n（有趣的是，维基百科页面引用了此页面，但省略了n 比例因子）。
我想知道为什么要包含这个比例因子？这背后有什么直觉吗？
这是否意味着随着样本数量的增加，正在测试的相同样本的可能性会导致我们拒绝零假设的可能性增加？
我想象 2-D 多元正态数据作为样本，可能 n=100 和 n=1000（从相同的真实分布中采样）。这些将具有（接近）相同的样本均值和方差，但由于此 n 因素，此分布中的新样本不符合零假设的可能性会随着 n 的增加而增加？
当然，随着 n 的增加，与 F 分布（我们用来检查的）的关系会发生变化，但变化幅度不大。对于 p=2，T^2 (n-p)/(pn-p) 的缩放比例为 98/198 ~ 1/2（n=100）和 998/1998 ~ 1/2（n=1000），并且 F 临界值对于 alpha=0.05 来说，两者都约为 3，因此它们的影响很小。]]></description>
      <guid>https://stats.stackexchange.com/questions/644831/why-does-the-hotellings-t-squared-statistic-scale-by-a-factor-of-n</guid>
      <pubDate>Thu, 11 Apr 2024 19:13:50 GMT</pubDate>
    </item>
    <item>
      <title>具有大量预测变量的逻辑回归/一般理解</title>
      <link>https://stats.stackexchange.com/questions/644828/logistic-regression-with-a-lot-of-predictors-general-understanding</link>
      <description><![CDATA[我目前正计划写我的学士论文，但距离上一次统计研讨会已经有一段时间了，我已经非常生疏了，所以这里的任何指导将不胜感激。
我的样本规模相对较小，n=40，其中 20 名参与者均患有学习障碍，20 名参与者没有作为对照。每个参与者完成三项不同的任务，从中生成大量数据点。
我的数据的简单示例：

&lt;标题&gt;

参与者
疾病
任务
Var1
Var2
Var3
...
Var38


&lt;正文&gt;

1
0
1
.67555
.5353
.4456
.2345
.3812


1
0
2
.5514
.7753
.2239
.3567
.2234


1
0
3
.4563
.6675
.3345
.5681
.5234


...









40
1
2
.8898
.7798
.7887
.9989
.5662


40
1
3
.7854
.8334
.7687
.7878
.6534



我的计划是为每项任务建立一个具有二分 DV（疾病/非疾病）的逻辑回归模型，问题是其中一个模型是否可以比另一个更好地分离 DV，以及生成的数据点是哪个是这项任务中最好的预测因子。经过简短的研究后，人们应该更好地预测 DV，因为它是测量 DV 的现场标准，但我“在方法上不安全”。该怎么做。
我的第一个问题是：

这种方法是否可行，是否可以直接比较任务（例如 AUC、RMSE 和 r2 等拟合指数）？

其次，由于我使用的分析技术会产生许多可能的预测变量 (38)，因此我试图减少这些预测变量以避免过度拟合。我听说过有关 LASSO 的好消息，但由于许可原因我一直在使用 SPSS。由于单变量和逐步技术似乎不建议使用，这将是一种将它们降低到更易于管理的水平的明智方法。
对于宽泛的问题和稀疏的理解，我深表歉意，很长一段时间以来，我一直在努力忘记我学到的一切。]]></description>
      <guid>https://stats.stackexchange.com/questions/644828/logistic-regression-with-a-lot-of-predictors-general-understanding</guid>
      <pubDate>Thu, 11 Apr 2024 18:41:02 GMT</pubDate>
    </item>
    <item>
      <title>对于模型调整参数不稳定我该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/644826/what-can-i-do-about-model-tuning-parameter-instability</link>
      <description><![CDATA[我正在尝试确定流域特征对几条河流浓度-流量关系斜率的重要性。由于分水岭特征之间存在多重共线性，我使用偏最小二乘回归 (plsr)。拟合 plsr 模型后，我将使用投影上的变量重要性对分水岭特征进行排序，以解释响应变量。
我的第一步是使用 caret::train 确定 plsr 的理想组件数量。然而，组件的数量根据种子和交叉验证方法的不同而有很大差异。 此处是我的数据的链接，我的代码如下。请注意，第 1 列 term 是响应变量，其余列是预测变量。
库（插入符号）
图书馆（tidyverse）

# 加载数据

加载（&#39;Processed_Data/df1.Rdata&#39;）

# 设置不同的 CV 方法：

trC.cv &lt;- trainControl(method = &quot;cv&quot;, number = 10)
trC.repeatedcv &lt;- trainControl(方法 = &quot;repeatedcv&quot;, 数量 = 10, 重复 = 10)
trC.LGOCV &lt;- trainControl(方法 = “LGOCV”, p = 0.8)
trC.boot &lt;- trainControl(method = &quot;boot&quot;)
trC.LOOCV &lt;- trainControl(method = &quot;LOOCV&quot;)

# 将 CV 方法合并到列表中：

l.trCon &lt;- 列表(trC.boot, trC.cv, trC.repeatedcv, trC.LGOCV, trC.LOOCV)
名称(l.trCon) &lt;- c(“trC.boot”、“trC.cv”、“trC.repeatedcv”、“trC.LGOCV”、“trC.LOOCV”)

# 比较不同种子/CV 方法中的 ncomp 的函数：

fun.compare.plsr.models &lt;- 函数（df，种子）{
  df.i &lt;- data.frame(seed = NA, CV.method = NA, ncomp = NA) # 对于每个 i 循环，将 df 初始化为 cbind：
  for (i in seq_along(seeds)){ # 循环遍历种子：
    v.CV.method &lt;- NA # 为每个 j 循环初始化 Cv 方法和 ncomp 的向量：
    v.ncomp &lt;- NA
    for(j in seq_along(l.trCon)){ # 循环 CV 方法：
      set.seed(i) # 设置种子：
      model.j &lt;- train(term ~., data = df, # 使用 j 循环对应的 CV 方法构建模型：
                       方法=&#39;请&#39;，
                       规模=真，
                       trControl = l.trCon[[j]],
                       tuneGrid = data.frame(ncomp = c(1:30)))
      v.CV.method[j] &lt;- names(l.trCon)[j] # 设置 j 循环的向量元素：
      v.ncomp[j] &lt;- model.j$bestTune[1,1]
    }
    df.j &lt;- data.frame(seed = i, CV.method = v.CV.method, ncomp = v.ncomp) # 使用 j 循环的结果向量创建 df：
    df.i &lt;- rbind(df.i, df.j) # cbind j 循环 df 到整体 df:
  }
  df.i &lt;- df.i[-1,] # 删除第一行，因为它不适用：
  返回（df.i）
}

# run 函数（运行需要一分钟）：

system.time(df.compare10 &lt;- fun.compare.plsr.models(df = df1, seeds = 1:10)) # 95 秒

# 看结果：

ggplot(df.compare10, aes(x = 种子, y = ncomp, 颜色 = CV.method)) +
  几何线（）

除了这篇文章，我无法找到与“模型调整参数不稳定”相关的在线资源（同样在那篇文章中，他们没有提供不稳定的示例，我相信我在这里看到了）。
我看到参数不稳定是什么意思？我能做些什么来解决这个问题吗？
我已经研究过 PCA 来识别异常值观测值，但我对于是否丢弃数据犹豫不决。
我唯一的另一个想法是响应变量和预测变量之间的关系并不存在于 plsr 模型的框架中。也许我应该尝试另一个模型？我是 caret 和交叉验证的新手，所以请原谅这篇文章的多个问题/含糊之处。我确实尝试在网络上搜索这方面的帮助，但我没有找到任何与我的类似的示例。
非常感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/644826/what-can-i-do-about-model-tuning-parameter-instability</guid>
      <pubDate>Thu, 11 Apr 2024 18:29:24 GMT</pubDate>
    </item>
    <item>
      <title>导出新实验的 F 统计量</title>
      <link>https://stats.stackexchange.com/questions/644825/deriving-the-f-statistic-for-a-new-experiment</link>
      <description><![CDATA[我正在解决一个家庭作业问题，我得到了以下信息：

使用此信息，我能够复制 ANOVA 表：
#从 EXAM II 创建数据帧
分数 &lt;- c(7,8,6,7,8,9,4,5,8,8,7,7,5,7,2,4,5,6,3,4,9,10, 7,9,5,7,1,4,4,6,5,5)

plant.type&lt;-c(“WT”、“WT”、“MU”、“MU”、“WT”、“WT”、“MU”、“MU”、” WT”、“WT”、“MU”、“MU”、“WT”、“WT”、“MU”、“MU”、“WT”、“WT”、“ MU”、“MU”、“WT”、“WT”、“MU”、“MU”、“WT”、“WT”、“MU”、“MU”、“ WT”、“WT”、“MU”、“MU”)

锅 &lt;-c(1,1,2,2,1,1,2,2,1,1,2,2,1,1,2,2,1,1,2,2,1,1, 2,2,1,1,2,2,1,1,2,2)

托盘 &lt;- c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,6,6, 6,6,7,7,7,7,8,8,8,8)

农药&lt;-c(“H”、“H”、“H”、“H”、“L”、“L”、“L”、“L”、“H”； 、“H”、“H”、“H”、“L”、“L”、“L”、“L”、“L”、“L”、“L”等。 、“L”、“H”、“H”、“H”、“H”、“L”、“L”、“L”、“L”、“H” 、“H”、“H”、“H”）

full.df &lt;- data.frame(plant.type = as.factor(plant.type),
                      分数=分数，
                      锅=as.因子(锅),
                      托盘=as.factor(托盘),
                      农药=as.factor(农药))

anova(model1 &lt;- lm(score~农药+托盘+植物.类型+农药:植物.类型+托盘:植物.类型, data=full.df)

对于一个问题，我们需要计算 ${\overline{\mu_{l}}= \frac{(\mu_{WTl} + \mu_ {MUl})}{2}}$ 其中 $l = L, H$。我们测试 $H_0: \overline{\mu_{.l}} = \overline{\mu_{.H}}$。
我对如何计算 F-stat 有点困惑，因为之前我们的响应只是作为预测变量函数的平均得分，但现在它是“l”以下的平均得分。
我尝试通过使用线性模型找到作为植物类型和农药函数的平均得分来获得 F 检验统计量来解决该问题。因为我们本质上是比较不同两种不同农药水平下植物类型之间的变异性。：
grp.df &lt;- full.df %&gt;% select(植物类型, 农药, 分数)

model2 &lt;- lm(score ~ plant.type + 农药,data=grp.df)

摘要（模型2）

但是，我不确定我的做法是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/644825/deriving-the-f-statistic-for-a-new-experiment</guid>
      <pubDate>Thu, 11 Apr 2024 18:15:54 GMT</pubDate>
    </item>
    <item>
      <title>在混合效应模型中，忽略截距斜率相关参数是否会导致 I 类误差增大？</title>
      <link>https://stats.stackexchange.com/questions/644822/in-a-mixed-effects-model-can-leaving-out-the-intercept-slope-correlation-parame</link>
      <description><![CDATA[我正在考虑在混合效应模型中省略截距斜率相关参数，以避免收敛问题（即，在 nlme::lme 中，random = list(~1|individual , ~0+时间|个人))。
“安全”吗？这样做的意义是不会导致相关固定斜率的 I 类错误概率夸大？
我已经为自己运行了一些模拟，看看完全忽略随机斜率（random = ~1|individual）肯定会增加错误发现的机会，但我没有信心关于使用模拟来检查相关性，因为完整模型 (random=~time|individual) 对于我的模拟数据经常无法收敛。
这个问题对于理解省略相关参数的含义有很大帮助，但它并没有解决 I 类错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/644822/in-a-mixed-effects-model-can-leaving-out-the-intercept-slope-correlation-parame</guid>
      <pubDate>Thu, 11 Apr 2024 18:09:06 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的 abc 包进行近似贝叶斯计算的不准确估计</title>
      <link>https://stats.stackexchange.com/questions/644821/inaccurate-estimates-with-approximate-bayesian-computation-using-the-abc-package</link>
      <description><![CDATA[我正在尝试使用近似贝叶斯计算（ABC）来校准参数，以获得接近文献中观察值的模型输出变量。为此，我使用 abc 包。
第一步，我使用 cv4abc 函数测试容差率选择对 ABC 估计值的影响。然而，结果表明，估计值并不准确，因为它们与真实值相差很大。我测试了几种类型的 ABC 算法（rejection、loclinear 和 neuralnet）和转换（none 和 &lt;代码&gt;日志）。我的代码可能做错了什么。因此，我们将非常感谢您提供任何帮助来了解导致估计不准确的原因。
这是我的数据集
文献中观察到的响应变量的范围是：min = 0.5，max = 2.5，mean = 1.5。
数据集中的模拟汇总统计数据为：simulated_rmse。对于数据集的每一行，我计算了模拟数据（列=“simulated_response”）和文献中观测值（即 1.5）之间的 RMSE。
数据集中要估计的模拟参数为：param_1 至 param_20。
观察到的汇总统计数据为 0（即 RMSE = 0）
以下是使用“拒绝”方法和“无”转换的参数图示例：

这是我的代码：
&lt;前&gt;&lt;代码&gt;库(abc)

数据 &lt;- read.csv(“C:/Users/Downloads/Test.csv”)
## 摘要（数据）

## 观察到的汇总统计数据
Observed_summary_statistics &lt;- 0

## 模拟汇总统计
Simulated_summary_statistics &lt;- data[, c(“simulated_RMSE”)]
## 摘要(simulated_summary_statistics)

## 模拟参数值
Simulated_pa​​rameters &lt;- data[, !(colnames(data) %in% c(“simulated_response”, “simulated_RMSE”))]
## 摘要（模拟参数）

## 运行“cv4abc” “abc”的函数包裹
cv_abc_rejection &lt;- abc::cv4abc(param=simulated_pa​​rameters, sumstat=simulated_summary_statistics, nval=100, tols=c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method=“拒绝”, transf=“ ;无”)
## 情节（cv_abc_rejection）
## 摘要(cv_abc_rejection)

cv_abc_rejection_log &lt;- abc::cv4abc(param =simulated_pa​​rameters, sumstat =simulated_summary_statistics, nval = 100, tols = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method = “拒绝”, transf = “ ;日志”）
## 情节（cv_abc_rejection_log）
## 摘要(cv_abc_rejection_log)

cv_abc_loclinear &lt;- abc::cv4abc(param =simulated_pa​​rameters, sumstat =simulated_summary_statistics, nval = 100, tols = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method = “loclinear”, transf = “ ;无”)
## 绘图（cv_abc_loclinear）
## 摘要(cv_abc_loclinear)

cv_abc_loclinear_log &lt;- abc::cv4abc(param =simulated_pa​​rameters, sumstat =simulated_summary_statistics, nval = 100, tols = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method = “loclinear”, transf = “ ;日志”）
## 绘图（cv_abc_loclinear_log）
## 摘要(cv_abc_loclinear_log)

cv_abc_neuralnet &lt;- abc::cv4abc(param=simulated_pa​​rameters, sumstat=simulated_summary_statistics, nval=100, tols=c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method=“neuralnet”, transf=“ ;无”)
## 绘图（cv_abc_neuralnet）
## 摘要(cv_abc_neuralnet)

cv_abc_neuralnet_log &lt;- abc::cv4abc(param=simulated_pa​​rameters, sumstat=simulated_summary_statistics, nval=100, tols=c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method=“neuralnet”, transf=“ ;日志”）
## 绘图（cv_abc_neuralnet_log）
## 摘要(cv_abc_neuralnet_log)
]]></description>
      <guid>https://stats.stackexchange.com/questions/644821/inaccurate-estimates-with-approximate-bayesian-computation-using-the-abc-package</guid>
      <pubDate>Thu, 11 Apr 2024 18:02:42 GMT</pubDate>
    </item>
    <item>
      <title>马尔可夫决策过程中，如何理解剧集平均长度的计算？</title>
      <link>https://stats.stackexchange.com/questions/644820/in-markov-decision-process-how-to-understand-the-calculation-of-the-average-len</link>
      <description><![CDATA[在Sec。 RL: An Introduction (Sutton &amp; Barto)的13.2，平均剧集长度的概念是针对情景 MDP 和持续 MDP 进行了讨论。
在情景 MDP 中，情景的平均长度可以计算为策略 $\pi$ 下状态的平稳分布之和，表示为 &lt; span class=&quot;math-container&quot;&gt;$\sum_{s}d^{\pi}(s)$。在连续的MDP中，平均情节长度被定义为1。如何理解这两种情况下平均长度的计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/644820/in-markov-decision-process-how-to-understand-the-calculation-of-the-average-len</guid>
      <pubDate>Thu, 11 Apr 2024 17:38:14 GMT</pubDate>
    </item>
    <item>
      <title>根据 Log 10 转换模型数据对预测 Y 进行反向转换</title>
      <link>https://stats.stackexchange.com/questions/644819/back-transformation-of-predicted-y-from-log-10-transformed-model-data</link>
      <description><![CDATA[我正在 Minitab 中使用一般线性模型进行分析。
我有两个问题。
我有两个响应变量，我使用 Log10 对其进行了转换，因为有一些正态性和顺序问题的残差图的证据，并且转换似乎很好地改善了这一点。 （我之前在这里得到过一些建议，非常感谢）
根据所有这些，我对 Log10 转换后的响应进行了分析，以获取有关各种因素的重要性和交叉效应等的一些详细信息。我还使用回归方程来预测 Y 值。现在，这些预测的 Y 值当然可以轻松地与变换后的 Y 值进行比较。但是对于这一部分我有疑问。

我对预测 Y 值进行反向变换（Minitab 中的反对数）有什么问题，即，为了将它们与原始未变换均值进行比较，作为评论 Y 值的方式，预测均值各种相关因素的模型？
这是否合法，因为我在某处读到，将原始算术平均值与我认为所谓的几何平均值进行比较存在问题，是否有直接的解决方法？
有人可以参考这方面的书籍或论文吗？
如果我想报告这些标准错误，我该如何进行反向转换？
]]></description>
      <guid>https://stats.stackexchange.com/questions/644819/back-transformation-of-predicted-y-from-log-10-transformed-model-data</guid>
      <pubDate>Thu, 11 Apr 2024 17:24:17 GMT</pubDate>
    </item>
    <item>
      <title>求前 k 个特征向量在空间上的投影</title>
      <link>https://stats.stackexchange.com/questions/644818/finding-the-projection-on-the-space-of-the-first-k-eigenvectors</link>
      <description><![CDATA[我有 100 个维度为 n 的向量。
我想找到它们在前 2 个特征向量生成的空间上的投影。
但我需要表达前 100 个向量的投影。
假设我已经计算了 2 个特征向量 PC1 和 PC2。
如何获取 PC1 和 PC2 生成的空间上的投影？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644818/finding-the-projection-on-the-space-of-the-first-k-eigenvectors</guid>
      <pubDate>Thu, 11 Apr 2024 17:00:40 GMT</pubDate>
    </item>
    <item>
      <title>当预测变量值按组平均时，使用随机森林是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/644816/does-it-make-sense-to-use-random-forest-when-predictor-values-are-averaged-by-gr</link>
      <description><![CDATA[简而言之：当预测变量按样本组进行平均时，使用随机森林来分析预测变量的重要性是否有意义？
我正在开展一个生态数据分析项目，涉及多个岛屿（150 个观测值，5 个岛屿）土壤细菌丰富度的多样性。然而，由于我们采样方法的限制，我们的预测变量（例如 pH 值）是对每个岛屿的样本进行平均，这意味着我有每个岛屿一个 pH 值和 50 个细菌丰富度值（每个岛屿的观察数量不平衡）岛）。
我希望使用随机森林 (RF) 来确定影响岛屿间细菌多样性的关键预测变量，但我不确定每个岛屿的平均预测变量是否会影响模型的有效性或可解释性。 RF 在这里仍然有效吗？平均预测变量是否需要进行任何调整？
注意：另一种选择是平均细菌丰富度并执行线性回归，但由于随机森林可以更“自然”地捕获非线性关系和相互作用。 （并且不假设线性模型限制），我想给这种方法一个机会。]]></description>
      <guid>https://stats.stackexchange.com/questions/644816/does-it-make-sense-to-use-random-forest-when-predictor-values-are-averaged-by-gr</guid>
      <pubDate>Thu, 11 Apr 2024 16:42:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么选择术语“显着性”($a$) 来表示 I 类错误的概率？</title>
      <link>https://stats.stackexchange.com/questions/644808/why-was-the-term-signifiance-a-chosen-for-the-probability-of-type-i-error</link>
      <description><![CDATA[我目前正在学习“统计 1”作为我计算机科学学位的一部分，我很难理解“重要性”的概念。
我们获得了以下定义：
$H_0$ - 零假设
$H_1$ - 替代假设。
$R$ - $H_0$ 拒绝区
$\bar{R}$ - $H_0$ 无拒绝区
$\begin{对齐} \alpha &amp;= P(\text{I 型错误})\\&amp;=P_{H_0}(\text{拒绝 } H_0 ) \\&amp;= P_{H_0}(X\in R) \\&amp;; \end{对齐} $
虽然我相信我已经很好地掌握了这些定义以及它们与 p 值的关系，但术语“显着性”并不适用。我仍然感到困惑。
我理解某事物“具有统计显着性”的概念，但显着性水平越高，出错的风险就越大，这似乎违反直觉。直觉上，当某件事非常重要时，我预计风险会较低。
有人可以解释一下为什么“重要性”一词如此重要吗？被选中了？
对于那些正在寻找的人来说，这些是关于这些术语的统计含义的一些非常好的讨论。我正在寻找更直观的解释来解释为什么选择这个术语。
比较和对比，p -值、显着性水平和 I 类错误
显着性水平 alpha 与 1 类误差 alpha 之间的关系是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644808/why-was-the-term-signifiance-a-chosen-for-the-probability-of-type-i-error</guid>
      <pubDate>Thu, 11 Apr 2024 15:02:37 GMT</pubDate>
    </item>
    </channel>
</rss>