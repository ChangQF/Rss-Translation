<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 23 Jan 2024 15:15:01 GMT</lastBuildDate>
    <item>
      <title>如何将多个二元（二项式）变量相互关联？</title>
      <link>https://stats.stackexchange.com/questions/637561/how-to-correlate-several-binary-binominal-variables-with-each-other</link>
      <description><![CDATA[我有一个数据集，描述了学生对 7 个问题（正确/错误）的回答。所以：

&lt;表类=“s-表”&gt;
&lt;标题&gt;


问题1
问题2
...
问题7


&lt;正文&gt;

学生#1
正确
正确

错误


学生#2
错误
正确

正确


学生#3
正确
正确

正确


...
...
...

...




我想将每个问题相互关联以查看模式，例如，当 Q6 回答正确时，Q7 也往往会回答正确。
我可以使用什么方法？四面相关性？点双列相关性？皮尔逊？
我将正确编码为 1，错误编码为 0，并在 R 中尝试了 corrplot。但是，我不确定 Paerson 是否是正确的选择，因为我尝试了这个简单的示例：
set.seed(11)

a = rbinom(n=100，大小=1，概率=0.9)
b = rbinom(n=100，大小=1，概率=0.9)

意外事件 &lt;- xtabs (~ a+ b)
意外事件

cor(a, b, 方法=“皮尔逊”)


&lt;表类=“s-表”&gt;
&lt;标题&gt;


b：0
b：1


&lt;正文&gt;

一个：0
0
3


一个：1
8
89




这里 a 和 b 彼此强烈相关。每次a为1时，b也趋向于1。但是，phi只有0.05左右，所以表明根本没有相关性？
我不确定哪种方法最适合比较多个二元（二项式）变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/637561/how-to-correlate-several-binary-binominal-variables-with-each-other</guid>
      <pubDate>Tue, 23 Jan 2024 14:49:09 GMT</pubDate>
    </item>
    <item>
      <title>如何对时间序列输入和输出进行敏感性分析</title>
      <link>https://stats.stackexchange.com/questions/637560/how-to-perform-a-sensitivity-analysis-on-time-series-in-and-output</link>
      <description><![CDATA[我想通过逆估计标量输入参数对物理模型进行计算机模型校准。不幸的是，模拟需要大量时间序列作为输入和输出。因此我想进行敏感性分析以消除不必要的时间序列。由于我对敏感性分析不太熟悉，我开始阅读一些论文，但没有找到任何有用的。有人有什么建议吗？提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637560/how-to-perform-a-sensitivity-analysis-on-time-series-in-and-output</guid>
      <pubDate>Tue, 23 Jan 2024 14:44:18 GMT</pubDate>
    </item>
    <item>
      <title>集成、合并或组合多个 lmertree 对象</title>
      <link>https://stats.stackexchange.com/questions/637558/ensemble-merge-or-combine-multiple-lmertree-objects</link>
      <description><![CDATA[使用 PISA 数据（其中包括每个参与者的多个成绩分数（合理值）），我想运行相同的 lmertree 并将结果组合起来。
lmm_treeM01 &lt;- lmertree(PV1MATH~ 1 | schid | X1 + X2)
lmm_treeM02 &lt;- lmertree(PV2MATH~ 1 | schid | X1 + X2)
是否可以组合lmm_treeM01和lmm_treeM02？
我的手动装袋尝试失败了。]]></description>
      <guid>https://stats.stackexchange.com/questions/637558/ensemble-merge-or-combine-multiple-lmertree-objects</guid>
      <pubDate>Tue, 23 Jan 2024 14:22:05 GMT</pubDate>
    </item>
    <item>
      <title>令 X 为来自正态 N(0,sigma^2) 总体的一个观测值。仔细解释一下如果 |X|西格玛的足够统计量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637556/let-x-be-one-observation-from-a-normal-n0-sigma2-population-carefully-explai</link>
      <description><![CDATA[有人可以帮我解决这个问题吗？
令 X 为来自正态 N(0,sigma^2) 总体的一个观测值。仔细解释一下如果 |X|西格玛的足够统计量]]></description>
      <guid>https://stats.stackexchange.com/questions/637556/let-x-be-one-observation-from-a-normal-n0-sigma2-population-carefully-explai</guid>
      <pubDate>Tue, 23 Jan 2024 14:02:46 GMT</pubDate>
    </item>
    <item>
      <title>细菌每秒按照泊松分布分裂，某时刻$n$的细菌数量分布是怎样的？</title>
      <link>https://stats.stackexchange.com/questions/637555/bacteria-split-each-second-according-to-a-poisson-distribution-what-is-the-dist</link>
      <description><![CDATA[每个细菌每秒分裂成一定数量的细菌，这些细菌是泊松分布的，所有细菌的参数都相同。所有的分割都不相关。如果我们一开始只有一个细菌，$n$ 秒后细菌的分布是什么？
我的第一个观察是
$$X_t = \sum_{i=1}^{X_{t-1}} \text{Po}(\lambda) = \text{Po}(X_{t- 1}\lambda)$$
然后我尝试通过调节泊松分布来找到 $X_2$：
$$P(X_2=k) = \sum_{i \geq 0} P(X_2=k | X_1 = i)P(X_1 = i)$$
$$= \sum_{i \geq 0} \frac{e^{-i\lambda}(i\lambda)^k}{k!}\frac{e^{ -\lambda}\lambda^i}{i!}= \frac{e^{-\lambda}\lambda^k}{k!} \sum_{i \geq 0} \frac{e^{-i\ lambda}i^k\lambda^i}{i!}$$
但后来我不知道如何评估这笔钱。我想这也许可以通过 MGF 或类似的东西来完成，但我不知道该怎么做。]]></description>
      <guid>https://stats.stackexchange.com/questions/637555/bacteria-split-each-second-according-to-a-poisson-distribution-what-is-the-dist</guid>
      <pubDate>Tue, 23 Jan 2024 13:45:41 GMT</pubDate>
    </item>
    <item>
      <title>因变量是具有上限的计数变量</title>
      <link>https://stats.stackexchange.com/questions/637554/dependent-variables-are-count-variable-with-an-upper-bound</link>
      <description><![CDATA[我需要测试社会科学论文的一些假设。在下面的描述中，我将自变量称为 X，将因变量称为 Y。
我期望 X 和 Y 之间存在直线关系，例如 Y = mX + C。X 是“连续”关系。变量将是 5 点李克特量表中四个问题的平均值。 Y 都是计数变量，可以取值 0、1、2、3、4、5、6、7、8、9、10。
我假设因为我的 Y 是计数变量，所以我需要使用泊松模型或零膨胀泊松模型之类的模型。然而，由于我的 Y 有上限，这会让事情变得复杂吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637554/dependent-variables-are-count-variable-with-an-upper-bound</guid>
      <pubDate>Tue, 23 Jan 2024 13:25:31 GMT</pubDate>
    </item>
    <item>
      <title>广义可加模型中的空间相关性</title>
      <link>https://stats.stackexchange.com/questions/637552/spatial-correlation-in-generalised-additive-model</link>
      <description><![CDATA[我是 GAM 新手，并且很高兴这个问题有一些变体。抱歉，如果这是多余的。
我希望将 GAM 与 7 年来每天从大约 500 个站点进行的温度测量的大型数据集相匹配。这个想法是为了研究土地覆盖对温度的影响。数据如下所示：
ID 日期 day_numbermean_tempmean_met_temp x y green_percbuilt_percavg_height
697 2016-11-02 307 7.158333 6.6 529811.8 180107.3 1.12 27.87628 21.45
697 2020-08-29 242 13.445833 13.0 529811.8 180107.3 1.12 27.87628 21.45
697 2021-11-23 327 5.629167 4.4 529811.8 180107.3 1.12 27.87628 21.45
697 2018-04-07 97 12.866667 12.3 529811.8 180107.3 1.12 27.87628 21.45
697 2021-02-02 33 9.262500 9.1 529811.8 180107.3 1.12 27.87628 21.45

我想根据土地覆盖（green_perc、built_perc、avg_height）和附近官方气象站的温度（met_met_temp）预测测量站的日平均温度（mean_temp）。
像这样的非空间和时间模型：
gam_nonspatial &lt;- gam(mean_temp ~ s(mean_met_temp) + s(green_perc) + s(built_perc) + s(avg_height),data = temperature_final, na.action = na.omit, method = &quot; REML”，选择 = TRUE，控制 = ctrl)

有一个像这样的变异函数：

所以，我猜有一些自相关。
我的问题是，假设空间变化会随日期而变化，哪种空间游戏最适合。我尝试过以下方法：
选项 1 具有基于变差函数的指定相关性（按日期）
gamm_spattemp1 &lt;- gamm(mean_temp ~ s(mean_met_temp) + s(green_perc) +
                                s(build_perc) + s(avg_height),
                                数据=最终温度，
                                方法=“REML”，
                                选择=真，
                                na.action = na.omit,
                                相关性 = corExp(形式 = ~ x + y |日期))

选项 2：通过坐标和日期进行平滑
gam_spattemp2 &lt;- gam(mean_temp ~ s(mean_met_temp) + s(green_perc) + s(build_perc) + s(avg_height) + ti(x, y, day_number, d=c(2,1) ),
                                      数据=最终温度，
                                      方法=“REML”，
                                      控制=ctrl，
                                      选择=真，
                                      na.action = na.omit
）

选项 3：对当天进行带有 by= 的平滑，因此每天都有不同的空间平滑
&lt;前&gt;&lt;代码&gt;
gam_spattemp3 &lt;- gam(mean_temp ~ as.factor(day_number) + s(mean_met_temp) + s(green_perc) + s(build_perc) + s(avg_height) + s(x, y, bs=“gp”, by=天数），
                                       数据=最终温度，
                                       方法=“REML”，
                                       控制=ctrl，
                                       选择=真，
                                       na.action = na.omit
）


选项 4：或者甚至是某种地理加权回归 此处
gam_spattemp4 = gam(mean_temp ~ 截距 + s(x,y,bs=&#39;gp&#39;, by=截距) +
            green_perc + s(x,y,bs=&#39;gp&#39;, by=green_perc) +
            build_perc + s(x,y,bs=&#39;gp&#39;, by=build_perc) +
            平均高度 + s(x,y,bs=&#39;gp&#39;, by=平均高度 ),
            数据 = 最终温度）


我的问题是，1) 哪种方法比另一种方法更好，2) 所有方法似乎在 gam.check 上都表现不佳，p 值较低，k 指数小于 1，并且 edf 接近k - 但增加 k 会导致点之间出现奇怪的插值或使我的计算机崩溃。是否可以基于更简化的关系来限制此处的基础？]]></description>
      <guid>https://stats.stackexchange.com/questions/637552/spatial-correlation-in-generalised-additive-model</guid>
      <pubDate>Tue, 23 Jan 2024 13:17:55 GMT</pubDate>
    </item>
    <item>
      <title>阿尔茨海默病数据分析</title>
      <link>https://stats.stackexchange.com/questions/637551/analysis-of-alzheimer-data</link>
      <description><![CDATA[我有两个数据集，其中包含阿尔茨海默病患者和健康患者的值。我的任务是找到评估患者的决策规则。任务原文：
“想出一个区分健康人和阿尔茨海默病患者的决策规则。给出一个决策规则，使每组中正确分类的人的百分比之和最大。给出另一个使正确分类总数最大化的方法。”
数据：
阿尔茨海默病：1.70 1.95 2.04 2.24 2.27 2.28 2.35 2.56 2.57 2.77 3.93 4.21 4.69 4.72 4.74 4.75 4.92 4.95 5.37
健康：1.87 1.92 1.97 1.99 2.02 2.03 2.11 2.11 2.12 2.14 2.17 2.20 2.30 2.30 2.31 2.32 2.36 2.36 2.80 2.16 2.20 2.27 2.28 2. 29 2.36 2.37 2.43 2.49 2.51 2.53 2.53 2.53 2.55 2.63 2.71 2.73 2.86 2.94
第一条规则的做法应该是n_classified/n_sample并最大化总和。
第二条规则的做法应该是（真阳性+真阴性）/样本总数。
不幸的是，两个变体的值相同，均为 2.94。从任务来看，我猜应该不是这样的。
如果有任何帮助，我将不胜感激。
best_threshold = 无
最大结果 = float(&#39;-inf&#39;)

阿尔茨海默病 = [1.70, 1.95, 2.04, 2.24, 2.27, 2.28, 2.35, 2.56, 2.57, 2.77, 3.93, 4.21, 4.69, 4.72, 4.74, 4.75, 4.92, 4.95, 5.37]
健康= [1.87, 1.92, 1.97, 1.99, 2.02, 2.03, 2.11, 2.11, 2.12, 2.14, 2.17, 2.20, 2.30, 2.30, 2.31, 2.32, 2.36, 2.36, 2.80, 2.16, 2 .20、2.27、2.28、2.29 , 2.36, 2.37, 2.43, 2.49, 2.51, 2.53, 2.53, 2.53, 2.55, 2.63, 2.71, 2.73, 2.86, 2.94]

对于 np.arange(2.02, 3.5, 0.02) 中的阈值：
    true_positive = np.sum(np.array(阿尔茨海默病) &gt; 阈值)
    true_negative = np.sum(np.array(healthy) &lt;= 阈值)


    准确度 = (真阳性 + 真阴性) / (len(阿尔茨海默氏症) + len(健康))
    阿尔茨海默氏症敏感性 = (真阳性) / len(阿尔茨海默氏症)
    Specificity_healthy = (true_阴性) / len(健康)

    百分比总和 = 阿尔茨海默氏症敏感性 + 健康特异性

    如果准确度&gt;最大结果：
        最大结果 = 准确度
        最佳阈值 = 阈值


    print(&quot;阈值：&quot;, 阈值)
    print(&quot;真阳性 (TP):&quot;, true_positive)
    print(&quot;真阴性 (TN):&quot;, true_阴性)

    打印（“阿尔茨海默氏症：”，sensitivity_alzheimer）
    print(“健康：”, Specificity_healthy)
    print(&quot;结果百分比总和：&quot;, sum_of_percentages)
    print(&quot;结果（准确度）：&quot;, 准确度）
    打印（）

print(&quot;最佳阈值：&quot;, best_threshold)
print(&quot;最大化结果（准确度）：&quot;, max_result)
]]></description>
      <guid>https://stats.stackexchange.com/questions/637551/analysis-of-alzheimer-data</guid>
      <pubDate>Tue, 23 Jan 2024 13:10:45 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用独立得分匹配还是倾向得分匹配？</title>
      <link>https://stats.stackexchange.com/questions/637547/should-i-use-independent-or-propensity-score-matching</link>
      <description><![CDATA[我处理一项观察性研究 (n=34) 的数据，并希望将个人的结果与历史队列 (n=600) 进行比较。与历史队列相比，观察性研究中的受试者接受了额外的治疗。我收集了两组的疾病类型、疾病强度、反应和人口统计数据。
现在，我想使用 Kaplan-Meier-Estimator 执行生存分析，对两组进行总体比较并进行 1:1、1:2 匹配。您能否建议推荐的匹配方法，用于将观察性研究的 34 名受试者与历史队列进行匹配，以根据疾病类型、疾病强度和反应进行调整？]]></description>
      <guid>https://stats.stackexchange.com/questions/637547/should-i-use-independent-or-propensity-score-matching</guid>
      <pubDate>Tue, 23 Jan 2024 12:32:51 GMT</pubDate>
    </item>
    <item>
      <title>当自变量为计数数据时的线性回归</title>
      <link>https://stats.stackexchange.com/questions/637545/linear-regression-when-independent-variable-are-count-data</link>
      <description><![CDATA[在我即将发表的社会科学论文中，我正在深入研究检验某些变量之间关系的假设。在我的框架中，我将这些变量分为两组：自变量（我将其称为 X）和因变量（称为 Y）。
我的研究核心是基于 X 和 Y 之间线性关系的假设，通常用方程 Y = mX + C 表示。这里，X 是计数变量，具体取范围从 0 到10. 另一方面，Y 是连续的，可以采用任何数值，无论是正值还是负值。
最初，我的方法是应用线性回归来模拟这种关系。然而，考虑到 X 作为计数变量的具体性质，我越来越不确定使用线性回归的适当性。我主要担心的是，考虑到自变量的离散性质，这种方法是否可能违反线性回归模型的任何基本假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/637545/linear-regression-when-independent-variable-are-count-data</guid>
      <pubDate>Tue, 23 Jan 2024 12:12:37 GMT</pubDate>
    </item>
    <item>
      <title>西迪基《信用风险记分卡》一书中的信息价值定义</title>
      <link>https://stats.stackexchange.com/questions/637543/information-value-definition-on-siddiqui-credit-risk-scorecards-book</link>
      <description><![CDATA[我正在研究信息价值，并看到“Siddiqui，信用风险记分卡”上的定义。我正在寻找一些关于为什么公式是这样的参考资料，以及他为变量选择假设的阈值，有人可以帮助我吗？起初，我假设信息值与互信息几乎相同，但公式不匹配（我尝试了逐点互信息和预期互信息，如下所述：信息增益和互信息：不同还是相等？）。书上的定义是：
$$
\sum_i (DistrGood_i - DistrBad_i) ∗ ln\frac{DistrGood_i}{DistrBad_i}
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/637543/information-value-definition-on-siddiqui-credit-risk-scorecards-book</guid>
      <pubDate>Tue, 23 Jan 2024 12:08:28 GMT</pubDate>
    </item>
    <item>
      <title>因变量的范围介于 0 和 1 之间</title>
      <link>https://stats.stackexchange.com/questions/637542/dependent-variable-is-a-bounded-between-0-and-1</link>
      <description><![CDATA[我需要测试社会科学论文的一些假设。在下面的描述中，我将自变量称为 X，将因变量称为 Y。
我已经记下了我认为可以用于这个假设的模型/测试。然而，由于变量的性质，我不确定这些是否违反了基础模型的一些假设。我对模型做了一些研究，但我仍然很困惑。任何指导和建议都将受到高度赞赏。
我期望 X 和 Y 之间存在倒 U 形关系。 X 是计数变量，可以取值 0、1、2、3、4、5、6、7、8、9、10。Y 可以是 0 到 1 之间的任何数字，包括 0 和 1。
我正在考虑使用二次回归来测试这一点。但是，我不确定是否可以使用它，因为我的 X 变量是计数变量，而我的 Y 变量是有界的。另外，Y 变量只能落在 [0, 1] 范围内 - 这并不是只能在这个范围内观察到的情况。
有人建议我使用零一膨胀的 Beta 模型作为可能的替代方案，因为我的 Y 可以取值 0 或 1。理想情况下，我正在寻找最简单的解决方案，因为我的字数限制了我做任何过于复杂的事情.
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/637542/dependent-variable-is-a-bounded-between-0-and-1</guid>
      <pubDate>Tue, 23 Jan 2024 11:31:59 GMT</pubDate>
    </item>
    <item>
      <title>Box-Cox 变换后是否存在分组交互问题？</title>
      <link>https://stats.stackexchange.com/questions/637539/is-there-a-by-group-interaction-issue-after-the-box-cox-transformation</link>
      <description><![CDATA[我遇到一个问题，有点难倒我，希望寻求您的宝贵见解。具体来说，我一直在使用 Box-Cox 变换来标准化每种语言的每个组内的因变量。在线性混合效应模型中，跨语言主效应仍然显着。我担心的是，群体间的互动是否可能是群体间整体差异的产物，正如 Faust 等人所讨论的那样。 （1999）。我将非常感谢您对此事的任何指导或想法。预先感谢您的帮助。
这是我的 Box-Cox 转换代码：
model1 = lm(响应 ~ 组 * 语言 * AOA, 数据 = L1)
图书馆（大众）
bc = boxcox(model1,lambda=seq(-1,1,by = 0.05),plotit = TRUE)
lambda&lt;-bc$x[which.max(bc$y)]
L1$response_BC = (L1$response ^ lambda-1)/lambda

这是我的模型代码：
lmer_model1 &lt;- lmer(response_BC ~ 组 * 语言 * AOA + (1 | 参与者), data = 数据, REML = TRUE )

组和语言是分类变量：组：法语与德语； 语言：母语与第二语言。 AOA是一个连续变量，表示参与者学习该单词的年龄。
这是我的结果：

如您所见，组非常重要。有人问我在 GroupGerman:AOA 中观察到的显着性是否是各组之间总体差异的产物（Faust et al., 1999）。有什么想法或建议吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/637539/is-there-a-by-group-interaction-issue-after-the-box-cox-transformation</guid>
      <pubDate>Tue, 23 Jan 2024 10:19:14 GMT</pubDate>
    </item>
    <item>
      <title>Bing 藏文错误表情符号问题</title>
      <link>https://stats.stackexchange.com/questions/637505/the-bing-tibetan-glitch-emoji-problem</link>
      <description><![CDATA[这是一个非常有趣的数理统计难题，是我在使用 Bing 时偶然发现的。事实证明这个问题太深了，我花了相当长的时间思考如何解决它！尽管背景故事相对有趣，但看起来这可能是一个非常普遍（众所周知？）的统计问题。
请原谅我的篇幅，但我认为背景故事很有趣，值得分享:)
谜题：Bing 的新 AI 语言模型有一个非常奇特的错误。如果您向它发送一个来自未知“故障表情符号”列表中的单个表情符号，它会随机用藏语回复。例如，这是它对 🥲 的响应：

目标是描述引起此响应的所有表情符号的特征。由于表情符号有 3782 个，因此每个表情符号发送一条消息需要几个小时。
但有趣的是。如果您向 Bing 发送的消息仅包含有此“故障”的表情符号，财产，它会用西藏的废话来回应。但是，即使您发送一个没有表情符号的表情符号，它也会正常响应。这是两者的示例，其中 🥲🫥🤥🤫🤠 是故障表情符号，而 😊 不是：

因此，可以“批量测试”表情符号，并可能减少表征该集合所需的消息数量。大批量的风险更大，因为如果你足够幸运，选择了所有故障表情符号，你会立即获得大量信息，但如果没有，你除了至少有一个表情符号不是故障表情符号之外，一无所知。 
问题：用最少的消息来描述整套故障表情符号的最佳策略是什么？
为了简单起见，以下是我们可以做出的数学假设：

所有表情符号都同样可能是故障表情符号。
对于哪些表情符号是故障标记、哪些不是故障标记，没有特定的模式。
各种表情符号的故障/非故障状态在条件上都是相互独立的。
特别是，如果我们知道某些表情符号是或不是故障表情符号，我们假设这与概率无关，例如相邻的故障表情符号或任何其他表情符号。
我们可以访问一个黑盒函数，该函数将表情符号的一些子集作为输入，并且当且仅当每个表情符号都是故障表情符号时才返回 TRUE。

那么问题实际上是：如果您作为坚定的常客/贝叶斯/其他什么人，需要解决这个问题并在尽可能少的查询中最大限度地提高解决问题的机会，您会如何解决？ 
在我看来，“最佳”可能有多种概念。贝叶斯主义者和频率主义者对此可能有不同的看法。一个人可以尝试查看发送的消息数量的预期值；另一个可能会查看似然函数等。所以，我将其保留。我将在下面发布我的部分解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/637505/the-bing-tibetan-glitch-emoji-problem</guid>
      <pubDate>Tue, 23 Jan 2024 01:23:09 GMT</pubDate>
    </item>
    <item>
      <title>GAN 框架中符号 $ \mathbb{E}_{x\sim \mu_{\text{ref}}, y\sim \mu_D(x)}[\ln y]$ 的含义</title>
      <link>https://stats.stackexchange.com/questions/637483/meaning-of-the-notation-mathbbe-x-sim-mu-textref-y-sim-mu-dx-l</link>
      <description><![CDATA[关于生成对抗网络（GAN）数学框架中使用的符号的一个非常天真的问题。诸如此类的术语的精确数学定义是什么
$$ \mathbb{E}_{x\sim \mu_{\text{ref}}, y\sim \mu_D(x)}[\ln y] $ $
如维基介绍中所示。
一般来说，如果 $X: \Omega \to \mathbb{R}$ 是概率空间上的随机变量 $(\Omega, P)$ 具有密度函数 $f_X$ 和 $g: \mathbb{ R} \to \mathbb{R}$，然后 $ \mathbb{E}[g(X)]= \int g(X) dP_X= \int g (x) f_X(x)dx $ 根据定义。
我的问题是纯数学上这个看起来像对象的期望值意味着什么
$ \mathbb{E}_{x\sim \mu_{\text{ref}}, y\sim \mu_D(x)}[\ln y] $在上面的表达式中使用底部符号 $x\sim \mu_{\text{ref}}, y\sim \mu_D(x)$ 吗？这个底部符号是否只是一个额外的余数，预期值是相对于两个随机变量 $\mathbb{E}[\ln y]$ 之前形成的class=&quot;math-container&quot;&gt;$x$ 和 $y$，其中前者具有密度函数  $ \mu_{\text{ref}}$ 和后者 $\mu_D(x)$？对了，这有什么不同的含义吗？
请注意，$\mu_D$ 以概率度量进行评估，因此
$ \mathbb{E}_{x\sim \mu_{\text{ref}}, y\sim \mu_D(x)}[\ln y] $也许应该更好地将其视为“扩展值的参数化系列”。但我不明白这个对象看起来如何明确地写出来？
对不起，如果这个问题是微不足道的，但在经典随机学中我有点熟悉我从未遇到过这种预期值的底部符号，所以似乎是非标准的“GAN 特定”术语，因此我想澄清它精确的数学含义。]]></description>
      <guid>https://stats.stackexchange.com/questions/637483/meaning-of-the-notation-mathbbe-x-sim-mu-textref-y-sim-mu-dx-l</guid>
      <pubDate>Mon, 22 Jan 2024 20:08:15 GMT</pubDate>
    </item>
    </channel>
</rss>