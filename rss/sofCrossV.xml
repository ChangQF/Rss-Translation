<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 06 Jan 2025 01:18:56 GMT</lastBuildDate>
    <item>
      <title>抛硬币能给假设检验提供任意的$\alpha$吗？</title>
      <link>https://stats.stackexchange.com/questions/659589/can-flipping-a-coin-give-a-hypothesis-test-an-arbitrary-alpha</link>
      <description><![CDATA[以下假设检验是否符合所有定义？

选择一个 $\alpha$（通常为 $0.05$）
设 $A := \lceil -\log_2(\alpha) \rceil$（其中 $\lceil x \rceil$ 是大于或等于 $x$ 的最小整数）
抛硬币 $A$ 次
如果其中一次抛出的是正面，则维持原假设
如果全部都是反面，则拒绝原假设假设

此检验的显著性水平为$\alpha$。它对所有备选假设的功效也为$\alpha$，因此效率很低。]]></description>
      <guid>https://stats.stackexchange.com/questions/659589/can-flipping-a-coin-give-a-hypothesis-test-an-arbitrary-alpha</guid>
      <pubDate>Sun, 05 Jan 2025 22:58:56 GMT</pubDate>
    </item>
    <item>
      <title>在进行 A/B 测试时，假设检验有助于做出决策吗？</title>
      <link>https://stats.stackexchange.com/questions/659587/does-hypothesis-testing-help-make-a-decision-in-case-of-an-a-b-test</link>
      <description><![CDATA[我根据大型语言模型 (LLM) 的最新进展开发了一个文本生成管道。用户可以输入一个主题，然后我的复杂管道会生成一篇文章。我通过询问用户对每篇文章 (C-SAT) 的 5 分制序数表的满意程度来衡量用户满意度。
我实施了一个管道变体，在某些地方使用更便宜、更愚蠢的 LLM。我进行了 A/B 测试，以确定管道的当前版本和更便宜的版本之间的差异。假设平均 C-SAT 为 3.9 比 3.8，那么更便宜的版本的 C-SAT 分数低 0.1。现在，我必须决定是否引入新版本的管道以降低成本并承担降低平均 C-SAT 的风险。
我想知道 C-SAT 的下降是否足以让我放弃削减成本。
Q1：在这种情况下，假设检验有意义吗？
Q2：如果有意义，那么总体是什么？现在知道了未来文章的数量。此外，其中一个版本将不会继续。这是否意味着我不能应用测试？
测试的结果将是反对零假设的证据。假设我的零假设是“A 和 B 样本的总体分布均值相等”。从原始问题的角度来看（“如果 C-SAT 的下降足以让我放弃削减成本”），这样的 H0 是一个中间问题。
Q3：我怎么知道找到这样一个中间问题的答案有助于我找到原始问题的答案？]]></description>
      <guid>https://stats.stackexchange.com/questions/659587/does-hypothesis-testing-help-make-a-decision-in-case-of-an-a-b-test</guid>
      <pubDate>Sun, 05 Jan 2025 22:33:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们将标准误差定义为忽略偏差（与包含偏差的 MSE 不同）？</title>
      <link>https://stats.stackexchange.com/questions/659583/why-do-we-define-the-standard-error-to-ignore-bias-unlike-mse-which-includes-bi</link>
      <description><![CDATA[为什么估计量$\hat \theta$的标准误差定义为$$se = \sqrt{Var(\hat \theta)}$$，而不是$$se = \sqrt {MSE(\hat \theta)} = \sqrt{Bias^2(\hat \theta) + Var(\hat \theta)}.$$
也就是说，标准误差应该是均方误差的平方根。当然，如果估计量是无偏的，那就没有区别了。但无论如何，我能想到，如果估计量有偏差，那么我们使用标准误差的地方，偏差需要成为误差的一部分。
例如，考虑执行 Wald 检验。如果我们愿意增加偏差，我们总是可以得出任意低方差的 $\sigma^2$ 估计量。例如，给定 $\hat \sigma^2$，定义 $$\hat \sigma_1^2 = (1-t)\hat \sigma^2 + tk$$，对于任意常数 $t,k$ 将给出这样的估计量。如果我们使用它来执行 Wald 检验，我们可以通过降低 se 来获得我们想要的任何 $\alpha$，而无需真正改进测试。
如果 se 的定义包括偏差，这个问题就会得到解决 - 这会与 标准 错误 一词更加一致。我们为什么不这样做呢？

更新 - 与假设检验的相关性
撇开术语不谈，这里有一个有影响力的问题：在我们的估计量确实有偏差的情况下，我们应该在假设检验中使用 标准错误 还是上述定义？有些情况下，这会对测试结果产生影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/659583/why-do-we-define-the-standard-error-to-ignore-bias-unlike-mse-which-includes-bi</guid>
      <pubDate>Sun, 05 Jan 2025 21:17:49 GMT</pubDate>
    </item>
    <item>
      <title>梦幻篮球：重新思考球员的价值</title>
      <link>https://stats.stackexchange.com/questions/659577/fantasy-basketball-rethinking-player-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659577/fantasy-basketball-rethinking-player-value</guid>
      <pubDate>Sun, 05 Jan 2025 20:56:33 GMT</pubDate>
    </item>
    <item>
      <title>如何实现全卷积神经网络（FCN）用于多类分类任务？</title>
      <link>https://stats.stackexchange.com/questions/659573/how-can-a-fully-convolutional-neural-network-fcn-be-implemented-for-a-multicla</link>
      <description><![CDATA[在网络上我看到的几乎所有资料中，FCN 主要用于分割等问题（例如具有各种上采样层的 U-net），所以我的问题是，考虑到它们能够处理不同分辨率的图像，如何使用这些网络进行简单的多类分类任务。
我能想到的唯一解决方案是 FCN 产生具有 c 个通道（其中 c 是类别数）的特定热图体积，然后是 GAP，然后是 softmax。还有其他完全卷积方法吗？我读到过一种称为“卷积化”的过程，它可以让你在这种情况下重用预先训练的 CNN（非完全卷积）的权重，但我真的不明白它是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/659573/how-can-a-fully-convolutional-neural-network-fcn-be-implemented-for-a-multicla</guid>
      <pubDate>Sun, 05 Jan 2025 20:08:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么交互项虚拟变量的个体显著性取决于基类/省略类，而联合显著性却不取决于基类/省略类？</title>
      <link>https://stats.stackexchange.com/questions/659572/why-is-individual-significance-of-interaction-term-dummies-dependent-on-the-base</link>
      <description><![CDATA[我不认为我可以展示数据，但在线性回归模型中，除了其他几个变量外，我还有一个连续变量年龄和分类变量健康之间的交互项。健康有 5 个类别。当我以不同的类别为基础运行模型时，每个非省略类别的个体显著性检验 p 值差异很大（例如，当“优秀”健康为基础时，年龄和“一般”健康之间的交互作用显著，达到 95%，但当“较差”健康为基础时，它并不单独显著），但联合显著性检验 p 值始终相同（显著性达到 95%）。
此外，交互项的输出系数会发生变化，但使用“margins”和“marginsplot”的图形的实际斜率不会发生变化Stata 中的命令。
因此
regressdependentvar c.age##ibx.healthother_variable1other_variable2testparm c.age#ibx.healthmargins,at(age=(16(1)80)health=(12345))atmeansmarginsplot 产生相同的联合显著性和相同的图形，但每个交互项的个体显著性 p 值和系数不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/659572/why-is-individual-significance-of-interaction-term-dummies-dependent-on-the-base</guid>
      <pubDate>Sun, 05 Jan 2025 20:03:09 GMT</pubDate>
    </item>
    <item>
      <title>SPSS中具有多个分类预测变量和一个连续预测变量的线性回归[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659570/linear-regression-with-multiple-categorical-predictor-and-one-continuous-predict</link>
      <description><![CDATA[我想在 SPSS 中执行包含 3 个分类预测因子（每个都有两个级别）、一个连续预测因子和一个标准变量的回归分析。我希望能够查看简单的效果，因此我计划使用 PROCESS。但是，对话框中只有一个 X 变量的空间。我如何才能将所有 4 个预测变量输入模型并获取所有交互项的统计数据，并获得简单斜率？]]></description>
      <guid>https://stats.stackexchange.com/questions/659570/linear-regression-with-multiple-categorical-predictor-and-one-continuous-predict</guid>
      <pubDate>Sun, 05 Jan 2025 19:13:35 GMT</pubDate>
    </item>
    <item>
      <title>比较参数曲线：基于傅里叶级数的相似度度量</title>
      <link>https://stats.stackexchange.com/questions/659553/comparing-parametric-curves-fourier-series-based-similarity-metric</link>
      <description><![CDATA[使用傅里叶级数开发参数曲线的相似度度量
我正在探索使用傅里叶级数表示法在 xy 平面上比较参数曲线的方法。我的目标是开发一种能够最好地捕捉曲线“形状”的相似度度量。以下是我正在考虑的一些想法：
背景：

xy 平面上的参数曲线表示为复函数：
$z(t) = x(t) + iy(t)$
其中 $x(t)$ 和 $y(t)$ 是曲线的参数方程，$t \in (0, 1)$。

此复函数可表示为傅里叶级数：
$z(t) = \sum_{n=-\infty}^{\infty} c_n e^{2\pi int}$

傅里叶系数$c_n$的计算方法如下：
$c_n = \int_0^1 z(t) e^{-2\pi int} dt$

这些系数包含幅度和相位信息：
$c_n = |c_n|e^{i\phi_n}$
其中$|c_n|$为幅度，$\phi_n$为相位。

首先，我们将傅里叶级数标准化为具有能量 1：
$\sum_{n=-N}^{N} |c_n|^2 = 1$


当前考虑事项：

相位信息：我认为相位对于确定曲线形状至关重要。是否有证据表明情况并非如此？

相关工作：

一些现有方法比较功率谱密度（忽略相位）
这些方法通常将 PSD 视为概率密度
两个离散傅里叶变换的相似性
比较傅里叶空间中的两个分布



潜在方法：

分离幅度和相位比较：

分别比较功率谱密度和相位谱密度
将两者视为概率分布
使用上述相关工作中的方法


笛卡尔形式的余弦相似性：

以平坦笛卡尔形式写入傅里叶系数（自然包括幅度和相位信息）
应用余弦相似性
优点：自然在 -1 和 1 之间有界
缺点：对于接近 0 或负值的分数的解释不明确


笛卡尔形式的 L1/L2 距离：

与方法 2 类似，但使用 L1 或 L2 距离而是



问题：
是否有一种原则性的方法，可以使用傅里叶级数表示法来开发 xy 平面上参数曲线的相似性度量，该度量法可以同时考虑幅度和相位信息？
我特别想了解这些方法与我可能忽略的任何其他方法之间的权衡。]]></description>
      <guid>https://stats.stackexchange.com/questions/659553/comparing-parametric-curves-fourier-series-based-similarity-metric</guid>
      <pubDate>Sun, 05 Jan 2025 08:49:43 GMT</pubDate>
    </item>
    <item>
      <title>如何计算独立拍卖实验中销售额、退货和退货率变化的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/659552/how-to-compute-confidence-intervals-for-changes-in-sales-returns-and-return-ra</link>
      <description><![CDATA[问题
假设我正在组织一场汽车拍卖会，并进行两个独立的实验：

拍卖会 A 进行了 1000 次。
拍卖会 B 进行了 1000 次。
（例如，我更换了拍卖会 B 中的拍卖师，并想测量其效果。）

以下是观察到的结果：




拍卖会 A
拍卖会 B
符号




数量运行
1000
1000
常数 $ n_A $ 和 $ n_B $


售出数量
500
600
随机变量 $ S_A $ 和 $ S_B $


（售出和）退回数量
200
300
随机变量$ R_A $ 和 $ R_B $



根据这些数据，增量（我感兴趣的）如下：

销售数量增加了 20%：从 500 增加到 600。
退货数量增加了 50%：从 200 增加到 300。
退货率增加了 25%：从 40%（$ \frac{200}{500} $）增加到 50%（$ \frac{300}{600} $)。

问题 1：增量的置信区间
如何计算 95% 置信水平下每个增量的置信区间？例如：

销售数量增量，例如 $[+16\%, +27\%]$。
退货数量增量，例如 $[+42\%, +53\%]$。
退货率增量，例如 $[-5\%, +41\%]$。


我目前的方法（针对 #1）：
计算销售数量增量的置信区间：

我假设 $ S_A \sim \text{Binomial}(n_A, p^s_A) $ 和 $ S_B \sim \text{Binomial}(n_B, p^s_B) $，其中 $ p^s_A $ 和 $ p^s_B $ 是拍卖 A 或拍卖 B 中拍卖成交的概率 ($ p^s_A = 50\%, p^s_B = 60\% $)。
然后，我计算置信区间如下：
$$
\Delta S \pm z_{\alpha/2} \sqrt{\text{Var}(\Delta S)}
$$
其中：
$$
\text{Var}(\Delta S) = \text{Var}(S_A) + \text{Var}(S_B),
$$
并且：
$$
\text{Var}(S_A) = n_A p^s_A (1 - p^s_A), \quad \text{Var}(S_B) = n_B p^s_B (1 - p^s_B)。
$$
这种方法有意义吗？


我的挑战（针对 #2 和 #3）：
计算回报数量和回报率的增量置信区间：

我假设 $ R_A \mid S_A \sim \text{Binomial}(S_A, p^r_A) $，对于 $ R_B $ 也是如此。
我应该如何计算 $ \text{Var}(R_A) $ 和 $ \text{Var}(R_B) $？

我是否应该将观察到的销售数量（$ s_A $ 和 $ s_B $）视为常数（如第一种情况下的 $ n_A $ 和 $ n_B $）？
或者我应该将销售数量（$ S_A $ 和 $ S_B $）视为随机变量，并使用总方差定理计算 $ \text{Var}(R_A) $：
$$
\text{Var}(R_A) = \mathbb{E}[\text{Var}(R_A \mid S_A)] + \text{Var}(\mathbb{E}[R_A \mid S_A])?
$$



如能提供关于这些计算的任何指导或替代方法的建议，我们将不胜感激！

备注

我特别关心我的假设（例如，将观测值视为常数而不是随机变量）是否正确。
我希望得到任何相关统计方法或框架的指引，以便更好地处理这些类型的分析。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659552/how-to-compute-confidence-intervals-for-changes-in-sales-returns-and-return-ra</guid>
      <pubDate>Sun, 05 Jan 2025 06:07:41 GMT</pubDate>
    </item>
    <item>
      <title>检验具有交互项的对数线性模型中变量效应的显著性</title>
      <link>https://stats.stackexchange.com/questions/659543/test-significance-of-effect-of-a-variable-in-log-linear-model-with-interaction-t</link>
      <description><![CDATA[假设我们有以下模型：
$\log(\mathbb{E}(​​y|x_1, x_2))=\beta_0+\beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2$。
它可以是逻辑回归、泊松回归或负二项模型。
假设$y$为正整数，模型为负二项模型。
假设$x_1$和$x_2$为虚拟变量。
假设所有估计系数在统计上都是显著。
那么，当 $x_1=1$ 时，将 $x_2$ 从 $0$ 切换到 $1$ 会使 $\mathbb{E}(​​y|x_1, x_2)$ 乘以 $e^{\beta_2} e^{\beta_3}$。
$\beta_2$ 和 $\beta_3$ 都具有统计显著性，足以证明上述事实吗？
或者我需要测试两者对 $y$ 的影响也具有统计显著性？在这种情况下，对 $\beta_2+\beta_3&gt;0$ 进行单侧 t 检验是否足够？]]></description>
      <guid>https://stats.stackexchange.com/questions/659543/test-significance-of-effect-of-a-variable-in-log-linear-model-with-interaction-t</guid>
      <pubDate>Sat, 04 Jan 2025 22:36:32 GMT</pubDate>
    </item>
    <item>
      <title>寻找多项式似然和拉普拉斯先验的后验</title>
      <link>https://stats.stackexchange.com/questions/659538/finding-posterior-of-multinomial-likelihood-and-laplace-prior</link>
      <description><![CDATA[使用狄利克雷先验和多项似然模型，可以推导出离散事件频率估计的后验分布。可以通过计算参数的后验均值估计来应用伪计数技术。假设对于 $\mathbf{n}$ 个可能的离散结果，存在均匀先验和多项模型，我正在寻找这些结果的概率向量 $\boldsymbol{\theta}$ 的后验分布。我来这里是为了验证我的发现。
推导：
后验来自贝叶斯规则：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{P(\mathbf{n} \mid \boldsymbol{\theta}) P(\boldsymbol{\theta})}{P(\mathbf{n})}$。
似然项
多项式似然为：
$P(\mathbf{n} \mid \boldsymbol{\theta}) = \frac{N!}{\prod_{i=1}^K n_i!} \prod_{i=1}^K \theta_i^{n_i},$
其中 $N = \sum_{i=1}^K n_i$ 是观测总数。
先验项
先验是狄利克雷分布：
$P(\boldsymbol{\theta}) = \frac{1}{Z(\boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{\alpha_i - 1},$
带有归一化常数：
$Z(\boldsymbol{\alpha}) = \frac{\Gamma\left(\sum_{i=1}^K \alpha_i\right)}{\prod_{i=1}^K \Gamma(\alpha_i)}$。
合并项
后验变为：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{\frac{N!}{\prod_{i=1}^K n_i!} \prod_{i=1}^K \theta_i^{n_i} \cdot \frac{1}{Z(\boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{\alpha_i - 1}}{P(\mathbf{n})}$。
简化分子：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{\frac{N!}{\prod_{i=1}^K n_i!} \frac{1}{Z(\boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{n_i + \alpha_i - 1}}{P(\mathbf{n})}$。
规范化
确保$P(\boldsymbol{\theta} \mid \mathbf{n})$积分为1，归一化因子$P(\mathbf{n})$必须是：
$P(\mathbf{n}) = \frac{N!}{\prod_{i=1}^K n_i!} \cdot \frac{Z(\boldsymbol{\alpha})}{Z(\mathbf{n} + \boldsymbol{\alpha})}$。
此处：
$Z(\mathbf{n} + \boldsymbol{\alpha}) = \frac{\Gamma\left(\sum_{i=1}^K (n_i + \alpha_i)\right)}{\prod_{i=1}^K \Gamma(n_i + \alpha_i)}$.
最终后验
后验分布简化为：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{1}{Z(\mathbf{n} + \boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{n_i + \alpha_i - 1}$.

均匀先验
我们使用拉普拉斯先验（不要与拉普拉斯分布混淆），它对应于均匀先验（$\boldsymbol{\alpha} = \mathbf{1}$)，其中 $\mathbf{1}$ 是一个向量，其长度与 $\mathbf{n}$ 的长度相对应。
$P(\boldsymbol{\theta} \mid \mathbf{n}) = D(\mathbf{n} + \mathbf{1}; \boldsymbol{\theta}) = \frac{1}{Z(\mathbf{n} + \mathbf{1})} \prod_{i=1}^K \theta_i^{n_i}$。
请随意评论此推导。]]></description>
      <guid>https://stats.stackexchange.com/questions/659538/finding-posterior-of-multinomial-likelihood-and-laplace-prior</guid>
      <pubDate>Sat, 04 Jan 2025 20:11:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么这么多问题是线性的以及如何解决非线性问题？</title>
      <link>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</link>
      <description><![CDATA[我这学期选修了一门深度学习 Python 课，我们正在学习线性代数。
上一节课，我们从头开始“发明”了梯度下降的线性回归（之前做过最小二乘法），我们讨论了定义假设、损失函数、成本函数等。
为什么许多问题可以看作是线性的，而“只是试图找到方程 Ax = b 的解”？
可以通过最小二乘法或训练神经网络等方法来实现这一点。
在现实世界中，大多数问题都不是线性的。
由于线性代数仅适用于线性函数，那么如何解决这些问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</guid>
      <pubDate>Sat, 04 Jan 2025 19:41:00 GMT</pubDate>
    </item>
    <item>
      <title>Mann-Whitney-U 和 Mood 的独立样本中值检验是分析两个文化样本差异的正确方法吗？</title>
      <link>https://stats.stackexchange.com/questions/659534/is-a-mann-whitney-u-and-moods-median-test-for-independent-samples-the-correct-m</link>
      <description><![CDATA[第一个问题，如果太长，我深表歉意。我设计了一个双语问卷，用他们的母语对两个不同国籍的人进行调查，试图在一个通用的文化尺度上区分他们的态度水平。由于时间限制，无法进行预测试，语言 1 的 C.-α = 0,546（n = 112），语言 2 的 C.-α = 0,774（n = 74），语言 1 的总体辨别能力很差，但语言 2 的辨别能力很好。语言 1 产生了一个非参数样本，语言 2 产生了一个参数样本，通过对独立样本进行 Kolmogorov-Smirnov 检验进行测试。对改进的问卷进行了双重检查（每种语言删除了不同的项目），结果仍然相同。
我通过应用 Mann-Whitney-U 检验了均值差异的假设，通过应用情绪中位数检验检验了中位数的假设。两者都给出了被拒绝的零假设，因此结果很重要。这是使用混合参数和非参数独立样本案例进行测试的正确方法吗？
考虑到语言 1 版问卷的低 cronbach&#39;s alpha 和判别力，有没有办法计算错误发现的可能性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659534/is-a-mann-whitney-u-and-moods-median-test-for-independent-samples-the-correct-m</guid>
      <pubDate>Sat, 04 Jan 2025 17:49:50 GMT</pubDate>
    </item>
    <item>
      <title>处理一次膨胀计数数据而不是零膨胀计数数据</title>
      <link>https://stats.stackexchange.com/questions/659503/handling-one-inflated-count-data-instead-of-zero-inflated</link>
      <description><![CDATA[处理零膨胀数据时需要零膨胀模型和 Hurdle 模型，或者考虑到研究使用截断泊松或 NB 模型似乎合适。但是，如果数据中不存在 0 计数，而是存在 1 的潜在膨胀，该如何处理？这是否与零膨胀类似，还是事件未在大量观察中发生（零膨胀）的情况是进行调整的具体原因？（也就是说，在建模计数方面，没有零的数据集中的一次膨胀与零膨胀数据集有何不同？）]]></description>
      <guid>https://stats.stackexchange.com/questions/659503/handling-one-inflated-count-data-instead-of-zero-inflated</guid>
      <pubDate>Fri, 03 Jan 2025 18:39:46 GMT</pubDate>
    </item>
    <item>
      <title>统计学中帽子符号的混淆</title>
      <link>https://stats.stackexchange.com/questions/659390/confusion-on-the-hat-symbol-in-statistics</link>
      <description><![CDATA[学习统计学中的不同符号让我感到困惑。
在基本的线性回归中，我们写：
$$Y = \beta_0 + \beta_1 X + \epsilon$$
$$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 X$$
$$\hat{\epsilon} = y - \hat{y}$$
这是因为误差仅存在于理论模型中，上限位于估计值之上，而残差（$\hat{\epsilon}$）取决于估计量，因此它有一个上限。
除此之外，我越来越困惑。
例如，关于 $Y$ 的边际分布，这两个陈述是否正确？

$$Y \sim N(X^T \beta, \sigma^2) \implies E(Y) = X^T \beta$$
$$Y \sim N(X^T \hat{\beta}, \hat{\sigma}^2) \implies E(Y) = X^T \beta$$

关于 $Y$ 的条件分布，这两个陈述是否正确？

$$E(Y \mid X) = \beta_0 + \beta_1 X$$
$$E(Y \mid X, \beta, \sigma^2) = \beta_0 + \beta_1 X$$
$$E(Y \mid X, \hat{\beta}, \hat{\sigma}^2) = \beta_0 + \beta_1 X$$

一般来说，我知道一旦你对左边的某个东西取期望，右边就会失去帽子。但我想知道，也许这些陈述中的一些实际上是等价的，只是陈述 1)（在条件和边际陈述中）是简写符号，而其他陈述实际上等同于 1)？
如能帮助澄清有关帽子符号和期望的困惑，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659390/confusion-on-the-hat-symbol-in-statistics</guid>
      <pubDate>Tue, 31 Dec 2024 02:39:46 GMT</pubDate>
    </item>
    </channel>
</rss>