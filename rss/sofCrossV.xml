<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 01 Jan 2024 15:13:30 GMT</lastBuildDate>
    <item>
      <title>使用对数正态分布拟合数据（最大似然估计）</title>
      <link>https://stats.stackexchange.com/questions/635963/fitting-the-data-using-lognormal-distribution-maximum-likelihood-estimation</link>
      <description><![CDATA[我正在尝试编写一个代码，使用最大似然估计对数正态分布的参数（平均值，标准差）。
我的目标是给定xdata，对数正态分布应该具有给定数组ydata的概率。
我相信我在定义似然函数时犯了一些错误。
这是我现在使用的代码：
ydata = np.array([0.03, 0.832])
xdata = np.array([0.5, 0.7])
im_log = np.log(xdata)

# 打印结果的格式
FORMAT_STRING = “{:&lt;20}{:&lt;20}{:&lt;20}”
打印（FORMAT_STRING.format（“sigma”，“beta”，“log_likelihood_sum”））

def neg_log_likelihood_sum(params, im_l):
    西格玛, 贝塔 = 参数

    # 计算正态分布的累积分布函数（CDF）
    fragility_curve = stats.norm(np.log(sigma), beta).cdf(im_l)

    # 计算可能性
    可能性 = ydata-fragility_curve

    # 计算对数似然
    log_likelihood = np.log(可能性)

    # 计算负对数似然
    neg_log_likelihood = np.sum(log_likelihood)

    print(f&quot;sigma: {sigma}, beta: {beta}, neg_log_likelihood_sum: {neg_log_likelihood}&quot;)
    返回-neg_log_likelihood

# 使用partial修复im_l参数
neg_log_likelihood_sum_partial = 部分(neg_log_likelihood_sum, im_l=im_log)

# 显式使用优化模块
res = optimize.minimize(neg_log_likelihood_sum_partial, x0=(1.3, 0.4), method=“Nelder-Mead”)

打印（解析）
x = np.linspace(0, 10, 100)
y = stats.norm(np.log(res[&quot;x&quot;][0]), res[&quot;x&quot;][1]).cdf(np.log(x))
# 绘制数据、拟合曲线和分布
plt.plot(xdata, ydata, &#39;go&#39;, label=&#39;数据&#39;)
plt.plot(x, y, label=&#39;脆弱性曲线（估计参数）&#39;)
plt.图例()
plt.xlabel(&#39;输入变量&#39;)
plt.ylabel(&#39;输出变量&#39;)
plt.title(&#39;拟合曲线和脆性曲线&#39;)
plt.show()
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/635963/fitting-the-data-using-lognormal-distribution-maximum-likelihood-estimation</guid>
      <pubDate>Mon, 01 Jan 2024 14:15:27 GMT</pubDate>
    </item>
    <item>
      <title>pinouin 库中两个样本 t 检验允许的最大样本量是多少？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/635959/what-is-the-maximum-allowed-sample-size-for-two-sample-t-test-in-pingouin-librar</link>
      <description><![CDATA[我目前正在运行测试来比较新旧机器的性能时间。处理大量数据集（超过 50,000 条记录），这使得新机器速度更快。此前，我进行过类似的测试，但在某些技术方面缺乏清晰度。因此，我选择了曼惠特尼 U 检验，为假设得出二元结果。
我投入了专门的时间来学习和更好地理解基础知识，因此我正在使用不同时期的相同数据集重新进行测试。这次我的目标是通过考虑新机器相对于旧机器的百分比改进，并考虑数据的规模和特征来执行更稳健的分析。我正在考虑使用 Pingouin 库中的双样本 t 检验，该库以其输出中提供置信区间而闻名，并且适合中心极限定理下的大样本量。
我发现的信息表明，虽然 t 检验适合较小的样本量（例如 30 个或更少），但 z 检验更适合较大的样本（例如 30 个或更多）。但是，我不确定这是否适用于 Pingouin 中如此大的样本的 ttest 函数，因为该库没有 ztest 函数。如何知道我是否可以自信地利用 Pinouin 的 ttest 来处理如此大的样本量？任何意见、建议、推荐都会非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/635959/what-is-the-maximum-allowed-sample-size-for-two-sample-t-test-in-pingouin-librar</guid>
      <pubDate>Mon, 01 Jan 2024 13:26:30 GMT</pubDate>
    </item>
    <item>
      <title>ADI 和 CoV - 根据数据集移动阈值？</title>
      <link>https://stats.stackexchange.com/questions/635954/adi-and-cov-move-thresholds-based-on-dataset</link>
      <description><![CDATA[我目前正在从事需求预测工作。在我的在线研究过程中，我了解到用于需求分类的方法，这有助于我们专注于具有更好预测能力的系列等。因此，需求的分类主要基于变异系数（CoV）、平均需求间隔（ADI） ）。这引导我们进行 ABC XYZ 细分等分析和需求分类，例如 - 间歇性、块状、不稳定、平滑等。
只有当它们具有固定的阈值（就像我经常在网上看到的那样）并且它们都使用相同的阈值截止值（至少基于我在网上曝光的文章）时，上述所有方法才有意义吗？您可以参考 此处和此处
1.需求平稳（ADI &lt; 1.32 且 CV² &lt; 0.49）
2.间歇性需求（ADI≥1.32且CV²＜0.49）
3.需求不稳定（ADI&lt;1.32且CV²&gt;=0.49）
4.块状需求（ADI &gt;= 1.32 且 CV² &gt;= 0.49）
所以，我的问题，
a) 是否应该提醒这些阈值以反映我们的数据集？例如：我可以在 CV 上运行 1D-Kmeans 聚类并识别数据中的自然中断，以提​​出 XYZ 分割或需求分类 ADI 或 CV**2
b) 我们是否应该仅考虑活跃期（非零销售时间段）或完整时间段（使用客户不活跃的时间段）来计算平均销售额]]></description>
      <guid>https://stats.stackexchange.com/questions/635954/adi-and-cov-move-thresholds-based-on-dataset</guid>
      <pubDate>Mon, 01 Jan 2024 12:16:42 GMT</pubDate>
    </item>
    <item>
      <title>我可以对非整数的计数数据使用简单回归吗？</title>
      <link>https://stats.stackexchange.com/questions/635950/can-i-use-simple-regression-for-means-of-count-data-that-are-not-whole-numbers</link>
      <description><![CDATA[我是统计初学者，只需要了解基础知识。我已经学习了简单回归、逻辑回归和泊松回归，并且正在尝试一些问题。
我有一组计数数据，这些数据已对重复样本进行平均，以便为每个实验图创建平均计数（因此不是整数）的数据集。这些平均数据点的分布不正常（它是正偏态） - 我认为这对于计数数据来说是预期的。我的笔记说您应该使用泊松来计算计数数据，但仅当值为整数时。我没有原始数据点，只有平均值。
我尝试了一个简单的回归，残差对我来说看起来不错 - 这是正确的方法吗？我在下面附上了 Q-Q 图。
我还添加了计数平均值（y 轴）相对于自变量（x 轴）的散点图，以及显示计数平均值非正态分布的直方图。


]]></description>
      <guid>https://stats.stackexchange.com/questions/635950/can-i-use-simple-regression-for-means-of-count-data-that-are-not-whole-numbers</guid>
      <pubDate>Mon, 01 Jan 2024 10:16:49 GMT</pubDate>
    </item>
    <item>
      <title>我试图理解一篇研究论文，但我无法理解 https://ieeexplore.ieee.org/document/9527655 中方程的工作原理 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635947/im-trying-to-understand-a-research-paper-but-i-couldnt-understand-the-working</link>
      <description><![CDATA[在本文中，他们使用模型方程在未标记的目标数据集中学习，如图所示，方程的工作原理对我来说并不清楚，而且第一次馈送是如何进行的对源数据进行 resnet，然后分别定位数据，帮助模型提高其性能。当他们尝试拉出训练图像中的每个图像时，他们会将所有图像彼此分开，然后使相似的图像更接近。我已经理解他们想要做什么，但无法理解图像中显示的数学公式。我会建议那些给出答案的人请浏览一次研究论文。我无法理解用于在类上进行分配的函数的工作原理。]]></description>
      <guid>https://stats.stackexchange.com/questions/635947/im-trying-to-understand-a-research-paper-but-i-couldnt-understand-the-working</guid>
      <pubDate>Mon, 01 Jan 2024 09:06:37 GMT</pubDate>
    </item>
    <item>
      <title>了解蒙特卡罗积分中的重要性采样</title>
      <link>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</guid>
      <pubDate>Mon, 01 Jan 2024 05:16:12 GMT</pubDate>
    </item>
    <item>
      <title>帮助理解 Cohen's D 在 lme 中进行成对比较</title>
      <link>https://stats.stackexchange.com/questions/635928/help-understanding-cohens-d-for-pairwise-comparisons-in-lme</link>
      <description><![CDATA[审稿人要求我提供成对、计划比较的效果大小。在实验设计中，我有一个固定因素和三个条件（一致性）。通道&amp;主题是随机效应。我想报告 Cohen 的 D 三个计划比较（一致性 1 - 一致性 2；一致性 1 - 一致性 3；一致性 2 - 一致性 3）。然而，当我计算 Cohen&#39;s D 时，我得到两个效应大小，一个标记为一致性 2 (d = .732)，另一个标记为一致性 3 (d = .296)。首先，我不确定这些效果大小指的是哪些比较，并且输出仅提供两种效果大小。其次，我怎样才能得到第三次比较的科恩 D 值？
这是我的代码：
PdatFIN$RT_target &lt;- as.numeric(PdatFIN$RT_target)
PdatFIN$一致性 &lt;- as.factor(PdatFIN$一致性)
str(PdatFIN)
m &lt;- lmer(RT_target ~ 一致性 + (1 | 主题) + (1 | 段落), PdatFIN);摘要(m)；方差分析(米)
lme.dscore(m,数据=PdatFIN,类型=“lme4”)
m.contrasts &lt;- emmeans(m,“一致性”)
对(m.contrasts)

这是我的输出：
&lt;前&gt;&lt;代码&gt;组：1
             vars n 均值 SD 中值 修剪疯狂最小值 最大范围 偏斜峰度 se
RT_目标 1 148 1709.04 527.09 1631 1697.14 650.12 846 2974 2128 0.22 -1.06 43.33
组别：2人
             vars n 均值 SD 中值 修剪疯狂最小值 最大范围 偏斜峰度 se
RT_目标 1 162 2137.73 741.01 2056.5 2081.52 717.58 897 4414 3517 0.70 0.34 58.22
组别：3人
             vars n 均值 SD 中值 修剪疯狂最小值 最大范围 偏斜峰度 se
RT_目标 1 166 1888.73 736.85 1740 1811.35 708.68 750 4318 3568 1.01 0.83 57.19

REML [&#39;lmerMod&#39;] 拟合线性混合模型
公式：RT_target ~ 一致性 + (1 | 主题) + (1 | 段落)
   数据：PdatFIN

REML 收敛准则：7314.2

缩放残差：
    最小 1Q 中值 3Q 最大
-2.0682 -0.6320 -0.1771 0.5346 4.1376

随机效果：
 组名称方差标准差
 主题（拦截）203923 451.6
 通过（拦截）23091 152.0
 剩余 239054 488.9
obs 数量：476，组：受试者，30；通道，18

固定效果：
             估计标准。误差t值
（拦截）1711.58 98.75 17.333
一致性2 427.71 56.19 7.612
一致性3 173.18 55.99 3.093

固定效应的相关性：
            (Intr) Cnsst2
一致性2 -0.301
稠度3 -0.303 0.532
偏差表分析（II 型 Wald 卡方检验）

响应：RT_target
             Chisq Df Pr(&gt;Chisq)
稠度 59.216 2 1.385e-13 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
&gt; #科恩斯d
&gt; lme.dscore(m,数据=PdatFIN,类型=“lme4”)
                    t df d
一致性2 7.612028 432.5373 0.7320127
一致性3 3.092820 434.6247 0.2967068
&gt; m.contrasts &lt;- emmeans(m,“一致性”)
&gt;对(m.contrasts)
 对比估计 SE df t.ratio p.value
 一致性 1 - 一致性 2 -428 56.2 432 -7.607 &lt;.0001
 一致性 1 - 一致性 3 -173 56.1 434 -3.090 0.0060
 一致性2 - 一致性3 255 54.3 429 4.688 &lt;.0001

自由度方法：kenward-roger
P 值调整：用于比较 3 个估计值的 tukey 方法

我非常感谢您的帮助和指导。我是 LME 的新手，试图解释我的输出是一个挑战。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/635928/help-understanding-cohens-d-for-pairwise-comparisons-in-lme</guid>
      <pubDate>Sun, 31 Dec 2023 17:49:27 GMT</pubDate>
    </item>
    <item>
      <title>经验分布（直方图箱）的比率是否显示出它们的差异？</title>
      <link>https://stats.stackexchange.com/questions/635918/does-taking-the-ratio-of-empirical-distributions-histogram-bins-show-their-dif</link>
      <description><![CDATA[背景
我有两个经验分布，均来自社交媒体数据。
第一个代表约 480 万个帖子的广泛样本以及每个帖子作者拥有的关注者数量。分布如下：

第二个是专门向我推荐的 1020 个帖子的较小样本。分布如下：

从目视检查中可以明显看出，如果忽略尺度并对分布进行归一化，它们将彼此非常不同。
我已经对这些分布进行了标准化，并采用了推荐分布与广泛分布的比率。我所说的比率是指将推荐故事的 bin 值除以广泛故事的 bin 值。我将结果绘制为散点图：
$$ R_i = \frac{r_i}{b_i}$$
其中 $R_i$ 是为 bin 位置 $i$ 计算的比率，$r_i$ 是推荐故事分布的 bin 位置 $i$ 中故事的标准化数量，并且 $b_i$ 是广泛故事分布的 bin 位置 $i$ 中故事的标准化数量。
它显示了一个有趣的模式。该比率随着追随者数量的增加而增加。由此，我推断，当您获得更多关注者时，您被推荐的机会就会增加。我预料到了我找到的结果，但我不知道它是否有意义。
问题
如果您有经验分布（定义为具有相同组箱的直方图），那么采用它们的箱的比率是否可以让您了解它们之间的差异？特别是关于管理每个创建的可能行为？]]></description>
      <guid>https://stats.stackexchange.com/questions/635918/does-taking-the-ratio-of-empirical-distributions-histogram-bins-show-their-dif</guid>
      <pubDate>Sun, 31 Dec 2023 14:13:58 GMT</pubDate>
    </item>
    <item>
      <title>如果 Cov(X,Y)=Var(Y)，X 和 Y 之间的依赖关系是什么？</title>
      <link>https://stats.stackexchange.com/questions/635725/if-covx-y-vary-what-is-the-dependence-between-x-and-y</link>
      <description><![CDATA[在一个问题中我发现
$$Cov(X,Y)=Var(Y),$$
其中 $X$ 和 $Y$ 是随机变量。
关于 $X$ 和 $Y$ 之间的线性相关性我可以得出什么结论？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635725/if-covx-y-vary-what-is-the-dependence-between-x-and-y</guid>
      <pubDate>Wed, 27 Dec 2023 19:05:08 GMT</pubDate>
    </item>
    <item>
      <title>概率密度函数乘积和积分的含义</title>
      <link>https://stats.stackexchange.com/questions/635658/the-meaning-of-probability-density-functions-product-followed-by-an-integration</link>
      <description><![CDATA[Scipy 的 KDE 对象允许集成函数乘以另一个 KDE 对象。我认为这意味着用于估计两个分布之间的距离。据我了解，为了保持一致的度量，在积分之前需要平方根，类似于 $$BC(P,Q)= 给出的 Bhattacharyya 系数的定义\int_\chi\sqrt{p(x)q(x)}dx$$ 因此有一个问题：这个输出的解释是什么？
PS：我已经看到另一个问题的这个答案，但它似乎不相关，因为它需要额外的标准化参数。]]></description>
      <guid>https://stats.stackexchange.com/questions/635658/the-meaning-of-probability-density-functions-product-followed-by-an-integration</guid>
      <pubDate>Tue, 26 Dec 2023 14:21:51 GMT</pubDate>
    </item>
    <item>
      <title>如何识别样本正态分布的直方图</title>
      <link>https://stats.stackexchange.com/questions/635958/how-to-recognize-my-histogram-chart-for-normal-distribution-of-samples</link>
      <description><![CDATA[我完成了一个行动研究项目，并使用 DART 提高了学生的阅读理解能力。我只是为了结果而比较手段。现在我要写一篇文章，我将应用 $t$ 测试以获得更好的结果。我正在使用 Google Sheets 检查样本的正态分布。我制作了一个图表，但不明白。
我把全班分成了两组，即对照组（不进行治疗）和实验组（进行治疗）。我制作了图表只是为了检查对照组的结果，但我无法理解分布是否正常。查看下图，请说明它是否显示正态分布。
我上传了一张图像，仅显示对照组的结果：
]]></description>
      <guid>https://stats.stackexchange.com/questions/635958/how-to-recognize-my-histogram-chart-for-normal-distribution-of-samples</guid>
      <pubDate>Mon, 25 Dec 2023 11:08:59 GMT</pubDate>
    </item>
    <item>
      <title>“统计模型”这个概念与（监督）机器学习无关吗？</title>
      <link>https://stats.stackexchange.com/questions/621152/is-the-concept-statistical-model-irrelevant-in-supervised-machine-learning</link>
      <description><![CDATA[在监督机器学习中，我们得到一组数据
$\{x_i\}_{i=1}^N$ 其中每个数据都与一个标签关联 $\{ y_i\}_{i = 1}^N$。
我们希望创建/训练函数 $f$ 来完成几件事。

创建一条最佳拟合曲线：$f: x_i \to y_i$，以使指标（训练误差）最小化。

回归：为新数据分配实际值

分类：为新数据分配离散标签


这些是监督机器学习最常见的任务。深度神经网络是最常用的通用函数形式 $f$ ，可以完成这些任务（封装了线性、逻辑、多类逻辑、概率回归）等等。
请注意我的描述中的一件关键事情：我没有提及任何有关“统计模型”存在的内容。许多机器学习作者在教科书中讨论了这一点。
&lt;小时/&gt;
通过统计模型，我引用了第一句中描述的数据集和标签之间的一些规定关系。
例如：根据https://statmath.wu.ac。在/courses/heather_turner/glmCourse_001.pdf
线性模型为： $y_i = \beta_0 + \beta_1^T x_i + \epsilon_i$ 其中 $\ epsilon_i$ 是一个噪声项。
一般的线性模型是： $y_i = \beta_0 + \beta_1^T x_{1i} + \ldots + \beta_p^T x_{pi} + \epsilon_i$&lt; /跨度&gt;
逻辑回归模型为：$\log(y_i) = \beta_0 + \beta_1^T x_{i} + \epsilon_i$
还有非参数、半参数模型，均遵循以下形式 $y_i = m(x_i) + \epsilon_i$ 其中 $m$ 是一些函数。
&lt;小时/&gt;
我很困惑为什么需要对统计模型进行讨论，特别是在作者试图使用这些统计模型本质上做与机器学习模型相同的事情的情况下。
以下是一些相关问题：

直观上，在现实世界中我们不知道什么是
标签和数据之间的关系。那么为什么要费心创建一个
他们之间的关系？

不属于现代机器学习的一部分
训练/验证/测试例程我们是否需要假设
$x_i$ 和 $y_i$ 之间的关系清晰。它确实没有
向我们提供任何其他信息。

在现代深度监督机器学习中，模型的概念甚至没有被提及。例如，诸如“GoogLeNet 的统计模型是什么”或“LSTM 的统计模型是什么”这样的说法似乎没有意义。我的意思是， $m$ 的函数形式和 $\epsilon_i$ 上的噪声假设是什么，&lt; span class=&quot;math-container&quot;&gt;$y_i = m(x_i) + \epsilon_i$ 用于 DenseNet 或 U-Net 等？


有人可以帮我理解这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/621152/is-the-concept-statistical-model-irrelevant-in-supervised-machine-learning</guid>
      <pubDate>Tue, 11 Jul 2023 23:54:54 GMT</pubDate>
    </item>
    <item>
      <title>对测试集文本（无标签）进行预训练可以吗？</title>
      <link>https://stats.stackexchange.com/questions/611877/is-pretraining-on-test-set-texts-without-labels-ok</link>
      <description><![CDATA[编辑：浏览本文后6，我将这个问题的范围缩小到NLP问题。摘要的相关摘录（强调我自己的）：
&lt;块引用&gt;
我们证明，无监督预处理实际上会给交叉验证估计带来很大的偏差，并可能损害模型选择。 这种偏差可能是正的，也可能是负的，其确切大小以复杂的方式取决于问题的所有参数。

动机
使用测试集标签来训练测试集特征显然是错误的。但在许多机器学习竞赛中，发布测试集功能并允许参与者对其进行训练是标准做法。一个例子是 NLP 中的真实世界注释少样本任务 (RAFT) 基准。1以下是 RAFT论文（强调我自己的）：
&lt;块引用&gt;
对于每项任务，我们都会发布一个包含 50 个示例的公共训练集和一个更大的未标记测试集。 我们鼓励对未标记示例进行无监督预训练和开放域信息检索。

在 RAFT 竞赛中，您可以通过在您可能训练的同一组未标记文本上运行模型来提交预测。在 NLP 中，训练未标记文本的常见方法是训练一个语言模型，该模型根据其他标记来预测标记。将此过程应用于特定域的数据集通常称为“域适应”。
我知道发布测试集功能对于主办竞赛的人很有帮助，因为它允许参与者提交预测而不是模型/代码。我还了解到，在现实世界的模型开发中，您可能观察到大量未标记的文本。但我认为关键的区别在于，在现实世界中，您无法访问样本外文本。
问题
在（样本内）测试集文本上训练模型，然后在相同的测试集上评估该模型是否是样本外性能的乐观估计？
一个听起来合理的假设是，对（样本内）测试集文本进行训练会导致测试集预测和测试集标签之间存在相关性，这是一个乐观的估计量（至少对于线性回归，请参见 ESL 中的方程 7.21&lt; sup&gt;2）。但对于这种依赖究竟是如何在没有测试集标签的测试集文本上进行训练而产生的，我没有任何争论。
我的PCA实验结果对机器学习竞赛有重要意义：如果测试很少如果集合观测值和特征表现出高等级，那么可以通过在测试集特征上拟合 PCA 来人为地减少测试集上的误差。
我很好奇是否可以在 NLP 中观察到类似类型的结果，这是标准实践&lt; /a&gt; 在分类任务之前训练未标记文本的语言模型。3 我有一种感觉，部分答案就在论文的某个地方 关于因果和反因果学习4或其子数据收集的因果方向很重要：因果和反因果学习对 NLP 的影响5。这些论文表明，领域适应应该只对文本导致目标的数据有帮助。
参考文献

亚历克斯、尼尔等人。 “RAFT：现实世界的少量文本分类基准。” arXiv 预印本 arXiv:2109.14076 (2021)。

Hastie、Trevor 等人。统计学习的要素：数据挖掘、推理和预测。卷。 2. 纽约：施普林格，2009 年。

Gururangan、Suchin 等人。 “不要停止预训练：使语言模型适应领域和任务。” arXiv 预印本 arXiv:2004.10964 (2020)。

Schölkopf、Bernhard 等人。 “关于因果学习和反因果学习。” arXiv 预印本 arXiv:1206.6471 (2012)。

金志敬，等。 “数据收集的因果方向很重要：因果和反因果学习对 NLP 的影响。” arXiv 预印本 arXiv:2110.03618 (2021)。

莫斯科维奇、阿米特和萨哈龙·罗塞特。 “关于由于无监督预处理导致的交叉验证偏差。”英国皇家统计学会杂志 B 系列：统计方法 84.4 (2022)：1474-1502。

]]></description>
      <guid>https://stats.stackexchange.com/questions/611877/is-pretraining-on-test-set-texts-without-labels-ok</guid>
      <pubDate>Tue, 04 Apr 2023 19:17:08 GMT</pubDate>
    </item>
    <item>
      <title>统计方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/605730/what-is-the-statistical-method</link>
      <description><![CDATA[对于这个问题可能具有哲学性质，我提前表示歉意，但是我现在想从这个网站而不是哲学交流中得到答案。我也来自纯数学背景，所以我可能对统计学领域的运作方式有一些误解。数学的科学方法和公理化方法试图解决区分科学与伪科学、数学与“伪数学”的问题。分别。我希望知道区分统计与“伪统计”的类似问题的答案。我将在下面提出对前面问题的一个可能的答案，我想听听这个网站上的统计学家的意见，我是否有正确的答案。
我对科学方法的看法基本上是下面的流程图：

例如，一位科学家可能生活在二维表面上，她总是观察到任何三角形的角度总和为 180 度。根据这一观察，我们的科学家可能会假设该表面具有欧几里德几何形状。这个假设将做出一个预测，例如毕达哥拉斯定理在我们的表面是正确的。科学家将通过更多的实验来检验这一预测的有效性。如果预测被证明是错误的，那么假设就会被抛弃。如果预测结果与进一步的实验相符，那么科学家对她的模型的信心就会增加一点，她会使用该假设进行进一步的预测并在持续的过程中对其进行测试。
我尝试修改上面的场景进行统计。

第 1 步：我们收集一些关于现实世界现象的观察结果。这种现象可以是抛硬币
第 2 步：假设现实世界中抛硬币 $n$ 次的现象可以建模为伯努利过程 $B(n,\frac{1}{2})$。我认为假设的提出是将数学结构与现实世界现象相匹配的过程。在上面的场景中，我们关心的是将我们生活的表面的现实世界现象与某些数学几何结构相匹配，而这里我们关心的是将抛硬币的现实世界现象与某些数学概率结构相匹配。
下一步是做出预测。在调查开始之前，我们按照惯例就某个显着性水平达成一致，可以说是 $99$%。如果我们假设的概率模型中的某个事件 $E$ 具有 $P(E)\geq 0.99$，那么它算作一个预测。例如，在我们的例子中，切比雪夫不等式将给出 $$P(\text{$10,000$ 试验后正面的比例将位于区间 $]0.45,0.55[$})\ geq 0.99$$。因此，我们预测，如果我们抛硬币 $10,000$ 次，那么正面的比例将在 0.45,0.55 之间
第 4 步：我们通过实验测试我们的预测。我们实际上抛硬币一万次。如果预测与实证结果一致，那么我们对假设的信心就会增加。如果预测与实证结果不符，则假设将被抛弃，并应进行进一步的调查。也许硬币是有偏差的，我们的概率模型应该是 $B(n,p)$，也许硬币抛掷会影响后来的抛掷，例如硬币温度发生变化或者它的形状发生变化，从而改变了它的机制，因此我们假设抛硬币的独立性是不合适的，并且不会产生好的预测......等等。

问题：我对统计工作原理的理解正确吗？如果是，我们根据什么选择显着性水平？]]></description>
      <guid>https://stats.stackexchange.com/questions/605730/what-is-the-statistical-method</guid>
      <pubDate>Fri, 17 Feb 2023 10:02:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 进行多重比较校正后计算 wilcoxon 检验的效应大小</title>
      <link>https://stats.stackexchange.com/questions/596878/calculating-effect-size-of-wilcoxon-test-after-correction-for-multiple-compariso</link>
      <description><![CDATA[我正在尝试比较两种处理变化后的两种氨基酸浓度。数据不是正态分布的，所以我必须使用非参数检验。我计算了调整后的 p 值，但现在我还想要效应大小。是否可以选择计算调整后的 p 值的效应大小？
我使用 Wilcox_test 函数来获取 p 值。
df %&gt;%
  group_by(氨基酸) %&gt;%
  wilcox_test(浓度 ~ 治疗，配对 = TRUE) %&gt;%
  调整p值（方法=“holm”）

有一个函数可以计算硬币库中的效应大小，但它没有为我提供纠正多重比较的选项。
 df %&gt;%
  group_by(氨基酸) %&gt;%
  wilcox_effsize（浓度 ~ 治疗，配对 = TRUE）

有解决方案吗？找不到有关该特定主题的任何内容
编辑：
我添加了数据的箱线图。每次治疗后，我们从 18 个人身上采集了血液样本。每个人都接受两种治疗方案，间隔 7-14 天。
]]></description>
      <guid>https://stats.stackexchange.com/questions/596878/calculating-effect-size-of-wilcoxon-test-after-correction-for-multiple-compariso</guid>
      <pubDate>Thu, 24 Nov 2022 19:22:37 GMT</pubDate>
    </item>
    </channel>
</rss>