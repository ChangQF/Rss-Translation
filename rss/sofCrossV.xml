<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sun, 02 Mar 2025 15:17:17 GMT</lastBuildDate>
    <item>
      <title>关于最小二乘的概念怀疑是一个不适的问题</title>
      <link>https://stats.stackexchange.com/questions/662052/conceptual-doubt-about-least-squares-as-an-ill-posed-problem</link>
      <description><![CDATA[ wikipedia状态

问题有解决方案
该解决方案是唯一的
解决方案的行为随着初始条件的连续变化


和不s的（大胆是我的）：

从上面意义上说的问题不当的问题被称为未解决的问题。一个简单的示例是全局优化问题，因为 Optima的位置通常不是指定目标的参数的连续函数，即使目标本身是这些参数的平滑函数。 

我知道，如果 $ x^t \，x $ &lt; / span&gt;不是可逆的 /是单数字，那么最小二乘可能没有唯一的解决方案。但是，在最小二乘的情况下，不是均方损失参数的连续函数吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662052/conceptual-doubt-about-least-squares-as-an-ill-posed-problem</guid>
      <pubDate>Sun, 02 Mar 2025 15:13:16 GMT</pubDate>
    </item>
    <item>
      <title>Nesterov在极端学习机器中加速梯度下降，而高正规化</title>
      <link>https://stats.stackexchange.com/questions/662050/nesterov-accelerated-gradient-descent-stalling-with-high-regularization-in-extre</link>
      <description><![CDATA[我正在用一个隐藏的层实现Nesterov加速梯度下降（NAG）。我的损耗函数是带有L2正则化的平均平方错误（MSE）。
我计算的梯度是：
  其中：
 w2是参数矩阵，h是隐藏层激活矩阵（固定在榆树中），d是目标输出，λ是正则化参数。
如果我们选择一个固定的步骤大小，取决于凸α的强度和功能的平滑度β，则该理论可以通过最佳解决方案对间隙的单调减小提供理论保证，如下面的等式从Bubeck 2015所示：：。
  其中k是函数的条件数。
问题：
如果我选择一个高lambda（等于或高于1），则该理论预测收敛速度更快，因为该函数的条件数较低。这正是我从实验中观察到的。但是，尽管我的算法很快达到了不错的差距，但即使该理论预测单调减少，它也会失速。这是典型学习曲线的一个示例（在理论上的最坏情况间隙，蓝色算法）。 
  我的问题：如何调和这样的事实，即理论预测趋同的束缚，而我的算法由于较小的梯度而被卡住了？这个问题是高λ制度中L2正则化固有的，还是我的实施特定的？任何见解，数学解释或实际建议都将不胜感激！
事先感谢您的帮助！
注意：这与我选择的问题，隐藏层大小和激活功能无关。]]></description>
      <guid>https://stats.stackexchange.com/questions/662050/nesterov-accelerated-gradient-descent-stalling-with-high-regularization-in-extre</guid>
      <pubDate>Sun, 02 Mar 2025 13:48:05 GMT</pubDate>
    </item>
    <item>
      <title>基于DAG的倾向评分加权（PSW）中应包括哪些变量？</title>
      <link>https://stats.stackexchange.com/questions/662047/which-variables-should-be-included-in-propensity-score-weighting-psw-based-on</link>
      <description><![CDATA[我正在执行倾向得分加权（PSW），并使用CDAG构建了我的因果假设（见下文）：

我的DAG中的灰色圆圈代表了实际的混杂因素，我
被确定为影响治疗和结果的变量； 
红色圆圈代表了我的其他临床重要变量
数据集; 
调解人，处理_apprace ，用蓝色描绘。

 我的问题：
计算加权的倾向得分时，应该是：

在PS模型中仅包括实际的混杂因子（灰色圆圈），并评估这些变量的平衡？
在PS模型中包括DAG中描绘的所有变量（调解员除外），然后仅使用实际的混杂因素来估计我的感兴趣结果？
使用不同的选择标准将可变包含在PS加权中？

任何见解或参考都将不胜感激！
  &lt;img alt =“ cdag”]]></description>
      <guid>https://stats.stackexchange.com/questions/662047/which-variables-should-be-included-in-propensity-score-weighting-psw-based-on</guid>
      <pubDate>Sun, 02 Mar 2025 09:48:37 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯混合模型的顺序更新 - 粒子过滤器还是其他？</title>
      <link>https://stats.stackexchange.com/questions/662046/sequential-updating-of-a-bayesian-mixed-model-particle-filters-or-something-el</link>
      <description><![CDATA[我想从具有随机群集变量和进一步固定的预测变量的贝叶斯模型开始，每个预测变量都有群集变量的随机斜率。此外，我想使用贝叶斯更新以重复将新批次的多群集数据纳入模型。目的是能够为决策支持提供模型预测，但随着我们获取新数据的效果，它会变得更好（因此，我不能只等待所有数据模型）。​​
即使我不认为我的系数是动态的，我也被粒子过滤器模型所吸引（因此R封装NimblesMC），因为它们提供了一种方法来维持参数概率分布，而不是经验性的重复更新而不是参数近似值，但仍然保持一定的计算效率（这是我的计算效率（这是粒子）。
该模型需要具有随机斜率的群集的随机因素，因为（a）群集数据是非独立的，并且（b）有很好的理论理由相信固定效应确实会因批量而变化。关键目标是逐渐改善固定参数，我不在乎特定的群集参数或斜率。相同的簇不会在以后的数据批次中重新出现，因此我不需要维护更新特定随机参数的模型。粒子中应该是固定效果和随机的超参数。
我可以为（1）通常相关（并且尽可能访问）的文献提出建议，（2）特定方法（我是在吠叫一些错误的树木吗？也许是一种机器学习方法吗？），（3）具体实施建议（如果我可以在这里问，否则不要介意，否则请不要介意）？
我有8个参数，我的启动数据集具有1280个数据点和32个群集，并且在项目寿命上，我可能会得到大约100个群集，平均约50个数据点。我想尽可能更新模型。
我有一个LLM来写给我的NimblesMC代码，该代码声称它可以实现我在这里概述的内容，但是我不太了解它来信任它。我在实施各种常见的模型方面经验丰富，但是我是一个有贝叶斯统计数据和适当理解它们所需的复杂公式的新手。]]></description>
      <guid>https://stats.stackexchange.com/questions/662046/sequential-updating-of-a-bayesian-mixed-model-particle-filters-or-something-el</guid>
      <pubDate>Sun, 02 Mar 2025 09:38:35 GMT</pubDate>
    </item>
    <item>
      <title>分布距离估计器的渐近方差</title>
      <link>https://stats.stackexchange.com/questions/662019/asymptotic-variance-of-distribution-distance-estimators</link>
      <description><![CDATA[Given I sampled $x_1,\dots,x_n$ from $P_X$ and $y_1,\dots,y_n$ from $P_Y$.请注意， $ x_i，y_i \ in \ mathbb {r}^m $ 。使用样品，我从经验上计算了一些分布距离，例如，地球发动机距离（EMD）和两个分布之间的最大平均差异（MMD）。
是否有一种方法来得出EMD估计器或MMD估计器的方差。我不需要确切的东西 - 我只需要仅取决于 $ n $ 的渐近大o符号。此外，如果我给出的例子是棘手的，那么什么距离允许我们计算方差？
假设 $ cov（x）$ 和 $ cov（y）$ 是常数，而那个 $ m $ 也很常数，
注意：MMD的确切方差在 https：//arxiv.org/arxiv.org/abs/1906.02104  $ n $ 。]]></description>
      <guid>https://stats.stackexchange.com/questions/662019/asymptotic-variance-of-distribution-distance-estimators</guid>
      <pubDate>Sun, 02 Mar 2025 01:03:28 GMT</pubDate>
    </item>
    <item>
      <title>SEM约束 - 数据与理论驱动</title>
      <link>https://stats.stackexchange.com/questions/662018/sem-constraints-data-vs-theory-driven</link>
      <description><![CDATA[我正在估计SEM中的几个嵌套模型。它们是具有不同性别夫妇的二元随机拦截跨滞后面板模型，因此男性和女性数量相等。我对性别差异感兴趣。当参数可以随性别而变化时，会有性别差异，因此某些效果对于一组而不是另一组具有统计学意义。但是，我将这些参数限制为相等，并进行了似然比测试，并且卡方并不重要，这表明通过添加约束对模型拟合没有损害。
现在我感到被撕裂了：我可以通过性别报告免费参数的模型吗？这里最好的道路是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/662018/sem-constraints-data-vs-theory-driven</guid>
      <pubDate>Sun, 02 Mar 2025 00:04:32 GMT</pubDate>
    </item>
    <item>
      <title>对线性混合效应模型假设感到困惑</title>
      <link>https://stats.stackexchange.com/questions/662010/confused-about-linear-mixed-effects-model-assumptions</link>
      <description><![CDATA[当绘图暗示它们不暗示时，为什么在混合模型中以零为中心的随机效应？
我正在使用“得分”的混合效应模型合作。 （ $ y_ {ij} $ ）跨国家和类别。对于国家/地区 $ i $ 和category  $ j $ ， $ y_ {ij {ij} $ 被建模为
  $$
y_ {ij} = \ alpha + u_i + v_j +ε_{ij}
$$  
其中：

态
  $ u_i \ sim n（0，\ sigma_u^2）$ 是国家特定的随机效果
  $ v_j \ sim n（0，\ sigma_v^2）$ 是类别特定的随机效果
  $ \ epsilon_ {ij} \ sim n（0，\ sigma^2）$ 是残差错误

My understanding is that we&#39;re assuming each $u_i$ and $v_j$ follow normal distributions centered at 0. However, when I plot the estimated random effects (using ranef() in R), they&#39;re clearly not all centered at 0 (see attached plot of country-specific random effects).
这似乎与模型假设相矛盾： $ u_i \ sim n（0，\ sigma_u^2）$ 。如果我们假设这些效果来自以零为中心的分布，那么它们为什么不在图中以零的位置看起来为零（请参见国家特定的随机效果 $ u_i $ 下面）？
  我了解每个特定国家都有自己的估计，但是我对：之间的关系感到困惑

模型假设来自 $ n（0，\ sigma_u^2）$ 。
实际未居中的实际估计效果

我是否误解了以零为中心的假设的实际含义？我听说过这些随机效果“模型假设”被称为贝叶斯先验，从概念上讲，这在概念上更容易吞咽，因为这些阴谋并不矛盾模型假设。而是根据数据更新先验。但是...这些不是贝叶斯先生吗？它们是“模型假设”
任何澄清都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/662010/confused-about-linear-mixed-effects-model-assumptions</guid>
      <pubDate>Sat, 01 Mar 2025 21:41:19 GMT</pubDate>
    </item>
    <item>
      <title>对数回归模型中系数的解释</title>
      <link>https://stats.stackexchange.com/questions/661976/interpretation-of-coefficients-in-log-regression-models</link>
      <description><![CDATA[对于基本的线性回归：
在
很清楚地看到对估计参数的解释：
在
  $$ \ frac {dy} {dx} = \ beta_1 $$   
  $ x $ 与估计的 $ \ beta_1 $ 单位更改 $ y $ y $ 。
 我正在尝试理解以下模型相同的互动： 
模型1（log-log）： $$ \ log（y）= \ beta_0 + \ beta_1 \ beta_1 \ log（x） + \ varepsilon $$   
型号2（log-linear）： $$ \ log（y）= \ beta_0 + \ beta_1 x + \ varepsilon $$   
我试图自己得出这些。


模型1：
在
  $$ \ frac {d（\ log（y））} {dx} = \ beta_1 \ frac {d（\ log（x））} {dx} {dx} $$
  $$ \ frac {1} {y} {y} \ cdot \ frac {dy} {dx} = \ beta_1 \ cdot \ cdot \ frac \ frac {1}
  $$ \ frac {dy} {dx} \ cdot \ frac {x} {y} {y} = \ beta_1 $$   
  $$ \ beta_1 = \ frac {dy} {dx} {dx} \ cdot \ frac {x} {y} {y} $$
  $$ \ beta_1 = \ frac {dy/y} {dx/x} $$
来自微积分，我们知道：
  $$ \ text {百分比变化} y = \ frac {y _ _ {\ text {new}}}  -  y _ _ {\ text {old}}}}}}}
在
 $$ \ text {} y = \ frac {\ delta y} {y} {y} $$  
因此：

  $ \ frac {dy} {y} {y} \ of $   $ y $      $ \ frac {dx} {x} {x} \ of $ 百分比 $ x $    

 因此
  $$ \ beta_1 = \ frac {\ text {百分比变化} y} y} {\ text {百分比{百分比变化} x} $ span&gt;  

模型2：
  $$ \ log（y）= \ beta_0 + \ beta_1 x + \ varepsilon $$  
  $$ \ frac {d \ log（y）} {dx} = \ beta_1 $$   
在
  $$ \ frac {dy} {dx} = \ beta_1 \ cdot y $$ y $ $  
  $$ \ frac {dy/y} {dx} = \ beta_1 $$   
因此，解释变为：
  $$ \ beta_1 = \ frac {\ text {百分比{百分比变化} y} y} {\ text {unit change in} x} $    


得出结论：

在模型1中， $ x $ 与估计的 $ \ beta_1 $ 百分比更改 $ y $ y $ y $    
在模型2中， $ x $ 与估计的 $ \ beta_1 $ 百分比变化 $ y $ y $ y $    

 这些是正确的解释吗？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/661976/interpretation-of-coefficients-in-log-regression-models</guid>
      <pubDate>Fri, 28 Feb 2025 19:57:07 GMT</pubDate>
    </item>
    <item>
      <title>詹姆斯 - 斯坦估计器的偏见</title>
      <link>https://stats.stackexchange.com/questions/661943/bias-of-james-stein-estimator</link>
      <description><![CDATA[假设 $ x \ sim n（[\ mu_1 \ space \，\ mu_2 \ space \，\ mu_3]^\ intercal，i_ {3 \ times3}）$  $ 。 （样本尺寸 $ n = 1 $ ） $ [\ mu_1 \ space \，\ mu_2 \ space \ space \，\ mu_3]^\ mu_3]^\ spail $ spail $  $$ \ hat {\ mu} _ {js} = \ left（1- \ frac {1} {\ lvert {x} {x} \ rvert^2} \ right）
计算机模拟（1000000个试验）表明， $ \ hat {\ mu} _ {js} $  $ 略微偏向零，确认直觉，如果 $ \ mu = [1.2 \ mU = [1.2 \ \ \ \ \ \ \ \ face \，1.2] $ 然后 $ 1-1/\ lvert {x} \ rvert^2 $ 将在附近波动 $ 3/4 $ 
但是，我无法在标准参考文献中找到偏见的证据，我不确定如何自己计算理论偏见。詹姆斯 - 斯坦估计器是否有偏见？如果是这样，是否有其偏见的已知闭合形式表达？]]></description>
      <guid>https://stats.stackexchange.com/questions/661943/bias-of-james-stein-estimator</guid>
      <pubDate>Fri, 28 Feb 2025 01:02:44 GMT</pubDate>
    </item>
    <item>
      <title>从两个已知的成对系数中推断出3x3系统中的间接相关性</title>
      <link>https://stats.stackexchange.com/questions/661815/infer-indirect-correlations-in-a-3x3-system-from-two-known-pairwise-coefficients</link>
      <description><![CDATA[假设我知道成对的相关 $ r_ {12} $  and  $ r_ {13} $  $ \ {x_1，x_3 \} $ 。如果我知道 $ x_2 $ 和 $ x_3 $ 是有条件地独立，（如何）我可以计算它们之间的相关性？
我认为我应该能够在构造精度矩阵，假设有条件独立性的地方做（即SET  $ q_ {23} $ 零），然后倒置，但是我还没有完全弄清楚。如果我采用相关矩阵
  $$
\ left（\ begin {array} {cc} 1＆amp; r_ {12} \\ r_ {12}＆amp; 1 \ end end {array} \ right）
$$ 
倒转我得到
 $$
\ left（\ begin {array} {cc} \ frac {1} {1-r_ {12}^2}^2}＆amp; \ frac {-r_ {12}} {1-r_ {12}}^2}^2}^2}^2}
\ frac {-r_ {12}} {1-r_ {12}^2}＆amp; \ frac {1} {1-r_ {12}^2} \ end {array} \ right）
$$  
（我认为）。如果我构造精度矩阵 $ q $ 我知道我想要 $ q_ {23} = q_ {32} = 0 $ 矩阵（或者也许我只是朝错误的方向前进...？）]]></description>
      <guid>https://stats.stackexchange.com/questions/661815/infer-indirect-correlations-in-a-3x3-system-from-two-known-pairwise-coefficients</guid>
      <pubDate>Tue, 25 Feb 2025 01:11:36 GMT</pubDate>
    </item>
    <item>
      <title>时间序列拆分（扩展窗口）与时间序列预测中的k折交叉验证</title>
      <link>https://stats.stackexchange.com/questions/619918/time-series-split-expanding-window-vs-k-fold-cross-validation-in-time-series-f</link>
      <description><![CDATA[我使用ML模型进行时间序列预测（Q-O-Q GDP）。
对于超参数调谐，我将网格搜索与交叉验证。交叉验证是专门的时间序列拆分（使用扩展的窗口方法）。在获得最佳高参数组合的模型后，我在整个火车集合中再次重新训练该模型，并在测试集的一个观察结果上对一个时期进行预测，因此，用于测试模型I也使用了扩展的窗口。我有2个问题：

这种时间序列预测的正确方法？
 i在使用的超参数调谐过程中，而不是时间序列拆分（扩展窗口）k折交叉验证。我知道从理论上讲，这是错误的，因为模型可以训练未来的值并验证过去的值，但是当我使用扩展窗口测试看不见的测试集上的最终模型时，我会获得更好的结果，而不是我要在超级参数调音使用时间段的时间表分开（扩展窗口）。因此，我的问题是，如果这种方法仍然有效，因为我在保持时间依赖性的同时正确测试了模型。

谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/619918/time-series-split-expanding-window-vs-k-fold-cross-validation-in-time-series-f</guid>
      <pubDate>Tue, 27 Jun 2023 18:01:23 GMT</pubDate>
    </item>
    <item>
      <title>关键的Z统计与样本z统计</title>
      <link>https://stats.stackexchange.com/questions/539016/critical-z-statistic-vs-sample-z-statistic</link>
      <description><![CDATA[ 一个假设，即种群平均值较小或等于 $ x $ 时，应拒绝当临界z统计量大于样本z统计量。 
如果 $ x = 5 $ ，则语句是对还是错误？答案是错误的，但是为什么？
对于 $ x $ 语句是对还是错误？

我知道这是一个单尾假设，但是我怎么知道我们在谈论哪个尾巴呢？还是可以回答的一般规则2）？
 更新：我将完全发布问题：

以下关于假设检验的哪些陈述最多
准确？
 a）类型I错误是在否定零假设的情况
II型错误是拒绝替代假设
true。
 b）人口平均值小于或相等的假设
当关键的Z统计量大于大于
样本z统计。
 c）假设平均值为3，样本平均值
6，以及2的采样平均值2给出样品
z统计量为1.5。

答案是C。]]></description>
      <guid>https://stats.stackexchange.com/questions/539016/critical-z-statistic-vs-sample-z-statistic</guid>
      <pubDate>Tue, 03 Aug 2021 18:33:48 GMT</pubDate>
    </item>
    <item>
      <title>在RL中的SARSA和Q学习算法中，Q值学习期间是否更新了策略？</title>
      <link>https://stats.stackexchange.com/questions/478466/in-sarsa-and-q-learning-algorithms-in-rl-is-policy-updated-during-the-iteration</link>
      <description><![CDATA[在Brunskill教授的视频中“ Stanford CS234 CS234 Winter 2019讲座4”用于模型的控制（ https：//www.youtube.com/watch？ SARSA包括第8行，用于当前策略PI的电子屏幕更新。似乎该代码的结果包括最佳策略PI以及Q（s，a）。 Q学习的代码在1：10：53/1：17：45是相同的。
另一方面，在Sutton和Barto的书中（ https://web.stanford.edu/class/psych209/readings/suttonbartoiprlbook2nded.pdf ）在SARSA算法中（第155页的图6.9）（第155页的图6.9），该策略在itteration中未更新。此代码的结果似乎只是Q（s，a）。 Q学习的代码（第158页的图6.12）是相同的。
在后一种情况下，如何获得最佳政策？我是否基于Q（s，a）进行另一轮贪婪的学习来获得最佳政策？还是可以将Q（s，a）视为2-D表，然后选择最大化每个s q（s，a）的动作？这样的政策与Brunskill教授的算法相同吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/478466/in-sarsa-and-q-learning-algorithms-in-rl-is-policy-updated-during-the-iteration</guid>
      <pubDate>Wed, 22 Jul 2020 19:20:00 GMT</pubDate>
    </item>
    <item>
      <title>XGBOOST和验证数据中的eval_set</title>
      <link>https://stats.stackexchange.com/questions/463870/eval-set-in-xgboost-and-validation-data</link>
      <description><![CDATA[在我的理解中，如果我是从一组模型中挑选的，每个模型都有不同的超参数，那么正确的方法就是这样：首先，将数据分配给 train&gt; train   val 。然后使用 train 拟合模型，然后用 val 进行评分。然后选择具有最高分数的模型和超参数，然后使用 train 和 val 的组合集对其进行重新培训。。

因此，例如，如果我在具有K1，...，K3邻居的KNN型号和带有A1，...，A5树的随机森林模型中选择，我适合所有 3 + 5 = 8 带有 Train&gt; Train  val  val 。然后，我以最佳分数选择模型，例如K2邻居，然后用 train 和 val 组合来对其进行重新培训。
至此，我认为我的理解是正确的。但是当我到达Xgboost时，我真的很困惑。 
在XGBoost拟合函数中，有两个参数使我感到困惑： fround_stopping_rounds 和 eval_set_set 。基于 noreferrer“&gt; documentation&gt;如果基于 eval_set 的分数不会在  ropard_stopping_rounds 回合中改进，则训练停止并返回结果。我的问题是如何在拟合过程中使用验证数据？我正在考虑两种可能性，但是我不确定哪个是正确的，或者是否不确定：
 可能性1 ：
 eval_set 应该是火车集的子集。因此，继续以上面的示例，我应该将 train 拆分为 train_for_train 和 trib_for_val  as  triar_for_val_val 。然后，我应该用与我的KNN和随机森林模型相同的 val 返回的模型。
 可能性2 ： eval_set 不影响树木的建造方式，因此在技术上不用于适合模型。因此，对过度拟合的关注较少。  eval_set 影响有多少个回合，这实际上是在合奏中使用多少树。就像可以使用 val 确定随机森林中树的最佳数量一样，使用 val 可以确定XGBoost中最佳的回合数量也是可以的。因此，可以将 evar_set 设置为 val 在模型拟合期间，用 val 为返回的模型进行评分，然后将分数与其他KNN和随机森林模型进行比较。 
如果可能性2是正确的，那么我的下一个问题是：如果XGBoost具有自动检测到的最佳回合数量，则在所有型号中都具有最高分数，我该如何使用 train&gt; train    val 对其进行重新训练？我看不到文档中此超参数的选项。 
最后，我还与如何使用XGBoost使用交叉验证相混淆了吗？如果我让模型使用 eval_set 和 fresed_stopping_rounds 来决定最佳的回合数，那么当我使用不同的折叠进行火车和验证时，结果将有所不同。或者，如果我让模型决定超参数，则不应该使用交叉验证，并且仅当我是指定超参数集的人时使用的？]]></description>
      <guid>https://stats.stackexchange.com/questions/463870/eval-set-in-xgboost-and-validation-data</guid>
      <pubDate>Fri, 01 May 2020 09:33:56 GMT</pubDate>
    </item>
    <item>
      <title>哪个是更好的估计器，平均功能与平均功能？</title>
      <link>https://stats.stackexchange.com/questions/452227/which-is-a-better-estimator-averaged-functions-vs-a-function-of-an-average</link>
      <description><![CDATA[问题：
假设我们要估计 $ f（\ theta）$ ，并具有预先指定的严格增加函数 $ f $  $ f $ 和一个参数

让 $ \ hat {\ theta} _1 $  and  $ \ hat {\ theta} _2 $ 是 $ \ theta $ $  $ f（\ theta）$ ：

  $ f \ left（\ frac {\ hat {\ theta} _1 + \ hat {\ theta} _2} _2} {2} {2} \ right）
  $ \ frac {f（\ hat {\ theta} _1） + f（\ hat {\ theta} _2）}} {2} $ 。。

我的方法：
我的方法是基于泰勒的扩展 $ f $ 的期望。

   $$ \ Mathbb {e} f \ left（\ frac {\ hat {\ theta} _1 + \ hat {\ theta} _2} _2} _2} _2} {2} {2} \ right）= 
f（\ theta） + \ frac {f&#39;&#39;（\ theta）} {2} \ text {var} \ left（\ frac {\ frac {\ hat {\ theta} _1 + \ hat {\ hat {\ theta}
$$   
   $$ \ Mathbb {e} \ left [\ frac {f（\ hat {\ theta} _1） + f（\ hat {\ theta} 
f（\ theta） + \ frac {f&#39;&#39;（\ theta）} {2} \ left（\ frac {\ frac {\ text {var}（\ hat {\ theta} _1） + \ text {
$$   

在这里，每次期望中的一阶都消失了，因为 $ \ hat {\ theta} _1 $  and  $ \ hat {\ theta} _2 _2 $  nmias dibias。

让我们进一步假设 $ f&#39;&#39;（\ theta）＆gt; 0 $ 。然后，从那以后
 $$ \ label {varineq}
（0 \ le）
\ text {var} \ left（\ frac {\ hat {\ theta} _1 + \ hat {\ theta} _2} {2} {2} \ right）\ le
\ frac {\ text {var}（\ hat {\ theta} _1） + \ text {var}（\ hat {\ theta} _2）} {2}，
$$ 
只要剩余的术语（顺序 $ \ ge ge 3 $ ），第一个估计器（即平均的函数）似乎与 $ f（\ theta）$  $ f（\ theta）$ ）。
最后的不平等来自一个简单的观察：
 $$
\ frac {\ text {var}（\ hat {\ theta} _1） + \ text {var}（\ hat {\ theta} _2）} {2}  -  
\ text {var} \ left（\ frac {\ hat {\ theta} _1 + \ hat {\ theta} _2} {2} {2} \ right）=
\ dfrac {1} {4} \ left（\ text {var}（\ hat {\ theta} _1） + \ text {var}（\ hat {\ theta} _2） -  
2 \ text {cov} \ left（\ hat {\ theta} _1，\ hat {\ theta} _2 \ right）\ right）= \ dfrac {\ dfrac {\ dffrac {\ text {var} {var}（\ hat hat {\ theta} {\ theta} _1- _1- _1- \ hat {
$$  
问题：
我想知道这是否是合乎逻辑的，还有另一种证明更好估计器合理的方法。
编辑：
让我们限制严格增加的 $ f $ 。]]></description>
      <guid>https://stats.stackexchange.com/questions/452227/which-is-a-better-estimator-averaged-functions-vs-a-function-of-an-average</guid>
      <pubDate>Mon, 02 Mar 2020 12:27:27 GMT</pubDate>
    </item>
    </channel>
</rss>