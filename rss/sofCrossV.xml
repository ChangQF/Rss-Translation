<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 13 Feb 2024 12:23:08 GMT</lastBuildDate>
    <item>
      <title>李克特量表 - R</title>
      <link>https://stats.stackexchange.com/questions/639174/likert-scale-r</link>
      <description><![CDATA[我正在做一项作业，需要一些额外的帮助。我想通过使用李克特量表收集的数据来测试三个职业群体（学生、兼职和全职）之间的差异，了解他们对进行多项活动的兴趣。然而，我正在努力解决如何将数据组织到 R 中。举例来说，如果问题是他们是否喜欢遛狗，我是否会将 1 保留为同意，2 保留为中立，3 保留为不同意作为数值在 csv 中还是我应该将其转换为它们所代表的内容？这些组是按列还是按行排列？来自 Likertscale 的数据是否保留为单个细胞，还是我需要总结每个组的反应？我知道我必须使用 Kruskal-Wallis 测试，并且我可以解释所有内容，但我正在努力解决所有内容应该如何显示的初始部分。任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/639174/likert-scale-r</guid>
      <pubDate>Tue, 13 Feb 2024 11:52:51 GMT</pubDate>
    </item>
    <item>
      <title>双变量重现期</title>
      <link>https://stats.stackexchange.com/questions/639173/bivariate-return-periods</link>
      <description><![CDATA[我正在研究干旱特征。我使用 r studio 中的“干旱”包计算了干旱的严重程度和持续时间。我还计算了单变量返回期的持续时间和严重程度。任何人都可以向我提供使用 copula 的 bivaraite（AND 和 OR）返回周期的 R 代码]]></description>
      <guid>https://stats.stackexchange.com/questions/639173/bivariate-return-periods</guid>
      <pubDate>Tue, 13 Feb 2024 11:49:41 GMT</pubDate>
    </item>
    <item>
      <title>如何处理零膨胀数据并在 beta 回归中纳入随机效应</title>
      <link>https://stats.stackexchange.com/questions/639172/how-to-handle-zero-inflated-data-and-incorporate-random-effect-in-beta-regressio</link>
      <description><![CDATA[嘿，
我的响应变量是连续的并且位于 0 和 1 [0,1] 的紧密区间内。它有多余的零并且接近 xero，它是比例数据，我的响应变量是分类的。我发现我的数据遵循 beta 分布。 （我在直方图中看到并应用 fitdistrplus 包中的 descdist 函数来查找分布）我发现 betaregression (betareg) 不起作用，因为有 0。
我发现的一个选择是添加小常数来删除零，但我也有随机因素..我的数据是重复观察的并且还包含随机因素。（我的响应变量是近交系数，预测变量是阶段（生命阶段）..我研究问题是近亲繁殖水平在不同年龄阶段如何变化。我必须将岛屿作为随机因素，因为近亲繁殖水平在不同岛屿内也有所不同..（10个岛屿）。我发现贝塔回归并没有考虑随机因素...在这样的情况下条件如何做统计建模？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/639172/how-to-handle-zero-inflated-data-and-incorporate-random-effect-in-beta-regressio</guid>
      <pubDate>Tue, 13 Feb 2024 11:39:12 GMT</pubDate>
    </item>
    <item>
      <title>具有线性解码器和非线性编码器的 VAE，这只是学习数据的线性分解吗？</title>
      <link>https://stats.stackexchange.com/questions/639171/vae-with-linear-decoder-and-nonlinear-encoder-does-this-just-learn-a-linear-dec</link>
      <description><![CDATA[有许多具有非线性编码器和线性解码器的变分自动编码器 (VAE) 方法。使用线性解码器的概念是提高 VAE 的可解释性（潜在变量贡献哪些特征）。解码器中的权重将告诉我们哪些特征对于 VAE 中的每个潜在变量更重要。
统计上，VAE 可以分为两部分：编码器网络（推理网络）和解码器的潜在分布（生成模型）。生成网络类似于 VAE 的统计模型。因此，如果生成模型是线性的，那么该方法不是数据的线性分解吗？无论编码器是非线性的。那么编码器真的需要非线性吗，除非它有利于推理或训练原因。
采用此类方法的论文。
VEGA：https://www.nature.com/articles/s41467 -021-26017-0
LDVAE：https://academic.oup.com/bioinformatics /文章/36/11/3418/5807606]]></description>
      <guid>https://stats.stackexchange.com/questions/639171/vae-with-linear-decoder-and-nonlinear-encoder-does-this-just-learn-a-linear-dec</guid>
      <pubDate>Tue, 13 Feb 2024 11:03:23 GMT</pubDate>
    </item>
    <item>
      <title>证明线性回归中预测变量的缩放如何影响拟合系数</title>
      <link>https://stats.stackexchange.com/questions/639170/proving-how-scaling-of-predictor-variable-in-linear-regression-affects-the-fitt</link>
      <description><![CDATA[在线性回归中，OLS 解由下式给出：
$$
\hat{\beta} = (X^TX)^{-1}X^TY
$$
我想表明，如果将第 $i$ 个预测变量缩放一个常数，则相应的 $第 i$ 个系数按比例缩小。
我想以矩阵表示法显示：
如果我们缩放第$i$列
$$
X^{*}_{(i)} = a \cdot X_{(i)}
$$
其中 $X_{(i)}$ 表示第 $i$ 列，则： 
$$\hat{\beta}^*_i = \frac{\hat{\beta}_i}{a}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/639170/proving-how-scaling-of-predictor-variable-in-linear-regression-affects-the-fitt</guid>
      <pubDate>Tue, 13 Feb 2024 10:51:36 GMT</pubDate>
    </item>
    <item>
      <title>在 scikit-learn 和 PCA 中使用向后特征选择进行特征选择</title>
      <link>https://stats.stackexchange.com/questions/639169/feature-selection-using-backward-feature-selection-in-scikit-learn-and-pca</link>
      <description><![CDATA[我使用 PCA 计算了数据框中所有列的分数，该数据框中有 312 列和 650 行。我使用了以下代码：
all_pca=PCA(random_state=4)
all_pca.fit(tt)
all_pca2=all_pca.transform(tt)
plt.plot(np.cumsum(all_pca.explained_variance_ratio_) * 100)
plt.xlabel(&#39;组件数量&#39;)
plt.grid(which=&#39;两者&#39;, linestyle=&#39;--&#39;, linewidth=0.5)
plt.xticks(np.arange(0, 330, 步骤=25))
plt.yticks(np.arange(0, 110, 步骤=10))
plt.ylabel(&#39;解释方差(%)&#39;)
plt.savefig(&#39;elbow_plot.png&#39;, dpi=1000)

结果如下图：

我的主要目标是仅使用随机森林回归、梯度提升、OLS 回归和 LASSO 的重要特征。如您所见，100 列描述了我的数据框中 95.2% 的方差。
我有 2 个问题：

我可以使用此阈值（100 列）进行向后特征选择吗？
使用随机森林进行特征选择并根据结果训练随机森林是最佳实践吗？或者使用向后/向前选择会更好？
]]></description>
      <guid>https://stats.stackexchange.com/questions/639169/feature-selection-using-backward-feature-selection-in-scikit-learn-and-pca</guid>
      <pubDate>Tue, 13 Feb 2024 10:33:01 GMT</pubDate>
    </item>
    <item>
      <title>一对多 LSTM 的时间复杂度是多少？</title>
      <link>https://stats.stackexchange.com/questions/639168/what-is-the-time-complexity-one-to-many-lstm</link>
      <description><![CDATA[一对多 LSTM 的时间复杂度是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/639168/what-is-the-time-complexity-one-to-many-lstm</guid>
      <pubDate>Tue, 13 Feb 2024 09:40:42 GMT</pubDate>
    </item>
    <item>
      <title>P(A ∩ B|C) = P(A|C) · P(B|C) 是真的吗？</title>
      <link>https://stats.stackexchange.com/questions/639166/is-it-true-that-pa-%e2%88%a9-bc-pac-pbc</link>
      <description><![CDATA[设 C、B 和 A 是同一概率空间中的事件，使得 A 和 B 独立且
P(A∩C)&gt; 0、P(B∩C)＞ 0。
证明或反驳：
P(A ∩ B|C) = P(A|C) · P(B|C)]]></description>
      <guid>https://stats.stackexchange.com/questions/639166/is-it-true-that-pa-%e2%88%a9-bc-pac-pbc</guid>
      <pubDate>Tue, 13 Feb 2024 09:02:37 GMT</pubDate>
    </item>
    <item>
      <title>使用吉布斯采样枚举子集和问题的可行解</title>
      <link>https://stats.stackexchange.com/questions/639164/enumerating-feasible-solutions-to-the-subset-sum-problem-using-gibbs-sampling</link>
      <description><![CDATA[给定一组 $m$ 严格正实数 $W = \{ w_{1}, \dots , w_{m} \}$，我想查找 $W$ 的子集，其总和小于或等于最大值 $N$ 使用吉布斯采样。为此，我们为每个 $w_{i} \in W 定义一个二进制随机变量 $X_{i}$ $，其中 $X_{i} = 1$ 意味着 $w_{i}$包含在给定子集中，并且 $X_{i} = 0$ 表示不包含它。然后我们可以将 $X_{1}, \dots, X_{m}$ 上的联合分布定义为 \begin{对齐}
P(X_{1}, \dots, X_{m}) \triangleq
\开始{案例}
\frac{1}{Z} \, \epsilon, \, &amp; \text{if } \sum_{i=1}^{m} X_{i} w_{i} = 0 \\
\frac{1}{Z} \, \sum\limits_{i=1}^{m} X_{i} w_{i}, &amp; \text{如果 } 0 &lt; \sum_{i=1}^{m} X_{i} w_{i} \leq N \\
0，&amp; \text{否则，}
\结束{案例}
\end{对齐}
其中 $\epsilon &gt; 0$ 和 $Z$ 是一些标准化常数。如果 $\phi(X_{1}, \dots X_{m}) \triangleq Z \times P(X_{1}, \dots, X_{m})$，然后我们可以使用从条件分布中采样的吉布斯采样器枚举所需的子集：
\begin{align}
P(X_{i} \, | \, X_{\setminus i}) = \dfrac{ \phi(X_{1}, \dots, X_{m}) }{ \phi(X_{i} = 0, X_{\setminus i}) + \phi(X_{i} = 1, X_{\setminus i})},
\end{对齐}
其中 $X_{\setminus i}$ 表示除 $X_{i}$ 之外的所有 RV。下面包含此 Gibbs 采样器的 Python 代码：
将 numpy 导入为 np


def gibbs_sampler(W, N, number_of_samples=int(1e4), epsilon=0.01):
    # 初始化变量
    样本=[]
    米=长度（W）
    W_总计 = 0
    x = np.zeros(m, dtype=int)

    # 吉布斯采样
    对于 _ 在范围内（样本数）：
        对于范围 (m) 内的 i：
            # 删除当前x[i]
            W_total -= W[i] * x[i]
            x[i] = 0

            # 对 x[i] 采样一个新值
            如果 W_total + W[i] &lt;= N：
                P = (
                    (W_total + W[i]) / (2 * W_total + W[i])
                    如果W_total&gt; 0
                    否则 W[i] / (W[i] + epsilon)
                ）
                如果 np.random.rand() &lt;电话：
                    x[i] = 1
                    W_total += W[i]

        # 将样本添加到列表中
        样本.append(1.0 * x)

    返回样品


如果 __name__ == “__main__”：
    ＃ 设置
    W = np.array([6, 7, 8, 5, 9])
    数 = 15

    # 生成样本
    样本 = gibbs_sampler(W, N)
    对于 i，枚举中的样本（np.unique（样本，轴=0））：
        print(f&quot;样本 {i}: {sample}, sum: {np.dot(sample, W)}.&quot;)

我的问题是：

这个表述正确，甚至合理吗？我该如何改进它？我想“赞成”总和较大的子集，所以我认为它们的可能性应该与它们的总和成正比。然而，这需要引入 $\epsilon$ 参数来确保空集出现的概率非零。

是否可以重新表述这个问题并创建一个吉布斯采样器，而不是枚举总和在非零下界和上限之间的子集？这才是我想要解决的真正问题。

]]></description>
      <guid>https://stats.stackexchange.com/questions/639164/enumerating-feasible-solutions-to-the-subset-sum-problem-using-gibbs-sampling</guid>
      <pubDate>Tue, 13 Feb 2024 08:15:36 GMT</pubDate>
    </item>
    <item>
      <title>寻求帮助以检索由于天然气不足错误而失败的交易的交易哈希值[已关闭]</title>
      <link>https://stats.stackexchange.com/questions/639163/seeking-assistance-in-retrieving-transaction-hashes-for-failed-transactions-due</link>
      <description><![CDATA[Stack Exchange 社区您好，
我目前正在开发一个项目，我需要识别由于以太坊区块链上的天然气耗尽错误而失败的交易。但是，我在以编程方式检索这些失败事务的事务哈希值时遇到了挑战。
根据我的理解，由于气体耗尽错误而失败的交易通常不会发出任何日志或事件，因此很难直接识别它们。我探索了各种方法，包括使用 Etherscan 等 API，但尚未找到简单的解决方案。
任何人都可以提供以下方面的指导：
是否有可用的方法或 API 端点（通过 Etherscan 或任何其他服务）允许专门针对因气体耗尽错误而失败的交易检索交易哈希值？
我知道这些交易的数据存在，例如 Etherscan 上的此交易被取消，因为它耗尽了 Gas：0xda8c0b80d8e240a83c8f6b067c4656babeb13e8e0ece4fd4292aa06252f1285c
https://etherscan.io/tx/0xda8c0b80d8e240a83c8f6b067 c4656babeb13e8e0ece4fd4292aa06252f1285c
如果这样的方法或端点不存在，可以使用哪些替代方法来完成此任务？
我知道，由于交易失败的性质，这可能是一个复杂的问题，但我们将不胜感激任何见解或建议。
感谢您的时间和帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/639163/seeking-assistance-in-retrieving-transaction-hashes-for-failed-transactions-due</guid>
      <pubDate>Tue, 13 Feb 2024 07:39:43 GMT</pubDate>
    </item>
    <item>
      <title>I(0)、I(1) 和 I(2) 阶积分的回归变量</title>
      <link>https://stats.stackexchange.com/questions/639140/regression-variables-integrated-of-orders-i0-i1-and-i2</link>
      <description><![CDATA[我正在研究一个具有 4 个变量的模型，这些变量是积分 I(0) 和 I(1)，但一个变量是积分 I(2)。什么模型适合这个数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/639140/regression-variables-integrated-of-orders-i0-i1-and-i2</guid>
      <pubDate>Mon, 12 Feb 2024 23:21:03 GMT</pubDate>
    </item>
    <item>
      <title>对训练数据和权重进行二次采样的最佳实践（在 XGBoost 中）</title>
      <link>https://stats.stackexchange.com/questions/639114/best-practice-for-subsampling-training-data-and-weights-in-xgboost</link>
      <description><![CDATA[我正在尝试在 pycharm 中构建 XGBoost 模型，尽管它与我选择的模型 (XGBoost) 有关，但我有一个一般方法问题。任何有关正确统计方法的一般性评论也将受到赞赏。我的数据非常不平衡：12,114 个 1，1,732,081 个零（然后我将其拆分并使用 60% 进行训练）。然而，我不清楚如何解释这两组的不平衡。
到目前为止我的解决方案
我已经使用了类权重，我认为这很好（从 ROC 和校准图来看）。即：
class_weights =compute_class_weight(&#39;平衡&#39;,classes=np.unique(y_train),y=np.ravel(y_train))
hyper_param_dict = {“class_weight”: {0: class_weights[0], 1: class_weights[1]} ,
                # 与问题无关的其他模型参数：
                “num_workers” ：4，“最大深度” ：5，“n_估计器” ：300，“学习率”：0.1，“伽玛”：1
              }
xgb_classifier = SparkXGBClassifier(label_col=&#39;标签&#39;, features_col = &#39;特征&#39;, **hyper_param_dict)

我的问题
像这样训练模型需要 8 个小时，这让我想到使用子样本。在这里我有点困惑正确的方法是什么。

一种选择是以相同的比例进行子采样，但我担心 1 的数量太少，模型将无法很好地学习它们。
另一个选项（我认为如果有实现选项会更好）是构建大小相等的 1 和 0 集合，每个集合包含 7,268 个元素。就速度而言，这只需要半个小时，但我认为我没有正确实现权重，而且我担心权重会过度拟合。我的想法是，我必须在模型中输入完整训练数据和子样本中的 0:1 比率，但我不知道在哪里。我看到 sklearn （此处）有一个选项“子样本”，我可以在其中输入子样本比率，但我不知道这是否有用和/或如何使用它。

编辑以使这个问题更加精确，并且听起来不像我想知道不平衡集是否是一个问题：
我关心 TPR，我想很好地预测我的 1，尽管这不是我唯一的目的（而且我也非常关心精度）。我想让我的模型尽可能小，因为目前需要很长时间来训练。因此，我想问哪种是更好的二次采样方法，以及我可以使用什么来评估和/或决定最佳权衡和最小训练数据大小。
提前感谢您的帮助:)]]></description>
      <guid>https://stats.stackexchange.com/questions/639114/best-practice-for-subsampling-training-data-and-weights-in-xgboost</guid>
      <pubDate>Mon, 12 Feb 2024 15:56:00 GMT</pubDate>
    </item>
    <item>
      <title>使用前向和后向概率的观测序列的 HMM 概率 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/639098/hmm-probability-of-sequence-of-observations-using-forward-and-backward-probabili</link>
      <description><![CDATA[我在阅读有关 HMM 的文章时遇到过这样的说法：
给定 $\alpha_{n}(j) = P(Y_{0}^{n}, X_{n} = j)$ 和  class=&quot;math-container&quot;&gt;$\beta_{n}(j) = P(Y_{n+1}^{N} | X_{n} = j)$，然后
$$P(Y_{0}^{N}) = \sum_{j} \alpha_{n}(j)\beta_{n}(j)$$ 
但这没有任何解释。
我的问题是，为什么会这样？
我知道$P(Y)=Σ_{i=1}=α_{T}(i)$。所以，我不确定 $\alpha$ 和 $\beta$ 的乘积如何给出相同的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/639098/hmm-probability-of-sequence-of-observations-using-forward-and-backward-probabili</guid>
      <pubDate>Mon, 12 Feb 2024 11:32:20 GMT</pubDate>
    </item>
    <item>
      <title>了解样条变换和回归系数</title>
      <link>https://stats.stackexchange.com/questions/638916/understanding-spline-transformation-and-regression-coefficients</link>
      <description><![CDATA[即使在分段回归的简单情况下，我也无法正确理解样条函数的作用，并且需要一些帮助。
考虑以下基本示例：
&lt;前&gt;&lt;代码&gt;
库（数据.表）
df &lt;- data.table(power = seq(50,250,12))

阈值1 &lt;- 120
阈值2 &lt;- 200
coef1 &lt;- 1/10
coef2 &lt;- 1/5

df[,lactate_raw := fcase(功率 &lt; thres1,1,
                           功率%之间%c(thres1,thres2), 1+ (功率 - thres1)*coef1,
                           功率&gt; thres2, 1+ (thres2 - thres1)*coef1 + (功率 - thres2)*coef2)]

ggplot(df)+
  geom_line(aes(power,lactate_raw),颜色=“红色”)+
  geom_point(aes(功率,lactae))+
  主题_bw()+
  geom_vline(xintercept = c(thres1,thres2),linetype = “点线”)+
  labs(y = “血乳酸 (mmol/L)”,x = “功率 (W)”)


我这里有三个斜率的数据。
我可以进行简单的手动分段回归：
fitsimple &lt;- lm(data = df,
                乳糖〜力量+
                  I((功率 - 阈值 1)*(功率 &gt;= 阈值 1) )+
                  I((功率 - 阈值2)*(功率&gt;=阈值2)))

系数：
                                        估计标准。误差t值Pr(&gt;|t|)
（截距）2.36299 1.05772 2.234 0.04368 *
功率 -0.01566 0.01126 -1.392 0.18737
I((功率 - 阈值 1) * (功率 &gt;= 阈值 1)) 0.12154 0.01839 6.610 1.69e-05 ***
I((功率 - 阈值 2) * (功率 &gt;= 阈值 2)) 0.11392 0.02754 4.137 0.00117 **

这里我有易于解释的简单系数，并且拟合效果很好

如果我现在想使用library(splines)中的bs函数，我应该能够得到相同的结果，给出结并指定度数等于 1。
但我不明白转换 bs 的作用：
库（样条线）
拟合 &lt;- lm(数据 = df,
   乳酸 ~ bs(功率,结 = c(thres1,thres2),度 = 1))

总结（适合）
系数：
                                                  估计标准。误差t值Pr(&gt;|t|)
（截距）1.5797 0.5362 2.946 0.0114 *
bs(功率, 节 = c(thres1, thres2), 度 = 1)1 -1.0965 0.7879 -1.392 0.1874
bs(功率，节 = c(thres1, thres2)，度 = 1)2 7.3734 0.6802 10.840 7.01e-08 ***
bs(功率，节 = c(thres1, thres2)，度 = 1)3 16.6048 0.8392 19.787 4.35e-11 ***

这些系数是什么意思？
如果我绘制预测图，它确实会估计三段线性关系：
df$predict &lt;- 预测（拟合）
ggplot(df)+
  geom_line（aes（功率，预测），颜色=“红色”）+
  geom_point(aes(功率,lactae))+
  主题_bw()+
  geom_vline(xintercept = c(thres1,thres2),linetype = “点线”)+
  labs(y = “血乳酸 (mmol/L)”,x = “功率 (W)”)


但是bs的转换与我手写的例子无关
bs(df$power,结 = c(thres1,thres2),度 = 1)
              1 2 3
 [1，] 0.0000000 0.0000000 0.0000000
 [2，] 0.1714286 0.0000000 0.0000000
 [3，] 0.3428571 0.0000000 0.0000000
 [4，] 0.5142857 0.0000000 0.0000000
 [5，] 0.6857143 0.0000000 0.0000000
 [6，] 0.8571429 0.0000000 0.0000000
 [7、] 0.9750000 0.0250000 0.0000000
 [8、] 0.8250000 0.1750000 0.0000000
 [9、] 0.6750000 0.3250000 0.0000000
[10，] 0.5250000 0.4750000 0.0000000
[11、] 0.3750000 0.6250000 0.0000000
[12、] 0.2250000 0.7750000 0.0000000
[13、] 0.0750000 0.9250000 0.0000000
[14、] 0.0000000 0.8571429 0.1428571
[15、] 0.0000000 0.5714286 0.4285714
[16、] 0.0000000 0.2857143 0.7142857
[17、] 0.0000000 0.0000000 1.0000000

我不明白。有人可以帮忙吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638916/understanding-spline-transformation-and-regression-coefficients</guid>
      <pubDate>Fri, 09 Feb 2024 08:33:39 GMT</pubDate>
    </item>
    <item>
      <title>比较路径分析模型：中介与（残差）协方差</title>
      <link>https://stats.stackexchange.com/questions/638854/comparing-path-analysis-models-mediation-vs-residual-covariance</link>
      <description><![CDATA[我正在使用 lavaan 运行路径分析，以根据 WA 和 LC 预测 PC。这些是多组模型。这里描述的是第一步（识别最适合的路径）；接下来是约束参数在三个组之间相等（group.equal = c(“intercepts”, “regressions”)），这里不做描述。
我的问题与模型的等效性有关。手稿的审稿人表示这三个模型应该是等效的，但我不确定。我感谢论坛提供的任何建议。
模型 1 分别对 WA 和 LC 预测变量进行建模，但允许（残余）协方差。
Mod_1 &lt;- &#39;
PC ~ c(c1, c2, c3) * WA + c(d1, d2, d3) * LC
西澳~~LC
&#39;

模型 2 通过 WA 模拟间接效应。
Mod_2 &lt;- &#39;
PC ~ c(c1, c2, c3) * WA + c(d1, d2, d3) * LC
WA ~ c(a1, a2, a3) * LC
&#39;

模型 3 通过 LC 模拟间接效应。
Mod_3 &lt;- &#39;
PC ~ c(c1, c2, c3) * WA + c(d1, d2, d3) * LC
LC ~ c(a1, a2, a3) * WA
&#39;

所有三个模型都使用此语法运行（如果没有约束截距，模型将不会收敛）：
fit&lt;- sem(mod, data = new_df, group = &quot;grade&quot;,missing=&quot;ML&quot;,
               group.equal = c(“拦截”))

以下是模型拟合统计数据：

模型似乎不同。我读过，允许外生变量共变相当于对它们之间的路径进行建模（例如，参见这篇文章)，但这些结果似乎表明并非如此。另外，在中介模型中，只有 1 个外生变量，所以我不确定这如何适用于这些模型。
对于模型2和模型3，唯一的区别是间接效应的方向性。它们之间唯一不同的估计参数是 WA 是由 LC 预测（模型 2），还是反之亦然（模型 3）。在各组中，模型 2 (.25-.32) 的 WA~LC 斜率估计值大于模型 3 (.20-.23) 的 LC~WA 斜率。鉴于其他斜率估计在模型之间是相等的，我相信解释的方差较大的模型将具有更好的拟合统计数据。然而，审阅者指出这些模型是等效的。
如果您对模型的等效性有任何澄清，我将不胜感激。我还在 https://groups.google.com/g/lavaan/ 上发布了我的问题c/VIdHuxqRKM4。
非常感谢，
珍妮·辛克莱]]></description>
      <guid>https://stats.stackexchange.com/questions/638854/comparing-path-analysis-models-mediation-vs-residual-covariance</guid>
      <pubDate>Thu, 08 Feb 2024 14:28:17 GMT</pubDate>
    </item>
    </channel>
</rss>