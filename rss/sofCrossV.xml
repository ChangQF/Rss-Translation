<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 09 Jul 2024 01:06:10 GMT</lastBuildDate>
    <item>
      <title>跟随领袖，后悔不已</title>
      <link>https://stats.stackexchange.com/questions/650703/follow-the-leader-tight-bound-in-regret</link>
      <description><![CDATA[在 Follow The Leader (FTL) 的情况下，如果 $p_t$ 是我的预测变量，$x_t$ 是时间 t 时的目标点，并且 $x_t$ 属于单位球，即让 $S = \{x \in R^n \mid ||x||_2 \le 1\}$ 和 $x_t \in B$，则如何证明在线二次优化的紧密界限？]]></description>
      <guid>https://stats.stackexchange.com/questions/650703/follow-the-leader-tight-bound-in-regret</guid>
      <pubDate>Tue, 09 Jul 2024 00:47:22 GMT</pubDate>
    </item>
    <item>
      <title>贝塞尔修正的有效证明</title>
      <link>https://stats.stackexchange.com/questions/650702/efficient-proof-of-bessels-correction</link>
      <description><![CDATA[我刚刚开始学习统计学的基础知识，正在维基百科页面上阅读关于贝塞尔方差估计校正为何有效的证明。我理解了一切，除了以下计算的戏剧性简化（在此处重现）：

... 这里我们有（通过独立、对称抵消和平等分配）
$$... \mathbb{E} \Big[ \displaystyle\sum_{j=1}^n\sum_{l=1}^n (x_k - x_j)(x_k - x_l) \Big] = n(n-1)\mathbb{E}[X_1^2] - n(n-1)\mathbb{E}[X_1]^2$$

我不明白计算如何如此容易地进行。页面作者所说的“通过独立、对称抵消和平等分配”究竟是什么意思？]]></description>
      <guid>https://stats.stackexchange.com/questions/650702/efficient-proof-of-bessels-correction</guid>
      <pubDate>Tue, 09 Jul 2024 00:41:52 GMT</pubDate>
    </item>
    <item>
      <title>整合多名参与者的数据进行统计分析</title>
      <link>https://stats.stackexchange.com/questions/650700/combining-data-from-multiple-participants-for-statistical-analysis</link>
      <description><![CDATA[我的问题是：是否有任何统计技术允许将多个参与者的数据组合起来形成“宏观参与者”，以计算命中率或准确率等统计数据？这个想法是随机分组来自 3 或 4 名参与者的数据来计算这些统计数据，然后对它们进行假设检验。
查询背景：我正在开展一个涉及面部表情记忆任务的项目，该任务由两个阶段组成：

编码阶段：在此阶段，参与者会接触到 8 个虚拟角色，每个角色在 8 次试验中显示四种不同的面部表情（痛苦、愤怒、悲伤、中性）之一。
回忆阶段：此阶段包括 24 次试验，分为 8 次“旧”试验（参与者回忆以前见过的角色表情组合）和 16 次“新”试验。参与者的任务是确定他们之前是否见过特定的字符-表情组合。

统计挑战：
主要的挑战来自于每个参与者每个表情的试验次数有限，这限制了信号检测理论等传统统计方法的使用。
例如，“疼痛”表情的命中率计算仅依赖于两次试验。这是因为，在回忆阶段，在所有“旧”试验中，只有两个实例具有“疼痛”的表情并且与计算其命中率相关（8 个字符/4 个表情 = 每次出现 2 次）。结果命中率被限制为 0%、50% 或 100%。由于数据的非正态分布，如此受限的数值范围不适合进行典型的统计分析，如方差分析（比较所有四种面部表情的记忆）。
将数据组合起来形成宏观参与者是否可行？任何建议或见解都将不胜感激！
命中率 = 参与者正确识别为“旧”的“旧”或以前见过的项目的比例 = 命中次数 /“旧”项目的总数]]></description>
      <guid>https://stats.stackexchange.com/questions/650700/combining-data-from-multiple-participants-for-statistical-analysis</guid>
      <pubDate>Tue, 09 Jul 2024 00:32:17 GMT</pubDate>
    </item>
    <item>
      <title>无法从 shapley 值的全局热图中识别出重要特征</title>
      <link>https://stats.stackexchange.com/questions/650699/cannot-identify-important-feature-from-global-heatmap-of-shapley-value</link>
      <description><![CDATA[在我的例子中，每个实例有 166 个特征。我以 80:20 的比例分割训练和测试数据集，并训练了一个用于二元分类的 DNN 模型。模型架构如下：

现在对于测试数据，我使用 shap 库 来识别重要特征。我计算 shap 值的代码如下：
dnn_explainer = shap.DeepExplainer(model, X_train_shap.float().to(device)) 
shap_values_test = dnn_explainer.shap_values(X_test_shap.float().to(device))

现在我试图从局部和全局热图中可视化真正样本的重要特征。对于单个真正的阳性实例，我得到了这个热图：

从这个热图中，我看到大多数特征都很重要，因为它们是红色的，这些特征对模型向正方向的预测没有任何影响，因为它们的 shap 值为零。
我还使用以下代码绘制了全局热图：
import matplotlib.pyplot as plt
import seaborn as sns 

plt.figure(figsize=(10, 2)) 

sns.heatmap(shap_values_test_tp, cmap=&#39;coolwarm&#39;, cbar_kws={&#39;label&#39;: &#39;特征重要性值&#39;}) #, vmin=-1, vmax=1)
plt.title(&#39;TP 样本的局部分析&#39;, fontsize=10)
plt.show()

全局热图：
我获得了测试数据集所有真正例的全局热图，如下所示：

从这个热图中，我也无法在全球范围内识别出任何重要特征。我正在尝试找出我在整个模型解释过程中的错误，但我无法找到它。
我读过题为使用分层相关性传播解释表格数据的深度学习模型的论文，并看到了它们的局部和全局热图，如下所示：

从这些热图中，我们可以轻松识别局部和全局重要特征。我想在我的模型解释中实现这一点。我在解释我的模型时是否遗漏了任何步骤？任何澄清或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650699/cannot-identify-important-feature-from-global-heatmap-of-shapley-value</guid>
      <pubDate>Mon, 08 Jul 2024 23:22:18 GMT</pubDate>
    </item>
    <item>
      <title>当正类相对稀少时，如何在不进行大量随机抽样的情况下估计准确率和召回率</title>
      <link>https://stats.stackexchange.com/questions/650695/how-to-estimate-precision-and-recall-without-taking-a-huge-random-sample-when-th</link>
      <description><![CDATA[我有一个二元文本分类模型，我想在一个包含 200 万个尚未注释的文本文档的新数据集上测试其在精确度和召回率方面的效果。鉴于我对这个新数据集的背景知识，我预计Positive 类文档相对较少。
我将模型应用于数据集，它预测该数据集中只有 0.5% 属于 Positive 类。现在我想知道，考虑到 Positive 类可能很少见，在不进行大量随机抽样的情况下，估计精确度和召回率的好方法是什么。对于精确度，我想，我可以从模型预测为 Positive 的文档部分中抽取样本，但我不确定如何估计召回率。]]></description>
      <guid>https://stats.stackexchange.com/questions/650695/how-to-estimate-precision-and-recall-without-taking-a-huge-random-sample-when-th</guid>
      <pubDate>Mon, 08 Jul 2024 22:33:37 GMT</pubDate>
    </item>
    <item>
      <title>是否存在快速威布尔变换软件？</title>
      <link>https://stats.stackexchange.com/questions/650694/does-a-fast-weibull-transform-software-exist</link>
      <description><![CDATA[我经常被要求根据 WEIBULL 概率函数（通常为 2 个参数）计算数据序列的反卷积。
我使用自己设计的 EXCELL 扩展鞘层获得了非常好的结果，并手动更改可能的第一个分布的模式和尺度参数，直到输入和输出之间的 Pearson 相关系数达到最大值。然后继续第二个可能分布，依此类推。不幸的是，以前的分布必须重新调整
想知道这样的过程是否已经自动化？或者至少，是否存在类似于傅立叶变换的方法，这将使我有一些空闲时间
感谢您的帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/650694/does-a-fast-weibull-transform-software-exist</guid>
      <pubDate>Mon, 08 Jul 2024 22:01:44 GMT</pubDate>
    </item>
    <item>
      <title>对于 3x3 列联表中对角线的丰富度，单尾 Fisher 精确检验的等效性如何？</title>
      <link>https://stats.stackexchange.com/questions/650693/equivalent-of-one-tailed-fishers-exact-test-for-enrichment-of-the-diagonal-in-3</link>
      <description><![CDATA[我有 2 个序数变量 A 和 B，每个变量有 3 个级别（例如“下降”、“不变”和“上升”）。我想知道 A 和 B 指示的上升/下降变化是否彼此一致。也就是说，我的备选假设是，如果 A 是“上升”，那么 B 也比随机概率更有可能“上升”，“下降”也是如此。如果级别只是“变化”和“不变”，我将制作 2x2 列联表并执行单尾 Fisher 精确检验，备选假设是比值比大于 1，即我将测试 2x2 列联矩阵的对角线项是否大于随机变化的预期。我想对我的 3x3 列联表的对角线丰富性进行类似测试，但我找不到合适的测试。我见过的 Fisher 精确检验对 3x3 表的扩展并没有指定如何测试特定的备选假设。它们只是测试两个变量独立于它们之间任何形式的依赖关系的零假设。有这样的测试吗？或者，“对角线丰富性”是概念化这一问题的错误方式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650693/equivalent-of-one-tailed-fishers-exact-test-for-enrichment-of-the-diagonal-in-3</guid>
      <pubDate>Mon, 08 Jul 2024 21:14:20 GMT</pubDate>
    </item>
    <item>
      <title>将估计协方差的非对角线元素设置为 0 有何含义？</title>
      <link>https://stats.stackexchange.com/questions/650688/what-are-the-implications-of-setting-off-diagonal-elements-of-estimated-covarian</link>
      <description><![CDATA[我有时在已发表的著作中看到，在估计协方差矩阵时，非对角线元素被设置为 0。例如，在本文中，记录了$N$ 个神经元，作者希望使用他们的反应的$N \times N$协方差矩阵$\Sigma$进行线性判别分析 (LDA)。但是因为数据点的数量 $K$ 与 $N \times N$ 相比较少，所以它们将非对角线元素设置为 0。从补充部分：“... 我们没有足够的数据来获得可靠的协方差估计... 因此，我们假设刺激反应在条件内是独立的（即，我们将非对角线元素设置为零）。”
我想知道上述程序的含义/理由。例如，假设 $N = 20$ 和 $K = 5$，那么如果我们使用通常的协方差公式估计 $\Sigma$，我们将得到一个秩为 5 的奇异矩阵。我们不能在 vanilla LDA 中使用此矩阵。但是，如果我们将这个结果矩阵的非对角线元素设置为 0，我们将得到一个可以在 LDA 中使用的满秩矩阵。在某种程度上，我们似乎通过将非对角线元素设置为 0 来“获得”信息。原始秩效率矩阵告诉我们，我们没有足够的数据来解决问题，但修改后的矩阵并非如此。
这可以看作只是在 $\Sigma$ 上使用强先验，还是正则化？是否有一些理论依据可以证明此类程序有助于理解其含义？这是否与修复随机效应模型中随机效应矩阵的结构的程序有关（例如此处和此处）？]]></description>
      <guid>https://stats.stackexchange.com/questions/650688/what-are-the-implications-of-setting-off-diagonal-elements-of-estimated-covarian</guid>
      <pubDate>Mon, 08 Jul 2024 18:46:15 GMT</pubDate>
    </item>
    <item>
      <title>如何对密度数据进行功效分析？</title>
      <link>https://stats.stackexchange.com/questions/650687/how-to-do-a-power-analysis-on-density-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650687/how-to-do-a-power-analysis-on-density-data</guid>
      <pubDate>Mon, 08 Jul 2024 18:27:16 GMT</pubDate>
    </item>
    <item>
      <title>单位球中最近邻的期望最大距离、平均距离和最小距离的解析渐近近似</title>
      <link>https://stats.stackexchange.com/questions/650686/analytical-asymptotic-approximation-of-the-expected-maximum-mean-and-minimum-d</link>
      <description><![CDATA[假设我均匀随机地将 $x = n^3$ 个（独立同分布）点分布在 $r=1$ 半径的球中，位于 $\mathbb{R}^3$。
对于任何给定点的最近邻居之间的预期最大、最小和平均距离，可以怎样描述，渐近地为 $n\to\infty$？
尝试模拟这些，我得到：

不要太在意“理论平均值”，这实际上只是为了斜率。它是 $\frac{1}{x} = \frac{1}{n^3}$，其中 $n$ 是点数。
我得到：
最小距离拟合：
斜率：-2.0084
截距：1.0666
R²：0.9336
方程式：y = 1.0666 * x^(-2.0084)
平均距离拟合：
斜率：-1.0253
截距：0.9858
R²：0.9987
方程式：y = 0.9858 * x^(-1.0253)
最大距离拟合：
斜率：-0.8986
截距：1.7097
R²：0.9918
方程：y = 1.7097 * x^(-0.8986)
所以这些是相当不错的拟合，但是有没有什么确切的信息吗？
我知道，对于两个点，根据这个答案https://math.stackexchange.com/a/167983/49989，平均值的答案应该是$\frac{35}{36}\approx0.9722$

最小值的斜率明显接近 -2。
我还看到了这个https://en.wikipedia.org/wiki/Complete_spatial_randomness

如果我做对了，这意味着对于给定密度的完全均匀分布的点，我最终会得到带有
$$
P\left(r,\rho,N\right)=\frac{3^{1-N}\left(4\pi\rho\right)^N r^{3 N - 1}e^{-\frac{4}{3}\pi\rho r^3}}{\left(N - 1\right)!}
$$
对于给定密度$\rho$的距离$r$到$N^\text{th}$个最近邻居的概率。
我想我可以用$\rho = \frac{3 n}{4 \pi R^3}$代替$n$ 个点位于半径为 $R$ 的体积中，这给了我
$$
\frac{3 e^{-n\frac{r^3}{R^3}}\left(n\frac{r^3}{R^3}\right)^N}{r\left(N-1\right)!}
$$
对于该期望（在域 $0\leq r\leq\infty$ 上）最终应为
$$
\frac{R\ \Gamma\left(N+\frac{1}{3}\right)}{n^\frac{1}{3} \Gamma\left(N\right)}
$$
这似乎与最近邻平均值的结果相当接近，尽管它并不完全一致：它预测，对于半径为 $R=1$ 且 $x=n^3$ 个点的球体，我得到
$$
\frac{\Gamma\left(\frac{4}{3}\right)}{x}\approx\frac{\text{0.89298}}{x}
$$
而不是
$$
\approx\frac{\text{0.9858}}{x^\text{1.0253}}
$$
但我不确定这是否在模拟误差范围内。从图上看肯定不是这样：对于较大的点集（至少对于均值拟合），方差很快变得非常小，并且该线显然略比该分析值陡峭。]]></description>
      <guid>https://stats.stackexchange.com/questions/650686/analytical-asymptotic-approximation-of-the-expected-maximum-mean-and-minimum-d</guid>
      <pubDate>Mon, 08 Jul 2024 18:11:49 GMT</pubDate>
    </item>
    <item>
      <title>应用 IPTW 权重后计算 SMD 的问题</title>
      <link>https://stats.stackexchange.com/questions/650684/issues-calculating-smds-after-applying-iptw-weights</link>
      <description><![CDATA[在对我的数据应用逆治疗概率 (IPTW) 和稳定 IPTW 权重之前和之后，我得到了完全相同的标准化均值差 (SMD)。我使用 cobalt 包创建了一个平衡表，如下所示。我还尝试手动计算加权均值、SD 和 SMD，结果相同。
这是正常的吗？如果是，为什么？对总体应用权重应该会直观地改变协变量的加权平均值，所以我很困惑。提前致谢！
library(&#39;cobalt&#39;)
data(&#39;lalonde&#39;, package = &#39;cobalt&#39;)

# 计算 IPTW 权重
iptw_fit &lt;- glm(treat ~ age + educ + race, 
family = binomial(), 
data = lalonde)

prop_score &lt;- if_else(lalonde$treat == 0, 
1 - predict(iptw_fit, type = &#39;response&#39;),
predict(iptw_fit, type = &#39;response&#39;))

lalonde$iptw &lt;- 1/prop_score

# 计算稳定的 IPTW 权重
numer_fit &lt;- glm(treat~1, family = binomial(), data = lalonde) # numerator
pn_trt &lt;- predict(numer_fit, type = &#39;response&#39;)

denom_fit &lt;- glm(treat ~ age + educ + race, # 分母
family = binomial(),
data = lalonde)
pd_trt &lt;- predict(denom_fit, type = &#39;response&#39;)

lalonde$siptw &lt;- if_else(lalonde$treat == 0, 
((1-pn_trt) / (1-pd_trt)),
pn_trt/pd_trt)

# 计算 SMD

bal_tab &lt;- bal.tab(treat ~ age + educ + race , data = lalonde,
weights = c(&quot;iptw&quot;, &quot;siptw&quot;),
binary = &quot;std&quot;, Continuous = &quot;std&quot;,
stats = c(&#39;mean.diffs&#39;),
s.d.denom = &#39;pooled&#39;
) 

print(bal_tab)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/650684/issues-calculating-smds-after-applying-iptw-weights</guid>
      <pubDate>Mon, 08 Jul 2024 17:12:09 GMT</pubDate>
    </item>
    <item>
      <title>仅对一个个体进行相关观测的回归</title>
      <link>https://stats.stackexchange.com/questions/650676/regression-with-dependent-observations-of-only-one-individual</link>
      <description><![CDATA[上周，我接到一项任务，计划我的团队希望执行的分析。
我的目标是衡量一位医生是否同意某个工具为一组 N 幅医学图像生成的输出。为此，我会让他查看每幅图像和每个模型输出并回答一份简短的问卷。我的 Y 变量可能是二进制（同意/不同意）或李克特量表（1-5）；我还没有决定。其他 X 变量将是其他问题的答案，我想用 X 因子解释 Y 变异性，例如，看看哪些因素与医生的同意有关。
我最初的想法是使用广义线性模型 (GLM)，但我的观察结果不会是独立的。虽然我可以要求医生在 10 份问卷之间等待一段时间，以尝试减少遗留效应，但不能保证 (1) 他确实会这样做，并且 (2) 这样做会有效，因为尽管存在哲学问题，但他仍然是同一个人。我可以继续这样做并尝试测试独立性，但如果这个假设不成立，我该怎么办？
经过一些初步研究，我想到了一些选择，但由于我对它们不熟悉，我希望得到一些反馈，如果可能的话，我希望得到一些参考。

在 GAMLSS 模型中添加随机项 - 这可行吗？或者也许使用广义线性混合模型 (GLMM)？如果我只有一个集群变量（一个专家），这是否有意义？

使用时间序列回归分析，例如 $$Y_t \sim Y_{t-1} + X1_t + X2_t + ...$$ 这个选项在我看来过于复杂，而且我不太确定我是否能用它回答我的问题。

]]></description>
      <guid>https://stats.stackexchange.com/questions/650676/regression-with-dependent-observations-of-only-one-individual</guid>
      <pubDate>Mon, 08 Jul 2024 14:29:21 GMT</pubDate>
    </item>
    <item>
      <title>贝塔随机变量的乘积与和的分布</title>
      <link>https://stats.stackexchange.com/questions/650663/distribution-of-product-and-sum-of-beta-random-variables</link>
      <description><![CDATA[我有一组概率，我将其建模为（独立的）$p_{A,i} \sim Beta(\alpha_{A,i},\beta_{A,i})$ 和 $p_{B,i} \sim Beta(\alpha_{B,i},\beta_{B,i})$。我正在计算以下乘积：
$$Y = \sum_{i=1}^N p_{A,i}^{n_{A}}(1-p_{B,i})^{n_{B}} + p_{B,i}^{n_{B}}(1-p_{A,i})^{n_{A}},$$
其中 $n_{A}$ 和 $n_{B}$ 为整数。我想推断（近似）$Y$ 的分布。由于 $Y$ 是倾斜的且在实数轴上定义，所以我想将 Beta-Prime 分布拟合到我的直方图中。这是否正确？您能否给我一些关于 $Y$ 的真实分布或更好的近似值的见解？
PD。如果之前有人问过类似的问题，请见谅。]]></description>
      <guid>https://stats.stackexchange.com/questions/650663/distribution-of-product-and-sum-of-beta-random-variables</guid>
      <pubDate>Mon, 08 Jul 2024 08:59:56 GMT</pubDate>
    </item>
    <item>
      <title>条件逻辑（离散 Cox PH）回归模型</title>
      <link>https://stats.stackexchange.com/questions/650662/conditional-logistic-discrete-cox-ph-regression-model</link>
      <description><![CDATA[我对椎间盘时间生存建模这一主题非常陌生。我从包 powerSurvEpi 中找到了 R 中的以下函数。似乎 powerConLogistic.bin 函数可用于 #二元协变量条件逻辑回归的样本量计算#，遵循 Lachin, JM 使用条件逻辑（离散 Cox PH）回归模型的分数检验对多重匹配病例对照研究进行样本量评估。 所以我想知道后续函数是否可以用于离散 Cox PH，因为我的理解是离散 Cox PH 和条件逻辑回归是不同的统计建模。
 powerConLogistic.bin(
N = NULL,
power = 0.8,
OR,
pE,
nD,
nH,
R2 = 0,
alpha = 0.05,
nTests = 1,
OR.low = 1.01,
OR.upp = 100
)
]]></description>
      <guid>https://stats.stackexchange.com/questions/650662/conditional-logistic-discrete-cox-ph-regression-model</guid>
      <pubDate>Mon, 08 Jul 2024 08:51:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 R STM 包分析评论评级-样本平衡问题</title>
      <link>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</link>
      <description><![CDATA[在考察主题占比差异时，由于在线评论评分呈正偏J型分布/评分分布不均衡，学者们倾向于平衡样本量，即随机选取正评分评论（即4分和5分评分），使其数量与负评分评论（即1分和2分评分）数量相等或相近。类似以下论文的做法：
论文1：酒店顾客抱怨什么？使用结构化主题模型进行文本分析
论文 2：药物消费者的声音：使用结构化主题模型进行在线文本评论分析
除了研究主题比例（正面 vs. 负面）的差异（例如论文 1，图 2）之外，我还想使用线性回归研究主题和评分之间的关​​系。
一方面，如果我对主题比例的差异进行分析，似乎我必须删除一些评论才能实现样本平衡；另一方面，如果我只运行线性回归，则没有必要这样做。
在这种情况下，有什么解决方案可以不删除样本，同时解决样本不平衡的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</guid>
      <pubDate>Mon, 08 Jul 2024 08:17:13 GMT</pubDate>
    </item>
    </channel>
</rss>