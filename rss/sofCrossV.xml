<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 13 Sep 2024 12:30:21 GMT</lastBuildDate>
    <item>
      <title>多项响应变量的虚拟编码</title>
      <link>https://stats.stackexchange.com/questions/654322/dummy-encoding-for-the-multinomial-response-variable</link>
      <description><![CDATA[我正在阅读 Fahrmeir 和 Tutz 合著的《基于广义线性模型的多元统计建模》一书中有关多项响应模型的内容。我试图理解书中的以下段落（第 3.1 章，第 70 页）：

对于本章中考虑的分类响应，基本分布是多项分布。假设响应变量 $Y$ 有 $k$ 个可能值，为简单起见，将其标记为 $1, ... , k$。有时，考虑 $Y\in \{1, 2, ..., k\}$ 会隐藏我们实际上有一个多变量响应变量的事实。通过考虑虚拟变量的响应向量 $y&#39; = (\tilde{y_1}, \tilde{y_2}... ,\tilde{y_q}), q = k - 1$，其分量为
$$
\begin{equation} \tag{3.1.1}
\tilde{y_r} = 
\begin{cases}
1 &amp; \text{if $Y = r$, $r = 1, ..., q$} \newline
0 &amp; \text{otherwise.}
\end{cases}
\end{equation}
$$
然后我们有
$$
Y = r \iff y = (0, ..., 1, ..., 0).
$$
概率通过以下公式简单连接起来：
$$P(Y = r) = P(y_r =1).$$

我对上述方程组中 $r$ 的使用感到困惑。方程 $Y = r$ 中的 $r$ 与方程 3.1.1 中的 $r$ 不同吗？因为，如果我们考虑$Y$，其中$k = 4$，那么对于$Y = 4$，$r &gt; q$，但考虑方程 3.1.1，$r \in \{1, 2, ..., q\}$，因此，$ r \le q$。]]></description>
      <guid>https://stats.stackexchange.com/questions/654322/dummy-encoding-for-the-multinomial-response-variable</guid>
      <pubDate>Fri, 13 Sep 2024 11:38:50 GMT</pubDate>
    </item>
    <item>
      <title>模拟退火回归模型中的迭代次数</title>
      <link>https://stats.stackexchange.com/questions/654321/number-of-iterations-in-simulated-annealing-regression-model</link>
      <description><![CDATA[我是机器学习模型应用的新手。我正在尝试应用模拟退火回归模型。现在的问题是我应该在回归控制和模拟退火控制中设置迭代次数，还是两者都设置？
代码如下：
# 设置并行后端
Mycluster &lt;- makeCluster(detectCores() - 2) # 使用可用核心减 2
registerDoParallel(Mycluster) # 注册并行执行

stime = system.time({
# 训练函数的回归控制
reg.ctrl &lt;- trainControl(method = &quot;LOOCV&quot;, 
number = 100, 
repeats = 5, 
allowParallel = TRUE)

# 模拟退火控制设置
safs.ctrl &lt;- safsControl(functions = caretSA, 
method = &quot;LOOCV&quot;, 
number = 100,
metric = c(internal = &quot;RMSE&quot;, external = &quot;RMSE&quot;),
maximize = c(internal = FALSE, external = FALSE),
holdout = 0.2,
improve = 5,
allowParallel = TRUE,
verbose = TRUE)

# 模拟退火特征选择
sa_100 &lt;- safs(x = MEs[, 1:dim(MEs)[[2]]],
y = gsva[1, ],
iters = 100,
metric = &quot;RMSE&quot;,
trControl = reg.ctrl,
safsControl = safs.ctrl)
})[3]

stime[1]

# 计算完成后停止集群
stopCluster(Mycluster)
registerDoSEQ() # 重置为顺序执行

我的意思是，我应该设置 number = 的参数吗100 在 trainControl() 和 safsControl() 函数中还是其中一个？或者只是在 safs() 函数中使用 iters = 100？
此外，我需要了解，回归控制和模拟退火控制之间有什么区别？]]></description>
      <guid>https://stats.stackexchange.com/questions/654321/number-of-iterations-in-simulated-annealing-regression-model</guid>
      <pubDate>Fri, 13 Sep 2024 11:34:06 GMT</pubDate>
    </item>
    <item>
      <title>SurvDisc 软件包（A 功能）</title>
      <link>https://stats.stackexchange.com/questions/654320/survdisc-package-a-function</link>
      <description><![CDATA[当我们对风险率只有一个估计值时，假设风险随时间呈线性变化，那么SurvDisc包中的以下函数是否可用于计算样本量？在这种情况下，没有对每个时间点的风险率 1,..., T(r) 进行单独的估计，因为我们没有假设风险随时间推移完全普遍存在。
SampleSizeDiscSurv(power=0.9,alpha=0.025,alternative=c(&quot;less&quot;,&quot;greater&quot;),beta0=0,
h0,h1,p0,p1,ties.method=c(&quot;efron&quot;,&quot;breslow&quot;,&quot;PrenticeGloeckler&quot;),
method=c(&quot;asymptotic&quot;,&quot;simulation&quot;),tol,AMV=NULL,nsim=10000,Nvec=NULL,
test=c(&quot;Wald&quot;,&quot;Score&quot;))

h0 
长度为 r-1 的向量包含时间 1、...、r-1 或相应时间间隔内对照组的假设风险率。假设为 r 个间隔，最后一个间隔为无限。

h1 
治疗组的假设风险率向量

p0 
处于风险集和对照组的概率向量。

p1 
处于风险集和治疗组的概率向量。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654320/survdisc-package-a-function</guid>
      <pubDate>Fri, 13 Sep 2024 11:28:30 GMT</pubDate>
    </item>
    <item>
      <title>进行 n 次成对比较。是否应先对单个成对比较进行多重比较校正，然后再对所有 n 次进行校正？</title>
      <link>https://stats.stackexchange.com/questions/654315/doing-pairwise-comparisons-n-times-should-correction-for-multiple-comparison-be</link>
      <description><![CDATA[我正在使用线性混合效应模型对我的实验进行统计评估。实验由在受试者内随机进行的几种不同的干预方案组成。每次干预期间都有 3 个不同的时间段。我希望评估每个时间段内干预方案的效果以及每个干预方案内时间段之间的差异。
具体来说，我的模型如下：
fit_simple &lt;- lmer(log(target_variable) ~ Protocol * period + sex + (1 | contestant), data = input_data, REML = TRUE)

数据是对数转换的，因此它符合假设，而且数据分布的性质在文献中几乎总是对数转换的。在我的最终模型中，随机结构稍微复杂一些，但这与此并不相关。
为了评估时间段内干预方案之间的差异以及干预方案内时间段之间的差异，我采用成对比较并使用估计边际均值（R 中的包 emmeans）。 emmeans 包已经包含了针对每个成对比较的多重测试（默认情况下为 Tukey HMD）的校正。
emm &lt;- emmeans(fit_simple, ~ Protocol * period)

# 每个 Protocol 内各个周期级别之间的成对比较
pairwise_comparisons_Protocol &lt;-contrast(emm, method = &quot;pairwise&quot;, by = &quot;Protocol&quot;)

# 每个周期内各个 Protocol 级别之间的成对比较
pairwise_comparisons_period &lt;-contrast(emm, method = &quot;pairwise&quot;, by = &quot;period&quot;)

#摘要
summary_Protocol &lt;- summary(pairwise_comparisons_Protocol)
summary_period &lt;- summary(pairwise_comparisons_period)

问题是，我正在进行两次成对比较。我需要对两次成对比较进行校正吗？或者 emmeans 中对每次成对比较的内置校正是否足够？是否需要这样做：
all_pvals &lt;- c(
summary_Protocol$p.value,
summary_period$p.value
)

holm_adjusted_pvals &lt;- p.adjust(all_pvals, method = &quot;holm&quot;)

另一个问题是，我应该在单次成对测试中使用哪种多重比较校正方法，然后（如果需要）对进行两次成对测试的校正使用哪种方法？如果可能的话，我希望避开 Bonferroni。
感谢您的帮助，非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654315/doing-pairwise-comparisons-n-times-should-correction-for-multiple-comparison-be</guid>
      <pubDate>Fri, 13 Sep 2024 10:28:02 GMT</pubDate>
    </item>
    <item>
      <title>关于生存建模中区间删失的澄清</title>
      <link>https://stats.stackexchange.com/questions/654313/a-clarification-on-interval-censoring-in-modeling-survival</link>
      <description><![CDATA[直到阅读 Vinh Nguyen 的 第 11 讲：区间删失和离散时间数据 (2012)，我才认为离散时间生存模型才是适合我们研究的统计方法。我的理解是离散时间生存分析 (Cox) 包括区间删失。然而，区间删失似乎是一种独立的技术（如果我错了，请纠正我）。现在，我有点困惑，区间审查方法或离散时间生存是否适合我的研究。
在我们的研究中，受试者每三个月（最多 18 个月）访问一次中心，在以下时间检查他们的疾病状态：T0、T3、T6、T9、T12、T15 和 T18。主要协变量 测试状态 是二元的且与时间相关（1 vs. 0）。事件是二元结果（1：健康状况下降，0：健康状况稳定）。这项研究是单一事件。数据可能看起来像这样：
ID TIME AGE EVENT TEST STATUS
1 0 45 0 0
1 3 45 1 1
2 0 46 0 0
2 3 46 0 1
2 6 46 0 0
2 9 46 1 1
3 0 34 0 0
3 3 34 0 0
3 6 34 0 1
3 9 34 0 1
3 12 34 0 0
3 15 34 0 1
3 18 34 1 0
]]></description>
      <guid>https://stats.stackexchange.com/questions/654313/a-clarification-on-interval-censoring-in-modeling-survival</guid>
      <pubDate>Fri, 13 Sep 2024 09:17:13 GMT</pubDate>
    </item>
    <item>
      <title>Keras 中的简单梯度下降</title>
      <link>https://stats.stackexchange.com/questions/654312/simple-gradient-descent-in-keras</link>
      <description><![CDATA[我正在通过在笔记本中构建自己的神经网络来练习神经网络。我正尝试将我的模型与 Keras 中的等效模型进行对比。我的模型似乎与其他简单的编码神经网络框架一样工作，例如：https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76
但是，随着我增加 epoch 的数量，Keras 模型的权重逐渐与我自己的权重不同。我正尝试使用简单的梯度下降来训练网络，批量大小等于整个训练集，将初始化权重设置为与我的模型中的初始化权重相同。 （我目前一直在 Iris 数据集上执行此操作，因此批处理大小 = 150。）
我感兴趣的是，这里 keras 中是否存在默认情况，这意味着我下面描述的模型与我的模型（或文章中描述的模型）的功能略有不同？比如批量标准化之类的？
从 tensorflow 导入 keras
从 tensorflow.keras.models 导入 Sequential
从 tensorflow.keras.layers 导入 Dense、Activation、Input

network_shape = np.array([4,20,10,1])
activations=[&quot;relu&quot;,&quot;relu&quot;,&quot;sigmoid&quot;]
model = Sequential()
model.add(Input(shape=(network_shape[0],)))
for i in range(len(activations)):
model.add(Dense(units=network_shape[i+1],activation=activations[i]))

model.set_weights(set_weights)

sgd = keras.optimizers.SGD(learning_rate=alpha,动量=0.0)
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=sgd)

model.fit(X.T, y.T, batch_size=150, epochs=n_iter, verbose=0, shuffle=False)

提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654312/simple-gradient-descent-in-keras</guid>
      <pubDate>Fri, 13 Sep 2024 08:32:10 GMT</pubDate>
    </item>
    <item>
      <title>逆回归的无偏估计量</title>
      <link>https://stats.stackexchange.com/questions/654311/unbiased-estimator-of-the-reversed-regression</link>
      <description><![CDATA[假设我有随机变量 $X$ 和 $Y$。我对 $\mathbb{E}[Y | X]$ 的无偏估计量感兴趣，但我以另一种方式执行了回归，并得到 $\mathbb{E}[X |Y]$。在什么数据生成分布和进一步假设下，是否知道我可以构建一个无偏估计量 $\mathbb{E}[Y | X] = \beta \mathbb{E}[X |Y]$？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654311/unbiased-estimator-of-the-reversed-regression</guid>
      <pubDate>Fri, 13 Sep 2024 08:29:49 GMT</pubDate>
    </item>
    <item>
      <title>mmrm R 包：没有优化器导致模型拟合成功</title>
      <link>https://stats.stackexchange.com/questions/654310/mmrm-r-package-no-optimizer-led-to-a-successful-model-fit</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654310/mmrm-r-package-no-optimizer-led-to-a-successful-model-fit</guid>
      <pubDate>Fri, 13 Sep 2024 07:52:54 GMT</pubDate>
    </item>
    <item>
      <title>量化对异常值敏感的两个分布之间的差异</title>
      <link>https://stats.stackexchange.com/questions/654309/quantifying-the-discrepancy-between-two-distributions-with-sensitivity-to-outlie</link>
      <description><![CDATA[我在样本空间 $x \in \Omega$ 上有两个概率分布，分别表示为 $P:\Omega \mapsto \mathbb{R}$ 和 $Q:\Omega \mapsto \mathbb{R}$。这些分布出现在构建纠错码解码器的背景下。假设 $\Omega$ 表示所有可能错误的空间，而 $P(\cdot)$ 是一个错误模型，它为 $\Omega$ 中的每个错误事件分配一个概率。本质上，$P(\cdot)$ 捕获了所有不想要的效果。如果解码策略完全了解 $P(\cdot)$，则它可以发挥最佳性能。但是，$P(\cdot)$ 在实践中通常是未知的。相反，我们经常进行校准实验来推断一个模型 $Q(\cdot)$，该模型合理地近似了底层噪声过程 $P(\cdot)$。因此，了解$P(\cdot)$和$Q(\cdot)$之间的差异至关重要，尤其是在解码器的性能方面。
在错误校正中，众所周知，位于$P(\cdot)$尾部的$x \in \Omega$错误，即异常值，对解码器的性能有重大影响。例如，如果 $\Omega$ 表示独立的位翻转错误，其中每个位翻转发生的概率为 $p$，则关键异常值是具有较大汉明权重的错误（刚好超过代码距离的一半 $d$），概率约为 $p^{d/2}$。因此，$P(\cdot)$ 和 $Q(\cdot)$ 在异常值上紧密匹配至关重要，而对于非异常值错误，较大的差异更容易被接受。
在这种情况下，什么是合适的可区分性指标来量化 $P(\cdot)$ 和 $Q(\cdot)$ 之间的相关差异？以下常用指标似乎不适合这种特殊情况：

总变异距离 (TVD)：$\sup_{x \in \Omega} |P(x) - Q(x)|$。该指标主要由更可能发生事件的概率差异决定。例如，如果我们有两个误差$x_1, x_2 \in \Omega$，其中$P(x_1) = 0.9$、$Q(x_1) = 0.8$，以及$P(x_2) = 10^{-5}$、$Q(x_2) = 10^{-7}$，则 TVD 对估计$x_2$概率的显著误差不敏感。
Kullback-Leibler 散度 (KL 散度)： $ D(P || Q) = \sum_{x \in \Omega} P(x) \log \left( \frac{P(x)}{Q(x)} \right) $。与 TVD 一样，对于典型事件，KL 散度对 $P(x)$ 和 $Q(x)$ 的差异更为敏感。因此，它无法充分捕捉异常值的差异。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654309/quantifying-the-discrepancy-between-two-distributions-with-sensitivity-to-outlie</guid>
      <pubDate>Fri, 13 Sep 2024 07:37:11 GMT</pubDate>
    </item>
    <item>
      <title>在优化问题中使用零膨胀负二项回归的估计值</title>
      <link>https://stats.stackexchange.com/questions/654307/use-estimates-from-zero-inflated-negative-binomial-regression-in-optimization-pr</link>
      <description><![CDATA[假设我希望将投资预算优化为两个不同的投资机会。在案例 1 中，我们假设我们拥有每个机会的先前投资和销售数据。我们还假设响应（假设为销售额）在两个投资之间不相关，并且投资不会以任何方式相互作用。可以假设两个投资的响应变量遵循零膨胀负二项分布。我们假设投资 1 的销售额可以根据 $y_{1, t} = e^{b_{1, t}} * x_{1, t}^{exponent_{1, t}}$ 建模，其中 $y_{1, t}$ 是时间步 t 时归因于投资 1 的销售额。投资 2 可以以相同的方式建模。
那么我的问题是，是否只需将 $1 - \psi$ 上的后验与 $e^{b_{1, t}}$ 上的后验相乘，然后将其包装在确定性变量中，以获得适当的系数 $e^{b_{1, t, \text{zero-inflation-scaled}}}$，然后将其输入到我们的优化问题中，我们试图最大化我们的投资销售额：
$\max_{x_c} \sum_{c \in \{1, 2\}} \sum_{\text{posterior_sample}} (1 - \psi_{c, \text{posterior_sample}}) \cdot e^{b_{1, \text{posterior_sample}}} \cdot x_c^{\text{exponent}_{c, \text{posterior_sample}}}$
受一些约束，例如：
$\sum_{c \in \{1, 2\}} x_c \leq B \quad \text{and} \quad x_c \geq 0 \quad \forall c$,
其中 posterior_sample 表示一些采样的后验集。
考虑以下用 pymc 编写的代码片段：
def zero_inflated_negative_binomial_test():
# 生成所需的变量
x_1 = np.random.lognormal(sigma=0.5, size=1000)
response_1 = np.array(
[max(0.0, round(x)) for x in np.exp(2 * x_1 ** 0.5) + np.random.normal(scale=1,
size=1000)])
zeros = np.random.binomial(n=1, p=0.4, size=1000)

# 根据零数组在 response_1 中插入零
response_1[zeros == 0] = 0

import pymc as pm
with pm.Model() as model:
b_1 = pm.HalfNormal(&#39;b_1&#39;, sigma=10)
exponent = pm.Beta(&#39;exponent&#39;, alpha=1, beta=1)

mu = pm.math.exp(b_1) * x_1 ** 指数

alpha = pm.Exponential(&quot;alpha&quot;, 10)
psi = pm.Beta(&quot;psi&quot;, alpha=1, beta=1)

truecoefficient = pm.Deterministic(name=&quot;truecoefficient&quot;, var=(1 - psi) * pm.math.exp(b_1))

_ = pm.ZeroInflatedNegativeBinomial(
name=&quot;outcome&quot;,
psi=psi,
mu=mu,
alpha=alpha,
observer=response_1
)

import pymc.sampling_jax as jax
trace = jax.sample_blackjax_nuts(1000,
tune=1000,
target_accept=0.97,
cores=2,
random_seed=0,
idata_kwargs={&quot;log_likelihood&quot;: True},
return_inferencedata=True)

var_names = [&quot;truecoefficient&quot;, &quot;b_1&quot;, &quot;exponent&quot;, &quot;psi&quot;]
inf = pm.sample_posterior_predictive(trace, var_names=var_names,random_seed=0, extend_inferencedata=True)

print(&quot;_&quot;)

其中 truecoefficient 表示零膨胀缩放的 $e^{b_{1, t}}$，其估计值将在优化中替换 $(1 - \psi)e^{b_1}$问题。
类似地，考虑诸如$y_t = 截距 + b_{1, t} * x_{1, t} + b_{2, t} * x_{2, t}$之类的模型，我们能否简单地将右侧后验和未来投资建议与 psi 相乘并将其输入到优化问题中？点预测显然不准确，因为我们不考虑似然函数并且不对输出进行离散化，但这样做难道不应该足以获得某种平均预测吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654307/use-estimates-from-zero-inflated-negative-binomial-regression-in-optimization-pr</guid>
      <pubDate>Fri, 13 Sep 2024 06:46:06 GMT</pubDate>
    </item>
    <item>
      <title>下采样是否是一种比较不同样本量组间回归结果的有效方法？如果是，那么如何实现？</title>
      <link>https://stats.stackexchange.com/questions/654301/is-downsampling-a-valid-approach-to-compare-regression-results-across-groups-wit</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654301/is-downsampling-a-valid-approach-to-compare-regression-results-across-groups-wit</guid>
      <pubDate>Thu, 12 Sep 2024 23:50:58 GMT</pubDate>
    </item>
    <item>
      <title>生存模型中的时间间隔</title>
      <link>https://stats.stackexchange.com/questions/654297/time-interval-in-a-survival-model</link>
      <description><![CDATA[要使用 Cox 回归，我们可以使用 R 中的以下函数作为示例。

coxph(Surv(time, status) ~ sex, data = lung)

如果我们有一个时间依赖性协变量，我们需要以一种称为计数过程格式的格式设置一个特殊的数据集。
假设我们有以下数据。
T1 和 delta1 是时间和事件指标变量。
TA 和 deltaA 是继发性疾病的时间和事件指标。

## my_id T1 delta1 TA deltaA
## 1 1 2081 0 67 1
## 2 2 1602 0 1602 0
## 3 3 1496 0 1496 0
## 4 4 1462 0 70 1
## 5 5 1433 0 1433 0

我们需要将数据结构更改为以下格式，以便在 Cox 回归中包含时间相关的协变量。
## my_id T1 delta1 tstart tstop death agvhd
## 1 1 2081 0 0 67 0 0
## 2 1 2081 0 67 2081 0 1
## 3 2 1602 0 0 1602 0 0
## 4 3 1496 0 0 1496 0 0
## 5 4 1462 0 0 70 0 0
## 6 4 1462 0 70 1462 0 1
## 7 5 1433 0 0 1433 0 0

coxph(
Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, 
data = td_dat
) %&gt;% 
tbl_regression(exp = TRUE)

*我的问题是：为什么我们需要定义间隔（添加 tstart）来应用 Cox 回归？为什么不能仅通过包含 tstop 来运行 Surv 函数（如以下函数）？既然我们知道事件发生的确切时间（tstop），那么 tstart 在计算中的作用是什么？
 coxph(Surv(time=tstop, event = death) ~ agvhd, data = .) 
]]></description>
      <guid>https://stats.stackexchange.com/questions/654297/time-interval-in-a-survival-model</guid>
      <pubDate>Thu, 12 Sep 2024 22:20:58 GMT</pubDate>
    </item>
    <item>
      <title>仅具有一个连续预测变量和小样本量的二元逻辑回归：测试显着性和拟合优度是否有意义？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654296/binary-logistic-regression-with-only-one-continious-predictor-and-a-small-sample</link>
      <description><![CDATA[我有一个包含 10 个数据点的拟合二元模型。单个连续变量位于 [2.4, 4.4] 区间，有一个二元输出变量 Y。Y 包含 4 个 Y=1 的事件和 6 个 Y=0 的事件。在避免完全分离的情况下，建模效果很好。我使用了 Python。
我读过许多论文，其中指出需要检查逻辑回归的假设（(1)线性：线性预测器是否正确？(2) Logit 变换是将协变量与条件均值联系起来的正确函数，以及 (3) 方差是伯努利）。
我的问题如下：

只有一个预测器，我需要检查线性吗？或者就此而言：任何假设？仅供参考：我无法添加第二个协变量。

如果我只有一个变量，我需要测试变量的显著性吗？这意味着我要用零模型来测试我的模型。这个测试基本上是似然比测试，它总是会告诉我我的协变量是显著的，对吧？所以这个测试不会给我任何信息？


关于评估模型：有预测能力的测量（McFadden 伪 R^2、Brier 分数）和拟合优度测试，它们只是测试是否存在我遗漏的非线性或相互作用。
由此产生了两个问题：

GOF 测试：关于第一个问题：当我假设我的假设得到满足时，我是否还需要执行经典的 GOF 测试，如 Hosmer-Lemeshow 测试？当 HL 测试基本上只是测试是否存在我遗漏的非线性或相互作用，并且我得出结论它们不存在时，我可以不执行测试吗？根据这种推理，这有效吗？当它无效时：对于 10 个样本，哪一个是可接受的/最好的？
关于预测能力测试：对于 10 个样本，哪一个是可接受的/最好的？不幸的是，我没有办法获得更多样本。我喜欢 McFadden Pseudo R^2，它给我的值为 0.41。我可以在这么小的样本量下使用它吗？

如果您需要有关我的模型的更多信息，请告诉我！]]></description>
      <guid>https://stats.stackexchange.com/questions/654296/binary-logistic-regression-with-only-one-continious-predictor-and-a-small-sample</guid>
      <pubDate>Thu, 12 Sep 2024 22:12:20 GMT</pubDate>
    </item>
    <item>
      <title>线性机器学习模型的数字输入变量的概率分布</title>
      <link>https://stats.stackexchange.com/questions/654261/probability-distribution-of-numeric-input-variables-for-linear-machine-learning</link>
      <description><![CDATA[所以我读了这本书：Jason Brownlee 的机器学习的数据准备。其中有一段文字有点令人困惑，我找不到任何解释。
“例如，一些算法假设每个输入变量，也许还有目标变量，
具有特定的概率分布。线性机器学习模型通常就是这种情况，它们期望每个数字输入变量都具有高斯概率分布。这意味着，如果您的输入变量不是高斯或接近高斯，则可能需要更改它们，使它们成为高斯或更接近高斯的变量。” 
我知道对于任何固定的 $X$（输入）值，$Y$（目标）都呈正态分布，如下图所示，输入也是这样吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654261/probability-distribution-of-numeric-input-variables-for-linear-machine-learning</guid>
      <pubDate>Thu, 12 Sep 2024 11:01:49 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中进行数据拟合时，如何处理区间数据（具有无限上限）？</title>
      <link>https://stats.stackexchange.com/questions/654300/how-do-i-deal-with-interval-data-having-infinite-upper-limit-when-doing-data-f</link>
      <description><![CDATA[我从一份政府报告中提取了住房建筑面积（​​以平方米 (sqm.) 为单位）的数据。第一类指建筑面积低于 5 平方米，最后一类指建筑面积为 200 平方米或以上。鉴于下限和上限有点模糊，我怀疑在进行数据拟合时这些因素会产生重大影响。实际上，没有零平方米甚至 1 平方米的房屋；此外，人们可以拥有非常宽敞的地板面积，但在给定的数据中，超过 200 平方米的面积限制并没有得到很好的确定。
category &lt;- c(&quot;&lt; 5&quot;, &quot;5 - 9&quot;, &quot;10 - 19&quot;, &quot;20 - 29&quot;, &quot;30 - 49&quot;, &quot;50 - 69&quot;, &quot;70 - 89&quot;, &quot;90 - 119&quot;, &quot;120 - 149&quot;, &quot;150 - 199&quot;, &quot;&gt; 200&quot;)
count &lt;- c(13676, 48589, 111144, 174631, 203851, 124424, 82277, 54410, 31702, 16239, 14516)

为了进行数据拟合，我尝试生成 Cullen 和 Frey 图。我假设我无法处理区间数据，因此我将区间转换为中点。请注意，对于下限和上限，我只是假设它们是 5 平方米。和 200 平方米，尽管我不确定这是否是一个合理的假设，因为概率分布在稍后模拟时会产生误导，即会产生零或接近零的值或远远超过 200 的值。
# 步骤 1：安装必要的软件包
install.packages(&quot;fitdistrplus&quot;)
install.packages(&quot;moments&quot;)

# 步骤 2：加载软件包
library(fitdistrplus)
library(moments)

# 步骤 3：准备数据
类别 &lt;- c(&quot;&lt; 5&quot;, &quot;5 - 9&quot;, &quot;10 - 19&quot;, &quot;20 - 29&quot;, &quot;30 - 49&quot;, &quot;50 - 69&quot;, &quot;70 - 89&quot;, &lt;90 - 119&quot;, &lt;120 - 149&quot;, &lt;150 - 199&quot;, &gt; 200&quot;)
count &lt;- c(13676, 48589, 111144, 174631, 203851, 124424, 82277, 54410, 31702, 16239, 14516)

# 使用中点近似
中点 &lt;- c(5, (5+9)/2, (10+19)/2, (20+29)/2, (30+49)/2, (50+69)/2, 
(70+89)/2, (90+119)/2, (120+149)/2, (150+199)/2, 200)

# 根据计数值重复中点
data &lt;- rep(midpoints, count)

# 步骤 4：Cullen 和 Frey 图测试
descdist(data, discrete = FALSE, boot = 1000)

Cullen 和 Frey 图测试表明分布为 Beta。本能地，我认为楼面面积的概率分布最有可能是对数正态的。不确定的上限和下限是否可能影响 Cullen 和 Frey 图的结果？
总结：
当我有区间数据并且想要找到给定数据集的最佳拟合概率分布时，如何处理不确定的上限和下限？]]></description>
      <guid>https://stats.stackexchange.com/questions/654300/how-do-i-deal-with-interval-data-having-infinite-upper-limit-when-doing-data-f</guid>
      <pubDate>Thu, 12 Sep 2024 00:26:16 GMT</pubDate>
    </item>
    </channel>
</rss>