<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 26 Sep 2024 15:18:10 GMT</lastBuildDate>
    <item>
      <title>多元对数正态线性变换的 PDF 和矩</title>
      <link>https://stats.stackexchange.com/questions/654954/pdf-and-moments-for-a-linear-transformation-of-multivariate-lognormal</link>
      <description><![CDATA[我有一个多元对数正态变量$Y$，维度为$d$。 $Y=e^X$ 其中 $X\sim N(\mu,\Sigma)$。
就 $\mu$ 和 $\Sigma$ 而言，对数正态分布的 PDF 为：
$$
p(\vec{y}|\mu,\Sigma) = ((2\pi)^d|\Sigma|)^{-\frac{1}{2}}\Pi_i{y_i^{-1}}\exp\left\lbrack{(\ln(\vec{y}) - \mu)^T\Sigma^{-1}(\ln{(\vec{y})} - \mu))}\right\rbrack
$$
我正在寻找第三个变量 $Z$ 的 pdf 和矩，其中 $Z=AY$，其中 $A \in R^{pxd}$ 为矩形矩阵 $p&lt;d$。最终，我希望可视化“投影”变量 $Z$（平面子空间上的分布）的统计数据，就像绘制高斯的均值和协方差一样。
很高兴回答任何澄清问题。在此先感谢您的任何想法和指导！
PS——这是一篇关于多元对数正态变量矩生成函数的很好的文章，但我不清楚如何“干净地”处理线性变换。这是一篇关于对数正态分布的很好的论文。]]></description>
      <guid>https://stats.stackexchange.com/questions/654954/pdf-and-moments-for-a-linear-transformation-of-multivariate-lognormal</guid>
      <pubDate>Thu, 26 Sep 2024 15:02:21 GMT</pubDate>
    </item>
    <item>
      <title>如何在具有两个或更多假设的 Kruskal Wallis 检验中调整 p 值</title>
      <link>https://stats.stackexchange.com/questions/654953/how-to-adjust-for-p-values-in-kruskal-wallis-test-with-two-or-more-hypothesis</link>
      <description><![CDATA[我需要帮助调整 p 值。我有 200 名患者。我使用 3 个指标将这组患者分为不同的类别。以下是它们的分布情况。



指标 A 类别
患者人数




无
120


轻度
55


中度
20


重度
5






指标 B类别
患者人数




低风险
125


中等风险
55


高风险
20






指标 C 类别
患者人数




疾病
160


无疾病
40



我感兴趣的是，指标 A 的各组之间的体重指数和载脂蛋白 A 水平是否存在显著差异。我还对指标 B 的相同变量感兴趣。还有指标 C。我决定使用 Kruskal-Wallis 检验，因为所有指标的分布都不符合方差分析的假设。
我最初使用 Bonferroni 方法，alpha 为 0.05，以校正 Kruskal-Wallis 检验得出的 p 值。由于我对两个变量感兴趣，即载脂蛋白 A 和体重指数，我认为我应该使用 m =2。这为我得出了调整后的 p 值 0.025。我使用这个 p 值阈值来确定 Kruskal-Wallis 检验的哪些结果是显著的。
只有指标 A 的 p 值 &lt; 0.025。之后，我使用 alpha 为 0.05 的 Conover-Iman 检验和使用 Holm-Bonferroni 方法的 p 调整来确定指标 A 中各组之间的载脂蛋白 A 和 BMI 是否不同。
但是，我不确定这是否是正确的方法。从本网站的帖子中，有人建议使用所有假设检验的数量来调整 p。使用帖子的示例，在我的情况下，这将是 (4 * 2) + (3 * 2) + (2 * 2) = 18。因此 m = 18，这将为我提供一个 p &lt;0.002 的阈值。我看到的另一种方法是在事后检验后直接进行p 值调整，而不事先进行任何校正。哪种方法是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654953/how-to-adjust-for-p-values-in-kruskal-wallis-test-with-two-or-more-hypothesis</guid>
      <pubDate>Thu, 26 Sep 2024 14:41:47 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分类，使用滞后数据和外生时间序列变量作为探索性特征</title>
      <link>https://stats.stackexchange.com/questions/654951/time-series-classification-using-lagged-data-and-exogenous-time-series-variabl</link>
      <description><![CDATA[我有以下 pandas 数据框
import pandas as pd
pd.DataFrame({
&#39;region&#39;: [1,1,1,1,2,2,2,2,3,3,3,3],
&#39;week&#39;: [1,2,3,4,1,2,3,4,1,2,3,4],
&#39;rain&#39;: [1,1,0,1,1,1,1,1,1,0,0,0],
&#39;clouds&#39;: [1,1,0,0,0,0,1,0,1,0,0,0]
})

region 周 雨 云
0 1 1 1 1
1 1 2 1 1
2 1 3 0 0
3 1 4 1 0
4 2 1 1 0
5 2 2 1 0
6 2 3 1 1
7 2 4 1 0
8 3 1 1 1
9 3 2 0 0
10 3 3 0 0
11 3 4 0 0

表示在特定区域、特定周，如果下雨，则考虑该周该地区是否有云。
在我的示例示例中，我希望能够预测第 n 周是否会下雨，同时考虑前几周是否下雨以及前几周是否有云。
我该如何实现？对于此类问题，什么模型合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/654951/time-series-classification-using-lagged-data-and-exogenous-time-series-variabl</guid>
      <pubDate>Thu, 26 Sep 2024 14:18:49 GMT</pubDate>
    </item>
    <item>
      <title>如何确定具有模糊随机化单元的实验的样本大小？</title>
      <link>https://stats.stackexchange.com/questions/654948/how-to-determine-sample-sizes-for-experiments-with-ambiguous-randomisation-units</link>
      <description><![CDATA[我正在运行 A/B 测试，以比较在线拍卖系统中的两种竞价策略，其目标是提高投资回报率 (ROI)。这两种策略在展示次数和转化次数的竞价方式上有所不同，因此支出金额和转化次数并不相互独立。
由于不同拍卖中同一转化可能会出现多个竞价（即，同一用户在转化之前可能会被多次定位），因此我无法假设各个拍卖是独立的。相反，我将每一天视为一个集群，观察总支出、转化次数和收入以计算当天的投资回报率。
我想计算需要运行此测试多少天才能检测到两种策略之间的投资回报率的显著差异。详情如下：

ROI=收入/支出
ROI=支出收入​
基准 ROI：当前（固定）竞价策略下的 ROI 为 $ ROI_0 $​。
目标 ROI：我预计新的（自适应）竞价策略可将 ROI 提高 $δ$（例如 10%）。
集群大小：平均每天有 m 次拍卖。
集群内相关性 (ICC)：我预计每天（集群）内的拍卖是相关的，但我不确定如何估算。
标准差：我对基准策略的每日 ROI 标准差进行了估计，$σ_{ROI_0}​$​。

我知道在集群随机试验中，所需的集群数量（天数）可以使用以下公式计算：
$$
N_{\text{clusters}} = \left( \frac{Z_{\alpha/2} + Z_{\beta}}{\delta_{\text{ROI}}} \right)^2 \times \frac{\sigma_{\text{ROI}_0}^2}{m \left( 1 + (m - 1) \cdot \text{ICC} \right)}
$$
其中：

$ Z_{\alpha/2} $：重要性水平的临界值（例如，重要性为 5% 时为 1.96）。
$ Z_{\beta} $：功效的临界值（例如，功效为 80% 时为 0.84）。
$ \delta_{\text{ROI}} $：ROI 中可检测到的最小差异（例如，10% 的改善）。
$ m $：每天的平均拍卖次数。
$ \text{ICC} $：集群内相关系数。
$ \sigma_{\text{ROI}_0} $：ROI 的标准差基线投资回报率。

问题：

鉴于支出和转化相互交织，我应该如何估计投资回报率的集群内相关性 (ICC)？

上述公式是否适合计算测试所需的天数？如果不适合，我应该考虑哪些调整？


3. 在当前策略下，在估计每日投资回报率的标准差时，我应该考虑哪些因素？
如能提供任何有关如何进行此计算或改进这些估算的指导，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/654948/how-to-determine-sample-sizes-for-experiments-with-ambiguous-randomisation-units</guid>
      <pubDate>Thu, 26 Sep 2024 13:33:47 GMT</pubDate>
    </item>
    <item>
      <title>逐点互信息（PMI）逐点是什么？</title>
      <link>https://stats.stackexchange.com/questions/654946/what-is-pointwise-about-pointwise-mutual-information-pmi</link>
      <description><![CDATA[我在学习自然语言处理时刚刚遇到了正逐点互信息 (PPMI)。我没有很好的统计学基础。我理解为什么它是正，因为在 NLP 中，他们不使用负 PMI 值。我查看了互信息 (MI)和逐点互信息 (PMI)的维基百科页面，我对互信息是什么有了大致的了解，但无法解释是什么让它成为逐点的。 相互信息页面没有进一步说明

MI 是逐点相互信息 (PMI) 的期望值

现在，我觉得我不知道 PMI 在做什么。它计算的点数是多少？我试过谷歌，但没有看到可以澄清的来源。]]></description>
      <guid>https://stats.stackexchange.com/questions/654946/what-is-pointwise-about-pointwise-mutual-information-pmi</guid>
      <pubDate>Thu, 26 Sep 2024 13:27:46 GMT</pubDate>
    </item>
    <item>
      <title>统计评估多组中两个变量的</title>
      <link>https://stats.stackexchange.com/questions/654941/statistics-evaluating-two-variables-in-several-groups</link>
      <description><![CDATA[我不确定在以下实验场景中会使用哪种统计数据 (MVA)：
在不同条件下，我测量两个（对数范数分布）参数，并想评估这些条件对参数的单独和/或组合影响。
实际上，数据可能如下所示：
在不同条件下测量的两种细菌共培养中，对每种细菌的细胞数进行多次重复计数（数据矩阵中的 log2 细胞数）：



:实验
:BacA:
:BacB:




CondA_rep1
1.5
1.1


CondA_rep2
1.3
1.2


CondA_rep3
1.5
1.1


CondB_rep1
3.0
4.1


CondB_rep2
2.9
4.2


CondB_rep3
3.2
3.9


CondC_rep1
6.0
2.1


CondC_rep2
5.7
1.8


CondC_rep3
5.3
2.1



对于统计测试，我可以将数据转换为 BacX/BacY 的比率和每个实验中的细胞总数。或者保留原值。
使用 ANOVA，我可以测试比率和/或细胞总数，但是，我想一起测试数据（BacX/BacY 的比率和总生长；或 BacX 和 BacY 的细胞数）。
到目前为止，我的研究表明我可以使用类似 MANOVA 的方法？
我希望这个问题可以理解。到目前为止，我只对单个因素/变量进行了测试，其中 T 检验或方差分析就是我所需要的，甚至通过在线搜索找到正确的术语来查找合适的统计数据也不是很成功。
所以任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654941/statistics-evaluating-two-variables-in-several-groups</guid>
      <pubDate>Thu, 26 Sep 2024 11:06:16 GMT</pubDate>
    </item>
    <item>
      <title>有调节的中介分析中交互项的 VIF</title>
      <link>https://stats.stackexchange.com/questions/654940/vif-for-interaction-terms-in-moderated-mediation-analysis</link>
      <description><![CDATA[据我所知，作为两个独立变量的乘积，VIF 可以自然地膨胀为交互项？
我想阅读包含交互作用的模型的多重共线性，是否有一些我也可以引用的文献？]]></description>
      <guid>https://stats.stackexchange.com/questions/654940/vif-for-interaction-terms-in-moderated-mediation-analysis</guid>
      <pubDate>Thu, 26 Sep 2024 10:54:13 GMT</pubDate>
    </item>
    <item>
      <title>计算零事件/发生率的相对风险或风险比</title>
      <link>https://stats.stackexchange.com/questions/654938/calculating-relative-risk-or-risk-ratio-with-zero-events-incidence</link>
      <description><![CDATA[我读过这篇关于戴口罩影响的最新评论，偶然发现了这张图表，其中显示了佩戴医用口罩和不戴口罩的风险比，这些风险比在不同研究中以不同的结果衡量。
除一些舍入问题外，我可以复制远处风险比的点估计图中右列。例如，对应于 Aiello(PCR-influenza),2010 RR 值 2.43 的第三行是通过执行 $\frac{5}{378}/\frac{3}{552}$ 计算得出的。
但是——不熟悉生物统计学的标准做法——我不确定当测量 0（零）事件时会做什么，例如图中的第二行（Macintyer(PCR-influenza),2009）和第七行（Bundgaard(PCR-SARS-CoV-2),2002）。
我在网上能找到的最有用的信息来源是 NIH 的这个页面：在观察到零事件时估计相对风险——频率推断和贝叶斯可信区间 - PMC。
这里讨论了三种方法：

在交叉表中的每个单元格中添加一个。
将干预组中的一个非事件移动到事件。
在交叉表中的每个单元格中添加 0.5。

据我了解，此处呈现的数据不是标准交叉表格式（即事件和非事件（干预组和对照组），但玩了一会儿我发现方法 3.（或我对它的解释）似乎是图中使用的方法。
对于 Macintyre(PCR_influenza),2009，我们得到
$$ \frac{1 + 0.5}{94 + 0.5} / \frac{0 + 0.5}{100 + 0.5} = 3.19 $$
对于 Bundgaard(PCR-SARS-CoV-2),2021，我们得到
$$ \frac{0 + 0.5}{2392 + 0.5} / \frac{5 + 0.5}{2470 + 0.5} = 0.09 $$
与最右侧列的相应条目相匹配。
问：这是正确的程序吗？
当然，第一种情况似乎表明了这一点，否则很难得到接近 3 的比率。但分母（掩蔽和未掩蔽情况下的总观察次数）似乎足够大，以至于有一些空间可以捏造。当干预组和对照组的总观察次数少于 10 次时会发生什么？
这种方法的统计依据是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654938/calculating-relative-risk-or-risk-ratio-with-zero-events-incidence</guid>
      <pubDate>Thu, 26 Sep 2024 10:43:04 GMT</pubDate>
    </item>
    <item>
      <title>斜率的线性回归 MLE；OLS 和双变量 MLE</title>
      <link>https://stats.stackexchange.com/questions/654936/linear-regression-mle-of-slope-ols-and-bivariate-mle</link>
      <description><![CDATA[假设变量 X 和 Y 取自二元正态分布，其均值向量为 $(\mu, \mu)$，且均具有相同的总体方差 $V$，且该方差已知。唯一未知的参数是 $\rho$。
样本仅包含低于已知截止值 $c$ 的 X 值，该值小于 $\mu$ 和相应的 $Y$ 值。因此，样本均值和方差与真实（已知）总体均值和方差不同。

将其定义为线性回归问题是否正确，模型为$Y = \beta_0 + \beta_1 X + \epsilon $，并且由于方差相同，取$\rho = \beta_1$？

OLS 估计量最小化$(y - \mu) - \beta_1(x - \mu) $恰好为$\Sigma (x_i - \mu)(y_i - \mu)/\Sigma (x_i - \mu)^2 $，MLE 也获得相同的结果假设残差$(y_i - \mu) - \beta_1(x_i - \mu) $呈正态分布，均值为零，方差固定。

是否可以使用已知均值和 SD 的原始双变量分布的 MLE 来估计$\rho$？我试图获得估计值，但它包含$\rho$的三次表达式，我无法求解。在模拟中，双变量的 MLE 并不完全相同。这些方法是否等效？

更新：
截断机制：$X$是生化参数的测量值。仅当 $X$ 低于截止值 $c$ 时，才进行重复测量 $(Y)$。假设第一次测量不影响第二次测量，我想使用此截断数据对估计它们之间的无偏相关性。]]></description>
      <guid>https://stats.stackexchange.com/questions/654936/linear-regression-mle-of-slope-ols-and-bivariate-mle</guid>
      <pubDate>Thu, 26 Sep 2024 10:17:55 GMT</pubDate>
    </item>
    <item>
      <title>二项比例方差的方差的文献参考</title>
      <link>https://stats.stackexchange.com/questions/654934/literature-reference-for-variance-of-the-variance-of-the-binomial-proportion</link>
      <description><![CDATA[如果 K 是 $n$ 次伯努利试验后的成功次数，成功概率为 $p$，则它服从二项分布：K $\sim$ Bin(n, p)。估计比例 $\hat{p}= \frac{K}{n}$ 已知方差为 $n^{-1}p(1-p)$。
然而，这个方差估计量的方差是多少，即 $Var\left(n^{-1}\hat{p}(1-\hat{p})\right)$？我正在尝试使用二项分布的高阶矩来解决这个问题，找到答案后我会发布，但我想知道是否有人为我做过这项工作。因此，任何对现有文献或 CV 问题的引用都非常受欢迎。
Bradley 等人 (2008) “Brier 分数和 Brier 技能分数的抽样不确定性和置信区间”在他们的方程 (29) 中提供了一个公式，但这感觉不对，因为它很容易产生负方差。我在他们引用的 Kenney 和 Keeping (1951) 中找不到这个表达式。
这里提供了 delta 方法近似值，但我正在寻找一个精确的解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/654934/literature-reference-for-variance-of-the-variance-of-the-binomial-proportion</guid>
      <pubDate>Thu, 26 Sep 2024 10:03:15 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的因子分析？</title>
      <link>https://stats.stackexchange.com/questions/654932/factor-analysis-for-repeated-measures-data</link>
      <description><![CDATA[我创建了一个包含 9 个标准的评估标准，用于评估演示，现在我想验证一下。
我想对此进行因子分析。
我有什么数据？所有 66 人都对 4 个演示进行了评分。这 4 个演示对所有 66 人来说都是相同的。
我可以对所有 4 个演示进行一次 EFA 或 CFA 吗？
我不确定这是否真的是重复测量设计。经验表明，因子结构也取决于被评估的演示。因此，如果可能的话，我想进行一次单因子分析，整合所有 4 个演示的评分。
如果有人能帮忙就太好了]]></description>
      <guid>https://stats.stackexchange.com/questions/654932/factor-analysis-for-repeated-measures-data</guid>
      <pubDate>Thu, 26 Sep 2024 09:43:38 GMT</pubDate>
    </item>
    <item>
      <title>模拟人们离开鸡尾酒会</title>
      <link>https://stats.stackexchange.com/questions/654926/simulate-people-leaving-a-cocktail-party</link>
      <description><![CDATA[这是我研究了一段时间的一道数学题 https://math.stackexchange.com/questions/4976090/probability-of-people-leaving-a-cocktail-party
在这个问题中，有一个有“n”个人的鸡尾酒会。然而，随着越来越多的人离开聚会，人们离开聚会的速度也会增加。我们假设没有新人可以加入派对，离开派对的客人将永远离开。
我试图模拟客人在以下条件下离开派对的情况：

加速离开：客人离开派对的速度取决于派对上目前有多少客人
标准离开：客人离开派对的速度完全随机

我试图在 R 中对此进行模拟：
library(ggplot2)
library(dplyr)

simulate_party_accelerating &lt;- function(n, alpha) {
t &lt;- 0
X &lt;- n
times &lt;- c(0)
​​people &lt;- c(n)
while (X &gt; 0) {
lambda &lt;- alpha * (n - X + 1) / X
T &lt;- rexp(1, lambda * X)
t &lt;- t + T
X &lt;- X - 1
次 &lt;- c(次, t)
人 &lt;- c(人, X)
}
data.frame(时间 = 次, 人 = 人)
}

simulate_party_fixed &lt;- function(n, lambda) {
t &lt;- 0
X &lt;- n
次 &lt;- c(0)
​​人 &lt;- c(n)
while (X &gt; 0) {
T &lt;- rexp(1, lambda * X)
t &lt;- t + T
X &lt;- X - 1
次 &lt;- c(次, t)
人 &lt;- c(人, X)
}
data.frame(时间 = 次, 人 = 人)
}

run_simulations &lt;- function(n_sims, n_people, alpha, lambda) {
sim_data_accelerating &lt;- lapply(1:n_sims, function(i) {
df &lt;- mock_party_accelerating(n_people, alpha)
df$simulation &lt;- i
df$type &lt;- &quot;Accelerating&quot;
return(df)
})

sim_data_fixed &lt;- lapply(1:n_sims, function(i) {
df &lt;- mock_party_fixed(n_people, lambda)
df$simulation &lt;- i
df$type &lt;- &quot;Fixed&quot;
return(df)
})

rbind(do.call(rbind, sim_data_accelerating),
do.call(rbind, sim_data_fixed))
}

n_people &lt;- 100
alpha &lt;- 0.1
lambda &lt;- 0.1 
n_sims &lt;- 100

set.seed(123) # 用于可重复性
sim_results &lt;- run_simulations(n_sims, n_people, alpha, lambda)

ggplot(sim_results, aes(x = time, y =人， 
组 = 交互（模拟，类型），颜色 = 类型））+
geom_line（alpha = 0.3）+
scale_color_manual（值 = c（“加速” = “蓝色”，“固定” = &quot;red&quot;)) +
labs(title = &quot;派对出发模拟：加速与固定速度&quot;,
x = &quot;时间&quot;, y = &quot;剩余人数&quot;,
subtitle = paste(n_people, &quot;initial people,&quot;, n_sims, 
&quot;simulations each&quot;)) +
theme_minimal() +
guides(color = guide_legend(title = &quot;出发率&quot;))


乍一看，这似乎有些不合逻辑。似乎加速离场的派对比完全随机离场的派对持续时间更长。
我是不是哪里搞错了？或者这仅仅取决于 alpha 和 lambda 的选择？（例如，我注意到，对于其他 alpha 和 lambda 值，加速离场的派对持续时间比另一方短）。
对问题可能是什么有什么想法？]]></description>
      <guid>https://stats.stackexchange.com/questions/654926/simulate-people-leaving-a-cocktail-party</guid>
      <pubDate>Thu, 26 Sep 2024 05:36:11 GMT</pubDate>
    </item>
    <item>
      <title>处理连续比率模型中的缺失信息 - 审查？</title>
      <link>https://stats.stackexchange.com/questions/654925/handling-missing-information-in-continuation-ratio-model-censoring</link>
      <description><![CDATA[我正在 R 中拟合连续比率模型，首先使用 rms::cr.setup() 将数据放入“人阈值”或“人周期”格式，然后拟合逻辑回归。（如 Cole &amp; Ananth, 2001 中所述）。我的结果涉及“治疗级联”的进展程度每个人得到：
1 - 需要治疗但未转诊
2 - 转诊（但未参加入院治疗）
3 - 参加入院治疗（但治疗时间 &lt;14 天）
4 - &gt;= 14 天治疗

我的问题是，对于某些人，我们知道他们参加了入院治疗，但没有关于他们接受治疗时间的信息。换句话说，我们知道它们对结果的价值是 &gt;=3，但不知道真实值是 3 还是 4。
我读到，连续比率模型可以概念化为具有逻辑链接的离散生存或风险模型（例如，Cole &amp; Ananth，2001；Suresh 等人，2022；Tutz &amp; Schmid，2016，第 38 页）。鉴于此，我可以右删失那些我不知道它们是否超出摄入量/第 3 级的情况吗？我该如何实现这一点？
图 1 来自 Suresh 等人。似乎表明我可以通过添加行直到审查点来实现这一点，但对于这些情况将所有值设置为 0（例如，ID 2 在间隔 4 处审查，ID 3 在间隔 5 处审查）：

但我真的不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/654925/handling-missing-information-in-continuation-ratio-model-censoring</guid>
      <pubDate>Thu, 26 Sep 2024 05:09:51 GMT</pubDate>
    </item>
    <item>
      <title>如何平滑这些曲线以获取其趋势？</title>
      <link>https://stats.stackexchange.com/questions/654922/how-to-smoothen-these-curves-to-get-their-trends</link>
      <description><![CDATA[我有一组 10 个信号，如下所示：

我们可以看到，它们非常嘈杂（它们是来自软件分析的数据，即运行时），而大多数噪声都是异常值。我需要能够以某种方式使它们平滑，从而保留每个信号中的点数。
到目前为止，我已经尝试了双重应用中值滤波器，然后将序列标准化为 0-1 范围，并且获得了接近我想要的结果，但不幸的是，它们并不适用于所有情况，并且在信号开始时看起来并不可靠：

那么，您知道对这种情况有用的方法吗？我在这个领域的知识非常有限，基本上仅限于中值滤波和 Savitzky-Golay，这似乎没什么用。
我需要非常平滑的线条来保留主要趋势（不是超精确），并且没有异常值/振荡，因为我打算稍后进行一些相似性分析，希望根据曲线的趋势/形状将其分类为“类”。我希望根据MSE对相似度进行分类。

数据（10个列表的列表）
链接：https://jpst.it/3VUqP

MWE
 data = []
for filename in filenames:
for fork in json.load(open(PATH)):
# 平滑
smooth_fork = median_filter(median_filter(fork, size=150), size=50)

# 规范化
data.append(list((np.array(smooth_fork) - np.min(smooth_fork)) / (np.max(smooth_fork) - np.min(smooth_fork))))

plt.figure()
for fork in data:
plt.plot(fork)
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/654922/how-to-smoothen-these-curves-to-get-their-trends</guid>
      <pubDate>Thu, 26 Sep 2024 01:10:42 GMT</pubDate>
    </item>
    <item>
      <title>应该用置信区间还是 t 检验来评估统计显著性？</title>
      <link>https://stats.stackexchange.com/questions/654897/should-one-assess-statistically-significance-with-confidence-intervals-or-a-t-te</link>
      <description><![CDATA[我有兴趣评估两个时间序列均值差异的统计显著性。
为了这个目标，我生成了两个时间序列中均值的引导程序。
然后我遵循了两种方法：
A. 计算引导程序差异的 95% 置信区间（使用百分位数 p2.5 和 p97.5），并将零不在置信区间内的区域视为统计显著。
B. 在两个引导均值之间使用配对 t 检验 (scipy.stats.ttest_rel) 来计算 p 值，并将 p 值低于 .05 的区域视为统计显著
以下哪个选项是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654897/should-one-assess-statistically-significance-with-confidence-intervals-or-a-t-te</guid>
      <pubDate>Wed, 25 Sep 2024 15:15:05 GMT</pubDate>
    </item>
    </channel>
</rss>