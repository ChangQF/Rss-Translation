<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 14 Nov 2024 03:22:27 GMT</lastBuildDate>
    <item>
      <title>为什么在尝试解释许多 RV 可以通过正态分布很好地建模这一事实时，我们要依赖 CLT？</title>
      <link>https://stats.stackexchange.com/questions/657234/why-do-we-rely-on-clt-when-trying-to-explain-the-fact-that-many-rvs-are-well-mod</link>
      <description><![CDATA[我曾听到过许多声称 RV $W$ 的说法，它本质上是大量其他 RV $W_1,W_2,\dots, W_n$ 的总和，由于 CLT 而具有正态分布。我相信在许多情况下，这些 $W_i$ 满足 CLT 适用的条件。但我不明白为什么我们可以将正态分布的 PDF 用作 $W$ 的 PDF（假设 $W_i$ 是连续的），因为一般来说，CLT 不能保证 $W$ 的 PDF 收敛到正态 RV 的 PDF。您能试着解释一下吗？
我知道，只要满足一些附加条件，我们就能保证 $W$ 的 PDF 将收敛到正态分布的 PDF。难道只是假设在实践中这些附加条件是完全合理的，而且很可能会被满足吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657234/why-do-we-rely-on-clt-when-trying-to-explain-the-fact-that-many-rvs-are-well-mod</guid>
      <pubDate>Thu, 14 Nov 2024 02:46:35 GMT</pubDate>
    </item>
    <item>
      <title>边际效应比率的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/657233/confidence-intervals-for-the-ratio-of-marginal-effects</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657233/confidence-intervals-for-the-ratio-of-marginal-effects</guid>
      <pubDate>Thu, 14 Nov 2024 02:28:39 GMT</pubDate>
    </item>
    <item>
      <title>计算事件总数的置信区间</title>
      <link>https://stats.stackexchange.com/questions/657232/calculating-a-confidence-interval-for-a-sum-of-events</link>
      <description><![CDATA[我有一个包含一组事件的试验，很多次都没有发生任何事件。每个事件都有一定的量级，但事件的量级遵循合理的分布（正态分布）。
我拥有的：

使用比例检验发现事件发生的概率，置信区间（事件率）为 95%
使用 t 检验对所有事件得出的事件量级的 95% 置信区间

我想要找到的

在规模为 n 的试验中，所有事件总和的 95% 置信区间。

示例：
假设我试图估计如果有 n 位顾客进来，商店将赚多少钱。我收集了有关客户购买任何东西的可能性的数据，以及任何一次购买的平均金额的数据。
因为购买金额的分布极其不正常（你有一群客户如果商店中没有顾客购买任何东西，则对所有顾客进行 t 检验或 z 检验会违反正态性假设。更糟糕的是，商店很小，因此购买的商品数量很少（~10），而顾客数量较大，但仍然不多（~50）。
如果有 n 个顾客进来，有没有办法获得产生的收入的 95% 置信区间？]]></description>
      <guid>https://stats.stackexchange.com/questions/657232/calculating-a-confidence-interval-for-a-sum-of-events</guid>
      <pubDate>Thu, 14 Nov 2024 02:17:22 GMT</pubDate>
    </item>
    <item>
      <title>自定义损失函数过度拟合错误的输出，但 MSE 不会</title>
      <link>https://stats.stackexchange.com/questions/657231/custom-loss-function-overfits-to-the-wrong-output-but-mse-doesnt</link>
      <description><![CDATA[我有一个简单的函数，我想用神经网络来近似它：
N(1) = -1
N(2) = -1
N(3) = 1
N(4) = -1

我不想使用 MSE 或交叉熵损失，而是想尝试使用自定义损失函数：
它的工作原理如下：
if input == 3:
loss = -1 * output
else:
loss = 1 * output

如果我的网络以 tanh 激活结束，则当神经网络接近 N 时，其损失会最小化。因此，网络应该接近权重来计算 N。
但网络并没有接近 N。它采用一个函数，该函数为每个输入输出 -1（即使输入为 3）。下面是 pytorch 中的一些示例代码来演示：
import torch
import torch.nn as nn

# 损失函数
class CustomLoss(nn.Module):
def __init__(self):
super().__init__()

def forward(self, x, i):

multiplier = -1 if i == 3 else 1

return multiplier * x

# 网络 &amp;优化器
net = nn.Sequential(
nn.Linear(1, 20),
nn.Tanh(),
nn.Linear(20, 20),
nn.Tanh(),
nn.Linear(20, 20),
nn.Tanh(),
nn.Linear(20, 1),
nn.Tanh(),
)
optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)
loss_function = CustomLoss()

# 训练
for _i in range(100000):
i = _i % 4 + 1
input_value = torch.FloatTensor([i])
output_value = net(input_value)

optimizer.zero_grad()
loss_value = loss_function(output_value, i)
loss_value.backward()
optimizer.step()

print(i, output_value.item(), loss_value.item())

运行一分钟后，输出如下：
输入 | 输出 | 损失
1 | -0.9999958276748657 | -0.9999958276748657
2 | -0.9999961853027344 | -0.9999961853027344
3 | -0.9999962449073792 | 0.9999962449073792 &lt;--- 可以通过使输出 1
4 | -0.9999962449073792 | -0.9999962449073792

我在之前的一个问题（在 AI stackexchange 上）中问过为什么模型不适合，但得到的答复是，这是由于梯度消失造成的，因为
$$
\lim_{x \to \pm \infty} tanh^{\prime}(x) = 0
$$
一旦我的模型过度拟合到仅输出 -1 的情况，它就会被困在那里，因为没有梯度。但在使用 MSE 和 BCE 测试后，模型正确拟合。这两个损失函数都不能解决梯度消失问题。如果模型过度拟合，MSE 几乎无法将其从零梯度区域移出。
为了测试这个想法，我在我的损失函数上运行了该模型 1000 次迭代（直到它过度拟合到仅输出 -1 的情况）。然后我采用了同样的过度拟合模型，并在 MSE 上运行它。看到数据后，我惊讶地发现它能够在 MSE 上正确拟合（即使事先过度拟合）。所以看来我错了。
但我的问题是：为什么模型可以在 MSE 上突破这个零梯度区域，而在我的损失函数上却不能？
感谢您对此的任何澄清。]]></description>
      <guid>https://stats.stackexchange.com/questions/657231/custom-loss-function-overfits-to-the-wrong-output-but-mse-doesnt</guid>
      <pubDate>Thu, 14 Nov 2024 02:05:05 GMT</pubDate>
    </item>
    <item>
      <title>模型堆叠 - 折叠程序</title>
      <link>https://stats.stackexchange.com/questions/657230/model-stacking-out-of-fold-procedures</link>
      <description><![CDATA[我尝试使用模型堆叠程序，其中我使用时间序列分割我拥有的一组数据（大约 5000 个条目）。目标是二元分类。
在使用训练集上的 CV 获得基础模型的超参数后，我随后在折叠中训练基础模型并存储折叠外预测的预测概率。我最终将这些折叠外预测用作元模型中的特征。
但是存在一些问题和疑问。

当使用时间序列分割时，我似乎注意到我的平均折叠外预测大小明显小于折叠内预测中的数据量。因此，我没有一个很好的方法来选择我在训练/调整元模型时应该使用的折叠数量。例如，我注意到使用 10 的折叠大小会导致我的模型根本不合适（无论基础模型输入如何，它都只投射一个分类类别）。我的假设是，折叠量越大，元模型的数据量就越少，因此无法找到最佳拟合。我该如何选择最佳折叠量？
使用我目前的程序，我不确定如何校准我的基础模型（使用 CalibratedClassifierCV 之类的程序）。我应该在使用折叠概率之前校准我的基础模型吗？还是我应该在训练元模型之后校准我的基础模型（针对元模型特征的用例）。
]]></description>
      <guid>https://stats.stackexchange.com/questions/657230/model-stacking-out-of-fold-procedures</guid>
      <pubDate>Thu, 14 Nov 2024 01:07:12 GMT</pubDate>
    </item>
    <item>
      <title>当数据集中存在 NA 时，predict() 函数对 R 中的 lmer 不起作用</title>
      <link>https://stats.stackexchange.com/questions/657227/predict-function-fails-for-lmer-in-r-when-nas-present-in-dataset</link>
      <description><![CDATA[当数据集中存在 NA 时，predict() 函数对 lmer 失败，例如

请参阅附件 LMEM_TEST_withNA.csv。
R 代码读取（为简单起见，省略了数据重新缩放等）
library(tidyverse)
library(lme4)
library(lmerTest)

#### 读入数据 
fileName = paste0(&#39;LMEM_TEST&#39;)
DF &lt;- read.csv(paste0(fileName,&#39;.csv&#39;), check.names=FALSE, header = T) #
DF$SEX &lt;- as.factor(DF$SEX)
DF$TRT &lt;- as.factor(DF$TRT)

# 拟合线性混合效应模型
model_lmer &lt;- lmer(ENDPOINT ~ TIME + TRT + SEX + AGE + WT + BIOMARKER1 + BIOMARKER2 + TRT*TIME + (1 | ID), 
data = DF)

# 检查 model_lmer 的摘要
print(summary(model_lmer))

# 绘制数据和预测
p = ggplot(data = DF, aes(x=TIME, y=ENDPOINT, colour=factor(ID))) +
facet_wrap(~ ID) +
geom_point(size=2) +
geom_line(aes(y=predict(model_lmer)),linewidth=1)
print(p)

我收到的错误消息是
Stack/LMEM_withNA.R:28:1 处的 `geom_line()` 出错：
! 计算美学时出现问题。
ℹ 错误发生在第二层。
由 `check_aesthetics()` 中的错误引起：
! 美学的长度必须为 1 或与数据 (96) 相同。
✖ 修复以下映射：`y`。
运行 `rlang::last_trace()` 以查看错误发生的位置。

有什么想法可以修复它吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657227/predict-function-fails-for-lmer-in-r-when-nas-present-in-dataset</guid>
      <pubDate>Wed, 13 Nov 2024 23:28:54 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有特定选择变量的模型中使用 mlogit</title>
      <link>https://stats.stackexchange.com/questions/657226/how-to-use-mlogit-for-models-where-there-are-no-choice-specific-variables</link>
      <description><![CDATA[假设有人想在两部手机和两种颜色之间建立产品选择模型，但手机 1 只有红色或绿色，而手机 2 只有蓝色或黑色。因此选择中存在嵌套。但是，没有特定于选择的变量。如果为此使用 mlogit，下面的代码是否正确？
mlogit(choice ~ 1 | gender + age, data = ddataset, nests = nests)
其中 ddataset 格式化为长格式，每个参与者有 4 行（每个选择一行），但性别和年龄对于每一行都具有相同的值（因为它们属于同一个人）。]]></description>
      <guid>https://stats.stackexchange.com/questions/657226/how-to-use-mlogit-for-models-where-there-are-no-choice-specific-variables</guid>
      <pubDate>Wed, 13 Nov 2024 22:25:54 GMT</pubDate>
    </item>
    <item>
      <title>比较时间序列中不同位置的数据</title>
      <link>https://stats.stackexchange.com/questions/657224/comparing-data-at-different-locations-over-a-time-series</link>
      <description><![CDATA[我有来自放置在湖泊不同位置的探测器的水质数据，这些数据在整个夏季每小时收集一次。我想知道我收集的参数在四个位置之间是否存在差异。我还想知道在夏季的什么时候出现了最大的差异。我不知道可以运行什么统计测试来调查这两个问题。我绘制了时间序列数据，但这只能提供定性分析。
根据简短的搜索，我发现重复测量方差分析可能有效，因为数据都与时间戳配对，但我还看到广义线性模型或其他模型（如 AIRMA 模型）可能更好。我不太熟悉这些模型，所以我不确定它们是否适合我的数据或如何使用它们。
任何有关如何处理这些数据的建议都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/657224/comparing-data-at-different-locations-over-a-time-series</guid>
      <pubDate>Wed, 13 Nov 2024 21:01:16 GMT</pubDate>
    </item>
    <item>
      <title>木材分解</title>
      <link>https://stats.stackexchange.com/questions/657223/wold-decomposition</link>
      <description><![CDATA[AR(p) 模型的自协方差总和
为什么这个等式成立？
$$
\sum_{k=0}^{\infty} \psi_k = \frac{1}{1-\sum_{i=1}^{p}\phi_{i}}
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/657223/wold-decomposition</guid>
      <pubDate>Wed, 13 Nov 2024 20:15:45 GMT</pubDate>
    </item>
    <item>
      <title>配对样本（SD 和 SE）</title>
      <link>https://stats.stackexchange.com/questions/657222/paired-sample-sd-and-se</link>
      <description><![CDATA[在一些出版物中，没有关于数据是基于标准差 (SD) 还是标准误差 (SE) 的信息。例如，在一篇出版物中，他们写道：“切换前后的平均注射间隔是可比的（33.8 ± 11.2 vs. 29.3 ± 2.6 天；p = 0.08）。”通常，± 后的数字指的是 SD（标准差）或 SE（标准误差）。（例如在这个例子中：11.2 指的是 SD 还是 SE）？]]></description>
      <guid>https://stats.stackexchange.com/questions/657222/paired-sample-sd-and-se</guid>
      <pubDate>Wed, 13 Nov 2024 20:09:58 GMT</pubDate>
    </item>
    <item>
      <title>Kaplan Meier 与累积发生率和事件发生率有区别吗？</title>
      <link>https://stats.stackexchange.com/questions/657220/is-there-a-difference-in-kaplan-meier-and-cumulative-incidence-and-incidence-of</link>
      <description><![CDATA[卡普兰迈耶 (Kaplan Meier) 和累积发病率有区别吗？CI 只是 1 公里吗？例如，如果住院后 5 年内心血管死亡的估计发病率为 43%，那么 KM 生存率估计为 100 - 43%，这样说对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657220/is-there-a-difference-in-kaplan-meier-and-cumulative-incidence-and-incidence-of</guid>
      <pubDate>Wed, 13 Nov 2024 19:58:40 GMT</pubDate>
    </item>
    <item>
      <title>X/Z 和 Y/Z 的相关系数</title>
      <link>https://stats.stackexchange.com/questions/657218/correlation-coefficient-of-x-z-and-y-z</link>
      <description><![CDATA[设 $X$ 和 $Y$ 为随机变量，相关系数为 $r_{x,y} \neq 0$。让 $Z$ 成为另一个随机变量，独立于 $Y$ 和 $X$。
定义 $W \equiv \frac{X}{Z}$ 和 $T \equiv \frac{Y}{Z}$。
就 $r_{x,y}$ 而言，$W$ 和 $T$ 的相关系数是多少？
我的第一个方法是尝试假设 $EX = EY = EZ= 0$。然后：
$$r_{w,t} = \frac{E(\frac{X}{Z} \frac{Y}{Z})}{\sqrt{V(\frac{X}{Z}) V(\frac{Y}{Z})}}$$
对于分母，我们有这个属性
$\mathrm{Var}(XY)=E(X)^2 \mathrm{Var}(Y)+E(Y)^2 \mathrm{Var}(X)+\mathrm{Var}(X)\mathrm{Var}(Y)$
在这种情况下，这等于 $V(X/Z) = V(X)V(1/Z)$
因此：
$$r_{w,t} = \frac{E(\frac{X}{Z} \frac{Y}{Z})}{\sqrt{V(X)V(1/Z)V(Y)V(1/Z)}}$$
由于在此上下文中 $V(\cdot) = E(\cdot^2)$，我们得到：
$$r_{w,t} = \frac{E(\frac{1}{Z^2}) E(XY)}{\sqrt{V(X)V(Y) E(\frac{1}{Z^2})^2}}$$
简单来说：
$$r_{w,t} = \frac{E(XY)}{\sqrt{V(X)V(Y)}} \equiv r_{x,y}$$
如果我尝试删除所有期望等于零的假设，代数运算会相当麻烦。这是否符合 $EX, EY, EZ \neq 0$？]]></description>
      <guid>https://stats.stackexchange.com/questions/657218/correlation-coefficient-of-x-z-and-y-z</guid>
      <pubDate>Wed, 13 Nov 2024 18:44:06 GMT</pubDate>
    </item>
    <item>
      <title>将 Hessian 矩阵居中并进行 QR 变换后恢复为原始参数 X</title>
      <link>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</link>
      <description><![CDATA[在进行最大似然估计 (MLE) 或贝叶斯后验抽样时，我开始更常规地对设计矩阵 $X$ 进行均值中心化和 QR 旋转。这有助于收敛，并在存在共线性时加快后验抽样。在对 $X$ 的列进行均值中心化之后，R qr 函数会转换（正交归一化）$X$，并提供一个矩阵 Rinv（我将其缩写为 $R$），该矩阵可与参数向量相乘以获得原始尺度上的参数。然后，将均值中心化反转以调整截距。我正在使用比例优势半参数模型来计算因变量 $k+1$ 个不同值 $Y$，因此有 $k$ 个截距 $\alpha_{1}, \ldots, \alpha_{k}$。在原始尺度上，当 $p$ 个 $X$ 列时，有 $p$ 个回归系数 $\beta_{1}, \ldots, \beta_{p}$。假设变换后的 $X$ 上的 MLE 为 $\delta$ 和 $\gamma$，分别对应于原始 $X$ 上的 $\alpha, \beta$。
给定矩阵 $R$ 和均值向量，很容易从 $\delta, \gamma$ 计算出 $\alpha, \beta$。令 $M$ 为 $k$ 行行重复矩阵，其中 $p$ 列包含 $X$ 的 $p$ 个原始列均值，即 $M = 1_{k\times 1} \times \bar{X}$，其中 $\bar{X}$ 是 $1\times p$ 均值向量。然后
$\beta = R \gamma$
$\alpha = \delta - M R \gamma$
让 $H$ 表示 $\delta, \gamma$ 的对数似然函数的二阶偏导数的 $(k+p)\times (k+p)$ 矩阵。将 $H$ 划分为
$$
\begin{bmatrix}
A_{k\times k} &amp; B_{k \times p} \newline
B&#39; &amp; D_{p\times p}
\end{bmatrix}
$$
我的理解是，变换参数尺度上的 $H$ 由以下公式计算得出
$J&#39;HJ$
其中雅可比矩阵 $J$ 由以下公式给出
$$
\begin{bmatrix}
\frac{\partial\alpha}{\partial\delta} &amp; \frac{\partial\alpha}{\partial\gamma} \newline
\frac{\partial\beta}{\partial\delta} &amp; \frac{\partial\beta}{\partial\gamma}
\end{bmatrix}
$$
等于
$$
\begin{bmatrix}
I_{k\times k} &amp; -M_{k\times p}R_{p\times p} \newline
0_{p\times k} &amp; R_{p\times p}
\end{bmatrix}
$$
其中 $I$ 是单位矩阵，而 $0$ 是零矩阵。
我用于计算转换后的 $H$ 的 R 代码是
M &lt;- matrix(1, nrow=k, ncol=1) %*% matrix(xbar, nrow=1)
J &lt;- rbind(cbind(diag(k), -M %*% R),
cbind(matrix(0, nrow=p, ncol=k), R ) )
H2 &lt;- t(J) %*% H %*% J

但在我的例子中，我得到的 H2 值，尤其是 $\beta$ 的右下子矩阵，偏差很大。有人能发现我哪里出错了吗？在贝叶斯设置中，一切都很简单，因为您只需为每个后验抽样计算 $\alpha$ 和 $\beta$，即可获得原始参数的正确后验分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</guid>
      <pubDate>Wed, 13 Nov 2024 15:34:57 GMT</pubDate>
    </item>
    <item>
      <title>零点的中位绝对偏差</title>
      <link>https://stats.stackexchange.com/questions/657149/median-absolute-deviation-of-zero</link>
      <description><![CDATA[我使用 MAD 来衡量不同数字数据分布的分布范围，其中一些分布的 MAD 为 0。我很好奇，这怎么可能呢？如果我理解正确的话，MAD 是衡量数据集变异性的指标。我检查了一下，这些数据集的观测值并非全部相同。如果是这样的话，MAD 怎么会是零呢？
对于那些好奇的人，我在 R 中使用 mad() 函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/657149/median-absolute-deviation-of-zero</guid>
      <pubDate>Tue, 12 Nov 2024 16:39:02 GMT</pubDate>
    </item>
    <item>
      <title>如何检验相关观测值的方差是否相等？</title>
      <link>https://stats.stackexchange.com/questions/657075/how-to-test-for-equal-variances-of-correlated-observations</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657075/how-to-test-for-equal-variances-of-correlated-observations</guid>
      <pubDate>Mon, 11 Nov 2024 12:02:09 GMT</pubDate>
    </item>
    </channel>
</rss>