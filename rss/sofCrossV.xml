<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 06 Jul 2024 21:15:13 GMT</lastBuildDate>
    <item>
      <title>随机变量线性系统中的方差</title>
      <link>https://stats.stackexchange.com/questions/650605/variance-in-a-linear-systems-of-random-variables</link>
      <description><![CDATA[设 $Y_1 = \{3, 5, 4, 2, 3, 4, 2, 4\}$，$Y_2 = \{7, 6, 10, 8, 9, 7, 10, 7\}$，且设 $U = Y_2 - Y_1 = \{y_{2,1} - y_{1,1}, y_{2,2} - y_{1,2}, ...\} = \{4, 1, 6, 6, 6, 3, 8, 3\}$。然后 $U$ 的方差等于
$V(U) = \sum{a_i^2V(Y_i)} + 2\sum{\sum{a_ia_jCov(Y_i, Y_j)}}$
方差也可以通过使用标准公式 $V(U) = \frac{\sum{(u_i - \mu_u)^2}}{N}$ 来找到，其中 $\mu_u$ 是 $U$ 的平均值。
问题是在 python 中使用这两种方法会产生不同的结果：
import numpy as np

Y1 = [3, 5, 4, 2, 3, 4, 2, 4]
Y2 = [7, 6, 10, 8, 9, 7, 10, 7]

U = [y2 - y1 for y1, y2 in zip(Y1, Y2)]

print(np.var(u)) # 4.484375

print(np.var(Y1) + np.var(Y2)) # 2.984375


根据第一种方法（作为线性系统）$a_1 = 1$ 和 $a_2 = -1$，因此即使 $Y_1$ 和 $Y_2$ 不是独立的，也就是说，如果 $Cov(Y_1, Y_2) \neq 0$，则第二个值将小于现在的值，因此也小于 $U$。
我哪里做错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/650605/variance-in-a-linear-systems-of-random-variables</guid>
      <pubDate>Sat, 06 Jul 2024 21:09:42 GMT</pubDate>
    </item>
    <item>
      <title>预测不使用示例命令设置的日期范围[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650603/forecast-does-not-use-the-date-range-set-by-sample-command</link>
      <description><![CDATA[我有一个范围为 1999-2024 的工作文件，其中有具有不同开始和结束日期的系列。我正在为较小的样本 smpl &quot;2015 2015+1000&quot; 天运行 ls 回归方程，虽然这会估算该特定样本中的所有内容，但之后我使用 smpl &quot;2015+1000 2015+2000&quot; 对样本外部分运行预测，但我发现预测的 Y 是从观察其中一个 X 开始预测的，即 2008 年，并且它对 1000 天都这样做，所以现在我预测的 Y 日期不匹配。为什么预测不只预测我告诉它的内容？在书中，它甚至在每次预测之前使用 smpl 命令对特定日期范围进行预测。]]></description>
      <guid>https://stats.stackexchange.com/questions/650603/forecast-does-not-use-the-date-range-set-by-sample-command</guid>
      <pubDate>Sat, 06 Jul 2024 18:51:44 GMT</pubDate>
    </item>
    <item>
      <title>测量治疗异质性</title>
      <link>https://stats.stackexchange.com/questions/650602/measuring-treatment-heterogeneity</link>
      <description><![CDATA[这是第一个问题，发布于此处
我正在研究信息对当地价格和搬到某些城市的选择的影响。我认为这些信息会对那些感到惊喜的人（他们认为当地价格比实际价格高）的结果（搬家）产生积极影响，而对那些感到惊喜的人（他们认为当地价格比实际价格便宜）则产生消极影响。我可以测量治疗组的先验和后验信念，但显然不能测量对照组。我是否仍然可以通过观察人们是感到惊喜还是感到惊喜的异质性来探索治疗的效果？
即，它是否估计：
Movei​=β0​+β1​Treatmenti​+β2​PosSurprisei​×Treatmenti​+β3​NegSurprisei​×Treatmenti​+ei​
对我来说，异质性意味着与对照组进行比较，但我无法理解这种情况。
编辑：如果我能够找到关于先前（但不是后验）信念的数据，我可以将其添加为控制，作为一种想法]]></description>
      <guid>https://stats.stackexchange.com/questions/650602/measuring-treatment-heterogeneity</guid>
      <pubDate>Sat, 06 Jul 2024 18:46:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在稀疏数据结构时选择阈值</title>
      <link>https://stats.stackexchange.com/questions/650601/how-to-pick-a-threshold-when-sparsifying-a-data-structure</link>
      <description><![CDATA[我试图找到最基本和普遍接受的策略来解决看似简单的分位数估计问题。假设我有一个长度为 $n$ 的数字列表，这个数字非常大，而我对它们的分布一无所知。我想进行稀疏化，以便只有最大的 p%
的数字得以保留，其余的数字设置为 0。需要注意的是，我实际上并不想评估所有这些数字。

在尽可能少地看到这些数字的情况下，什么是合理的首次通过方法？

什么方法具有某种统计一致性保证？


我查看了一下分位数估计，但似乎它们都有潜在的分布假设？但是，由于我正在对这些数字进行独立同分布抽样，所以这似乎没有必要。您觉得怎样？]]></description>
      <guid>https://stats.stackexchange.com/questions/650601/how-to-pick-a-threshold-when-sparsifying-a-data-structure</guid>
      <pubDate>Sat, 06 Jul 2024 18:04:27 GMT</pubDate>
    </item>
    <item>
      <title>解释交互术语</title>
      <link>https://stats.stackexchange.com/questions/650598/interpreting-interaction-term</link>
      <description><![CDATA[假设我有兴趣估计一种治疗（相对于对照）的效果，完全且有条件地基于基线特征（例如收入水平）的不同水平（例如 3）。我会进行如下回归（T 是治疗，I 是收入水平 1-3）：
$Y = a + b_1T + b_2T(x=1) + b+3T(x=2) + b_4T(x=3) + e$
我不确定我是否理解了三个交互项是与什么进行比较的：是“纯对照”还是 b1？换句话说，我们是否使用来自对照组的收入水平数据来运行此回归？或者我们只是将 b2、b3 和 b4 的结果与 b1 的结果进行比较？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650598/interpreting-interaction-term</guid>
      <pubDate>Sat, 06 Jul 2024 15:42:26 GMT</pubDate>
    </item>
    <item>
      <title>进行线性混合模型和事后比较检验的步骤</title>
      <link>https://stats.stackexchange.com/questions/650597/steps-to-conduct-a-linear-mixed-model-and-post-hoc-comparison-test</link>
      <description><![CDATA[我想请您帮助我以最佳方式在 R 中分析以下实验。
这是我的设计：有 15 种处理方法，分为 4 个区块。对于每个处理方法，每个区块中有 5 株植物，我们评估了其中 6 片叶子的病害严重程度。
最初，我使用线性混合模型，将植物和叶子视为随机效应，以下是函数：
mix &lt;- lmer(sev ~ Treat + Block + (1|Plant/Leaf),
data = sev)

这是正确的吗？我也应该将 Block 视为随机效应吗？为什么？
但是，它不符合方差分析的假设，因此我使用对数、平方根和 box-cox 进行了转换，但尚未成功。
然后，我的第二个想法是通过每株植物的平均严重程度汇总数据，并将植物用作随机效应。这是模型（可以吗？）：
mix2 &lt;- lmer(sev_mean ~ Treat + Block + (1|Plant),
data = sev_m)

但是，使用 log+0.5 变换后，我发现方差具有正态性和齐次性：
mix3 &lt;- lmer(log+0.5(sev_mean) ~ Treat + Block + (1|Plant),
data = sev_m)

按顺序，我进行了事后比较。我尝试使用 Scott-Knott 检验*，所以我查看了 Chat GPT，它建议获得具有固定效应（在本例中是治疗，对吗？）的线性模型，然后运行分析。这是正确的吗？还有其他方法可以进行这些比较吗？您是否建议使用软件包来运行此步骤？
*我也尝试了 Tukey 测试，但我有组叠加，无法轻松确定最佳治疗方法。 
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/650597/steps-to-conduct-a-linear-mixed-model-and-post-hoc-comparison-test</guid>
      <pubDate>Sat, 06 Jul 2024 14:18:19 GMT</pubDate>
    </item>
    <item>
      <title>Emmeans 中的自由度</title>
      <link>https://stats.stackexchange.com/questions/650596/degrees-of-freedom-in-emmeans</link>
      <description><![CDATA[我正在使用 R 中的“emmeans”包来计算我的（线性混合效应）模型的估计边际均值。但是，我遇到了与观测值数量超过 3000 相关的警告消息。以下是我收到的具体代码和警告消息：
emmeans_results &lt;- emmeans(lmer_model, ~ assistance + group)
警告消息是：
注意：由于观测值数量超过 3000，因此已禁用 D.f. 计算。要启用调整，请添加参数“pbkrtest.limit = 161345”（或更大）[或全局“set emm_options(pbkrtest.limit = 161345)”或更大]；但请注意，这可能会导致大量的计算时间和内存使用。注意：D.f.由于观测次数超过 3000，计算已被禁用。要启用调整，请添加参数“lmerTest.limit = 161345”（或更大）[或全局“set emm_options(lmerTest.limit = 161345)”或更大]；但请注意，这可能会导致大量的计算时间和内存使用。
如何在不花费大量计算时间和内存使用的情况下处理此问题（设置 lmerTest.limit = 161345 会导致我的计算机上的 R 崩溃）。在“emmeans”中是否有推荐的方法来处理此问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/650596/degrees-of-freedom-in-emmeans</guid>
      <pubDate>Sat, 06 Jul 2024 13:43:38 GMT</pubDate>
    </item>
    <item>
      <title>Stata 或 R 中的循环回归和推理</title>
      <link>https://stats.stackexchange.com/questions/650594/looped-regression-and-inference-in-stata-or-r</link>
      <description><![CDATA[我有一个面板数据样本，正在循环运行特定分类变量值的回归分析。举例来说：
$$ y_{it} = \alpha_i + \eta_t + \beta^C D_{it} + \epsilon_{it} $$
其中 $y_{it}$ 是感兴趣的结果，$\alpha_i, \eta_t$ 是单位和时间固定效应，$D_{it}$ 是治疗虚拟变量，$\epsilon_{it}$ 是误差项。假设还有一个分类 $C$ 变量，其支持集为 $\{1,2...,10\}$，并且根据此变量的值对不同的子样本运行此回归（即运行 10 个不同的回归）。
每次迭代后，我都会保存每个回归的系数、标准误差和样本大小。然后，我会找到这些系数的平均值，从而得到一个估计值（我确实有这样做的理由）。结果，我有变量：
$$ \tau = \frac{1}{10} \sum_{C=1}^{10}\beta^C $$
我的问题是，我希望为这个回归系数平均值得出标准误差/t 统计量。但是，我不确定是否很容易得出此估计的解析表达式，还是最好使用引导程序？如果是后者，有人可以指出一些 R 或 Stata 中的资源来执行此操作吗？我在这方面没有太多经验，而且这种情况似乎有些不标准。]]></description>
      <guid>https://stats.stackexchange.com/questions/650594/looped-regression-and-inference-in-stata-or-r</guid>
      <pubDate>Sat, 06 Jul 2024 13:13:24 GMT</pubDate>
    </item>
    <item>
      <title>在高方差对数正态分布的总和中，哪个分数来自第一项？</title>
      <link>https://stats.stackexchange.com/questions/650589/in-a-sum-of-high-variance-lognormals-what-fraction-comes-from-the-first-term</link>
      <description><![CDATA[如果 $X_i \overset{\textrm{iid}}{\sim} \text{Lognormal}(0, \sigma^2)$ 其中 $i=1,\ldots,n$ 且 $Y_1 = X_1 / \sum_{j=1}^n X_j$，那么我预期 $Y_1$ 的一个特定*极限分布，即 $ \lim_{\sigma \to \infty} Y_1$，将会非常简单：$1$ 的概率为 $1/n$ 且 $1/n$ 且 $0$ 的概率为 $1-1/n$。有没有（简单的）方法可以证明这一点？
*NB：我感兴趣的是 $\sigma$ 的极限，而不是 $n$。$n$ 不一定很大。]]></description>
      <guid>https://stats.stackexchange.com/questions/650589/in-a-sum-of-high-variance-lognormals-what-fraction-comes-from-the-first-term</guid>
      <pubDate>Sat, 06 Jul 2024 12:05:40 GMT</pubDate>
    </item>
    <item>
      <title>局部线性核回归</title>
      <link>https://stats.stackexchange.com/questions/650588/local-linear-kernel-regression</link>
      <description><![CDATA[已知给定点 $x$ 的预测由以下公式给出：
$$\hat{f}_h(x) = \hat{\beta}_0(x)$$
其中
$$\hat{\beta}(x) = argmin_{\beta_0, \beta_1}\sum_{i=1}^nK\left(\frac{x - x_i}{h}\right)(Y_i - \beta_0 - \beta_1(x_i - x))^2.$$
我直观地理解了为什么对于预测我们只考虑截距：局部线性模型正在回归 $x_i$ 和 $x$，因此对于预测，我们认为距离回归线的值等于 0 是有道理的。
我不明白的是，为什么我们不直接解决这个问题呢（这是我接触这个主题时首先想到的）？
$$\hat{f}_h(x) = \hat{\beta}_0(x) + \hat{\beta_1}(x)x$$
其中
$$\hat{\beta}(x) = argmin_{\beta_0, \beta_1}\sum_{i=1}^nK\left(\frac{x - x_i}{h}\right)(Y_i - \beta_0 - \beta_1x_i)^2.$$
因此，我们不会对距离进行回归，而是对单个点进行局部回归，然后使用所有回归线进行预测。
这种方法错误吗？有人能帮我吗？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/650588/local-linear-kernel-regression</guid>
      <pubDate>Sat, 06 Jul 2024 12:01:14 GMT</pubDate>
    </item>
    <item>
      <title>如何测量双对数拟合外推的误差？[重复]</title>
      <link>https://stats.stackexchange.com/questions/650537/how-to-measure-the-error-on-extrapolation-from-a-double-log-fit</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650537/how-to-measure-the-error-on-extrapolation-from-a-double-log-fit</guid>
      <pubDate>Fri, 05 Jul 2024 16:35:01 GMT</pubDate>
    </item>
    <item>
      <title>如何将贝叶斯模型拟合到 Beta、指数和一零膨胀数据的混合中？</title>
      <link>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-exponential-and-one-zero-infl</link>
      <description><![CDATA[我的数据非常嘈杂，我相信这是通过多个物理过程的相互作用而产生的。在映射 $Y = f(X),$ 中，$Y$ 是一个比率 $[0, 1]$ 和 $X \ge 0.$，而 $Y$ 是 $X,$ 的函数，它也可以取 $0$（更可能在较低的 $X$ 值时）或 $1$（更可能在较高的 $X$ 值时）。 $Y$ 是每个 $X$ 间隔的指数、Beta 和零一膨胀过程的混合。指数部分在 $X$ 值较低时更明显，并随着 $X$ 的增加而缓慢消失。
如何使用贝叶斯方法对此类过程进行建模？我是贝叶斯统计的新手，希望得到任何帮助。我可以拟合零一膨胀的 Beta 模型，但它无法捕捉指数类分量。
模拟真实数据的虚拟数据：
# 设置种子以实现可重复性
set.seed(123)

# 生成 x 值
x &lt;- seq(0, 20, length.out = 1000)

# 为 y 创建非线性函数
y &lt;- 0.15 + 0.005 * x^1.05 + 1 / (2.5 + 2532 * exp(-1.611 * x))

# 添加一些随机噪声
noise_factor &lt;- 0.03
# 使用 beta 噪声创建模型（此处使用正态分布创建）
noisy_y &lt;- rnorm(length(x), mean = 0, sd = noise_factor * sqrt(x))

y &lt;- y + noisy_y

# 向数据添加零个和一个噪声
noisy_indices &lt;- sample(1:length(x), round(0.2 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 1 / (1 + exp(x[i]))) {
y[i] &lt;- 1
} else {
y[i] &lt;- 0
}
}

# 添加指数分布
noisy_indices &lt;- sample(1:length(x), round(0.5 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 100 / (1 + exp(x[i]))) {
y[i] &lt;- rexp(1, rate =4)
} else {
y[i] &lt;- y[i]
}
}

# 创建数据框
data &lt;- data.frame(x = x, y = y) |&gt;
filter(y&lt;=1 &amp; y&gt;=0)

ggplot(data, 
aes(x, y)) +
geom_point() +
xlim(0, 20) + 
ylim(0, 1)

ggplot(data = data, 
aes(x=y))+
geom_histogram()

我正在尝试制定一个将 X 映射到 Y 的函数

整个数据集中 Y 的分布。在原始数据集中，从零（@Y=0）到指数部分（Y ~ 0-0.25）的过渡非常平滑。

我尝试（在原始数据上）在 brms 中使用零一膨胀 Beta 得出此后验预测：
]]></description>
      <guid>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-exponential-and-one-zero-infl</guid>
      <pubDate>Fri, 05 Jul 2024 14:49:43 GMT</pubDate>
    </item>
    <item>
      <title>当我的因变量在 R 中被分数幂运算时，我应该如何反向变换 beta 系数</title>
      <link>https://stats.stackexchange.com/questions/650513/what-should-i-back-transform-beta-coefficients-when-my-dependent-variable-is-fra</link>
      <description><![CDATA[我有这个混合效应回归模型。为了在连续尺度因变量中创建正态分布，我对其进行了分数指数化：
TB_fract &lt;- TB ^ (1/1.4)

我的以下模型是这样的，其中 period 表示时间的整数值，MRN 表示单个受试者：
lme4::lmer(TB_fract ~ Surg_group_fact + (1 + period|MRN), data = full_patient_data_2, na.action = na.omit)

我的输出是这样的。 time_below_sqrt 是 TB_fract 的 DV 表示：


我显然有负 beta 估计值，这不允许转换为 1.4 次方。如果我的 DV 是具有负 beta 系数的原始值的分数值，那么我该如何解释这些结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/650513/what-should-i-back-transform-beta-coefficients-when-my-dependent-variable-is-fra</guid>
      <pubDate>Fri, 05 Jul 2024 09:14:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么偏斜正态分布中的一个小形状参数会反转偏斜度？</title>
      <link>https://stats.stackexchange.com/questions/650512/why-does-a-small-shape-parameter-in-the-skew-normal-distribution-invert-the-skew</link>
      <description><![CDATA[我正在使用 fGarch R 库中的 rsnorm 函数。正如人们所预料的那样，对于足够大（abs(xi) &gt; 1）的形状参数（此实现中的 xi），直方图具有明显可见的偏斜度。但是，对于 -1 &lt; xi &lt; 1，偏斜度似乎在错误的方向。例如，考虑以下内容：
library(&#39;fGarch&#39;)
n &lt;- 10000
xis &lt;- c( -5, -2, -1, -0.1, 0.1, 1, 2, 5 )
for (xi in xis) {
r &lt;- rsnorm(n,xi=xi)
title &lt;- as.character(xi)
hist(r, main=title)
}

我误解了 xi 吗？似乎对于 abs(xi) == 1 存在对称性。如果是这样，那么对于小偏度参数，xi 的矩估计方法如何工作（请参阅维基百科文章 https://en.wikipedia.org/wiki/Skew_normal_distribution，其中形状参数是 alpha 而不是 xi（维基百科将 xi 作为位置参数）？
非常感谢您的见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/650512/why-does-a-small-shape-parameter-in-the-skew-normal-distribution-invert-the-skew</guid>
      <pubDate>Fri, 05 Jul 2024 09:00:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么`pROC::roc`默认计算$\max\{AUC, 1 - AUC\}$？</title>
      <link>https://stats.stackexchange.com/questions/650273/why-would-procroc-calculate-max-auc-1-auc-by-default</link>
      <description><![CDATA[R 中的 pROC::roc 函数有一些有趣的行为。
library(pROC)
set.seed(2024)
N &lt;- 100
p &lt;- rbeta(N, 1/2, 1/2)
y &lt;- rbinom(N, 1, p)
r1 &lt;- pROC::roc(y, p)
r2 &lt;- pROC::roc(y, 1 - p)
r1$auc # 我得到 0.8894
r2$auc # 我得到 0.8894

无论我们使用概率（p）还是翻转所有概率（1-p），该函数都会计算相同的面积ROC 曲线。
但这与通常的计算 ROC 曲线的思路不一致，即通过改变截止阈值并计算每个阈值处的敏感度-特异性对。其中一个应该在接近 1 时显示相当高的 AUC，而另一个应该在接近 0 时显示相当低的 AUC。毕竟，当我们将 p 翻转为 1-p 时，高概率值通常对应于 1 的值，低概率值通常对应于 0 的值，相反，情况正好相反，这会导致可怕的敏感度和特异性值。
library(ModelMetrics)
thresholds &lt;- r1$thresholds
sens1 &lt;- spec1 &lt;- sens2 &lt;- spec2 &lt;- rep(NA, length(thresholds))
yhat1 &lt;- yhat2 &lt;- rep(0, length(thresholds))
for (i in 1:length(thresholds)){

# 我忘了如何以更清晰的方式与阈值进行比较
#
idx1 &lt;- which(p &gt; Thresholds[i])
idx2 &lt;- which(1 - p &gt; 阈值[i])
#
yhat1[idx1] &lt;- 1 
yhat1[-idx1] &lt;- 0 
yhat2[idx2] &lt;- 1 
yhat2[-idx2] &lt;- 0

sens1[i] &lt;- ModelMetrics::sensitivity(y, yhat1)
sens2[i] &lt;- ModelMetrics::sensitivity(y, yhat2)
#
spec1[i] &lt;- ModelMetrics::specificity(y, yhat1)
spec2[i] &lt;- ModelMetrics::specificity(y, yhat2)

}
plot(r1)
points(spec1, sens1, col = &#39;blue&#39;)
points(spec2, sens2, col = &#39;red&#39;)

绘图这样，与 1-p 预测相对应的红色曲线的曲线下面积非常糟糕，正如预期的那样。
因此，我很好奇为什么 pROC::roc 会计算出 AUC 对于如此不同的输入是相同的，一个具有良好的概率值，另一个具有糟糕的概率值。幸运的是，pROC::roc 可以与 direction = &quot;&lt;&quot; 一起运行，以防止函数输出 $\max\{AUC, 1 - AUC\}$，而是返回真实的 AUC 值。但是，这不是默认行为？函数返回 $\max\{AUC, 1 - AUC\}$ 而不是仅仅返回 AUC，这是否有一些统计原因？我想我可以看到一个论点，即$AUC&lt;0.5$意味着对预测值进行简单的转换会给出$AUC&gt;0.5$，但你必须知道要执行这样的校准步骤，否则你会使用可怕的预测值。
由于软件包开发人员是 Cross Validated 的成员，因此我对来自此类来源的答案特别感兴趣。]]></description>
      <guid>https://stats.stackexchange.com/questions/650273/why-would-procroc-calculate-max-auc-1-auc-by-default</guid>
      <pubDate>Mon, 01 Jul 2024 17:47:29 GMT</pubDate>
    </item>
    </channel>
</rss>