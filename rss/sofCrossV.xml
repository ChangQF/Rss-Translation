<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 09 Sep 2024 01:13:40 GMT</lastBuildDate>
    <item>
      <title>Sklearn PLS 属性 X_scores、X_weights、X_Loadings 含义</title>
      <link>https://stats.stackexchange.com/questions/654062/sklearn-pls-attributes-x-scores-x-weights-x-loadings-meaning</link>
      <description><![CDATA[尝试阅读 sci-kit 文档，但文档很短，帮助不大。有人能用通俗易懂的术语来描述通过 sklearn 进行偏最小二乘回归 PLS 的 X 和 Y 分数、权重和载荷吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654062/sklearn-pls-attributes-x-scores-x-weights-x-loadings-meaning</guid>
      <pubDate>Sun, 08 Sep 2024 22:19:14 GMT</pubDate>
    </item>
    <item>
      <title>主教高斯基</title>
      <link>https://stats.stackexchange.com/questions/654060/bishop-gaussian-basis</link>
      <description><![CDATA[在 Christopher Bishop 所著的模式识别与机器学习一书中，他在第 3.3.2 节“预测分布”中说道

如果我们使用局部基函数（如高斯函数），那么在远离基函数中心的区域中，预测方差（3.59）中第二项的贡献将变为零，只留下噪声贡献$\beta^{−1}$。因此，
当在基函数所占区域外进行外推时，模型对其预测非常有信心，这通常是不受欢迎的行为。

但就在本段之前，它说

请注意，预测不确定性取决于$x$，并且在数据点的邻域中最小。还要注意，随着观察到更多的数据点，不确定性水平会降低。

在图中，当远离数据点时，方差似乎很高。]]></description>
      <guid>https://stats.stackexchange.com/questions/654060/bishop-gaussian-basis</guid>
      <pubDate>Sun, 08 Sep 2024 21:42:32 GMT</pubDate>
    </item>
    <item>
      <title>使用分类数据和现有标签对数据点进行聚类的算法</title>
      <link>https://stats.stackexchange.com/questions/654059/algorithm-to-cluster-data-points-with-categorical-data-and-existing-labels</link>
      <description><![CDATA[假设我有一个电子商务产品浏览数据的数据框，其中每一行代表一个产品浏览量以及它是否导致转化（购买/未购买）
数据的示例列：currencyCode、country、pageType、isMobile、browser、hourOfDay、productPrice、converted。
我的目标是使用除价格之外的所有特征（所有/大多数都是分类的）合理地将“群组”分配给用户浏览量。同时考虑数据中的价格和标签（几乎像半监督）。这样，当出现新视图（没有价格和转化数据）时，我知道该视图属于哪个群集。
这些视图的聚类应该以某种方式考虑productPrice和converted的影响。想知道对这些数据点进行聚类的最佳方法是什么？
我知道存在处理分类数据的 kprototypes / kmodes，但还没有找到一种方法来考虑价格和转换的影响，而且它也没有考虑数据的标签。]]></description>
      <guid>https://stats.stackexchange.com/questions/654059/algorithm-to-cluster-data-points-with-categorical-data-and-existing-labels</guid>
      <pubDate>Sun, 08 Sep 2024 21:25:11 GMT</pubDate>
    </item>
    <item>
      <title>如何获得高斯和的 LRT 和 ROC（高斯项的数量具有泊松分布）？</title>
      <link>https://stats.stackexchange.com/questions/654057/how-to-obtain-lrt-and-roc-of-sum-of-gaussians-with-number-of-gaussian-terms-has</link>
      <description><![CDATA[若
$$
y = \sum_{i=0}^n x_i
$$
其中$x_i$为独立同分布随机变量，其密度为高斯分布$N(0, \sigma^2)$。总和中的变量数是具有泊松分布的随机变量：
$$
\Pr(n = k) = \frac{\lambda^k e^{-\lambda}}{k!}, \quad k = 0, 1, \ldots
$$
我们想在两个假设之间做出决定：
$$
H_1 : n \leq 1 \quad \text{and} \quad H_0 : n &gt; 1
$$.
如何得出 ROC 曲线（检测概率与误报概率）？]]></description>
      <guid>https://stats.stackexchange.com/questions/654057/how-to-obtain-lrt-and-roc-of-sum-of-gaussians-with-number-of-gaussian-terms-has</guid>
      <pubDate>Sun, 08 Sep 2024 21:09:27 GMT</pubDate>
    </item>
    <item>
      <title>样本量计算的假设检验与置信区间</title>
      <link>https://stats.stackexchange.com/questions/654055/hypothesis-testing-vs-confidence-intervals-for-sample-size-calculation</link>
      <description><![CDATA[假设我们正在审计一个低风险集团，该集团的历史平均逃税额为 \$7,883，审计时的标准差为 \$27,274。我的目标是确定平均逃税额是否接近于零。使用 t 检验，假设平均逃税额为零（双侧，$\alpha = 0.05$，功效 = 0.8），双侧检验所需的样本量为 96，单侧检验所需的样本量为 76。我假设备择假设下的平均值和标准差就是历史数据所显示的。
但是，如果我使用置信区间 $\bar{x} \pm 1.96 * \frac{\sigma}{\sqrt{n}}$ 进行计算并将下限设置为接近零，则求解 $n$ 得到的样本量为 46。
使用样本量 46 来确定零是否在置信区间内有效，从而否定了假设检验所建议的更大样本量的需要吗？如果不是，为什么这种方法是错误的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654055/hypothesis-testing-vs-confidence-intervals-for-sample-size-calculation</guid>
      <pubDate>Sun, 08 Sep 2024 20:43:37 GMT</pubDate>
    </item>
    <item>
      <title>使用诱导点进行精确的高斯过程推断</title>
      <link>https://stats.stackexchange.com/questions/654054/using-inducing-points-for-exact-gaussian-process-inference</link>
      <description><![CDATA[我对使用诱导点进行高斯过程推断有点困惑，特别是在应该是精确推断而不是近似的情况下。
对于高斯过程$f\sim GP(\textbf{0}, \kappa)$，其中
$ \kappa :X\times X \rightarrow \mathbb{R}$为正定核，训练数据为$f(x_1), \dots, f(x_n)$，如果想推断新点$x_*$的值，我们通常以$\mathcal{O}(n^3)$ 来反转矩阵 $\kappa(f(x_i), f(x_j))$，其中 $i,j=1,\dots n$，其中 $n$ 是提供正态分布 $p(f(x_*)|f(x_1), \dots, f(x_n))$ 的训练点数。
我的问题是关于使用诱导点来加速这种推理。具体来说，如果我们让
$y= f(x_*) + z$其中$z \sim N(0, \varepsilon)$，
则$p(y | f(x_*),f(x_1), \dots, f(x_n)) = p(y | f(x_*))$，
但同时$\{ f(x) | x \in X\} \cup \{y\}$ 是一个高斯过程，如果我们将 $\kappa$ 扩展到 $X \cup \{x_{**}\}$ 域并添加一个点，其中 $f(x_{**}) :=y$，以自然的方式（考虑到它提供了 GP 的协方差）：$\kappa&#39;(x_{**},x) := \kappa(x_*,x) \text{ for } x\neq x_{**} \text{ and } \kappa&#39;(x_{**},x_{**}) := \kappa(x_{*},x_{*}) + \varepsilon$
那么为什么我们不能使用诱导点方法，以诱导点为 $x_*$，推断 $\mathcal{O}(m^2n) = \mathcal{O}(n)$ 时间中 $f(x_{**})$ 的值，其中诱导点的数量为 $m=1$，如此处所用：https://andrewcharlesjones.github.io/journal/inducing-points.html，或在本文中：https://mlg.eng.cam.ac.uk/zoubin/papers/nips05spgp.pdf。
更详细地说，由于我们有 $p(y | f(x_*),f(x_1), \dots, f(x_n)) = p(y | f(x_*))$，我们知道 $p(y|f(x_1), \dots, f(x_n)) = \int p(y| f(x_*))\ p(f(x_*)|f(x_1), \dots, f(x_n))\ df(x_*)$，并且从右侧表达式中我们得到高斯形式，其参数我们可以在亚立方时间内推断出来，如上链接所示。
然后在这种情况下，如果 $\varepsilon$ 很小，我们可以计算后验的近似值 $p(y|f(x_1), \dots, f(x_n))$ 在线性时间内完成，这似乎是不可能的，因为这应该是 $\mathcal{O}(n^3)$。]]></description>
      <guid>https://stats.stackexchange.com/questions/654054/using-inducing-points-for-exact-gaussian-process-inference</guid>
      <pubDate>Sun, 08 Sep 2024 20:36:59 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在循环图中定义有限路径？</title>
      <link>https://stats.stackexchange.com/questions/654051/it-is-possible-to-define-finite-path-in-looped-graphs</link>
      <description><![CDATA[我对图论不太感兴趣，所以这个问题可能毫无意义。从非指导的角度来看，有向图或无向图中的路径和循环概念是清晰的。但如果我们转向循环图（即节点可以有循环），仍然可以在节点之间定义一条有限路径，其中中间的某些顶点是循环的？有人能给我指出一些文献参考吗？
提前谢谢
Paolo]]></description>
      <guid>https://stats.stackexchange.com/questions/654051/it-is-possible-to-define-finite-path-in-looped-graphs</guid>
      <pubDate>Sun, 08 Sep 2024 19:28:11 GMT</pubDate>
    </item>
    <item>
      <title>注意力是一种 K 近邻回归器吗？</title>
      <link>https://stats.stackexchange.com/questions/654050/is-attention-a-kind-of-k-nearest-neighbors-regressor</link>
      <description><![CDATA[我想出了一个奇怪的 KNN 算法，我认为它相当于自注意力：

假设我们有一个典型的 (特征、标签) 样式数据集 $\mathscr D = \{(x_1, Vx_1), (x_2, Vx_2),\dots, (x_N, Vx_N)\}$，其中 $x_n$ 是向量，V 是某个矩阵。
原则上，我们可以将常规 KNN 应用于此集合，将每个向量 $x_n$ 视为查询向量，并让 $K=|\mathscr D \setminus (x_n, Vx_n)|=N-1$，因此所有都是邻居，没有前 K 个最近向量：

给定某个特征向量 $x_n$，计算其与所有其他向量的相似度：$S(x_n)=\left\{\frac{1}{\lVert x_n - x \rVert} : x \in \mathscr D \setminus x_n\right\}$。我猜这也需要规范化，这样 $\sum_i S_i(x_n)=1$。
输出是标签的加权和：$y_n^* = \sum_{i} S_i(x_n) Vx_i$。
对所有其他向量重复此操作，并获得一组对应于每个特征向量的预测标签：$\mathscr Y = \{y_1^*, y_2^*, \dots, y_N^*\}$。


现在像这样修改上面的 KNN：

使用点积作为相似度度量：$s_{Q,K}(x_n, x_m) = x_n&#39; Q&#39;K x_m$.
现在 $x_n$ 的权重为：$S(x_n)=\mathrm{softmax}\left(\left\{s_{Q,K}(x_n, x) : x \in \mathscr D\right\}\right)$.

我们迭代整个数据集，包括 $x_n$ 本身，因为这里不可能除以零。在我看来，我们也可以像上面一样使用 $\mathscr D \setminus x_n$。
我们使用 softmax，而不是通过 $\sum_{x \in \mathscr D \setminus x_n} \frac{1}{\lVert x_n - x \rVert}$ 进行归一化。


预测标签再次为 $y_n^* = \sum_{i=1}^N S_i(x_n) Vx_i$。


如果 $Vx_n$（因此 $y_n^*$) 具有相同的维度，我们可以堆叠这些算法，使用 $\{y_n^*\}$ 作为下一层的 $\{x_n\}$。

我认为我的算法 (2) 1) 与自注意力相同，2) 是一种 KNN，或“全最近邻”。因此，似乎可以将自注意力理解为一种 KNN。
这有意义吗？我可以这样思考注意力吗？

编辑：我发现了一些介绍某种“连续最近邻居”的论文：

“神经最近邻居网络”，2018 年（方程 10-11）：https://proceedings.neurips.cc/paper_files/paper/2018/file/f0e52b27a7a5d6a1a87373dffa53dbe5-Paper.pdf
“KVT： k-NN Attention for Boosting Vision Transformers”，2022 年（第 3.2 节似乎讨论了与上述算法 (2) 类似的内容）：https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136840281.pdf
]]></description>
      <guid>https://stats.stackexchange.com/questions/654050/is-attention-a-kind-of-k-nearest-neighbors-regressor</guid>
      <pubDate>Sun, 08 Sep 2024 19:26:57 GMT</pubDate>
    </item>
    <item>
      <title>是否可以对多项研究的总体方差取平均值以用于样本量计算？</title>
      <link>https://stats.stackexchange.com/questions/654048/can-population-variance-from-multiple-studies-be-averaged-to-use-for-a-sample-si</link>
      <description><![CDATA[想象一下，您正在计划一项临床试验，以评估一种新疗法对改善慢性中风患者 VO2peak 的有效性。根据 Jin 等人的初步研究，您使用 Jin 等人报告的 VO2peak 方差估计试验所需的样本量。
来自 Jin 等人的数据：

VO2peak 方差：2.5 ml/kg/min
估计样本量：每组 40 名参与者

但是，您后来发现，您的试点研究中的方差比 Jin 等人的估计值高得多。
来自其他研究的数据：

DaCun：方差 = 10 ml/kg/min
Mac：方差 = 15 ml/kg/min
Len：方差 = 20 ml/kg/min
Ive：方差 = 18 ml/kg/min
Glob：方差 = 25 ml/kg/min

修订方法：
现在，您不再仅仅依赖 Jin 等人的方差估计，而是包括来自这些其他研究的数据：

来自其他研究的平均方差：(10 + 15 + 20 + 18 + 25) / 5 = 17.6 ml/kg/min

修订样本量计算：使用这个更高的平均方差，您可以计算出一个新的样本量估计值。


结果：

新的样本量估计：每组 80 名参与者（基于更高的平均方差）

这是一种可接受的方法吗？计算样本量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654048/can-population-variance-from-multiple-studies-be-averaged-to-use-for-a-sample-si</guid>
      <pubDate>Sun, 08 Sep 2024 17:52:41 GMT</pubDate>
    </item>
    <item>
      <title>有序回归/2 步模型</title>
      <link>https://stats.stackexchange.com/questions/654047/ordinal-regression-2-step-model</link>
      <description><![CDATA[遗憾的是，我在细节方面有些含糊，但我希望可以提供足够的一般信息来提出相关问题，并有足够的内容，以便读者能够引导我找到一些有用的材料。我没有接受过正规的统计学培训，但我会尽力做合理的事情，并在可能/负担得起的情况下寻求统计学家的帮助。无论如何......我有横断面调查数据（通过社交媒体宣传），收集了有关人口统计变量、其他解释性变量（一些连续的，一些分类的）的信息，还提出了一组问题是主要感兴趣的响应变量。这些响应变量问题的量表如下（每个问题都是一个单独的构造 - 它们不会被加在一起或平均成任何总分或正式的测量模型）：
1 = 完全没有问题
2 = 轻微
3 = 中等
4 = 严重
假设我有兴趣评估两个解释变量（一个连续变量，一个具有 3 个级别的分类变量）与序数响应之间的关系，那么据我所知，我可以拟合比例优势序数逻辑回归来模拟预测因子与响应之间的关系，但是，响应量表对我来说更像是一个两步过程。即：
步骤/模型 1 = 问题存在/不存在？
步骤/模型 2 = 如果问题存在，那么它有多严重？
因此，在我看来，我有几个选择：

只需使用 PO 序数回归对所有序数响应类别进行建模（或者在需要/必要时放宽 PO 假设的某些替代方案）
首先使用二元逻辑回归对存在/不存在进行建模，然后使用 PO 序数回归对轻度/中度/重度响应结果进行建模（这是否合理，或者“使用数据两次”等是否存在问题？
或者，是否有任何 2 步模型，我可以在其中联合估计存在/不存在，然后在问题存在的条件下估计严重程度，但实际上对序数响应进行建模？

如果有人可以向我指出他们认为可能有用的任何可访问的材料/阅读/博客或模型，那就太好了。
提前谢谢大家]]></description>
      <guid>https://stats.stackexchange.com/questions/654047/ordinal-regression-2-step-model</guid>
      <pubDate>Sun, 08 Sep 2024 17:46:57 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何计算拟二项分布模型的伪 R 平方？</title>
      <link>https://stats.stackexchange.com/questions/654046/how-should-i-calculate-a-pseudo-r-squared-for-models-with-a-quasi-binomial-distr</link>
      <description><![CDATA[我已经使用 glm 函数在 R 中创建了一个模型，其中 family = quasibinomial。我正在尝试计算 psquedo R 平方，即 cox-snell 变量，以便与现有研究进行比较。
但是，由于 cox-snell R 平方使用对数似然，我该如何调整它以适应具有准分布的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/654046/how-should-i-calculate-a-pseudo-r-squared-for-models-with-a-quasi-binomial-distr</guid>
      <pubDate>Sun, 08 Sep 2024 17:15:28 GMT</pubDate>
    </item>
    <item>
      <title>协方差矩阵的浓度不等式</title>
      <link>https://stats.stackexchange.com/questions/654041/concentration-inequality-of-the-covariance-matrix</link>
      <description><![CDATA[在高维统计领域，我们经常利用集中不等式来获得高概率的收敛速度。当我阅读有关图形模型的讲义时，我发现$\|\Sigma-\hat{\Sigma}\|_{max}$的集中不等式经常出现在$\|A\|_{max}=\underset{i,j}{\max}|X_{ij}|$。
我的问题：

范数$\|\cdot\|_{\max}$的频繁出现意味着什么，背后隐藏着什么直觉？

我想知道协方差矩阵与其他范数的集中不等式，例如谱范数$\|\Sigma-\hat{\Sigma}\|_2$。据您所知，此浓度不等式的最佳结果是什么？

]]></description>
      <guid>https://stats.stackexchange.com/questions/654041/concentration-inequality-of-the-covariance-matrix</guid>
      <pubDate>Sun, 08 Sep 2024 15:37:24 GMT</pubDate>
    </item>
    <item>
      <title>传递核的分解是否定义明确？</title>
      <link>https://stats.stackexchange.com/questions/654039/is-the-decomposition-of-a-transitive-kernel-well-defined</link>
      <description><![CDATA[在下面的论文中，作者写道：
假设某个函数 (p(x, y)) 的转换核表示为
$$
P(x, d y)=p(x, y) d y+r(x) \delta_x(d y),
$$
其中 $p(x, x)=0, \delta_x(d y)=1$ 如果 $x \in d y$ 否则为 0，并且 $r(x)=1-\int_{\mathbb{R}^d} p(x, y) d y$ 是链保持在 $x$。从 $r(x) \neq 0$ 的可能性来看，应该清楚的是 $p(x, y)$ 对 $y$ 的积分不一定是 1。
我的问题：您如何验证此分解实际上等于过渡核？换句话说：我如何知道满足此等式的函数 $p(x,y)$ 和 $r(x)$ 确实存在？]]></description>
      <guid>https://stats.stackexchange.com/questions/654039/is-the-decomposition-of-a-transitive-kernel-well-defined</guid>
      <pubDate>Sun, 08 Sep 2024 13:30:32 GMT</pubDate>
    </item>
    <item>
      <title>通过两个传感器进行估算</title>
      <link>https://stats.stackexchange.com/questions/654037/estimating-from-two-sensors</link>
      <description><![CDATA[我们想测量两个物体之间的距离。一个传感器的读数为 120。另一个传感器的读数为 200。我们知道第一个传感器的读数的标准偏差为 20，第二个传感器的读数的标准偏差为 30。
最佳估计是什么？
问题的第二部分
传感器位于飞机上，测量到码头的距离。如果我们高估了，飞机就会坠毁。我想要几乎 95% 的信心保证它不会坠毁的距离。我现在对距离的最佳估计是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654037/estimating-from-two-sensors</guid>
      <pubDate>Sun, 08 Sep 2024 13:07:15 GMT</pubDate>
    </item>
    <item>
      <title>矩阵范数的次梯度</title>
      <link>https://stats.stackexchange.com/questions/654025/subgradient-of-the-matrix-norm</link>
      <description><![CDATA[当我想要获得矩阵变量套索方法的统计特性时，例如，
$$
\hat{X}=\underset{X\in \mathbb{R}^{n\times n}}{\arg \min}\mathcal{L}\left(X\right)+\lambda_n \|X\|_1,
$$
其中 $\mathcal{L}$ 是损失函数，$\|X\|_1=\sum_{i,j}|X_{ij}|$，我总是关注其方向导数的 KKT 条件。因此，我有
$$
\mathcal{L}^{\prime}\left(\hat{X}\right)+\lambda_n Z,
$$
其中$Z\in \partial\|\hat{X}\|_1$且$\|Z\|_{\max}=\underset{i,j}{\max}|Z_{ij}|\le 1$。
我们能否限制$Z$的谱范数？我了解到，如果 $Z$ 是核范数的次梯度，则 $Z$ 的谱范数小于 1。逐元素 1 范数是否具有类似的性质？]]></description>
      <guid>https://stats.stackexchange.com/questions/654025/subgradient-of-the-matrix-norm</guid>
      <pubDate>Sun, 08 Sep 2024 04:56:35 GMT</pubDate>
    </item>
    </channel>
</rss>