<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 27 May 2024 18:18:45 GMT</lastBuildDate>
    <item>
      <title>根据 GLICKO1 和 GLICKO2 评级计算获胜概率的公式是什么？</title>
      <link>https://stats.stackexchange.com/questions/648088/what-is-the-formula-to-calculate-win-probability-based-on-glicko1-and-glicko2-ra</link>
      <description><![CDATA[给定 GLICO1 或 GLICO2 系统的非平局游戏、评级、mu、phi 和 sigma，如何计算各方获胜概率？
我搜索了有关这些系统的信息，例如http://glicko.net/glicko/glicko.pdf 或 wiki，甚至研究了来源计算库的代码，但未能找到解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/648088/what-is-the-formula-to-calculate-win-probability-based-on-glicko1-and-glicko2-ra</guid>
      <pubDate>Mon, 27 May 2024 18:09:59 GMT</pubDate>
    </item>
    <item>
      <title>混合效应分析中的 P 值与数据不匹配</title>
      <link>https://stats.stackexchange.com/questions/648086/p-values-not-matching-data-in-mixed-effects-analysis</link>
      <description><![CDATA[我有一个数据集，其中包含 3 种不同鱼类的耗氧量 (MO2) 值。我的实验是重复测量设计，在 4 个不同温度点（15C、20C、25C 和 30C）下测量了每个物种的 14 条鱼的 MO2。我还记录了研究中使用的所有鱼的重量。我正在尝试在 R 中运行一个混合效应模型（采用重复测量设计），其中包含重量作为协变量，因为已知重量会影响耗氧量 (MO2)。
我有一个重复测量混合效应模型，正在 R 中运行，并以权重作为协变量。我使用以下代码来运行模型：
model_interaction &lt;- lmer(MO2 ~ 温度 * 物种 + 重量 + (1|Subject_ID), 数据 = MO2mixed)
然后我进行了事后测试，因为我想知道在每个给定温度下每个物种之间的 MO2 值是否存在差异。我使用了这段代码：
emm_interaction &lt;- emmeans(model_interaction, 成对 ~ 物种 | 温度)
pairwise_interaction &lt;-pairs(emm_interaction)
打印（pairwise_interaction）
但是，当我获得事后测试的结果时，p 值和显着性与我的数据图表的外观完全不一致。例如，emmeans 函数为我提供以下统计数据：
表格参见图片：
温度=30：
对比估计 SE df t.ratio p.value
FTD-JD 0.16016 0.109 123.5 1.465 0.3115
FTD-RBD 0.47990 0.109 129.1 4.413 0.0001
JD-RBD 0.31974 0.123 101.3 2.600 0.0286
自由度方法：kenward-roger
P 值调整：用于比较 3 个估计值的 tukey 方法
然而，这对我的图表没有任何意义（见附件），在 30 度时，FTD 和 JD 之间的差异看起来最大，但在统计数据中，p 值表明它根本不显着。&lt; /p&gt;
关于为什么会发生这种情况有什么想法吗？
对于我的一些数据，在较高温度下个体缺少点，因为鱼无法应对这些温度。因此，对于某些人来说，存在早期温度的数据点，但较高温度的数据点不存在。这会是一个问题吗？我认为混合效应模型能够处理空白值？
为什么我的 p 值与数据集图表中给出的关系根本不匹配，有什么建议吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/648086/p-values-not-matching-data-in-mixed-effects-analysis</guid>
      <pubDate>Mon, 27 May 2024 17:24:20 GMT</pubDate>
    </item>
    <item>
      <title>BACI实验设计</title>
      <link>https://stats.stackexchange.com/questions/648085/baci-experimental-design</link>
      <description><![CDATA[更多的是统计问题而不是编码问题。我有来自 BACI 实验设计的数据。我有以下变量：
年份：前、第 1 年和第 2 年后
治疗：治疗和对照
3 个区域
盐度、氧化还原、水分
2 个因变量
我正在尝试回答以下问题：
治疗会改变盐度、氧化还原和水分吗？
治疗会改变因变量吗？
如果是，是什么驱动了它？
我认为一个简单的方差分析与年份*治疗相互作用可以回答关于治疗效果的问题。但我很难理解如何整合其他变量。我在想一个线性混合模型？感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/648085/baci-experimental-design</guid>
      <pubDate>Mon, 27 May 2024 16:17:38 GMT</pubDate>
    </item>
    <item>
      <title>如何从 lcmm 模型获得平均后验概率</title>
      <link>https://stats.stackexchange.com/questions/648082/how-to-obtain-the-average-posterior-probabilities-from-a-lcmm-model</link>
      <description><![CDATA[如何从 lcmm 模型对象获取平均后验概率 (APP)？我希望这个参数能够帮助我选择最合适的模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/648082/how-to-obtain-the-average-posterior-probabilities-from-a-lcmm-model</guid>
      <pubDate>Mon, 27 May 2024 15:14:10 GMT</pubDate>
    </item>
    <item>
      <title>如何比较线性回归模型与混合效应模型的性能</title>
      <link>https://stats.stackexchange.com/questions/648081/how-to-compare-the-performance-of-a-linear-regression-model-with-a-mixed-effect</link>
      <description><![CDATA[我正在分析对照小鼠和转基因 (KO) 小鼠之间的葡萄糖水平数据。我已经进行过多次这个实验（&gt; 5 个独立实验）。
为了进行分析，我执行了 3 个模型：

我只是比较各组之间的血糖水平，而不考虑体验效应 (~Group)。
在另一个例子中，我使用实验作为协变量，以考虑实验效果 (~ 实验 + 组)
最后是一个混合效应模型，其中组作为固定效应，实验作为随机效应（~Group + (1|Experiment)）。

现在，我想比较这三个模型，看看它们是否相似，并且在最好的情况下，我可以就哪个模型最好做出明智的决定。为此，我应该使用哪种指标和/或方法？我目前正在研究 AIC，但是我有点不确定该使用什么。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648081/how-to-compare-the-performance-of-a-linear-regression-model-with-a-mixed-effect</guid>
      <pubDate>Mon, 27 May 2024 15:13:04 GMT</pubDate>
    </item>
    <item>
      <title>位于不同国家/地区的设备的多元回归模型</title>
      <link>https://stats.stackexchange.com/questions/648080/multiple-regression-model-for-devices-located-in-different-countries</link>
      <description><![CDATA[如何处理回归问题，其中我有一组时间序列信号 (40) 并预测一些特征，情况是数据来自世界各地测量内部-外部温度的不同设备/电压/电流/功耗/等..
当我为每个位置设备构建模型时，我得到了很好的结果，但是当尝试将来自所有不同位置的所有数据合并到单个模型中时，性能要差得多。
鉴于测量的信号相同，为什么它给出的结果更差，我应该尝试其他方法吗？为每个设备添加某种标识符，或者我应该坚持为每个设备构建模型？
我尝试过 SGD 回归、XGboost 和 Catboost。]]></description>
      <guid>https://stats.stackexchange.com/questions/648080/multiple-regression-model-for-devices-located-in-different-countries</guid>
      <pubDate>Mon, 27 May 2024 15:07:34 GMT</pubDate>
    </item>
    <item>
      <title>修正 t 分布</title>
      <link>https://stats.stackexchange.com/questions/648078/modified-t-distribution</link>
      <description><![CDATA[设 $X_{1}, \dots, X_{n}$ 为正态分布的样本 $N (\mu, \sigma^{2})$。下一个，
$$
t_{n} = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}}
$$
具有 $t$ 自由度为 $n-1$ 的分布。
什么是分布
$$
\frac{\bar{X}}{\sigma/\sqrt{n}} ？
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/648078/modified-t-distribution</guid>
      <pubDate>Mon, 27 May 2024 14:27:08 GMT</pubDate>
    </item>
    <item>
      <title>对多个校准曲线之间的灵敏度进行排序</title>
      <link>https://stats.stackexchange.com/questions/648074/rank-the-sensitivity-among-multiple-calibration-curves</link>
      <description><![CDATA[假设使用测量设备，输出测量值 I（以 mV 为单位）与分析物浓度 C 之间存在线性关系。目标是测量 C。
我们的设备有 3 种不同的硬件配置，这些配置会影响灵敏度：

配置 1：I = a_1 * C + b_1

配置 2：I = a_2 * C + b_2

配置 3：I = a_3 * C + b_3


如何使用数字指示器定义我们的配置对浓度 C 的灵敏度？
直观上，a_i 值越高，我们的设备（输出 I）对于 C 的微小变化最敏感.
但另一方面，这两条校准曲线：
&lt;前&gt;&lt;代码&gt;I = 0.2 * C + 1000 std=100 (1)
I = 0.1 * C + 100 标准 = 10 (2)

(2) 可能是具有更高灵敏度的校准，即使斜率 0.1 是最低的，因为
0.1/10&gt; 0.2/1000，即噪音减少10倍。
这个论点相当曲折，如何用更严格的数字指标来形式化它？
注意：在在物理检测测试的背景下，$\frac{a}{b}$ 在 $y=a x+b$ 回归中被称为什么？ 我想到了斜率/截距 作为指标，但肯定还有更通用的指标。​​
指标slope / std在化学计量学中很常见吗？它有名字吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648074/rank-the-sensitivity-among-multiple-calibration-curves</guid>
      <pubDate>Mon, 27 May 2024 12:44:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Lehr 方法和 Statsmodels 的样本量估计存在如此大的差异</title>
      <link>https://stats.stackexchange.com/questions/648073/why-is-there-such-is-difference-in-sample-size-estimation-between-lehrs-method</link>
      <description><![CDATA[我一直在使用Lehr规则来估计一些实验所需的样本量我得跑了。
Lehr 规则指出我们需要：
$$ n = \frac{ 2\left(z(1-\alpha) + z(1-\beta)\right)^2 \sigma^2}{ \Delta^2} $$
其中 $ z(x) $ 是显着性水平的 $z$ 分数 $x$，$\sigma^2$ 是样本方差，$\Delta^2$ 是最小可检测效果。
下面是一些计算所需样本量的代码。
将 numpy 导入为 np
将 pandas 导入为 pd
从 scipy.stats 导入 ttest_ind，规范
从 statsmodels.stats.power 导入 TTestPower

# 计算所需样本量的函数
def计算样本大小（阿尔法，贝塔，样本方差，mde）：
    ## https://en.wikipedia.org/wiki/Power_of_a_test#Rule_of_thumb

    norm_inv_z5 =norm.ppf(1.0 - alpha/2)
    norm_inv_1_z6 =norm.ppf(1.0 - beta)
    K = 2 * (norm_inv_z5 +norm_inv_1_z6)**2
    num = K * 样本方差
    分母 = mde ** 2
    样本大小 = num / denom
    返回 int(np.ceil(sample_size))

alpha = 0.1 # t 检验的显着性水平
beta = 0.2 # 功率等级
CvR = 0.1 # 转化率
Sample_variance = CvR * (1 - CvR) # 样本方差
MDE = 0.05 # 最小可检测效果 %
n_samples =calculate_sample_size(alpha, beta,sample_variance, CvR * MDE) # 样本大小

在此示例中，我想计算网站干预的样本量。我想将转化率提高 5%。这样做可以得到大约 50,000 个样本。
使用相同的输入，我发现了以下 Statsmodels 函数来计算 t 检验的功效：
 效果大小 = (CvR * MDE) / 样本方差 
 分析 = TTestPower()
 n_samples = int(np.ceil(analysis.solve_power(effect_size, power=1.0-beta, nobs=None, alpha=alpha, Alternative=&#39;双面&#39;)))

但是，这种方法只需要约 3000 个样本。
如何解释这种差异以及原因？]]></description>
      <guid>https://stats.stackexchange.com/questions/648073/why-is-there-such-is-difference-in-sample-size-estimation-between-lehrs-method</guid>
      <pubDate>Mon, 27 May 2024 12:43:03 GMT</pubDate>
    </item>
    <item>
      <title>模型非常不稳定，固定效应回归模型中的变量大多不显着</title>
      <link>https://stats.stackexchange.com/questions/648072/very-unstable-model-and-mostly-insignificant-variables-in-fixed-effects-regressi</link>
      <description><![CDATA[上周我一直在尝试为我的硕士论文创建一个回归模型，但我遇到了以下问题。目前正在寻求我能得到的任何帮助，非常感谢您提供的任何意见。 :)
我的目标是通过几个公司和宏观经济控制变量找出欧盟排放配额价格对公司自由现金流的影响。我为此使用的数据集涵盖了大约 500 家公司以及 2005 年至 2022 年的数据。
我在 R 中建立了一个单向固定效应模型（内部），并尝试用它来估计模型。它得出以下结果，这些结果还可以，但在我看来没有意义，因为我确信某些变量应该会产生重大影响，例如 GDP 增长。
我可以做/调查什么，看看我估计模型的方式是否存在错误？我是否需要以某种方式转换变量（已经尝试过一些方法，例如日志、标准化、差分）？
非常感谢您的帮助！非常感谢。
R 输出：
模型内的单向（个体）效应
致电：
plm(公式 = FCFF ~ GDP_Growth + 无形资产 + 收入 +
折旧 + TOTAL_ASSETS + 已申请专利 + 汇率_EUR.CNY +
通货膨胀 + 石油价格 + 铅现货 + EU_ETS_期货 + EU_ETS_现货，
数据=数据，模型=“内”）
平衡面板：n = 511，T = 18，N = 9198
残差：
分钟。    第一曲。     第三曲中位数。       最大限度。
-5609351.5 -5784.3 -676.8 3676.6 7938700.2

信号。代码：0&#39;&#39;0.001&#39;&#39;0.01&#39;&#39;0.05&#39;.&#39;0.1&#39;&#39;1
总平方和：3.5016e+14
残差平方和：2.8466e+14
R 平方：0.18705
调整。 R 平方：0.13814
F 统计量：12 和 8675 DF 上为 166.339
p 值：&lt; 2.22e-16]]></description>
      <guid>https://stats.stackexchange.com/questions/648072/very-unstable-model-and-mostly-insignificant-variables-in-fixed-effects-regressi</guid>
      <pubDate>Mon, 27 May 2024 12:34:17 GMT</pubDate>
    </item>
    <item>
      <title>当处理方法是欧盟立法时，我如何论证双向固定效应模型中的控制变量？</title>
      <link>https://stats.stackexchange.com/questions/648071/how-do-i-argue-for-control-variables-in-a-two-way-fixed-effects-model-when-the-t</link>
      <description><![CDATA[首先，我不知道这是否是发布此问题的合适位置。
我使用双向固定效应回归来分析欧盟指令对公司利润的影响是否受到国家公共资金总体使用情况的调节。
问题是，当争论模型中应包含哪些控制变量以解释对国家/地区产生不同影响的时变变量时，我有点陷入困境。几年后，对我的一些单位（位于欧盟成员国的单位）进行处理（以强制执行指令的形式），而对其他单位则不会，因为它们没有放置在国家/地区是欧盟的一部分。接下来对我提出挑战的是要包含哪个控件。
由于该指令尚未实施，所有单位一开始都不会受到任何待遇，而谁受到待遇的决定因素是这些国家是否是欧盟的一部分。通常将其他变量纳入控制范围，例如国家 GDP（因为它们随时间变化并单独影响每个国家），但是，正常控制在这里似乎并不相关，因为实施指令时国家 GDP 不会产生影响。与此同时，仅包含一个变量作为控件似乎并不正确。
所以我希望有人可以帮助我了解哪种控件是合适的。]]></description>
      <guid>https://stats.stackexchange.com/questions/648071/how-do-i-argue-for-control-variables-in-a-two-way-fixed-effects-model-when-the-t</guid>
      <pubDate>Mon, 27 May 2024 12:21:54 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归系数解释</title>
      <link>https://stats.stackexchange.com/questions/648065/interpretation-of-logistic-regression-coefficient</link>
      <description><![CDATA[在逻辑回归框架内，赔率定义为：
$$\frac{p(X)}{1-p(X)}=e^{\beta_0+\beta_{1}X}。 $$
在教科书“统计学习简介”中（Gareth James 等人，2013 年），第 132 页我读到：
&lt;块引用&gt;
相比之下，在逻辑回归模型中，将 $X$ 增加一个单位会使对数几率改变 $\ beta_1 (4.4)$，或者等效地将赔率乘以 $e^{\beta_1} (4.3)$。

为什么 $X$ 中的一个单位变化会使赔率乘以 $e^{\beta_1}$?
我的推理如下：
$$\frac{\partial e^{\beta_0+\beta_{1}X}}{\partial X}= \beta_1e^{\beta_0+\beta_{1} X},$$
因此 $X$ 中的单位更改应更改 $\frac{p(X)}{1-p (X)}$ 通过 $\beta_1e^{\beta_0+\beta_{1}X}$。这对吗？
编辑在引文中，我们有（4.3）和（4.4）方程，分别给出
$$\frac{p(X)}{1-p(X)}=e^{\beta_0+\beta_{1}X}。 $$
$$log(\frac{p(X)}{1-p(X)})=\beta_0+\beta_{1}X。 $$]]></description>
      <guid>https://stats.stackexchange.com/questions/648065/interpretation-of-logistic-regression-coefficient</guid>
      <pubDate>Mon, 27 May 2024 09:13:13 GMT</pubDate>
    </item>
    <item>
      <title>心理物理学中的非正态数据：三路混合方差分析的替代方案？ （已编辑）</title>
      <link>https://stats.stackexchange.com/questions/648005/non-normal-data-in-psychophysics-alternative-to-three-way-mixed-anova-edited</link>
      <description><![CDATA[我正在对人们检测信号的能力进行实验。我计算信号检测理论测量 d prime 和 beta。我想调查信号“蓝色”是否有效比“红色”更好地被检测到。以及在实验的前半部分和后半部分中这种情况是否发生变化（两部分是看是否发生学习）。样本量为 N=18。
使用 R，我的方差分析将如下所示：
anova = aov(d&#39;~ color *section * color:section * 1|观察者)

和 

beta = aov(d&#39;~ 颜色 * 部分 * 颜色:部分 * 1|观察者)

因此，我计算了每个观察者和颜色实验部分（第一或第二）的每个组合的测量值。我使用每个实验部分的总体误报率。
事实证明，数据确实存在偏差。 d prime 是双峰分布。 d prime 的 Shapiro-Wilk 检验给出了 W = 0.92869，p 值 = 0.0003652，β 的同样结果给出了 W = 0.70378，p 值 = 4.312e-11。
在绘制 d prime 和 beta 时，d prime 似乎具有双峰分布，而 beta 严重向右倾斜。对于 Beta 值，似乎有些人在部分实验中采用了非常保守的响应偏差（Beta 值从 7 到 12）。然而，近 200 次试验并没有太大差异（因此您不会期望部分和信号之间的 beta 差异如此之大
我尝试标准化数据（平方根和对数），但没有成功。考虑到样本量较小，这种方法很难纠正它。对此有什么建议吗？我一直在寻找一种非参数替代方案，其作用与我的方差分析相同，但我找不到。如果您需要有关实验的更多详细信息，请告诉我！
]]></description>
      <guid>https://stats.stackexchange.com/questions/648005/non-normal-data-in-psychophysics-alternative-to-three-way-mixed-anova-edited</guid>
      <pubDate>Sun, 26 May 2024 09:09:22 GMT</pubDate>
    </item>
    <item>
      <title>针对小型且不平衡的数据集进行训练-验证-测试分割？</title>
      <link>https://stats.stackexchange.com/questions/647996/train-validation-test-split-for-small-and-unbalanced-dataset</link>
      <description><![CDATA[我有一个大约 100 行的数据集，每行大约有 400 个特征。其中 93 个为 0 类，7 个为 1 类。
我希望能够将 100 个示例拆分为训练集、验证集和测试集，以便我可以优化超参数并选择一个好的模型。
但是，我的 1 类行数非常少，以至于将它们混入验证或测试集的方式会导致性能指标出现巨大波动。
分割数据集以便选择良好的超参数并报告有意义的性能指标的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647996/train-validation-test-split-for-small-and-unbalanced-dataset</guid>
      <pubDate>Sun, 26 May 2024 03:47:26 GMT</pubDate>
    </item>
    <item>
      <title>计算边际效应与 brms 模型的边际效应对比</title>
      <link>https://stats.stackexchange.com/questions/647910/calculating-contrasts-of-marginal-effects-with-marginaleffects-for-brms-model</link>
      <description><![CDATA[我已经使用 brms 拟合了逻辑模型，并想要计算平均边际效应 (AME)。
库(brms)

模型 &lt;- brm(公式 = 结果 ~ var1 + var2 + var3, family = Bernoulli(), data = data)

var1 是分类的，具有两个级别 (1, 0)，var3 是分类的，具有三个级别（“a”、“b”、“0”）。 c”）。 var3 是另一个变量，在计算边际效应时我不想设置/平均其值。
现在，我想计算 var2 每个级别的 var1 的 AME/斜率。 （我不想使用平均协变量 (MEM)。）
库（边际效应）

斜率 &lt;- avg_slopes(
  模型，
  变量=“var1”，
  通过=“var2”
) %&gt;%terior_draws()

这给了我：
 术语对比度 var2 估计 2.5 % 97.5 %
 var1 平均值(1) - 平均值(0) a 0.0361 -0.1098 0.1735
 var1 平均值 (1) - 平均值 (0) b 0.0618 -0.0454 0.1666
 var1 平均值(1) - 平均值(0) c -0.0788 -0.1667 0.0177

现在，我需要这些对比之间的成对对比。即，a - b、a - c 和 b - c 的估计差异。
我可以像这样手动完成：
slopes_a &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;a&quot;)
lopes_b &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;b&quot;)
lopes_c &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;c&quot;)

df &lt;- data.frame(
  `a - b` =lopes_a$draw-slopes_b$绘制，
  `a - c` =lopes_a$draw-slopes_c$绘制，
  `b - c` =lopes_b$draw-slopes_c$绘制
）

这是一种有效的方法吗？是否有更好/更好的方法，例如直接使用 marginaleffects 包？]]></description>
      <guid>https://stats.stackexchange.com/questions/647910/calculating-contrasts-of-marginal-effects-with-marginaleffects-for-brms-model</guid>
      <pubDate>Fri, 24 May 2024 16:50:10 GMT</pubDate>
    </item>
    </channel>
</rss>