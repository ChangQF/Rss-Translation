<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 22 Jul 2024 18:19:54 GMT</lastBuildDate>
    <item>
      <title>对于在 GAM 中使用 by= 有序因子平滑处理什么作为“参考”水平感到困惑</title>
      <link>https://stats.stackexchange.com/questions/651554/confusion-about-what-is-treated-as-the-reference-level-in-gam-using-by-ordere</link>
      <description><![CDATA[在尝试遵循示例 (https://fromthebottomoftheheap.net/2017/12/14/difference-splines-ii/) 时，我有些困惑，即在 mgcv 中使用有序因子来获取差异平滑的 p 值。该博客指出，当使用公式 Y~Factor+s(X)+s(X, by=Ordered_Factor) 建模数据时，其中“因子”和“Ordered_Factor”定义相同的组，一个是有序的，另一个不是，s(X) 项应该在有序因子的参考水平上对平滑进行建模。我对这里提到的“参考水平”很好奇。例如，如果我的因子已按 A、B、C、D、E、G 级别排序，那么参考级别是 A 吗？或者参考级别是所有数据的整体平滑度，而无需按因子分离它们？
我问这个问题的原因是，如果我创建一些假设数据，则 s(X) 项似乎适合整体数据的平滑度，而不是因子级别 A 的平滑度：
library(mgcv)
library(ggplot2)
library(gratia)

set.seed(42)

x&lt;-seq(0,20, by=2)

A&lt;-data.frame(Treatment=rep(&quot;A&quot;,length(x)),Time=x,Expression=rep(rnorm(length(x),0,0.1)))

B&lt;-data.frame(Treatment=rep(&quot;B&quot;,长度(x)),时间=x,表达式=(100*(-exp(-x*0.5)+exp(-x*0.4))+rnorm(长度(x), 0 , 0.1)))

C&lt;-data.frame(Treatment=rep(&quot;C&quot;, 长度(x)),时间=x,表达式=(100*(-exp(-x*0.5)+exp(-x*0.44))+rnorm(长度(x), 0 , 0.1)))

D&lt;-data.frame(Treatment=rep(&quot;D&quot;, 长度(x)),时间=x,表达式=(100*(-exp(-x*0.20)+exp(-x*0.174))+rnorm(长度(x), 0 , 0.1)))

E&lt;-data.frame(Treatment=rep(&quot;E&quot;, length(x)),Time=x,Expression=(100*(-exp(-x*0.50)+exp(-x*0.4))+rnorm(length(x), 0 , 0.1)))

G&lt;-data.frame(Treatment=rep(&quot;G&quot;, length(x)),Time=x,Expression=(100*(-exp(-x*0.50)+exp(-x*0.4))+rnorm(length(x), 0 , 0.1)))

df&lt;-rbind(A,B,C,D,E,G)

df$Treatment&lt;-factor(df$Treatment)

df$Treatmentord&lt;-factor(df$Treatment, ordered=T)

数据如下所示：

然后，我使用模型中的有序因子拟合带有 mgcv 的 GAM，如链接博客中所述，并使用 gratia 包绘制平滑拟合：
md_ordered&lt;-gam(Expression ~ Treatment + s(Time) + s(Time, by=Treatmentord), data=df, method = &quot;REML&quot;)

gratia::draw(md_ordered, residuals=T)

gratia::draw() 的输出如下所示：

此输出向我表明，s（时间）平滑是因子水平未分离时的时间平滑，而不是&quot;参考&quot; 处的时间平滑因子水平。
如果我改为拟合没有 s（时间）项的模型并使用无序因子并绘制 gratia::draw() 输出：
md_unordered&lt;-gam(Expression ~ Treatment + s(Time, by=Treatment), data=df, method = &quot;REML&quot;)
gratia::draw(md_unordered, residuals=T)

那么因子水平 A 的输出当然有意义，但现在我无法获得能够统计测试平滑差异的好处。

有人能帮忙澄清一下，是否确实可以拟合一个仅在参考水平上平滑，然后在剩余因子水平上进行差异平滑的模型，或者我只是误解了如何使用 mgcv 和 gratia 包。如果无法实现我想要的效果，那么测试平滑但子集数据仅具有两个无序因子水平并比较以下两个模型是否合适（例如）：
df_sub&lt;-rbind(A,B)
df_sub$Treatment&lt;-factor(df_sub$Treatment)

md1&lt;-gam(Expression ~ Treatment + s(Time, by=Treatment), data=df_sub, method=&quot;REML&quot;)
md2&lt;-gam(Expression ~ Treatment + s(Time), data=df_sub, method=&quot;REML&quot;)

anova(md1,md2)

提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/651554/confusion-about-what-is-treated-as-the-reference-level-in-gam-using-by-ordere</guid>
      <pubDate>Mon, 22 Jul 2024 18:06:43 GMT</pubDate>
    </item>
    <item>
      <title>训练图像分类器来检测线角度的细微差异</title>
      <link>https://stats.stackexchange.com/questions/651553/training-an-image-classifier-to-detect-slight-differences-in-line-angles</link>
      <description><![CDATA[我一直在努力训练 Yolov8 分类器来检测线角度的细微差异，以取得成功。
我的直觉是，线角度的差异非常小，分类器很难做出区分。一些证据证实了这一猜测，即 top-1 准确率仅为 0.66，而 top-5 准确率仅为 1。
训练数据大致如下：




原始数据以 0.01 为增量将角度分开。因此 0.01、0.02、0.03 都符合不同角度的条件。我知道分类器很难达到这种特异性水平，所以我对其进行了简化，将数据分组为不同的类别：0.0-0.1、0.1-0.2 和 0.2-0.3，一直到 1.5-1.6，剩下 11 个类别。
虽然类别存在，并为模型添加了可行的结构，但数据中的实际特异性仍然存在。为了说明这一点，以下两幅图像看起来几乎相同，但属于不同的类别。


人眼无法轻易辨别哪条线更陡峭，这一事实让我怀疑该模型是否能够可靠地做到这一点。
需要注意的一点是，我没有在训练数据中包含背景类。原因是该模型只会在背景最少的非常特殊的条件下使用。
最后一件事 - 这是来自训练输出的混淆矩阵。
]]></description>
      <guid>https://stats.stackexchange.com/questions/651553/training-an-image-classifier-to-detect-slight-differences-in-line-angles</guid>
      <pubDate>Mon, 22 Jul 2024 17:55:58 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试拟合混合模型，但得到“边界（单数）拟合：参见帮助（‘isSingular’）”</title>
      <link>https://stats.stackexchange.com/questions/651552/im-trying-to-fit-a-mixed-model-but-i-get-boundary-singular-fit-see-helpis</link>
      <description><![CDATA[我对组和时间的主要影响以及它们之间的相互作用感兴趣
model &lt;- lmer(Y~ Group * Time +(1|ID),data=data)


summary(model)
REML [&#39;lmerMod&#39;] 拟合的线性混合模型
公式：Y ~ Group * Time + (1 | ID)
数据：data

收敛时的 REML 标准：365.3
缩放残差：
最小 1Q 中位数 3Q 最大
-2.0906 -0.6369 -0.1614 0.7726 2.1487
随机效应：
组名称方差标准差。
ID（截距）0.00 0.000
残差 89.89 9.481
观察数：54，组：ID，27
固定效应：
估计标准差。误差 t 值
（截距） 50.1511 3.1604 15.869
GroupB -0.6267 4.4695 -0.140
GroupC 1.1667 4.4695 0.261
Time1 2.5922 4.4695 0.580
GroupB:Time1 -2.3111 6.3208 -0.366
GroupC:Time1 -3.8178 6.3208 -0.604
固定效应相关性：
（内部） GroupB GroupC T1 GrB:T1
GroupB -0.707
GroupC -0.707 0.500
Time1 -0.707 0.500 0.500
GroupB:T1 0.500 -0.707 -0.354 -0.707
GroupC:T1 0.500 -0.354 -0.707 -0.707 0.500
优化器 (nloptwrap) 收敛代码：0 (OK)
边界 (奇异) 拟合：参见帮助 (&#39;isSingular&#39;)
变量：

时间 (第 1 天，第 2 天)
组 A B C

起初我认为 ID 没有随机效应方差，但在我看来，图中的集群似乎存在依赖性。问题是否出在只有 2 个时间点的小集群大小上？建模该问题更合适的方法是什么？

我尝试了线性模型，结果显示 Group、Time 和 Y 之间没有显著相关性。]]></description>
      <guid>https://stats.stackexchange.com/questions/651552/im-trying-to-fit-a-mixed-model-but-i-get-boundary-singular-fit-see-helpis</guid>
      <pubDate>Mon, 22 Jul 2024 17:38:47 GMT</pubDate>
    </item>
    <item>
      <title>根据 NHANES 中具有不同加权方案的两个不同变量定义一个变量</title>
      <link>https://stats.stackexchange.com/questions/651551/defining-a-variable-based-on-two-different-variables-with-different-weighting-sc</link>
      <description><![CDATA[我想使用 NHANES 中的两个原始变量（$X$ 和 $Y$）定义一个派生变量（我们称之为 $Z$）。如果 $X$ 或 $Y$ 中的任何一个符合条件，则 $Z$ 的值应为 1；否则，应为零。即使 $X$ 缺失，但 $Y$ 等于 1，我也会认为 $Z$ 等于 1。
我的问题是，这两个变量在 NHANES 的检查部分中处于不同的域中，因此 $X$ 需要使用 WTMEC 权重，而 $Y$ 需要对那些接受过该测试的人使用特定权重。
我最初认为我需要在加权中使用最小的样本权重，这与 $Y$ 相关。但是，这将根据 $X$ 等于 1 的情况丢弃符合条件的人。所以，我不确定在这种情况下最好的行动方案是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/651551/defining-a-variable-based-on-two-different-variables-with-different-weighting-sc</guid>
      <pubDate>Mon, 22 Jul 2024 17:28:26 GMT</pubDate>
    </item>
    <item>
      <title>逻辑分布的 MLE</title>
      <link>https://stats.stackexchange.com/questions/651550/mle-for-the-logistic-distribution</link>
      <description><![CDATA[对数似然由以下公式给出
$\log L(k,\mu) = \sum_{i=1}^n \log k - k(x_i-\mu) - 2\log(1+e^{-k(x_i-\mu)})$
如果 $-k(x_i-\mu)$ 很大，则 $\log(1+e^{-k(x_i-\mu)}\approx -k(x_i - \mu)$ 足够。
这意味着 $\log L(k,\mu) \approx \sum_{i=1}^n \log k + k(x_i-\mu)$。
如果 $k\to\infty,\mu\to-\infty$，则该值无界。
我的问题是如何才能让它最终发挥作用？我更喜欢基于梯度的方式进行参数估计。]]></description>
      <guid>https://stats.stackexchange.com/questions/651550/mle-for-the-logistic-distribution</guid>
      <pubDate>Mon, 22 Jul 2024 17:21:50 GMT</pubDate>
    </item>
    <item>
      <title>浅层深度学习嵌入模型比宽层深度学习嵌入模型更好吗？</title>
      <link>https://stats.stackexchange.com/questions/651549/shallow-better-than-wide-deep-learning-embedding-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651549/shallow-better-than-wide-deep-learning-embedding-models</guid>
      <pubDate>Mon, 22 Jul 2024 17:15:40 GMT</pubDate>
    </item>
    <item>
      <title>应用权重而不是匹配</title>
      <link>https://stats.stackexchange.com/questions/651546/applying-weights-instead-of-matching</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651546/applying-weights-instead-of-matching</guid>
      <pubDate>Mon, 22 Jul 2024 16:15:02 GMT</pubDate>
    </item>
    <item>
      <title>在 partykit 中指定调查权重</title>
      <link>https://stats.stackexchange.com/questions/651544/specifying-survey-weights-in-partykit</link>
      <description><![CDATA[对于我正在处理的数据集，我知道如何使用 survey 包中的 svydesign 函数指定权重：
svydesign(data = x, id = ~id, strata = NULL, weights = wgt)
我的问题是关于在 party::mob() 中实现此结构的可能性。鉴于上述 svydesign 对象中 strata 的 NULL 值，以下是否是等效的权重规范？
mob(..., weights = wgt, cluster = id)
我看到了一些关于这个主题的一般问题（例如 这个），这些问题表明复杂的调查权重无法在 party 包中成功实施。不过，我想知道，svydesign() 函数中缺少 strata 参数是否足以简化权重情况，以便 party 包能够处理它。]]></description>
      <guid>https://stats.stackexchange.com/questions/651544/specifying-survey-weights-in-partykit</guid>
      <pubDate>Mon, 22 Jul 2024 16:05:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么在应用 CLR 转换之前将计数转换为比例？</title>
      <link>https://stats.stackexchange.com/questions/651542/why-convert-counts-to-proportions-before-applying-clr-transformation</link>
      <description><![CDATA[我注意到，在微生物组数据分析中，分类单元计数通常会在应用中心对数比 (CLR) 变换之前转换为比例。为什么需要先将计数转换为比例，而不是直接将 CLR 变换应用于原始计数？]]></description>
      <guid>https://stats.stackexchange.com/questions/651542/why-convert-counts-to-proportions-before-applying-clr-transformation</guid>
      <pubDate>Mon, 22 Jul 2024 14:53:50 GMT</pubDate>
    </item>
    <item>
      <title>帕累托随机变量的参数 k 的 MLE 偏差 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/651541/bias-of-mle-of-parameter-k-of-pareto-random-variable</link>
      <description><![CDATA[在使用帕累托 R.V. 的 CDF 时

Pr(X&lt;x) = 1- (1/x^k) ，其中 k &gt; 0 和 x &gt; 1 ，其中我的 X_i ，i = 1,2,...,n 是 i.i.d ，然后将偏差应用于 k = n/(sum(log(x_i)) 的 MLE 估计量，我被困在将预期值应用于此类估计量的分母，如果 k 在 log(x) 中是凸的，是否可以通过 Jensen 不等式进行？

非常感谢您的意见]]></description>
      <guid>https://stats.stackexchange.com/questions/651541/bias-of-mle-of-parameter-k-of-pareto-random-variable</guid>
      <pubDate>Mon, 22 Jul 2024 14:52:00 GMT</pubDate>
    </item>
    <item>
      <title>估计最小检测概率以选择对照和病例</title>
      <link>https://stats.stackexchange.com/questions/651539/estimating-a-minimal-probability-of-detection-to-choose-controls-and-cases</link>
      <description><![CDATA[我有一个养牛场的数据集，包括牛结核病的检测结果以及检测和屠宰的牛的数量。肉类检查也算作牛结核病的检测。
我想对农场进行对照案例研究，而不是牛，阳性/病例农场被认为是至少有一头牛检测呈阳性的农场。
问题在于“监测压力”或“检测概率”各个农场之间的差异并不明显，样本也不是随机的，所以我想根据最小的预期检测概率来选择对照和病例，以避免分析检测概率太低的农场的结果，如果存在疾病，可能会导致假阴性。
为了估计牛结核病阳性农场的预期检测概率，我制定了以下公式：

其中：
ePD 表示在农场为阳性的情况下，检测出阳性动物的预期概率。
p 表示阳性农场内 BT 的设计或预期流行率牛群/农场。
sid 表示皮内测试的灵敏度。
sab 表示屠宰场检查的灵敏度。
i 表示皮内测试的数量
a 表示屠宰场检查的牛的数量
我现在的问题是如何选择 ePD 的最小值而不武断？0.5 似乎是一个很好的值，但我需要从统计上解释其背后的逻辑。]]></description>
      <guid>https://stats.stackexchange.com/questions/651539/estimating-a-minimal-probability-of-detection-to-choose-controls-and-cases</guid>
      <pubDate>Mon, 22 Jul 2024 14:36:38 GMT</pubDate>
    </item>
    <item>
      <title>如何解决估计线性双变量回归模型中的ARCH效应问题？</title>
      <link>https://stats.stackexchange.com/questions/651531/how-to-solve-the-arch-effect-problem-in-estimating-linear-bivariate-regression-m</link>
      <description><![CDATA[我用 OLS 方法估计了一个线性双变量回归模型。
我做了 ARCH 效应检验。残差中存在 ARCH 效应。
在估计双变量线性模型时，如何处理 ARCH 效应的存在？]]></description>
      <guid>https://stats.stackexchange.com/questions/651531/how-to-solve-the-arch-effect-problem-in-estimating-linear-bivariate-regression-m</guid>
      <pubDate>Mon, 22 Jul 2024 13:17:17 GMT</pubDate>
    </item>
    <item>
      <title>连续治疗变量的差异</title>
      <link>https://stats.stackexchange.com/questions/651529/difference-in-difference-with-continuous-treatment-variable</link>
      <description><![CDATA[我想看看冲突导致某个地区的人员伤亡对金融机构业绩的影响。我有 8 家在 8 个国家/地区运营的机构 2015 年至 2022 年的数据。死亡相关数据是截至 2018 年每个国家/地区冲突造成的死亡总人数，这是一个处理变量。我想在 2018 年前后应用具有固定效应的 DiD。我指定的模型如下：
$$
Y_{it} = \beta_0 + \beta_1 \text{Fatalities}_i + \beta_2\text{Post}_t + \beta_3\text{Fatalities}_i\text{Post}_t + X_{it} + \alpha_i + \gamma_t + \epsilon_{it}
$$
其中 $\alpha_i$ 是机构固定效应，$\gamma_t$ 是时间固定效应。
上述模型正确吗？使用具有固定效应的 DID 进行分析的最佳方法是什么？
​]]></description>
      <guid>https://stats.stackexchange.com/questions/651529/difference-in-difference-with-continuous-treatment-variable</guid>
      <pubDate>Mon, 22 Jul 2024 13:07:50 GMT</pubDate>
    </item>
    <item>
      <title>解释 $R^2$ 的复根</title>
      <link>https://stats.stackexchange.com/questions/651523/interpreting-complex-roots-of-r2</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651523/interpreting-complex-roots-of-r2</guid>
      <pubDate>Mon, 22 Jul 2024 10:47:57 GMT</pubDate>
    </item>
    <item>
      <title>基于模拟的校准 - 意外相关性 - 文献</title>
      <link>https://stats.stackexchange.com/questions/651521/simulated-based-calibration-unexpected-correlations-literature</link>
      <description><![CDATA[我正在尝试应用 SBC，因此我根据先验（使用 rstan）生成了一些虚假数据，然后使用相同的模型拟合数据。
模型如下所示，
y ~ -1+analyst + (analyst|p) + (analyst|u)
尽管生成的虚假数据没有相关的随机效应，但模型显示出负相关性。我也在这里发布了这个问题，但现在我正在寻找讨论这个问题的参考资料。

蓝点：每个后验的平均值
黑色间隔：蓝点的 HDI
橙色是我用来生成数据的先验。


有没有参考资料讨论为什么模型会发现相关性是否存在数据生成时不相关的情况？
更详细地说，
虚假数据由具有不同截距和斜率的多层模型生成（即 analyst|p）。用于此的先验是 LKJ(5)，其结果应平均无相关性。但是，如上图所示，Omega_p 和 Omega_u 具有负相关性
]]></description>
      <guid>https://stats.stackexchange.com/questions/651521/simulated-based-calibration-unexpected-correlations-literature</guid>
      <pubDate>Mon, 22 Jul 2024 10:25:46 GMT</pubDate>
    </item>
    </channel>
</rss>