<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 14 Dec 2023 21:11:54 GMT</lastBuildDate>
    <item>
      <title>$\frac{X^2}{Y^2}$ 的分布，其中 $X$ 和 $Y$ 是 iid 标准正态分布</title>
      <link>https://stats.stackexchange.com/questions/634951/distribution-of-fracx2y2-where-x-and-y-are-iid-standard-normal</link>
      <description><![CDATA[让 $X,Y\in \mathcal{N}(0,1)$ 与 $X$&lt; /span&gt; 和 $Y$ 独立。我对 $Z=X^2/Y^2$ 的 pdf 感兴趣，其中有一个 $\mathcal{F }(1,1)$ Fisher 分布。我知道他可以通过首先找到 $U=X^2$ 和 $V=Y^ 的 pdf 来完成2$ 并找到 $U/V$ 的 pdf。但是，我对以下方法感兴趣：让 $h$ 为任何 Borel 可测量函数
$$E[h(Z)]=E[h(X^2/Y^2)]=\int_0^\infty\int_0^\infty h\left(\frac {x^2}{y^2}\right)e^{-x^2/2-y^2/2}\frac{1}{2\pi}dxdy.$$
我不确定，但我的直觉告诉我，可以通过更改变量来获得
$$E[h(Z)]=\int_0^\infty h(z)\cdot f(z)dz,$$
因此 $f(z)$ 将是 $Z$ 的 pdf。你认为有人能发现这一变量的变化吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634951/distribution-of-fracx2y2-where-x-and-y-are-iid-standard-normal</guid>
      <pubDate>Thu, 14 Dec 2023 20:54:58 GMT</pubDate>
    </item>
    <item>
      <title>如何用python组建一个专业的项目？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/634947/how-to-form-a-professional-project-in-python</link>
      <description><![CDATA[我正在学习Python，特别是在机器学习和计算机视觉方面。最近在尝试查看Github上的一些论文的代码。我得到的一件事是，为论文编写代码与互联网上的教程有很大不同。它们要复杂得多，由许多不同的文件夹和 .py 文件组成，例如 utils.py、main.py、train.py、init.py 等。我对此事有一些疑问。首先，这些文件的名称是使用某些东西自动创建的还是由编写者手动创建的？其次，如果是自动的，我如何创建这样的编码风格，如果它们是手动完成的，是否有我应该使用的命名或编码的标准格式？最后，有没有参考资料可以教如何创建这样的标准编码风格？]]></description>
      <guid>https://stats.stackexchange.com/questions/634947/how-to-form-a-professional-project-in-python</guid>
      <pubDate>Thu, 14 Dec 2023 20:15:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么训练准确率保持很高，但验证准确率没有变化？</title>
      <link>https://stats.stackexchange.com/questions/634946/why-the-training-accuracy-stays-high-but-validation-accuracy-does-not-change</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/634946/why-the-training-accuracy-stays-high-but-validation-accuracy-does-not-change</guid>
      <pubDate>Thu, 14 Dec 2023 20:13:06 GMT</pubDate>
    </item>
    <item>
      <title>如何将非独立实验的结果与相同的零假设相结合（例如突变小鼠没有焦虑）</title>
      <link>https://stats.stackexchange.com/questions/634944/how-to-combine-results-from-non-independent-experiments-with-same-null-hypothesi</link>
      <description><![CDATA[我们对一组野生型和突变型小鼠进行了许多不同的行为测试。
在不同日期对同一组小鼠进行 5 项不同的测试，评估焦虑程度。
虽然 bonferonni 或其他一些多重测试校正会“惩罚”重复测试，将我们的 alpha 调整到 ~alpha/5，我认为通过以某种方式结合结果应该会增加信心。
Fisher 的组合 p 值方法（据我了解）无法应用，因为这些方法不是独立的：重复测试相同的小鼠。
我可以运行什么统计测试，或者推荐使用什么方法来结合 5 个（非独立）测试的结果来对显着性差异进行总体评估？
因为测试不同，例如在长度和字符方面，我们无法汇集原始数据，但可以在这方面使用 z 分数吗？
在这些类型的实验中，我们通常可能会看到 2、3 或 4 个与 p&lt;0.05 一样显着（没有多重测试校正），但由于 n 较低，每个 p 值并不惊人靠自己。]]></description>
      <guid>https://stats.stackexchange.com/questions/634944/how-to-combine-results-from-non-independent-experiments-with-same-null-hypothesi</guid>
      <pubDate>Thu, 14 Dec 2023 19:32:01 GMT</pubDate>
    </item>
    <item>
      <title>多重插补后汇集假设检验的 p 值</title>
      <link>https://stats.stackexchange.com/questions/634943/pooling-p-values-from-hypothesis-tests-after-multiple-imputation</link>
      <description><![CDATA[我正在开发一个项目，该项目使用了一些比我通常习惯的更先进的统计方法和编码，并且希望得到一些帮助。该项目要求我进行多重插补，这是我使用 mouse r 包完成的。我现在有一个 mids 对象，其中包含 10 个估算数据集（1,200 行，123 个变量）。
我正在制作表 1，其中包含人口统计学差异和性别（男性与女性）其他变量差异的汇总统计数据和 p 值。因为我的连续变量不是正态分布的，所以我计划进行 Mann Whitney U/Wilcoxon 检验来比较它们并提取 p 值。
我的问题在于如何使用乘法插补数据集来执行此操作并汇集 p 值。取中位数就足够了，还是应该使用更高级的方法？我在这里遇到了一种方法：(如何获取在多个估算数据集中完成的测试的汇总 p 值？ - 请参阅 Stef van Buuren 的评论），但此方法声明它仅适用于单方面测试，我我正在进行双边测试，以检测性别之间年龄、体重和身高等特征的任何差异。
据我所知，考虑到我的样本量，t 检验可能足够稳健（并且在 R 中合并这些 p 值的方法似乎更简单），但除年龄之外的所有连续变量都显着偏斜。 
有人知道这里什么是合适的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634943/pooling-p-values-from-hypothesis-tests-after-multiple-imputation</guid>
      <pubDate>Thu, 14 Dec 2023 19:31:39 GMT</pubDate>
    </item>
    <item>
      <title>作为最接近线性表面的主成分与作为二维最佳线性近似的回归线之间的差异</title>
      <link>https://stats.stackexchange.com/questions/634941/difference-between-principal-component-as-closest-linear-surface-and-regression</link>
      <description><![CDATA[我目前正在做一个有关 PCA 的演示，作为研讨会计划的一部分，其中一张幻灯片是关于在任意二维数据集上构建的第一个主成分的解释。在我的一本名为“统计学习与应用简介”的参考书中，作者：Gareth James、Daniela Witten、Trevor Hastie、Robert，自 2015 年起，作者在第 14 页给出了另一种解释。 [第 379 章] 第 379 章
&lt;块引用&gt;
“p 维空间中最接近 n 个观测值的线（使用平均平方欧几里得距离作为接近度的度量）”。

我认为这意味着将第一条 PC 线添加到我的数据的二维散点图中，该数据是在我的缩放和居中的原始数据集上从 R 中的 PCA 获得的，将是等效的在缩放和居中的数据集上添加简单线性回归的回归线（=最佳线性近似），但我的示例中的值/结果反对它。在数字中，当我在基R中使用prcomp(x)对我的数据执行PCA时，它产生了加载向量$\对于第一台 PC，phi_1 = (-0.7071068, -0.7071068)$，但简单的线性回归产生的斜率参数为 $\hat{\beta}_1 = 0.7843085$ 。 
因此，我不得不问我的方法/思维是否有问题，这种关于 PC 的解释是否大约成立，或者我是否搞砸了编码？我的代码示例：
ex.df &lt;- 结构(列表(x = c(70.7, 82.5, 36.5, 97.2, 52.7, 56, 61.3,
59.6、32.5、33.6、70.7、31.3、67、47.6、98.5、64.4、78.7、71.4、
88.7、83.4、44.7、44、56.4、69、30.8、54.5、67.3、56.7、40.7、
36.7, 57.8, 84.7, 35.9), y = c(16, 23.2, 12.2, 18.2, 16.2, 13.5,
14.8、17.3、8、11.7、21.8、10、21.9、13、19.1、14.7、20.2、22.1、
20.5、16.7、9.4、12.2、9.4、18.4、5.8、15.8、13、16、12.5、8.1、
16.4, 14.9, 10.5)), row.names = c(NA, -33L), class = c(“tbl_df”,
“tbl”、“data.frame”））

ex.df &lt;- as.data.frame(scale(ex.df, center = T, scale = T))
apply(ex.df, 2,mean) # 检查 ~0
apply(ex.df, 2, var) # 检查 1
ex.pca &lt;- prcomp(ex.df)
ex.pca # 第一次加载 = (−0.7071068,−0.7071068)
coef(lm(y ~ x, 数据 = ex.df))
]]></description>
      <guid>https://stats.stackexchange.com/questions/634941/difference-between-principal-component-as-closest-linear-surface-and-regression</guid>
      <pubDate>Thu, 14 Dec 2023 19:24:37 GMT</pubDate>
    </item>
    <item>
      <title>从样本中重新采样以匹配所需的分布</title>
      <link>https://stats.stackexchange.com/questions/634940/resample-from-a-sample-to-match-a-desired-distribution</link>
      <description><![CDATA[假设我有观察$x_1,\dots,x_n$，从$\mathbb{上的某些分布中采样了iid R}$，带有 pdf $p(x)$。假设我希望有一个 pdf $q(x)$ 发行版的样本。有没有办法从 $x_1,\dots,x_n$ 中选择子样本，以便子样本可以被视为来自 $q(x)$?
动机：也许我的观察来自有偏差的分布，我想消除它的偏差。也许现实世界的分布发生了变化，我会观察以匹配更新的分布。不幸的是，我无法“称重”个人观察；我所能做的就是为我的子样本选择观察结果的子集。
换句话说，我想要一个概率过程，将 $x_1,\dots,x_n$ 作为输入，并输出 $x_1,\dots,x_n$，如果给定 $n$ iid 则从 $p(x)$，那么其输出的分布与从 $q(x)$ 中提取的一些 iid 相同。这里 $p(x),q(x)$ 是已知的。我很高兴对 $p(x),q(x)$ 做出任何有用的假设，例如，它们是平滑的、连续可微的，等等。]]></description>
      <guid>https://stats.stackexchange.com/questions/634940/resample-from-a-sample-to-match-a-desired-distribution</guid>
      <pubDate>Thu, 14 Dec 2023 19:20:55 GMT</pubDate>
    </item>
    <item>
      <title>线性和非线性模型的辨识</title>
      <link>https://stats.stackexchange.com/questions/634939/identifications-for-the-linear-and-non-linear-models</link>
      <description><![CDATA[考虑线性模型和非线性模型：
$$Y=X&#39;\beta+u$$
$$Y=m\left(X;\beta\right)+u$$
那么，根据我的理解，线性模型中$\beta$的识别条件是
条件1：对于某些$\beta_0$，$\mathbb{E}\left[Y\middle| X\right]=X&#39;\beta_0$
条件2：$\mathbb{E}\left[XX&#39;\right]$满级
并且，在非线性模型中，辨识需要
条件3：对于某些$\beta_0$，$\mathbb{E}\left[Y|X\右]=m\left(X;\beta_0\right)$
条件4：$\mathbb{E}\left[\left(Y-m\left(X;\beta_0\right)\right)^2\right]&lt;\ mathbb{E}\left[\left(Y-m\left(X;\beta\right)\right)^2\right]$ 对于所有 $\beta\ neq \beta_0$
这里，因为条件1是条件3的特例，所以我认为条件2也可能是条件4的特例，或者至少它们之间应该有某种联系。
所以，我首先将条件 4 重写如下
$$\mathbb{E}\left[\left(Y-X&#39;\beta_0\right)^2\right]&lt;\mathbb{E}\left[\left( Y-X&#39;\beta\right)^2\right]\quad \textrm{对于所有} \quad \beta \neq \beta_0$$
那么，条件 2 和 4 似乎都说明了 $\beta_0$ 的独特性。
但是，我不确定条件 2 和条件 4 之间的确切联系是什么。
条件 2 是条件 4 的特例吗？如果不是，那么它们之间不是有联系吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634939/identifications-for-the-linear-and-non-linear-models</guid>
      <pubDate>Thu, 14 Dec 2023 19:15:50 GMT</pubDate>
    </item>
    <item>
      <title>Python 中没有趋势或季节性的短时间序列的预测方法</title>
      <link>https://stats.stackexchange.com/questions/634938/forecasting-methods-for-a-short-time-series-with-no-trend-or-seasonality-in-pyth</link>
      <description><![CDATA[我对数据科学还很陌生，我的项目遇到了一些问题。
我正在尝试为时间序列数据建立预测模型。这大约是农业每年的二氧化碳排放量。
问题是数据集非常有限（30 个值对应 30 年，即每年一个值），从这个系列中我没有发现任何趋势，并且季节性为 0。
df 来自 csv 文件，格式如下：
“年份”包含 1990 - 2020 年值的列
“CO 2 ”包含每年值的列 (115-47)
所有值都是整数，没有缺失值或极端值
我正在尝试使用Python工作，到目前为止，我已经尝试过ETS、Holt Winters、Prophet和ARIMA，但它们都输出一条与总值平均值相对应的直线，作为预测，具有非常广泛的ci .
我的问题是，我可以使用什么模型来尝试为即将到来的
10-20 个时间步长（年）？
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/634938/forecasting-methods-for-a-short-time-series-with-no-trend-or-seasonality-in-pyth</guid>
      <pubDate>Thu, 14 Dec 2023 19:07:58 GMT</pubDate>
    </item>
    <item>
      <title>多重比较 LSD 检验中对均值进行分组的算法是什么？</title>
      <link>https://stats.stackexchange.com/questions/634937/what-is-the-algorithm-for-grouping-means-in-a-multiple-comparisons-lsd-test</link>
      <description><![CDATA[从 10 次处理的平均值开始，Fisher LSD 区间为 2.1，如何“手动”计算确定同质组（a、b、c、d...）的数量以及哪个均值属于哪一个？
treatments = c(“一”,“二”,“三”,“四”,“五”,“六”,“七”,“八”, “九”、“十”）
平均值 = c(6.4,7.6,8.7,8.9,9.1,9.4,9.6,9.8,9.9,11.0)
LSD=2.1

两两比较很容易理解，但同时对多个均值进行分组就很复杂。
我正在寻找一种 R 算法来理解显着不同的均值的分组过程。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/634937/what-is-the-algorithm-for-grouping-means-in-a-multiple-comparisons-lsd-test</guid>
      <pubDate>Thu, 14 Dec 2023 19:06:57 GMT</pubDate>
    </item>
    <item>
      <title>研究数据集几何结构的学术领域名称</title>
      <link>https://stats.stackexchange.com/questions/634930/name-of-academic-field-studying-geometric-structure-of-data-sets</link>
      <description><![CDATA[我对数据集的几何结构有疑问，尤其是。因为它涉及预测变量之间的关系。该字段有名称吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634930/name-of-academic-field-studying-geometric-structure-of-data-sets</guid>
      <pubDate>Thu, 14 Dec 2023 17:44:51 GMT</pubDate>
    </item>
    <item>
      <title>如何用 sin 和 cos 函数之和来近似时间序列？</title>
      <link>https://stats.stackexchange.com/questions/634929/how-do-i-approximate-a-timeseries-with-a-sum-of-sin-and-cos-functions</link>
      <description><![CDATA[我有一个时间序列，我试图使用以下类型的方程来近似它：
y = A + B*sin(2*pi*x/n) + C*cos(2*pi*x/m) + D*sin(2*pi*x/q) + . ..
问题是如何找到参数A、B、C、D、n、m、q等...手动查找这些值显然是一个非常繁琐的过程。我认为这对于 FFT 来说是一个相对简单的问题，但我一无所获（以前从未做过！）。
我的代码（R）是这样的：
value.ft &lt;- fft(out.df$VALUE)
value.terms &lt;- 4

fft.value &lt;-rep(0, length(value.ft))
fft.value[1:value.terms] &lt;- value.ft[1:value.terms]

value.approx &lt;- Re(fft(fft.value, inverse=TRUE)) / length(out.df$VALUE)

使用以下 data.frame (out.df) 作为输入：
结构(列表(out.df.SEC = c(0, 300, 600, 900, 3000, 3300, 3600,
3900、4200、4500、6600、6900、7200、7500、7800、8100、10200、
10500、10800、11100、11400、13500、13800、14100、14400、14700、
15000、17100、17400、17700、18000、18300、18600、20700、21000、
21300、21600、21900、22200、24000、24300、24600、24900、25200、
25500、27600、27900、28200、28500、28800、29100、31200、31500、
31800、32100、32400、32700、34500、34800、35100、35400、35700、
36000、38100、38400、38700、39000、39300、39600、41700、42000、
42300、42600、42900、43200、45300、45600、45900、46200、46500、
48600、48900、49200、49500、49800、50100、52200、52500、52800、
53100、53400、53700、55800、56100、56400、56700、57000、59100、
59400、59700、60000、60300、60600、62700、63000、63300、63600、
63900、64200、66300、66600、66900、67200、67500、69600、69900、
70200、70500、70800、71100、73200、73500、73800、74100、74400、
74700、76800、77100、77400、77700、78000、78300、80100、80400、
80700, 81000, 81300, 81600), out.df.VALUE = c(4.858, 4.938, 4.724,
4.45、3.70666666666667、3.9、3.83、3.784、3.704、3.6775、3.4375、
3.368、3.394、3.552、3.728、3.65、3.46、3.444、3.392、3.378、
3.444、3.34、3.328、3.246、3.192、3.212、3.23、3.6475、3.484、
3.418、3.556、3.778、3.80666666666667、4.278、4.428、4.62、4.886、
4.872、4.99、6.7、6.132、5.318、4.722、4.556、4.32、4.4125、4.442、
4.376、4.43、4.55、4.58、4.114、4.026、4.11、3.994、3.97、4.13、
3.98、4.006、3.918、3.75、3.734、3.652、3.81、3.814、3.816、3.674、
3.592、3.78、3.608、3.446、3.474、3.564、3.252、3.17、3.1、3.044、
2.818、2.868、2.564、2.65、2.732、2.76、2.646、2.608、2.6075、
3.0975、2.794、2.962、2.848、2.276、2.15、2.326、2.19、2.396、
2.072、2.758、2.73666666666667、2.66、2.726、2.556、2.61、2.964、
3.125、3.014、2.966、2.794、2.95、2.91666666666667、3.054、3.148、
3.068、2.97、3.08、2.9、2.88、2.904、2.976、3.148、3.078、3、
2.888、2.914、2.774、2.708、2.59666666666667、3.008、2.976、3.152、
3.102, 2.954, 2.96, 2.895, 2.854, 2.832, 2.908, 2.886, 3.026)), 类 = &quot;data.frame&quot;, row.names = c(NA, -138L))

结果看起来像这样，我认为它并没有达到预期的那么好：

更改变量value.terms不会改善结果，并且往往会导致过度拟合。 FFT 是正确的方法吗？还是我把事情变得过于复杂了？
编辑：只是澄清一下，目标不是数据的精确再现，而是近似值，其方程可用于其他计算。在示例中，如果 30k 秒左右的峰值以及 15k 和 50k 秒左右的两个波谷稍微明显一点就足够了。]]></description>
      <guid>https://stats.stackexchange.com/questions/634929/how-do-i-approximate-a-timeseries-with-a-sum-of-sin-and-cos-functions</guid>
      <pubDate>Thu, 14 Dec 2023 17:34:01 GMT</pubDate>
    </item>
    <item>
      <title>在没有自然分组的情况下使用双重差异</title>
      <link>https://stats.stackexchange.com/questions/634921/using-difference-in-differences-with-no-natural-groupings</link>
      <description><![CDATA[我在我的组织中进行了许多分析，其中人们在没有自然分组的情况下对个人级别的数据进行双重差异。例如，研究人员研究了某种特定药物对健康结果的影响。许多人在一年中的不同时间点开始服用药物，分析对这些人进行分析，并根据同一时间段的一组协变量为每个人匹配一个对照个体，然后将治疗个体及其对照进行堆叠以便治疗期的开始时间重叠（即，一个治疗期可能在一月开始，另一个可能在六月开始，但为了分析，这两个治疗期都被视为治疗期的开始）。然后他们运行标准 2x2 DiD。
假设匹配足以处理选择问题和平行趋势，这是一个合适的方法吗？我的直觉告诉我，这会遇到一些文献中提到的交错采用的问题，但由于它们及时地重新集中了每个人，我对此并不清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/634921/using-difference-in-differences-with-no-natural-groupings</guid>
      <pubDate>Thu, 14 Dec 2023 15:53:02 GMT</pubDate>
    </item>
    <item>
      <title>取得成功的迭代次数分布</title>
      <link>https://stats.stackexchange.com/questions/634911/distribution-of-the-number-of-iterations-to-achieve-success</link>
      <description><![CDATA[设 $Z=X+jY$ （$j$ 是虚数单位），其中$X\sim\mathcal{N}(\mu,1)$ 和 $Y\sim\mathcal{N} (0,1)$.
我正在运行一个算法，每次迭代$k$都会对复数进行采样$z_k$ 紧随 $Z$ 并计算统计数据：
\begin{方程}
\xi = k\cdot \dfrac{\left|\bar{z}\right|^2}{s^2}
\end{方程}
与 $\bar{z}=\dfrac{1}{k}\sum_{i=1}^k z_i$ 和 $s^2 = \dfrac{1}{k-1}\sum_{i=1}^k \left|z_i-\bar{z}\right|^2$&lt; /p&gt;
我知道 $\xi\sim F&#39;_{2,2(k-1)}(\lambda)$ 是一个非中心 $F$ 分布，分子自由度为 $2$， $2(k-1)$ 分母自由度和与 $\lambda$ &quot;&gt;$\mu$。
当原假设 $\mu=0$ 被固定的预定义 p 值拒绝时，算法停止（获得成功）$\alpha$。
对于给定的 $\mu$ 和 $\alpha$，算法停止所需的迭代次数$k$？
到目前为止，我已经得到了一个粗略的近似值，考虑到如果算法在第 k 次迭代中获得成功，那么如果我进行第 (k+1) 次迭代，它肯定会继续获得成功，即对于大型 $\mu$ 来说确实如此，但对于较小的则不然。考虑到这一点，我发现了以下成功迭代次数的累积分布的近似值：
\begin{方程}
CDF(k) = 1-g_k(h_k^{-1}(1-\alpha))
\end{方程}
其中 $g_k$ 是 $F&#39;_{2,2(k-1)} 的累积分布(\lambda)$ 和 $h_k$ 是 $F_{2,2(k -1)}$（集中式 F 分布）。
我认为如果我发现 $P(\xi\geq\xi_{thresh}\ \text{in iteration}\ k\ |\ \xi&lt; \xi_{thresh}\ \text{对于每次迭代}\ i，其中 $\xi_{thresh}$ 是统计值这给出了所需的 p 值，但我不知道如何计算它。]]></description>
      <guid>https://stats.stackexchange.com/questions/634911/distribution-of-the-number-of-iterations-to-achieve-success</guid>
      <pubDate>Thu, 14 Dec 2023 14:34:09 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用单层感知器和 sigmoid 函数来预测不可分类的标签？ （不使用任何感知器库）</title>
      <link>https://stats.stackexchange.com/questions/634902/is-it-possible-to-predict-non-classifiable-label-using-single-layer-perceptron-a</link>
      <description><![CDATA[想象一下预测 BMI 指数（如 1、2、3、4、5）并以体重和身高作为输入。我知道用其他方法可以轻松完成。另外我必须使用 sigmoid 函数，而且我对此很陌生。我似乎找不到这个问题的答案。
据我所知，到目前为止，感知器只是线性可分的，并且 sigmoid 函数给出的值在 0 和 1 之间。我不知道如何对索引值 1,2,3,4,5 进行分类，它们是BMI指数。

没有感知器或除 numpy 和 pandas 之外的任何库
仅使用 sigmoid 函数。

导入 pandas 作为 pd
将 numpy 导入为 np


df = pd.read_csv(&#39;bmi.csv&#39;)


X = df[[&#39;身高&#39;, &#39;体重&#39;]].values
y = df[&#39;Index&#39;].values / 5.0 # 标准化目标

#
X = (X - np.mean(X, 轴=0)) / np.std(X, 轴=0)

X = np.c_[X, np.ones(X.shape[0])]


np.随机.种子(42)
权重 = np.random.uniform(低=-0.5, 高=0.5, 大小=X.shape[1])

学习率 = 0.1

迭代次数 = 10000

对于 _ 在范围内（num_iterations）：
    对于范围内的 i(X.shape[0])：
        # 前向传递
        Weighted_sum = np.dot(X[i], 权重)
        输出 = 加权和
        错误 = y[i] - 输出

        权重 += 学习率 * 误差 * X[i]

test_input = np.array([174, 96])
test_input = (test_input - np.mean(X[:, :2], axis=0)) / np.std(X[:, :2], axis=0)
test_input = np.append(test_input, 1)

Predicted_output = np.dot(test_input, 权重)
预测体重 = 预测输出 * 5.0

print(“预测体重指数：”,predicted_bmi)

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/634902/is-it-possible-to-predict-non-classifiable-label-using-single-layer-perceptron-a</guid>
      <pubDate>Thu, 14 Dec 2023 13:19:33 GMT</pubDate>
    </item>
    </channel>
</rss>