<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 20 Sep 2024 01:13:30 GMT</lastBuildDate>
    <item>
      <title>根据散点图的非线性关系</title>
      <link>https://stats.stackexchange.com/questions/654621/non-linear-relationship-according-to-scatterplot</link>
      <description><![CDATA[我在 stata 中做了线性回归，然后做了 rvfplot。然后我看到一个散点图，其中所有点都随机地在零上方和下方，但图的左侧是一条具有负斜率的实线。这看起来不像是线性关系，尽管我认为我的数据应该通过线性回归进行分析。我认为这是因为我的因变量中有一些零值，而一些自变量中也有 0 值。此外，我已经转换了变量。所以在转换之前和之后我都遇到了问题。之前，没有线，但最左边有一组点（可能又是零）。转换后，对因变量取对数，有时对自变量取 sqrt() 或 2xsqrt()，我又得到了线。在转换零值之前，我添加了 +2，以避免零值在对数之后消失。我该怎么办？
不幸的是，我不知道如何在这里上传图片。]]></description>
      <guid>https://stats.stackexchange.com/questions/654621/non-linear-relationship-according-to-scatterplot</guid>
      <pubDate>Thu, 19 Sep 2024 22:01:49 GMT</pubDate>
    </item>
    <item>
      <title>分层回归模型的预测区间</title>
      <link>https://stats.stackexchange.com/questions/654619/prediction-intervals-with-hierarchical-regression-model</link>
      <description><![CDATA[我正在阅读Gelman 和 Hill 撰写的这本数据分析书，并试图理解使用分层模型的预测。在第 273 页，他们演示了如何对已经观察到的组和状态做出新的预测

更一般地说，我们可以在估计的参数 α、β 和 σ 中添加推理不确定性。

我试图理解如何做到这一点。举个例子：
我有一个这样的分层回归模型：
\begin{aligned} &amp; Y = b_{0_j} + b_1 x + \epsilon \\
&amp; b_0 = U + \eta_j \\
\end{aligned&gt;
我将模型拟合到 5 个不同的组 j1、j2、j3、j4 和 j5
我收到的结果参数是

U = 5
$\eta_j = [1, 2, -1, 4, -3]$
b_1 = 3
epsilon 呈正态分布，方差为 2.25
组间方差为 2.25

我想使用此模型对新观察进行预测。新的观察结果在第 5 组中，x 值为 4。我相信我会通过将值代入上述公式来计算点预测，即
\begin{aligned} &amp; b_{0_5} = 5 + (-3) = 2 \\
&amp; Y = 2 + 3(4) = 14 \\
\end{aligned&gt;
我的主要问题是，如何围绕这个估计值构建 95% 的置信区间？我想我可能会加/减 1.96 * std(e)，但这不能解释组间差异。另一方面，我认为完全添加组间变异似乎是错误的，因为组 j5 ($U + \eta_5$) 的截距已经远离平均截距 U。
此外，如果模型具有不同的截距和斜率，构建区间的方法是否相同？如果有组级预测因子怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/654619/prediction-intervals-with-hierarchical-regression-model</guid>
      <pubDate>Thu, 19 Sep 2024 21:01:08 GMT</pubDate>
    </item>
    <item>
      <title>使用不相关特征进行 OLS 高估</title>
      <link>https://stats.stackexchange.com/questions/654617/overestimation-in-ols-using-uncorrelated-features</link>
      <description><![CDATA[我正在使用 OLS 构建最佳线性模型，以解释（预测）$Y$的方差，使用两个特征 $X_1$ 和 $X_2$，并考虑以下两个因素：

$X_1$ 和 $X_2$ 不表现出多重共线性，即 $\rho(X_1, X_2) \approx 0 $
$X_1$ 和 $X_2$ 均解释方差的重叠部分在$Y$中，即
$\beta_1 X_1 + \beta_2 X_2$高估了$Y$ 
其中，$\beta_1$和$\beta_2$是两个独立线性回归的结果：$Y = \beta_1 X_1 + \epsilon$和$Y = \beta_2 X_2 + \epsilon$

最好的技术是什么用什么术语来解释#2 中的上述场景？以下是否是解决这种情况的最佳方法：
步骤 1：使用 OLS 估算 $\beta_1$ $Y = \beta_1 X_1 + \epsilon$ 
步骤 2：将误差估算为 $\hat{Y_1} = Y - \beta_1 X_1$ 
步骤 3：使用 OLS 估算 $\hat{Y_1} = \beta_2 X_2 + \epsilon$ 
考虑将其推广到 $n$ 特征 $X_1, X_2, ..., X_n$
背景：
人们可以认为 $X_2$ 是 $X_1$ 的一些非线性变换，几乎没有其他信息内容可以解释 $Y$]]></description>
      <guid>https://stats.stackexchange.com/questions/654617/overestimation-in-ols-using-uncorrelated-features</guid>
      <pubDate>Thu, 19 Sep 2024 20:57:32 GMT</pubDate>
    </item>
    <item>
      <title>根据多个独立标准进行调节是否会增加共同因素的预期值？</title>
      <link>https://stats.stackexchange.com/questions/654614/does-conditioning-on-multiple-independent-criteria-increases-the-expected-value</link>
      <description><![CDATA[我正在努力解决经济学论文中的一些问题。
我有一个模型，其中 A∼N(0,1) 是工人的永久能力。ε1,ε2 ~ N(0,1) 是工人能力的“噪音”。A、ε1、ε2 是独立的。
在每个时期 (t)，如果 Ât = A+εt &gt; A*，工人就会从容易的工作晋升到困难的工作（只有两个工作）。在 t=1 时，所有工人都从事轻松的工作，这意味着：在 t=2 时，从事艰苦工作的工人是那些对他们来说：A+ε1 &gt; A*。这里出现了转折，公司可以将工人从艰苦的工作降级到轻松的工作：在 t=3 时，从事艰苦工作的工人只是那些对他们来说 (A+ε1&gt;A*)^(A+ε2&gt;A*) 的工人。看看同一批工人，我试图证明在 t=3 从事艰苦工作的工人的预期值大于在 t=3 从事艰苦工作的工人的预期值，因此：E[A|(A+ε1&gt;A*)^(A+ε2&gt;A*)] &gt; E[A|(A+ε1&gt;A*)]
这是真的吗？我遗漏了什么吗？尝试了很多次使用风险率来证明这一点，但结果却不是这样。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654614/does-conditioning-on-multiple-independent-criteria-increases-the-expected-value</guid>
      <pubDate>Thu, 19 Sep 2024 17:52:50 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中测试时间序列的平稳性（而不是单位根）</title>
      <link>https://stats.stackexchange.com/questions/654613/test-in-r-for-stationarity-not-for-unit-root-of-a-time-series</link>
      <description><![CDATA[我正在教授时间序列分析课程。我们讨论平稳性这一概念，然后我们的教科书解释了增强迪基富勒检验，该检验在 R 中由命令 adf.test() 执行。不幸的是，许多非平稳时间序列没有单位根，因此 ADF 检验将正确得出“无单位根”的结论，并让学生相信时间序列是平稳的。
上次我教授这门课程时，我使用了 kpss.test 作为替代方案，鼓励学生运行这两个测试，以检查给定时间序列可能不平稳的两种不同方式（以及绘制图表、查看可变性等）。不幸的是，许多非平稳时间序列都可以通过这两种测试，例如 AR(1) 过程 $x_t = - x_{t-1} + w_t$，其中 $w_t$ 是白噪声，或 AR(2) 过程 $x_t = -x_{t-2} + w_t$。
在网上搜索后，我了解到 Priestley-Subba Rao (PSR) 测试，该测试以前在 R 库 fractal 中可用，但现在已被弃用。
还有其他平稳性测试可以与我的学生分享，这些测试在 R 包中很容易获得吗？我不需要 Phillips–Perron pp.test，因为那只是另一个单位根测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/654613/test-in-r-for-stationarity-not-for-unit-root-of-a-time-series</guid>
      <pubDate>Thu, 19 Sep 2024 17:34:05 GMT</pubDate>
    </item>
    <item>
      <title>在原型分析和 PCA 的背景下，最小化误差与最大化方差之间的等价性</title>
      <link>https://stats.stackexchange.com/questions/654612/equivalence-between-minimizing-error-vs-maximizing-variance-in-the-context-of-a</link>
      <description><![CDATA[我试图填补 Cutler 和 Breiman 的论文原型分析中的推理空白。
本文的目的是识别数据矩阵$X$中的模式或原型$Z$，这些模式或原型最能描述底层数据。数据中的每个点$X_i$都近似为这些原型的组合。原型是通过最小化重建误差来找到的。
具体来说，我想证明最小化以下误差函数：
$$
E(\alpha, Z) = \sum_{i=1}^n \left\| x_i - Z \alpha_i \right\|^2
$$
其中：

$ X \in \mathbb{R}^{m \times n} $ 是数据矩阵
$ Z \in \mathbb{R}^{m \times p} $ 具有正交列 $ Z^\top Z = I_p$
$ \alpha \in \mathbb{R}^{n \times p}$ 是系数矩阵 $\alpha_i$ 是第 $i$ 行$\alpha $

相当于最大化：
$$
\sum \limits z_k^\top S z_k = \operatorname{tr}(Z^\top S Z)
$$
其中 $S = X^\top X$。
我目前的方法：
将 $Z$ 视为给定并从 Frobenius 范数开始，我们可以将误差函数 $ E(\alpha) $ 重写为：
$$
E(\alpha) = \left\| X - Z \alpha^\top \right\|_F^2 = \operatorname{tr} \left( (X - Z \alpha^\top)^\top (X - Z \alpha^\top) \right).
$$
扩展轨迹：
$$
E(\alpha) = \operatorname{tr}(X^\top X - X^\top Z \alpha^\top - \alpha Z^\top X + \alpha Z^\top Z \alpha^\top).
$$
由于 $ Z^\top Z = I_p $，因此简化为：
$$
E(\alpha) = \operatorname{tr}(X^\top X - 2 X^\top Z \alpha^\top + \alpha \alpha^\top)。
$$
接下来，我们对 $E(\alpha)$ 求导，相对于 $\alpha$：
$$
\frac{\partial E}{\partial \alpha} = -2 X^\top Z + 2 \alpha。
$$
将其设置为零：
$$
-2 X^\top Z + 2 \alpha = 0 \quad \Rightarrow \quad \alpha = X^\top Z。
$$
将 $\alpha = X^\top Z $ 代回 $ E(\alpha) $：
现在，将 $\alpha = X^\top Z $ 代入 $ E(\alpha) $ 的表达式中，我们得到：
$$
E(\alpha) = \operatorname{tr}(X^\top X - 2 X^\top Z (X^\top Z)^\top + (X^\top Z)(X^\top Z)^\top)。
$$
进一步简化：
$$
E(\alpha) = \operatorname{tr}(X^\top X - 2 X^\top Z Z^\top X + X^\top Z Z^\top X)。
$$
这简化为：
$$
E(\alpha) = \operatorname{tr}(X^\top X - X^\top Z Z^\top X) = \operatorname{tr}(X^\top X) - \operatorname{tr}( X^\top Z Z^\top X) = \operatorname{tr}(X^\top X) - \operatorname{tr}( Z^\top XX^\top Z),
$$
因为 $\operatorname{tr}(AB) = \operatorname{tr}(BA)$。
我的问题：
因为 $X X^\top \neq X^\top X$，所以我不确定如何从这里继续完成证明并显示最大化 $ \operatorname{tr}(Z^\top S Z) $ 的等价性，其中 $ S = X^\top X $。
有人可以指导我完成接下来的步骤吗？我如何关联这两个表达式并完成这个证明？]]></description>
      <guid>https://stats.stackexchange.com/questions/654612/equivalence-between-minimizing-error-vs-maximizing-variance-in-the-context-of-a</guid>
      <pubDate>Thu, 19 Sep 2024 17:07:22 GMT</pubDate>
    </item>
    <item>
      <title>Beta 帽条件方差 - Hansen 计量经济学</title>
      <link>https://stats.stackexchange.com/questions/654608/beta-hat-conditional-variance-hansen-econometrics</link>
      <description><![CDATA[我正在研究 Bruce Hansen 的计量经济学，我不知道如何找到第 90 页的条件方差证明。
Hansen 说：
对于任何 $n \times r$ 矩阵 $\mathbf{A} = \mathbf{A}(\mathbf{X})$：
$\text{var}(\mathbf{A}^T\mathbf{y}|\mathbf{X}) = \text{var}(\mathbf{A}^T\mathbf{e}|\mathbf{X}) = \mathbf{A}^T\mathbf{D}\mathbf{A}$，其中 $D=\text{diag}(\sigma_1^2, ..., \sigma^2_n)$。
为什么会这样？我可以看到这个步骤，但我不确定如何从完整定义中证明它：$\text{var}(\mathbf{A}^T\mathbf{e}|\mathbf{X}) = \mathbf{A}^T\text{var}(\mathbf{e}|\mathbf{X})\mathbf{A} = \mathbf{A}^T\mathbf{D}\mathbf{A}$.
即我该如何实现这个：$\text{var}(\mathbf{Z}|\mathbf{X}) = \mathbb{E}[(\mathbf{Z} - \mathbb{E}[\mathbf{Z}|\mathbf{X}])(\mathbf{Z} - \mathbb{E}[\mathbf{Z}|\mathbf{X}])^T|\mathbf{X}], \mathbf{\hat\beta} = \mathbf{A}^T\mathbf{y}, \mathbf{A} = \mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}$
我试过了，但得到的矩阵维度一直不匹配向上。]]></description>
      <guid>https://stats.stackexchange.com/questions/654608/beta-hat-conditional-variance-hansen-econometrics</guid>
      <pubDate>Thu, 19 Sep 2024 16:46:25 GMT</pubDate>
    </item>
    <item>
      <title>当每个数据点都带来一个置信区间时，如何在两个或多个组之间进行检验？</title>
      <link>https://stats.stackexchange.com/questions/654615/how-to-run-a-test-between-two-or-more-groups-when-each-data-point-brings-a-confi</link>
      <description><![CDATA[早上好，
我最近开始研究一个数据集，但作为一名应届毕业生，我的经验有限，这阻碍了我取得进展。在执行了项目所需的稀疏化之后，我现在有一个包含 24 个指标的数据框，每个指标都伴随着由随机稀疏化过程生成的置信区间。这 24 个指标属于 2 个不同的非独立组，我需要进行比较。如果没有置信区间，我只能使用均值，我会使用配对 t 检验。
为了解释通过稀疏化获得的置信区间，我尝试使用从区间得出的方差执行加权 t 检验。但是，我对我的方法没有信心，也找不到任何支持这种方法的在线文章。谢谢您的帮助。
这是我的数据框：
size1 &lt;- c(32.67256,30.59280,33.56214,30.15552,29.02073,24.92427,34.79967,34.26559,29.33457,25.75716,27.91638,33.87884)
size2 &lt;-c(34.18847,30.94369,37.38462,22.96785,27.98805,31.39834,30.26401,33.59788,36.19856,31.19667,21.27245,28.87137)
尺寸 &lt;-c(尺寸1,尺寸2)
尺寸1CI05 &lt;-c(29.50177,26.23491,29.60487,25.94388,24.48941,21.78924,29.24082,28.09738,25.20056,21.21051,24.40705,30.08490)
size2CI05 &lt;-c(29.51654,23.75201,31.29203,17.60071,21.92296,26.38236,23.69115,26.15880,26.44932,26.72620,17.48761,23.76434)
sizeCI05 &lt;-c(size1CI05,size2CI05)
size1CI95 &lt;-c(35.84336,34.95070,37.51941,34.36716,33.55205,28.05929,40.35851,40.43380,33.46857,30.30381,31.42571,37.67278) 
size2CI95 &lt;-c(38.86039,38.13538,43.47722,28.33500,34.05315,36.41432,36.83687,41.03696,45.94780,35.66713,25.05730,33.97840)
sizeCI95 &lt;-c(size1CI95,size2CI95)
group &lt;- c(c(rep(&quot;1&quot;,12),rep(&quot;2&quot;,12))
df &lt;-data.frame(size,sizeCI05,sizeCI95,group)

我还按要求添加了 dput 输出：
df &lt;-structure(list(size = c(32.67256, 30.5928, 33.56214, 30.15552, 
29.02073, 24.92427, 34.79967, 34.26559, 29.33457, 25.75716, 27.91638, 
33.87884, 34.18847, 30.94369, 37.38462, 22.96785, 27.98805, 31.39834, 
30.26401, 33.59788, 36.19856, 31.19667, 21.27245, 28.87137), 
size05CI = c(29.5017662019491, 26.2349058385758, 29.6048735822698, 
25.9438818737996, 24.4894140422372, 21.7892435074709, 29.2408246478003, 
28.097376313181, 25.2005633026381, 21.2105115402011, 24.4070457401779, 
30.0849045894848, 29.5165407340379, 23.7520071901393, 31.2920265619889, 
17.6007091843407, 21.9229562124319, 26.3823600157115, 23.6911524798744, 
26.158796800294, 26.4493176960902, 26.7262037524753, 17.4876088906701, 
23.7643440166671), size95CI = c(35.8433590913617, 34.9506991382152, 
    37.5194133001315、34.3671592174968、33.5520534941053、28.0592932279925、40.3585126169722、40.4338032764411、33.46857135214 04、30.303809204322、31.4257104335821、37.6727751129716、38.8603902871733、38.1353758799793、43.4772171945701、 28.3349990423006, 34.0531465846994, 36.4143170389483, 
36.8368654619253, 41.0369594182707, 45.9478039221974, 35.6671344715295, 
25.0572999101401, 33.9783955274194), group = c(&quot;1&quot;, &quot;1&quot;, 
&quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2&quot;, &quot;2&quot;, 
&quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;)), class = &quot;data.frame&quot;, row.names = c(NA, 
-24L))

这是我尝试做的：
install.packages(&quot;weights&quot;,dependencies=T)
library(weights)
SE1 &lt;-(size1CI95-size1CI05)/3.919928
SE2 &lt;-(size2CI95-size2CI05)/3.919928
sizepaired &lt;-size1-size2
combSE &lt;-sqrt(SE1^2+SE2^2)
weights &lt;-1/combSE^2
wtd.t.test(x=sizepaired,y=0,weight=weights)

我的方法是使用加权检验来考虑由于检验中的稀疏性而产生的置信区间（即标准偏差），其中权重来自标准偏差。但是，我不确定这是否是一种有效的方法，而且我还没有找到任何涉及这种方法的科学文章。我的同事有些怀疑，不愿意使用“实验性”方法。
此外，我目前正在使用参数检验，但在我的数据中（我没有在这里包括），有些数据不遵循正态分布。因此，我应该考虑如何进行加权配对非参数检验]]></description>
      <guid>https://stats.stackexchange.com/questions/654615/how-to-run-a-test-between-two-or-more-groups-when-each-data-point-brings-a-confi</guid>
      <pubDate>Thu, 19 Sep 2024 16:36:06 GMT</pubDate>
    </item>
    <item>
      <title>转换变量时的测量尺度逻辑（名义、序数等）</title>
      <link>https://stats.stackexchange.com/questions/654604/logic-of-scales-of-measurement-nominal-ordinal-etc-when-transforming-variab</link>
      <description><![CDATA[经常讨论的测量尺度如下：

名义：无序的定性类别
序数：有序但值之间没有有意义的距离
间隔：值之间的有序和有意义的距离
比率：有序、有意义的距离和真正的零

当对原始变量进行转换时，我对测量尺度的逻辑感到好奇。
例如

收入（比率） -&gt; 自然对数 -&gt; 对数（收入）比率？没有真正的零，距离的值会发生变化
身高（比率） -&gt; 标准化为平均值为零且标准差为 1 -&gt; Z 分数高度（间隔？）零代表平均值。

我们是否将测量尺度的逻辑应用于转换后的变量，并在相关时重新分类？]]></description>
      <guid>https://stats.stackexchange.com/questions/654604/logic-of-scales-of-measurement-nominal-ordinal-etc-when-transforming-variab</guid>
      <pubDate>Thu, 19 Sep 2024 15:33:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么如果我将样本分为尾部和主体，子样本相关性会发生变化，即使整个样本分布是双变量高斯分布？</title>
      <link>https://stats.stackexchange.com/questions/654589/why-subsample-correlations-change-if-i-partition-the-sample-in-tails-and-body-ev</link>
      <description><![CDATA[我通过蒙特卡罗模拟生成了一个数据样本，其中底层分布是“双变量正态”，相关系数为 0.5，两个系列的平均值均为 0%，两个系列的标准差均为 20%。
随后，我根据第一个变量的值将数据集划分为三个子样本：左尾（第一四分位数）、右尾（第四四分位数）和分布主体（第二和第三四分位数）。
为什么这两个系列之间的相关系数在这三个子样本中会发生变化，为什么它与 0.5（数据从中划分出来的原始分布的值）不同？我想从数学和直观的角度来理解它。]]></description>
      <guid>https://stats.stackexchange.com/questions/654589/why-subsample-correlations-change-if-i-partition-the-sample-in-tails-and-body-ev</guid>
      <pubDate>Thu, 19 Sep 2024 08:44:29 GMT</pubDate>
    </item>
    <item>
      <title>关于离散时间生存分析的修改问题（固定间隔，固定效应时间）</title>
      <link>https://stats.stackexchange.com/questions/654562/a-modified-question-about-discrete-time-survival-analysis-with-fixed-intervals</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654562/a-modified-question-about-discrete-time-survival-analysis-with-fixed-intervals</guid>
      <pubDate>Wed, 18 Sep 2024 18:54:52 GMT</pubDate>
    </item>
    <item>
      <title>关于双变量分布的估计</title>
      <link>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</link>
      <description><![CDATA[我正在处理一个具有累积分布函数$F(x, y)$的非负、绝对连续的双变量随机向量，并且我正在尝试使用 Epanechnikov 核来估计$$\int_0^{t_1}F^2(x_1,t_2)dx_1$$。对此的估计定义为
$$\widehat{I}=\frac{1}{n^2h_1^2h_2^2}\int_0^{t_1}\left(\sum_{i=1}^n K\left(\frac{x_1-X_{1i}}{h_1}\right)K\left(\frac{t_2-X_{2i}}{h_2}\right)\right)^2dx_1$$
我在模拟中使用双变量Gumbel分布。下面是我的代码，但我很难为双变量数据选择合适的带宽，而且我得到的估计值与真实值有显著差异。
library(stats)
library(ks)
n &lt;- 40
lambda1 = 2
lambda2 = 0.5
theta = 0.5

for (i in 1:100) {
X1 &lt;- rexp(n, lambda1)
X2 = rgamma(n, (runif(n) &gt; 1 - theta/(1 + lambda1 * theta)) + 1, lambda2 * (1 + lambda1 * theta * X1))
sigma1 &lt;- sd(X1)
sigma2 &lt;- sd(X2)
h1 &lt;- 0.5
h2 &lt;- 0.55
t1 &lt;- 0.2
t2 &lt;- 0.3

epan_kernel_cdf &lt;- function(u) {
0.25 * (3 * u - u^3)
}

积分1 &lt;- sapply(X1, function(Xi) h1 * epan_kernel_cdf((t1 - Xi) / h1))
积分2 &lt;- sapply(X2, function(Yi) h2 * epan_kernel_cdf((t2 - Yi) / h2))

被积函数 &lt;- function(x1) {
kernel_cdf_values &lt;- sapply(X1, function(X1) epan_kernel_cdf((x1 - X1) / h1))
prod_kernel &lt;- kernel_cdf_values * 积分 2
sum_kernel &lt;- sum(prod_kernel)
(sum_kernel)^2
}

x_vals &lt;-seq(0,t1,length.out = 10000)
dx &lt;-x_vals[2]-x_vals[1]
sum_approx &lt;-sum(sapply(x_vals,integrand))*dx
estimated_value &lt;-(1/(n^2*h1^2*h2^2))*sum_approx
true_value &lt;-0.98

bias[i] &lt;-estimated_value[1]-true_value
MSE[i] &lt;-mean((estimated_value[1]-true_value[1])^2)
}

bias
MSE
bias1 &lt;-mean(bias)
bias1
MSE1 &lt;- 平均值 (MSE)
MSE1

我面临的一些具体问题：

为我的双变量数据选择合适的带宽。
我的估计值与真实值 (0.98) 相差甚远。

如果您能提供任何关于如何改进带宽选择或我应该在代码中进行的其他调整的见解或建议，我将不胜感激。提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</guid>
      <pubDate>Tue, 17 Sep 2024 16:55:15 GMT</pubDate>
    </item>
    <item>
      <title>对零假设下 p 值的均匀分布感到困惑</title>
      <link>https://stats.stackexchange.com/questions/654484/confused-about-the-uniform-distribution-of-p-values-under-the-null-hypothesis</link>
      <description><![CDATA[我目前正在学习一门生物信息学入门课程，我对零假设下（当零假设为真时）p 值的均匀分布感到困惑。
已经广泛证明和讨论过，在正确的条件下，当零假设成立时，p 值是均匀分布的，正如这篇文章所解释的那样：为什么 p 值在零假设下是均匀分布的？。
我的困惑更多的是关于这个想法背后的直觉和实际意义。
例如，让我们考虑一个简单的（尽管是离散的）场景：抛硬币。如果掷出正面的概率（表示为&quot;1&quot;）为 $p = 0.3$，且我们进行 $1000$ 次抛掷，我们预计大多数情况下掷出正面的次数约为 $300$ 次。因此，我们预计在大多数情况下 p 值将在 $P(X &lt; 300)$ 左右（左尾 p 值，其中 $X$ 是二项式（$1000$，$p$）变量）。
但是，这似乎与 p 值在零假设下应均匀分布的想法相矛盾。如果 p 值是均匀的，那么所有 p 值是否都应该具有同等可能性，而不是聚集在某个值附近？
有人可以解释为什么这个均匀分布在这个例子中仍然成立，或者我是否误解了一些基本的东西？
我已运行以下模拟作为示例：
library(ggplot2)

n_experiments &lt;- 100000 # 实验次数（抛硬币）
n_trials &lt;- 100000 # 每个实验的试验次数
p &lt;- 0.3 # 获得“1”（成功）的概率

# 模拟实验
set.seed(123) # 为了可重复性
results &lt;- rbinom(n_experiments, n_trials, p) # 每个实验中 1 的数量

# 计算每个实验的 p 值
p_values &lt;- sapply(results, function(x) pbinom(x, n_trials, p))

# 创建用于绘图的数据框
df &lt;- data.frame(Experiment = 1:n_experiments, 
Number_of_1s = results, 
p_value = p_values)

# 绘制“1”的数量直方图
ggplot(df, aes(x = Number_of_1s)) +
geom_histogram(binwidth = 1, fill = &#39;skyblue&#39;, color = &#39;black&#39;) +
labs(title = &quot;100 次实验中 1 的数量直方图&quot;, 
x = &quot;1 的数量&quot;, 
y = &quot;频率&quot;) +
theme_minimal()

# 绘制 p 值的直方图
ggplot(df, aes(x = p_value)) +
geom_histogram(binwidth = 0.01, fill = &#39;coral&#39;, color = &#39;black&#39;) +
labs(title = &quot;100 次实验中的 p 值直方图&quot;, 
x = &quot;p 值&quot;, 
y = &quot;频率&quot;) +
theme_minimal()

我发现以下预期结果对我来说感觉矛盾，值的分布不均匀，但 p 值的分布是均匀的。

]]></description>
      <guid>https://stats.stackexchange.com/questions/654484/confused-about-the-uniform-distribution-of-p-values-under-the-null-hypothesis</guid>
      <pubDate>Tue, 17 Sep 2024 13:24:56 GMT</pubDate>
    </item>
    <item>
      <title>R 中混合效应模型 (lme) 的 III 型方差分析对比</title>
      <link>https://stats.stackexchange.com/questions/654447/contrasts-for-type-iii-anova-on-mixed-effects-model-lme-in-r</link>
      <description><![CDATA[我正在使用 R 中的 nlme 运行一系列混合效应模型。这是我的最终模型的示例：
M1.Final &lt;- lme(Response ~Treatment * Species, random = ~1|ID, 
data = data, method=&quot;REML&quot;)

我运行了初始 II 型方差分析来解释不平衡设计（每个处理的范围为 9-25 个样本），并得到了以下结果：
Anova(M1.Final, type = 2)

Chisq Df Pr(&gt;Chisq) 
Treatment 152.1071 4 &lt; 2.2e-16 ***
物种 1.9636 1 0.161130 
治疗：物种 15.2138 4 0.004278 ** 

由于治疗：物种相互作用显著，我认为 III 型方差分析比 II 型方差分析更合理。我知道要运行 III 型方差分析，您必须更改模型的对比度。我想检查并确保我做得正确。只在 ANOVA 命令中更改对比度可以吗，还是我需要在 lme 命令中更改它？即这是否正确：
type3 &lt;- list(Treatment = contr.sum, Species = contr.sum)

Final_Anova &lt;- Anova(M1.Final,contras = type3,type=3)
print(Final_Anova)

Chisq Df Pr(&gt;Chisq) 
(截距) 106.6099 1 &lt; 2.2e-16 ***
Treatment 151.0898 4 &lt; 2.2e-16 ***
物种 0.0406 1 0.840396 
治疗：物种 15.2138 4 0.004278 ** 


这是交互图：

更新：听起来你应该在 lme 中指定对比。我试过了，但输出结果很怪异，所以我不确定我做错了什么：
test &lt;- lme(Response ~Treatment * Species, random = ~1|ID, 
data = data, method=&quot;REML&quot;,contras = type3)
Anova(test, type = 3)

(Intercept) 1575.8 1 &lt; 2.2e-16 ***
Treatment 0 
Species 0 
Treatment:Species 0 


编辑：听起来，如果存在显著的相互作用，则 III 型不一定是必要的。如果能提供关于如何在这种情况下选择 ANOVA 类型的见解，我们将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654447/contrasts-for-type-iii-anova-on-mixed-effects-model-lme-in-r</guid>
      <pubDate>Mon, 16 Sep 2024 17:45:12 GMT</pubDate>
    </item>
    <item>
      <title>如何使用核技巧在 SVM 中拟合数据？</title>
      <link>https://stats.stackexchange.com/questions/645752/how-does-fitting-data-work-in-svm-using-the-kernel-trick</link>
      <description><![CDATA[在 SVM 中，我了解如何将一些数据转换为更高维度后对其进行拟合。 （例如：$(X_1, X_2) \to (X_1, X_2, X_1^2, X_2^2, X_1X_2)$，这是 2 维到 5 维的转换）。
为了拟合这些数据，我们将最大化 $M$，并满足 $\sum_{j=1}^p B_j^2 = 1$，使得 $y_i(B_0 + B_1x_{i1} + ... + B_px_{ip}) \geq M(1-e_i)$，其中 $e_i \geq 0$，$\sum_{i=1}^n e_i \leq C$ 且 $p$ 是更高维度。
然而，使用核技巧，我们完全跳过了将数据实际映射到更高维度的步骤，而只是查看 $n \choose 2$ 个数据点之间的关系。在这种情况下，我不明白如何拟合训练数据，因为我们只看到它们成对的点积关系。
更具体地说，如果我们不知道更高维度中 $y_i, x_{i1}, ... x_{ip}$ 的值，我们将如何计算此示例中的 $y_i(B_0 + B_1x_{i1} + ... + B_px_{ip})$？]]></description>
      <guid>https://stats.stackexchange.com/questions/645752/how-does-fitting-data-work-in-svm-using-the-kernel-trick</guid>
      <pubDate>Wed, 24 Apr 2024 17:32:08 GMT</pubDate>
    </item>
    </channel>
</rss>