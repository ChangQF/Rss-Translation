<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 08 Apr 2024 03:15:21 GMT</lastBuildDate>
    <item>
      <title>使用 Gamma 分布与变换响应来评估 GLM 以预测右偏价格数据</title>
      <link>https://stats.stackexchange.com/questions/644532/evaluating-glm-with-gamma-distribution-vs-transformed-response-for-predicting-r</link>
      <description><![CDATA[我正在尝试使用具有以下变量的数据集来预测房价：
&#39;data.frame&#39;：9800 obs。 6 个变量：
$ 浴室 : 编号 1 1 1 1 1 1 1 1 1 1 ...
$ 卧室 : 数量 0 0 0 0 0 1 1 1 1 1 ...
$ pets_allowed: 因子 w/ 4 个级别“猫”、“猫、狗”,..: 4 4 4 4 4 2 2 4 4 4 ...
$ 价格：整数 1390 925 2475 1495 1695 1560 1560 1000 950 625 ...
$ 平方英尺：整数 107 116 130 138 190 200 200 200 200 200 ...
$ 区域：因子包含 4 个级别“中西部”、“东北”、...： 3 4 2 4 4 3 3 3 4 3 ...

价格变量是右偏的，所以我首先尝试用 Gamma 分布和日志链接拟合 GLM：
model2 &lt;- glm(价格 ~ 浴室 + square_feet + 地区，数据 = 美国，家庭 = Gamma(link = &#39;log&#39;))

在执行前向、后向和最佳子集选择之后，我最终将浴室、square_feet 和区域作为预测变量。
模型摘要看起来很合理，所有预测变量都非常显着。方差膨胀因子也全部&lt;0。 5、表明不存在重大多重共线性问题：
我的主要问题是：这个具有 Gamma 分布的 GLM 看起来是否非常适合基于模型摘要和 VIF 值的数据？
&lt;前&gt;&lt;代码&gt;调用：
glm(公式 = 价格 ~ 浴室 + square_feet + 区域, 家庭 = Gamma(link = &quot;log&quot;),
    数据=美国）

系数：
                 估计标准。误差t值Pr(&gt;|t|)
(截距) 6.549e+00 1.147e-02 571.209＜ 2e-16 ***
浴室 1.234e-01 1.041e-02 11.859 &lt; 2e-16 ***
平方英尺 3.366e-04 1.238e-05 27.197 &lt; 2e-16 ***
地区东北 4.456e-01 1.438e-02 30.982 &lt; 2e-16 ***
南部地区 6.763e-02 9.914e-03 6.822 9.52e-12 ***
西部地区 5.058e-01 1.109e-02 45.606 &lt; 2e-16 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（Gamma 系列的色散参数为 0.1441117）

    零偏差：9799 个自由度上为 2300.3
残余偏差：9794 个自由度上为 1215.2
工商局：148140

Fisher 评分迭代次数：4


]]></description>
      <guid>https://stats.stackexchange.com/questions/644532/evaluating-glm-with-gamma-distribution-vs-transformed-response-for-predicting-r</guid>
      <pubDate>Mon, 08 Apr 2024 00:22:13 GMT</pubDate>
    </item>
    <item>
      <title>如何从贝叶斯回归中后验预测分布的定义导出条件后验预测分布？</title>
      <link>https://stats.stackexchange.com/questions/644530/how-to-derive-conditional-posterior-predictive-distribution-from-definition-of-p</link>
      <description><![CDATA[就我而言，我有一组数据点：
$$ z_{0:n} = \\{ (x_0, y_0),\dots ,(x_{n-1}, y_{n-1}) \ \} $$
我正在尝试找出如何导出条件后验预测分布的完全扩展形式：
$$p(y|x, \mathcal{z}_{0:n})$$
根据后验预测分布的定义$(z=(x,y))$：
$$p(z|z_{0:n}) = \int p(z | \theta)p(\theta|z_{0:n}) d\ θ$$
哪里
$$p(\theta|z_{0:n}) = \frac{p(z_{0:n}|\theta)p(\theta)}{ p(z_{0:n})}$$
和
$$p(z_{0:n}) = \int p(z_{0:n}|\theta)p(\theta) d\theta$$&lt; /span&gt;.
这只是贝叶斯法则的重复应用吗？因为我不知道如何“拆分” $x_{0:n}$ 因此它位于条件概率条的另一侧，而 $y_{0:n }$ 仍然存在。]]></description>
      <guid>https://stats.stackexchange.com/questions/644530/how-to-derive-conditional-posterior-predictive-distribution-from-definition-of-p</guid>
      <pubDate>Sun, 07 Apr 2024 22:59:56 GMT</pubDate>
    </item>
    <item>
      <title>对二元因变量和三个自变量使用哪种统计检验？</title>
      <link>https://stats.stackexchange.com/questions/644525/which-statistical-test-to-use-with-binary-dependent-variable-and-three-independe</link>
      <description><![CDATA[我有一个数据集，其中包含一个二元因变量（成功/失败）和三个分类自变量（地理方面、时间方面和参与者类型，所有这些都包含多个“级别”/组）。我想分析与其他组相比，哪些参与者组的成功率最高，但也要考虑地理和时间因素。我运行了二项式逻辑回归分析，但我不确定这是否真的适合该数据集，因为我没有适当的对照组来设置基线，并且每个变量中也有如此多的类别/组使得解释有点混乱。放弃这一点将使我可以选择分别为每个自变量运行卡方检验的同质性，但我不喜欢这种方法，因为我不确定这是否会带来多重比较的问题？
对此有什么想法或建议吗？是否有任何测试（例如阶乘方差分析）适合具有二元因变量的多变量分类数据？例如，PERMANOVA 在这种情况下会起作用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644525/which-statistical-test-to-use-with-binary-dependent-variable-and-three-independe</guid>
      <pubDate>Sun, 07 Apr 2024 21:13:58 GMT</pubDate>
    </item>
    <item>
      <title>因果中介分析，治疗在结果阶段平滑，在中介阶段线性</title>
      <link>https://stats.stackexchange.com/questions/644523/causal-mediation-analysis-with-treatment-smoothed-in-the-outcome-stage-and-linea</link>
      <description><![CDATA[我正在考虑在 r 中进行如下所示的中介分析：
m_1 &lt;- gam(mediator1 ~age_cat + s(treat, k = 50, bs = &quot;cr&quot;) +
            cov1 + cov2 + cov3 + cov4 + 年份，数据 = mediation_df，
            方法=“REML”）

y_1 &lt;- gam(dem_important ~age_cat + mediator1 +
            s（治疗，k = 50，bs =“cr”）+ cov1 + cov2 + cov3 + cov4 +
            年，数据 = mediation_df，方法 =“REML”）

结果1 &lt;- 中介(m_1, y_1, sims = 1000, boot = TRUE,
            治疗=“治疗”，调解员=“调解员1”）



其中，m_1 是中介模型，y_1 是结果模型，mediator1 是连续变量，age_cat 是一个分类变量，treat 是一个用平滑建模的因子变量，cov1、cov2、cov3 、cov4 都是虚拟变量，year 是因子变量。
我现在正在考虑中介模型不同的模型规范：
m_2 &lt;- lm(mediator1 ~age_cat + treat +
            cov1 + cov2 + cov3 + cov4 + 年份，数据 = mediation_df，
            方法=“REML”）

y_2 &lt;- gam(dem_important ~age_cat + mediator1 +
            s（治疗，k = 50，bs =“cr”）+ cov1 + cov2 + cov3 + cov4 +
            年，数据 = mediation_df，方法 =“REML”）

结果2 &lt;- 中介(m_2, y_2, sims = 1000, boot = TRUE,
            治疗=“治疗”，调解员=“调解员1”）


在此模型设置中，出于中介目的，我没有对治疗变量进行平滑处理，因为我没有假设因子变量 treat 对中介变量具有平滑效果。
我想知道这个模型规范是否有意义。我见过一些调解案例，其中调解模型是线性的，结果模型是 GAM (今井等人）。然而，我还没有看到治疗变量本身是两个模型设置之间采用不同形式的变量的设置。
是否有研究做到了这一点？这种方法到底合法吗？必须做出什么样的假设才能建立这样的因果中介分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/644523/causal-mediation-analysis-with-treatment-smoothed-in-the-outcome-stage-and-linea</guid>
      <pubDate>Sun, 07 Apr 2024 20:09:23 GMT</pubDate>
    </item>
    <item>
      <title>校正自相关后，回归量在统计上变得微不足道</title>
      <link>https://stats.stackexchange.com/questions/644521/regressors-became-statistically-insignificant-upon-correcting-for-autocorrelatio</link>
      <description><![CDATA[我正在使用 Stata 并使用回归命令并收到 $p$ 值，表明回归量具有统计显着性。
但是，在绘制残差后，我注意到明显存在自相关性（这一点已通过布劳施-戈弗雷检验得到证实）。然后我使用 prais ..., corc 命令来纠正它，但得到的结果是现在我的回归量在统计上微不足道。
这是什么意思？我的回归没用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644521/regressors-became-statistically-insignificant-upon-correcting-for-autocorrelatio</guid>
      <pubDate>Sun, 07 Apr 2024 19:02:04 GMT</pubDate>
    </item>
    <item>
      <title>Casella 和 Berger 中估计量的方差</title>
      <link>https://stats.stackexchange.com/questions/644513/variance-of-estimator-in-casella-and-berger</link>
      <description><![CDATA[嗨，我正在尝试阅读卡塞拉和伯杰的作品。
在第 345 页的示例 7.3.21 中，他们考虑分布族 Uniform($\theta$, $\ theta +1$）并提出基于单个观察的 theta 估计量。他们声称很容易看出估计器 $X - \frac12 + \sin(2\pi X) / (2\pi)$ 的方差为 0.71 (重点是，这小于明显估计量的方差 $X- \frac12$)。
但是，当我进行计算时，我似乎无法得到这一点。
\begin{align}
Var_\theta(X - \frac12 + \sin(2\pi X) / (2\pi))
&amp;= \int_\theta^{\theta+1} (x - \frac12 + \sin(2\pi x) / (2\pi) -\theta)^2 dx \\
&amp;= (3 + 2 π^2 - 12 \cos(2 π \theta))/(24 π^2) \\
&amp;\大约 0.0959985 - 0.0506606 \cos(2\pi \theta)
\end{对齐}
我错过了一些非常简单的事情吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644513/variance-of-estimator-in-casella-and-berger</guid>
      <pubDate>Sun, 07 Apr 2024 17:25:01 GMT</pubDate>
    </item>
    <item>
      <title>因变量应接受多小的变异系数？它如何影响线性回归？</title>
      <link>https://stats.stackexchange.com/questions/644510/how-small-coefficient-of-variation-should-be-accepted-for-dependent-variable-and</link>
      <description><![CDATA[我想知道如果 $Y$ 变量的变异系数很小，线性回归模型会发生什么。另外，什么被认为是“简历太小”？最低接受阈值是多少？
更具体的上下文：我正在尝试对时间序列数据建立线性回归以用于学习目的。与天气相关的 10 个数值变量有 499 个测量值 (来源）。下面附有图表和数字摘要。
数字汇总表

所用时间序列图
归一化，即 $\frac{X- \operatorname{mean}(X)}{\operatorname{sd}(X)}$
]]></description>
      <guid>https://stats.stackexchange.com/questions/644510/how-small-coefficient-of-variation-should-be-accepted-for-dependent-variable-and</guid>
      <pubDate>Sun, 07 Apr 2024 16:39:39 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯观点中的“数据是固定的”和频率论观点中的“数据是随机的”在数学上谈论的是同一件事吗？</title>
      <link>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</link>
      <description><![CDATA[在我看来，在贝叶斯推理和频率推理中，观测数据$x$被建模为随机变量的观测值$X$ 遵循一定的概率分布。因此，当我遇到这两个语句时 - “数据已固定”从贝叶斯观点来看，“数据是随机的”。从频率论的角度来看，我发现它们很难理解，因为它似乎表明对数据概念的解释存在差异。
读了一些资料后，似乎“数据是固定的”是指观察到的数据$x$是固定的，“数据是随机的”是指随机变量&lt; span class=&quot;math-container&quot;&gt;$X$ 是随机的。这两个陈述中的“数据”所指的并不是同一件事。不确定我的解释是否正确。欢迎您的建议。如果我的解释是正确的，那么这两个陈述是否多余/令人困惑？
编辑
两种说法的参考：-

什么“参数是固定的，数据是变化的”吗？用频率论者的术语来说，“参数变化而数据固定”。用贝叶斯术语到底是什么意思？
https://dataalltheway.com/posts /015-00-frequentist-vs-bayesian-statistics/index.html
https://youtu.be/EJe3jiZNwUU?t=1130
]]></description>
      <guid>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</guid>
      <pubDate>Sun, 07 Apr 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>使用回归似然从回归中复制 t 或 F 检验</title>
      <link>https://stats.stackexchange.com/questions/644482/replicate-t-or-f-test-from-regression-using-regression-likelihoods</link>
      <description><![CDATA[我听说我们用来获取回归结果显着性的 t 检验和 F 检验是从似然比检验得出的，但我在复制 t/F 的 p 值时遇到了麻烦对回归似然进行似然比检验的检验
使用底部的数据集，
在 R 中运行这三个回归：
withCov&lt;-lm(Y~X)
logLik(withCov) # &#39;log Lik。&#39; -61.98043（df=3）
与Int&lt;-lm(Y~1)
logLik(withInt) # &#39;log Lik.&#39; -63.18456（df=2）
有无&lt;-lm(Y~0)
logLik(withNone) # &#39;log Lik.&#39; -65.32909（df=1）

例如，当我对 beta_1 的显着性进行似然比检验时，我得到
1-pchisq(2*(logLik(withCov)-logLik(withInt)),df = 1)
# 0.1206958
＃ 相比于
摘要（withCov）
称呼：
lm(公式 = Y ~ X)

残差：
     最小 1Q 中值 3Q 最大
-1.98508 -0.44415 -0.02294 0.59907 1.66593

系数：
            估计标准。误差t值Pr(&gt;|t|)
（截距）-0.2568 0.1206 -2.129 0.0384 *
X -0.2045 0.1329 -1.53​​9 0.1304
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残余标准误差：48 自由度上为 0.8531
多重 R 平方：0.04702，调整 R 平方：0.02717
F 统计量：1 和 48 DF 上为 2.369，p 值：0.1304

虽然值很接近，但 0.1304 显然与 0.1206958 不同。
对于似然比检验的所有 6 种组合，我无法从 lm 恢复任何 p 值。
我做错了什么？谢谢！
下面的 R 代码设置 X 和 Y 变量：
&lt;预&gt;&lt;代码&gt;X&lt;-c(0.147462983739098,-0.552822250273655,0.0791413008277721,1.64705442993914,0.68248797132517,-0.315633973636888,1. 40047872456033,0.776033233883272,-0.343689753439294,-0.526351059575156,0.275611183793461,1.7751174954305,-0.932913434395753,0 .163895795533468,-1.00807323166609,-0.434797856886559, 0.112072003876197,-0.319445372479459,1.6989373340732,0.639738727242407,0.02980494131095,0.564230726111237,1.61191604859755, -0.474733281647485,-1.46213462226689,-1.33823497263023,0.0771907623203949,-0.698998017227839,-0.775816444324552,1.46468840793 603,-0.0940659257837727,-1.85718512842644,0.109762500597346,0.293088069440979,-1.33774986808507,0.804321505460817,1.246387803 51287 ,-1.66909878637454,-0.107871283787089,-0.286526054190293,-1.30268476505327,0.241186917275982,0.0941940655245403,0.426156461 908492,-0.951908401332523,-0.782389908678191,0.436387212517629,0.491981905432585,0.863964246361868,-0.715853080383197)
Y＜-c(0.123592053622774，-0.156626343170975，-1.00704515111936，-0.333485064105835，0.539121555715671，0.0827543989201612，-1.381 38102448818,-0.510996824863877,1.40679987755037,-0.289587787513398,-1.00983646108717,0.20397559183913,-1.53​​795623798144,-0.37 4138120013244,0.753381985793875,-0.195106670583694,-0.395410227522805, 0.314058948313302,-0.567075906102368,-0.823999734395967,0.334195737940288,-0.382748868492066,-1.1924589353617,-2.1447830778 6596,0.198528331051895,0.616636192164357,-1.66623239116232,0.906880778089087,0.663909698659448,-0.96026161021686,-0.028951352 9973109,0.103477089026045,-0.517840007699842,-1.42770065687853,-1.18735568345121,0.441872906307648,- 0.814014579874374,-0.96658546843308,0.474244931448731,-0.975319336891573,-0.0672523439350411,-0.743286641930158,0.788159757 412595,1.23723123779866,-0.508581741865352,0.220065470600985,0.822051420773978,-0.383737198032438,-2.04890944754108,1.5555393 999865)
]]></description>
      <guid>https://stats.stackexchange.com/questions/644482/replicate-t-or-f-test-from-regression-using-regression-likelihoods</guid>
      <pubDate>Sun, 07 Apr 2024 01:59:46 GMT</pubDate>
    </item>
    <item>
      <title>解释流行病学模型的泊松 GAM</title>
      <link>https://stats.stackexchange.com/questions/644475/interpreting-poisson-gam-for-epidemiological-model</link>
      <description><![CDATA[我正在开展一个项目，调查 PM2.5（一种污染形式）与缺血性中风住院治疗（即每天收集的住院总人数）之间的关系。我的模型如下所示，结果图也是如此：
&lt;前&gt;&lt;代码&gt;库(mgcv)
gam_model &lt;- gam(行程 ~ s(PM2.5) +
        因素（地区）+
        ns(日期, df= 7) +
        偏移量（日志（人口）），
                 数据=区域数据，
                 家庭=泊松（链接=“日志”））

绘图（gam_model，trans = exp，xlab =“PM2.5”，ylab =“相对风险”，rug = TRUE）


因为我想根据相对风险（相对于零基线 PM2.5 水平）来解释模型，所以我设置了 trans = exp。然而，我不明白如何解释结果，该结果表明，PM2.5 时，因缺血性中风住院的相对风险较低 $\approx 20$ 比 0 低。我犯错了吗？
如果这是一个愚蠢的问题，我很抱歉，我对这一切都很陌生。]]></description>
      <guid>https://stats.stackexchange.com/questions/644475/interpreting-poisson-gam-for-epidemiological-model</guid>
      <pubDate>Sat, 06 Apr 2024 22:31:38 GMT</pubDate>
    </item>
    <item>
      <title>降维和预先计算的距离矩阵</title>
      <link>https://stats.stackexchange.com/questions/644469/dimensionality-reduction-and-precomputed-distance-matrix</link>
      <description><![CDATA[我有一个关于降维的问题。我想了解 MDS 和 t-SNE 等方法是如何工作的。特别是，我想了解预先计算距离矩阵与不预先计算距离矩阵时的差异。
为了尝试理解它，我从 MNIST 数据集中获取了 10 张图像，并为每张图像创建了 10 个副本，并将它们全部放在一个文件夹中（总共 100 张图像）。然后我使用所有这些图像之间的修改豪斯多夫距离创建了一个距离矩阵。最后，我使用 sklearn.manifold 中提供的 TSNE 和 MDS 函数将它们投影到 2D 空间中。我运行了这两个函数两次，一次使用指定的预先计算的距离矩阵 (metric=&#39;precompulated&#39;)，一次使用默认值。
所以，我有 10 张图像，每张图像重复 10 次。我期望在 t-SNE 和 MDS 空间中看到由 10 个点（每个图像重复 10 次）组成的 10 个点（每个不同的 MNIST 图像一个）彼此重叠，因为距离是重复的。只有当我没有将指标指定为“预先计算”时，我才会看到这一点，而在我看到分散的其他情况下，我不会看到这一点。
为什么会发生这种情况？不知道有没有文章讲这个。如果您能帮助我解决这个问题，我将非常感激。
编辑：
抱歉缺少信息，我对此类帖子很菜鸟：C
这是 100 张图像之间的距离矩阵的热图：

正如您所看到的，由于图像的重复，它的尺寸为 100x100，并且具有 10 个完全相同值的清晰块。
我使用名为 distance_matrix 的矩阵来计算 t-SNE 和 MDS 的降维。以下是 t-SNE 案例的代码，适用于预计算指标和默认指标：
# t-SNE 参数
随机状态 = 10
n_iter = 50000
困惑度 = 4
早期夸张 = 1

# 对数据应用 t-SNE 进行降维

# tsne = TSNE(n_components=2, random_state=random_state, n_iter = n_iter, perplexity = perplexity, Early_exaggeration=early_exaggeration)

tsne = TSNE(n_components=2, random_state=random_state, n_iter = n_iter, perplexity = perplexity, Early_exaggeration=early_exaggeration, metric=&#39;预计算&#39;, init=&#39;随机&#39;)


X_tsne = tsne.fit_transform(distance_matrix)

图, ax1 = plt.subplots(1, 1, Figsize=(13,5))
cmap = plt.get_cmap(&#39;tab10&#39;)

# 散点图，颜色代表时间进展

sc = ax1.scatter(X_tsne[:,0]，X_tsne[:,1]，marker=&#39;.&#39;，s=50，c=np.arange(len(X_tsne))，edgecolors=&#39;黑色&#39;，线宽= 0.2, cmap=&#39;彩虹&#39;)

ax1.set_xlabel(&#39;t-SNE 暗淡 1&#39;)
ax1.set_ylabel(&#39;t-SNE 暗淡 2&#39;)
Fig.colorbar(sc, label=&#39;时间进程&#39;)

# 显示图
plt.tight_layout()
plt.show()

这给出了以下输出：

对于预先计算：

默认情况下：


如您所见，两个结果相似但不相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/644469/dimensionality-reduction-and-precomputed-distance-matrix</guid>
      <pubDate>Sat, 06 Apr 2024 20:30:17 GMT</pubDate>
    </item>
    <item>
      <title>中心极限定理是关于多个样本还是只关于一个样本？</title>
      <link>https://stats.stackexchange.com/questions/644441/is-central-limit-theorem-about-multiple-samples-or-just-one</link>
      <description><![CDATA[我研究过 CLT，我的理解是多个样本将生成以总体平均值为中心的正态分布。然而，今天，Linkedin 上的一篇帖子称“CLT 表示足够大的样本具有与总体相同的特征”。准确吗？看来不是。帖子的作者是否犯了任何错误，或者我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644441/is-central-limit-theorem-about-multiple-samples-or-just-one</guid>
      <pubDate>Sat, 06 Apr 2024 11:45:33 GMT</pubDate>
    </item>
    <item>
      <title>硬币翻转游戏：HH 与 HT 的一系列翻转</title>
      <link>https://stats.stackexchange.com/questions/643092/coin-flip-game-hh-vs-ht-in-a-sequence-of-flips</link>
      <description><![CDATA[一个涉及翻转公平的有趣思想实验正在X/Twitter：
&lt;块引用&gt;
抛一枚均匀的硬币 100 次——得到一系列正面 (H) 和反面的序列
（T）。对于翻转序列中的每个 HH，Alice 都会得到一分；为了
每个 HT，Bob 都会这样做，所以例如对于序列 THHHT Alice 得到 2 分
鲍勃得 1 分。谁最有可能获胜？

答案是鲍勃更有可能获胜，这似乎违反直觉。我当然可以暴力破解这个问题来证明“鲍勃”是正确的答案——它似乎确实与鲍勃的方差比爱丽丝更低有关。但我很难理解为什么差异会有所不同。
库(dplyr)

sim.flip = 函数(X){
s2 = 样本(x = c(0,1),大小 = X,替换 = T) %&gt;% as.character() %&gt;% as.matrix()

s3 = s2 %&gt;% 矩阵(ncol = 2,byrow = T)
s4 = s2[-c(1,X)] %&gt;% 矩阵(ncol = 2,byrow = T)

s5=应用(s3,1,函数(X){粘贴(X,崩溃=“”,sep=“”)})
s6=应用(s4,1,函数(X){粘贴(X,崩溃=“”,sep=“”)})

A = 长度(grep(x = s5,模式 = “00”) )+
长度（grep（x = s6，模式=“00”））

B = 长度(grep(x = s5,模式 = “01”))+
长度（grep（x = s6，模式=“01”））

返回(数据.frame(A=A,B=B))
}

设置.种子(12345)
sims = sapply(c(1:10000),function(X){sim.flip(X=100)}) %&gt;% unlist() %&gt;% 矩阵(ncol = 2,byrow = T) %&gt;; % as.data.frame()
colnames(sims) = c(“爱丽丝”,“鲍勃”)

sims$winner = ifelse(sims$Alice &gt; sims$Bob,yes = &quot;Alice&quot;,&quot;Bob&quot;)
sims$获胜者[sims$Alice == sims$Bob] = “平局”

表（模拟$获胜者）

爱丽丝·鲍勃·蒂
 4626 4791 583

# 期望值相同
平均值（sims$Alice）
[1]24.7837
意思是（sims$鲍勃）
[1]24.7572

# 方差不同
var(sims$Alice)
[1] 30.36575
var(sims$鲍勃)
[1]6.229471
]]></description>
      <guid>https://stats.stackexchange.com/questions/643092/coin-flip-game-hh-vs-ht-in-a-sequence-of-flips</guid>
      <pubDate>Wed, 20 Mar 2024 17:15:24 GMT</pubDate>
    </item>
    <item>
      <title>两种实验条件的适当设计和不完全封闭</title>
      <link>https://stats.stackexchange.com/questions/634879/appropriate-design-for-two-experimental-conditions-and-incomplete-blocking</link>
      <description><![CDATA[我计划进行一项实验，其中我将评估两个实验变量（A：6 个水平，B：4 个水平）对既定结果的作用，但是，该结果可能会受到我所考虑的外部因素的影响。将能够在定义的块中进行控制。
鉴于一些实验限制，我将无法评估块内的所有 A x B 组合，而必须采用仅具有大约 4-6 个组合的不完整块设计。
查看一些在线指南（例如，https： //people.math.ethz.ch/~meier/teaching/anova/incomplete-block-designs.html）我发现他们主要处理单个实验变量，但事实并非如此（即使我考虑一下我将有 28 个级别的组合），所以我不知道处理这个问题的最佳方法是什么（既涉及规划又涉及数据分析）。
面对这个问题更合理的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/634879/appropriate-design-for-two-experimental-conditions-and-incomplete-blocking</guid>
      <pubDate>Thu, 14 Dec 2023 09:04:15 GMT</pubDate>
    </item>
    <item>
      <title>从分位数确定 CDF 和 PDF</title>
      <link>https://stats.stackexchange.com/questions/611821/determine-cdf-and-pdf-from-quantiles</link>
      <description><![CDATA[我想根据通过分位数回归确定的分位数来确定 CDF 和 PDF。
我在论坛上读到（从分位数查找 PDF）可以通过 B 样条的积分对其进行插值。然后应通过正常评估来确定 PDF。
不幸的是，我不明白为什么我必须使用 B 样条的积分，如何确保 CDF 单调递增以及如何获得导数（PDF）？有人可以帮我吗？
这就是我目前的样子：
导入 scipy.interpolate
将 numpy 导入为 np

x = np.array([ 38.45442808, 45.12051933, 46.85565437, 47.84576924,
        49.50084204、50.09833301、51.3717386、54.85307741、
        59.91982266、63.11786854、66.90037244、67.84446378、
        72.96120777、73.92993279、81.63075081、85.42178836、
        90.70554533, 91.2393176, 110.03872988])

y = np.array([0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95])

t,c,k = scipy.interpolate.splrep(x, y)
样条 = scipy.interpolate.BSpline(t, c, k, extrapolate=False)
d_spline = spline_.derivative()

N = 100
xmin, xmax = x.min(), x.max()
xx = np.linspace(xmin, xmax, N)

无花果, 斧头 = plt.subplots(2,1, 无花果大小 =(12, 8))

ax[0].plot(x, y, &#39;bo&#39;, label=&#39;原始点&#39;)
ax[0].plot(xx, 样条曲线(xx), &#39;r&#39;, label=&#39;BSpline&#39;)

ax[1].plot(xx, d_spline(xx), &#39;c&#39;, label=&#39;BSpline&#39;)


不幸的是，我的方法并没有真正发挥作用，我找不到任何数字示例来帮助我。我感谢所有的评论和评论！
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/611821/determine-cdf-and-pdf-from-quantiles</guid>
      <pubDate>Tue, 04 Apr 2023 13:37:56 GMT</pubDate>
    </item>
    </channel>
</rss>