<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 16 Aug 2024 09:17:56 GMT</lastBuildDate>
    <item>
      <title>用类高斯因子近似高维积分的有效方法</title>
      <link>https://stats.stackexchange.com/questions/652919/efficient-methods-for-approximating-high-dimensional-integrals-with-gaussian-lik</link>
      <description><![CDATA[我正在寻找一种计算效率高的方法来近似地评估以下形式的高维积分：
$\int f(\textbf{x}) \prod_i g(x_i) d\textbf{x}$
其中 $f(\mathbf{x}) = (\mathbf{x}&#39;\mathbf{A}\mathbf{x})^{-k}$，其中 $k$ 是一个大整数，而 $\mathbf{x}$ 的维度通常为 $n &gt; 5,000$。函数 $g(x_i)$ 是概率密度函数，可以用高斯分布 $\mathcal{N}(x_i; \mu_i, \tau_i)$ 来近似，因为 $g(x_i)$ 的拉普拉斯近似很容易推导。一般来说，$g(x_i)$ 可以假设为具有简单易处理的单变量形式，并且易于从中采样。
到目前为止我尝试过的方法：

蒙特卡洛积分：虽然从 $g(x_i)$ 采样很简单，但收敛速度非常慢。一般而言，基于采样的方法可能不可行，因为计算成本高。

拉普拉斯近似：这种方法不切实际，因为$\mathbf{A}$的结构、$f(\mathbf{x})$的行为（当$\mathbf{x} = 0$时会飙升至无穷大）以及高维性使得以计算成本低廉的方式找到被积函数的模式非常具有挑战性。

关注$g(x_i)$：当所有$\tau_i$都很小时，拉普拉斯近似在近似被积函数模式$\mathbf{\mu}$下进行近似，甚至简单地使用$\int f(\mathbf{x}) \prod_i g(x_i) d\mathbf{x} \approx (\mathbf{\mu}&#39;\mathbf{A}\mathbf{\mu})^{-k}$都非常有效。但是，假设所有 $i$ 的 $\tau_i$ 都很小并不总是可行的。

直接近似：尝试近似随机变量 $g(\mathbf{x})$ 的高斯近似值 $\mathbf{x}&#39;\mathbf{A}\mathbf{x}$ 的密度，然后估计所得分布的第 $k$ 个负矩，这有点有效，但结果并不令人满意。


我很好奇，考虑到$g(x_i)$ 是（近似）高斯分布且独立。考虑到此问题的结构，还有其他近似方法可能在计算上可行吗？如能提供其他方向的任何建议或提示，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/652919/efficient-methods-for-approximating-high-dimensional-integrals-with-gaussian-lik</guid>
      <pubDate>Fri, 16 Aug 2024 09:16:27 GMT</pubDate>
    </item>
    <item>
      <title>比较不同调查方法生态调查数据在两个时间点的变化</title>
      <link>https://stats.stackexchange.com/questions/652918/comparing-changes-between-two-time-points-in-ecological-survey-data-with-differe</link>
      <description><![CDATA[我正在分析一些水下生态调查数据，希望能得到一些关于最佳统计方法的建议。调查是在 2009 年和 2024 年在同一地点进行的，所以我有两个时间点的数据。我的目标是了解底栖生物覆盖随时间的变化，以及深度、暴露和沉积等环境因素如何影响这些变化。
有一件重要的事情需要注意：2009 年的调查使用了线截距法，而 2024 年的调查使用了点截距法。我关心的是如何确保这些不同方法的数据具有可比性。
考虑到这些因素，考虑到环境变量是潜在的预测因素，您会推荐哪种统计测试来分析这些数据？任何关于处理调查方法差异的提示也将不胜感激！
非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652918/comparing-changes-between-two-time-points-in-ecological-survey-data-with-differe</guid>
      <pubDate>Fri, 16 Aug 2024 09:06:38 GMT</pubDate>
    </item>
    <item>
      <title>这个GARCH(1,1)模型方程正确吗？</title>
      <link>https://stats.stackexchange.com/questions/652915/is-this-equation-of-the-garch1-1-model-correct</link>
      <description><![CDATA[我是 GRACH 模型的新手，读过很多论文，但对下面提供的方程感到困惑。方程 (15) 正确吗？如果 $z_{t}$ 是误差，为什么作者将它们定义为残差，然后用它们来拟合 copula 模型？根据我的理解，$\alpha$ 系数必须乘以误差，而不是标准差。]]></description>
      <guid>https://stats.stackexchange.com/questions/652915/is-this-equation-of-the-garch1-1-model-correct</guid>
      <pubDate>Fri, 16 Aug 2024 05:40:29 GMT</pubDate>
    </item>
    <item>
      <title>我可以比较 4 点李克特量表和 5 点李克特量表的数据吗？</title>
      <link>https://stats.stackexchange.com/questions/652914/can-i-compare-data-from-a-4-point-likert-scale-and-a-5-point-likert-scale</link>
      <description><![CDATA[我正在计划撰写一份政策文件，比较一组国家/地区公众的政策偏好，并试图解释为什么某些国家/地区倾向于强烈支持冰淇淋，但不支持披萨，反之亦然。（这些是任意示例，实际类别与特定政策问题有关。）
为了说明我的论点，我想将每个国家/地区的数据散点图，以便冰淇淋认可的百分比在 x 轴上，披萨认可的百分比在 y 轴上。
我自己没有进行过任何调查（本文旨在探讨未来开展此类项目的可行性）。目前，我对每个问题都进行了单独的调查。两项调查都声称提供了相关国家人口的代表性样本，并且是在大致相同的时间进行的。
冰淇淋调查要求参与者在 4 点李克特量表上表示赞成或反对，没有中立选项；披萨调查要求参与者在 5 点李克特量表上表示赞成或反对，有中立选项。
我想通过将两个样本的“非常赞成”和“有点赞成”加在一起来绘制每个选项的净赞成率。当然，由于冰淇淋调查没有中立选项，它可能迫使一些人选择“有点赞成”或“有点反对”而不是中性选项。
是否有某种方法可以规范化数据，以使两个数据集具有可比性，或者我是否需要做更多研究来找到在李克特量表上具有相同点数的研究？]]></description>
      <guid>https://stats.stackexchange.com/questions/652914/can-i-compare-data-from-a-4-point-likert-scale-and-a-5-point-likert-scale</guid>
      <pubDate>Fri, 16 Aug 2024 04:49:23 GMT</pubDate>
    </item>
    <item>
      <title>比较 PCA 方法：限制为 3 个成分与使用完整模型的前 3 个成分</title>
      <link>https://stats.stackexchange.com/questions/652911/comparing-pca-methods-constraining-to-3-components-vs-using-the-first-3-compone</link>
      <description><![CDATA[您好，统计社区！
我正在为一个项目探索主成分分析 (PCA)，我对两种 PCA 方法的实际差异和含义感到好奇：
直接将 PCA 模型限制为 3 个成分。
对所有成分运行 PCA，然后选择前 3 个成分。
具体来说，我想了解：
这些方法之间的选择如何影响数据的解释？
是否存在一种方法绝对优于另一种方法的情况？
目标是计算成分分数，然后将其用作 IV。
任何关于这两种方法在应用和结果上可能有何不同的见解、参考或示例都将不胜感激！
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652911/comparing-pca-methods-constraining-to-3-components-vs-using-the-first-3-compone</guid>
      <pubDate>Fri, 16 Aug 2024 03:40:26 GMT</pubDate>
    </item>
    <item>
      <title>了解何时使用负二项式 GLMM</title>
      <link>https://stats.stackexchange.com/questions/652909/understanding-when-to-use-a-negative-binomial-glmm</link>
      <description><![CDATA[我有 16 只鸟。其中有 6 只雄鸟和 10 只雌鸟。数据集名为“Gbirds_sex”，记录了它们重访释放地点的次数 (visitIdx)。我还有 (timeInside) 列，用于显示它们在释放地点内的停留时间。我想在 R 中进行统计分析，看看性别是否会影响重访次数 (visitIdx) 和停留时间 (timeInside)。鉴于我的样本量不相等，我不知道哪种测试效果最好，以及 R 代码是什么。LLM，GLM。我应该使用随机截距吗？
我尝试过这些模型：
# 1) visitIdx 变量是计数变量，因此使用泊松分布拟合 GLMM
library(lme4)
model_glmm &lt;- glmer(visitIdx ~ sex + (1 | id), family =
poisson(), data = Gbirds_sex)
summary(model_glmm)

# 2) residenceTime 变量是连续的，因此使用高斯族。
# 使用高斯响应分布和随机 
# 截距拟合每个个体的 GLMM。
model_timeInside_Gaussian &lt;- lm(timeInside ~ sex, data = 
Gbirds_sex)
summary(model_timeInside_Gaussian)

但是，离散度很高 (2.8)。我现在应该使用这个模型吗？
library(glmmTMB)
model_glmm_nb &lt;- glmmTMB(visitIdx ~ sex + (1 | id), family = nbinom2(), data = Gbirds_sex)
summary(model_glmm_nb)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652909/understanding-when-to-use-a-negative-binomial-glmm</guid>
      <pubDate>Fri, 16 Aug 2024 03:05:07 GMT</pubDate>
    </item>
    <item>
      <title>$|X_n|+|Y_n|=o_p\left(1\right)$是否意味着 $|X_n|=o_p\left(1\right)$？</title>
      <link>https://stats.stackexchange.com/questions/652905/does-x-ny-n-o-p-left1-right-imply-x-n-o-p-left1-right</link>
      <description><![CDATA[$X_n$ 和 $Y_n$ 是随机变量。在本幻灯片中，我学习了$o_p$的性质，例如$o_p(1)+o_p(1)=o_p(1)$（第 5 页）。直观地讲，如果 $|X_n|+|Y_n|=o_p(1)$ 成立，则有 $|X_n|=o_p(1)$。这是正确的吗？如何证明？]]></description>
      <guid>https://stats.stackexchange.com/questions/652905/does-x-ny-n-o-p-left1-right-imply-x-n-o-p-left1-right</guid>
      <pubDate>Fri, 16 Aug 2024 01:52:01 GMT</pubDate>
    </item>
    <item>
      <title>仅使用一个参数对小数据集进行聚类 - 统计人员帮助我</title>
      <link>https://stats.stackexchange.com/questions/652904/clustering-a-small-dataset-with-only-one-parameter-help-me-statisticians</link>
      <description><![CDATA[我是一名生物学家，对个体之间的形态差异很感兴趣
目前，我正在研究一种称为尾鳍长宽比的东西。我想确定尺寸相似的个体是否具有不同的长宽比。
然而，人们早已知道长宽比与鱼的大小呈正相关。因此，我的第一步是通过创建一个新参数来消除长宽比中尺寸的影响：长宽比和鱼大小之间的简单线性模型中的残差。
然后，我想根据这个残差值在我的数据集中识别不同的组。为此，我创建了一个仅包含残差参数的子集，我认为聚类是将个体分类为组的最佳方法。
我的数据集：
 | 数据集 | nrows |
| ------- | ------- |
| 1 | 101 |
| 2 | 55 |
| 3 | 102 |

知道我的数据集（每个数据集一个物种）很小，为了确定最佳聚类数 (k)，我应用了分层方法的 NbClust 函数。
NbClust(subset, min.nc = 2, max.nc = 10, method = &quot;ward.D2&quot;)

有了 num_clusters 后，我进行了分析，绘制了树状图，消除了异常值并重复了该过程。
dist_matrix &lt;- dist(subset)
hc &lt;- hclust(dist_matrix, method = &quot;ward.D2&quot;)

plot(hc, main = paste(&quot;Dendrograma com&quot;, num_clusters, &quot;Clusters&quot;),
xlab = &quot;Observações&quot;, ylab = &quot;Distância Euclidiana&quot;)

rect.hclust(hc, k = num_clusters, border = &quot;red&quot;)


然后，我将原始数据集中的聚类转换为类别
clusters &lt;- cutree(hc, k = num_clusters)
hast$Cluster &lt;- clusters
hast$Cluster&lt;-factor(hast$Cluster)

最后，我想比较个体的聚类
anova&lt;-aov(resid~Cluster, data = dataset)
TukeyHSD(anova)

我不知道我的方法是否是正确的，聚类也不是更好的选择。因此，我希望得到统计学方面更有经验的人的帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/652904/clustering-a-small-dataset-with-only-one-parameter-help-me-statisticians</guid>
      <pubDate>Fri, 16 Aug 2024 00:55:55 GMT</pubDate>
    </item>
    <item>
      <title>瑞利或指数参数估计的预测区间</title>
      <link>https://stats.stackexchange.com/questions/652891/prediction-interval-for-rayleigh-or-exponential-parameter-estimate</link>
      <description><![CDATA[我正在研究瑞利和指数随机变量。它们具有方便的闭式置信区间，可用于参数估计。但现在我们感兴趣的是做出以下形式的陈述：“给定一些实验数据，我们可以对未来实验的参数估计值有什么期望？”我明白我要求的是 MLE 上的预测区间。
我最初认为这会是置信区间 (CI) 平方之类的东西。例如，“第一个实验在 $\hat{\sigma}$ = [1, 2] 上产生了 90% 的置信区间。因此，真正的 $\sigma$ 有 90% 的概率处于该范围内，这意味着 90% 的类似实验将产生包含区间 [1, 2] 部分内容的 90% 置信区间。”但有 10% 的概率，真正的 $\sigma$ 不在该区间，在这种情况下……嗯，我不知道。但考虑到指数分布的“良好”和正态相邻性，我怀疑预测区间存在一个闭式表达式。有人能建议一个吗？
（我可以使用蒙特卡罗技术验证公式，但推导可能更有帮助。我没有成功找到答案，因为预测区间在回归场景中被广泛用于获取未来值。）

示例问题陈述：

设 $X \sim \operatorname{Exponential}(\lambda)$，其中 $\lambda$ 未知。
估计 $\lambda$ 的实验抽取 $n$ 个 $X$ 样本，并估计 $\hat{\lambda} = \bar{x}$。
给定一个实验的结果 $\hat{\lambda_1}$，通过重复实验（使用相同的 $n$）找到值 $\hat{\lambda_2}$ 的 90% 预测区间。

为了通过模拟验证预测区间公式，我将：

设置任意 $\lambda^*$ 和整数 $n &gt; 2$。
进行第一个实验：从用 $\lambda^*$ 参数化的指数 RNG 中抽取 $n$ 个样本。计算 $\hat{\lambda_1} = \bar{x}$。
使用公式计算预测区间的上限，$\operatorname{PI}_{90\%}$。
模拟重复实验并计算 $\hat{\lambda_i} &gt; \operatorname{PI}_{90\%}$ 的次数。
如果该频率收敛至 5%，则公式得到验证。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652891/prediction-interval-for-rayleigh-or-exponential-parameter-estimate</guid>
      <pubDate>Thu, 15 Aug 2024 18:11:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 SARIMA 模型的模拟结果与原始数据不相似？</title>
      <link>https://stats.stackexchange.com/questions/652888/why-do-the-simulations-of-my-sarima-model-not-resemble-my-original-data</link>
      <description><![CDATA[我想使用 R 包“forecast”中的 auto.arima 函数模拟我获得的 SARIMA 模型。我的目标是能够进行大量模拟，以便“预测”例如百年一遇的洪水。
我的模型名称为“final.model”，以下是 auto.arima 函数的输出：
&gt; summary(final.model) # -&gt; ARIMA(1,0,0)(4,1,0)[12] 
Series: mlog 
ARIMA(1,0,0)(4,1,0)[12] 

系数：
ar1 sar1 sar2 sar3 sar4
0.3317 -0.7356 -0.5288 -0.3651 -0.2587
s.e. 0.0388 0.0402 0.0489 0.0489 0.0409

sigma^2 = 0.361：对数似然 = -536.49
AIC=1084.98 AICc=1085.12 BIC=1111.23

训练集误差测量：
ME RMSE MAE MPE MAPE MASE ACF1
训练集 0.006117115 0.5922533 0.4615495 -41.48468 111.4677 0.7431494 -0.01109284 

当我尝试进行模拟时，我得到的模拟与我的原始时间序列相比太大，以下是一个例子：

这是我使用的代码：
n_simulations=10 # 复制次数
q=nsim/12
colors=c(&quot;red&quot;,&quot;blue&quot;,&quot;green&quot;,&quot;orange&quot;,&quot;purple&quot;)

plot(exp(mlog),xlim=c(2015,2035),ylim=c(0,100),type=&quot;l&quot;,col=&quot;black&quot;,
main=&quot;Original Data and Simulations&quot;,xlab=&quot;Year&quot;,ylab=&quot;Values&quot;)

simulated_values=replicate(n=n_simulations,expr=simulate(final.model,nsim=nsim))

for (i in 1:n_simulations) {
lines(time(monthly_ts)[length(monthly_ts)] + 1:(q*12)/12+1/12, exp(simulated_values[,i]), col=alpha(&quot;red&quot;, 0.2))
}

最后三点说明：我无法提供数据（因为来源不允许），在 auto.arima 函数中，我提供了原始时间序列的对数，它是环境数据（即河流的流量）。
我的问题是：我的做法正确吗？为什么我会得到如此奇怪的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/652888/why-do-the-simulations-of-my-sarima-model-not-resemble-my-original-data</guid>
      <pubDate>Thu, 15 Aug 2024 17:54:52 GMT</pubDate>
    </item>
    <item>
      <title>R MSM 包：如何标记事件和流行疾病？</title>
      <link>https://stats.stackexchange.com/questions/652883/r-msm-package-how-to-flag-incident-and-prevalent-disease</link>
      <description><![CDATA[我正在尝试使用 R 中的 msm 包创建一个 2 状态马尔可夫模型（状态 1 到 2 和 2 到 1）。hpv_state 在感染时为 2，在未感染时为 1，在状态未知时为 999。我想创建一个变量来标记每次感染事件是普遍发生的（从跟踪开始连续为 2）还是偶发事件（在观察到 1 后为 2）。当我在 hpv_state=1 时将 infection_type 保留为缺失时，模型似乎会忽略这些条目。当 hpv_state=1 或 999 时，我该如何正确标记 infection_type？
infection_type 变量的用途仅用于 2 到 1 的转换：
hpv16_inft.msm &lt;- msm(hpv_state ~ years_followup, subject=patientid, data=df_hpv16, qmatrix=Q, censor=999, covariates = list(&quot;2-1&quot; = ~infection_type))

数据示例：
patientid hpv_state infection_type 
10 1-0002 2 流行 
11 1-0002 1 NA 
12 1-0002 2 发病率
13 1-0002 2 事件 
14 1-0002 999 NA 
15 1-0002 999 NA 
16 1-0002 1 NA 

我尝试为 NA（即“neg”）分配一个值，但从 infection_type=neg 到 hpv_state=1 的转变是不合逻辑的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652883/r-msm-package-how-to-flag-incident-and-prevalent-disease</guid>
      <pubDate>Thu, 15 Aug 2024 16:50:20 GMT</pubDate>
    </item>
    <item>
      <title>方差分析中如何控制固定效应？</title>
      <link>https://stats.stackexchange.com/questions/652864/how-to-control-within-fixed-effects-in-analysis-of-variance</link>
      <description><![CDATA[我将引用 R 中的常用术语来简化交流，并期望在 R 中得到解决方案，无论是否整洁。
我有一个 tibble，其中包含数字列 value 和字符列 fe 和 treatment。有 3 种治疗和 3 类固定效应。
fe 和 treatment 的每个组合都会重复出现多次。
我有兴趣测试 treatment 是否不会改变 value 的位置，也不会改变其方差。
我想要一个频率检验，以对抗 treatment 改变位置或方差的假设。换句话说，我希望的结果是允许假设 treatment 对 value 的分布没有影响，并且均匀分布在 fe 上。
在没有 fe 的情况下，我会对位置采用常规 ANOVA 检验，对方差采用 Levene 检验；即使我对如何确定 alpha 感到困惑。
如果 fe 用作配对变量，我会运行配对测试。
但在这种情况下，同一个 fe 中有超过 2 个 values 案例。
你能建议我如何进行这个测试吗？
理论上我可以运行多个测试，每个 fe 一个；但我觉得这种方法在确定 alpha 方面是多余的和有问题的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652864/how-to-control-within-fixed-effects-in-analysis-of-variance</guid>
      <pubDate>Thu, 15 Aug 2024 12:50:42 GMT</pubDate>
    </item>
    <item>
      <title>R 中的二元预测分类，预测因子由多个值组成</title>
      <link>https://stats.stackexchange.com/questions/652858/binary-predictive-classification-in-r-with-predictors-consisting-of-multiple-va</link>
      <description><![CDATA[由于维度问题，我目前正在努力构建二元 glm 预测分类器。
我有一个包含 N 个样本的数据集，其中每个样本都有 M 个条目（基因）的值，并且是病例或对照。但是，每个基因由 1 ... k 个数据点组成，每个数据点都是一个数值，范围从 0 到 1，代表与基因重叠的 CpG 位点的甲基化。并且每个基因的数据点数量依次变化（因此意味着每个基因由不同大小的数据框表示）。分类器应该是二进制的，根据通过交叉验证选择的一组预测因子（基因）的值将样本分配为病例/对照。
我之前构建了二元预测分类器，其中每个样本的一个值代表一个基因（即来自 NxM 数据框），但我不知道如何处理当前情况，其中我的 NxM 数据框中的每个 1...M 列实际上可以说是 NxK 数据框而不是 Nx1 列。
我曾想过通过从 N 个样本中的每一个的 1...k 数据点中取出中值来将 NxK 数据框表示为 Nx1 列，或者通过选择 NxK 数据框中的一列来表示数据框（基于适合我的研究问题的选择标准），但理想情况下，我希望在构建分类器时指向代表基因的 NxK 数据框。
有人有这种类型的经验吗问题，如果可以，是否有可能从预测器的数据框构建一个预测分类器，其中预测器依次指向单独的数据框？
如果没有，我从每个样本的 1...k 个数据点中取出中值的方法是否有效？
我之前构建过分类器，其中每个基因都由一个值表示，但我没有处理此类问题的经验。]]></description>
      <guid>https://stats.stackexchange.com/questions/652858/binary-predictive-classification-in-r-with-predictors-consisting-of-multiple-va</guid>
      <pubDate>Thu, 15 Aug 2024 10:04:31 GMT</pubDate>
    </item>
    <item>
      <title>具有趋势和季节性的时间序列数据中的因果推断</title>
      <link>https://stats.stackexchange.com/questions/652855/causal-inference-in-time-series-data-with-trend-and-seasonality</link>
      <description><![CDATA[各位统计学家大家好，
我有一个关于时间序列数据中的因果推断和影响评估的问题，特别是在处理趋势、季节性和政策干预或结构性中断时。
在横截面数据中，我们通常应用 OLS 或非参数模型（如 KNN）来估计独立变量 𝑋 和 𝑍 对因变量 𝑌 的影响。然后，对于 OLS，我会检查假设；对于 KNN，我会检查 𝑌 与预测变量 𝑋 和 𝑍 之间的关系，而无需假设参数形式。
但是，我将处理时间序列数据，其中 𝑌、𝑋 和 𝑍 是同时显示趋势和季节性模式的月度序列。此外，在研究期间的中间可能存在已知的政策干预/趋势中断。
我的问题是：

哪些模型最适合估计时间序列数据中的因果关系，特别是在处理趋势、自相关和结构中断时？

我正在考虑对数据进行季节性调整，但我该如何处理趋势成分？由于趋势存在时均值不是恒定的，我应该采取什么方法来处理这个问题？

我如何将政策干预或趋势突破纳入我的因果分析？

这些时间序列模型做出了哪些假设，我如何在因果推断的背景下验证这些假设？


我不是一个铁杆统计学家，所以如果你能推荐任何相关的资料或教科书来解释这些概念——最好是用 R 中的实际例子/代码——那就太好了。任何指导或参考都将不胜感激。
提前感谢您的见解和帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652855/causal-inference-in-time-series-data-with-trend-and-seasonality</guid>
      <pubDate>Thu, 15 Aug 2024 10:03:20 GMT</pubDate>
    </item>
    <item>
      <title>用于建模财务回报的 AR(1) 过程的时间缩放</title>
      <link>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</link>
      <description><![CDATA[过程：
考虑一个均值为零的 AR(1) 过程，*
$\lambda_t = \kappa \cdot \lambda_{t-1} + \omega_t$，
其中 $\kappa = 0.9$，$\omega \sim N(0, \sigma_{\omega}^2)$，并且 $\sigma_{\omega}^2 = 0.00027$。 $\lambda_0$ 的初始值取自平稳分布 $N \left(0, \frac{\sigma_{\omega}^2}{(1-\kappa^2)} \right)$
我使用此过程生成长度为 $T=672$ 的样本。
* 我知道，对于股票收益建模而言，均值为零是不现实的，但我的问题并不取决于此选择。

上述时间序列应解释为每月收益（以百分点表示），即 672 个月的观测值。
问题：
什么是合适的参数值生成总共 14,112 个每日观测值（即$672 \times 21$，如果我们假设一个月内有 21 个交易日）以符合上述（每月）流程？月回报率是给定月份内所有 21 天回报率的累计乘积。
尝试（在 R 中）：
DAYS &lt;- 21
T &lt;- 672
kappa &lt;- 0.9
variance_omega &lt;- 0.00027

get_init_lambda &lt;- function(variance) return(rnorm(n = 1, mean = 0, sd = sqrt(variance / (1-(kappa)^2))))

#### 月度分析

set.seed(1234)

lambda_T &lt;- vector(mode = &quot;numeric&quot;, length = T)

lambda_shock &lt;- rnorm(T, mean = 0, sd = sqrt(variance_omega))

lambda_T[1] &lt;- kappa * get_init_lambda(variance_omega) + lambda_shock[1]
for(i in 2:T) lambda_T[i] &lt;- kappa * lambda_T[i-1] + lambda_shock[i]

acf(lambda_T)$acf[2]
# [1] 0.9064949 # 符合预期

var(lambda_T)
# [1] 0.001547795

#### 每日分析

set.seed(1234)

kappa_daily &lt;- 0.90 # ??? 如何设置 kappa_daily，使月收益 AC = 0.9？

lambda_T_daily &lt;- vector(mode = &quot;numeric&quot;, length = T * DAYS)

lambda_shock_daily &lt;- rnorm(T * DAYS, mean = 0, sd = sqrt(variance_omega / DAYS))

lambda_T_daily[1] &lt;- kappa_daily * get_init_lambda(variance_omega / DAYS) + lambda_T_daily[1]
for(i in 2:(T * DAYS)) lambda_T_daily[i] &lt;- kappa_daily * lambda_T_daily[i-1] + lambda_shock_daily[i]

# 检索月末指数；假设每个月有 21 个交易日
begin_month &lt;- seq(1, T * DAYS, 21)
end_month &lt;- c(tail(begin_month, -1) - 1, T * DAYS)

lambda_monthly_aggregate &lt;- vector(mode = &quot;numeric&quot;, length = T)

for(i in 1:T){
month_ind &lt;- (begin_month[i]):(end_month[i])

daily_ret_within_month &lt;- 0.01*lambda_T_daily[month_ind] # 收益以 % 表示
monthly_return &lt;- 100*(cumprod(1+daily_ret_within_month) - 1) # 累计每日收益

lambda_monthly_aggregate[i] &lt;- monthly_return[DAYS] # 检索累计。 21 天后返回
}

# 与上述值不相同：自相关性太低，mth 方差返回值太高！
&gt; acf(lambda_monthly_aggregate)$acf[2]
[1] 0.2988249

var(lambda_monthly_aggregate)
[1] 0.01494742

]]></description>
      <guid>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</guid>
      <pubDate>Wed, 14 Aug 2024 16:01:50 GMT</pubDate>
    </item>
    </channel>
</rss>