<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 21 Jul 2024 21:13:22 GMT</lastBuildDate>
    <item>
      <title>预言的假设检验</title>
      <link>https://stats.stackexchange.com/questions/651492/hypothesis-testing-of-a-prophecy</link>
      <description><![CDATA[一个高度具体和不可能的预言是否足以让人相信它不是偶然发生的？还是需要很多预言才能确定这一点？
我明白我们无法（也许）知道所有可能的不同概率描述的全部人口和分布，但让我们假设我们主观地评估预言足够精确和不可能，可以通过我们选择的显著性水平，是否有可能排除预言偶然成功的假设？
此外，如何测试预言以确信它不是偶然发生的？]]></description>
      <guid>https://stats.stackexchange.com/questions/651492/hypothesis-testing-of-a-prophecy</guid>
      <pubDate>Sun, 21 Jul 2024 20:40:38 GMT</pubDate>
    </item>
    <item>
      <title>使用多重比较校正和复合 DV</title>
      <link>https://stats.stackexchange.com/questions/651491/use-of-multiple-comparison-correction-and-composite-dv</link>
      <description><![CDATA[我正在研究单个 X 对复合 DV Y 的影响。我还想研究 X 对 Y 的 36 个子成分的影响。因此，我必须运行 37 个多元回归模型，特别是具有稳健聚类 SE 和年份 FE 的池化 OLS。X 是时不变的，所以我不能包括国家 FE。
我明白我应该校正多重比较，我打算使用 BH 校正。我的问题是，我是否应该调整所有模型，包括复合 Y 是 DV 的主模型？要清楚，这是一个条件过程：只有当 X 在主模型中显著时，才会针对子成分进行测试。
我很困惑，因为我确实调整了主模型的 p 值，但校正后主模型中的 X 并不显著。然而，X 对很多子成分来说都是显著的。我知道在看到不利结果时质疑模型是不科学的，但如果 X 在主模型中的初始显著影响可归因于噪音，我很难解释结果。
总而言之，我有两个问题：

如果我有一个条件过程，只有当 X 在主模型中具有显著影响时才会运行更多模型，是否需要调整主模型的 p 值以进行多重比较？如果我有一个条件过程，测试是否仍被视为同时进行的？
如果需要调整，我该如何解决由于初始效果显著而需要调整的悖论，但调整后初始效果变得不显著，因此无需进一步测试并因此进行调整？

任何建议都值得赞赏。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651491/use-of-multiple-comparison-correction-and-composite-dv</guid>
      <pubDate>Sun, 21 Jul 2024 20:05:43 GMT</pubDate>
    </item>
    <item>
      <title>是否可以对正则化器进行逆向工程，以对相关的非正则化回归问题的解决方案进行精确的修改？</title>
      <link>https://stats.stackexchange.com/questions/651488/can-a-regularizer-be-reverse-engineered-to-induce-precise-modifications-to-the-a</link>
      <description><![CDATA[以下是回归问题中正则化的图片...

蓝线表示未正则化或正则化程度较低，绿线表示正则化程度较高。此类问题通常写为$\min_w\ (\frac{\sum_{i = 1}^n l(h_w(x_i),\ y_i)}{n} + \lambda r(w))$，其中$\lambda$设置得越大，解越接近直线、水平线。
这个描述听起来很像$1$维热方程的动态行为。正如此处所示，受偏微分方程$T_t = \alpha T_{xx}$控制，用任意高波动率初始化的棒的温度分布会随着时间的推移平滑为一条水平直线。
虽然我期望与热方程相关的某些东西能够控制正则化，但当我真正研究正则化时，我并没有发现任何联系。有没有办法有意构建一个正则化器，其常数$\alpha$等于热方程中的热扩散率常数，使得对于每个固定的$\alpha$值，增加正则化器上的$\lambda$会修改非正则化的损失函数解，其修改方式与在$1$维热方程中增加$t$（初始温度分布等于非正则化的损失函数解）（“热方程正则化器”）相同？]]></description>
      <guid>https://stats.stackexchange.com/questions/651488/can-a-regularizer-be-reverse-engineered-to-induce-precise-modifications-to-the-a</guid>
      <pubDate>Sun, 21 Jul 2024 18:46:43 GMT</pubDate>
    </item>
    <item>
      <title>r 中的 Cocor 用于比较两个斯皮尔曼相关系数吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651484/cocor-in-r-to-compare-two-spearman-correlation-coefficients</link>
      <description><![CDATA[我可以在 r 中使用 Cocor 比较两个斯皮尔曼相关系数吗？以及比较两个类内相关系数 (ICC)？]]></description>
      <guid>https://stats.stackexchange.com/questions/651484/cocor-in-r-to-compare-two-spearman-correlation-coefficients</guid>
      <pubDate>Sun, 21 Jul 2024 15:43:51 GMT</pubDate>
    </item>
    <item>
      <title>生存分析中不相互排斥的竞争风险</title>
      <link>https://stats.stackexchange.com/questions/651481/competing-risks-that-are-not-mutually-exclusive-in-survival-analysis</link>
      <description><![CDATA[我有 5 种类型的事件可供主体体验。但是，并非所有这些事件都相互竞争：对于事件 A、B、C、D、E，A 的发生会阻止 B 的发生。B、D 和 E 相互排斥，而 C 的发生会阻止所有其他事件。我想使用 Aalen-Johansen 估计器估计每个事件的累积发生率，但我不确定如何处理和解释这些相互竞争的情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/651481/competing-risks-that-are-not-mutually-exclusive-in-survival-analysis</guid>
      <pubDate>Sun, 21 Jul 2024 15:14:12 GMT</pubDate>
    </item>
    <item>
      <title>处理具有大量异常值的数据集[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651479/dealing-with-a-dataset-with-huge-outliers</link>
      <description><![CDATA[我正在研究一个少于 100 个样本、大约 20 个特征的数据集。这个数据集与医学物理领域中与肺和心脏等器官相关的参数的多元回归问题有关。这个数据集的奇怪之处在于与肺相关的目标值有关。事实上，肺在不同的人身上有很大的差异，因此，这种类型的目标值中存在大量异常数据，这导致其中出现大量过度拟合。你认为我该如何处理这个数据集？]]></description>
      <guid>https://stats.stackexchange.com/questions/651479/dealing-with-a-dataset-with-huge-outliers</guid>
      <pubDate>Sun, 21 Jul 2024 11:55:08 GMT</pubDate>
    </item>
    <item>
      <title>具有多个时间段的 Diff-in-Diff</title>
      <link>https://stats.stackexchange.com/questions/651478/diff-in-diff-with-multiple-time-periods</link>
      <description><![CDATA[这是我在这里的第一篇帖子，我还是个新手，希望这篇文章能说清楚。
背景：
对于我的硕士论文，我想估计重复对论文引用的影响。为此，我想比较曾经重复过的论文和没有重复过的论文的引用。
我的导师告诉我，考虑到我的因变量的性质（引用是一个非负计数数字），更合适的模型是交错式差异分析，并采用泊松回归。但是，他告诉我尝试初始的“简单”差异分析来查看结果，即使结果可能有偏差。
在我的数据集中，我有大约 80 篇在不同时间点重复的论文（因此是我的治疗组），以及 160 篇从未重复的论文（对照组）。为了确保可比性，我只选取在同一期刊、卷、期上发表、涉及相同主题或 JEL 代码的实证论文。以下是一个片段：

因此，如果我们查看一个简单的 DiD 方程，并将其应用于我的数据，这就是我想要估计的：

其中，replicated 是治疗虚拟变量（如果已复制则为 1，如果从未复制则为 0），d_time 是时间虚拟变量（before=0 并且after=1)。
我在这里看到的问题是，我的对照组没有“之后”，因为这些论文从未被复制过，而且我无法取单个处理过的论文的“之后”，因为所有论文的处理年份都不同（有些重复，但一般是 15 年）。因此，我的时间虚拟变量的构造使我的对照组的 d_time 始终为 0（replicated=0），
如果我运行这样的模型，由于交互项和 d_time 之间存在完全共线性，我的交互项会被省略。我在这里遗漏了什么？
现在，我知道这是“基本” DiD 模型，由于我的数据的性质，这可能会导致一些规范问题。但我想在尝试任何其他更高级的方法之前实现它。有人有什么建议吗？
（我试图理解 Callaway 和 Sant&#39;Ana 关于交错方法的论文，但我无法理解该模型的实施和解释。因为据我所知，如果在另一篇论文之后进行处理，每篇经过处理的论文都可以作为对照论文（例如：2015 年的重复论文可以作为 2010 年重复论文的对照论文，依此类推）。但是，我只想比较从未重复的论文和重复的论文，因此我不确定这是否是最好的方法）]]></description>
      <guid>https://stats.stackexchange.com/questions/651478/diff-in-diff-with-multiple-time-periods</guid>
      <pubDate>Sun, 21 Jul 2024 11:49:31 GMT</pubDate>
    </item>
    <item>
      <title>使用未观察组件模型时，首选的程序和相关方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/651477/what-is-the-preferred-procedure-and-associated-methods-when-using-an-unobserved</link>
      <description><![CDATA[首先我要说的是，我的统计知识非常有限。如果您发现我的思维方式有任何错误，或者有任何好的初学者参考资料供我进一步阅读我将要描述的主题，请告诉我。
我有一个数据库，其中包含来自各个来源的按国家/地区每年的治理指标（对于那些感兴趣的人：世界银行的全球治理指标）。我想将其中一些指标组合在一起并创建一个综合指数。这需要为指标分配权重。鉴于各种来源和方法论的差异，主成分分析似乎不太合适。相反，我想到使用具有趋势成分的未观察成分模型 (UCM)，类似于全球治理指标。这样，我可以使用趋势来衡量一些潜在的治理概念。但是，由于我正在改变他们的程序，我必须自己弄清楚，而不是能够复制他们的步骤。
因此，我试图弄清楚在创建这个综合指数时要遵循哪些步骤。我有一个大概的提纲，但想知道一些更具体的步骤以及最适合执行它们的方法

标准化数据：所有数据都使用最小-最大方法标准化为 0-1 的范围
考虑缺失值：有很多缺失值，因为并非所有年份和所有国家都得到一致测量。我仍在尝试找出最佳处理方法
加权和聚合：要计算赋予值的权重，我想使用 UCM，这需要估计相关参数。我读过我可以使用 MLE 或贝叶斯方法，但我不知道在哪种情况下哪种方法更可取
根据 UCM 确定的权重，计算每个国家每年值的加权平均值

这些仍然很笼统，我想寻求帮助来充实这个过程。此外，如果您愿意成为我的陪练伙伴，向我提出一些更一般的问题，我也将不胜感激。
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/651477/what-is-the-preferred-procedure-and-associated-methods-when-using-an-unobserved</guid>
      <pubDate>Sun, 21 Jul 2024 11:46:20 GMT</pubDate>
    </item>
    <item>
      <title>最近（>2015 年）关于变量误差模型的学术介绍有哪些？</title>
      <link>https://stats.stackexchange.com/questions/651471/what-is-a-good-recent-2015-academic-introduction-to-errors-in-variables-mode</link>
      <description><![CDATA[我知道这个资源 https://en.wikipedia.org/wiki/Errors-in-variables_models，但我不太相信维基百科上关于统计的文章，所以我正在寻找一些关于这个主题的学术参考资料。如果它能帮助我提出一些建议，我已经熟悉标准回归模型，对混合模型也有点了解。
你有什么好的建议吗？如果它只是教科书中的一章，只要它涵盖基础知识并（理想情况下）建议进一步的资源，我就会感兴趣。如果该资源是旧资源的新版本，我也会感兴趣。干杯，]]></description>
      <guid>https://stats.stackexchange.com/questions/651471/what-is-a-good-recent-2015-academic-introduction-to-errors-in-variables-mode</guid>
      <pubDate>Sun, 21 Jul 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>分数布朗运动参数估计中的偏差估计（逆转对数变换后）</title>
      <link>https://stats.stackexchange.com/questions/651469/bias-estimation-after-reversing-the-log-transformation-in-parameter-estimation</link>
      <description><![CDATA[我正在学习这两篇文献，
1 [分数布朗运动的模拟与识别：文献和比较研究 COEURJOLLY Jean-François]
2 [通过离散样本路径变化估计分数布朗运动的参数 JEAN-FRANÇOIS COEURJOLLY]
我坚持理解 fBm 的缩放参数 $C$ 的偏差。此参数 $C$ 是通过对数据进行对数变换（以获得线性）、执行 OLS 然后再变换回来获得的。
因此，$C$ 的估计量是一个有偏估计量。
我检查了作者如何估计偏差的代码，但我无法弄清楚作者到底在做什么，因为两篇文献中都没有提到偏差估计。
从代码中我可以看出，作者试图使用渐近方差来估计方差，但它与下面的方差公式并不完全匹配
我在下面粘贴了文献和代码的相关部分。代码似乎使用了 Digamma 函数的渐近展开。
所以我想问一下这里执行的是哪种偏差校正？如果可能的话，为什么 Digamma 函数的扩展在这里？

]]></description>
      <guid>https://stats.stackexchange.com/questions/651469/bias-estimation-after-reversing-the-log-transformation-in-parameter-estimation</guid>
      <pubDate>Sun, 21 Jul 2024 04:19:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 LOOCV 中的正则化减少小型数据集的方差</title>
      <link>https://stats.stackexchange.com/questions/651449/reducing-variance-with-regularization-in-loocv-for-small-datasets</link>
      <description><![CDATA[我有一个小数据集，我正在考虑使用留一交叉验证 (LOOCV) 来评估我的模型。我理解，交叉验证通常是一种评估模型在未见数据上的表现的方法。
但是，我担心偏差-方差权衡。具体来说，使用 LOOCV 时，存在偏差低但方差高的风险。为了缓解这种情况，我正在考虑使用正则化模型（L1、L2 或 Elastic Net）来引入一些偏差并减少方差（在使用 loocv 时同时……）。
您能否提供任何实施此方法的提示或最佳实践？任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/651449/reducing-variance-with-regularization-in-loocv-for-small-datasets</guid>
      <pubDate>Sat, 20 Jul 2024 10:57:12 GMT</pubDate>
    </item>
    <item>
      <title>不可靠测量的方差分析</title>
      <link>https://stats.stackexchange.com/questions/651443/anova-with-unreliable-measure</link>
      <description><![CDATA[我正在做一些关于体育科学的文献综述，特别是训练对耐力的影响。
没有标准的耐力测试。有些测试包括间歇性收缩，直到筋疲力尽，然后测量最终的力量。
有些测试已成为研究的主题，以获得 ICC、LoA 或其他会话间可靠性指标，而有些则没有。有些被发现具有较低的 ICC（&lt;0.8）或非常大的 LoA（+/- 40%）。
我遇到过一些研究训练对耐力的影响的研究。他们对一组人进行耐力测试，然后让他们接受训练，并进行另一次耐力测试。然后他们进行单向方差分析以确定耐力是否有显著提高。但是，其中一些研究使用了尚未表征的耐力测试，从未进行过任何重测信度评估。
所以我的问题是：如果使用的测量方法不可靠或信度未知，方差分析能否得出显着差异的结论？
这对我来说似乎很奇怪，因为这就像使用不可靠的量表而不知道其标准误差一样。]]></description>
      <guid>https://stats.stackexchange.com/questions/651443/anova-with-unreliable-measure</guid>
      <pubDate>Sat, 20 Jul 2024 09:54:24 GMT</pubDate>
    </item>
    <item>
      <title>如何计算所需样本量以实现所需的假阴性率</title>
      <link>https://stats.stackexchange.com/questions/651434/how-to-calculate-required-sample-size-for-desired-false-negative-rate</link>
      <description><![CDATA[我正在尝试设计一个进行二元分类的系统。假阴性的成本很高，所以我想确保我已经进行了足够彻底的测试，以尽量减少这种可能性。我希望系统的假阴性率小于 1%，确定性为 95%。如果我预计真阳性率很小（大约 2%），我应该如何计算达到这一置信度所需的人口规模？ 单侧检验程序是此处适用的正确方程吗？
$$
N \geq \left ( \frac{z_{1-\alpha} \sqrt{p_0(1-p_0)} + z_{1-\beta} \sqrt{p_1(1-p_1)}}{p_1-p_0} \right ) ^2
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/651434/how-to-calculate-required-sample-size-for-desired-false-negative-rate</guid>
      <pubDate>Sat, 20 Jul 2024 01:48:58 GMT</pubDate>
    </item>
    <item>
      <title>如何预测转换后的时间序列数据？</title>
      <link>https://stats.stackexchange.com/questions/651425/how-can-you-forecast-transformed-time-series-data</link>
      <description><![CDATA[我有包含趋势和季节性成分的时间序列数据。我使用以下方法从数据中删除了它：
 remove_seasonality &lt;- function(x) {
t &lt;- seq_along(x)
sin_term &lt;- sin(2 * pi * t / 52)
cos_term &lt;- cos(2 * pi * t / 52)
lm_model &lt;- lm(x ~ sin_term + cos_term)
residuals(lm_model)
}
subset_data_two$x_deseasonalized &lt;- remove_seasonality(subset_data_two$Nitrogen_Dioxide)
detrended_data &lt;- subset_data_two

split_data &lt;- function(data, train_or_test, prop) {
ordered_data &lt;- data[order(data$Date), ]
row_count &lt;- nrow(ordered_data)
train_size &lt;- round(prop * row_count)

if (train_or_test == &quot;train&quot;) {
train_data &lt;- ordered_data[1:train_size, ]
return(train_data)
} else if (train_or_test == &quot;test&quot;) {
test_data &lt;- ordered_data[(train_size + 1):row_count, ]
return(test_data)
} else {
stop(&quot;train_or_test 必须是 &#39;train&#39; 或 &#39;test&#39;&quot;)
}
}
training_data &lt;- split_data(detrended_data, &quot;train&quot;, 0.85)
test_data &lt;- split_data(detrended_data, &quot;test&quot;, 0.85)

# 3.0 拟合模型
fix &lt;- training_data[,c(&quot;Date&quot;, &quot;x_deseasonalized&quot;)]
fixed_tseries &lt;- read.zoo(fix)
three_plots(fixed_tseries, &quot;时间序列：从固定 x 到固定 x 的平稳序列&quot;)

fix_model &lt;- arima(fix$x_deseasonalized, order=c(1,0,1))
three_plots(fix_model$residuals, &quot;AR(1)MA(1) 时间序列&quot;)

# 4.0 预测
forecasted &lt;- Forecast(fix_model, h = 31)

然后我能够使用平稳数据拟合 ARMA(1,1) 模型。
我现在想预测 n 步。我知道 predict() 函数采用转换后的模型，并且我相信新的平稳 x 值 (data$x_fixed)，但我不知道在哪里应用原始趋势/季节性转换以使预测变得非平稳？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651425/how-can-you-forecast-transformed-time-series-data</guid>
      <pubDate>Fri, 19 Jul 2024 20:05:26 GMT</pubDate>
    </item>
    <item>
      <title>我有一个包含 18 个生物标志物特征和一个目标变量的数据集。我想找到对目标影响最大的特征</title>
      <link>https://stats.stackexchange.com/questions/651353/i-have-a-dataset-with-18-biomarker-features-and-a-target-variable-i-want-to-fin</link>
      <description><![CDATA[我有一些疾病生物标志物数据集，其中包含来自不同样本的 18 个生物标志物读数和一个显示疾病存在与否的目标变量（特征既有分类特征也有数值特征）。我想看看是否只使用对目标变量影响最大的特征会提高我的预测模型的性能——目前使用 scikit learn。
以下是数据等的一些细节。

这些是我拥有的肝病数据集，共有 4 个。它们都包含相同的 18 个生物标志物特征，其中包括“白蛋白水平”、“总胆固醇”、“性别”、“甘油三酯”等读数。

2.目标变量是二进制的，“0”= 无肝病，“1”= = 肝病。

我有一个用于训练的发现数据集和 3 个用于测试的验证数据集。因此准确度指标基于验证集中对疾病的正确预测。

我尝试应用浅层模型，包括使用 18 种生物标志物以及 MLP 的逻辑回归、梯度提升和随机森林。数据集非常不平衡，表现不如我希望的那样好，尤其是对于预测第 1 组。- 这就是我认为特征选择可以帮助减少噪音的原因。

我尝试过一种随机森林方法来查看每个特征在多大程度上降低了分割的杂质 - 虽然鉴于我经验不足，我不知道这是否是最好的方法。


有人可以建议如何做这件事的好方法吗？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/651353/i-have-a-dataset-with-18-biomarker-features-and-a-target-variable-i-want-to-fin</guid>
      <pubDate>Thu, 18 Jul 2024 16:31:46 GMT</pubDate>
    </item>
    </channel>
</rss>