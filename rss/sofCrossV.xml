<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 15 Jul 2024 21:14:58 GMT</lastBuildDate>
    <item>
      <title>使用引导偏差校正和加速 (BCa) 置信区间计算 p 值 - R</title>
      <link>https://stats.stackexchange.com/questions/651101/computing-p-value-using-bootstrap-bias-corrected-and-accelerated-bca-confidenc</link>
      <description><![CDATA[在计算 BCa p 值时，boot.pval 包会抛出错误。建议的修复似乎有效，但我不确定这是否正确。该修复是在两年多前提出的，但尚未被接受。已经在 StackExchange 上检查了这个问题，但没有关于 BCa 的具体指导。在下面的代码中，我展示了问题以及使用函数 boot.pval2 的建议修复。
还有其他方法（包等）来计算 bootstrap BCa p 值吗？
library(boot.pval)
library(boot)
# BCA 不起作用

ratio &lt;- function(d, w) sum(d$x * w)/sum(d$u * w)

city.boot &lt;- boot(
city, 
ratio, 
R = 99, 
stype = &quot;w&quot;,
sim = &quot;ordinary&quot;)

boot.pval(city.boot, 
type = &#39;bca&#39;)

# 抛出错误：
# if (any(ints)) out[inds[ints]] 中的错误&lt;- tstar[k[inds[ints]]] :
# 需要 TRUE/FALSE 的缺失值

# 根据建议的修复进行了调整：
# alpha_seq &lt;- seq(pval_precision, 1-pval_precision, pval_precision)

# 调整后的函数：

boot.pval2 &lt;- function(boot_res,
type = &quot;perc&quot;,
theta_null = 0,
pval_precision = NULL,
...)
{
if(is.null(pval_precision)) { pval_precision = 1/boot_res$R }

# 创建一个 alpha 序列：
alpha_seq &lt;- seq(pval_precision, 1-pval_precision, pval_precision)

# 上面的内容从 alpha_seq &lt;- seq(1e-16, 1-1e-16, pval_precision)

# 计算 1-alpha 置信区间，并提取
# 它们的边界：
ci &lt;- suppressWarnings(boot::boot.ci(boot_res,
conf = 1- alpha_seq,
type = type,
...))

bounds &lt;- switch(type,
norm = ci$normal[,2:3],
basic = ci$basic[,4:5],
stud = ci$student[,4:5],
perc = ci$percent[,4:5],
bca = ci$bca[,4:5])

# 找到最小的 alpha，使得 theta_null 不包含在 1-alpha
# 置信区间中：
alpha &lt;- alpha_seq[which.min(theta_null &gt;= bounds[,1] &amp; theta_null &lt;= bounds[,2])]

# 返回 p 值：
return(alpha)
}

boot.pval2(city.boot, 
type = &#39;bca&#39;)

# 结果：
# 0.01010101

可能相关的一个问题是，BCa 引导间隔至少需要与观测次数一样多的迭代次数。请参阅此处和此处。]]></description>
      <guid>https://stats.stackexchange.com/questions/651101/computing-p-value-using-bootstrap-bias-corrected-and-accelerated-bca-confidenc</guid>
      <pubDate>Mon, 15 Jul 2024 20:01:23 GMT</pubDate>
    </item>
    <item>
      <title>风险函数怎么会是负数呢？</title>
      <link>https://stats.stackexchange.com/questions/651100/how-can-a-hazard-function-be-negative</link>
      <description><![CDATA[我一直在阅读R 中的生存分析，这是我为独立学习而找到的一本电子书，但遇到了一个困惑。他们对风险函数的定义如下：

其中 T 是事件时间或正确审查时间中先到的那个。分子是概率，因此是非负的，我假设我们应该将 δ 取为正，因为当 δ ≤ 0 时，P(t &lt; T &lt; t + δ) = 0。因此，风险函数似乎应该是非负的。然而，在第 3 章关于参数建模的文章中，他们展示了以下观察到的瞬时风险函数的示例：

这与风险函数定义如何一致？风险函数为负的解释是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/651100/how-can-a-hazard-function-be-negative</guid>
      <pubDate>Mon, 15 Jul 2024 19:45:32 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用哪种匹配，为什么我的倾向得分匹配不起作用？</title>
      <link>https://stats.stackexchange.com/questions/651099/which-kind-of-matching-can-i-use-and-why-doesnt-my-propensity-score-matching-wor</link>
      <description><![CDATA[我目前正在尝试找出某种疾病特征是否会影响长期生存。我有观察数据，我正在尝试匹配我的队列，因为两组之间存在巨大的基线差异。我尝试过倾向得分匹配，但结果很差，它稍微增加了平衡，但不是很多。我有大约 6 个变量想要匹配，它们与长期生存有关。我正在使用 R 上的 matchit() 包。这是我用于匹配的代码：
 m.data &lt;- matchit(mydata$cto ~ X, data = mydata, method = &quot;optimal&quot;, distance = &quot;glm&quot;, estimand = &quot;ATC&quot;) X 是我的协变量列表。这是产生最平衡数据集的参数排列。但仍然存在显着的基线差异，我想摆脱这些差异。您将如何实现更好的匹配。
PS：我知道倾向得分匹配的缺陷。我并不是想在这里证明因果关系，我只是希望我的数据能为我未来的工作指明方向。]]></description>
      <guid>https://stats.stackexchange.com/questions/651099/which-kind-of-matching-can-i-use-and-why-doesnt-my-propensity-score-matching-wor</guid>
      <pubDate>Mon, 15 Jul 2024 19:35:44 GMT</pubDate>
    </item>
    <item>
      <title>清理 Pandas 数据集时的奇怪行为（数据类型转换和缺失值）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651098/strange-behavior-when-cleaning-dataset-in-pandas-data-type-conversion-and-missi</link>
      <description><![CDATA[我当时处理的数据集的特征是未知的（编码名称），尽管所有特征都已包含数字，但数据类型是字符串或对象。此外，还指出缺失值被标记为“na”。其中一个挑战要求我确定某些列的平均值、中位数和标准差，忽略空值。
我所做的是使用带有参数 error=“coerce” 的 to_numeric() 函数，以便“na”值会自动转换为 NaN，我可以删除它们或使用自动忽略这些值的函数（如 describe()）。但是，我无法得出任何列出的选项答案。
在下面的例子中，我得出了 corr 的值为 0.195。
train_df[&#39;class&#39;] = train_df[&#39;class&#39;].map({&#39;neg&#39;: 0, &#39;pos&#39;: 1})

for column in train_df.columns:
train_df[column] = pd.to_numeric(train_df[column], errors=&#39;coerce&#39;)

train_df.dropna(inplace=True, subset=&#39;var1&#39;)
train_df.dropna(inplace=True, subset=&#39;var2&#39;)

corr, _ = spearmanr(train_df[&#39;var1&#39;], train_df[&#39;var2&#39;])
corr

所以，我决定采取不同的方法，看看我是否能找到正确的答案：我决定使用布尔掩码手动删除所有“na”值，然后使用 to_numeric() 转换整个数据集并计算统计数据。这种方法有效，我甚至使用了参数 error=“raise”，没有抛出任何错误。我终于得到了我想要的答案。
在下面的例子中，我得到了 corr 的值为 0.310。
mask = ~train_df.apply(lambda x: x.astype(str).str.contains(&#39;na&#39;)).any(axis=1)
df_cleaned = train_df[mask]

df_cleaned[&#39;var1&#39;] = pd.to_numeric(df_cleaned[&#39;var1&#39;])
df_cleaned[&#39;var2&#39;] = pd.to_numeric(df_cleaned[&#39;var2&#39;])

corr, _ = spearmanr(df_cleaned[&#39;var1&#39;], df_cleaned[&#39;var2&#39;])
corr

有人知道为什么会发生这种情况吗？为什么使用第一种方法得到的统计数据与使用第二种方法得到的统计数据不同？从理论上讲，这两种方法不应该都得到相同的干净数据集吗？我的意思是，如果除了“na”之外还有其他空值在第一种方法中自动转换为 NaN，那么在使用 error=“raise” 时，这些值会在第二种方法中导致错误，因为我只从数据集中删除了“na”。有人知道为什么会发生这种情况吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651098/strange-behavior-when-cleaning-dataset-in-pandas-data-type-conversion-and-missi</guid>
      <pubDate>Mon, 15 Jul 2024 19:30:22 GMT</pubDate>
    </item>
    <item>
      <title>如何找到多变量相关性？</title>
      <link>https://stats.stackexchange.com/questions/651097/how-to-find-multi-variable-correlation</link>
      <description><![CDATA[我拥有工程学学位，但没有更深入的统计学知识，所以我想知道是否有人可以指出我找到以下问题的解决方案的方向：

我有一组输入变量 [A、B、C、...] 和一个输出变量 X，我想预测或至少估计一些概率。让我们使用一组输入数据（一天的温度 (A)、城市中的游客数量 (B)、是否下雨 (C) 等）估计冰淇淋销售量 (X) 的示例。

这里的问题是：

也许输入变量的子集（例如 C）与 X 不相关（或相关较弱），但与其他变量结合时可能具有很强的相关性（即 B 和 C 结合起来可能与 X 密切相关）。例如：也许当天的温度（变量 A）本身无法帮助我预测冰淇淋的销量（X），也无法预测当前城市中的游客数量（B）。但是，当将两者（游客数量和当天的温度，即 A 和 B）结合起来时，我可能与销售量（X）有很强的相关性。
输入变量可能是连续的，也可能是布尔值。例如：变量 C（是否下雨）是布尔值，但可能有助于我预测销售量。
我不确定这是否被称为相关性，因为我不一定在寻找线性关系，而是任何可能有价值的关系。例如，当 B 接近特定值时，X 可能倾向于在特定间隔内。这意味着，我只对 B 的特定值区域感兴趣。每当 B 远离这个区域时，它就不再让我感兴趣了（即它与 X 的关系无关紧要）。例如：如果白天的温度高于 35°C 或低于 15°C，可能就一点也不有趣了，因为在这两种情况下，出去吃冰淇淋要么太热要么太冷，所以我只想知道，每当温度落在特定范围内时，冰淇淋的销量往往会更高，但我不想知道它们在这些范围之外是否仍然相互关联。
我不需要为每个输入组合估计 X 的可能值，而是在特定值范围内识别可能指示 X 可能范围的输入变量的潜在子集。换句话说，浏览数据集并尝试找到输入值（可能是整个输入，也可能是通过丢弃一些变量得到的子集），这些输入值可能表明当 X 也在特定范围内时，这种特定组合通常会发生（比平时更频繁）。例如：在销售额低的日子里，我不一定想知道是因为下雨，还是因为温度太高或太低。我只是想找到可能表明这一天的销售额可能很高的输入组合，即当温度在特定范围内时，没有下雨等等......（也许其他一些变量 D、E、F......甚至不相关，所以也可以丢弃）。

我知道这听起来像是一个多步骤问题（在这里可能不太容易解决），但如果有人能指出任何可以帮助我的非线性关系，我会很高兴，尤其是有多个变量的情况下。
问题 3 对我来说是最关键的，因为它阻止我使用一些协方差矩阵或皮尔逊相关，因为变量可能不是线性相关的。例如：
问题 4 也使事情变得复杂，因为我并不是在寻找一种总是适用的关系，而是在数据集中找到可能有趣的区域/组合。
我正在考虑使用无监督学习方法，因为我在人工智能方面的背景比在纯统计学方面的背景要好，但我还没有找到合适的算法。
任何帮助都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/651097/how-to-find-multi-variable-correlation</guid>
      <pubDate>Mon, 15 Jul 2024 19:22:49 GMT</pubDate>
    </item>
    <item>
      <title>使用已知 copula 参数进行预测的步骤</title>
      <link>https://stats.stackexchange.com/questions/651095/steps-for-forecasting-with-know-copula-parameters</link>
      <description><![CDATA[我想计算我的 copula 模型的平均绝对百分比误差 (MAPE)。我卡在了预测步骤。我在这里没有为不同的数据对指定 copula。

我有两个时间序列 $X$ 和 $Y$。我发现最佳 GARCH 参数 $\alpha$ 和 $\beta$ 假设均值为 0。
两个变量之间的 Kendals $\tau$ 为 $\tau$
然后我找到了最佳 copula，其参数为 $\kappa$ 和 $\omega$。
现在为了进行预测，我需要使用在步骤 3 中找到的 copula 参数生成残差。

如果我想手动输入 copula 参数而不使用某些 $param=fit$ 类型的代码，该如何执行此操作R。
我既能用 R 也能用 Excel。请问有人能帮我完成第 4 点的具体步骤吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651095/steps-for-forecasting-with-know-copula-parameters</guid>
      <pubDate>Mon, 15 Jul 2024 19:10:53 GMT</pubDate>
    </item>
    <item>
      <title>最佳序列分析和假设检验</title>
      <link>https://stats.stackexchange.com/questions/651093/optimal-sequence-analyses-and-hypothesis-testing</link>
      <description><![CDATA[我正在使用 TraMineR 包处理 R 中的数据。我对这种类型的分析还不太熟悉，所以请耐心等待。
我有一个随时间推移在二元组中发生的唯一事件列表（例如：A-F）。我使用 TraMineR 来识别二元组中的聚类模式。最终，我想知道这些聚类是否预测了二元组之间发生事件 Y 的频率（事件 Y 未包含在序列中）。我想我可以使用某种回归方法，但有人能确认这种方法是否合适或哪种回归方法最好吗？
我还在考虑使用生存分析来分析事件发生所需的时间（例如，从事件 A 到 B、从 B 到 C 的过渡...）以及序列成员如何影响该时间范围。同样，我想知道这是否是适合此数据的测试]]></description>
      <guid>https://stats.stackexchange.com/questions/651093/optimal-sequence-analyses-and-hypothesis-testing</guid>
      <pubDate>Mon, 15 Jul 2024 18:20:53 GMT</pubDate>
    </item>
    <item>
      <title>根据中位数和 IQR 值估计平均值和 SD</title>
      <link>https://stats.stackexchange.com/questions/651092/estimating-mean-and-sd-given-the-median-and-iqr-values</link>
      <description><![CDATA[根据中位数和 IQR，可以估算平均值和 SD 吗？我参与了一项荟萃分析，其中一些试验将结果显示为平均值和标准差，但大多数显示中位数和分位数间距。]]></description>
      <guid>https://stats.stackexchange.com/questions/651092/estimating-mean-and-sd-given-the-median-and-iqr-values</guid>
      <pubDate>Mon, 15 Jul 2024 18:18:53 GMT</pubDate>
    </item>
    <item>
      <title>差异对数水平回归的弹性</title>
      <link>https://stats.stackexchange.com/questions/651090/elasticity-from-differenced-log-level-regression</link>
      <description><![CDATA[我有回归
$ \Delta \ln Y_i = \alpha + \beta \Delta X_i + \varepsilon_i $
其中 $\Delta \ln Y_i = \ln Y_{t,i} - \ln Y_{t-1,i}$ 和 $\Delta X_i = ((X_{t,i} - X_{t-1,i}) / T_{t-1,i} ) \cdot 100$。T 是总人口，X 是子集，i 是地区。
假设 $\beta$ 为 -0.073。我对半弹性的解释是，X 相对于基线 T 增加 1 个百分点会导致 Y 下降 7.3%。（这是正确的吗？）
问题：我如何才能消除弹性？也许可以将 $\beta$ 除以 $\Delta X_i$ 的平均值？]]></description>
      <guid>https://stats.stackexchange.com/questions/651090/elasticity-from-differenced-log-level-regression</guid>
      <pubDate>Mon, 15 Jul 2024 17:54:26 GMT</pubDate>
    </item>
    <item>
      <title>样本量：集群随机试验</title>
      <link>https://stats.stackexchange.com/questions/651088/sample-size-cluster-randomized-trials</link>
      <description><![CDATA[我寻求同行对我计算配对或分层集群随机试验样本量的方法进行检查，假设功效为 80%。
研究背景：我正在与传染病研究人员合作设计一项集群随机试验，以比较新消毒方法与常规护理在降低聚集环境（军营、船只等）传染病发病率方面的效果。这项研究可以显著影响这些环境中的传染病控制策略。
随机化的单位是一艘船或一个排，因此他们将在单个士兵/水手级别衡量结果。
问题在于：这项研究不会使用简单的随机单位样本。相反，它将根据大小和其他特征对单位进行配对，并将每对中的一个单位随机分配到干预措施中。如果这不是最好的方法，研究将根据这些特征对单位进行分层，并将每层中的一半单位随机分配到干预组中。
欢迎您对我在 R 中的方法提出建议，如下所示。我的方法基于 Hayes 和 Bennett (1999) 中描述的方法，并针对配对或分层进行了调整。
我感觉研究小组需要向我提供更多详细信息，因此我对参数 expected_effect、icc、cv、mean_cluster_size、incidence_control 做了一些假设。
配对和分层方法 (n = 1200) 得出的样本量似乎有点高，因此计算一系列合理样本量可能是明智之举值。
此查询已交叉发布此处。
calculate_sample_size &lt;- function(design = c(&quot;pair-matched&quot;, &quot;stratified&quot;),
n_strata = 1,
alpha = 0.05,
power = 0.80,
expected_effect = 0.1,
icc = 0.01, # 组内相关系数
cv = 0.25, # 变异系数
mean_cluster_size = 100,
incident_control = 0.1) { # 对照组的预期发生率

design &lt;- match.arg(design)

#计算 z 分数
z_alpha &lt;- qnorm(1 - alpha/2)
z_beta &lt;- qnorm(power)

# 计算 k（每臂的簇数）
if (design == &quot;pair-matched&quot;) {
# 对于成对匹配设计
k &lt;- 1 + (z_alpha + z_beta)^2 * (1 + (mean_cluster_size - 1) * icc) * 
(incidence_control * (1 - incident_control) + 
(incidence_control + expected_effect) * (1 - (incidence_control + expected_effect))) / 
(mean_cluster_size * expected_effect^2)
} else {
# 对于分层设计
k &lt;- 1 + (1 + cv^2) * (z_alpha + z_beta)^2 * 
(incidence_control * (1 - 发生率控制) + 
(发生率控制 + 预期效应) * (1 - (发生率控制 + 预期效应))) / 
(平均簇大小 * 预期效应^2)
}

# 四舍五入到最接近的偶数
k &lt;- ceiling(k / 2) * 2

# 调整分层
if (design == &quot;stratified&quot;) {
k &lt;- ceiling(k / n_strata) * n_strata
}

# 计算簇总数和样本大小
total_clusters &lt;- k * 2 # 乘以 2 得到两个组
total_sample_size &lt;- total_clusters * 平均簇大小

# 计算可检测效应大小
if (design == &quot;pair-matched&quot;) {
detectable_effect &lt;- sqrt((z_alpha + z_beta)^2 * (1 + (mean_cluster_size - 1) * icc) * 
(incidence_control * (1 - incident_control) * 2) / 
(k * mean_cluster_size))
} else {
detectable_effect &lt;- sqrt((1 + cv^2) * (z_alpha + z_beta)^2 * 
(incidence_control * (1 - incident_control) * 2) / 
(k * mean_cluster_size))
}

# 准备结果
results &lt;- list(
design = design,
n_strata = if(design == &quot;stratified&quot;) n_strata else NULL,
total_clusters = total_clusters,
clusters_per_arm = total_clusters / 2,
total_sample_size = total_sample_size,
detectable_effect = detectable_effect
)

return(results)
}

# 示例用法
pair_matched_result &lt;- calculate_sample_size(&quot;pair-matched&quot;, expected_effect = 0.1)
stratified_result &lt;- calculate_sample_size(&quot;stratified&quot;, n_strata = 3, expected_effect = 0.1)

# 打印结果
print(pair_matched_result)
print(stratified_result)
]]></description>
      <guid>https://stats.stackexchange.com/questions/651088/sample-size-cluster-randomized-trials</guid>
      <pubDate>Mon, 15 Jul 2024 16:42:52 GMT</pubDate>
    </item>
    <item>
      <title>视觉模拟量表与李克特评分量表 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/651071/visual-analogue-scales-vs-likert-rating-scale</link>
      <description><![CDATA[您能用简单的术语描述一下视觉模拟量表和 LIKERT 评分量表之间的区别吗？如果我有一个基于这两个量表的两个问题，我可以确定每个问题分数的平均值和标准差吗？（我的意思是，我可以计算 Likert 评分量表的平均值吗）？最后，对于元分析，如果使用视觉模拟量表（10 个量表）测量相同的问题（来自两个不同的出版物），而第二个问题使用五个 Likert 评分量表，我该如何标准化信息？]]></description>
      <guid>https://stats.stackexchange.com/questions/651071/visual-analogue-scales-vs-likert-rating-scale</guid>
      <pubDate>Mon, 15 Jul 2024 13:27:29 GMT</pubDate>
    </item>
    <item>
      <title>珍珠干预配方？</title>
      <link>https://stats.stackexchange.com/questions/651065/pearl-intervention-formula</link>
      <description><![CDATA[给定因果图$(Z\to X$, $Z\to Y$, $X\to Y)$，根据Pearl的干预，干预$X$对$Y$的影响可以估计为
$$P(Y=y|\operatorname{do}(X=x)) = \sum_z P(Y=y|X=x,Z=z)\,P(Z=z).$$
关于这个公式，我有以下2个问题：


如果对于$Z=z^*,$ $\text{count}(X=x,Z=z^*)=0,$ 我们是否设置 $P(Y=y│X=x,Z=z^*)=0?$
在 $P(z^*)$ 很大但只有一个实例同时存在 $Z=z^*$ 和 $X=x$ 的情况下，即 $\text{count}(X=x,Z=z^* )=1,$ 我们是否写 $P(Y=y│X=x,Z=z^*)=1?$


$P(Y=y│X=x,Z=z^*)\,P(Z=z^*)$ 项是否会主导 $P(Y=y│\operatorname{do}(X=x))?$ 的估计，这是该估计中的问题吗？
上述问题通过以下数据进行演示。与问题相关的项在等式中以粗体显示。在此数据中，$X\in\{0,1\},Y\in\{0,1\}$ 和 $Z\in\{z_1,z_2,z_3\}$。

为了分析 $X$ 对 $Y$ 的因果效应，我们估计平均因果效应 (ACE)：
\begin{align*}
P(Y=1│\operatorname{do}(X=1))
&amp;=P(Y=1│X=1,Z=z_1)\cdot P(Z=z_1)\\
&amp;\quad+P(Y=1│X=1,Z=z_2)\cdot P(Z=z_2)\\
&amp;\quad+P(Y=1│X=1,Z=z_3)\cdot P(Z=z_3)\\
&amp;=1/4\times 5/10+ 0/1\times 3/10+\mathbf{0/0}\times 2/10,\\
P(Y=1│\operatorname{do}(X=0))
&amp;=P(Y=1│X=0,Z=z_1)\cdot P(Z=z_1)\\
&amp;\quad+P(Y=1│X=0,Z=z_2)\cdot P(Z=z_2)\\
&amp;\quad+P(Y=1│X=0,Z=z_3)\cdot P(Z=z_3)\\
&amp;=\mathbf{1/1\times 5/10}+ 1/2\times 3/10+2/2\times 2/10.
\end{align*&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/651065/pearl-intervention-formula</guid>
      <pubDate>Mon, 15 Jul 2024 11:20:02 GMT</pubDate>
    </item>
    <item>
      <title>“两步”结构方程模型中的调节中介作用</title>
      <link>https://stats.stackexchange.com/questions/651030/moderated-mediation-in-a-two-step-structural-equation-model</link>
      <description><![CDATA[有人能帮我弄清楚如何在下面的结构方程模型 (SEM) 中加入调节器吗？
这是一个“两步”模型，因为有两个因果关系，一个从孤儿 (链接 1) 到贫困/虐待 (链接 2)，另一个从这些中介变量到最终结果，抑郁 (链接 3)。
我想在链接 2 处加入一个调节器，即年龄贫困。（为了清楚起见，我没有在图表中包含单个“年龄”变量）。我无法包括年龄贫困与贫困之间的协方差，因为贫困是一个因变量，但如果我不考虑它们的相互关系，规范将不正确。
有人能帮我提供适当的参考资料吗？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651030/moderated-mediation-in-a-two-step-structural-equation-model</guid>
      <pubDate>Sun, 14 Jul 2024 17:40:55 GMT</pubDate>
    </item>
    <item>
      <title>对大小为 61,000 的数据集执行完全匹配的可能解决方案有哪些？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651017/what-are-the-possible-solutions-for-performing-full-matching-on-a-dataset-with-a</link>
      <description><![CDATA[我正在处理一个包含大约 61,000 个观测值的数据集（其中 27,686 个为治疗组，32,405 个为对照组），需要使用 R 中的 MatchIt 包执行完全匹配。我遇到了性能问题和冗长的计算时间。这是我得到的错误
`matchit()` 中的错误：！（来自 optmatch）结果将超过 2^31-1 字节。运行 `rlang::last_trace()` 以查看错误发生的位置。
在如此大的数据集上使用 MatchIt 执行完全匹配的潜在解决方案或最佳实践是什么？具体来说，我正在寻找优化匹配过程的方法或可以有效处理大型数据集的替代方法。
任何有关参数调整、并行处理或其他可以提高 MatchIt 中完全匹配性能的技术的建议都将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651017/what-are-the-possible-solutions-for-performing-full-matching-on-a-dataset-with-a</guid>
      <pubDate>Sun, 14 Jul 2024 11:27:16 GMT</pubDate>
    </item>
    <item>
      <title>我可以将数据增强应用于测试集吗？</title>
      <link>https://stats.stackexchange.com/questions/650992/can-i-apply-data-augmentation-to-the-test-set</link>
      <description><![CDATA[我正在处理一个包含 102 行（表格数据）的数据集，其中 91 行用于训练，11 行用于测试。我通过为训练集添加高斯噪声来使用数据增强。假设我做了所有正确的预处理（没有数据泄露），那么科学出版物将数据增强应用于我的测试集是否正确/可以接受，因此它可以大于 11 行？]]></description>
      <guid>https://stats.stackexchange.com/questions/650992/can-i-apply-data-augmentation-to-the-test-set</guid>
      <pubDate>Sat, 13 Jul 2024 21:47:42 GMT</pubDate>
    </item>
    </channel>
</rss>