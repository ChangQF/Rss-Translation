<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 10 Jun 2024 09:17:17 GMT</lastBuildDate>
    <item>
      <title>标准差的最大似然法</title>
      <link>https://stats.stackexchange.com/questions/648950/maximum-likelihood-of-standard-deviation</link>
      <description><![CDATA[我试图更好地理解样本标准差的分布和不确定性。由于我不是数学家，我尝试将数学文献与一些模拟结果进行比较。
我做了一个相当简单的模拟研究，首先假设 X∼N(μ,σ²)。我从这个分布中抽样三次并估计样本方差。
我使用估计的样本方差并模拟卡方分布以获得方差的上限和下限 95% CI。（我知道，我可以通过取分布的分位数而不模拟结果来做到这一点，但出于比较的原因，我希望得到分布）。我取这些结果的平方根并将它们与总体标准差进行比较。通过重复这种方法 2,500 次，我可以显示样本标准差的 95% 置信区间的覆盖率约为 95%。这就是我所期望的。
不过，我还对 2,500 个卡方分布的众数取了平均值，取了平方根，并将该值与平均样本方差的平方根进行了比较。
众所周知，方差是真实总体方差的无偏估计量，我得到了 1 作为结果。但是，平均模式的平方根导致结果约为 0.77。
为了更好地理解这一点，我绘制了模拟 2500 的卡方分布，并将该分布的模式与样本方差（红线）进行了比较。

模式和估计的样本方差之间存在明显偏差。我的下一个想法是，这可能与最大似然 (ML) 与受限最大似然估计 (REML) 有关。所以，我做了一个小改动。我没有将样本方差乘以 n-1，而是将其乘以 n，然后重复该过程。
var_sim &lt;- (n-1)*sample_var[i]/rchisq(n = n_sim, df = n-1)
对比
var_sim &lt;- (n)*sample_var[i]/rchisq(n = n_sim, df = n-1)
样本方差的预期值再次为 1，平均模式的平方根约为 0.95，现在更接近预期值 1。然而，这带来了覆盖率损失（89%）的代价。

我预计卡方分布的众数/最大似然估计量应该与样本方差一起下降。然而，这两种方法都不是这种情况。我想，我对 ML 估计量和卡方样本分布的模式有一个根本性的误解，我希望有人能解释一下我的问题。
这里是重现我的结果的代码：
set.seed(09062024)

result_var &lt;- NULL
sd_qt_upper &lt;- NULL
sd_qt_lower &lt;- NULL
sd_mean &lt;- NULL
sd_mode &lt;- NULL
sample_var &lt;- NULL

n_sim &lt;- 2500
n &lt;- 3

for(i in 1:n_sim){
x &lt;- rnorm(n = n, 0,1)
sample_var[i] &lt;- var(x)

var_sim &lt;- (n-1)*sample_var[i]/rchisq(n = n_sim, df = n-1)

sd_qt_lower[i] &lt;- sqrt(quantile(var_sim, probs = 0.025)) 
sd_qt_upper[i] &lt;- sqrt(quantile(var_sim, probs = 0.975))
sd_mean[i] &lt;- sqrt(mean(var_sim))
var_density_temp &lt;- density(var_sim, n = n_sim, from = 0, to = 10 )
sd_mode[i] &lt;- sqrt(var_density_temp[[&quot;x&quot;]][which(var_density_temp[[&quot;y&quot;]]==max(var_density_temp[[&quot;y&quot;]]))])
}

coverage_sd &lt;- sd_qt_upper&gt;1&amp;sd_qt_lower&lt;1
mean(coverage_sd) #覆盖率
mean(sd_mean) #基于每个卡方分布和模拟轮次的预期值的预期值
sqrt(mean(sample_var)) #基于初始 var 计算的预期值
mean(sd_mode) #基于模拟模式的预期值

#plot
plot(var_density_temp, main = paste(&quot;chi square distribution simulation:&quot;, i, &quot;\n Mode = &quot;, 
round(var_density_temp[[&quot;x&quot;]][which(var_density_temp[[&quot;y&quot;]]==max(var_density_temp[[&quot;y&quot;]]))],2),
&quot;\n 样本方差 = &quot;, round(sample_var[n_sim], 2)))
abline(v = sample_var[n_sim], col = &quot;red&quot;, lwd = 2)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648950/maximum-likelihood-of-standard-deviation</guid>
      <pubDate>Mon, 10 Jun 2024 08:07:12 GMT</pubDate>
    </item>
    <item>
      <title>计算结果的标准差</title>
      <link>https://stats.stackexchange.com/questions/648949/standard-deviation-on-result-of-calculation</link>
      <description><![CDATA[我正在根据实验数据计算一个值。计算结果为
$$ k = \frac{a - b}{c} \cdot \frac{1}{T}, $$
并且 $a$、$b$ 和 $c$ 都是通过多次实验测量的，样本之间会有一些差异，并且 $T$ 是一个常数。它们也是独立测量的，因此即使我碰巧有 $a$、$b$ 和 $c$ 各 $N$ 个值，我也不能说它们在三元组中彼此“属于”对方，或诸如此类。
计算结果 $k$ 中的标准差的正确方法是什么？我相信我不能完全不合理地假设 $a$、$b$ 和 $c$ 服从正态分布。
（我尝试从 $a$、$b$ 和 $c$ 的不同值的所有排列中计算 $k$。假设 $N = 4$，那么我就有 $4 \times 4 \times 4 = 64$ 种不同的组合，我可以用来计算 $k$，并且然后我就可以取其标准差。不过，这感觉有点像黑客行为，所以一些理论见解会很好。）]]></description>
      <guid>https://stats.stackexchange.com/questions/648949/standard-deviation-on-result-of-calculation</guid>
      <pubDate>Mon, 10 Jun 2024 07:59:51 GMT</pubDate>
    </item>
    <item>
      <title>使用哪些数据来确定医学诊断测试的最终阈值？</title>
      <link>https://stats.stackexchange.com/questions/648946/what-data-are-used-to-find-the-final-threshold-for-a-medical-diagnostic-test</link>
      <description><![CDATA[假设我有一些血液测量值 X，其值与某种疾病 Y 相关（因此患有该疾病的人通常具有较大的 X 值）。此外，假设该疾病很罕见，占人口的 1%。
现在我想开发一种新的医学诊断测试。
我应该从 1000 名健康和 1000 名不健康的人中计算阈值，还是应该将计数与人口计数相对应（例如 100 名患病者和 10 000 名健康人），因为在这两种情况下，找到的最佳阈值都会不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/648946/what-data-are-used-to-find-the-final-threshold-for-a-medical-diagnostic-test</guid>
      <pubDate>Mon, 10 Jun 2024 06:51:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么真正无信息的先验不存在？</title>
      <link>https://stats.stackexchange.com/questions/648945/why-a-truly-uninformative-prior-does-not-exist</link>
      <description><![CDATA[据说，没有真正无信息的先验。
例如，这里。
问：

是否已经证明不存在真正无信息的先验，或者仅仅是没有发现这样的先验？

如果已经证明，那么为什么真正无信息的先验不可能存在的概念解释是什么？

]]></description>
      <guid>https://stats.stackexchange.com/questions/648945/why-a-truly-uninformative-prior-does-not-exist</guid>
      <pubDate>Mon, 10 Jun 2024 06:18:35 GMT</pubDate>
    </item>
    <item>
      <title>如何对电力系统的144个数据集和4个输入参数进行多元分析和可视化？</title>
      <link>https://stats.stackexchange.com/questions/648942/how-to-do-multivariate-analysis-and-visualization-for-144-datasets-and-4-input-p</link>
      <description><![CDATA[我正在为研究建模和模拟微电网。我修改了模拟的 4 个输入参数，以便观察它产生的不同结果。为了明确起见，我将在下面描述设置。
输入特性：

太阳能容量（0 kW、200 kW、400 kW）
电池大小（0 kWh、800 kWh、1600 kWh、2400 kWh）
电动汽车充电器数量（0、5、10）
控制算法（控制算法 #1、控制算法 #2、控制算法 #3、控制算法 #4）

每个模拟都是这些特性的变体，例如：（太阳能 200 kW、电池 1600 kWh、电动汽车充电器数量 10、控制算法 # 3）。这就是为什么有 144 次模拟。
每次模拟都是一个为期一年的时间序列，分辨率为 5 分钟。输出数据为：

时间戳（每 5 分钟一个 [我使用重采样来实现此目的]）
功率输出 (kW)
温室气体排放量 (mTons)
电力成本 ($)

我进行此实验的目的是查看控制算法对输出参数的影响。但是，我改变了其他输入参数，以便更有力地证明我得出的关于控制算法的结论是始终可见的，而不仅仅是异常。
我遇到的困境是如何最好地分析和可视化这些数据：
在我进行这个大型实验之前，我会做一些较小的实验，其中我会改变 1-2 个参数，总共进行 6-8 次模拟。在这种情况下，使用相关系数或线性回归可以达到我的目的。我读过关于多元分析的不同方法，但我不确定哪种方法最适合我上面提到的实验（多元协方差分析、典型相关分析、聚类等）。哪种方法是最佳实践，最好是可以用 Python 实现的方法？
至于数据可视化，我将对每个模拟使用箱线图，这些箱线图针对时间序列数据单独标记，或者当我将数据平均为每个模拟一个数据点时使用散点图（例如：年度温室气体排放量（mTons）6-8 个数据点）。我可以轻松改变图表中的 1 或 2 个特征，以轻松查看模式。我不确定可视化这些数据的好方法是什么。我正在考虑显示 4 个子图，其中我改变一个特征，并在 3d 图中绘制其他 3 个子图，其中颜色变化以显示每个模拟图（总共 144 个数据点）单个数据点的输出数据（温室气体等）。我不知道如何在用户可以进行 144 次模拟的地方显示四分位数数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/648942/how-to-do-multivariate-analysis-and-visualization-for-144-datasets-and-4-input-p</guid>
      <pubDate>Mon, 10 Jun 2024 06:12:08 GMT</pubDate>
    </item>
    <item>
      <title>与收敛序列相同的极限是否意味着收敛？[迁移]</title>
      <link>https://stats.stackexchange.com/questions/648939/same-limit-as-convergent-sequence-implied-convergency</link>
      <description><![CDATA[假设 {x} 是收敛序列，并且 {y} 是这样的：对于任何 e &gt; 0，都存在 M，使得 |x - y| &lt; e 对所有 n&gt;=M。这是否意味着 {y} 是收敛的？
我的方法如下：
由于 |x - y| &lt; e 意味着 lim x = lim y。
由于 {x} 已经收敛，并且从上面直观地看出，当 n 趋近于无穷大时，{x} 和 {y} 之间的差距必须减小，我们可以从这里得出结论，{y} 也必须收敛吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648939/same-limit-as-convergent-sequence-implied-convergency</guid>
      <pubDate>Mon, 10 Jun 2024 03:04:36 GMT</pubDate>
    </item>
    <item>
      <title>在 ADF 测试中，如何指定非线性？</title>
      <link>https://stats.stackexchange.com/questions/648934/in-adf-test-how-do-i-specify-non-linearity</link>
      <description><![CDATA[我有一个时间序列，表现出非线性关系，在经济衰退期间会下降。我想执行增强迪基富勒检验来测试单位根/平稳性。我不确定我是否必须在 ADF 测试中考虑这一点，或者如何考虑这一点，据我所知，如果我们不考虑非线性，拒绝零假设就会变得困难。
我试图用 python 编写代码，statstools 中的 adfuller 函数似乎无法适应非线性，它只允许指定滞后数。
这引出了我的下一个问题：我是否还必须确保在我的 ADF 测试中正确指定滞后数？]]></description>
      <guid>https://stats.stackexchange.com/questions/648934/in-adf-test-how-do-i-specify-non-linearity</guid>
      <pubDate>Mon, 10 Jun 2024 00:30:42 GMT</pubDate>
    </item>
    <item>
      <title>考虑分类问题中的非对称损失函数</title>
      <link>https://stats.stackexchange.com/questions/648926/taking-into-account-a-non-symmetric-loss-function-in-a-classification-problem</link>
      <description><![CDATA[
考虑一种二元分类方法，该方法估计类别概率，并且可以指定观察权重（例如 Logistic 回归）。为了适应 TP 和 FP 的差异损失，哪种方法效果更好：

1a) 不要指定权重。相反，调整概率阈值，直到结果从客户端的角度来看看起来不错。
1b) 将概率阈值固定在 0.5 并调整权重。

考虑一个问题，其中响应有超过 2 个类别，并且损失函数取决于观察被错误分类的确切程度。例如，将 1 误分类为 5 比将 1 误分类为 2 损失更大。

2a) 我理解的对吗？仅通过指定观察权重就不可能容纳这种损失函数？
2b) 如果 2a) 的答案是肯定的，您可以推荐什么免费软件来解决该问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/648926/taking-into-account-a-non-symmetric-loss-function-in-a-classification-problem</guid>
      <pubDate>Sun, 09 Jun 2024 21:06:27 GMT</pubDate>
    </item>
    <item>
      <title>如何使用少量数据集来改进模型？[重复]</title>
      <link>https://stats.stackexchange.com/questions/648923/how-to-improve-a-model-with-little-dataset</link>
      <description><![CDATA[我有一个包含 20 个特征和 65 个样本的数据集。我进行了数据缩放。我还以不同的方式进行了特征选择。但这是结果。
测试集评估：
_____________________________________
MAE：2.3462910007887787
MSE：8.68486045116839
RMSE：2.947008729401457
R2平方0.11298965960629503
__________________________________
训练集评估：
_____________________________________
MAE：1.9746175830150061
MSE：6.369273380984405
RMSE：2.5237419402514996
R2平方0.45535061890623796
__________________________________
adj r2 train 0.4008856807968617
adj r2 test -0.12354643116535957 

我研究过不同的模型，最好的结果是线性模型，比如线性回归。你有办法改进模型和结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648923/how-to-improve-a-model-with-little-dataset</guid>
      <pubDate>Sun, 09 Jun 2024 20:42:50 GMT</pubDate>
    </item>
    <item>
      <title>通过 MLE 估计参数与最小化期望偏差之间有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/648914/what-is-the-difference-between-estimating-parameters-via-mle-versus-minimizing-d</link>
      <description><![CDATA[使用 MLE（或具有均匀先验的 MAP）估计参数与使用 MLE（或具有均匀先验的 MAP）估计参数之间有什么区别：
$$\theta^* = \arg \max_\theta p(X|\theta)$$
根据哪种设置估计它们会导致我们的测量数据与基于这些参数的预期之间的偏差最小？也就是说，
$$\theta^* = \arg \min_\theta ||\,\bar{X} - \mathbb E_{p(X|\theta)}[X|\theta]\,||.$$
这是一个例子。我有一枚可能有偏差的硬币（$\theta = p(H) \in \lbrace{0.25, 0.50, 0.75\rbrace}$），但您不知道是哪一枚。我将其抛 $1000$ 次，看到 $625$ 个正面。我们想要估计$\theta$。
爱丽丝说，“嗯，当$\theta = \lbrace{0.25, 0.50, 0.75\rbrace}$时，看到$625$个正面的概率分别为$3.8 \times 10^{-138}、0.5 \times 10^{-19}$和$7.4 \times 10^{-19}$。 $\theta = 0.75$ 最大化二项概率给出的 $\mathscr L = p(X|\theta)$ 可能性，所以这是我的猜测。&quot;
Bob 说，“如果 $\theta$ 是 $\theta = \lbrace{0.25, 0.50, 0.75\rbrace}$，那么我们分别会预期看到 $250$、$500$ 和 $750$ 正面。 $0.5$ 和 $0.75$ 最小化了我们看到的结果与预期结果之间的偏差，因此我对这些结果的猜测无所谓。&quot;
Bob 的参数估计风格有名字吗？他的方法有问题吗？它有任何统计保证吗？当然，人们可以将他的算法视为针对损失函数 $L = (\bar{X} - \mathbb E_{\mathscr L}[X|\theta])^2$ 的优化，但我想知道这是否是一种具有直观概率公式的合理方法（就像 OLS 中的 MSE 损失和高斯似然一样）。]]></description>
      <guid>https://stats.stackexchange.com/questions/648914/what-is-the-difference-between-estimating-parameters-via-mle-versus-minimizing-d</guid>
      <pubDate>Sun, 09 Jun 2024 19:05:08 GMT</pubDate>
    </item>
    <item>
      <title>$E[X\mid \max(X,Y,Z)]$ 带有因变量 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648896/ex-mid-maxx-y-z-with-dependent-variables</link>
      <description><![CDATA[设$(X,Y,Z)$为三维随机变量，其密度函数为$f(x,y,z)=\frac{2}{3}(x+y+z)$在$0&lt;x,y,z&lt;1$上。计算$E[X\mid \max(X,Y,Z)]$。
我认为答案是$\frac{25}{36}\max(X, Y, Z)$，但我不确定：
\begin{gather*}
E[X\mid \max(X,Y,Z)=u]=\\
=\frac{\int_0^u\int_0^u uf(u,y,z)dydz+\int_0^u\int_0^u xf(x,u,z)dxdz+\int_0^u\int_0^u xf(x,y,u)dxdy}{\int_0^u\int_0^u f(u,y,z)dydz+\int_0^u\int_0^u f(x,u,z)dxdz+\int_0^u\int_0^u f(x,y,u)dxdy}
\end{gather*&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/648896/ex-mid-maxx-y-z-with-dependent-variables</guid>
      <pubDate>Sun, 09 Jun 2024 09:13:22 GMT</pubDate>
    </item>
    <item>
      <title>emmeans 中交互作用中缺少类别，我可以获得某个因子水平的全局边际均值吗？</title>
      <link>https://stats.stackexchange.com/questions/648947/missing-category-in-an-interaction-in-emmeans-can-i-obtain-the-global-marginal</link>
      <description><![CDATA[我有一个数据集，其中的测量值来自五个不同城市的两种环境。在其中一个城市，我们无法获得其中一个环境的测量值。运行 emmeans 时，我得到了该城市该环境的预期非估计边际均值。见下文：
 environment city_key emmean SE df lower.CL upper.CL
R C 3.20 0.472 210 2.266 4.13
U C 2.98 0.472 210 2.047 3.91
R K 4.61 0.609 210 3.408 5.81
U K 3.13 0.677 210 1.794 4.46
R M 3.85 0.666 210 2.534 5.16
U M nonEst NA NA NA NA
R T 1.93 0.518 210 0.904 2.95
U T 1.95 0.509 210 0.952 2.96
R V 2.78 0.354 210 2.080 3.47
U V 3.32 0.879 210 1.586 5.05

但是，我也想获得仅来自环境的边际均值，但由于我缺少其中一个，因此其中一个环境结果不是估计值。这就是 emmeans 的工作方式，据我所知。
 environment emmean SE df lower.CL upper.CL
R 3.27 0.231 210 2.81 3.73
U nonEst NA NA NA NA

我知道 emmeans 的警告（“由于涉及相互作用，结果可能会产生误导”），解决方案是删除我的两个因素之间的相互作用（已经尝试过，并且有效，但是......），但在我看来，相互作用的生物学意义及其解释很重要。
主要是，我想要结果的原因是由于标准误差和置信区间，我不确定如何手动计算边际均值。
有没有办法让 emmeans 输出结果，尽管我的模型中存在明显的漏洞数据？或者我手动计算边际均值的方法？或者有其他解决方案吗？
除了消除模型中的交互作用。我尝试了 ggeffects 中的 predict_response，使用 margin=marginalmeans 和 margin=empirical，但这些结果不同，我认为边际均值是我想要的结果。我也尝试过手动获得边际均值，只需从预测值中计算它们即可，但我不知道如何从它们中计算标准误差或置信区间——说到这个话题，如果我使用混合模型，这一切会有所不同吗？
我没有包含任何内容来重现我的结果，因为我认为我的问题很简单。如果您对我的观察次数感兴趣，这里有一个表格，列出了每个类别的观察次数（以及为什么我没有对 city_keyM:environmentU 进行估计）：
 city_key environment obs
&lt;fct&gt; &lt;fct&gt; &lt;int&gt;
1 C R 25
2 C U 35
3 K R 13
4 K U 10
5 M R 15
6 M U 0
7 T R 23
8 T U 22
9 V R 72
10 V U 16
]]></description>
      <guid>https://stats.stackexchange.com/questions/648947/missing-category-in-an-interaction-in-emmeans-can-i-obtain-the-global-marginal</guid>
      <pubDate>Sat, 08 Jun 2024 20:43:17 GMT</pubDate>
    </item>
    <item>
      <title>多元荟萃分析中的稳健方差估计或聚类野生引导法</title>
      <link>https://stats.stackexchange.com/questions/648831/robust-variance-estimation-or-cluster-wild-bootstrapping-on-a-multivariate-meta</link>
      <description><![CDATA[Cliffnotes
我可以在非元回归的元分析模型中使用 RVE 或 Cluster Wild Bootstrapping 吗？
问题
我正在进行三级元分析，研究特定心理治疗干预（与比较器相比）对许多精神症状领域的影响。请参阅以下模型：
full.model &lt;- rma.mv(yi = es, 
V = var, 
slab = study,
data =pression,
random = ~ 1 | study/es.id, 
test = &quot;t&quot;, 
method = &quot;REML&quot;)

在这种情况下，效果大小嵌套在研究集群中。我知道这些影响是相关的，因为它们都是从同一样本中提取的，我想通过使用 RVE 并估算一个常数相关协方差矩阵来解释这种依赖关系，如下所示：
rho &lt;- 0.7
V.7 &lt;- with(depression, 
impute_covariance_matrix(vi = var,
cluster = study,
r = rho))

che.model.7 &lt;- rma.mv(yi = es,
V = V.7,
random = ~ 1 | study/es.id,
data =pression,
sparse = TRUE)

然后我一直在使用 clubSandwich 包来计算集群稳健推断统计数据，例如 SE、Sattherwaithe-df 调整后的 95% CI 和 p 值。我读过的所有文献都给我这样的印象：这只能在元回归模型上完成，我担心我的应用可能不合适，原因我目前还不理解。此外，由于我的样本量很小，只有 13 项研究和 26 个效应，我担心这种形式的 RVE 可能会夸大 I 型错误，导致统计数据过于保守。
我想使用 wildmeta 通过 cluster wild bootstrapping 来估计这些依赖关系，但我无法使用该包来生成估计值，这再次让我担心这仅适用于具有多个系数的元回归模型。
请帮助我理解非回归多元元分析模型中依赖关系的解释。s]]></description>
      <guid>https://stats.stackexchange.com/questions/648831/robust-variance-estimation-or-cluster-wild-bootstrapping-on-a-multivariate-meta</guid>
      <pubDate>Fri, 07 Jun 2024 15:41:05 GMT</pubDate>
    </item>
    <item>
      <title>通过变异函数实现空间相关性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648813/spatial-correlation-via-variogram</link>
      <description><![CDATA[我根据我的数据（1800 个观测值）制作了一个变异函数来检测空间相关性，并得到了以下结果：

我的问题是：

该图是否表明不存在空间相关性？
每个位置都有多个观测值（时间序列）。这会影响变异函数吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648813/spatial-correlation-via-variogram</guid>
      <pubDate>Fri, 07 Jun 2024 11:36:29 GMT</pubDate>
    </item>
    <item>
      <title>均匀分布矩法</title>
      <link>https://stats.stackexchange.com/questions/638337/method-of-moments-of-uniform-distribution</link>
      <description><![CDATA[设$x_1=2, x_2 = 1, x_3 = \sqrt5, x_4 = \sqrt2$为服从均匀分布$U(-\theta, \theta)$的大小为 4 的随机样本的观测值，其中$\theta&gt;0$。那么$\theta$的矩估计值是多少？
a) 1
b) 2
c) 3
d) 4
我处理这个问题的方法是：
第一种矩估计值是$\bar{X}$ = $\sum X_i/n$ = ($2+1+\sqrt5+\sqrt2)/4 = 1.66$。
$U(-\theta, \theta)$的期望值 = ($-\theta+\theta)/2 = 0$。我无法进一步解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/638337/method-of-moments-of-uniform-distribution</guid>
      <pubDate>Thu, 01 Feb 2024 18:34:22 GMT</pubDate>
    </item>
    </channel>
</rss>