<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 29 Jan 2024 03:15:04 GMT</lastBuildDate>
    <item>
      <title>可能性和概率</title>
      <link>https://stats.stackexchange.com/questions/637977/likelihood-and-probability</link>
      <description><![CDATA[据我了解，概率是固定分布下的区域，可以用数学方式表达给定分布的数据概率：$$P(Data|Distribution)$$
而可能性是具有可移动分布的固定数据点的 y 轴值。所以，从数学上来说
$$L(分布|数据)$$
如果上述情况成立，那么当我试图找到指数分布的可能性时为什么是： $$P(X_{1},X_{2},\cdots X_{ n}|\lambda)=P(X_{1}|\lambda)\cdot P(X_{2}|\lambda)\cdots P(X_{n}|\lambda)$$
因此，这意味着给出的是分布，而不是我之前定义的可能性数据。我觉得我对可能性有一个愚蠢的误解。]]></description>
      <guid>https://stats.stackexchange.com/questions/637977/likelihood-and-probability</guid>
      <pubDate>Mon, 29 Jan 2024 03:11:17 GMT</pubDate>
    </item>
    <item>
      <title>Z 分数和拟似然之间的联系？</title>
      <link>https://stats.stackexchange.com/questions/637975/connection-between-z-score-and-quasi-likelihood</link>
      <description><![CDATA[考虑拟似然函数（我在 GEE 上下文中编写它）：
$$ Q(\beta; y) = \sum_{i=1}^{n} (y_i - \mu_i(\beta))^T V_i^{- 1}(\beta, \alpha) (y_i - \mu_i(\beta))$$
地点：

$y_i$ 是第 $i$ 个主题的响应，
$\mu_i(\beta)$ 是 $i$ 的平均响应主题，
$V_i(\beta, \alpha)$ 是 $i$ 的方差函数-第一个主题，
$\beta$ 是固定效果参数，
$\alpha$ 是色散参数。

查看拟似然，我可以看到与 Z 分数（矩阵形式）非常相似的东西：随机变量减去随机变量的期望值除以方差。
这让我想知道 - 拟似然和 Z 分数之间是否存在任何关系？也许拟似然的动机确切形式被选择为相似？这是否与中心极限定理有关 - 即拟似然是渐近正态的，因为它是归一化随机变量的总和？ （我试图自己证明这一点，并将在另一个问题中展示我的工作）]]></description>
      <guid>https://stats.stackexchange.com/questions/637975/connection-between-z-score-and-quasi-likelihood</guid>
      <pubDate>Mon, 29 Jan 2024 00:17:38 GMT</pubDate>
    </item>
    <item>
      <title>如果 OLS 估计器使 MSE 最小化，那么 James-Stein 估计器如何实现更低的 MSE？</title>
      <link>https://stats.stackexchange.com/questions/637973/if-ols-estimator-minimizes-mse-how-does-james-stein-estimator-achieve-a-lower-m</link>
      <description><![CDATA[OLS 估计器解决了以下最小化问题：
$\min ||y-X\beta||^2$
通过采用 FOC，我们获得 $\hat{\beta}$，它最小化了目标函数。
但是 James-Stein 估计器的 MSE 较低。我知道 James-Stein 的证明，但如何将其与 OLS 估计中平方误差损失已最小化这一事实相协调？我在这里缺少什么？
如果 James-Stein 估计器实现了较低的 MSE，为什么我们仍然使用 OLS？虽然 James-Stein 要求分布是正态的，但是根据中心极限定理的某些版本可以满足近似正态性，它不是仍然有用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637973/if-ols-estimator-minimizes-mse-how-does-james-stein-estimator-achieve-a-lower-m</guid>
      <pubDate>Sun, 28 Jan 2024 23:22:26 GMT</pubDate>
    </item>
    <item>
      <title>合并协方差矩阵是 Wishart 吗？</title>
      <link>https://stats.stackexchange.com/questions/637963/is-the-pooled-covariance-matrix-wishart</link>
      <description><![CDATA[如果 $X_1,\ldots,X_{n_x}$ 是 IID $N(\mu_x,\sigma^ 2)$ 和 $Y_1,\ldots,Y_{n_y}$ 是 IID $N(\mu_y ,\sigma^2)$、$S_x^2$ 和 $S_y^2$ 是他们的无偏方差估计，以及
$$
S^2_p = ((n_x-1)S_x^2 + (n_y-1)S_y^2)/(n_x+n_y-2)
$$
是合并方差估计，则 $(n_x+n_y-2)/\sigma^2S^2_p$ 是 $\ chi^2$ 与 $n_x+n_y-2$ df 一起分发。当 $X_i$ 和 $Y_i$ 是具有共同方差的多元法向量时，类似的结果是否成立span 类 =“math-container”&gt;$\Sigma$？合并协方差估计量是否遵循 $n_x+n_y-2$ df 的 Wishart 分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/637963/is-the-pooled-covariance-matrix-wishart</guid>
      <pubDate>Sun, 28 Jan 2024 19:02:55 GMT</pubDate>
    </item>
    <item>
      <title>减去 Wilcoxon 秩和中的理想秩均值，它有什么作用</title>
      <link>https://stats.stackexchange.com/questions/637961/subtracting-the-ideal-rank-mean-in-wilcoxon-rank-sum-what-does-it-do</link>
      <description><![CDATA[我正在阅读 Andy Field 的《使用 R 发现统计》。在关于如何计算 MWU 中的排名统计量的部分中，步骤之一是从排名总和中减去平均排名。
W = 等级总和 - 平均等级
这个想法是，它可以纠正群组中的人数。
但是我们减去的不是总排名的真实平均值，而是理想平均值（有 10 个观测值，总和为 [1+2+...+10]，而实际排名为 1 ,2,3.5,....12，因为关系。
当我们通常从样本中删除均值时，是为了创建居中。这个程序在这种情况下起什么作用？我不是一个数学素养很高的人，所以对正在发生的事情有一些直观的了解会很有帮助
谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/637961/subtracting-the-ideal-rank-mean-in-wilcoxon-rank-sum-what-does-it-do</guid>
      <pubDate>Sun, 28 Jan 2024 18:48:21 GMT</pubDate>
    </item>
    <item>
      <title>数据/观察本身如何有助于我们确定假设是真是假的能力？</title>
      <link>https://stats.stackexchange.com/questions/637955/how-do-data-observations-themselves-contribute-to-our-ability-to-make-determinat</link>
      <description><![CDATA[假设我有一个假设，并且我正在尝试确定该假设是真是假。如果我没记错的话，在统计中，标准的哲学观点是，从技术上讲，我们无法确定假设是真是假，而是证据（数据）是否无法反驳该假设。但是数据/观察本身如何有助于我们做出此类决定的能力呢？特别是，所有创建的数据都是平等的，还是有些数据的贡献不同/具有优越的“解释力”？天真地思考这一点，在我看来，“独立”的数据/观察结果似乎是“独立的”。彼此之间具有较低的相关性，或者彼此之间具有较低的相关性，将具有更强的“解释力”。 /“信号” /“贡献”进行我们的分析/确定假设是真是假？但是，在我的统计推断研究中，我不记得以这种方式讨论/处理数据点/观察结果的事情。这个想法有什么道理吗，还是我错了？如果这个想法有道理，我可以使用哪些好的资源（教科书）来深入研究这个问题？
&lt;小时/&gt;
编辑
我想这个想法也可以被认为是多么“经济”。数据是。因此，举例来说，如果数据是独立的，我就能够使用较少的数据执行一定程度的假设检验，但如果数据是独立的，则要达到相同的准确性水平，则需要更多的数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/637955/how-do-data-observations-themselves-contribute-to-our-ability-to-make-determinat</guid>
      <pubDate>Sun, 28 Jan 2024 17:28:55 GMT</pubDate>
    </item>
    <item>
      <title>随机化有什么魔力？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637953/whats-the-magic-of-randomization</link>
      <description><![CDATA[我读到可以执行 A/B 测试和测试考虑到总体被随机抽样并分配给 A 和 A 的效果大小推断B组。您只需对 B 组进行治疗，并且由于治疗暴露而导致的提升为 B。
听起来好得令人难以置信？我想是的。
假设您有一些具有 100 个随机化单元的总体。您随机选择 50 名作为治疗组。 “100选50”是 10^29 种可能的 A/B 分割；无论您获得哪一组，分割都是“随机”的。并且适合推理（我觉得非常可疑。）
一些变量是连续的，而另一些变量是分类的。对于分类变量，可以进行分层；例如，将 100 个随机化单位的总体划分为全男性和全女性的同质亚群体，随机分配给 A 或 B，然后聚合。 （A-男 &amp; A-女 -&gt; A。）
假设总人口中男性（或女性）的数量为偶数，则可以确保每个性别在 A 组和 A 组中的代表性均等。 B. 这确保了性别与治疗暴露正交，而不是混淆。如果男性的数量是奇数，你会接近正交（足够接近？我不确定。）事实上，在实验后回归模型中，人们可以以性别及其与治疗暴露的相互作用为条件来学习甚至更多 - 万岁！
这个过程可以对所有分类变量重复递归。但不明显的是连续变量的分层。我见过将此类变量分解为分位数（例如：0-10%，...，90-100%），然后处理这些基于分位数的子总体，然后执行与分类变量详细说明相同的过程。
无论如何，对我来说，随机化似乎并不是“这些人群尽可能相似”的可靠机制。因为这将是一个优化问题，而不是一个洗牌问题。
如果我们正在研究的任何指标存在任何不平衡，那么普通 T 检验就不合适。有一些方法可以适应实验前的均值差异，例如差异差异 (DiD)。但这种方法假设了平行趋势假设，这也不能通过洗牌来保证。
从哲学上讲，我认为随机化被过度炒作，因为替代优化问题的计算量太大。
如果有人能够为为什么 A/B 均值不平衡的随机化是可以接受的提供适当的辩护，我非常有兴趣了解更多信息。
编辑：哇这篇文章收到的赞成票和反对票的数量！甚至是近距离的请求……我没有预见到这个问题对于某些学术界来说会有多么两极分化/政治性。]]></description>
      <guid>https://stats.stackexchange.com/questions/637953/whats-the-magic-of-randomization</guid>
      <pubDate>Sun, 28 Jan 2024 17:01:57 GMT</pubDate>
    </item>
    <item>
      <title>对于具有前测-后测和两个因素的序数因变量，应使用哪种检验？</title>
      <link>https://stats.stackexchange.com/questions/637923/which-test-should-be-used-for-an-ordinal-dependent-variable-with-pretest-posttes</link>
      <description><![CDATA[考虑一个测试前-测试后设计，其中因变量 (y) 通过 3 个序数值 1、2、3 进行测量。还有两个因素：一个因素（例如A）由对照组和实验组组成。另一个因素（例如B）由两个年龄组组成。总样本量为 60，其中因素 A 和 B 组的每种可能组合都有 15 个受试者（总共可能的组合为 4，因此 4*15=60） 。现在我们要测试以下情况：

A 对 y 的影响，
A 和 B 对 y 的影响。

如果y连续服从正态分布，我们可以使用协方差或ANCOVA分析（第一种情况使用单向ANCOVA，第二种情况使用双向ANCOVA）。但这里的 y 不是正规变量，也不能转换为正规变量，因为它只有 3 个序数值。那么您建议对这两种情况进行什么统计测试？
如果您能在 y 是二分变量的情况下回答这个问题，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/637923/which-test-should-be-used-for-an-ordinal-dependent-variable-with-pretest-posttes</guid>
      <pubDate>Sun, 28 Jan 2024 08:13:39 GMT</pubDate>
    </item>
    <item>
      <title>假阳性率二项式过程的标准误是多少</title>
      <link>https://stats.stackexchange.com/questions/637916/what-is-the-standard-error-of-a-binomial-process-with-a-false-positive-rate</link>
      <description><![CDATA[我有一个肯定很常见的问题，但是经过搜索，我找不到解释。假设我们希望估计患有某种疾病的人数百分比 p。我们测试n个人。该测试已知TP 和FP 的真阳性率和假阳性率。预期阳性测试数量为 $E[Y]=TPp+FP(1-p)$。求解 p，p 的估计值为 $$p = \frac{(y/n)-FP}{TP -FP}$$ 我们如何计算p估计中的误差？总体抽样存在不确定性/误差（n 个样本的二项分布和概率 p），以及测试的真阳性和假阳性带来的额外不确定性/误差正率，也是二项式分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/637916/what-is-the-standard-error-of-a-binomial-process-with-a-false-positive-rate</guid>
      <pubDate>Sun, 28 Jan 2024 02:11:18 GMT</pubDate>
    </item>
    <item>
      <title>coxph 函数在我的模拟案例中给出了奇怪的风险比</title>
      <link>https://stats.stackexchange.com/questions/637910/coxph-function-gave-a-weird-hazard-ratio-in-my-simulation-case</link>
      <description><![CDATA[我适合三个 Cox 型号。三个风险比分别为 0.52、1.02 和 0.514。第一个风险比是治疗组和对照组之间的风险比。第二个是控制臂和外部控制臂之间的风险比。这里，1.02 表示控制臂比外部控制臂差。第三个风险比是将控制臂和外部控制臂集中在一起时的风险比。由于控制臂比外部控制臂更差，因此在我们将这两种治疗方法合并在一起后，第三个风险比应该大于第一个。然而，coxph函数却给出了违反直觉的答案。有谁知道原因吗？非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637910/coxph-function-gave-a-weird-hazard-ratio-in-my-simulation-case</guid>
      <pubDate>Sat, 27 Jan 2024 23:06:06 GMT</pubDate>
    </item>
    <item>
      <title>特定组线性变换模型的仿真：Cox</title>
      <link>https://stats.stackexchange.com/questions/637905/simulation-of-group-specific-linear-transformation-models-cox</link>
      <description><![CDATA[在我读过的一篇文章中，他们进行了一项模拟研究：
在此模拟中，我们从以下内容生成 $T_i$
特定组的线性变换模型： $$H(T_i) = \beta_{k,1}
 X_{i,1} + \beta_{k,2} X_{i,2} + \varepsilon_i, i = 1, 2, \ldots,
n; \quad k = 1, 2 $$ 其中 $ H(t) = \log\left(2(e^{4t} - 1)\right)$&lt; /span&gt; 和 $\varepsilon_i $ 遵循标准极值
分配。在这种情况下，线性变换模型是
相当于 Cox 比例风险模型。我们生成样本
来自混合的二元 Cox 比例风险模型
权重 $ \pi_1 = \frac{1}{3}$，$\pi_2 = \frac{2}{3 }$ 和 $ \beta_1
= (-3, -2)^T$, $\beta_2 = (1, 1)^T$。协变量 $X_i$ 由均值为零和一阶自回归结构的多元正态分布生成 $ \ Sigma = (\sigma_{st})$ 与 $ \sigma_{st} = 0.5^{|s - t|}$ 对于 $ s, t = 1, 2$。审查时间是根据 $[0, C]$ 上的均匀分布生成的，
其中选择 $C$ 来实现 $5\%$ 和 $25\%$。
所以，我在这里编写了 R 代码，我想确保我正确生成了 $T_i$ 。
 # 定义变换函数及其逆函数
  H &lt;- 函数(t) log(2 * (exp(4 * t) - 1))
  H_inverse &lt;- 函数(y) (1/4) * log((exp(y)/2) + 1)
  
  # 模型参数
  pi1 &lt;- 1/3； pi2 &lt;- 2/3;n=1000
  beta1 &lt;-c(-3,-2); beta2 &lt;- c(1, 1)
  
  
  # 协变量生成
  西格玛 &lt;- 矩阵(c(1, 0.5, 0.5, 1), ncol = 2)
  X &lt;- MASS::mvrnorm(n, mu = c(0, 0), Sigma)
  
  # 分组分配和生存时间模拟
  组 &lt;- ifelse(runif(n) &lt; pi1, 1, 2)
  epsilon &lt;- extRemes::revd(n,loc=0,scale=1,shape=0) # 标准极值分布

  H_Ti &lt;- 数字(n)
  for (i in 1:n) {
     if (组[i] == 1) {
     H_Ti[i] &lt;- beta1 %*% X[i,] + epsilon[i]
   } 别的 {
     H_Ti[i] &lt;- beta2 %*% X[i,] + epsilon[i]
  }}
  

  T &lt;- H_inverse(H_Ti) # 应用逆变换
]]></description>
      <guid>https://stats.stackexchange.com/questions/637905/simulation-of-group-specific-linear-transformation-models-cox</guid>
      <pubDate>Sat, 27 Jan 2024 22:26:09 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器中的非线性 PCA 与编码器</title>
      <link>https://stats.stackexchange.com/questions/637889/nonlinear-pca-vs-encoder-in-autoencoders</link>
      <description><![CDATA[我发现编码器比 PCA 更有优势，因为它们可以转换线性和非线性数据。然而，非线性 PCA 不是为处理非线性数据而设计的吗？那么，为什么我们仍然倾向于使用编码器而不是非线性 PCA？]]></description>
      <guid>https://stats.stackexchange.com/questions/637889/nonlinear-pca-vs-encoder-in-autoencoders</guid>
      <pubDate>Sat, 27 Jan 2024 15:39:05 GMT</pubDate>
    </item>
    <item>
      <title>从 $P(x) \propto \cosh^{m}(a x) e^{-x^{2}/2}$ 采样</title>
      <link>https://stats.stackexchange.com/questions/637831/sampling-from-px-propto-coshma-x-e-x2-2</link>
      <description><![CDATA[是否有一种有效的算法从 PDF 中提取样本 $x \sim P(x)$：
$$
P(x) \propto \cosh^{m}(a x) e^{-x^{2}/2}
$$
其中 $a\ge0$ 是实数参数，$m$ 是正整数？ 
由于这是一个单变量 PDF，我的第一次尝试是计算 CDF 并使用逆 CDF 方法对其进行采样，但 CDF 和逆 CDF 似乎都没有易于处理的分析形式。]]></description>
      <guid>https://stats.stackexchange.com/questions/637831/sampling-from-px-propto-coshma-x-e-x2-2</guid>
      <pubDate>Fri, 26 Jan 2024 16:03:02 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用历史数据的模拟（引导）A/A 测试来估计混杂因素对治疗效果的影响？</title>
      <link>https://stats.stackexchange.com/questions/637821/is-it-possible-to-use-simulated-bootstrap-a-a-tests-of-historic-data-to-estima</link>
      <description><![CDATA[我最近听到了一项关于衡量混杂变量对 A/B 测试历史结果影响程度的方法的提案。
为了使用 t 检验确定混杂因素对先前 A/B 测试结果准确性的影响程度，建议我们使用历史数据来重复运行模拟 A/A 测试：&lt; /p&gt;

对治疗组进行替换抽样
计算自举样本与整体治疗组样本之间的转化差异

并使用这些差异来衡量“混杂因素造成的差异”。
根据我的理解，这是没有意义的，因为以这种方式对治疗组进行随机抽样只会提供有关随机抽样导致的治疗转化率固有变异性的信息（即有关转化率抽样分布方差的信息） ）。
这个过程没有提及治疗组内因混杂而存在的任何固有偏差，因为系统偏差将被随机抽样掩盖，因为中心极限定理确定来自同一群体的 2 个随机样本之间的差异将接近 0 ，并且重复执行此操作肯定不会告诉我们有关对照组的任何信息。
也就是说，混杂是测量中的偏差，而不是测量中的变异性。
我用下面的Python代码进一步说明了我的观点。
问题：是否可以使用模拟（引导重采样）A/A 测试来估计混杂因素影响治疗效果测量的程度？或者我在这里遗漏了什么？
将 numpy 导入为 np
将 pandas 导入为 pd

n = 10000
x = np.random.normal(0.1, 0.06, n) # 转换倾向
confounding = np.clip(np.random.logistic(.6 * x, scale = 0,size = n),0,1) #与 x 创建混淆
t = np.random.binomial(1, confounding, n) # 治疗组指标

# 使用 x &amp; 计算转换概率t 并确保 p 保持在 [0, 1] 范围内
p = np.clip(x + t * 0.02, 0, 1) # 转换概率（假设处理效果均匀）
conv = np.random.binomial(1, p, n) # 实际转换

df = pd.DataFrame({&#39;t&#39;: t, &#39;conv&#39;: conv})
处理 = df.query(&#39;t == 1&#39;)

差异 = []
p1 = 处理[&#39;conv&#39;].mean()

对于 _ 在范围（1000）内：
    样本=处理过的.样本（1000，替换= True）
    p2 = 样本[&#39;conv&#39;].mean()
    差异.append(p1 - p2)

np.mean(diffs), np.std(diffs) # 这不会直接反映混杂的方差
]]></description>
      <guid>https://stats.stackexchange.com/questions/637821/is-it-possible-to-use-simulated-bootstrap-a-a-tests-of-historic-data-to-estima</guid>
      <pubDate>Fri, 26 Jan 2024 14:28:47 GMT</pubDate>
    </item>
    <item>
      <title>事件研究使治疗效果显着</title>
      <link>https://stats.stackexchange.com/questions/637572/event-study-renders-treatment-effect-significant</link>
      <description><![CDATA[目前，我正在使用犯罪小组数据（数年的县级数据）来调查警察存在对犯罪的影响。我使用“外源性”每年增加一天的警察存在，以解释内生性偏差，并应用双向固定效应模型来解释未观察到的异质性（县固定效应，以及年、月和周固定效应）。因此，我的主要回归表述为：
$$
C_{ct} = \beta_1 Police_{ct} + 𝜑_c +𝜇年 + 𝜋月 +𝜌日 + \beta_2 X_{ct} + \epsilon_{ct}。
$$
治疗指示符“警察”如果在 $t$ 天，县 $c$ 的警力增加，则等于 1，则等于 0否则。使用相互作用的固定效应运行此回归得到的结果在统计上不显着（p 值 ~ 0.06）。请参阅第一个表（括号中的标准错误）。
但是，当我检查平行趋势假设并包括 5 个滞后和 4 个领先时，处理“警察”将变为“警察”。具有统计显着性（p 值 ~ 0.04）。请参阅第二个表（括号中的标准错误）。


有没有人遇到过类似的问题，可以帮我解决一下吗？
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/637572/event-study-renders-treatment-effect-significant</guid>
      <pubDate>Tue, 23 Jan 2024 17:18:31 GMT</pubDate>
    </item>
    </channel>
</rss>