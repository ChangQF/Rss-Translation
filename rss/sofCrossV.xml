<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 06 Jan 2025 18:22:59 GMT</lastBuildDate>
    <item>
      <title>解释优化 MSE 的模型中的模块权重和激活函数</title>
      <link>https://stats.stackexchange.com/questions/659615/interpreting-module-weights-and-activation-functions-in-a-model-optimizing-mse</link>
      <description><![CDATA[我正在使用一个由三个模块组成的模型：{A、B、C}。每个模块在预测股票价格方面都发挥着作用，模型的学习目标是最小化均方误差 (MSE)。
这些模块具有以下特点：
模块 A：具有较大的正权重。模块 B：具有较小的负权重。模块 C：具有接近于零的权重（例如，绝对值在 0.01 左右）。
权重是从检查点文件分析的，该文件是根据在验证集上评估的最佳性能参数保存的。
我试图了解这些权重如何影响模型以及某些设计决策背后的原理。以下是我的具体问题：
了解 A 和 B 的互补作用：
在训练期间，模块 A 的权重会以幅度（正方向）增加，这会降低 MSE。另一方面，模块 B 的权重变得更负，也会降低 MSE。我发现很难解释为什么一个模块用较大的正权重学习，而另一个模块用较小的负权重学习。我如何理解它们的互补作用，特别是在股票价格预测这样的任务中？
ReLU 的历史用途：
虽然 ReLU 现在不那么常用，但它在过去被广泛使用。采用 ReLU 是否是为了故意忽略负面贡献，例如来自模块 B 的贡献？如果是这样，这是否意味着在某些任务或情况下负权重被认为意义较小？或者，主要动机是为了避免梯度消失或简化计算？
转向 GELU：
像 GELU 这样的现代激活函数允许使用负权重。这是否意味着负面贡献现在被认为更有意义，而 GELU 有助于在模型中保留它们的影响力？
删除权重接近于零的模块：
如果模块 C 的权重非常小（例如 0.01 或 -0.01），这是否应该是将其从模型中删除的信号？这是否表明模块 C 对模型没有做出有意义的贡献，特别是如果消融研究表明删除后没有性能差异？
我特别有兴趣在有效集优化检查点分析的背景下理解上述观点。
摘要：
我使用在验证集上优化的已保存检查点分析了模型权重。我希望了解为什么模块 A 以较大的正权重学习，而模块 B 以较小的负权重学习，两者都降低了 MSE。我还希望确定权重接近于零的模块 C 是否做出了有意义的贡献并应该保留。然而，我很难解释 A 和 B 的互补作用以及模块 C 接近零的权重与模型性能的相关性。]]></description>
      <guid>https://stats.stackexchange.com/questions/659615/interpreting-module-weights-and-activation-functions-in-a-model-optimizing-mse</guid>
      <pubDate>Mon, 06 Jan 2025 13:50:46 GMT</pubDate>
    </item>
    <item>
      <title>探索性因子分析，非正态数据</title>
      <link>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</link>
      <description><![CDATA[我正在分析的数据对于几乎每个观察到的变量都是非正态的。我想在 R 中进行探索性因子分析 (EFA)。KMO 检验和 Bartlett 检验表明数据符合 EFA 条件。在 psych 包的文档中，我没有找到应如何处理非正态分布的数据 (https://personality-project.org/r/psych/HowTo/factor.pdf)。我的样本相对较小 (N=60)。
在进行验证性因子分析时，我可以使用 lavaan 包中的 Satorra-Bentler 校正来处理非正态数据，cfa() 函数，例如cfa(model = spec, data = df_data, std.lv=TRUE, estimator = &quot;MLM&quot;) ，这种使用稳健标准误差的校正是一种可接受的方法。 estimator=&quot;MLM&quot; 代表 Satorra-Bentler 校正。我可以用 psych 包 以某种方式做到这一点吗？
psych 包执行 EFA，fa() 函数，例如fa(data, nfactors = 4, rotate = &quot;oblimin&quot;) 并提供可行的因子，但如果我没有弄错的话，它被设计用于正态分布的数据。
如果我尝试使用 lavaan 包 中的 efa() 和 Satorra-Bentler 校正，它会发出 警告，表示协方差矩阵包含较小的负值，这可能表明模型未被识别：
efa(data = df_data, nfactors=4, rotation=&quot;oblimin&quot;, std.lv=TRUE, estimator = &quot;MLM&quot;)

警告消息：
1：lavaan-&gt;lav_model_vcov()： 
估计参数 (vcov) 的方差-协方差矩阵似乎不是
正定！最小特征值 (= -5.425180e-15) 小于零。这可能是模型无法识别的症状。
2：lavaan-&gt;lav_model_vcov()：
估计参数 (vcov) 的方差-协方差矩阵似乎不是 
正定的！最小特征值 (= -2.190854e-32) 小于零。这可能是模型无法识别的症状。


所以问题是：如何使用非正态数据计算 EFA，可能使用 psych 包？]]></description>
      <guid>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</guid>
      <pubDate>Mon, 06 Jan 2025 12:41:19 GMT</pubDate>
    </item>
    <item>
      <title>auto_arima() 可以在行为不良的时间序列中使用吗？</title>
      <link>https://stats.stackexchange.com/questions/659612/can-auto-arima-be-used-in-badly-behaved-time-series</link>
      <description><![CDATA[也许我无法正确配置它，但是当将 Python 模块 pmdarima 的 auto_arima() 函数应用于表现不佳的时间序列（例如来自加密货币的 OHLC 数据的时间序列）时，我遇到了非常糟糕的体验。
您能否为我提供使用它的指南？由于 pmd_arima 大量借鉴了 Hyndman 在 R 中的 forecast 代码，我阅读了它的 vignette，似乎整个算法最适合 (p, d, q) 分量的低值。]]></description>
      <guid>https://stats.stackexchange.com/questions/659612/can-auto-arima-be-used-in-badly-behaved-time-series</guid>
      <pubDate>Mon, 06 Jan 2025 12:11:24 GMT</pubDate>
    </item>
    <item>
      <title>解释 R 中零膨胀模型的均值预测：为什么零膨胀均值与原始均值不同？</title>
      <link>https://stats.stackexchange.com/questions/659607/interpreting-mean-predictions-from-zero-inflated-models-in-r-why-do-zi-adjusted</link>
      <description><![CDATA[我使用以下代码在 R 中拟合零膨胀模型：glmmTMB(score ~ year - 1 + (1 | farm), ziformula = ~ year - 1, data = data, family = &quot;nbinom2&quot;)
为了提取我的分数的平均预测值，我使用以下方法：

对于&quot;true&quot;零：exp(fe_mod4$cond)
包括零膨胀公式：exp(fe_mod4$cond) * (1 - plogis(fe_mod4$zi))
直接从样本计算的原始均值，没有任何模型。

结果均值如下：
年份 原始均值 均值（不含 ZI） 均值（含 ZI）
1 0.5 1.1 0.4
2 0.9 1.6 0.6
3 0.6 1.4 0.4
4 0.4 1.2 0.4
5 0.5 1.5 0.4

问题：

为什么用零膨胀 (ZI) 公式计算的均值与原始均值非常相似样本均值？
为什么使用 ZI 公式和不使用 ZI 公式计算出的均值之间存在很大差异？这是否表明背景效应导致模型（不使用 ZI）没有考虑到过多的零值？
为什么我们对没有零膨胀 (ZI) 部分的结果感兴趣？
如果 ZI 调整后的预测与原始数据均值非常相似，那么我们为什么需要这个模型，使用 ZI 公式进行预测的目的是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659607/interpreting-mean-predictions-from-zero-inflated-models-in-r-why-do-zi-adjusted</guid>
      <pubDate>Mon, 06 Jan 2025 09:09:38 GMT</pubDate>
    </item>
    <item>
      <title>估计量的偏差是否取决于观测值的数量？预期值的实际解释</title>
      <link>https://stats.stackexchange.com/questions/659603/can-the-bias-of-an-estimator-depend-on-the-number-of-observations-practical-int</link>
      <description><![CDATA[这里表示
$\hat{\theta}=\frac{1}{n} \sum x_i + \frac{1}{n}$
是样本均值的有偏估计量。
我们来看看：
\begin{align}
\mathbb{E}(​​\hat{\theta}) &amp;= \frac{1}{n} \sum \mathbb{E}(​​x_i) + \frac{1}{n} \\
&amp;= \frac{1}{n} \sum \mu + \frac{1}{n} \\
&amp;= \frac{n \cdot \mu}{n} + \frac{1}{n} \\
&amp;= \mu + \frac{1}{n} \\
\end{align&gt;
因此偏差是观察次数的函数。
我觉得这很奇怪。
以下是我对如何计算$\mathbb{E}(​​\hat{\theta})$的直觉。
我们从总体中抽取一个大小为$n_1$的样本。称之为$x^{(1)} \in \mathbb{R}^{n_1}$。
我们应用函数来计算平均值$\hat{\theta}^{(1)}$的估计值。
在这种情况下$\hat{\theta}^{(1)}=\frac{1}{n} \sum x^{(1)}_i + \frac{1}{n}$。
我们从总体中抽取另一个样本，大小为$n_2$。称之为$x^{(2)} \in \mathbb{R}^{n_2}$。
我们应用函数来计算平均值$\hat{\theta}^{(2)}$的估计值。
我们从总体中抽取另一个样本，大小为$n_3$。称之为$x^{(3)} \in \mathbb{R}^{n_3}$。
我们应用我们的函数来计算平均值$\hat{\theta}^{(3)}$的估计值。
我们以此方式进行无数次。
然后我们取所有这些估计值的平均值（期望值）。
$\mathbb{E}(​​\hat{\theta}) = (\hat{\theta}^{(1)}+\hat{\theta}^{(2)}+\hat{\theta}^{(3)}+\cdots+\hat{\theta}^{(N)})/N$
根据这种解释，期望值取决于观察次数似乎很奇怪。
观察次数是多少？我是否必须有同样大小的样本？
编辑：我发现，由于我的估计量本身是观察次数的函数，因此其预期值是观察次数的函数也就不足为奇了。然后我必须固定 $n$，因此样本大小相同（也就是说，更改 $n$ 会改变估计量）。
不过，由于我进行了无限次采样，因此预期值取决于样本大小感觉很奇怪。]]></description>
      <guid>https://stats.stackexchange.com/questions/659603/can-the-bias-of-an-estimator-depend-on-the-number-of-observations-practical-int</guid>
      <pubDate>Mon, 06 Jan 2025 07:53:24 GMT</pubDate>
    </item>
    <item>
      <title>$|μ| \gg σ$ 的 Delta 方法近似条件</title>
      <link>https://stats.stackexchange.com/questions/659598/condition-for-delta-method-approximation-for-%ce%bc-gg-%cf%83</link>
      <description><![CDATA[我试图理解当 $|μ|$ 远大于 $σ.$ 时 Delta 方法近似的数学依据。具体来说，我正在寻找以下公式的证明：
$$ E[g(X)] \approx g(\mu) + \frac{1}{2}g&#39;&#39;(\mu)\sigma^2 $$
$$ \operatorname{Var}[g(X)] \approx (g&#39;(\mu))^2\sigma^2 $$
其中 $X$ 是均值为 $μ$ 的随机变量和标准偏差 $σ,$ 和 $g$ 是一种变换。
我不确定获取这些简化形式所涉及的具体步骤和假设。
我有一些问题：
条件 $|μ| \gg σ$ 是如何正式定义或量化的？我的讲义中提到了这个条件。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659598/condition-for-delta-method-approximation-for-%ce%bc-gg-%cf%83</guid>
      <pubDate>Mon, 06 Jan 2025 03:46:26 GMT</pubDate>
    </item>
    <item>
      <title>加权可能性间接模拟可靠性？</title>
      <link>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</link>
      <description><![CDATA[对于纵向回归问题，我可能认为，与信息较少的受试者相比，我观察到的具有更多观察结果的受试者的数据更可靠（情况可能并非总是如此，但假设如此）。这里，可以使用回归权重，以便在模型中考虑到这种感知可靠性吗？

这是针对$i^{th}$主题的基本纵向/随机效应模型：
$$y_{ij} = X_{ij}\beta + u_i + \epsilon_{ij}$$
$$u_i \sim N(0, \sigma^2_u)$$
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon)$$
我看到这种权重格式经常用于最小二乘回归（$n_i$ 是受试者 $i$ 的测量次数，$N$ 是受试者总数):
$$w_i = \frac{n_i}{\sum_{k=1}^N n_k}$$
最后，修改似然函数以包含权重（我不确定哪个更好 - 单个受试者级别权重或单个观察级别权重）：
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N \prod_{j=1}^{n_i} f(y_{ij}|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
从这个来看，似乎即使有了这些权重，这些权重似乎也不会影响方差。使用多层次建模/随机效应中采用的一般方法，也许可以将方差修改为（$I$ 是一个单位矩阵，而$J$ 是一个 1 的矩阵 - 这意味着单个受试者的方差取决于所有受试者的未加权方差加上基于该受试者测量次数的单个受试者的加权方差）。这样做，我们实际上在个体层面上将随机效应引入模型：
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon / n_i)$$
$$Var(y_i) = \sigma^2_u J_{n_i} + (\sigma^2_\epsilon/n_i) I_{n_i}$$
$$Y_i \sim MVN(X_i\beta, V_i)$$
这现在使得可能性（更复杂 - 但最小二乘解可用于固定效应估计）：
$$f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon) = (2\pi)^{-n_i/2}|V_i|^{-1/2}\exp\left(-\frac{1}{2}(y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right)$$
$$\ell(\beta, \sigma^2_u, \sigma^2_\epsilon) = -\frac{1}{2}\sum_{i=1}^N \left[n_i\log(2\pi) + \log|V_i| + (y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right]$$
$$\hat{\beta} = \left(\sum_{i=1}^N X_i^T V_i^{-1} X_i\right)^{-1} \left(\sum_{i=1}^N X_i^T V_i^{-1} y_i\right)$$
我可以看到，在这个最终设置中，固定效应估计和方差都受到每个受试者可用的观察次数的影响。 （下一部分超出了我的理解范围，但我听说随机效应是使用 RMLE 估计的）

假设数学是正确的，在纵向研究中，基于每个受试者可用的测量次数的权重可以用来隐式地解释可靠性？
结束语：最后，看起来只需使用基本的多级建模方法就可以解决所有问题，并根据每个受试者的观察次数间接地考虑他们的贡献……]]></description>
      <guid>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</guid>
      <pubDate>Sun, 05 Jan 2025 03:44:55 GMT</pubDate>
    </item>
    <item>
      <title>BAM mgcv 算法的可重复性</title>
      <link>https://stats.stackexchange.com/questions/659490/reproducibility-of-bam-mgcv-algorithm</link>
      <description><![CDATA[我经常处理大型空间数据集，其中 mgcv 中实现的 bam() 算法非常适合。对于我的分析来说，点估计的可重复性是一个关键问题，不幸的是，我经常看到 BAM 预测的结果取决于所用数据集中数据点的顺序。
最小可重复示例
以下内容基于由协变量 x、y 和目标变量 z 组成的 15.000 个数据点的数据集，可在此处下载：https://drive.google.com/file/d/16dZ66KmT4CrQHkVQtw7vRP065SoztUNg/view?usp=drive_link
另请注意，在执行每个代码示例之前下面，数据集已重新加载并使用相同的随机种子进行了混洗。
首先考虑使用 bam() 拟合的结果：
set.seed(1)

model1 &lt;- mgcv::bam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

dataset &lt;- dataset[sample(nrow(dataset)),]

model2 &lt;- mgcv::bam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

#calculate response on scale of linear predictor
dataset$pred_model1 &lt;- as.vector(predict.gam(model1, dataset))
dataset$pred_model2 &lt;- as.vector(predict.gam(model2, dataset))
plot(dataset$pred_model1, dataset$pred_model2)

这将生成以下图表：

现在考虑 gam() 的结果：
model1 &lt;- mgcv::gam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

数据集 &lt;- 数据集[sample(nrow(数据集)),]

模型2 &lt;- mgcv::gam(z ~ s(x, y, k = 100),
数据 = 数据集,
family = Gamma(link = log),
method = &quot;REML&quot;)

#计算线性预测器尺度上的响应
数据集$pred_model1 &lt;- as.vector(predict.gam(model1, dataset))
数据集$pred_model2 &lt;- as.vector(predict.gam(model2, dataset))

plot(数据集$pred_model1, dataset$pred_model2)


这将生成以下图表：

所以我的问题是：这种行为是预料之中的，还是我这边的一个错误？如果这只是使用 bam() 时必须忍受的事情，那么除了始终确保数据点的顺序相同之外，还能做些什么来确保可重复性？
我已经通过尝试 k=1000 个基函数来测试它是否与有限的空间分辨率有关。在这里我发现了同样的问题。然而，我确实看到将数据集大小减少到只有 1000 个数据点可以大大减少问题。然而，这不是理想的解决方案，因为我想使用所有数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/659490/reproducibility-of-bam-mgcv-algorithm</guid>
      <pubDate>Fri, 03 Jan 2025 13:43:22 GMT</pubDate>
    </item>
    <item>
      <title>理解两个孩子问题的直觉</title>
      <link>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</link>
      <description><![CDATA[受到此推特帖子的启发，发布了这个问题：

我有两个孩子，（至少）其中一个是男孩，出生在星期二

两个孩子都是男孩的概率是多少？


通过Joel Grus，这里是一个建议的答案：

总共 196 种可能性（每种（性别、天）的概率均等）27那些
至少一个星期二男孩（13 个较小的星期二男孩，较大的不是；13 个较大的
星期二男孩，较小的不是，1 个都）其中 13 个都是男孩（6，6，1）所以
13 / 27

这似乎是正确的。但同时也令人困惑。这让我们觉得我们可以任意地以我们知道是真实的任何事物为条件（例如，婴儿出生在银河系；或者婴儿的父母说英语），并以某种方式使用它来改变后验概率。有人能把我从这引起的存在主义困境中解救出来吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</guid>
      <pubDate>Tue, 31 Dec 2024 09:34:01 GMT</pubDate>
    </item>
    <item>
      <title>“AUROC 曲线”这个术语实际上是否正确且有意义？</title>
      <link>https://stats.stackexchange.com/questions/659370/is-the-term-auroc-curve-actually-correct-or-meaningful</link>
      <description><![CDATA[15 年前，当我进入机器学习领域时，我了解到 AUC 代表“曲线下面积”，即“ROC 曲线下面积”，而 ROC 是“接收者操作特性”。
现在我自己在指导学生，（当然）他们有时会根据他们首先阅读的文献和资料使用不同的术语。我听说过 AUROC，根据这里的一些观点，它比 AUC 更好，因为后者没有指定指的是哪条曲线，而且除了 ROC 之外还有其他可能。
但后来我读到 AUROC 曲线，它在很多层面上听起来都是错误的。 （我不是以英语为母语的人。）
您指的是曲线下的面积，即 AUC 或 AUROC，或曲线本身，即ROC 曲线，因此 AUROC 曲线对我来说真的没有意义。但是，通过 CV 搜索我发现它被使用了几次，但从未被更正或解决，例如

为什么 ROC 曲线和 AUC 值并不总是相关的？
如何解释抵押贷款拒绝/批准的 AUROC 曲线？
如何解释 AUROC分数？

所以，我的问题是：我在这里是对的还是过于迂腐？还是忽略了一些显而易见的东西？
澄清：
似乎我的问题含糊不清，我应该澄清：
我的问题是使用术语“AUROC 曲线”来表示曲线，而不是值，例如

对于随机分类器，AUROC 曲线将是一条从 [0,0] 到 [1,1] 的对角线
]]></description>
      <guid>https://stats.stackexchange.com/questions/659370/is-the-term-auroc-curve-actually-correct-or-meaningful</guid>
      <pubDate>Mon, 30 Dec 2024 15:26:49 GMT</pubDate>
    </item>
    <item>
      <title>可视化多种样品类型和杂质水平的 PCA 结果</title>
      <link>https://stats.stackexchange.com/questions/659145/visualizing-pca-results-with-multiple-sample-types-and-impurity-levels</link>
      <description><![CDATA[我正在对一个数据集执行主成分分析 (PCA)，该数据集包含四种材料 (a、b、c、d) 的样本，这些样本的杂质水平各不相同 (10%、20%、30% 和 40%)。此外，还有一个纯样本 (p)。
我打算使用 R 创建一个分数图，以根据这些样本的主要成分直观地显示这些样本的分离情况。我希望在图中有效地表示样本类型 (a、b、c、d、p) 和杂质水平 (10%、20%、30%、40%)。
我正在寻找有关如何在分数图中以最佳方式直观地编码此双重信息 (样本类型和杂质水平) 的建议。是否有既定的最佳实践或建议用于在 PCA 得分图中表示多个分类变量？
其他详细信息
• 数据有 17 列（a、b、c、d 及其级别以及纯样本）和 949 行。
任何见解或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659145/visualizing-pca-results-with-multiple-sample-types-and-impurity-levels</guid>
      <pubDate>Tue, 24 Dec 2024 09:54:49 GMT</pubDate>
    </item>
    <item>
      <title>GAM 留一交叉验证 (LOOCV)，适用于较大的模型</title>
      <link>https://stats.stackexchange.com/questions/659016/gam-leave-one-out-cross-validation-loocv-for-biggish-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659016/gam-leave-one-out-cross-validation-loocv-for-biggish-models</guid>
      <pubDate>Fri, 20 Dec 2024 14:44:07 GMT</pubDate>
    </item>
    <item>
      <title>需要有共同原因的因果调整公式</title>
      <link>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</link>
      <description><![CDATA[
在上述因果模型中，计算$P(X=x \mid \text{do}(Y=y))$时，是否需要使用因果调整公式$\sum_c P(X=x \mid Y=y, C=c) P(C=c)$？一旦我们$\text{do}(Y=y)$，$Y$的生成过程是否就独立于$X$的生成过程，因此$P(X=x \mid \text{do}(Y=y)) = P(X=x)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</guid>
      <pubDate>Mon, 16 Dec 2024 06:30:13 GMT</pubDate>
    </item>
    <item>
      <title>我们可以将一个随机正态变量大于其他 $N$ 个正态变量的概率写成累积密度函数的乘积吗？</title>
      <link>https://stats.stackexchange.com/questions/655163/can-we-write-the-probability-that-a-random-normal-variable-is-greater-than-other</link>
      <description><![CDATA[对于 $Y_1 \sim N(\mu_y;\sigma_y^2)$ 和 $X_i, ..., X_N$ 个分布为 $N(\mu_i, \sigma_i^2)$ 的随机变量，我们可以将 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})$ 写为 $\prod_{i=1}^{N}F(z_i)$ 吗？其中 $F(\cdot)$ 是标准正态分布的累积密度函数，并且 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})$ 写为 $\prod_{i=1}^{N}F(z_i)$，其中 $F(\cdot)$ 是标准正态分布的累积密度函数，并且 $z_i=\frac{\mu_y-\mu_i}{\sqrt{\sigma_y^2+\sigma_i^2}}$?
对于 $i=1$ 的情况，我知道很容易证明 $P(Y_i \geq X_1)=F(\frac{\mu_y-\mu_i}{\sqrt{\sigma_y^2+\sigma_1^2}})$，但我们能否推广到 $N$ 的情况 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})=\prod_{i=1}^{N}F(z_i)$?
如果 $\mu_y=\mu_i \forall i$，则为 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})=F(z_1)^N$。
我之所以产生疑问，是因为似乎只要 $Y$ 的均值与任何其他 $X_i$ 相同，$Y$ 方差的任何变化都不会影响 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})$。而直观上 $Y$ 需要较高的值才能击败所有其他分布。
（这不是任务，只是好奇心）]]></description>
      <guid>https://stats.stackexchange.com/questions/655163/can-we-write-the-probability-that-a-random-normal-variable-is-greater-than-other</guid>
      <pubDate>Tue, 01 Oct 2024 10:25:44 GMT</pubDate>
    </item>
    <item>
      <title>“不可预测”的定义</title>
      <link>https://stats.stackexchange.com/questions/620271/definition-of-unpredictable</link>
      <description><![CDATA[在点和密度预测的情况下，我们如何严格定义术语“不可预测”？
术语“不可预测”用于各种上下文，例如

“抛一枚公平硬币的结果是不可预测的”，
“随机游走的增量是不可预测的”或
“在信息有效的市场中，价格变化是不可预测的”。

这些陈述并非完全正确，因为人们总是可以提供预测，无论预测多么不准确。我可以做出点数预测（硬币将出现正面；增量为 0.18879；价格变化为 0.12 英镑）或密度预测（$P(\text{heads})=0.51$，增量为 N(0,0.4)，价格变化为 ...）。
直观地说，“不可预测”意味着“无法比一些简单/朴素/自然的基准更准确地预测”，例如“抛硬币的最佳密度预测是 $P(\text{heads})=0.5$”。但随后我们需要定义“最佳”的含义在评估密度预测时。
那么，我们如何严格定义“不可预测”一词？
关键词：不可预测、不可预测、可预测性、可预测性。]]></description>
      <guid>https://stats.stackexchange.com/questions/620271/definition-of-unpredictable</guid>
      <pubDate>Sat, 01 Jul 2023 18:56:43 GMT</pubDate>
    </item>
    </channel>
</rss>