<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 03 Sep 2024 15:17:13 GMT</lastBuildDate>
    <item>
      <title>lme4 包中 BLUPs 的适用功能</title>
      <link>https://stats.stackexchange.com/questions/653795/suitable-function-of-blups-in-lme4-package</link>
      <description><![CDATA[我想分析一个包含 4 年内 2 种条件（干旱胁迫和正常）下 12 种基因型的数据集。
我使用了一篇使用 BLUPs 方法的文章的分析作为我的分析模型，该模型使用 BLUPs 方法评估多年来单个基因型在每种处理下的特征，使用 R 中的“lme4”包，但我不知道该使用哪个函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/653795/suitable-function-of-blups-in-lme4-package</guid>
      <pubDate>Tue, 03 Sep 2024 15:11:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Vgg19 进行图像重建的训练收敛停滞</title>
      <link>https://stats.stackexchange.com/questions/653794/training-convergence-stagnation-in-image-reconstruction-using-vgg19</link>
      <description><![CDATA[-----------------------------------------------------上下文---------------------------
我正在尝试实现这篇论文通过特征变换实现通用风格迁移。在论文中，他们针对预训练的 vgg19 编码器编码的 relu1_1、relu2_1、relu3_1、relu4_1、relu5_1 特征输出训练了 5 个解码器。为了实现这一点，他们使用了每像素损失（生成的图像和训练图像之间的均方误差）和特征损失（训练特征输出和生成的图像特征输出之间的均方误差）。他们使用的这两个损失之间的权重是 1.0。在训练期间，预训练的 vgg 模型保持不变
-----------------------实现差异 --------------------------
在论文中，他们使用了来自 vgg 论文的预训练 vgg19。我使用了来自 pytorch 的预训练模型。因此预处理不同。在 vgg 论文中，仅从 0 到 255 的像素值中减去平均值。在 pytorch 中，平均值 = [0.485, 0.456, 0.406] 和 std = [0.229, 0.224, 0.225] 这些值用于规范化。
第二个区别是，我在解码器输出后使用了一个额外的 tanh 层来获取从 -1 到 1 的像素值，我在训练期间将其重新缩放到 0 和 1 之间，这后来导致了问题，因为与每个像素的特征损失相比，损失变得太低。他们在实现中没有使用 tanh 或任何边界函数。他们的官方推理代码可以在此处找到
--------------------------问题---------------------------
无论每像素损失和内容损失之间的权重如何。我能够为 relu1_1、relu2_1、relu3_1（此处使用权重 1）生成相当不错的图像重建。问题始于从 relu4_1（生成的图像中有一些伪影但仍然可以）和主要 relu5_1 进行图像重建，因为更多像素值和精细细节丢失了。在 relu5_1 中，如果我使用权重值 1。两个训练有效图像的生成图像如下所示-

因此，我将每像素损失增加到 200，并尝试在单个批次上进行过度拟合，经过 1000 次迭代后，我能够在大小为 16 的批次上进行过度拟合，损失小于 0.2。图像看起来也相当不错。但是当使用整个数据集进行训练时，训练变得非常不稳定。损失从 13 开始下降到 6。但此后，训练损失下降得非常非常慢。在整个训练过程中，训练损失也非常不稳定。输出如下所示

在图像中我们可以看到内容缺失。还产生了一些伪影。我检查了单个像素和特征损失。我发现特征损失下降非常缓慢，并且每个像素的损失更新不稳定。我使用了批处理大小为 16、lr=1e-4 和梯度裁剪和 adam 优化器。在 coco 2014 数据集上进行了 15K 次迭代。我的问题是

我现在应该做什么？
我是否应该花更多时间找到两种损失之间的完美平衡。但这似乎非常耗时，因为在小批量上，模型总是过度拟合各种权重值。但在全批次上训练时，训练损失仍然很高，并且在 3 个 epoch 后更新非常缓慢
我是否应该使用更高的批次大小和学习率（高学习率会导致更不稳定的训练）
我是否应该使用学习率调度程序
这种情况收敛问题是否常见，其中训练损失确实得到了理想的损失
]]></description>
      <guid>https://stats.stackexchange.com/questions/653794/training-convergence-stagnation-in-image-reconstruction-using-vgg19</guid>
      <pubDate>Tue, 03 Sep 2024 15:00:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R 中的并行引导比顺序引导（使用 boot 和 future 包）慢？[迁移]</title>
      <link>https://stats.stackexchange.com/questions/653792/why-is-parallel-bootstrapping-in-r-slower-than-sequential-bootstrapping-using-b</link>
      <description><![CDATA[我正在使用 R 中的 boot 包进行引导分析，选项为 parallel = &#39;snow&#39;（适用于 Windows 计算机）。但是，并行计算比顺序计算更慢或相同。
我尝试更改设置以增加核心数量（ncpus = 2 和 ncpus = 4）并手动设置集群，然后使用 cl = mycluster 选项。增加核心数量和设置集群使时间进一步变慢。我找不到有关 boot 包中 boot 函数使用的默认核心数的文档。
我还尝试使用相同的 bootstrap 函数来使用 future 包，这再次比顺序计算慢，而且当我将核心数从 2 增加到 4 时，速度会更慢。我尝试了 15、30、500 和 1000 次迭代，发现了类似的结果（使用 2 个工作器的 1000 次迭代是最慢的）。
本质上，在我的 bootstrap 中，我正在计算权重并计算非常大样本的加权率（一次迭代需要 ~2 分 30 秒）。我的 bootstrap 函数很长，所以我在下面放了一个简化版本。在简化版本中，并行计算更快，但在我的实际代码中并非如此。
我是并行计算的新手，所以不确定为什么它比顺序计算慢。我是不是漏掉了什么？
set.seed(1)
R = 1000

library(boot)
library(survival)
library(dplyr)

my_bootstrap_fx &lt;- function(data, indices) {

d &lt;- data[indices,]

# 计算 IPTW 权重
denom_fit &lt;- glm(trt ~ age + previous + karno, data = d)
numer_fit &lt;- glm(trt ~ 1, data = d)
pn_trt &lt;- predict(numer_fit, type = &#39;response&#39;)
pd_trt &lt;- predict(denom_fit, type = &#39;response&#39;)
d$iptw &lt;- if_else(d$trt == 1, ((1-pn_trt) / (1-pd_trt)), pn_trt/pd_trt)

# 计算风险比
dtime &lt;- unique(veteran$time[veteran$status==1]) 
newdata &lt;- survSplit(Surv(time, status) ~ trt + celltype + karno,
data=veteran, cut=dtime)
fit &lt;- coxph(Surv(tstart, time, status) ~ trt + celltype + karno, weights = newdata$iptw, newdata)
result &lt;- c(fit$coef[1], fit$coef[2])

return(result)

}

# 顺序

system.time(
my_boostrap_results &lt;- boot(data = veteran, statistic = my_bootstrap_fx, R = R)
)

# 使用 boot 并行

system.time(
my_bootstrap_results &lt;- boot(data = veteran, statistic = my_bootstrap_fx, R = R, parallel = &#39;snow&#39;)
)

# 使用 boot 并行并手动设置集群
library(parallel)

mycluster &lt;- makeCluster(4)
clusterExport(mycluster, list(&#39;my_bootstrap_fx&#39;, &#39;veteran&#39;))
clusterEvalQ(mycluster, {
library(survival)
library(dplyr)
})

system.time(
my_bootstrap_results &lt;- boot(data = veteran, statistic = my_bootstrap_fx, R = R, parallel = &#39;snow&#39;, ncpus = 2, cl = mycluster)
)

stopCluster(mycluster)

# 使用 Future 进行并行
library(doFuture)
library(foreach)
doFuture::registerDoFuture()
future::plan(multisession, worker = 4)

system.time(
my_bootstrap_results &lt;- foreach(i = 1:R, .combine = rbind) %dofuture% {my_bootstrap_fx(veteran)}
)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/653792/why-is-parallel-bootstrapping-in-r-slower-than-sequential-bootstrapping-using-b</guid>
      <pubDate>Tue, 03 Sep 2024 13:33:24 GMT</pubDate>
    </item>
    <item>
      <title>完成充分统计量练习问题背后的动机</title>
      <link>https://stats.stackexchange.com/questions/653790/motivation-behind-this-exercise-problem-on-complete-sufficient-statistic</link>
      <description><![CDATA[这来自 Hogg 和 McKean 的《数理统计学导论》第 7 章（充分性），第 7.4 节（完整性和唯一性）。
练习 7.4.10。
设 $Y_1 &lt; Y_2 &lt; \cdots &lt; Y_n$ 为大小为 $n$ 的随机样本的顺序统计量，样本来自具有 pdf $f (x; \theta) = 1/\theta,$ $0 &lt; x &lt; \theta$ 的分布，其他地方为零。通过示例 $7.4.2$，统计量 $Y_n$ 是 $\theta$ 的完全充分统计量，并且它的 pdf
$$g(y_n;\theta)= \frac{ny_n^{n-1}}{\theta^n} , 0&lt;y_n &lt;\theta,$$
其他地方为零。
(a) 找到 $Z = n(\theta − Y_n)$ 的分布函数 $H_n(z; \theta)$。
(b) 找到 $\lim_{n \to \infty} H_n(z; \theta)$，因此是 Z 的极限分布。
我的问题：
这个问题的解决方法非常简单，我并没有问如何解决这个问题。事实上，他在上一章的练习中已经给出过这个问题，而我当时已经解决了。我的问题是“这与完整性和唯一性有什么关系？”
有关我的问题的更多详细信息：
在本文的这一点上，均匀分布$U(0,\theta)$中随机样本的$n^{th}$阶统计量可用作$\theta$的估计量，这一事实已被彻底驳倒。他还提到，已经确定（在示例 $7.4.2$ 中）它是一个完全充分统计量，并且 $n/(n+1)Y_n$ 是 $\theta$ 的所谓 MVUE。他提出的问题（其部分 (a) 和 (b) 之前已经问过）似乎与完整性无关，这感觉很奇怪。
如果您能看到此练习的解决方案与完整性之间的任何联系，即如果您能看到在完整性部分提出此问题的动机，请向我说明。]]></description>
      <guid>https://stats.stackexchange.com/questions/653790/motivation-behind-this-exercise-problem-on-complete-sufficient-statistic</guid>
      <pubDate>Tue, 03 Sep 2024 11:58:23 GMT</pubDate>
    </item>
    <item>
      <title>在元回归中正确建模小剂量的连续对数剂量反应关系</title>
      <link>https://stats.stackexchange.com/questions/653788/correctly-modelling-a-continuous-log-dose-response-relationship-in-meta-regressi</link>
      <description><![CDATA[我正在研究一种计划的有效性，该计划的疗程数范围为 1 到 20。我首先进行荟萃分析 (k = 70)，结果显示该类计划的平均效果大小为 0.50 SD。在我的荟萃分析中，平均疗程数为 7。我想预测实施 1 疗程的该计划的效果。
(1) 我可以先预测为 0.50 * (1/7) = 0.07。其中 1/7 = 0.14 可作为疗程数（即剂量）的线性调整。但是，我认为凹剂量反应关系比线性关系更合理。所以也许我应该做 ln(1)/ln(7)。嗯，这行不通，因为 ln(1) = 0。所以我可以做 ln(1+1)/ln(7+1) = 0.33 吗？
但是，我还没有看到这样的先例。我认为人们不会用 ln(income+1) 来做模型——我见过的主要变量是收入，以这种方式处理——尽管这可能并不重要，因为收入是 1000 而不是 1 到 20。还不清楚除 +1 之外的常数是否合适。
(2) 与其使用一般剂量调整，也许我想用更多的证据来锚定它。我可以用元回归来预测剂量反应关系，其中我预测参加的课程次数的效果。如果我想要对数剂量反应关系，我应该使用 ln(sessions) 作为预测因子还是使用 ln(sessions+1)？这会改变截距的含义吗？其中 ln(sessions) 的截距是 session = 1 时的效果，因为 ln(1) = 0，而 ln(sessions+1) 的截距是 session = 0 时的效果，因为 ln(0+1) = 0？
(3) 如果我的模型给出的截距为 0.20 SD，每个 session 的效果为 0.65 SD，那么我能否将调整计算为 (0.20 + ln(1+1)*0.65)/(0.20 + ln(7+1)*0.65) = 0.42？
(4) 将此预测因子均值居中是否会在解释和计算调整方面发生任何变化？
感谢您的时间！]]></description>
      <guid>https://stats.stackexchange.com/questions/653788/correctly-modelling-a-continuous-log-dose-response-relationship-in-meta-regressi</guid>
      <pubDate>Tue, 03 Sep 2024 09:50:52 GMT</pubDate>
    </item>
    <item>
      <title>多级回归，模型规范</title>
      <link>https://stats.stackexchange.com/questions/653787/multilevel-regression-model-specification</link>
      <description><![CDATA[我们非常感谢您就分析我们的研究设计的最佳方式提出建议：
我们研究了教育内容的传递媒体（即增强现实与视频）对记忆（“binary_memory_score”）随时间（“时间”）的影响。我们有 20 次增强现实体验，每次体验都有三个记忆问题（每个多项选择题有四个选项）。视频是增强现实体验的屏幕录制。
我们有两种条件（增强现实与视频），我们分别随机招募（在受试者之间）。参与者被要求参与教育内容并回答记忆问题。对于这两个组，参与者被招募到五个“群组”，代表不同的教育主题（例如群组 1 = 艺术，群组 2 = 科学），这意味着群组也是一个受试者间变量。在每个队列中，所有队列参与者都经历了五种关于该队列主题的特定体验（在队列 1 中，我们有体验 1、体验 2、体验 3、体验 4、体验 5；在队列 2 中，我们有体验 6、体验 7 等）。
在完成每项体验后的初始记忆测试（time_0）之后，一些参与者在 1 个月后（gap1）或 6 个月后（gap6）再次被问到问题（time_later）。因此，我们有一个受试者内时间因素（time_0 vs time_later）和一个受试者间差距因素（gap1 vs gap6）。我们目前将记忆作为二元变量（正确答案 vs 错误答案）作为单个记忆问题（“exp_title_question”）的“分数”。以下是我们提出的使用 glmer 的分析：
binary_memory_score ~ 1 + media*time*gap + (1 | experience / experience_question) + (1 + time | id) + (1 | cohort / id), family = binomial(&quot;logit&quot;), nAGQ=0, control=glmerControl(optimizer = &quot;nloptwrap&quot;), data=combined_data_cor_screened,contrasts = list(media = contr.sum, time=contr.sum, gap=contr.sum))

非常感谢您的想法或建议。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653787/multilevel-regression-model-specification</guid>
      <pubDate>Tue, 03 Sep 2024 08:23:00 GMT</pubDate>
    </item>
    <item>
      <title>如何评估忽略重复测量的错误线性模型下的治疗效果估计？</title>
      <link>https://stats.stackexchange.com/questions/653786/how-to-evaluate-estimation-of-treatment-effect-under-wrong-linear-model-ignoring</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653786/how-to-evaluate-estimation-of-treatment-effect-under-wrong-linear-model-ignoring</guid>
      <pubDate>Tue, 03 Sep 2024 08:11:52 GMT</pubDate>
    </item>
    <item>
      <title>回归方程预测值的标准差</title>
      <link>https://stats.stackexchange.com/questions/653785/standard-deviation-of-predicted-value-of-a-regression-equation</link>
      <description><![CDATA[在残差独立的典型回归设置中，响应变量的新值的标准差将是
${\sigma} \sqrt{ \left(1 + a^T { \left(X^T X \right)}^{-1} a\right)}$
其中 $\sigma$ 是回归方程中误差项的标准差，$a$ 是解释变量的新值的向量，$X$ 是用于估计回归参数的设计矩阵。
然而在我的例子中，误差不是独立的，而是遵循以下形式
${\varepsilon}_{t} = {\gamma}_{1}{\varepsilon}_{t-1} + {\gamma}_{2}{\varepsilon}_{t-2} + {\nu}_{t} $
这里${\nu}_t$服从独立正态分布。
在这种情况下，我如何才能正确得出响应变量新值的标准差？
任何指针或在线资源都会非常有帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/653785/standard-deviation-of-predicted-value-of-a-regression-equation</guid>
      <pubDate>Tue, 03 Sep 2024 07:48:05 GMT</pubDate>
    </item>
    <item>
      <title>标题：用 Python 拟合带有趋势项的准周期函数的问题</title>
      <link>https://stats.stackexchange.com/questions/653784/title-issues-with-fitting-a-quasi-periodic-function-with-a-trend-term-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653784/title-issues-with-fitting-a-quasi-periodic-function-with-a-trend-term-in-python</guid>
      <pubDate>Tue, 03 Sep 2024 07:17:48 GMT</pubDate>
    </item>
    <item>
      <title>anova（）和summary（）之间的区别？</title>
      <link>https://stats.stackexchange.com/questions/653778/difference-between-anova-and-summary</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653778/difference-between-anova-and-summary</guid>
      <pubDate>Tue, 03 Sep 2024 01:59:06 GMT</pubDate>
    </item>
    <item>
      <title>经过超参数调整、数据集平衡和卷积分层后，模型仍然过拟合</title>
      <link>https://stats.stackexchange.com/questions/653776/model-still-overfits-after-hyperparameter-tuning-dataset-balancing-and-convolut</link>
      <description><![CDATA[我尝试将堆叠在一起的 25x25 像素图像分类为 50x25 像素图像是相同 (1) 还是不同 (0)。我使用 keras 创建 NN 层。训练集中有 1 和 0 的实例 10,000 个，而验证集中有 2000 张 1 的图像和 500 张 0 的图像。
相同 (1) 的示例数据集：

不同 (0) 的示例数据集：

Keras 顺序层如下所示：
layers.Input((2*imsize,imsize,3)), 
layers.Reshape((2,imsize,imsize,3)), 
layers.LayerNormalization(axis=[-1,-2,-3]), 
layers.Flatten(), 
layers.Dense(16,activation=&#39;relu&#39;), 
layers.Dense(2,activation=&#39;softmax&#39;) 

然后我使用 adam 优化器编译了这些层，损失和准确率如下：
ml.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), 
metrics=[&#39;accuracy&#39;])
ml_hist = ml.fit(x=training_dataset, epochs=20, validation_data = validation_dataset, shuffle=True)

之后，我使用 epoch=20 和 batch_size=100 训练模型。我根据 epoch 绘制了这些结果。
结果

尝试将验证集平衡为 500 个 1 和 500 个 0 后，结果仍然过度拟合

我甚至删除了正则化并添加了 2 个卷积和池化层有用。它只会导致较低的准确率
layers.Input((2*imsize,imsize,3)), 
layers.Reshape((2*imsize,imsize,3)), 
layers.LayerNormalization(axis=[-1,-2,-3]), 

# 新层 
layers.Conv2D(32, (3, 3),activation=&#39;relu&#39;,padding=&#39;same&#39;),
layers.MaxPooling2D(pool_size=(2, 2)),
layers.Conv2D(64, (3, 3),activation=&#39;relu&#39;,padding=&#39;same&#39;),
layers.MaxPooling2D(pool_size=(2, 2)),

layers.Flatten(), 
layers.Dropout(rate=0.7), 
layers.Dense(16,activation=&#39;relu&#39;),
layers.Dense(2,activation=&#39;softmax&#39;) 


我的问题是：如何解决这个过度拟合问题？我不知道我做错了什么，我尝试将学习率更改为 0.1、0.01 和 0.001。我还尝试在 Flatten() 之后、ReLu 之前添加 0.2、0.5 和 0.7 的 Dropout 层。]]></description>
      <guid>https://stats.stackexchange.com/questions/653776/model-still-overfits-after-hyperparameter-tuning-dataset-balancing-and-convolut</guid>
      <pubDate>Tue, 03 Sep 2024 00:30:42 GMT</pubDate>
    </item>
    <item>
      <title>3-D 图表适合于什么情况？</title>
      <link>https://stats.stackexchange.com/questions/653752/in-what-instances-are-3-d-charts-appropriate</link>
      <description><![CDATA[多年来，我读过的所有与数据分析相关的文章都建议在几乎所有情况下都不要使用三维图表。引用其中一句话，“当二维图表就足够时，永远不要使用三维图表。”
这引出了一个问题：在什么情况下三维图表是合适的？]]></description>
      <guid>https://stats.stackexchange.com/questions/653752/in-what-instances-are-3-d-charts-appropriate</guid>
      <pubDate>Mon, 02 Sep 2024 15:41:10 GMT</pubDate>
    </item>
    <item>
      <title>省略随机斜率时，如何使用 lmer()、anova() 和 bootstrap 评估混合模型？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653749/how-to-evaluate-mixed-model-using-lmer-anova-and-bootstrap-when-omitting-ra</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653749/how-to-evaluate-mixed-model-using-lmer-anova-and-bootstrap-when-omitting-ra</guid>
      <pubDate>Mon, 02 Sep 2024 15:12:12 GMT</pubDate>
    </item>
    <item>
      <title>当从混合模型中省略固定效应时，如何解释 1 型错误？</title>
      <link>https://stats.stackexchange.com/questions/653747/how-to-interpret-type-1-error-when-omitting-fixed-effect-from-mixed-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653747/how-to-interpret-type-1-error-when-omitting-fixed-effect-from-mixed-model</guid>
      <pubDate>Mon, 02 Sep 2024 14:21:54 GMT</pubDate>
    </item>
    <item>
      <title>具有 [0,1] 中连续权重的随机块模型</title>
      <link>https://stats.stackexchange.com/questions/653746/stochastic-blockmodel-with-continuous-weights-in-0-1</link>
      <description><![CDATA[我想使用随机块模型 (SBM) 对网络中的节点进行聚类，其中边权重是 0 到 1 之间的连续数字。似乎 blockmodels 和 SBM 等 R 软件包为权重提供了伯努利、泊松和高斯分布。高斯是唯一提供的连续分布（在我查看过的软件包中），但我的权重分布为众数为 0（最小值），一些权重恰好为零（可能不是问题，因为似乎允许不存在边），而其他权重从众数为零向上严重倾斜分布。我确实明白，SBM 中的高斯模型并不一定意味着权重必须整体呈高斯分布，因为它可以是社区内和社区之间的不同高斯的混合，但似乎仍然没有办法将两个或几个高斯的混合放在一起来模拟我所拥有的权重分布。此外，我很惊讶地发现边缘权重首先是高斯分布，因为在我知道的几乎所有情况下，权重都被限制为正，而高斯分布将质量放在整个实线上（当然，它有时仍然是正数据的良好近似值）。
在这种情况下该怎么办？无论如何都要拟合高斯模型？是否有任何版本的 SBM 实现假设其他分布，例如指数或 Beta？我应该将权重转换为“近高斯”吗？如果可能的话？
更一般地说，我是否正确理解了高斯假设适用于原始权重（分别在社区之间和社区内），而不是某些潜在变量或允许强非高斯权重的东西？我发现很难找到对连续权重的 SBM 的全面解释。此外，对我来说似乎很奇怪，唯一可用于连续数据的模型似乎是一种作为标准生成负值的模型，而实际上我所看到的只是权重被限制为非负值。]]></description>
      <guid>https://stats.stackexchange.com/questions/653746/stochastic-blockmodel-with-continuous-weights-in-0-1</guid>
      <pubDate>Mon, 02 Sep 2024 14:01:31 GMT</pubDate>
    </item>
    </channel>
</rss>