<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 21 Aug 2024 03:17:43 GMT</lastBuildDate>
    <item>
      <title>Little 的 MCAR 中包含太多连续变量会导致 1 类错误吗？</title>
      <link>https://stats.stackexchange.com/questions/653093/can-including-too-many-continuous-variables-in-littles-mcar-result-in-type-1-er</link>
      <description><![CDATA[在检查单个项目级别的缺失数据时（在计算量表分数之前），我的每个单个项目的缺失数据范围为 0% - 1.7%。
当我需要检查数据是否随机缺失时，单个项目级别是否存在阈值（例如，Little 的 MCAR）。我听过和读过 5% 的说法，但我不清楚它们是指每个单个项目的缺失 5%，还是整个数据集中的项目总数的缺失 5%，还是在计算的量表分数级别。
出于兴趣，我对我的单个问卷项目运行了 Little 的 MCAR，测试结果显著，这意味着我的数据是 MNAR。然而，这对我来说似乎很奇怪，因为每个单个项目中缺失数据的比例都很低（我的样本量为 299 名参与者）。考虑到缺失数据的低水平，Little 的测试是否可能无效？我有大约 230 个项目 x 299 名参与者。我是否应该针对这种程度的缺失值运行这项测试？或者一次针对这么多项？
当目视检查缺失数据时，没有明显的模式，缺失数据是零散的，看似随机的。数据是 MNAR 感觉很奇怪。]]></description>
      <guid>https://stats.stackexchange.com/questions/653093/can-including-too-many-continuous-variables-in-littles-mcar-result-in-type-1-er</guid>
      <pubDate>Wed, 21 Aug 2024 00:41:07 GMT</pubDate>
    </item>
    <item>
      <title>优化正定矩阵的简单问题</title>
      <link>https://stats.stackexchange.com/questions/653090/simple-problem-of-optimizing-a-positive-definite-matrix</link>
      <description><![CDATA[我正在编写一个关于约束优化的简单教程。我计划使用两个示例：约束一个向量具有单位范数，约束一个矩阵为对称正定矩阵。我想用合成数据来提供一些此类优化的非常简单的示例。
例如，对于单位范数约束，我生成单位圆上分布的随机样本，然后优化一个向量 $\theta$，以最小化到样本的平均平方距离。当不约束 $\theta$ 时，结果不在单位圆内，而添加约束后，我们得到一个在单位圆内的 $\theta$。
我试图想出一个同样简单直观的问题，涉及优化某个应该是正定的矩阵 $\Sigma$。但是，我想不出任何简单明了的东西。例如，如果我们想按照上述方法操作并找到最小化与一组正定矩阵的距离的矩阵，则不受约束的结果将是正定的。我曾考虑过使用一个损失函数将 $\Sigma$ 推向非 SPD 矩阵，但后来我猜想优化过程不会收敛。
因此，我的问题是，矩阵 $\Sigma$ 上的一些简单的、表现良好的优化问题是什么，直观地了解我们为什么要让它是正定的，以及如果我们在优化中不包含约束，它在哪里不会是正定的？我希望能够在我的教程中用不太多的代码为我的问题合成数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/653090/simple-problem-of-optimizing-a-positive-definite-matrix</guid>
      <pubDate>Tue, 20 Aug 2024 22:33:09 GMT</pubDate>
    </item>
    <item>
      <title>使用随机效应模型对标准误差进行聚类？</title>
      <link>https://stats.stackexchange.com/questions/653089/clustering-standard-errors-with-a-random-effects-model</link>
      <description><![CDATA[我正在评估失业率 (X) 与人均酒后驾车逮捕率 (Y) 之间的关系。我有一个包含 2000 个县的面板，t=15。
我正在使用 r 上的 plm 包运行随机效应模型。是否可以在县级对 SE 进行聚类？]]></description>
      <guid>https://stats.stackexchange.com/questions/653089/clustering-standard-errors-with-a-random-effects-model</guid>
      <pubDate>Tue, 20 Aug 2024 22:29:37 GMT</pubDate>
    </item>
    <item>
      <title>Probit 中的内生交互项和稳健标准误差</title>
      <link>https://stats.stackexchange.com/questions/653087/endogenous-interaction-terms-in-probit-and-robust-standard-errors</link>
      <description><![CDATA[我使用 Probit 模型来处理内生独立变量 X1，并创建了与独立变量的交互项（见下面的公式）。我使用的是横截面数据。
Y= X1 + X2 + X3 + X1*X2 + X1*X3 +constant
通过查看其他帖子，我意识到我无法使用 ivprobit（在 Stata 中），因为交互项也是内生的。但我不确定我的方法是否有效，以下是我所做的：
regress X1 Z1 X2 X3
estimate X1_hat, xb
gen X1X2_hat = X1_hat * X2
gen X1X3_hat = X1_hat * X3
probit Y X1_hat X2 X3 X1X2_hat X1X3_hat
Z1 是 X1 的工具。
我的问题是：

这些命令正确吗？如果正确，我如何在这些命令的基础上进行稳健标准误差计算？
如果它们不正确，我可以使用哪些命令来运行回归？

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653087/endogenous-interaction-terms-in-probit-and-robust-standard-errors</guid>
      <pubDate>Tue, 20 Aug 2024 22:05:19 GMT</pubDate>
    </item>
    <item>
      <title>仅根据白球数量猜测选了多少个球</title>
      <link>https://stats.stackexchange.com/questions/653084/guessing-how-many-balls-picked-based-on-number-of-white-balls-only</link>
      <description><![CDATA[我有一个白球和黑球池。在这个例子中，假设 20% 是白球，其余 80% 是黑球。
现在，随机地，某人按照某种选择分布挑选不同数量的球，例如 1 挑选 10% 2 挑选 20% 3 挑选 60 4 挑选 10%。
如果最后，我只被允许看到该人每次尝试挑选了多少个白球，我怎么知道该人从池子里挑选 X 个球的可能性有多大？
我应该如何思考这个问题？
示例：同样是一个 20% 白球和 80% 黑球的无限池。人 B 可以按照挑选概率为每次试验随机挑选不同数量的球 1 挑选 10% 2 挑选 20% 3 挑选 60% 4 挑选 10%。甲只能询问乙在每次试验中挑选了多少个白球。（顺序无关紧要）
假设乙挑选了：
1 白 1 黑
0 白 2 黑
1 白 2 黑
1 白 1 黑
2 白 2 黑
1 白 2 黑
1 白 0 黑
3 白 0 黑
0 白 1 黑
0 白 1 黑
甲有一份乙在 10 次试验中挑选的白球列表（1、0、1、1、2、1、1、3、0、0）。我该如何思考 B 每次试验从球池中挑选多少个球的可能性？
或者我也可以问一个不同的问题，我该如何估计 B 的挑选概率，即不知道 B 如何挑选球，我该如何猜测 1 挑选 10% 2 挑选 20% 3 挑选 60% 4 挑选 10% 的挑选概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/653084/guessing-how-many-balls-picked-based-on-number-of-white-balls-only</guid>
      <pubDate>Tue, 20 Aug 2024 20:58:22 GMT</pubDate>
    </item>
    <item>
      <title>BCa bootstrap CI 调整 A-B 组中位数差异的偏差，但不调整相反方向的偏差</title>
      <link>https://stats.stackexchange.com/questions/653083/bca-bootstrap-ci-adjusts-for-bias-in-median-difference-of-groups-a-b-but-not-th</link>
      <description><![CDATA[我正在使用 R 中的 boot-package 来计算两组 A 和 B 等待时间中位数差异的 BCa bootstrap 间隔，四舍五入为天数。原始样本的中位数差异为 $t0$，中位数的 bootstrap 复制为 $t$。
每组的等待时间都是长尾的，但大部分质量集中在一小组离散值上。总体而言，引导分布将 20% 的质量置于 $t0$ 左侧，将 40% 的质量置于 $t0$ 处，将 40% 的质量置于 $t0$ 右侧。
令我惊讶的是，我注意到 BCa 置信区间存在很大差异，具体取决于我估计的是“A 组中位数 - B 组中位数”还是“B 组中位数 - A 组中位数”。百分位数 CI 的情况并非如此，因为方向的改变只会翻转 y 轴周围的引导分布，一个方向的 2.5 百分位数对应于翻转引导分布的 97.5 百分位数。
但是，由于 $t0$ 周围的 20/40/40 分布，BCa 中的偏差校正参数 $z_0$ 有效地重新排列了 $\alpha=0.05$ 在 B-A 方向上的幅度比在 A-B 方向上的幅度大得多。
$$ z_0 = \Phi^{-1}(\Sigma(t&lt;t0)/B) $$
对于我的数据，在 A-B 中，使用 BCa 时 $t$ 的百分位数变为 0.01 和 0.95，而在 B-A 另一个方向上，则为 0.0001 和 0.60。引导包正确地发出了关于“BCa 区间使用极端分位数，某些 BCa 区间可能不稳定”的警告。
如果我相信偏差校正实际上正在做一些明智的事情，它会告诉我，由于对 40% 侧存在强烈偏差，偏差调整后的中位数差异应该强烈推向 20% 侧，在 20% 侧尾部，我们实际上不能相信引导分布在极端尾部是可靠的。
幸运的是，这次我最关心的区间端点不是极端的（0.0001 百分位数），而是 0.60 百分位数，我想它应该和引导分布的第 97.5 百分位数一样值得信赖。也就是说，如果一个人对不能信任“另一个”持务实态度，那么可以使用偏差调整间隔端点（是的，距离零最远的那个）。
令我感到不安的是，我必须在两个方向上运行间隔才能得出这个严重偏差的发现。
如果我误解了什么，或者如果您知道将来不涉及在两个方向上运行我的所有中位数差异的解决方案，我很乐意听到任何评论。]]></description>
      <guid>https://stats.stackexchange.com/questions/653083/bca-bootstrap-ci-adjusts-for-bias-in-median-difference-of-groups-a-b-but-not-th</guid>
      <pubDate>Tue, 20 Aug 2024 20:46:33 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何修正逻辑回归中的分类表？</title>
      <link>https://stats.stackexchange.com/questions/653082/how-should-i-correct-my-classification-table-in-logistic-regression</link>
      <description><![CDATA[模型系数的综合检验表明该模型是显著的。但是，区块 1 下的分类表显示的观测值与预测值的比率与区块 0 相同。这是否意味着我的独立变量对模型没有贡献？我的 nagelkarke、cox 和 snell 也很小，但方程中的变量显示出显著的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/653082/how-should-i-correct-my-classification-table-in-logistic-regression</guid>
      <pubDate>Tue, 20 Aug 2024 20:42:10 GMT</pubDate>
    </item>
    <item>
      <title>准确计算截断二项式期望</title>
      <link>https://stats.stackexchange.com/questions/653081/compute-a-truncated-binomial-expectation-accurately</link>
      <description><![CDATA[我需要计算二项式随机变量的以下期望值
$$E_{S \sim \rm{Binom}(\frac{k}{M}; N)} \left[\left(\frac{k-1}{k}\right)^S 1_{\{S \leq k\}}\right] = \sum_{s=0}^k \binom{N}{s} \left(\frac{k}{M}\right)^s \left(1 - \frac{k}{M}\right)^{N-s} \left(\frac{k-1}{k}\right)^s.$$
变量的典型范围是 $0 &lt; k \leq 256$，$M = N = 10^9$。如果 $k = N$，则可以使用二项式 RV 的独立伯努利分解来很好地评估。如果不存在 $\left(\frac{k-1}{k}\right)^s$ 项，则这是二项式的累积分布函数，等于不完全 Beta 积分，并且在数值上相当稳定。但是，如何以数值稳定的方式处理上述混合公式？我不需要它很快，只需要给我合理的数字而不是 nan 或类似的数字 $&gt; 1$.
更新：为了完整性，总和可以用超几何函数重写
$$\sum_{s=0}^k \binom{N}{s} p^s q^{N-s} = q^N\left((1 + p/q)^N - (p/q)^{k+1} \binom{N}{k+1} {}_2F_1(1, k-N + 1; k + 2; -p/q)\right),$$
其中
\begin{align*}
{}_2F_1(a, b; c; z) := \sum_{n=0}^\infty \frac{(a)_n(b)_n}{(c)_n} \frac{z^n}{n!}.
\end{align*}
但是对于非常大的 $N$，这会导致数字溢出。总和在 $n &gt; N - k + 1$ 之后终止，但不值得用 $k+1$ 项的总和与具有更多项的总和进行权衡。]]></description>
      <guid>https://stats.stackexchange.com/questions/653081/compute-a-truncated-binomial-expectation-accurately</guid>
      <pubDate>Tue, 20 Aug 2024 20:03:48 GMT</pubDate>
    </item>
    <item>
      <title>统计方法建议</title>
      <link>https://stats.stackexchange.com/questions/653079/advice-on-statistical-method</link>
      <description><![CDATA[我只是想听听大家对分析数据的最佳方法的看法，因为我对统计学不是很精通。
我一直在收集土壤中微生物的丰度数据。基因拷贝数。
我有两种森林类型（混合物种和竹子）和两种土壤深度（10 厘米和 50 厘米）。
我的问题是 - 方差分析在这里合适吗？因为我只有两种处理方法而不是三种？
我以为你需要两种以上的处理方法才能进行方差分析。
祝一切顺利]]></description>
      <guid>https://stats.stackexchange.com/questions/653079/advice-on-statistical-method</guid>
      <pubDate>Tue, 20 Aug 2024 19:48:54 GMT</pubDate>
    </item>
    <item>
      <title>在双重稳健学习器中，结果模型和倾向模型的协变量是否需要相同？</title>
      <link>https://stats.stackexchange.com/questions/653076/in-a-doubly-robust-learner-do-the-covariates-need-to-be-the-same-for-the-outcom</link>
      <description><![CDATA[这可能是一个愚蠢的问题，但我还没有找到明确的答案。在双重稳健学习器/估计器中，在创建结果模型和倾向模型时，我们是否需要使用相同的特征集 X？或者我们可以将 X 的子集用于倾向模型，甚至将完全不同的特征一起使用吗？
从我读到的内容来看，它们似乎使用相同的协变量，但这是硬性规定吗？如果我使用单独的特征对它们进行建模，会违反任何规定吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653076/in-a-doubly-robust-learner-do-the-covariates-need-to-be-the-same-for-the-outcom</guid>
      <pubDate>Tue, 20 Aug 2024 19:08:34 GMT</pubDate>
    </item>
    <item>
      <title>常数与独立变量共享一个系数的回归</title>
      <link>https://stats.stackexchange.com/questions/653070/regression-with-a-constant-sharing-a-coefficient-with-an-independent-variable</link>
      <description><![CDATA[我有一个方程式，想估算一下，但不确定如果有的话会有什么影响。
Y = b0 + b1 * p + b1 * X + e

其中，
Y 是因变量
b0 是截距
X 是自变量
b1 是 X 的系数
e 是误差
p 是常数值或 0，70% 的 obs 的 p = 0，其余 30% 的 obs 都有一个它们都共享的常数值。

编辑：我无法将 p 与 X 合并。这是数据性质的一部分。尽管将 p 添加到 X 简化了估计，但模型无法进行解释。
我需要 p，而不是拥有自己的系数，因为它必须与 X 共享系数 b1。
我希望，因为变量 p 是常数或 0，所以它不会对 X 的系数 b1 产生任何影响。
我是否正确地假设 p 不会产生影响，因为它是常数或 0？我可以将 b1*p 简化为某种不带有自身系数的指示变量吗？
不确定如何解决这个问题]]></description>
      <guid>https://stats.stackexchange.com/questions/653070/regression-with-a-constant-sharing-a-coefficient-with-an-independent-variable</guid>
      <pubDate>Tue, 20 Aug 2024 18:18:44 GMT</pubDate>
    </item>
    <item>
      <title>在建立模型时选择随机观察作为参考的最佳做法是什么？</title>
      <link>https://stats.stackexchange.com/questions/653060/what-are-the-best-practices-for-selecting-a-random-observation-as-a-reference-wh</link>
      <description><![CDATA[我正在开展一个项目，需要构建一个模型来预测给定的 Spark 配置是否优于其他配置。我对“更好”的标准是基于每秒核心电压指标。
为了实现这一点，我有一个数据集，其中包含各种 Spark 配置及其各自的每秒核心电压值。我最初的方法是使用随机选择的行作为参考，然后创建一个新列，指示每个配置是否比随机选择的参考配置更好 (1) 或更差 (0)。
但是，我意识到由于参考配置是随机选择的，因此模型的性能可能高度依赖于此选择。例如，在极端情况下，如果参考配置是数据集中最好的，则所有其他配置都将获得 0，并且模型不会学到太多东西。
我的问题是：处理这种情况的最佳方法是什么？
我考虑过以下方法：
1/ 构建多个模型，每个模型都有不同的参考配置，并根据投票系统做出决策。
2/ 使用每秒平均或中位数 Vcor​​e 作为参考，因此性能优于平均值（或中位数）的配置获得 1，而性能较差的配置获得 0。
我愿意接受建议，并感谢任何讨论类似问题的理论方面或实际解决方案的参考资料或论文。]]></description>
      <guid>https://stats.stackexchange.com/questions/653060/what-are-the-best-practices-for-selecting-a-random-observation-as-a-reference-wh</guid>
      <pubDate>Tue, 20 Aug 2024 15:27:30 GMT</pubDate>
    </item>
    <item>
      <title>使用弹性网络进行特征选择[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653042/feature-selection-with-elastic-net</link>
      <description><![CDATA[我是机器学习中特征选择的新手。我读到弹性网络相对优于 Lasso 和 Ridge 回归，并且还考虑了多重共线性，所以我选择了这种方法进行特征选择。
我编写了一个代码，该代码将在嵌套交叉验证设置（5 个内折和 20 个外折）之后从最佳弹性网络模型（即具有 alpha 和 lambda 组合的弹性网络，可检索最佳 AUC）中选择最佳特征，并使用这些特征进行进一步的模型训练。
尽管如此，我不太确定我是否做对了，特别是在嵌套交叉验证方面。此外，当我尝试检索 alpha 和 lambda 以报告其可重复性时，我无法在结果中找到它。
以下是代码：
set.seed(1)
train_elastic_net &lt;- function(X_train, y_train, alphas, lambdas) {
best_auc &lt;- 0
best_model &lt;- NULL
best_features &lt;- NULL

for (alpha_value in alphas) {
# 设置用于交叉验证的训练控制
train_control &lt;- trainControl(method = &quot;cv&quot;, 
number = 5, 
classProbs = TRUE, 
summaryFunction = twoClassSummary)

# 定义调整网格
tune_grid &lt;- expand.grid(alpha = alpha_value, lambda = lambdas)

# 使用 caret 训练模型
model &lt;- train(X_train, y_train,
method = &quot;glmnet&quot;,
trControl = train_control,
tuneGrid = tune_grid,
metric = &quot;ROC&quot;,
family = &quot;binomial&quot;)

# 获取最佳模型
best_lambda &lt;- model$bestTune$lambda
elastic_net_model &lt;- glmnet(as.matrix(X_train), y_train, 
alpha = alpha_value, lambda = best_lambda, 
family = &quot;binomial&quot;)

# 获取最佳模型的 AUC
auc &lt;- max(model$results$ROC)

# 更新最佳模型如果当前的更好
如果 (auc &gt; best_auc) {
best_auc &lt;- auc
best_model &lt;- elastic_net_model
coef_elastic_net &lt;- coef(best_model, s = best_lambda)
selected_features &lt;- which(coef_elastic_net != 0) - 1 
# 获取非零系数的索引
selected_features &lt;- selected_features[selected_features != 0] 
# 删除截距索引
best_features &lt;- selected_features
}
}

list(model = best_model, features = best_features)
}

y_train_factor &lt;- as.factor(y_train_total)
X_train_matrix &lt;- as.matrix(X_train_total)

# 定义要搜索的 alpha 和 lambda 值
alpha_values &lt;- seq(0.1, 1, by = 0.1)
lambda_values &lt;- 10^seq(-4, 1, length = 100)

# 为每个分割执行 20 次重复
n_repeats &lt;- 20
selected_features_list &lt;- list()

for (i in 1:n_repeats) {

# 使用弹性网络执行变量选择
result &lt;- train_elastic_net(X_train_matrix, y_train_factor, 
alpha_values, lambda_values)
best_model &lt;- result$model
best_features &lt;- result$features

# 存储此重复的选定特征
selected_features_list[[i]] &lt;- best_features
}
selected_features_list
# 聚合在所有重复中选择的特征
selected_features_final &lt;- Reduce(intersect, selected_features_list)
selected_features_final
# 使用最终选定的特征对训练数据进行子集化
X_train_total &lt;- X_train_total[, selected_features_final]
]]></description>
      <guid>https://stats.stackexchange.com/questions/653042/feature-selection-with-elastic-net</guid>
      <pubDate>Tue, 20 Aug 2024 09:37:53 GMT</pubDate>
    </item>
    <item>
      <title>glmmTMB 的预测函数</title>
      <link>https://stats.stackexchange.com/questions/653020/predict-function-for-glmmtmb</link>
      <description><![CDATA[我有以下模型：
mod &lt;- glmmTMB(cound_data ~ year-1 +(1|Site), ziformula = ~year-1, data = df, family = &quot;nbinom2&quot;)。我正在对 4 个不同年份和 38 个不同站点的计数数据进行建模。由于数据中存在许多零，我使用零膨胀模型。我的主要兴趣在于年份的影响，但我也对探索不同站点的结果感兴趣。
我使用代码获得固定效应：fixef(mod)，使用代码获得随机效应：ranef(mod)。
假设对于 2018 年，我的固定效应为 0.85，对于站点&quot;X&quot;，我的随机效应（截距）为 -0.18。根据我的理解，要获得站点&quot;X&quot;的预测值在 2018 年，我应该手动计算如下：exp(0.85-0.18)=1.95。
但是，当我使用 predict() 函数时：df$predicted_mean &lt;- predict(mod, newdata = df, re.form = NULL, type = &quot;response&quot;) 我获得了 2018 年站点 &quot;X&quot; 的不同值，例如 1.1。我不认为这种差异是由于舍入误差造成的。
predict() 函数计算的值与我的手动计算不同吗？它也考虑了 ziformula 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653020/predict-function-for-glmmtmb</guid>
      <pubDate>Mon, 19 Aug 2024 17:37:05 GMT</pubDate>
    </item>
    <item>
      <title>如果获得的样本量比功效分析中显示的大得多，该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</link>
      <description><![CDATA[老实说，我们没想到这一点——毕竟我们一切都是按照剧本做的。
我们计划对一些心理问题进行研究，我们将问卷输入到 Qualtrics，在 G*Power 的帮助下，我们进行了功效分析以获得最小样本量，最后我们在互联网上发布了该研究的链接。然后样本量激增。几天后，我们检查了我们设法收集了多少观察结果，结果发现数量增加了四倍（所以我们匆忙停止收集数据）。功效分析表明 N = 500，我们得到了 N = 2000（当然是 2000 多）。开心吗？不，我们离幸福还很远。
问：现在我们有一个问题，如何处理超大样本（记住超强研究）。
想法是：

在第 500 次观察时截断——丢弃其余数据（听起来像是在浪费数据）
在第 500 次观察时截断，使用其余数据作为复制研究（听起来很狡猾，我们实际上没有进行复制研究，数据来自原始研究）
从我们的大数据（N = 2000）中抽取样本 - 不放回抽样，样本由N = 500 次观察组成（并丢弃休息）。
... 大家还有其他想法吗？你们遇到过这种情况吗？你们做了什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</guid>
      <pubDate>Sun, 18 Aug 2024 14:54:41 GMT</pubDate>
    </item>
    </channel>
</rss>