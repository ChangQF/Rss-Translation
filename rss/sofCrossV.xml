<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 15 Feb 2024 06:18:27 GMT</lastBuildDate>
    <item>
      <title>T分布和CLT</title>
      <link>https://stats.stackexchange.com/questions/639313/t-distribution-and-clt</link>
      <description><![CDATA[根据定义，T 分布是标准正态变量与缩放 $\chi^2$ 变量的 sqrt 之比。 “流行的” （一个样本）t 统计量的版本如下：$\frac{\bar{x}-\mu}{S/\sqrt{n}}$。但实际上，这是使用 $t = \frac{Z}{\sqrt{\frac{\chi^2_{(n-1)}}{n-1}} 导出的} = \frac{\frac{\bar{x}-\mu}{\sigma/\sqrt{n}}}{\sqrt{\frac{(n-1)S^2/\sigma^2}{ n-1}}} = \frac{\bar{x}-\mu}{S/\sqrt{n}}$。
$Z$ 来自 CLT 假设，即样本均值近似正态分布。非正式地，这仅适用于幻数 $n &gt;= 30$。由于 t 统计量是基于这一假设构建的，那么单样本 t 检验不应该仅在 $n &gt;= 30$ 时应用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639313/t-distribution-and-clt</guid>
      <pubDate>Thu, 15 Feb 2024 05:13:27 GMT</pubDate>
    </item>
    <item>
      <title>混淆矩阵的线性代数性质（特征值、特征向量和行列式）</title>
      <link>https://stats.stackexchange.com/questions/639312/linear-algebra-properties-of-a-confusion-matrix-eigenvalues-eigenvectors-and</link>
      <description><![CDATA[对 Math Stack Exchange 上一个问题的回答让我开始思考混淆矩阵不仅仅是一个数字的矩形数组。我们不会将混淆矩阵视为线性变换，但我们确实将其称为“矩阵”，所以为什么不考虑它们的线性代数属性。
似乎 $2\times 2$ 混淆矩阵与 phi 系数有关。 行列式与特征值有关。特征值对于评估分类器性能是否有用（除了相乘以给出与 phi 系数相关的行列式之外）？特征向量能告诉我们什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639312/linear-algebra-properties-of-a-confusion-matrix-eigenvalues-eigenvectors-and</guid>
      <pubDate>Thu, 15 Feb 2024 04:20:24 GMT</pubDate>
    </item>
    <item>
      <title>为随机森林模型选择合适的样本量</title>
      <link>https://stats.stackexchange.com/questions/639311/choosing-a-suitable-sample-size-for-a-random-forest-model</link>
      <description><![CDATA[我知道这并不总是一个需要直接回答的问题，但我正在研究一个全省范围的湿地分类模型，该模型具有 $7$ 类和 &lt; span class=&quot;math-container&quot;&gt;$32$ 左右解释变量。在我的模型中，我有一个 $92 \%$ OA，价格在 $90 - 98$ PA 和UA。在检查模型并每天使用它进行研究后，我发现它相当准确。
我有 $2000$ 训练/验证点。 $20 \%$ 用于验证。
一旦开始得到我想要的结果，我就停止训练模型并构建我​​的训练和验证集。您认为我的样本量足够大并且站得住脚吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639311/choosing-a-suitable-sample-size-for-a-random-forest-model</guid>
      <pubDate>Thu, 15 Feb 2024 02:55:15 GMT</pubDate>
    </item>
    <item>
      <title>自回归遇到多元回归？ - 帮助解决措辞和方法</title>
      <link>https://stats.stackexchange.com/questions/639310/autoregession-meets-multiple-regression-help-with-verbiage-and-approach</link>
      <description><![CDATA[需要一些关于我如何接近这个模型的措辞和意见方面的帮助。
我统计了过去 24 个月的人数。

&lt;标题&gt;

月
计数


&lt;正文&gt;

1
100


2
105


...
...


24
200



首先，我将月份反转为：

&lt;标题&gt;

月
计数


&lt;正文&gt;

24
100


23
105


...
...


1
200



我从 24 个月开始创建多个自定义期间...

&lt;标题&gt;

期间
月


&lt;正文&gt;

3
1


3
2


3
3


6
1


...
...


6
6


9
1


9
...


9
9


...
...


24
24



对于每个时期，我计算线性回归并预测下一个值

&lt;标题&gt;

期间
lr_坡度
lr_拦截
lr_r2
预测下一个
期间_权重*
贡献


&lt;正文&gt;

3
4.543
903
.4499
900
1/3*
300


6
44.67
309
.9944
903
1/6*
150.5


9
990.33
33.990
.9494
910
1/9*
101.11


...
...
...
...
980

...


24
776.677
77.09
.0009
990
1/24*
41.5



对于此示例，假设 SUM(period_weight) = 1
贡献是 period_weight * Forecast_next
我总结了上述所有贡献以获得最终的预测值。
这是一个有效的回归模型吗？它模仿当前模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639310/autoregession-meets-multiple-regression-help-with-verbiage-and-approach</guid>
      <pubDate>Thu, 15 Feb 2024 01:20:40 GMT</pubDate>
    </item>
    <item>
      <title>估计最大效应大小和 Skillings-Mack 检验</title>
      <link>https://stats.stackexchange.com/questions/639309/estimating-maximum-effect-size-and-skillings-mack-test</link>
      <description><![CDATA[我正在处理符合 Skillings-Mack 测试的数据：不平衡不完整的块设计。或者类似弗里德曼测试的缺失数据。
如果测试结果为阴性，我想估计可以“隐藏”测试结果的最大效应大小。数据中。
通过弗里德曼检验，我可以相当容易地估计效果的大小，方法是选取任意两组并根据成对差异（无论是均值、中位数还是截尾均值）引导 95% 置信区间。
但是，当样本中的组大小遵循二项式分布时，即使是最高计数组的大小也非常小，因此自举置信区间非常大，即使 Skillings-Mack 检验非常显着（p 值 &lt; 1e -9)。
具体示例
我想要测量的是其中一个变量的汉明权重（RSA）对测量变量（使用该素数进行 RSA 签名的时间）有影响。问题在于变量（素数）是均匀随机的并且具有特定的位长度（如 1024）。这意味着预期的汉明权重将遵循 p=0.5 且 N=1024 的二项式分布。
在缺乏独立性产生影响之前，我可以执行大约 10 到 30 次测量，因此我的 Skillings-Mack 块不大于 30 次测量。块中的具体权重是独立且随机的。这意味着对于特定的汉明权重（例如 511 和 513），很少有块实际上会同时包含这两个权重，在我看来，引导单个对严重低估了样本中的效应大小（Skillings-Mack 测试可以报告1e-18 的 p 值和成对差异 95% 置信区间仍包含零，符号检验和 Wilcoxon 符号秩检验均为负，p 值 &gt; 0.01）。
问题
如何估计此类数据的效应大小？
据我了解，排名上的重复测量方差分析也可以用于测试此类数据，但如果组的大小不同（我的组非常多），我也看到很少有反对它的建议。那是对的吗？如果没有，有没有办法用 rANOVA 来估计排名的效应大小？
我知道，如果测试结果为阴性，我可以修改特定组中的测量值，然后一次又一次地运行 Skillings-Mack 测试，看看什么时候了解它可以检测到的数据效果是什么变得很重要手，但这对于我期望需要收集的样本量（数亿个测量值）来说是相当昂贵的，更不用说严格指定应该修改哪个组是相当困难的。
背景
由于我正在测量计算机上操作的计算时间，因此我需要能够区分大约 1 毫秒的操作的亚 1 纳秒效应，但我还需要知道样本何时足够大且足够干净检测特定尺寸的效果。]]></description>
      <guid>https://stats.stackexchange.com/questions/639309/estimating-maximum-effect-size-and-skillings-mack-test</guid>
      <pubDate>Thu, 15 Feb 2024 00:48:43 GMT</pubDate>
    </item>
    <item>
      <title>格兰杰因果关系和 FEVD 的输出彼此相反</title>
      <link>https://stats.stackexchange.com/questions/639307/outputs-of-granger-causality-and-fevd-are-opposite-of-each-other</link>
      <description><![CDATA[这是关于双变量系统的协整或 VAR 分析。格兰杰因果关系要么表示工具 1（例如基金）和工具 2（例如指数）不是彼此的格兰杰原因，要​​么是工具 2 是工具 1 的格兰杰原因。
但是，当我看到FEVD输出时，指数90%以上的FEV都归因于基金。无论两种工具之间是否存在协整，这种情况都会发生。换句话说，set1 是协整的，并且估计 ECM，而 set2 不是协整的，并且估计差异中的 VAR。
这意味着 FEVD 和格兰杰因果关系输出显示相反的结果。我该如何解决这个问题？
这些输出已通过 E-Views 和 R 检查。因此，这可能不是由于我在 R 中编写的一些错误代码所致。我正在使用“使用 R 进行集成和协整时间序列分析”作者：Bernhard Pfaff 的 R 代码。


R 代码如下：
comboFEVD1&lt;-tsDyn::fevd(var_model_diff1,n.ahead = 10)
情节（组合FEVD1）

## R 的输出
# 截图已上传

tsVAR &lt;- vars::VAR(ret_df1, p = 2)
vars::causality(tsVAR, Cause = &quot;dindex&quot;)$Granger

## R 的输出
## 格兰杰因果关系 H​​0：dindex 不格兰杰因果 dfund
##
## 数据：VAR 对象 tsVAR
## F 检验 = 7.6993，df1 = 2，df2 = 2980，p 值 = 0.0004622

vars::causality(tsVAR, Cause = &quot;dfund&quot;)$Granger

## R 的输出
## 格兰杰因果关系 H​​0：dfund 不格兰杰因果 dindex
##
## 数据：VAR 对象 tsVAR
## F 检验 = 4.6794，df1 = 2，df2 = 2980，p 值 = 0.009353
]]></description>
      <guid>https://stats.stackexchange.com/questions/639307/outputs-of-granger-causality-and-fevd-are-opposite-of-each-other</guid>
      <pubDate>Thu, 15 Feb 2024 00:38:21 GMT</pubDate>
    </item>
    <item>
      <title>运行回归并且不清楚如何思考问题</title>
      <link>https://stats.stackexchange.com/questions/639303/running-a-regression-and-unclear-how-to-think-about-the-problem</link>
      <description><![CDATA[我想运行线性回归，以更好地理解力如何与分层/扭曲面部框架的位置相关。这是针对与机械工程相关的制造产品。因此，我在面部框架周围 8 个不同位置对 20 个独立单元进行了力测量。我使用单元位置编号作为 x 值（自变量），并将测量的力作为 y 值（因变量）。
我不确定如何在 Excel 中设置回归，因为面部框架上的每个位置都有 20 个单独的条目。但我希望能够查看数据，或许还可以根据 8 个位置中的 6 个位置来预测力的大小（在我的测试中显示出更高的力值）。我该如何设置呢？我将附上几张图片来提供一些背景。
在第一幅图像中，从左到右的测量值分别是最小值、平均值、最大值、标准偏差和范围（后面是 20 帧中每一帧的单独测量值）。第二张图显示了一个范围图，其中我根据位置（x 轴）确定了力测量的范围。

]]></description>
      <guid>https://stats.stackexchange.com/questions/639303/running-a-regression-and-unclear-how-to-think-about-the-problem</guid>
      <pubDate>Wed, 14 Feb 2024 21:57:45 GMT</pubDate>
    </item>
    <item>
      <title>计数数据和比例协变量：最佳实践</title>
      <link>https://stats.stackexchange.com/questions/639301/count-data-and-proportion-covariates-best-practices</link>
      <description><![CDATA[我正在处理空间数据，并且我有以下用于计数数据的对数线性模型。让 $y \sim Poisson(\lambda_{i})$ 使得
$$
\log \lambda_{i} = \text{x}_i^\top\beta_{} + \epsilon_{i}
$$
这样 $\epsilon_{ij}$ 就是站点 $i$ 处的空间效果。
我有每个站点的计数，我想将其作为响应变量进行分析，以及文献中所说的相关的其他辅助计数，并且可能会导致计数上升或下降。我的问题是将数据计数为协变量的最佳实践是什么，我应该使用

原始计数；
比例（我知道每个地点的总人口）；
$z$-分数。
]]></description>
      <guid>https://stats.stackexchange.com/questions/639301/count-data-and-proportion-covariates-best-practices</guid>
      <pubDate>Wed, 14 Feb 2024 21:44:05 GMT</pubDate>
    </item>
    <item>
      <title>如何使用具有成分（加起来为 1 的比例）预测变量的广义线性混合模型？</title>
      <link>https://stats.stackexchange.com/questions/639299/how-to-use-generalised-linear-mixed-model-with-compositional-proportions-that-a</link>
      <description><![CDATA[该研究分析了用户的视线，看看视线是否可以用来预测场景的记忆力。我的目标是观察时间和视觉目标（屏幕、机器人等）之间的交互，并查看用户在早期阶段（具体来说，120 秒中的前 25 秒）的注视分布是否更能体现记忆性比后期用户的注视分布。
以下变量与本研究相关：

已记忆：二进制响应变量，0 表示未记忆，1 表示已记忆
级别：它是一个从 0 -&gt; 0 的分类变量。 23. 这基本上是指时间间隔。 0 表示前 5 秒，23 表示第 23 个 5 秒间隔（即 115 秒-120 秒间隔）
机器人：这是用户看机器人的时间比例
屏幕：这是用户观看屏幕的时间比例
其他：这是用户注视非机器人或屏幕的目标的时间比例。
视觉：这是另一个分类变量，用于标识用户正在查看的场景。由于使用了具有多个参与者的单一场景，因此我将其用作随机效应。

请注意，机器人 + 屏幕 + 其他总和为 1。每个数据点都是 5 秒间隔（用 0 到 23 之间的数字表示），并具有相关的注视分布和可记忆性（响应）。
我有以下广义线性混合模型（广义是因为响应变量是二进制的）：
已记住 ~ 1 + 关卡 + 机器人 + 屏幕 + 关卡：屏幕 + 关卡：机器人 + (1 | 视觉)

我省略其中一个目标（其他）的原因是因为它们依赖于机器人和屏幕。
我的问题是，我可以使用比例作为预测变量吗？如果您对上下文有任何疑问，请随时提问。
我的另一个问题是，如果我有 24 个时间步长（5 秒的时间间隔），那么最好的建模方法是什么来检查初始时间步长是否比后面的时间步长在指示记忆性方面具有更好的效果？我不确定当前的建模是否可用于获取该信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/639299/how-to-use-generalised-linear-mixed-model-with-compositional-proportions-that-a</guid>
      <pubDate>Wed, 14 Feb 2024 21:26:10 GMT</pubDate>
    </item>
    <item>
      <title>每个参与者具有随机条件子集的多级模型</title>
      <link>https://stats.stackexchange.com/questions/639297/multilevel-model-with-random-subset-of-conditions-per-participant</link>
      <description><![CDATA[我对 5 个因素进行了重复测量实验，每个因素有 3 个不同的水平。我正在尝试找到一种方法来减少对参与者的需求，让他们不必经历每一种情况。
我一直在研究部分因子设计，但我突然想到，我可以运行一个为每个参与者部分完成的多级模型。
所以，我的问题是：是否可以向每个参与者展示条件的随机子集（例如 50%），收集足够的参与者，以便每个单独的条件都有良好的代表性，然后使用多级线性模型来建立各因素的影响？我怀疑可能是这样，但我不确定是否有什么我忽略的事情。]]></description>
      <guid>https://stats.stackexchange.com/questions/639297/multilevel-model-with-random-subset-of-conditions-per-participant</guid>
      <pubDate>Wed, 14 Feb 2024 21:02:54 GMT</pubDate>
    </item>
    <item>
      <title>$P(\text{观察到的极端数据} | \text{替代假设})$</title>
      <link>https://stats.stackexchange.com/questions/639287/p-textdata-as-extreme-as-observed-textalternative-hypothesis</link>
      <description><![CDATA[在频率假设检验中，计算值 $P(\text{与观察到的极端数据} | H_0)$，如果它小于特定阈值，$H_0$ 被拒绝。我理解“极端”的概念是“极端”。需要定义，这取决于$H_1$。它可以使用似然比明确定义，但据我在文献（在我的例子中是生物学）中看到的，对 $H_1$ 的依赖通常是隐含的。这就提出了一个问题：人们使用的“正确”是什么？极端的定义？
现在，这听起来可能像是我很迂腐。但我问这个问题的原因是，在我正在分析的数据集上，我定义了一个统计量和极端的直观定义，并使用采样计算了 pvalue $P(\text {观察到的极端数据} | H_0)$。看到这个值很小，我心里就高兴了。由于我的替代假设 $H_1$ 也得到了很好的定义，我可以计算 $P(\text{与观察到的极端数据} | H_1)$ 也是如此，发现这个值也很小。这让我想知道：

我该如何解释这一点？直观上，这让我认为 $H_0$ 和 $H_1$ 都不是好的假设，并且“ “现实” （当然，定义很宽松），是另一回事。我能想到的另一种解释是，我的数据（或至少是我的汇总统计数据）并不能提供有关这些假设的信息。另一种看待它的方式是，我拒绝了复合假设 $H_C:H_0 \lor H_1$（如果这些概率的总和也很小）。
如果我不报告 $P(\text{观察到的极端数据} | H_1)$，而只报告 pvalue，这实际上可能令人信服至少有一些我能够拒绝的人 $H_0$，因为直观地导致测试的替代方案是 $ H_1$，对于那些人来说，这似乎是 $H_1$ 的证据。这告诉我，至少可能有一些论文存在类似的问题。有人研究过这个吗？我的担心有道理吗？如果这确实是一个值得关注的问题，那么补救措施是什么（除了完全放弃 pvalue 的概念并进行贝叶斯测试之外）？是否应该要求人们始终计算和报告 $P(\text{观察到的极端数据} | H_1)$ 以及 pvalue？这样就能解决问题吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/639287/p-textdata-as-extreme-as-observed-textalternative-hypothesis</guid>
      <pubDate>Wed, 14 Feb 2024 18:15:45 GMT</pubDate>
    </item>
    <item>
      <title>估计排序数组中连续分布的随机值的位置[关闭]</title>
      <link>https://stats.stackexchange.com/questions/639263/estimate-the-position-of-continuously-distributed-random-values-in-a-sorted-arra</link>
      <description><![CDATA[我在 0 和 1 之间连续分布随机值。我的目标是仅根据密度函数估计这些值在排序数组中的位置。
知道分布后，我相信应该存在数学关系将数据转换为排序数组中均匀分布的位置。或者可以使用累积密度函数 (CDF) 进行此类转换。
实现这一目标的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/639263/estimate-the-position-of-continuously-distributed-random-values-in-a-sorted-arra</guid>
      <pubDate>Wed, 14 Feb 2024 13:34:09 GMT</pubDate>
    </item>
    <item>
      <title>对于高度相关的变量，特征重要性为何以及如何降低？</title>
      <link>https://stats.stackexchange.com/questions/639206/why-and-how-does-feature-importance-decrease-for-highly-correlated-variables</link>
      <description><![CDATA[我正在使用 sklearn 的 DecisionTreeClassifier 算法研究特征之间的相关性及其对其特征重要性的影响之间的关系。
我使用以下函数操纵变量的相关性。这会从数据集中获取现有特征（特征 A），并创建一个相关特征（特征 B），其中除了一些噪声之外，还包含与特征 A 相似的信息：
def create_highly_corlated_column(existing_column,correlation_coefficient,seed=0):
    “”“创建与基数相等的现有特征高度相关的特征。”“”“
    
    np.随机.种子（种子）
    嘈杂的列=现有的列.copy()
    噪声值=噪声列.值计数(归一化=真).索引
    分布=noisy_column.value_counts(normalize=True).tolist()
    嘈杂的列=嘈杂的列.应用（lambda x：np.random.choice（噪声值，p=分布）
                                      if np.random.rand() &gt;= correlation_coefficient else x)

    返回noise_column

因此，在相关性 = 0 时，特征 B 本质上是纯噪声，而在相关性 = 1 时，特征 B 是特征 A 的精确副本。以下是上述函数与两个特征之间的皮尔逊相关系数的相似之处：

然后，我绘制了函数相关系数与特征 A 和特征 B 在多个 RNG 种子上平均的特征重要性的图表。下图展示了特征A（橙色）和特征B（蓝色）的重要性：

随着特征 B 变得高度相关 (~ &gt;0.8)，特征 A 的特征重要性开始大幅下降。我认为原因是因为一些原本由特征A决定的分割现在由特征B决定，所以重要性在某种程度上开始从特征A转移到特征B（当特征多重共线时变得均匀分割）。&lt; /p&gt;
但是，当特征 A 更改时，出现在 0.8 左右的截止范围会有所不同。例如，选择将我的函数应用于不同的特征 A 会生成一个图表，其中仅当相关特征的相关值为 0.99 时才分割特征重要性。
不同的特征在特征重要性开始下降之前是否承认不同程度的相关性？哪些因素决定了这一点？
注意：由于我的绘图结果是对多个种子进行平均，因此特征 B 和特征 A 的特征重要性几乎相同，相关系数接近 1。]]></description>
      <guid>https://stats.stackexchange.com/questions/639206/why-and-how-does-feature-importance-decrease-for-highly-correlated-variables</guid>
      <pubDate>Tue, 13 Feb 2024 17:07:31 GMT</pubDate>
    </item>
    <item>
      <title>InstructGPT RL 阶段优化的损失是多少？</title>
      <link>https://stats.stackexchange.com/questions/638792/whats-the-loss-that-is-optimized-in-instructgpt-rl-stage</link>
      <description><![CDATA[在InstructGPT论文中，他们将强化学习阶段的目标定义为：

他们尝试使用 PPO 来最大化这一目标。
不过，我很难理解他们如何将此目标纳入 PPO。他们是否只是在 PPO 优势计算中替换每个 $r_t$ $\hat{A}_t$通过这个目标的价值？
（这也意味着他们使用 $L^\text{CLIP}$ 而不是 $L^\ text{KLPEN}$ 在最终的损失中，否则 KL 项会有点重复，不是吗？）]]></description>
      <guid>https://stats.stackexchange.com/questions/638792/whats-the-loss-that-is-optimized-in-instructgpt-rl-stage</guid>
      <pubDate>Wed, 07 Feb 2024 20:04:25 GMT</pubDate>
    </item>
    <item>
      <title>两阶段集群设计中的双重后分层</title>
      <link>https://stats.stackexchange.com/questions/638772/double-poststratification-in-a-two-stage-cluster-design</link>
      <description><![CDATA[假设我们的国家分为 100 个市镇。在每个市镇内，可以将人口分为 10 岁年龄组，并且每个组的人口规模是已知的。可以实施两阶段聚类设计，首先随机抽样 20 个城市。随后，在每个抽样城市内，抽取 200 人的简单随机样本。最初，不应用按年龄组的分层。该调查可能会受到单位不答复的影响，这本身可能因城市和年龄而异。
考虑到单位没有答复，对每个采样城市内的年龄数据集进行后分层似乎是合理的。 问题1使用R包调查时，第二阶段的后分层是通过城市和年龄之间的交互来完成的吗？
设计 &lt;- svydesign(
  ids = ~ 市政府 + 个人，
  阶层 = ~ 国家 + 年龄，
  fpc = ~ 市政当局. 规模 + 人口. 规模,
  数据 = 数据
）
后分层（
  设计=设计，
  阶层 = ~ 市政府 + 年龄，
  人口 = 人口.频率
）

完成此操作后，由于仅包含城市样本，数据集的年龄分布将与全国年龄分布不一致。因此，对我来说，对国家层面每个年龄组的人口规模进行第二次后分层是有意义的。我认为，通常寻求的是国家层面的一致意见。如果是这种情况，我们首先根据市政府和年龄的相互作用进行后分层，然后在全国范围内仅根据年龄再次进行后分层。我以前没有见过这样的过程的例子。 问题 2 这个过程在理论上有意义吗？
据我所知，数据集的年龄分布在各个城市内和国家层面上无法保持一致。后分层的第二次迭代破坏了城市内的年龄分布。 问题3是否可以跳过城市内部的后分层步骤，而只需要在国家层面进行后分层？或者首先确保数据在市一级一致是否有价值？
请注意，我已经谈到了“后分层”，但人们也可能将其理解为“倾斜”或“校准”。我已经给出了基于 R 包调查的示例，但有关此过程的一般问题并不依赖于这个特定的包。]]></description>
      <guid>https://stats.stackexchange.com/questions/638772/double-poststratification-in-a-two-stage-cluster-design</guid>
      <pubDate>Wed, 07 Feb 2024 16:37:56 GMT</pubDate>
    </item>
    </channel>
</rss>