<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 11 Mar 2024 12:24:33 GMT</lastBuildDate>
    <item>
      <title>使用联合分类器和回归模型进行收入预测</title>
      <link>https://stats.stackexchange.com/questions/642299/income-prediction-using-joint-classifier-and-regression-models</link>
      <description><![CDATA[所以我有一个收入回归任务，我正在为其构建 XGBoost 模型。当我建立第一个模型时，存在一个问题，即低收入会被高度高估，高收入会被低估。建议我按部分划分收入，并为每个部分创建一个回归模型，然后使用分类器对收入部分进行分类（我的预测收入是所有 3 个预测和分类概率的点积）。事实上，这种方法在几乎所有指标上都被证明更好，并且由于数据的性质，其性能优于单一 XGBoost 方法。
所以我的流程是这样的：3 个 XGBoost 收入回归模型（&lt;600、600-1500、&gt;1500）和一个 XGBClassifier。我目前面临的一个问题是，虽然单个回归模型表现非常好，例如&lt;600模型在&lt;600数据上损失较低，整个模型在&lt;600数据上表现明显较差。这种差异是由分类错误引起的。
我尝试过单独调整所有模型，但我在想是否有一种方法可以以某种方式在共享损失上训练单个模型（类似于深度学习中的方式），或者我的方法可能存在缺陷开始并且坚持单一回归模型更好？
我无法找到类似结构模型的任何来源，因此任何帮助和信息都可以提供。非常感谢指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/642299/income-prediction-using-joint-classifier-and-regression-models</guid>
      <pubDate>Mon, 11 Mar 2024 12:06:51 GMT</pubDate>
    </item>
    <item>
      <title>类似于 $t$ 统计量的数量分布</title>
      <link>https://stats.stackexchange.com/questions/642298/distribution-of-a-quantity-similar-to-the-t-statistic</link>
      <description><![CDATA[假设我有来自 $A$ 和 $B$ 的样本容器&quot;&gt;$N(\mu,\sigma^2)$ 均值和方差未知。
样本大小为 $n_A$ 和 $n_B$。
我构建了两个统计数据：
$$t_A=\frac{\bar X_A}{s_A/\sqrt{n_A}}$$
和
$$t_{B/A}=\frac{\bar X_B}{s_A/\sqrt{n_A}}$$
其中 $\bar X$ 是样本均值 $s$ 是样本标准差。显然，$t_A\sim t(n-1)$。我对 $t_{B/A}$ 的分布感兴趣。问题：

当$n_A=n_B$时，是否$t_{B/A}\sim t(n -1)$?我猜是因为正态分布的样本均值和方差的独立性。
当$n_A\neq n_B$时，$t_{B/A}$的分布是什么跨度&gt;？
]]></description>
      <guid>https://stats.stackexchange.com/questions/642298/distribution-of-a-quantity-similar-to-the-t-statistic</guid>
      <pubDate>Mon, 11 Mar 2024 11:56:44 GMT</pubDate>
    </item>
    <item>
      <title>关于潜变量的线性模型等价</title>
      <link>https://stats.stackexchange.com/questions/642297/linear-model-equivalence-regarding-latent-variables</link>
      <description><![CDATA[在阅读论文时，我被困在一个章节的一部分（5.4，第16页） ~18）。
&lt;块引用&gt;
考虑协变量 $x_i = (x_{i,1},\dots,x_{i,p}) \in \mathbb R^p$ 和 a响应变量 $y_i \in \mathbb R$ 分布如下：
$$y_i = \beta^Tx_i+\epsilon_i, \tag a$$
其中 $\mathbb E[x_i] = 0、\text{Cov}[x_i] = \Sigma$ 和 $\ mathbb E[\epsilon_i] = 0，\text{Var}[\epsilon_i] = \sigma^2$。此外，我们假设响应变量在潜在特征 $z_i\in\mathbb R^d (p \ge d)$ 中是线性的，并且协变量也是线性的在 $z_i$ 中：
$$y_i = \theta^Tz_i+\zeta_i,\qquad x_{i,j}=w_j^Tz_i+u_{i,j},\tag b$$
其中 $\zeta_i \sim N(0,\sigma_{\zeta}^2), u_{i,j}\sim N(0,1)$ 是相互独立，独立于 $z_i\sim N(0,I_d)$ 和 $\theta,w_j \in\ mathbb R^d$。令 $W\in\mathbb R^{p\times d}$ 为第 i 行为 $w_i$&lt; 的矩阵/span&gt;，(a) 和 (b) 中的模型是等效的。也就是说，我们通过匹配它们的协方差得到以下结果：
$$ \begin{align}
\Sigma &amp;=I_p+WW^T &amp;(1)\\
\beta &amp;= W(I+W^TW)^{-1}\theta &amp; (2)\\
\sigma^2 &amp;= \sigma_{\zeta}^2+\theta^T(I+W^TW)^{-1}\theta &amp;(3)
\end{对齐}$$

通过定义 $x_i =Wz_i+u_i$ ，结果 (1) 非常简单，其中 $u_i\in\ mathbb R^p, u_i\sim N_p(0,I)$ 和 $Cov[x_i] = WCov[z_i]W^T+I_p = WW^T+我$。
但我不确定结果（2）和（3）是否也是通过匹配协方差得出的。我尝试使用以下方法
$$\begin{align}
y_i &amp;= \beta^Tx_i+\epsilon_i \\
&amp;= \beta^T(Wz_i+u_i) + \epsilon_i \\
&amp;=\theta^Tz_i+\zeta_i,
\end{对齐}$$
但我认为这并没有提供关于预期结果 (2)、(3) 的有用想法。
任何有关此问题的提示将不胜感激。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/642297/linear-model-equivalence-regarding-latent-variables</guid>
      <pubDate>Mon, 11 Mar 2024 11:46:11 GMT</pubDate>
    </item>
    <item>
      <title>通过交叉验证和形状值重要性选择重要特征</title>
      <link>https://stats.stackexchange.com/questions/642295/selection-of-important-features-through-cross-validation-and-shape-value-importa</link>
      <description><![CDATA[为了提取二分类问题的重要特征，通过嵌套CV根据shap值的重要性值进行递归特征消除。
我在这里好奇的第一件事是，当只保留非常重要的特征（如附图所示）时，训练和测试的 auc 分数是否会下降，从而导致良好的泛化，或者差距会因为特征数量的减少而减小吗？功能减少？
第二个是特征选择。我不确定在什么时候应该选择重要功能的最终数量。我使用了roc auc Score，这是一种广泛使用的二元分类评估指标。我应该简单地选择测试集 AUC 分数最高的点吗？或者我应该选择一个训练和测试之间差距较小的点？或者我应该选择一个满足所有这些条件的点？
y 轴是 auc 分数，x 轴是删除的特征数量。
]]></description>
      <guid>https://stats.stackexchange.com/questions/642295/selection-of-important-features-through-cross-validation-and-shape-value-importa</guid>
      <pubDate>Mon, 11 Mar 2024 11:19:34 GMT</pubDate>
    </item>
    <item>
      <title>特定数据子集中的 lme4 收敛警告</title>
      <link>https://stats.stackexchange.com/questions/642294/lme4-convergence-warning-in-specific-subset-of-data</link>
      <description><![CDATA[我们的主要分析包括单变量逻辑混合模型，使用lme4的glmer来检查血浆生化参数之间的关联（在下面的模型中按比例缩放） N~4000 数据集中的连续变量）和疾病结果。
作为敏感性分析的一种形式，我们使用补充来移除参与者，以查看我们的结果如何变化（将数据集减少大约三分之一，即 N~2600）。
主要型号：
疾病 ~ 年龄 + 性别 + BMI + 生化参数 + (1|Family_group)
其中年龄&amp; BMI 是连续协变量，运行良好且稳定。没有任何生化参数的警告。
敏感性分析中的模型（相同的公式，但现在仅使用不服用补充剂的患者）对大多数生化参数发出以下警告：
警告消息：
1：在 checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, 中：
  无法评估缩放梯度
2：在 checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, 中：
  模型无法收敛：具有 1 个负特征值的退化 Hessian 矩阵
3：在 vcov.merMod(full, useScale = FALSE) 中：
  根据有限差分 Hessian 计算得出的方差-协方差矩阵为
非正定或包含 NA 值：回退到从 RX 估计的 var-cov
4. 在 checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, 中：
  模型几乎无法识别：特征值非常大


（警告会根据使用的生化参数而变化）。
警告不能被忽略，因为我得到的结果不可信（巨大的比值比；巨大的 SE；许多 p 值 = 1，即使置信区间或比值比不包含 1）。
我已通读帮助页面以了解这些警告许多简历都发布了这些警告，但仍然找不到解决方案。到目前为止我尝试过的：

各种优化器
重新缩放连续参数（即使在执行此操作后，以 Rescale Variables? 结尾的警告仍然存在）
降低了容差 (optCtrl=list(maxfun=2e5))
从之前的拟合重新开始拟合

我在故障排除中发现的其他可能有用的线索：

我从未收到过有关空模型的警告，该模型不包含生化参数（即疾病 ~ 年龄 + 性别 + BMI + (1|Family_group)）

当我使用生化参数但没有年龄或 BMI 运行模型时，收到警告的频率会降低。这让我想知道共线性是否会成为这里的一个问题；然而，年龄或BMI与任何生化参数之间均不存在相关性(r&lt;0.1)。

如果我采用与未进行补充的数据集大小相同的初始数据集的随机子集，我很少收到警告（警告在原始数据集的 10 个不同的随机子样本中出现一次） .

这让我想知道近乎完美的分离是否会导致警告；但是，与未补充使用的数据子集相比，连续变量的均值以及不同数据子集的分类变量的 table() 计数都没有显示出差异。


事实上，我在不采取补充的子集上始终得到错误，但很少在随机子集上得到错误，这表明问题在于数据集子集而不是建模。但是，我无法确定确切的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/642294/lme4-convergence-warning-in-specific-subset-of-data</guid>
      <pubDate>Mon, 11 Mar 2024 11:10:37 GMT</pubDate>
    </item>
    <item>
      <title>机器学习实验：是否应该固定训练参数以进行模型之间的有效比较？</title>
      <link>https://stats.stackexchange.com/questions/642292/machine-learning-experiment-should-training-parameters-be-fixed-for-a-valid-com</link>
      <description><![CDATA[我正在对自动编码器进行三次训练，每次都在不同的数据集上。这三个数据集都具有相同数量的特征，但大小却截然不同。
假设其中一个数据集A的长度为n，则数据集B包括数据集A和其他n个样本。数据集C包括数据集B和其他n个样本。
我想测量模型的性能如何随着样本数量的增加而变化。然而，“最佳”值是训练参数取决于数据。
给定任意一组固定的超参数，模型 A（在数据集 A 上训练）可能看起来比模型 B（在 B 上训练）表现更好，而实际上，如果针对模型 B 调整了训练参数，它的性能会优于模型 A。
另一方面，找出“最佳集合”每个数据集的训练参数是巨大且困难的。]]></description>
      <guid>https://stats.stackexchange.com/questions/642292/machine-learning-experiment-should-training-parameters-be-fixed-for-a-valid-com</guid>
      <pubDate>Mon, 11 Mar 2024 11:01:58 GMT</pubDate>
    </item>
    <item>
      <title>具有交互项的神经网络和类别分离</title>
      <link>https://stats.stackexchange.com/questions/642291/neural-net-and-category-separation-with-interaction-terms</link>
      <description><![CDATA[我们有一个由分类和数字特征组成的表格数据流。其中一类对于影响目标、与其他功能交互以及对数据流进行排序在某种程度上至关重要。假设该流包含一天来自 A 类的 30K 个观察值，第二天包含来自 B 类的 20K 个观察值，依此类推。
现在考虑下图所示的简化线性情况。数据经过预处理，使其包含交互项。

至少在没有正则化的情况下，使用 A 类的一批观测值更新随机梯度下降回归模型不会改变 B 组的系数，而 B 组的系数是期望的行为。
但是，线性模型在准确性方面无法满足我们的需求，但实验表明，简单的多层神经网络可以满足我们的需求。但是用 A 组的数据更新网络会影响 B 类的权重，并降低 B 类的准确性。
解决这个问题的最佳策略是什么？当使用类别 A 的数据更新网络时，为什么类别 B 的权重会发生变化？当使用类别 A 的数据更新权重时，如何防止神经网络降低类别 B 的准确性？]]></description>
      <guid>https://stats.stackexchange.com/questions/642291/neural-net-and-category-separation-with-interaction-terms</guid>
      <pubDate>Mon, 11 Mar 2024 10:34:32 GMT</pubDate>
    </item>
    <item>
      <title>出于域适应目的而改变数据长度</title>
      <link>https://stats.stackexchange.com/questions/642289/varying-length-of-data-for-domain-adaptation-purposes</link>
      <description><![CDATA[我的目标是使用预训练的转换器来获取固定大小的数据（比方说，5X150 的数组），并将其编码为嵌入。我想将这种嵌入用于回归任务，比方说向编码器添加一个完全连接的层，并仅训练该层。问题是我的输入数据的长度不同。我可以在纸上分割并填充它以适合编码器，但从概念上讲，将分割数据的不同块与单个目标分数配对是没有意义的，因为分数是作为一个整体给予数据的（例如，一段长文本，因其质量而获得一些分数；分数是对整个文本进行的，而不仅仅是第一段）。我想到也许可以对不同块的嵌入进行平均（或使用其他池化技术），然后使用平均嵌入作为回归层的输入，但我不确定在训练管道中的哪个点进行此操作（在数据集模块？在主函数中？）。
如果有人可以建议我如何处理这种情况的布局或管道，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/642289/varying-length-of-data-for-domain-adaptation-purposes</guid>
      <pubDate>Mon, 11 Mar 2024 10:00:22 GMT</pubDate>
    </item>
    <item>
      <title>敏感性分析 - 删除样本或向模型添加变量？</title>
      <link>https://stats.stackexchange.com/questions/642288/sensitivity-analysis-remove-samples-or-add-variables-to-model</link>
      <description><![CDATA[我们有逻辑回归模型：
疾病 ~ 年龄 + 性别 + BMI + 血浆钙
我们有兴趣了解 Plasma_calcium 是否“显着”与疾病结果相关。
由于补充剂的使用可能与血浆钙和疾病相关，因此我们希望进行敏感性分析，以了解在模型中考虑补充剂的使用时我们的结果如何变化。
我认为我们应该运行以下模型：
疾病 ~ 年龄 + 性别 + BMI + 血浆钙 + supp1 + supp2 + supp3 … supp 15
其中每个补充剂都是一个二元变量，指示每个参与者是否服用它（我们的样本量约为 4000，所以我不担心过度拟合）。
然而，我的老板说，以这种方式调整补充剂是错误的，因为患有这种疾病的人更有可能服用补充剂（这是事实），这会引发多重共线性问题。他提出的替代方法是简单地重新运行分析，排除任何服用补充剂的人。
我认为这是错误的，因为：

补充是二元变量，因此不
呈现我认为的经典意义上的多重共线性
他指的是
“患有这种疾病的人更有可能服用补充剂”这一事实（结合以下事实）
该补充剂可能对血浆钙有影响）正是
为什么我们应该在我们的模型中考虑它。那是，
患有这种疾病的人使用补充剂可能会使其看起来像
血浆钙与结果相关。
通过剔除那些服用补充剂的人，我们损失了大约 1/3 的样本，从而导致比较困难
之前和之后的结果（我们无法知道 p 值的变化是否是由于不同的子样本总体，因为我们现在只有非补充用户，或者样本大小本身的变化）。

这两种执行敏感性分析的有效方法吗？如果有的话，是首选吗？如果不是，我们谁错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/642288/sensitivity-analysis-remove-samples-or-add-variables-to-model</guid>
      <pubDate>Mon, 11 Mar 2024 09:56:38 GMT</pubDate>
    </item>
    <item>
      <title>“偏差-方差权衡”和“一致模型选择”之间有什么关系？</title>
      <link>https://stats.stackexchange.com/questions/642287/whats-the-relationship-between-bias-variance-tradeoff-and-consistent-model-s</link>
      <description><![CDATA[我对“偏差-方差权衡”和“偏差-方差权衡”之间的关系感到非常困惑。和“一致的模型选择”。根据我目前的解释，处理“偏差-方差权衡”的最终目标是就是要有良好的样本外预测。也就是说，我们要避免过拟合（复杂模型，高方差）和欠拟合（简单模型，高偏差），以便我们的估计模型能够对我们的目标做出良好的预测 $ Y$ 在之前未使用过的全新数据集上使用回归器 $X$。在这个过程中，我们并不关心“真实模型”是什么。 $Y$ 和 $X$ 之间是。
另一方面，“一致的模型选择”假设 $Y$ 和 $X$ 之间存在真实关系，用 $Y=X^{*&#39;}\beta+\epsilon$ 对于某些 $\beta$，其中 $X^*$ 是 $X$ 的子集。目标是使用某些标准（例如 BIC）找出这个正确的模型（回归量的正确子集），众所周知，当样本量趋于无穷大时，该标准可以找到概率为 1 的正确模型。因此，在更强的假设下，一致模型选择的主题似乎是一个更狭窄的领域，并且具有完全不同的最终目标。
令我困惑的是，我经常看到 BIC 标准的说明是试图平衡偏差（样本拟合良好）和方差（模型复杂性）。这样的讨论似乎暗示 BIC 是为了改进样本外预测而构建的。就我个人而言，选择正确的模型与良好的样本外预测并没有太大关系。错误的模型在样本外预测方面也可能表现得同样好甚至更好。我的问题是，这些解释正确吗？如果是，那么当我们在一致模型选择的背景下谈论平衡偏差和方差时，我们实际上意味着什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/642287/whats-the-relationship-between-bias-variance-tradeoff-and-consistent-model-s</guid>
      <pubDate>Mon, 11 Mar 2024 09:36:40 GMT</pubDate>
    </item>
    <item>
      <title>创建具有特定比例的二元向量</title>
      <link>https://stats.stackexchange.com/questions/642284/creating-a-binary-vector-with-specific-proportion-of-ones</link>
      <description><![CDATA[我想生成一个大小为 $n=20$ 的二元向量，其比例等于 $\压裂{3}{20}$
binary_vector &lt;- rbinom(20, 1, 0.15)

但是为什么这并不总是给出 0.15 的固定比例：
&lt;预&gt;&lt;代码&gt;[1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 # 5%
[1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 # 0%
[1] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 # 15%
[1] 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 # 20%
]]></description>
      <guid>https://stats.stackexchange.com/questions/642284/creating-a-binary-vector-with-specific-proportion-of-ones</guid>
      <pubDate>Mon, 11 Mar 2024 09:13:35 GMT</pubDate>
    </item>
    <item>
      <title>拉丁方设计的用处</title>
      <link>https://stats.stackexchange.com/questions/642283/usefulness-of-latin-square-design</link>
      <description><![CDATA[我想了解拉丁方设计的用处。假设有两个块因子，每个因子有三个块。共有三个实验组：A、B、C。拉丁方设计的一种实现是：
&lt;前&gt;&lt;代码&gt;&gt;设计1＜-c(“A”、“B”、“C”、“B”、“C”、“A”、“C”、“A”、“B”) ）
&gt;矩阵(设计1,3,3)
     [,1] [,2] [,3]
[1，]“A” “B” “C”
[2，]“B” “C” “A”
[3，]“C” “A” “B”

在此设计中，行和列代表块因子。该设计假设三个因素之间不存在相互作用。但是，如果我们假设不存在交互作用，则可以在不使用拉丁方设计的情况下估计三个因素的影响，如design2
&lt;前&gt;&lt;代码&gt;&gt;设计2＜-c(“A”、“B”、“C”、“B”、“C”、“A”、“C”、“A”、“A”) ）
&gt;矩阵(设计2,3,3)
     [,1] [,2] [,3]
[1，]“A” “B” “C”
[2，]“B” “C” “A”
[3，]“C” “A” “A”

在design2中，实验组B没有出现在第三行第三列中，但我们仍然可以估计块效应和实验效果。我想知道拉丁方设计的主要优点。
&lt;前&gt;&lt;代码&gt;&gt; y &lt;- rnorm(9,1,1)
&gt;设计1＜-因子(c(“A”、“B”、“C”、“B”、“C”、“A”、“C”、“A”、“)” B”））
&gt; design2＜-factor(c(“A”、“B”、“C”、“B”、“C”、“A”、“C”、“A”、“)” A”））
&gt; design3＜-factor(c(“A”、“B”、“C”、“B”、“C”、“A”、“A”、“A”、“)” A”））
&gt; blk1＜-因子(c(“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“blk1”) T3”））
&gt; blk2＜-因子(c(“A1”、“A1”、“A1”、“A2”、“A2”、“A2”、“A3”、“A3”、”) A3”））
&gt;
&gt;方差分析(lm(y~design1+blk1+blk2))
方差分析表

响应：是
          Df Sum Sq Mean Sq F 值 Pr(&gt;F)
设计1 2 4.2330 2.11652 2.4836 0.2871
块1 2 0.2355 0.11775 0.1382 0.8786
块2 2 0.6779 0.33897 0.3978 0.7154
残差 2 1.7044 0.85221
&gt;方差分析(lm(y~design2+blk1+blk2))
方差分析表

响应：是
          Df Sum Sq Mean Sq F 值 Pr(&gt;F)
设计2 2 2.97039 1.48520 1.0063 0.4984
块1 2 0.49651 0.24825 0.1682 0.8560
块2 2 0.43222 0.21611 0.1464 0.8723
残差 2 2.95177 1.47589
&gt;方差分析(lm(y~design3+blk1+blk2))
方差分析表

响应：是
          Df Sum Sq Mean Sq F 值 Pr(&gt;F)
设计3 2 2.8600 1.43001 0.8500 0.5405
块1 2 0.1706 0.08530 0.0507 0.9517
块2 2 0.4554 0.22772 0.1354 0.8808
残差 2 3.3648 1.68241

我猜 deign1 (LSD) 可能比 deign2 或 deign3 更强大。但教科书中并没有将统计功效作为 LSD 的优势进行讨论。教科书上通常讲减少样本，但减少样本可以在不使用LSD的情况下完成。]]></description>
      <guid>https://stats.stackexchange.com/questions/642283/usefulness-of-latin-square-design</guid>
      <pubDate>Mon, 11 Mar 2024 09:07:47 GMT</pubDate>
    </item>
    <item>
      <title>Caperaa Fougeres Genest 非参数尾部依赖性估计器的 R 代码</title>
      <link>https://stats.stackexchange.com/questions/642282/r-code-for-nonparametric-tail-dependence-estimator-of-caperaa-fougeres-genest</link>
      <description><![CDATA[任何人都可以帮助我如何使用 R 代码来估计 Caperaa Fougeres Genest 的非参数尾部依赖性估计器。我尝试过使用 gofEVCopula() 函数，但它只能计算极值 copula。然而，我在许多论文中发现，他们能够使用其他类型的 copula 进行计算，而不仅限于 copula 的极值类。]]></description>
      <guid>https://stats.stackexchange.com/questions/642282/r-code-for-nonparametric-tail-dependence-estimator-of-caperaa-fougeres-genest</guid>
      <pubDate>Mon, 11 Mar 2024 07:43:14 GMT</pubDate>
    </item>
    <item>
      <title>如何应对堆叠 DiD 中的预趋势违规？</title>
      <link>https://stats.stackexchange.com/questions/642281/how-to-cope-with-pre-trend-violations-in-a-stacked-did</link>
      <description><![CDATA[我想使用双重差分方法来分析多个事件。由于事件发生在不同的时间，因此交错或堆叠的 DiD 方法将是合适的。就我而言，我有很多观察结果，并且还想查看交互，这对于堆叠 DiD 来说似乎更容易。然而，我现在面临的问题是我必须控制违反治疗前趋势的情况。我已经分别为每个实验尝试了匹配方法，然后合并了数据，但我丢失了很多观察结果。另外，逆概率加权似乎是一个可行的选择。然而，如何将其合并到堆叠式 DiD 方法中尚不清楚。如果没有标准化，不同事件的权重将会不同。
是否可以将 IPW 或其他形式的加权与堆叠式 DiD 结合起来？我将非常感谢您提供提示、片段和参考资料！现在，我将使用 Weightit 单独权衡每个实验，使用固定的单独 DiD 进行估计，然后汇总结果。这一切是否可以在单个 Stacked DiD 中完成，即更优雅？]]></description>
      <guid>https://stats.stackexchange.com/questions/642281/how-to-cope-with-pre-trend-violations-in-a-stacked-did</guid>
      <pubDate>Mon, 11 Mar 2024 07:08:52 GMT</pubDate>
    </item>
    <item>
      <title>ValidError，输入无效，x 为常量</title>
      <link>https://stats.stackexchange.com/questions/642280/validerror-invalid-input-x-is-constant</link>
      <description><![CDATA[我该如何调查数据并进行预处理？我正在尝试使用 pvalue 对协整对进行热图分析。
执行协整对分析
cointegrated_pa​​irs = [] correlation_matrix = np.zeros((len(tickers), len(tickers))) 对于 i，枚举（tickers）中的ticker1：对于 j，枚举（tickers）中的ticker2：如果 i != j: p_value = cointegration_test(returns[ticker1], returns[ticker2]) #如果 p_value &lt; 则出现错误0.01: cointegrated_pa​​irs.append((ticker1,ticker2))correlation_matrix[i,j] = returns[ticker1].corr(returns[ticker2])
错误消息“输入无效，x 对于股票对 (GME, GME) 来说是常量”表示该对的线性回归模型中的外生变量 (x) 是常量。这意味着该变量不会因观察而变化，这可能会导致模型估计和解释出现问题。
我尝试继续使用 for i, ticker1 in enumerate(tickers)：
对于 j，枚举（tickers）中的ticker2：
如果我！= j：
p_value = cointegration_test(返回[ticker1], 返回[ticker2])
p_values.loc[ticker1,ticker2] = p_value
但之前，我成功地运行了热图分析，没有任何问题，我不明白为什么这次 GME，GME 协整返回错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/642280/validerror-invalid-input-x-is-constant</guid>
      <pubDate>Mon, 11 Mar 2024 07:03:55 GMT</pubDate>
    </item>
    </channel>
</rss>