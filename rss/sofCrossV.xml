<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 25 Dec 2024 12:31:45 GMT</lastBuildDate>
    <item>
      <title>当我不能使用精确检验（fisher）时，我可以使用蒙特卡洛吗？</title>
      <link>https://stats.stackexchange.com/questions/659191/can-i-use-monte-carlo-when-i-cant-use-the-exact-testfisher</link>
      <description><![CDATA[我目前正在为我的硕士论文进行数据分析。
在进行交叉制表（卡方检验）分析时，我遇到了一些结果，其中超过 50%（甚至 80%）的预期频率低于 5，违反了卡方检验的假设。表格大小为 2x7 或 4x7，因此无法在 SPSS 中计算精确检验。
在这种情况下，使用蒙特卡罗方法计算 p 值是否合适？IBM 表示，当无法计算 Fisher 精确检验时，可以使用蒙特卡罗方法，但我理解蒙特卡罗方法通常用于大型数据集，这让我感到困惑。我很感激您对此事的指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/659191/can-i-use-monte-carlo-when-i-cant-use-the-exact-testfisher</guid>
      <pubDate>Wed, 25 Dec 2024 10:53:39 GMT</pubDate>
    </item>
    <item>
      <title>在 Friedman 检验中拒绝 H0，但在任何成对 wilcoxin 检验中均无法拒绝</title>
      <link>https://stats.stackexchange.com/questions/659188/reject-h0-on-friedman-test-but-fail-to-reject-in-any-pairwise-wilcoxin-test</link>
      <description><![CDATA[我目前正在比较不同模型的 auroc，我首先进行了 Friedman 检验，然后进行了成对 Wilcoxon 检验以查看差异。
测试数据：数据链接
数据由 SVM、随机森林、XGBoost 生成，重复测试 3 次，分层 10 倍。
这是我的 r 代码：
variables &lt;- c(&quot;model_name&quot;, &quot;n_pcs&quot;, &quot;n_snps&quot;,&quot;treatment&quot;)

# 如果尚未完成，则创建“treatment”变量
auc$treatment &lt;- with(auc, paste(model_name, n_pcs, n_snps, sep = &quot;_&quot;))

#加载所需库
library(RColorBrewer)

# 加载所需库
library(ggplot2)
library(multcompView)

# 循环遍历变量，执行 Friedman 检验，计算组标签并绘制
结果 &lt;- lapply(variables, function(var) {
# 创建矩阵：行 = 观察值，列 = 组（变量的级别）
组 &lt;- unique(auc[[var]])
样本 &lt;- sapply(groups, function(g) auc$roc_auc[auc[[var]] == g])
y &lt;- auc$roc_auc

# 执行 Friedman 检验
friedman_result &lt;- friedman.test(Sample)

# 打印 Friedman 检验结果
cat(&quot;Friedman test for&quot;, var, &quot;\n&quot;)
print(friedman_result)
cat(&quot;\n&quot;)

# 带 Bonferroni 调整的成对 Wilcoxon 符号秩检验
p_values &lt;- pairwise.wilcox.test(y, auc[[var]], p.adjust.method = &quot;bonferroni&quot;, exact = FALSE)$p.value
print(p_values)

# 创建重要性矩阵
sig_matrix &lt;- matrix(1, nrow = length(groups), ncol = length(groups))
rownames(sig_matrix) &lt;- colnames(sig_matrix) &lt;- groups

# 用调整后的 p 值填充矩阵
for (i in 1:nrow(p_values)) {
for (j in 1:ncol(p_values)) {
if (!is.na(p_values[i, j])) {
sig_matrix[i+1, j] &lt;- p_values[i, j]
sig_matrix[j, i+1] &lt;- p_values[i, j]
}
}
}

print(sig_matrix)

# 分配组标签
group_labels &lt;- multcompLetters(sig_matrix, Threshold = 0.05)$Letters

# 计算每个组的中位数
medians &lt;- tapply(auc$roc_auc, auc[[var]], median, na.rm = TRUE)

# 为 ggplot 准备数据
plot_data &lt;- data.frame(
roc_auc = y,
group = factor(auc[[var]], levels = groups)
)
label_data &lt;- data.frame(
group = names(group_labels),
labels = group_labels,
y = 1.1 # 图上方组标签的位置
)
median_data &lt;- data.frame(
group = names(medians),
medians = medians
)

# 创建 ggplot 箱线图
p &lt;- ggplot(plot_data, aes(x = group, y = roc_auc)) +
geom_boxplot(fill = &quot;#EBEBEB&quot;, color = &quot;black&quot;, width = 0.6, position = position_dodge(0.9)) + # 灰色框，带黑色边框
theme_bw(base_size = 14) +
geom_text(data = median_data, aes(x = group, y = medians + 0.05, label = round(medians, 2)),
color = &quot;red&quot;, size = 3) + # 添加中位数值
geom_text(data = label_data, aes(x = group, y = y, label = labels),
color = &quot;blue&quot;, size = 4) + # 添加组标签
labs(title = paste(&quot;Friedman Test with Pairwise Wilcoxon:&quot;, var),
x = ifelse(var == &quot;treatment&quot;, &quot;&quot;, var), # 删除 &#39;treatment&#39; 的 x 标签
y = &quot;AUROC&quot;) +
ylim(0, 1.2) # 设置 y 轴限值

if (var == &quot;treatment&quot;) {
p &lt;- p + theme(
plot.margin = margin(10, 10, 10, 10), # 在图周围添加边距
axis.text.x = element_text(angle = 45, hjust = 1, size = 8), # 旋转 x 轴标签
axis.title.x = element_text(size = 10), # 调整 x 轴标题大小
axis.title.y = element_text(size = 10) # 调整 y 轴标题大小
)
} else {
p &lt;- p + theme(
plot.margin = margin(10, 10, 10, 10), # 在图表周围添加边距
axis.title.x = element_text(size = 10), # 调整 x 轴标题大小
axis.title.y = element_text(size = 10) # 调整 y 轴标题大小
)
}

# 打印图表
print(p)

# 返回测试结果和组标签
list(test_result = friedman_result, p_values = p_values, group_labels = group_labels)
})

奇怪的结果：
Friedman chi-squared = 23.952, df = 3，p值 = 2.556e-05
 MLP RandomForest SVM
RandomForest 0.6986949 NA NA
SVM 0.4126711 1.0000000 NA
XGBoost 1.0000000 0.4126711 0.1787532

我写错了代码，还是这种情况比较少见，但确实存在？
谢谢~]]></description>
      <guid>https://stats.stackexchange.com/questions/659188/reject-h0-on-friedman-test-but-fail-to-reject-in-any-pairwise-wilcoxin-test</guid>
      <pubDate>Wed, 25 Dec 2024 06:16:32 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用小样本引导法来满足功效分析要求吗？</title>
      <link>https://stats.stackexchange.com/questions/659185/can-i-use-bootstrapping-for-small-sample-sizes-to-satisfy-the-power-analysis-req</link>
      <description><![CDATA[我有 15 名参与者在条件 A 下执行任务，还有 15 名参与者在条件 B 下执行任务。为了提高数据的有效性，每个参与者重复了 20 次任务。据我了解，在方差分析中，这些数据仍然只被视为每个条件的 15 个数据点，因为对于每个参与者，20 次重复减少为一个平均值。所以我的理解是，方差分析没有考虑到我总共进行了 2*300 次测量，但我可能只对每个参与者进行了一次测量。
问题：虽然条件 A 下的数据似乎始终比条件 B 下的数据小，但功效分析表明，我需要的样本量是条件 A 下的十倍。我不可能再重复这项研究，而且绝对不可能达到所需的样本量。
参与者的重复测量表明，重复是相互独立的（例如，没有学习效果等）。对我来说，这意味着实际上我在每种情况下都有 300 个数据点，而不仅仅是 15 个平均数据点。如果我将两种情况下的 300 个数据点相互比较，而不对测量值进行平均，则统计数据会起作用。但样本量为 15 时则不行。
问题：

是否有可能使用重复测量来引导数据，最终目标是满足所需的样本量？

您会推荐哪种引导程序？

还有其他不需要我重新进行整个实验的建议吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659185/can-i-use-bootstrapping-for-small-sample-sizes-to-satisfy-the-power-analysis-req</guid>
      <pubDate>Wed, 25 Dec 2024 02:16:43 GMT</pubDate>
    </item>
    <item>
      <title>从指数函数分布获得幂律的必要充分条件？</title>
      <link>https://stats.stackexchange.com/questions/659182/necessary-and-sufficient-conditions-to-obtain-power-law-from-distribution-over-e</link>
      <description><![CDATA[分布 $p(x)$ 的哪些属性 (1) 是充分的且 (2) 是必要的，以使
$$-\log \Bigg(1 - \int_{x=0}^{x=1} p(x) \, (1-x)^k \, dx \Bigg)$$
导致幂律
$$\propto k^{-b}$$
对于某个常数 $b &gt; 0$？
我有一个隐含的假设，即分布 $p(x)$ &quot; n&quot;在某种意义上，但我不确定这个假设到底是什么。也许是平滑的、连续的，还是类似的东西？
我已经得出 Beta 分布和 Kumaraswamy 分布就足够了。从数值上讲，连续伯努利分布也同样有效。我正在寻找这些分布背后的一般“结构”。]]></description>
      <guid>https://stats.stackexchange.com/questions/659182/necessary-and-sufficient-conditions-to-obtain-power-law-from-distribution-over-e</guid>
      <pubDate>Tue, 24 Dec 2024 23:53:30 GMT</pubDate>
    </item>
    <item>
      <title>Stata biprobit - 解释</title>
      <link>https://stats.stackexchange.com/questions/659181/stata-biprobit-interpretation</link>
      <description><![CDATA[生产力和培训都是二元变量。假设我正在研究培训对不同性别的个人生产力的影响。我使用到培训中心的距离作为我的工具变量 (IV)。
biprobit (productive = i.training i.training##i.male age i.gender wealth region) (training = distance age i.male wealth region) 

margins, at(training=(0 1) gender=(0 1)) predict(pmarg1) post

lincom _b[4._at] - _b[3._at]

结果为 0.02
categories:

3._at: training = 1, male = 0 (female with training)
4._at: training = 1, male = 1 (male with training)

我想确认我对 lincom 结果的解释是否正确：
对于接受过培训的人来说，男性比女性更有可能提高生产力 2%女性，并且这种差异具有统计学意义。
问题 2：
我不确定如何导出我的结果。有人能帮我吗？我应该只提供 lincom 结果，还是还应该包括主系数表？我找不到任何显示 lincom 结果的论文。
假设这是我的主表结果（假设）：
 | 系数 P&gt;|z| 
------------------------+----------------------------------------------------------------
productive |
1.training | .1265 0.000 
1.male | .188 0.000 
|
training#male |
1 1 | -.03049 0.315 
|


培训总体上对生产力有积极影响。
男性比女性更有生产力。
培训对男性和女性的生产力的影响并没有显著差异。

我应该坚持使用 lincom，对吧？不应该解释这些？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659181/stata-biprobit-interpretation</guid>
      <pubDate>Tue, 24 Dec 2024 23:48:51 GMT</pubDate>
    </item>
    <item>
      <title>神经网络不学习正弦函数参数</title>
      <link>https://stats.stackexchange.com/questions/659180/neural-network-not-learning-sinusoidal-function-parameters</link>
      <description><![CDATA[我有一个如下所示的正弦函数，带有预定义的a、b 和 c参数
def fun_sin(a, b, c, apply_noise=False):
&quot;&quot;&quot;
返回表示带噪声的正弦曲线的函数。

参数：
a：正弦波的振幅。
b：正弦波的频率。
c：正弦波的相移。
&quot;&quot;&quot;
def ann(x):
x = torch.tensor(x, dtype=torch.float32).to(device) if not isinstance(x, torch.Tensor) else x.to(device)
return (a * torch.sin(b * x + c)) + torch.tensor(random_gen.random(x.shape) * 0.2 if apply_noise else 0).to(device)
return ann

fun, a, b, c, learning_rate = fun_sin, 4, 0.1, 2, 0.0001

以下是该函数的曲线示例：

我创建了一个神经网络，给定 X（x 轴上的点）和 Y 值（fun_sin(a, b, c)(X) 的结果），我希望我的网络能够确定生成该曲线的 a, b, c 的位置。为了做到这一点，我让输出层输出 3 个值，并创建一个具有这些参数的函数，如下所示
def loss_fun(label, pred):
return torch.mean((label - pred) ** 2)

...

my_model = nn.Sequential(
nn.Linear(X_length, 32),
nn.ReLU(),
nn.Linear(32, 32),
nn.ReLU(),
nn.Linear(32, 3) # 具有 3 个参数 (a, b, c) 的输出层
)
...

my_model.train()
for i in epochs:
optimizer.zero_grad()
pred_a, pred_b, pred_c = my_model(X)
Y_pred = fun_sin(pred_a, pred_b, pred_c)(X)
loss = loss_fun(Y_label, Y_pred)
loss.backward()
optimizer.step()

所以事情是这样的：如果我给网络提供大约 100 个 X 和 Y 数据条目，我的网络就会相当合理地学习；我能够找到 a、b 和 c 的良好预测，这些预测能够呈现与原始曲线非常相似的正弦曲线。但是，如果我传递更多数据，通过增加 X &amp; Y 长度（分批或不分批），网络将停止给出良好的损失结果。
我尝试了多种方法来改善这种情况：

规范化数据
使用各种学习率和不同的调度程序（LambdaLR、OneCycleLR）
创建不太复杂的网络（更少的神经元、更少的层）
创建更复杂和更深的网络
更改优化器（Adam、SGD 等）
进行随机重启
进行梯度裁剪
进行梯度的批量传播与每个时期进行单次传播
消除我在 fun_sin 中的噪音
检查我传递的额外数据是否都很好（绘制图表并检查平均值/标准差）
尝试了各种不同的损失函数，这些函数会对网络的错误进行更多的惩罚

当我有更多数据时，我就是无法获得合理的损失。我读过这篇文章https://arxiv.org/abs/1906.00425，它讨论了为什么神经网络在频率较高时会出现收敛循环曲线的问题，但在我的例子中，驱动频率的参数b非常低（0.1），所以不要认为这适用于这里（此外，如果我的数据较少，网络学习得很好）。
有人知道我在这里可能遇到什么问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659180/neural-network-not-learning-sinusoidal-function-parameters</guid>
      <pubDate>Tue, 24 Dec 2024 22:52:19 GMT</pubDate>
    </item>
    <item>
      <title>有争议的观点是，PDF 的卷积可能不是 PDF</title>
      <link>https://stats.stackexchange.com/questions/659168/controversial-view-that-convolutions-of-a-pdf-might-not-be-a-pdf</link>
      <description><![CDATA[有一条帖子说，对 $f(x) \cdot f(s-x)\,dx,$ 进行积分的 卷积公式 再次返回 PDF。我有点同意这一点。但后来，我偶然发现了这个 youtube 视频。我在下面提供了它们的链接。
在视频的 00:15:30，如果右侧的单条曲线（三角形）是 PDF，那么当他说“这个数字 $s$ 是该（卷积）函数的输入，而相应的输出是左下方图形的面积”时，他的意思是什么。
我的理解是，$s$ 取精确值的概率理想情况下应该是 $0.$ 那么他怎么能说“相应的输出是左下方图形的面积”呢？由于概率，因此面积应限制为 $0.$
链接：
证明 PDF 的卷积可得到 PDF
https://youtu.be/IaSGqQa5O-M?si=smyv_63FsMNkH9ly&amp;t=930]]></description>
      <guid>https://stats.stackexchange.com/questions/659168/controversial-view-that-convolutions-of-a-pdf-might-not-be-a-pdf</guid>
      <pubDate>Tue, 24 Dec 2024 17:25:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么在半监督 VAE 模型中将目标 𝑦 y 用作编码器的输入？</title>
      <link>https://stats.stackexchange.com/questions/659156/why-is-the-target-y-used-as-an-input-to-the-encoder-in-a-semi-supervised-vae</link>
      <description><![CDATA[正如标题所述，我理解 Kingma 的原始论文中方程 (6-7) 的数学推导。但是，由于 𝑦 已在模型中用作分类器的目标，那么将 𝑦 用作编码器的输入的目的是什么？这会不会是多余的？似乎从编码器的输入中删除 𝑦 在实践中也是可行的。]]></description>
      <guid>https://stats.stackexchange.com/questions/659156/why-is-the-target-y-used-as-an-input-to-the-encoder-in-a-semi-supervised-vae</guid>
      <pubDate>Tue, 24 Dec 2024 13:53:10 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 拟合带有工具变量的负二项混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/659184/fit-negative-binomial-mixed-effects-model-with-instrumental-variables-with-r</link>
      <description><![CDATA[如何使用 R 拟合带有工具变量的固定效应负二项式模型？
我尝试过 fixest 包，但它仅支持 OLS 的工具变量，而不支持负二项式：
id &lt;- rep(seq(1,10), each=5)
year &lt;- rep(seq(2021, 2025), times=10)
df &lt;- data.frame(id=id, year=year)
df[[&quot;weight&quot;]] &lt;- rnorm(nrow(df), 100, 10)
df[[&quot;height&quot;]] &lt;- 2*df$weight+rnorm(nrow(df), 0, 5)
df[[&quot;count&quot;]] &lt;- rpois(nrow(df), df$height+rnorm(nrow(df), 0, 5))
mod &lt;- fixest::fenegbin(count ~ 1 | id | height~weight, df)

fixest::fenegbin(count ~ 1 | id | height ~ weight, df) 中的错误： 
参数“fml”不能包含由竖线（“|”）分隔的两个以上部分。IV 仅适用于“feols”。
语法为：DEP VAR ~ EXPL VARS | FIXED EFFECTS。 （不允许 IV。）

相关：带诊断的固定效应模型中的 IV 回归]]></description>
      <guid>https://stats.stackexchange.com/questions/659184/fit-negative-binomial-mixed-effects-model-with-instrumental-variables-with-r</guid>
      <pubDate>Tue, 24 Dec 2024 13:01:47 GMT</pubDate>
    </item>
    <item>
      <title>比较两个具有相同预测变量但不同数据集的广义线性模型</title>
      <link>https://stats.stackexchange.com/questions/659137/comparing-two-generalized-linear-models-with-same-predictors-but-different-datas</link>
      <description><![CDATA[我想知道两个或多个组之间的系数是否不同（例如老年人与年轻人、白天与夜间事故）。我听说过 Chow 检验，但它只适用于线性回归。我想将其应用于泊松或逻辑回归。我读过一些论文（如这篇），其中使用似然比检验来处理这个问题，但我不确定它是如何工作的。]]></description>
      <guid>https://stats.stackexchange.com/questions/659137/comparing-two-generalized-linear-models-with-same-predictors-but-different-datas</guid>
      <pubDate>Mon, 23 Dec 2024 22:44:10 GMT</pubDate>
    </item>
    <item>
      <title>在回归中独立性是否意味着条件独立性？</title>
      <link>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</link>
      <description><![CDATA[我正在阅读统计学习要素（第 44 页），并看到了这句话：

&quot;从统计学的角度来看，如果训练观测值$(x_i, y_i)$代表从其总体中独立随机抽取的样本，则该标准是合理的。即使 $x_i$ 不是随机抽取的，如果 $y_i$ 在给定输入 $x_i$ 的情况下是条件独立的，则该标准仍然有效。&quot;

为了探索这一点，我考虑了两种情况下的联合似然：

情况 1：$(x_i, y_i)$ 完全独立
如果 $(x_i, y_i)$ 对完全独立，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \prod_{i=1}^n P(y_i \mid x_i, \theta) P(x_i \mid \theta)。
$$

案例 2：给定 $x_i$，$y_i$ 的条件独立性&gt;
如果给定 $x_i$，$y_i$ 是条件独立的，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \left( \prod_{i=1}^n P(y_i \mid x_i, \theta) \right) P(x_1, x_2, \dots, x_n \mid \theta)。
$$



观察：

边际：
在情况 1中，由于独立性假设，输入的边际分布分解为$\prod_{i=1}^n P(x_i \mid \theta)$。
在情况 2中，输入的边际分布写为单个项$P(x_1, x_2, \dots, x_n \mid \theta)$，因为没有假设$x_i$。

条件：
在这两种情况下，除去边际，给定$x_i$的$y_i$的条件分布是相同的：
$$
\prod_{i=1}^n P(y_i \mid x_i, \theta)。
$$


这表明，尽管对边际的假设不同，但条件结构并没有不同。

问题：
假设$(x_i, y_i)$完全独立（情况 1）是否意味着在给定$x_i$的情况下，$y_i$具有条件独立性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</guid>
      <pubDate>Fri, 20 Dec 2024 13:04:15 GMT</pubDate>
    </item>
    <item>
      <title>防止时间序列数据拆分中的数据泄露</title>
      <link>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</link>
      <description><![CDATA[我正在研究机械系统的故障检测问题，目标是确定故障类型。我使用的数据集对于每种类型的故障（目标标签）都有三种大小，每种故障大小都有四种不同的工作条件，如下图所示。请注意，数据集中的每个样本都是时间序列，由于样本数量太少而且太长，因此需要将每个样本分成固定长度的块。现在的问题是如何将每个块分配给训练集或测试集，以确保公平和无偏见的评估。

在之前的研究中，常见的做法是将所有块随机分成训练集和测试集。

使用这种方法，神经网络模型通常在测试集上实现近乎完美的性能。然而，这种方法似乎存在根本缺陷，因为将近似平稳的信号分成块会导致来自同一信号的块高度相似，而相似的块可能最终出现在两个集合中，从而导致严重的数据泄漏。为了说明这种数据泄漏，我将 t-SNE 算法应用于这些块。

在此图中，每种颜色对应特定的故障类型和故障大小。请注意，来自同一样本的块紧密聚集在一起。以下是放大版的图：

我认为应该根据故障大小来拆分块。例如，故障大小为 1 和 2 的样本块应包含在训练集中，而故障大小为 3 的样本块应包含在测试集中。这可确保测试集中不存在来自训练信号的任何信息。

现在我想问：

我关于数据泄露的说法正确吗？如果正确，是否有其他方法可以更严格地证明数据泄露，例如使用相似性指标或其他可视化？
您如何看待提议的拆分方法？基于故障大小的拆分是否足以防止数据泄露？如果不是，您会推荐哪些替代拆分策略来确保公平评估？

编辑：针对评论，我将尝试澄清一些观点。在我的应用中，不同设置中的故障大小可能有很大差异，因此重要的是模型可以在不暴露于与不同故障大小相关的信号的情况下检测故障。理想情况下，我们会在训练集中包含不同故障大小的信号，但这是不切实际的。另一方面，预计在两种故障大小上训练的模型将难以在第三种未见过的故障大小上表现良好。这就引出了一个问题：“训练测试拆分之间的相似度有多大是可以接受的？”如果答案是这取决于应用程序，那么在我的情况下，与某些故障大小相关的信号在测试期间应该保持未知，因为这反映了生产中的条件。
正如@Ggjj11 已经提到的，在我提出的方法中，重复拆分，并报告平均准确度。具体来说，在第一次迭代中，与小故障和中等故障相关的信号包含在训练集中，而与大故障相关的信号包含在测试集中。在第二次迭代中，与小故障和大故障相关的信号包含在训练集中，而中等故障大小包含在测试集中。第三次迭代遵循类似的模式。经过一番研究，我发现这种方法被称为GroupKFold 交叉验证。]]></description>
      <guid>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</guid>
      <pubDate>Tue, 17 Dec 2024 15:38:37 GMT</pubDate>
    </item>
    <item>
      <title>稳健线性混合模型 (rlmer)：如何解析三向相互作用</title>
      <link>https://stats.stackexchange.com/questions/606702/robust-linear-mixed-modelrlmer-how-to-unpack-the-three-way-interaction</link>
      <description><![CDATA[我在稳健线性混合模型（RLMM）中发现了三因素交互效应（三个因素各有两个水平），不知道该如何解析这个交互效应。
我的做法是：先根据因素1的两个水平，将其拆分成两个以上的RLMM，然后为了进一步的简单比较，我使用了配对或非配对的Mann-Whitney非参数检验。这有点麻烦，不知道有没有类似pairs()的函数可以一次性得到所有简单比较的结果。
谢谢关注！]]></description>
      <guid>https://stats.stackexchange.com/questions/606702/robust-linear-mixed-modelrlmer-how-to-unpack-the-three-way-interaction</guid>
      <pubDate>Sun, 26 Feb 2023 16:21:32 GMT</pubDate>
    </item>
    <item>
      <title>训练集没有缺失值，但测试集有缺失值，如何处理？</title>
      <link>https://stats.stackexchange.com/questions/593178/training-set-does-not-have-missing-values-but-test-set-does-how-to-handle</link>
      <description><![CDATA[对于建模挑战，我分别获得了训练集和测试集。由于我的训练集没有大量缺失记录，因此我省略了所有包含 NA 的行。并在完整的数据集上训练我的模型。
但是，我的测试数据集也包含 NA。我没有能力删除任何测试数据集行，因为我需要为每一行生成预测。我应该如何解决这个问题？即使我不需要在训练数据集中插补任何内容，仅在测试数据集上使用插补方法（例如 MICE）是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/593178/training-set-does-not-have-missing-values-but-test-set-does-how-to-handle</guid>
      <pubDate>Sat, 22 Oct 2022 02:30:15 GMT</pubDate>
    </item>
    <item>
      <title>Keras LSTM：如何在单个批次内进行陈述和维护？</title>
      <link>https://stats.stackexchange.com/questions/570957/keras-lstm-how-is-stated-maintained-within-a-single-batch</link>
      <description><![CDATA[假设 Keras LSTM 会在每个批次之后重置内部状态，我想了解如何在单个批次内维护内部状态。假设 batch_size=4、timesteps=3 和 num_features=1。问题是预测单变量时间序列 $x_1,x_2, ... ,x_n$ 的下一个元素。
根据指南，为该模型提供数据的正确方法是准备长度为 timesteps 的重叠窗口。因此，第一批由以下输入和目标组成：
输入 A：[$x_1,x_2,x_3$] $\rightarrow$ 目标 A：$x_4$
输入 B：[$x_2,x_3,x_4$] $\rightarrow$ 目标 B：$x_5$
输入 C：[$x_3,x_4,x_5$] $\rightarrow$ 目标 C：$x_6$
输入 D：[$x_4,x_5,x_6$] $\rightarrow$ 目标 D：$x_7$
因为这是单个批次，所以内部状态应始终保持。首先，模型将使用初始内部状态（重置后的状态）处理输入 A。处理输入 A 后的新内部状态将是处理 $(x_1,x_2,x_3)$ 后产生的内部状态，我将其表示为 $h_{3}$。类似地，处理 $(x_1)$ 和 $(x_1,x_2)$ 后的内部状态为 $h_{1}$ 和 $h_{2}$，但这些状态并未保留。
接下来，模型将处理输入 B。但是，如果我理解正确的话，它将在给定内部状态 $h_3$ 的情况下处理输入 B。因此，它将在给定 $(x_2,x_3,x_4)$ 的情况下处理 $(x_1,x_2,x_3)$。但是，当模型即将被输入 $x_2$，接着是 $x_3$ 和 $x_4$ 时，怎么会认为模型已经看到了 $x_3$ 呢？相反，我认为在给定内部状态 $h_{1}$ 的情况下处理输入 B 更有意义，而不是 $h_{3}$。
总之，内部状态的序列似乎基于序列 $(x_1,x_2,x_3,x_2,x_3,x_4,x_3,x_4,x_5...)$，而不是原始序列 $(x_1,x_2,x_3,x_4,...)$。这怎么就不对了呢？
此外，如果网络已经在输入 A 中被输入了 $x_3$，那么如何才能在输入 B 和输入 C 中再被输入两次 $x_3$，而不会弄乱内部状态？]]></description>
      <guid>https://stats.stackexchange.com/questions/570957/keras-lstm-how-is-stated-maintained-within-a-single-batch</guid>
      <pubDate>Sat, 09 Apr 2022 13:58:38 GMT</pubDate>
    </item>
    </channel>
</rss>