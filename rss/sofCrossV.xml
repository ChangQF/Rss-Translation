<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 18 Sep 2024 12:31:27 GMT</lastBuildDate>
    <item>
      <title>如何解释 0 至 1 范围内变量的优势比</title>
      <link>https://stats.stackexchange.com/questions/654542/how-to-interpret-odds-ratio-for-variables-that-range-from-0-to-1</link>
      <description><![CDATA[我该如何解释逻辑回归模型中变量的几率比，该变量是一个“比率”，即介于 0 和 1 之间的值？在这种情况下，单位是什么？
例如，假设我正在对篮球投篮数据进行建模，如果球员投篮成功，我的响应变量等于 1，如果投篮失败，则等于 0。此外，我有一个解释变量，即球队到那时为止的投篮准确率，这个变量的范围是 0 到 1。那么，我该如何解释这个变量的系数的几率比？因为我不能说它会增加 1 个单位，因为变量不能超过大于 1 的值。请问有什么关于如何解释这一点的提示吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654542/how-to-interpret-odds-ratio-for-variables-that-range-from-0-to-1</guid>
      <pubDate>Wed, 18 Sep 2024 11:35:11 GMT</pubDate>
    </item>
    <item>
      <title>具有 nll 高斯损失的 unet 中的异方差方差预测是恒定的</title>
      <link>https://stats.stackexchange.com/questions/654541/heteroscedastic-variance-prediction-in-unet-with-nll-gaussian-loss-is-constant</link>
      <description><![CDATA[我正在尝试预测数据集中的异方差噪声。我已经设置了一个 FPN，将方差视为一个附加类。我的数据集是空中语义分割无人机数据集。这是模型：
class FPN(nn.Module):
def __init__(self,coder_name=&quot;resnet34&quot;,coder_weights=&quot;imagenet&quot;,in_channels=1,activation=None,decoder_dropout=0.3):
super(FPN,self).__init__()
self.base_model = smp.FPN(
encoder_name=encoder_name,
encoder_weights=encoder_weights,
in_channels=in_channels,
classes=2,
activation=activation,
decoder_dropout=decoder_dropout
)

def forward(self,x):
mean,var = torch.split(self.base_model(x),1,dim=1)
var = torch.nn. functional.softplus(var)
return torch.cat((mean,var), dim=1)

损失函数是 pytorch 的标准 NLL-Gaussian Loss：
class CustomGaussianLoss(base.Loss):
def __init__(self):
super(CustomGaussianLoss, self).__init__()
self.gaussian_nll_loss = nn.GaussianNLLLoss()

def forward(self, input, target):
mean, var = torch.split(input, 1, dim=1)

loss = self.gaussian_nll_loss(mean, target, var)
return loss 

然而，在第一个 epoch 之后，方差总是预测为每个像素的常数 0.69。像素值在 0 和 1 之间缩放。有趣的是，0.69 大致是数据集跨像素的方差。
鉴于此数据集，这一切对我来说毫无意义。即使方差大致恒定（但事实并非如此），量级也完全错误。有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654541/heteroscedastic-variance-prediction-in-unet-with-nll-gaussian-loss-is-constant</guid>
      <pubDate>Wed, 18 Sep 2024 10:38:14 GMT</pubDate>
    </item>
    <item>
      <title>使用螺旋桨计算细胞比例是否显著</title>
      <link>https://stats.stackexchange.com/questions/654540/calculating-if-cell-proportions-are-significant-using-propeller</link>
      <description><![CDATA[我正在使用 propeller，https://rdrr.io/github/Oshlack/speckle/man/propeller.anova.html，来计算肥大细胞与对照组细胞比例之间的显著性。我的模型设计如下。
design &lt;- model.matrix(~0 + grp + md_subset$batch)

我理解不设置截距就没有基线水平，所有分类变量都表示为单独的列。所以我总共有 10 个样本，3 个对照组和 7 个肥大组，它们分 4 个批次完成。我的设计矩阵如下所示：

我对设计矩阵有几个问题。首先，为什么我的设计矩阵中没有 2 列，一列表示条件，该行是否用 0 表示控制，1 表示肥大，一列表示批次，行中用 1、2、3 或 4 表示，因为它们有 4 个批次？我看到的是每个条件都有自己的列，每个批次也是如此。在我看来这像是热编码，但为什么在这种情况下这是必要的？其次，如果热编码是必要的，并且这就是每个变量都有单独列的原因，那么为什么批次 1 列不存在，因为我的样本 3（第 3 行）是批次 1？这个设计矩阵是否不考虑批次 1 的影响？
最后，当我运行它时，我得到了这样的输出：

首先，使用设计运行它是否意味着我正在查看在控制批次效应的情况下，条件之间每种细胞类型的比例有多大？我问这个问题的原因是，根据我的理解，通常在回归中，~ 之后的第一个变量是您要测试的变量，任何其他变量都是您想要控制的混杂因素。然而，在 DESeq2 或 edgeR 等包中，我看到控制的混杂因素首先出现，最后一个变量是您要测试响应变量如何与之相关的变量。此外，这里的 p 值和 F 统计量是否显示了条件对比例的影响有多大，以及它是否显著？标有 PropMean.* 的每一列表示不同细胞类型的变量的系数？
我很感激任何帮助和澄清，因为我认为我主要理解了，但希望得到一些帮助和建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/654540/calculating-if-cell-proportions-are-significant-using-propeller</guid>
      <pubDate>Wed, 18 Sep 2024 09:48:03 GMT</pubDate>
    </item>
    <item>
      <title>当缺少时间点时，emmeans 和 mmrm</title>
      <link>https://stats.stackexchange.com/questions/654539/emmeans-and-mmrm-when-there-are-missing-timepoints</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654539/emmeans-and-mmrm-when-there-are-missing-timepoints</guid>
      <pubDate>Wed, 18 Sep 2024 09:27:00 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归与均值和方差相比，哪个估计更有效，为什么？</title>
      <link>https://stats.stackexchange.com/questions/654538/logistic-regression-versus-mean-and-variance-which-estimate-is-more-efficient-a</link>
      <description><![CDATA[让
$$\begin{array}{}
Y_i &amp; \sim&amp; Bernoulli(0.5) \\
X_i|Y_i &amp;\sim&amp; N(\mu_{Y_i},\sigma^2)
\end{array}$$
在这种情况下，我们可以考虑独立的观测对 $X_i,Y_i$，遵循逻辑回归模型，其中 $Y_i$ 具有条件伯努利分布，并且
$$P(Y_i=1|X_i=x) = \frac{1}{1+e^{-(a+bx)}}$$
其中 $a = \frac{\mu_1^2-\mu_0^2}{2\sigma^2}$ 和 $b=\frac{\mu_0-\mu_1}{\sigma^2}$
因此，我们可以用两种不同的方法估计这些参数$a$和$b$

执行逻辑回归。
直接用假设的正态分布估计$\mu_i$和$\sigma$，然后计算参数$a$和$b$。

这两种方法不会给出相同的结果。哪种方法最有效（具有预期平方误差）？

进一步澄清我的问题。这也是为了理解。
以下是一个模拟，表明均值和方差的估计导致较小的误差。它可以回答这个问题。

但它是通用的吗？
为什么逻辑回归不能达到同样的效果？
关于 $X_i$ 分布的知识增加了什么样的信息，是否可以将其纳入逻辑回归（例如通过增加权重）以使其表现更好？

set.seed(1)

sim = function(n, mu) {

Y = rbinom(n,1,0.5)
X = rnorm(n,Y*mu,1)

mod = glm(Y~X, family = binomial)
glm_est = mod$coefficients

m = c(mean(X[Y==0]),mean(X[Y==1]))
V = (sum((X-m[Y+1])^2)/(n-2))

mm_est = c(-diff(m^2)/2/V,
diff(m)/V)

return(c(glm_est,mm_est))
}

mu = 1
z = replicate(10^3,sim(200,mu))

true_a = -mu^2/2
true_b = mu

### glm_errors
mean((z[1,]-true_a)^2) # 0.03592216
mean((z[2,]-true_b)^2) # 0.03245813

### gaussian_mm_errors
mean((z[3,]-true_a)^2) # 0.01323784
mean((z[4,]-true_b)^2) # 0.03075781
]]></description>
      <guid>https://stats.stackexchange.com/questions/654538/logistic-regression-versus-mean-and-variance-which-estimate-is-more-efficient-a</guid>
      <pubDate>Wed, 18 Sep 2024 08:55:29 GMT</pubDate>
    </item>
    <item>
      <title>基于Gershgorin定理的实现方法</title>
      <link>https://stats.stackexchange.com/questions/654537/implement-method-based-on-gershgorin-s-theorem</link>
      <description><![CDATA[有人能帮忙实现（在 Python 中）一个函数/算法吗？该函数/算法利用 Gershgorin 定理通过返回磁盘中心/特征值和半径来定位矩阵的特征值。我曾尝试查看 https://github.com/HowDoIUseThis/GershgorinCircles/blob/master/EAprox.py，但似乎不是我真正想要的。它似乎还为其他矩阵示例提供了错误的图表，但也许你们中的任何一个人都可以使用其中的想法来解决这个问题。格什戈林定理可在此处找到 https://mathworld.wolfram.com/GershgorinCircleTheorem.html]]></description>
      <guid>https://stats.stackexchange.com/questions/654537/implement-method-based-on-gershgorin-s-theorem</guid>
      <pubDate>Wed, 18 Sep 2024 08:53:45 GMT</pubDate>
    </item>
    <item>
      <title>在加法和乘法生存模型之间进行选择</title>
      <link>https://stats.stackexchange.com/questions/654533/choosing-between-additive-and-multiplicative-survival-model</link>
      <description><![CDATA[我正在使用生存模型对住房建设时机进行研究。我现在面临的问题是选择加法生存模型还是乘法生存模型。在两者之间进行选择时我应该考虑什么，是否有任何测试统计数据可以帮助做出此决定？]]></description>
      <guid>https://stats.stackexchange.com/questions/654533/choosing-between-additive-and-multiplicative-survival-model</guid>
      <pubDate>Wed, 18 Sep 2024 07:33:59 GMT</pubDate>
    </item>
    <item>
      <title>计算具有任意数量事件的泊松分布的 Fisher 信息</title>
      <link>https://stats.stackexchange.com/questions/654530/computing-fisher-information-for-a-poisson-distribution-with-any-number-of-event</link>
      <description><![CDATA[该问题的背景是这篇论文。我试图理解如何从方程 (5) 得到方程 (6)。 (7)。
为简单起见，我只考虑 1 维，而本文中的方程式推广到 $D$ 维。
给定概率密度
$$ p(t_1,...,t_K|r) = \frac{1}{K!} \prod_{k=1}^K \Gamma(r,t_k)) \exp{\left[-\int_0^{\tau} dt \Gamma(r, t)\right]},$$
关于位置 $r$ 的 Fisher 信息由以下公式给出：
$$F = \sum_{K=0}^{\infty}\int_0^{\tau}dt_t...dt_K\ p(t_1,...,t_K|r)\left(\frac{d}{dr} \ln{p(t_1,...,t_K|r)}\right)^2.$$
我试图证明这可以简化为
$$ F = \int_0^{\tau}dt \frac{1}{\Gamma(r, t)}\left(\frac{d}{dr}\Gamma(r, t)\right)^2.$$
我对此感兴趣的原因是因为我想为不同的$p$（高斯分布而不是泊松分布）。
我尝试过：在加数中替换 K 的特定值并尝试简化它。这似乎没有多大帮助。
我认为有一些我不知道的通用方法来处理这种求和。我的背景是物理学博士学位，但我没有学过很多统计学。]]></description>
      <guid>https://stats.stackexchange.com/questions/654530/computing-fisher-information-for-a-poisson-distribution-with-any-number-of-event</guid>
      <pubDate>Wed, 18 Sep 2024 06:45:39 GMT</pubDate>
    </item>
    <item>
      <title>$\mathbb{E}(​​|X|$ 和 $\mathbb{E}(​​|X+Y|)$ 的展开</title>
      <link>https://stats.stackexchange.com/questions/654527/expansion-of-mathbbex-and-mathbbexy</link>
      <description><![CDATA[给定一个数值随机变量$X$和$Y$，我对$\mathbb{E}(​​|X|)$和$\mathbb{E}(​​|X| + |Y|)$的展开式有点困惑。
对于 $\mathbb{E}(​​|X|)$，是否
$$\mathbb{E}(​​|X|)= \lim_{n \to \infty}\frac{|X_1|+|X_2|+...|X_n|}{n}$$
或
$$\mathbb{E}(​​|X|)= \lim_{n \to \infty}\frac{|X_1+X_2+...X_n|}{n}?$$
类似地，对于 $\mathbb{E}(​​|X| + |Y|)$，是否
$$\mathbb{E}(​​|X| + |Y|)=\lim_{n \to \infty}\frac{|X_1|+|X_2|+...|X_n|+|Y_1|+...|Y_n|}{n}$$
或
$$\mathbb{E}(​​|X| + |Y|)=\lim_{n \to \infty}\frac{|X_1+X_2+...X_n|+|Y_1+...Y_n|}{n}?$$]]></description>
      <guid>https://stats.stackexchange.com/questions/654527/expansion-of-mathbbex-and-mathbbexy</guid>
      <pubDate>Wed, 18 Sep 2024 05:59:43 GMT</pubDate>
    </item>
    <item>
      <title>一般基准利率谬误（来自《统计分析原理》，Arias-Castro）</title>
      <link>https://stats.stackexchange.com/questions/654525/general-base-rate-fallacy-from-principles-of-statistical-analysis-arias-castro</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654525/general-base-rate-fallacy-from-principles-of-statistical-analysis-arias-castro</guid>
      <pubDate>Wed, 18 Sep 2024 05:14:42 GMT</pubDate>
    </item>
    <item>
      <title>封锁对新冠病例的影响</title>
      <link>https://stats.stackexchange.com/questions/654522/effect-of-lockdowns-on-covid-cases</link>
      <description><![CDATA[对于我的流行病学课程，我想使用以下数据为一个国家/地区的各省（即该国有不同的省份）建立一个纵向回归模型：

自大流行开始以来各省的新冠病例（每周）
自大流行开始以来各省累计的新冠疫苗接种量（每周）
自大流行开始以来各省累计发布的新冠警告数量

例如，我想看看那些不断更改新冠警告（例如新的封锁、疫苗强制令、封锁强制令、限制社交聚会等）以及疫苗接种的省份是否导致新冠病例减少。假设是，与调整新冠警告速度较慢的省份相比，不断调整新冠警告的省份的新冠病例可能会减少。
我尝试这样编写模型：

$ i = 1, ..., N $ (省份)
$ t = 1, ..., T $ (时间点，例如几周)

$$ Y_{it} = \beta_0 + \beta_1 V_{it} + \beta_2 A_{it} + \beta_3 t + \beta_4 (V_{it} \times A_{it}) + u_i + \epsilon_{it} $$
其中：

$ Y_{it} $ = 省份 $i$ 时间 $t$ 的新增 COVID-19 病例

$ V_{it} $ = 省份 $i$ 时间 $t$ 的累计疫苗接种量

$ A_{it} $ = 省份 $i$ 时间 $t$

$ t $ = 时间变量（自疫情开始以来的周数）

$ \beta_0 $ = 截距

$ \beta_1, \beta_2, \beta_3 $ = 固定效应系数

$ u_i $ = 省份 $i$ 的随机效应，其中 $u_i \sim N(0, \sigma_u^2)$

$ \epsilon_{it} $ = 误差项，其中 $\epsilon_{it} \sim N(0, \sigma_\epsilon^2)$


在此模型中：

$\beta_1$ 表示累积疫苗对新病例的影响。

$\beta_2$ 表示累积建议对新病例的影响。

$\beta_3$ 表示总时间趋势。

$u_i$ 表示未观察到的

$\beta_4$ 表示疫苗和建议的综合效果。

$\epsilon_{it}$ 是误差项。


这种统计方法有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654522/effect-of-lockdowns-on-covid-cases</guid>
      <pubDate>Wed, 18 Sep 2024 01:43:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 R 中的逐次试验数据运行重复测量方差分析？</title>
      <link>https://stats.stackexchange.com/questions/654535/how-can-i-run-a-repeated-measures-anova-in-r-with-trial-by-trial-data</link>
      <description><![CDATA[我需要帮助设置数据集并在 R 中运行重复测量方差分析。我当前的数据集是 41 个受试者的试验数据。有一列表示受试者 ID（1-41），一列表示受试者所属的组（“置信度”或“定位”），一列表示相位（“前”或“后”），一列表示滞后位置（1-7），一列表示准确度（0 或 1）。每个受试者有 140 行：其中 70 行来自受试者“前”试验，70 行来自受试者“后”试验。在每组 70 行中，7 个滞后位置（1-7）各有 10 行。准确度是因变量。
我尝试过许多不同的方法，但我认为方差分析一直将数据视为每次试验都是不同的受试者。残差或 DenDF 中的 df 会返回 5166 或 5673 之类的数字，具体取决于我尝试的方法。我对 R 和运行方差分析还很陌生，正在尝试复制已经完成的分析。阶段 * 组 * 滞后的残差 df 应该是 234，而不是 5,000+]]></description>
      <guid>https://stats.stackexchange.com/questions/654535/how-can-i-run-a-repeated-measures-anova-in-r-with-trial-by-trial-data</guid>
      <pubDate>Wed, 18 Sep 2024 00:53:18 GMT</pubDate>
    </item>
    <item>
      <title>估计玩硬币 1 的后验概率</title>
      <link>https://stats.stackexchange.com/questions/654521/estimating-the-posterior-probability-of-playing-coin-1</link>
      <description><![CDATA[假设某人有两枚硬币，正面朝上的概率为 $p_1$，正面朝上的概率为 $p_2$，而正面朝上的概率为 $p_2\le p_1$。该人正在抛硬币，并且可能会以 $\gamma$ 的概率从掷硬币 1 切换到掷硬币 2，但是一旦他们开始掷第二枚硬币，他们就不会再切换回掷第一枚硬币。我们看到了结果，但是我们不知道该人是掷第一枚硬币还是掷第二枚硬币。假设我们不知道$p_1$、$p_2$和$\gamma$的确切值，我们如何计算该人所玩的硬币是第二枚硬币的后验概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/654521/estimating-the-posterior-probability-of-playing-coin-1</guid>
      <pubDate>Wed, 18 Sep 2024 00:18:40 GMT</pubDate>
    </item>
    <item>
      <title>基于模量函数的随机化有效性</title>
      <link>https://stats.stackexchange.com/questions/654506/randomization-validity-based-on-a-modulus-function</link>
      <description><![CDATA[我想在仅支持基于 address_id 分配变体的平台上运行 AB 测试。在我们的平台上，每个用户可以有多个 address_id，即每个 user_id 可以映射到多个 address_id。我想确保每个 user_id 的有效随机化。我相信我的测试有两个选项。

排除具有多个 address_id 的用户，仅对只有一个 address_id 的用户运行测试。（包括具有多个 address_id 的用户意味着在测试期间可能会有用户根据其不同的 address_id 被分配到 A 和 B，因此这违反了组的独立性）

创建称为 bucket_number 的东西，并将 bucket 分配给不同的组。这将以以下方式工作：

根据供应商 ID 计算 bucket 编号。这可以通过 supplier_id mod 10 来计算。每个供应商将始终以这种方式获得一个存储桶编号。
此存储桶编号将分配给一个变体，例如存储桶编号 0-4 分配给 A，存储桶编号 5-9 分配给 B。
这样，每个供应商将始终被分配给相同的变体。



我强烈倾向于方法 2。即创建存储桶编号。但我想检查这是否仍然是一种有效的随机化方法？（请注意，原始 supplier_id 是按顺序创建的数字，因此没有理由相信 supplier_id 的模数会以某种方式导致偏差）
我的问题：方法 2 有效吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654506/randomization-validity-based-on-a-modulus-function</guid>
      <pubDate>Tue, 17 Sep 2024 20:19:22 GMT</pubDate>
    </item>
    <item>
      <title>关于双变量分布的估计</title>
      <link>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</link>
      <description><![CDATA[我正在处理一个具有累积分布函数$F(x, y)$的非负、绝对连续的双变量随机向量，并且我正在尝试使用 Epanechnikov 核来估计$$\int_0^{t_1}F^2(x_1,t_2)dx_1$$。对此的估计定义为
$$\widehat{I}=\frac{1}{n^2h_1^2h_2^2}\int_0^{t_1}\left(\sum_{i=1}^n K\left(\frac{x_1-X_{1i}}{h_1}\right)K\left(\frac{t_2-X_{2i}}{h_2}\right)\right)^2dx_1$$
我在模拟中使用双变量Gumbel分布。下面是我的代码，但我很难为双变量数据选择合适的带宽，而且我得到的估计值与真实值有显著差异。
library(stats)
library(ks)
n &lt;- 40
lambda1 = 2
lambda2 = 0.5
theta = 0.5

for (i in 1:100) {
X1 &lt;- rexp(n, lambda1)
X2 = rgamma(n, (runif(n) &gt; 1 - theta/(1 + lambda1 * theta)) + 1, lambda2 * (1 + lambda1 * theta * X1))
sigma1 &lt;- sd(X1)
sigma2 &lt;- sd(X2)
h1 &lt;- 0.5
h2 &lt;- 0.55
t1 &lt;- 0.2
t2 &lt;- 0.3

epan_kernel_cdf &lt;- function(u) {
0.25 * (3 * u - u^3)
}

积分1 &lt;- sapply(X1, function(Xi) h1 * epan_kernel_cdf((t1 - Xi) / h1))
积分2 &lt;- sapply(X2, function(Yi) h2 * epan_kernel_cdf((t2 - Yi) / h2))

被积函数 &lt;- function(x1) {
kernel_cdf_values &lt;- sapply(X1, function(X1) epan_kernel_cdf((x1 - X1) / h1))
prod_kernel &lt;- kernel_cdf_values * 积分 2
sum_kernel &lt;- sum(prod_kernel)
(sum_kernel)^2
}

x_vals &lt;-seq(0,t1,length.out = 10000)
dx &lt;-x_vals[2]-x_vals[1]
sum_approx &lt;-sum(sapply(x_vals,integrand))*dx
estimated_value &lt;-(1/(n^2*h1^2*h2^2))*sum_approx
true_value &lt;-0.98

bias[i] &lt;-estimated_value[1]-true_value
MSE[i] &lt;-mean((estimated_value[1]-true_value[1])^2)
}

bias
MSE
bias1 &lt;-mean(bias)
bias1
MSE1 &lt;- 平均值 (MSE)
MSE1

我面临的一些具体问题：

为我的双变量数据选择合适的带宽。
我的估计值与真实值 (0.98) 相差甚远。

如果您能提供任何关于如何改进带宽选择或我应该在代码中进行的其他调整的见解或建议，我将不胜感激。提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</guid>
      <pubDate>Tue, 17 Sep 2024 16:55:15 GMT</pubDate>
    </item>
    </channel>
</rss>