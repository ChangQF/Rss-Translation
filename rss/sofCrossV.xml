<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 29 Jan 2024 00:57:55 GMT</lastBuildDate>
    <item>
      <title>Z 分数和拟似然之间的联系？</title>
      <link>https://stats.stackexchange.com/questions/637975/connection-between-z-score-and-quasi-likelihood</link>
      <description><![CDATA[考虑拟似然函数（我在 GEE 上下文中编写它）：
$$ Q(\beta; y) = \sum_{i=1}^{n} (y_i - \mu_i(\beta))^T V_i^{- 1}(\beta, \alpha) (y_i - \mu_i(\beta))$$
地点：

$y_i$ 是第 $i$ 个主题的响应，
$\mu_i(\beta)$ 是 $i$ 的平均响应主题，
$V_i(\beta, \alpha)$ 是 $i$ 的方差函数-第一个主题，
$\beta$ 是固定效果参数，
$\alpha$ 是色散参数。

查看拟似然，我可以看到与 Z 分数（矩阵形式）非常相似的东西：随机变量减去随机变量的期望值除以方差。
这让我想知道 - 拟似然和 Z 分数之间是否存在任何关系？也许拟似然的动机确切形式被选择为相似？这是否与中心极限定理有关 - 即拟似然是渐近正态的，因为它是归一化随机变量的总和？ （我试图自己证明这一点，并将在另一个问题中展示我的工作）]]></description>
      <guid>https://stats.stackexchange.com/questions/637975/connection-between-z-score-and-quasi-likelihood</guid>
      <pubDate>Mon, 29 Jan 2024 00:17:38 GMT</pubDate>
    </item>
    <item>
      <title>如果 OLS 估计器使 MSE 最小化，那么 James-Stein 估计器如何实现更低的 MSE？</title>
      <link>https://stats.stackexchange.com/questions/637973/if-ols-estimator-minimizes-mse-how-does-james-stein-estimator-achieve-a-lower-m</link>
      <description><![CDATA[OLS 估计器解决了以下最小化问题：
$\min ||y-X\beta||^2$
通过采用 FOC，我们获得 $\hat{\beta}$，它最小化了目标函数。
但是 James-Stein 估计器的 MSE 较低。我知道 James-Stein 的证明，但如何将其与 OLS 估计中平方误差损失已最小化这一事实相协调？我在这里缺少什么？
如果 James-Stein 估计器实现了较低的 MSE，为什么我们仍然使用 OLS？虽然 James-Stein 要求分布是正态的，但是根据中心极限定理的某些版本可以满足近似正态性，它不是仍然有用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637973/if-ols-estimator-minimizes-mse-how-does-james-stein-estimator-achieve-a-lower-m</guid>
      <pubDate>Sun, 28 Jan 2024 23:22:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么拉普拉斯平滑时分母要加2？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/637966/why-do-we-add-2-to-the-denominator-when-doing-laplace-smoothing</link>
      <description><![CDATA[对拉普拉斯平滑（例如垃圾邮件过滤）的每个解释都包括以下内容：
&lt;块引用&gt;
解决方案是通过向上平滑它们，永远不要让任何单词概率为零。代替
每个单词计数从 0 开始，从 1 开始。这样，所有计数都不会有分子
为 0。这高估了单词概率，因此我们还在分母上加了 2。 （我们添加 2 因为
我们隐式地跟踪两件事：包含该单词的电子邮件数量以及数量
事实并非如此。这两件事的总和应该在分母中，并且 2 占开始
两个计数器都为 1。）

我不明白为什么我们要在分母上加2。例如，如果我们从 1 开始每个字数计数，则相当于将一封电子邮件添加到我们的数据集，其中每个字数为 1。
并且，由于计算 $P(w_1|S)$ 的公式为 $\frac{\text{包含 }w_1}{\text{垃圾邮件总数}}$ 的垃圾邮件数量，我们不应该在分子和分母上加 1 吗？
如果可能，请用一个非常简单的示例/数据集和具体数字进行解释。我的猜测是，如果您只在分母上加 1（而不是 2），那么解释应该包括关于总和不等于 1 的概率的内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/637966/why-do-we-add-2-to-the-denominator-when-doing-laplace-smoothing</guid>
      <pubDate>Sun, 28 Jan 2024 19:37:09 GMT</pubDate>
    </item>
    <item>
      <title>合并协方差矩阵是 Wishart 吗？</title>
      <link>https://stats.stackexchange.com/questions/637963/is-the-pooled-covariance-matrix-wishart</link>
      <description><![CDATA[如果 $X_1,\ldots,X_{n_x}$ 是 IID $N(\mu_x,\sigma^ 2)$ 和 $Y_1,\ldots,Y_{n_y}$ 是 IID $N(\mu_y ,\sigma^2)$、$S_x^2$ 和 $S_y^2$ 是他们的无偏方差估计，以及
$$
S^2_p = ((n_x-1)S_x^2 + (n_y-1)S_y^2)/(n_x+n_y-2)
$$
是合并方差估计，则 $(n_x+n_y-2)/\sigma^2S^2_p$ 是 $\ chi^2$ 与 $n_x+n_y-2$ df 一起分发。当 $X_i$ 和 $Y_i$ 是具有共同方差的多元法向量时，类似的结果是否成立span 类 =“math-container”&gt;$\Sigma$？合并协方差估计量是否遵循 $n_x+n_y-2$ df 的 Wishart 分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/637963/is-the-pooled-covariance-matrix-wishart</guid>
      <pubDate>Sun, 28 Jan 2024 19:02:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么不直接暴力稀疏 OLS 估计器而不是使用 Lasso？</title>
      <link>https://stats.stackexchange.com/questions/637962/why-not-directly-brute-force-sparsify-the-ols-estimator-instead-of-using-lasso</link>
      <description><![CDATA[我对 Lasso 估算器有疑问。据我所知，由于其稀疏性特性，它在高维设置中特别有用。
例如，如果设计矩阵是正交的，则应用 Lasso 本质上等同于执行普通最小二乘法 (OLS)。在这种情况下，我们将 OLS 估计器中低于某个阈值的所有组件设置为零，并最终对其余组件引入轻微的偏差。
但是，为什么这个策略不能用于非正交情况呢？在这种情况下，我们是否可以简单地执行 OLS，然后将 OLS 估计器中所有不够大的分量归零？
从直观的角度来看，如果 OLS 估计量的某个分量很小，则表明相应的协变量影响不是特别大。因此，将其设置为零似乎是合理的。
任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/637962/why-not-directly-brute-force-sparsify-the-ols-estimator-instead-of-using-lasso</guid>
      <pubDate>Sun, 28 Jan 2024 18:54:53 GMT</pubDate>
    </item>
    <item>
      <title>减去 Wilcoxon 秩和中的理想秩均值，它有什么作用</title>
      <link>https://stats.stackexchange.com/questions/637961/subtracting-the-ideal-rank-mean-in-wilcoxon-rank-sum-what-does-it-do</link>
      <description><![CDATA[我正在阅读 Andy Field 的《使用 R 发现统计》。在关于如何计算 MWU 中的排名统计量的部分中，步骤之一是从排名总和中减去平均排名。
W = 等级总和 - 平均等级
这个想法是，它可以纠正群组中的人数。
但是我们减去的不是总排名的真实平均值，而是理想平均值（有 10 个观测值，总和为 [1+2+...+10]，而实际排名为 1 ,2,3.5,....12，因为关系。
当我们通常从样本中删除均值时，是为了创建居中。这个程序在这种情况下起什么作用？我不是一个数学素养很高的人，所以对正在发生的事情有一些直观的了解会很有帮助
谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/637961/subtracting-the-ideal-rank-mean-in-wilcoxon-rank-sum-what-does-it-do</guid>
      <pubDate>Sun, 28 Jan 2024 18:48:21 GMT</pubDate>
    </item>
    <item>
      <title>从具有已知子组的组中采样时的功率大小</title>
      <link>https://stats.stackexchange.com/questions/637958/power-sizing-when-sampling-from-a-group-with-known-subgroups</link>
      <description><![CDATA[我需要对由三个子组组成的组进行功效分析。
采样的测量值是并排评估的同一品种的两只狗之间的差异测量值。对狗进行独立采样。每个狗品种下面又分为三个子类别。原假设是品种（亲本组）之间没有差异（d = 0）。替代方案是存在差异&gt; 0.
因此，当我们收集数据时，我们有三行：

品种取样
子类别
差异测量（-1 和 1 之间的连续实数）

对于没有已知子组的组的典型功效分析，我只需使用“pwr.t.test(n, d, type=“one.sample”)。
但是，如果您为一个拥有已知子组且每个子组分布不同的组提供支持，我不清楚这是否合理。
我们是否简单地认为父组中的每个样本都是相同分布的，即使子组分布不同（但总的来说，它们形成了我们可以认为相同的另一个分布）？
或者我们应该对子组进行建模，并通过复制来自多个子组的单纯形组（具有自己的分布）的采样过程来模拟所需的功率？]]></description>
      <guid>https://stats.stackexchange.com/questions/637958/power-sizing-when-sampling-from-a-group-with-known-subgroups</guid>
      <pubDate>Sun, 28 Jan 2024 18:09:32 GMT</pubDate>
    </item>
    <item>
      <title>数据/观察本身如何有助于我们确定假设是真是假的能力？</title>
      <link>https://stats.stackexchange.com/questions/637955/how-do-data-observations-themselves-contribute-to-our-ability-to-make-determinat</link>
      <description><![CDATA[假设我有一个假设，并且我正在尝试确定该假设是真是假。如果我没记错的话，在统计中，标准的哲学观点是，从技术上讲，我们无法确定假设是真是假，而是证据（数据）是否无法反驳该假设。但是数据/观察本身如何有助于我们做出此类决定的能力呢？特别是，所有创建的数据都是平等的，还是有些数据的贡献不同/具有优越的“解释力”？天真地思考这一点，在我看来，“独立”的数据/观察结果似乎是“独立的”。彼此之间具有较低的相关性，或者彼此之间具有较低的相关性，将具有更强的“解释力”。 /“信号” /“贡献”进行我们的分析/确定假设是真是假？但是，在我的统计推断研究中，我不记得以这种方式讨论/处理数据点/观察结果的事情。这个想法有什么道理吗，还是我错了？如果这个想法有道理，我可以使用哪些好的资源（教科书）来深入研究这个问题？
&lt;小时/&gt;
编辑
我想这个想法也可以被认为是多么“经济”。数据是。因此，举例来说，如果数据是独立的，我就能够使用较少的数据执行一定程度的假设检验，但如果数据是独立的，则要达到相同的准确性水平，则需要更多的数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/637955/how-do-data-observations-themselves-contribute-to-our-ability-to-make-determinat</guid>
      <pubDate>Sun, 28 Jan 2024 17:28:55 GMT</pubDate>
    </item>
    <item>
      <title>随机化有什么魔力？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637953/whats-the-magic-of-randomization</link>
      <description><![CDATA[我读到可以执行 A/B 测试和测试考虑到总体被随机抽样并分配给 A 和 A 的效果大小推断B组。您只需对 B 组进行治疗，并且由于治疗暴露而导致的提升为 B。
听起来好得令人难以置信？我想是的。
假设您有一些具有 100 个随机化单元的总体。您随机选择 50 名作为治疗组。 “100选50”是 10^29 种可能的 A/B 分割；无论您获得哪一组，分割都是“随机”的。并且适合推理（我觉得非常可疑。）
一些变量是连续的，而另一些变量是分类的。对于分类变量，可以进行分层；例如，将 100 个随机化单位的总体划分为全男性和全女性的同质亚群体，随机分配给 A 或 B，然后聚合。 （A-男 &amp; A-女 -&gt; A。）
假设总人口中男性（或女性）的数量为偶数，则可以确保每个性别在 A 组和 A 组中的代表性均等。 B. 这确保了性别与治疗暴露正交，而不是混淆。如果男性的数量是奇数，你会接近正交（足够接近？我不确定。）事实上，在实验后回归模型中，人们可以以性别及其与治疗暴露的相互作用为条件来学习甚至更多 - 万岁！
这个过程可以对所有分类变量重复递归。但不明显的是连续变量的分层。我见过将此类变量分解为分位数（例如：0-10%，...，90-100%），然后处理这些基于分位数的子总体，然后执行与分类变量详细说明相同的过程。
无论如何，对我来说，随机化似乎并不是“这些人群尽可能相似”的可靠机制。因为这将是一个优化问题，而不是一个洗牌问题。
如果我们正在研究的任何指标存在任何不平衡，那么普通 T 检验就不合适。有一些方法可以适应实验前的均值差异，例如差异差异 (DiD)。但这种方法假设了平行趋势假设，这也不能通过洗牌来保证。
从哲学上讲，我认为随机化被过度炒作，因为替代优化问题的计算量太大。
如果有人能够为为什么 A/B 均值不平衡的随机化是可以接受的提供适当的辩护，我非常有兴趣了解更多信息。
编辑：哇这篇文章收到的赞成票和反对票的数量！甚至是近距离的请求……我没有预见到这个问题对于某些学术界来说会有多么两极分化/政治性。]]></description>
      <guid>https://stats.stackexchange.com/questions/637953/whats-the-magic-of-randomization</guid>
      <pubDate>Sun, 28 Jan 2024 17:01:57 GMT</pubDate>
    </item>
    <item>
      <title>如何分析每个参与者仅收到一半条件的重复测量设计？</title>
      <link>https://stats.stackexchange.com/questions/637951/how-to-analyze-a-repeated-measures-design-where-each-participant-receives-only-h</link>
      <description><![CDATA[我有一项研究的设计似乎跨越了受试者内和受试者间的设计。我怀疑有大量关于如何分析此类数据的文献，但我只是缺乏找到它的术语。
我的研究感兴趣的是人们对无家可归者的态度，特别是种族是否与无家可归者相互作用以增加耻辱感。为了研究这一点，参与者阅读了有关某人的小插曲，并进行了与耻辱相关的评级。我的自变量是插图中的角色是否有家（有家、无家可归）和种族（白人、黑人）。在一个完美的世界中，每个人都会收到所有四种结果条件（有家的白人、有家的黑人、无家可归的白人、无家可归的黑人）。但由于时间原因，每位参赛者只能领取两张。因此，每个参与者都会收到以下其中一项：
无家可归的黑 / 有家的白
无家可归的白 / 有家的黑
（两个小插图的顺序相互平衡，但这在这里并不重要）
这看起来像是 2 x 2 重复测量设计，因为每个参与者都会收到两个级别的无家可归和两个级别的种族，但事实并非如此，因为他们没有收到所有四个条件，而只有两个。
这在表面上听起来像分数阶乘设计（https://en.wikipedia.org/ wiki/Fractional_factorial_design；另请参阅混合因子两​​者”在主题之内和主题之间），但在我读过的示例中，设计的同一部分似乎属于特定类型（例如，设计的一部分完全是交叉，可以指定为内部或之间 - 就像一个变量在受试者内有两个级别和在受试者之间有一个级别）。
可能是我的思考方式错误，但简而言之，我正在寻求以下建议：
1.) 这是否是正确的分数设计？
2.) 如何使用类似于方差分析的方法来分析这些数据？
3.) 虽然我不限于 R，但我更喜欢使用它，因此对函数或包的建议表示赞赏。
另外，如果我只是简单地转身，这确实是非常基本的，知道这也会是最有帮助的！也乐于进行自导阅读。我只需要知道这叫什么！]]></description>
      <guid>https://stats.stackexchange.com/questions/637951/how-to-analyze-a-repeated-measures-design-where-each-participant-receives-only-h</guid>
      <pubDate>Sun, 28 Jan 2024 16:36:24 GMT</pubDate>
    </item>
    <item>
      <title>计数模型中女性作为回归量的百分比，以人口作为偏移量 - 解释？</title>
      <link>https://stats.stackexchange.com/questions/637932/percentage-of-females-as-a-regressor-in-count-model-with-population-as-offset</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637932/percentage-of-females-as-a-regressor-in-count-model-with-population-as-offset</guid>
      <pubDate>Sun, 28 Jan 2024 10:32:21 GMT</pubDate>
    </item>
    <item>
      <title>对于具有前测-后测和两个因素的序数因变量，应使用哪种检验？</title>
      <link>https://stats.stackexchange.com/questions/637923/which-test-should-be-used-for-an-ordinal-dependent-variable-with-pretest-posttes</link>
      <description><![CDATA[考虑一个测试前-测试后设计，其中因变量 (y) 通过 3 个序数值 1、2、3 进行测量。还有两个因素：一个因素（例如A）由对照组和实验组组成。另一个因素（例如B）由两个年龄组组成。总样本量为 60，其中因素 A 和 B 组的每种可能组合都有 15 个受试者（总共可能的组合为 4，因此 4*15=60） 。现在我们要测试以下情况：

A 对 y 的影响，
A 和 B 对 y 的影响。

如果y连续服从正态分布，我们可以使用协方差或ANCOVA分析（第一种情况使用单向ANCOVA，第二种情况使用双向ANCOVA）。但这里的 y 不是正规变量，也不能转换为正规变量，因为它只有 3 个序数值。那么您建议对这两种情况进行什么统计测试？
如果您能在 y 是二分变量的情况下回答这个问题，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/637923/which-test-should-be-used-for-an-ordinal-dependent-variable-with-pretest-posttes</guid>
      <pubDate>Sun, 28 Jan 2024 08:13:39 GMT</pubDate>
    </item>
    <item>
      <title>coxph 函数在我的模拟案例中给出了奇怪的风险比</title>
      <link>https://stats.stackexchange.com/questions/637910/coxph-function-gave-a-weird-hazard-ratio-in-my-simulation-case</link>
      <description><![CDATA[我适合三个 Cox 型号。三个风险比分别为 0.52、1.02 和 0.514。第一个风险比是治疗组和对照组之间的风险比。第二个是控制臂和外部控制臂之间的风险比。这里，1.02 表示控制臂比外部控制臂差。第三个风险比是将控制臂和外部控制臂集中在一起时的风险比。由于控制臂比外部控制臂更差，因此在我们将这两种治疗方法合并在一起后，第三个风险比应该大于第一个。然而，coxph函数却给出了违反直觉的答案。有谁知道原因吗？非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637910/coxph-function-gave-a-weird-hazard-ratio-in-my-simulation-case</guid>
      <pubDate>Sat, 27 Jan 2024 23:06:06 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器中的非线性 PCA 与编码器</title>
      <link>https://stats.stackexchange.com/questions/637889/nonlinear-pca-vs-encoder-in-autoencoders</link>
      <description><![CDATA[我发现编码器比 PCA 更有优势，因为它们可以转换线性和非线性数据。然而，非线性 PCA 不是为处理非线性数据而设计的吗？那么，为什么我们仍然倾向于使用编码器而不是非线性 PCA？]]></description>
      <guid>https://stats.stackexchange.com/questions/637889/nonlinear-pca-vs-encoder-in-autoencoders</guid>
      <pubDate>Sat, 27 Jan 2024 15:39:05 GMT</pubDate>
    </item>
    <item>
      <title>从 $P(x) \propto \cosh^{m}(a x) e^{-x^{2}/2}$ 采样</title>
      <link>https://stats.stackexchange.com/questions/637831/sampling-from-px-propto-coshma-x-e-x2-2</link>
      <description><![CDATA[是否有一种有效的算法从 PDF 中提取样本 $x \sim P(x)$：
$$
P(x) \propto \cosh^{m}(a x) e^{-x^{2}/2}
$$
其中 $a\ge0$ 是实数参数，$m$ 是正整数？ 
由于这是一个单变量 PDF，我的第一次尝试是计算 CDF 并使用逆 CDF 方法对其进行采样，但 CDF 和逆 CDF 似乎都没有易于处理的分析形式。]]></description>
      <guid>https://stats.stackexchange.com/questions/637831/sampling-from-px-propto-coshma-x-e-x2-2</guid>
      <pubDate>Fri, 26 Jan 2024 16:03:02 GMT</pubDate>
    </item>
    </channel>
</rss>