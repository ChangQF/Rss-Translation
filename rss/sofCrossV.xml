<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 29 Apr 2024 09:15:31 GMT</lastBuildDate>
    <item>
      <title>平均差异 置信区间 重复测量方差分析</title>
      <link>https://stats.stackexchange.com/questions/646074/mean-difference-confidence-interval-repeated-measures-anova</link>
      <description><![CDATA[我在相同条件下对每个受试者进行 4 次重复测量（T1、T2、T3 和 T4），以计算重复性。我有 10 个科目。
报告重复测量方差分析（如重复性值）的事后均值差异 95% 置信区间是否正确？
T1-T2：CI95 MD = -1.1 | 2.3
T1-T3：...
T1-T4：...
T2-T3：...
T2-T4：...
T3-T4：...
例如，在此数据中，我们将确定在 95% 的情况下，差异将在 -1.1 和 2.3 之间，并且与我们的最大不确定性为 2.3 相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/646074/mean-difference-confidence-interval-repeated-measures-anova</guid>
      <pubDate>Mon, 29 Apr 2024 08:35:48 GMT</pubDate>
    </item>
    <item>
      <title>仅将应用程序评论与平均值和样本量进行比较</title>
      <link>https://stats.stackexchange.com/questions/646072/comparing-app-reviews-with-only-mean-and-sample-size</link>
      <description><![CDATA[我正在开发一个项目，我的子问题之一是：
给定两个应用程序 $a$ 和 $b$，其中  $n_a, n_b$ 是他们的评分数， $r_a, r_b$ 分别是他们的平均评分，我需要确定哪一个可能是更好，如果其中一个实际上在统计上比另一个更好。
这里的评级是从 1 到 5 的整数。
我无法使用假设检验，因为我没有实际的分布，而且我认为假设正态分布没有意义，因为问题涉及应用评分。
我一直在考虑用 beta 发行版做一些事情，但我还不够了解它是否真的有效。
非常感谢任何提示或指示。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646072/comparing-app-reviews-with-only-mean-and-sample-size</guid>
      <pubDate>Mon, 29 Apr 2024 08:01:02 GMT</pubDate>
    </item>
    <item>
      <title>无需 p-hacking 即可品尝第二口数据苹果</title>
      <link>https://stats.stackexchange.com/questions/646071/having-a-second-bite-of-the-data-apple-without-p-hacking</link>
      <description><![CDATA[我的假设涉及随机对照试验中的干预与对照（受试者间，每组 n=500，在线调查实验）。我预先注册了我的主要测试将是一个回归模型，其中组作为感兴趣的变量，并且还包括协变量来解释方差和增加功效。我预先注册的测试没有检测到效果（也许模型一团糟，协变量太多），但简单的两个样本排列测试可以检测到效果（p&lt;0.05）。效应量很小（Cohen d 的自举 95% CI 为 0.07 至 0.33），但即使很小的效应也很有趣。我不能声称检测到，那将是 p-hacking - 我必须收集更多数据。
我的问题是，在收集第二个样本后，以任何方式将我的第一个样本纳入我的分析中是否合法。我可以再收集 500+500 个样本，但功率永远不会有利于这种效果。无法考虑第一个样本并直接回到绘图板，感觉非常保守。但在新的分析中过多地依赖第一个样本将是同一个苹果的第二口，也是不合适的。
在这种情况下是否有适当妥协的建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/646071/having-a-second-bite-of-the-data-apple-without-p-hacking</guid>
      <pubDate>Mon, 29 Apr 2024 07:30:19 GMT</pubDate>
    </item>
    <item>
      <title>对高维多重共线性数据进行建模</title>
      <link>https://stats.stackexchange.com/questions/646070/modeling-a-high-dimensional-multicollinear-data</link>
      <description><![CDATA[我试图根据 400 到 2400nm 的高光谱反射率数据来预测 y。到目前为止我已经做了以下工作

使用 y 上的 sqrt 进行倾斜校正
使用 MinMaxScaler 在 X 上进行缩放
RFECV 使用 PLSR 作为估计器选择至少 22 个特征。
偏斜校正后 y 的分布


我得到以下结果
true 与 pred 中的聚类是否意味着模型存在偏差？我应该如何解释残差图？可以采取哪些措施来改进模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/646070/modeling-a-high-dimensional-multicollinear-data</guid>
      <pubDate>Mon, 29 Apr 2024 07:03:11 GMT</pubDate>
    </item>
    <item>
      <title>Frisch-Waugh-Lowell 定理的特例</title>
      <link>https://stats.stackexchange.com/questions/646069/special-case-of-frisch-waugh-lowell-theorem</link>
      <description><![CDATA[该公式只是 FWL 的一个特例。假设我们有一个分区回归， $Y=X_1\beta_1+X_2\beta_2+\epsilon$ 但带有 $X_2$&lt; /span&gt; 是 $n\times 1$ 和 $\beta_2$ 常量。
通过回归 $b_1,b_2$ 成为 $\beta_1,\beta_2$ 的两个 OLS 估计量$X_1,X_2$ 上的 class=&quot;math-container&quot;&gt;$Y$。 $\tilde \beta_1$ 是在 $Y$ 上回归时的 ols 估计器仅container&quot;&gt;$X_1$，并且$\delta$是回归$X_2$时的估计器$X_1$ 上的 span&gt;。
我们想要显示 $\tilde\beta_1=b_1+\delta b_2$。
我认为这应该是FWL的推论，我可以使用$X_1,X_2,Y$的矩阵乘法写出这些系数的值，但是我不知道下一步该做什么。我应该尝试操纵矩阵吗？但我无法得到结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/646069/special-case-of-frisch-waugh-lowell-theorem</guid>
      <pubDate>Mon, 29 Apr 2024 05:16:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的神经网络不学习？我正在使用带有单个隐藏层的 numpy 实现简单的反向传播，以进行二元分类</title>
      <link>https://stats.stackexchange.com/questions/646068/why-isnt-my-neural-network-learning-i-am-implementing-simple-backpropagation-u</link>
      <description><![CDATA[这是我的神经网络的代码（data[i] 是填充二进制数据的向量，标签是二进制的）。经过大量的 epoch，所有数据的输出都趋向于 1（例如 0.99），无论是 0 还是 1。然而，与 0 标签相关的输出似乎更接近 0.97。我只是不知道为什么会发生这种情况。
 # 初始化
    n，输入大小=数据.形状
    总权重大小 = 输入大小*(输入大小+1)+(输入大小+1)
    边界 = 1/math.sqrt(input_size)
    权重 = np.random.uniform(-bound,bound,totalWeightSize)
    theta1 = 权重[:input_size * (input_size+1)].reshape(input_size, input_size+1)
    theta2 = 权重[输入大小 * (输入大小+1):]
    偏差 1, 偏差 2 = 1, 1
    对于范围 (10) 内的 j：
        print(&quot;纪元&quot; + str(j))
        delta1 = np.zeros_like(theta1)
        delta2 = np.zeros_like(theta2)
        对于范围内的 i(data.shape[0])：
            如果我％100==0：
                打印（一）
            # 前向道具
            yi = 标签[i]
            a1 = np.insert(数据[i], 0, 偏差1)
            z2 = θ1 @ a1
            gz2 = sigmoidFunc(z2)
            a2 = np.insert(gz2, 0, 偏差2)
            z3 = θ2 @ a2
            a3 = sigmoidFunc(z3)
            # 反向传播
            d3 = a3 - yi
            gpz2 = a2[1:] * (1 - a2[1:])
            d2 = (theta2[1:].T * d3) * gpz2

            delta1 += d2[:, 无] @ a1[无, :]
            delta2 += (d3 * a2)
        平均调节梯度 1 = (1/n)*delta1
        平均调节梯度2 = (1/n)*delta2
        theta1 -= AvgRegGrad1
        theta2 -= AvgRegGrad2
    返回（theta1，theta2）
]]></description>
      <guid>https://stats.stackexchange.com/questions/646068/why-isnt-my-neural-network-learning-i-am-implementing-simple-backpropagation-u</guid>
      <pubDate>Mon, 29 Apr 2024 05:05:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在生成潜变量分类器中进行预测（评估边际似然）？</title>
      <link>https://stats.stackexchange.com/questions/646067/how-to-do-prediction-evaluate-marginal-likelihood-in-generative-latent-variabl</link>
      <description><![CDATA[
数据集为 $\{\boldsymbol x_t,y_t\}$ for $t=1,\dots, T$，其中 $y_t \in \{0,1\}$。
定义一个生成潜变量分类器，其板图如上所示。
对于每个数据点，关联一个本地潜在 $z_t$，其先验由超参数 $\eta$&lt; /跨度&gt;。条件概率 $p(\boldsymbol x_t \mid z_t)$ 和 $p(y_t \mid z_t)$ 由固定模型参数 $\boldsymbol\theta$ 参数化。由于证据棘手，后验 $p(z_t \mid \boldsymbol x_t,y_t)$ 也很棘手。
使用变分 EM 拟合模型非常简单。困扰我很长时间的是如何对新数据进行预测，即求概率 $p(y \mid \boldsymbol x,\boldsymbol\theta, \eta)$ 。
由于 $p(y \mid \boldsymbol x,\boldsymbol\theta,\alpha) \propto p(y,\boldsymbol x \mid \boldsymbol\theta,\eta)$&lt; /span&gt;，我们只需要评估后一种形式，即证据。
然而，如上所述，证据很棘手：
$$
p(y,\boldsymbol x \mid \boldsymbol\theta,\eta) = \int p(z \mid \eta) p(y,\boldsymbol x \mid z,\boldsymbol\theta)\,\mathrm d z
$$
其中 $z$ 位于某个高维空间（有一些约束的欧几里得空间）。
我的尝试：

我尝试过天真的蒙特卡洛。我从 $p(z \mid \eta)$ 中采样，这很简单，并估计 $p( y,\boldsymbol x \mid z,\boldsymbol\theta)$。这当然失败了。
我尝试过重要性采样。重要性分布设置为 $q(z)$，其中 $q(z) \approx p(z \mid y,\boldsymbol x,\boldsymbol\theta,\eta)$ 通过变分推理（例如，平均场近似）找到。如果 $q(z)$ 与后验完全匹配，则方差应该为零。从 $q(z)$ 采样很容易。然后我找到平均值 $p(z \mid \eta)/q(z) p(y,\boldsymbol x \mid z,\boldsymbol\theta)$ 。令人惊讶的是，似乎采样 100k 次仍然无法对证据产生良好的估计，因为我无法有效地区分 $\log p(y=0,\boldsymbol x \mid \ boldsymbol\theta,\eta)$ 和 $\log p(y=1,\boldsymbol x \mid \boldsymbol\theta,\eta)$ .
我知道 Metropolis-Hastings 算法，该算法在高维中更容易使用 (墨菲，2012）。但我不知道如何将其应用于我的问题，因为从 $p(z \mid \eta)$ 采样已经是一个简单的问题。
我直接使用证据下界 (ELBO) 进行预测，但失败了，因为它偏差太大且区分度不够。

如果删除 $y_t$ 变量，我还发现这个问题有点与 VAE 中的边际似然估计相关。在 (Kingma &amp; Welling, 2014) 中，作者声称边际可能性只能在低维设置。
我的问题：是否有关于如何使用这种生成潜变量分类器进行预测的通用指南？我觉得这应该是一个简单的问题......或者也许我没有走在正确的轨道上 - 应该尝试一些除了找到做出预测的边际可能性之外的东西？
非常感谢您的帮助和建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/646067/how-to-do-prediction-evaluate-marginal-likelihood-in-generative-latent-variabl</guid>
      <pubDate>Mon, 29 Apr 2024 05:02:37 GMT</pubDate>
    </item>
    <item>
      <title>预测里程碑</title>
      <link>https://stats.stackexchange.com/questions/646066/predicting-milestones</link>
      <description><![CDATA[我有详细说明正在进行的特定项目以及它们何时实现某些里程碑的数据。我试图根据这些里程碑日期来预测项目的结束日期。日期的示例如下：
ID 里程碑 1 里程碑 2 里程碑 3 结束日期 1 08-10-2022 08-24-2022 09-25-2022 10-08-2022 2 09-15-2022 10-10-2022 10-25-2022 11 -04-2022 3 08-17-2022 9-10-2022 10-01-2022 10-26-2022 我还有其他可用的变量，例如项目的位置，但这些变量已被证明远没有那么强大。 
将这个模型付诸实践时遇到了困难。当预测正在进行的项目的结束日期时，他们可能尚未达到所有里程碑。为了模拟这一点，我找到了里程碑之间的平均持续时间，找到了实时数据中缺失里程碑的比例，然后人为地从我的建模数据中删除了该数量，并插入了之前非缺失里程碑日期的总和加上平均持续时间，为那些缺失的事件创建估算的里程碑日期。然后，我将所有这些日期转换为序数并创建了几个模型。
结果非常好，我在大约 12 天的 3 次交叉验证中获得了平均绝对误差。然而，当我在实时（而不是建模）数据上将其付诸实践时，我注意到绝大多数预测的结束日期都落后于我的里程碑 3，并且尽管这些项目正在进行中，但都落后于今天的日期。 
这让我意识到我的过程的天真......通过使用最大结束日期只能到今天的日期的建模数据，那么我对实时数据的预测可能不会超过这个，这就是模型的全部要点.
既然我已经意识到自己的错误，你们会建议我做什么呢？我考虑过使用里程碑之间的持续时间，但这可能最终只是发生的最后一个里程碑日期，加上到结束日期的平均持续时间。这在我的测试中并没有产生显着的结果，这就是我所希望实现的一切吗？任何替代方法将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/646066/predicting-milestones</guid>
      <pubDate>Mon, 29 Apr 2024 03:50:54 GMT</pubDate>
    </item>
    <item>
      <title>Newey-West HAC 协方差估计量中的权重如何使其成为正半定？</title>
      <link>https://stats.stackexchange.com/questions/646065/how-does-the-weighting-in-newey-west-hac-covariance-estimator-make-it-positive-s</link>
      <description><![CDATA[我了解到 Newey-West 协方差估计器的一个重要动机是协方差矩阵的朴素估计器不一定是正半定的（从现在起 psd）（请参阅下面的参考链接，其中最后一个链接是论文链接Newey-West 1987 年论文中提出了 HAC 协方差估计器）。
https://en.wikipedia.org/wiki/Newey%E2%80% 93West_estimator
https://www.econometrics-with-r .org/15.4-hac-standard-errors.html
https://www.jstor.org/stable/1913610
下面是介绍朴素估计器的论文中的段落，不一定是 psd：

以下段落是 newey-west HAC 估计器：

比较这两个公式，我们可以看到 newey-west HAC 估计器只是在原始估计器上添加了权重 $w(j,m)$ 。因此，这种权重似乎是制作新估计器 $\widehat{S}_T$ psd 的关键。但这里有两件事让我困惑，一是在突出显示的部分，作者声称 $\widehat{S}_T$ 的 psd 遵循样本自协方差的 psd $\widehat{\Omega}_j$ （而不是权重）。由于样本自协方差 $\widehat{\Omega}_j$ 已经存在于等式（4）中的朴素估计器中，它怎么可能不能保证朴素估计器 $\widetilde{S}_T$ 但只能保证新估计器 $\widehat{S}_T 的 psd $？第二件让我困惑的事情是，通常我们可以通过某种对称化来制作矩阵 psd，即 $A$ 变成 $ A&#39;A$，直观上我看不出求和中的加权如何生成非 psd 矩阵 psd？对底层机制的一些直观解释，或者对其证明的一些直观解释会很棒！]]></description>
      <guid>https://stats.stackexchange.com/questions/646065/how-does-the-weighting-in-newey-west-hac-covariance-estimator-make-it-positive-s</guid>
      <pubDate>Mon, 29 Apr 2024 03:45:14 GMT</pubDate>
    </item>
    <item>
      <title>证明 Wald 统计量 = 线性限制数乘以 F 统计量</title>
      <link>https://stats.stackexchange.com/questions/646062/prove-wald-statistic-number-of-linear-restrictions-times-f-statistics</link>
      <description><![CDATA[我正在考虑 $F[J,n-k]= \displaystyle \frac{(e_{*}^{&#39;}e_{*}-e&#39;e) \backslash J}{e&#39;e\backslash (n-k)}$，其中 $J$ 代表限制数量。我想证明 $W=(Rb-q)&#39;(Rs^2(X&#39;X)^{-1}R&#39;)^{-1}(Rb-q) =JF$，其中 $s^2=\displaystyle{\frac{e&#39;e}{n-k}}$。因此足以显示 $(e_{*}^{&#39;}e_{*}-e&#39;e)$ 是 $(Rb-q)&#39;(R(X&#39;X)^{-1}R&#39;)^{-1}(Rb-q)$,$ R$代表限制。
在格林的教科书中，他陈述了这一点，但我不知道如何得出它。
在一个可能更简单的特定示例中，考虑分区线性回归模型 $Y=X_1\beta_1+X_2\beta_2+\epsilon$ 和 $H_0$:$\beta_2=0$，所以 $Rb-q =b_2$，它是 $\beta_2$ 的 OLS 估计器。$\beta_1$是 $k_1\times 1$ 且 $\beta_2$ 是 $k_2\times 1$ 所以 $J$ 应该是 $k_2$。我们想要 $k_2F=W$。但即使在这个例子中我也不知道如何导出它。
您能否先给出示例中的证明，然后再给出一般情况下的证明？]]></description>
      <guid>https://stats.stackexchange.com/questions/646062/prove-wald-statistic-number-of-linear-restrictions-times-f-statistics</guid>
      <pubDate>Mon, 29 Apr 2024 02:50:22 GMT</pubDate>
    </item>
    <item>
      <title>假设检验问题中的渐近分布和描述增加功效的来源</title>
      <link>https://stats.stackexchange.com/questions/646061/asymptotic-distribution-and-describe-sources-of-increasing-power-in-an-hypothesi</link>
      <description><![CDATA[我目前在过去的考试中遇到以下问题（没有解决方案）：
&lt;块引用&gt;
假设 $S$ 服从泊松分布，平均值为 $2\lambda&gt;0$，这里 &lt; span class=&quot;math-container&quot;&gt;$\lambda$ 是一个参数。另外两个随机变量 $X,Y$ 是条件独立的伯努利随机变量，给定 $S=s$，并具有以下分布
$$P(X=1|S=s)=2^{-1-s},\,P(Y=1|S=s)=2^{-s }\theta.$$
这里 $\theta\in(0,1)$ 是第二个参数，$S$ 是不可观察的。假设我们观察到 $n$ i.i.d.复制 $(X_i,Y_i)$ 的 $(X,Y)$。

&lt;块引用&gt;
(1) 求 $\hat{\theta}_n:=\frac{\bar{Y}_n}{2\bar{X}_n} 的渐近分布$，其中 $\bar{X}_n,\bar{Y}_n$ 是  的平均值$X_i,Y_i$。

我认为我们可以使用多元中心极限定理来解决这个问题。很清楚
$$E(X)=E(E(X|S))=E(2^{-S-1})=\frac{1}{2}\sum_{ s\geq0}e^{-2\lambda}\frac{(2\lambda)^s}{s!}2^{-s}=\frac{1}{2}e^{-\lambda}。 $$
类似地 $E(Y)=E(E(Y|S))=\theta e^{-\lambda}.$ 请注意
$$E(XY)=E(E(XY|S))=E(E(X|S)E(Y|S))=\frac{\theta}{ 2}E(2^{-2S})=\frac{\theta}{2}e^{-\frac{3}{2}\lambda}.$$
所以 $Cov(X,Y)=\frac{\theta}{2}(e^{-\frac{3}{2}\lambda}-e^{-2 \lambda}).$ 方差由下式给出
$$Var(X)=E(E(X^2|S))-E(X)^2=E(E(X|S))-E(X) ^2=E(X)-E(X)^2=\frac{1}{2}e^{-\lambda}-\frac{1}{4}e^{-2\lambda}.$$ 
$$Var(Y)=E(E(Y^2|S))-E(Y)^2=E(E(Y|S))-E(Y) ^2=E(Y)-E(Y)^2=\theta e^{-\lambda}-\theta^2 e^{-2\lambda}.$$
所以根据中心极限定理，我们知道
$$\sqrt{n}((\bar{X}_n,\bar{Y}_n)-(EX,EY))\to N((0,0), \begin{bmatrix}Var(X)&amp;Cov(X,Y)\\Cov(X,Y)&amp;Var(Y)\end{bmatrix}).$$
从连续性映射定理我们可以推导出渐近分布，但我不知道如何计算它。
&lt;块引用&gt;
(2) 考虑测试 $H_0:\theta=0.5$ 与$H_1:\theta\neq0.5$。构建精确的检验统计量。描述随着 $\theta$ 远离 $0.5$ 增加力量的来源。

现在这是我的问题：
(a) 我在第一个问题中做的事情正确吗？如果是，那么渐近分布是什么？
(b) 对于 (2) 我不知道如何构建精确的检验统计量（也许我可以使用 $\hat{\theta}_n$在（a）中构建？但渐近分布对我来说不清楚。），而且我不知道如何总结功率增加的来源。你能给我一些提示或指导吗？
任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/646061/asymptotic-distribution-and-describe-sources-of-increasing-power-in-an-hypothesi</guid>
      <pubDate>Mon, 29 Apr 2024 02:29:58 GMT</pubDate>
    </item>
    <item>
      <title>通过通用神经网络解释时间序列谱熵值的可预测性</title>
      <link>https://stats.stackexchange.com/questions/646053/interpretation-of-time-series-spectral-entropy-values-wrt-forecastability-by-a-g</link>
      <description><![CDATA[我最近开始使用谱熵来分析时间序列（已经加窗）。我很难解释结果，系列最后 25% 的熵是 0.19，整个系列的熵是 0.23，这有意义吗？例如，神经网络拥有的数据越多，预测不是越好吗？主要考虑到最后25%的数据并不包含完整的分布，例如测试数据与训练数据的分布不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/646053/interpretation-of-time-series-spectral-entropy-values-wrt-forecastability-by-a-g</guid>
      <pubDate>Sun, 28 Apr 2024 22:52:40 GMT</pubDate>
    </item>
    <item>
      <title>如何利用 MCMC 采样中的可分离函数？</title>
      <link>https://stats.stackexchange.com/questions/646051/how-to-leverage-the-separable-functions-in-mcmc-sampling</link>
      <description><![CDATA[我正在通过贝叶斯方法考虑参数模型的后验。更具体地说，我有一个参数模型 $u(p_1,p_2, p_3) = u_1(p_1) \times u_2(p_2) \times u_3(p_3)$ 和我想研究给定一些数据 $\mathbf{p}= \{p_1, p_2, p_3\}$ 的后验分布 $\mathcal {D}$。因此贝叶斯公式返回：
$$p(\mathbf{p}|D) = \frac{p(D|\mathbf{p})\times p(\mathbf{p})} {\text{证据}}.$$
假设我之前的 $p(\mathbf{p})$ 可以写成 $p(p_1) \ times p(p_2) \times p(p_3)$，我的似然函数是以模型输出为中心的高斯函数：$$p(D|\mathbf{ p}) = \mathcal{N}(u(\mathbf{p},\sigma^2)$$
是否有有效的采样技术来利用张量积结构
$$u(p_1,p_2, p_3) = u_1(p_1) \times u_2(p_2) \times u_3(p_3)$$]]></description>
      <guid>https://stats.stackexchange.com/questions/646051/how-to-leverage-the-separable-functions-in-mcmc-sampling</guid>
      <pubDate>Sun, 28 Apr 2024 21:55:24 GMT</pubDate>
    </item>
    <item>
      <title>通过未知参数的依赖？</title>
      <link>https://stats.stackexchange.com/questions/646033/dependence-through-an-unknown-parameter</link>
      <description><![CDATA[考虑一个我们可以进行替换采样的瓮。让 $\pi$ 表示瓮中黑色球的比例，其余为白色。
从频率论的角度来看，每个观察值都被视为独立同分布（IID）变量。然而，在贝叶斯的视角下，这些观察结果是否仍然保持其独立性？似乎每次抽奖都会更新我们对 $\pi$ 的估计，可能会影响下一次抽奖为黑色的概率。
有人可以澄清我可能误解的地方吗？
编辑 - 具体示例：
让我们假设一个非常简单的先验。瓮完全黑色的概率为 $q$ ($\pi=1$)，并且$1-q$ 它是完全白色的 ($\pi=0$)。
我们画第一个球，它是黑色的。因此，第二个球也必须是黑色的：$p(x_2=black\mid x_1=black)=1$。这与边际概率 $p(x_2=black)=p(x_1=black)=q$ 形成对比。
相同的逻辑适用于任何先验（不一定是二分法）。如果参数被视为随机变量，它不会自动呈现依赖的观察结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646033/dependence-through-an-unknown-parameter</guid>
      <pubDate>Sun, 28 Apr 2024 15:22:38 GMT</pubDate>
    </item>
    <item>
      <title>lmList如何计算AIC？</title>
      <link>https://stats.stackexchange.com/questions/646016/how-does-lmlist-calculate-aic</link>
      <description><![CDATA[我使用 lme4 R 包中的 lmList 函数来拟合以下模型：
mod.list &lt;- lmList(记录 ~ log(LL)*site |species, data = dat, family=binomial)

我的理解是 lmList 适合每个物种的单独模型，如下所示：
mod.single &lt;- glm(记录 ~ log(LL)*site, data = dat, family=binomial)

我希望使用 AIC 作为统计推断模型列表。
lmList 是如何计算 AIC 的？它与列表中每个型号的 AIC 有何关系？
有点类似于方差分析和事后成对比较，似乎一些单一模型可以对 lmList AIC 做出最大贡献。]]></description>
      <guid>https://stats.stackexchange.com/questions/646016/how-does-lmlist-calculate-aic</guid>
      <pubDate>Sun, 28 Apr 2024 10:52:12 GMT</pubDate>
    </item>
    </channel>
</rss>