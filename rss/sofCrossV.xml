<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 27 Jan 2025 15:15:56 GMT</lastBuildDate>
    <item>
      <title>具有不同链接函数的逆高斯混合效应模型中的 ICC 问题</title>
      <link>https://stats.stackexchange.com/questions/660615/issue-with-icc-in-inverse-gaussian-mixed-effects-models-with-different-link-func</link>
      <description><![CDATA[我正在开展一项使用混合效应模型分析反应时间的研究，在使用逆高斯族对我的数据进行建模时，我遇到了类内相关系数 (ICC) 的问题。我希望您的见解能更好地理解和解决这个问题。
背景
我的因变量是反应时间，它是正偏的。
我正在使用混合效应模型，对参与者 (id) 进行随机截距，对两个预测因子进行固定效应：种族和身份。
我的模型是使用 R 中的 lme4 包构建的。
以下是我测试过的模型：
带身份链接的逆高斯：
model1_rt_invGauss_identity &lt;- glmer(Reaction_time ~ Ethnicity + Identity + (1 | id),
data = data_clean,
family = inverse.gaussian(link = &quot;identity&quot;),
control = glmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5)))


ICC：调整后的 ICC = 1，未调整的 ICC = 0.811。
固定效应：系数很简单，对我来说很有意义（例如，表示反应时间的变化（以毫秒为单位）。
随机效应：残差方差非常小 (8.25e-03)，而随机截距的方差则大得多 (40.12)。

带对数链接的逆高斯：
model1_rt_invGauss_log &lt;- glmer(Reaction_time ~ Ethnicity +identity + (1 | id),
data = data_clean,
family = inverse.gaussian(link = &quot;log&quot;),
control = glmerControl(optimizer = &quot;bobyqa&quot;,optCtrl = list(maxfun = 2e5)))


ICC：调整后的 ICC = 0.420，未调整的 ICC = 0.384。
固定效应：由于系数采用对数刻度，因此更难解释。指数化后，它们表示比例变化（例如百分比），但这不如恒等链接直观。
随机效应：残差方差和随机截距方差都更加平衡。

与 lmer（高斯家族）的比较：
使用 lmer 和原始或对数转换的反应时间不会产生 ICC = 1 问题，这表明该问题特定于逆高斯家族。
问题
使用逆高斯家族时，ICC 会根据链接函数发生巨大变化：
对于恒等链接，ICC 为 1，因为残差方差几乎为零。
对于对数链接，ICC 更合理（例如 0.42）。
此外，系数的可解释性各不相同：
身份链接以原始反应时间单位提供直观、附加的解释。
对数链接稳定方差并避免 ICC = 1，但系数变为乘法且更难直接解释。
我尝试过的
诊断：
检查了两个模型的残差和方差分量。
身份链接中的残差方差始终接近零，导致 ICC 膨胀。
模型比较：
比较使用 AIC 和 BIC 的模型，对数链接始终表现更好。
替代分布：
使用高斯分布 (lmer) 避免了 ICC 问题，但没有考虑反应时间的偏斜。
我的问题
为什么逆高斯族中的链接函数选择会极大地影响 ICC？
这是由于逆高斯模型的方差假设，还是与我的特定数据结构有关（例如，参与者内高度一致的反应时间）？
对于反应时间数据，我应该优先考虑哪种链接函数？
身份链接提供直观的系数，但会增加 ICC。
对数链接解决了 ICC 问题，但使解释变得复杂。
是否有其他检查或替代方法可以尝试平衡 ICC 和可解释性？
修改随机效应结构或使用不同的优化器是否有助于稳定身份链接模型中的残差方差？
提前感谢您的见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/660615/issue-with-icc-in-inverse-gaussian-mixed-effects-models-with-different-link-func</guid>
      <pubDate>Mon, 27 Jan 2025 14:23:36 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助实施针对二元分类严重类别不平衡的建议解决方案</title>
      <link>https://stats.stackexchange.com/questions/660613/need-help-implementing-a-suggested-solution-to-severe-class-imbalance-w-binary</link>
      <description><![CDATA[信息：
二元分类问题。少数类在整个数据集中的频率为 1.16%。我的数据集中有 30 万个观测值。我有分类和数字特征的混合。我发现只有两个特征具有高度预测性（基于在不同特征集上使用随机森林多次运行排列重要性）。
我尝试过的事情：

XGBoost：


scale_pos_weight 调整
max_delta_step 调整


随机森林：


class_weight 调整

问题：
帖子中的发帖人 skillsmuggler https://stackoverflow.com/questions/59409967/proper-way-to-handle-highly-imbalanced-data-binary-classification 建议使用平衡折叠的交叉验证。我搞不清楚他到底在建议什么。从他的帖子和他分享的图片来看，他似乎建议在每一折叠中：从同一少数类（100%？）中抽取样本，并从多数类中随机抽取样本，匹配少数类观察值的 2 倍。
如果我这样做，对于在其测试的观察值上进行训练的模型，难道不会出现疯狂的目标泄漏吗？假设我将其分成 10 个折，使用 9 个进行训练，1 个进行验证，则验证的折将具有与模型训练的折相同的观察结果，不是吗？
如果我将其分成更小的折，例如 10% 的少数类观察结果和 2 倍数量的多数类观察结果，我觉得我会丢失太多信息（一开始只有 3500 个少数类观察结果）。
然后，在分成这些折之后，无论期望的结果是什么，假设我的得分很高。目标是在整个数据集上执行该采样方案并以此方式训练最终模型吗？因为 CV 只是为了测试正在测试的任何策略的稳健性……除非他说要进行模型集成……这可能是一个好主意。
我打算尝试许多重新采样方案。我将尝试 SMOTE 变体，通过对少数群体进行重新采样来获得 50/50 的分割，尝试随机欠采样和随机过采样。如果我还应该尝试其他方法，请告诉我！
无论如何……希望对此问题有所帮助！非常感谢，如果我还能提供其他帮助，请告诉我！]]></description>
      <guid>https://stats.stackexchange.com/questions/660613/need-help-implementing-a-suggested-solution-to-severe-class-imbalance-w-binary</guid>
      <pubDate>Mon, 27 Jan 2025 14:14:57 GMT</pubDate>
    </item>
    <item>
      <title>单细胞数据中同时进行差异基因表达检测</title>
      <link>https://stats.stackexchange.com/questions/660612/simultaneous-differential-gene-expression-testing-in-single-cell-data</link>
      <description><![CDATA[我正在研究单细胞数据，想寻找对照组和测试组之间的差异基因表达。我不想单独测试多个基因，而是想看看两个或三个基因是否在同一细胞中存在差异表达。
例如，在测试组中，同一细胞中是否存在基因 A 增加而基因 B 减少的影响？
我希望这可以提高我的统计能力，因为单个基因的效应大小很小。
我想到的一种方法就是计算每个样本的基因表达差异与对照群体的平均值，并将其标准化为对照群体中基因表达的标准差。然后，我将计算我感兴趣的基因之间的平均差异，并运行 wilcoxon 检验来比较对照群体和测试群体。 （差异将被加权，这样如果我测试基因 A 上调而基因 B 下调，基因 A 的正差异将保持为正，但基因 B 的反差异将适用（因为在这种情况下我特别关注下调）。）
然而，这种加权意味着我基本上是在进行两次单侧威尔科克森检验。有没有更好的方法来解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/660612/simultaneous-differential-gene-expression-testing-in-single-cell-data</guid>
      <pubDate>Mon, 27 Jan 2025 14:06:56 GMT</pubDate>
    </item>
    <item>
      <title>$\ell_1$ 惩罚分位数回归的收敛速度为 $\sqrt{\frac{s\log (p \vee n)}{n}}$</title>
      <link>https://stats.stackexchange.com/questions/660611/rate-of-convergence-of-ell-1-penalized-quantile-regression-is-sqrt-fracs</link>
      <description><![CDATA[在标准 LASSO 文献中，您经常会遇到 LASSO 估计量以 $\sqrt{\frac{s\log p}{n}}$ 的速率收敛（例如，参见此帖子）。
一种相关方法是 $\ell_1$ 惩罚分位数回归，这意味着您将 $\ell_1$ 惩罚（如在 Lasso 中）添加到分位数回归损失。这样，你就可以估算给定$X$的$Y$的条件分位数，同时将一些系数缩小为零以用于变量选择或正则化目的。设置如下：
$$
\hat{\beta} = \arg \min_{\beta} \sum_{i=1}^n \rho_\tau (y_i - x_i^\top \beta) + \lambda \|\beta\|_1,
$$
其中

$\rho_\tau(u) = u(\tau - \mathbb{I}\{u &lt; 0\})$ 是分位数损失，调整残差的权重，
$\lambda$ 控制惩罚强度，
$\|\beta\|_1 = \sum_{j=1}^p |\beta_j|$ 是鼓励稀疏性的 $\ell_1$-惩罚。

此方法理论的主要参考文献是 Belloni 和 Chernozhukov (2011) 在《统计年鉴》中的文章。
在他们的论文中（例如，请参阅摘要、第 2.6 节或定理 2 了解完整结果），他们提到估计量的收敛速度为 $\sqrt{\frac{s\log (p \vee n)}{n}}$，其中 $\vee$ 用于表示 $p$ 和 $n$ 中的最大值。
因此，与标准 LASSO 速率相比，我们现在可以看到对数中有 $p \vee n$。对于许多有趣的制度，即 $p &gt;&gt; n$，这将提供与标准 LASSO 相同的速率。
有人知道为什么现在 $p$ 和 $n$ 存在最大值吗？任何见解都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660611/rate-of-convergence-of-ell-1-penalized-quantile-regression-is-sqrt-fracs</guid>
      <pubDate>Mon, 27 Jan 2025 14:01:25 GMT</pubDate>
    </item>
    <item>
      <title>均匀分布变量在 $\left\{(u, v); 0 \leq u \leq \sqrt{\tilde{\pi}(v/u)} \right\}$ 中的比率服从分布 $\pi$</title>
      <link>https://stats.stackexchange.com/questions/660610/ratio-of-a-uniforms-distributions-variables-in-left-u-v-0-leq-u-leq-s</link>
      <description><![CDATA[问题：设$\pi = \tilde{\pi}/Z_\pi$为$\mathbb{R}$上的任意概率密度函数。证明如果$(U, V)$在$G = \left\{ (u, v)}上均匀分布； 0 \leq u \leq \sqrt{\tilde{\pi}(v/u)} \right\}$，则$V/U$服从$\pi$分布，即承认$\pi$为概率密度函数。
我的尝试：若$(U, V)$在G上均匀分布，则联合概率密度函数$f_{U, V} (u, v)$为
$$
f_{U, V} (u, v) = \frac{1}{\mathtt{Area}(G)}。
$$
我们可以集中精力于 $X = V/U$ 和 $U = u$。然后 $V = Xu$。变换的雅可比行列式为：
$$
J = \begin{Vmatrix}
1 &amp; 0 \\
x &amp; u
\end{Vmatrix} = u。
$$
因此，x 和 u 的联合密度为：
$$
f_{U, X}(u, x) = f_{U, V}(u, ux) \cdot |u|。
$$
那么，我最后的结论是
\begin{align}
f_X(x) &amp;= \int_0^{\sqrt{\tilde{\pi}}} f_{U, V} (u, xu) u du \\
&amp;= \frac{1}{\mathtt{Area}(G)} \int_0^{\sqrt{\tilde{\pi}}} u du = \frac{1}{\mathtt{Area}(G)} \frac{\tilde{\pi}(x)}{2}。
\end{align
我理解归一化常数的作用是使积分为 1，但我不知道如何将归一化常数转换为最后一个方程（假设其他计算有意义）。
编辑：
我可以只“设置”$Z_\pi := 2 \cdot\mathtt{Area}(G)$吗？（如果这在某种程度上有意义的话。）]]></description>
      <guid>https://stats.stackexchange.com/questions/660610/ratio-of-a-uniforms-distributions-variables-in-left-u-v-0-leq-u-leq-s</guid>
      <pubDate>Mon, 27 Jan 2025 14:00:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在模型训练中根据一致性与准确性选择正则化超参数？</title>
      <link>https://stats.stackexchange.com/questions/660609/how-to-choose-regularization-hyperparameters-based-on-consistency-vs-accuracy-i</link>
      <description><![CDATA[我正在训练一个机器学习模型，并优化正则化超参数以确保模型具有良好的泛化能力。在训练期间，我在损失函数中加入正则化项来控制过度拟合。训练结束后，我通过计算训练数据集和测试数据集上不带正则化项的损失来评估模型的性能。这是因为，在这个阶段，模型是固定的，我只关心它在训练和看不见的测试数据上的表现如何。
挑战如下：
我经常遇到以下情况（为简单起见，假设训练和测试的比例为 50-50）：
情况 1：训练损失很低，但测试损失要高得多（例如，训练损失 = 50，测试损失 = 100）。
情况 2：训练和测试损失更接近且更一致，但总体上更高（例如，训练损失 = 80，测试损失 = 90）。
情况 3：两个损失甚至更高但仍然一致（例如，训练损失 = 120，测试损失 = 122）。
我理解普遍性（训练和测试之间的一致性）性能）通常比绝对准确度更重要，尤其是对于训练嵌入（例如 NLP 中的矩阵分解）等任务。但是，我很难决定以下问题：
我是否应该始终优先考虑一致性（例如案例 2 或 3）而不是准确性（例如案例 1）？
如何决定何时可以接受更高、一致的损失（例如案例 3），而不是即使训练和测试损失不同也要以低测试损失为目标？
我正在寻找一种算法或理论方法来决定哪组正则化超参数最合适。注意：我所说的“超参数”仅指正则化术语中使用的超参数，而不是与模型架构或其他组件相关的超参数。此外，我只处理两个数据分割：训练和测试。
任何关于如何处理这种权衡的指导都将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660609/how-to-choose-regularization-hyperparameters-based-on-consistency-vs-accuracy-i</guid>
      <pubDate>Mon, 27 Jan 2025 14:00:43 GMT</pubDate>
    </item>
    <item>
      <title>关于优化高斯混合模型的建议</title>
      <link>https://stats.stackexchange.com/questions/660608/advice-on-optimising-gaussian-mixture-model</link>
      <description><![CDATA[我有一个显然是双峰的数据分布，但我似乎无法应用高斯混合模型来估计两个正态分布。两个估计分布的均值似乎一直默认为 0 处的窄分布，而我希望均值为 ~0 和 0.3。
我是否误解了什么？您对如何优化设置以检测这两个分布有什么建议吗？供参考，我正在使用 MATLAB。]]></description>
      <guid>https://stats.stackexchange.com/questions/660608/advice-on-optimising-gaussian-mixture-model</guid>
      <pubDate>Mon, 27 Jan 2025 13:46:00 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中的 LongituRF 包中使用带有 MERT 的分层样本时出错</title>
      <link>https://stats.stackexchange.com/questions/660606/error-when-using-stratified-samples-with-mert-in-longiturf-package-in-r</link>
      <description><![CDATA[我正在使用 R 中的 LongituRF 包来将 MERT（混合效应回归树）模型拟合到我的数据。虽然我使用随机训练/测试分割来拟合模型没有问题，但当我尝试使用基于 id_class 的分层样本来拟合模型时，我收到错误。
这是我生成分层训练和测试集的过程：

library(LongituRF)
library(caret)
library(rpart.plot)

# 创建数据
n_classes &lt;- 30
n_pupils &lt;- 30

# 为 MERT 模型模拟一些多级数据
ds &lt;- data.frame(
x1 = rnorm(n_classes * n_pupils, 0, 1),
z1 = rep(rnorm(n_classes, 0, 1), each = n_pupils),
y = NA,
id_class = rep(1:n_classes, each = n_pupils),
id = rep(1:(n_classes * n_pupils))
)

# 定义结果
ds$y &lt;- 1 + 2*ds$x1 + 3*ds$z1 + rnorm(n_classes * n_pupils, 0, 1)

# 使用插入符号创建分层折叠
folds &lt;- caret::groupKFold(ds$id_class, k = 2)

fold_1_training &lt;- ds[folds[[1]], ]

fold_1_testing &lt;- ds[-folds[[1]], ]

# 拟合 MERT 模型
X &lt;- as.matrix(fold_1_training[,c(&quot;x1&quot;, &quot;z1&quot;)])
Y &lt;- as.vector(fold_1_training$y)
id &lt;- as.vector(fold_1_training$id_class)
Z &lt;- as.matrix(rep(1, nrow(fold_1_training)))
time &lt;- as.vector(rep(1, nrow(fold_1_training)))

mymert &lt;- LongituRF::MERT(X, Y, id, Z, iter = 100, time, sto = &quot;none&quot;, delta = 0.001)

rpart.plot(mymert$forest)


拟合 MERT 模型后，我准备测试数据如下：
# 准备测试数据
X_test &lt;- as.matrix(fold_1_testing[,c(&quot;x1&quot;, &quot;z1&quot;)])
id_test &lt;- as.vector(fold_1_testing$id_class)
Z_test &lt;- as.matrix(rep(1,nrow(fold_1_testing)))
time_test &lt;- as.vector(rep(1, nrow(fold_1_testing)))

预测 &lt;- predict(mymert, X = data.frame(X_test), Z = Z_test, id = id_test, time = time_test)


Ypred[w] 中的错误 &lt;- f[w] + Z[w, , drop = FALSE] %*% object$random_effects[k, : replacement 的长度零

我已验证我的训练和测试集格式正确，并且模型在随机训练/测试分割中拟合无问题。但是，当我切换到分层抽样时，会出现此错误。
我是否在分层或准备 MERT 时遗漏了某个步骤，从而导致此错误？我该如何解决这个问题，以便我可以使用模型对分层测试数据进行预测？
我不确定这是编码问题还是方法问题。
软件包信息和MERT 信息]]></description>
      <guid>https://stats.stackexchange.com/questions/660606/error-when-using-stratified-samples-with-mert-in-longiturf-package-in-r</guid>
      <pubDate>Mon, 27 Jan 2025 13:39:33 GMT</pubDate>
    </item>
    <item>
      <title>假设，当采用 GEE 方法对聚类二元响应进行处理时，类内相关性是皮尔逊相关性</title>
      <link>https://stats.stackexchange.com/questions/660605/assumption-that-the-intra-class-correlation-is-pearsons-correlation-while-empl</link>
      <description><![CDATA[我正在审阅论文“具有相关观测的研究的样本量计算” https://www.jstor.org/stable/2533554?seq=1
作者使用了一般估计方程，并提出了一个考虑了簇内相关性的检验统计量，并基于这个检验统计量，提出了不同情况下的样本量（簇数）计算公式，以实现一些预定义的功效。
现在在二元响应的两个样本问题中，他们假设同一簇中任何两个观测值之间的相关性是由某个 \rho 给出的皮尔逊相关性，然后该簇的相关结构 R 被视为由 \rho 索引的可交换相关矩阵。
假设两个二元响应之间的相关性是皮尔逊相关性是否有效？]]></description>
      <guid>https://stats.stackexchange.com/questions/660605/assumption-that-the-intra-class-correlation-is-pearsons-correlation-while-empl</guid>
      <pubDate>Mon, 27 Jan 2025 13:23:10 GMT</pubDate>
    </item>
    <item>
      <title>哪个更好 - AIC 还是 ANOVA？</title>
      <link>https://stats.stackexchange.com/questions/660603/which-is-better-aic-or-anova</link>
      <description><![CDATA[我正在比较三种不同的嵌套线性回归模型。基于 ANOVA f 统计量，最简单的模型是最好的。但是，这些模型的 AIC 非常相似，在 +_3 以内。根据 AIC，第三个模型是最好的。最好使用 ANOVA 或 AIC。
此外，在查看诊断图时，第二个模型看起来更好。我知道这不是用来确定最佳拟合模型的，但我认为最好尽量减少方差。
所以我有点不知道如何决定哪个模型最好。提前谢谢！
编辑：
]]></description>
      <guid>https://stats.stackexchange.com/questions/660603/which-is-better-aic-or-anova</guid>
      <pubDate>Mon, 27 Jan 2025 12:49:29 GMT</pubDate>
    </item>
    <item>
      <title>竞争风险一致性指数为100%</title>
      <link>https://stats.stackexchange.com/questions/660602/concordance-index-for-competing-risks-is-100</link>
      <description><![CDATA[我正在外部验证一个预测癌症死亡的预后模型，并试图计算一致性指数 (C)。我有预测（风险概率）和观察到的时间和事件。有 130 个审查事件、44 个感兴趣的事件（死亡）和 1 个（是的，只有一个！）竞争风险事件（移民）。如果我计算考虑竞争风险（只有一个事件！）的 C 指数，那么 C 指数将达到 100%（仅供参考，我使用了 R 包中同名的 timeROC() 函数）。这似乎高得令人难以置信，所以我通过审查移民的竞争风险重新计算了 C 指数，然后 C 指数为 70%，这似乎更合理（为此，我使用了 R 中生存包中的 concordance() 函数）。
我希望得到一些关于如何最好地进行的指导。在这种情况下，我倾向于采用后一种方法（即审查移民），即使从技术上讲这是一种竞争风险情况。我怀疑问题在于竞争风险的发生率低？竞争风险事件的数量是否有一定的最低限度，需要合理计算 C 指数，正确考虑竞争风险？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660602/concordance-index-for-competing-risks-is-100</guid>
      <pubDate>Mon, 27 Jan 2025 12:45:44 GMT</pubDate>
    </item>
    <item>
      <title>类别不平衡的小型生物医学数据集的分类策略</title>
      <link>https://stats.stackexchange.com/questions/660600/classification-strategies-for-small-biomedical-dataset-with-imbalanced-classes</link>
      <description><![CDATA[我有从 10 只不同的猪身上测量的光谱数据。目标是分析三种不同的组织类型。但是，并不是每只猪都测量了所有组织。总数为脂肪：3、肾脏：4、肝脏：9。每种组织都有重复的光谱测量，从中提取了几个特征。我计划通过取每个组织样本的中位数来汇总重复测量特征。
我想通过使用提取的特征和几个模型将样本分为三个不同的类别来分析样本的差异。我知道数据集非常小，因此我最初的计划是利用嵌套留一交叉验证。但是，由于多类分类中最小的类只有 3 个，我怀疑这种方法是否可行。对于如此小的数据集，留一法交叉验证是否合适，或者其他验证方法是否更合适？
数据摘要：

脂肪组织：3（重复次数：33、30、54）
肾脏组织：4（重复次数：155、128、107、74）
肝脏组织：9（重复次数：12、25、21、29、52、63、62）
]]></description>
      <guid>https://stats.stackexchange.com/questions/660600/classification-strategies-for-small-biomedical-dataset-with-imbalanced-classes</guid>
      <pubDate>Mon, 27 Jan 2025 12:30:55 GMT</pubDate>
    </item>
    <item>
      <title>卡方蒙特卡罗模拟</title>
      <link>https://stats.stackexchange.com/questions/660599/chi-square-monte-carlo-simulation</link>
      <description><![CDATA[我有一个列联表，我想在其上应用卡方检验，但有些单元格不大于 5，这意味着我无法使用该检验。我读到过蒙特卡罗模拟是可行的，但我不知道在这种情况下它是否合适，或者是否有替代测试。
这是我的数据：
data &lt;- matrix(c(326, 32, 22, 2, 96, 115, 271, 4, 132, 29), 
nrow = 5, byrow = TRUE,
dimnames = list(c(&quot;GR1&quot;, &quot;GR2&quot;, &quot;GR3&quot;, &quot;GR4&quot;, &quot;GR5&quot;),
c(&quot;No&quot;, &quot;Yes&quot;)))

这是 R 中的结果：
chisq.test(data, mock.p.value = TRUE, B = 10000)

带模拟 p 值的 Pearson 卡方检验（基于 10000 次重复）

数据：数据
X 平方 = 266.48，df = NA，p 值 = 9.999e-05

我的方法好吗，或者是否有更可靠或更有趣的替代方法？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660599/chi-square-monte-carlo-simulation</guid>
      <pubDate>Mon, 27 Jan 2025 12:20:54 GMT</pubDate>
    </item>
    <item>
      <title>用于碳封存分析的混合效应随机森林 (MERF) 的层次结构和模型表示</title>
      <link>https://stats.stackexchange.com/questions/660598/hierarchical-structure-and-model-representation-in-mixed-effects-random-forest</link>
      <description><![CDATA[我计划使用 randomForest 和 lme4packages 在 R 中执行混合效应随机森林 (MERF) 分析。但是，我不确定我的层次结构是否设置正确。
我最终想要了解的是高级和低级因素对城市公园碳封存的影响。
我的数据集包括：

高级（公园级）数据：20 个公园的 4 个变量。
低级（树木级）数据：4 个变量，包括单棵树的碳封存，总共 3,850 个数据点。
每个公园包含的树木数据点数量取决于其大小（例如，较小的公园只有 36 棵树，而较大的公园则有多达 630 棵树）。

以下是我的两个主要问题：

就我而言，许​​多 AI 工具建议使用求和 (Σ) 形式的方程来表示模型。这种表示方式是否也适合我的数据？此外，这种表示方式是否经济实惠？
￼
对于较低级别的数据（单棵树数据），我是否应该将单棵树的碳封存作为变量？或者，既然它已经是公园级总碳封存的一部分，那么将其排除在固定效应之外是否有意义？

此外，如果您认为 MERF 可能不是实现我的目标的最佳方法，我将非常感激您推荐可能更适合的替代方法。
我将非常感激专家的任何建议。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660598/hierarchical-structure-and-model-representation-in-mixed-effects-random-forest</guid>
      <pubDate>Mon, 27 Jan 2025 12:15:03 GMT</pubDate>
    </item>
    <item>
      <title>多元 Ornstein-Uhlenbeck（Vasicek）过程的最大似然估计</title>
      <link>https://stats.stackexchange.com/questions/660596/maximum-likelihood-estimation-for-multivariate-ornstein-uhlenbeck-vasicek-proc</link>
      <description><![CDATA[我想知道多元 Ornstein-Uhlenbeck (OU) 过程的最大似然估计量 (MLE) 的解析表达式是否可用。
设置如下：考虑一个 $p$ 维 OU 过程 $(\mathbf{X}_t)_{t\geq 0}$，用于求解 SDE
$$d\mathbf{X}_t = \mathbf{\kappa}(\mathbf{\alpha}-\mathbf{X}_t) \, dt+\mathbf{\Sigma} \, d\mathbf{W}_t$$
其中 $\mathbf{\kappa}, \mathbf{\Sigma}$ 是 $k\times k$ 正定矩阵，$\mathbf{\alpha}$ 是 $k$ 向量，$\mathbf{W}_t$ 是 $p$ 维维纳过程。
假设我们在等距时间实例中观察到 OU 过程，即观测结果由
$$\mathbf{x}=\{\mathbf{x}_0, \mathbf{x}_\Delta, \ldots, \mathbf{x}_{n\Delta}\}$$
很明显，$\mathbf{X}_{i\Delta}\mid\mathbf{X}_{(i-1)\Delta}$ 服从高斯分布，利用 OU 过程的马尔可夫特性，我们可以写出观测值 $\mathbf{x}$ 的对数似然。现在我想问的是，是否有可能最大化 $(\mathbf{\kappa,\alpha,\Sigma})$ 的对数似然，并获得 MLE 的解析表达式？
我注意到一篇论文“扩散过程的参数估计和偏差校正”对单变量 OU 过程进行了此操作。如果有人能告诉我显示多变量版本的论文/书籍的方向，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660596/maximum-likelihood-estimation-for-multivariate-ornstein-uhlenbeck-vasicek-proc</guid>
      <pubDate>Mon, 27 Jan 2025 11:35:17 GMT</pubDate>
    </item>
    </channel>
</rss>