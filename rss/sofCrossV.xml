<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Sep 2024 15:17:32 GMT</lastBuildDate>
    <item>
      <title>我应该对数据进行什么类型的测试</title>
      <link>https://stats.stackexchange.com/questions/653859/what-type-of-test-should-i-run-my-data</link>
      <description><![CDATA[您好，
我有一些数据需要分析，我想确保我运行了适当的测试。我的数据包括一组样本，我在不同的日子里接种了病原体（我将这些样本命名为“测试”），考虑到样本的可用性，我必须随机选择在给定的“测试”中要接种的样本，并在所有“测试”中包含两个对照。
我附上了我的数据示例。



测试
样本
代表
评级




1
A
1
1


1
A
2
1


1
B
1
3


1
B
2
3


1
C
1
2


1
C
2
2


1
D
1
4


1
D
2
 3


1
CtrR
1
1


1
CtrR
2
1


1
CtrS
1
4


1
CtrS
2
4


2
A
1
1


2
A
2
2


2
E
1
4


2
E
2
4


2
F
1
4


2
 F
2
4


2
G
1
2


2
G
2
3


2
CtrR
1
1


2
CtrR
2
1


2
CtrS
1
4


2
CtrS
2
4


3
A
1
1


3
A
2
1


3
B
1
3


3
B
2
2


3
F
1
4


3
F
2
3


3
G
1
2


3
G
2
2


3
CtrR
1
1


3
CtrR
2
2


3
CtrS
1
4


3
CtrS
2
4



数据只是为了代表设计，实际数据的样本量和“测试”要大得多，并且在同一测试中样本的重复次数更多，但想展示设计的概念。因此，正如您所看到的，有些样本会在多个测试中重复，有些样本只会在一次测试中重复，我的控制肯定会出现在所有测试中。
我想知道我是否可以使用以下模型运行 lsmeans：
lm(Rating~ Sample + Test + Sample*Test)
或者，为了获得能够纠正未在所有“测试”中出现的样本的平均值，最好的统计分析是什么？同时。
还想问一下，如果 lsmeans 可行，我是否也可以做一个 Tukey HSD 来比较不同样本之间的平均值，看看它们的评级是否有明显差异？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653859/what-type-of-test-should-i-run-my-data</guid>
      <pubDate>Wed, 04 Sep 2024 14:56:53 GMT</pubDate>
    </item>
    <item>
      <title>连续时间中的移动平均过程</title>
      <link>https://stats.stackexchange.com/questions/653857/moving-average-process-in-continuous-time</link>
      <description><![CDATA[在统计学中，移动平均通常定义为离散时间序列。移动平均 (MA) 过程是否有连续时间模型，就像自回归 (AR) 过程一样？例如以微分方程的形式。
这类似于 10 年前提出的这个问题。
我不确定，但根据我从Dr. 那里找到的 2002 年文档，答案似乎是肯定的。约克大学的 Alet Roux：

连续时间自回归移动平均时间序列模型的一些属性

本文档介绍了连续时间和离散时间的自回归 (AR)、移动平均 (MA) 和自回归移动平均 (ARMA) 模型。
第 3.3 节从第 36 页开始，标题为“连续时间移动平均过程”。在这里，他们给出了离散时间 MA 过程的方程，然后指出

连续时间移动平均 (CMA) 过程的定义类似，用微分方程代替差分方程

他们定义如下。
对于 $\{Y(t)\}_{t \in[0, \infty)}$ 的 CMA(q) 过程被定义为微分方程的解：
$$
Y^{(q+1)}(t)=\varepsilon(t)+\beta_1 \varepsilon^{\prime}(t)+\beta_2 \varepsilon^{\prime \prime}(t)+\cdots+\beta_q \varepsilon^{(q)}(t) \text { for } t \in(0, \infty)
$$
他们引用了以下来源来定义该模型

Priestley, M. B. (1981)，频谱分析和时间序列，概率和数理统计，Academic Press，伦敦（第 176 页）。

但是，他们在论文中对该模型进行了以下陈述：

(3.3.3) 中 A 的具体形式允许我们直接计算 A 的 q +1 个特征值：它们都等于零。这与以下事实一致：在 CMA(q) 过程中，自回归多项式 $\alpha(z)$（在 (3.2.13) 中定义）简化为
$$ \begin{aligned} &amp;\alpha(z)=z^{q+1} \text { for } z \in \mathbb{C} . &amp;(3.3 .14) \end{aligned} $$
不幸的是，与离散时间情况形成鲜明对比的是，定理 2.2.10 断言 $\{Y(t)\}_{t \in[0, \infty)}$ 不是渐近弱平稳的。即使不参考定理 2.2.10，这个令人失望的事实从 (3.3.13) 右边的第二项中也可以看出；由于其多项式性质，极限协方差矩阵（如 (3.1.16) 中的 $\sum$）不可能存在。

（有关更多详细信息，请参阅论文）
有人可以从该模型的实际使用/实施的角度解释这些陈述的含义吗？这是否意味着该模型不稳定，因此无法在实践中使用？]]></description>
      <guid>https://stats.stackexchange.com/questions/653857/moving-average-process-in-continuous-time</guid>
      <pubDate>Wed, 04 Sep 2024 14:09:02 GMT</pubDate>
    </item>
    <item>
      <title>如何加快以下 ELBO 评估？</title>
      <link>https://stats.stackexchange.com/questions/653855/how-to-speed-up-the-following-elbo-evaluation</link>
      <description><![CDATA[我有一个估计问题，需要最大化证据下限：
$$ \mathrm{ELBO} = -\frac{1}{2} \Bigg( \mathbb{E}_{q(\theta)} \left[ \mathrm{vec}(\mathbf{Z})^{\mathrm{H}} \mathbf{C}^{-1} \mathrm{vec}(\mathbf{Z})+ \log \left| \mathbf{C} \right| \right] + N_T \times L \log \left(2\pi\right) \\ \nonumber -\mathrm{tr}\left( \mathbf{C}_{\xi}^{-1} \mathbf{\Sigma} \right) - (\mathbf{m})^\top \mathbf{C}_{\xi}^{-1} (\mathbf{m}) + \log \frac{|\mathbf{C}_{\xi}|}{|\mathbf{\Sigma}|} + K \Bigg) $$
任务：
$$ [\hat{\mathbf{m}}, \hat{\mathbf{\Sigma}}, \hat{\xi}] = \arg\max_{[{\mathbf{m}}, {\mathbf{\Sigma}}, \xi]} \mathrm{ELBO}({\mathbf{m}}, {\mathbf{\Sigma}}, \xi) $$
括号中的第一个项ELBO 是近似分布 $q(\theta)$ 的预期值。现在，我正在使用蒙特卡罗模拟来评估它，这非常耗时。这里，$\mathrm{vec}$ 是 $\mathbf{Z}$ 的矢量化形式，它最初是二维的。协方差 $\mathbf{C}$ 是一个块对角矩阵，它是 $\theta$ 的函数。$q(\theta) = \mathcal{N}(\mathbf{m}, \mathbf{\Sigma})$。有六个参数控制$\mathbf{C}_{\xi}$。参数$\theta$的大小与$\mathbf{m}$相同，即$3 \times K$。对于$\mathbf{\Sigma}$，我使用对角矩阵，其中$\mathrm{diag}[\mathbf{\Sigma}] = \mathbf{m}/N$，其中$N$是需要估计的常数。如果 $K = 64$，则要估计的参数数量为 $6 + 192 + 1 = 199$。要估计这么多参数，我无法花费太多计算时间来评估一次目标函数（因为它涉及蒙特卡罗期望步骤）。有没有办法加快这个过程？
我正在使用 MATLAB。我使用 MATLAB 中的简单函数进行所有评估。即使我使用有效的函数，例如 $A\setminus B$ 而不是 $A*inv(B)$，它仍然需要大量时间，因为它必须执行蒙特卡罗。在每个蒙特卡罗步骤中，我需要对 $\theta$ 进行采样，如下所示：$\theta \sim q(\theta)$。任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653855/how-to-speed-up-the-following-elbo-evaluation</guid>
      <pubDate>Wed, 04 Sep 2024 14:05:16 GMT</pubDate>
    </item>
    <item>
      <title>为分类变量添加了变量图和 CCPR 图</title>
      <link>https://stats.stackexchange.com/questions/653854/added-variable-plot-and-ccpr-plot-for-categorical-variable</link>
      <description><![CDATA[添加的变量图和 CCPR 图对分类变量有意义吗？变量的显著性可以从偏 F 检验中获得，非线性仅适用于连续变量。
对于分类和连续预测变量的交互作用（对于 0 表示的分类变量的一个级别，所有点的 x 坐标都等于 0），CCPR 图呢？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653854/added-variable-plot-and-ccpr-plot-for-categorical-variable</guid>
      <pubDate>Wed, 04 Sep 2024 14:04:47 GMT</pubDate>
    </item>
    <item>
      <title>LGBM 回归器中的残差随预测值范围而变化</title>
      <link>https://stats.stackexchange.com/questions/653849/residuals-changes-with-predicted-values-range-in-lgbm-regressor</link>
      <description><![CDATA[我正在做一个回归问题，其中目标变量的范围在 0.01 到 0.15 之间。当预测值在 0.1 左右时，模型给出最佳值。绘制残差似乎显示出异方差。但是我找不到解决这个问题的方法。
是否有任何进一步的步骤来分析和调试它
]]></description>
      <guid>https://stats.stackexchange.com/questions/653849/residuals-changes-with-predicted-values-range-in-lgbm-regressor</guid>
      <pubDate>Wed, 04 Sep 2024 12:14:35 GMT</pubDate>
    </item>
    <item>
      <title>我的 Javascript 神经网络没有按预期学习[重复]</title>
      <link>https://stats.stackexchange.com/questions/653848/my-javascript-neural-network-is-not-learning-as-expected</link>
      <description><![CDATA[我正在用 JavaScript 创建一个神经网络类来解决一个简单的问题，例如 XOR。问题是，无论训练迭代次数如何，训练后预测的值总是在 0.5 左右。我相当确定问题出在网络的反向传播中。
我搜索了参考资料并检查了运行中的神经网络代码，但无法确定问题所在。
这是神经网络类：

function sigmoid(x) {
return 1 / (1 + Math.exp(-x));
}

function sigmoid_d(x) {
let s = sigmoid(x);
return s * (1 - s);
}

class NeuralNetwork {
constrained_size, hidden_​​size, output_size) {
this.input_size = input_size;
this.hidden_​​size = hidden_​​size;
this.output_size = output_size;
this.input = [];

// 初始化权重并随机化
this.weights_ih = new Matrix(this.hidden_​​size, this.input_size); // 输入层和隐藏层之间的权重
this.weights_ho = new Matrix(this.output_size, this.hidden_​​size); // 隐藏层和输出层之间的权重
this.weights_ih.randomize();
this.weights_ho.randomize();

// 初始化偏差
this.bias_h = new Matrix(this.hidden_​​size, 1);
this.bias_o = new Matrix(this.output_size, 1);
this.bias_h.randomize();
this.bias_o.randomize();

this.learning_rate = 0.1;
}

feedForward(inputs, weights, bias) {
let output = Matrix.multiply(weights, input);
output.add(bias);
output.map(sigmoid);

return output;
}

fullFeedForward(inputs) {
inputs = Matrix.fromArray(inputs);
let hidden = this.feedForward(inputs, this.weights_ih, this.bias_h);
let output = this.feedForward(hidden, this.weights_ho, this.bias_o);

return output;
}

train(inputs, target) {
// 将数组转换为矩阵
inputs = Matrix.fromArray(inputs);
target = Matrix.fromArray(targets);

// 通过网络传播并记录每层的输出
let hidden = this.feedForward(inputs, this.weights_ih, this.bias_h);
let output = this.feedForward(hidden, this.weights_ho, this.bias_o);

// 计算输出层的误差
let output_errors = Matrix.subtract(targets, output);

// 计算输出梯度
let gradients = Matrix.map(outputs, sigmoid_d);
gradients.multiply(output_errors);
gradients.multiply(this.learning_rate);

// 计算隐藏增量
let hidden_​​T = Matrix.transpose(hidden);
let weight_ho_deltas = Matrix.multiply(gradients, hidden_​​T);

// 调整权重和偏差
this.weights_ho.add(weight_ho_deltas);
this.bias_o.add(gradients);

// 计算隐藏层的误差
let weights_ho_T = Matrix.transpose(this.weights_ho);
let hidden_​​errors = Matrix.multiply(weights_ho_T, output_errors);

// 计算隐藏梯度
let hidden_​​gradient = Matrix.map(hidden, sigmoid_d);
hidden_​​gradient.multiply(hidden_​​errors);
hidden_​​gradient.multiply(this.learning_rate);

// 计算输入增量
let input_T = Matrix.transpose(inputs);
let weight_ih_deltas = Matrix.multiply(hidden_​​gradient, input_T);

this.weights_ih.add(weight_ih_deltas);
this.bias_h.add(hidden_​​gradient);
}

}

以下是主要代码
const nn = new NeuralNetwork(2, 2, 1);

let input = [[1, 0], [0, 1], [1, 1], [0, 0]];
让目标 = [[1], [1], [0], [0]];

for(让 i = 0; i &lt; 50000; i++) {
让 random_index = Math.floor(Math.random() * 输入.length);
nn.train(输入[random_index], 目标[random_index]);
}

nn.fullFeedForward([1, 0]).print();
nn.fullFeedForward([0, 1]).print();
nn.fullFeedForward([1, 1]).print();
nn.fullFeedForward([0, 0]).print();
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/653848/my-javascript-neural-network-is-not-learning-as-expected</guid>
      <pubDate>Wed, 04 Sep 2024 12:09:36 GMT</pubDate>
    </item>
    <item>
      <title>WGEE 中因死亡或住院而删除数据</title>
      <link>https://stats.stackexchange.com/questions/653847/drop-out-data-due-to-death-or-hospitalization-in-wgee</link>
      <description><![CDATA[我有一个 RCT 数据集，其中包含 60 岁或以上的老年人，他们因心血管事件住院，并在进入研究之前出院。参与者被随机分配到对照组或治疗组，为期 12 个月。我想估计干预对一些次要结果（连续）的影响，包括生活质量和孤独感，以及一些生物标志物（HbA1c、CRP 等）。
问题是由于再次入院或死亡而缺少观察值。我想通过加权 GEE 来解决这个问题，但我看到的关于由于再次入院或死亡而导致的结构性辍学的文献很少，我也不知道 R 中有任何函数可以直接处理这个问题。有没有关于 R 中可以充分处理这个问题的包的建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/653847/drop-out-data-due-to-death-or-hospitalization-in-wgee</guid>
      <pubDate>Wed, 04 Sep 2024 11:36:41 GMT</pubDate>
    </item>
    <item>
      <title>接吻问题右侧偏好计算结果中 $\chi^2$ 值出现差异的原因</title>
      <link>https://stats.stackexchange.com/questions/653843/reason-for-discrepancy-in-calculated-chi2-value-in-this-right-side-preferenc</link>
      <description><![CDATA[在文章成年人头部转动不对称的持续性中，作者观察了$ 124 $对情侣。其中$80 $对情侣接吻时将头移到右侧。剩余的$44$对情侣将头移到左侧。
当我使用$50\%$预期频率$(62 + 62),$计算卡方统计量时，我得到$10.45$作为卡方统计量。但这篇论文报告的卡方统计量为 $5.34$。
我的计算：




右
左




观察值
80
44


预期值
62
62



$\chi^2 = \frac{(80-62)^2}{62} + \frac{(44-62)^2}{62}$
$\chi^2 = 10.45 $
我做错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/653843/reason-for-discrepancy-in-calculated-chi2-value-in-this-right-side-preferenc</guid>
      <pubDate>Wed, 04 Sep 2024 10:24:23 GMT</pubDate>
    </item>
    <item>
      <title>如果没有给出 p 值和其他信息，则决定是否拒绝 $H_{0}$ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/653841/decide-on-h-0-rejection-if-p-value-and-further-information-is-not-given</link>
      <description><![CDATA[我尝试回答以下教科书问题：
如果我运行如下测试
set.seed(123)
DescTools::VarTest(rnorm(100, mean = 3, sd = sqrt(4)), sigma.squared = 3)

给出
 方差单样本卡方检验

数据：rnorm(100, mean = 3, sd = sqrt(4))
X-squared = 148.7, df = 99, p-value = 0.001387
备选假设：真实方差不等于 3
95% 置信区间：
3.473594 6.080687
样本估计：
x 的方差 
4.505917 

如果输出为，我该如何获得测试决策
数据：...........................
X 平方 = 148.7，df = 99，p 值 = ........
备选假设：真实方差 ........ 3
95% 置信区间：
3.473594 6.080687
样本估计：
x 的方差 
4.505917 

相反。此外，是否有可能争论测试是左、右还是双侧？

编辑：
我怀疑，我使用哪种测试并不重要，例如
t.test(1:10, y = c(7:20)) 
t.test(1:10, y = 2:11)

可能是替代方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/653841/decide-on-h-0-rejection-if-p-value-and-further-information-is-not-given</guid>
      <pubDate>Wed, 04 Sep 2024 10:18:23 GMT</pubDate>
    </item>
    <item>
      <title>不同维度的聚类之间 x-means 的 BIC 和似然分数是否可以比较？</title>
      <link>https://stats.stackexchange.com/questions/653834/are-x-means-bic-and-likelihood-scores-comparable-between-clusters-of-different</link>
      <description><![CDATA[我目前正在实施 x-means 变体，在计算贝叶斯信息准则的对数似然（通过 scipy 的多元正态 logpdf）时遇到了问题，该问题在低空间集群上失败。
用例是通过 3D 笛卡尔坐标对地理点进行类似 k-means 的聚类，但具有可配置的最大 k 个集群。坐标系以 (0,0,0) 为地球中心，所有点都相距约 6371 个单位。因此，集群可以是平坦的、非常弯曲的，甚至有点像 1D，但永远不会是真正的 3D 高斯。因此，目前的计划是在计算 BIC 分数时尝试通过子集群上的 PCA 进行降维。
问题是：当使用此实现（大概基于 Ishioka (2000) 的扩展）时，不同维度的集群之间的 BIC 和对数似然分数是否大部分可比？请注意，此实现在单个集群上计算 BIC，然后通过它们单独缓存的协方差/似然/BIC 对 2 个新集群执行某种合并的 BIC。
如果不是，最大 k 聚类的其他选项可能是什么（替代似然函数、聚类算法等）？]]></description>
      <guid>https://stats.stackexchange.com/questions/653834/are-x-means-bic-and-likelihood-scores-comparable-between-clusters-of-different</guid>
      <pubDate>Wed, 04 Sep 2024 08:58:43 GMT</pubDate>
    </item>
    <item>
      <title>低 $R^2$ 谜题</title>
      <link>https://stats.stackexchange.com/questions/653822/low-r2-puzzle</link>
      <description><![CDATA[我进行了一项实验，并使用数据拟合了一个基本的线性回归模型。上图显示了拟合结果。$R^2$ 非常低，表明几乎没有解释力（调整后的 $R^2$ 甚至更低）。但是，当我绘制每组 x 值的 y 值平均值时，我可以非常清楚地看到线性关系。第 7 组的平均值比第 2 组的平均值高很多。通常我会根据 F 统计量（2.253）、$R^2$、解释变量的 t 统计量等指标来抛弃这种回归。但很明显，它告诉我，组数越高，效果就越好。组平均值的差异很明显，而且随着组数的增加而增加。我有点困惑。是回归分析让我失望了，还是我对结果的解释是错误的？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653822/low-r2-puzzle</guid>
      <pubDate>Wed, 04 Sep 2024 02:50:44 GMT</pubDate>
    </item>
    <item>
      <title>在轮盘赌中，出现长红色序列的频率是否低于出现短红色序列的频率？</title>
      <link>https://stats.stackexchange.com/questions/653816/in-roulette-is-the-frequency-of-getting-long-sequences-of-reds-lower-than-that</link>
      <description><![CDATA[在一场无限期的轮盘游戏中，与连续 10 次出现红色相比，连续 100 次出现红色的概率（可能每百万次旋转才出现一次）要小得多，这样说对吗？
如果出现一长串红色的概率会随着序列变长而降低，那么为什么认为在一长串红色之后出现黑色的可能性更大会被视为赌徒谬误？如果 101 次出现红色的序列比 100 次出现红色的序列出现的可能性更小，那么为什么认为当前序列更有可能是 100 次出现红色并因此下一轮旋转将是黑色是错误的？
编辑：
我知道这些都是独立事件，概率没有记忆，因此必须保持不变。我在问，这一事实如何与较长序列出现频率较低的说法相一致。
此外，我并不是说根据大数定律，它应该平衡，因此下一次旋转更有可能是黑色。我是说，我们更有可能处于 100 个红色的序列而不是 101 个红色的序列，因为它发生的频率更高，并且如果更有可能假设现在是较短的序列而不是较长的序列，那么从逻辑上讲，下一次旋转更有可能是黑色不是吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653816/in-roulette-is-the-frequency-of-getting-long-sequences-of-reds-lower-than-that</guid>
      <pubDate>Tue, 03 Sep 2024 23:44:05 GMT</pubDate>
    </item>
    <item>
      <title>lme4 包中 BLUP 的适用功能 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/653795/suitable-function-of-blups-in-lme4-package</link>
      <description><![CDATA[我想分析一个包含 4 年内 2 种条件或环境（干旱胁迫和正常）中 12 种基因型的数据集。
我使用了一篇使用 BLUPs 方法的文章的分析作为我的分析模型，该模型使用 BLUPs 方法评估多年来单个基因型在每种处理下的特征，使用 R 中的“lme4”包，但我不知道该使用哪个函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/653795/suitable-function-of-blups-in-lme4-package</guid>
      <pubDate>Tue, 03 Sep 2024 15:11:00 GMT</pubDate>
    </item>
    <item>
      <title>如何评估忽略重复测量的错误线性模型下的治疗效果估计？</title>
      <link>https://stats.stackexchange.com/questions/653786/how-to-evaluate-estimation-of-treatment-effect-under-wrong-linear-model-ignoring</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653786/how-to-evaluate-estimation-of-treatment-effect-under-wrong-linear-model-ignoring</guid>
      <pubDate>Tue, 03 Sep 2024 08:11:52 GMT</pubDate>
    </item>
    <item>
      <title>当省略随机斜率时，如何使用 lmer()、anova() 和 bootstrap 评估混合模型？</title>
      <link>https://stats.stackexchange.com/questions/653749/how-to-evaluate-mixed-model-using-lmer-anova-and-bootstrap-when-omitting-ra</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653749/how-to-evaluate-mixed-model-using-lmer-anova-and-bootstrap-when-omitting-ra</guid>
      <pubDate>Mon, 02 Sep 2024 15:12:12 GMT</pubDate>
    </item>
    </channel>
</rss>