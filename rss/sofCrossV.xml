<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 07 Aug 2024 21:16:13 GMT</lastBuildDate>
    <item>
      <title>如何验证 R 中“forecast::forecast”的预测？</title>
      <link>https://stats.stackexchange.com/questions/652463/how-to-validate-the-predictions-from-forecastforecast-in-r</link>
      <description><![CDATA[动机
当模型遇到以前未见过的数据时，我们常常有兴趣评估模型的性能。我正在测试 ARIMA 模型来分析一些数据，并希望确保我理解 prediction::forecast 函数的内部工作原理。
数据生成
为了执行此任务，我从 AR(2) 生成数据并将其存储为时间序列对象 ts。
set.seed(123)
z= vector(length = 48)
z[1] = 10
z[2] = 10

for (i in 3:48) {
z[i] = 5 + 1.0*foo[i-1] - 0.70*foo[i-2] + rnorm(n = 1, sd = 1)
}

ts &lt;- as.ts(z, frequency = 1)

# 如果您想查看数据及其 ACF，请运行以下行
# par(mfrow = c(1,2))
# plot(ts, main = &quot;时间序列 Y&quot;, ylab = &quot;值&quot;)
# Acf(ts, main = &quot;时间序列 Y 的 ACF&quot;)
# par(mfrow=c(1,1))

建模
然后我使用函数 forecast::auto.arima 来建模数据。我对模型的唯一限制是它不应考虑任何季节性。请注意，我仅使用 y 的前 24 个值来拟合模型，即我采用了 50/50 分割。
fit &lt;- auto.arima(y = ts[1:24], seasonal = FALSE)

# 要查看调整后的参数和逆 AR 根，请运行以下行
# summary(fit)
# plot(fit)

预测
使用模型 fit，我可以轻松预测 h 步。下面的两行代码将准确显示
fit_forecasts = Forecast(fit, h = 24)
plot(fit_forecast)
abline(v = 25, lwd = 2, lty = 2, col = &quot;grey30&quot;)

如果我检查第一个预测值 $y_{25}$，我会得到 7.339453。
fit_forecasts$mean[1]

验证第一个一步预测，$y_{25}$
我想手动计算这个值，以便更好地了解引擎盖下的情况。拟合模型的系数为$\phi_1 = 0.9380345$和$\phi_2 = -0.7773760$。截距为$y_0 = 7.3359679$。因此，模型为
$$
y_{t+1} = y_0 + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \eta_{t+1} = 7.3359679 + 0.9380345y_{t-1} -0.7773760y_{t-2} + \eta_{t+1},
$$
其中 $\eta$ 为创新。鉴于我在前 24 个数据点上拟合了模型，第一个一步预测可以表示为
$$
y_{25} = 7.3359679 + 0.9380345y_{24} -0.7773760y_{23} + \eta_{25}
$$
已知 $y_{23}$ 和 $y_{24}$ 分别为 $5.779341$ 和 $6.049662$，我们可以解出 $y_{25}$
\begin{align}
y_{25} &amp;= 7.3359679 + 0.9380345 \times 6.049662 -0.7773760 \times 5.779341 + \eta_{25}\\
y_{25} &amp;= 8.518039 + \eta_{25}
\end{align&gt;
我到此为止了：我不知道 $\eta_{25}$ 的值是什么，所以我无法计算 $y_{25}$。我从 forecast 调用的结果中知道 $y_{25} = 7.339453$，因此，我可以将创新计算为 $\eta_{25} = 7.339453 - 8.518039 = -1.178586$，但我不想计算创新。理想情况下，我会得到采样的创新，这样我就可以计算预测值。
我检查了 fit$residuals，但这些是拟合模型的 &quot;残差。即 x 减去拟合值。&quot;，根据 forecast 包手册。
问题
我的目标是将 $y_{25}, ..., y_{48}$ 提供给 fit，以查看模型如何处理在训练期间从未见过的数据，但首先我想了解如何进行预测。我找不到任何地方的采样创新序列。如果预测是按照模型的期望值计算的，并且创新的均值为零，则$\mathbb{E}[\eta_{25}] = 0$，但即便如此，我仍然不知道如何手动计算$y _{25} = 7.339453$。
我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/652463/how-to-validate-the-predictions-from-forecastforecast-in-r</guid>
      <pubDate>Wed, 07 Aug 2024 21:15:51 GMT</pubDate>
    </item>
    <item>
      <title>在什么情况下迁移学习是合理的？</title>
      <link>https://stats.stackexchange.com/questions/652462/under-which-circumstances-is-transfer-learning-sensible</link>
      <description><![CDATA[给定某些任务，其样本为 $y_1(\vec{x}), ... y_n(\vec{x})$
我们何时可以期望迁移学习成为一种合理的方法（即比训练 n 个独立模型产生“更好”的结果）？
我确实理解以下内容：

寻找任务 1..n 的“良好”性能本质上是一个多目标优化问题，因此将有无数个帕累托最优解（无可比拟的好解，需要额外的无差异曲线来选择单个最佳优化解）
虽然这是一个艰难的多目标优化问题，但我可以想象这样一种情况，即所有任务的条件均值估计量都通过多目标学习得到改进，或者在保持无偏的情况下方差更小（在引导测试训练数据集时）。也许这在某种意义上类似于 Cramer Rao 边界 https://en.m.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound

现在对于神经网络和基于梯度下降的优化，我想到了以下想法：

虽然在实践中，人们训练“嵌入模型”然后将它们与不同任务 1..n 的任务头连接起来，如果只有这种联合嵌入（一个共同的神经主干）的存在有助于在所有任务中实现更好的性能，这似乎很幸运（尽管这可以隐式地作为一种正则化，但它更像是一种负担，避免在公共主干中为给定任务提取最佳特征……）
当目标 1..n 之间存在高协方差结构时，多任务学习是否应该最有益（所以我应该在开始多目标学习模型之前检查这一点）
通过多维高斯负对数似然损失利用目标中的这种协方差结构是否有益？

还有什么需要考虑的？]]></description>
      <guid>https://stats.stackexchange.com/questions/652462/under-which-circumstances-is-transfer-learning-sensible</guid>
      <pubDate>Wed, 07 Aug 2024 21:13:30 GMT</pubDate>
    </item>
    <item>
      <title>通过分析车辆轨迹，聚类/查找罚单中的模式</title>
      <link>https://stats.stackexchange.com/questions/652461/clustering-finding-patterns-in-tickets-analysing-vehicle-traces</link>
      <description><![CDATA[我正在从事一个涉及分析汽车 CAN 总线跟踪数据的项目。目标是根据 ECU 通信跟踪从票证（公司的票证工具）中聚类出类似的问题。详情如下：
数据：

格式：.blf（二进制日志格式）用于主票，.asc（ASCII）用于从票
大小：大文件，每个约 350MB
内容：时间戳、通道、协议、消息 ID、解码信号等。

当前方法：

解析 .blf 和 .asc 文件
识别主动传输的 ECU 信号
从时间序列数据中提取特征
使用 PCA 降维
使用 K-means 进行聚类

挑战：

有效处理大文件
识别相关信号聚类
处理主从票证之间的不同时间戳
选择适当的特征来聚类 ECU 通信模式

问题：

从 ECU 跟踪中聚类时间序列数据的有效技术是什么？
如何优化大型 .blf 和 .asc 文件的处理？
是否有适合汽车 CAN 总线数据的特定特征提取方法？
在此背景下验证聚类结果的好方法是什么？

任何见解、改进建议或资源都将不胜感激！
技术堆栈：Python、pandas、scikit-learn
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652461/clustering-finding-patterns-in-tickets-analysing-vehicle-traces</guid>
      <pubDate>Wed, 07 Aug 2024 20:54:23 GMT</pubDate>
    </item>
    <item>
      <title>我需要对 2 Ivs 和 2 DV 进行什么分析？</title>
      <link>https://stats.stackexchange.com/questions/652456/what-analysis-do-i-need-for-2-ivs-and-2-dvs</link>
      <description><![CDATA[我认为我需要 MANOVA，但我可能需要 ANCOVA，然后仅在实验组内进行 ANOVA。
我认为它是干预组内的 2x2 因子独立测量 ANOVA。我没有任何等价的句子可以用于 MANOVA，因为我之前从未写过 MANOVA
我有 2 个 IV：
IV1 有 2 个级别：对照组和干预组
IV2 是干预组中的个性特征，因为这是一个次要假设
我有 2 个相关的 DV：
DV1 是儿童自我评价的幸福感得分随时间的变化（1 个分数在实验开始时，另一个分数在实验结束时）
DV2 儿童父母评价的幸福感得分随时间的变化（1 个分数在实验开始时，另一个分数在实验结束时）
我可以将幸福感得分分为各种不同的子分数（希望、幸福、乐观、价值）
我的假设是：
H0- 实验组和对照组之间的幸福感改善随时间没有显著差异
H1- 与对照组相比，干预组的幸福感得分将显着改善
H2- 干预组的具体幸福感得分显着改善希望、幸福、乐观和价值感
H3- 干预组的改善程度在具有特定人格特质的人中会更高。
我很高兴被告知我完全错了，因为我的论文的分析部分总是花费最长的时间来写，我感到完全迷失了。提前谢谢 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/652456/what-analysis-do-i-need-for-2-ivs-and-2-dvs</guid>
      <pubDate>Wed, 07 Aug 2024 19:41:25 GMT</pubDate>
    </item>
    <item>
      <title>确定四种不同人口统计数据和他们的李克特量表反应之间的相关性的最佳统计工具/测量方法是什么</title>
      <link>https://stats.stackexchange.com/questions/652455/what-is-the-best-statistical-tool-measurement-to-determine-correlation-between-f</link>
      <description><![CDATA[我有几个李克特量表问题的结果以及每个答案的人口统计数据（4 个不同规模的不同年龄组）。确定答案和人口统计数据之间相关性的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652455/what-is-the-best-statistical-tool-measurement-to-determine-correlation-between-f</guid>
      <pubDate>Wed, 07 Aug 2024 19:01:50 GMT</pubDate>
    </item>
    <item>
      <title>使用带有嵌套/随机因子的 lmer 在 R 中建立模型</title>
      <link>https://stats.stackexchange.com/questions/652459/making-a-model-in-r-using-lmer-with-nested-random-factors</link>
      <description><![CDATA[我正在尝试制作一个反映以下实验设计（分裂设计）的模型：一棵树被分成几个象限，每个象限测量 20 棵树的 3 片叶子。我制作的模型的分母自由度非常高（即：687.04），其他交互作用也具有相同的自由度，但由于它们处于不同的级别，因此不应该出现这种情况。我不确定如何调整嵌套和随机因子，以便它们正确反映实验设计。象限嵌套在树中，日期嵌套在象限中
Injection_lm_a&lt;-lmer(data=CIT_Block, Fv.Fm~Treatment*Date/Quadrant+(1|Tree)+(1|Quadrant))
anova(Injection_lm_a)

Injection_lm_b&lt;-lmer(data=CIT_Block, Fv.Fm~Treatment*Date+(1|Tree)+(1|Quadrant))
anova(Injection_lm_b)

Injection_lm_c&lt;-lmer(data=CIT_Block, Fv.Fm~治疗+日期*治疗*象限+(1|治疗/样本编号/Cuadrant))
anova(注射_lm_c)

注射_lm_d&lt;-lmer(Fv.Fm ~ 治疗*Cuadrant + (1 | 树/象限) + (1 | 日期), 数据 = CIT_Block)
anova(注射_lm_d)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652459/making-a-model-in-r-using-lmer-with-nested-random-factors</guid>
      <pubDate>Wed, 07 Aug 2024 18:02:43 GMT</pubDate>
    </item>
    <item>
      <title>关于“假设 $Z_i$ 是 i.i.d. $N(0, 1).$ 且令 $M_n = \max\{Z_1, \ldots, Z_n\}$，证明 $P(M_n > t) \leq n(1 - \Phi(t))$”</title>
      <link>https://stats.stackexchange.com/questions/652454/about-suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n</link>
      <description><![CDATA[关于 https://stats.stackexchange.com/users/395275/lisa-w 的问题
假设 $Z_i$ 是 i.i.d。 $N(0, 1).$ 令 $M_n = \max\{Z_1, \ldots, Z_n\}$，表明 $P(M_n &gt; t) \leq n(1 - \Phi(t))$

我注意到独立性没有被使用。我记得通常当你有 $\max &gt; t$ 时，你通常会将概率更改为“1 减”，如 $P(\max &gt; t) = 1-P(\max \le t)$，然后使用独立性。对于 $\min &lt; t$ 也类似。我很惊讶，我没有看到这个。

https://stats.stackexchange.com/users/79698/jimb 给出了一个提示“第一步是显示 $P(M_n &gt; t)=1−(\Phi(t))^n$&#39;

好吧，我注意到 $1 - (\Phi(t))^n \le n(1-(\Phi(t))^n)$ 为真，因为 $1+x+x^2+...+x^{n-1} = \frac{1-x^n}{1-x} \le n$ 因为每当 $0 &lt; x &lt; 1$ 时，即每当 $x$ 是非退化概率，$1+x+x^2+...+x^{n-1} \le \sum_{i=1}^{n} 1 = n$。因此，


$$P(M_n &gt; t)$$
$$= 1 - P(M_n \le t) \ \text{1 减 1 真好}$$
$$= 1 - P(Z_1, ..., Z_n \le t)$$
$$= 1 - P(\bigcap_{i=1}^{n} \{ Z_i \le t \})​​$$
$$= 1 - \prod_{i=1}^{n} P(\{ Z_i \le t \})​​ \ \text{by独立！}$$
$$= 1 - \prod_{i=1}^{n} \Phi(t) \ \text{by same distribution}$$
$$= 1 - (\Phi(t))^n \le n(1-(\Phi(t))^n)$$
问题：既然显然有更短的路，那发生了什么？
猜测：讲师没有意识到有更短的路？或者也许只是为了展示 $1 - (\Phi(t))^n \le n(1-(\Phi(t))^n)$ 的另一种证明，我们通过以两种不同的方式查看 $P(M_n &gt; t)$ 来做什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652454/about-suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n</guid>
      <pubDate>Wed, 07 Aug 2024 16:50:12 GMT</pubDate>
    </item>
    <item>
      <title>两组点之间的最大相关匹配正在形成团块</title>
      <link>https://stats.stackexchange.com/questions/652452/maximum-correlation-matching-between-2-sets-of-points-is-creating-clumps</link>
      <description><![CDATA[我在这里描述的是映射两组点的问题，这个问题困扰了我一段时间。任何意见都将不胜感激！
任务：
我有两组点存在于多变量特征空间中，我想通过识别两组点之间的相似点对，将这两组点映射到彼此上。
方法：
由于特征向量的“方向”比各个特征的实际值更具信息量，我将两点之间的相似性定义为它们的特征向量之间的相关性。由此，自然的（方向性）映射是将一组中的每个点分配给另一组中与其最相关的点。
直觉和问题：
我认为这个过程会给我一个大约 1:1 的映射，因为我希望每个点在另一组中都有一个明确的最近邻居。然而，我注意到，这个过程会在最终集合中产生团块/吸收点，从而收集大量源自起始集合的连接。在运行几次模拟后，我注意到这种聚集效应并不是我的数据独有的属性，而是在某种程度上在更常见的分布中出现。
问题：
我很难对这种现象出现的原因形成直觉；我也对更正式的演示感兴趣。我觉得应该对此效果进行简单的统计解释。

一个 R 模拟来说明此效果
set.seed(7)

getMaxMatch &lt;- function(mat, margin=c(&quot;row&quot;, &quot;column&quot;)){
margin &lt;- ifelse(margin==&quot;row&quot;, 1, 2)
return(apply(mat, margin, which.max))
}
printClumping &lt;- function(n, n_tot){
sprintf(&quot;匹配使用了另一组中可用点的 %s/%s (%s%%)。&quot;, n, n_tot, round(n/n_tot, 3)*100)
}

n_obs &lt;- 1000
n_feats &lt;- 200

# 2 个集合，其中每个特征和每个点都是 iid
x &lt;- matrix(runif(n_obs*n_feats), ncol = n_feats)
y &lt;- matrix(runif(n_obs*n_feats), ncol = n_feats)

# 每对点之间的成对相关性
pw_obsCorr &lt;- cor(t(x), t(y), method = &quot;pearson&quot;)

# 两个方向上的最大相关性映射 x -&gt; y 和 x &lt;- y
x_match &lt;- getMaxMatch(pw_obsCorr, &quot;row&quot;)
y_match &lt;- getMaxMatch(pw_obsCorr, &quot;column&quot;)

printClumping(length(unique(x_match)), n_obs)
# &quot;匹配使用了另一组中可用点的 619/1000 (61.9%)。&quot;
printClumping(length(unique(y_match)), n_obs)
# &quot;匹配使用了另一组中可用点的 621/1000 (62.1%)。&quot;

我仍然可以观察到上述模拟中约 62% 的聚集，方法是用其他常见分布（例如泊松、正态……）代替均匀分布，并使用 Spearman 而不是 Pearson 相关性。显然，当一组变得比另一组大时，这种聚集统计数据会受到影响，但有趣的是，它对特征数量和此模拟中的点数不敏感。

我在这里描述了一个我在处理真实数据时遇到的问题，但提供了一个简化的示例，我相信它说明了同样的效果。在我的实际用例中，我处理的是基因表达数据，其中每个观察值代表一个细胞，该细胞本身属于某些潜在亚群，每个特征代表嘈杂的基因计数，每个基因计数都遵循自己的分布并依赖于细胞亚群。
最后，对这种匹配的分析表明，尽管存在这种意外特性，但所创建的连接仍然有意义（例如，它确实将来自同一群体的细胞映射到不同集合中），但它对于下游应用来说是不切实际的，并且会产生非常粗粒度的匹配。我找到了一种使用加权二分图匹配程序的解决方法，但我很想了解更多有关此处描述的效果的信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/652452/maximum-correlation-matching-between-2-sets-of-points-is-creating-clumps</guid>
      <pubDate>Wed, 07 Aug 2024 15:47:40 GMT</pubDate>
    </item>
    <item>
      <title>依赖于另一个时间序列的时间序列的均值回归</title>
      <link>https://stats.stackexchange.com/questions/652451/mean-reversion-of-a-time-series-dependent-on-another-time-series</link>
      <description><![CDATA[我正在查看一个时间序列 $x_t$，该序列被认为依赖于另一个时间序列 $p_t$。
我想建立一个过程，在其中随机模拟 $p_t$ 并从模拟中确定 $x_t$。
为了提供背景信息，假设 $p_t$ 是“小部件”的价格，而 $x_t$ 是“精美小部件”的价格。“精美”意味着 $x_t &gt; p_t$ 或者 $x_t = p_t + \delta_t$ 其中 $\delta_t &gt; 0$。
一般理解是，随着 $p_t$ 的增加，$\delta_t$ 将减少，但随着价格稳定，$\delta_t$ 将恢复到其长期平均水平。或者，随着 $p_t$ 的减少，$delta_t$ 将在短期内增加，但随后会恢复。
使用以下内容作为资源：
http://marcoagd.usuarios.rdc.puc-rio.br/revers.html ，我发现我可以估计单个变量的 AR(1) 过程的参数：
$\delta_t - \delta_{t-1} = a + b\delta_{t-1} + \epsilon_t$
并回归以找到参数$a$ 和 $b$。
如果我希望将 $p_t$ 纳入模型，我可以使用
$\delta_t - \delta_{t-1} = a + b\delta_{t-1} + cp_{t-1} + \epsilon_t$
其中 $c$ 是 $p_t$ 对 $\delta_t$ 的影响？
抱歉，这个问题问得不好。我缺乏适当的行话来简洁地提出这个问题。我尝试搜索“协整均值回归”，但一无所获。]]></description>
      <guid>https://stats.stackexchange.com/questions/652451/mean-reversion-of-a-time-series-dependent-on-another-time-series</guid>
      <pubDate>Wed, 07 Aug 2024 15:09:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的分类模型中的最佳阈值会产生意外结果？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652450/why-is-the-optimal-threshold-in-my-classification-model-yielding-unexpected-resu</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652450/why-is-the-optimal-threshold-in-my-classification-model-yielding-unexpected-resu</guid>
      <pubDate>Wed, 07 Aug 2024 15:01:22 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用混合逻辑分析 DCE</title>
      <link>https://stats.stackexchange.com/questions/652448/analysing-dce-with-mixed-logit-in-r</link>
      <description><![CDATA[我正在通过调查进行离散选择实验 (DCE)。我的研究基于具有不同属性级别/类型的护肤产品。总共有四个属性（每个属性有 3 个级别/类型），我生成了 81 种不同的产品。我将它们分成 3 个不同的调查（每个调查有 9 个选择集，每个选择集有 3 种产品可供选择，受访者只能选择其中一种）。此外，他们还回答了有关他们的人口统计和对某些品牌（我在产品设计中使用的品牌）的熟悉程度的问题。这些是协变量（年龄组、收入组、居住地区、对 6 个不同品牌的使用熟悉程度）。
我以长格式扩展了数据（总共 2430 行，因为每个受访者考虑了超过 27 种具有不同属性级别的产品，总共有 90 名受访者）。我使用这段代码放入 mlogit 模型中：
expanded_data &lt;- expand_data %&gt;%
mutate(
Age = as.factor(Age),
Income = as.factor(Income),
Region = as.factor(Region),
CeraVe = as.factor(CeraVe),
Maybelline = as.factor(Maybelline),
LOreal = as.factor(LOreal),
LaMer = as.factor(LaMer),
Chanel = as.factor(Chanel),
Dior = as.factor(Dior),
Price = as.factor(Price),
Packaging = as.factor(Packaging),
Quality = as.factor(Quality),
Brand = as.factor(Brand),
ProductChoiceBinary = as.logical(ProductChoiceBinary)
)
mlogit_data &lt;- mlogit.data(expanded_data,
choice = &quot;ProductChoiceBinary&quot;,
shape = &quot;long&quot;,
id.var = &quot;UniqueChoiceID&quot;,
alt.var = &quot;ProductID&quot;)
complex_model &lt;- mlogit(ProductChoiceBinary ~ Price + Packaging + Quality + Brand | Age + Income + Region + CeraVe + Maybelline + LOreal + LaMer + Chanel + Dior,
data = mlogit_data,
random = ~ Price + Packaging + Quality + Brand | UniqueChoiceID)
但是这个错误一直出现：“solve.default(H, g[!fixed]) 中的错误：Lapack 例程 dgesv：系统完全是奇异的：U[1,1] = 0&quot;
我已经检查过没有多重共线性，这可能是数据结构的问题。但是，我的时间不多了，我真的需要结果。有人知道哪里出了问题，我该怎么办？
我不确定如何在此处上传我的结构图像。我的数据结构为 2430 行和 19 列（RespondentID、问题、产品、年龄、地区、收入、CeraVe、Maybelline、LOreal、LaMer、Chanel、Dior、ProductChoice、价格、包装、质量、品牌、ProductChoiceBinary、UniqueChoiceID）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652448/analysing-dce-with-mixed-logit-in-r</guid>
      <pubDate>Wed, 07 Aug 2024 14:52:46 GMT</pubDate>
    </item>
    <item>
      <title>Surpyval Weibull 拟合优度</title>
      <link>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</link>
      <description><![CDATA[我一直在使用 surpyval 将一些校准数据拟合到威布尔分布。我想评估拟合优度，但我不知道该怎么做。我以前使用过“可靠性”库，它有一个 KS 检验，但我不知道如何在 Surpyval 中执行此操作（可靠性不支持区间删失数据）。代码：
import surpyval as surv
import matplotlib.pyplot as plt
#sample data
Fail = [1,1,3,1,5,1,1,2,1,1,1,1,1]
Type = [1,1,1,2,1,1,2,1,1,2,1,2,1,2,1]
Time = [1820,1987,2176,[2373.0, 2542.0],2373,2731,[2920.0, 3093.0],2920,3279,[3472.0, 3641.0],3472,[3829.0, 4009.0],3829]

model = surv.Weibull.fit(x = Time, c =类型，n = 失败)
model.plot()
plt.show()

libraries:
matplotlib 3.6.0
numpy 1.26.0
scipy 1.14.0
surpyval 0.10.10

包含完整数据集的图。
我的完整数据集有左、右和区间数据。任何其他拟合优度方法/知识都会非常有帮助，并且包括对图像的任何见解。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</guid>
      <pubDate>Wed, 07 Aug 2024 14:49:15 GMT</pubDate>
    </item>
    <item>
      <title>关于提升方法的阅读材料</title>
      <link>https://stats.stackexchange.com/questions/652442/materials-for-reading-on-boosting-methods</link>
      <description><![CDATA[我正在寻找一些关于 boosting 方法的参考资料（教科书、讲义、幻灯片），这些资料要通俗易懂，而且不是太详细。理想情况下，这些资料应该涵盖以下主题：

AdaBoost
Gradient Goosting
XgBoost
]]></description>
      <guid>https://stats.stackexchange.com/questions/652442/materials-for-reading-on-boosting-methods</guid>
      <pubDate>Wed, 07 Aug 2024 13:49:18 GMT</pubDate>
    </item>
    <item>
      <title>某个因素的主要影响是什么？</title>
      <link>https://stats.stackexchange.com/questions/652428/whats-the-main-effect-for-a-factor</link>
      <description><![CDATA[这是我在这里的第一个问题。补充一点背景信息：我正在研究实验设计，在因子主效应部分遇到了麻烦。我了解到，如果您有 $k$ 个因子，每个因子有 $2$ 个级别，例如0 和 1，重复 $n$ 次，那么因子 $A$ 的主效应为
$$
\delta A = \frac{[A1]-[A0]}{2 n}
$$
其中 $[A1]$ 是 $A=1$ 等情况下的结果总和。
第一个问题，为什么会这样？我的意思是为什么是这样而不是相反？即
$$
\delta A = \frac{[A0]-[A1]}{ 2n}
$$
第二个问题，当一个因子有两个以上的水平时，它的主要影响是什么？
第三个问题，在我的笔记中，我有因子“i”在水平“q”上的主要影响是
$$
\delta_{iq}=m_{iq}-m
$$
其中 $m$ 显然是所有实验的平均值，而 $m_{iq}$ 是因子 $i$ 等于水平 $q$ 的实验的平均值。如果这是真的，那么我不明白为什么第一个是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652428/whats-the-main-effect-for-a-factor</guid>
      <pubDate>Wed, 07 Aug 2024 09:09:59 GMT</pubDate>
    </item>
    <item>
      <title>用于评估特征解释力的逻辑回归——分数和置信度的解释</title>
      <link>https://stats.stackexchange.com/questions/652427/logistic-regression-for-evaluating-explanatory-power-of-features-interpretatio</link>
      <description><![CDATA[我需要帮助来确定我的分析是否合理。
我的目标是评估一组特定特征对于二元分类问题的解释力。
我目前的策略是：

选择不相关且具有统计意义的特征（t 检验）
使用这些特征拟合逻辑回归模型 (sklearn)
通过查看系数来比较特征的强度
通过从决策函数中获取置信度值和分数来评估这些特征的解释力 - 在训练数据上测试模型。

这是我不确定的地方。我的直觉告诉我，在训练数据上进行测试总是错误的（呃）。但我的大脑告诉我，在这种情况下这样做是有意义的。我想知道根据我的特征提供的信息，有多少数据点是可以区分的 - 而不是它对看不见的数据会做出什么反应。
大致来说，这是我的思考过程：

高置信度，高分 =&gt; 特征很好
高置信度，低分 =&gt; 特征具有误导性
低置信度，高分 =&gt; 特征具有信息性但不是那么强
低置信度，低分 =&gt; 特征没有信息性

这个分析方案合理吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652427/logistic-regression-for-evaluating-explanatory-power-of-features-interpretatio</guid>
      <pubDate>Wed, 07 Aug 2024 08:51:39 GMT</pubDate>
    </item>
    </channel>
</rss>