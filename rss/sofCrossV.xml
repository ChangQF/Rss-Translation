<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 13 Feb 2024 15:12:45 GMT</lastBuildDate>
    <item>
      <title>获得五分之一的概率 3 次或以上</title>
      <link>https://stats.stackexchange.com/questions/639194/probability-to-get-a-1-in-5-rolls-3-or-more-time</link>
      <description><![CDATA[如果我掷骰子 5 次，得到 3 个或更多骰子的概率是多少？
也就是说，掷 1 三次或以上？
因为我认为它接近 0.05：
$ \binom{5}{3} \left(\frac{1}{6}\right)^3 = 0.046 $
但是这个人认为它接近0.03.]]></description>
      <guid>https://stats.stackexchange.com/questions/639194/probability-to-get-a-1-in-5-rolls-3-or-more-time</guid>
      <pubDate>Tue, 13 Feb 2024 15:07:53 GMT</pubDate>
    </item>
    <item>
      <title>模型评估方法及其如何影响模型的性能</title>
      <link>https://stats.stackexchange.com/questions/639193/model-evaluation-approach-and-how-it-affects-the-performance-of-the-model</link>
      <description><![CDATA[因此，我正在处理的任务是监督视频摘要，其中模型尝试使用视频帧的特征和标签作为帧分数的注释来预测视频帧是否重要。
接下来的相关工作人们通常不会直接使用这些注释作为标签，而是将它们从关键帧分数转换为关键镜头摘要（将进行解释）
然后这些标签用于训练和评估，每帧的模型预测也将转换为关键镜头摘要以进一步评估它们。
key-shot-summary：一个函数，它将帧的分数序列转换为具有高分的片段序列，并且这些片段被分配整个片段的平均分数，然后使用具有限制一定的百分比，最后为视频中的每一帧返回一个一维布尔数组
我目前正在尝试了解使用两种方法之一评估模型的差异
首先：使用 key-shot-summary 进行模型预测后，我们使用该 key-shot-summary 和之前的原始关键帧分数（标签）之间的 f1-score 来评估模型转换（通常在相关工作中完成）
它给出了跨 epoch 的正常评估结果和稳定的 f-score。
其次：我们将标签转换为关键镜头摘要，就像预测一样，然后我们评估它们（我想出了）
但使用它会导致 f1-score 更高，但在各个时期都非常不稳定。
这是代表第二种方法及其结果的图像：

在此图中，您可以看到 f1 分数确实不稳定，但是在第一种方法中，它与 trianing-loss 线 [150:300] 具有相同的稳定性，但 f1 分数要低得多。]]></description>
      <guid>https://stats.stackexchange.com/questions/639193/model-evaluation-approach-and-how-it-affects-the-performance-of-the-model</guid>
      <pubDate>Tue, 13 Feb 2024 14:50:22 GMT</pubDate>
    </item>
    <item>
      <title>是否可以拟合潜在类回归，其中潜在类由 1 个变量分组，但另一个变量存在随机截距？</title>
      <link>https://stats.stackexchange.com/questions/639192/is-it-possible-to-fit-a-latent-class-regression-where-the-latent-class-is-groupe</link>
      <description><![CDATA[我感兴趣的数据生成过程如下
$$y_i=\beta_g x_i+\epsilon_t+\epsilon_i$$
$$S(i)=s, G(s)=g$$
这意味着第 $i$ 个观察结果由主题 $s$ 属于潜在组 $g$ 是协变量 $x$ 的线性函数和一些与时间相关的随机性 $t$ 以及与观察相关的一些随机性 $i$。
希望我没有把 notaiton 破坏得太严重。
生成这样的数据的相同示例代码
图书馆(tidyverse)
设置.种子(1)
n_科目 &lt;- 200
n_times &lt;- 5
n_obs &lt;- n_subjects * n_times

sd_t &lt;- 1
sd_obs &lt;- 0.1

group_beta &lt;- c(0.3, 1.5, 2.7)
n_groups &lt;- 长度(group_beta)

主题组 &lt;-
  蒂布尔（
    主题 = 1:n_主题，
    g = 样本(n_groups, n_subjects, 替换 = TRUE)
  ) |&gt;变异（
    组_贝塔 = 组_贝塔[g]
  ）

epsilon_t &lt;- rnorm(n = n_times, sd = sd_t)

模拟数据&lt;-
  交叉（主题= 1：n_主题，t = 1：n_次）|&gt;
  inner_join(subject_groups, by = &quot;subject&quot;) |&gt;;
  变异（
    epsilon_t = epsilon_t[t],
    epsilon_obs = rnorm(n = n(), sd = sd_obs),
    x = rnorm(n = n()),
    y = group_beta * x + epsilon_t + epsilon_obs，
    random_label = 样本(n_groups, n(), 替换 = TRUE)
  ）

如果我预先知道这些组，那么标准随机效应模型就完美了。以lme4为例：
m_lmer &lt;- lmer(y ~ x + (x - 1 | g) + (1 | t), data = Simulated_data)

但我事先不知道这些组。所以我想使用一个为潜在类回归设计的库。
我看过的两个库是 flexmix和 lcmm。据我所知，他们似乎都无法表达这个简单的模型，但我对这些技术很陌生，所以也许我错过了一些东西。
例如使用 Flexmix：
我能做到
m_flexmix = flexmix(. ~ . | 主题, 模型 = FLXMRglm(y ~ x - 1), 数据 = Simulated_data, k = 3)

我可以让它按主题找到合理的最新课程，但它对随机效应没有任何作用。
或者我可以使用 lme4 接口来做到这一点
m_flexmix = flexmix(. ~ . | 主题, 模型 = FLXMRglm(y ~ x - 1), 数据 = Simulated_data, k = 3)

在这里，我告诉它我想要按主题的潜在类，但我告诉它我也想要按主题进行随机拦截，这是不正确的。
或者，我可以这样做
m_flexmix = flexmix(y ~ 1 | t，模型 = FLXMRlmer(y ~ x - 1，随机 = ~ 1)，数据 = Simulated_data，k = 3)

即使我告诉它我想要 t 的随机拦截，我也告诉它我想要 t 的潜在类。
作为最后的手段，我可​​以使用 lmer 尝试估计 $\epsilon_t$，然后从 y 中减去该值并使用 flexmix从那里开始，如：
m_lmer &lt;- lmer(y ~ x - 1 + (1 | t), data = Simulated_data)
estimated_epsion_t &lt;- ranef(m_lmer)$t$`（截距）`
模拟_数据2 &lt;-
  模拟数据 |&gt;
  突变（y2 = y -estimated_epsion_t[t]）
m_flexmix &lt;- flexmix(. ~ . | 主题, 模型 = FLXMRglm(y2 ~ x - 1), 数据 = Simulated_data2, k = 3)

这似乎在模拟数据中做得很好，但它决不会最大化实际感兴趣的可能性，并且会导致不正确的标准错误等。
最后我的问题是：潜在类回归是否不适合处理像我这样的情况，即潜在类按一个变量分组，但随机效应按另一个变量分组？]]></description>
      <guid>https://stats.stackexchange.com/questions/639192/is-it-possible-to-fit-a-latent-class-regression-where-the-latent-class-is-groupe</guid>
      <pubDate>Tue, 13 Feb 2024 14:44:53 GMT</pubDate>
    </item>
    <item>
      <title>使用经典误差计算而不是 PI 指标来评估上限预测结果</title>
      <link>https://stats.stackexchange.com/questions/639190/evaluate-upper-bound-prediction-results-using-classic-error-calculation-instead</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/639190/evaluate-upper-bound-prediction-results-using-classic-error-calculation-instead</guid>
      <pubDate>Tue, 13 Feb 2024 14:28:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么服从泊松分布可以解释为偶然的结果？</title>
      <link>https://stats.stackexchange.com/questions/639189/why-following-poisson-distribution-can-be-explained-as-a-result-of-chance</link>
      <description><![CDATA[我正在阅读期刊文章，该文章应用泊松分布来确定有多少因素可以被视为超出贫困线。
我的问题是：为什么应用泊松分布并将模型与实际分布进行比较可以完成这项工作？并且，可以应用任何显着性检验来确认偏差是否存在？
让我选择文章的一部分来解释我的问题。
作者解释说：
&lt;块引用&gt;
...泊松框架可以证明在给定人口平均被剥夺物品数量的情况下，根据预期分布频率对剥夺的经验分布进行建模的程度。由此可见，任何与泊松分布的正偏差都表明贫困发生率过高，反映了系统性地经历过度集中贫困的人口规模（Babones 等人，2016）。&#39;&lt; /p&gt;

另外，
&lt;块引用&gt;
如果未满足需求的经验集中可以用纯随机机会来解释，则无需通过确定贫困阈值来对情况进行问题化。只有当未满足需求的经验集中度系统地大于偶然性时，需求才应被识别为“贫困”。

我的理解是，泊松分布可以用来回答给定 lambda 值（平均值）的事件发生次数的概率。但我还没有听说可以确定这样的频率是偶然还是偶然。
以下是文章中的示例：第一个应用程序涉及确定非占有的阈值。在图 1 中，使用总体缺失项目的平均数 1.16 作为 lambda 值绘制了一条泊松曲线。与此相对应的是，我们绘制了个人缺失 1、2、3、…、8 项的经验频率。虽然这两条曲线表现出大致相似的趋势，但在经验频率中可以观察到严重的右尾，并且缺失项目数量较多。这意味着存在过多的个人不拥有比泊松期望通常出现的多套必需物品。
表 2 提供了图 1 中绘制的数据，用于估计相对于基线对应物的过度非占有的累积发生率。根据泊松分布，预计大约 2.39% 的人口 (584,275) 将无法拥有 4 件 lambda 值为 λ = 1.1647 的物品。然而，实际数据表明，大约 4.22% 的人口 (1,031,853) 报告缺少 4 件必需品。重要的是，这种差异出现在 k = 4 时，此时非占有的经验分布超过了基线发生率。由此可见，k ≥ 4 阈值导致名义剥夺率为 5.6%，这意味着总人数过多为 1,365,830 人。

简而言之，“阈值允许人们确定未满足需求的经验集中度大于统计预期的水平”。
我对了解泊松分布的额外函数非常感兴趣。]]></description>
      <guid>https://stats.stackexchange.com/questions/639189/why-following-poisson-distribution-can-be-explained-as-a-result-of-chance</guid>
      <pubDate>Tue, 13 Feb 2024 14:22:33 GMT</pubDate>
    </item>
    <item>
      <title>添加条件的 ML 聚类</title>
      <link>https://stats.stackexchange.com/questions/639188/ml-clustering-with-an-added-condition</link>
      <description><![CDATA[问题：我想创建基于距离的客户集群，总而言之，每个集群产生相同的收入潜力。
说明：

我正在查看分布在一个国家/地区的数千名客户
每个客户都标有邮政编码和收入潜力（我们将通过该客户赚多少钱？）
目标：
1.) 创建定义数量的集群，其中包含地理位置彼此接近的客户（基于 Zip）-&gt;直到这里都没问题
2.) 总之，每个集群应该产生大致相同的收入潜力 -&gt;我还没有找到包含这样一个条件的方法

有人知道这样做的方法吗？提前非常感谢！！！！]]></description>
      <guid>https://stats.stackexchange.com/questions/639188/ml-clustering-with-an-added-condition</guid>
      <pubDate>Tue, 13 Feb 2024 14:02:08 GMT</pubDate>
    </item>
    <item>
      <title>随机森林模型中可疑的部分相关曲线</title>
      <link>https://stats.stackexchange.com/questions/639187/suspicious-partial-dependence-curves-from-a-random-forest-model</link>
      <description><![CDATA[我为 RF 模型中的一些顶级变量创建了多个部分相关图 (PDP)。总的来说，这些情节似乎是有道理的；然而，对于“Bog”来说类中，所有分析变量的概率上升到约 0.9 概率，而对于其他变量，概率要低得多（例如 0.02）。
我知道概率会根据类别而变化，并且预测变量在一个类别中可能比另一个类别更重要。然而，所有沼泽类别的高概率让我对数据提出质疑。如果有任何有关故障排除方法的反馈和想法（如有必要），我将不胜感激。


]]></description>
      <guid>https://stats.stackexchange.com/questions/639187/suspicious-partial-dependence-curves-from-a-random-forest-model</guid>
      <pubDate>Tue, 13 Feb 2024 14:00:31 GMT</pubDate>
    </item>
    <item>
      <title>回归预测与数据样本的统计比较</title>
      <link>https://stats.stackexchange.com/questions/639186/statitical-comparison-of-regression-prediction-to-sample-of-data</link>
      <description><![CDATA[我有一个数据集，我们称之为 data1(x,y)，其中数据 y 是在 16 个 x 值处测量的。我使用该数据集来拟合三参数模型。我可以获得三个模型系数及其标准误差的估计值，并且可以计算整个数据空间中通常的 95% 置信度和预测区间。
我现在有一个较小的数据集，我们称之为 data2(x,y)，其中我在单个 x 值处有 5 个 y 测量值。我想测试以下假设：data2 中获得的数据来自与特定 x 值的模型预测具有相同均值和方差的分布。
我在应用 T 检验和 Z 检验方面有些困难，因为除其他外，我不确定如何解释预测相对于数据2 测量值的自由度。有人可以就如何解决这个问题提供任何建议吗？是否有一个我可以看的例子？
提前谢谢您，
戴维德]]></description>
      <guid>https://stats.stackexchange.com/questions/639186/statitical-comparison-of-regression-prediction-to-sample-of-data</guid>
      <pubDate>Tue, 13 Feb 2024 13:59:52 GMT</pubDate>
    </item>
    <item>
      <title>假设我使用 KM 曲线来参数化估计 S(t)（假设它遵循对数正态分布）</title>
      <link>https://stats.stackexchange.com/questions/639185/suppose-i-am-using-km-curve-to-estimate-st-parametrically-say-assuming-it-fol</link>
      <description><![CDATA[假设我使用 KM 曲线来参数化估计 S(t)（假设它遵循对数正态分布）。现在这个 t 是（比如说）几个月，我想得到对数正态曲线的估计，其中 t 是几周，我该怎么做，我相信曲线将与我们获得的曲线相同如果我们用 0.25*t 代替生存函数 S(t) 中的 t。有什么想法，请分享！]]></description>
      <guid>https://stats.stackexchange.com/questions/639185/suppose-i-am-using-km-curve-to-estimate-st-parametrically-say-assuming-it-fol</guid>
      <pubDate>Tue, 13 Feb 2024 13:54:53 GMT</pubDate>
    </item>
    <item>
      <title>如何标准化标准差？</title>
      <link>https://stats.stackexchange.com/questions/639184/how-to-normalize-standard-deviations</link>
      <description><![CDATA[我有以下数据集（时间与数量）：
数据 = {{0, 0.974}, {3, 0.492}, {6, 0.829}, {9, 0.554}, {15, 0.208},
        {18, 0.138}, {21, 0.199}, {24, 0.0893}};

读取相应的标准差
datawithSD = {0.289, 0.165, 0.404, 0.245, 0.191, 0.0962, 0.241, 0.0359};

我想将数据集中的 $y$ 值按其最大值标准化，即将第二个分量除以 $0.974$。在这种情况下，我应该如何处理标准差？我应该将它们除以对应于 $0.974$ 的标准差，还是应该将它们除以最大的标准差？]]></description>
      <guid>https://stats.stackexchange.com/questions/639184/how-to-normalize-standard-deviations</guid>
      <pubDate>Tue, 13 Feb 2024 13:53:47 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型或结构方程模型，该使用哪一个？</title>
      <link>https://stats.stackexchange.com/questions/639180/linear-mixed-models-or-structural-equation-modeling-which-one-to-use</link>
      <description><![CDATA[我目前正在尝试确定是否使用 LMM 还是 SEM（或其他方法？）进行我的纵向中介研究（3 个时间点）。我想研究下面提到的效果，我想知道这对于 LMM 是否可行，特别是因为前一个时间点的 DV 会影响下一个时间点的 MED。 IV 是干预措施，MED 是通过调查测量的结构，DV 是行为。我不一定对潜在变量感兴趣。
我可以使用 SPSS、Python 或 R...
直接效应和中介：
IV1(t2)-&gt; MED(t2)→ DV（t2）
IV2(t1)-&gt; MED(t2)→ DV (t2)（直接滞后）
IV1 (t2) * IV2 -&gt; MED(t2)→ DV (t2)（滞后交互）
IV1(t3)-&gt; MED(t3)→ DV（t3）
IV2(t1)-&gt; MED(t3)→ DV (t3)（直接滞后）
IV1(t3)*IV2→ MED(t3)→ DV (t3)（滞后交互）
对后续期间的影响（自回归效应）
MED t1 - &gt; MED t2-&gt;中度t3
DV t1 -&gt; DV t2→ DV t3
更改：
MED t2 – t1
MED t3 – t1
DV t2 – t1
DV t3 – t1
随时间变化的混杂因素：
DV t1 -&gt;中度t2
DV t2 -&gt;中度t3
▲ DV t2 – t1 -&gt;中度t3
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/639180/linear-mixed-models-or-structural-equation-modeling-which-one-to-use</guid>
      <pubDate>Tue, 13 Feb 2024 12:59:18 GMT</pubDate>
    </item>
    <item>
      <title>在进行 ARIMAX/SARIMAX 时，外生变量与 Y 变量的协整检验是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/639178/does-cointegration-test-of-exogenous-variable-with-y-variable-make-sense-when-do</link>
      <description><![CDATA[根据我的理解，当您执行回归模型时，两个时间序列变量之间的协整检验通常是相关的。就 ARIMA 模型而言，方法很简单，即使用 Box-Jenkins 方法来构建 ARIMA 模型。
&lt;块引用&gt;
https://davegiles.blogspot.com /2016/07/the-forecasting-performance-of-models.html

但是当使用ARIMAX模型（由多个时间序列宏观经济变量组成 - 也非平稳）时，我们是否需要专门进行外生变量与因变量的协整检验。据我了解，这些外生变量作为外部多元回归 (x) 变量添加到 ARIMA 中。此外，在将这些外生因素添加到 ARIMAX 建模之前，需要执行或评估任何进一步的假设/测试。
&lt;块引用&gt;
仅供参考：我正在使用 python 中的 stats 包来对这个 arimax 进行建模。
]]></description>
      <guid>https://stats.stackexchange.com/questions/639178/does-cointegration-test-of-exogenous-variable-with-y-variable-make-sense-when-do</guid>
      <pubDate>Tue, 13 Feb 2024 12:30:02 GMT</pubDate>
    </item>
    <item>
      <title>如何编写 Gompertz 模型作为加速失效时间模型？</title>
      <link>https://stats.stackexchange.com/questions/639177/how-to-write-a-gompertz-model-as-an-accelerated-failure-time-model</link>
      <description><![CDATA[加速失效时间模型通常定义为具有（常量）协变量 $Z 的 $X&gt;0$ 模型\in \mathbb{R}^p$ 这样
\begin{方程}
\log(X) = \mu + \beta^*Z + \sigma W,
\end{方程}
其中 $W$ 是随机变量。常见的 AFT 模型有 Weibull、Loglogistic 和 Lognormal*。我正在尝试将 Gompertz 实现为 AFT 模型，以获得具有指数风险的模型，并且由于我的数据被非典型地审查和截断，所以我放弃了尝试寻找 R 包而只是自己做。一些 R 包具有 Gompertz 分布式 AFT 模型的实现，但请阅读文档和代码；我无法弄清楚 $W$ 需要什么分布。
我很确定 Gompertz 模型与上面的形式并不完全相同，而是在形式上
\begin{方程}
\log(X) = \mu + \beta^*Z + W\end{方程}
其中 $W$ 是取决于参数 $\sigma$ 的分布，但不是以通常的缩放方式。这是否是 AFT 模型似乎取决于定义（或品味），但它仍然具有比例中位生存时间模型（以及所有其他分位数）的解释，这正是我感兴趣的。我希望有人可以帮助我，如果有人能提供答案参考就完美了。
*参见例如生存分析、审查和截断数据技术，John P. Klein &amp; Melvin L. Moeschberger 2003 年第二版，Science+Business Media, Inc 系列：生物与健康统计 Springer。]]></description>
      <guid>https://stats.stackexchange.com/questions/639177/how-to-write-a-gompertz-model-as-an-accelerated-failure-time-model</guid>
      <pubDate>Tue, 13 Feb 2024 12:23:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 STATA 的 Svy 逻辑回归的模型显着性</title>
      <link>https://stats.stackexchange.com/questions/639176/model-significance-for-svy-logistic-regression-using-stata</link>
      <description><![CDATA[我正在研究逻辑回归调查。基于&lt;10的P值来识别超过10个预测变量。双变量分析为 0.25。然而，当我尝试多变量分析时，模型显着性检验仅适合少数变量（&lt;5）。如果我们添加更多变量，模型显着性水平就会恶化。那么，即使这些变量很重要，我是否应该放弃这些变量（为了模型的重要性）？]]></description>
      <guid>https://stats.stackexchange.com/questions/639176/model-significance-for-svy-logistic-regression-using-stata</guid>
      <pubDate>Tue, 13 Feb 2024 12:22:50 GMT</pubDate>
    </item>
    <item>
      <title>如何处理零膨胀数据并在 beta 回归中纳入随机效应？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/639172/how-to-handle-zero-inflated-data-and-incorporate-random-effect-in-beta-regressio</link>
      <description><![CDATA[我的响应变量是连续的并且位于闭区间 [0,1] 内。有超零且接近于零；它是比例数据，我的响应变量是分类变量。我发现我的数据遵循贝塔分布。 （我在直方图中看到并应用 fitdistrplus 包中的 descdist 函数来查找分布）我发现 betaregression (betareg) 不起作用，因为有 0。
我发现的一个选择是添加一个小常数来删除零。不过，我也有随机因素。我的数据是重复观察的，包含随机因素。 （我的响应变量是近交系数，预测变量是一个阶段（生命阶段）..我的研究问题是：近交水平在不同年龄阶段如何变化？我必须将岛屿作为随机因素，因为近交水平不同岛屿之间也有差异..（10个岛屿）。我发现beta回归没有考虑随机因素。在这种情况下，我们如何进行统计建模？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/639172/how-to-handle-zero-inflated-data-and-incorporate-random-effect-in-beta-regressio</guid>
      <pubDate>Tue, 13 Feb 2024 11:39:12 GMT</pubDate>
    </item>
    </channel>
</rss>