<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 25 Sep 2024 18:22:14 GMT</lastBuildDate>
    <item>
      <title>RA Fisher（或“Fisherian”）如何选择样本大小？</title>
      <link>https://stats.stackexchange.com/questions/654905/how-would-ra-fisher-or-a-fisherian-choose-sample-sizes</link>
      <description><![CDATA[正如许多其他 CV.SE 帖子（例如此处或此处）中所述，RA Fisher 和 Neyman &amp; Pearson 的统计假设检验框架在实践和解释上存在差异。
我很好奇他们在如何设计您的研究方面的差异。为了简单起见，我将重点关注样本量（但当然，功效和精度也会受到研究设计的其他方面的影响，例如阻塞等）。
在 N-P 框架下，一般方法对我来说很清楚：首先确定您想要的功效，您感兴趣的特定替代点假设 $H_A$（例如，就您想要检测的最小效应大小而言），以及您可以容忍的 I 类错误率 $\alpha$。从那里，您可以计算出实现 $\alpha$ 和 $H_A$ 所需功效所需的样本量。
但据我了解，在 Fisher 方法中，没有 $\alpha$、没有 $H_A$，也没有明确的功效计算。那么 Fisher 如何为自己的研究选择样本量？（或者他如何建议其他人规划样本量？）

我很好奇，尤其是因为 Fisher 确实写过“一个设计合理的实验”通常会产生较低的 p 值。

就我个人而言，作者更喜欢将显着性标准设定为 5%。点，并完全忽略所有未达到该水平的结果。只有当经过适当设计的实验很少失败时，科学事实才应被视为实验确定的。

-- Fisher, R. A. 田间实验的安排。《农业部期刊》，1926 年，33，第 504 页。
对我来说，这句 1926 年的引言（尤其是“很少失败”）听起来很像说精心设计的实验应该具有很高的功效：尽管他没有指定特定的$H_A$，但 Fisher 想象在相同的人群中重复使用相同设计的相同实验（尽管在这句话中它是不确定这些重复是假设的还是应该实际执行的），并且反复得到等于或低于 5% 显著性水平的结果。
如果 Fisher 同意设置显著性水平，并且 Fisher 也致力于实现高功效——那么他还能做什么来选择样本量来实现这些目标，同时又与 N-P 的整体方法有实质性的不同？
（当然，还有贝叶斯方法、似然法，也许还有其他非 Fisher 和非 NP 方法。但我特别想问的是，什么才算是 Fisher 而非 NP。）]]></description>
      <guid>https://stats.stackexchange.com/questions/654905/how-would-ra-fisher-or-a-fisherian-choose-sample-sizes</guid>
      <pubDate>Wed, 25 Sep 2024 18:08:15 GMT</pubDate>
    </item>
    <item>
      <title>使用 SPSS 计算广义倾向得分</title>
      <link>https://stats.stackexchange.com/questions/654901/calculating-generalized-propensity-score-using-spss</link>
      <description><![CDATA[我正在为一项包含大量混杂变量的医学研究计算 Cox 回归。我已经计算了具有二进制值的变量的倾向得分，以调整混杂因素。但也有一些度量变量。为此，我需要计算广义倾向得分。我在互联网上进行了广泛搜索，但我只能找到我不理解的公式，没有实用指南。显然有不同的方法可以做到这一点。我不希望我的连续变量有子类。我了解到我必须为连续变量和可能的混杂因素计算线性回归。之后，应该计算残差的方差。但我不知道如何从那里继续。
有人知道如何在 SPSS 中计算 GPS 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654901/calculating-generalized-propensity-score-using-spss</guid>
      <pubDate>Wed, 25 Sep 2024 16:21:34 GMT</pubDate>
    </item>
    <item>
      <title>用连续给定条件概率建模</title>
      <link>https://stats.stackexchange.com/questions/654900/modelling-conditional-probabilities-with-continuous-givens</link>
      <description><![CDATA[我目前正在努力解决这个方程式
$$ p(x; \theta) = P(Y = 1 | X = x) $$
其中 $p$ 是右侧条件概率的模型。如果 $X$ 是连续随机变量，那么这个方程式肯定没有意义。我们是否简单地将 $X$ 视为离散变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654900/modelling-conditional-probabilities-with-continuous-givens</guid>
      <pubDate>Wed, 25 Sep 2024 16:19:27 GMT</pubDate>
    </item>
    <item>
      <title>应该用置信区间还是 t 检验来评估统计显著性？</title>
      <link>https://stats.stackexchange.com/questions/654897/should-one-assess-statistically-significance-with-confidence-intervals-or-a-t-te</link>
      <description><![CDATA[我对评估温差的统计显著性感兴趣。
为了这个目标，我生成了历史和未来时期的平均值的引导时间序列。
然后我遵循了两种方法：
A. 计算引导差异的 95% 置信区间，并认为零不在置信区间内的区域具有统计显著性。
B. 使用历史和未来引导均值之间的配对 t 检验 (scipy.stats.ttest_rel) 来计算 p 值，并认为 p 值低于 .05 的区域具有统计显著性
以下哪个选项是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654897/should-one-assess-statistically-significance-with-confidence-intervals-or-a-t-te</guid>
      <pubDate>Wed, 25 Sep 2024 15:15:05 GMT</pubDate>
    </item>
    <item>
      <title>球体上的采样角度：从广义协方差矩阵到浓度参数</title>
      <link>https://stats.stackexchange.com/questions/654893/sampling-angles-on-a-sphere-from-a-general-covariance-matrix-to-concentration-p</link>
      <description><![CDATA[我正在尝试使用 Python 提取球体上的点。
我必须在天空中定位事件并使用 healpy 生成地图。
在测试期间，我使用了 von Mises-Fisher，因为我假设 $\theta$ 的方差与 $\phi$ 的方差相同。一切运行良好，我能够通过使用 $\kappa=1/\sigma^2$ 获得浓度参数 $\kappa$。
我用于评估像素中概率的函数是
def Mises_Fisher(theta,phi,DS_theta,DS_phi,conc):
meanvec=hp.ang2vec(DS_theta,DS_phi)
meanvec=np.asarray(meanvec,dtype=np.float128)
norm=np.sqrt(np.dot(meanvec,meanvec))
meanvec=meanvec/norm

var=hp.ang2vec(theta,phi)
var=np.asarray(var,dtype=np.float128)
norm=np.sqrt(np.dot(var,var))
var=var/norm

factor=np.dot(conc*var,meanvec)
factor=np.float128(factor)
#归一化是徒劳的，我们将除以总和
#fullnorm=conc/(2*np.pi*(np.exp(conc)-np.exp(-conc)))
ret=np.float128(np.exp(factor))#/fullnorm
#ret=factor
return ret

然后，对于 healpy 图中的每个像素，我可以分配一个概率。
现在我有一个不再各向同性的协方差矩阵，在这种情况下，我如何在球体上生成点？我知道Kent 分布的存在，但我没有所需的数量，例如$\gamma$、$\beta$ 和 $\kappa$。我不知道是否有办法根据协方差矩阵获得这些。
为了进一步复杂化问题，矩阵是 11 维的，但我只需要投影到 (distance,$\theta$,$\phi$) 空间，然后生成地图。
现在我尝试从多元高斯中提取，但由于高斯在切平面上，对于某些方差，分布产生的角度超出了 $\theta$ 和 $\phi$ 的范围。
这是我用来提取点的代码
num_samples = 10**7
samples = np.random.multivariate_normal(perm_mean, perm_cov, num_samples)

phi = samples[:, 2]
theta = samples[:, 1]
print(np.min(theta),np.max(theta))
print(np.min(phi),np.max(phi))
print(&#39;starting mean values&#39;)
print(&#39;theta={}, phi={}&#39;.format(perm_mean[1],perm_mean[2]))

关键是，对于某些矩阵，方差使得角度可以超出范围。我无法对矩阵采取行动，这些矩阵是由其他一些代码提供给我的，应被视为固定数据。
提前感谢大家！
*编辑
在这里我澄清一下，使我的陈述更加严格。
因此，矩阵是另一段代码给我的协方差矩阵，我无法更改。我必须评估引力波 (GW) 事件的天空定位。在我的例子中，这意味着将包括天空位置在内的 11 个参数提供给程序，并且此代码会返回一个协方差矩阵。对于这个问题的范围，该程序可以被视为一个黑匣子，因为我无法修改那里的任何东西。
现在我可以从这个矩阵中采样并获得 $\theta$ 和 $\phi$，即天空位置。
让我们以单位球体为中心，表面上的每个点都由指向引力波事件天空坐标的向量标识。我们现在可以忘记其他参数。
如果事件定位良好，这意味着如果角度的变化“很小”，我们可以想象建立一个与天空相切的平面，法向量沿径向，从引力波位置开始。现在，如果我们对高斯分布进行采样，该分布的参数为 $\mu$ 和 $\Sigma$，其中 $\mu$ 为 11 个起始参数给出的均值向量，$\Sigma$ 为 cov 矩阵，我们可以获得 $\theta$ 和 $\phi$ 的样本。这种方法效果很好，但是一旦方差足够大，我们开始“感觉”我们在球体上而不是在平面上，这种方法就会失效。解决这个问题的分布是 Kent 分布。我的问题是
给定一个均值向量$\mu$和一个协方差矩阵$\Sigma$，是否可以构造肯特分布中所需的必要量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654893/sampling-angles-on-a-sphere-from-a-general-covariance-matrix-to-concentration-p</guid>
      <pubDate>Wed, 25 Sep 2024 13:00:09 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证不起作用</title>
      <link>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</link>
      <description><![CDATA[我目前在当地大学听一场数据科学演讲。我们是从工作单位来的，我从事 DS/ML 工作，已经 7 年了，但我的学位是计算机科学，因此我在 DS/ML 方面主要是自学的。
这个人告诉我们，DS 文章中写到的很多东西实际上都不起作用。
例如，他提到精确度、召回率和 F1 分数很少使用（相反，他更喜欢 AUC）。
但对我来说，另一个更古怪的事情是，交叉验证也不应该用于业务问题。他解释说它不起作用，因为它不代表现实生活。在现实生活中，你的目标不是预测数据分布中的随机样本，而是必须根据过去 x 年建立一个模型来预测未来 y 个月的数据。
所以他说交叉验证基本上是无用的，应该使用前向优化。
首先，它是如何工作的？它只用于验证还是也可以用于优化？怎么做？
此外，CV 真的那么没用吗？这是我读过的关于 DS 的任何文章中最被接受的验证形式。但也许这是我自学知识的不足之处。
还有什么关于很多事情的“神话”更高大上，但在现实生活中却不起作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</guid>
      <pubDate>Wed, 25 Sep 2024 12:55:02 GMT</pubDate>
    </item>
    <item>
      <title>估计低人口规模的误差幅度</title>
      <link>https://stats.stackexchange.com/questions/654891/estimating-margin-of-error-with-low-population-sizes</link>
      <description><![CDATA[我协助举办一个小型的定期活动，随后对部分贸易参与者进行调查，以评估他们的体验，并尝试改进未来活动的体验。到目前为止，响应率约为 40%，而预计响应人数不会超过 100 人，目前约为 50 人。我的一些问题的答案可能是“差”、“一般”或“好”，这些答案的比例显然可以逐一跟踪。
鉴于存在一些混杂因素，这些因素可能会使响应人群与总体人群存在重大差异，是否可以通过数字判断答案比率随时间的变化是否显著？我可以假设这些回答在一定程度上具有代表性，但使用 Z 值的标准 MoE 计算器似乎假设了无限的人口或至少比样本量大几个数量级的人口，而这里的情况并非如此。
目前我有一个加权分数，如下所示：
((A x 1)+(B x 0.5)+(C x -1))/n，其中：
A =“良好”回答
B =“平均”回答
C =“较差”回答
n = 总回答
这给了我一个介于 -1 和 1 之间的总分，可以随时间进行跟踪。有没有办法计算或估计这个分数的误差幅度？还是我只是目测？我的样本数字是否在任何情况下都使收集这些数据毫无意义？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654891/estimating-margin-of-error-with-low-population-sizes</guid>
      <pubDate>Wed, 25 Sep 2024 12:24:31 GMT</pubDate>
    </item>
    <item>
      <title>如何在单个 mids 对象中合并多重插补的并行处理结果？[已迁移]</title>
      <link>https://stats.stackexchange.com/questions/654890/how-can-i-combine-the-results-of-parallel-processing-of-multiple-imputation-in-a</link>
      <description><![CDATA[我一直在尝试使用 miceadds 进行多重插补（我使用 2l.pmm 方法，但 mice 中没有该方法）。这是并行处理的代码：
library(foreach)
library(doParallel)
library(miceadds)

# 设置并行后端
num_cores &lt;- 30
cl &lt;- makeCluster(num_cores)
registerDoParallel(cl)

# 定义插补函数
impute_function &lt;- function(data, pred_matrix, method, seed) {
set.seed(569)
mice::mice(
data,
method = &quot;2l.pmm&quot;,
predictorMatrix = pred,
maxit = 2,
seed = seed
)
}

num_imputations &lt;- 5
seeds &lt;- 1:num_imputations

# 并行运行插补
imputations &lt;- foreach(seed = seeds, .combine = &#39;c&#39;, .packages = &#39;miceadds&#39;) %dopar% {
impute_function(data, pred_matrix, method = &quot;2l.pmm&quot;, seed = seed)
}

# 停止集群
stopCluster(cl)

对象 imputations 是一个包含每次迭代的列表。
我如何将这些迭代组合成一个像函数这样的单个 mids 对象
mice(data, method=&quot;2l.pmm&quot;, predictorMatrix = pred, maxit = 2, seed = 569)

会给出什么结果？
P.S 我尝试使用函数 futuremice，但无法将其与 miceadds 中的 2l.pmm 方法一起使用。如果您知道这样做的方法，我想会更好。]]></description>
      <guid>https://stats.stackexchange.com/questions/654890/how-can-i-combine-the-results-of-parallel-processing-of-multiple-imputation-in-a</guid>
      <pubDate>Wed, 25 Sep 2024 12:20:59 GMT</pubDate>
    </item>
    <item>
      <title>一般时间序列模型估计量的渐近性质</title>
      <link>https://stats.stackexchange.com/questions/654889/asymptotic-properties-of-estimators-for-general-time-series-model</link>
      <description><![CDATA[我的问题涉及时间序列分析中估计量的渐近性质。特别是，我对时间序列（不是 ARMA 时间序列）的估计量的行为感兴趣。因此，让 $(Y_t)_{t \in I \subset \mathbb{N}}$ 成为单变量时间序列。我们可以假设时间序列遵循以下形式的更新方程：
$Y_t = g(Y_{t-1}, ..., Y_{t-p}, f(\epsilon_{t-1}, ..., \epsilon_{t-q}), \epsilon_t)$
其中 $\epsilon_t$ 是 $iid$ 创新，其中 $\epsilon_t \sim (0, \sigma^2)$。 $f(\epsilon_{t-1}, ..., \epsilon_{t-q})$ 是某种类似于移动平均的部分，用于使时间序列具有衰减的自相关性（而不是截止）。$g$ 是处理自相关的函数。请注意，对于特殊选择，其中 $g$ 和 $f$ 是线性函数，我们得到经典的 ARMA 模型。我们可以假设 $g$ 由参数 $\phi$ 参数化，而 $f$ 由参数 $\theta$ 参数化。我感兴趣的是足以满足 $\phi$ 和 $\theta$ 的 MLE 估计量的一致性和渐近正态性的条件。在几篇论文中（对函数 $g$ 和 $f$ 做出特殊选择），我遇到了平稳性和混合条件。但是，我想知道这些条件是否足以满足我在此处给出的相当通用的模型。
任何有关论文/书籍/网站等的提示都将不胜感激。当然，直接回答也很好 :D。]]></description>
      <guid>https://stats.stackexchange.com/questions/654889/asymptotic-properties-of-estimators-for-general-time-series-model</guid>
      <pubDate>Wed, 25 Sep 2024 11:55:48 GMT</pubDate>
    </item>
    <item>
      <title>当零过多时使用零膨胀 GlMM</title>
      <link>https://stats.stackexchange.com/questions/654883/using-zero-inflated-glmm-when-you-have-too-many-zeros</link>
      <description><![CDATA[我试图使用广义线性混合模型来了解几个预测因子（n=8）对物种存在与否的影响。不幸的是，我没有很好的数据。我有 13000 个点，其中 300 个为 1（存在），其余为 0（不存在）。在遇到收敛和高特征值问题后，我现在认为问题出在我的数据上，具体来说，就是 0 太多了。我想知道使用零膨胀模型是否可以解决这些问题。
发布 GlmmTMB 后，我使用 delta AIC 进行模型选择以选择最佳模型。
下面是我的代码：
SP1 &lt;- cbind(Data_scaled, 
SP1 = Data$SP1, 
Dist_ID = Data$Dist_ID) 

set.seed(123)

SP1_Final &lt;- SP1 %&gt;% dplyr::select(ProtectedAreas, TRI, 
Water, Perc_NR, Perc_TB, Settlements, Precipitation, 
HMI, SP1, Dist_ID)

SP1_ZIGLMM &lt;- glmmTMB(SP1 ~ ProtectedAreas + TDF + Water + Perc_NR +
Settlements + TRI+ Perc_TB + Precipitation + (1 | Dist_ID), 
data = SP1_Final, family = binomial, 
ziformula = ~ 1, 
na.action = na.fail,# 零膨胀模型（仅截距模型）
control = glmmTMBControl(optimizer = &quot;nlminb&quot;, # 已更改优化器
optCtrl = list(iter.max = 100000)))
summary(SP1_ZIGLMM)
SP1model_set_sample &lt;- dredge(SP1_ZIGLMM)
print(SP1model_set_sample)
]]></description>
      <guid>https://stats.stackexchange.com/questions/654883/using-zero-inflated-glmm-when-you-have-too-many-zeros</guid>
      <pubDate>Wed, 25 Sep 2024 10:16:22 GMT</pubDate>
    </item>
    <item>
      <title>二项分布中中位数和众数有什么关系</title>
      <link>https://stats.stackexchange.com/questions/654894/whats-the-relationship-of-median-and-mode-in-binomial-distribution</link>
      <description><![CDATA[假设$X\sim B(30,\frac{1}{3})$。
可以说中位数是$15$。
如果我们要找出$\Pr(X\gt15)$和$\Pr(X\lt15)$哪个值更大，众数大于中位数（右偏）是否表示$\Pr(X\gt15)$值更大，反之亦然。
这个逻辑正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654894/whats-the-relationship-of-median-and-mode-in-binomial-distribution</guid>
      <pubDate>Wed, 25 Sep 2024 10:08:04 GMT</pubDate>
    </item>
    <item>
      <title>使用缺失值的 Wilcoxon 符号秩检验</title>
      <link>https://stats.stackexchange.com/questions/654879/using-wilcoxon-signed-rank-test-with-a-missing-value</link>
      <description><![CDATA[我正在研究一个问题，我应该使用 Wilcoxon 符号秩检验，$9$ 个元素。第九对中的一个值缺失，我只知道它的结果为负数。我应该如何处理该值？我在网上找到了信息，“如果数据范围内有缺失值，则整个对将被排除在分析之外”，但在符号检验的情况下，我知道如果我们不知道最后一个条目但知道它的秩，我们仍然可以使用它。但在这种情况下，我们有配对结果，所以我不确定。我应该手动完成计算，而不是使用 R。
差异如下：$−7$, $−15$, $−1$, $−17$, $−10$, $−5$, $+11$, $−6$, $X_{9}&lt;0$。
我的猜测是，我可以将其省略，因为它是负数，并且与大多数 $X_{i}$ 值没有什么不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/654879/using-wilcoxon-signed-rank-test-with-a-missing-value</guid>
      <pubDate>Wed, 25 Sep 2024 07:34:40 GMT</pubDate>
    </item>
    <item>
      <title>一个数据集来自多个分布</title>
      <link>https://stats.stackexchange.com/questions/654863/one-data-set-drown-from-multiple-distributions</link>
      <description><![CDATA[我不清楚如何拟合至少从视觉上看是从多个分布中提取的数据集。
我尝试使用 GaussianMixture，但结果看起来并不令人信服。我不擅长统计，也不想争辩说它是错误的，但这不是我所期望的。代码在这里：
import numpy as np
from pylab import *
from sklearn.mixture import GaussianMixture
from pylab import concatenate, normal
import pandas as ps

from scipy.stats import norm

df = ps.read_csv(&#39;Book6.csv&#39;)
multimodal_dist = df.E.to_numpy()

weights = np.ones_like(multimodal_dist)/float(len(multimodal_dist))
y, x, _=hist(multimodal_dist, bins=np.arange(df[&#39;E&#39;].min(), df[&#39;E&#39;].max()+1)-0.5, alpha=.5, weights=weights, label=&#39;data&#39;)

components = 2

gm = GaussianMixture(n_components=components)
gm.fit(multimodal_dist.reshape(-1, 1))

means = gm.means_
standard_deviations = gm.covariances_**0.5 
weights = gm.weights_ 

new_X = np.linspace(min(multimodal_dist), max(multimodal_dist), 100)

对于 zip(means, standard_deviations, weights) 中的平均值、标准差、权重：
print(weight,mean, std)
pdf = 2*weight * norm.pdf(new_X, mean, std)
plt.plot(new_X.reshape(-1, 1), pdf.reshape(-1, 1), alpha=0.8)

pdf_full = np.zeros(len(new_X))
对于范围(components) 中的 i：
pdf_full = pdf_full + weights[i] * norm.pdf(new_X, means[i], standard_deviations[i])

plt.plot(new_X.reshape(100,1), 2*pdf_full.reshape(-1, 1))

plt.show()

我根据 GaussianMixture 拟合系数生成的图是

整体曲线确实看起来正确，但底层分布不是我所期望的。
我期望的图是手动拟合的，没有统计支持，但我认为，应该是这样的：

我的期望是错误的，还是我没有使用好的方法，或者误用了它们？首先，在这两种情况下，我的标准化都是手动完成的。我不明白如何标准化我的拟合以匹配分布。
数据在这里。]]></description>
      <guid>https://stats.stackexchange.com/questions/654863/one-data-set-drown-from-multiple-distributions</guid>
      <pubDate>Tue, 24 Sep 2024 20:55:32 GMT</pubDate>
    </item>
    <item>
      <title>何时应用 P 值校正进行多重检验：多结果研究示例</title>
      <link>https://stats.stackexchange.com/questions/654803/when-to-apply-p-value-corrections-for-multiple-testing-a-multi-outcome-study-ex</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654803/when-to-apply-p-value-corrections-for-multiple-testing-a-multi-outcome-study-ex</guid>
      <pubDate>Mon, 23 Sep 2024 22:36:40 GMT</pubDate>
    </item>
    <item>
      <title>我们如何在 R 中计算一个数据集中的一个记录与第二个数据集中的所有记录之间的 Gower 距离？</title>
      <link>https://stats.stackexchange.com/questions/654811/how-do-we-calculate-the-gower-distance-between-one-record-in-one-dataset-and-all</link>
      <description><![CDATA[我想计算数据集 1 的一条记录与数据集 2 的所有记录之间的 Gower 距离。第一种方法如下
library(gower)

data(iris)
dat1 &lt;- iris[1:10,]
dat2 &lt;- iris[11:30,]

# 第一种方法
gower::gower_dist(dat1[1,], dat2)

这给了我长度为 20 的结果。
0.09079365 0.09873016 0.16142857 0.29476190 0.20920635 0.33079365 
0.21936508 0.05000000 0.23952381 0.11507937 0.12095238 0.15079365 
0.16984127 0.24523810 0.16539683 0.12920635 0.17206349 0.03555556 
0.02761905 0.14063492

我可以将第一个值解释为 dat1[1,] 和 dat2[1,] 之间的 gower 距离，将第二个值解释为 dat1[1,] 和 dat2[2,] 之间的 gower 距离，依此类推吗？
让我感到困惑的是，如果我计算
gower::gower_dist(dat1[1,],dat2[1,])

这给了我
0.75

这与 0.09079365 不同。最终，我想计算 dat1 中每个观测值与 dat2 中每个观测值的 Gower 距离。如果我使用第二种方法，我将需要在 dat2 中的所有观测值上添加一个 for 循环，如下所示。
# 第二种方法
for(i in 1:nrow(dat2)) {
print(gower::gower_dist(dat1[1,],dat2[i,]))
}

由于这两种方法给出的结果不同，我应该使用哪一种方法来实现目的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654811/how-do-we-calculate-the-gower-distance-between-one-record-in-one-dataset-and-all</guid>
      <pubDate>Mon, 23 Sep 2024 17:37:36 GMT</pubDate>
    </item>
    </channel>
</rss>