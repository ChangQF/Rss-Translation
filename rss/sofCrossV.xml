<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 02 Sep 2024 06:23:48 GMT</lastBuildDate>
    <item>
      <title>高度不平衡的样本如何影响 A/B 测试结果的 1 类和 2 类错误？</title>
      <link>https://stats.stackexchange.com/questions/653730/how-does-a-highly-imbalanced-sample-affect-the-type-1-and-2-errors-of-a-b-test-r</link>
      <description><![CDATA[假设我有一个 A/B 测试，其中两个样本大小差异很大（即 1000 和 100）。我想知道是否有一个框架可以让我思考第 1 类和第 2 类错误通常会发生什么？例如，我在另一篇文章中的这个答案中看到

如果最小样本量是方差最大的样本量，则测试将产生夸大的第 I 类错误。

我想知道为什么会这样。我的直觉是，如果我们要检查 $t$ 统计量，它由均值差除以标准误差组成：
$$
t=\frac{\bar{X}_1-\bar{X}_2}{SE}
$$
由于样本量小且方差通常较大，$SE$ 似乎会被夸大，导致 $t$ 统计量较小，从而更难拒绝原假设。这似乎意味着第 1 类错误（假设原假设为真，错误地拒绝原假设的概率）会降低，因为现在通常更难拒绝原假设。
但是，这与上面的答案和引用不一致。为什么？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653730/how-does-a-highly-imbalanced-sample-affect-the-type-1-and-2-errors-of-a-b-test-r</guid>
      <pubDate>Mon, 02 Sep 2024 05:50:55 GMT</pubDate>
    </item>
    <item>
      <title>何时使用负二项式和泊松回归</title>
      <link>https://stats.stackexchange.com/questions/653727/when-to-use-negative-binomial-and-poisson-regression</link>
      <description><![CDATA[何时使用负二项回归，何时使用关于均值和方差的泊松回归]]></description>
      <guid>https://stats.stackexchange.com/questions/653727/when-to-use-negative-binomial-and-poisson-regression</guid>
      <pubDate>Mon, 02 Sep 2024 04:35:12 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯定理和逆概率</title>
      <link>https://stats.stackexchange.com/questions/653724/bayes-theorem-and-the-inverse-probabilities</link>
      <description><![CDATA[如果我有以下数据：
p（发生致命车祸）= 0.02%
p（吸毒后驾车）= 4.7%
p（吸毒后驾车 | 发生致命车祸）= 31.8%

我计算出 p（发生致命车祸 | 吸毒后驾车）= 0.135%
是否可以这样说：
p（未吸毒后驾车）= 1 - p（吸毒后驾车）= 95.3？

和 . . .

p(未吸毒时驾车 | 发生致命车祸) 
= 1 - p(吸毒时驾车 | 发生致命车祸) 
= 68.2

因此：
p(发生致命车祸 | 未吸毒时驾车) = 0.014%
]]></description>
      <guid>https://stats.stackexchange.com/questions/653724/bayes-theorem-and-the-inverse-probabilities</guid>
      <pubDate>Mon, 02 Sep 2024 02:44:54 GMT</pubDate>
    </item>
    <item>
      <title>如果有两个概率，你怎样描述其中一个概率比另一个概率大多少？</title>
      <link>https://stats.stackexchange.com/questions/653721/if-you-have-two-probabilities-how-do-you-describe-how-much-more-likely-one-is-t</link>
      <description><![CDATA[所以，如果我有两个统计数据，例如，
“如果你在吸毒后开车，发生致命车祸的概率为 0.135%，而如果你在醉酒后开车，发生致命车祸的概率为 0.108%。”
如果你在吸毒后开车，发生致命车祸的概率是高出 25% 还是高出 0.027%？
我在想，这意味着今年每 100000 名吸毒后开车的人中，有 135 名会撞死人，但每 100000 名醉酒后开车的人中，有 108 名会撞死人。这高出 25%。但我不确定是否是这样。]]></description>
      <guid>https://stats.stackexchange.com/questions/653721/if-you-have-two-probabilities-how-do-you-describe-how-much-more-likely-one-is-t</guid>
      <pubDate>Mon, 02 Sep 2024 01:53:31 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法将贝叶斯可信区间转换为标准差？</title>
      <link>https://stats.stackexchange.com/questions/653719/is-there-a-way-to-convert-a-bayesian-credible-interval-to-standard-deviation</link>
      <description><![CDATA[我正在开展一项荟萃分析，其中一项纳入的研究仅提供了 95% 可信区间作为离散度的度量，我想知道是否有办法将其转换为标准差，就像 Cochrane 建议的置信区间 ((UPPER-LOWER)/3.92)*SQRT(N)]]></description>
      <guid>https://stats.stackexchange.com/questions/653719/is-there-a-way-to-convert-a-bayesian-credible-interval-to-standard-deviation</guid>
      <pubDate>Mon, 02 Sep 2024 00:48:24 GMT</pubDate>
    </item>
    <item>
      <title>对 Alex Smola 1998 年实现的支持向量回归的一些进一步解释</title>
      <link>https://stats.stackexchange.com/questions/653718/some-further-explanation-of-alex-smolas-1998-implementation-of-support-vector-r</link>
      <description><![CDATA[我目前正在研究并尝试实现 Alex Smola 1998 年关于支持向量回归的论文中的伪代码，特别是关于顺序最小优化的伪代码。（第 4.6.3 节，http://alex.smola.org/papers/1998/Smola98.pdf）。我有几个问题

他所说的偏差项更新到底是什么意思？ （他在第 1.1.4 节中给出了简要解释，但我不知道我们是否必须为当前问题集中的每个拉格朗日乘数计算偏差项，或者我们是否为问题集中的每个问题都这样做）。
在他的实现中，没有实际的方法更新拉格朗日乘数，或从 0 开始移动，因为乘数的选择似乎总是将它们设置为 0，以获得正的、较小的 epsilon 值。

我想知道如何解决这些问题，或者进一步的资源可以帮助我完成任务。如果您想了解有关我的实现的更多详细信息，请随时询问]]></description>
      <guid>https://stats.stackexchange.com/questions/653718/some-further-explanation-of-alex-smolas-1998-implementation-of-support-vector-r</guid>
      <pubDate>Mon, 02 Sep 2024 00:09:05 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 中相似度得分与增益的关系</title>
      <link>https://stats.stackexchange.com/questions/653717/relationship-between-similarity-score-and-gain-in-xgboost</link>
      <description><![CDATA[我试图理解 XGBoost 中相似度得分和增益背后的直觉。
相似度得分的计算方法如下：

\[
\text{相似度得分} = \frac{\text{(残差总和)}^2}{\text{残差计数 + 正则化}} 
\]

我的理解是，如果偏差较小，则残差总和较小。因此，相似度得分越低越好。

然后我们继续进行拆分并计算每个节点的相似度得分。为了找到阈值，我们使用

\[
\text{增益} = \text{similarity_left + similarity_right - similarity_root}
\]

然后我们选择最高增益阈值。这就是我挣扎的地方。更高的相似度不是意味着偏差更大吗？

相似度得分和增益背后的直觉到底是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/653717/relationship-between-similarity-score-and-gain-in-xgboost</guid>
      <pubDate>Sun, 01 Sep 2024 22:00:25 GMT</pubDate>
    </item>
    <item>
      <title>R 中可以使用“mboxcox”吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653715/is-mboxcox-available-in-r</link>
      <description><![CDATA[在这篇论文 https://journals.sagepub.com/doi/pdf/10.1177/1536867X1001000108 中，介绍了 Stata 包 mboxcox。我尝试在 R 中查找该包，但找不到。R 中是否有这个包？如果没有，R 中是否有任何包可以像 Velilla (1992) 中那样执行多变量 Box-Cox 变换，如 mboxcox 包？]]></description>
      <guid>https://stats.stackexchange.com/questions/653715/is-mboxcox-available-in-r</guid>
      <pubDate>Sun, 01 Sep 2024 20:20:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 5 点李克特量表和“是/否/可能”问卷进行相关性和回归分析？</title>
      <link>https://stats.stackexchange.com/questions/653701/how-to-perform-correlation-regression-analysis-using-both-5-point-likert-scale</link>
      <description><![CDATA[我为我的论文收集了数据，以分析个人纳税人的认知程度。为此，我分发了一份问卷，其中包含基于 5 点李克特量表的 IV（审计、处罚、社会人口因素等）问题以及 DV（税收认知程度）的“是/否/可能”问题。我坚持分析同时使用 5 点李克特量表和“是/否/可能”量表的数据。任何进一步提高我的数据分析的建议都会有所帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653701/how-to-perform-correlation-regression-analysis-using-both-5-point-likert-scale</guid>
      <pubDate>Sun, 01 Sep 2024 13:19:37 GMT</pubDate>
    </item>
    <item>
      <title>根据后验预测分布定义概率</title>
      <link>https://stats.stackexchange.com/questions/653697/defining-probabilities-from-the-posterior-predictive-distribution</link>
      <description><![CDATA[我想了解如何在给定后验预测分布的情况下定义输出处于特定区间的概率。
假设一个预测模型具有一些参数$\theta$和一些先验，$y$是连续的。 $\epsilon$ 是区间 $[a, b]$
我们将后验预测分布定义为
$$
p(\tilde{y} \mid \mathbf{y}) = \int_{\Theta} p(\tilde{y} \mid \theta) p(\theta \mid \mathbf{y}) \, d\theta
$$
这是定义输出在特定区间的概率的方法吗？
$$
P(\tilde{y} \in \epsilon \mid \mathbf{y}) = \int_{\Theta} P(\tilde{y} \in \epsilon \mid \theta) \, p(\theta \mid \mathbf{y}) \, d\theta
$$
正确，或者我应该使用后验预测分布积分的方法：
$$
P(\tilde{y} \in \epsilon \mid \mathbf{y}) = \int_a^b p(\tilde{y} \mid \mathbf{y}) \, d\tilde{y} = \int_a^b \left( \int_{\Theta} p(\tilde{y} \mid \theta) \, p(\theta \mid \mathbf{y}) \, d\theta \right) d\tilde{y}?
$$
它们两个对我来说似乎都不对，我们如何确定这些表达式实际上定义了概率，我们不需要用积分除以所有这些区间吗？因此正确答案应为：
$$
P(\tilde{y} \in \epsilon \mid \mathbf{y}) = \frac{\int_a^b p(\tilde{y} \mid \mathbf{y}) \, d\tilde{y}}{\int_{-\infty}^{\infty} p(\tilde{y} \mid \mathbf{y}) \, d\tilde{y}} = \frac{\int_a^b \left( \int_{\Theta} p(\tilde{y} \mid \theta) \, p(\theta \mid \mathbf{y}) \, d\theta \right) d\tilde{y}}{\int_{-\infty}^{\infty} \left( \int_{\Theta} p(\tilde{y} \mid \theta) \, p(\theta \mid \mathbf{y}) \, d\theta \right) d\tilde{y}}?
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/653697/defining-probabilities-from-the-posterior-predictive-distribution</guid>
      <pubDate>Sun, 01 Sep 2024 12:05:46 GMT</pubDate>
    </item>
    <item>
      <title>基于 glm 聚类 se 的 p 值</title>
      <link>https://stats.stackexchange.com/questions/653725/p-values-based-on-clustered-se-with-glm</link>
      <description><![CDATA[我想从 glm 中检索具有聚类标准误差的 p 值。我使用了一个函数来计算聚类标准误差，然后使用这些误差来生成模型结果的摘要。当我手动计算从模型结果摘要中获得的 p 值时，p 值与我手动计算的值不相似。
我按照三个步骤手动计算 p 值。

估计聚类标准误差并将其存储为向量。

根据公式计算 z 值：估计系数/聚类标准误差。

根据 z 值检索双侧 p 值。我使用正态分布，因为我有一个逻辑回归。


下面是我的测试代码。
data(mtcars)

cluster &lt;- sample(1:3, 32, replace =TRUE)

mtcars &lt;-cbind(mtcars, cluster)

model &lt;- glm(am ~ wt + hp, data = mtcars, family = binomial(link = &quot;logit&quot;))

# 提取系数

coef_estimates &lt;- coef(model)

# 聚类红色序列的函数
get_CL_vcov&lt;-function(model, cluster){
require(sandwich, quietly = TRUE)
require(lmtest, quietly = TRUE)

#计算自由度调整
M &lt;- length(unique(cluster))
N &lt;- length(cluster)
K &lt;- model$rank
dfc &lt;- (M/(M-1))*((N-1)/(N-K))

#计算 uj
uj &lt;- apply(estfun(model),2, function(x) tapply(x, cluster, sum))

#使用sandwich 获取方差-协方差矩阵
vcovCL &lt;- dfc*sandwich(model, meat=crossprod(uj)/N)
return(vcovCL)
}

model_vcov &lt;- get_CL_vcov(model, mtcars$cluster)

model_cse &lt;- sqrt(diag(model_vcov))

# 每个系数的 z 值
z_values &lt;- coef_estimates / model_cse 

# 使用正态分布的双尾 p 值z 值
p_values &lt;- 2 * pnorm(-abs(z_values))

#### 比较无聚类标准误差、聚类标准误差（p 值未手动校正）和聚类标准误差（p 值手动计算）的结果
#summary(model_cse)

summary(model)

summary(model, model_cse)

p_values

我不确定问题是否出在我计算聚类标准误差或 p 值的方式上。我是否需要对我的公式进行一些调整或是否还应该考虑其他问题？我使用的样本是 n=32，只是为了说明问题，但我不认为这是我有不同 p 值的原因。]]></description>
      <guid>https://stats.stackexchange.com/questions/653725/p-values-based-on-clustered-se-with-glm</guid>
      <pubDate>Sat, 31 Aug 2024 16:58:33 GMT</pubDate>
    </item>
    <item>
      <title>测量两组内部距离差异的重要性</title>
      <link>https://stats.stackexchange.com/questions/653500/measure-the-significance-of-differences-in-internal-distances-in-two-groups</link>
      <description><![CDATA[我是一名语言学家，正在研究 169 名挪威女性作家和 169 名挪威男性作家的语法变异（使用树库），该变异基于八个屈折和句法属性。这八个属性是两种表达类别的备选方式之间的八个二元选择，称为“保守”和“激进”。对于给定属性，记录的是作者保守选择的百分比。因此，它将是 0 到 100 之间的值。因此，这八个属性定义了作者分布的八维空间。然后可以像往常一样计算任何两个作者之间的（欧几里得）距离，取点坐标平方差之和的平方根。两组之间的一个显着差异（在各个属性之间都稳定）是，在八维可能性空间中，男性比女性分散得更多，女性聚集得更密集，选择组合的变化较少。我计算一个群体的密度作为内部距离的平均值——即取每个群体成员与群体中其他作者的平均距离的平均值。该图显示了女性和男性与同性别其他成员的平均距离。男性的平均值为 69（标准差 16.6），女性的平均值为 60（标准差 15.3）。t 检验可以极高置信度地得出显著性，但——不是统计学家——我对 t 检验的适用性表示怀疑。群体成员的数值是相互依赖的，因此我们测试的是性别群体作为整体的属性，而不是两个群体中每个成员的可比属性。因此，我的问题是：是否有适合这种数据的显著性检验——或者我错误地认为 t 检验不合适（这很好）？评论中提到的表格：



作者
F1
F2
F3
F4
F5
F6
F7
F8




author1
92,1
98
 99,2
26,7
71,3
56,8
80
22,7


author2
55,2
73
93,1
6,4
30,9
49,2
37,2
23,8


作者3
97
99,7
100
49
99,1
62,8
86
39,7


作者4
99,5
98,7
100
6,5
50, 3
61,8
51
20,6


author5
23,2
37,9
99,9
5,6
27,2
78,4
57,8
28



]]></description>
      <guid>https://stats.stackexchange.com/questions/653500/measure-the-significance-of-differences-in-internal-distances-in-two-groups</guid>
      <pubDate>Wed, 28 Aug 2024 18:39:51 GMT</pubDate>
    </item>
    <item>
      <title>差异项目功能标准选择</title>
      <link>https://stats.stackexchange.com/questions/653367/differential-item-functioning-criteria-selection</link>
      <description><![CDATA[当使用（有序）逻辑回归框架测试差异项目功能 (DIF) 时，一系列（有序）逻辑回归会拟合数据，使用项目响应 ($Y$) 作为因变量，并使用潜在变量 ($θ$)、测试 DIF 的组变量 ($group$) 作为预测变量：
$$
Y = \beta_1\theta \tag{1}
$$
$$
Y = \beta_1\theta + \beta_2group \tag{2}
$$
$$
Y = \beta_1\theta + \beta_2group + \beta_3\theta \times group \tag{3}
$$
计算这些回归后，似乎有三个常用的标准来检测 DIF。如 Crane et al. 2007 中所述：

在第一个标准中，使用 $X^2$ 统计数据来比较模型；如果后续模型的可能性明显更高，则存在 DIF。
在第二个标准中，为每个模型计算伪$R^2$；如果后续模型具有明显更好的 $R^2$，则存在 DIF。
在第三个标准中，比较 $\beta_1$ 系数；如果后续模型具有明显不同的 $\beta_1$ 系数，则存在 DIF。

这些标准对我来说很有意义，但我不明白为什么在控制潜在变量（即 $\beta_2$ 系数）后，我们不会对 $group$ 的影响感兴趣。如果即使在控制潜在变量后，组成员身份仍显着影响观察到的反应，在我看来，这表明存在 DIF。然而，这似乎不仅没有被用作标准，我唯一一次看到它被引用为一种方法是在 Crane et al. 2004 中，他们驳斥了它。在将方法 (3) 与检查 $\beta_2$ 的方法进行比较时，他们说：

在统一 DIF 检测中，有趣的是，当考虑到人口统计特征时，整体能力水平与项目响应之间的关系幅度是否发生了显着变化。这就是混淆的本质，也是均匀 DIF 的本质……因此，我们选择采用 [$\beta_1$ 标准] 来确定项目中是否存在均匀 DIF。

为什么显著的 $\beta_2$ 系数不表示 DIF？
示例
这个问题是由我正在进行的 DIF 分析引起的，我得到了一些令人困惑的结果。我正在比较大学生和非大学生的 PHQ-9（衡量抑郁症状严重程度的指标）反应。总样本量约为 90,000。我正在使用 lordif 在 R 中测试 DIF。
当我使用第一种方法（$X^2$）时，我发现所有项目都有 DIF；考虑到我的样本量很大，$X^2$ 统计数据显著也就不足为奇了，因此我测试了其他两种方法。
当我使用第二种方法（$R^2$ 中的变化）时，我没有发现 DIF；各个模型之间，伪$R^2$度量（McFadden、Nagelkerke 或 Cox-Snell）的变化均不超过 0.01。
当我使用第三种方法（$\beta_1$的变化）时，我也没有发现 DIF；$\beta_1$系数的变化均不超过 3.3%（即使“少量”的 DIF 也应伴随至少 5% 的变化）。
但是，当我查看模型 $(2)$ 的实际回归结果时，我发现$\beta_2$系数较大且显著。以 PHQ-9 的第七项（注意力不集中）为例：lrm 系数为 0.789（OR = 2.2），这表明在控制潜在抑郁分数后，大学生在更高类别中回答的几率是非大学生的 2.2 倍。在我看来，这似乎是相当大的 DIF，但大多数人似乎并不认为这是 DIF。这是为什么呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/653367/differential-item-functioning-criteria-selection</guid>
      <pubDate>Mon, 26 Aug 2024 22:28:38 GMT</pubDate>
    </item>
    <item>
      <title>重新创建`lm`分类回归</title>
      <link>https://stats.stackexchange.com/questions/651363/recreate-lm-categorical-regression</link>
      <description><![CDATA[考虑以下代码，它使用来自正确模型的数据，使用两个分类变量和一个连续变量的 lm 进行回归，没有交互作用：
set.seed(12345)

n &lt;- 100
X1 &lt;- as.factor(sample(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), n, replace = TRUE))
X2 &lt;- as.factor(sample(c(&quot;d&quot;, &quot;e&quot;), n, replace = TRUE))
X3 &lt;- rnorm(n, mean = 0, sd = 1)

effeta &lt;- 1
effetb &lt;- 2
effetc &lt;- 3
effetd &lt;- 4
effete &lt;- 5

Y &lt;- 10 + 3*X3 + effeta*(X1 == &quot;a&quot;) + effetb*(X1 == &quot;b&quot;) + 
effetc*(X1 == &quot;c&quot;) + effetd*(X2 == &quot;d&quot;) + effete*(X2 == &quot;e&quot;) + 
rnorm(n, mean = 0, sd = 1)

model &lt;- lm(Y ~ X1 + X2 + X3)
print(summary(model))

输出为：
调用：
lm(formula = Y ~ X1 + X2 + X3)

残差：
最小值 1Q 中位数 3Q 最大值
-2.74679 -0.60571 0.06521 0.67873 1.85143

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 15.06741 0.20151 74.773 &lt; 2e-16 ***
X1b 0.95913 0.23994 3.997 0.000127 ***
X1c 1.96010 0.23637 8.292 7.26e-13 ***
X2e 1.08521 0.18887 5.746 1.10e-07 ***
X3 3.03324 0.09537 31.804 &lt; 2e-16 ***
---
显著性代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

残差标准误差：95 自由度上的 0.9327
多重 R 平方：0.9194，调整后的 R 平方：0.916
F 统计量：4 和 95 DF 上的 270.8，p 值：&lt; 2.2e-16

目标是从数学上理解到底发生了什么，然后在 R 中重现它。更具体地说：

可以说 X3 系数的估计是正确的。在线来源表明 lm 将以一个级别为参考，将其效果设置为零。在一般情况下，如何提前预测哪个变量将作为参考？也许是按字母顺序？一旦估计了效果，我们如何知道它们是正确的？
虽然没有参考，但我相信 R 使用虚拟变量将分类观察结果写入矩阵中，将所有内容组合在一起，就像 Searle 中提到的那样，然后进行多元线性回归。在这种情况下，我该如何写下这样的矩阵？

让我们用 $x_3 \in \mathbb{R}^n$ 代替 x3。然后：
\begin{equation*}
x_3 =
\begin{bmatrix}
x_{1,3} \\
x_{2,3} \\
\vdots \\
x_{n,3}
\end{bmatrix}
\end{equation*&gt;
要对分类变量进行盲目计算，可以这样写：
\begin{equation*}
x_1 =
\begin{bmatrix}
x_{1,1a} &amp;&amp; x_{1,1b} &amp;&amp; x_{1,1c} \\
x_{2,1a} &amp;&amp; x_{2,1b} &amp;&amp; x_{2,1c} \\
\vdots &amp;&amp; \vdots &amp;&amp; \vdots\\
x_{n,1a} &amp;&amp; x_{n,1b} &amp;&amp; x_{n,1c} \\
\end{bmatrix};
x_2 =
\begin{bmatrix}
x_{1,1d} &amp;&amp; x_{1,1e} \\
x_{2,1d} &amp;&amp; x_{2,1e}\\
\vdots &amp;&amp; \vdots \\
x_{n,1d} &amp;&amp; x_{n,1e} \\
\end{bmatrix}
\end{equation*&gt;
两个矩阵中的所有元素均为 $0$ 或 $1$。
然后输入：
\begin{equation*}
X =
\begin{bmatrix}
1 &amp;&amp;x_{1,1a} &amp;&amp; x_{1,1b} &amp;&amp; x_{1,1c} &amp;&amp; x_{1,1d} &amp;&amp; x_{1,1e} &amp;&amp; x_{1,3} \\
1 &amp;&amp; x_{2,1a} &amp;&amp; x_{2,1b} &amp;&amp; x_{2,1c} &amp;&amp; x_{2,1d} &amp;&amp; x_{2,1e} &amp;&amp;x_{2,3} \\\\
\vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots \\
1 &amp;&amp; x_{n,1a} &amp;&amp; x_{n,1b} &amp;&amp; x_{n,1c} &amp;&amp; x_{n,1d} &amp;&amp; x_{n,1e} &amp;&amp; x_{n,3}
\end{bmatrix}
\end{equation*
这样我们就可以进行回归分析 lm(Y~X)。但这显然不是实际发生的情况。我如何去掉一些列才能得到实际发生的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/651363/recreate-lm-categorical-regression</guid>
      <pubDate>Thu, 18 Jul 2024 19:45:11 GMT</pubDate>
    </item>
    <item>
      <title>在观察性因果研究中，匹配何时会导致 ATE 与 ATT 的对比？</title>
      <link>https://stats.stackexchange.com/questions/647187/when-does-matching-result-in-an-ate-vs-att-on-observational-causal-studies</link>
      <description><![CDATA[我读到匹配几乎总是会产生 $ATT$ 效果，但子分类匹配可以产生 $ATE$。因此，我想知道有什么启发式方法可以确定哪些类型的匹配会导致 $ATE$ 与 $ATT$ 效果？例如，精确匹配、倾向得分匹配或基因匹配会产生什么效果？]]></description>
      <guid>https://stats.stackexchange.com/questions/647187/when-does-matching-result-in-an-ate-vs-att-on-observational-causal-studies</guid>
      <pubDate>Tue, 14 May 2024 07:32:37 GMT</pubDate>
    </item>
    </channel>
</rss>