<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 01 Jan 2024 09:14:06 GMT</lastBuildDate>
    <item>
      <title>我试图理解一篇研究论文，但无法理解 https://ieeexplore.ieee.org/document/9527655 中方程的工作原理</title>
      <link>https://stats.stackexchange.com/questions/635947/im-trying-to-understand-a-research-paper-but-i-couldnt-understand-the-working</link>
      <description><![CDATA[在本文中，他们使用模型方程在未标记的目标数据集中学习，如图所示，方程的工作原理对我来说并不清楚，而且第一次馈送是如何进行的对源数据进行 resnet，然后分别定位数据，帮助模型提高性能。]]></description>
      <guid>https://stats.stackexchange.com/questions/635947/im-trying-to-understand-a-research-paper-but-i-couldnt-understand-the-working</guid>
      <pubDate>Mon, 01 Jan 2024 09:06:37 GMT</pubDate>
    </item>
    <item>
      <title>ARCH/GARCH 可以配合价格值吗？</title>
      <link>https://stats.stackexchange.com/questions/635946/arch-garch-can-work-with-price-value</link>
      <description><![CDATA[ARCH/GARCH 可以结合价格值来识别影响因变量的因素。不需要转换才能返回吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635946/arch-garch-can-work-with-price-value</guid>
      <pubDate>Mon, 01 Jan 2024 07:44:58 GMT</pubDate>
    </item>
    <item>
      <title>我们是否总是需要对数据进行过采样或欠采样以防止类别不平衡？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/635945/do-we-always-need-to-over-sample-or-under-sample-the-data-for-class-imbalance</link>
      <description><![CDATA[假设我们正在处理一个类别不平衡的数据集。我知道有多种方法可以缓解类别不平衡问题。举个例子，

我们可以调整模型的相关超参数。例如，在 RandomForestClassifier 中，我们可以调整 class_weight
我们可以使用比简单的准确度得分更深入地了解性能的误差指标
我们可以进行 SMOTE、过采样或欠采样。

我的问题是，我们是否需要执行所有这些步骤，或者上述步骤或其他步骤中的一个步骤就足以解决类别不平衡问题？
例如，如果我打算使用class_weight，我是否还需要使用SMOTE或执行过采样或欠采样？]]></description>
      <guid>https://stats.stackexchange.com/questions/635945/do-we-always-need-to-over-sample-or-under-sample-the-data-for-class-imbalance</guid>
      <pubDate>Mon, 01 Jan 2024 07:34:24 GMT</pubDate>
    </item>
    <item>
      <title>了解蒙特卡罗积分中的重要性采样</title>
      <link>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</guid>
      <pubDate>Mon, 01 Jan 2024 05:16:12 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 的概率推理</title>
      <link>https://stats.stackexchange.com/questions/635942/probabilistic-inference-for-lstm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635942/probabilistic-inference-for-lstm</guid>
      <pubDate>Mon, 01 Jan 2024 04:23:24 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该向 ARIMA 模型添加自变量</title>
      <link>https://stats.stackexchange.com/questions/635941/should-i-even-add-independent-variables-to-an-arima-model</link>
      <description><![CDATA[我用过STATA。我有一个时间序列数据集，其中包含时间（年份和季度）、GDP、CPI（消费者价格指数）、PCE（个人消费支出）和 JAPAN_IP（日本总工业生产）。目的是根据 PCE 解释通货膨胀并预测通货膨胀率。
我做了什么：
我已经记录了 PCE，并首先对记录的 PCE 进行差分以获得年率的季度通胀 (gen inf = 400*(lcpi[_n]-lcpi[_n-1])。然后我使用以下方法测试单位根：ADF 和Phillips Perron 测试。使用 ACF 和 PACF 测试平稳性。然后生成 ARIMA 模型，进行白噪声测试，并预测通货膨胀率。
但是，如果我最初运行回归（reg PCE GDP CPI JAPAN_IP）。所有 P 值均为 0.0000，表明它们之间存在显着性。这是否意味着我可以做我已经做过的所有事情，但是在执行 ARIMA 时将这些变量添加到自变量部分，看看它们如何影响预测。
或者我应该忽略自变量并仅使用 PCE 来预测通货膨胀率，这就是我所做的。
干杯]]></description>
      <guid>https://stats.stackexchange.com/questions/635941/should-i-even-add-independent-variables-to-an-arima-model</guid>
      <pubDate>Mon, 01 Jan 2024 03:04:35 GMT</pubDate>
    </item>
    <item>
      <title>跨多个数据集计算功率参数并拟合 Tweedie 模型</title>
      <link>https://stats.stackexchange.com/questions/635927/calculating-power-parameter-and-fitting-tweedie-model-across-multiple-datasets</link>
      <description><![CDATA[有关研究的信息：

解释变量是三种成分、两种抑制剂及其组合的不同剂量。
响应变量是脂质点及其共定位。原始数据为计数数据。
通过将每个响应变量的值除以对照组的平均值来对数据进行归一化。
数据包括零，这些代表实际测量结果：不存在脂质点。值得注意的是，共定位中零的百分比相当高。

一个数据集中响应变量的汇总统计：

标准化数据的直方图：

当前方法：

我认为 Tweedie 最适合我的数据集，并采取了以下步骤：
查找每种处理的每个响应变量的功效参数 p，然后为其运行 Tweedie 模型，然后应用“emmeans”成对比较：

## Lipid1-Treatment：组件
Lipid1_component= data[data$Treatment %in% &#39;组分&#39;, c(&#39;Lipid1&#39;, &#39;浓度&#39;)]
p_estimate= tweedie.profile(Lipid1 ~ 浓度，数据=脂质1_成分，方法=“系列”)
best_p= p_estimate$xi.max
tweedie_glm= glm(Lipid1 ~ 浓度，family= statmod::tweedie(var.power= best_p，link.power= 0)，data = Lipid1_component)
对（emmeans（tweedie_glm，〜浓度））

## Lipid1-治疗：抑制剂
Lipid1_inhibitor = data[data$Treatment %in% &#39;抑制剂&#39;, c(&#39;Lipid1&#39;, &#39;浓度&#39;)]
p_estimate= tweedie.profile（Lipid1 ~ 浓度，数据= Lipid1_inhibitor，方法=“系列”）
best_p= p_estimate$xi.max
tweedie_glm= glm(Lipid1 ~ 浓度，family= statmod::tweedie(var.power= best_p，link.power= 0)，data = Lipid1_inhibitor)
对（emmeans（tweedie_glm，〜浓度））

## Lipid1-治疗：组合
Lipid1_combination = data[data$Treatment %in% &#39;组合&#39;, c(&#39;Lipid1&#39;, &#39;浓度&#39;)]
p_estimate= tweedie.profile（Lipid1 ~ 浓度，数据= Lipid1_combination，方法=“系列”）
best_p= p_estimate$xi.max
tweedie_glm= glm(Lipid1 ~ 浓度，family= statmod::tweedie(var.power= best_p，link.power= 0)，data= Lipid1_combination)
对（emmeans（tweedie_glm，〜浓度））

问题：

Tweedie 方法是拟合此数据的最佳方法吗？
如果是这样，您认为为所有 30 个数据集的每种治疗方法计算每个响应变量的“p”参数是否明智？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635927/calculating-power-parameter-and-fitting-tweedie-model-across-multiple-datasets</guid>
      <pubDate>Sun, 31 Dec 2023 17:20:13 GMT</pubDate>
    </item>
    <item>
      <title>“成功的项目都具有相同的 5 个关键品质。在每个品质中，我们的项目都取得了超过平均分的成绩”。对此我们能得出什么结论呢？</title>
      <link>https://stats.stackexchange.com/questions/635912/successful-projects-share-the-same-5-keys-qualities-in-each-quality-our-projec</link>
      <description><![CDATA[我不确定这是否是一个统计问题，但我想这是一个涉及使用统计的常见问题，所以我还是在这里问。希望它是主题。
摘自《智能定价：Google、Priceline 和领先企业如何利用定价创新提高盈利能力》一书：
&lt;块引用&gt;
尽管音乐是一项风险很高的行业，但我们发现 Radiohead 的 In Rainbows 活动与任何成功的“按需付费”定价计划具有相同的五个关键品质：

边际成本低的产品
公正的客户
可以以多种价格可靠销售的产品
买方和卖方之间牢固的关系
竞争非常激烈的市场


在每个质量中，我们评估我们的项目的得分高于平均水平，如下所示：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

质量编号
得分（超过 10）


&lt;正文&gt;

1
6


2
7


3
8


4
7


5
7




没有对每种质量进行测量。我们只是根据我们所拥有的进行推理并评估我们的信心。基本上我们只是“感觉数字”。
从中我们可以得出什么结论？我们可以采取哪些技术来证实或否认我们的任何假设？如果我们认为“我们的项目成功的可能性比失败的可能性更大”，我们是否有任何谬误？
相关：是什么阻止了按需付费定价策略变得更受欢迎？ 关于经济学 SE]]></description>
      <guid>https://stats.stackexchange.com/questions/635912/successful-projects-share-the-same-5-keys-qualities-in-each-quality-our-projec</guid>
      <pubDate>Sun, 31 Dec 2023 12:00:20 GMT</pubDate>
    </item>
    <item>
      <title>CLT、欧几里德距离和均值</title>
      <link>https://stats.stackexchange.com/questions/635893/clt-euclidean-distances-and-means</link>
      <description><![CDATA[这可能听起来像是一个相当奇怪的问题，但我偶然发现了一种类似于正态分布的均值分布，但我不确定是否可以证明它确实是一个。这是设置。
假设我抽取了 $n$ 个独立且同分布的随机向量/变量 $ x_1, x_2, 的样本。 ..,x_n$ （我确实使用了特定的发行版，但我认为这并不重要）。现在，我们找到每个随机变量/向量与所有其他变量的欧几里德距离并找到平均值。因此，对于示例中的每个变量 $j = 1,...,n$，我们有：
$$
Y_j = \frac{1}{n-1} \sum_{i \neq j} ||x_j,x_i||
$$
现在，如果我增加 $n$ 并重复绘制这些变量的分布，我会得到越来越像正态分布的东西。这是侥幸还是有更深层次的东西我不明白？毕竟，$Y_j$ 变量并不是彼此独立的，欧几里德距离也不是。
编辑：提供更多上下文细节。每个随机向量 $\mathbf{x_i}$ 有 8094 个分量。每个组件 $m$ 都是独立导出的，如下所示：
$$
x_{im} = \min \{z_1,...,z_{K_m}\}
$$
此处 $z_1,...,z_{K_m}$ 是从带有参数 $[ 1,108]$。我有一个固定向量，它指定每个组件的 $K_m$ （即每个组件的绘制次数）。
这里是模拟的相关 R 代码。我注意到 total 是一个包含 8094 行和一列的数据帧，称为 num。任何整数向量都可以完成这项工作。
&lt;前&gt;&lt;代码&gt;
模拟向量 &lt;- 复制（10000，{
样本 &lt;- lapply(total$num, function(n) 样本(1:108, n, Replace = TRUE))
  min_values &lt;- sapply(样本, 分钟)
  返回（最小值）
})

mat &lt;- t(simulated_vectors)
距离 &lt;- dist(mat)

distances_matrix &lt;- as.matrix(距离)

平均距离 &lt;- 应用（距离矩阵，1，函数（行）{
  (总和(行) - 最小值(行)) / (长度(行) - 1)
})

 hist(average_distances, main = “平均距离直方图”, xlab = “平均距离”)
]]></description>
      <guid>https://stats.stackexchange.com/questions/635893/clt-euclidean-distances-and-means</guid>
      <pubDate>Sat, 30 Dec 2023 23:20:41 GMT</pubDate>
    </item>
    <item>
      <title>没有重复测量的随机效应？</title>
      <link>https://stats.stackexchange.com/questions/635855/random-effects-without-repeated-measures</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635855/random-effects-without-repeated-measures</guid>
      <pubDate>Sat, 30 Dec 2023 06:22:41 GMT</pubDate>
    </item>
    <item>
      <title>Huber 如何计算 $\operatorname{var}(s_n)/E[s_n]^2$ 和 $\operatorname{var}(d_n)/E[d_n]^2$？</title>
      <link>https://stats.stackexchange.com/questions/627174/how-does-huber-compute-the-operatornamevars-n-es-n2-and-operatorname</link>
      <description><![CDATA[ （注意，我从 数学堆栈交换 自从之后
x 天了我仍然没有收到任何回复。）
Huber 在“稳健统计过程”一书的第一章中如何计算某些统计函数的方差？
他将均方差定义为 $$s_n = \sqrt{\frac{1}{n} \sum \left(x_i - \bar{x} \right)^2 }$$
平均绝对偏差为 $$d_n = \frac{1}{n} \sum \| x_i - \bar{x} \|.$$
然后他继续获得渐近相对效率表达式 ARE($\epsilon$)，如图所示。 （因此，我们至少应该在 ARE() 中拥有 for 参数，即
ARE($\epsilon;n,x_i,x$)，对吗？即使 $n \to \infty.$ 在我们发送 $n \to \infty 之前 ARE() 是什么样子$？
第2步的表达式到底是怎么得到的？）
什么是$\operatorname{var}(s_n), E[s_n]$？如何获取这些表达式？
在 @whuber 关于 $x_i$ 的实际假设的评论后添加。
Huber 做出以下假设。 “我们有一大堆随机混合的“好”观察值，它们是正常的 $N(\mu, \sigma^2)$ 和“坏”观察值。正常的 $N(\mu, 9\sigma^2)$，即所有观测值具有相同的平均值，但某些观测值的误差增加了一个因子3. 现在，每个 $x_i$ 都是一个好的，概率为 $(1-\epsilon)$，一个坏的概率为 $\epsilon$，其中 $\epsilon$ 是一个很小的数字。 
最后，他为什么说 1000 个观测值中只有两个不好的观测值就足以抵消均方误差 12% 的优势？是不是有5个不好的观察？请参阅：

在照片中，$\epsilon = 0.005$ 的值为 1.198，我猜这是 (12%)？]]></description>
      <guid>https://stats.stackexchange.com/questions/627174/how-does-huber-compute-the-operatornamevars-n-es-n2-and-operatorname</guid>
      <pubDate>Sun, 24 Sep 2023 13:28:09 GMT</pubDate>
    </item>
    <item>
      <title>对测试集文本（无标签）进行预训练可以吗？</title>
      <link>https://stats.stackexchange.com/questions/611877/is-pretraining-on-test-set-texts-without-labels-ok</link>
      <description><![CDATA[编辑：浏览本文后6，我将这个问题的范围缩小到NLP问题。摘要的相关摘录（强调我自己的）：
&lt;块引用&gt;
我们证明，无监督预处理实际上会给交叉验证估计带来很大的偏差，并可能损害模型选择。 这种偏差可能是正的，也可能是负的，其确切大小以复杂的方式取决于问题的所有参数。

动机
使用测试集标签来训练测试集特征显然是错误的。但在许多机器学习竞赛中，发布测试集功能并允许参与者对其进行训练是标准做法。一个例子是 NLP 中的真实世界注释少样本任务 (RAFT) 基准。1以下摘录自 RAFT论文（强调我自己的）：
&lt;块引用&gt;
对于每项任务，我们都会发布一个包含 50 个示例的公共训练集和一个更大的未标记测试集。 我们鼓励对未标记示例进行无监督预训练和开放域信息检索。

在 RAFT 竞赛中，您可以通过在您可能训练的同一组未标记文本上运行模型来提交预测。在 NLP 中，训练未标记文本的常见方法是训练一个语言模型，该模型根据其他标记来预测标记。将此过程应用于特定域的数据集通常称为“域适应”。
我知道发布测试集功能对于主办竞赛的人很有帮助，因为它允许参与者提交预测而不是模型/代码。我还了解到，在现实世界的模型开发中，您可能观察到大量未标记的文本。但我认为关键的区别在于，在现实世界中，您无法访问样本外文本。
问题
在（样本内）测试集文本上训练模型，然后在相同测试集上评估该模型是否是样本外性能的乐观估计？
一个听起来合理的假设是，对（样本内）测试集文本进行训练会导致测试集预测和测试集标签之间存在相关性，这是一个乐观的估计量（至少对于线性回归，请参见 ESL 中的方程 7.21&lt; sup&gt;2）。但对于这种依赖究竟是如何在没有测试集标签的测试集文本上进行训练而产生的，我没有任何争论。
我的PCA实验结果对机器学习竞赛有重要意义：如果测试很少如果集合观测值和特征表现出高等级，那么可以通过在测试集特征上拟合 PCA 来人为地减少测试集上的误差。
我很好奇是否可以在 NLP 中观察到类似类型的结果，这是标准实践&lt; /a&gt; 在分类任务之前训练未标记文本的语言模型。3 我有一种感觉，部分答案就在论文的某个地方 关于因果和反因果学习4或其子数据收集的因果方向很重要：因果和反因果学习对 NLP 的影响5。这些论文表明，领域适应应该只对文本导致目标的数据有帮助。
参考文献

亚历克斯、尼尔等人。 “RAFT：现实世界的少量文本分类基准。” arXiv 预印本 arXiv:2109.14076 (2021)。

Hastie、Trevor 等人。统计学习的要素：数据挖掘、推理和预测。卷。 2. 纽约：施普林格，2009 年。

Gururangan、Suchin 等人。 “不要停止预训练：使语言模型适应领域和任务。” arXiv 预印本 arXiv:2004.10964 (2020)。

Schölkopf、Bernhard 等人。 “关于因果学习和反因果学习。” arXiv 预印本 arXiv:1206.6471 (2012)。

金志敬，等。 “数据收集的因果方向很重要：因果和反因果学习对 NLP 的影响。” arXiv 预印本 arXiv:2110.03618 (2021)。

莫斯科维奇、阿米特和萨哈龙·罗塞特。 “关于由于无监督预处理导致的交叉验证偏差。”英国皇家统计学会杂志 B 系列：统计方法 84.4 (2022)：1474-1502。

]]></description>
      <guid>https://stats.stackexchange.com/questions/611877/is-pretraining-on-test-set-texts-without-labels-ok</guid>
      <pubDate>Tue, 04 Apr 2023 19:17:08 GMT</pubDate>
    </item>
    <item>
      <title>固定效应的3SLS及其解释问题</title>
      <link>https://stats.stackexchange.com/questions/610004/3sls-with-fixed-effects-and-its-interpretation-issue</link>
      <description><![CDATA[由于同时性引起的潜在内生性问题，我正在运行基于 3SLS 的经验模型。所以，我选择3SLS作为我的主要分析工具，并使用reg3命令来分析它。我的模型和STATA命令如下。
经验模型：DV =截距+ endog_var1 + control1 + ... + control6 + i.industry + i.year + 误差项（在这个模型中，我假设只有一个内生变量，因为我只对var1，并且由于影响两者的不可观察因素，DV 和 var1 之间可能存在潜在的同时性偏差，我计划使用一种仪器来消除偏差。）
STATA命令：reg3（DV endog_var1 control1 control2 control3 control4 control5 control6 i.industry i.Year）（endog_var1 DV Instrument1 i.industry i.Year）
实际上，当我运行固定效应模型时，DV 和 endog_var1 分别与 DV 和 IV 相反（即模型 1：DV = 截距 + endog_var1 + control1 + ... + control6 + i.industry + i.年 + 误差项和模型 2：endog var1 = 截距 + DV + control1 + ... + control6 + i.industry + i.year + 误差项），无论哪种方式，我都可以发现 DV 和 endog_var1 的系数为具有相当的统计意义。
但是，如果我运行上面的 STATA 命令，我只能在第二阶段看到显着的 endog_var1，但在 3SLS 的第一阶段（reg3 中的第二个括号）中 DV 变得微不足道（p 值 &gt; 0.1）型号。
总而言之，我的问题有四个。 

我是否也应该将所有控制变量放入 3SLS 模型中的第一阶段（reg3 模型中的第二个括号）？ （但是，我不断收到警告，例如方程未识别 - 不满足订单条件。

运行 3SLS 模型后，当 DV 变得不显着时如何解释？ （endog_var1 DV Instrument1 i.industry i.Year；此处，DV 不重要。）

如果我想将固定效应添加到模型中，如何将它们添加到 STATA 命令中？ 

如果我在第一阶段设置一个没有 DV 的模型，如 reg3 (DV endog_var1 control1 control2 control3 control4 control5 control6 i.industry i.Year) (endog_var1 Instrument1 i.industry i.Year)，会怎样？该模型是否仍能解决我的模型可能存在的同时性偏差？


感谢您阅读这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/610004/3sls-with-fixed-effects-and-its-interpretation-issue</guid>
      <pubDate>Sun, 19 Mar 2023 22:17:31 GMT</pubDate>
    </item>
    <item>
      <title>如何“选择”对回归有很大影响的二元变量？</title>
      <link>https://stats.stackexchange.com/questions/561236/how-to-choose-binary-variables-which-have-a-big-impact-on-a-regression</link>
      <description><![CDATA[我目前在分析项目数据时遇到问题。
我有大约 100.000 个样本的数据集。我有大约 50 列，它们都是二进制，我的因变量是时间（以小时为单位）。每一行显示产品所经历的流程记录，无论产品是否经过指定的“停止”。
我的目标不是做出预测，而是做出解释/推论。
假设我的数据集如下所示：
​

&lt;表类=“s-表”&gt;
&lt;标题&gt;

stop1
stop2
stop3
stop4
...
时间


&lt;正文&gt;

1
0
0
1
...
23.35


1
0
0
1
...
8.26


1
0
1
1
...
200.06


...
...
...
...
...
...


0
1
0
0
...
1.71


1
1
1
1
...
2.03




如何“测量”这些变量对最终时间的影响如何？我想象做一个简单的线性回归可以让我深入了解“影响”是什么。不同的二元变量中的哪一个取决于从属变量？
您如何决定将哪些变量用于回归以及将哪些变量保留在一边，因为它们与模型不“相关”。到最终的因变量？
（同样，这是为了了解特定的停止是否比其他停止花费更多的时间，如果是这样，我应该更多地研究它，而不是为了预测。）]]></description>
      <guid>https://stats.stackexchange.com/questions/561236/how-to-choose-binary-variables-which-have-a-big-impact-on-a-regression</guid>
      <pubDate>Thu, 20 Jan 2022 16:58:26 GMT</pubDate>
    </item>
    <item>
      <title>如何计算低维主成分分析中的重构误差</title>
      <link>https://stats.stackexchange.com/questions/492953/how-to-compute-the-reconstruction-error-in-principal-component-analysis-at-lower</link>
      <description><![CDATA[我有 m 个示例和 d 个特征，其中 m&lt;
所以我的原始数据集具有形状
&lt;前&gt;&lt;代码&gt;(m, d)

如果我采用 n 个主成分，其中 n  d，变换后的矩阵矩阵将具有形状
&lt;前&gt;&lt;代码&gt;(m, n)

因此，由于形状不匹配，我真的无法找到任何方法来计算重建误差]]></description>
      <guid>https://stats.stackexchange.com/questions/492953/how-to-compute-the-reconstruction-error-in-principal-component-analysis-at-lower</guid>
      <pubDate>Wed, 21 Oct 2020 06:33:38 GMT</pubDate>
    </item>
    </channel>
</rss>