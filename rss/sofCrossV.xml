<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Fri, 14 Mar 2025 01:18:31 GMT</lastBuildDate>
    <item>
      <title>ACF或PACF的强烈时间依赖性</title>
      <link>https://stats.stackexchange.com/questions/662587/strong-temporal-dependency-with-acf-or-pacf</link>
      <description><![CDATA[我正在使用时间序列数据，其中每天由包含24×25网格的CSV文件表示，每个条目都充当像素。
我已经生成了ACF和PACF来了解我的数据的时间结构，并且整天都使用了第一个功能：
 导入statsmodels.api as s sm
导入matplotlib.pyplot作为PLT

系列= data_flatted [：，0]＃整天使用第一个功能
图，轴= plt.subplot（2，1，无花果=（10，8））
sm.graphics.tsa.plot_acf（系列，滞后= 30，ax = axes [0]）
sm.graphics.tsa.plot_pacf（系列，滞后= 30，ax = axes [1]）
plt.show（）
 
我的输出：
  从上图中，我会说短暂滞后的强大相关性表明时间依赖性很大吗？
或
我的意思是问我的数据集有任何重复模式或趋势？
或
所有数据点都可能遵循一些简单的确定性线性结构方程，并具有一些小的白噪声？
或我的数据集中存在强大的时间依赖性？]]></description>
      <guid>https://stats.stackexchange.com/questions/662587/strong-temporal-dependency-with-acf-or-pacf</guid>
      <pubDate>Fri, 14 Mar 2025 00:47:24 GMT</pubDate>
    </item>
    <item>
      <title>使用测试集评估小样本中的模型：Bootstrap与LOOCV</title>
      <link>https://stats.stackexchange.com/questions/662584/evaluating-a-model-in-a-small-sample-using-a-test-set-bootstrap-vs-loocv</link>
      <description><![CDATA[线程 评估具有小样本的分类器 考虑了其标题中的问题。具体而言，问题是要多次从其他数据分开测试集，而不仅仅是一次以减少样本外部性能的估计值的可变性。
戴夫的回答建议遵循弗兰克·哈雷尔（Frank Harrell）的建议。用戴夫的话来说，

他对样本外测试的建议是通过对整个数据集的替换，在该新样本上构建模型，评估整个数据集上的模型性能，并将此性能与在完整数据集中受过训练和评估的模型的性能进行比较。这是重复的数十个，数百或数千次，以获得性能差异的分布。再次，他的RMS书讨论了这一点。

在一个小样本中对我来说似乎直觉的另一种方法是（允许计算资源！）进行嵌套的剩余交叉验证（LOOCV）。也就是说，在外循环中，将单个观察结果分为测试集。然后在内部循环中do loocv选择和调整模型。厕所而不是k折应最大程度地减少偏见，这在处理小样本时可能非常重要，而且这里的情况也是如此。我想相对于k折的loo的差异可能是一个问题，也可能不是一个问题。在这里）。
 cbeleites在对第一个链接线程的评论中警告我，这可能不是一个好主意。我在这里发布此信息以弄清楚细节。因此，我的问题是，弗兰克·哈雷尔（Frank Harrell）的方法比我的方法更可取，如果是，我的方法的主要缺点是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/662584/evaluating-a-model-in-a-small-sample-using-a-test-set-bootstrap-vs-loocv</guid>
      <pubDate>Thu, 13 Mar 2025 19:29:28 GMT</pubDate>
    </item>
    <item>
      <title>高等教育对GDP的影响（独立变量 - 支出和入学，控制 - 人口和失业，依赖GDP）Regsion [关闭]</title>
      <link>https://stats.stackexchange.com/questions/662583/impact-of-higher-education-on-gdp-independent-variables-expenditure-and-enrol</link>
      <description><![CDATA[该研究涉及8个已发达（欧洲）和8个发展中国家（亚洲）国家的数据。
独立支出，注册
依赖性GDP
控制 - 失业和人口增长
 1）支出对发展中国家和发达国家增长的影响

 入学人数对上述国家增长的影响

 控制变量对发展中国家GDP的影响是什么

 开发和发展之间的发现的相似性和差异。


什么是合适的方法？固定，随机的，正常的回归？
应该使用杜米变量吗？为了什么？如何？
我不考虑时间效应/滞后]]></description>
      <guid>https://stats.stackexchange.com/questions/662583/impact-of-higher-education-on-gdp-independent-variables-expenditure-and-enrol</guid>
      <pubDate>Thu, 13 Mar 2025 18:57:42 GMT</pubDate>
    </item>
    <item>
      <title>比较火星中相互作用项的效果大小（Earth Package，r）</title>
      <link>https://stats.stackexchange.com/questions/662581/comparing-effect-sizes-of-interaction-terms-in-mars-earth-package-r</link>
      <description><![CDATA[我正在使用R中的接地软件包运行多元自适应回归条纹（MARS）。
我想知道如何比较不同交互项的效果大小（或模型中的所有术语）？
我知道evimp（）根据GCV计算可变重要性，但它不能为交互项提供重要的分数。我认为标准化Beta系数不是有用的，因为我的模型既包含分类和连续的预测指标。 
谢谢您的任何想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/662581/comparing-effect-sizes-of-interaction-terms-in-mars-earth-package-r</guid>
      <pubDate>Thu, 13 Mar 2025 18:44:05 GMT</pubDate>
    </item>
    <item>
      <title>非固定状态更新方程式气体模型</title>
      <link>https://stats.stackexchange.com/questions/662580/non-stationary-state-update-equation-gas-model</link>
      <description><![CDATA[是否有必要在气体模型中具有固定状态上的方程？
我的状态更新等式对增长率建模
我的方程式定义为：
 gamma_t = 0.002 + 0.25 *得分 + 1.025 * gamma_ {t-1} 
这个方程是非平稳的，因为我们具有1.025，这可能会导致伽马的爆炸行为。但是有必要静止吗？这些参数意味着伽马？]]></description>
      <guid>https://stats.stackexchange.com/questions/662580/non-stationary-state-update-equation-gas-model</guid>
      <pubDate>Thu, 13 Mar 2025 18:36:12 GMT</pubDate>
    </item>
    <item>
      <title>如果一个变量在个人之间持续不变，我可以使用面板数据吗？</title>
      <link>https://stats.stackexchange.com/questions/662578/can-i-use-panel-data-if-one-variable-is-constant-across-individuals</link>
      <description><![CDATA[我正在研究一个小组模型，以分析地缘政治风险对商品市场的影响，但我遇到了挑战。由于商品价格是全球的，因此随着时间的流逝而不同。 
随着时间的推移，使用相同的价格值对不同国家/地区使用相同的价格值是有效的，或者这会使面板模型不适合分析？
这是我的模型：
 pcpi =α +β1.gpr +β2.EPU +β3.VIX + DCOV + DGFC +ε

 pcpi：的国家i的主要商品价格指数
 gpr：国家的地缘政治风险指数
 epu：t。
 vix：cboe波动率指数i在时间t。
 dcov：covid-19虚拟变量。
 DGFC：全球金融危机虚拟变量。
ε：错误项。

预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662578/can-i-use-panel-data-if-one-variable-is-constant-across-individuals</guid>
      <pubDate>Thu, 13 Mar 2025 17:57:07 GMT</pubDate>
    </item>
    <item>
      <title>多维数据的相关性</title>
      <link>https://stats.stackexchange.com/questions/662575/correlation-of-multi-dimensional-data</link>
      <description><![CDATA[我做了一个实验，我要求18个人阅读12条短裤文字。他们阅读了每个文本后，我要求他们评分他们对文本的享受程度，并写下他们在阅读时的眨眼率。我想使用我的数据来了解眨眼速度与阅读享受相对应的程度。我可以看到三种方法：
 a）我可以采用与每个文本示例相对应的平均眨眼率和平均享受，这给了我一组十二对值，我可以计算出。的相关性。
 b）对于每个参与者， $ p $ ，我可以计算如何 $ p $ 的眨眼率和文本享受相关，然后取出18个值的平均值。
 c）我可以做与（b）中相同的事情，但是对于每个文本示例（也许这会给我与（b）中的结果相同的结果？
所有这些选项似乎都不好。有更好的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662575/correlation-of-multi-dimensional-data</guid>
      <pubDate>Thu, 13 Mar 2025 17:42:44 GMT</pubDate>
    </item>
    <item>
      <title>如何计算PCA的标尺不变重建错误？</title>
      <link>https://stats.stackexchange.com/questions/662573/how-to-compute-a-scale-invariant-reconstruction-error-for-pca</link>
      <description><![CDATA[我正在使用主成分分析（PCA）并试图评估重建误差。具体而言，我有兴趣能够在不同规模的数据上比较PCA的结果（MinMax与标准尺度与未量化数据）。我看到的标准方法是计算原始数据和重建数据之间的根平方误差（RMSE）：
 rmse
 $$
\ text {rmse} = \ sqrt {\ frac {1} {n} {n} \ sum || x- \ hat {x} ||^2}
$$ 
其中：
  $ x $ &lt; /span&gt;是原始数据集，
 $ \ hat {x} $ &lt; /span&gt;是PCA之后的重建数据集，
 $ n $ 是样本的数量。
但是，RMSE受数据规模的影响。如果我的数据集以不同的单位（例如原始数据与标准化数据）为单位，则绝对RMSE值不直接可比。这使得很难确定PCA在不同尺度上的表现更好还是更糟。
提出的替代方案：归一化重建误差
为了使重建误差量表不变，我正在考虑通过原始数据中的总差异将其归一化：
归一化重建误差
 $$
\ text {归一化重建错误} = \ frac {\ sum || x- \ hat {x} ||^2} {\ sum || x- \ bar {x} ||^2}
$$ 

在哪里
 $ \ bar {x} $ 是原始数据的均值。
此归一化确保误差表示为总方差的一部分，从而可以在不同的缩放技术（例如Minmaxscaler vs. StandardsCaler）之间进行比较。
问题：
这是将PCA重建错误归一化的合适方法吗？
PCA中是否还有其他标准标准不变的指标来比较具有不同尺度的数据集的重建错误（或其他指标）？
这是声音吗？
对规模不变的PCA重建错误的现有工作的任何见解或参考将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/662573/how-to-compute-a-scale-invariant-reconstruction-error-for-pca</guid>
      <pubDate>Thu, 13 Mar 2025 17:32:11 GMT</pubDate>
    </item>
    <item>
      <title>分析植物社区数量和覆盖数据的最统计学上最正确的方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/662571/what-is-the-most-statistically-correct-way-to-analyze-plant-community-count-and</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662571/what-is-the-most-statistically-correct-way-to-analyze-plant-community-count-and</guid>
      <pubDate>Thu, 13 Mar 2025 16:30:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么负概率密度是不正确的评分规则？反例？</title>
      <link>https://stats.stackexchange.com/questions/662570/why-is-negative-probability-density-an-improper-scoring-rule-a-counterexample</link>
      <description><![CDATA[ gneiting＆amp; Katzfuss（2014）讨论（除其他外）评估密度预测的适当评分规则。引用论文（第133页），

 定义4：评分规则 $ s：f \ times r \ rightarrow \ bar r $ 相对于类 $ \ nathcal {f}
 $$ s（g，g）\ leq s（f，g）\ tag {1} $$ 
对于所有 $ f，g \ in \ Mathcal {f} $ 。如果方程式 $ 1 $ 仅在 $ f = g $ 。

以及

 定理3：得分规则 $ s $ 相对于类 $ \ nathcal {f} $ ，仅当预期得分函数 $ e $ e（$ e e（$ e e（f）， class =“数学container”&gt; $ s（f，\ cdot）$ 是 $ e $ 在点 $ f $  $  $ f $ 的超级gradeient

他们指出，线性得分， $ s（f，y）=  -  f（y）$ （即，在目标随机变量实现时评估的负概率密度函数）不是正确的得分规则，因为它不是超级级别。他们引用了Ovcharov（2013）。我在任何地方都找不到Ovcharov（2013）。此外，我并不是想研究涉及凸分析和超级成分的证据。这听起来很技术！
相反，我想了解 intuition 为什么线性得分不是适当的得分规则。理想情况下，我想要一个示例展示某个密度 $ f \ neq g $ 比真实密度 $ g $ 连续随机变量 参考： 

 gneiting，T。，＆amp; Katzfuss，M。（2014年）。 概率的预测。 125-151。
 Ovcharov E.2013。多变量的本地适当评分规则。 Heidelberg大学应用数学研究所工作论文。
]]></description>
      <guid>https://stats.stackexchange.com/questions/662570/why-is-negative-probability-density-an-improper-scoring-rule-a-counterexample</guid>
      <pubDate>Thu, 13 Mar 2025 16:21:21 GMT</pubDate>
    </item>
    <item>
      <title>我可以将Fisher的Z变换用于非显着相关性吗？</title>
      <link>https://stats.stackexchange.com/questions/662568/can-i-use-fishers-z-transformation-on-non-significant-correlations</link>
      <description><![CDATA[我试图找出使用Fisher的Z变换来评估两个相关系数之间关系强度的差异是否合适。我可以这样做：
 a）两个非显着相关
b）一个显着的相关性和一个不重要的相关性？
我正在寻找一个可靠的来源来引用，但我很难在任何地方找到适合这种技术的地方。]]></description>
      <guid>https://stats.stackexchange.com/questions/662568/can-i-use-fishers-z-transformation-on-non-significant-correlations</guid>
      <pubDate>Thu, 13 Mar 2025 15:51:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在MonoBit测试中确定阈值，为什么要比5％的显着性水平高1％？</title>
      <link>https://stats.stackexchange.com/questions/662552/how-is-the-threshold-determined-in-the-monobit-test-and-why-is-it-larger-for-a</link>
      <description><![CDATA[在随机性的单托测试中，通过或失败的阈值基于置信区间。我了解到1％的显着性水平（99％的置信度）导致阈值较大，而显着性水平为5％（95％的置信度）。
然而，这似乎是违反直觉的 - 由于较高的信心应该意味着与预期的50:50比率更少的偏差，为什么它允许在零数量和零之间有更大的差异？更严格的测试（较低的alpha）不需要较小的偏差吗？
有人可以澄清阈值是如何设定的，为什么会发生这种行为？
我尝试的是：我审查了单片测试公式，该公式根据对应于所选置信度的z得分设置阈值。我还研究了95％和99％置信度的临界值是从正态分布中得出的。
我期望的是：我期望较高的置信度（99％）会导致更严格的测试，这意味着允许的数量和零之间的差异较小。
实际发生的事情：相反，我发现较高的置信度（99％）允许在零和零之间差异更大，而95％则允许置信度更大。这似乎是违反直觉的，因为我认为更严格的测试应该忍受较小的偏差。我想澄清为什么这是数学上会发生的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662552/how-is-the-threshold-determined-in-the-monobit-test-and-why-is-it-larger-for-a</guid>
      <pubDate>Thu, 13 Mar 2025 05:18:08 GMT</pubDate>
    </item>
    <item>
      <title>减轻多个残差连接的效果</title>
      <link>https://stats.stackexchange.com/questions/662550/mitigate-the-effect-of-multiple-residual-connections</link>
      <description><![CDATA[我最近遇到了一个问题，我无法根据我的先前知识回答（注意：不是作业，我已经毕业了）：
假设，我们在具有前层归一化的变压器中使用多个残差连接（即在层开始时层标准），我们假设每个残差都独立地分布在某种程度上，那么其总和的方差就会增长到添加的数量。例如，如果我们有2个残差，那么方差就可以达到极端水平，例如3-4个数量级。因此，在培训期间，我们将遇到具有精度和二元效应的问题（层变为-1或1），并且梯度将变得很小（接近0）。
我们该怎么做才能避免这些问题？
我认为，为避免这些问题，我们必须弄清楚如何在这些残差连接之间进行检查。我的第一个思想是围绕在这些残差连接之间应用层归一化的，以使方差恢复到正常水平。但是，由于我们已经具有层归一化，因此这种想法显然是错误的。另外，这显然也会导致梯度爆炸。
您还可以提供与此问题相关的一些理论（或参考文献）吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662550/mitigate-the-effect-of-multiple-residual-connections</guid>
      <pubDate>Thu, 13 Mar 2025 02:25:05 GMT</pubDate>
    </item>
    <item>
      <title>了解一致MLE的判别模型中X条件的数学必要性</title>
      <link>https://stats.stackexchange.com/questions/662417/understanding-the-mathematical-necessity-of-conditions-on-x-in-discriminative-mo</link>
      <description><![CDATA[我以前曾问了两个问题，可以解决相关问题：

In this answer to my question about the intuition behind the conditions on the design matrix $X$ (or the predictors), the answer provided insight into why such conditions are needed to ensure consistency of discriminative model估算器。
我从这个答案是，如果log-likelihoodhiehoodhiehienhiphienhighie proments  $ log（f_i logi lim 
问题是：
   $ x $ 在派别模型中施加的详细数学推理是什么？具体？并具有相同的条件模型 $ P（y | x）$ ？
我正在寻找一种严格的解释或派生，将第一个答案中提供的直觉与数学要求联系起来，以确保可能性贡献不会“吹”。或消失，从而影响估计程序的整体一致性。
对有关此主题的进一步文献的任何见解，证明或参考，都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/662417/understanding-the-mathematical-necessity-of-conditions-on-x-in-discriminative-mo</guid>
      <pubDate>Mon, 10 Mar 2025 16:59:45 GMT</pubDate>
    </item>
    <item>
      <title>跨时间的纵向受试者的γ/HGAM不同组的纵向受试者</title>
      <link>https://stats.stackexchange.com/questions/662362/gamm-hgam-for-longitudinal-subjects-across-time-in-different-groups</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662362/gamm-hgam-for-longitudinal-subjects-across-time-in-different-groups</guid>
      <pubDate>Sun, 09 Mar 2025 02:21:04 GMT</pubDate>
    </item>
    </channel>
</rss>