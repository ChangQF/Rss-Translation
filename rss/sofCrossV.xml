<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 30 Jul 2024 12:28:50 GMT</lastBuildDate>
    <item>
      <title>对 p 值和 Cohen's d 感到困惑</title>
      <link>https://stats.stackexchange.com/questions/652003/confused-about-the-p-value-and-cohens-d</link>
      <description><![CDATA[我有以下代码，用于计算 p 值和 cohen 距离。
import numpy as np
from scipy.stats import ttest_ind
import matplotlib.pyplot as plt

# 计算 Cohen 的 d
def calculate_cohens_d(group1, group2):
mean_group1 = np.mean(group1)
mean_group2 = np.mean(group2)
std_group1 = np.std(group1, ddof=1)
std_group2 = np.std(group2, ddof=1)
n_group1 = len(group1)
n_group2 = len(group2)
pooled_std = np.sqrt(((n_group1 - 1) * (std_group1 ** 2) + (n_group2 - 1) * (std_group2 ** 2)) / (n_group1 + n_group2 - 2))
cohen_d = (mean_group1 - mean_group2) / pooled_std
return cohen_d

# 模拟数据并执行 t 检验和 Cohen&#39;s d 计算的函数
def perform_experiment():
# 模拟数据
group1_EXP = np.random.normal(80, 10, 10)
group2_EXP = np.random.normal(81, 10, 10)

# 执行多重 t 检验
_, p_value_EXP = ttest_ind(group1_EXP, group2_EXP)
cohen_d_EXP = calculate_cohens_d(group1_EXP, group2_EXP)

return p_value_EXP, cohen_d_EXP


如果我使用给定的种子运行代码两次：
# 可重复性的种子
np.random.seed(42)

# 执行 2 次实验
p_value_EXP, cohen_d_EXP = perform_experiment()
print(f&#39;p-value: {p_value_EXP:.4f}, Cohen\&#39;s d: {cohen_d_EXP:.4f}&#39;)

p_value_EXP, cohen_d_EXP = perform_experiment()
print(f&#39;p-value: {p_value_EXP:.4f}, Cohen\&#39;s d: {cohen_d_EXP:.4f}&#39;)

我得到：
p-value: 0.0029， Cohen 的 d：1.5402
p 值：0.9792，Cohen 的 d：-0.0118

因此可以说，第一个实验的 p 值为 0.0029，Cohen 距离“较大”，是显著的。
相比之下，我会说第二个实验并不那么重要。
现在，如果我运行 1,000 次模拟
# 执行 1000 次实验

n_simulations = 1000

p_values_EXP = np.zeros(n_simulations)

cohen_ds_EXP = np.zeros(n_simulations)

for i in range(n_simulations):
p_values_EXP[i], cohen_ds_EXP[i] = perform_experiment()

# 计算 p 值 &gt; 的比例0.05
prop_p_value_EXP_greater_0_05 = np.mean(p_values_EXP &gt; 0.05)

print(&quot;Proportion of p-values &gt; 0.05:&quot;, prop_p_value_EXP_greater_0_05)

我得到
Proportion of p-values &gt; 0.05: 0.951

这意味着更有可能观察到不显著的结果。但前 2 个实验显示相反的结果。
因此，我不确定在这种情况下 Cohen 距离的用处。]]></description>
      <guid>https://stats.stackexchange.com/questions/652003/confused-about-the-p-value-and-cohens-d</guid>
      <pubDate>Tue, 30 Jul 2024 12:20:20 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 SYSTEMFIT 如何工作（从统计角度来看）？</title>
      <link>https://stats.stackexchange.com/questions/652002/how-does-systemfit-from-r-work-from-statistical-perspective</link>
      <description><![CDATA[在 R 中，有一个使用 OLS 估计方程组的包，称为 SYSTEMFIT。最初，这个包似乎并没有增加太多的价值，因为我实际上可以通过 OLS 分别估计每个方程（多次使用函数“lm()”）......除了一种情况，当我需要对方程进行限制时，这是我无法通过单独估计方程来做到的......这让我意识到我甚至无法想象这个包是如何工作的以及如何将多个方程作为一个系统来估计。

所以，首先：我们有两个方程A和B。
\begin{align}
\text{A)} \qquad y_1 &amp; = \alpha_0 + \alpha_1 x_1 + \alpha_2 x_2 + \alpha_3 x_3 + u \\
\text{B)} \qquad y_1 &amp; = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + v \\
\end{align&gt;
现在，我可以通过 $\boldsymbol{\hat\beta} = \left(\mathbf{X}&#39; \mathbf{X} \right)^{-1} \mathbf{X}&#39; \mathbf{Y}$ 分别估计两个方程，或者通过 SYSTEMFIT 将其作为一个系统估计，并得到相同的结果。
现在，如果我有一个单方程假设，即 $\alpha_2 = 1$，我可以用两种方式简单地解决这个问题，使用两个方程的单独估计：
案例 1：我只需在方程中代入正确的值，相应地移动它，然后通过 OLS 估算新方程：
$$
y_1 - 1 \cdot x_2= \alpha_0 + \alpha_1 x_1 + \alpha_3 x_3 + u
$$
案例 2：或者，我可以提出一个限制矩阵 $\boldsymbol{R} = [0,0,1,0]$，右侧向量 $r = [1]$，然后将新模型参数估算为 $\boldsymbol{\hat\beta}_p = \boldsymbol{\hat\beta} - \left(\mathbf{X}&#39; \mathbf{X} \right)^{-1} \boldsymbol{R}&#39;\boldsymbol{R} \left(\mathbf{X}&#39; \mathbf{X} \right)^{-1} \boldsymbol{R}&#39; ( \boldsymbol{R} \boldsymbol{\hat\beta} - r )$

尽管如此，如果我想将其应用于跨方程假设即$\alpha_2 = \beta_2$，我不知道该怎么做。案例 1 和案例 2 在该场景中均不适用。我只能通过 SYSTEMFIT 编写代码，它的语法相对简单。但是我没有看到代码内部。
所以，问题是：SYSTEMFIT 如何将两个方程作为一个系统进行估算，以及如何根据限制进行调整；或者，我们一般如何做到这一点（我们应该使用哪个方程）？]]></description>
      <guid>https://stats.stackexchange.com/questions/652002/how-does-systemfit-from-r-work-from-statistical-perspective</guid>
      <pubDate>Tue, 30 Jul 2024 11:50:06 GMT</pubDate>
    </item>
    <item>
      <title>控制变量时的多重共线性</title>
      <link>https://stats.stackexchange.com/questions/652000/multicollinearity-when-controlling-for-a-variable</link>
      <description><![CDATA[我对数据中的多重共线性有几个问题：我正在查看 MRI 扫描中发现的某种类型的病变；对于每位患者，我都知道这些病变的体积以及捕捉其分布模式的指标。我对模式指标对临床评分的影响感兴趣，而不仅仅是体积的影响。然而，模式指标与体积高度相关（r = 0.7），这是事物的本质，因为病变在大脑中覆盖的面积越大，它们就越成为一个有凝聚力的区域的一部分，而不是单独的斑点。这让我想知道一些事情：

在像临床评分 ~ 模式 + 体积这样的回归中是否存在多重共线性问题？缓解这样的问题似乎违背了我想要看到的目的。
模式指标已根据体积进行了校正，即每个人的指标已除以该人的病变体积。如果体积已经以某种方式纳入，我是否仍需要在回归中考虑体积？
如果我想进行相关性而不是回归，那么 a) 考虑体积后临床评分和模式指标的偏相关性与 b) 临床评分和残差模式指标的相关性（在将模式指标回归到体积后）之间有什么区别？
当我计算临床评分和残差模式指标的相关性时，相关性高于残差之前，这是正常观察结果吗？我注意到临床评分和体积的相关性为负，而临床评分和模式的相关性为正，鉴于模式和体积的相关性为正且很大，我不确定这是否表明出了问题。也许这就是为什么残差化后与临床评分的相关性更高的原因？有没有更深入的分析方法？

提前谢谢您！
]]></description>
      <guid>https://stats.stackexchange.com/questions/652000/multicollinearity-when-controlling-for-a-variable</guid>
      <pubDate>Tue, 30 Jul 2024 11:23:33 GMT</pubDate>
    </item>
    <item>
      <title>在一个非常简单的情况下解释由 R acf 函数计算的自相关</title>
      <link>https://stats.stackexchange.com/questions/651999/interpreting-autocorrelation-as-computed-by-r-acf-function-in-a-very-simple-case</link>
      <description><![CDATA[我曾经以为我知道自相关是什么，并且 R 中的 acf 函数会产生我所理解的自相关函数，但我一定遗漏了一些细节，因为结果不是我所期望的。
我的理解是，自相关是一系列与自身的相关性，并移开了一些滞后。例如，如果 x=1:10，则存在自相关：
&gt; # lag 0
&gt; cor(1:10, 1:10)
[1] 1
&gt; # lag 1
&gt; cor(1:9,2:10)
[1] 1
&gt; # lag 2
&gt; cor(1:8,3:10)
[1] 1

也就是说，对于线性序列，任何滞后时间的自相关都应该为 1。
但是，这不是 acf 函数的结果：
acf(1:10)

&gt; acf(1:10)[0:9]

序列‘1:10’的滞后自相关

0 1 2 3 4 5 6 7 8 9 
1.000 0.700 0.412 0.148 -0.079 -0.258 -0.376 -0.421 -0.382 -0.245 

这显然不同于我通过滞后序列计算出的自相关。
我猜 acf 函数在某种程度上校正了样本大小，因为当样本大小没有太大变化时差异较小（例如，使用 1:1000 而不是 1:10）。此外，我预计图中的蓝色虚线显著性会随着样本量的减少而向外扩展，但它被绘制为一条水平线，因此由于阈值没有向外扩展，因此向内校正相关性以保持阈值的显著性不变是合理的。
那么问题是：

acf 是否校正了样本量？如果答案是肯定的，它如何校正样本量？
该校正是否解释了通过滞后序列计算出的相关性与 acf 函数的结果之间的差异？
如果不是，我对自相关是什么以及 acf 的作用的理解是否错误？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651999/interpreting-autocorrelation-as-computed-by-r-acf-function-in-a-very-simple-case</guid>
      <pubDate>Tue, 30 Jul 2024 11:15:48 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用嵌套交叉验证中的投票来获得估计量吗？</title>
      <link>https://stats.stackexchange.com/questions/651998/can-i-use-voting-in-nested-cross-validation-to-obtain-estimator</link>
      <description><![CDATA[新手警告：首次发帖，所以请保持温柔 :-)
我研究过嵌套交叉验证（例如在这篇 Medium 文章中）。我知道我能够从外循环中获得平均分数，并且这些分数应该比从任意训练/测试分割中获得的分数更好地估计泛化能力。
获得模型的性能很棒，但最终不是我的目标。我想要的是做出预测，比如在二元分类问题中。理想情况下，我希望估算器的表现与我从嵌套交叉验证中获得的平均分数一样。
因此，我所做的是在外循环中对从估算器获得的预测实施一个简单的投票机制。
来自 sklearn.model_selection 导入 cross_val_score
来自 sklearn.ensemble 导入 RandomForestClassifier
来自 sklearn.model_selection 导入 GridSearchCV、KFold
来自 sklearn.metrics 导入 roc_auc_score
来自 sklearn.datasets 导入 make_classification

# 示例数据集
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)

# 要调整的超参数
param_grid = {
&#39;n_estimators&#39;: [50, 100],
&#39;max_depth&#39;: [None, 10, 20],
}
# 用于超参数调整的内部 CV
grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, verbose=1,scoring=&#39;roc_auc&#39;)
# 用于模型评估的外部 CV
outer_cv = KFold(n_splits=5)
results = cross_validate(grid_search, X, y, cv=outer_cv,scoring=&#39;roc_auc&#39;,return_estimator=True)
y_predictions = np.ndarray((len(results[&#39;estimator&#39;]), len(X), 2))
estimators = results[&#39;estimator&#39;]
for i, estimator in enumerate(estimators):
# 现在我们需要对每个样本进行投票
y_pred = estimator.predict_proba(X)
y_predictions[i] = y_pred

# 现在我们可以计算平均预测
y_pred = y_predictions.mean(axis=0)
# 并使用 argmax 获得最可能的类
y_pred = np.argmax(y_pred, axis=1)

print(&quot;ROC AUC: &quot;, roc_auc_score(y, y_pred))
print(classification_report(y, y_pred))

但是，这个估计器的性能接近完美，显然表明过度拟合。
我的假设错了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651998/can-i-use-voting-in-nested-cross-validation-to-obtain-estimator</guid>
      <pubDate>Tue, 30 Jul 2024 10:53:32 GMT</pubDate>
    </item>
    <item>
      <title>如何在 huggingface 模型上执行模型截断/切片？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651997/how-would-you-perform-model-truncating-slicing-on-a-huggingface-model</link>
      <description><![CDATA[嗨，我想知道是否有任何方法可以在 pytorch 上对 Huggingface CV 模型（例如 MobileNetv1）执行模型切片/截断？据我搜索，互联网上大多数主题都与 Transformers 有关。我想知道是否可以截断 CV 模型，如果可以，如何操作？]]></description>
      <guid>https://stats.stackexchange.com/questions/651997/how-would-you-perform-model-truncating-slicing-on-a-huggingface-model</guid>
      <pubDate>Tue, 30 Jul 2024 10:23:43 GMT</pubDate>
    </item>
    <item>
      <title>温度矩阵的比较——统计结果不符合实际情况？</title>
      <link>https://stats.stackexchange.com/questions/651993/comparison-of-temperature-matrix-statistical-result-not-practical-reality</link>
      <description><![CDATA[我遇到了以下问题：我想在 Python 中比较热图像（数据以大矩阵/每个像素一个值的形式存在，50x300，数字介于 800 和 1000,0 摄氏度之间）并确定它们是否不同。只有在实际发生相关变化时，图片才应该传输到服务器。因此，比较的是新图片和前一张图片。我想找到一种自动执行此过程的方法/算法。哪些统计方法是相关的？
我有几个数据集，并且知道其中一些数据应该在测试中被视为不同，而另一些数据则被视为相似（由专家事先评估）。我尝试了配对 t 检验、Wilcoxon 检验，并对图片中的不同感兴趣区域进行检验。结果总是图像明显不同。这不是实际情况。有些图片实际上没有区别。
是否有未考虑的不同测试/修改测试的方法？统计检验是否不适合这个问题？有什么建议可以指导我如何继续？]]></description>
      <guid>https://stats.stackexchange.com/questions/651993/comparison-of-temperature-matrix-statistical-result-not-practical-reality</guid>
      <pubDate>Tue, 30 Jul 2024 09:28:46 GMT</pubDate>
    </item>
    <item>
      <title>线性回归模型构建：我是否需要包含之前证明对模型很重要的变量？</title>
      <link>https://stats.stackexchange.com/questions/651992/linear-regression-model-building-do-i-need-to-include-variables-previously-prov</link>
      <description><![CDATA[对于线性回归入门课程的学校项目，我们需要分析三个研究问题：

肥料类型会影响玉米产量吗？（产量 ~ 肥料）
玉米品种会影响玉米产量吗？（产量 ~ 品种）
环境/管理因素会影响玉米产量吗？（降雨、温度、除草剂使用等）

当我分析前两个研究问题（方差分析 + t 检验）时，我发现肥料类型确实似乎显著影响玉米产量，而玉米品种则不会。现在对于第三个研究问题，我想知道我是否需要在线性模型中包含肥料类型，因为我已经知道它很重要，或者我是否可以将其排除在外，因为我正在尝试在这个问题中找到肥料类型以外的其他变量的影响，并且可折叠性在这里适用。]]></description>
      <guid>https://stats.stackexchange.com/questions/651992/linear-regression-model-building-do-i-need-to-include-variables-previously-prov</guid>
      <pubDate>Tue, 30 Jul 2024 08:56:32 GMT</pubDate>
    </item>
    <item>
      <title>具有协变量的短文本无监督聚类</title>
      <link>https://stats.stackexchange.com/questions/651991/unsupervised-clustering-of-short-texts-with-covariates</link>
      <description><![CDATA[我在 Data Science Stack Exchange 上发布了这篇文章，但没有收到任何回复（该网站似乎没什么人气）。所以我在这里尝试！
我正在做一个项目，需要对短文本进行分类。我事先不知道主题，所以这项工作是无人监督的。
目前，我正在使用双词主题模型 (BTM)。我看到了一些不错的结果。
但是，我们的语料库带有许多可以解释主题流行度的协变量。例如，来自 X 国的文本更有可能来自主题 Y。
在估计主题流行度时，如何利用这些协变量并获得更好的分类？通常我会使用结构主题模型，但我认为我的文本不够长（大概 5-30 个字）。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/651991/unsupervised-clustering-of-short-texts-with-covariates</guid>
      <pubDate>Tue, 30 Jul 2024 08:23:35 GMT</pubDate>
    </item>
    <item>
      <title>测量误差模型中“朴素”估计量的渐近方差</title>
      <link>https://stats.stackexchange.com/questions/651990/asymptotic-variance-of-the-naive-estimator-in-measurement-error-model</link>
      <description><![CDATA[考虑经典测量误差模型：
$Y= \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon$
其中 $W=X+U$ 是观察到的。X 是“真实”数量，U 是测量误差。 Var$(X) = \Sigma_x$，Var$(U) = \Sigma_U$。
“朴素”估计量$\hat{\beta}_{\text{naive}} = (W^TW)^{-1}W^TY$是$\beta = (\beta_1, \beta_2)^T$的 OLS 估计量。一个众所周知的结果是 E$(\hat{\beta}_{\text{naive}}) = \Lambda \beta$，其中 $\Lambda = \Sigma_x (\Sigma_x + \Sigma_u)^{-1}$
我对“朴素”估计量的渐近方差感兴趣，其中 $\Sigma_x$ 和 $ \Sigma_u$ 已知。根据非线性模型中的测量误差 - Carrol (2006)中的结果，我相当有信心，$p=1$ 情况下的渐近方差由$\frac{\sigma^2_\epsilon + \beta^2 \sigma^2_x \frac{\sigma^2_u}{\sigma^2_u + \sigma^2_x}}{n (\sigma^2_u + \sigma^2_x)}$ 给出，如果这有帮助的话。]]></description>
      <guid>https://stats.stackexchange.com/questions/651990/asymptotic-variance-of-the-naive-estimator-in-measurement-error-model</guid>
      <pubDate>Tue, 30 Jul 2024 07:55:40 GMT</pubDate>
    </item>
    <item>
      <title>simr 包：powerCurve 给出的结果与 powerSim 不同</title>
      <link>https://stats.stackexchange.com/questions/651989/simr-package-powercurve-does-not-give-the-same-results-as-powersim</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651989/simr-package-powercurve-does-not-give-the-same-results-as-powersim</guid>
      <pubDate>Tue, 30 Jul 2024 07:24:50 GMT</pubDate>
    </item>
    <item>
      <title>证明线性模型</title>
      <link>https://stats.stackexchange.com/questions/651987/justifying-a-linear-model</link>
      <description><![CDATA[我对两个变量之间的关联很感兴趣，即认知扭曲和总体痛苦（分别在 0 到 40 和 0 到 10 的范围内）。Spearman 等级检验表明存在正相关，因此为了研究这种关联的强度，我会直观地使用线性回归来量化痛苦随着认知扭曲的每个增加单位分数而变化的程度。
我想知道基于像所附数据集这样的数据集，线性回归是否是一个合理的模型。独立性、正态分布和方差相等假设都得到满足（基于 Breusch-Pagan 测试）。或者其他模型更合适？
一个相关但略有不同的问题：使用 Kolmogorov-Smirnov 或 Shapiro 检验进行正态性检验是否一定需要？我注意到它们表明在检查时“看起来”正常的数据存在非正态性。
我会将该模型描述为解释性的而不是预测性的。如果我认为线性模型适合检查散点图，我该如何正式证明这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/651987/justifying-a-linear-model</guid>
      <pubDate>Tue, 30 Jul 2024 06:56:26 GMT</pubDate>
    </item>
    <item>
      <title>我对委内瑞拉选举投票总数可能性的推理是否有效？</title>
      <link>https://stats.stackexchange.com/questions/651986/is-my-reasoning-about-the-likelihood-of-the-venezuelan-election-vote-totals-vali</link>
      <description><![CDATA[我不是统计人员，所以我很容易犯错误，但这似乎很简单。
考虑一下委内瑞拉选举机构 Consejo Nacional Electoral 在马杜罗获胜公告中给出的数字，这是他们迄今为止提供的唯一官方信息：
尼古拉斯·马杜罗以 51.2% 的选票获胜，埃德蒙多·冈萨雷斯·乌鲁蒂亚获得 44.2%，其他候选人获得 4.6%
他们还提供了每个人的投票总数：分别为 5150092、4445978 和 462704。
看看这些数字在百分比方面等于多少：
(5150092 * 100) / 10058774 = 51.19999713682801
(4445978 * 100) / 10058774 = 44.1999989263105
(462704 * 100) / 10058774 = 4.600003936861491
这几乎精确地代表了 51.2%、44.2% 和 4.6%，精度在四个九之内。事实上，如果你在马杜罗或乌鲁蒂亚的选票总数上增加一票，或者从其他候选人中减去一票，你就会让他们的选票超过十分之一的界限。
我试图弄清楚这些候选人的选票总数都达到这一界限的几率，我得出的结论是大约 2500 万分之一。可能性极小，但并非完全不可能。我的理由如下：
如果你将投票总数简化为大约 1000 万人投票，这已经足够接近了，那么十分之一就是 1 万人。因此每 10,000 张选票都会多出一位小数点。
但是，由于我们允许数字在小数点以上或以下各有一位选民，因此候选人获得总票数达到此门槛的概率为 10,000 分之 2 或 5,000 分之 1。
如果有第二位候选人达到门槛，那么考虑到已经是 5,000 分之 1 的概率，这个概率就是 5,000 分之 1，也就是 5,000 分之 1 的平方或 2,500 万分之 1。
您可以将此逻辑扩展到第三位候选人（或“其他”候选人的合并），但如果选票只有三个部分，那么前两次出现意味着最后一位候选人也将达到相同的门槛。
因此，2,500 万分之一，对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651986/is-my-reasoning-about-the-likelihood-of-the-venezuelan-election-vote-totals-vali</guid>
      <pubDate>Tue, 30 Jul 2024 06:37:57 GMT</pubDate>
    </item>
    <item>
      <title>参考请求：柯西分布随机变量族在线性分式变换下封闭的历史</title>
      <link>https://stats.stackexchange.com/questions/651982/reference-request-history-of-the-fact-that-the-family-of-cauchy-distributed-ran</link>
      <description><![CDATA[我在 MathOverflow 上询问了这个问题，但几乎没有人关注，也没有人回答。
假设一个位置尺度概率分布族具有这样的属性：如果随机变量 $X$ 的分布属于该族，并且 $a,b,c,d\in \mathbb R$ 和 $ad-bc\ne0$ 则 $(aX+b)/(cX+d)$ 的分布也属于该族。那么这就是柯西分布族。这在 Frank B. Knight 的《柯西型的特征》中得到了证明，Proc. Amer. Math. Soc. 55 (1976), 130–135.
一个更简单的结果是其逆命题：柯西型分布族在该运算下是封闭的。
应该引用哪些书籍或论文来表明这个更简单的命题，即 Knight 论文所说的逆命题，已经存在了一段时间？]]></description>
      <guid>https://stats.stackexchange.com/questions/651982/reference-request-history-of-the-fact-that-the-family-of-cauchy-distributed-ran</guid>
      <pubDate>Tue, 30 Jul 2024 02:57:46 GMT</pubDate>
    </item>
    <item>
      <title>比较非负随机变量的分数矩</title>
      <link>https://stats.stackexchange.com/questions/651978/comparing-fractional-moments-of-non-negative-random-variables</link>
      <description><![CDATA[假设我有非负随机变量$X,Y$，服从$\langle X\rangle = \langle Y \rangle = 1$，并且假设$X$的所有其他整数矩都大于或等于$Y$的矩。
是否可以得出，对于$ a \geq 1$，它们的分数矩$\langle X^a \rangle \geq \langle Y^a \rangle$？
如果有反例，如果我另外保证$X,Y$是有界非负 RV？
我尝试使用 Noel Cressie 和 Marinus Borkent 中所述的矩生成函数来计算分数矩：“矩生成函数有其矩”，《统计规划与推断杂志》13 (1986) 337-344（参见示例计算的
独立平方均匀随机变量之和的平方根期望的指导性答案），但无法对积分设置任何界限。]]></description>
      <guid>https://stats.stackexchange.com/questions/651978/comparing-fractional-moments-of-non-negative-random-variables</guid>
      <pubDate>Tue, 30 Jul 2024 00:38:13 GMT</pubDate>
    </item>
    </channel>
</rss>