<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 12 Jan 2025 15:15:37 GMT</lastBuildDate>
    <item>
      <title>GLMM 的倾斜独立变量的变换</title>
      <link>https://stats.stackexchange.com/questions/659915/transformation-of-skewed-independent-variables-for-glmms</link>
      <description><![CDATA[我正在使用 glmmTMB R 包构建具有随机效应的广义线性混合模型。我有一组连续固定变量，其中许多变量表现出高偏度和峰度。我在各种网站上看到，高度偏斜的固定变量可能会产生过度的杠杆作用，可能会掩盖其他变量的影响，因此建议进行转换以提高其正态性。不幸的是，这些建议没有附带对已发布来源的引用。
我的问题是：我如何确保转换固定变量是最佳方法？您能否提供详细解释此主题的已发表论文或书籍的参考资料？
我尝试通过根据情况对这些变量应用 log、yj 和 sqrt 转换（然后进行缩放）来解决这个问题。我观察到结果发生了积极的变化，一些变量获得了统计意义。新结果确实有意义，但我不确定这是否是正确的方法。
PS：我已经使用 DHARMa 诊断检查了模型，使用转换后的变量和原始变量均未发现任何问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/659915/transformation-of-skewed-independent-variables-for-glmms</guid>
      <pubDate>Sun, 12 Jan 2025 13:15:04 GMT</pubDate>
    </item>
    <item>
      <title>时间序列回归的滚动 PCA：信息泄露</title>
      <link>https://stats.stackexchange.com/questions/659913/rolling-pca-for-time-series-regression-information-leakage</link>
      <description><![CDATA[假设一个随机变量$y_{i,t}$由一些线性因子$x_{t,j}$和一个随机噪声项$\epsilon_{i,t+1}$控制：
$$
y_{i,t} = \sum_{j}^{M+1}\beta_{j,i}x_{t,j} + \epsilon_{i,t+1}
$$
写得更紧凑：
$$
\mathbf{Y} = \mathbf{X}\mathbf{\beta} + \mathbf{E}
$$
其中，

$\mathbf{Y}$ 是一个 $(T,N)$ 矩阵
$\mathbf{X}$ 是一个 $(T,M)$ 矩阵
$\beta$ 是一个 $(M,N)$ 时不变参数矩阵，用于解释 $M$ 个因素对 $N$ 个随机变量的影响。
$\mathbf{E}$ 是一个 $(T,N)$ 矩阵，包含 $T$ 个误差项，维度为 $N$，即 $E \sim N(0,\Sigma_{\epsilon})$

使用这种因子模型，我们可以更稳健地分解和估计均值和方差，因为 $
\mathbb{X}$ 的维度要小得多，即 $M&lt;&lt;N$。
$$
\mathbb{E}_{t|t-1}[\mathbf{Y}] = \mathbf{\mu}_{t} = \mathbf{x}_{t}\mathbf{\beta} \\
\mathbb{V}_{t|t-1}[\mathbf{Y}] = \mathbf{\Sigma}_{t} = \mathbf{x}_{t}\Sigma_{x}\mathbf{x}_{t}^{T} + \Sigma_{\epsilon}
$$
我选择 PCA 作为统计潜在因子，而我的估计选择是时间序列回归方式。我是否对贬低的$\mathbf{Y}$进行 SVD 或对经验协方差进行 PCA 并不重要，假设我进行前者。回归现在将是：
$$
y_{i,t} = \sum_{j}^{M+1}\beta_{j,i}PC_{t,j} + \epsilon_{i,t+1}
$$
这里出现的问题是 $PC_{t,j}$ 已使用 整个 $
\mathbf{Y}$ 矩阵进行估计，即它依赖于 $y_{i,t+1}, y_{i,t+2}, ... y_{i,T}$，因此存在信息泄露。
我可以选择进行滚动 PCA。使用移动窗口 $t$ 来 $t+w$ 估计 PCA，并得出 $PC_{t+w}$。但是，我需要 $PC_{t+w}$ 为标量，而不是向量，否则在上述问题中 $\mathbf{X}$ 变为三维（PC 数量、次数、窗口数量）。在这种情况下如何执行滚动 PCA？]]></description>
      <guid>https://stats.stackexchange.com/questions/659913/rolling-pca-for-time-series-regression-information-leakage</guid>
      <pubDate>Sun, 12 Jan 2025 12:28:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用引导程序处理大规模文本匹配和不确定性？</title>
      <link>https://stats.stackexchange.com/questions/659912/how-to-handle-large-scale-text-matching-and-uncertainty-with-bootstrap</link>
      <description><![CDATA[我有一个大型数据库，其中有一个字符列，其中包含数百万个产品描述。我有一个参考表，其中有一个字符列，其中包含我试图匹配的描述。我将使用 EXACT 匹配、IN 匹配和最终的 Levenshtein 距离进行匹配。然后我想计算匹配次数。有时会出现错误匹配，例如参考词包含在一个不匹配的大词中，这更像是参考数据的异常。所以我还想在组合中添加不确定性。我不会在完成后检查所有匹配，因为匹配实在太多了。
我对此有两个疑问：

我知道如何进行匹配。这不是问题。我想计算匹配次数，并说我们怀疑 3 月份有 200 次匹配。我们不知道误报率，但它很小（我们怀疑）。参考列表由另一个部门保存。假阳性可能由包含单词的产品引起，例如 shoe 可能包含在 Shoehorn 中。引导捆绑是一种我可以使用的方法吗？逐月从数据库中提取数据，然后应用匹配。这将为我提供该月的总匹配数，然后从每月样本中进行引导（10k 个案例 5000 次，并将这些案例相加并计算置信区间。

假设 A 是正确的。在理想情况下，我会这样做，其中一行包含一个产品实例。但是数据库很大。是否可以先在数据库中聚合 Shoehorn - 100 个匹配项。然后进行引导。这不会给我一个完全不同的答案吗，因为抽样不再在 100 个匹配项中随机抽样，它会将 Shoehorn - 100 个匹配项作为单个记录进行抽样。


所以我的问题是第一点是否是解决这个问题的有用方法，第二点是关于如何聚合数据对置信区间的有效性的影响。
下面是一些 R 代码，它生成数据的两种方法出现
# 加载必要的库
library(dplyr)

# 生成逐行数据 ----------------------------------------------------------
# 生成具有随机卷的虚假产品描述数据
set.seed(123)
descriptions &lt;- c(
&#39;红色鞋子&#39;, &#39;蓝色衬衫&#39;, &#39;绿色鞋带&#39;, &#39;黄色鞋拔&#39;, 
&#39;黑色帽子&#39;, &#39;白色鞋子&#39;, &#39;粉色衬衫&#39;, &#39;灰色帽子&#39;, 
&#39;紫色鞋拔&#39;, &#39;橙色鞋带&#39;
)
volumes &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)

product_descriptions &lt;- data.frame(
ProductID = unlist(lapply(1:10, function(i) rep(i, volumes[i]))),
Description = unlist(lapply(1:10, function(i) rep(descriptions[i], volumes[i]))),
Volume = unlist(lapply(1:10, function(i) rep(volumes[i], volumes[i])))
)

# 随机抽取 5000 行并替换以生成逐行产品
set.seed(456) # 设置种子以实现可重复性
line_by_line_df &lt;- product_descriptions %&gt;%
sample_n(5000, replace = TRUE) |&gt; 
mutate(ProductID = row_number()) %&gt;% 
mutate(match = sample(0:1, n(), replace = TRUE))

# 生成聚合数据 -------------------------------------------------
# 在这里我们从&quot;database&quot; 中提取并汇总数据库中的计数
aggregated_df &lt;- line_by_line_df |&gt; 
group_by(Description) |&gt; 
summarise(total_products = sum(Volume),
matches = sum(match))

]]></description>
      <guid>https://stats.stackexchange.com/questions/659912/how-to-handle-large-scale-text-matching-and-uncertainty-with-bootstrap</guid>
      <pubDate>Sun, 12 Jan 2025 12:03:38 GMT</pubDate>
    </item>
    <item>
      <title>如果水平为 $\alpha$ 的假设检验对我的实际样本拒绝，那么所有水平 > $\alpha$ 的检验是否也会拒绝同一个样本？</title>
      <link>https://stats.stackexchange.com/questions/659910/if-a-hypothesis-test-with-level-alpha-rejects-for-my-realized-sample-will-al</link>
      <description><![CDATA[问题：如果水平为 $\alpha$ 的假设检验拒绝了一个已实现样本，那么水平 &gt; $\alpha$ 的所有检验是否也会拒绝同一个样本？
正式地：让 $\hat{\psi}_{\alpha} \in \{0, 1\}$ 成为我的水平为 $\alpha$ 的检验。我获得一个已实现样本 $x_{obs} = \left( x_1, ..., x_n \right)^{T}$，并获得了拒绝的决定，即 $\hat{\psi}_{\alpha}(x_{obs}) = 1$。这是否意味着同一家族（即相同的零模型和备选模型，以及相同的检验统计量）但水平为 $&gt; \alpha$ 的任何检验也将拒绝 $H_0$？我们将这样的检验称为 $\hat{\psi}_{&gt; \alpha}$。
更直观地，如果我们考虑单调递增的级别序列$\{\alpha\}_{0 \le \alpha \le 1}$，我们有相应的测试$\{\hat{\psi}_{\alpha}\}_{0 \le \alpha \le 1}$和决策$\{\hat{\psi}_{\alpha}(x_{obs})\}_{0 \le \alpha \le 1}$，是否可以保证我的决策序列看起来像 00000000111111...，或者可能是像 00001010001111... 这样的序列？
我看到一些幻灯片中有人断言了这一说法（幻灯片 3 和 4 上的橙色框，“请注意...”位于 https://pages.stat.wisc.edu/~shao/stat610/stat610-13.pdf）：

请注意，inf({t ∈ (0, 1) : $T_t(x_{obs})$ 拒绝 $H_0$}) ≤ α 意味着 $T_α(x_{obs})$ 拒绝 $H_0$。

但我觉得它唯一正确的方法是，如果拒绝域序列 $\{RR_{\alpha}\}_{0 \le \alpha \le 1}$ 随着级别的增加而成为彼此的超集。我认为这一般不能保证吗？对于某些特定类别的测试，例如 UMP 测试，它有保证吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659910/if-a-hypothesis-test-with-level-alpha-rejects-for-my-realized-sample-will-al</guid>
      <pubDate>Sun, 12 Jan 2025 11:35:17 GMT</pubDate>
    </item>
    <item>
      <title>不存在负负数据时的评分者间信度</title>
      <link>https://stats.stackexchange.com/questions/659908/inter-rater-reliability-when-negative-negative-data-does-not-exist</link>
      <description><![CDATA[我想分析口语表达以确定隐喻的使用。两位评分员将独立分析全文，并识别、计数和列出他们发现的隐喻。然后将比较他们的列表以查看一致性。可能的结果是两位评分员都同意某个语言实例是隐喻，或者一位评分员发现/识别出某个语言实例是隐喻，但另一位评分员不同意（他们实际上不同意）。Cohen Kappa 通常用于两人评分者间信度。问题是，在我描述的研究中，不会有任何负负一致性的机会，即两位评分员都将一段语言识别为非隐喻（大多数文本都不是隐喻，这是一个寻找语言的问题）。这可能会导致数据偏差，因为观察到的一致性可能看起来很低，因为没有负负一致性。是否有替代的 Cohen Kappa 来解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659908/inter-rater-reliability-when-negative-negative-data-does-not-exist</guid>
      <pubDate>Sun, 12 Jan 2025 10:38:46 GMT</pubDate>
    </item>
    <item>
      <title>估计混合效应模型后，如何使用附加数据更新新组的随机效应？</title>
      <link>https://stats.stackexchange.com/questions/659906/how-to-update-random-effects-for-a-new-group-with-additional-data-after-estimati</link>
      <description><![CDATA[问题。在估计混合效应模型后，如何更新随机效应以适应具有额外数​​据的新组，从而实现准确预测？
目标。我有水污染物浓度的纵向数据，每个单位（即样品采集点）的观测次数随时间变化，范围在 1 到 10 之间。除了在同一地点重复测量外，这些地点还按水系统聚类（由于共用管道），而水系统又按地理区域聚类（由于共用水源）。研究目的是创建一个预测模型，以准确预测预测站点未来时间点的水污染物浓度，理想情况下具有可解释的预测、置信度或可信区间。预测地点及其水系统可能包括在模型开发样本中，也可能不包括在内，但将提供其历史数据（包括响应和预测因子），而这些数据在模型估计时不可用。
现有方法。我的理解是，最合适的模型类型是具有时间趋势平滑函数的混合效应 Cox 比例风险模型，因为 Cox 模型对于严格正响应和非检测删失具有分布自由的灵活性。但我不认为模型类型在特定地点预测的方法中很重要。因此，为了概念简单起见，我们可以在线性混合模型下进行讨论。随机效应方差可能很大，尤其是聚集在地理区域聚集的水系统中的收集点的随机截距。因此，控制新组的随机效应对于减少预测误差非常重要。我注意到，在混合效应模型的后估计例程中，有几个统计软件包允许新组，例如 R 软件包 lme4 在 predict() 中提供了参数 allow.new.levels = 。但是，启用此参数将 (1) 将所有随机系数设置为 0，并为新组提供非常大的标准误差（完全包括随机效应的不确定性）或 (2) 将随机系数设置为其组特定的最佳线性无偏预测因子（BLUP、条件模式或经验贝叶斯估计），并为现有组提供非常小的标准误差（我推测不包括任何随机效应的不确定性）。我认为它们都不符合我的目标。
暂定方法。我认为我应该利用在模型估计后在模型部署期间提交的预测站点的历史数据，以减少预测误差。我的计划如下。

使用频率论框架和包下的模型开发样本估计模型。提交新站点数据后，结合模型开发样本和新站点数据重新估计模型。使用模型开发样本是因为新站点数据的样本量可能太小，无法估计所有参数。为了加速重新估计的收敛，在先前的点估计中设置固定系数和随机效应方差（或其他一些估计量，如对数标准差）的起始值。然后将 predict() 应用于重新估计的模型，其中新站点成为现有组。但是，当参数 re.form = NULL 包含所有随机效应时，我不知道预测标准误差中包含和不包含什么类型的不确定性。
使用贝叶斯框架和包下的模型开发样本估计模型。提交新站点数据后，仅使用新站点数据拟合新模型，并将先验设置为先前估计的后验分布。我认为在重新拟合过程中不需要大量的模型开发样本，因为其信息包含在所选先验中。如果先验很强，贝叶斯模型似乎在样本量小于参数数量时有效。但我对线性混合效应模型的解读表明，BLUP 是由整个响应系列生成的，因此仅使用新站点数据可能不足以对随机效应给出良好的估计。但是，如果我结合模型开发样本和新站点数据来重新估计模型，模型拟合过程可能会花费太长时间，最终用户无法接受。

我想到了上述两个选项，但我没有理论和实践经验来支持任何一个。你有什么建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/659906/how-to-update-random-effects-for-a-new-group-with-additional-data-after-estimati</guid>
      <pubDate>Sun, 12 Jan 2025 08:14:53 GMT</pubDate>
    </item>
    <item>
      <title>DDPM 中的 $p_{\theta}(x_{t-1} | x_t)$ 仍然是条件 pdf 吗？</title>
      <link>https://stats.stackexchange.com/questions/659905/is-p-thetax-t-1-x-t-in-ddpm-still-a-conditional-pdf</link>
      <description><![CDATA[我正在阅读这篇论文（第 5 页中间），内容是关于去噪扩散模式。在逆向过程中，它指出我们无法直接计算$q(x_{t-1} | x_t)$，因此我们改为使用$p_{\theta}(x_{t-1} | x_t)$来近似它。如果我错了请纠正我，但我相信$q(x_{t-1} | x_t)$是给定$\mathbf{X}_{t}$的随机变量$\mathbf{X}_{t-1}$的条件pdf。这是否意味着近似值$p_{\theta}$也是条件pdf？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659905/is-p-thetax-t-1-x-t-in-ddpm-still-a-conditional-pdf</guid>
      <pubDate>Sun, 12 Jan 2025 08:12:11 GMT</pubDate>
    </item>
    <item>
      <title>并行化蒙特卡罗模拟最简单的方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/659889/what-is-the-easist-way-to-parallelize-a-monte-carlo-simulation</link>
      <description><![CDATA[据我所知，并行化蒙特卡罗模拟归结为将问题分解为子问题，并行运行它们以产生多个马尔可夫链，最后将马尔可夫链连接在一起。
现在的问题是，没有直接的方法来连接马尔可夫链。
并行化蒙特卡罗模拟最简单的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659889/what-is-the-easist-way-to-parallelize-a-monte-carlo-simulation</guid>
      <pubDate>Sat, 11 Jan 2025 18:02:09 GMT</pubDate>
    </item>
    <item>
      <title>无法拟合高斯混合模型，估计错误参数</title>
      <link>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</link>
      <description><![CDATA[下面的测试从高斯混合模型生成样本，然后对其进行拟合。
拟合模型与原始模型完全不同。为什么？这怎么可能呢，结果不只是稍微不同——错误是巨大的。

原文：weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2]
拟合：weights=[0.525, 0.475], means=[-0.617, 0.716], sigmas=[1.434, 1.443]
代码（带图的完整代码)
import numpy as np
from sklearn.mixture import GaussianMixture

def fit_normal_mixture(*, n_components, values, random_state, n_init):
values = np.array(values).reshape(-1, 1) # 转换为 2D 数组
nmm = GaussianMixture(n_components, covariance_type=&#39;diag&#39;, random_state=random_state, n_init=n_init)
nmm.fit(values)
means = nmm.means_.flatten().tolist()
sigmas = np.sqrt(nmm.covariances_.flatten()).tolist()
weights = nmm.weights_.flatten().tolist()
return weights, means, sigmas

def sample_normal_mixture(*, weights, means, sigmas, n):
if not np.isclose(sum(weights), 1):
raise ValueError(&quot;Weights must sum to 1&quot;)
components = np.random.choice(len(weights), size=n, p=weights)
return np.random.normal(loc=np.array(means)[components], scale=np.array(sigmas)[components])

# 测试
if __name__ == &#39;__main__&#39;:
# 从正态混合模型生成样本
nmm_sample = sample_normal_mixture(weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2], n=10000)

# 将样本拟合到正态混合模型
print(fit_normal_mixture(n_components=2, values=nmm_sample, random_state=0, n_init = 10))

附言：是否可以告诉拟合算法使用 0 作为平均值？]]></description>
      <guid>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</guid>
      <pubDate>Sat, 11 Jan 2025 06:59:18 GMT</pubDate>
    </item>
    <item>
      <title>对称单峰分布系列，其中峰度与峰值成反比？</title>
      <link>https://stats.stackexchange.com/questions/659400/family-of-symmetric-unimodal-distributions-where-kurtosis-is-inversely-related</link>
      <description><![CDATA[DeCarlo 于 1997 年在著名期刊《心理学方法》上发表了论文《论峰度的意义和用途》。该论文被广泛引用（引用次数超过 1500 次，其中 129 次“极具影响力”），人们仍然在文献和网络内容中频繁引用该论文。然而，摘要的第一句话指出：

对于对称单峰分布，正 [过量] 峰度表示
相对于正态分布，尾部较重且呈尖峰状，而负 [过量] 峰度表示尾部较轻且呈平坦状。

这种说法在尖峰状和平坦状方面是不正确的，并且无疑导致了“尖峰状/平坦状”现象的持续存在尽管最近的研究彻底推翻了峰度可以衡量分布的峰值或平坦度（无论是对称分布还是单峰分布）的观点，但这种误解仍然难以消除。
如果给出一组对称单峰分布，其中峰度降低时分布变得更加尖锐，峰度增加时分布变得更加平顶，这将有助于消除这种误解。
（编辑：由于“峰值”定义不明确，因此出于本练习的目的，可以将其操作为标准化变量分布的高度。）
这种对称单峰族的一个简单示例是$\{F_1, F_2\}$，其中$F_1$ 和 $F_2$ 在 维基百科页面 中给出：$F_1$ 是参数为 $0.5$ 和 $1$ 的 beta 分布与其关于 $0.0$ 的反射的均等混合，而 $F_2$ 是 $−1$ 和 $1$ 具有 $T(4.0000001)$ 学生 t 分布，混合概率为 $0.999$ 和 $0.001$。在这个家族中，峰度较高的分布较低，并且看起来完全是平顶的，而峰度较低的（和“platykurtic”）分布则无限尖峰。
然而，描述一个更传统的无限家族 $F_{\theta}$ 会很有趣，其中 $\theta$ 连续变化，峰度范围从“platykurtic” ($&lt;3$) 到无穷大，并且分布（所有对称和单峰）的范围从无限峰值到几乎平顶，因为峰度范围从最小值到无穷大。
有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659400/family-of-symmetric-unimodal-distributions-where-kurtosis-is-inversely-related</guid>
      <pubDate>Tue, 31 Dec 2024 17:07:42 GMT</pubDate>
    </item>
    <item>
      <title>混合模型中部分合并聚类估计消失或超出总体估计</title>
      <link>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</link>
      <description><![CDATA[我认为我对混合模型中部分池化的主要目标和特征有相当好的理解。然而，部分池化的实际执行中有一些细节与我期望从各个集群得到的行为相冲突。例如，在下面我将链接的所有三个演示中，使用了各种表达式来表明特定于集群的截距和斜率估计应该向样本中相应的总体估计移动（也允许保持静止）。但是，如果您仔细跟踪集群估计从无池化到部分池化版本的一些可视化运动，您可以看到集群估计实际上如何沿着各个轴远离总体估计。在某些情况下，集群估计值也可能超出总体估计值。
https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/
https://towardsdatascience.com/when-mixed-effects-hierarchical-models-fail-pooling-and-uncertainty-77e667823ae8
https://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/（编辑：不幸的是，动画不再可见，至少在我的浏览器中）。
至少定义集群截距重新定位的公式（参见上面的中间链接和此视频讲座）表明，单个集群的移动范围应该限制在初始无池位置和总体估计值之间（据我所知，如有必要，请纠正我）。但是，上述相互矛盾的观察结果是否与同一模型中随机截距和斜率的存在及其相关性有关？我还没有拿尺子，但我的直觉也告诉我，尽管聚类估计值可以沿着单个轴发散，但也许在部分池化期间整体斜边会变小。错误：我实际上拿了尺子，通过从屏幕上测量，由于部分池化，至少一个整体距离增加了（参见最后列出的网站、df = create_data(sd_int = .25, sd_slope = 1) 的图和右上角的一个聚类）。
如果观察到的行为不是由错误引起的，而且我没有误解什么，那么原因是否可以从直观的实际意义上得到解释。为什么这种行为是有益的，尽管它似乎与部分池化的主要原则不一致。为什么所有聚类估计值不应该沿着截距轴和斜率轴更接近总体估计值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</guid>
      <pubDate>Thu, 19 Dec 2024 12:35:28 GMT</pubDate>
    </item>
    <item>
      <title>DF 和 ADF 检验结果相矛盾</title>
      <link>https://stats.stackexchange.com/questions/657656/conflicting-results-in-df-and-adf-tests</link>
      <description><![CDATA[我正在对 globtemp 数据集进行单位根检验，该数据集显然是具有趋势和季节性（非平稳）的序列。但是，当应用简单的 Dickey-Fuller 检验时，我获得的 p 值很小，导致拒绝零假设并表明该序列是平稳的。
同时，使用增强版本 (ADF) 执行测试，使用 R 的默认滞后数 (k)，p 值不会拒绝零假设，表明时间序列是非平稳的。话虽如此，我很困惑，不明白这种差异。为什么在简单的 DF 测试（k=0）的情况下，测试无法产生真实的结果？此外，如果测试对“k”的选择如此敏感，那么最好的方法是什么？我们应该始终依赖默认值吗？
此外，我读到残差中存在自相关违反了测试中残差不相关的假设，可能会导致错误的结果。因此，我还评估了第一次测试（DF）残差中是否存在自相关，它们的行为与白噪声的行为一致（我也使用 Box-Ljung 对此进行了测试）。这让我对上面提到的不一致的结果更加困惑。
可以检查下面我所做的代码：
library(tseries)

globtemp &lt;- stats::ts(
c(-0.32, -0.32, -0.4, -0.39, -0.65, -0.43, -0.4, -0.52, -0.3, -0.12,
-0.4, -0.42, -0.39, -0.45, -0.35, -0.36, -0.19, -0.14, -0.37, -0.22,
0, -0.08, -0.24, -0.36, -0.49, -0.27, -0.19, -0.43, -0.29, -0.3,
    -0.29、-0.29、-0.28、-0.23、-0.04、-0.02、-0.24、-0.42、-0.35、-0.16、
    -0.17、-0.09、-0.13、-0.16、-0.14、-0.14、0.1、-0.03、0.03、-0.18、
    -0.06、0.04、0.02、-0.13、0.03、-0.06、0.02、0.13、0.13、-0.03、
    0.15、0.12、0.1、0.04、0.11、-0.04、0.01、  0.13、-0.01、-0.06、
    -0.14、-0.02、0.04、0.14、-0.07、-0.06、-0.17、0.1、0.1、0.05、
    -0.01、0.08、0.02、0.02、-0.26、-0.16、-0.09、-0.02、-0.12、0.03、
    0.04、-0.11、-0.07、0.19、-0.07、-0.05、-0.22、0.16、0.09、0.14、
    0.28、0.39、0.07、0.29、0.11、0.11、0.16、 0.32, 0.35, 0.25,
0.47, 0.41, 0.13),
start=1880, end = 1992)

plot(globtemp)

adf.test(globtemp, k=0) #DF 检验
#Dickey-Fuller = -3.4235, 滞后阶数 = 4, p 值 = 0.05414

dx &lt;- diff(globtemp) 
x_lag &lt;- globtemp[-length(globtemp)] 
df_model &lt;- lm(dx ~ x_lag) 
summary(df_model)

residuals_df &lt;- resid(df_model)
acf(residuals_df, 50, main = &quot;&quot;) #否自相关
Box.test(residuals_df, lag = 15, type = &quot;Ljung-Box&quot;)

adf.test(globtemp) #ADF 默认为 &quot;k&quot;
#Dickey-Fuller = -3.4235, 滞后阶数 = 4, p 值 = 0.05414
]]></description>
      <guid>https://stats.stackexchange.com/questions/657656/conflicting-results-in-df-and-adf-tests</guid>
      <pubDate>Fri, 22 Nov 2024 04:44:14 GMT</pubDate>
    </item>
    <item>
      <title>纵向研究中的缺失数据；SPSS；Python</title>
      <link>https://stats.stackexchange.com/questions/649990/missing-data-in-longitudinal-study-spss-python</link>
      <description><![CDATA[我有一个心理学领域的数据集，有 3 个测量点（纵向数据）、4 份问卷和大约 120 名参与者。这个数据集中有很多缺失数据。我需要清理数据并准备进行相关性、MANOVA 等分析……如果我删除所有参与者，则只剩下不到一半的样本。此外，我需要对所有问卷使用相同的样本（我认为）。然而，数据是分散的：例如：一名参与者完成了所有问卷（A、B、C），除了问卷 D，他跳过了观察 2 和 3。在这种情况下，他们可以包括在问卷 A、B、C 的样本中，但是他没有参与问卷 D 的观察 2 和 3，该怎么办？应该完全删除此人还是只删除问卷 D 的分析，这不会破坏样本吗？
在这种情况下无法进行插值。归纳法也不太可能给出可靠的结果。
-&gt; 最简单的方法似乎是删除数据，但这会大大减少样本……
那么我们如何处理纵向数据中的缺失数据？我使用 SPSS，但 R 或 Python 也可以。]]></description>
      <guid>https://stats.stackexchange.com/questions/649990/missing-data-in-longitudinal-study-spss-python</guid>
      <pubDate>Wed, 26 Jun 2024 19:23:38 GMT</pubDate>
    </item>
    <item>
      <title>如何计算差异分数的信度？</title>
      <link>https://stats.stackexchange.com/questions/642521/how-to-calculate-reliability-of-difference-scores</link>
      <description><![CDATA[我正在尝试计算差异分数的可靠性。具体来说，数据中每个参与者在条件 X（1 和 0）中都有 10 个项目的分数，在条件 Y（1 和 0）中也有 10 个不同的项目的分数。差异分数是条件 X 的平均值减去条件 Y 的平均值。研究中的每个参与者都有 1 个差异分数。
我需要计算差异分数的可靠性，例如使用 Cronbach 的 alpha。有人对如何做到这一点有什么建议吗？提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642521/how-to-calculate-reliability-of-difference-scores</guid>
      <pubDate>Wed, 13 Mar 2024 17:03:38 GMT</pubDate>
    </item>
    <item>
      <title>如果变量似乎没有太大影响，是否应该删除偏移量？</title>
      <link>https://stats.stackexchange.com/questions/619782/should-an-offset-be-removed-if-the-variable-doesnt-seem-to-have-much-influence</link>
      <description><![CDATA[这是一个与主题专家的联合项目，我是统计学家。我不会解释背景并简化统计问题，因为背景相当复杂。我们实际拟合的模型是负二项式混合效应 GLM，但可以使用泊松回归来解释该问题。
假设我们有一个响应变量 $Y$，它是一个计数，由一些变量 $X_1,\ldots,X_p$ 解释。还有一个变量 $P$，它是“人口规模”与 $Y$ 有某种联系，因此最初我的专家认为 $Y/P$ 建模是个好主意，即“$Y$ 按人口成员”，而不是 $Y$。我应该补充一点，从变量的主题信息/含义来看，情况并不十分清楚，我的意思是，$Y$ 应该由 $P$ 标准化，这有点合理但并不完全明显。一些 X 变量也由 $P$ 标准化，而其他变量则没有，这增加了复杂性。同样，这样做也有原因，但它们也“有些合理，但并不完全明显”。
使用对数链接的泊松回归对 $Y/P$ 进行建模的方法是在模型中包含一个偏移量，即具有固定回归系数 1 的项 $\log(P)$。我将此模型称为 M1。出于好奇，我们还研究了模型 M2，其中没有偏移量，但 $\log(P)$ 被包含为另一个预测变量。拟合模型 M2，$\log(P)$ 变量的估计系数接近于零，并且（不是临界值）不显著。 （如果将 $\log(P)$ 替换为 $P$，这和我后面写的内容不会发生重大变化。）
在 X 变量中，有几个与 $\log(P)$ 相关（不是非常强烈；相关性高达 0.4）。在我看来，这解释了 M1 中的估计系数及其 p 值与 M2 有很大不同，以至于两个预测因子具有相反的符号但在两个模型中都具有很强的显著性，而另一个预测因子在 M1 中似乎非常强，但在 M2 中却不显著。
现在我的问题是，不显著性和“接近零”是否意味着 M1 中的估计系数及其 p 值与 M2 中的估计系数及其 p 值完全不同。 M2 中 $\log(P)$ 的状态实际上是一个强有力的理由，可以说明不应使用 M1（并且无论 M1 中估计量和 p 值是否不同，都应该从 M2 中解释它们）。如果 M2 中 $\log(P)$ 的“真实”系数确实为零，则意味着（给定其他变量）$Y$ 不会关心 $P$，因此，像在 M2 中那样对 $Y$ 建模似乎比像在 M1 中那样对 $Y/P$ 建模更有意义。当然，估计 $\log(P)$ 的系数，即使为零，也比将该系数固定为 1（AIC 等更喜欢 M2）更适合数据。另一方面，人们可能会怀疑 $Y$ 被 $P$ 标准化仍然可能是正确的（给定“合理的”主题论点），只是在 M2 中，其影响被其他变量“接管”，并且解释 M2 中其他变量的结果系数可能无法正确代表情况。
这里的目的是分析历史情况，解释变量影响和重要性。预测与此分析的目的无关。
有什么见解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/619782/should-an-offset-be-removed-if-the-variable-doesnt-seem-to-have-much-influence</guid>
      <pubDate>Mon, 26 Jun 2023 15:36:52 GMT</pubDate>
    </item>
    </channel>
</rss>