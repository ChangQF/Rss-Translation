<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 05 Jun 2024 18:19:04 GMT</lastBuildDate>
    <item>
      <title>在 R 中的 GAM 中整合站点级随机效应和二维坐标样条</title>
      <link>https://stats.stackexchange.com/questions/648695/incorporating-site-level-random-effects-and-2-dimensional-spline-of-coordinates</link>
      <description><![CDATA[使用 R 中 mgcv 包中的 gam() 构建广义加性模型时，样条项 s() 中的一个选项是 bs= 参数。选项的描述在此处给出，但简而言之，有许多平滑选项可用于生成基于地理坐标的样条。还有一个选项 bs = &quot;re&quot; 来合并随机效应。
我正在处理一种情况，我在不同位置的采样点重复进行现场访问。我的目标是既结合重复采样的随机效应，又结合每个站点的两个坐标值的样条函数。
模型调用如下所示：
gam(formula = DV ~ IV + s(lat,lon) + s(site,bs = &quot;re&quot;),
data = df)

以这种方式结合随机效应的方法有哪些，这里是否需要两个单独的术语？即，我可以用以下方式对其进行建模吗？
gam(formula = DV ~ IV + s(lat,lon,bs = &quot;re&quot;),
data = df)

或者类似的东西，假设纬度和经度对是唯一的并且与分类站点完全相等？]]></description>
      <guid>https://stats.stackexchange.com/questions/648695/incorporating-site-level-random-effects-and-2-dimensional-spline-of-coordinates</guid>
      <pubDate>Wed, 05 Jun 2024 15:47:10 GMT</pubDate>
    </item>
    <item>
      <title>机器学习实验中嵌套交叉验证的统计显著性检验</title>
      <link>https://stats.stackexchange.com/questions/648693/statistical-significance-testing-for-nested-cross-validation-in-ml-experiment</link>
      <description><![CDATA[我目前正在进行一项 ML 实验，其中我使用嵌套 5 交叉验证程序并为每个测试用户获得 NDCG@10 分数。我正在比较 6 种不同的 ML 算法，并拥有大约 10,000 名用户的数据。
我的交叉验证过程涉及训练 6 种不同的模型，这些模型自然会共享一些训练数据。我最终从 5 个折叠中获得了评估分数，每个折叠都包含不同的测试用户。本质上，我有一个数据集，但由于交叉验证程序，我从每个测试折叠的部分重叠训练数据集上训练的模型中获得评估分数。
以下是我考虑的两种方法，目的是测试 6 个 ML 模型之间的统计显着性：
1.分别对每个折叠进行统计测试：

分别对 5 个测试折叠的 6 个模型进行统计测试。
使用每个折叠中用户的评估分数执行 Friedman 检验，然后对所有成对模型比较进行 Nemenyi 事后 检验。
使用 Stouffer 方法（Z 变换检验）合并事后检验的结果 p 值。

2.将所有测试折叠视为独立数据集：

将 5 个测试折叠视为独立数据集，并对每个数据集的平均评估分数进行统计测试。
对于每个 ML 模型，测试 5 个数据集中平均用户评估分数的统计显著性。
使用 Friedman 检验和 Nemenyi 事后检验，无需合并 p 值。

我读过关于这个主题的各种文献，但由于我是这个领域的新手，我对采取的最佳方法感到困惑。
有人可以为我的嵌套交叉验证程序提供指导吗？
如能提供任何建议或相关文献的参考，我将不胜感激。
谢谢，我是初学者！

简而言之：

嵌套 5 倍 CV 产生 5 个测试折叠的评估分数，其中每个测试折叠包含不同的用户。
内部 CV 部分在重叠的训练实例上进行训练。
6 个 ML 模型
ML 模型的全成对多重比较
如何处理来自 5 个测试折叠的用户评估分数以及针对 6 种不同 ML 算法的统计显着性测试？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648693/statistical-significance-testing-for-nested-cross-validation-in-ml-experiment</guid>
      <pubDate>Wed, 05 Jun 2024 15:28:16 GMT</pubDate>
    </item>
    <item>
      <title>如何近似序列收敛的点？</title>
      <link>https://stats.stackexchange.com/questions/648690/how-to-approximate-the-point-a-sequence-is-converging-to</link>
      <description><![CDATA[作为硕士论文的一部分，我创建了一个扑克解算器。该解算器使用反事实遗憾最小化 (CFR) 来计算德州扑克或奥马哈扑克的纳什均衡。该解算器使用现有解决方案来解决从树中的某个游戏节点开始的解决方案，但这不是重点。
众所周知，使用 CFR 的玩家的平均策略（所有迭代策略的平均值）收敛到纳什均衡。因此，这些玩家的平均估计收益也会收敛。
我试图通过收敛到近似均衡中玩家的平均收益在实际纳什均衡的 X（大盲注）范围内来近似纳什均衡。挑战在于实际纳什均衡的收益是未知的。
有没有办法使用统计数据来估计收敛点在什么范围内？我已经搜索了很长时间（几天到几周），但什么也没找到。
更一般意义上的问题：
众所周知，序列 X = (x1, x2, x3 , ... ,xN , ...) 中的点是随机选择的，因此该序列最终会收敛到一个点。根据 x1 到 xN 的观察结果，我们可以说它预计会收敛到的点的值是什么？
论文“评估马尔可夫链蒙特卡罗算法的收敛性”描述了一些统计方法和局限性，以评估马尔可夫链是否几何收敛。与问题并不完全相关，但我找不到更多信息。 https://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/ConvergeDiagnostics/brooks97assessing.pdf)
以下问题与之密切相关，但尚未得到解答 https://stackoverflow.com/questions/77657691/algorithmic-game-theory-poker-cfr-and-the-approximation-distance
我认为可以作为收敛性良好指标的一件事是序列 X 的视觉指示。从查看此序列的图得出的任何结论当然都是主观的，因此对于硕士论文的目的而言是不够的。]]></description>
      <guid>https://stats.stackexchange.com/questions/648690/how-to-approximate-the-point-a-sequence-is-converging-to</guid>
      <pubDate>Wed, 05 Jun 2024 14:39:02 GMT</pubDate>
    </item>
    <item>
      <title>如何通过统计方法检验特定地点的物种群落是否越来越像另一类型的地点</title>
      <link>https://stats.stackexchange.com/questions/648689/how-to-statistically-test-if-a-community-of-species-at-a-particular-site-is-beco</link>
      <description><![CDATA[我有以下数据框（我在这里使用 R）。
set.seed(2)
Site &lt;- rep(LETTERS[1:13], length.out = 39)
Year &lt;- rep(2019:2022, each = 13, length.out = 39)
Site_Category &lt;- rep(c(paste(&quot;Type&quot;, rep(1:4, each = 3), sep = &quot;_&quot;), &quot;Test_Site&quot;), length.out = 39)
Species_1 &lt;- sample(1:100, 39, replace = T)
Species_2 &lt;- sample(1:25, 39, replace = T)
Species_3 &lt;- sample(1:50, 39, replace = T)
Species_4 &lt;- sample(1:500, 39, replace = T)
Species_5 &lt;- sample(1:100, 39, replace = T)
My_Data &lt;- data.frame(Site = Site, Year = Year, Site_Category = Site_Category, Species_1 = Species_1, Species_2 = Species_2, Species_3 = Species_3, Species_4 = Species_4, Species_5 = Species_5)

本质上，我有四个独立的社区数据矩阵（研究的每个年份一个）。您还会注意到，我有一个附加列 Site_Category，它将某些站点分组在一起，并且还指定其中一个站点是独一无二的，因为它是我们感兴趣的站点。
我们的研究问题是判断这个感兴趣的站点是否随着时间的推移变得更像其他站点类型之一。
我熟悉多元分析，例如 Mantel 检验、多响应置换程序和置换方差分析，但我不仅仅是想看看是否存在差异 - 我想结合某种趋势分析来判断随着时间的推移，是否有朝着其他站点类型之一的特定方向的变化。
我可以在这里使用某种统计分析吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648689/how-to-statistically-test-if-a-community-of-species-at-a-particular-site-is-beco</guid>
      <pubDate>Wed, 05 Jun 2024 14:28:26 GMT</pubDate>
    </item>
    <item>
      <title>计算 Cox-Snell Rsquared 的值</title>
      <link>https://stats.stackexchange.com/questions/648684/calculating-the-value-of-cox-snell-rsquared</link>
      <description><![CDATA[我想计算前瞻性纵向研究的最小样本量（使用 cox 回归 - 项目的目的是预测）。 R 中 pmsampsize 包中的以下函数 pmsampsize 可用于计算（基于以下出版物；用于开发具有连续、二元或生存（事件发生时间）结果的模型的最小样本量。 Riley 等人（2018 年））。要运行以下函数，我们需要输入 csrsquared 的值，即新模型的 Cox-Snell Rsquared 值。
pmsampsize(type = &quot;s&quot;, csrsquared = , parameters = , rate = ,timepoint = , meanfup = )

我没有任何试验数据，而且在类似的研究中也没有报告伪 R2 的值 - 所以我想知道如何定义 csrsquared 的值以便使用此函数进行计算。此外，如果我们假设伪 R2 的值可用，我如何计算 Cox-Snell Rsquared 的值]]></description>
      <guid>https://stats.stackexchange.com/questions/648684/calculating-the-value-of-cox-snell-rsquared</guid>
      <pubDate>Wed, 05 Jun 2024 13:08:22 GMT</pubDate>
    </item>
    <item>
      <title>t 代之后回归的方差是多少？</title>
      <link>https://stats.stackexchange.com/questions/648671/what-is-the-variance-of-a-regression-after-t-generations</link>
      <description><![CDATA[假设我们有一个回归：
$x_{t+1} = b x_t + e_t$。
取每边的方差，我们得到
$Var(x_{t+1}) = b^2 Var(x_t) + Var(e_t)$。
现在假设 $Var(e_t) = \sigma^2$ 是所有 $t$ 的常数。
然后我们有一个一阶递归关系，因此我们可以明确地求解：
$Var(x_t) = \frac{\sigma^2 (1 - b^{2t})}{(1-b^2)}$。
不幸的是，我正在阅读的 Gregory Clark 的《儿子也复活》一书给出的方差为 $\sigma^2 (1 - b^{2t})$。我的推导正确吗？
（注意：对于拥有这本书的人来说，页码是 297。这不是打字错误，后续文本已明确指出。）]]></description>
      <guid>https://stats.stackexchange.com/questions/648671/what-is-the-variance-of-a-regression-after-t-generations</guid>
      <pubDate>Wed, 05 Jun 2024 10:18:23 GMT</pubDate>
    </item>
    <item>
      <title>如果分布中缺少数据，哪种统计数据可以最好地替代真实样本均值？</title>
      <link>https://stats.stackexchange.com/questions/648668/what-statistic-is-best-alternative-to-the-true-sample-mean-in-case-of-missing-da</link>
      <description><![CDATA[我有一组值，其中每个值代表基于一个样本的分布的统计数据。底层可观察值可以假设为粒子长度，因此该值是粒子长度分布的平均值或中位数或其他统计数据。问题是使用图像分析来评估分布。由于粒子重叠，分布不完整且有偏差，因此较长的长度相对于较短的长度被过度代表。一个样本分布中最长的粒子的长度是准确的。每个分布中的粒子数量实际上并不相同，可以假设在 10-50 之间，每个粒子通常与 1-5 个其他粒子重叠。
总而言之，每个样本都会生成一个不完整的离散分布，从中可以计算出一个代表性统计数据。统计数据“最大值”是准确的，其他数据（例如中位数或均值）可能不是，但没有办法通过实验来测试这一点。长度分布未知，但可能不是高斯分布，可能略微偏向大值，而短值很少。还请注意，不同样本的个体分布可能会有所不同，但您可以假设不同样本的分布的一般形状相似，并且真实统计量的分布是正态的。
我的问题是，基于此信息，是否有可能选择最能代表每个样本分布的真实平均值的统计量。特别是，如果离散采样分布中的最大值是准确的，但分布的其他区域由于重叠而采样不足。直观地说，如果我有 N 个样本，“最佳”意味着真实均值与我为这些分布选择的统计量之间的平方偏差之和最小化，因此 SSE 最小。
我的直觉是中位数是最好的统计数据。我正在考虑进行一些数值模拟，但为了节省时间，因为这可能是统计学家可以轻松诊断的问题，我首先在这里询问。在此先感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/648668/what-statistic-is-best-alternative-to-the-true-sample-mean-in-case-of-missing-da</guid>
      <pubDate>Wed, 05 Jun 2024 10:06:22 GMT</pubDate>
    </item>
    <item>
      <title>如何根据一组百分位数重建正态分布？</title>
      <link>https://stats.stackexchange.com/questions/648589/how-can-i-reconstruct-a-normal-distribution-from-a-set-of-percentiles</link>
      <description><![CDATA[我有一个正态分布变量的第 3、10、50、90 和 97 个百分位数值，我希望生成一个数据集，使我能够查询其他百分位数值（例如，第 67 个百分位数值）。
我（天真地，我敢肯定）尝试了以下操作，但失败了：
underlying_data = np.random.normal(loc=0.0, scale=1.0, size=[1000])

percentiles = np.percentile(underlying_data, [3, 10, 50, 90, 97])

#

generated_data = []

for i in range(3):
generated_data.append(underlying_data[0])

for i in range(7):
generated_data.append(underlying_data[1])

for i in range(80):
generated_data.append(underlying_data[2])

for i in range(7):
generated_data.append(underlying_data[3])

for i in range(3):
generated_data.append(underlying_data[4])

print(&quot;from underground distribution: &quot;, np.percentile(np.array(underlying_data), [67]))
print(&quot;from generated distribution: &quot;, np.percentile(np.array(generated_data), [67]))

输出：
from underground distribution: [0.44470627]
from generated distribution: [-0.73888881]
]]></description>
      <guid>https://stats.stackexchange.com/questions/648589/how-can-i-reconstruct-a-normal-distribution-from-a-set-of-percentiles</guid>
      <pubDate>Tue, 04 Jun 2024 06:25:11 GMT</pubDate>
    </item>
    <item>
      <title>R(k+1, n+1) < R(k, n) 是否正确？</title>
      <link>https://stats.stackexchange.com/questions/648586/is-it-true-that-rk1-n1-rk-n</link>
      <description><![CDATA[以下说法是否正确：

在 n+1 次试验中至少有 k+1 次成功的概率小于在 n 次试验中至少有 k 次成功的概率。

也就是说，$$R(k+1, n+1) &lt; R(k, n)$$ 其中
$
R(k,n)=\sum_{i=k}^n\binom ni p^iq^{n-i}
$是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/648586/is-it-true-that-rk1-n1-rk-n</guid>
      <pubDate>Tue, 04 Jun 2024 03:35:46 GMT</pubDate>
    </item>
    <item>
      <title>类似于投票箱模型的练习</title>
      <link>https://stats.stackexchange.com/questions/648575/exercise-similar-to-the-ballot-box-model</link>
      <description><![CDATA[考虑以下问题
一个盒子里有 10 个灯泡，其中 6 个是新的，4 个是用过的，随机选择 4 个灯泡而不放回，直到取出一个用过的灯泡。我想确定需要选择恰好 3 个灯泡才能获得第一个使用的灯泡的概率。
假设 A：随机选择 3 个灯泡，B：使用第 i 个灯泡，我想我们想要确定的是：
$$P(B_{1}|A)=\frac{P(A \cap B_{1})}{P(A)}$$
注意到 $P(A)=\frac{\binom{4}{1}}{\binom{10}{4}}$，但交集呢，这里我想计算随机取出三个灯泡，其中第一个被使用的概率，我想到了类似的东西：
$$P(A \cap B_1)=\frac{\binom{4}{3} \binom{4}{1}}{\binom{10}{4}}$$
但我并不完全相信，我觉得我在计算交集时遗漏了一些情况，有什么关于如何解决这个问题的建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648575/exercise-similar-to-the-ballot-box-model</guid>
      <pubDate>Mon, 03 Jun 2024 21:27:49 GMT</pubDate>
    </item>
    <item>
      <title>重复测量方差分析问题</title>
      <link>https://stats.stackexchange.com/questions/648560/repeated-measures-analysis-of-variance-question</link>
      <description><![CDATA[我有以下数据集。
My_Data &lt;- data.frame(Sampling_Date = rep(1:4, each = 12), Block = rep(1:3, length.out = 48), Treatment = rep(LETTERS[1:4], each = 3, length.out = 48), Response = abs(rnorm(48, 10, 1)))

我正在做重复测量方差分析。每个区块包含四个图，其中区块中的每个图都接受不同的处理。这些图在一年内被重复采样。我想知道在 R 中对这些数据进行建模的最合适方法是什么。这是我根据所读内容得出的结论。
Model &lt;- aov(Response ~ (Treatment * as.factor(Sampling_Date)) + Error(as.factor(Block) / (Treatment * as.factor(Sampling_Date))), data = My_Data)
summary(Model)

在此模型输出中，每个主效应和交互项都有自己的误差项，这本质上是主效应或感兴趣的交互与阻塞（复制）变量的相互作用。
我有几个问题。
首先，此模型的工作方式是否合适？换句话说，这些误差项是否适用于每个不同的主效应和交互？如果是，那么为什么？
其次，我是否需要考虑混合效应模型，以便可以将块视为随机变量？由于区块本质上只是我们的复制变量，我认为它不应该包含在模型中。
第三，何时以及为什么要考虑球形度？这取决于我们将采样日期视为数字变量还是分类变量吗？
第四，如果我将采样日期视为数字变量，模型将如何变化？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648560/repeated-measures-analysis-of-variance-question</guid>
      <pubDate>Mon, 03 Jun 2024 17:20:53 GMT</pubDate>
    </item>
    <item>
      <title>如何确定单变量 ADE/ACE 模型中的“起始值”？</title>
      <link>https://stats.stackexchange.com/questions/648529/how-to-determine-starting-values-in-univariate-ade-ace-model</link>
      <description><![CDATA[有人知道如何确定起始值吗，例如在未测量的基因型数据中执行饱和模型？我使用了 https://hermine-maes.squarespace.com/#/one/ 中的代码“oneSATc.R”，但它没有很好地解释如何确定起始值，所以也许有人有这方面的经验，可以帮助我。这里我将提供我的代码片段。
 #################
## 假设测试 ##
#################

#------------#
## 准备数据 ##
#------------#

# 选择要分析的变量
vars &lt;- &#39;SBJS5T&#39; # 变量名称列表
nv &lt;- 1 # 变量数量
ntv &lt;- nv*2 # 总变量数量
selVars &lt;- paste(vars,c(rep(1,nv),rep(2,nv)),sep=&quot;&quot;) 

# 选择要分析的数据
mzData &lt;- subset(raw, ZYGO == 1, selVars) 
dzData &lt;- subset(raw, ZYGO == 2, selVars) 

# 生成描述性统计
colMeans(mzData,na.rm=TRUE)
colMeans(dzData,na.rm=TRUE)
cov(mzData,use=&quot;complete&quot;)
cov(dzData,use=&quot;complete&quot;)

# 设置起始值
# 更新设置起始值
svMe &lt;- 18.42 # 平均值的起始值，四舍五入的平均平均值
svVa &lt;- 3.45 # 方差的起始值，四舍五入的方差意味着双胞胎
lbVa &lt;- .0001 # 方差的下限


现在我仅使用 4 个“colMeans”的平均值作为“svME”，使用 8 个“cov”的平均值作为“svVa”
有人可以肯定这一点或告诉我哪种方法可以准确确定这些起始值吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648529/how-to-determine-starting-values-in-univariate-ade-ace-model</guid>
      <pubDate>Mon, 03 Jun 2024 09:37:03 GMT</pubDate>
    </item>
    <item>
      <title>Kaplan-Meier 检验与比例检验的根本区别是什么？</title>
      <link>https://stats.stackexchange.com/questions/647835/what-are-the-fundamental-differences-of-kaplan-meier-testing-versus-tests-of-pro</link>
      <description><![CDATA[假设我的研究将招募 50 名患者并监测他们可能在任何时间点出现的某些结果。我的零假设是 $t=12$ 时无事件受试者的比例小于或等于某个基准（$\pi=0.2$）。假设当时的真实比例为 0.4。如果我们假设事件到达时间呈指数分布，则幸存者函数可以求解为 $\lambda = -\log(0.4)/12 = 0.076 $ 事件/月。
为了定义我的响应变量，我不知道（在我的分析中）事件时间是指数的。此外，我的研究会在一段时间后终止，受试者以分步方式入组，甚至在跟踪到时间 $t$ 之前就可能退出。因此，Kaplan-Meier 方法是理想的分析框架。我们可以将 95% CI 的下限与基准进行比较，如果超过基准，则我们的测试在 0.05 水平上显著。另一方面，如果受试者在研究中被跟踪了 6 个月且没有发生事件，我可以将二进制值定义为 1，否则为 0。在单组试验 (SAT) 中，将审查和研究终止的并发事件视为负面反应显然更为保守。
但我如何向审阅者实际描述这两种测试策略之间的差异？ 是否有一个定义明确的术语集来区分这两个看似相似的终点定义？在下面的小模拟中，我们看到，只要能够可靠地跟踪受试者直到观察到终点，KM 曲线方法的功效就会略高，但仍然会估计相同的比例。
library(survival)
set.seed(123)
do.one &lt;- function() {
n &lt;- 50
t0 &lt;- runif(50, 0, 6) ## 在 6 个月内招募所有 n=50
t1 &lt;- rexp(50, 0.076)
y &lt;- Surv(time=pmin(t1, 18-t0), event=t1 &lt; 18-t0)
f &lt;- survfit(y ~ 1)
sf &lt;- summary(f, conf.type=&#39;clog-log&#39;)

c(
&#39;estSurvKM&#39; = sf$surv[max(which(sf$time &lt; 12))],
&#39;estProp&#39; = sum((t1 &gt; 12) &amp; ((18-t0) &gt; 12))/50,
&#39;sigSurvKM&#39; = sf$lower[max(which(sf$time &lt; 12))] &gt; 0.2,
&#39;sigPropr&#39; = prop.test(sum(t1 &gt; 12 &amp; (18-t0) &gt; 12) , n=50, 
p=0.2)$p.value &lt; 0.05
)
}

val &lt;- replicate(1000, do.one())
rowMeans(val)

&gt; rowMeans(val)
estSurvKM estProp sigSurvKM sigPropr 
0.40184 0.40184 0.91400 0.84500
]]></description>
      <guid>https://stats.stackexchange.com/questions/647835/what-are-the-fundamental-differences-of-kaplan-meier-testing-versus-tests-of-pro</guid>
      <pubDate>Thu, 23 May 2024 16:00:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R robustbase 和 rrcov covMcd 使用异常值的实际分数来计算重加权步进微调调整？</title>
      <link>https://stats.stackexchange.com/questions/647825/why-does-r-robustbase-and-rrcov-covmcd-compute-reweighted-step-trimming-adjustme</link>
      <description><![CDATA[R robustbase 和 rrcov 中的 covMcd 和 CovMcd 默认计算重新加权步骤。
MCD 和类似方法中的重新加权计算马哈拉诺比斯距离，并使用卡方分布的截止值，计算距离低于截止值的观测值的标准均值和协方差。
此估计值已针对截断样本进行了校正。在原始 MCD 估计中，此校正基于包含集合中的观测值比例，默认情况下为 50% 或略大。
但是，在重新加权步骤中，修剪是度量的，这意味着我们基于理论阈值而不是固定的观测值比例进行修剪。
因此，在这种情况下，截断校正因子应基于阈值尾部概率，而不是低于截止值的实际观测值比例。
据我所知，covMcd 和 CovMcd 使用低于阈值的实际观测值比例，而不是用于卡方截止值的概率。
R 中的非度量修剪校正的结果是，即使“好”数据从未改变，重新加权的协方差也会随着更多异常值的添加而发生变化。通过度量修剪校正，尾部概率保持不变，并且当添加其他异常值时协方差不会改变。
背景和示例
https://github.com/statsmodels/statsmodels/pull/9227#issuecomment-2125161686
问题：R 使用我遗漏的观察分数是否有理由或理由？
旁白：
我目前必须决定 statsmodels 是否应该匹配 R 在这种情况下的行为。我的意见是不匹配 robustbase 和 rrcov。然而，R 中强大的包是由该领域的专家编写的，而对我来说，这只是另一个主题，我必须弄清楚才能将其实现为 statsmodels。]]></description>
      <guid>https://stats.stackexchange.com/questions/647825/why-does-r-robustbase-and-rrcov-covmcd-compute-reweighted-step-trimming-adjustme</guid>
      <pubDate>Thu, 23 May 2024 13:18:46 GMT</pubDate>
    </item>
    <item>
      <title>如何处理不同暴露状态下的暴露状态变化及结果贡献？</title>
      <link>https://stats.stackexchange.com/questions/647797/how-to-deal-with-exposure-status-change-and-outcome-contribution-in-different-ex</link>
      <description><![CDATA[我想估计糖尿病患者（暴露组）与非糖尿病患者（未暴露组）相比发生心血管事件的风险。我们如何处理（在分析中）没有糖尿病（未暴露组）但发生心血管事件，然后患上糖尿病的患者（即他们从未暴露变为暴露，但在未暴露时发生了感兴趣的事件）？
最佳策略是使用随时间变化的分析，还是在同一日历时间创建具有和不具有感兴趣的暴露的患者匹配组？]]></description>
      <guid>https://stats.stackexchange.com/questions/647797/how-to-deal-with-exposure-status-change-and-outcome-contribution-in-different-ex</guid>
      <pubDate>Thu, 23 May 2024 01:03:02 GMT</pubDate>
    </item>
    </channel>
</rss>