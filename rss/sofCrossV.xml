<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 14 May 2024 12:26:59 GMT</lastBuildDate>
    <item>
      <title>预测变量的后向选择和 GLM 先前的假设</title>
      <link>https://stats.stackexchange.com/questions/647208/backward-selection-of-predictors-and-glm-previous-assumptions</link>
      <description><![CDATA[我想确定哪些环境因素（预测变量）对一个生态变量（因变量）有影响。我有一组 110 个观察结果。
因变量是连续的、正的并且包含零。
预测变量并不共线，我从 24 个变量的列表开始。
我设置了 GLM 并执行了预测变量的向后选择，仅保留重要的预测变量。我不希望最终模型做出任何预测，我只想确定重要的预测变量（因此模型拟合不相关）。因此，我一次删除一个预测变量，始终排除 p 值最高的预测变量。
问题在于，初始模型不满足残差正态性（显着 Shapiro-Wilk）和同方差性（不显着 Breuch-Pagan），并且最后一个模型不满足残差正态性（显着 Shapiro-Wilk） ）
在这里您可以看到初始模型的一些图：


第一个问题：
在执行预测变量的逐步选择时，哪些 GLM 需要满足先前的假设？每一个？第一和最后？只是最后一个？
第二个问题：
我尝试使用不同的方法使初始模型具有残差的正态性，但我找不到实现它的方法。我尝试通过平方根、倒数、自然对数、box-cox 和 yeo-johnson 变换因变量，始终保持零；我尝试在 GLM 中使用不同的族分布（高斯分布、毒分布、伽玛分布、二项式分布、拟分布......基本 R 中所有可用的分布，即使它们没有多大意义）；我尝试排除异常值（尽管这是我真的不想做的事情）。什么都没起作用。有什么想法吗？
第三个问题：
（关于何时可以“忽略”GLM 中残差缺乏正态性的大主题）查看我的图和数据点，似乎缺乏正态性是由因变量的最高值引起的，因此，我在模型中包含的预测变量可能缺少与这些高值相关的内容，但它们适用于大多数值范围。从生态角度来看，这在我看来是合理的。鉴于我的目的不是建立一个预测模型，这种解释是否足以“忽略”这一点？缺乏常态？
非常感谢，我已经花了很多时间在网上寻找答案，但我没有找到我想要的东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/647208/backward-selection-of-predictors-and-glm-previous-assumptions</guid>
      <pubDate>Tue, 14 May 2024 11:19:41 GMT</pubDate>
    </item>
    <item>
      <title>残差重尾分布的修正？</title>
      <link>https://stats.stackexchange.com/questions/647207/correction-for-heavy-tailed-distribution-of-residuals</link>
      <description><![CDATA[我有兴趣研究使用固定的 $x$ 对 $y$ 的影响效果法。正如正态 Q-Q 图所示，残差遵循重尾分布。为了进行推理，我需要残差的正态分布。
哪些策略可以应用于模型以使残差变得更加正态分布？我想到了对数转换。这使得残差确实更加正态分布，但重尾仍然存在。]]></description>
      <guid>https://stats.stackexchange.com/questions/647207/correction-for-heavy-tailed-distribution-of-residuals</guid>
      <pubDate>Tue, 14 May 2024 11:14:46 GMT</pubDate>
    </item>
    <item>
      <title>绘制模型调整的变化分数基线值</title>
      <link>https://stats.stackexchange.com/questions/647206/plotting-model-adjusted-baseline-values-of-change-scores</link>
      <description><![CDATA[我知道一些人不赞成使用变化评分来评估 RCT 中治疗对结果的影响。但我有兴趣了解人们在绘制模型调整均值时通常会做什么，无论是在结果向量中包含基线还是在 ANCOVA 中调整基线。在后一种情况下，模型中不会估计结果的基线值，但在前一种情况下会估计结果的基线值。鉴于它们是变化分数并且基线值为零（至少在样本中），将两个治疗组中的图投影回零是否合理（如果在技术上无效）。审阅者质疑为什么学生的模型调整平均值在基线时不为零，但当然这些不是描述性平均值，这取决于模型中调整的协变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/647206/plotting-model-adjusted-baseline-values-of-change-scores</guid>
      <pubDate>Tue, 14 May 2024 11:08:49 GMT</pubDate>
    </item>
    <item>
      <title>深度学习中的统计测试</title>
      <link>https://stats.stackexchange.com/questions/647205/statistical-test-in-deeplearning</link>
      <description><![CDATA[在写论文期间，我评估了各种模型的性能并写下了性能平均值。
然而，许多论文即使坚持其方法是 SOTA，也没有包含统计分析。
当然，大多数实验都是在相同的测试数据集上进行的，因此可以使用配对 t 检验（或某种配对测试策略，如 Wilcoxon 符号秩检验）。
但是，许多测试数据集提供的数据超过数千个，因此测试统计数据将大得离谱，并且可能会变得过于重要。
那么，他们如何才能对模型的卓越性充满信心呢？ （引导？）]]></description>
      <guid>https://stats.stackexchange.com/questions/647205/statistical-test-in-deeplearning</guid>
      <pubDate>Tue, 14 May 2024 11:07:49 GMT</pubDate>
    </item>
    <item>
      <title>药物的科恩 d 效应大小</title>
      <link>https://stats.stackexchange.com/questions/647201/cohens-d-effect-size-of-a-medication</link>
      <description><![CDATA[研究使用 Cohen 的 d 效应大小来表达干预措施的有效性。作为心理学的一般规则，效应大小 0.2 被认为是小，0.5 是中，0.8 是大。
假设安慰剂和干预措施（药物 X）之间的效应值较大，为 0.8，那么可以公平地解释说，服用药物 X 的人中 78.8% 的比例高于服用安慰剂组的平均值吗？
这看起来并不像是一个“大”的问题。效应，因为安慰剂组中 50% 的人也会高于平均值（假设正态分布）。
那么这种药物只对大约 28% 的人有效？还是我完全偏离了基地？
该统计数据是否还可以传达有关药物强度的任何信息（例如，生活质量评分的变化为 9/10 与 1/10），或者它只是用于衡量二元结果（药物 X 有效果，或没有效果，我们将效果定义为 2/10 的改进）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647201/cohens-d-effect-size-of-a-medication</guid>
      <pubDate>Tue, 14 May 2024 10:20:59 GMT</pubDate>
    </item>
    <item>
      <title>在标准回归分析中利用二分网络信息</title>
      <link>https://stats.stackexchange.com/questions/647198/utilizing-bipartite-network-information-in-standard-regression-analysis</link>
      <description><![CDATA[我的一般性问题的要点是，当目标是使用标准回归模型进行节点级分析时，是否有一些有用的方法可以利用有关嵌入在二分网络中的个体之间关系的信息。
我的主要目标是确定解释特定人群中的个人是否接种疫苗的因素。我有两个数据集：

1.) 包含具有多个个体级别变量（例如年龄、性别、疫苗接种状态等）的不同个体的数据集。
2.) 一个数据集，其中包含有关哪个人去看哪个医生的信息。

由于该数据集中的医生之间没有直接关系，个人之间也没有直接关系，因此它本质上是一个二分网络。使用第一个数据集的信息来预测疫苗接种状态可以使用各种模型轻松完成，没有任何问题。我的问题是我不确定如何使用第二个数据集。这是我到目前为止的想法：

A) 聚合医生级别的信息（患者的平均年龄、过去接种疫苗的患者比例等）并将其合并到第一个数据集是我能想到的最简单的方法。然而，由于人们可能（而且通常确实）在给定时间点去看多个医生，因此需要另一个级别的聚合。例如。必须取医生级别变量的平均值（或最大值、最小值等）才能得到每人一个值。
B) 创建二分网络，提取节点级属性（例如接近度、中心性等），并将这些属性用作节点级回归中的预测变量。

这两个选项看起来都有点“hacky”。对我来说，所以我想知道是否有更正式的方法来结合我所拥有的两种信息。如果有人有任何想法或能指出我在文学方面的正确方向，我会非常高兴。任何意见都将受到高度赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/647198/utilizing-bipartite-network-information-in-standard-regression-analysis</guid>
      <pubDate>Tue, 14 May 2024 10:09:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 sigmoid 函数进行线性逻辑回归 - 为什么需要对 y 进行变换？</title>
      <link>https://stats.stackexchange.com/questions/647197/making-linear-to-logistic-regression-with-sigmoid-function-why-is-a-transforma</link>
      <description><![CDATA[我读过有关逻辑回归的内容，如果我理解正确的话，它基本上是一个线性回归，其中对 y 值应用了符号函数。但如果我自己尝试，我不会得到预期的结果。为什么我们不能简单地使用线性模型中的系数来使用 y= b0 + x*b1 进行 y 预测，然后获得与使用 Logistic 模型获得的概率相同的概率通过应用 sigmoid 函数进行回归 p = 1/ (1 + e^(-y))？这是行不通的。但我注意到，如果第一步我们对 y 应用线性变换，第二步应用 sigmoid 函数，那么我们会得到与逻辑回归相同的概率。为什么我们需要在应用 sigmoid 函数之前对 y 进行线性变换？并且：如果我们不运行逻辑回归，如何知道线性变换的系数是多少？
&lt;小时/&gt;
请参阅以下示例，其中我生成一些数据，对其进行逻辑回归并沿 x 值进行预测。由此产生的 x/概率图看起来似乎是合理的。这是一个 R 代码：
&lt;前&gt;&lt;代码&gt;库(magrittr)
# 生成数据
# 使其可重现
设置.种子(1)
# 观察次数。
n &lt;- 100000
# 随机 x 变量。
x &lt;- rnorm(n, 50, 10)
# 系数。
b0 &lt;- log(.001)
b_x &lt;- log(1.2)
b_noise &lt;- log(.9)
＃ 公式。
z &lt;- b0 + b_x* x + b_noise* rnorm(n, 0, 1)
# y.
y &lt;- {1/ (1 + exp(-z))} %&gt;%
  rbinom(n= n, 大小= 1, 概率= .) %&gt;%
  as.logic()

# 使其成为数据框。
df &lt;- data.frame(x, y, y_num= as.numeric(y) - 1)

# 拟合模型。
mod_log &lt;- glm(公式= y ~ x, family=二项式(link=“logit”), 数据= df)

# 预测什么值。
df_pred &lt;- data.frame(x= seq(0, max(x), .1))

＃ 预测。
# 逻辑预测
df_pred$log_logit &lt;- 预测(mod_log, newdata= df_pred)
# 应用逆 logit 转换为概率
df_pred$log_prob &lt;- 1 / (1 + exp(-df_pred$log_logit))

绘图（df_pred$x，df_pred$log_prob）

这会产生以下图：

接下来，我使用相同的 x 和 y 数据来拟合线性模型。然后，我使用这些系数构建公式 y = b0 + b1*x 并沿着感兴趣的 x 值预测 y 值。最后，我通过执行 p = 1/ (1 + e^(-y)) 应用 sigmoid 函数。我相信这些 p 值将与我之前使用逻辑回归计算的概率相同（= 与上例中的 df_pred$log_prob 相同）。但这种情况并非如此。
后来我注意到线性回归预测的 y 值与逻辑回归预测的 logit 预测之间存在完美的线性关系。这意味着在转换使用线性回归预测的 y 值后，我能够使用线性回归重新创建逻辑回归的概率预测。但为什么我们需要在应用 sigmoid 函数之前传输 y 呢？请参阅下面的代码：
# 运行线性模型
mod_lm &lt;- lm(公式= y_num ~ x, 数据= df)
# 使用线性模型拟合预测 y
df_pred$lm_y &lt;- coef(mod_lm)[1] + coef(mod_lm)[2] *df_pred$x
# 变换 y。
df_pred$lm_y_transformed &lt;- data.frame(lm_y= df_pred$lm_y, log_logit= df_pred$log_logit) %&gt;%
  lm(log_logit ~ lm_y, .) %&gt;%
  系数() %&gt;%
  {.[1] + .[2] *df_pred$lm_y}
# 对 y 应用 sigmoid 函数
df_pred$lm_prob &lt;- 1/(1 + exp(-df_pred$lm_y_transformed))
# 测试概率是否相同。
all.equal(df_pred$log_prob, df_pred$lm_prob)
＃ 真的！
]]></description>
      <guid>https://stats.stackexchange.com/questions/647197/making-linear-to-logistic-regression-with-sigmoid-function-why-is-a-transforma</guid>
      <pubDate>Tue, 14 May 2024 09:42:09 GMT</pubDate>
    </item>
    <item>
      <title>是否可以仅通过了解我的组的平均值和样本量来进行统计分析？</title>
      <link>https://stats.stackexchange.com/questions/647193/is-it-possible-to-do-statistic-analysis-from-only-knowing-my-groupss-means-and</link>
      <description><![CDATA[我正在写一个我的同事（在人类健康领域）认为不可能解决的问题，但我想相信数学有答案。我被告知不可能对下述实验进行统计分析：
我们有 32 只个体，我们认为它们最初是相同的（来自同一批次的小鼠），并将它们分为 8 组，每组 4 只。每组都接受不同的治疗。
然后，在两个不同的时间点，我们对每组的 4 个人进行血液采样，汇集血液，然后对汇集的血液进行分析。我们获得的数据是我们混合的血液样本中不同细胞类型（例如：淋巴细胞）的数量。
我想知道是否可以确定我们合并的血液样本中的淋巴细胞数量是否存在统计差异。
下一个层次是了解同一组的两个时间点的汇集血液样本是否存在统计差异。
在互联网上，我查找了诸如“Aspin-Welch t 检验”之类的测试，这些测试似乎很有希望，但看起来我们仍然需要能够提供我们所缺乏的 SD 值？
如果有人能提供帮助，我将不胜感激。
祝你有美好的一天！]]></description>
      <guid>https://stats.stackexchange.com/questions/647193/is-it-possible-to-do-statistic-analysis-from-only-knowing-my-groupss-means-and</guid>
      <pubDate>Tue, 14 May 2024 08:35:21 GMT</pubDate>
    </item>
    <item>
      <title>GAMLSS - 如何调整 AIC 以进行变量的对数转换</title>
      <link>https://stats.stackexchange.com/questions/647188/gamlss-how-to-adjust-aic-for-log-transformation-of-variables</link>
      <description><![CDATA[我有一个 GAMLSS 模型，其中自变量和因变量均处于自然尺度，以及第二个模型，其中两个变量都已进行对数转换。如何调整对数转换模型的 AIC 以便可以比较两个模型？
（这对于回答问题可能并不重要，但如果您想知道，我正在将测量值的 CV 建模为其真实值的函数。我有几千个未知的真实值，并且每个测量值都有两个测量值他们。
在自然尺度模型中，我使用两次测量的平均值（作为真值的估计量）作为自变量，并将样本 SD 作为因变量。 GAMLSS 模型得到的 mu 是对受抚养群体 SD 的估计，然后可用于计算受抚养群体 CV。
然后，我使用对数转换测量值的平均值作为因变量，将其 SD 作为因变量，从而直接估计相关群体 CV。）
这是一个例子：
库（matrixStats）
图书馆（gamss）

设置.seed(0)

# 模拟数据
x_mu &lt;- rGB2(5000, 2.7, 8.6, 0.13, 1.28)
x_mu &lt;- x_mu[x_mu &gt; .5]

cv &lt;- 函数(x) .03 * exp(-1 * x) + .01

# 假装你不知道数据是由 rlnorm() 生成的
dat &lt;- as.data.frame(矩阵(
  rlnorm(2 * 长度(x_mu), log(x_mu), cv(x_mu)),
  ncol = 2
））

# 假设误差服从正态分布
dat_normal &lt;- 数据
dat_normal$mean &lt;- rowMeans(dat_normal)
dat_normal$sd &lt;- rowSds(as.matrix(dat_normal[, 1:2]))

model_normal &lt;- gamlss(sd ~ pbm(mean, mono = “up”),
                     〜意思是，
                     数据 = dat_normal,
                     家庭 = GG(),
                     控制 = gamlss.control(n.cyc = 50))

# 假设误差服从对数正态分布
dat_lognormal &lt;- log(dat)
dat_lognormal$logmean &lt;- rowMeans(dat_lognormal)
dat_lognormal$logsd &lt;- rowSds(as.matrix(dat_lognormal[, 1:2]))

model_lognormal &lt;- gamlss(logsd ~ pbm(logmean, mono = “向下”),
                        〜对数平均值，
                        数据 = dat_lognormal,
                        家庭 = GG(),
                        控制 = gamlss.control(n.cyc = 50))

x_compare &lt;- c(.5, 1, 2, 4)
比较 &lt;- data.frame(
  x = x_比较，
  true = cv(x_compare),
  model_normal = exp(预测(model_normal, newdata = data.frame(mean = x_compare))) / x_compare,
  model_lognormal = exp(预测(model_lognormal, newdata = data.frame(logmean = log(x_compare))))
）

回合（比较，4）
x true model_normal model_lognormal
0.5 0.0282 0.0303 0.0295
1.0 0.0210 0.0215 0.0215
2.0 0.0141 0.0146 0.0146
4.0 0.0105 0.0112 0.0099

AIC（模型_正态，模型_对数正态）

                df AIC
模型对数正态 6.141213 -28058.55
模型正常 8.663739 -24779.60
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/647188/gamlss-how-to-adjust-aic-for-log-transformation-of-variables</guid>
      <pubDate>Tue, 14 May 2024 07:43:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么将 IQR 数据分为 4 个部分，而不是每个部分 20 或 10 个百分比？</title>
      <link>https://stats.stackexchange.com/questions/647182/why-divide-data-into-4-parts-for-iqr-and-not-into-parts-of-20-or-10-percentages</link>
      <description><![CDATA[为什么将数据分为 4 个部分以进行 IQR，而不是分成更多部分，例如每个部分 20% 或 10%？
我知道四分位距的定义是 25%，但这不是我的问题。
我认为丢弃 IQR 的 50% 数据来删除异常值太浪费数据了。但总得有个理由吧？]]></description>
      <guid>https://stats.stackexchange.com/questions/647182/why-divide-data-into-4-parts-for-iqr-and-not-into-parts-of-20-or-10-percentages</guid>
      <pubDate>Tue, 14 May 2024 06:25:10 GMT</pubDate>
    </item>
    <item>
      <title>sklearn 的“RadiusNeighborsClassifier”的“距离”选项背后的算法是什么？</title>
      <link>https://stats.stackexchange.com/questions/647170/what-is-the-algorithm-behind-the-distance-option-of-radiusneighborsclassifier</link>
      <description><![CDATA[在 scikit-learn 中，我正在测试 RadiusNeighborsClassifier，我发现选项 weights=&#39;distance&#39; 极大地提高了 CCR（分类正确率）。是否有任何期刊参考文献或有关此选项背后的算法的一些注释？]]></description>
      <guid>https://stats.stackexchange.com/questions/647170/what-is-the-algorithm-behind-the-distance-option-of-radiusneighborsclassifier</guid>
      <pubDate>Mon, 13 May 2024 21:00:00 GMT</pubDate>
    </item>
    <item>
      <title>何时需要显着性或零假设检验的基本原理</title>
      <link>https://stats.stackexchange.com/questions/647167/the-rationale-for-when-significance-or-null-hypothesis-testing-is-needed</link>
      <description><![CDATA[为什么人们有时会声称效果如此巨大且“明显”？即使样本量不大，它也不能保证任何推论统计计算？
这来自生物/医学领域，主要来自实验室设计的实验。
以下是此类实验的一个示例

这些是均值+标准差。他们通常会得出“差异太明显，所以不需要测试”的结论。在计算样本 CI 之前。
有人可以分享一些关于此事的参考资料吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647167/the-rationale-for-when-significance-or-null-hypothesis-testing-is-needed</guid>
      <pubDate>Mon, 13 May 2024 19:49:07 GMT</pubDate>
    </item>
    <item>
      <title>时间点 lsmeans 事后均值比较</title>
      <link>https://stats.stackexchange.com/questions/647165/timepoint-lsmeans-post-hoc-mean-comparisons</link>
      <description><![CDATA[谁能建议哪个是最合适的测试？
我的 Y 轴上的基线（包括基线在内的 4 个时间点）和 X 轴上的时间点相比发生了变化，4 次治疗。我想看看治疗中不同时间点是否存在显着差异。使用 Tukey 调整进行 lsmeans 测试是否合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/647165/timepoint-lsmeans-post-hoc-mean-comparisons</guid>
      <pubDate>Mon, 13 May 2024 19:19:07 GMT</pubDate>
    </item>
    <item>
      <title>标准误和置信区间</title>
      <link>https://stats.stackexchange.com/questions/647158/standard-error-and-confidence-intervals</link>
      <description><![CDATA[关于理论概念...我们使用置信区间进行推断，将研究结果外推到类似样本。这是真的吗？
置信区间有什么区别，结果除以$\sqrt{n}$，标准误差是怎么产生的？]]></description>
      <guid>https://stats.stackexchange.com/questions/647158/standard-error-and-confidence-intervals</guid>
      <pubDate>Mon, 13 May 2024 17:02:53 GMT</pubDate>
    </item>
    <item>
      <title>序列相关性如何使 OLS 保持无偏（即使在横截面数据中）</title>
      <link>https://stats.stackexchange.com/questions/647155/how-does-serial-correlation-cause-ols-to-remain-unbiased-even-in-cross-section</link>
      <description><![CDATA[为了使系数估计量在 OLS 中保持无偏，给定回归量的条件误差期望必须为零，$E(u_i |x_i )=0$.
但是，如果我们在误差项中具有序列相关性，这是否不会使误差产生偏差，从而使误差的条件期望不再为零？
例如，如果错误存在序列相关性，那么我们可以拟合方程 $u_i = \phi_i * u_j + \epsilon_i $，则不会这意味着 $u_i$ 现在偏向于具有非零条件均值（因为 $\epsilon_i $ 是 i.i.d)？
例如，如果我们固定了 $x_i$，则更改 $u_j$ 会影响 &lt; span class=&quot;math-container&quot;&gt;$u_i$ 给定 $x_i$？
如果序列相关性被破坏，这是否会违反 OLS 的无偏性？]]></description>
      <guid>https://stats.stackexchange.com/questions/647155/how-does-serial-correlation-cause-ols-to-remain-unbiased-even-in-cross-section</guid>
      <pubDate>Mon, 13 May 2024 16:35:04 GMT</pubDate>
    </item>
    </channel>
</rss>