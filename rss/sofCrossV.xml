<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 24 May 2024 21:14:21 GMT</lastBuildDate>
    <item>
      <title>当所有数据来自同一个人时相关性的独立性假设</title>
      <link>https://stats.stackexchange.com/questions/647922/independence-assumptions-in-correlations-when-all-data-comes-from-same-individua</link>
      <description><![CDATA[这感觉像是一个愚蠢的问题，但无论如何 - 如果所有数据都来自同一个人并且我不想做出任何更广泛的推论/假设，那么常见相关性测试中的独立性假设是否很重要？也就是说，假设我有一个数据集，其中包含 2 个变量的 1000 个观测值，全部来自单个个体，除了绘制散点图之外，我还想计算 r 值......
在上下文中，我稍后可能会访问另一个人的数据，并且能够比较个人之间的 r 值会很好。]]></description>
      <guid>https://stats.stackexchange.com/questions/647922/independence-assumptions-in-correlations-when-all-data-comes-from-same-individua</guid>
      <pubDate>Fri, 24 May 2024 20:54:30 GMT</pubDate>
    </item>
    <item>
      <title>相对精度公式名称？ n = z²(1-p)/e²p</title>
      <link>https://stats.stackexchange.com/questions/647921/relative-precision-formula-name-n-z%c2%b21-p-e%c2%b2p</link>
      <description><![CDATA[我需要知道我最后一年论文的方法部分中样本量计算的相对精度公式名称（标准化）
n = z²(1-p)/e²p]]></description>
      <guid>https://stats.stackexchange.com/questions/647921/relative-precision-formula-name-n-z%c2%b21-p-e%c2%b2p</guid>
      <pubDate>Fri, 24 May 2024 20:51:09 GMT</pubDate>
    </item>
    <item>
      <title>如何计算集合预测的估计方差？</title>
      <link>https://stats.stackexchange.com/questions/647919/how-do-i-calculate-estimated-variance-for-an-ensemble-forecast</link>
      <description><![CDATA[基于相同的数据，但使用截然不同的统计模型，我对一个变量有几个（n）个质量相当的不同预测。对于每个预测，我都生成了未来 m 个周期的估计值，使用标准 R 工具为每个预测生成点估计值和置信区间。我希望将这些估计值合并为未来 m 个周期的单点估计值，以及组合点估计值的单个置信区间。
如果这些估计值的误差均通过正态性检验，我倾向于将组合估计值视为 n 个正态变量的平均值，并相应地计算该平均值的点估计值和置信区间。
这是一个合理的方法吗？还有更好的吗？
这是我第一次尝试集成估计，我对文献中的结果几乎一无所知。因此，请毫不犹豫地阐述显而易见的事情]]></description>
      <guid>https://stats.stackexchange.com/questions/647919/how-do-i-calculate-estimated-variance-for-an-ensemble-forecast</guid>
      <pubDate>Fri, 24 May 2024 19:47:31 GMT</pubDate>
    </item>
    <item>
      <title>我们可以使用卷积网络来学习单词中的屏蔽字母吗？</title>
      <link>https://stats.stackexchange.com/questions/647918/can-we-use-convnets-to-learn-the-masked-letter-in-a-word</link>
      <description><![CDATA[我有兴趣训练 CNN 来学习带有单个掩码字母的单词与该掩码字母之间的关系。例如，如果我的模型是 $M$ 并且输入是“he-lo”，那么它应该预测“l”因为缺少的字母是“l”。注意：我掩盖了单词中的一个字母。
有人提出了类似的问题，但据我所知，没有深入回答：预测单词中缺失的字母
这个任务看起来确实类似于使用掩码词训练 Transformer 的方式。然而，直观上预测单个掩码字母应该更容易，并且可以通过更简单的架构来解决。
我目前将单词表示为形状为 $1 x N$ 的向量，其中 $N$ 是单词的长度，每个条目对应于字母表中字符的索引，即“ab-”将表示为 [0, 1, -1]。
我的模型架构是一个嵌入层，嵌入维度等于$27$，两个堆叠卷积层+最大池化层，之后是一个扁平化层，最后是由一个密集层和最后一个 softmax 输出层组成，该输出层指示模型预测的掩码字符是 26 个字母中的哪一个。代码实现见下文。
我当前的问题：尽管有超过 100 万个训练样本，但我的模型在 41% 左右的准确度上停滞不前（定义为与该输入的正确字符输出匹配的最大预测概率的字符）。我的模型有缺陷吗？我是否低估了这项任务的复杂性，而模型实际上表现得相当好？如有任何建议或反馈，我们将不胜感激。
导入tensorflow为tf
从tensorflow.keras.layers导入嵌入、Conv1D、GlobalMaxPooling1D、密集、输入、掩蔽、Dropout、MaxPooling1D、展平
从tensorflow.keras.models导入模型
从tensorflow.keras.optimizers导入Adam
def getModel():
    输入形状 = (29,)
    类数=26
    输入=输入（形状=input_shape）
    x = 嵌入（input_dim=29，output_dim=27，input_length=None）（输入）
    x = Conv1D(过滤器=64，kernel_size=3，激活=&#39;relu&#39;)(x)
    x = MaxPooling1D(pool_size=2)(x)
    x = Conv1D(过滤器=16，kernel_size=3，激活=&#39;relu&#39;)(x)
    x = MaxPooling1D(pool_size=2)(x)
    x = 展平()(x) 
    x = 密集(100, 激活=&#39;relu&#39;)(x)
    x = 辍学(0.5)(x)
    输出=密集（num_classes，激活=&#39;softmax&#39;）（x）
    模型=模型（输入=输入，输出=输出）
    custom_adam = Adam(学习率=0.003, beta_1=0.99, beta_2=0.999, epsilon=1e-07)
    model.compile（优化器=custom_adam，损失=&#39;categorical_crossentropy&#39;，指标=[&#39;categorical_accuracy&#39;]）
    模型.summary()

    返回模型
]]></description>
      <guid>https://stats.stackexchange.com/questions/647918/can-we-use-convnets-to-learn-the-masked-letter-in-a-word</guid>
      <pubDate>Fri, 24 May 2024 19:43:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么信度是真实得分方差与总得分方差的比率，而不是真实得分与总得分的比率？</title>
      <link>https://stats.stackexchange.com/questions/647917/why-is-reliability-a-ratio-of-true-score-variance-to-total-score-variance-inste</link>
      <description><![CDATA[可靠性由下式给出：
$r_{xx} = \frac{Var(T)}{Var(X)}$
其中 $T$ 是真实分数，$X$ 是总分。
为什么可靠性不简单：
$r_{xx} = \frac{T}{X}$
其中 $T$ 是所有个人真实分数的总和，$X$ 是是所有个人总分的总和吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647917/why-is-reliability-a-ratio-of-true-score-variance-to-total-score-variance-inste</guid>
      <pubDate>Fri, 24 May 2024 19:14:38 GMT</pubDate>
    </item>
    <item>
      <title>导出贝叶斯线性模型中数据的条件联合概率模型</title>
      <link>https://stats.stackexchange.com/questions/647915/deriving-a-conditional-joint-probability-model-for-the-data-in-a-bayesian-linear</link>
      <description><![CDATA[我一直在阅读 Tony Lancaster 2004 年出版的书“现代贝叶斯计量经济学简介”。在第 116-117 页，Lancaster 导出了线性模型 $p(y,X|\boldsymbol{\beta})$ 的条件联合分布class=&quot;math-container&quot;&gt;$y=X\boldsymbol{\beta}+\epsilon$ 使用 $X$ 的联合分布和残差，$p(\epsilon, X)$。但他在获得结果的过程中使用的换人似乎并不总是合理的。他们有道理吗？
他从目标开始：给定 $X$ 的情况下，对 $\boldsymbol{\beta}$ 进行后验推理 和 $y$，使用贝叶斯定理
$$p(\boldsymbol{\beta}|y,X)\propto p(y,X|\boldsymbol{\beta})p(\boldsymbol{\beta })$$
这需要导出数据的条件联合分布
$$p(y,X|\boldsymbol{\beta})$$
他的策略是首先获得 $\epsilon$ 和 $X$ 的联合分布，假设 $\epsilon$ 和 $X$ 是独立的，而不仅仅是不相关
$$p(\epsilon, X)=p_{\epsilon}(\epsilon)p(X)$$
他的下一步是使用 $y=X\boldsymbol{\beta}+\epsilon$ 对此联合分布进行替换，然后以 $\boldsymbol{\beta}$，产生所需的条件联合分布
$$p(y,X|\boldsymbol{\beta})=p_{\epsilon}(y-X\boldsymbol{\beta})p(X|\boldsymbol{ \beta})$$
我理解这个结果的右侧，只需使用 $\epsilon=y-X\boldsymbol{\beta}$ 即可。但是左边呢？它不能简单地替换 $y=\epsilon$，因为这没有意义。有人可以帮助我更好地理解这个结果的合理性吗？我错过了一些基本的东西吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647915/deriving-a-conditional-joint-probability-model-for-the-data-in-a-bayesian-linear</guid>
      <pubDate>Fri, 24 May 2024 18:09:37 GMT</pubDate>
    </item>
    <item>
      <title>复发事件模型——多次停药的时间</title>
      <link>https://stats.stackexchange.com/questions/647914/recurrent-event-model-time-to-multiple-medication-discontinuations</link>
      <description><![CDATA[我正在使用以下重复事件模型（计算过程样式输入）来绘制多次药物启动的累积平均频率。就像研究中的患者可以在 2 年的观察期内开始使用多种药物一样，他们也可以停止多种药物。
我有以下问题 -

如果有人想总结 2 年期间的停产情况，您想要回答的是什么 - 与启动类似吗？如果是这样，下面的输入数据结构和代码会如何变化？
如果没有，有哪些相关问题。此类数据。

我处理药物数据的经验有限，因此任何论文/代码/链接的指示都会有所帮助。
proc phreg data=meds covs(aggregate) covm;
  类 trt(ref=&#39;B&#39;);
  模型 (TSTART, TSTOP)*STATUS(0) = trt / rl;
  危险比“A与B” trt / diff=参考；
  基线协变量=covd out=outd cmf=_all_/nomean；
  id 主题；
  跑步;
]]></description>
      <guid>https://stats.stackexchange.com/questions/647914/recurrent-event-model-time-to-multiple-medication-discontinuations</guid>
      <pubDate>Fri, 24 May 2024 17:08:13 GMT</pubDate>
    </item>
    <item>
      <title>Ali-Mikhail-Haq 和 Farlie-Gumbel-Morgenstern Copulas 的条件逆函数公式是什么？</title>
      <link>https://stats.stackexchange.com/questions/647911/what-is-the-formula-for-the-conditional-inverse-function-for-the-ali-mikhail-haq</link>
      <description><![CDATA[我正在尝试进行蒙特卡罗模拟，并希望为 Ali-Mikhail-Haq 和 Farlie-Gumbel-Morgenstern Copula 的条件逆函数定义一个函数。下面是我正在寻找的公式的示例 ]]></description>
      <guid>https://stats.stackexchange.com/questions/647911/what-is-the-formula-for-the-conditional-inverse-function-for-the-ali-mikhail-haq</guid>
      <pubDate>Fri, 24 May 2024 16:50:34 GMT</pubDate>
    </item>
    <item>
      <title>计算边际效应与 brms 模型的边际效应对比</title>
      <link>https://stats.stackexchange.com/questions/647910/calculating-contrasts-of-marginal-effects-with-marginaleffects-for-brms-model</link>
      <description><![CDATA[我已经使用 brms 拟合了逻辑模型，并想要计算平均边际效应 (AME)。
库(brms)

模型 &lt;- brm(公式 = 结果 ~ var1 + var2 + var3, family = Bernoulli(), data = data)

var1 是分类的，具有两个级别 (1, 0)，var3 是分类的，具有三个级别（“a”、“b”、“0”）。 c”）。 var3 是另一个变量，在计算边际效应时我不想设置/平均其值。
现在，我想计算 var2 每个级别的 var1 的 AME/斜率。 （我不想使用平均协变量 (MEM)。）
库（边际效应）

斜率 &lt;- avg_slopes(
  模型，
  变量=“var1”，
  通过=“var2”；
) %&gt;%terior_draws()

这给了我：
 术语对比度 var2 估计 2.5 % 97.5 %
 var1 平均值(dY/dX) a 0.0361 -0.1098 0.1735
 var1 平均值(dY/dX) b 0.0618 -0.0454 0.1666
 var1 平均值(dY/dX) c -0.0788 -0.1667 0.0177

现在，我需要这些对比之间的成对对比。即，a - b、a - c 和 b - c 的估计差异。
我可以像这样手动完成：
slopes_a &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;a&quot;)
lopes_b &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;b&quot;)
lopes_c &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;c&quot;)

df &lt;- data.frame(
  `a - b` =lopes_a$draw-slopes_b$绘制，
  `a - c` =lopes_a$draw-slopes_c$绘制，
  `b - c` =lopes_b$draw-slopes_c$绘制
）

这是一种有效的方法吗？是否有更好/更好的方法，例如直接使用 marginaleffects 包？]]></description>
      <guid>https://stats.stackexchange.com/questions/647910/calculating-contrasts-of-marginal-effects-with-marginaleffects-for-brms-model</guid>
      <pubDate>Fri, 24 May 2024 16:50:10 GMT</pubDate>
    </item>
    <item>
      <title>这张图是对 PLS 几何表示的一个很好的总结吗？</title>
      <link>https://stats.stackexchange.com/questions/647908/is-this-image-a-good-summary-of-the-geometric-representation-of-pls</link>
      <description><![CDATA[我很想知道我是否能得到关于我制作的图像的反馈/批评，该图像试图以视觉方式（部分）解释什么是 PLS。口头上我会说我们有三个预测变量（$x_1、x_2、x_3$）和一个响应变量（$y_1$）。然后我会继续说 PLS 寻求最大化预测变量和响应之间的协变。为此，我们对预测变量的第一个潜在变量进行随机猜测（即 $LV_1 = x_1 * \beta_1 + x_2 * \beta_2 + x_3 * \beta_3$，其中 $\beta_n$ 是第 n 个预测变量的载荷），然后将其投影到新空间中，我们从 $LV_1$ 和响应变量中获取分数（因为它只有 1-D，所以分数是其真实值）并绘制它们。
从数学上讲，我们只需对每个猜测使用协方差方程，但在几何表示中，我们会将它们绘制到一组新的轴上（LV 分数 vs y 分数），并存储预测值和真实值之间的误差。然后，我们重复此过程，对 $LV_1$ 的组合进行新的猜测，并存储协方差值，最终，我们将选择 $LV_1$ 的载荷，以产生 x 和 y 之间最大的协方差值。
我绘制的图片左侧有一个 x 空间和 y 空间的示例，后面是使用 $LV_1$ 的一个实例和要绘制的响应值的示例，然后是最右边的一个例子，其中猜测被重复多次，我们现在有一个协方差的“图”可供选择。然后我们继续选择最大协方差（在最右边的图中用虚线表示）。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/647908/is-this-image-a-good-summary-of-the-geometric-representation-of-pls</guid>
      <pubDate>Fri, 24 May 2024 15:43:19 GMT</pubDate>
    </item>
    <item>
      <title>帮助将双指数曲线拟合到原始质谱数据、时间</title>
      <link>https://stats.stackexchange.com/questions/647906/help-fitting-doube-exponential-curve-to-raw-mass-spec-data-time</link>
      <description><![CDATA[我正在用 Python 为氦测量系统编写质谱数据缩减软件，并且可以用手获取双指数函数来拟合我的数据。基本上，质谱室中的气体会随着时间的推移而演变，我们正在尝试将原始数据拟合回t=0。
过去，我们传统上对数据使用线性拟合，因为它在足够短的时间段内通常是线性序列；然而，随着时间的推移，质谱仪测量的气体强度是一个双指数函数：负项表示电离消耗，正项表示从内存中增长。消费或内向增长是否占主导地位，或者数据是否只是沿着基线的零散混乱，通常很难预测。
我正在使用以下功能：
def double_exp_func(x, a1, b1, a2, b2, c):
    返回 -a1 * np.exp(-b1 * x) + a2 * np.exp(-b2 * x) + c


def double_exp_fit(x, y, Analysis_raw_std):

    # 从线性拟合中获取斜率和截距
    斜率、截距 = np.polyfit(x, y, 1)
    
    # 从线性拟合中得到R^2值
    残差 = y - (斜率 * x + 截距)
    ss_res = np.sum(残差 ** 2)
    ss_tot = np.sum((y - np.mean(y)) ** 2)
    r_squared = 1 - (ss_res / ss_tot)

    # 如果数据分散，则使用最小指数贡献来拟合
    如果 r_squared &lt; 0.8: # 对于高度分散的数据
        p0 = [0.01, 0.01, 0.01, 0.01, 截距] # 拟合的最小指数贡献
    别的：
        如果斜率&gt; 0: # 对于正斜率，记忆/向内生长是主导过程（第二个 exp 是主导过程）
            p0 = [1e-10，斜率，1e-12，斜率，截距]
        else: # 对于负斜率，消耗是主导过程（第一个 exp 是主导）
            p0 = [100, 100, 100, 100, 截距]
    
    def cost_function(参数):
        a1, b1, a2, b2, c = 参数
        Fitted_y = double_exp_func(x, a1, b1, a2, b2, c)
        残差 = y -fitting_y
        返回 np.sum(残差 ** 2)
    
    初始参数 = p0
    适合=最小化（cost_function，initial_params，方法=&#39;Nelder-Mead&#39;，选项= {&#39;maxiter&#39;：100000}）
    优化参数 = fit.x
    # 拟合数据
    # 拟合，协方差 = curve_fit(double_exp_func, x, y, p0, maxfev=100000)
    Fitted_y = double_exp_func(x, *optimized_pa​​rams)
    误差 = np.sum((y -fitting_y) ** 2)
    
    返回optimized_pa​​rams

我将数据分为三组：

分散数据（线性 R^2 &lt; 0.8）
数据呈正斜率，记忆/向内生长是主导过程
数据具有负斜率，消耗是主导过程

但是，您可能会注意到，p0 项中的值是......好吧，我在这里盲目了。称它们为有根据的猜测有点夸张。
以下是我的程序提供的原始数据拟合的一些示例：



请注意，右下角的图 5 amu 始终显示平均值而不是拟合值。这是因为 5 amu 是我们的基线（5 amu 处没有气态物质），并且或多或少没有测量到任何内容，因此没有理由将其适合于任何东西。其余的图应该有双经验拟合。
您会注意到“适合”大多数时候只是绘制平坦的线，但是，在过去，我已经成功地拟合了具有不同参数的一些数据，但它并没有转换为数据集的其余部分。 
以下是我对所涉及流程的了解：

指数贡献应该是温和的 - 毕竟，该数据接近线性
其中一个指数项应锁定为负数，另一个指数项锁定为正数，而不是让拟合参数根据需要将数据变为负值和正值。
斜率为正的数据以向内生长为主导过程。
斜率为负的数据以消耗为主导过程。

不过，我是 Python 新手，而且不是数学家，因此我可以使用一些建议来让这些讨厌的双指数拟合发挥作用。
我做错了什么？如何提高找到合适人选的机会？]]></description>
      <guid>https://stats.stackexchange.com/questions/647906/help-fitting-doube-exponential-curve-to-raw-mass-spec-data-time</guid>
      <pubDate>Fri, 24 May 2024 15:16:06 GMT</pubDate>
    </item>
    <item>
      <title>使用偏度和峰度估计 Box-Cox 变换 Lambda</title>
      <link>https://stats.stackexchange.com/questions/647903/estimate-box-cox-transformation-lambda-using-skewness-and-kurtosis</link>
      <description><![CDATA[我对一种仅基于给定样本的偏度和峰度来为 Box-Cox 变换找到合适的 Lambda 参数的方法感兴趣。
即，如果偏度和峰度表明数据可能是正态的（即偏度为 0，峰度为 3），则该方法应选择 Lambda 为 1。
如果偏度和峰度偏离这些值，则应选择 Lambda，以便尽可能纠正偏差。
我无法找到提出这种方法的先前工作。
有没有人可以在这方面帮助我？]]></description>
      <guid>https://stats.stackexchange.com/questions/647903/estimate-box-cox-transformation-lambda-using-skewness-and-kurtosis</guid>
      <pubDate>Fri, 24 May 2024 14:34:29 GMT</pubDate>
    </item>
    <item>
      <title>人们如何称呼在时间间隔内具有峰值条带的图表？</title>
      <link>https://stats.stackexchange.com/questions/647886/what-do-people-call-a-chart-with-a-strip-of-peak-values-in-time-intervals</link>
      <description><![CDATA[人们如何称呼像下面这样的图表，该图表在 Y 轴上显示天数，在 X 轴上显示一天中的时间，而颜色代表某些值的级别（例如加载、使用计数等）？
图表如下所示：

如果我想在论坛上询问如何使用特定工具实现一个工具，在图像和描述中添加它的最佳方式是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647886/what-do-people-call-a-chart-with-a-strip-of-peak-values-in-time-intervals</guid>
      <pubDate>Fri, 24 May 2024 11:29:36 GMT</pubDate>
    </item>
    <item>
      <title>当应用实体和时间固定效应时，数据会发生什么？</title>
      <link>https://stats.stackexchange.com/questions/647876/what-happens-to-the-data-when-entity-and-time-fixed-effects-are-applied</link>
      <description><![CDATA[假设真实的数据生成过程如下：
Y_it = beta_0 + beta_1 X_it + u_it

当我同时应用实体固定效果和时间固定效果时会发生什么？
(Y_it - Y_i - Y_t) = beta_0 + beta_1 (X_it - X_i - X_t) + (u_it - u_i - u_t)

其中 Y_i = 实体 i 的所有 Y 值的平均值，Y_t = 时间 t 内实体的所有 Y 值的平均值。
这真的是数据发生的情况吗？
这是一个用于说明目的的简单示例：
让我们想象一下原始数据集如下所示：
t t+1 t+2
A 10 20 30
B 20 30 40
C 30 40 50
这些国家的意思是：
A 20
B 30
C 40
从我们得到的原始值中减去这些国家/地区意味着：
&lt;前&gt;&lt;代码&gt;**t** **t+1** **t+2**  

A -10 0 10
B -10 0 10
C -10 0 10
年份平均值为（对于已转换的数据）：
t -10
t+1 0
t+2 10
从我们得到的转换值中减去这些年份意味着：
&lt;前&gt;&lt;代码&gt;**t** **t+1** **t+2**  

A 0 0 10
B 0 0 10
C 0 0 10
因此，我想说，在应用国家和年份固定效应后，转换数据的值是，例如，顶部链接的第一个值是：Y_it - Y_i - Y_t = 10 - 20 - ( -10) = 0。]]></description>
      <guid>https://stats.stackexchange.com/questions/647876/what-happens-to-the-data-when-entity-and-time-fixed-effects-are-applied</guid>
      <pubDate>Fri, 24 May 2024 09:34:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么在此随机效应方差分析中估计的总体方差不等于估计的 $\sigma^2 + \tau^2$？</title>
      <link>https://stats.stackexchange.com/questions/647826/why-does-estimated-population-variance-not-equal-estimated-sigma2-tau2-i</link>
      <description><![CDATA[随机效应方差分析模型通常写为
$Y_{ij} = \gamma_{00} + u_{0j} + \epsilon_{ij}$
。结果变量的总方差分解为
$var(Y_{ij}) = \tau^2 + \sigma^2$
其中$\tau^2$表示$u_{0j}$和&lt;的方差span class=&quot;math-container&quot;&gt;$\sigma^2$ $\epsilon_{ij}$ 的方差。
我有一些代码可以创建 $\sigma^2$ 和 $\tau^2$ 的估计值span&gt; 来自人工数据。
然后我运行一个空的多级模型，可以看到 $\sigma^2$ 和 $\ 的估计值tau^2$ 与 lme4 给我的结果完全匹配。
但是，当我将估计总体方差计算为
estimated_population_variance &lt;- var(my_data$y) * (N-1)/N

它不等于$\sigma^2 + \tau^2$。为什么不？ $\sigma^2 + \tau^2$ 不就是总方差的分解吗？
我认为这一定与我估计总体方差的方式有关，但我不确定我做错了什么。
代码：
库(lme4)

设置.种子(123) 
组 &lt;- 代表（1:10，每组 = 10）
random_numbers &lt;- 样本（1:99，长度（组），替换 = TRUE）
my_list &lt;- 列表(group = groups, y = random_numbers)
my_data &lt;- as.data.frame(my_list)

N &lt;- 100
组数 &lt;- 10
平均组大小 &lt;- 10

table_of_groups &lt;- my_data %&gt;%
  group_by(组) %&gt;%
  总结（均值 = 均值（y），方差 = var（y），n = n（））

s2within &lt;- 均值(table_of_groups$variance)
估计_sigma2 &lt;- s2within

s2之间 &lt;- sum((table_of_groups$mean-mean(my_data$y))^2) * (1/(num_groups-1))
estimated_tau2 &lt;- s2 Between - (s2within/average_group_size)

empty_model &lt;- lmer(“y ~ 1 + (1 | group)”, data = my_data) 
摘要（空模型）

估计总体方差 &lt;- var(my_data$y) * (N-1)/N

估计_tau2 + 估计_sigma2
]]></description>
      <guid>https://stats.stackexchange.com/questions/647826/why-does-estimated-population-variance-not-equal-estimated-sigma2-tau2-i</guid>
      <pubDate>Thu, 23 May 2024 13:55:02 GMT</pubDate>
    </item>
    </channel>
</rss>