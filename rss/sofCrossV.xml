<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 20 Sep 2024 03:19:58 GMT</lastBuildDate>
    <item>
      <title>Cronbach Alpha 的高阶构造变量警告</title>
      <link>https://stats.stackexchange.com/questions/654627/warning-in-higher-order-construct-variable-for-cronbach-alpha</link>
      <description><![CDATA[在我执行 check.keys=TRUE 后，我的 cronbach 值均未发生改变。全部都超过了 0.70 的阈值。
为什么应用后我的值均未发生改变？这仍然是个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654627/warning-in-higher-order-construct-variable-for-cronbach-alpha</guid>
      <pubDate>Fri, 20 Sep 2024 03:09:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么 r 包/函数“plm”会报告随机效应模型的 z 统计量和固定效应模型的 t 统计量？</title>
      <link>https://stats.stackexchange.com/questions/654625/why-does-the-r-package-function-plm-report-a-z-statistic-for-a-random-effects</link>
      <description><![CDATA[从包 plm 的帮助文件中获取示例，
data(&quot;Grunfeld&quot;, package = &quot;plm&quot;)
wi &lt;- plm(inv ~ value + capital,
data = Grunfeld, model = &quot;within&quot;, effect = &quot;twoways&quot;)
swar &lt;- plm(inv ~ value + capital,
data = Grunfeld, model = &quot;random&quot;, effect = &quot;twoways&quot;)
summary(wi)

给出输出
Twoways effects Within Model

调用：
plm(formula = inv ~ value + capital, data = Grunfeld, effect = &quot;twoways&quot;, 
model = &quot;within&quot;)

Balanced Panel: n = 10, T = 20, N = 200

残差：
最小值 第 1 区 中位数 第 3 区 最大值
-162.6094 -19.4710 -1.2669 19.1277 211.8420

系数：
估计标准误差 t 值 Pr(&gt;|t|)
值 0.117716 0.013751 8.5604 6.653e-15 ***
资本 0.357916 0.022719 15.7540 &lt; 2.2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

总平方和：1615600
残差平方和：452150
R 平方：0.72015
调整 R 平方：0.67047
F 统计量：2 和 169 DF 上的 217.442，p 值：&lt; 2.22e-16

并且
summary(swar)

给出
双向效应随机效应模型 
（Swamy-Arora 变换）

调用：
plm(formula = inv ~ value + capital, data = Grunfeld, effect = &quot;twoways&quot;, 
model = &quot;random&quot;)

平衡面板：n = 10, T = 20, N = 200

效应：
var std.dev share
idiosyncratic 2675.43 51.72 0.274
individual 7095.25 84.23 0.726
time 0.00 0.00 0.000
theta： 0.864 (id) 0 (时间) 0 (总计)

残差：
最小值 第 1 区 中位数 第 3 区 最大值
-177.1700 -19.7576 4.6048 19.4676 252.7596

系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -57.865377 29.393359 -1.9687 0.04899 *
值 0.109790 0.010528 10.4285 &lt; 2e-16 ***
资本 0.308190 0.017171 17.9483 &lt; 2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

总平方和：2376000
残差平方和：547910
R 平方：0.7694
调整 R 平方：0.76706
Chisq：2 DF 上的 657.295，p 值：&lt; 2.22e-16

所以（简单的）问题是，为什么 plm 摘要会报告固定效应（即“内部”）模型的参数检验的 t 统计量，以及随机效应模型的参数检验的 z 统计量？我怀疑这只是简单的任意表现不一致，但我有兴趣知道是否有更深层次的原因。]]></description>
      <guid>https://stats.stackexchange.com/questions/654625/why-does-the-r-package-function-plm-report-a-z-statistic-for-a-random-effects</guid>
      <pubDate>Fri, 20 Sep 2024 02:56:10 GMT</pubDate>
    </item>
    <item>
      <title>验证不等概率样本中记录的抽样概率</title>
      <link>https://stats.stackexchange.com/questions/654622/validating-recorded-sampling-probabilities-in-an-unequal-probability-sample</link>
      <description><![CDATA[我有一个包含 $n$ 个对象的样本，据称是从 $N$ 的大量样本中抽取 $n$ 次并放回获得的，其中每个对象在每次抽取中被选中的概率为 $p_i$。有些项目被抽样多次，并且我对每个对象都有计数（但大多数只抽样一次）。因此，我们可以将抽样过程视为从具有 N 个类别的多项分布中抽取。但是，我对抽样过程不信任，并想测试该假设。是否有任何标准方法可以检查这一点？乍一看，似乎只需对整个人群进行卡方检验即可，但在实践中，这并不是很有吸引力，因为我不想（或者可能无法）获得整个人群的抽样概率，而且几乎所有计数都是 0 或 1。我曾尝试想办法仅对样本计数进行卡方检验，将其视为概率为 $p_i/\sum p_i$ 的多项分布，其中总和在样本上，但这仍然存在大多数计数为 1 的问题，而且这似乎非常敏感。有没有标准方法可以做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/654622/validating-recorded-sampling-probabilities-in-an-unequal-probability-sample</guid>
      <pubDate>Fri, 20 Sep 2024 01:21:44 GMT</pubDate>
    </item>
    <item>
      <title>根据散点图的非线性关系</title>
      <link>https://stats.stackexchange.com/questions/654621/non-linear-relationship-according-to-scatterplot</link>
      <description><![CDATA[我在 stata 中做了线性回归，然后做了 rvfplot。然后我看到一个散点图，其中所有点都随机地在零上方和下方，但图的左侧是一条具有负斜率的实线。这看起来不像是线性关系，尽管我认为我的数据应该通过线性回归进行分析。我认为这是因为我的因变量中有一些零值，而一些自变量中也有 0 值。此外，我已经转换了变量。所以在转换之前和之后我都遇到了问题。之前，没有线，但最左边有一组点（可能又是零）。转换后，对因变量取对数，有时对自变量取 sqrt() 或 2xsqrt()，我又得到了线。在转换零值之前，我添加了 +2，以避免零值在对数之后消失。我该怎么办？
不幸的是，我不知道如何在这里上传图片。]]></description>
      <guid>https://stats.stackexchange.com/questions/654621/non-linear-relationship-according-to-scatterplot</guid>
      <pubDate>Thu, 19 Sep 2024 22:01:49 GMT</pubDate>
    </item>
    <item>
      <title>分层回归模型的预测区间</title>
      <link>https://stats.stackexchange.com/questions/654619/prediction-intervals-with-hierarchical-regression-model</link>
      <description><![CDATA[我正在阅读Gelman 和 Hill 撰写的这本数据分析书，并试图理解使用分层模型的预测。在第 273 页，他们演示了如何对已经观察到的组和状态做出新的预测

更一般地说，我们可以在估计的参数 α、β 和 σ 中添加推理不确定性。

我试图理解如何做到这一点。举个例子：
我有一个这样的分层回归模型：
\begin{aligned} &amp; Y = b_{0_j} + b_1 x + \epsilon \\
&amp; b_0 = U + \eta_j \\
\end{aligned&gt;
我将模型拟合到 5 个不同的组 j1、j2、j3、j4 和 j5
我收到的结果参数是

U = 5
$\eta_j = [1, 2, -1, 4, -3]$
b_1 = 3
epsilon 呈正态分布，方差为 2.25
组间方差为 2.25

我想使用此模型对新观察进行预测。新的观察结果在第 5 组中，x 值为 4。我相信我会通过将值代入上述公式来计算点预测，即
\begin{aligned} &amp; b_{0_5} = 5 + (-3) = 2 \\
&amp; Y = 2 + 3(4) = 14 \\
\end{aligned&gt;
我的主要问题是，如何围绕这个估计值构建 95% 的置信区间？我想我可能会加/减 1.96 * std(e)，但这不能解释组间差异。另一方面，我认为完全添加组间变异似乎是错误的，因为组 j5 ($U + \eta_5$) 的截距已经远离平均截距 U。
此外，如果模型具有不同的截距和斜率，构建区间的方法是否相同？如果有组级预测因子怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/654619/prediction-intervals-with-hierarchical-regression-model</guid>
      <pubDate>Thu, 19 Sep 2024 21:01:08 GMT</pubDate>
    </item>
    <item>
      <title>使用不相关特征进行 OLS 高估</title>
      <link>https://stats.stackexchange.com/questions/654617/overestimation-in-ols-using-uncorrelated-features</link>
      <description><![CDATA[我正在使用 OLS 构建最佳线性模型来解释（预测）$Y$的方差，使用两个特征 $X_1$ 和 $X_2$，并考虑以下两个因素：

$X_1$ 和 $X_2$ 不表现出多重共线性，即 $\rho(X_1, X_2) \approx 0 $
$X_1$ 和 $X_2$ 均解释方差的重叠部分在$Y$中，即
$\beta_1 X_1 + \beta_2 X_2$高估了$Y$ 
其中，$\beta_1$和$\beta_2$是两个独立线性回归的结果：$Y = \beta_1 X_1 + \epsilon$和$Y = \beta_2 X_2 + \epsilon$

最好的技术是什么用什么术语来解释#2 中的上述场景？以下是否是解决这种情况的最佳方法：
步骤 1：使用 OLS 估算 $\beta_1$ $Y = \beta_1 X_1 + \epsilon$ 
步骤 2：将误差估算为 $\hat{Y_1} = Y - \beta_1 X_1$ 
步骤 3：使用 OLS 估算 $\hat{Y_1} = \beta_2 X_2 + \epsilon$ 
考虑将其推广到 $n$ 特征 $X_1, X_2, ..., X_n$
背景：
人们可以认为 $X_2$ 是 $X_1$ 的一些非线性变换，几乎没有其他信息内容可以解释 $Y$]]></description>
      <guid>https://stats.stackexchange.com/questions/654617/overestimation-in-ols-using-uncorrelated-features</guid>
      <pubDate>Thu, 19 Sep 2024 20:57:32 GMT</pubDate>
    </item>
    <item>
      <title>Beta 帽条件方差 - Hansen 计量经济学</title>
      <link>https://stats.stackexchange.com/questions/654608/beta-hat-conditional-variance-hansen-econometrics</link>
      <description><![CDATA[我正在研究 Bruce Hansen 的计量经济学，我不知道如何找到第 90 页的条件方差证明。
Hansen 说：
对于任何 $n \times r$ 矩阵 $\mathbf{A} = \mathbf{A}(\mathbf{X})$：
$\text{var}(\mathbf{A}^T\mathbf{y}|\mathbf{X}) = \text{var}(\mathbf{A}^T\mathbf{e}|\mathbf{X}) = \mathbf{A}^T\mathbf{D}\mathbf{A}$，其中 $D=\text{diag}(\sigma_1^2, ..., \sigma^2_n)$。
为什么会这样？我可以看到这个步骤，但我不确定如何从完整定义中证明它：$\text{var}(\mathbf{A}^T\mathbf{e}|\mathbf{X}) = \mathbf{A}^T\text{var}(\mathbf{e}|\mathbf{X})\mathbf{A} = \mathbf{A}^T\mathbf{D}\mathbf{A}$.
即我该如何实现这个：$\text{var}(\mathbf{Z}|\mathbf{X}) = \mathbb{E}[(\mathbf{Z} - \mathbb{E}[\mathbf{Z}|\mathbf{X}])(\mathbf{Z} - \mathbb{E}[\mathbf{Z}|\mathbf{X}])^T|\mathbf{X}], \mathbf{\hat\beta} = \mathbf{A}^T\mathbf{y}, \mathbf{A} = \mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}$
我试过了，但得到的矩阵维度一直不匹配向上。]]></description>
      <guid>https://stats.stackexchange.com/questions/654608/beta-hat-conditional-variance-hansen-econometrics</guid>
      <pubDate>Thu, 19 Sep 2024 16:46:25 GMT</pubDate>
    </item>
    <item>
      <title>当每个数据点都带来一个置信区间时，如何在两个或多个组之间进行检验？</title>
      <link>https://stats.stackexchange.com/questions/654615/how-to-run-a-test-between-two-or-more-groups-when-each-data-point-brings-a-confi</link>
      <description><![CDATA[早上好，
我最近开始研究一个数据集，但作为一名应届毕业生，我的经验有限，这阻碍了我取得进展。在执行了项目所需的稀疏化之后，我现在有一个包含 24 个指标的数据框，每个指标都伴随着由随机稀疏化过程生成的置信区间。这 24 个指标属于 2 个不同的非独立组，我需要进行比较。如果没有置信区间，我只能使用均值，我会使用配对 t 检验。
为了解释通过稀疏化获得的置信区间，我尝试使用从区间得出的方差执行加权 t 检验。但是，我对我的方法没有信心，也找不到任何支持这种方法的在线文章。谢谢您的帮助。
这是我的数据框：
size1 &lt;- c(32.67256,30.59280,33.56214,30.15552,29.02073,24.92427,34.79967,34.26559,29.33457,25.75716,27.91638,33.87884)
size2 &lt;-c(34.18847,30.94369,37.38462,22.96785,27.98805,31.39834,30.26401,33.59788,36.19856,31.19667,21.27245,28.87137)
尺寸 &lt;-c(尺寸1,尺寸2)
尺寸1CI05 &lt;-c(29.50177,26.23491,29.60487,25.94388,24.48941,21.78924,29.24082,28.09738,25.20056,21.21051,24.40705,30.08490)
size2CI05 &lt;-c(29.51654,23.75201,31.29203,17.60071,21.92296,26.38236,23.69115,26.15880,26.44932,26.72620,17.48761,23.76434)
sizeCI05 &lt;-c(size1CI05,size2CI05)
size1CI95 &lt;-c(35.84336,34.95070,37.51941,34.36716,33.55205,28.05929,40.35851,40.43380,33.46857,30.30381,31.42571,37.67278) 
size2CI95 &lt;-c(38.86039,38.13538,43.47722,28.33500,34.05315,36.41432,36.83687,41.03696,45.94780,35.66713,25.05730,33.97840)
sizeCI95 &lt;-c(size1CI95,size2CI95)
group &lt;- c(c(rep(&quot;1&quot;,12),rep(&quot;2&quot;,12))
df &lt;-data.frame(size,sizeCI05,sizeCI95,group)

我还按要求添加了 dput 输出：
df &lt;-structure(list(size = c(32.67256, 30.5928, 33.56214, 30.15552, 
29.02073, 24.92427, 34.79967, 34.26559, 29.33457, 25.75716, 27.91638, 
33.87884, 34.18847, 30.94369, 37.38462, 22.96785, 27.98805, 31.39834, 
30.26401, 33.59788, 36.19856, 31.19667, 21.27245, 28.87137), 
size05CI = c(29.5017662019491, 26.2349058385758, 29.6048735822698, 
25.9438818737996, 24.4894140422372, 21.7892435074709, 29.2408246478003, 
28.097376313181, 25.2005633026381, 21.2105115402011, 24.4070457401779, 
30.0849045894848, 29.5165407340379, 23.7520071901393, 31.2920265619889, 
17.6007091843407, 21.9229562124319, 26.3823600157115, 23.6911524798744, 
26.158796800294, 26.4493176960902, 26.7262037524753, 17.4876088906701, 
23.7643440166671), size95CI = c(35.8433590913617, 34.9506991382152, 
    37.5194133001315、34.3671592174968、33.5520534941053、28.0592932279925、40.3585126169722、40.4338032764411、33.46857135214 04、30.303809204322、31.4257104335821、37.6727751129716、38.8603902871733、38.1353758799793、43.4772171945701、 28.3349990423006, 34.0531465846994, 36.4143170389483, 
36.8368654619253, 41.0369594182707, 45.9478039221974, 35.6671344715295, 
25.0572999101401, 33.9783955274194), group = c(&quot;1&quot;, &quot;1&quot;, 
&quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2&quot;, &quot;2&quot;, 
&quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;)), class = &quot;data.frame&quot;, row.names = c(NA, 
-24L))

这是我尝试做的：
install.packages(&quot;weights&quot;,dependencies=T)
library(weights)
SE1 &lt;-(size1CI95-size1CI05)/3.919928
SE2 &lt;-(size2CI95-size2CI05)/3.919928
sizepaired &lt;-size1-size2
combSE &lt;-sqrt(SE1^2+SE2^2)
weights &lt;-1/combSE^2
wtd.t.test(x=sizepaired,y=0,weight=weights)

我的方法是使用加权检验来考虑由于检验中的稀疏性而产生的置信区间（即标准偏差），其中权重来自标准偏差。但是，我不确定这是否是一种有效的方法，而且我还没有找到任何涉及这种方法的科学文章。我的同事有些怀疑，不愿意使用“实验性”方法。
此外，我目前正在使用参数检验，但在我的数据中（我没有在这里包括），有些数据不遵循正态分布。因此，我应该考虑如何进行加权配对非参数检验]]></description>
      <guid>https://stats.stackexchange.com/questions/654615/how-to-run-a-test-between-two-or-more-groups-when-each-data-point-brings-a-confi</guid>
      <pubDate>Thu, 19 Sep 2024 16:36:06 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法用数字方式确定期望 E[f(Z)]，其中 Z 是具有参数 lambda 的泊松随机变量？</title>
      <link>https://stats.stackexchange.com/questions/654583/is-there-a-way-to-numerically-determine-the-expectation-efz-where-z-is-poiss</link>
      <description><![CDATA[由于$E[f(Z)]=\Sigma_{z=0}^{\infty} f(z)Pr(Z=z) $和$Z \sim Poiss(\lambda)$。我特别想问的问题是，当我以数字方式确定期望值时，是否有一种标准方法可以截断此总和。]]></description>
      <guid>https://stats.stackexchange.com/questions/654583/is-there-a-way-to-numerically-determine-the-expectation-efz-where-z-is-poiss</guid>
      <pubDate>Thu, 19 Sep 2024 03:40:43 GMT</pubDate>
    </item>
    <item>
      <title>关于离散时间生存分析的修改问题（固定间隔，固定效应时间）</title>
      <link>https://stats.stackexchange.com/questions/654562/a-modified-question-about-discrete-time-survival-analysis-with-fixed-intervals</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654562/a-modified-question-about-discrete-time-survival-analysis-with-fixed-intervals</guid>
      <pubDate>Wed, 18 Sep 2024 18:54:52 GMT</pubDate>
    </item>
    <item>
      <title>对零假设下 p 值的均匀分布感到困惑</title>
      <link>https://stats.stackexchange.com/questions/654484/confused-about-the-uniform-distribution-of-p-values-under-the-null-hypothesis</link>
      <description><![CDATA[我目前正在学习一门生物信息学入门课程，我对零假设下（当零假设为真时）p 值的均匀分布感到困惑。
已经广泛证明和讨论过，在正确的条件下，当零假设成立时，p 值是均匀分布的，正如这篇文章所解释的那样：为什么 p 值在零假设下是均匀分布的？。
我的困惑更多的是关于这个想法背后的直觉和实际意义。
例如，让我们考虑一个简单的（尽管是离散的）场景：抛硬币。如果掷出正面的概率（表示为&quot;1&quot;）为 $p = 0.3$，且我们进行 $1000$ 次抛掷，我们预计大多数情况下掷出正面的次数约为 $300$ 次。因此，我们预计在大多数情况下 p 值将在 $P(X &lt; 300)$ 左右（左尾 p 值，其中 $X$ 是二项式（$1000$，$p$）变量）。
但是，这似乎与 p 值在零假设下应均匀分布的想法相矛盾。如果 p 值是均匀的，那么所有 p 值是否都应该具有同等可能性，而不是聚集在某个值附近？
有人可以解释为什么这个均匀分布在这个例子中仍然成立，或者我是否误解了一些基本的东西？
我已运行以下模拟作为示例：
library(ggplot2)

n_experiments &lt;- 100000 # 实验次数（抛硬币）
n_trials &lt;- 100000 # 每个实验的试验次数
p &lt;- 0.3 # 获得“1”（成功）的概率

# 模拟实验
set.seed(123) # 为了可重复性
results &lt;- rbinom(n_experiments, n_trials, p) # 每个实验中 1 的数量

# 计算每个实验的 p 值
p_values &lt;- sapply(results, function(x) pbinom(x, n_trials, p))

# 创建用于绘图的数据框
df &lt;- data.frame(Experiment = 1:n_experiments, 
Number_of_1s = results, 
p_value = p_values)

# 绘制“1”的数量直方图
ggplot(df, aes(x = Number_of_1s)) +
geom_histogram(binwidth = 1, fill = &#39;skyblue&#39;, color = &#39;black&#39;) +
labs(title = &quot;100 次实验中 1 的数量直方图&quot;, 
x = &quot;1 的数量&quot;, 
y = &quot;频率&quot;) +
theme_minimal()

# 绘制 p 值的直方图
ggplot(df, aes(x = p_value)) +
geom_histogram(binwidth = 0.01, fill = &#39;coral&#39;, color = &#39;black&#39;) +
labs(title = &quot;100 次实验中的 p 值直方图&quot;, 
x = &quot;p 值&quot;, 
y = &quot;频率&quot;) +
theme_minimal()

我发现以下预期结果对我来说感觉矛盾，值的分布不均匀，但 p 值的分布是均匀的。

]]></description>
      <guid>https://stats.stackexchange.com/questions/654484/confused-about-the-uniform-distribution-of-p-values-under-the-null-hypothesis</guid>
      <pubDate>Tue, 17 Sep 2024 13:24:56 GMT</pubDate>
    </item>
    <item>
      <title>不保留部分顺序的收缩</title>
      <link>https://stats.stackexchange.com/questions/654394/shrinkage-that-does-not-preserve-partial-order</link>
      <description><![CDATA[在估计多元均值时，所有收缩方法是否都保留部分顺序？我的意思是，MLE 估计的均值的顺序在收缩后会改变吗？
显然，形式为 $\hat{m}&#39; = (1-\lambda)\hat{m}$ 的收缩是保序的（确保 $\lambda$ 介于 0 和 1 之间）。
是否有任何不保留部分顺序的收缩方法（基本上在收缩后使它们相等不算在内，例如硬阈值）。
显然，人们可以将任意先验放在某个地方来实现这一点。但我更希望的是经验贝叶斯设置。]]></description>
      <guid>https://stats.stackexchange.com/questions/654394/shrinkage-that-does-not-preserve-partial-order</guid>
      <pubDate>Sun, 15 Sep 2024 10:37:41 GMT</pubDate>
    </item>
    <item>
      <title>如何使用核技巧在 SVM 中拟合数据？</title>
      <link>https://stats.stackexchange.com/questions/645752/how-does-fitting-data-work-in-svm-using-the-kernel-trick</link>
      <description><![CDATA[在 SVM 中，我了解如何将一些数据转换为更高维度后对其进行拟合。 （例如：$(X_1, X_2) \to (X_1, X_2, X_1^2, X_2^2, X_1X_2)$，这是 2 维到 5 维的转换）。
为了拟合这些数据，我们将最大化 $M$，并满足 $\sum_{j=1}^p B_j^2 = 1$，使得 $y_i(B_0 + B_1x_{i1} + ... + B_px_{ip}) \geq M(1-e_i)$，其中 $e_i \geq 0$，$\sum_{i=1}^n e_i \leq C$ 且 $p$ 是更高维度。
然而，使用核技巧，我们完全跳过了将数据实际映射到更高维度的步骤，而只是查看 $n \choose 2$ 个数据点之间的关系。在这种情况下，我不明白如何拟合训练数据，因为我们只看到它们成对的点积关系。
更具体地说，如果我们不知道更高维度中 $y_i, x_{i1}, ... x_{ip}$ 的值，我们将如何计算此示例中的 $y_i(B_0 + B_1x_{i1} + ... + B_px_{ip})$？]]></description>
      <guid>https://stats.stackexchange.com/questions/645752/how-does-fitting-data-work-in-svm-using-the-kernel-trick</guid>
      <pubDate>Wed, 24 Apr 2024 17:32:08 GMT</pubDate>
    </item>
    <item>
      <title>什么是不依赖于分类“难度”的二元分类评分规则？</title>
      <link>https://stats.stackexchange.com/questions/638717/what-is-a-scoring-rule-for-binary-classification-that-is-not-dependent-on-the-d</link>
      <description><![CDATA[考虑一个模型，该模型预测某些二元事件 $Y$ 的概率（可能给定一些特征 $X$）。将 $Y$ 发生的估计概率表示为 $\hat{p}$。评估$\hat{p}$的（适当）评分规则的一个可能选择是逻辑评分规则：
$$-\left(Y\log\left(\hat{p}\right) + (1 - Y)\log\left(1 - \hat{p}\right)\right)$$
我的问题是，在做出最佳决策时，预期分数的值取决于真实的$P(Y) = p$。假设 $p = .9$，则最佳 $\hat{p} = .9$，这会最小化预期分数，在本例中约为 .325。
现在，假设 $p = .5$。在本例中，最佳 $\hat{p} = .5$，预期分数为 .693，是前一种情况下最佳分数的两倍多。
我有一个贝叶斯回归模型，我首先在几百个数据点上进行训练。然后，我使用得到的后验概率为接下来的几百个数据点生成 $\hat{p}$（称为数据集 A）。然后，我在原始训练集和数据集 A 上训练模型，并为另外几百个数据点生成 $\hat{p}$（称为数据集 B）。所有 3 个数据集在时间上相互跟随。
数据集 A 上的平均逻辑损失比数据集 B 上的平均逻辑损失低得多。对此的简单解释是，该模型在某种程度上“更好”在估计数据集 A 上的概率方面比在数据集 B 上更差，并且模型不知何故没有学到任何东西和/或 A 和 B 之间存在这样的分布转变，以至于模型“变得更糟”。
然而，我相信正在发生的事情是，数据集 A 中的许多点比数据集 B 中的更容易预测，即真正的 $p$ 在数据集 A 中更接近 0 或 1，在数据集 B 中更接近 .5。因此，数据集 B 中的平均逻辑损失更高，不是因为模型变得更差，而是因为问题变得更难。
如何调和这一点？我想要一些指标来告诉我我的模型在估计这些概率方面有多“好”，而不依赖于真实概率的底层分布。存在这样的指标吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638717/what-is-a-scoring-rule-for-binary-classification-that-is-not-dependent-on-the-d</guid>
      <pubDate>Tue, 06 Feb 2024 21:51:53 GMT</pubDate>
    </item>
    <item>
      <title>比较 IV 和 OLS 结果以获取有关遗漏变量相关性的信息</title>
      <link>https://stats.stackexchange.com/questions/601230/comparing-iv-and-ols-results-to-get-infomation-about-the-omitted-variable-correl</link>
      <description><![CDATA[在研讨会上，人们经常将 OLS 估计结果（由于内生性而有偏差）与 IV 策略估计结果（无偏差）进行比较。假设 IV 假设一切正常，我的问题集中在我们可以从比较 IV 和 OLS 估计中了解到哪些关于遗漏变量偏差的信息。我认为这样说是正确的（但我不确定），如果 OLS 估计大于 IV 估计，则意味着遗漏变量与结果变量和感兴趣的回归量都呈正相关（或负相关）：因此通过该渠道，X 对 Y 的真实影响被放大，OLS 无法解开这一点。反之亦然，如果 IV 大于 OLS，则意味着遗漏变量与 X 和 Y 呈相反方向相关（即与 X 呈正相关，与 Y 呈负相关，或反之亦然）。在这种情况下，X 对 Y 的真实影响被省略的变量减弱，OLS 再次无法看到这一点。但是，我想知道这是否仅当 X 对 Y 的真实影响具有正号时才成立。如果它具有负号，那么这一切是否应该反过来呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/601230/comparing-iv-and-ols-results-to-get-infomation-about-the-omitted-variable-correl</guid>
      <pubDate>Sun, 08 Jan 2023 10:18:25 GMT</pubDate>
    </item>
    </channel>
</rss>