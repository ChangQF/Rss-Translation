<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 13 Dec 2024 09:19:01 GMT</lastBuildDate>
    <item>
      <title>模拟多级数据以获得特定的边际 R 平方值</title>
      <link>https://stats.stackexchange.com/questions/658662/simulating-multilevel-data-to-achieve-a-specific-marginal-r-squared-value</link>
      <description><![CDATA[我正在致力于模拟多级数据，目标是通过模拟实现特定的边际 R 平方值。鉴于多级建模中的方差分解在调整不同级别的参数时会变得相当复杂，我一直在尝试通过模拟来近似边际 R 平方值。
以下是 R 代码片段，用于具有两个 1 级预测因子（X1ij、X2ij）和两个 2 级预测因子（Z1j、Z2j）的两级模型的基本数据生成过程：
# 加载必要的库
library(lme4) # 用于拟合混合模型

# # 设置种子以实现可重复性
# set.seed(12654)

# 模拟参数
n_groups &lt;- 30 # 2 级组数
n_per_group &lt;- 30 # 每组的 1 级单元数
n &lt;- n_groups * n_per_group # 总数观察

# 固定效应
gamma_00 &lt;- 0 # 截距
gamma_10 &lt;- 1 # 1 级预测器的初始斜率（X1ij - 待调整）
gamma_01 &lt;- 1 # 2 级预测器的初始斜率（Z1j - 待调整）
gamma_20 &lt;- 0 # 附加 1 级预测器的斜率（X2ij）
gamma_02 &lt;- 0 # 附加 2 级预测器的效应（Z2j）

# 方差分量
sigma2_e &lt;- 1 # 残差方差（epsilon）
sigma2_U0j &lt;- 0.5 # 随机截距方差

# 数据生成过程函数
dgp_function &lt;- function(n_groups, n_per_group, sigma2_e, sigma2_U0j,
gamma_00, gamma_10, gamma_01, gamma_20, gamma_02) {

# 模拟 2 级预测因子 (Z1j 和 Z2j)
Z1j &lt;- rnorm(n_groups, mean = 0, sd = 1)
Z2j &lt;- rnorm(n_groups, mean = 0, sd = 1)

# 初始化数据存储
data &lt;- data.frame()

# 为每个组生成数据
for (j in 1:n_groups) {
# 组 j 的随机截距
b_j &lt;- rnorm(1, mean = 0, sd = sqrt(sigma2_U0j))

# 1 级预测因子 (X1ij 和 X2ij)
X1ij &lt;- rnorm(n_per_group, mean = 0, sd = 1)
X2ij &lt;- rnorm(n_per_group, mean = 0, sd = 1)

# 1 级残差
epsilon &lt;- rnorm(n_per_group, mean = 0, sd = sqrt(sigma2_e))

# 生成结果变量 Y
Y &lt;- (gamma_00 + b_j) + gamma_10 * X1ij + gamma_01 * Z1j[j] + gamma_20 * X2ij + gamma_02 * Z2j[j] + epsilon

# 为该组创建数据框
group_data &lt;- data.frame(
group = j,
X1ij = X1ij,
X2ij = X2ij,
Z1j = Z1j[j],
Z2j = Z2j[j],
Y = Y
)

# 与主数据框合并
data &lt;- rbind(data, group_data)
}

return(data)
}

我的目标是通过使用缩放因子更新模型参数 gamma_10 和 gamma_01，以迭代调整它们，以近似所需的边际 R 平方值。但是，我使用的方法产生了一些奇怪的结果，我不确定是否有更可靠的方法。
这是我的代码的一部分，我调整了 gamma_10 和 gamma_01 以尝试达到所需的 R 平方：
不幸的是，我没有这种模拟的经验，因此任何想法或文献参考都值得赞赏。
# 期望的边际 R 平方
desired_marginal_R2 &lt;- 0.25

# 实现的 R2 和迭代容差和计数器的占位符
achieved_R2 &lt;- 0
容差 &lt;- 0.01
迭代 &lt;- 1
max_iterations &lt;- 100

# 迭代调整 gamma_10 和 gamma_01 以实现所需的边际R2
while (abs(achieved_R2 - desire_marginal_R2) &gt; tolerance &amp;&amp; iteration &lt;= max_iterations) {
# 生成数据
data &lt;- dgp_function(n_groups, n_per_group, sigma2_e, sigma2_U0j,
gamma_00, gamma_10, gamma_01, gamma_20, gamma_02) 

# 拟合混合模型
model &lt;- lmer(Y ~ X1ij + Z1j + (1 | group), data = data)

# 使用 performance 包计算边际 R2
reached_R2 &lt;- performance::r2(model, details = TRUE)$R2_marginal

# 根据实现的 R2 调整 gamma_10 和 gamma_01（启发式）
scaling_factor &lt;- sqrt(desired_marginal_R2 / reached_R2)
gamma_10 &lt;- gamma_10 * scaling_factor
gamma_01 &lt;- gamma_01 * scaling_factor

# 增加迭代计数器
iteration &lt;- iteration + 1
}

# 输出结果
cat(&quot;Achieved Marginal R2:&quot;, reached_R2, &quot;\n&quot;)
cat(&quot;Desired Marginal R2:&quot;, desire_marginal_R2, &quot;\n&quot;)
cat(&quot;迭代次数：&quot;, 迭代次数 - 1, &quot;\n&quot;)
cat(&quot;调整后的 gamma_10：&quot;, gamma_10, &quot;\n&quot;)
cat(&quot;调整后的 gamma_01：&quot;, gamma_01, &quot;\n&quot;)

]]></description>
      <guid>https://stats.stackexchange.com/questions/658662/simulating-multilevel-data-to-achieve-a-specific-marginal-r-squared-value</guid>
      <pubDate>Fri, 13 Dec 2024 08:24:27 GMT</pubDate>
    </item>
    <item>
      <title>检查异常值随时间增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</link>
      <description><![CDATA[有人要求我测试多年来高异常值的数量和大小是否有所增加。目的是表明随着时间的推移（基数保持不变），极端情况会越来越多，越来越高。
我有很多例子和年份、年龄组和性别之间的比较，但下面我只会展示一个。有两组数据，恰当地命名为组 1（2022），包含 207 个样本，组 2（2023），包含 250 个样本。 y 轴变量以整数形式测量。
首先，进行 t 检验，表明平均值有所下降。

绘制了箱线图来可视化这一点
应该注意的是，组 2 中有 9 个点高于 10（约为组 1 的平均值），组 2 中有 10 个点约为 10（总共 12 个高异常值），其中组 2 中的顶级异常值高于组 1。所有异常值都经过严格检查，以确认它们是有效的数据点。

并且为了合理性，绘制了 var 随日期变化的散点图。红线表示箱线图的上限，其中任何高于该上限的点都被视为异常值。

这些都表明平均值有所下降，但是有人要求我统计地确认 2023 年是否存在更多和更高的异常值，而不管平均值的行为如何。有人要求我在不同性别、年龄和性别群体中展示这一点，在某些群体中比其他群体更明显。
我该如何进行统计测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</guid>
      <pubDate>Fri, 13 Dec 2024 06:09:28 GMT</pubDate>
    </item>
    <item>
      <title>哪些统计数据最适合用于评估基于常模的能力评估的有效性和可靠性？</title>
      <link>https://stats.stackexchange.com/questions/658660/which-statistics-are-best-practice-for-assessing-the-validity-and-reliability-of</link>
      <description><![CDATA[我计划评估常模参照能力评估的有效性和可靠性。该工具有 5 个与能力相关的子量表。有现成的常模，但我想对我拥有的样本进行一些额外的研究，以增加对该工具的研究内容。
对于标准参照评估，我会考虑的两个统计数据是每个项目的 Cronbach&#39;s alpha 和因子分析。一般来说，这些是否也构成能力评估的最佳实践？]]></description>
      <guid>https://stats.stackexchange.com/questions/658660/which-statistics-are-best-practice-for-assessing-the-validity-and-reliability-of</guid>
      <pubDate>Fri, 13 Dec 2024 05:44:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么不使用这种“矩量法”来估计矩阵正态分布？</title>
      <link>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</link>
      <description><![CDATA[根据维基百科页面，随机矩阵$\bf{X}\in \mathbb{R}^{p\times q}$服从矩阵正态分布$\cal{MN}(\bf M, \bf U, \bf V)$，这意味着
$$ \text{vec}(\bf X) \sim \cal N ( \mathrm{vec} (\bf M), \bf V \otimes \bf U),$$
其中$\bf M \in \mathbb{R}^{p\times q}$, $\bf U \in \mathbb{R}^{p\times p}$, 以及 $\bf V \in \mathbb{R}^{q\times q}$.
假设我们观察到矩阵值数据 $\bf X_1, \dots, \bf X_n$，它们被假定为 $\cal{MN}(\bf M, \bf U, \bf V)$ 的 i.i.d. 实现。然后，MLE 具有估计值 $\hat{\bf M}$ 作为通常的样本均值，并且 $\bf U$、$\bf V$ 由以下迭代过程给出：
$$
\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X - \bf M) \hat{\bf V}^{-1} (\bf X - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{np} \sum_{i=1}^n (\bf X - \bf M)^\top \hat{\bf U}^{-1} (\bf X - \bf M)。
\end{aligned}
$$
我理解 MLE 框架，但想知道为什么这种方法不起作用：请注意，从同一个维基百科页面
$$\begin{aligned}
\bf E[(\bf X - \bf M) (\bf X - \bf M)^\top] = \bf U\, \mathrm{tr}(\bf V), \\
\bf E[(\bf X - \bf M)^\top (\bf X - \bf M)] = \bf V\, \mathrm{tr}(\bf U)。
\end{aligned}$$
由于 $\bf U$ 和 $\bf V$ 无法通过缩放因子进行识别，我们提出附加限制 $\mathrm{tr}(\bf V) = q$。那么，我认为可以这样估计：
$$\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X - \bf M) (\bf X - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{n\, \mathrm{tr}(\hat{\bf U})} \sum_{i=1}^n (\bf X - \bf M)^\top (\bf X - \bf M)。
\end{aligned}$$
但是，第二种方法与 MLE 不一致。哪里出了问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</guid>
      <pubDate>Fri, 13 Dec 2024 03:43:57 GMT</pubDate>
    </item>
    <item>
      <title>基于密度比估计的分类</title>
      <link>https://stats.stackexchange.com/questions/658658/density-ratio-estimation-based-classification</link>
      <description><![CDATA[考虑分类问题 $p(y \mid x)$，其中 $y$ 是标签，$x$ 是特征向量，例如图像。通常，我们会拟合卷积网络，并根据 $x$ 预测 $y$。昨天我突然想到，根据贝叶斯规则，$\log p(y \mid x) = \log p(y) + \color{blue}{\log \frac{p(x \mid y)}{p(x)}}$。由于$\log p(y)$可以从数据集中轻松估算出来，因此找到对数密度比（蓝色）将等同于找到分类器$p(y \mid x)$。根据密度比技巧（Sugiyama 等人， 2012；Dhuliawala 等人， 2023），可以通过拟合一组分类器 $T_y(x)$（也可以选择拟合一个摊销分类器）来找到对数密度比，该分类器区分 $p(x \mid y)$ 样本和 $p(x)$ 样本。 $T_y(x)$ 的优化条件是 $\mathbb E_{p(x \mid y)}[\log \sigma(T_y(x))] + \mathbb E_{p(x)}[\log (1-\sigma(T_y(x)))]$ 最大化，其中 $\sigma(\cdot)$ 为 S 型函数。因此，$\log p(y \mid x) = \log p(y) + T_y(x)$。一个优点可能是校准标签偏移很简单。
这种方法在实践中使用过吗？如果有人能给我指出相关文献，我将不胜感激。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658658/density-ratio-estimation-based-classification</guid>
      <pubDate>Fri, 13 Dec 2024 03:36:18 GMT</pubDate>
    </item>
    <item>
      <title>与回归分析相比，生存分析在预测方面有哪些优势？</title>
      <link>https://stats.stackexchange.com/questions/658656/are-there-any-advantages-of-survival-analysis-over-regression-for-prediction</link>
      <description><![CDATA[我最近遇到了生存分析，它似乎对于模拟事件发生时间和/或处理审查非常有用。文献中激励性的例子很有意义，例如在临床试验中，我们可能会有参与者退出，或者那些可能经历了不良影响但研究提前结束的人。
在我的应用程序中，我使用机器学习对事件发生时间进行建模并将其视为回归问题。然而，审查在这里并不是一个真正的问题，我想知道生存分析是否会比标准回归方法提供任何优势。
为了简化设置，假设我们有来自小部件工厂的数据。小部件发生故障的平均时间为$\bar{Y} = 40$天（最多 100 天），而数据集可以追溯到几年前，并且有几百万个观察值。因此，确实存在一些右删失，但考虑到数据的大小，这相对微不足道。我们还观察到小部件级协变量 $X$，它们会影响故障时间。
目前，我只是将其建模为非参数回归问题，即学习函数 $f : X \to Y$，该函数可最小化 $L^2$ 经验风险/MSE。如果这里的目标只是预测故障时间 $Y$，而不考虑推理，那么生存分析是否会比回归方法有任何优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/658656/are-there-any-advantages-of-survival-analysis-over-regression-for-prediction</guid>
      <pubDate>Fri, 13 Dec 2024 01:17:45 GMT</pubDate>
    </item>
    <item>
      <title>与基线纵向模型的变化</title>
      <link>https://stats.stackexchange.com/questions/658655/change-from-baseline-longitudinal-model</link>
      <description><![CDATA[我正在研究一个纵向模型，以分析变量 Y 的相对于基线的变化，该变量在基线 Y1 和后续时间点 (Y2、Y3、Y4 ...) 处针对一组患者进行测量。对于每个测量值，我都有相应的标准差 (Y1_SD、Y2_SD、Y3_SD ...)。
(相对于基线的变化) 平均差异 (MD) 很容易计算为 ( Y1 ) 与每个后续 ( Y_i ) 之间的差异。但是，我很难正确定义 平均差异的标准差 (SD_diff)，因为这需要 ( Y1 ) 和 ( Y2、Y3、...) 之间的相关性 ( r )；编码协方差矩阵（例如自回归矩阵）也需要相关性
我引用的 SD_diff 公式是：
SD_diff = sqrt(S1² + S2² - 2 * r * S1 * S2)
我的问题是：

我需要两个元素来构建纵向模型吗？
纵向模型可以只用协方差矩阵编码吗？

方差和协方差矩阵应该如何定义？
假设任何协方差矩阵（例如 AR(1)）在其公式中包含变量方差；这应该由 SD_diff 定义吗？还是由 Yi_SD 定义？

]]></description>
      <guid>https://stats.stackexchange.com/questions/658655/change-from-baseline-longitudinal-model</guid>
      <pubDate>Fri, 13 Dec 2024 00:07:57 GMT</pubDate>
    </item>
    <item>
      <title>适合我的数据进行因果关系检验的算法/测试</title>
      <link>https://stats.stackexchange.com/questions/658654/algorithms-tests-that-suit-my-data-for-causal-relationship-examination</link>
      <description><![CDATA[我有两份在 18 个采样点和 20 个采样日期收集的观测数据，我想测试我的数据中两个变量之间是否存在因果关系。请注意，由于我的数据是观测数据，因此无法对其进行操纵，并且没有假定的有向无环图 (DAG)。基于这些条件，我想知道哪种算法或测试最适合我的数据？
我相信 Peter-Clark (PC) 算法可能适合我的数据，因为它可以用于表格数据，但我正在寻找更多算法/测试来检查因果关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/658654/algorithms-tests-that-suit-my-data-for-causal-relationship-examination</guid>
      <pubDate>Fri, 13 Dec 2024 00:05:20 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用函数 HSD.test 作为 R 中双向方差分析的事后检验吗？</title>
      <link>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</link>
      <description><![CDATA[我已经做过双向方差分析，现在我想做事后检验。我有 2 个因素，并且都只有 2 个类别。我找到了 agricolae 包中的 HSD.test 函数，我非常喜欢它能给出组别和字母，说明各组之间的差异。但我不确定这个函数是否可以用于两个因素，或者它是否只适用于单向方差分析。有人知道吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</guid>
      <pubDate>Thu, 12 Dec 2024 23:05:32 GMT</pubDate>
    </item>
    <item>
      <title>fixest 和 plm 模型的回归表？</title>
      <link>https://stats.stackexchange.com/questions/658650/regression-table-for-fixest-and-plm-models</link>
      <description><![CDATA[我正在使用 fixest 和 plm 模型。我通常对 fixest 对象使用 fixest 的 etable，对 plm 使用 stargazer。问题是它们不相互兼容。有没有支持这两种对象类的命令？
如果没有，我该怎么办？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658650/regression-table-for-fixest-and-plm-models</guid>
      <pubDate>Thu, 12 Dec 2024 22:58:40 GMT</pubDate>
    </item>
    <item>
      <title>和的联合分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658649/joint-distribution-of-sum</link>
      <description><![CDATA[假设 $X_1$ 和 $Y$ 是两个独立且正值的随机变量，其分布为 $F_{X_1}(x_1)$ 和 $F_{Y}(y)$。
现在，我们定义，
$X_2 = X_1 + Y$
$X_1$ 和 $X_2$ 的联合概率分布是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658649/joint-distribution-of-sum</guid>
      <pubDate>Thu, 12 Dec 2024 22:22:44 GMT</pubDate>
    </item>
    <item>
      <title>支持完全交叉研究设计的评分者间信度系数</title>
      <link>https://stats.stackexchange.com/questions/658648/inter-rater-reliability-coefficients-that-support-fully-crossed-study-designs</link>
      <description><![CDATA[我需要计算一项研究的评分者间信度，该研究有大约 100 名评分者针对 12 个研究对象进行。
评分是无顺序或排名的名义数据。
根据 Hallgren 2012，对于评分者不是针对每个受试者随机抽样的情况，Fleiss&#39; Kappa 不是一种选择。
相反，他建议使用 Light&#39;s kappa 或 Davies &amp;而是使用 Fleiss 的 kappa。
但是，Gwet 2014 不鼓励使用 Light 的 kappa，因为“对多个成对 kappa 系数求平均值将产生没有明确含义的测量值”。
对于 Davies &amp; Fleiss 的 kappa，我在 R 中找不到任何可以使用的实现。
目前尚不清楚 Gwet 手册中推荐的其他系数（如 Conger 的 Kappa、Gwet 的 AC1 或 Krippendorf 的 Alpha）是否也适用于完全交叉设计。
或者研究设计最终不是什么大问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658648/inter-rater-reliability-coefficients-that-support-fully-crossed-study-designs</guid>
      <pubDate>Thu, 12 Dec 2024 22:10:00 GMT</pubDate>
    </item>
    <item>
      <title>重复测量二元变量的 Cohen Kappa</title>
      <link>https://stats.stackexchange.com/questions/658643/cohens-kappa-for-repeated-measures-binary-variables</link>
      <description><![CDATA[我进行了一项实验，展示了两种类型的广告信息：第一种类型具有理性风格，第二种具有感性风格。样本多次接触这些信息（重复测量），每次我都会进行问卷调查，询问这些信息是理性的还是感性的。所以我有一个 2x2 矩阵，其中变量 1 是信息类型（理性/感性），变量 2 是信息的识别（理性/感性）。因此，两个变量都是二元名义分类变量。
我想进行操纵检查，看看受试者是否正确识别了信息风格，我应该使用哪种一致性测试？我考虑过 Cohen 的 kappa，但就我而言，我进行了重复测量，并且我读到这可能不是正确的测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/658643/cohens-kappa-for-repeated-measures-binary-variables</guid>
      <pubDate>Thu, 12 Dec 2024 20:35:46 GMT</pubDate>
    </item>
    <item>
      <title>具有排列标准误差的 Wald 检验？</title>
      <link>https://stats.stackexchange.com/questions/658642/wald-test-with-permutation-standard-error</link>
      <description><![CDATA[许多统计检验都基于 Wald 类 z 统计量：$z = \frac{\hat{\theta} - \theta_0}{\text{SE}(\hat{\theta})}$，其中 $\theta$ 是感兴趣的参数，$\theta_0$ 是零假设下的值，SE 是标准误差。然后可以通过将 $z$ 与标准正态 (0,1) 分布进行比较来计算 p 值。
我想知道是否可以基于 $\theta$ 的置换零分布来估计 z 检验中的标准误差？或者 z 检验的标准误差是否应始终在备择假设下计算？
更多上下文：
我知道我可以直接从置换分布计算 p 值，但就我而言，我正尝试进行荟萃分析，这需要每个队列的点估计和标准误差。但是，我使用的统计数据没有封闭形式的标准误差估计，但我已经有了统计数据的置换零分布。我可以只使用置换分布的标准误差进行荟萃分析吗？
我使用的统计数据是来自 GSEA 的“标准化富集分数”(NES)。 NES 没有标准误差公式，而是使用置换检验来计算其 p 值。我想知道是否可以使用置换分布的标准差作为元分析的标准误差估计量。
编辑：这个答案似乎表明在置换零分布下估计标准误差是可以的，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/658642/wald-test-with-permutation-standard-error</guid>
      <pubDate>Thu, 12 Dec 2024 20:35:35 GMT</pubDate>
    </item>
    <item>
      <title>试验次数的二项置信区间</title>
      <link>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</link>
      <description><![CDATA[我有一个过程，其成功概率为已知$p$，失败概率为$q = 1-p$。该过程重复有限但未知的次数$n$。
给定成功次数$r$（失败次数$n-r$，未知），我们应该如何确定导致$r$次成功的试验次数的置信区间？
举一个简单的例子，一枚公平的硬币总共被抛了$n$次，其中150次正面朝上落地。 $n$ 是如何分布的，其平均值的 95% 置信区间是多少，涵盖 $n$ 最可能的值。最可能的$n$ 为 300，最小的$n$ 为 150，最大的$n$ 为无穷大，但我们如何考虑介于两者之间的一切？
注意：如果分布不对称，间隔不必以平均值为中心。

我一直在研究威尔逊分数和其他二项比例置信区间，它们是相关的，但它们估计的是$p$，而不是$n$。我想知道是否存在类似的方法可以准确地找到我所寻找的内容。
由于缺乏估计量的封闭公式，我只能尝试通过拟合两个高斯分布来找到我的置信区间$(n_{low}, n_{high})$的端点，这两个高斯分布的均值为$n_{low}p$和$n_{high}p$，其中$n\hat{p}$（其中$\hat{n} = r/p$是我估计的$n$）落在其 2.5% 面积尾部边界上，使用表格。
（这是我对此的第一个问题论坛）]]></description>
      <guid>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</guid>
      <pubDate>Thu, 12 Dec 2024 17:08:40 GMT</pubDate>
    </item>
    </channel>
</rss>