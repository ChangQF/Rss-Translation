<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 17 Jan 2025 01:13:23 GMT</lastBuildDate>
    <item>
      <title>泊松回归中的虚拟变量与虚拟变量交互作用</title>
      <link>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</link>
      <description><![CDATA[我正在 R 中进行泊松回归，以估计按年龄组和病毒分类的死亡人数，其中相互作用的项是因子：
model &lt;- glm(death_count ~ strain * cohort + age + year,
family = poisson(link = &quot;log&quot;),
offset = log(exposure),
data = df)

我的 df 是面板数据，其中包含每年特定年龄的死亡人数。每年都以特定病毒为特征，每个年龄分配一个群体。我试图找出以病毒 C 为特征的年份中死亡人数减少的统计意义。以下是简化的回归输出：
 估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -15.39575 0.07621 -202.012 &lt; 2e-16 ***
病毒A -1.29389 0.08358 -3.516 0.000437 ***
病毒B 2.80059 0.06230 12.851 &lt; 2e-16 ***
病毒C 4.22142 0.05298 60.800 &lt; 2e-16 ***
群组X -2.99472 0.02494 -39.890 &lt; 2e-16 ***
群组Y -1.76074 0.02747 -27.691 &lt; 2e-16 ***
群组Z -1.31331 0.03499 -8.953 &lt; 2e-16 ***
病毒A：群组X 1.39666 0.07366 5.385 7.24e-08 ***
病毒B：群组X 1.21714 0.05685 3.820 0.000134 ***
病毒C：群组X -3.97906 0.03390 -28.883 &lt; 2e-16 ***
病毒A：队列Y 1.24520 0.10246 2.393 0.016701 * 
病毒B：队列Y 1.05056 0.07980 0.634 0.526360 
病毒C：队列Y -1.43923 0.03422 -12.836 &lt; 2e-16 ***
virusA:cohortZ 0.12472 0.13408 0.930 0.352274 
virusB:cohortZ -0.33748 0.11851 -2.848 0.004404 ** 
virusC:cohortZ -1.13441 0.04187 -3.210 0.001327 ** 

我知道没有交互项的系数是与参考组相比的，但我听说在泊松回归中，交互项并不那么简单。
我有兴趣解释为什么与队列 Y 和 Z 相比，队列 X 感染病毒 C 的死亡率减少幅度最大。我不太明白如何理解交互系数，我也不明白为什么截距为负。如果没有偏移量，截距 = 0.18252，我无法理解这一点，因为我认为添加偏移量会将 DV 变成速率。]]></description>
      <guid>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</guid>
      <pubDate>Fri, 17 Jan 2025 00:16:33 GMT</pubDate>
    </item>
    <item>
      <title>在 Anderson-Gill 模型中，tstart 和 tstop 可以相同吗？</title>
      <link>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</link>
      <description><![CDATA[我正在处理事件发生时间数据，并使用 R 中生存包的 coxph() 函数中实现的 Anderson-Gill 模型。在此模型中，时间间隔由 tstart（开始时间）和 tstop（停止时间）定义，我需要了解如何处理 tstart == tstop 的间隔。
具体来说，我想知道：
在 Anderson-Gill 模型中，tstart 和 tstop 相同是否有效？
如果不是，零长度间隔的含义是什么，应该如何处理？
例如，考虑以下数据集：



id
tstart
tstop
event




1
0
10
0


1
10
10
1


2
5
5
1



当我尝试使用 coxph(Surv(tstart, tstop, event) ~ 1, data = my_data)，我收到有关 tstart == tstop 的警告。我理解零长度间隔并不代表有意义的风险时间，但我想确认解决这种情况的最佳方法。
我应该如何处理这些情况？我应该：排除 tstart == tstop 的行？为 tstop 添加一个小值（例如，tstop = tstart + 1e-5）？还有其他推荐的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</guid>
      <pubDate>Thu, 16 Jan 2025 23:19:41 GMT</pubDate>
    </item>
    <item>
      <title>包含两个样本之间差异值的数据集是否会违反独立性假设？</title>
      <link>https://stats.stackexchange.com/questions/660131/would-a-dataset-that-included-a-value-that-is-the-difference-between-two-samples</link>
      <description><![CDATA[例如，我的数据是这样的：
df &lt;- data.frame(
patch1 = c(&quot;Sample1-1&quot;, &quot;Sample1-1&quot;, &quot;Sample2-1&quot;,&quot;Sample1-2&quot;, &quot;Sample1-2&quot;,&quot;Sample2-2&quot;),
patch2 = c(&quot;Sample2-1&quot;, &quot;Sample3-1&quot;, &quot;Sample3-1&quot;, &quot;Sample2-2&quot;, &quot;Sample3-2&quot;,&quot;Sample3-2&quot;),
Contrast= c(1, 2, 3, 4,5,6),
Species = c(&quot;Species1&quot;, &quot;物种1&quot;、&quot;物种1&quot;、&quot;物种2&quot;、&quot;物种2&quot;、&quot;物种2&quot;))

从个体中抽取样本并相互测量，以得出给定个体样本之间的差异（我在“对比”中看到的）。
我想要做的是使用一个简单的高斯线性模型来查看不同物种之间的对比变量是否存在显着差异。
我想知道这是否会违反独立性假设，如果是，我该如何解决这个问题，我想使用一个随机效应模型，其中 patch1 和 patch2 都是随机效应，这样可行吗？或者我对随机效应如何应用的理解是错误的。
为了进一步说明，我真正想做的是估计在动物体内发现的塑料碎片（我的样本）之间的 dS（色度对比度）是否存在显着差异，以及这种模式在物种层面上是否存在差异。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660131/would-a-dataset-that-included-a-value-that-is-the-difference-between-two-samples</guid>
      <pubDate>Thu, 16 Jan 2025 22:08:55 GMT</pubDate>
    </item>
    <item>
      <title>进行缺失数据插补是否会导致观测值之间的依赖性？</title>
      <link>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</link>
      <description><![CDATA[当对数据集的所有观测值进行插补时，这是否会导致观测值之间的依赖性？那么假设观测值独立的统计模型是否不够充分？
例如，K 最近邻观测值的插补缺失值是其他观测值观测值的函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</guid>
      <pubDate>Thu, 16 Jan 2025 20:41:13 GMT</pubDate>
    </item>
    <item>
      <title>改进小样本标准均值估计量</title>
      <link>https://stats.stackexchange.com/questions/660126/improving-standard-mean-estimator-for-small-samples</link>
      <description><![CDATA[我有一系列 $X_1,\ldots X_n$ 独立同分布随机变量，其期望值为有限值 $\mu$，需要对其进行估计。标准估计量是 $\frac{X_1+\ldots+X_n}{n}$，但我希望避免出现异常值（当 $X_i$ 为极值时），因为 $n$ 很小。我们如何避免出现异常值？为了更精确，我需要使估计器更稳定，但不能删除值。
如果我们尝试$X_1,\frac{X_1+X_2}{2},\frac{X_1+X_2+X_3}{3},\ldots \frac{X_1+\ldots+X_n}{n}$并取中位数会怎样？这会有帮助吗？统计属性是什么？
我很感激任何评论和想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/660126/improving-standard-mean-estimator-for-small-samples</guid>
      <pubDate>Thu, 16 Jan 2025 19:52:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么在使用最大似然法进行参数估计时对数加性模型被认为比其他模型更准确</title>
      <link>https://stats.stackexchange.com/questions/660124/why-is-the-log-additive-model-considered-more-accurate-than-other-models-in-para</link>
      <description><![CDATA[我试图通过 Phoenix NLME 中使用的不同误差模型更好地掌握参数估计理论。对数加性模型似乎对我的用例表现更好，我正在尝试了解原因。我正在整体上进行评估（图形和定量测量），但非常看重 -2LL 分数。我在网上偶然发现了以下说法：

这是因为误差模型在对数空间中变为可加的，从而可以实现更高的性能和准确性。

因此，该模型具有以下形式
log(value) = log(predicticed_value) + error

有人能解释一下为什么这种形式比普通的加法或比例误差项具有某种数值优势吗？
引用来源]]></description>
      <guid>https://stats.stackexchange.com/questions/660124/why-is-the-log-additive-model-considered-more-accurate-than-other-models-in-para</guid>
      <pubDate>Thu, 16 Jan 2025 19:05:35 GMT</pubDate>
    </item>
    <item>
      <title>推断回归拟合中存在异方差</title>
      <link>https://stats.stackexchange.com/questions/660123/inference-on-the-presence-of-heteroscedasticity-in-regression-fit</link>
      <description><![CDATA[我已经拟合了一个简单的线性回归，如下所示
dat = structure(list(A = c(-3.673, -4.914, -4.556, -4.732, -3.36, -3.731, 
-5.069, -5.263, -5.054, -3.711, -4.159, -3.191, -5.035, -5.205, 
-4.809, -5.485, -3.621, -4.551, -3.989, -3.963, -5.092, -4.508, 
-6.163, -4.923, -4.022, -3.098), B = c(0.01, 0.016, 0.011, 0.023, 
-0.014, 0.036, 0.083, 0.082, 0.03, 0.005, 0.025, 0.012, 0.027, 
0.056, 0.023, 0.103, 0.009, 0.02, 0.033, 0.051, 0.076, 0.004, 
0.049, 0.052, 0.033, -0.032), C = c(-0.205, -0.15, -0.378, -0.751, 
0.304, -0.314, 0.587, 0.258, 0.147, -0.379, -0.271, -0.527, -0.076, 
-0.149, -0.001, 0.412, 0.021, -0.182, -0.363, -0.447, 0.335, 
0.108, 1.209, 0.035, -0.116, -0.319)), row.names = c(NA, -26L
), class = &quot;data.frame&quot;)

MyModel = lm(A ~ B + C, data = dat)

&gt; print(summary(MyModel))

调用：
lm(formula = A ~ B + C, data = dat)

残差：
最小值 1Q 中位数 3Q 最大值 
-0.8979 -0.4668 0.1139 0.3984 0.7566 

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) -4.0786 0.1619 -25.198 &lt; 2e-16 ***
B -13.0134 3.7676 -3.454 0.00216 ** 
C -0.7241 0.2879 -2.515 0.01935 * 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：23 个自由度上的 0.5183

多重 R 平方：0.5904，调整后的 R 平方：0.5547

F 统计量：2 和 23 DF 上的 16.57，p 值：3.488e-05

但是，如果我想获得异方差稳健估计，我会得到
library(sandwich)
&gt; print(coeftest(MyModel, vcov = vcovHC(MyModel, type = &quot;HC0&quot;)))

系数的 t 检验：

估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) -4.07864 0.16581 -24.5980 &lt; 2.2e-16 ***
B -13.01339 3.40801 -3.8185 0.000882 ***
C -0.72411 0.34479 -2.1001 0.046885 * 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

正如您所见，对变量 C 重要性的推断会根据异方差稳健估计而改变，该变量似乎略微不重要。
基于上述情况，我应该采用异方差稳健估计还是普通估计？
但是，如果我使用 Berush-pegan 检验来测试残差中是否存在异方差，我会发现似乎没有异方差
&gt; bptest(MyModel)

学生化 Breusch-Pagan 检验

数据：MyModel
BP = 2.3604，df = 2，p 值 = 0.3072

我该如何解释这种相互矛盾的结果？样本量相对较小是真正的问题吗？即使在这种情况下，我应该采用哪个估计值？]]></description>
      <guid>https://stats.stackexchange.com/questions/660123/inference-on-the-presence-of-heteroscedasticity-in-regression-fit</guid>
      <pubDate>Thu, 16 Jan 2025 18:47:17 GMT</pubDate>
    </item>
    <item>
      <title>最佳重要性抽样</title>
      <link>https://stats.stackexchange.com/questions/660122/optimal-importance-sampling</link>
      <description><![CDATA[假设我们想通过重要性抽样估计
$$r = \mathbb{E}_{x\backsim p(x)} [f(x)]$$，即
$$r = \mathbb{E}_{x\backsim q(x)} \left[\frac{f(x)p(x)}{q(x)}\right]$$
现在wikipedia说，当$$q^{*}(x) = \frac{f(x)p(x)}{r}$$时，可获得方差为零的最佳重要性抽样。我的问题是，我们只能在覆盖率$q(x)$ 至少与 $p(x)$ 一样大，即如果对于某些 $x$，$p(x) \neq 0$ 意味着 $q(x) \neq 0$。
但对于上述 $q^{*}(x)$，例如在 CE 方法连续优化问题 $r = P_{\theta} [S(x) \geq \gamma]$ 中，此条件可能不成立。有人能解释为什么最佳重要性抽样在这些情况下仍然成立吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660122/optimal-importance-sampling</guid>
      <pubDate>Thu, 16 Jan 2025 18:21:50 GMT</pubDate>
    </item>
    <item>
      <title>如何检查分层连续数据水平分布的一致性</title>
      <link>https://stats.stackexchange.com/questions/660121/how-can-i-check-for-consistency-in-the-distribution-of-the-levels-of-stratified</link>
      <description><![CDATA[我在一些食品购买数据中有一个专有的权重特征，有人告诉我应该将其应用于热量含量以“纠正”他们对样本代表性的不确定性。我想分析特定篮子/家庭中出售的食品的类别组成，并拥有这样做所需的识别特征。然而，我担心，如果不应用这些权重，单个篮子/家庭的实际热量含量可能不具有代表性，因为显然，这些权重的必要性意味着他们认为他们需要重新称量所售产品的总量等，以符合整个人口的某种预期。
我的问题有一半是双重的，但我在调查这个问题时遇到了一个主要问题：
我如何评估食品类别的分层分类变量是否对权重的分布有显著影响（这些是数字和连续的，而类别有大约 20 个级别）。我相信我可以进行 Kruskal-Wallis 检验来检查是否存在总体差异（结果显示 p 值非常低），但我主要想检查与特定类别相关的权重是否与总体分布有显著差异，但我不确定如何做到这一点。
此外，我想知道我是否应该只应用权重并忘记这一点，但这样我就失去了谈论篮子具体热量含量的能力，这是一个缺点。
我觉得我可能把事情复杂化了，错过了一个明显的类比或解决这个问题的方法，如果能得到任何帮助，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660121/how-can-i-check-for-consistency-in-the-distribution-of-the-levels-of-stratified</guid>
      <pubDate>Thu, 16 Jan 2025 18:00:11 GMT</pubDate>
    </item>
    <item>
      <title>当其中一个分布比较简单时，使用蒙特卡洛估计 Kullback-Leibler 散度</title>
      <link>https://stats.stackexchange.com/questions/660116/estimate-kullback-leibler-divergence-with-monte-carlo-when-one-of-the-distributi</link>
      <description><![CDATA[我感兴趣的是估算$D_\mathrm{KL}(q \parallel p) = \int q(x) \log \frac{q(x)}{p(x)}\,\mathrm dx$，其中$p$是多元高斯分布，$q$是通过神经网络参数化的隐式分布，例如GAN中的生成器网络。背景：分布是隐式的，这意味着虽然我们可以从分布中抽样，但其密度是难以处理的。
一种直接的估计方法是拟合一个 Logistic 分类器 $f(x)$，将 $q$ 的样本与 $p$ 的样本区分开来，然后通过蒙特卡洛近似 KL 为：$\frac{1}{S}\sum_{j=1}^S \log\frac{\sigma(f(x_j))}{1-\sigma(f(x_j))}$，又名密度比技巧。我们用$\sigma(\cdot)$表示 S 型函数。
这种方法的一个明显缺点，也是我想问这个问题的原因，是我们没有利用$p(x)$的密度是已知且简单的事实，参见这篇文章。我们能做些什么来利用$p(x)$的高斯分布来改进估计吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660116/estimate-kullback-leibler-divergence-with-monte-carlo-when-one-of-the-distributi</guid>
      <pubDate>Thu, 16 Jan 2025 16:12:32 GMT</pubDate>
    </item>
    <item>
      <title>如果需要真实参数的值来确定统计数据是否无偏，那么无偏估计量的意义何在？</title>
      <link>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</link>
      <description><![CDATA[我对无偏估计量的定义是：“如果用于估计参数的统计数据的抽样分布的平均值等于被估计参数的值，则该统计数据是无偏估计量。”
我知道如何确定统计数据是否是无偏估计量，因为我能够基于此解决应用题，但我不明白我们为什么要使用无偏估计量。我的笔记说，您需要使用无偏估计量，以便您的估计更准确。这对我来说很有意义，但为了确定统计数据是否是无偏估计量，您需要知道参数的值，以便将其与抽样分布的平均值进行比较，看看它们是否相等。如果使用无偏估计量来估计参数的值，如果我们已经知道参数的值，使用它有什么意义呢？
我一直在为此绞尽脑汁，但无济于事，如能得到任何帮助我将不胜感激，谢谢。
（我不擅长措辞，如果我听起来很重复或没有意义，请原谅）]]></description>
      <guid>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</guid>
      <pubDate>Thu, 16 Jan 2025 15:06:38 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中计算多重插补后合并结果的部分 Eta 平方</title>
      <link>https://stats.stackexchange.com/questions/660097/calculating-partial-eta-squared-for-pooled-results-after-multiple-imputation-in</link>
      <description><![CDATA[我已经为这个问题苦苦挣扎了一段时间，所以任何帮助我都非常感谢！
我正在尝试使用 R 中的 mice 包，使用多重插补后的汇总数据计算 ANCOVA 模型的效应大小（部分 eta 平方或 $\eta^{2}_p$）。ANCOVA 应用于认知测试的变化分数（基线和 12 周随访之间的差异）。这是模型：
results_test &lt;- with(imputed_data, lm((test_12 - test_base) ~ test_base + group + yoe))
pooled_results_test &lt;- pool(results_test)

从汇总结果中，我可以轻松提取组效应的 p 值、调整后的平均差异和置信区间。但是，我想计算一个效应大小的度量，例如 $\eta^{2}_p$。
我的困境
$\eta^{2}_p$ 的计算方法如下：
eta_squared &lt;- ss_effect / (ss_effect + ss_residual)

此处 $SS$ 表示平方和。
现在，如果我针对每个插补数据集分别计算并取插补平均值，我怀疑这可能存在缺陷，因为它是一个比率，而不是线性统计数据。对比率求平均值可能会扭曲真实的汇总效应大小。因此，我没有直接对 $\eta^{2}_p$ 进行平均，而是尝试将所有插补的平方和相加，然后计算合并的 $\eta^{2}_p$，如下所示：
# 计算合并的部分 eta 平方，方法是先对插补的平方和相加，最后在此基础上计算部分 eta 平方：

total_ss_effect &lt;- sum(sapply(1:imputed_data$m, function(i) {
anova(lm((test_12 - test_base) ~ test_base + group + yoe, 
data = complete(imputed_data, i)))[&quot;group&quot;, &quot;Sum Sq&quot;]
}))
total_ss_residual &lt;- sum(sapply(1:imputed_data$m, function(i) {
anova(lm((test_12 - test_base) ~ test_base + group + yoe, 
data = complete(imputed_data, i)))[&quot;Residuals&quot;, &quot;Sum Sq&quot;]
}))
eta_squared_pooled &lt;- total_ss_effect / (total_ss_effect + total_ss_residual)
cat(&quot;\nPooled Partial Eta Squared:&quot;, round(eta_squared_pooled, 3), &quot;\n&quot;)

此方法将组效应和插补残差的 $SS$ 相加，并从中计算 $\eta^{2}_p$总计。这似乎更合适，因为它考虑了插补之间的差异性。
我的问题：

这是一种合理的方法吗？将插补的平方和相加，然后计算部分 eta 平方，这在统计上有意义吗？

在 R 中是否有计算合并部分 eta 平方的标准方法或包？

在合并分析中不报告效应大小是否很常见？我注意到很多文章都没有包括它们，这似乎令人惊讶。


再次感谢你们提供的任何意见。我真的很感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660097/calculating-partial-eta-squared-for-pooled-results-after-multiple-imputation-in</guid>
      <pubDate>Thu, 16 Jan 2025 12:31:47 GMT</pubDate>
    </item>
    <item>
      <title>排除构成数据结构一部分的相关变量，转而采用生物学上更有意义的变量</title>
      <link>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</link>
      <description><![CDATA[我正在处理从卫星图像 (Sentinel) 捕获的植被覆盖率数据集。数据以季度/季节为间隔捕获。使用 GAM，我正在模拟植被覆盖率如何响应环境变量，降雨量是感兴趣的关键预测变量。但是，降雨量与季度/季节具有合理的相关性，相关系数为 r = -0.73。通常，当两个变量的相关性大于 0.7 时，我会将其中一个排除在分析之外。所以，我的问题是，我可以从分析中排除季度/季节吗？
季度/季节是数据集设计/结构的一部分，通常我的理解是应该在模型中考虑数据结构。但是，从生物学角度来看，连续降雨变量是一个更有趣、更有意义的变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</guid>
      <pubDate>Thu, 16 Jan 2025 03:22:55 GMT</pubDate>
    </item>
    <item>
      <title>回归分析中总体模型和样本模型的区别是什么？</title>
      <link>https://stats.stackexchange.com/questions/660132/formal-difference-between-population-and-sample-model-in-regression-analysis</link>
      <description><![CDATA[术语“样本回归模型”在回归分析中究竟指什么？假设我们有一个数据集$\{(\mathbf{x}_i,\mathbf{y}_i)\}$，我们假设一个底层回归模型形式为
$$
\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon},
$$
其中$\boldsymbol{\theta}$是真实总体参数（频率学派观点）和$\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\Sigma)$。我们所说的样本回归模型到底是什么意思？
以下是我正在探索的一些可能性：

拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}})$，从某种意义上说，我们已经选择了一个估计值$\hat{\boldsymbol{\theta}}$;
拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}}) + \hat{\boldsymbol{\epsilon}}$，其中我们有一个估计值$\hat{\boldsymbol{\theta}}$ 而且 $\hat{\boldsymbol{\epsilon}} \sim \mathcal{N}(\mathbf{0},\hat{\Sigma})$;
从字面上理解，人口模型 $\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon}$，但现在以样本指数的形式写出：$\mathbf{y}_i = f(\mathbf{x}_i;\boldsymbol{\theta}) + \boldsymbol{\epsilon}_i$;
关系$\mathbf{y}_i = f(\mathbf{x}_i;\hat{\boldsymbol{\theta}}) + \mathbf{e}_i$，其中$\mathbf{e}_i = \mathbf{y}_i - \hat{\mathbf{y}}_i$为残差。

如能提供严格说明，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660132/formal-difference-between-population-and-sample-model-in-regression-analysis</guid>
      <pubDate>Wed, 15 Jan 2025 20:28:19 GMT</pubDate>
    </item>
    <item>
      <title>L2 惩罚 cox 比例风险回归的统计推断</title>
      <link>https://stats.stackexchange.com/questions/660048/statistical-inference-for-l2-penalized-cox-proportional-hazard-regression</link>
      <description><![CDATA[首先，感谢您阅读我的问题。这是我第一次在这个平台上提问，所以如果某些要求没有得到满足，我深表歉意。
我试图使用 cox 比例风险生存分析来估计多个预测因子（HR 及其 95% CI 和 p 值）对直肠癌复发概率的影响。
由于我的数据集规模小（140 个观测值）且事件计数低（7 个事件），我决定使用 glmnet 包中的岭回归。Lasso 并不可取，因为我想保留所有预测因子，因为我有证据表明它们对复发的重要性。
我搜索了文献并了解到，虽然惩罚模型的统计推断以前由于惩罚引入的偏差而并不可取，但现在已被诸如“hdi”和“selectiveInference”之类的包克服，用于 Lasso 型回归，“lmridge”用于 L2 惩罚线性回归。
我的问题如下：

有没有什么方法可以对 Cox 比例模型上的岭回归进行统计推断。到目前为止，我还没有找到任何具有此功能的文章或 R 包
如果岭回归的统计推断仍然不可接受，我该如何解释 glmnet() 提供的 HR

这是我用于拟合模型的代码：
set.seed(10)
y &lt;- with(df_cox, Surv(df_cox$recurrencetime, df_cox$recurrence)) # 响应变量
x &lt;- model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1] # 预测器
df_cox = model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1] # 预测器
df_cox = model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1]
cv_model &lt;- cv.glmnet(
x, y,
family = &quot;cox&quot;,
alpha = 0, # 弹性网络 (alpha = 0.5 是套索和脊线的混合)
nfolds = 10 # 10 倍交叉验证
)
best_lambda &lt;- cv_model$lambda.min

# 使用最佳 lambda 拟合最终模型
final_model &lt;- glmnet(x, y, family = &quot;cox&quot;, alpha = 0, lambda = best_lambda)
]]></description>
      <guid>https://stats.stackexchange.com/questions/660048/statistical-inference-for-l2-penalized-cox-proportional-hazard-regression</guid>
      <pubDate>Wed, 15 Jan 2025 07:30:52 GMT</pubDate>
    </item>
    </channel>
</rss>