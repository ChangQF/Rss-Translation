<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 01 Jun 2024 01:06:49 GMT</lastBuildDate>
    <item>
      <title>在堆叠中训练和调整元学习器时如何分割数据？</title>
      <link>https://stats.stackexchange.com/questions/648418/how-to-split-data-when-training-and-tuning-the-meta-learner-in-stacking</link>
      <description><![CDATA[我有一个关于元学习过程的数据分割的简单而又棘手的概念问题。
假设我有一个简单的 X_train、X_test 分割，我在此分割上训练和调整了 model_1 和 model_2。现在我想使用 stacker_0 将它们堆叠起来。我设想这样做：
将 X_train 分成 5 折 $F_{i=0}^4$，然后在 $F_{i, i\neq j}$ 上训练 model_1 和 model_2，并在 $F_j$ 上进行预测。然后我将有一个新的数据集 X_train&#39;，我可以用它来训练我的元模型而不会出现泄漏。
我现在的问题是知道我是否可以使用此 X_train&#39; 在 stacker_0 上执行通常的模型选择工作（即超参数调整、元模型验证等）。这样公平吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648418/how-to-split-data-when-training-and-tuning-the-meta-learner-in-stacking</guid>
      <pubDate>Sat, 01 Jun 2024 00:15:32 GMT</pubDate>
    </item>
    <item>
      <title>缺失结果数据的多重填补</title>
      <link>https://stats.stackexchange.com/questions/648417/multiple-imputation-for-missing-outcome-data</link>
      <description><![CDATA[我花了大量时间试图了解 MICE 在帮助“填补”缺失结果数据方面可能发挥的作用。我对多重插补和预测模型都比较陌生，因此我非常感谢您的见解。
问题：我有一个约 70% 国家/地区的临床医生劳动力密度数据集（# 临床医生/100k 人）。我想要一个所有国家/地区的完整数据集（这将使我们能够提供全球临床医生总数），这意味着我需要为其余国家/地区创建插补或预测。我有许多协变量（约 15 个）。但是，这些协变量数据很少是所有国家/地区的完整数据。我的理解是，我通过传统预测模型（使用训练/测试分割）获得所有缺失国家结果估计的能力将受到缺失协变量数据的限制。
我的解决方案：我的想法是使用 MICE 来估算每个国家缺失的结果变量，即临床医生密度。
如果这是 MICE 的有效用途，那么我的问题是如何获得结果变量（劳动力密度）。我已经创建了 m 个估算数据集。我明白我不应该取这些数据集的平均值或选择单个数据集。我还没有找到清楚地解释下一步的出版物，因为 MICE 似乎更多地用于获取回归系数而不是数据本身。我的计划是使用具有完整数据的协变量创建合并回归模型（这限制了我可以使用的协变量），然后使用该回归模型来“预测”缺失的国家劳动力密度。
这合理吗，或者有更好的方法吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648417/multiple-imputation-for-missing-outcome-data</guid>
      <pubDate>Fri, 31 May 2024 23:57:18 GMT</pubDate>
    </item>
    <item>
      <title>给出的例子是否与先前的预测检查相对应？</title>
      <link>https://stats.stackexchange.com/questions/648416/does-the-example-given-correspond-to-a-prior-predictive-check</link>
      <description><![CDATA[有人能向我解释一下贝叶斯推理中先验预测检验的确切含义吗？在一些文档中，人们使用观察到的数据（“我们将观察到的数据与模型的预测进行比较”），而在某些其他文档中，人们不使用观察到的数据（“在观察数据之前总结我们的知识”）。
根据我对贝叶斯的了解（但远非专家），第一种情况让我想起了所谓的后验预测检验，它本身似乎有相当清晰的记录，我相信我很好地理解了这项技术。另一方面，对于先前的预测检查，我仍然不清楚该如何进行。
因此，为了避免空谈，我在下面给出了一个（略显人为的）例子。
假设我试图模拟一分钟内通过给定道路点的车辆数量，对此，我认为使用参数为$\lambda$的泊松分布是合理的。我了解到我们最常使用 Gamma 分布作为 $\lambda$ 的 先验。在类似情况下，1 分钟内通过的车辆平均值约为 $20$，在我看来我应该使用 Gamma( $\alpha$, $\beta$ ) 分布，其中 $\alpha$/$\beta$ ~ $20$。除了我可以将 (2, 0.1) 或 (20,1) 或许多其他的一对作为一对 ($\alpha$, $\beta$)...
因此，我目前对 先前预测检查 的理解使我采取如下方式：

我决定将要进行的 泊松 分布的观察次数，假设 $n = 100$。
我给自己两个值 ​​$\alpha$ 和 $\beta$，使得 $\alpha$/$\beta$ $=20$。
我从 Gamma($\alpha$, $\beta$) 中采样一个值 $\lambda_i$。
利用这个 $\lambda_i$，我从 Poisson($\lambda_i$) 中采样 $n$ 个值，并记下采样的 $n$ 个中的最大值 $M_i$值。
我重复$N$次（例如$1000$次）点3）和4）。
我绘制了$N$个最大值$M_i$的直方图。
我为不同的对（$\alpha$，$\beta$）创建了几个直方图。

我得到的结果由下面的图给出（我没有给出整个程序，以免帖子超载）：

对要进行的实验的讨论得出结论，不可能假设几百辆车可以在 1 分钟内通过给定点（必须消除$(0.2, 0.01)$这对最大值）；另一方面，有时也会出现一百辆或更多的车辆可以通过的情况（必须消除$(20, 1)$和$(200, 10)$这对组合，因为最大值太低）。
最后，我选择先验Gamma$(2, 0.1)$，它看起来最合适。
这种推理真的构成了先前的预测检查吗？这是通常的推理方式吗？
如果不是，如果我在详细描述这个例子时完全错了，你能给我一个如何进行事先预测检查的具体例子吗？
任何能解决我疑惑的信息都会受到欢迎！]]></description>
      <guid>https://stats.stackexchange.com/questions/648416/does-the-example-given-correspond-to-a-prior-predictive-check</guid>
      <pubDate>Fri, 31 May 2024 22:04:54 GMT</pubDate>
    </item>
    <item>
      <title>离散时间生存分析（Cox 回归）的样本量</title>
      <link>https://stats.stackexchange.com/questions/648415/sample-size-for-survival-analysis-cox-regression-with-discrete-time</link>
      <description><![CDATA[我有一项研究，患者每两个月来医院检查一次。T0（手术前一周）、T1（手术后两个月）、T2（手术后 4 个月）直至 T9（手术后 18 个月）。
我需要运行包含两个协变量（一个连续的和一个二元时间相关协变量）的 Cox 回归。
似乎时间可以被视为离散的（如果我错了，请纠正我）。
问题：当时间是离散的时，是否有任何函数公式（R 中的包）来计算 Cox 回归的样本量。*]]></description>
      <guid>https://stats.stackexchange.com/questions/648415/sample-size-for-survival-analysis-cox-regression-with-discrete-time</guid>
      <pubDate>Fri, 31 May 2024 20:53:53 GMT</pubDate>
    </item>
    <item>
      <title>矩阵正态分布和多元高斯分布有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/648414/what-is-the-difference-between-a-matrix-normal-distribution-and-the-multivariate</link>
      <description><![CDATA[考虑一组 N 矩阵 $X_1, X_2, \cdots, X_N$。我想估计这些矩阵的分布，这些分布由均值和协方差表示。
我通过简单地矢量化我的矩阵 $vec(X_1), vec(X_2), \cdots, vec(X_N)$ 来解决这个问题，然后我计算均值和协方差，就像我对多元高斯分布所做的那样。换句话说，这意味着 $vec(X) \sim \mathcal{N}(M, \Sigma)$，其中 $vec(X)$ 经过重新整形后得到 $X$
然而，我遇到了矩阵正态分布，它根据行协方差和列协方差定义分布。因此，从矩阵正态分布中抽样的矩阵由$X \sim \mathcal{M}\mathcal{N}(M, U, V)$给出。
在维基百科文章中，它说，对于随机矩阵$X$，矩阵正态分布与多元高斯分布之间的关系是$X \sim \mathcal{M}\mathcal{N}(M, U, V)$当且仅当$X \sim \mathcal{N}(V \otimes U)$，其中$\otimes$是克罗内克积的运算符。
如果我生成一组随机矩阵，我可以估计以多种方式计算分布的参数。我可以将矩阵矢量化，将其视为多元高斯分布以获得协方差。或者，我可以计算行协方差和列协方差，然后可以从克罗内克积计算协方差。
但是，我从矢量化方法和克罗内克积方法中获得的协方差值并不相同。我应该得到相同的结果吗？如果不是，为什么它们不同？我不明白这些分布在实践中代表什么，所以我不确定在哪种情况下应该使用哪种分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/648414/what-is-the-difference-between-a-matrix-normal-distribution-and-the-multivariate</guid>
      <pubDate>Fri, 31 May 2024 20:35:43 GMT</pubDate>
    </item>
    <item>
      <title>G*Power 混合双向方差分析功效分析 - 样本量似乎太小？</title>
      <link>https://stats.stackexchange.com/questions/648412/gpower-mixed-two-way-anova-power-analysis-sample-size-seems-too-small</link>
      <description><![CDATA[我正在运行我有史以来的第一次功效分析，我担心我对 G*Power 的某些方面存在误解。我正在运行 2x2 混合方差分析。我选择了“方差分析：重复测量，组内-组间相互作用”选项，并将 Cohen&#39;s d 保留为默认值 0.25，只是为了了解一下。当我将功效调整为 0.80 时，计算得出的总样本量只有 34 人 - 我有点震惊，因为它表明每组只有 17 人就足够了。我曾经做过动物研究，这大约是我在老鼠身上使用的样本量。这听起来对吗，还是我对软件有什么不理解的地方？谢谢！
参数：
效果大小 f：0.25
alpha 错误概率：.05
功效：.80
组数：2
测量次数：2
重复测量之间的校正：0.5
非球面校正 epsilon：1]]></description>
      <guid>https://stats.stackexchange.com/questions/648412/gpower-mixed-two-way-anova-power-analysis-sample-size-seems-too-small</guid>
      <pubDate>Fri, 31 May 2024 19:42:34 GMT</pubDate>
    </item>
    <item>
      <title>GPytorch - Guasisan 过程回归器的手动预测与内置功能不同</title>
      <link>https://stats.stackexchange.com/questions/648411/gpytorch-manual-prediction-from-a-guasisan-process-regressor-is-not-the-same-a</link>
      <description><![CDATA[我是 GPytorch 的新手，我的问题可能看起来很初级！但我真的被难住了！
为了解释我的问题，我使用了一个简单的 GP 回归器来解释这个问题。假设我在 GPytorch 中有以下模型来训练回归器：
import torch
import gpytorch
from gpytorch.kernels import RBFKernel
from gpytorch.means import ConstantMean, ZeroMean
from gpytorch.likelihoods import GaussianLikelihood
from gpytorch.models import ExactGP

# 生成合成数据
torch.manual_seed(0)
train_x = torch.linspace(0, 1, 100)
train_y = torch.sin(train_x * (2 * torch.pi)) + torch.randn(train_x.size()) * 0.2

class GPRegressionModel(ExactGP):
def __init__(self, train_x, train_y, unlikely):
super(GPRegressionModel, self).__init__(train_x, train_y,可能性)
self.mean_module = ZeroMean()
self.covar_module = RBFKernel()

def forward(self, x):
mean_x = self.mean_module(x)
covar_x = self.covar_module(x)
return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)

likelihood = GaussianLikelihood()
model = GPRegressionModel(train_x, train_y, unlikely)

# 模型训练
model.train()
likelihood.train()
optimizer = torch.optim.Adam(model.parameters(), lr=0.1)
mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)
training_iterations = 50

for i in range(training_iterations):
optimizer.zero_grad()
output = model(train_x)
loss = -mll(output, train_y)
loss.backward()
optimizer.step()


现在，我可以通过 GPytorch 内置功能自动进行预测，如下所示：
# 示例测试实例
test_x = torch.tensor([0.5])

# 模型预测 
model.eval()
likelihood.eval()

with torch.no_grad(), gpytorch.settings.fast_pred_var():
perceived_pred = unlikely(model(test_x))
model_mean = perceived_pred.mean.item()
model_variance = perceived_pred.variance.item()


但由于我想进行一些其他推断，因此我将使用优化的超参数进行一些计算；我意识到我甚至无法复制上述模型的预测！这是我根据模型超参数进行预测的代码：
# 提取长度尺度和噪声方差
lengthscale = model.covar_module.lengthscale.item()
noise_variance = model.likelihood.noise.item()

# 定义精炼预测函数
def rbf_kernel(x1, x2, lengthscale):
&quot;&quot;&quot;计算 x1 和 x2 之间的 RBF 核。&quot;&quot;&quot;
diff = x1.unsqueeze(1) - x2.unsqueeze(0)
dists = torch.sum(diff ** 2, -1)
return torch.exp(-0.5 * dists / lengthscale ** 2)

def predict_from_parameters(train_x, train_y, test_x, lengthscale, noise_variance):
K = rbf_kernel(train_x, train_x, lengthscale) + noise_variance * torch.eye(train_x.size(0))
K_s = rbf_kernel(train_x, test_x, lengthscale)
K_ss = rbf_kernel(test_x, test_x, lengthscale) + noise_variance * torch.eye(test_x.size(0))

L = torch.linalg.cholesky(K)
alpha = torch.cholesky_solve(train_y.unsqueeze(-1), L)
pred_mean = K_s.t().matmul(alpha).squeeze()
v = torch.linalg.solve(L, K_s)
pred_var = K_ss - v.t().matmul(v)
return pred_mean, pred_var.diag()

# 手动预测
pred_mean, pred_var = predict_from_parameters(train_x, train_y, test_x, lengthscale, noise_variance)

问题：
手动预测（pred_mean 和 pred_var）与从 GPytorch 内置功能（model_mean、model_var）获得的预测完全不同。我一直无法找出我错在哪里。
任何帮助都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648411/gpytorch-manual-prediction-from-a-guasisan-process-regressor-is-not-the-same-a</guid>
      <pubDate>Fri, 31 May 2024 19:42:02 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在通常通过 McNemar 检验进行分析的设计中对随机效应进行建模？</title>
      <link>https://stats.stackexchange.com/questions/648407/is-there-an-way-to-model-random-effects-in-a-design-that-is-typically-analyzed-b</link>
      <description><![CDATA[我的问题是：如果在一项具有配对二元响应数据的研究中（其中经常使用 McNemar 检验），我们可以使用精确二项式检验来检验比值比，是否可以使用 GLMM 来建模相同的比值比（并利用在此 GLMM 中建模随机效应等）？
基本上，我是在阅读 Fay, 2020 后想到这个问题的。他们以此开头：

考虑配对二元响应数据。例如，假设您将双胞胎随机分配到两个治疗组（测试和对照），然后对二元结果（通过或失败）进行测试。每对双胞胎都有 4 种可能的结果：（a）两个双胞胎都失败了；（b）对照组的双胞胎失败了，而测试组的双胞胎通过了；（c）测试组的双胞胎失败了，而对照组的双胞胎通过了；或（d）两个双胞胎都通过了。下面是一个表格，其中属于四个类别的双胞胎数量分别表示为 a、b、c 和 d：





测试：失败
测试：通过




对照：失败
a
b


对照：通过
c
d



然后作者解释了为什么 McNemar 测试的假设可以稍作修改，并使用精确二项式检验进行测试，从这个开始声明：

在对不一致对的总数$b + c$进行条件化之后，我们可以将问题视为$B ∼ 二项式（b + c，θ）$，其中$B$是与$b$相关的随机变量。

基于此声明，他们继续表明，在这种成对二元响应数据设置中，可以使用精确二项式检验来确定优势比是否等于 1，其中$\theta=\frac{b}{b+c}$和
$$ 优势比 = \phi = \frac{\theta}{1-\theta}$$
后来，在附录 A（第 4 页）中，作者指出：

假设我们有一个逻辑模型，其对数几率建模为：

$$\log\left(\frac{\pi_{ij}}{1-\pi_{ij}}\right)=\mu_i+group*\beta$$
其中：

$group$ 是一个指示函数，对于对照组为 0，对于测试组为 1。
$\mu_i$ 是一个随机双胞胎效应。
$\pi_{ij} = P[Y_{ij} = 1]$，并且 $Y_{ij}$ 是来自 $i^{th}$ 对的 $j^{th}$ 个二元响应

重要的是，他们指出：

在此模型下，$\phi=\exp(\beta)$

鉴于此陈述，优势比 $\phi=\exp(\beta)$，这是否表明使用 GLMM 来估计优势比并测试其重要性？
如果是，那么是什么优点和缺点？]]></description>
      <guid>https://stats.stackexchange.com/questions/648407/is-there-an-way-to-model-random-effects-in-a-design-that-is-typically-analyzed-b</guid>
      <pubDate>Fri, 31 May 2024 18:56:04 GMT</pubDate>
    </item>
    <item>
      <title>在训练多个 SVM 二元分类器之前应用 PCA 来减少数据</title>
      <link>https://stats.stackexchange.com/questions/648406/applying-pca-before-training-multiple-svm-binary-classifiers-to-reduce-data</link>
      <description><![CDATA[我正在开展一个项目，该项目的目标是确定新样本是属于 A 类还是 A&#39; 类。我需要多个这样的分类器。我将使用 SVM 进行分类：
ClassA - ClassA&#39;（类别类型 A）
ClassB - ClassB&#39;（类别类型 B）
ClassC - CalssC&#39;（类别类型 C）
等等
从一开始，我就已经知道数据属于哪种类别类型。例如，我已经知道新数据属于 A 类、B 类还是 C 类，但我不知道它是 ClassA 还是 ClassA&#39;。这就是每个类别类型的 SVM 将为我做的事情。
原始数据的形状为 (1,900)，因此两个类别都有 900 个特征。
我为每个类别类型训练了一个 SVM，并且获得了很好的结果！问题是我需要在资源受限且内存有限的嵌入式系统上执行推理。
我训练过的 SVM 最终会得到大约 30 到 100 个支持向量，具体取决于类类型。使用线性核。对于每个类类型（A、B、C 等），我需要存储所有支持向量。
对于具有 60 个支持向量的 SVM，我需要在内存中存储的支持向量数据形状将是 (60, 900)。每个数据点只有 1 个字节，因此单个类类型需要 54,000 字节。
我很容易就会有 40 多个类类型。40 * 54,000 = 2,160,000 字节。我需要将其放在 700kB 到 800kB 之间。这就是 PCA 发挥作用的地方。
我首先尝试对每个类类型使用 PCA。使用 ClassA 和 ClassA&#39; 的数据训练 PCA。使用 ClassB 和 ClassB&#39; 进行另一个 PCA，等等。这能够将支持向量的大小减少 70% 到 90%，而不会影响性能！太棒了。
但是，当我深入研究如何将原始输入数据转换为新的 PCA 空间时，我发现，进行转换时需要存储的主成分数据需要的数据比我通过转换节省的数据要多得多。如果我需要保留 200 个主成分，我需要存储一个 (200, 900) 的主成分矩阵！即 180,000 字节。
因此，使用 PCA（200 个主成分）和 SVM（60 个支持向量）：
PCA 需要存储 180,000 字节 = (200,900)
SVM 需要存储 12,000 字节 = (60,200)
单个类类型总计 = 192,000。
不使用 PCA：
SVM 需要存储 54,000 字节 = (60,900)
使用 PCA 实际上使每个类类型需要存储的数据量增加了 355%！这甚至不包括存储 PCA 均值和存储 SVM 系数。因为我需要在原始数据上进行 PCA 变换，并在嵌入式系统上为 SVM 运行推理。
问题：

有没有办法使用 PCA 显著减少每个 SVM 所需的数据？
有没有办法使用其他方法显著减少每个 SVM 所需的数据？

可能的解决方案：
我试图回答 #1 的一件事是为所有类类型拟合一个 PCA 模型。因此，我通过 PCA 运行所有类数据，它将为所有数据选择一个新的坐标系。但我觉得这不如对每个类类型使用 PCA 那样有针对性。在这种情况下，PCA 将找到所有数据中方差最大的向量。但每个类类型的 PCA 只会找到 ClassA 和 ClassA&#39; 中方差最大的向量，并将最大限度地区分它们。 PCA 在仅针对一种类别类型进行训练时会选择非常不同的特征，而不是针对所有类别类型进行训练。
使用一个 PCA 模型，将允许我减小每个 SVM 的大小并仅存储单个 PCA 矩阵。从理论上讲，这将足够减少数据。但在我走这条路之前。我想听听关于这个问题的一些其他想法和看法。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648406/applying-pca-before-training-multiple-svm-binary-classifiers-to-reduce-data</guid>
      <pubDate>Fri, 31 May 2024 18:19:20 GMT</pubDate>
    </item>
    <item>
      <title>两组时间序列之间的假设检验</title>
      <link>https://stats.stackexchange.com/questions/648405/hypothesis-testing-between-two-sets-of-time-series</link>
      <description><![CDATA[我想通过比较在不同时间捕获的两组时间序列来验证捕获方法的可重复性。
让我们考虑两组时间序列$A=(tsa_1,\dots,tsa_n)$和$B=(tsb_1,\dots,tsb_m)$，其中$n,m &gt;&gt; 100$。
我们还定义$H_0$=两个数据集彼此一致，并且$H_a$=两个数据集显示出显着差异。
测试这些假设的经典方法是什么？
我想出了基于距离的方法，但我想探索统计方法来进行比较。我读过关于统计测试的文章，但找不到太多关于处理时间序列的信息。任何帮助或资源指导都值得感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648405/hypothesis-testing-between-two-sets-of-time-series</guid>
      <pubDate>Fri, 31 May 2024 18:00:19 GMT</pubDate>
    </item>
    <item>
      <title>BUG/JAG 中的条件独立性？</title>
      <link>https://stats.stackexchange.com/questions/648404/conditional-independence-in-bugs-jags</link>
      <description><![CDATA[我正在尝试在 BUG 中创建一个分层模型。我实际上正尝试在 Nimble 中实现这一点，但我怀疑 JAG 实现会提供一些信息。
为了尝试将我的问题减少到最低限度：我有一些关于两个变量之间条件独立性的先验知识，我想将其纳入我的模型中。因此，联合分布有以下方程式：
$f(x,y,z) = f(x,y|z) * f(z)$（贝叶斯规则）
$f(x,y,z) = f(x | y, z) * f(y | z) * f(z)$（再次使用贝叶斯规则）
$f(x,y,z) = f(x | y) * f(y | z) * f(z)$（我先验地知道，在给定 $y$ 的情况下，$x$ 和 $z$ 的条件独立性。）
碰巧的是，我还知道$f(x,y)$、$f(y,z)$和$f(z)$的边际分布。在我的例子中，它们都是多元高斯分布。
通过简单地对上面列出的三个边际分布进行编码来应用此方法的一种简单尝试是：
xy[1:2] ~ dmnorm(...)
yz[1:2] ~ dmnorm(...)
z ~ dnorm(...)

但是，这忽略了 yz[1] 与 xy[2] 是同一个变量，并且 yz[2] 是 z 的事实。
我也可以简单地：
xyz[1:3] ~ dmnorm(...)

但是这忽略了我的知识，即 x 和 z 在给定条件下是条件独立的y。
鉴于我对边际分布和条件独立假设的了解，我该如何在 BUG 中定义 xyz 的联合分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/648404/conditional-independence-in-bugs-jags</guid>
      <pubDate>Fri, 31 May 2024 17:50:06 GMT</pubDate>
    </item>
    <item>
      <title>无偏性 Wilcoxon-Mann-Whitney 检验</title>
      <link>https://stats.stackexchange.com/questions/648399/unbiasedness-wilcoxon-mann-whitney-test</link>
      <description><![CDATA[对于 Wilcoxon-Mann-Whitney 检验，有许多不同的替代方案。一种替代方案是 $P(X &lt; Y) + \frac{1}{2}P(X = Y) \neq 0.5$。对此有令人信服的论据，例如检验统计量本质上是该概率的样本等价物，并且它代表了检验一致的最广泛替代方案。
但是，在这种替代方案下，检验并非无偏。下面的示例说明了这一点。它可能在附加假设下无偏（我怀疑排名数据的方差相等）。不幸的是，我没有找到任何关于这方面的研究；研究通常侧重于其他替代方案，例如随机排序（其中一个累积分布函数始终大于另一个），在这种替代方案下，检验是无偏的。因此，我的问题是：是否存在假设（其他/弱于随机排序）使得该替代方案的测试无偏？
set.seed(123)
reps &lt;- 10^3
p_wmw &lt;- rep(NA, reps) 
for(i in 1:reps){
g1 &lt;- rnorm(80, mean = 0, sd = 5)
g2 &lt;- rnorm(20, mean = .2, sd = 1)
p_wmw[i] &lt;- wilcox.test(g1, g2)$p.value
}
print(mean(p_wmw &lt; .05))

prints: 0.013]]></description>
      <guid>https://stats.stackexchange.com/questions/648399/unbiasedness-wilcoxon-mann-whitney-test</guid>
      <pubDate>Fri, 31 May 2024 16:03:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么 OLS 库使用设计矩阵的 MP 伪逆来拟合模型？</title>
      <link>https://stats.stackexchange.com/questions/648392/why-do-ols-libraries-fit-models-using-the-mp-pseudoinverse-of-the-design-matrix</link>
      <description><![CDATA[对于设计矩阵 $X$ 的线性模型 $y = X\beta$，众所周知，最优解是 $\hat{\beta} = (X&#39;X)^{-1}X&#39;y$。
一些统计库（例如 Python 的 statsmodels）通过首先计算设计矩阵的伪逆来估计参数：$X^{+} = \text{pseudoinverse}(X) = (X&#39;X)^{-1}X&#39;$，然后计算估计值为 $\hat{\beta}=X^{+}y$。
我在内存受限的环境中操作，使用形状高达 (1e8,3) 的“高而瘦”设计矩阵。计算伪逆需要在计算最终参数之前分配一个形状为 (3,1e8) 的附加矩阵 X^{+}，而正是在这一步我经常耗尽内存。
我们可以将其与分 3 个步骤计算参数进行对比：

$A = (X&#39;X)^{-1}$。这会分配一个 3x3 矩阵，然后将其反转。
$B = X&#39;y$。这将分配一个 3x1 向量。
$\hat{\beta} = AB$。

我的问题是：使用上述方法计算 OLS 估计值是否存在任何缺点（例如数值问题）？我可以保证不存在完全多重共线性（从设计矩阵的结构来看），从而保证克矩阵（$A$）的逆存在。]]></description>
      <guid>https://stats.stackexchange.com/questions/648392/why-do-ols-libraries-fit-models-using-the-mp-pseudoinverse-of-the-design-matrix</guid>
      <pubDate>Fri, 31 May 2024 15:41:55 GMT</pubDate>
    </item>
    <item>
      <title>如何使用带有反向传播的遗传算法？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648388/how-to-use-a-genetic-algorithm-with-back-propagation</link>
      <description><![CDATA[我的想法是，每一代，我都可以选取 n 个最佳个体，并通过反向传播对它们进行优化。
我无法完全描述我的模型的架构，但它有点像脉冲神经网络。模型必须记住序列。前 n 次迭代模型采用 x - 具有正态分布的向量，以及所需的输出 y_target - 一个热向量，M(x, y_target)，接下来的 m 次迭代仅提供 x 作为输入，y_predicted = M(x)。loss(y_predicted, y_target)。我使用交叉熵作为损失。问题是，由于模型对 RAM 的要求很高，我无法使用反向传播对长序列进行模型训练，因此我正在考虑使用遗传算法和反向传播。反向传播将在短距离内优化模型，而在长距离内优化遗传算法。]]></description>
      <guid>https://stats.stackexchange.com/questions/648388/how-to-use-a-genetic-algorithm-with-back-propagation</guid>
      <pubDate>Fri, 31 May 2024 15:05:58 GMT</pubDate>
    </item>
    <item>
      <title>我想要回答的假设的最低调查受访者人数</title>
      <link>https://stats.stackexchange.com/questions/648384/minimum-survey-respondents-for-hypotheses-i-want-to-answer</link>
      <description><![CDATA[我是一个热切的统计学菜鸟，所以对于这些基本问题我深表歉意。
我打算向大量人群（美国使用胰岛素的糖尿病患者）（约 840 万）发送一份调查问卷
基于此，我的目标是总共获得 96+ 份调查问卷回复（误差幅度为 +- 10%），目标是接近 300 份回复。
我有一些假设，想在调查结果中加以研究，并将进行一些统计测试

一个假设是“假设：根据用户使用胰岛素的时间，对（xyz 用户需求，仅举一个虚假的例子 - 能够快速计算一餐所需的胰岛素量）重要性的评级存在显著差异”
这将是我收集的一个人口统计问题（您使用胰岛素多长时间了？），答案范围个月。
由于重要性是李克特量表（序数）上的评级，因此各组有所不同，我想了解差异，因此我考虑进行 Mann-Whitney 测试。我特别想了解使用胰岛素的时间越长，是否会影响对这一用户需求的重要性评级。

我的问题：我是否需要至少 96 名回答每个时间段（例如 1 年或更长和 1 年或更短）的受访者才能获得统计签名响应，或者我是否只需要查看回答此问题的所有受访者的总数为 96 的受访者。此外，如果您对我的方法有任何反馈，请随时发表意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/648384/minimum-survey-respondents-for-hypotheses-i-want-to-answer</guid>
      <pubDate>Fri, 31 May 2024 14:24:51 GMT</pubDate>
    </item>
    </channel>
</rss>