<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 18 Jan 2024 12:26:11 GMT</lastBuildDate>
    <item>
      <title>可以/应该在整个数据集上而不只是在测试集上计算概率估计吗？</title>
      <link>https://stats.stackexchange.com/questions/637155/can-should-probability-estimates-be-calculated-on-the-whole-dataset-and-not-just</link>
      <description><![CDATA[对于数据集 X 上的二元分类问题，分为训练集和测试集（或训练、验证、测试，如果执行参数调整），可以通过在训练集上拟合模型来获得概率估计，然后使用 &lt;测试集上的 code&gt;predict_proba 方法（如果可用）。通过这种方式，我们可以得到未见过的数据的概率估计。
但是，获得整个数据集概率估计的最佳方法是什么 - 如果这有意义的话，这不涉及对整个数据集 X 进行训练，然后使用 predict_proba(X)？]]></description>
      <guid>https://stats.stackexchange.com/questions/637155/can-should-probability-estimates-be-calculated-on-the-whole-dataset-and-not-just</guid>
      <pubDate>Thu, 18 Jan 2024 12:09:31 GMT</pubDate>
    </item>
    <item>
      <title>如何解释截断泊松中的相互作用系数</title>
      <link>https://stats.stackexchange.com/questions/637154/how-to-interpret-interaction-coefficients-in-a-truncated-poisson</link>
      <description><![CDATA[我正在使用截断泊松（也称为正泊松），我想解释两个变量之间的系数相互作用。
从这个问题中，我们看到解释系数不是直接的，就像典型的泊松分布一样。在链接中，我们只看到如何解释变量的 beta，但看不到任何交互。
虽然通过一点代数我得出的结论是不同变量的贝塔可以相互比较，以确定谁对因变量影响最大（尽管贝塔经历了变换），但事实并非如此指导交互分析。
您通常如何解释两个变量之间的相互作用项？和正常值一样吗？你们核实案件吗？如果是这样，你是如何做到的？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/637154/how-to-interpret-interaction-coefficients-in-a-truncated-poisson</guid>
      <pubDate>Thu, 18 Jan 2024 12:05:43 GMT</pubDate>
    </item>
    <item>
      <title>从波谱中提取电流的最小二乘法</title>
      <link>https://stats.stackexchange.com/questions/637153/least-squares-method-for-extracting-currents-from-the-wave-spectrum</link>
      <description><![CDATA[我有一组雷达数据示例，其中以 3D 阵列的形式给出了自由表面以及与波数相关的水流速度。我正在尝试实施最小二乘法来看看是否能找到有效电流。我很难绘制正确的波数频率三元组 $(k_{x,i},k_{y,i},w_{i})$。我从一本书的章节中摘录了以下内容：


我已经成功地使用给定的速度正确绘制了数据的蓝色色散表面。下面我根据色散表面绘制了三元组。

为此，我找到了频谱高于最大频谱值 0.2 倍的点的索引，稍后在摘录中它建议使用 $C_{1}$值为 0.2。然而，这会产生大约 94 个三元组值 $0.7&lt;\omega&lt;1$。所以我有几个问题：

有什么方法可以在不引入额外噪声的情况下增加此范围，或者这只是该方法的限制？

我还尝试了 0.005 的值来看看会发生什么。它给了我 $0.5&lt;\omega&lt;1.6$。增加了范围，但现在查看 3D 图，似乎有些三联体不在色散表面附近。有没有办法过滤这些三元组，只给我接近色散表面的三元组（记住我不知道色散表面是什么）？

]]></description>
      <guid>https://stats.stackexchange.com/questions/637153/least-squares-method-for-extracting-currents-from-the-wave-spectrum</guid>
      <pubDate>Thu, 18 Jan 2024 12:04:06 GMT</pubDate>
    </item>
    <item>
      <title>序数Logistic回归SPSS解释</title>
      <link>https://stats.stackexchange.com/questions/637148/ordinal-logistic-regression-spss-interpretation</link>
      <description><![CDATA[我从问卷调查中获得的数据结构如下：

年龄 - 顺序（18-24、25-34、35-44、45-54、55+）

性别 - 名义（男、女）

焦虑类型 - 名义（自我诊断、专业诊断）

AnxietyYears - 量表

慢性疼痛 - 名义（否，是）

回应 - 顺序（强烈同意、同意、中立、不同意、强烈不同意）


我正在使用 SPSS 运行序数逻辑回归，其中“响应”作为我的因变量，其他 5 个作为我的自变量。
将数据放入 SPSS 时，我将其编码如下：

年龄 - (18-24, 0) (25-34, 1) (35-44, 2) (45-54, 3) (55+, 4)

性别 - （男，0）（女，1）

焦虑类型 -（自我诊断，0）（专业诊断，1）

AnxietyYears - 量表

慢性疼痛 - （否，0）（是，1）

回应 - （非常同意，1） （同意，2） （中立，3） （不同意，4） （非常不同意，5）


当我运行回归时，这是我的输出，其中显着的结果以黄色突出显示。

根据我所阅读和理解的有关解释序数逻辑回归结果的内容，这表明：
“男性与女性相比，处于较高因变量类别的优势比为 2.244”也就是说，男性比女性更有可能更强烈地同意。
但是，当我创建一个图表来查看男性和女性之间的反应差异时，它表明女性实际上比男性更有可能更强烈地同意。

如果有人能帮助我理解我做错了什么 - 无论是在我的建模还是我的解释中。]]></description>
      <guid>https://stats.stackexchange.com/questions/637148/ordinal-logistic-regression-spss-interpretation</guid>
      <pubDate>Thu, 18 Jan 2024 10:41:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么多重插补在数据科学中没有得到更广泛的应用？</title>
      <link>https://stats.stackexchange.com/questions/637147/why-is-multiple-imputation-not-used-more-widely-in-data-science</link>
      <description><![CDATA[几天前我在 datascience.SE 上发布了这个问题，因为我认为它在那里更相关：
为什么多重插补不在数据科学中应用更广泛？
&lt;块引用&gt;
我有统计学背景。多重插补非常常用于处理缺失数据，如果不使用它几乎总是会导致严重的批评。最近，我一直在面试数据科学家的职位，到目前为止，没有一个雇主似乎使用多重插补。快速搜索“多重插补”此网站上的结果只有 27 个匹配项！

&lt;块引用&gt;
我当然知道使用 MI 需要更多的时间和精力，但这就是唯一的原因吗？对于分类数据，我可以看到“缺失”数据的吸引力。类别，但是数字数据呢？平均数（或中位数）插补在 DS 中似乎很常见，但在统计学中，这种做法非常不受欢迎，因为它改变了数据的分布，通常会导致偏差。

但是，我有点惊讶地收到的回复相当少，而且这些回复的质量不高（例如。“...如果您的主要任务是预测，那么偏见就不是一个大问题。”&lt; /em&gt;）。
因此，我将其发布在这里，因为我知道我们在简历上有很多出色的数据科学家。手指交叉:)]]></description>
      <guid>https://stats.stackexchange.com/questions/637147/why-is-multiple-imputation-not-used-more-widely-in-data-science</guid>
      <pubDate>Thu, 18 Jan 2024 10:32:24 GMT</pubDate>
    </item>
    <item>
      <title>用于单向和双向方差分析的 Box-Cox 数据转换公式</title>
      <link>https://stats.stackexchange.com/questions/637145/box-cox-data-transformation-formulas-for-one-and-two-way-anova</link>
      <description><![CDATA[我想编写自己的程序，使用 ANOVA 的 box-cox 数据转换。我不明白如何针对我的情况执行 λ 的最大似然估计。我发现了如何找到常见数字序列的最佳 λ，但在方差分析中，有多个组（在单因素情况下）、多个因素（在多因素情况下），因此常见数字序列的 λ 的最大似然估计不会&#39; t 适用于分为不同组的数据。因此我需要知道，是否有 ANOVA 的 Box-Cox 公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/637145/box-cox-data-transformation-formulas-for-one-and-two-way-anova</guid>
      <pubDate>Thu, 18 Jan 2024 10:26:56 GMT</pubDate>
    </item>
    <item>
      <title>python中STL分解和查找异常值的问题</title>
      <link>https://stats.stackexchange.com/questions/637143/problems-with-stl-decomposition-and-finding-outliers-in-python</link>
      <description><![CDATA[这是我正在制作的一个示例系列，旨在探讨异常值检测主题。我是一名开发人员，不是统计学家。
我的目标是使用 STL 来消除趋势并淡化我的系列。这样我就可以开始分析异常值的残余分量。
我的分解问题是时间步 15 处的异常值成为季节性分量的一部分。这意味着对于剩余部分来说，第一年会出现下降，而不是第二年会出现峰值。
我读过并且已经被告知使用平均值和标准差可能不是最佳的。但这不是这里的主要问题。

我的思维过程有缺陷吗？
您建议我做什么来开始异常值检测领域？
您可以推荐异常值检测方法吗？
我应该使用哪些指标来代替均值和标准差来检测残差中的异常值？
数据：
[0, 2, 5, 8, 12, 15, 18, 22, 25, 28, 20, 10, 0, 2, 5, 18, 12, 15, 18, 22, 25, 28, 20, 10]
我的代码：
def detector_outliers(时间序列):
timeseries_values = timeseries[&#39;prognosebasis&#39;].values
stl = STL(timeseries_values，周期=12，稳健=True)
stl_fit = stl.fit()
绘图组件（stl_fit）

resid_mean = stl_fit.resid.mean()
resid_std = stl_fit.resid.std()

下=残差平均值 - (3*残差标准差)
上层 = 残差平均值 + (3*残差标准差)

异常值 = np.where((stl_fit.resid &gt; upper) | (stl_fit.resid &lt; lower))
返回异常值
]]></description>
      <guid>https://stats.stackexchange.com/questions/637143/problems-with-stl-decomposition-and-finding-outliers-in-python</guid>
      <pubDate>Thu, 18 Jan 2024 09:50:05 GMT</pubDate>
    </item>
    <item>
      <title>条件期望函数和因果推理</title>
      <link>https://stats.stackexchange.com/questions/637141/conditional-expectation-function-and-causal-inference</link>
      <description><![CDATA[！对于问题本身，跳到最后一段！
据我了解，当我们有一个以下形式的模型 $$Y = m(X) + e$$ 和 $E[e|X] = 0$ 我们知道 $m(X)$ 是条件期望函数，因此： $m(X) = E[Y|X]$。如果我们观察 $X$ 和 $Y$，它们的参数关系是线性的，我们知道什么这个关系看起来像，我们可以使用 OLS 来估计 CEF。对于真实的 CEF，我们的估计值将是一致且无偏见的。如果违反任何一个假设，我们只估计线性投影模型（可以或不能接近真实的 CEF）。
在因果推理的文本中（例如 Angrist and Pischke 2009），我们将因果效应定义为 $$E[Y|X, T = 1] - E[Y|X , T = 0] = E[Y(1) - Y(0)|X, T = 1]$$ （$T$ 表示随机指定治疗）。如果 $T$ 是二进制的，我可以看到我们可以完全饱和模型（假设 $X$仅保存二进制变量或只是一个常量），这意味着 $$Y = \gamma T + X&#39;\beta + e$$ 形式的任何结构模型 $$Y = \gamma T + X&#39;\beta + e$$实际上是真正的 CEF，我们可以很好地估计我们的因果效应（假设样本足够大，矩有限，并且没有完美的共线性）。
但是如果 $T$ 是连续的怎么办？或者随机分配仅以 $X$ 为条件且 $X$ 具有连续分量？在这种情况下，我们如何知道我们实际上是在估计真实的 CEF？如果不是，上面因果效应的定义在总体模型中仍然成立，但我们无法使用 OLS 来估计它。那么为什么我们最终在应用研究中的这种情况下仍然使用它（我说的是计量经济学，我不知道其他领域如何处理这个问题）？]]></description>
      <guid>https://stats.stackexchange.com/questions/637141/conditional-expectation-function-and-causal-inference</guid>
      <pubDate>Thu, 18 Jan 2024 09:32:30 GMT</pubDate>
    </item>
    <item>
      <title>训练/验证/测试数据子集；我们使用哪一个？</title>
      <link>https://stats.stackexchange.com/questions/637139/train-validate-test-subsets-of-the-data-which-one-do-we-use</link>
      <description><![CDATA[我们正在使用大型医疗保健数据集撰写一篇科学论文。我们将数据分为三组：训练集 (60%)、验证集 (20%) 和测试集 (20%)。
我的问题是我们在论文的每个部分使用什么。估计过程在训练集上运行。这是肯定的。

我们使用什么来制作描述性表格？
模型拟合测试是测试集吗？使用我们的估计进行的模拟是验证集吗？

谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637139/train-validate-test-subsets-of-the-data-which-one-do-we-use</guid>
      <pubDate>Thu, 18 Jan 2024 09:02:46 GMT</pubDate>
    </item>
    <item>
      <title>降维同时保留统计和相关特征</title>
      <link>https://stats.stackexchange.com/questions/637138/dimensionality-reduction-while-preserving-statistical-and-correlational-features</link>
      <description><![CDATA[我正在处理一个由 $k$ 矩阵组成的数据集，每个矩阵代表不同的资产类别，例如股票、债券、链接器。每个矩阵的大小为 $m \times n$，其中 $m$ 是 $n$ 这些资产类别的年回报率。矩阵中的每个条目都是实数，表示特定年份和模拟的年回报。主要目标是减少由于使用这些数据集的其他模型中的计算限制而导致的模拟数量，这些数据集每年分析所有 10,000 次模拟。面临的挑战是在减少过程中保持统计稳健性以及时间序列和矩阵间关系的完整性。
需要保留的关键属性包括每个数据集中的统计稳健性，例如年度收益的均值、方差（标准差）、偏度和峰度的保留。在我看来，自相关和波动性聚类等时间序列特征也很重要。必须维护不同资产类别之间的矩阵间关系，例如相关性和协方差矩阵结构，以捕获它们随时间的相互作用。
我正在寻找有关统计方法或算法的建议，以有效减少模拟次数，同时保留这些统计和时间序列属性。是否有专门针对金融时间序列中这些要求的既定方法、文献或案例研究？除了列出的属性之外，在降维过程中是否还需要考虑其他关键方面，特别是对于金融时间序列？高度赞赏见解、经验和建议，包括理论建议、实际应用或软件/工具推荐。]]></description>
      <guid>https://stats.stackexchange.com/questions/637138/dimensionality-reduction-while-preserving-statistical-and-correlational-features</guid>
      <pubDate>Thu, 18 Jan 2024 09:01:38 GMT</pubDate>
    </item>
    <item>
      <title>科霍机器。立式包装机电脑故障而忽略的一些参数</title>
      <link>https://stats.stackexchange.com/questions/637137/cohomachine-some-parameters-being-ignored-by-malfunctioning-vertical-packaging</link>
      <description><![CDATA[我的立式包装机电脑主板出现故障。我从速卖通得到的。来自一家名为 Cohomachine 的公司，我建议不惜一切代价避免使用它。该提供商拒绝提供任何文档或技术手册，而这家公司（BateRpak）似乎并不真正存在，彻底的搜索只让我找到了一千个速卖通所谓的“官方”BateRpak 供应商，基本上都是我购买它的地方。
完全缺乏文档使得任何类型的配置或修复几乎不可能，因此如果有人遇到类似问题，我将其发布在这里，以便互相帮助。
该控件基本上是一个微控制器，通过引入一系列 3 (0-9) 个字符来选择参数，然后引入值来进行配置。
问题：问题是它设置了一些非常重要的参数，它记住了，但并不适用。
此参数为303（切断延迟），机器有2个元件来切割和密封袋子，此参数负责将切割器保持在切割位置一段时间，以便袋子有时间正确密封。它的值以秒为单位设置，其范围应该是 0s-2s，但它永远不会被应用。
这里是公共驱动器文件夹的链接，其中包含：
PCB图片
他们提供的（非常糟糕的）用户手册。
一张表格，其中包含 PCB 型号和参数的信息，以及我发现的其他参数，但我不知道它们的含义。 https://drive.google.com/drive/folders/1Xr_2a6YlLg24- 3eazLKi49V6APXLXe8h?usp=共享
这是 YouTube 上的一段视频，展示了这台机器以及问题所在，并用迷人的墨西哥南部口音进行了描述。 https://youtu.be/ou9fCLKt82w
非常感谢您抽出宝贵的时间，希望我们能够解决该问题，并为遇到同样问题的人创建一个打开的云端硬盘文件夹。 “……帮帮我，欧比旺·克诺比。你是我唯一的希望。”
我已尽力向提供商寻求帮助或文件，但这是不可能的，从我们转账的那一刻起他们就拒绝合作。当我们坚持要求时，他们屏蔽了我们。]]></description>
      <guid>https://stats.stackexchange.com/questions/637137/cohomachine-some-parameters-being-ignored-by-malfunctioning-vertical-packaging</guid>
      <pubDate>Thu, 18 Jan 2024 08:54:51 GMT</pubDate>
    </item>
    <item>
      <title>β OLS 或 β GARCH</title>
      <link>https://stats.stackexchange.com/questions/637135/beta-ols-or-beta-garch</link>
      <description><![CDATA[我想了解对于相同的证券但具有不同的回报间隔，比较市场模型的 OLS beta 参数 (Ri = alpha + betaRmt + e) 是否有意义。换句话说，对于每日频率，误差项存在 ARCH 问题，因此我使用 ARCH(1) 或 GARCH(1,1) 模型，而对于每月频率，OLS 估计效果很好。比较这两个值（beta OLS 和 beta ARCH）是否合适，或者我应该仅使用 OLS 方法比较两者并忽略误差项的任何潜在问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/637135/beta-ols-or-beta-garch</guid>
      <pubDate>Thu, 18 Jan 2024 08:00:54 GMT</pubDate>
    </item>
    <item>
      <title>自定义 KDE 中 scipy.rv_continuos 的 ppf() 函数存在问题 [已关闭]</title>
      <link>https://stats.stackexchange.com/questions/637134/problem-with-ppf-function-of-scipy-rv-continuos-from-custom-kde</link>
      <description><![CDATA[我得到了一个分布（无法用任何已知的教科书分布模型来描述或拟合）。我想应用逆变换来制作大量的 r.v.从这个分布。用scipy就很简单了，如果scipy中已经实现了分布，那么我们就可以使用ppf(u)函数，其中u是Uniform(0,1)
对于我的情况，我制作了发行版的 kde，然后执行以下步骤：
https:// docs.scipy.org/doc/scipy/reference/ generated/scipy.stats.rv_continuous.html#scipy-stats-rv-continuous
x = some_random 变量（分析函数未知）
kde = stats.gaussian_kde(np.array(x))

类 kde_gen(stats.rv_连续):
    “kde”
    def _pdf(自身, x):
        返回 kde.evaluate(x)
kde_g = kde_gen(名称=&#39;kde&#39;)
kde_g.cdf(0.99),kde_g.ppf(0.9)

但是我得到了：
文件 ~/*python3.8/site-packages/scipy/stats/_distn_infrastruct.py:2106，在 rv_continuous.ppf(self, q, *args, **kwds)
   第2104章
   第2105章
-&gt;第2106章
   第2107章
   第2108章

文件 ~*python3.8/site-packages/scipy/stats/_distn_infrastruct.py:994，在 rv_generic._ppf(self, q, *args) 中
    第993章
--&gt;第994章

文件〜/*/python3.8/site-packages/numpy/lib/function_base.py:2113，在向量化.__call__(self, *args, **kwargs)
   第2110章
   第2111章
-&gt;第2113章

文件 ~*python3.8/site-packages/numpy/lib/function_base.py:2197，在 vectorize._vectorize_call(self, func, args) 中
   第2193章
   第2194章
   第2195章
-&gt;第2197章
   第2199章
   第2200章

文件 ~*python3.8/site-packages/scipy/stats/_distn_infrastruct.py:1773，在 rv_continuous._ppf_single(self, q, *args)
   第1770章 左，右=右，右*系数
   第1771章
-&gt;第1773章
   第1774章 左，右，args=(q,)+args，xtol=self.xtol)

文件 ~/*/python3.8/site-packages/scipy/optimize/zeros.py:776，在 brentq(f、a、b、args、xtol、rtol、maxiter、full_output、disp) 中
    [第 774 章] _rtol：
    第775章
--&gt;第776章
    第777章

RuntimeError：100次迭代后未能收敛。

请帮忙。]]></description>
      <guid>https://stats.stackexchange.com/questions/637134/problem-with-ppf-function-of-scipy-rv-continuos-from-custom-kde</guid>
      <pubDate>Thu, 18 Jan 2024 07:50:25 GMT</pubDate>
    </item>
    <item>
      <title>价格弹性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637100/price-elasticity</link>
      <description><![CDATA[根据本文，计算不同模型的需求弹性为：

我生成基本价格 = 500 和基准销售额 = 100 单位的数据，固定价格弹性 =-5，并从线性模型中获得不同的结果系数。
基本价格 &lt;- 500
基本销售数量 &lt;- 100
弹性 &lt;- -5 # 价格上涨 1% 销量下降 5%（反之亦然）
d &lt;- data.frame(价格=c(470,500,480,485,485,530,555,465,565,490,475))
平均值（d$价格）
d$priceDev &lt;- d$price/basePrice-1 # 价格折扣
d$salesDev &lt;- d$priceDev*100*elasticity/100 # 销售额提升
d$salesQty &lt;- baseSalesQty+baseSalesQty*d$salesDev
fit &lt;- lm(log(salesQty)~log(price),data = d)
系数(fit)[2] # beta coef = -6.726256 不等于弹性= -5！

我的问题是，为什么线性模型给出的弹性不等于原始弹性？]]></description>
      <guid>https://stats.stackexchange.com/questions/637100/price-elasticity</guid>
      <pubDate>Wed, 17 Jan 2024 20:08:57 GMT</pubDate>
    </item>
    <item>
      <title>与 Welch 的 F 相比，经典方​​差分析 F 有何优点？</title>
      <link>https://stats.stackexchange.com/questions/637085/benefits-of-classical-anova-f-compared-to-welchs-f</link>
      <description><![CDATA[是否有理由报告经典 ANOVA F 值，而不是 Welch 的 F 检验？]]></description>
      <guid>https://stats.stackexchange.com/questions/637085/benefits-of-classical-anova-f-compared-to-welchs-f</guid>
      <pubDate>Wed, 17 Jan 2024 17:19:52 GMT</pubDate>
    </item>
    </channel>
</rss>