<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 06 Jan 2025 06:25:33 GMT</lastBuildDate>
    <item>
      <title>$|μ| \gg σ$ 的 Delta 方法近似条件</title>
      <link>https://stats.stackexchange.com/questions/659598/condition-for-delta-method-approximation-for-%ce%bc-gg-%cf%83</link>
      <description><![CDATA[我试图理解当 $|μ|$ 远大于 $σ.$ 时 Delta 方法近似的数学依据。具体来说，我正在寻找以下公式的证明：
$$ E[g(X)] \approx g(\mu) + \frac{1}{2}g&#39;&#39;(\mu)\sigma^2 $$
$$ \operatorname{Var}[g(X)] \approx (g&#39;(\mu))^2\sigma^2 $$
其中 $X$ 是均值为 $μ$ 的随机变量和标准偏差 $σ,$ 和 $g$ 是一种变换。
我不确定获取这些简化形式所涉及的具体步骤和假设。
我有一些问题：
条件 $|μ| \gg σ$ 是如何正式定义或量化的？我的讲义中提到了这个条件。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659598/condition-for-delta-method-approximation-for-%ce%bc-gg-%cf%83</guid>
      <pubDate>Mon, 06 Jan 2025 03:46:26 GMT</pubDate>
    </item>
    <item>
      <title>减少 MLP 过度拟合以提高特征重要性</title>
      <link>https://stats.stackexchange.com/questions/659597/reducing-mlp-overfitting-for-feature-importance</link>
      <description><![CDATA[我正在一个数据集上训练 MLP，数据集的特征数量 &gt;&gt; 样本数量。出于某些原因，至少有一个隐藏层的 MLP 是我唯一考虑的架构。毫不奇怪，即使是最简单的 MLP，我也会出现严重的过度拟合（训练 AUROC 很快达到 1）。
我的 Xs 也不太能描述 ys：即使我有无限数量的样本，我也不会期望超过测试 AUROC ~0.7。
我的目标不是训练一个好的预测模型，而是训练最好的模型，然后在下游分析中研究最重要的特征。由于我正在处理特征重要性，因此对我来说，尽可能减少过度拟合至关重要。
问题是：l1/l2 正则化和 dropout 等标准技术是否允许尽可能减少过度拟合，还是它们的能力有限？我不介意包含具有非常高丢失概率的丢失层，但我真的想避免必须考虑更少的特征。我知道提前停止，但我真的不想在一个时期后停止。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659597/reducing-mlp-overfitting-for-feature-importance</guid>
      <pubDate>Mon, 06 Jan 2025 03:13:45 GMT</pubDate>
    </item>
    <item>
      <title>使用 rep() 会导致向量比“times”参数更短[迁移]</title>
      <link>https://stats.stackexchange.com/questions/659593/using-rep-results-in-vector-shorter-than-times-argument</link>
      <description><![CDATA[我正在一个循环中工作，我需要将一个字符串复制一定次数。随着循环的进行，复制的次数需要增加，我从向量中提取该值。我的循环卡在需要复制“ES”56 次的迭代上，因为 rep() 函数只复制了 55 次。这是一个更大任务的一部分，但我已将其精简为失败的部分。
在对此进行故障排除时，我发现只有当我需要复制“ES”的次数从百分比向量中引用时才会发生这种情况。如果我将 x 指定为值本身，它会正常工作，并生成完整的 56 长度向量。但是当从序列中提取 x 时，它只生成一个长度为 55 的向量。
# 这将生成一个长度为 56 的向量
x &lt;- 0.14
y &lt;- 400
test &lt;- rep(&quot;ES&quot;,times=x*y) 
length(test)
class(x)

# 这将生成一个长度为 55 的向量
x &lt;- seq(0.02,0.50,0.02)[7]
y &lt;- 400
rep(&quot;ES&quot;,times=x*y)
length(test)
class(x)

变量 x 在两个实例中都属于“numeric”类。经过大量测试，我发现唯一可行的方法是将 x 转换为字符，然后再将其转换回数字。
i &lt;- seq(0.02,0.50,0.02)
x &lt;- as.character(i[7])
x &lt;- as.numeric(x)
y &lt;- 400
rep(&quot;ES&quot;,times=x*y)

有人能解释为什么会发生这种情况吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659593/using-rep-results-in-vector-shorter-than-times-argument</guid>
      <pubDate>Mon, 06 Jan 2025 01:23:19 GMT</pubDate>
    </item>
    <item>
      <title>抛硬币能给假设检验提供任意的$\alpha$吗？</title>
      <link>https://stats.stackexchange.com/questions/659589/can-flipping-a-coin-give-a-hypothesis-test-an-arbitrary-alpha</link>
      <description><![CDATA[以下假设检验是否符合所有定义？

选择一个 $\alpha$（通常为 $0.05$）
设 $A := \lceil -\log_2(\alpha) \rceil$（其中 $\lceil x \rceil$ 是大于或等于 $x$ 的最小整数）
抛硬币 $A$ 次
如果其中一次抛出正面，则维持原假设
如果全部抛出反面，则拒绝原假设假设

此检验的显著性水平为$\alpha$。它对所有备选假设的功效也为$\alpha$，因此效率很低。]]></description>
      <guid>https://stats.stackexchange.com/questions/659589/can-flipping-a-coin-give-a-hypothesis-test-an-arbitrary-alpha</guid>
      <pubDate>Sun, 05 Jan 2025 22:58:56 GMT</pubDate>
    </item>
    <item>
      <title>在进行 A/B 测试时，假设检验有助于做出决策吗？</title>
      <link>https://stats.stackexchange.com/questions/659587/does-hypothesis-testing-help-make-a-decision-in-case-of-an-a-b-test</link>
      <description><![CDATA[我根据大型语言模型 (LLM) 的最新进展开发了一个文本生成管道。用户可以输入一个主题，然后我的复杂管道会生成一篇文章。我通过询问用户对每篇文章 (C-SAT) 的 5 分制序数表的满意程度来衡量用户满意度。
我实施了一个管道变体，在某些地方使用更便宜、更愚蠢的 LLM。我进行了 A/B 测试，以确定管道的当前版本和更便宜的版本之间的差异。假设平均 C-SAT 为 3.9 比 3.8，那么更便宜的版本的 C-SAT 分数低 0.1。现在，我必须决定是否引入新版本的管道以降低成本并承担降低平均 C-SAT 的风险。
我想知道 C-SAT 的下降是否足以让我放弃削减成本。
Q1：在这种情况下，假设检验有意义吗？
Q2：如果有意义，那么总体是什么？现在知道了未来文章的数量。此外，其中一个版本将不会继续。这是否意味着我不能应用测试？
测试的结果将是反对零假设的证据。假设我的零假设是“A 和 B 样本的总体分布均值相等”。从原始问题的角度来看（“如果 C-SAT 的下降足以让我放弃削减成本”），这样的 H0 是一个中间问题。
Q3：我怎么知道找到这样一个中间问题的答案有助于我找到原始问题的答案？]]></description>
      <guid>https://stats.stackexchange.com/questions/659587/does-hypothesis-testing-help-make-a-decision-in-case-of-an-a-b-test</guid>
      <pubDate>Sun, 05 Jan 2025 22:33:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们将标准误差定义为忽略偏差（与包含偏差的 MSE 不同）？</title>
      <link>https://stats.stackexchange.com/questions/659583/why-do-we-define-the-standard-error-to-ignore-bias-unlike-mse-which-includes-bi</link>
      <description><![CDATA[为什么估计量$\hat \theta$的标准误差定义为$$se = \sqrt{Var(\hat \theta)}$$，而不是$$se = \sqrt {MSE(\hat \theta)} = \sqrt{Bias^2(\hat \theta) + Var(\hat \theta)}.$$
也就是说，标准误差应该是均方误差的平方根。当然，如果估计量是无偏的，那就没有区别了。但无论如何，我能想到，如果估计量有偏差，那么我们使用标准误差的地方，偏差需要成为误差的一部分。
例如，考虑执行 Wald 检验。如果我们愿意增加偏差，我们总是可以得出任意低方差的 $\sigma^2$ 估计量。例如，给定 $\hat \sigma^2$，定义 $$\hat \sigma_1^2 = (1-t)\hat \sigma^2 + tk$$，对于任意常数 $t,k$ 将给出这样的估计量。如果我们使用它来执行 Wald 检验，我们可以通过降低 se 来获得我们想要的任何 $\alpha$，而无需真正改进测试。
如果 se 的定义包括偏差，这个问题就会得到解决 - 这会与 标准 错误 一词更加一致。我们为什么不这样做呢？

更新 - 与假设检验的相关性
撇开术语不谈，这里有一个有影响力的问题：在我们的估计量确实有偏差的情况下，我们应该在假设检验中使用 标准错误 还是上述定义？有些情况下，这会对测试结果产生影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/659583/why-do-we-define-the-standard-error-to-ignore-bias-unlike-mse-which-includes-bi</guid>
      <pubDate>Sun, 05 Jan 2025 21:17:49 GMT</pubDate>
    </item>
    <item>
      <title>除了单纯形之外，狄利克雷分布还有哪些其他支持的推广形式？</title>
      <link>https://stats.stackexchange.com/questions/659565/is-there-any-generalization-of-the-dirichlet-distribution-to-supports-other-than</link>
      <description><![CDATA[让我们考虑$(\theta_1,\theta_2,\ldots,\theta_k) \sim \operatorname{Dirichlet}(a_1,a_2,\ldots,a_k)$。我想知道我们是否还有$\theta_1 &gt; \varepsilon_1, \theta_2 &gt; \varepsilon_2,\ldots,\theta_k &gt; \varepsilon_k,$ 其中 $\varepsilon_i \geq 0, \forall i \in \{1,2,\ldots,k\}$ 是已知常数。
是否有任何已知的分布或封闭的解析形式？
我曾尝试通过条件概率计算来发展这个想法，但这有点具有挑战性。]]></description>
      <guid>https://stats.stackexchange.com/questions/659565/is-there-any-generalization-of-the-dirichlet-distribution-to-supports-other-than</guid>
      <pubDate>Sun, 05 Jan 2025 14:41:16 GMT</pubDate>
    </item>
    <item>
      <title>比较参数曲线：基于傅里叶级数的相似度度量</title>
      <link>https://stats.stackexchange.com/questions/659553/comparing-parametric-curves-fourier-series-based-similarity-metric</link>
      <description><![CDATA[使用傅里叶级数开发参数曲线的相似度度量
我正在探索使用傅里叶级数表示法在 xy 平面上比较参数曲线的方法。我的目标是开发一种能够最好地捕捉曲线“形状”的相似度度量。以下是我正在考虑的一些想法：
背景：

xy 平面上的参数曲线表示为复函数：
$z(t) = x(t) + iy(t)$
其中 $x(t)$ 和 $y(t)$ 是曲线的参数方程，$t \in (0, 1)$。

此复函数可表示为傅里叶级数：
$z(t) = \sum_{n=-\infty}^{\infty} c_n e^{2\pi int}$

傅里叶系数$c_n$的计算方法如下：
$c_n = \int_0^1 z(t) e^{-2\pi int} dt$

这些系数包含幅度和相位信息：
$c_n = |c_n|e^{i\phi_n}$
其中$|c_n|$为幅度，$\phi_n$为相位。

首先，我们将傅里叶级数标准化为具有能量 1：
$\sum_{n=-N}^{N} |c_n|^2 = 1$


当前考虑事项：

相位信息：我认为相位对于确定曲线形状至关重要。是否有证据表明情况并非如此？

相关工作：

一些现有方法比较功率谱密度（忽略相位）
这些方法通常将 PSD 视为概率密度
两个离散傅里叶变换的相似性
比较傅里叶空间中的两个分布



潜在方法：

分离幅度和相位比较：

分别比较功率谱密度和相位谱密度
将两者视为概率分布
使用上述相关工作中的方法


笛卡尔形式的余弦相似性：

以平坦笛卡尔形式写入傅里叶系数（自然包括幅度和相位信息）
应用余弦相似性
优点：自然在 -1 和 1 之间有界
缺点：对于接近 0 或负值的分数的解释不明确


笛卡尔形式的 L1/L2 距离：

与方法 2 类似，但使用 L1 或 L2 距离而是



问题：
是否有一种原则性的方法，可以使用傅里叶级数表示法来开发 xy 平面上参数曲线的相似性度量，该度量法可以同时考虑幅度和相位信息？
我特别想了解这些方法与我可能忽略的任何其他方法之间的权衡。]]></description>
      <guid>https://stats.stackexchange.com/questions/659553/comparing-parametric-curves-fourier-series-based-similarity-metric</guid>
      <pubDate>Sun, 05 Jan 2025 08:49:43 GMT</pubDate>
    </item>
    <item>
      <title>如何计算独立拍卖实验中销售额、退货和退货率变化的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/659552/how-to-compute-confidence-intervals-for-changes-in-sales-returns-and-return-ra</link>
      <description><![CDATA[问题
假设我正在组织一场汽车拍卖会，并进行两个独立的实验：

拍卖会 A 进行了 1000 次。
拍卖会 B 进行了 1000 次。
（例如，我更换了拍卖会 B 中的拍卖师，并想测量其效果。）

以下是观察到的结果：




拍卖会 A
拍卖会 B
符号




数量运行
1000
1000
常数 $ n_A $ 和 $ n_B $


售出数量
500
600
随机变量 $ S_A $ 和 $ S_B $


（售出和）退回数量
200
300
随机变量$ R_A $ 和 $ R_B $



根据这些数据，增量（我感兴趣的）如下：

销售数量增加了 20%：从 500 增加到 600。
退货数量增加了 50%：从 200 增加到 300。
退货率增加了 25%：从 40%（$ \frac{200}{500} $）增加到 50%（$ \frac{300}{600} $)。

问题 1：增量的置信区间
如何计算 95% 置信水平下每个增量的置信区间？例如：

销售数量增量，例如 $[+16\%, +27\%]$。
退货数量增量，例如 $[+42\%, +53\%]$。
退货率增量，例如 $[-5\%, +41\%]$。


我目前的方法（针对 #1）：
计算销售数量增量的置信区间：

我假设 $ S_A \sim \text{Binomial}(n_A, p^s_A) $ 和 $ S_B \sim \text{Binomial}(n_B, p^s_B) $，其中 $ p^s_A $ 和 $ p^s_B $ 是拍卖 A 或拍卖 B 中拍卖成交的概率 ($ p^s_A = 50\%, p^s_B = 60\% $)。
然后，我计算置信区间如下：
$$
\Delta S \pm z_{\alpha/2} \sqrt{\text{Var}(\Delta S)}
$$
其中：
$$
\text{Var}(\Delta S) = \text{Var}(S_A) + \text{Var}(S_B),
$$
并且：
$$
\text{Var}(S_A) = n_A p^s_A (1 - p^s_A), \quad \text{Var}(S_B) = n_B p^s_B (1 - p^s_B)。
$$
这种方法有意义吗？


我的挑战（针对 #2 和 #3）：
计算回报数量和回报率的增量置信区间：

我假设 $ R_A \mid S_A \sim \text{Binomial}(S_A, p^r_A) $，对于 $ R_B $ 也是如此。
我应该如何计算 $ \text{Var}(R_A) $ 和 $ \text{Var}(R_B) $？

我是否应该将观察到的销售数量（$ s_A $ 和 $ s_B $）视为常数（如第一种情况下的 $ n_A $ 和 $ n_B $）？
或者我应该将销售数量（$ S_A $ 和 $ S_B $）视为随机变量，并使用总方差定理计算 $ \text{Var}(R_A) $：
$$
\text{Var}(R_A) = \mathbb{E}[\text{Var}(R_A \mid S_A)] + \text{Var}(\mathbb{E}[R_A \mid S_A])?
$$



如能提供关于这些计算的任何指导或替代方法的建议，我们将不胜感激！

备注

我特别关心我的假设（例如，将观察值视为常数而不是随机变量）是否正确。
我希望得到任何相关统计方法或框架的指引，以便更好地处理这些类型的分析。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659552/how-to-compute-confidence-intervals-for-changes-in-sales-returns-and-return-ra</guid>
      <pubDate>Sun, 05 Jan 2025 06:07:41 GMT</pubDate>
    </item>
    <item>
      <title>加权可能性间接模拟可靠性？</title>
      <link>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</link>
      <description><![CDATA[对于纵向回归问题，我可能认为，与信息较少的受试者相比，我观察到的具有更多观察结果的受试者的数据更可靠（情况可能并非总是如此，但假设如此）。这里，可以使用回归权重，以便在模型中考虑到这种感知可靠性吗？

这是针对$i^{th}$主题的基本纵向/随机效应模型：
$$y_{ij} = X_{ij}\beta + u_i + \epsilon_{ij}$$
$$u_i \sim N(0, \sigma^2_u)$$
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon)$$
我看到这种权重格式经常用于最小二乘回归（$n_i$ 是受试者 $i$ 的测量次数，$N$ 是受试者总数):
$$w_i = \frac{n_i}{\sum_{k=1}^N n_k}$$
最后，修改似然函数以包含权重（我不确定哪个更好 - 单个受试者级别权重或单个观察级别权重）：
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N \prod_{j=1}^{n_i} f(y_{ij}|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
从这个来看，似乎即使有了这些权重，这些权重似乎也不会影响方差。使用多层次建模/随机效应中采用的一般方法，也许可以将方差修改为（$I$ 是一个单位矩阵，而$J$ 是一个 1 的矩阵 - 这意味着单个受试者的方差取决于所有受试者的未加权方差加上基于该受试者测量次数的单个受试者的加权方差）。这样做，我们实际上在个体层面上将随机效应引入模型：
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon / n_i)$$
$$Var(y_i) = \sigma^2_u J_{n_i} + (\sigma^2_\epsilon/n_i) I_{n_i}$$
$$Y_i \sim MVN(X_i\beta, V_i)$$
这现在使得可能性（更复杂 - 但最小二乘解可用于固定效应估计）：
$$f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon) = (2\pi)^{-n_i/2}|V_i|^{-1/2}\exp\left(-\frac{1}{2}(y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right)$$
$$\ell(\beta, \sigma^2_u, \sigma^2_\epsilon) = -\frac{1}{2}\sum_{i=1}^N \left[n_i\log(2\pi) + \log|V_i| + (y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right]$$
$$\hat{\beta} = \left(\sum_{i=1}^N X_i^T V_i^{-1} X_i\right)^{-1} \left(\sum_{i=1}^N X_i^T V_i^{-1} y_i\right)$$
我可以看到，在这个最终设置中，固定效应估计和方差都受到每个受试者可用的观察次数的影响。 （下一部分超出了我的理解范围，但我听说随机效应是使用 RMLE 估计的）

假设数学是正确的，在纵向研究中，基于每个受试者可用的测量次数的权重可以用来隐式地解释可靠性？
结束语：最后，看起来只需使用基本的多级建模方法就可以解决所有问题，并根据每个受试者的观察次数间接地考虑他们的贡献……]]></description>
      <guid>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</guid>
      <pubDate>Sun, 05 Jan 2025 03:44:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么这么多问题是线性的以及如何解决非线性问题？</title>
      <link>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</link>
      <description><![CDATA[我这学期选修了一门深度学习 Python 课，我们正在学习线性代数。
上一节课，我们从头开始“发明”了梯度下降的线性回归（之前做过最小二乘法），我们讨论了定义假设、损失函数、成本函数等。
为什么许多问题可以看作是线性的，而“只是试图找到方程 Ax = b 的解”？
可以通过最小二乘法或训练神经网络等方法来实现这一点。
在现实世界中，大多数问题都不是线性的。
由于线性代数仅适用于线性函数，那么如何解决这些问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</guid>
      <pubDate>Sat, 04 Jan 2025 19:41:00 GMT</pubDate>
    </item>
    <item>
      <title>识别与平方根过程相关的随机过程的分布</title>
      <link>https://stats.stackexchange.com/questions/659526/identifying-the-distribution-of-a-random-process-associated-to-the-square-root-p</link>
      <description><![CDATA[让 $x(t)$ 成为遵循以下的随机平方根过程
$$dx(t) = (a + bx(t)) \, dt + c\sqrt{x(t)} \, dW(t)$$
其中 $W(t)$ 是某些过滤的标准布朗运动。
它有很多名字，但出于本文的目的，我不会提及它们。如果我们定义
$$ \varphi(u;t,h) = \mathbb E\left( e^{u x(t+h)} \mid x(t) \right); \quad u\in \mathbb C$$
那么我可以证明对于 $\Re(u) \leqslant 0$，我们有
$$
\mathbb E(e^{u x(t+h)} \mid x(t) = x ) = 
\frac{1}{\left(1- 2z(h)u
\right)^{\frac k2}}\exp\left(
\dfrac{\lambda(t)x\cdot z(h)u }{1- 2z(h)u}
\right) $$
其中 $z(h) = q(h)e^{bh}\frac{c^2}{4}$，$q(h) = \dfrac{1-e^{-bh}}{b}$，$\lambda(h) = \frac{4q(h)^{-1}}{c^2}$ 和 $k = \frac{4a}{c^2}$。因此，在 $x(t)$ 条件下，我们有
$$
z(h)^{-1} x(t+h) \sim \chi_k^2(\lambda(h)^{-1}x(t))
$$
其中右边是非中心卡方分布，具有 $k$ 自由度和非中心参数 $\lambda = \lambda(h)^{-1}x(t)$。具体来说，我们可以让 $c=2$ 和 $b\to 0$ 恢复平方贝塞尔过程满足
$$
h^{-1} x(t+h) \sim \chi_k^2(h^{-1}x(t))
$$
这是众所周知的。

现在考虑联合过程$y(t) = \left( \int_0^t x(s) \, ds, x(t) \right)$。然后，我可以证明联合条件特征函数
$$\varphi(u;t,h) = 
\mathbb E\left( e^{u\cdot y(t+h)}\mid y(t) \right); \quad u\in \mathbb C^2 
$$
对于 $y(t) = (y_1, y_2)$ 等于
$$ \varphi(u;t,h) = \frac1 {\left(1- 2z \right)^{\frac k2}}
\exp\left(\dfrac{ \lambda z}
{1- 2 z}y_2 + v y_2\right)\exp(u_1 y_1 + ah v(u_1))
$$
其中 $v(u_1)$ 是 $\frac 12 c^2 v^2 + bv = u_1$ 的解，并且
\begin{align*}
z(h,u) &amp;= (u_2 - v(u_1))e^{(b + v(u_1) c^2)h} \lambda^{-1}(h,u) \\
\lambda(h,u) &amp;= \frac{4}{c^2}q_0(h,u)^{-1} \\
q_0(h, u) &amp;= \dfrac{1-e^{-(b + v(u_1)c^2)h}}{b + v(u_1)c^2} 
\end{align*&gt;
一个明显的检查是，如果 $u_1=0$ 那么我们可以连续选取 $v(u_1)=0$ 并且那么特征函数就是 $x(t)$，正如它应该的那样。
但是，我无法识别这个联合分布。我最天真的猜测是，它可能是广义卡方分布，如这里，但我没有取得太大进展。
有人知道该怎么做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659526/identifying-the-distribution-of-a-random-process-associated-to-the-square-root-p</guid>
      <pubDate>Sat, 04 Jan 2025 12:28:35 GMT</pubDate>
    </item>
    <item>
      <title>分析离散数据的相关性</title>
      <link>https://stats.stackexchange.com/questions/659520/analyzing-correlation-in-discrete-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659520/analyzing-correlation-in-discrete-data</guid>
      <pubDate>Sat, 04 Jan 2025 06:01:42 GMT</pubDate>
    </item>
    <item>
      <title>为每个受试者建模累积率</title>
      <link>https://stats.stackexchange.com/questions/659518/modelling-cumulative-rates-per-subject</link>
      <description><![CDATA[有多个受试者，每个受试者都有多个观察结果（每次测量时都会观察到连续的预测因子，并观察到 ​​0/1 的响应）。纵向回归可用于对每个受试者的（演变）累积率进行建模吗？

例如：对于每个受试者 $i$ 和时间点 $t$，观察一个二元结果 $Y_{it}$（0 或 1）和一个预测因子向量 $X_{it}$。累积率 $R_{it}$ 是截至时间 $t$，对于主题 $i$，积极响应的比例：
$$R_{it} = \frac{\sum_{s=1}^t Y_{is}}{t}$$
基本逻辑回归：
$$\text{logit}(E[R_{it}|X_{it}, b_i]) = X_{it}^\top \beta + \gamma t + b_i$$
其中：

$\beta$是固定效应系数
$b_i$ 是主题 $i$ 的随机效应，例如 $b_i \sim N(0, \sigma_b^2)$
主题级别的相关性：$\text{Corr}(R_{it}, R_{is}) = \rho^{|t-s|}$

我想也许可以使用 Beta 分布回归，但它有点超出我的理解范围，我想保持简单。但我认为由于 Beta 分布模拟比例响应，它也可能合适。
有什么想法？]]></description>
      <guid>https://stats.stackexchange.com/questions/659518/modelling-cumulative-rates-per-subject</guid>
      <pubDate>Sat, 04 Jan 2025 03:52:05 GMT</pubDate>
    </item>
    <item>
      <title>理解因果关系中的定义 2.7.3（虚假关联）——Judea Pearl</title>
      <link>https://stats.stackexchange.com/questions/659424/understanding-definition-2-7-3-spurious-association-in-causality-by-judea-pear</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659424/understanding-definition-2-7-3-spurious-association-in-causality-by-judea-pear</guid>
      <pubDate>Wed, 01 Jan 2025 19:41:38 GMT</pubDate>
    </item>
    </channel>
</rss>