<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 15 Dec 2024 09:17:05 GMT</lastBuildDate>
    <item>
      <title>小离散值的分布可视化</title>
      <link>https://stats.stackexchange.com/questions/658744/distributional-visualization-of-small-discrete-values</link>
      <description><![CDATA[对于研究对象，每种测量类型我几乎只得到 40 个小整数计数。计数从零开始，分布高度正偏。参见附图。无需赘述，从样本中可以得出结论，经过测试的、非常简单的测试假设可以肯定地被接受。但是，从这种类型的离散小值数据中可视化分布体有什么合适的方法吗？在图像中，我添加了 ggplot2 R 包中的典型 geom_boxplot，没有离群值和晶须，以显示中位数、第一和第三四分位数，以帮助理解分布。如果仅显示单个测量值（沿 y 轴略微抖动以缓解视觉分离），它看起来有点不直观的“空洞”。您是否保持 geom_boxplot 合理，或者您可以提出其他建议？

从这里找到了小提琴图表的提议：分析/可视化紧密分组的离散结果]]></description>
      <guid>https://stats.stackexchange.com/questions/658744/distributional-visualization-of-small-discrete-values</guid>
      <pubDate>Sun, 15 Dec 2024 08:39:49 GMT</pubDate>
    </item>
    <item>
      <title>带条件的多元随机正态分布</title>
      <link>https://stats.stackexchange.com/questions/658734/multivariate-random-normal-distribution-with-conditions</link>
      <description><![CDATA[我正在开发一个模拟模型，该模型将作为对实证考古数据进行分类的基础。我正在使用 R 语言，并使用有界版本的 mvrnorm() 来模拟 8 个抛射点（即箭头/矛头）尺寸（最大长度、轴向长度、最大宽度等），并使用从实证数据集得出的相关矩阵。然后，模拟数据将遵循文化传播规则，并投射到 n 代，以模拟不同社会学习场景的影响。大多数文物尺寸都具有显著相关性，并且有几个必须具有特定的关系，才能使我的模拟文物逼真。例如，轴向长度不能大于最大长度，因为它们是相同的。我尝试通过添加需要满足​​的条件（包括上限和下限）来调整 mvrnorm 函数。我尝试在模拟期间进行拒绝抽样，并在模拟后进行调整。然而，在这两种情况下，Gen 1 的结果协方差矩阵与我试图在 Gen 1 中复制的原始协方差矩阵相差甚远。我希望找到一个解决方案：1）导致 Gen 1 相关矩阵非常接近我在经验数据中看到的矩阵；2）导致模拟测量值落入经验数据集设定的范围内（最小和最大观测值）；并且 3) 满足实际工件测量的条件。
下面是我尝试在模拟后调整记录的一个例子，这似乎是所有方法中问题最少的，但仍然导致 Gen 1 中的协方差矩阵明显不同：
adjust_simulated_data &lt;- function(data,traits,mu,Sigma,bounds,max_iterations = 10) {
n&lt;-nrow(data)
p&lt;-length(traits)

# 定义要检查的条件
check_conditions&lt;-function(row) {
c(
row[&quot;LengthAxial&quot;]&lt;=row[&quot;LengthMax&quot;],
row[&quot;WidthBasal&quot;]&lt;=row[&quot;WidthMax&quot;],
row[&quot;WidthNeck&quot;]&lt;= row[&quot;WidthMax&quot;],
row[&quot;PSA&quot;] &lt;= row[&quot;DSA&quot;]
)
}

# 对违反条件的单个行进行重新采样
for (iteration in 1:max_iterations) {
licences &lt;- logical(n)

# 检查违规情况
for (i in 1:n) {
row &lt;- data[i, ]
conditions &lt;- check_conditions(row)
if (any(!conditions)) {
licences[i] &lt;- TRUE
}
}

# 如果不存在违规情况，则退出循环
if (!any(violations)) {
message(&quot;All conditions satisfaction after &quot;, iteration, &quot; iterations.&quot;)
break
}

# 对违规行进行重新采样
for (i in which(violations)) {
# 保留非特征列
non_trait_columns &lt;- data[i, !(names(data) %in% characters), drop = FALSE]

# 使用 mvrnorm_bounded 和原始 param_list 值对特征进行重新采样
resampled_traits &lt;- mvrnorm_bounded(
n = 1,
mu = mu,
Sigma = Sigma,
bounds = bounds
)

# 使用重新采样的特征更新数据行
data[i, characters] &lt;- resampled_traits
data[i, !(names(data) %in% characters)] &lt;- non_trait_columns
}
}

# 如果达到最大迭代次数，则发出警告
if (any(!violations) &amp;&amp; iteration == max_iterations) {
warning(&quot;已达到最大迭代次数；可能仍违反某些约束。&quot;)
}

return(data)
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/658734/multivariate-random-normal-distribution-with-conditions</guid>
      <pubDate>Sun, 15 Dec 2024 04:27:32 GMT</pubDate>
    </item>
    <item>
      <title>通过微分矩阵形式推导正规方程</title>
      <link>https://stats.stackexchange.com/questions/658732/deriving-the-normal-equations-by-differentiating-the-matrix-form</link>
      <description><![CDATA[因此，如果我们有 $RSS(\beta) = (\mathbf{y}-\mathbf{X}\beta)^T(\mathbf{y}-\mathbf{X}\beta)$ 并根据 $\beta$ 进行区分，并将其设置为零以最小化它，我们如何得到 $\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta)=0$？
我得到的是 $\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta)+(\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta))^T=0$
并且，只有当 $\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta)$ 的转置与其自身相同时，这才是相同的……这意味着 $\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta)$ 必须是对称的。
但是，为什么会这样呢？我知道这是一个经常出现的基本问题，但我认为基于微积分的统计学和使用线性代数之间存在某种飞跃。我学过一些线性代数，但我仍然无法解决这个问题……它更侧重于空间、投影和正交性，而不是区分矩阵……
但是，它怎么会是对称的呢？因为它是一个 p x 1 向量，甚至不是正方形……我的结果没有任何意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/658732/deriving-the-normal-equations-by-differentiating-the-matrix-form</guid>
      <pubDate>Sun, 15 Dec 2024 03:48:25 GMT</pubDate>
    </item>
    <item>
      <title>深度强化学习中改进概率指标所需的运行次数</title>
      <link>https://stats.stackexchange.com/questions/658731/number-of-runs-needed-for-probability-of-improvement-metric-in-deep-rl</link>
      <description><![CDATA[我正在使用 [1] 第 4.3 节中描述的改进概率 (POI) 指标。
本文在第 4.3 节中介绍了各种综合指标，对于大多数这些指标（IQM、平均值、中位数、最优性差距），它们指定每场游戏使用 3-11 次运行，大多数算法的标准运行次数为 5 次（M-IQN 除外，M-IQN 运行 3 次，DreamerV2 运行 11 次）。
但是，在讨论 POI 时，具体定义为：
$P(X &gt; Y) = \frac{1}{M} \sum_{m=1}^M P(X_m &gt; Y_m)$
其中 $P(X_m &gt; Y_m)$ 是算法 X 在任务 m 上优于算法 Y 的概率，本文没有明确说明所需的运行次数。
鉴于 POI 将算法 X 的每次运行与算法 Y 的每次运行进行比较，我试图确定：
对于具有统计意义的 POI 计算，每个算法所需的最少运行次数是多少？
运行次数如何影响 POI 估计的置信度？
超过一定次数的运行后，收益是否会递减？
如果有助于解答这个问题，本文中提到了与此计算相关的 Mann-Whitney U 检验。
[1]。Agarwal，Rishabh 等人。“统计悬崖边缘的深度强化学习。”神经信息处理系统进展 34 (2021)：29304-29320。]]></description>
      <guid>https://stats.stackexchange.com/questions/658731/number-of-runs-needed-for-probability-of-improvement-metric-in-deep-rl</guid>
      <pubDate>Sun, 15 Dec 2024 00:09:26 GMT</pubDate>
    </item>
    <item>
      <title>估计者的期望</title>
      <link>https://stats.stackexchange.com/questions/658727/expectations-of-estimators</link>
      <description><![CDATA[我正在研究一些面板数据计量经济学主题，我遇到了以下渐近性质：$N \to \infty$:
\begin{equation}
\theta^{\ast} \to \frac{\mathbb{E}(​​\beta_i)}{1 - \mathbb{E}(​​\gamma_i)} 
\quad \text{and} \quad 
\bar{\theta} \to \mathbb{E}\left(\frac{\beta_i}{1 - \gamma_i}\right) = \mathbb{E}(​​\theta_i),
\end{equation&gt;
幻灯片指出，除非$\beta_i$ 和 $\gamma_i$ 是独立分布的。为什么会这样？具体来说，为什么比率的期望值不等于期望值的比率？随机参数分布的独立性在这种差异中起什么作用？原因很简单，因为如果 $\beta_i$ 和 $\gamma_i$ 是独立的随机系数，则联合期望为：$\mathbb{E} (\beta_i) \times \mathbb{E}\left(\frac{1}{1-\gamma_i}\right)$?]]></description>
      <guid>https://stats.stackexchange.com/questions/658727/expectations-of-estimators</guid>
      <pubDate>Sat, 14 Dec 2024 22:35:57 GMT</pubDate>
    </item>
    <item>
      <title>我是否正确推导出加权最小二乘的迭代更新？</title>
      <link>https://stats.stackexchange.com/questions/658722/have-i-correctly-derived-the-iterative-updates-for-weighted-least-squares</link>
      <description><![CDATA[我有一项练习，需要从迭代加权最小二乘更新方程 $b^{(m)} = \left( X^\top W^{(m-1)} X \right)^{-1} X^\top W^{(m-1)} z^{(m-1)}$ 中推导出 $w_i^{(m-1)}$ 和 $z_i^{(m-1)}$，其中 BeetleMortality 数据具有概率单位链接 $\phi$。然后我必须在 R 中实现它。据我所知，$w_i^{(m-1)}=\frac{1}{\text{Var}(Y)} (\frac{\partial \mu_i}{\partial \eta_i}) ^2 = \frac{\phi&#39;(\eta_i)^{(m-1)}}{n\mu_i^{(m-1)}(1 - \mu_i^{(m-1)})}$ 和 $z_i^{(m-1)} = \eta_i^{(m-1)} (y_i -\mu_i) \frac{\partial \eta_i}{\partial \mu_i}= \eta_i^{(m-1)} + \frac{y_i + \mu_i^{(m-1)}}{\phi&#39;(\eta_i)^{(m-1)}}$ 其中 $\phi&#39;$ 是正态分布 PDF。我已经在 R 中实现了这一点，我非常确定实现中的所有内容都是正确的。因此，我相信问题在于我如何得出这些值。我犯了什么错误吗？我对这一切还比较陌生，所以很可能是我犯了一些我无法发现的明显错误。任何反馈都值得赞赏！]]></description>
      <guid>https://stats.stackexchange.com/questions/658722/have-i-correctly-derived-the-iterative-updates-for-weighted-least-squares</guid>
      <pubDate>Sat, 14 Dec 2024 16:41:27 GMT</pubDate>
    </item>
    <item>
      <title>使用随机森林预测 FPL 球员总得分</title>
      <link>https://stats.stackexchange.com/questions/658730/predicting-fpl-player-total-points-using-random-forest</link>
      <description><![CDATA[我有一个数据集，其中包含英超联赛（2016-2023 年）大约 100k 个比赛周统计数据。我的目标是预测一名球员在某个比赛周/比赛中将获得多少总分。
我将数据分为训练/测试集，其中训练集包含赛季 &lt; 2022 的统计数据，测试集包含赛季 &gt; 的统计数据2022.
为了说明某位球员的当前状态，我计算了过去 3 个比赛周以下变量的滚动平均值：
进球数、助攻数、零封数、失球数、分钟数、自进球数、扑救数、错失点球数、黄牌数、红牌数、扑救数、影响力、创造力、威胁和 ict_index
然后，我使用这些变量和一些其他变量运行随机森林：
was_home、player_team、opponent_team、opponent_strength、element_type（后卫/中场等）
模型如下所示：
rf &lt;- randomForest(
as.formula(paste(target, &quot;~&quot;, paste(predictors, collapse = &quot; + &quot;))),
data = train,
ntree = 500,
mtry = 7,
nodesize = 10,
significance = TRUE)

这样做我只得到 R^2 约为 57%。所以我的问题是这是否正常，或者我的方法是否出错？我想知道我可以在哪里改进模型，机器学习是否是预测总分的好方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/658730/predicting-fpl-player-total-points-using-random-forest</guid>
      <pubDate>Sat, 14 Dec 2024 11:25:11 GMT</pubDate>
    </item>
    <item>
      <title>纳入因变量的下限是否可以改善估计？</title>
      <link>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</link>
      <description><![CDATA[假设 $T : \Omega \to \mathbb{R}^+$ 是一个非负离散随机变量 - 例如四舍五入到最接近分钟的公交车等待时间，并且我们有一些特征 $X : \Omega \to \mathbb{R}^d$。目标是在给定 $X$ 的情况下预测 $T$。
给定数据集 $\{(X_i, T_i):i=1,\dots,n\}$，假设我们知道概率分布 $P_{T|X}(t|x)$。这意味着对于给定的一组特征 $x$，一个“朴素”估计量是
$$ \hat{\theta}_n(x) = \mathbb{E}_n[T|X=x] = \int T \ dP_{T|X} = \sum_{t\in\text{supp}(T)} t P_{T|X}(t|x) $$
现在假设我们有一些关于 $T_i$ 下限的额外数据，所以我们知道 $T_i \geq t^*_i$。有没有办法正式证明“增强”将此信息纳入因变量的估计量
$$ \tilde{\theta}_n(x) = \mathbb{E}_n[T|X=x, T \geq t^*] = \frac{\sum_{t \geq t^*} t P_{T|X}(t|x)}{\sum_{t \geq t^*} P_{T|X}(t|x)} $$
“更好​​”在某种意义上比条件均值估计量$\hat{\theta}_n$更准确？

为了使这个例子具体化，假设$X_i \in \{red, blue\}$是公交车的颜色，我们知道下一班公交车是什么。为简单起见，等待时间为 5 或 15 分钟，其中：
X | P(T=t|X) | 等待时间 T
---------------------------------
红色 | 0.3 | 5
红色 | 0.7 | 15
蓝色 | 0.7 | 5
蓝色 | 0.3 | 15

条件均值的简单估计量为：
$$
\hat{\theta}_n(X_i) = \begin{cases} 12 &amp; if X_i=red \\ 8 &amp; if X_i=blue \end{cases} 
$$
我们可以认为这是统计学家在$L^2$意义上的最佳预测，该统计学家收集了公交车到达车站所需时间的历史数据。
现在假设我们希望预测下一班公交车的时间，但现在我们有一个观察员在车站坐了$t^*$分钟。每过 $t^*$ 分钟，我们就能观察到，这一特定实现必须满足 $T_i \geq t^*$。如果超过 5 分钟没有公交车，那么我们知道公交车时间一定是 $T_i = 15$ 分钟。然后，增强估计器给出 $t^* &gt; 5$
$$
\tilde{\theta}_n(X_i; t^*) = 15 = T_i
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</guid>
      <pubDate>Sat, 14 Dec 2024 05:37:35 GMT</pubDate>
    </item>
    <item>
      <title>解释负二项残差图</title>
      <link>https://stats.stackexchange.com/questions/658692/interpreting-negative-binomial-residual-plot</link>
      <description><![CDATA[我对圣巴巴拉 125 个街区的自行车事故数据进行了负二项回归。该方程如下所示：
MASS::glm.nb(Crashes ~ network coverage + network density + 
交叉口密度 + 复杂度 + offset(log(number of bike trips))

我得到了一个带有曲线的残差图，如下图所示。这是否意味着关系是非线性的？我不知道该如何处理：我应该添加非线性项还是应该尝试其他模型，还是其他？如果有人可以对此有所启发，那就太好了。谢谢。

我尝试了残差图DHARMa 这是我得到的图：
]]></description>
      <guid>https://stats.stackexchange.com/questions/658692/interpreting-negative-binomial-residual-plot</guid>
      <pubDate>Fri, 13 Dec 2024 20:44:28 GMT</pubDate>
    </item>
    <item>
      <title>Jeffreys 离散参数空间的先验</title>
      <link>https://stats.stackexchange.com/questions/658678/jeffreys-prior-for-a-discrete-parameter-space</link>
      <description><![CDATA[以下问题涉及二项分布，其概率已知$p$，但试验次数未知$n$。
试验次数的二项置信区间
尝试思考如何为这种情况构建贝叶斯区间，我首先进入了思考 Jeffreys 先验的阶段。但是，对于离散参数空间，这没有定义，因为导数不存在。
是否有根据相同想法找到先验的方法？当然，坐标变换下分布的不变性已经过时，因为概率质量函数不会像概率密度函数那样变换。这是 Jeffreys 先验的唯一属性/动机吗，或者还有其他属性可以应用于概率质量函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/658678/jeffreys-prior-for-a-discrete-parameter-space</guid>
      <pubDate>Fri, 13 Dec 2024 16:07:13 GMT</pubDate>
    </item>
    <item>
      <title>当 $X\sim \operatorname{Beta}(\alpha,\beta)$ 时，$Y=-\log(X)$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</guid>
      <pubDate>Fri, 13 Dec 2024 11:02:03 GMT</pubDate>
    </item>
    <item>
      <title>多参数最大似然估计的渐近正态性证明</title>
      <link>https://stats.stackexchange.com/questions/658664/proof-for-asymptotic-normality-for-mle-with-multiple-parameters</link>
      <description><![CDATA[我有一个问题，关于如何证明多个 MLE 估计量的渐近性质。您在网上找到的大多数资源都提供了仅估计一个参数的情况的证明（例如此处：https://gregorygundersen.com/blog/2019/11/28/asymptotic-normality-mle/）。在这个证明中，将参数方面的均值定理应用于似然的一阶导数，得到类似$(\hat{\theta} - \theta_0) = - \frac{L_n&#39;(\theta_0)}{L_n&#39;&#39;(\tilde{\theta})}$的表达式，然后将渐近结果应用于似然。我将这种证明扩展到多参数情况的问题是均值定理仅适用于标量函数。对于矢量值函数，只有不等式成立，参见例如。 https://en.wikipedia.org/wiki/Mean_value_theorem#Mean_value_theorem_for_vector-valued_functions。
有人能告诉我如何证明多个参数的渐近正态性吗？当然，如果能提供参考，我也非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658664/proof-for-asymptotic-normality-for-mle-with-multiple-parameters</guid>
      <pubDate>Fri, 13 Dec 2024 10:29:14 GMT</pubDate>
    </item>
    <item>
      <title>为什么不使用这种“矩量法”来估计矩阵正态分布？</title>
      <link>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</link>
      <description><![CDATA[根据维基百科页面，随机矩阵$\bf{X}\in \mathbb{R}^{p\times q}$服从矩阵正态分布$\cal{MN}(\bf M, \bf U, \bf V)$，这意味着
$$ \text{vec}(\bf X) \sim \cal N ( \mathrm{vec} (\bf M), \bf V \otimes \bf U),$$
其中$\bf M \in \mathbb{R}^{p\times q}$, $\bf U \in \mathbb{R}^{p\times p}$, 以及 $\bf V \in \mathbb{R}^{q\times q}$.
假设我们观察到矩阵值数据 $\bf X_1, \dots, \bf X_n$，它们被假定为 $\cal{MN}(\bf M, \bf U, \bf V)$ 的 i.i.d. 实现。然后，MLE 具有估计值 $\hat{\bf M}$ 作为通常的样本均值，并且 $\bf U$、$\bf V$ 由以下迭代过程给出：
$$
\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X_i - \bf M) \hat{\bf V}^{-1} (\bf X_i - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{np} \sum_{i=1}^n (\bf X_i - \bf M)^\top \hat{\bf U}^{-1} (\bf X_i - \bf M)。
\end{aligned}
$$
我理解 MLE 框架，但我想知道为什么这种方法不起作用：请注意，从同一个维基百科页面
$$\begin{aligned}
\bf E[(\bf X - \bf M) (\bf X - \bf M)^\top] = \bf U\, \mathrm{tr}(\bf V), \\
\bf E[(\bf X - \bf M)^\top (\bf X - \bf M)] = \bf V\, \mathrm{tr}(\bf U)。
\end{aligned}$$
由于 $\bf U$ 和 $\bf V$ 无法通过缩放因子进行识别，我们提出附加限制 $\mathrm{tr}(\bf V) = q$。那么，我认为可以这样估计：
$$\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X_i - \bf M) (\bf X_i - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{n\operatorname{tr}(\hat{\bf U})} \sum_{i=1}^n (\bf X_i - \bf M)^\top (\bf X_i - \bf M)。
\end{aligned}$$
但是，第二种方法与 MLE 不一致。哪里出了问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</guid>
      <pubDate>Fri, 13 Dec 2024 03:43:57 GMT</pubDate>
    </item>
    <item>
      <title>是否存在计算边际效应的标准方法？</title>
      <link>https://stats.stackexchange.com/questions/658594/is-there-a-standard-way-to-calculate-marginal-effects</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658594/is-there-a-standard-way-to-calculate-marginal-effects</guid>
      <pubDate>Wed, 11 Dec 2024 21:11:19 GMT</pubDate>
    </item>
    <item>
      <title>基线和多次随访的前后设计（无控制）（元分析）</title>
      <link>https://stats.stackexchange.com/questions/658486/pre-post-design-no-control-at-baseline-and-multiple-follow-up-times-meta-anal</link>
      <description><![CDATA[我正在从事一个荟萃分析项目，需要有关选择正确统计方法的建议。我们可以查阅大约 18 篇出版物。该设计类似于治疗前后设计（无对照组）。但我们有两个以上的时间点。
在这些出版物中，受试者在治疗前后的不同时间点（T0、T1、T3、T6）来到诊所检查胆固醇值。在接受治疗之前的 T0 测量他们的胆固醇值，然后对他们进行治疗。要求他们在一个月后（T1）回来接受治疗并再次测量。这个过程在三个月和六个月时重复。
研究问题是将每个时间点的治疗效果与基线进行比较，以确定治疗需要多长时间才能见效。如果患者在 3 个月后没有出现改善，他们可能会考虑换一种治疗方法。但是，如果 3 个月时没有改善，但 6 个月时有明显改善，他们可能会考虑继续注射更多相同的药物。
出版物包括单独的配对样本检验（配对 t 检验或 Wilcoxon 符号秩检验）的结果，以比较 T1 与 T0、T3 与 T0 和 T6 与 T0（设计前后的配对样本）。因此，我们可以访问平均值和标准差（治疗前后）以及 p 值*
我们的数据是这样的（假设我们只有前、后（T1）和后（T3）：
 dat &lt;- data.frame(study=c(1,2,3,4,5,6), 
n=c( 40, 40, 10,150,150,150),
Mean_pre=c(4,2.3,3.1,6.1,2.2,3.4),
sd_pre=c(1,1.3,0.1,1.1,0.9,1.2), 
Mean_post_T1=c(2,1.3,4.1,5.1,4.2,1.4),
sd_post_T1=c(2,3.3,1.1,2.1,0.9,2.2),
r_T0_T1=c(0.4,0.5,0.3,0.3,1.5,0.7),
pvalue_T0_T1=c(0.001,0.03,0.006,0.05,0.004,0.01),
Mean_post_T3=c(1,2.3,6.1,6.1,5.2,4.4),
sd_post_T3=c(1,2.3,3.1,1.1,1.9,3.2),
r_T0_T3=c(1.4,2.5,3.3,4.3,2,1.7),
pvalue_T0_T3=c(0.003,0.01,0.004,0.05,0.004,0.04)
)

研究 n Mean_pre sd_pre Mean_post_T1 sd_post_T1 r_T0_T1 pvalue_T0_T1
1 1 40 4.0 1.0 2.0 2.0 0.4 0.001
2 2 40 2.3 1.3 1.3 3.3 0.5 0.030
3 3 10 3.1 0.1 4.1 1.1 0.3 0.006
4 4 150 6.1 1.1 5.1 2.1 0.3 0.050
5 5 150 2.2 0.9 4.2 0.9 1.5 0.004
6 6 150 3.4 1.2 1.4 2.2 0.7 0.010
Mean_post_T3 sd_post_T3 r_T0_T3 pvalue_T0_T3
1 1.0 1.0 1.4 0.003
2 2.3 2.3 2.5 0.010
3 6.1 3.1 3.3 0.004
4 6.1 1.1 4.3 0.050
5 5.2 1.9 2.0 0.004
6 4.4 3.2 1.7 0.040


现在，我想知道我们应该如何将元分析方法应用于这些类型的研究？我们是否也应该对每个比较应用单独的元分析？任何关于潜在和正确的统计技术或参考的建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658486/pre-post-design-no-control-at-baseline-and-multiple-follow-up-times-meta-anal</guid>
      <pubDate>Mon, 09 Dec 2024 13:30:12 GMT</pubDate>
    </item>
    </channel>
</rss>