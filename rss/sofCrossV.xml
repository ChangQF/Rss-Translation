<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 13 Mar 2025 18:24:07 GMT</lastBuildDate>
    <item>
      <title>如果一个变量在个人之间持续不变，我可以使用面板数据吗？</title>
      <link>https://stats.stackexchange.com/questions/662578/can-i-use-panel-data-if-one-variable-is-constant-across-individuals</link>
      <description><![CDATA[我正在研究一个小组模型，以分析地缘政治风险对商品市场的影响，但我遇到了挑战。由于商品价格是全球的，因此随着时间的流逝而不同。 
随着时间的推移，使用相同的价格值对不同国家/地区使用相同的价格值是有效的，或者这会使面板模型不适合分析？
这是我的模型：
 pcpi =α +β1.gpr +β2.EPU +β3.VIX + DCOV + DGFC +ε

 pcpi：的国家i的主要商品价格指数
 gpr：国家的地缘政治风险指数
 epu：t。
 vix：cboe波动率指数i在时间t。
 dcov：covid-19虚拟变量。
 DGFC：全球金融危机虚拟变量。
ε：错误项。

预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662578/can-i-use-panel-data-if-one-variable-is-constant-across-individuals</guid>
      <pubDate>Thu, 13 Mar 2025 17:57:07 GMT</pubDate>
    </item>
    <item>
      <title>多维数据的相关性</title>
      <link>https://stats.stackexchange.com/questions/662575/correlation-of-multi-dimensional-data</link>
      <description><![CDATA[我做了一个实验，我要求18个人阅读12条短裤文字。他们阅读了每个文本后，我要求他们评分他们对文本的享受程度，并写下他们在阅读时的眨眼率。我想使用我的数据来了解眨眼速度与阅读享受相对应的程度。我可以看到三种方法：
 a）我可以采用与每个文本示例相对应的平均眨眼率和平均享受，这给了我一组十二对值，我可以计算出。的相关性。
 b）对于每个参与者， $ p $ ，我可以计算如何 $ p $ 的眨眼率和文本享受相关，然后取出18个值的平均值。
 c）我可以做与（b）中相同的事情，但是对于每个文本示例（也许这会给我与（b）中的结果相同的结果？
所有这些选项似乎都不好。有更好的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662575/correlation-of-multi-dimensional-data</guid>
      <pubDate>Thu, 13 Mar 2025 17:42:44 GMT</pubDate>
    </item>
    <item>
      <title>如何计算PCA的标尺不变重建错误？</title>
      <link>https://stats.stackexchange.com/questions/662573/how-to-compute-a-scale-invariant-reconstruction-error-for-pca</link>
      <description><![CDATA[我正在使用主成分分析（PCA）并试图评估重建误差。具体而言，我有兴趣能够在不同规模的数据上比较PCA的结果（MinMax与标准尺度与未量化数据）。我看到的标准方法是计算原始数据和重建数据之间的根平方误差（RMSE）：
 rmse
 $$
\ text {rmse} = \ sqrt {\ frac {1} {n} {n} \ sum || x- \ hat {x} ||^2}
$$ 
其中：
  $ x $ &lt; /span&gt;是原始数据集，
 $ \ hat {x} $ &lt; /span&gt;是PCA之后的重建数据集，
 $ n $ 是样本的数量。
但是，RMSE受数据规模的影响。如果我的数据集以不同的单位（例如原始数据与标准化数据）为单位，则绝对RMSE值不直接可比。这使得很难确定PCA在不同尺度上的表现更好还是更糟。
提出的替代方案：归一化重建误差
为了使重建误差量表不变，我正在考虑通过原始数据中的总差异将其归一化：
归一化重建误差
 $$
\ text {归一化重建错误} = \ frac {\ sum || x- \ hat {x} ||^2} {\ sum || x- \ bar {x} ||^2}
$$ 

在哪里
 $ \ bar {x} $ 是原始数据的均值。
此归一化确保误差表示为总方差的一部分，从而可以在不同的缩放技术（例如Minmaxscaler vs. StandardsCaler）之间进行比较。
问题：
这是将PCA重建错误归一化的合适方法吗？
PCA中是否还有其他标准标准不变的指标来比较具有不同尺度的数据集的重建错误（或其他指标）？
这是声音吗？
对规模不变的PCA重建错误的现有工作的任何见解或参考将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/662573/how-to-compute-a-scale-invariant-reconstruction-error-for-pca</guid>
      <pubDate>Thu, 13 Mar 2025 17:32:11 GMT</pubDate>
    </item>
    <item>
      <title>分析植物社区数量和覆盖数据的最统计学上最正确的方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/662571/what-is-the-most-statistically-correct-way-to-analyze-plant-community-count-and</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662571/what-is-the-most-statistically-correct-way-to-analyze-plant-community-count-and</guid>
      <pubDate>Thu, 13 Mar 2025 16:30:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么负概率密度是不正确的评分规则？反例？</title>
      <link>https://stats.stackexchange.com/questions/662570/why-is-negative-probability-density-an-improper-scoring-rule-a-counterexample</link>
      <description><![CDATA[ gneiting＆amp; Katzfuss（2014）讨论（除其他外）评估密度预测的适当评分规则。引用论文（第133页），

 定义4：评分规则 $ s：f \ times r \ rightarrow \ bar r $ 相对于类 $ \ nathcal {f}
 $$ s（g，g）\ leq s（f，g）\ tag {1} $$ 
对于所有 $ f，g \ in \ Mathcal {f} $ 。如果方程式 $ 1 $ 仅在 $ f = g $ 。

以及

 定理3：得分规则 $ s $ 相对于类 $ \ nathcal {f} $ ，仅当预期得分函数 $ e $ e（$ e e（$ e e（f）， class =“数学container”&gt; $ s（f，\ cdot）$ 是 $ e $ 在点 $ f $  $  $ f $ 的超级gradeient

他们指出，线性得分， $ s（f，y）=  -  f（y）$ （即，在目标随机变量实现时评估的负概率密度函数）不是正确的得分规则，因为它不是超级级别。他们引用了Ovcharov（2013）。我在任何地方都找不到Ovcharov（2013）。此外，我并不是想研究涉及凸分析和超级成分的证据。这听起来很技术！
相反，我想了解 intuition 为什么线性得分不是适当的得分规则。理想情况下，我想要一个示例展示某个密度 $ f \ neq g $ 比真实密度 $ g $ 连续随机变量 参考： 

 gneiting，T。，＆amp; Katzfuss，M。（2014年）。 概率的预测。 125-151。
 Ovcharov E.2013。多变量的本地适当评分规则。 Heidelberg大学应用数学研究所工作论文。
]]></description>
      <guid>https://stats.stackexchange.com/questions/662570/why-is-negative-probability-density-an-improper-scoring-rule-a-counterexample</guid>
      <pubDate>Thu, 13 Mar 2025 16:21:21 GMT</pubDate>
    </item>
    <item>
      <title>我可以在非显着相关性上使用Fishers Z变换吗？</title>
      <link>https://stats.stackexchange.com/questions/662568/can-i-use-fishers-z-transformation-on-non-significant-correlations</link>
      <description><![CDATA[我试图找出使用Fishers Z变换来评估两个相关系数之间关系强度的差异是否合适。我可以这样做：
 a）两个非显着相关
b）一个信号。相关性和一个非sig相关性？
我正在寻找一个可靠的来源来引用，但我很难在任何地方找到适合这种技术的地方。]]></description>
      <guid>https://stats.stackexchange.com/questions/662568/can-i-use-fishers-z-transformation-on-non-significant-correlations</guid>
      <pubDate>Thu, 13 Mar 2025 15:51:30 GMT</pubDate>
    </item>
    <item>
      <title>设置r最佳目标函数类似于NLME VARCONSTPROP？</title>
      <link>https://stats.stackexchange.com/questions/662563/set-r-optim-objective-function-similar-to-nlme-varconstprop</link>
      <description><![CDATA[我试图写下比 nlme :: gls 。更具普遍化的目标函数
这个想法是有一个任意函数j和方差函数g。
在此基本示例中，j和输出y之间有一个直接的映射，因此计算差异f（观察到 - 实际）。
两校区错误的差异是 $ g = \ sigma ^2 *观察到的 ^2 + \ sigma_1 $ ，其中每个Sigma都是平均值0. 的标准分布的标准偏差。
一个论文中的-log可能性为：
 $$ \ sum_i \ dfrac {（y_i -j（p）_i）^2} {g_i} + ln（g_i）
  nll＆lt;  -  function（params，conc，conc_std，lognorm = f）{
  sigma1＆lt;  -  params [1] 
  sigma2＆lt;  - 参数[2] 

  f＆lt;  -  conc_std

  如果（lognorm）{ 
    conc＆lt;  -  log（conc） 
    conc_std＆lt;  -  log（conc_std）
  } 
  
  g＆lt;  -  sigma2 ** 2*conc^2 + sigma1 ** 2 
  l＆lt;  -  log（g） +（f^2/g）
  sum（l）＃== -log（y | theta），没有否定
}



stdconc_dil＆lt; -1：200
res＆lt;  -  lapply（1：nrep，function（i）{
    响应＆lt;  -  stdconc_dil + rnorm（长度（stdconc_dil），0，0.06*stdconc_dil） + rnorm（长度（stdconc_dil），0，0.4）
    data.frame（stdconc = stdconc_dil，conc = revertmon）
}））

res＆lt;  -  do.call（rbind，res）
optim（c（1，1），nll，conc = res  $ con，conc_std = res $  stdconc，hessian = true，method =＆quort; l-bfgs-b＆quot

GLS（conc〜stdconc-1，data = res， 
  striges = varconstprop（form = 〜StdConc），控制=列表（Sigma = 1））

 
在此示例中，这给出了我的需求。结果非常相似，只有一个负参数发行。
但是，如果我从实现中的零转移而不是 gls（） ，则常数 $ sigma_1 $ 发​​生了重大问题。
当然，要获得接近零的积分对于估计此参数很有益，但是我希望我的实现至少有效，因为 gls（） 
这是两个示例：
  stdconc_dil＆lt;  -  100：200
＃这里的sigma_1为零，范围已从零转移
res＆lt;  -  lapply（1：nrep，function（i）{
    响应＆lt;  -  stdconc_dil + rnorm（长度（stdconc_dil），0，0.06*stdconc_dil） + rnorm（长度（stdconc_dil），0，0，0）
    data.frame（stdconc = stdconc_dil，conc = revertmon）
}））

res＆lt;  -  do.call（rbind，res）
优点（C（1，1），NLL，Conc = Res  $ cons，conc_std = res $  stdconc，hessian = true）

＃ 结果
＃Sigma 1：1.62
＃Sigma 2：-0.058
 

GLS（conc〜stdconc-1，data = res， 
  striges = varconstprop（form = 〜StdConc），控制=列表（Sigma = 1））
＃ 结果
＃Sigma 1：0.002
＃Sigma 2：-0.06

 
  stdconc_dil＆lt;  -  100：200＃这里的范围已从零转移

res＆lt;  -  lapply（1：nrep，function（i）{
    响应＆lt;  -  stdconc_dil + rnorm（长度（stdconc_dil），0，0.06*stdconc_dil） + rnorm（长度（stdconc_dil），0，0.4）
    data.frame（stdconc = stdconc_dil，conc = revertmon）
}））

res＆lt;  -  do.call（rbind，res）
优点（C（1，1），NLL，Conc = Res  $ cons，conc_std = res $  stdconc，hessian = true）
＃ 结果
＃Sigma 1：4.54
＃Sigma 2：-0.051

GLS（conc〜stdconc-1，data = res， 
  striges = varconstprop（form = 〜StdConc），控制=列表（Sigma = 1））

＃ 结果
＃Sigma 1：0.64
＃Sigma 2：-0.059

 
所以看来 nlme :: gls（）显然对我的方法更稳定和敏感。
我有几个问题。我不需要完全实现：

如何使我的实现更适合数据范围，例如 gls（）？
最好是如何将参数限制为非阴性？我试图拥有“ l-bfgs-b”以0为0，但有时会失败。
]]></description>
      <guid>https://stats.stackexchange.com/questions/662563/set-r-optim-objective-function-similar-to-nlme-varconstprop</guid>
      <pubDate>Thu, 13 Mar 2025 14:10:00 GMT</pubDate>
    </item>
    <item>
      <title>r中使用LME4的预测差异（考虑随机效应）</title>
      <link>https://stats.stackexchange.com/questions/662558/predictive-variances-with-lme4-in-r-accounting-for-random-effects</link>
      <description><![CDATA[考虑具有两个交叉随机效应的线性混合效应模型：
  y〜x * beta + z * b + epsilon。
 
是否可以在R中使用 lme4 获得这种模型的预测差异？具体而言，（后）预测分布 p（yp | y，xp，zp），其中 xp 是协变量， zp 进行了预测的分组变量，是一个已知的平均值和协方差（假设ZB），该分组已有ZB（假设ZB）已包含了现有的Z中的Z）。是否可以使用 LEM4 获得此预测分布的差异？我知道 lme4 可以分别计算随机效果的条件（=后验）差异，但是当进行预测时，不能仅仅添加它们，因为它忽略了相关性（请参见下面的示例）。我还知道使用预测Interval 从 mertools 软件包进行计算预测间隔的软件包，可以进行调整以获得近似方差。但是我正在寻找一种获得确切差异的方法，鉴于对此有一个分析公式。
下面是一个示例，如何在 gpboost 中完成此操作
 ＃仿真数据
N＆lt;  -  400＃样品数量
m＆lt;  -  200＃大约1个类别 /级别的数量。分组变量
group1＆lt;  -  rep（1，n）＃分组变量
for（i in 1：m）group1 [（（i-1）*n/m+1）:( i*n/m）]＆lt;  -  i
group1＆lt;  -  group1 [sample.int（n，n，替换= true）]
group1＆lt;  - 匹配（group1，unique（sort（group1）））
set.seed（1）
b1＆lt;  -  sqrt（0.5） * rnorm（m）＃模拟随机效果
group2＆lt;  -  rep（1，n）＃2。分组变量
for（i in 1：（m/2））group2 [（（（i-1）*n*2/m+1）:( i*n*2/m）]＆lt;  -  i
group2＆lt;  -  group2 [sample.int（n，n，替换= true）]
group2＆lt;  - 匹配（group2，unique（stort（group2）））
b2＆lt;  -  sqrt（0.25） * rnorm（m）＃模拟第二个交叉随机效应
y＆lt; -b1 [group1] + b2 [group2] + sqrt（0.1） * rnorm（n）＃响应变量

＃带GPBoost的后差异
图书馆（GPBoost）
gpb_model＆lt;  -  fitgpmodel（group_data = cbind（group1，group2），y = y， 
                         x = rep（1，n），可能性=;高斯;
＃摘要（gpb_model）
pred＆lt;  - 预测（gpb_model，group_data_pred = cbind（group1，group2）， 
                 x_pred = rep（1，n），precention_var = true）
pred $ var
 
以下代码计算 lme4 中两个随机效应的条件差异，但忽略进行预测时随机效果之间的后验相关：
 库（LME4）
lme4_model＆lt;  -  lmer（y〜1 +（1 | group1） +（1 | group2）， 
                    data = data.frame（y = y，group1 = group1，group2 = group2））
＃摘要（lme4_model）
ranef_vals＆lt;  -  ranef（lme4_model，condvar = true）
post_means_group1＆lt;  -  ranef_vals  $ group1 [，1]
post_means_group2＆lt;  -  ranef_vals $  group2 [，1]
post_var_group1＆lt;  -  attr（ranef_vals  $ group1，“ post var”）[1,1，]
post_var_group2＆lt;  -  attr（ranef_vals $  group2，&#39;post var＆quot; quot;
ristual_variance＆lt;  -  sigma（lme4_model）^2 
tot_var_lme4＆lt;  -  post_var_group1 [as.numeric（group1）] + 
    post_var_group2 [as.numeric（group2）] + residual_variance
TOT_VAR_LME4

＃与GPBoost的同一件事
pred_train＆lt;  -  gpb_model  $ predict_training_training_data_random_effects（
                  preditive_var = true）
appla（pred_train [，3：4]，1，sum） + gpb_model $  get_cov_pars（）[1] 
＃与&#39;tot_var_lme4&#39;相同，但与&#39;pred $ var&#39;不同
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662558/predictive-variances-with-lme4-in-r-accounting-for-random-effects</guid>
      <pubDate>Thu, 13 Mar 2025 09:05:04 GMT</pubDate>
    </item>
    <item>
      <title>如何在MonoBit测试中确定阈值，为什么要比5％的显着性水平高1％？</title>
      <link>https://stats.stackexchange.com/questions/662552/how-is-the-threshold-determined-in-the-monobit-test-and-why-is-it-larger-for-a</link>
      <description><![CDATA[在随机性的单托测试中，通过或失败的阈值基于置信区间。我了解到1％的显着性水平（99％的置信度）导致阈值较大，而显着性水平为5％（95％的置信度）。
然而，这似乎是违反直觉的 - 由于较高的信心应该意味着与预期的50:50比率更少的偏差，为什么它允许在零数量和零之间有更大的差异？更严格的测试（较低的alpha）不需要较小的偏差吗？
有人可以澄清阈值是如何设定的，为什么会发生这种行为？
我尝试的是：我审查了单片测试公式，该公式根据对应于所选置信度的z得分设置阈值。我还研究了95％和99％置信度的临界值是从正态分布中得出的。
我期望的是：我期望较高的置信度（99％）会导致更严格的测试，这意味着允许的数量和零之间的差异较小。
实际发生的事情：相反，我发现较高的置信度（99％）允许在零和零之间差异更大，而95％则允许置信度更大。这似乎是违反直觉的，因为我认为更严格的测试应该忍受较小的偏差。我想澄清为什么这是数学上会发生的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662552/how-is-the-threshold-determined-in-the-monobit-test-and-why-is-it-larger-for-a</guid>
      <pubDate>Thu, 13 Mar 2025 05:18:08 GMT</pubDate>
    </item>
    <item>
      <title>用时间系数变化的监管提交系数来解释和重新组合生存曲线</title>
      <link>https://stats.stackexchange.com/questions/662540/interpreting-and-recombining-a-survival-curve-with-time-varying-coefficient-for</link>
      <description><![CDATA[我一直在用一个分析数据集挣扎，其中分类预测器具有时间变化的系数。在观察期间固定协变量。为了在上面放一个创可贴，我使用了步骤功能方法。有了3个切点，我可以解决时间依赖问题，但现在我陷入困境。我现在有四个单独的曲线，我一直在尝试将它们拼凑回一个可以促进与广泛受众的沟通的情节。
根据我对互联网的搜索，这是一个开放的问题……任何人都有任何简单的示例绘制这些内容。小插图示例，不适用于我的特定情况，因为它是二进制的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662540/interpreting-and-recombining-a-survival-curve-with-time-varying-coefficient-for</guid>
      <pubDate>Wed, 12 Mar 2025 21:08:10 GMT</pubDate>
    </item>
    <item>
      <title>确定人口的回归模型</title>
      <link>https://stats.stackexchange.com/questions/662493/identifying-the-population-for-a-regression-model</link>
      <description><![CDATA[
我有1000个客户的人口。
我知道所有客户的年龄和性别
这些客户中有50个注册了高级会员资格（会员注册存在自我选择偏见）。在这50个客户中，有20个经常购买，而30个客户则不购买。
我想建立一个回归模型来研究年龄和性别对高级会员资格的影响

我知道我需要首先制作一个统计模型，以签署会员资格的概率，然后是第二个模型，用于进行频繁购买条件。
这是我对第一个模型的困惑：

想法1：我是否进行逻辑回归，其中有50个客户有class =已注册，并且有950个客户有class =未注册？
想法2：或者我首先在非会员人群中找到与成员群体最相似的50个客户（即倾向得分匹配），然后在50 class上创建逻辑回归=已注册，50个班级=未注册？？

我提出这个问题的原因是，如果我的客户群非常大，并且总体会员注册率非常低（例如，1000万人口中的500名成员）。在如此严重的阶级失衡中，第一个logistic回归模型不会挣扎吗？因此，模型1的倾向分数选项听起来更逻辑？]]></description>
      <guid>https://stats.stackexchange.com/questions/662493/identifying-the-population-for-a-regression-model</guid>
      <pubDate>Tue, 11 Mar 2025 19:43:12 GMT</pubDate>
    </item>
    <item>
      <title>计算检查功能是否为凸</title>
      <link>https://stats.stackexchange.com/questions/662445/computationally-checking-if-a-function-is-convex</link>
      <description><![CDATA[考虑一个实值函数 $ f：\ Mathbb {r} \ to \ Mathbb {r} $ 。给定任何 $ x \ in \ mathbb {r} $ ，我们可以计算 $ f（x）$ 。我们不知道 $ f $ 的分析形式，应将其视为黑匣子。但是，我们确实知道 $ f $ 是一阶可区分，并且可以（数值）计算其派生 $ f&#39;$ 。
 问题：是否有一种有效的方法来检查 $ f $ 是使用计算方法凸的？
我理想情况下会使用二级测试之类的东西，但是不能保证 $ f $ 是二阶可区分的，并且此方法需要推广到任意 $ c^1 $ c^1 $ 函数。

一个“蛮力”想法是从字面上应用凸的定义，
 $$ f（\ lambda x_1 +（1- \ lambda）x_2）\ leq \ lambda f（x_1） +（1- \ lambda）f（x_2）
对于所有 $ \ lambda \ in [0，1]，x_1，x_2 \ in \ mathbb {r} $ 。但是，这可能有些不切实际，因为它可能需要在 $ \ mathbb {r} $ 上测试许多不同的点，并且可能有一些本地区域违反了凸度，但此测试不会进行。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662445/computationally-checking-if-a-function-is-convex</guid>
      <pubDate>Tue, 11 Mar 2025 01:02:39 GMT</pubDate>
    </item>
    <item>
      <title>了解一致MLE的判别模型中X条件的数学必要性</title>
      <link>https://stats.stackexchange.com/questions/662417/understanding-the-mathematical-necessity-of-conditions-on-x-in-discriminative-mo</link>
      <description><![CDATA[我以前曾问了两个问题，可以解决相关问题：

In this answer to my question about the intuition behind the conditions on the design matrix $X$ (or the predictors), the answer provided insight into why such conditions are needed to ensure consistency of discriminative model估算器。
我从这个答案是，如果log-likelihoodhiehoodhiehienhiphienhighie proments  $ log（f_i logi lim 
问题是：
   $ x $ 在派别模型中施加的详细数学推理是什么？具体？并使用相同的条件模型 $ p（y | x）$ ？
我正在寻找一种严格的解释或派生，将第一个答案中提供的直觉与数学要求联系起来，以确保可能性贡献不会“吹”。或消失，从而影响估计程序的整体一致性。
对有关此主题的进一步文献的任何见解，证明或参考，都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/662417/understanding-the-mathematical-necessity-of-conditions-on-x-in-discriminative-mo</guid>
      <pubDate>Mon, 10 Mar 2025 16:59:45 GMT</pubDate>
    </item>
    <item>
      <title>文献：效果大小的预测间隔</title>
      <link>https://stats.stackexchange.com/questions/662406/literature-prediction-intervals-for-effect-size</link>
      <description><![CDATA[ 简短版本：我有兴趣形成从给定尺寸的未来样本中得出的汇总数量的频繁预测间隔，主要集中于广义线性模型中各种效应大小的度量（例如，两组观察到的平均值之间的差异/比率/比率））。除线性模型外，文献是否有正常噪声的结果？
 详细信息＆amp;结果到目前为止： 
我在这个主题上发现的文献几乎是心理方法论文。这让我觉得我可能缺少一些描述统计文献中相同数量的关键字。
这是我到目前为止发现的： spence＆amp＆amp; Stanley 2024-回火期望：在复制的背景下计算和解释预测间隔的教程汇总方法以计算平均值，平均值和相关性的预测间隔，这在正常线性模型中均在正常线性模型中。从那里的参考链跟踪回到 Cumming，G。，G。，＆amp; Maillardet，R。（2006） - 置信区间和复制：下一个平均值将在哪里跌落？和“ noreferrer”&gt; estes（1997）。关于通过标准错误和置信区间的显示信息的通信。 都讨论了未来分布的未来样本平均值的预测间隔。
特别是在引文网络中的所有论文中，间隔均来自第一原理，并且没有与更广泛的理论的联系。
与此引用网络分开，统计间隔 bek by Meeker＆amp;在这种情况下，倾向于经常推荐Hahn，但它仅讨论未来样本的平均值的预测间隔，而仅讨论一些分布。我在引用文献中没有发现大量扩展（经过一点攻击性过滤）。
我是否缺少一些关键字，还是此时尚未真正开发有关此类型的预测间隔的文献？或在Meeker＆amp;中进行讨论的方法哈恩如此琐碎地扩展到更复杂的案例，以至于没有人打扰它们分别描述它们？
请注意，我需要合理的有限样本保证，因此在广义模型中使用正常线性模型的方法不起作用（例如，我已经看到在小样本负二项式模型中从正常近似值下降到85％的95％间隔的覆盖率）。）。）。）。）。
 编辑：我确实需要体面的频繁保证，因此，除非有证据表明他们在类似情况下提供此类保证，否则贝叶斯的方法将无法执行。频繁的行为不一定是确切的，但必须是好的（最差的1个百分点底部底漆可能还可以）。
本网站上的相关问题包括：

 预测间隔
 预测间隔？  
 ＆quort“&gt;＆quot”对于适合新数据的模型的斜率（我自己）
]]></description>
      <guid>https://stats.stackexchange.com/questions/662406/literature-prediction-intervals-for-effect-size</guid>
      <pubDate>Mon, 10 Mar 2025 11:45:29 GMT</pubDate>
    </item>
    <item>
      <title>用正态分布近似计数数据</title>
      <link>https://stats.stackexchange.com/questions/662384/approximating-count-data-with-a-normal-distribution</link>
      <description><![CDATA[ i具有以下有关两年内人口中计数变量（即正数）的信息（例如，在1年和5年度成年人的每名成人车祸）。我得到了每个人的95％置信区间的下限和上限（即，实际人口和汽车事故数量未知，并且估计自己 - 可能是更高或更低的，因此提供了边界）：

   $ x_1 $ 及其相关的95％置信区间 $（x_ {1 \ _l}，x__ {1 \ _U}）

   $ y_1 $ 及其相关的95％置信区间 $（y__ {1 \ _l}，y__ {1 \ _U}）$

   $ x_5 $ 及其相关的95％置信区间 $（x_ {5 \ _l}，x__ {5 \ _U}）$

   $ Y_5 $ 及其相关的95％置信区间 $（y__ {5 \ _l}，y__ {5 \ _U}）$


I want to estimate the total percent change in the ratio $x/y$ from Year 1 to Year 5, using the formula (i.e.  Rate1 = $x_1/y_1$ and Rate5 = $x_5/y_5$)and add a measure of此估计值的不确定性： 
  $$ \ text {百分比cange} = \ frac {\ text {rate5}  -  \ text {rese1}}} {\ text {rese1}}
我试图使用Delta方法早期解决此问题（帮助我使用delta方法的帮助），我被告知我可能需要对conteration和denomation进行数字划分。我认为也许我可以通过假设分子和分母遵循多元正态分布来使用Bootstrap模拟来解决此问题。 
我写了1年的联合多变量（可以为5年代写同样的多元）
  $$ \ begin {pmatrix} x_1 \\ y_1 \ end end {pmatrix} \ sim \ sim \ Mathcal {n} \ left（\ okit \ sigma^2_ {x_1}＆amp; \ end {pmatrix} \ right）$$  
其中：

  $ x_1 $ 是 $ x_1 $  的点估计值
  $ y_1 $ 是 $ y_1 $   的点估计值
   $ \ sigma_ {x_1} $ 是从置信区间 $（x_ {1 \ _l}，x___ {1 \ _U}） \ frac {x_ {1 \ _U}  -  x_ {1 \ _l}}} {2 \ times 1.96} $   
   $ \ sigma_ {y_1} $ 是从置信区间 $（y__ {1 \ _l}，y__ ___ {1 \ _U}）$ {1 \ _U} \ frac {y_ {1 \ _u} -y_ {1 \ _l}}} {2 \ times 1.96} $   
  $ \ rho_1 $ 是 $ x_1 $ 和

该计划是（主观）确定 $ \ rho $ 的值，并模拟多对（ $ x_1，y_1 $ ）和（ $ x_5，y_5，y___5 $ ）。对于每个模拟对，我将计算更改百分比。然后，我要么使用百分位数引导程序或偏差校正的加速BCA）引导程序对最终答案进行不确定性度量（由于这是一个非线性统计量，因此常规的引导程序可能不适合（例如 bootstrap用于对称vs symmetric vs symmetric分布， href =“ https://stats.stackexchange.com/questions/662304/does-the-bootstrap-work-for-non-linear-statistics”&gt; bootstrap适用于非线性统计信息？）。）。）。）
 这是模拟的正确应用吗？还是我应该避免这种情况，因为从可用的数据中无法估算 $ \ rho_1，\ rho_5 $ ？理想情况下，由于数据的计数性质，我本来会尝试根据泊松分布模拟模型，但我认为也许正常的方法可能还可以吗？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/662384/approximating-count-data-with-a-normal-distribution</guid>
      <pubDate>Sun, 09 Mar 2025 20:06:07 GMT</pubDate>
    </item>
    </channel>
</rss>