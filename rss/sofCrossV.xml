<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 01 Jun 2024 06:19:04 GMT</lastBuildDate>
    <item>
      <title>在堆叠中训练和调整元学习器时如何分割数据？</title>
      <link>https://stats.stackexchange.com/questions/648418/how-to-split-data-when-training-and-tuning-the-meta-learner-in-stacking</link>
      <description><![CDATA[我有一个关于元学习过程的数据分割的简单而又棘手的概念问题。
假设我有一个简单的 X_train、X_test 分割，我在此分割上训练和调整了 model_1 和 model_2。现在我想使用 stacker_0 将它们堆叠起来。我设想这样做：
将 X_train 分成 5 折 $F_{i=0}^4$，然后在 $F_{i, i\neq j}$ 上训练 model_1 和 model_2，并在 $F_j$ 上进行预测。然后我将有一个新的数据集 X_train&#39;，我可以用它来训练我的元模型而不会出现泄漏。
我现在的问题是知道我是否可以使用此 X_train&#39; 在 stacker_0 上执行通常的模型选择工作（即超参数调整、元模型验证等）。这样公平吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648418/how-to-split-data-when-training-and-tuning-the-meta-learner-in-stacking</guid>
      <pubDate>Sat, 01 Jun 2024 00:15:32 GMT</pubDate>
    </item>
    <item>
      <title>缺失结果数据的多重填补</title>
      <link>https://stats.stackexchange.com/questions/648417/multiple-imputation-for-missing-outcome-data</link>
      <description><![CDATA[我花了大量时间试图了解 MICE 在帮助“填补”缺失结果数据方面可能发挥的作用。我对多重插补和预测模型都比较陌生，因此我非常感谢您的见解。
问题：我有一个约 70% 国家/地区的临床医生劳动力密度数据集（# 临床医生/100k 人）。我想要一个所有国家/地区的完整数据集（这将使我们能够提供全球临床医生总数），这意味着我需要为其余国家/地区创建插补或预测。我有许多协变量（约 15 个）。但是，这些协变量数据很少是所有国家/地区的完整数据。我的理解是，我通过传统预测模型（使用训练/测试分割）获得所有缺失国家结果估计的能力将受到缺失协变量数据的限制。
我的解决方案：我的想法是使用 MICE 来估算每个国家缺失的结果变量，即临床医生密度。
如果这是 MICE 的有效用途，那么我的问题是如何获得结果变量（劳动力密度）。我已经创建了 m 个估算数据集。我明白我不应该取这些数据集的平均值或选择单个数据集。我还没有找到清楚地解释下一步的出版物，因为 MICE 似乎更多地用于获取回归系数而不是数据本身。我的计划是使用具有完整数据的协变量创建合并回归模型（这限制了我可以使用的协变量），然后使用该回归模型来“预测”缺失的国家劳动力密度。
这合理吗，或者有更好的方法吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648417/multiple-imputation-for-missing-outcome-data</guid>
      <pubDate>Fri, 31 May 2024 23:57:18 GMT</pubDate>
    </item>
    <item>
      <title>给出的例子是否与先前的预测检查相对应？</title>
      <link>https://stats.stackexchange.com/questions/648416/does-the-example-given-correspond-to-a-prior-predictive-check</link>
      <description><![CDATA[有人能向我解释一下贝叶斯推理中先验预测检验的确切含义吗？在一些文档中，人们使用观察到的数据（“我们将观察到的数据与模型的预测进行比较”），而在某些其他文档中，人们不使用观察到的数据（“在观察数据之前总结我们的知识”）。
根据我对贝叶斯的了解（但远非专家），第一种情况让我想起了所谓的后验预测检验，它本身似乎有相当清晰的记录，我相信我很好地理解了这项技术。另一方面，对于先前的预测检查，我仍然不清楚该如何进行。
因此，为了避免空谈，我在下面给出了一个（略显人为的）例子。
假设我试图模拟一分钟内通过给定道路点的车辆数量，对此，我认为使用参数为$\lambda$的泊松分布是合理的。我了解到我们最常使用 Gamma 分布作为 $\lambda$ 的 先验。在类似情况下，1 分钟内通过的车辆平均值约为 $20$，在我看来我应该使用 Gamma( $\alpha$, $\beta$ ) 分布，其中 $\alpha$/$\beta$ ~ $20$。除了我可以将 (2, 0.1) 或 (20,1) 或许多其他的一对作为一对 ($\alpha$, $\beta$)...
因此，我目前对 先前预测检查 的理解使我采取如下方式：

我决定将要进行的 泊松 分布的观察次数，假设 $n = 100$。
我给自己两个值 ​​$\alpha$ 和 $\beta$，使得 $\alpha$/$\beta$ $=20$。
我从 Gamma($\alpha$, $\beta$) 中采样一个值 $\lambda_i$。
利用这个 $\lambda_i$，我从 Poisson($\lambda_i$) 中采样 $n$ 个值，并记下采样的 $n$ 个中的最大值 $M_i$值。
我重复$N$次（例如$1000$次）点3）和4）。
我绘制了$N$个最大值$M_i$的直方图。
我为不同的对（$\alpha$，$\beta$）创建了几个直方图。

我得到的结果由下面的图给出（我没有给出整个程序，以免帖子超载）：

对要进行的实验的讨论得出结论，不可能假设几百辆车可以在 1 分钟内通过给定点（必须消除$(0.2, 0.01)$这对最大值）；另一方面，有时也会出现一百辆或更多的车辆可以通过的情况（必须消除$(20, 1)$和$(200, 10)$这对组合，因为最大值太低了）。
最后，我选择了先验Gamma$(2, 0.1)$，它看起来最合适。
这种推理真的构成了先前的预测检查吗？这是通常的推理方式吗？
如果不是，如果我在详细描述这个例子时完全错了，你能给我一个如何进行事先预测检查的具体例子吗？
任何能解决我疑惑的信息都会受到欢迎！]]></description>
      <guid>https://stats.stackexchange.com/questions/648416/does-the-example-given-correspond-to-a-prior-predictive-check</guid>
      <pubDate>Fri, 31 May 2024 22:04:54 GMT</pubDate>
    </item>
    <item>
      <title>离散时间生存分析（Cox 回归）的样本量</title>
      <link>https://stats.stackexchange.com/questions/648415/sample-size-for-survival-analysis-cox-regression-with-discrete-time</link>
      <description><![CDATA[我有一项研究，患者每两个月来医院检查一次。T0（手术前一周）、T1（手术后两个月）、T2（手术后 4 个月）直至 T9（手术后 18 个月）。
我需要运行包含两个协变量（一个连续的和一个二元时间相关协变量）的 Cox 回归。
似乎时间可以被视为离散的（如果我错了，请纠正我）。
问题：当时间是离散的时，是否有任何函数公式（R 中的包）来计算 Cox 回归的样本量。*]]></description>
      <guid>https://stats.stackexchange.com/questions/648415/sample-size-for-survival-analysis-cox-regression-with-discrete-time</guid>
      <pubDate>Fri, 31 May 2024 20:53:53 GMT</pubDate>
    </item>
    <item>
      <title>矩阵正态分布和多元高斯分布有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/648414/what-is-the-difference-between-a-matrix-normal-distribution-and-the-multivariate</link>
      <description><![CDATA[$\newcommand{\vec}{\operatorname{vec}}$考虑一组 $N$ 矩阵 $X_1, X_2, \ldots, X_N$。我想估计这些矩阵的分布，这些分布由均值和协方差表示。
我通过简单地矢量化我的矩阵 $\vec(X_1), \vec(X_2), \ldots, \vec(X_N)$ 来解决这个问题，然后我计算均值和协方差，就像我对多元高斯分布所做的那样。换句话说，这意味着 $\vec(X) \sim \mathcal{N}(M, \Sigma)$，其中 $\vec(X)$ 经过重新整形后得到 $X$
然而，我遇到了矩阵正态分布，它根据行协方差和列协方差定义分布。因此，从矩阵正态分布中抽样的矩阵由$X \sim \mathcal{M}\mathcal{N}(M, U, V)$给出。
在维基百科文章中，它说，对于随机矩阵$X$，矩阵正态分布与多元高斯分布之间的关系是$X \sim \mathcal{M}\mathcal{N}(M, U, V)$当且仅当$X \sim \mathcal{N}(V \otimes U)$，其中$\otimes$是克罗内克积的运算符。
如果我生成一组随机矩阵，我可以估计以多种方式计算分布的参数。我可以将矩阵矢量化，将其视为多元高斯分布以获得协方差。或者，我可以计算行协方差和列协方差，然后可以从克罗内克积计算协方差。
但是，我从矢量化方法和克罗内克积方法中获得的协方差值并不相同。我应该得到相同的结果吗？如果不是，为什么它们不同？我不明白这些分布在实践中代表什么，所以我不确定在哪种情况下应该使用哪种分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/648414/what-is-the-difference-between-a-matrix-normal-distribution-and-the-multivariate</guid>
      <pubDate>Fri, 31 May 2024 20:35:43 GMT</pubDate>
    </item>
    <item>
      <title>G*Power 混合双向方差分析功效分析 - 样本量似乎太小？</title>
      <link>https://stats.stackexchange.com/questions/648412/gpower-mixed-two-way-anova-power-analysis-sample-size-seems-too-small</link>
      <description><![CDATA[我正在运行我有史以来的第一次功效分析，我担心我对 G*Power 的某些方面存在误解。我正在运行 2x2 混合方差分析。我选择了“方差分析：重复测量，组内-组间相互作用”选项，并将 Cohen&#39;s d 保留为默认值 0.25，只是为了了解一下。当我将功效调整为 0.80 时，计算得出的总样本量只有 34 人 - 我有点震惊，因为它表明每组只有 17 人就足够了。我曾经做过动物研究，这大约是我在老鼠身上使用的样本量。这听起来对吗，还是我对软件有什么不理解的地方？谢谢！
参数：
效果大小 f：0.25
alpha 错误概率：.05
功效：.80
组数：2
测量次数：2
重复测量之间的校正：0.5
非球面校正 epsilon：1]]></description>
      <guid>https://stats.stackexchange.com/questions/648412/gpower-mixed-two-way-anova-power-analysis-sample-size-seems-too-small</guid>
      <pubDate>Fri, 31 May 2024 19:42:34 GMT</pubDate>
    </item>
    <item>
      <title>GPytorch - Guasisan 过程回归器的手动预测与内置功能不同</title>
      <link>https://stats.stackexchange.com/questions/648411/gpytorch-manual-prediction-from-a-guasisan-process-regressor-is-not-the-same-a</link>
      <description><![CDATA[我是 GPytorch 的新手，我的问题可能看起来很初级！但我真的被难住了！
为了解释我的问题，我使用了一个简单的 GP 回归器来解释这个问题。假设我在 GPytorch 中有以下模型来训练回归器：
import torch
import gpytorch
from gpytorch.kernels import RBFKernel
from gpytorch.means import ConstantMean, ZeroMean
from gpytorch.likelihoods import GaussianLikelihood
from gpytorch.models import ExactGP

# 生成合成数据
torch.manual_seed(0)
train_x = torch.linspace(0, 1, 100)
train_y = torch.sin(train_x * (2 * torch.pi)) + torch.randn(train_x.size()) * 0.2

class GPRegressionModel(ExactGP):
def __init__(self, train_x, train_y, unlikely):
super(GPRegressionModel, self).__init__(train_x, train_y,可能性)
self.mean_module = ZeroMean()
self.covar_module = RBFKernel()

def forward(self, x):
mean_x = self.mean_module(x)
covar_x = self.covar_module(x)
return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)

likelihood = GaussianLikelihood()
model = GPRegressionModel(train_x, train_y, unlikely)

# 模型训练
model.train()
likelihood.train()
optimizer = torch.optim.Adam(model.parameters(), lr=0.1)
mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)
training_iterations = 50

for i in range(training_iterations):
optimizer.zero_grad()
output = model(train_x)
loss = -mll(output, train_y)
loss.backward()
optimizer.step()


现在，我可以通过 GPytorch 内置功能自动进行预测，如下所示：
# 示例测试实例
test_x = torch.tensor([0.5])

# 模型预测 
model.eval()
likelihood.eval()

with torch.no_grad(), gpytorch.settings.fast_pred_var():
perceived_pred = unlikely(model(test_x))
model_mean = perceived_pred.mean.item()
model_variance = perceived_pred.variance.item()


但由于我想进行一些其他推断，因此我将使用优化的超参数进行一些计算；我意识到我甚至无法复制上述模型的预测！这是我根据模型超参数进行预测的代码：
# 提取长度尺度和噪声方差
lengthscale = model.covar_module.lengthscale.item()
noise_variance = model.likelihood.noise.item()

# 定义精炼预测函数
def rbf_kernel(x1, x2, lengthscale):
&quot;&quot;&quot;计算 x1 和 x2 之间的 RBF 核。&quot;&quot;&quot;
diff = x1.unsqueeze(1) - x2.unsqueeze(0)
dists = torch.sum(diff ** 2, -1)
return torch.exp(-0.5 * dists / lengthscale ** 2)

def predict_from_parameters(train_x, train_y, test_x, lengthscale, noise_variance):
K = rbf_kernel(train_x, train_x, lengthscale) + noise_variance * torch.eye(train_x.size(0))
K_s = rbf_kernel(train_x, test_x, lengthscale)
K_ss = rbf_kernel(test_x, test_x, lengthscale) + noise_variance * torch.eye(test_x.size(0))

L = torch.linalg.cholesky(K)
alpha = torch.cholesky_solve(train_y.unsqueeze(-1), L)
pred_mean = K_s.t().matmul(alpha).squeeze()
v = torch.linalg.solve(L, K_s)
pred_var = K_ss - v.t().matmul(v)
return pred_mean, pred_var.diag()

# 手动预测
pred_mean, pred_var = predict_from_parameters(train_x, train_y, test_x, lengthscale, noise_variance)

问题：
手动预测（pred_mean 和 pred_var）与从 GPytorch 内置功能（model_mean、model_var）获得的预测完全不同。我无法找出我错在哪里。
任何帮助都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648411/gpytorch-manual-prediction-from-a-guasisan-process-regressor-is-not-the-same-a</guid>
      <pubDate>Fri, 31 May 2024 19:42:02 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在通常通过 McNemar 检验进行分析的设计中对随机效应进行建模？</title>
      <link>https://stats.stackexchange.com/questions/648407/is-there-an-way-to-model-random-effects-in-a-design-that-is-typically-analyzed-b</link>
      <description><![CDATA[我的问题是：如果在一项具有配对二元响应数据的研究中（其中经常使用 McNemar 检验），我们可以使用精确二项式检验来检验比值比，是否可以使用 GLMM 来建模相同的比值比（并利用在此 GLMM 中建模随机效应等）？
基本上，我是在阅读 Fay, 2020 后想到这个问题的。他们以此开头：

考虑配对二元响应数据。例如，假设您将双胞胎随机分配到两个治疗组（测试和对照），然后对二元结果（通过或失败）进行测试。每对双胞胎都有 4 种可能的结果：（a）两个双胞胎都失败了；（b）对照组的双胞胎失败了，而测试组的双胞胎通过了；（c）测试组的双胞胎失败了，而对照组的双胞胎通过了；或（d）两个双胞胎都通过了。下面是一个表格，其中属于四个类别的双胞胎数量分别表示为 a、b、c 和 d：





测试：失败
测试：通过




对照：失败
a
b


对照：通过
c
d



然后作者解释了为什么 McNemar 测试的假设可以稍作修改，并使用精确二项式检验进行测试，从这个开始声明：

在对不一致对的总数$b + c$进行条件化之后，我们可以将问题视为$B ∼ 二项式（b + c，θ）$，其中$B$是与$b$相关的随机变量。

基于此声明，他们继续表明，在这种成对二元响应数据设置中，可以使用精确二项式检验来确定优势比是否等于 1，其中$\theta=\frac{b}{b+c}$和
$$ 优势比 = \phi = \frac{\theta}{1-\theta}$$
后来，在附录 A（第 4 页）中，作者指出：

假设我们有一个逻辑模型，其对数几率建模为：

$$\log\left(\frac{\pi_{ij}}{1-\pi_{ij}}\right)=\mu_i+group*\beta$$
其中：

$group$ 是一个指示函数，对于对照组为 0，对于测试组为 1。
$\mu_i$ 是一个随机双胞胎效应。
$\pi_{ij} = P[Y_{ij} = 1]$，并且 $Y_{ij}$ 是来自 $i^{th}$ 对的 $j^{th}$ 个二元响应

重要的是，他们指出：

在此模型下，$\phi=\exp(\beta)$

鉴于此陈述，优势比 $\phi=\exp(\beta)$，这是否表明使用 GLMM 来估计优势比并测试其重要性？
如果是，那么是什么优点和缺点？]]></description>
      <guid>https://stats.stackexchange.com/questions/648407/is-there-an-way-to-model-random-effects-in-a-design-that-is-typically-analyzed-b</guid>
      <pubDate>Fri, 31 May 2024 18:56:04 GMT</pubDate>
    </item>
    <item>
      <title>无偏性 Wilcoxon-Mann-Whitney 检验</title>
      <link>https://stats.stackexchange.com/questions/648399/unbiasedness-wilcoxon-mann-whitney-test</link>
      <description><![CDATA[对于 Wilcoxon-Mann-Whitney 检验，有许多不同的替代方案。一种替代方案是 $P(X &lt; Y) + \frac{1}{2}P(X = Y) \neq 0.5$。对此有令人信服的论据，例如检验统计量本质上是该概率的样本等价物，并且它代表了检验一致的最广泛替代方案。
但是，在这种替代方案下，检验并非无偏。下面的示例说明了这一点。它可能在附加假设下无偏（我怀疑排名数据的方差相等）。不幸的是，我没有找到任何关于这方面的研究；研究通常侧重于其他替代方案，例如随机排序（其中一个累积分布函数始终大于另一个），在这种替代方案下，检验是无偏的。因此，我的问题是：是否存在假设（其他/弱于随机排序）使得该替代方案的测试无偏？
set.seed(123)
reps &lt;- 10^3
p_wmw &lt;- rep(NA, reps) 
for(i in 1:reps){
g1 &lt;- rnorm(80, mean = 0, sd = 5)
g2 &lt;- rnorm(20, mean = .2, sd = 1)
p_wmw[i] &lt;- wilcox.test(g1, g2)$p.value
}
print(mean(p_wmw &lt; .05))

prints: 0.013]]></description>
      <guid>https://stats.stackexchange.com/questions/648399/unbiasedness-wilcoxon-mann-whitney-test</guid>
      <pubDate>Fri, 31 May 2024 16:03:10 GMT</pubDate>
    </item>
    <item>
      <title>我想要回答的假设的最低调查受访者人数</title>
      <link>https://stats.stackexchange.com/questions/648384/minimum-survey-respondents-for-hypotheses-i-want-to-answer</link>
      <description><![CDATA[我是一个热切的统计学菜鸟，所以对于这些基本问题我深表歉意。
我打算向大量人群（美国使用胰岛素的糖尿病患者）（约 840 万）发送一份调查问卷
基于此，我的目标是总共获得 96+ 份调查问卷回复（误差幅度为 +- 10%），目标是接近 300 份回复。
我有一些假设，想在调查结果中加以研究，并将进行一些统计测试

一个假设是“假设：根据用户使用胰岛素的时间，对（xyz 用户需求，仅举一个虚假的例子 - 能够快速计算一餐所需的胰岛素量）重要性的评级存在显著差异”
这将是我收集的一个人口统计问题（您使用胰岛素多长时间了？），答案范围个月。
由于重要性是李克特量表（序数）上的评级，因此各组有所不同，我想了解差异，因此我考虑进行 Mann-Whitney 测试。我特别想了解使用胰岛素的时间越长，是否会影响对这一用户需求的重要性评级。

我的问题：我是否需要至少 96 名回答每个时间段（例如 1 年或更长和 1 年或更短）的受访者才能获得统计签名响应，或者我是否只需要查看回答此问题的所有受访者的总数为 96 的受访者。此外，如果您对我的方法有任何反馈，请随时发表意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/648384/minimum-survey-respondents-for-hypotheses-i-want-to-answer</guid>
      <pubDate>Fri, 31 May 2024 14:24:51 GMT</pubDate>
    </item>
    <item>
      <title>具有共变预测变量的线性回归模型中的方差比例</title>
      <link>https://stats.stackexchange.com/questions/648334/proportion-of-variance-in-a-linear-regression-model-with-a-covaring-predictor</link>
      <description><![CDATA[给定一个模型：
\begin{align}Y_{i}=Z_{i}*\beta * X_{i} + Z_{i} + \epsilon_{i}\tag{Eq. 1}&amp;\end{align&gt;
我对预测变量 $X$ 解释的方差比例的封闭公式感兴趣，通常也称为判定系数。请注意，在此模型中，变量 $Z_{i}$ 与 $X_{i}$ 共变，因此这不一定是具有单个预测变量的线性回归模型。
我知道可以使用以下表达式计算方差比例（又名判定系数）：
\begin{align}R^2=\beta^2*\frac{V(X)}{V(Y)}\tag{Eq. 2}&amp;\end{align&gt;
我认为有两种可能的替代方案可以实现我的目标：

将响应变量 $Y_{i}$ 除以 $Z_{i}$，这样：
\begin{align}\frac{Y_{i}}{Z_{i}}=\beta * X_{i} + 1\tag{Eq. 3}&amp;\end{align&gt;
然后使用 $Eq. 2$。

将 $Z_{i}$ 的期望视为常数，使得：
\begin{align}Y_{i}=\beta&#39; * X_{i} + \operatorname{E}(Z)\tag{Eq. 4}&amp;\end{align
其中 $\beta&#39;=\operatorname{E}(Z)*\beta$。然后相应地使用 $Eq. 2$。


当我将某些模拟数据（此处未显示）上通过线性回归估计的斜率与预期斜率（使用模拟数据的先前信息计算）进行比较时，对于 Eq. 3 和 Eq. 4，我确实得到了非常准确的结果。
对于 Eq. 4 模型中计算的 $R^2$，情况并非如此。
我推测，将 $R^2$ 表达式应用于 Eq. 2（对于单个预测器线性回归准确）可能对 Eq. 1 中的模型不太好。]]></description>
      <guid>https://stats.stackexchange.com/questions/648334/proportion-of-variance-in-a-linear-regression-model-with-a-covaring-predictor</guid>
      <pubDate>Fri, 31 May 2024 01:21:40 GMT</pubDate>
    </item>
    <item>
      <title>方差分析不显著但事后分析显著 - 如何解释？</title>
      <link>https://stats.stackexchange.com/questions/648329/anova-not-significant-but-post-hoc-is-how-to-interpret</link>
      <description><![CDATA[我有一些关于动物的数据，它们的饮食（食肉动物、杂食动物、食草动物）以及它们的轨道相对于头骨中线的角度。通常，食肉动物的眼睛更多朝前，而食草动物的眼睛角度更大（眼睛在头部侧面），以便在进食/饮水等时能够看到更多周围环境。
我的数据如下所示：

我在同一块中运行了 ANOVA 和事后检验，但 ANOVA 返回 p&gt;0.05，而 Tukey 显示某些组之间存在差异
diet.aov2 &lt;- aov(mean_pos ~ Diet, data= raw_skull)
summary(diet.aov)

TukeyHSD(diet.aov2)

-------

Df Sum Sq Mean Sq F value Pr(&gt;F)
Diet 2 501 250.5 2.345 0.13
残差 15 1602 106.8 
Tukey 均值多重比较
95% 家族置信水平

拟合：aov（公式 = 平均值 ~ 饮食，数据 = raw_skull）

$饮食
diff lwr upr p adj
食草动物-食肉动物 16.474861 6.96985 25.979873 0.0003479
杂食动物-食肉动物 -3.728538 -12.86324 5.406165 0.5881155
杂食动物-食草动物 -20.203399 -29.17716 -11.229635 0.0000054

我认为这是不可能的，我也不确定如何解释它。事后检验的结果从生物学角度来看是有意义的，但为什么方差分析不显著呢？
这怎么解释呢？或者我应该运行不同的测试？
这是我的图
]]></description>
      <guid>https://stats.stackexchange.com/questions/648329/anova-not-significant-but-post-hoc-is-how-to-interpret</guid>
      <pubDate>Thu, 30 May 2024 06:59:52 GMT</pubDate>
    </item>
    <item>
      <title>一个结果变量可以在同一个模型中使用两次吗？</title>
      <link>https://stats.stackexchange.com/questions/648251/can-an-outcome-variable-be-used-twice-in-the-same-model</link>
      <description><![CDATA[在什么时候，在同一个模型框架中的两个似然中使用同一个结果变量是合适的？
下面是一个具体的例子：
model{
y ~ bernoulli( (1-psi) * mu);
y ~ bernoulli( (1-psi) * theta);

u ~ bernoulli( theta);
}


我能够使这个模型工作的唯一方法是在两个单独的似然中使用 y。该模型公式完美地恢复了模拟参数。
在联合似然（混合模型，Stan 中的 log_mix）中执行此操作会导致 mu 的估计有偏差。它仅在可能性独立时才有效。
更新：添加了 R 模拟代码以显示问题的生成过程：
set.seed(2)
n = 1000
psi = 0.23 # 假阴性比例
beta0 = -0.5
X = rnorm(n)
beta = 0.01

y = rbinom(n, size = 1, prob = (1 - psi) * 1/(1+exp(-(beta0 + beta * X))))

# 计算&quot;true&quot;模拟成功概率，考虑 beta * X
# 模拟此问题的更彻底的方法是首先仅使用 beta0 生成 y 值，
# 然后模拟 X 值，但我试图让此代码块保持简洁。
alpha = 平均值（1/（1+exp（-（beta0 + beta * X））））

u = rbinom（n，1，1/（1+exp（-alpha）））

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648251/can-an-outcome-variable-be-used-twice-in-the-same-model</guid>
      <pubDate>Wed, 29 May 2024 22:38:31 GMT</pubDate>
    </item>
    <item>
      <title>具有聚类 SE 或 GLMER 的 GLM</title>
      <link>https://stats.stackexchange.com/questions/648313/glm-with-clustered-se-or-glmer</link>
      <description><![CDATA[我正在对 113 名受试者进行行为经济学实验，每人回答从 10 个问题中随机挑选出的 6 个问题。我的因变量是二进制的（错误 = 0 或错误 = 1），我正在使用逻辑回归。我不知道在具有个体随机效应的 GMLER 或 GLM 之间进行选择，然后在个体层面进行聚类 SE。我认为两者都可以控制个体内相关性 + GMLER 还会增加个体间变异性。我尝试了这两种模型，但得到了非常不同的结果，我不确定如何解释它以及选择哪种模型......特别是我不明白为什么我的所有系数在 GMLER 中都是显著的，但在 GLM 中却不是。这是否意味着随机效应捕获了部分无法解释的方差？因此 GMLER 是一个更好的模型？感觉我的 p 值“好得令人难以置信” ...
我使用 GLM（上）和 GLMER（下）进行了两次逻辑回归，并比较了结果。我得到了非常不同的标准错误和 p 值...我应该相信哪一个？

# glm
model2 &lt;- glm(Error ~ Complexity + Response_time + 
Response_time:Complexity, family = binomial(&quot;logit&quot;), 
data = B)
clustered_se2 &lt;- coeftest(model2, 
vcov. = vcovCR(model2, cluster = B$Individual, type = &quot;CR2&quot;))
p_values2 &lt;- clustered_se2[, 4]

# glmer
model &lt;- glmer(Error ~ Complexity + Response_time + 
Response_time:Complexity + (1 | Individual), 
family = binomial(&quot;logit&quot;), data = B)

]]></description>
      <guid>https://stats.stackexchange.com/questions/648313/glm-with-clustered-se-or-glmer</guid>
      <pubDate>Wed, 29 May 2024 16:08:04 GMT</pubDate>
    </item>
    <item>
      <title>具有 $\sigma^2$ 未知值的简单线性回归的最大似然估计量</title>
      <link>https://stats.stackexchange.com/questions/648163/maximum-liklihood-estimators-for-simple-linear-regression-with-sigma2-unknow</link>
      <description><![CDATA[假设我们有以下形式的简单线性回归模型：
$$Y_i = \beta X_i +\varepsilon_i$$
以下一组“经典假设”成立：

$E(\varepsilon_i)=0$

$Var(\varepsilon_i) = {E}(\varepsilon_i^2)-{E}(\varepsilon_i)^2= {E}(\varepsilon_i^2) = \sigma^2$

$Cov(\varepsilon_i, \varepsilon_j)=0$ 对所有 $i\neq j$

$\varepsilon_i$ 是正态的

$X_i$ 是常数，而不是随机变量。


我想找到 $\sigma^2$ 的最大似然估计量（假设它是未知的），以及 $\beta$ 的最大似然估计量（假设 $\sigma^2$ 是未知的）。
作为背景，假设 $\sigma^2$ 已知，则有以下公式表明 OLS 估计量是 MLE 估计量。
由此，我们可以看出 $\beta$ 的 OLS 估计量是通过求解以下公式得出的：
$$ \text{minimize s.t.} \beta: f(\beta) =\sum (\hat{\varepsilon_i}^2) = \sum (Y_i - \beta X_i)^2$$
我们可以很容易地看出，因为 $\frac{df}{d\beta} = \sum (-2Y_iX_i + \beta^2 X_i^2)$ 和 $\frac{d^2f}{d\beta^2} = 2X_i^2 \geq 0$ 则 $\beta$ 的 OLS 估计量由下式给出：
$$\hat{\beta} = \dfrac{\sum X_iY_i}{\sum X_i^2}$$
我们可以轻松证明这也是最大似然估计量。我们首先查看似然函数，它定义为$Y_i&#39;s$的联合概率密度函数，并回想一下，$\varepsilon_i$为正常的假设意味着$Y_i$为正常的。我们有：
$$L(\beta) = \prod \frac{1}{\sqrt{2\pi\sigma^2}}\exp(\frac{-1}{2\sigma^2}(Y_i - \beta X_i)^2)$$
$$ \therefore L(\beta) \frac{1}{(2\pi \sigma^2)^{\frac{N}{2}}} \exp (\frac{-1}{2\sigma^2}\sum (Y_i - \beta X_i)^2$$
如果我们考虑对数似然函数，我们得到：
$$l(\beta) = \text{ln} \left [ \frac{1}{(2\pi \sigma^2)^{\frac{N}{2}}} \right ]\frac{-1}{2\sigma^2}\sum (Y_i - \beta X_i)^2$$
这又是一个相当简单的问题，最大化$l(\beta)$，这再次表明$$\hat{\beta} = \frac{\sum Y_iX_i}{\sum X_i^2}$$
这是我有点困惑的地方。我是否应该将最大似然函数视为：
$$L(\beta,\sigma^2) = \prod \frac{1}{\sqrt{2\pi\sigma^2}}\exp(\frac{-1}{2\sigma^2}(Y_i - \beta X_i)^2)$$
然后根据 $\sigma^2$ 和 $\beta$ 找到最大值。此外，我不清楚我实际上在哪里使用了 $\sigma^2$ 已知的假设？这在考虑置信区间、假设检验等时显然是相关的。但我不清楚 $\sigma^2$ 已知或未知如何影响上述推导。
谢谢您的帮助，
Hmmm16]]></description>
      <guid>https://stats.stackexchange.com/questions/648163/maximum-liklihood-estimators-for-simple-linear-regression-with-sigma2-unknow</guid>
      <pubDate>Tue, 28 May 2024 18:12:44 GMT</pubDate>
    </item>
    </channel>
</rss>