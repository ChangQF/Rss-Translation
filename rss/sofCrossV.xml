<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 16 Jan 2025 21:15:05 GMT</lastBuildDate>
    <item>
      <title>进行缺失数据插补是否会导致观测值之间的依赖性？</title>
      <link>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</link>
      <description><![CDATA[当对数据集的所有观测值进行插补时，这是否会导致观测值之间的依赖性？那么假设观测值独立的统计模型是否不够充分？
例如，K 最近邻观测值的插补缺失值是其他观测值观测值的函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</guid>
      <pubDate>Thu, 16 Jan 2025 20:41:13 GMT</pubDate>
    </item>
    <item>
      <title>改进小样本标准均值估计量</title>
      <link>https://stats.stackexchange.com/questions/660126/improving-standard-mean-estimator-for-small-samples</link>
      <description><![CDATA[我有一系列 $X_1,\ldots X_n$ 独立同分布随机变量，其期望值为有限值 $\mu$，需要对其进行估计。标准估计量是 $\frac{X_1+\ldots+X_n}{n}$，但我希望避免出现异常值（当 $X_i$ 为极值时），因为 $n$ 很小。我们如何避免出现异常值？为了更精确，我需要使估计器更稳定，但不能删除值。
如果我们尝试$X_1,\frac{X_1+X_2}{2},\frac{X_1+X_2+X_3}{3},\ldots \frac{X_1+\ldots+X_n}{n}$并取中位数会怎样？这会有帮助吗？统计属性是什么？
我很感激任何评论和想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/660126/improving-standard-mean-estimator-for-small-samples</guid>
      <pubDate>Thu, 16 Jan 2025 19:52:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么在使用最大似然法进行参数估计时对数加性模型被认为比其他模型更准确</title>
      <link>https://stats.stackexchange.com/questions/660124/why-is-the-log-additive-model-considered-more-accurate-than-other-models-in-para</link>
      <description><![CDATA[我试图通过 Phoenix NLME 中使用的不同误差模型更好地掌握参数估计理论。对数加性模型似乎对我的用例表现更好，我正在尝试了解原因。我正在整体上进行评估（图形和定量测量），但非常看重 -2LL 分数。我在网上偶然发现了以下说法：

这是因为误差模型在对数空间中变为可加的，从而可以实现更高的性能和准确性。

因此，该模型具有以下形式
log(value) = log(predicticed_value) + error

有人能解释一下为什么这种形式比普通的加法或比例误差项具有某种数值优势吗？
引用来源]]></description>
      <guid>https://stats.stackexchange.com/questions/660124/why-is-the-log-additive-model-considered-more-accurate-than-other-models-in-para</guid>
      <pubDate>Thu, 16 Jan 2025 19:05:35 GMT</pubDate>
    </item>
    <item>
      <title>推断回归拟合中存在异方差</title>
      <link>https://stats.stackexchange.com/questions/660123/inference-on-the-presence-of-heteroscedasticity-in-regression-fit</link>
      <description><![CDATA[我已经拟合了一个简单的线性回归，如下所示
dat = structure(list(A = c(-3.673, -4.914, -4.556, -4.732, -3.36, -3.731, 
-5.069, -5.263, -5.054, -3.711, -4.159, -3.191, -5.035, -5.205, 
-4.809, -5.485, -3.621, -4.551, -3.989, -3.963, -5.092, -4.508, 
-6.163, -4.923, -4.022, -3.098), B = c(0.01, 0.016, 0.011, 0.023, 
-0.014, 0.036, 0.083, 0.082, 0.03, 0.005, 0.025, 0.012, 0.027, 
0.056, 0.023, 0.103, 0.009, 0.02, 0.033, 0.051, 0.076, 0.004, 
0.049, 0.052, 0.033, -0.032), C = c(-0.205, -0.15, -0.378, -0.751, 
0.304, -0.314, 0.587, 0.258, 0.147, -0.379, -0.271, -0.527, -0.076, 
-0.149, -0.001, 0.412, 0.021, -0.182, -0.363, -0.447, 0.335, 
0.108, 1.209, 0.035, -0.116, -0.319)), row.names = c(NA, -26L
), class = &quot;data.frame&quot;)

MyModel = lm(A ~ B + C, data = dat)

&gt; print(summary(MyModel))

调用：
lm(formula = A ~ B + C, data = dat)

残差：
最小值 1Q 中位数 3Q 最大值 
-0.8979 -0.4668 0.1139 0.3984 0.7566 

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) -4.0786 0.1619 -25.198 &lt; 2e-16 ***
B -13.0134 3.7676 -3.454 0.00216 ** 
C -0.7241 0.2879 -2.515 0.01935 * 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：23 个自由度上的 0.5183

多重 R 平方：0.5904，调整后的 R 平方：0.5547

F 统计量：2 和 23 DF 上的 16.57，p 值：3.488e-05

但是，如果我想获得异方差稳健估计，我会得到
library(sandwich)
&gt; print(coeftest(MyModel, vcov = vcovHC(MyModel, type = &quot;HC0&quot;)))

系数的 t 检验：

估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) -4.07864 0.16581 -24.5980 &lt; 2.2e-16 ***
B -13.01339 3.40801 -3.8185 0.000882 ***
C -0.72411 0.34479 -2.1001 0.046885 * 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

正如您所见，对变量 C 重要性的推断会根据异方差稳健估计而改变，该变量似乎略微不重要。
基于上述情况，我应该采用异方差稳健估计还是普通估计？
但是，如果我使用 Berush-pegan 检验来测试残差中是否存在异方差，我会发现似乎没有异方差
&gt; bptest(MyModel)

学生化 Breusch-Pagan 检验

数据：MyModel
BP = 2.3604，df = 2，p 值 = 0.3072

我该如何解释这种相互矛盾的结果？样本量相对较小是真正的问题吗？即使在这种情况下，我应该采用哪个估计值？]]></description>
      <guid>https://stats.stackexchange.com/questions/660123/inference-on-the-presence-of-heteroscedasticity-in-regression-fit</guid>
      <pubDate>Thu, 16 Jan 2025 18:47:17 GMT</pubDate>
    </item>
    <item>
      <title>最佳重要性抽样</title>
      <link>https://stats.stackexchange.com/questions/660122/optimal-importance-sampling</link>
      <description><![CDATA[假设我们想通过重要性抽样估计
$$r = \mathbb{E}_{x\backsim p(x)} [f(x)]$$，即
$$r = \mathbb{E}_{x\backsim q(x)} \left[\frac{f(x)p(x)}{q(x)}\right]$$
现在wikipedia说，当$$q^{*}(x) = \frac{f(x)p(x)}{r}$$时，可获得方差为零的最佳重要性抽样。我的问题是，我们只能在覆盖率$q(x)$ 至少与 $p(x)$ 一样大，即如果对于某些 $x$，$p(x) \neq 0$ 意味着 $q(x) \neq 0$。
但对于上述 $q^{*}(x)$，例如在 CE 方法连续优化问题 $r = P_{\theta} [S(x) \geq \gamma]$ 中，此条件可能不成立。有人能解释为什么最佳重要性抽样在这些情况下仍然成立吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660122/optimal-importance-sampling</guid>
      <pubDate>Thu, 16 Jan 2025 18:21:50 GMT</pubDate>
    </item>
    <item>
      <title>如何检查分层连续数据水平分布的一致性</title>
      <link>https://stats.stackexchange.com/questions/660121/how-can-i-check-for-consistency-in-the-distribution-of-the-levels-of-stratified</link>
      <description><![CDATA[我在一些食品购买数据中有一个专有的权重特征，有人告诉我应该将其应用于热量含量以“纠正”他们对样本代表性的不确定性。我想分析特定篮子/家庭中出售的食品的类别组成，并拥有这样做所需的识别特征。然而，我担心，如果不应用这些权重，单个篮子/家庭的实际热量含量可能不具有代表性，因为显然，这些权重的必要性意味着他们认为他们需要重新称量所售产品的总量等，以符合整个人口的某种预期。
我的问题有一半是双重的，但我在调查这个问题时遇到了一个主要问题：
我如何评估食品类别的分层分类变量是否对权重的分布有显著影响（这些是数字和连续的，而类别有大约 20 个级别）。我相信我可以进行 Kruskal-Wallis 检验来检查是否存在总体差异（结果显示 p 值非常低），但我主要想检查与特定类别相关的权重是否与总体分布有显著差异，但我不确定如何做到这一点。
此外，我想知道我是否应该只应用权重并忘记这一点，但这样我就失去了谈论篮子具体热量含量的能力，这是一个缺点。
我觉得我可能把事情复杂化了，错过了一个明显的类比或解决这个问题的方法，如果能得到任何帮助，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660121/how-can-i-check-for-consistency-in-the-distribution-of-the-levels-of-stratified</guid>
      <pubDate>Thu, 16 Jan 2025 18:00:11 GMT</pubDate>
    </item>
    <item>
      <title>当其中一个分布比较简单时，使用蒙特卡洛估计 Kullback-Leibler 散度</title>
      <link>https://stats.stackexchange.com/questions/660116/estimate-kullback-leibler-divergence-with-monte-carlo-when-one-of-the-distributi</link>
      <description><![CDATA[我感兴趣的是估算$D_\mathrm{KL}(q \parallel p) = \int q(x) \log \frac{q(x)}{p(x)}\,\mathrm dx$，其中$p$是多元高斯分布，$q$是通过神经网络参数化的隐式分布，例如GAN中的生成器网络。背景：分布是隐式的，这意味着虽然我们可以从分布中抽样，但其密度是难以处理的。
一种直接的估计方法是拟合一个 Logistic 分类器 $f(x)$，将 $q$ 的样本与 $p$ 的样本区分开来，然后通过蒙特卡洛近似 KL 为：$\frac{1}{S}\sum_{j=1}^S \log\frac{\sigma(f(x_j))}{1-\sigma(f(x_j))}$，又名密度比技巧。我们用$\sigma(\cdot)$表示 S 型函数。
这种方法的一个明显缺点，也是我想问这个问题的原因，是我们没有利用$p(x)$的密度是已知且简单的事实，参见这篇文章。我们能做些什么来利用$p(x)$的高斯分布来改进估计吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660116/estimate-kullback-leibler-divergence-with-monte-carlo-when-one-of-the-distributi</guid>
      <pubDate>Thu, 16 Jan 2025 16:12:32 GMT</pubDate>
    </item>
    <item>
      <title>证明 LDA 目标函数 $w^T \Sigma_b w / w^T \Sigma_w w$ 最大化平方配对马哈拉诺比斯距离</title>
      <link>https://stats.stackexchange.com/questions/660113/prove-that-lda-objective-wt-sigma-b-w-wt-sigma-w-w-maximizes-squared-pai</link>
      <description><![CDATA[我们有一个随机变量$x \in \mathbb{R}^n$，它有$k$个类，类均值为$\bar{x}_i$。 线性判别分析找到$w$成分，使类间方差与类内方差的比率最大化，目标如下：
$$\frac{w^T \Sigma_b w}{w^T \Sigma_w w}$$
其中$\Sigma_b = \sum_{i=1}^k \bar{x}_i \bar{x}_i^T$是类间协方差，$\Sigma_w$是类内协方差。
我们可以预测$x$ 放入 $m$ 个第一个 LDA 分量中，得到 $z = W^T x$，其中 $W$ 的列是 LDA 的分量，并且 $z \in \mathbb{R}^m$。
我想表明 LDA 还最大化了 $z$ 空间中类均值之间的成对平方马哈拉诺比斯距离，由以下公式给出：
$$\sum_{i,j} (\bar{z}_i - \bar{z}_j)^T \Sigma_{z,w}^{-1} (\bar{z}_i - \bar{z}_j)$$
其中 $\bar{z}_i$ 是类 $i$ 中变量 $z$ 的平均值，而 $\Sigma_{z,w}$ 是变量 $z$ 的类内协方差。]]></description>
      <guid>https://stats.stackexchange.com/questions/660113/prove-that-lda-objective-wt-sigma-b-w-wt-sigma-w-w-maximizes-squared-pai</guid>
      <pubDate>Thu, 16 Jan 2025 15:25:24 GMT</pubDate>
    </item>
    <item>
      <title>如果需要真实参数的值来确定统计数据是否无偏，那么无偏估计量的意义何在？</title>
      <link>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</link>
      <description><![CDATA[我对无偏估计量的定义是：“如果用于估计参数的统计数据的抽样分布的平均值等于被估计参数的值，则该统计数据是无偏估计量。”
我知道如何确定统计数据是否是无偏估计量，因为我能够基于此解决应用题，但我不明白我们为什么要使用无偏估计量。我的笔记说，您需要使用无偏估计量，以便您的估计更准确。这对我来说很有意义，但为了确定统计数据是否是无偏估计量，您需要知道参数的值，以便将其与抽样分布的平均值进行比较，看看它们是否相等。如果使用无偏估计量来估计参数的值，如果我们已经知道参数的值，使用它有什么意义呢？
我一直在为此绞尽脑汁，但无济于事，如能得到任何帮助我将不胜感激，谢谢。
（我不擅长措辞，如果我听起来很重复或没有意义，请原谅）]]></description>
      <guid>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</guid>
      <pubDate>Thu, 16 Jan 2025 15:06:38 GMT</pubDate>
    </item>
    <item>
      <title>概率分布的均匀性</title>
      <link>https://stats.stackexchange.com/questions/660107/uniformity-of-probability-distribution</link>
      <description><![CDATA[我有一个关于从一组均匀分布的样本中移除样本的问题。
设$E = \{ X_{ij} \}, 1 \leq i &lt; j \leq n$为一组随机变量，其中每个$X_{ij}$在$\sim [0,1]$中是独立同分布的。显然，$|E| = \binom{n}{2}$。这些是完整加权图的权重，其中 $X_{ij}$ 确实是节点 $i$ 和节点 $j$ 之间的权重。
现在，我递归重复以下步骤（例如 $n/2$ 次）：

选择一个顶点 $z \in \{1,n\}$ 来验证以下内容：
存在另外两个顶点，$p, q \in [0,1], g \neq m$ s.t.
\begin{align}
X_{zp} = \arg\min\{ X_{uv} : u=p \text{ 或 } v=p \} \text{ 和 } X_{zq} = \arg\max\{ X_{uv} : u=q \text{ 或 } v=q \}
\end{align
存在另外两个顶点 $p$ 和 $q$ s.t. $z$ 和 $p$ 之间的关联边是 $p$ 所有关联边中的最小值，而 $z$ 和 $q$ 之间的关联边是 $q$ 所有关联边中的最大值，反之亦然。
这里有一个表示


如果是这种情况，则表示 $R = \{ X_{uv} \text{ s.t. } z=u \text{ or } z=v \}$.

设置 $E = E \setminus R$, $n = n-1$.

在每一步，我都会选择一个顶点 $z$ 来验证上述属性。然后我将其连同所有边一起删除，留下一个较小的完全图。
如果根据上述规则从中选取子集并删除它们，$E$ 是否仍是均匀分布的？]]></description>
      <guid>https://stats.stackexchange.com/questions/660107/uniformity-of-probability-distribution</guid>
      <pubDate>Thu, 16 Jan 2025 14:58:53 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中计算多重插补后合并结果的部分 Eta 平方</title>
      <link>https://stats.stackexchange.com/questions/660097/calculating-partial-eta-squared-for-pooled-results-after-multiple-imputation-in</link>
      <description><![CDATA[我已经为这个问题苦苦挣扎了一段时间，所以任何帮助我都非常感谢！
我正在尝试使用 R 中的 mice 包，使用多重插补后的汇总数据计算 ANCOVA 模型的效应大小（部分 eta 平方或 $\eta^{2}_p$）。ANCOVA 应用于认知测试的变化分数（基线和 12 周随访之间的差异）。这是模型：
results_test &lt;- with(imputed_data, lm((test_12 - test_base) ~ test_base + group + yoe))
pooled_results_test &lt;- pool(results_test)

从汇总结果中，我可以轻松提取组效应的 p 值、调整后的平均差异和置信区间。但是，我想计算一个效应大小的度量，例如 $\eta^{2}_p$。
我的困境
$\eta^{2}_p$ 的计算方法如下：
eta_squared &lt;- ss_effect / (ss_effect + ss_residual)

此处 $SS$ 表示平方和。
现在，如果我针对每个插补数据集分别计算并取插补平均值，我怀疑这可能存在缺陷，因为它是一个比率，而不是线性统计数据。对比率求平均值可能会扭曲真实的汇总效应大小。因此，我没有直接对 $\eta^{2}_p$ 进行平均，而是尝试将所有插补的平方和相加，然后计算合并的 $\eta^{2}_p$，如下所示：
# 计算合并的部分 eta 平方，方法是先对插补的平方和相加，最后在此基础上计算部分 eta 平方：

total_ss_effect &lt;- sum(sapply(1:imputed_data$m, function(i) {
anova(lm((test_12 - test_base) ~ test_base + group + yoe, 
data = complete(imputed_data, i)))[&quot;group&quot;, &quot;Sum Sq&quot;]
}))
total_ss_residual &lt;- sum(sapply(1:imputed_data$m, function(i) {
anova(lm((test_12 - test_base) ~ test_base + group + yoe, 
data = complete(imputed_data, i)))[&quot;Residuals&quot;, &quot;Sum Sq&quot;]
}))
eta_squared_pooled &lt;- total_ss_effect / (total_ss_effect + total_ss_residual)
cat(&quot;\nPooled Partial Eta Squared:&quot;, round(eta_squared_pooled, 3), &quot;\n&quot;)

此方法将组效应和插补残差的 $SS$ 相加，并从中计算 $\eta^{2}_p$总计。这似乎更合适，因为它考虑了插补之间的差异性。
我的问题：

这是一种合理的方法吗？将插补的平方和相加，然后计算部分 eta 平方，这在统计上有意义吗？

在 R 中是否有计算合并部分 eta 平方的标准方法或包？

在合并分析中不报告效应大小是否很常见？我注意到很多文章都没有包括它们，这似乎令人惊讶。


再次感谢你们提供的任何意见。我真的很感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660097/calculating-partial-eta-squared-for-pooled-results-after-multiple-imputation-in</guid>
      <pubDate>Thu, 16 Jan 2025 12:31:47 GMT</pubDate>
    </item>
    <item>
      <title>如何测试具有少量箱体的直方图是否符合正态分布？</title>
      <link>https://stats.stackexchange.com/questions/660096/how-do-i-test-if-a-histogram-with-few-bins-is-obtained-from-a-normal-distributio</link>
      <description><![CDATA[假设我有一个直方图，显示已成功完成 $0, 1, 2, ..., n$ 门课程的学生人数。学生人数较多，但课程数量较少（例如 6 门）。我的零假设 $H_{0}$ 是学生的“能力”是一个具有正态分布的实数（均值和方差未知），学生完成的课程数量为 $\lfloor \text{aptitude} \rfloor$。如何检验备择假设 $H_{1}$“能力分布不正常”？我知道 Jarque-Bera、Lilliefors 或 Anderson-Darling 等正态性检验，但据我所知，它们假设离散化细化程度要高得多，即有更多的箱体，并且它们不包含任何限制假设（即，观测量的最大值和最小值是有限的，尽管底层随机变量不是）。我也在 Cross Validated 上看到了这个问题，其中一个答案建议使用卡方拟合优度检验，但据我所知，您需要指定正态分布的均值和方差才能使用卡方拟合优度检验，而我两者都没有。
附言。由于我发现在教育背景下提出这个问题会引发太多与统计本身无关的问题，因此假设我们讨论的是游戏中给予玩家的随机点数。玩家最多可以购买 $n$ 件物品，每件物品花费 $X$ 点，并且总是会购买尽可能多的物品。通过查看玩家购买的物品数量的分布，我们试图确定给予玩家的点数是否符合正态分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/660096/how-do-i-test-if-a-histogram-with-few-bins-is-obtained-from-a-normal-distributio</guid>
      <pubDate>Thu, 16 Jan 2025 12:31:45 GMT</pubDate>
    </item>
    <item>
      <title>排除构成数据结构一部分的相关变量，转而采用生物学上更有意义的变量</title>
      <link>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</link>
      <description><![CDATA[我正在处理从卫星图像 (Sentinel) 捕获的植被覆盖率数据集。数据以季度/季节为间隔捕获。使用 GAM，我正在模拟植被覆盖率如何响应环境变量，降雨量是感兴趣的关键预测变量。但是，降雨量与季度/季节具有合理的相关性，相关系数为 r = -0.73。通常，当两个变量的相关性大于 0.7 时，我会将其中一个排除在分析之外。所以，我的问题是，我可以从分析中排除季度/季节吗？
季度/季节是数据集设计/结构的一部分，通常我的理解是应该在模型中考虑数据结构。但是，从生物学角度来看，连续降雨变量是一个更有趣、更有意义的变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</guid>
      <pubDate>Thu, 16 Jan 2025 03:22:55 GMT</pubDate>
    </item>
    <item>
      <title>应该使用什么正确的测试来计算所需样本量（微生物水污染）？</title>
      <link>https://stats.stackexchange.com/questions/660015/what-would-be-the-correct-test-to-use-to-calculate-required-sample-size-microbi</link>
      <description><![CDATA[我提议进行一项实验，比较动物直接使用过的水样、暴露在空气中相同时间但被关在笼子里以避免动物直接使用的水样以及基线（实验开始时采集的样本）中微生物病原体的存在情况。我不确定计算所需样本量的适当方法是什么——希望试点数据可以表明效果大小，但目前我想考虑一个范围内的要求。假设动物饮用/洗澡时微生物污染最高。
取样将来自每种条件下的不同水碗；可能每种情况下两个，一次放出。我可以多次进行实验。我还不确定从每个碗中采集多个样本的利弊——了解这对样本量意味着什么会很有帮助。我知道这可以帮助理解水碗内的变化 + 可能更具代表性，但我需要考虑来自同一碗的样本之间的相关性？
我计划同时进行总活菌计数和目标病原体（沙门氏菌、假单胞菌、金黄色葡萄球菌）的二元存在/不存在。
最小功率应为 80%，alpha 误差 == 0.05。]]></description>
      <guid>https://stats.stackexchange.com/questions/660015/what-would-be-the-correct-test-to-use-to-calculate-required-sample-size-microbi</guid>
      <pubDate>Tue, 14 Jan 2025 16:23:02 GMT</pubDate>
    </item>
    <item>
      <title>重复测量设计中评估基因-代谢物关系的指导</title>
      <link>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</guid>
      <pubDate>Mon, 13 Jan 2025 20:11:27 GMT</pubDate>
    </item>
    </channel>
</rss>