<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Mon, 10 Feb 2025 21:15:48 GMT</lastBuildDate>
    <item>
      <title>应用T-SNE时，您是否知道有此行为的数据集吗？</title>
      <link>https://stats.stackexchange.com/questions/661194/do-you-know-of-any-dataset-with-this-behavior-when-applying-t-sne</link>
      <description><![CDATA[    
嘿，伙计们！
我目前正在寻找一个数据集，该数据集在应用T-SNE时表现出此行为。 T-SNE是一种降低算法，有时可以分开最初属于同一群集的数据点。
在本文的图9中（ https://arxiv.org/abs/2009.01512 ） ，您可以完全看到这种现象。作者提出了一种拓扑维度降低算法（TOPOMAP），该算法使簇保持完整，并将其与T-SNE进行比较。很明显，T-SNE最终分开应该保留在一个群集中的点。
您曾经遇到过这种现象吗？如果是这样，您可以共享数据集及其上下文吗？我正在研究一个本科研究项目，并非常感谢任何帮助。
谢谢您的时间和关注！]]></description>
      <guid>https://stats.stackexchange.com/questions/661194/do-you-know-of-any-dataset-with-this-behavior-when-applying-t-sne</guid>
      <pubDate>Mon, 10 Feb 2025 20:33:58 GMT</pubDate>
    </item>
    <item>
      <title>在这种简单的语言建模情况下，数学概率如何出现？</title>
      <link>https://stats.stackexchange.com/questions/661193/how-does-the-log-probabilities-mathematically-appear-in-this-simple-case-of-lang</link>
      <description><![CDATA[在（又名 word2vec ），说明：
    
一个人如何得出这个公式？如果一个人遍历每个word  $ \ pm c $  words; （即使用单词和周围。）并计算与周围单词发生的单词的关节概率，可以写：
  \ begin {align}
\ prod_ {-c \ leq j \ leq c，j \ neq 0} p（w_ {i+j} | w_i）
\ end {align}  
，总而言之，我们添加了所有单词
  \ begin {align}
1 = \ sum_ {i = 0} \ prod_ {-c \ leq j \ leq c，j \ neq 0} p（w_ {i+j} | w_i）
\ end {align}  
用日志概率替换，因为 $ p（i）$ 总是大于 $ \ log p（ i）它的$ ，为负；然后我们可以说：
  \ begin {align}
0 \ geq \ sum_ {i = 0} \ sum_ {-c \ leq j \ leq c，j \ neq 0} \ log p（w_ {i+j} | w_i）
\ end {align}  
人们想最大化这一点是有道理的。但是我不确定这种推理是正确的，还是背后有不同的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/661193/how-does-the-log-probabilities-mathematically-appear-in-this-simple-case-of-lang</guid>
      <pubDate>Mon, 10 Feb 2025 20:16:48 GMT</pubDate>
    </item>
    <item>
      <title>使用HyperOPT FMIN进行LightGBM超参数调整</title>
      <link>https://stats.stackexchange.com/questions/661191/lightgbm-hyperparameter-tuning-using-hyperopt-fmin</link>
      <description><![CDATA[我正在遇到一个多分类问题。我正在尝试使用HyperOPT FMIN执行超参数调整。但是，我不知道我应该在搜索空间中使用什么合适的值，以及我应该如何解决此问题。我是否先执行随机搜索，然后在该区域进行搜索？每个搜索空间的价值应该是什么？我的数据集为6000行，我有大约200个变量（如果执行一个热编码，则为400个）。我的目标变量有4个级别
 来自sklearn.model_selection导入随机搜索
导入numpy作为NP
从HyperOPT Import Fmin，TPE，HP，status_ok，试验
导入LightGBM作为LGB
来自sklearn.model_selection导入train_test_split
来自Sklearn.metrics导入精度_score
从hyperopt.pyll.base导入范围

＃定义随机搜索的参数分布
param_dist = {
    &#39;num_leaves&#39;：范围（20，150），
    &#39;Learning_rate&#39;：np.linspace（0.01，0.3，10），
    &#39;n_estimators&#39;：范围（100，1000，100），
    &#39;min_child_weight&#39;：np.linspace（0.01，10，10），
    “子样本”：np.linspace（0.5，1.0，6），
    &#39;colsample_bytree&#39;：np.linspace（0.5，1.0，6），
    &#39;reg_alpha&#39;：np.linspace（0.0，1.0，10），
    &#39;reg_lambda&#39;：np.linspace（0.0、1.0、10）
}

＃创建LightGBM分类器
model = lgb.lgbmclassifier（objective =&#39;多类&#39;，num_class = len（set（y）））

＃执行随机搜索
Random_search = RandomizedSearchCV（
    估算器=模型，
    param_distributions = param_dist，
    n_iter = 20，＃采样的参数设置数量
    评分=&#39;准确性&#39;，
    CV = 3，＃交叉验证分裂策略
    Random_State = 42，
    n_jobs = -1＃使用所有可用内核
）

＃适合随机搜索
Random_search.fit（x_train，y_train）

＃获取最佳参数
best_params = Random_search.best_params_
打印（使用随机搜索搜索发现的最佳超参数：＆quot; best_params）

＃定义围绕最佳参数的搜索空间
search_space = {
    &#39;num_leaves&#39;：scope.int（hp.quniform（&#39;num_leaves&#39;，best_params [&#39;num_leaves&#39;]  -  10，best_params [&#39;num_leaves&#39;] + 10，1），），），），），
    &#39;Learning_rate&#39;：hp.Uniform（&#39;Learning_rate&#39;，best_params [&#39;Learning_rate&#39;] * 0.8，best_params [&#39;Learning_rate&#39;] * 1.2）， * 1.2），
    &#39;n_estimators&#39;：scope.int（hp.quuniform（&#39;n_estimators&#39;，best_params [&#39;n_estimators&#39;]  -  100，best_params [&#39;n_estimators&#39;] + 100，10），），
    &#39;min_child_weight&#39;：hp.ribour（&#39;min_child_weight&#39;，best_params [&#39;min_child_weight&#39;] * 0.8，best_params [&#39;min_child_weight&#39;] * 1.2），
    &#39;subsample&#39;：hp. rustom（&#39;subsample&#39;，max（0.5，best_params [&#39;subsampe&#39;] * 0.8），min（1.0，best_params [&#39;subsampe&#39;] * 1.2）），），），
    &#39;colsample_bytree&#39;：hp.uliform（&#39;colsample_bytree&#39;，max（0.5，best_params [&#39;colsample_bytree&#39;] * 0.8），min（1.0，best_params [&#39;colsample_bytree&#39;] * 1.2），），
    &#39;reg_alpha&#39;：hp.riborm（&#39;reg_alpha&#39;，best_params [&#39;reg_alpha&#39;] * 0.8，best_params [&#39;reg_alpha&#39;] * 1.2），
    &#39;reg_lambda&#39;：hp.Uniform（&#39;reg_lambda&#39;，best_params [&#39;reg_lambda&#39;] * 0.8，best_params [&#39;reg_lambda&#39;] * 1.2）
}

＃定义目标功能
DEF目标（参数）：
    型号= lgb.lgbmclassifier（objective =&#39;多类&#39;，num_class = len（set（y_train）），** params）
    得分= cross_val_score（型号，x_train，y_train，cv = 3，评分=&#39;cercucy&#39;）。平均（）
    返回{&#39;损失&#39;：-score，&#39;状态&#39;：status_ok}

＃运行优化
试验=试验（）
best_hyperparams = fmin（fn =客观，
                        space = search_space，
                        algo = tpe.suggest，
                        max_evals = 50，＃根据您的需求调整评估次数
                        试验=试验，
                        rstate = np.random.default_rng（42））

打印（“使用Hyperopt的最佳超参数：＆quot”，best_hyperparams）
``
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661191/lightgbm-hyperparameter-tuning-using-hyperopt-fmin</guid>
      <pubDate>Mon, 10 Feb 2025 19:47:00 GMT</pubDate>
    </item>
    <item>
      <title>分析分位数残差分析回归拟合</title>
      <link>https://stats.stackexchange.com/questions/661190/analysing-regression-fit-with-quantile-residual</link>
      <description><![CDATA[我是指基于估计的 Quantile Restuals  分析回归方程的拟合的论文。
  http://www.statsci.orgg y&gt;  
替代链接：
  nofollow noreferrer“&gt; https://www.researchgate.net/publiation/publiation __net/publiation/2647151 
在第3节中指出，
  如果正确指定了回归参数/方程，分数残差的分布会收敛到标准正态分布。   
以下是其定义的快照
    
然而，鉴于分数残差基于正常分布的逆CDF ”容器“&gt; $ f $ ，不是估计量化残差 始终 be    正态分布至关重要的如果回归方程的响应变量是连续的，无论是否正确指定了回归方程？
任何见解都会非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/661190/analysing-regression-fit-with-quantile-residual</guid>
      <pubDate>Mon, 10 Feb 2025 19:24:06 GMT</pubDate>
    </item>
    <item>
      <title>为不同的交互拟合单独的LMM</title>
      <link>https://stats.stackexchange.com/questions/661189/fitting-separate-lmms-for-different-interactions</link>
      <description><![CDATA[我使用线性混合模型（LMM）分析了主要临床范围（DV）的主要临床量表的纵向变化。我的完整模型包括：
  dv〜time ∗因子1 ∗因子2+协变量+（1 riD）
 
其中：
  dv =抑郁症状的临床量表，
时间=重复测量点，
因子1 =一个分类变量区分两个亚组（条件1 vs条件2），
因子2 =与临床特征相关的二元分类（Group1 vs Group2），
id =对个别参与者的随机效果。
 
三向相互作用时间：factor1：factor2 很重要。
为了更好地了解每个因素的贡献，我分别拟合三个LMM，每个LMM都对不同的相互作用进行建模：
 基线模型：
  dv〜time+协变量+（1月）
 
  factor1相互作用的模型：
  dv〜time ∗因子1+协变量+（1月ID）
 
  factor2相互作用的模型：
  dv〜time ∗因子2+协变量+（1月ID）
 
考虑到完整模型中的三向相互作用很重要，这种方法是否过于普遍？
具体来说，运行单独的模型是否会过分简化解释？
是否有更好的方法可以在保留完整的模型结构的同时分解重要的三向相互作用？
对解释LMM中三向互动的最佳实践的任何见解将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661189/fitting-separate-lmms-for-different-interactions</guid>
      <pubDate>Mon, 10 Feb 2025 19:20:04 GMT</pubDate>
    </item>
    <item>
      <title>GLMM（LME4包）中极低的R²m，无线性趋势怀疑</title>
      <link>https://stats.stackexchange.com/questions/661188/extremely-low-r%c2%b2m-in-glmm-lme4-package-with-a-non-linear-trend-suspected</link>
      <description><![CDATA[上下文和数据集：
我正在使用LME4软件包的GLMER功能的广义线性混合模型（GLMM）来建模“ Mean_cover_of_aquatic_plants”随着时间的流逝（时间=年度抽样，有37年的样本）在人造湖泊中。
响应变量是Mean_cover_of_aquatic_plant，它是一个百分比值，是通过将所有水生植物在同一湖中不同子图中的封面进行求和，然后除以子图的数量。解释性变量是年份，随机效应是katervervation_site（即不同的保护_ site之间的可变性）。
   
型号设置：
  glmer（mean_cover_of_aquatic_plants〜Time +（1 | kedervation_site），family = gaussian（link =＆quos; log＆quot; log＆quot; log＆quot; data = lake_data）
 
我正在使用高斯家族使用日志链接函数，因为我怀疑时间和均值_cover_of_aquatic_plants之间的非线性关系。
 问题： 
r²m（边际R²）值极低，结果始终低于0.001。
  print（r2_values）
             R2M R2C
[1，] 0.001076443 0.2087605
 
我怀疑低R²m表示该模型没有捕获预期趋势，即使我应用了日志变换来处理数据中可疑的非线性（ logistic ？）。或者，即使在同一年之内的变异性如此之高，以至于导致此输出？
我已经检查了模型拟合，探索了替代的随机效应结构（例如随机斜率），并确保对数链接适用于对非线性趋势进行建模。
我已经考虑了模型中的过度分散，但这似乎不是一个问题。
我已经测试了其他潜在的解释变量，但时间是我分析中感兴趣的主要因素。
    ]]></description>
      <guid>https://stats.stackexchange.com/questions/661188/extremely-low-r%c2%b2m-in-glmm-lme4-package-with-a-non-linear-trend-suspected</guid>
      <pubDate>Mon, 10 Feb 2025 19:18:13 GMT</pubDate>
    </item>
    <item>
      <title>将数据集分为培训和测试集方法</title>
      <link>https://stats.stackexchange.com/questions/661187/split-a-dataset-into-training-and-testset-method</link>
      <description><![CDATA[我创建了一个用于培训神经网络的二进制分类问题的数据集。培训数据来自与特定环境（例如2D地图环境）有关的集合。对于测试案例，我考虑了来自同一2D地图的数据点，但培训集中不存在数据点。
这将是有效的测试用例设计？
任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/661187/split-a-dataset-into-training-and-testset-method</guid>
      <pubDate>Mon, 10 Feb 2025 19:17:01 GMT</pubDate>
    </item>
    <item>
      <title>如何解释队列研究中置信区间宽度的差异和无与伦比的病例对照研究？</title>
      <link>https://stats.stackexchange.com/questions/661186/how-to-explain-the-difference-in-the-width-of-confidence-interval-in-cohort-stud</link>
      <description><![CDATA[ i有一项队列研究的数据，我称之为研究1。在这项研究中，死亡是结果，糖尿病（存在或不存在）是暴露，年龄和性别是协变量。我使用的回归公式是：
 死亡〜糖尿病 +性别 +年龄，家庭=二项式（link =; logit; quot;
接下来，我从队列研究中选择了所有病例（死亡），然后选择了相等数量的对照组，创建了我称为研究2的无与伦比的病例对照研究。对于研究2，我使用了相同的回归模型如研究1。
研究1和研究2的所有系数（糖尿病，性别和年龄）的估计非常相似，除了拦截。但是，研究2中系数的置信区间（CI）比研究1中的系数宽。如何使用数学公式来解释这种差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/661186/how-to-explain-the-difference-in-the-width-of-confidence-interval-in-cohort-stud</guid>
      <pubDate>Mon, 10 Feb 2025 19:10:11 GMT</pubDate>
    </item>
    <item>
      <title>拉普拉斯分布的后部带有拉普拉斯先验</title>
      <link>https://stats.stackexchange.com/questions/661183/posterior-of-a-laplace-distribution-with-a-laplace-prior</link>
      <description><![CDATA[我正在练习我的研究生统计课程中的一些概念，并试图得出平方损耗函数的贝叶斯规则 $ l（\ theta，a）=（\ theta-a） ^2 $ 。我有一个带有位置参数 $ \ theta $ 和单位刻度（即 $ x \ sim \ sim \ text {laplace} { （\ theta，1）$ ）和可能性 $ f（x; \ theta）= \ frac {\ exp \ \ exp \ { -  \ sum_ {i = 1}^n | x_i- \ theta | \}}} {2^n} $ 。此外，我有一个laplace先验，位于位置 $ \ eta $ 和单位刻度，即 $ \ pi_ \ theta（\ theta） = \ frac {\ exp \ { -  | \ theta- \ eta | \}}} {2} $ 。
首先，我不完全确定该计算的方法，但我从衍生后验，如下所示：
 $$ \ pi _ {\ theta | x}（\ theta | x）\ propto \ exp \ exp \ big \ big \ { -  \ sum_ {i = 1}^n | x_i--- \ \ theta | -  | \ theta- \ eta | \ big \} $$ 
但是我不知道如何简化我的表达。如果它们都是正常的分布，我知道要完成正方形，并用 $ \ theta $ 来写出我的表达。但是，在这种情况下，我对模量标志感到困惑。我以前从未使用过拉普拉斯（Laplace）发行版，因此对任何帮助都将不胜感激。谢谢！
编辑：要回答贝叶斯规则的问题，我认为我必须找到一个 $ a $ 才能最小化
 $$ \ MATHBB {e} [l（\ theta，a）| x = x] \ propto \ int \ int _ { -  \ infty}^\ infty（\ theta-a）^2 \ exp \ big \ { -  \ sum_ {i = 1}^n | x_i- \ theta |  -  | \ theta- \ eTa | \ big \} d \ theta $$  
但是，如果没有更多有关我的后部的信息，这变得很困难。]]></description>
      <guid>https://stats.stackexchange.com/questions/661183/posterior-of-a-laplace-distribution-with-a-laplace-prior</guid>
      <pubDate>Mon, 10 Feb 2025 16:30:10 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon签名的等级测试是否精确分布（排列）仍然非参数？计算确切的区域时如何处理关系？</title>
      <link>https://stats.stackexchange.com/questions/661182/is-a-wilcoxon-signed-rank-test-with-exact-distribution-permutation-still-nonpa</link>
      <description><![CDATA[
 首先，我想知道Wilcoxon签名的等级测试是否具有精确分布（排列）仍然非参数？

 对于排列，我只考虑了样本中的联系。但这很可能歪曲了。我觉得我必须考虑样本中的所有可能联系方式n = 10。

 我也想知道如何计算不均匀n的排列。目前，我在排列中只获得了1：5，因为它考虑了W+的所有变化（正等级的总和）。对于n = 9，我需要服用4.5（数字不均）。


我想知道这些问题通常是如何解决的，或者我是否完全以计算分销的方式完全消失了
数据：
  x11＆lt;  -  c（12、15、10、10、13、10、12、12、17、10、19）
x21＆lt;  -  c（10、14、12、9、11、15、17、16、13、18）

＃计算差异
差异＆lt;  -  x11 -x21

等级＆lt;  - 等级（ABS（差异））  

排列＆lt;  -  permn（排名）

list1＆lt;  -  lapply（排列，函数（x）x [1：5]）

w＆lt;  -  sapply（list1，sum）

＃分配：
排序
ranksums_freq＆lt;  -  sapply（ranksums，function（x）sum（w == x））/长度（置换）
``
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661182/is-a-wilcoxon-signed-rank-test-with-exact-distribution-permutation-still-nonpa</guid>
      <pubDate>Mon, 10 Feb 2025 16:07:49 GMT</pubDate>
    </item>
    <item>
      <title>分层的COX模型：为什么经过乐观校正的要大于明显的C索引（Tidymodels和审查的R包）？</title>
      <link>https://stats.stackexchange.com/questions/661185/stratified-cox-model-why-is-optimism-corrected-greater-than-apparent-c-index-t</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661185/stratified-cox-model-why-is-optimism-corrected-greater-than-apparent-c-index-t</guid>
      <pubDate>Mon, 10 Feb 2025 07:53:22 GMT</pubDate>
    </item>
    <item>
      <title>如果一个（联合国）有意忽略所有可用数据的10％，那么最高准确性是多少？</title>
      <link>https://stats.stackexchange.com/questions/661168/if-one-unintentionally-ignores-10-of-all-available-data-what-is-the-highest</link>
      <description><![CDATA[我不记得场地，但我相信是一位语言学家，他认为，如果人们忽略了10％或15％的数据，那么从一个人专心考虑的85％的数据中就不会得出任何有意义的结论。 
在统计学方面，会发生这种情况还是取决于人口遵循的分布？？]]></description>
      <guid>https://stats.stackexchange.com/questions/661168/if-one-unintentionally-ignores-10-of-all-available-data-what-is-the-highest</guid>
      <pubDate>Mon, 10 Feb 2025 05:55:22 GMT</pubDate>
    </item>
    <item>
      <title>阅读部分依赖/条件期望图</title>
      <link>https://stats.stackexchange.com/questions/661167/reading-partial-dependence-conditional-expectation-plots</link>
      <description><![CDATA[我制作了以下图：  
我尚未完成，但请专注于第一行。 Y轴是我计算的条件期望（请参阅底部的代码），这是 $ [0,1] $ 的概率，而X轴是我的自变量（区域）。我对我的情节有些困惑，所有期望都显着高于 $ 0.5 $ ，我认为我会获得比没有更多的正值，但是这些都应该是少数群体。我使用smote使它们成为 $ 50/50 $ 余额，但我仍然认为有条件的期望不应该那么高，尤其是因为我的模型表现良好。 
以下是我的蒙特卡洛集成，以进行有条件的期望。
  def calculate_partial_dependence（model，x，features_index，grid_resolution = 100，sample_num = 20000）：
    “”
    计算功能对模型预测的部分依赖性。

    参数：
     - 型号：模型
    -X：数据集
    -Features_Index：为其计算部分依赖性的功能的索引。
    -grid_resolution：该功能网格中的点数。
    -sample_num：网格中每个点的均匀绘制数量

    返回：
     -  feature_values：计算部分依赖的特征的值。
    -pd_values：部分依赖值。
    “”

    #min and Maxes    
    f = x [：，feature_index]
    x_deleted = np.delete（x，feature_index，axis = 1）

    a = np.min（f）
    b = np.max（f）
    值= np.linspace（start = a，
                    停止= b，
                    num = grid_resolution）
    期望= np.seros_like（values）

    kde = kerneldents（）
    如果x_deleted.shape [1]！= 0：
        对于IDX，枚举（值）中的条件：
            #find附近的X，然后计算“条件ish”密度，因为我们没有足够的值来实现实际条件密度
            XL = 0
            Q = 5
            xl＆lt; = 10：
                R =（条件-Q*（B-A）/GRID_RESOLUTION，条件 + Q*（B-A）/GRID_RESOLITY）
                #filter指数r
                x_temp = x_deleted [（f＆gt; = r [0]）＆amp; （f＆lt; = r [1]），：]
                xl = x_temp.shape [0]
                Q += 1

            #Generate样本分布
            generator = kde.fit（x_temp）.sample（sample_num）
            col = np.ones（（Sample_num，1））*条件
            sample = np.insert（Generator，fentrator_index，np.full（xl，cond），axis = 1）

            #Predict tagrip概率
            output = model.predict_proba（示例）[：，1]
            
            自从蒙特卡洛以来 
            期望[idx] = np.mean（输出）

    别的： 
        ＃NULL模型只有一个变量，因此我不需要``条件&#39;&#39;
        期望= model.predict_proba（values）[：，1]
    返回值，期望

 
我在这里误会了什么吗？我也尝试了像Sklearn这样的普通图书馆，以达到有条件的期望，他们给了我相同的答案。我的模型是腥的，还是我不明白我在看什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/661167/reading-partial-dependence-conditional-expectation-plots</guid>
      <pubDate>Mon, 10 Feb 2025 03:12:27 GMT</pubDate>
    </item>
    <item>
      <title>如何确定偏斜的引导分布的平均值和95％的置信区间[封闭]</title>
      <link>https://stats.stackexchange.com/questions/661165/how-to-determine-the-mean-and-95-confidence-interval-of-a-skewed-bootstrapped-d</link>
      <description><![CDATA[我已经引导了我的数据1000（甚至是10,000），但是此引导分布偏斜，因此真实的组平均值与分布的模式更为一致，而不是平均值。。
在忠于真实群体的含义的同时，如何报告平均值和CI？我可以报告模式吗？
下面的编辑以具体示例阐明我的确切方法：
我正在使用线性SVM在两个变量（来自脑电图数据）之间解码。从20个受试者中，我有一个来自每个条件的解码精度迹线。在这里，解码精度跟踪是每个时间点的％精度（例如，从0到1000ms）。我的目的是测试我可以及时解码的条件（A或B）。
统计测试1：首先，要测试解码精度是否超过了小组级别的机会（对于条件A＆amp; b，分别），我执行基于置换的群集大小的推断。简而言之，我通过将每个样本解码精度输出乘以+1或-1来生成无效分布（设置为50％的机会水平）来缩小样品标签。然后，确定最早的有意义的时间点（即开始时间）。
统计测试2：然后，要测试哪个条件（a或b）具有较早的发作时间，请通过随机进行替换来进行1000次引导数据集。这种方法背后的理由是在两个发病时间之间进行了强有力的统计比较。我不能直接使用发作时间来强烈主张两个条件之间的差异，因为它们是奇异的值，并且不反映基本的分布。参见Sassenhagen和Draschko，心理生理学。 2019; 56：e13335 。
因此，我用更换随机对20次进行样品，执行上述定义的统计测试，并保存第一个重要的时间点。重复此过程1000次后，我的发作时间分布（我计划从中得出平均自举的发作时间和置信区间）。
但是，第二个测试中的发作时间的分布并不正态分布，因此自举的发作时间的平均值与基于群集的置换测试的起始时间不符合。我应该期望在更清洁的数据中有正态分布吗？如果结果是真实的，我可以报告模式+/- CI，而不是均值+/- CI，以说明数据的偏差？
我希望这是有道理的。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661165/how-to-determine-the-mean-and-95-confidence-interval-of-a-skewed-bootstrapped-d</guid>
      <pubDate>Sun, 09 Feb 2025 21:35:46 GMT</pubDate>
    </item>
    <item>
      <title>具有固定效果的逻辑回归：预测的概率和边际影响</title>
      <link>https://stats.stackexchange.com/questions/661102/logistic-regression-with-fixed-effects-predicted-probability-and-marginal-effec</link>
      <description><![CDATA[我有 feglm 回归
在 
    lextreme）|因子（年），data = merged_data_final_dum， 
    family =二项式（link =＆quot; logit; quot;）））））     
 
由于这仅给我带来了赔率和优势比，所以我想计算预测的概率和边缘效应。
但是，这对我不起作用。我尝试了软件包 Margins 和 marginaleffects 。
我的朋友告诉我，不可能计算出PRE。概率。如果我有固定的效果，边缘效应。但是，我找不到任何在线解释的内容。
我在R中做错了吗？
计算P.P.是不可能甚至有用的。和M.E.？我真的很感谢您的帮助
我可以获得具有固定效果的逻辑回归模型的预测概率和边缘效应吗？
，如果是，我该如何在r？中进行]]></description>
      <guid>https://stats.stackexchange.com/questions/661102/logistic-regression-with-fixed-effects-predicted-probability-and-marginal-effec</guid>
      <pubDate>Fri, 07 Feb 2025 17:01:07 GMT</pubDate>
    </item>
    </channel>
</rss>