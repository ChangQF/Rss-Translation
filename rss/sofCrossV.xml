<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 08 Mar 2025 06:20:08 GMT</lastBuildDate>
    <item>
      <title>2个不等大小的样品的分布测试</title>
      <link>https://stats.stackexchange.com/questions/662336/distribution-testing-for-2-samples-with-unequal-sizes</link>
      <description><![CDATA[说我有两个示例 $ n $ 和另一个大小 $ m $ ，我不知道每个样本的先验分布，但想知道是否从相同的分布中绘制样品（即是否试图检测概念draind drave drail）。每个示例中的每个数据点均为 $ d $ 尺寸。为了测试分布平等，我可以使用具有一定校正（Bonferroni）的Kolmogorov-Smirnov或使用2样本内核测试（具有最大平均差异）。
我想知道，如果 $ n $ 比 $ m $ （但是 $ m $ 仍然非常大） class =“ Math-Container”&gt; $ n = 20000 $ 。测试技术（我上面提到的确切条件）是否仍然存在？
如果没有，那我该怎么办？如果有已知技术，请随时向我指出资源。]]></description>
      <guid>https://stats.stackexchange.com/questions/662336/distribution-testing-for-2-samples-with-unequal-sizes</guid>
      <pubDate>Sat, 08 Mar 2025 00:34:51 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯过滤 - 为什么我们不能迭代地直接更新联合分布？为什么需要预测和更新步骤？</title>
      <link>https://stats.stackexchange.com/questions/662335/bayesian-filtering-why-cant-we-iteratively-update-the-joint-distribution-dire</link>
      <description><![CDATA[进行贝叶斯过滤时，我们有一个贝叶斯网络，因此：
  $$
p（x_ {0：t}）= p（x_0）\ prod_ {k = 1}^t p（x_k | x__ {k-1}）
$$ 
 $$
p（y_ {1：t} | x_ {0：t}）= \ prod_ {k = 1}^t p（y_ _ {k} | x_ {k {k}）
$$  
和
  $$
p（x_ {0：t}，y_ {1：t}）= p（y_ {1：t} | x_ {0：t}）p（x_ {0：t}）
$$  
给定
  $$
p（x_ {0：t+1}，y_ {1：t+1}）= p（x_0）p（x_ {t+1} | x_t）
$$  
如果我们有 $ p（x_ {0：t}，y_ {1：t}）$ ，为什么我们不能简单地计算 $ p（x__ {0：x_ {0：t+1}
  $$
p（x_ {0：t}，y_ {1：t}）p（x_ {t+1} | x_t）p（y_ {t+1} | x__ {t+1}）
$$  
因此，迭代地计算了一段时间的关节分布，而不是在每个时间步骤进行预测和更新步骤？
我知道，在过滤我们实际关心的分布时，是 $ p（x_ {t} | y_ {1：t}）$ ，但是如果我们忽略归一化常规化，这不应该等于关节分布吗？即。
  $$
p（x_ {0：t} | y_ {1：t}）\ propto p（y_ {1：t} | x_ {0：t}）p（x_ {0：t}）= p（x__ {0：t}，y__ ___ {1：t}）
$$  
我觉得我一定会缺少一些东西，所以如果有人可以指出它是什么，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662335/bayesian-filtering-why-cant-we-iteratively-update-the-joint-distribution-dire</guid>
      <pubDate>Sat, 08 Mar 2025 00:03:15 GMT</pubDate>
    </item>
    <item>
      <title>每组进行预测时是否需要归一化？</title>
      <link>https://stats.stackexchange.com/questions/662333/is-normalization-necessary-when-the-predictions-are-made-per-group</link>
      <description><![CDATA[作为ML的初学者，我正在YouTube上观看视频（ https://youtu.be/vyzmylgbsbm?si = d9dygpgxab8v6661v 
精明10）
关于在Spotify上设计歌曲建议模型。对于每个用户，都有关于推荐哪些歌曲的预测。
功能之一是历史参与数，例如视图/喜欢。
我不明白的是，面试官问，如果某些用户比其他用户比其他用户单击更多，因为他们通常更活跃，因为他们是点击器，他们点击了很多。并解释说，这就是为什么我们需要将点击标准化（例如，除以某些用户活动的总数）。
如果一个模型正在预测每个组，则预测是针对每个用户的歌曲。  那么您真的必须标准化吗？如果用户A有900个单击歌曲A和歌曲B的100次点击，而用户B有20个点击歌曲A，歌曲B的5次点击，则为歌曲C进行5次点击。归根结底，我们在每个用户之间决定不关心不同用户的歌曲。
，即使您要归一化，您也可以模拟歌曲A的用户为0.9，而歌曲B则为0.1，但用户B观看了3首歌曲，因此他的发行版本是0.6、0.2和0.2。。
标准化对您有何帮助？您仍然无法比较0.9和0.6。它们是每组最佳分数，但整个组仍然是无与伦比的。原始点击数与比率有何不同？
，但根据用户，就像原始数字一样，它可以获得最大的百分比。
所以我的意思是，当预测为每个组时，您需要正常化。您是否必须关心各组的比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/662333/is-normalization-necessary-when-the-predictions-are-made-per-group</guid>
      <pubDate>Fri, 07 Mar 2025 23:14:59 GMT</pubDate>
    </item>
    <item>
      <title>绘制测试统计量与其相应的PVALUE</title>
      <link>https://stats.stackexchange.com/questions/662329/plotting-a-test-statistic-vs-their-corresponding-pvalues</link>
      <description><![CDATA[我想可视化特定测试的p值与其测试统计量的关系。该测试是“两次采样的未配对t检验，具有不平等的差异（welch的t检验）＆quot。
这样的数据，如果汇总40次左右，则可能出现：
  q = tstat_lst = [0.9660006171910432，
 0.7721621329351528，
 1.8100610634639722，
 -1.658160637924077，
 0.40426388807743174，
 -0.39322170596362177，
 -0.10057948819452832，
 -0.184443124516603937，
 0.12476123296525302，
 0.15156528516797133，
 -0.09564454667893868，
 -0.3565764937019235，
 0.6296035952012742，
 0.41864142400724524，
 -0.2947978905804754，
 -2.0477391038941315，
 0.6516953409964041，
 -0.10427275892823629，
 -0.383987967078378，
 0.49301579010836505，
 0.34309883856311163，
 -0.555996825678678，
 -0.9614457089082035，
 -0.4307174435897561，
 -0.2402370244487562，
 2.7217356150809198，
 -0.017687813740055347，
 0.37063599036565176，
 -1.433975290423805，
 -2.3163482190361595，
 0.527195768444428，
 1.0793544390271224，
 1.3726447186789736，
 2.1823987824609015，
 -1.886371488297514，
 -0.3327480340089581，
 -0.845831028027378，
 0.14159397099600338，
 1.770628236732337，
 -0.7129657016096798]

a = pvals_lst = [0.3351428270482858，
 0.44086256073619356，
 0.07167660898253647，
 0.09875110470687849，
 0.6864215472089106，
 0.6945485673825906，
 0.9199788061143731，
 0.8538488639722835，
 0.9008289373935419，
 0.8796716928044668，
 0.9238915619509784，
 0.7217575250663029，
 0.5296193782796346，
 0.6758955006039，
 0.7684339395166478，
 0.04185437874159891，
 0.51530430232936，
 0.9170562755796249，
 0.7013651604121057，
 0.6225036851619269，
 0.7318582035931929，
 0.5787900268922169，
 0.3374373699051052，
 0.6671072554315649，
 0.8103783128508254，
 0.007040388064127454，
 0.9859042929350978，
 0.7112719001389117，
 0.15302591592384204，
 0.021480204407496793，
 0.5986165798143437，
 0.2816495551645849，
 0.17128927509245642，
 0.030158422398817143，
 0.06060294356030884，
 0.7396484229164317，
 0.39859184655628466，
 0.8875327037601481，
 0.0780364091452371，
 0.4766433668999457]
 
是否有一个通用图？]]></description>
      <guid>https://stats.stackexchange.com/questions/662329/plotting-a-test-statistic-vs-their-corresponding-pvalues</guid>
      <pubDate>Fri, 07 Mar 2025 21:35:51 GMT</pubDate>
    </item>
    <item>
      <title>哪个更好 -  FDR或Holm -Bonferroni？</title>
      <link>https://stats.stackexchange.com/questions/662328/which-is-better-fdr-or-holm-bonferroni</link>
      <description><![CDATA[我正在用猴子进行听觉侧翼任务。它是一个受试者内部设计，有4个（6个）受试者，有4个条件。我想在运行单向RM ANOVA后进行成对比较。 Bonferroni被证明是非常保守的。我看着替代方案，罗姆和霍尔姆出现了。两者都给出不同的结果。哪一个对我的数据集更好？是否有一个在认知心理学中比其他人更好地接受的？]]></description>
      <guid>https://stats.stackexchange.com/questions/662328/which-is-better-fdr-or-holm-bonferroni</guid>
      <pubDate>Fri, 07 Mar 2025 21:18:20 GMT</pubDate>
    </item>
    <item>
      <title>对称与不对称分布的引导程序</title>
      <link>https://stats.stackexchange.com/questions/662327/bootstrap-for-symmetric-vs-asymmetric-distributions</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662327/bootstrap-for-symmetric-vs-asymmetric-distributions</guid>
      <pubDate>Fri, 07 Mar 2025 21:04:15 GMT</pubDate>
    </item>
    <item>
      <title>什么是研究报告中的SD，SE和覆盖概率？</title>
      <link>https://stats.stackexchange.com/questions/662326/what-is-sd-se-and-coverage-probability-in-research-report</link>
      <description><![CDATA[当我阅读论文时，在模拟研究中，我经常看到它们报告的表与以下相似的表格   
我认为

估计值是2000年以上的平均模拟运行
 SD是估算的标准偏差 $ \ beta_1 $ 在2000模拟中运行
他们没有报告偏见，但是在其他报道偏见的论文中，我认为这是根据2000年模拟的平均估计与真相之间的差异来计算的。

我不确定在这种情况下是什么标准错误以及如何计算。
同样，我想知道如何计算覆盖范围。我的猜测是 - 在每个模拟运行中，计算一个置信区间，我们存储了真相是否在置信区间，然后我们计算了2000年模拟中真相的比例。 
也许这是非常标准的知识，这就是为什么论文通常省略了有关如何计算这些数量的描述，我还在寻找任何有助于解释的教科书。]]></description>
      <guid>https://stats.stackexchange.com/questions/662326/what-is-sd-se-and-coverage-probability-in-research-report</guid>
      <pubDate>Fri, 07 Mar 2025 19:23:41 GMT</pubDate>
    </item>
    <item>
      <title>初学者：确定数据组是否在统计上相似</title>
      <link>https://stats.stackexchange.com/questions/662323/beginner-determining-whether-data-groups-are-statistically-similar</link>
      <description><![CDATA[我是统计数据的新手，并且具有岩石孔隙率的数据集1）使用三种不同的方法，2）来自两种不同的岩石类型。我正在尝试评估1）三种方法是否产生可比的结果，2）如果两种岩石类型在统计上相似。
这三种方法的数据如下（单位=％）：
  method_a = [17.6，19.3，18.7，28.0，25.8，17.1，18.5]
method_b = [17.6，17.0，18.3，11.1，12.5，16.6，15.3，8.4，15.8，14.9，11.6，9.0，9.0，6.4，9.6]
method_c = [11.1、10.9、9.7、7.8、0.9、11.2、11.0、12.5、14.0、8.3、9.9、9.9、6.9、6.9、8.4、0.4、0.9、0.8]
 
通过岩石类型分离的方法A和B的数据如下（方法C是故意的）：
  rock_a = [17.6，19.3，18.7，28.0，25.8，17.6，17.0，18.3，11.1，12.5，16.6，15.3]）
rock_b = [17.1，18.5，8.4，15.8，14.9，11.6，9.0，6.4，9.6））
 
 基于此数据，我应该使用哪些测试来确定这些组在统计上是相似的还是不同的？ 
我以为这是不正确的，但是要了解我的头部的位置，这是我第一次通过的事情：

我使用shapiro-wilk测试来评估每组的正态性。
我使用莱文的测试评估群体之间的差异同质性。
对于方法，我使用了Kruskal-Wallis检验，因为仅方法B是正态分布的。但是，所有组都基于上述测试都具有相似的差异。
对于岩石类型，我使用了学生的t检验，因为两者都是正态分布的，并且基于上述测试具有相似的差异

任何帮助将不胜感激。外行语言是首选，但行话也可以，因为我会尽力研究和理解所有建议。
编辑：添加了代码示例以使数据更可读。]]></description>
      <guid>https://stats.stackexchange.com/questions/662323/beginner-determining-whether-data-groups-are-statistically-similar</guid>
      <pubDate>Fri, 07 Mar 2025 17:18:30 GMT</pubDate>
    </item>
    <item>
      <title>热情的多元数据集中的变量选择</title>
      <link>https://stats.stackexchange.com/questions/662322/variable-selection-in-higly-multivariate-dataset</link>
      <description><![CDATA[ i具有超过200万特征的宏基因组学数据集（每个都是基因家族的相对丰度，这是基因序列的簇） 。首先，我将数据集转化为CLR。现在，我想通过执行某种变量选择来减少矩阵大小。
这样做的目的是删除那些不影响样本差异的变量，因为我稍后将使用多摩学方法来搜索宏基因组学与其他OMIC数据之间的关联。我想保留一部分相关特征，如果它们仅在样品之间是变量（并且研究为什么，它们仅是嘈杂的，或者是其他生物学原因）或治疗之间的。
但是，我不确定要遵循的最优势的变量选择程序。到目前为止，我尝试了r。中的几种策略

  pca ：我试图通过为两个第一个组件的PCA中的负载来选择变量。但是，这些组件不能解释很多方差（10和5％），并且最大载荷的绝对值为0.003，在两个组件中最大值。
 gf_pca＆lt;  -  prcomp（clrmatrix） 
  umap ：我还尝试了这些功能，而对其功能有很好的了解。看来我无法通过这种方法查看变量的重要性。
 gf_umap＆lt;  -  umap（clrmatrix，n_neighbors = 10，metric =&#39;euclidean&#39;） 
 随机森林：我读到有关运行无监督随机森林的选择。它给了我一组可以使用的变量，但是我不知道该如何检查模型是否足够好。
 gf_rforest＆lt;  -  Randomforest（x = clrmatrix，ntree = 5000，重要性= t，plot = f） 
 删除相关特征：我想直接计算所有相对丰度之间的相关矩阵，并删除高度相关的相关矩阵。但是，计算成本使我知道的方法变得不可能。
 corr_matrix＆lt;  -  cor（clrmatrix） 

 i也是关于使用样品的分类因素来进行某些监督的东西，因为我的样品分为两个分类因素：温度（3个水平）和养分量（两个水平）。为此，我可以使用：

 （s）PLS ：我以前使用此使用此的经验是该模型通常具有较低的Q2值。
 套索回归：使用我的治疗变量（温度和营养）与 y （尽管它们不是真正的响应变量）。
 随机森林：使用治疗变量（温度和营养）进行监督。

测试方法是否足够好，还是还有其他更好的选择？
在使用测试方法之一的情况下，我该如何解决遇到的问题？
使用分类因素信息并使用监督方法会更好吗？
事先感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/662322/variable-selection-in-higly-multivariate-dataset</guid>
      <pubDate>Fri, 07 Mar 2025 16:30:36 GMT</pubDate>
    </item>
    <item>
      <title>在GLMMTMBβ-二元模型中设置先验</title>
      <link>https://stats.stackexchange.com/questions/662294/setting-priors-in-a-glmmtmb-beta-binomial-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662294/setting-priors-in-a-glmmtmb-beta-binomial-model</guid>
      <pubDate>Thu, 06 Mar 2025 21:20:54 GMT</pubDate>
    </item>
    <item>
      <title>在部分相关分析中处理分类变量</title>
      <link>https://stats.stackexchange.com/questions/662090/handling-categorical-variables-in-partial-correlation-analysis</link>
      <description><![CDATA[我正在分析具有两个条件的实验的数据：野生型（WT）和突变基因型。每个基因型大约有25个样本。
对于每个样品，测量了〜15个基因和〜5代谢产物的表达。
目的是研究基因与代谢产物之间的关系，以及基因本身之间的关系。
但是，我注意到基因型之间的基因和代谢产物水平的主要差异。这意味着简单的相关分析将主要捕获基因型驱动的差异而不是真实的关联。
我遇到了部分相关（ ppcor :: pcor.test  in R），该在R）中计算两个变量之间的相关性，同时控制第三个变量（在这种情况下，基因型）。该方法可以应用于所有变量对，并在具有多测试校正的相关图中可视化。 Spearman的等级相关性（似乎是适当的选择）可以计算。
但是， ppcor 要求控制变量是数字的，而基因型为分类（WT/MUT）。
一种方法是将基因型编码为（0,1），但我不确定这种转换的含义。

 将基因型（WT，MUT）转换为（0,1）的统计后果是什么？？

 是否有任何有效性检查以确保此方法合适？

]]></description>
      <guid>https://stats.stackexchange.com/questions/662090/handling-categorical-variables-in-partial-correlation-analysis</guid>
      <pubDate>Mon, 03 Mar 2025 07:55:24 GMT</pubDate>
    </item>
    <item>
      <title>基于DAG的倾向评分加权（PSW）中应包括哪些变量？</title>
      <link>https://stats.stackexchange.com/questions/662047/which-variables-should-be-included-in-propensity-score-weighting-psw-based-on</link>
      <description><![CDATA[我正在执行倾向得分加权（PSW），并使用CDAG构建了我的因果假设（见下文）：

我的DAG中的灰色圆圈代表了实际的混杂因素，我
被确定为影响治疗和结果的变量； 
红色圆圈代表了我的其他临床重要变量
数据集; 
调解人，处理_apprace ，用蓝色描绘。

 我的问题：
计算加权的倾向得分时，应该是：

在PS模型中仅包括实际的混杂因子（灰色圆圈），评估这些变量的平衡，然后仅使用治疗和结果变量来计算因果效应估计？

 ＃ipw
w.out＆lt;  -  strigeit（治疗〜ASA + NOFMET + DEMASTGB + METDIAM + METLOC，data = df，estemand =&#39;ate&#39;ate&#39;ate&#39;aTe; cbps; cbps; cbps; link; link =;

＃评估余额 
bal.tab（w.out，stats = c（m＆quot; v; v＆quot; quot））

＃适合结果模型
fit＆lt; -glm_weightit（并发症〜处理，数据= DF，strighit = w.out）

＃治疗效果的G型
AVG_COMPARISON（fit，变量=“ Treats”）
 

在PS模型中包括DAG中描绘的所有变量（调解员除外），然后仅使用实际的混杂因素来估计我的感兴趣结果？

 ＃ipw
w.out＆lt;  -  strigeit（治疗〜性别 + bmi + age + comorb + stage + aSA + nofmet + decancegb + metdiam + metloc，data = df，estionand =&#39;ate&#39;ate;

＃评估余额 
bal.tab（w.out，stats = c（m＆quot; v; v＆quot; quot））

＃适合结果模型
fit＆lt;  -  glm_weightit（并发症〜处理 + asa + nofmet + decancegb + metdiam + metloc，data = df，weightit = w.out）

＃治疗效果的G型
AVG_COMPARISON（fit，变量=“ Treats”）
 

使用不同的选择标准将可变包含在PS加权中？

任何见解或参考都将不胜感激！
  &lt;img alt =“ cdag”]]></description>
      <guid>https://stats.stackexchange.com/questions/662047/which-variables-should-be-included-in-propensity-score-weighting-psw-based-on</guid>
      <pubDate>Sun, 02 Mar 2025 09:48:37 GMT</pubDate>
    </item>
    <item>
      <title>如何处理HLM Logistic回归中没有差异的群集</title>
      <link>https://stats.stackexchange.com/questions/661928/how-to-handle-clusters-that-have-no-variance-in-hlm-logistic-regression</link>
      <description><![CDATA[使用逻辑回归进行建模时，采用以下形式：
  $$
\ text {ln} \ frac {p（x）} {1- p（x）} = \ beta_0 + \ beta_1x_1 + \ dots + \ beta_px_p 
$$  
  $ p（x）$ 接近1或0获得正无穷大或负的无穷大。
使用HLM时，让我们定义一个随机截距：
  $$
\ text {ln} \ frac {p（x）} {1- p（x）} = \ beta_0+ u_j
$$  
  $ u_j $ 当某些簇只有所有1或0观察值（即没有差异）时，会发生什么？这些集群是否应该包括在模型中？它们是否导致 $ \ beta_0 $ ？
我在R中进行了一些模拟来调查
 库（dplyr）＃for数据框架操纵
图书馆（TIDYR）＃对于不努力的列表列
图书馆（LME4）＃for Glmer
J＆lt; -20 #number of clusters
n＆lt;  -  100 #number ob obs per cluster
set.seed（123）
sim.dat＆lt;  -  data.frame（id = as.factor（1：j），
           pi_cluster = rbeta（n，shape1 = 1，shape2 = 1））|＆gt;
  rowwise（）|＆gt; 
  突变（obs = list（rbinom（n，size = 1，prob = pi_cluster）））|＆gt; 
  Unnest（obs）


glmer（obs〜1 +（1 | id），data = sim.dat，
      family =“二项式”
＃＆gt;广义线性混合模型拟合最大似然（拉普拉斯
＃＆gt;   近似）[glmermod]
＃＆gt;  家庭：二项式（logit）
＃＆gt;公式：obs〜1 +（1 | id）
＃＆gt;    数据：sim.dat
＃＆gt;       AIC BIC LOGLIK偏差DF。 
＃＆gt; 13412.788 13427.208 -6704.394 13408.788 9998 
＃＆gt;随机效果：
＃＆gt;  组名称std.dev。
＃＆gt;  ID（截距）0.4617  
＃＆gt;观察数：10000，组：ID，20
＃＆gt;固定效果：
＃＆gt; （截距）  
＃＆gt;      -0.101

perfect_scores＆lt;  -  data.frame（id = as.factor（c（21,22）），obs = rep（1，n））

sim.dat_100 = persect_scores |＆gt;  ＃100％准确性
  bind_rows（sim.dat）

test＆lt; -glmer（obs〜1 +（1 | id），data = sim.dat_100，
      family =“二项式”
测试
＃＆gt;广义线性混合模型拟合最大似然（拉普拉斯
＃＆gt;   近似）[glmermod]
＃＆gt;  家庭：二项式（logit）
＃＆gt;公式：obs〜1 +（1 | id）
＃＆gt;    数据：SIM.DAT_100
＃＆gt;       AIC BIC LOGLIK偏差DF。 
＃＆gt; 13457.053 13471.494 -6726.527 13453.053 10098 
＃＆gt;随机效果：
＃＆gt;  组名称std.dev。
＃＆gt;  ID（截距）1.004   
＃＆gt;观察数：10100，组：ID，22
＃＆gt;固定效果：
＃＆gt; （截距）  
＃＆gt;      0.1791
头（ranef（test）$ id）
＃＆gt;    （截距）
＃＆gt; 21 2.69422960
＃＆gt; 22 2.69422960
＃＆gt; 1 0.27435351
＃＆gt; 2 0.07770447
＃＆gt; 3 0.35866584
＃＆gt; 4 -0.30482495
 
我们可以看到HLM中所有1s的簇具有非常大的随机效果。和 $ \ beta_0 $ 估计已向上拉。
在这个简单的示例中，我们只是随机拦截。如果我们有其他协变量，将包含所有1导致 $ \ beta_1，\ ldots，\ beta_p $ 更接近零的class =“ nath-container”&gt; $ \ beta_1，]]></description>
      <guid>https://stats.stackexchange.com/questions/661928/how-to-handle-clusters-that-have-no-variance-in-hlm-logistic-regression</guid>
      <pubDate>Thu, 27 Feb 2025 17:58:59 GMT</pubDate>
    </item>
    <item>
      <title>序数回归：z得分预测变量后的p值[封闭]</title>
      <link>https://stats.stackexchange.com/questions/661607/ordinal-regression-p-values-change-after-z-scoring-predictors</link>
      <description><![CDATA[使用标准线性回归，p值在z得分后不变，只有系数。但是，在我正在运行的序数回归模型中，预测变量的p值在某种程度上发生了变化（请注意，我仅z得分只有z得分，或者预测因素和序数结果都无关紧要）。。
结果有19个级别。
 没有z得分：
   z得分后：
  变量 Choroid_volume 具有范围 200-4000 ， tiv   1153852-1153852-1927779 范围。我测试了它是将这些变量缩放还是以零为中心的变量，以更改P值。
缩放它们，因此平均值为1不会影响脉络膜_volume，但确实会影响tiv（鉴于tiv太大，我并不感到惊讶，尽管缩放不会随线性回归而改变任何内容）。。
零中心更改两个变量的p值。关于序数回归是否有一些使变量分布的符号或中心相关的内容？因此，有理由是您不应该在序数回归中z得分吗？
缩放但不居中
这是缩放结果的结果，但不为病变evol_cubic，choroid_volume和tiv。
   choroid_volume和vol_cubic的p与原始数据相同（我现在相信tiv只会翻转，因为它的原始比例很大）。 Z得分后所有三个P值都会发生变化，这使我相信分布的中心很重要。为了娱乐，我尝试翻译分布不同的数量，并且每次都会改变。这与线性回归没有区别。]]></description>
      <guid>https://stats.stackexchange.com/questions/661607/ordinal-regression-p-values-change-after-z-scoring-predictors</guid>
      <pubDate>Wed, 19 Feb 2025 21:23:52 GMT</pubDate>
    </item>
    <item>
      <title>在多级潜在类别的远端结果中的3级聚类</title>
      <link>https://stats.stackexchange.com/questions/653039/3-level-clustering-in-multilevel-latent-class-analysis-of-distal-outcomes</link>
      <description><![CDATA[我正在研究基于PISA数据（横截面，连续的“远端结果”和班级的分类典型指标）的潜在学生体验（也在学校一级汇总）与学生成绩之间的关系。我打算使用多级潜在类别分析，以便可以在学生级别和学校层面上对关系进行建模。但是，我很担心，因为学生数据不仅嵌套在学校，而且还嵌套在国家（有60多个国家）。由于我对国家水平的效果不感兴趣，但只想考虑国家内的聚类，我是否有办法进行这种调整？我可以使用Mplus或R。您是否有建议，或者您会推荐任何资源，有人使用MLCA使用这样的3级聚类来预测远端结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/653039/3-level-clustering-in-multilevel-latent-class-analysis-of-distal-outcomes</guid>
      <pubDate>Tue, 20 Aug 2024 09:03:44 GMT</pubDate>
    </item>
    </channel>
</rss>