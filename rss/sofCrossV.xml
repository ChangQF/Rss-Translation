<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 09 Jul 2024 18:20:00 GMT</lastBuildDate>
    <item>
      <title>如何在 sommer R 包中正确指定嵌套？</title>
      <link>https://stats.stackexchange.com/questions/650758/how-do-i-correctly-specify-nesting-in-the-sommer-r-package</link>
      <description><![CDATA[我习惯于 lme4，它很简单：(1|genotype/root_ID)，但我通过查看文档不清楚在 sommer 中执行此操作的适当方法。
mod1 &lt;- mmer(Y ~ 1,
random= ~vsr(genotype,Gu=a) + genotype + genotype:root_ID,
rcov= ~units, nIters=10,
data=fold, verbose = FALSE, dateWarning=FALSE)
结果看起来很逼真，但我不完全确定这是否正确，并担心我会得到虚高的 CV 准确度...]]></description>
      <guid>https://stats.stackexchange.com/questions/650758/how-do-i-correctly-specify-nesting-in-the-sommer-r-package</guid>
      <pubDate>Tue, 09 Jul 2024 18:10:33 GMT</pubDate>
    </item>
    <item>
      <title>测试混合问题中多个比例的相等性</title>
      <link>https://stats.stackexchange.com/questions/650757/testing-equality-of-multiple-proportions-in-mixing-problems</link>
      <description><![CDATA[有两个湖泊 A（43000 立方英尺）和 B（30000 立方英尺）。一家工厂将废物倾倒到这两个湖泊中。测量结果显示三种污染物 a、b、c。
充满这些污染物的湖泊的百分比为：
湖泊 A：[%a(A)、%b(A)、%c(A)] = [8%、4%、2%]。这里的 8% 表示整个湖泊的 8% 由污染物 a 组成。
湖泊 B：[%a(B)、%b(B)、%c(B)] = [7%、5%、1.5%]。
我想检验三个比例相同的零假设，即 %a(A)=%a(B)、%b(A)=%b(B)、%c(A)=%c(B)。我需要一个统计数据来进行这个测试。
注意：测试必须是尺度不变的，这意味着如果我用立方英尺、立方英寸或立方米来测量湖泊，我都会得到相同的答案。常规卡方检验不具有尺度不变性。]]></description>
      <guid>https://stats.stackexchange.com/questions/650757/testing-equality-of-multiple-proportions-in-mixing-problems</guid>
      <pubDate>Tue, 09 Jul 2024 17:07:45 GMT</pubDate>
    </item>
    <item>
      <title>将模型 A 的输出作为训练数据输入到模型 B 中</title>
      <link>https://stats.stackexchange.com/questions/650755/output-from-model-a-as-training-data-into-model-b</link>
      <description><![CDATA[不确定这里是不是提出这个问题的合适地方，但我和同事在这个想法上意见不一。
假设我们有一个由“不干净”字符串组成的数据集。最终目标是拥有“干净”字符串。
现在假设有一个现有模型，称为模型 A。我们将所有“不干净”字符串传递到模型 A 中，并将结果称为“干净”数据。
接下来，如果我使用相同的“不干净”字符串作为输入来训练模型 B，并使用模型 A 的输出作为训练和验证数据，模型 B 是否会提供明显不同的结果？您能确定它的表现是否优于模型 A 吗？
关于目标的更多背景信息。当前项目目标是创建基于正则表达式的模型 A 的 ML 版本。我的理解是，如果我们使用模型 A 的输出来训练模型 B，它最多只能重现模型 A 的功能。
模型 A 的输出没有经过人工编辑，因此它实际上只是模型 A（正则表达式）进入模型 B（某种 ML 算法）。
以下是一些示例数据：
模型 A



输入字符串
输出字符串




发生了什么事？
发生了什么事？


你今天怎么样？
你好吗今天？


123 号主街
123 号主街


]]></description>
      <guid>https://stats.stackexchange.com/questions/650755/output-from-model-a-as-training-data-into-model-b</guid>
      <pubDate>Tue, 09 Jul 2024 16:48:33 GMT</pubDate>
    </item>
    <item>
      <title>Dickey-Fuller 检验统计显著性</title>
      <link>https://stats.stackexchange.com/questions/650752/dickey-fuller-test-statistical-significance</link>
      <description><![CDATA[我最近读到了关于 Dickey-Fuller 检验的文章。
首先，关于从
$$
y_t=\rho y_{t-1}+\epsilon_t
$$
到：
$$
y_t-y_{t-1}=(\rho-1) y_{t-1}+\epsilon_t
$$
我假设它是为了获得 $\delta=\rho -1$
的统计量，哪个更容易计算分布？
其次，据我所知，对 delta 进行的统计测试是片面的。为什么我们要忽略 rho 绝对值大于 1 的负值？]]></description>
      <guid>https://stats.stackexchange.com/questions/650752/dickey-fuller-test-statistical-significance</guid>
      <pubDate>Tue, 09 Jul 2024 16:21:22 GMT</pubDate>
    </item>
    <item>
      <title>使用哪种相关性检验</title>
      <link>https://stats.stackexchange.com/questions/650748/which-correlation-test-to-use</link>
      <description><![CDATA[我正在处理县级经济不平等和犯罪率的数据集，以生成相关矩阵。我的经济不平等数据有几个变量，即收入处于特定区间（0 到 9,999、10,000 到 14,999、15,000 到 35,000 等）的县人口百分比。这是连续的区间数据。我的犯罪率数据有几个变量，即不同的犯罪类型（谋杀、抢劫、福利欺诈等）。这些值是各县每种犯罪的犯罪率，通过将绝对犯罪计数除以人口计算得出。这些数据也是连续的区间数据。
我的犯罪率都严重偏右（大多数县的犯罪率较低；少数县的犯罪率较高）。我的经济数据向右倾斜，最低收入和最高收入阶层的异常值较高，中等收入阶层的数据趋近于正态性（尽管两边都有长尾）。
在我的经济和犯罪变量之间绘制一些散点图，没有显示出清晰的线性/曲线关系，没有清楚地表明单调性，并且表明相关值较低。我的 n = 1,441。我正在尝试确定是否使用 Pearson 的 r、Kendall 的 t 或 Spearman 的 rho。
在 Kendall 的 t 和 Spearman 的 rho 之间，最佳选择似乎是 Spearman，因为我的 n 很大（Kendall 的更适合小样本量）。所以问题是皮尔逊还是斯皮尔曼更好。
因为我的犯罪数据有偏差，而且我的经济数据有时有异常值，所以斯皮尔曼似乎比皮尔逊更可取。请注意，我假设单调性（随着特定收入阶层的人口百分比上升，犯罪率将均匀上升或下降），这支持使用斯皮尔曼。
我的分析合理吗？我遗漏了什么吗？我应该使用斯皮尔曼的 rho 还是其他测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/650748/which-correlation-test-to-use</guid>
      <pubDate>Tue, 09 Jul 2024 15:35:56 GMT</pubDate>
    </item>
    <item>
      <title>我的 MCMC 模拟</title>
      <link>https://stats.stackexchange.com/questions/650746/my-mcmc-simulation</link>
      <description><![CDATA[我是 MCMC 模拟和贝叶斯分析的新手，所以我想让别人看看我的图表，看看我的模拟是否有任何错误或改进空间（例如样本太少、相关性太高……）
我的后验本质上是高度相关的，所以我很难确保有足够数量的样本。正确来说，我使用的是 10 条链中每条链的最后 5,000 个样本。
我希望收敛诊断看起来也不错。
如果有人能对我的工作提出意见，我会非常高兴！





]]></description>
      <guid>https://stats.stackexchange.com/questions/650746/my-mcmc-simulation</guid>
      <pubDate>Tue, 09 Jul 2024 15:30:45 GMT</pubDate>
    </item>
    <item>
      <title>双向方差分析或混合模型</title>
      <link>https://stats.stackexchange.com/questions/650745/two-way-anova-or-mixed-model</link>
      <description><![CDATA[我有一个数据集，其 x 轴上按时间点组织：基线（0 天）、3、7、14、21 和 28 天。这些时间点对应于我测量动物受试者的缺陷分数（y 轴）的时期。
在基线和第 3 天之间诱发中风，导致中风后缺陷最初增加，随后进入恢复期，缺陷随时间减少。
我的数据集包括在这些时间点测量的大约 100 名受试者。每个时间点都有两组：中风组（接受中风诱导的受试者）和对照组（未进行手术，没有预期变化）。我的目标是对这些数据进行适当的统计分析。
一些受试者在不同时间点有缺失值，随机分布。例如，一个受试者可能在时间点 21 和 3 缺少数据，而另一个受试者可能在 0 和 3 缺少数据。但是，大多数受试者在所有 6 个时间点都有数据。
最初，在考虑了各种示例后，我尝试使用以下模型：
smf.mixedlm(&quot;Deficit_score ~ TimePoint * Group&quot;, df_sorted, groups=df_sorted[&quot;SubjectID&quot;], re_formula=&quot;~TimePoint&quot;)

在此模型中，“Group”表示中风或对照受试者，re_formula 表示允许每个受试者使用不同的斜率和截距。
但是，我很担心，因为我读到mixedlm是为线性模型设计的（？）。在我的数据中，由于中风诱发，缺陷从基线到第 3 天增加，但从第 1 天到第 28 天减少，表明存在非线性模式。
我也尝试使用 AnovaRM，但遇到了缺失值和缺乏受试者间因素实施的问题。
作为参考，我在 Stack Overflow 上找到了相关讨论：[https://stackoverflow.com/q/69859587/16528477]]]></description>
      <guid>https://stats.stackexchange.com/questions/650745/two-way-anova-or-mixed-model</guid>
      <pubDate>Tue, 09 Jul 2024 15:17:43 GMT</pubDate>
    </item>
    <item>
      <title>重复测量研究设计，患者退出血药浓度</title>
      <link>https://stats.stackexchange.com/questions/650744/repeated-measures-study-design-with-patient-drop-out-for-blood-concentrations</link>
      <description><![CDATA[我正在研究 100 名患者对某种药物的纵向反应（血药浓度变化过程）。这是一项回顾性研究。为此，我收集了服药后几分钟内的血药浓度。不幸的是，由于纵向反应只是部分调查，因此无法在所有时间点测量所有患者的血药浓度值。因此，我创建了两个图表进行评估：

5 个时间点上所有现有浓度的变化过程；这里我使用了 Mann-Whitney U 检验进行比较
在所有测量时间点进行分析的浓度变化过程；这里我使用了 Wilcoxon 符号秩检验。不幸的是，这里的病例数非常少，因为在所有时间点只有 20 名患者的测量值。

在审查中，我收到反馈，我应该使用重复测量研究设计进行分析，并让患者退出。在这里，我遇到的问题是，我不确定哪种统计方法适合这个问题。我使用 R 进行分析。
如果您有任何想法和建议，我将不胜感激！提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650744/repeated-measures-study-design-with-patient-drop-out-for-blood-concentrations</guid>
      <pubDate>Tue, 09 Jul 2024 15:15:07 GMT</pubDate>
    </item>
    <item>
      <title>在 MVGAM 中，如何模拟 1 个连续变量（丰度）、1 个离散变量（天数）和 1 个因素（真核生物属）之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/650741/in-mvgam-how-can-i-model-an-interaction-between-1-continuous-variable-abundanc</link>
      <description><![CDATA[我正在从事微生物生态学研究，并试图在微生物初级演替的情况下模拟几个属的丰富程度对单个感兴趣的属随时间的影响。我已经创建了这个模型，但我真的不确定我是否理解得正确，尤其是关于相互作用。
我发现有几个主题讨论 1 个变量和因素，但没有 1 个连续变量（丰度）、一个离散变量（时间）和因素（属）

Alkanindiges 是包含我感兴趣的属的相对丰度的列
丰度是每天所有属的相对丰度
时间是天数（1-24）
生物反应器是我的实验三重奏（其中有 3 个）

我使用 CAR(1)，因为我预计前一天我感兴趣的属的丰度会对当天的丰度产生影响，但我缺少一些数据点。
这是完整的模型，我包含了数据的摘要我正在处理。如果您想要整个文件，我很乐意通过电子邮件发送给您！
非常感谢您抽出时间。

mod_alk &lt;- mvgam( Alkanindiges ~ te(Abundance, time, by = Genus) + s(bioreactor, bs = &#39;re&#39;),

trend_model = CAR(1),

noncentred = TRUE,

data = AHAPCN_train, 

chains = 4,

adapt_delta = 0.97,

max_treedepth = 14,

parallel = TRUE,

backend = &#39;cmdstanr&#39;,

family = Gamma(link = &#39;inverse&#39;)) 

这是我的 df 的摘要。 NA 是因为我将丰度列分成了每个属的丰度的多个列。
]]></description>
      <guid>https://stats.stackexchange.com/questions/650741/in-mvgam-how-can-i-model-an-interaction-between-1-continuous-variable-abundanc</guid>
      <pubDate>Tue, 09 Jul 2024 14:16:22 GMT</pubDate>
    </item>
    <item>
      <title>评估随机搜索交叉验证：使用大型特征集调整 ElasticNet</title>
      <link>https://stats.stackexchange.com/questions/650740/assessing-random-search-cross-validation-tuning-in-elasticnet-with-large-featur</link>
      <description><![CDATA[我正在为一个包含超过 100,000 个变量的大型数据框估算 ElasticNet 模型，结果导致过度识别的情况。为了调整我的模型，我设置了一个超参数网格（alpha 和 l1 比率），确保它涵盖从完全密集到完全稀疏模型的组合，总共 10,100 种可能的组合。
鉴于详尽网格搜索不切实际，我选择了随机搜索交叉验证，其中随机选择了 1,000 个超参数组合。我现在关心的是评估从总共 10,100 个组合中随机选择的 1,000 个组合是否足以提供对模型在超参数空间中的表现的可靠理解。是否有任何既定的经验法则、理论指导或模拟可以指导我确定这一点？
补充：贝叶斯优化可能是一种更有意义的方法。但是，我缺乏使用 Python 实现 ElasticNet 模型的专业知识。有人能帮忙吗？
代码示例：
import numpy as np
from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit
from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_squared_error

# 生成合成数据（模拟您的 data_complete 和 y）
np.random.seed(42)
data_complete = np.random.rand(300, 100000) # 300 个观测值，100000 个变量
y = np.random.rand(300) # 目标变量的 300 个观测值

# 定义超参数网格
params = {
&#39;alpha&#39;: np.logspace(-5, 5, 100, end=True), # 100 个介于 e^-5 和 e^5 之间的值
&#39;l1_ratio&#39;: np.append(np.arange(0, 1.01, 0.01), 1.0) # 101 个介于 0 和 1 之间的值，包括 1.0
}

# 创建 Elastic Net Regressor 实例
regressor = ElasticNet()

# TimeSeriesSplit 交叉验证
tscv = TimeSeriesSplit(n_splits=5) # 根据需要调整分割数

# 随机搜索交叉验证
rs_cv = RandomizedSearchCV(regressor, params, n_iter=1000,scoring=&#39;neg_mean_squared_error&#39;, cv=tscv, verbose=1, n_jobs=4)
rs_cv.fit(data_complete, y)

# 最佳超参数
best_params = rs_cv.best_params_
best_alpha = best_params[&#39;alpha&#39;]
best_l1_ratio = best_params[&#39;l1_ratio&#39;]

print(f&quot;最佳 alpha: {best_alpha}&quot;)
print(f&quot;最佳 l1_ratio: {best_l1_ratio}&quot;)

# 使用最佳超参数拟合模型
best_enet = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio, random_state=42)
best_enet.fit(data_complete, y)

# 评估模型性能
y_pred = best_enet.predict(data_complete)
mse = mean_squared_error(y, y_pred)
print(f&quot;最终均方误差: {mse}&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/650740/assessing-random-search-cross-validation-tuning-in-elasticnet-with-large-featur</guid>
      <pubDate>Tue, 09 Jul 2024 14:06:09 GMT</pubDate>
    </item>
    <item>
      <title>如何测量二进制数据列表中分布的规律性？</title>
      <link>https://stats.stackexchange.com/questions/650739/how-do-i-measure-the-regularity-of-the-distribution-in-a-list-of-binary-data</link>
      <description><![CDATA[假设我有一个列表 list = [0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1]，它给出了某人在某一天是生病 (1) 还是没生病 (0) 的信息，由于该列表有 15 个元素，我考虑 1-15 天。现在我想确定如何“很好地”或者这些病假有规律地分布在这段时间内。
例如，规则的分布是
[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1]

不美观的分布是例如：
[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]

我考虑的是基尼系数或距离的标准差。但是我不知道如何处理第二个列表。
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]

这里，距离的标准差值为 0，但 1 的分布不太好。
还有什么其他可能性？]]></description>
      <guid>https://stats.stackexchange.com/questions/650739/how-do-i-measure-the-regularity-of-the-distribution-in-a-list-of-binary-data</guid>
      <pubDate>Tue, 09 Jul 2024 13:46:10 GMT</pubDate>
    </item>
    <item>
      <title>处理 Cox 回归中的分类变量</title>
      <link>https://stats.stackexchange.com/questions/650738/dealing-with-categorical-variables-on-cox-regression</link>
      <description><![CDATA[我试图将 Cox 回归模型拟合到我的事件发生时间数据，并有一个具有 5 个不同级别的分类变量。如果我不忽略其中一个级别，那么我将具有多重共线性，因此我假设我需要忽略一个类别作为“参考”类别。如果我忽略一个级别，那么我将如何解释得到的 cox 系数？忽略的类别有什么影响？它是否会导致基线风险？
我正在使用 Python 中 lifelines 库中的 CoxTimeVaryingFitter。]]></description>
      <guid>https://stats.stackexchange.com/questions/650738/dealing-with-categorical-variables-on-cox-regression</guid>
      <pubDate>Tue, 09 Jul 2024 13:32:30 GMT</pubDate>
    </item>
    <item>
      <title>元问题：理解相关性与效应大小</title>
      <link>https://stats.stackexchange.com/questions/650737/meta-question-understanding-correlation-vs-effect-size</link>
      <description><![CDATA[背景：我一直在研究一些关于解释幸福（幸福感）的因素的荟萃分析，因为我想检查某种哲学对幸福的主张，并且希望自己总体上幸福（谁不想呢：）。当然，这些荟萃分析揭示了幸福的不同协变量，它们具有不同的相关系数。
所以我想知道：根据这些研究，为了了解什么能长期带来最大的幸福感，我只需要关注相关系数的大小吗？还是我需要查看效果大小？或者还有什么需要注意的？我想我想知道我应该做些什么才能从我花费的一小时内获得最大的长期幸福感？]]></description>
      <guid>https://stats.stackexchange.com/questions/650737/meta-question-understanding-correlation-vs-effect-size</guid>
      <pubDate>Tue, 09 Jul 2024 13:14:35 GMT</pubDate>
    </item>
    <item>
      <title>多个总体均值相互作用的效应对比矩阵</title>
      <link>https://stats.stackexchange.com/questions/650720/effects-contrast-matrix-for-interaction-with-multiple-grand-means</link>
      <description><![CDATA[我想在我的 GAM（MGCV）中包含两个因素之间的相互作用：area 和 house_type，我希望进行总和为零的对比编码。
但是，我不希望将每个因素组合与所有级别的总平均值进行比较。我想要 每个级别的总平均值 area。因此，每个区域内的 house_types 都会与该 area 的总平均值进行比较。
这是我尝试过的
取 house_type 的对比矩阵。有 7 种类型：它是一个 7*6 矩阵。

对于 6 个级别的 area，我创建了一个矩阵，该矩阵由对角线上的 house_type 对比矩阵和非对角线上相同大小的零矩阵组成。这是 42*36。
前两个子矩阵如下所示：

查询

有没有更好的方法？
使用交互项运行简单线性回归，我得到 NA 系数 - 为什么会这样？
此模型中是否存在总体截距，还是每个 area 级别的截距代表总平均值？

谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/650720/effects-contrast-matrix-for-interaction-with-multiple-grand-means</guid>
      <pubDate>Tue, 09 Jul 2024 08:32:42 GMT</pubDate>
    </item>
    <item>
      <title>样本量对指标提升度的影响</title>
      <link>https://stats.stackexchange.com/questions/650716/impact-of-sample-size-on-metric-lift</link>
      <description><![CDATA[假设我们连续运行了三个随机用户拆分 AB 实验 exp_1、exp_2、exp_3。这三个实验的处理和控制完全相同。
Exp_1 在 2014 年 6 月 1 日至 2014 年 6 月 1 日期间运行了 2 周。 Exp_2 在 06/15-06/28 期间运行了 2 周，Exp_3 在 06/29-07/12 期间运行了 2 周。
Exp_1 有 2% 的用户参与了实验，Exp_2 有 50% 的用户参与了实验，Exp_3 有 100% 的用户参与了实验。
Exp_1 的主要指标提升的 95% CI 为 2.3% - 13.0%
Exp_2 的主要指标提升的 95% CI 为 6.2% - 8.4%
Exp_3 的主要指标提升的 95% CI 为 5.9% - 7.4%
从这些结果中，我们可以得出结论，这三个实验都具有相同的指标提升吗？
如果是/否，为什么？
我原本希望这些实验的指标提升是相同的。因为三个实验的处理方式相同。它们之间唯一的区别是参与实验的用户数量。因此，我想了解的是指标提升是否会根据参与实验的用户数量而变化。如果是这样，那么我们将不得不始终在 100% 用户参与的情况下运行实验。这并不理想，因为我们不能同时运行其他实验。]]></description>
      <guid>https://stats.stackexchange.com/questions/650716/impact-of-sample-size-on-metric-lift</guid>
      <pubDate>Tue, 09 Jul 2024 07:16:34 GMT</pubDate>
    </item>
    </channel>
</rss>