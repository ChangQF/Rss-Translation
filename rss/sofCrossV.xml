<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 07 Mar 2024 18:16:34 GMT</lastBuildDate>
    <item>
      <title>有效可视化具有过高 1.0 值的 P 值分布</title>
      <link>https://stats.stackexchange.com/questions/642089/effectively-visualizing-p-value-distributions-with-excessive-1-0-values</link>
      <description><![CDATA[我正在处理一个离散统计测试场景，其中计算的 P 值的很大一部分恰好为 1.0，因为测试统计量的性质在许多情况下不超过其观察值。在包含 1,000 个测试的数据集中，大约 700 个测试的 P 值为 1。1.0 的浓度为直方图呈现带来了可视化挑战，因为它会导致 1.0 处出现高耸的条形图，从而模糊了其余 P 值的分布。为了在出版物中实现更清晰的可视化，我正在考虑从直方图中删除这些 P 值 1，并向读者清楚地说明这一调整。
我想知道这种方法是否合适，以及是否有任何替代建议可以以信息丰富且可直观解释的方式可视化此数据。
演示 Python 代码：
导入 matplotlib.pyplot 作为 plt
将 numpy 导入为 np

# 虚拟数据：300 个 P 值，范围从 0.01 到 0.99，1.0 时有 700 个
p_values = np.concatenate((np.random.rand(300), np.ones(700)))

# P 值的直方图，包括 1.0
plt.figure(figsize=(10, 4))
plt. 子图(1, 2, 1)
plt.hist(p_values, bins=50, color=&#39;skyblue&#39;)
plt.title(&#39;包括 1.0 的 P 值直方图&#39;)
plt.xlabel(&#39;P值&#39;)
plt.ylabel(&#39;频率&#39;)

# 删除 1.0 值后的 P 值直方图
p_values_filtered = p_values[p_values &lt;； 1.0]
plt. 子图(1, 2, 2)
plt.hist(p_values_filtered, bins=50, color=&#39;lightgreen&#39;)
plt.title(&#39;没有 P=1.0 的直方图&#39;)
plt.xlabel(&#39;P值&#39;)
plt.ylabel(&#39;频率&#39;)

plt.tight_layout()
plt.show()

]]></description>
      <guid>https://stats.stackexchange.com/questions/642089/effectively-visualizing-p-value-distributions-with-excessive-1-0-values</guid>
      <pubDate>Thu, 07 Mar 2024 18:09:38 GMT</pubDate>
    </item>
    <item>
      <title>分析死亡纵向数据</title>
      <link>https://stats.stackexchange.com/questions/642087/analyzing-longitudinal-data-with-deaths</link>
      <description><![CDATA[我获得了接受不同胶质母细胞瘤治疗的动物的一些纵向数据。除了传统的生存分析之外，他们还想观察动物的体重和肿瘤的大小。当然，动物会在这个过程中死亡。我如何有效地分析这些数据，特别是如果死亡可能会通过消除病情最严重的动物而影响其余动物的结果变量的平均值？我认为我需要假设数据是 NMAR/MNAR，因为缺失（死亡）是肿瘤进展的直接影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/642087/analyzing-longitudinal-data-with-deaths</guid>
      <pubDate>Thu, 07 Mar 2024 18:01:30 GMT</pubDate>
    </item>
    <item>
      <title>Python：根据曲线拟合数据确定最佳输入变量</title>
      <link>https://stats.stackexchange.com/questions/642086/python-determine-best-input-variables-based-on-curve-fitted-data</link>
      <description><![CDATA[我有一个算法，它获取多个值作为输入并返回多个值作为输出。
我的目标是确定导致最佳（最低）输出的最佳输入变量。
我的方法如下：

我使用随机搜索生成 100 个输入变量集的样本，并使用这些数据运行我的算法 100 次。

我使用 scypi 中的 curve_fitting 来拟合具有成本函数的曲线，成本函数应尽可能低：
&lt;前&gt;&lt;代码&gt; df_values = load_data_into_data_frame()

    def func_2nd_ Degree(x, a, b, c, d, e, f, g, h, i, j, k, L, m, n, o):
        返回一个+\
               b * x[0] + c * x[1] + d * x[2] + e * x[3] + f * x[4] + g * x[5] + h * x[6] + \
               i * x[0]**2 + j * x[1]**2 + k * x[2]**2 + L * x[3]**2 + m * x[4]**2 + n * x[5]**2 + o * x[6]**2


    输入值 = (
        df_values.PROPERTY_1.values，
        df_values.PROPERTY_2.values，
        df_values.PROPERTY_3.values，
        df_values.PROPERTY_4.values，
        df_values.PROPERTY_5.values，
        df_values.PROPERTY_6.values，
        df_values.PROPERTY_7.values
    ）

    cost_function = df_values.RESULT_1_MOV_AVG_MAX
                    + df_values.RESULT_2_MOV_AVG_MAX
                + df_values.RESULT_3_MOV_AVG_MAX
                ...


    popt, pcov = curve_fit(func_2nd_ Degree, input_values, cost_function)
    波普特

结果popt如下所示：
&lt;块引用&gt;
[ 4.88752977e+05, 2.62450640e+01, -1.01704599e+04, 2.55909433e+00,
3.03087363e+03、1.05260748e+03、3.51454352e+04、1.47821739e+02、
-9.99235863e-01、6.77257297e+01、-9.90881101e-04、-1.50705705e+03、
-4.43665226e+01、-4.73133670e+04、-3.00483670e+02、1.08617538e-02、
-1.50337244e-01、1.27225960e-07、2.47541989e+02、6.19103961e-01、
2.10554677e+04, 1.68530759e+02]


为了验证曲线拟合结果，我绘制了数据：

&lt;前&gt;&lt;代码&gt; plt.figure(figsize=(20,10))
    plt.plot(cost_function.tolist(), label=&#39;值&#39;)
    plt.plot(func_2nd_ Degree(input_values, *popt), label=“fit”);
    plt.xlabel(“迭代”)
    plt.图例()



&lt;块引用&gt;



为了确定最佳输入值，我尝试使用 SciPy 的 minimize() 函数，但得到的结果始终等于我定义的边界。

# 给出不错结果的当前输入值
初始猜测 = [19.77, 152.31, 2417, 2.4, 25.96, 0.64, 0.68]
边界 = ((3.0, 25.0), (80.0, 170.0), (2000.0, 2700.0), (1.5, 5.0), (15.0,50.0), (0.5, 0.96), (0.0, 2.0))
min = 最小化(lambda x: func_2nd_ Degree(x, *popt), x0=initial_guess, method=&#39;SLSQP&#39;,bounds=bounds)
分钟

 乐趣：26.513436903241427
     jac: 数组([-8.55688477e+00, -3.44024658e+00, 6.92749023e-02, -8.32626648e+01,
       -3.52287903e+01、1.33221912e+03、-1.27986570e+02])
 消息：“优化已成功终止”
    NFEV：128
     尼特：18
    新值：16
  状态：0
 成功：真实
       x: 数组([2.50000000e+01, 1.70000000e+02, 2.00000002e+03, 5.00000000e+00,
       5.00000000e+01, 5.00000000e-01, 2.00000000e+00])


问题：
我现在如何确定导致成本函数尽可能最低的最佳输入值？]]></description>
      <guid>https://stats.stackexchange.com/questions/642086/python-determine-best-input-variables-based-on-curve-fitted-data</guid>
      <pubDate>Thu, 07 Mar 2024 17:58:31 GMT</pubDate>
    </item>
    <item>
      <title>如何训练和测试分割不平衡的数据集？</title>
      <link>https://stats.stackexchange.com/questions/642085/how-do-you-train-test-split-an-imbalanced-dataset</link>
      <description><![CDATA[我有一个不平衡的数据集，我正在尝试预测二进制目标。少数群体占所有观察值的比例不到 0.01%。
我对多数类进行了欠采样，并对少数类进行了过采样，因此我的目标列的平均值现在为 23%。训练测试分割这个平衡数据集是否正确？
换句话说，我应该：

重新平衡后，train-test 分割数据；或
分配原始数据集的子集用于测试、分配原始数据集的子集用于训练并重新平衡训练数据集？
]]></description>
      <guid>https://stats.stackexchange.com/questions/642085/how-do-you-train-test-split-an-imbalanced-dataset</guid>
      <pubDate>Thu, 07 Mar 2024 17:56:48 GMT</pubDate>
    </item>
    <item>
      <title>给定 $P(D)、P(C)、P(C|D)、P(B|C)、P(B|D)、P(B|CD)、P( B|C^cD^c)$</title>
      <link>https://stats.stackexchange.com/questions/642079/what-is-pb-given-pd-pc-pcd-pbc-pbd-pbcd-pbccdc</link>
      <description><![CDATA[鉴于已知值，
$$P(CD) = P(C|D)P(D)$$$$P(C^cD) ) = P(C^c|D)P(D) = (1 - P(C|D))P(D)$$
然后使用我们找到的这些值，
$$P(D|C) = \frac{P(CD)}{P(C)}, \, P(D|C^c) = \frac {P(C^cD)}{P(C^c)}$$
这给了我们 $P(D^c|C)$ 和 $P(D^c|C^ c)$。使用这些值
$$ P(CD^c) = P(D^c|C)P(C)$$ $$P(C^cD^c) = (D^c|C^c)P(C^c)$$
现在要计算$P(B)$，我们得到这个长表达式，
$$P(B) = P(B|DC)P(DC) + P(B|D^cC)P(D^cC) + P(B| DC^c)P(DC^c) + P(B|D^cC^c)P(D^cC^c)$$
我不知道如何计算 $P(B|D^cC)$ 和 $P(B| DC^c)$ 从这里开始。这是计算 $P(B)$ 的错误方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642079/what-is-pb-given-pd-pc-pcd-pbc-pbd-pbcd-pbccdc</guid>
      <pubDate>Thu, 07 Mar 2024 16:45:48 GMT</pubDate>
    </item>
    <item>
      <title>排列测试在比较两个不同月份的欺诈阻止政策误报率时是否有效？</title>
      <link>https://stats.stackexchange.com/questions/642076/is-a-permutation-test-valid-in-comparing-a-fraud-block-policy-false-positive-rat</link>
      <description><![CDATA[我正在寻求在电子商务欺诈背景下进行反事实实验。当欺诈政策阻止交易时，您永远不会知道它是否真正是欺诈的。我试图对这个被封锁的人群进行抽样，并牢记两个目标：

合理估计误报率（即被阻止的交易有多少实际上是欺诈性的）
比较不同时间点（每月等）的误报测量结果，并确定我们的政策绩效是否出现统计上显着的变化

我希望确定一个最小样本量，以帮助我实现这些目标，并且我得出了以下方法：

估计：首先，我查看了二项式比例的威尔逊得分区间，但我不认为其假设适用于我所讨论的总体。因此，我选择了引导置信区间，因为我相信这更灵活，并且适用于我对真实分布缺乏了解的人群。我的目标是两边的置信度均为 10%，这是我从大约 80 个样本中获得的，并假设误报率为 30%。
比较：我建议在接下来的几个月之间测试 fpr 因某种效应大小而增加或减少的假设。出于与引导程序选择类似的原因，我建议对此设置进行排列测试。在这里我不太确定我的实验设计是否有效。我的想法是，我将每个月视为自己的样本，并测试平均值（假阳性率）是否增加了某种效应大小。我已经运行了一些模拟，我可以看到，如果我用不同的真实均值模拟总体两个月，当样本在 100 范围内时，我的排列测试可以获得截然不同的结果。这是否是最好的我可以希望用那么小的样本量来做，如果我不相信我的样本量会给我带来有用的结果，那么这是否值得做？我还有点担心我的人群的排列测试中的可交换性假设，如果我们假设我正在比较不同的用户交易，那么一笔交易是否欺诈应该对另一笔交易没有影响。也许它大致正确，这是一个有效的假设吗？

是否有另一种方式来思考我在这里缺少的随时间比较问题，或者我本质上会受到我试图尽可能减少样本大小这一事实的限制？]]></description>
      <guid>https://stats.stackexchange.com/questions/642076/is-a-permutation-test-valid-in-comparing-a-fraud-block-policy-false-positive-rat</guid>
      <pubDate>Thu, 07 Mar 2024 16:16:46 GMT</pubDate>
    </item>
    <item>
      <title>如何仅根据直方图确定数据集的偏度</title>
      <link>https://stats.stackexchange.com/questions/642075/how-do-i-determine-the-skewness-of-a-data-set-from-only-a-histogram</link>
      <description><![CDATA[我有一个收集事件数据的控制器。但是，它不会保存每个数据点并将其发送给我。它只构建一个直方图并将其发送给我。如果没有实际的数据点来计算平均值、中位数和众数，我可以仅根据直方图确定数据的偏度吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642075/how-do-i-determine-the-skewness-of-a-data-set-from-only-a-histogram</guid>
      <pubDate>Thu, 07 Mar 2024 15:56:49 GMT</pubDate>
    </item>
    <item>
      <title>以目标值作为特征进行训练</title>
      <link>https://stats.stackexchange.com/questions/642072/training-with-a-target-value-as-feature</link>
      <description><![CDATA[我有一个数据集，其中将试剂 x 添加到悬浮液中以达到实验前设置的某个值 ŷ。
实际测量的值为y，这就是我的目标值。
我现在的问题是，我可以使用 ŷ 和 x （以及其他）进行训练来预测 y 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642072/training-with-a-target-value-as-feature</guid>
      <pubDate>Thu, 07 Mar 2024 15:35:02 GMT</pubDate>
    </item>
    <item>
      <title>计算样本方差时，为什么除以“n-1”而不是“n-2”或“n-0.5”？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/642069/when-calculating-the-sample-variance-why-do-we-divide-by-n-1-and-not-n-2-or</link>
      <description><![CDATA[计算样本方差时，我们除以 $n-1$ 而不是 $n$纠正因使用样本平均值而不是总体平均值而导致的偏差。
我的问题是为什么我们只减去 1 而不是任何其他值？例如，为什么我们不除以 $n-2$ 呢？
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/642069/when-calculating-the-sample-variance-why-do-we-divide-by-n-1-and-not-n-2-or</guid>
      <pubDate>Thu, 07 Mar 2024 14:14:09 GMT</pubDate>
    </item>
    <item>
      <title>从线性回归模型中删除异常值，减少调整后的 R^2</title>
      <link>https://stats.stackexchange.com/questions/642065/dropping-outlier-from-linear-regression-model-reducing-adjusted-r2</link>
      <description><![CDATA[我正在 R 中对具有 8 个自变量的数据集运行线性回归。当我使用所有变量运行模型时：
fullmodel &lt;- lm(价格 ~ ., data = basedata)
摘要（完整模型）

我得到一个形容词。 R2 为 0.9901。然而，数据中有一个非常明显的异常值，正如 car::outlierTest(fullmodel) 所证实的那样。这一观察结果不是编码错误，但仍然不能代表更广泛的人群，因此我决定放弃它。但是，当我运行排除了此观察结果的修订模型时：
fullmodel_nooutlier &lt;- lm(价格 ~ ., data = nooutlier)
摘要（fullmodel_nooutlier）

使用 par(mfrow=c(2,2)) plot(fullmodel_nooutlier) 我的模型诊断看起来好多了，并且没有违反线性回归的假设，所以我这样做不认为需要任何进一步的数据转换。然而我的形容词。 R2 降至 0.8589。我不确定这样的极端异常值如何降低模型拟合度，因此如果我能就是否应该保留它进行分析提供任何建议，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/642065/dropping-outlier-from-linear-regression-model-reducing-adjusted-r2</guid>
      <pubDate>Thu, 07 Mar 2024 13:43:41 GMT</pubDate>
    </item>
    <item>
      <title>添加更多数据，GLMM 突然无法收敛 (R)</title>
      <link>https://stats.stackexchange.com/questions/642061/added-more-data-and-suddenly-glmm-fails-to-converge-r</link>
      <description><![CDATA[我有一个数据集，我在其中对住房开发进行了随机抽样，然后在其中系统地对每个栖息地进行了抽样。我现在有一个数据集，其中每个观察结果都是一个 patch_ID，并且我记录了该补丁的变量，例如project_ID（它来自的开发）、Area_ha（补丁的面积，以公顷为单位）、Pre_post（补丁是否来自开发前的场地规划或开发后的场地规划）。我想进行 GLMM 来调查开发前后栖息地斑块的大小 (Area_ha) 之间是否存在差异（例如 Pre_post 变量中的“前”或“后”），同时考虑我的分组因素（project_ID）。我正在使用 GLMM，因为我的 Area_ha 数据严重右偏并且没有零值。区域是连续的，Pre_post 是一个有两个级别的因子（“pre”、“post”），project_ID 是一个有 25 个级别的因子（25 个开发项目中的每个级别）。
上个月我使用以下代码在较小的数据集上成功进行了 GLMM：
glmm_gamma &lt;- glmer(Area_ha ~ Pre_post + (1 | project_ID),
                    family = Gamma(link = &quot;log&quot;),
                    数据 = 大小3)

但是，现在我增加了数据集的大小，并且与上面运行模型相同的代码行给出了错误：
警告：模型未能与 max|grad| 收敛= 0.0209587（tol = 0.002，分量 1）

数据仍然右偏，我已经删除了最麻烦的异常值。
我已尝试以下选项来排除故障，但无济于事：
#重新缩放并居中我的东西：
mu &lt;- 平均值(size3$Area_ha, na.rm = TRUE)
西格玛 &lt;- sd(size3$Area_ha, na.rm = TRUE)
size3$Area_ha_scaled &lt;- (size3$Area_ha - mu) / sigma
#但我后来意识到我不能这样做，因为伽玛分布不允许负值

尝试检查奇点：
tt &lt;- getME(glmm_gamma,“theta”)
ll &lt;- getME(glmm_gamma,“较低”)
分钟(tt[ll==0])
#0.8909557，所以不用担心奇点

尝试更多迭代
glmm_gamma &lt;- glmer(Area_ha ~ Pre_post + (1 | project_ID),
                    family = Gamma(link = &quot;log&quot;),
                    数据=大小3，
                    控制= glmerControl（优化器=“bobyqa”，optCtrl =列表（maxfun = 1000000）））
#还是没用

我完全不知道下一步该怎么做，非常感谢一些帮助！我很困惑为什么添加更多数据会使我的模型完全停止工作 - 我对统计数据不太有信心，所以希望这个社区可以提供帮助！
我已将我的数据放在这里 - 包括数据和一些代码： https://github .com/sirianmckellen/stackex.git
如果有人对我如何前进有任何想法，这是否是一个可解决的问题，或者我是否需要新的模型类型（如果是这样，我应该考虑什么？）等等，我将非常感激！谢谢大家！]]></description>
      <guid>https://stats.stackexchange.com/questions/642061/added-more-data-and-suddenly-glmm-fails-to-converge-r</guid>
      <pubDate>Thu, 07 Mar 2024 12:33:39 GMT</pubDate>
    </item>
    <item>
      <title>获取高斯过程二元分类的认知不确定性</title>
      <link>https://stats.stackexchange.com/questions/642037/get-epistemic-uncertainty-of-gaussian-process-binary-classification</link>
      <description><![CDATA[假设 $f \colon \mathbb R \to \{0, 1\}$ 是由 $P(f(x) = 1)=p(x)$ 对于所有 $x \in \mathbb R$，其中 $p(x)$ 是一个 sigmoid 函数（对于 $x \to -\infty$ 为零，一个用于 $x \to \infty$，它是连续且非递减的）。
我有 $(x_i, f(x_i))$ 的示例 $i = 1, \ldots, N $。我想获得函数 $p$ 的估计及其认知不确定性的估计。我的目标是有一个不确定性界限，就像 $p(x) \in [\langle p \rangle(x) - C_\alpha(x), \langle p \rangle(x ) + C_\alpha(x)]$，其中 $\langle p\rangle$ 是 $p$ 和 $C_\alpha$ 是依赖于 $x$ 的置信度区间宽度取决于置信水平 $\alpha$。
由于我事先不知道 $p(x)$ 的适当函数形状，所以我想到了高斯过程分类。借助 sklearn，我可以使用 GaussianProcessClassifier 并通过该函数获得 $p(x)$ 的估计值预测概率。此函数不允许使用关键字 return_std。有数学原因吗？
这是一个代码片段，其中使用 $p$ 生成数据，该数据是重新缩放的 arctan：
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

从 sklearn.gaussian_process 导入 GaussianProcessClassifier
从 sklearn.gaussian_process.kernels 导入 RBF、ConstantKernel

# %%
# 生成合成数据

贝塔 = 10
prob_func = lambda x: 1 / np.pi * (np.pi / 2 + np.arctan(beta * x))
rng = np.random.default_rng(2024)
N = 100

X = rng.normal(大小=N, 比例=1/np.sqrt(beta))
Y = rng.二项式(1, prob_func(X), size=N)

plt.plot(X, Y, &#39;o&#39;)
plt.plot(np.sort(X), prob_func(np.sort(X)))

# %%
# 高斯过程分类

rbf = ConstantKernel(1.0) * RBF(length_scale=1.0)

gpc = GaussianProcessClassifier(内核=rbf)

gpc.fit(np.reshape(X, (N, 1)), Y)

# %%
# 预测概率

x_test = np.reshape(np.linspace(-3, 3, 1000), (1000, 1))
prob_estimate = gpc.predict_proba(x_test)
估计 = gpc.predict(x_test)

plt.plot(x_test, prob_estimate[:, 1])
plt.plot(x_test, prob_func(x_test))
plt.plot(x_test, 估计)
plt.legend([&#39;GP 估计&#39;, &#39;真相&#39;])
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/642037/get-epistemic-uncertainty-of-gaussian-process-binary-classification</guid>
      <pubDate>Thu, 07 Mar 2024 07:59:47 GMT</pubDate>
    </item>
    <item>
      <title>在地理加权回归中包括位置虚拟变量</title>
      <link>https://stats.stackexchange.com/questions/642014/including-location-dummy-variables-in-geographically-weighted-regression</link>
      <description><![CDATA[我使用对房地产销售的个人观察（而不是多边形数据）来对房价进行建模。
在 GWR 模型中包含邮政编码区域的虚拟变量作为参数是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/642014/including-location-dummy-variables-in-geographically-weighted-regression</guid>
      <pubDate>Wed, 06 Mar 2024 22:10:36 GMT</pubDate>
    </item>
    <item>
      <title>依次缩小模型</title>
      <link>https://stats.stackexchange.com/questions/642004/reduce-the-model-sequentially</link>
      <description><![CDATA[我收到了一个方差分析表，并要求我按顺序缩小模型。
我搜索了在线资源，说：按顺序简化模型时，通常首先评估高阶项的重要性，然后在必要时继续评估低阶项。
这是否意味着在简化模型时，我们总是首先检查具有最高 p 值的最高阶交互项，然后删除任何不显着的项，然后重新拟合模型？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642004/reduce-the-model-sequentially</guid>
      <pubDate>Wed, 06 Mar 2024 20:26:49 GMT</pubDate>
    </item>
    <item>
      <title>具有交互作用的混合效应线性模型的系数解释</title>
      <link>https://stats.stackexchange.com/questions/642000/interpretation-of-coefficients-from-a-mixed-effect-linear-model-with-an-interact</link>
      <description><![CDATA[我从具有交互作用的混合效应线性回归模型中获得以下输出。该模型包括：

连续结果（范围从 590 到 1401）。
组变量（二元；对照与治疗）。
连续协变量（范围从 0 到 1）。
组变量和协变量之间的交互项。

&lt;前&gt;&lt;代码&gt;&gt;总结（测试）
REML 拟合线性混合模型。 t 检验使用 Satterthwaite 方法 [&#39;lmerModLmerTest&#39;]
公式：结果 ~ 组 * 协变量 + (1 | 受试者)
   数据：ex.dat

REML 收敛准则：1942.7

缩放残差：
    最小 1Q 中值 3Q 最大
-2.8484 -0.4493 -0.0084 0.3499 3.8192

随机效果：
 组名称方差标准差
 主题（拦截）20772 144.12
 剩余 4511 67.16
obs 数量：164，组：主题，48

固定效果：
                         估计标准。误差df t值Pr(&gt;|t|)
(截距)833.73 31.85 55.31 26.175＜ 2e-16 ***
组处理 20.95 45.08 55.47 0.465 0.643903
协变量 66.99 18.68 114.30 3.586 0.000496 ***
组处理：协变量 14.14 26.49 114.39 0.534 0.594531
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

在这种情况下：我相信我可以说（+如果这些解释有任何问题，请告诉我。）：

协变量系数 66.99 表示（基线）对照组内协变量每增加一个单位，结果的平均增加。 （重要）
随着协变量每增加一个单位，治疗组的结果平均比对照组高 14.14 个单位。 （不显着）

但是，考虑到组变量的系数及其相应的 p 值，我不确定得出组间不存在显着差异的结论是否合适。
如果我不能根据这个模型得出这样的结论，我应该检查哪个模型或哪个数字来确定对照组和治疗组之间是否存在显着差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/642000/interpretation-of-coefficients-from-a-mixed-effect-linear-model-with-an-interact</guid>
      <pubDate>Wed, 06 Mar 2024 19:53:27 GMT</pubDate>
    </item>
    </channel>
</rss>