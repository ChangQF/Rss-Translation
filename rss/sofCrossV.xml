<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 27 Sep 2024 03:22:30 GMT</lastBuildDate>
    <item>
      <title>关于 x/y 的回归 y 有问题吗？</title>
      <link>https://stats.stackexchange.com/questions/654984/problems-regressing-y-on-x-y</link>
      <description><![CDATA[我正在尝试思考回归是否
$y = a + b (x/y)$
是否有问题。这不是共线性，因为没有线性关系？但是，随着 $y$ 的增加，$bx$ 会趋于减少，所以我很怀疑。这里有问题吗？这只是 $y^2$ 对 $x$ 的回归，对吧？
这里真正要讨论的回归是：
$$
\text{出席天数} = a + b (\text{事件计数/出席天数})
$$
事件只能发生在出席的当天。]]></description>
      <guid>https://stats.stackexchange.com/questions/654984/problems-regressing-y-on-x-y</guid>
      <pubDate>Fri, 27 Sep 2024 02:08:46 GMT</pubDate>
    </item>
    <item>
      <title>创建特定领域的语料库？</title>
      <link>https://stats.stackexchange.com/questions/654982/creating-domain-specific-corpora</link>
      <description><![CDATA[我正在开展一些自然语言处理研究，需要特定领域的语料库，例如商业、文学、地理等。
我的想法是从古腾堡计划中抓取不同领域的免费电子书的 HTML 内容。然后从这些语料库中减去可以在某些 nltk 语料库中找到的通用单词。这种方法有意义吗？
是否有现成的特定领域的免费语料库可以用于此目的？我只需要来自此类语料库的单词列表。]]></description>
      <guid>https://stats.stackexchange.com/questions/654982/creating-domain-specific-corpora</guid>
      <pubDate>Fri, 27 Sep 2024 00:01:49 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归功效分析</title>
      <link>https://stats.stackexchange.com/questions/654981/logistic-regression-power-analysis</link>
      <description><![CDATA[我正在复制一项研究，研究线粒体 DNA 拷贝数对 AD 的影响。
我需要进行功效分析来估计研究所需的样本量。我正在使用研究中的效应量进行逻辑回归功效分析。研究中报告的效应量是风险比 1.65。根据我的理解，我必须将其转换为比值比或科恩 d。对吗？我也有点困惑如何从那里继续。任何帮助都将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654981/logistic-regression-power-analysis</guid>
      <pubDate>Thu, 26 Sep 2024 23:55:51 GMT</pubDate>
    </item>
    <item>
      <title>结果和预测因子之间存在多重共线性吗？</title>
      <link>https://stats.stackexchange.com/questions/654980/multicollinearity-between-outcome-and-predictor</link>
      <description><![CDATA[我有一个针对美国各县的小组研究。我感兴趣的结果是 15 至 40 岁男性的凶杀率。我希望我的一个控制变量是“15 至 40 岁男性占人口的百分比”。这会造成问题吗？
最好，]]></description>
      <guid>https://stats.stackexchange.com/questions/654980/multicollinearity-between-outcome-and-predictor</guid>
      <pubDate>Thu, 26 Sep 2024 22:25:23 GMT</pubDate>
    </item>
    <item>
      <title>标准化为什么这样计算？</title>
      <link>https://stats.stackexchange.com/questions/654978/why-is-normalization-calculated-like-this</link>
      <description><![CDATA[我正在阅读一篇研究论文，其中研究人员提到所有数据都标准化为零均值单位方差。对于这个特定的模型，标准化统计数据是在模型训练时计算的。
在模型训练时，标准化函数会累积一百万步的统计数据，然后使用这些统计数据进行标准化。
标准化函数如下所示（伪代码）：
normalized_data = (data - mean) / std_with_epsilon()

这对我来说很有意义。然而，std_with_epsilon() 函数却没有意义。
std_with_epsilon() 函数并不像数学文献中预期的那样计算标准差，而是像这样计算：
在累积阶段，它将所有输入数据的平方相加：
accumulated_sum_squared += data**2

然后，当调用 std_with_epsilon() 时，它会像这样计算 std：
std = squareRoot(accumulated_sum_squared / safe_count - mean**2)
return max(std, 1e-8)

这不是我期望的标准差计算。
有人能解释一下这里发生了什么吗？或者给我指出任何有助于解释的资源？
这是实际源代码的链接。]]></description>
      <guid>https://stats.stackexchange.com/questions/654978/why-is-normalization-calculated-like-this</guid>
      <pubDate>Thu, 26 Sep 2024 21:29:03 GMT</pubDate>
    </item>
    <item>
      <title>加权三次拟合的误差估计</title>
      <link>https://stats.stackexchange.com/questions/654976/error-estimation-in-weighted-cubic-fitting</link>
      <description><![CDATA[给定数据集 $(t_i, y_i)$ 和绝对误差 $\varepsilon_{y_i}$，我想拟合一个加权三次函数并获取插值 $\hat{y}(t)$ 的误差：
$$
\hat{y}(t) = \sum^{3}_{j=0}c_jt^j
$$
其中 $c_j$ 是由加权拟合过程确定的系数。
计算残差和卡方很简单：
$$
r_i = y_i - \hat{y}(t_i)
$$
$$
\chi^2 = \sum^n_{i=1}\left( \frac{r_i}{\varepsilon_{y_i}}\right)^2
$$
...但我不清楚从哪里可以得到 $\hat{y}$ 值的误差。我如何估计插值 $\hat{y}(t)$ 的误差？]]></description>
      <guid>https://stats.stackexchange.com/questions/654976/error-estimation-in-weighted-cubic-fitting</guid>
      <pubDate>Thu, 26 Sep 2024 21:14:48 GMT</pubDate>
    </item>
    <item>
      <title>“规律性条​​件”是什么意思</title>
      <link>https://stats.stackexchange.com/questions/654975/what-does-regularity-condition-mean</link>
      <description><![CDATA[在阅读博客时在一篇关于分数匹配的博客文章中，我偶然发现了“规律性条​​件”一词。当我在 Google 上搜索它时，我找到了一个答案：

规律性条件是指对似然函数施加的限制，以确保期望运算和微分的顺序可以互换。

但是，我发现这个定义在博客文章和分数匹配主题的上下文中没有意义。那么，“规律性条​​件”到底是什么意思呢？
编辑：我添加了引用的直接链接。作者在解释为什么我们可以在下面的等式中删除两个第一项时提到了该术语：
]]></description>
      <guid>https://stats.stackexchange.com/questions/654975/what-does-regularity-condition-mean</guid>
      <pubDate>Thu, 26 Sep 2024 21:10:07 GMT</pubDate>
    </item>
    <item>
      <title>不同长度的 ARIMAX 时间序列</title>
      <link>https://stats.stackexchange.com/questions/654974/arimax-time-series-with-different-lengths</link>
      <description><![CDATA[我正在构建一个包含两个时间序列的 ARIMAX 模型：一个时间序列经过差分后变得平稳，而另一个时间序列已经平稳且具有更多观测值。如何对齐这两个不同长度的序列，以便它们可以在 ARIMAX 模型中一起使用？在 R 中处理这个问题的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654974/arimax-time-series-with-different-lengths</guid>
      <pubDate>Thu, 26 Sep 2024 20:51:35 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中使用功效分析进行回归？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654973/how-to-use-a-power-analysis-for-regression-in-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654973/how-to-use-a-power-analysis-for-regression-in-r</guid>
      <pubDate>Thu, 26 Sep 2024 20:30:05 GMT</pubDate>
    </item>
    <item>
      <title>特征工程高度相关的特征</title>
      <link>https://stats.stackexchange.com/questions/654971/feature-engineering-highly-corrrelated-features</link>
      <description><![CDATA[我正在创建一个分类模型，用于预测患者的急诊就诊次数。目标变量是患者是否去过急诊室，如果没有去过，则为 0，如果他们至少去过一次，则为 1。其中一个特征是患者过去去过急诊室的次数。该特征与目标高度相关，因为非零值对应目标中的 1，而 0 对应目标中的 0，因此我不得不将其删除。
但是，这可能是非常有用的信息，因为患者去过急诊室的次数越多，他们再次就诊的可能性就越高。我尝试了许多方法来设计该特征，例如将其转换为分类变量、对其进行分类，但即便如此，相关性仍然很高。
有没有办法设计这个特征以便也可以使用它？]]></description>
      <guid>https://stats.stackexchange.com/questions/654971/feature-engineering-highly-corrrelated-features</guid>
      <pubDate>Thu, 26 Sep 2024 19:47:46 GMT</pubDate>
    </item>
    <item>
      <title>仅用3个变量进行潜变量演示</title>
      <link>https://stats.stackexchange.com/questions/654968/latent-variable-demonstration-with-only-3-variables</link>
      <description><![CDATA[我收集了焦虑（ANX）、抑郁（DEP）和创伤后应激综合症（PTSD）症状的数据。 Spearman 相关性结果如下 (***p &lt; .001):

ANX 和 DEP：r = 0.5452 ***
ANX 和 PTSD：r = 0.5568 ***
DEP 和 PTSD：r = 0.4599 ***

我考虑使用验证性因子分析 (CFA) 来查看是否可以确认单个潜在变量的存在。
如果我没记错的话，进行 CFA 的变量的最小数量是 3。但是，问题在于模型将完全拟合，自由度为零，这会使模型受到质疑。
功效分析表明，我应该拥有的样本量是以下：

ANX：n = 99
DEP：n = 99
PTSD：n = 53

虽然我收集了 n &gt; 400，但所有变量都违反了正态性假设，并且有一些异常值。
我的问题：是否有任何统计模型可以在知道只有 3 个变量的情况下显示潜在变量的存在，并且数据违反了正态性假设并有异常值？]]></description>
      <guid>https://stats.stackexchange.com/questions/654968/latent-variable-demonstration-with-only-3-variables</guid>
      <pubDate>Thu, 26 Sep 2024 18:51:20 GMT</pubDate>
    </item>
    <item>
      <title>为了模拟的目的，将小样本量分解为大样本量</title>
      <link>https://stats.stackexchange.com/questions/654966/factoring-a-small-sample-size-into-a-larger-sample-size-for-the-purpose-of-simul</link>
      <description><![CDATA[假设一名左撇子棒球投手面对过 153 名击球手 — 其中 150 名是右撇子，3 名是左撇子。人们普遍认为，左撇子投手在对付左撇子击球手时表现更好，而在对付右撇子击球手时表现稍差，因此在这种情况下，绝大多数数据偏向投手的弱点 — 左撇子 vs. 右撇子。
在投手面对的 150 名右撇子击球手中，有 30 名击出了安打，击球率达到 0.200。面对 3 名左撇子击球手，投手三振 2 名，并让第三名击球手在飞球中出局，因此在这个非常小的样本量中，击球率是 .000。
现在，假设我想模拟一场 9 局比赛，其中对方球队的每个击球手都是左撇子。如果我只考虑 3 名左撇子击球手的小样本量，投手理论上不会让对手击出安打，并三振 18 名击球手，从而打出一场非凡的完美比赛。我们知道这是完全不现实的。
除了抛弃小样本量并仅使用针对右撇子击球手采样的数据外，我该如何考虑非常小样本量的结果？
我假设当两个样本量都足够大时，我可以使用左撇子 vs 左撇子数据进行模拟，而无需考虑左撇子 vs 右撇子数据。但是，什么时候需要将两个样本的数据考虑在内才能最好地模拟结果？例如，如果左 vs 左数据占组合样本的 33%，左 vs 右数据占数据的 67%，模拟应该考虑两个样本，还是只考虑左 vs 左样本？换句话说，在模拟仅测试较小样本量情况的场景时，什么时候需要将较大的样本量考虑在内？
这里有任何提示吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654966/factoring-a-small-sample-size-into-a-larger-sample-size-for-the-purpose-of-simul</guid>
      <pubDate>Thu, 26 Sep 2024 17:56:29 GMT</pubDate>
    </item>
    <item>
      <title>R 中的大面板数据回归软件包[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654962/packages-for-big-panel-data-regression-in-r</link>
      <description><![CDATA[是否可以对具有 10,000 个对象 ($N$) 的面板数据进行回归分析，每个对象具有 $2,000$ 个观测值（时间序列长度，$T$）？如果可以，R 中的哪个包可以处理这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/654962/packages-for-big-panel-data-regression-in-r</guid>
      <pubDate>Thu, 26 Sep 2024 16:47:25 GMT</pubDate>
    </item>
    <item>
      <title>计算时间序列中的分类阈值</title>
      <link>https://stats.stackexchange.com/questions/654960/calculate-classification-thresholds-in-time-series</link>
      <description><![CDATA[我需要一些想法来解决某个问题。我有一个包含过去三年降水数据的时间序列。数据以小时为间隔记录。我想将降水级别分为：无、低、中等、强烈和严重。
我的想法是计算阈值并根据每个值所属的间隔为其分配标签。我的第一个想法是使用百分位数，但问题是数据有许多等于 0 的值。因此，我删除了值 0 并计算了四分位数，因为 0 值对应于标签无。计算出的四分位数没有给我正确的分类间隔。间隔如下：

降水量 = 0 -&gt;无


降水量 &gt; 0 且降水量&lt;= 0.1 -&gt; 低


降水量 &gt; 0.1 且降水量&lt;= 0.2 -&gt; 中等


降水量 &gt; 0.2 且降水量&lt;= 0.6 -&gt; 强烈


降水量 &gt; 0.6 -&gt; 严重

我的第二个想法是使用平均值和标准差。为此，我还从计算中删除了 0 值。先验的想法是使用间隔：从 0 到平均值-std，从平均值-std 到平均值，从平均值到平均值+std 和 大于平均值+std。但是 平均值 和 std 的值分别为 0.61 和 1.13，因此 平均值-std = -0.52 是无效值。
最后查看数据的分布，我做出了这样的分类

降水量 = 0 -&gt; 无


降水量 &gt; 0 和降水量&lt;= 平均值+2std -&gt; 低


降水量 &gt;平均值+2std 且降水&lt;= 平均值+10std ——&gt; 中等


降水 &gt; 平均值+10std 且降水&lt;= 平均值+20std ——&gt; 强烈


降水 &gt; 平均值+20std ——&gt; 严重


虽然这些阈值可能对这些数据有效，但我不确定它们是否可用于对来自其他地区的降水值进行分类。这就是为什么我正在寻找一个想法来帮助我计算对我获得的任何时间序列都有效的阈值。
提前谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654960/calculate-classification-thresholds-in-time-series</guid>
      <pubDate>Thu, 26 Sep 2024 16:14:13 GMT</pubDate>
    </item>
    <item>
      <title>PCA 和数据的自然变化</title>
      <link>https://stats.stackexchange.com/questions/654957/pca-and-natural-variation-in-the-data</link>
      <description><![CDATA[我想知道 PC（主成分）范围与数据中的自然变化之间的关系是什么。
为了测试这一点，我从两个具有不同标准差的正态分布中生成随机值，如下所示。我预计由 $N(0,10)$ 生成的第二组在 PC 成分中具有更长的范围，但有时并非如此。例如，在下面的输出中，PC 范围为：
 [,1] [,2]
PC1 6.578774 6.231871
PC2 5.885548 5.859284

R 代码：
# 设置可重复性的种子
set.seed(123456789)

# 生成随机数据
n = 1500
x = matrix(rnorm(n), ncol = 10)
y = matrix(rnorm(n, 0, 10), ncol = 10)

# 对两个数据集执行 PCA
p1 = prcomp(x, scale. = TRUE,center = TRUE)
p2 = prcomp(y, scale. = TRUE,center = TRUE)

# 设置两个图的绘图区域并排
par(mfrow = c(1, 2))

# 绘制数据集 1 的 PCA
plot(
p1$x[, 1],
p1$x[, 2],
main = &quot;数据集 1 的 PCA。N(0,1)&quot;,
xlab = &quot;PC1&quot;,
ylab = &quot;PC2&quot;,
col = &quot;blue&quot;
)

# 绘制数据集 2 的 PCA
plot(
p2$x[, 1],
p2$x[, 2],
main = &quot;数据集 2 的 PCA。N(0,10)&quot;,
xlab = &quot;PC1&quot;,
ylab = &quot;PC2&quot;,
col = &quot;red&quot;
)

f=function(x){
max(x)-min(x)
}
cbind(apply(p1$x, 2, f), apply(p2$x, 2, f))[1:2,]

]]></description>
      <guid>https://stats.stackexchange.com/questions/654957/pca-and-natural-variation-in-the-data</guid>
      <pubDate>Thu, 26 Sep 2024 15:40:46 GMT</pubDate>
    </item>
    </channel>
</rss>