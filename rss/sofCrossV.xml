<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 06 Dec 2024 12:34:57 GMT</lastBuildDate>
    <item>
      <title>能否说出哪个术语更大？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658373/is-it-possible-to-say-which-term-is-grater</link>
      <description><![CDATA[比较以下内容：
第一次求和：对于 X∼Binomial(n−1,p)，𝑃 ( 𝑋 ≥ 𝑘 − 1 )。
第二次求和：对于 X∼Binomial(n,p)，P(X≥k)。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658373/is-it-possible-to-say-which-term-is-grater</guid>
      <pubDate>Fri, 06 Dec 2024 12:10:45 GMT</pubDate>
    </item>
    <item>
      <title>向非数学专业的学生教授单方面测试[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658371/teaching-one-sided-tests-to-non-mathematical-students</link>
      <description><![CDATA[据我所知和教学经验，大多数参加第一门统计推断课程的学生很难理解统计检验的含义（尤其是单侧检验的方选择）。此外，许多学生会在没有进一步数学学习的情况下将统计检验应用于各种应用科学。特别是，他们可能会在查看数据后选择测试的方，这意味着 I 型错误不受控制。
顺便说一句，许多统计推断课程涉及双边置信区间，但不涉及单侧置信区间。为什么测试不是这样？
在大多数简单情况下，双边检验只不过是一种结合两种单侧检验的（平衡）多重检验方法。特别是，如果拒绝 $H_0$，它自然会给出应该接受哪种单侧替代方案。顺便说一句，这个事实很少被教授：学生被告知要接受$H_0$的补集，这个补集不太精确。
当然，有些情况下双边测试不太自然。不过，我认为非数学学生很少遇到这些情况。
因此，主要问题是：为什么我们不只教授双边测试（至少在第一步）？]]></description>
      <guid>https://stats.stackexchange.com/questions/658371/teaching-one-sided-tests-to-non-mathematical-students</guid>
      <pubDate>Fri, 06 Dec 2024 10:44:12 GMT</pubDate>
    </item>
    <item>
      <title>从 copula 生成随机样本的样本大小</title>
      <link>https://stats.stackexchange.com/questions/658369/sample-size-in-generating-random-samples-from-copula</link>
      <description><![CDATA[我见过许多使用 copula 的论文，这些论文从不同的 copula 系列中生成了随机样本。具体来说，其中大多数（或许多）从 copula 中生成了 1000 个随机样本。我想知道选择这个数字而不是其他样本量的原因是什么？以下图片取自本文。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658369/sample-size-in-generating-random-samples-from-copula</guid>
      <pubDate>Fri, 06 Dec 2024 10:18:13 GMT</pubDate>
    </item>
    <item>
      <title>重测信度估计的受试者人数</title>
      <link>https://stats.stackexchange.com/questions/658368/number-of-subjects-for-test-retest-reliability-estimates</link>
      <description><![CDATA[我正在设计一项研究，旨在评估某项运动耐力测试的重测信度，我将按照 Weir (2005) 使用 ICC(3,1) 进行计算。
我想大致了解一下我应该在我的研究中招募多少个受试者，以便在估计我的测试的 ICC 时获得合理的间隔。
有没有办法可以提前计算出这样的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/658368/number-of-subjects-for-test-retest-reliability-estimates</guid>
      <pubDate>Fri, 06 Dec 2024 10:14:57 GMT</pubDate>
    </item>
    <item>
      <title>根据二元变量制定信用评级（最好使用 R 语言）</title>
      <link>https://stats.stackexchange.com/questions/658366/develop-credit-rating-based-on-binary-variable-in-r-preferably</link>
      <description><![CDATA[我在 R 中处理信用数据。我有一个贷款数据集，其中包含借款人和信用特定变量以及二元指标违约/不违约。第一步，我进行 logit 并获取违约概率 (PD)。接下来我想做什么：
根据这些 PD 建立类似信用评级模型的东西。例如，类别 1：PD&lt;0.2，类别 2：0.2
我认为基于 PD 和其他一些特征，我可以进行聚类分析，然后将这些聚类用作有序 logit 中的因变量或类似的东西。但我害怕相关性和其他东西。我也对证明最佳聚类数感到困惑。我该如何选择？如果您可以提供 R 代码思路就好了，但不一定]]></description>
      <guid>https://stats.stackexchange.com/questions/658366/develop-credit-rating-based-on-binary-variable-in-r-preferably</guid>
      <pubDate>Fri, 06 Dec 2024 08:49:39 GMT</pubDate>
    </item>
    <item>
      <title>分类因变量 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658365/categorical-dependent-variable</link>
      <description><![CDATA[我正在尝试构建机器学习模型，其中因变量是分类变量，并且有超过 60 个值。它们不是序数，也不遵循任何等级。
关于如何处理这个问题，有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658365/categorical-dependent-variable</guid>
      <pubDate>Fri, 06 Dec 2024 07:45:40 GMT</pubDate>
    </item>
    <item>
      <title>如何检验二分重复测量结果与连续调节变量之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/658364/how-to-test-for-interaction-between-dichotomous-repeated-measures-outcome-and-co</link>
      <description><![CDATA[在我的资料集中，参与者被问及在销售演示之前和之后是否计划购买（是/否）。预计人们在销售演示之后比之前更有可能回应购买意向（即“是”）。
但是，我们也有收入数据（连续变量），并希望测试收入是否与时间（销售演示之前与之后）相互作用以预测购买意向。
我们预计大多数人会在销售演示之前对购买意向回答“否”。但是，我们推测，在演示之后，收入较高的人更有可能将他们的意向改为“是”，而收入较低的人仍然会说“否”。
在这种情况下，哪种类型的测试合适？
我知道我可以将收入二分（例如中位数分割）并运行卡方检验，但如果可能的话，我希望保持收入连续。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658364/how-to-test-for-interaction-between-dichotomous-repeated-measures-outcome-and-co</guid>
      <pubDate>Fri, 06 Dec 2024 07:29:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么在用偏移量 = log(population) 计数的拟泊松 GLM 拟合之前对数据进行分组时会得到不同的标准误差？</title>
      <link>https://stats.stackexchange.com/questions/658361/why-do-i-get-different-standard-errors-when-i-group-the-data-before-fitting-a-qu</link>
      <description><![CDATA[在拟合拟泊松之前对数据进行分组在理论上是否正确，还是我应该不进行分组？
评论以及 R 代码示例发布如下。
我注意到，在拟合肿瘤计数的拟泊松 GLM 之前对数据进行分组时，我得到了不同的标准误差，偏移量 = log(Population)。如果我使用泊松系列而不是拟泊松系列，就不会发生这种情况，所以我很惊讶。
以下是 R 代码和示例数据，说明了我的问题：
## 创建分组和未分组数据集，其中按 Psych.Profile 和 Cig 分组时，肿瘤和人口的总和相同
## 分组数据
data_grouped &lt;- data.frame(Tumor = c(45,77,95,92,103,12,29,31,43,56,30,36,62,57,71)
,Pop = c(24795,32125,34706,23440,14133,11946,22781,14566,15654,10097,50711,35332,41707,26319,22978)
,Psych.Profile = factor(c(&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;), levels = c(&quot;C&quot;, &quot;B&quot;, &quot;A&quot;))
,Cig = c(0,0.5,1,1.5,2,0,0.5,1,1.5,2,0,0.5,1,1.5,2))

## 未分组数据。这个分组数据的第一行被分成 45 行，每行 1 个肿瘤，人口 = 24795/45 = 551
data_ungrouped &lt;- data.frame(Tumor = c(rep(1,45),77,95,92,103,12,29,31,43,56,30,36,62,57,71)
,Pop = c(rep(551,45),32125,34706,23440,14133,11946,22781,14566,15654,10097,50711,35332,41707,26319,22978)
,Psych.Profile = factor(c(rep(&#39;A&#39;,45),&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;), levels = c(&quot;C&quot;, &quot;B&quot;, &quot;A&quot;))
,Cig = c(rep(0,45),0.5,1,1.5,2,0,0.5,1,1.5,2,0,0.5,1,1.5,2))

## 将拟泊松模型拟合到每个数据集
model_grouped &lt;- glm(Tumor ~ Cig + Psych.Profile, family = quasipoisson((link = &quot;log&quot;)), offset = log(Pop), data = data_grouped)
model_ungrouped &lt;- glm(Tumor ~ Cig + Psych.Profile, family = quasipoisson((link = &quot;log&quot;)), offset = log(Pop), data = data_ungrouped)

&gt; coef(summary(model_grouped))
估计标准差。误差 t 值 Pr(&gt;|t|)
(截距) -7.3071846 0.09242152 -79.06367 1.649769e-16
Cig 0.7661623 0.05563362 13.77157 2.791780e-08
Psych.ProfileB 0.3887326 0.10225686 3.80153 2.935492e-03
Psych.ProfileA 0.7645370 0.08235288 9.28367 1.545673e-06

&gt; coef(summary(model_ungrouped))
估计标准差误差 t 值 Pr(&gt;|t|)
(截距) -7.3071846 0.04133216 -176.79175 1.814343e-77
Cig 0.7661623 0.02488011 30.79417 2.303794e-36
Psych.ProfileB 0.3887326 0.04573066 8.50048 1.343316e-11
Psych.ProfileA 0.7645370 0.03682933 20.75892 1.081513e-27

## 系数的标准误差下降。例如Cig 从 0.05563362 降至 0.02488011


对数据进行分组的一个动机是，我可以显著减少行数并更轻松地处理更大的数据集。]]></description>
      <guid>https://stats.stackexchange.com/questions/658361/why-do-i-get-different-standard-errors-when-i-group-the-data-before-fitting-a-qu</guid>
      <pubDate>Fri, 06 Dec 2024 04:01:11 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用 Nadaraya-Watson 估计量来估计随机过程的条件期望吗？</title>
      <link>https://stats.stackexchange.com/questions/658359/can-i-use-the-nadaraya-watson-estimator-to-estimate-conditional-expectation-of-s</link>
      <description><![CDATA[我想估计以下条件期望
$$
E\left[ Y(t,\beta) \mid X=x \right],
$$
其中$X$和$Y$是连续随机变量。
我想使用 Nadaraya–Watson 估计量来估计
$$
\hat{E}\left[ Y(t,\beta) \mid X=x \right]=\frac{\sum_{i=1}^nY_i(t,\beta)K_h(x-X_i)}{\sum_{i=1}^nK_h(x-X_i)}。
$$
这是真的吗？
在某些条件下它是否具有一致收敛性质？
$$
\sup_{t, \beta,x}\left|\hat{E}\left[ Y(t,\beta) \mid X=x \right]-E\left[ Y(t,\beta) \mid X=x \right]\right|\rightarrow 0 \quad a.s.
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/658359/can-i-use-the-nadaraya-watson-estimator-to-estimate-conditional-expectation-of-s</guid>
      <pubDate>Fri, 06 Dec 2024 03:22:51 GMT</pubDate>
    </item>
    <item>
      <title>测试预测准确性 - 异常值 [附示例]</title>
      <link>https://stats.stackexchange.com/questions/658353/testing-forecasting-accuracy-outliers-with-example</link>
      <description><![CDATA[我有一个简单的模型，可以生成预测值。该模型适用于每小时数据。现在，我只对带有标记的观察结果感兴趣。我想确定预测值与实际值存在显著差异的地方。
我正在考虑以下两个指标——哪一个效果更好？ （请参阅下面代码中的选项 1 和选项 2）
或者我应该关注 RMSE、MAE 等？
# 示例数据：实际值和预测值
实际 &lt;- c(100, 110, 95, 120, 105, 130, 125)
预测 &lt;- c(102, 108, 97, 150, 103, 128, 123)

plot(actual, type = &quot;o&quot;, col = &quot;blue&quot;, pch = 16, lwd = 2,
ylim = range(c(actual, Forecasted)), ylab = &quot;Values&quot;,
xlab = &quot;Index&quot;, main = &quot;Actual vs Forecasted Values&lt;)
lines(forecasted, type = &quot;o&quot;, col = &quot;red&quot;, pch = 16, lwd = 2)

# 计算残差（实际值与预测值之间的差异）
residuals &lt;- actual - Forecasted

# 定义阈值：
# 选项 1：（例如，2 个标准差）
dynamic_threshold &lt;- 2 * sd(residuals)
dynamic_outliers &lt;- abs(residuals) &gt; dynamic_threshold

# 选项 2：（例如，基于实际数据的平均值和标准差的 2 个标准差）
upper_threshold &lt;- mean(actual)+2 * sd(actual)
lower_threshold &lt;- mean(actual)-2 * sd(actual)

outliers_forecasted &lt;- (forecasted &gt; upper_threshold) | (forecasted &lt; lower_threshold)
]]></description>
      <guid>https://stats.stackexchange.com/questions/658353/testing-forecasting-accuracy-outliers-with-example</guid>
      <pubDate>Thu, 05 Dec 2024 23:32:48 GMT</pubDate>
    </item>
    <item>
      <title>寻找适合在 SPSS 上运行的模型，同时考虑同一主题的多个测量值</title>
      <link>https://stats.stackexchange.com/questions/658351/looking-for-appropriate-model-to-run-on-spss-while-accounting-for-multiple-measu</link>
      <description><![CDATA[我有两组（A组和B组），它们具有不同的基线特征。所有受试者都经过5种不同的体重测试（每种两次），并测量结果变量。如果我的解释不清楚，下表概述了研究设计。



样本
组
0 磅
5 磅
10 磅
15 磅
20 磅




#1 试验 1
A







#1 试验2
A







#2 试验 1
A







#2 试验 2
A







#3 试验1
B







#3 试验 2
B







#4 试验 1
B







#4 试验2
B








我想知道：

5 个权重中结果变量的变化是否因组（A 或 B）而异？换句话说，是否存在交互作用？我还想知道组和权重的主要影响。

如何解释每个样本两次承受相同重量的事实。让每个受试者经历每种条件两次是增加样本量的一种方法，因为很难获得用于此类研究的样本。在输入数据时，我是否应该将它们作为单独的样本输入到 SPSS 中，或者由于它们是同一个样本，我是否需要以任何方式将它们关联起来？


我想这将是一个线性混合模型，但我不太清楚如何处理问题 2。
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658351/looking-for-appropriate-model-to-run-on-spss-while-accounting-for-multiple-measu</guid>
      <pubDate>Thu, 05 Dec 2024 22:22:25 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 匹配对符号秩和相关性（Pearson、Spearman 或 Kendall）</title>
      <link>https://stats.stackexchange.com/questions/658344/wilcoxon-matched-pair-signed-rank-and-correlation-pearson-spearman-or-kendall</link>
      <description><![CDATA[根据出版物《提取重复测量设计的元分析前后相关性》https://matthewbjane.quarto.pub/pre-post-correlations/，如果配对 t 检验的 t 统计量值可用，则可以计算相关样本中前后得分之间的 Pearson 相关性。
pre_mean &lt;- 12.62
pre_sd &lt;- 3.845
post_mean &lt;- 18.33
post_sd &lt;- 5.155
paired_t &lt;- 10.52
n &lt;- 78

r &lt;- (paired_t^2*(sd_pre^2 + sd_post^2)-n*(post_mean-pre_mean)^2) / 
(2*paired_t^2*sd_pre*sd_post)

r

还提到，可以根据配对 t 检验的 p 值计算 Pearson 相关性。
pre_mean &lt;- 12.62
pre_sd &lt;- 3.845
post_mean &lt;- 18.33
post_sd &lt;- 5.155
pval &lt;- 1.5e-16 # 来自配对 t 检验
n &lt;- 78

# 从 p 值获取配对 t
paired_t &lt;- qt(pval/2, n-1, lower.tail = FALSE)

r &lt;- (paired_t^2*(sd_pre^2 + sd_post^2)-n*(post_mean-pre_mean)^2) /
(2*paired_t^2*sd_pre*sd_post)

我在网站上找到了类似的问题
重复测量设计的提取前后相关性
但我找不到我想要的答案。
问题：这些公式可以扩展到 Wilcoxon 符号秩检验 及其对应的 p 值吗？如果我们在运行 Wilcoxon 符号秩检验后知道 p 值（甚至可以访问 W 统计量），我们可以计算相关性（Pearson、Spearman 或 Kendall）吗？
问题：如果我们的样本量很大，我们可以说 Wilcoxon 符号秩检验和配对 t 检验的结果趋于收敛吗？因为如果答案是肯定的，也许我可以将 p 值（来自 Wilcoxon 符号秩检验）放入计算相关性的公式中（基于配对 t 检验的 p 值）。
注意：在元分析领域（在重复测量设计中），相关性值（Pearson、Spearman 或 Kendall）对于计算效果大小是必要的。我们可以获得一些信息（例如平均值、标准差、p 值和检验类型——无论是配对 t 检验还是 Wilcoxon 符号秩检验），但没有一篇出版物提供前后分数之间的相关值。我们需要找到一种方法来根据我们拥有的信息计算相关值。一些参考资料提供了公式，用于在运行配对 t 检验后根据可用的 t 统计量和 p 值计算相关性。所以，我正在寻找一种方法来计算那些应用 Wilcoxon 符号秩检验 的出版物的相关值（Spearman 或 Kendall）。]]></description>
      <guid>https://stats.stackexchange.com/questions/658344/wilcoxon-matched-pair-signed-rank-and-correlation-pearson-spearman-or-kendall</guid>
      <pubDate>Thu, 05 Dec 2024 19:25:03 GMT</pubDate>
    </item>
    <item>
      <title>从相反方向的回归方程进行预测[重复]</title>
      <link>https://stats.stackexchange.com/questions/658323/prediction-from-regression-equation-in-opposite-direction</link>
      <description><![CDATA[假设我有以下简单的线性回归
$y = \alpha + \beta X + \epsilon$
这里$X$是有序分类变量，假设类别用 1 到 12 表示。
现在在典型的回归方程中，我们根据$X$预测$y$的值如下
$\hat{y} = \hat{\alpha} + \hat{\beta}X$
但是这里我的问题不同，给定$y$的值，我想预测$X$。
为此，我认为我需要为 $X$ 的每个类别构建可能的 $y$ 值的连续且不重叠的区间，即 $y$ 将有 10 个重叠区间，例如
如果 $y_{Val}$ 落在 $ \left( -\inf, y_1 \right]$ 内，那么我会预测 $X = 1$ 的值
如果 $y_{Val}$ 落在 $ \left( y_1, y_2 \right]$ 然后我会预测 $X = 2$ 的值，依此类推
我的目标是最好地估计 $y_1, y_2, ..,y_9$ 的值。
我的数据如下所示
]]></description>
      <guid>https://stats.stackexchange.com/questions/658323/prediction-from-regression-equation-in-opposite-direction</guid>
      <pubDate>Thu, 05 Dec 2024 13:16:05 GMT</pubDate>
    </item>
    <item>
      <title>数据符合除正态性之外的所有线性假设。我的下一步应该怎么做？</title>
      <link>https://stats.stackexchange.com/questions/658300/data-passing-all-linearity-assumptions-except-normality-what-should-my-next-ste</link>
      <description><![CDATA[我需要为一系列具有相同问题的数据集构建模型。
编辑：下图显示了我的一个数据集的示例，其中拟合了一条线性回归线。它是体积 (y) 与日期时间 (x)，目标是确定 1. 体积是否随时间发生显着变化，以及 2.（不如 1 重要但仍然重要）如果有，则预测未来的体积可能是多少。

“目测”让我相信数据最适合线性回归。我的数据似乎通过了同质性假设 (leveneTest pval &gt; 0.05) 和线性假设 (需要对独立性进行更多研究)。 没有点的 Cook 距离 &gt; 0.5，表明没有高度有影响力的异常值。 但是，我的线性图表未通过正态性检验。
对于 shapiro.test(residuals(model)) 检查，P-val 为 &lt; 0.05。
qq 图的尾部下降：

我试过平方根 &amp; y 的 Box-Cox 变换，以及更稳健的建模，如 rlm 和 glm（针对转换和未转换的数据），但这些都产生了类似的结果。
我承认，通常没有办法转换数据以使其正常化。
我所有的问题都围绕着同一个主题：我接下来该怎么做才能对这些数据进行建模？
我还能合理地使用线性回归来对这些数据进行建模吗？
由于我的大多数数据集都超过 500 分，我可以合理地声称 C.L.T 吗？
我可以使用其他建模方法吗？或者我完全错过了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658300/data-passing-all-linearity-assumptions-except-normality-what-should-my-next-ste</guid>
      <pubDate>Thu, 05 Dec 2024 06:29:11 GMT</pubDate>
    </item>
    <item>
      <title>单调变换保留概率直觉</title>
      <link>https://stats.stackexchange.com/questions/658283/monotonic-transformation-preserving-probabilities-intuition</link>
      <description><![CDATA[我正在努力对为什么单调变换在连续情况下保留相对概率形成深刻的直觉。虽然我从表面上理解这个想法，特别是对于离散情况（在这种情况下更容易用计数来思考），但当我试图将其扩展到连续分布时，我失去了直觉。
我认为到目前为止我理解了以下内容：

单调变换$f(x)$（例如，$f(x) = x^2$ on $x \geq 0$）保留了结果的顺序。如果$x_1 &lt; x_2$，则$f(x_1) &lt; f(x_2)$。
在离散情况下，这种顺序保持与映射的一对一性质相结合，帮助我理解了为什么相对概率不会改变——即使值被转换，计数仍然保持成比例。
在连续情况下，概率密度函数 (PDF) 根据变换的导数而变化：
$$p_Y(y) = p_X(f^{-1}(y)) \cdot \left| \frac{d}{dy} f^{-1}(y) \right|,$$
其中 $f^{-1}(y)$ 是 $f(x)$ 的倒数。但是我很难将此公式与直观/视觉理解联系起来，以了解为什么区间内的相对概率保持不变。

我遇到的问题：

对于像$f(x) = x^2$这样的变换，它会非均匀地拉伸输入空间（例如，$1 \to 1, 2 \to 4, 10 \to 100$），感觉较大的值可能会不成比例地主导概率。例如，区间 $[10, 11]$ 映射到 $[100, 121]$，这比 $[1, 2] \to [1, 4]$ 大得多。
我的直觉失败了，因为我很难理解如何通过导数 $\frac{1}{f&#39;(x)}$ (或 $\frac{1}{2\sqrt{y}}$ for $f(x) = x^2$) 进行调整来“平衡”这种拉伸效应。在离散情况下，我可以想象一对一映射就像简单的重新标记一样，其中相对计数保持不变。但对于连续情况，我无法找到相同的满足感。

我想了解：

变量变化公式如何确保相对概率（例如，$P(Y \in [a, b]) / P(Y \in [c, d])$）在单调变换下得以保留？除了信任公式之外，还有其他方法可以建立直觉吗？
我应该如何从几何角度思考这种转变？将概率视为“密度质量”有帮助吗？重新分配，如果是这样，为什么这种重新分配不会扭曲相对大小？
是否有具体示例或可视化可以帮助弥补我的直觉差距，特别是对于连续分布？

感谢您的任何见解！
更新
正如 Whuber 善意指出的那样，我最初的假设/问题是错误的，这也许就是它让我感到困惑的原因。我在下面附上了一个参考资料，我显然误解了它以得出这个结论。仍然非常感谢你的想法。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658283/monotonic-transformation-preserving-probabilities-intuition</guid>
      <pubDate>Wed, 04 Dec 2024 21:19:40 GMT</pubDate>
    </item>
    </channel>
</rss>