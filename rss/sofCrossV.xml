<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 11 Nov 2024 06:24:29 GMT</lastBuildDate>
    <item>
      <title>当数据缺失时，如何根据分层随机抽样估计总体平均值？</title>
      <link>https://stats.stackexchange.com/questions/657061/how-do-you-estimate-overall-population-means-from-stratified-random-sampling-whe</link>
      <description><![CDATA[对某国 20 个县的 200 户家庭进行电话调查。这 20 个县中的每一个县都作为一个层。每个县都从县电话簿中选择了一组电话号码。当无法联系到某个家庭或该家庭不愿意参与研究时，就会使用另一个电话号码，直到达到该层所需的样本量。该调查调查了每个家庭的居住人数。
我需要找出这所房子里居住的平均人数。以及 90% 的 CI。
我得到的数据集提供了县名、每个县的人口、每个县的样本量以及联系到的每个家庭的家庭人数。
我知道如何做到这一点，我需要找到
$$\bar{y}_{str}=\Sigma^{20}_{h=1} \frac{N_h}{N}\bar{y}_h$$
其中 h 表示每个县，$N_h$ 表示每个县 h 的人口，N 表示该国的总人口，$\bar{y}_h$ 表示样本平均值。
但是，有两个县不在我得到的数据集中，所以我不知道这些县的人口规模县，因此没有准确的 N 值。即使这些县没有人接受调查（至少我认为这是数据集中没有样本的原因），这些样本的人口也会对总体人口平均值产生影响，不是吗？
此外，为了计算 CI，我需要知道每个层中样本的标准差。但是，除了数据集中没有出现的两个县外，还有另一个县只调查了一所房子，因此我无法计算出这个样本的标准差，因为只有一个观察值。
但是，如果一个样本只有一个观察值，我不明白我该如何计算 CI，因为这个样本的标准差不是 0，而是未定义的。
可以后分层并合并较小的样本以创建较大的样本，但这可以是随机的吗？或者我可以完全省略缺失的县和只有一个观察单位的县吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657061/how-do-you-estimate-overall-population-means-from-stratified-random-sampling-whe</guid>
      <pubDate>Mon, 11 Nov 2024 04:44:41 GMT</pubDate>
    </item>
    <item>
      <title>针对极高维度（约 14,000 个特征）的具有加权重要性的快速特征选择</title>
      <link>https://stats.stackexchange.com/questions/657060/fast-forward-feature-selection-with-weighted-importance-for-very-high-dimension</link>
      <description><![CDATA[我正在处理一个包含 14,000 个特征的数据集，我想为每个特征拟合一个模型，以便我可以使用其他特征对其进行回归。但是，我相信只有一小部分（大约 10-15 个特征）与每个模型相关。
我的挑战是找到一个满足以下标准的特征选择算法：

前向选择：我更喜欢一种根据特征重要性迭代添加特征的方法，因为这符合我对小而相关的子集的期望。
速度和效率：算法需要具有计算效率，特别是因为我计划重复执行特征选择。理想情况下，它针对大型数据集的重复使用进行了优化（就像图形 LASSO 是 LASSO 的优化版本一样）。
加权特征重要性：与 LASSO 惩罚类似，我希望能够在选择过程中加权各个特征的重要性。

在过去的两周里，我一直在探索图形 LASSO。虽然它可以为高维数据提供快速计算并允许加权惩罚，但不幸的是，它在我的笔记本电脑上仍然太慢了。欢迎大家提出所有想法和建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/657060/fast-forward-feature-selection-with-weighted-importance-for-very-high-dimension</guid>
      <pubDate>Mon, 11 Nov 2024 02:08:38 GMT</pubDate>
    </item>
    <item>
      <title>估计 Fisher 信息为 0 的回归系数？</title>
      <link>https://stats.stackexchange.com/questions/657057/estimating-regression-coefficients-where-the-fisher-information-is-0</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657057/estimating-regression-coefficients-where-the-fisher-information-is-0</guid>
      <pubDate>Mon, 11 Nov 2024 00:51:27 GMT</pubDate>
    </item>
    <item>
      <title>证明当 $X_1,\cdots,X_n\sim U(0,\theta)$ 时检验最有效</title>
      <link>https://stats.stackexchange.com/questions/657054/prove-that-a-test-is-most-powerful-when-x-1-cdots-x-n-sim-u0-theta</link>
      <description><![CDATA[设$X_1,\cdots,X_n\sim U(0,\theta),\theta &gt;0$为独立随机变量。我想证明 $\phi :\mathbb{R}^n\to [0,1]$ 由 $\phi (x):=\begin{cases}1,&amp;\theta _0&lt;x_{(n)}\vee x_{(n)}\leq \theta _0\alpha ^{1/n}\\0,&amp;\text{otherwise}\end{cases}$ 给出，是 $\alpha\in (0,1)$ 级别最强的测试，可测试 $H:\theta=\theta _0$ vs $K:\theta =\theta _1&gt;\theta _0$。

我能够证明 $\phi$ 具有级别 $\alpha$。为了证明 $\phi$ 最强大，我尝试使用 Neyman-Pearson 引理，但失败了。
首先，我尝试找到一个常数 $k\geq 0$，使得对于所有 $x\in\mathbb{R}^n$，$\phi (x)=\begin{cases}1,&amp;f_{\theta_1}(x)&gt;kf_{\theta_0}(x)\\0,&amp;\text{otherwise}\end{cases}$ 成立，以便使用 NP 引理的&quot;充分性&quot; 部分。我知道，通过 $k=(\theta _1/\theta _0)^n$ 我们可以得出结论，给定任意 $x\in\mathbb{R}^n$，不等式 $f_{\theta_1}(x)&gt;kf_{\theta_0}(x)$ 意味着 $\phi (x)=1$。但是，我无法证明，给定 $x\in\mathbb{R}^n$，等式 $\phi (x)=1$ 意味着 $f_{\theta_1}(x)&gt;kf_{\theta_0}(x)$。

我的问题是：如何证明测试 $\phi$ 对测试 $H:\theta=\theta _0$ 与 $K:\theta =\theta _1&gt;\theta _0$ 最有效。]]></description>
      <guid>https://stats.stackexchange.com/questions/657054/prove-that-a-test-is-most-powerful-when-x-1-cdots-x-n-sim-u0-theta</guid>
      <pubDate>Sun, 10 Nov 2024 23:12:49 GMT</pubDate>
    </item>
    <item>
      <title>对于 t 分布，df = n-1。n 代表什么？</title>
      <link>https://stats.stackexchange.com/questions/657053/for-a-t-distribution-df-n-1-what-does-n-represent</link>
      <description><![CDATA[根据 2 人的建议从 Math Stack Exchange 交叉发布。
我知道 $t$ 分布有一个参数：自由度 (df) 的数量。
我还知道 $\mathrm{df} = n - 1$。
但是，$n$ 究竟代表什么？
我听说过几种含义：

&quot;数据集中的数据点数量。&quot; 这听起来不对。如果我有 $100$ 个数据点，但 $t$ 分布（其中 $\mathrm{df}=50$）比 $\mathrm{df}=99$ 更能模拟该分布，那么我为什么要强制 $\mathrm{df}$ 为 99？

&quot;您用来从样本平均值 $\bar{x}$ 定义 $t$ 统计量的正态随机变量的数量。&quot; 这听起来也不对。我知道
$$t = \frac{\bar{x} - \mu}{s / \sqrt{n}}.$$
然而，这看起来更像是一个数学关系，而不是$t$的定义。如果我不从正态随机变量开始会怎样？

]]></description>
      <guid>https://stats.stackexchange.com/questions/657053/for-a-t-distribution-df-n-1-what-does-n-represent</guid>
      <pubDate>Sun, 10 Nov 2024 22:38:03 GMT</pubDate>
    </item>
    <item>
      <title>非参数直方图密度估计量的渐近偏差是多少？</title>
      <link>https://stats.stackexchange.com/questions/657051/what-is-the-asymptotic-bias-of-the-nonparametric-histogram-density-estimator</link>
      <description><![CDATA[我试图推导非参数直方图密度估计量的渐近偏差表达式，以便将其与核密度估计量的偏差进行比较。在符号方面，直方图定义为$\hat{h}(x)=(nl_n)^{-1}\sum^n_{i=1}I(a_n\leq x\leq b_n)$，其中$l_n=b_n-a_n$，$I$表示指示函数（也许这很简单，但我对此事不太熟悉）。我收到了一个提示，提示我需要假设极限 $(a_n - x)/l_n$ 和 $(b_n-x)/l_n$ 的存在。
到目前为止，我已经将估计值的期望表达为：
$E[\hat{h}(x)]=(l_n)^{-1}Pr(a_n\leq x\leq b_n)$。然后，我使用泰勒展开式围绕 $x$ 获得：
$f(u)\approx f(x)+f&#39;(x)(u-x)$。
因此我这样写，
$E[\hat{h}(x)]=(l_n)^{-1}Pr(a_n\leq x\leq b_n) \approx (l_n)^{-1}\int^{b_n}_{a_n} f(x)+f&#39;(x)(u-x)du$。
然而，我在这里卡住了。我猜想，对边界上的第一项 ($f(x)$) 进行积分将得出 $\int^{b_n}_{a_n}f(x)du=f(x)l_n$，这是由于 $b_n$、$a_n$ 和 $l_n$ 之间的关系。然后，$l_n$ 被抵消，剩下 $f(x)$。这是密度的真实值，所以我认为积分第二项 ($\int^{b_n}_{a_n} f&#39;(x)(u-x)du$) 必定构成偏差。
我是否使用了极限存在的假设？ 我如何计算积分中的第二项？我希望能够将其与核估计进行比较，该估计等于 $\frac{h^2}{2}f&#39;&#39;(x)\mu_2(K)$。是否有第二项的表示（我可以进一步开发它）以便能够这样做？
顺便说一句，我知道我已经从泰勒展开式中省略了 O(.)（为了方便）。
如果有人能帮助我，我将不胜感激。提前感谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/657051/what-is-the-asymptotic-bias-of-the-nonparametric-histogram-density-estimator</guid>
      <pubDate>Sun, 10 Nov 2024 22:08:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么回归模型比 LSTM 效果更好？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657050/why-regression-models-working-so-well-over-lstm</link>
      <description><![CDATA[我关注的是这个问题。

以下是我关注的问题的摘要。
我有以下任务要做：通过连续 3 天的训练来预测每个第 4 天。每天的数据代表一个尺寸为 24x25 的 CSV 文件。每个 CSV 文件的每个数据点都是像素。
现在，我需要这样做，使用训练数据第 1 天、第 2 天、第 3 天（即连续三天）预测第 4 天（即第 4 天），然后计算预测的第 4 天数据和原始第 4 天数据之间的 mse。我们称之为 mse1。
同样，我需要使用训练数据 day2、day3、day4 预测 day5（即第 5 天），然后计算 mse2（预测的第 5 天数据与原始的第 5 天数据之间的 mse）
我需要使用训练数据 day3、day4、day5 预测 day6（即第 6 天），然后计算 mse3（预测的第 6 天数据与原始的第 6 天数据之间的 mse）
..........
最后，我想使用训练数据 day90、day91、day92 预测 day93，计算 mse90（预测的第 93 天数据与原始的第 93 天数据之间的 mse）。
我想使用 Ridge 回归，线性回归和 LSTM 模型。每个模型都有 90 mse。
在随后的问题中，@Dave 给了我满意的答案。并且我按照@Dave实现我的模型。
准备数据：
# 为范围 (3, 93) 准备数据
X = np.array([data_flattened_scaled[i-3:i].flatten() for i in range(3, 93)]) # 形状：(90, 1800)
y = data_flattened_scaled[3:93] # 目标是每个序列中的第 4 天

LSTM 模型：
# ---------- LSTM 模型 ----------
X_lstm = np.array([data_flattened_scaled[i-3:i] for i in range(3, 93)]) # 形状：(90, 3, 600)
y_lstm = data_flattened_scaled[3:93].reshape(len(y), 1, 600) # 形状：(90, 1, 600)

lstm_model = Sequential()
lstm_model.add(LSTM(64, 激活=&#39;relu&#39;, 输入形状=(X_lstm.shape[1], X_lstm.shape[2])))
lstm_model.add(Dense(600))
lstm_model.compile(优化器=&#39;adam&#39;, 损失=&#39;mse&#39;)
lstm_model.fit(X_lstm, y_lstm, epochs=50, batch_size=8, verbose=1)
y_pred_lstm = lstm_model.predict(X_lstm)
residuals_lstm = [np.mean((y_lstm[i][0] - y_pred_lstm[i]) ** 2) for i in range(len(y_lstm))]

线性回归模型：
# ---------- 线性回归 ----------
lr_model = LinearRegression()
lr_model.fit(X, y)
y_pred_lr = lr_model.predict(X)
residuals_lr = [np.mean((y[i] - y_pred_lr[i]) ** 2) for i in range(len(y))]

岭回归模型：
# ---------- 岭回归 ----------
ridge_model = Ridge()
ridge_model.fit(X, y)
y_pred_ridge = ridge_model.predict(X)
residuals_ridge = [np.mean((y[i] - y_pred_ridge[i]) ** 2) for i in range(len(y))]


实施上述模型后我得到了什么：

问题是什么：当我为每个模型绘制 90 天的 90 mse 图表时，lstm 在整个 90 天内都出现峰值（这是正确的），但两个回归模型的 mse 最接近 0，我的问题是为什么回归模型效果这么好？
我的理解：我们不能使用 Ridge 和线性回归在这里，它们无法有效地捕获时间依赖性，并且缺乏对数据中的顺序模式进行建模的能力，因此不适合涉及每日模式的时间序列预测。因此，即使我们使用这些模型，我们也只能始终获得 MSE 0。除此之外，LSTM 模型是专门为顺序数据设计的。
我说得对吗？有人能帮我了解这里到底发生了什么吗？
我的数据样本例如第 1 天、第 2 天、第 3 天,第 4 天]]></description>
      <guid>https://stats.stackexchange.com/questions/657050/why-regression-models-working-so-well-over-lstm</guid>
      <pubDate>Sun, 10 Nov 2024 21:53:14 GMT</pubDate>
    </item>
    <item>
      <title>时间序列平稳性和消除虚假相关性的严格证明</title>
      <link>https://stats.stackexchange.com/questions/657049/rigorous-proofs-on-stationarity-and-reduction-of-spurious-correlations-in-time-s</link>
      <description><![CDATA[我理解时间序列分析中的平稳性至关重要，尤其是对于推断而言，因为它有助于降低伪回归的风险。在非平稳序列中，由于方差或均值的变化，相关性更有可能显得显著，从而导致对因果关系的误导性推断。
是否有严格的证明或理论解释支持这一点？具体来说，为什么随时间变化的非恒定方差会增加伪相关的可能性？平稳性如何增强暗示因果关系的相关性的可靠性？任何数学见解或参考资料都会有所帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/657049/rigorous-proofs-on-stationarity-and-reduction-of-spurious-correlations-in-time-s</guid>
      <pubDate>Sun, 10 Nov 2024 21:34:25 GMT</pubDate>
    </item>
    <item>
      <title>Excel中PDF的离散化</title>
      <link>https://stats.stackexchange.com/questions/657047/discretization-of-pdf-in-excel</link>
      <description><![CDATA[我正在尝试使用 excel 计算对数正态分布的期望值，不知道我做得对不对。我有 0 到 1 之间的一千个 X 步长，我用 LOGNORM.DIST 计算 PDF，平均值为 -3.5，标准差为 1.17183，因此期望值为 0.06 -&gt; Exp(mu+st.dev^2/2)。
现在，如果我对 x 和 p(x) 进行求和，我会得到 0.0579，所以我想知道我在离散化 PDF 的积分中遗漏了什么]]></description>
      <guid>https://stats.stackexchange.com/questions/657047/discretization-of-pdf-in-excel</guid>
      <pubDate>Sun, 10 Nov 2024 21:29:03 GMT</pubDate>
    </item>
    <item>
      <title>具有一般解释因素的预测校准</title>
      <link>https://stats.stackexchange.com/questions/657045/forecast-calibration-with-a-general-explanatory-factor</link>
      <description><![CDATA[我正在考虑对特朗普​​政府未来两年的执政情况做出一系列基于概率的预测。预测将是一系列命题，例如：

20% 的联邦将禁止堕胎。

这个想法是为了测试我的校准，即理想情况下，我的 20% 预测中的 20% 应该会实现，我的 50% 预测中的 50% 应该会实现，等等。
当我试图思考我的预测时，我很快遇到了一个潜在的问题，即所有预测都有一个共同的因素——我对 DJT 性格的评估。也许他最感兴趣的是赢得选举和获得掌声，在这种情况下，实施他的政策议程可能会几乎一事无成。或者他是一个有远见的人，之前被房间里的各种成年人所阻碍，而这些成年人这次不会在场。如果这种思路是正确的，那么我可能会在一个方向上完全出错，或者在另一个方向上完全出错。 （我觉得这会不公平地搞砸我的校准，因为我已经预见到了这个问题）。
我的问题是，是否有人对我如何将这个共同因素整合到我的预测集中有什么建议？
我的第一个想法是指定每个预测与这个因素的关系，如果一个预测成真，那么将增加所有其他预测的概率（每个命题指定的某个量）。当我试图找出如何做到这一点的细节时，不幸的是我被卡住了。有人对我如何做到这一点有什么建议吗？或者可以告诉我有人做过类似的事情吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657045/forecast-calibration-with-a-general-explanatory-factor</guid>
      <pubDate>Sun, 10 Nov 2024 20:44:40 GMT</pubDate>
    </item>
    <item>
      <title>有一个与用作随机效应的变量重叠的预测因子可以吗？</title>
      <link>https://stats.stackexchange.com/questions/657042/would-it-be-okay-to-have-a-predictor-that-overlaps-with-the-variable-used-as-a-r</link>
      <description><![CDATA[我将使用基于国家紧密度指数（数字）的预测因子，因此每个国家都有一个值。我将在 50 个国家/地区收集数据，但我预计不同国家/地区的参与者数量会有很大差异（预计每个国家/地区的最低参与者数量为 100 名）。
因此，我正在考虑将国家/地区添加为随机效应（因子）。但大多数国家/地区都有独特的预测因子值，其中五个国家/地区的紧密度得分相同。
我担心这可能会使模型变得奇异或扰乱结果，假设国家/地区的随机效应最终可能会吞噬预测因子的大部分可变性。这是我应该担心的事情吗？ （我还没有数据，但我知道结果变量将是二分的）。
数据预期结构示例：
participant_id consequence_variable tightness country 
x01 1 -0.2 USA 
x01 0 -0.2 USA 
x01 0 -0.2 USA 
x01 1 -0.2 USA 
x02 1 -0.2 USA 
x02 1 -0.2 USA 
x02 0 -0.2 USA 
x02 1 -0.2 USA 
x03 1 0.3 UK 
x03 1 0.3 UK 
x03 1 0.3 UK 
x04 0 0.5 FR 
x04 1 0.5 FR 
x04 1 0.5 FR
x04 0 0.5 FR 

预期模型：
glmer(outcome_variable ~ tightness + (1 | contestant_id) + (1 | country), data, family=binomial)
我想看看在紧密度较高的国家，对某些规范（结果）的遵守是否更为普遍。]]></description>
      <guid>https://stats.stackexchange.com/questions/657042/would-it-be-okay-to-have-a-predictor-that-overlaps-with-the-variable-used-as-a-r</guid>
      <pubDate>Sun, 10 Nov 2024 18:48:49 GMT</pubDate>
    </item>
    <item>
      <title>假设检验的 p 值</title>
      <link>https://stats.stackexchange.com/questions/657034/p-values-for-hypothesis-testing</link>
      <description><![CDATA[直观地讲，标准假设检验（其中检验统计量呈正态分布或近似正态分布）中的 p 值被认为是“在假设零假设成立的情况下，观察到至少与统计学家观察到的值一样极端的值的概率”。
我的问题来自“至少一样极端的部分”。这是由于使用了检验统计量的值的 CDF 的补集。这意味着我们正在考虑我们没有观察到的检验统计量的其他更极端（且不相关）的值。为什么使用检验统计量的 pdf 还不够？我担心在拒绝零假设时，我们正在考虑与特定检验无关的极端值。]]></description>
      <guid>https://stats.stackexchange.com/questions/657034/p-values-for-hypothesis-testing</guid>
      <pubDate>Sun, 10 Nov 2024 15:42:55 GMT</pubDate>
    </item>
    <item>
      <title>显示两个变量在数年内变化的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/657033/best-way-to-display-two-variables-changing-over-the-span-of-a-number-of-years</link>
      <description><![CDATA[我试图在 y 轴上显示某个城市的中位租金及其人口，x 轴上显示年份。
我的第一反应是使用气泡图，其中 y 轴对应人口，x 轴对应年份，每个气泡的体积与中位租金相关。但这在视觉上模糊了人口与年份的关系。
有没有更好的方法可以做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/657033/best-way-to-display-two-variables-changing-over-the-span-of-a-number-of-years</guid>
      <pubDate>Sun, 10 Nov 2024 15:26:18 GMT</pubDate>
    </item>
    <item>
      <title>使用分类器预测作为具有受试者内数据的独立变量？</title>
      <link>https://stats.stackexchange.com/questions/656964/using-classifier-prediction-as-independent-variable-with-within-subjects-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656964/using-classifier-prediction-as-independent-variable-with-within-subjects-data</guid>
      <pubDate>Fri, 08 Nov 2024 17:05:16 GMT</pubDate>
    </item>
    <item>
      <title>“最好的测试是无偏见的”这一说法的证明</title>
      <link>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</guid>
      <pubDate>Wed, 06 Nov 2024 12:41:53 GMT</pubDate>
    </item>
    </channel>
</rss>