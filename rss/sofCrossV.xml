<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 19 Apr 2024 21:12:35 GMT</lastBuildDate>
    <item>
      <title>结合百分比来估计新的百分比</title>
      <link>https://stats.stackexchange.com/questions/645420/combining-percentages-to-estimate-new-percentage</link>
      <description><![CDATA[我正在尝试根据其居住州来估计在大学第一年选择本科级别大学专业的真正新生群体（首次入学、全日制、攻读学位）的比例。举例来说：对于从 X 州高中毕业并于明年上大学的学生，这些学生中有多少比例是全日制攻读学位的学生，并声明了所希望的大学专业。我没有直接获得这些数据，但有一些数据可以用来进行估计。以下是可用数据：

本科生总数（所有即将入学的本科生）
即将入学的全日制、首次攻读学位的本科生人数
过去 12 个月内高中毕业的首次攻读学位的本科生人数（因此，这里基本上也是第一次），按其被录取时的居住州划分
选择相关专业的全日制一年级攻读学位本科生的人数。

正如您所看到的，每个数据源涉及的学生类型都存在一些问题。来源 3 在计数中没有寻求程度，而来源 4 有。有谁知道我如何能够有效地组合这些数据来创建相关的估计？我可以假设进入真正的新生的家乡州的分布在整体队列和大学专业队列之间是相同的，以及你们可能会看到的我可能需要做出的其他假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/645420/combining-percentages-to-estimate-new-percentage</guid>
      <pubDate>Fri, 19 Apr 2024 20:39:20 GMT</pubDate>
    </item>
    <item>
      <title>链式法则条件熵</title>
      <link>https://stats.stackexchange.com/questions/645419/chain-rule-conditional-entropy</link>
      <description><![CDATA[在我正在阅读的教科书中，它指出 $H(X,Y)=H(X)+H(Y|X)$，其中$H(X,Y)$ 是随机变量的联合熵 $X,Y$, &lt; span class=&quot;math-container&quot;&gt;$H(X)$ $X$ 和 $H(Y|X)$ 是条件熵。然后它继续说，以类似的方式，可以显示
$H(X,Y|Z)=H(X|Z)+H(Y|X,Z)$。我很困惑如何解释左侧的术语。它是否意味着被解释为随机变量 $X$ 和 $Y|X$ 的交叉熵&gt;，或者它是否意味着被解释为 $X$ 和 $Y$&lt; 的联合分布的条件熵/span&gt;，以 $Z$ 为条件？]]></description>
      <guid>https://stats.stackexchange.com/questions/645419/chain-rule-conditional-entropy</guid>
      <pubDate>Fri, 19 Apr 2024 20:29:19 GMT</pubDate>
    </item>
    <item>
      <title>对相同向量的卡方检验返回显着的 p 值</title>
      <link>https://stats.stackexchange.com/questions/645418/chi-square-test-on-identical-vectors-return-a-signficant-p-value</link>
      <description><![CDATA[下面的代码对两个相同向量运行 chisq 测试。我希望 p 值等于 1（即两个向量之间没有差异）。然而 p 值非常低，警告消息表明可能出现问题，但我没有找到任何进一步的信息。
我做错了什么？
库(dplyr)
设置.种子(123)
x = rpois(1700, lambda = 3)
df = 数据.frame(x = x,
                y = x，
                因子 = as.factor(1:length(x))) %&gt;%
  过滤器(!(x == 0 &amp; y == 0))
all.equal(df$x,df$y)
#&gt; [1] 正确
chisq.test(df$x,df$y)
#&gt; chisq.test(df$x, df$y) 中的警告：卡方近似值可能不正确
#&gt;
#&gt;皮尔逊卡方检验
#&gt;
#&gt;数据：df$x 和 df$y
#&gt; X 平方 = 14481，df = 81，p 值 &lt; 2.2e-16
chisq.test(df$x,df$y,simulate.p.value = TRUE)
#&gt;
#&gt;带模拟 p 值的 Pearson 卡方检验（基于 2000 年
#&gt;重复）
#&gt;
#&gt;数据：df$x 和 df$y
#&gt; X 平方 = 14481，df = NA，p 值 = 0.0004998
chisq.test(c(1:20), c(1:20))
#&gt; chisq.test(c(1:20), c(1:20)) 中的警告：卡方近似值可能是
#&gt;不正确
#&gt;
#&gt;皮尔逊卡方检验
#&gt;
#&gt;数据：c(1:20) 和 c(1:20)
#&gt; X 平方 = 380，df = 361，p 值 = 0.2358

创建于 2024 年 4 月 19 日，使用 reprex v2.0.2]]></description>
      <guid>https://stats.stackexchange.com/questions/645418/chi-square-test-on-identical-vectors-return-a-signficant-p-value</guid>
      <pubDate>Fri, 19 Apr 2024 20:16:48 GMT</pubDate>
    </item>
    <item>
      <title>实验中缺失数据，MIPO、MIPO|X 与 MCAR、MAR、MNAR</title>
      <link>https://stats.stackexchange.com/questions/645417/missing-data-in-experiments-mipo-mipox-vs-mcar-mar-mnar</link>
      <description><![CDATA[您好，我正在阅读艾伦·格伯和唐纳德·格林的《现场实验》，并向我介绍了独立于潜在结果的缺失 (MIPO) 的概念。当您以协变量为条件时，MIPO|X 与缺失无关。我接受的关于失踪的大部分教育都是关于 MCAR、MAR、MNAR 以及是否进行估算。
据我所知，MIPO 关注的是治疗效果是否公正或仍然有因果依据，而 MCAR、MAR、MNAR 更关注是否可以在没有缺失的情况下对完整样本进行推论，这是正确的吗？&lt; /p&gt;
我很好奇不同的思维方式如何影响分析以及这些想法来自哪里以供进一步阅读？]]></description>
      <guid>https://stats.stackexchange.com/questions/645417/missing-data-in-experiments-mipo-mipox-vs-mcar-mar-mnar</guid>
      <pubDate>Fri, 19 Apr 2024 20:13:30 GMT</pubDate>
    </item>
    <item>
      <title>移动块引导程序以获得趋势的一阶导数的 CI</title>
      <link>https://stats.stackexchange.com/questions/645416/moving-block-bootstrap-to-get-ci-arou-d-first-derivative-of-trend</link>
      <description><![CDATA[我有一个时间序列，我想知道非线性趋势分量的变化率。为此，我想获取趋势的一阶导数，但我需要围绕它的置信区间。我认为一种方法可能是执行 STL，然后在残差上使用移动块引导程序来生成引导时间序列，对每个重复分解并每次计算趋势的导数 - 让我可以围绕衍生品？
这是一个合理的方法吗？注意我不关心预测，只关心历史数据 - 引导在这里仍然有用吗？如果是这样，多少个引导程序合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/645416/moving-block-bootstrap-to-get-ci-arou-d-first-derivative-of-trend</guid>
      <pubDate>Fri, 19 Apr 2024 19:32:54 GMT</pubDate>
    </item>
    <item>
      <title>色散和相关参数之间的 Beta 二项式关系</title>
      <link>https://stats.stackexchange.com/questions/645415/beta-binomial-relationship-between-dispersion-and-correlation-parameters</link>
      <description><![CDATA[上下文：我已经使用 glmmTMB 包中的 glmmTMB() 创建了一个 beta-二项式模型，现在我正在尝试使用  模拟 beta-二项式结果&gt;pbetabinom() 来自 VGAM 包。每个包中方差的参数化是不同的。 此处 28 显示 glmmTMB 包中的 beta 二项式方差为 V = $\mu$(1-$\mu$)(n($\phi$+n)/($ \phi$+1)) 和此处&lt; /a&gt; 对于 VGAM 包显示为 V = $\mu$(1- $\mu$)(1+(n-1)$\rho$)/n。如何将 $\phi$ 关联到 $\rho$？
pbetabinom() 使用 $\rho$ 参数，它称为相关参数，定义在 0 和1. 但是这个$\rho$并没有在glmmTMB()的输出中给出，而是我们得到了一个色散参数，$\phi$。
我想根据我的模型输出进行模拟，但我正在努力如何将 $\phi$ 与 $ 关联起来\rho$。设置方差相等，并隔离 $\rho$，我的代数让我：
$\rho$=(n*n($\phi$+n)-( $\phi$+1))/((n-1)($\phi$+1 ））。
我尝试过简化这个过程，但无法从方程中得到“n”。我还可以看到，假设 $\phi$ 具有正值，则 $\rho$ 不会绑定在 0 和 1 之间，根据 VGAM 详细信息，它应该是这样。
所以，我的问题是：如何使用由 glmmTMB() 输出给出的色散参数 $\phi$ 到模拟需要相关参数 $\rho$ （由 VGAM 的 pbetabinom() 定义）的 beta 二项式结果？我在处理两个给定的方差方程时哪里出错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/645415/beta-binomial-relationship-between-dispersion-and-correlation-parameters</guid>
      <pubDate>Fri, 19 Apr 2024 19:00:32 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何物理过程产生物流配送？</title>
      <link>https://stats.stackexchange.com/questions/645411/is-there-any-physical-process-producing-a-logistic-distribution</link>
      <description><![CDATA[在他的 Logit 模型中，J.S.克莱默写了以下内容（第 23 页）
&lt;img alt=&quot;据我所知，没有任何实验或过程可以自然地产生这种分布方式。” src =“https://i.stack.imgur.com/gRf9b.png”/&gt;
他的推测正确吗？是否没有物理过程产生物流配送？]]></description>
      <guid>https://stats.stackexchange.com/questions/645411/is-there-any-physical-process-producing-a-logistic-distribution</guid>
      <pubDate>Fri, 19 Apr 2024 17:46:31 GMT</pubDate>
    </item>
    <item>
      <title>如何选择将分布放在 KL 散度的右侧或左侧？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/645409/how-do-you-choose-to-put-a-distribution-on-the-right-or-left-of-kl-divergence</link>
      <description><![CDATA[我一直认为 KL 散度是分布之间的距离度量，很像 Earth-Movers 距离。但我不能再忽视这种不对称性。真实距离度量是对称的。
我应该如何解释这种不对称性？如果我有两个分布，我想测量它们之间的 KL，我该如何决定是将一个分布放在 KL[Q||P] 的右侧参数还是左侧参数中？]]></description>
      <guid>https://stats.stackexchange.com/questions/645409/how-do-you-choose-to-put-a-distribution-on-the-right-or-left-of-kl-divergence</guid>
      <pubDate>Fri, 19 Apr 2024 17:34:13 GMT</pubDate>
    </item>
    <item>
      <title>请帮助解决向后回归残差[关闭]</title>
      <link>https://stats.stackexchange.com/questions/645408/please-help-with-backwards-regression-residuals</link>
      <description><![CDATA[所以我认为我们的最终模型没问题，但倒数第二页 (Sheet64) 上的散点图一直如此聚集。我们怎样才能让它看起来恒定或至少呈正态分布？我们到底做错了什么？ 这里是我们的电子表格。
非常感谢！
我们是一年级学生，之前没有统计经验。抱歉，页数太多！]]></description>
      <guid>https://stats.stackexchange.com/questions/645408/please-help-with-backwards-regression-residuals</guid>
      <pubDate>Fri, 19 Apr 2024 17:31:31 GMT</pubDate>
    </item>
    <item>
      <title>从多种模型中进行选择时进行多次测试和 p-hacking</title>
      <link>https://stats.stackexchange.com/questions/645400/multiple-testing-and-p-hacking-when-choosing-from-many-models</link>
      <description><![CDATA[我正在尝试用粒子群优化算法训练随机森林模型，因为我的目标函数不平滑并且对我来说是未知的，也就是说，本质上，这是同时进行搜索和训练。
我将以虹膜数据和 mse 健身函数为例向您展示我正在做什么。
（我选择所有内容只是为了清楚起见，我有一个完全不同的健身功能）
set.seed(1)
par(mar=c(2,2,2,2))
库（随机森林）
图书馆（PSO）

X &lt;- 虹膜[样本(150), -5]

时间 &lt;- 1:50
vl &lt;- 51:100
时间 &lt;- 101:150

bst_err &lt;- Inf
bst_model &lt;- NULL

fit 函数采用一个值向量，该向量是随机森林的目标变量，它将在数据序列上进行训练。
接下来，tr_ts_mse 错误被认为是训练和测试数据。
fit &lt;- 函数(y) {
rf &lt;- randomForest(y~., X[tr,], ntree=100)
pred &lt;- 预测(rf, X)
err &lt;- (pred - X[,“Sepal.Length”])^2

错误 &lt;- 错误[c(tr,ts)]
tr_ts_mse &lt;- 平均值（错误）

如果（tr_ts_mse &lt; bst_err）{
  bst_model &lt;&lt;- rf
  bst_err &lt;&lt;- 平均值（错误）
  
  ＃ 视觉的
  cbind(X[,“Sepal.Length”], pred) |&gt;
        matplot(lty = c(1,4), col=c(1,4), t=“l”, ylim = c(3,9))
  abline(v=c(50,100)，col=2，lty=2)
  文本(c(20,70,130),c(9,9,9),c(“训练”,“验证”,“测试”))
}
tr_ts_mse
}

接下来，启动优化算法，迭代不同的目标函数并训练模型
pso &lt;- psoptim(rep(NA,length(tr)), fit, lower=0, upper=10,
               控制=列表（跟踪=1，报告=1，最大值=200））

经过 200 次迭代后，我们将得到一些经过训练的模型

在我提出问题之前，这是一个很大的介绍。
我的问题是，我所做的本质上是在相同数据上搜索大量模型。
我如何才能尽可能地保护自己免受多重测试和 p-hacking 的问题。
也就是说，我如何确定我的模型没有过度训练？
除了用于数据测试的模型检查选项
问题是我并不总是能够创建一个能够在新数据上充分工作的模型，我认为这是由于重复测试而选择了错误的模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/645400/multiple-testing-and-p-hacking-when-choosing-from-many-models</guid>
      <pubDate>Fri, 19 Apr 2024 15:40:19 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 模型低估</title>
      <link>https://stats.stackexchange.com/questions/645370/arima-model-underestimates</link>
      <description><![CDATA[如果我的 ARIMAX 模型持续低估，我们应该采取什么措施？
此外，这种低估是否应该成为我分析中的一个重大问题？
编辑：
我正在进行 ARIMAX 预测，其中使用报纸中的情绪作为外生变量来预测股票走势，并将误差指标 + Diebold-Mariano 与随机游走的误差指标进行比较。
这意味着我在周末和节假日缺少值。
我的 ARIMAX 预测值低估了实际运动的值。
ARIMAX 模型通过了偏度和序列相关性，并且没有此类问题。
代码：
库（预测）

set.seed(123) # 设置种子

# 分割、训练和测试。
split_index &lt;- round(0.8 * nrow(fin_zoo2))
train_data &lt;- fin_zoo2[1:split_index, ]
test_data &lt;- fin_zoo2[(split_index + 1):nrow(fin_zoo2), ]

# 列名称
colnames(train_data)[which(colnames(train_data) == “FINsentiment2”)] &lt;- “FINsentiment2”
colnames(test_data)[which(colnames(test_data) == “FINsentiment2”)] &lt;- “FINsentiment2”

train_data_core &lt;- coredata(train_data)
test_data_core &lt;- coredata(test_data)

# 标准差
error_sd &lt;- sd(diff(train_data_core[,“OMXdaily_return2”]))

# 指标累积向量
metrics_accumulator &lt;- 列表（
  RW_MAPE = 数字（50），ARIMAX_MAPE = 数字（50），
  RW_MedAE = 数字（50），ARIMAX_MedAE = 数字（50），
  RW_sMAPE = 数字（50），ARIMAX_sMAPE = 数字（50），
  RW_RMSE = 数字(50)，ARIMAX_RMSE = 数字(50)
）

for(1:50 后试听) {
    set.seed(123 + 试用版) # 种子
    
    random_walk_forecasts &lt;- numeric(nrow(test_data_core))
    arimax_forecasts &lt;- 数字(nrow(test_data_core))
    
    for(i in 1:nrow(test_data_core)) {
        current_train_data &lt;- fin_zoo2[1:(split_index + i - 1), ]
        current_train_data_core &lt;- coredata(current_train_data)
        
        # 根据迄今为止所有可用数据更新标准差
        Updated_error_sd &lt;- sd（diff（current_train_data_core [，“OMXdaily_return2”]））
        
        error_term &lt;- rnorm(1, 均值 = 0, sd = Updated_error_sd)
        last_observation &lt;- tail(current_train_data_core[, “OMXdaily_return2”], 1)
        random_walk_forecasts[i] &lt;-last_observation
        
        如果（我&gt; 1）{
            xreg_train &lt;- as.matrix(current_train_data_core[, &quot;FINsentiment2&quot;, drop = FALSE])
            xreg_forecast &lt;- test_data_core[i - 1,“FINsentiment2”, drop = FALSE]
            arima_model_with_exog &lt;- Arima(current_train_data_core[, “OMXdaily_return2”],
                                           xreg = xreg_train,
                                           顺序 = c(2, 0, 2),
                                           包括.平均值=假）
            arimax_forecasts[i] &lt;- 预测(arima_model_with_exog, xreg = xreg_forecast, h = 1)$mean
        }
    }
    
 #指标计算
    
    实际值 &lt;- test_data_core[, “OMXdaily_return2”]
    metrics_accumulator$RW_MAPE[试验] &lt;- 平均值（abs（（实际值 - random_walk_forecasts）/实际值）） * 100
metrics_accumulator$ARIMAX_MAPE[试验] &lt;- 平均值(abs((actual_values - arimax_forecasts) /actual_values)) * 100
    metrics_accumulator$RW_MedAE[试验] &lt;- 中位数(abs(actual_values - random_walk_forecasts))
metrics_accumulator$ARIMAX_MedAE[试验] &lt;- 中位数(abs(actual_values - arimax_forecasts))
    metrics_accumulator$RW_sMAPE[试验] &lt;- 平均值(2 * abs(actual_values - random_walk_forecasts) / (abs(actual_values) + abs(random_walk_forecasts))) * 100
metrics_accumulator$ARIMAX_sMAPE[试验] &lt;- 平均值(2 * abs(actual_values - arimax_forecasts) / (abs(actual_values) + abs(arimax_forecasts))) * 100
    # RMSE 计算
    metrics_accumulator$RW_RMSE[试验] &lt;- sqrt(mean((actual_values - random_walk_forecasts)^2))
metrics_accumulator$ARIMAX_RMSE[试用] &lt;- sqrt(mean((actual_values - arimax_forecasts)^2))
}

# 计算平均指标
Final_metrics &lt;- sapply(metrics_accumulator, 平均值)

# 决赛桌
Final_metrics_table &lt;- data.frame(
  度量=c(“MAPE”、“MedAE”、“sMAPE”、“RMSE”)，
  Random_Walk=final_metrics[c(“RW_MAPE”、“RW_MedAE”、“RW_sMAPE”、“RW_RMSE”)]，
  ARIMAX = Final_metrics[c(“ARIMAX_MAPE”、“ARIMAX_MedAE”、“ARIMAX_sMAPE”、“ARIMAX_RMSE”)]
）
打印（最终指标表）
]]></description>
      <guid>https://stats.stackexchange.com/questions/645370/arima-model-underestimates</guid>
      <pubDate>Fri, 19 Apr 2024 10:24:12 GMT</pubDate>
    </item>
    <item>
      <title>系统 GMM 对于任何加权矩阵都会产生相同的结果</title>
      <link>https://stats.stackexchange.com/questions/645362/system-gmm-yields-identical-results-for-any-weighting-matrix</link>
      <description><![CDATA[我正在估计 R 中看似不相关的回归 (SUR) 系统。每个方程都有一个唯一的回归量和一个公共回归量。我正在使用 gmm::sysGmm 并尝试不同的权重矩阵。我得到了相同的结果（点估计、标准误差和我能看到的任何其他结果 - 除了 $J$ 的值 -测试），无论权重矩阵如何。我认为这是不正确的。
无论我使用哪种类型的协方差矩阵估计器，这种现象都会持续存在：MDS、CondHom 或 HAC。无论我使用无限制估计还是限制其中一个系数在方程中相等，它都仍然存在。
问题：为什么系统 GMM 通过 gmm::sysGmm 对于任何加权矩阵都会产生相同的结果？
库(gmm)
库（系统适配）

# 生成并准备数据
n &lt;- 1000 # 样本量
m＜-100#“第二部分”的长度样本的
N &lt;- 3 # 方程数
设置.种子(321); x &lt;- 矩阵(rnorm(n*N),ncol=N); colnames(x) &lt;-paste0(“x”,1:N) # 生成回归量
dummy &lt;- c(rep(0,n-m),rep(1,m))#生成一个公共回归器
x &lt;- cbind(x,dummy) # 包含公共回归器和其余回归器
设置.种子(123); y &lt;- 矩阵(rnorm(n*N),ncol=N); colnames(y) &lt;- Paste0(“y”,1:N) # 因变量的占位符
for(i in 1:N){
 y[,i] &lt;- i + sqrt(i)*x[,i] - i*虚拟 + y[,i]*15*sqrt(i)
 # y[,i] 是 x[,i] 和虚拟变量的线性函数，
 # 加上一个带有方程特定方差的误差项
}
data1 &lt;- as.data.frame(cbind(y,x)) # 创建所有数据（y 和 x）的数据框

# 创建模型方程和力矩条件
eqSystem_g = eqSystem_h &lt;- list()
for(i in 1:N){
 eqSystem_g[[i]] &lt;- as.formula(assign(paste0(&quot;eq&quot;,i), value=paste0(&quot;y&quot;,i,&quot; ~ x&quot;,i,&quot; + dummy&quot;) )) # 定义 SUR 的线性方程
 eqSystem_h[[i]] &lt;- as.formula(assign(paste0(&quot;eq&quot;,i), value=paste0( &quot;~ x&quot;,i,&quot; + dummy&quot;))) # 定义矩条件对于高斯模型
}

# 估计 WLS 类型的权重矩阵，用作 GMM 中用户指定的权重矩阵
m0 &lt;- systemfit(公式=eqSystem_g，方法=“OLS”，数据=data1)
OLSmat &lt;- diag(diag(m0$residCov)); Wmat &lt;- 求解(OLSmat)

# 选择GMM中协方差矩阵的类型
vc1＜-“MDS”
vc1＜-“CondHom”
vc1＜-“HAC”
#vc1 &lt;-“TrueFixed”

# 在限制估计和非限制估计之间进行选择
cec1=NULL # 无限制
cec1=3 # 限制虚拟变量的系数在方程中相等

# 使用不同的权重矩阵“sysGmm”估计模型：identity、“optimal”并手动指定
m1a &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h, wmatrix=“ident” ,weightsMatrix=NULL, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1a)
m1b &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h, wmatrix=“最佳”,weightsMatrix=NULL, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1b)
m1c &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h,weightsMatrix=Wmat, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1c)

相关：
* 通过 systemfit 与 sysGmm 估计的 SUR：不同的标准误差 
* 为什么 systemfit 对于 OLS 和 WLS 会产生相同的结果？  
* 为什么在交叉方程限制下，systemfit 会产生不同的 OLS 和 WLS 结果？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/645362/system-gmm-yields-identical-results-for-any-weighting-matrix</guid>
      <pubDate>Fri, 19 Apr 2024 07:51:09 GMT</pubDate>
    </item>
    <item>
      <title>识别分层簇的最佳方法</title>
      <link>https://stats.stackexchange.com/questions/645346/best-method-to-identify-layered-clusters</link>
      <description><![CDATA[问题
大家好。我正在使用一个数据集，该数据集包含 15300 个样本，每个样本有 49 个特征，均匀分布在三个类别中。我使用 TSNE 将特征空间的维度减少到二维，以更好地可视化数据的分布，并发现一些有点奇怪的东西（至少对我来说）。这些类似乎是相互叠加的。
嵌入数据分布

欧几里德距离

余弦相似度

我知道这些图表很恶心，对此感到抱歉。无论如何，是否有一种聚类算法可以正确识别这些类别？我听说谱聚类方法非常擅长识别非凸簇，但它们的空间和计算复杂度非常高，这不太好，因为我仅限于 16GB RAM。是否有一种迭代方法可以逼近传统谱聚类方法（图拉普拉斯特征分解）提供的解？]]></description>
      <guid>https://stats.stackexchange.com/questions/645346/best-method-to-identify-layered-clusters</guid>
      <pubDate>Thu, 18 Apr 2024 22:23:44 GMT</pubDate>
    </item>
    <item>
      <title>比值比悖论？合并 OR 与子组 OR 不一致</title>
      <link>https://stats.stackexchange.com/questions/645304/odds-ratios-paradox-pooled-or-inconsistent-with-subgroup-ors</link>
      <description><![CDATA[我有两个组（A 和 B），每个组的 OR 分别为 1.44 和 1.50。但是，如果我将两个组的频率组合起来创建一个合并数据集，则 OR 值为 1.40。
我知道这不会是一个很好的简单加权平均值或任何东西，但我预计合并的 OR 至少会落在两个 OR 的范围内。经过几天的苦苦思索试图找出原因后，我放弃了，转而求助于这里的集体智慧。
这是我的数据：
A 组频率

&lt;标题&gt;


控制
测试


&lt;正文&gt;

低
1374
1422


高
4759
7062



产生 1.44 的 OR 
B 组频率

&lt;标题&gt;


控制
测试


&lt;正文&gt;

低
825
534


高
4033
3914



产生 1.50 的 OR
合并频率

&lt;标题&gt;


控制
测试


&lt;正文&gt;

低
2199
1956


高
8792
10976



产生 1.40 的 OR
对这里发生的事情有什么想法吗？我使用这两个组来显示模式，但我的数据实际上分为更多组。
我将其称为悖论，因为如果我包括所有组，尽管事实上几乎所有组都产生 1.2-1.8 范围内的 OR（有几个组产生 0.95-1.0 范围内的 OR） ），池化版本基本上变为空（OR = 1.00）。感觉就像存在某种辛普森悖论。
编辑：根据下面的@COOLSerdash，本文&lt; /a&gt; 解释了“不可折叠性” OR 的数量。经过一番尝试后，我们发现，如果较大的组的 RR 与其他组的 RR 非常不同，那么它就会产生强烈的“扭曲”效果。效果。]]></description>
      <guid>https://stats.stackexchange.com/questions/645304/odds-ratios-paradox-pooled-or-inconsistent-with-subgroup-ors</guid>
      <pubDate>Thu, 18 Apr 2024 13:07:54 GMT</pubDate>
    </item>
    <item>
      <title>英文文本中每个单词有多少知识点？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/645182/how-many-bits-of-knowledge-are-there-in-english-text-per-word</link>
      <description><![CDATA[人们常说，典型的英语文本可以最佳地压缩到每个单词 12 位左右。
然而，由于陈述相同事实的方式有很多种，因此典型文本中传达的事实知识每个字少于 12 位。我正在阅读的一篇 ML 论文提到了一个数值估计：
&lt;块引用&gt;
[4]
截至 2024 年 2 月 1 日，英语维基百科总共包含 45 亿个单词，请参阅 https://en.wikipedia。 org/wiki/Wikipedia:Size_of_Wikipedia#Size_of_the_English_Wikipedia_database，访问于 2024 年 3 月。
据估计，英语教科书的非重叠内容总共不到160亿字，参见
备注 G.1。这总计 205 亿个单词，但我们认为它们包含的知识不到 140 亿位。

但没有提供参考资料，因此我的问题是：
英文文本中每个单词有多少知识点？
&lt;小时/&gt;
对版主和反对者的回应：
一位版主坚持认为，提及“知识（文本）”的帖子必须被禁止。给出它的定义。
这对我来说似乎很奇怪，因为“知识”一词是在我看来。在NLP、信息抽取、知识抽取等领域已经被普遍理解。否则，他们想抽取什么？
当然，这个术语很难甚至不可能精确定义。但“图书馆”这个词也不是。你需要有多少本书才能成为一个“图书馆”？一把“椅子”也没有明确定义，但我打赌你仍然可以在你的房子里数它们。
定义“知识”作为“文本中的有用信息”只会把责任推给“有用”。
虽然我无法给出“知识”的清晰定义，但允许它被量化，我可以尝试对其进行上限和下限：

下限：知识（文本形式）是被提取到图形结构（例如 Google 的知识图）中的信息。这是一个下限，因为现有的方法可能会遗漏一些东西。
上限：知识（文本形式）是翻译中保留的信息。这是一个上限，因为其他一些内容会被保留（文档的整体结构等）

与其他信息一样，这两者都是可量化的。]]></description>
      <guid>https://stats.stackexchange.com/questions/645182/how-many-bits-of-knowledge-are-there-in-english-text-per-word</guid>
      <pubDate>Tue, 16 Apr 2024 21:31:36 GMT</pubDate>
    </item>
    </channel>
</rss>