<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 17 Dec 2024 01:22:13 GMT</lastBuildDate>
    <item>
      <title>结构方程模型：semPaths 图表、布局</title>
      <link>https://stats.stackexchange.com/questions/658846/structural-equation-modeling-sempaths-charts-layout</link>
      <description><![CDATA[我有一个 SEM 模型，其中包含指示变量，其中一些指示变量与两个潜在变量相连。由于变量、潜在构造和高阶因子众多，内置布局：tree、tree2、circle、circle2、spring 无法产生可接受且可读的结果。
semptools 包提供了一个函数 (set_sem_layout()) 来设置布局 (https://cran.r-project.org/web/packages/semptools/vignettes/quick_start_sem.html)，但 indicator_factor 矩阵（必需参数）似乎要求每个指示变量只有一个因子。
如果指示变量与更多因子相连，如何定义自定义布局？我用一个简单的例子来说明下面的问题：
fit_struct &lt;- sem(&#39;f1 =~ NA*x1 + x2 + x3
f2 =~ NA*x3 + x4 + x5

#variance standardization
f1~~ 1*f1
f2~~ 1*f2

#regression 
y ~ f1 + f2&#39;, data=df_struct_reg)
sem_o &lt;- summary(fit_struct, unified=TRUE, fit.measures=TRUE)

p &lt;- semPaths(fit_struct, whatLabels=&quot;est&quot;,
sizeMan = 5.25,
node.width = 1,
edge.label.cex = .75,
style = &quot;LISREL&quot;,
mar = c(5, 4, 4, 4),
layout = &quot;tree&quot;,
width = 12，高度 = 15)

# 查看节点标签、顺序
semPaths(fit_struct, 截距 = F，nodeLabels = 1:6)

我想要一个布局，其中 x3 连接到 f1 和 f2。我可以指定指标顺序，因子布局也是如此。如何定义将 x3 分配给 f1 和 f2 的 indicator_factor 矩阵？]]></description>
      <guid>https://stats.stackexchange.com/questions/658846/structural-equation-modeling-sempaths-charts-layout</guid>
      <pubDate>Mon, 16 Dec 2024 22:20:42 GMT</pubDate>
    </item>
    <item>
      <title>r 中的 mediate() 是否适用于多分类预测因子？</title>
      <link>https://stats.stackexchange.com/questions/658844/does-mediate-in-r-work-with-a-multicategorical-predictor</link>
      <description><![CDATA[我的数据是多级的（每个条件内的每个参与者有多个测量值），有 3 个条件。
DV = 连续；中介 = 连续；IV = 分类（有 3 个条件：控制、条件 A、条件 B；ss 内）。
对于 IV，我为分析创建了虚拟变量（A = 0, 1；B = 0, 1；控制 = 0, 1）。
mediate() 是否适用于多分类预测因子？假设我的模型在理论上是合理的，运行以下分析来计算变量的间接影响、总体影响、直接影响等中介路径是否合适？
分析：
fit.mediator=lmer(Mediator ~ IV.A + IV.B + (1 | id), data=data1)
summary(fit.mediator)
fit.dv=lmer(DV ~ IV.A + IV.B + Mediator + (1 | id), data=data1)
summary(fit.dv)
summary(mediate(fit.mediator, fit.dv, treat=&#39;IV.A&#39;, mediator=&#39;Mediator&#39;))
summary(mediate(fit.mediator, fit.dv, treat=&#39;IV.B&#39;, mediator=&#39;调解员&#39;))]]></description>
      <guid>https://stats.stackexchange.com/questions/658844/does-mediate-in-r-work-with-a-multicategorical-predictor</guid>
      <pubDate>Mon, 16 Dec 2024 22:09:37 GMT</pubDate>
    </item>
    <item>
      <title>横截面依赖性的渐近理论</title>
      <link>https://stats.stackexchange.com/questions/658841/asymptotic-theory-in-cross-sectional-dependence</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658841/asymptotic-theory-in-cross-sectional-dependence</guid>
      <pubDate>Mon, 16 Dec 2024 21:47:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么推荐系统的 UV 矩阵分解有效？</title>
      <link>https://stats.stackexchange.com/questions/658839/why-does-uv-matrix-factorization-for-recommender-systems-work</link>
      <description><![CDATA[在推荐系统研究中，一种方法是进行 UV 矩阵分解。
$M&#39; = U\cdot V$
其中 $U$ 的列数等于 $V$ 的行数，而“$\cdot$”是矩阵乘积。
$M$ 有很多缺失值，我们最小化 $||M-M&#39;||$。
这里，我们使用 Frobenius 距离对 $M$ 的非缺失值进行计算。
我的理解是，这个想法是我们有效地将所有用户和项目投射到一个相对低维的空间中，例如二维空间。
然后我们使用点积作为相似度度量。
对我来说，它在这里分解：如果有人喜欢特征 A 而不喜欢特征 B，那么他们的偏好向量（在二维空间中）为 (5,1)。如果一个项目具有这些特征（或没有这些特征），那么我们的相似度为 $5^2+1^2=26$。但是，如果偏好向量为 (1,1)，且项目具有相同的特征 (1,1)，则相似度为 2。而如果两个向量为 (5,5) 和 (5,5)，则相似度为 50。但是，这意味着在成本函数 $||M-M&#39;||$ 中对这些因素考虑不足或过度。也就是说，(1,1) 对考虑不足，而 (5,5) 对考虑过多。
（顺便说一句：我看不出使用余弦相似度在这里会有什么太大的改善：使用它意味着 (1,1) 与 (1,1) 和 (5,5) 具有相同的相似性，这没有意义。）
我也读到它们是降维的，但我看不出这里降维到什么程度。
我的问题是：考虑到我写的问题，为什么推荐系统的 UV 矩阵分解有效。]]></description>
      <guid>https://stats.stackexchange.com/questions/658839/why-does-uv-matrix-factorization-for-recommender-systems-work</guid>
      <pubDate>Mon, 16 Dec 2024 21:43:08 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中构建具有非整数因变量的 GLM 时使用泊松分布。使用偏移量</title>
      <link>https://stats.stackexchange.com/questions/658838/using-poisson-distribution-when-constructing-glm-in-r-with-non-integer-dependent</link>
      <description><![CDATA[我在使用泊松分布构建 GLM 模型时遇到了麻烦。我正在研究变量对鸟类数量的影响（总共 4 个变量）。我的因变量“密度”有非整数，因此出现错误。我不想对数字进行四舍五入，也不想使用拟泊松。
示例&lt;-structure(list(birds = c(9L, 2L, 2L, 4L, 1L, 1L, 4L, 1L, 5L, 
5L, 2L), area = c(3.55, 2.52, 1.49, 1, 1.13, 1.49, 1.4, 0.57, 
1.11, 1.78, 1.63), density = c(2.5, 0.8, 1.3, 4, 0.9, 0.7, 2.9, 
1.8, 4.5, 2.8, 1.2), green = c(5.95, 5.62, 6.32, 6.04, 4.91, 
5.36, 7.15, 5.22, 6.8, 6.69, 6.47), 开放 = c(3.69, 5, 3.94, 4.05, 
3.48, 3.97, 4.12, 4.29, 4.29, 3.56, 4), 距离 = c(0.6, 3, 
1, 0.9, 1, 1, 2.5, 3.2, 3.8, 2.5, 3), 人类 = c(21.29, 22.76, 
23.02, 20.88, 21.26, 21.87, 23.19, 21.82, 19.49, 21.68, 19.6)), 类别 = &quot;data.frame&quot;, row.names = c(NA, 
-11L))

fix(Example) # 数据表

我读到在这种情况下 log 用作偏移量，并在表中添加了新列 &quot;birds&quot; 和 &quot;area&quot;，考虑到密度 = 鸟类 / 面积。
我使用了以下代码：
model = glm (birds ~ green + human + distance + open + offset (log (area)),
data = Example, family = poisson (link = &quot;log&quot;))

在手动构建所有可能的模型后，我开始怀疑所获得数据的结果。影响最小的因素 &quot;open&quot; 的模型位于前 3 个模型中，这是一个伪像。我使用 compareGLM 比较了模型，并使用小样本的 AICc 值。
compareGLM(model.1, model.2, model.3, model.4, model.5, model.6, model.7, model.8, model.9, model.10, model.11, model.12, model.13, model.14, model.15)

$Models
公式 
1 &quot;birds ~ green + human + distance + open + offset(log(area))&quot;
2 &quot;birds ~ green + human + distance + offset(log(area))&quot; 
3 &quot;birds ~ green + human + offset(log(area))&quot; 
4 &quot;birds ~ green + offset(log(area))&quot; 
5 &quot;birds ~ human + offset(log(area))&quot; 
6 “鸟类 ~ 距离 + 偏移量(log(面积))” 
7 “鸟类 ~ 人类 + 距离 + 偏移量(log(面积))” 
8 “鸟类 ~ 开放 + 偏移量(log(面积))” 
9 “鸟类 ~ 绿色 + 开放 + 偏移量(log(面积))” 
10 “鸟类 ~ 绿色 + 距离 + 偏移量(log(面积))” 
11 “鸟类 ~ 开放 + 距离 + 偏移量(log(面积))” 
12 “鸟类 ~ 开放 + 人类 + 偏移量(log(面积))” 
13 “鸟类 ~ 绿色 + 开放 + 距离 + 偏移量(log(面积))” 
14 “鸟类 ~ 绿色 + 开放 + 人类 + 偏移量(log(面积))” 
15 “鸟类~开放+距离+人类+偏移（对数（面积））”

$Fit.criteria
排名 Df.res AIC AICc BIC McFadden Cox.and.Snell Nagelkerke p.value
1 5 6 48.17 69.17 50.55 0.2506 0.6669 0.6753 0.05776
2 4 7 46.23 58.23 48.22 0.2493 0.6651 0.6735 0.03640
3 3 8 45.53 52.20 47.13 0.2222 0.6228 0.6306 0.03394
4 2 9 44.58 48.01 45.77 0.2006 0.5852 0.5925 0.02195
5 2 9 47.41 50.84 48.61 0.1419 0.4634 0.4692 0.15350
6 2 9 48.88 52.31 50.07 0.1115 0.3869 0.3918 2.02200
7 3 8 49.41 56.07 51.00 0.1420 0.4636 0.4694 0.23540
8 2 9 48.02 51.45 49.22 0.1292 0.4327 0.4382 0.27070
9 3 8 45.98 52.65 47.57   0.2130 0.6073 0.6149 0.04238
10 3 8 46.03 52.69 47.62 0.2120 0.6055 0.6132 0.04340
11 3 8 49.21 55.88 50.80 0.1460 0.4731 0.4790 0.21340
12 3 8 48.97 55.64 50.57 0.1510 0.4843 0.4904 0.18950
13 4 7 47.87 59.87 49.86 0.2153 0.6112 0.6189 0.07186
14 4 7 47.13 59.13 49.12 0.2307 0.6365 0.6445 0.05315
15 4 7 50.72 62.72 52.71 0.1562 0.4961 0.5024 0.19730

我使用偏移量做错了什么？还有其他方法可以将泊松分布应用于因变量的非整数值吗？
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658838/using-poisson-distribution-when-constructing-glm-in-r-with-non-integer-dependent</guid>
      <pubDate>Mon, 16 Dec 2024 20:55:46 GMT</pubDate>
    </item>
    <item>
      <title>在此次治疗师依从性测试中，作者是否适当地应用了重复测量单因素方差分析和 ROC 分析？</title>
      <link>https://stats.stackexchange.com/questions/658834/have-the-authors-appropriately-applied-repeated-measures-one-way-anova-and-roc-a</link>
      <description><![CDATA[我正在阅读一篇关于我所从事的心理治疗类型的研究。我的直觉是，这篇论文对统计数据的使用是有缺陷的，但我在意识形态上想要找出这篇特定研究的缺陷，而且我对统计数据的了解相当基础。出于这些原因，我不会链接到这篇论文。
这篇论文的所有作者都是接受过同一种治疗培训的心理治疗师。他们创建了一份问卷，供接受过该治疗培训的观察员使用，以评估治疗师在特定疗程中对该治疗的治疗程度。（即，这是一项依从性测试。）作者将这份问卷分发给了大约 200 名参与者（均接受过相关治疗培训），并附上了 4 个治疗疗程的视频；其中 2 个由接受过相关治疗培训的治疗师制作，另外 2 个由接受过其他治疗培训的治疗师制作。参与者对前两个视频的评分（每个约平均值 = 16.5，标准差 = 0.2）高于对后两个视频的评分（每个约平均值 = 4.5，标准差 = 0.25），这表明使用问卷可以清楚地区分受过相关疗法培训的人提供的疗法和受过其他疗法培训的人提供的疗法。
作者将上述平均值和标准差值作为“单向重复测量方差分析”的一部分呈现测试，他们说这显示出了统计学意义。
然后，他们进行了 ROC 分析，以确定将感兴趣的疗法与其他类型的疗法区分开来的阈值分数，并获得了 11 的值。
我有两个顾虑：
1：Statology 说，“重复测量单向方差分析用于确定三个或更多组的平均值之间是否存在统计学上的显着差异，其中每个组中都出现了相同的受试者。”我可以看到这里有 4 个组（4 个视频中的每个视频都有 1 组分数），但是，按照 Statology 的字面意思理解，这意味着观察者评分者是受试者，而不是他们正在评分的视频会话。如果研究的目的是找到一种方法来区分感兴趣的疗法和其他类型的疗法，那么我们实际上肯定有两组（2 个感兴趣的疗法样本和 2 个来自另一种疗法的样本）。如果我们只有 4 个样本，那么我认为统计显着性检验尚不合适。我愿意被告知我对此的想法是错误的，并欢迎任何评论。
2：维基百科说 ROC 分析是为了确定什么强度的信号应该被视为值得在雷达上显示的物体而开发的。我认为该任务必然是二进制的，以限制雷达操作员必须解析的信息量。我认为阈值不适用于确定某人是否遵守特定类型的治疗（特别是如果我们只有 4 个样本并且我们只评估了 2 种类型的治疗）。再次，我欢迎任何评论，包括对我的观点的任何更正。
我不知道是否已经发布了足够的有关该研究的信息。如果我应该提供更多详细信息，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/658834/have-the-authors-appropriately-applied-repeated-measures-one-way-anova-and-roc-a</guid>
      <pubDate>Mon, 16 Dec 2024 20:53:10 GMT</pubDate>
    </item>
    <item>
      <title>建模重叠时间段</title>
      <link>https://stats.stackexchange.com/questions/658825/modelling-overlapping-time-periods</link>
      <description><![CDATA[我在很长一段时间内一直在跟踪我的体重和卡路里摄入量。假设我有连续 100 天的完整卡路里观测数据。
我可以通过回归体重和卡路里来估算诸如每日总能量消耗 (TDEE) 之类的数据。普遍接受的数字是 3,500 千卡的缺口导致体重减轻 1 磅（或 1,600 千卡的缺口导致体重减轻 1 公斤）。
现在，我可以对整个 100 天的时间段进行建模，但我也有兴趣研究其中较短的时间跨度。最简单的做法是将 100 天分成 7 个两周的时间段。但是，你可以将 100 天分成更多重叠的两周时间段，每个时间段的值分别为（总卡路里）和（总损失）。
当然，这些新时间段不会是独立的，但增加时间段的数量会给我带来更多的力量，但我不清楚如何解决这个问题，我找不到任何东西，因为我不知道该怎么称呼它。]]></description>
      <guid>https://stats.stackexchange.com/questions/658825/modelling-overlapping-time-periods</guid>
      <pubDate>Mon, 16 Dec 2024 18:37:22 GMT</pubDate>
    </item>
    <item>
      <title>是否可以对使用非概率抽样收集的加权数据进行统计显著性检验方法？</title>
      <link>https://stats.stackexchange.com/questions/658822/can-statistical-significance-testing-methods-be-carried-out-on-weighted-data-tha</link>
      <description><![CDATA[我正在分析使用非概率抽样方法收集的调查数据集。此数据集还包括一个权重字段，允许将调查结果推断到更广泛的人群。
鉴于此权重数据的存在，我是否能够使用传统的统计显着性检验方法，如卡方检验和 t 检验？（我将使用 R 的 survey 和 srvyr 包或 Python 的 samplics 包将权重值合并到我的代码中。或者这些测试是否仍然无效，因为原始数据不是从随机样本中收集的？（如果是这样，我们将非常感激与非概率抽样方法兼容的替代测试的建议。）]]></description>
      <guid>https://stats.stackexchange.com/questions/658822/can-statistical-significance-testing-methods-be-carried-out-on-weighted-data-tha</guid>
      <pubDate>Mon, 16 Dec 2024 17:39:03 GMT</pubDate>
    </item>
    <item>
      <title>在机器/深度学习中，什么才算是“低级”或“高级”特征？</title>
      <link>https://stats.stackexchange.com/questions/658819/what-qualifies-as-low-level-or-high-level-feature-in-machine-deep-learning</link>
      <description><![CDATA[在讨论 CNN 时，通常会出现术语“低级”和“高级”特征。例如：（摘自R 中的统计学习应用简介）

网络首先识别输入图像中的低级特征，
例如小边缘、色块等。然后，将这些低级
特征组合起来形成更高级的特征，例如
耳朵、眼睛等的部分。最终，这些更高级特征的存在或不存在会影响任何给定输出类的概率。

为什么“眼睛”与边缘相比，哪些特征被视为“高级”特征（即更“抽象”的特征）？
在深度学习或机器学习中，对于什么是“低级”特征和“高级”特征，是否存在共识？]]></description>
      <guid>https://stats.stackexchange.com/questions/658819/what-qualifies-as-low-level-or-high-level-feature-in-machine-deep-learning</guid>
      <pubDate>Mon, 16 Dec 2024 17:07:32 GMT</pubDate>
    </item>
    <item>
      <title>多元分布函数示例[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658818/multivariate-distribution-function-examples</link>
      <description><![CDATA[我正在寻找多元分布的累积分布函数 (CDF) 的示例。我在网上搜索过但没有找到。有人能给我提供一些示例吗？我正在寻找一些 $k$ 维 CDF。]]></description>
      <guid>https://stats.stackexchange.com/questions/658818/multivariate-distribution-function-examples</guid>
      <pubDate>Mon, 16 Dec 2024 16:59:45 GMT</pubDate>
    </item>
    <item>
      <title>多个非独立同分布 beta 素数变量之和</title>
      <link>https://stats.stackexchange.com/questions/658799/the-sum-of-multiple-non-i-i-d-beta-prime-variables</link>
      <description><![CDATA[假设 $X_1$,$X_2$,$X_3$ 是独立同分布的。伽马随机变量，则$\frac{X_1}{X_2}$、$\frac{X_2}{X_3}$、$\frac{X_3}{X_1}$服从 beta 素数分布且相互关联。
那么，$\frac{X_1}{X_2}+\frac{X_2}{X_3}+\frac{X_3}{X_1}$的分布是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658799/the-sum-of-multiple-non-i-i-d-beta-prime-variables</guid>
      <pubDate>Mon, 16 Dec 2024 08:29:57 GMT</pubDate>
    </item>
    <item>
      <title>在回归模型中意外地两次包含同一个变量？</title>
      <link>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</link>
      <description><![CDATA[我在 R (mgcv) 中有这种混合效应 GAM 回归：
library(mgcv)
gam_beta &lt;- gam( 
y ~ te(time, x1) + te(time, x2) + s(time, by = city) + s(city, bs = &quot;re&quot;), 
data = my_data,
method = &quot;REML&quot;, 
family = betar(link = &quot;logit&quot;)
)

我尝试为该模型编写方程（基于我对 `mgcv te 的理解） noreferrer&quot;&gt;https://www.rdocumentation.org/packages/mgcv/versions/1.9-1/topics/te):
$$ y_{ij} \sim \text{Beta}(\mu_{ij}\phi, (1-\mu_{ij})\phi) $$
$$\mu_{ij} = \frac{1}{1+e^{-\eta_{ij}}}$$
$$ \text{logit}(\mu_{ij}) = \eta_{ij}= \beta_0 + f_{12}(time_{ij}, x1_{ij}) + f_{34}(time_{ij}, x2_{ij}) + h_i(time_{ij}) + b_i $$
我尝试将其进一步扩展：
$$ \eta_{ij} = \underbrace{\sum_{k=1}^{K_1} \hat{\gamma}_{1k}f_{1k}(time_{ij}) + \sum_{l=1}^{L_1} \hat{\gamma}_{2l}g_{1l}(x1_{ij}) + \sum_{k=1}^{K_1}\sum_{l=1}^{L_1} \hat{\gamma}_{3kl}f_{1k}(time_{ij})g_{1l}(x1_{ij})}_{\text{first te(): time and x1 term}} + $$
$$ \underbrace{\sum_{m=1}^{M_1} \hat{\gamma}_{4m}f_{2m}(time_{ij}) + \sum_{n=1}^{N_1} \hat{\gamma}_{5n}g_{2n}(x2_{ij}) + \sum_{m=1}^{M_2}\sum_{n=1}^{N_2} \hat{\gamma}_{6mn}f_{2m}(time_{ij})g_{2n}(x2_{ij})}_{\text{second te(): time and x2 term}} + $$
$$ \underbrace{\sum_{p=1}^P \hat{\alpha}_{ip}h_p(time_{ij})}_{\text{city-specific smooth}} + \underbrace{\hat{b}_i}_{\text{random effect}} $$
我的问题如下：我知道 mgcv 中的 te 函数既包含主效应，又包含交互效应（GAM 回归：交互作用与主效应？）。但这是否意味着某个术语存在被重复计算并在 GAM 方程中出现两次的风险？
例如，我有 te(time,x1) 和 te(time,x2)。这是因为我想在模型中包含时间与协变量 x1 和 x2 的相互作用。但这会导致时间的主效应被包含两次吗？或者 mgcv 会识别这一点并且只包含一次吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</guid>
      <pubDate>Mon, 16 Dec 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>需要有共同原因的因果调整公式</title>
      <link>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</link>
      <description><![CDATA[
在上述因果模型中，计算$P(X=x \mid \text{do}(Y=y))$时，是否需要使用因果调整公式$\sum_c P(X=x \mid Y=y, C=c) P(C=c)$？一旦我们$\text{do}(Y=y)$，$Y$的生成过程是否就独立于$X$的生成过程，因此$P(X=x \mid \text{do}(Y=y)) = P(X=x)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</guid>
      <pubDate>Mon, 16 Dec 2024 06:30:13 GMT</pubDate>
    </item>
    <item>
      <title>纳入因变量的下限是否可以改善估计？</title>
      <link>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</link>
      <description><![CDATA[假设我们抛硬币 $K$ 次，其中 如果正面，则为 $Z_k = 1$，否则为 0，并且 $Y = \sum_{k=1}^{K} Z_k$ 是正面的总数。假设这些是 i.i.d. 公平硬币，并且 $P(Z_k=1) = 0.5$。
然后我们重复此游戏 $n$ 次，每次抛 $K$ 枚硬币并观察实现 $Y_i$。目标是预测每场游戏中正面朝上的次数$\{Y_i : i=1,\dots, n\}$。

由于我们知道分布$Y \sim Binom(K, 0.5)$，标准/“朴素”方法就是简单的均值估计量：
$$ \hat{Y}_i = \mathbb{E}[Y] = 0.5K$$
这为$n$场游戏中的每一场提供恒定的预测。
现在问题如下。假设我们处于$i$场游戏。在 $K$ 次抛硬币之前，我们可以随时暂停游戏，优化模型，然后继续进行其余的抛硬币。我们能改进朴素估计器吗？
Oracle 估计器会设置 $\hat{Y}_i = Y_i$ 和 $MSE(Y_i, \hat{Y}_i) = 0$，但这在实践中显然是不可能的，因为我们实际上并不知道结果是什么。然而，每次抛硬币，我们都会收集更多关于 $Y_i$ 下限的信息。更准确地说，如果我们暂停翻转并观察到有$c_i$次正面，那么我们就知道
$$ Y_i \geq c_i $$
这就会激发&quot;增强&quot;估计量：
$$ \hat{Y}_i^{aug}(c_i) = \mathbb{E}[Y|Y\geq c_i] = \frac{ \int_{c_i}^{K} y \ dP_Y}{\int_{c_i}^{K} dP_Y} = \frac{\sum_{y=c_i}^{K} y P(Y=y)}{P(Y \geq c_i)}$$
其中，朴素估计量是$c_i = 0$的一个特例。将条件$\sigma$-代数的解释作为信息，我们获得了关于每个$Y_i$的一些额外信息，这应该可以让我们获得更好的预测。例如，假设$K=10$，我们在$c=6$次翻转后暂停游戏。朴素估计器将预测$\hat{Y}_i = 5$。但是我们已经知道 $Y_i \geq 6$，因此任何高于 6 的预测都会比朴素估计更接近真实的 $Y_i$。
有没有办法正式证明增强估计在某种意义上比朴素估计“更好”？

我用 $K=10$ 进行了数值模拟，得到了一些有趣的结果。这里的 x 轴是让 $c = pY$ 和 $p \in [0,1]$。随着 $c$ 的增加，我们获得更多的“部分知识”关于$Y$。直观上讲，我们拥有的信息越多，MSE 就越低，我们的预测就越好，但 U 形现象很有趣。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</guid>
      <pubDate>Sat, 14 Dec 2024 05:37:35 GMT</pubDate>
    </item>
    <item>
      <title>检查异常值随时间增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</link>
      <description><![CDATA[有人要求我测试多年来高异常值的数量和大小是否有所增加。目的是表明随着时间的推移（基数保持不变），极端情况越来越多，越来越高。
我有很多例子和年份、年龄组和性别之间的比较，但下面我只会展示一个。有两组数据，恰当地命名为 group1 (2022)，包含 207 个样本，group2 (2023)，包含 250 个样本。y 轴变量以整数测量。
首先，进行 t 检验，表明平均值有所下降。

绘制了箱线图来可视化这一点
应该注意的是，group2 有 9 个点高于 10（大约为 group 1 的上限），group2 有 10 个点约为 10（总共 12 个高异常值），其中第 2 组中的顶级异常值高于第 1 组中的异常值。所有异常值都经过严格检查，以确认它们是有效的数据点。

并且为了合理性，绘制了 var 随日期变化的散点图。红线表示箱线图的上限，其中任何高于该上限的点都被视为异常值。

这些表明平均值/中位数有所下降，但是有人要求我统计地确认 2023 年是否存在更多和更高的异常值，无论平均值的行为如何。我被要求在不同的性别、年龄和性别群体中展示这一点，在某些群体中比其他群体更明显。
我该如何进行统计测试？
[编辑：&#39;样本量&#39;，箱线图中没有平均值]]]></description>
      <guid>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</guid>
      <pubDate>Fri, 13 Dec 2024 06:09:28 GMT</pubDate>
    </item>
    </channel>
</rss>