<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 22 Nov 2024 09:20:01 GMT</lastBuildDate>
    <item>
      <title>测试马尔可夫特性和模拟/验证的代码</title>
      <link>https://stats.stackexchange.com/questions/657664/code-for-testing-markov-property-simulation-validation</link>
      <description><![CDATA[我知道这个问题之前已经有人问过了（例如1、2、3），但这些答案都没有提供代码。
根据以上链接提供的信息（尤其是这篇论文），我已经实现了 R 代码来：

生成随机马尔可夫样本
运行 Pearson &amp;似然比$\chi^2$检验

代码
注意：我们不允许零概率转换；这会使测试统计数据的定义更加复杂。
library(&#39;ggplot2&#39;)
rbind.lappy = function(...){ # 便利
do.call(rbind,parallel::mclapply(...,mc.cores=7))
}
px.random = function(d=2){ # 生成随机转换矩阵
px = matrix(runif(d^2,.1,.9),d,d) # 随机数
px = sweep(px,1,rowSums(px),&#39;/&#39;) # 标准化
}
markov.limit = function(px){ # 获取极限分布
e1 = eigen(t(px))$vectors[,1]
p0 = e1 / sum(e1)
}
markov.sim = function(p0,px,nt,ni){ # 模拟样本
ns = length(p0)
state = list(sample(1:ns,ni,p=p0,rep=TRUE)) # 初始时间
for (i in 2:nt){ # 后续每个时间
state[[i]] = sapply(state[[i-1]],function(si){ sample(1:ns,1,p=px[si,]) })
}
names(state) = paste0(&#39;s&#39;,1:nt)
ms = data.frame(i=1:ni,state)
}
markov.test = function(ms){
ns = length(unique(ms[,2])) # 状态数
nt = ncol(ms)-1 # 时间点数
n_hij = array(1,c(ns,ns,ns)) # 二阶计数
n_hi = array(1,c(ns,ns)) # 一阶计数
for (m in seq(nt-2)){ n_hij = n_hij + table(ms[paste0(&#39;s&#39;,m+0:2)]) }
for (m in seq(nt-1)){ n_hi = n_hi + table(ms[paste0(&#39;s&#39;,m+0:1)]) }
p_hij = sweep(n_hij,2:3,colSums(n_hij),&#39;/&#39;) # 标准化
p_hi = sweep(n_hi, 2, colSums(n_hi), &#39;/&#39;) # 标准化
# 以下：重复 c(*_hi) 以匹配 c(*_hij)，因为 j 是最后一个维度
Q = c( # 测试统计量：两个 chi^2 相同 d.f.
皮尔逊 = sum(c(n_hi)/c(p_hi)*(c(p_hij)-c(p_hi))^2),
    like.ratio = sum(c(n_hij)*log(c(p_hij)/c(p_hi))) )
  p = pchisq(Q,df=ns*(ns-1)*(nt-1),下=FALSE)
}
markov.test.pvs = 函数(nt,ni,ns=2,nk=100,lim=1){
  pvs = rbind.lappy(1:nk,函数(k){
    设置种子(k)
    px = px.随机(ns)
    if (lim){ p0 = markov.limit(px) }
    否则 { p0 = 代表(1,ns) / ns }
    ms = markov.sim(p0,px,nt=nt,ni=ni)
    光伏= c(nt=nt,ni=ni,ns=ns,nk=nk,lim=lim,markov.test(ms))
})
}
# main
G = expand.grid( # 要扫描的参数
ni=c(30,100,300,1000), # 个体数（链）
nt=3:7, # 时间点数
ns=2, # 状态数
nk=1000, # 重复次数
lim=0:1) # 在稳定状态下初始化
pvs = rbind.lappy(split(G,1:nrow(G)),do.call,what=markov.test.pvs)
# 重塑 &amp;图
pvs.m = reshape2::melt(as.data.frame(pvs),id=colnames(pvs)[1:5])
pvs.m$init = factor(pvs.m$lim,0:1,c(&#39;uniform&#39;,&#39;limit&#39;))
pos = position_dodge(width=1)
g = ggplot(pvs.m,aes(y=value,x=&#39;&#39;,color=variable,lty=init)) +
facet_grid(&#39;ni~nt&#39;,labeller=label_both) +
geom_violin(scale=&#39;width&#39;,position=pos,fill=NA) +
geom_hline(yintercept=.05,lty=&#39;11&#39;) +
stat_summary(geom=&#39;text&#39;,position=pos,show.legend=FALSE,
fun.data=function(x){ data.frame(y=-.1,label=mean(x &lt; .05),size=2) }) +
labs(y=&#39;p value&#39;,x=&#39;&#39;,color=&#39;statistic&#39;) + ylim(-.1,1)
ggsave(&#39;Rplots.pdf&#39;,w=8,h=6)


结果

问题

我的代码是否正确模拟了马尔可夫样本？
我的代码是否正确实现了两个测试？
如果1 和 2，为什么 I 类（假阳性）错误率存在差异：


Pearson 与 LR 检验（统计量：颜色）
链是否在平衡/极限下初始化（init：线型）
观察到的时间点数量（nt：水平面板）
观察到的链数量（ni：垂直面板）

这些趋势都是预期结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657664/code-for-testing-markov-property-simulation-validation</guid>
      <pubDate>Fri, 22 Nov 2024 09:04:40 GMT</pubDate>
    </item>
    <item>
      <title>检查两组比例是否_无差异_的检验</title>
      <link>https://stats.stackexchange.com/questions/657663/a-test-to-check-whether-two-sets-of-proportions-are-not-different</link>
      <description><![CDATA[是否有检验方法可以检查两组小比例是否显著无差异？
例如，考虑两组比例
(0.2,0.3,0.25,0.35,0.19)
(0.31, 0.25, 0.21,0.17, 0.22) 
我想证明两组显著无差异。这意味着零假设必须是它们不同。
如果对数据来源​​感兴趣，那就是各种样本的细胞类型比例。我想表明，经过治疗后，各种细胞类型比例的分布没有改变。
之所以选择零假设和备择假设，是因为我感兴趣的实质性主张是两种情况之间没有发生任何变化。无法拒绝无变化的零假设并不等同于接受无变化的假设，后者才是我感兴趣的。]]></description>
      <guid>https://stats.stackexchange.com/questions/657663/a-test-to-check-whether-two-sets-of-proportions-are-not-different</guid>
      <pubDate>Fri, 22 Nov 2024 08:15:29 GMT</pubDate>
    </item>
    <item>
      <title>血液碱度与癌症：癌症相关因素、转移效应和血液 pH 相关性：我们可用的工具</title>
      <link>https://stats.stackexchange.com/questions/657661/blood-alkalinity-and-cancer-cancer-implicants-metastasis-effect-and-blood-ph</link>
      <description><![CDATA[假设我有

一个可以量化的原因变量

一个可以量化的结果变量

原因数量如何影响结果数量的图表

一些相关因素（这些不是暗示结果的原因，但可以共存）。


我们想确定改变相关因素是否会改变蕴涵项和确定结果的图表。
我可以使用哪些统计工具？
例如，我们可以有：

存在致癌印迹（蕴涵项）

血液系统中存在转移（效应）

相关因素（血液 pH 值，以及系统中物质的存在（可能与 pH 有关，影响 pH 值）


我们想知道改变血液的 pH 值是否会影响转移产生的含义
也就是说，我们想知道带电的 pH 值是否是含义的影响（副作用），... 或者改变血液 pH 值是否可以改变含义图
假设，血液 pH 值可以通过营养改变（例如，假设饮食或营养素可以使血液碱化）。
我可以使用哪些统计工具？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657661/blood-alkalinity-and-cancer-cancer-implicants-metastasis-effect-and-blood-ph</guid>
      <pubDate>Fri, 22 Nov 2024 07:57:56 GMT</pubDate>
    </item>
    <item>
      <title>多个独立同分布随机变量乘积的方差？</title>
      <link>https://stats.stackexchange.com/questions/657659/variance-of-product-of-multiple-i-i-d-random-variables</link>
      <description><![CDATA[定义：如果随机变量 X1、X2、...、Xn 是独立的，并且具有相同的边际分布，则称它们为独立同分布 (i.i.d.)：
FX1(x)=FX2(x)=...=FXn(x)，对于所有 x∈R。
它们的乘积的期望值为：
E[X1*X2*⋯*Xn] = E[X1]*E[X2]*⋯*E[Xn] = E[X1]*E[X1]*⋯*E[X1] = (E[X1])^n
问题：它们的方差是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/657659/variance-of-product-of-multiple-i-i-d-random-variables</guid>
      <pubDate>Fri, 22 Nov 2024 06:38:50 GMT</pubDate>
    </item>
    <item>
      <title>发生率受测试频率影响</title>
      <link>https://stats.stackexchange.com/questions/657657/incidence-influenced-by-test-frequency</link>
      <description><![CDATA[我对研究设计感到困惑。假设我想研究一种疾病的发病率，但这种疾病大多无症状，其检测仅依赖于定期检测。有些人的检测频率比其他人高。我想根据每个人的检测频率为他们分配权重。如果我打算使用逆倾向得分来计算权重（仅举一个例子）：
PS= glm(test_frequency~age+sex, data=df)
PS$Wt= 1/predict(PS, df)
这听起来合理吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657657/incidence-influenced-by-test-frequency</guid>
      <pubDate>Fri, 22 Nov 2024 05:07:30 GMT</pubDate>
    </item>
    <item>
      <title>DF 和 ADF 检验结果相矛盾</title>
      <link>https://stats.stackexchange.com/questions/657656/conflicting-results-in-df-and-adf-tests</link>
      <description><![CDATA[我正在对 globtemp 数据集进行单位根检验，该数据集显然是具有趋势和季节性（非平稳）的序列。但是，当应用简单的 Dickey-Fuller 检验时，我获得的 p 值很小，导致拒绝零假设并表明该序列是平稳的。
同时，使用增强版本 (ADF) 执行测试，使用 R 的默认滞后数 (k)，p 值不会拒绝零假设，表明时间序列是非平稳的。话虽如此，我很困惑，不明白这种差异。为什么在简单的 DF 测试（k=0）的情况下，测试无法产生真实的结果？此外，如果测试对“k”的选择如此敏感，那么最好的方法是什么？我们应该始终依赖默认值吗？
此外，我读到残差中存在自相关违反了测试中残差不相关的假设，可能会导致错误的结果。因此，我还评估了第一次测试（DF）残差中是否存在自相关，它们的行为与白噪声的行为一致（我也使用 Box-Ljung 对此进行了测试）。这让我对上面提到的不一致的结果更加困惑。
可以检查下面我所做的代码：
library(tseries)

globtemp &lt;- stats::ts(
c(-0.32, -0.32, -0.4, -0.39, -0.65, -0.43, -0.4, -0.52, -0.3, -0.12,
-0.4, -0.42, -0.39, -0.45, -0.35, -0.36, -0.19, -0.14, -0.37, -0.22,
0, -0.08, -0.24, -0.36, -0.49, -0.27, -0.19, -0.43, -0.29, -0.3,
    -0.29、-0.29、-0.28、-0.23、-0.04、-0.02、-0.24、-0.42、-0.35、-0.16、
    -0.17、-0.09、-0.13、-0.16、-0.14、-0.14、0.1、-0.03、0.03、-0.18、
    -0.06、0.04、0.02、-0.13、0.03、-0.06、0.02、0.13、0.13、-0.03、
    0.15、0.12、0.1、0.04、0.11、-0.04、0.01、0.13、-0.01、 -0.06,
    -0.14、-0.02、0.04、0.14、-0.07、-0.06、-0.17、0.1、0.1、0.05、
    -0.01、0.08、0.02、0.02、-0.26、-0.16、-0.09、-0.02、-0.12、0.03、
    0.04、-0.11、-0.07、0.19、-0.07、-0.05、-0.22、0.16、0.09、0.14、
    0.28、0.39、0.07、0.29、0.11、0.11、0.16、0.32、0.35、 0.25,
0.47, 0.41, 0.13),
start=1880, end = 1992)

plot(globtemp)

adf.test(globtemp, k=0) #DF 检验
#Dickey-Fuller = -3.4235, 滞后阶数 = 4, p 值 = 0.05414

dx &lt;- diff(globtemp) 
x_lag &lt;- globtemp[-length(globtemp)] 
df_model &lt;- lm(dx ~ x_lag) 
summary(df_model)

residuals_df &lt;- resid(df_model)
acf(residuals_df, 50, main = &quot;&quot;) #无自相关
Box.test(residuals_df, lag = 15, type = &quot;Ljung-Box&quot;)

adf.test(globtemp) #ADF 默认为 &quot;k&quot;

#Dickey-Fuller = -3.4235，滞后阶数 = 4，p 值 = 0.05414
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/657656/conflicting-results-in-df-and-adf-tests</guid>
      <pubDate>Fri, 22 Nov 2024 04:44:14 GMT</pubDate>
    </item>
    <item>
      <title>将连续变量转换为逻辑回归的更大序数类别？</title>
      <link>https://stats.stackexchange.com/questions/657655/converting-a-continuous-variable-into-a-larger-ordinal-categories-for-logistic-r</link>
      <description><![CDATA[与结核病类似，非结核分枝杆菌肺病患者需要咳出痰液才能确诊。但是，没有关于需要多少痰液才能达到足够灵敏度的数据。
我目前正在研究痰液量 (x) 是否与培养阳性 (y) 相关的问题。
在逻辑回归模型中，分析因变量 Y（培养阳性）与自变量 X（最初是痰液量的连续变量）之间的关联，如果您发现关系不是线性的并且可能存在阈值效应，您能否将变量 X 从连续变量转换为权重不等的较大离散序数值并将其分析为数值（而不是纯粹的分类值）？]]></description>
      <guid>https://stats.stackexchange.com/questions/657655/converting-a-continuous-variable-into-a-larger-ordinal-categories-for-logistic-r</guid>
      <pubDate>Fri, 22 Nov 2024 03:59:53 GMT</pubDate>
    </item>
    <item>
      <title>对偶自然对数模型中的过度拟合</title>
      <link>https://stats.stackexchange.com/questions/657652/overfitting-in-a-dual-natural-logarithm-model</link>
      <description><![CDATA[我有这个函数
$$y = a \ln(p(t + 32)) - b \ln(q(t+30))$$
其中：

$t,y$ 是测量值
$a, b, p$ 和 $q$ 是拟合值
$30$ 和 $32$ 是偏移项

我使用此函数拟合质谱数据，其中 $y$ 是强度，$t$ 是气体平衡后的时间。目标是尽可能准确地测量 $t=0$ 时的 $y$。
使用标准曲线拟合程序，特别是 scipy.optimize.curve_fit，在绝大多数情况下会产生理想的结果。示例：
函数：
 def natural_log_func(self, t, a, b, p, q):
return a * np.log(p*(t + self.pos_lneq_time)) - b * np.log(q*(t + self.neg_lneq_time))

def fit(self):
return curve_fit(self.natural_log_func, self.t, self.y, maxfev=100000)


然而，在少数情况下，我看到了过度拟合：

其中数据是：
7.083,3.63E-12
14.291,3.49E-12
21.494,3.48E-12
28.709,3.59E-12
35.915,3.79E-12
43.02,3.60E-12
50.226,3.80E-12
57.431,3.84E-12
64.639,3.76E-12
71.846,3.79E-12
79.05 6,3.84E-12
86.262,3.71E-12
93.467,4.05E-12
100.578,3.93E-12
107.783,4.12E-12
114.992,4.01E-12
122.2,4.12E-12
129.403,4.30E-12
136.606,4.12E-12
143.812,4.28E-12

另一个两个例子：

其中数据为：
$t$ = 7.208,14.411,21.624,28.833,36.038,43.142,50.347,57.553,64.759,71.964,79.173,86.378,93.583,100.785,107.892,115.095,122.303,129.51,136.711,143.92
4 amu = 5.48E-14,3.60E-14,2.75E-14,5.22E-14,5.87E-14,5.14E-14,5.70E-14,5.17E-14,5.41E-14,5.53E-14,4.58E-14,7.52E-14,4.85E-14,7.06E-14,9.48E-14,6.42E-14,8.56E-14,6.71E-14,8.48E-14,9.84E-14
40 amu = 3.66E-12,3.73E-12,3.94E-12,3.94E-12,4.02E-12,3.92E-12,3.90E-12,4.09E-12,4.18E-12,4.17E-12,4.24E-12,4.13E-12,4.35E-12,4.32E-12,4.51E-12,4.41E-12,4.74E-12,4.62E-12,4.68E-12,4.64E-12
我可以做些什么来防止这些“俯冲”在低$t$值时形成？
编辑：请同时考虑以下示例：
$t$ = 5.303, 12.508, 19.711, 26.916, 34.13, 41.335, 48.44, 55.645, 62.847, 70.051, 77.258, 84.46, 91.67, 98.877, 105.98, 113.286, 120.391, 127.498, 134.704, 141.909
$y$ = 1459.0265113713006、1461.3176024628895、1470.7175396409543、1467.8009514214775、1466.5423320874656、 1473.6950214047804、1467.676141431994、1464.8844871395088、1460.1777269623358、1466.415876623664、1466.2427296537421、 1467.0116731759495, 1468.5874962643757, 1461.1129950726006, 1470.1431311995577, 1469.7089696334676, 1469.1248745384707, 1469.0477801972727, 1472.1239998394688, 1465.2701939696003
]]></description>
      <guid>https://stats.stackexchange.com/questions/657652/overfitting-in-a-dual-natural-logarithm-model</guid>
      <pubDate>Fri, 22 Nov 2024 00:53:34 GMT</pubDate>
    </item>
    <item>
      <title>rugarch 包中条件方差的初始值如何计算？</title>
      <link>https://stats.stackexchange.com/questions/657651/how-are-initial-values-of-conditional-variance-calculated-in-rugarch-package</link>
      <description><![CDATA[我正在尝试使用 rugarch 库验证我的 0 均值 GARCH(1,1) 模型的计算，起初我以为条件方差的初始值与非条件方差（python 中的 arch 包使用）是相同的值，但当我重新检查条件方差的第一个初始值时，它与非条件方差不同。
我尝试使用计算器手动计算它，它给了我与 uncvariance(garch_fit) 相同的输出，这不是来自模型的条件方差的初始值。]]></description>
      <guid>https://stats.stackexchange.com/questions/657651/how-are-initial-values-of-conditional-variance-calculated-in-rugarch-package</guid>
      <pubDate>Fri, 22 Nov 2024 00:48:50 GMT</pubDate>
    </item>
    <item>
      <title>时间序列模型和平稳性</title>
      <link>https://stats.stackexchange.com/questions/657649/time-series-model-and-stationarity</link>
      <description><![CDATA[考虑一个非常简单的模型，该模型预测$y_t$作为$x_t$上的函数，使用真实数据构建，如下所示：
$y_t = a + b.x_t$
对于这样的系统，我们需要$y_t$和$x_t$都是I(0)，但这里我谈论的是具有真实噪声数据的实际应用。在我的例子中，使用ADF、PP和KPSS测试，$y_t$绝对是平稳的。问题是$x_t$“看起来”平稳且“直观地”是平稳的，但根据用于构建我的模型的时间范围，它在 3 次平稳性测试中没有通过 2 次。
如果我扩大范围来评估平稳性，那么 $x_t$ 会通过 2 或 3 次测试，这意味着从长期来看 $x_t$ 是平稳的。请注意，如果我将范围从 1980 年推至 2024 年，它将再次变为非平稳。
问题：

扩大范围以评估平稳性的论点是否有效，以支持使用 $x_t$？

有关于这个主题的文献吗？

如果可以在与用于构建有效模型的范围不同的范围内评估平稳性，那么我如何将其与回归系数不变的事实相协调，同时论证 $x_t$ 在较长时期内是平稳的，甚至 $x_t$ 是“直观地”平稳的。因此，如何通过论证模型在数学上合理？

]]></description>
      <guid>https://stats.stackexchange.com/questions/657649/time-series-model-and-stationarity</guid>
      <pubDate>Fri, 22 Nov 2024 00:14:27 GMT</pubDate>
    </item>
    <item>
      <title>我应该为梦幻英超联赛模型预测个人数据还是整体得分？</title>
      <link>https://stats.stackexchange.com/questions/657648/should-i-predict-individual-stats-or-points-as-a-whole-for-a-fantasy-premier-lea</link>
      <description><![CDATA[我正在做一项大学作业，目的是使用历史比赛数据预测梦幻英超联赛球员的得分。在 FPL 中，球员根据各种比赛统计数据（例如，上场时间、进球、助攻、零封）获得积分。得分公式很简单，但因位置而异（例如，后卫零封对手的得分高于中场球员）。
我的方法是使用 XGBoost 为各个统计数据（例如，助攻、扑救）训练单独的模型，然后结合这些预测，使用已知方程计算得分。例如：
预测预期助攻的特征：
player_id、gameweek、value、home_crowd_effect、opponent_defense_strength、own_attack_strength、rolling_xa_5、season、position
预测扑救的特征：
player_id、gameweek、value、home_crowd_effect、opponent_attack_strength、own_defense_strength、rolling_saves_5、season
这与我在网上看到的大多数例子不同，人们只训练一个模型来直接预测得分。例如，在这篇文章中，他们训练了一个积分模型，并得到了 ~0.74 的 R 平方。另一方面，我的方法似乎无法超过 ~0.33，这感觉差距很大。
现在我想知道：

使用多个模型来处理单个统计数据而不是使用单个模型来处理积分，是否有理论或实践优势？
是否有任何资源或研究论文详细讨论这种建模权衡？我还没有找到任何关于 Fantasy Premier League 的资源或研究论文，但也许同样的情况可能发生在不同的问题中。
]]></description>
      <guid>https://stats.stackexchange.com/questions/657648/should-i-predict-individual-stats-or-points-as-a-whole-for-a-fantasy-premier-lea</guid>
      <pubDate>Thu, 21 Nov 2024 23:49:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的某个 GAM 响应与数据不太吻合？</title>
      <link>https://stats.stackexchange.com/questions/657637/why-does-one-of-my-gam-responses-not-fit-the-data-well</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657637/why-does-one-of-my-gam-responses-not-fit-the-data-well</guid>
      <pubDate>Thu, 21 Nov 2024 20:10:18 GMT</pubDate>
    </item>
    <item>
      <title>使用线性混合模型时，输出变量中缺失多少数据是可以接受的？</title>
      <link>https://stats.stackexchange.com/questions/657631/how-much-missing-data-in-the-output-variable-is-ok-when-using-linear-mixed-model</link>
      <description><![CDATA[我有重复测量数据，但由于缺失，我计划使用线性混合模型。我唯一的预测因子是时间，结果变量是定量测量的幸福感得分。目标是确定幸福感是否随着时间的推移而发生整体变化。
幸福感得分是通过四个时间点的季度调查收集的，参与人数如下：

时间 1：25 名参与者
时间 2：54 名参与者
时间 3：70 名参与者
时间 4：120 名参与者

由于大量缺失数据，近 80% 的答复不完整。许多参与者只参加了一次，特别是在时间 4，缺乏后续数据。为了解决这个问题，我过滤了数据集以仅包含至少参加过两个时间点的参与者。经过筛选后，参与人数如下：

时间 1：21 名参与者
时间 2：35 名参与者
时间 3：46 名参与者
时间 4：47 名参与者

此调整将缺失数据减少至约 36%。排除仅参加过一次的参与者是否合适？缺失数据多少才合适？
我非常感谢任何反馈或建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/657631/how-much-missing-data-in-the-output-variable-is-ok-when-using-linear-mixed-model</guid>
      <pubDate>Thu, 21 Nov 2024 17:24:52 GMT</pubDate>
    </item>
    <item>
      <title>glmmTMB nbinom1 计算不正确？coef</title>
      <link>https://stats.stackexchange.com/questions/657620/glmmtmb-nbinom1-computing-incorrect-coef</link>
      <description><![CDATA[我有固定效应模型（无随机效应）葡萄糖 ~ 基因型，其中基因型是具有两个水平的因子。拟泊松和负二项式 GLM 应该估计相同的系数。但是，glmmTMB(nbinom1) 不会计算与 glm(quasipoisson)、glmTMBB(nbinom2) 或 glm.nb 匹配的模型系数。由于系数不同，估计的组边际均值也不同。这些在函数之间应该相同并且等同于样本均值，对吗？发生了什么？
library(data.table)
library(MASS)
library(glmmTMB)
fd &lt;- data.table(
genotype = rep(c(&quot;WT&quot;, &quot;KO&quot;), each = 8),
tumors = rnegbin(8*2, mu = rep(c(5, 10), each = 8), theta = 1)
)
qp1 &lt;- glm(tumors ~ genotype,
family = quasipoisson(link = &quot;log&quot;),
data = fd)
qp2 &lt;- glmmTMB(tumors ~ genotype,
family = nbinom1(link = &quot;log&quot;),
data = fd)
nb1 &lt;- glm.nb(tumors ~ genotype,
data = fd)
nb2 &lt;- glmmTMB(tumors ~ genotype,
family = nbinom2(link = &quot;log&quot;),
data = fd)
coef(summary(qp1))
coef(summary(qp2))$cond
coef(summary(nb1))
coef(summary(nb2))$cond

 估计标准误差 t 值 Pr(&gt;|t|)
(截距) 2.431418 0.2891563 8.408662 7.631869e-07
genotypeWT -1.215023 0.6044945 -2.009981 6.410986e-02
估计标准误差误差 z 值 Pr(&gt;|z|)
(截距) 2.3225197 0.3044603 7.628318 2.378361e-14
genotypeWT -0.8076885 0.4786590 -1.687399 9.152671e-02
估计标准误差 z 值 Pr(&gt;|z|)
(截距) 2.431418 0.3515361 6.916553 4.627644e-12
genotypeWT -1.215023 0.5226885 -2.324564 2.009530e-02
估计标准误差 z 值 Pr(&gt;|z|)
(截距) 2.431419 0.3515362 6.916554 4.627620e-12
genotypeWT -1.215022 0.5226886 -2.324563 2.009535e-02

更新
PBulls 链接到帖子，该帖子显示任何具有正交分类因子的 GLM 的系数都相等（如果包含截距，则加起来等于 log(mean)，如果排除截距，则等于 log(mean)）。那么为什么 glmmTMB(family = nbinom) 不是这种情况呢？
我修改了该链接中用户 cardinal 的回复中的代码，以包含两个准泊松拟合。这些是无截距模型中的系数（因此这些系数应等于样本均值）。
 negbin poisson gaussian invgauss gamma qpoisson qpoissson_tmb
XX1 4.234107 4.234107 4.234107 4.234107 4.234107 4.234107 4.288181
XX2 4.790820 4.790820 4.790820 4.790820 4.790820 4.789353
XX3 4.841033 4.841033 4.841033 4.841033 4.841033 4.841033 4.811718

以下是带有截距的模型的系数。这里，X2 和 X3 的系数（我们试图估计的影响）与其他 glms 相差约 10%。
 negbin poisson gaussian invgauss gamma qpoisson qpoissson_tmb
（截距）4.234107 4.234107 4.234107 4.234107 4.234107 4.234107 4.2881807
XX2 0.556713 0.556713 0.556713 0.556713 0.556713 0.5011718
XX3 0.606926 0.606926 0.606926 0.606926 0.606926 0.606926 0.5235374
]]></description>
      <guid>https://stats.stackexchange.com/questions/657620/glmmtmb-nbinom1-computing-incorrect-coef</guid>
      <pubDate>Thu, 21 Nov 2024 15:14:54 GMT</pubDate>
    </item>
    <item>
      <title>调查数据集处理</title>
      <link>https://stats.stackexchange.com/questions/657609/survey-data-set-manipulation</link>
      <description><![CDATA[我很抱歉这个问题太过简单，但我需要一些指导。我有两个数据集，第一个数据集是我认为的控制集，它是整个区域的 GPS 测量值。这些测量值的海拔就是问题所在。我还有另一个数据集，其海拔值与第一个数据集不同，是二阶获得的。我需要找到一个值来移动第二个数据集，以便它以 95% 的置信度匹配第一个数据值，也就是说，我想将第二个数据集移动一个我还没有找到的数字，以便移动后第二个数据集的新值都在控制 GPS 测量值的 5% 以内。找到移动第二个数据集的正确值的正确方法是什么，我如何验证移动的数据集是否在容差范围内？
非常感谢您的帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/657609/survey-data-set-manipulation</guid>
      <pubDate>Thu, 21 Nov 2024 11:35:22 GMT</pubDate>
    </item>
    </channel>
</rss>