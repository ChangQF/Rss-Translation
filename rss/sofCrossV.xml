<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 12 Apr 2024 09:14:37 GMT</lastBuildDate>
    <item>
      <title>rpart包如何在“缺失”的情况下得到“改善”？</title>
      <link>https://stats.stackexchange.com/questions/644860/how-does-the-rpart-package-get-the-improve-when-there-is-missing</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;库(mlbench)
库（r部分）

数据（声纳）

声纳[1，“V11”] &lt;- NA
ct1 &lt;- rpart(Class ~ .,data = 声纳, method = “class”, cp = 0)
摘要(ct1)


rpart包如何获得“improve=27.13488”什么时候有“1 缺失”？]]></description>
      <guid>https://stats.stackexchange.com/questions/644860/how-does-the-rpart-package-get-the-improve-when-there-is-missing</guid>
      <pubDate>Fri, 12 Apr 2024 08:55:30 GMT</pubDate>
    </item>
    <item>
      <title>这些值遵循什么分布（如果有）？</title>
      <link>https://stats.stackexchange.com/questions/644859/what-distribution-if-any-are-these-values-following</link>
      <description><![CDATA[我不确定这是否是问这个问题的正确地方，但这似乎是最相关的，因为我的问题是关于随机分布的。请告诉我是否应该将其移至其他社区。
我一直在研究 LCG/MCG 伪随机发生器的频谱测试值。在本文和我自己对更大的二次幂模数运行一些测试之间（在特别是 2^64 和 2^128），看起来在 24 维以内的光谱测试有一致的趋势，看起来与链接论文中提供的相似。使用 scipy.stats，我确定随着维度变高，分布越来越接近拟合 beta 分布，但对于 2 维和 3 维谱来说，它显然非常糟糕至少测试结果。此外，贝塔分布似乎低估了“高度”。即使在相对较高的尺寸下也能达到峰值。
这是否更适合某些现有的连续分布，还是 Beta 分布是我能做的最好的？]]></description>
      <guid>https://stats.stackexchange.com/questions/644859/what-distribution-if-any-are-these-values-following</guid>
      <pubDate>Fri, 12 Apr 2024 08:50:12 GMT</pubDate>
    </item>
    <item>
      <title>具有 Tweedie 分布的 GAM 可以用于二元响应吗？</title>
      <link>https://stats.stackexchange.com/questions/644858/can-gam-with-tweedie-distribution-be-used-for-a-binary-response</link>
      <description><![CDATA[我正在尝试使用 GAM 进行物种分布模型。数据集是每个网格中是否存在物种和环境变量。在 Virgili 等人的论文中。 (2018)，作者建议，“使用具有 Tweedie 分布和存在-不存在数据的 GAM，为罕见物种生成可靠的栖息地建模预测”。我尝试了以下代码：
模型 &lt;- gam(Occurrence ~ s(Depth) + s(Temperature), data=dt, family=tw(link=log), method=“REML”)
与二项分布模型相比，该模型具有较低的 AIC 和较高的解释偏差。 predict(Model, dt0, type=&quot;response&quot;)  的映射看起来很好。
但是，由于在 Tweedie 系列中不能选择 logit 链接函数，我可以将此预测输出称为“发生概率”吗？就像逻辑回归一样？]]></description>
      <guid>https://stats.stackexchange.com/questions/644858/can-gam-with-tweedie-distribution-be-used-for-a-binary-response</guid>
      <pubDate>Fri, 12 Apr 2024 08:49:49 GMT</pubDate>
    </item>
    <item>
      <title>数据缩减方法</title>
      <link>https://stats.stackexchange.com/questions/644857/methods-for-data-reduction</link>
      <description><![CDATA[主题：排放率计算中的数据缩减方法
亲爱的社区，
我在谷仓里进行了多次测量，以计算年排放率（例如氨、甲烷等）。这些测量是全年进行的。我正在寻找统计和数学上合理的方法来确定哪些天足以提供年排放率的代表性评估。
我已将具有固定和随机效应的混合线性模型应用于我的谷仓测量数据。然而，由于模型结果中存在科学上荒谬的相关性，我随后从数据集中计算了各个谷仓的温度加权平均值。将当前气温与该地点的长期每小时平均气温相比的相对频率作为权重因子。
猪舍的氨排放率取决于多种因素，包括温度、氮排泄量、氮排泄量中总氨氮 (TAN) 的比例、土壤污染程度、储存温度、空气流速、粪便中的 TAN 含量、粪便中的空气流速。畜舍和储藏室、脲酶活性、粪便pH值、占地面积、饲喂情况等均进行了测量。
哪些方法对于减少获取年排放平均值所需的测量天数或小时数是明智的？能否使用主成分分析（PCA）和聚类分析方法来选择或减少数据？在我的环境中应用这些方法时是否需要考虑具体步骤或注意事项？
对于有关此主题的任何建议或建议，我将非常感激。
提前谢谢您！
最好的问候]]></description>
      <guid>https://stats.stackexchange.com/questions/644857/methods-for-data-reduction</guid>
      <pubDate>Fri, 12 Apr 2024 08:37:56 GMT</pubDate>
    </item>
    <item>
      <title>多元 t 分布的 EM 算法</title>
      <link>https://stats.stackexchange.com/questions/644856/em-algorithm-for-the-multivariate-t-distribution</link>
      <description><![CDATA[我正在为多元 t 分布实现 EM 算法，并遵循此 纸。
根据 E-Step 期间的方程 (23)，他们给出：
$$
E\left(U_i \mid \boldsymbol{x}_i, \widehat{\boldsymbol{\Theta}}^{(k)}\right)=\frac{\hat{v}^{(k)}+p }{\hat{v}^{(k)}+\left(\boldsymbol{x}_i-\widehat{\boldsymbol{\mu}}^{(k)}\right)^T \widehat{\Sigma }^{(k)^{-1}}\left(\boldsymbol{x}_i-\widehat{\boldsymbol{\mu}}^{(k)}\right)}
$$
$$E\left(\log U_i \mid \boldsymbol{x}_i, \widehat{\boldsymbol{\Theta}}^{(k)}\right) \\
=\psi\left(\frac{\hat{v}^{(k)}+p}{2}\right)-\log \left(\frac{1}{2}\left(\hat{v }^{(k)}+\left(\boldsymbol{x}_i-\widehat{\boldsymbol{\mu}}^{(k)}\right)^T \widehat{\Sigma}^{(k) }{ }^{-1}\left(\boldsymbol{x}_i-\widehat{\boldsymbol{\mu}}^{(k)}\right)\right)\right)$$&lt; /p&gt;
其中 $\phi()$ 是 digamma 函数。那么目标函数就变为：
$$Q(\boldsymbol{\Theta} ; \widehat{\boldsymbol{\Theta}}^{(k)}) = \frac{n v}{2} \log \left(\frac{v}{2}\right) - n \log \Gamma\left(\frac{v}{2}\right)
 \left(\frac{v+p}{2}-1\right) \hat{u}_{2 i}^{(k)} - \frac{n p}{2} \log (2 \pi) - \frac{n}{2} \log |\Sigma|$$
$$- \frac{1}{2} \sum_{i=1}^n \hat{u}_{1 i}^{(k)}\左(v+(\boldsymbol{x}_i-\boldsymbol{\mu})^T \Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\mu})\right)$$
用于分发$\Gamma()$（以及digamma，$\ phi()$)?我们输入 $\nu/2$ 和 $\frac{v+p}{2}$每次迭代时的伽玛和迪伽玛 PDF，但我们需要 $\alpha$ 和 $\beta$ 。他们用什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644856/em-algorithm-for-the-multivariate-t-distribution</guid>
      <pubDate>Fri, 12 Apr 2024 07:35:19 GMT</pubDate>
    </item>
    <item>
      <title>我对字典学习的理解或者代码是错误的吗？</title>
      <link>https://stats.stackexchange.com/questions/644852/is-my-understanding-or-my-code-for-dictionary-learning-wrong</link>
      <description><![CDATA[所以我正在做一些休闲字典学习，我不确定我是否有正确的理解或者我的代码是否是错误的。目前，我采用 MNIST 数据集 $Y$，图像大小为 $28\times 28$ ，并尝试查找字典 $D$ 和稀疏代码 $X$，s.t. $Y \大约 DX$。在我的实验中，我采用 $Y\in \mathbb{R}^{28^2 \times 3}$，其中每一列都是手写的样本数字“5” （所以我不会将图像转换成补丁）。我初始化一个随机字典 $D\in\mathbb{R}^{28^2 \times 3}$，也就是说我总共有三个原子，即每个样品一个。对于我的稀疏代码 $X\in\mathbb{R}^{3\times 3}$，我将稀疏级别设置为 1，s.t。我在每一列中仅获得一个非零值。
现在，我希望字典算法能够“学习”只需将 $Y$ 的列放入 $D$ 中，并使稀疏代码接近到看起来像的东西
\begin{align}
X \approx \begin{pmatrix}
0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{pmatrix},
\end{对齐}
或行的任何其他排列。这样， $D$ 中的一个原子只需乘以身份，我就可以恢复我的 $Y$&lt; 列/span&gt; 完全正确。但是，我获得的代码的输出
\begin{align}
X = \begin{pmatrix}
0 &amp; 5.58615414&amp; 6.33388578\\
0 &amp; 0 &amp; 0 \\
9.55769633&amp; 0 &amp; 1
\end{pmatrix}。
\end{对齐}
现在，由于第一行中有两个非零值，这意味着我可以几乎完全恢复 $y_1$ ，但不能恢复 $y_2, y_3$ 因为它们都混合了。
我的直觉错了吗？当我只取两个样本时，它按预期工作，即 $Y\in\mathbb{R}^{28^2 \times 2}$。
提前致谢！
我的代码：
导入 mnist
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
从 sklearn. Linear_model 导入 o​​rthogonal_mp

def approx_ksvd_dictionary_update(D: np.ndarray, X: np.ndarray, Y: np.ndarray) -&gt; np.ndarray：
    # 取自 https://github.com/fubel/sparselandtools/tree/master/sparselandtools
    n, K = D.形状
    对于范围 (K) 内的 k：
        wk = np.nonzero(X[k, :])[0]
        如果 len(wk) == 0:
            继续
        D[:, k] = 0
        g = np.transpose(X)[wk, k]
        d = np.matmul(Y[:, wk], g) - np.matmul(D, X[:, wk]).dot(g)
        d = d / np.linalg.norm(d)
        g = np.matmul(Y[:, wk].T, d) - np.transpose(np.matmul(D, X[:, wk])).dot(d)
        D[:, k] = d
        X[k, wk] = g.T
    返回D

# 选择仅代表数字5的MNIST数据
数据 = mnist.mnist()
图像 = 数据[0][数据[1] == 5]

np.随机.种子(1)

# 选择三张样本图片，放入Y的列中
N = 3
图片 = []
对于范围 (N) 内的 j：
    imgs.append(images[j].reshape(28*28, 1))
Y = np.concatenate(imgs, 轴=1)
Y /= np.max(Y)

# 用 K=N 个原子初始化随机字典
K=N
n = Y.形状[0]
D = np.zeros([n, K])
对于范围 (K) 内的 j：
    D[:, j] = np.random.randn(n)
    D[:, j] *= 1 / np.linalg.norm(D[:, j])

# 进行字典学习
n_nonzeros_coefs=1
对于范围（10）内的 _：
    X = orthogonal_mp(D, Y, n_nonzero_coefs=n_nonzeros_coefs)
    D = approx_ksvd_dictionary_update(D, X, Y)

打印（X）
]]></description>
      <guid>https://stats.stackexchange.com/questions/644852/is-my-understanding-or-my-code-for-dictionary-learning-wrong</guid>
      <pubDate>Fri, 12 Apr 2024 05:26:21 GMT</pubDate>
    </item>
    <item>
      <title>CNN（一维和二维）必须采用相同大小的输入吗？</title>
      <link>https://stats.stackexchange.com/questions/644846/must-a-cnn-both-1d-and-2d-take-input-of-the-same-size</link>
      <description><![CDATA[我认为 CNN 输入数据必须始终具有相同的维度。如果我们输入一维表格数据，列的编号必须相同；如果我们输入 2D 图像数据，所有图像必须具有相同的尺寸。这种大小调整可能发生在 CNN 的输入层中，也可能发生在 CNN 外部 - 在数据处理阶段。
因此，我给我的主管写了以下电子邮件：
&lt;块引用&gt;
你好。
CNN 可以处理一维表格数据和二维数据。但是，它无法处理具有不同列长度的一维表格数据。
我们不能使用以下文件：
ABC.dat
 ------------------数据-------------------- --matrix- -
  6 赖氨酸 C 4.768 7.342 10.221 1 0 1 0 1 0 1 2 3
  7 酪氨酸C 8.992 6.431 4.110 0 1 0 1 0 0 1 2 3
  8 SER C 2.345 8.901 12.345 0 0 1 0 1 1 1 2 3

PQR.dat
--------------------数据-------------------- ---矩阵--
  0 丙氨酸 C 0.000 0.000 0.000 1 1 1 1 1 0 1 2 3 4 5 6
  1 GLU C 6.691 9.772 0.000 1 1 1 1 1 0 1 2 3 4 5 6
  2 PHE C 6.601 8.709 12.389 0 0 0 0 1 0 1 2 3 4 5 6
  3 参数 C 6.489 9.682 11.525 0 0 0 0 0 0 1 2 3 4 5 6
  4 HIS C 6.249 0.000 0.000 0 0 0 0 0 0 1 2 3 4 5 6
  5 ASP C 0.000 0.000 0.000 0 0 0 0 0 0 1 2 3 4 5 6

XYZ.dat
&lt;前&gt;&lt;代码&gt;--------------------数据-------------------- ---- - -矩阵 -  -  - -
  0 GLU C 0.773 6.403 9.702 1 0 1 0 1 0 0 1 2 3 4 5 6 7 8 9 10
  1 酪氨酸C 1.710 3.978 3.997 1 0 1 1 1 0 1 1 2 3 4 5 6 7 8 9 10
  2 ASP C 2.564 9.689 4.051 1 0 1 0 0 0 1 1 2 3 4 5 6 7 8 9 10
  3 酪氨酸C 4.485 4.886 8.724 1 0 0 1 1 1 0 1 2 3 4 5 6 7 8 9 10
  4 HIS C 6.145 7.992 9.437 1 0 0 1 0 0 1 1 2 3 4 5 6 7 8 9 10
  5 丙氨酸 C 5.373 3.810 6.506 1 0 0 0 0 0 1 1 2 3 4 5 6 7 8 9 10
  6 HIS C 6.314 3.519 1.994 0 1 0 1 1 0 0 1 2 3 4 5 6 7 8 9 10
  7 ASP C 8.348 3.026 9.201 0 1 1 0 1 0 1 1 2 3 4 5 6 7 8 9 10
  8 酪氨酸 5.810 2.019 9.094 0 1 0 1 1 1 0 1 2 3 4 5 6 7 8 9 10
  9 赖氨酸 C 7.361 1.221 2.055 0 0 0 1 0 0 0 1 2 3 4 5 6 7 8 9 10

我们可以将这三个文件输入 CNN 吗？当然，我们可以。然而，问题将是标签。在我们的数据中，每一行的第三列都有一个标签。如果我们将这些表作为 2D 数据输入 CNN，我们就会丢失这些标签。因为 CNN 需要为每条 2D 数据分配一个标签，在我们的例子中就是蛋白质名称。
另一个问题是 CNN 必须（并且必须）采用相同维度的 2D 输入。在我们的例子中，每个文件都有不同的尺寸。因此，我们必须将文件大小调整为通用尺寸（平均值、中位数或众数），或者需要将较小的图像用零填充到文件中找到的最大尺寸。在我们的例子中，这将一事无成。因为由于上一段中描述的标签问题，我们的 2D 数据首先将毫无用处。
亲切的问候。
学生

我的教授不同意这一点。
他写道：
&lt;块引用&gt;
&lt;块引用&gt;
另一个问题是 CNN 必须（并且必须）采用相同维度的 2D 输入。

不，没必要。以我们之前的论文为例：对于 N 个残基的蛋白质，输入的大小为 NxK，每个残基有 K 个特征。输出层为Nx2。对于每种蛋白质，输入的大小不同，我们使用相同的网络。它使用一维卷积。
&lt;块引用&gt;
在我们的例子中，每个文件都有不同的尺寸。因此，我们必须将文件大小调整为通用尺寸（平均值、中位数或众数），或者需要将较小的图像用零填充到文件中找到的最大尺寸。在我们的例子中，这将一事无成。因为由于上一段中描述的标签问题，我们的 2D 数据首先将毫无用处。

不，这不是必需的。
但是，您可以使用填充，否则您的图层将会收缩。更具体地说，当您的卷积窗口为 WxW 时，大小为 NxN 的输入将产生 (N-W) x (N-W) 的输出。
亲切的问候
主管

你能解决我的困惑吗？
CNN（一维和二维）是否必须接受相同大小的输入？]]></description>
      <guid>https://stats.stackexchange.com/questions/644846/must-a-cnn-both-1d-and-2d-take-input-of-the-same-size</guid>
      <pubDate>Fri, 12 Apr 2024 02:50:18 GMT</pubDate>
    </item>
    <item>
      <title>FDR 置信区间调整</title>
      <link>https://stats.stackexchange.com/questions/644844/fdr-adjustment-for-confidence-intervals</link>
      <description><![CDATA[我在 R 中有一个多元回归模型，我应该报告 beta 估计值、95 CI 和 p 值。模型中有很多变量，因此我使用 Benjamini-Hochberg 方法来调整 p 值。然而，现在 CI 和调整后的 p 值不匹配；有些变量的 95% CI 不包含零，但调整后的 p 值不显着。
我想知道如何调整 FDR 的 CI。我可以使用调整后的 p 值通过下面本文中描述的过程对 CI 进行逆向工程吗？
https://www.bmj.com/content/343/bmj.d2090 
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644844/fdr-adjustment-for-confidence-intervals</guid>
      <pubDate>Fri, 12 Apr 2024 01:07:52 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中通过复制运行回归</title>
      <link>https://stats.stackexchange.com/questions/644854/how-to-run-regression-with-replication-in-r</link>
      <description><![CDATA[看看是否有人知道如何在 R 中运行带有复制的回归分析。我有一个数据集，每个 X 值都有多个 Y 值。我可以取 Y 值的平均值，但这会丢弃信息和统计分析将失去力量。我有一段参考文本描述了数学，当然我可以尝试手工完成，但是其中的乐趣在哪里？
我尝试寻找将这一点考虑在内的代码示例，但尚未提出任何建议。我想象它就在那里，但出于某种原因我找不到它。我确实知道我不是在寻找多元回归或具有多个回归量的回归。
示例数据：

&lt;标题&gt;

x
y


&lt;正文&gt;

15
5,2,5,6,1,3


30
2,4,7,1,4


40
1,6,8


45
5、4、9、10、2、9



对于我的应用程序，我有 45 个不同的 x 变量和 3 个关联的 y 数据点。我相信带有复制的回归应该是可能的，如果需要手动计算而不是在 R 中计算，那么这只是一个沉重的负担。
感谢您的宝贵时间。]]></description>
      <guid>https://stats.stackexchange.com/questions/644854/how-to-run-regression-with-replication-in-r</guid>
      <pubDate>Fri, 12 Apr 2024 00:01:55 GMT</pubDate>
    </item>
    <item>
      <title>我们如何摆脱 MLE 中的 $p(x|\theta)$</title>
      <link>https://stats.stackexchange.com/questions/644841/how-do-we-get-rid-of-px-theta-in-mle</link>
      <description><![CDATA[简单的问题...通常机器学习的介绍会告诉您以下内容：

您想要最大化$p(\theta|D)$
应用贝叶斯定理$p(\theta|D) \propto p(D|\theta)p(\theta)$
如果你考虑 $p(\theta)$ 常数，你会得到 MLE，如果你考虑它高斯，你会得到 L2 正则化等等

但是，我想更详细一点，这是我的问题：
$$
p(\theta|D) \propto p(D|\theta)p(\theta) = p(x,y|\theta)p(\theta) = p(y|x, \theta)p(x| θ)p(θ)
$$
现在，通常我们优化的实际上是 $p(y|x,\theta)p(\theta)$，所以我的问题是...下我们要删除哪个假设 $p(x|\theta)$？
我们是否认为 $x$ 独立于 $\theta$ 并且保持不变？.. .]]></description>
      <guid>https://stats.stackexchange.com/questions/644841/how-do-we-get-rid-of-px-theta-in-mle</guid>
      <pubDate>Thu, 11 Apr 2024 22:11:00 GMT</pubDate>
    </item>
    <item>
      <title>如何证明K-Means将所有空间分割成凸多边形？</title>
      <link>https://stats.stackexchange.com/questions/644838/how-to-prove-that-k-means-splits-all-space-into-convex-polygons</link>
      <description><![CDATA[我想证明 K-Means 算法将整个对象空间分割成凸（可能没有边界）多边形。我试图利用K-Means算法收敛的事实并与之矛盾，但我没有成功。
任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/644838/how-to-prove-that-k-means-splits-all-space-into-convex-polygons</guid>
      <pubDate>Thu, 11 Apr 2024 21:41:29 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中模拟具有指定最小值和最大值以及 cov 和平均值的相关数据</title>
      <link>https://stats.stackexchange.com/questions/644848/how-to-simulate-correlated-data-with-specified-min-and-max-and-cov-and-mean-in-r</link>
      <description><![CDATA[我想将具有固定均值和协方差矩阵的数据模拟为多变量分布，其中生成的数据必须在范围 [floor ,上限] 内。
使用 MASS::mvrnorm 我无法指定范围（最大值和最小值）。这个问题有什么解决办法吗？
我阅读了所有相关主题和文档，但找不到可以设置生成数据的最大值和最小值的解决方案
xy &lt;- MASS::mvrnorm(n = 500, mu = c(mean_a,mean_b), Sigma = Sigma)
colnames(xy) &lt;- c(“a”, “b”)
xydf &lt;- data.frame(xy)
头(xydf)
]]></description>
      <guid>https://stats.stackexchange.com/questions/644848/how-to-simulate-correlated-data-with-specified-min-and-max-and-cov-and-mean-in-r</guid>
      <pubDate>Thu, 11 Apr 2024 19:55:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么选择术语“显着性”($\alpha$) 来表示 I 类错误的概率？</title>
      <link>https://stats.stackexchange.com/questions/644808/why-was-the-term-signifiance-alpha-chosen-for-the-probability-of-type-i-e</link>
      <description><![CDATA[我目前正在学习“统计 1”作为我计算机科学学位的一部分，我很难理解“重要性”的概念。
我们获得了以下定义：
$H_0$ - 零假设
$H_1$ - 替代假设。
$R$ - $H_0$ 拒绝区
$\bar{R}$ - $H_0$ 无拒绝区
$\begin{对齐} \alpha &amp;= P(\text{I 型错误})\\&amp;=P_{H_0}(\text{拒绝 } H_0 ) \\&amp;= P_{H_0}(X\in R) \\&amp;; \end{对齐} $
虽然我相信我已经很好地掌握了这些定义以及它们与 p 值的关系，但术语“显着性”并不适用。我仍然感到困惑。
我理解某事物“具有统计显着性”的概念，但显着性水平越高，出错的风险就越大，这似乎违反直觉。直觉上，当某件事非常重要时，我预计风险会较低。
有人可以解释一下为什么“重要性”一词如此重要吗？被选中了？
对于那些正在寻找的人来说，这些是关于这些术语的统计含义的一些非常好的讨论。我正在寻找更直观的解释来解释为什么选择这个术语。
比较和对比，p -值、显着性水平和 I 类错误
显着性水平 alpha 与 1 类误差 alpha 之间的关系是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644808/why-was-the-term-signifiance-alpha-chosen-for-the-probability-of-type-i-e</guid>
      <pubDate>Thu, 11 Apr 2024 15:02:37 GMT</pubDate>
    </item>
    <item>
      <title>OLS 回归的此应用程序的名称/术语是什么</title>
      <link>https://stats.stackexchange.com/questions/644803/what-is-the-name-terminology-for-this-application-of-ols-regression</link>
      <description><![CDATA[我没有统计背景，并被指示按照以下步骤填写缺失的数据。我想知道这个特定方法是否有一个名称，以便我可以了解更多它及其假设。
给定来自与感兴趣的站点距离不同的多个站点的数据集。每个站的数据集的完整性各不相同。通过应用 OLS 回归预测缺失值，估算感兴趣站的缺失数据。使用 OLS 回归优于其他模型的动机是为了“简单性”

按照邻近的顺序遍历站点（因为较近的站点可能与兴趣点具有更强的相关性）

在每次迭代中，使用选择的站点作为预测数据集 (X) 和感兴趣的站点作为目标数据集 (y) 创建 OLS 模型。使用模型来估算缺失的目标值。


通过对每个站点数据集执行指定的过程，应该会为感兴趣的站点创建一个扩展且更完整的数据集

这是应用 OLS 回归的有效方法吗（即结果有意义）吗？这种 OLS 回归的应用有具体的名称吗？或者我们应该使用其他回归模型来完成类似的事情？]]></description>
      <guid>https://stats.stackexchange.com/questions/644803/what-is-the-name-terminology-for-this-application-of-ols-regression</guid>
      <pubDate>Thu, 11 Apr 2024 14:13:23 GMT</pubDate>
    </item>
    <item>
      <title>如何计算下面的Dirichlet分布和Beta分布的期望？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/644769/how-to-calculate-the-expectation-of-the-following-dirichlet-distribution-and-bet</link>
      <description><![CDATA[这是我的研究中的一个问题，涉及基于LDA的模型的平均场假设的变分EM算法的推导。
我们都知道，鉴于 $\boldsymbol{\theta} \sim \mathrm{Dir}(\boldsymbol{\alpha})$，则 $E_{p(\boldsymbol{\theta} \mid \boldsymbol{\alpha})}[\log{\theta_k}] = \Psi(\alpha_k) - \Psi(\sum_ {k&#39;=1}^K \alpha_{k&#39;})$，其中 $\Psi$ 是 Digamma 函数。
然后，如何计算以下期望： $$E_{q(\psi, \boldsymbol{\varphi} \mid \boldsymbol{\lambda}, \boldsymbol{\ mu})}[\log{((1-\psi)\cdot \varphi_{v} +\psi)}]$$
其中 $\psi$ 和 $\boldsymbol{\varphi}$ 是独立的， $\psi \sim \mathrm{Beta}(\lambda_1, \lambda_2), \boldsymbol{\varphi} = (\varphi_1, \varphi_2,\cdots, \varphi_V) \sim \mathrm{Dir} (\boldsymbol{\mu})$]]></description>
      <guid>https://stats.stackexchange.com/questions/644769/how-to-calculate-the-expectation-of-the-following-dirichlet-distribution-and-bet</guid>
      <pubDate>Thu, 11 Apr 2024 02:03:03 GMT</pubDate>
    </item>
    </channel>
</rss>