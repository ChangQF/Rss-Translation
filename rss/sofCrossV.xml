<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 08 Sep 2024 21:14:36 GMT</lastBuildDate>
    <item>
      <title>如何取得 LRT 和 ROC？</title>
      <link>https://stats.stackexchange.com/questions/654057/how-to-obtain-lrt-and-roc</link>
      <description><![CDATA[若
$$
y = \sum_{i=0}^n x_i
$$
其中$x_i$为独立同分布随机变量，其密度为高斯分布$N(0, \sigma^2)$。总和中的变量数是具有泊松分布的随机变量：
$$
\Pr(n = k) = \frac{\lambda^k e^{-\lambda}}{k!}, \quad k = 0, 1, \ldots
$$
我们想在两个假设之间做出决定：
$$
H_1 : n \leq 1 \quad \text{and} \quad H_0 : n &gt; 1
$$.
如何得出 ROC 曲线（检测概率与误报概率）？]]></description>
      <guid>https://stats.stackexchange.com/questions/654057/how-to-obtain-lrt-and-roc</guid>
      <pubDate>Sun, 08 Sep 2024 21:09:27 GMT</pubDate>
    </item>
    <item>
      <title>样本量计算的假设检验与置信区间</title>
      <link>https://stats.stackexchange.com/questions/654055/hypothesis-testing-vs-confidence-intervals-for-sample-size-calculation</link>
      <description><![CDATA[假设我们正在审计一个低风险集团，该集团的历史平均逃税额为 \$7,883，审计时的标准差为 \$27,274。我的目标是确定平均逃税额是否接近于零。使用 t 检验，假设平均逃税额为零（双侧，$\alpha = 0.05$，功效 = 0.8），双侧检验所需的样本量为 96，单侧检验所需的样本量为 76。我假设备择假设下的平均值和标准差就是历史数据所显示的。
但是，如果我使用置信区间 $\bar{x} \pm 1.96 * \frac{\sigma}{\sqrt{n}}$ 进行计算并将下限设置为接近零，则求解 $n$ 得到的样本量为 46。
使用样本量 46 来确定零是否在置信区间内有效，从而否定了假设检验所建议的更大样本量的需要吗？如果不是，为什么这种方法是错误的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654055/hypothesis-testing-vs-confidence-intervals-for-sample-size-calculation</guid>
      <pubDate>Sun, 08 Sep 2024 20:43:37 GMT</pubDate>
    </item>
    <item>
      <title>使用诱导点进行精确的高斯过程推断</title>
      <link>https://stats.stackexchange.com/questions/654054/using-inducing-points-for-exact-gaussian-process-inference</link>
      <description><![CDATA[我对使用诱导点进行高斯过程推断有点困惑，特别是在应该是精确推断而不是近似的情况下。
对于高斯过程$f\sim GP(\textbf{0}, \kappa)$，其中
$ \kappa :X\times X \rightarrow \mathbb{R}$为正定核，训练数据为$f(x_1), \dots, f(x_n)$，如果想推断新点$x_*$的值，我们通常以$\mathcal{O}(n^3)$ 来反转矩阵 $\kappa(f(x_i), f(x_j))$，其中 $i,j=1,\dots n$，其中 $n$ 是提供正态分布 $p(f(x_*)|f(x_1), \dots, f(x_n))$ 的训练点数。
我的问题是关于使用诱导点来加速这种推理。具体来说，如果我们让
$y= f(x_*) + z$其中$z \sim N(0, \varepsilon)$，
则$p(y | f(x_*),f(x_1), \dots, f(x_n)) = p(y | f(x_*))$，
但同时$\{ f(x) | x \in X\} \cup \{y\}$ 是一个高斯过程，如果我们将 $\kappa$ 扩展到 $X \cup \{x_{**}\}$ 域并添加一个点，其中 $f(x_{**}) :=y$，以自然的方式（考虑到它提供了 GP 的协方差）：$\kappa&#39;(x_{**},x) := \kappa(x_*,x) \text{ for } x\neq x_{**} \text{ and } \kappa&#39;(x_{**},x_{**}) := \kappa(x_{*},x_{*}) + \varepsilon$
那么为什么我们不能使用诱导点方法，以诱导点为 $x_*$，推断 $\mathcal{O}(m^2n) = \mathcal{O}(n)$ 时间中 $f(x_{**})$ 的值，其中诱导点的数量为 $m=1$，如此处所用：https://andrewcharlesjones.github.io/journal/inducing-points.html，或在本文中：https://mlg.eng.cam.ac.uk/zoubin/papers/nips05spgp.pdf。
更详细地说，由于我们有 $p(y | f(x_*),f(x_1), \dots, f(x_n)) = p(y | f(x_*))$，我们知道 $p(y|f(x_1), \dots, f(x_n)) = \int p(y| f(x_*))\ p(f(x_*)|f(x_1), \dots, f(x_n))\ df(x_*)$，并且从右侧表达式中我们得到高斯形式，其参数我们可以在亚立方时间内推断出来，如上链接所示。
然后在这种情况下，如果 $\varepsilon$ 很小，我们可以计算后验的近似值 $p(y|f(x_1), \dots, f(x_n))$ 在线性时间内完成，这似乎是不可能的，因为这应该是 $\mathcal{O}(n^3)$。]]></description>
      <guid>https://stats.stackexchange.com/questions/654054/using-inducing-points-for-exact-gaussian-process-inference</guid>
      <pubDate>Sun, 08 Sep 2024 20:36:59 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在循环图中定义有限路径？</title>
      <link>https://stats.stackexchange.com/questions/654051/it-is-possible-to-define-finite-path-in-looped-graphs</link>
      <description><![CDATA[我对图论不太感兴趣，所以这个问题可能毫无意义。从非指导的角度来看，有向图或无向图中的路径和循环概念是清晰的。但如果我们转向循环图（即节点可以有循环），仍然可以在节点之间定义一条有限路径，其中中间的某些顶点是循环的？有人可以给我指出一些文献参考吗？
提前谢谢
Paolo]]></description>
      <guid>https://stats.stackexchange.com/questions/654051/it-is-possible-to-define-finite-path-in-looped-graphs</guid>
      <pubDate>Sun, 08 Sep 2024 19:28:11 GMT</pubDate>
    </item>
    <item>
      <title>注意力是一种 K 近邻回归器吗？</title>
      <link>https://stats.stackexchange.com/questions/654050/is-attention-a-kind-of-k-nearest-neighbors-regressor</link>
      <description><![CDATA[我想出了一个奇怪的 KNN 算法，我认为它相当于自注意力：

假设我们有一个典型的 (特征、标签) 样式数据集 $\mathscr D = \{(x_1, Vx_1), (x_2, Vx_2),\dots, (x_N, Vx_N)\}$，其中 $x_n$ 是向量，V 是某个矩阵。
原则上，我们可以将常规 KNN 应用于此集合，将每个向量 $x_n$ 视为查询向量，并让 $K=|\mathscr D \setminus (x_n, Vx_n)|=N-1$，因此所有都是邻居，没有前 K 个最近向量：

给定某个特征向量 $x_n$，计算其与所有其他向量的相似度：$S(x_n)=\left\{\frac{1}{\lVert x_n - x \rVert} : x \in \mathscr D \setminus x_n\right\}$。我猜这也需要规范化，这样 $\sum_i S_i(x_n)=1$。
输出是标签的加权和：$y_n^* = \sum_{i} S_i(x_n) Vx_i$。
对所有其他向量重复此操作，并获得一组对应于每个特征向量的预测标签：$\mathscr Y = \{y_1^*, y_2^*, \dots, y_N^*\}$。


现在像这样修改上面的 KNN：

使用点积作为相似度度量：$s_{Q,K}(x_n, x_m) = x_n&#39; Q&#39;K x_m$.
现在 $x_n$ 的权重为：$S(x_n)=\mathrm{softmax}\left(\left\{s_{Q,K}(x_n, x) : x \in \mathscr D\right\}\right)$.

我们迭代整个数据集，包括 $x_n$ 本身，因为这里不可能除以零。在我看来，我们也可以像上面一样使用 $\mathscr D \setminus x_n$。
我们使用 softmax，而不是通过 $\sum_{x \in \mathscr D \setminus x_n} \frac{1}{\lVert x_n - x \rVert}$ 进行归一化。


预测标签再次为 $y_n^* = \sum_{i=1}^N S_i(x_n) Vx_i$。


如果 $Vx_n$（因此 $y_n^*$) 具有相同的维度，我们可以堆叠这些算法，使用 $\{y_n^*\}$ 作为下一层的 $\{x_n\}$。

我认为我的算法 (2) 1) 与自注意力相同，2) 是一种 KNN，或“全最近邻”。因此，似乎可以将自注意力理解为一种 KNN。
这有意义吗？我可以这样思考注意力吗？

编辑：我发现了一些介绍某种“连续最近邻居”的论文：

“神经最近邻居网络”，2018 年（方程 10-11）：https://proceedings.neurips.cc/paper_files/paper/2018/file/f0e52b27a7a5d6a1a87373dffa53dbe5-Paper.pdf
“KVT： k-NN Attention for Boosting Vision Transformers”，2022 年（第 3.2 节似乎讨论了与上述算法 (2) 类似的内容）：https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136840281.pdf
]]></description>
      <guid>https://stats.stackexchange.com/questions/654050/is-attention-a-kind-of-k-nearest-neighbors-regressor</guid>
      <pubDate>Sun, 08 Sep 2024 19:26:57 GMT</pubDate>
    </item>
    <item>
      <title>是否可以对多项研究的总体方差取平均值以用于样本量计算？</title>
      <link>https://stats.stackexchange.com/questions/654048/can-population-variance-from-multiple-studies-be-averaged-to-use-for-a-sample-si</link>
      <description><![CDATA[想象一下，您正在计划一项临床试验，以评估一种新疗法对改善慢性中风患者 VO2peak 的有效性。根据 Jin 等人的初步研究，您使用 Jin 等人报告的 VO2peak 方差估计试验所需的样本量。
来自 Jin 等人的数据：

VO2peak 方差：2.5 ml/kg/min
估计样本量：每组 40 名参与者

但是，您后来发现，您的试点研究中的方差比 Jin 等人的估计值高得多。
来自其他研究的数据：

DaCun：方差 = 10 ml/kg/min
Mac：方差 = 15 ml/kg/min
Len：方差 = 20 ml/kg/min
Ive：方差 = 18 ml/kg/min
Glob：方差 = 25 ml/kg/min

修订方法：
现在，您不再仅仅依赖 Jin 等人的方差估计，而是包括来自这些其他研究的数据：

来自其他研究的平均方差：(10 + 15 + 20 + 18 + 25) / 5 = 17.6 ml/kg/min

修订样本量计算：使用这个更高的平均方差，您可以计算出一个新的样本量估计值。


结果：

新的样本量估计：每组 80 名参与者（基于更高的平均方差）

这是一种可接受的方法吗？计算样本量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654048/can-population-variance-from-multiple-studies-be-averaged-to-use-for-a-sample-si</guid>
      <pubDate>Sun, 08 Sep 2024 17:52:41 GMT</pubDate>
    </item>
    <item>
      <title>有序回归/2 步模型</title>
      <link>https://stats.stackexchange.com/questions/654047/ordinal-regression-2-step-model</link>
      <description><![CDATA[遗憾的是，我在细节方面有些含糊，但我希望可以提供足够的一般信息来提出相关问题，并有足够的内容，以便读者能够引导我找到一些有用的材料。我没有接受过正规的统计学培训，但我会尽力做合理的事情，并在可能/负担得起的情况下寻求统计学家的帮助。无论如何......我有横断面调查数据（通过社交媒体宣传），收集了有关人口统计变量、其他解释性变量（一些连续的，一些分类的）的信息，还提出了一组问题是主要感兴趣的响应变量。这些响应变量问题的量表如下（每个问题都是一个单独的构造 - 它们不会被加在一起或平均成任何总分或正式的测量模型）：
1 = 完全没有问题
2 = 轻微
3 = 中等
4 = 严重
假设我有兴趣评估两个解释变量（一个连续变量，一个具有 3 个级别的分类变量）与序数响应之间的关系，那么据我所知，我可以拟合比例优势序数逻辑回归来模拟预测因子与响应之间的关系，但是，响应量表对我来说更像是一个两步过程。即：
步骤/模型 1 = 问题存在/不存在？
步骤/模型 2 = 如果问题存在，那么它有多严重？
因此，在我看来，我有几个选择：

只需使用 PO 序数回归对所有序数响应类别进行建模（或者在需要/必要时放宽 PO 假设的某些替代方案）
首先使用二元逻辑回归对存在/不存在进行建模，然后使用 PO 序数回归对轻度/中度/重度响应结果进行建模（这是否合理，或者“使用数据两次”等是否存在问题？
或者，是否有任何 2 步模型，我可以在其中联合估计存在/不存在，然后在问题存在的条件下估计严重程度，但实际上对序数响应进行建模？

如果有人可以向我指出他们认为可能有用的任何可访问的材料/阅读/博客或模型，那就太好了。
提前谢谢大家]]></description>
      <guid>https://stats.stackexchange.com/questions/654047/ordinal-regression-2-step-model</guid>
      <pubDate>Sun, 08 Sep 2024 17:46:57 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何计算拟二项分布模型的伪 R 平方？</title>
      <link>https://stats.stackexchange.com/questions/654046/how-should-i-calculate-a-pseudo-r-squared-for-models-with-a-quasi-binomial-distr</link>
      <description><![CDATA[我使用 glm 函数在 R 中创建了一个模型，其中 family = quasibinomial。我正在尝试计算 psquedo R 平方，即 cox-snell 变量，以便与现有研究进行比较。
但是，由于 cox-snell R 平方使用对数似然，我该如何调整它以适应具有准分布的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/654046/how-should-i-calculate-a-pseudo-r-squared-for-models-with-a-quasi-binomial-distr</guid>
      <pubDate>Sun, 08 Sep 2024 17:15:28 GMT</pubDate>
    </item>
    <item>
      <title>判别风险、生成风险和贝叶斯风险</title>
      <link>https://stats.stackexchange.com/questions/654045/discriminative-vs-generative-bayes-risk</link>
      <description><![CDATA[在二元分类的背景下，特征表示为$X$，标签为$y$，可以用两种等效但不同的方式指定$(X, y)$的联合分布：

通过先验和类条件密度指定此联合分布的生成方式，
通过后验概率$\eta(X) = \mathbb{P}(y = 0|X)$和$X$的分布进行判别。

这仅涉及底层贝叶斯模型。
现在，考虑$l$ 一个损失函数。从生成的角度来看，贝叶斯风险可以定义为：
$$\underset{T : \mathcal{X} \to \Theta}{\inf} \mathbb{E}_{X, \theta}[l(T(X), \theta)],$$
其中最小值适用于标签的估计量。
在Reid and Williamson中，作者在第 16/17 页（文档中索引为 746/747）采用了更具判别性的观点，通过定义估计的损失后验概率的$\hat{\eta}$。然后我们考虑贝叶斯风险，其中最小值适用于后验概率的估计量。
然后声称这两个贝叶斯风险是一致的（这很直观，因为联合分布的两个规范是等价的）。
有人能帮我正式证明情况确实如此吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654045/discriminative-vs-generative-bayes-risk</guid>
      <pubDate>Sun, 08 Sep 2024 16:40:46 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何使用 Stata 处理面板数据集中参与者之间对不同主题的接触？</title>
      <link>https://stats.stackexchange.com/questions/654043/how-should-i-handle-exposure-to-different-topics-between-participants-in-a-panel</link>
      <description><![CDATA[我希望使用 Stata 分析数据，其中参与者被随机分配阅读 4 个可能主题中的 2 个。阅读完一个主题后，参与者会接触到五个级别的治疗（受试者内设计）。对于每种治疗，参与者对六个测量值（连续变量）做出反应。
以下是数据结构的示例：
[CODE]
* 示例由 -dataex- 生成。有关更多信息，请键入 help dataex
clear
输入字节（id 参与者主题治疗措施1措施2措施3措施4措施5措施6治疗1治疗2治疗3治疗4治疗5）
1 1 2 1 3 2 3 3 3 1 1 0 0 0 0
2 1 2 2 7 1 1 1 1 7 0 1 0 0 0
3 1 2 3 7 7 1 1 6 6 0 0 1 0 0
4 1 2 4 3 4 3 3 3 4 0 0 0 1 0
5 1 2 5 4 4 4 4 4 4 0 0 0 0 1
6 1 3 1 1 1 1 1 1 1 1 0 0 0 0
7 1 3 2 1 1 1 1 1 1 0 1 0 0 0 8 1 3 3 1 1 1 1 1 1 0 0 1 0 0 9 1 3 4 1 1 1 1 1 1 0 0 0 1 0 10 1 3 5 1 1 1 1 1 1 0 0 0 0 1 11 2 1 1 6 6 6 6 6 6 1 0 0 0 0 12 2 1 2 5 5 5 5 5 5 0 1 0 0 0 13 2 1 3 5 5 5 5 6 6 0 0 1 0 0 14 2 1 4 5 5 5 5 5 5 0 0 0 1 0 15 2 1 5 4 4 4 5 4 4 0 0 0 0 1 16 2 3 1 6 4 6 5 6 6 1 0 0 0 0 17 2 3 2 7 7 7 7 7 7 0 1 0 0 0 18 2 3 3 6 6 6 6 5 6 0 0 1 0 0 19 2 3 4 6 6 6 6 6 6 0 0 0 1 0 20 2 3 5 7 7 7 1 1 1 0 0 0 0 1 21 3 3 1 4 1 5 1 4 3 1 0 0 0 0 22 3 3 2 1 1 3 3 4 4 0 1 0 0 0 23 3 3 3 3 3 1 3 4 4 0 0 1 0 0 24 3 3 4 4 4 4 4 4 3 0 0 0 1 0 25 3 3 5 1 4 4 3 4 4 0 0 0 0 1 26 3 4 1 4 3 4 1 4 3 1 0 0 0 0 27 3 4 2 5 4 1 4 3 2 0 1 0 0 0 28 3 4 3 6 4 1 1 3 7 0 0 1 0 0 29 3 4 4 5 7 4 1 4 7 0 0 0 1 0 30 3 4 5 3 4 1 1 4 4 0 0 0 0 1 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。
 。 。 . ...我将“参与者”指定为固定效应，以减轻响应的非独立性。
xtset 参与者
xtreg measure1 i.treatment1 i.treatment2 i.treatment3 i.treatment4 i.treatment5, fe 

但我不确定如何解释主题对参与者对每个治疗水平的反应的影响，特别是因为参与者被随机分配到 2 个主题。我不知道参与者首先对哪个主题做出反应，并且担心每个主题之间的定性差异会影响响应，或者存在排序效应。
应该将主题指定为随机效应吗？我考虑过这样做：
mixed measure1 treatment || topic:

但我不确定这是否是最好的方法。我还想知道是否有一个线性模型可以用于在同一模型中同时考虑参与者固定效应和主题。
处理这个问题的最佳方法是什么？对于任何含糊不清的地方，我深表歉意，并很乐意提供更多信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/654043/how-should-i-handle-exposure-to-different-topics-between-participants-in-a-panel</guid>
      <pubDate>Sun, 08 Sep 2024 15:50:06 GMT</pubDate>
    </item>
    <item>
      <title>协方差矩阵的浓度不等式</title>
      <link>https://stats.stackexchange.com/questions/654041/concentration-inequality-of-the-covariance-matrix</link>
      <description><![CDATA[在高维统计领域，我们经常利用集中不等式来获得高概率的收敛速度。当我阅读有关图形模型的讲义时，我发现$\|\Sigma-\hat{\Sigma}\|_{max}$的集中不等式经常出现在$\|A\|_{max}=\underset{i,j}{\max}|X_{ij}|$。
我的问题：

范数$\|\cdot\|_{\max}$的频繁出现意味着什么，背后隐藏着什么直觉？

我想知道协方差矩阵与其他范数的集中不等式，例如谱范数$\|\Sigma-\hat{\Sigma}\|_2$。据您所知，此浓度不等式的最佳结果是什么？

]]></description>
      <guid>https://stats.stackexchange.com/questions/654041/concentration-inequality-of-the-covariance-matrix</guid>
      <pubDate>Sun, 08 Sep 2024 15:37:24 GMT</pubDate>
    </item>
    <item>
      <title>传递核的分解是否定义明确？</title>
      <link>https://stats.stackexchange.com/questions/654039/is-the-decomposition-of-a-transitive-kernel-well-defined</link>
      <description><![CDATA[在下面的论文中，作者写道：
假设某个函数 (p(x, y)) 的转换核表示为
$$
P(x, d y)=p(x, y) d y+r(x) \delta_x(d y),
$$
其中 $p(x, x)=0, \delta_x(d y)=1$ 如果 $x \in d y$ 否则为 0，并且 $r(x)=1-\int_{\mathbb{R}^d} p(x, y) d y$ 是链保持在 $x$。从 $r(x) \neq 0$ 的可能性来看，应该清楚的是 $p(x, y)$ 对 $y$ 的积分不一定是 1。
我的问题：您如何验证此分解实际上等于过渡核？换句话说：我如何知道满足此等式的函数 $p(x,y)$ 和 $r(x)$ 确实存在？]]></description>
      <guid>https://stats.stackexchange.com/questions/654039/is-the-decomposition-of-a-transitive-kernel-well-defined</guid>
      <pubDate>Sun, 08 Sep 2024 13:30:32 GMT</pubDate>
    </item>
    <item>
      <title>根据两个传感器进行估算</title>
      <link>https://stats.stackexchange.com/questions/654037/estimating-from-two-sensors</link>
      <description><![CDATA[我们想测量两个物体之间的距离。一个传感器的读数为 120。另一个传感器的读数为 200。我们知道第一个传感器的读数的标准偏差为 20，第二个传感器的读数的标准偏差为 30。
最佳估计是什么？
问题的第二部分
传感器位于飞机上，测量到码头的距离。如果我们高估了，飞机就会坠毁。我想要几乎 95% 的信心保证它不会坠毁的距离。我现在对距离的最佳估计是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654037/estimating-from-two-sensors</guid>
      <pubDate>Sun, 08 Sep 2024 13:07:15 GMT</pubDate>
    </item>
    <item>
      <title>矩阵范数的次梯度</title>
      <link>https://stats.stackexchange.com/questions/654025/subgradient-of-the-matrix-norm</link>
      <description><![CDATA[当我想要获得矩阵变量套索方法的统计特性时，例如，
$$
\hat{X}=\underset{X\in \mathbb{R}^{n\times n}}{\arg \min}\mathcal{L}\left(X\right)+\lambda_n \|X\|_1,
$$
其中 $\mathcal{L}$ 是损失函数，$\|X\|_1=\sum_{i,j}|X_{ij}|$，我总是关注其方向导数的 KKT 条件。因此，我有
$$
\mathcal{L}^{\prime}\left(\hat{X}\right)+\lambda_n Z,
$$
其中$Z\in \partial\|\hat{X}\|_1$且$\|Z\|_{\max}=\underset{i,j}{\max}|Z_{ij}|\le 1$。
我们能否限制$Z$的谱范数？我了解到，如果 $Z$ 是核范数的次梯度，则 $Z$ 的谱范数小于 1。逐元素 1 范数是否具有类似的性质？]]></description>
      <guid>https://stats.stackexchange.com/questions/654025/subgradient-of-the-matrix-norm</guid>
      <pubDate>Sun, 08 Sep 2024 04:56:35 GMT</pubDate>
    </item>
    <item>
      <title>过度拟合时间序列</title>
      <link>https://stats.stackexchange.com/questions/654023/overfitting-time-series</link>
      <description><![CDATA[我只有一个时间序列$(y_0, t_0), (y_1,t_1), \ldots, (y_n, t_n)$，其中$y_i \in \mathbb{R}$和$t_0 &lt; \cdots &lt; t_n$。人们相信这些是函数 $f(t; \mu)$ 上的点，其中 $\mu \in \mathbb{R}^d$ 是可学习参数，在某种意义上，给定 $t_i$，$y_i$ 是 $Y_i$ 的实现，如下所示：
\begin{equation*}
Y_i = f(t_i;\mu) + \epsilon_i
\end{equation*&gt;
这里 $\epsilon_i$ 是独立同分布的误差项，即正态分布，$0$ 均值和一些方差。
假设我们是频率论者。我们使用最小二乘法等方法来估计 $\hat{\mu}$ 并进行推断。
问题是，在 $d$ 和 $n$ 方面，是否存在适用于大型非线性函数类 $f$ 的经验法则，以便人们在实践中判断是否存在过度拟合。例如，在线性回归的情况下，通常要求每个可学习参数进行 10 次观察，不包括截距。并不是说如果我们只有 9 个可学习参数，我们就不进行回归，而只是一般的经验法则。我对平滑单峰（即只有一个峰值）函数$f$的非线性回归情况特别感兴趣，因为我的时间序列就是这样的。]]></description>
      <guid>https://stats.stackexchange.com/questions/654023/overfitting-time-series</guid>
      <pubDate>Sun, 08 Sep 2024 01:13:19 GMT</pubDate>
    </item>
    </channel>
</rss>