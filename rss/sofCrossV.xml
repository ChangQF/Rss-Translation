<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 18 Dec 2024 21:14:25 GMT</lastBuildDate>
    <item>
      <title>负百分比偏差解释增强回归树</title>
      <link>https://stats.stackexchange.com/questions/658941/negative-percent-deviance-explained-boosted-regression-tree</link>
      <description><![CDATA[提前感谢大家的帮助。
我正在使用 dismo 包 (V1.3.16) 中的 gbm.step 函数在 R 中构建一系列增强回归树。响应是物种存在或不存在，预测变量是一组环境变量，例如海面温度和水深测量。用于生成 BRT 的代码粘贴在此处：
library(dismo)

mod_file &lt;- dismo::gbm.step(
data = dat_train, 
gbm.x = pred_vars, 
gbm.y = 5,
family = &quot;bernoulli&quot;, 
tree.complexity = 3,
learning.rate = 0.05, 
bag.fraction = 0.75, 
silent = TRUE, 
plot.main = TRUE

我想评估不同空间区域和年份组合的模型性能，因此用于评估模型性能的测试数据集是通过对给定区域-年份组合的 20% 进行子采样生成的。可以在 此处，示例测试数据集可在此处找到。在下面的代码中，模型对象称为 mod_file，测试数据称为 dat_test。由于我对测试数据集进行子采样的方式，其中一些数据集相对于其他时空组合（&gt;1000）具有较低的 n（100-400）。对于样本量较小的时空组合，我在模型评估期间得到了负的百分比偏差解释值。我正在使用以下代码计算解释的百分比偏差：
library(gbm)

#循环遍历每个时空组合

for(i in 1:length(unique(test_file$st_id))){ 

#创建空数据集以存储偏差解释值
if(i == 1){
temp_df &lt;- data.frame(matrix(ncol = 2, nrow = 9))
cols_names &lt;- c(&quot;dev_exp&quot;, &quot;st_id&quot;)
colnames(temp_df) &lt;- cols_names 
}

#为每个时空组合单独设置
st_id_temp &lt;- unique(test_file$st_id)[i]
test_temp &lt;- test_file %&gt;% filter(st_id == st_id_temp)

#计算百分比偏差解释
preds &lt;-predict.gbm(mod_file,test_temp,
n.trees = mod_file$gbm.call$best.trees,
type =&quot;response&quot;)
observed &lt;-test_temp$PA

ext.residual.deviance &lt;-calc.deviance(obs = test_temp$PA,pred=preds,family=&quot;bernoulli&quot;,calc.mean=TRUE)

null.dev = calc.deviance(test_temp$PA,rep(mean(test_temp$PA),length(test_temp$PA)),family=&quot;bernoulli&quot;,calc.mean=T)

dev=(null.dev - ext.residual.deviance)/null.dev 

#将指标存储在性能指标数据框中
temp_df$dev_exp[i] &lt;- dev
temp_df$st_id[i] &lt;- st_id_temp
} 

是否有任何方法或经验法则可以处理这些负值？]]></description>
      <guid>https://stats.stackexchange.com/questions/658941/negative-percent-deviance-explained-boosted-regression-tree</guid>
      <pubDate>Wed, 18 Dec 2024 21:12:38 GMT</pubDate>
    </item>
    <item>
      <title>如何估计排队模型的蒙特卡罗模拟的不确定性？</title>
      <link>https://stats.stackexchange.com/questions/658938/how-would-i-estimate-uncertainty-from-a-monte-carlo-simulation-of-a-queuing-mode</link>
      <description><![CDATA[我正在对具有确定性和随机性成分的复杂服务模型进行蒙特卡罗模拟。以下是一个简化的描述：

每分钟有 $i$ 次呼叫，服从泊松分布
有 $n$ 个服务器可用
呼叫长度服从具有指定平均值和方差的正态分布

在不同情况下，每分钟呼叫率或服务器数量等参数会有所不同。
我针对每种情况运行蒙特卡洛模拟，模拟一分钟一分钟地进行，随机从泊松分布中抽取新呼叫，评估服务器是否可用，如果可用则分配服务器，通过从正态分布中抽取来分配呼叫长度，并在分配的呼叫长度结束时结束呼叫（从而将服务器标记为可用）。如果没有可立即使用的服务器，则呼叫会被中断。
我对此进行了模拟，因为实际模型有点复杂，使得估算闭式解决方案变得困难。
我对每个场景运行 1000 次模拟迭代，并估算汇总统计数据（例如，中断的呼叫次数）。然后，我使用这些迭代的中位数，并估算不确定性，我取这些模拟的第 2.5 和第 97.5 个百分位数。这合理吗？
为了了解两种场景之间的差异，我可以从每种场景的迭代中获取中位数的差异。我将如何估算两种场景之间中位数差异的不确定性？]]></description>
      <guid>https://stats.stackexchange.com/questions/658938/how-would-i-estimate-uncertainty-from-a-monte-carlo-simulation-of-a-queuing-mode</guid>
      <pubDate>Wed, 18 Dec 2024 20:17:01 GMT</pubDate>
    </item>
    <item>
      <title>离散分布的变换</title>
      <link>https://stats.stackexchange.com/questions/658937/transformation-for-discrete-distributions</link>
      <description><![CDATA[是否存在针对离散分布（例如泊松分布）的有效变换？]]></description>
      <guid>https://stats.stackexchange.com/questions/658937/transformation-for-discrete-distributions</guid>
      <pubDate>Wed, 18 Dec 2024 20:13:56 GMT</pubDate>
    </item>
    <item>
      <title>偏态分布的 Beta 分布</title>
      <link>https://stats.stackexchange.com/questions/658936/beta-distribution-for-a-skewed-distribution</link>
      <description><![CDATA[我正在尝试为生物数据集开发一个分布。这是一个包含 890 万个位置的速率数据集 (0-1)。90% 的位置的速率为 0，平均值为 0.002447，最大值为 1。当我尝试使用矩量法进行参数估计时，alpha=0.00427 和 beta = 1.74。由于数据集的生物学性质，不适合过滤掉 0 或上限，但参数的极值似乎令人担忧。有没有办法为这种数据建立适当的 beta 分布，或者其他分布会更好？
非常感谢您的任何建议，]]></description>
      <guid>https://stats.stackexchange.com/questions/658936/beta-distribution-for-a-skewed-distribution</guid>
      <pubDate>Wed, 18 Dec 2024 19:55:27 GMT</pubDate>
    </item>
    <item>
      <title>随机顺序符号 - 不寻常的符号</title>
      <link>https://stats.stackexchange.com/questions/658935/stochastic-order-symbols-unusual-notation</link>
      <description><![CDATA[教授为我们提供了以下 big-oh-P-one 的定义，与我找到的其他来源相比，这个定义似乎有点不寻常。该定义是：
设 $Z_n$ 和 $a_n$、$n = 1, 2, \ldots$ 分别为随机变量和常数序列。符号 $Z_n = O_p(1)$（“big oh-P-one”）表示 $Z_n$ 的概率是有界的。确切地说，对于任何 $\epsilon &gt; 0$，存在一个常数 $M_\epsilon &lt; \infty$，使得
\begin{equation}
\limsup_{n \to \infty} P(|Z_n| &gt; M_\epsilon) \leq \epsilon.
\end{equation
Q1：为什么在这个定义中需要使用上确界？
Q2：直觉似乎是，对于足够大的 $n$，$Z_n$ 超过大常数 $M$ 的概率会变小。这种解释正确吗？为什么这个概念在计量经济学中特别有用？]]></description>
      <guid>https://stats.stackexchange.com/questions/658935/stochastic-order-symbols-unusual-notation</guid>
      <pubDate>Wed, 18 Dec 2024 19:07:24 GMT</pubDate>
    </item>
    <item>
      <title>如何将 Kenward-Roger 自由度应用于具有零通胀项和每个系数的离散估计的 GLMM？</title>
      <link>https://stats.stackexchange.com/questions/658932/how-to-apply-kenward-roger-degrees-of-freedom-to-a-glmm-with-a-zero-inflation-te</link>
      <description><![CDATA[假设我有一个 glmmTMB 模型（这个问题并不局限于 glmmTMB，它只是一个例子）：
glmmTMB(y~Treatment + (1|Site/Patient), dispformula = ~Site, family=gaussian(link=&quot;identity&quot;), REML=T)
如果我假设模型有一组方差，我可以计算 Kenward-Roger 自由度，或者如果 dispformula = ~Treatment，那么我可以使用单个治疗沿对角线的方差和两个治疗的平均值（最好使用加权平均值？）调整协方差矩阵，以进行非对角线校正。
在这种情况下，如果将 dispformula 应用于被视为随机效应的水平，会怎么样？这样做有意义吗？如果确实有意义，我会取给定治疗中存在的站点的平均方差吗？
问题的下一部分是针对零膨胀模型。
假设我有以下模型：
glmmTMB(y~Treatment + (1|Site/Patient), ziformula = ~Treatment, family=Gamma(link=&quot;log&quot;), REML=T)
我是否应该将治疗固定效应的协方差和模型的零膨胀部分结合起来？由于它们处于不同的尺度（对数和逻辑回归），可以直接将它们结合起来吗？还是需要以某种方式进行转换？]]></description>
      <guid>https://stats.stackexchange.com/questions/658932/how-to-apply-kenward-roger-degrees-of-freedom-to-a-glmm-with-a-zero-inflation-te</guid>
      <pubDate>Wed, 18 Dec 2024 16:38:10 GMT</pubDate>
    </item>
    <item>
      <title>基尼不纯度与误分类误差的关系</title>
      <link>https://stats.stackexchange.com/questions/658931/relationship-between-gini-impurity-and-misclassification-error</link>
      <description><![CDATA[我理解基尼不纯度和误分类误差之间的区别，但我很好奇以下处理两者关系的结果是否正确：
假设我们有两组概率$p_i$和$q_i$，其中$0 \leq p_i \leq 1$，$\forall i=1, 2, \ldots, m$和$0 \leq q_i \leq 1$，$\forall i=1, 2, \ldots, n$。此外，假设我们有两组权重$w_i$和$v_i$，它们的总和为 1，即$w_1+w_2+\cdots+w_m=1$和$v_1+v_2+\cdots+v_n=1$。如果
$\sum_{i=1}^m w_i 2p_i(1-p_i) \leq \sum_{i=1}^n v_i 2q_i(1-q_i)$，
这是否意味着
$\sum_{i=1}^m w_i (1-\max(p_i, 1-p_i)) \leq \sum_{i=1}^n v_i (1-\max(q_i, 1-q_i))$？
换句话说，与另一个分割相比，加权基尼不纯度较低的分割是否也具有较低的加权误分类误差？由于基尼不纯度和误分类误差曲线的形状，情况似乎确实如此，但我无法严格证明（或反驳）这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/658931/relationship-between-gini-impurity-and-misclassification-error</guid>
      <pubDate>Wed, 18 Dec 2024 16:23:38 GMT</pubDate>
    </item>
    <item>
      <title>关于使用监督机器学习处理时间序列数据中的结构突变以进行预测的查询</title>
      <link>https://stats.stackexchange.com/questions/658930/query-on-handling-structural-breaks-in-time-series-data-for-prediction-using-sup</link>
      <description><![CDATA[商品价格（原始数据）的结构性突变是否会影响机器学习模型的预测准确性？
如果答案是肯定的，我将非常感激您对以下方面的指导：
识别：我们如何确定时间序列数据是否包含结构性突变？
缓解/消除：在继续预测之前，我们可以采取哪些步骤来解决结构性突变？
您对此事的见解对我的研究非常有价值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658930/query-on-handling-structural-breaks-in-time-series-data-for-prediction-using-sup</guid>
      <pubDate>Wed, 18 Dec 2024 16:19:47 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑混合模型中，估计值会发生变化，但对于高斯模型则不会</title>
      <link>https://stats.stackexchange.com/questions/658929/in-logistic-mixed-model-the-estimate-changes-but-it-does-not-for-a-gaussian</link>
      <description><![CDATA[比较 2 个逻辑模型：
result~1 

和
result~1|randomeffect

两个模型之间的估计值（即比例的对数（几率））会发生变化 &amp;我正在努力解释这一点。
当我用模拟数据对高斯模型进行实验时，使平均值偏移的唯一方法是使随机效应的各组中的观测值数量不相等（我理解为什么会发生这种情况）。
但是，在逻辑/二进制中工作时，即使随机效应中每个组的观测值数量相等，我也会得到估计值的变化（对于比例的对数几率）。
我希望能够向外行观众解释这一点，否则会破坏从基础模型转移到混合模型的可信度。
有人可以提出建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658929/in-logistic-mixed-model-the-estimate-changes-but-it-does-not-for-a-gaussian</guid>
      <pubDate>Wed, 18 Dec 2024 16:11:36 GMT</pubDate>
    </item>
    <item>
      <title>如果以 $f(Y)$ 为条件的 $X$ 是正态的，那么以 $Y$ 为条件的 $X$ 也是正态的？</title>
      <link>https://stats.stackexchange.com/questions/658927/if-x-conditional-on-fy-is-normal-then-x-conditional-on-y-is-normal</link>
      <description><![CDATA[考虑两个实值随机变量 $X$ 和 $Y$，并得到完全支持。设 $f:\mathbb{R}\rightarrow \mathbb{R}$。假设
$$
X\mid f(Y) \sim N(\mu_{f(Y)}, \sigma_{f(Y)})
$$
即：$X$ 条件为 $f(Y)$ 具有正态分布，其均值和方差取决于 $f(Y)$。
问题：这个假设是否意味着给定 $Y$ 的 $X$ 也具有正态分布？如果是，那么该正态分布的参数与$\mu_{f(Y)}$和$\sigma_{f(Y)}$有何关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/658927/if-x-conditional-on-fy-is-normal-then-x-conditional-on-y-is-normal</guid>
      <pubDate>Wed, 18 Dec 2024 15:35:14 GMT</pubDate>
    </item>
    <item>
      <title>轻松理解混合模型中聚类变量和随机变量之间的区别</title>
      <link>https://stats.stackexchange.com/questions/658926/easy-way-to-understand-the-difference-between-a-cluster-variable-and-a-random-va</link>
      <description><![CDATA[假设我们有一个数据集，其中我们根据社会经济地位对一系列不同学校的数学成绩分数进行建模。使用 lme4 的适当模型将是：
lmer(math~ses + (ses | school), data=d)
我的学生经常混淆 ses 和 school 的位置。为了解决这个问题，我制作了一个 YouTube 视频，帮助学生识别他们的“聚类变量”。该视频为他们提供了三条规则来帮助识别他们的聚类变量：

这个变量在您的数据集中是否经常重复出现？（聚类变量将重复）
这个变量是否识别一个人？ （如果是，那就是您的聚类变量，跳过 #3）
此变量是否表示特定组？（如果是，那就是您的聚类变量）

对于此示例，学校将被重复（该学校的每个学生一行），它不会识别特定的人，但会识别特定的组。
我对我的解释一直不太满意，因为它留下了一些歧义。让我们修改示例以使我的规则失败。假设我们正在预测数学成绩，但这次，我们想添加种族作为预测因素。合适的模型可以是：
lmer(math~ses + ethnicity + (ses + ethnicity | school), data=d)
（假设 ses 和 ethnicity 的斜率实际上因学校而异）。
这个例子的问题是学生会感到困惑，特别是如果数据集尚未按学校排序。ethnicity 和 school 都符合标准：两者都重复，都不能识别一个人，并且都表示一个“群体”。当他们问为什么 ethnicity 不是时，我有点不知道如何解释为什么 ethnicity 不是一个群体。
关于如何使差异更具体，有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658926/easy-way-to-understand-the-difference-between-a-cluster-variable-and-a-random-va</guid>
      <pubDate>Wed, 18 Dec 2024 15:33:06 GMT</pubDate>
    </item>
    <item>
      <title>Copula 实证估计 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658925/copula-empirical-estimation</link>
      <description><![CDATA[我正在研究这篇论文。
考虑以下数据：
$X : 0.29, 0.36, 0.39, 0.41, 0.50, 0.53, 0.54, 0.55, 0.56, 0.56, 0.56, 0.58, 0.60, 0.60, 0.62, 0.64, 0.64, 0.67, 0.80, 0.87
$
$Y : 0.17, 0.24, 0.26, 0.26, 0.27, 0.29, 0.30, 0.32, 0.33, 0.34, 0.38, 0.47, 0.47, 0.50, 0.56, 0.58, 0.59, 0.62, 0.63
$
分析的第一步是估算${I}_{\overline{C}}$。我们考虑随机样本 $(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)$ 的经验生存 copula，该样本来自连续双变量分布：
$$
\overline{C}\left(\frac{i}{n}, \frac{j}{n}\right) = \frac{\text{(样本中 x &gt; x_{(i)}, y \geq y_{(j)} 的对数)}{n},
$$
其中 $ x_{(i)} ( y_{(j)}) $ 是第 $i$ 个 ($j$ ) 顺序统计量，用于对 $X$ 和 $Y$ 进行观测。使用$\overline{C} \left( \frac{i}{n}, \frac{j}{n} \right) $作为$\overline{C}(u, v) $的估计量，$I_{\overline{C}}$的再代入估计量为：
$$
\widehat{I}_{\overline{C}} = \frac{2}{n^2} \sum_{i=1}^n \sum_{j=1}^n \overline{C} \left( \frac{i}{n}, \frac{j}{n} \right) \log \overline{C} \left( \frac{i}{n}, \frac{j}{n} \right),
$$
在那些点上，$ \frac{i}{n} + \frac{j}{n} - 1 &gt; 0 $。给定样本的估计值为 $\widehat{I}_{\overline{C}} = 0.3049$。
有人可以纠正我试过的这段代码吗：
X &lt;- c(0.29, 0.36, 0.39, 0.41, 0.50, 0.53, 0.54, 0.55, 0.56, 0.56, 
0.56, 0.58, 0.60, 0.60, 0.62, 0.64, 0.64, 0.67, 0.80, 0.87)
Y &lt;- c(0.17, 0.24, 0.26, 0.26, 0.27, 0.29, 0.30, 0.32, 0.33,0.33, 0.34, 
0.38, 0.47, 0.47, 0.50, 0.56, 0.58, 0.59, 0.62, 0.63)
n &lt;- length(X)
X_sorted &lt;- sort(X)
Y_sorted &lt;- sort(Y)
C_bar &lt;- function(i, j, X_sorted, Y_sorted) {
count &lt;- sum((X_sorted &gt; X_sorted[i]) &amp; (Y_sorted &gt; Y_sorted[j]))
return(count / n)
}
I_C_hat &lt;- 0
for (i in 1:n) {
for (j in 1:n) {
u &lt;- i / n
v &lt;- j / n
C_val &lt;- C_bar(i, j, X_sorted, Y_sorted)
if (!is.na(C_val) &amp;&amp; C_val &gt; 0 &amp;&amp; (u + v - 1) &gt; 0) {
I_C_hat &lt;- I_C_hat + C_val * log(C_val)
}
}
}

I_C_hat &lt;- 2 / (n^2) * I_C_hat
cat(&quot;I_C_hat 的估计值：&quot;, I_C_hat, &quot;\n&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/658925/copula-empirical-estimation</guid>
      <pubDate>Wed, 18 Dec 2024 15:12:18 GMT</pubDate>
    </item>
    <item>
      <title>我针对两个不同的用户群进行了两项实验。我的目标是了解一项实验是否效果更好。如何进行？</title>
      <link>https://stats.stackexchange.com/questions/658921/i-have-two-experiments-going-on-two-different-user-bases-my-aim-is-to-access-wh</link>
      <description><![CDATA[我有两个实验，针对两个不同的用户群。我的目标是确定哪个实验效果更好。我每天跟踪两个指标。一个是关于留存率 - 基本上是今天使用我们应用的 100 个用户中，第二天有多少人使用。另一个是用户在两个实验中执行的活动数量。我希望活动数量更高。
这里要注意的一点是，两个实验的组大小可能不同。考虑到我每天测量这些指标，并且这些测量可能不独立于时间，因此应该使用哪种统计测试。
为了进行比较，我们跟踪了上述两个指标，即两个实验的用户在我们的应用上执行的留存率（越高越好）和活动事件数量（越高越好）。如果某个特定实验（假设为 A）的留存率和活动数量在几天内持续较高，则 A 更好。一个实验基本上是一种为调整用户行为而设计的策略。
我们想弄清楚哪种策略效果更好，我应该做哪种统计测试来确定结果是否具有统计意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/658921/i-have-two-experiments-going-on-two-different-user-bases-my-aim-is-to-access-wh</guid>
      <pubDate>Wed, 18 Dec 2024 12:40:44 GMT</pubDate>
    </item>
    <item>
      <title>调整超参数以尽量减少过度拟合时的目标应该是什么？</title>
      <link>https://stats.stackexchange.com/questions/658909/what-should-the-objective-be-when-tuning-hyperparameters-to-minimize-overfitting</link>
      <description><![CDATA[我正在研究一个包含约 90k 行数据和 12 个特征的分类问题。我正在尝试调整 XGBoost 模型的超参数以尽量减少过度拟合。我使用 ROC_AUC 作为评估模型性能的指标。使用默认的 XGBoost 参数，5 倍 CV 结果分别显示训练 auc 为 0.782 和测试 auc 为 0.739。这表明过度拟合，因为训练集的表现优于测试集。
我开始调整超参数，因为 a) 应该调整，b) 已知超参数可用于减少过度拟合。但是，像许多其他人一样，我将验证 auc 设置为目标，并在目标函数中实现交叉验证。使用的库是 Optuna 和 Hyperopt。有趣的是，对于这两种情况，我发现当算法试图将验证 auc 推向 0.745 时，训练测试 auc 差距（过度拟合指标）会扩大。如果我按验证 auc 降序绘制训练和验证 auc，验证 auc 会从 0.745 降至 0.729，而训练 auc 会从 0.868 降至 0.742。
我对结果感到很困惑。我将验证 auc 设置为 Optuna 优化的目标是否正确？我是否应该选择（训练 auc - 验证 auc），但我在网上没有找到类似的例子。而且我是否应该查看结果并选择最低的验证 auc 和相关的超参数值作为“最佳参数”，因为训练验证指标差距最小？
请在这里分享您的想法，因为在我输入时，我不确定我对过度拟合的理解是否正确。
我的代码：
X, y = df[features], df[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,
random_state = 42, stratify = y)
dtrain = xgb.DMatrix(X_train, label = y_train, enable_categorical = True)
dtest = xgb.DMatrix(X_test, label = y_test, enable_categorical = True)

def objective(trial):

params = {&#39;max_depth&#39;: trial.suggest_int(&#39;max_depth&#39;, 3, 10),
&#39;min_child_weight&#39;: trial.suggest_int(&#39;min_child_weight&#39;, 1, 100),
&#39;gamma&#39;: trial.suggest_float(&#39;gamma&#39;, 0, 2),
&#39;subsample&#39;: trial.suggest_float(&#39;subsample&#39;, 0.5, 1),
&#39;colsample_bytree&#39;: trial.suggest_float(&#39;colsample_bytree&#39;, 0.5, 1),
&#39;reg_alpha&#39;: trial.suggest_float(&#39;reg_alpha&#39;, 1e-8, 10, log = True),
&#39;reg_lambda&#39;: trial.suggest_float(&#39;reg_lambda&#39;, 1e-8, 10, log = True),
&#39;learning_rate&#39;: trial.suggest_float(&#39;learning_rate&#39;, 0.001, 0.3),
&#39;objective&#39;: &#39;binary:logistic&#39;}

cv_results = xgb.cv(
params, dtrain, num_boost_round = 10000, early_stopping_rounds = 50, 
metrics = &#39;auc&#39;, nfold = 5, stratified = True, shuffle = False
)

trial.set_user_attr(&#39;n_estimators&#39;, len(cv_results))
trial.set_user_attr(&#39;train-auc&#39;, cv_results[&#39;train-auc-mean&#39;].iloc[-1])

return cv_results[&#39;test-auc-mean&#39;].iloc[-1]

study = optuna.create_study(
direction =&#39;maximize&#39;, sampler = optuna.samplers.TPESampler(seed = 42))

study.optimize(objective, n_trials = 500, n_jobs = -1)

]]></description>
      <guid>https://stats.stackexchange.com/questions/658909/what-should-the-objective-be-when-tuning-hyperparameters-to-minimize-overfitting</guid>
      <pubDate>Wed, 18 Dec 2024 09:28:26 GMT</pubDate>
    </item>
    <item>
      <title>比例均值的置信区间（可能不对称）</title>
      <link>https://stats.stackexchange.com/questions/658901/confidence-intervals-on-means-of-proportions-with-possibly-asymmetry</link>
      <description><![CDATA[我正在研究一份调查报告，并试图弄清楚如何正确计算误差幅度。（我正在提供反馈，这些不是我的计算，所以我无法重新计算任何东西）。
有 9 个李克特项目（5 分量表），每个项目都已转换为二进制（真/假）。对于回答了 9 个项目中至少 5 个的参与者，计算出真比例。计算这些比例的平均值以获得“总体真比例”。
误差幅度使用基本公式：1.96*sqrt(p(1-p)/n)，其中 p 是总体真比例。对我来说，这似乎不对，因为它没有考虑到不同的人可能回答不同数量的项目这一事实。此外，我不确定是否也需要考虑比例平均值（相对于直接比例）。
在这种情况下，您将如何处理误差幅度？如果所有参与者都回答了所有问题，这种方法会改变吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658901/confidence-intervals-on-means-of-proportions-with-possibly-asymmetry</guid>
      <pubDate>Tue, 17 Dec 2024 23:37:12 GMT</pubDate>
    </item>
    </channel>
</rss>