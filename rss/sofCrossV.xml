<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 22 Feb 2025 18:22:30 GMT</lastBuildDate>
    <item>
      <title>我们需要估算稳定重量的分子吗？</title>
      <link>https://stats.stackexchange.com/questions/661737/do-we-need-to-estimate-the-numerator-of-the-stablized-weights</link>
      <description><![CDATA[如果在Herman和Robins第12.3章中，他们引入了稳定的IP权重 $$ \ frac {p（a）}} {p（a \ mid l）} $$ &lt; /span&gt;用于二进制处理，其中 $ l $ 是covaraite。实际上，他们提到的任何IP权重 $$ \ frac {p} {f（a \ mid l} $$ 带有 $ 0＆lt; p \ le 1 $ 用于连续处理。 class =“数学 - 范围”&gt; $$ \ frac {f（a）} {f（a \ mid l）} $$ 用于连续处理。
但是，在同一章的后面某个地方，他们实际上确实进行了估计 $ p（a）$ 或 $ f（ a）$ 。我的问题是，为什么我们不能仅估计 $ f（a \ id l）$ 并施加密度函数，以平均0.5方差1表示正常，以获取值对于 $ f（a）$ ？]]></description>
      <guid>https://stats.stackexchange.com/questions/661737/do-we-need-to-estimate-the-numerator-of-the-stablized-weights</guid>
      <pubDate>Sat, 22 Feb 2025 17:18:22 GMT</pubDate>
    </item>
    <item>
      <title>一个模拟数据如何独立而不是分布相同的数据（INID）？</title>
      <link>https://stats.stackexchange.com/questions/661733/how-would-one-simulate-data-that-is-independent-and-not-identically-distributed</link>
      <description><![CDATA[当一个人使用INID数据时，我经常认为模拟非常容易。当您要生成 $ n $  datapoints，并且 $ n $ 不同的DGP，您只需绘制来自每个 $ n $  dgps的独立样本，该&gt; $ n $  DGP会为您提供独立但不是相同分布的数据。
有时在论文中，使用三角阵列数据描述了这种INID数据。可以找到有关此的更多信息在这里。在其中一个答案中，给出了一个很好的例子，您有时在假设测试中看到。也就是说，考虑替代性 $ \ mu = \ delta / \ sqrt {n} $ &lt; / span&gt;以 $ \ \ $ \ y缩小的速率收缩sqrt {n} $ 。
当我开始考虑这些三角阵列时，我实际上意识到可能还有另一种模拟I.N.I.D.的方法。数据。假设您有一个DGP  $ P_N $ ，它取决于样本大小 $ n $ 。这可以例如如前所述，成为一个DGP，您有一个参数 $ \ mu = \ delta / \ sqrt {n} $ &lt; / span&gt;以 $ \ sqrt {n} $ 。现在，如果我想拥有 $ n $ 来自此DGP的数据点，我可以选择绘制 $ n $  DATAPOINTS  IID 来自 $ P_N $ 。如果我想拥有 $ n +1 $  datapoints，我可以选择绘制 $ n +1 $  datapoints  iid 来自 $ P_ {N+1} $ 。从三角阵列数据的定义中查看它，我认为这也有意义。
任何人是否熟悉这种使用这种依赖于 $ n $ 的DGP的论文中经常进行的？使用采样的第一种方法或采样方式更有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661733/how-would-one-simulate-data-that-is-independent-and-not-identically-distributed</guid>
      <pubDate>Sat, 22 Feb 2025 16:28:53 GMT</pubDate>
    </item>
    <item>
      <title>使用Dirichlet分布的设备质量测量</title>
      <link>https://stats.stackexchange.com/questions/661731/device-quality-measurement-using-dirichlet-distribution</link>
      <description><![CDATA[我有一个与事件的连续时间序列，例如该信号中的峰值。使用多个设备（在我的情况三）观察到这个时间序列。在记录了独立的多个会话后，我们使用各种公认的检测算法提取事件，其中一些算法比其他算法更好。
然后，我们计算事件的发生。例如，将两个设备与一种用于两个设备使用的检测算法进行比较时，结果看起来像：
  number_event_detected（a+b）= 1245＃命中
number_event_detected（a+！b）= 64＃失踪
number_event_detected（！a+b）= 12＃错误警报
 
从随机选择的记录中的各种测量值中多次重复此过程，从而导致事件发生的不同数量：
  number_event_detected（a+b）= [1245，4567，3214，7894，4562，5571]
number_event_detected（a+！b）= [64、128、155、799、5、128]
number_event_detected（！a+b）= [122，77，78，455，788，2]
 
我们可以将此“混乱矩阵”归一化。 （由于是事件检测，不包括真正的负面因素），导致概率分布，每列总和1：
  p（a，b）= [0.870，0.957，0.932，0.863，0.852，0.977]
p（a，！b）= [0.045，0.027，0.045，0.087，0.001，0.022]
p（！a，b）= [0.085，0.016，0.023，0.050，0.147，0.001]
 
我的问题是：我们如何表达这些测量值的质量和不确定性？我正在考虑使用具有三个α值的Dirichlet分布。
我们可以利用命中，错过和错误的警报率比较三个设备，每台设备都具有多个检测算法和记录，同时使用相同的提取器进行测量。
由于计算平均值和标准偏差将无法与概率作用，因此拟合Dirichlet函数是我当前的方法，我的目标是与此类似地可视化： https://en.wikipedia.org/wiki/file:dirichlet.pdf 。
对我来说，这个问题在事件检测中似乎很普遍。您能指出我的一本书，纸张或文章，以分析这种类型的问题？还是您可以发布一些示例以进一步帮助我，如果我的方法有效？]]></description>
      <guid>https://stats.stackexchange.com/questions/661731/device-quality-measurement-using-dirichlet-distribution</guid>
      <pubDate>Sat, 22 Feb 2025 15:54:35 GMT</pubDate>
    </item>
    <item>
      <title>II型和III型Ancovas的事后测试</title>
      <link>https://stats.stackexchange.com/questions/661730/post-hoc-tests-for-type-ii-type-iii-ancovas</link>
      <description><![CDATA[我尝试使用CAR :: ANOVA（型号）对我的II型ANCOVA进行事后测试，但是我无法使用Tukeyhsd或Glht功能进行R。是否有其他方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/661730/post-hoc-tests-for-type-ii-type-iii-ancovas</guid>
      <pubDate>Sat, 22 Feb 2025 15:50:23 GMT</pubDate>
    </item>
    <item>
      <title>EWMA类似功能的收敛？</title>
      <link>https://stats.stackexchange.com/questions/661728/convergence-of-an-ewma-like-function</link>
      <description><![CDATA[我正在研究一个系统，该系统处理两种类型的随机事件，这些事件由函数 $ f（t）$ 和 $ g（t）$ 。这些函数在大多数情况下为零，除非发生事件，在这种情况下，值为正。这两种事件不能同时发生。
系统计算值 $ v $ 如下：
  $$ \ frac {\ delta v} {\ delta t} = \ alpha（f（t） -  g（t） -  g（t）v）$$    
其中 $ 0＆lt; \ alpha＆lt; 1 $ 和 $ 0 \ leq \ alpha g（t）＆lt; 1 $ 。
此复发（如果与 $ g（t）$  factor的差异非常相似，
  $ v $ ？的收敛值是多少
以下有效答案？
  $$ v^* = \ frac {\ mathbb {e} [f（t）]} {\ mathbb {e} [g（t）} $$ &lt;&lt; /span&gt; ]]></description>
      <guid>https://stats.stackexchange.com/questions/661728/convergence-of-an-ewma-like-function</guid>
      <pubDate>Sat, 22 Feb 2025 15:27:37 GMT</pubDate>
    </item>
    <item>
      <title>横截面回归中的误差协方差矩阵（Cochrane 2005）</title>
      <link>https://stats.stackexchange.com/questions/661727/error-covariance-matrix-in-cross-sectional-regression-cochrane-2005</link>
      <description><![CDATA[我正在阅读Cochrane 2005和顶部P 237的资产定价，他解释了错误协方差 $ cov（\ alpha，\ alpha，\ alpha&#39;）$ 在横截面回归中。只是，我没有得到他的结果。
 背景 
从横截面回归的步骤1开始
  $$
r_t^i = f_ {t，1} \ beta_1^i + \ dots + f_ {t，k} \ beta_k^i + + \ varepsilon_t
$$  
以矩阵形式
  $$
\下划线{r} _i = \下划线{f} \下划线{\ beta} _i + \ usepline {\ varepsilon} _i _i
$$ 
其中的大小 $ r_i $  is  $（t \ times 1）$ 和 $ \下划线f $ 是 $（t \ times k）$ 。。
对于 $ i = 1，\ dots n $ 生产 $ n $  vector  $ \ usewandline \ beta_i $  size  $（K \ times 1）$ 。收集这些 $ \ upsine \ beta_i $   $ n $ 资产 $ \下划线B $  size  $（n \ times k）$ 并执行以下内容回归。
  $$
\ bar {r} _i = \下划线{\ beta} _i&#39;\ lissine {\ lambda} + \ alpha_i
$$  
其中 $ \ bar {r} _i = \ frac {1} {t} {t} \ sum_ {i = 1} class =“数学 - 范围”&gt; $ \ usepline {\ lambda} $  size size  $（k \ times 1）$ 。这可以使用矩阵 $ \ upes b $  as 以矩阵 来编写。
  $$
\下划线{\ bar {r}} = \下划线{b} \ lissine {\ lambda} + \ usepline {\ alpha}
$$  
 我的问题 
所以现在我想计算 $ cov（\ undesline {\ alpha}，\ suespline {\ alpha}&#39;）$ 。我会停止从现在开始强调向量和矩阵，因为一切都是向量或矩阵。
首先，这本书在第237页上说 $ cov（\ alpha，\ alpha&#39;）= \ frac {1} {t} {t}（b \ sigma_f b&#39; + \ sigma）$ 。我的派生（如下所示）产生不同的结果。
使用回归中的残差为零（即 $ e [\ alpha] = 0 $ ）：
  $$
\ begin {Aligned}
cov（\ alpha，\ alpha&#39;）＆amp; = e [\ alpha \ alpha&#39;] \\
＆amp; = e [（\ bar {r} -b \ lambda）（\ bar {r} -b \ lambda）&#39;] \\
＆amp; = e [\ bar {r} \ bar {r}&#39; -  \ bar {r} \ lambda&#39;b&#39; -  b \ lambda \ bar \ bar {r}&#39; + b \ lambda \ lambda \ lambda \ lambda&#39;b&#39;b&#39;b&#39;]
＆amp; = e [\ bar {r} \ bar {r}&#39;] + e [b \ lambda \ lambda&#39;b&#39;]  -  2e [\ bar {r} \ lambda&#39;b&#39;] \\
＆amp; = \ frac {1} {t} \ sigma + \ frac {1} {t} b \ sigma_f b -2e [\ bar {r} \ lambda&#39;b&#39;]
＆amp; = \ frac {1} {t}（b \ sigma_f b&#39; + \ sigma）-2e [\ bar {r} \ lambda&#39;b&#39;]
\ end {Aligned}
$$  
我不知道为什么作者没有得到额外的 $  -  2e [\ bar {r} \ lambda&#39;b&#39;] $ 。我一定犯了一个错误 - 我是否错过了一个协方差术语]]></description>
      <guid>https://stats.stackexchange.com/questions/661727/error-covariance-matrix-in-cross-sectional-regression-cochrane-2005</guid>
      <pubDate>Sat, 22 Feb 2025 15:17:32 GMT</pubDate>
    </item>
    <item>
      <title>使用复杂的随机拦截来解决LMM中的奇异性/收敛问题</title>
      <link>https://stats.stackexchange.com/questions/661726/using-complex-random-intercepts-to-resolve-singularity-convergence-issues-in-lmm</link>
      <description><![CDATA[我将混合模型拟合到由2 x 2重复测量设计产生的数据。自变量是上下文（高，低）和一致性（一致，不一致）。有20段。因变量是在目标信息上读取时间（请注意，我在适当的情况下进行log-thransform）。。
我正在阅读Scandola＆amp; tidoni（2024;  https：//doii.org/1177/1177/251515259231231212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212121212AIN感谢您，本！），并与复杂的随机拦截模型（CRI）一起玩。斯堪的兰州＆amp; Tidoni提供了一个逐步的过程，用于拟合跨设计的模型，当最大模型导致收敛/奇异性问题时，这很有帮助。但是，经过文章后，我有两个有关使用CRI模型的问题。
 问题1 ：Scandola＆amp; Tidoni（2024）建议，如果最大模型（随机截距＆amp;随机斜率）会导致收敛/奇异性问题，以尝试完整的CRI模型。如果完整的CRI模型解决了问题，请出色并继续下一步。如果完整的CRI模型无法解决问题，那么Scandola＆amp; Tidoni建议以最低的方差去除CRI，然后重试。这是我的问题 -  我要降低哪种型号 - 最初的最大模型或完整的CRI模型？
例如，如果“段落”导致最小的可变性，请从中减少原始最大模型：
  m＆lt;  -  lmer（rt_target〜上下文*一致性 +（1 +上下文*一致性|主题） +（1 +上下文*一致性| vassage），mydata）;摘要（m）;方差分析（M） 
对此：
  m＆lt;  -  lmer（rt_target〜上下文*一致性 +（1 +上下文*一致性|主题） +（1 | vassage），mydata）;摘要（m）;方差分析（M） 
或，我应该从中减少CRI模型
  m＆lt;  -  lmer（rt_target〜上下文*一致性 +（1 |主题/上下文：一致性） +（1 | vassage/context/context：一致性），mydata）;摘要（m）;方差分析（M） 
对此：
  m＆lt;  -  lmer（rt_target〜上下文*一致性 +（1 |主题/上下文：一致性） +（1 | vassage），mydata）;摘要（m）;方差分析（M） 
 Scandola＆amp;蒂多尼（Tidoni）的语言在减少模型时的语言“……可以删除最低方差的CRIS”表明我应该减少CRI模型，而不是原始的最大模型。对此有任何想法吗？
 问题2 ：如果一个实验只有1个固定效果，而最大模型会导致奇异性，那么尝试将完整的CRI模型（并在必要时减少）是否合适？ /p&gt;
因此，例如，如果以下最大模型导致奇异性：
  m＆lt;  -  lmer（rt_target〜一致性 +（1 +一致性|主题） +（1 +一致性| vassage），mydata）; ANOVA（M）;摘要（M） 
然后尝试以下类似于以下的完整CRI模型是合适的：
  m＆lt;  -  lmer（rt_target〜一致性 +（1 |主题/一致性） +（1 | vassage/Ontermentions），mydata）;摘要（m）;方差分析（M） 
我问的是Scandola＆amp; Tidoni在交叉设计的背景下讨论CRIS。我想知道CRIS是否也适用于具有1个固定效果的简单实验设计。
一如既往，我感谢您的任何反馈或建议。我在这里得到的支持刚刚出色。]]></description>
      <guid>https://stats.stackexchange.com/questions/661726/using-complex-random-intercepts-to-resolve-singularity-convergence-issues-in-lmm</guid>
      <pubDate>Sat, 22 Feb 2025 14:59:12 GMT</pubDate>
    </item>
    <item>
      <title>用于证明Q学习收敛的定理中数学术语的含义</title>
      <link>https://stats.stackexchange.com/questions/661723/meaning-of-mathematical-terms-in-a-theorem-used-to-prove-q-learning-convergence</link>
      <description><![CDATA[我试图在这里理解定理的陈述 htttps：// apps.dtic.mil/sti/tr/pdf/ada276517.pdf ，用于证明Q学习算法的收敛性（即使定理更抽象）：
    
，但是我在理解术语的含义方面有问题。您能评论以下几点：
 1-什么是 $ x $ 在这里？是在x $ 中假设 $ x \的语句，因此，每个 $ x $ ，例如在高斯流程中？并且 $ x $ 即使没有明确提及条件1的状态空间？
 2-标准 $ || \ cdot || _W $ 在哪个设置上定义了？是在上一个集合 $ x $ 上定义的规范（在这种情况下是矢量空间）？是在基本概率空间的随机变量 $ \ omega $ 上定义的规范，让我们称其为 $ v（\ omega（\ omega） ）$ ？它是否在随机过程的空间中定义了标准（我猜 $ v（\ Omega \ times x）$ ）？
例如。在左侧的条件3中，规范适用于 $ e \ {f_n（x）| p_n \} $ （案例1），我将其解释为一个函数 $ x $ ，但在右边，它应用于流程 $ \ delta_n $  （情况3），所以我不确定正确的解释是什么。
感谢您帮助我澄清。该定理中似乎给予了一些设置。]]></description>
      <guid>https://stats.stackexchange.com/questions/661723/meaning-of-mathematical-terms-in-a-theorem-used-to-prove-q-learning-convergence</guid>
      <pubDate>Sat, 22 Feb 2025 11:11:23 GMT</pubDate>
    </item>
    <item>
      <title>变压器：如果值和嵌入向量不具有相同的维度，则如何完成残差连接器？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/661722/transformers-how-are-the-residual-connectinos-done-if-the-value-and-embedding-v</link>
      <description><![CDATA[在这篇文章中&gt;据说查询，密钥和值向量不必与嵌入相同的维度。 （&#39;他们不必较小，这是一个架构的选择，可以选择多头注意的计算（主要）恒定。＆quort;）
后来他解释了残差连接。我想知道：当嵌入和值向量没有相同的维度时，是否可以进行残差连接？那你不能添加它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/661722/transformers-how-are-the-residual-connectinos-done-if-the-value-and-embedding-v</guid>
      <pubDate>Sat, 22 Feb 2025 10:52:52 GMT</pubDate>
    </item>
    <item>
      <title>结合非独立概率指标</title>
      <link>https://stats.stackexchange.com/questions/661721/combining-non-independent-probability-indicators</link>
      <description><![CDATA[ i有n指标，每个事件都发生了，每个事件都具有关联的概率
  indies_a-＆gt; 0.1
indionator_b-＆gt; 0.7
indionator_c-＆gt; 0.5
 
 i还具有一个相关矩阵，该矩阵描述了每对指标的相关性。
我想计算事件发生的总体概率。
我有一个想法（但我不确定它是正确的）：
  p（e）≈w_a.p（a） + w_b.p（b） + w_c.p（c）

w_a = 1 + p（a，b） + p（a，c） / z
w_b = 1 + p（a，b） + p（b，c） / z
w_c = 1 + p（a，c） + p（b，c） / z

z = w_a + w_b + w_c
 
其中p（a，b）可能是从相关矩阵中得出的一定程度。

如果有一种正式的方法可以做到这一点，那就太好了。但是粗糙的近似也可以。
任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661721/combining-non-independent-probability-indicators</guid>
      <pubDate>Sat, 22 Feb 2025 10:09:07 GMT</pubDate>
    </item>
    <item>
      <title>关于比较三个不同小组评分的问题</title>
      <link>https://stats.stackexchange.com/questions/661696/questions-on-comparing-three-different-groups-ratings</link>
      <description><![CDATA[我目前正在比较三个群体之间的职业障碍：学生，教职员工和行业专业人员。尽管我使用李克特量表的同一调查问卷（例如，“在决定职业时工作满意度很重要”），但我注意到与其他两个组相比，行业参与者通常反应更负面。例如，学生的平均评分为6.2/7，教职员工的平均评分为6.1/7，在所有调查项目中的行业专业人员的平均评分为4.89/7。
鉴于这些基线差异，我担心简单的均值比较可能不会产生有意义的见解。取而代之的是，我正在考虑专注于排名（例如，确定哪些障碍对学生与行业专业人员最重要）。在这种情况下，使用最合适的分析方法是什么？
我记得看到一篇有类似方法的论文，但是尽管进行了数小时的搜索，但我还是找不到它。任何人都知道有类似方法的好论文吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661696/questions-on-comparing-three-different-groups-ratings</guid>
      <pubDate>Fri, 21 Feb 2025 16:30:57 GMT</pubDate>
    </item>
    <item>
      <title>如何在不同聚集/粒度水平下的时间序列数据的经验估计标准偏差和变异系数？</title>
      <link>https://stats.stackexchange.com/questions/661685/how-to-empirically-estimate-standard-deviation-and-coefficient-of-variation-for</link>
      <description><![CDATA[我正在与2024年9月19日至11月19日的图书馆建筑物收集的时间序列建筑物占用数据。每5分钟，使用Motion（PIR）传感器（总共450张椅子）记录每5分钟的数据。然后将数据重新采样至30分钟的间隔（2689个数据点），并在不同级别进行汇总：
椅子级别：450椅→1,210,050个数据点（450*2689）
表级：50个表→134,450数据点（50*2689）
子区域级别：6个子区域→16,134个数据点（6*2689）
区域级别：2区→5,378个数据点（2*2689）
 客观：我旨在使用两个关键指标（即标准偏差（SD）（SD）和变异系数（CV），在不同水平的粒度（椅子，桌子，子区域和区域）处量化可变性。 。
在较小的级别（例如椅子级）下，我有更多的观察结果（更高的数据点，而在更粗的水平（例如区域级别）下，样本量明显较小。
我的主要问题是
 1-当每个粒度水平的数据点总数显着差异时，我如何从经验上估计SD，CV进行公平比较？我已经计算了原始SD，而没有考虑到不平等的观察数（请参阅附件图）每小时标准偏差的箱形图表所有粒度级别” src =“ https://i.sstatic.net/vok57dth.jpg”/&gt; 。
数据集附加在此处
考虑不平等的数据点，可以用来估算SD的任何见解，参考或方法将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661685/how-to-empirically-estimate-standard-deviation-and-coefficient-of-variation-for</guid>
      <pubDate>Fri, 21 Feb 2025 13:39:12 GMT</pubDate>
    </item>
    <item>
      <title>我是否了解主教的主教？</title>
      <link>https://stats.stackexchange.com/questions/661681/have-i-understood-bishop-on-uninformative-priors</link>
      <description><![CDATA[主教将A 定义参数满足以下内容，
 $$
p（x | \ mu）= f（x- \ mu）。
$$ 
他想定义“不信息先验”对于 $ {\ MU} $ 对于贝叶斯推理。如果我没记错的话，那是他想利用以下不变性，
 $$
\ wideHat {x}：= x + c \ leadsto p（\ wideHat {x} | \ wideHat {\ mu}）= p（x | \ mu），
$$ 
我们定义了 $ {\ wideHat {\ mu} = \ mu+c} $ 。这是我想验证我理解的阶段：他本质上想定义先前的 $ {p（\ mu）} $ ，以便我们具有以下后代：
 $$
p（\ wideHat {\ mu} | \ wideHat {x} _1，...，\ wideHat {x} _n）= p（\ mu | x_1，...，...，x_n）。
$$ 
他并没有这样说，所以这就是为什么我想检查我本质上理解这个想法的原因。如果您继续这个想法，则最终会以 $ {p（\ wideHat {\ mu}）= p（\ mu）} $ ，并且由于选择了 $ {c} $ 是任意的，您最终会 $ {p（\ mu）= \ text {const。}} $  ]]></description>
      <guid>https://stats.stackexchange.com/questions/661681/have-i-understood-bishop-on-uninformative-priors</guid>
      <pubDate>Fri, 21 Feb 2025 12:12:55 GMT</pubDate>
    </item>
    <item>
      <title>GLMM比较偏移模型与非出生模型</title>
      <link>https://stats.stackexchange.com/questions/661361/glmm-comparing-offset-model-to-non-offset</link>
      <description><![CDATA[ [重试] 
  [这个问题] 已经被我打开了，但是帐户注册（很可能用户错误）的问题阻止了我回答评论。我发送支持请求以合并帐户，与此同时，我想遵循 @benbolker的建议（尽管目前我无法删除旧线程）：

最好删除此问题并在使用您的新帐户登录时重新发布它（@pbulls的评论将消失，但是您可以在您的问题下在您自己的评论中引用它 - 最好不要包括它是问题本身的一部分

主题
我试图了解我对GLMM的偏移术语的解释以及不同偏移模型之间的进一步解释是正确的。
起点
从不同陷阱（TRT）收集的生物，这些陷阱在体积和开放直径上不同。
公式非出现：
 glmmtmb（counts〜trt+盐度+（1 | group），family = truncated_nbinom2）
 计数是发现的生物数量

TRT是一个因子变量，有5个级别（例如A-E）

盐度是连续的变量

组是一个具有15个级别的因素，代表了TRT级别的重复块
 
在构造零截断的负二元格GLMM并使用EMMEANS之后，此模型返回每个TRT级别计数的平均估计值，并且可以进行成对比较。
正如预期的最高体积容器所含的最高计数。
模型中的偏移
，但我也很感兴趣，如果计数率取决于数量或表面积。
因此，我在公式中添加了音量或表面积的偏移项：
 glmmtmb（counts〜trt+盐度+（1 | group），offset = log（卷），family = truncated_nbinom2）
 glmmtmb（counts〜trt+盐度+（1 | group），offset = log（afore），family = truncated_nbinom2）
再次使用emmeans（包括偏移= 0，在emmeans呼叫中），我现在获得每卷（ML）或表面积（mmm²）的生物计数。
偏移的比较 - 问题
看着“ hierachy”是否明智。总数和偏移率之间的TRT水平的水平，以比较哪个偏移项是更好的“预测指标”总数？
示例（编号数字）：
非偏移结果：
  trt估算
A 200
B 150
C 100
D 90
E 20
 
音量折扣：
  trt估算
一个10
B 8
C 5
E 4
D 0.5
 
地面偏移：
  trt估算
E 90
D 70
C 55
B 42
A 33
 
  如果 此比较是明智的，我的解释是，体积比表面积更好。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661361/glmm-comparing-offset-model-to-non-offset</guid>
      <pubDate>Fri, 14 Feb 2025 06:34:46 GMT</pubDate>
    </item>
    <item>
      <title>基于过渡概率的聚类</title>
      <link>https://stats.stackexchange.com/questions/661254/clustering-based-on-transition-probabilities</link>
      <description><![CDATA[我有工人职业历史的面板数据，其中每个工人的职业在每个时间段都被指示。我希望将职业聚集在一起。这个想法是在同一集群中的职业之间建立群集。
例如，如果许多工人从数据科学家转换为计算机科学家，反之亦然，这两个职业可能处于同一集群中。
我知道序列聚类，但这会根据工人的职业历史而不是职业聚类。
问题：什么是（）将职业分为组的方式？]]></description>
      <guid>https://stats.stackexchange.com/questions/661254/clustering-based-on-transition-probabilities</guid>
      <pubDate>Tue, 11 Feb 2025 22:08:45 GMT</pubDate>
    </item>
    </channel>
</rss>