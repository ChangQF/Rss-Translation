<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 07 Jan 2025 21:15:35 GMT</lastBuildDate>
    <item>
      <title>线性回归 - 响应变量为百分比改善或 m/s？</title>
      <link>https://stats.stackexchange.com/questions/659686/linear-regression-response-variabel-as-percent-improvement-or-m-s</link>
      <description><![CDATA[我正在尝试对包含 8 种不同跑步距离的数据集进行统计，这些距离在遵循训练方案之前和之后都有时间，并且基于距离对改进进行线性回归（所有完成时间都有所下降）。我不确定是否要转换为百分比改进或使用 m/s 之类的变量，然后减去跑步时间 1 和跑步时间 2，以便能够比较不同的距离组。显然，绝对时间差异并不大，因为更长的距离自然会有更大的改进。但我读到过，不建议将百分比改进转换为线性回归中的响应变量。我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/659686/linear-regression-response-variabel-as-percent-improvement-or-m-s</guid>
      <pubDate>Tue, 07 Jan 2025 21:03:50 GMT</pubDate>
    </item>
    <item>
      <title>在 statsmodels 中 GLM 上使用哪些参数</title>
      <link>https://stats.stackexchange.com/questions/659683/what-params-to-use-on-glm-from-statsmodels</link>
      <description><![CDATA[我正在模拟试剂转化率对试剂 L 和 M 之间比率的依赖性。比率越高，试剂转化率越高，在 1.5 左右有一个明显的拐点。下面是我拥有的完整数据集

df = pd.DataFrame({&#39;L_M&#39;:[4.75, 3.8, 3.32, 2.85, 2.37, 1.9, 1.42, 0.95, 0.71, 0.47, 0.24, 0.09],
&#39;Conversion&#39;:[0.992, 0.987, 0.993, 1, 0.9, 0.7, 0.31, 0.1, 0.07, 0.06, 0.07, 0.065]})

为此，我使用二项式家族的 GLM 模型，以 Logit 作为链接函数（又称 Logistic 回归）。这似乎很合适，因为我正在对二项式过程中的成功率进行建模（试剂要么发生反应，要么不发生反应）。我尝试使用 statmodels.GLM 失败了，下面的代码产生了非常差的拟合效果：
# 定义因变量和自变量 
Xtrain = df[&#39;L_M&#39;] 
ytrain = df[&#39;Conversion&#39;]

# 构建模型并拟合数据 
log_reg = sm.GLM(ytrain, Xtrain, family=sm.families.Binomial()).fit()

# 推理 
df[&#39;Predicted&#39;] = log_reg.predict(Xtrain)


然而，我使用了一种 hack 的方法，为每个变量创建了 100 个原始数据实验点，每个原始 y 变量为 0 或 1，概率等于此实验点的转换，然后使用 sklearn 将 logreg 拟合到这个（膨胀很多的）数据集，效果很好，产生更好的拟合效果：
from sklearn.linear_model import LogisticRegression

# 实例化模型（使用默认参数）
logreg = LogisticRegression(random_state=16)

# 用数据拟合模型
logreg.fit(X_train, y_train)
new_X = pd.DataFrame(df[&#39;L_M&#39;])
new_X.columns = [&#39;ratio&#39;]
df[&#39;Predicted&#39;]= logreg.predict_proba(new_X)[::,1]



我在 statsmodels.GLM 中遗漏了哪些参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/659683/what-params-to-use-on-glm-from-statsmodels</guid>
      <pubDate>Tue, 07 Jan 2025 20:27:59 GMT</pubDate>
    </item>
    <item>
      <title>以序数数据作为中介变量，检验数值数据对数值数据的影响：conver</title>
      <link>https://stats.stackexchange.com/questions/659681/testing-the-effect-of-numerical-data-on-numerical-data-with-ordinal-data-as-a-me</link>
      <description><![CDATA[我必须运行一个测试，测试数值数据（ESG 评级；范围 0-300）对数值数据（Tobin&#39;s Q（衡量公司财务业绩的指标：范围 0+））的影响。我添加了信用评级（具有 13 个范围类别的序数）。我应该运行什么测试？
上述数据是非正态的。
到目前为止，我已经看到了两种方法：

将序数数据转换为数值数据（因此为 1-13）并运行回归测试。
为序数数据创建虚拟变量并测试它们对因变量的影响。

此外，建议使用引导程序运行测试。
您认为最好的分析方法是什么？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659681/testing-the-effect-of-numerical-data-on-numerical-data-with-ordinal-data-as-a-me</guid>
      <pubDate>Tue, 07 Jan 2025 20:06:49 GMT</pubDate>
    </item>
    <item>
      <title>mgcv::gam 不能正确地从平滑中分解线性分量</title>
      <link>https://stats.stackexchange.com/questions/659680/mgcvgam-does-not-correctly-decompose-the-linear-component-from-the-smooth</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659680/mgcvgam-does-not-correctly-decompose-the-linear-component-from-the-smooth</guid>
      <pubDate>Tue, 07 Jan 2025 18:52:03 GMT</pubDate>
    </item>
    <item>
      <title>我应该将点大小（面积）比例缩放为 1/标准误差还是 1/SE^2？</title>
      <link>https://stats.stackexchange.com/questions/659678/should-i-scale-point-size-area-proportion-to-1-standard-error-or-1-se2</link>
      <description><![CDATA[我有一堆估计值，我想将它们绘制在 y 轴上，而 x 轴上则绘制其他值。我想传达每个点的不确定性（x 轴值已知，y 轴值是估计值）。误差线会使图变得非常混乱，所以我想使用点的大小来传达我们对每个点的确定程度。据我所知，建议人们将面积（而不是直径）视为信息量（例如，参见本文或此链接 - 不确定这些是否是标准参考文献）。
但是，有没有研究信息度量应该是 1/SE（标准误差的倒数）还是 1/SE^2（抽样方差的倒数）。鉴于对于误差线，我们将使用 +-SE 或置信区间（95% 的置信区间大约为 +- 1.96*SE），我猜是 1/SE？不知何故，我找不到是否有人尝试过实证检验这是否有效（例如，当人们被问到问题时，他们会根据所选的可视化效果做出适当的回答，即当给定基于 1/SE 或 1/SE^2 或其他东西的点大小时，他们是否会做得更好）。
鉴于我们倾向于绘图]]></description>
      <guid>https://stats.stackexchange.com/questions/659678/should-i-scale-point-size-area-proportion-to-1-standard-error-or-1-se2</guid>
      <pubDate>Tue, 07 Jan 2025 17:47:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 IRT 进行非监考评估</title>
      <link>https://stats.stackexchange.com/questions/659676/using-irt-for-a-non-proctored-assessment</link>
      <description><![CDATA[过去几年，我的研究团队一直在为大学课程结束时参加的学生进行内部多项选择知识评估。我的老板坚持要我们进行有效性测试，并且非常喜欢 IRT 模型。但是，我们没有资源来监考考试，而且为了招聘，我们的研究负责人不想规定我们的合作教师如何进行评估或为其分配多少学分。这允许教师享有某些自由。例如，评估是基于计算机的，我知道许多教师只是让学生在家参加评估，有些教师会给予很少的学分。
我担心的是，当我们运行 IRT 模型时，它们不会非常准确，因为学生很有可能作弊，或者没有付出任何努力。我们过去几次管理中有大约 300-600 名学生，2PL 模型往往是最合适的。然而，它们仍然不是很好的匹配（RMSEA 和 CFI 不错，但 M2 显示预期和实际观察值之间存在显著差异）。此外，过去两个学期的 IRT 结果显示出不一致的结果。在一个学期中，一个项目表现良好；在下一个学期，我会得到负面歧视或难度指数为 30 或类似的奇怪结果。
是否有方法可以减轻非监考评估固有的可变性，并适合 IRT 框架？或者，我运气不好，我需要求助于其他方法来测试有效性？或者，我是否只需要说服我的研究负责人，我们需要投入资源来建立监考管理部门以进行测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/659676/using-irt-for-a-non-proctored-assessment</guid>
      <pubDate>Tue, 07 Jan 2025 17:32:27 GMT</pubDate>
    </item>
    <item>
      <title>调整 Chernozhukov 等人的通用机器学习推理以获得事件发生时间结果</title>
      <link>https://stats.stackexchange.com/questions/659674/adapting-chernozhukov-et-al-s-generic-machine-learning-inference-for-time-to-ev</link>
      <description><![CDATA[这是一个非常具体的问题，但我们开始吧！
我正在努力将 Chernozhukov 等人的随机实验中对异质性治疗效果的通用机器学习推断中的方法应用于事件发生时间结果（例如生存分析）。本文通过将机器学习方法与最佳线性预测器 (BLP) 估计和有效推理技术相结合，提供了一个估计异质治疗效果 (HTE) 的框架。
虽然对连续或二元结果有一般的扩展，但将其应用于事件发生时间数据会因审查和生存特定指标而带来独特的挑战。
一般问题：
是否有人实施或改编了 Chernozhukov 等人的事件发生时间结果方法？如果是，需要进行哪些修改才能使该方法与生存分析兼容？
是否有任何通用工具、库或资源可用于解决此类问题，特别是用于调整生存数据的第 1 阶段（代理函数估计）和第 2 阶段（BLP）？

具体挑战：
第 1 阶段：代理函数估计（B(Z) 和 S(Z)）
第 1 阶段的损失函数是根据 BLP 估计量身定制的。如何调整它以考虑生存数据中的审查？
标准生存损失函数（例如 Cox 模型或 Brier 评分的负偏对数似然）是否足够？如果不够，建议使用哪些替代方案？

第 2 阶段：最佳线性预测器 (BLP) 估计
在生存分析中，通常使用生存概率、风险比或时间相关指标（例如一致性指数、时间相关 AUC）等结果。如何使 BLP 框架适应此类指标？
BLP 计算应如何处理审查，以及在这种情况下进行有效推理需要考虑哪些因素？

实施和工具
是否有针对事件发生时间数据量身定制的此方法的具体实施（使用 R 或 Python）？

更广泛的背景：
目标是在存在审查的事件发生时间结果的情况下估计异质性治疗效果，同时通过重复数据分割和分位数聚合等技术保持有效推断。任何与将此方法用于生存分析相关的见解、参考或示例都将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/659674/adapting-chernozhukov-et-al-s-generic-machine-learning-inference-for-time-to-ev</guid>
      <pubDate>Tue, 07 Jan 2025 17:24:47 GMT</pubDate>
    </item>
    <item>
      <title>检测生存分析中的单个变化点/拐点</title>
      <link>https://stats.stackexchange.com/questions/659673/detection-of-a-single-change-point-inflection-in-a-survival-analysis</link>
      <description><![CDATA[我正在对有和没有手术并发症的患者进行生存分析。当检查这两个群体的 Kaplan-Meier 曲线时，很明显手术并发症对术后早期生存的影响更大。Schoenfeld 残差和对数减对数图显示违反了 PH 假设。
有/无并发症的患者的 KM 曲线显示其拐点在术后 3 个月左右发生了明显变化。这表明术后早期并发症的影响更大。术后每个月的调整和未调整 HR 显示​​出相似的趋势。
我如何准确检测和描述这个精确的变化点/拐点？
我想估计一个确切的日期以协助临床决策。我花了好几天到处寻找这个特定问题的答案，但我找不到解决方案。
我正在与 R 合作。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659673/detection-of-a-single-change-point-inflection-in-a-survival-analysis</guid>
      <pubDate>Tue, 07 Jan 2025 17:24:04 GMT</pubDate>
    </item>
    <item>
      <title>R 中带有测量误差的优化函数（矩量模拟法）</title>
      <link>https://stats.stackexchange.com/questions/659682/optimizing-function-with-measurement-error-in-r-simulated-method-of-moments</link>
      <description><![CDATA[统计学中的一个常见问题是假设一个总体，模拟许多样本，并找到与所需统计数据集最接近（在 MSE 意义上）的参数。为了说明，下面是如何找到与 AR1 过程匹配的参数的草图。（这只是一组广泛问题的说明 --- 这个特定问题是 AR1 并不重要。）

NT &lt;- 50
match &lt;- c( 截距=0.2, ar1=0.90, expsigma=(-0.1) )

sim.and.est.1 &lt;- function( i, p ) {

## 模拟某个过程，比如 true ar1
set.seed( i ); e &lt;- rnorm(NT, 0, exp(p[3]))
s &lt;- c( 0.2, numeric(NT-1) )
for (t in 2:NT) s[t] &lt;- p[1] + p[2]*s[t-1] + e[t]

## 估计 OLS ar1
a &lt;- lm.fit( cbind(1, s[1:(NT-1)]), s[2:NT] )
c( coef(a), expsigma= log(sd(resid(a)) ))
}

mcsapply &lt;- function( iter, fun, ... ) { simply2array(mclapply( iter, fun, ... )) }
penalty &lt;- function( a, b ) mean( (a-b)^2 )

result &lt;- optim(par=c(1.0, 0.0, 0.05),
fn=function( guess3, MC=1000 ) {
## message( paste( p3, collapse=&quot; &quot; ) )
simsests &lt;- t(mcsapply( 1:MC, function(i) sim.and.est.1(i, guess3) ))
thisone &lt;- colMeans( simsests )
ov &lt;- penalty( thisone , match )

## 如果我们接近，则抽样更多
if (ov &lt; 1e-2) {
## 增加精度
simsests &lt;- rbind(simsests, t(mcsapply( 1:MC*5, function(i) sim.and.est.1(i+MC, guess3) )))
thisone &lt;- colMeans( simsests )
ov &lt;- penalty( thisone , match )
}
ov
},
method=&quot;Nelder-Mead&quot;)

print(result)

R 中是否有更好的方法来处理具有测量误差的函数优化？

我试图处理这样的想法：远离最佳值，我不需要在函数本身中采样那么多点。它完全是临时的。
我也尝试重新启动 Nelder-Mead，但即使从局部最优开始似乎也没有减少其迭代次数（函数评估）。

是否有更适合手头任务的优化器？
我在这里做的事情可以做得更好吗？
建议表示感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659682/optimizing-function-with-measurement-error-in-r-simulated-method-of-moments</guid>
      <pubDate>Tue, 07 Jan 2025 17:01:55 GMT</pubDate>
    </item>
    <item>
      <title>混合模型：在 R 中探究聚类内中心化后一级分类变量之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/659667/mixed-model-probing-an-interaction-between-level-1-categorical-variables-after</link>
      <description><![CDATA[我有以下模型：
model &lt;- lmer(scores ~glasses + D1 + D2 +glasses:D1 +glasses:D2 + (1|participantNumber),data,REML = FALSE)


参与者在戴或不戴眼镜（关 = 0，开 = 1）的情况下完成了一项任务的试验，并且分为三个难度级别（简单 = 0，中等 = 1，困难 = 2）

两个 1 级预测因子（眼镜和任务难度）在概念上都是分类的，但已在集群内居中，因此它们现在是“连续的”


我如何评估每个任务难度级别上分数和眼镜之间的关系？
由于我的预测因子现在是“连续”，我使用 Johnson-Neyman 方法来探测交互作用（使用 interactions 包）。但是，我想报告诸如 t 统计量之类的值，但除非我“选择一个点”，否则我无法这样做，但我不知道该选择哪个点，因为数字范围很广。
例如，在常规回归中，我的虚拟编码变量对于所有参与者都如下所示：



任务难度
D1
D2
D1b
D2b
D1c
D2c




简单
0
0
0
1
1
0


中等
 1
0
0
0
0
1


困难
0
1
0
0
0



之后在集群内居中，参与者有不同的虚拟编码值：
参与者 1



任务难度
D1
D2
D1b
D2b
D1c
D2c




容易
-0.33
-0.33
-0.33
+0.67
+0.67
-0.33


中等
+0.67
-0.33
-0.33
-0.33
-0.33
+0.67


困难
-0.33
+0.67
+0.67
-0.33
-0.33
-0.33



参与者22



任务难度
D1
D2
D1b
D2b
D1c
D2c




简单
-0.48
-0.05
-0.05
+0.95
+0.52
-0.48


中等
+0.52
-0.05
-0.05
-0.05
-0.48
+0.52


困难
-0.48
+0.95
+0.95
-0.05
-0.48
-0.48



因此， Johnson-Neyman 方法告诉我，分数和眼镜之间的关系取决于 D1/D2 是负数还是正数。
probe_interaction(model, pred =glasses, modx = D1, data,
confint=TRUE, cond.int=TRUE, interval=TRUE,
centered=&quot;none&quot;, johnson_neyman=TRUE, jnplot=TRUE)

probe_interaction(model, pred =glasses, modx = D2, data,
confint=TRUE, cond.int=TRUE, interval=TRUE,
centered=&quot;none&quot;, johnson_neyman=TRUE, jnplot=TRUE)

但是，要报告 t 统计量，例如在评估简单任务难度下的分数和眼镜之间的关系时，我不知道如何选择“0” 表示简单条件，因为“0”在一个参与者中为 -0.33，在另一个参与者中为 -0.48。
任何指导（统计或要使用的函数）都值得赞赏，提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/659667/mixed-model-probing-an-interaction-between-level-1-categorical-variables-after</guid>
      <pubDate>Tue, 07 Jan 2025 15:05:35 GMT</pubDate>
    </item>
    <item>
      <title>GAM 中相互作用项的意义</title>
      <link>https://stats.stackexchange.com/questions/659666/significance-of-interaction-term-in-gam</link>
      <description><![CDATA[我有一个广义加性模型，其形式如下：
$E[Y] = \beta_0 + f(X_1) + \beta_2X_2 + f(X_1)\times X_2$
其中 $f(X_1)=\sum^n_i\beta_i\boldsymbol{B}_i(X_{1i})$ 是平滑函数，$\boldsymbol{B}(\cdot)$ 是用于平滑连续协变量 $X_1$ 的基函数（例如三次样条函数），$f(X_1)\times X_2$ 是平滑的 $X_1$ 和二元协变量 $X_2$ 之间的交互项。
我感兴趣的是测试 $X_1$ 和 $X_2=0$ 之间的交互是否与 $X_1$ 和 $X_2=1$ 之间的交互有显著不同，例如测试两个相互作用的斜率是否显著不同。
如果这是一个 GLM，其中人们使用 $X_1$ 而不应用基函数，则可以通过比较两个不同相互作用的参数直接推断出差异（分别为 $X_2=0$ 和 $X_2=1$）。现在涉及到样条函数，我们总共有 $2n$ 个交互项（$n$ 个基函数，每个基函数与两个条件交互）及其相应的系数，我不再确定如何测试交互是否因条件 $X_2$ 而显著不同。
当连续协变量被多个基函数“分割”为区间，并且这些区间与二元协变量的两个级别交互时，如何测试显著交互？特别是在不使用 LRT 或需要拟合嵌套模型的类似方法的情况下。使用例如 Wald 检验来测试两组参数是否显著不同或逐一比较系数是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/659666/significance-of-interaction-term-in-gam</guid>
      <pubDate>Tue, 07 Jan 2025 14:55:32 GMT</pubDate>
    </item>
    <item>
      <title>非对称独立变量的排序</title>
      <link>https://stats.stackexchange.com/questions/659660/ranks-for-an-asymmetric-independent-variable</link>
      <description><![CDATA[我正在使用回归模型分析数据，其中感兴趣的独立变量是治疗，我想估计其效果。我打算调整一组协变量的估计值，包括两个生物标志物。这些生物标志物的分布高度偏斜（大多数个体的值介于 0 和 1 之间，少数个体的值超过 10,000）。最初，我考虑将生物标志物值分为 4 组，这是一种常见的方法。后来，我考虑使用等级，因为与分类相比，这可能会减少丢失的信息量。虽然这会降低参数的可解释性（使用类别更清晰，但使用等级则不那么清晰），但我的主要目标是进行调整，以便更好地估计感兴趣变量的效果。
您觉得如何？这种方法能带来优势吗？您知道任何描述这种方法的资源吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659660/ranks-for-an-asymmetric-independent-variable</guid>
      <pubDate>Tue, 07 Jan 2025 11:54:44 GMT</pubDate>
    </item>
    <item>
      <title>何时使用哪种样本方差公式？</title>
      <link>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</link>
      <description><![CDATA[我知道样本方差的公式为
$$s^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1}$$
我还知道样本方差的公式为“均值平方减均值平方”。
在计算给定样本的样本方差时，我使用了这两个公式，但发现它们给出了两个不同的答案，因此我想问，什么时候应该使用第一个公式，什么时候应该使用第二个公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</guid>
      <pubDate>Tue, 07 Jan 2025 05:32:19 GMT</pubDate>
    </item>
    <item>
      <title>使用加权逻辑回归对重复数据进行误差估计的校正因子</title>
      <link>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</link>
      <description><![CDATA[假设一个数据集被复制，但第一个副本被分配了一组特殊权重，而第二个副本具有另一组权重，其中权重与我们复制数据的事实无关。 主要问题：

我是否应该将每个权重乘以 1/2 以纠正数据重复？

上下文
假设对于每个观察值 1 到 N，您有概率估计 $p_a=P(race=a)$、$p_b=P(race=b)$、$p_c=P(race=c)$，其中 $\sum_{r=\{a,b,c\}}p_r=1$ 和一些二元结果变量 $y$，并且我们希望估计逻辑回归 $\text{logit }y\sim \beta_0 + \beta_1 D^{r}+X\beta$ 其中 $D^r=1$ 当 P(race=r)&gt;.8 时，否则为 0。但是，由于我们希望明确地并且只比较 a 与 b，因此我们在 P(race=a)&gt;.8 或 P(race=b)&gt;.8 的数据子集上估计 $\text{logit }y\sim \beta_0 + \beta_1 D^{b}+X\beta$。这是传统方法，但它会丢弃所有 P(race=a)&lt;.8 AND P(race=b)&lt;.8 的数据。
重复的数据集，但每个重复项的权重不同
为了不丢弃 P(race=a)&lt;.8 AND P(race=b)&lt;.8 为真的观测值所包含的信息，我上面的一些高阶估计了一个加权逻辑回归，其中
\begin{align}
\text{logit }\begin{pmatrix}
y \\
y \\
\end{pmatrix} &amp;= \beta_0+\beta_1\begin{pmatrix}
D^{b} \\
D^{b} \\
\end{pmatrix}
+ \begin{pmatrix} X \\ X\\ \end{pmatrix} \beta
\end{align&gt;
其中 $$\text{weights} =\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$$ 且 $D^b_{1\dots N}$=1 且 $D^b_{(N+1)\dots 2N}=0$（基本上，第一个 1...N 堆栈具有虚拟 $D^b=1$ 且第二个 (N+1)...2N 具有虚拟 $D^b=0$。
问题：通常，每个观察值的权重为 1/2 应该可以解决因重复数据集而产生的错误估计问题。这是否仍然适用于权重的使用。例如，我可以这样做 $\text{weights} =\frac{1}{2}\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$。
附言
为了有形的直觉，想想比较黑人与白人以及西班牙裔与白人，但不知道谁是白人、西班牙裔和黑人，你只能对每个类别有一个概率估计。
请原谅我草率的符号，希望它足以传达这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</guid>
      <pubDate>Tue, 07 Jan 2025 04:28:49 GMT</pubDate>
    </item>
    <item>
      <title>从 nlme 方差结构中修复方差参数</title>
      <link>https://stats.stackexchange.com/questions/659628/fixing-variance-parameters-from-nlme-variance-structure</link>
      <description><![CDATA[我一直在使用 nlme 包中的异方差随机效应模型。我不知道如何设置 varStruct 中的参考水平方差参数。在下面的例子中，我使用样本数据 Orthodont 拟合模型，该模型允许根据受试者的性别在受试者内差异化个体。
我知道值输出代表受试者内误差的标准差比率：
$$
\frac{\hat\sigma_{female}}{\hat\sigma_{male}} = .4533
$$
library(nlme)
ex.data &lt;- as.data.frame(Orthodont)
ex.model &lt;- lme(distance ~ age, data = ex.data,
random = ~1|Subject,
weights = varIdent(form = ~1|Sex))

ex.model$modelStruct$varStruct #如何从这个对象中提取值？
#&gt; 表示类 varIdent 的方差函数结构
#&gt; 男性 女性 
#&gt; 1.000000 0.453369


于 2025-01-06 使用 reprex v2.0.2 创建
有没有办法重新参数化模型，将女性的权重设置为 1，并让男性自由估计，以便我可以找到：
$$
\frac{\hat\sigma_{male}}{\hat\sigma_{female}}
$$
我试过这个，但没有结果：
ex.model_fixed &lt;- lme(distance ~ age, data = ex.data,
random = ~1|Subject,
weights = varIdent(form = ~1|Sex, fixed = c(&quot;Female&quot; = 1))) #如何将级别固定为某些值？

ex.model_fixed$modelStruct$varStruct
#&gt; 类 varIdent 的方差函数结构没有参数，或未初始化

我知道在这个例子中，只需反转比率即可轻松手动计算。一般来说，我想学习如何更改我在实践中使用的这种形式的其他模型的参考级别。]]></description>
      <guid>https://stats.stackexchange.com/questions/659628/fixing-variance-parameters-from-nlme-variance-structure</guid>
      <pubDate>Mon, 06 Jan 2025 21:32:41 GMT</pubDate>
    </item>
    </channel>
</rss>