<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 21 Nov 2024 18:23:34 GMT</lastBuildDate>
    <item>
      <title>使用线性混合模型时，输出变量中缺失多少数据是可以接受的？</title>
      <link>https://stats.stackexchange.com/questions/657631/how-much-missing-data-in-the-output-variable-is-ok-when-using-linear-mixed-model</link>
      <description><![CDATA[我有重复测量数据，但由于缺失，我计划使用线性混合模型。我唯一的预测因子是时间，结果变量是定量测量的幸福感得分。目标是确定幸福感是否随着时间的推移而发生整体变化。
幸福感得分是通过四个时间点的季度调查收集的，参与人数如下：

时间 1：25 名参与者
时间 2：54 名参与者
时间 3：70 名参与者
时间 4：120 名参与者

由于大量缺失数据，近 80% 的答复不完整。许多参与者只参加了一次，特别是在时间 4，缺乏后续数据。为了解决这个问题，我过滤了数据集以仅包含至少参加过两个时间点的参与者。经过筛选后，参与人数如下：

时间 1：21 名参与者
时间 2：35 名参与者
时间 3：46 名参与者
时间 4：47 名参与者

此调整将缺失数据减少至约 36%。排除仅参加过一次的参与者是否合适？缺失数据多少才合适？
我非常感谢任何反馈或建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/657631/how-much-missing-data-in-the-output-variable-is-ok-when-using-linear-mixed-model</guid>
      <pubDate>Thu, 21 Nov 2024 17:24:52 GMT</pubDate>
    </item>
    <item>
      <title>LMEM - 什么时候可以不将重复测量视为随机效应？以及其他相关问题</title>
      <link>https://stats.stackexchange.com/questions/657629/lmem-when-is-it-okay-to-not-treat-repeated-measures-as-a-random-effect-and-ot</link>
      <description><![CDATA[设计：我有 3 个组，每个受试者在每个时间点接受 3 次测试（3 次试验），在三个不同的时间点。
独立变量为：组（A、B 或 C）、试验（1、2 或 3）和时间（0、2、4）。
问题 1：我的模型是奇异的（边界（奇异）拟合消息），除非我将时间排除为随机因素。在这种情况下，我可以排除时间作为随机因素吗？如果不能，解决方案是什么？
我的原始模型：lmer (score ~ Group*Time + (1+Time | ID))，获得边界（奇异）拟合消息。时间是一个连续变量。
随机效应 ID（截距）与时间之间的相关性为 -1.00，这表明随机效应之间存在共线性，我不明白这一点。
新模型：lmer (score ~ Group*Time + (1 | ID))，模型不返回警告，结果几乎相同。如果这不合适，解决方案是什么？在这种情况下，我应该忽略奇异拟合消息吗？
问题 2：我怀疑对于所有时间点，受试者在试验 1 中的反应与试验 2 和 3 相比会有所不同（更慢）。也就是说，试验不是独立的。假设我有足够大的数据集，如何将试验作为固定和随机因素？我需要嵌套模型吗？
其中一个是正确的吗？用外行人的话来说，它们有什么不同？
lmer (score ~ Group*Time*Trial + (1 + Time + Trial | ID)) 或 lmer (score ~ Group*Time*Trial + (1 + Time | ID) + (1 | Trial))？
与问题 1 类似，如果模型是单数，我可以排除 Trial 作为随机因素吗？
问题 3：假设 Trial 顺序对所有组的影响相同，或者我不关心 Trial，我是否仍应将其作为随机效应包括在内，因为它是重复测量？如果是这样，这是否意味着我必须将其作为固定因素包括在内，因为（我可能是错的）经验法则是所有随机效应都应作为固定效应包括在内？什么时候我不会将随机效应作为固定效应包括在内？
这正确吗？ lmer (得分 ~ 组*时间 + 试验 + (1 + 时间 + 试验 | ID))?
什么时候可以这样做？lmer (得分 ~ 组*时间 + (1 + 时间 + 试验 | ID))?]]></description>
      <guid>https://stats.stackexchange.com/questions/657629/lmem-when-is-it-okay-to-not-treat-repeated-measures-as-a-random-effect-and-ot</guid>
      <pubDate>Thu, 21 Nov 2024 17:09:35 GMT</pubDate>
    </item>
    <item>
      <title>根据可用性对最佳产品进行排名</title>
      <link>https://stats.stackexchange.com/questions/657627/ranking-the-best-products-based-on-availability</link>
      <description><![CDATA[假设我有一个典型的销售数据集，其中每个订单号占一行，每个订单中都有单独的产品。有了这个数据集，我被要求推荐一款新产品。
我最初的方法是根据销售量找到最畅销的产品。然后确定最受欢迎产品的共同属性是什么，并根据这些属性设计一些新产品。
看起来很简单，但我甚至不知道如何确定“最畅销”的产品。如果我简单地确定每件产品的总销售额并进行排序，我觉得我没有考虑到一些产品在更多商店或比其他产品有更长的可用时间这一事实。
我想知道有什么更好的方法/指标来考虑产品的“可用性”。我是否应该通过将销售单位数除以零售商数量和/或可用天数来标准化？]]></description>
      <guid>https://stats.stackexchange.com/questions/657627/ranking-the-best-products-based-on-availability</guid>
      <pubDate>Thu, 21 Nov 2024 16:23:54 GMT</pubDate>
    </item>
    <item>
      <title>使用威布尔分布模拟机器维护发生</title>
      <link>https://stats.stackexchange.com/questions/657626/simulating-machine-maintenance-occurrences-using-weibull-distributions</link>
      <description><![CDATA[我有一组机器，我正在尝试模拟这组机器的维护作业的发生。我有一个适合维护作业发生间隔时间的威布尔分布，对于每台机器，在模拟开始时，我知道距离该机器上一次发生维护作业有多长时间。我想知道的是，给定分布和自上次维护以来的初始时间，如何模拟接下来 $n$ 个时间步长的作业发生情况。我已经确定了几种方法。
方法 1
生存函数 $S(t)$ 给出事件在 $t$ 时间之前未发生的概率。我想计算的是，假设已经过去 $t_0$ 天，机器在第二天需要维护的概率。即
$P(\text{明天维护}|t_{0} \text{自上次维护以来的天数})$。
因此，我想要计算
\begin{align}
P(\text{明天维护}|t_{0} \text{自上次维护以来的天数})=1-\frac{S(t_{0}+1)}{S(t_{0})}
\end{align&gt;
对于每台机器。为了将其纳入 $n$ 时间步长的模拟中，我计算了每台机器设置阈值的概率。然后我使用随机数生成器生成 0 到 1 之间的数字，如果数字低于阈值，则我说事件发生了。如果事件发生，则 $t_{0}$ 重置为 0。如果事件未发生，则我们说 $t_{0}=t_{0}+1$ 并重复计算。我们对所有 $n$ 个时间步执行此操作。
这是一种有效的方法吗？如果不是，我应该做哪些调整？通过计算概率并在每个时间戳使用随机数生成器，我是否人为地增加了说机器需要维护的机会，因为我实际上是多次“从袋子中抽取”，直到得到我想要的结果？
方法 2
我为每台机器的分布抽取随机的生命周期样本。如果该生命周期 $t^{\max}$ 位于模拟的时间范围内，即 $t_{0}+n$，那么我们可以说在 $t^{\max}-t_{0}$ 时该机器上发生了维护工作。我的直觉是这种方法不正确，因为它没有考虑到自每台机器上次维护以来的时间，并且它还不允许在一次模拟长度内对一台机器进行多次维护。
任何有关这些的帮助都将不胜感激。如果这不是正确的论坛，我深表歉意，任何指导都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657626/simulating-machine-maintenance-occurrences-using-weibull-distributions</guid>
      <pubDate>Thu, 21 Nov 2024 16:13:43 GMT</pubDate>
    </item>
    <item>
      <title>从 R 中的调整曲线包中汇集 50 个风险表 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/657625/pool-50-risk-tables-from-the-adjusted-curves-package-in-r</link>
      <description><![CDATA[使用 R 的 mice 包进行多重插补后，我得到了 50 个数据集，其中包含两种治疗的事件发生时间数据：药物 A 和 药物 B。我对每个数据集执行了 Cox 比例风险模型 coxph()，并使用了治疗权重的逆概率 (IPtW)，以检索风险比 (HR) 并进行生存分析（KM 曲线）。对于调整后的 KM 曲线，我使用 adjustedCurves R 包，并将 50 个 adjustedsurv() 对象中的每一个的数据 ($adj) 存储在一个列表中：
library(ggplot2)
library(MASS)
library(data.table)
library(adjustedCurves)
library(survival)
library(survminer)

# datasets 是一个包含 50 个插补数据集的列表 
for (i in 1:length(datasets)){
# 对于每个数据集，应用一个cox 比例风险模型
cox_list[[i]] &lt;- coxph(
formula = Surv(time_to_event, consequence) ~ treatment + as.factor(period) + score + age + sex,
data = datasets[[i]], 
weights = datasets[[i]]$sw, x=TRUE)

# 使用 adaptedCurve 包创建调整后的 KM 曲线：
adjsurv &lt;- adaptedsurv(data=datasets[[i]],
variable=&quot;treatment&quot;,
ev_time=&quot;time_to_event&quot;,
event=&quot;outcome&quot;,
method=&quot;direct&quot;,
consequence_model=cox_list[[i]],
conf_int=TRUE)

# 存储数据，以应用 Rubin 规则
cox_data[[i]] &lt;- adjsurv$adj
```
使用 Rubin 规则，我设法汇集数据并捕获每个数据集内的方差以及每个插补数据集之间的方差。从而成功创建了一个可用于 KM 曲线的数据表：
```R
#Rubin 规则用于计算每个时间点的 CI：
# 将 SE 转换为方差内
for (i in 1:length(datasets)){
cox_data[[i]]$w_var &lt;- cox_data[[i]]$se^2
}

# 将所有数据表合并为一个大型数据表，并使用 dplyr 执行 Rubin 规则步骤：
cox_data_comb &lt;- rbindlist(cox_data, idcol = &quot;source_id&quot;)

# 对于 50 个数据集...
result &lt;- cox_data_comb %&gt;%
group_by(group, time) %&gt;% # ...对于每个治疗的每个时间点...
mutate(b_var = var(surv)) %&gt;% # ...取 var平均 surv prob 以获取 50 个数据集之间的 var
mutate(t_var = w_var + (1 + 1/length(datasets)) * b_var) %&gt;% # ...并计算总方差
mutate(pooled_se = sqrt(t_var)) %&gt;% # 创建池化 SE
mutate(lower_bound = surv - z_value * pooled_se) %&gt;% # ...和池化下限 CI
mutate(upper_bound = surv + z_value * pooled_se) %&gt;% # ...和池化上限 CI
ungroup()

并使用 ggplot2 和 results 表在自定义 KM 曲线中绘制结果：
ggplot(result, aes(x = time, y = surv, color = as.factor(group), group = group)) +
geom_line(size = 1) + # 平均值线
# CI 带状图：
geom_ribbon(aes(ymin = lower_bound, ymax = upper_bound, fill = as.factor(group)),
alpha = 0.2, color = NA) + # CI 阴影区域
scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;), name = &quot;Treatment&quot;, labels=c(&#39;drug A&#39;, &#39;drug B&#39;)) + # 自定义颜色
scale_fill_manual(values = c(&quot;blue&quot;, &quot;red&quot;), name = &quot;Treatment&quot;, labels=c(&#39;drug A&#39;, &#39;drug B&#39;)) +
labs(title = &quot;Probability of experience a first event&quot;,
x = &quot;时间（天）&quot;,
y = &quot;概率&quot;,
color = &quot;治疗&quot;,
fill = &quot;治疗&quot;) +
theme_minimal() +
theme(legend.position = &quot;top&quot;)

很可爱，不是吗？但是通常绘制在曲线下方的风险表怎么办？
我知道风险表隐藏在每个 adjustedsurv() 对象中，因为有可能在其后续函数 plot.adjustedsurv() 中绘制风险表，但我找不到它，也不知道如何将这 50 个图形风险表汇总到一个图形风险表中。
我还在考虑使用 data.table 自己创建 at_risk 表，通过计算时间概率t * 每个治疗组的大小（再次分层治疗）。gt 包在这里能帮上忙吗？我在 gt 中找不到任何有关风险表或宽格式纵向数据的内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/657625/pool-50-risk-tables-from-the-adjusted-curves-package-in-r</guid>
      <pubDate>Thu, 21 Nov 2024 16:05:08 GMT</pubDate>
    </item>
    <item>
      <title>在 SEM 模型中应用聚类稳健标准误差需要多少个聚类？</title>
      <link>https://stats.stackexchange.com/questions/657623/how-many-clusters-are-needed-for-applying-cluster-robust-standard-errors-in-a-se</link>
      <description><![CDATA[我正在研究一个 SEM 模型，该模型的数据来自 13 所学校（集群）的 1078 名学生。我想应用集群稳健标准误差，但我不确定 13 个集群是否足以让这种方法提供可靠的估计值。集群规模从每所学校 19 名学生到 165 名学生不等。
鉴于集群数量相对较少（13），我是否应该担心集群稳健标准误差的可靠性？]]></description>
      <guid>https://stats.stackexchange.com/questions/657623/how-many-clusters-are-needed-for-applying-cluster-robust-standard-errors-in-a-se</guid>
      <pubDate>Thu, 21 Nov 2024 15:46:12 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的 Se、Sp、NPV 和 PPV 问题</title>
      <link>https://stats.stackexchange.com/questions/657622/se-sp-npv-and-ppv-questions-for-repeated-measures-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657622/se-sp-npv-and-ppv-questions-for-repeated-measures-data</guid>
      <pubDate>Thu, 21 Nov 2024 15:41:33 GMT</pubDate>
    </item>
    <item>
      <title>检验的功效是否受重要性水平的下限限制？</title>
      <link>https://stats.stackexchange.com/questions/657621/is-power-of-a-test-lower-bounded-by-the-significance-level</link>
      <description><![CDATA[下面这个例子让我提出了这个问题。假设显著性水平为 $\alpha$。
假设我们有一个已知标准差的正态分布 $\sigma = 1$。
$H_0$：分布的均值为 0。
$H_1$：分布的均值为其他值。
我从分布中得到一个样本 x。
当 $H_1$ 为真时，此检验的功效是拒绝原假设的概率。让我们将 其他值 均值称为 $\mu_1$。在这种情况下，功率是根据标准正态分布$\phi$的 c.d.f 定义的：
$$1-\beta = 1 - (\phi(z_{\alpha/2} - \mu_1) - \phi(z_{-\alpha/2} - \mu_1))$$
通过将$\mu_1$移离 0，我们将一侧尾部区域与另一侧内部区域进行交换。因此，当 $\mu_1 = 0$ 时，上述方法可实现的最小值为 $\alpha$。
我的问题是，这是否也适用于其他示例？
另一种情况：
假设我们有一个形状未知的分布。让重要性水平为 5%。
$H_0$：分布为标准正态分布。
$H_1$：分布为 1 亚高斯分布，均值为零。
现在，假设我得到一个样本 $x=2$。根据定义，我们必须拒绝原假设。但是，$H_1$ 似乎更不可能。
在这里，测试的效力下限由 $\alpha$ 决定并不成立。但是，我觉得在设计这样的情况时，测试本身最终会定义不明确。也许这就像在得出 $1=2$ 结论的证明中发现错误一样。
还有其他（更好的？）例子吗？其中功效不受显着性水平的下限？
类似的问题在这里：如果零假设为假，类型 1 错误能否给出检验功效的下限
我觉得我已经深入研究了，所以我在这里发布了这个。]]></description>
      <guid>https://stats.stackexchange.com/questions/657621/is-power-of-a-test-lower-bounded-by-the-significance-level</guid>
      <pubDate>Thu, 21 Nov 2024 15:22:14 GMT</pubDate>
    </item>
    <item>
      <title>glmmTMB nbinom1 计算不正确？coef</title>
      <link>https://stats.stackexchange.com/questions/657620/glmmtmb-nbinom1-computing-incorrect-coef</link>
      <description><![CDATA[我有固定效应模型（无随机效应）葡萄糖 ~ 基因型，其中基因型是具有两个水平的因子。拟泊松和负二项式 GLM 应该估计相同的系数。但是，glmmTMB(nbinom1) 不会计算与 glm(quasipoisson)、glmTMBB(nbinom2) 或 glm.nb 匹配的模型系数。由于系数不同，估计的组边际均值也不同。这些在函数之间应该相同并且等同于样本均值，对吗？发生了什么？
library(data.table)
library(MASS)
library(glmmTMB)
fd &lt;- data.table(
genotype = rep(c(&quot;WT&quot;, &quot;KO&quot;), each = 8),
tumors = rnegbin(8*2, mu = rep(c(5, 10), each = 8), theta = 1)
)
qp1 &lt;- glm(tumors ~ genotype,
family = quasipoisson(link = &quot;log&quot;),
data = fd)
qp2 &lt;- glmmTMB(tumors ~ genotype,
family = nbinom1(link = &quot;log&quot;),
data = fd)
nb1 &lt;- glm.nb(tumors ~ genotype,
data = fd)
nb2 &lt;- glmmTMB(tumors ~ genotype,
family = nbinom2(link = &quot;log&quot;),
data = fd)
coef(summary(qp1))
coef(summary(qp2))$cond
coef(summary(nb1))
coef(summary(nb2))$cond

 估计标准误差 t 值 Pr(&gt;|t|)
(截距) 2.431418 0.2891563 8.408662 7.631869e-07
genotypeWT -1.215023 0.6044945 -2.009981 6.410986e-02
估计标准误差误差 z 值 Pr(&gt;|z|)
(截距) 2.3225197 0.3044603 7.628318 2.378361e-14
genotypeWT -0.8076885 0.4786590 -1.687399 9.152671e-02
估计标准误差 z 值 Pr(&gt;|z|)
(截距) 2.431418 0.3515361 6.916553 4.627644e-12
genotypeWT -1.215023 0.5226885 -2.324564 2.009530e-02
估计标准误差 z 值 Pr(&gt;|z|)
(截距) 2.431419 0.3515362 6.916554 4.627620e-12
genotypeWT -1.215022 0.5226886 -2.324563 2.009535e-02
]]></description>
      <guid>https://stats.stackexchange.com/questions/657620/glmmtmb-nbinom1-computing-incorrect-coef</guid>
      <pubDate>Thu, 21 Nov 2024 15:14:54 GMT</pubDate>
    </item>
    <item>
      <title>对于带有 cloglog 链接的二项式 GLMM，`predictInterval()` 和 `bootMer()` 估计的不确定性之间存在很大差异</title>
      <link>https://stats.stackexchange.com/questions/657619/major-discordance-between-uncertainties-estimated-by-predictinterval-and-bo</link>
      <description><![CDATA[我们一直在使用 merTools 包中的 predictInterval() 来引导二项式 GLMM 模型的不确定性（补充对数对数链接），这是分析印度鸟类丰度趋势的大型项目的一部分。（有关更多背景信息，请参阅此 方法预印本 或 我们的网站。）
由于我们的分析很复杂，数据集很大，我们选择 predictInterval() 而不是 bootMer() 来估计模型估计中的不确定性。然而，当我们尝试使用更新的数据重新运行今年的 2023 年分析时，我们意识到该函数现在给出了截然不同/出乎意料的不确定性估计值——与去年的值以及当前数据的 bootMer() 值相比，这很不寻常。差异相当“显著”，predictInterval() 给出的不确定性大了 10 倍（在 reprex 中为 0.058 vs 0.616）。对于我们的 2023 年分析，我们使用了 merTools 0.6.1，这次我们使用了 merTools 0.6.2。虽然我们无法从 merTools 版本历史中找到任何明显的罪魁祸首，但我们仍尝试使用 0.6.1 重新运行。有趣的是，这现在也产生了不寻常的 SE。
我们无法找出可能导致这种明显差异的原因。从我们目前的测试来看，我们的代码或数据中没有与此相关的内部变化。有趣的是，自举均值估计似乎完全不受影响，只是 SE 发生了变化。事实上，我们在另一个独立项目中也遇到了同样的问题，该项目也分析了 eBird 数据的鸟类数量趋势。
假设这与两个函数之间的统计方法差异有关，我们将在 CrossValidated 上发布此信息，但如果需要，我们很乐意将其移至 GitHub 问题或 StackOverflow。考虑到 bootMer() 根本不是我们用例的实用解决方案，我们将不胜感激任何帮助，并期待 predictInterval() 再次正常工作！
Reprex
此 GitHub 存储库 包含重现我们问题所需的一切，包括 reprex_pred_lwdu.RData 中的输入数据。脚本 soib_reprex.R 重现了我们的确切问题，只是使用了我们真实数据的较小子集（以便更快地计算）。sim_reprex.R 使用模拟数据集来运行类似的模型并比较引导估计值，但那里的差异并不比一般情况下预期的大。这可能是因为模拟不能很好地捕捉我们的数据特征。最后，test_versions.R 尝试使用 merTools 0.6.1 来检查这些估计值是否“正常” （但事实并非如此）。
系统规格
当前测试是在具有 16 GB RAM、8 个内核和 Intel i5 处理器的 Linux 系统上进行的，运行 R 4.4.2 和 RStudio 2024.09.0。在此系统上，predictInterval() 调用几乎每次都只需要一秒钟，而 bootMer() 调用（10 个模拟）需要大约 60 秒才能处理子集数据（100,000 行），而无需并行化。（但是，在运行各种 Windows 操作系统配置的多台机器上出现了差异。）]]></description>
      <guid>https://stats.stackexchange.com/questions/657619/major-discordance-between-uncertainties-estimated-by-predictinterval-and-bo</guid>
      <pubDate>Thu, 21 Nov 2024 15:12:08 GMT</pubDate>
    </item>
    <item>
      <title>从逻辑回归中获取 NAN p 值！</title>
      <link>https://stats.stackexchange.com/questions/657618/getting-nan-p-value-from-logistic-regression</link>
      <description><![CDATA[我尝试使用 MATLAB fitglm 函数查找逻辑回归系数的 p 值，但一直得到 NAN 值。我怀疑这是由 logit 函数的 INF 输出引起的。因此，我将响应值从 0 和 1 修改为 0.01 和 0.99，但这没有用。
接下来，我尝试手动计算 logit 并应用简单线性回归，但我不确定要使用哪种分布。我尝试了二项分布，但仍然返回 NAN p 值。我还尝试了返回有限值的正态分布，但似乎不正确！
那么我该如何处理这个问题？
我有大约 290 个样本，其中我保留了 40 个样本用于验证，因此剩下 250 个样本用于训练。这些特征由从 EEG 信号中提取的各种特征组成，有两个类别的概率几乎相同（0.4 和 0.6）。
mdl = fitglm(features, response, &#39;link&#39;, &#39;logit&#39;, 
&#39;Distribution&#39;, &#39;binomial&#39;, &#39;CategoricalVars&#39;, 
CategoricalVars);

估计系数：
                            
                   __________ ________ __________ ______

                     估计 SE tStat pValue              
    （截距）1.8993 2.3721 0.80067 NaN  
    x1 -2.197 0.73318 -2.9966 南  
    x2 -1.3026 0.94587 -1.3771 南  
    x3 -0.20243 0.96988 -0.20872 南  
    x4 0.35804 0.86712 0.41291 南  
    x5 -0.29205 0.67105 -0.43521 南  
    x6 1.5936 1.0911 1.4605 南  
    x7 -1.2516 0.66291 -1.888 南  
    x8 -1.1029 1.0365 -1.0641 南  
    x9 3.9931 0.7776 5.1352 南  
    x10 -0.0062073 0.91793 -0.0067622 南  
    x11 0.15274 0.7048 0.21671 南  
    x12 -0.28497 0.97436 -0.29247 南  
    x13 1.6847 0.95336 1.7671 南  
    x14 4.7506 1.1674 4.0692 南  
    x15 0.61685      1.0558 0.58426 南  
    x16 -0.91512 1.0008 -0.91437 南  
    x17 -0.9848 1.0112 -0.97391 南  
    x18 -2.1549 1.0969 -1.9644 南  
    x19 -1.5119 1.0367 -1.4583 南  
    x20 -1.0072 0.69128 -1.457 南  
    x21 -3.0984 0.76139 -4.0695 南  
    x22 -0.25906 0.99083 -0.26146 南  
    x23 0.47229 0.9586       0.49268 南  
    x24 0.91123 0.92178 0.98856 南  
    x25 0.10853 0.99246 0.10936 南  
    x26 -3.1111 1.0167 -3.0602 南  
    x27 0.096781 1.1659 0.083013 南  
    x28 -0.21485 0.68659 -0.31292 南  
    x29 -0.040434 0.015808 -2.5579 南  
    x30 -0.033061 0.016251 -2.0344 南  
    x31_1 0.092989     0.32625 0.28502 南  
]]></description>
      <guid>https://stats.stackexchange.com/questions/657618/getting-nan-p-value-from-logistic-regression</guid>
      <pubDate>Thu, 21 Nov 2024 15:09:11 GMT</pubDate>
    </item>
    <item>
      <title>为我的数据寻找分布时遇到问题（glmm）</title>
      <link>https://stats.stackexchange.com/questions/657616/problem-finding-a-distribution-for-my-data-glmm</link>
      <description><![CDATA[我想对两个变量进行相关性分析，范围从 0 到 1（包括这些值），并包括其他可能的环境解释变量。
我选择了混合模型，因为我的数据是分层的（按采集数据的区域）。问题是，当我运行模型并分析残差时，我发现它们远非正常（漏斗形状）。我一直在思考如何解决这个问题，但我陷入困境：我的数据是从 0 到 1 的小数，所以泊松分布不太好，我知道二项式也不适用于这种情况。我被伽马分布说服了，但问题是我必须牺牲我的 0 值数据，而这些数据非常有用，有什么解决方案呢？
顺便说一句，我的数据（如果有帮助的话）是一个指数，它是将一个地块中的物种数量除以该地区所有地块中发现的物种总数而得出的，可以说是一个非常简单的生物多样性指数。
非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/657616/problem-finding-a-distribution-for-my-data-glmm</guid>
      <pubDate>Thu, 21 Nov 2024 14:31:19 GMT</pubDate>
    </item>
    <item>
      <title>利用状态-动作边际推导 REINFORCE 算法</title>
      <link>https://stats.stackexchange.com/questions/657601/deriving-reinforce-algorithm-with-state-action-marginals</link>
      <description><![CDATA[（相关问题在这里：在强化学习中推导“状态-动作边际”）
CS 285（伯克利）讲座https://www.youtube.com/watch?v=GKoKNYaBvM0&amp;list=PL_iWQOsE6TfVYGEGiAOMaOzzv41Jfm_Ps&amp;index=15 (3:31) 告诉我们以下两个目标是等价的：
$$
\arg\max_{\theta} J(\theta) = E_{\tau \sim p_\theta(\tau)}\Big[\sum_{t}r(s_t,a_t)\Big]
$$
and
$$
\arg\max_{\theta} J(\theta) = E_{(s_t,a_t) \sim p(s_t,a_t)}r(s_t, a_t)
$$
如果我们从公式 1 开始
$$
\arg\max_{\theta} J(\theta) = E_{\tau \sim p_\theta(\tau)}\Big[\sum_{t}r(s_t,a_t)\Big]
$$
通过一些推导 + 似然比技巧，我们得到了 REINFORCE 算法，其更新规则如下，如讲义所示：
$$
\nabla_\theta J \propto \frac{1}{N}\sum_{i=1}^N \Big(\sum_{t=1}^T\nabla_\theta \pi(a_{i,t} |s_{i,t}) \Big) \Big(\sum_{t=1}^T r(s_{i,t}, a_{i,t})\Big)
$$
其中 $N$ 是轨迹的数量。让我感到困惑的是，此更新的第二项要求我们将每个采样轨迹从 t = 1 到 T 的所有奖励相加。但是如果我们从
$$
\arg\max_{\theta} J(\theta) = E_{(s_t,a_t) \sim p(s_t,a_t)}r(s_t, a_t)
$$
在我看来，最终的更新规则将是这样的：
$$
\nabla_\theta J \propto \frac{1}{N}\sum_{i=1}^N \Big(\sum_{t=1}^T\nabla_\theta \pi(a_{i,t} |s_{i,t}) r(s_{i,t}, a_{i,t}) \Big)
$$
因为期望和奖励与特定的时间步骤有关。但如果两个目标如讲座所示是等价的，我们应该得出相同的更新规则。
有人能告诉我我遗漏了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657601/deriving-reinforce-algorithm-with-state-action-marginals</guid>
      <pubDate>Thu, 21 Nov 2024 06:05:55 GMT</pubDate>
    </item>
    <item>
      <title>显示模型对于具有非中心 $\chi^2$ 分布的 MLE 是可识别的（可估计的）</title>
      <link>https://stats.stackexchange.com/questions/657594/show-model-is-identifiable-estimatable-for-mle-with-non-central-chi2-distr</link>
      <description><![CDATA[我正在尝试做一些 MLE 工作，但我的统计学背景非常有限，所以我正在学习。

定义。让 $\mathcal{P} = \{ P_\boldsymbol{\rho} : \boldsymbol{\rho}\in \Theta \}$
成为具有参数空间 $\Theta$ 的统计模型。如果映射 $\rho \mapsto P_{\boldsymbol{\rho}}$ 是一对一的，即对于所有 $\boldsymbol{\rho}_1, \boldsymbol{\rho}_2 \in \Theta$，$P_{\rho_1} = P_{\boldsymbol{\rho}_2} \Rightarrow \boldsymbol{\rho}_1= \boldsymbol{\rho}_2$，则我们说 $\mathcal{P}$ 是可识别的。
我的分布由缩放的非中心 $\chi^2$ 分布，自由度为 $d$，非中心参数为 $\lambda$，参数为 $\boldsymbol{\rho}=(\kappa, \theta,\sigma)$，其中 $$
d=4 \kappa \theta / \sigma^{2} ; \quad n(t, T)=\frac{4 \kappa e^{-\kappa(T-t)}}{\sigma^{2}\left(1-e^{-\kappa(T-t)}\right)}, \quad \lambda=r_t \cdot n(t, T), \quad T&gt;t
$$
换句话说，在$r_t, r_T$的条件下，其分布为$e^{-\kappa(T-t)} / n(t, T)$乘以非中心卡方分布，其自由度为$d$，非中心参数为$\lambda$。即，
$$
\operatorname{Pr}(r_T&lt;x \mid r_t)=F_{\chi^{\prime 2}}\left(\frac{x \cdot n(t, T)}{e^{-\kappa(T-t)}} ; d, r_t \cdot n(t, T)\right) .
$$
问题：上述统计模型是否可识别？即映射
$$
\boldsymbol{\rho}\mapsto P_\boldsymbol{\rho},
$$
是一一对应的。一般来说，我们如何证明这样的性质？我发现对于一些较简单的模型，通过反例证明它们不是一一对应的是相当容易的。例如，上述模型的渐近分布。
编辑：它们仅通过 DF 和 NCP 进行参数化。我应该提到，我曾尝试通过数值检验来解决这个问题，但似乎无法找到解决方案，但这不够严格。]]></description>
      <guid>https://stats.stackexchange.com/questions/657594/show-model-is-identifiable-estimatable-for-mle-with-non-central-chi2-distr</guid>
      <pubDate>Wed, 20 Nov 2024 18:28:39 GMT</pubDate>
    </item>
    <item>
      <title>如何从回归模型中消除由于共线性和多重共线性（线性、泊松和负二项式）引起的变量</title>
      <link>https://stats.stackexchange.com/questions/657561/how-to-eliminate-variables-from-regression-models-due-to-collinearity-and-multic</link>
      <description><![CDATA[由于相关性值较高，我试图从回归模型（线性、泊松和负二项式）中消除变量。R 代码如下
pairs.panels(a12, cex.cor = 4, cex.labels = 4, cex.axis = 2, method = &quot;pearson&quot;)
pairs.panels(a12, cex.cor = 4, cex.labels = 4, cex.axis = 2, method = &quot;spearman&quot;)
pairs.panels(a12, cex.cor = 4, cex.labels = 4, cex.axis = 2, method = &quot;Kendall&quot;) 

因为我的变量值不遵循正态分布，所以我主要考虑 Spearman 方法中的值。我看到一个值高于 0.7（例如 0.77），还有一些值高于 0.6。
我不确定我对消除变量的方法的想法是否正确。
我会的

我将删除与我的目标变量（响应、因变量）具有较低相关值的变量（两个相关变量之间）
我使用 AIC 和 BIC 来查找具有最佳值的模型（最低 AIC、BIC）
我应用 LASSO、贝叶斯模型平均（BMA 包）、统计等效签名（SES、MXM 包）
我还在这里找到了一个有趣的信息：https://www.statalist.org/forums/forum/general-stata-discussion/general/650016-decide-which-variables-to-be-omitted-in-ols-regression

感谢读者的评论，我想从我的模型中添加更多信息：

结果值的类型：我确实计算了数据回归，因此预期结果是 0、1、2、3、........
我的模型总共有 104 个观测值
我的模型有 1 个目标变量和 6 个预测因子（独立变量）
我使用该模型根据人口、面积等检查病房内出现的设施数量之间的因果关系，并做出预测。
我认为我应该消除我的变量，因为我的模型中两个变量之间存在一些较高的相关值（0.6 到 0.8）。我读过一些文献，说这会影响模型系数的精度和系数的标准误差。
我检查了所有变量的 VIF（使用 car 包进行线性回归），所有值都低于 5

您有什么参考或意见给我吗？我不确定上述这些方法]]></description>
      <guid>https://stats.stackexchange.com/questions/657561/how-to-eliminate-variables-from-regression-models-due-to-collinearity-and-multic</guid>
      <pubDate>Wed, 20 Nov 2024 14:11:19 GMT</pubDate>
    </item>
    </channel>
</rss>