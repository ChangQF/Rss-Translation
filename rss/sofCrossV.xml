<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 17 Dec 2024 09:19:31 GMT</lastBuildDate>
    <item>
      <title>控制多重比较</title>
      <link>https://stats.stackexchange.com/questions/658859/control-for-multiple-comparisons</link>
      <description><![CDATA[我想选择一组特定于学生和性别的单词。因此，我让参与者根据学生喜欢程度和女性喜欢程度对单词进行评分。每个单词都是成对的（一个特定单词和一个控制单词；例如，女性和编织）。对于每个单词，我都有 2 个评分（学生喜欢和性别喜欢），每对有 4 个评分。我总共有 100 对，其中一半有特定性别的单词，一半​​有特定的学生单词。
我知道想要测试特定单词是否特定于其自己的类别，而不是其他类别（例如，比较所有对的评分）。我已经运行了 LME 和 Anova，并得到了预期的效果，即学生单词在学生属性上被评为更高。但是，我想选择评分最高的 30 个特定单词及其配对词，但要确保它们只针对自己的类别（女性应该针对性别类别，但在学生气和女性气方面评分明显低于编织词。此外，编织词和女性应该同样像学生，因为它们应该在不感兴趣的类别中作为对照）。我显然可以运行多个配对 t 检验。你会怎么做？
最好！]]></description>
      <guid>https://stats.stackexchange.com/questions/658859/control-for-multiple-comparisons</guid>
      <pubDate>Tue, 17 Dec 2024 08:39:11 GMT</pubDate>
    </item>
    <item>
      <title>如何从混合模型中获取总体方差？</title>
      <link>https://stats.stackexchange.com/questions/658855/how-can-i-get-the-population-variance-from-a-mixed-model</link>
      <description><![CDATA[我以为这是一个基本问题，但我被它难住了，找不到解决方案。
我有一个数据库，其中包含不同养猪生产阶段（类别）的粪浆干物质含量，并且由不同的操作员（OP）在不同时刻（季节）采集样本。我只是对估计每个类别的平均值和方差总体感兴趣。
为了解决这个问题，我建立了一个线性混合模型，其中对因变量进行了平方变换。在测试了它们的重要性（AIC、BIC）后，我将 OP 纳入随机效应，将 CATEGORY 和 SEASON 纳入固定效应。
fit &lt;- nlme::lme(sqrt(MS) ~ CATEGORY + SEASON, 
random= ~ 1|OP, data=dat)

据我了解，每个 CATEGORY 中的估计平均值是每个固定效应值对应的 LSM。但是我不太清楚如何估计每个类别的方差。简化一下，我读到过，在一般线性回归中，模型的均方误差用于估计总体的方差，但在混合模型中，对于一些分组变量，我找不到任何关于如何计算它的解释。
每个固定效应的标准误差是否等同于 MSE？
summary(fit)

固定效应：sqrt(MS) ~ CATEGORY + SEASON 
值 标准误差 DF t 值 p 值
（截距） 2.0142552 0.1127073 197 17.871557 0.0000
CATEGORYpiglets -0.2367893 0.1400533 197 -1.690708 0.0925
CATEGORYsows -0.8191891 0.1195440 197 -6.852615 0.0000
SEASONspring -0.0280369 0.02811633 194 -0.997177 0.3199
SEASONsummer -0.0126275 0.03969934 194 -0.318078 0.7508
SEASONoutom -0.0884407 0.02879816 194 -3.071054 0.0024

我的最终目标是估算覆盖 75% 人口的干物质含量值。您能帮我解决这个疑问吗？如果它有用，我正在使用 R 中的 nlme 包。]]></description>
      <guid>https://stats.stackexchange.com/questions/658855/how-can-i-get-the-population-variance-from-a-mixed-model</guid>
      <pubDate>Tue, 17 Dec 2024 06:54:51 GMT</pubDate>
    </item>
    <item>
      <title>计算 GLM 的边际效应方差</title>
      <link>https://stats.stackexchange.com/questions/658853/calculating-the-variance-of-marginal-effects-for-a-glm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658853/calculating-the-variance-of-marginal-effects-for-a-glm</guid>
      <pubDate>Tue, 17 Dec 2024 04:21:32 GMT</pubDate>
    </item>
    <item>
      <title>如何找到跨多天的时间序列中变量之间的相关性？</title>
      <link>https://stats.stackexchange.com/questions/658852/how-do-i-find-correlation-between-variables-in-a-time-series-across-multiple-day</link>
      <description><![CDATA[我有每天的数据，包括日期/时间、事件以及触发次要事件的时间。
日期 | 时间 | 事件 | 触发次要事件
2019 年 9 月 9 日 | 上午 12:00 | A | 否
2019 年 9 月 9 日 | 上午 12:30 | A | 否
2019 年 9 月 9 日 | 上午 01:00 | | 否
2019 年 9 月 9 日 | 上午 01:30 | B | 否
...
2019 年 9 月 9 日 | 下午 03:00 | E | 否
2019 年 9 月 9 日 | 下午 03:30 | | 否
2019 年 9 月 9 日 | 下午 04:00 | | 是
2019 年 9 月 9 日 | 晚上 11:30 | C |是
2019 年 9 月 10 日 | 上午 12:00 | D | 否
2019 年 9 月 10 日 | 上午 12:30 | D | 否
...

每一天都是完全相互隔离的，我确信一天内没有任何事情会导致另一天触发次要事件 - 因此我们可以假设存在的任何相关性都是在一天内隔离的。
鉴于这些数据有多个“块”，每个月的每一天一个，持续数月 - 可以进行哪种分析才能更好地了解哪些事件更可能与触发次要事件有关？
我首先查看了时间序列的互相关，使用正常相关性，但将最后一列的数据移动 X 时间量，以查看哪个时间滞后量可以获得最佳相关性。
但让我困惑的是我发布这篇文章的原因是因为我的时间序列并不完全连续。它们是离散的时间序列数据块。所以在这种情况下我不确定该怎么做。]]></description>
      <guid>https://stats.stackexchange.com/questions/658852/how-do-i-find-correlation-between-variables-in-a-time-series-across-multiple-day</guid>
      <pubDate>Tue, 17 Dec 2024 03:23:25 GMT</pubDate>
    </item>
    <item>
      <title>适合还是不适合：在模型与平均值之间进行选择</title>
      <link>https://stats.stackexchange.com/questions/658851/to-fit-or-not-to-fit-choosing-between-a-model-vs-the-average</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658851/to-fit-or-not-to-fit-choosing-between-a-model-vs-the-average</guid>
      <pubDate>Tue, 17 Dec 2024 02:43:46 GMT</pubDate>
    </item>
    <item>
      <title>卡方检验残差与 Fisher 精确检验</title>
      <link>https://stats.stackexchange.com/questions/658850/chi-square-test-residuals-vs-fishers-exact-test</link>
      <description><![CDATA[我正在对具有两个分类变量的数据运行卡方检验，并且对获取 Fisher 精确检验与卡方检验的标准化残差有一个疑问，以便能够确定表中哪些单元格驱动（或不驱动）两个变量之间的关联。
Fisher 精确检验中如何获得标准化残差，这与卡方检验有何不同？
您可以运行哪些类型的 Fisher 精确检验的事后测试来获取标准化残差和 p 值？]]></description>
      <guid>https://stats.stackexchange.com/questions/658850/chi-square-test-residuals-vs-fishers-exact-test</guid>
      <pubDate>Tue, 17 Dec 2024 02:42:11 GMT</pubDate>
    </item>
    <item>
      <title>结构方程模型：semPaths 图表、布局</title>
      <link>https://stats.stackexchange.com/questions/658846/structural-equation-modeling-sempaths-charts-layout</link>
      <description><![CDATA[我有一个 SEM 模型，其中包含指示变量，其中一些指示变量与两个潜在变量相连。由于变量、潜在构造和高阶因子众多，内置布局：tree、tree2、circle、circle2、spring 无法产生可接受且可读的结果。
semptools 包提供了一个函数 (set_sem_layout()) 来设置布局 (https://cran.r-project.org/web/packages/semptools/vignettes/quick_start_sem.html)，但 indicator_factor 矩阵（必需参数）似乎要求每个指示变量只有一个因子。
如果指示变量与更多因子相连，如何定义自定义布局？我用一个简单的例子来说明下面的问题：
fit_struct &lt;- sem(&#39;f1 =~ NA*x1 + x2 + x3
f2 =~ NA*x3 + x4 + x5

#variance standardization
f1~~ 1*f1
f2~~ 1*f2

#regression 
y ~ f1 + f2&#39;, data=df_struct_reg)
sem_o &lt;- summary(fit_struct, unified=TRUE, fit.measures=TRUE)

p &lt;- semPaths(fit_struct, whatLabels=&quot;est&quot;,
sizeMan = 5.25,
node.width = 1,
edge.label.cex = .75,
style = &quot;LISREL&quot;,
mar = c(5, 4, 4, 4),
layout = &quot;tree&quot;,
width = 12，高度 = 15)

# 查看节点标签、顺序
semPaths(fit_struct, 截距 = F，nodeLabels = 1:6)

我想要一个布局，其中 x3 连接到 f1 和 f2。我可以指定指标顺序，因子布局也是如此。如何定义将 x3 分配给 f1 和 f2 的 indicator_factor 矩阵？]]></description>
      <guid>https://stats.stackexchange.com/questions/658846/structural-equation-modeling-sempaths-charts-layout</guid>
      <pubDate>Mon, 16 Dec 2024 22:20:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么推荐系统的 UV 矩阵分解有效？</title>
      <link>https://stats.stackexchange.com/questions/658839/why-does-uv-matrix-factorization-for-recommender-systems-work</link>
      <description><![CDATA[在推荐系统研究中，一种方法是进行 UV 矩阵分解。
$M&#39; = U\cdot V$
其中 $U$ 的列数等于 $V$ 的行数，而“$\cdot$”是矩阵乘积。
$M$ 有很多缺失值，我们最小化 $||M-M&#39;||$。
这里，我们使用 Frobenius 距离对 $M$ 的非缺失值进行计算。
我的理解是，这个想法是我们有效地将所有用户和项目投射到一个相对低维的空间中，例如二维空间。
然后我们使用点积作为相似度度量。
对我来说，它在这里分解：如果有人喜欢特征 A 而不喜欢特征 B，那么他们的偏好向量（在二维空间中）为 (5,1)。如果一个项目具有这些特征（或没有这些特征），那么我们的相似度为 $5^2+1^2=26$。但是，如果偏好向量为 (1,1)，且项目具有相同的特征 (1,1)，则相似度为 2。而如果两个向量为 (5,5) 和 (5,5)，则相似度为 50。但是，这意味着在成本函数 $||M-M&#39;||$ 中对这些因素考虑不足或过度。也就是说，(1,1) 对考虑不足，而 (5,5) 对考虑过多。
（顺便说一句：我看不出使用余弦相似度在这里会有什么太大的改善：使用它意味着 (1,1) 与 (1,1) 和 (5,5) 具有相同的相似性，这没有意义。）
我也读到它们是降维的，但我看不出这里降维到什么程度。
我的问题是：考虑到我写的问题，为什么推荐系统的 UV 矩阵分解有效。]]></description>
      <guid>https://stats.stackexchange.com/questions/658839/why-does-uv-matrix-factorization-for-recommender-systems-work</guid>
      <pubDate>Mon, 16 Dec 2024 21:43:08 GMT</pubDate>
    </item>
    <item>
      <title>在深度学习图像分割中：为 N 个类别训练 N 个模型是否比为 N 个类别训练一个模型更好</title>
      <link>https://stats.stackexchange.com/questions/658814/in-deep-learning-image-segmentation-is-it-better-to-train-n-models-for-n-class</link>
      <description><![CDATA[我想知道您是否有任何最近的出版物参考资料或关于深度学习图像分割中“为 N 个类别训练 N 个模型还是为 N 个类别训练一个模型更好”问题的经验？
我知道这取决于主干、数据类型等......但我找不到关于这个问题（所有对象都混淆）的任何最新、可靠和稳健（论文类型）的内容。
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658814/in-deep-learning-image-segmentation-is-it-better-to-train-n-models-for-n-class</guid>
      <pubDate>Mon, 16 Dec 2024 15:42:59 GMT</pubDate>
    </item>
    <item>
      <title>在回归模型中意外地两次包含同一个变量？</title>
      <link>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</link>
      <description><![CDATA[我在 R (mgcv) 中有这种混合效应 GAM 回归：
library(mgcv)
gam_beta &lt;- gam( 
y ~ te(time, x1) + te(time, x2) + s(time, by = city) + s(city, bs = &quot;re&quot;), 
data = my_data,
method = &quot;REML&quot;, 
family = betar(link = &quot;logit&quot;)
)

我尝试为该模型编写方程（基于我对 `mgcv te 的理解） noreferrer&quot;&gt;https://www.rdocumentation.org/packages/mgcv/versions/1.9-1/topics/te):
$$ y_{ij} \sim \text{Beta}(\mu_{ij}\phi, (1-\mu_{ij})\phi) $$
$$\mu_{ij} = \frac{1}{1+e^{-\eta_{ij}}}$$
$$ \text{logit}(\mu_{ij}) = \eta_{ij}= \beta_0 + f_{12}(time_{ij}, x1_{ij}) + f_{34}(time_{ij}, x2_{ij}) + h_i(time_{ij}) + b_i $$
我尝试将其进一步扩展：
$$ \eta_{ij} = \underbrace{\sum_{k=1}^{K_1} \hat{\gamma}_{1k}f_{1k}(time_{ij}) + \sum_{l=1}^{L_1} \hat{\gamma}_{2l}g_{1l}(x1_{ij}) + \sum_{k=1}^{K_1}\sum_{l=1}^{L_1} \hat{\gamma}_{3kl}f_{1k}(time_{ij})g_{1l}(x1_{ij})}_{\text{first te(): time and x1 term}} + $$
$$ \underbrace{\sum_{m=1}^{M_1} \hat{\gamma}_{4m}f_{2m}(time_{ij}) + \sum_{n=1}^{N_1} \hat{\gamma}_{5n}g_{2n}(x2_{ij}) + \sum_{m=1}^{M_2}\sum_{n=1}^{N_2} \hat{\gamma}_{6mn}f_{2m}(time_{ij})g_{2n}(x2_{ij})}_{\text{second te(): time and x2 term}} + $$
$$ \underbrace{\sum_{p=1}^P \hat{\alpha}_{ip}h_p(time_{ij})}_{\text{city-specific smooth}} + \underbrace{\hat{b}_i}_{\text{random effect}} $$
我的问题如下：我知道 mgcv 中的 te 函数既包含主效应，又包含交互效应（GAM 回归：交互作用与主效应？）。但这是否意味着某个术语存在被重复计算并在 GAM 方程中出现两次的风险？
例如，我有 te(time,x1) 和 te(time,x2)。这是因为我想在模型中包含时间与协变量 x1 和 x2 的相互作用。但这会导致时间的主效应被包含两次吗？或者 mgcv 会识别这一点并且只包含一次吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</guid>
      <pubDate>Mon, 16 Dec 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>数据分类</title>
      <link>https://stats.stackexchange.com/questions/658795/data-categorization</link>
      <description><![CDATA[我已将我的教育数据集分类以供以下分析。但是，我遇到过一位受访者就读于一所传教学校，我不知道其水平，也不确定将其归类到哪里。我应该将他们排除在外吗？我的决定基于什么依据？
教育 是 否 总计
高等教育 22 13 35
中学 144 47 191
小学 103 52 155
未受过教育 23 13 36
]]></description>
      <guid>https://stats.stackexchange.com/questions/658795/data-categorization</guid>
      <pubDate>Mon, 16 Dec 2024 06:47:39 GMT</pubDate>
    </item>
    <item>
      <title>需要有共同原因的因果调整公式</title>
      <link>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</link>
      <description><![CDATA[
在上述因果模型中，计算$P(X=x \mid \text{do}(Y=y))$时，是否需要使用因果调整公式$\sum_c P(X=x \mid Y=y, C=c) P(C=c)$？一旦我们$\text{do}(Y=y)$，$Y$的生成过程是否就独立于$X$的生成过程，因此$P(X=x \mid \text{do}(Y=y)) = P(X=x)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</guid>
      <pubDate>Mon, 16 Dec 2024 06:30:13 GMT</pubDate>
    </item>
    <item>
      <title>纳入因变量的下限是否可以改善估计？</title>
      <link>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</link>
      <description><![CDATA[假设我们抛硬币 $K$ 次，其中 如果正面，则为 $Z_k = 1$，否则为 0，并且 $Y = \sum_{k=1}^{K} Z_k$ 是正面的总数。假设这些是 i.i.d. 公平硬币，并且 $P(Z_k=1) = 0.5$。
然后我们重复此游戏 $n$ 次，每次抛 $K$ 枚硬币并观察实现 $Y_i$。目标是预测每场游戏中正面朝上的次数$\{Y_i : i=1,\dots, n\}$。

由于我们知道分布$Y \sim Binom(K, 0.5)$，标准/“朴素”方法就是简单的均值估计量：
$$ \hat{Y}_i = \mathbb{E}[Y] = 0.5K$$
这为$n$场游戏中的每一场提供恒定的预测。
现在问题如下。假设我们处于$i$场游戏。在 $K$ 次抛硬币之前，我们可以随时暂停游戏，优化模型，然后继续进行其余的抛硬币。我们能改进朴素估计器吗？
Oracle 估计器会设置 $\hat{Y}_i = Y_i$ 和 $MSE(Y_i, \hat{Y}_i) = 0$，但这在实践中显然是不可能的，因为我们实际上并不知道结果是什么。然而，每次抛硬币，我们都会收集更多关于 $Y_i$ 下限的信息。更准确地说，如果我们暂停翻转并观察到有$c_i$次正面，那么我们就知道
$$ Y_i \geq c_i $$
这就会激发&quot;增强&quot;估计量：
$$ \hat{Y}_i^{aug}(c_i) = \mathbb{E}[Y|Y\geq c_i] = \frac{ \int_{c_i}^{K} y \ dP_Y}{\int_{c_i}^{K} dP_Y} = \frac{\sum_{y=c_i}^{K} y P(Y=y)}{P(Y \geq c_i)}$$
其中，朴素估计量是$c_i = 0$的一个特例。将条件$\sigma$-代数的解释作为信息，我们获得了关于每个$Y_i$的一些额外信息，这应该可以让我们获得更好的预测。例如，假设$K=10$，我们在$c=6$次翻转后暂停游戏。朴素估计器将预测$\hat{Y}_i = 5$。但是我们已经知道 $Y_i \geq 6$，因此任何高于 6 的预测都会比朴素估计更接近真实的 $Y_i$。
有没有办法正式证明增强估计在某种意义上比朴素估计“更好”？

我用 $K=10$ 进行了数值模拟，得到了一些有趣的结果。这里的 x 轴是让 $c = pY$ 和 $p \in [0,1]$。随着 $c$ 的增加，我们获得更多的“部分知识”关于$Y$。直观上讲，我们拥有的信息越多，MSE 就越低，我们的预测就越好，但 U 形现象很有趣。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</guid>
      <pubDate>Sat, 14 Dec 2024 05:37:35 GMT</pubDate>
    </item>
    <item>
      <title>检查异常值随时间增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</link>
      <description><![CDATA[有人要求我测试多年来高异常值的数量和大小是否有所增加。目的是表明随着时间的推移（基数保持不变），极端情况越来越多，越来越高。
我有很多例子和年份、年龄组和性别之间的比较，但下面我只会展示一个。有两组数据，恰当地命名为 group1 (2022)，包含 207 个样本，group2 (2023)，包含 250 个样本。y 轴变量以整数测量。
首先，进行 t 检验，表明平均值有所下降。

绘制了箱线图来可视化这一点
应该注意的是，group2 有 9 个点高于 10（大约为 group 1 的上限），group2 有 10 个点约为 10（总共 12 个高异常值），其中第 2 组中的顶级异常值高于第 1 组中的异常值。所有异常值都经过严格检查，以确认它们是有效的数据点。

并且为了合理性，绘制了 var 随日期变化的散点图。红线表示箱线图的上限，其中任何高于该上限的点都被视为异常值。

这些表明平均值/中位数有所下降，但是有人要求我统计地确认 2023 年是否存在更多和更高的异常值，无论平均值的行为如何。我被要求在不同的性别、年龄和性别群体中展示这一点，在某些群体中比其他群体更明显。
我该如何进行统计测试？
[编辑：&#39;样本量&#39;，箱线图中没有平均值]]]></description>
      <guid>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</guid>
      <pubDate>Fri, 13 Dec 2024 06:09:28 GMT</pubDate>
    </item>
    <item>
      <title>如何在我的受污染数据问题中找到具有 ML 组件的去偏估计量？</title>
      <link>https://stats.stackexchange.com/questions/658578/how-to-find-a-de-biased-estimator-with-a-ml-component-in-my-contaminated-data-pr</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658578/how-to-find-a-de-biased-estimator-with-a-ml-component-in-my-contaminated-data-pr</guid>
      <pubDate>Wed, 11 Dec 2024 15:48:04 GMT</pubDate>
    </item>
    </channel>
</rss>