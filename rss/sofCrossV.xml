<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 09 Jul 2024 06:22:03 GMT</lastBuildDate>
    <item>
      <title>通过 TP、TN、FP 和 FN 值判断模型</title>
      <link>https://stats.stackexchange.com/questions/650709/judging-a-model-through-the-tp-tn-fp-and-fn-values</link>
      <description><![CDATA[我正在使用多个数据集评估一个模型，该模型可以预测某个“特征”是否存在（例如，“这张图片中有一只狗”）。系统会针对每个数据集输出 TP、TN、FP 和 FN。
我想要一个指标来判断模型的工作效果，但我意识到我无法仅绘制 TP，因为例如第一个数据集有 20 个具有特征（有一只狗）的实例，而第二个数据集只有 10 个。即使模型是完美的，第二个数据集也只有 10 个 TP。
我正在考虑计算每个数据集和所有数据集的准确率、精确率和召回率。
我也对每个数据集运行了三次模型，变化很小
我也在研究精确率-召回率曲线，但似乎这些是针对不同的阈值的，显然每个数据集只有一组精确率、召回率
有什么好方法可以判断模型是否“好”？由于我的经验不足，我无法提出一个好的判断标准
起初我想绘制所有数据集中每个（TP 等）的分布
然后我想绘制一个结合所有数据集的混淆矩阵
任何建议都将不胜感激

作为一个简单的虚构示例，我想到
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confused_matrix, precision_score, recall_score, f1_score, accuracy_score

# 示例虚构数据
datasets = {
&#39;datasetA&#39;: {&#39;TP&#39;: 150, &#39;TN&#39;: 200, &#39;FP&#39;: 50, &#39;FN&#39;: 100, &#39;no_GT&#39;: 34},
&#39;数据集B&#39;：{&#39;TP&#39;：180，&#39;TN&#39;：220，&#39;FP&#39;：40，&#39;FN&#39;：81，&#39;no_GT&#39;：20}，
&#39;数据集C&#39;：{&#39;TP&#39;：160，&#39;TN&#39;：240，&#39;FP&#39;：70，&#39;FN&#39;：110，&#39;no_GT&#39;：30}，
&#39;数据集D&#39;：{&#39;TP&#39;：190，&#39;TN&#39;：250，&#39;FP&#39;：60，&#39;FN&#39;：90，&#39;no_GT&#39;：42}，
}

def calculate_metrics（TP，TN，FP，FN）：
准确度 = (TP + TN) / (TP + TN + FP + FN)
精度 = TP / (TP + FP) if (TP + FP) &gt; 0 否则 0
召回率 = TP / (TP + FN) 如果 (TP + FN) &gt; 0 否则 0
f1 = 2 * (精确度 * 召回率) / (精确度 + 召回率) 如果 (精确度 + 召回率) &gt; 0 else 0

return {
&#39;Accuracy&#39;: 准确度，
&#39;Precision&#39;: 精度，
&#39;Recall&#39;: 召回率，
&#39;F1 分数&#39;: f1
}

# 聚合计数
total_TP = sum(data[&#39;TP&#39;] for data in datasets.values())
total_TN = sum(data[&#39;TN&#39;] for data in datasets.values())
total_FP = sum(data[&#39;FP&#39;] for data in datasets.values())
total_FN = sum(data[&#39;FN&#39;] for data in datasets.values())

# 计算总体指标
overall_metrics = calculate_metrics(total_TP, total_TN, total_FP, total_FN)

# 计算每个数据集的指标
metrics_df = pd.DataFrame({dataset: calculate_metrics(data[&#39;TP&#39;], data[&#39;TN&#39;], data[&#39;FP&#39;], data[&#39;FN&#39;]) for dataset, data in datasets.items()})

# 添加总体指标
metrics_df[&#39;Overall&#39;] = Overall_metrics

print(metrics_df)

# 可视化
fig, axis = plt.subplots(2, 2, figsize=(14, 10))
axes = axis.flatten()

for i, (dataset, data) in enumerate(datasets.items()):
cm = confused_matrix([1] * data[&#39;TP&#39;] + [0] * data[&#39;TN&#39;] + [1] * data[&#39;FN&#39;] + [0] * data[&#39;FP&#39;],
[1] * (data[&#39;TP&#39;] + data[&#39;FP&#39;]) + [0] * (data[&#39;TN&#39;] + data[&#39;FN&#39;]))
sns.heatmap(cm, annot=True, fmt=&#39;d&#39;, cmap=&#39;Blues&#39;, ax=axes[i])
axes[i].set_title(f&#39;混淆矩阵 - {dataset}&#39;)
axes[i].set_xlabel(&#39;预测&#39;)
axes[i].set_ylabel(&#39;True&#39;)

plt.tight_layout()
plt.show()

我得到了
 数据集A 数据集B 数据集C 数据集D 总体
准确率 0.700000 0.767754 0.689655 0.745763 0.725696
精确率 0.750000 0.818182 0.695652 0.760000 0.755556
召回率 0.600000 0.689655 0.592593 0.678571 0.640905
F1 分数 0.666667 0.748441 0.640000 0.716981 0.693524

和
]]></description>
      <guid>https://stats.stackexchange.com/questions/650709/judging-a-model-through-the-tp-tn-fp-and-fn-values</guid>
      <pubDate>Tue, 09 Jul 2024 05:43:39 GMT</pubDate>
    </item>
    <item>
      <title>我对产权欺诈统计数据的解读是否正确？</title>
      <link>https://stats.stackexchange.com/questions/650708/am-i-interpreting-title-fraud-statistics-correctly</link>
      <description><![CDATA[每年有 10,000 起产权欺诈案件。99% 的诉讼都是庭外和解。
这是否意味着每年有 100 万人的房屋被盗或 10,000 人？我倾向于更高的数字，因为任何拥有房屋的人的产权都会被盗，这很合理，这就是为什么人们有抵押贷款让银行拥有房产的原因。]]></description>
      <guid>https://stats.stackexchange.com/questions/650708/am-i-interpreting-title-fraud-statistics-correctly</guid>
      <pubDate>Tue, 09 Jul 2024 03:10:51 GMT</pubDate>
    </item>
    <item>
      <title>R 错误：'响应是恒定的' - GAMM</title>
      <link>https://stats.stackexchange.com/questions/650704/r-error-response-is-constant-gamm</link>
      <description><![CDATA[我正在尝试为企鹅创建一个物种分布模型，以评估不同环境变量对其分布的影响。
最初我计划使用 GLM，但在进一步阅读后，我决定使用 GAMM，因为它可以结合随机效应（例如，企鹅个体之间的差异）和分组结构（例如，岛屿之间的差异）。
我的响应变量是存在（1 = 存在，0 = 不存在）二项式。
但是，当我尝试拟合我的 GAMM 时，我得到：&quot;错误：响应为常数&quot;
我已检查我的数据中是否存在缺失数据/​​NA 值，并已将其删除。我还在表格 0 = 1000、1 = 328 中检查了我的响应变量的分布，（0/缺失值被提取为背景点，因为我的原始数据仅包含存在点）。
拟合我的模型：
gamm_model &lt;- gamm4(presence ~ s(bathy) + s(slope) + s(mean_chla), etc etc,
+ random = ~(1|Bird.ID), + family = binomial(link = &quot;logit&quot;), + data = data)

运行正常的 glm 可以正常工作，因此我认为我的数据中没有任何重大错误。
如能就此错误提供任何帮助，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/650704/r-error-response-is-constant-gamm</guid>
      <pubDate>Tue, 09 Jul 2024 02:10:17 GMT</pubDate>
    </item>
    <item>
      <title>跟随领袖，后悔不已</title>
      <link>https://stats.stackexchange.com/questions/650703/follow-the-leader-tight-bound-in-regret</link>
      <description><![CDATA[在 Follow The Leader (FTL) 的情况下，如果 $p_t$ 是我的预测变量，$x_t$ 是时间 t 时的目标点，并且 $x_t$ 属于单位球，即让 $S = \{x \in R^n \mid ||x||_2 \le 1\}$ 和 $x_t \in B$，则如何证明在线二次优化的紧密界限？]]></description>
      <guid>https://stats.stackexchange.com/questions/650703/follow-the-leader-tight-bound-in-regret</guid>
      <pubDate>Tue, 09 Jul 2024 00:47:22 GMT</pubDate>
    </item>
    <item>
      <title>贝塞尔修正的有效证明</title>
      <link>https://stats.stackexchange.com/questions/650702/efficient-proof-of-bessels-correction</link>
      <description><![CDATA[我刚刚开始学习统计学的基础知识，正在维基百科页面上阅读关于贝塞尔方差估计校正为何有效的证明。我理解了一切，除了以下计算的戏剧性简化（在此处重现）：

... 这里我们有（通过独立、对称抵消和平等分配）
$$... \mathbb{E} \Big[ \displaystyle\sum_{j=1}^n\sum_{l=1}^n (x_k - x_j)(x_k - x_l) \Big] = n(n-1)\mathbb{E}[X_1^2] - n(n-1)\mathbb{E}[X_1]^2$$

我不明白计算如何如此容易地进行。页面作者所说的“通过独立、对称抵消和平等分配”究竟是什么意思？]]></description>
      <guid>https://stats.stackexchange.com/questions/650702/efficient-proof-of-bessels-correction</guid>
      <pubDate>Tue, 09 Jul 2024 00:41:52 GMT</pubDate>
    </item>
    <item>
      <title>整合多名参与者的数据进行统计分析</title>
      <link>https://stats.stackexchange.com/questions/650700/combining-data-from-multiple-participants-for-statistical-analysis</link>
      <description><![CDATA[我的问题是：是否有任何统计技术允许将多个参与者的数据组合起来形成“宏观参与者”，以计算命中率或准确率等统计数据？这个想法是随机分组来自 3 或 4 名参与者的数据来计算这些统计数据，然后对它们进行假设检验。
查询背景：我正在开展一个涉及面部表情记忆任务的项目，该任务由两个阶段组成：

编码阶段：在此阶段，参与者会接触到 8 个虚拟角色，每个角色在 8 次试验中显示四种不同的面部表情（痛苦、愤怒、悲伤、中性）之一。
回忆阶段：此阶段包括 24 次试验，分为 8 次“旧”试验（参与者回忆以前见过的角色表情组合）和 16 次“新”试验。参与者的任务是确定他们之前是否见过特定的字符-表情组合。

统计挑战：
主要的挑战来自于每个参与者每个表情的试验次数有限，这限制了信号检测理论等传统统计方法的使用。
例如，“疼痛”表情的命中率计算仅依赖于两次试验。这是因为，在回忆阶段，在所有“旧”试验中，只有两个实例具有“疼痛”的表情并且与计算其命中率相关（8 个字符/4 个表情 = 每次出现 2 次）。结果命中率被限制为 0%、50% 或 100%。由于数据的非正态分布，如此受限的数值范围不适合进行典型的统计分析，如方差分析（比较所有四种面部表情的记忆）。
将数据组合起来形成宏观参与者是否可行？任何建议或见解都将不胜感激！
命中率 = 参与者正确识别为“旧”的“旧”或以前见过的项目的比例 = 命中次数 /“旧”项目的总数]]></description>
      <guid>https://stats.stackexchange.com/questions/650700/combining-data-from-multiple-participants-for-statistical-analysis</guid>
      <pubDate>Tue, 09 Jul 2024 00:32:17 GMT</pubDate>
    </item>
    <item>
      <title>无法从 shapley 值的全局热图中识别出重要特征</title>
      <link>https://stats.stackexchange.com/questions/650699/cannot-identify-important-feature-from-global-heatmap-of-shapley-value</link>
      <description><![CDATA[在我的例子中，每个实例有 166 个特征。我以 80:20 的比例分割训练和测试数据集，并训练了一个用于二元分类的 DNN 模型。模型架构如下：

现在对于测试数据，我使用 shap 库 来识别重要特征。我计算 shap 值的代码如下：
dnn_explainer = shap.DeepExplainer(model, X_train_shap.float().to(device)) 
shap_values_test = dnn_explainer.shap_values(X_test_shap.float().to(device))

现在我试图从局部和全局热图中可视化真正样本的重要特征。对于单个真正的阳性实例，我得到了这个热图：

从这个热图中，我看到大多数特征都很重要，因为它们是红色的，这些特征对模型向正方向的预测没有任何影响，因为它们的 shap 值为零。
我还使用以下代码绘制了全局热图：
import matplotlib.pyplot as plt
import seaborn as sns 

plt.figure(figsize=(10, 2)) 

sns.heatmap(shap_values_test_tp, cmap=&#39;coolwarm&#39;, cbar_kws={&#39;label&#39;: &#39;特征重要性值&#39;}) #, vmin=-1, vmax=1)
plt.title(&#39;TP 样本的局部分析&#39;, fontsize=10)
plt.show()

全局热图：
我获得了测试数据集所有真正例的全局热图，如下所示：

从这个热图中，我也无法在全球范围内识别任何重要特征。我正在尝试找出我在整个模型解释过程中的错误，但我无法找到它。
我读过题为使用分层相关性传播解释表格数据的深度学习模型的论文，并看到了它们的局部和全局热图，如下所示：

从这些热图中，我们可以轻松识别局部和全局重要特征。我想在我的模型解释中实现这一点。我在解释我的模型时是否遗漏了任何步骤？任何澄清或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650699/cannot-identify-important-feature-from-global-heatmap-of-shapley-value</guid>
      <pubDate>Mon, 08 Jul 2024 23:22:18 GMT</pubDate>
    </item>
    <item>
      <title>当正类相对稀少时，如何在不进行大量随机抽样的情况下估计准确率和召回率</title>
      <link>https://stats.stackexchange.com/questions/650695/how-to-estimate-precision-and-recall-without-taking-a-huge-random-sample-when-th</link>
      <description><![CDATA[我有一个二元文本分类模型，我想在一个包含 200 万个尚未注释的文本文档的新数据集上测试其在精确度和召回率方面的效果。鉴于我对这个新数据集的背景知识，我预计Positive 类文档相对较少。
我将模型应用于数据集，它预测该数据集中只有 0.5% 属于 Positive 类。现在我想知道，考虑到 Positive 类可能很少见，在不进行大量随机抽样的情况下，估计精确度和召回率的好方法是什么。对于精确度，我想，我可以从模型预测为 Positive 的文档部分中抽取样本，但我不确定如何估计召回率。]]></description>
      <guid>https://stats.stackexchange.com/questions/650695/how-to-estimate-precision-and-recall-without-taking-a-huge-random-sample-when-th</guid>
      <pubDate>Mon, 08 Jul 2024 22:33:37 GMT</pubDate>
    </item>
    <item>
      <title>贝塔随机变量的乘积与和的分布</title>
      <link>https://stats.stackexchange.com/questions/650663/distribution-of-product-and-sum-of-beta-random-variables</link>
      <description><![CDATA[我有一组概率，我将其建模为（独立的）$p_{A,i} \sim Beta(\alpha_{A,i},\beta_{A,i})$ 和 $p_{B,i} \sim Beta(\alpha_{B,i},\beta_{B,i})$。我正在计算以下乘积：
$$Y = \sum_{i=1}^N p_{A,i}^{n_{A}}(1-p_{B,i})^{n_{B}} + p_{B,i}^{n_{B}}(1-p_{A,i})^{n_{A}},$$
其中 $n_{A}$ 和 $n_{B}$ 为整数。我想推断（近似）$Y$ 的累积分布。由于 $Y$ 因支持值 $\gt 1$ 而出现偏差，我考虑将 Beta-Prime（或对数正态）密度分布拟合到 $Y$。这样对吗？您能否就 $Y$ 的真实分布或更好的近似值提供一些见解？
PD。如果之前有人问过类似的问题，请见谅。]]></description>
      <guid>https://stats.stackexchange.com/questions/650663/distribution-of-product-and-sum-of-beta-random-variables</guid>
      <pubDate>Mon, 08 Jul 2024 08:59:56 GMT</pubDate>
    </item>
    <item>
      <title>条件逻辑（离散 Cox PH）回归模型</title>
      <link>https://stats.stackexchange.com/questions/650662/conditional-logistic-discrete-cox-ph-regression-model</link>
      <description><![CDATA[我对椎间盘时间生存建模这个主题非常陌生。我从包 powerSurvEpi 中找到了 R 中的以下函数。似乎 powerConLogistic.bin 函数可用于 #二元协变量条件逻辑回归的样本量计算#，遵循 Lachin, JM 使用条件逻辑（离散 Cox PH）回归模型的分数检验对多重匹配病例对照研究进行样本量评估。 所以我想知道后续函数是否可以用于离散 Cox PH，因为我的理解是离散 Cox PH 和条件逻辑回归是不同的统计建模。
 powerConLogistic.bin(
N = NULL,
power = 0.8,
OR,
pE,
nD,
nH,
R2 = 0,
alpha = 0.05,
nTests = 1,
OR.low = 1.01,
OR.upp = 100
)
]]></description>
      <guid>https://stats.stackexchange.com/questions/650662/conditional-logistic-discrete-cox-ph-regression-model</guid>
      <pubDate>Mon, 08 Jul 2024 08:51:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 R STM 包分析评论评级-样本平衡问题</title>
      <link>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</link>
      <description><![CDATA[在考察主题占比差异时，由于在线评论评分呈正偏J型分布/评分分布不平衡，学者们倾向于平衡样本量，即随机选取正评分评论（即4分和5分评分），使其数量与负评分评论（即1分和2分评分）数量相等或相近。类似以下论文的做法：
论文1：酒店顾客抱怨什么？使用结构化主题模型进行文本分析
论文 2：毒品消费者的声音：使用结构化主题模型进行在线文本评论分析
除了研究主题比例（正面 vs. 负面）的差异（例如论文 1，图 2）之外，我还想使用线性回归研究主题和评分之间的关​​系。
一方面，如果我对主题比例的差异进行分析，似乎我必须删除一些评论才能实现样本平衡；另一方面，如果我只运行线性回归，则没有必要这样做。
在这种情况下，有什么解决方案可以不删除样本，同时解决样本不平衡的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</guid>
      <pubDate>Mon, 08 Jul 2024 08:17:13 GMT</pubDate>
    </item>
    <item>
      <title>关于测试可靠性对测试组合权重的影响的问题</title>
      <link>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</link>
      <description><![CDATA[最初，测试组件有 4 个部分：两个 100 项多项选择题测试、一个口语测试和一个论文测试。每个部分测量不同的主题。4 个部分中的每一个权重为 25%。
现在，每个多项选择题测试的测试长度已减少到 60 项（出于实际原因）。每个部分仍占 25%。
如果两个 MC 测试的可靠性降低到零，则两个 MC 测试测量的两个主题的权重将为零。（两个 MC 测试只会产生误差。）实际上，可靠性降低了，但并没有降低到零。
我的问题是，可靠性的变化对两个 MC 测试测量的两个主题的权重有何影响。我如何估计由于变化而导致的权重差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</guid>
      <pubDate>Fri, 05 Jul 2024 22:15:38 GMT</pubDate>
    </item>
    <item>
      <title>如何将贝叶斯模型拟合到 Beta 和 One-Zero 膨胀数据的混合中？</title>
      <link>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-and-one-zero-inflated-data</link>
      <description><![CDATA[我的数据非常嘈杂，我相信这是通过多个物理过程的相互作用而产生的。在映射 $Y = f(X),$ 中，$Y$ 是一个比率 $[0, 1]$ 和 $X \ge 0.$，而 $Y$ 是 $X,$ 的函数，它也可以取 $0$（更可能在较低的 $X$ 值时）或 $1$（更可能在较高的 $X$ 值时）。 $Y$ 是每个 $X$ 间隔的 Beta 和 Zero-One 膨胀过程的混合。
对于 $X$ 的选定间隔，$Y$ 的条件分布（即 $Y|X$ ）显示出与数据边际分布（如下所示）类似的模式。但是，$Y|X$ 的扩散在 $X$ 的较低值时更为明显，并且随着 $X$ 的增加而缓慢消失。
如何使用贝叶斯方法对此类过程进行建模？我是贝叶斯统计的新手，希望得到任何帮助。我能够拟合零一膨胀的 Beta 模型，但它无法捕捉到 $X$​ 值较低时 $Y$ 的高分布。
虽然数据的其他特征可以减少模型误差，尤其是在较高的 $X$ 时，但它们在大多数应用中通常是不可观察的。因此，我的目标是一个能够提供最佳映射的函数，以促进实际应用。
模拟真实数据的虚拟数据：
# 设置种子以实现可重复性
set.seed(123)

# 生成 x 值
x &lt;- seq(0, 20, length.out = 1000)

# 为 y 创建非线性函数
y &lt;- 0.15 + 0.005 * x^1.05 + 1 / (2.5 + 2532 * exp(-1.611 * x))

# 添加一些随机噪声
noise_factor &lt;- 0.03
# 使用 beta 噪声创建模型（此处使用正态分布创建）
noisy_y &lt;- rnorm(length(x), mean = 0, sd = noise_factor * sqrt(x))

y &lt;- y + noisy_y

# 向数据添加零个和一个噪声
noisy_indices &lt;- sample(1:length(x), round(0.2 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 1 / (1 + exp(x[i]))) {
y[i] &lt;- 1
} else {
y[i] &lt;- 0
}
}

# 添加指数分布
noisy_indices &lt;- sample(1:length(x), round(0.5 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 100 / (1 + exp(x[i]))) {
y[i] &lt;- rexp(1, rate =4)
} else {
y[i] &lt;- y[i]
}
}

# 创建数据框
数据 &lt;- data.frame(x = x, y = y) |&gt;
filter(y&lt;=1 &amp; y&gt;=0)

ggplot(data, 
aes(x, y)) +
geom_point() +
xlim(0, 20) + 
ylim(0, 1)

ggplot(data = data, 
aes(x=y))+
geom_histogram()

我正在尝试制定一个将 X 映射到 Y 的函数

整个数据集中 Y 的分布。在原始数据集中，从零（@Y=0）到指数部分（Y ~ 0-0.25）的过渡非常平滑。

我尝试（在原始数据上）在 brms 中使用零一膨胀 Beta 得出此后验预测：
]]></description>
      <guid>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-and-one-zero-inflated-data</guid>
      <pubDate>Fri, 05 Jul 2024 14:49:43 GMT</pubDate>
    </item>
    <item>
      <title>最可能结果的可能性有一个名称吗？</title>
      <link>https://stats.stackexchange.com/questions/650439/is-there-a-name-for-the-likelihood-of-the-most-likely-outcome</link>
      <description><![CDATA[在流行统计学中，我们通常会将最可能的结果描述为非常有意义的属性。
但是，如果不知道最可能的结果有多大的可能性，它实际上就没有那么大的意义。
例如，在四次抛硬币中，最可能的结果是一半正面，一半反面，
但实际得到该结果的可能性只有 37.5%；几乎三分之二的时间里，结果会是其他的。
硬币数量越多，最可能的结果就越不可能发生，但实现该结果的可能性就越接近于零。
也就是说，最可能发生的事情可能非常不可能。
这似乎是几乎从未被提及过的事情，但是这个最可能结果的（不）可能程度的概念有名字吗？
（对于预期值，可以提出类似的问题。）
澄清：
我对实际值本身不太感兴趣，但我对值可能被歪曲或误解的方式很感兴趣。
例如，如果我从一副牌中取出黑桃 A，我可以如实地说，随机抽一张牌最有可能的结果是红色。
或者我可以删除除黑桃之外的所有 A，并声称随机选择的最可能结果是黑桃。
这两个陈述都是准确的，但远没有听起来那么精确。
这些陈述的实际真实性、有用性、价值、价值等接近于零。
我正在寻找这种统计数据的术语，它听起来很重要，但几乎毫无意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/650439/is-there-a-name-for-the-likelihood-of-the-most-likely-outcome</guid>
      <pubDate>Thu, 04 Jul 2024 00:35:03 GMT</pubDate>
    </item>
    <item>
      <title>去聚类影响、平稳性和离散化</title>
      <link>https://stats.stackexchange.com/questions/649812/declustering-impact-stationarity-and-discretization</link>
      <description><![CDATA[我有一个季节性时间序列，我正在考虑使用运行去聚类对其进行去聚类（在任何其他预处理步骤之前）。如果我观察到极值指数为 1，我可以声称我的数据是 i.i.d.，因此是平稳的吗？这是否允许我避免事先使用非平稳方法？此外，我很好奇运行去聚类时间序列是否类似于离散化，因为我不确定我的去聚类分布是否仍然属于最大吸引域。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649812/declustering-impact-stationarity-and-discretization</guid>
      <pubDate>Mon, 24 Jun 2024 14:33:04 GMT</pubDate>
    </item>
    </channel>
</rss>