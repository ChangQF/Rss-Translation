<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 11 Feb 2025 15:19:45 GMT</lastBuildDate>
    <item>
      <title>匹配和 AIPW/倾向评分方法</title>
      <link>https://stats.stackexchange.com/questions/661229/matching-and-aipw-propensity-score-methods</link>
      <description><![CDATA[在运行基于倾向得分 (PS) 的匹配算法后，人们是否经常运行增强逆概率加权或双重稳健方法来估计治疗效果？就此而言，人们是否经常在通用匹配算法之后使用基于倾向得分的估计程序？
我的直觉告诉我，当使用基于 PS 的匹配算法时，人们会通过重新估计匹配样本的倾向得分而引起偏差，因此这似乎不是一个好主意。
Ho 等人的一篇论文 (https://gking.harvard.edu/files/matchp.pdf) 主张​​减少模型依赖性，因此在匹配后使用基于 PS 的估计方法可能并不常见。如果能听听其他人对此的看法就好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/661229/matching-and-aipw-propensity-score-methods</guid>
      <pubDate>Tue, 11 Feb 2025 15:04:38 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用卡方还是 Mcnemar</title>
      <link>https://stats.stackexchange.com/questions/661223/should-i-use-chi-squared-or-mcnemar</link>
      <description><![CDATA[我是一名博士生，不可否认，统计学是我的弱项。我正在制定一份提案，必须说明我将对假设数据进行什么测试。我计划看看注意力控制组和干预组之间是否存在差异。参与者将被随机分配到各个组中。每个参与者将进行基线评估。注意力控制组和干预组将参加关于该主题的相同教育。干预组将参加模拟以练习该技能。然后，每个参与者将进行事后评估。我想看看模拟组在干预后是否有更准确的评估结果。评估要么正确，要么不正确。我想比较干预前后两组之间的正确评估数量。我认为由于每个参与者都贡献了两个评估，这是配对数据，我应该进行 McNemars 检验。但是，我的第一稿有卡方，我正在重新考虑自己。我应该更改我提议进行的测试吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661223/should-i-use-chi-squared-or-mcnemar</guid>
      <pubDate>Tue, 11 Feb 2025 13:06:08 GMT</pubDate>
    </item>
    <item>
      <title>如何在 K 均值聚类中获取较小的最优 K 值</title>
      <link>https://stats.stackexchange.com/questions/661222/how-to-get-a-smaller-number-of-optimal-k-in-k-means-clustering</link>
      <description><![CDATA[我想在大小为 $5000$ 的数据集上进行 k 均值聚类，以获得 $k$ 的较小最优值（$k≤5$）。我已使用 BIC 和 Gap 统计量来确定最优聚类数，两种方法均表明最优 $k$ 为 $7$ 或更高。我想知道我是否可以进行调整（例如，通过将 $s(k+1)$ 乘以因子 $c&gt;1$ 或将其作为 BIC 中的惩罚项包括在内），以便获得较小的 $k$ 最佳值。
以下是我为计算 Gap 统计量和 BIC 而执行的计算：
BIC 计算
$$\text{BIC}=n\ln(\frac{W}{n})+m\ln(n)$$
其中 $W$ 是簇内总平方和，
$m$ 是模型中自由参数的数量，$n$ 是数据点的总数。
最优的 $k$ 是 BIC 值最小的那个。
差距统计
$$\text{Gap}(k)≥\text{Gap}(k+1)−s(k+1)$$
其中 $\text{Gap}(k)=\frac{1}{B}\sum_{b=1}^{B}\ln(W_{k} ^{∗(b)})−\ln(W_k)$。
这里 $W_k$ 是 k 个簇的簇内弥散度，$W_{k} ^{∗(b)}$ 是 $W_{k} ^{∗(b)}$ 是 k 个簇的簇内弥散度。 class=&quot;math-container&quot;&gt;$b^\text{th}$ 参考数据集（来自总共 $B$ 参考数据集）从无明显聚类的分布生成，用于 $k$ 个聚类。
如果我犯了任何错误，或者有其他方法可以获取较小的聚类数，或者我可以进行任何修改，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/661222/how-to-get-a-smaller-number-of-optimal-k-in-k-means-clustering</guid>
      <pubDate>Tue, 11 Feb 2025 12:53:35 GMT</pubDate>
    </item>
    <item>
      <title>loess() 与自滚黄土平滑器之间的差异[关闭]</title>
      <link>https://stats.stackexchange.com/questions/661221/discrepancy-between-loess-and-roll-your-own-loess-smoother</link>
      <description><![CDATA[为了更好地理解 R 的 loess() 的作用，我尝试根据 ?loess 上的描述编写自己的 LOESS 函数。它产生的结果与 loess() 获得的结果相似，但不完全相同。如果您能提供任何关于导致这些差异的见解，我将不胜感激。我认为这个问题对于 CV 来说很好，因为我的目标是更好地理解统计程序。
需要澄清的是，predict_loess() 代码实现了我所理解的

对于 $\alpha &lt; 的跨度1$，保留最接近 $x_*$ 值（我们想要评估 LOESS 平滑器的值）的 $\alpha$ 数据点的比例。在这些数据点上，我们拟合二次回归模型，使用三次加权，如 ?loess 中所述。然后使用该模型预测平滑器在 $x_*$ 处的值。
对于 $\alpha \geq 1$ 的跨度，所有数据点都包含在二次模型中。再次使用三次加权，但这次将$x_*$与输入$x$值之间的最大距离乘以$\alpha$。 （如 ?loess 中所述。）再次使用该模型预测平滑器在 $x_*$ 处的值。

# 自己动手编写 LOESS 函数
predict_loess &lt;- function(x_star, x, y, span) {
if (span &lt; 1) {
n &lt;- ceiling(length(x) * span)
max_dist &lt;- sort(abs(x - x_star))[n]
} else {
n &lt;- length(x)
max_dist &lt;- span * max(abs(x - x_star))
}
x_retained &lt;- x[abs(x - x_star) &lt;= max_dist]
y_retained &lt;- y[abs(x - x_star) &lt;= max_dist]
weights &lt;- (1 - (abs(x_retained - x_star)/max_dist)^3)^3
d &lt;- data.frame(x_retained, y_retained, weights)
mod.lm &lt;- lm(y_retained ~ poly(x_retained, 2), data = d, weights = weights)
predict(mod.lm, newdata = data.frame(x_retained = x_star))
}

三个示例表明 predict_loess() 获得的拟合与 loess() 获得的拟合相似但不完全相同：
# 示例 1
plot(mpg ~ disp, mtcars)
x_stars &lt;- seq(71, 472, 1)

mod.loess &lt;- loess(mpg ~ disp, mtcars, span = 1/2)
lines(x = x_stars, y = predict(mod.loess, newdata = data.frame(disp = x_stars)), col = &quot;blue&quot;)
predictions_loess &lt;- sapply(x_stars, predict_loess, x = mtcars$disp, y = mtcars$mpg, span = 1/2)
lines(x = x_stars, y = predictions_loess, col = &quot;red&quot;)


# 示例 2
plot(mpg ~ disp, mtcars)
mod.loess &lt;- loess(mpg ~ disp, mtcars, span = 3/4)
x_stars &lt;- seq(71, 472, 1)
lines(x = x_stars, y = predict(mod.loess, newdata = data.frame(disp = x_stars)), col = &quot;blue&quot;)
predictions_loess &lt;- sapply(x_stars, predict_loess, x = mtcars$disp, y = mtcars$mpg, span = 3/4)
lines(x = x_stars, y = predictions_loess, col = &quot;red&quot;)


# 示例 3
plot(mpg ~ disp, mtcars)
mod.loess &lt;- loess(mpg ~ disp, mtcars, span = 2)
x_stars &lt;- seq(71, 472, 1)
lines(x = x_stars, y = predict(mod.loess, newdata = data.frame(disp = x_stars)), col = &quot;blue&quot;)
predictions_loess &lt;- sapply(x_stars, predict_loess，x = mtcars$disp，y = mtcars$mpg，span = 2)
lines(x = x_stars，y = predictions_loess，col = &quot;red&quot;)

]]></description>
      <guid>https://stats.stackexchange.com/questions/661221/discrepancy-between-loess-and-roll-your-own-loess-smoother</guid>
      <pubDate>Tue, 11 Feb 2025 12:10:28 GMT</pubDate>
    </item>
    <item>
      <title>如何从数学上正确计算每个协变量对总模型概率预测的概率加法？</title>
      <link>https://stats.stackexchange.com/questions/661218/how-to-mathematically-properly-calculate-the-probabilistic-addition-of-each-cova</link>
      <description><![CDATA[抱歉，事先已注明。

y&#39; (P) = 1 / (1 + exp(-sum(betas times Xs))) 1

我想知道我的每个 x 对 P 贡献了多少 p，以便它们的总和恰好等于 P。
我的模型的参数是：
logreg_coefs = (139.8640, 11.3660, 61.3583, 115.9492, 237.9015, 38.8623, -3.5466)


假设我有协变量：
协变量 = (0.5, 0.3, 0.2, 0.1, 0, 0, 1)

如果我对各个协变量应用 1，我会得到奇怪的数字，例如，对于零协变量值，我得到 p = 1/2（期望得到它零...）。
我尝试对各个 ps 求和，然后取份额，但我得到的值 &gt; 0，其中我的协变量为零，因此 b*x 给出零。
稍后更新
我回想起了通过增加模型的阶数（从仅截距到完全协变量存在）来逐步改进模型的做法。考虑到这一点，我可以重现累积概率计算，并对概率值进行一步减差分。至少我现在看到的是更正确的值，并且具有完美的求和结果。
python 中的代码执行以下操作：
logreg_coefs = (139.8640, 11.3660, 61.3583, 115.9492, 237.9015, 38.8623, -3.5466)

exogs = (0, 0.02, 0.03, 0.004, 0.005, 0.006, 1)

exog_ps = []

bx = 0

for x, b in zip(reversed(exogs), reversed(logreg_coefs)):
bx += b * x
exog_ps.append(1 / (1 + np.exp(-bx)))

打印(exog_ps)

x_adds_p = []

exog_ps_reversed = list(reversed(exog_ps))

对于 i 在范围(len(exog_ps_reversed)-1)内：
x_adds_p.append(exog_ps_reversed[i] - exog_ps_reversed[i + 1])

x_adds_p.append(exog_ps[0])

打印(x_adds_p)

打印(sum(x_adds_p))

logreg_prob = 1 / (1 + np.exp(-1 * np.sum(np.array(exogs) * np.array(logreg_coefs))))

打印(logreg_prob)

打印(logreg_prob - sum(x_adds_p))

]]></description>
      <guid>https://stats.stackexchange.com/questions/661218/how-to-mathematically-properly-calculate-the-probabilistic-addition-of-each-cova</guid>
      <pubDate>Tue, 11 Feb 2025 09:59:05 GMT</pubDate>
    </item>
    <item>
      <title>当经验分布收敛时，NLL-交叉熵等价性对于独立数据成立吗？</title>
      <link>https://stats.stackexchange.com/questions/661216/does-the-nll-cross-entropy-equivalence-hold-for-independent-data-when-the-empiri</link>
      <description><![CDATA[在这个先前的问题中，我确定对于 IID 数据，负对数似然 (NLL) 相当于模型与经验分布之间的交叉熵。
对于独立数据（即使分布不同），也可以将联合似然分解为各个项。例如，如果数据点 (x_1, x_2, \dots, x_n) 独立于各自的密度 (p_i(x))，则联合似然由下式给出
$$
p(x_1, x_2, \dots, x_n) = \prod_{i=1}^n p_i(x_i),
$$
负对数似然变为
$$
-\log p(x_1, x_2, \dots, x_n) = -\sum_{i=1}^n \log p_i(x_i)。
$$
这种分解使我们能够将平均 NLL 直接与使用经验分布计算的交叉熵联系起来
$$
\hat{P}_n(x) = \frac{1}{n}\sum_{i=1}^{n}\delta(x - x_i)。
$$
相比之下，对于依赖数据，联合似然不会以如此直接的方式分解。相反，它必须使用条件密度来表达：
$$
p(x_1, x_2, \dots, x_n) = p(x_1) \prod_{i=2}^n p(x_i \mid x_1, \dots, x_{i-1}),
$$
这样 NLL 就变成
$$
-\log p(x_1, x_2, \dots, x_n) = -\log p(x_1) - \sum_{i=2}^n \log p(x_i \mid x_1, \dots, x_{i-1})。
$$
此处，依赖结构（条件项）阻止对经验分布进行简单平均以恢复模型和数据之间的交叉熵。
现在，假设数据是独立的（但不一定是相同分布的），并且经验分布收敛。这种收敛是否意味着平均 NLL 和交叉熵之间的等价性成立，就像在 IID 情况下一样？或者在处理独立但不相同的数据时是否还有其他微妙之处？
任何关于此主题的见解、参考或示例都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/661216/does-the-nll-cross-entropy-equivalence-hold-for-independent-data-when-the-empiri</guid>
      <pubDate>Tue, 11 Feb 2025 09:32:19 GMT</pubDate>
    </item>
    <item>
      <title>具有不确定性的泊松过程的中值预期上限</title>
      <link>https://stats.stackexchange.com/questions/661210/median-expected-upper-limit-for-a-poisson-process-with-uncertainties</link>
      <description><![CDATA[考虑在存在不确定的背景速率$b$的情况下确定过程信号速率$s$的上限的问题。背景速率受到另一个测量的限制，其中观察到$b_{obs}$个事件。然后，观察到$n_{obs}$个事件的总可能性由以下公式给出：
$$
L(s,b| n_{obs}, b_{obs}) = Pois(n_{obs}| s+b) \times Pois(b_{obs} | b)
$$
这里感兴趣的参数是$s$。我知道如何建立置信区间，或者对于这个问题更重要的是，使用各种频率学派技术和玩具蒙特卡罗实验来提取上限。现在我所苦苦挣扎的是如何计算“预期”中位数上限。几篇文章（我稍后会添加参考资料）只是说，应该在背景假设中执行“玩具 MC 实验”，将它们视为数据，然后从那里构建上限的分布。如何生成玩具？具体来说，$b$ 使用什么值？
任何帮助都将非常有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/661210/median-expected-upper-limit-for-a-poisson-process-with-uncertainties</guid>
      <pubDate>Tue, 11 Feb 2025 05:56:06 GMT</pubDate>
    </item>
    <item>
      <title>通过模拟进行对数秩检验的功效</title>
      <link>https://stats.stackexchange.com/questions/661209/power-of-logrank-test-through-simulation</link>
      <description><![CDATA[对数秩检验样本量公式由 Lachin 和 Foulkes (1986) 制定，题为“评估样本量和生存分析的功效，同时考虑患者入组不均匀、失访、不依从和分层”。我正在运行一个玩具模拟来查看公式的准确性。按照论文的符号，患者在 R 年的累积期内被招募，并被跟踪到研究结束 T 年。假设 R = 3、T =5、指数生存、均匀累积，并且在研究结束前没有其他审查，geDesign 包中的 nSurvival 函数使用 Lachin 和 Foulkes (1986) 方法，并给出样本量 = 368 以达到 90% 的功效：
# 事件发生时间样本量计算 (Lachin-Foulkes)
library(gsDesign)

ss &lt;- nSurvival(
lambda1 = .3, lambda2 = .2, eta = 0, Ts = 5, Tr =3,
sided = 1, alpha = .05
)
ss

以下是我的模拟代码来验证此方法：
n &lt;- 368
后续 &lt;- 2
eff &lt;- 0
Nsim &lt;- 20000
级别 &lt;- 0.05
lamda1 &lt;- .2
lamda0 &lt;- .3
p &lt;- 1/2
R &lt;- 3

for (i in 1:Nsim){
trt &lt;- rbinom(n,1,p)

cumentrytime &lt;- runif(n,0,R) #统一应计
censorT &lt;- R + 后续 # 研究结束 T =5

T1 &lt;- rexp(n,lamda1) #指数生存
T0 &lt;- rexp(n,lamda0)
T &lt;- T1
T[trt==0] &lt;- T0[trt==0]

statustrue &lt;- (T+cumentrytime &lt; censorT) # 如果事件时间在研究结束之前，则 status = 1
T[statustrue==0] &lt;- censorT-cumentrytime[statustrue==0] # 审查对象的曝光时间

logrank_testfinal &lt;- survdiff(Surv(T, statustrue) ~ trt)
pvaluefinal &lt;- pchisq(logrank_testfinal$chisq, length(logrank_testfinal$n)-1, lower.tail = 
FALSE)
if (pvaluefinal &lt; level ) eff &lt;- eff+1 
}

eff/Nsim

结果功效约为 83%。模拟和公式之间的功效差异 7% 是否在预期范围内（假设我的模拟进行了公平比较）？如果没有，是否有其他样本量计算公式可以得出与模拟更一致的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/661209/power-of-logrank-test-through-simulation</guid>
      <pubDate>Tue, 11 Feb 2025 03:26:49 GMT</pubDate>
    </item>
    <item>
      <title>偏回归系数线性模型中的缩放坐标（纬度和经度）</title>
      <link>https://stats.stackexchange.com/questions/661202/scaling-coordinates-latitude-and-longitude-in-a-linear-model-for-partial-regre</link>
      <description><![CDATA[我有一个数据集，我想比较一下偏回归系数。我在多个地方都读到，预测变量应该是均值中心化的，并按 1 个标准差缩放，以便于实现这一点，特别是当变量的尺度相差很大时。但是，我的一个预测变量恰好是经度。一般示例：
响应变量 ~ 中心化和缩放变量 1 + 中心化和缩放变量 2 + 经度 + 
中心化和缩放变量 1：中心化和缩放变量 2 + 
中心化和缩放变量 1：经度 + 
中心化和缩放变量 2：经度)

似乎惯例是将所有变量中心化/缩放或不缩放，但这让我想知道缩放和中心化对于纬度和经度是否必要且合适。我偶然发现了这篇 StackOverflow 帖子，似乎暗示答案可能是“否”因为它扭曲了坐标的含义：
（https://stackoverflow.com/questions/48426533/variation-partitioning-using-latitude-and-longitude-as-explanatory-variables）
但是，如果我主要对系数感兴趣，我不太明白在多元线性回归的背景下，缩放和居中纬度/经度是否不合适？
感谢您对此的任何想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/661202/scaling-coordinates-latitude-and-longitude-in-a-linear-model-for-partial-regre</guid>
      <pubDate>Mon, 10 Feb 2025 22:44:18 GMT</pubDate>
    </item>
    <item>
      <title>根据生存函数的对数直观地了解风险函数</title>
      <link>https://stats.stackexchange.com/questions/661201/intuition-for-hazard-function-in-terms-of-logarithm-of-survival-function</link>
      <description><![CDATA[此帖子有助于解释风险函数的直觉。其中，风险函数被解释为
$$h(t) = \frac{f(t)}{S(t)},$$
其中 $f(t)$ 是 PDF，$S(t)$ 是生存函数。这导致了身份
$$h(t) = -\frac{d}{dt} \log (S(t)). $$
从中获得任何直觉吗？风险函数是假设患者存活到时间 t，则在时间 t 时的瞬时死亡率。令我惊讶的是，它不知何故等于生存函数对数变换的变化率。]]></description>
      <guid>https://stats.stackexchange.com/questions/661201/intuition-for-hazard-function-in-terms-of-logarithm-of-survival-function</guid>
      <pubDate>Mon, 10 Feb 2025 22:12:18 GMT</pubDate>
    </item>
    <item>
      <title>具有拉普拉斯先验的拉普拉斯分布的后验</title>
      <link>https://stats.stackexchange.com/questions/661183/posterior-of-a-laplace-distribution-with-a-laplace-prior</link>
      <description><![CDATA[我正在练习研究生统计课上的一些概念，并尝试推导平方损失函数 $L(\theta,a)=(\theta-a)^2$ 的贝叶斯规则。我有一个拉普拉斯分布，其位置参数为 $\theta$，单位尺度为（即 $X\sim \text{Laplace}(\theta,1)$），似然值为 $f(x;\theta)=\frac{\exp\{-\sum_{i=1}^n|x_i-\theta|\}}{2^n}$。此外，我有一个拉普拉斯先验，其位置为$\eta$，单位尺度为$\pi_\Theta(\theta)=\frac{\exp\{-|\theta-\eta|\}}{2}$。
首先，我并不完全确定如何进行此计算，但我已开始推导后验，如下所示：
$$\pi_{\Theta|X}(\theta|x)\propto\exp\Big\{-\sum_{i=1}^n|x_i-\theta|-|\theta-\eta|\Big\}$$
但我不知道如何简化我的表达式。如果它们都是正态分布，我就会知道完成平方并用 $\theta$ 来写我的表达式，这样我就能得到另一个正态分布。但是，在这种情况下，我对模数符号感到困惑。我以前没有使用过拉普拉斯分布，所以任何帮助我都会很感激。谢谢！
编辑：要回答贝叶斯规则的问题，我认为我必须找到一个$a$来最小化
$$\mathbb{E}[L(\Theta,a)|X=x]\propto\int_{-\infty}^\infty (\theta-a)^2 \exp\Big\{-\sum_{i=1}^n|x_i-\theta|-|\theta-\eta|\Big\}d\theta$$
但如果没有更多关于我的后验的信息，这会变得很困难。]]></description>
      <guid>https://stats.stackexchange.com/questions/661183/posterior-of-a-laplace-distribution-with-a-laplace-prior</guid>
      <pubDate>Mon, 10 Feb 2025 16:30:10 GMT</pubDate>
    </item>
    <item>
      <title>如果一个人（非）故意忽略了所有可用数据的 10％，那么最高的准确度是多少？</title>
      <link>https://stats.stackexchange.com/questions/661168/if-one-unintentionally-ignores-10-of-all-available-data-what-is-the-highest</link>
      <description><![CDATA[我不记得当时的场合了，但我相信是一位语言学家提出，如果忽略 10% 或 15% 的数据，那么从人们所关注的 85% 的数据中就永远无法得出任何有意义的结论。
从统计学的角度来看，这种情况会发生吗？还是取决于人群遵循哪种分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/661168/if-one-unintentionally-ignores-10-of-all-available-data-what-is-the-highest</guid>
      <pubDate>Mon, 10 Feb 2025 05:55:22 GMT</pubDate>
    </item>
    <item>
      <title>如何确定偏斜自举分布的平均值和 95% 置信区间</title>
      <link>https://stats.stackexchange.com/questions/661165/how-to-determine-the-mean-and-95-confidence-interval-of-a-skewed-bootstrapped-d</link>
      <description><![CDATA[我已经对我的数据进行了 1000 次（甚至 10,000 次）引导，但这种引导分布是有偏差的，因此真正的组平均值与分布的模式更一致，而不是平均值。
我如何在保持真实组平均值的同时报告平均值和 CI？我可以报告模式吗？
以下编辑以通过一个具体示例阐明我的确切方法：
我使用线性 SVM 在两个变量之间进行解码（来自 EEG 数据）。从 20 个受试者中，我获得了每个条件的解码准确度轨迹。在这里，解码准确度轨迹是每个时间点（例如，从 0 到 1000 毫秒）的准确度百分比。我的目标是测试哪种情况（A 或 B）可以更早地解码。
统计测试 1：首先，为了测试解码准确度在组级别是否高于偶然性（分别针对条件 A 和 B），我执行基于排列的簇大小推断。简而言之，我通过将每个样本解码准确度输出随机乘以 +1 或 -1 来排列样本标签，以生成零分布（设置为 50% 的概率水平）。然后，确定最早的重要时间点（即开始时间）。
统计测试 2：然后，为了测试哪种情况（A 或 B）具有更早的开始时间，我通过随机抽样替换对数据集进行了 1000 次引导。这种方法背后的原理是在两个开始时间之间进行强有力的统计比较。我不能直接使用开始时间来对两种情况之间的差异做出强有力的断言，因为它们是奇异值并且不反映底层分布。请参阅 Sassenhagen 和 Draschko，心理生理学。2019；56：e13335。
因此，我随机抽样 20 次，进行替换，执行上述定义的统计检验，并保存第一个重要时间点。重复此过程 1000 次后，我得到了一个发病时间分布（我计划从中得出平均自举发病时间和置信区间）。
但是，第二次测试中的发病时间分布不是正态分布，因此自举发病时间的平均值与基于聚类的置换测试的发病时间不匹配。我是否应该在更干净的数据中期待正态分布？如果结果是真实的，我可以报告模式 +/- CI，而不是平均值 +/- CI，以解释数据的偏斜吗？
我希望这有意义。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661165/how-to-determine-the-mean-and-95-confidence-interval-of-a-skewed-bootstrapped-d</guid>
      <pubDate>Sun, 09 Feb 2025 21:35:46 GMT</pubDate>
    </item>
    <item>
      <title>估计具有外生状态的状态空间模型</title>
      <link>https://stats.stackexchange.com/questions/661071/estimating-state-space-model-with-exogenous-states</link>
      <description><![CDATA[我正在尝试使用 R 中的 DLM 包来估计状态空间模型，其中观测和状态方程如下：
$y_t=\beta_1a_t + B_t\beta_2(\frac{u_t-v_t}{u_t}) + C_t\beta_3(\frac{u_t-v_t}{u_t}) + \epsilon_t$
$v_t = v_{t-1}+ \zeta_t$
其中 $\epsilon_t\sim N(0,\sigma_\epsilon^2)$ 和 $\zeta_t\sim N(0,\sigma_\zeta^2)$
我有$y_t, a_t, B_t, C_t, u_t$的数据（时间序列）
我想估计 beta 并找到时间序列$v_t$。
我完全不确定如何估计这个模型，我只有一个状态方程，但我不确定我的状态在这里是什么。由于必须同时估计参数$\beta$和序列$v_t$，我无法将此模型与我读过的模型联系起来。
如果在这方面有任何帮助，我将不胜感激。
我认为我需要将其表示为状态空间模型，然后应用带有卡尔曼滤波的 EM 算法来估计参数和状态变量。例如，以下代码估计 $\beta$、$\sigma_\epsilon^2$ 和 $\sigma_\zeta^2$ 以及状态 $v_t$:
library(dlm)

# 观测方程
observation_equation &lt;- function(beta, a_t, B_t, C_t, u_t, v_t) {
beta[1] * a_t + B_t * beta[2] * ((u_t - v_t) / u_t) + C_t * beta[3] * ((u_t - v_t) / u_t)
}

# 定义状态空间模型
build_dlm &lt;- function(Q, R) {
# 我认为这个 dlmModPoly 将充当 v_t = v_{t-1} + \zeta_t
dlmModPoly(order = 1, dV = R, dW = Q)
}

# def 平方误差和
objective_function &lt;- function(params, y_t, a_t, B_t, C_t, u_t, v_t) {
beta &lt;- params[1:3]
y_pred &lt;- sapply(1:length(y_t), function(t) observer_equation(beta, a_t[t], B_t[t], C_t[t], u_t[t], v_t[t]))
error &lt;- y_t - y_pred

sum(error^2)
}

# beta、Q 和的初始猜测R
beta_init &lt;- c(0.5, 0.5, 0.5)
Q_init &lt;- 0.1
R_init &lt;- 0.1
params_init &lt;- c(beta_init, Q_init, R_init)
#初始化变量
Q_estimated = Q_init
R_estimated = R_init

# EM 算法
for (iteration in 1:10) {
# E-Step：使用当前 beta、Q 和 R 估计 v_t
model &lt;- build_dlm(Q_estimated, R_estimated)
fit &lt;- dlmFilter(y_t, model) # 卡尔曼滤波器应用
v_estimated &lt;- dropFirst(fit$m) # 估计状态 v_t

# M-Step：使用估计的参数更新模型
result &lt;- optim(params_init, objective_function, y_t = y_t, a_t = a_t, B_t = B_t, C_t = C_t, u_t = u_t, v_t = v_estimated)
params_estimated &lt;- result$par
beta_estimated &lt;- params_estimated[1:3]
Q_estimated &lt;- params_estimated[4]
R_estimated &lt;- params_estimated[5]

# 更新下一次迭代的初始参数
params_init &lt;- c(beta_estimated, Q_estimated, R_estimated)
}

其中 a_t、B_t、C_t、u_t 是已知且长度相同的时间序列。
这准确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661071/estimating-state-space-model-with-exogenous-states</guid>
      <pubDate>Fri, 07 Feb 2025 01:47:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 KSG 估计量来计算一个变量的固定值的特定互信息估计？</title>
      <link>https://stats.stackexchange.com/questions/660782/how-can-we-compute-a-specific-mutual-information-estimate-for-a-fixed-value-of-o</link>
      <description><![CDATA[我正在使用 Kraskov-Stögbauer-Grassberger (KSG) 估计器进行互信息 (MI) 计算，并希望计算一个变量固定值的特定互信息估计值，同时考虑另一个变量的所有值。这在概念上类似于 DeWeese &amp; 引入的刺激特定信息Meister (1999)。
互信息的 KSG 估计量由以下公式给出：
$
I(X; Y) = \psi(k) - \frac{1}{N} \sum_{i=1}^{N} \left[ \psi(n_x(i) + 1) + \psi(n_y(i) + 1) \right] + \psi(N)
$
其中 $k$ 是最近邻居的数量，$n_x(i)$ 是 $X$ 中 $k$-NN 半径内的邻居数量（$x_i$, $y_i$), $n_y(i)$ 是 Y 中同一半径内的邻居数量，$\psi(\cdot)$ 是双伽马函数。每对 $(x_i, y_i)$ 对 MI 的贡献可以通过取消平均值来实现：
$
i(x_i; y_i) = \psi(k) - \psi(n_x(i) + 1) - \psi(n_y(i) + 1) + \psi(N)
$
但是，我想调整这个估计量来计算给定值 $Y=y_i$ 的特定互信息，同时考虑 $X$ 的所有值。具体来说，我想估计 $I(X; Y=y_i)$。是否可以使用 KSG 估计器的修改来计算这个特定的相互信息？如果可以，那么实现这一点的最佳方法是什么，同时确保对整个 $y$ 取 $I(X; Y=y_i)$ 的平均仍能恢复总相互信息 I(X; Y)？]]></description>
      <guid>https://stats.stackexchange.com/questions/660782/how-can-we-compute-a-specific-mutual-information-estimate-for-a-fixed-value-of-o</guid>
      <pubDate>Thu, 30 Jan 2025 22:30:18 GMT</pubDate>
    </item>
    </channel>
</rss>