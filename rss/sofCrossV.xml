<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Fri, 07 Feb 2025 15:18:59 GMT</lastBuildDate>
    <item>
      <title>线性回归与神经网络之间的选项[重复]</title>
      <link>https://stats.stackexchange.com/questions/661090/options-between-linear-regression-and-neural-network</link>
      <description><![CDATA[我希望主要是概念上的答案或链接到解决这些问题的特定文章。在努力撰写长期回应之前，请随时发表评论。
 背景 
  （在优化期间）的输入如下：
  \ begin {align}
y＆amp; = w x + b \ hspace {1cm}＆amp; \ text {（单变量）} \\
y＆amp; = \ sum_i w_i x^j + b＆amp; \ text {（多变量）} \ tag {1} \\
y＆amp; = \ sum_i w_i x_i^i + b＆amp; \ text {（polyenmial）} \\
y＆amp; = \ sum_i w_i x_i +b＆amp; \ text {（multi-variate）} \\
\ end {align}  
在上述大多数情况下，最小二乘。。。 P&gt;
即使系数是线性的，多项式扩展似乎具有无限的能力，尽管在某些情况下它实际上会引起麻烦（我认为）。
 概念问题 
我看不到拟合复杂数据的多项式回归的理论局限性，但是Chatgpt表明它可以过度拟合或适合噪声 /离群值，这似乎是可能的。另一个问题显然是权力的数字稳定性。
我知道山脊回归等，但是我怀疑这些回归并不强大。
我认为神经网络存在的原因是由于缺乏在多层设置中非线性优化问题的分析解决方案。即使是非负平方，也缺乏简单的非著作解决方案。
但是我需要问：

是否还有其他具有分析解决方案和更少问题的拟合方法？ （我的意思是，我们不需要错误的后传播才能纠正梯度。）

或类似地，

是否有某些非线性单层或多层的封闭解决方案？
]]></description>
      <guid>https://stats.stackexchange.com/questions/661090/options-between-linear-regression-and-neural-network</guid>
      <pubDate>Fri, 07 Feb 2025 14:17:17 GMT</pubDate>
    </item>
    <item>
      <title>匹配Kaplan-Meier在电子表格中与Lifelines Python包装</title>
      <link>https://stats.stackexchange.com/questions/661089/match-kaplan-meier-in-spreadsheet-with-lifelines-python-package</link>
      <description><![CDATA[使用众所周知的
 
对于每个任期，我都会计算出流失，累积流失以及累积生存。然后，在每个时间点，我都计算了那些搅动的人 /那些可能会搅动的人。然后以累积概率认为这是Kaplan-Meier：
    
公式的描述：

可乐任期：数据中的独特任期
 COLB帐户：每个任期的帐户计数
 Colc Churn：此时流失的帐户计数
冷累积流失：所有帐户的计数
 Cole累积生存：总帐户 - 日期总流行
 COLF生存％在每个时间点：在此期间的筹集帐户 /累计生存期间&lt; / li&gt; &lt; / li&gt;
 Colg Kaplan -Meir：Colf *以前的Colg-累积概率

公式在链接的纸张中。
使用Python我在相同的数据上安装了一个km：
 将大熊猫作为pd导入
从救生线进口kaplanmeierfi​​tter
导入matplotlib.pyplot作为PLT

＃加载数据
TELCO_CHURN = PD.READ_CSV（&#39;https：//docs.google.com/spreadsheets/d/1l5/1l5axjlzdcqskozefrcfpv8in5 ededyxne7t8sbrvfffrsqursbrvfffrsq/export？
电视_CHURN [&#39;Churn&#39;] =电视_Churn [&#39;Churn&#39;]。MAP（{&#39;YES&#39;：1，&#39;no&#39;：0}）

＃适合Kaplan-Meier
kmf = kaplanmeierfi​​tter（）
kmf.fit（telco_churn [&#39;tenure&#39;]，event_observed = telco_churn [&#39;Churn&#39;]）

＃在特定时间计算生存概率
time_points = [5，10，20，30]
survival_probs = kmf.predict（time_points）
印刷（reservival_probs）
 
输出：
  5 0.891111
10 0.854915
20 0.804520
30 0.768680
名称：km_estimate，dtype：float64
 
将其与我的电子表格进行比较：
  5：89.44
10：86.26
20：82.24
30：79.77
 
我的电子表格正确吗？我该如何计算此纸上的公里？为什么它与Python的Lifelines软件包计算有所不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/661089/match-kaplan-meier-in-spreadsheet-with-lifelines-python-package</guid>
      <pubDate>Fri, 07 Feb 2025 12:58:39 GMT</pubDate>
    </item>
    <item>
      <title>计算两个二进制变量之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/661088/computing-the-correlation-between-two-binary-variables</link>
      <description><![CDATA[如果我有三个二进制向量：
 a = [1，1，0，0] 
 b = [1，1，1，0] 
 c = [1，1，1，1] 
我想知道相关性（corr（a，b），corr（a，c），corr（b，c）），计算此问题的正确方法是什么？我正在使用的数据来自调查，其中A，B和C是多选问题的类别（因此受访者可以选择所有选项），每行都为特定受访者指示所有答案。
我想检查在一般情况下，选择例如选择之间的相关性是什么。选项A和C一起。
我当前的方法是计算例如A和C，在我的理解中，这相当于二进制变量的Pearson相关系数。我只是不确定这是否是我的数据类型的正确方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/661088/computing-the-correlation-between-two-binary-variables</guid>
      <pubDate>Fri, 07 Feb 2025 12:58:31 GMT</pubDate>
    </item>
    <item>
      <title>运行混合线性模型时奇怪的行为</title>
      <link>https://stats.stackexchange.com/questions/661086/strange-behavior-when-running-mixed-linear-models</link>
      <description><![CDATA[我对正在发生的事情的想法已经用尽，欢迎任何帮助。
我在7个特征和8个环境中运行R中混合线性模型。我运行了一个循环，为每个个体，性状和环境组合输出Emmeans。一切顺利，除了在一个环境中的一个特征，我的奇怪值在-14到46之间，而我期望的值在100至150之间。这是我的代码：
 （traits_q23＆lt;  - 名称（nora_main_23）[C（30：33，35：36，41））） 

#emmeans
#loop for Single Env
（single_env_23＆lt; -inique（nora_main_23 $ env））

for（j in 1：长度（single_env_23））{
  subset_data＆lt;  -  nora_main_23％＆gt;％滤镜（env == single_env_23 [j]）
  ＃初始化数据框以存储结果
  final_results＆lt;  -  data.frame（cross = unique（subset_data $ cross））＃确保交叉是第一列
  
  for（i在1：长度（traits_q23））{
    ＃检查特征是否包含任何非NA值
    if（all（ass.na（subset_data [[[traits_q23 [i]]]]]）））{
      消息（粘贴（跳过特征：&#39;&#39;traits_q23 [i]，环境中：＆quot; single_env_23 [j]，因为它仅包含na value;））
      下一个＃跳过这个特征，转到下一个特征
    }
    
    ＃将当前环境的数据子集
    mod_rb＆lt;  -  glmmtmb（as.formula（paste（traits_q23 [i]，;
                    reml = f，
                    control = glmmtmbcontrol（optctrl = list（iter.max = 1e4，eval.max = 1e4）），），），），），
                    数据= subset_data）
        
    ＃提取Emmeans并将其整理到数据框架中
    emmeans_result＆lt;  -  emmeans（mod_rb，“ cross＆quot” lmer.df =＆quot; satterthwaite＆quort＆quot;
      as_tibble（）％＆gt;％
      选择（交叉，Emmean）＃仅保留十字和Emmean列
    
    
    ＃重命名Emmean列以反映性状
    colname＆lt;  -  paste0（traits_q23 [i]
    emmeans_result＆lt;  -  emmeans_result％＆gt;％
      重命名（!! colname：= emmean）＃动态命名Emmean列
    
    ＃结合最终结果（交叉加入）
    final_results＆lt;  -  left_join（final_results，emmeans_result，by =&#39;cross; quot;）
    
  }
  write_csv（final_results，paste0（single_env_23 [j]，&#39;_combined_emmeans.csv＆quot;））
}
 
这是针对特定特征/env组合的警告：
 警告消息：
1：在finalizetMB中（tmbstruc，obj，fit，h，data.tmb.old）：
  模型收敛问题；非阳性的黑森矩阵。请参阅Vignette（“故障排除”）
2：在finalizetMB中（tmbstruc，obj，fit，h，data.tmb.old）：
  模型收敛问题；假收敛（8）。请参阅Vignette（“故障排除”），帮助（“诊断”），这是摘要摘要（MOD_RB）
 家庭：高斯（身份）
公式：Plant_height〜Cross +（1 |行） +（1 | Col） +（1 | Rep）
数据：subset_data

     AIC BIC LOGLIK偏差DF。 
      na na na na 27 

随机效果：

条件模型：
 组名称差异std.dev。 
 行（截距）1.747E+01 4.180E+00
 COL（截距）4.835E+01 6.954E+00
 REP（截距）1.357E+04 1.165E+02
 剩余5.413E-06 2.327E-03
OBS数：222，组：行，8； Col，30；代表，2

高斯家庭的分散估计（Sigma^2）：5.41E-06 

条件模型：
                                    估计标准。错误z值pr（＆gt; | z |）    
（截距）27.110072 Nan Nan Nan    
Cross121/138 -MSL325 -6.409456 7.397595 -0.9 0.386258    
Cross121/199 -GX47390 -6.412536 7.397597 -0.9 0.386029    
Cross121/199 -MSL325 -11.413252 7.397598 -1.5 0.122872
 
我期望的看起来更像是这样：
 摘要（mod_rb）
 家庭：高斯（身份）
公式：Plant_height〜Cross +（1 |行） +（1 | Col） +（1 | Rep）
数据：subset_data

     AIC BIC LOGLIK偏差DF。 
  1145.1 1818.1 -375.6 751.1 28 

随机效果：

条件模型：
 组名称差异std.dev。
 行（截距）24.9410 4.994   
 Col（截距）56.7841 7.536   
 REP（拦截）4.5482 2.133   
 残留0.5242 0.724   
观察数：225，组：行，8； Col，30；代表，2

高斯家族的分散估计（Sigma^2）：0.524 

条件模型：
                                  估计标准。错误z值pr（＆gt; | z |）    
（截距）133.7390 3.4559 38.70＆lt; 2E-16 ***
Cross121/138 -MSL325 -4.7004 2.8917 -1.63 0.104063    
Cross121/199-GX47390 1.7874 3.4278 0.52 0.602054    
Cross121/199 -MSL325 -16.4060 7.9761 -2.06 0.039696 *  
 
我试图减少随机效果，但是差异会不断跳到下一个随机效果。知道什么可能出了什么？
谢谢
乔纳森]]></description>
      <guid>https://stats.stackexchange.com/questions/661086/strange-behavior-when-running-mixed-linear-models</guid>
      <pubDate>Fri, 07 Feb 2025 09:56:39 GMT</pubDate>
    </item>
    <item>
      <title>Lambda的大小与Ridge Recression的罚款大小</title>
      <link>https://stats.stackexchange.com/questions/661082/size-of-lambda-vs-size-of-penalty-term-in-ridge-regression-and-lasso</link>
      <description><![CDATA[训练山脊回归时，我们最小化
 $$ rss（\ lambda） + \ lambda \ sum_ {j = 1}^p [\ beta_j（\ lambda）]^2 $$ 
其中 $ rss（\ lambda）=（y_i  - （\ beta_0 + \ sum_ {i = 1}^{n_ {train}} \ beta_j（\ beta_j（\ lambda） }））^2 $ 是训练集中的平方残差之和。
确实将罚款权重从 $ \ lambda_1 $ 到 $ \ lambda_2 $ （带有 $ \ lambda_1＆lt; \ lambda_2 $ ）必​​须增加罚款项吗？ IE。我们可以确定
 $$ \ lambda_1 \ sum_ {j = 1}^p [\ beta_j（\ lambda_1）]^2  -  \ lambda_2 \ sum_ {j = 1} lambda_2）]^2 \？$$  
拉索的答案与山脊一样吗？
（我认识到 $ rss（\ lambda_1） = 1}^p [\ beta_j（\ lambda_1）]^2＆gt; \ sum_ {j = 1}^p [\ beta_j（\ lambda_2）]^2 $ 问题。）]]></description>
      <guid>https://stats.stackexchange.com/questions/661082/size-of-lambda-vs-size-of-penalty-term-in-ridge-regression-and-lasso</guid>
      <pubDate>Fri, 07 Feb 2025 09:08:11 GMT</pubDate>
    </item>
    <item>
      <title>FGLS估计值的簇旋转三明治协方差矩阵估计器如何收敛到渐近协方差矩阵？</title>
      <link>https://stats.stackexchange.com/questions/661080/how-does-the-cluster-robust-sandwich-covariance-matrix-estimator-of-the-fgls-est</link>
      <description><![CDATA[在Wooldridge的横截面和面板数据的第7章（第180页）中，他写下了系统FGLS估算器的群集塑料三明治协方差估算器的公式：：
    
特别是，此公式中的中心术语：b̂在渐近协方差矩阵中以此术语收敛到此术语：
    
我的问题是：如果B̂具有估计的矩阵ω-hat，而B具有固定的实际矩阵ω？
在本书之前，Wooldridge已证明了这两个足够的条件，以显示FGLS估算器的一致性和渐近正态性：
   
   
但是，要表明b̂会收敛到b的概率等同于显示这种情况：
    
那么，如何显示？非常感谢您对此的任何指导，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661080/how-does-the-cluster-robust-sandwich-covariance-matrix-estimator-of-the-fgls-est</guid>
      <pubDate>Fri, 07 Feb 2025 08:20:16 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将子优化问题结合到一个优化问题中？</title>
      <link>https://stats.stackexchange.com/questions/661079/is-it-possible-to-combine-sub-optimization-problems-into-one-optimization-proble</link>
      <description><![CDATA[考虑决策变量的向量 $ w \ in \ re^{n \ times 1} $ ，因此 $ w = \ begin {bmatrix} w_1＆amp; W_2＆amp; \ cdots＆amp; w_n \ end {bmatrix}^\ top $ ，可以通过求解 $ n $  sub-optimization问题，以递归确定，以便以便
 \ begin {equation}
\ min_ {w_1 \ geq0} \ left \ | w_1 h_1 w_1 -y_1 \ right \ |^2
\ end {equation} 
因此
 \ begin {equation}
\ min_ {w_2 \ geq0} \ left \ | \ begin {bmatrix} w_1＆amp; w_2 \ end {bmatrix} \ begin {bmatrix} h_1＆amp; 0 \\ 0＆amp; H_2 \ end {bmatrix} \ begin {bmatrix} w_1 \\ w_2 \ end end {bmatrix} -y_2 \ y_2 \ right \ |^2
\ end {equation} 
 $ \ VDOTS $ 
 \ begin {equation}
\ min_ {w_n \ geq0} \ left \ | \ begin {bmatrix} w_1＆amp; \ cdots＆amp; w_n \ end {bmatrix} \ begin {bmatrix} h_1＆amp; 0＆amp; \ cdots＆amp; 0 \\ 0＆amp; H_2＆amp; \ cdots＆amp; 0 \\ 0＆amp; 0＆amp; \ ddots＆amp; 0 \\ 0＆amp; 0＆amp; 0＆amp; h_n \ end {bmatrix} \ begin {bmatrix} w_1 \\ \ vdots \\ w_n \ end end {bmatrix}  -  y_n \ right \ |^2
\ end {equation}  
我想知道，是否有可能建立一个可以解决vector  $ W $ 的优化问题？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661079/is-it-possible-to-combine-sub-optimization-problems-into-one-optimization-proble</guid>
      <pubDate>Fri, 07 Feb 2025 07:49:21 GMT</pubDate>
    </item>
    <item>
      <title>估计总数的预测间隔？</title>
      <link>https://stats.stackexchange.com/questions/661072/prediction-interval-for-an-estimated-total</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661072/prediction-interval-for-an-estimated-total</guid>
      <pubDate>Fri, 07 Feb 2025 01:53:39 GMT</pubDate>
    </item>
    <item>
      <title>横截面数据集的预测比较的重要性</title>
      <link>https://stats.stackexchange.com/questions/661061/significance-in-forecast-comparison-in-cross-sectional-dataset</link>
      <description><![CDATA[我的最终目标是评估与横截面数据集中的模型2相比，模型1是否产生的预测误差明显较小。根据不同的预测精度，例如RMSE或MAE。
让我们假设一个简单的方案我想预测客户支出。我在10年内观察10,000个不同客户的数据，包括收入，区域等信息。根据这些数据，我创建了两个模型，模型1（例如，某些机器学习模型）和模型2（例如，线性回归） ，预测客户支出。培训数据是1  -  7年的数据，测试数据是8  -  10年的数据。。
对于测试集中的每个观察结果，我将预测误差视为预测和实际数量之间的差异。现在，我想评估与模型2相比，模型1是否产生明显较小的预测错误。
我知道是文献评估此类预测差异的一种常见方法。但是，通常在时间序列数据的背景下使用，而我的数据集则是横截面。
为了完整性，我附上了DM测试实现的小R代码。虽然我在这里模拟了简单性的正态分布预测错误，但在我的实际应用中，它们可能不是正态分布的。
这是解决此问题的正确方法，还是有其他方法可以获得两个模型之间的性能是否显着不同？
示例性R代码：
 库（预测）

set.seed（123）

＃样本尺寸
N＆lt; -3000

＃预测误差模型1和模型2，正态分布为简单
m1＆lt;  -  rnorm（n，平均值= 0.02，sd = 0.5）
m2＆lt;  -  rnorm（n，平均= 0.10，sd = 0.5）

dm. -test（M1，M2，替代=; lims＆quort＆quort＆quort h = 1，power = 2）
 
 DM检验的输出：
  diebold-mariano测试

数据：M1M2
dm = -2.2584，预测范围= 1，损耗函数功率= 2，p值= 0.012
替代假设：少
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661061/significance-in-forecast-comparison-in-cross-sectional-dataset</guid>
      <pubDate>Thu, 06 Feb 2025 21:51:03 GMT</pubDate>
    </item>
    <item>
      <title>匹配前后的逻辑回归结果相同</title>
      <link>https://stats.stackexchange.com/questions/661060/identical-results-in-logistic-regression-before-and-after-matching</link>
      <description><![CDATA[ i使用llogistic回归（GLM框架）在使用Matchit软件包应用最佳完整匹配后，比较了R中的logistic回归（Model1）和匹配模型（Model2）的结果。但是，我得到的是Model1和Model2之间的完全相同的结果，甚至到小数点。。
我怀疑这可能与赛后模型中的权重有关。我是否需要明确说明Model2中的权重才能观察结果的差异？

 逻辑回归
  model1＆lt;  -  glm（y〜x1 + x2 + x3 + ... + x10， 
           family =二项式（link =＆quot; logit; quot;）， 
           数据= data1）
 

 使用0.2 的最佳完整匹配匹配
  d1_match＆lt;  -  agatit（x1〜x2 + x3 + x4 + ... + x10， 
                 数据= data1，
                 方法=“ full＆quot”，  
                 距离=; glm＆quot＆quot         
                 link =&#39;logit＆quot＆quot＆quot 
                 估计=“ att”
                 卡钳= 0.2）
 

 提取匹配数据集
  data1_match＆lt;  -  match.data（d1_match）
 

 匹配数据集的逻辑回归
  model2＆lt;  -  glm（y〜x1 + x2 + x3 + ... + x10， 
           family =二项式（link =＆quot; logit; quot;）， 
           data = data1_match） 
 


问题：
为什么Model1和Model2即使在匹配之后也会产生相同的结果？
在运行Model2时，我是否需要合并D1_Match的权重？
如果是这样，我应该如何在Model2中正确包括权重？
会感谢我的方法是否需要调整的任何见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/661060/identical-results-in-logistic-regression-before-and-after-matching</guid>
      <pubDate>Thu, 06 Feb 2025 21:35:35 GMT</pubDate>
    </item>
    <item>
      <title>从符号分布中生成样品</title>
      <link>https://stats.stackexchange.com/questions/661059/generating-samples-from-a-symbolic-distribution</link>
      <description><![CDATA[以下考虑了。
一个人可以从数值定义的统计分布中计算随机变化。  因此，我们可以要求从平均值 $ \ mu = 3 $ 和标准偏差 $ \ $ \ $ \ $ \ $ \ $ \ $ \ $ \ $ \ $ \ $ \ $ \ mu = 3 $  $ \ mu = 3 $  $ \ mu = 3 $  $ \ mu = 3 $  $ \ mu = 3 $  Sigma = 4 $ 。  我们还可以从完全指定象征性地指定的高斯分布中生成样本。  例如，我们可能会生成从 $ n [\ mu，\ sigma] $ 随机采样的三个点，并查找
  $ \ {\ MU + .41 \ SIGMA，\ MU  -  .22 \ SIGMA，\ MU + 2.1 \ SIGMA \ sigma \} $ 。
同样，如果我们强加条件Xmin＆lt; Xmax，我们可以从统一分布 $ u [xmin，xmax] $ 中生成随机样本，并找到
  $ \ {Xmin + 0.4（Xmax -Xmin），Xmin + 0.91（Xmax -Xmin），Xmin + 0.16（Xmax -xmax -xmin）\ \} $ 。 
（离散）泊松分布的类似点可能产生
  $ \ {e^{\ mu} \ mu^5/5！ \ mu^{41}/41！ \} $  
因此，我的问题：

一个人总是可以为指定的每个分布象征性地生成一个随机样本？
是否有一种原则方法来确定给定的分布（正常，统一，泊松，指数，...）是否会或不会支持这种 smormbolic 样本生成？
]]></description>
      <guid>https://stats.stackexchange.com/questions/661059/generating-samples-from-a-symbolic-distribution</guid>
      <pubDate>Thu, 06 Feb 2025 21:29:59 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程的后部和后部预测之间的差异</title>
      <link>https://stats.stackexchange.com/questions/661052/difference-between-the-posterior-and-posterior-predictive-of-a-gaussian-process</link>
      <description><![CDATA[这里提出了一个类似的问题：
    
从幻灯片来看，我知道后验分布是 $ f $ 的条件分布，后验预测分布是未见观测值 $ y _*$ 位置 $ x _*$ ，但是如何 $ f $ 和 $ y^*$ 直觉上有所不同吗？后分布与 $ y _*$ 只是在假设没有与 $的噪声相同的情况下相同y _*$ ？最让我感到困惑的是您经常看到这样的情节：
    
但我会根据上面的公式来假设后部分布只有在观察到数据的地方才是分布，但是图片到处都有不确定性带（即对我来说，感觉就像是后部的情节预测性，因为您在尚未观察到的点上具有预测和不确定性频段）。任何帮助理解和消除我的困惑的帮助都将非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661052/difference-between-the-posterior-and-posterior-predictive-of-a-gaussian-process</guid>
      <pubDate>Thu, 06 Feb 2025 18:20:25 GMT</pubDate>
    </item>
    <item>
      <title>如何使用逆概率加权（IPW）考虑采样偏差：协变量选择和处理缺失数据的最佳实践</title>
      <link>https://stats.stackexchange.com/questions/661044/how-to-account-for-sampling-bias-using-inverse-probability-weighting-ipw-best</link>
      <description><![CDATA[我正在分析来自生物库/大型队列研究的蛋白质组学数据，其中包括随机选择的参与者子集和两个非随机子集。由于这些非随机选择可能会引入偏见，因此我正在考虑使用逆概率加权（IPW）来解释潜在的选择偏见。
 问题： 

 选择协变量进行倾向得分估计 


数据的原始论文并未提供有关参与者选择标准的完整详细信息。由于当选择过程得到充分了解时，IPW最有效，因此哪些协变量适合估计倾向分数？
在这种情况下可能很重要的其他因素？


 处理蛋白质组学中缺少的数据 


由于缺少数据随蛋白质而异，因此每种蛋白质的样品略有不同。 计算蛋白质特异性的倾向分数和权重是否适合，以确保权重反映每个蛋白质中没有错失数据的个体的子集？
或一组基于完整蛋白质组学样本的权重？

对IPW类似应用的任何建议或参考都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661044/how-to-account-for-sampling-bias-using-inverse-probability-weighting-ipw-best</guid>
      <pubDate>Thu, 06 Feb 2025 14:21:27 GMT</pubDate>
    </item>
    <item>
      <title>使用Bootstrap生成预测间隔</title>
      <link>https://stats.stackexchange.com/questions/661026/generating-prediction-intervals-using-bootstrap</link>
      <description><![CDATA[我有一些数据并符合线性回归：
 $$ y_i = \ beta_0 + \ beta_1x_i + \ epsilon_i，\ quad \ epsilon_i \ sim n（0，\ sigma^2）
 我想对一个新点进行预测 $ x _ {\ text {new}} $ 并记录预测间隔。我的脑海中对以下情况有些困惑。我可以想到3种不同的方法： 
我在下面概述了它们：

方法1：没有个人预测间隔的引导程序样本
使用bootstrap采样。对于新点 $ x _ {\ text {new}} $ ，生成引导程序样本。对于每个引导程序样本 $ b = 1，\ ldots，b $ ：

用我们原始数据替换的示例 $（x_i^{（b）}，y_i^{（b）}）$  for  $ i = 1，\ ldots，n $  
拟合一个新的回归模型以获取估计 $ \ hat {\ beta} _0^{（b）} $  and span&gt; and  $ \ hat {\ beta} _1^{（b）} $  

对于每个引导程序示例 $ b $ ，仅计算点预测：
 $$ \ hat {y} _ {\ text {new}}}}^{（b）} = \ hat {\ beta} _0^{（b）} + hat beta} _1^{（b）} x _ {\ text {new}} $$  
然后从这些预测的经验分布中形成预测间隔：
 $$ [\ hat {y} _ {\ text {new}，\ text {lower}}，\ hat {y} _ {y} _ {\ text {new}，\ text { }}] = [\ text {persitile} _ {2.5}（\ {\ hat {y} _ {\ text {new}}}^{（b）} \}） \ {\ hat {y} _ {\ text {new}}}^{（b）} \}）$$  

方法2：具有单个预测间隔的引导程序样本
对于每个引导程序示例 $ b $ ，我们计算完整的预测间隔：
 $$ \ hat {y} _ {\ text {new}}}}^{（b）} \ pm t_ {n-2，\ alpha/2} \ hat {\ sigma} ^{（b）} \ sqrt {1 + \ frac {1} {n} + \ frac {（x _ {x _ {\ text {new}}}  -  \ bar {x}^}^{（b）} sum（x_i^{（b）}  -  \ bar {x}^{（b）}）^2}}} $$   
其中：

  $ \ hat {\ sigma}^{（b）} $ 是Bootstrap示例 $ $的残留标准错误B $  
  $ t_ {n-2，\ alpha/2} $ 是t-distribution的关键值
  $ \ bar {x}^{（b）} $ 是Bootstrap示例中X值的均值&gt; $ b $  

这为我们提供了一个间隔的集合 $ [l^{（b）}，u^{（b）}] $  for  $ b = 1，\ ldots，b $ 。最终预测间隔是：
 $$ [\ text {persitile} _ {2.5}（\ {l^{（b）} \}），\ text {persitaile} _ {97.5} {（b）} \}）$$  

方法3：没有bootstrap，使用封闭形式的预测间隔
使用封闭式公式的经典方法：
 $$ \ hat {y} _ {\ text {new}} \ pm t_ {n-2，\ alpha/2} \ hat {\ sigma} \ sqrt frac {1} {n} + \ frac {（x _ {\ text {new}}}  -  \ bar {x}）^2} {\ sum（x_i- \ bar {x}）跨度&gt; 
其中：

  $ \ HAT {\ SIGMA} $ 是原始模型的残留标准错误
  $ \ bar {x} $ 是原始X-Values的均值


总结：

方法1仅在回归系数中捕获不确定性（ $ \ beta_0 $ 和 $ \ beta_1 $  ）。这将是最小的。
方法2通过boottrapping来解释系数不确定性和固有的可变性（ $ \ sigma^2 $ ）。这将是最大的
方法3使用基于T分布假设的理论公式。这将是中间

 在实践中，是否建议使用方法2获取最现实的预测间隔？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/661026/generating-prediction-intervals-using-bootstrap</guid>
      <pubDate>Thu, 06 Feb 2025 03:45:25 GMT</pubDate>
    </item>
    <item>
      <title>$ y $从$ x $计算时回归</title>
      <link>https://stats.stackexchange.com/questions/660990/regression-when-y-has-been-calculated-from-x</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660990/regression-when-y-has-been-calculated-from-x</guid>
      <pubDate>Wed, 05 Feb 2025 12:43:17 GMT</pubDate>
    </item>
    </channel>
</rss>