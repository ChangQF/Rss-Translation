<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 16 Jul 2024 18:20:29 GMT</lastBuildDate>
    <item>
      <title>Cox 比例风险模型的功效分析</title>
      <link>https://stats.stackexchange.com/questions/651176/power-analysis-for-the-cox-proportional-hazards-model</link>
      <description><![CDATA[我正在尝试根据一项小型研究计算出 RCT 所需的样本量，该研究研究了指数手术后的再次手术。在这项小型研究中，有 1000 名患者，第 1 组有 700 名，第 2 组有 300 名患者。第 1 组中有 20 名再次手术，第 2 组中有 30 名再次手术。但是，第 1 组的 10 年生存率为 15%，第 2 组的 10 年生存率为 12%。因此，大多数患者不再面临再次手术的风险。我想知道如何计算 RCT 所需的样本量，以 1:1 随机分配，并观察如果对患者进行 10 年的随访，考虑到随访期间的死亡，各组之间的风险比是否会降低 0.10？我的 stata 代码目前如下所示
power cox, hratio(0.90) alpha(0.05) power(0.80)]]></description>
      <guid>https://stats.stackexchange.com/questions/651176/power-analysis-for-the-cox-proportional-hazards-model</guid>
      <pubDate>Tue, 16 Jul 2024 18:17:39 GMT</pubDate>
    </item>
    <item>
      <title>将五点李克特量表转换为均匀量表</title>
      <link>https://stats.stackexchange.com/questions/651175/converting-five-point-likert-scale-to-uniform-scale</link>
      <description><![CDATA[体力活动的平均值和 SD（在元分析中）分别为 2.3 和 3.4。我想知道如何将这两个基于五点李克特量表的值重新调整为统一量表（0 到 100）？]]></description>
      <guid>https://stats.stackexchange.com/questions/651175/converting-five-point-likert-scale-to-uniform-scale</guid>
      <pubDate>Tue, 16 Jul 2024 18:16:09 GMT</pubDate>
    </item>
    <item>
      <title>灌注分析算生存分析吗？</title>
      <link>https://stats.stackexchange.com/questions/651173/perfusion-analysis-counts-as-survival-analysis</link>
      <description><![CDATA[在灌注分析中，患者被注射一定剂量的药物。机器会随着时间的推移检测患者体内的药物剂量。换句话说，每个患者的数据是时间点 $0=t_0 &lt; t_1 &lt; \cdots &lt; t_N$ 和剂量 $y_1, \ldots, y_N$，其中 $y_i \in [0, \infty)$ 表示时间 $t_i$ 时患者体内的剂量。 （通常，$y_i$ 也可以是某种间接的剂量测量值。）根据具体情况，可能只有一名患者或多名患者，或者患者被分成几组等。我们只强调一个假设：给定时间 $t$，任何患者在时间 $t$ 的剂量都是随机的，因此这不是机器学习任务。
当我们绘制所有对 $(t_i,y_i)$ 时，形状通常看起来像一些集中在 $[0, \infty)$ 上的分布的概率密度函数（例如对数正态分布、威布尔分布、指数分布，...）
统计学家的任务通常是调查趋势，推断例如剂量何时达到峰值，剂量何时上升等。解决问题的一种方法是与客户交谈，根据信念拟合概率密度函数，然后查看任务。
例如，假设只有一名患者，我们想要估计剂量何时达到峰值。我们可以说在与客户讨论后，用对数正态分布的概率密度函数拟合数据，选择参数以最小化最小二乘，然后查看拟合的最大值。
问题：统计员的任务名称是什么？这样的任务算生存分析吗？时间序列分析？我倾向于称之为生存分析，但我不确定，因为在这种情况下，生存分析中的典型工具似乎不可用。]]></description>
      <guid>https://stats.stackexchange.com/questions/651173/perfusion-analysis-counts-as-survival-analysis</guid>
      <pubDate>Tue, 16 Jul 2024 18:14:45 GMT</pubDate>
    </item>
    <item>
      <title>有限的结果事件。方法的选择</title>
      <link>https://stats.stackexchange.com/questions/651170/limited-outcome-events-choice-of-method</link>
      <description><![CDATA[我正在对罕见事件进行研究。我比较了两个组 A（n=50）和 B（n=200），但我发现结果事件比预期的要少，A（n=12），B（n=4）。我可以将这些数据用于任何有意义的目的吗？还是统计不确定性太大？我打算进行多变量分析（cox reg），但如果变量超过 1-2 个，这将失败？
谨致问候，
H]]></description>
      <guid>https://stats.stackexchange.com/questions/651170/limited-outcome-events-choice-of-method</guid>
      <pubDate>Tue, 16 Jul 2024 17:57:08 GMT</pubDate>
    </item>
    <item>
      <title>汇集参与者数据以解决每种情况的试验数量有限问题</title>
      <link>https://stats.stackexchange.com/questions/651169/pooling-participant-data-to-resolve-limited-trials-per-condition-issues</link>
      <description><![CDATA[问题：在一项实验任务中，有 4 种条件，每种条件只有 2 次试验，因此每个参与者有 8 次观察。通常，我们使用信号检测理论 (SDT) 来计算描述性统计数据，例如命中率 (H) 或 d prime(d’)，然后执行推断统计（例如，对 4 种条件的准确度进行重复测量方差分析）。但是，每个参与者每个条件的试验次数很少，因此无法准确计算这些统计数据。SDT 标准要求，对于给定的统计数据（例如命中率 H），要被视为有效且呈正态分布，每个条件的试验次数 (N) 必须满足不等式 NH &gt; 5 和 N(1-H) &gt; 5. 每种情况只有两次试验，这些条件无法满足。
可能的解决方案：为了解决这个问题，我正在考虑两个潜在的解决方案（第二个解决方案似乎是第一个解决方案的更好版本）：

将 200 名参与者分成 25 组，每组 8 人，将他们的回答结合起来形成“宏观参与者”。每个宏观参与者每个条件将有 16 次试验，从而可以有效计算 SDT 描述性统计数据。然后可以对这些进行常规分析，例如，使用 ANOVA 比较 4 种条件下的表现。
使用受 Bootstrap 启发的重采样方法来创建宏观参与者：随机抽样 10,000 组 8 名参与者（有替换）以形成 10,000 名宏观参与者，用于计算 SDT 统计数据，然后用于推断统计。

我的问题是：

这样的解决方案在统计上有效吗？

如果有效，第二种方法（使用 Bootstrap）是否更可取？

这种方法是否有特定的名称，我可以使用它来查找更多参考资料？ （或相关关键词，如池化、合并、合并、聚合等）

我们如何解决每个宏观参与者内部的数据依赖性问题？


提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/651169/pooling-participant-data-to-resolve-limited-trials-per-condition-issues</guid>
      <pubDate>Tue, 16 Jul 2024 17:40:02 GMT</pubDate>
    </item>
    <item>
      <title>固定值与均匀分布混合的浓度界限</title>
      <link>https://stats.stackexchange.com/questions/651167/concentration-bounds-for-a-mixture-of-a-fixed-value-and-a-uniform-distribution</link>
      <description><![CDATA[假设我们有一个混合随机变量 $R= (1-p)X + pU$，其中 $X$ 只是一个值 $X \in [-\pi, \pi]$，$0 \leq p \leq 1$，以及 $U \sim \text{Uniform}[-\pi, \pi]$。即：单次试验以概率 $p$ 返回 $X$，否则以概率 $1-p$ 返回来自 $U$ 的样本。
我想给出（最好是双尾）浓度界限，以估计 $X$ 的附加准确度 $\epsilon$ 和置信度 $\delta$ 所需的试验次数。参数 $p$ 是预先知道的。如果我们将试验表示为 $R_i$ 并使用估计量 $\hat{R} = \frac{1}{n(1-p)} \sum_{i=1}^n R_i$，那么我认为，简单应用 Hoeffding 可以得出，
$$
n \geq \frac{2\pi p^2}{\epsilon^2(1-p)^2}\log\frac{1}{\delta},
$$
但是可以得出更严格的界限吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651167/concentration-bounds-for-a-mixture-of-a-fixed-value-and-a-uniform-distribution</guid>
      <pubDate>Tue, 16 Jul 2024 16:34:16 GMT</pubDate>
    </item>
    <item>
      <title>如何培养对统计方法的直观理解，以及“知道”使用哪种测试、为什么以及如何解释结果的能力[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651165/how-does-one-develop-an-intuitive-understanding-of-statistical-methods-and-the-a</link>
      <description><![CDATA[这不是数学或编码问题。如果这不是讨论这个问题的论坛，请原谅，如果我需要在其他地方提问，请告诉我。
我拥有数据科学硕士学位，并且已经担任数据库分析师一年了。我在一个团队中从事学术界的医学科学研究，该团队使用住院数据对某些医疗状况、治疗、医院实践和结果进行研究。
我在团队中的主要角色更多的是项目的数据管理方面。我通常会得到研究问题的概述和定义该研究队列的标准列表，然后我使用这些规范来构建我们的队列并执行数据清理和正确构建数据所需的任何数据转换。
然后，我通常会计算最终输出数据集的基本汇总统计数据，以广泛了解该队列。这些通常只是符合某些条件的患者数量的简单计数，我们稍后会对其进行分析。
有时我会对某些变量进行一些卡方或 t 检验，或者我会负责执行数据可视化任务，但任何进一步的统计分析往往会传递给其他人，或者如果我要做，团队中拥有博士学位或医学博士学位或两者兼有的人会在验证我的数据和流程后告诉我该怎么做。
我的问题是，经过所有这些培训、这么多年、所有这些经验、我参加过无数次解释这些事情的课程后，我仍然觉得，如果我足够幸运地掌握了一个测试的工作原理（比如线性回归）、我们为什么使用它、它告诉我们什么以及如何解释它，我永远也记不住这些知识，更糟糕的是，这些知识从一开始就很少能记住。
我想发展这种基本的理解，并最终直觉知道在什么情况下使用哪种测试以及为什么使用，数据结构和统计方法的选择与假设之间的关系，理解为模型设置的参数的复杂性和原因的能力，如何解释结果，以及所有基础概念，如方差和协方差、标准误差和残差以及不同类型的影响和解释所有这些的数学等等。
感觉它只是某些人可以掌握的一种不同的语言，而我不是其中之一。或者我只是太懒了，不愿意花时间和精力去精通。或者我希望的情况是，我只是还没有找到正确的策略来学习这些东西，而传统的课堂和讲座形式对我来说，对于学习这些东西来说并不有效。
我知道这可能和其他事情一样，我只需要练习等等。我同意这一点，但我也想听听你的想法和建议，以及你在发展统计掌握过程中的个人经验。当然，还有天生能力的因素，所以除了天生的统计天才之外，你认为还有什么可以帮助人们在这方面做得更好？我觉得这是我在这个领域发展事业的下一步。]]></description>
      <guid>https://stats.stackexchange.com/questions/651165/how-does-one-develop-an-intuitive-understanding-of-statistical-methods-and-the-a</guid>
      <pubDate>Tue, 16 Jul 2024 16:12:02 GMT</pubDate>
    </item>
    <item>
      <title>对平稳性和单位根概念感到困惑</title>
      <link>https://stats.stackexchange.com/questions/651164/confused-about-the-stationarity-and-unit-root-concepts</link>
      <description><![CDATA[假设我考虑一个白噪声过程，根据定义，它是平稳的。
我对以下事实感到困惑：如果我使用 Dickey-Fuller 检验，从技术上讲，我应该无法拒绝零假设。
这是假设该序列是自回归过程的结果。例如，如果我考虑围绕确定性趋势的白噪声过程，也会发生同样的事情。
在这种情况下，我可以使用带漂移的 DF 检验，但如果我进行数学运算，则根据构造，我的 DF 检验中的系数 $\gamma$ 将等于 0。
因此，即使该序列围绕 q 趋势平稳，我也会未通过测试。
我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/651164/confused-about-the-stationarity-and-unit-root-concepts</guid>
      <pubDate>Tue, 16 Jul 2024 16:11:23 GMT</pubDate>
    </item>
    <item>
      <title>如何确定图形套索的 lambda？</title>
      <link>https://stats.stackexchange.com/questions/651161/how-to-determine-lambda-for-graphical-lasso</link>
      <description><![CDATA[我正在尝试弄清楚如何确定 glasso 的 lambda。
我使用的是从简单套索回归 (cv.glmnet) 获得的 lambda，但后来发现这样做可能不太好，因为 lambda 是根据独立变量矩阵确定的，以预测一个因变量。相比之下，glasso 不会只测试这种关系，因为重要的是所有变量之间的关系，对吧？
我发现有人在 9 年前提出了与我完全相同的问题。我想知道 R 中是否还有除了 python 命令之外的其他东西可以确定这个 lambda？
如何对 glasso 执行交叉验证以在 R 中选择 lambda]]></description>
      <guid>https://stats.stackexchange.com/questions/651161/how-to-determine-lambda-for-graphical-lasso</guid>
      <pubDate>Tue, 16 Jul 2024 15:58:20 GMT</pubDate>
    </item>
    <item>
      <title>评估癌症监测中新生物标志物的实施和性能</title>
      <link>https://stats.stackexchange.com/questions/651160/assessing-the-implementation-and-performance-of-a-new-biomarker-in-cancer-survei</link>
      <description><![CDATA[问题：评估癌症监测中新生物标志物的实施和性能
在旨在检测高风险人群中特定类型癌症的监测计划中，生物标志物 A 和超声 (US) 每半年使用一次。如果 A 或 US 返回阳性结果，则进行确认测试。
一项新研究旨在评估另一种生物标志物 G，与 US 一起使用。由于在 G 的性能得到验证之前我们不能改变标准途径，因此研究中的所有参与者都将接受 A、G 和 US 的测试。如果这些测试中的任何一个返回阳性结果，患者将接受确认测试。由于确认测试的成本高昂，因此不会对所有指数测试结果为阴性的人进行该测试（部分验证）。
生物标志物 G 结合了 A 以及其他成分来检测癌症。因此，G 和 A 是相关的，尽管相关程度未知。根据 Chan 等人的研究（“Elecsys PIVKA-II 和 Elecsys AFP 检测在肝细胞癌诊断中的性能评估”，doi: 10.1002/jgh3.12720），G 比单独的 A 具有更高的灵敏度。将这些发现与 Tzartzeva 等人的荟萃分析（“监测成像和甲胎蛋白用于早期检测肝硬化患者中的肝细胞癌：荟萃分析”，doi:10.1053/j.gastro.2018.01.064）进行比较，似乎 G 也比 A 和 US 的组合具有更高的灵敏度和特异性。但是，没有研究直接比较 G/G+US 与 A/A+US。
这种比较对于评估测试准确性和成本效益至关重要。直觉上，G+US 的灵敏度会比 A+US 更好，尽管考虑到 A 的高特异性，G+US 的特异性可能会更低。但是，这个假设需要检验。
问题：

将这项研究简化为比较 G 与 A 是否合适？
有什么方法可以最好地证明 G+US 优于 A+US？我们应该重点比较这两种组合的灵敏度吗？或者，考虑到 G 包括 A，有没有一种方法可以显示 G 在检测准确性方面的附加值？
这种比较需要多大的样本量？
如果比较灵敏度是合适的，那么最好的样本量计算方法是什么？

我找到了吴 (2024) 的一篇论文，题为“当金标准随机缺失时，比较两种筛选测试的样本量计算” (doi: 10.1002/sim.10109)，提出了简化的样本量计算，用于比较配对诊断测试和部分验证，包括那些指数测试为阴性的人没有接受验证的情况。所有方法都考虑了两个指数测试之间的相关性。然而，当指数测试之间的相关性很高时，一种方法被认为是不合适的，这可能与我们的情况有关。这是相关研究的链接：(https://www.sciencedirect.com/science/article/pii/S0167947308003782)。我不确定这是否也适用于其他方法。
对这些问题的任何见解都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/651160/assessing-the-implementation-and-performance-of-a-new-biomarker-in-cancer-survei</guid>
      <pubDate>Tue, 16 Jul 2024 15:40:59 GMT</pubDate>
    </item>
    <item>
      <title>我是否正确构建了 Neyman 正交分数？</title>
      <link>https://stats.stackexchange.com/questions/651159/have-i-constructed-the-neyman-orthogonal-score-correctly</link>
      <description><![CDATA[我正在尝试使用 Chernozhukov 等人 (2018) 的 2.2 节为泊松 m 估计量构建一个 Neyman 正交分数。我做对了吗？如果是这样，有人能帮我展示/证明它在分析上是 Neyman 正交的吗？
考虑一个一般的指数模型
\begin{equation}
\mathbb{E}[y_{ijt} | x_{ijt}, \alpha_{it}, \gamma_{jt}, \eta_{ij}] = \exp(x_{ijt} \beta + \alpha_{it} + \gamma_{jt} + \eta_{ij}),
\end{equation&gt;
以及最大化问题
\begin{equation}
\max_{\beta \in \mathcal{B}, \theta \in \Theta} \mathbb{E} [l(y; \beta, \theta)],
\end{equation&gt;
其中我将回归量拆分为感兴趣的参数$x_{ijt}&#39; \beta$和固定效应（或干扰参数），$z_{ijt}&#39; \theta$。泊松
（伪）对数似然函数由以下公式给出：
\begin{equation}
l(y; \beta, \theta) = \sum_{i=1}^n \left( y_{ijt} (x_{ijt}&#39; \beta + z_{ijt}&#39; \theta) - \exp(x_{ijt}&#39; \beta + z_{ijt}&#39; \theta) - \ln \Gamma (y_{ijt} + 1) \right)。
\end{equation
奈曼正交分数
现在考虑新的分数函数，我们将其称为奈曼正交分数，
\begin{equation}
\psi(y; \beta, \eta) = \partial_\beta l(y; \beta, \theta) - \mu \partial_\theta l(y; \beta, \theta),
\end{equation
其中 $\mu$ 是 $d_\beta \times d_\theta$ 正交化参数矩阵，其真实值 $\mu_0$ 可解方程
$
J_{\beta\theta} - \mu J_{\theta\theta} = 0
$
对于
$
J = 
\begin{pmatrix}
J_{\beta \beta} &amp; J_{\beta \theta}\\
J_{\theta \beta} &amp; J_{\theta \theta}
\end{pmatrix}
$
并且当$J_{\theta \theta}$可逆时，有唯一解
$
\mu_0 = J_{\beta\theta} J_{\theta \theta}^{-1}。
$
偏导数
给定对数似然函数，我们有关于$\beta$的偏导数：
\begin{equation}
\partial_\beta l(y; \beta, \theta) = X&#39; \left( Y - \exp(X \beta + Z \theta) \right),
\end{equation&gt;
以及关于$\theta$的偏导数：
\begin{equation}
\partial_\theta l(y; \beta, \theta) = Z&#39; \left( Y - \exp(X \beta + Z \theta) \right),
\end{equation
其中 $\exp(X \beta + Z \theta)$ 是一个 $n \times 1$ 列向量，需要将其对角化为 $n \times n$ 矩阵才能进一步求导，我们将其称为 $D$。
矩阵 $J$ 的元素
我们计算 $J_{\beta \theta}$ 如下：
\begin{equation}
J_{\beta \theta} = \mathbb{E}\left[ -\partial_\beta \partial_\theta l(y; \beta, \theta) \right] = \mathbb{E}\left[ X&#39; D Z \right],
\end{equation&gt;
并计算 $J_{\theta \theta}$ 如下：
\begin{equation}
J_{\theta \theta} = \mathbb{E}\left[ -\partial_\theta^2 l(y; \beta, \theta) \right] = \mathbb{E}\left[ Z&#39; D Z \right].
\end{equation
计算$\mu_0$
假设$J_{\theta \theta}$可逆，我们计算$\mu_0$：
$
\mu_0 = J_{\beta\theta} J_{\theta\theta}^{-1} = \mathbb{E}\left[ X&#39; D Z \right] \left(\mathbb{E}\left[ Z&#39; D Z \right]\right)^{-1}。
$
Neyman 正交得分
最后，我们构建 Neyman 正交得分函数：
$
\psi(y; \beta, \eta) = \partial_\beta l(y; \beta, \theta) - \mu \partial_\theta l(y; \beta, \theta)
$
用 $\partial_\beta l(y; \beta, \theta)$、$\partial_\theta l(y; \beta, \theta)$ 和 $\mu_0$ 的表达式代入：
\begin{equation}
\psi(y; \beta, \eta) = X&#39; \left( Y - \exp(X \beta + Z \theta) \right) - \left( \mathbb{E}\left[ X&#39; D Z \right] \left( \mathbb{E}\left[ Z&#39; D Z \right] \right)^{-1} \right) Z&#39; \left( Y - \exp(X \beta + Z \theta) \right)。
\end{equation&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/651159/have-i-constructed-the-neyman-orthogonal-score-correctly</guid>
      <pubDate>Tue, 16 Jul 2024 15:10:17 GMT</pubDate>
    </item>
    <item>
      <title>理解可忽略性和混杂变量</title>
      <link>https://stats.stackexchange.com/questions/651158/understanding-ignorability-and-confounding-variables</link>
      <description><![CDATA[我正在阅读使用回归和分层模型进行数据分析，对可忽略性的概念感到困惑。书中的描述似乎说了不同的事情。

换句话说，
我们不一定期望任何两个（学校）班级有相同的概率
接受补充版本的治疗。但是，我们预期任何两个（学校）班级在混杂协变量（即治疗前变量；在我们的例子中，是平均预测试分数）水平相同的情况下，接受补充版本的治疗的概率相同。


思考可忽略性假设的第三种方式是，它要求我们控制所有混杂协变量，即与治疗和结果相关的预处理变量。

对我来说，第一个陈述似乎表明，在任何给定的混杂变量水平内（例如，对于具有低/中/高预测试分数的学生），治疗与控制的分布应该大致相等。也就是说，如果预测试分数低的学生接受治疗的概率与不接受治疗的概率相同，那么接受治疗的预测试分数低的学生人数应该大致等于不接受治疗的人数。但是，这通常（几乎按照定义？）不适用于混杂变量。在大多数情况下，混杂变量之所以混杂，是因为在某些混杂因素水平上接受治疗的单位多于其他水平。那么，如果存在任何混杂变量，即使它们受到控制，可忽略性又如何能得到满足呢？
在书中，他们还写道：

这表明，一旦我们以混杂协变量 X 为条件，潜在结果 (y0, y1) 的分布在治疗变量 T 的各个水平上都是相同的。

这 ^ 似乎与 此处的解释 非常吻合。鉴于此定义，我想知道，是否真的可以确定可忽略性是否得到满足？有哪些方法可以确定是否满足？]]></description>
      <guid>https://stats.stackexchange.com/questions/651158/understanding-ignorability-and-confounding-variables</guid>
      <pubDate>Tue, 16 Jul 2024 15:09:39 GMT</pubDate>
    </item>
    <item>
      <title>当计数主要为零时，标准负二项回归？</title>
      <link>https://stats.stackexchange.com/questions/651155/standard-negative-binomial-regression-when-counts-are-mainly-zeros</link>
      <description><![CDATA[这个问题肯定已经被问过很多次了，但我找不到答案。
我对何时使用零膨胀负二项回归与标准负二项回归感到非常困惑。
我正在比较两组受试者生病的次数。零是真正的零，因为我们设计的实验使我们拥有所有相关数据。然而，大约三分之二的人在测量期间没有生病，这意味着有“过多的零”。
我现在已经阅读了很多资料，这些资料说零膨胀负二项回归用于“过多的零计数”，但它也适用于数据生成过程意味着它们不是真正的零（或者零不可能是零以外的任何东西）的模型。我的实验不是这种情况。因此，我不确定我是否可以使用常规负二项回归。有人可以建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651155/standard-negative-binomial-regression-when-counts-are-mainly-zeros</guid>
      <pubDate>Tue, 16 Jul 2024 14:19:10 GMT</pubDate>
    </item>
    <item>
      <title>具有累积距离的 GLMM</title>
      <link>https://stats.stackexchange.com/questions/651174/glmm-with-cumulative-distances</link>
      <description><![CDATA[我计算了每个人累计的行进距离。目的是使用 R 包 ggplot2 将数据以趋势曲线的形式表示出来。但是，数据太过分散，导致趋势线不准确，有时还会下降。我想知道检查是否可以使用广义线性混合效应模型 (GLMM) 或模型来表示男女之间的差异并对其进行测试是否有用。
以下数据框代表了所讨论的数据：
library(ggplot2)

num_ids &lt;- 30

generate_data_for_id &lt;- function(id) {
num_observations &lt;- sample(1:20, 1)
distances &lt;- runif(num_observations, min = 1, max = 5) 
cumual_distances &lt;- cumsum(distances)
time_since_release &lt;- seq_len(num_observations) - 1
sex &lt;- sample(c(&quot;female&quot;, &quot;male&quot;), 1) 

data.frame(
ID = rep(id, num_observations), 
Distance = distances,
Cumulative_Distances_km =cumulative_distances,
Time_Since_Release = time_since_release,
Sex = rep(sex, num_observations)
)
}

all_data &lt;- do.call(rbind, lapply(1:num_ids, generate_data_for_id))

all_data_female &lt;- subset(all_data, all_data$Sex==&quot;female&quot;)
all_data_male &lt;- subset(all_data, all_data$Sex==&quot;male&quot;)

以下是我表示数据的方式

female_dist_max &lt;- ggplot() +
geom_line(data = all_data_female, aes(x = Time_Since_Release，y = Cumulative_Distances_km，color = as.factor(ID))，size = 0.4，linetype=&quot;dashed&quot;，alpha=0.5) +
geom_smooth(data = all_data_female，aes(x = Time_Since_Release，y = Cumulative_Distances_km，group = 1)，method = &quot;loess&quot;，color = &quot;#f8766dff&quot;，size = 0.7，se = TRUE，span = 1) +
labs(x = &quot;Time_since_release (days)&quot;，y = &quot;Cumulative distance (km)&quot;，color = &quot;ID&quot;) +
theme_minimal() 
print(female_dist_max)

male_dist_max &lt;- ggplot() +
geom_line(data = all_data_male, aes(x = Time_Since_Release, y = Cumulative_Distances_km, color = as.factor(ID)), size = 0.4, linetype=&quot;dashed&quot;, alpha=0.5) +
geom_smooth(data = all_data_male, aes(x = Time_Since_Release, y = Cumulative_Distances_km, group = 1), method = &quot;loess&quot;, color = &quot;#f8766dff&quot;, size = 0.7, se = TRUE, span = 1) +
labs(x = &quot;Time_since_release (days)&quot;, y = &quot;Cumulative distance (km)&quot;, color = &quot;ID&quot;) +
theme_minimal()

print(male_dist_max)


我想要另一种方法来表示这些距离并测试男性和女性之间的差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/651174/glmm-with-cumulative-distances</guid>
      <pubDate>Tue, 16 Jul 2024 09:54:25 GMT</pubDate>
    </item>
    <item>
      <title>风险函数怎么会是负数呢？</title>
      <link>https://stats.stackexchange.com/questions/651100/how-can-a-hazard-function-be-negative</link>
      <description><![CDATA[我一直在阅读R 中的生存分析，这是我为独立学习而找到的一本电子书，但遇到了一个困惑。他们对风险函数的定义如下：

其中 T 是事件时间或正确审查时间中先到的那个。分子是概率，因此是非负的，我假设我们应该将 δ 取为正，因为当 δ ≤ 0 时，P(t &lt; T &lt; t + δ) = 0。因此，风险函数似乎应该是非负的。然而，在第 3 章关于参数建模的文章中，他们展示了以下观察到的瞬时风险函数的示例：

这与风险函数定义如何一致？风险函数为负的解释是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/651100/how-can-a-hazard-function-be-negative</guid>
      <pubDate>Mon, 15 Jul 2024 19:45:32 GMT</pubDate>
    </item>
    </channel>
</rss>