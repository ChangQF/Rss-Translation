<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 16 Dec 2023 06:16:18 GMT</lastBuildDate>
    <item>
      <title>用于重复测量设计的基于精度的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/635034/precision-based-sample-size-calculation-for-repeated-measures-design</link>
      <description><![CDATA[请寻求帮助！
我正在根据估计的精度来计算一项研究所需的样本量，但我很难弄清楚到底如何做。主要让我失望的是 1) 需要考虑测量误差，2) 需要考虑同一参与者的重复测量。另外，我想根据估计精度而不是统计显着性来计算样本量。
设计：在基线时测量二头肌厚度，然后参与者进行 8 组阻力训练。每组结束后，参与者将被要求提供“感知的肌肉肿胀”的主观评分。并再次测量肌肉厚度。这样，我们最终将得到基线肌肉厚度，以及每个参与者的主观肌肉肿胀和测量的肌肉厚度的 8 个后续值。
计划分析：1）主观肌肉肿胀评分与测量的肌肉肿胀之间的相关性。 2) 检查随着进行更多组阻力训练，主观评分和测量的肌肉厚度的变化。
根据之前也使用同一设备测量肌肉厚度的研究，我收集了测量设备的典型重测 ICC 为 ~0.988，典型标准偏差为 ~4.96，以及测量的典型标准误差约为 0.459。我的目标是达到 95% 的置信度，精度高于测量误差（也就是说，我希望有很高的信心，如果观察到时间点之间存在任何差异，它们很可能是真正的差异，而不是简单地通过测量误差来解释）。
我不确定如何将所有这些整合到基于精度的样本量计算中。正如我上面提到的，我需要考虑测量误差和每个参与者的重复测量。一些在线阅读还提醒我，可能需要考虑这些重复测量中的相关模式，我认为在这种情况下，最好将其描述为线性指数自回归 (LEAR) 或一阶自回归 (AR1)。
如果有人有任何意见或建议，我们将不胜感激！非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/635034/precision-based-sample-size-calculation-for-repeated-measures-design</guid>
      <pubDate>Sat, 16 Dec 2023 00:07:58 GMT</pubDate>
    </item>
    <item>
      <title>几年内性别之间的多重比较方差分析或 t 检验？图基事后？邦费罗尼？</title>
      <link>https://stats.stackexchange.com/questions/635030/multiple-comparisions-between-sexes-within-years-anova-or-t-tests-tukey-posthoc</link>
      <description><![CDATA[我正在进行一项遗传分析，比较 2013-2019 年雄性和雌性动物之间的 Fst 和相关系数值。每年分为季度，所以我总共有 40 个季度类别。每年的个体数量有所不同，每年的男性和女性数量也不相等。我想看看每个季度内和每个季度之间的性别价值观是否有所不同。我使用的是 R，所以我做了一个线性模型（Fst ~ Sex*Year），然后使用 Tukey 事后测试对模型进行方差分析，以查看每个季度内性别之间的比较。
Fst.test = lm(Fst ~ 性别*年份，数据 = Fst)
Fst.aov = aov(Fst.test)
摘要(Fst.aov)
Fst.posthoc = TukeyHSD(Fst.aov)

我对每个季度内的性别进行的许多事后比较并没有显着差异，尽管数值看起来相当不同。所以我随机选择了一些并做了标准的 t 检验，它们是显着的。
我应该在这里做哪些统计？方差分析和图基事后检验是最好的方法还是我应该为每个季度进行多次 t 检验并进行某种修正？如果是这样，哪个更正，我记得几年前做过 Bonferroni...]]></description>
      <guid>https://stats.stackexchange.com/questions/635030/multiple-comparisions-between-sexes-within-years-anova-or-t-tests-tukey-posthoc</guid>
      <pubDate>Fri, 15 Dec 2023 22:35:23 GMT</pubDate>
    </item>
    <item>
      <title>局部平滑器的浓度不等式 (Nadaraya Watson)</title>
      <link>https://stats.stackexchange.com/questions/635028/concentration-inequalities-for-local-smoothers-nadaraya-watson</link>
      <description><![CDATA[令 $m(X)=E(Y|X)$ 为随机设计的回归函数，并令  $\hat{m}_h(x)$
\begin{方程}
\hat{m}_h(x)=\frac{\sum_{i=1}^n K_h\left(x-x_i\right) y_i}{\sum_{i=1}^n K_h\left(x- x_i\右）}
\end{方程}
是 Nadaraya Watson 估计器，带宽为 h。对于任何 $\epsilon &gt;0$，我想绑定 Nadaraya Watson 估计器的修改。我那方面，我首先要束缚
\begin{方程}
P (|\hat{m}_h(x) - m(x)|&gt;\epsilon)。
\end{方程}
我试图避免马尔可夫/切比雪夫等不等式和收敛结果的速度。我正在寻找集中不等式的证明。我正在通过偏差方差分解尝试 Hoeffding 不等式，但遇到了困难。
任何人都可以帮助我迈出有用的第一步吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635028/concentration-inequalities-for-local-smoothers-nadaraya-watson</guid>
      <pubDate>Fri, 15 Dec 2023 21:51:45 GMT</pubDate>
    </item>
    <item>
      <title>对于软标签使用 KL 散度而不是交叉熵更好吗？</title>
      <link>https://stats.stackexchange.com/questions/635027/is-it-better-to-use-kl-divergence-for-soft-labels-instead-of-cross-entropy</link>
      <description><![CDATA[所以我正在阅读这篇论文：在 Fuse 之前对齐：利用动量蒸馏进行视觉和语言表示学习 (2017) 由 Junnan Li 等人提出，他们使用 KL 散度执行对比损失。
$$
L_{\text{ITC}} = (1 - \alpha) L_{\text{对比度}} + \frac{\alpha}{2} \left[ \text{KL} \left( q^{i2t} \平行 p^{i2t} \right) + \text{KL} \left( q^{t2i} \平行 p^{t2i} \right) \right]
$$
在此方程中，LITC-base​是基础图像文本对比损失，$\alpha$是权重因子，DKL表示KL散度，&lt; span class=&quot;math-container&quot;&gt;$q^{i2t}$ 和 $q^{t2i}$ 是预测分布（从图像到分别为文本和文本到图像），以及 $p^{i2t}$ 和 $p^{t2i}$&lt; /span&gt; 是 KL 散度项的目标分布。

但是，在实现中，交叉熵使用损失，而不是明确地使用KL散度。KL散度用于与软标签的对比损失。这种方法理论上可以避免损失图中出现大的恒定熵，如图所示，即使在反向传播时不使用熵，也可能会掩盖减少。
但是，该实现利用了交叉熵损失。这就提出了为什么选择交叉熵而不是论文中指定的 KL 散度的问题，特别是考虑到对解释训练损失曲线的影响，因为由于高熵掩盖了 KL 散度和论文，我们将无法看到 KL 散度的减少明确提到使用软伪标签进行对比学习。这是一个实际的实施决策，还是反映了模型学习过程的更深层次？
与 torch.no_grad():
            self._momentum_update()
            image_embeds_m = self.visual_encoder_m(图像)
            image_feat_m = F.normalize(self.vision_proj_m(image_embeds_m[:,0,:]),dim=-1)
            image_feat_all = torch.cat([image_feat_m.t(),self.image_queue.clone().detach()],dim=1)
            text_output_m = self.text_encoder_m.bert（text.input_ids，attention_mask = text.attention_mask，
                                                return_dict = True, 模式 = &#39;文本&#39;)
            text_feat_m = F.normalize(self.text_proj_m(text_output_m.last_hidden_​​state[:,0,:]),dim=-1)
            text_feat_all = torch.cat([text_feat_m.t(),self.text_queue.clone().detach()],dim=1)

            sim_i2t_m = image_feat_m @ text_feat_all / self.temp
            sim_t2i_m = text_feat_m @ image_feat_all / self.temp

            sim_targets = torch.zeros(sim_i2t_m.size()).to(image.device)
            sim_targets.fill_diagonal_(1)

            sim_i2t_targets = alpha * F.softmax(sim_i2t_m, dim=1) + (1 - alpha) * sim_targets
            sim_t2i_targets = alpha * F.softmax(sim_t2i_m, dim=1) + (1 - alpha) * sim_targets

        sim_i2t = image_feat @ text_feat_all / self.temp
        sim_t2i = text_feat @ image_feat_all / self.temp
                             
        loss_i2t = -torch.sum(F.log_softmax(sim_i2t, dim=1)*sim_i2t_targets,dim=1).mean()
        loss_t2i = -torch.sum(F.log_softmax(sim_t2i, dim=1)*sim_t2i_targets,dim=1).mean()
]]></description>
      <guid>https://stats.stackexchange.com/questions/635027/is-it-better-to-use-kl-divergence-for-soft-labels-instead-of-cross-entropy</guid>
      <pubDate>Fri, 15 Dec 2023 21:37:22 GMT</pubDate>
    </item>
    <item>
      <title>二项分布样本的方差估计器</title>
      <link>https://stats.stackexchange.com/questions/635019/estimator-of-variance-for-a-binomially-distributed-sample</link>
      <description><![CDATA[我想对一些数据进行贝叶斯分析。假设我们有一个样本，我们认为该样本来自二项式总体。我们有 $m$ 个观察值
$$X_i \sim Bin(n,p) \text{ 对于某些 } i \in \{1,2,\dots,m\}$$
我选择了之前的测试版本。我不确定如何选择参数以使我的分布更好地符合我的信念。我假设我会取样本均值并将贝塔先验的均值设置为等于该数字。但我不确定如何计算方差。任何人都可以提供建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/635019/estimator-of-variance-for-a-binomially-distributed-sample</guid>
      <pubDate>Fri, 15 Dec 2023 17:55:09 GMT</pubDate>
    </item>
    <item>
      <title>相对差异的置信区间</title>
      <link>https://stats.stackexchange.com/questions/635033/confidence-interval-of-a-relative-difference</link>
      <description><![CDATA[我知道两个样本 $X_1$ 和 $X_2$，但我不知道这些值。如何计算平均值相对差的置信区间界限$(m_1-m_2)/m_1$？
当我尝试进行直接计算时，我必须计算比率的方差。在线发表的论文中提供了一个基于泰勒级数的公式，但在我的情况下，相应的一阶近似并不准确，因为与平均值相比方差相当大。
我想到了一种替代方案，即将参考样本 $X_1$ 的均值和方差视为理论常数值而不是随机变量。这类似于将 $X_2$ 与理论分布进行比较，而不是比较两个样本。在这种情况下，不再有比率，但我不确定该方法是否有意义。
感谢您的反馈]]></description>
      <guid>https://stats.stackexchange.com/questions/635033/confidence-interval-of-a-relative-difference</guid>
      <pubDate>Fri, 15 Dec 2023 13:58:15 GMT</pubDate>
    </item>
    <item>
      <title>我的非线性问题的最大似然估计量是多少？</title>
      <link>https://stats.stackexchange.com/questions/634974/what-is-the-maximum-likelihood-estimator-for-my-nonlinear-problem</link>
      <description><![CDATA[在区域 $0\leq x\leq 1$ 和 $0\leq y\leq 1$ 我在 $(x_b,y_b)$ 中放置了 1 个无线电广播电台和 N 个接收器。广播公司的立场尚不清楚。
然而，每个接收器的位置是已知的： $(x_i,y_i)$ 以及从接收器到广播器的距离：$d_i$。
距离测量中存在一些噪声，我假设这些噪声呈正态分布，均值为 0，并且所有接收器的方差相同：
$$
\sqrt{(x_i - x_b)^2+(y_i - y_b)^2} = d_i + \epsilon_i
$$
在哪里
$$
\epsilon_i \sim \mathcal{N}(0,\,\sigma^{2})
$$
我的目标是估计无线电广播公司最可能的位置：$(x_b,y_b)$。
我想通过将其表述为一个最小化问题来做到这一点。
到目前为止，我正在最小化：
$$
SE = \sum_i \left[\sqrt{(x_i - x_b)^2+(y_i - y_b)^2} - d_i\right]^2
$$
我读到，对于线性回归，最小二乘估计器也是正态分布误差假设下的最大似然估计器。
但是这对于我的非线性问题也适用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634974/what-is-the-maximum-likelihood-estimator-for-my-nonlinear-problem</guid>
      <pubDate>Fri, 15 Dec 2023 08:33:05 GMT</pubDate>
    </item>
    <item>
      <title>比率的自然对数和双向固定效应模型偏差</title>
      <link>https://stats.stackexchange.com/questions/634967/natural-log-of-ratios-and-two-way-fixed-effects-model-bias</link>
      <description><![CDATA[Bartlett 和 Partnoy (BP) (2020) 表明自然对数因变量（即比率）的 OLS 必须在 RHS 上包含 Ln（分母），以避免偏差（请参阅第 24-28 页），除非假设分子和分母具有精确的线性关系，即 &lt; (E1) 中的 span class=&quot;math-container&quot;&gt;$\beta_2 = 1$。这是因为 $Ln(ratio)$，例如 $Ln(\frac{GDP_{it}}{population_ {it}})$ 相当于 $Ln(GDP_{it})-Ln(population_{it})$。因此，任何在 LHS 上具有 $Ln(\frac{GDP_{it}}{population_{it}})$ 的 OLS 模型都隐式假设：
$$Ln(GDP_{i})= \beta_0 + X_i + 1Ln(population_{i}) + \epsilon_{i}$$
解决方案是在 RHS 上包含 $Ln(denominator)$，就像在 TWFE 5 中一样。他们不会在面板数据的上下文中讨论这些问题具有双向固定效应 (TWFE)，如 (E1)。
问题
在 OLS 背景下是否有任何理由怀疑 BP？ (E1) 和模型 TWFE 5 是否低于正确的模型来识别 TWFE 面板环境中治疗的无偏效应？ TWFE 2 模型确实给出了治疗的有偏系数吗？是否有任何方法文献在 OLS 或 TWFE 上下文中讨论 $Ln(ratio)$ 的问题？
在模型 TWFE 5 中，$\beta_2$ 并不接近 1，但在中为 $0.92$ OLS 版本没有单位FE的模型。在单位固定效应的背景下，我如何理解 BP 关于 $Ln(\frac{numerator}{denominator})$ 之间线性的观点？
下面的模型 TWFE 4 方程修正了线性假设的偏差：
$$
Ln(\frac{GDP_{it}}{人口_{it}}) = \beta_1 治疗_{it} + \beta_2 Ln(人口_{it}) + \lambda_{t} + \alpha_i + \epsilon_{it}
\标签{E1}
$$
双向固定效应模型：
&lt;前&gt;&lt;代码&gt;============================================== =================================
                                     因变量：
                 -------------------------------------------------- ---------
                  log_gdp log_gdp_pc (log_gdp-log_pop) log_gdp log_gdp_pc
                  TWFE 1 TWFE 2 TWFE 3 TWFE 4 TWFE 5
-------------------------------------------------- --------------------------
处理 -0.025 -0.025 0.059*** 0.059***
                            (0.028) (0.028) (0.020) (0.020)
                                                                            
log_pop -0.264*** -0.281*** -1.281***
                  (0.041) (0.042) (0.042)
                                                                            
-------------------------------------------------- --------------------------
TWFE 是 是 是 是 是
观察次数 1,155 1,155 1,155 1,155 1,155
R2 0.712 0.508 0.508 0.714 0.750
=================================================== =========================
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/634967/natural-log-of-ratios-and-two-way-fixed-effects-model-bias</guid>
      <pubDate>Fri, 15 Dec 2023 03:57:04 GMT</pubDate>
    </item>
    <item>
      <title>混合设计实验：中值缩减还是线性混合模型？</title>
      <link>https://stats.stackexchange.com/questions/634791/mixed-design-experiment-median-reduction-or-linear-mixed-model</link>
      <description><![CDATA[我从混合设计的声学定位实验中收集了数据，其中因素是人群（一个带有助听器 (HA)，一个带有人工耳蜗 (CI)）和条件，第一组人群有四个（带有左 HA、右 HA、两者 HA、无 HA），以及第二个群体的三个（左 CI、右 CI、两者 CI）。在每种情况下，对于 13 个收集的项目（目标定位答案）有 5 次重复测量。并非所有参与者都在每种情况下都进行了测试。我想分析不同条件下受试者内部、受试者之间以及人群之间的差异。混合方差分析不是一种选择，即使它可以容纳丢失的数据，因为数据严重倾斜，并且违反了球形和正态分布假设。我看到两种可能的选择：

通过中位数将每个参与者每个条件的重复测量值减少到一个值。在这种情况下，一些统计功效就会丧失。如何计算和报告效应大小或统计功效？考虑到通过这种减少，所执行的测试不是参数化的。
拟合线性混合效应模型，并随机截取受试者 ID。在这种情况下，没有直线的 Q-Q 图是否违反了必要的假设？如果关系比线性关系更复杂，LMM 是否是一个可行的选择？如果 Q-Q 图是线性的，我会选择 R，如下所示：

&lt;前&gt;&lt;代码&gt;
# 拟合混合效应模型
# - 响应：因变量
# - 总体：受试者间因素（2 个级别）
# - 条件：受试者内因素
# - subjectID：受试者的随机效应

模型 &lt;- lmer(响应 ~ 总体 * 条件 + (1 | subjectID), data = data)

我分析了四个不同的响应变量：头部距离、头部旋转、有符号误差和无符号误差。
平均值 + 2*标准差（针对每种条件）的异常值已被删除。数据已进行对数转换。
以下是 Q-Q 图、残差直方图以及残差与四个变量的拟合值的关系。四个变量残差的偏度值分别为：0.98、-2.69、-4.26、-0.58。











]]></description>
      <guid>https://stats.stackexchange.com/questions/634791/mixed-design-experiment-median-reduction-or-linear-mixed-model</guid>
      <pubDate>Wed, 13 Dec 2023 10:28:47 GMT</pubDate>
    </item>
    <item>
      <title>具有二元结果的纵向数据的变量选择</title>
      <link>https://stats.stackexchange.com/questions/633663/variable-selection-for-longitudinal-data-with-a-binary-outomce</link>
      <description><![CDATA[我有一个大型纵向数据集（100,000 观测值），其中包含固定 ID 和年份，以及大约 1000 特征（大多数数字和一些因子）。我一直在使用一小部分可用功能对此数据运行一些分类任务（随机森林、xgboost、svm）。我希望能够使用这些模型来进行一些特征选择/变量重要性，但是，使用全部或大多数可用预测变量运行这些模型似乎并不可行。
在纵向数据集的上下文中，我可以采用哪些可能的方法来选择相关特征，其中特征随 ID 的不同而变化，也随时间的变化而变化。
我是否要硬着头皮允许这些模型在所有功能上运行，然后检查变量重要性和其他指标？或者在对特征进行子集化之前我可以采取一些探索性数据分析步骤吗？
编辑：在特征子集上运行随机森林可能有意义吗，例如一次 100 个特征，因此 10 RF 模型并使用变量重要性对它们中的每一个进行了解，以了解我最终可以使用哪些预测因子？
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/633663/variable-selection-for-longitudinal-data-with-a-binary-outomce</guid>
      <pubDate>Mon, 11 Dec 2023 22:34:43 GMT</pubDate>
    </item>
    <item>
      <title>适当的统计测试来确定分类数据的内部凝聚力</title>
      <link>https://stats.stackexchange.com/questions/633558/appropriate-statistical-test-to-determine-internal-cohesion-of-a-categorical-dat</link>
      <description><![CDATA[我有一个主要由二进制变量组成的数据集，每行代表一名患者，每列代表一种疾病的症状。患者会勾选 1（如果出现症状），否则勾选 0。每个表代表一种疾病，如下所示：
表 1. 仅疾病 A

&lt;表类=“s-表”&gt;
&lt;标题&gt;

症状 1
症状 2
......
症状 N


&lt;正文&gt;

0
1
....
1


1
1
....
1


....
....
....
0


0
1
...
1




我想进行一项测试来确定患者是否来自同一人群，即他们的反应差异最小。理想情况下，患者应该对特定疾病有相同的症状，因为疾病通常以症状的形式表现出来，但实际上情况并非如此，因为有些人可能会经历这种情况，而另一些人则不会。
我正在寻找一个统计测试来显示患者的反应是一致的（反应是同质的），这表明几乎所有人都有相同的症状，如果患者的反应不一致，那么就需要再次调查原因.
我已经阅读过有关 phi 系数的内容，但它仅适用于两个二元变量，进一步阅读使我进行了卡方检验和多重对应分析，不幸的是，我很困惑这两者中哪一个是最合适的。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/633558/appropriate-statistical-test-to-determine-internal-cohesion-of-a-categorical-dat</guid>
      <pubDate>Sun, 10 Dec 2023 21:29:39 GMT</pubDate>
    </item>
    <item>
      <title>独立但非同分布随机变量的中心极限定理</title>
      <link>https://stats.stackexchange.com/questions/632592/central-limit-theorem-for-independent-but-non-identically-distributed-random-var</link>
      <description><![CDATA[我的问题是关于证明Lyapunov CLT（每个均值都是$0$，$\delta = 1$）。它类似于这个问题，但没有对遵循伯努利分布的随机变量进行任何假设。
这个想法是使用泰勒展开式：
$\psi_{X_1}(t) = 1 - \frac{1}{2}\mathbb{E}X_1^2t^2 - \frac{i}{6}\ mathbb{E}X_1^3t^3 + o(t^3)$。
与维基百科条目一样，定义 $s_n^2 = \Sigma_{i = 1}^n\sigma_i^2$。然后 $\psi_{X_1}(\frac{t}{s_n}) = 1 - \frac{1}{2}\mathbb{E}X_1^2\frac{t ^2}{s_n^2} - \frac{i}{6}\mathbb{E}X_1^3\frac{t^3}{s_n^3} + o(\frac{t^3}{s_n^ 3})$.
如果满足李亚普诺夫条件 ($\delta = 1$)，我会看到 $\lim_{n\ rightarrow\infty}\psi_{X_1}(\frac{t}{s_n}) = 1 - \frac{1}{2}\mathbb{E}X_1^2\frac{t^2}{s_n^2} + o(\frac{t^3}{s_n^3})$。
定义$S_n = X_1 + \dots + X_n$。如果随机变量是 i.i.d.，则缩放后方差为 $1$、$\psi_{\frac{S_n} {\sqrt{n}}}$ 涉及将泰勒展开式提高到 $n$ 次方。但由于随机变量分布不同，$\psi_{\frac{S_n}{s_n}}$ 是 $n$ 条款。如何操作它以便我可以使用 $e^x = \lim_{n\rightarrow\infty}(1 + \frac{x}{n})^n$&lt; /跨度&gt;？
（如何将 $s_n^2$ 除法转换为除以 $n$，这是通过在 i.i.d. 情况下对 $\sqrt{n}$ 进行平方来实现的吗？）]]></description>
      <guid>https://stats.stackexchange.com/questions/632592/central-limit-theorem-for-independent-but-non-identically-distributed-random-var</guid>
      <pubDate>Wed, 29 Nov 2023 06:56:54 GMT</pubDate>
    </item>
    <item>
      <title>GAMM 功耗分析</title>
      <link>https://stats.stackexchange.com/questions/618904/power-analysis-for-gamm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/618904/power-analysis-for-gamm</guid>
      <pubDate>Fri, 16 Jun 2023 06:13:19 GMT</pubDate>
    </item>
    <item>
      <title>当有更多样本可用时，后验概率可以大于 1 吗？</title>
      <link>https://stats.stackexchange.com/questions/585274/can-a-posterior-probability-be-larger-than-1-when-more-samples-are-available</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/585274/can-a-posterior-probability-be-larger-than-1-when-more-samples-are-available</guid>
      <pubDate>Fri, 12 Aug 2022 03:56:42 GMT</pubDate>
    </item>
    <item>
      <title>lifelines.CoxPHFitter - p值是如何计算的？</title>
      <link>https://stats.stackexchange.com/questions/581037/lifelines-coxphfitter-how-are-the-p-values-calculated</link>
      <description><![CDATA[我假设 lifelines.CoxPHFitter 在测试显着性时使用似然比检验（或者使用 Wald？）来计算 p 值。但我必须确定：是否有官方来源可以找到使用的测试？ （我没有成功搜索抛出生命线的文档）
lifelines.CoxPHFitter 在执行单变量和多变量 Cox 回归时是否使用相同的测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/581037/lifelines-coxphfitter-how-are-the-p-values-calculated</guid>
      <pubDate>Tue, 05 Jul 2022 23:13:20 GMT</pubDate>
    </item>
    </channel>
</rss>