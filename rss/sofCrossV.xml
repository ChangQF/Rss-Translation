<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 03 Jul 2024 15:16:03 GMT</lastBuildDate>
    <item>
      <title>如何知道什么样本量（细胞数量）足以确定高于阈值的细胞百分比？</title>
      <link>https://stats.stackexchange.com/questions/650407/how-to-know-what-sample-size-number-of-cells-is-sufficient-to-determine-what-p</link>
      <description><![CDATA[
我有一个包含不同细胞类型的样本（上面显示了一种细胞类型）。我为每个样本和细胞类型计算了一个阈值，表示非增殖细胞与增殖细胞。高于此阈值的细胞正在增殖，低于此阈值的细胞则不会增殖。我的问题是，我如何知道或确信我使用的样本大小或总细胞数是正确的？换句话说，我需要进行高于阈值的百分比计算的最小细胞数是多少，我该如何计算？我之所以问这个问题，是因为下图中的总细胞数为数千，但我的一些细胞类型的总细胞数为 100 甚至更少。非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/650407/how-to-know-what-sample-size-number-of-cells-is-sufficient-to-determine-what-p</guid>
      <pubDate>Wed, 03 Jul 2024 15:13:21 GMT</pubDate>
    </item>
    <item>
      <title>在逐步回归中选择自由度（R 中的 stepAIC 函数）</title>
      <link>https://stats.stackexchange.com/questions/650404/selecting-degrees-of-freedom-in-stepwise-regression-stepaic-function-in-r</link>
      <description><![CDATA[背景：我拥有多个集水区水质的数据，例如锌 (Zn) 的浓度。对于每个集水区，我还有一系列特征 (n=16)，例如平均海拔和坡度，或不同土地覆盖类型（例如城市、农业）的比例。
有很多方法可以选择哪些特征对于解释水质的变化最为重要，例如专家意见/理论、偏最小二乘回归、LASSO、弹性网络方法、岭回归和逐步回归。虽然使用逐步回归有很多缺点，但这是我目前使用的方法 [注意：此分析不用于研究，而用于教学目的，为批判性参与提供了机会]。
要在 R 中使用逐步回归，我首先要构建一个线性模型：
# 拟合线性模型，包括所有其他列 (~.) 作为独立变量
zn_model &lt;- lm(formula = Zn ~ ., data = model_df)

要执行逐步回归，我们可以使用 stats 包中的 step() 或 MASS 包中的 stepAIC()，这里使用后者：
# 逐步模型
step.model &lt;- stepAIC(zn_model, direction = &quot;both&quot;, 
trace = FALSE, k = 2)

根据文档，k 等于

用于惩罚的自由度数的倍数。只有 k = 2 才能给出真正的 AIC

这将返回以下输出：
系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 30.80991 24.60874 1.252 0.217845 
average_elevation 0.09583 0.03540 2.707 0.009926 ** 
average_rainfall -0.07308 0.01876 -3.895 0.000364 ***
average_aspect -0.06559 0.04378 -1.498 0.141969 
Arable_percent 0.35771 0.22094 1.619 0.113297 
Heath_percent 0.69317 0.28778 2.409 0.020706 * 
草地百分比 0.48670 0.21753 2.237 0.030897 * 
城市百分比 0.96455 0.22102 4.364 8.74e-05 ***
湿地百分比 0.52525 0.25851 2.032 0.048844 * 
沙地和泥地百分比 -0.10270 0.05353 -1.919 0.062181 . 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：41 个自由度上的 9.583

多重 R 平方：0.6017，调整后的 R 平方：0.524

F 统计量：8 和 41 个 DF 上的 7.744，p 值：2.881e-06

为了教学练习的目的，我想制作更简约的模型，删除不太重要的变量，在本例中为 average_aspect 和 arable_percent，以及其他可能的变量。
这可以通过增加用于惩罚的自由度来实现，例如：
# 逐步模型
step.model &lt;- stepAIC(zn_model, direction = &quot;both&quot;, 
trace = FALSE, k = 4)

这将产生以下内容：
系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 37.28031 9.70645 3.841 0.000374 ***
average_elevation 0.09429 0.02667 3.536 0.000940 ***
average_rainfall -0.05416 0.01581 -3.426 0.001299 ** 
Urban_percent 0.51266 0.09382 5.464 1.82e-06 ***
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：46 个自由度上的 10.09
多重 R 平方：0.5051，调整后的 R 平方：0.4728
F 统计量：3 和 46 DF 上的 15.65，p 值：3.751e-07

这是一个更简单的模型（只有 3 个独立变量），R2 的减少相对较小（0.6 -&gt; 0.5）。但是，没有明确的理由选择特定的 k 值，只能逐步增加，直到所有值都被视为“显著” （在上面的例子中，所有都是 p &lt; 0.05）。
Cross Validated 上的其他答案表明 k 的值可以更改，例如此处，但大多数其他示例使用 AIC（k = 2）或 BIC（k = log(n)）。
问题：暂时忽略逐步的更广泛问题，将 k 的值从标准 AIC 或 BIC 值更改是否合法？如果是，逐步增加 k 以产生所需的模型简约性是否也是可接受的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/650404/selecting-degrees-of-freedom-in-stepwise-regression-stepaic-function-in-r</guid>
      <pubDate>Wed, 03 Jul 2024 14:58:31 GMT</pubDate>
    </item>
    <item>
      <title>对于具有因子平滑相互作用的混合模型，gamm 和 gamm4 给出非常不同的平滑项结果</title>
      <link>https://stats.stackexchange.com/questions/650403/gamm-and-gamm4-give-very-different-smooth-term-results-for-mixed-models-with-fac</link>
      <description><![CDATA[我正在分析一个纵向数据集，该数据集包含两组（患者组与对照组；有序因子），其中包含随时间变化的脑容量数据。参与者在不同的年龄进入研究，并且有不同次数的随访和持续时间。我的目标是测试各组脑容量的纵向轨迹是否不同，我想考虑随机截距和斜率。
我一直在尝试不同的数据拟合方法（R 的 gam、gamm 和 gamm4），但它们都给出了不同的结果。我希望得到一些帮助，包括（1）纠正我的模型语法，（2）选择正确的函数，以及（3）找到一种进行显着性检验的方法（例如，我是否信任 summary(model) 结果，或者我应该进行简单与复杂嵌套模型比较）。
非常感谢任何帮助。谢谢！
gam：（long_age = 纵向年龄；性别 = 协变量，因子；受试者 = 受试者 ID）
gam_model &lt;- gam(volume ~ 
s(long_age) + 
s(long_age, by = ExperimentalGroup) + 
ExperimentalGroup + 
sex + 
s(subject, bs = &quot;re&quot;) +
s(subject, long_age, bs = &quot;re&quot;),
data = 数据集，
method = &quot;REML&quot;)

gamm：（根据其他发育神经科学论文使用 k = 4，但我不确定）
gamm_model &lt;- gamm(volume ~ 
ExperimentalGroup + 
s(long_age, k = 4, fx = TRUE) + 
s(long_age, by = ExperimentalGroup, k = 4, fx = TRUE) + 
sex,
random = list(subject = ~ 1 + long_age),
data = dataset)

gamm4:
gamm4_model &lt;- gamm4(volume ~ 
s(long_age, k = 4, bs = &quot;cr&quot;) +
s(long_age, by = ExperimentalGroup, k = 4, bs = &quot;cr&quot;) + 
ExperimentalGroup + 
sex, 
data = dataset,
random = ~(long_age|subject),
REML = TRUE)

调用 summary(model) 可得到以下结果：（为简洁起见，省略了 formula）
请注意，平滑的 p 值变化很大术语：
gam：
系列：高斯
链接函数：身份
参数系数：
估计标准误差t值Pr（&gt; | t |）
（截距）0.275693 0.002422 113.814 &lt; 2e-16 ***
ExperimentalGroup.L 0.006638 0.002581 2.571 0.011 *
Sex1 -0.001611 0.003484 -0.462 0.644
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值 
s(long_age) 1.000 1.000 30.814 &lt; 2e-16 ***
s(long_age):ExperimentalGroup1 2.749 2.911 10.762 7.68e-06 ***
s(Subject) 49.457 78.000 7.677 0.000171 ***
s(Subject,long_age) 13.614 79.000 2.940 0.050874 . 
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = 0.778 偏差解释 = 84.3%
-REML = -656.06 尺度估计 = 9.5812e-05 n = 236

gamm:
系列：高斯
链接函数：恒等

参数系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 0.276129 0.002389 115.585 &lt;2e-16 ***
ExperimentalGroup.L 0.006532 0.002567 2.545 0.0116 * 
Sex1 -0.002067 0.003406 -0.607 0.5445 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值 
s(long_age) 3 3 9.485 6.28e-06 ***
s(long_age):ExperimentalGroup1 3 3 2.907 0.0355 * 
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = 0.325 
尺度估计 = 9.1442e-05 n = 236

最后是 gamm4：
系列：高斯 
链接函数：恒等 

参数系数：
估计标准误差 t 值 Pr(&gt;|t|) 
（截距）0.275845 0.001866 147.833 &lt; 2e-16 ***
实验组.L 0.006708 0.002058 3.260 0.00128 ** 
性别1 -0.002079 0.001588 -1.309 0.19186 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值 
s(long_age) 1.000 1.000 117.01 &lt;2e-16 ***
s(long_age):ExperimentalGroup1 2.893 2.893 50.18 &lt;2e-16 ***
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = 0.341 
lmer.REML = -1320.1 Scale est. = 9.1773e-05 n = 236
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/650403/gamm-and-gamm4-give-very-different-smooth-term-results-for-mixed-models-with-fac</guid>
      <pubDate>Wed, 03 Jul 2024 14:49:22 GMT</pubDate>
    </item>
    <item>
      <title>对于动物袭击记录的时间序列，最佳的混合模型方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/650402/what-is-the-best-mixed-model-approach-for-a-time-series-of-animal-attack-records</link>
      <description><![CDATA[我有 2007 年至 2022 年巴西各州动物袭击记录的数据集。我有三个解释变量，它们已标准化以用于分析。为了将数据的时间自相关性纳入混合模型，我考虑使用具有泊松分布（计数数据）的 glmmPQL（MASS 包）。由于此分析不允许获取 AIC 值，因此我考虑通过目视检查残差来评估模型的最佳自相关结构。模型的结构如下。我使用 r.squaredGLMM 函数获得了 R^2 值，但它给出了两个不同的 R^2 值（见下文）。因为这是我第一次使用具有时间自相关的混合模型，所以我想知道我是否朝着正确的方向前进。
模型 &lt;- glmmPQL(attacks~x1 + x2 + x3,random=~1|ID,data=envir,family=poisson, correlation=corGaus(form = ~ year|ID))
###“ID”代表巴西各州，“年份”代表表示每年（2007-2022 年）和每个州的袭击次数。
plot(model)#检查残差
r.squaredGLMM(model)#package MuMIn
 R2m R2c

delta 0.6348790 0.9995354
lognormal 0.6348793 0.9995358
trigamma 0.6348788 0.9995350]]></description>
      <guid>https://stats.stackexchange.com/questions/650402/what-is-the-best-mixed-model-approach-for-a-time-series-of-animal-attack-records</guid>
      <pubDate>Wed, 03 Jul 2024 14:46:02 GMT</pubDate>
    </item>
    <item>
      <title>两个以上分类变量之间的关联</title>
      <link>https://stats.stackexchange.com/questions/650400/association-between-more-than-2-categorical-variables</link>
      <description><![CDATA[是否有一种方法可以检测多个分类变量之间的关联？我知道卡方检验可以帮助我检测成对变量，但想象一下有 5 个变量的用例，并且 V1、V2 和 V3 之间存在隐藏关联：我看不到三元组变量（或更多）之间的关联。]]></description>
      <guid>https://stats.stackexchange.com/questions/650400/association-between-more-than-2-categorical-variables</guid>
      <pubDate>Wed, 03 Jul 2024 14:36:51 GMT</pubDate>
    </item>
    <item>
      <title>如何将意向治疗随机化与区块随机实验设计相结合，以在功效分析中解决组内差异问题</title>
      <link>https://stats.stackexchange.com/questions/650398/how-to-combine-intention-to-treatment-randomization-with-block-randomized-experi</link>
      <description><![CDATA[我想计算我的实验的功效。在多个相似性区块内（例如，相同的性别，相同的治疗前结果），受访者有机会参与治疗。由于只有一半的人（每个区块内）接受了治疗，我有一个意向治疗设计，并想使用 IV（工具变量）来估计这种二元治疗的 LATE（局部平均治疗效果）（也就是说，对符合者而言）。但是，考虑到我的区块设计（以及区块内 n 的大小可能不相等），我很难对这种区块 IV 设计进行功效分析。
我 a) 对我的结果变量的个体差异感兴趣。因此，我将使用它作为治疗前区块变量，只是比实际更粗略。这个结果变量是在 6 点李克特量表上测量的，并以高/低进行区块（另外还有其他因素，如年龄）。 （该结果是对计划的信心，例如为某些参与者提供的计划。）
b) 此外，结果（来自 a）的个体转变会根据其对另一个结果（结果 2）的影响进行测试。结果 2 仅在研究结束时进行测量，没有先前的值。（这是参与/不参与后的健康结果。）
鉴于 b) 中的第二个结果未被阻止，我该如何对此进行功效分析？
我可以使用 R 或 G 功效进行分析。]]></description>
      <guid>https://stats.stackexchange.com/questions/650398/how-to-combine-intention-to-treatment-randomization-with-block-randomized-experi</guid>
      <pubDate>Wed, 03 Jul 2024 14:18:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么加权平均值的标准误差可以小于单个测量的标准误差？</title>
      <link>https://stats.stackexchange.com/questions/650397/why-can-the-standard-error-of-the-weighted-mean-be-smaller-than-the-standard-err</link>
      <description><![CDATA[我使用加权平均值将两个独立测量值与它们各自的标准误差相结合。测量值为：

加权平均值的标准误差（≈0.186）小于第一次和第二次测量的标准误差（1 和 0.19），这对我来说似乎违反直觉。
我认为这是因为第二次测量比第一次测量重得多，标准误差较低。
这是正确的吗？有人能解释一下为什么会这样吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650397/why-can-the-standard-error-of-the-weighted-mean-be-smaller-than-the-standard-err</guid>
      <pubDate>Wed, 03 Jul 2024 14:16:09 GMT</pubDate>
    </item>
    <item>
      <title>关联替代方案/如何测试这种关系？</title>
      <link>https://stats.stackexchange.com/questions/650396/correlation-alternatives-how-to-go-about-testing-this-relationship</link>
      <description><![CDATA[我有来自上游和下游测量仪的大量温度数据。我试图找出大坝泄水对下游温度的影响。为此，我正在比较尾水测量仪（位于大坝正下方）与各个下游站点之间的相关性。这是我的数据集。
&gt; dput(head(TravelTimeAdjustedSaltData))
结构(列表(日期 = 结构(c(1709942400, 1709943300, 1709944200, 
1709945100, 1709946000, 1709946900), 类 = c(&quot;POSIXct&quot;, &quot;POSIXt&quot;
), tzone = &quot;UTC&quot;), S1 = c(12.824443359375, 12.824443359375, 12.824443359375, 
12.824443359375, 12.824443359375, 12.78154296875), S2 = c(12.86734375, 
12.86734375, 12.86734375, 12.910244140625, 12.86734375, 12.824443359375
), S3 = c(12.223837890625, 12.223837890625, 12.26673828125, 12.26673828125, 
12.223837890625, 12.26673828125), S4 = c(NA, NA, NA, NA, 7.8908984375, 
7.847998046875), S5 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S6 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S7 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S8 = c(12.309638671875, 12.309638671875, 
12.26673828125, 12.3525390625, 12.3525390625, 12.309638671875
), S9 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_
), S10 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_), S11 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_), GaugeTemp = c(8.2, 8.2, 8.2, 8.2, 8.2, 8.2), GaugeHeight = c(70.83, 
70.84, 70.84, 70.85, 70.83, 70.83)), row.names = c(NA, 6L), class = c(&quot;tbl_df&quot;, 
&quot;tbl&quot;, &quot;data.frame&quot;))

数据根据下游水流的流动时间进行了调整，这就是为什么某些列的前几行有 NA。无论如何，我进行了 Spearman 相关性分析，但发现了一种意料之外的模式，因此，我认为相关性并没有真正检验出我真正想要发现的东西。我发现，下游站点 (S10 / S11) 与尾水水位计的相关性实际上比下游第一个站点 (S4) 更高或大致相同。我同时包含了 S4（距离尾水下游最近的站点）和 S11（距离尾水最远的站点）来说明我的意思。事实并非如此，因为大坝泄水对下游温度的影响应该会随着距离的增加而减小。这让我相信相关性测试不是我的问题的答案。


cor.test(TravelTimeAdjustedSaltData$GaugeTemp, TravelTimeAdjustedSaltData$S11, method = &quot;spearman&quot;, na.rm=TRUE)
cor.test(TravelTimeAdjustedSaltData$GaugeTemp, TravelTimeAdjustedSaltData$S4, method = &quot;spearman&quot;, na.rm=TRUE)
我不知道如何测试大坝泄洪的原因（即尾水压力表温度读数）及其影响（下游温度读数）。我正在研究两者之间的某种非参数回归（LOESS），但不确定这是否是正确的方法，而且我对局部回归分析也不是很熟悉。任何帮助都将不胜感激。我只是想要一种统计方法来显示大坝泄洪是否确实对下游产生影响。相关性似乎没有达到这个目的（虽然不确定为什么）。]]></description>
      <guid>https://stats.stackexchange.com/questions/650396/correlation-alternatives-how-to-go-about-testing-this-relationship</guid>
      <pubDate>Wed, 03 Jul 2024 14:10:50 GMT</pubDate>
    </item>
    <item>
      <title>使用自举残差估计时间序列预测区间</title>
      <link>https://stats.stackexchange.com/questions/650395/using-bootstrapped-residuals-to-estimate-time-series-prediction-intervals</link>
      <description><![CDATA[我正在使用一个非常简单的预测“模型”，它不是标准的统计模型。我试图使用Hyndman 的教科书中“自举残差的预测区间”部分中描述的方法来估计一些预测区间。
但是，我注意到，如果模型在估计误差的期间内有偏差，那么预测本身就不会位于预测区间的中心。这是因为，平均而言，我们会将正值（或负值）$e_t$添加到预测中以获得我们的“模拟数据”，
$$y_t = \hat{y}_{t|t-1} + e_t.$$
这种偏差在我的用例中并不罕见，因为该模型应用于~1000个时间序列，因此其中一些会以这种方式表现（例如，如果它们在误差估计期间出现意外的水平跳跃，或者如果时间序列有趋势但模型没有考虑趋势等）。

黑线是预测，红色区间是按照上面链接中的方法估算的每 5%（即 5%、10%、...、95%）的预测区间。（训练数据未显示，出于隐私原因，比例已更改）。这对我来说似乎是不可接受的 - 点预测应该是未来值的“最佳”估计，而预测区间则表示最可能的未来值完全在其他地方。我做错了什么，还是这只是这种方法不可避免的怪癖？]]></description>
      <guid>https://stats.stackexchange.com/questions/650395/using-bootstrapped-residuals-to-estimate-time-series-prediction-intervals</guid>
      <pubDate>Wed, 03 Jul 2024 14:06:52 GMT</pubDate>
    </item>
    <item>
      <title>NIBRS 变量，特别是人口</title>
      <link>https://stats.stackexchange.com/questions/650393/nibrs-variables-specifically-population</link>
      <description><![CDATA[我正在使用国家事件报告系统 (NIBRS)。我知道变量通常定义不明确，我找不到对它们的良好描述。我有兴趣了解有关如何解释所有变量的更多信息，但目前我正在尝试确定“当前人口 1”到“当前人口 5”和“最后人口 1”到“最后人口 5”的含义。任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650393/nibrs-variables-specifically-population</guid>
      <pubDate>Wed, 03 Jul 2024 13:13:53 GMT</pubDate>
    </item>
    <item>
      <title>考虑 96 个观测值来估计截距（经验法则）</title>
      <link>https://stats.stackexchange.com/questions/650391/considering-96-observation-for-estimating-the-intercept-rule-of-thumb</link>
      <description><![CDATA[我记得 Frank Harrell 教授曾说过，为了使用经验法则计算样本量，我们必须包括 96 个观测值才能计算截距，因此估计的样本量为 96+15*参数数量。

如果我希望使用经验法则来建立生存模型，我是否仍需要包括 96 个观测值来计算截距？96+15*参数数量

如果我希望按照 Ogundimu 等人的建议使用经验法则，考虑模型中每个参数的 20 个观测值，我是否仍需要包括 96 个观测值来计算样本量？

]]></description>
      <guid>https://stats.stackexchange.com/questions/650391/considering-96-observation-for-estimating-the-intercept-rule-of-thumb</guid>
      <pubDate>Wed, 03 Jul 2024 13:05:25 GMT</pubDate>
    </item>
    <item>
      <title>相对风险率</title>
      <link>https://stats.stackexchange.com/questions/650389/relative-hazard-rate</link>
      <description><![CDATA[我仍然对风险率的含义感到困惑。我想知道如何获得下面示例（Cox 回归）的相对风险率。
library(&quot;survival&quot;)
library(&quot;survminer&quot;)
res.cox &lt;- coxph(Surv(time, status) ~ sex, data = lung)
res.cox
]]></description>
      <guid>https://stats.stackexchange.com/questions/650389/relative-hazard-rate</guid>
      <pubDate>Wed, 03 Jul 2024 12:17:07 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中的混杂变量：辛普森悖论</title>
      <link>https://stats.stackexchange.com/questions/650388/confounding-variable-in-regression-model-simpsons-paradox</link>
      <description><![CDATA[我正在研究一个混合效应回归模型，其中 Yi = 学生 i 的考试成绩。
解释变量如下：

级别 3：学校类型（公立与私立）和学校的社会经济水平（数字变量）

级别 2：每个班级的教育模式（100% 西班牙语、50% 西班牙语、特殊教育）

级别 1：移民背景（学生是否是移民）、学生的社会经济水平（数字变量）、在家使用的语言（西班牙语或其他语言）以及学生的身份（学生是否必须留级）
我使用两个模型来解释 Y。第一个模型不包括变量 student_socioeconomic 和student_idoneity。
model1 = lmer(data = scores, English_score ~ (1| school_id/group_id) +
school_type + school_socioeconomic + group_educational_model +
student_inmigrant + student_language)
model2 = lmer(data = scores, English_score ~ (1| school_id/group_id) +
school_type + school_socioeconomic + group_educational_model +
student_socioeconomic + student_inmigrant + student_language +
student_idoneity)


在第一个模型中，变量“student_inmigrant”的估计系数在 1% alpha 水平上为正且显著。然而，当我添加变量“student_socioeconomic”时和“student_idoneity”，变量“student_inmigrant”的估计系数在 1% alpha 水平上变为负且显著。
我认为这里存在混杂变量的问题，但我不知道如何解决。您能给我一些关于如何处理这个问题的建议吗？
我检查了存在多重共线性时的 VIF 值，但 student_inmigrant、student_idoneity 和 student_socioeconomic 的调整后的 GVIF 都低于 2。]]></description>
      <guid>https://stats.stackexchange.com/questions/650388/confounding-variable-in-regression-model-simpsons-paradox</guid>
      <pubDate>Wed, 03 Jul 2024 12:15:21 GMT</pubDate>
    </item>
    <item>
      <title>元学习器根据匹配数据进行训练</title>
      <link>https://stats.stackexchange.com/questions/650386/meta-learner-trained-on-matched-data</link>
      <description><![CDATA[我正在尝试估计治疗组的平均治疗效果。
我首先使用倾向得分匹配来创建对照组和治疗组。
我最终得到的组规模非常小（每个组 1500 个样本）。
倾向得分匹配的结果是我们无法拒绝两组相似的零假设。
现在我在该数据上训练元学习器（更具体地说是 S-learner）。使用测试集的预测和反事实，治疗组的平均治疗效果为正（结果具有统计意义）。
哪个结果更可靠？]]></description>
      <guid>https://stats.stackexchange.com/questions/650386/meta-learner-trained-on-matched-data</guid>
      <pubDate>Wed, 03 Jul 2024 11:22:44 GMT</pubDate>
    </item>
    <item>
      <title>包含理论上不可能的值（零）的比例的置信区间</title>
      <link>https://stats.stackexchange.com/questions/650383/confidence-intervals-for-proportions-containing-a-theoretically-impossible-value</link>
      <description><![CDATA[这实际上是一个假设性问题，与我遇到的实际问题无关，所以这个问题只是出于好奇。我知道这个其他相关问题当置信区间包含不可能的值范围时，我该怎么办？但我认为我脑海中的细节是不同的。
假设我想估计某种东西在人群中的比例。我从定性研究中知道，这种“东西”在人群中绝对存在，尽管它很罕见（多么罕见，我真的没有关于这方面的信息，除了关于这个主题的几项定性研究中描述的几个观察结果）。我计划计算二项式置信区间（例如 Wilson 置信区间）以获得对总体中合理比例的估计。
但是，在从总体中随机抽取几千个观测值后，我无法在样本中识别出任何这种“东西”，因此置信区间包含 0，尽管我知道零不是可能值，并且我的抽样方法没有问题（除了样本量显然不够大）。
使用 R 的示例，其中“lwr.ci”是计算出的 CI 下限：
&gt; library(&quot;DescTools&quot;)
&gt; BinomCI(0, 50000, conf.level = 0.95, sides = &quot;two.sided&quot;, method = &quot;wilson&quot;)

est lwr.ci upr.ci
[1,] 0 0 7.682327e-05

有哪些方法可以解决这个问题并计算出首先不包含 0 的估计值？在这种情况下我应该使用可信区间吗？（如果是这样，定义先验的一些正确方法是什么？）]]></description>
      <guid>https://stats.stackexchange.com/questions/650383/confidence-intervals-for-proportions-containing-a-theoretically-impossible-value</guid>
      <pubDate>Wed, 03 Jul 2024 09:31:50 GMT</pubDate>
    </item>
    </channel>
</rss>