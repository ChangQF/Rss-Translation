<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Dec 2024 12:35:55 GMT</lastBuildDate>
    <item>
      <title>XGBoost F1 分数改进方法，用于多类分类[重复]</title>
      <link>https://stats.stackexchange.com/questions/658259/xgboost-f1-score-impovement-methods-for-multi-class-classification</link>
      <description><![CDATA[我正在使用 XGBoost 构建多类别分类（5 个类别）。目前使用 56 个特征来处理 160 万个客户群，类别均衡。
总体准确率为 83%，F1 得分为 0.81，AUC &gt; 0.90。如何提高准确率？
我已经进行了以下测试：
无缺失值
交叉验证
异常值处理
逻辑和随机森林（XGBoost 提供更好的结果）
相关性
超参数调整，以下是最终参数：
model = xgb.XGBClassifier(objective=&#39;multi:softmax&#39;, 
num_class=5,
eval_metric=&#39;mlogloss&#39;,
max_depth=6,
eta=0.3,
seed=42
)

任何有助于进一步提高准确率的帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658259/xgboost-f1-score-impovement-methods-for-multi-class-classification</guid>
      <pubDate>Wed, 04 Dec 2024 12:02:44 GMT</pubDate>
    </item>
    <item>
      <title>使用 semopy 中的分类数据进行预测 [已迁移]</title>
      <link>https://stats.stackexchange.com/questions/658257/prediction-with-categorical-data-in-semopy</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658257/prediction-with-categorical-data-in-semopy</guid>
      <pubDate>Wed, 04 Dec 2024 11:15:40 GMT</pubDate>
    </item>
    <item>
      <title>为两个问题生成表格[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658256/generate-table-for-the-two-questions</link>
      <description><![CDATA[
该组有多少成员 2. 此类组的成员中有多少女性 我在 Stata 中遇到了这两个问题，想生成一个表格，显示上述问题 1 中每个组中女性的百分比。提供生成此表格的步骤
]]></description>
      <guid>https://stats.stackexchange.com/questions/658256/generate-table-for-the-two-questions</guid>
      <pubDate>Wed, 04 Dec 2024 09:49:40 GMT</pubDate>
    </item>
    <item>
      <title>横截面数据中条件独立与边际依赖的真实示例</title>
      <link>https://stats.stackexchange.com/questions/658255/real-world-examples-of-conditional-independence-with-marginal-dependence-in-cros</link>
      <description><![CDATA[在之前的问题中，我探索了仅使用条件独立性假设来推导联合似然 - 仅使用条件独立性假设（无边际独立性）推导联合似然 。
现在，我有兴趣了解现实世界中的应用或数据集，其中观察到边际依赖性的条件独立性。
问题：

是否存在众所周知的现实世界用例或数据集，其中出现这种类型的关系？
哪些类型的统计模型或领域（例如经济学、医学、社会科学）通常会遇到这种关系？

我希望得到示例、参考资料，或有关该主题的任何相关讨论，以便更好地理解其在实践中的含义。]]></description>
      <guid>https://stats.stackexchange.com/questions/658255/real-world-examples-of-conditional-independence-with-marginal-dependence-in-cros</guid>
      <pubDate>Wed, 04 Dec 2024 09:33:06 GMT</pubDate>
    </item>
    <item>
      <title>如何进行时间序列预测</title>
      <link>https://stats.stackexchange.com/questions/658251/how-to-approach-time-series-forecasting</link>
      <description><![CDATA[我正在研究一个涉及高频数据（每小时或每 10-15 分钟）的时间序列预测问题，例如能耗或其他 IoT 设备指标。我的目标是预测第二天（或可能更短的时间范围，取决于可行性）的能耗。
过去，我曾使用 LSTM 神经网络解决过类似的问题，但这次，我想采用更系统的方法。我的目标是尝试不同的模型，以确定最适合我的用例的模型。
目前，我有几个月的数据。我正在考虑是否使用此数据集来测试模型，或者使用 Kaggle 中涵盖数年的类似数据集。由于我要预测的数据表现出很高的季节性，因此拥有更多数据似乎很有益。我检查了 ADF 测试和 ACF 图，发现数据是平稳的，并且具有很强的季节性。
我拥有的数据集包括以下变量：

时间戳
能源消耗
其他一些与电力相关的变量

由于数据的季节性很强，我正在考虑添加诸如一年中的某天、一天中的某小时和一周中的某天等特征。我的探索性数据分析表明，这些特征会显著影响数据，尤其是一天中的某小时。添加这些特征会将问题从单变量预测转变为多变量预测，这可能会影响模型的选择。我目前正在考虑的模型是 XGBoost 或深度学习模型。
最后，我正在考虑如何在生产中维护模型。在训练和部署模型后，是否应该定期使用新数据对其进行重新训练以纳入更多背景信息？如果是，建议的再培训频率是多少？
我明白，这些问题中的一些可能不是针对每个用例都有明确的答案，但我非常感激任何建议。如果您有可以提供帮助的参考资料或资源，我很乐意探索它们。]]></description>
      <guid>https://stats.stackexchange.com/questions/658251/how-to-approach-time-series-forecasting</guid>
      <pubDate>Wed, 04 Dec 2024 07:10:12 GMT</pubDate>
    </item>
    <item>
      <title>在因子分析中，删除唯一性较低的变量后的新模型对原始模型有何影响？</title>
      <link>https://stats.stackexchange.com/questions/658250/in-factor-analysis-what-does-the-new-model-with-a-variable-with-low-uniqueness</link>
      <description><![CDATA[我正在使用 R 中的 factanal 进行因子分析模型：
$$X=Lf+\mathcal E. $$
当将因子设置为相对较大时，
我收到一个错误，即变量的唯一性（即 $E(\epsilon_i^2)$ 的估计值）接近于零。
虽然我可以通过设置非常小的lower值来解决这个问题，但是这篇文章说这会导致问题。
按照这篇文章的建议，我尝试删除唯一性较低的变量$Y_i$，然后模型就可以正常工作了。
但是，我想问一下，删除$Y_i$后的新模型对原始模型意味着什么？
例如，如果在新模型中，$p$ 个因素拟合良好，我们能否断言在原始模型中$p+1$ 个因素拟合良好？]]></description>
      <guid>https://stats.stackexchange.com/questions/658250/in-factor-analysis-what-does-the-new-model-with-a-variable-with-low-uniqueness</guid>
      <pubDate>Wed, 04 Dec 2024 05:51:04 GMT</pubDate>
    </item>
    <item>
      <title>我可以在使用组学数据的两阶段研究的两个阶段中使用 FDR 进行多重校正吗？</title>
      <link>https://stats.stackexchange.com/questions/658248/can-i-use-fdr-for-multiple-correction-in-both-stages-of-a-two-stage-study-using</link>
      <description><![CDATA[请问我是否可以在使用组学数据的两阶段研究的两个阶段中使用 FDR 进行多重校正。例如，基于 RNA-seq 数据，我想识别 20 名患者和 20 名健康受试者之间基因表达差异的基因。我正在考虑一个两阶段的研究设计。首先，作为发现阶段，对 10,000 个基因进行学生 t 检验（我知道可以使用 edgeR 或其他分析方法，但由于这个问题是关于多重比较的，我将使用 t 检验）。获得的 P 值会根据错误发现率 (FDR) 进行校正，q 值 &lt; 0.05 被认为是显著的。结果，50 个基因显示出显著差异。作为下一个阶段，我在与 RNA-seq 测量的样本不同的样本中验证这 50 个基因。另外 20 名患者和 20 名健康受试者通过 RNA-seq 以外的方法进行测量，并再次通过 t 检验进行比较。因此，测试了 50 次（50 个基因），所以我必须进行多次校正。我可以在这里再次调整 FDR 并假设 q 值 &lt; 0.05 是显著的吗？或者我应该在此阶段对 Bonferro 应用校正并将显著性水平设置为 P 值 &lt; 0.05/50（=0.001）？如果您能启发我，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658248/can-i-use-fdr-for-multiple-correction-in-both-stages-of-a-two-stage-study-using</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:39 GMT</pubDate>
    </item>
    <item>
      <title>影响预测的特征的XGboost分类顺序[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658246/xgboost-classification-order-of-features-influencing-predictions</link>
      <description><![CDATA[我正在使用 xgboost 分类创建一个 UFC 比赛预测模型，该模型在包含 2 名战士的统计数据和比赛结果的数据集上进行训练。在训练模型后，我定义了一个函数，我只需输入战士姓名，它就会从战士统计数据数据集中获取他们的统计数据，并将其输入到模型中以预测谁将获胜。但是，当尝试进行新的预测时（例如：xgb_ufc(&quot;Vicente Luque&quot;, &quot;Themba Gorimbo&quot;) 和 xgb_ufc(&quot;Themba Gorimbo&quot;, &quot;Vicente Luque&quot;)），预测结果不同（在这两种情况下，第一个战士都被选为&quot;获胜&quot;））。我尝试过减少过度拟合的方法，但似乎输入比赛统计数据/特征的顺序仍然会影响预测。有人知道这是为什么以及如何解决它吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658246/xgboost-classification-order-of-features-influencing-predictions</guid>
      <pubDate>Wed, 04 Dec 2024 04:06:09 GMT</pubDate>
    </item>
    <item>
      <title>三个相关伯努利随机变量之和的分布，所有变量均具有相同的相关性</title>
      <link>https://stats.stackexchange.com/questions/658241/the-distribution-of-the-sum-of-three-dependent-bernoulli-random-variables-all-w</link>
      <description><![CDATA[$\mathbb{P}(X+Y+Z=z)=\text{?}$
$X,Y,Z\sim \text{Bernoulli}(p)$，并且 $\text{Cor}(X,Y)=\text{Cor}(X,Z)=\text{Cor}(Y,Z)=\rho~, 0&lt;\rho&lt;1$。]]></description>
      <guid>https://stats.stackexchange.com/questions/658241/the-distribution-of-the-sum-of-three-dependent-bernoulli-random-variables-all-w</guid>
      <pubDate>Wed, 04 Dec 2024 01:41:00 GMT</pubDate>
    </item>
    <item>
      <title>如何手动计算自相关</title>
      <link>https://stats.stackexchange.com/questions/658213/how-to-calculate-autocorrelation-manually</link>
      <description><![CDATA[我学过滞后 $k$ 的时间序列中的自相关是所有以此滞后为间隔的值对之间的相关性。
假设我想试一试，并手动计算滞后 1。
模拟一些白噪声
set.seed(123)
TS &lt;- ts(rnorm(1e3))

然后手动计算自相关并使用内置函数。
calc_autocorrelation_manually &lt;- function(x) { cor(x[-1], x[-length(x)]) }

&gt; calc_autocorrelation_manually(TS)
[1] -0.02741628
&gt; 
&gt; acf(TS, lag = 1, plot = F)

序列‘TS’的自相关，按滞后

0 1 
1.000 -0.027

两者给出相同或几乎相同的结果（我知道 acf() 中的计算并不完全相同，因为它不使用偏差调整。不过，我认为这不会产生实质性差异）。
但是，如果我对模拟 AR(1) 过程执行此操作，结果就不一样了！例如，使用没有噪音的“理想”AR(1)：
&gt; TS &lt;- ts(99999) # 初始值
&gt; for (i in 1:350) { TS &lt;- c(TS, TS[i] * 0.3) }
&gt; 
&gt; calc_autocorrelation_manually(TS)
[1] 1
&gt; 
&gt; acf(TS, lag = 1, plot = F)

序列‘TS’的自相关，按滞后

0 1 
1.0 0.3 

我认为手动计算自相关是不正确的，但正确的方法是什么？为什么在第一个例子中它仍然运行良好？]]></description>
      <guid>https://stats.stackexchange.com/questions/658213/how-to-calculate-autocorrelation-manually</guid>
      <pubDate>Tue, 03 Dec 2024 15:05:35 GMT</pubDate>
    </item>
    <item>
      <title>解释 A/B 测试结果中的 p 值</title>
      <link>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</link>
      <description><![CDATA[我需要解释 A/B 测试结果。因此，我有一个名为 Baseline 的控制队列，还有另外两个名为 NewFTUE 和 AppReopenFS 的队列。
此 AB 测试数据的最大问题是 NewFTUE 的 p 值几乎等于 1，而 AppReopenFS 的 P 值要低得多。
我无法理解两件事：

据我所知，如果平均差异较大且
标准差较小，则 p 值应该变得更小，即零假设应该更容易被拒绝。但我们可以
在这里看到，对于较大的标准差和较小的均值差，p 值要小得多（0.187 vs 0.991）
第二件我无法理解的事情是 95% CI（正如仪表板上所解释的那样，这是“95% 可能包含均值真实差异的值范围”。）。因此，正如您所看到的，对于 NewFTUE，均值差异的置信区间完全位于 0 的左侧。即我们有 95% 的信心，无论我们采用什么样本（对于相同的样本量），与 Baseline 相比，我们都会得到更差的结果。

那么为什么 NewFTUE 的 p 值为 0.991 并且大于 AppReopenFS 的 0.187 值？

编辑：添加以下 p 值的描述：和 这里是文档页面。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</guid>
      <pubDate>Tue, 03 Dec 2024 13:44:27 GMT</pubDate>
    </item>
    <item>
      <title>如何处理 1-5 星评级中的偏见？</title>
      <link>https://stats.stackexchange.com/questions/658166/how-to-handle-bias-in-1-5-star-ratings</link>
      <description><![CDATA[我和一位朋友讨论了我在一家健康保险公司的不愉快经历，为了支持我的印象，我向她指出 trustpilot 给它的分数很低。
有 70 条评论，分布如下：{1：61、2：3、3：0、4：1、5：5}（星级：投票数）。
她的回答是：“哦，但是只有 70 条评论，所以它不算数”。
我最初的想法是 70 不是一个很小的数字；从多项分布来看，如果人们实际上总体上对这家保险公司感到满意，那么随机获得如此负面结果的可能性就很小。
经过进一步思考，我发现问题可能不在于评论的数量，而在于数据收集过程中可能存在的偏见。
由于这不是真正随机选择的调查结果，而是自发报告的结果，数据是否真的代表了整体客户群体？
例如，对保险公司更满意的人是否不太可能留下评论，反之亦然，不太满意的人是否更有可能报告他们的不满？
假设是这样，是否有任何已知的方法或途径可以减少这种偏见？
例如能否根据某种概率分布对评论进行加权？
下面是更多信息，仅用于说明我的进一步研究和思考过程。
我看到了一些关于贝叶斯平均值估计的帖子，例如这个，事实上，根据上述数据得出的 trustpilot 平均评分并不是通过简单的算术平均值得到的。
但是，我不确定这是否解决了我在这里讨论的偏见问题，因为它似乎更侧重于比较具有相同纯算术平均值但基于不同评论总数的评分对。从这个意义上讲，我当然不得不同意有必要进行纠正。但它是否解决了数据收集部分？
我正在讨论的保险公司示例的平均分数（不考虑贝叶斯校正或 trustpilot 所做的任何其他校正）是：
$$\frac {\sum_{n=1}^5 {votes(n) \cdot n}} {\sum_{n=1}^5 {votes(n)}} = \frac {61 \cdot 1+3 \cdot 2+ 0 \cdot 3 + 1 \cdot 4+5 \cdot 5} {70} = \frac {48} {25} \approx 1.37$$
我猜测偏差校正可能看起来像一个非常简单的例子：假设我们知道对保险公司的看法为“n 星”的人写评论的概率与 $\frac 1 n$ 成比例。
那么 $PMF(n)$ 将是 $\frac 1 n \cdot \frac {60} {137}$。
这意味着如果 $x(n)$ 人投了 $n$ 颗星，那么实际考虑该评分的人数将成比例增加 $\frac 1 {PMF(n)}$。 （顺便说一句，这是我边写边编的，如果我错了，请纠正我：这篇文章的目的是就此事征求建议）。
如果我没有记错的话，根据这个逻辑修正后的平均值将是：
$$\frac {\sum_{n=1}^5 {votes(n) \cdot n \cdot \frac 1 {PMF(n)}}} {\sum_{n=1}^5 {votes(n) \cdot \frac 1 {PMF(n)}}} = \frac {\sum_{n=1}^5 {votes(n) \cdot n^2}} {\sum_{n=1}^5 {votes(n) \cdot n }} = \frac {61 \cdot 1^2 + 3 \cdot 2^2 + 0 \cdot 3^2 + 1 \cdot 4^2 + 5 \cdot 5^2} {61 \cdot 1+3 \cdot 2+ 0 \cdot 3 + 1 \cdot 4+5 \cdot 5} = \frac {103} {48} \approx 2.14$$
我的看法是：由于对保险公司满意度较高的人不太可能撰写评论和投票，因此这种方法会给他们的投票赋予更大的权重，以更好地接近如果有可能从所有人那里获得投票，则会获得的平均水平。
这有意义吗？
根据上述问题，是否有任何旨在减少自发报告与设计民意调查可能导致的偏差的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/658166/how-to-handle-bias-in-1-5-star-ratings</guid>
      <pubDate>Mon, 02 Dec 2024 19:29:10 GMT</pubDate>
    </item>
    <item>
      <title>已知 Copula 函数的随机变量和的最优覆盖集</title>
      <link>https://stats.stackexchange.com/questions/658123/optimal-coverage-sets-of-a-sum-of-random-variables-with-known-copula</link>
      <description><![CDATA[设$X, Y$为已知系动词$C$的连续随机变量。让我们访问集合（区间）$S_x(\alpha),S_y(\alpha), \alpha\in(0,1)$，使得$$P(X\in S_x(\alpha))\geq \alpha,$$ $$P(Y\in S_y(\alpha))\geq \alpha$$
对于任何$\alpha$。
如果有帮助，我们可以假设集合是对称的，即$$P(X &gt; \sup S_x(\alpha))&lt; 1-\alpha/2,$$
$$P(X &lt; \inf S_x(\alpha))&lt; 1-\alpha/2.$$
我想找到一个（至少是一个很好的近似值）最短可能集 $S$，使得 $$P(X+Y\in S)\geq 0.9.$$
您知道如何做到这一点吗（至少对于一些非平凡的 copula 示例）？一个基本的猜测是 $S=S_x(0.95) + S_y(0.95)$，其中我使用符号 $A+B = \{a+b: a\in A, b\in B\}$ 表示两个集合 $A,B$。但是，显然，当且仅当 $X=-Y$ 时，这才是最优集合。
此外，我觉得应该存在某种理论将集合 $S$ 描述为 copula 和边际分布 $F_X, F_Y$ 的函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/658123/optimal-coverage-sets-of-a-sum-of-random-variables-with-known-copula</guid>
      <pubDate>Mon, 02 Dec 2024 06:31:31 GMT</pubDate>
    </item>
    <item>
      <title>如何最好地预测显示水平变化和方波类型噪声行为的时间序列</title>
      <link>https://stats.stackexchange.com/questions/658059/how-to-best-forecast-a-time-series-showing-level-changes-and-square-wave-kind-of</link>
      <description><![CDATA[这是 2019 年 3 月至 12 月每隔 1 分钟测量一次的交流电力数据。我想对时间序列进行建模，但样本外预测基本上是恒定的。我从 EDA 中发现了以下内容：

每个工作日的上午 8 点到下午 5 点功率较高，其余时间功率较低。
周六和周日功率较低，其他日子功率较高。

因此，似乎在小时级别和天级别存在季节性。
数据图及其季节性分解如下所示，

我尝试使用带有 exog 变量的 ARIMA 作为一天中的小时和一周中的天，以及带有季节性周期的 SARIMA。由于数据量太大，我暂时无法得到结果。
寻找一些关于如何解决这个问题的指示。
如果我想预测分钟级数据，我是否仍需要平滑数据。在我看来，ARIMA/SARIMA 不起作用，基于 ML 的方法可能更适合。
ARIMA 模型非常适合输入样本，但输出样本只是一个常数值，根本没有跟踪模式。
我是时间序列的新手，很乐意根据需要提供其他信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/658059/how-to-best-forecast-a-time-series-showing-level-changes-and-square-wave-kind-of</guid>
      <pubDate>Sat, 30 Nov 2024 07:05:56 GMT</pubDate>
    </item>
    <item>
      <title>倾向得分匹配：如何决定优先考虑平衡还是样本量</title>
      <link>https://stats.stackexchange.com/questions/657980/propensity-score-matching-how-to-decide-if-prioritise-balance-or-sample-size</link>
      <description><![CDATA[我尝试使用 MatchThem 包以不同的方法（最近或无放回法、最优法、完全法、遗传法）在两组之间执行 PSM。最终，我确定了两个表现良好的模型：一个模型中所有变量都是平衡的，但排除了一些情况；另一个（完整模型）中一个变量略微不平衡，但所有情况都保留。
NEAREST LOGIT
# 在每个插补数据集中执行匹配
m.out_model1 &lt;- matchthem(formula, 
data = new_df_imputed, 
method = &quot;nearest&quot;, 
distance = &quot;logit&quot;,
replace = TRUE,
ratio = 3,
caliper = 0.2)

输出：
所有插补的平衡摘要
Type Max.Diff.Adj M.Threshold
distance Distance 0.0130 Balanced, &lt;0.1
Metastasis_size_at_treatment_mm Contin. 0.0136 平衡，&lt;0.1
Segments_treated_per_session 持续。 0.0336 平衡，&lt;0.1
Metastasis_location_superficial_Yes 二进制 0.0089 平衡，&lt;0.1

平衡平均差异计数
count
平衡，&lt;0.1 4
不平衡，&gt;0.1 0

具有最大平均差异的变量
Variable Max.Diff.Adj M.Threshold
Segments_treated_per_session 0.0336 平衡，&lt;0.1

插补的平均样本大小
0 1
全部 53. 77
匹配（ESS） 26.96 75
匹配（未加权） 45. 75
不匹配 8. 2

完整方法
m.out_full &lt;- matchthem(formula,
data = new_df_imputed,
method = &quot;full&quot;,
distance = &quot;mahalanobis&quot;)

输出：
所有插补的平衡摘要
类型 Max.Diff.Adj M.Threshold
Metastasis_size_at_treatment_mm Contin. 0.0477 平衡，&lt;0.1
Segments_treated_per_session Contin. 0.1179 不平衡，&gt;0.1
Metastasis_location_superficial_Yes 二进制 0.0260 平衡，&lt;0.1

平衡平均差异计数
count
平衡，&lt;0.1 2
不平衡，&gt;0.1 1

具有最大平均差异的变量
Variable Max.Diff.Adj M.Threshold
Segments_treated_per_session 0.1179 不平衡，&gt;0.1

插补的平均样本大小
0 1
全部 53. 77
匹配（ESS） 27.47 77
匹配（未加权） 53. 77

如果我使用第一个模型，我会失去能力（而且我的队列已经很小）。另一方面，选择第二个模型允许我保留整个人群，但这两个群体略微不平衡。但是，我可以通过多变量逻辑回归中包含不平衡变量来解释这一点。
我的问题是：有没有办法确定哪个模型是最佳选择？计算与每个匹配数据集相关的功效以评估使用哪个模型在方法论上是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/657980/propensity-score-matching-how-to-decide-if-prioritise-balance-or-sample-size</guid>
      <pubDate>Thu, 28 Nov 2024 13:21:04 GMT</pubDate>
    </item>
    </channel>
</rss>