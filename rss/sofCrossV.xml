<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 01 Jun 2024 09:17:21 GMT</lastBuildDate>
    <item>
      <title>适合多个独立变量和因变量的研究设计</title>
      <link>https://stats.stackexchange.com/questions/648423/appropriate-research-design-for-multiple-independent-variables-and-dependent-var</link>
      <description><![CDATA[我需要一些关于设计我即将进行的硕士研究项目的定量方面的建议。我的研究设计涉及一项收敛混合方法研究，旨在探索破坏残疾微型企业家（分为不同的亚群）运营的因素。主要目标是衡量这些破坏在亚群中的程度并找出任何显著差异。
在我的文献综述中，我发现了大约 50 个可能破坏这些运营的因素，这些因素将作为我的因变量。我计划将参与者分成几组，这将成为我的两个独立变量：

这些微型企业活跃的五大经济部门。
七种不同类型的残疾。

由于没有残疾人拥有的微型企业的综合名单，我将使用滚雪球抽样在我的研究地点收集数据。
我需要为这个研究项目做出几个决定，在此过程中，我将非常感谢您提供反馈和建议。
首先，因变量的测量尺度。我正在考虑使用二分法尺度（每个障碍是/否）或序数尺度（5 点李克特）。了解参与者的教育水平以及我衡量和比较运营障碍普遍性的目标，我倾向于使用二分法尺度。但是，李克特量表可以捕捉到严重程度，从而更细致地描绘出每个障碍。
其次，我需要决定如何分析数据。如果我选​​择二分测量，那么先进行同质性卡方检验 (r x 2)，然后进行事后检验，这种方法有效吗？考虑到我的抽样方法，我担心这种方法的有效性。如果我使用李克特量表，我会考虑进行双向方差分析或事后检验的 Kruskal-Wallis。但是，我听说方差分析可能并不适用于李克特量表数据。据我所知，Kruskal-Wallis 仅适用于一个独立变量。哪种方法最好，或者我可以考虑哪些其他分析选项？
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/648423/appropriate-research-design-for-multiple-independent-variables-and-dependent-var</guid>
      <pubDate>Sat, 01 Jun 2024 09:12:16 GMT</pubDate>
    </item>
    <item>
      <title>在堆叠中训练和调整元学习器时如何分割数据？</title>
      <link>https://stats.stackexchange.com/questions/648418/how-to-split-data-when-training-and-tuning-the-meta-learner-in-stacking</link>
      <description><![CDATA[我有一个关于元学习过程的数据分割的简单而又棘手的概念问题。
假设我有一个简单的 X_train、X_test 分割，我在此分割上训练和调整了 model_1 和 model_2。现在我想使用 stacker_0 将它们堆叠起来。我设想这样做：
将 X_train 分成 5 折 $F_{i=0}^4$，然后在 $F_{i, i\neq j}$ 上训练 model_1 和 model_2，并在 $F_j$ 上进行预测。然后我将有一个新的数据集 X_train&#39;，我可以用它来训练我的元模型而不会出现泄漏。
我现在的问题是知道我是否可以使用此 X_train&#39; 在 stacker_0 上执行通常的模型选择工作（即超参数调整、元模型验证等）。这样公平吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648418/how-to-split-data-when-training-and-tuning-the-meta-learner-in-stacking</guid>
      <pubDate>Sat, 01 Jun 2024 00:15:32 GMT</pubDate>
    </item>
    <item>
      <title>缺失结果数据的多重填补</title>
      <link>https://stats.stackexchange.com/questions/648417/multiple-imputation-for-missing-outcome-data</link>
      <description><![CDATA[我花了大量时间试图了解 MICE 在帮助“填补”缺失结果数据方面可能发挥的作用。我对多重插补和预测模型都比较陌生，因此我非常感谢您的见解。
问题：我有一个约 70% 国家/地区的临床医生劳动力密度数据集（# 临床医生/100k 人）。我想要一个所有国家/地区的完整数据集（这将使我们能够提供全球临床医生总数），这意味着我需要为其余国家/地区创建插补或预测。我有许多协变量（约 15 个）。但是，这些协变量数据很少是所有国家/地区的完整数据。我的理解是，我通过传统预测模型（使用训练/测试分割）获得所有缺失国家结果估计的能力将受到缺失协变量数据的限制。
我的解决方案：我的想法是使用 MICE 来估算每个国家缺失的结果变量，即临床医生密度。
如果这是 MICE 的有效用途，那么我的问题是如何获得结果变量（劳动力密度）。我已经创建了 m 个估算数据集。我明白我不应该取这些数据集的平均值或选择单个数据集。我还没有找到清楚地解释下一步的出版物，因为 MICE 似乎更多地用于获取回归系数而不是数据本身。我的计划是使用具有完整数据的协变量创建合并回归模型（这限制了我可以使用的协变量），然后使用该回归模型来“预测”缺失的国家劳动力密度。
这合理吗，或者有更好的方法吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648417/multiple-imputation-for-missing-outcome-data</guid>
      <pubDate>Fri, 31 May 2024 23:57:18 GMT</pubDate>
    </item>
    <item>
      <title>给出的例子是否与先前的预测检查相对应？</title>
      <link>https://stats.stackexchange.com/questions/648416/does-the-example-given-correspond-to-a-prior-predictive-check</link>
      <description><![CDATA[有人能向我解释一下贝叶斯推理中先验预测检验的确切含义吗？在一些文档中，人们使用观察到的数据（“我们将观察到的数据与模型的预测进行比较”），而在某些其他文档中，人们不使用观察到的数据（“在观察数据之前总结我们的知识”）。
根据我对贝叶斯的了解（但远非专家），第一种情况让我想起了所谓的后验预测检验，它本身似乎有相当清晰的记录，我相信我很好地理解了这项技术。另一方面，对于先前的预测检查，我仍然不清楚该如何进行。
因此，为了避免空谈，我在下面给出了一个（略显人为的）例子。
假设我试图模拟一分钟内通过给定道路点的车辆数量，对此，我认为使用参数为$\lambda$的泊松分布是合理的。我了解到我们最常使用 Gamma 分布作为 $\lambda$ 的 先验。在类似情况下，1 分钟内通过的车辆平均值约为 $20$，在我看来我应该使用 Gamma( $\alpha$, $\beta$ ) 分布，其中 $\alpha$/$\beta$ ~ $20$。除了我可以将 (2, 0.1) 或 (20,1) 或许多其他的一对作为一对 ($\alpha$, $\beta$)...
因此，我目前对 先前预测检查 的理解使我采取如下方式：

我决定将要进行的 泊松 分布的观察次数，假设 $n = 100$。
我给自己两个值 ​​$\alpha$ 和 $\beta$，使得 $\alpha$/$\beta$ $=20$。
我从 Gamma($\alpha$, $\beta$) 中采样一个值 $\lambda_i$。
利用这个 $\lambda_i$，我从 Poisson($\lambda_i$) 中采样 $n$ 个值，并记下采样的 $n$ 个中的最大值 $M_i$值。
我重复$N$次（例如$1000$次）点3）和4）。
我绘制了$N$个最大值$M_i$的直方图。
我为不同的对（$\alpha$，$\beta$）创建了几个直方图。

我得到的结果由下面的图给出（我没有给出整个程序，以免帖子超载）：

对要进行的实验的讨论得出结论，不可能假设几百辆车可以在 1 分钟内通过给定点（必须消除$(0.2, 0.01)$这对最大值）；另一方面，有时也会出现一百辆或更多的车辆可以通过的情况（必须消除$(20, 1)$和$(200, 10)$这对组合，因为最大值太低了）。
最后，我选择了先验Gamma$(2, 0.1)$，它看起来最合适。
这种推理真的构成了先前的预测检查吗？这是通常的推理方式吗？
如果不是，如果我在详细描述这个例子时完全错了，你能给我一个如何进行事先预测检查的具体例子吗？
任何能解决我疑惑的信息都会受到欢迎！]]></description>
      <guid>https://stats.stackexchange.com/questions/648416/does-the-example-given-correspond-to-a-prior-predictive-check</guid>
      <pubDate>Fri, 31 May 2024 22:04:54 GMT</pubDate>
    </item>
    <item>
      <title>离散时间生存分析（Cox 回归）的样本量</title>
      <link>https://stats.stackexchange.com/questions/648415/sample-size-for-survival-analysis-cox-regression-with-discrete-time</link>
      <description><![CDATA[我有一项研究，患者每两个月来医院检查一次。T0（手术前一周）、T1（手术后两个月）、T2（手术后 4 个月）直至 T9（手术后 18 个月）。
我需要运行包含两个协变量（一个连续的和一个二元时间相关协变量）的 Cox 回归。
似乎时间可以被视为离散的（如果我错了，请纠正我）。
问题：当时间是离散的时，是否有任何函数公式（R 中的包）来计算 Cox 回归的样本量。*]]></description>
      <guid>https://stats.stackexchange.com/questions/648415/sample-size-for-survival-analysis-cox-regression-with-discrete-time</guid>
      <pubDate>Fri, 31 May 2024 20:53:53 GMT</pubDate>
    </item>
    <item>
      <title>矩阵正态分布和多元高斯分布有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/648414/what-is-the-difference-between-a-matrix-normal-distribution-and-the-multivariate</link>
      <description><![CDATA[$\newcommand{\vec}{\operatorname{vec}}$考虑一组 $N$ 矩阵 $X_1, X_2, \ldots, X_N$。我想估计这些矩阵的分布，这些分布由均值和协方差表示。
我通过简单地矢量化我的矩阵 $\vec(X_1), \vec(X_2), \ldots, \vec(X_N)$ 来解决这个问题，然后我计算均值和协方差，就像我对多元高斯分布所做的那样。换句话说，这意味着 $\vec(X) \sim \mathcal{N}(M, \Sigma)$，其中 $\vec(X)$ 经过重新整形后得到 $X$
然而，我遇到了矩阵正态分布，它根据行协方差和列协方差定义分布。因此，从矩阵正态分布中抽样的矩阵由$X \sim \mathcal{M}\mathcal{N}(M, U, V)$给出。
在维基百科文章中，它说，对于随机矩阵$X$，矩阵正态分布与多元高斯分布之间的关系是$X \sim \mathcal{M}\mathcal{N}(M, U, V)$当且仅当$X \sim \mathcal{N}(V \otimes U)$，其中$\otimes$是克罗内克积的运算符。
如果我生成一组随机矩阵，我可以估计以多种方式计算分布的参数。我可以将矩阵矢量化，将其视为多元高斯分布以获得协方差。或者，我可以计算行协方差和列协方差，然后可以从克罗内克积计算协方差。
但是，我从矢量化方法和克罗内克积方法中获得的协方差值并不相同。我应该得到相同的结果吗？如果不是，为什么它们不同？我不明白这些分布在实践中代表什么，所以我不确定在哪种情况下应该使用哪种。]]></description>
      <guid>https://stats.stackexchange.com/questions/648414/what-is-the-difference-between-a-matrix-normal-distribution-and-the-multivariate</guid>
      <pubDate>Fri, 31 May 2024 20:35:43 GMT</pubDate>
    </item>
    <item>
      <title>无偏性 Wilcoxon-Mann-Whitney 检验</title>
      <link>https://stats.stackexchange.com/questions/648399/unbiasedness-wilcoxon-mann-whitney-test</link>
      <description><![CDATA[对于 Wilcoxon-Mann-Whitney 检验，有许多不同的替代方案。一种替代方案是 $P(X &lt; Y) + \frac{1}{2}P(X = Y) \neq 0.5$。对此有令人信服的论据，例如检验统计量本质上是该概率的样本等价物，并且它代表了检验一致的最广泛替代方案。
但是，在这种替代方案下，检验并非无偏。下面的示例说明了这一点。它可能在附加假设下无偏（我怀疑排名数据的方差相等）。不幸的是，我没有找到任何关于这方面的研究；研究通常侧重于其他替代方案，例如随机排序（其中一个累积分布函数始终大于另一个），在这种替代方案下，检验是无偏的。因此，我的问题是：是否存在假设（其他/弱于随机排序）使得该替代方案的测试无偏？
set.seed(123)
reps &lt;- 10^3
p_wmw &lt;- rep(NA, reps) 
for(i in 1:reps){
g1 &lt;- rnorm(80, mean = 0, sd = 5)
g2 &lt;- rnorm(20, mean = .2, sd = 1)
p_wmw[i] &lt;- wilcox.test(g1, g2)$p.value
}
print(mean(p_wmw &lt; .05))

prints: 0.013]]></description>
      <guid>https://stats.stackexchange.com/questions/648399/unbiasedness-wilcoxon-mann-whitney-test</guid>
      <pubDate>Fri, 31 May 2024 16:03:10 GMT</pubDate>
    </item>
    <item>
      <title>我想要回答的假设的最低调查受访者人数</title>
      <link>https://stats.stackexchange.com/questions/648384/minimum-survey-respondents-for-hypotheses-i-want-to-answer</link>
      <description><![CDATA[我是一个热切的统计学菜鸟，所以对于这些基本问题我深表歉意。
我打算向大量人群（美国使用胰岛素的糖尿病患者）（约 840 万）发送一份调查问卷
基于此，我的目标是总共获得 96+ 份调查问卷回复（误差幅度为 +- 10%），目标是接近 300 份回复。
我有一些假设，想在调查结果中加以研究，并将进行一些统计测试

一个假设是“假设：根据用户使用胰岛素的时间，对（xyz 用户需求，仅举一个虚假的例子 - 能够快速计算一餐所需的胰岛素量）重要性的评级存在显著差异”
这将是我收集的一个人口统计问题（您使用胰岛素多长时间了？），答案范围个月。
由于重要性是李克特量表（序数）上的评级，因此各组有所不同，我想了解差异，因此我考虑进行 Mann-Whitney 测试。我特别想了解使用胰岛素的时间越长，是否会影响对这一用户需求的重要性评级。

我的问题：我是否需要至少 96 名回答每个时间段（例如 1 年或更长和 1 年或更短）的受访者才能获得统计签名响应，或者我是否只需要查看回答此问题的所有受访者的总数为 96 的受访者。此外，如果您对我的方法有任何反馈，请随时发表意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/648384/minimum-survey-respondents-for-hypotheses-i-want-to-answer</guid>
      <pubDate>Fri, 31 May 2024 14:24:51 GMT</pubDate>
    </item>
    <item>
      <title>采样以最大化 f(x)p(x)</title>
      <link>https://stats.stackexchange.com/questions/648338/sampling-to-maximise-fxpx</link>
      <description><![CDATA[我有一个概率分布 $p(x)$，我可以非常轻松地从中生成样本。我还有一些函数 $f(x)$，我可以为每个样本计算。我的目标是估算最大化 $f(x)p(x)$ 的 $x$ 的值。我没有简单的方法来计算 $p(x)$ 本身，并且我想避免使用任何 KDE 或任何东西从我的样本中确定 $p(x)$。
我的一个想法是计算大量 $p(x)$ 样本的 $f(x)$，然后根据 $f(x)$ 的值拒绝一些样本。但是 $f(x)$ 没有下限，所以我不确定这是否是正确的选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/648338/sampling-to-maximise-fxpx</guid>
      <pubDate>Fri, 31 May 2024 06:28:36 GMT</pubDate>
    </item>
    <item>
      <title>具有共变预测变量的线性回归模型中的方差比例</title>
      <link>https://stats.stackexchange.com/questions/648334/proportion-of-variance-in-a-linear-regression-model-with-a-covaring-predictor</link>
      <description><![CDATA[给定一个模型：
\begin{align}Y_{i}=Z_{i}*\beta * X_{i} + Z_{i} + \epsilon_{i}\tag{Eq. 1}&amp;\end{align&gt;
我对预测变量 $X$ 解释的方差比例的封闭公式感兴趣，通常也称为判定系数。请注意，在此模型中，变量 $Z_{i}$ 与 $X_{i}$ 共变，因此这不一定是具有单个预测变量的线性回归模型。
我知道可以使用以下表达式计算方差比例（又名判定系数）：
\begin{align}R^2=\beta^2*\frac{V(X)}{V(Y)}\tag{Eq. 2}&amp;\end{align&gt;
我认为有两种可能的替代方案可以实现我的目标：

将响应变量 $Y_{i}$ 除以 $Z_{i}$，这样：
\begin{align}\frac{Y_{i}}{Z_{i}}=\beta * X_{i} + 1\tag{Eq. 3}&amp;\end{align&gt;
然后使用 $Eq. 2$。

将 $Z_{i}$ 的期望视为常数，使得：
\begin{align}Y_{i}=\beta&#39; * X_{i} + \operatorname{E}(Z)\tag{Eq. 4}&amp;\end{align
其中 $\beta&#39;=\operatorname{E}(Z)*\beta$。然后相应地使用 $Eq. 2$。


当我将某些模拟数据（此处未显示）上通过线性回归估计的斜率与预期斜率（使用模拟数据的先前信息计算）进行比较时，对于 Eq. 3 和 Eq. 4，我确实得到了非常准确的结果。
对于 Eq. 4 模型中计算的 $R^2$，情况并非如此。
我推测，将 $R^2$ 表达式应用于 Eq. 2（对于单个预测器线性回归准确）可能对 Eq. 1 中的模型不太好。]]></description>
      <guid>https://stats.stackexchange.com/questions/648334/proportion-of-variance-in-a-linear-regression-model-with-a-covaring-predictor</guid>
      <pubDate>Fri, 31 May 2024 01:21:40 GMT</pubDate>
    </item>
    <item>
      <title>方差分析不显著但事后分析显著 - 如何解释？</title>
      <link>https://stats.stackexchange.com/questions/648329/anova-not-significant-but-post-hoc-is-how-to-interpret</link>
      <description><![CDATA[我有一些关于动物的数据，它们的饮食（食肉动物、杂食动物、食草动物）以及它们的轨道相对于头骨中线的角度。通常，食肉动物的眼睛更多朝前，而食草动物的眼睛角度更大（眼睛在头部侧面），以便在进食/饮水等时能够看到更多周围环境。
我的数据如下所示：

我在同一块中运行了 ANOVA 和事后检验，但 ANOVA 返回 p&gt;0.05，而 Tukey 显示某些组之间存在差异
diet.aov2 &lt;- aov(mean_pos ~ Diet, data= raw_skull)
summary(diet.aov)

TukeyHSD(diet.aov2)

-------

Df Sum Sq Mean Sq F value Pr(&gt;F)
Diet 2 501 250.5 2.345 0.13
残差 15 1602 106.8 
Tukey 均值多重比较
95% 家族置信水平

拟合：aov（公式 = 平均值 ~ 饮食，数据 = raw_skull）

$饮食
diff lwr upr p adj
食草动物-食肉动物 16.474861 6.96985 25.979873 0.0003479
杂食动物-食肉动物 -3.728538 -12.86324 5.406165 0.5881155
杂食动物-食草动物 -20.203399 -29.17716 -11.229635 0.0000054

我认为这是不可能的，我也不确定如何解释它。事后检验的结果从生物学角度来看是有意义的，但为什么方差分析不显著呢？
这怎么解释呢？或者我应该运行不同的测试？
这是我的图
]]></description>
      <guid>https://stats.stackexchange.com/questions/648329/anova-not-significant-but-post-hoc-is-how-to-interpret</guid>
      <pubDate>Thu, 30 May 2024 06:59:52 GMT</pubDate>
    </item>
    <item>
      <title>一个结果变量可以在同一个模型中使用两次吗？</title>
      <link>https://stats.stackexchange.com/questions/648251/can-an-outcome-variable-be-used-twice-in-the-same-model</link>
      <description><![CDATA[在什么时候，在同一个模型框架中的两个似然中使用同一个结果变量是合适的？
下面是一个具体的例子：
model{
y ~ bernoulli( (1-psi) * mu);
y ~ bernoulli( (1-psi) * theta);

u ~ bernoulli( theta);
}


我能够使这个模型工作的唯一方法是在两个单独的似然中使用 y。该模型公式完美地恢复了模拟参数。
在联合似然（混合模型，Stan 中的 log_mix）中执行此操作会导致 mu 的估计有偏差。它仅在可能性独立时才有效。
更新：添加了 R 模拟代码以显示问题的生成过程：
set.seed(2)
n = 1000
psi = 0.23 # 假阴性比例
beta0 = -0.5
X = rnorm(n)
beta = 0.01

y = rbinom(n, size = 1, prob = (1 - psi) * 1/(1+exp(-(beta0 + beta * X))))

# 计算&quot;true&quot;模拟成功概率，考虑 beta * X
# 模拟此问题的更彻底的方法是首先仅使用 beta0 生成 y 值，
# 然后模拟 X 值，但我试图让此代码块保持简洁。
alpha = 平均值（1/（1+exp（-（beta0 + beta * X））））

u = rbinom（n，1，1/（1+exp（-alpha）））

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648251/can-an-outcome-variable-be-used-twice-in-the-same-model</guid>
      <pubDate>Wed, 29 May 2024 22:38:31 GMT</pubDate>
    </item>
    <item>
      <title>具有聚类 SE 或 GLMER 的 GLM</title>
      <link>https://stats.stackexchange.com/questions/648313/glm-with-clustered-se-or-glmer</link>
      <description><![CDATA[我正在对 113 名受试者进行行为经济学实验，每人回答从 10 个问题中随机挑选出的 6 个问题。我的因变量是二进制的（错误 = 0 或错误 = 1），我正在使用逻辑回归。我不知道在具有个体随机效应的 GMLER 或 GLM 之间进行选择，然后在个体层面进行聚类 SE。我认为两者都可以控制个体内相关性 + GMLER 还会增加个体间变异性。我尝试了这两种模型，但得到了非常不同的结果，我不确定如何解释它以及选择哪种模型......特别是我不明白为什么我的所有系数在 GMLER 中都是显著的，但在 GLM 中却不是。这是否意味着随机效应捕获了部分无法解释的方差？因此 GMLER 是一个更好的模型？感觉我的 p 值“好得令人难以置信” ...
我使用 GLM（上）和 GLMER（下）进行了两次逻辑回归，并比较了结果。我得到了非常不同的标准错误和 p 值...我应该相信哪一个？

# glm
model2 &lt;- glm(Error ~ Complexity + Response_time + 
Response_time:Complexity, family = binomial(&quot;logit&quot;), 
data = B)
clustered_se2 &lt;- coeftest(model2, 
vcov. = vcovCR(model2, cluster = B$Individual, type = &quot;CR2&quot;))
p_values2 &lt;- clustered_se2[, 4]

# glmer
model &lt;- glmer(Error ~ Complexity + Response_time + 
Response_time:Complexity + (1 | Individual), 
family = binomial(&quot;logit&quot;), data = B)

]]></description>
      <guid>https://stats.stackexchange.com/questions/648313/glm-with-clustered-se-or-glmer</guid>
      <pubDate>Wed, 29 May 2024 16:08:04 GMT</pubDate>
    </item>
    <item>
      <title>具有 $\sigma^2$ 未知值的简单线性回归的最大似然估计量</title>
      <link>https://stats.stackexchange.com/questions/648163/maximum-liklihood-estimators-for-simple-linear-regression-with-sigma2-unknow</link>
      <description><![CDATA[假设我们有以下形式的简单线性回归模型：
$$Y_i = \beta X_i +\varepsilon_i$$
以下一组“经典假设”成立：

$E(\varepsilon_i)=0$

$Var(\varepsilon_i) = {E}(\varepsilon_i^2)-{E}(\varepsilon_i)^2= {E}(\varepsilon_i^2) = \sigma^2$

$Cov(\varepsilon_i, \varepsilon_j)=0$ 对所有 $i\neq j$

$\varepsilon_i$ 是正态的

$X_i$ 是常数，而不是随机变量。


我想找到 $\sigma^2$ 的最大似然估计量（假设它是未知的），以及 $\beta$ 的最大似然估计量（假设 $\sigma^2$ 是未知的）。
作为背景，假设 $\sigma^2$ 已知，则有以下公式表明 OLS 估计量是 MLE 估计量。
由此，我们可以看出 $\beta$ 的 OLS 估计量是通过求解以下公式得出的：
$$ \text{minimize s.t.} \beta: f(\beta) =\sum (\hat{\varepsilon_i}^2) = \sum (Y_i - \beta X_i)^2$$
我们可以很容易地看出，因为 $\frac{df}{d\beta} = \sum (-2Y_iX_i + \beta^2 X_i^2)$ 和 $\frac{d^2f}{d\beta^2} = 2X_i^2 \geq 0$ 则 $\beta$ 的 OLS 估计量由下式给出：
$$\hat{\beta} = \dfrac{\sum X_iY_i}{\sum X_i^2}$$
我们可以轻松证明这也是最大似然估计量。我们首先查看似然函数，它定义为$Y_i&#39;s$的联合概率密度函数，并回想一下，$\varepsilon_i$为正常的假设意味着$Y_i$为正常的。我们有：
$$L(\beta) = \prod \frac{1}{\sqrt{2\pi\sigma^2}}\exp(\frac{-1}{2\sigma^2}(Y_i - \beta X_i)^2)$$
$$ \therefore L(\beta) \frac{1}{(2\pi \sigma^2)^{\frac{N}{2}}} \exp (\frac{-1}{2\sigma^2}\sum (Y_i - \beta X_i)^2$$
如果我们考虑对数似然函数，我们得到：
$$l(\beta) = \text{ln} \left [ \frac{1}{(2\pi \sigma^2)^{\frac{N}{2}}} \right ]\frac{-1}{2\sigma^2}\sum (Y_i - \beta X_i)^2$$
这又是一个相当简单的问题，最大化$l(\beta)$，这再次表明$$\hat{\beta} = \frac{\sum Y_iX_i}{\sum X_i^2}$$
这是我有点困惑的地方。我是否应该将最大似然函数视为：
$$L(\beta,\sigma^2) = \prod \frac{1}{\sqrt{2\pi\sigma^2}}\exp(\frac{-1}{2\sigma^2}(Y_i - \beta X_i)^2)$$
然后根据 $\sigma^2$ 和 $\beta$ 找到最大值。此外，我不清楚我实际上在哪里使用了 $\sigma^2$ 已知的假设？这在考虑置信区间、假设检验等时显然是相关的。但我不清楚 $\sigma^2$ 已知或未知如何影响上述推导。
谢谢您的帮助，
Hmmm16]]></description>
      <guid>https://stats.stackexchange.com/questions/648163/maximum-liklihood-estimators-for-simple-linear-regression-with-sigma2-unknow</guid>
      <pubDate>Tue, 28 May 2024 18:12:44 GMT</pubDate>
    </item>
    <item>
      <title>R 中的因果影响包显示我的数据呈正增长，而实际应该是下降</title>
      <link>https://stats.stackexchange.com/questions/623612/causal-impact-package-in-r-is-showing-a-positive-increase-in-my-data-when-it-sho</link>
      <description><![CDATA[好的，首先，我使用相同的数据集创建了不同的图表，没有出现任何问题。我现在遇到的问题是尝试让因果影响包将我的数据绘制为减少，但相反，它显示出增加的趋势，这是不正确的。
首先，我加载了我的包。
## 包

library(lubridate)
library(ggplot2)
library(CausalImpact)

然后我确保我的日期变量看起来不错，并在我的 df 中添加了一年列
raw_data$Date -&gt; dates
ymd(dates) -&gt;日期

raw_data$Year = NA
raw_data$Year &lt;- year(dates)

然后我为因果影响分析创建了前期和后期

#创建日期变量
rdate &lt;- seq(as.Date(&quot;2018-09-01&quot;), by = &quot;month&quot;, length.out = 34)

#建立前期/后期
pre.period &lt;- as.Date(c(&quot;2018-09-01&quot;, &quot;2020-02-01&quot;))
post.period &lt;- as.Date(c(&quot;2020-03-01&quot;, &quot;2021-06-01&quot;))

# 结合 DV 和 IV 进行分析
comb &lt;- zoo(cbind(raw_data$ADP), rdate)


当我使用 ggplot2 绘制数据时，没有任何问题。
which(raw_data$Date == &quot;2018-09-01&quot;)
which(raw_data$Date == &quot;2021-06-01&quot;)

df &lt;- raw_data[19:nrow(raw_data),]

df$rdate &lt;- rdate

ggplot(data=df, mining = aes(x=rdate,y=ADP)) + geom_line()


然后我运行了因果影响分析
impact &lt;- CausalImpact(comb, pre.period, post.period, model.args = list(niter = 10000, nseasons = 12, season.duration = 1))

但是当我在运行分析后尝试绘制数据时，问题就出现了。它没有显示使用 ggplot2 时类似的趋势，而是显示我的数据在增加（但事实并非如此）。如您所见，ggplot2 中的图表与因果影响包中的原始图表不同，而它们应该是相同的。
plot(impact)
summary(impact)
impact$summary
summary(impact, &quot;report&quot;)


我运行了完全相同的代码和分析，但时间范围更长，从 2017-03-01 到 2021-06-01，我没有遇到问题并得到了这些结果。
如果主要区别在于我使用的日期，为什么我会遇到问题？我是否需要在 impact 命令中做出规定才能绘制下降趋势？或者 [causalimpact] 无法绘制并解释下降趋势？到目前为止，我所做的分析都是正向/增加趋势。主要问题是当我的结果应该下降时尝试运行这些分析。
对此有什么想法或建议吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/623612/causal-impact-package-in-r-is-showing-a-positive-increase-in-my-data-when-it-sho</guid>
      <pubDate>Wed, 09 Aug 2023 17:57:01 GMT</pubDate>
    </item>
    </channel>
</rss>